function in a certain set of brain regions. But a really persistent mystery, at least to me, is like
what makes activity in a visual region good for vision, like what makes activity in a memory region
good for memory, so on. I think that's been a persistent mystery. And I think it could start to be
addressed by applying these more kind of theoretical motivations for why activity looks the way it does
by using something like efficient coding again, where the idea is the brain needs to transmit
maximal information in a compressed form or economical form to improve behavior. And one way that
this has been proposed to be implemented in the brain is by, again, redundancy reduction, which makes
a really nice link to lossy compression again.
So the rest of the talk will be trying to show how we can think about efficient coding and lossy
compression in brain networks. I'm going to skip this slide for time. But basically, there's a lot
of evidence in like insect neuroscience that cells of an insect retina and their ganglia are really
optimized to pick out specific sensory features that help them distinguish objects or distinguish prey.
And this idea is consistent with efficient coding because efficient coding says we need to allocate
our limited resources to best represent the things that matter most to that organism.
But in this talk, I want to say, as humans, we have way more neurons. It's really hard to know if this
generalizes. We also are in different niches. We're not just in this natural habitat. We have abstract niches.
And so we wanted to test if these theories generalize, we can come up with a model that
generalizes this to the level of systems. Okay, so specifically, I'm going to be arguing that we
can try to think of efficient coding and data compression as network communication via random
walks. And then I'll be showing how we can find evidence that the brain is investing its metabolic
