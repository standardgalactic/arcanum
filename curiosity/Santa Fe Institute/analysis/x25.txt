and cellular resources to improve this kind of random walk mechanism.
So again, we're thinking of compression via this rate distortion function. But now our question is,
how can we construct a rate distortion function using brain network properties or data? Ignore that.
That's me and my cat. And so the question is, yeah, can we describe this using a random walk? So in
order to do this, there's two questions that are seemingly unrelated, but I'm going to show you that are
actually related. So one is, how many randomly propagating particles would a source need to emit for a
least one of those particles to travel towards a target along a specific path with any given
probability? And the other question is, how can macro scale brain circuits compress information?
And the first one seems really like mathematically tractable, whereas the second one is that one we
actually care about and might be a little bit more like metaphorical for computers. But I want to show
you that like these are actually related and can help us understand compression. So if we think of a random
walk across a network has discretized neural activity flow that propagates across structural
connections according to their strength, we can kind of get this model of the communication of neural
signals. This model has been predictive of the flow of activity of the complexity of connectivity
and of behavioral performance. So we think it's a good model. We can use the number of random walkers
it takes to communicate from any region to another region as kind of this rate measure. And a random walk is
naturally implementing a repetition code because the random walkers are identical. But the question
is, can we get one random walker to travel along the shortest path if we assume that traveling along
a longer path introduces noise and distortion? So if longer paths are introducing noise that contaminates
the input, the shortest path between any region is the best we can do in terms of fidelity. And so this
