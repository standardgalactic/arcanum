Alison Kopnik proposes you explore widely, and then later narrow down as you get more experience.
And that's definitely one strategy that can be seen in some if you follow the time series of some
people's browsing patterns. If they explore broadly, and then when they find an interest,
they really dig into it. And so there is some overlap, but not there's some parallels with explore,
exploit literature. But yeah, it's much more goal directed in that literature. Yeah.
Hi. Hi. Yeah.
Because in that literature, there's a difference between novelty and surprise.
That has made, and I thought, like, can it maybe help in this context to, as we were saying,
some people digging deep without a switch? Well, that might be, it could be, potentially,
by including an element of surprise. When you're surprised about something, you might stick with
it a little bit. But then if you're quite novel, like, you want to have a lot of news, you might
switch again. So, I don't know. Does this make, like, does it relate to something you really
thought about? Or what are you including? Because when you chose the parameters, they seem to be
double choices, like go to... Yeah. So, yeah.
Yeah. Yeah. So, in other tasks, like video game tasks, people have tried to
use exactly the ideas you've described to make an agent explore more efficiently.
So, like, there's one where you try to train a Mario character to not just, you know, run left,
right, left, right for a long time before the episode ends and they realize they got no
reward or, like, a good outcome. They try to make an objective that's kind of really similar,
actually, to the reinforcement parameter we have here. They call it, like, count-based novelty.
