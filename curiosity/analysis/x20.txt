pointing from xj to xi, and the node motions. Hence, Eq. 6 implies that the nodes must move
perpendicular to the edge such that the edge does not change length.
If we compile all such
constraints for every edge in E then we obtain E = |E| constraints on the node motions. If these
constraints are independent, then the total number of degrees of freedom is reduced to dN −E.
Among these degrees of freedom, d(d+1)/2 are rigid body motions that do not change the distance
between any pair of nodes. Hence, the number of conformational degrees of freedom is given by
DoFC = dN −E −d(d + 1)
2
.
This line of reasoning was ﬁrst put forth by Maxwell [78] in 1864.
Many important extensions of this idea exist. One important extension considers the violation of in-
dependent constraints. This violation can occur in several ways. One such way is over-constraining a
network. For example, a network of N = 4 nodes embedded in d = 2 dimensions is over-constrained
if we place edges between all node pairs, such that E = {(1, 2), (1, 3), (1, 4), (2, 3), (2, 4), (3, 4)}. Here,
there are |E| = 6 edges, such that DoFC = [(2 × 4) −6] −3 = −1. For a network to possess neg-
ative degrees of freedom, there must exist patterns of edge compressions and tensions that are
load-bearing, such that there are balanced internal forces held within the edges and experienced by
the nodes [52]. In the conformational change theory of curiosity, we treat such states of self-stress
as aversive. Practically, whenever DoFC becomes negative, we resolve competing constraints by
incrementing the embedding dimensionality by 1.
5.5
Statistical testing
We use non-parametric permutation testing to determine whether feature curves, such as those for
compressibility and conformational ﬂexibility, for empirical knowledge networks diﬀer signiﬁcantly
from those for corresponding null model networks [79]. For a given feature, we ﬁrst compute the
area A between the average curve for the observed data and the average curve for the null model
data using numerical integration in Python. We then pool all data together and randomly re-assign
each data point to either the empirical data group or the null model data group. Each group results
in a pseudo-curve of values for a given feature of interest. We compute the area A′ between the
pseudo-curves for the two groups and repeat this process for I = 1000 iterations. For the group
diﬀerence between empirical and null model data, we deﬁne the p-value pperm as the number of
times A′ is greater than A divided by the number of iterations I.
5.6
Data and code availability
All data used in the manuscript are available upon request from the corresponding author. All code
used is available at https://github.com/spatank/Curiosity.
21

6
