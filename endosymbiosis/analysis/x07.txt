Life is self-made. Each cell is relatively simple and mindless, but working together in huge populations over long stretches of time, they develop their own programming. How they do it is quite different from how a human programmer would, but from a collective perspective, there are also some surprising similarities.
Life influences future generations. Organisms don’t just worry about their own survival, they put an enormous amount of time and energy into influencing the next generation for the better. Science is only beginning to understand this, but it offers the tantalizing possibility that, in some limited sense, life might steer its own evolution.
More on that next month.

What do you think? Did reading this make you think of life, cells, or evolution any differently? Any new ideas? Does anything I said sound wrong or misleading? Do you have other ways of looking at it? This post is more speculative than usual, and represents some of the ideas I hope to pursue in my PhD research, so I’m very interested in criticism and feedback. If you have any thoughts, please let me know in the comments!

Author Nate Gaylinn (he/him)Posted onAugust 2, 2023CategoriesTheoryTagscells, computers, development, dna, evolution, genetic_algorithms, meaning, platforms, programming, reproduction, universal automaton19 Commentson Universal Automata
A Cell’s Eye View of Evolution
I’m trying something a little different. Over the next few months, I will publish a three-part series about evolution from some (hopefully) new perspectives. This represents how I, personally, have come to think about evolution. I’ll go beyond the scientific consensus to talk about some ideas that are uncommon and controversial. I believe I have a compelling story that’s consistent with established science, but this isn’t authoritative yet. In fact, I’m being a little bold and spicy in the hope of attracting criticism and feedback. I hope these ideas will frame my PhD research, so I’m excited to learn what people find interesting, useful, confusing, or problematic.

I’m doing this because I believe the way we usually talk about evolution obscures what’s really going on. In the “survival of the fittest” story, an individual organism lives its life, making choices that either help it thrive and reproduce, or not. If it’s successful, it will attract mates and have many children who are like them, but a little different, perhaps better. To follow the path of evolution, we then pick a new individual, maybe one of that organism’s children with a beneficial mutation, and see where life goes from there.

That’s an oversimplification of Darwin’s theory of Evolution by Natural Selection. It lacks nuance, but it’s basically correct and useful. The problem is, it’s just one way of looking at the situation, shaped by human bias. Each person is a multicellular individual that lives a long time and reproduces sexually, so it’s natural that we look at evolution from that perspective. But when it comes to life on Earth, we are the exception. The vast majority of life comes in colonies of single-celled organisms, living short lives and reproducing asexually. From that perspective, the process of evolution looks very different.

The next three blog posts will explore that perspective. Part one describes the cell as a tiny robot that uses DNA to program its own behavior. This will illustrate what it means to evolve such a program, and what purpose the program serves. Part two shifts perspective from a single cell to a population of cells over time. This illustrates how when individual cells work together in large numbers, they program themselves, using an evolutionary algorithm much more powerful than mere random variation and selection. Finally, part three discusses the complex ways that life influences the design of its own programming, and effectively “steers” its evolution, in a blind sort of way.

The first post goes out today, and you can read it here. I’ll release the other two installments in September and November. Each post is written to stand on its own, but together they tell a more powerful story, so I hope you’ll come back for more!

Author Nate Gaylinn (he/him)Posted onAugust 2, 2023CategoriesTheoryTagscells, dna, epigenetics, evolution, platforms4 Commentson A Cell’s Eye View of Evolution
Believing is Seeing
Believing is Seeing
(I took this posts’s photo of a banana slug crawling through leaf litter. It’s shape and color resembles some of the leaves, which makes it hard to spot if you don’t know what to look for)

People say all sorts of things about the world, but how can you tell what’s right? If you’re not sure, you probably want to see for yourself. Those other people might be confused, mistaken, suffering from wishful thinking, or actively trying to mislead you, but you see reality for what it is. Right? At the least, you won’t have the same misperceptions as them, so another look is useful. But how much can you trust your own senses? How does perception even work, and how come we’re so often misled?

Like most people, I “just see” everything around me. Sometimes, I become aware of my perspective. I move around to get a clear view. I notice where I’m glancing, and I know I can’t see what’s behind my head. Yet, most of the time I don’t think about those things at all. The visual world just seems to surround me seamlessly, with rich, consistent detail in all directions. Objects are plain to see, trivial to discern from most angles and distances. It all seems so obvious, like a simple “window on reality,” yet nothing could be farther from the truth.

Human eyes have tunnel vision. I only see a tiny spot in clear focus at a time. My eyes constantly dart around, collecting many snapshots of the world as I move through it. My brain gets a continuous stream of these disconnected snatches of imagery that it somehow must turn into an integrated whole. It tracks my position and perspective as I move through the world, to piece the images together and infer a 3D model of my surroundings. This takes a great deal of real time data processing, and more than a little creativity.

One thing humans don’t do is scan a scene from left-to-right, top-to-bottom, like a TV camera, capturing equally high fidelity data of a whole scene. My eyes are drawn to “interesting” features of the visual field, gathering much more detail about those, and leaving large gaps over the “boring” parts of the image where I never bothered to look closely. To get a sense of this yourself, check out this selective attention test on YouTube. It’s pretty shocking how well the brain filters relevant details from irrelevant ones, and shows you only what it thinks is useful. Of course, what’s “interesting” or “useful” is a judgment call, and I’m biased by my context, culture, and evolution. That means I’m blind to important things that I don’t expect, recognize, or know about.

Yet, I don’t notice any gaps in my perception. My brain creates the illusion of a clear and complete view of reality, using a technique called hierarchical segmentation. The image from my eyes is projected into my brain, then layer after layer of neurons interpret that image. The first layer detects patterns and discontinuities in the raw image data: edges. The second layer detects patterns in those edges: shapes. Layers above detect patterns of patterns of patterns, finding textures, objects, faces, bodies, groups, situations, and more. I don’t see pixels, colors, and shapes. I directly perceive the objects and agents in a scene, their properties, activities, and relationships. I experience that as if it were “really there,” even though it’s just a model in my mind, distantly derived from sense data.

The first pass of vision notices low-level features present in the image (edges, corners, curves), but doesn’t know what they mean. Later passes piece those features together to represent larger features (in a desk drawer, that arrangement of curves must be a fidget spinner). Most likely, the lower-level processing didn’t see all the relevant details clearly, but that’s okay. The fidget spinner neurons see enough to recognize what’s there. They tell the edge-detecting neurons what they should have seen, filling in the missing details. This is how I can clearly perceive a whole fidget spinner, even though it’s in shadow and half covered. My brain uses past knowledge of objects, where they appear, what they look like, and how they behave to imagine what was obscured.

This works extremely well, and it’s necessary, since low-level sensory data is noisy and ambiguous. It often helps to have some idea what I’m looking at to make sense of what I’m seeing. Yet, sometimes my brain’s predictions are wrong. That’s not actually a fidget spinner in the drawer, it’s a pile of coins. How could I tell? Well, the fidget spinner neurons projected their predictions down, but looking a little more closely, some of those guesses were clearly wrong. There were some edges that weren’t accounted for, some angles that didn’t fit. The lower level neurons noticed the gap between expectation and reality, so they had to push back and negotiate with the higher level neurons, eventually arriving at an interpretation that was the best compromise across multiple levels of analysis.

What I perceive is a blending of what my senses took in and what “makes sense” for me to see based on past experience. At first glance, I only notice the most eye-catching details and my mind fills in the rest. If I take my time to really look over a scene, exploring every corner and paying attention to details, then my past experience has less influence and I perceive reality more like it truly is. I’m giving my lower-level perceptions the best chance to find evidence that I wasn’t expecting to see, which might revise my first impression. The problem is, I can’t afford to do this all the time, and often don’t think to. When should I bother to put in the extra effort? When should I distrust my own perception of reality enough to double check?

My brain automatically groups every object I see into categories, collections of objects with similar properties. Each category has a mental stereotype, an image that sort of averages all my experiences. This is how I know the “normal” shape of a fidget spinner, even though no two are the same. It’s where my mind draws from when it fills the gaps in my perception. As I gain experience, I learn more useful ways to group things into categories that better predict their similarities and differences. I build more accurate, nuanced, and fine-grain stereotypes, which makes my perceptions clearer. That said, it’s easy to hold onto bad stereotypes. They warp my perception, overwriting key details of a visual scene that might prove me wrong, rendering them literally invisible to me until someone points them out.

Stereotypes play a central role in perception, and all the fancy understanding, thinking, and being human that layers on top of that. Stereotypes are great tools. They’re bite-sized models of reality that let us generalize past experience and predict the future. But they aren’t real. In fact, many of my stereotypes aren’t based on my experience at all. I learned them from other people! Some may be wrong, hurtful, and dangerous, but I wouldn’t know without personal experience. So far we’ve just been talking about objects, but it gets serious when we move onto people.

I saw this when I worked at Google. They would spoil engineers, with easy access to everything from staplers to lunch to massages. That meant lots of staff to keep the place clean, well stocked, and in good working order. These service workers—these people—were generally ignored, treated as part of the environment rather than part of the team. That’s problematic in itself, but also engineers with darker skin tones often reported being mistaken for the service staff. Despite wearing a nerdy T-shirt and an engineering badge, they got categorized as “the help” based on skin alone. They were ignored, or worse, asked to clean up spills. This was demoralizing, even though there was no ill-intent. They just weren’t seen, by folks who were misled by stereotypes and didn’t even notice.

Knowing all this makes me distrust my own senses, but I think that’s a good thing. They’re mostly reliable, but they can fail in specific ways, and it’s important to remember that. It’s also useful to know when to trust my stereotypes. That mostly comes down to knowing where I have deep personal experience and have paid close attention. Where I don’t, my stereotype might be a shallow hand-me-down, even though it feels just as “real” in my mind. What about you? Have you noticed folks seeing what they want to see, or hearing what they want to hear? How does this generalize to other kinds of perceptions? How do you try to see reality for what it truly is? I’d love to hear from you in the comments.

Author Nate Gaylinn (he/him)Posted onJuly 5, 2023CategoriesIntrospectionTagsattention, brains, google, illusions, minds, neurons, ontology, perception, racism, stereotypes, vision4 Commentson Believing is Seeing
The Programmable Species
The Programmable Species
(Featured image is a photo I took of a hazy city skyline in Seoul, South Korea)

People love to speculate about what sets us apart from other species. We’d like to think if we put a human side by side with any other animal, we’d be smarter, more capable, and dominant. If we’re being honest, though, individual humans aren’t that impressive. Our big brains only make a difference when we gather in groups. It’s the collective intelligence of humanity that changed the world, not the human animal. It’s less rational, less coherent, and harder to control. With modern science and technology, we’re beginning to understand this collective intelligence and how to shape it. But who shapes our culture, and to what ends? How as a society do we want to shape it? These are big questions, but first we need to understand what it means to be “the programmable species.”

Human beings are excellent at independent creative thinking. Yet, alone and without the tools of society, we’re actually pretty helpless. For instance, our big brains demand calorie-dense food, but our jaws are too weak to eat meat unless it’s thoroughly cooked. We can’t start a fire without physical tools (like flint and tinder) and mental tools (like knowing what a fire is for, that we can make one, and how to do that). Thus, to become fully human, we must be programmed with human culture. We depend on our community to shape us, give us tools to survive, teach us a lifestyle, and integrate us into a network of relationships that form a society.

We’re also capable of programming ourselves. That is, we can think strategically and make plans. We can invest in self-improvement, building our knowledge, skills, and relationships in order to achieve new goals. We invent tools that extend our abilities. This is extraordinary, but not unheard of. There are hints of this sort of intelligence in chimpanzees, elephants, crows, and many other species. They make tools, play politics, solve puzzles, and occasionally invent new lifestyles, but they don’t collaborate much. They may help each other, or use each other, but they almost never work “as a team.”

Humans, on the other hand, work together all the time. We form groups with a shared identity, purpose, and plan. We coordinate so that groups of almost any size can act as one much more powerful individual. This is rare in nature, but not unique. Colonial insects do it. What’s different with humans is how we spontaneously form and break these collectives on the fly. We don’t have to evolve new ways of collaborating. We can imagine them and share them with language. We continuously remake our culture, dynamically shifting goals and strategies as each individual nudges the collective in whatever direction they think is best.

