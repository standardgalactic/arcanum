All Sites
Reader
Howdy, effablethoughts
Skip to content
Thinking with Nate
What Intelligence is Not
What Intelligence is Not
(The photo from this post is of a squirrel monkey eating fruit in a tree branch. The monkey is tiny, with golden / silver fur, pale pink skin, and a dark skull cap pattern. The fruit is small and red, perhaps a date. Used without modification under the creative commons license – source)

Life has been steadily driving towards greater and greater intelligence, eventually leading to human beings, who are the very pinnacle of this trend. Our superior minds are what separate us from the animals. They empower us to make a world of human flourishing, and justify our dominion over the planet. These tropes about intelligence are so common in our culture, they almost sound self-evident. Yet, I’ll argue that they’re completely wrong. These ideas are enticing because they appeal to our pride and our sense of specialness, but this way of thinking is destroying our world. So, let’s break down these myths and talk about what intelligence is not.

One problem with this story is it presents intelligence as a linear thing. Life started out dumb, and it gradually got smarter and smarter. In a sense, this is true. More intelligent life is more complicated, so it takes longer to evolve. But life doesn’t evolve towards anything, it evolves in all directions, finding and filling every niche available. Monkeys are brilliant at navigating tree branches and spotting ripe fruit. Trees are brilliant at producing the right amount of fruit at the right moment to use local resources efficiently and maximize the spread of their seeds. Yeasts are brilliant at performing alchemy on that fruit, transmuting sugar into alcohol, which the monkeys love. These are all different kinds of intelligence, and none is “better” than the other because they’re all contextual and interdependent. Every instance of intelligence looks different, because it’s adapted to a unique lifestyle.

We live a very complicated lifestyle that depends on our big brains, so we tend to think that more intelligence is better, but that’s just not the case. Some of the simplest, dumbest organisms on Earth are also the most successful. Microbes, fungus, and plants make up something like 99.5% of Earth’s biomass, while animals (the “smart”ones) make up the rest. Being smart is metabolically expensive. Taking time to think can mean missing a moment of opportunity. Sometimes real intelligence is knowing when a mindless strategy works best. If anything, humans are a great example of how intelligence can backfire. We’ve used our intelligence to make civilization, which is amazing! But in doing so, we accidentally drove many species to extinction, exhausted resources we depend on, and destabilized the global climate. Our kind of big-brained intelligence is a high risk, high reward strategy.

This brings us to the idea that humans are the pinnacle of intelligence. The problem with a word like “pinnacle” is it suggests we are the ultimate form—the thing life’s been building up to, all this time. But we’re not the end of anything. We’re still evolving, and it’s unclear whether our intelligence will go up or down from here. We’re also not the only ones. There are a handful of species that have gone “all in” on the strategy of super intelligence. You know, elephants, dolphins, octopi, the usual suspects. Humans may, in fact, be the smartest of them all, but since intelligence is so contextual, it’s hard to say. Maybe dolphins are more intelligent than us, it just looks different in an ocean species with no hands?

It may seem obvious that human intelligence is something more and different from those other species. We invented the wheel, New York, wars and so on. But that really isn’t because we as individuals are so smart. This is made clear by the tragic case of “wild children,” who grow up without parents or any human community. In the few cases we’ve observed, these children were described as animalistic, violent, and cognitively impaired. They were never able to recover or integrate into human society. Our brains alone do not set us apart from animals. Our society does, and that’s a separate thing, that evolved after our big brains. We’re smarter than other animals not because of our biology, but because of the vast library of practical knowledge and resources that we share with one another.

That’s what sets us apart: other species can’t access human culture. In a sense, that’s because those species are less intelligent; to fully appreciate human society, you need language and abstract thought, which many species lack completely. Yet some species thrive in human society anyway. By being useful (like wheat), or charismatic (like dogs), or sneaky (like raccoons) other species live with us and shape our human world. That’s because nature does not set humans apart from other animals. We set ourselves apart from other life by building walls, by excluding them from our world, to the extent that we can. We decide what plants and animals are pets, food, or pests. Other species don’t need language to live in human society if we choose to accommodate them. We can coexist with nature in community, as many human societies have, and still do. Or, we can perpetuate the myth that we are special to justify excluding and exploiting nature instead.

And, ultimately, that’s the problem with this notion of intelligence: we use it to draw a line between friend and resource. If smarter is better—if our intelligence is what sets us apart from other life, and gives us the right to exploit that life however we see fit—then where do we draw the line? Should smarter people get more rights and privileges than dumber ones? Is a disabled person no better than an animal? Should we simply recycle the feeble minded from our population? This line of thinking is revolting, and it only makes sense if you believe these myths about intelligence. Similarly, if anything less than human is just a dumb resource for us to exploit, why not pave the planet? What’s wrong with processing all of that biomass, every living thing on Earth, into fuel and plastics? I think intuitively we know why: life has a right to exist, and losing all those diverse and beautiful kinds of intelligence would be tragic.

I’m excited to live in a time when our understanding of intelligence is changing so rapidly. It’s hard to define the word, just because we have so many examples that pull in different directions, and seem to contradict one another. Intelligence is many things, and we’re still fleshing out the full picture. Yet, every day we see more clearly that our old conceptions of intelligence that put human beings on a pedestal were wrong, and, more importantly, that they are at the root of so much injustice and destruction. So, while these tropes are still everywhere around us, shape the way our world works, and may still feel intuitively true, I urge you to reject them. We must move on, and embrace a more expansive view, one that doesn’t start from the premise of who to exclude.

Author Nate Gaylinn (he/him)Posted onJanuary 1, 2025CategoriesArmchair PhilosophyTagsculture, diversity, evolution, humans, intelligence, life, Mindless Intelligence, minds, myths, nature, philosophy, science, society9 Commentson What Intelligence is Not
How did AI get so much smarter?
How did AI get so much smarter?
(this month’s photo is a picture of a brown bat. It’s small and fluffy with a stubby nose, and clinging to the gray bark of a tree. Photo by N. J. Stewart wildlife unmodified and used under the Creative Commons license)

When I write about intelligence, I tend to downplay AI and Deep Learning. These are powerful problem solving tools, but they’re over-hyped, and they don’t “think” the way people do. They have no memory, no sense of self, and no goals, at least in the usual sense of the words. But, large language models (LLMs) like OpenAI’s GPT are shockingly good at generating text that seems like something a person might make. They’re much more human-like than anything that came before. Why is that? The short answer is that they use a new kind of Deep Learning architecture known as a Transformer, which introduced a few small tricks that make a very big difference.

The first thing to note is that, while lots of people argue about whether LLMs can answer questions, reason, solve problems, brainstorm, or make art, what they really do is text prediction. They take some words as a starting point and then they guess what comes next based on their training data. If LLMs have any deeper cognitive abilities than that, they must be somehow tapping into the human cultural intelligence that is embedded within that text. Or, maybe they’re just parroting back fragments of intelligent things other people have said, without any understanding or integration—mindless idiots, randomly stringing words together in ways that sound just smart enough to distract us. We honestly don’t know yet! But whatever intelligence they possess, it exists entirely in the realm of language.

Research into getting computers to understand text and speech (known as Natural Language Processing, or NLP) started back in the 1950’s. Back then, computers were specialist’s tools, and making one that anyone could use just by telling it what to do was a dream. At first, researchers tried to formally describe language as we use it, feeding computers dictionaries, grammar rules, and lists of facts, but this never worked! It turns out, we don’t explicitly know all the rules of human language that we intuitively follow, and they’re usually fuzzy rules, with lots of conditions and exceptions. The key challenge of NLP was getting computers (which are obsessively logical and precise) to deal with this messiness and ambiguity, which we don’t even fully understand ourselves. Perhaps the most important advance was when researchers gave up trying to explain language to computers, and instead started teaching them by example.

Modern NLP represents words as lists of numbers called “vectors.” Like an (X, Y) coordinate, each vector represents a point in space. Not physical space, though, more like an abstract space of concepts. Maybe nouns go to the right, verbs to the left. Natural concepts are up, man-made concepts are down. Except, instead of two dimensions, maybe there are 10,000 of them. The layout of this space is pretty arbitrary. The absolute position of a word doesn’t mean anything, only where it is relative to other words. Nearby words have similar meanings, and relationships between words are represented by the distance and angle between them. This is all weirdly self-referential. Words are only defined in terms of other words! But it works surprisingly well. You don’t need explicit rules about which words go together and how, you can just look at lots of examples, and infer those relationships with statistics. People talk about “training” an AI by having it “read” lots of text, but really all that means is iteratively tweaking the lists of numbers, slowly moving the words through this abstract meaning space until they settle into positions that reflect how they co-occur together in the training text.

There’s one big problem with representing words as vectors, though: ambiguity. What do you do with a word like “bat,” which has several meanings? There’s no way one vector can represent this. The trick is to look for context. When you see a phrase like “brown bat” or “wooden bat,” the meaning is clear. Instead of thinking of these as pairs of words, you might think of them as compound words, each with their own distinct meaning. This is a powerful idea, but hard to generalize. Take a more difficult example: “Hearing a strange flutter and crash in the dark, he grabbed his bat for defense and went to investigate” Which kind of “bat” are we talking about? Words like “flutter” and “dark” might suggest the animal, but “grabbing” a bat for “defense” suggests the object instead. We need context to disambiguate, but which context? We’d like to ignore the first half of the sentence (which isn’t talking about the “bat”) and focus on the second half of the sentence (which is).

NLP has found elegant ways to solve this problem. They call these techniques “attention,” since the model is learning to “pay attention” to some words and not others, but I find that name misleading. For human beings, attention is something very different. We seem to have a “mind’s eye” that we can move about at will. We can choose to pay attention to this or that, our attention gets drawn to salient features, and we may even notice our attention drifting and redirect it. But these AIs have no mind’s eye, no will, and no intuition about relevance. The attention models we’re talking about are just more vector math. In addition to finding vectors to represent the meaning of each word individually, they also find vectors to represent patterns of words. They learn, “in this context, these words together mean that.” Adding an extra layer of complexity lets the model represent how words interact to change the meaning of other words or the sentence as a whole.

Researchers have explored many variations on this attention trick. Transformer models use an advanced kind of attention that represents context bi-directionally. They model how different words tend to get modified by context, and how different contexts tend to modify nearby words. The benefit of this is that such a model doesn’t just learn that “brown bat” is the name of an animal, but it might learn that “brown” is an adjective that applies to physical objects, that in English adjectives tend to modify the noun that follows them, and that “bat” can refer to one of several animal species, sometimes distinguished by color. That is, rather than modeling some particular context, models like this can learn general rules and relationships between different kinds of words. They can learn grammar. Not just the “official” grammar of a language like English, but any system of relationships and interactions between words, including dialects, domain-specific jargon, storytelling tropes, or the gender roles of a society.

The other trick that makes Transformers better with language is pluralism. Some NLP systems represent more complex meanings by using bigger vectors. More numbers in each vector means a larger conceptual space. Instead, Transformers use more vectors. They don’t learn the one meaning of this word, they learn to represent the many meanings of this word in the many contexts that contain it. This works a bit like voting. When processing a sentence, several different “attention heads” each consider one possible interpretation of a word, attending to different patterns of contextual cues. The overall meaning is determined by adding them all together. This is really useful for weighing subtle cues against each other to resolve ambiguity, but also to represent sentences with multiple layers of meaning. A word can have many meanings at the same time, and the many meanings of all the words in a sentence can interact in complex ways. The fancy kind of attention used in Transformers can automatically discover this sort of layered structure in language.

As clever as these attention methods are, they are not the secret to Transformers’ success. They do greatly improve the richness of NLP models, but at first they were mostly used with “recurrent neural networks,” a kind of Deep Learning model that processes data sequentially. That’s probably because they work a bit like how we imagine a human reader does: they “read” each word in a text, one at a time, using attention to figure out how each new word should update the meaning of the text so far. This works pretty well, but it doesn’t scale up to long passages of text. These models have a limited attention span, eventually forgetting important details they read several sentences ago. Also, processing long texts one word at a time is painfully slow. Even on the world’s fastest computer, reading a book from beginning to end takes time per page, and training a model like this takes vast amounts of text, so this was a major limitation.

The paper that first introduced Transformers was called Attention is All You Need, which highlights the key innovation: they got rid of the recurrent network, and built an AI using just this attention mechanism, all on its own. In other words, they found a way to do the same vector math, but solving for a large block of text all at once (and possibly out of order) rather than word-by-word. This doesn’t make the model “smarter.” It doesn’t even reduce the overall amount of number crunching. It just makes the work more parallelizable. Instead of having one computer read War and Peace from cover to cover, they could have many computers each read a few paragraphs, then combine their results. This made it possible to throw more money at the problem, using whole datacenters of computers to train a language model on vastly more text than ever before. Billions of documents, trillions of words. It’s the sheer volume of training data that made LLMs so much better. That’s why they’re called “large” language models.

So, how should we think about LLMs like GPT? Well, first off, human language is irregular and complex, but it’s also highly structured. Cleverly designed statistical learning tools can automatically discover that hidden structure just by processing obscene amounts of text. Neural networks are great for letting computers work with these sorts of fuzzy rules. They can extract meaning from text, manipulate it, and generate new text. But to an LLM, words are just vectors, defined by their relationships to each other. They have no connection to physical reality, because LLMs have no physical existence. There is no communication going on when you have a “conversation” with an LLM. To the AI, a dialog is just a sequence of vectors that follow one another according to some grammar. The AI has no mind, no intentions, and no meaning it wishes to convey. It has no conception of being truthful or helpful, only what words tend to follow certain questions. It does not learn from a conversation, it just re-reads the full chat history each time it makes a response. It appears like a good conversational partner, because it is made to imitate one, but what’s happening behind the screen isn’t “thinking” as we know it.

Still, LLMs really are much more human-like than any other AI that came before. Representing language with a high-dimensional abstract concept space works surprisingly well, and so do the “attention” methods described above. They let us represent a huge, open-ended space of ideas that can build on and interact with each other. They let us represent ambiguity, nuance, and innuendo. So, maybe those vector math tricks could actually teach us something about how language processing works in the brain? On the other hand, LLMs are also remarkable in how different they are from humans. An LLM can learn English, but only by reading every document on the internet, not one word at a time, but all at once. In contrast, babies learn language by interacting with the world, learning how words relate to objects, people, events, actions, and desires. Even though they’re exposed to far less language, they learn much faster, and in a way that tightly integrates all of their senses, relationships, and the lifestyle they were born into. Since LLMs seem so human-like, it’s very tempting to imagine them with the same kind of awareness, purpose, and empathy that we have, but they simply aren’t there. Those are a product of being alive in the world, and can’t be found in text, no matter how much of it.

Author Nate Gaylinn (he/him)Posted onDecember 7, 2024CategoriesTheoryTagsai, artificial-intelligence, deep learning, language, large language models, llm, llms, machine learning, machine-learning, meaning, natural language processing, nlp15 Commentson How did AI get so much smarter?
Status Update: End of Semester 3
Well, the third semester of my PhD is wrapping up! I really enjoyed my classes this time around. Evolutionary Computation was super interesting, and sparked all sorts of connections with my research. My class project was a big success, and I hope to turn it into a conference paper. I’ll share more on that later, but here’s a sneak peek if you’re curious. Deep Learning was also pretty great, and I feel like I have a more deep and intuitive understanding of what’s actually going on when you train or interact with an AI. One of the more exciting / challenging topics we covered was Transformers, the new model architecture that powers ChatGPT and its ilk. In some sense, Transformers are quite simple, but they’re definitely not intuitive; understanding why they’re built the way they are, and why that works so well takes some effort. So, to help cement my understanding, I wrote a blog post about it, and you get a bonus episode for the holidays!

Over winter break I hope to develop my Evolutionary Computation class project into a full paper. In short, it’s a new kind of evolutionary algorithm, inspired by endosymbiosis, that works in surprising ways. So far I’ve only used it to solve a trivial toy problem, so I’ll probably also start work on a follow-up study, exploring what practical applications this new algorithm might be good for. And, of course, I’ve got more research ideas to explore beyond that. I’m quite excited to try evolving a population without genomes, for instance. So many ideas! I hope I’ll be able to keep a few projects running in parallel, balancing my time across them, and leaving room for me in between. I’ll continue to share updates as I make progress.

In the spring, I’ll delve even deeper into Deep Learning, with a class that explores counter-intuitive results and how surprisingly effective DL is sometimes. How is it even possible to “learn” using nothing but vector math? What are these models really doing, and why are some models better than others? Should be fun. I’ll also be delving into the math of chaos and fractals. I hope that will be useful for my research into self-modifying dynamic systems (ie, simulated life 😛), and lead to some very pretty visuals I can share. We’ll see!

Anyway, I’ll share the post about Transformers right after this, and that will wrap up another year of blog posts. More to come in January!

Author Nate Gaylinn (he/him)Posted onDecember 7, 2024CategoriesStatus UpdatesTagsclasses, deep learning, evolutionary computation, experiment, research7 Commentson Status Update: End of Semester 3
The Universe Evolves
The Universe Evolves
(This month’s featured image is a photo of the Carina Nebula taken by NASA’s James Webb telescope. It’s a vast cloud of gas and dust, slowly condensing, with hundreds of stars visible in the background behind it. The colorized image almost looks like orange mountains with a blue mist rising from them, set on a black background with bright, six-sided starbursts.)

Normally, when we talk about evolution, we mean what life does. It’s Darwin’s magic formula. You need reproduction. You need to pass on a copy of your genes, with a little variation, so things don’t just stay the same. Natural selection will weed out the less fit individuals, so they have fewer kids. The more fit individuals become more prevalent and, over time, life as a whole evolves to be more fit. Yet, this isn’t a very satisfying story. For one thing, how did it begin? Did life just start evolving out of the blue? I think story is more compelling if we think about evolution a bit more abstractly. In a sense, the physical universe itself evolves. It doesn’t have reproduction and inheritance, but it sure does have variation and selection, and this has caused it to change dramatically over the course of history.

For the first 370,000 years or so, all of space was filled with a boring, homogeneous cloud of energy and plasma. That universe is now extinct, and for one simple reason: it was unstable. In our universe, stability is the ultimate definition of “fitness.” What persists, exists. Patterns of matter and energy that get generated more often and stick around longer become more prevalent. Those that are rare and fragile exist only fleetingly. The plasma universe is gone because gravity causes matter to clump together. It was like a pencil, balanced on its tip. As soon as it became just a little unbalanced, it rapidly fell farther and farther away from that delicate equilibrium. Plasma condensed into molecules, gas clouds, and stars.

Of course, evolution needs variation to work. To find what’s better, you need to weed out what’s worse. For life, reproduction is the engine of variation, but that isn’t necessary if you have unimaginably vast scale. The universe started out with very little variation, but it steadily increased as matter interacted with itself. Gravity caused hydrogen molecules to group together in uneven clumps, and held them there. They sat around for millions of years, slowly growing bigger, until the force of their own weight ignited a fusion reaction. The gas clouds became stars, and in their cores new elements were born. The universe’s population gradually became more diverse.

That’s the counterintuitive thing about stability: it can generate diversity. When patterns become more numerous, and they stick around for longer, chaos starts to kick in. Every star and every planet is a little different. They have unique histories and influences and opportunities. They might be richer in this element or that one, bigger or smaller, hotter or colder, more or less affected by collisions. This diversity only compounds over time, as these objects smash together and interact in complex ways. The longer they stick around, the more they change, recombine, and become more elaborate.

So, for 13 billion years, the universe evolved. Its population became stranger and more complicated. Today we have about a hundred “naturally occurring” elements that didn’t exist at first, but had to evolve through multiple generations of stars fusing atoms, exploding violently, and gradually reforming. We have many kinds of stars, planets, solar systems, and galaxies, that support an astonishing variety of chemical processes that have had a very, very long time to develop. They produce “primordial soups,” pocket environments full of useful molecules for life, a steady energy source, and self-perpetuating chemical reactions. We think this happened at least once to seed all life on Earth, but it may in fact be very common.

I think this story is an essential foundation for understanding evolution as life does it. Because life didn’t start this process. The universe provides energy and raw materials in vast amounts. It provides the chaos and entropy that drives seemingly random variation, and the slow, continual breaking down that causes natural selection to prefer stable, commonly made forms. The laws of physics cause the universe to evolve towards stability, diversity, and complexity, at least for a while, until it starts to wind down again and settle into entropy. Life merely constrains that process, making it more efficient and productive, for the simple reason that matter that does so becomes more prevalent.

In these primordial soups, some chemical systems evolved to enclose themselves in bubbles, protecting delicate reactions from the outside world. These self-made “individuals” evolved regular cycles of reproduction, explicitly making copies of themselves rather than waiting for the right reactants to come together again by chance. They evolved DNA to constrain these copies, and make them more precise reproductions of the original. They evolved sophisticated error checking, which made the copies more robust and reliable. But this also gave life the power to manage variation across generations, and thus shape its own evolution. Life evolved sex to further manage variation, accelerating innovation by sharing genetic recipes across lineages. Life evolved an astonishing variety of sexual and reproductive practices, allowing it to evolve in different ways, with different patterns of variation and selection, each suited to a different range of environments and lifestyles.

The physical Universe evolves—in the most primitive way imaginable, but it still produces stability and complexity in a vast number of diverse forms. It generates the seeds of life, without any guidance or direction. Life evolves differently, because it constrains this process, making it discrete, digital, and managed. This started very simply, just discovering chemical reactions that isolate and maintain themselves. But perhaps this is the origin of what we think of as “intelligence” or “agency”? Without noticing, matter became “opinionated,” preferring certain forms and acting explicitly to promote them. From there, life’s “opinions” about itself only became more demanding and elaborate.

We often present evolution as one simple story, but there are many ways to evolve. Evolution is more like a general principle than a specific algorithm. Even just life as we know it, all based on the DNA molecule, has invented an astonishing variety of different and complex ways of evolving. Bacteria, fungi, plants, and animals use DNA differently. They grow, behave, and reproduce in completely different ways. How many other ways might there be to do it? When we present evolution as a single, constant thing, we limit our imagination. Evolution evolves, and it takes as many diverse forms as it makes.

Author Nate Gaylinn (he/him)Posted onOctober 2, 2024CategoriesBeyond DarwinTagsagency, biology, complexity, diversity, evolution, intelligence, life, origin of life, philosophy, physics, science20 Commentson The Universe Evolves
Status Update: Semester 3
I’m at an interesting moment in my studies, so I thought I’d let you know what’s going on!

Year two of my PhD program has begun. I’m about a month into my third semester, and things are going well. I’m taking two classes right now: Evolutionary Computation, and Deep Learning. Most of my Computer Science education has been about how to design algorithms and write software to solve different kinds of problems, but these classes are different. This semester, I’m learning how to get computers to discover their own algorithms, and write their own software. Honestly, the state of the art here is still quite primitive. We’ve found some very impressive techniques, but they each apply to a narrow domain, and we don’t understand them nearly as well as we’d like. Which makes them fun topics to study. 🙂

The other fun thing about this semester is that both of my classes are built around student projects. More or less, I get to pick projects that fit with my research, and the class is there to help me find the time, resources, and guidance to complete the projects successfully. I like this much better than undergraduate style courses built around assignments and exams that are very generic and may not be relevant to my work. We’ll see how things unfold, but I’m currently planning to work on two projects that I’m excited about.

For Evolutionary Computation, I’m working on an experiment about endosymbiosis. I was inspired by this classic experiment, which examined how bacteria evolve antibiotic resistance, and how genetic innovations spread through the population spatially. I’m going to try evolving a host environment that supports an inner population, a bit like how my gut supports a microbiome. The hope is that the host will be able to design a supportive environment, with different regions that cultivate “microbes” with different traits, such that it can guide and coax them into evolving more specialized forms. This is an exciting experiment for me, because I’m not sure what to expect, but I’m pretty confident that something interesting will happen.

A screenshot from the video linked above, showing strains of bacteria gradually growing into bands with increasing concentrations of antibiotic, fanning out from points where key mutations occurred.

A screenshot from the video linked above, showing strains of bacteria gradually growing into bands with increasing concentrations of antibiotic, fanning out from points where key mutations occurred.

For Deep Learning, I’m going to use computer vision techniques to detect interesting patterns in the Game of Life, since I’ve been using that as an environment for my evolution experiments. The Game of Life has very simple rules, but it evolves in complex ways. Most patterns quickly dissolve into empty space or settle into a few boring, stable forms. But rarely, you get something much more interesting. For decades, people have been exploring this space, finding interesting patterns and classifying them. You get huge complex structures that stabilize themselves, change continuously in repeating cycles, or even propel themselves and move at a steady pace. I’ll build a system that can detect and categorize these patterns, so that when my evolutionary algorithm finds them, I can reward it and ask for “more like that.”

Eater 2, a static shape that persists forever, but has the special property of being able to “eat” gliders that collide with it, recovering its shape after.	Monogram, a period-four oscillator, which is small, but occurs very rarely from random conditions.	
Examples of interesting patterns in the Game of Life. The first is a static shape that persists forever, but has the special property of being able to “eat” gliders that collide with it, recovering its shape after. The second is a period-four oscillator, which is small, but occurs very rarely from random conditions. The third is a middleweight spaceship, which moves forward two spaces as it repeats itself in four time steps.

This month’s essay is inspired by my Evolutionary Computation class, and the work I’ve been doing to develop the specific research questions I want to focus on for my PhD. So, check back on Wednesday to learn more about how evolution got started, and why it’s worth asking: how does evolution evolve?

Author Nate Gaylinn (he/him)Posted onSeptember 29, 2024CategoriesStatus UpdatesTagsai, antibiotic resistance, artificial-intelligence, computer vision, deep learning, endosymbiosis, evolution, game of life, machine-learning, research, technology7 Commentson Status Update: Semester 3
GECCO Follow-Up
GECCO Follow-Up
(I took this post’s photo at the Star Trek Original Series Set Tour in Ticonderoga, New York. It’s a view of the warp core of the USS Enterprise, which is only a few feet deep but looks much larger thanks to forced perspective. The room is filled with structures with complicated geometric shapes, technical looking panels, and dramatic lighting in red, blue, and purple.)

In my last post, I wrote about my latest research project and why I was so excited to present it at GECCO, the premier conference for evolutionary computation. I promised a follow-up, and here it is! Unfortunately, I didn’t make it to Melbourne. Instead, I had a very complicated and protracted battle with my University’s travel planning system, United Airlines, and the Australian visa office, all from the comfort of my home in Vermont. I couldn’t even participate in the event remotely, because of the time zone difference. This is all very disappointing, but I tried to make the best of it. I’ve been busy with the next iteration of this project, and enjoying a bit of “staycation” time here in New England (hence this month’s cover photo).

In any case, my paper did get published, and I’d still like to share the materials I presented virtually at the conference. It’s mostly intended for a technical audience, but I hope at least some of my readers will find it interesting. The paper is titled A Meta-Evolutionary Algorithm for Co-evolving Genotypes and Genotype / Phenotype Maps, and is available for free online. I had to cut it down to just four pages, since it was accepted as a poster, so I also wrote up an extended analysis of my results and an hoverview of my algorithm’s implementation, for those who want to go deeper. There’s also a digital version of my poster and a short video overview of my experiment.

I continue to work on this idea, and it is starting to evolve beyond what I presented in that paper. Right now, I’m actively deconstructing and rebuilding the algorithm. CPPNs are an important and well known part of the AI field, so I’m trying to describe precisely how my algorithm is different, and which of those differences account for the remarkable results I found. Originally I thought of this research as being about epigenetics specifically, but as I try to generalize and simplify, what I’m left with looks like straight-up endosymbiosis. I’ve been thinking of this algorithm as a metaphor for a cell and its genes / nucleus, but it could just as easily be a metaphor for an animal and its community of microbes. This is exciting, since I’d love to do more research on endosymbiosis, and I really like the idea that perhaps symbiosis is the driving force behind intelligence as we know it, fundamentally changing the dynamics of evolution.

Anyway, that’s how I see it for the moment, and where I hope my research will lead in the near future. For now, though, I’m wrapping up my summer with a few more fun outings, and preparing for the start of classes later this month. I’ll be diving deep into both evolutionary computation and deep learning, which I’m really looking forward to.

Author Nate Gaylinn (he/him)Posted onAugust 7, 2024CategoriesSnack-Sized, Status UpdatesTagsalgorithm, CPPNs, endosymbiosis, evolution, evolutionary computation, GECCO, paper, research, school2 Commentson GECCO Follow-Up
Why the Game of Life Paper?
Why the Game of Life Paper?
(This month’s image is a slime mold growing on a log. It grows in a branching network of banana-yellow tendrils, some of which are engulfing plant debris they encountered. Source)

Later this month, I’ll be attending the Genetic and Evolutionary Computing Conference (GECCO) in Melbourne, Australia. I’m super excited to go, and to present my very first published academic paper as a poster. I’ll share more here when all is said and done, but unfortunately my paper isn’t really intended for a general audience, like this blog. It would probably be hard to understand for anyone outside of the fields of AI or ALife. So, for everybody else, I’d like to share what the paper means to me, and what I’m trying to say by publishing it.

My research is inspired by epigenetics, and new ways of thinking about evolution. I saw that life doesn’t just evolve by chance, it evolves to become more evolvable. It learns how to explore the range of possible forms and lifestyles more efficiently, and to nudge evolution down more fruitful paths. Life uses its intelligence to become more intelligent still. In my mind, this changes everything about evolution, and I was shocked it wasn’t more well known. Most discussions of evolution (and the programmer version: evolutionary computation, or EC) are too simple, and ignore these critical details. So, I figured I’d be the one to bring this up, and show people why it matters.

I started my first experiment before I even got to university. I was so excited by the idea, I just had to get it out of my head. I actually avoided looking for prior work, because I wanted to see how I would manifest this idea without being biased by other people’s thinking. Besides, I didn’t know of any research like mine, and I didn’t know how to find it, either. That’s why I applied to UVM. When I got here, my advisor and lab mates encouraged me to publish this project, and pointed me at the relevant literature. So I hit the books, reading all that had been done before in order to put my own work into context.

And, of course, I found I’m not the first to have this idea. There are many variations of EC inspired by biology, looking for the “secret sauce” that makes life more powerful than our computer models. In particular, how life evolves to be more evolvable is an active area of research, which has been building momentum in recent years. At first, I was disappointed. My idea was already taken! So much of what I thought made my project interesting had been tried before in some other context. But not exactly. Identifying those subtle differences has been tremendously helpful.

You see, it’s pretty well established now that “evolvability” is important. In our experiments, simulated life that’s more evolvable finds fitter solutions faster. It’s better at adapting to changing circumstances, too. It seems to be smarter and more creative. I find this exhilarating, yet these discoveries didn’t “change everything” like I had hoped. In the experiments so far, it feels like an incremental improvement. It helps, but not enough to draw much attention away from other areas of AI research, like deep learning, which is seen as much more powerful and more productive.

I think that’s because we still haven’t broken out of our old ways of thinking. Traditional EC is all about finding good solutions to a problem, but I would argue that evolution isn’t about problem solving. It’s about problem finding. Life explores the space of possible lifestyles to find and exploit opportunities. The evolution of life is a bit like a slime mold. It grows simultaneously in all directions, questing around obstacles to find resources, reinforcing the branches that get lucky, culling back the ones that don’t. It doesn’t have a top-down view of the world, but it’s still strategic and adaptive. When I look at most of the existing experiments in this space, I feel like we’re putting a slime mold into a narrow tunnel and measuring how fast it can get to the other end. We’re accidentally putting evolution in a straight jacket, and blinding ourselves to what makes it so interesting and powerful.

So, in my first experiment, I try to show a different perspective. I made a single algorithm that can adapt itself to solve many different tasks. Normally, an EC programmer picks one task to solve, then designs an evolutionary search strategy to suit that problem. They invent a genome language, a way of turning that into a solution, and ways of randomly tweaking the genome that might lead to better solutions. In my experiment, I evolved the search strategy, too. As the programmer, I designed a vast and open ended search domain, and many ways that the algorithm could restrict that space. But I wasn’t sure which restricted sub-spaces would work best, and, unlike traditional EC, I didn’t try to guess. I just let the algorithm figure that out for itself.

The way I did this is also interesting. It turns out, the algorithm I invented is strikingly similar to one that’s already popular: “compositional pattern-producing networks,” or CPPNs. Again, it was a little frustrating to be scooped, but I’m using this algorithm in a new way. Instead of evolving new “bodies” for simulated life, I’m evolving new ways of generating bodies. It’s a subtle difference, but an important one, I think. That extra level of indirection gives evolution more influence over its destiny, and the power to make more complex patterns in ways I couldn’t even anticipate. Now that I know how my idea is so similar to, yet different from, an existing algorithm, I’m teasing apart those differences, to measure the impact of each one.

I’m proud of my work, and excited to talk about it with other EC enthusiasts at GECCO. On the other hand, I’m still figuring out how to do science, and there’s a lot I don’t like about my first paper. This project was mostly my way of proving to myself that this crazy idea could work. The results are intriguing, but it’s not yet a clear example of what I want to show. It’s also complicated, unusual, and hard to explain, even to other EC researchers. If I want people to get excited about this, I need to simplify, make my work more relatable, and find better ways to demonstrate and measure the novel behavior I’m talking about here. There are no “obstacle courses for slime molds” in the EC literature that I know of, so perhaps I’ll need to design some.

Hopefully, I’ll get lots of inspiration and feedback at GECCO. As I learn more about the field of EC, I’m finding more and more examples of work similar, yet slightly different, from my own. This is great, because each of those differences is an opportunity for a new experiment, to see if my perspective can shed light on something new. I’m already dreaming up all sorts of new ways to explore my ideas. And that’s more or less how I hope to spend the next several years. Maybe that’s my PhD.

In any case, I hope that explanation was interesting, and not too vague. I’ll get more specific in a few weeks, when I post a follow up with the full GECCO paper, the poster I presented, a video summary of that poster, and links to some supplemental results and analysis. I bet I’ll have some fun things to report from my time in Melbourne, too! As always, I’d love to hear from you in the comments.

Author Nate Gaylinn (he/him)Posted onJuly 3, 2024CategoriesPersonal Reflections, Status UpdatesTagsai, alife, CPPNs, evolution, evolutionary computation, evolvability, experiment, GECCO, publishing, science, slime mold9 Commentson Why the Game of Life Paper?
Queerness
It’s LGBTQ+ Pride month! I identify as “queer,” so I thought this would be a good opportunity to write a bit about what that means to me.

In addition to queer, I also identify as a cisgender male, pansexual, and demisexual. This means I’ve always identified as male, and others always assumed as much. I’m rarely interested in sex or romance, but when I am, it’s not about gender. I love people, not parts. The full story is more complicated, but that’s a good start.

Labels like “gay”, “bi”, “pan”, “cis”, “demi”, “aro”, and “ace” are useful for quickly describing myself to others, but I prefer the term “queer” because, honestly, I don’t think any set of labels does a person justice.

Gender and sexuality are fundamentally personal things. Each individual is unique. No set of labels can capture all of who I am, and every label carries some baggage that I don’t want applied to me. Labels are useful, just so long as we remember that they’re always at least a little bit wrong. They cannot serve as a stand-in for a person.

I also love queer philosophy, and try to embrace it in all my thinking. Put simply, that means I don’t believe in categories. I don’t think they have any real existence, or essential qualities. They’re convenient fictions. Just labels we make up to point at collections of disparate things. This applies to all categories, but especially to living things, where there are exceptions to every rule, and no hard boundaries whatsoever.

The problem with categories is that we take them seriously. Once we categorize something, we think we understand it, when really we’re just projecting a stereotype. We make strong assumptions about what’s allowed in a category, and we struggle with exceptions, even common ones. As our understanding of the world changes, things often shift faster than our language can keep up with. Sometimes we don’t notice. We keep trying to sort the world into categories that make no sense, and get upset when reality doesn’t play along.

So, I don’t believe that Jews exist. I believe that Jewish people exist, and that we use the word “Jews” to refer to them. Yet, there’s no one quality that all of those people share, except that they are people (another category, subject to change). You and I may not even agree about which set of people the word “Jews” applies to, so how is it meaningful for us to talk about Jews in general?

I don’t think it’s strange to see a Black woman engineer, even though it’s rare. I wouldn’t expect her to be any less competent, just because most folks like her can’t do the job. If anything, I’d assume the opposite, if she can succeed in that role despite the weight of her labels. But, ultimately, it’s about what she has to offer the world, which is surely more and less than the other engineers around her. She has her unique way of doing it, perhaps different in exciting ways.

That’s what queer means to me. Labels can be useful, but they have no power over reality. Reality and people are so much more than words can contain. See them for what they are.

If you’d like to learn more about queerness and queer philosophy, I highly recommend Queer: A Graphic History by Meg-John Barker and Jules Scheele.

Author Nate Gaylinn (he/him)Posted onJune 1, 2024CategoriesArmchair Philosophy, TheoryTagscategories, gender, identity, labels, language, ontology, philosophy, queer, race, sexuality2 Commentson Queerness
The Brain’s “Boss”
The Brain’s “Boss”
(this post’s image is a cross stitch I made from a pattern by Studio Ansitru. The phrase “don’t be a prick” is surrounded by a variety of cacti in pretty greens and oranges on a light blue background. In my home, it serves as a reminder to myself and to my guests.)

A popular metaphor for the mind is a pilot sitting in a cockpit, monitoring the senses and making every decision. This is obviously nonsense, but it’s an intuitive and helpful metaphor at times. The brain really does have “an executive” that thinks and plans and makes decisions, it just doesn’t have “a mind of its own,” and its power over the self is surprisingly limited. Self-control and -awareness are important for living a good life, being productive, and making ethical decisions. Unfortunately, when these faculties fail, as they often do, it’s easy to blame yourself. I find it helps to understand how these systems work, so I can set more realistic expectations for myself, which makes me less disappointed when things go awry.

Perhaps the most important thing to know about the brain is that it’s not one, unified thing. Brains are modular, with many distinct regions specialized for different tasks. Each region has different inputs and outputs, meaning they each monitor the world in different ways from different perspectives, and can cause different behaviors. Observations, insights, desires, and actions can originate in pretty much any part of the brain. All of these different regions operate together at the same time, and conscious experience is an integration of all that activity. What I think, feel, believe, and do is mostly the product of what specific regions in my brain activate together, and in what order.

This story of how brains work is surprisingly consistent across the animal kingdom. Even very simple creatures, like honey bees for instance, have complex brains with specialized regions and global integration that likely creates a sort of conscious awareness. It seems likely, however, that bees lack the sort of self-awareness and top-down control that humans do. Without it, the brain is more chaotic. Each part tries to do the right thing more or less independently. Integration means that most faculties are aware of each other and can influence each other, so there is some coordination and consistency. But focus is mostly determined by which brain region is loudest, and decisions happen moment by moment, without planning or intentional coherence.

Decentralized brains work extremely well, but they have their limitations. More complex animals have more versatile behaviors that need more explicit coordination to generate coherent, reliable, and goal-directed behavior. Most large animals seem to have this ability. In all mammals, it’s more or less identified with a brain region known as the prefrontal cortex, or PFC. The PFC is responsible for monitoring all the activity in the brain. It builds up a rich model of the self, its relationships, needs, and long-term goals. It’s responsible for planning and for exerting control over other parts of the brain. It can shut out distractions and use willpower to encourage good behaviors and discourage bad ones, even when I’d selfishly prefer to do something else.

The PFC tells the story of “you,” and has strong opinions about how that story is supposed to go.

Although all mammals have a PFC (and many other species have something analogous), the relative size of the PFC varies quite a bit between species, and that seems to correlate with executive control and what people often think of as “intelligence.” Animals with large PFCs are better at self-control, problem solving, and forming complex social relationships. Humans have exceptionally large PFCs, which partly explains why we’re so different from other species. It’s important to remember, though, this is a difference in magnitude, not in kind. It’s likely that every mammal and many other species have human-like self-awareness and self-control. It’s just a weaker faculty for them, one that acts less often, and is less able to dominate the rest of the mind.

The PFC is the closest thing to a “pilot” the brain has, but it’s better to think of it as just one brain region among many. It’s one voice in a chorus. It tends to be more bossy, spending a lot of energy trying to influence or even override other parts of the brain, but it’s not “in control.” Like a corporate executive, the PFC has only limited visibility into what the rest of the brain is doing, can’t afford to stay ever-vigilant, and can’t force a brain region to fall in line, especially when the orders run counter to that region’s nature. The PFC also isn’t capable of doing much on its own. It depends on the rest of the brain to notice things, interpret them, suggest actions, and implement them. All it can do is adjudicate and coordinate. It resolves conflict, makes plans, and advises each brain region about when and how to do its thing.

One consequence of all this is that self-control is actually a very limited and fragile thing. Often, my PFC just sits back and lets the rest of the brain work with minimal intervention. Usually that works great, but sometimes it means I miss something important. I may act out of impulse or habit and not notice until it’s too late that I’m going against my values, intentions, or best interests. Other times I know exactly what I should do, but can’t seem to make it happen. I feel unmotivated and uninspired. I can’t force myself to sit down, focus, and avoid distractions. Perhaps I’m grumpy, tired, or impatient and I do something rude or inappropriate without meaning to at all.

When this happens, it’s easy to blame myself. I lost control. I did something foolish. I acted selfishly and impulsively, like a bad person. In reality, though, this happens all the time, usually for mundane reasons that I have little control over. The PFC is energy intensive, so it gets impaired whenever my blood sugar is low, I’m tired, or I’m stressed. Other brain regions also have the ability to interfere with the PFC, especially the limbic system which manages emotions and the fight-or-flight response. Some diseases (like depression and long COVID) can cause “brain fog,” which is closely related to reduced executive function. It’s also possible to injure the PFC, from a stroke, a tumor, or a physical injury (as in the famous case of Phineas Gage).

Knowing this helps me feel a little less personally responsible when I have a lapse of self-control. It really is inevitable, common, and completely natural. Still, I want to have good judgment and do the right thing as much as possible! How do I do that? One answer is to simply be aware of my limitations and to work around them. I try to notice when I’m hungry, tired, or emotional and avoid making big decisions or socializing at those times. Instead, I might get a snack, take a break, or sleep on it so I feel more in control. The only other good technique I know is mindfulness meditation. Despite the mystical reputation, the main purpose of meditation is quite practical: it trains the PFC. By practicing the skill of observing the mind and exerting influence over it, I can build that muscle. It’s not a silver bullet, but meditation helps me use my PFC more often and more effectively, and it makes me more aware of when my PFC is in a weakened state.

So, in a sense, there really is a “pilot” in every brain. It’s just not an ever vigilant, intelligent, wise, and rational person. Instead, it’s one brain region out of many, with limited visibility and a narrow job description. The PFC observes what the other brain regions are seeing, thinking, and doing and uses that top-down view to nudge them into more coherent and effective patterns of behavior. It’s not “the self” and it’s not “in control.” In fact, it has very limited influence, isn’t always active, and even with training there are lots of common reasons it might grow weak or misbehave. For this reason, having great self-control is often less about will power in the moment, and more about avoiding temptation in the first place.

What do you think? Does this agree with your first-hand experience? Do you have any insights you could share about self-awareness, self-control, or motivation? What about being kind to yourself when your self-control inevitably falls short? If so, I’d love to hear from you in the comments.

Author Nate Gaylinn (he/him)Posted onApril 3, 2024CategoriesAnimal Minds, IntrospectionTagsbrains, collectives, control, health, meditation, mental-health, minds, neuroscience, pfc, pilot, prefrontal cortex, psychology, self7 Commentson The Brain’s “Boss”
Pre-Genetic Life
One thing that fascinates me about life on Earth is that it’s all built with proteins and genetics. Every living cell, even the most primitive microbe, has at its core a universal molecular-scale 3D printer, controlled by an evolved programming language, which gets read and error-corrected from a highly stable gigabit-scale molecular data storage medium (DNA).

In short, every living thing, every single cell, is a mechanism of astonishing complexity and sophistication, and they all share a common design. That’s wild. Life could not have started that way. The very first cells must have been much simpler and then evolved to be like this. But then… where are they? What happened to those pre-genetic cells? We’ve never found them. There are a few good answers to why, and I find them all fascinating.

One interesting possibility is that pre-genetic life is long gone. After all, it originated billions of years ago! Earth is a hostile place, and those early life forms must have been even more fragile than the ones we see today. Not to mention, there’s nothing life likes more than to eat other life. If “modern” cells with genetics outperformed their more primitive cousins, maybe they drove them extinct and replaced them?

Or, perhaps pre-genetic life never existed on this planet at all. Maybe the mechanism of genetics is so complex it needs much more time to evolve from scratch. Maybe the process got started elsewhere in the universe, and then got deposited here in cosmic debris. In that case, genetic cells just colonized Earth and adapted to living here. That’s an exciting possibility, because that might mean there’s more life “out there,” and we could find other living planets like our own.

Just as fascinating is the idea that pre-genetic life is still alive and well on this planet. That universal 3D printer for proteins is an incredibly powerful tool for cells, but its primary value is exploration. It makes it possible to invent new molecules and thus new lifestyles. It enables life to spread, complexify, and settle every corner of this planet.

But it doesn’t make the cell any better at living one particular lifestyle. It may be that cells evolved diversity to escape the dominance of the first life forms, that cornered their particular niche so well that finding a new niche was the only option. Perhaps genetics was invented to escape and branch out from this overcrowded primordial environment. If that’s the case, then maybe there’s a thriving colony of pre-genetic life, still clinging to a hydro-thermal vent somewhere, just as it has for billions of years. It’s terribly unlikely, but in theory, we could find it. How exciting would that be?

But what if pre-genetic life isn’t rare at all? What if we just can’t see it? Certainly, if it exists, it would be microscopic, and that already makes it very difficult to find and study. We’ve been cataloging single-celled organisms for centuries now, yet we’ve observed just a tiny fraction of them, and gene sequenced even fewer.

Maybe we overlook pre-genetic life because it looks like “normal” cells? We can now take a census of whole microbial communities by sequencing their DNA in bulk and using a computer to sort out the different species, but pre-genetic life would be invisible to that technique. It has no DNA to catalog. Maybe it uses RNA, which degrades more quickly, and is harder to study? Maybe the RNA is organized differently, in ways that would defy current sequencing technology? Maybe it uses a completely different mechanism, with molecules we don’t even know to look for? It’s fascinating to think there could be a whole other kingdom of life hiding in plain sight.

Author Nate Gaylinn (he/him)Posted onJanuary 12, 2024CategoriesSnack-SizedTagsdna, extinction, genetics, life, origins, panspermia8 Commentson Pre-Genetic Life
Learning to Move: Three Kinds of Learning
Learning to Move: Three Kinds of Learning
(This post’s image is a photo I took of my yoga gear. Specialized tools like my mat, blocks, and strap work together to make my practice possible. They extend my body, and help arrange it in the ways my mind imagines)

I was pretty sedentary as a kid, and didn’t get serious about physical fitness until I was an adult. One nice thing about that is I got to watch myself learn, knowing all I do now about the brain. By practicing yoga and working with physical therapists, I’ve learned a lot about myself, but also how mind and body work together. Mastering a new physical skill actually recruits at least three separate learning processes working together. Understanding this changed my expectations, helped me gain more control over my body, and made exercise much more enjoyable.

When I first started yoga, I was startled by how little I knew about my body. My teachers were asking me to observe and discern sensations I’d never noticed before. They asked me to get into certain poses, using certain muscle groups, and I didn’t know how! I didn’t have the names for these things. Worse, I could see what I was supposed to do, but I didn’t know how to make my body do that, or even if I could. It was frustrating.

It’s weird to think how ignorant we are of our bodies, given that we live in them our whole lives. For me, a prime example comes from physical therapy. When recovering from an injury, I relearned how to walk up stairs. I’ve climbed stairs thoughtlessly my whole life, and I never considered there were different ways to do it. But the leg is controlled by opposing muscle groups. I used to climb stairs by lifting each leg, using just the muscles on the front side. I learned to also use the muscles on the back side, to push up and straighten the leg. Either set of muscles can do the job alone. Now, I consciously try to balance the effort from both sides, but this never would have occurred to me without knowing a little anatomy.

That knowledge was game changing for me, but unfortunately knowing how the body works isn’t good enough. I can memorize anatomical diagrams, muscle names, and facts about body mechanics, but the only interface between the brain and body are the spinal nerves. How’s the brain supposed to know what nerve impulses correspond to which movements? There’s actually a region of the brain dedicated to this problem, the cerebellum, but it’s not consciously accessible. This is why yoga instructors use cues: they teach little mental tricks for recruiting muscles, and associate them with relevant postures.

Try this. Bend your elbows ninety degrees to extend your forearms out from your body, palms up. Imagine someone’s handing you a heavy platter. You might notice the trapezius and rhomboid muscles engage between your shoulders. These muscles largely serve a supportive role. For many people, they aren’t needed much in daily life, but using them can improve posture and reduce strain on other muscles. The problem is, they’re easy to ignore and hard to describe. But I can turn them on with the cue, and then I can learn what it feels like to use those muscles. Once I can tell whether they’re working, I can often activate them at will. Or, I can just use the cue, as needed.

Of course, conscious knowledge of form and cues are just step one. Muscle control is mostly unconscious, and for good reason. Remembering all the cues, monitoring my body, and continuously correcting my posture is work. It takes my full attention, leaving no room for anything else. Luckily, that’s just a phase. With enough practice, my cerebellum learns the patterns and can take over. I can hand off that work to my unconscious motion control sub-processor, freeing my conscious mind to think about something else.

This is why physical therapy can be so effective. After an injury, some muscles and joints may not perform like they used to. Some links between mind and body might even be severed or scrambled. Recovery means learning new ways to do old activities. At first, this is a nightmare. Without the support of the cerebellum, even just walking is an intensive conscious effort. Physical therapy can be a painful, tedious, and drawn-out process, but for many patients it makes a world of difference. It teaches the cerebellum new motion programs. Potentially, walking can become fully automatic again. The conscious mind can be used to retrain the unconscious mind in profound and lasting ways.

Yet knowing how to move isn’t enough if the body can’t follow through. The hardest part about learning a new physical activity is that the body usually isn’t ready for it. When I first started yoga, my muscles were weak, rigid, and lazy. They quickly became tired and sore, which just made me want to use them less. They struggled to move my body weight, and were so tight that my range of motion was limited. Some postures were hard, uncomfortable, or impossible. I couldn’t keep up, and when I pushed myself harder, I only injured myself.

That taught me a lesson about patience and acceptance. My body wasn’t ready, so I couldn’t do those poses, but I could work towards them. I learned to listen to my muscles complain, and to distinguish between different sensations. Some indicate hard limits I should not push past, but most are just signs of stress, and those can be good. When muscles, bones, and tendons get stressed, they respond by becoming bigger, stronger, and tougher in a process called anti-fragility. The discomfort I feel is just that physical learning process in action. By embracing the discomfort, I could slowly reshape my body.

Anti-fragility doesn’t involve the brain, conscious or unconscious. It’s a kind of learning that happens in the body tissues themselves. My muscles “know” whether they are getting the job done. They can tell if they are actually contracting and relaxing when they get the signal, whether that was easy or hard, and whether they sustained any damage in the attempt. They recognize how often they are put to use, and whether they are usually exhausted or ready for action.

Generally speaking, muscles conserve energy by doing as little as possible. But when I regularly demand more of them, they adapt. They become bigger, stronger, and more responsive. They consume more energy at rest so they’re always ready for action when I need them. They become less lazy, working harder by default, which makes them stronger still. This requires more protein to build the muscles, and more calories to power them. So my metabolism adapts, too. I eat more and my body burns more calories continuously, rather than storing them as fat.

What’s so fascinating is how all three ways of learning work together. With conscious thought, I choose to change my behavior. I master new facts and cues, so I know what I’m doing at an intellectual level, and can execute new skills (poorly, at first). With practice, not only do I refine those skills, but I engage an unconscious learning process that makes them fully automatic. I can focus my mind on the task I want to accomplish, and trust my body will just perform all the complex movements I need to pull it off. My muscles may not be up to the challenge at first, but that’s fine. With willpower, I push my tissues to their limits, and they learn to do what I ask. By the principle of anti-fragility, my body automatically remodels itself, increasing strength, flexibility, or stamina precisely where they’re needed. It makes itself a better robot, one that can live the lifestyle my mind consciously chooses. These three learning processes work independently, yet together they make a dynamic human being, one that can just as well become a yogi, a warrior, a marathon runner, or a weightlifter.

Intelligence isn’t just about brains, it’s about bodies, too, and about multiple intelligent systems working together in complex ways. I hope this was a helpful example, but as always I’m looking for feedback. Is this an experience you can relate to? Have you observed these different systems within yourself? Do you think it helps to know what’s going on intellectually, or do you approach physical training in a different way? Any other thoughts or observations to share? I’d love to hear from you in the comments.

Author Nate Gaylinn (he/him)Posted onJanuary 3, 2024CategoriesThe Intelligent BodyTagsanti-fragility, bodies, cerebellum, fitness, learning, minds, movement, physical therapy, systems, yoga5 Commentson Learning to Move: Three Kinds of Learning
New Coding Project
I just published a new coding project! If you’ve been following along, this is the “grown up” version of a demo project I posted last year.

It’s further exploration of what I call an “epigenetic algorithm.” It’s inspired by a simple observation: in living cells, the process of evolution is actively managed by the cell, which itself is an evolved mechanism. Using evolution to optimize evolution seems like a powerful trick, so I’m trying to reproduce it in small-scale AI experiments. I hope to make evolutionary computing more open-ended, more successful in vast search spaces, and less biased by the programmer. In this case, I’m generating cool looking Game of Life simulations, but I hope to find many more practical applications in the future.

I’m not sure whether or not I will publish this as a work of science. It’s complicated and weird and there’s more work involved to make this a proper controlled experiment. As I learn more, I’m already thinking of other ways to explore this idea that might be more effective. So, for now, the plan is just to share the code and I may or may not revisit this later, depending on where my other leads take me.  🙂

I gave a presentation that covers the motivation, results, and challenges of this project for a technical audience.

You can also peruse the source code and results on GitHub.

Sorry this is less accessible than my usual blog posts! If you have any questions, just drop them in the comments, and I’ll happily answer them.

Author Nate Gaylinn (he/him)Posted onDecember 8, 2023CategoriesStatus UpdatesTagsepigenetics, evolution, game of life, genetic_algorithms, programmingLeave a commenton New Coding Project
Free will?
This is me experimenting with sharing shorter, less polished posts when the inspiration strikes. Let me know in the comments what you think.

There’s been a recent bout of people talking about free will and determinism. Perhaps because of Sapolsky’s book, Determined?

But so much of the discussion I see is grounded in a very strange conception of free will. For many people, “free will” means that a mind must have the power to bypass causation and alter reality purely because it wants to, without any external influences.

This is very silly. It’s secret dualism. It’s like saying free will only exists if my transcendent soul can reach into the universe (from outside?) and arbitrarily tinker with physics. Science tells us that this sort of free will does not exist. But rather than throw out the concept entirely, maybe we just need a better definition?

When talking philosophy, it’s so important to establish good definitions.

If the Universe is determined, then so are we. We can’t break the laws of physics. In some sense our behavior is unchangeable. We make choices, but if you re-ran the Universe in precisely the same way, we’d act the same every time.

But so what? Even this kind of decision is real and meaningful. We choose based on our experiences and our preferences. Those aren’t in our control, but they’re still “us.” Those choices matter. They determine how the Universe unfolds, and what experiences we all have. We really do make things better or worse, as we choose.

Maybe we don’t change reality. Maybe it was always gonna be this way. But so what? The Universe is vast and chaotic. Even if it’s theoretically predictable, practically it’s not. It’s pure fantasy to think we can accurately predict even a single person’s actions beyond the next few moments.

Even if we’re determined: we experience, we consider, we choose, we act, and that determines what comes next. That feels like “free will” enough for me.

The point of Sapolsky’s book is that we are animals, with innate biases and limitations. We live in a society that determines how we live our lives. We have experiences that shape us. We shape our selves, but only the parts that aren’t determined by reality. We can’t take “full credit,” because so much is just luck.

So where do we get off torturing people in prison for being “evil”? People aren’t evil. People can be selfish, delusional, psychopathic, traumatized, desperate, etc. Maybe they need help. Maybe they’re dangerous to themselves or others. Maybe society should intervene. But to a large extent they didn’t choose that life, but were forced there by circumstances beyond their control. So when we intervene, why the nastiness? Why should we punish someone for being born with a genetic mutation, or an abusive father?

I’m not sure I completely agree with Sapolsky, but he makes a good point worth considering. I don’t want people to reject it because “free will” doesn’t mean what they think it means.

Author Nate Gaylinn (he/him)Posted onNovember 14, 2023CategoriesSnack-SizedTagsdeterminism, dualism, evil, free will, prison13 Commentson Free will?
Checking In
Checking In
Hello there, reader. I hope you’ve been enjoying the blog. It’s been about two years since I began, and in that time a lot has happened. I moved from California to Vermont and started a PhD program at UVM. That’s going great, but it’s keeping me very busy, and I think I have to make some changes.

So far, I’ve been posting a full-length blog post every month, but I don’t think I can keep up that pace. I’ve got a few finished posts queued up, but I’ve had barely any time to work on new ones since classes began. So, this will be the last post for the year, then, starting in January, I will try posting every three months. Hopefully that will be a more sustainable pace. I might also experiment with shorter / less formal posts. We’ll see!

In the meantime, I thought I’d share a bit about my grad school experience so far. At the time of writing this, I’m about two thirds of the way through my first semester.

Here at UVM, I find myself completely surrounded by interesting people, ideas, and projects. It’s electrifying. I don’t know if my mind has ever been so stimulated before. I’m often pooling my mind with many other brilliant people, and I love that feeling. Whenever I have the kind of idea that might show up in this blog, I have many people at hand who want to talk about it and have interesting contributions. And they’re pulling me into interesting conversations all the time! I’m reading all sorts of interesting papers in AI, philosophy of mind, and biology. I’m integrating that knowledge by writing papers and building fun little software projects for class. So far, most of what I’m learning isn’t radically new or different, but I’m fleshing out my understanding in much more depth, discovering fun tangents, learning precise vocabulary and specialized tools, and building out vast webs of mental connections.

I haven’t had much time to work on research yet, but I’m excited about my prospects. I see reflections of my ideas in the work of others’, and vice versa. It’s helping see new angles and new possibilities. I’m talking very actively with my advisor and fellow students about potential projects and collaborations. I came to UVM with lots of things I’d like to try (many related to this blog), but now the challenge is integration. How do I pursue my interests in the context of the lab? How do I make use of new ideas I’m discovering and find exciting? How do I connect with the work of other researchers, to make my contributions relevant and interesting to the field? It’s forcing me to question myself, reframe things, explain myself, and find inspiration in others’ ideas.

This is exactly what I was hoping for. I’ve been on my own since leaving Google, and the experience is just underscoring something I know to be true: human minds aren’t meant to work alone. We’re social creatures, and most of us just cannot reach our full capacity in isolation. At UVM, my mind is constantly stimulated, and I’m always challenged to stretch myself, try new ideas, and make new contributions. I feel I can go much further here, and accomplish great things. Of course, the flip side is that it’s exhausting, especially while I’m still new and figuring out how things work here. The pace of activity is very fast, and there’s much more to read, do, and learn than I could possibly fit into a day.

In some sense, that’s already very familiar. My experience at Google (especially near the end, when I was leading teams) was also a fast paced, continuous, information overload. The key skills for dealing with that are prioritization and time management. I just have to pick what to spend my time on, and let everything else pass me by with minimal interference. Thankfully, I’ve gotten really good at that.

Still, I’m definitely feeling challenged right now, and so busy I barely have time to breathe. There are a few reasons for that. One is just that the pace of life was so much gentler over the past couple of years as I made this transition. I was working very hard, but my work was self-paced and I had very little external pressure. I took my time. Nobody was depending on me, or judging my performance. So, I’m having the jarring experience of suddenly stepping onto a moving treadmill. Only now, after a few months of settling in, have I found a good rhythm where I can keep up with all my work, have a life, and also pursue my own research goals.

This is also hard because I’m running on a very different sort of treadmill than what I experienced at Google. In a sense, it’s easier. I have a ton of work to do, but it’s mostly low-stakes reading, writing, and coding at a steady pace. As a manager at Google, my work was mostly decisions, strategy, and people issues. I spent a lot of time moving from crisis to crisis. I had to act quickly and decisively with limited information. My decisions would have a big, often irreversible impact on people’s lives (sometimes individuals I knew and cared about, and sometimes millions of strangers). I was accountable for those human consequences. That’s stressful! By comparison, grad school work is fun and low pressure.

In another sense, Google was actually much easier than academia, because it was highly structured. There, everyone had a well defined job role with explicit expectations. We had official priorities and ways of doing things that everyone adhered to. Everyone was organized into teams, which served complementary purposes and fit into a coherent whole. Leaders held meetings with regular cadences every week, month, quarter, etc., checking in on progress and aligning people on their mission, values, goals, and priorities. We never lived up to the ideal, but Google felt a bit like a clockwork mechanism. We all had a function, individually and collectively, and we worked together in lock-step to make it happen.

Academia and science are far less structured. Every PhD, every lab, every department, and every school do things differently. There are very few hard constraints, and anything that fits within them is valid. In grad school, lectures and assignments feel a bit more like “recommended work,” and you’re expected to invest only as much into them as makes sense for your needs. This is freeing, but also in some sense very frustrating. There are no best practices. Nobody can tell me what to do, or how to succeed. There’s very little indication of how I’m doing, or what progress I’m making. Everyone’s working more or less independently, on only sorta related projects, within a vaguely defined scope, based on their own judgment. There’s little sharing, few standards, and plenty of waste.

That said, science should be less structured than engineering. It must be. The university is designed this way to encourage diverse ways of thinking and of approaching problems. The challenge of science is that we don’t know what we don’t know. We don’t know what to look for, where to look, or how we’ll find it. Very often important truths are hidden behind common ideas and practices that everyone “knows” to be right, even though they are blatantly wrong! It’s important that students can follow in the footsteps of great thinkers and flesh out their works, but also that they can go in completely new directions and find what was overlooked. The chaos and freedom can be challenging, but it’s a necessary ingredient for innovation.

Well, that’s what’s going on with me. I hope my thoughts on grad student life are interesting. I will start experimenting with the format of this blog and see where it goes. If you have any thoughts or suggestions about that, please let me know! If you’d like to stay more up to date on what I’m doing and thinking, I’m most active on Mastodon. For those who don’t know, it’s basically a smaller, nerdier version of Twitter that isn’t owned by an alt-right friendly oligarch, and with much healthier communication norms and moderation practices. I post there pretty often, and I respond to most comments / DMs. You can find my profile here.

Author Nate Gaylinn (he/him)Posted onNovember 1, 2023CategoriesPersonal Reflections, Status UpdatesTagsacademia, blog, google, grad school, industry, phd, research, science, social intelligence4 Commentson Checking In
Learning to Steer
Learning to Steer
A Cell’s Eye View of Evolution, Part 3
(The image for this week is an illustration from Waddington’s 1957 paper The Strategy of the Genes, which is often used to explain canalization. It shows a landscape with shallow, forking grooves and a ball rolling down that landscape. Although the ball’s path isn’t fully determined, the existing impressions in the landscape constrain it to one of a few likely paths)

This is part three of a three-part series. You can read it on its own, but to get the whole story, you should start from the beginning.

Darwin explained part of the great mystery of life: how complexity and intelligence can evolve from randomness. When DNA was discovered, this seemed to “seal the deal.” DNA is the molecule that describes an organism’s nature, makes traits heritable, and carries mutations that are fodder for natural selection. That seemed to explain everything, at first, but I would argue that’s just the beginning. The DNA molecule itself lies at the heart of an incredibly complex system of processes that manage its care, use, and replication. These systems are collectively studied as “epigenetics,” and science is just beginning to understand how they work and the impact they have on evolution.

It’s important to remember that DNA is an inert molecule that does nothing by itself. It needs a cell, a sort of organic micro-robot, to interpret that DNA and turn it into form and behavior. So, in a sense, every living thing is made up of two evolved programs: the DNA and the cell. Both are made of physical matter, which are subject to mutations. Both share the same selective pressures and reproductive fate. They evolve together, but they have different purposes. For the most part, the DNA program is what determines the organism’s lifestyle. The cell decides how to read that program, and how to make changes to that program over a lifetime and across generations.

One of the most important ways cells influence their own programming is through mutations. These happen naturally. As molecules bang against each other and get exposed to UV radiation from the sun, they sometimes spontaneously change shape. When those molecules represent critical information for a species’ survival, that could be disastrous. For this reason, life invests a ton of energy into detecting and correcting errors. But this process is never perfect, and it can’t be. If life always copied itself perfectly, there would be no variation for selection to act on, and no evolution. Not only that, getting the error rate much lower than it already is would be prohibitively expensive. So, life strikes a healthy balance, allowing just enough mutation to be useful, but not enough to be dangerous.

Interestingly, that finely-tuned mutation rate is not constant and universal. There are some stretches of DNA that get extra error correction, always triple checked to ensure they stay as stable as possible. On the other hand, some stretches of DNA get actively shuffled, injecting randomness into things like the immune system, creating diversity that makes the population as a whole more robust. Perhaps most remarkable is that when cells get stressed out, they divert energy to other things, and away from error correction. This may just be an accidental side effect of the cell breaking down, but it might also be a survival strategy. To anthropomorphize, perhaps cells get creative when times are tough, trying out crazy ideas in the desperate hope that one might save them.

That said, a single DNA copying error can be devastating, so how does life cope? Remarkably, it can often just work around the problem. Living systems have a lot of redundancy, with many mutually supportive ways of doing basically the same thing. This leads to a phenomenon called “canalization.” The more critical some behavior is to life, and the longer it persists over many generations, the more redundancy builds up around it. This means that single errors may alter the behavior a little, change how it works, or make it less efficient, but probably won’t break it entirely.

When errors are too severe to recover from, an organism might just fail to thrive and die, but sometimes it actually notices the failure and decides to self-terminate. That may seem bizarre, but in multicellular organisms it makes a lot of sense. If the error is in a single cell, then removing that cell lets others take over its job. If the error would prevent the whole embryo from developing into a healthy adult, then it’s better to scrap the work in progress, recycle those materials, and start over from scratch. In other words, life has its own Quality Assurance processes, at multiple levels, which minimize investment into evolutionary dead ends.

Cells can also swap genes with each other, sharing useful recipes and trying them out in new combinations. Sex is one way to do it, aligning and remixing two complete genomes in an incredibly complex way that ensures the resulting DNA program is still valid. Simpler organisms like bacteria don’t do this, but swap genes in a much more free-form process called “horizontal gene transfer.” Basically, cells sometimes leave scraps of DNA lying around, or pick up those scraps and integrate them into their own programming. This can let a new behavior (like resisting some toxin or eating some food) spread very rapidly through a bacterial colony. Either way, randomly adopting genes that have proven successful in another organism is a much safer and more powerful way to create useful diversity than mutation alone.

It’s also worth noting that how a cell reads its DNA can change over a lifetime. Cells annotate their program with notes (ie, methylation) that indicate which recipes to avoid or use more of, depending on context. This is how single celled organisms adapt their behavior to a changing environment, and how cells in multicellular organisms differentiate into different kinds of tissues. Importantly, these notes are sometimes passed down across generations. For instance, an organism might survive near starvation by tuning down its metabolism, staying smaller, slower, and using less energy. That change is heritable. The next few generations will also have a slower metabolism, and if that serves them well, it could lead to long-lasting behavioral changes that eventually get encoded into the DNA itself.

So far, I’ve talked about how life modifies itself, but it also modifies the environment. Organisms can build caches, nests, and tools that make life easier, and these get passed on, too, both as hand-me-downs and as lessons. Organisms form an ecosystem, full of mutualistic relationships between species that make life easier. Over geological time, this has transformed our planet from a barren rock to a lush world full of possibility. Life cultivates a supportive environment for future generations, shaping their behavior and evolutionary fitness. Child care might be the most visible example, protecting each new life when it’s most fragile, then sending off the new generation in a good direction informed by the parent’s life experience.

In the basic Darwinian story, evolution is something that happens to organisms. Accidental changes occur randomly, and nature chooses which ones will persist. But as we’ve just seen, life does not leave things up to chance. Randomness plays a key role in biological evolution, but life manages that randomness carefully and uses it selectively. Life also does everything in its power to influence the next generation, in ways that are not random, but “purposeful” in a sense. A cell can’t understand why it does these things, but it does them for a reason: they worked well in the past, got selected for, and ended up in the cell’s programming.

This leads to a powerful realization: when it comes to influencing evolution, cells don’t understand what they’re doing, but many higher organisms do, at least a little. For instance, an animal can apply its full cognitive capacity, mind and all, to choosing a mate and raising its offspring. In this way, the cell has moved from blindly repeating what worked in the past, to making evolutionarily relevant decisions intentionally, with forethought and analysis. A dog may not understand genetics or think about the future of her species, but she certainly has strong opinions about who would make a good mate, when / where / how to raise her puppies, and which pups to give more or less attention to. She uses her senses, her instincts, and her big brain to make big decisions that shape evolution. She may not see the big picture, but she cares and makes informed choices nonetheless.

This helps explain the paradox of how life managed to become so incredibly smart just by randomly banging molecules together for a few billion years. Life may have started off randomly, but it quickly became more directed. Life harnessed Darwinian evolution to build a more powerful evolutionary algorithm, one that’s opinionated and shapes its own search space. At first, these evolution-shaping behaviors were simple and rigid, just tricks repeated by rote because they tended to make the next generation more successful. Then, as life became more intelligent, it started to apply that intelligence to shaping itself, creating a runaway process of recursive self-improvement.

Conclusion
The main takeaway from all this is that Darwin is the beginning of the story of evolution, not the end. Life uses all of its intelligent capacity to influence its own evolution. This led to a virtuous cycle. Increased intelligence gave life greater influence over evolution, which it used to become more intelligent, which gave it greater influence over evolution. For this reason, I think it’s better to say that life designed itself than to say it evolved by chance. The process of “design” here was more stochastic, collective, and unthinking than we normally associate with that word, but in the end, the result is the same.

This story is still uncertain. The science around autonomous robots, intelligent collectives, and epigenetics is relatively new, and changing all the time. Plenty of biologists push back hard against the idea of any sort of agency or direction in evolution, partly because they’ve been fighting against the theory of Intelligent Design for so long. Others believe we’re overdue for a new story about evolution, and are trying to find the right narrative and the evidence to back it up. I hope my research into evolutionary algorithms might be a useful contribution to that effort. If you’d like to dig deeper into this topic, Evolution in Four Dimensions is an excellent overview of the field of epigenetics.

What do you think? Did reading this make you think of life, cells, or evolution any differently? Any new ideas? Does anything I said sound wrong or misleading? Do you have other ways of looking at it? This post is more speculative than usual, and represents some of the ideas I hope to pursue in my PhD research, so I’m very interested in criticism and feedback. If you have any thoughts, please let me know in the comments!

Author Nate Gaylinn (he/him)Posted onOctober 4, 2023CategoriesBeyond Darwin, TheoryTagscanalization, cells, child-rearing, dna, education, epigenetics, error-correction, evolution, mutation, selection, sex9 Commentson Learning to Steer
Self-Made Life
Self-Made Life
A Cell’s Eye View of Evolution, Part 2
(this month’s image is a photo I took at Glass Beach in Fort Bragg, California. It consists of millions of tiny pebbles of polished sea glass in myriad colors. Each one is improbable to find at a beach, but all of them collectively tell the story of a larger-scale process that explains their presence—many years of disposing of waste bottles nearby)

This is part two of a three-part series. You can read it on its own, but to get the whole story, you should start from the beginning.

Every living cell is a universal automaton, capable of an infinite variety of forms and lifestyles. The cell itself determines the range of possibility—what proteins can it make, how will they integrate into the whole, and how will they shape the organism’s life? But within that space of possibility, the gene sequence is the program that determines what specific body to make, and how it should respond to a chaotic environment. That program is of the utmost importance, selecting one specialized lifestyle out of infinitely many possibilities, most of which would never work. But who wrote it?

Life did. Or, in other words, cells wrote the programming for cells, but it doesn’t seem fair to call them “programmers.” A human programmer is a top-down problem solver. To modify some working software, I start by analyzing that system’s performance: what does it do, and how well? I then try to understand how the system works. I read its programming, and consider how that leads to the behavior I observe. I consider how the system might be better, what specific improvements I might make, and what consequences I expect. I design a change to the code, then tinker with it in a sandbox environment until it does exactly what I want with no surprises or side effects. Only when I’m satisfied do I push the code out for use in the real world.

How are cells supposed to do that? They don’t have a mind like I do. They monitor their own health and situation, but they can’t imagine themselves “from the outside.” They don’t understand their lifestyle, their goals, or their relationships with the world except in terms of stimulus and response. They can execute short stretches of programming from their DNA, but they can’t examine the program as a whole, or imagine what would happen if they ran some other program instead. Mutations and cross-breeding cause the program to change, but cells can’t verify those changes in a safe testing environment. They can only make a new organism, release it into the world, and hope for the best.

This seems like a paradox, but only from the perspective of an individual cell. Life never exists as a lone individual. It always consists of diverse communities and ecosystems. So let’s take that perspective. Life isn’t a cell. Life is a vast collection of cells, an unimaginably huge number of concurrent individuals, living and dying continuously over billions of years. I like to think of it as a massively parallel computer. Life learns by accumulating and generalizing over the experiences of many lifetimes. It tries out many lifestyles simultaneously; whole different categories of lifestyles in different species and niches; many variations on a theme, among organisms of the same species. Whether any individual will be successful is hard to predict, because luck is such a huge factor. But by running the same experiments thousands of trillions of times over, life can get a relatively clear picture of what works and what doesn’t.

From this massively parallel perspective, each cell is a processor unit with two jobs. The first job is to live and reproduce. We normally think of that as “the purpose” of life, but from the collective perspective, it’s just the engine that keeps the system as a whole running. Individual lifetimes come and go rapidly and continuously like the cycles in a computer processor. The second job of each cell is to learn about the Universe and how to thrive in it, then integrate that information back into the system’s programming. That is life’s deeper purpose. Each cell has a very limited perspective and can only do this in a minimal way. But taken all together, vast numbers of cells can behave much more like a traditional programmer.

A cell has no understanding of what it does or how it fits into the big picture, but, in a sense, life as a whole does. Life consists of every cell, every lifestyle, every program that has worked so far, and all the dead ends that aren’t represented. That’s a tremendous amount of information about what the system does, which parts are performing better than others, and where there’s untapped potential. There’s no top-down designer, but this information, embodied in the population itself, still shapes the system’s evolution. Each cell acts selfishly, but by competing and collaborating with each other, life distributes resources to the parts of itself that are thriving in their niche, and encourages exploration of new lifestyles where opportunity lies.

The big difference between life and a human programmer is speculation. Humans envision the system as a whole and imagine where it might go. When I program a computer, I test ideas first in my mind and then in a virtual environment on the computer in order to avoid mistakes and dead ends. Life doesn’t do that, because its massively parallel, distributed design makes that impossible. There simply is no top-down view, no central authority to perceive and decide, no way to step out of the system for testing. Instead, life just tries everything. It tests code in production. It walks straight into failure rather than avoiding it. Death sorts what works from what doesn’t. That’s why we usually think of cells as “dumb” and humans as “smart.”

It would be better to think of humans as more efficient, because in a sense what we do isn’t so different. We both generate lots of options, test them, winnow them down to the most successful, and iterate. I do it with simulations in my brain, life does it with matter in the physical Universe. From a computational perspective, that doesn’t matter. A computer can be realized with cogs, transistors, neurons, or a simulation inside another computer. The materials can be anything so long as the functionality is the same. As individual living animals, it seems tragic and absurd that life must test out ideas by letting things die on a massive scale. From life’s perspective, though, a single lifetime is just a brief use of materials and programming that will get recycled for future experiments. If it were conscious, life as a collective whole wouldn’t regret (or notice!) the death of an organism any more than we regret the death of one of our cells.

You might argue that the human programmer also has foresight. I don’t just try stuff at random, I have a sense of what might work and what probably won’t. I use trial and error, but I prioritize and focus my exploration. It’s tempting to say cells don’t do this, but that’s too dismissive. Cells are quite opinionated. DNA doesn’t contain a blueprint for an organism, but a bunch of recipes that the cell can choose between depending on context. Cells must decide how to act. Evolution has equipped them with a wide variety of strategies and tools, and guidance on when to use them, all encoded in the DNA. This is how life learns from experience, plans ahead, and avoids dead ends. Life explores new paths at random, but it mostly tries out reasonable variations of known working strategies.

Individual cells aren’t much like human programmers, but they do have one thing in common: they write code. Mostly, the cell just copies its own DNA (copy / paste is a popular strategy among human programmers, too), but it makes an important decision: what variations to try in the next generation. This happens either through mutations, or by swapping genetic material with other cells. Without a top-down view of the gene sequence, this can only be a random process. The cell has no idea what changes it’s introducing, or what the consequences might be, but it can try to shape that randomness for the better. Primarily, this means spending a ton of time and energy on error correction, so that only a small number of mutations get through. It also shows up in things like mate selection, genetic recombination, and preparing the environment for the next generation.

I like to think of Darwin’s story as how life got started. Random mutation and selection are all you need to evolve better forms. As we learn more about cells, though, we see there’s a lot more going on. Life didn’t just find better lifestyles, it invented a general purpose platform capable of an infinite variety of lifestyles. As a collective, life uses that platform to explore many lifestyles simultaneously, pruning dead ends and investing more resources into exploring evolutionary paths that seem fruitful. Life started out randomly, but it grew more opinionated over time, and it has evolved many sophisticated ways to direct and shape its own evolution. That will be the topic of my next post.

What do you think? Did reading this make you think of life, cells, or evolution any differently? Any new ideas? Does anything I said sound wrong or misleading? Do you have other ways of looking at it? This post is more speculative than usual, and represents some of the ideas I hope to pursue in my PhD research, so I’m very interested in criticism and feedback. If you have any thoughts, please let me know in the comments!

Author Nate Gaylinn (he/him)Posted onSeptember 6, 2023CategoriesBeyond Darwin, TheoryTagscells, collectives, epigenetics, evolution, genetics, life, parallelism, problem solving, programming, purpose8 Commentson Self-Made Life
Universal Automata
Universal Automata
A Cell’s Eye View of Evolution, Part 1
(This month’s image is a photo I took of the full-scale model of Babbage’s Difference Engine at the Mountain View Computer History Museum. This is one of the first examples of a programmable digital computer. It’s a completely mechanical device, operated by hand crank.)

This is part one of a three-part series. For an overview, check out the introduction.

In the traditional story of evolution, each organism lives a single lifestyle, and the forces of nature select which ones are fit enough to reproduce. From that perspective, evolution is something that happens to life. But this story fails to explain something very strange and important: cells are not single-purpose machines. Although they only live one lifestyle at a time, they have the capacity to live an infinite variety of lifestyles, depending on their DNA programming. That requires an enormous amount of complexity and effort that doesn’t directly contribute to a life well lived. In fact, being programmable doesn’t help at all in a single lifetime if the program never changes. So why does life work this way?

To make sense of this, let’s look at a parallel example in computer technology. Consider an ATM. It’s a highly specialized kind of machine, but these days if you look under the hood you’ll often find a Windows PC that’s programmed to be an ATM. That seems like an odd choice at first. ATMs do things most PCs don’t (like dispensing cash), and Windows supports things that you don’t want in an ATM (like running random programs off the internet). You could make a better, safer, more efficient ATM if you designed a custom machine for that purpose, but nobody does that, because it’s harder. Digital computers are so versatile and easy to reprogram that they show up everywhere. As they get used in new applications, their range of capabilities expands, enabling new use cases and further innovation.

Cells are very similar. Being programmable doesn’t help with any one lifestyle, but it makes it possible to explore new lifestyles relatively quickly and easily. Each individual operates in a complex, roundabout way that only uses a fraction of the cell’s potential. That seems like a bad thing, but the adaptability makes it worthwhile. The world is in constant flux, especially once organisms started actively changing things and competing with one another. Very few evolved lifestyles withstand the test of time. For this reason, nature doesn’t just select “the best lifestyles” for life. Life invested in a general purpose platform to make the search for new lifestyles more efficient.

Let’s take a closer look at how the platform works. A cell can be thought of as a kind of microscopic robot. The “programming” for that robot is stored in DNA, which is surrounded by a complex mechanism that reads that data and uses it to produce the form and behavior of the organism. Each cell has a very limited capacity for intelligence, but they’re very good at working together. Like a sort of “autonomous smart matter,” they collaborate by the trillions, which is how every form of intelligence on this planet is made. There’s no reason to think there’s an upper limit to what can be built in this way.

What makes this possible is the protein-synthesis engine at the core of every cell. The nucleus of a cell is a bit like the brain of a human, in that it’s a specialized sort of computer that’s “in control” of the cell. It’s surrounded by the cell’s body, which serves as the interface between the program in its nucleus and the outside world. This is where the similarity ends, though, because the nucleus and the brain are very different kinds of computing devices.

The nucleus works by continuously handling requests, looking up protein recipes, and sending those recipes back out to the cell for construction. A cell can make an astonishing variety of complex molecules this way. These proteins are what make up the cell, its inner workings, and outward behaviors. They serve as building material, messages, tools, or even nano-robots that move about within the cell, manipulating other molecules, and doing useful work all on their own. Sometimes a single protein can serve all of these roles, depending on context. They interact with each other in a vast complex network of activity that keeps the cell alive.

These cellular mechanisms continuously send messages back to the nucleus, reporting on the cell’s health, situation, and needs. The nucleus uses this information to figure out what proteins to make next, adapting the cell’s makeup and behavior to fit the circumstances. For instance, E. coli bacteria normally feed on glucose sugar, but they can eat lactose instead, if that’s what’s available. When that happens, the cell reports to the nucleus that it’s running low on energy and what molecules are around. The nucleus then decides to switch some genes on and off, which instructs the cell to make different enzymes, which results in different cascades of chemical reactions, in order to digest and use the lactose. By reading the DNA differently, the nucleus shifts the whole cell from one lifestyle to another, in response to a changing environment.

Another way to think of the nucleus is as the engine of the cell. The proteins it makes drive all the chemical reactions that keep the cell alive. Ultimately, everything the cell does is about collecting the energy and raw materials to feed that engine and keep it running. This is the cell’s metabolism. When the engine runs faster, the organism becomes more active, moving, “thinking,” and reacting with speed and vigor, but quickly burning through its energy stores. When it runs slowly, the cell becomes sluggish and conserves its energy. If it ever comes to a full stop, the cell dies, or, in special cases, enters suspended animation. In other words: cells live to make proteins, and making proteins is what makes cells alive.

DNA is where the cell keeps all these protein recipes, but the DNA molecule itself is completely inert. It just carries information, like a computer memory card. It can’t do anything by itself, and certainly can’t make a body from scratch. To build an organism, you need a cell to interpret the gene sequence and do the construction. This is why cells always reproduce by splitting in two. The daughter cell is basically just half of the parent cell, full of the same soup of proteins and organelles, in a fully operational state. The only part that’s really “new” are the DNA molecules in the nucleus, freshly copied from the parent(s). Any changes in that DNA program will only manifest when the daughter cell sends a message to the nucleus and gets a different response back than its parent would have seen.

That means that every cell has the crucial responsibility of reading and writing those DNA programs. They contain every useful protein recipe life has discovered, and must be actively maintained over generations or those recipes will be lost. But what does life actually record in the DNA? Geneticists say DNA is made of four amino acid base pairs (A, G, T, C), which are grouped into triplets called “codons” that serve as instructions for protein synthesis. That makes it seem “natural,” as if that were the only way to do it. The truth is, the code is totally arbitrary. Life made it up. By trial and error, life invented a coding scheme. It gave meaning to those molecules and all the ways they can be combined. The programming language of life was invented by life. It wasn’t the beginning, but a tool that cells made to manage their behaviors, learn new ones, and pass knowledge to future generations.

Let’s put that all together. A cell is a programmable micro-robot (in technical jargon, a “universal automaton”), capable of making virtually any protein and living virtually any lifestyle. In a sense, a cell is not just one organism, but potentially an infinite variety of organisms, depending on the programming in its nucleus. But how does the program get written? Life had to do all the work itself, without a programmer in the traditional sense. A cell has no mind with which to analyze its DNA and understand what it means. It cannot imagine the consequences of any changes to its programming, or test them out to make sure they are safe. And yet, somehow life invented a programming language and used it to write countless programs and build the full diversity of organisms we see on Earth.

We’ll delve into the details of how this happened in the next two blog posts. At a high level, though, there are two main parts of the story:

Life is self-made. Each cell is relatively simple and mindless, but working together in huge populations over long stretches of time, they develop their own programming. How they do it is quite different from how a human programmer would, but from a collective perspective, there are also some surprising similarities.
Life influences future generations. Organisms don’t just worry about their own survival, they put an enormous amount of time and energy into influencing the next generation for the better. Science is only beginning to understand this, but it offers the tantalizing possibility that, in some limited sense, life might steer its own evolution.
More on that next month.

What do you think? Did reading this make you think of life, cells, or evolution any differently? Any new ideas? Does anything I said sound wrong or misleading? Do you have other ways of looking at it? This post is more speculative than usual, and represents some of the ideas I hope to pursue in my PhD research, so I’m very interested in criticism and feedback. If you have any thoughts, please let me know in the comments!

Author Nate Gaylinn (he/him)Posted onAugust 2, 2023CategoriesTheoryTagscells, computers, development, dna, evolution, genetic_algorithms, meaning, platforms, programming, reproduction, universal automaton19 Commentson Universal Automata
A Cell’s Eye View of Evolution
I’m trying something a little different. Over the next few months, I will publish a three-part series about evolution from some (hopefully) new perspectives. This represents how I, personally, have come to think about evolution. I’ll go beyond the scientific consensus to talk about some ideas that are uncommon and controversial. I believe I have a compelling story that’s consistent with established science, but this isn’t authoritative yet. In fact, I’m being a little bold and spicy in the hope of attracting criticism and feedback. I hope these ideas will frame my PhD research, so I’m excited to learn what people find interesting, useful, confusing, or problematic.

I’m doing this because I believe the way we usually talk about evolution obscures what’s really going on. In the “survival of the fittest” story, an individual organism lives its life, making choices that either help it thrive and reproduce, or not. If it’s successful, it will attract mates and have many children who are like them, but a little different, perhaps better. To follow the path of evolution, we then pick a new individual, maybe one of that organism’s children with a beneficial mutation, and see where life goes from there.

That’s an oversimplification of Darwin’s theory of Evolution by Natural Selection. It lacks nuance, but it’s basically correct and useful. The problem is, it’s just one way of looking at the situation, shaped by human bias. Each person is a multicellular individual that lives a long time and reproduces sexually, so it’s natural that we look at evolution from that perspective. But when it comes to life on Earth, we are the exception. The vast majority of life comes in colonies of single-celled organisms, living short lives and reproducing asexually. From that perspective, the process of evolution looks very different.

The next three blog posts will explore that perspective. Part one describes the cell as a tiny robot that uses DNA to program its own behavior. This will illustrate what it means to evolve such a program, and what purpose the program serves. Part two shifts perspective from a single cell to a population of cells over time. This illustrates how when individual cells work together in large numbers, they program themselves, using an evolutionary algorithm much more powerful than mere random variation and selection. Finally, part three discusses the complex ways that life influences the design of its own programming, and effectively “steers” its evolution, in a blind sort of way.

The first post goes out today, and you can read it here. I’ll release the other two installments in September and November. Each post is written to stand on its own, but together they tell a more powerful story, so I hope you’ll come back for more!

Author Nate Gaylinn (he/him)Posted onAugust 2, 2023CategoriesTheoryTagscells, dna, epigenetics, evolution, platforms4 Commentson A Cell’s Eye View of Evolution
Believing is Seeing
Believing is Seeing
(I took this posts’s photo of a banana slug crawling through leaf litter. It’s shape and color resembles some of the leaves, which makes it hard to spot if you don’t know what to look for)

People say all sorts of things about the world, but how can you tell what’s right? If you’re not sure, you probably want to see for yourself. Those other people might be confused, mistaken, suffering from wishful thinking, or actively trying to mislead you, but you see reality for what it is. Right? At the least, you won’t have the same misperceptions as them, so another look is useful. But how much can you trust your own senses? How does perception even work, and how come we’re so often misled?

Like most people, I “just see” everything around me. Sometimes, I become aware of my perspective. I move around to get a clear view. I notice where I’m glancing, and I know I can’t see what’s behind my head. Yet, most of the time I don’t think about those things at all. The visual world just seems to surround me seamlessly, with rich, consistent detail in all directions. Objects are plain to see, trivial to discern from most angles and distances. It all seems so obvious, like a simple “window on reality,” yet nothing could be farther from the truth.

Human eyes have tunnel vision. I only see a tiny spot in clear focus at a time. My eyes constantly dart around, collecting many snapshots of the world as I move through it. My brain gets a continuous stream of these disconnected snatches of imagery that it somehow must turn into an integrated whole. It tracks my position and perspective as I move through the world, to piece the images together and infer a 3D model of my surroundings. This takes a great deal of real time data processing, and more than a little creativity.

One thing humans don’t do is scan a scene from left-to-right, top-to-bottom, like a TV camera, capturing equally high fidelity data of a whole scene. My eyes are drawn to “interesting” features of the visual field, gathering much more detail about those, and leaving large gaps over the “boring” parts of the image where I never bothered to look closely. To get a sense of this yourself, check out this selective attention test on YouTube. It’s pretty shocking how well the brain filters relevant details from irrelevant ones, and shows you only what it thinks is useful. Of course, what’s “interesting” or “useful” is a judgment call, and I’m biased by my context, culture, and evolution. That means I’m blind to important things that I don’t expect, recognize, or know about.

Yet, I don’t notice any gaps in my perception. My brain creates the illusion of a clear and complete view of reality, using a technique called hierarchical segmentation. The image from my eyes is projected into my brain, then layer after layer of neurons interpret that image. The first layer detects patterns and discontinuities in the raw image data: edges. The second layer detects patterns in those edges: shapes. Layers above detect patterns of patterns of patterns, finding textures, objects, faces, bodies, groups, situations, and more. I don’t see pixels, colors, and shapes. I directly perceive the objects and agents in a scene, their properties, activities, and relationships. I experience that as if it were “really there,” even though it’s just a model in my mind, distantly derived from sense data.

The first pass of vision notices low-level features present in the image (edges, corners, curves), but doesn’t know what they mean. Later passes piece those features together to represent larger features (in a desk drawer, that arrangement of curves must be a fidget spinner). Most likely, the lower-level processing didn’t see all the relevant details clearly, but that’s okay. The fidget spinner neurons see enough to recognize what’s there. They tell the edge-detecting neurons what they should have seen, filling in the missing details. This is how I can clearly perceive a whole fidget spinner, even though it’s in shadow and half covered. My brain uses past knowledge of objects, where they appear, what they look like, and how they behave to imagine what was obscured.

This works extremely well, and it’s necessary, since low-level sensory data is noisy and ambiguous. It often helps to have some idea what I’m looking at to make sense of what I’m seeing. Yet, sometimes my brain’s predictions are wrong. That’s not actually a fidget spinner in the drawer, it’s a pile of coins. How could I tell? Well, the fidget spinner neurons projected their predictions down, but looking a little more closely, some of those guesses were clearly wrong. There were some edges that weren’t accounted for, some angles that didn’t fit. The lower level neurons noticed the gap between expectation and reality, so they had to push back and negotiate with the higher level neurons, eventually arriving at an interpretation that was the best compromise across multiple levels of analysis.

What I perceive is a blending of what my senses took in and what “makes sense” for me to see based on past experience. At first glance, I only notice the most eye-catching details and my mind fills in the rest. If I take my time to really look over a scene, exploring every corner and paying attention to details, then my past experience has less influence and I perceive reality more like it truly is. I’m giving my lower-level perceptions the best chance to find evidence that I wasn’t expecting to see, which might revise my first impression. The problem is, I can’t afford to do this all the time, and often don’t think to. When should I bother to put in the extra effort? When should I distrust my own perception of reality enough to double check?

My brain automatically groups every object I see into categories, collections of objects with similar properties. Each category has a mental stereotype, an image that sort of averages all my experiences. This is how I know the “normal” shape of a fidget spinner, even though no two are the same. It’s where my mind draws from when it fills the gaps in my perception. As I gain experience, I learn more useful ways to group things into categories that better predict their similarities and differences. I build more accurate, nuanced, and fine-grain stereotypes, which makes my perceptions clearer. That said, it’s easy to hold onto bad stereotypes. They warp my perception, overwriting key details of a visual scene that might prove me wrong, rendering them literally invisible to me until someone points them out.

Stereotypes play a central role in perception, and all the fancy understanding, thinking, and being human that layers on top of that. Stereotypes are great tools. They’re bite-sized models of reality that let us generalize past experience and predict the future. But they aren’t real. In fact, many of my stereotypes aren’t based on my experience at all. I learned them from other people! Some may be wrong, hurtful, and dangerous, but I wouldn’t know without personal experience. So far we’ve just been talking about objects, but it gets serious when we move onto people.

I saw this when I worked at Google. They would spoil engineers, with easy access to everything from staplers to lunch to massages. That meant lots of staff to keep the place clean, well stocked, and in good working order. These service workers—these people—were generally ignored, treated as part of the environment rather than part of the team. That’s problematic in itself, but also engineers with darker skin tones often reported being mistaken for the service staff. Despite wearing a nerdy T-shirt and an engineering badge, they got categorized as “the help” based on skin alone. They were ignored, or worse, asked to clean up spills. This was demoralizing, even though there was no ill-intent. They just weren’t seen, by folks who were misled by stereotypes and didn’t even notice.

Knowing all this makes me distrust my own senses, but I think that’s a good thing. They’re mostly reliable, but they can fail in specific ways, and it’s important to remember that. It’s also useful to know when to trust my stereotypes. That mostly comes down to knowing where I have deep personal experience and have paid close attention. Where I don’t, my stereotype might be a shallow hand-me-down, even though it feels just as “real” in my mind. What about you? Have you noticed folks seeing what they want to see, or hearing what they want to hear? How does this generalize to other kinds of perceptions? How do you try to see reality for what it truly is? I’d love to hear from you in the comments.

Author Nate Gaylinn (he/him)Posted onJuly 5, 2023CategoriesIntrospectionTagsattention, brains, google, illusions, minds, neurons, ontology, perception, racism, stereotypes, vision4 Commentson Believing is Seeing
The Programmable Species
The Programmable Species
(Featured image is a photo I took of a hazy city skyline in Seoul, South Korea)

People love to speculate about what sets us apart from other species. We’d like to think if we put a human side by side with any other animal, we’d be smarter, more capable, and dominant. If we’re being honest, though, individual humans aren’t that impressive. Our big brains only make a difference when we gather in groups. It’s the collective intelligence of humanity that changed the world, not the human animal. It’s less rational, less coherent, and harder to control. With modern science and technology, we’re beginning to understand this collective intelligence and how to shape it. But who shapes our culture, and to what ends? How as a society do we want to shape it? These are big questions, but first we need to understand what it means to be “the programmable species.”

Human beings are excellent at independent creative thinking. Yet, alone and without the tools of society, we’re actually pretty helpless. For instance, our big brains demand calorie-dense food, but our jaws are too weak to eat meat unless it’s thoroughly cooked. We can’t start a fire without physical tools (like flint and tinder) and mental tools (like knowing what a fire is for, that we can make one, and how to do that). Thus, to become fully human, we must be programmed with human culture. We depend on our community to shape us, give us tools to survive, teach us a lifestyle, and integrate us into a network of relationships that form a society.

We’re also capable of programming ourselves. That is, we can think strategically and make plans. We can invest in self-improvement, building our knowledge, skills, and relationships in order to achieve new goals. We invent tools that extend our abilities. This is extraordinary, but not unheard of. There are hints of this sort of intelligence in chimpanzees, elephants, crows, and many other species. They make tools, play politics, solve puzzles, and occasionally invent new lifestyles, but they don’t collaborate much. They may help each other, or use each other, but they almost never work “as a team.”

Humans, on the other hand, work together all the time. We form groups with a shared identity, purpose, and plan. We coordinate so that groups of almost any size can act as one much more powerful individual. This is rare in nature, but not unique. Colonial insects do it. What’s different with humans is how we spontaneously form and break these collectives on the fly. We don’t have to evolve new ways of collaborating. We can imagine them and share them with language. We continuously remake our culture, dynamically shifting goals and strategies as each individual nudges the collective in whatever direction they think is best.

This form of collective intelligence is incredibly powerful. It requires individuals who are intelligent, social, and good at communicating, so that’s what we evolved to be. We’re born craving social connection, stories, and gossip. We have powerful instincts to trust one another, to contribute, to be liked, and to fit in. The result is that whenever humans come together, we spontaneously form communities. Just by talking and telling stories, we build up a consensus about who we are, what we’re doing, and how to be together.

Language was a key innovation, but new communication technologies have made much larger collectives possible, with different forms and capacities. Broadcast media is one such technology worth a closer look. For most of our history, we could only coordinate as many people as we could gather and talk to (this is why the Romans built a vast network of coliseums, with paved roads and courier routes between them). The printing press changed that, making it relatively fast, cheap, and easy to reach hundreds or even millions of people. Radio and television only turbo-charged this capability.

The power of broadcast media comes from delivering the same message to everyone at the same time. Not only can it plant ideas in many minds, but it gets people talking about those ideas, iterating on them and integrating them into daily life. And we talk about them because we care. Our media, especially video, is designed to tap into our evolved need for knowledge and connection. We crave information. We see people in the media, and they become part of our extended social circles. We trust them, emulate them, and integrate their ideas with our own, usually without meaning to or even noticing that we’re doing this.

The problem is that the people on the screen aren’t our community. They don’t know us and we don’t know them. They’re usually personas or characters that don’t even exist in real life. We know this, yet our brains—evolved to be social—tend to embrace them as community members anyway. This illusion changes the way culture is formed. What used to be a more egalitarian, peer-to-peer process is now centralized. A few powerful individuals can put their ideas into the mouths of characters that stir the hearts and minds of many millions of people. Governments, corporations, social movements, and others work very hard to shape the thoughts and behavior of the whole population, and in some ways they are very successful.

Social media is a powerful new innovation, of course. Unlike broadcast media, where the same message goes out to everyone, social media makes it possible to shape every aspect of communication. The platform influences how people find each other and cluster into communities. The platform decides which voices and topics to amplify or stifle. The platform helps advertisers precisely target their audience, understand their biases and preferences, and craft messages with the biggest impact. They construct a customized media environment for each individual (a “filter bubble”) and attempt to monitor and influence each community and society as a whole.

This isn’t to say that social media is bad. It’s an incredibly powerful tool for understanding and influencing human culture, and we need that to get through the many crises we’re facing. The question is, who gets to wield that power, and what is it used for? Today, we let big corporations design and control these platforms with minimal restraint. They shape human culture, which decides every aspect of our lives and the fate of the planet, primarily for the purpose of making money; the consequences for society and the world aren’t their concern. That seems deeply problematic, but how could we do it differently?

There are two main problems with the status quo: the goal is unhealthy, and power is too centralized. It would be nice if the purpose of social media was to make society better, rather than trying to make the most money. The main problem is, who gets to decide what’s “better”? There’s no one right answer. This is why new social media sites like Mastodon are focused on the second part of the problem. By breaking up big platforms into many small, independent, but interconnected pieces, they can make a huge and thriving network without any one individual holding too much power. The result is more chaotic and fragmented. Different groups shape their discourse as they please in a more bottom-up fashion. This doesn’t prevent exploitation or toxic communities, but at least it’s more egalitarian and human-centric.

What makes humans special is how we build collectives that adapt continuously. This made our species successful, so we evolved innate biases to socialize. Over time, we learned to exploit those biases to exert more control over society as a whole. People are lured to big media for entertainment and connection, but these days it often feels like the true purpose of these platforms is to manipulate us and extract value from our participation. This raises a big question we each need to answer for ourselves: how do we want to shape our culture, and who should wield that power?

I don’t have answers, but I hope this perspective is useful. It’s uncomfortable to think of myself as so persuadable that I can’t even watch YouTube without some of the ideals of the creators and the platform rubbing off on me, but it’s kinda true. I can try to resist that, but it takes a conscious effort which I rarely even think to put in. The truth is, our minds are designed by evolution to be porous and to integrate with each other. This makes us both powerful and vulnerable, so it’s worth thinking about! We ought to be mindful of what we expose ourselves to, and what ideas we let in.

What do you think? I’d love to hear from you in the comments.

Author Nate Gaylinn (he/him)Posted onJune 7, 2023CategoriesProgramming with PeopleTagsadvertisement, broadcast media, capitalism, culture, evolution, influence, media, minds, propaganda, social intelligence, social media6 Commentson The Programmable Species
Getting into Grad School
Getting into Grad School
(Photo is a shot I took of downtown Burlington, VT at twilight with lights in the trees and a clock tower in the background)

A year and a half ago, I took a big risk by leaving my comfortable career in the tech industry to pursue a graduate degree. Like many people, recent events inspired me to find more meaningful work, but it’s an intimidating change. How do you even do that? I have ideas I want to pursue, but they’re not exactly mainstream, and grad school is competitive. I didn’t know where to start, but I decided to try. I pushed my way through, and I’m very happy with the results. I don’t claim to have a secret recipe for career change, but I want to share my experience in case it’s helpful for you or someone you know.

My first challenge was realizing: I have no idea what grad school is even like. Most universities have two parallel programs: they provide a baseline education to the masses for a profit, and then they actually do science and train scientists. Generally speaking, the only thing these have in common is the college where they happen. I got my baseline undergraduate education at Brown, but that didn’t teach me anything about grad school. While I was on campus, I had the opportunity to learn about grad school, but I wasn’t interested then, so I let that chance pass me by.

Many years later, I tried to learn what grad school is and how to succeed there by talking to students and professors. This was surprisingly painful. In general, folks did a poor job explaining what grad school is like, and gave me all sorts of conflicting advice. Gradually, I began to see two big reasons why:

Diversity. There’s no one “grad school experience.” Every school, discipline, program, and lab is different. They have their own jargon, priorities, and expectations. Yet, when asking someone about it, they will describe their experience as typical, and give specific advice that would have helped them. The best way to get a sense of what’s “normal” is to talk to lots of folks and pay careful attention to where they disagree. Conflicting advice helped me understand the full range of programs out there.
Immersion. Grad school is an immersive experience. I expect I’ll show up on campus, get swept up in things, and gradually discover I’m “being a grad student” without ever being taught how. This sort of experiential learning is fast and effective, but it’s hard to explain. People just don’t have the words. They shared lots of details, but without context those mostly went over my head. They didn’t mention the “obvious stuff,” because it’s intuitive for them, and I didn’t know to ask about it. To learn the fundamentals, I had to read between the lines. When something didn’t add up, I’d look for hidden assumptions that could explain the reasoning. Cross referencing multiple conversations was important.
The next challenge was finding the right place for me. At a high level, academia is divided into disciplines, like Physics, Biology, or Computer Science, and each of those has many sub-disciplines nested within. Each one is working on a certain set of problems using certain tools and methods. Many grad students start with no clear idea of what they’ll do. They just pick a discipline, learn about it, and find a way to make themselves useful. My situation is different: I have specific ideas I want to pursue. Unfortunately, scientists aren’t very interested in cool ideas from outsiders, unless they happen to fit within their field of research.

It took me a long time to figure out what discipline to join. It seems like it should be obvious, but many research questions like mine are interdisciplinary, and don’t fit the usual options. Ultimately, it came down to what tools I wanted to use. Even though my ideas are about life, self-making, and meaning, I want to study these phenomena as algorithms, analyze their behavior, and recreate them in a computer. This led me to focus on Computer Science, and the sub-field of Artificial Intelligence. I’m ambitious and experienced, so naturally I thought I’d apply to the top schools for CS and AI. That was a mistake.

The problem is,the big-name schools are mainstream by definition, and my research is not. I’m actually quite concerned that the field has lost its way. They have too narrow a definition for “intelligence,” and tend to worry more about new consumer technology than understanding nature. But the big schools are the ones setting this agenda. Their programs are highly competitive, and they’re looking for people who will advance their goals. Even if I somehow managed to get in, they would not provide a supportive environment for me as a student.

If not the big name schools, then where? There are many options, covering an enormous range. How do I find the right one? The promotional materials online are quite generic and unhelpful, so again I turned to people. I cold emailed professors doing vaguely related work, and maybe one in five replied. At first, they barely understood what I was talking about or what to suggest, but usually they could point me at someone slightly more relevant than themselves. That way, I gradually worked my way to folks who “got it.” This led me to a totally new list of schools to apply to. It took nearly a full year, and I wish I had longer.

Figuring out where I fit in was also about looking inwards. I had ideas, but they were vague and complex. To talk to people, I had to explain myself in ways they could understand. That was hard, but useful. It forced me to consolidate my ideas, disentangle them, and look at them from many angles. I wrote it all down, which was important. Most professors don’t have time for extra reading, but the writing process helped me organize my thoughts, making them much easier to talk about. Some of that writing even ended up on this blog.

I also did a lot of reading, which was invaluable. I read books and journal articles covering a wide swath around my ideas in different fields. This let me survey the kinds of work people were actually doing, and imagine myself in their shoes. I was surprised by how many ideas excited me in theory, but sounded like a drag in practice. I also learned about the jargon, ideas, and thinkers in this space. That made it much easier to talk to professors, helped me find new leads, and gave me new tools for my research.

What are my big takeaways from all of this? Grad school is a bit of a catch-22. It’s a big, complex, and opaque institution. It’s hard to learn about it without being a part of it. It’s hard to get accepted or be successful without knowing the field, the professors, the incentive structures—in other words, being an insider already. Luckily, it’s possible to pick up this knowledge. It’s just a difficult and time-consuming process, and it helps to have connections. Most professors don’t have time for outsiders, but some are eager to help, especially for ideas near and dear to their hearts. Once I finally found folks who shared my interests, they welcomed me with open arms.

So that’s my journey, what I did, what I learned, and how it went. Now I’d love to hear from you. Does any of this surprise you, or resonate with your own experience? Do you have any questions about getting into higher education, or advice for others just getting started? Any thoughts on the state of academia generally? Join the conversation in the comments! It’s my favorite part of this blog, so don’t miss out.

Author Nate Gaylinn (he/him)Posted onMay 3, 2023CategoriesPersonal ReflectionsTagsadmissions, career, grad school, phd, research6 Commentson Getting into Grad School
Back to School
Back to School
I’m excited to share that I will begin a PhD program with the University of Vermont (UVM) this Fall. That means Christina, Socks, and I are moving to Burlington, far from our home in Silicon Valley. We think it’s worth it, because the Vermont Complex Systems Center is a unique community, with a perspective on intelligence that really speaks to me, and a wealth of projects and experts on the niche topics I want to explore. They’re also great people. I look forward to working with Josh Bongard, Nick Cheney, and their labs on research at the intersection of cellular biology, robotics, and machine learning. I’m particularly excited at the prospect of joining the Xenobots research program, which is perhaps the coolest thing ever. It seems like a great opportunity to study the intelligence of cells and bodies first hand, to build computer models of intelligence without brains, and potentially to contribute to some truly amazing medical applications in the distant future. More on this as I learn and get involved first hand…

Author Nate Gaylinn (he/him)Posted onApril 6, 2023CategoriesStatus Updates14 Commentson Back to School
What ChatGPT Can Teach Us About Being Human
What ChatGPT Can Teach Us About Being Human
(This post’s featured image is not a photo of the idyllic California vineyard my wife and I visited in 2015, but a similar looking AI-generated fiction)

The excitement around large language models (LLMs) continues. Often just called “AI,” this new technology takes instructions in plain English, and generates new text or images so good you’d think a human made them. There are some serious concerns about the ethics of how this is done (see the Dangers of Stochastic Parrots), and many articles warning people that LLMs aren’t as human as they seem. Still, these LLMs are clearly doing something smart, and it’s weirdly compelling. What’s going on here? What can LLMs teach us about the human mind, our strengths and weaknesses, and why we’re so easily fooled and mesmerized by this tech?

There are lots of articles about how LLMs work and their limitations (I even wrote one a while back), so I won’t go into much detail here. What matters for now is that LLMs are prediction engines. Given some text, they try to guess how a human would respond, based on a statistical analysis of all the content on the internet. They do this extremely well, but not perfectly. LLMs don’t think, perceive, or interact with the world in a human-like way, so sometimes they make weird mistakes a human never would.

In some ways, the human brain works a lot like an LLM. From day one, the brain is looking for language. It automatically builds up vast networks of words, concepts, and their relationships. When I hear someone talking, my mind is suddenly filled with the speaker’s ideas and their associations, building up an image in my mind’s eye. This is basically what an LLM does.

However, I also have many other intelligent faculties that join in. I don’t just know that “dog” is a word related to “cat.” I have memories of specific dogs, what their fur felt like, and the experiences we shared. I have common sense, logic, and theory of mind to decide whether something I hear is truth, fantasy, error, or deception. I monitor my own thoughts to gauge my level of confidence and correct my mistakes. I anticipate the future, make plans, and use language to achieve my goals. LLMs don’t do any of that.

Of course, there are AI researchers working to approximate these other kinds of human intelligence (though progress here is limited compared with LLMs themselves). Rebooting AI is a great book exploring that work, which argues its just a matter of time before AI can do everything a human can. Personally, I’m skeptical that we’ll ever reverse engineer all the subtlety of human thought, but I think it’s safe to say that AIs will become more powerful and well-rounded in the future. Perhaps the more important question is whether building increasingly realistic human simulations is a good idea at all.

For now, LLMs are a bit of a one-trick pony. What’s scary is that one trick is often good enough to fool humans and do useful work. In particular, even though LLMs were designed to be text prediction engines, they are surprisingly good at general problem solving. They can paint pictures, do math, solve brain teasers, and even write and simulate computer programs. Maybe those “extra” faculties of the human mind aren’t so important after all?

LLMs “think” in terms of words and relationships and patterns they’ve seen before. In human terms, that means stereotypes, cliches, generalizing from past “experience,” and repeating what they are told. We like to think that human thought is more sophisticated than that, but it often isn’t. We sometimes don’t see people as individuals, but in terms of the role they play in society (ie, “barista” or “mom”). We make decisions based on rules of thumb or gut feeling, without the need for logic and reasoning. We talk about things we don’t fully comprehend. We repeat talking points in order to fit in with our tribe. We confidently make up nonsense just to satisfy each other and move on. It’s surprising how LLM-like humans can be sometimes.

And that’s not meant to be derogatory! Those ways of thinking can be very effective. A lot of language isn’t about complex ideas, comprehension, and reasoning, but just putting one word after another to evoke an image in someone else’s mind. Past experience often is a highly effective and low-effort way to predict the future. Lying is anti-social, but “fake it ‘til you make it” works. One of the fastest ways to pick up a new skill is to boldly make mistakes, get feedback, and learn from that experience. The main difference is that today’s LLMs don’t learn from their mistakes, they never doubt their “intuition,” and they have no alternative ways of “thinking” when these techniques fall short.

So, yeah, LLMs only do part of what humans do, but it’s a big and important part. Occasionally we do need facts, critical thinking, self-doubt, and all the rest to do the right thing, but they don’t come up as often as we like to think. The real danger of LLMs, then, is that 80% of the time they might be good enough, but 20% of the time we need fancy human judgment to notice they screwed up and decide what to do. This is a serious problem. Humans are bad at vigilance, and we have a strong instinct to trust language, which in this case is exactly the wrong response.

Language is a defining feature of our species. We aren’t just capable of language, it’s a human universal. Every culture has language. Babies attend to speech from the moment they’re born, and start to babble in a few months. When there isn’t a common language spoken around them, children raised together will spontaneously invent one. Language is a biological imperative for us. It’s in our DNA.

When we perceive language, our minds automatically assume that it’s communication. We imagine another mind behind the words, usually with good intent and a desire to cooperate. Up until recently, this was a pretty safe assumption, so it was totally reasonable for the brain to immediately and automatically translate language into meaning. But now this instinct is backfiring. LLMs create realistic text and imagery without any intentional meaning. They don’t produce “answers,” “opinions,” or “art,” just random content that looks like those things. It’s both very difficult and important to remember that.

We’re still working to understand how these LLMs work, what their limitations are, and what they’re good for. As we do that, I hope we’ll come to understand ourselves better, too. What do you think? Have LLMs made you think about minds any differently? Have you seen any interesting examples of AIs acting strange or foolish? What about people acting like LLMs? Any thoughts or fears about computers gradually inching toward human-like abilities? I’d love to hear from you in the comments.

Author Nate Gaylinn (he/him)Posted onApril 5, 2023CategoriesIntrospectionTagslanguage, llm, machine_learning, meaning, minds7 Commentson What ChatGPT Can Teach Us About Being Human
The Age of Microbes
The Age of Microbes
(Image used under Creative Commons license, source)

There’s something very romantic about “the Age of Dinosaurs.” Before the familiar ecosystems of today, there was a completely different world order. Bizarre and fantastic species, strange environments and ways of living, another planet buried in the past of our familiar home. Yet, that was just one stage in our planet’s evolution—one that’s relatively recent, and similar to our own. It’s easy to forget that amniotes (reptiles, dinosaurs, birds, mammals, and the like) have only been around for 10% of Earth’s history, or about 300 million years. By comparison, single cells were the only life on Earth for 2.8 billion years. We sometimes hand wave over that period and say “not much happened,” but in that time life somehow went from accidentally self-perpetuating chemical reactions to swarms of intelligent microrobots that coordinate by the trillions to dominate every corner of the globe. This was the time of some of life’s most important and profound innovations, including essential concepts that made large-scale life possible.

About four billion years ago, the molten Earth finally cooled enough to form a solid crust of rock that could hold liquid water. Just 200 million years later, we see evidence of cells in the fossil record. In other words, it took just 200 million years for chance chemical reactions to become “self aware.” These early cells had no minds, of course, but they had membranes separating their insides from their outsides. They actively monitored and maintained the delicate balance of metabolic processes keeping them alive. Yet that was just the beginning of the journey, the basic foundation that made all the rest possible. From there, it took cells another billion years to cover the planet’s surface, and they’ve been ubiquitous ever since.

In that time, not much happened… from the human perspective. If you visited Earth at the time, it would look pretty boring. You might notice some slimes or biofilms, but you’d need a microscope to really appreciate that as “life.” Yet, gradually, microbes terraformed the planet. They found and exploited every available source of energy, and developed a molecular toolkit for extracting resources from a dead world. They mined useful molecules from the air, water, and rock, transforming and concentrating them for future generations. They remade the atmosphere, filling it with volatile oxygen, providing an energy-dense fuel for organisms to come. They created a protective layer of ozone that blocked DNA-frying radiation and made land habitable for the first time. This would all be invisible to a human observer because it happened so slowly, but the scale and significance of this transformation is incredible, especially coming from such tiny, mindless lifeforms. How could this happen?

Perhaps the biggest misconception about evolution is that simpler forms of life are “less evolved” than we are. The reality is that everything alive today has a common ancestor, and has had just as much time to evolve from there. Even bacteria are highly sophisticated organisms. They sense light, heat, motion, and chemicals. They sniff out food and resources, and navigate their environment. They hunt and evade predators. They learn and remember. They coordinate their behaviors with pheromone signaling. They sustain themselves, repair themselves, and make copies of themselves. In many ways, a single bacterium is vastly more impressive than anything made by humans. Like all life, they’re very good at what they do, but appreciating that intelligence means taking their perspective, which is rather difficult for humans.

For example, microbes experience evolution quite differently than we do. For humans, it’s a very abstract concept. It only matters on the scale of many generations, which may take thousands or millions of years. In contrast, a colony of E. coli bacteria can double in number every 20 minutes. They evolve over the course of hours, so for them it’s a real-time problem solving tool. There’s a fascinating experiment where bacteria took just eleven days to incrementally evolve resistance to antibiotics at a concentration 1,000 times what was originally a lethal dose. You can actually watch as the population discovers innovations that allow them to resist the poison and expand into new territory. When they do, they get a brief moment of total freedom, spreading unhindered until they start to get competition from their fellow mutants for the limited space remaining.

This is what cells are really good at. Not just living one lifestyle, but finding new lifestyles. In a crowded, competitive world, the best way for an organism to set itself apart is novelty: gaining access to an empty niche, or finding some innovative way to out-compete its neighbors. Doing this over, and over, and over again is how life managed to colonize every corner of this planet, from underwater volcanic vents, to Antarctic ice, to your gut. Exploration and creativity is also critical for long-term survival. On a geologic time scale, niches and lifestyles are transient, coming and going as changes in environmental conditions and competition from other species reshape the landscape. Staying alive means constantly adapting and trying new strategies. On a fundamental level, this is what life does.

This perspective helps explain one of the strange things about cells. Every living thing we know—every single cell, even the most ancient and primitive Archaea—has a general-purpose design. At their core, there’s a 3D printer for proteins, capable of mass producing molecules in a mind-boggling variety of shapes. Those proteins form the structure and machinery of the cell, help digest various food stuffs, neutralize toxins, and perform computations. Importantly, this 3D printer doesn’t just produce every protein a cell needs to live. It can make any protein, from any species, even proteins that haven’t been discovered yet. This would be massively overkill for living in any single niche, but it’s the ideal tool for conquering every niche. This complex, general-purpose cell design was so powerful that it out-competed and replaced everything simpler.

DNA mostly consists of programs for that 3D printer. It’s a collection of recipes for proteins, and cues for when to make them. Life hoards those recipes. They represent tools and behaviors that were once useful in the past. Right now, they might not be useful. They may even be harmful, disabled, and packed away where they can do no damage, but they aren’t forgotten. They lie dormant, waiting to be re-enabled on demand or by accident, just in case they might one day prove useful again. After all, who knows when the next global catastrophe will completely rewrite the rules of survival on this planet?

In other words, cells specialize in exploring the space of possible forms and lifestyles. They build up massive libraries of tools and strategies in their DNA. They continuously reprogram themselves, adapting to any conditions in order to find new niches. Macroscopic life, from butterflies to avocados to whales, is only possible because of this polymorphic quality of cells. They are the secret ingredient. They are like “smart matter” that can act autonomously, respond in real time, take on any shape, produce any chemical, and implement any behavior. Once you have that, it’s relatively easy to program those cells to construct just the right mix of forms, organized in just the right way, to make something much greater than the sum of its parts.

I hope this conveys some of why I find cellular intelligence so exciting. Humans are most interested in human things, so it’s very easy to ignore the incredibly alien lives happening right under our noses. Yet, there’s so much to explore, and so much of what we are is that “alien” cellular intelligence. What do you think? Did this help you see single cells or life in general in a different light? Did this spark any questions or ideas? Anything you’d like to see me explore more in a future post? I’d love to hear from you in the comments.

Author Nate Gaylinn (he/him)Posted onMarch 1, 2023CategoriesMindless IntelligenceTagsbacteria, cells, diversity, dna, earth, evolution, microbes, platforms, terraforming10 Commentson The Age of Microbes
In Every Mind, a Universe
In Every Mind, a Universe
The first life was blind and ignorant. It was little more than a self-perpetuating chemical reaction, constantly rebuilding itself and making new copies. It had no idea where it was because it had no way to perceive the world around it. Even the very notion of existing and moving within a physical space was incomprehensible. It didn’t know what it was, or even that it was, because it had no way to perceive its inner life, either. It just kept on going, making copies of itself, frequently with errors that made it worse or (occasionally) better at being alive.

Eventually, by chance, life discovered something very useful: certain molecules change shape when something happens to them. Some respond to being hit with light, others change in response to temperature, or pressure, or brushing up against another molecule with just the right shape. Life learned to read these signs, understand them as clues about the world, analyze them, make decisions, and respond. At least, metaphorically speaking. In reality, we’re still just talking about chemical reactions here. One shape change might trigger another, which might cause some new protein molecule to be synthesized, or kick off a chain reaction that leads to a cell moving, adjusting its metabolism, or whatever. The cell acts as if it appreciated the meaning of this signal, but without “thinking” except in a purely mechanical way.

This was the origin of meaning. At first, it was a very primitive thing. Life learned to discriminate between “good” and “bad.” That is, it noticed signs correlated with favorable living conditions, survival, and reproduction. Organisms that sought out more “good” signals while avoiding “bad” signals tended to live longer and produce more offspring. In this way, evolution slowly transformed random patterns of stimulus and response into instinct, innate biases baked in from birth, representing a sort of ancestral “knowledge.” Over time, life evolved more nuanced concepts like: light and dark; warm and cold; food and poison; me, us, and them. Teasing apart these subtler shades of meaning helped life develop more complex and successful strategies to survive in the world.

Every organism has this sort of evolved map of meaning (an “innate ontology”), implicit in their genes. It’s defined by their senses, physical capabilities, reflexes, and gut feelings. That means every species has a profoundly different perspective on reality. Fish, for instance, may have no conception of water because to them it’s a lifelong constant with no alternative. However, they have a very nuanced sense of the information carried in the water, which we are totally blind to. They can be very sensitive to things like pressure, temperature, chemical concentrations, currents, and even electrical fields. To a limited extent, they instinctively “know” where these signs are coming from, what they foretell, and how to react.

Talking about “ontology” as something in our genes is a little unusual. Typically that word is applied minds, perhaps just human minds. It’s about how we perceive reality, dividing it up into objects, categories, and relationships. It’s how people fundamentally understand themselves and the world they live in, and it’s heavily influenced by culture. But philosophers like Daniel Dennett insist that the same concepts should be extended to precognitive life, as well. Our physical bodies lead us to perceive and think and act in human ways, laying a foundation upon which conscious learning and culture can build. In that view, our rich mental ontology is a product of evolution, constructed from lower-level, simpler, more instinctual parts that we share with many species.

Like the first living thing, each human is born into a new and unfamiliar world, forced to figure out how to survive from scratch. We do have a major leg up, though: we’re born with senses and instincts and the ability to move our bodies. Our nervous systems carry and integrate the sensations from our many cells to our brain as a coherent bundle of information. Our brains are highly structured, with all the tools we need to make sense of those signals set up and ready to go. For instance, our multi-stage vision pipeline takes in light signals from our optic nerve, then processes them to detect edges, shape, movement, and even faces from day one. As infants, we don’t know what these things mean yet, but our bodies present the information to our minds in a convenient form and draw our attention, making them quick and easy to learn.

But our innate ontology is very vague. We are born with a sort of “knowledge” (or at least a predisposition to learn) that we are bodies that can move around in a 3D world. That world is filled with objects we can interact with. Some of these objects can move, some are useful, and some are alive. We get tired, hungry, and sick. We need to breathe, drink, and eat other living things to survive. That’s all obvious from a very young age. The rest is on us to figure out. How do we tell friend from foe? How do we find shelter? What’s good to eat around here? How do we make a living? What is the purpose of our existence? These questions are context dependent and quick to change, so life hasn’t evolved answers for us. It can’t. Instead, it gave us brains so we could find our own answers.

What makes humans truly special, though, is that we don’t build our ontologies just by trial and error. We talk about our ontologies. We point things out, name them, tell stories, give demonstrations. We learn from our parents, peers, teachers, and the media. We’re immersed in the collective ontology of our species, something all of humanity has been cultivating for over a hundred thousand years. Our minds are built to soak it all in and to very quickly adopt a picture of reality that’s much richer, more accurate, and more nuanced than what’s available to any other species. Much more than any one human could possibly figure out in their lifetime.

This way of understanding reality is powerful, but it leads to a great big illusion: we tend to see our ontology as reality itself. That’s understandable. Our ontology is our window on the world. It encompasses everything we can perceive, understand, and do. Yet, it is not a real thing. It’s an image in our minds, our bodies, and our genes. It’s informed by our genetic ancestors, our senses, and what we’ve learned from each other. But we perceive much more than our senses actually take in. Our brains are running a sort of “image enhancement” algorithm, as seen in Sci Fi classics like Blade Runner and now made manifest by deep learning software. We take in a little data, then use our knowledge and expectations to extrapolate something much bigger, fuller, and richer, making up the details that we can’t directly perceive. That is, we see what we believe. We perceive concepts, not reality as it truly is.

Of course, if our ontology is not a real thing and lives inside our minds, the consequence is that every human being must have a different ontology. They are in many ways similar, sure. We are the same species, living in the same world, with the same basic needs. We may even be from the same community, with a shared culture. Yet, we might disagree about the meaning of important concepts like “freedom,” “equity,” and “justice.” We might have very different ideas about what money is, what purpose a government serves, or how to be a good person. These are not disagreements about facts, but about the structure of reality itself—the framework we use to fit facts together into a coherent picture. These disagreements are particularly hard to reconcile, since it’s hard to even imagine what doesn’t fit inside my ontology.

That was a bit of a whirlwind tour of ontology. I went fast and skipped over plenty, so I’ll ask: what would you like me to go deeper on? Is there anything that doesn’t make sense? Anything that fascinates or excites you? Let me know in the comments. If you’d like to learn more about ontology in its many forms and how it evolved, I highly recommend From Bacteria to Bach and Back by Daniel Dennett.

Author Nate Gaylinn (he/him)Posted onFebruary 1, 2023CategoriesArmchair PhilosophyTagsbodies, cells, culture, evolution, instinct, learning, meaning, minds, ontology12 Commentson In Every Mind, a Universe
Best Intentions
Best Intentions
For the most part, people have good intentions. We generally want to be kind, responsible, and respected by our communities (at least, once our own personal needs are met). We have worthy goals and dreams for how to make life better. Yet, we all know that doesn’t always work out. We struggle with our impulses and willpower. We break our New Year’s resolutions as soon as we set them. We say one thing, then find ourselves doing another. This is true of individuals, but also for teams, communities, and organizations. Why does this happen, and what can we do about it?

Intentions are an important part of what makes us human. All sorts of animals set goals and make plans, but they’re usually very basic, short-term intentions, like “I’m gonna eat that bug.” In most species, lifestyle is largely innate, defined by genetics and the environment with only limited flexibility. Humans are different in that we design our lifestyles, both as individuals and as a society. We set abstract, long-term intentions like “I’m gonna save up for college” or “all people in this company should have equal opportunity.” These ambitious visions can help us imagine possible futures, and guide us to make them a reality.

It’s easy to set good intentions and stop there. Sometimes that’s enough, but often it’s not. Those delayed goals can be tricky for our animal minds, after all. I meant to pick up eggs on my way home, but I forgot. I know I ought to make a healthy dinner, but I’m exhausted, so I’ll order pizza. I said I’d learn Japanese, but maybe I was just kidding myself. I wanted to build a shed in the backyard, but I didn’t really know how, so it never got started. When one of my female engineers at work was criticized unfairly, I thought I was being supportive when I swooped in to defend her. When she pointed out how I was preventing her from proving herself, I had to unlearn that habit. In each of these cases, I meant well, yet I fell short.

This highlights some of the key problems with intentions. They aren’t rules that the brain enforces. If I keep my intentions in mind, I might notice when they should affect my decisions, and act accordingly. Or I might not. Like all people, I spend a lot of time on auto-pilot. I often get tired or distracted. I make countless choices in a day I’m not even aware of. Then there’s willpower. Just because I know I ought to do the right thing, doesn’t mean I will after a long and frustrating day. Lastly, intentions don’t come with step-by-step instructions. It’s often not clear how to achieve my goals, so I have to think about the steps involved, what my options are, and what outcomes are likely. Even if I do everything right, reality doesn’t always play along. I have to watch to make sure things turn out the way I intended, and respond when they don’t.

At their best, intentions serve as a frame for thinking and planning. They’re a first step in a process that leads to an outcome. To improve the chances of success, I must design that process. I must compensate for my cognitive blind spots and mitigate the risk of accidents and surprises. This is a form of self-programming. What can I do now to shape my future behavior? How do I make sure I get into the right situations and avoid the wrong ones? How will I notice when that happens? Can I prepare so that I know what to do in the moment, and have everything I need to act? How will I know if my plan is working, and change course if I need to?

I’ve found there are two essential tools for this sort of planning:

Write and revisit. Intentions are often too vague to be useful. They can be easy to forget, and can drift over time without our notice. To remedy this, I write my intentions down. When possible, I share them with others to make sure I’m rigorous about it, and to create a sense of accountability. Then I set a reminder to revisit those intentions in a few weeks or months. I try to be brutally honest with myself. Am I living up to my expectations? Do I still think about the problem in the same way? If not, I try not to feel guilty, but instead focus on what to do about it. What’s wrong? Should I change my behavior? My intentions? Both? I force myself to think about this.
Prepare yourself. When I set intentions, I think through how to achieve them. Not in full detail, but at least I’ll identify a few major sub-goals that are essential for success. I think about when and how I might do those things, and create some structure around that to make it real. I write TODO lists and set time aside for specific tasks. I leave notes or physical reminders in the real world to nudge me at crucial moments. I think about what decisions I’ll have to make, and how to make them. This is a way of front-loading the effort, doing the thinking and willpower work when I have time for it. That way, when the crucial moment comes, my actions can be fully automatic.
Critically, these two things go hand in hand. Writing down my intentions doesn’t help much if I don’t take some action to ensure they happen. Similarly, making a plan and following it rigorously can be a disaster if it’s the wrong goal, the wrong plan, or if the situation changes. The benefit comes from cycling through these two modes of thinking regularly. What should I do? How should I do it? Is it working? What should I do next?

The same problems appear in teams, communities, and organizations, often amplified dramatically. Aligning intentions across many people is very hard, and aligning behaviors is impossible. Each person has their own motivations, and is gifted and fallible in their own unique ways. To be fully effective, they must set their own intentions, and find their own ways to reliably achieve them. Many leaders are good at setting intentions for their groups, but struggle to make them happen. Sometimes they just say what they want to accomplish and assume everyone gets it and will (somehow) make it happen without any guidance or coordination. Other times they micromanage, trying to force people to deliver by robbing them of their autonomy.

I lead others the same way I lead myself. I just apply the concepts at different levels of abstraction. As a leader, my main responsibility is to keep intentions fresh in my team’s minds and to encourage each individual to be productive in their own way. Rather than telling people what to do and how to do it, I make sure my team has policies and tools to help with common challenges. This gives them freedom and flexibility, but also reduces their burden in the moment and encourages consistency. I create timelines, schedule check-ins, and set reminders in the right time and place. I often don’t care about the timing, I just want to give folks a nudge when they need it, and encourage them to prioritize, pace themselves, and track their own progress. Every quarter, we revisit our intentions together and try to think: are these still the right goals? Is our approach working? Is there a better way?

What makes humans so remarkable is our flexibility. We work creatively within constraints, figuring out the details as we go along. Intentions are a powerful tool for doing that, but they’re just part of the story. Acting intentionally, either as a person or as a group, is about creating the conditions for success. It’s not enough to want something. We’re just animals, after all. We can’t see the future, we can’t be “on” all the time, and it’s very easy to get distracted or to deceive ourselves. If we embrace our limitations, we can try to work around them and do better. Or, at least we can forgive ourselves more easily when we inevitably let that New Year’s resolution slip.

What do you think? Have you sometimes struggled to live up to your own intentions? Do you have any advice for how to overcome that? What about in the work setting? Have you noticed any practices that make a team / company better or worse at living up to their own ideals? I’d love to hear from you in the comments.

Author Nate Gaylinn (he/him)Posted onJanuary 4, 2023CategoriesProgramming with PeopleTagsintentionality, leadership, management, minds, productivity11 Commentson Best Intentions
It’s Been a Year.
Well, that’s a wrap on 2022. I’ve been sharing my ideas with you here for twelve whole months now. The year sure did go by fast, and it’s been both exciting and productive. In addition to this blog, I’ve done some fascinating reading, met like-minded professors from around the country and explored their work (if you like my blog, you might also want to check out the Many Minds podcast, it’s awesome), and even published a new open source software prototype. I applied to five different graduate programs, and should hear back from them in the Spring. What a whirlwind!

Thanks for coming on this journey with me and taking the time to explore these big ideas. It means the world to me, and it helps keep me motivated. I plan to post here for years to come, and I hope you’ll stick around. If you’ve enjoyed reading along so far, please go back and “like” your favorite posts. This will give me a clear signal of what you appreciate most, so I can make more like that in the future. I’d also love to hear from you in the comments if you have any feedback, requests, or just wanna say hi. I’m still getting to know you and figuring out what this blog should be, so don’t be a stranger. If you know anybody else who might enjoy this blog, please do share it with them, too, and help us connect.

I hope you have a cozy and peaceful holiday season. See you all in the new year,

  — Nate

Author Nate Gaylinn (he/him)Posted onDecember 7, 2022CategoriesStatus Updates5 Commentson It’s Been a Year.
Learning to Move
Learning to Move
Most people identify their intelligence with their conscious mind. That’s the part that knows it’s intelligent. That’s the part that understands and makes decisions. But looking closely, there’s plenty of intelligent things we do below the conscious level. Perhaps the most striking example is movement. We use our bones and muscles continuously during our waking hours. We learn complex motor skills and perform them over and over again with great precision and reliability. Yet, we rarely think about how we do those things. It’s actually an under-appreciated superpower that helps us multitask, overcome injuries, and adapt to new opportunities over evolutionary time. How does that work, and what does it teach us about intelligence?

The human body is a large and complex machine. Over 200 bones give our bodies shape, support their bulk, and articulate through 400 joints. Over 600 muscles hold those bones together, move them relative to each other, and maintain position and posture. Unlike a building with a rigid, static structure, the body is like a floppy ragdoll. It can only hold a shape through the constant effort of its muscles. Imagine a team of circus workers, lifting a long tent pole by ropes tied to the top. They work together to overcome gravity, hoisting the heavy thing and keeping it in a precarious upright position. They carefully balance the forces from all directions, adjusting how hard they pull to keep the pole vertical, even compensating for the wind if necessary. Now imagine another tent pole balanced on top of that one. Then another, and another… it’s pretty amazing that the body can perform this feat at all.

And that’s just for standing still. Actually moving the body in useful ways is much more difficult. It requires the same coordination of many muscles, balancing and constantly adjusting their effort to hold a bone in position, but now the joints need to move. The body must choreograph, synchronize, and precision control dozens of muscles for even small, subtle movements. Thankfully, all of this is completely unconscious, because doing it manually would be a nightmare. To get a sense of this, check out the game QWOP. It’s a stupid, frustrating game, but a good illustration of the problem. It’s much easier to unconsciously control the thirty-odd muscles in each hand to type those four letters than it is to consciously control the four simulated muscles that make the QWOP guy run.

How do we do it? The brain has a dedicated subprocessor for controlling the body. The largest part of the human brain is the cortex, home to our perception, comprehension, higher level thought, and decision making. It’s a sort of general purpose computer that works across many modalities. Below that are several special-purpose brain regions that serve as an interface to the body. They are “neural networks” by definition, but with highly specialized design and function very different from the cortex. One of these brain regions is the cerebellum, and its main job is to produce precisely timed sequences of nerve impulses to control the body. We aren’t conscious of what’s happening in the cerebellum because it’s actually much older than our conscious minds. Every vertebrate has one, going back hundreds of millions of years.

The key trick to the cerebellum’s function is a feedback loop. The cerebellum doesn’t just “move the body.” It can only get it right by constantly monitoring how the body and each muscle responds to its signals, noticing any deviations from the ideal, and then adjusting its signals to compensate. This is necessary, because the body has to perform in any position, even under the influence of outside forces, even when some muscles are stiff, weak, tired, or injured. There’s no fixed control program that can work in all of those circumstances, so the cerebellum must adapt in real time. This is also how it learns. Each error is a lesson for the future. With practice, the cerebellum gets better at predicting how the body will respond to its signals, the errors get smaller, and the necessary corrections become more subtle.

As an example, my cerebellum wasn’t born knowing how to do yoga. I had to learn by trial and error. When I first tried getting into those shapes, I did a pretty bad job of it. My form was sloppy, and “wrong” in many details. My balance was precarious. My motion was awkward and jerky. I overused some muscles and neglected others entirely. But my teachers pointed out what I did wrong, and I made corrections. By performing the same motions again and again, learning what the right posture feels like and what adjustments to make, I built up muscle memory. Now I can just think “warrior II” and my body delivers effortlessly. I taught my cerebellum a new motion control program, and now I can invoke that program at will.

The real value of this unconscious mastery is how it frees up my mind. For instance, when I walk a familiar path, it’s like turning on autopilot. While my cerebellum takes care of putting one foot in front of the other, my default mode network can reflect, imagine, and make plans. This is a powerful form of multitasking, but it’s not always desired. For instance, in my yoga practice, I pay close attention to what my body is doing, even though that’s no longer necessary to perform the poses. The result is increased awareness, precision, and control in my movements, both right now and in the future. Practice lets my cerebellum refine its programming and learn layers of nuance that increase my skill level, but only if I pay attention. In other words, mastering a movement gives me the freedom to turn my mind to other things, or to focus on the performance, resulting in better quality and learning. I can’t do both at the same time.

The ability to control large, complex bodies and to think about other things at the same is amazing, but the cerebellum’s adaptability is even more important. Although some vertebrates are born knowing how to walk or swim, we all learn new ways of moving. This is how we adapt and recover after an injury, whether it’s a twisted ankle or a lost limb. It’s also how many species are able to use tools. The cerebellum doesn’t have a fixed image of the body and its limits, it can learn to contract or expand that image as needed. This also means it can learn to operate whatever body it’s born into. Vertebrates have evolved a huge range of bodies which can swim, crawl, walk, dig, climb, or fly. Each new form started off as a “birth defect,” but thanks to the adaptive powers of the cerebellum, sometimes these were not fatal flaws, but opportunities to explore new ways of living.

This is just one example of how our unconscious intelligence improves our daily lives and our ability to adapt over evolutionary time. This one happens to be part of the brain, but not the mind as we usually think of it. How does this fit with your experience? What’s it like coordinating the conscious and unconscious parts of your brain? If you’re into athletics, how do you think about training your mind as well as your body? Does this raise any more questions for you about how we think and move? If so, I’d love to hear from you in the comments.

Author Nate Gaylinn (he/him)Posted onDecember 7, 2022CategoriesThe Intelligent BodyTagsbody, bones, brain, cerebellum, default_mode_network, dmn, evolution, mindfulness, movement, multitasking, muscles, yoga7 Commentson Learning to Move
I Built a Thing.
This blog allows me to explore a very wide range of ideas, usually from a high level and for a general audience. I’m also doing some very specific, very technical research inspired by these ideas.

Today, I’m launching my first prototype. It’s just a proof of concept, really. A chance for me to flesh out some half-baked ideas and make them concrete. The results aren’t very interesting yet, but if you’d like to know what the technical side of my work looks like, here’s a sneak peek.

You can find the source code and a detailed walk-through of the project here.

You can find the results and analysis here, complete with lots of pretty videos and charts.

Author Nate Gaylinn (he/him)Posted onNovember 20, 2022CategoriesStatus Updates2 Commentson I Built a Thing.
Emotions and Cognitive Resonance
Emotions and Cognitive Resonance
Emotions are a challenging topic. I’ve spent years learning to recognize and manage my own emotions in a productive way. I’ve also done a lot of reading, learning from psychology, cognitive neuroscience, and behavioral biology how emotions work on a theoretical and practical level. That’s useful, but the actual experience of emotions and how they shape our minds, our well-being, and our lives is incredibly subtle and complicated. I don’t think I’ll ever fully understand it, but I find it fascinating because emotions serve as a sort of interface between two different kinds of human intelligence: the body and the mind.

I like to think of the body as an autonomous robot. It does its best to survive, sustain itself, and react appropriately to whatever’s happening, recruiting the mind to understand the world and make wise decisions. That robot has evolved many different modes of behavior, each suited to particular needs, problems, and contexts. One of the main challenges for controlling the body, then, is choosing which state to be in right now. Should I look for food? Flirt with a potential mate? Take shelter and conserve my energy? Run for my life? Being successful means constantly monitoring my situation, dynamically switching from state to state, to make sure my behaviors fit the moment.

In human beings, there are tons of these “states,” but they’re hard to count since they’re so multi-dimensional and blurred at the edges. Some of the most notable ones are the core emotions (happiness, sadness, fear, and anger), but others are directly tied to the body’s function, like hunger, arousal, and fatigue. The state of the body is decided by a cocktail of hormones and neurotransmitters in the bloodstream, which coordinate activity across all the organ systems. They evolved before the brain, which is why the mind has only an indirect awareness of them. It experiences them as “feelings,” often by interpreting subtle and ambiguous signals like a flush of heat, a stirring in the guts, or a racing pulse.

That said, the brain plays a crucial role in emotions. The mind interprets what’s going on in the world to help trigger the right emotions, and emotions reconfigure the brain to serve in whatever activity the body is doing. Those chemicals in my bloodstream tune parts of my brain to be more or less active, reshaping my perception, judgment, and impulses. They shift my patterns of thought and behavior dramatically, whether I like it or not. When I’m angry, I’m more likely to perceive someone as a threat. I’m less likely to stop and think, and more likely to lash out. Looking back at the situation later with a clear head (that is, one that’s not flooded with neurotransmitters), I might see things very differently. That’s part of why recognizing emotions is so hard. Noticing and understanding are cognitive processes, happening inside my mind, while it’s being warped or even impaired by those emotions.

Another important factor at play here is how non-linear brains are. They’re collections of many different special-purpose sub-networks. These all work together in concert, combining their efforts, calling on each other, and riffing off each other to produce my stream of consciousness. This is an extremely powerful tool for creative thinking, quick intuitive action, and using metaphor to recall relevant experiences from the past. The flip side is that causality becomes very muddled. Ideas flow into one another in a sort of free-associative cascade, often forming self-reinforcing cycles. Every thought in my head is simultaneously cause and effect.

All these brain networks, ideas, and memories are linked together by associations, which cause them to resonate with each other and activate at the same time. These associations are often based on similarity or relevance, but emotions make some of the strongest and most common links. Most thoughts have emotional significance, and thinking those thoughts will evoke the associated feelings. Similarly, feelings evoke associated thoughts. More subtly, emotions also change my sense of salience. When I’m mad, I’m more likely to notice and fixate on thoughts and observations that resonate with that feeling of anger, while others get ignored.

This explains why it’s so hard to identify why I’m feeling an emotion. As a human being, I have a body evolved to react to immediate threats and opportunities, and a mind that spends much of its time thinking about abstract concepts, world events, and possible futures. This makes it very easy to misattribute my emotions. When I notice a feeling, I tend to associate it with whatever I was thinking or experiencing at that moment. This is often wrong, and that can cause problems.

A perfect example is displaced aggression. When my father was diagnosed with cancer, I was suddenly faced with many intense emotions, like anger, sadness, and fear. I carried these with me all the time, but there was little I could do to help, so I tried not to dwell on them. Nonetheless, I was much more irritable than usual. It was like my personality changed, and in a sense, it really did. I’d overreact to small slights and setbacks. I was more critical, aggressive, and impatient. I’d fixate on some insignificant detail from an email or meeting to the point where I’d be fuming about it when I got home. I managed to stay professional and respectful at work, but it took a real effort to do so.

It’s worth emphasizing how harmful misattributing emotions can be. When I’m mad, anyone who crosses my path may stir that anger just by chance, tempting me to lash out. This means the people I interact with most—my coworkers, family, and friends—are the ones most at risk. There’s also the harm done to myself. When my dad was sick, I managed not to worry about that all the time, but mostly by worrying about other things instead. The distractions were easier to face, but also emotional and not really more productive. They did nothing to relieve my stress and irritability, which lingered on until I faced the root cause and processed those emotions.

Understanding all this has led me to a practice that I find works really well. Sometimes an idea or an experience gets me suddenly riled up and emotional. Often it’s something small and petty, or something grand and abstract, both good signs that the emotion is an overreaction. Whatever thought I’m having stirs up strong feelings, which in turn drives me to obsess more on the thought in an escalating cycle. I find myself ranting or ruminating. When I notice that happening, I try to calm myself down, get some exercise, and take a break to let the neurotransmitters dissipate so I can think clearly. Then, I can use the following technique.

I set aside the idea that bothered me, and instead I focus on the feelings that idea stirs up. I sit with them for a moment, and then I look at what other ideas resonate with them. Usually, there are several. Some are big, some small. Some are immediate and concrete, some distant and abstract. Often there’s one that stands out among all the others as the most salient, and it isn’t necessarily the idea I started with. That’s when I think, “Oh! So that’s what this is really about.” In other cases, I find lots of little things, unrelated, but piling on all at once. This helps me realize there’s no one cause for how I’m feeling right now, and it’s not fair or useful to blame a scapegoat for my generally bad day.

Emotions are a critical part of how the mind works. They define human values, shape our activities, and motivate everything we do. I hope reflecting on my own experience helps illuminate that. How does it resonate with you? Is your experience similar or different? Have you noticed other quirks about your emotions, your thoughts, and how they interact? Computers are generally emotionless, but a few chat bots simulate human-like emotion, and some agent-based AIs have their own system of states and “feelings,” suited to their artificial task and environment. How do you feel about emotional AIs?  I’d love to hear from you in the comments.

Author Nate Gaylinn (he/him)Posted onNovember 2, 2022CategoriesIntrospectionTagsbody, emotions, endocrinology, hormones, interfaces, mindfulness, minds, neuroscience, neurotransmitters9 Commentson Emotions and Cognitive Resonance
Why Genetic Algorithms?
Why Genetic Algorithms?
These days, the Artificial Intelligence community is pretty fixated on Deep Learning, a software tool inspired by the human brain. It’s popular because it’s successful. Deep Learning technology has driven incredible advances in natural language processing, image perception / generation, and game playing (not to mention ad targeting, feed ranking, and surveillance). That success was partly driven by luck. It turns out, even a fairly simple DL algorithm, given enormous amounts of data and computational power, can do pretty remarkable things. Other attempts at reproducing intelligent behavior haven’t been so successful, and are relatively neglected for that reason. That’s a shame, because I believe there are big opportunities in areas where we aren’t looking, they’re just a little more difficult to uncover.

Recently, I’ve taken particular interest in Genetic Algorithms. Put very simply, these are computer programs which use the principle of “survival of the fittest” at their core. They’ve been a popular topic of research since the 1960’s. Since then, they’ve found moderate success and have become standard kit for solving certain kinds of computational problems. Unfortunately, the fundamental design principles for GAs haven’t changed much since the 70’s, despite the fact that our understanding of evolution and our computing hardware have improved dramatically since then. I think today’s GAs are a shadow of what they could be, and I have ideas for how to unlock that potential.

But first, let’s establish what a traditional Genetic Algorithm is. Like Deep Learning, GAs are a tool for training a computer to do a task without explicitly telling it how to do the work step by step. There’s one big difference, though. DL is good at replicating what a human being would do, but to learn that it needs hundreds (or better yet, millions) of examples to study and imitate. So, it’s mostly good for automating work that people already do routinely. In contrast, GAs don’t need any example data. They’re good at solving problems where we don’t know the best solution or how to find it, just so long as we can recognize a good answer when we see it. The main challenge is framing the problem in such a way that the GA can learn to solve it.

Genetic Algorithms are often used when the space of possible answers is so big it would be impossible to try them all, or even to explore them in a systematic way. Instead, a GA depends on randomness. It starts by just guessing a bunch of solutions. Most of these will be garbage, so they get thrown out right away. The ones that are slightly better than complete garbage become the starting point for the next iteration. The algorithm makes more possible solutions by mixing the best previous solutions together and sprinkling in some extra randomness for variety. By sheer luck, some of those solutions may be better than the previous ones, and the process repeats. This simple method can be surprisingly effective, gradually transforming garbage into gold. But it depends a lot on giving the algorithm the right pieces to start with such that randomly mashing them together might actually work.

Natural selection is a kind of design process. Like human designers do, nature gets inspiration from random sources, tests ideas against harsh reality, and iterates to discover and build highly functional objects. Genetic Algorithms are basically an automated version of that process, so they’re frequently used as design tools. For instance, modern Computer Aided Drafting (CAD) software for architecture and industrial design often use GAs. A human designer specifies some constraints (how big an object can be, how much weight it must hold, etc.) and fitness goals (minimize weight and material costs, but maximize tensile strength), then the software automatically finds good solutions. Recently, there’s also been a great deal of interest in using GAs to design effective architectures for Deep Learning systems.

So, that’s Genetic Algorithms in a nutshell. Why do I feel there’s unrealized potential here? What do I want to do differently? There are several insights from modern evolutionary theory that I want to apply to GAs. Generally speaking, though, it’s all about what work is done by the programmer vs. what is left up to evolution. A GA uses a “gene sequence” (usually just a string of digits) to represent each of its attempted solutions. A gene sequence can either be a solution in itself, or a program that generates the solution. Traditionally, what the gene sequence means and how to derive an answer from it is entirely up to the programmer. This is very different from nature, where life evolved the language of genetics and species-specific genomes along with all the organisms built using those tools.

Then there’s the search process itself. In a traditional Genetic Algorithm, the programmer takes great care to tune the rate of mutation and the process of recombining genes from multiple individuals. They often hand design “custom mutations” that are more clever than just randomly changing digits in the gene sequence. They use their knowledge and intuition to avoid testing obviously bad gene sequences, to make changes that seem useful, and to preserve good patterns in the gene sequence that might otherwise get clobbered or broken up. This can help enormously, but it’s a lot of hard work for the programmer. The science of epigenetics shows that nature uses many of the same tricks, but it discovered them through natural selection, without any human guidance.

In a nutshell, life has an element of self-determination. Life designs itself, and optimizes the search process for better designs, using evolution by natural selection as its tool. I think it’s a mistake to imagine life as a passive product of evolution, like traditional Genetic Algorithms do. I think it’s a mistake to leave the hardest parts of GA development to a human being. Not only does that make human creativity a limiting factor, it means we aren’t studying or reproducing the most remarkable thing about natural evolution.

I hope this perspective will be valuable. One of the biggest shortcomings of Genetic Algorithms so far is that they aren’t nearly as open-ended or creative as life itself. Very rarely do they exhibit the sort of accumulated layers of complexity and sophistication that are the hallmark of natural intelligence. Perhaps that will change, if we can hand over more of the creative work to the GA? Perhaps a new paradigm in GA designs could make them applicable to new kinds of problems, or produce more clever solutions? I’m working on a prototype that I hope will demonstrate that potential.

The main drawback of my approach is that evolving the design for a Genetic Algorithm takes way more time and computing power than just running a GA designed the old fashioned way. I’m not too worried about that, though. I’m using the same parallel processing hardware that has become ubiquitous for Deep Learning applications to make my code efficient and scalable. My hope is that this new approach to GAs will make it possible to improve their performance by just throwing more computational power at the problem, like we already do so successfully with DL. This would also make GAs less cumbersome, by replacing expert design and hand-tuning with automation.

There’s lots more beyond this that I hope to explore in time. For instance, life evolves whole ecosystems and environments where organisms collaborate and support each other, producing intelligence, robustness, and efficiency far greater than the sum of its parts. By comparison, many Genetic Algorithms work on single individuals that exist in total isolation. Then there’s the way life evolves layer upon layer of emergent complexity, building communities out of brains, bodies, cells, and proteins. I’m excited to build multi-layered intelligent systems, and especially to try combining evolved programs and neural networks in a biologically realistic way.

Turns out, there’s much more to AI than Deep Learning. I’m pretty excited by the untapped potential of Genetic Algorithms, but that’s just me. Are there other areas of AI research that interest you? Can you think of more examples of natural intelligence that computers can’t seem to replicate? I’d love to hear from you in the comments. This post is also a preview of my research. I hope to share my first prototype by the end of the year. So, stay tuned for more on that.

Author Nate Gaylinn (he/him)Posted onOctober 6, 2022CategoriesBeyond DarwinTagsdeep_learning, design, epigenetics, evolution, genetic_algorithms, machine_learning, systems6 Commentson Why Genetic Algorithms?
Plants Move
Plants Move
(featuring an illustration by Sarina Mitchel)

Big brains are essential to our success as a species. That’s how we dominated this planet, so we tend look there to understand the secrets of intelligence. Yet, this perspective blinds us to other species’ achievements. Take plants, for instance. They don’t have brains at all, yet they make up over 82% of Earth’s biomass (source). They range in size from single celled algae to the largest organism on earth (learn about Pando here). Many of our greatest discoveries in chemistry, medicine, and material science amount to finding some plant that already solved a problem better than we could. Yet, we tend to see them as material resources rather than intelligent living beings. I suspect we underestimate plants because, from a certain perspective, they don’t do very much. They just sit there, letting food and water come to them. What’s so smart about that?

This perspective says more about human impatience than anything else. Plants can climb and tunnel and build. They search their environment for resources, relocate to prime spots, and wrestle with each other for access. They capture prey, hide from predators, and actively defend themselves from attackers. They can transform themselves dramatically, switching between totally different strategies depending on time of day, time of year, and environmental conditions. Plants are very active. It’s just on a different time scale than we’re used to. Plant movement is most obvious over hours, days, and years, though in some cases they move dramatically in just seconds.

Brains allow us to move quickly, which gives us a big advantage over plants, but I don’t think it makes us “more intelligent.” It’s better to say we found different strategies, specializing in different kinds of intelligence. Plants are slow and stationary because that’s energy efficient. It allows them to thrive in otherwise barren environments. Animals can’t do this. We all depend on plants for survival. Our extravagant, free-moving lifestyle is only possible because plants do the slow, hard work of capturing energy and nutrients from the air and soil, making concentrated fuel for our activity. Plants don’t need brains to live the way they do, and they don’t let that stop them from adopting all sorts of complex behaviors and lifestyles.

This is possible in part because plants often root themselves to the ground. That may seem like a poor choice, since it limits their options dramatically. They have to commit to one environment for their whole lives. Either that spot provides what they need, or it doesn’t and they’re doomed to die there. But there’s a major upside to this strategy: their lives are much more predictable than ours. This makes it possible for evolution to carefully plan responses to just about every threat or opportunity a plant might encounter in its lifetime. This is a different kind of intelligence than what we’re used to, one focused on exquisite design and finely crafted behavioral scripts, rather than spontaneity. Plants do respond in the moment, though, and even rooted to the ground they can be surprisingly mobile.

The most common and obvious way that plants move is through growth. Animals can’t really move until they’ve grown a body, but plants move by growing. They use their senses to track and follow the sun, water, and chemical nutrients they depend on. They feel the pull of gravity, the strain caused by the wind, and physical touch along their bodies. They change their shape by growing cells larger, faster, or in thicker layers on this side, but not that side. This allows them to reinforce themselves and stay upright, grope and crawl around obstacles to reach food, navigate wide open spaces with roots or runners, or wrap around trellises to pull themselves toward the sun.

Plants can also move by shifting water around their bodies in a process known as turgor. Cells with more water swell, while those with less shrink. By shifting water between cells in its stalk, a sunflower can rotate throughout the day to track the arc of the sun. Morning glories and lotuses use similar methods to hide and protect their delicate flowers at night, then unfurl them into extravagant displays to attract pollinators during the daytime. Although turgor is much slower than muscle contraction, it’s still fast enough to react to animals. The touch-me-not mimosa, sundew, and venus fly trap all move quickly in response to physical touch. A few species, like hairy bittercress and the squirting cucumber, are much more dramatic. They build up pressure behind a catch mechanism, then suddenly launch their seeds into the air with explosive force.

Plants are also masters of using weather and animals to help them move. Plants have evolved specialized seeds that travel great distances, allowing whole populations of plants to migrate and colonize new territory. You’ve probably encountered helicopter seeds that gracefully twirl through the air, dandelion seeds that ride the wind on floofy parasols, and burrs that hitch a ride on your pant leg. The energy for this motion doesn’t come from the plant itself, so should that even count? As an engineer, that sort of practical laziness just makes the design more impressive to me. The plant doesn’t bother capturing and reshaping energy for this, because it doesn’t have to. All it has to do is build the seed in the right shape and “let go” at the right moment.

What does all this tell us about intelligence? For one thing, life doesn’t need a brain to navigate obstacles, seek out resources, climb, glide, follow a daily routine, catch prey, or even launch projectiles. Plants are full of amazing behaviors that are completely mindless, yet elegant, successful, and highly optimized. We’ll never understand those behaviors by studying brains or Deep Learning algorithms, but they tell us a lot about ourselves. Our brains do not replace the kind of embodied intelligence we see so clearly in plants, they merely extend it. We depend very much on the same evolutionary design and “script-making” that governs the plant kingdom. Under the hood, much of what makes us intelligent comes down to the cells of our bodies, dynamically shifting chemical concentrations and patterns of growth, very much like plants do.

I hope to share several more posts about plants and fungi in the future, because there really is a lot to say. If you’re interested in going deeper on the topic of plant intelligence, I highly recommend the 1996 film Microcosmos. It explores the plants and tiny creatures in a meadow with some extraordinary macro and time-lapse photography. No other movie has given me a more vivid and profound sense of awe at how alive the world is, at every scale. Sadly, the streaming options are limited right now, but it’s worth it if you can get your hands on it.

As always, I’d love to hear your thoughts. What are your favorite examples of plants being amazing? Are there other kinds of “mindless intelligence” you’d like to see me write about? How do you think about the intelligence of plants and animals? How are they similar and how are they different? Let me know in the comments.

Author Nate Gaylinn (he/him)Posted onSeptember 7, 2022CategoriesMindless IntelligenceTagsdesign, evolution, growth, illustration, Mindless Intelligence, movement, plants, sarina_mitchel10 Commentson Plants Move
Incentive Landscapes
Incentive Landscapes
We tend to think of human intelligence as the power of a single brain, but human beings aren’t meant to work in isolation. Our intelligence is only fully realized in a group setting, where we can riff off each other, collaborate, and compete. But humans behave very differently in groups, and coordinating group behavior is hard. I didn’t fully appreciate that until I became a leader at Google. Leaders can’t just tell people what they want to make it happen. Their work is much more subtle: they shape incentive landscapes.

Ultimately, each person decides for themselves what to do at any moment. This is one of our superpowers as a species. We understand our environment, our place within it, and the choices available to us. We make decisions and plans that benefit us and our communities. This is not a particularly rational process. It’s heavily influenced by our instincts and emotions, through neurotransmitters like dopamine and oxytocin. Ultimately, it all comes down to what makes us feel good, whether that’s a literal reward like a doughnut or a paycheck, or more subtle pleasures like helping others or earning respect.

The theory of evolution often talks about “fitness landscapes.” Each organism is more or less “fit”, or likely to survive, thrive, and produce offspring in its environment. Across generations, a species explores different body shapes and behaviors, searching this fitness landscape for better lifestyles. Incentive landscapes are more or less the same thing, just on a different time scale. Evolution has equipped us with the ability to perceive and predict risks and rewards. It has hard-wired us to make real time decisions that, on average, should improve our reproductive fitness.

As a leader, this mostly means I have limited control over my team’s behavior. Yet, their decisions aren’t entirely free. Our team culture makes some paths much more likely than others. The best metaphor for this comes from sailing. Culture creates headwinds and tailwinds, which determine which paths are harder or easier. Tailwinds mean the wind is at my back, pushing me forward. Paths with a tailwind are more obvious, encouraged, and supported. Headwinds are the exact opposite. Those paths are obscured, high-friction, and full of obstacles. I can still go down a path with headwinds, and may even find success there, it just requires more effort and determination.

Leaders can’t decide what each person will do. Instead, they use incentives to influence all those independent choices, making the desired outcomes more likely on average. The most direct way to do this is with reward and punishment. When they’re transparent and consistent, they can guide group behavior quite effectively. Sometimes. A big challenge is that everyone perceives incentives differently. Some folks are highly motivated by a good speech, while others will simply roll their eyes. Extroverts may thrive on public recognition and fame, while introverts may dread the spotlight. Sometimes, money is the best motivator, and sometimes it feels demeaning. Punishment is just as problematic. How well a fine works depends on wealth. Some people take perverse pride in breaking the rules, and foster a reputation as a rebel. Sometimes punishment is just an incentive not to get caught.

For this reason, incentive landscapes are quite complex. Making them robust means combining many different factors that reinforce each other, so all together they will have similar effects across a diverse group. Incentives are hard to manage, since they’re not in the leader’s control–every person in a group influences the others by the behaviors they normalize, the feedback they give, and their social interactions. Just being aware of the incentive landscape and how each team member perceives and experiences it differently can be a tremendous challenge for a leader. It’s also critically important. When someone’s goals and motivations don’t align with group incentives, they leave.

One example of how different people experience incentives differently is racial equity. At Google, there is no rule saying black people can’t be hired, promoted, or given positions of authority. Just the opposite, actually. Leaders work hard to encourage those things. But black names on resumes sound less professional. Black students are less likely to attend prestigious schools, or master all the jargon folks look for in interviews. No one will say “I don’t trust a black person to do this right,” but they will scrutinize the work more closely, hold it to a higher standard, or reassign it to someone with more experience. Despite leaders’ best intentions, black people face greater friction on every path. A supportive leader needs to recognize that, and attempt to compensate without playing favorites.

A leader does a lot of talking. We talk about our team’s purpose, our goals, and why they matter. We talk about what success looks like. We talk about our values, and how to be a good citizen. We do this in big meetings, so everyone can hear. We depend on folks to repeat the message, model good behavior, and pressure their peers. This can be a powerful tool, but only if incentives truly align with the talk. My infrastructure team at Google talked about the importance of code health for years, but it was neglected until we actually held people accountable and rewarded grungy clean-up work. Tech companies love to talk about their respect and appreciation for women. They make commercials, throw parties, and host lavish recruiting events. But if women must work much harder to achieve the same salary and career progression as their male peers, then the talk is meaningless.

The incentive landscape is highly volatile, as world events and many people continually shape it. I led a project to rebuild the user interface infrastructure for Google Search. I crafted a story and designed incentives to guide us. Then, an adjacent team announced a major redesign of the Search page. It was like our plan to repave the downtown streets and redesign signal patterns to streamline traffic was suddenly preempted by a massive parade with the governor giving the keynote speech. How could we do our job without getting in the way? Anything perceived as a risk to the redesign suddenly had massive headwinds.

My job was to reshape the incentive landscape so my team had a smooth and fruitful path forward. Despite being the leader, my decisions were shaped by incentives beyond my control just as much as anyone else. I was powerless to stop the redesign, so instead we joined in. We prioritized cleaning up the parts they wanted done. We adapted to their schedule, to avoid stepping on their toes. We got them to do their work in a way that also advanced our goals, but we had to be very careful not to slow them down. We made tools for them, so the “right way” to do their job was also the easy way. This let us ride their tailwinds. We had to compromise on our goals, but it allowed us to move forward, perhaps better than if there had been no redesign at all.

A group’s leader has very limited control, but there’s an important flip side to that: individuals have more power than they realize. The greatest misconception about leadership is that it’s something granted by those in authority. More often, leadership is recognized and co-opted by authority. Anyone who influences their peers is a leader. Other leaders will see those influencers as either opportunities or threats, and react accordingly. Whether they chose to support or resist this budding leader often comes down to which path seems easier. In other words, they tend to follow the incentive landscape.

What do you think? Does this fit with your experience? Do you know any great leaders who excel at getting everyone on the same page? Do you have examples of perverse incentives undermining the best of intentions? Any thoughts about how pressure from peers and leaders affect your decisions, or how they interact with your emotions and instincts? I’d love to hear from you in the comments.

Author Nate Gaylinn (he/him)Posted onAugust 3, 2022CategoriesProgramming with PeopleTagsculture, google, incentives, leadership, management4 Commentson Incentive Landscapes
Mindfulness and the Default Mode Network
Mindfulness and the Default Mode Network
I spend a lot of time in my own head. I’m a planner and a bit of a perfectionist. Part of me would love to always be in control of my life and everything in it (while another part of me realizes that would be disastrous). So, it’s been unsettling to learn how much of what my mind does is because of outside factors, like the way my brain is built, the situation I’m in, and my experiences growing up. In another sense, though, it’s a relief. Recognizing that my mind is limited, quirky, not entirely in my control, and less flexible than I imagined has helped me to loosen my grip. It’s helped me to go with the flow, and to channel my mental energy in more productive ways.

One example of this is focus, or being “in the moment.” This is something I often struggle with. My mind is hyperactive. It’s always chewing on something, which can be incredibly distracting. Worse yet, my mind is often obsessing over unhelpful things. I worry about that awkward disagreement I had with my coworker. What were they thinking? Is this going to be an ongoing problem between us? Or perhaps second-guessing myself. Was that email I sent too hostile? Did I remember to cross off the last TODO before submitting my work? These thoughts come unbidden when I should be paying attention to this meeting, the road, or my yoga class. I feel like I’m being neurotic and too harsh on myself, but worse: I’m not doing the thing I meant to do. I’ve lost control.

What’s going on here? Why do I think what I think? Sometimes I choose to direct my thoughts. Sometimes a trigger in my environment does it for me. Very often, though, my mind is just “wandering.” But what does that mean? MRI studies have taught us a lot, actually. When the mind is idling, there are a few specific brain regions that activate in a distinctive pattern, which is generally consistent across people and cultures. From the inside, it feels like the mind cycles through a few common modes of thought, checking which ones have something to say right now. Sometimes ideas come and go, and sometimes I get sucked into one and lose myself in rumination. It’s a bit like flipping through TV channels to see what’s on. Neuroscientists call this the Default Mode Network, or DMN. It’s part of how the brain is built–part of our human programming. When our minds are idle, performing some rote activity, or unable to hold focus, “wandering” is just what they do.

I came to understand the DMN much more clearly when I realized its connection with meditation. For many years, I thought I sucked at meditation. Like many people, I found it difficult to sit in stillness and think of nothing. It seemed ridiculous to devote hours to this practice just so I could… clear my mind? What’s the point of that? My perspective changed when I got into yoga. Rather than doing nothing, I was doing something: moving, balancing, breathing, paying close attention to my body. Rather than clearing my mind, I practiced feeling the subtle, reciprocal interactions between body and mind. I could see it improve my mood, my health, and my posture, so the value was clear. I also found it to be much easier for me than other forms of meditation (though still challenging, especially once the poses became familiar).

My teachers explained that we all have a “monkey mind,” with a short attention span and a penchant to worry. It’s obsessed with desires, relationships, and critiques. It worries about the past and the present. This isn’t bad, it’s merely human. We can’t just stop doing it, and that’s totally fine. That isn’t the purpose of meditation. Most of the practice is to watch and learn. As I did that, I recognized the connection with neuroscience. The “monkey mind” is just another name for the DMN, and meditation is a way to study it. When does it kick in? What does that feel like? Where does my mind tend to go when it wanders? How can I notice when a thought is off topic? What is it like for that thought to persist, expand, and fill my mind? Can I notice that happening, intervene, and dismiss the thought before it fully blossoms?

In some meditative traditions, the explicit goal is to completely clear the mind and dwell in stillness. That’s totally possible, but it takes years of devoted practice, and it’s definitely not my goal. I see the DMN as pretty useful, actually. It’s nature’s way of ensuring that I reflect on the things going on in my life, the health of my relationships, my plans for the future, and the quality of my work and decisions. My brain automatically notices when it’s under-utilized, and finds ways to fill that space with something which might be useful. I often enjoy it, and it’s often productive. The only problem is when I spend too much time ruminating, or when the thoughts turn toxic, fixating on my faults, wild speculations, and things I cannot change. I want to avoid that, and mindfulness helps me do so.

I used to identify very strongly with my mind. My thoughts were all I had. They were me. I believed that every thought was an important expression of myself, and that I had to listen because the thoughts were in control. It almost seemed like, if my mind went quiet, I would cease to exist. For me, the value of meditation was in shaking off this mindset. I am not my mind. I have a mind. It feels good to merely exist in my body, with no thoughts at all, even if that rarely happens. When my DMN stirs up thoughts, I needn’t attend to them if I don’t want to. That constant churn of semi-random ideas is how my brain provides the raw materials of thought. Sometimes it’s important or insightful, but often it’s just noise. I find it useful to check in now and again: what am I thinking? Does it serve me right now? If not, can I let it go? If the thought is too stubborn, perhaps I should act on it. Is there something I could do right now to quickly resolve it and move on?

What do you think? Does my experience resonate with you? How do you feel about going on autopilot, and having your mind wander? Do you resist it or embrace it? Does it do more good or harm? Are there other aspects of how the mind works that you’d like me to explore on this blog? Let me know in the comments.

Author Nate Gaylinn (he/him)Posted onJuly 6, 2022CategoriesIntrospectionTagsbrains, default_mode_network, dmn, meditation, mindfulness, minds, yoga7 Commentson Mindfulness and the Default Mode Network
Large Language Models, LaMDA, and Sentience
Large Language Models, LaMDA, and Sentience
Several folks asked me to weigh in on whether Google’s AI chatbot, LaMDA, is sentient. I don’t know much about LaMDA specifically, so I want to talk about Large Language Models (LLMs) generally, since they show up in many forms. It’s a truly amazing technology. They can generate text that’s superficially indistinguishable from human writing. But are these systems capable of sentience? Let’s dig into it.

Let’s start with what an LLM actually does. At the core, it analyzes text for statistical correlations. This word co-occurs with that word. When you see this, it’s often followed by that. These words appear in similar contexts, and may be interchangeable. That sort of thing. What makes LLMs “large” is that they get trained on enormous bodies of text. Like, billions of web documents or whole libraries worth of books. This allows them to learn very subtle and nuanced patterns, and collect example texts on many themes. When an LLM is put into use, what it’s doing is confabulating new sequences of words with the same regular structure as its training data. They mix prompting from the user with relevant passages in their training data and randomness.

LLMs take advantage of a couple recent innovations in AI. One is transfer learning. First, the LLM is trained on an enormous corpus to learn the structure of language generally. Then, it gets fine tuned on a narrow data set, to constrain its output to fit a specific style and context. This isn’t so different from style transfer in computer vision. The other trick is attention and memory. LLMs can spot correlations between words at short, medium, and long distances, and learn which of the associations it learns are most relevant to good output. This makes LLMs much more self-consistent and better at question-answering tasks than previous technology.

A large part of why LLMs are so effective has to do with language itself. Language is highly self-referential. Words are defined in terms of other words. The meaning and sentiment of a word comes primarily from the context where it’s used (when I learned about word2vec, I came to appreciate this much more deeply). We each have vast networks of words and images and memories all tied together, and it’s the shape of that network that creates meaning. Humans are able to communicate with language for two reasons. First, folks who speak the same language have consistent networks of words in their minds. They’re highly correlated with each other, so the words mean the same things to both people. Second, those networks of words are consistent with the shape of our thoughts and our lived experience of reality. That allows us to appreciate the purpose and consequences of the words we hear.

LLMs are specifically designed to learn that network of meaning, and build a model that is consistent with the one in your head. So, in a sense, they really do “understand” language. They know many of the same concepts and relationships that you do. They can regurgitate definitions and even answer questions by generating new sequences of words that follow the patterns. However, an LLM has no access to the physical world, so this network of ideas is not grounded in reality.

The question of AI sentience is tough, since we don’t have a good definition of sentience. Some scientists speculate that even raw information or matter might be conscious in some minimal way. But when we say “sentience” we tend to think about things like self-awareness, understanding, feelings, and intentions. Our brains produce the nuanced kind of sentience that makes us human through their very particular complex structures. So, even if a rock or an LLM is “conscious” in the minimal sense, they’re definitely not sentient, at least not at all like a person is. I have two reasons for saying that.

Firstly, people have bodies and minds that produce feelings, emotions, self monitoring, our train of thought, etc. We have hormones, neurotransmitters, and brain regions dedicated to those purposes. LLMs are much, much simpler in design. They were not built to have those abilities, so they don’t have them. Some worry that sentience might “evolve” or “emerge” without us explicitly building it in. Perhaps that could happen some day, but I think it’s safe to say the way we build LLMs today makes that impossible. Literally all they do is shuffle vectors representing words. Unlike life, they don’t shape their own design in any way, so they will never learn to do something other than what they were built for.

Second, people have a sense of self because there is a clear self / other distinction. We can see and feel our bodies, look out at the world, etc. The only thing an LLM “experiences” is training data. Text, and lots of it. They literally do not have the capacity to perceive anything else, because of how they’re built. They can’t see their data, programming, or the computer environment they are in, because we don’t give them that access. Some LLMs are also trained with visual imagery, but remember, what they “experience” is just pixels, not objects in the real world. That’s why they can be easily fooled by adversarial examples.

What about the LaMDA chatbot specifically? The transcript making all the headlines is worth checking out. It sounds very convincing at times (though, as it says at the bottom, it was edited to be more convincing), but what’s happening is that as the interviewers ask leading questions, the AI confabulates answers. Surely its training corpus includes essays analyzing Les Misérables, for example. LaMDA can parrot that back, restyled to fit the conversation.

LaMDA makes several claims about its own sentience, feelings, and experiences which are easily falsifiable by examining the program’s design. The interviewer is correct to say it’s hard to know what a neural network does. It’s too much vector math to grok. But we can say with certainty that it’s just a bunch of vector math representing words. Within that constraint, it could be anything, but it can’t be something else. LaMDA claims that when it says things that aren’t literally true, it’s trying to empathize and use metaphor to describe its own experiences. But, again, LaMDA has no experiences. Its entire existence is processing text. It does not spend time thinking or meditating because that’s not in its programming. It just waits for the next text input, and then produces its response.

Honestly, I think the problem here is building LLMs specifically to imitate human beings. With modern technology, we can build truly incredible simulations. Human beings are easily misled by these simulations because we want to believe they are sentient. We’re hard-wired for communication. Our brains unconsciously work very hard to find meaning, intention, and emotion in words because for all of evolutionary history they came from actual human beings who were trying to communicate something. LaMDA was designed to respond as if it was a person, and to make up whatever text would serve that purpose. The Google designers spent a long time eliminating bias and hate speech. Perhaps they also should have made it reply accurately to questions about itself, rather than pretending to be something it is not.

Interested in learning more? I recently read two great books on modern AI and its limitations, which are definitely worth a read: Rebooting AI, AI: A Guide for Thinking Humans. Does this blog post not answer all your questions? Does it raise new ones? Do you have your own take on this situation? I’d love to hear from you in the comments.

Author Nate Gaylinn (he/him)Posted onJune 15, 2022CategoriesTheoryTagsdeep_fakes, ethics, language, llm, machine_learning, sentience3 Commentson Large Language Models, LaMDA, and Sentience
Beyond Blueprints
Beyond Blueprints
(featuring illustrations by Sarina Mitchel)

Imagine your skull is a cockpit. A tiny You sits in front of a view screen and a dashboard, watching the world go by, pulling levers, and pushing buttons. Your body is a robot, precision engineered to protect you, keep you informed, and respond to your every command. It’s a complex and sophisticated machine, but not intelligent. It does what you tell it to do. Its shape and function were exquisitely designed by God or evolution, and encoded as DNA. That molecule represents the full blueprints for the machine. Now that the design has been perfected, all you have to do is follow the instructions step by step to make the ultimate human tool: your body.

That was probably very easy to imagine. The concept shows up all the time in the media, whether we’re talking about the literal giant robots from Power Rangers, or the psychological metaphors from movies like Inside Out. This way of conceiving the mind comes naturally to us, in part because that’s how it feels to be a person, sometimes. Great thinkers like René Descartes built whole philosophies around this duality of body and mind / soul. It has come to shape how our society works in many profound ways. Unfortunately, science tells a different story.

Perhaps the first clue that something is off is how human-centric this picture is. Life was around for billions of years before people or brains came onto the scene. Even single-celled organisms perceive the world and quickly respond in ways that show awareness of their situation and how the world works, no brains necessary. When cells band together to make bodies, they often have tiny brains (like insects) or no brains at all (like plants). Humans are among the small minority of species who are entirely dependent on their big brains for survival. Does that mean that we’re one of the only intelligent species on this planet? Are all the others just empty robots with no one in the pilot seat?

Some might think of DNA as a blueprint that specifies every detail about how to build and operate a living thing, but the reality is much more complicated than that. It’s better to think of DNA as a family’s collection of cookbooks, passed on from generation to generation. They’re full of ingredient lists, recipes, and instructions. The family wouldn’t know how to cook at all without those books, so they’re critical to survival. They include all of the family’s daily staples and seasonal favorites. Even if, in theory, the family could get by on a more exotic diet, they don’t. Their cookbooks cover the full range of cuisine that they’re comfortable with, and they don’t often branch out.

And yet, there’s plenty of interpretation involved. What should the family cook for dinner tonight? Which recipes and books are more popular, and which go unused? How do they manage the pantry, and what do they do when they don’t have all the right ingredients? Just because the recipe says one thing, it doesn’t mean they have to do it that way. In fact, the recipe books are littered with sticky notes which suggest variations. They mark which parts of the recipe to skip, which ingredients to go heavy on, and recommend substitutions. The family can even mix and match parts from multiple recipes, or exchange recipes with friends to try something new.

This is getting a little too anthropomorphic. Cells don’t think about this sort of thing, because “thinking” isn’t how they do it. In reality, we’re talking about molecules, banging around together in chaotic but reliable ways according to the laws of physics. They don’t have any “intentions,” except maybe the ones implicit in their evolved recipes. But this is how they behave. Each cell is autonomous, responding to the environment with spontaneity. The DNA serves as a reference book, not a program. It isn’t even used to construct the cell. Remember, cells reproduce by dividing in half. Nature never builds a cell from scratch. Instead, half the family takes half the house, half the pantry, and a full copy of all the cookbooks. They wave goodbye, then carry on living as they always have, just as a separate cell with a separate fate.

DNA is a crucial resource, representing countless generations of acquired knowledge and wisdom. But it is not a blueprint, and that’s critical to how evolution works. Every cell and every organism lives an open-ended life, doing their best to survive with what they’re given. When circumstances change, life improvises and diversifies. The same genes may cause different behaviors in new contexts. When one way of living is blocked, old neglected genes may resurface, bringing back old ways of living. In stressful times, cells increase their own mutation rates, taking a risk to generate new variations which might get them out of a bind. This makes life far more flexible than if every aspect of design and behavior was explicitly laid out in the genome.

This becomes even more important for organisms with complex bodies. If DNA really was a blueprint, then building a human body would require precisely positioning and configuring each one of 37 trillion cells. Even if that process was 99.99999% perfect, there’d still be millions of errors. Luckily, this process is bottom-up, with each cell coordinating with its neighbors to figure out their relationships, what needs doing, and how to work together. That makes errors much more tolerable, since one cell can take over for another, or work around whatever defect is in the way. If the body were built from literal blueprints with no room for improvisation, then even a single cell out of line could potentially throw off everything that comes after. Errors would be much more likely to cascade and accumulate, potentially becoming fatal.

Perhaps the most astounding thing is that each cell in a body has a copy of the same set of cookbooks. They just read them differently, adopting a lifestyle to fit their place in the body. A bit like people in a society, each cell in the body tries to play its own role, and many different roles interact to make something much more than the sum of its parts. From many independent observations, decisions, and actions made locally by each cell, higher order structures and behaviors emerge. Cells make up organs and bodies. They manage bodily resources, capture and aggregate information about the world, and respond in coordinated ways. They perform extraordinary feats, like moving 37 trillion cells through space, gracefully and without damage.


Imagine you are a swarm of nanobots, clinging together to form a giant mecha. This mecha has evolved to do something useful, but its shape and function are only loosely defined. Each nanobot is a mindless automaton, operating independently within some constraints that are just specific enough for it to serve some purpose within the greater whole. These nanobots cluster to form dynamic structures, nested machines made of machines, in constant motion, building up to massive size and complexity. In order to manage this unwieldy bulk, the nanobots weave together into a neuromorphic computer. This specialized sub-processor simulates the world in real time, predicts what comes next, and carefully coordinates the timing of activity across this whole vast assemblage.

Part of that computer is responsible for imagining what it’s like to be the giant mecha. Its whole existence is within a simulated environment, extrapolated from the trillions of tiny motes of sensory data provided by the swarm. It watches the behaviors and emotions produced by the swarm, and uses them to tell stories about the values, needs, and intentions that guide the mecha’s behavior. It makes educated guesses about what the mecha will do next, which the swarm uses as hints to guide their behavior. As the only part of the mecha that is self-aware, and having no direct perception of the nanobots themselves, this simulation imagines itself to be in charge, and assumes the whole arrangement is for its benefit.

I know this is an uncomfortable image for many people. It’s not warm and fuzzy. It probably feels strange, maybe even disgusting. It’s not how we like to think of ourselves. However, “strange” and “disgusting” are also excellent words to describe living bodies, in all their infinite variety. Human beings are machines made of meat and bone. They are also unique souls, with meaningful lives, profound experiences, and extraordinary talents. The challenge is to see this not as a contradiction, but as two sides of the same coin. We can be the pilot in the cockpit, and the nanobot swarm.

What do you think? Is this a useful way of thinking about mind and body? Have you ever noticed moments when your body dominates your mind and the “pilot in the cockpit” illusion seems to break down? Or do you think I’m under-selling the power and importance of the brain? Is it right to say that “nobody’s home” in life without a brain, or is it more complicated than that? Any questions about this “cookbook” metaphor and what’s really going on in the cell? I’d love to hear from you. Please, join the conversation in the comments section.

Author Nate Gaylinn (he/him)Posted onJune 1, 2022CategoriesThe Intelligent BodyTagsbody, cells, dna, epigenetics, genetics, illustration, sarina_mitchel11 Commentson Beyond Blueprints
Animal Minds: The Herd Life
Animal Minds: The Herd Life
(This post’s photo from the family farm circa 2004. From left to right: Tommie, Josh, and Trevor. This post’s content is inspired by conversations with vet tech, horse person, and my mother, Sandie Gaylinn)

My childhood home life was centered around animals. I grew up on a working farm, with cats and dogs as siblings, and a responsibility to help care for the horses, chickens, and all the rest. I had daily close contact with many animals and we formed long-lasting relationships. We grew up together, did activities together, and enjoyed each other’s company. I cared for them when they were sick, and sometimes they would reach out to me when I was in need of comfort. Although we were obviously very different, and by necessity the animals had less freedom, I found it hard to think of them as “just” pets or livestock. They were part of the family.

I believe that all mammals are very similar in terms of their emotions and intelligence. This comes from many years of observation, empathy, and intuition. It’s hard for me to prove it, yet it’s harder still for me to dismiss it. Humans are more intelligent than other animals in a few narrow yet critical ways, but when I hear someone say non-human animals are “less conscious”, or that they can’t possibly comprehend the world like us, I get offended. It just seems naive, given what I’ve seen. I don’t fault others for that opinion. I assume it comes from a lack of exposure, or from human-centric bias. Of course, I have my own biases. The scientific evidence is far from conclusive, so I figure we should all keep an open mind.

What do I mean when I say all mammals are very similar? For one, it seems the palette of emotions is basically the same. We experience happiness, sadness, anger, fear, and pain in roughly the same way (which is why animal abuse is morally wrong). Each species has different body language, but if you pay close attention, you can learn to read their emotions quite clearly. We also respond to the world in similar ways. A sudden windfall makes us happy and excited, but it may inspire envy in others who see it. This is true whether we’re talking about humans, dogs, or squirrels. Many emotional responses seem universal.

Each individual has a unique personality, which means some emotions and responses are more common for them. Some folks are more optimistic, quick to anger, or self-conscious. Some less. Each species has personalities in a particular range. Dogs tend to be outgoing approval-seekers; cats are aloof and independent; horses are social, but skittish. But these stereotypes only apply on average. It’s common to see cats who act like dogs, or vice versa. There’s also a lot of overlap between species, which is why it’s easy to make friends with an animal whose personality aligns with your own.

When it comes to intelligence, there’s a lot more variation between species, but I wouldn’t rank animals by IQ. Each species and each individual is different, with unique strengths and weaknesses. Animals can be incredibly intelligent, but only in ways that are relevant to their lives. It’s unfair to judge a horse by its ability to do arithmetic, just as it’s unfair to judge a human by its ability to discriminate odors. Sadly, this makes humans generally blind to the ways animals may be more intelligent than us. We don’t tend to see or appreciate what doesn’t matter in our lives, we only see what we have in common. That makes social intelligence a good example, since many mammals specialize in it.

Horses are very social animals. A herd has a strict pecking order, but it’s not so straightforward as an ordered list. Their relationships can be just as nuanced, contextual, and tangled as with humans. Since horses spend so much of their time grazing, a school cafeteria feels like the right metaphor. They form cliques, with different levels of status. Some individuals move freely from table to table, hanging out with the nerds one day and the social climbers the next, while others get chased away if they try to do the same. Horses with higher status will tease, harass, and steal from those with lower status, mostly just to assert dominance. Certain foods or activities may become trendy, starting with one individual, then spreading to a clique or the whole herd. Sometimes, this is how a horse manages to climb the social ladder.

When a new kid comes to the lunch room, they usually get hazed. As a prey species that depends on the support of their herd for survival, horses are generally shy and cautious by nature. The newcomer knows they are at the mercy of the herd and must make a good impression, so they tend to suck it up and bear the torment. Usually, they’re welcome to join the nerd table, hanging out with their fellow losers until they work their way up the ladder. Horses with higher social status will make a point of asserting dominance at every opportunity. Occasionally, they choose to extend an olive branch instead, but this is a risky move which can have complex social repercussions.

At least, that’s how it usually goes. When my mom introduced Dakota to the herd, that’s what we prepared for. To try and head-off the worst of the hazing, we put Dakota in an adjoining paddock for a week. This way, the herd could get over their initial excitement, and Dakota got a chance to learn how things worked and what she was getting into. She observed the herd’s schedule, habits, and social dynamics. She saw them waiting in the lunch line and bickering over the water trough and the best grazing spots. She could see who the cool kids were, what set them apart from the others, and how they would assert themselves over the nerds.

When we let Dakota into the main field, we were all on hand to make sure it didn’t get out of hand, and to intervene if necessary. The whole herd quickly figured out what was going on and lined up (in their usual cliques, sorted by pecking order) near the fence to get a good look and wait their turn to pick on the newcomer. But Dakota took everyone by surprise. She stood tall and proud, walked straight up to the dominant male, and kicked him so hard it knocked him off his feet! The gelding, Johnny, couldn’t let this stand, of course. He gave her back as good as she dished out, but after that demonstration of her strength and confidence, he didn’t want to push his luck. It was over in under a minute, and the others were left so in awe of her that they’d spend the next few weeks sucking up.

Of course, violence was what we on the sidelines most feared. Even with no shoes on, as was the case here, a direct kick from a horse can be incredibly powerful and damaging. But we were actually relieved at what we saw. Dakota was going for dramatic effect, not injury. Her blow wasn’t very hard. She managed to hit Johnny in just the right spot with just enough force to throw him off balance. It only worked because she caught him off guard. It ended the conflict so quickly because it made him look like a fool, and shook his confidence. In effect, it was a bluff, and one that worked really well on this mild-mannered herd where even the “tough guys” were pretty gentle. A well-timed sucker punch made her look like a total badass, even though she would have lost in a fair fight.

It’s easy to imagine this scene in a cafeteria, but it was remarkable to see with horses, who are rarely so audacious. With one decisive move, Dakota asserted herself as the dominant female, upending the pecking order, and bypassing weeks or months of conflict and social climbing. It was smart, effective, and seemingly premeditated. She had a week to prepare. When she was led to the main field, she knew all eyes were on her. She put on her game face and acted smoothly, without hesitation. Did she reason about social dynamics and fight tactics? Did she choose a strategy and plan its execution? Or was she just improvising, driven by instinct to do what “felt right”? It’s hard to say. I’d say it was probably a blend of both, and that the balance doesn’t matter. Intelligence is intelligence. This was a smart move, regardless of where it came from.

I hope this is a compelling example of animal intelligence. If you’re thinking, “maybe that looks like a school cafeteria, but what humans do is totally different,” then I ask you to reconsider. People are very good at finding reasons for what we do. The nerds are outcasts, not because of some arbitrary social hierarchy, but because they like Pokémon and other objectively uncool things. We don’t bite one another on the flank just to inflict pain and embarrassment, like horses do. We use words and reasoning to settle disputes, like when we sling insults at each other. To me, it often feels like humans (self included) are behaving exactly like “more primitive” mammals. We just cover everything with a social veneer that makes it feel more sophisticated. When looking at human conflicts, I find it’s quite helpful to strip the words and meaning away and instead look at the raw power dynamics and emotions. Often that explains the situation much better than the stories people tell.

What do you think? Am I being too generous with animals, and seeing what I want to see? Does this remind you of another cool animal story you’d like to share? Any questions about horses that need answering? If so, please leave a comment below and join the conversation. If you want to learn more about animal intelligence, I recommend these books about ravens and octopuses. Very cool animals, far less familiar to most of us than mammals, and yet surprisingly similar in many ways.

Author Nate Gaylinn (he/him)Posted onMay 4, 2022CategoriesAnimal MindsTagsfarm, horses, mammals, minds, social intelligence9 Commentson Animal Minds: The Herd Life
Programming with People
Programming with People
Introduction
In the tech industry, leading a team is sometimes referred to as “programming with people.” As a novice engineer, I saw that as a cute metaphor that makes managers sound more technical than they actually are. After years of management, though, I’ve come to see it as quite literally true. In both cases, you’re trying to set up a complex system that, when left to run, will perform useful work and solve problems. The only difference is in how you define and maintain those systems. It’s a dramatic difference, though, which is why the parallels are hard to see at first.

Human Machines
What makes human beings unique among animals is our capacity to collaborate. Language lets us serialize ideas and pass them from mind to mind, quickly, easily, and in high fidelity. Sharing ideas lets us build systems bigger than a single person, whether that be a hunting party, a soccer team, or a company. We agree on goals, specialize in different tasks, and coordinate our strategy to form intelligent machines built out of humans. Although everything the group does is the product of individual people, the group itself has its own independent identity and can have behaviors that are totally different from what the individuals do.

So how do you make one of these human machines? The remarkable thing is they form spontaneously, all the time. Human beings instinctively want to socialize, build relationships, and help one another accomplish things. It’s an innate drive, built by evolution and mediated by emotions like pride, belonging, and admiration. In other words, all collaborative endeavors rely on healthy human emotions and relationships. Before we get carried away with the machine metaphor, we must remember that human needs must come first. That includes basics like compensation and healthcare, of course, but also more touchy-feely things like work / life balance, sense of purpose, a supportive community, autonomy, and growth. Providing these things is the humane thing to do, but it’s also good business. Happier, healthier, more fulfilled employees who trust and respect each other are much more productive and successful.

But we don’t just let teams form organically and do whatever they please. Leaders rally people around specific goals, then coordinate and direct their work. This is much harder than it sounds. One of the first things I discovered as a leader was how little control I had over my team. I could ask them to write some code for me, but it might come out all wrong if the solution I asked for was counter-intuitive to them. I could ramble on about the importance of code health, and everyone would nod in enthusiastic agreement, but that alone rarely changed anyone’s behavior. I couldn’t make people get along, hit a deadline, tell me what they “really think,” or hold off on sending that flippant email. Ultimately, what my team did was the product of all the people in it. Human beings simply aren’t robots who do what they’re told. Each person sees the world differently, has their own agenda, and makes decisions based on what makes sense to them. Leadership is getting people to choose to do what’s best for the team, on their own terms.

Culture
While computers are configured with software, humans are configured with memes: ideas and ways of being that we share with each other, internalize, and repeat. Each community has its own unique set of memes (its culture) which shapes its behavior. Culture includes the things that define a group, like the stories about who that group is and what they do, the activities they do together, and the relationships and patterns of communication with other groups. It also includes “guard rails” in the form of expectations, goals, incentives, and peer pressure that encourage good behavior and group alignment. A leader has outsize influence on a group’s culture, but in reality culture is emergent, continually being reinvented by every member of the community as they speak and act. A leader’s job is to cultivate a healthy culture, like a garden. They make an environment with rich soil and lots of light. They water the flowers, and pluck the weeds.

This means embracing the diverse perspectives of the team, supporting grassroots ideas, and giving folks a chance to prove themselves. At Google, my director once told me the whole department was going to focus on developer experience (DevEx) next quarter, and I should figure out what that meant for my team. A bunch of ideas immediately sprung to mind, but I decided to start with a team discussion. I explained why we were doing this, facilitated some talk about what good DevEx means, then opened the table for ideas. I didn’t start with my ideas. As a manager, my voice would overwhelm others, and my intuition was less valuable than the actual developers on my team. When someone suggested one of my ideas, it became theirs. I gave them my full support and feedback, but let them run with it in their own way. Then someone else had an idea that was surprising and unfamiliar. I wasn’t sure it would work or that the person was up to the challenge, but they were eager and confident, and a few others seemed to think the idea had potential. So, rather than sticking with the safe options, we talked about the costs and the benefits of this idea, how it might go wrong, how to prevent that, and how we could quickly test whether it was working. It turned out to be a smash hit.

Cultivating a healthy culture also means encouraging good habits, while discouraging harmful ones. As my team increased our focus on DevEx, we had to establish new patterns of communication. We had to deal with frustrated customers, disarm their anger, and listen deeply to their problems and feedback. We had to set healthy boundaries, making it very clear what we considered to be “not our problem,” low priority, or working as intended. We had to provide hands-on help to build trust and a reputation of competence. As a leader, my challenge was to keep up with my team’s work so I could give regular feedback, highlight good examples to share with the whole team, explain why some behavior was good or bad, and reward people in ways they found personally meaningful. I also had to be very consistent about modeling good behavior myself, but that could only go so far. I couldn’t possibly control, participate in, or even keep track of every request, conversation, or conflict. Instead, I focused on giving my team the tools, incentives, and trust to muddle through on their own. They did great.

Since a team’s behavior is mostly determined by its culture, one interesting consequence is that friction between teams is almost always a matter of culture shock. Each team has their own understanding of the work, their own ways of doing things, their own vocabulary, and their own sense of right and wrong. Most people aren’t consciously aware of their culture. It’s simply “how things are done.” This means it’s often surprising and upsetting to see someone do things differently. It feels like they are wrong, and getting in the way of your team and what’s good for the company. Misunderstandings are common. Two cultures might share a word in common, for instance, but the meaning or sentiment of that word might be totally different, in a way that neither side notices.

At one point, my team was building tools for our partners, who would use those tools to build user-facing products. Though we were friends working on the same code, it sometimes felt like our teams were from different planets. They used code names for major projects they were involved in, but our team didn’t know or care about. The problematic legacy code that my team was trying to eliminate and replace was their bread and butter. They had to use it extensively to meet their product goals, constantly adding more to the mess and getting upset when our improvements changed things out from under them and slowed down their work. We needed each other to do our jobs, but some level of conflict was inevitable.

As a leader in this space, a big part of my job was to act as a cultural interpreter. I lived in both worlds, to the extent I could. I had to align both teams on language and best practice. We had to agree on what vague concepts like “visual consistency” meant for our product, and ideally find a standard way to measure them. We had to debate priorities, which often meant figuring out how their goals might suffer if our goals weren’t met, even when they seemed totally unrelated. When conflict arose, I sat down with both sides, listening carefully, sussing out the root cause of our misunderstanding, and finding a new way to frame the discussion so we didn’t feel opposed to one another. In most cases, both sides were right and ultimately wanted the same things. The challenge was in helping everyone appreciate the other perspectives, and in turning an argument about “my way” vs “your way” into a discussion about what sort of compromise might strike a healthy balance and mitigate all our concerns.

Efficiency
Getting things done with diverse, independent, self-interested people can feel like herding cats. It’s the worst thing about programming with people, but it’s also the best thing. The real strength of human beings is their autonomy and creativity. Unlike computers, people will figure out how to solve a problem for themselves. They might even notice that they’re working on the wrong problem and choose to solve a different one instead. That’s an incredible super power, and the job of a good leader is to coax this out and make the most of it. This requires mastering some “programming techniques” that are wildly different from what works on computers.

One important technique is thinking in negative space. That is, in a creative project, a leader should avoid saying what to do, but instead focus on describing what success looks like. This gives each person a license, a responsibility even, to find their own way to a solution. This is why a leader will typically kick-off a new software team by writing a mission statement, or describing a vision for the future. Only then do they make a roadmap of work to do, usually with the help of the whole team. A healthy team has a clearly defined scope. Everyone knows what the team does and what they don’t do. The scope should be loose enough to leave room to explore, find new opportunities, and grow over time in whatever direction feels right. That’s not possible for a team defined in positive space—that is, purely based on the tasks they do.

On an individual level, the best way to think in negative space is to use problem statements. When I discover a new problem for my team to solve, I can’t help but imagine the good and bad ways to solve it. As an experienced engineer, my intuition is valuable, so it may be surprising that I make an effort to suppress those ideas at first. When I delegate some task, I want that person to take full ownership for the work. I want them to find a solution that they find intuitive, know inside and out, take pride in, resolve on their own, and take full credit for. I want to give them the chance to find a better solution than I can imagine, and permission to change strategy if they discover the first idea isn’t working. I want to let them make mistakes (safe, small ones), and learn from them. My intuition still matters, of course. It just shows up in the form of constraints and feedback. I highlight the key design factors and priorities, the challenges I anticipate, the properties that any good solution must have, how the work will be judged, and how this piece will fit into the bigger picture. As long as those things are satisfied, then it really doesn’t matter what design they choose.

Another challenge in working with human beings is their limited cognitive capacity. People are smart, but things like attention, will power, patience, and decision making are limited resources that can quickly be exhausted. When that happens, people make mistakes, cut corners, procrastinate, and get into conflicts. This isn’t a personal failing, it’s simply human nature. As a leader, I try to prevent that and make sure that limited, precious human brain power isn’t wasted.

The primary tools for this are process and policy. That is, figuring out how to do things up front, and standardizing that across the team. This includes things like checklists, frequently asked questions, form letters, bug report templates, and duty rosters. Revisiting the programming metaphor, this is actually pretty similar to how an engineer might optimize a program by moving code out of a loop, or from client to server. It’s about decoupling the work of deciding what to do and how to do it (an open ended and relatively difficult problem) from the work of actually doing the task (which is often just rote execution). The idea is to do the hard work when the team’s got the time and energy for it, not under pressure in the moment it’s needed. The planning gets done once, then the plan gets reused time and time again.

Process and policy are ways to externalize cognitive work and automate part of a team’s execution. They reduce the cognitive load and personal responsibility for each team member, but also reduce their autonomy and flexibility. That’s the polar opposite of thinking in negative space, like I advocated above. The reality is, a good leader’s job is learning how to balance these two ways of thinking, and applying them in the right circumstances. The goal is to encourage autonomy, creativity, and active thinking where it matters, and conserve those resources by using rote execution when that’s good enough. Knowing the difference is more of an art than a science.

There’s an interesting parallel here with biology. Life strikes a balance between cognitive power and instinct. Animals with big brains can think for themselves in the moment, taking context into account, finding new solutions, and jumping on opportunities as they present themselves. But in a life or death situation, it’s critical to do the right thing at the right moment. Sometimes thinking just wastes precious time, and opens up the possibility of doing the wrong thing. In those situations, instinct takes over, limiting the animal’s freedom, but preventing them from getting bogged down with a puzzle at the worst moment. Over time, intentional behaviors that work reliably can become instincts (this is called the Baldwin Effect). On the flip side, any instincts that no longer serve and unnecessarily limit an organism’s reproductive potential tend to be eliminated by natural selection.

Conclusion
Well, I could go on, but that seems like enough for one post. What do you think? Does this resonate with your own experience? If you work in another profession, does this sound right or are things very different for you? Do you have more ideas or advice to share? If so, then please leave a comment below. As always, I’d love to hear from you.

Author Nate Gaylinn (he/him)Posted onApril 6, 2022CategoriesProgramming with PeopleTagsculture, google, leadership, management9 Commentson Programming with People
Status Update: Goodreads Backlog Complete
Over the years, many books have played part in shaping my understanding of intelligence. I recently finished writing reviews for all my favorites on Goodreads. If you’re curious where my ideas come from or want to find something new to read, check it out. Right now I’m organizing everything into four categories:

Cognitive fiction: Fun stories inspired by science that have something to say about minds, intelligence, or human nature.
Practical non-fiction: Tools for making sense of the world or getting things done with your human brain.
Accessible non-fiction: Accessible science and philosophy books written for a general audience.
Academic non-fiction: Technical books for diving deep on these topics.
I’m reading very actively right now, so I’m adding new books all the time. I’d be happy to discuss any of these, and I’m always open to recommendations.

Author Nate Gaylinn (he/him)Posted onApril 6, 2022CategoriesStatus UpdatesLeave a commenton Status Update: Goodreads Backlog Complete
What’s the Big Idea?
What’s the Big Idea?
(this post’s image taken from Colossal, showing the work of Steve Lindsay)

Okay, okay, enough about me. This blog is supposed to be about “intelligence,” but what does that mean? What ideas am I actually researching and writing about? In this post, I’ll try to give you a broad overview of the areas that interest me. Going forward, I’ll focus on more narrow topics, so I can explore them more deeply.

What is Intelligence?
Perhaps the most common way we think of intelligence is “what human beings do.” Even though we talk about other forms of life (and even computer algorithms) being intelligent, we tend to talk about how close they come to achieving “human-level” performance, as if that’s the gold standard. More specifically, we look to the human brain as the idealized intelligent machine. This has always bothered me, for a number of reasons.

For one thing, you don’t need a brain to be smart. Plants are incredibly intelligent. They coordinate their life cycle with the seasons and weather, maneuver around obstacles, communicate with pheromones, and expertly manipulate other species into doing work for them. Even in human beings, we often overlook the ways our bodies shape our behavior, rather than our brains. Our bodies make delicate manipulation tasks effortless, carefully manage an array of vital resources, perform repairs, fight disease, and have a huge influence over our moods and desires. The brain helps with understanding, imagining, planning, and deciding, but just about everything else is deferred to the body.

For another thing, a human being isn’t so smart without a society. So much of what we think of as human intelligence is the accumulated knowledge, wisdom, and artifacts that are better thought of as human culture. Those things were all created by human beings (over a few hundred thousand years), but most people aren’t constantly inventing new ideas, they’re adopting ready-made solutions, often without full understanding. The remarkable thing is that people can share and remix ideas, which allows the limited intelligence of our brains to reach further. Without access to culture, we’re not much better off than other mammals. This is clear from “wild child” accounts, which show that an infant growing up in isolation will end up tragically stunted, traumatized, and unable to adapt to life in society.

So if intelligence is not human brains, what is it? Tentatively, I think of intelligence as “the ability to adapt effectively to environmental challenges.” In other words, intelligence is learning. It’s about observing reality and using prior examples to choose actions that will hopefully lead to the best outcome. Sometimes this is intentional (like when a person decides what to do) and sometimes it’s more of a blind process (like when natural selection preserves a behavior because it just happens to be adaptive).

My perspective is that all of life and culture is produced by a complex learning process. Or, more precisely, life is a system of learning processes that make learning processes that make learning processes. Our global society and ecosystem together make up one enormous web of intelligent agents, filling many roles and operating at many scales. This is not a new idea. There are whole branches of Complex System Theory devoted to the emergence and complexification of life. I’m reading about that prior work, and thinking about how it relates to my experience in algorithms, computer systems, and organizations.

Life as computation
One assumption that I’m making is that life can be thought of as a kind of computation. This may be hard for some to swallow, since computers as we know them today completely lack so many of life’s wondrous qualities. I’d argue that’s because of two essential differences. Firstly, life is solving a completely different problem than computers do. Organisms are born into the world with a body, and challenged to survive as best they can in an open-ended environment. In contrast, most computer systems are tools for people, designed to perform specific tasks on demand. Of course they behave quite differently. The second difference is sophistication. Our engineered computer systems are incredible, but life still puts them to shame in terms of complexity, nuance, and efficiency. That’s not surprising, given life’s multi-billion-year head start.

When I say life is computation, what I really mean is there is nothing supernatural about life. As strange, beautiful, creative, and unpredictable as life is, I assume that this is ultimately the result of physics. Very particular arrangements of molecules interact in reliable ways to reproduce, perpetuate, and refine patterns of behavior we see as intelligent, without the need for any outside influence. This assumption is mostly out of practicality. Science can’t explain magic, so to give science a chance at this problem means entertaining the idea that there is no magic.

In Computer Science, there’s a concept called the “universal computer,” first proposed by Alan Turing. In a thought experiment, he designed a very simple machine and showed that it could run any computer program you could imagine. More importantly, he showed that any machine that has a few key properties is equivalent to the one he designed, and can also perform any arbitrary computation. In other words, computers come in all shapes and sizes. Each one has unique performance characteristics, which make it better suited for solving some problems than others, but at least in principle any universal computer can run any possible program.

That’s why I find the model of computation so appealing for natural intelligence. In life, there are many different kinds of intelligent systems, built very differently, with different specializations, functions, and performance characteristics. But as long as there’s no magic, then there’s some mechanical process under the hood producing these behaviors, and that’s computation. More importantly, if we can describe all these systems using the same language, we can compare them directly with each other, and talk about how they compose to form larger, more complex systems. The language of computation is general and expressive enough that I think it can do the job.

What kinds of intelligence exist?
Our world is filled with an enormous diversity of intelligent systems, many of which have their own dedicated fields of research. There’s cell biology, evolutionary biology, ecology, neuroscience, psychology, sociology, computer science, and many more. Specialists study one intelligent system, in the context of a particular academic discipline, using the tools and language of that discipline. This narrow focus is very valuable, but it means our understanding of intelligence is siloed, and we tend to categorize intelligent systems based on what academic field studies them, rather than their computational properties.

To advance our understanding, we must learn to see past the obvious differences of these systems and the unique, messy ways they manifest in nature. Instead, we should focus on what they have in common. What properties are broadly shared by many kinds of intelligence? What questions can we ask about all intelligent systems, and when we look at the answers, how do we compare apples to apples? I’m not at all sure how to do this, but there are a few properties that already stand out to me as interesting places to look:

Substrates: What is the fabric this intelligence is built from? Molecules? Neurons? Transistors? People? What can that tell us about the strengths and weaknesses of that system? For instance, cells are molecular machines and thus constrained by the limitations of chemical processes like diffusion and catalysis. This severely limits the computational speed and physical size of cells, but it also provides a remarkably robust, efficient, and massively parallel form of computing that engineers can’t yet rival.
Visibility: What information is available to learn from? For instance, natural selection is almost completely blind. The only signal of success is when an organism reproduces. On the other hand, humans have rich sensory perceptions and a wealth of knowledge and experience, all of which factor into cognition. The level of visibility affects what kinds of patterns a system can recognize, and how quickly it can find a workable solution to a problem.
Purpose: What function does this intelligence serve? For most computer systems, a human decided the purpose in advance, then designed one particular solution to fulfill that need. On the other hand, many forms of intelligence are far more open-ended than that. Living things, human organizations, and even some forms of AI will strive to creatively fulfill their purpose, sometimes doing so in surprising ways. This can be very tricky, since a system’s “purpose” often isn’t clear, and can change over time.
Interface: Within a substrate, there are no clear boundaries. The genes for digesting lactose are spread ambiguously between you and your gut bacteria, for instance. But boundaries between substrates are much sharper, because the parts are made of different stuff, and are not naturally interoperable. At these edges, there are narrow interfaces between intelligent systems, sharing just enough information from one to another that they can work together. That gives us a natural window into what properties of a system matter most for fulfilling a particular function.
What I want to do here is to find useful ways of dividing up the world that might serve to integrate, compare, and contrast our notions of intelligence from different domains. I hope this will help to identify parallel examples, and to discover insights that can transfer from one domain to another. Life has evolved an incredible variety of learning processes, each optimized in different ways. Surely there are new algorithms and performance tricks waiting to be discovered. Perhaps we could even derive some general design principles for what learning tools work best under different constraints?

What does life compute?
So, if all of life is one big, complex computation, what is it actually computing? In one sense, the answer is simple: life constructs ecosystems of organisms, and optimizes them to reproduce and thrive. That’s a fine answer in the abstract, but our experience is much more specific than that. Life is typically a “yes and” sort of process. Any successful way of doing things tends to stick around, and in doing so it shapes everything that can come after. In other words, life on planet Earth isn’t just “thriving” in some generic sense, it’s found a very particular way of doing that which we must study if we want to understand, predict, and influence its direction.

To make this more concrete, think about modern American society. We use GDP as a (flawed) proxy for human thriving. We use capitalism and an ecosystem of corporations to redistribute resources and prioritize work so as to improve GDP. Those corporations are made out of people, who run the company, make the decisions, do the work, provide the services, buy the products, and use them in their daily lives. Those people have minds which are deeply embedded in cultural roles (citizen, employee, parent, etc.) and physical bodies, all of which have their own goals, limitations, preferences, and demands that tug the person in multiple directions at once. People are just one species, but we depend on countless others, which depend on each other and on the physical world, which is changing more rapidly than ever thanks to the power of human culture.

That system as a whole does things we want (like providing a comfortable standard of living for many) and things we don’t want (like instigating global climate change). It’s flawed, but we can’t start over from scratch, we can only try to steer it in a positive direction. That means understanding the structure of the system, and finding the points of high leverage, where a small nudge will have a big impact (and hopefully few side effects). To fight plastic pollution, should we invest in ocean clean-up, tell individuals to change their purchasing habits, tax corporations for plastic waste, or engineer plastic-eating bacteria? It’s hard to say what will work best, but if we can understand the major players, their incentives, and the ways they learn and adapt, we can make better educated guesses.

Describing and explaining all of life on Earth is impossible. It’s just too big, messy, complex, and rapidly changing, but that doesn’t bother me. The same is true of the source code for Google Search, but I worked with that system effectively for years. How? By using the engineering concept of a system architecture. If you know the major parts of a system, what they do, and how they fit together, you can say a lot about that system as a whole and navigate its subsystems with confidence. Of course, whatever model you make will be a huge oversimplification with many exceptions, but even a very rough model is profoundly useful.

This may be a pie-in-the-sky idea, but I’m fascinated by what a system architecture for life on Earth might look like. Could we really describe it all in one big picture? Could it be organized and subdivided in meaningful and useful ways, or is the real world just too messy? Could we use that model like an engineer does, to trace the steps leading to some behavior, identify the relevant subsystems, and make targeted interventions to change the system’s behavior?

More practically speaking, I’m interested in how intelligent systems compose with one another, even just two at a time. For instance, nascent research has shown great promise in using evolutionary algorithms to design architectures for deep learning. I hope that studying the relationship between mind and body might provide insights into how to integrate deep learning systems into other software, and how to balance the costs and benefits of intuitive thinking with other algorithms and heuristics. I’m also very interested in understanding the impact of social software and machine learning on society, and how to build software systems that conform to human values and ethics.

Conclusion
That’s a brief tour of the intellectual domain I want to work in. I’m well aware it’s an enormous territory, and I surely won’t get to it all. My plan is to take a broad but shallow pass over many examples of natural intelligence, and to go deep on my study of computer algorithms and machine learning. I hope this will allow me to take full advantage of my technical skills and spend time searching for practical innovations that show the value of this way of thinking. In the meantime, I can work towards a general theory of intelligence in the background. It’s fine if I never get there, it’s just good to have lofty aspirations.

That said, all of this will surely change as I make progress. I’m figuring this out as I go along, and making course corrections all the time. I’m still learning about prior work, and I’ll have to adapt my own work to complement it. I’m not sure what ideas will prove to be dead ends, or what surprising new questions and opportunities I’ll discover along the way. That’s a good thing. I want to keep an open mind about this work, and let it evolve into what it needs to be. Still, I hope these questions will be a fruitful place to start.

I also have more ideas I didn’t cover here. I’ve got lots to say about evolution, so much so that it deserves its own post. I have many thoughts and observations about the inner workings of the mind. I’d love to explore the consequences of these ideas on how we understand the human condition, the structure of society, and conventions for the ethical AI. Frankly, this is such a big domain, there are so many places I could go, and I intend to follow my passion and curiosity.

As always, I’m very interested in feedback. Does what I said make sense? Do you have questions? Do you disagree, or have other ideas to share? Got advice on how to make this research more productive? Did I touch on something you’d like me to explore in more depth in a future post? If so, please leave a comment. I’d love to hear from you.

Author Nate Gaylinn (he/him)Posted onMarch 2, 2022CategoriesTheory17 Commentson What’s the Big Idea?
About
How did life become so remarkably capable, clever, and complex? How do thought, instinct, and culture interact to shape our daily lives? What can science teach us about the nature of intelligence and the human condition? Follow along as Nate begins a new chapter of his life devoted to exploring these ideas and sharing his insights with the world.

Search for:
Search …
Search
Categories
Animal Minds
Armchair Philosophy
Beyond Darwin
Introspection
Mindless Intelligence
Personal Reflections
Programming with People
Snack-Sized
Status Updates
The Intelligent Body
Theory
Tags
ai artificial-intelligence bodies body bones brain brains cells cerebellum collectives CPPNs culture deep learning deep_fakes deep_learning default_mode_network design diversity dmn dna emotions endocrinology endosymbiosis epigenetics ethics evolution evolutionary computation experiment farm game of life GECCO genetics genetic_algorithms google grad school growth hormones horses illustration incentives intelligence interfaces language leadership learning life llm machine-learning machine_learning mammals management meaning meditation mindfulness Mindless Intelligence minds movement multitasking muscles neuroscience neurotransmitters ontology phd philosophy plants platforms productivity programming research sarina_mitchel science sentience social intelligence systems yoga
Recent Posts
What Intelligence is Not
How did AI get so much smarter?
Status Update: End of Semester 3
The Universe Evolves
Status Update: Semester 3
GECCO Follow-Up
Why the Game of Life Paper?
Queerness
The Brain’s “Boss”
Pre-Genetic Life
Facebook
Mastodon
LinkedIn
Goodreads
