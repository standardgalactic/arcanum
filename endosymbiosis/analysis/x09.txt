
There are lots of articles about how LLMs work and their limitations (I even wrote one a while back), so I won’t go into much detail here. What matters for now is that LLMs are prediction engines. Given some text, they try to guess how a human would respond, based on a statistical analysis of all the content on the internet. They do this extremely well, but not perfectly. LLMs don’t think, perceive, or interact with the world in a human-like way, so sometimes they make weird mistakes a human never would.

In some ways, the human brain works a lot like an LLM. From day one, the brain is looking for language. It automatically builds up vast networks of words, concepts, and their relationships. When I hear someone talking, my mind is suddenly filled with the speaker’s ideas and their associations, building up an image in my mind’s eye. This is basically what an LLM does.

However, I also have many other intelligent faculties that join in. I don’t just know that “dog” is a word related to “cat.” I have memories of specific dogs, what their fur felt like, and the experiences we shared. I have common sense, logic, and theory of mind to decide whether something I hear is truth, fantasy, error, or deception. I monitor my own thoughts to gauge my level of confidence and correct my mistakes. I anticipate the future, make plans, and use language to achieve my goals. LLMs don’t do any of that.

Of course, there are AI researchers working to approximate these other kinds of human intelligence (though progress here is limited compared with LLMs themselves). Rebooting AI is a great book exploring that work, which argues its just a matter of time before AI can do everything a human can. Personally, I’m skeptical that we’ll ever reverse engineer all the subtlety of human thought, but I think it’s safe to say that AIs will become more powerful and well-rounded in the future. Perhaps the more important question is whether building increasingly realistic human simulations is a good idea at all.

For now, LLMs are a bit of a one-trick pony. What’s scary is that one trick is often good enough to fool humans and do useful work. In particular, even though LLMs were designed to be text prediction engines, they are surprisingly good at general problem solving. They can paint pictures, do math, solve brain teasers, and even write and simulate computer programs. Maybe those “extra” faculties of the human mind aren’t so important after all?

LLMs “think” in terms of words and relationships and patterns they’ve seen before. In human terms, that means stereotypes, cliches, generalizing from past “experience,” and repeating what they are told. We like to think that human thought is more sophisticated than that, but it often isn’t. We sometimes don’t see people as individuals, but in terms of the role they play in society (ie, “barista” or “mom”). We make decisions based on rules of thumb or gut feeling, without the need for logic and reasoning. We talk about things we don’t fully comprehend. We repeat talking points in order to fit in with our tribe. We confidently make up nonsense just to satisfy each other and move on. It’s surprising how LLM-like humans can be sometimes.

And that’s not meant to be derogatory! Those ways of thinking can be very effective. A lot of language isn’t about complex ideas, comprehension, and reasoning, but just putting one word after another to evoke an image in someone else’s mind. Past experience often is a highly effective and low-effort way to predict the future. Lying is anti-social, but “fake it ‘til you make it” works. One of the fastest ways to pick up a new skill is to boldly make mistakes, get feedback, and learn from that experience. The main difference is that today’s LLMs don’t learn from their mistakes, they never doubt their “intuition,” and they have no alternative ways of “thinking” when these techniques fall short.

So, yeah, LLMs only do part of what humans do, but it’s a big and important part. Occasionally we do need facts, critical thinking, self-doubt, and all the rest to do the right thing, but they don’t come up as often as we like to think. The real danger of LLMs, then, is that 80% of the time they might be good enough, but 20% of the time we need fancy human judgment to notice they screwed up and decide what to do. This is a serious problem. Humans are bad at vigilance, and we have a strong instinct to trust language, which in this case is exactly the wrong response.

Language is a defining feature of our species. We aren’t just capable of language, it’s a human universal. Every culture has language. Babies attend to speech from the moment they’re born, and start to babble in a few months. When there isn’t a common language spoken around them, children raised together will spontaneously invent one. Language is a biological imperative for us. It’s in our DNA.

When we perceive language, our minds automatically assume that it’s communication. We imagine another mind behind the words, usually with good intent and a desire to cooperate. Up until recently, this was a pretty safe assumption, so it was totally reasonable for the brain to immediately and automatically translate language into meaning. But now this instinct is backfiring. LLMs create realistic text and imagery without any intentional meaning. They don’t produce “answers,” “opinions,” or “art,” just random content that looks like those things. It’s both very difficult and important to remember that.

We’re still working to understand how these LLMs work, what their limitations are, and what they’re good for. As we do that, I hope we’ll come to understand ourselves better, too. What do you think? Have LLMs made you think about minds any differently? Have you seen any interesting examples of AIs acting strange or foolish? What about people acting like LLMs? Any thoughts or fears about computers gradually inching toward human-like abilities? I’d love to hear from you in the comments.

Author Nate Gaylinn (he/him)Posted onApril 5, 2023CategoriesIntrospectionTagslanguage, llm, machine_learning, meaning, minds7 Commentson What ChatGPT Can Teach Us About Being Human
The Age of Microbes
The Age of Microbes
(Image used under Creative Commons license, source)

There’s something very romantic about “the Age of Dinosaurs.” Before the familiar ecosystems of today, there was a completely different world order. Bizarre and fantastic species, strange environments and ways of living, another planet buried in the past of our familiar home. Yet, that was just one stage in our planet’s evolution—one that’s relatively recent, and similar to our own. It’s easy to forget that amniotes (reptiles, dinosaurs, birds, mammals, and the like) have only been around for 10% of Earth’s history, or about 300 million years. By comparison, single cells were the only life on Earth for 2.8 billion years. We sometimes hand wave over that period and say “not much happened,” but in that time life somehow went from accidentally self-perpetuating chemical reactions to swarms of intelligent microrobots that coordinate by the trillions to dominate every corner of the globe. This was the time of some of life’s most important and profound innovations, including essential concepts that made large-scale life possible.

About four billion years ago, the molten Earth finally cooled enough to form a solid crust of rock that could hold liquid water. Just 200 million years later, we see evidence of cells in the fossil record. In other words, it took just 200 million years for chance chemical reactions to become “self aware.” These early cells had no minds, of course, but they had membranes separating their insides from their outsides. They actively monitored and maintained the delicate balance of metabolic processes keeping them alive. Yet that was just the beginning of the journey, the basic foundation that made all the rest possible. From there, it took cells another billion years to cover the planet’s surface, and they’ve been ubiquitous ever since.

In that time, not much happened… from the human perspective. If you visited Earth at the time, it would look pretty boring. You might notice some slimes or biofilms, but you’d need a microscope to really appreciate that as “life.” Yet, gradually, microbes terraformed the planet. They found and exploited every available source of energy, and developed a molecular toolkit for extracting resources from a dead world. They mined useful molecules from the air, water, and rock, transforming and concentrating them for future generations. They remade the atmosphere, filling it with volatile oxygen, providing an energy-dense fuel for organisms to come. They created a protective layer of ozone that blocked DNA-frying radiation and made land habitable for the first time. This would all be invisible to a human observer because it happened so slowly, but the scale and significance of this transformation is incredible, especially coming from such tiny, mindless lifeforms. How could this happen?

Perhaps the biggest misconception about evolution is that simpler forms of life are “less evolved” than we are. The reality is that everything alive today has a common ancestor, and has had just as much time to evolve from there. Even bacteria are highly sophisticated organisms. They sense light, heat, motion, and chemicals. They sniff out food and resources, and navigate their environment. They hunt and evade predators. They learn and remember. They coordinate their behaviors with pheromone signaling. They sustain themselves, repair themselves, and make copies of themselves. In many ways, a single bacterium is vastly more impressive than anything made by humans. Like all life, they’re very good at what they do, but appreciating that intelligence means taking their perspective, which is rather difficult for humans.

For example, microbes experience evolution quite differently than we do. For humans, it’s a very abstract concept. It only matters on the scale of many generations, which may take thousands or millions of years. In contrast, a colony of E. coli bacteria can double in number every 20 minutes. They evolve over the course of hours, so for them it’s a real-time problem solving tool. There’s a fascinating experiment where bacteria took just eleven days to incrementally evolve resistance to antibiotics at a concentration 1,000 times what was originally a lethal dose. You can actually watch as the population discovers innovations that allow them to resist the poison and expand into new territory. When they do, they get a brief moment of total freedom, spreading unhindered until they start to get competition from their fellow mutants for the limited space remaining.

This is what cells are really good at. Not just living one lifestyle, but finding new lifestyles. In a crowded, competitive world, the best way for an organism to set itself apart is novelty: gaining access to an empty niche, or finding some innovative way to out-compete its neighbors. Doing this over, and over, and over again is how life managed to colonize every corner of this planet, from underwater volcanic vents, to Antarctic ice, to your gut. Exploration and creativity is also critical for long-term survival. On a geologic time scale, niches and lifestyles are transient, coming and going as changes in environmental conditions and competition from other species reshape the landscape. Staying alive means constantly adapting and trying new strategies. On a fundamental level, this is what life does.

This perspective helps explain one of the strange things about cells. Every living thing we know—every single cell, even the most ancient and primitive Archaea—has a general-purpose design. At their core, there’s a 3D printer for proteins, capable of mass producing molecules in a mind-boggling variety of shapes. Those proteins form the structure and machinery of the cell, help digest various food stuffs, neutralize toxins, and perform computations. Importantly, this 3D printer doesn’t just produce every protein a cell needs to live. It can make any protein, from any species, even proteins that haven’t been discovered yet. This would be massively overkill for living in any single niche, but it’s the ideal tool for conquering every niche. This complex, general-purpose cell design was so powerful that it out-competed and replaced everything simpler.

DNA mostly consists of programs for that 3D printer. It’s a collection of recipes for proteins, and cues for when to make them. Life hoards those recipes. They represent tools and behaviors that were once useful in the past. Right now, they might not be useful. They may even be harmful, disabled, and packed away where they can do no damage, but they aren’t forgotten. They lie dormant, waiting to be re-enabled on demand or by accident, just in case they might one day prove useful again. After all, who knows when the next global catastrophe will completely rewrite the rules of survival on this planet?

In other words, cells specialize in exploring the space of possible forms and lifestyles. They build up massive libraries of tools and strategies in their DNA. They continuously reprogram themselves, adapting to any conditions in order to find new niches. Macroscopic life, from butterflies to avocados to whales, is only possible because of this polymorphic quality of cells. They are the secret ingredient. They are like “smart matter” that can act autonomously, respond in real time, take on any shape, produce any chemical, and implement any behavior. Once you have that, it’s relatively easy to program those cells to construct just the right mix of forms, organized in just the right way, to make something much greater than the sum of its parts.

I hope this conveys some of why I find cellular intelligence so exciting. Humans are most interested in human things, so it’s very easy to ignore the incredibly alien lives happening right under our noses. Yet, there’s so much to explore, and so much of what we are is that “alien” cellular intelligence. What do you think? Did this help you see single cells or life in general in a different light? Did this spark any questions or ideas? Anything you’d like to see me explore more in a future post? I’d love to hear from you in the comments.

Author Nate Gaylinn (he/him)Posted onMarch 1, 2023CategoriesMindless IntelligenceTagsbacteria, cells, diversity, dna, earth, evolution, microbes, platforms, terraforming10 Commentson The Age of Microbes
In Every Mind, a Universe
In Every Mind, a Universe
The first life was blind and ignorant. It was little more than a self-perpetuating chemical reaction, constantly rebuilding itself and making new copies. It had no idea where it was because it had no way to perceive the world around it. Even the very notion of existing and moving within a physical space was incomprehensible. It didn’t know what it was, or even that it was, because it had no way to perceive its inner life, either. It just kept on going, making copies of itself, frequently with errors that made it worse or (occasionally) better at being alive.

Eventually, by chance, life discovered something very useful: certain molecules change shape when something happens to them. Some respond to being hit with light, others change in response to temperature, or pressure, or brushing up against another molecule with just the right shape. Life learned to read these signs, understand them as clues about the world, analyze them, make decisions, and respond. At least, metaphorically speaking. In reality, we’re still just talking about chemical reactions here. One shape change might trigger another, which might cause some new protein molecule to be synthesized, or kick off a chain reaction that leads to a cell moving, adjusting its metabolism, or whatever. The cell acts as if it appreciated the meaning of this signal, but without “thinking” except in a purely mechanical way.

This was the origin of meaning. At first, it was a very primitive thing. Life learned to discriminate between “good” and “bad.” That is, it noticed signs correlated with favorable living conditions, survival, and reproduction. Organisms that sought out more “good” signals while avoiding “bad” signals tended to live longer and produce more offspring. In this way, evolution slowly transformed random patterns of stimulus and response into instinct, innate biases baked in from birth, representing a sort of ancestral “knowledge.” Over time, life evolved more nuanced concepts like: light and dark; warm and cold; food and poison; me, us, and them. Teasing apart these subtler shades of meaning helped life develop more complex and successful strategies to survive in the world.

Every organism has this sort of evolved map of meaning (an “innate ontology”), implicit in their genes. It’s defined by their senses, physical capabilities, reflexes, and gut feelings. That means every species has a profoundly different perspective on reality. Fish, for instance, may have no conception of water because to them it’s a lifelong constant with no alternative. However, they have a very nuanced sense of the information carried in the water, which we are totally blind to. They can be very sensitive to things like pressure, temperature, chemical concentrations, currents, and even electrical fields. To a limited extent, they instinctively “know” where these signs are coming from, what they foretell, and how to react.

Talking about “ontology” as something in our genes is a little unusual. Typically that word is applied minds, perhaps just human minds. It’s about how we perceive reality, dividing it up into objects, categories, and relationships. It’s how people fundamentally understand themselves and the world they live in, and it’s heavily influenced by culture. But philosophers like Daniel Dennett insist that the same concepts should be extended to precognitive life, as well. Our physical bodies lead us to perceive and think and act in human ways, laying a foundation upon which conscious learning and culture can build. In that view, our rich mental ontology is a product of evolution, constructed from lower-level, simpler, more instinctual parts that we share with many species.
