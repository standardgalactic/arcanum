For one thing, you don’t need a brain to be smart. Plants are incredibly intelligent. They coordinate their life cycle with the seasons and weather, maneuver around obstacles, communicate with pheromones, and expertly manipulate other species into doing work for them. Even in human beings, we often overlook the ways our bodies shape our behavior, rather than our brains. Our bodies make delicate manipulation tasks effortless, carefully manage an array of vital resources, perform repairs, fight disease, and have a huge influence over our moods and desires. The brain helps with understanding, imagining, planning, and deciding, but just about everything else is deferred to the body.

For another thing, a human being isn’t so smart without a society. So much of what we think of as human intelligence is the accumulated knowledge, wisdom, and artifacts that are better thought of as human culture. Those things were all created by human beings (over a few hundred thousand years), but most people aren’t constantly inventing new ideas, they’re adopting ready-made solutions, often without full understanding. The remarkable thing is that people can share and remix ideas, which allows the limited intelligence of our brains to reach further. Without access to culture, we’re not much better off than other mammals. This is clear from “wild child” accounts, which show that an infant growing up in isolation will end up tragically stunted, traumatized, and unable to adapt to life in society.

So if intelligence is not human brains, what is it? Tentatively, I think of intelligence as “the ability to adapt effectively to environmental challenges.” In other words, intelligence is learning. It’s about observing reality and using prior examples to choose actions that will hopefully lead to the best outcome. Sometimes this is intentional (like when a person decides what to do) and sometimes it’s more of a blind process (like when natural selection preserves a behavior because it just happens to be adaptive).

My perspective is that all of life and culture is produced by a complex learning process. Or, more precisely, life is a system of learning processes that make learning processes that make learning processes. Our global society and ecosystem together make up one enormous web of intelligent agents, filling many roles and operating at many scales. This is not a new idea. There are whole branches of Complex System Theory devoted to the emergence and complexification of life. I’m reading about that prior work, and thinking about how it relates to my experience in algorithms, computer systems, and organizations.

Life as computation
One assumption that I’m making is that life can be thought of as a kind of computation. This may be hard for some to swallow, since computers as we know them today completely lack so many of life’s wondrous qualities. I’d argue that’s because of two essential differences. Firstly, life is solving a completely different problem than computers do. Organisms are born into the world with a body, and challenged to survive as best they can in an open-ended environment. In contrast, most computer systems are tools for people, designed to perform specific tasks on demand. Of course they behave quite differently. The second difference is sophistication. Our engineered computer systems are incredible, but life still puts them to shame in terms of complexity, nuance, and efficiency. That’s not surprising, given life’s multi-billion-year head start.

When I say life is computation, what I really mean is there is nothing supernatural about life. As strange, beautiful, creative, and unpredictable as life is, I assume that this is ultimately the result of physics. Very particular arrangements of molecules interact in reliable ways to reproduce, perpetuate, and refine patterns of behavior we see as intelligent, without the need for any outside influence. This assumption is mostly out of practicality. Science can’t explain magic, so to give science a chance at this problem means entertaining the idea that there is no magic.

In Computer Science, there’s a concept called the “universal computer,” first proposed by Alan Turing. In a thought experiment, he designed a very simple machine and showed that it could run any computer program you could imagine. More importantly, he showed that any machine that has a few key properties is equivalent to the one he designed, and can also perform any arbitrary computation. In other words, computers come in all shapes and sizes. Each one has unique performance characteristics, which make it better suited for solving some problems than others, but at least in principle any universal computer can run any possible program.

That’s why I find the model of computation so appealing for natural intelligence. In life, there are many different kinds of intelligent systems, built very differently, with different specializations, functions, and performance characteristics. But as long as there’s no magic, then there’s some mechanical process under the hood producing these behaviors, and that’s computation. More importantly, if we can describe all these systems using the same language, we can compare them directly with each other, and talk about how they compose to form larger, more complex systems. The language of computation is general and expressive enough that I think it can do the job.

What kinds of intelligence exist?
Our world is filled with an enormous diversity of intelligent systems, many of which have their own dedicated fields of research. There’s cell biology, evolutionary biology, ecology, neuroscience, psychology, sociology, computer science, and many more. Specialists study one intelligent system, in the context of a particular academic discipline, using the tools and language of that discipline. This narrow focus is very valuable, but it means our understanding of intelligence is siloed, and we tend to categorize intelligent systems based on what academic field studies them, rather than their computational properties.

To advance our understanding, we must learn to see past the obvious differences of these systems and the unique, messy ways they manifest in nature. Instead, we should focus on what they have in common. What properties are broadly shared by many kinds of intelligence? What questions can we ask about all intelligent systems, and when we look at the answers, how do we compare apples to apples? I’m not at all sure how to do this, but there are a few properties that already stand out to me as interesting places to look:

Substrates: What is the fabric this intelligence is built from? Molecules? Neurons? Transistors? People? What can that tell us about the strengths and weaknesses of that system? For instance, cells are molecular machines and thus constrained by the limitations of chemical processes like diffusion and catalysis. This severely limits the computational speed and physical size of cells, but it also provides a remarkably robust, efficient, and massively parallel form of computing that engineers can’t yet rival.
Visibility: What information is available to learn from? For instance, natural selection is almost completely blind. The only signal of success is when an organism reproduces. On the other hand, humans have rich sensory perceptions and a wealth of knowledge and experience, all of which factor into cognition. The level of visibility affects what kinds of patterns a system can recognize, and how quickly it can find a workable solution to a problem.
Purpose: What function does this intelligence serve? For most computer systems, a human decided the purpose in advance, then designed one particular solution to fulfill that need. On the other hand, many forms of intelligence are far more open-ended than that. Living things, human organizations, and even some forms of AI will strive to creatively fulfill their purpose, sometimes doing so in surprising ways. This can be very tricky, since a system’s “purpose” often isn’t clear, and can change over time.
Interface: Within a substrate, there are no clear boundaries. The genes for digesting lactose are spread ambiguously between you and your gut bacteria, for instance. But boundaries between substrates are much sharper, because the parts are made of different stuff, and are not naturally interoperable. At these edges, there are narrow interfaces between intelligent systems, sharing just enough information from one to another that they can work together. That gives us a natural window into what properties of a system matter most for fulfilling a particular function.
What I want to do here is to find useful ways of dividing up the world that might serve to integrate, compare, and contrast our notions of intelligence from different domains. I hope this will help to identify parallel examples, and to discover insights that can transfer from one domain to another. Life has evolved an incredible variety of learning processes, each optimized in different ways. Surely there are new algorithms and performance tricks waiting to be discovered. Perhaps we could even derive some general design principles for what learning tools work best under different constraints?

What does life compute?
So, if all of life is one big, complex computation, what is it actually computing? In one sense, the answer is simple: life constructs ecosystems of organisms, and optimizes them to reproduce and thrive. That’s a fine answer in the abstract, but our experience is much more specific than that. Life is typically a “yes and” sort of process. Any successful way of doing things tends to stick around, and in doing so it shapes everything that can come after. In other words, life on planet Earth isn’t just “thriving” in some generic sense, it’s found a very particular way of doing that which we must study if we want to understand, predict, and influence its direction.

To make this more concrete, think about modern American society. We use GDP as a (flawed) proxy for human thriving. We use capitalism and an ecosystem of corporations to redistribute resources and prioritize work so as to improve GDP. Those corporations are made out of people, who run the company, make the decisions, do the work, provide the services, buy the products, and use them in their daily lives. Those people have minds which are deeply embedded in cultural roles (citizen, employee, parent, etc.) and physical bodies, all of which have their own goals, limitations, preferences, and demands that tug the person in multiple directions at once. People are just one species, but we depend on countless others, which depend on each other and on the physical world, which is changing more rapidly than ever thanks to the power of human culture.

That system as a whole does things we want (like providing a comfortable standard of living for many) and things we don’t want (like instigating global climate change). It’s flawed, but we can’t start over from scratch, we can only try to steer it in a positive direction. That means understanding the structure of the system, and finding the points of high leverage, where a small nudge will have a big impact (and hopefully few side effects). To fight plastic pollution, should we invest in ocean clean-up, tell individuals to change their purchasing habits, tax corporations for plastic waste, or engineer plastic-eating bacteria? It’s hard to say what will work best, but if we can understand the major players, their incentives, and the ways they learn and adapt, we can make better educated guesses.

Describing and explaining all of life on Earth is impossible. It’s just too big, messy, complex, and rapidly changing, but that doesn’t bother me. The same is true of the source code for Google Search, but I worked with that system effectively for years. How? By using the engineering concept of a system architecture. If you know the major parts of a system, what they do, and how they fit together, you can say a lot about that system as a whole and navigate its subsystems with confidence. Of course, whatever model you make will be a huge oversimplification with many exceptions, but even a very rough model is profoundly useful.

This may be a pie-in-the-sky idea, but I’m fascinated by what a system architecture for life on Earth might look like. Could we really describe it all in one big picture? Could it be organized and subdivided in meaningful and useful ways, or is the real world just too messy? Could we use that model like an engineer does, to trace the steps leading to some behavior, identify the relevant subsystems, and make targeted interventions to change the system’s behavior?

More practically speaking, I’m interested in how intelligent systems compose with one another, even just two at a time. For instance, nascent research has shown great promise in using evolutionary algorithms to design architectures for deep learning. I hope that studying the relationship between mind and body might provide insights into how to integrate deep learning systems into other software, and how to balance the costs and benefits of intuitive thinking with other algorithms and heuristics. I’m also very interested in understanding the impact of social software and machine learning on society, and how to build software systems that conform to human values and ethics.

Conclusion
That’s a brief tour of the intellectual domain I want to work in. I’m well aware it’s an enormous territory, and I surely won’t get to it all. My plan is to take a broad but shallow pass over many examples of natural intelligence, and to go deep on my study of computer algorithms and machine learning. I hope this will allow me to take full advantage of my technical skills and spend time searching for practical innovations that show the value of this way of thinking. In the meantime, I can work towards a general theory of intelligence in the background. It’s fine if I never get there, it’s just good to have lofty aspirations.

That said, all of this will surely change as I make progress. I’m figuring this out as I go along, and making course corrections all the time. I’m still learning about prior work, and I’ll have to adapt my own work to complement it. I’m not sure what ideas will prove to be dead ends, or what surprising new questions and opportunities I’ll discover along the way. That’s a good thing. I want to keep an open mind about this work, and let it evolve into what it needs to be. Still, I hope these questions will be a fruitful place to start.

I also have more ideas I didn’t cover here. I’ve got lots to say about evolution, so much so that it deserves its own post. I have many thoughts and observations about the inner workings of the mind. I’d love to explore the consequences of these ideas on how we understand the human condition, the structure of society, and conventions for the ethical AI. Frankly, this is such a big domain, there are so many places I could go, and I intend to follow my passion and curiosity.

As always, I’m very interested in feedback. Does what I said make sense? Do you have questions? Do you disagree, or have other ideas to share? Got advice on how to make this research more productive? Did I touch on something you’d like me to explore in more depth in a future post? If so, please leave a comment. I’d love to hear from you.

Author Nate Gaylinn (he/him)Posted onMarch 2, 2022CategoriesTheory17 Commentson What’s the Big Idea?
About
How did life become so remarkably capable, clever, and complex? How do thought, instinct, and culture interact to shape our daily lives? What can science teach us about the nature of intelligence and the human condition? Follow along as Nate begins a new chapter of his life devoted to exploring these ideas and sharing his insights with the world.

Search for:
Search …
Search
Categories
Animal Minds
Armchair Philosophy
