<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	xmlns:georss="http://www.georss.org/georss" xmlns:geo="http://www.w3.org/2003/01/geo/wgs84_pos#" xmlns:media="http://search.yahoo.com/mrss/"
	>

<channel>
	<title>Thinking with Nate</title>
	<atom:link href="https://thinkingwithnate.wordpress.com/feed/" rel="self" type="application/rss+xml" />
	<link>https://thinkingwithnate.wordpress.com</link>
	<description>Becoming an intelligence researcher</description>
	<lastBuildDate>Wed, 01 Jan 2025 14:39:29 +0000</lastBuildDate>
	<language>en</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>http://wordpress.com/</generator>
<cloud domain='thinkingwithnate.wordpress.com' port='80' path='/?rsscloud=notify' registerProcedure='' protocol='http-post' />
<image>
		<url>https://s0.wp.com/i/buttonw-com.png</url>
		<title>Thinking with Nate</title>
		<link>https://thinkingwithnate.wordpress.com</link>
	</image>
	<atom:link rel="search" type="application/opensearchdescription+xml" href="https://thinkingwithnate.wordpress.com/osd.xml" title="Thinking with Nate" />
	<atom:link rel='hub' href='https://thinkingwithnate.wordpress.com/?pushpress=hub'/>
	<item>
		<title>What Intelligence is Not</title>
		<link>https://thinkingwithnate.wordpress.com/2025/01/01/what-intelligence-is-not/</link>
					<comments>https://thinkingwithnate.wordpress.com/2025/01/01/what-intelligence-is-not/#comments</comments>
		
		<dc:creator><![CDATA[Nate Gaylinn (he/him)]]></dc:creator>
		<pubDate>Wed, 01 Jan 2025 14:39:29 +0000</pubDate>
				<category><![CDATA[Armchair Philosophy]]></category>
		<category><![CDATA[culture]]></category>
		<category><![CDATA[diversity]]></category>
		<category><![CDATA[evolution]]></category>
		<category><![CDATA[humans]]></category>
		<category><![CDATA[intelligence]]></category>
		<category><![CDATA[life]]></category>
		<category><![CDATA[Mindless Intelligence]]></category>
		<category><![CDATA[minds]]></category>
		<category><![CDATA[myths]]></category>
		<category><![CDATA[nature]]></category>
		<category><![CDATA[philosophy]]></category>
		<category><![CDATA[science]]></category>
		<category><![CDATA[society]]></category>
		<guid isPermaLink="false">http://thinkingwithnate.wordpress.com/?p=272</guid>

					<description><![CDATA[(The photo from this post is of a squirrel monkey eating fruit in a tree branch. The monkey is tiny, with golden / silver fur, pale pink skin, and a dark skull cap pattern. The fruit is small and red, perhaps a date. Used without modification under the creative commons license &#8211; source) Life has &#8230; <a href="https://thinkingwithnate.wordpress.com/2025/01/01/what-intelligence-is-not/" class="more-link">Continue reading<span class="screen-reader-text"> "What Intelligence is&#160;Not"</span></a>]]></description>
										<content:encoded><![CDATA[
<p>(The photo from this post is of a squirrel monkey eating fruit in a tree branch. The monkey is tiny, with golden / silver fur, pale pink skin, and a dark skull cap pattern. The fruit is small and red, perhaps a date. Used without modification under the creative commons license &#8211; <a href="https://www.flickr.com/photos/tambako/8156760351/in/photostream/">source</a>)</p>



<p>Life has been steadily driving towards greater and greater intelligence, eventually leading to human beings, who are the very pinnacle of this trend. Our superior minds are what separate us from the animals. They empower us to make a world of human flourishing, and justify our dominion over the planet. These tropes about intelligence are so common in our culture, they almost sound self-evident. Yet, I&#8217;ll argue that they&#8217;re completely wrong. These ideas are enticing because they appeal to our pride and our sense of specialness, but this way of thinking is destroying our world. So, let’s break down these myths and talk about what intelligence is <em>not</em>.</p>



<p>One problem with this story is it presents intelligence as a linear thing. Life started out dumb, and it gradually got smarter and smarter. In a sense, this is true. More intelligent life is more complicated, so it takes longer to evolve. But life doesn’t evolve <em>towards</em> anything, it evolves in all directions, finding and filling every niche available. Monkeys are brilliant at navigating tree branches and spotting ripe fruit. Trees are brilliant at producing the right amount of fruit at the right moment to use local resources efficiently and maximize the spread of their seeds. Yeasts are brilliant at performing alchemy on that fruit, transmuting sugar into alcohol, which the monkeys love. These are all different kinds of intelligence, and none is “better” than the other because they’re all contextual and interdependent. Every instance of intelligence looks different, because it’s adapted to a unique lifestyle.</p>



<p>We live a very complicated lifestyle that depends on our big brains, so we tend to think that more intelligence is better, but that’s just not the case. Some of the simplest, dumbest organisms on Earth are also the most successful. Microbes, fungus, and plants make up something like 99.5% of Earth’s biomass, while animals (the “smart”ones) make up the rest. Being smart is metabolically expensive. Taking time to think can mean missing a moment of opportunity. Sometimes real intelligence is knowing when a mindless strategy works best. If anything, humans are a great example of how intelligence can backfire. We’ve used our intelligence to make civilization, which is amazing! But in doing so, we accidentally drove many species to extinction, exhausted resources we depend on, and destabilized the global climate. Our kind of big-brained intelligence is a high risk, high reward strategy.</p>



<p>This brings us to the idea that humans are the pinnacle of intelligence. The problem with a word like “pinnacle” is it suggests we are the <em>ultimate</em> form—the thing life’s been building up to, all this time. But we’re not the end of anything. We’re still evolving, and it’s unclear whether our intelligence will go up or down from here. We’re also not the only ones. There are a handful of species that have gone “all in” on the strategy of super intelligence. You know, elephants, dolphins, octopi, the usual suspects. Humans may, in fact, be the smartest of them all, but since intelligence is so contextual, it’s hard to say. Maybe dolphins are <em>more</em> intelligent than us, it just looks different in an ocean species with no hands?</p>



<p>It may seem obvious that human intelligence is something more and different from those other species. We invented the wheel, New York, wars and so on. But that really isn’t because we as individuals are so smart. This is made clear by the tragic case of “wild children,” who grow up without parents or any human community. In the few cases we’ve observed, these children were described as animalistic, violent, and cognitively impaired. They were never able to recover or integrate into human society. Our brains alone do <em>not</em> set us apart from animals. Our <em>society</em> does, and that’s a separate thing, that evolved <em>after</em> our big brains. We’re smarter than other animals not because of our biology, but because of the vast library of practical knowledge and resources that we share with one another.</p>



<p><em>That’s</em> what sets us apart: other species can’t access human culture. In a sense, that&#8217;s because those species are less intelligent; to fully appreciate human society, you need language and abstract thought, which many species lack completely. Yet some species <em>thrive</em> in human society anyway. By being useful (like wheat), or charismatic (like dogs), or sneaky (like raccoons) other species live with us and shape our human world. That’s because nature does not set humans apart from other animals. We set <em>ourselves</em> apart from other life by building walls, by excluding them from our world, to the extent that we can. We decide what plants and animals are pets, food, or pests. Other species don&#8217;t need language to live in human society if we choose to accommodate them. We can coexist with nature in community, as many human societies have, and still do. Or, we can perpetuate the myth that we are special to justify excluding and exploiting nature instead.</p>



<p>And, ultimately, that’s the problem with this notion of intelligence: we use it to draw a line between friend and resource. If smarter is better—if our <em>intelligence</em> is what sets us apart from other life, and gives us the right to exploit that life however we see fit—then where do we draw the line? Should smarter people get more rights and privileges than dumber ones? Is a disabled person no better than an animal? Should we simply recycle the feeble minded from our population? This line of thinking is revolting, and it only makes sense if you believe these myths about intelligence. Similarly, if anything less than human is just a dumb resource for us to exploit, why not pave the planet? What’s wrong with processing all of that biomass, every living thing on Earth, into fuel and plastics? I think intuitively we know why: life has a right to exist, and losing all those diverse and beautiful kinds of intelligence would be tragic.</p>



<p>I’m excited to live in a time when our understanding of intelligence is changing so rapidly. It’s hard to define the word, just because we have so many examples that pull in different directions, and seem to contradict one another. Intelligence is <em>many</em> things, and we’re still fleshing out the full picture. Yet, every day we see more clearly that our old conceptions of intelligence that put human beings on a pedestal were <em>wrong</em>, and, more importantly, that they are at the root of so much injustice and destruction. So, while these tropes are still everywhere around us, shape the way our world works, and may still <em>feel</em> intuitively true, I urge you to reject them. We must move on, and embrace a more expansive view, one that doesn’t start from the premise of who to exclude.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://thinkingwithnate.wordpress.com/2025/01/01/what-intelligence-is-not/feed/</wfw:commentRss>
			<slash:comments>8</slash:comments>
		
		
		
		<media:thumbnail url="https://thinkingwithnate.wordpress.com/wp-content/uploads/2025/01/8156760351_8459849c03_k.jpg" />
		<media:content url="https://thinkingwithnate.wordpress.com/wp-content/uploads/2025/01/8156760351_8459849c03_k.jpg" medium="image">
			<media:title type="html">Picture by Tambako the Jaguar</media:title>
		</media:content>

		<media:content url="https://0.gravatar.com/avatar/39ae42d33af99a13fa6ef7e7c81e595cc0e2e241e360bb495dc7e4c89ab517fd?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">nategaylinn</media:title>
		</media:content>
	</item>
		<item>
		<title>How did AI get so much smarter?</title>
		<link>https://thinkingwithnate.wordpress.com/2024/12/07/how-did-ai-get-so-much-smarter/</link>
					<comments>https://thinkingwithnate.wordpress.com/2024/12/07/how-did-ai-get-so-much-smarter/#comments</comments>
		
		<dc:creator><![CDATA[Nate Gaylinn (he/him)]]></dc:creator>
		<pubDate>Sat, 07 Dec 2024 15:51:05 +0000</pubDate>
				<category><![CDATA[Theory]]></category>
		<category><![CDATA[ai]]></category>
		<category><![CDATA[artificial-intelligence]]></category>
		<category><![CDATA[deep learning]]></category>
		<category><![CDATA[language]]></category>
		<category><![CDATA[large language models]]></category>
		<category><![CDATA[llm]]></category>
		<category><![CDATA[llms]]></category>
		<category><![CDATA[machine learning]]></category>
		<category><![CDATA[machine-learning]]></category>
		<category><![CDATA[meaning]]></category>
		<category><![CDATA[natural language processing]]></category>
		<category><![CDATA[nlp]]></category>
		<guid isPermaLink="false">http://thinkingwithnate.wordpress.com/?p=267</guid>

					<description><![CDATA[(this month&#8217;s photo is a picture of a brown bat. It&#8217;s small and fluffy with a stubby nose, and clinging to the gray bark of a tree. Photo by N. J. Stewart wildlife unmodified and used under the Creative Commons license) When I write about intelligence, I tend to downplay AI and Deep Learning. These &#8230; <a href="https://thinkingwithnate.wordpress.com/2024/12/07/how-did-ai-get-so-much-smarter/" class="more-link">Continue reading<span class="screen-reader-text"> "How did AI get so much&#160;smarter?"</span></a>]]></description>
										<content:encoded><![CDATA[
<p>(this month&#8217;s photo is a picture of a brown bat. It&#8217;s small and fluffy with a stubby nose, and clinging to the gray bark of a tree. Photo by <a href="https://www.flickr.com/photos/stuartwildlife/">N. J. Stewart wildlife</a> unmodified and used under the Creative Commons license)</p>



<p>When I write about intelligence, I tend to downplay AI and Deep Learning. These are powerful problem solving tools, but they’re over-hyped, and they don’t “think” the way people do. They have no memory, no sense of self, and no goals, at least in the usual sense of the words. But, large language models (LLMs) like OpenAI’s GPT are shockingly good at generating text that <em>seems</em> like something a person might make. They’re much more human-like than anything that came before. Why is that? The short answer is that they use a new kind of Deep Learning architecture known as a Transformer, which introduced a few small tricks that make a very big difference.</p>



<p>The first thing to note is that, while lots of people argue about whether LLMs can answer questions, reason, solve problems, brainstorm, or make art, what they really do is <em>text prediction</em>. They take some words as a starting point and then they guess what comes next based on their training data. If LLMs have any deeper cognitive abilities than that, they must be somehow tapping into the human cultural intelligence that is embedded within that text. Or, maybe they’re just parroting back fragments of intelligent things other people have said, without any understanding or integration—mindless idiots, randomly stringing words together in ways that sound just smart enough to distract us. We honestly don’t know yet! But whatever intelligence they possess, it exists entirely in the realm of language.</p>



<p>Research into getting computers to understand text and speech (known as Natural Language Processing, or NLP) started back in the 1950’s. Back then, computers were specialist’s tools, and making one that anyone could use just by telling it what to do was a dream. At first, researchers tried to formally describe language as we use it, feeding computers dictionaries, grammar rules, and lists of facts, but this never worked! It turns out, we don’t explicitly <em>know</em> all the rules of human language that we intuitively follow, and they’re usually <em>fuzzy</em> rules, with lots of conditions and exceptions. The key challenge of NLP was getting computers (which are obsessively logical and precise) to deal with this messiness and ambiguity, which we don’t even fully understand ourselves. Perhaps the most important advance was when researchers gave up trying to explain language to computers, and instead started teaching them by example.</p>



<p>Modern NLP represents words as lists of numbers called “vectors.” Like an (X, Y) coordinate, each vector represents a point in space. Not physical space, though, more like an abstract space of concepts. Maybe nouns go to the right, verbs to the left. Natural concepts are up, man-made concepts are down. Except, instead of two dimensions, maybe there are 10,000 of them. The layout of this space is pretty arbitrary. The absolute position of a word doesn’t mean anything, only where it is relative to other words. Nearby words have similar meanings, and relationships between words are represented by the distance and angle between them. This is all weirdly self-referential. Words are only defined in terms of other words! But it works surprisingly well. You don’t need explicit rules about which words go together and how, you can just look at <em>lots</em> of examples, and infer those relationships with statistics. People talk about “training” an AI by having it “read” lots of text, but really all that means is iteratively tweaking the lists of numbers, slowly moving the words through this abstract meaning space until they settle into positions that reflect how they co-occur together in the training text.</p>



<p>There’s one big problem with representing words as vectors, though: ambiguity. What do you do with a word like “bat,” which has several meanings? There’s no way one vector can represent this. The trick is to look for context. When you see a phrase like “brown bat” or “wooden bat,” the meaning is clear. Instead of thinking of these as pairs of words, you might think of them as <em>compound words</em>, each with their own distinct meaning. This is a powerful idea, but hard to generalize. Take a more difficult example: “Hearing a strange flutter and crash in the dark, he grabbed his bat for defense and went to investigate” Which kind of “bat” are we talking about? Words like “flutter” and “dark” might suggest the animal, but “grabbing” a bat for “defense” suggests the object instead. We need context to disambiguate, but which context? We’d like to ignore the first half of the sentence (which isn’t talking about the “bat”) and focus on the second half of the sentence (which is).</p>



<p>NLP has found elegant ways to solve this problem. They call these techniques “attention,” since the model is learning to “pay attention” to some words and not others, but I find that name misleading. For human beings, attention is something very different. We seem to have a “mind’s eye” that we can move about at will. We can choose to pay attention to this or that, our attention gets drawn to salient features, and we may even notice our attention drifting and redirect it. But these AIs have no mind’s eye, no will, and no intuition about relevance. The attention models we’re talking about are just <em>more vector math</em>. In addition to finding vectors to represent the meaning of each word individually, they also find vectors to represent <em>patterns</em> of words. They learn, “in this context, these words together mean that.” Adding an extra layer of complexity lets the model represent how words interact to change the meaning of other words or the sentence as a whole.</p>



<p>Researchers have explored many variations on this attention trick. Transformer models use an advanced kind of attention that represents context bi-directionally. They model how different words tend to get modified by context, and how different contexts tend to modify nearby words. The benefit of this is that such a model doesn’t just learn that “brown bat” is the name of an animal, but it might learn that “brown” is an adjective that applies to physical objects, that in English adjectives tend to modify the noun that follows them, and that “bat” can refer to one of several animal species, sometimes distinguished by color. That is, rather than modeling some <em>particular</em> context, models like this can learn general rules and relationships between different <em>kinds</em> of words. They can learn <em>grammar</em>. Not just the “official” grammar of a language like English, but <em>any</em> system of relationships and interactions between words, including dialects, domain-specific jargon, storytelling tropes, or the gender roles of a society.</p>



<p>The other trick that makes Transformers better with language is <em>pluralism</em>. Some NLP systems represent more complex meanings by using <em>bigger</em> vectors. More numbers in each vector means a larger conceptual space. Instead, Transformers use <em>more</em> vectors. They don’t learn <em>the one</em> meaning of this word, they learn to represent the <em>many</em> meanings of this word in the <em>many</em> contexts that contain it. This works a bit like voting. When processing a sentence, several different “attention heads” each consider one possible interpretation of a word, attending to different patterns of contextual cues. The overall meaning is determined by adding them all together. This is really useful for weighing subtle cues against each other to resolve ambiguity, but also to represent sentences with multiple layers of meaning. A word can have many meanings at the same time, and the many meanings of all the words in a sentence can interact in complex ways. The fancy kind of attention used in Transformers can automatically discover this sort of layered structure in language.</p>



<p>As clever as these attention methods are, they are <em>not</em> the secret to Transformers’ success. They do greatly improve the richness of NLP models, but at first they were mostly used with “recurrent neural networks,” a kind of Deep Learning model that processes data sequentially. That’s probably because they work a bit like how we imagine a human reader does: they “read” each word in a text, one at a time, using attention to figure out how each new word should update the meaning of the text so far. This works pretty well, but it doesn’t scale up to long passages of text. These models have a limited attention span, eventually forgetting important details they read several sentences ago. Also, processing long texts one word at a time is painfully slow. Even on the world’s fastest computer, reading a book from beginning to end takes time <em>per page</em>, and training a model like this takes <em>vast</em> amounts of text, so this was a major limitation.</p>



<p>The paper that first introduced Transformers was called <em>Attention is All You Need</em>, which highlights the key innovation: they got rid of the recurrent network, and built an AI using just this attention mechanism, all on its own. In other words, they found a way to do the same vector math, but solving for a large block of text all at once (and possibly out of order) rather than word-by-word. This doesn’t make the model “smarter.” It doesn’t even reduce the overall amount of number crunching. It just makes the work more <em>parallelizable</em>. Instead of having one computer read <em>War and Peace</em> from cover to cover, they could have <em>many</em> computers each read a few paragraphs, then combine their results. This made it possible to throw more money at the problem, using whole <em>datacenters</em> of computers to train a language model on <em>vastly</em> more text than ever before. Billions of documents, trillions of words. It’s the <em>sheer volume</em> of training data that made LLMs so much better. That’s why they’re called “large” language models.</p>



<p>So, how should we think about LLMs like GPT? Well, first off, human language is irregular and complex, but it’s also highly structured. Cleverly designed statistical learning tools can automatically discover that hidden structure just by processing <em>obscene</em> amounts of text. Neural networks are great for letting computers work with these sorts of fuzzy rules. They can extract meaning from text, manipulate it, and generate new text. But to an LLM, words are just vectors, defined by their relationships to each other. They have no connection to physical reality, because LLMs have no physical existence. There is no communication going on when you have a “conversation” with an LLM. To the AI, a dialog is just a sequence of vectors that follow one another according to some grammar. The AI has no mind, no intentions, and no meaning it wishes to convey. It has no conception of being truthful or helpful, only what words tend to follow certain questions. It does not learn from a conversation, it just re-reads the full chat history each time it makes a response. It <em>appears</em> like a good conversational partner, because it is made to imitate one, but what&#8217;s happening behind the screen isn’t “thinking” as we know it.</p>



<p>Still, LLMs really are much more human-like than any other AI that came before. Representing language with a high-dimensional abstract concept space works surprisingly well, and so do the “attention” methods described above. They let us represent a huge, open-ended space of ideas that can build on and interact with each other. They let us represent ambiguity, nuance, and innuendo. So, maybe those vector math tricks could actually teach us something about how language processing works in the brain? On the other hand, LLMs are also remarkable in how <em>different</em> they are from humans. An LLM can learn English, but only by reading every document on the internet, not one word at a time, but <em>all at once</em>. In contrast, babies learn language by interacting with the world, learning how words relate to objects, people, events, actions, and desires. Even though they’re exposed to far less language, they learn much faster, and in a way that tightly integrates all of their senses, relationships, and the lifestyle they were born into. Since LLMs seem so human-like, it’s very tempting to imagine them with the same kind of awareness, purpose, and empathy that we have, but they simply aren’t there. Those are a product of being alive in the world, and can’t be found in text, no matter how much of it.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://thinkingwithnate.wordpress.com/2024/12/07/how-did-ai-get-so-much-smarter/feed/</wfw:commentRss>
			<slash:comments>15</slash:comments>
		
		
		
		<media:thumbnail url="https://thinkingwithnate.wordpress.com/wp-content/uploads/2024/12/image.png" />
		<media:content url="https://thinkingwithnate.wordpress.com/wp-content/uploads/2024/12/image.png" medium="image">
			<media:title type="html">image</media:title>
		</media:content>

		<media:content url="https://0.gravatar.com/avatar/39ae42d33af99a13fa6ef7e7c81e595cc0e2e241e360bb495dc7e4c89ab517fd?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">nategaylinn</media:title>
		</media:content>
	</item>
		<item>
		<title>Status Update: End of Semester 3</title>
		<link>https://thinkingwithnate.wordpress.com/2024/12/07/status-update-end-of-semester-3/</link>
					<comments>https://thinkingwithnate.wordpress.com/2024/12/07/status-update-end-of-semester-3/#comments</comments>
		
		<dc:creator><![CDATA[Nate Gaylinn (he/him)]]></dc:creator>
		<pubDate>Sat, 07 Dec 2024 15:35:37 +0000</pubDate>
				<category><![CDATA[Status Updates]]></category>
		<category><![CDATA[classes]]></category>
		<category><![CDATA[deep learning]]></category>
		<category><![CDATA[evolutionary computation]]></category>
		<category><![CDATA[experiment]]></category>
		<category><![CDATA[research]]></category>
		<guid isPermaLink="false">http://thinkingwithnate.wordpress.com/?p=263</guid>

					<description><![CDATA[Well, the third semester of my PhD is wrapping up! I really enjoyed my classes this time around. Evolutionary Computation was super interesting, and sparked all sorts of connections with my research. My class project was a big success, and I hope to turn it into a conference paper. I’ll share more on that later, &#8230; <a href="https://thinkingwithnate.wordpress.com/2024/12/07/status-update-end-of-semester-3/" class="more-link">Continue reading<span class="screen-reader-text"> "Status Update: End of Semester&#160;3"</span></a>]]></description>
										<content:encoded><![CDATA[
<p>Well, the third semester of my PhD is wrapping up! I really enjoyed my classes this time around. Evolutionary Computation was super interesting, and sparked all sorts of connections with my research. My class project was a big success, and I hope to turn it into a conference paper. I’ll share more on that later, but here’s a <a href="https://tech.lgbt/@ngaylinn/113544231802797345">sneak peek</a> if you’re curious. Deep Learning was also pretty great, and I feel like I have a more deep and intuitive understanding of what’s actually going on when you train or interact with an AI. One of the more exciting / challenging topics we covered was Transformers, the new model architecture that powers ChatGPT and its ilk. In some sense, Transformers are quite simple, but they’re definitely not intuitive; understanding why they’re built the way they are, and why that works so well takes some effort. So, to help cement my understanding, I wrote a blog post about it, and you get a bonus episode for the holidays!</p>



<p>Over winter break I hope to develop my Evolutionary Computation class project into a full paper. In short, it&#8217;s a new kind of evolutionary algorithm, inspired by endosymbiosis, that works in surprising ways. So far I’ve only used it to solve a trivial toy problem, so I’ll probably also start work on a follow-up study, exploring what practical applications this new algorithm might be good for. And, of course, I’ve got more research ideas to explore beyond that. I’m quite excited to try evolving a population without genomes, for instance. So many ideas! I hope I’ll be able to keep a few projects running in parallel, balancing my time across them, and leaving room for me in between. I’ll continue to share updates as I make progress.</p>



<p>In the spring, I’ll delve even deeper into Deep Learning, with a class that explores counter-intuitive results and how surprisingly effective DL is sometimes. How is it even possible to “learn” using nothing but vector math? What are these models really doing, and why are some models better than others? Should be fun. I’ll also be delving into the math of chaos and fractals. I hope that will be useful for my research into self-modifying dynamic systems (ie, simulated life <img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f61b.png" alt="😛" class="wp-smiley" style="height: 1em; max-height: 1em;" />), and lead to some very pretty visuals I can share. We’ll see!</p>



<p>Anyway, I’ll share the post about Transformers right after this, and that will wrap up another year of blog posts. More to come in January!</p>
]]></content:encoded>
					
					<wfw:commentRss>https://thinkingwithnate.wordpress.com/2024/12/07/status-update-end-of-semester-3/feed/</wfw:commentRss>
			<slash:comments>7</slash:comments>
		
		
		
		<media:content url="https://0.gravatar.com/avatar/39ae42d33af99a13fa6ef7e7c81e595cc0e2e241e360bb495dc7e4c89ab517fd?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">nategaylinn</media:title>
		</media:content>
	</item>
		<item>
		<title>The Universe Evolves</title>
		<link>https://thinkingwithnate.wordpress.com/2024/10/02/the-universe-evolves/</link>
					<comments>https://thinkingwithnate.wordpress.com/2024/10/02/the-universe-evolves/#comments</comments>
		
		<dc:creator><![CDATA[Nate Gaylinn (he/him)]]></dc:creator>
		<pubDate>Wed, 02 Oct 2024 12:33:40 +0000</pubDate>
				<category><![CDATA[Beyond Darwin]]></category>
		<category><![CDATA[agency]]></category>
		<category><![CDATA[biology]]></category>
		<category><![CDATA[complexity]]></category>
		<category><![CDATA[diversity]]></category>
		<category><![CDATA[evolution]]></category>
		<category><![CDATA[intelligence]]></category>
		<category><![CDATA[life]]></category>
		<category><![CDATA[origin of life]]></category>
		<category><![CDATA[philosophy]]></category>
		<category><![CDATA[physics]]></category>
		<category><![CDATA[science]]></category>
		<guid isPermaLink="false">http://thinkingwithnate.wordpress.com/?p=257</guid>

					<description><![CDATA[(This month&#8217;s featured image is a photo of the Carina Nebula taken by NASA&#8217;s James Webb telescope. It&#8217;s a vast cloud of gas and dust, slowly condensing, with hundreds of stars visible in the background behind it. The colorized image almost looks like orange mountains with a blue mist rising from them, set on a &#8230; <a href="https://thinkingwithnate.wordpress.com/2024/10/02/the-universe-evolves/" class="more-link">Continue reading<span class="screen-reader-text"> "The Universe Evolves"</span></a>]]></description>
										<content:encoded><![CDATA[
<p class="has-small-font-size">(This month&#8217;s featured image is a <a href="https://webbtelescope.org/contents/media/images/2022/031/01G77PKB8NKR7S8Z6HBXMYATGJ">photo of the Carina Nebula</a> taken by NASA&#8217;s James Webb telescope. It&#8217;s a vast cloud of gas and dust, slowly condensing, with hundreds of stars visible in the background behind it. The colorized image almost looks like orange mountains with a blue mist rising from them, set on a black background with bright, six-sided starbursts.)</p>



<p>Normally, when we talk about evolution, we mean what life does. It’s Darwin’s magic formula. You need reproduction. You need to pass on a copy of your genes, with a little variation, so things don’t just stay the same. Natural selection will weed out the less fit individuals, so they have fewer kids. The more fit individuals become more prevalent and, over time, life as a whole evolves to be more fit. Yet, this isn’t a very satisfying story. For one thing, how did it begin? Did life just start evolving out of the blue? I think story is more compelling if we think about evolution a bit more abstractly. In a sense, the physical universe itself evolves. It doesn’t have reproduction and inheritance, but it sure does have variation and selection, and this has caused it to change dramatically over the course of history.</p>



<p>For the first 370,000 years or so, all of space was filled with a boring, homogeneous cloud of energy and plasma. That universe is now extinct, and for one simple reason: it was unstable. In our universe, stability is the ultimate definition of “fitness.” What persists, exists. Patterns of matter and energy that get generated more often and stick around longer become more prevalent. Those that are rare and fragile exist only fleetingly. The plasma universe is gone because gravity causes matter to clump together. It was like a pencil, balanced on its tip. As soon as it became just a little unbalanced, it rapidly fell farther and farther away from that delicate equilibrium. Plasma condensed into molecules, gas clouds, and stars.</p>



<p>Of course, evolution needs variation to work. To find what&#8217;s better, you need to weed out what&#8217;s worse. For life, reproduction is the engine of variation, but that isn’t necessary if you have unimaginably vast scale. The universe started out with very little variation, but it steadily increased as matter interacted with itself. Gravity caused hydrogen molecules to group together in uneven clumps, and held them there. They sat around for millions of years, slowly growing bigger, until the force of their own weight ignited a fusion reaction. The gas clouds became stars, and in their cores new elements were born. The universe’s population gradually became more diverse.</p>



<p>That’s the counterintuitive thing about stability: it can generate diversity. When patterns become more numerous, and they stick around for longer, chaos starts to kick in. Every star and every planet is a little different. They have unique histories and influences and opportunities. They might be richer in this element or that one, bigger or smaller, hotter or colder, more or less affected by collisions. This diversity only compounds over time, as these objects smash together and interact in complex ways. The longer they stick around, the more they change, recombine, and become more elaborate.</p>



<p>So, for 13 billion years, the universe evolved. Its population became stranger and more complicated. Today we have about a hundred “naturally occurring” elements that didn’t exist at first, but had to evolve through multiple generations of stars fusing atoms, exploding violently, and gradually reforming. We have many <em>kinds</em> of stars, planets, solar systems, and galaxies, that support an astonishing variety of chemical processes that have had a very, very long time to develop. They produce “primordial soups,” pocket environments full of useful molecules for life, a steady energy source, and self-perpetuating chemical reactions. We think this happened at least once to seed all life on Earth, but it may in fact be very common.</p>



<p>I think this story is an essential foundation for understanding evolution as life does it. Because life didn’t start this process. The universe provides energy and raw materials in vast amounts. It provides the chaos and entropy that drives seemingly random variation, and the slow, continual breaking down that causes natural selection to prefer stable, commonly made forms. The laws of physics cause the universe to evolve towards stability, diversity, and complexity, at least for a while, until it starts to wind down again and settle into entropy. Life merely <em>constrains</em> that process, making it more efficient and productive, for the simple reason that matter that does so becomes more prevalent.</p>



<p>In these primordial soups, some chemical systems evolved to enclose themselves in bubbles, protecting delicate reactions from the outside world. These self-made &#8220;individuals&#8221; evolved regular cycles of reproduction, explicitly making copies of themselves rather than waiting for the right reactants to come together again by chance. They evolved DNA to constrain these copies, and make them more precise reproductions of the original. They evolved sophisticated error checking, which made the copies more robust and reliable. But this also gave life the power to <em>manage</em> variation across generations, and thus shape its own evolution. Life evolved sex to further manage variation, accelerating innovation by sharing genetic recipes across lineages. Life evolved an <em>astonishing variety</em> of sexual and reproductive practices, allowing it to evolve in different ways, with different patterns of variation and selection, each suited to a different range of environments and lifestyles.</p>



<p>The physical Universe evolves—in the most primitive way imaginable, but it still produces stability and complexity in a <em>vast</em> number of diverse forms. It generates the seeds of life, without any guidance or direction. Life evolves differently, because it constrains this process, making it discrete, digital, and managed. This started very simply, just discovering chemical reactions that isolate and maintain themselves. But perhaps this is the origin of what we think of as “intelligence” or “agency”? Without noticing, matter became “opinionated,” preferring certain forms and acting explicitly to promote them. From there, life’s “opinions” about itself only became more demanding and elaborate.</p>



<p>We often present evolution as one simple story, but there are many ways to evolve. Evolution is more like a general principle than a specific algorithm. Even just life as we know it, all based on the DNA molecule, has invented an <em>astonishing</em> variety of different and complex ways of evolving. Bacteria, fungi, plants, and animals <em>use</em> DNA differently. They grow, behave, and reproduce in <em>completely</em> different ways. How many other ways might there be to do it? When we present evolution as a single, constant thing, we limit our imagination. Evolution evolves, and it takes as many diverse forms as it makes.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://thinkingwithnate.wordpress.com/2024/10/02/the-universe-evolves/feed/</wfw:commentRss>
			<slash:comments>20</slash:comments>
		
		
		
		<media:thumbnail url="https://thinkingwithnate.wordpress.com/wp-content/uploads/2024/09/stsci-01g77pkya4t05ykj3edq36nzcx.png" />
		<media:content url="https://thinkingwithnate.wordpress.com/wp-content/uploads/2024/09/stsci-01g77pkya4t05ykj3edq36nzcx.png" medium="image">
			<media:title type="html">STScI-01G77PKYA4T05YKJ3EDQ36NZCX</media:title>
		</media:content>

		<media:content url="https://0.gravatar.com/avatar/39ae42d33af99a13fa6ef7e7c81e595cc0e2e241e360bb495dc7e4c89ab517fd?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">nategaylinn</media:title>
		</media:content>
	</item>
		<item>
		<title>Status Update: Semester 3</title>
		<link>https://thinkingwithnate.wordpress.com/2024/09/29/status-update-semester-3/</link>
					<comments>https://thinkingwithnate.wordpress.com/2024/09/29/status-update-semester-3/#comments</comments>
		
		<dc:creator><![CDATA[Nate Gaylinn (he/him)]]></dc:creator>
		<pubDate>Sun, 29 Sep 2024 14:17:46 +0000</pubDate>
				<category><![CDATA[Status Updates]]></category>
		<category><![CDATA[ai]]></category>
		<category><![CDATA[antibiotic resistance]]></category>
		<category><![CDATA[artificial-intelligence]]></category>
		<category><![CDATA[computer vision]]></category>
		<category><![CDATA[deep learning]]></category>
		<category><![CDATA[endosymbiosis]]></category>
		<category><![CDATA[evolution]]></category>
		<category><![CDATA[game of life]]></category>
		<category><![CDATA[machine-learning]]></category>
		<category><![CDATA[research]]></category>
		<category><![CDATA[technology]]></category>
		<guid isPermaLink="false">http://thinkingwithnate.wordpress.com/?p=252</guid>

					<description><![CDATA[I’m at an interesting moment in my studies, so I thought I’d let you know what’s going on! Year two of my PhD program has begun. I’m about a month into my third semester, and things are going well. I’m taking two classes right now: Evolutionary Computation, and Deep Learning. Most of my Computer Science &#8230; <a href="https://thinkingwithnate.wordpress.com/2024/09/29/status-update-semester-3/" class="more-link">Continue reading<span class="screen-reader-text"> "Status Update: Semester&#160;3"</span></a>]]></description>
										<content:encoded><![CDATA[
<p>I’m at an interesting moment in my studies, so I thought I’d let you know what’s going on!</p>



<p>Year two of my PhD program has begun. I’m about a month into my third semester, and things are going well. I’m taking two classes right now: Evolutionary Computation, and Deep Learning. Most of my Computer Science education has been about how to design algorithms and write software to solve different kinds of problems, but these classes are different. This semester, I’m learning how to get computers to discover their own algorithms, and write their own software. Honestly, the state of the art here is still quite primitive. We’ve found some very impressive techniques, but they each apply to a narrow domain, and we don’t understand them nearly as well as we’d like. Which makes them fun topics to study. <img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f642.png" alt="🙂" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>



<p>The other fun thing about this semester is that both of my classes are built around student projects. More or less, I get to pick projects that fit with my research, and the class is there to help me find the time, resources, and guidance to complete the projects successfully. I like this much better than undergraduate style courses built around assignments and exams that are very generic and may not be relevant to my work. We’ll see how things unfold, but I’m currently planning to work on two projects that I’m excited about.</p>



<p>For Evolutionary Computation, I’m working on an experiment about endosymbiosis. I was inspired by <a href="https://www.youtube.com/watch?v=yybsSqcB7mE">this classic experiment</a>, which examined how bacteria evolve antibiotic resistance, and how genetic innovations spread through the population spatially. I’m going to try evolving a host environment that supports an inner population, a bit like how my gut supports a microbiome. The hope is that the host will be able to design a supportive environment, with different regions that cultivate “microbes” with different traits, such that it can guide and coax them into evolving more specialized forms. This is an exciting experiment for me, because I’m not sure what to expect, but I’m pretty confident that <em>something</em> interesting will happen.</p>



<p><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXdXXQwS7goi1ItbTdONUzbfEiFKBIKils0XIfkXZl1xwzGxuTrV76lD5OFiNLNtXdXMpPz_do1AW3qdFEFbe4loZzIcjVBTtC7ciQbwbYhN1TQMr3tf_AuT-skSA-X_9lOauzGL31dv3Lj7hQqRBu0stv8?key=F266DdYKyjrziMBoqIpF8A" alt="A screenshot from the video linked above, showing strains of bacteria gradually growing into bands with increasing concentrations of antibiotic, fanning out from points where key mutations occurred."></p>



<p class="has-small-font-size">A screenshot from the video linked above, showing strains of bacteria gradually growing into bands with increasing concentrations of antibiotic, fanning out from points where key mutations occurred.</p>



<p>For Deep Learning, I’m going to use computer vision techniques to detect interesting patterns in the <a href="https://conwaylife.com/">Game of Life</a>, since I’ve been using that as an environment for my evolution experiments. The Game of Life has very simple rules, but it evolves in complex ways. Most patterns quickly dissolve into empty space or settle into a few boring, stable forms. But rarely, you get something much more interesting. For decades, people have been exploring this space, finding interesting patterns and classifying them. You get huge complex structures that stabilize themselves, change continuously in repeating cycles, or even propel themselves and move at a steady pace. I’ll build a system that can detect and categorize these patterns, so that when my evolutionary algorithm finds them, I can reward it and ask for “more like that.”</p>



<figure class="wp-block-table aligncenter"><table class="has-fixed-layout"><tbody><tr><td><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfHtu6cHt8izDgOPsqUFq4LlQe2-X9tsFJeeQNfCy7dsr2MNlzludfJDIpQuRxRAEmU7z0gNqIq-eBjqp1gmoTIqjp2sK94w04bPiAHszCiEfa4FwojIinklOwzL-BWHctVrs5WeZI7qsfNyWjZP00Imjs?key=F266DdYKyjrziMBoqIpF8A" alt="Eater 2, a static shape that persists forever, but has the special property of being able to “eat” gliders that collide with it, recovering its shape after."></td><td><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXf6gA-5OxaNWa0rKpTU7QzHUOYa_S6pBQAYecuiFWR2okztfSwoAGHL03vZ2SLEmiOcFqdvR3VtTw1Nx0tOo1TBJIx9SoLRmOrbvpQ0xbNntupupQ0z_0TDxO84pcfSf6ZCpXl1ZsgVeZCc5IYoVw5MzPw?key=F266DdYKyjrziMBoqIpF8A" alt="Monogram, a period-four oscillator, which is small, but occurs very rarely from random conditions."></td><td><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXeay7S7PMLnfhvkF5wDd3pkukQeU7IFpsWUpbiR0pvW1V5kwEMn7APgkIip4UlvIjhC8BriCsHD4CC2fi_tBVn_64enDOPCPizrxglozcs735sNys9mU2V-Qo6Ue4FHwRCfnz-dhRIpD0ekMLexD08RF2xz?key=F266DdYKyjrziMBoqIpF8A" alt=""></td></tr></tbody></table></figure>



<p class="has-small-font-size">Examples of interesting patterns in the Game of Life. <a href="https://conwaylife.com/wiki/Eater_2">The first</a> is a static shape that persists forever, but has the special property of being able to “eat” <a href="https://conwaylife.com/wiki/Glider">gliders</a> that collide with it, recovering its shape after. <a href="https://conwaylife.com/wiki/Monogram">The second</a> is a period-four oscillator, which is small, but occurs very rarely from random conditions. <a href="https://conwaylife.com/wiki/Middleweight_spaceship">The third</a> is a middleweight spaceship, which moves forward two spaces as it repeats itself in four time steps.</p>



<p>This month’s essay is inspired by my Evolutionary Computation class, and the work I’ve been doing to develop the specific research questions I want to focus on for my PhD. So, check back on Wednesday to learn more about how evolution got started, and why it’s worth asking: how does evolution evolve?</p>
]]></content:encoded>
					
					<wfw:commentRss>https://thinkingwithnate.wordpress.com/2024/09/29/status-update-semester-3/feed/</wfw:commentRss>
			<slash:comments>7</slash:comments>
		
		
		
		<media:content url="https://0.gravatar.com/avatar/39ae42d33af99a13fa6ef7e7c81e595cc0e2e241e360bb495dc7e4c89ab517fd?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">nategaylinn</media:title>
		</media:content>

		<media:content url="https://lh7-rt.googleusercontent.com/docsz/AD_4nXdXXQwS7goi1ItbTdONUzbfEiFKBIKils0XIfkXZl1xwzGxuTrV76lD5OFiNLNtXdXMpPz_do1AW3qdFEFbe4loZzIcjVBTtC7ciQbwbYhN1TQMr3tf_AuT-skSA-X_9lOauzGL31dv3Lj7hQqRBu0stv8?key=F266DdYKyjrziMBoqIpF8A" medium="image">
			<media:title type="html">A screenshot from the video linked above, showing strains of bacteria gradually growing into bands with increasing concentrations of antibiotic, fanning out from points where key mutations occurred.</media:title>
		</media:content>

		<media:content url="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfHtu6cHt8izDgOPsqUFq4LlQe2-X9tsFJeeQNfCy7dsr2MNlzludfJDIpQuRxRAEmU7z0gNqIq-eBjqp1gmoTIqjp2sK94w04bPiAHszCiEfa4FwojIinklOwzL-BWHctVrs5WeZI7qsfNyWjZP00Imjs?key=F266DdYKyjrziMBoqIpF8A" medium="image">
			<media:title type="html">Eater 2, a static shape that persists forever, but has the special property of being able to “eat” gliders that collide with it, recovering its shape after.</media:title>
		</media:content>

		<media:content url="https://lh7-rt.googleusercontent.com/docsz/AD_4nXf6gA-5OxaNWa0rKpTU7QzHUOYa_S6pBQAYecuiFWR2okztfSwoAGHL03vZ2SLEmiOcFqdvR3VtTw1Nx0tOo1TBJIx9SoLRmOrbvpQ0xbNntupupQ0z_0TDxO84pcfSf6ZCpXl1ZsgVeZCc5IYoVw5MzPw?key=F266DdYKyjrziMBoqIpF8A" medium="image">
			<media:title type="html">Monogram, a period-four oscillator, which is small, but occurs very rarely from random conditions.</media:title>
		</media:content>

		<media:content url="https://lh7-rt.googleusercontent.com/docsz/AD_4nXeay7S7PMLnfhvkF5wDd3pkukQeU7IFpsWUpbiR0pvW1V5kwEMn7APgkIip4UlvIjhC8BriCsHD4CC2fi_tBVn_64enDOPCPizrxglozcs735sNys9mU2V-Qo6Ue4FHwRCfnz-dhRIpD0ekMLexD08RF2xz?key=F266DdYKyjrziMBoqIpF8A" medium="image" />
	</item>
		<item>
		<title>GECCO Follow-Up</title>
		<link>https://thinkingwithnate.wordpress.com/2024/08/07/gecco-follow-up/</link>
					<comments>https://thinkingwithnate.wordpress.com/2024/08/07/gecco-follow-up/#comments</comments>
		
		<dc:creator><![CDATA[Nate Gaylinn (he/him)]]></dc:creator>
		<pubDate>Wed, 07 Aug 2024 12:46:25 +0000</pubDate>
				<category><![CDATA[Snack-Sized]]></category>
		<category><![CDATA[Status Updates]]></category>
		<category><![CDATA[algorithm]]></category>
		<category><![CDATA[CPPNs]]></category>
		<category><![CDATA[endosymbiosis]]></category>
		<category><![CDATA[evolution]]></category>
		<category><![CDATA[evolutionary computation]]></category>
		<category><![CDATA[GECCO]]></category>
		<category><![CDATA[paper]]></category>
		<category><![CDATA[research]]></category>
		<category><![CDATA[school]]></category>
		<guid isPermaLink="false">http://thinkingwithnate.wordpress.com/?p=245</guid>

					<description><![CDATA[(I took this post’s photo at the Star Trek Original Series Set Tour in Ticonderoga, New York. It’s a view of the warp core of the USS Enterprise, which is only a few feet deep but looks much larger thanks to forced perspective. The room is filled with structures with complicated geometric shapes, technical looking &#8230; <a href="https://thinkingwithnate.wordpress.com/2024/08/07/gecco-follow-up/" class="more-link">Continue reading<span class="screen-reader-text"> "GECCO Follow-Up"</span></a>]]></description>
										<content:encoded><![CDATA[
<p>(I took this post’s photo at the Star Trek Original Series Set Tour in Ticonderoga, New York. It’s a view of the warp core of the USS Enterprise, which is only a few feet deep but looks much larger thanks to forced perspective. The room is filled with structures with complicated geometric shapes, technical looking panels, and dramatic lighting in red, blue, and purple.)</p>



<p>In my last post, I wrote about my latest research project and why I was so excited to present it at GECCO, the premier conference for evolutionary computation. I promised a follow-up, and here it is! Unfortunately, I didn’t make it to Melbourne. Instead, I had a very complicated and protracted battle with my University’s travel planning system, United Airlines, and the Australian visa office, all from the comfort of my home in Vermont. I couldn’t even participate in the event remotely, because of the time zone difference. This is all very disappointing, but I tried to make the best of it. I’ve been busy with the next iteration of this project, and enjoying a bit of “staycation” time here in New England (hence this month’s cover photo).</p>



<p>In any case, my paper <em>did</em> get published, and I’d still like to share the materials I presented virtually at the conference. It’s mostly intended for a technical audience, but I hope at least some of my readers will find it interesting. The paper is titled <a href="https://dl.acm.org/doi/10.1145/3638530.3654259">A Meta-Evolutionary Algorithm for Co-evolving Genotypes and Genotype / Phenotype Maps</a>, and is available for free online. I had to cut it down to just four pages, since it was accepted as a poster, so I also wrote up an <a href="https://github.com/ngaylinn/epigenetic-gol-prototype-results/blob/main/ANALYSIS.md">extended analysis of my results</a> and an <a href="https://github.com/ngaylinn/epigenetic-gol-v1/blob/main/README.md">hoverview of my algorithm&#8217;s implementation</a>,  for those who want to go deeper. There&#8217;s also a digital version of my <a href="https://drive.google.com/file/d/1o3x58W46RPuXOkqY6NavS6ndpeaEgiZB/view?usp=drive_link">poster</a> and a <a href="https://drive.google.com/file/d/10Ej09sxSULmzwNd65EPQInTUySmsUtiq/view?usp=drive_link">short video</a> overview of my experiment.</p>



<p>I continue to work on this idea, and it is starting to evolve beyond what I presented in that paper. Right now, I’m actively deconstructing and rebuilding the algorithm. CPPNs are an important and well known part of the AI field, so I’m trying to describe precisely how my algorithm is different, and which of those differences account for the remarkable results I found. Originally I thought of this research as being about epigenetics specifically, but as I try to generalize and simplify, what I’m left with looks like straight-up endosymbiosis. I’ve been thinking of this algorithm as a metaphor for a cell and its genes / nucleus, but it could just as easily be a metaphor for an animal and its community of microbes. This is exciting, since I’d love to do more research on endosymbiosis, and I really like the idea that perhaps symbiosis is the driving force behind intelligence as we know it, fundamentally changing the dynamics of evolution.</p>



<p>Anyway, that’s how I see it for the moment, and where I hope my research will lead in the near future. For now, though, I’m wrapping up my summer with a few more fun outings, and preparing for the start of classes later this month. I’ll be diving deep into both evolutionary computation and deep learning, which I’m really looking forward to.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://thinkingwithnate.wordpress.com/2024/08/07/gecco-follow-up/feed/</wfw:commentRss>
			<slash:comments>2</slash:comments>
		
		
		
		<media:thumbnail url="https://thinkingwithnate.wordpress.com/wp-content/uploads/2024/08/enterprise_engine_room.jpg" />
		<media:content url="https://thinkingwithnate.wordpress.com/wp-content/uploads/2024/08/enterprise_engine_room.jpg" medium="image">
			<media:title type="html">enterprise_engine_room</media:title>
		</media:content>

		<media:content url="https://0.gravatar.com/avatar/39ae42d33af99a13fa6ef7e7c81e595cc0e2e241e360bb495dc7e4c89ab517fd?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">nategaylinn</media:title>
		</media:content>
	</item>
		<item>
		<title>Why the Game of Life Paper?</title>
		<link>https://thinkingwithnate.wordpress.com/2024/07/03/why-the-game-of-life-paper/</link>
					<comments>https://thinkingwithnate.wordpress.com/2024/07/03/why-the-game-of-life-paper/#comments</comments>
		
		<dc:creator><![CDATA[Nate Gaylinn (he/him)]]></dc:creator>
		<pubDate>Wed, 03 Jul 2024 16:35:53 +0000</pubDate>
				<category><![CDATA[Personal Reflections]]></category>
		<category><![CDATA[Status Updates]]></category>
		<category><![CDATA[ai]]></category>
		<category><![CDATA[alife]]></category>
		<category><![CDATA[CPPNs]]></category>
		<category><![CDATA[evolution]]></category>
		<category><![CDATA[evolutionary computation]]></category>
		<category><![CDATA[evolvability]]></category>
		<category><![CDATA[experiment]]></category>
		<category><![CDATA[GECCO]]></category>
		<category><![CDATA[publishing]]></category>
		<category><![CDATA[science]]></category>
		<category><![CDATA[slime mold]]></category>
		<guid isPermaLink="false">http://thinkingwithnate.wordpress.com/?p=240</guid>

					<description><![CDATA[(This month’s image is a slime mold growing on a log. It grows in a branching network of banana-yellow tendrils, some of which are engulfing plant debris they encountered. Source) Later this month, I’ll be attending the Genetic and Evolutionary Computing Conference (GECCO) in Melbourne, Australia. I’m super excited to go, and to present my &#8230; <a href="https://thinkingwithnate.wordpress.com/2024/07/03/why-the-game-of-life-paper/" class="more-link">Continue reading<span class="screen-reader-text"> "Why the Game of Life&#160;Paper?"</span></a>]]></description>
										<content:encoded><![CDATA[
<p>(This month’s image is a slime mold growing on a log. It grows in a branching network of banana-yellow tendrils, some of which are engulfing plant debris they encountered. <a href="https://sitn.hms.harvard.edu/flash/2016/slime-molds-capable-passing-learned-behaviors-new-cell-populations/">Source</a>)</p>



<p>Later this month, I’ll be attending the <a href="https://gecco-2024.sigevo.org/HomePage">Genetic and Evolutionary Computing Conference</a> (GECCO) in Melbourne, Australia. I’m super excited to go, and to present my very first published academic paper as a poster. I’ll share more here when all is said and done, but unfortunately my paper isn’t really intended for a general audience, like this blog. It would probably be hard to understand for anyone outside of the fields of AI or ALife. So, for everybody else, I’d like to share what the paper means to me, and what I’m trying to say by publishing it.</p>



<p>My research is inspired by epigenetics, and new ways of thinking about evolution. I saw that life doesn’t just evolve by chance, it evolves to become more evolvable. It learns how to explore the range of possible forms and lifestyles more efficiently, and to nudge evolution down more fruitful paths. Life uses its intelligence to become more intelligent still. In my mind, this changes <em>everything</em> about evolution, and I was shocked it wasn’t more well known. Most discussions of evolution (and the programmer version: evolutionary computation, or EC) are too simple, and ignore these critical details. So, I figured I’d be the one to bring this up, and show people why it matters.</p>



<p>I started my first experiment before I even got to university. I was so excited by the idea, I just had to get it out of my head. I actually avoided looking for prior work, because I wanted to see how <em>I</em> would manifest this idea without being biased by other people’s thinking. Besides, I didn’t know of any research like mine, and I didn’t know how to find it, either. That’s why I applied to UVM. When I got here, my advisor and lab mates encouraged me to publish this project, and pointed me at the relevant literature. So I hit the books, reading all that had been done before in order to put my own work into context.</p>



<p>And, of course, I found I’m not the first to have this idea. There are many variations of EC inspired by biology, looking for the “secret sauce” that makes life more powerful than our computer models. In particular, how life evolves to be more evolvable is an active area of research, which has been building momentum in recent years. At first, I was disappointed. My idea was already taken! So much of what I thought made my project interesting had been tried before in some other context. But not exactly. Identifying those subtle differences has been tremendously helpful.</p>



<p>You see, it’s pretty well established now that “evolvability” is important. In our experiments, simulated life that’s more evolvable finds fitter solutions faster. It’s better at adapting to changing circumstances, too. It seems to be smarter and more creative. I find this exhilarating, yet these discoveries didn’t “change everything” like I had hoped. In the experiments so far, it feels like an incremental improvement. It helps, but not enough to draw much attention away from other areas of AI research, like deep learning, which is seen as much more powerful and more productive.</p>



<p>I think that’s because we still haven’t broken out of our old ways of thinking. Traditional EC is all about finding good solutions to a problem, but I would argue that evolution isn’t about problem solving. It’s about problem <em>finding</em>. Life explores the space of possible lifestyles to find and exploit <em>opportunities</em>. The evolution of life is a bit like a slime mold. It grows simultaneously in all directions, questing around obstacles to find resources, reinforcing the branches that get lucky, culling back the ones that don’t. It doesn’t have a top-down view of the world, but it’s still <em>strategic</em> and <em>adaptive</em>. When I look at most of the existing experiments in this space, I feel like we’re putting a slime mold into a narrow tunnel and measuring how fast it can get to the other end. We’re accidentally putting evolution in a straight jacket, and blinding ourselves to what makes it so interesting and powerful.</p>



<p>So, in my first experiment, I try to show a different perspective. I made a single algorithm that can adapt itself to solve many <em>different</em> tasks. Normally, an EC programmer picks one task to solve, then designs an evolutionary search strategy to suit that problem. They invent a genome language, a way of turning that into a solution, and ways of randomly tweaking the genome that might lead to better solutions. In my experiment, I evolved the search strategy, too. As the programmer, I designed a vast and open ended search domain, and many ways that the algorithm could restrict that space. But I wasn’t sure which restricted sub-spaces would work best, and, unlike traditional EC, I didn’t try to guess. I just let the algorithm figure that out for itself.</p>



<p>The way I did this is also interesting. It turns out, the algorithm I invented is strikingly similar to one that’s already popular: “compositional pattern-producing networks,” or CPPNs. Again, it was a little frustrating to be scooped, but I’m using this algorithm in a new way. Instead of evolving new “bodies” for simulated life, I’m evolving new <em>ways of generating</em> bodies. It’s a subtle difference, but an important one, I think. That extra level of indirection gives evolution more influence over its destiny, and the power to make more complex patterns in ways I couldn’t even anticipate. Now that I know how my idea is so similar to, yet different from, an existing algorithm, I’m teasing apart those differences, to measure the impact of each one.</p>



<p>I’m proud of my work, and excited to talk about it with other EC enthusiasts at GECCO. On the other hand, I’m still figuring out how to do science, and there’s a lot I <em>don’t</em> like about my first paper. This project was mostly my way of proving to myself that this crazy idea could work. The results are intriguing, but it’s not yet a clear example of what I want to show. It’s also complicated, unusual, and hard to explain, even to other EC researchers. If I want people to get excited about this, I need to simplify, make my work more relatable, and find better ways to demonstrate and measure the novel behavior I’m talking about here. There are no “obstacle courses for slime molds” in the EC literature that I know of, so perhaps I’ll need to design some.</p>



<p>Hopefully, I’ll get lots of inspiration and feedback at GECCO. As I learn more about the field of EC, I’m finding more and more examples of work similar, yet slightly different, from my own. This is great, because each of those differences is an opportunity for a new experiment, to see if my perspective can shed light on something new. I’m already dreaming up all sorts of new ways to explore my ideas. And that’s more or less how I hope to spend the next several years. Maybe <em>that’s</em> my PhD.</p>



<p>In any case, I hope that explanation was interesting, and not too vague. I’ll get more specific in a few weeks, when I post a follow up with the full GECCO paper, the poster I presented, a video summary of that poster, and links to some supplemental results and analysis. I bet I’ll have some fun things to report from my time in Melbourne, too! As always, I’d love to hear from you in the comments.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://thinkingwithnate.wordpress.com/2024/07/03/why-the-game-of-life-paper/feed/</wfw:commentRss>
			<slash:comments>9</slash:comments>
		
		
		
		<media:thumbnail url="https://thinkingwithnate.wordpress.com/wp-content/uploads/2024/07/physarum_polycephalum2.jpg" />
		<media:content url="https://thinkingwithnate.wordpress.com/wp-content/uploads/2024/07/physarum_polycephalum2.jpg" medium="image">
			<media:title type="html">Physarum_polycephalum2</media:title>
		</media:content>

		<media:content url="https://0.gravatar.com/avatar/39ae42d33af99a13fa6ef7e7c81e595cc0e2e241e360bb495dc7e4c89ab517fd?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">nategaylinn</media:title>
		</media:content>
	</item>
		<item>
		<title>Queerness</title>
		<link>https://thinkingwithnate.wordpress.com/2024/06/01/queerness/</link>
					<comments>https://thinkingwithnate.wordpress.com/2024/06/01/queerness/#comments</comments>
		
		<dc:creator><![CDATA[Nate Gaylinn (he/him)]]></dc:creator>
		<pubDate>Sat, 01 Jun 2024 13:03:14 +0000</pubDate>
				<category><![CDATA[Armchair Philosophy]]></category>
		<category><![CDATA[Theory]]></category>
		<category><![CDATA[categories]]></category>
		<category><![CDATA[gender]]></category>
		<category><![CDATA[identity]]></category>
		<category><![CDATA[labels]]></category>
		<category><![CDATA[language]]></category>
		<category><![CDATA[ontology]]></category>
		<category><![CDATA[philosophy]]></category>
		<category><![CDATA[queer]]></category>
		<category><![CDATA[race]]></category>
		<category><![CDATA[sexuality]]></category>
		<guid isPermaLink="false">http://thinkingwithnate.wordpress.com/?p=237</guid>

					<description><![CDATA[It&#8217;s LGBTQ+ Pride month! I identify as “queer,” so I thought this would be a good opportunity to write a bit about what that means to me. In addition to queer, I also identify as a cisgender male, pansexual, and demisexual. This means I’ve always identified as male, and others always assumed as much. I’m &#8230; <a href="https://thinkingwithnate.wordpress.com/2024/06/01/queerness/" class="more-link">Continue reading<span class="screen-reader-text"> "Queerness"</span></a>]]></description>
										<content:encoded><![CDATA[
<p>It&#8217;s LGBTQ+ Pride month! I identify as “queer,” so I thought this would be a good opportunity to write a bit about what that means to me.</p>



<p>In addition to queer, I also identify as a cisgender male, pansexual, and demisexual. This means I’ve always identified as male, and others always assumed as much. I’m rarely interested in sex or romance, but when I am, it’s not about gender. I love people, not parts. The full story is more complicated, but that’s a good start.</p>



<p>Labels like “gay”, “bi”, “pan”, “cis”, “demi”, “aro”, and “ace” are useful for quickly describing myself to others, but I prefer the term “queer” because, honestly, I don’t think any set of labels does a person justice.</p>



<p>Gender and sexuality are fundamentally personal things. Each individual is unique. No set of labels can capture all of who I am, and every label carries some baggage that I don’t want applied to me. Labels are useful, just so long as we remember that they’re always at least a little bit wrong. They cannot serve as a stand-in for a person.</p>



<p>I also love queer philosophy, and try to embrace it in all my thinking. Put simply, that means I don’t believe in categories. I don’t think they have any real existence, or essential qualities. They’re convenient fictions. Just labels we make up to point at collections of disparate things. This applies to all categories, but <em>especially</em> to living things, where there are exceptions to every rule, and no hard boundaries whatsoever.</p>



<p>The problem with categories is that we take them seriously. Once we categorize something, we think we understand it, when really we’re just projecting a stereotype. We make strong assumptions about what’s allowed in a category, and we struggle with exceptions, even common ones. As our understanding of the world changes, things often shift faster than our language can keep up with. Sometimes we don’t notice. We keep trying to sort the world into categories that make no sense, and get upset when reality doesn’t play along.</p>



<p>So, I don’t believe that Jews exist. I believe that Jewish <em>people</em> exist, and that we use the word “Jews” to refer to them. Yet, there’s no one quality that all of those people share, except that they are people (another category, subject to change). You and I may not even agree about which set of people the word “Jews” applies to, so how is it meaningful for us to talk about Jews in general?</p>



<p>I don’t think it’s strange to see a Black woman engineer, even though it’s rare. I wouldn’t expect her to be any less competent, just because most folks like her can’t do the job. If anything, I’d assume the opposite, if she can succeed in that role despite the weight of her labels. But, ultimately, it’s about what she has to offer the world, which is surely more and less than the other engineers around her. She has her unique way of doing it, perhaps different in exciting ways.</p>



<p>That’s what queer means to me. Labels can be useful, but they have no power over reality. Reality and people are so much more than words can contain. See them for what they are.</p>



<p>If you’d like to learn more about queerness and queer philosophy, I highly recommend <em><a href="https://www.iconbooks.com/ib-title/queer-a-graphic-history/">Queer: A Graphic History</a></em> by Meg-John Barker and Jules Scheele.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://thinkingwithnate.wordpress.com/2024/06/01/queerness/feed/</wfw:commentRss>
			<slash:comments>2</slash:comments>
		
		
		
		<media:content url="https://0.gravatar.com/avatar/39ae42d33af99a13fa6ef7e7c81e595cc0e2e241e360bb495dc7e4c89ab517fd?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">nategaylinn</media:title>
		</media:content>
	</item>
		<item>
		<title>The Brain&#8217;s &#8220;Boss&#8221;</title>
		<link>https://thinkingwithnate.wordpress.com/2024/04/03/the-brains-boss/</link>
					<comments>https://thinkingwithnate.wordpress.com/2024/04/03/the-brains-boss/#comments</comments>
		
		<dc:creator><![CDATA[Nate Gaylinn (he/him)]]></dc:creator>
		<pubDate>Wed, 03 Apr 2024 15:26:58 +0000</pubDate>
				<category><![CDATA[Animal Minds]]></category>
		<category><![CDATA[Introspection]]></category>
		<category><![CDATA[brains]]></category>
		<category><![CDATA[collectives]]></category>
		<category><![CDATA[control]]></category>
		<category><![CDATA[health]]></category>
		<category><![CDATA[meditation]]></category>
		<category><![CDATA[mental-health]]></category>
		<category><![CDATA[minds]]></category>
		<category><![CDATA[neuroscience]]></category>
		<category><![CDATA[pfc]]></category>
		<category><![CDATA[pilot]]></category>
		<category><![CDATA[prefrontal cortex]]></category>
		<category><![CDATA[psychology]]></category>
		<category><![CDATA[self]]></category>
		<guid isPermaLink="false">http://thinkingwithnate.wordpress.com/?p=232</guid>

					<description><![CDATA[(this post&#8217;s image is a cross stitch I made from a pattern by Studio Ansitru. The phrase &#8220;don&#8217;t be a prick&#8221; is surrounded by a variety of cacti in pretty greens and oranges on a light blue background. In my home, it serves as a reminder to myself and to my guests.) A popular metaphor &#8230; <a href="https://thinkingwithnate.wordpress.com/2024/04/03/the-brains-boss/" class="more-link">Continue reading<span class="screen-reader-text"> "The Brain&#8217;s &#8220;Boss&#8221;"</span></a>]]></description>
										<content:encoded><![CDATA[
<p>(this post&#8217;s image is a cross stitch I made from <a href="https://studioansitru.bigcartel.com/product/don-t-be-a-prick-digital-download-only">a pattern by Studio Ansitru</a>. The phrase &#8220;don&#8217;t be a prick&#8221; is surrounded by a variety of cacti in pretty greens and oranges on a light blue background. In my home, it serves as a reminder to myself and to my guests.)</p>



<p>A popular metaphor for the mind is a pilot sitting in a cockpit, monitoring the senses and making every decision. This is obviously nonsense, but it’s an intuitive and helpful metaphor at times. The brain really does have “an executive” that thinks and plans and makes decisions, it just doesn’t have “a mind of its own,” and its power over the self is surprisingly limited. Self-control and -awareness are important for living a good life, being productive, and making ethical decisions. Unfortunately, when these faculties fail, as they often do, it&#8217;s easy to blame yourself. I find it helps to understand how these systems work, so I can set more realistic expectations for myself, which makes me less disappointed when things go awry.</p>



<p>Perhaps the most important thing to know about the brain is that it’s not one, unified thing. Brains are modular, with many distinct regions specialized for different tasks. Each region has different inputs and outputs, meaning they each monitor the world in different ways from different perspectives, and can cause different behaviors. Observations, insights, desires, and actions can originate in pretty much any part of the brain. All of these different regions operate together at the same time, and conscious experience is an integration of all that activity. What I think, feel, believe, and do is mostly the product of what specific regions in my brain activate together, and in what order.</p>



<p>This story of how brains work is surprisingly consistent across the animal kingdom. Even very simple creatures, like <a href="https://www.goodreads.com/review/show/5010568365">honey bees</a> for instance, have complex brains with specialized regions and global integration that likely creates a sort of conscious awareness. It seems likely, however, that bees lack the sort of self-awareness and top-down control that humans do. Without it, the brain is more chaotic. Each part tries to do the right thing more or less independently. Integration means that most faculties are aware of each other and can influence each other, so there is some coordination and consistency. But focus is mostly determined by which brain region is loudest, and decisions happen moment by moment, without planning or intentional coherence.</p>



<p>Decentralized brains work extremely well, but they have their limitations. More complex animals have more versatile behaviors that need more explicit coordination to generate coherent, reliable, and goal-directed behavior. Most large animals seem to have this ability. In all mammals, it’s more or less identified with a brain region known as the prefrontal cortex, or PFC. The PFC is responsible for monitoring all the activity in the brain. It builds up a rich model of the self, its relationships, needs, and long-term goals. It’s responsible for planning and for exerting control over other parts of the brain. It can shut out distractions and use willpower to encourage good behaviors and discourage bad ones, even when I’d selfishly prefer to do something else.</p>



<p><em>The PFC tells the story of “you,” and has strong opinions about how that story is supposed to go.</em></p>



<p>Although all mammals have a PFC (and many other species have something analogous), the relative <em>size</em> of the PFC varies quite a bit between species, and that seems to correlate with executive control and what people often think of as “intelligence.” Animals with large PFCs are better at self-control, problem solving, and forming complex social relationships. Humans have exceptionally large PFCs, which partly explains why we’re so different from other species. It’s important to remember, though, this is a difference in magnitude, not in kind. It’s likely that <em>every</em> mammal and <em>many</em> other species have human-like self-awareness and self-control. It’s just a weaker faculty for them, one that acts less often, and is less able to dominate the rest of the mind.</p>



<p>The PFC is the closest thing to a “pilot” the brain has, but it’s better to think of it as just one brain region among many. It’s one voice in a chorus. It tends to be more bossy, spending a lot of energy trying to influence or even override other parts of the brain, but it’s not “in control.” Like a corporate executive, the PFC has only limited visibility into what the rest of the brain is doing, can’t afford to stay ever-vigilant, and can’t <em>force</em> a brain region to fall in line, especially when the orders run counter to that region’s nature. The PFC also isn’t capable of doing much on its own. It depends on the rest of the brain to notice things, interpret them, suggest actions, and implement them. All it can do is adjudicate and coordinate. It resolves conflict, makes plans, and advises each brain region about when and how to do its thing.</p>



<p>One consequence of all this is that self-control is actually a very limited and fragile thing. Often, my PFC just sits back and lets the rest of the brain work with minimal intervention. Usually that works great, but sometimes it means I miss something important. I may act out of impulse or habit and not notice until it’s too late that I’m going against my values, intentions, or best interests. Other times I know exactly what I <em>should</em> do, but can’t seem to make it happen. I feel unmotivated and uninspired. I can’t force myself to sit down, focus, and avoid distractions. Perhaps I’m grumpy, tired, or impatient and I do something rude or inappropriate without meaning to at all.</p>



<p>When this happens, it’s easy to blame myself. I lost control. I did something foolish. I acted selfishly and impulsively, like a bad person. In reality, though, this happens all the time, usually for mundane reasons that I have little control over. The PFC is energy intensive, so it gets impaired whenever my blood sugar is low, I’m tired, or I’m stressed. Other brain regions also have the ability to <em>interfere</em> with the PFC, especially the limbic system which manages emotions and the fight-or-flight response. Some diseases (like depression and long COVID) can cause “brain fog,” which is closely related to reduced executive function. It’s also possible to injure the PFC, from a stroke, a tumor, or a physical injury (as in the famous case of <a href="https://en.wikipedia.org/wiki/Phineas_Gage">Phineas Gage</a>).</p>



<p>Knowing this helps me feel a little less personally responsible when I have a lapse of self-control. It really is inevitable, common, and completely natural. Still, I want to have good judgment and do the right thing as much as possible! How do I do that? One answer is to simply be aware of my limitations and to work around them. I try to notice when I’m hungry, tired, or emotional and avoid making big decisions or socializing at those times. Instead, I might get a snack, take a break, or sleep on it so I feel more in control. The only other good technique I know is mindfulness meditation. Despite the mystical reputation, the main purpose of meditation is quite practical: it trains the PFC. By practicing the skill of observing the mind and exerting influence over it, I can build that muscle. It’s not a silver bullet, but meditation helps me use my PFC more often and more effectively, and it makes me more aware of when my PFC is in a weakened state.</p>



<p>So, in a sense, there really is a “pilot” in every brain. It’s just not an ever vigilant, intelligent, wise, and rational person. Instead, it’s one brain region out of many, with limited visibility and a narrow job description. The PFC observes what the other brain regions are seeing, thinking, and doing and uses that top-down view to nudge them into more coherent and effective patterns of behavior. It’s not “the self” and it’s not “in control.” In fact, it has very limited influence, isn’t always active, and even with training there are lots of common reasons it might grow weak or misbehave. For this reason, having great self-control is often less about will power in the moment, and more about avoiding temptation in the first place.</p>



<p>What do you think? Does this agree with your first-hand experience? Do you have any insights you could share about self-awareness, self-control, or motivation? What about being kind to yourself when your self-control inevitably falls short? If so, I’d love to hear from you in the comments.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://thinkingwithnate.wordpress.com/2024/04/03/the-brains-boss/feed/</wfw:commentRss>
			<slash:comments>7</slash:comments>
		
		
		
		<media:thumbnail url="https://thinkingwithnate.wordpress.com/wp-content/uploads/2024/04/prick.jpg" />
		<media:content url="https://thinkingwithnate.wordpress.com/wp-content/uploads/2024/04/prick.jpg" medium="image">
			<media:title type="html">prick</media:title>
		</media:content>

		<media:content url="https://0.gravatar.com/avatar/39ae42d33af99a13fa6ef7e7c81e595cc0e2e241e360bb495dc7e4c89ab517fd?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">nategaylinn</media:title>
		</media:content>
	</item>
		<item>
		<title>Pre-Genetic Life</title>
		<link>https://thinkingwithnate.wordpress.com/2024/01/12/pre-genetic-life/</link>
					<comments>https://thinkingwithnate.wordpress.com/2024/01/12/pre-genetic-life/#comments</comments>
		
		<dc:creator><![CDATA[Nate Gaylinn (he/him)]]></dc:creator>
		<pubDate>Fri, 12 Jan 2024 13:28:02 +0000</pubDate>
				<category><![CDATA[Snack-Sized]]></category>
		<category><![CDATA[dna]]></category>
		<category><![CDATA[extinction]]></category>
		<category><![CDATA[genetics]]></category>
		<category><![CDATA[life]]></category>
		<category><![CDATA[origins]]></category>
		<category><![CDATA[panspermia]]></category>
		<guid isPermaLink="false">http://thinkingwithnate.wordpress.com/?p=229</guid>

					<description><![CDATA[One thing that fascinates me about life on Earth is that it’s all built with proteins and genetics. Every living cell, even the most primitive microbe, has at its core a universal molecular-scale 3D printer, controlled by an evolved programming language, which gets read and error-corrected from a highly stable gigabit-scale molecular data storage medium &#8230; <a href="https://thinkingwithnate.wordpress.com/2024/01/12/pre-genetic-life/" class="more-link">Continue reading<span class="screen-reader-text"> "Pre-Genetic Life"</span></a>]]></description>
										<content:encoded><![CDATA[
<p>One thing that fascinates me about life on Earth is that it’s all built with proteins and genetics. Every living cell, even the most primitive microbe, has at its core a universal molecular-scale 3D printer, controlled by an evolved programming language, which gets read and error-corrected from a highly stable gigabit-scale molecular data storage medium (DNA).</p>



<p>In short, every living thing, every single cell, is a mechanism of astonishing complexity and sophistication, and they <em>all</em> share a common design. That’s wild. Life could not have started that way. The very first cells <em>must</em> have been much simpler and then evolved to be like this. But then… where are they? What happened to those pre-genetic cells? We’ve never found them. There are a few good answers to why, and I find them all fascinating.</p>



<p>One interesting possibility is that pre-genetic life is long gone. After all, it originated billions of years ago! Earth is a hostile place, and those early life forms must have been even more fragile than the ones we see today. Not to mention, there’s nothing life likes more than to <em>eat</em> other life. If “modern” cells with genetics outperformed their more primitive cousins, maybe they drove them extinct and replaced them?</p>



<p>Or, perhaps pre-genetic life never existed on this planet at all. Maybe the mechanism of genetics is so complex it needs much more time to evolve from scratch. Maybe the process got started elsewhere in the universe, and then got deposited here in cosmic debris. In that case, genetic cells just <em>colonized</em> Earth and adapted to living here. That’s an exciting possibility, because that might mean there’s more life “out there,” and we could find other living planets like our own.</p>



<p>Just as fascinating is the idea that pre-genetic life is still alive and well on this planet. That universal 3D printer for proteins is an incredibly powerful tool for cells, but its primary value is exploration. It makes it possible to invent new molecules and thus new lifestyles. It enables life to spread, complexify, and settle every corner of this planet.</p>



<p>But it doesn’t make the cell any better at living <em>one particular</em> lifestyle. It may be that cells evolved diversity to escape the dominance of the first life forms, that cornered their particular niche so well that finding a new niche was the only option. Perhaps genetics was invented to escape and branch out from this overcrowded primordial environment. If that’s the case, then maybe there’s a thriving colony of pre-genetic life, still clinging to a hydro-thermal vent somewhere, just as it has for billions of years. It’s terribly unlikely, but in theory, we could find it. How exciting would that be?</p>



<p>But what if pre-genetic life isn’t rare at all? What if we just can’t see it? Certainly, if it exists, it would be microscopic, and that already makes it very difficult to find and study. We’ve been cataloging single-celled organisms for centuries now, yet we’ve observed just a tiny fraction of them, and gene sequenced even fewer.</p>



<p>Maybe we overlook pre-genetic life because it looks like “normal” cells? We can now take a census of whole microbial communities by sequencing their DNA in bulk and using a computer to sort out the different species, but pre-genetic life would be invisible to that technique. It has no DNA to catalog. Maybe it uses RNA, which degrades more quickly, and is harder to study? Maybe the RNA is organized differently, in ways that would defy current sequencing technology? Maybe it uses a completely different mechanism, with molecules we don’t even know to look for? It’s fascinating to think there could be a whole other kingdom of life hiding in plain sight.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://thinkingwithnate.wordpress.com/2024/01/12/pre-genetic-life/feed/</wfw:commentRss>
			<slash:comments>8</slash:comments>
		
		
		
		<media:content url="https://0.gravatar.com/avatar/39ae42d33af99a13fa6ef7e7c81e595cc0e2e241e360bb495dc7e4c89ab517fd?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">nategaylinn</media:title>
		</media:content>
	</item>
	</channel>
</rss>
