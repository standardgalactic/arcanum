<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:georss="http://www.georss.org/georss" xmlns:geo="http://www.w3.org/2003/01/geo/wgs84_pos#" xmlns:media="http://search.yahoo.com/mrss/"
	
	>
<channel>
	<title>
	Comments on: Status Update: Semester 3	</title>
	<atom:link href="https://thinkingwithnate.wordpress.com/2024/09/29/status-update-semester-3/feed/" rel="self" type="application/rss+xml" />
	<link>https://thinkingwithnate.wordpress.com/2024/09/29/status-update-semester-3/</link>
	<description>Becoming an intelligence researcher</description>
	<lastBuildDate>Thu, 07 Nov 2024 01:46:40 +0000</lastBuildDate>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>http://wordpress.com/</generator>
	<item>
		<title>
		By: Thorin N. Tatge		</title>
		<link>https://thinkingwithnate.wordpress.com/2024/09/29/status-update-semester-3/comment-page-1/#comment-313</link>

		<dc:creator><![CDATA[Thorin N. Tatge]]></dc:creator>
		<pubDate>Thu, 07 Nov 2024 01:46:40 +0000</pubDate>
		<guid isPermaLink="false">http://thinkingwithnate.wordpress.com/?p=252#comment-313</guid>

					<description><![CDATA[&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Based on this, I would indeed like to see a post about these Transformers models!  Hopefully they&#039;re more than meets the eye.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;]]></description>
			<content:encoded><![CDATA[<p>Based on this, I would indeed like to see a post about these Transformers models!  Hopefully they&#8217;re more than meets the eye.</p>
<p id="comment-like-313" data-liked=comment-not-liked class="comment-likes comment-not-liked"><a href="https://thinkingwithnate.wordpress.com/2024/09/29/status-update-semester-3/?like_comment=313&#038;_wpnonce=4aea92cca0" class="comment-like-link needs-login" rel="nofollow" data-blog="201189235"><span>Like</span></a><span id="comment-like-count-313" class="comment-like-feedback">Like</span></p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Nate Gaylinn (he/him)		</title>
		<link>https://thinkingwithnate.wordpress.com/2024/09/29/status-update-semester-3/comment-page-1/#comment-310</link>

		<dc:creator><![CDATA[Nate Gaylinn (he/him)]]></dc:creator>
		<pubDate>Thu, 31 Oct 2024 20:48:31 +0000</pubDate>
		<guid isPermaLink="false">http://thinkingwithnate.wordpress.com/?p=252#comment-310</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://thinkingwithnate.wordpress.com/2024/09/29/status-update-semester-3/comment-page-1/#comment-308&quot;&gt;Thorin N. Tatge&lt;/a&gt;.

I agree, Nick is brave and full of integrity. I respect him greatly!

I think you&#039;re right that deep learning &lt;i&gt;has&lt;/i&gt; had a big breakthrough recently, especially in the area of language. I kinda downplay that, just to counter the exaggerated AI hype, but you&#039;re not imagining things. Your question actually makes me want to write a whole post about it! I&#039;ve just learned about Transformer models for class, so it would be fun and helpful to reflect and share what I learned. The very short version, though, is that Transformers combine a few important innovations. Some of them radically improve our ability to model grammars and other sorts of complex patterns of relationships between words. But the thing that &lt;i&gt;really&lt;/i&gt; turbo-charged the AI boom was an efficiency trick. It just became much faster and cheaper to train these more complicated language models on &lt;i&gt;vast&lt;/i&gt; amounts of text, and when you do that you get models that capture much more depth and nuance of meaning than anything before.

That suggests two possible answers to your question. Maybe &quot;no,&quot; because LLMs only learn to generate language by processing &lt;i&gt;the entire internet&lt;/i&gt;, and clearly humans do it in a very different way. Maybe &quot;yes,&quot; because just a subtle changes in how we capture associations between words allows LLMs to grasp complex grammars and multiple shades of meaning, so maybe a small change in brain structure could have opened that same door for humans?]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://thinkingwithnate.wordpress.com/2024/09/29/status-update-semester-3/comment-page-1/#comment-308">Thorin N. Tatge</a>.</p>
<p>I agree, Nick is brave and full of integrity. I respect him greatly!</p>
<p>I think you&#8217;re right that deep learning <i>has</i> had a big breakthrough recently, especially in the area of language. I kinda downplay that, just to counter the exaggerated AI hype, but you&#8217;re not imagining things. Your question actually makes me want to write a whole post about it! I&#8217;ve just learned about Transformer models for class, so it would be fun and helpful to reflect and share what I learned. The very short version, though, is that Transformers combine a few important innovations. Some of them radically improve our ability to model grammars and other sorts of complex patterns of relationships between words. But the thing that <i>really</i> turbo-charged the AI boom was an efficiency trick. It just became much faster and cheaper to train these more complicated language models on <i>vast</i> amounts of text, and when you do that you get models that capture much more depth and nuance of meaning than anything before.</p>
<p>That suggests two possible answers to your question. Maybe &#8220;no,&#8221; because LLMs only learn to generate language by processing <i>the entire internet</i>, and clearly humans do it in a very different way. Maybe &#8220;yes,&#8221; because just a subtle changes in how we capture associations between words allows LLMs to grasp complex grammars and multiple shades of meaning, so maybe a small change in brain structure could have opened that same door for humans?</p>
<p id="comment-like-310" data-liked=comment-not-liked class="comment-likes comment-not-liked"><a href="https://thinkingwithnate.wordpress.com/2024/09/29/status-update-semester-3/?like_comment=310&#038;_wpnonce=333f47f49e" class="comment-like-link needs-login" rel="nofollow" data-blog="201189235"><span>Like</span></a><span id="comment-like-count-310" class="comment-like-feedback">Like</span></p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Thorin N. Tatge		</title>
		<link>https://thinkingwithnate.wordpress.com/2024/09/29/status-update-semester-3/comment-page-1/#comment-308</link>

		<dc:creator><![CDATA[Thorin N. Tatge]]></dc:creator>
		<pubDate>Wed, 30 Oct 2024 12:32:22 +0000</pubDate>
		<guid isPermaLink="false">http://thinkingwithnate.wordpress.com/?p=252#comment-308</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://thinkingwithnate.wordpress.com/2024/09/29/status-update-semester-3/comment-page-1/#comment-302&quot;&gt;Nate Gaylinn (he/him)&lt;/a&gt;.

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;That sounds like an interesting topic.  From my layperson perspective, it does seem like deep learning/neural networks recently managed to penetrate some barrier and become much more effective, even beyond what one would expect from gradually increasing processor speeds and such.  Could it be related to how our human language seems so tremendously more powerful than the rudimentary language of our nearest relatives?  Did we hit a complexity threshold and break through?&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Also, that sounds like a brave professor.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://thinkingwithnate.wordpress.com/2024/09/29/status-update-semester-3/comment-page-1/#comment-302">Nate Gaylinn (he/him)</a>.</p>
<p>That sounds like an interesting topic.  From my layperson perspective, it does seem like deep learning/neural networks recently managed to penetrate some barrier and become much more effective, even beyond what one would expect from gradually increasing processor speeds and such.  Could it be related to how our human language seems so tremendously more powerful than the rudimentary language of our nearest relatives?  Did we hit a complexity threshold and break through?</p>
<p>Also, that sounds like a brave professor.</p>
<p id="comment-like-308" data-liked=comment-not-liked class="comment-likes comment-not-liked"><a href="https://thinkingwithnate.wordpress.com/2024/09/29/status-update-semester-3/?like_comment=308&#038;_wpnonce=003706a016" class="comment-like-link needs-login" rel="nofollow" data-blog="201189235"><span>Like</span></a><span id="comment-like-count-308" class="comment-like-feedback">Like</span></p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Nate Gaylinn (he/him)		</title>
		<link>https://thinkingwithnate.wordpress.com/2024/09/29/status-update-semester-3/comment-page-1/#comment-302</link>

		<dc:creator><![CDATA[Nate Gaylinn (he/him)]]></dc:creator>
		<pubDate>Sat, 26 Oct 2024 10:52:57 +0000</pubDate>
		<guid isPermaLink="false">http://thinkingwithnate.wordpress.com/?p=252#comment-302</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://thinkingwithnate.wordpress.com/2024/09/29/status-update-semester-3/comment-page-1/#comment-299&quot;&gt;Thorin N. Tatge&lt;/a&gt;.

I&#039;m sorry you&#039;ve been stressed, and glad to hear from you, even if it&#039;s quite a bit later.

For the record: you&#039;re not alone in being mystified about how seemingly deep and complex ideas become embedded in a neural network&#039;s weights. This is something we only &quot;understand&quot; in a vague, hand-wavey sort of way. Next semester, I&#039;m actually taking a graduate seminar called &quot;the unreasonable effectiveness of deep learning&quot; which is all about probing this question and trying to gain some sort of intuition about it. The professor (who I respect greatly) is leading this because he doesn&#039;t get it and hopes reading about it and discussing it with grad students will help him make sense of it.  ;)]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://thinkingwithnate.wordpress.com/2024/09/29/status-update-semester-3/comment-page-1/#comment-299">Thorin N. Tatge</a>.</p>
<p>I&#8217;m sorry you&#8217;ve been stressed, and glad to hear from you, even if it&#8217;s quite a bit later.</p>
<p>For the record: you&#8217;re not alone in being mystified about how seemingly deep and complex ideas become embedded in a neural network&#8217;s weights. This is something we only &#8220;understand&#8221; in a vague, hand-wavey sort of way. Next semester, I&#8217;m actually taking a graduate seminar called &#8220;the unreasonable effectiveness of deep learning&#8221; which is all about probing this question and trying to gain some sort of intuition about it. The professor (who I respect greatly) is leading this because he doesn&#8217;t get it and hopes reading about it and discussing it with grad students will help him make sense of it.  😉</p>
<p id="comment-like-302" data-liked=comment-not-liked class="comment-likes comment-not-liked"><a href="https://thinkingwithnate.wordpress.com/2024/09/29/status-update-semester-3/?like_comment=302&#038;_wpnonce=6edbca0b9c" class="comment-like-link needs-login" rel="nofollow" data-blog="201189235"><span>Like</span></a><span id="comment-like-count-302" class="comment-like-feedback">Like</span></p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Thorin N. Tatge		</title>
		<link>https://thinkingwithnate.wordpress.com/2024/09/29/status-update-semester-3/comment-page-1/#comment-299</link>

		<dc:creator><![CDATA[Thorin N. Tatge]]></dc:creator>
		<pubDate>Fri, 25 Oct 2024 02:38:27 +0000</pubDate>
		<guid isPermaLink="false">http://thinkingwithnate.wordpress.com/?p=252#comment-299</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://thinkingwithnate.wordpress.com/2024/09/29/status-update-semester-3/comment-page-1/#comment-295&quot;&gt;Nate Gaylinn (he/him)&lt;/a&gt;.

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Hi Nate!  I&#039;ve been too stupid or too stressed or too busy with a trip to respond to these comments for a while, but maybe I can manage now.  I think I understand the neural network construction concept a little better than previously based on your description.  When a neural network does something like learn how to play Go well from scratch, I&#039;m still a but mystified how the winning concepts (like controlling space) take form in the network&#039;s &#039;mind&#039;.  It feels to me like it would need to somehow build its own algorithms to solve some more complex problems, but apparently not, apparently that&#039;s a next-steps bonus.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;It totally makes sense that SETI would be a good example of wanting to look for anomalies.  Presumably an intelligently designed signal would need a system that recognizes intelligent things in order to recognize it.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;I see what you&#039;re saying about teaching the program to recognize gliders and so on!  I could see how an attempt to recognize something interesting that hasn&#039;t been explicitly programmed in might have to depend on defining fixed interesting objects explicitly first.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Okay, that comment wasn&#039;t so hard.  Now for the especially smart one...&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://thinkingwithnate.wordpress.com/2024/09/29/status-update-semester-3/comment-page-1/#comment-295">Nate Gaylinn (he/him)</a>.</p>
<p>Hi Nate!  I&#8217;ve been too stupid or too stressed or too busy with a trip to respond to these comments for a while, but maybe I can manage now.  I think I understand the neural network construction concept a little better than previously based on your description.  When a neural network does something like learn how to play Go well from scratch, I&#8217;m still a but mystified how the winning concepts (like controlling space) take form in the network&#8217;s &#8216;mind&#8217;.  It feels to me like it would need to somehow build its own algorithms to solve some more complex problems, but apparently not, apparently that&#8217;s a next-steps bonus.</p>
<p>It totally makes sense that SETI would be a good example of wanting to look for anomalies.  Presumably an intelligently designed signal would need a system that recognizes intelligent things in order to recognize it.</p>
<p>I see what you&#8217;re saying about teaching the program to recognize gliders and so on!  I could see how an attempt to recognize something interesting that hasn&#8217;t been explicitly programmed in might have to depend on defining fixed interesting objects explicitly first.</p>
<p>Okay, that comment wasn&#8217;t so hard.  Now for the especially smart one&#8230;</p>
<p id="comment-like-299" data-liked=comment-not-liked class="comment-likes comment-not-liked"><a href="https://thinkingwithnate.wordpress.com/2024/09/29/status-update-semester-3/?like_comment=299&#038;_wpnonce=7933d5919b" class="comment-like-link needs-login" rel="nofollow" data-blog="201189235"><span>Like</span></a><span id="comment-like-count-299" class="comment-like-feedback">Like</span></p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Nate Gaylinn (he/him)		</title>
		<link>https://thinkingwithnate.wordpress.com/2024/09/29/status-update-semester-3/comment-page-1/#comment-295</link>

		<dc:creator><![CDATA[Nate Gaylinn (he/him)]]></dc:creator>
		<pubDate>Sat, 12 Oct 2024 13:09:05 +0000</pubDate>
		<guid isPermaLink="false">http://thinkingwithnate.wordpress.com/?p=252#comment-295</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://thinkingwithnate.wordpress.com/2024/09/29/status-update-semester-3/comment-page-1/#comment-292&quot;&gt;Thorin N. Tatge&lt;/a&gt;.

Great questions!

Getting computers to &quot;discover their own algorithms&quot; is still a very primitive thing. Some might even object to me calling it that. The basic idea is that a person picks a problem, comes up with a space of possible solutions, and designs a model of that solution space that can then be automatically narrowed down. Neural networks are by far the most common way to do this. That sounds brain-like, but it&#039;s really not. It&#039;s just like making a &lt;i&gt;huge&lt;/i&gt; equation with hundreds or thousands or &lt;i&gt;billions&lt;/i&gt; of variables in it, then having the computer guess and iteratively improve values for those variables, using evolution or gradient descent or some other optimization technique. Then the human has to go in to see if the computer is doing what they wanted in an acceptable way (often it isn&#039;t) and then tweak this whole process until they get what they want. So a &lt;i&gt;lot&lt;/i&gt; of the hard work is still done by hand. Part of what I&#039;m trying to do is to get the computer to take on more of the &quot;meta learning&quot; tasks of designing and refining solution spaces. If anything, that&#039;s probably the part most like you designing your own productivity systems, though it&#039;s still pretty far from being so deliberate and creative.

The latest incarnation of this gut microbiome experiment is much simpler than the things we discussed before. I&#039;m excited to have an experiment design that&#039;s &lt;i&gt;not&lt;/i&gt; an over-complicated thing that will take months to build, for once! I just want to test what happens when I evolve a host environment for evolving &quot;microbes&quot; where the fitness function varies spatially. To keep it simple, the &quot;microbes&quot; will just be bit strings (ie., &quot;00101010&quot;) and their fitness (whether they get to survive and reproduce) is just determined by the values of those bits. That way I don&#039;t have to make a fancy simulation where the microbes actually do stuff. The fitness function I&#039;m using is called &quot;HIFF,&quot; but every spot in the environment has a different variation on HIFF: I only evaluate parts of the bit string, rather than the whole thing, and there&#039;s a tunable threshold for survival. I&#039;m hoping I can evolve an environment with a gradual ramp in difficulty, or a way of dividing up the work, or something that will make the search more effective than if I just solved HIFF the normal way. It&#039;s a bit like how the scientists helped the bacteria evolve antibiotic resistance by giving them steps with gradually increasing concentrations of antibiotic.

Yes, I think I might keep using the Game of Life for my experiments! It&#039;s effective, relatively easy to work with, and produces cool visuals. But &quot;interestingness&quot; is very hard for computers. What it really means is &quot;interesting to humans,&quot; which means somehow the human has to tell the computer what counts, and that means the human has to understand what &lt;i&gt;they&lt;/i&gt; care about, which... we&#039;re really bad at. Certainly people try, though! You&#039;re describing a common use case called &quot;anomaly detection,&quot; where a computer watches a sequence of numbers (digits of pi, sensor readings, a radio signal, whatever) and points out when something unexpected or exciting shows up. I actually just heard about &lt;a href=&quot;https://www.seti.org/seti-institute-researchers-engage-worlds-first-real-time-ai-search-fast-radio-bursts&quot; rel=&quot;nofollow ugc&quot;&gt;SETI using this for their investigation of fast radio bursts&lt;/a&gt;!

What I&#039;m hoping to build is a video segmentation tool for the Game of Life. That is, show it a video, and it will highlight all the different objects in the scene and tell you things like: is this a familiar pattern? Does it repeat itself? How often? Does it move? etc. That&#039;s not actually an &quot;interestingness detector&quot; on its own, but I figure I could use it to define more interesting challenges for my evolutionary algorithm to solve. For instance, I could say &quot;give me as many gliders as possible, and bonus points if they pass through this target&quot; or &quot;how many &lt;i&gt;different&lt;/i&gt; patterns can you put into one scene?&quot; or &quot;make a scene that settles down into stable (possibly repeating) patterns after N steps.&quot; So, I&#039;m still responsible for saying &quot;what&#039;s interesting,&quot; but I&#039;ll have a richer vocabulary for describing that to the computer, without having to manually design detectors for all these complicated scenarios.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://thinkingwithnate.wordpress.com/2024/09/29/status-update-semester-3/comment-page-1/#comment-292">Thorin N. Tatge</a>.</p>
<p>Great questions!</p>
<p>Getting computers to &#8220;discover their own algorithms&#8221; is still a very primitive thing. Some might even object to me calling it that. The basic idea is that a person picks a problem, comes up with a space of possible solutions, and designs a model of that solution space that can then be automatically narrowed down. Neural networks are by far the most common way to do this. That sounds brain-like, but it&#8217;s really not. It&#8217;s just like making a <i>huge</i> equation with hundreds or thousands or <i>billions</i> of variables in it, then having the computer guess and iteratively improve values for those variables, using evolution or gradient descent or some other optimization technique. Then the human has to go in to see if the computer is doing what they wanted in an acceptable way (often it isn&#8217;t) and then tweak this whole process until they get what they want. So a <i>lot</i> of the hard work is still done by hand. Part of what I&#8217;m trying to do is to get the computer to take on more of the &#8220;meta learning&#8221; tasks of designing and refining solution spaces. If anything, that&#8217;s probably the part most like you designing your own productivity systems, though it&#8217;s still pretty far from being so deliberate and creative.</p>
<p>The latest incarnation of this gut microbiome experiment is much simpler than the things we discussed before. I&#8217;m excited to have an experiment design that&#8217;s <i>not</i> an over-complicated thing that will take months to build, for once! I just want to test what happens when I evolve a host environment for evolving &#8220;microbes&#8221; where the fitness function varies spatially. To keep it simple, the &#8220;microbes&#8221; will just be bit strings (ie., &#8220;00101010&#8221;) and their fitness (whether they get to survive and reproduce) is just determined by the values of those bits. That way I don&#8217;t have to make a fancy simulation where the microbes actually do stuff. The fitness function I&#8217;m using is called &#8220;HIFF,&#8221; but every spot in the environment has a different variation on HIFF: I only evaluate parts of the bit string, rather than the whole thing, and there&#8217;s a tunable threshold for survival. I&#8217;m hoping I can evolve an environment with a gradual ramp in difficulty, or a way of dividing up the work, or something that will make the search more effective than if I just solved HIFF the normal way. It&#8217;s a bit like how the scientists helped the bacteria evolve antibiotic resistance by giving them steps with gradually increasing concentrations of antibiotic.</p>
<p>Yes, I think I might keep using the Game of Life for my experiments! It&#8217;s effective, relatively easy to work with, and produces cool visuals. But &#8220;interestingness&#8221; is very hard for computers. What it really means is &#8220;interesting to humans,&#8221; which means somehow the human has to tell the computer what counts, and that means the human has to understand what <i>they</i> care about, which&#8230; we&#8217;re really bad at. Certainly people try, though! You&#8217;re describing a common use case called &#8220;anomaly detection,&#8221; where a computer watches a sequence of numbers (digits of pi, sensor readings, a radio signal, whatever) and points out when something unexpected or exciting shows up. I actually just heard about <a href="https://www.seti.org/seti-institute-researchers-engage-worlds-first-real-time-ai-search-fast-radio-bursts" rel="nofollow ugc">SETI using this for their investigation of fast radio bursts</a>!</p>
<p>What I&#8217;m hoping to build is a video segmentation tool for the Game of Life. That is, show it a video, and it will highlight all the different objects in the scene and tell you things like: is this a familiar pattern? Does it repeat itself? How often? Does it move? etc. That&#8217;s not actually an &#8220;interestingness detector&#8221; on its own, but I figure I could use it to define more interesting challenges for my evolutionary algorithm to solve. For instance, I could say &#8220;give me as many gliders as possible, and bonus points if they pass through this target&#8221; or &#8220;how many <i>different</i> patterns can you put into one scene?&#8221; or &#8220;make a scene that settles down into stable (possibly repeating) patterns after N steps.&#8221; So, I&#8217;m still responsible for saying &#8220;what&#8217;s interesting,&#8221; but I&#8217;ll have a richer vocabulary for describing that to the computer, without having to manually design detectors for all these complicated scenarios.</p>
<p id="comment-like-295" data-liked=comment-not-liked class="comment-likes comment-not-liked"><a href="https://thinkingwithnate.wordpress.com/2024/09/29/status-update-semester-3/?like_comment=295&#038;_wpnonce=51f9589084" class="comment-like-link needs-login" rel="nofollow" data-blog="201189235"><span>Like</span></a><span id="comment-like-count-295" class="comment-like-feedback">Like</span></p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Thorin N. Tatge		</title>
		<link>https://thinkingwithnate.wordpress.com/2024/09/29/status-update-semester-3/comment-page-1/#comment-292</link>

		<dc:creator><![CDATA[Thorin N. Tatge]]></dc:creator>
		<pubDate>Wed, 09 Oct 2024 20:10:29 +0000</pubDate>
		<guid isPermaLink="false">http://thinkingwithnate.wordpress.com/?p=252#comment-292</guid>

					<description><![CDATA[&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Thanks for the update!&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Having computers discover their own algorithms does seem pretty next level. Though I guess that could be simple or complicated. I remember some ten or fifteen years ago when there was work using computers to try to find random new proofs in basic geometry. Is discovering a new algorithm for oneself like evolving more evolvability? Is it like how I improve and tweak my productivity systems (like the goal week I&#039;m currently doing) and rules for self-discipline over time, based on what works well?&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;We discussed possible structures for the endosymbiosis experiment. I seem to recall you telling me that you went in a rather different direction, but I&#039;m curious what design you eventually settled on. The classic experiment was vaguely familiar and entertaining to watch.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Looks like you&#039;re stuck with the Game of Life for a while! I wonder if it will stick with you for further experiments. So, the next step is to teach the computer to do the work of figuring out when a pattern result is interesting? That sounds maybe harder than the entire rest of the experiment! Do computers already know how to find &quot;interesting&quot; patterns? Have they been used to find interesting features in the decimal expansion of pi, for example, or in other numerical sequences? That reminds me of the old-school AI efforts that Doug Hofstadter wrote about in Metamagical Themas.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;]]></description>
			<content:encoded><![CDATA[<p>Thanks for the update!</p>
<p>Having computers discover their own algorithms does seem pretty next level. Though I guess that could be simple or complicated. I remember some ten or fifteen years ago when there was work using computers to try to find random new proofs in basic geometry. Is discovering a new algorithm for oneself like evolving more evolvability? Is it like how I improve and tweak my productivity systems (like the goal week I&#8217;m currently doing) and rules for self-discipline over time, based on what works well?</p>
<p>We discussed possible structures for the endosymbiosis experiment. I seem to recall you telling me that you went in a rather different direction, but I&#8217;m curious what design you eventually settled on. The classic experiment was vaguely familiar and entertaining to watch.</p>
<p>Looks like you&#8217;re stuck with the Game of Life for a while! I wonder if it will stick with you for further experiments. So, the next step is to teach the computer to do the work of figuring out when a pattern result is interesting? That sounds maybe harder than the entire rest of the experiment! Do computers already know how to find &#8220;interesting&#8221; patterns? Have they been used to find interesting features in the decimal expansion of pi, for example, or in other numerical sequences? That reminds me of the old-school AI efforts that Doug Hofstadter wrote about in Metamagical Themas.</p>
<p id="comment-like-292" data-liked=comment-not-liked class="comment-likes comment-not-liked"><a href="https://thinkingwithnate.wordpress.com/2024/09/29/status-update-semester-3/?like_comment=292&#038;_wpnonce=ac14eb33f4" class="comment-like-link needs-login" rel="nofollow" data-blog="201189235"><span>Like</span></a><span id="comment-like-count-292" class="comment-like-feedback">Like</span></p>
]]></content:encoded>
		
			</item>
	</channel>
</rss>
