<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	xmlns:georss="http://www.georss.org/georss" xmlns:geo="http://www.w3.org/2003/01/geo/wgs84_pos#" xmlns:media="http://search.yahoo.com/mrss/"
	>

<channel>
	<title>artificial-intelligence &#8211; Thinking with Nate</title>
	<atom:link href="https://thinkingwithnate.wordpress.com/tag/artificial-intelligence/feed/" rel="self" type="application/rss+xml" />
	<link>https://thinkingwithnate.wordpress.com</link>
	<description>Becoming an intelligence researcher</description>
	<lastBuildDate>Sat, 07 Dec 2024 15:51:05 +0000</lastBuildDate>
	<language>en</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>http://wordpress.com/</generator>
<cloud domain='thinkingwithnate.wordpress.com' port='80' path='/?rsscloud=notify' registerProcedure='' protocol='http-post' />
<image>
		<url>https://s0.wp.com/i/buttonw-com.png</url>
		<title>artificial-intelligence &#8211; Thinking with Nate</title>
		<link>https://thinkingwithnate.wordpress.com</link>
	</image>
	<atom:link rel="search" type="application/opensearchdescription+xml" href="https://thinkingwithnate.wordpress.com/osd.xml" title="Thinking with Nate" />
	<atom:link rel='hub' href='https://thinkingwithnate.wordpress.com/?pushpress=hub'/>
	<item>
		<title>How did AI get so much smarter?</title>
		<link>https://thinkingwithnate.wordpress.com/2024/12/07/how-did-ai-get-so-much-smarter/</link>
					<comments>https://thinkingwithnate.wordpress.com/2024/12/07/how-did-ai-get-so-much-smarter/#comments</comments>
		
		<dc:creator><![CDATA[Nate Gaylinn (he/him)]]></dc:creator>
		<pubDate>Sat, 07 Dec 2024 15:51:05 +0000</pubDate>
				<category><![CDATA[Theory]]></category>
		<category><![CDATA[ai]]></category>
		<category><![CDATA[artificial-intelligence]]></category>
		<category><![CDATA[deep learning]]></category>
		<category><![CDATA[language]]></category>
		<category><![CDATA[large language models]]></category>
		<category><![CDATA[llm]]></category>
		<category><![CDATA[llms]]></category>
		<category><![CDATA[machine learning]]></category>
		<category><![CDATA[machine-learning]]></category>
		<category><![CDATA[meaning]]></category>
		<category><![CDATA[natural language processing]]></category>
		<category><![CDATA[nlp]]></category>
		<guid isPermaLink="false">http://thinkingwithnate.wordpress.com/?p=267</guid>

					<description><![CDATA[(this month&#8217;s photo is a picture of a brown bat. It&#8217;s small and fluffy with a stubby nose, and clinging to the gray bark of a tree. Photo by N. J. Stewart wildlife unmodified and used under the Creative Commons license) When I write about intelligence, I tend to downplay AI and Deep Learning. These &#8230; <a href="https://thinkingwithnate.wordpress.com/2024/12/07/how-did-ai-get-so-much-smarter/" class="more-link">Continue reading<span class="screen-reader-text"> "How did AI get so much&#160;smarter?"</span></a>]]></description>
										<content:encoded><![CDATA[
<p>(this month&#8217;s photo is a picture of a brown bat. It&#8217;s small and fluffy with a stubby nose, and clinging to the gray bark of a tree. Photo by <a href="https://www.flickr.com/photos/stuartwildlife/">N. J. Stewart wildlife</a> unmodified and used under the Creative Commons license)</p>



<p>When I write about intelligence, I tend to downplay AI and Deep Learning. These are powerful problem solving tools, but they’re over-hyped, and they don’t “think” the way people do. They have no memory, no sense of self, and no goals, at least in the usual sense of the words. But, large language models (LLMs) like OpenAI’s GPT are shockingly good at generating text that <em>seems</em> like something a person might make. They’re much more human-like than anything that came before. Why is that? The short answer is that they use a new kind of Deep Learning architecture known as a Transformer, which introduced a few small tricks that make a very big difference.</p>



<p>The first thing to note is that, while lots of people argue about whether LLMs can answer questions, reason, solve problems, brainstorm, or make art, what they really do is <em>text prediction</em>. They take some words as a starting point and then they guess what comes next based on their training data. If LLMs have any deeper cognitive abilities than that, they must be somehow tapping into the human cultural intelligence that is embedded within that text. Or, maybe they’re just parroting back fragments of intelligent things other people have said, without any understanding or integration—mindless idiots, randomly stringing words together in ways that sound just smart enough to distract us. We honestly don’t know yet! But whatever intelligence they possess, it exists entirely in the realm of language.</p>



<p>Research into getting computers to understand text and speech (known as Natural Language Processing, or NLP) started back in the 1950’s. Back then, computers were specialist’s tools, and making one that anyone could use just by telling it what to do was a dream. At first, researchers tried to formally describe language as we use it, feeding computers dictionaries, grammar rules, and lists of facts, but this never worked! It turns out, we don’t explicitly <em>know</em> all the rules of human language that we intuitively follow, and they’re usually <em>fuzzy</em> rules, with lots of conditions and exceptions. The key challenge of NLP was getting computers (which are obsessively logical and precise) to deal with this messiness and ambiguity, which we don’t even fully understand ourselves. Perhaps the most important advance was when researchers gave up trying to explain language to computers, and instead started teaching them by example.</p>



<p>Modern NLP represents words as lists of numbers called “vectors.” Like an (X, Y) coordinate, each vector represents a point in space. Not physical space, though, more like an abstract space of concepts. Maybe nouns go to the right, verbs to the left. Natural concepts are up, man-made concepts are down. Except, instead of two dimensions, maybe there are 10,000 of them. The layout of this space is pretty arbitrary. The absolute position of a word doesn’t mean anything, only where it is relative to other words. Nearby words have similar meanings, and relationships between words are represented by the distance and angle between them. This is all weirdly self-referential. Words are only defined in terms of other words! But it works surprisingly well. You don’t need explicit rules about which words go together and how, you can just look at <em>lots</em> of examples, and infer those relationships with statistics. People talk about “training” an AI by having it “read” lots of text, but really all that means is iteratively tweaking the lists of numbers, slowly moving the words through this abstract meaning space until they settle into positions that reflect how they co-occur together in the training text.</p>



<p>There’s one big problem with representing words as vectors, though: ambiguity. What do you do with a word like “bat,” which has several meanings? There’s no way one vector can represent this. The trick is to look for context. When you see a phrase like “brown bat” or “wooden bat,” the meaning is clear. Instead of thinking of these as pairs of words, you might think of them as <em>compound words</em>, each with their own distinct meaning. This is a powerful idea, but hard to generalize. Take a more difficult example: “Hearing a strange flutter and crash in the dark, he grabbed his bat for defense and went to investigate” Which kind of “bat” are we talking about? Words like “flutter” and “dark” might suggest the animal, but “grabbing” a bat for “defense” suggests the object instead. We need context to disambiguate, but which context? We’d like to ignore the first half of the sentence (which isn’t talking about the “bat”) and focus on the second half of the sentence (which is).</p>



<p>NLP has found elegant ways to solve this problem. They call these techniques “attention,” since the model is learning to “pay attention” to some words and not others, but I find that name misleading. For human beings, attention is something very different. We seem to have a “mind’s eye” that we can move about at will. We can choose to pay attention to this or that, our attention gets drawn to salient features, and we may even notice our attention drifting and redirect it. But these AIs have no mind’s eye, no will, and no intuition about relevance. The attention models we’re talking about are just <em>more vector math</em>. In addition to finding vectors to represent the meaning of each word individually, they also find vectors to represent <em>patterns</em> of words. They learn, “in this context, these words together mean that.” Adding an extra layer of complexity lets the model represent how words interact to change the meaning of other words or the sentence as a whole.</p>



<p>Researchers have explored many variations on this attention trick. Transformer models use an advanced kind of attention that represents context bi-directionally. They model how different words tend to get modified by context, and how different contexts tend to modify nearby words. The benefit of this is that such a model doesn’t just learn that “brown bat” is the name of an animal, but it might learn that “brown” is an adjective that applies to physical objects, that in English adjectives tend to modify the noun that follows them, and that “bat” can refer to one of several animal species, sometimes distinguished by color. That is, rather than modeling some <em>particular</em> context, models like this can learn general rules and relationships between different <em>kinds</em> of words. They can learn <em>grammar</em>. Not just the “official” grammar of a language like English, but <em>any</em> system of relationships and interactions between words, including dialects, domain-specific jargon, storytelling tropes, or the gender roles of a society.</p>



<p>The other trick that makes Transformers better with language is <em>pluralism</em>. Some NLP systems represent more complex meanings by using <em>bigger</em> vectors. More numbers in each vector means a larger conceptual space. Instead, Transformers use <em>more</em> vectors. They don’t learn <em>the one</em> meaning of this word, they learn to represent the <em>many</em> meanings of this word in the <em>many</em> contexts that contain it. This works a bit like voting. When processing a sentence, several different “attention heads” each consider one possible interpretation of a word, attending to different patterns of contextual cues. The overall meaning is determined by adding them all together. This is really useful for weighing subtle cues against each other to resolve ambiguity, but also to represent sentences with multiple layers of meaning. A word can have many meanings at the same time, and the many meanings of all the words in a sentence can interact in complex ways. The fancy kind of attention used in Transformers can automatically discover this sort of layered structure in language.</p>



<p>As clever as these attention methods are, they are <em>not</em> the secret to Transformers’ success. They do greatly improve the richness of NLP models, but at first they were mostly used with “recurrent neural networks,” a kind of Deep Learning model that processes data sequentially. That’s probably because they work a bit like how we imagine a human reader does: they “read” each word in a text, one at a time, using attention to figure out how each new word should update the meaning of the text so far. This works pretty well, but it doesn’t scale up to long passages of text. These models have a limited attention span, eventually forgetting important details they read several sentences ago. Also, processing long texts one word at a time is painfully slow. Even on the world’s fastest computer, reading a book from beginning to end takes time <em>per page</em>, and training a model like this takes <em>vast</em> amounts of text, so this was a major limitation.</p>



<p>The paper that first introduced Transformers was called <em>Attention is All You Need</em>, which highlights the key innovation: they got rid of the recurrent network, and built an AI using just this attention mechanism, all on its own. In other words, they found a way to do the same vector math, but solving for a large block of text all at once (and possibly out of order) rather than word-by-word. This doesn’t make the model “smarter.” It doesn’t even reduce the overall amount of number crunching. It just makes the work more <em>parallelizable</em>. Instead of having one computer read <em>War and Peace</em> from cover to cover, they could have <em>many</em> computers each read a few paragraphs, then combine their results. This made it possible to throw more money at the problem, using whole <em>datacenters</em> of computers to train a language model on <em>vastly</em> more text than ever before. Billions of documents, trillions of words. It’s the <em>sheer volume</em> of training data that made LLMs so much better. That’s why they’re called “large” language models.</p>



<p>So, how should we think about LLMs like GPT? Well, first off, human language is irregular and complex, but it’s also highly structured. Cleverly designed statistical learning tools can automatically discover that hidden structure just by processing <em>obscene</em> amounts of text. Neural networks are great for letting computers work with these sorts of fuzzy rules. They can extract meaning from text, manipulate it, and generate new text. But to an LLM, words are just vectors, defined by their relationships to each other. They have no connection to physical reality, because LLMs have no physical existence. There is no communication going on when you have a “conversation” with an LLM. To the AI, a dialog is just a sequence of vectors that follow one another according to some grammar. The AI has no mind, no intentions, and no meaning it wishes to convey. It has no conception of being truthful or helpful, only what words tend to follow certain questions. It does not learn from a conversation, it just re-reads the full chat history each time it makes a response. It <em>appears</em> like a good conversational partner, because it is made to imitate one, but what&#8217;s happening behind the screen isn’t “thinking” as we know it.</p>



<p>Still, LLMs really are much more human-like than any other AI that came before. Representing language with a high-dimensional abstract concept space works surprisingly well, and so do the “attention” methods described above. They let us represent a huge, open-ended space of ideas that can build on and interact with each other. They let us represent ambiguity, nuance, and innuendo. So, maybe those vector math tricks could actually teach us something about how language processing works in the brain? On the other hand, LLMs are also remarkable in how <em>different</em> they are from humans. An LLM can learn English, but only by reading every document on the internet, not one word at a time, but <em>all at once</em>. In contrast, babies learn language by interacting with the world, learning how words relate to objects, people, events, actions, and desires. Even though they’re exposed to far less language, they learn much faster, and in a way that tightly integrates all of their senses, relationships, and the lifestyle they were born into. Since LLMs seem so human-like, it’s very tempting to imagine them with the same kind of awareness, purpose, and empathy that we have, but they simply aren’t there. Those are a product of being alive in the world, and can’t be found in text, no matter how much of it.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://thinkingwithnate.wordpress.com/2024/12/07/how-did-ai-get-so-much-smarter/feed/</wfw:commentRss>
			<slash:comments>15</slash:comments>
		
		
		
		<media:thumbnail url="https://thinkingwithnate.wordpress.com/wp-content/uploads/2024/12/image.png" />
		<media:content url="https://thinkingwithnate.wordpress.com/wp-content/uploads/2024/12/image.png" medium="image">
			<media:title type="html">image</media:title>
		</media:content>

		<media:content url="https://0.gravatar.com/avatar/39ae42d33af99a13fa6ef7e7c81e595cc0e2e241e360bb495dc7e4c89ab517fd?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">nategaylinn</media:title>
		</media:content>
	</item>
		<item>
		<title>Status Update: Semester 3</title>
		<link>https://thinkingwithnate.wordpress.com/2024/09/29/status-update-semester-3/</link>
					<comments>https://thinkingwithnate.wordpress.com/2024/09/29/status-update-semester-3/#comments</comments>
		
		<dc:creator><![CDATA[Nate Gaylinn (he/him)]]></dc:creator>
		<pubDate>Sun, 29 Sep 2024 14:17:46 +0000</pubDate>
				<category><![CDATA[Status Updates]]></category>
		<category><![CDATA[ai]]></category>
		<category><![CDATA[antibiotic resistance]]></category>
		<category><![CDATA[artificial-intelligence]]></category>
		<category><![CDATA[computer vision]]></category>
		<category><![CDATA[deep learning]]></category>
		<category><![CDATA[endosymbiosis]]></category>
		<category><![CDATA[evolution]]></category>
		<category><![CDATA[game of life]]></category>
		<category><![CDATA[machine-learning]]></category>
		<category><![CDATA[research]]></category>
		<category><![CDATA[technology]]></category>
		<guid isPermaLink="false">http://thinkingwithnate.wordpress.com/?p=252</guid>

					<description><![CDATA[I’m at an interesting moment in my studies, so I thought I’d let you know what’s going on! Year two of my PhD program has begun. I’m about a month into my third semester, and things are going well. I’m taking two classes right now: Evolutionary Computation, and Deep Learning. Most of my Computer Science &#8230; <a href="https://thinkingwithnate.wordpress.com/2024/09/29/status-update-semester-3/" class="more-link">Continue reading<span class="screen-reader-text"> "Status Update: Semester&#160;3"</span></a>]]></description>
										<content:encoded><![CDATA[
<p>I’m at an interesting moment in my studies, so I thought I’d let you know what’s going on!</p>



<p>Year two of my PhD program has begun. I’m about a month into my third semester, and things are going well. I’m taking two classes right now: Evolutionary Computation, and Deep Learning. Most of my Computer Science education has been about how to design algorithms and write software to solve different kinds of problems, but these classes are different. This semester, I’m learning how to get computers to discover their own algorithms, and write their own software. Honestly, the state of the art here is still quite primitive. We’ve found some very impressive techniques, but they each apply to a narrow domain, and we don’t understand them nearly as well as we’d like. Which makes them fun topics to study. <img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f642.png" alt="🙂" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>



<p>The other fun thing about this semester is that both of my classes are built around student projects. More or less, I get to pick projects that fit with my research, and the class is there to help me find the time, resources, and guidance to complete the projects successfully. I like this much better than undergraduate style courses built around assignments and exams that are very generic and may not be relevant to my work. We’ll see how things unfold, but I’m currently planning to work on two projects that I’m excited about.</p>



<p>For Evolutionary Computation, I’m working on an experiment about endosymbiosis. I was inspired by <a href="https://www.youtube.com/watch?v=yybsSqcB7mE">this classic experiment</a>, which examined how bacteria evolve antibiotic resistance, and how genetic innovations spread through the population spatially. I’m going to try evolving a host environment that supports an inner population, a bit like how my gut supports a microbiome. The hope is that the host will be able to design a supportive environment, with different regions that cultivate “microbes” with different traits, such that it can guide and coax them into evolving more specialized forms. This is an exciting experiment for me, because I’m not sure what to expect, but I’m pretty confident that <em>something</em> interesting will happen.</p>



<p><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXdXXQwS7goi1ItbTdONUzbfEiFKBIKils0XIfkXZl1xwzGxuTrV76lD5OFiNLNtXdXMpPz_do1AW3qdFEFbe4loZzIcjVBTtC7ciQbwbYhN1TQMr3tf_AuT-skSA-X_9lOauzGL31dv3Lj7hQqRBu0stv8?key=F266DdYKyjrziMBoqIpF8A" alt="A screenshot from the video linked above, showing strains of bacteria gradually growing into bands with increasing concentrations of antibiotic, fanning out from points where key mutations occurred."></p>



<p class="has-small-font-size">A screenshot from the video linked above, showing strains of bacteria gradually growing into bands with increasing concentrations of antibiotic, fanning out from points where key mutations occurred.</p>



<p>For Deep Learning, I’m going to use computer vision techniques to detect interesting patterns in the <a href="https://conwaylife.com/">Game of Life</a>, since I’ve been using that as an environment for my evolution experiments. The Game of Life has very simple rules, but it evolves in complex ways. Most patterns quickly dissolve into empty space or settle into a few boring, stable forms. But rarely, you get something much more interesting. For decades, people have been exploring this space, finding interesting patterns and classifying them. You get huge complex structures that stabilize themselves, change continuously in repeating cycles, or even propel themselves and move at a steady pace. I’ll build a system that can detect and categorize these patterns, so that when my evolutionary algorithm finds them, I can reward it and ask for “more like that.”</p>



<figure class="wp-block-table aligncenter"><table class="has-fixed-layout"><tbody><tr><td><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfHtu6cHt8izDgOPsqUFq4LlQe2-X9tsFJeeQNfCy7dsr2MNlzludfJDIpQuRxRAEmU7z0gNqIq-eBjqp1gmoTIqjp2sK94w04bPiAHszCiEfa4FwojIinklOwzL-BWHctVrs5WeZI7qsfNyWjZP00Imjs?key=F266DdYKyjrziMBoqIpF8A" alt="Eater 2, a static shape that persists forever, but has the special property of being able to “eat” gliders that collide with it, recovering its shape after."></td><td><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXf6gA-5OxaNWa0rKpTU7QzHUOYa_S6pBQAYecuiFWR2okztfSwoAGHL03vZ2SLEmiOcFqdvR3VtTw1Nx0tOo1TBJIx9SoLRmOrbvpQ0xbNntupupQ0z_0TDxO84pcfSf6ZCpXl1ZsgVeZCc5IYoVw5MzPw?key=F266DdYKyjrziMBoqIpF8A" alt="Monogram, a period-four oscillator, which is small, but occurs very rarely from random conditions."></td><td><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXeay7S7PMLnfhvkF5wDd3pkukQeU7IFpsWUpbiR0pvW1V5kwEMn7APgkIip4UlvIjhC8BriCsHD4CC2fi_tBVn_64enDOPCPizrxglozcs735sNys9mU2V-Qo6Ue4FHwRCfnz-dhRIpD0ekMLexD08RF2xz?key=F266DdYKyjrziMBoqIpF8A" alt=""></td></tr></tbody></table></figure>



<p class="has-small-font-size">Examples of interesting patterns in the Game of Life. <a href="https://conwaylife.com/wiki/Eater_2">The first</a> is a static shape that persists forever, but has the special property of being able to “eat” <a href="https://conwaylife.com/wiki/Glider">gliders</a> that collide with it, recovering its shape after. <a href="https://conwaylife.com/wiki/Monogram">The second</a> is a period-four oscillator, which is small, but occurs very rarely from random conditions. <a href="https://conwaylife.com/wiki/Middleweight_spaceship">The third</a> is a middleweight spaceship, which moves forward two spaces as it repeats itself in four time steps.</p>



<p>This month’s essay is inspired by my Evolutionary Computation class, and the work I’ve been doing to develop the specific research questions I want to focus on for my PhD. So, check back on Wednesday to learn more about how evolution got started, and why it’s worth asking: how does evolution evolve?</p>
]]></content:encoded>
					
					<wfw:commentRss>https://thinkingwithnate.wordpress.com/2024/09/29/status-update-semester-3/feed/</wfw:commentRss>
			<slash:comments>7</slash:comments>
		
		
		
		<media:content url="https://0.gravatar.com/avatar/39ae42d33af99a13fa6ef7e7c81e595cc0e2e241e360bb495dc7e4c89ab517fd?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">nategaylinn</media:title>
		</media:content>

		<media:content url="https://lh7-rt.googleusercontent.com/docsz/AD_4nXdXXQwS7goi1ItbTdONUzbfEiFKBIKils0XIfkXZl1xwzGxuTrV76lD5OFiNLNtXdXMpPz_do1AW3qdFEFbe4loZzIcjVBTtC7ciQbwbYhN1TQMr3tf_AuT-skSA-X_9lOauzGL31dv3Lj7hQqRBu0stv8?key=F266DdYKyjrziMBoqIpF8A" medium="image">
			<media:title type="html">A screenshot from the video linked above, showing strains of bacteria gradually growing into bands with increasing concentrations of antibiotic, fanning out from points where key mutations occurred.</media:title>
		</media:content>

		<media:content url="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfHtu6cHt8izDgOPsqUFq4LlQe2-X9tsFJeeQNfCy7dsr2MNlzludfJDIpQuRxRAEmU7z0gNqIq-eBjqp1gmoTIqjp2sK94w04bPiAHszCiEfa4FwojIinklOwzL-BWHctVrs5WeZI7qsfNyWjZP00Imjs?key=F266DdYKyjrziMBoqIpF8A" medium="image">
			<media:title type="html">Eater 2, a static shape that persists forever, but has the special property of being able to “eat” gliders that collide with it, recovering its shape after.</media:title>
		</media:content>

		<media:content url="https://lh7-rt.googleusercontent.com/docsz/AD_4nXf6gA-5OxaNWa0rKpTU7QzHUOYa_S6pBQAYecuiFWR2okztfSwoAGHL03vZ2SLEmiOcFqdvR3VtTw1Nx0tOo1TBJIx9SoLRmOrbvpQ0xbNntupupQ0z_0TDxO84pcfSf6ZCpXl1ZsgVeZCc5IYoVw5MzPw?key=F266DdYKyjrziMBoqIpF8A" medium="image">
			<media:title type="html">Monogram, a period-four oscillator, which is small, but occurs very rarely from random conditions.</media:title>
		</media:content>

		<media:content url="https://lh7-rt.googleusercontent.com/docsz/AD_4nXeay7S7PMLnfhvkF5wDd3pkukQeU7IFpsWUpbiR0pvW1V5kwEMn7APgkIip4UlvIjhC8BriCsHD4CC2fi_tBVn_64enDOPCPizrxglozcs735sNys9mU2V-Qo6Ue4FHwRCfnz-dhRIpD0ekMLexD08RF2xz?key=F266DdYKyjrziMBoqIpF8A" medium="image" />
	</item>
	</channel>
</rss>
