distance without having to encode that relationship in the assumptions
one brings to bear on the task.

Exploitative representation is an efficient form of representation when
there is a constant, reliable, causal or informational relationship between
what a device does and how the world is. Thus, rather than encode the
structure of the world and then manipulate those encodings, “smart
mechanisms” can exploit that constancy. As the odometer example suggests, the encoding view also presupposes some mind-world constancy,
but this is presumed only for “input” representations to start the computational process on the right track. Exploitative representation makes a
deeper use of mind-world constancies.

The fact that there are these two different strategies for accomplishing
the same end should, minimally, make us wary of accepting the claim that
innate assumptions are the only way that a computational system could
solve the underdetermination problem. But I also want to develop the
idea that our perceptual system in particular and our cognitive systems
more generally typically exploit rather than encode information about
the world and our relationship to it, as well as say something about where
Marr himself seems to stand on this issue.

An assumption that Egan makes and that is widely shared in the philosophical literatures both on individualism and computation is that at least
the algorithmic level of description within computational psychology is
individualistic. The idea here has, I think, seemed so obvious that it has
seldom been spelled out: Algorithms operate on the syntactic or formal
properties of symbols, and these are intrinsic to the organisms instantiating the symbols. We might challenge this neither by disputing how much
is built into Marr’s computational level, nor by squabbling over the line
between Marr’s computational and algorithmic levels, but, rather, by arguing that computations themselves can extend beyond the head of the
organism and involve the relations between individuals and their environments. This position, wide computationalism, holds that at least some of
the computational systems that drive cognition reach beyond the limits of
the organismic boundary. Its application to Marr’s theory of vision marks
a departure from the parameters governing the standard individualistexternalist debate over that theory. Wide computationalism constitutes
one way of thinking about the way in which cognition, even considered
computationally, is“embedded” or“situated”in its nature, and it provides
a framework within which an exploitative conception of representation
can be pursued.

The basic idea of wide computationalism is simple. Traditionally, the
sorts of computation that govern cognition have been thought to begin
and end at the skull. But why think that the skull constitutes a magic
boundary beyond which true computation ends and mere causation
begins? Given that we are creatures embedded in informationally rich
and complex environments, the computations that occur inside the head
are an important part but are not exhaustive of the corresponding computational systems. This perspective opens up the possibility of exploring
computational units that include the brain as well as aspects of the brain’s
beyond-the-head environment. Wide computational systems thus involve
minds that literally extend beyond the confines of the skull into the world.

In the terms introduced earlier in Part Two, they have wide realizations
(see Figures 7.1 and 7.2).

Standard Computationalism An example: Multiplying
with only internal symbols
Computational system ends at the skull;
computation must be entirely in the
head.

1. Code external world.

2. Model computations between internal
 representations only.

3. Explain behavior, based on outputs from
 Step 2.

figure 7.1. Standard Computationalism
166 Individualism and Externalism in Cognitive Sciences
An example: Multiplying with Wide Computationalism 
internal and external symbols
Computational system can extend
beyond the skin into the world;
computation may not be entirely in the
head.

1. Identify representational or informational
2. Model computations between these
 forms -- whether in the head or not -- that
 constitute the relevant computational
system.

representations.

3. Behavior itself may be part of the wide
computational system.

figure 7.2. Wide Computationalism
One way to bring out the nature of the departure made by wide computationalism draws on a distinction between locational and taxonomic
conceptions of psychological states. Individualists and externalists are
usually presented as disagreeing over how to taxonomize or individuate
psychological states, but both typically presume that the relevant states
are locationally individualistic: They are located within the organismic envelope. What individualists and externalists typically disagree about is
whether in addition to being locationally individualistic, psychological
states must also be taxonomically individualistic. This is, as we have seen,
what is usually at issue in the debate over Marr’s theory of vision, where
the focus has been on whether Marr uses a wide or a narrow notion
of content. Wide computationalism, however, rejects this assumption of
locational individualism by claiming that some of the “relevant states” –
some of those that constitute the relevant computational system – are
located not in the individual’s head but in her environment.

If some cognitive systems, wide computational systems, are not locationally individualistic, then they, and thus the states that constitute them,
