case it is seen as extending beyond the individual into her environment.

Since the relevant part of the environment is often a cultural product,
such as a cognitive artifact, in both cases there are cultural and social
dimensions that are integral to cognition.

Edwin Hutchins’s work on seafaring navigation exemplifies a distributed approach to cognition of both types. While Hutchins is critical
of some of the turns that the computational approach to cognition has
taken, his own views have been developed within an overarching computational framework, one with interpersonal and artifactual dimensions.

Hutchins argues that technology should not be thought of simply as a way
of augmenting individual cognitive capacities, however, but as a means
of changing the nature of the representational spaces or media in which
computations are performed. Computations are not simply performed
in the head of the individual, but occur in interpersonal activities that
make use of recent (and not so recent) cognitive artifacts. The locus of
computation is in the beyond-the-individual world.

Hutchins brings out the interpersonal dimension to the cognitive processes involved in navigation when he says, in his introduction to Cognition
in the Wild, that he hopes
to show that human cognition is not just influenced by culture and society, but
that it is in a very fundamental sense a cultural and social process. To do this I will
move the boundaries of the cognitive unit of analysis out beyond the skin of the
individual person and treat the navigation team as a cognitive and computational
system.36
Here the unit of cognition is not the individual but the navigation team of
which the individual is a part. Both the social organization of the team and
the relationships between its members and various cognitive artifacts (for
example, the alidade, the bearing log, phone circuits, the hoey, the chart,
the fathometer) serve as the cognitive architecture of this larger cognitive unit. For example, consider the fix cycle, which plots the position
of the ship (output) given two lines of position as inputs. This cycle involves the generation, transformation, and utilization of representations
in many individuals and many cognitive artifacts. There is no one place,
in particular, no one individual, in which this process is implemented.

Hutchins’s study of navigation does tell us a lot about the social distribution of cognitive tasks in navigation, showing how modern navigation
176 Individualism and Externalism in Cognitive Sciences
involves exploiting social structures and relationships. And perhaps this
even provides an example of group-level cognition, a topic we will discuss
in detail in Part Four. But Hutchins also highlights how individual-level
cognition often extends beyond the boundary of the individual. For example, he does so in emphasizing how integral the use of representational
artifacts – from calendars, to maps, to alidades, to hoeys – are not only to
team-level cognitive tasks, but also to component, individual-level cognitive tasks – such as reading the alidade, writing an entry on the bearing
log, or adjusting the hoey. Such cognitive processes are realized in wide
computational systems, where these systems constitute ways of extending
an individual’s cognitive capacities. Navigation involves a wide range of
locationally externalist cognitive processes.

A second example that exemplifies this perspective is Dana Ballard’s
work on animate vision in general and on the role of deictic coding
in cognition in particular. Here the central idea is that cognition often
involves rapid updates of information from one’s environment in an unplanned or improvised manner, where this improvisational cognition involves adjusting one’s body, particularly through eye movements, to take
advantage of information that is stored in the environment and thus does
not need to be computed or stored by the individual. For example, vision
involves intense, repeated causal interactions with an environment via
rapid saccadic fixations, which shifts the burden of the computational
load from inside the head to the head-world. Inside-the-head representations are computationally expensive to construct and to maintain, hence
the idea that they are constructed only when necessary, with the representational slack being taken up by interaction with the world.

principle – know only as much as you need to know to get the job done,
where to “know” something is to internally represent it in some way. Exploitative representation reduces the informational load that individuals
bear through exploiting world-mind regularities, and in the case of animate vision this exploitation makes use not simply of such regularities
but the ease with which our bodies can be adjusted to utilize them.

The central novelty of Ballard’s approach to vision is to combine the
concept that looking is a form of doing with the claim that vision is computation. As we saw in section 6, although the ecological psychologist
James J. Gibson recognized the first of these points long ago, his views
were developed in direct opposition to the idea that vision was inferential
or computational. Ballard integrates these two points by introducing the
idea that eye movements constitute a form of deictic coding in that they
are behaviors that orient visual attention and fixation in ways that allow
perceivers to exploit the world as an external storage device. Eye movements are a type of pointing device, a type of“doing-it- where-I’m-looking”
strategy, that means that perceivers need not copy all of the information
in a scene in order to use it in guiding further action.37
Ballard applies this model of cognition not only to vision but also
to attention, memory, and action. Despite the name “deictic coding,” it
represents an approach to cognition that involves exploiting rather than
encoding beyond-the-head environments. Here too, I would suggest that
the idea of a wide computational system, and of cognitive processes being
locationally wide, aptly describe the program of animate vision.

To take a third and final example, consider the “intelligence without
reason” approach to robotics championed by Rodney Brooks that concentrates on developing behavior-based systems. Brooks makes no attempt
to model how people behave, and is explicit that he is not engaged in
any sort of “cognitive modeling” that captures (even in part) the cognitive processes that people instantiate. His goal is to build robots, which
he calls “Creatures,” that behave intelligently in natural environments,
rather than to mimic human performance on some specific task (for example, decision making, block moving, question answering) in an artifi-
cially restricted domain (for example, chess, the blocks worlds, restaurant
scripts, respectively). This is achieved by a subsumption architecture that
builds more complex layers on top of less complex layers, with each layer
achieving some action-centered goal, such as avoiding objects, wandering, or exploring its environment. Layers themselves are composed of
simple finite-state machines that achieve specific behaviors.

One of Brooks’ recurring themes is that the world is its own best model,
and so there is no attempt to have his Creatures encode features of the
world in order to negotiate successfully in it; rather, they exploit those
features. But his Creatures are not relying on symbolic aspects of their
environments or external representations. Indeed, Brooks has claimed
that the notion of representation itself is not readily applicable to his
Creatures at all. Like the claim of some early connectionists that they
had bypassed the notion of representation altogether, this claim seems
