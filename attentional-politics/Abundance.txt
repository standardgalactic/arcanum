This is Audible.

 Simon & Schuster Audio presents Abundance by Ezra Klein and Derek Thompson Read by the authors From Ezra to Annie, Moses, and Kieran, My Abundance And from Derek to Laura and Isla Author's Note Some of the details and the language in this book appeared previously in columns, articles, newsletters, and conversations.

 That were written and produced for the New York Times and the Atlantic.

 Introduction Beyond Scarcity You open your eyes at dawn and you turn in the cool bedsheets.

 A few feet above your head, on the top of your roof, a layer of solar panels is blinking in the morning sun.

 Their power mixes with electricity pulled from several clean energy sources.

 Towering wind turbines to the east, small nuclear power plants to the north, deep geothermal wells to the south.

 Forty years ago, your parents cooled their bedrooms with jewels dredged out of coal mines and oil pits.

 They mined rocks and burned them, coating their lungs in the byproducts.

 They encased their world, your world, in a chemical heat trap.

 Today, it seems barbaric.

 You live in a cocoon of energy so clean, it barely leaves a carbon trace, and so cheap, you can scarcely find it on your monthly bill.

 The year's 2050.

 You walk to the kitchen to turn on the sink.

 Water from the ocean pours out of the faucet.

 It's fresh and clear, piped from a desalination plant.

 These facilities squeeze out the ocean salt.

 Today, they provide more than half of the country's fresh, used water.

 Previously, overtaxed rivers, such as a Colorado, have surged back now that we don't rely on them to irrigate our farms and to fill our coffee mugs.

 In Phoenix and Las Vegas, previously parched cities are erupting in green foliage.

 You open the refrigerator.

 In the fruit and vegetable drawer are apples, tomatoes, and an eggplant, all of them shipped from the nearest farm, mere miles away.

 These crops don't grow horizontally across fields, taking up vast tracts of land.

 They grow vertically on tiered shelves inside a tall greenhouse.

 Banks of LED lights deliver the photons a plant's need in precisely timed increments.

 These skyscraper farms spare countless acres for forests and parks.

 As for the chicken and beef, much of it comes from cellular meat facilities, which grow animal cells to make chicken breasts and ribeye steaks.

 No live animals needed, which means no confinement and no slaughter.

 Once prohibitively expensive, cultivated meat scaled with the help of plentiful electricity.

 When your parents were young, nearly 25% of all global land was used to raise livestock for human consumption.

 That is unimaginable now.

 Much of that land is rewilded.

 Out the window and across the street, an autonomous drone is dropping off the latest shipment of star pills.

 Several years ago, daily medications that reduced overeating, that cured addiction, that slowed cellular aging, were considered miracle drugs for the rich, particularly after we learned the key molecules were best made in the zero-gravity conditions of space.

 But these days, automated factories thrum in low orbit.

 Cheap rocketry conveys a medicine down to Earth, where it has saved millions of lives and billions of healthy years.

 Outside, the air is clean and humming with a purr of electric machines all around you.

 Electric cars and trucks glide down the road, quiet as a light breeze and mostly self-driving.

 Children and adult commuters follow on electric bikes and scooters, some personally owned and some belonging to subscription networks run by the city.

 Another last-mile delivery drone descends from canopy level, pauses over a neighbor's yard like a hummingbird, and drops off a package.

 These e-bots now deliver a sizable chunk of online orders, reducing the drudgery of much human delivery work.

 Your micro-ear piece pings, a voice text from a friend and his family.

 They're on their way to the airport for another weekend vacation.

 Across the economy, the combination of artificial intelligence, labor rights, and economic reforms have reduced poverty and shortened the work week.

 Thanks to higher productivity from AI, most people can complete what used to be a full week of work in a few days, which has expanded the number of holidays of long weekends and vacations.

 Less work has not meant less pay.

 AI is built on the collective knowledge of humanity and so its profits are shared.

 Your friends are flying from New York to London.

 The trip will take them just over two hours.

 Modern jetliners now routinely reach Mach 2, twice the speed of sound, using a mix of traditional and green synthetic fuels that release far less carbon into the air.

 The world has changed, not just the virtual world.

 That dance of pixels on our screens.

 The physical world, too.

 Its houses, its energy, its infrastructure, its medicines, its hard tech.

 How different this era is from the opening decades of the 21st century, which unspooled a string of braided crises.

 A housing crisis, a financial crisis, a pandemic, a climate crisis, political crises.

 For years, we accepted homelessness and poverty and untreated disease and declining life expectancy.

 For years, we knew what we needed to build to alleviate the scarcity so many faced and create the opportunities so many wanted.

 But we simply didn't build it.

 For years, we failed to invent and implement technology that would make the world cleaner, healthier, and richer.

 For years, we constrained our ability to solve the most important problems we faced.

 Why?

 Scarcity is a choice.

 This book is dedicated to a simple idea.

 To have the future we want, we need to build and invent more of what we need.

 That's it.

 That's a thesis.

 It sounds, even to us, too simple.

 And yet, the story of America in the 21st century is a story of chosen scarcities.

 Recognizing that these scarcities are chosen, that we could choose otherwise, is thrilling.

 Confronting the reasons we choose otherwise is maddening.

 We say that we want to save the planet from climate change, but in practice, many Americans are dead set against a clean energy revolution, with even liberal states shutting down zero-carbon nuclear plants and protesting solar power projects.

 We say that housing is a human right, but our richest cities have made it excruciatingly difficult to build new homes.

 We say we want better health care, better medicine, and more cures for terrible diseases.

 But we tolerate a system of research, funding, and regulation that pulls scientists away from their most promising work, denying millions of people the discoveries that might extend or improve their lives.

 Sometimes these blockages reflect differences of beliefs or interests.

 A thousand square acres of solar panels can be a godsend to the city they power, and a blight to the community they abut.

 A seven-story affordable apartment building in San Francisco means homes for those who would otherwise live hours from their work, even as it blocks views and clogs parking for those who lived there before.

 Other times, our crises reflect the overhang of the past into the present.

 One generation's solutions can become the next generation's problems.

 After World War II, an explosion of housing and infrastructure enriched the country.

 But without regulations for clean air and water, the era's builders despoiled the environment.

 In response, the U.S. rushed to pass new environmental regulations.

 But these well-meaning laws to protect nature in the 20th century now blocked the clean energy projects needed in the 21st.

 Laws meant to ensure that government considers the consequences of its actions have made it too difficult for government to act consequentially.

 Institutional renewal is a labor that every generation faces anew.

 But some of this reflects a kind of ideological conspiracy at the heart of our politics.

 We are attached to a story of American decline that is centered around ideological disagreement.

 That makes it easy to miss pathologies rooted in ideological collusion.

 Over the course of the 20th century, America developed a right that fought the government and a left that hobbled it.

 Debates over the size of government obscured the diminishing capacity of government.

 An abundance of consumer goods distracted us from a scarcity of homes and energy and infrastructure and scientific breakthroughs.

 A counterforce is emerging, but it is young yet.

 The Supply Side Mistake At the heart of economics is supply and demand.

 Supply is how much there is of something.

 Demand is how much of that thing people want.

 Economies balance when supply and demand meet and derange when they part.

 Too much demand chasing too little supply causes shortages, price increases, and rationing.

 Too much supply pooling around too little demand brings gluts, layoffs, and depressions.

 Supply and demand are linked.

 At least, they are in the real world.

 In our politics, they have been cleaved apart.

 Republicans and Democrats divvied them up.

 The word supply side are coded as right-wing.

 They summon memories of the curve that the conservative economist Arthur Laffer jotted on a napkin in the 1970s, showing that when taxes are too high, economies slow and revenues, paradoxically, fall.

 This led, in part, to decades of Republican promises that cutting taxes on the rich would encourage the nation's dispirited John Galtz to work smarter and harder, leading economies to boom and revenues to rise.

 Tax cuts are a useful tool, and it is true that high taxes can discourage work.

 But the idea that tax cuts routinely lead to higher revenues is, as George H.W. Bush said, voodoo economics.

 It has been tried.

 It has failed.

 It has been tried again.

 It has failed again.

 These failures and the Republican Party's dogged refusal to stop trying the same thing and expecting a different result made it vaguely disreputable to worry about the supply side of the economy.

 It's as if the nonsense of phrenology made it sordid for doctors to treat disorders of the brain.

 But the conservative agenda did something else, too.

 It cast production as a function of unfettered markets.

 Supply-side economics was about getting the government out of the private sector's way, cutting taxes so people would work more, cutting regulations so companies would produce more.

 But what of the places where society needed to supply something that the market could not, or would not, provide on its own?

 This is where you might have expected Democrats to step in, but Democrats cowed by the Reagan revolution and frightened of being seen as socialists largely confine themselves to working on the demand side of the ledger.

 When Americans in 1978 heard that government cannot solve our problems, it can't set our goals, it cannot define our vision, the words didn't come from Ronald Reagan.

 They came from President Jimmy Carter, a Democrat in his State of the Union.

 This was a preview of things to come.

 In 1996, the next Democratic president, Bill Clinton, announced that the era of big government is over.

 The notion that the U.S. government cannot solve America's problems was not unilaterally produced by Reagan and the GOP.

 It was co-produced by both parties and reinforced by their leaders.

 Progressivism's promises and policies for decades were built around giving people money, or money like vouchers, to go out and buy something that the market was producing but that the poor could not afford.

 The Affordable Care Act subsidizes insurance that people can use to pay for health care.

 Food stamps give people money for food.

 Housing vouchers give them money for rent.

 Pell grants give them money for college.

 Tax credits for child care give people money to buy child care.

 Social Security gives people money for retirement.

 The minimum wage and the earned income tax credit give them more money for anything they want.

 These are important policies and we support them.

 While Democrats focused on giving consumers money to buy what they needed, they paid less attention to the supply of the goods and services they wanted everyone to have.

 Countless taxpayer dollars were spent on health insurance, housing vouchers, and infrastructure without an equally energetic focus, sometimes without any focus at all, on what all that money was actually buying and building.

 This reflected a faith in the market that was, in its way, no less touching than that offered by Republicans.

 It assumed that so long as enough money was dangled in front of it, the private sector could and would achieve social goals.

 It revealed a disinterest in the workings of government.

 Regulations were assumed to be wise.

 Policies were assumed to be effective.

 Cries that government was stifling production or innovation typically fell on deaf ears.

 A blind spot emerged.

 Political movements consider solutions where they know to look for problems.

 Democrats learned to look for opportunities to subsidize.

 They lost the knack for making it easier to build.

 The problem is that if you subsidize demand for something that is scarce, you'll raise prices or force rationing.

 Too much money chasing too few homes means windfall profits for homeowners and an affordability crisis for buyers.

 Too much money chasing too few doctors means long wait times or pricey appointments.

 This leads to the standard Republican riposte.

 Just don't subsidize demand.

 Keep the government out of it.

 Let the market work its magic.

 Well, that's fine for goods where access is not a matter of justice.

 If virtual reality headsets are expensive, well, so be it.

 It's not a public policy problem if most households can't afford a VR headset.

 But that cannot be said for housing and education and medicine.

 Society cares about access to these goods and services as well it should.

 Democrats and Republicans passed policies into law that, collectively, spend trillions of dollars helping people afford them.

 But giving people a subsidy for a good whose supply is choked is like building a ladder to try to reach an elevator that is racing ever upward.

 The results of that mistake are everywhere.

 In 1950, the median home price was 2.2 times the average annual income.

 By 2020, it was six times the average annual income.

 Between 1999 and 2023, the average premium for employer-based family health insurance rose from $5,791 to $23,968, an increase of more than 300%, and the worker contribution to that premium more than quadrupled.

 In 1970, the average annual cost of tuition and fees was $394 in public colleges and $1,706 at private colleges.

 In 2023, it was $11,310 in public colleges, and that was for in-state students, and it was $41,740 at private colleges.

 Child care for an infant and a four-year-old costs on average, $36,008 in Massachusetts, $28,420 in California, and $28,338 in Minnesota.

 An uncanny economy has emerged in which a secure, middle-class lifestyle receded from many, but the material trappings of middle-class success became affordable to most.

 In the 1960s, it was possible to attend a four-year college debt-free, but impossible to purchase a flat-screen television.

 By the 2020s, the reality was closer to the reverse.

 We papered over the affordability crisis with the low prices for consumer goods, soaring asset values that kept richer Americans happy, and mountains of debt, housing debt and student loan debt and medical debt that kept the working class semi-afloat.

 This makes some sense of the last few decades of our economic debates, a crisis of housing debt, a huge new program to subsidize health insurance costs, debates about making college-free and forgiving student loans, endless rounds of tax cuts, proposal after proposal for the government to pay for child care and preschool, a bubble in crypto that attracted so many investors in part because it seemed like a rocket ship into wealth that anyone could ride.

 But then came inflation.

 For years, the central problem in the American economy was demand.

 We both reported on the financial crisis.

 Back then, every conversation with Obama administration economists was about how to get employers to hire and consumers to spend.

 The 2009 stimulus was too small, and while we avoided a second Great Depression, we sank into an achingly slow recovery.

 Democrats carried those lessons into the COVID pandemic.

 They met the crisis with overwhelming fiscal force, joining with the Trump administration to pass the $2.2 trillion CARES Act and then adding the $1.9 trillion American Rescue Plan Act and the trillion dollar infrastructure bill on top.

 Democrats made clear that they preferred the risks of a hot economy, including inflation, to the threat of mass joblessness.

 They succeeded, but solving the crisis of the pandemic economy created a new crisis for the post-pandemic economy.

 Too much demand.

 Supply chains had been battered by the pandemic and Russia's invasion of Ukraine began to break.

 Inflation returned with a vengeance.

 The conversations we had with the Biden administration's economists were different from the ones we had with the Obama administration's economists.

 That was true even when we were talking to the same people.

 They needed companies to make more goods and make them faster.

 They needed more chips so there could be more cars and computers.

 They needed ports to clear more shipments and Pfizer to make more antiviral pills and shipping companies to hire more truckers and schools to upgrade ventilation systems.

 They needed more supply and if they could not get that, they needed less demand.

 If car prices are too high right now, there are two solutions, President Biden said.

 You increase the supply of cars by making more of them or you reduce demand for cars by making Americans poorer.

 That's the choice.

 By 2024, the surge in prices had slowed.

 Inflation, as economists measure it, had eased.

 But the broader affordability crisis that predated the bout of inflation persisted.

 The fear that we did not or would not have enough of what we needed settled heavily on politics.

 Policymakers began to rethink globalization, warning that we cannot depend on critical exports from China if conflict or crisis came between our nations.

 Governors and mayors turned their attention to housing supply as homeless encampments spread across their streets.

 The Inflation Reduction Act began the work of building the green infrastructure necessary to migrate our economy to clean energy.

 The Chips and Science Act dangled tens of billions of dollars to restart semiconductor manufacturing in America.

 Whether these policies will work remains to be seen.

 These policies represent a break with recent decades of American politics is undeniable.

 Politics is not just about the problems we have.

 It's about the problems we see.

 The supply problem has lurked for years, but it has not been the core of our politics.

 That's changing.

 A new theory of supply is emerging, and with it, a new way of thinking about politics, economics, and growth.

 Society is not a pie.

 Perhaps you've heard the clich√© that the economy is a pie must grow rather than slice.

 It's hard to know where to begin with what this image gets wrong because it gets almost nothing right.

 If you somehow grew a blueberry pie, you'd get more blueberry pie.

 But economic growth is not an addition of sameness.

 The difference between an economy that grows and an economy that stagnates is change.

 When you grow an economy, you hasten a future that is different.

 The more growth there is, the more radically the future diverges from the past.

 We've settled on a metaphor for growth that erases its most important characteristic.

 If you dig within the equations of power modern economics, you'll find that growth comes from one of a few places.

 An economy can grow because it adds more people.

 It can grow because it adds more land or natural resources.

 But once those avenues are exhausted, it needs to do more with what it has.

 People need to think up new ideas.

 Factories need to innovate new processes.

 These new ideas and new processes must be encoded into new technologies.

 All this is grouped under the sterile label of productivity.

 How much more can we produce with the same number of people and resources?

 When productivity surges, what we get is not more of what we had, but new things that we never imagined.

 Imagine going to sleep in 1875 in New York City and waking up 30 years later.

 As you shut your eyes, there is no electric lighting, no Coca-Cola or basketball or aspirin.

 There are no cars or sneakers.

 The tallest building in Manhattan is a church.

 When you wake up in 1905, the city has been remade with towering steel skeleton buildings called skyscrapers.

 The streets are filled with novelty.

 Automobiles powered by new internal combustion engines, people riding bicycles and rubber-soled shoes, all recent innovations.

 The Sears catalog, the cardboard box, aspirin, all new arrivals.

 People have enjoyed their first sip of Coca-Cola and their first bite of what we now call an American hamburger.

 The Wright brothers have flown the first airplane.

 When you passed into slumber, nobody had taken a picture with a Kodak camera or used a machine that made motion pictures or bought a device to play recorded music.

 By 1905, we have the first commercial versions of all three, the simple box camera, the cinematograph, and the phonograph.

 Now imagine dozing off for another 30-year nap between 1990 and 2020.

 You would wonder at the dazzling ingenuity that we funneled into our smartphones and computers.

 But the physical world would feel much the same.

 That is reflected in the productivity statistics, which record a slowing of change as the 20th century wore on.

 This is not just a problem for our economy.

 It is a crisis for our politics.

 The nostalgia that permeates so much of today's right and no small part of today's left is no accident.

 We have lost the faith in the future that once powered our optimism.

 We fight instead over what we have or what we had.

 Our era features too little utopian thinking, but one worthy exception is Aaron Bastani's fully automated luxury communism, a leftist track that puts the technologies in development right now.

 Artificial intelligence, renewable energy, asteroid mining, plant and cell-based meats, and gene editing at the center of a post-work, post-scarcity vision.

 What if everything could change, he asks.

 What if more than simply meeting the great challenges of our time, from climate change to inequality to aging, we went far beyond them, putting today's problems behind us like we did before, with large predators and, for the most part, illness.

 What if, rather than having no sense of a different future, we decided history hadn't actually begun?

 It is routine in politics to imagine a just present and work backwards to the social insurance programs that would get us there.

 It is equally important to imagine a just, even a delightful, future and work backward to the technological advances that would hasten its arrival.

 Bastani's vision is bracing because it insists that those of us who believe in a fairer, gentler, more sustainable world have a stake in bringing forward the technologies that will make that world possible.

 That is a political question as much as a technological one.

 Those same technologies could become accelerators of inequality and despair if they're not embedded in just policies and thoughtful institutions.

 What Bastani sees is that the world we want requires more than redistribution.

 We aspire to more than parceling out the present.

 New technologies create new possibilities.

 They allow us to solve once-impossible problems.

 In a world where many of the countries with the largest greenhouse gas emissions are middle-income nations like China and India, the only way for humanity to limit climate change while fighting poverty is to invent our way to clean energy that is plentiful and cheap and then spend enough to deploy it.

 The only reason we have even the barest hope of avoiding catastrophic warming is that the cost of solar power has fallen by 89% and onshore wind costs by almost 70% in just 10 years.

 California's decision to ban the sale of new gas-powered cars after 2035 would be unthinkable without the rapid advances in battery technology.

 Much that we need for the world we want we already know how to build.

 But much that we need for the world we want still needs to be invented and improved.

 Green hydrogen and cement, nuclear fusion, treatments for the terminal cancers that overwhelm today's therapies and the shadowy autoimmune diseases that baffle today's doctors.

 AI that molds itself to the needs of children who learn and think differently.

 Markets will, we hope, proffer some of these advances but not nearly enough of them.

 The market cannot on its own distinguish between the riches that flow from burning coal and the wealth that is created by bettering battery storage.

 Government can.

 The market will not on its own fund the risky technology whose payoff is social rather than economic.

 Government must.

 But let us not be naive.

 It is childish to declare government the problem.

 It is just as childish to declare it the solution.

 Government can be either the problem or the solution.

 It is often both.

 By some counts, nuclear power is safer than wind and cleaner than solar.

 It is inarguably safer than burning coal and petrol.

 And yet the U.S., facing a crisis of global warming, has almost stopped building nuclear power reactors and plants entirely.

 Between 1973 and 2024, the country started and finished only three new nuclear reactors.

 And it has shut down more nuclear plants than it has opened in most of our lifetimes.

 That is not a failure of the private market to responsibly bear risk, but of the federal government to properly weigh risk.

 To take technology seriously as a force for change is to take it seriously as infused with values and, yeah, politics.

 The relationship is bi-directional.

 It's not just that the politics we have will affect the technologies we develop.

 The technologies we develop will shape the politics we come to have.

 A world where renewable energy is plentiful and cheap permits a politics that is different than a world where it is scarce and pricey.

 A world where modular construction has brought down the cost of building opens different possibilities for state and local budgets.

 In 1985, the great technology critic Neil Postman wrote, To be unaware that a technology comes equipped with a program for social change, to maintain that technology is neutral, to make the assumption that technology is always a friend to culture, is, at this late hour, stupidity, plain and simple.

 But the corollary is also true.

 To have no program to harness technology in service of social change is, at this late hour, its own form of blindness.

 Too often, the right sees only the imagined glories of the past, and the left sees only the injustices of the present.

 Our sympathies there lie with the left, but it's not a debate we can settle.

 What is often missing from both sides is a clearly articulated vision of the future and how it should differ from the present.

 This book is a sketch of, and an argument for, one such a vision.

 A Liberalism That Builds We are both liberals in the American tradition.

 The problems we seek to solve are mostly problems that exist within the zone of liberal concern.

 We worry over climate change and health inequality.

 We want more affordable housing and higher median wages.

 We want children to breathe cleaner air and commuters to move easily on mass transit systems.

 We have many disagreements with the modern American right, but we focus in this book on the pathologies of the broad left.

 One reason for that is we don't see ourselves as effective messengers to the right.

 There are people seeking complementary reforms in that coalition, such as James Pethokoukis, author of The Conservative Futurist, the economist Tyler Cowen, who has called for a state-capacity libertarianism, and the array of policy experts organized in the Niskanen Center.

 We wish them well.

 But we focus on the left for larger reasons.

 This book is motivated in no small part by our belief that we need to decarbonize a global economy to head off the threat of climate change.

 To the extent that the right simply does not believe this, and in America, at least, it does not, it strikes us as naive to describe the policies that would help Republicans build green infrastructure faster.

 It is folly to expect a coalition that does not share our goals to do the work to achieve them.

 It is more interesting to ask, as we will, why it is often easier to build renewable energy in red states and in blue states, despite Republican opposition to the cause of climate change.

 Then there is the anger any liberal should feel when looking at the states and cities liberals govern.

 One of us was born in California and lived there throughout much of the writing of this book.

 California's most populous cities are run by Democrats.

 Every statewide elected official in California, every single one, is a Democrat.

 Both chambers of the legislature are run by Democrats.

 And California is, make no mistake, a land of wonders.

 It leads the world in developing new technology.

 It creates a culture that much of the world consumes.

 It is astonishingly, breathtakingly beautiful.

 If it were its own country, it would have the fifth largest GDP in the world.

 Liberals should be able to say, vote for us and we will govern the country the way we govern California.

 Instead, conservatives are able to say, vote for them and they will govern the country the way they govern California.

 California spent decades trying and failing to build high-speed rail.

 It has the worst homelessness problem in the country.

 It has the worst housing affordability problem in the country.

 It trails only Hawaii and Massachusetts in its cost of living.

 As a result, it is losing hundreds of thousands of people every year to Texas and Arizona.

 California's problems are often distinct in their severity, but not in their structure.

 The same dynamics are present in other blue states and cities.

 In this era of rising right-wing populism, there is pressure among liberals to focus only on the sins of the MAGA right.

 But this misses the contribution that liberal governance made to the rise of Trumpism.

 In their book Presidents, Populism, and the Crisis of Democracy, the political scientists William Howell and Terry Moe write that populists don't just feed on socioeconomic discontent.

 They feed on ineffective government.

 And their great appeal is that they claim to replace it with a government that is effective through their own autocratic power.

 In the 2024 election, Donald Trump won by shifting almost every part of America to the right.

 But the signal Democrats should fear most is that the shift was largest in blue states and blue cities.

 the places where voters were most exposed to the day-to-day realities of liberal governance.

 Nearly every county in California moved towards Trump, with Los Angeles County shifting 11 points towards the GOP.

 In and around the blue wall states, Philadelphia County shifted 4 points right, Wayne County, where Detroit is, shifted 9 points right, and Cook County, the home of Chicago, shifted 8 points right.

 In the New York City metro area, New York County, where Manhattan lies, shifted 9 points right.

 Kings County, which holds Brooklyn, shifted 12 points right.

 Queens County shifted 21 points right.

 And Bronx County shifted 22 points right.

 Voting is a cheap way to express anger.

 Moving is expensive.

 But residents of blue states and cities have been doing that, too.

 In 2023, California lost 342,000 more people than it gained.

 In Illinois, the net loss was 115,000.

 In New York, 284,000.

 And in the American political system, to lose people is to lose political power.

 If current trends hold, the 2030 census will shift the Electoral College sharply to the right.

 Even adding Michigan, Pennsylvania, and Wisconsin to the states Kamala Harris won won't be enough for Democrats to win future presidential elections.

 The problem here is not just political.

 Young families are leaving large urban metros so quickly that several counties, including those encompassing Manhattan, Brooklyn, Chicago, Los Angeles, and San Francisco, are on pace to lose 50%, 50% of their under-five childhood population in the next 20 years.

 Democrats cannot simultaneously claim to be the party of middle-class families while presiding over the parts of the country that middle-class families are leaving.

 A good way to marginalize the most dangerous political movements is to prove the success of your own.

 If liberals do not want Americans to turn to the false promise of strongmen, they need to offer them the fruits of effective government.

 Redistribution is important, but it is not enough.

 The Abundant Society There is a word that describes the future we want.

 Abundance.

 We imagine a future not of less, but of more.

 We do not subscribe to the seductive ideologies of scarcity.

 We will not get more or better jobs by closing our gates to immigrants.

 We will not turn back climate change by persuading the world to starve itself of growth.

 It's not merely that these visions are unrealistic.

 It's that they are counterproductive.

 They will not achieve the futures they promise.

 They will do more harm than good.

 But the abundance we envision is not indiscriminate.

 It's not an omnidirectional mournus.

 We take inspiration from People of Plenty, the historian David M. Potter's brilliant 1954 book on how abundance shaped American thought and culture.

 If abundance is to be properly understood, he wrote, it must not be visualized in terms of a storehouse of fixed and universally recognizable assets.

 reposing on shelves until humanity, by a process of removal, strips all the shelves bare.

 Abundance, he said, is a physical and cultural factor involving the interplay between man, himself a geological force, and nature.

 The kind of abundance we seek differs from the kind of abundance our generation has seen.

 Potter wrote of the way America was being reoriented to convert the producer's culture into a consumer's culture.

 and the rupture deepened in the decades that followed.

 American policy has been focused on enacting what the historian Elizabeth Cohen calls a consumer's republic.

 And it has been remarkably successful at that.

 Catastrophically successful.

 We have a startling abundance of the goods that fill a house and a shortage of what is needed to build a good life.

 We call for a correction.

 We are interested in production more than consumption.

 we believe we believe that what we can build is more important than what we can buy.

 Abundance as we define it is a state.

 It is a state in which there is enough of what we need to create lives better than what we have had.

 And so we are focused on the building blocks of the future.

 Housing, transportation, energy, health.

 And we are focused on the institutions and the people that must build and invent that future.

 Let's begin.

 Let's begin.

 Let's begin.

 Chapter One Grow Go west, young man.

 Go west.

 There is health in the country and room away from our crowds of idlers and imbeciles.

 It's not clear if Horace Greeley, the newspaper editor and liberal presidential candidate, ever uttered the advice so famously attributed to him.

 What is clear is that he never followed it.

 Greeley was born in 1811 to a poor family in rural Amherst, New Hampshire.

 He did not seek his fortune in the vast expanse of the American West.

 He made his way to New York City in 1831.

 It was there in the teeming center of urban American life that he built his wealth and his name, founding the New York Tribune, winning election to Congress, and losing the presidency to Ulysses S. Grant.

 The tension between Greeley's life and his legacy echoes that of the country he loved.

 Americans have long lionized the frontier, but our futures have largely been made in our cities.

 Though he preferred the romance of the West to the math of the tenements is no new fact.

 In David Potter's People of Plenty, he writes, We often forget that the country as a whole offered abundance in the form of fuel resources, mineral resources, bumper crops, industrial capacity, and the like, and provided the city as a locus for the transformation of this abundance into mobility.

 More Americans have changed their status by moving to the city than have done so by moving to the frontier.

 But that's not the story America told itself.

 The Western expanse lingered in our mind as a true guarantor of our prosperity.

 Its settlement inflicted a kind of psychic trauma.

 Europe and cities, too.

 What America had was open, often stolen, land.

 Without that, wouldn't we, too, fall into stagnation?

 The fear held well into the 20th century, emerging as a partial explanation for the Great Depression.

 Senator Louis Schwellenbach, a New Dealer who would serve as President Harry Truman's Secretary of Labor, warned that, so long as we had an undeveloped West, new lands, new resources, new opportunities, we had no cause to worry.

 But those days were over.

 Alvin Hansen, an influential economist, offered a more sophisticated version of his view.

 We are more or less through the heavy task of equipping the continent with giant capital expenditures, he said.

 The Depression, in this telling, heralded a new normal.

 A mature America could not expect the torrid growth of an expanding America.

 But economies are not bounded by land.

 Ideas, and the technologies and companies and products they power, they draw the outer borders of growth.

 The land that matters most is the land that aids in the fiery creation of the new.

 That land is in the heart of our cities, not at the edge of our settlements.

 And that land reveals a problem America faces now.

 A young family can still follow Horace Greeley's advice and find a cheap home in the rural West.

 What they typically cannot do is follow Horace Greeley's example and build a life in Manhattan where the median home now sells for $1.1 million.

 Or in San Francisco where the median home sells for $1.3 million.

 Or in Los Angeles where the asking price hovers around $1 million.

 Or in Seattle where the median home is over $900,000.

 Or in Boston where it's $830,000.

 Housing follows the laws of supply and demand.

 When supply is thick and demand is light, prices fall.

 You can see that in Cleveland where the average home now sells for about $115,000.

 But when supply is tight and demand is hot, prices rise.

 That's the story of the pricey blue cities.

 America used to be adept at building homes.

 In 1950, the U.S. Census Bureau reported, that America had added 8.5 million units in the previous decade, even with the interruption of a world war.

 This is the greatest numerical growth on record, the authors announced.

 But in the late 1970s, home construction started to fall behind the pace of population growth.

 New permits per capita declined in the 1980s and declined again in the 1990s.

 After the Great Recession, the housing market crashed and home construction in the 2010s was obliterated.

 Today, the average number of dwellings per thousand people in the developed world is about 470, according to the Organization for Economic Cooperation and Development.

 France and Italy have nearly 600 dwellings per thousand people.

 Japan and Germany have about 500.

 The U.S.

 only has about 425.

 So where did all the houses go?

 The answer is that they were never built at all.

 The result is a housing crisis of staggering proportions.

 Almost 30% of American adults are house poor, spending 30% or more of their income on housing.

 But that understates the problem because it doesn't take into account where people live.

 Housing costs are highest in the superstar cities and now drive the economy.

 But millions endure multi-hour commutes or far worse jobs because they have to live instead in a far-flung city where they can afford a home.

 These choices are missed in raw estimates of affordability but they are a drag on the economy and an anchor on people's lives.

 To immerse yourself in analyses of American housing is to drown yourself in data.

 Trust me.

 But sometimes a number stands out.

 Here's one that stood out to me.

 The economist Ed Glazer calculates that before the 1980s wages in New York City were unusually high even after you corrected for the local cost of living.

 The city had its problems but most people would make more money by moving there.

 But now that's flipped.

 By the year 2000 moving to New York meant, for most people, taking an effective pay cut.

 It's not because paychecks have shrunk but because housing costs have risen.

 People now pay to live in New York City.

 They aren't paid to live there.

 If New York City is a business it isn't Walmart.

 It isn't trying to be the lowest priced product in the market.

 That's Michael Bloomberg, the mayor of New York City speaking in 2003.

 He went on to say it's a high-end product maybe even a luxury product.

 New York was once where you went to make your fortune.

 It's now where you go to spend it.

 Comments like Bloomberg's are common.

 If you cannot afford to live in the city don't.

 Every so often social media will convulse over some urbanite claiming they can't afford a middle-class lifestyle on $450,000 a year or some similarly princely sum.

 A common retort even among self-styled progressives is that they opted out of a middle-class lifestyle the moment they opted into an apartment on the Upper West Side.

 They chose to spend their money on an unattainable luxury no different than if they purchased a speedboat or begun collecting pricey art.

 Too many have bought into a perverse inversion of what the city should be.

 Cities are where wealth is created not just where it is displayed.

 They are meant to be escalators into the middle-class not penthouses for the upper-class.

 But through bad policy and worse politics we are doing in the 21st century what we so feared in the 19th.

 We are finally closing the American frontier.

 Why cities matter now more than ever.

 A capsule history of the past few centuries of transportation and communication technology might simply say this we fought distance and we won.

 In 1800 it took a month and a half to travel from New York City to Chicago.

 In 1830 it took three weeks.

 In 1850 it took two days.

 Today a flight takes two to three hours.

 The telegraph and the telephone and email and teleconferencing made further mockery of space.

 It is now faster to FaceTime family across a continent than to rouse a neighbor across the street.

 What are cities at their most elemental?

 Cities are the absence of physical space between people and companies writes Ed Glazer in his book Triumph of the City.

 It's a great definition.

 Cities are the ancient answer to the difficulties of distance.

 But technology eroded their obvious advantages.

 Cities should have languished.

 They have so often been expected to languish.

 But they have stubbornly refused to accept their fate.

 Instead they thrived attaining a centrality and modernity they didn't possess even in antiquity.

 This, Glazer writes, is the central paradox of the modern metropolis.

 Proximity has become ever more valuable as the cost of connecting across long distances has fallen.

 In the new Geography of Jobs, Enrico Moretti, an economist at the University of California at Berkeley, explains why.

 A century ago, the American economy produced primarily physical goods.

 But now, we make ideas and services.

 Some of those are encoded into physical goods, but even then, the raw production often happens elsewhere.

 The iPhone made Apple, which is based in Cupertino, California, into the most valuable company in the world, even though two-thirds of the iPhones that made it so valuable are assembled in Foxconn factories in Shenzhen, China.

 Microsoft and Alphabet mostly sell bits of intangible code.

 Tesla's value lies in the software and battery advances that have taken electric vehicles from the automotive equivalent of Granola to the sleek, fast cars of the future.

 We do not trade in the fallacious belief that manufacturing and innovation are distant domains.

 Taiwan started out manufacturing commodity semiconductor chips that Intel cared little about.

 Over time, its lead in production allowed it to develop advanced chips that American companies cannot yet replicate, and that American policymakers' fear falling into Chinese hands.

 America lost its primacy in semiconductor innovation because much is learned in the making of things, a theme to which we'll return.

 The economic frontier is where new discoveries allow for the making of new things that can be sold to ever more people.

 The rising returns to innovation are a result of the same technological forces that should have decimated the city.

 As distance collapsed, markets expanded.

 It was once difficult to expand your business to another region.

 Shipping was costly and communication was challenging.

 That gave local producers a modest advantage.

 The factory nearby might not be best, but it was close, and that often made its products cheaper.

 Today, it is routine for many businesses to sell across state lines and across national borders.

 Goods that can be produced anywhere can also be purchased anywhere.

 Omnipresence is yet easier for digital products, where all that's needed is a download or the quick flash of an advertisement across a browser screen.

 Less than half of Apple's revenue comes from North America.

 Slightly more than half of Alphabet's revenue is international.

 The same holds for Tesla.

 Cities are engines of creativity because we create in community.

 We are spurred by competition.

 We need to find the colleagues and the friends and the competitors and the antagonists who unlock our genius and add their own.

 Ed Glazer writes that Americans who live in metropolitan areas with more than a million residents are, on average, more than 50% more productive than Americans who live in smaller metropolitan areas.

 These relationships are the same even when we take into account the education, experience, and industry of workers.

 They're even the same if we take individual workers' IQs into account.

 This is not just a dumb gift of density.

 Jamming a mass of people into a chosen place will not allow you to recreate what other groups of people have achieved elsewhere, as the Soviet Union found out again and again.

 Cities are not interchangeable.

 What each offers is a specific gift of the ecosystems of people and practice it has nurtured.

 Once deep communities of interest and industry form, they are difficult to dislodge and they prove nearly impossible to replicate.

 New York leads the world in finance.

 San Francisco and Silicon Valley lead the world in technology.

 New York has tried hard to take Silicon Valley's crown.

 But if you look for multi-billion dollar technology companies in New York, you will find few of them.

 Where New York City has seen technological success is where code serves finance.

 Bloomberg is a multi-billion dollar technology business built around providing data to financial firms.

 Banks like Goldman Sachs and J.P. Morgan Chase now employ thousands of software engineers.

 The same is true in reverse in San Francisco.

 There are successful banks and investment firms, but they mostly serve technology companies.

 The result is that even global businesses are rooted in local phenomena.

 Take the rise of generative AI companies.

 Outside China, the industry is concentrated within a few square miles along the California coast.

 Open AI is not far from Anthropic, which is a quick drive to Google, which is located near Meta.

 The sole exception is DeepMind, which is based in London, but sold itself to Google in part because it needed the computing expertise their Silicon Valley-based engineers provided.

 So why doesn't Toronto or Atlanta or New York or Barcelona or Los Angeles or Berlin have a major entrant in the industry?

 Why not build your AI behemoth somewhere really nice to live, like Maui or Bali?

 These companies are feeding digital data to algorithms running on off-site server farms.

 In theory, this arrangement should be possible anywhere.

 In practice, the frontier of ideas is best breached by people who know each other well and work with each other closely and move between different companies with different cultures and specialties smoothly.

 Those much-mocked Bay Area parties where young AI engineers gather in group houses to ingest psychedelics and contemplate the singularity, they matter.

 Enrico Moretti writes that companies appear to locate in absolutely the worst places.

 They pick very expensive areas, the Boston, San Francisco's, and New York's of the world.

 With sky-high wages and office rents, these are among the costliest places in America to operate a business.

 We would expect these cities to be unattractive for firms, especially those that compete globally.

 But they're not.

 It's the firms that locate outside these cities that struggle.

 The money you save in rent doesn't make up for the talent and knowledge that dissipate over distance.

 Walmart is famously frugal, maintaining its headquarters in Bentonville, Arkansas, and insisting top executives locate there, too.

 But when it wanted to enter into e-commerce, it didn't pile software engineers into a new wing of its headquarters.

 Moretti notes that instead, it chose Brisbane, California, just seven miles from downtown San Francisco, one of the most expensive labor markets in the world.

 Walmart saw what many tech executives see.

 If you want the best software products, you need to locate amid the best software engineers.

 Those engineers aren't cheap to hire, but if a few dozen or a few hundred of them can build you an e-commerce platform that you will use for millions or billions in sales, it'd be foolish to locate elsewhere.

 Walmart now trails only Amazon in annual online sales.

 Some thought that the dislocations of the pandemic, combined with the rise of videoconferencing, would finally sever the link between place and innovation.

 And it's undeniable that white-collar employees are more likely now to work remotely.

 Some have used this opportunity to move to smaller and cheaper cities while clocking in for firms based many miles away.

 But America's superstar cities still draw many of the country's most talented workers.

 And while remote and hybrid work have stabilized at a much higher level than before COVID, it is notable that in August 2023, the videoconferencing company Zoom itself announced that they were demanding employees be in the office at least a few days each week.

 Eric Yuan, Zoom's CEO, explained that it was simply too hard to build trust without nearness.

 He said, Trust is a foundation for everything.

 Without trust, we will be slow.

 Zoom was no outlier.

 Amazon and Meta and JPMorgan Chase and Alphabet and Tesla and Pfizer and almost every other major company one could name had, by mid-2023, announced a plan for employees to return to the office for at least a few days each week.

 Remote work is a powerful force, but the centripetal power of the city is stronger.

 To defeat the human need for face-to-face contact, Glazer writes, are technological marvels we need to defeat millions of years of human evolution that has made us into machines for learning from the people next to us.

 This resolves the paradox of the metropolis.

 We vanquish distance for shipping and sales, but innovation, innovation still thrives amid closeness, which is to say it thrives in cities.

 And because it thrives in cities, so does much else.

 It's in missing how much else that we made a terrible mistake.

 The Great Divergence Cities play two roles.

 They are engines of innovation and they are engines of mobility.

 High housing costs have blunted the role in innovation, but only modestly.

 The richest firms and most productive workers can still afford to locate in expensive zip codes.

 But high housing costs wreak havoc on the city's offering of opportunity.

 Think of it as a firefighter test.

 Could a firefighter serving a city afford to live in that city?

 If not, then not only is that firefighter going to be forced into a longer commute or an economically strained life, but his children, too, will be deprived of the awesome possibilities of the city their father works to safeguard.

 Most jobs aren't in firms like Google and Goldman Sachs.

 About two-thirds of the jobs in the American economy are in the local service sector.

 And that number has been steadily growing for 50 years.

 These are hairstylists and DMV employees and nurses and line cooks and retail workers and real estate agents.

 They don't see the kinds of wild productivity improvements that tradable goods do.

 Because while one software programmer can write code for a million users, one line cook cannot make food for a million mouths.

 But these jobs pay better in dynamic cities.

 Those Googlers, they have money to spend.

 And the consequences here ring out across generations.

 As economist Raj Chetty and his team have covered in several papers, upward mobility is in structural decline in the U.S.

 In 1940, a child born into an American household had a 92% chance of making more money than her parents.

 But a child born in the 1980s has just a 50% chance of surpassing their parents' income.

 In 40 years, the American dream went from being a widespread reality to a coin toss.

 Mobility, Chetty found, is a product of place.

 A child born poor in San Jose is three times the likelihood of ending up wealthy as a child born poor in Charlotte.

 Among children who moved from a more economically stagged zip code to a richer neighborhood, Chetty finds that the likelihood of better outcomes improves steadily with every extra year the child spends in their new city, with the kids who moved earliest faring best.

 Chetty's team also found that children who moved to a high innovation area when they were young are much likelier to patent inventions of their own when they matured.

 The effect was specific to the specialty of the place.

 He and his authors write, Children who grow up in a neighborhood or family with a high innovation rate in a specific technology class are more likely to patent in exactly the same class.

 But that depends on their parents being able to move to and live in high innovation areas.

 In the past, higher incomes would attract them.

 In the present, sky-high cost of living repels them.

 A 2017 study by Peter Ganong and Daniel Schoag reveals the scale of what's lost when housing prices gate cities to working-class migrants.

 From 1880 to 1980, the income gap between residents of different states closed steadily each year.

 Today, that convergence has dissolved almost entirely.

 Ganong and Schoag estimate that America's mid-century mobility accounted for more than a third of its mid-century drop in income inequality.

 Now it is gone.

 This is the quiet destruction of an ancient path to opportunity.

 Consider the fortunes of janitors and lawyers, Ganong and Schoag write.

 Janitors and lawyers have long made more money working in New York than in the Deep South.

 As a result, many migrated from the Deep South to New York.

 But as housing costs in New York rose, the benefits of migration crumbled, at least for the janitors.

 The lawyers still came out ahead, but the janitors saw housing consume more than 50% of their paychecks.

 It used to be that both high-wage and low-wage workers moved from poor areas to richer ones.

 By the 1990s, poor workers were moving away from high-income areas and away from the opportunities they once offered.

 It is, then, no surprise that income inequality began rising in the 70s and reached such striking peaks in recent decades.

 We took a process responsible for much of the march towards income convergence and threw it into reverse.

 We made mobility into an engine of inequality and we did it on purpose using policy levers that made life in dynamic cities too costly for the poor to afford.

 But the we here is hiding some uncomfortable culprits.

 It is liberals, and particularly a strain of liberalism that began to develop in the 60s and 70s, that bears much of the blame.

 The problem with lawn sign liberalism There's an old finding in political science that Americans are symbolically conservative but operationally liberal.

 That means Americans talk like conservatives, but they want to be governed like liberals.

 The Tea Party-era sign saying, keep your government hands off my Medicare, is perhaps the most famous example of this divided political soul.

 Americans like both the rhetoric and reality of low taxes, but they also like the programs the taxes fund.

 They thrill to politicians who talk of personal responsibility, but want a safety and a tight end if they, or those they know and love, fall.

 This dynamic is so well known, so easy to see, that we miss how often it gets reality exactly backwards.

 In many blue states, voters exhibit the same split political personality but in reverse.

 They are symbolically liberal but operationally conservative.

 In much of San Francisco, you can't walk 20 feet without seeing a multicolored sign declaring that Black Lives Matter, kindness is everything, and no human being is illegal.

 Those signs sit in yards zoned for single families, in communities that organize against efforts to add the new homes that would bring those values closer to reality.

 San Francisco's Black population has fallen in every census count since 1970.

 Poor families, disproportionately non-white and immigrant, are pushed into long commutes, overcrowded housing, and street homelessness.

 Texas has been the single largest beneficiary of California's housing crisis.

 And that is in part because Texas is California's mirror image on housing.

 The Austin metro area led the nation in housing permits in 2022, permitting 18 new homes for every 1,000 residents.

 Los Angeles's and San Francisco's metro areas permitted only 2.5 units per 1,000 residents.

 In our political typologies, it is liberals who embrace change and conservatives who cling to stasis.

 But that is not how things work when you compare red state and blue state housing policies.

 To be fair to California, change is messy and uncomfortable everywhere.

 Any growing community that likes itself roughly the way it is faces a problem.

 If more people want to live in that community, then developers will build places for them to live.

 Worse, they might build dense places for them to live.

 A plot of land that houses a large single-family house could become a plot of land housing a small building with six units.

 It can make more money typically selling homes to six families than selling to one family.

 So it's relatively easy for a developer to offer one family that is living there now a good price for their home, raise a building to the ground, stack six units on top of each other and make a profit.

 This can be done in many places at once fairly quickly and the community will soon wake to find that it is unrecognizable to itself.

 But how do you stop people from selling homes they own and developers from building on land they own and people from moving to a city they would like to be part of?

 Who invented this whole business of cutting cities into zones and creating rules about what can and can't be built there?

 The answer takes us back more than a hundred years.

 Go back to the 1800s and no American city had zoning rules.

 The economist William Fishel writes in his aptly titled book, Zoning Rules.

 In the early 1900s, Los Angeles adopted a small package of regulations that divided the city between zones for industrial buildings and zones for residential construction.

 New York City followed and soon enough so did almost everywhere else.

 Fishel writes, eight cities had zoning by the end of 1916.

 By 1926, 68 more cities had adopted it.

 And between 1926 and 1936, zoning was adopted by 1,246 additional municipalities.

 So the concept of zoning, unheard of in 1900, covered 70% of the U.S. population by 1933.

 Fishel's explanation for why begins with trucks and buses, which forever changed the spatial geometry of the city.

 Before these big, gas-powered vehicles took over the streets, it was easy to keep the different functions of the city separate.

 If you didn't want to live near a manufacturing plant or the masses of workers who worked in it, you could always live or build somewhere else.

 But trucks and buses changed that.

 Fishel writes, the truck liberated heavy industry from close proximity to downtown railroad stations and docks.

 Now, factories could be located anywhere.

 Buses liberated urban workers, too.

 They didn't have to live within walking distance of their jobs or on a streetcar line.

 They could reside anywhere and working-class apartments could be built anywhere.

 Homeowners could no longer rely on geography to protect them from the people and producers they wanted to avoid.

 If distance couldn't keep them safe, rules would have to do so instead.

 The first zoning rules did little to prevent housing construction at scale.

 Instead, they dictated what kind of buildings could go where.

 James Metzenbaum, an Ohio litigator, compared these early rules to good housekeeping in the 1930s.

 It keeps the kitchen stove out of the parlor, the bookcase out of the pantry, he said.

 Of course, the rules also often kept non-white Americans out of owning in rich parts of the city.

 But the American zoning experiment wasn't finished, not even close.

 It's what came next that really put the clamps on housing supply.

 Zoning as a form of anti-growth regulation.

 It is this form of zoning that still governs cities and suburbs today.

 Two communities in California trace a rise of the anti-growth movement.

 After World War II, millions of veterans returned from the European and Pacific theaters.

 They started families in a hurry.

 Birth rates spiked, and young parents balancing babies in their arms scoured the country for houses.

 No suburban development epitomized this go-go era more than Lakewood, California, a planned community built on open farmland just north of Long Beach.

 Between 1950 and 1953, more than 17,000 homes went up.

 At its most furious pace, the city's builders finished a new home once every seven and a half minutes.

 The houses sold almost as fast as they were built.

 On March 24, 1950, 30,000 people lined up to check out the inventory at Lakewood's grand opening.

 In July, the first resident, a Navy veteran named Jim Huffman, moved in with his family.

 Through the end of the year, 20 more families bought a Lakewood home on average every single day.

 By the spring of 1954, a sparse farmland for sugar beets and lima beans had been transformed into one of California's 20 largest cities.

 Two decades later, several hundred miles north of Lakewood, another city revealed how rapidly the politics of housing were changing.

 Petaluma is nestled in the windy hills north of San Francisco, where a gap in the coastal mountain range pulls cool, moist marine air into the farmland.

 Petaluma also saw its population bloom after the war.

 But unlike Lakewood, the city became famous for stopping growth rather than for welcoming it.

 In 1971, city officials introduced the Petaluma Plan.

 It included a growth rate cap of 500 annual new housing units and an urban growth boundary to prevent sprawl.

 Despite facing several legal challenges, the law was largely upheld in the courts.

 In the following decades, the Petaluma Plan offered a useful formula for Californians who wanted to freeze development in their neighborhoods, and other cities quickly adopted its quota system for building permits.

 Today, California is more Petaluma than Lakewood.

 In the 1950s and 1960s, California routinely built more than 200,000 homes each year.

 Since 2007, California has never once permitted more than 150,000 new homes in a year.

 In Cities of Amber, historian Jacob Anbender traces the rise of this anti-growth liberalism.

 He writes, In Los Angeles, fewer homes were built in the 70s and the 60s, fewer in the 80s than in the 70s, and fewer in the 90s and in the 80s, even as the city's overall population grew.

 And it wasn't just California.

 As Anbender points out, much of America has become more like Petaluma than like Lakewood.

 He writes, A slew of new zoning laws in Westchester County, New York, reduced the maximum permissible population of the county by 1.4 million people, largely by banning forms of home construction other than large-lot, single-family houses.

 Bergen County, New Jersey, made it illegal by 1970 to build apartments on all but 131 acres of land.

 A 1973 survey of city and county governments found that one in five had passed laws in the previous two years that limited new residential development by halting expansions of public sewer systems.

 New York City's first historic district was created in 1965.

 Three decades later, more than 15,000 buildings were protected from redevelopment by its Landmarks Law.

 By the 1990s, 71% of cities and 77% of counties in California practiced some form of growth control with hundreds of such measures enacted in the 80s alone.

 Fast forward to the present.

 In 2020, with home prices at record levels, the Petaluma Plan reached its logical endpoint.

 For the first time in the history of the state, California, which, as late as the 1960s, was growing twice as fast as the rest of the country, actually shrank.

 The state is dominated by Democrats, but many of the people Democrats claim to care about can't afford to live there.

 In the same progressive zip codes where homeowners press signs into the soil of their front lawns bearing the message kindness is everything, affordable housing cannot be found, and homelessness is endemic.

 This is your state on a housing shortage.

 In 2015, when the California Legislative Analyst's Office investigated the cause of the state's housing cost and availability crisis, the authors were unambiguous in their diagnosis.

 First and foremost, they wrote, far less housing has been built in California's coastal areas than people demand.

 That was almost a decade ago, but little has changed since the publication of that document.

 Since 2015, the state has authorized construction on about half as many housing units as Texas, despite now having nine million more residents.

 California is about 12% of the nation's population, 30% of the nation's homeless population, and about 50% of its unsheltered homeless population.

 To walk the streets of the Tenderloin in San Francisco or Skid Row in Los Angeles is to tumble into the dystopia tucked amid the plenty of these cities.

 Tents line the buildings, feces line the sidewalks, needles crunch underfoot.

 This is not what anyone trying to preserve the idyllic conditions of California's Central Coast wanted, but it is what they got.

 It is what they made.

 Homelessness has been particular grist for conservatives who see, in California's homelessness crisis, the roosting of liberal licentiousness.

 Heather McDonald of the Manhattan Institute writes, Failure to enforce basic standards of public behavior has made one of America's great cities increasingly unlivable.

 But McDonald is mistaken.

 San Francisco is eminently livable, which is why the average apartment sells for more than a million dollars.

 If San Francisco were unlivable and people ceased to want to live there, the price of homes would plummet, and so too would the ranks of the homeless.

 There have been no end of explanations offered for the severity of California's homelessness crisis.

 Perhaps it's nice weather which makes sleeping on the streets comfortable even in winter.

 But then, why is homelessness so much less prevalent in Houston, where the winters are even warmer?

 Maybe it's a generosity of California's social services.

 Perhaps it's a liberal drug and policing policies.

 Maybe it's something to do with mental health.

 Perhaps California is simply a magnet of social service compassion, attracting all the rest of the country's homeless.

 In their book, Homelessness is a Housing Problem, Greg Colburn and Clayton Page-Aldern test these and other explanations and find them worse than lacking.

 When we tell the stories of the homeless, we focus on the individual events that pockmarked a life path.

 The loss of the job, the workplace injury, the onset of schizophrenia, the first glow of an opioid high.

 What Colburn and Aldern wanted to understand is why homelessness varies so much across cities and regions.

 If a driver of homelessness doesn't predict these differences, then it is probably not a cause of mass homelessness.

 It might explain why an individual became homeless in a particular place, but it cannot explain why one place has a homelessness crisis and another does not.

 And so they begin ticking through the list of explanations and testing them against the data.

 An obvious place to begin is poverty rates.

 Does more poverty predict more homelessness?

 No.

 A number of cities with high rates of poverty, Detroit, Miami, Dallas, Cincinnati, Philadelphia, have low rates of homelessness.

 It is richer cities with low overall poverty rates that see more homelessness.

 And a similar story emerges for unemployment.

 Homelessness is low where unemployment is high, and it is high where unemployment is low.

 Odd.

 Then Colburn and Aldern move on to mental illness.

 It is hard to find reliable data on the rates of mental illness across cities, but the U.S. Department of Health and Human Services does collect data across states.

 Here, too, the obvious relationship eludes us.

 Homelessness is slightly less common in the states with the highest rates of mental illness, and vice versa.

 Hawaii, which has among the lowest rates of serious mental illness, has among the highest rates of homelessness.

 There is a slightly positive relationship between measured drug use and homelessness, but not much of one.

 More drug use explains only about 5% of the difference between places.

 So what does explain homelessness?

 The availability and the cost of housing.

 When Colburn and Aldern begin testing these variables, their charts, which had just been these masses of disconnected bubbles, coalesce into lockstep lines.

 As the cost of rent rises, so too does the number of homeless.

 As the vacancy rate plummets, meaning that the housing market is tight with too many buyers and too few sellers, homelessness rises.

 The way to think about homelessness, they write, is to imagine a game of musical chairs.

 With 10 chairs and 10 people, everyone will find a chair when the music stops.

 That will be true even if one of the players is on crutches.

 With 9 chairs, someone will inevitably be left out.

 And that's when individual life circumstances begin to predict homelessness.

 If you live in a city with too few homes, poverty and drug abuse and unemployment and mental illness make it likelier that you will be among those who end up without a home.

 But the cause of homelessness isn't the poverty or the addiction or the unemployment.

 All those conditions are far more prevalent in, say, West Virginia than in California.

 And yet, California is six times the per capita homelessness of West Virginia.

 This leads to a reality many prefer not to acknowledge.

 If homelessness is a housing problem, it is also a policy choice.

 Or, more accurately, it is a result of many, many, many small policy choices.

 The writer Matthew Iglesias, who has spent a decade trying to persuade liberals of where they've gone wrong in housing, illustrated this nicely in a 2021 essay.

 Iglesias quotes the urban planner Peyton Chung's description of the 1951 sci-fi classic The Day the Earth Stood Still, which features Klaatu, an alien, escaping captivity at what was then known as Walter Reed General Hospital and moving into a Washington, D.C.

 boarding house at 14th and Harvard Streets.

 Boarding houses were a common place for adults to live through much of American history.

 They worked something like today's college dorms.

 The rooms were small, the bathrooms and kitchenettes shared, and the cost was low.

 They weren't as nice to live in as a single-family home with a detached garage, but they were far nicer than a tent in the middle of an encampment in the dark of winter.

 So where did all the boarding houses go?

 The answer is that they were made, in most jurisdictions, functionally illegal.

 By the 1950s, rooming houses were already a target for city planners looking to maintain high home prices and orderly neighborhoods.

 The St. Louis Post-Dispatch in 1957 wrote, If rooming houses are permitted to spread to the city's one- and two-family neighborhoods, there is not much use in talking brave words about fighting blight.

 Rooming houses are not compatible with one- and two-family districts.

 When the rooming houses come in, the families move out, and the whole area starts downhill.

 A report from the American Society of Planning Officials that same year offered guidance to planners looking to creatively rid their cities or their neighborhoods of such nuisances.

 Zoning is not the only tool available to control the blighting effects of rooming houses, they wrote.

 Housing codes in an increasing number of cities require that decent, though often minimal, standards be maintained in them.

 Besides protecting the rumors, enforcement of these codes can do a great deal to assure that rooming houses do not harm districts in which they are properly located.

 Over time, planners did exactly that.

 Zoning and building codes required homes to be built with ever more features and amenities, minimum parking requirements were added, and maximum residency limits appeared.

 Some of this was done to upgrade housing stock or protect health and safety.

 Some of it was done to eliminate entire forms of housing that gave the poor or the unlucky a continued toehold in richer neighborhoods.

 Does it really protect the rumors to move them from a boarding home without parking spaces to a tent beneath the overpass?

 It took a while, Iglesias writes, but over the generations, the planners have been very successful at mostly eliminating the accommodations for down-and-outers, with the consequence that if you are down-and-out in a city where real estate is expensive, you end up on the street.

 The point is not that cities wanted the homelessness crises they now face.

 They didn't.

 Their hope was that people who couldn't afford the kind of housing they allowed would leave.

 And many did exactly that.

 But some had nowhere else to go.

 Others needed to stay near their families or jobs.

 And these policies did not generate crisis in a single year or even a single decade.

 It took time before choices to limit housing led to mass homelessness.

 But it is not surprising that choices to limit housing led to mass homelessness.

 And it is not even surprising that cities often choose to limit the forms of housing or the amount of housing that can be built nearby.

 After all, if you already own a home, scarcity makes the asset you own all the more valuable.

 What happened in the 1970s?

 There's an odd website called WTF Happened in 1971.

 It's a long stack of charts gathered magpie-like from all manner of books and papers and articles, recording the many ways society began to tilt on its axis as the 70s dawned.

 The most convincing of them are economic.

 Starting in the 70s, wages began to stagnate, inequality began to soar, inflation began to rise, and housing prices began their inexorable march upward.

 Our favorite among these charts shows how many years an average wage earner would presumably need to save to buy a home.

 In 1950, it's 2.3 years.

 In 1960, it's 2.6 years.

 In 1970, it's 2.4 years.

 And then something happens.

 By 1980, it's 3.8 years.

 By 1990, it's 5.4 years.

 By 2000, it's 7 years.

 And this forward march is hiding the regional differences.

 That home you could buy with 2.4 years of labor in 1970 was in a different kind of city than that home you could buy after even 7 years of work at median wages in 2000.

 Real wages stagnated over these decades, but they didn't fall.

 The action was in housing prices, which rose and rose and rose.

 And this was something new.

 Prior to 1970, housing wasn't a prime asset.

 You bought a home mainly to live in it.

 But that changed in the 1970s.

 Inflation was part of the reason.

 One of the main aims of federal housing policy has been to make possible the 30-year fixed-rate mortgage, a peculiar financial device it wouldn't survive a day in the economic wild.

 What lender in their right mind would hand out 30-year loans on fixed terms to virtually anybody with a job?

 But the federal government backed those mortgages and made the interest payments on them into large tax deductions, and they became the cornerstone of the American housing market.

 But they became something else, too, a hedge against inflation.

 A fixed-rate mortgage holds payments flat on an appreciating asset.

 While inflation eats away at the real value of those payments, the value of the thing the payments are going toward, the house, just goes up and up.

 From 1955 to 1970, owner-occupied housing held at about 21% of total household net wealth.

 Between 1970 and 1979, it climbed to 30% of net wealth.

 For those who owned a home, it was much more of their total wealth than that.

 But a home is a peculiar form of wealth.

 You typically need to live in it.

 Selling stocks or bonds liquidates an asset you don't use in your day-to-day life.

 Selling a home liquidates the place you sleep, the walls within which you may have raised your children or grow into adulthood yourself.

 Financial interest merges with sentimental attachment and daily need.

 But it gets worse, as Fischel explains.

 It is worth a moment to consider how financially problematic an owner-occupied home was at the beginning of the 20th century and remains to the present.

 An investment advisor, whom you have consulted, looks at your middle-income portfolio and tells you that you should put almost all of your liquid assets in a single investment.

 It is not a diversified mutual fund, it is a single firm.

 And the firm makes only one product in a single location.

 It has a great upside in that its returns are almost entirely untaxed under federal and state income tax laws.

 And it ensures you against rent increases by the landlord.

 But its asset value is subject to a multitude of risks.

 Not least are those from the neighborhood and the single municipality in which the firm is located.

 Bad events next door, down the street, at the school district, and in-city hall can put your life savings in a tailspin.

 In the 70s, rising inflation and slowing home building turned the homes people did own into the center of their wealth.

 But how do you protect the value of that asset?

 You can insure a home against fire, but you can't insure it against rising crime rates or local schools slipping in quality or a public housing complex being built down the block.

 To manage those risks, you need to control what happens around your home.

 And you do that through zoning and organizing.

 You do it through restricting how many homes and what kinds of homes can be built near you.

 You do it by making the minimum allowable lot sizes bigger and the parking requirements more expansive because both those rules ensure that only wealthier people will be able to buy into your community.

 You do it through organizing and planning meetings to defeat proposals for apartment buildings.

 They'll change the character of the neighborhood and think of the traffic.

 And you do it by refusing to expand sewer systems to areas where developers might want to build new homes.

 In her essay, the Homeownership Society was a mistake.

 Jerusalem Dempsis, who covers housing at the Atlantic, traces the politics of treating homes as assets.

 Housing is often spoken of as a safe investment, but it's not.

 Homes rise in price when there are too few of them to go around.

 The greater the gap between supply and demand, the higher the returns for homeowners.

 At the core of American housing policy is a secret hiding in plain sight, she writes.

 Home ownership works for some because it cannot work for all.

 If we want to make housing affordable for everyone, then it needs to be cheap and widely available.

 And if we want that housing to act as a wealth-building vehicle, home values have to increase significantly over time.

 How do we ensure that housing is both appreciating and value for homeowners, but cheap enough for all would-be homeowners to buy in?

 We can't.

 The logic of this is inescapable, and the politics it creates are predictable.

 A home's value is directly tied to the scarcity of housing for other people, Dempsis writes.

 This system, by its nature, pits incumbents against newcomers.

 The 70s were a period of ferment for this form of politics.

 The run-up in housing prices was part of it, but Fischl emphasizes a few other forces.

 The interstate highway system, coupled with the growth of car use, allowed people to live farther from their workplaces than was possible even a few decades before.

 Then came civil rights legislation that made it illegal to directly discriminate against homebuyers based on race.

 Communities it wanted to, in the sanitized language of real estate, preserve their character, needed to find other means by which to do it.

 And they did, through rules like setting a large minimum lot size for new construction.

 Lot size requirements forced developers to build fewer and more expensive homes, in turn guaranteeing that the homes would be sold to wealthier, whiter buyers, writes Anvander.

 He quotes a homeowner in Greenwich, Connecticut, giving up the game in 1967.

 It's like going into Tiffany and demanding a ring for $12.50, said the homeowner.

 Tiffany doesn't have rings for $12.50.

 Well, Greenwich is like Tiffany.

 If he's owned Greenwich so the only people who can afford homes that are multimillionaires, then only multimillionaires will live in Greenwich.

 Fischel's an economist, so he takes a materialist view of what was happening here.

 To him, the core of the story is home prices and the desire of homeowners to keep those prices rising and everything else was more or less a rationalization.

 Economic advantage is a powerful private motivator, but it plays poorly in public discourse, he writes.

 It is considered gauche, I have tried it, to mention in a public meeting that a particular public policy will raise or lower home values, even though what is acceptable to mention, traffic, crime, walkable streets, local pollution, pretty clearly maps onto home values.

 Something less obviously selfish is required to get other community residents to rally around the cause.

 But while there is plenty of selfishness in the housing politics of the 70s, something less obviously selfish was going on too, something noble, even necessary.

 The story of rising housing prices in America isn't a simple morality play of greedy homeowners and feckless city planners.

 This is a story, at least in part, of how the solutions of one era created the problems of the next.

 America the Ugly In May 1964, Lyndon B. Johnson stepped onto the podium at the University of Michigan to deliver that year's commencement address.

 The president began with a capsule history of the country he now led.

 For a century, we labored to settle and to subdue a continent, he said.

 For half a century, we called upon unbounded invention and untiring industry to create an order of plenty for all of our people.

 But the age of untrammeled growth, that whirlwind economic expansion that the New Dealers had set into motion was revealing its limits.

 What was the cost of all this plenty?

 Johnson continued, The catalog of ills is long.

 There is the decay of the centers and the despoiling of the suburbs.

 There is not enough housing for our people or transportation for our traffic.

 Open land is vanishing and old landmarks are violated.

 Worst of all, expansion is eroding the precious and time-honored values of community with neighbors and communion with nature.

 We've always prided ourselves on being not only America the strong and America the free, but America the beautiful.

 Today, that beauty is in danger.

 The water we drink, the food we eat, the very air that we breathe are threatened with pollution.

 Our parks are overcrowded, our seashores overburdened, green fields and dense forests are disappearing.

 A few years ago, we were greatly concerned about the ugly American.

 Today, we must act to prevent an ugly America.

 This was a change.

 The problem the New Deal faced was straightforward.

 People had too little and they needed much more.

 But by the time Johnson took office, the difficulties of deprivation had been joined by diseases of affluence.

 In his 1958 bestseller, The Affluent Society, John Kenneth Galbraith described in America cosseted by new comforts, yet unable to shake a sense that something had gone fundamentally awry.

 He writes, The family which takes its mauve and cerise air-conditioned, power-steered, and power-braked automobile out for a tour passes through cities that are badly paved, made hideous by litter, blighted buildings, billboards, and posts for wires that should long since have been put underground.

 They picnic on exquisitely packaged food from a portable icebox by a polluted stream and go on to spend the night at a park which is a menace to public health and morals.

 Just before dozing off on an air mattress beneath a nylon tent amid the stench of decaying refuse, they may reflect vaguely on the curious unevenness of their blessings.

 Is this, indeed, the American genius?

 Modern American liberalism may have been born in the New Deal, but it was reborn in its aftermath.

 It matured into a political movement with a divided soul.

 Much of mid-century liberalism evolved in reaction to the excesses and consequences of New Deal liberalism.

 Anbender puts this well.

 One of the most consequential conflicts in post-war America was between two systems of values, he writes.

 An older growth politics which extolled the benefits of metropolitan development and a newer anti-growth politics which rejected the idea that such development improved society.

 It is hard now to imagine how quickly the built environment of America changed in these years.

 In 1900, there were scarcely 8,000 cars in the entire country.

 By 1970, 118 million cars sluiced through a nearly complete interstate highway system.

 In 1900, no one had ever flown in an airplane.

 By 1970, millions of passengers boarded wide-bodied jetliners like the Boeing 747 to travel across the oceans to thousands of airports around the world.

 To a previous generation, this technology would have been indistinguishable from sorcery.

 But as every reader of fantasy novels knows, great magic carries a terrible price.

 In 1943, Los Angeles residents woke up to air so dark and noxious that they feared the Japanese had launched a gas attack.

 Five years later, a lethal smog in Donora, Pennsylvania, caused by industrial pollutants from zinc-smelting plants and a temperature inversion that trapped toxins in the air, killed 20 people and sickened thousands.

 In New Hampshire, the Merrimack River, lined with textile mills in Manchester and Nashua, ran in different colors by the day as dyes and chemicals dumped into the river tinged the water red, then green, then yellow.

 In Cleveland, Ohio, on June 22, 1969, oily waste and debris were ignited, possibly by a flare thrown into the Cuyahoga River, sparking a fire as tall as a four-story building.

 In Pittsburgh, mid-century drivers had to use their windshield wipers to clear away the soot so they could see the road.

 America, in the 1950s and 60s, was paradoxically the richest superpower in world history and functioned as a kind of mass industrial conspiracy to kill and sicken its own residents.

 The toxicity of growth triggered a reaction among intellectuals and, later, within government.

 In 1962, Rachel Carson, a marine biologist suffering from breast cancer, published Silent Spring, which argued that chemical pesticides were devastating our ecosystems and destabilizing the biosphere.

 The book is broadly credited with founding the environmental movement.

 Like any founding document, it hit a nerve because it concretized anxieties that already existed.

 Environmentalism soon permeated the broader culture.

 In the late 1960s, Gaylord Nelson, the senator from Wisconsin, who had been closely watching the student-led protests around the Vietnam War, was inspired to channel that energy and enthusiasm to protest on behalf of the environment.

 He hired a young activist named Dennis Hayes who came up with the idea of a walkout on the first day of spring, which they would call Earth Day.

 On April 22, 1970, more than 20 million people, roughly 10% of the U.S. population, poured into the streets.

 It was the largest single demonstration in American history.

 Between 1966 and 1973, the U.S. passed almost a dozen laws that required the government to be more responsive to local citizens and the environment.

 They were the National Historic Preservation Act, the Department of Transportation Act, the Federal Aid Highway Act of 1968, the National Environmental Policy Act, the Clean Air Act of 1970, the Uniform Relocation Assistance and Real Property Acquisition Policies Act, the Noise Control Act of 1972, the Clean Water Act, the Federal Aid Highway Act of 1973, and the Endangered Species Act.

 In seven years, America compiled an arsenal of regulation to slow or outright stop the era of big government building.

 These were not partisan fights.

 to read President Richard Nixon's State of the Union Address from 1970 is to tumble into a politics very different than our own where Republicans talked in ways that even few Democrats dare speak today.

 He said, The great question of the 70s is, Shall we surrender to our surroundings or shall we make our peace with nature and begin to make reparations for the damage we have done to our air, to our land, and to our water?

 Restoring nature to its natural state is a cause beyond party and beyond factions.

 It has become a common cause of all the people of this country.

 It is a cause of particular concern to younger Americans because they, more than we, will reap the grim consequences of our failure to act on programs which are needed now if we were to prevent disaster later.

 Clean air, clean water, open spaces, these should once again be the birthright of every American.

 If we act now, they can be.

 We still think of air as free, but clean air is not free, and neither is clean water.

 The price tag on pollution control is high.

 Through our years of past carelessness, we incurred a debt to nature.

 And now, that debt is being called.

 Nixon went on to promise that the program I shall propose to Congress will be the most comprehensive and costly program in this field in America's history.

 He went on to sign the National Environmental Policy Act, the Clean Air Act, and the Endangered Species Act, and he created the Environmental Protection Agency, making him arguably the most important environmentalist president of the 20th century.

 But Nixon was not aberrant as a Republican taking the environmental worries of the moment seriously.

 In 1984, President Ronald Reagan told the nation, I might be letting you in on a little secret, as a matter of fact, one of the best-kept secrets in Washington.

 He went on to describe California's leadership role in passing environmental legislation.

 He talked about how the nation had followed California's lead, and then he delivered the punchline.

 The secret I mentioned is that I happened to have been governor of California back when much of this was being done, Reagan said.

 In Cities of Amber, Ann Bender tells the story in more detail.

 Reagan signed the California Environmental Quality Act, CEQA as it's called, into law in 1970, but he did not know what he was signing, and the legislature did not know what it was passing.

 The bill was thought to be modest.

 Despite the environmental consciousness rising in the state and in the media at the moment, the Los Angeles Times didn't devote a single full article to the legislation.

 Then, in 1972, came a case called Friends of Mammoth versus Board of Supervisors of Mono County.

 A developer proposed to build six buildings worth of condominiums and shops and restaurants near Mammoth Lakes, one of California's beloved ski resort areas.

 Friends of Mammoth, a homeowner's association, sued to stop the build, arguing that it would strain water and sewage resources.

 The novelty of their argument was that they sued under CEQA.

 The legislation, as it was passed, held that government entities in California needed to produce environmental impact reports before embarking on major new projects.

 But the developer of the proposed Mammoth Lakes condos was not an arm of the California state, and this was not a public project.

 The argument of the Mammoth homeowners held that, yeah, actually it was, because any development that required public permits to be built was inherently a public project.

 Friends of Mammoth lost the case in the lower courts, but appealed up to the state Supreme Court, which ruled in their favor in a six-to-one decision.

 CEQA, the court held, applies not only to situations in which the government itself engages in construction, acquisition, or other development, but also in those instances in which the state regulates private activity.

 That meant it applied to, well, almost anything that anyone might try to build in the state of California.

 As a lobbyist for the Sierra Club put it, CEQA now covered anybody engaged commercially in putting two sticks of wood together.

 The Sacramento Bee called the decision probably the most important such ruling by any court in the field of environmental concern since the daisy pickers came out of the woods and plunged into the tangle of government influence.

 San Francisco froze all new plumbing, building, and electrical permits until it could fully understand the scope of the ruling.

 As Ambitur dryly notes, having been informed of what the law they had passed two years earlier actually said, the legislature moved quickly to impose a four-month moratorium on CEQA's implementation so that worksites across the state would not come to a complete standstill.

 A couple of years later, government agencies in California were reviewing more than 4,000 environmental impact statements annually, four times more than the entire federal government was generating under the facially similar National Environmental Policy Act.

 CEQA became a potent weapon against construction of new homes.

 Between 1972 and 1975, 29,000 proposed homes in the Bay Area, roughly a fifth of the region's total housing production at the time, were subject to environmental litigation, Ambitur writes.

 The Plague of Growth We think now of the interstate highway system as one of the grand achievements of the post-war era.

 The reaction at the time, particularly among liberals, was more mixed.

 The most charitable thing to assume about the highway bill is that they hadn't the faintest notion of what they were doing, the critic and historian Lewis Mumford wrote in 1958.

 Within the next 15 years, they will doubtless find out, but by that time, it will be too late to correct all the damage to our cities and our countryside.

 Robert Caro published The Power Broker, the study of how Robert Moses carved up New York in 1974.

 Much of what Moses was building was highways, and he was not alone.

 Moses might have been distinctive in his power, but planners were slicing highways through communities all across the nation.

 Cities fought back, culminating in the so-called highway revolts, in which residents organized to block the roads being cut into their neighborhoods, and in doing, they built connections and coalitions and tactics for opposing all manner of development.

 California was ground zero for both the possibilities and the predations of growth.

 In the 1950s, the five fastest-growing municipalities were all in California.

 New suburbs sprung like poppies across the state.

 Before Californication was a red-hot chili pepper song or a TV series starring David Duchovny.

 It was shorthand, Ann Bender writes, for the moral bankruptcy that many believed was inextricable from the physical form of sprawl itself.

 In 1972, Time magazine reported on conversations happening in other western states where legislators, scientists, and citizens are now openly concerned about the threat of Californication.

 This was growth unleavened by concern for beauty or community or conservation.

 The term ticky-tacky comes from a song recorded by Malvina Reynolds and then later covered by Pete Seeger describing the soulless, same-same tract housing covering the hills of Daly City just south of San Francisco.

 Anti-growth politics could, and often did, tip into a kind of misanthropy aimed at newcomers.

 Those who already lived in a place were its stewards, its guardians, its voice.

 Those who wanted to move to that place were recast as a consumptive horde.

 Harold Gilliam, who wrote the This Land column for the San Francisco Chronicle, put it grimly, Ultimately, every conservation problem is a population problem.

 Every effort to save some vestige of California's pristine splendor, every campaign to preserve the bay or the hills or a natural coastline or a grove of redwoods, every attempt to curb galloping slurbinism or to save breathing space for the future would be defeated by the unending advance of new hordes of population like a swarm of locusts devouring everything in sight.

 But what could you do about it?

 Chapter 2 Build No less in housing, climate change makes a hash of our traditional political categories.

 Here, it is typically the right that is willing to leap into the unknown, confident that humanity can adapt to unimaginable change.

 Here, it is largely the left that wants to conserve the climate that the entirety of human civilization has known.

 But to conserve our climate requires more than mere inaction.

 To do nothing, to let greenhouse gas emissions accelerate as they would if we kept burning coal and oil and gas heedlessly, is to welcome warming of 4 or 5 or 6 degrees Celsius.

 These are numbers that diverge from the climate of the 18th century as sharply as the climate of the 18th century diverges from the Ice Age.

 These are numbers inside which the planetary systems we rely on could simply break.

 To maintain the climate we've had or anything close to it requires us to remake the world we've built.

 One vision that is popular in some corners of the left is called degrowth.

 It holds that climate change reflects humanity's thrall to an impossible dream of endless growth.

 Rich countries must accept stasis, shuttering or scaling down major industries, and poor countries must grow more gently and prudently.

 Degrowth is simultaneously much more and much less than an answer to the climate crisis.

 It is much more than an answer because it is not really about climate at all.

 It is an anti-materialist philosophy that holds that humanity made its fundamental errors hundreds of years ago, trading the animism of our ancestors for Christianity's promise of dominion over nature.

 The problem is not simply greenhouse gas emissions or microplastics.

 It is Cartesian dualism and American-style capitalism and everything these systems of thought and practice have taught us to value and prize and want.

 Those who sought to pave the way for capitalism in the 16th century first had to destroy other, more holistic ways of seeing the world and either convince or force people to become dualists.

 That's Jason Hickel writing in Less is More, How to Growth Will Save the World.

 He continues, Dualist philosophy was leveraged to cheapen life for the sake of growth and it is responsible at a deep level for our ecological crisis.

 Hickel compares the scale of the philosophical and economic revolution DeGroeth imagines to Darwin persuading the world of evolution or Copernicus spreading the knowledge that the earth revolves around the sun.

 He envisions a wholesale shift in humanity's relationship to other living things and to itself.

 But shifts of that size take decades or centuries to play out.

 In the case of evolution, the victory is yet only partial.

 We do not have decades or centuries to convince the world to act on climate change.

 To the extent that DeGroeth has a specific climate plan, it is to shut off or scale down areas of production it deems destructive like military investment, meat and dairy production, advertising, and fast fashion.

 There is some appeal to this.

 All of us can identify some aspect of the global production system that seems wasteful, unnecessary, or harmful.

 The problem is that few of us identify the same aspects of the global production system.

 Take meat and dairy production.

 When we think of humanity's land footprint, we mostly think of buildings and roadways.

 But only 2 or 3% of habitable land is taken up by cities.

 We do not primarily use land to live on.

 We primarily use land to feed ourselves.

 About half of all habitable land is used for agriculture.

 Of that, three quarters is given over to raising livestock or growing feed for livestock.

 It is difficult to find an environmental challenge that is not tied up in raising animals for human consumption.

 It's a driver of climate change.

 It's a driver of deforestation.

 It's a driver of mass extinction as the land we turn over to cows and sheep and goats is the land that other species need to survive.

 It is a driver of drought and water scarcity as it takes about 1,800 gallons of water to produce a single pound of boneless beef.

 To the vegetarians and vegans among us, this is an obvious target for elimination.

 Humans thrive on a vegetarian diet and the factory farms that produce most of our meat are abattoirs of unimaginable cruelty and suffering.

 Industrial animal agriculture is more than a climate problem.

 It is a moral stain upon modernity.

 There is probably no single change that would do more for our interlinked environmental problems than for the world to cease using cows and goats and sheep for food.

 But to suggest such a thing is to court political ruin.

 People want to eat meat and they want that meat to be cheap and plentiful.

 The right accuses the left of scheming to ban hamburgers for a reason.

 The left denies those accusations and leaves direct confrontation with the meat industry out of its legislation for the same reason.

 There is no near-term politics that will ban meat consumption or redistribute it from richer countries to poorer countries.

 For all the radicalism of his book, even Hickel flinches from the task he sets for himself.

 He does not suggest anything akin to ridding the world of the factory farms that produce most of our beef.

 Instead, he proposes to end the subsidies high-income countries give to beef farmers and notes that researchers are also testing proposals for attacks on red meat.

 Fine proposals, but not the revolutionary upheaval that will cut our emissions rapidly enough to limit global temperature rise to 1.5 degrees Celsius.

 And that is even assuming you could pass a global or multinational tax on meat, which you could not.

 DeGroeth criticizes other approaches as unrealistic, noting the ease with which countries slip from their climate commitments or the ways that clean energy may allow other human cruelties to persist.

 In a telling passage, Hickel imagines what would happen if we perfected and deployed nuclear fusion tomorrow, bringing to life the clean energy economy of green dreams.

 What would we do with it, he asks, exactly what we are doing with fossil fuels.

 Raise more forests, trawl more fish, mine more mountains, build more roads, expand industrial farming, and send more waste to landfill.

 In this sense, DeGroeth recognizes the difficulty that politics poses to climate policy.

 It knows people want more of what they have, and although it blames capitalism and plutocracy for these wants, it sees the challenges these wants pose to traditional climate politics.

 But those challenges apply to the DeGroeth vision with even greater force.

 If you cannot imagine convincing people to change their desires in the presence of energy abundance, how do you imagine convincing them to accept the rapid, collective scarcity that DeGroeth demands?

 We know what it looks like when governments face a political fury of rising energy prices or fuel rationing.

 In 2022, 90 countries and territories experienced often violent protests over the rising price of fuel between January and September, according to a BBC analysis.

 In Sri Lanka, a country that Hickel holds out as a model for DeGroeth development, those protests led to the collapse of the ruling government.

 It is not much easier in rich countries where DeGroethers insist on the most radical restrictions in energy use.

 In France, the 2018 Yellow Vest protests followed a modest hike in the fuel tax.

 In America, rising energy costs resulting from sanctions against Russia forced the Biden administration to open up domestic fossil fuel production and beg Saudi Arabia for more oil.

 Germany's government tried to ban fossil fuel heating systems in favor of greener heat pumps.

 The outcry nearly split the ruling coalition and the compromised cut-up bill that ultimately passed was a shadow of the initial proposal.

 In 2023, a wave of electoral defeats for the UK's Conservative Party were blamed on high energy costs, leading Prime Minister Rishi Sunak to delay a suite of climate policies.

 In the 2024 election in America, Vice President Kamala Harris emphasized the record levels of oil and gas production achieved under the Biden administration far more than she talked about the historic climate investments she had helped pass into law.

 When Eric Voden, a political scientist, picked through the political consequences of recent climate policies, he found that people who bear the cost of climate policies increasingly flock to the far right.

 The only policy that seemed to blunt the backlash was directly compensating the people who suffer under green policies.

 But you can't both compensate residents of rich countries for lost growth and cut that growth in those same countries.

 Turning global politics into a zero-sum contest for allotted energy rations will not deliver a greener future.

 The cost of trying and failing to implement the degrowth vision would not merely be missing our climate targets by a few tenths of a percentage point.

 It would be to deliver a future of populist authoritarians who drill and burn their way back to a false prosperity.

 It is to discredit parties that care about climate change and empower strongmen who will give people what they have always wanted, the gift of abundant energy.

 We just burned it.

 Take any variable of human well-being, longevity, nutrition, income, mortality, overall population, and draw a graph of its value over time.

 Charles Mann writes in The Wizard and the Prophet, In almost every case, it skitters along at a low level for thousands of years, then rises abruptly in the 18th and 19th centuries as humans learn to wield the trapped solar power in coal, oil, and natural gas.

 Without energy, even material splendor has sharp limits.

 Mann notes that the visitors to the Palace of Versailles in February 1695 marveled at the furs worn to dinners with the king and the ice that collected on the glassware.

 It was frigid in Versailles and no treasury could warm it.

 A hundred years later, Thomas Jefferson had a vast wine collection and library in Monticello and the forced labor of more than a hundred slaves, but his ink still froze to the tip of his pen during winter.

 Today, heating is a solved problem for many, but not for all.

 There are few inequalities more fundamental than energy inequality.

 The late demographer Hans Rosling had a vivid way of framing this.

 In 2010, he argued that you could group humanity by the energy people had access to.

 At the time, roughly two billion people had little or no access to electricity.

 They still cooked food and heated water by fire.

 About three billion had access to enough electricity to power electric lights.

 An additional billion or so had the energy and wealth for labor-saving appliances like washing machines.

 It's only the richest billion who could afford to fly, and we used around half of global energy.

 Energy is the nucleus of wealth.

 Can we all be energetically wealthy?

 Not for burning coal and oil.

 The stocks of fossil fuel are finite and their continued combustion is lethal.

 This would be true even if climate change was a hoax.

 Air pollution kills between 7 million and 9 million people each year.

 That is six or seven times the death toll from traffic accidents and hundreds of times the death toll from war or terrorism or all natural disasters combined.

 It is deadliest where people cook by burning wood or charcoal and farm by burning the end of last season's crops.

 That is to say, it is deadliest where people are energy poor because where people are energy poor, they burn fuel and breathe in the byproducts.

 For most of human history, there was no other choice.

 That is why nearly every society that has become rich since the Industrial Revolution has seen air pollution build to crisis levels.

 Human beings choked on smog in London in the 19th century and in New York and Los Angeles in the 20th century.

 A few years ago, Beijing's air quality was an international scandal and now the same is true for Delhi.

 But notice, the problem passes.

 Los Angeles got richer and its residents now breathe clean air.

 The same is true in London where air pollution in the 18th century was worse than Delhi is today.

 Environmental action is often framed as at odds with the economy.

 writes Hannah Ritchie in Not the End of the World.

 It's either climate action or economic growth.

 Pollution versus the market.

 This is just wrong.

 As societies become economically and technologically rich, they clean their air and water.

 Air pollution is not a problem of using too much energy or pursuing too much growth.

 It is a problem of using dirty energy because you do not have the money or the know-how to grow another way.

 The same is true for climate change.

 We do not always know how to power economies without using fossil fuels.

 We do now.

 This is the technological miracle of our age.

 The cost of solar energy fell by about 90% from 2010 to 2020.

 The cost of wind power fell by nearly 70%.

 Solar power does not choke the lungs.

 Wind power does not sting the eyes.

 Neither of them warms the planet.

 Two decades ago, it was not possible to imagine that modernity was compatible with renewable energy.

 Now we do not imagine it.

 The world installed more solar power in 2023 than it did between 1954 and 2017.

 We've seen repeated periods now in California and Texas of negative energy prices.

 Moments where consumers are, mind-bendingly, paid to consume electricity because there is more of it than the system needs.

 The cost of solar is falling so fast that for much of the day, it will be effectively free in much of the world by 2030.

 I simply cannot believe where we are with solar, Jenny Chase, the Bloomberg NEF analyst, told the New York Times.

 And if you'd told me nearly 20 years ago what would be the case now, 20 years later, I would have just said you were crazy.

 I would have laughed in your face.

 There is genuinely a revolution happening.

 In a thrilling paper with the very unthrilling title, Empirically Grounded Technology Forecasts and the Energy Transition, a team of researchers found that the price of oil, gas, and coal after adjusting for inflation is about what it was 140 years ago.

 But renewable energy keeps crushing expectations.

 The authors looked at 2,905 projections for solar costs made by the most popular forecasting models and found that solar costs were expected to fall by 2.6% a year and never by more than 6%.

 In reality, they fell by 15% per year, year after year.

 In 2022, the U.S.

 Energy Information Administration released a report estimating life cycle costs for new energy installations in the coming decades.

 Solar was already cheaper than natural gas.

 Wind was a dollar more.

 Both were about half the price of coal.

 As a climate writer and activist Bill McKibben put it, in the place of those fires we keep lit day and night.

 It is possible for us to rely on the fact that there was a fire in the sky, a great ball of burning gas about 93 million miles away, whose energy can be collected in photovoltaic panels and which differentially heats the earth, driving winds whose energy can now be harnessed with great efficiency by turbines.

 The electricity they produce can warm and cool our homes, cook our food, and power our cars and bikes and buses.

 The sun burns, so we don't need to.

 To this miracle, one might add humanity's harnessing of nuclear power or a growing ability to tap the geothermal energy pulsing beneath the earth or the hydropower generated by the waves.

 So much clean energy is possible and available if we can muster the ingenuity and the will to harness it.

 And so there was nothing inevitable about the pace of greenhouse gas emissions.

 To see this clearly does not require imagining any new energy technology.

 It simply requires looking at the way different countries power themselves now.

 America emits about 15 tons of carbon per person per year.

 Canada and Australia belch out almost the same.

 In Germany and Japan, it's 8 tons.

 In France and the United Kingdom, it's less than 5 tons.

 These are vast differences across fairly similar lifestyles.

 A wanderer in London or Paris or Tokyo or Berlin would not notice material deprivation compared to Toronto or Sydney or Houston.

 What is true across space is also true across time.

 In 1979, Americans pumped out 22.7 tons of CO2 per person.

 Among Canadians, it was 18.2 tons.

 For Germans, 14.3 tons.

 Australians, 13.2.

 The UK, 11.5.

 France, 10 tons per person.

 All these countries are richer today than they were then, and yet they emit less carbon per person than they did then.

 Nor is it the case that their emissions have simply been offshore to the developing countries that manufacture many of the goods that richer countries buy.

 Researchers use trading data to track the movement of manufacturing emissions.

 Adjusting for offshore manufacturing blunts the cuts to emissions somewhat.

 In the United States, a 21% drop becomes a 14% drop, while in Germany, there's almost no difference.

 But it doesn't come close to erasing it.

 What is changing in all these countries is the source of power.

 In 1900, nearly all of the UK's energy came from coal, and by 1950, it was still supplying over 90%, writes Ritchie.

 Now, coal supplies less than 2% of our electricity, and the government has pledged to phase it out completely by 2025.

 Indeed, the last coal-fired power station operating in the UK shuttered in September of 2024.

 It is possible to power a modern economy with clean energy.

 It is possible to develop an economy with clean energy.

 And it will be possible to go beyond where any economy is today with clean energy.

 While we were writing this book, researchers at the Lawrence Livermore National Laboratory generated more energy than they used in a test of laser-ignited nuclear fusion.

 We know nuclear fusion can work.

 It is how stars generate power.

 We have never known if we can make it work here on Earth, at least not affordably and at scale.

 But we are getting closer.

 It is tempting to assume we in the United States sit at the terminus of what energy can achieve and all that is left is for the rest of the world to catch up.

 We do not.

 We are early in the story of humanity's relationship with energy.

 Today's technologies will come to seem comical, even barbaric.

 In 100 or 200 years, everything will look radically different, says Melissa Lott, the former director of research at Columbia University's Center on Global Energy Policy.

 Folks will look back and be blown away by how we used energy today.

 They'll say, wait, you just burned it?

 Too many see clearly the cost that dirty energy can impose on the environment, but do not dare imagine the possibilities clean and abundant energy unlocks for it.

 In a paper imagining energy superabundance, which they define modestly as simply every human being having access to the energy that the residents of Iceland enjoy, Austin Vernon and Eli Dorado sketch out some of the near-term possibilities.

 Vertical greenhouses could feed far more people while using far less land.

 Desalination is a major contributor to water supplies in Israel now and could supply more than half of the demand in Singapore by the middle of the century.

 That technology could become affordable for poorer, populous nations that need new water sources the most.

 Directly removing carbon dioxide from the air would become more plausible, giving us a path to reversing climate change over time.

 But the first step to building the clean economy of tomorrow is building the clean economy of today.

 and that is a daunting task.

 Electrify everything.

 Start with the major ways that most U.S. households warm the planet.

 We drive.

 We heat homes.

 We cook food.

 We dry clothes.

 These activities require millions and millions of machines, most of which now run on fossil fuels.

 To decarbonize, they all will need to run on electricity.

 The energy analysts Sam Kalish and Saul Griffith estimate that in the next few years, consumers will need to replace about 1 billion machines with clean alternatives.

 That means when old cars give out, they are replaced by electric vehicles.

 It means when old furnaces cough their last breath, they are replaced by heat pumps.

 It means trading gas stoves for induction stoves and clothes dryers that run on natural gas for dryers that work off of heat pumps.

 Producing all these new machines is itself a steep manufacturing challenge.

 It's also a persuasion challenge.

 People need to want these alternatives.

 That means the alternatives need to be excellent, which in many cases they now are.

 Electric cars accelerate faster and run quieter than cars powered by combustion engines.

 Induction stoves boil water in a fraction of the time it takes those little licks of fire.

 Because these advantages are not universally known and because new technologies are more expensive than mature ones, subsidies need to be generous and advertising needs to be everywhere.

 Making these replacement decisions needs to be a no-brainer every time.

 But assume that challenge can be met fully or at least partially.

 Now we have a billion more machines using more electricity than ever before.

 Where is all that electricity coming from?

 About 60% of the electricity generated in the United States in 2022 came from fossil fuels.

 The precise mix varies by state.

 South Dakota gets 84% of its power from renewables, mainly wind, and Washington gets 74% from renewables thanks to hydropower.

 But Nevada gets 56% of its electricity from natural gas.

 Wyoming gets 71% from coal.

 Florida gets only around 6% of its electricity from solar.

 So much for the sunshine state.

 The first task is to convert that 60% of energy coming from fossil fuels to something closer to 0%, or at least 0% coming from energy that releases carbon emissions into the atmosphere, which could leave a role for natural gas with carbon capture.

 That would be task enough, but with 1 billion new machines plugging into the country's grid, we don't just need the electricity we generate now to be clean.

 We need much more of it.

 One way to put that is for every 15 years from 2020 to 2050, we need to build the entirety of our electricity grid worth of supply again, says Jesse Jenkins, an energy expert at Princeton University.

 And we need to build it out of solar panels and wind turbines and storage batteries.

 Jenkins' team has modeled that build out in detail.

 A plausible path to decarbonization sees wind and solar installations spanning up to 590,000 square kilometers.

 That is roughly equal to the landmass of Connecticut, Illinois, Indiana, Kentucky, Massachusetts, Ohio, Rhode Island, and Tennessee.

 And we need to do it fast.

 In their 2023 paper, The Green's Dilemma, J.B. Rule and James Salzman, professors of environmental law at Vanderbilt and UCLA, respectively, put this vividly.

 Consider that the largest solar facility currently online in the United States is capable of generating 580 megawatts, they write.

 To meet even a middle-road renewable energy scenario would require bringing online two new 400 megawatt solar power facilities, each taking up at least 2,000 acres every week for the next 30 years.

 Installing that much wind and solar capacity isn't just a manufacturing challenge, it's a political challenge.

 Wind and solar require far more land than coal or natural gas to produce the same amount of energy.

 Some of the viable land is open and easy to purchase, much of it isn't.

 Neighbors have fears about a wind farm rising near their homes, and communities have concerns about becoming the site of a major solar array.

 If the land is publicly owned, the project has to negotiate with an overlapping set of federal and state authorities.

 It can take years to merely get the plans and permits approved.

 Once we've generated this electricity, we'll have to move it.

 This will sometimes require sending power across states, even across the country.

 The wind blows harder in Oklahoma than in Oregon, and the sun shines brighter in Arizona than in Maine.

 But a fully electric economy will require these far-flung states to be connected by an integrated energy grid.

 The name for the infrastructure that moves electricity from one place to another is transmission lines.

 And we've never completed more than 4,100 miles of transmission lines in one year, ever.

 We'd have to build more than that, year after year, to hit these goals.

 Transmission projects often come in late and over budget, and many planned projects stall.

 A 2016 report by Lawrence Berkeley National Laboratory looked at five major transmission projects with projected completion dates of 2021.

 Only one of them has been completed.

 Construction has not even begun on the other four.

 For decades, American liberalism has measured its successes in how near it could come to the social welfare system of Denmark.

 Liberals fought for expansions of health insurance and paid vacation leave and paid sick days, and a heftier earned income tax credit and an expanded child tax credit and decent retirement benefits.

 Worthy causes all.

 But those victories could be won when they were won, largely inside the tax code and the regulatory state.

 Building a social insurance program does occasionally require new buildings, but it rarely requires all that many of them.

 This was and is a liberalism that changed the world through the writing of new rules and the moving about of money.

 The climate crisis demands something different.

 It demands a liberalism that builds.

 The Infrastructure and Investment Jobs Act, the Inflation Reduction Act, and the Chips and Science Act add up to about $450 billion in clean energy investments, subsidies, and loan guarantees.

 This is how the scale of such bills is normally described in Washington by a price tag.

 The more money, the bigger the bill.

 It's an incomplete measure at best.

 If we could build faster, the numbers could rise.

 If we could build cheaper, the money would go further.

 That $450 billion, it's only an estimate.

 Many of the subsidies in these bills are open-ended.

 They will go to as many projects as can use them.

 These bills could spend trillions of dollars if we could build that infrastructure fast enough.

 They could spend far less than $450 billion if projects become too hard to permit or to construct.

 They could waste tens or hundreds of billions of dollars on projects that are never completed.

 What matters is not how much money gets spent.

 What matters is what gets built.

 California's no-speed rail rail system is not a high-speed rail system across California.

 Californians liked what they saw.

 In 1996, California formed a high-speed rail authority to plan for the construction of what would be America's fastest rail system.

 Planners imagined a silver shell whistling along beams of steel, carrying millions of parents, children, Silicon Valley entrepreneurs, Hollywood actors, and solo travelers through America's largest state at speeds reaching 220 miles per hour.

 Goodbye traffic and pollution choked freeways, hello classy dining cars and reclinable seats.

 High-speed rail is not some futuristic technology like cold fusion or flying cars.

 France and Japan broke ground on these projects back in the 1960s.

 Both of us have boarded bullet trains in foreign countries, taking the TGV from Paris to Bordeaux, or the Shinkansen from Tokyo to Kyoto.

 Ah, but California.

 The years ticked by.

 The governors came and went.

 In 2008, voters approved a plan to build the first segments by 2020 for $33 billion.

 Then in 2011, high-speed rail's foremost champion returned when Brown improbably won back the governor's mansion, almost 30 years after last leaving it.

 In his 2012 state-of-the-state address, he marked high-speed rail as his signature project.

 If you believe that California will continue to grow, as I do, and the millions more people will be living in our state, this is a wise investment, he said.

 And California was ready to make it.

 We are within weeks of a revised business plan that will enable us to begin initial construction before the year is out, he promised.

 And this time, Brown had allies.

 In 2009, President Barack Obama signed the American Recovery and Reinvestment Act into law.

 The recovery bit was obvious.

 The housing bubble had caused a financial crisis, a financial crisis had caused mass joblessness, the economy needed help and it needed it now.

 But the administration wanted to do more than mere stimulus.

 It wanted a legacy.

 It wanted the kinds of ambitious projects upon which another century of American might and prosperity could be built.

 You never want a serious crisis to go to waste, Rahm Emanuel, Obama's chief of staff said.

 And what I mean by that is an opportunity to do things that you think you could not do before.

 This was a reinvestment side of the bill.

 Hundreds of billions of dollars to build the infrastructure of the future.

 And high-speed rail was a glitzy headline project at the center of it.

 Imagine boarding a train in the center of a city, Obama said in April of 2009.

 No race into an airport and across the terminal.

 No delays.

 No sitting on the tarmac.

 No lost luggage.

 No taking off your shoes.

 Imagine whisking through towns at speeds of over 100 miles an hour, walking only a few steps to public transportation and ending up just blocks from your destination.

 Imagine what a great project that would be to rebuild America.

 Now, all of you know there's not some fanciful pie-in-the-sky vision of the future.

 It is now.

 It is happening right now.

 It's been happening for decades.

 The problem is it's been happening elsewhere, not here.

 Obama wanted it to happen here.

 And the most obvious place for it to happen was California, where, Obama continued, voters have already chosen to move forward with their own high-speed rail system, a system of new stations and 220-mile-per-hour trains that links big cities to inland towns, that alleviates crippling congestion on highways and at airports, and it makes travel from San Francisco to Los Angeles possible in two and a half hours.

 In 2009, then, this was the status of high-speed rail in California.

 It was a signature project of the President of the United States, a signature project of the most powerful and experienced governor California had in decades.

 Voters in California had set aside billions to make it real, and the federal government was adding billions more.

 It is hard to imagine a more favorable climate for the project.

 A spokesman for the California High-Speed Rail Authority joined a call-in radio show, told listeners that they'd be able to ride that train from San Francisco to L.A. in the year 2020.

 But progress crawled and costs ballooned.

 In his final state-of-the-state address in 2018, Brown tried to rally Californians to the task.

 Difficulties challenge us, but they can't discourage or stop us, he said.

 The next year, Gavin Newsom, who had served as lieutenant governor, succeeded Brown.

 Let's be real, Newsom said in his first state-of-the-state.

 The project is currently planned, would cost too much, and take too long.

 There's been too little oversight and not enough transparency.

 Right now, there simply isn't a path to get from Sacramento to San Diego, let alone from San Francisco to L.A.

 I wish there were.

 Ambitions were cut.

 No longer was California trying to build high-speed rail, to connect the megacities of San Francisco and Los Angeles.

 Now, it was trying to salvage something, anything.

 A line between the agricultural centers of Merced and Bakersfield.

 A line no one would have authorized if it had been the plan presented in the first place.

 The scaled-down plan was estimated at $22 billion.

 But even the price tag on that line has ballooned.

 The latest estimate is it will cost $35 billion to complete, and it won't begin carrying passengers until sometime between 2030 and 2033.

 And that's if all goes well from here.

 The U.S. has contributed as much to rail technology as any other country in the world, or more than any other country.

 Americans invented the airbrake and led the world in rail construction at the end of the 1800s.

 California businessmen helming the Central Pacific Railroad Company built all but a few hundred miles of the western portion of the transcontinental railroad in the 1860s.

 The project spanned nearly 1,800 miles.

 It took just six years to finish.

 These days, six years is roughly the amount of time it takes California to realize that its bullet train needs to be pushed back by another decade.

 In the time California spent failing to complete its 500-mile high-speed rail system, China has built more than 23,000 miles of high-speed rail.

 In October of 2023, I went to Fresno, California, and toured the miles of rail infrastructure that the California High-Speed Rail Authority has built.

 The project is caught in a strange limbo between political fantasy and physical fact.

 The agency doesn't have anywhere near the money or political capital it would need to complete the Los Angeles to San Francisco system Californians actually want.

 It doesn't even have the money to complete the Bakersfield to Merced system that Newsom proposed.

 It is no line of sight on how it will get that money or that political capital.

 But since it has some money and some political capital, it is building anyway in the hopes that Californians will eventually want to finish what they've started.

 As I walked the path of the track with the engineers who were building it, I heard less about engineering problems than political problems.

 I stood on a patch of the 99 freeway that had been moved in order to clear the hoped-for train's path.

 Not far from there had been a Daryl's mini-storage.

 In folk imagination, eminent domain is a simple process by which the state simply tells you it wants your land, gives you some money, and takes it from you.

 In reality, it took the High-Speed Rail Authority four separate requests for possession and two and a half years of legal wrangling to get that land.

 I heard a story like that repeated again and again and again.

 There are parts of the build that intersect with freight rail lines, but the freight rail lines are so busy in the holiday season that some impose a construction moratorium from October to December.

 So in those areas, no construction can happen for a large chunk of the year.

 Trains are cleaner than cars, but High-Speed Rail has had to clear every inch of its route through environmental reviews, with lawsuits lurking around every corner.

 The environmental review process began in 2012, and by 2024, it still wasn't finished.

 I talked with Brian Kelly, who served as CEO of the High-Speed Rail Authority from 2018 to 2024.

 I'm always amazed his staff has been working on these segments for a decade or longer to get through the environmental process, he said.

 What has taken so long on high-speed rail is not hammering nails or pouring concrete, it's negotiating.

 Negotiating with courts, with funders, with business owners, with homeowners, with farm owners, those negotiations cost time, and time costs money.

 Those negotiations lead to changes in the route, or the build, or the design, which costs money.

 Those negotiations lead to public disappointment and frustration, which leads to loss of money that might otherwise have been approved if the project was speeding toward completion.

 There is one school of thought that says it is worth taking the time to do these projects right.

 If the reviews and the negotiations and the consultations take a few more years, then those are years well spent, but they carry a price tag.

 Kelly said to me, time is a killer on the estimate of a project's cost.

 When you don't have funding and can't make decisions and can't drive to get operational and you can't move the ball, the cost is huge.

 Two to three percent a year, and in higher inflation periods like we just had, five percent.

 As delays mount, costs keep rising.

 The project becomes more expensive to finish.

 The public loses faith.

 The politicians begin second-guessing.

 Governor Gavin Newsom knows how bad this looks.

 He knows how bad this is.

 I watched as a mayor and then a lieutenant governor and now governor as years became decades on high-speed rail, he said.

 People are losing trust and confidence in our ability to build big things.

 People look at me all the time and ask, what the hell happened to the California of the 50s and 60s?

 But it's not just California.

 Democrats today are as searing in their criticisms of public sclerosis as any Republican.

 John Podesta, the graybeard who oversell the rollout of the Inflation Reduction Act for Joe Biden, bemoaned that delays are pervasive at every level of government, federal, state, and local.

 We got so good at stopping projects that we forgot how to build things in America.

 Brian Deese, then the director of Biden's National Economic Council, noted in April 2022 that the Empire State Building was completed in a little over a year.

 He said that government needs to demonstrate that America can build, fast as we've done before, and fairly as we've sometimes failed to do.

 One response, the typical Republican response, is that government is intrinsically inefficient.

 But the data doesn't bear that out.

 The transit cost project tracks the price tags on rail projects in different countries.

 It's hard to get an apples-to-apples comparison here because different projects are different, and it matters whether they include, say, a tunnel, which is expensive for all the obvious reasons.

 Even so, the U.S. is notable for how much we spend and how little we get for it.

 It costs about $609 million to build a kilometer, about 0.6 miles, of rail here.

 But Germany builds a kilometer of rail for $384 million.

 Canada gets it done for $295 million.

 Japan clocks in at $267 million.

 Portugal is the cheapest country in the database at $96 million.

 All those countries, by the way, they build more tunnels than we do, perhaps because they retain the confidence to regularly try.

 The better you are at building infrastructure, the more ambitious you can be when imagining infrastructure to build.

 We looked into it, and it turns out that all those countries, they also have governments.

 So the problem can't simply be government.

 There is a problem in unions, another favored bugaboo of the right.

 Union density is higher in all those countries than it is in the United States.

 The Construction Puzzle Think of the technology we have today that we didn't have in the 1970s.

 The new generations of power tools and computer modeling and teleconferencing and advanced machinery and prefab materials and global shipping.

 You'd think we could build so much more, so much faster, for so much less money than in the past.

 But we can't.

 Or at least, we don't.

 Throughout the 1950s and 1960s, productivity in the construction sector, how much more could be done given the same number of workers and machines and the same amount of land, grew faster than productivity in the rest of the economy.

 Then, around 1970, it began to fall, even as economy-wide productivity kept rising.

 Today, a chasm yawns.

 A construction worker in 2020 produced less than a construction worker in 1970, at least according to the official statistics.

 Contrast that with the economy overall, where labor productivity rose by 290 percent between 1950 and 2020, or to the manufacturing sector, which saw a stunning nine-fold increase in productivity.

 In the sharply titled The Strange and Awful Path of Productivity in the U.S.

 Construction Sector, Austin Goolsby, the president of the Chicago Federal Reserve and a former chairman of the Council of Economic Advisors under President Obama, and Chad Severson, an economist at the University of Chicago's Booth School of Business, set out to uncover whether this is all just a trick of statistics, and if not, what has gone wrong.

 Their paper works by process of elimination.

 First, they look at whether there's been less capital investment in construction than elsewhere in the economy.

 Nope.

 Then they examine whether we're mismeasuring construction, which would mean that sometimes starting in the 1970s, we began overestimating the labor or materials of the construction industry used, or underestimating how much it built with them, or maybe both.

 They test this a few different ways, but the most interesting is to look at how many houses were built per worker, adjusted for square footage.

 There, the trend looks more flat than negative, and maybe slightly positive for single-family homes.

 But it's far from bringing construction productivity anywhere near level with the rest of the economy.

 This isn't a quirk of American record-keeping.

 The slowdown is actually international.

 The Organization for Economic Cooperation and Development tracked construction productivity in 29 countries between 1996 and 2019.

 In 55% of them, productivity fell during that time.

 The only countries in which productivity rose at more than two percentage points per year were the Slovak Republic, Latvia, Estonia, and Lithuania, poor countries rebuilding after the crack-up of the Soviet Union and the Soviet bloc.

 So, if it's not under investment, and it's not a statistical illusion, what is it?

 Here, Goolsby and Severson seem stumped.

 The Warden School, for example, tracks building regulations across cities.

 And Goolsby and Severson tested regulatory burden against construction productivity.

 There was a slight relationship, but nothing all that impressive.

 They looked at which states saw the highest and lowest rates of productivity increases.

 The worst performers, Severson told me, were Alaska, Idaho, Wyoming, Delaware, and Michigan.

 The relative stars were Georgia, North Carolina, South Carolina, Virginia, and Colorado.

 That doesn't lend itself to a clean story of red states and blue states, or urban states and rural states.

 Severson, for one, is skeptical that there's any single answer.

 I don't know how you'd get 50 years of decline without having multiple problems, he said.

 Everyone has their pet theory, but everyone has a different pet.

 But Goolsby and Severson are economists.

 Maybe the cause is obvious to industry insiders.

 Ed Zarensky worked in construction, largely as an estimator, for more than 40 years, and he now runs a market analysis firm, Construction Analytics.

 Zarensky, who tracks construction costs and business volume closely, agrees that there has been a slowdown.

 And he agrees that there is no single cause for it.

 But when he thinks back on what the construction industry looked like when he began his career, and what it looks like now, the anecdotes tumble out.

 When I first started, back in the 70s, you did one estimate on a project, he said.

 You put it in, you got your bid, and if you won, you began construction.

 By the time I left in 2014, you did three estimates for every job before you even put the bid in.

 That becomes part of the cost of the job.

 Or take the job site, he continued.

 The safety features on jobs when I started in the industry were not even noticeable.

 Safety on a job today is incredibly different.

 You don't walk across a beam.

 You walk around on a pathway marked for you to stay safe so you don't fall off the side of the building.

 By the time I retired, one thing that took place every day on every job site was a mandatory 15 minutes of calisthenics before you started your workday.

 That's totally non-productive, but it led to fewer worksite injuries during the day.

 And behind all that is paperwork and paperwork and more paperwork, he said.

 The work we do today takes hundreds more people in the office to track and bring to completion.

 The level of reporting that you have to send to the government, to the insurance companies, to the owner, to show you're meeting all the requirements on the job site, all of that has increased.

 And so the number of people you need to produce that has increased.

 The Organizations of Affluence The economist Mansur Olson's famous 1982 book, The Rise and Decline of Nations, begins with its own productivity mystery.

 After World War II, Germany's and Japan's cities were bombed out, their people dispirited, their economies wrecked.

 The question of the age, Olson writes, was whether these abjectly defeated societies would be able to provide themselves with even the rudiments of survival.

 Instead, West Germany and Japan thrived, growing far faster in that era than Britain, which had emerged victorious from the war.

 Olson was known for seminal work on how groups cooperate, and why so often they don't.

 In The Rise and Decline of Nations, he developed a deeper theory of why nations often stagnate amid affluence, yet thrive in the aftermath of chaos.

 His key insight is that groups capable of collective action, imagine the Sierra Club or the Chamber of Commerce, are slow to build, but powerful and persistent when they coalesce.

 America has long had seniors, but the emergence of the AARP gave them a new level of political power.

 Workers become far stronger once they organize into unions.

 Forming these groups is difficult, but power creates persistence.

 Once a group is successfully organized, it can fight for its own survival and invest in its future strength.

 And so, Olson suggests, if organizations and collusions for collective action usually emerge only in favorable circumstances and develop strength over time, a stable society will see more organization for collective action as time passes.

 So the more organized groups you have, Olson says, the more fights over distribution you'll have, the more lobbying you'll have, the more complex regulations you'll have, the more bargaining you'll get between groups, and the harder it will be to get complex projects done.

 Affluent, stable societies have more negotiations, and that means they have more negotiators.

 There's great good in that.

 It means people's concerns can be voiced.

 It means their needs can be met, their ideas can be integrated, their insights can be shared.

 It also means it becomes difficult to get much of anything done.

 This is why China can build tens of thousands of miles of high-speed rail in the time it takes California to fail to build hundreds of miles of high-speed rail.

 China does not spend years debating with judges over whether it needs to move a storage facility.

 That power leads to abuse and imperiousness.

 It also leads to high-speed rail.

 The Rise and Decline of Nations is a classic economics text, but time has exposed gaps in the theory.

 Japan has gone from economic poster child to growth laggard.

 Olson's argument would seem to imply that the United States, with its geographic protection against invasion, and its long history of continuity, would be far more sclerotic than Germany.

 But it isn't.

 And Olson has no real answer for why so few countries that fall into crisis subsequently grow into affluence.

 Olson's biggest error is his assumption that groups organize around redistribution.

 Olson almost completely missed the post-materialist turn in the politics of affluent countries.

 Some groups seek to fill their coffers, but others are organized to protect the environment, to increase safety standards, to preserve the feel of their communities, or to express their values.

 These kinds of groups have been engines of social progress.

 Their existence is a gift of affluence, not just a disease of affluence.

 But Olson, who died in 1998, was right when he said that affluence is a gift that comes with costs.

 And those costs concentrate in the areas of the economy, in which the numbers of groups that have to be consulted mounts.

 From this perspective, the productivity woes in the construction industry don't seem so puzzling.

 It's relatively easy to build inside the confines of computer code.

 It's harder, but manageable, to manipulate matter within the four walls of a factory.

 When you construct a new building, or subway tunnel, or highway, you have to navigate neighbors and communities, and existing roads, and emergency access vehicles, and politicians, and beloved views of the park, and the possibility of earthquakes, and on, and on.

 Construction may well be the industry with the most exposure to Olson's thesis.

 And construction of public projects, like high-speed rail, is almost uniquely vulnerable.

 It is the government's job, after all, to balance society's many competing perspectives.

 They need to do more than turn a profit, or satisfy shareholders.

 Zarensky's experience often felt like a narrativization of Olson's thesis.

 There are so many people who want to have some say over a project, he told me.

 You have to meet so many parking spaces per unit, it needs to be this far back from the sight lines, you have to use this much reclaimed water, you didn't have 30 people sitting in a hearing room for the approval of a permit 40 years ago.

 Severson told a similar story.

 There are a million veto points, he said.

 There are a lot of mouths at the trough that need to be fed to get anything started, or done.

 So many people can gum up the works.

 That's particularly true in richer areas.

 There's a reason so much of the housing construction in Washington, D.C., since 2000, has happened in the city's southwest, rather than in Georgetown.

 When richer residents want something stopped, they know how to organize, and they often already have the organizations, to say nothing of the lobbyists and access needed to stop it.

 These dynamics help explain a curious finding that ends Severson and Goolsbee's paper.

 After looking at the states with the highest construction productivity, they note that the more productive states don't seem to gain market share in the construction industry.

 That doesn't make much sense if you assume that the difficulties of construction are primarily the organization of manpower and materials.

 It makes more sense if you assume that the frictions are navigating local regulations, community considerations, neighbors' qualms, and politicians' interests.

 Developers are often fixtures in the local political scene.

 They have to be.

 My feeling, Zarensky told me, is the guys that know the system have a much easier time getting through the system.

 They know ahead of time what they have to come into the party with, and how to speak to those people, and how to satisfy them, and so it goes a lot smoother for them.

 But a thorough knowledge of one city or state, and establishing relationships with its decision makers, won't necessarily translate to success in another.

 In a separate paper, Ed Glazer and four co-authors add to this story.

 They begin with another astonishing fact.

 From 1935 to 1970, the number of homes produced per construction worker increased at the same pace as, and sometimes even faster than, the number of cars produced per automobile industry worker, or the total manufactured output per industrial worker.

 The world we live in, where manufacturing productivity rises and rises, even as construction productivity falls, it's a new phenomenon, a new world, not a historical inevitability.

 Glazer and his colleagues go on to look at the size of the firms involved.

 It turns out that big home construction companies are much more efficient than small home construction companies.

 No surprise there.

 But the market in home construction is dominated by small firms.

 More than 60% of employment in single family home construction is in firms with fewer than 10 employees.

 In manufacturing, most employees work in firms of more than 500 people.

 So why is home construction in America dominated by such small firms?

 The researchers pick through the data, and they find that firms are allowed to build on less and less land, and are subject to more and more land use regulations, in ways that choke off their ability to grow and scale their work across cities and states.

 A manufacturing plant can locate in one place and sell everywhere.

 Builders have to negotiate through the regulations and interest groups and political relationships of each parcel of land they work on individually.

 One of Olson's insights is that a complex society begins to reward those who can best navigate complexity.

 That creates an incentive for its best and brightest to become navigators of complexity, and perhaps even creators of further complexity.

 Every society, whatever its institutions and governing ideology, gives greater rewards to the fittest.

 The fittest for that society, Olson writes.

 A young country that is still in its building phase creates opportunities for engineers and architects.

 A mature country that has entered its negotiations phase creates opportunities for lawyers and management consultants.

 Then there's the incentive to avoid bureaucracy and its attendant frustrations.

 Patrick Collison, the CEO of the online payments behemoth Stripe, was once asked whether too much talent is flowing into Silicon Valley.

 I don't think that the ambitious upstarts who go into high-speed rail, in America anyway, are going to have a great time or have much success in convincing their friends to follow them.

 And I suspect that, for various reasons, too many domains look somewhat like high-speed rail.

 There's a view that the internet is a frontier of last resort, and I don't think it's totally wrong.

 Nader's Raiders America's post-war politics are often shorthanded as the rise of New Deal liberalism and the backlash of small government conservatism.

 But it wasn't just conservatives who came to thank the government reckless and dangerous and in need of new rules and strictures.

 Liberals did too.

 After World War II, as highway construction grew, vehicle sales soared.

 So did road deaths.

 Motor vehicle fatalities rose from about 30,000 in 1946 to more than 50,000 in the late 1960s.

 In 1965, a lawyer named Ralph Nader published the book Unsafe at Any Speed, a blistering expose of car manufacturers resisting safety improvements while blaming individual drivers for rising fatalities.

 The book was a sensation.

 In 1966, Lyndon Johnson signed the National Traffic and Motor Vehicle Safety Act and the Highway Safety Act, which mandated a new set of auto safety standards.

 Nader soon became one of the most famous lawyers in America.

 To replicate his success, he recruited teams of young activists to join the cause of bird-dogging government and big business on behalf of consumers.

 His disciples, known as Nader's Raiders, transformed politics with their blend of expertise and advocacy.

 So far as anyone can remember, a Christian Science Monitor reporter wrote in 1969, nothing quite like this has happened in Washington before.

 A group of unofficial but informed outsiders as a sort of civilian posse has descended on a rather stuffy government commission, poked under sofas, and asked some rough questions.

 As the historian Paul Sabin writes in his book Public Citizens, reformers like Ralph Nader were right to concentrate their fury on government and its safety record in the 1960s.

 The government was allowing strip mines to ravage the Appalachian Mountains and leaving coal miners to suffer from black lung disease with little compensation, he writes.

 Government policies were permitting oil refineries to freely dump toxic emissions into low-income communities of color and letting oil spills pollute the nation's waterways and coasts.

 Nader didn't just criticize the government, he launched a movement to tame it.

 His rate was contributed to some of the most important environmental laws in history, including the Clean Water Act.

 With each win, they made it easier for more citizens and groups to sue the government for wrongdoing.

 But what they were building was an arm of liberalism with associated institutions, laws, and leaders designed to relentlessly sue the government itself and that would go on to fight for more bills and rules that would widen the opportunities to sue the government.

 Sabin writes, Litigation by leading public interest environmental law firms in the early 1970s almost exclusively targeted the government for legal action.

 The Sierra Club Legal Defense Fund boasted 77 legal accomplishments between 1971 and 1973.

 Approximately 70 sought to block government actions or to intervene in public proceedings to influence government regulatory and permitting practices.

 The Environmental Defense Fund similarly began its 1972 case summary with a list of acronyms for the 10 federal agencies named in its legal interventions.

 In more than 60 of its 65 listed legal actions, the Environmental Defense Fund either intervened in public proceedings, such as government permitting processes for private projects, or directly assailed a government-led initiative.

 Fewer than five of EDF's legal actions directly targeted companies or private parties.

 Similarly, only three out of 29 of NRDC, the National Resource Defense Council's legal action initiatives from its first seven months, directly named a corporate defendant.

 The environmentalist movement succeeded brilliantly.

 Between 1970 and 2020, the combined emissions of the six most common pollutants, which include lead, carbon monoxide, and sulfur dioxide, dropped by roughly 80 percent.

 New cars, SUVs, and trucks that run against today are more than 99 percent cleaner than in 1970.

 Imagine that, more than 99 percent cleaner.

 The benefits of the Clean Air Act, which was amended in 1977 and 1990, have prevented between 400,000 and several million premature deaths in the last 50 years.

 The reduction in lead furthermore saved tens of thousands from senseless poisoning and saved millions of IQ points.

 The number of very unhealthy or hazardous air days in Los Angeles fell from 160 in 1981 to an average of two in the 2010s.

 But behind these victories, NATO's revolution created a new layer of government, democracy by lawsuit.

 The number of lawyers and cases soared in the 1970s and 1980s.

 The result, Sabin argues, was a new kind of liberalism, which regarded government not as a partner in the solution of societal problems, but rather as a source of those very problems.

 When the PBS news anchor Jim Lehrer asked Nader why he was qualified to be president in 2000, Nader told him, I don't know anybody who has sued more agencies and departments.

 Nader and his raiders believed in government.

 They defended it from conservative assault.

 When they criticized it, when they fought it, sued it, restrained it, they did so to try to make it better.

 But those same laws and processes were available for anyone else to use, too.

 You can bog clean energy projects down in environmental reviews.

 You can use a process meant to stop the government from building a highway through your town, to keep a non-profit developer from building affordable housing down the block.

 It was as if liberals took a bicycle part to fix it, but never quite figured out how to get it running properly again, Sabin writes.

 Liberalism's Lawyer's Problem Nicholas Bagley, a law professor at the University of Michigan, has seen the broken bicycle up close.

 When he served as Governor Gretchen Whitmer's chief legal counsel, he noticed that Republicans were consistent in the way they tried to weaken the government.

 They would bury it in paperwork and procedure and hearings and disclosure demands and lawsuits.

 It was as if the right had studied the tactics of Nader's Raiders and adopted them for their own purposes.

 The 2017 Regulatory Accountability Act, which Republicans proposed but couldn't ultimately pass, was a good example.

 For every major regulation, it would have forced the government to open a period of comment and solicit alternative approaches from the public.

 It would have given those affected the opportunity to cross-examine the agency proposing the rule at an oral hearing.

 It would have forced the publication of ongoing frameworks for evaluation, and much more.

 Some of these ideas, they sound fine in theory, but multiplied across the entire swath of major regulations the government proposes or carries out, and weaponized by groups and individuals who oppose those regulations and want to destroy or slow them down, the burden of compliance would become overwhelming.

 What Bagley saw was that Democrats would defend the government against these salvos, but they didn't seem to notice what the defenses implied.

 If Republicans were proposing more paperwork and process to make the government less effective, wasn't it likely that less paperwork and process would make the government more effective?

 Or as Bagley asked, if new administrative procedures can be used to advance a libertarian agenda, might not relaxing existing administrative constraints advance progressive ones?

 In 2019, Bagley published an incendiary article in the Michigan Law Review, which he later turned into a policy paper for the Niskanen Center.

 The procedure fetish, as he called it, argued that something had gone wrong inside government, inside liberalism, inside Bagley's own profession.

 Liberal legalism, and through it liberal government, had become process-obsessed rather than outcomes-oriented.

 It had convinced itself that the state's legitimacy would be earned through compliance with an endless catalog of rules and restraints, rather than through getting things done for the people it claimed to serve.

 Inflexible procedural rules are a hallmark of the American state, Bagley wrote.

 The ubiquity of court challenges, the artificial rigors of notice and comment rulemaking, zealous environmental review, pre-enforcement review of agency rules, picayune legal rules governing hiring and procurement, nationwide court injunctions, the list goes on and on.

 Collectively, these procedures frustrate the very government action that progressives demand to address the urgent problems that now confront us.

 Behind these procedures, Bagley suggested, were two very real concerns, legitimacy and accountability.

 How can a government as powerful and vast as that of the United States maintain legitimacy?

 How can it maintain accountability to citizens?

 These fears reflect, in part, the age in which the rules were written.

 The 1946 Administrative Procedure Act, which governs much of the federal government's bureaucratic workings, was adopted to soothe the jangled nerves of legal and business communities alarmed by the New Deal and the muscular wartime exercise of state power.

 Then came the buildup of procedural architecture in the 70s, when liberal lawyers, inspired by the courtroom heroics of the civil rights movement, turned to the legal system to make sure that the government actually worked on behalf of the people.

 The system we developed is unique.

 Decisions that are often made by bureaucracies in other countries are made by judges in our country.

 Robert Kagan, a law professor at the University of California, Berkeley, calls it adversarial legalism.

 It is only a slight oversimplification to say that in the United States, lawyers, legal rights, judges, and lawsuits become functional equivalents for the large central bureaucracies that dominate governance in the activist states of Western Europe, he writes.

 There's a reason, Kagan thinks, that America's ended up with a system we have.

 Americans have always mistrusted the government.

 They've particularly mistrusted centralized power.

 But they also need a government able to wield power.

 They want the good a government can do.

 That tension became unbearable after the New Deal and the Great Society.

 Between 1965 and 1977, responding to the new political movements, Congress passed 25 major environmental and civil rights acts, plus far-reaching statutes regulating workplace safety, consumer lending, product safety, private pension funds, and local public education, Kagan writes.

 It created federal regulatory agencies or bureaus to issue implementing regulations, binding on millions of business firms.

 But to enforce those laws and regulations, Congress was compelled to bow to the inherited demands for decentralization of government.

 Americans were asking the government to do more than it ever had, but they were not willing to give the government the trust and authority it needed to do it.

 But reformers could not simply devolve power to state and local governments.

 Liberals had just seen, in the fight against Jim Crow, that you could not trust the states, much less the localities, to do what the federal government asked.

 And so they turned to the courts, which had, under Chief Justice Earl Warren, become newly beloved by liberals.

 Adversarial legalism was a way of reconciling the government we wanted with the suspicions we harbored.

 America is unusually legalistic.

 It always has been.

 In 1835, Alexis de Tocqueville wrote, Scarcely any political question arises in the United States that is not resolved, sooner or later, into a judicial question.

 What was true then is truer now.

 America has twice as many lawyers per capita as Germany, and four times as many as France.

 Much of this energy is now devoted to suing the government.

 In 1967, there were three cases per 100,000 Americans directed at enforcing federal laws.

 By 1976, there were 13.

 By 2014, there were 40.

 The prevalence of lawyers in American life is unusual, but their dominance at the top of American politics is startling.

 Bagley writes that, though they make up less than 1% of the population, lawyers currently constitute more than one-third of the House of Representatives, and more than half the Senate.

 Fully half of the last ten presidents were lawyers, as are more than a third of the officials now serving in the states as governor, lieutenant governor, and secretary of state.

 In the Democratic Party, every presidential and vice presidential nominee from Walter Mondale to Kamala Harris attended law school.

 Tim Wall's, in this respect, was an almost radical break with tradition.

 When you make legal training the default training for a political career, you make legal thinking the default thinking in politics.

 And legal thinking centers around statutory language and commitment to process, not results and outcomes.

 Olson predicted that a thriving, successful society would become more complex to navigate over time.

 There would be more groups and voices and laws and processes.

 Those who succeeded would be those best suited to operating at the nexus of that complexity.

 In the economy, that might be management consultants and financiers.

 In politics, it'll be lawyers.

 Now, there's nothing wrong with lawyers.

 There might be something wrong with a country or political system that needs so many of them, and that makes them so central to its operations.

 There might be a system so consumed, trying to balance its manifold interests, that it can no longer perceive what is in the public's interest.

 Legitimacy is not solely, not even primarily, a product of the procedures that the agencies follow, Bagley writes.

 Legitimacy arises more generally from the perception that government is capable, informed, prompt, responsive, and fair.

 And that is where government is failing.

 California's high-speed rail authority has been scrupulous in following the law, but it has been unable to deliver a train.

 The result is less, not more, faith in government.

 The Pew Research Center has aggregated decades of polls tracking the public's trust in government.

 The higher mark of the chart is in 1964, when 77% of the public believed that the government would do the right thing all or most of the time.

 Confidence plummets from there.

 In the 70s, after Watergate, it sits in the 30% range.

 Confidence rebounds into the 40s in the 1980s, and briefly brushes the 60s after 9-11.

 But the downward trend is undeniable.

 By 2023, only 16% of the country expressed confidence in government.

 This is not, in our view, attributable solely or even mainly to cumbersome government processes.

 But the collapse in trust across the same decades that so many processes were being built to affirm that government could be trusted should make us question whether we've yoked the state to a failed theory of legitimacy.

 Now the government has taken on the task of decarbonization and the responsibility of coordinating a once-in-a-century transformation of America's built landscape, but is doing so with laws and agencies and habits that are better designed to block green construction than to allow it.

 The Green Dilemma In 2020, J.B. Ruhle and James Salzman published a paper titled, What Happens When the New Green Deal Meets the Old Green Laws?

 They began by imagining a presidential debate in which two opposing candidates describe their vision for remaking America's energy infrastructure.

 One candidate proposes doubling down on oil and gas production, building more freeways, and crisscrossing the country in natural gas pipelines.

 The other candidate imagines an all-out race to an economy built atop renewables, with electric vehicle chargers everywhere and a national high-speed rail system anchoring American transit.

 These two infrastructure agendas could not be more different in vision, but they are very much alike in one key respect, Ruhle and Salzman write.

 Each is an environmental impact assessment and project permitting nightmare.

 The problem, Ruhle and Salzman argued, is that the Green New Deal must undertake multiple national-scale infrastructure initiatives of magnitudes never before processed through existing siting and environmental law standards and procedures.

 And there was little reason to believe that was possible.

 Examples were already piling up of renewable projects being stalled or killed by coalitions akin to those that formed against dirty energy projects and that were deploying the same environmental laws and rules.

 Most people do not like the idea of an oil pipeline or electric transmission line running through their backyard, write Ruhle and Salzman.

 And guess what?

 They do not like the idea of wind turbines or solar panels in their backyard either.

 In their follow-up, The Green's Dilemma, Ruhle and Salzman tried to diagnose a problem more precisely.

 The raft of environmental laws in the 1970s, he said, represented a grand bargain of sorts.

 The quid pro quo for a cleaner environment was that development would become slower and more expensive due both to permitting and to the litigation that often ensued.

 In many respects, this has turned out to be a good deal.

 Apart from greenhouse gases, which effectively have been unregulated, every major air pollutant has decreased significantly over the last five decades, from carbon monoxide and sulfur dioxide to airborne lead and others.

 Surface water quality has similarly improved substantially since the 1970s.

 But that bargain has broken down.

 The problem we faced in the 1970s was that we were building too much and too heedlessly.

 The problem we faced in the 2020s is that we were building too little and we are too often paralyzed by process.

 And this is not just a view of a few law professors.

 The environmentalist movement evolved to stop bad people from destroying the world.

 And so we have perfected the art of saying no.

 That's Larry Selzer, the president and CEO of the Conservation Fund.

 He continues, But we can't know our way to the kind of growth we need.

 The interstate highway system is 49,000 miles of road.

 The interstate clean energy system, the solar farms, the wind turbines, the geothermal land, the transmission lines, the pipes, will touch more than 500,000 miles of land.

 This will be an enormous project.

 We have to build and build and build.

 Rule and Salzman, for their part, believe we need new laws.

 The problem with the laws we have is that they're indiscriminate.

 It is as easy to obstruct an oil refinery as a wind farm.

 The National Environmental Policy Act, often called NEPA, gets much of the attention here.

 But the problem is really the profusion of different, overlapping policies and authorities.

 Beyond NEPA, Rule and Salzman note the Endangered Species Act, the Migratory Bird Treaty Act, the Marine Mammal Protection Act, the Coastal Zone Management Act, the Clean Water Act, the Federal Land Policy and Management Act, and the National Forest Management Act.

 All told, they write, over 60 federal permitting programs operate in the infrastructure approval regime.

 And that is just of the federal system.

 State and local approvals and impact assessments could also apply to any project.

 The Chokecherry and Sierra Madre Wind Energy Project, which is intended for federal land in Wyoming, would be the largest wind farm in U.S. history.

 Building it has meant navigating a morass of federal, state, and local permitting and siting authorities, as well as environmental challenges.

 If all goes well from here, it will be completed in 2026, 18 years after it was proposed.

 Timetables like that will not meet the climate emergency we now face.

 Either we build faster or we accept catastrophe.

 There is no third option.

 In his paper, Getting Infrastructure Built, The Law and Economics of Permitting, Zachary Liscoe notes that the United States performs below the average of OECD states in environmental quality, but it also performs below average in confidence in government.

 So despite its participatory ethos, he writes, the United States does not succeed in producing more trust.

 What we are leaders in is in the cost of public construction.

 In separate work with Leah Brooks, Liscoe has found that the cost of building a mile of interstate highway tripled in the back half of the 20th century.

 Though the data are fairly sparse, they write, available data show that the U.S. interstates built in the 1980s and 1990s were more expensive in real terms than any projects built elsewhere at any time, and that the highways built since 2010 are far more expensive than highway projects elsewhere in the world.

 To many environmentalists, that's a victory.

 It should be harder, they think, to build highways.

 But that same architecture of law affects the infrastructure they care about, too.

 It is important to keep in mind what is actually expected to be permitted in the coming decades, Liscoe continues.

 Among projects seeking to connect to the grid, which is one indicator, though an imperfect one, of what will ultimately be built, 95% of the capacity is solar, battery storage, or wind.

 That is a dramatic change from 1969, when 81% of the electricity supply was petrochemical, and only 19% was zero emission.

 New problems and new solutions require new laws.

 Rule and solves men favor past models by which certain kinds of projects have been fast-tracked past environmental and legal challenges.

 A 1996 law offered this favoritism to border security, and the Trump administration used it to great effect in constructing parts of their border wall.

 In another example, Congress recognized that we had too many military bases after the Cold War, and that closing them through the normal congressional process would be politically impossible.

 So they created an independent base-closing commission that received recommendations from the Department of Defense, proposed plans for closure based on those recommendations, and ensured those plans got simple and fast up-and-down votes.

 In October 2024, President Biden signed legislation exempting semiconductor manufacturing facilities receiving subsidies under the Chips and Science Act from Environmental Review.

 Something similar could be created for green infrastructure, Wuland Salzman suggests, with projects deemed important to our climate goals, fast-tracked past a slew of normal hurdles.

 Something akin to this system would, in their thinking, update our environmental laws for a new age, tuning them to meet the challenge of today rather than the challenge of yesteryear.

 But no individual law will address this many different blockages at this many points in the system.

 What is needed here is a change in political culture, not just a change in legislation.

 Liberalism acted across many different levels and branches of government in the 1970s to slow the system down so the instances of abuse could be seen and could be stopped.

 Now it will need to act across many different levels and branches of government to speed the system up.

 It needs to see the problem in what it has been taught to see as a solution.

 Nothing about this is easy and it is not always clear how to strike the right balance.

 But a balance that does not allow us to meet our climate goals has to be the wrong one.

 Chapter 3 Govern To Hannon at 833 Bryan Street in the Soma neighborhood of San Francisco is 145 studio units of permanent supportive housing for the chronically homeless.

 Completed in 2021, it's a cheerful, efficient building that bears the hopes and the scars of the population it serves.

 When I was there, the curated murals and architectural flourishes were pockmarked by extensive water damage inflicted when a resident on an upper floor reportedly slept with the faucets running.

 We also had social workers striding purposely through the halls.

 Well-loved dogs were being walked everywhere I turned.

 But what makes To Hannon notable isn't its aesthetic.

 It's the way it was built.

 To Hannon went up in three years for less than $400,000 per unit.

 Affordable housing projects in the Bay Area routinely take twice as long and can cost almost twice as much.

 A report from the Turner Center for Housing Innovation at the University of California, Berkeley reads, Development timelines for affordable projects in San Francisco have typically stretched to six years or longer and development costs have reached $600,000 to $700,000 per unit.

 San Francisco cannot dent its housing crisis at the speed and cost at which it is building affordable units now.

 But if the pace and price of To Hannon were the norm, the outlook would brighten.

 So how did To Hannon do it?

 The answer, for liberals, is depressing.

 It used private money to avoid the piles of rules and regulations that taking government money triggers.

 But it could only do that because it had the support of city and state officials who streamlined zoning and cut deals to make it possible.

 To Hannon reveals a confusion in the way we talk of the government.

 The government is a plural posing as a singular.

 Different factions and officials and regulations and processes push in different directions.

 It is often the case that no one is more frustrated by how the government works than the people who work in it or who are charged with running it.

 To Hannon was built on the former site of a parking lot and a temporary bail bond office.

 Sounds easy enough to build on.

 But the site wasn't zoned for affordable housing.

 The project could get off the ground only because of legislation passed by State Senator Scott Wiener in 2017 that fast-tracked certain kinds of affordable housing projects in California past the local approval process.

 I talked with Rebecca Foster, the chief executive of the Housing Accelerator Fund, which led the development of To Hannon.

 This project didn't have to go before the planning department for discretionary review or the board of supervisors, she told me.

 We got our entitlements in four months, which is unheard of.

 But entitlements merely mean you can begin the process of building.

 When you're building affordable housing, you're typically using public money.

 When using public money, you have to abide by public requirements.

 Take the Local Business Enterprise and Non-Discrimination in Contracting Ordinance, also known as 14B.

 These requirements began in 1984 as a preference for minority and female-owned contractors.

 But in 1996, California passed Proposition 209, which held that the state shall not discriminate against or grant preferential treatment to any individual or group on the basis of race, sex, color, ethnicity, or national origin in the operation of public employment, public education, or public contracting.

 Instead of scrapping the contracting requirements, San Francisco rewrote them to favor small businesses.

 The public has an interest in fostering a strong and vibrant network of small and very small micro-businesses in San Francisco, the ordinance says.

 To qualify as one of the favored micro-local business enterprises under 14B, a contractor must have less than $12 million in average annual gross revenue.

 This cap creates a few problems.

 One is that it means public housing efforts in San Francisco are, by definition, discouraged from working with large contractors that have grown in size and revenue precisely because they are good at delivering projects on time and under budget.

 Another is that San Francisco has a tight labor market and an even tighter construction market.

 There aren't a lot of capable small contractors sitting around with nothing to do.

 In practice, Foster said, a few small contractors end up attached to a large number of affordable housing jobs, causing delays and cost overruns.

 Then, of course, there's the cost of compliance, of proving to the city you're following the 14B rules.

 Foster's team estimates that requirements like 14B could add six to nine months and millions of dollars to building an affordable housing project the size of Tahanan.

 And it's not just 14B.

 There are other requirements.

 There are local hiring requirements.

 You have the Arts Commission do a separate review of your design.

 You then need an additional review from the Mayor's Office on Disability.

 That's a good one to look at.

 Who would oppose that?

 But these projects, they already have to comply with the Americans with Disabilities Act.

 And the additional review takes time and it comes at a cost.

 They come in when you're done, Foster told me.

 And they'll say, that threshold is two centimeters off and it is in all of your doors.

 And so that delays people moving in for another couple of months.

 And it might mean that you miss a financing deadline and now you have an adjuster on your tax credit fees that add another two million.

 So it just has a big ripple impact.

 Tehanan is the first affordable housing project in San Francisco built using modular housing.

 All the units above the ground floor were fabricated at a factory in Vallejo, California.

 That definitely helped with meeting the time and cost-saving goals, Foster said.

 But some local unions were furious even though the factory in Vallejo is unionized.

 Here then is another place where progressive goals can conflict.

 Local union jobs are a good thing.

 Modular housing can make construction cheaper and faster in a state facing a severe housing shortage.

 Which do you choose?

 What made Tehanan possible was a $65 million grant from Charles and Helen Schwab.

 The grant's conditions were that the housing had to be built in under three years and for under $400,000 per unit.

 By using private financing, the project avoided the standards and rules that public money carries.

 That isn't to say the political system in San Francisco was against the project.

 The Board of Supervisors approved a crucial lease to keep the development operating into the future.

 But private money was the secret sauce.

 It is damning that you can build affordable housing so much more cheaply and swiftly by foregoing public funds.

 Shouldn't things happen faster when they are backed by the might and the money of the government?

 A False Divide We are used to understanding the battle lines of American politics as cleaving liberals who believe in a strong, active government from conservatives who doubt it.

 The truth is far more complicated.

 Liberals speak as if they believe in government and then pass policy after policy hamstringing what it can actually do.

 Conservatives talk as if they want a small state but support a national security and surveillance apparatus of terrifying scope and power.

 Both sides are attached to a rhetoric of government that is routinely betrayed by their actions.

 The big government small government divide is often more a matter of sentiment than substance.

 Neither side focuses on what scholars call state capacity the ability of the state to achieve its goals.

 Sometimes that requires more government sometimes it requires less government but it always requires a focus on what the state is trying to achieve and what is in its way.

 In the absence of that focus absurdity reigns.

 Across Europe government administered healthcare systems negotiate down the prices of drugs and treatments.

 In America our fear of socialized medicine has led to a hodgepodge of private and public insurers who do not coordinate and do not effectively negotiate.

 The weight loss drug with Zempic for instance costs about 10 times as much in America as it does in Britain or France.

 Those countries have national healthcare systems that restrict what pharmaceutical companies can charge and we do not.

 As a result taxpayers in Europe spend less on healthcare as a percentage of GDP than taxpayers in America.

 And then Americans have enormous private healthcare bills atop our public healthcare spending.

 Keeping the American healthcare state weak has made the American government larger and left Americans poorer.

 But liberals lose sight of their goals too.

 In response to the Tehannon story Bob Kuttner the co-founder of the stalwart liberal publication The American Prospect tried to jam the problem into a container that the left is more comfortable with.

 We have a very modest social housing sector in the U.S.

 and limited funds for housing subsidies he wrote.

 We are largely at the mercy of developers.

 We could eliminate zoning restrictions and make it easier to build multifamily housing and that would solve only a small portion of the affordable housing shortage.

 You see a comfort there with solutions that put more faith in government like public or social housing and a discomfort with solutions that seem to align with markets like being at the quote mercy of developers and eliminating zoning restrictions.

 But the reality of housing development doesn't track along such neat ideological lines.

 Kuttner says that eliminating zoning restrictions and making it easier to build multifamily housing would make only a modest difference in our problems.

 He does not provide any evidence for this claim but there is evidence against it.

 Houston has no zoning rules at all though it does have some land use regulations.

 As a result it is dramatically easier to build in Houston than to build in Los Angeles or San Francisco or Seattle or Boston.

 The numbers here are astonishing.

 In 2023 the San Francisco metro area issued about 7,500 new housing permits.

 The Boston metro area issued 10,500.

 New York City, Newark and Jersey City together issued slightly fewer than 40,000.

 The Houston metro area issued almost 70,000.

 And this divergence is now decades old and its consequences are clear.

 Houston has the lowest homelessness rate of any major U.S.

 city.

 Officials estimate that it costs $17,000 to $19,000 to house a homeless resident of Houston with about 12,000 of that going to housing and the rest to wraparound services.

 In San Francisco the cost is between $40,000 and $47,000 annually with about $35,000 of that going to housing costs alone.

 This tracks a broader difference between the two cities.

 In Houston the median home costs a bit over $300,000 rather than a bit over $1.7 million in San Francisco.

 Houston is not free of affordability problems but it is not facing the crises of homelessness and housing affordability seen in the superstar cities of many blue states.

 Liberals lament that private developers want to build profitable developments when what is needed most is affordable housing.

 But even aside from how much housing is built, one way to make housing more affordable is to make it cheaper to build at all.

 The problem is that many liberal jurisdictions have layered on rules and regulations that make housing pricier when it is constructed.

 And that, of course, makes it less affordable.

 In San Francisco, a 2023 state report found that it took 523 days on average to get clearance to construct new housing and another 605 days to get building permits.

 And that's for the projects that aren't killed by community opposition during the planning process.

 A project needs to be quite profitable to make it through that gauntlet, and it needs to be acceptable to its wealthy neighbors.

 And that pushes developers towards luxury condos.

 But the grim absurdity of liberal housing policy comes clearest when you focus on the kind of housing liberals claim to support affordable housing built by non-profit developers with the backing of both voters and local government.

 In 2016, the people of Los Angeles overwhelmingly passed Proposition HHH, a ballot measure that raised $1.2 billion through a higher property tax to create 10,000 new apartments for the homeless.

 The voters of Los Angeles have radically reshaped our future, Mayor Eric Garcetti said, giving us a mandate to end street homelessness over the next decade.

 By March 2024, the city had built only 4,344 units under HHH, and a 2022 audit found the units were costing, on average, around $600,000, almost twice the cost of the median sale price for a home in Houston.

 There have been many problems with Prop HHH, but the real problem predates it.

 The way that taking advantage of public money layers on requirements, delays, and additional goals, slowing down construction and raising costs.

 HHH is designed to provide some, but not all, of the money for developments.

 Defenders of HHH are quick to point out that the average cost per unit includes only about $134,000 of HHH funds.

 The program is designed to seed projects that can find other financing too.

 That sounds good, right?

 By leveraging outside money, the taxpayer's dollar can go further.

 In reality, it means affordable housing projects you need to line up four or five or six different funders, cobbling together tax credits and philanthropic donations and state and local incentives.

 Everyone wants to be able to say, we spent only $50,000 on this apartment.

 That means I have to go through the process four or five times.

 Yasmin Tong, the founder of CTY Housing, which consults on affordable housing projects, told me, I've seen projects with as many as 10 funding sources.

 It takes time to do that.

 The different financing sources come with different demands, all of which make the project more complex.

 The developer has to hopscotch from one funding source to another, to another, Tong said.

 So you start by saying, we'll serve low-income families in this development, but the funding falls through.

 So you put in veterans units, or try to house domestic violence survivors in here.

 There's this constant restructuring of the project as the funding sources come and go.

 Ron Galperin was the Los Angeles City Controller from 2013 to 2022.

 His office was responsible for auditing HHH.

 His office tracked how much each unit cost and where the money came from and whether the program was achieving its aims.

 You might expect him to praise HHH's effort to match each dollar with five dollars from other funders.

 In fact, he's furious at the way the money was structured.

 If you look at the inflated cost that comes along with all of the regulations and rules and restrictions and limitations, Galperin told me, then basically all of this money is going to feed the beast of covering the cost of the regulations.

 Yes, they got $134,000 on average from the city, but the hoops that have to be jumped through to get it very well may exceed the $134,000.

 We've created an absolutely insane system.

 Then there are the higher quality standards that public money requires developers to meet.

 We're required to pay prevailing wage, so there's at least a 20% or 30% premium on the labor costs, Tonk says.

 We have sustainability requirements we need to maintain.

 I've had projects where the planning department required a higher quality air ventilation system because we were a certain distance from the freeway.

 All the affordable housing development is subject to green building requirements.

 The standards in California are higher than anywhere else in the country.

 And you're not just required to build to the standard.

 You also need to hire a consultant to confirm you've built to the standard.

 That adds costs.

 Every one of these is a worthy goal, but so too is building a lot of affordable housing quickly and cheaply.

 Los Angeles is failing and failing badly at doing that.

 Given that failure, does it make sense to be asking for special air filtration systems for developments near freeways when the alternative for many of the would-be residents is a tent beneath the freeway?

 To pose the question sounds callous, but to refuse to pose the question, given the need for more housing, is cruel.

 These additions do not come only from planning boards trying to upgrade the quality of the housing.

 They also come from the neighbors who would prefer that the housing never got built at all.

 In Venice, home of the legendary boardwalk, the Venice Dell Community Project is trying to turn a parking lot owned by the city into a 140-unit building for homeless residents, low-income artists, and families, all of it designed by a star architect.

 The development is being fought and even sued by a collection of local homeowners who complain that Venice desperately needs his parcel to address our chronic parking shortage, that the new housing would be an eyesore completely divorced from sound architectural principles, and that it is being developed with no environmental review in a designated tsunami zone and FEMA special flood hazard zone.

 When do Angelenos want affordable housing?

 Now.

 Where do they want it?

 Not here.

 Surviving local opposition often means agreeing to a range of demands that send costs ballooning.

 To try to neutralize local tax developers hire pricey architects, they redo plans repeatedly, making all kinds of aesthetic and architectural concessions or additions, hiring extra lawyers and auditors, and on and on.

 Even if a project does survive all this, it does so at a higher per unit cost, which then of course becomes one more data point that gets wielded in opposition to the next project.

 Perhaps, as Kuttner suggests, the problem is simply that we don't have enough public, or as it's been rebranded, social housing.

 In Singapore, almost 80% of the population lives in public housing.

 These projects have a bad reputation in the United States, but beautiful developments have opened in places like Montgomery County, Maryland, and larger cities like Atlanta are experimenting with using public projects to expand their housing stock.

 But social housing will rise or fail for the same reason that all building projects rise or fail.

 It doesn't matter whether the worker hammering in nails is a public employee or a private contractor.

 The government still needs to build those homes affordably and quickly.

 And that's not possible under the rules and strictures that liberals have designed within the governments they run.

 Heidi Marston led the Los Angeles Homeless Services Authority from late 2019 until April 2022 when she resigned in frustration.

 We had 38 unique funding sources coming in when I was there, Marston says.

 And each of those had annual or biannual audits of not just us, but the non-profits we were funding.

 Those audits were meant to show that the money was being spent exactly as intended.

 But that was part of the problem.

 Federal funding is probably more restrictive than any other, Marston continued.

 Every year we get money from the Department of Housing and Urban Development.

 The city often gives their share to us, but on top of the auditing and tracking that the federal money comes with, they add on their own conditions, like we can't use it for staffing.

 Just all this stuff that gets added on in the process.

 It's easy enough to imagine how these conditions emerge.

 The city wants to show that it is using its money to build houses rather than expand headcount.

 The Department of Housing and Urban Development has no end of priorities and is trying to satisfy the desires and demands of the members of Congress who control its funding.

 Tax credits are added to the code to address real and wrenching problems like the rise in homelessness among veterans.

 Grantmakers want to show donors that their money is being used well, and the only way to prove that is through audits.

 Everyone, everywhere, is afraid of being implicated in fraud or waste or having their funding cut or seeing the public turn on them.

 Each individual decision here is rational.

 The collective consequences are maddening.

 We hire skilled, dedicated people to do the public's work and then make it impossible for them to do that work well.

 We ask people to work on society's hardest problems, often making much less than they can make in the private sector, and then we rob them of the discretion and agility they need to solve those problems.

 And then we wonder why so many of them leave.

 There's tons of money that goes into homelessness, particularly in Los Angeles, Marston says.

 My budget was almost a billion dollars, but that money comes with such confined requirements that it's almost impossible to spend.

 If you give me a billion dollars and the ability to spend it, it would be a different story.

 It is hard to hear Marston's story without being reminded of Nicholas Bagley's argument that liberalism has become obsessed with procedure rather than with outcomes, that it seeks legitimacy through rule following rather than through the enactment of the public's will.

 Homelessness in Los Angeles is a catastrophe.

 The public is furious at the sluggish, ineffective response.

 And the lead agency on homelessness?

 It's spending its time filling out audit forms and making sure each dollar is spent in strict accordance with the specific demands of funders.

 The Problem with Everything Bay Goal Liberalism In his 2022 article, A Time for Triage, Michael Girard, the founder of Columbia Law School's Sabin Center for Climate Change Law, considered why it has proven so hard for liberals to build the kind of climate infrastructure they believe is needed.

 Rather than climate denial, the environmental community has trade-off denial.

 We don't recognize it is too late to preserve everything we consider precious and to linger in making decisions.

 Society has run out of time to save everything we want to save and to mull things over for years.

 One problem liberals are facing at every level where they govern is they often add too many goals to a single project.

 A government that tries to accomplish too much all at once often ends up accomplishing nothing at all.

 Conservatives are not immune from piling on procedure and stricture, but they often do so in a purposeful attempt to make government work poorly, and so failure and inefficiency become a perverse form of success.

 Call this everything bagel liberalism.

 The everything bagel is, of course, the best of the bagels.

 But that is because it adds just enough to the bagel and no more.

 It does not actually pile everything atop the bagel.

 In the Oscar-winning movie Everything Everywhere All at Once, there is an attempt to create a true everything bagel, and it becomes a black hole from which nothing can escape.

 The same is true for public projects.

 When the government adds the right number of goals, standards, and rules, much can be accomplished.

 When it adds too many, the project can collapse under its own weight, as has happened to high-speed rail in California.

 In 2022, President Biden signed the Chips and Science Act into law.

 The Biden administration believed semiconductors would be to the 21st century what oil was to the 20th century, and that America must be a leader again in manufacturing them.

 This is first and foremost and primarily a national security initiative, Gino Raimondo, the Secretary of Commerce, told me.

 We have national security goals you must achieve.

 Period.

 Full stop.

 No compromise.

 The semiconductor industry was invented in America.

 The silicon in Silicon Valley refers to the material that semiconductors are made from.

 But we long ago lost our dominant position in making what we invented.

 A report by the Semiconductor Industry Association says that the U.S. share of global semiconductor manufacturing capacity dropped from 37% in 1990 to 12% in 2020.

 Part of the reason is cost.

 The association estimates that building and operating a semiconductor manufacturing facility in the United States costs about 30% more over 10 years than it does in Taiwan, South Korea, or Singapore.

 In 2023, the Biden administration released its Notice of Funding Opportunity, known as a NOFO, for the $39 billion it intended to hand out to semiconductor manufacturers to locate new factories, which are called fabs, in the United States.

 Reading the NOFO was, for me, a strange experience.

 Here was the U.S.

 government trying to recapture an industry it had lost, in part because it had become cost prohibitive to manufacture semiconductors domestically.

 But the NOFO didn't seem laser focused on the cost problem.

 To be honest, it didn't seem laser focused on any problem.

 Page 12 encouraged a pre-application that includes an environmental questionnaire to assess the likely level of review under the National Environmental Policy Act.

 Page 20 mandated that applicants prepare an equity strategy in concert with their partners to create equitable workforce pathways for economically disadvantaged individuals in their region, which should include building new pipelines for workers, including specific efforts to attract economically disadvantaged individuals and promote diversity, equity, inclusion, and accessibility.

 Pages 21 and 22 asked for a plan to include women and other economically disadvantaged individuals in the construction industry, and encourage the use of project labor agreements, and sets out requirements for access to child care for facility and construction workers.

 Pages 24, 25, and 26 asked applicants to detail how they would include minority, veteran, and female-owned businesses, as well as small businesses in their supply chain.

 And then it offered seven bullet points detailing how this might be done, including dividing supply chain requirements into smaller tasks or quantities to expand access, and establishing delivery schedules for subcontractors that encourage participation by small, minority- owned, veteran-owned, and women- owned businesses.

 Then there are requirements for a climate and environmental responsibility plan, as well as community investments in areas like transit, affordable housing, and schools.

 Many of these are good goals, but are they good goals to include in this particular project?

 There is no discussion in the NOFO of trade-offs, nor is there any admission by the administration that anything they were asking for even represented a trade-off.

 Every one of the requirements, or they're not really requirements, nudges, are for criteria or factors we think relate directly to the effectiveness of the project, Raimondo told me.

 You want to build a new fab that will require between 7,000 and 9,000 workers.

 The unemployment rate in the building trades is basically zero.

 If you don't find a way to attract women to become builders and pipefitters and welders, you will not be successful.

 So you have to be thinking about childcare.

 But do Taiwanese semiconductor firms really know how to expand the role of women in the construction industry?

 How good will they be, really, at diversifying supply chains?

 These are all worthwhile goals, but there is some margin at which trying to do more means ultimately achieving less.

 It is impossible to read these bills and guidelines and not notice that the additions are rarely matched by deletions.

 Process is enthusiastically added, but seldom lifted.

 You can imagine a version of the CHIPS bill that lifted immigration rules to make it easier for skilled semiconductor workers to come to the U.S.

 That would have been the most direct way to address a shortage of skilled workers hindering the construction and operation of the fabs.

 You could have imagined rules exempting the semiconductor fabs from NEPA or giving them some kind of fast-track process.

 Ultimately, the Biden administration did exactly that.

 In late 2024, they signed a bill from Senators Mark Kelly and Ted Cruz exempting the fabs from environmental review after warning that environmental review could add years to the construction timeline.

 And to be clear, there is nothing unusual in the way the Biden administration approached the Chips and Science Act.

 The federal government often tries to make the subsidies it offers serve an array of goals and constituencies.

 California's high-speed rail was shaped by this dynamic, too.

 Many Californians were confused that construction had begun in the Central Valley, which was far less populated than the corridors near Los Angeles or San Francisco.

 Why start there?

 Well, there was a reason.

 When California applied for federal money under the terms of the American Recovery and Reinvestment Act, the Obama administration gave preference to bids that would improve air quality in poor communities.

 And so the $3 billion the federal government offered was not really to build high-speed rail.

 It was to begin building high-speed rail in ways that addressed air pollution in specific places.

 The Central Valley is poorer and more polluted than coastal California, so federal funding went there, and so did the initial construction.

 California is building high-speed rail in a place that makes it less likely that it will generate the ridership, political support, and financial backing to ever finish.

 The irony is that it's not just bad for the high-speed rail project.

 It's also bad for air pollution across the state because there is no high-speed rail.

 It should not be this hard to serve the public.

 Since 1960, federal government spending has risen more than five-fold.

 And yes, it's accounting for inflation.

 But the size of the federal civilian workforce has barely budged.

 It was slightly fewer than 2 million people in 1960, and it is slightly over 2 million people today.

 In countries like China and Singapore, civil service is held in high esteem, and the brightest graduates compete in nationwide tests to win government jobs.

 In the U.S., the word bureaucrat is tossed around as an epithet.

 Republicans have spent decades demonizing government, and they have largely won the argument.

 The dominant belief is that anything that can be outsourced or privatized should be.

 Government is bloated.

 The private sector is efficient.

 Democrats may not believe what Republicans believe about government, but they often act as if they do.

 In 2008, when California began building its high-speed rail system in earnest, the state's high-speed rail authority had just 10 workers.

 One of them was responsible for designing graphics for social media.

 The job was turned over to a vast assemblage of consultancies.

 It was one of these consultants, WSP, that estimated the system would cost only $33 billion and take only 12 years to build.

 But WSP wasn't alone.

 They were joined by Project Finance Advisory, by Cambridge Systematics, Arup, TY Lin, HNTB, PGH Wong Engineering, Harrison Associates, Arcadis, STV, Sennair, and Parsons Corporation.

 The outsourcing proved to be a foundational error in the project's execution.

 A miscalculation has resulted in the California high-speed rail authority being overly reliant on a network of high-cost consultants who have consistently underestimated the difficulty of the task, reported Ralph Vardabadian in the LA Times.

 California is one of the richest polities in the world.

 It was building one of the most ambitious rail projects in the world.

 But it did not hire the best rail designers and engineers to provide in-house expertise and manage the project.

 California was financing and overseeing a program it did not have the capacity to plan, manage, or even truly understand.

 There was an ideology at the authority some time ago that was like, let's keep this small and in-house and we're relying on consultants to build this, Brian Kelly, the high-speed rail authority CEO, told me.

 My philosophy when I got here was the state is the owner of this project and so we need to build state capacity.

 When I started, the authority was 70% consultants, 30% state.

 Now it's 55% state and 45% consultant.

 In the Bay Area, a different story was playing out.

 In 2012, Barrier Rapid Transit, the BART system, signed a contract with Alstom, a French rail car manufacturer, to deliver 775 cars for $2.58 billion.

 By 2023, though, something unusual had happened.

 The cars were coming in faster and cheaper than expected.

 The cost estimate was slashed by almost $400 million.

 One major source of savings, reported Trains.com, was BART's decision to have its own staff do more of the engineering work in-house.

 The project team has included engineers who have successfully completed new rail car projects at other agencies.

 Nor is this an isolated anecdote.

 Zachary Liscoe's research found that increasing employment in state departments of transportation by one employee per thousand residents reduced the cost per mile of highway construction by 26%.

 Government cannot do everything itself, but it needs enough know-how to oversee the projects it is doing.

 Jen Palka is a founder of Code for America, a civic tech group that tried to build a bridge between the technology industry and the government in a bid to upgrade government services.

 The work was hard, fruitful, important, frustrating.

 She went on to advise on digitizing government in the Obama White House.

 She is something of a godmother to a generation of idealistic technologists who tried, or are trying, to make government work the way it should work.

 Her memoir of this work, Recoding America, is a compendium of their stories.

 It is painful to read.

 In January 2020, Palka had stepped away from her role at Code for America.

 She needed some time away from the problems of digitizing government.

 But then came the pandemic and the lockdowns and the millions of people suddenly out of work.

 Those people were all, unexpectedly, now relying on unemployment insurance, which is managed by the states.

 And those systems were not prepared for anything like this level of demand.

 California's system, administered by the state's Employment Development Department, known as the EDD, fell into particular chaos with millions of people seeing their benefits wrongly delayed or denied.

 Palka was asked to co-lead a task force that would rescue it.

 Technologically, there was nothing particularly novel in the challenge.

 Unemployment insurance is fairly simple.

 People apply.

 They are accepted or rejected.

 Then checks are sent out.

 By the standards of the technology sector, this is a solved problem.

 Privately, some California officials told me they thought the EDD staff was just incompetent in technology and our team would find the problems easy to fix, Palka writes.

 But that wasn't how she and the task force saw it.

 Privately, we wondered if we could help at all.

 Palka's come to think of government technology and the regulations that control it as layers of sediment.

 As new problems emerge, new layers are added.

 But the older ones are rarely removed.

 Each successive layer is constrained by the limitations of the earlier technologies, she writes.

 The system is not so much updated as it is tacked onto.

 The challenge of updating government technology is a challenge of updating, harmonizing, or terminating the functions of these old systems.

 And all of it must be done while following procurement and contracting rules that no private technology company would ever impose on itself.

 At the EDD, the core technological layer was called the single-client database, which runs on an IBM mainframe from the 80s.

 Parts of it are written in a programming language called COBOL, which dates back to 1959.

 COBOL is almost never used today, and it is hard to find engineers who know how to program in it.

 Making matters worse, parts of the single-client database were designed to run on those old monochrome displays that showed green text on a black background.

 Because nobody makes those displays any longer, the staff used virtual emulators to access the system.

 So they would run software on new computers to make the new computers mimic the constraints of the old computers.

 Then came more layers.

 In 2002, the EDD contracted with Deloitte to bring their work online.

 Deloitte built one system to access the IBM mainframe through a web browser.

 It built another system to corral and manage applications flagged for manual identity verification.

 It built a third system that acts as the public-facing website for people to apply for benefits.

 All these systems had their own subsystems.

 And within those subsystems, applications could pool and get trapped in places no one was really looking.

 Palka and her team were told the number of backlogged applications was around 230,000.

 It took them seven weeks to organize the databases such that they could be precisely counted.

 The real number was 1.2 million.

 The EDD doesn't build or manage its own technology.

 Nor is the technology built or managed by a centralized team of software engineers in the state government.

 It is done by external firms chosen and managed through a labyrinthine procurement process.

 At the time of the meltdown, the EDD had been working on a modernization contract for 10 years that it was theoretically just weeks away from awarding.

 Listen to that again.

 They had not been working on modernizing their technology stack for 10 years.

 They had been working for 10 years on the massive contract they would award to outside firms to modernize and manage their technology stack.

 That contract was expected to take 11 years to execute.

 The sedimentary chaos of the EDD was not at all unusual.

 California spent 10 years and $500 million trying to bring its courts onto a common document management system before abandoning the effort.

 The State Department's Bureau of Consular Affairs has been trying to modernize and consolidate its visa and passport systems since 2009.

 The IRS began trying to replace one of its core systems, the Individual Master File, in 2000.

 The work is now projected to be completed in 2030.

 The public servants responsible for the interminably drawn-out modernization efforts are neither lazy, stupid, nor malicious, Palka writes.

 I've met hundreds of them, and they are overwhelmingly dedicated, conscientious, and often quite creative.

 IRS employees managed to send monthly child tax credit payments to nearly 40 million families and to mail out over $800 billion in stimulus checks during the pandemic, all while relying on systems that were never designed to change so quickly or handle such enormous volume.

 The problem is that the systems they're updating have become complex beyond our ability to imagine, as has the complexity of all the rules these public servants need to follow to do that updating.

 The worst of the EDD backlog was in the system that managed manual identity verification.

 But working in that system required years of experience, accreditation, and testing.

 When the EDD crisis had begun, elected officials demanded the EDD hire more people.

 So, they signed another contract with Deloitte to bring on another 5,000 workers.

 The governor touted the new hires.

 But it would have taken years to train those workers to face down the backlog the EDD was facing.

 And the questions and confusion of those new workers were taking up the time of the workers who actually could work on the backlog right now.

 Palka's team calculated that it was now taking two to five times as long to clear those files as it had before the pandemic.

 Letting go of thousands of new hires is cheaper and easier than training them.

 But that wasn't how the agency's leadership saw it.

 Hiring as fast as he possibly could had been the one consistent directive coming from everyone above them.

 The governor's office, the legislature, the federal department of labor, and every oversight body with jurisdiction over the EDD's operations, Palka was told.

 Telling all those overseers they were wrong was not in anyone's interest.

 And no one believed they would listen anyway.

 Firing workers during a crisis of EDD performance, that would look terrible.

 There was another option.

 The system was choking over manual verification.

 Manual verification was typically triggered when the information an applicant filled out on their form didn't precisely match some other piece of information the EDD had about them.

 Perhaps you write Jonathan on legal forms, but your employer pays you under John.

 Maybe you mistyped a digit in your social security number.

 It makes sense why this would lead to a manual check.

 But there was no real relationship between these tiny errors and fraud.

 Out of the 183,167 claims flagged in the previous quarter, only 804 were ultimately judged invalid.

 If anything, there was more fraud in the perfect-looking applications.

 Our world is awash in databases of stolen identities from breaches at credit monitoring services, retailers, and employers, and employers, and these stolen identities are freely traded on the dark web.

 Fraudulent applications using these sources will not get flagged.

 The data entered on the application will exactly match the sources the EDD checks against, because it is usually a copy of precisely that data, Polko writes.

 The EDD was implementing a new system of identity verification that would be quicker and more effective, but it needed to do something about the backlog that was building daily.

 The obvious answer was to loosen the rules that would lead to manual verification.

 But even though the process wasn't working, it was still the process.

 To follow it was safe.

 To evade it was risky.

 Fraud was really happening, and when its full extent was known, there was going to be a furor, and it would fall particularly heavily on anyone who loosened the anti-fraud rules.

 Even if the rules they loosened were failing to catch fraud and causing the huge backlogs that were crashing the system.

 What the EDD eventually did was simply stop taking applications altogether.

 For weeks, they shut down the portal for new applications.

 They reassigned the bulk of their staff to clearing the backlog and setting up the new identity verification program.

 Amid all this, Polko recalls, a member of the California Assembly introduced legislation requiring the EDD to make its applications and communications available in over a dozen languages.

 Most of those languages were already required by a 1973 state law.

 They were also required by multiple federal laws and rules.

 The EDD wasn't in compliance with all these older rules.

 It wasn't even serving English speakers effectively.

 It was not able to do what it was already required to do.

 Now it was being instructed to do more.

 What was needed was subtraction.

 What Polka and her team found, again and again, was that the rules and regulations that govern California's unemployment insurance system and that had been written into its code had just kept growing.

 That made the code more complex and harder to update.

 It made new hires harder to find and harder to train.

 It made backlogs harder to clear.

 Lawmakers often have good intentions, but they continually add policy layers with too little understanding of, and sometimes regard for, how what they add will interact with the layers that are already cluttering the delivery environment, Polka concluded.

 For government to do more, or even for it just to do what it is already doing, sometimes it first needs permission to do much less.

 A government that chooses is a government that works.

 On June 11, 2023, a tanker truck carrying 8,500 gallons of gasoline flipped over.

 The truck ignited underneath the I-95 bridge in Philadelphia, killing the driver and melting the steel beams undergirding it.

 The I-95 bridge, which carries 160,000 cars daily, collapsed.

 This wasn't just a crisis for a roadway.

 It was a crisis for a region.

 I-95 is one of the main transportation arteries on the East Coast.

 It is a crucial connector between New York and Washington.

 Officials, including Pennsylvania Governor Josh Shapiro, warned that rebuilding it would take months.

 And it would have taken months or longer under Pennsylvania's normal rules.

 We would hire a consultant to design it, Mike Carroll, the Pennsylvania Secretary of Transportation, told me.

 We need final design approved by the Federal Highway Administration.

 Then there'd be bidding from interested contractors.

 Then we'd process the bids.

 Then we'd issue a contract.

 That'd take about 12 to 24 months.

 But Shapiro signed a declaration of emergency that exempted the rebuilding process from the rules and requirements that slow so many public projects down.

 Speed was a priority here.

 There'd be no environmental impact statement.

 There'd be no lengthy bidding process.

 The procurement rules were shunted aside.

 When Carroll arrived at the disaster, C.

 Abenezio Contractors, a firm the state had worked with before, was already at the bridge on another job.

 They were chosen to oversee the demolition.

 Rob Buckley of the highway contractor Buckley & Company was also nearby, working on another project.

 His firm was pulled in too.

 The emergency declaration gave us the ability to engage contractors without bidding, Carroll said.

 Work commenced the moment the fire department released a scene, that same day.

 All the labor Pennsylvania used was union labor, and they pushed hard.

 Work went on 24 hours a day, seven days a week.

 A 24-hour live cam train on the site allowed the public to follow along.

 Shapiro took to giving updates on Twitter and TikTok.

 He turned the I-95 rebuild into a crucible for his governorship, and an object lesson in something few still believed.

 That government could build big things fast.

 That it could do so using union labor.

 That it could move at the speed of an emergency, where it had been according to its own rules.

 The common denominator with all these decisions was, let's get this thing done as fast as possible, Carroll said.

 He recalled a moment he came across a bunch of Abenezio workers using a screwdriver to disassemble a highway sign.

 He asked what they were doing, and they told him they were saving the sign for the Department of Transportation in case they wanted to reuse it.

 I said, turn the machine on and knock the goddamn thing over, he said with a chuckle.

 On another night, Carroll saw rain forecasted over the next few days.

 He told the team to pave anyway, in contravention of the Department of Transportation's rules, because the rain was light that night and could grow heavier soon.

 If they waited, they might be waiting for days.

 The emergency declaration was a game-changer, Carroll says.

 I took calculated risks that I'd have not taken in a normal project.

 It could have gone badly, but it didn't.

 It's worth taking seriously what Carroll says there.

 These were risks.

 There are reasons these rules are in place.

 No-bid contracts can enable corruption as well as speed.

 There are reasons not to put down asphalt when it's raining.

 But in turning these questions from choices into rules, we've taken discretion and judgment away from people like Carroll.

 We prefer that projects go badly by the book.

 We minimize some risks, but make delay and high costs routine.

 The emergency declaration allowed Shapiro to make choices.

 He chose to use union labor, but to gore a lot of other interests and processes.

 I-95 reopened in just 12 days, not the months initially forecasted.

 Shapiro did one heck of a job, President Biden said.

 His popularity swelled and he began to be mentioned as a possible future presidential candidate.

 Turns out people like it when their government gets things done.

 The Washington Post asked Shapiro to write an op-ed reflecting on lessons he'd learned.

 The first lesson, he said, was empower strong leadership.

 The key to the rebuild was that the people in charge of the rebuild could act.

 Managers of every component of the project were empowered to be decisive, take ownership, and make a call when necessary, not defer and delay to the often circular bureaucracy, Shapiro wrote.

 The process Shapiro used would typically be illegal.

 Yet, National Democrats and Pennsylvania voters alike loved it.

 What then does that say about the typical process?

 In his paper, State Capacity, What Is It?, How We Lost It?, and How to Get It Back?, Brink-Linsey puts it well.

 What is needed most is a change in ideas.

 Namely, a reversal of those intellectual trends in the past 50 years or so that have brought us to the current past.

 On the right, this means abandoning the knee-jerk anti-statism of recent decades, embracing the legitimacy of a large, complex welfare and regulatory state, and recognizing the vital role played by the nation's public servants, not just the police and military.

 On the left, it means reconsidering the decentralized, legalistic model of governance that has guided progressive-led state expansion since the 1960s, reducing the veto power that activist groups exercise in the courts, and shifting the focus of policy design from ensuring that power is subject to progressive checks to ensuring that power can actually be exercised effectively.

 When you look across recent decades, what you see is that liberals have chosen to trust elected politicians and government workers less, and to trust regulatory and judicial processes more in ensuring the government delivers.

 Maybe that made sense in a past era, but given the problems we face now, it's a mistake.

 Whether government is bigger or smaller is a wrong question.

 What it needs to be is better.

 It needs to justify itself not through the rules it follows, but through the outcomes it actually delivers.

 Chapter 4. Invent Catalin Carrico was born in a small village in the northern Great Plain of Hungary.

 Her home, built of clay and straw, had no running water.

 It drew heat from a sheet metal stove that burned leftover sawdust from a local toy store.

 Her first science lesson as a child did not come from a classroom, but rather from the small garden next to the house.

 One year, an infestation of Leptinotarsa disemlineata, or what Americans call Colorado potato beetle, blighted her family's crop of potatoes.

 On her hands and knees, she plucked the black and white bugs, one by one, from the tubers and scraped off the smear of their pink eggs to preserve the crop.

 The work was tedious and sometimes gross, she wrote years later.

 No fun for a kid, perhaps, but fitting practice for a career in medicine.

 As a young woman, Carrico became a scientist at the Biological Research Center in Szeged, near Hungary's southern border.

 When the center lost its state funding, she sold her car for 900 British pounds and sewed the cash into her daughter's teddy bear to elude Hungarian currency control laws.

 She moved to Pennsylvania with her family.

 For the first few years in America, Carrico was an academic tumbleweed.

 She bounced around several university labs before she was hired by the University of Pennsylvania.

 When Carrico arrived at Penn, a great gusher of money was flowing to DNA, as scientists hoped to directly edit the instruction manual of the human body.

 Carrico developed a different interest, messenger ribonucleic acid, or mRNA.

 If DNA was the king of the biotech landscape, mRNA was a frail courier, a single-stranded molecule that ferried information from the nucleus to the part of the cell that made new proteins.

 Upon accomplishing this, mRNA disintegrated.

 DNA had many technical advantages over mRNA, including its centrality to the genome.

 But in Carrico's mind, mRNA's apparent weakness, its structural frailty, was a strength.

 With human-edited mRNA, she thought, scientists could theoretically turn human cells into factories for producing any protein under the sun, to repair organs, or to fight disease, and then, poof, the therapy would disappear from the body without a trace.

 People didn't understand why I was so interested in RNA, Carrico said.

 They didn't see any potential.

 Nobody saw it as suitable for making medicine.

 At the University of Pennsylvania, Carrico submitted dozens of grants, including to the National Institutes of Health, the NIH, the largest and most important scientific body in the U.S., and, by extension, in the world.

 For two years, she submitted a new grant application almost every month.

 The rejections were relentless.

 Every night I was working, grant, grant, grant, she said, and it came back always, no, no, no.

 Sometimes the NIH told her that her work was too risky.

 Sometimes they said she didn't have enough data to prove that her experiments would work.

 Other times, her grants scored so poorly that she received no feedback at all.

 Throughout these years of failure and disappointment, Carrico stayed motivated.

 She loved science, the painstaking discovery of the new, the long and winding road out of ignorance.

 On her wall hung a Leonardo da Vinci quote that offered inspiration during the dark years, when the rejections piled one on top of another.

 Experiments never err, only your expectations do.

 I was a scientist through and through, she writes in her memoir.

 I wanted more than anything else to understand how the world works.

 But after five years of relentless rejection, Carrico hadn't brought in any federal grants, which are the lifeblood of American science.

 The NIH and other funding agencies rejected her work so many times she lost count.

 Penn demoted her to senior research investigator.

 The position was so feckless, it seemed practically made up.

 She didn't know anybody at the university with the same title.

 By the mid-1990s, Catalan Carrico's future as a scientist and the future of mRNA science itself had hit a dead end.

 Rejected, ignored, and unfunded, her work seemed destined to wither away in that great invisible graveyard of ideas that die a silent death, thrilling their creator, and then petering out into oblivion.

 In 2020, decades after Carrico's demotion, a novel coronavirus pandemic was rampaging around the world.

 With frantic desperation, countries experimented with a variety of policies to contain it.

 Some ideas worked in some places.

 Few ideas worked everywhere.

 Italy implemented a strict national lockdown, while Sweden allowed many businesses to stay open.

 In the U.S., the response was scattershot.

 Pennsylvania state rules permitted indoor dining in the summer, while in Philadelphia, a November city ordinance made it illegal for neighbors to sip beer on a porch.

 A year into the pandemic, researchers were still debating the most elemental questions, such as, do masking rules even work?

 In 2021, a group of scientists from Yale, Stanford, and other august institutions published the final results of a randomized study of masking, which included data from roughly 350,000 people in 600 villages in Bangladesh.

 The researchers concluded that villages randomized to receive surgical masks saw less symptomatic infection.

 But two years later, the co-author of a large analysis of global masking research concluded that there is just no evidence that masks make any difference, full stop.

 To bring the pandemic to heel, the world needed something more universally applicable than a rule or a law or a border control policy.

 We needed a global fix, a medicine that would achieve immunity protection at scale.

 What happened next is a kind of miracle.

 Before 2020, no vaccine in American history had ever gone from the lab to the public in less than three years.

 The COVID vaccines achieved this feat in about 10 months.

 In December, the U.S. Food and Drug Administration, the FDA, issued an emergency authorization for two COVID therapies based on mRNA technology, the very same idea that the science establishment rejected when Catalan Carrico had suggested it decades earlier.

 The first vaccine came from Pfizer, working with the German firm BioNTech.

 The second came from Moderna, a biotech startup based in the U.S.

 Unlike most behavioral interventions, the vaccines were immediately and obviously effective at reducing mortality for adults in every age cohort and in every country.

 Every study testified to their effectiveness at reducing severe illness, especially for the elderly.

 In the U.S., one year after the vaccines were first granted authorization, unvaccinated seniors were dying at more than 10 times the rate of vaccinated seniors.

 In Britain, an analysis by Imperial College London estimated that between 10 million and 20 million lives were saved worldwide by the shots in the first year of the vaccination program.

 In our first chapters, we recounted the many ways that America has gotten in the way of building what we need to flourish in the 21st century, from homes to clean energy.

 But the pandemic was a different kind of challenge.

 Here was a problem we couldn't regulate or subsidize or merely build our way out of.

 No number of masks for shoppers or plastic dividers in restaurants could do what the vaccines did.

 The end of the health emergency required the summoning into existence of something fully new.

 To defeat COVID, it wasn't possible to build our way out of the problem.

 We had to invent our way out.

 The Politics of Invention Invention, the act of solving problems by bringing new products, systems, and ideas into existence, is the basis of human progress.

 Consider a thought experiment.

 The average lifespan of an American today is about 80 years.

 The world of 2025 is therefore just three modern lifetimes away from the world of 1785.

 Three 80-year-olds holding hands across time.

 To travel back three lifetimes to the 1780s is to enter a world without a car, toilet paper, or large-scale production of soap.

 In the realm of food, it is a world before can openers, pasteurization, or modern refrigeration.

 In medicine, it is a world without antibiotics, anesthesia, or a single vaccine.

 What principally distinguishes the past from the present is not biology, nor psychology, but rather technology.

 If the world has changed, it's because we have changed the world.

 Modern liberal politics is made possible by invention.

 Almost every product or service that liberals seek to make universal today depends on technology that did not exist three lifetimes ago, or, in some cases, half a lifetime ago.

 Medicare and Medicaid guarantee the elderly and poor access to modern hospitals, where many essential technologies such as plastic IV bags, MRI and CT scan machines, and pulse oximeters are inventions of the last 60 years.

 It is tempting to say, with these essentials already in existence, that it's time for society to focus at last on the fair distribution of existing resources rather than the creation of new ideas.

 But this would be worse than a failure of imagination.

 It would be a kind of generational theft.

 When we claim the world cannot improve, we are stealing from the future something invaluable, which is the possibility of progress.

 Without that possibility, progressive politics is dead.

 Politics itself becomes a mere smash-and-grab war over scarce goods, where one man's win implies another man's loss.

 The world is filled with problems we cannot solve without more invention.

 In the fight against climate change, the clean energy revolution will require building out the renewable energy that we've already developed.

 But decarbonization will also require technology that doesn't exist yet at scale.

 Clean jet fuel, less carbon-intensive ways to manufacture cement, and machines to remove millions of tons of carbon from the atmosphere.

 In healthcare, the last few centuries of invention have turned a death planet, where disease ran rampant, and, before 1850, where one in two babies perished before their 16th birthday, into a world where people can look forward to generation-over-generation increases in life expectancy.

 But there are still so many mysteries that require fresh breakthroughs.

 We've made disappointingly little progress with many cancers.

 Complex diseases, like Alzheimer's and schizophrenia, elude treatment or even basic comprehension.

 The cellular process of aging is still a deep mystery.

 We don't have effective vaccines for adult tuberculosis or hepatitis C or vaccine platforms that we can immediately scale up in the event of a new pandemic.

 Decades from now, our children may gawk in horror that people with chronic pain or lingering illness in the 21st century couldn't take a simple all-purpose saliva or blood test to answer the basic question, why do I feel sick?

 If disease is a universe of mysteries, we have scarcely explored one minor solar system of its cosmos.

 Inventions that might seem outlandish today may soon feel essential to our lives.

 Streets filled with electric self-driving cars that give us mobility without emissions and free us from the vast number of deaths caused by faulty human reflexes or judgment.

 Gigantic desalination facilities that transform our oceans into drinkable tap water.

 An economy with robots that build our houses and machines that take on our most dangerous and soul-draining work.

 Wearable devices to scan our bodies for disease.

 Vaccines that we can rub on our skin rather than inject at the end of a needle.

 As unrealistic or even ludicrous as some of these ideas might seem, they are not much more ludicrous than a rejected, ignored, and unfunded mRNA theory that came out of nowhere to save millions of lives in a pandemic.

 To make these things possible and useful in our lifetime requires a political movement that takes invention more seriously.

 So where is that movement?

 Invention rarely plays a central role in American politics.

 In healthcare, for example, Democrats have spent decades fighting for universal insurance, while Republicans have consistently fought its expansion.

 But while the dominant fight in Washington is typically about how we buy healthcare, we rarely talk about the healthcare that exists to be bought.

 After all, in the future, progressives don't just want everybody to have an insurance card.

 They want that card to provide access to a world of treatments that liberates patients from unnecessary disease and debilitating pain.

 Technology expands the value of universalist policies.

 If progressives underrate the centrality of invention in their politics, conservatives often underrate the necessity of government policy in invention.

 The government has outlawed technology, the investor and entrepreneur Peter Thiel said in a debate with the Google CEO Eric Schmidt in 2014, echoing a popular view among techno-optimists and libertarians that government laws mostly block innovation.

 But many of Silicon Valley's most important achievements have relied on government largesse.

 Elon Musk is now a vociferous critic of progressive policy, but he has also been a beneficiary of it.

 In 2010, when Tesla needed cash to launch its first family-friendly sedan, the Model S, the company received a $465 million loan from the Obama administration Department of Energy.

 His rocket-launching company, SpaceX, has received billions of dollars from NASA under Democratic and Republican administrations.

 Musk has become a lightning rod in debates over whether technological progress comes from public policy or private ingenuity.

 But he is a walking advertisement for what public will and private genius can unlock when they work together.

 Beyond merely regulating technology, the state is often a key actor in its creation.

 An American who microwaves food for breakfast before using a smartphone to order a car to take them to the airport is engaging with a sequence of technologies and systems, the microwave, the smartphone, the highway, the modern jetliner, in which government policies played a starring role in their invention or deployment.

 Federal science spending is so fundamental to the overall economy that a 2023 study found that government-funded research and development have been responsible for 25% of productivity growth in the U.S.

 since the end of World War II.

 There is widespread agreement that scientific research and invention are the key driver of economic growth and improvements in human well-being, the Dartmouth economist Heidi Williams said.

 But I think researchers do a poor job of communicating its importance to lawmakers, and lawmakers do a poor job of making science policy a major focus.

 The pandemic proved the necessity of invention yet again.

 The mRNA COVID vaccines saved millions of lives and spared the U.S.

 more than $1 trillion in medical costs.

 But they might have never existed if it weren't for Carrico's force of will and the cosmic luck of an extremely well-placed Xerox machine.

 A shot to save the world.

 One day in the fall of 1997, after her demotion at the University of Pennsylvania, Catalin Carrico left her small office in the building for neurosurgery to make photocopies of several articles from science journals.

 The nearest large Xerox machine was in a different hall, inside Robert Wood Johnson Pavilion, which housed the biomedical library.

 Waiting to use the photocopier, she struck up a conversation with an immunologist named Drew Weissman.

 Carrico told him about her interest in mRNA as a therapy.

 Weissman told her he was working on an elusive HIV vaccine.

 Their brief interaction sparked an idea.

 What if synthetic mRNA, with its power to teach the body to make specific proteins, could trigger an immune response that fought off a virus like HIV?

 When they teamed up, their partnership felt like kismet.

 Each of us had exactly the knowledge and skills that the other needed, Carrico wrote.

 I was an RNA scientist who didn't know much about immunology.

 He was an immunologist without RNA experience.

 But progress was painfully slow, and the NIH rejected practically all of their grant applications.

 People were not interested in mRNA, Weissman said.

 The people who reviewed the grant said, mRNA will not be a good therapeutic, so don't bother.

 They cobbled together funds from other projects.

 Weissman had federal grant money coming in for his research on HIV, which he pulled over into the mRNA project.

 Meanwhile, Carrico made do with bits of funding that had been awarded to her Penn colleagues.

 For years, the science wasn't going much better than the fundraising.

 In their first experiments, mRNA injections in mice caused terrible inflammation.

 After several years of trial and error, they finally broke through in the early 2000s by creating an mRNA therapy that could enter the cell without sending the immune system into a frenzy.

 I was absolutely elated, Carrico wrote.

 But the scientific community largely ignored their discovery.

 When they submitted their findings to the leading science journal, Nature, the editors rejected the paper entirely.

 The specialty journal, Immunity, agreed to publish it in 2005 only after extensive edits.

 The night before the paper came out, Weissman told Carrico that, starting tomorrow, your phone is going to ring off the hook.

 He was wrong.

 In the years following publication, Carrico received only two speaking invitations.

 Our breakthrough had apparently failed to break through, she wrote.

 Rather than make Carrico a science rock star, the tepid response to her mRNA discovery made her a target for firing.

 In 2013, when it was clear that she wasn't bringing in enough outside funds to justify a tenured faculty position, she left academia for good.

 I was kicked out, forced to retire, she said.

 If mRNA was failing to impress the scientific establishment, its reception in the private sector was a different story.

 In the U.S., Carrico and Weissman's work caught the attention of a brash group of postdoctoral researchers, professors, and venture capitalists.

 They had started a company whose name smushed the words modified and RNA, Moderna.

 In Germany, Ugr Sahin and Oslem Turici, a married couple with backgrounds in immunotherapy research, also saw huge potential in Carrico's and Weissman's work.

 They founded several companies, including one to research mRNA-based treatments for cancer, BioNTech.

 In 2013, they made Carrico a vice president.

 There was a lot of skepticism in the industry when we started, because this was a new technology with no approved products, Turici said.

 Drug development is highly regulated, so people don't like to deviate from paths with which they have experience.

 BioNTech and Moderna pressed on for years without approved products, thanks to the support of investors and philanthropy groups, such as the Bill and Melinda Gates Foundation.

 By the time the coronavirus outbreak shut down the city of Wuhan in China, Moderna and BioNTech had spent years fine-tuning their technology, which explains how they solved the mystery of SARS-CoV-2 with such speed.

 It turned out that mRNA offered the perfect key to pick the lock of the virus that caused COVID.

 Coronaviruses are named after a crown, or corona, of proteins that surrounds the virus particle, like spikes around a ball.

 Synthetic mRNA therapies send detailed instructions to a person's cells to make duplicates of the distinctive spike protein, which the immune system trains itself to attack.

 Later, if the same person confronts the full-blown virus, the body recognizes the spike protein again and blitzes it with the precision of a well-trained military, reducing the risk of severe illness.

 With COVID, the science of mRNA proved its value almost immediately.

 On January 11, 2020, Chinese researchers published the genetic sequence of the virus.

 Within 48 hours, Moderna's mRNA vaccine recipe was finalized.

 By late February, batches of the vaccine had been shipped to Bethesda, Maryland for clinical trials.

 By December, it was approved, the fastest vaccine development in history.

 Today, several billion mRNA vaccines have been shipped.

 In 2023, Catalan Carrico and Drew Weissman, who struggled for years to get a dollar of funding from the NIH, won the Nobel Prize in Physiology or Medicine for a technology that saved millions of lives.

 The mRNA vaccines were a triumph for Carrico and Weissman, for Pfizer and Moderna, for all of us.

 But they are also clearly a cautionary tale for American science.

 Carrico said she never got a dime from the U.S. government to directly support her mRNA projects in her years at Penn.

 Even now, I am working on therapies that were part of grant applications that were rejected 20 years ago, she said.

 Carrico is not the only scientist to hear no, no, no from funding institutions like the NIH on her path to international renown.

 When he won the Nobel Prize in Physiology or Medicine in 2013, James Rothman told an interviewer that he was grateful to have started work in the 1970s, back when the federal government was willing to take much bigger risks on young scientists.

 I had five years of failure, really, before I had the first initial sign of success, Rothman said.

 I'd like to think that kind of support existed today, but I think there's less of it.

 At the highest levels, American science has become biased against the very thing that drives its progress, the art of taking bold risks.

 We have a problem of creaky institutions getting in the way of inventing, the MIT economist Pierre Azoulay said.

 It's not so different from housing or clean energy.

 American science has accumulated a set of processes and norms that favor those who know how to play the system rather than those who have the most interesting ideas.

 In short, America and American science has a Carrico problem.

 The Carrico Problem and the Great Science Slowdown By some measures, the business of academia in America has never been bigger.

 In the 1930s, there were just 80,000 professors across all U.S. universities.

 Today, there are more than 1.5 million.

 The search for knowledge has never been easier.

 We have more information about our genes, our proteins, and our cells, along with tools to make it easier to search, copy, paste, and organize the data and to run statistical analyses.

 It is easier than ever to collaborate across large distances on the Internet.

 Surely, it seems like if we value science, our society has done everything right.

 And, to be sure, the landscape of inventions sparkles with bright spots.

 The last few years have witnessed the remarkable emergence of new gene therapies, drugs to thwart diabetes and obesity, and a suite of artificial intelligence tools, such as ChatGPT from OpenAI and DeepMind from Alphabet, the parent company of Google, that can perform a wide range of complex tasks from writing essays in code to predicting the shape of proteins.

 But, mysteriously, progress in many fields seems to be slowing down.

 In April 2020, just as the world was convulsing from a pandemic, a group of economists from Stanford and MIT published a study with the irresistible title, Are Ideas Getting Harder to Find?

 Their answer was an unambiguous yes.

 From medicine to agriculture, basic science is becoming less productive.

 Consider what's happened in medicine in the 21st century, said Nicholas Bloom, a Stanford economist and co-author of the paper.

 In heart disease research, the number of journal publications has increased and the number of clinical trials has soared, but the quantity of lives saved or extended has slowed significantly.

 As a result, it's taking more and more research to eke out the same extra year of life.

 One area where we should expect much more from scientific progress is in the field of cancer research.

 In 1971, President Richard Nixon signed the National Cancer Act, kicking off what became known as the War on Cancer.

 Three decades later, Andrew von Eschenbach, the director of the National Cancer Institute, pledged in 2003 to eliminate suffering and death due to cancer by 2015.

 Six years later, President Obama pledged to find a cure for cancer in our time.

 Two presidents later, President Biden reinitiated a cancer moonshot to end cancer as we know it.

 But our progress on cancer research has been uneven.

 While some cancers, such as childhood leukemia, have become much less fatal, the prognosis for others has proven stubbornly resistant to improvement.

 The death rates of some cancers, such as uterine and pancreatic, are still rising despite significant investment.

 Although there are many drugs approved to treat very sick cancer patients, there are shockingly few drugs approved to prevent cancer in the first place.

 especially when you consider the scale of spending, cancer research has been a huge disappointment overall, said Eric Topol, director of the Scripps Research Translational Institute.

 There are all these drugs for treatment that mostly just extend people's lives a few months.

 How can we possibly account for this puzzle?

 More scientists, more money, more years of education, more knowledge, more technology, and more papers, but in many fields, slower progress.

 In 2008, the Northwestern economist Benjamin Jones proposed an elegant theory to explain the slowdown across science.

 It starts with two simple observations.

 First, nobody is born an expert.

 Second, total expertise in any given domain of knowledge, say physics or chemistry, grows over time as we unravel the mysteries of the natural world.

 As we build expertise in a field like medicine, it's a bit like plucking the lowest hanging fruit from a tree.

 The more low-hanging fruit we pick, the higher in the tree we have to climb to pick fruit, and the more resources we need to do it.

 Jones called this escalating challenge the burden of knowledge.

 The burden of knowledge isn't just plausible.

 It's practically obvious.

 To take one simple example, the first element discovered and recorded by a European scientist was phosphorus.

 The story goes that in the mid-1600s, a German alchemist did a little home experiment, the crux of which involved boiling piss, evaporating the urine, and heating the remains.

 Out came phosphorus.

 Almost any high school chemistry student could replicate the experiment today.

 Please don't.

 But they shouldn't expect it to break open any new scientific frontier.

 The latest elemental discoveries have been a bit more complicated.

 Element 117, Tennessean, was discovered only when a Tennessee laboratory created an isotope of the rare metal berkleum and sent 22 milligrams of the radioactive material to Russia, where a separate group of scientists at a nuclear research facility hit it with a beam of 6 trillion calcium ions per second for 150 days and used specialized equipment to detect the faintest whispers of Tennessean flickering into existence for less than a second.

 While it's hard to say how the next synthetic element will be detected, it is safe to assume that it will not be discovered in a pot of hot urine.

 If that example seems a little goofy, try this one.

 The godfather of genetics was Gregor Mendel.

 A Czech friar in the mid-1800s, Mendel grew peas of varying shape, color, and flower position in his monastery's garden.

 He bred the pea plants by cross-pollination over generations and noticed that peas seemed to pass down their traits, producing predictable crossbreeds.

 Although his 1866 analysis was published to little fanfare, a group of botanists later rediscovered Mendel's work, independently confirmed the principles of inheritance, and cracked open the field of genetics.

 160 years later, genetics is a mature scientific domain whose breakthroughs are a bit more complicated than careful gardening.

 For example, we haven't yet figured out how a complex disease like schizophrenia arises from the interplay between multiple genes and the environment.

 When an organization like the Broad Institute in Cambridge, Massachusetts, wanted to investigate the genetic building blocks of schizophrenia, scientists sequence the genomes of thousands of people around the world looking for commonalities among those who share the disease.

 Such research, called genome-wide association studies, takes hundreds of geneticists, neuroscientists, computer programmers, assistants, and more working together in organized teams over many years to get us one small step closer to solving the riddle of schizophrenia.

 It is absurd to imagine that one person, even as brilliant as Gregor Mendel, could do all this alone in his backyard.

 That is Joan's point in a nutshell.

 Scientific progress is a blessing that comes with a curse.

 The unsolved problems are typically harder than the solved ones.

 If keeping up the pace of scientific progress demands more resources, it points to a clear solution.

 Recruit more scientists and spend more money.

 These aren't bad ideas.

 They might be great ones.

 As a share of the economy, government-funded R&D has declined in the last 60 years, the economist Heidi Williams said.

 If scientific spending is fundamental to economic growth, this suggests that the U.S.

 has hugely underinvested in basic research.

 Meanwhile, recruiting brilliant immigrants to the U.S.

 has for decades been the secret ingredient to America's success in science and technology, according to Jeremy Neufeld, a fellow at the Institute for Progress.

 Some of the greatest achievements in U.S. history, including the Manhattan Project and the Apollo program, are impossible to imagine without the contribution of people who were born abroad, he said.

 Despite making up only about 14% of the U.S. population, immigrants accounted for 23% of U.S. patents from 1990 to 2016, 38% of U.S. Nobel Prizes in chemistry, medicine, and physics from 2000 to 2023, and more than half of the billion-dollar U.S. startups in the last 20 years.

 Today, however, this talent pipeline is at risk.

 As immigration politics has been subsumed by debates about border control policies, the U.S. has quietly made it harder for the typical foreign-born student to stay.

 America has allowed wait times for green cards to lengthen while the number of applicants stuck in immigration backlogs has gotten so large that some talented immigrants have stopped waiting and moved away.

 Since 2007, the share of international students on academic visas applying to stay and work in the U.S.

 has declined by more than a third.

 Neufeld singled out one policy for criticism, the H-1B visa, which is America's primary visa for high-skilled foreign workers.

 In 1990, the U.S. capped the number of annual H-1B visas at 65,000.

 The figure was eventually raised to 85,000 in the early 2000s.

 But in 20 years of immigration fights, it still has an increase to match the growth of the population or the urgent need for scientists, engineers, and researchers.

 This artificial scarcity means many promising foreign students and researchers are forced to leave the U.S.

 after completing their studies, taking their skills and innovative potential elsewhere.

 If Catalan Carrico, who moved to the U.S.

 in 1985, had tried to immigrate just a few years later, the creation of the H-1B visa cap might have prevented her move and perhaps catastrophically delayed the emergence of mRNA research.

 Strengthening and expanding America's high-skilled immigration program would be a good way to pull the Caracos of the future into the U.S., where they could cook up the next life-saving breakthrough.

 Doubling the H-1B visa cap, especially while raising the average wage for visa holders, could be transformative for American science and technology, Neufeld said.

 We'd have more and more meaningful inventions, which would increase productivity and make the U.S.

 as a whole richer.

 More money and more scientists might help the U.S.

 fight the knowledge burden, but it doesn't solve what we've called the Carrico problem.

 In fact, the same way that throwing housing vouchers into a market with insufficient supply raises home prices, throwing more money into a flawed science system might exacerbate its problems.

 Let's define the Carrico problem like this.

 American science funding has become biased against young scientists and risky ideas.

 What is most obvious is that American science is getting older.

 In the early 1900s, some of the most famous scientists, Einstein, Heisenberg, Schrodinger, did their breakthrough work in their 20s and 30s.

 Indeed, their youth may have been critical to their paradigm-busting genius.

 But these days, the 20-something scientist is an endangered species.

 The share of NIH-funded scientists who are 35 years old or younger declined from 22% in 1980 to less than 2% by the 2010s.

 American science also seems to produce far too many papers that don't create new knowledge while overlooking researchers with promising new ideas.

 A 2023 study titled Papers and Patents Are Becoming Less Disruptive Over Time found that any given paper today is much less likely to become influential than a paper from the same field decades ago.

 This could be because too many papers are essentially worthless.

 Or, it could mean that scientists feel pressured to herd around the same few safe ideas that will keep them in good standing with their peers.

 When you look at the diminishing returns in medicine, you can say, well, maybe all the easy drugs have been discovered, said James Evans, a sociologist at the University of Chicago.

 But the more compelling possibility, he said, is that the very organization of modern science is leading us astray.

 In Evans' interpretation, the low-hanging fruit hasn't been plucked.

 The problem is that too many scientists are all looking at the same few trees.

 I think there are all kinds of weird trees in the forest that we haven't found because everybody's looking in the same place and we're not making enough high-risk, high-reward bets, Evans said.

 That has nothing to do with the knowledge burden.

 That's all about the organization of American science.

 It's about our policies, our laws, and our rules.

 The idea that the NIH has become deeply biased against risky and novel research and too fixated on funding only those projects that are practically guaranteed to succeed is so widespread that it has become The Biggest Clich√© in Science, said Azoulay, the MIT economist.

 In 2012, Gregory Petsko, a biochemist and member of the National Academy of Sciences, published a satirical essay in which King Ferdinand and Queen Isabella of Spain mock Christopher Columbus for not collecting preliminary data about the voyage across the Atlantic.

 When King Ferdinand suggests that the explorer try a shorter trip, say, to Portugal, Columbus exclaims, Everybody knows that Portugal is immediately west of Spain.

 What will you learn from that?

 Not much, if anything, Queen Isabella responds, but it can't fail now, can it?

 Besides, you've sailed to Portugal before, so the study section will know you can do it.

 This satire didn't appear in some personal blog.

 It ran in Genome Biology, one of the most prestigious journals in the field of genetics.

 For all its flaws, the NIH has been central to some of the most important scientific discoveries in history.

 In the 1960s, when scientists developed the first effective treatment of childhood leukemia, they used NIH funding.

 In the 1980s, when researchers identified the first cancer-causing gene and developed the first HIV blood test, they did it with NIH funding.

 In the 2000s, when the Human Genome Project cracked open a new frontier in genetic research, the NIH was its leading bank roller.

 From the human brain to the immune system to the genetic basis of disease, almost every bountiful field of bioscience has been irrigated by the National Institutes of Health.

 To understand how a system designed to encourage risk-taking in science ironically became captured by risk aversion, we have to tell the story of the birth of the American innovation system and the creation of the modern NIH itself.

 The Growth of the American Innovation System Before the 20th century, science and invention had largely been a job for solo entrepreneurs.

 The cotton gin and the telegraph, icons of 18th and 19th century ingenuity, were made by individual tinkerers who, through trial and error, cobbled their way toward a product that, initially, barely worked.

 In the late 1800s and early 1900s, Thomas Edison proved a new model, the Corporate Research Lab.

 Inside the two-story shed he built in Menlo Park, New Jersey, Edison oversaw a team of muckers, his term for professional experimenters, who fleshed out his sketches and helped him invent, among other things, the incandescent light bulb and the first instruments for recording sound and video.

 Edison's team-based success became too obvious to ignore and other companies copied him with magical results.

 In the 1930s, DuPont's experimental station developed synthetic rubber, nylon, and Kevlar.

 Meanwhile, the university scientists who worked outside these labs mostly relied on funding from private philanthropies, such as the Rockefeller Foundation.

 In all these triumphs, one actor was notably absent, the federal government.

 Washington played almost no role in supporting innovation before the 1900s, outside of a few programs that subsidized research in farming, agriculture, and defense.

 But just as World War II reshaped borders and rules around the world, so too did it reshape the U.S. innovation system.

 In June 1940, as the German army invaded and occupied Paris, the eminent engineer Vannevar Bush delivered grave news to President Franklin D. Roosevelt in an urgent White House meeting.

 America was technologically unprepared to take on the Axis powers.

 Wiry thin with a narrow face and glasses, Bush dominated several disciplines.

 A pioneer in early computer research, he published some of the first predictions of the Internet, was the dean of the MIT School of Engineering, and was the chairman of the National Advisory Committee for Aeronautics, which was eventually folded into NASA.

 Bush urged Roosevelt to create a new agency to direct American ingenuity toward the war effort, presenting the president with a brief one-page proposal for a new organization, the likes of which had never existed in U.S. history, a committee to coordinate all the science and technological work that might help defeat the Nazis, which would be funded by the White House.

 The memo was persuasive.

 Roosevelt approved the creation of an agency that grew to become the Office of Scientific Research and Development, OSRD, a multibillion-dollar hydra of wartime science and technology operations that supported the work of thousands of scientists and engineers.

 OSRD's early work developing an atomic weapon eventually became the Manhattan Project, overseen by J. Robert Oppenheimer.

 With OSRD funding and guidance, American scientists invented radar, invested in malaria treatments, developed an early influenza vaccine, and built the foundations for early computing.

 The country emerged from World War II with a new way of thinking about science and innovation.

 This is a job for the government.

 In 1945, Bush drew on the lessons of the war to draft a blockbuster report on the future of American innovation titled Science, The Endless Frontier.

 The most important idea that emerged from the Bush report was the primacy of basic research, a term that Bush meant to refer to science at universities and research centers that seeks to understand the world without thought of practical ends.

 Bush wrote, Basic research leads to new knowledge.

 It provides scientific capital.

 It creates the fund from which the practical applications of knowledge must be drawn.

 New products and new processes do not appear full-grown.

 They are founded on new principles and new conceptions which in turn are painstakingly developed by research in the purest realms of science.

 It was a dreamy, even radical, depiction of American science.

 Rather than rely on private philanthropy or closed-door laboratories of corporate behemoths, Bush saw the future of science as a kind of hub-and-spoke system with the federal government directing funds to the most deserving university researchers.

 Bush's vision of a government organization for science funding led to the creation of the National Science Foundation, NSF, in 1950.

 As OSRD wound down, its charter depended on a wartime designation, contracts for medical research were transferred to the National Institutes of Health, NIH.

 At the time, the NIH was a fairly insignificant agency.

 It had evolved out of the Hygienic Laboratory, a meagerly funded facility with no experience coordinating a national research agenda.

 But this quickly changed.

 Medical schools, eager to capitalize on a new source of funding, overwhelmed the NIH with new proposals.

 Between 1945 and 1960, the NIH budget grew rapidly as it added several specialized institutes, such as the National Heart Institute in 1948 and the National Institute of Mental Health in 1949.

 By the mid-1950s, the NIH was the world's largest biomedical research organization.

 In the last 70 years, its budget has increased 1,000-fold.

 Today, NIH, along with the NSF, are irreplaceable.

 If these institutions had never been created or expanded, the lives of millions, even billions of people around the world would be shorter than they are today and people would be sicker.

 If they disappeared tomorrow, the world would instantly be worse.

 But it is precisely because the NIH stands above every bioscience institution in significance that we should scrutinize the way it shapes the practice of science in America and around the world.

 There are several popular complaints about the way the NIH has developed over the last few decades.

 The first problem echoes the criticism from our chapters on housing, energy, and the difficulty of building things in America.

 Rules have increased while efficiency has decreased.

 Immediately after World War II, NIH leaders foresaw that the rising tide of bureaucracy could drown the work of science.

 In 1946, Cassius Van Slyke, who would soon become the deputy director of the NIH, warned in the journal Science that he did not want the work of writing research grants to eclipse the work of actually doing science.

 It is not desired that the preparation of these reports present any long, tedious burden, he wrote.

 Ten years later, James Shannon, himself then one year into the job of NIH director, co-authored an article in Science with another ominous warning for his field.

 The research project approach can be pernicious if it is administered so that it produces certain specific end products, or if it provides short periods of support without assuring continuity, or if it applies overt or indirect pressure on the investigator to shift his interests to narrowly defined work set by the source of money, or if it imposes financial and scientific accounting in unreasonable detail.

 If we are living in the world that Bush built, we are also living in the world that Shannon feared.

 As science funding became more entrenched inside the federal government, politicians did what they do best.

 They created paperwork.

 In the early 1960s, Congressman Lawrence Fountain, a Democrat from North Carolina, published two reports complaining that the NIH did a lousy job accounting for the money it sent to scientists.

 He convinced Congress to take the unusual step of cutting the agency's funding.

 A decade later, Senator William Proxmire, a Wisconsin Democrat, created the Golden Fleece Award to draw negative attention to the worst use of government money in science.

 The first two Golden Fleece Awards went to studies about human attraction and why mammals clench their jaws when stressed.

 Proxmire called on government science funding to get out of the love racket and declared that these projects made a monkey out of the American taxpayer.

 The NIH got the message.

 Requirements for paperwork surged.

 All of a sudden, one NIH administrator wrote at the time, a whole series of thou shalts and thou shalt nots were written down.

 One 1960s science editorial, the headline, More Paperwork, Less Research, complained that turning scientists into clerks would cost the nation millions of dollars in lost time from research.

 It was a move reminiscent of blue states creating so many rules around permitting and environmental regulations that it became impossible to build necessary housing and energy.

 The instinct to make science democratically responsible has gunked up the scientific process.

 To appreciate the explosion of scientific paperwork requirements, imagine if every scientist working in America contracted a chronic fatigue disorder that made it impossible for them to work for half the year.

 We would consider this to be a national tragedy and an emergency.

 But this make-believe disorder is not so dissimilar to the burden we place on scientists today when it comes to paperwork.

 Today's scientists spend up to 40% of their time filling out research grants and follow-up administrative documents rather than on direct research.

 Funding agencies sometimes take seven months or longer to review an application or request a resubmission.

 Folks need to understand how broken the system is, said John Dench, the Director of Research and Development in Functional Genomics at the Broad Institute.

 So many really, really intelligent people are wasting their time doing really, really uninteresting things, writing progress reports or coming up with modular budgets five years in advance to the science as if those numbers have any meaning.

 Universities have whole floors whose main job is to administer these NIH grants.

 Why are we doing this?

 Because they're afraid I'm going to buy a Corvette with grant money?

 The rules exist for a reason, Dench acknowledged.

 Some scientists in the past probably abused their funding.

 But just as environmental laws passed in response to 20th century problems created a crisis of building in the 21st century, the paperwork cure in science is sometimes worse than the disease.

 We are very much in danger of falling behind because we are so bloatedly inefficient, Dench said.

 It's the same truth about how it takes forever to build a mile of subway in New York City.

 The cracks are emerging and we are going to lose our edge if our best and brightest people are spending their lives filling out forms rather than focusing on the next great thing.

 The second problem coming out of the growth of the NIH is that the onerous process of applying for grants has put a premium on status-seeking rather than pure science.

 This was a theme of Catelyn Carrico's years in the wilderness.

 I wasn't very good at kissing butts, Carrico said bluntly.

 In breaking through, she wrote that she felt success in academia was more about marketing and status than it was about hard science.

 You needed the ability to sell yourself and your work.

 You needed to attract funding.

 You needed the kind of interpersonal savvy that got you invited to speak at conferences or made people eager to mentor and support you.

 You needed to know how to do things in which I have never had any interest.

 Flattering people, schmoozing, being agreeable when you disagree, even when you are 100% certain that you are correct.

 You needed to know how to climb a political ladder to value a hierarchy that had always seemed at best wholly uninteresting and at worst antithetical to good science.

 I wasn't interested in those skills.

 While Carrico flashed the intelligence of a future Nobel-winning scientist, she wasn't world-class at a skill that Azoulay calls grantsmanship, the ability to write winning project proposals.

 There is a hidden curriculum for navigating grants and it is critical for success as a scientist today, Azoulay said.

 But those skills are weakly correlated with scientific potential and they might be negatively correlated.

 We have, even if by accident, designed a system that often privileges the game of performing the act of science over the actual practice of science.

 The final common criticism of the NIH might be the most important piece of the Carrico problem.

 While many discoveries depend on high-risk research that departs from the herd, like embracing the potential of mRNA while others rush toward DNA, modern science too often plays it safe.

 I have little doubt that the NIH is biased against high-risk science, said Azoulay.

 When I asked him how we know for sure that the current system isn't doing a perfect job balancing high-risk bets with important incremental projects, he offered a charmingly humble answer.

 We don't know.

 Not for sure, at least.

 This is one of the most important things that I'm working on and it's hard to make progress because the data is crap.

 He said it's hard to know for sure if there are a few Catalan Caracos in the world or thousands because the NIH makes it hard for outside researchers to compare the proposals that it funds against the ones it rejects.

 The NIH still largely relies on its decades-old peer-review system.

 A small team of independent scientists rates a project's merit, methodology, and significance before offering funding.

 Without full access to NIH decision-making, a scientist who wanted to study the agency's peer-review system might have to do something a little strange, like build a dummy peer-review system in a lab setting.

 In 2014, a team of researchers from Harvard University did just this.

 They recruited 142 star medical researchers to act as evaluators in a makeshift grant review process.

 They took 150 proposals and gave each one a novelty score and randomly assigned multiple proposals to each reviewer.

 In the final analysis of 2,130 evaluations, highly familiar proposals did all right and slightly novel proposals did the best.

 But highly novel ideas received the worst scores by far.

 We find that evaluators uniformly and systematically give lower scores to proposals with increasing novelty, the team concluded.

 New ideas no longer fuel American science the way they once did, the economists Mikko Pakalin and Jay Bhattacharya write.

 In a 2020 paper, they showed that NIH funding used to support fresh questions.

 In the 1990s, for example, the NIH consistently funded medical papers whose keywords first appeared in the literature in the previous seven years.

 But since the 2000s, NIH funding for the youngest vintage of science has declined by more than 25%.

 Once again, either the new ideas in science are getting worse or we're getting worse at looking for them and funding them.

 Bias against novelty, risk, and edgy thinking is a tragedy because the most important breakthroughs in scientific history are often wild surprises that emerge from bizarre obsessions.

 Too many projects get funding because they are probable, said Evans, the University of Chicago sociologist.

 But science moves forward one improbability at a time.

 In the 1990s, scientists studying the Gila monster, a stocky lizard, discovered a hormone in its venom that allowed the reptile to go months between meals.

 When they synthesized the hormone in a lab, they produced a medicine called the GLP-1 agonist, which was shown to reduce blood sugar levels in some people with diabetes.

 Today, GLP-1 drugs, like Ozempic, seem to treat not only diabetes, but also obesity, and a dizzying range of maladies including heart disease, alcoholism, and drug addiction.

 The most famous pharmaceutical breakthrough of the last decade is thus built on the foundation of a most delightfully peculiar obsession, lizard spit.

 Science is often nonlinear in this way.

 The most popular COVID tests relied on a technology called polymerase chain reaction.

 Developed in the 1980s, PCR is a method for amplifying small DNA sequences which can be used for paternity tests and disease diagnoses.

 When scientists were initially trying to figure out how to scale PCR, they needed bacterial enzymes that didn't fail at high temperatures.

 Fortunately, two decades earlier in the 1960s, biologists in Yellowstone National Park had isolated a hot springs bacteria that thrived in boiling conditions.

 The bacteria, the isolated, was incorporated into PCR research and helped launch a revolution in diagnostics and genetics.

 Without the bacteria, significant achievements such as the Human Genome Project might have been impossible, not to mention other great moments in scientific history such as You Are Not the Father outbursts on The Maury Show.

 Nobody building an effective medical test during a pandemic would ever stop to think, well, first thing, let's book a flight to Wyoming to take samples from geysers.

 But this is how science often works.

 A broad base of knowledge is built upon which we piece together disparate fragments of a puzzle to create new breakthroughs.

 Another example.

 CRISPR is a gene-editing function that some scientists believe could one day unlock the cure for any number of genetic diseases.

 But it was not discovered by a group of geneticists.

 The first mention of CRISPR in the scientific literature comes from Japanese and Spanish researchers working with bacteria that displayed a peculiar immune reaction when attacked by viruses.

 This early work did not initially receive many citations.

 But after 20 years of development, CRISPR now looks like one of the most powerful medical technologies in history.

 Isaac Newton famously said he saw further by standing on the shoulders of giants.

 But clearly, some brilliant ideas are not born giants.

 They are born as all children are born.

 Small and helpless, requiring care and protection to grow.

 We want the most life-saving, life-enhancing, productivity-expanding inventions and innovations possible, Evans said.

 That means we need a system that is designed to take more risks and accept more failures as a part of the scientific process.

 In a strange way, the problem isn't that too much science is doomed to fail, he said.

 It's the opposite.

 Too much science is, in his words, doomed to succeed, fated to duplicate what we know rather than risk failure by reaching into the unknown.

 Rather than see the NIH as an enemy of risky science, it makes more sense to think of it as a typical bureaucracy whose leaders are doing their best to solve typically bureaucratic problems.

 In 2017, longtime NIH director Francis Collins acknowledged in an email to the libertarian venture capitalist Peter Thiel that NIH needed to liberate young scientists from training periods that are much too long and that some of the ways in which we support biomedical research are outdated.

 In the last 20 years, NIH has created several grant programs that are earmarked for riskier research and younger scientists.

 Their high-risk, high-reward research program now includes a Pioneer Award for scientists pursuing new research directions and a new Innovator Award for younger academics.

 It's so important to be able to fund the people and ideas that might be a little bit out there, said Patricia Labosky, a program leader in NIH's High-Risk, High-Reward initiative.

 You want some science in low- or medium-risk areas where you're confident that you're going to learn something, but you also need this high-risk aspect where you can learn something different and you can push the envelope.

 The new Innovator Award initiative, which Labosky oversees, is structured very differently than typical NIH grants, known as RO1s.

 With a standard grant, you often have to show that you can accomplish everything you're proposing, and you're graded on a very high feasibility level, she said.

 For a new Innovator Award, we like to see a little plausibility, sure, but mostly, they just need a cool idea and the equipment to plausibly get it done.

 The NIH's own research indicates that Pioneer Award recipients seem to produce influential, highly cited research.

 But despite efforts to help younger scientists, the share of basic NIH funding going to scientists under 35 continues to decline.

 In the 2024 fiscal year, the High-Risk, High-Reward research program allocated about $200 million to scientists, a moderate decline since 2019.

 The amount was an almost negligible fraction, less than half of 1%, of the NIH's annual budget for that year.

 If we want a fully new approach to funding breakthrough science and invention, maybe we should look outside the NIH for the best ideas about how the government can accelerate invention.

 The Idea Factories In October 1957, a strange-looking device breached our planet's atmosphere and entered space.

 It resembled a kind of robotic daddy long legs with four spindly antennas connected to a spherical head made of polished metal.

 This space-age insectoid robot didn't live a long life.

 By January, it had fallen back to Earth and incinerated.

 But in its three-month lifespan, the little machine changed the world.

 Sputnik, as it was called, was the first man-made object to orbit the Earth.

 And to the great astonishment of many Americans, it was not launched by the United States, but rather by its chief rival, the Soviet Union.

 Sputnik ignited the space race, pushing the U.S.

 to invest in propulsion and rocket technology that would eventually put an American flag on the moon and leave boot prints in the moon dust.

 It also sparked an innovation race for terrestrial inventions.

 In 1958, vowing that the U.S.

 should never again be on the other side of a technological surprise, the Department of Defense established the Advanced Research Projects Agency.

 Later renamed the Defense Advanced Research Projects Agency, or DARPA, it produced a gaudy resume of ingenuity.

 The Internet, GPS, personal computers, and self-driving vehicles all traced their roots back to DARPA-funded research.

 What started as a bureaucratic reaction to a Soviet satellite became the seeds of the communications revolution that would shape the next 65 years of American innovation.

 Years before most people had heard of mRNA vaccines, DARPA invested $25 million in Moderna in 2013.

 The science and tech community has fervently debated what makes DARPA so special.

 With an annual budget of $4 billion, about one-tenth of the NIH, DARPA punches well above its weight.

 One answer is that DARPA empowers domain experts, called program managers, to pay scientists and technologists to work together on projects of their own design.

 There's no question to me that program managers, especially program managers with vision, creativity, and independence, are the most important part of DARPA, said Erica R. H.

 Fuchs, a professor of engineering and public policy at Carnegie Mellon.

 Unlike traditional scientists, these program managers do not face peer review.

 They can make big counterintuitive bets, are not punished for failure, and are not hauled before congressional committees for supporting weird sounding projects.

 To explain how a successful program manager works, Fuchs pointed to the invention of ARPANET, the world's first internet.

 In 1962, J.C.R.

 Licklider, a psychologist and computer scientist from MIT, joined ARPA to lead its information processing division.

 Licklider, who had previously sketched out the concept for a global computer network, set out to assemble a dream team of researchers to bring his idea to life.

 Like a Hollywood producer handpicking his favorite director, designers, and actors to make a new film, Licklider paid far-flung geniuses across the country to work together.

 Computer scientists at the Carnegie Institute of Technology, now Carnegie Mellon, and engineers at Stanford University collaborated to link computing systems to send coast-to-coast messages.

 In 1966, Bob Taylor, a psychologist who had worked at NASA, took over Licklider's program.

 He vastly expanded the network of collaborators, pulling in pioneers of science and engineering from several more universities, engineering firms, and government labs, including MIT, the RAND Corporation, and UCLA.

 When ARPANET went online in 1969, the world's original, and very basic, internet required the collaboration of individuals and firms who would never have otherwise come together.

 To invent an online network of information, Licklider and Taylor built an offline network of minds.

 Every worthwhile DARPA project is a bit like this, Fuchs said.

 The agency's most successful people are like talent scouts with a vision.

 They say, if we get this person over here working with this person over here, and then we bring in this third person, we could solve this unsolvable problem.

 In the early 2000s, the Department of Defense was worried that Moore's Law, the frequent doubling of the density of transistors on a computer chip, was slowing down and threatening the cost and quality of our military software.

 DARPA was asked to come up with a solution.

 One program manager Fuchs interviewed at length, convened an unlikely alliance of industry giants and academic luminaries.

 He brought together computer scientists and engineers from Hewlett Packard and MIT, along with promising California startups collaborating with the software firm Sun Microsystems, who collaborated with nanotube experts at Harvard and UCLA, all of them received millions in DARPA funds.

 This group contributed to a breakthrough in silicon germanium technology, which was ultimately commercialized by IBM.

 In 2015, IBM told the Wall Street Journal that they'd broken through major bottlenecks in advancing Moore's law.

 The announcement was IBM's, but the breakthrough itself began with DARPA.

 If the DARPA model holds a lesson, it is that the agency works because it empowers program managers to pursue their most radical ideas with an open-ended budget and vast connections throughout science and industry.

 By contrast, as John Dench of the Broad Institute said, many scientists seeking funding today are disempowered to the point of infantilization.

 Their time is colonized by paperwork, and their ambition is pinched by grantsmanship.

 The American innovation system would benefit from trusting individuals more and bureaucracies less.

 DARPA isn't the only mid-century factory of innovation that we can turn to for inspiration.

 Bell Labs, officially known as Bell Telephone Laboratories, was established in 1925 as the research and development arm of AT&T and Western Electric.

 Between the 1930s and 1950s, it became one of the most prolific research institutions in the world, responsible for a staggering number of accomplishments.

 In 1947, its engineers built the first transistor, which enabled the development of smaller and more efficient electronic devices.

 In 1954, Bell Labs demonstrated the first practical silicon solar cell, opening the door to solar energy as a viable power source.

 In 1958, the lab published a paper outlining the principles of the laser.

 While DARPA and Bell Labs are both considered icons of innovation, their success took place in very different contexts.

 DARPA emerged in a period of geopolitical insecurity.

 Bell Labs thrived in an environment of extraordinary security.

 As a state-sanctioned monopoly, AT&T could invest in every facet of telecommunications science without concern for short-term profits, which gave its scientists and engineers the freedom to pursue ambitious projects over decades.

 This long-term security was essential for many of Bell Labs' most important technological advances, such as fiber optics and electronic switching, which took decades to develop.

 Bell Labs benefited from a unique moment in history.

 After spending six years writing a book about Bell Labs, I've often wondered whether it would be possible to recreate it today, said John Gertner, the author of The Idea Factory.

 My answer is no.

 After World War II, AT&T was a Goliath within a Goliath, a huge government-sanctioned monopoly inside a country that dominated fields like chemistry and quantum mechanics, when Nazi Germany's assault on Europe forced many of the continent's best minds to flee to America.

 But its success still holds lessons for us as we think about a national invention agenda.

 If Bell Labs had a formula, it was to hire the smartest people, give them space and time to work, and make sure that they talk to each other, Gertner said.

 Like DARPA, the program thrived by identifying brilliant people who wouldn't normally work together, and by giving them freedom to pursue their most ambitious ideas together.

 This blending of minds got scientists to think about their work in new ways.

 Gertner visited the home of Morris Tannenbaum, who invented the silicon transistor at Bell Labs in the 1950s, before he became the first chief executive officer of the AT&T Corporation in the 1980s.

 When I was at his house, Tannenbaum brought me upstairs and showed me an entry in his notebook from the day he had invented the transistor made from silicon.

 He had written, This is the transistor we've been looking for.

 It should be very manufacturable.

 The journal entry struck Gertner as a microcosm of Bell Labs' unusual approach to science.

 Here was a chemist, tinkering with the fundamental principles of electrons, thinking about how his invention would become a product that went through factory assembly and ended up in people's houses.

 Our institutions shape the way we think, and new institutions can make new kinds of thinking possible.

 For decades, too many university researchers applying for NIH funding have constrained their own curiosity.

 The perceived biases of the NIH became their own biases.

 By contrast, the best DARPA program managers see the world as a set of puzzle pieces to snap together in the creation of a new initiative.

 The Bell Labs scientists worked in an offshoot of AT&T which made it natural for them to consider the commercial potential of their work, which might explain how they created so many useful products.

 America's innovation system still relies on agencies and habits that were developed in the middle of the 20th century.

 Decades have now passed.

 The world has changed, and today's scientific challenges are getting harder.

 So how do we build new centers that are as transformative in our time as DARPA was in its own?

 Where are the brand new government research labs for the 2020s?

 Such institutions are not guaranteed to succeed, but they represent the sort of risk-taking that American science needs more of.

 Experimenting with experiments Scientific research and invention are the key drivers of economic growth and improvements in human well-being, Dartmouth's Heidi Williams said.

 This is a fact, and it naturally raises a question.

 How could we get more of that?

 Today's politics is alarmingly vacant when it comes to answering this question.

 Neither liberals nor conservatives have articulated a clear politics of invention.

 Neither have prioritized the rigorous analysis of public policy in science.

 We could do so much better.

 We could fix the manufactured scarcities of our immigration system and make it easier for the world's most brilliant people, who often graduate from American schools, to stay and work in the U.S.

 We could increase federal research and development spending rather than allow it to decline as a share of the economy as we did for much of the second half of the 20th century.

 But perhaps most important, we could fix the incentives of the American innovation system to help each dollar of funding find the right scientist taking the right risk at the right time.

 In the last few years, a small group of researchers have advanced a theory of change in American politics that they call meta-science.

 Their thesis is straightforward.

 The U.S. government is the single largest source of science funding in the world, and yet we know shockingly little about how science actually works.

 Our laws, rules, and habits have accreted over decades without much of a grand strategy.

 A national invention agenda ought to operate from the first principle that, if we don't understand the science of invention at all, we should do what scientists do.

 We should run experiments.

 Lots of experiments.

 We could start with the NIH.

 To reduce the paperwork burden, we could run pilots that eliminate major parts of the application process.

 Or we could expand programs that prioritize the funding of younger scientists.

 To mimic the program director's power at DARPA, we could give some NIH panel members a golden ticket such that they would have the power to independently approve one proposal each year, regardless of how crazy the idea sounds to their peers.

 Or, for some applications, we could replace the existing selection process with a random lottery.

 Or we could announce that, for a lucky group of grantees, no scientists would have to fill out yearly progress reports.

 And then, after we run these experiments, we should have independent scientists study the results.

 In 2009, several researchers compared a group of typical NIH grant recipients to scientists funded by the Howard Hughes Medical Institute, HHMI.

 Whereas the NIH pays scientists for specific projects, HHMI funds scientists without attaching strings to their research.

 They found that HHMI funding led to more flops, but also more hits, more original discoveries, and more high-impact articles.

 Is it better to fund individual projects or to give open-ended grants to scientists and hope for the best?

 As Pierre Azoulay says, we don't know for sure, but we should run the experiment.

 As we tinker with the basic funding models of science, we could also pay for the creation of new federal research organizations where full-time scientists pursue ambitious projects over many years without having to stress over quarterly paperwork.

 The ambition would be to re-bottle the magic of mid-century DARPA and Bell Labs.

 It might not work, but that's what high-risk science does.

 It takes on projects with a keen possibility of failure.

 You don't want the entire innovation system made up of DARPA.

 And you don't want the entire innovation system made up of NIH grants.

 And you don't want it made up of any one thing, Azoulay said.

 We want a well-tempered balance of experiments.

 Let a thousand initiatives bloom, track their long-term success, and determine whether there are better ways to finance the sort of scientific breakthroughs that can save or improve millions of lives.

 This approach to science and invention would be genuinely novel.

 It would mean creating a layer of the American science system that specializes in self-experimentation.

 It would mean turning the federal government into a kind of meta-laboratory for the study of science itself.

 Generations from now, inventions that we can scarcely imagine will feel core to modern life.

 All disease, saliva, and blood tests.

 Vaccines that wipe out whole classes of virus and disease.

 Materials stronger than steel and lighter than air.

 Infinite clean energy from fusion reactors.

 If these things are possible in the realm of physical reality, then they are possible to discover.

 And if they can be discovered in a century, they can be discovered in a decade.

 Or in a year.

 These achievements will require a level of risk-taking and ambition that we are too effective at snuffing out.

 For all the wonders of American invention, it is astonishing to realize that we don't know for sure how the process of discovery actually works.

 We still don't know how to identify and nurture the Catalan Caracos of the world.

 To find them, we need a better science of science.

 Chapter 5.

 Deploy.

 In the fall of 1928, the Scottish scientist Alexander Fleming returned from a long holiday to his lab in London.

 He had been working with Staphylococcus, a bacterium that caused common infections.

 Deriving its name from the Greek staphyl, meaning a bunch of grapes, and kokos, meaning berry, its colonies resembled a cluster of white grapes under a microscope.

 But when Fleming looked closely at his samples, he saw something unexpected in a dish he'd left open to the air.

 While he was away, a substance of unknown origin had contaminated the sample and killed much of the bacteria.

 Fleming later identified the mysterious material as a mold belonging to the genus Penicillium.

 As for the bacteria-killing substance it produced, he called it Penicillin.

 Fleming later claimed that the spore of mold blew into his lab through an unlocked window.

 If so, it was carried by a heavenly breeze.

 For millennia, humankind fought bacteria in war after war within our bodies and died by the millions at the hands of an unseen enemy.

 As late as 1900, bacterial infections were the most common cause of death in the U.S.

 More people died of bacterial pneumonia during the 1918 influenza pandemic than from the virus itself.

 When Fleming tested the mold against other bacteria, he saw it was even more powerful at neutralizing the nemeses of diphtheria and meningococcus.

 He suspected that he might have something miraculous on his hands.

 But after several more experiments, his work hit a wall.

 In 1939, an Australian-born professor at Oxford University named Howard Flory and a German-born biochemist named Ernst Chain picked up where Fleming left off.

 Whereas the Scottish scientist had shown that penicillin could zap microbes on glass, Flory and Chain wanted to know if it might do the same inside animals.

 Their lab divided 150 mice into three groups and injected each with, respectively, staphylococci, streptococci, and a bacterium that causes gangrene.

 Half of the mice were left untreated to serve as the control group, and the other half were given penicillin.

 In the control group, all 75 untreated mice died.

 In the intervention group, 70 survived.

 Penicillin seemed quite special indeed.

 But people are not mice, and Flory, Chain, and their group had more trouble testing the effect of penicillin in humans.

 After nearly two years of work, they, too, were stuck.

 By the spring of 1941, with Europe submerged in war, five human patients and their experiments had been treated with penicillin.

 Two of them had died.

 Let's pause the story here, as strange as this interruption might seem.

 Fleming's discovery of penicillin is world-famous, cherished by scientists, and hailed as one of the most significant breakthroughs in the history of health or any field.

 Flory's portrait adorned the Australian $50 note for decades.

 Chain, along with Fleming and Flory, won the 1945 Nobel Prize in Physiology or Medicine.

 For many, progress appears to be a mere timeline of such eureka moments.

 Our mythology of invention treats the moment of discovery as a sacred scene.

 In schools, students memorize the dates of major inventions, along with the names of the people who made them.

 Edison, lightbulb, 1879.

 Wright Brothers, airplane, 1903.

 The great discoverers, Franklin, Bell, Curie, Tesla, get best-selling biographies, and millions of people know their names.

 You can think of this as the eureka theory of history.

 It's the story of progress you might expect to see in Hollywood or to read in nonfiction books that hail the lonely hero whose flash of insight changes the world.

 But this approach to history is worse than incomplete.

 It's downright wrong.

 Inventions do matter greatly to progress.

 But too often, when we isolate these famous scenes, we leave out the most important chapters of the story, the ones that follow the initial lightning bolt of discovery.

 Consider the actual scale of penicillin's achievement in 1941.

 Five human subjects and two deaths.

 Thirteen years after one of the most famous discoveries in science history, penicillin had accomplished practically nothing.

 The Eureka Myth When a good idea is born, or when the first prototype of an invention is created, we should celebrate its potential to change the world.

 But progress is more about implementation than it is about invention.

 An idea going from non-existence to existence, from zero to one, introduces the possibility of change.

 But the way individuals, companies, and governments take an idea from one to one billion is the story of how the world actually changes.

 And it doesn't always change, even after a truly brilliant discovery.

 The 10,000-year history of human civilization is mostly the story of things not getting better, diseases not being cured, freedoms not being extended, truths not being transmitted, technology not delivering on its promises.

 Progress is our escape from the status quo of suffering, our ejection seat from history.

 It is the less common story of how our interventions and institutions reduce disease, poverty, pain, and violence, while expanding freedom, happiness, and empowerment.

 It's a story that has been at risk of grinding to a halt in the United States.

 The U.S. has thrown billions of dollars annually into scientific discovery, but it hasn't brought as much progress as we'd expect.

 As we explained in the previous chapter, we have haphazardly burdened the scientific progress with the same flavor of procedural kludge that has slowed down other critical parts of the economy.

 What's more, as we'll explain in this chapter, we have gotten worse at translating our inventions into domestic industries.

 To borrow some familiar language, it's not just that ideas are getting harder to find.

 The problem is also that new ideas are getting harder to use.

 What went wrong?

 There are many answers, but one is that we have become too enthralled by the Eureka myth, and more to the point, too inattentive to all the things that must follow a Eureka moment.

 The U.S. has more Nobel Prizes for science than the U.K., Germany, France, Japan, Canada, and Austria combined.

 But if there were a Nobel Prize for the domestic deployment of technology, even technology that we invented, our legacy wouldn't be so sterling.

 An American craftsman, Elijah Otis, invented the first safe passenger elevator in 1853.

 This only deepens the irony that 170 years later, the U.S. struggles to build tall apartments efficiently, in part because American elevators have become over-engineered, bespoke, handcrafted, and expensive pieces of equipment that are unaffordable in all the places where they are most needed, according to Stephen Jacob Smith, executive director of the Center for Building in North America.

 Burdened by regulations and inattention to cost-effective production, basic elevators cost four times more in New York City than in Switzerland.

 Americans invented the world's first nuclear reactor and solar cell, but today we're well behind various European and Asian countries in deploying and developing these technologies.

 Thirty years ago, a group at the University of Texas developed next-generation technology to create lithium-iron-phosphate batteries, which car companies need for the top-performing electric vehicles.

 But in the early 2020s, no American company knew how to manufacture these batteries at scale, and China held a monopoly on the market.

 Politics should take technology more seriously.

 Innovation can make impossible problems possible to solve, and policy can make impossible technologies possible to create.

 the fundamental link between the two is not at the core of the Democratic or the Republican agenda.

 Instead, we are stuck between a progressive movement that is too afraid of growth and a conservative movement that is allergic to government intervention.

 In the last 70 years, we have too often followed the same playbook, invent, but don't implement.

 We cannot afford to follow this playbook for the next 70 years.

 To appreciate the deeper story of progress and to see how it illuminates America's own problems in the 21st century, let's return to the 1940s to watch how penicillin went from a scientific discovery in a lab to a medicine that saved millions of lives.

 In 1941, Howard Florey and Ernst Chain were stumped.

 The British research teams that were investigating the potential for antimicrobial medicine had hit a dead end.

 Deep in war, England didn't have resources to scale the technology.

 Florey and Chain needed help from overseas.

 By some providence, America had everything the scientists wanted.

 President Roosevelt had just approved Vannevar Bush's vision of a centralized agency to coordinate wartime innovation.

 Bush's Office of Scientific Research and Development, OSRD, included a division focused on new treatments that could be useful for soldiers and other military personnel.

 This agency, called the Committee on Medical Research, CMR, had already invested in malaria medicine and new research on novel influenza vaccines.

 CMR took Florey and Chain's science project and turned it into a medical product.

 First, the U.S. solved penicillin's chemistry problem.

 It was one thing to make a small batch of penicillin in a little flask.

 But if you used the same ingredients to make larger amounts, microorganisms would mess up the mixture, producing a worthless sludge.

 The historian James Finney Baxter III elegantly described the irony.

 The same accident of contamination which led to the discovery of penicillin very nearly prevented its use.

 With OSRD's encouragement, scientists in Peoria, Illinois, discovered that adding corn steep, water soaked with corn, could increase penicillin production tenfold.

 The military collected and tested new strains of mold which, mixed in the larger vats and with further modifications to the process, made mass production possible.

 With the help of the War Production Board, OSRD spent millions of dollars paying firms to set up penicillin plants.

 Penicillin production went exponential, rising from an average of 10 million units per plant per month in 1942 to 646 million units by June 1945.

 As production scaled, the cost of making the antibiotic plummeted by more than 95%.

 Meanwhile, CMR conducted clinical trials on penicillin to ensure its effectiveness.

 In the spring of 1943, with the chemical procedures standardized, the U.S. government turned to distribution.

 An advisory board and the American Medical Association chose 1,000 hospitals across the country to store and distribute the drug, which was also made available to local communities.

 In December, a report on 209 soldiers and civilians across the country with severe wound and bloodstream infections found that those treated with penicillin experienced both lower mortality rates and shorter hospitalizations.

 Just as important, the medication obliterated bacteria without any toxic effects.

 By March 1945, there was enough penicillin for just about everyone in America.

 In short order, the little mold that blew in through the window revolutionized modern medicine and life.

 Bacterial infections became manageable health problems.

 Surgeries became safer, childbirth less deadly, and war wounds less lethal.

 Penicillin saved the equivalent of full battalions by reducing the mortality rate of bacterial pneumonia in soldiers from 18% to 1%.

 One source estimated that one in seven wounded British soldiers lived thanks to the drug.

 From 1945 to 2023, considering global disease burden data and accounting for antibiotic effectiveness against bacterial diseases, it's reasonable to assert that penicillin and its progeny have saved hundreds of millions, if not billions, of lives around the world.

 Building what we invent The development of penicillin offers a usefully complete story, where humanity triumphed over a natural adversary.

 The lesson, which the U.S.

 seems to have forgotten in the last few decades, is that implementation, not mere invention, determines the pace of progress.

 In 1941, penicillin was a stalled science project, languishing in the resource-starved labs of warring Europe.

 It became a life-saving product only thanks to hundreds of American scientists and engineers.

 Almost every technology is like this.

 Most major inventions initially don't work very well, the economic historian Joel Mokir said.

 They have to be tweaked, the way the steam engine was tinkered with by many engineers over decades.

 They have to be embodied by infrastructure, the way nuclear fission can't produce useful electricity until it's contained inside a working reactor.

 And they have to be built at scale, the way Ford's Model T came down in price before it made a big difference to the country.

 Tinkering, embodiment, scaling.

 These are examples of what Mokir calls micro-inventions, or the incremental improvements needed to turn a new idea into a significant product.

 These micro-inventions are often more important than the original breakthrough.

 For example, it's broadly understood that Thomas Edison invented the incandescent light bulb in his Menlo Park, New Jersey lab in 1879.

 But what exactly did he invent?

 Certainly not electric power.

 In 1800, the Italian physicist Alessandro Volta reportedly built the first battery with an electric current.

 Not electric light, either.

 In 1809, Humphrey Davy built the first practical arc lamp that sent a span of sparks across two rods.

 Edison didn't even invent light bulbs.

 In 1841, the English inventor Frederick de Molins was granted the first patent for a charcoal-powered incandescent lamp.

 So, what did Edison actually do?

 In his chambers, he painstakingly burned hundreds of materials inside a glass vacuum until he settled on a carbonized bamboo to serve as an efficient light bulb filament.

 Understanding that electric light required the steady delivery of electricity, Edison also built a system of generators to make power, wires to carry it, sockets and switches to turn it on and off, and meters to measure usage and allow for the billing of customers.

 Edison, did not make electric light possible, but his micro-inventions did something even more important.

 Through exhaustive tinkering, embodying, and scaling, he made electric light useful.

 Making technology useful often means building it at scale.

 For many decades, however, U.S.

 policy hasn't taken this lesson as seriously as it should.

 After World War II, the American approach to innovation has been to throw money at the initial eureka moment, sporadically support its development, and then watch idly as the technological frontier moves to other countries.

 In 1954, three American researchers at Bell Labs built the first device for turning sunlight into energy, a silicon-based solar cell.

 When light struck the silicon chip, electrons in the metal splashed around as if cannonballed into activity, lab engineers found a way to convert the electrons into a current, electricity.

 At last, sunlight from our nearest star could be technologically photosynthesized into energy for human use.

 On April 25th, the laboratory's managers gathered for a press conference to unveil the world's first solar-powered machine, a miniature Ferris wheel.

 The New York Times heralded the demonstration as the beginning of a new era that might finally realize mankind's most cherished dreams, the harnessing of the almost limitless energy of the sun for the uses of civilization.

 Yet, despite the initial fanfare, the first solar cells were impractical for daily use.

 If you try to use these earliest models to heat and light your home tomorrow, it would cost you about $1 million a day.

 Despite little utility on Earth, solar technology found early promise in orbit.

 The first American satellite, Explorer 1, which had relied on heavy mercury batteries, lasted less than four months.

 In a bold move, the U.S. Navy turned to solar cells for its Vanguard 1 satellite, launched in March 1958.

 The gamble paid off.

 Vanguard 1's six solar cells powered its radio transmitter for six years.

 This success triggered a decade of intensive development.

 From 1958 to 1969, the U.S.

 space program poured tens of millions of dollars into solar cells for its satellites.

 Just as the environmental movement gained momentum, the 1973 oil crisis sent shockwaves through the American economy and exposed the nation's vulnerability to foreign energy suppliers.

 In response, the U.S.

 government launched a strong push to develop alternative energy sources.

 Solar power became a centerpiece of these efforts.

 Federal funding for its research and development took off.

 New agencies like the Energy Research and Development Administration and the Solar Energy Research Institute were established to coordinate and accelerate its progress.

 The results were undeniable.

 Over the course of the decade, solar cell efficiencies tripled while costs plummeted by a factor of five, according to Gregory Nemet, a professor at the University of Wisconsin and the author of the book How Solar Energy Became Cheap.

 Thousands of scientists, engineers, and entrepreneurs flocked to the field sensing the dawn of an energy revolution.

 The election of Ronald Reagan in 1980, however, decimated the solar revolution in America.

 Driven by a conservative ideology that favored free markets and limited government intervention, Reagan dismantled much of the solar infrastructure built over the previous decade.

 For Secretary of Energy, he appointed James Edwards, a dentist with no expertise or interest in developing nascent energy technology.

 Solar R&D spending under Reagan fell by over 60% in his first year in office.

 Some of the dismantling was painfully literal.

 In 1986, Reagan removed the solar hot water panels installed on the White House roof by Jimmy Carter.

 Reagan's election was the most important factor in the slowdown of U.S.

 solar development, according to Nemet.

 His conservative revolution coincided with a huge drop in gasoline prices as Saudi Arabia flooded the market with cheap oil in the 1980s.

 Consumers embraced gas-guzzling SUVs, and alternative energy fell out of favor.

 The spirit of imagining life after oil seemed to shrivel up and die.

 As late as the early 2000s, federal energy R&D spending was still 80% below its level in the 1970s.

 The U.S.

 solar industry gradually withered.

 Many companies couldn't survive without government support.

 By 2001, renewable energy accounted for 5% to 6% of total energy consumption, the lowest share since at least 1989.

 As American firms pulled back from solar power, other countries picked up the slack.

 In the 1990s, Germany subsidized solar technology from both sides, paying companies to make panels and paying consumers to buy them.

 The solar market took off.

 Between 2001 and 2011, German employment in the industry surged alongside rooftop solar installations.

 If the U.S.

 invented solar energy in the 1950s, and Germany made it a market in the 1990s, China made solar energy cheap in the 2000s.

 Without sufficient oil and gas resources to power a billion-person economy, China has had existential motivation to develop its own domestic energy technology.

 In the 2010s, Beijing got serious about building out a solar energy business, lavishing subsidies, loans, and free land to upstart solar panel makers.

 Recognizing this lasting commitment, Chinese solar companies invested for the long run.

 Whereas America whiplashed between boom and bust cycles in solar policy that have surely slowed down its progress, Nemet wrote that China's consistent policy has allowed its firms to build more, faster, and cheaper.

 There is an idea in manufacturing history known as Wright's Law, which says that some things get cheaper as we learn to build more.

 The theory is named after Theodore Wright, an American aeronautical engineer who served as vice chairman of NASA's predecessor, the National Advisory Committee for Aeronautics.

 In the 1930s, Wright recognized that the cost of building airplanes had declined with an eerie consistency since World War I.

 For every quadrupling of total aircraft production, unit costs consistently fell by about one-third.

 In 1936, Wright proposed that some products enjoy a kind of virtuous cycle of building and learning.

 Wright's Law runs counter to the Eureka myth.

 It says that innovation is not a two-stage process where a loner genius conceives of a brilliant idea and then a bunch of thoughtless brutes manufacture it.

 Innovation is enmeshed in the act of making.

 Wright's Law is the story of penicillin, whose costs declined as the government learned to cook larger batches of the medicine.

 It is the story of the Model T automobile, which became more affordable as Ford built larger and larger factories.

 It is also the story of the computer chip.

 In the 1960s, Gordon Moore, the founder of Intel, wrote that the number of transistors on a chip might double every two years.

 His prediction became prophecy.

 Fifty years later, transistor costs declined by a factor of one billion.

 Wright's Law echoes loudly in the history of China's solar energy revolution.

 Drawing from the country's expertise at making cheap textiles and shoes, Chinese firms gradually learned how to make solar panels more efficiently.

 In one case, a Chinese company bought a saw from a Swiss company that could cut thinner and thinner silicon wafers, which meant more panels from the same crystal ingot.

 They built machines to automate production lines.

 As they figured out what worked, they scaled up their lessons to build more production lines and larger factories.

 In 2000, China had barely enough solar energy to power a small town.

 By 2020, the nation was making 70% of the world's photovoltaic panels.

 As China ramped up manufacturing, the cost of solar panels in the last 15 years has declined by about 90%.

 Seventy years ago, the New York Times had anticipated that America's solar energy revolution would lead to limitless energy.

 But rather than treat limitless clean energy as a project of national urgency, the U.S.

 treated solar panels as a trifling and essential, with no long-term plan to make or deploy them at scale.

 And we lost decades of progress because of it.

 In Germany, between 1990 and 2015, the share of electricity production that came from renewable energy like solar rose from about 3.5% to 30%.

 But in the U.S., over the same period, solar's share of electricity stagnated.

 These were wasted decades, which we are paying for in the form of more modern pollution, more dependency on fossil fuels, less total energy, and more expensive electricity bills.

 All is not lost.

 After a long hiatus, solar energy has taken off again to become America's fastest-growing electricity source, partly thanks to subsidies passed in the Inflation Reduction Act of 2022.

 But while today's solar progress deserves our celebration, the policy errors of the last 40 years deserve our attention.

 The U.S.

 led the world in solar energy development throughout the 1970s.

 In a parallel universe where we had continued to develop and deploy solar, we might today have the green energy paradise of our dreams, an economy fully fueled by the sun.

 With such abundance of electricity, we might untap businesses that today are science fiction given their high energy demands, like machines that suck carbon dioxide from the sky and factories that grow animal meat without animal suffering.

 But for too long, America fell for the Eureka myth and its attending faith in markets alone to solve the problem of scaling new technology.

 Progress is, now as it has always been, about the combination of invention and implementation.

 John Arnold, the co-chair of Arnold Ventures Philanthropy, put it pithily, America has the ability to invent, China has the ability to build.

 The first country that can figure out how to do both will be the superpower.

 For the past few decades, the Eureka myth has walked hand in hand with another attractive fable.

 That the U.S. government is helpless as an investor in new technologies.

 One useful summary of this view came from a 2012 Economist essay, which claimed, governments have always been lousy at picking winners, and they are likely to become more so, as legions of entrepreneurs and tinkerers swap designs online and turn them into products.

 This dual image, the state as a lazy slowpoke versus the market as the self-sufficient dynamo of innovation, bears little resemblance to history.

 As the economist Mariana Mazzucato pointed out in The Entrepreneurial State, it's strange that we still debate whether the government ought to pick winners when it is obvious that we live in a world that has amply picked for us.

 When you use an iPhone, you are playing with a technology that bundles silicon chips, the internet, GPS, voice recognition software, and multi-touch technology, which were in part funded by the Defense Department, NIH, the National Science Foundation, and other government entities.

 If you heat and cool your home with power drawn from natural gas, you're tapping into an energy revolution that began with federal research into drilling shale formations.

 If you own a home in the suburbs, you drive down state-funded roads with federally subsidized mortgages.

 We live in a ripely picked world.

 The smartest question, then, is not if the government should intervene in markets, but how to do so.

 Nearly 100 years ago, the economist John Maynard Keynes offered an elegant answer in his 1926 book The End of Laissez-Faire.

 The important thing for government is not to do things which individuals are doing already and to do them a little better or a little worse, but to do those things which at present are not done at all, he wrote.

 If technological progress requires money or resources that are beyond the scope of any one company, and government does nothing, progress slows down.

 This is exactly what we saw after 1980 in the solar industry.

 As the private sector lacked the resources to scale solar production, Washington slashed its support and the industry went cold.

 The highest purpose of a pro-invention government is to make possible what would otherwise be impossible.

 No private company could orchestrate the national production of penicillin in World War II, so OSRD did it.

 No private companies were close to putting a man on the moon in the 1960s, so NASA did it.

 Government should have a vision of the future, and within that vision it can create space for companies to do what they otherwise cannot, to make possible what is otherwise impossible.

 The COVID pandemic was a crisis that required a first-of-its-kind invention that no company could solve on its own.

 It was inconceivable that a single firm might invent, test, approve, and manufacture a therapy in record-breaking time.

 In the case of mRNA technology, an ingenious invention was not enough.

 We needed an equally ingenious plan to bring that invention to life.

 And just as the U.S. government did for penicillin in World War II, the U.S. succeeded by providing a model for how to turn invention into implementation.

 Progress at warp speed.

 In the spring of 2020, the typical timeline for new vaccine development was thought to be a decade or longer.

 The grim truth, the New York Times journalist Stuart A. Thompson wrote in April, is that a vaccine probably won't arrive anytime soon.

 Many scientists agreed.

 When the MSNBC host, Brian Williams, asked Erwin Redliner, a public health expert at Columbia University, about the prospects of a vaccine by the end of 2020, the scientists said the mission was impossible.

 On May 15, 2020, with the COVID death count screaming toward 100,000, the White House announced in a Rose Garden kickoff a mission to end the pandemic.

 The goal of the new plan, Operation Warp Speed, OWS, was to create the fastest vaccine development and distribution program in history.

 A new vaccine built, not in 10 years, but in 10 months.

 To succeed, officials had to map out the entire journey of a new therapy.

 Research, clinical trials, regulatory approval, distribution.

 The people in charge of OWS weren't students of Vannevar Bush.

 They weren't experts on the history of the Office of Scientific Research and Development.

 In conversations with its top officials, they said they'd never heard of OSRD.

 But whether by accident or by instinct, they retraced many of the steps that made penicillin a wartime reality.

 First, they had to solve the problem of basic science.

 In May 2020, nobody knew what kind of vaccine technology would have the best chance at knocking out COVID.

 Officials decided to spread their bets.

 We embraced a venture capital approach, said Paul Mango, then Deputy Chief of Staff for Policy at the Department of Health and Human Services, and the author of Warp Speed, an insider's history of the program.

 Rather than put all their money behind one type of vaccine technology or one pharmaceutical company, they spread their investments across three vaccine platforms or technologies.

 Synthetic mRNA, replication-defective live vector, and recombinant subunit-adjuvanted protein.

 We wanted to spread out the risk because we didn't know what technology would solve the problem, he said.

 But we also didn't want to make too many bets because it would have been a logistical nightmare to coordinate the development of dozens and dozens of vaccine candidates at once.

 Notably, Warp Speed didn't force any company to make vaccines.

 Instead, firms were lured with upfront subsidies and promises of future payouts.

 Second, OWS had to accelerate the approval and production pipeline, where many drugs wait years to go to market.

 To reduce barriers that could slow down vaccine approval, OWS helped to recruit populations for clinical trials and to accelerate the timeline for FDA review.

 To fast-track production, OWS set up or expanded 27 manufacturing facilities.

 Science is the easy part of making a vaccine.

 Monsef Slaoui, the head of OWS, said often to his team, The hard part will be manufacturing this stuff at scale.

 Just because you know how to make 5 liters of vaccine doesn't mean you can make 100 liters of it.

 A vaccine's journey from the production plant to tens of thousands of pharmacies created other challenges.

 For example, the Pfizer vaccine needed to be stored at around minus 70 degrees Celsius, a temperature at which most glass vials shattered.

 So Warp Speed approached the materials science company, Corning, to produce, in quantity, a special glass they had developed a few years earlier.

 The program ultimately granted $347 million to Corning and one other glass manufacturer to ensure ultra-cold transport.

 Third, OWS had to solve the distribution problem.

 It doesn't do any good to have millions of vaccines sitting on the shelf, Mango said.

 We had to get them to 70,000 sites working with 64 separate health jurisdictions in all 50 states.

 We had to do it very quickly and all at once.

 OWS brought a combat operation focus to procuring vaccines and ensuring their speedy delivery.

 Warp Speed leaned on officials from the Defense Department's Army Materiel Command to help with logistics and lessons from the battlefield were pulled into the vaccine program.

 For example, for every 100 doses of vaccines sent to pharmacies, the government sent 110 needles and 110 syringes.

 The equivalent of a frontline soldier will sometimes drop a syringe or contaminate a needle, so you need redundancy, Mango said.

 OWS solve problems by enabling the private sector rather than commanding it.

 With few exceptions, such as the Veterans Administration, no federal employee was directly involved in manufacturing, packaging, shipping, or injecting a single dose of any Warp Speed COVID vaccine, Mango wrote in his book on the program.

 We let one of the biggest pharmaceutical distributors in the world, McKesson, handle the vaccines.

 Let the most successful delivery companies in the world, UPS and FedEx, deliver the vaccines.

 Let those entities who knew best how to vaccinate millions of Americans, CVS and Walgreens, conduct vaccinations.

 Finally, the simplest part of OWS is perhaps the most important.

 The vaccines were free.

 The federal government bought out the vaccines from pharmaceutical companies, which allowed them to sell the shots to the public for any price they wanted.

 They chose the price of zero dollars and zero cents.

 For much of 2021, the most cutting-edge biotechnology in America was also the cheapest therapy in the world.

 The single most important thing that Operation Warp Speed did was to provide a whole-of-government urgency to the goal of rapid deployment, Caleb Watney, co-founder of the Institute for Progress, said.

 Getting everything right meant you needed to make a million correct decisions in the right order.

 If the government had bet only on traditional vaccine technology, we would have had no mRNA therapies.

 If the government hadn't done extensive supply chain mapping in the summer of 2020, the initial vaccine rollout might have taken months rather than weeks.

 And if the government hadn't bought out vaccines from the pharmaceutical companies, they wouldn't have been free to consumers.

 But because Operation Warp Speed did all this, the vaccines were expeditiously approved, manufactured, and distributed at no cost to the public.

 In all, the U.S. government spent less than $40 billion to develop, produce, and buy mRNA COVID vaccines.

 It might be one of the best bang-for-buck policies in U.S. history.

 COVID vaccines prevented up to 20 million excess deaths worldwide, with several million of those saved lives directly attributable to the acceleration of the Pfizer and Moderna vaccines.

 Tens of millions of hospitalizations were prevented by the further prevention of severe disease.

 One analysis by three U.S. economists estimated that the lives saved in just the eight months of the vaccinations were worth $6.5 trillion.

 Stacked up against more popular American programs, such as the Apollo program, Warp Speed's accomplishment shines even brighter.

 For all the wondrous drama and exploratory genius of touching a human foot to moon dust, the Apollo missions did not directly save any lives or unveil any new technologies, even as they accelerated the development of computer chips and related fields.

 Americans love to take credit for their accomplishments, so one might expect that Warp Speed would receive universal adulation today.

 Quite the opposite, however.

 Warp Speed has been practically abandoned by both parties.

 In January 2021, the incoming White House announced it would rename the program.

 Rather than officially rename it, they basically stopped talking about it.

 Democrats rarely credit or mention Operation Warp Speed perhaps because they're reluctant to be caught lavishing praise on anything that bears the fingerprints of Donald Trump.

 Meanwhile, Republicans, including Trump himself, rarely celebrate the vaccines because much of the party is populated by anti-vax conservatives who refused to take the shot and came up with wild conspiracy theories to discredit its effectiveness.

 When Trump won re-election in 2024, he named Robert F.

 Kennedy Jr., perhaps the nation's most famous vaccine skeptic, to lead the Department of Health and Human Services.

 Operation Warp Speed is the oddest political orphan.

 A program named after Star Trek has disappeared into its own kind of black hole.

 A policy that stimulated the economy more than the Apollo program and which may have saved more lives than the Manhattan Project, has almost no loud champions in politics.

 Even its scarce champions seem intent on taking the wrong lessons from its success.

 In an essay for the Wall Street Journal, the University of Chicago professor Casey B. Mulligan, who had served as chief economist for the Trump White House, claimed that the urgent lesson from Operation Warp Speed was that too much government hinders private innovation.

 But OWS increased government spending by billions of dollars.

 With an urgency typically reserved for war, the federal government directed the development of vaccines from their testing to their final transport.

 It's odd to claim that a program that expanded government powers succeeded by proving that one should never expand government powers.

 The right lesson from World War II and Warp Speed is that the state is no enemy of invention or innovation.

 In fact, the government can accelerate both.

 In the 1940s, the Office of Scientific and Research Development mapped out the chemistry and production challenges for penicillin and turned an obstacle course into a glide path.

 In 2020, the U.S. government similarly identified the bottlenecks to rapid vaccine development and removed them.

 In both cases, the government served as a chief national problem solver, molding its policies to fit the moment.

 It is a vision of a new kind of entrepreneurial state.

 It is the government as a bottleneck detective.

 The Bottleneck Detective The U.S. faces complex challenges in housing, energy, science policy, invention, and innovation.

 Solving them must begin with the appreciation that these are different industries with different constraints enmeshed in different markets.

 Figuring out how to build more apartments in Los Angeles might not be relevant to the problem of adding solar energy in Massachusetts, which has nothing to do with the question of how to accelerate scientific discovery in cancer.

 To be a bottleneck detective is to recognize that wise policy begins with an investigation rather than an ideology that tries to force the same key into a variety of ill-fitting locks.

 Making progress in these industries requires first that we want to understand, how does this industry actually work?

 From that question can emerge an agenda for overcoming the barriers to growth.

 Sometimes, being a bottleneck detective is about removing restrictions that shouldn't exist.

 The U.S.

 has fewer primary care physicians as a share of its population than almost any other rich country, despite having the world's most expensive healthcare system.

 This shortage is partly by design.

 In the early 1980s, a special committee established to review the state of American medicine reported to the U.S. Department of Health and Human Services that the U.S.

 was on the verge of a massive surplus of doctors.

 Physician groups backed up the finding.

 The size of medical schools must be diminished, Charles Everts, the president of the American Orthopedic Association, said in a 1985 speech.

 Certain programs need to reduce their numbers, others must consolidate, and others need to terminate voluntarily or be terminated.

 Starting in the 1980s, the government cut its support for medical schools and medical students, and many universities agreed to freeze the number of new studies and stop construction on medical programs.

 Between 1980 and 2005, the number of medical school matriculants essentially flatlined as the U.S.

 added 70 million people.

 This policy of deliberate scarcity succeeded, and the inevitable result was a scarcity of doctors, especially those like primary care physicians who make the least money.

 Years later, the U.S.

 is still digging out from under the moratorium.

 Fixing this problem is eminently within the powers of the federal government.

 The first thing I would do is to expand the residency system so that more doctors can become residents after medical school, Robert Orr, a policy analyst who studies health care policy at the Niskanen Center, said.

 This might be the key bottleneck.

 The medical schools say they can't easily expand because there aren't enough residency slots for their graduates to fill.

 But there aren't enough residency slots because Washington has purposefully limited federal residency financing.

 The arithmetic is simple.

 More funding means more residents.

 Accepting more residents allows medical schools to grow.

 More medical students today means more doctors in a decade.

 Being a bottleneck detective isn't just about removing things that don't work.

 Sometimes, it's about creating entirely new programs that don't exist but should.

 Imagine somebody is trying to build a new kind of rocket and you're the czar of rocket innovation policy at the Department of Defense.

 You have $1 billion that you can use to accelerate the invention.

 There are several things you can do.

 You can give the company $1 billion as a simple grant.

 Here, have the money for nothing.

 You can make it a loan.

 Pay me back later plus interest.

 You can create a so-called loan guarantee.

 If you default to the $1 billion loan, I'll pay back the lender in full.

 These are all examples of push funding because the upfront money pushes forward innovation.

 But there is another, very different way to use that $1 billion.

 You can dangle a reward if the rocket company meets some target, say, the construction of three new rockets.

 As opposed to push funding, this is called pull funding.

 If push funding pays for effort, pull funding pays for success.

 Warp Speed used both.

 With push funding, it covered the early expenses of several vaccine makers.

 With pull funding, it promised to buy a certain number of vaccine doses, provided that the therapies received FDA authorization.

 Pull funding is efficient because it only pays out if the technology pans out.

 It's effective because it solves a common bottleneck in new technology.

 Demand uncertainty.

 Some companies are rightly concerned that consumers cannot afford the early, expensive versions of a product.

 These companies need more certainty about future profits to invest in the final stages of invention.

 For example, pneumococcal disease has been the world's most common form of bacterial pneumonia and one of the leading causes of child mortality in low-income countries.

 But for years, pharmaceutical companies seemed reluctant to invest in a vaccine for African strains of the disease, in part because they assumed its countries couldn't afford the medicine at full price.

 In 2007, the Bill and Melinda Gates Foundation joined several nations to offer pharmaceutical companies a deal.

 Make a pneumococcal vaccine for low-income countries and we'll pay you $1.5 billion to produce it at volume.

 The promise of future funding proved astonishingly effective.

 By 2020, several companies had developed the vaccine and hundreds of millions of doses were purchased and distributed around the world.

 By one estimate, the vaccine saved 700,000 lives.

 This policy, a promise to buy a certain number of early products to accelerate their invention, is called an Advanced Market Commitment, or AMC.

 An AMC is particularly effective when the world needs an abundance of a brand new technology that is currently too expensive.

 For example, pharmaceutical firms assumed that African buyers wouldn't pay back their investment in vaccines, so the commitment to pay for millions of doses unlocked an invention that otherwise wouldn't exist.

 This AMC model could unlock other inventions.

 One of the most devilish challenges in energy is how to efficiently remove carbon dioxide from the atmosphere.

 By 2050, the world will need to permanently remove 10 billion tons of carbon dioxide from the skies every year to avoid the most catastrophic effects of climate change.

 But in all of history, only 10,000 tons of carbon dioxide have been technologically removed, one million times short of what we'll need to do every year.

 In 2022, Nan Ransihoff, the head of climate policy at the payment company Stripe, launched Frontier, an AMC that raised $1 billion to pay any company that develops carbon removal technology that meets a high level of efficiency.

 The initiative has already encouraged more carbon removal companies to jump into the race.

 One survey found that of all the firms that have launched since Frontier began, 7 in 10 say Frontier's launch was key to their founding.

 If we eventually hit big with carbon vacuuming machines that save the world from climate change, it might very well be due to policies that guarantee a return for the best early technologies.

 Looking forward, AMCs could be used for a range of futuristic ideas.

 Staying in the realm of climate tech, AMCs could accelerate the development of clean cement.

 The traditional manufacture of cement is a major contributor to climate change.

 Every year, the world produces about 4 billion tons of cement to make concrete and other binding agents.

 By most estimates, cement is responsible for 8% of the world's carbon dioxide emissions.

 If it were a country, cement would be the third biggest carbon emitter on the planet, the New York Times journalist David Wallace-Wells wrote.

 Cement poses a unique challenge to decarbonization.

 Cleaning up electricity is conceptually simple.

 It's possible to power an electric car battery with wind or to run air conditioning with electricity from solar energy.

 But the cement manufacturing process is different.

 Making cement requires converting limestone, calcium carbonate, into quicklime, calcium oxide, by heating it to about 1,500 degrees Fahrenheit.

 This is a double whammy for carbon dioxide emissions.

 Not only does that level of heat often require burning fossil fuels like coal, but also the chemical reaction automatically produces carbon dioxide as a byproduct.

 To make traditional cement without releasing an enormous amount of carbon dioxide simply isn't possible.

 As billions of people transition to urban living in the coming decades, demand for cement will only grow.

 The problem cannot be simply wished away.

 It's not realistic to demand that the entire planet stop building things.

 The only truly global solution is invention.

 There are several technological paths here.

 We can build machines and systems to scrub up the carbon released from the chemical process that makes calcium oxide.

 These carbon capture technologies would trap emissions at the source, preventing them from entering the atmosphere.

 Another possibility is to replace limestone as the rock source of cement with a new material.

 Maybe we don't need to use limestone at all, says the climate policy author Hannah Ritchie.

 If we use a source rock that doesn't emit carbon, then there's nothing to scrub up.

 Several companies are innovating with alternate rocks to produce cement-like products, such as basalt, the most abundant surface rock on Earth, and calcium silicate, which produces the key ingredient of cement, calcium oxide, without releasing carbon dioxide in the process.

 The few companies that are working on lower-emission cement replacements face significant bottlenecks in terms of cost and scale.

 That could make them prime candidates for pull funding.

 Cement could be perfect for an AMC because the government already buys 40% of U.S. cement and suppliers don't know who will pay high prices in the short run, Ranserhoff said.

 We need a policy to move it down the cost curve.

 If the U.S.

 pledged to buy several billions of dollars worth of affordable green cement, it could encourage investors and entrepreneurs to pour more time and treasure into its development.

 The upfront funds could help green cement companies expand their production facilities.

 As Wright's law works its magic, the cost of producing low-carbon cement would decline over time.

 The result would optimistically be a win-win-win-win.

 The startups would get funding.

 The public would get cleaner infrastructure.

 The treasury would protect taxpayers by only paying for success.

 And the climate would get a reprieve from carbon-coughing cement.

 The most important lesson of AMCs is that they make government a more active agent of invention by identifying bottlenecks in public demand and filling them.

 The U.S.

 often makes financial commitments contingent on failure, like loan guarantees which pay a lender in the event of a default, said Thomas Kalil, the former deputy director for technology and innovation in the White House Office of Science and Technology Policy.

 But we don't make enough financial commitments contingent on success, like a prize or advance purchase order.

 Operation Warp Speed did it very successfully.

 We should be looking for many more opportunities to identify what's holding back the invention and implementation of the most important technologies of the future and dangle prizes and purchase orders to pull them closer to the present.

 Artificial intelligence might be the most important technology of the decade.

 In the last few years, tech firms have spent hundreds of billions of dollars to build machines that can carry out a dizzying array of tasks, writing essays and code, reading thousands of pages in seconds, carrying on fluent conversations, and even producing animated movies.

 AI has not transformed the U.S. economy in the hour that we're writing these words.

 But things are moving fast enough that it is impossible to predict what effect AI will have had by the time you've heard them.

 For all the uncertainties about AI's larval potential, one thing is very certain.

 Its development will require a gigantic amount of energy.

 The computational intensity of training artificial intelligence consumes significantly more power than other computer systems.

 Data centers that house AI hardware are projected to triple their share of total American energy use in the next decade.

 And AI is already wreaking havoc on U.S. power systems, Bloomberg reported in 2024.

 The biggest tech firms, like Microsoft and Alphabet, have pledged to run their data centers on low-carbon energy.

 But these promises are smashing up against America's inability to build clean energy fast enough.

 So tech companies are hunting for electricity in surprising places.

 In March 2024, Amazon agreed to buy energy from the Susquehanna nuclear power plant in Pennsylvania to power its data centers.

 In September, Microsoft made a deal to buy the entire electricity output of the last working reactor of the Three Mile Island nuclear plant, which suffered a partial meltdown in 1979.

 Buying power from existing power plants is a short-term stopgap, but it's not a long-term solution.

 New nuclear power plants can take years, even decades, to complete.

 The AI revolution makes the cause of energy abundance even more urgent.

 In the last few decades, U.S. energy infrastructure projects have been slowed by all the challenges we've described.

 A lack of productivity in construction, permitting blockages, extended environmental reviews, and long interconnection queues.

 These bottlenecks are largely self-made, and if we don't make it easier for AI companies to build in America, we should expect them to build data centers abroad.

 Some AI executives have met with Gulf state leaders about citing data centers in the Middle East.

 In the next few decades, trillions of dollars of AI infrastructure could be built somewhere in the world.

 The biggest question is where?

 If the U.S.

 fails to add energy supply in the U.S., the results could be chaotic, at best, and catastrophic, at worst.

 As new data centers demand more energy, electricity prices would rise for consumers in the absence of supply growth.

 More troublingly, it's conceivable that AI researchers are years, not decades, away from building a superintelligent system with the ability to hack foreign government secrets, cripple their military software systems, and partly collapse the energy grids of adversaries.

 This would be a breakthrough akin to a kind of digital nuclear bomb.

 Do we really want the infrastructure for the Manhattan Project to be controlled by some capricious Middle Eastern dictatorship?

 The AI researcher Leopold Aschenbrenner wrote in his 2024 manifesto, Situational Awareness.

 It is paramount, he said, for the U.S.

 to prioritize energy construction in the next decade.

 America sorely regretted her energy dependence on the Middle East in the 70s, and we worked so hard to get out from under their thumbs.

 We cannot make the same mistake again.

 An abundance of cheap and clean electricity would provide broad benefits even if AI didn't pan out.

 Abundant energy would reduce electricity bills for households.

 It would make other futuristic technologies that need ample power more feasible.

 For example, desalination facilities that turn salt water into drinkable water might be necessary to sustain populations in the American Southwest in this century.

 This technology is extremely energy intensive.

 In Israel, one of the world's leaders in desalination, desalination accounts for about 3% of the country's total energy consumption.

 In this light, energy abundance is not strictly speaking a data center policy or an AI policy.

 It is an all-purpose national affordability policy and an innovation policy.

 Simply put, energy abundance might be the single most important technological bottleneck of our time.

 20 years from now, it is possible that we will consider the combination of clean energy growth and AI the most important technology story of the decade.

 In 2024, Sam Altman, the chief executive and co-founder of OpenAI, framed our ability to make artificial intelligence in dramatic terms.

 After thousands of years of compounding scientific discovery and technological progress, he wrote, we have figured out how to melt sand, add some impurities, arrange it with astonishing precision at extraordinarily tiny scale into computer chips, run energy through it, and end up with systems capable of creating increasingly capable artificial intelligence.

 Our breakthroughs in energy are no less mythic.

 After thousands of years of scientific discovery and technological progress, we have figured out how to turn the most elemental functions of nature, the sun's light, the wind, the heat beneath the earth, into a swarm of electrons that can run our machines and power our lives.

 The direction of progress in the 21st century might depend on America's ability to merge these breakthroughs, AI and clean energy, melted sand and swarming electrons, to bring broad prosperity and peace rather than the opposite.

 Doing so requires at least that U.S. policy has a say in directing AI, and that means building AI and its energy source here in America, where it was invented.

 Focus is a choice.

 When we asked Paul Mango to name the single most important part of Operation Warp Speed, he said it was focus.

 On the Warp Speed team, you could have asked anyone what the project's goal was, from the generals and leaders down to the lowest ranking officials, and they would all give the same answer.

 Deliver at least one safe and effective vaccine manufactured at scale before the end of the year, he said.

 Every decision we made was based on those constraints.

 The health crisis served as a focusing mechanism, a way of taking the tangles of competing priorities and rightening them into a straight thread.

 A regrettable feature of history is that progress often requires the focusing mechanism of disaster.

 Penicillin took a world war and mRNA vaccines took a plague.

 The Federal Reserve was created only after a string of financial disasters culminating in the Panic of 1907.

 The tragedy of the Great Depression allowed for the boldness of the New Deal.

 The Nazi domination of Europe galvanized the creation of the Office of Scientific Research and Development.

 The Soviet Union's successful launch of Sputnik in 1957 moved Washington to create the Advanced Projects Research Agency, later renamed DARPA, which contributed to the invention of the personal computer, GPS, and drone technology.

 It also pushed the U.S.

 to expand NASA and eventually launch the Apollo program.

 Again and again in American history, we seem to be at our very best when things are at their very worst.

 This is a depressing thought.

 One interpretation might be that we are doomed to sleepwalk through history until a catastrophe jolts us into action.

 But there is comfort in the connection between perceived crisis and urgency.

 If crisis is the ultimate push-and-pull mechanism, both galvanizing action and rewarding success, we must remember that it is always up to us to decide what counts as a crisis.

 In an alternate history of the 20th century, the launch of Sputnik might not have led the U.S.

 to do anything.

 After all, there was no real existential danger posed to any American by a metal box floating in orbit.

 Surely, if France or Britain had by some miracle managed to launch the first object into space, it wouldn't have caused much geopolitical angst in America.

 But the U.S.

 government determined that because Sputnik was a Soviet instrument, the achievement was a crisis that required a response.

 And in that crucible of insecurity and inspiration, the U.S.

 created a set of institutions that ultimately put a man on the moon and the Internet in our pockets.

 The moon race is remembered today as a necessary and broadly popular response to the Soviet threat.

 But one of the most misunderstood aspects of the space race is that the Apollo program survived because of political persistence, not because of its popularity.

 In its brief history, the moon mission pulled poorly.

 A 1965 Gallup survey found that only 39% of Americans thought that the U.S.

 should do everything possible, regardless of cost, to be the first nation on the moon.

 A majority of Americans consistently told pollsters that the Apollo missions weren't worth the cost, with up to 60% saying the government was spending too much on space.

 At one point, President John F. Kennedy, who famously said, we choose to go to the moon in this decade and do the other things, not because they are easy, but because they are hard, told NASA chief James Webb, I'm not that interested in space.

 A majority of Americans supported the lunar missions only once in the 1960s, in a poll taken just after Neil Armstrong's televised landing.

 One lesson of Apollo's surprising unpopularity is that the program was sustained by leaders within NASA and the White House, which never pulled the plug on an audacious task that pulled poorly among the public.

 Kennedy was right when he said, we choose to go to the moon.

 So did we choose to pass the New Deal, just as we chose to build OSRD, just as we chose to invent the bones of the internet in a government lab, just as we chose to break the record for vaccine development during a pandemic.

 Yes, crisis is a focusing mechanism, but leaders define what counts as a crisis, and leaders are the ones who choose to focus.

 The U.S.

 could announce a warp speed for heart disease tomorrow on the theory that the leading cause of death in America is a national crisis.

 We could announce a full emergency review of federal and local permitting rules for clean energy construction, with the rationale that climate change is a crisis.

 The U.S.

 could decide that the major diseases afflicting developing countries, such as malaria, deserve a concerted global coalition to eradicate them within a decade.

 Even in times without world wars and pandemics, crises abound.

 Turning them into national priorities is, and has always been, a political choice.

 In the last half century, we have made several choices about invention and implementation and science and technology.

 We have chosen to create a system that rewards caution and punishes outsider thinking and risk in scientific research.

 We have chosen to embrace a political economy that encourages offshoring the development of American inventions that are key to our national security and flourishing.

 None of this was inevitable.

 These policies are the fruits of human decisions.

 They are artifacts of our rightly picked world.

 Breakthroughs often involve a flash of luck, even when they follow decades of painstaking labor.

 The historian James Finney Baxter III called penicillin the blue mold which blew in through Fleming's window on that happy breeze.

 Many scientific breakthroughs, similarly shock their discoverers, blowing in sideways through proverbial windows.

 Few people expected synthetic mRNA, an idea that had languished in the wilderness of academia, to match up so perfectly with the spiky crowns of a novel coronavirus.

 The serendipity of science is one reason why it's so important to untether research from politics and allow scientists to seek the truth freely without spending half their time deluged by bureaucratic paperwork and paralyzed by fear that their ideas might diverge from the moment's conventional wisdom.

 But the next stages of technology are not about luck.

 Building, deployment, and implementation are not the stuff of happy breezes.

 They require deliberate acts, laws, and policies.

 They require choices.

 For too long, the U.S.

 has been enthralled by the Eureka myth, the idea that flashes of individual genius are the most important moments in the history of technology.

 This mindset governed our approach to economic growth in the last 40 years.

 In the next generation, the U.S. needs a plan to build what it invents.

 Conclusion Toward Abundance Politics is a way of organizing conflict, and so our attention is naturally drawn to divisions.

 That is particularly true now when the divisions are so fundamental.

 The Democratic and Republican parties do not merely disagree over the details of tax policy.

 They disagree over the legitimacy of elections, of institutions, of the structure of American government.

 They are split in their views of speech and history and decency and truth.

 Distinguished scholars write books considering the nearness of another civil war and wondering whether fascism is resurgent on American soil.

 The polarization of the 1990s feels quaint against the chasmic conflict of the 2020s.

 These divisions are real.

 They are dangerous.

 But behind them is the murky outline of something very different.

 Perhaps a path out of the morass we're in.

 A new political order.

 The term political order is the coinage of Gary Gerstle, an American historian and a professor at Cambridge University.

 Many historians focus on how Republicans and Democrats have fought and disagreed over the years.

 Gerstle's work focuses instead on how hidden points of consensus between the parties create distinctive periods of history which he calls political orders.

 He defines a political order as a constellation of ideologies, policies, and constituencies that shape American politics in ways that endure beyond the two, four, and six-year election cycles.

 Two such constellations have extended across the last hundred years of American history, according to Gerstle.

 The New Deal order rose in the 1930s and collapsed in the 1970s.

 The Neoliberal order rose in the 1970s and declined in the 2010s.

 The New Deal order brought the agreement that the federal government must take an active role in managing the American economy and protecting workers.

 Begun under Franklin Roosevelt, a Democrat, it continued under Dwight Eisenhower, a Republican, who endorsed its basic framework.

 Rather than rail against big government programs, Eisenhower signed legislation to create the interstate highway system.

 Rather than bemoan welfare, he celebrated its growth.

 We want a broader and stronger system of unemployment insurance, Eisenhower said, sounding much more like a Democrat from the 2020s than a Republican of the 1980s.

 Why did Eisenhower and the GOP of his era acquiesce to the New Deal order?

 It had far less to do with Eisenhower the man than with the geopolitical situation in which the new president and his party had been thrust, Gerstel writes.

 The Cold War wasn't just an arms race or a military conflict with the Soviet Union.

 It was a competition over whose philosophy of government would produce the best outcomes for people.

 Eisenhower needed to prove that he could take better care of his ordinary citizens than the leaders of Soviet communism could provide for theirs.

 That meant embracing the policies of Roosevelt and the Democrats who had succeeded in raising America's living standards after the Great Depression.

 In the 1970s, the New Deal order collapsed beneath the weight of crises it could not contain, stagflation and the Vietnam War most notably.

 But there was more to it than that.

 Abroad, the horrors and absurdities of communism became clearer.

 At home, millions of oppressed Americans marched, sat in, and organized for rights.

 A change in values took hold.

 The promise of collective action lost its luster.

 Nurturing the dignity and genius of the individual in the face of regimes that seemed to squelch both became the reigning ethos.

 A new kind of individualism was ascendant, and not just on the right.

 The New Deal Democrats found themselves challenged by the new left.

 We seek the establishment of a democracy of individual participation governed by two central aims, read the Port Huron statement, a left-wing student activist manifesto written in 1962.

 That the individual share in those social decisions determining the quality and direction of his life.

 That society be organized to encourage independence in men and provide the media for their common participation.

 Policy is downstream of values, and by the 1970s, Washington was a changed place.

 Jimmy Carter, a Democrat, deregulated large parts of the economy, including the trucking and airline industries.

 In the 1980s, Ronald Reagan slashed the high tax rates that Harry Truman had imposed and that Dwight Eisenhower had kept.

 Much of even the liberal legislation of the age, including the major environmental bills we've discussed throughout this book, worked by centering the individual, making it easier for Americans to slow the government by suing it.

 The Soviet Union collapsed, proving the supremacy of the American model.

 Bill Clinton emerged as the Eisenhower to Reagan's FDR, cementing the principles of a once radical presidency into a political order.

 Clinton said the era of big government was over, and he proved it.

 He did what Reagan had only promised to do and slashed the federal budget while deregulating the financial and IT sectors.

 When the spell of a political order breaks, ideas once regarded as implausible and unacceptable become possible and even inevitable.

 This happened in the 1930s, when the Great Depression created space for the rise of Roosevelt's social-democratic collectivism.

 It happened in the 1970s, when an upswing of individualism changed the way people thought about taxing and spending, regulating the economy, and managing our relationship to the environment.

 It may be happening again.

 We are in a rare period in American history when the decline of one political order makes space for another.

 The crack-up was decades in the making.

 It started with the Great Recession, which shattered a broad belief in deregulated markets.

 The climate crisis revealed how much the profit motive missed.

 The aftermath of normalizing trade with China proved that the profits of free trade understood neither China nor America.

 Throughout the 2010s, a slow economic recovery fueled public resentment of inequality, and an affordability crisis gathered steam.

 In 2020, the pandemic obliterated many Americans' trust in government or what was left of it.

 And between 2021 and 2024, inflation brought national attention to our interlocking crises of scarcity, supply, and unaffordability.

 For years, the boundaries of American politics had felt fixed, even settled.

 But now they are falling.

 For a political order to triumph, it must have a narrative, a story it tells about the good life, Gerstel says.

 Today's politics are suffused with cynicism and pessimism about government because a way of living sold to us as good and achievable is no longer good or no longer achievable.

 In 2016, the rise of Bernie Sanders on the left and the rise of Donald Trump on the right revealed how many Americans had stopped believing that the life they had been promised was achievable.

 What both the socialist left and the populist authoritarian right understood was that the story that had been told by the establishments of both parties, the story that had kept their movements consigned to the margins, had come to its end.

 Transitions between orders are provoked by crises that can feel like derangements.

 As the tectonic plates of American politics shift, once settled questions reopen and once unthinkable answers vie to become a new consensus.

 One way of understanding the era we're in is as the messy interregnum between political orders, a molten moment when old institutions are failing, traditional elites are flailing, and the public is casting about for a politics that feels like it is of today rather than of yesterday.

 A fork in the road, scarcity or abundance?

 This may be the moment for politics of abundance, but the arc of history does not always bend toward our beliefs.

 There is no guarantee that the next political order will align with our values.

 Its opposite is just as likely.

 The politics of scarcity can be seductive.

 When there is not enough to go around, we look with suspicion on anyone who might take what we have.

 In the 2024 election, J.D.

 Vance spoke often of the inadequacy of housing supply, which he wielded as a cudgel against immigrants.

 Illegal aliens competing with Americans for scarce homes is one of the most significant drivers of home prices in this country, he said in the vice presidential debate.

 Donald Trump sounded the same themes.

 Voters cannot ignore the impact that the flood of 21 million illegal aliens has had on driving up housing costs, he warned.

 Right-wing populism seeks power by closing doors, halting change, and venerating the businesses and dominance hierarchies of the past.

 Scarcity is its handmaiden.

 So, too, is the sense that governments today are weak and corrupt, and therefore that strong men are needed to see the world clearly and deliver on democracy's failed promises.

 Liberals might detest the language that Trump and Vance use to demonize immigrants, but Blue America practices its own version of scarcity politics.

 Zoning regulations in liberal states and cities that restrict housing supply have increased costs far more than the recent influx of immigrants.

 These restrictions exacerbated an affordability crisis that was harnessed by the right.

 Thus, the mistakes of liberals contributed to the rise of illiberalism.

 The tendency to turn against outsiders in the face of critical shortages is not restricted to a basket of deplorables, Jerusalem Demsis wrote in The Atlantic.

 It's in all of us.

 Most people see others as a threat to their resources, whether it's immigrants coming for your housing, yuppies pushing up rents, other students taking slots at all the good schools, or just more people on the road adding to congestion.

 As the chronic housing shortage and affordability crisis destabilized the reigning political order internally, America's greatest external threat has been the rise of China, a superpower that many now fear and even envy.

 How could they build so much as we struggle to complete even simple projects?

 As sluggishness and process came to feel like the defining features of American governance, it became common even at the heights of American power to hear China's speed and capacity spoken of wistfully.

 Sit and watch us for seven days.

 Just watch the Senate floor, Senator Michael Bennett said in 2010.

 You know what you'll see happening?

 Nothing.

 When I'm in the chair, I sit there thinking, I wonder what they're doing in China right now.

 China has been the great shadow pressure on American politics over the past two decades.

 The confidence brought by the fall of the Soviet Union has been replaced by a fear that China has learned what we've forgotten.

 In Washington, a consensus began to crumble.

 Republicans and Democrats alike had been too complacent about what China's rise meant for American workers and too certain that a richer China would embrace American values.

 But the blindness was not just about what China was capable of.

 It was also about what America was losing the capacity to do.

 It's no accident that the most forceful challenge to this miasma of complacency and fear came from Donald Trump, a builder whose economic appeal centered around an obsession with manufacturing jobs and a deep suspicion of trade.

 America's political and economic class had ceased to see the value in making things.

 Workers were told to learn how to code even as Washington kept proving that America had forgotten how to build.

 Trump didn't care whether you knew how to code, but he seemed viscerally disgusted that America couldn't build as it once could, and that it didn't value the people who'd once done that work.

 I've been talking about China for many years, and you know what?

 Nobody listened, Trump said in 2016, but they are listening now.

 That I can tell you.

 The temperament needed to shatter a consensus does not often coexist with the judiciousness and patience needed to build something better in its place.

 Trump slapped tariffs on China and called COVID the Kung Flu, but he did little to solve the problems he ran on.

 He promised one infrastructure week after another without ever passing an infrastructure bill.

 Trump understood the dark side of competition, but he never understood the possibilities of cooperation.

 To the surprise of many, Joe Biden, as thorough a creature of the Washington establishment as has ever held the presidency, accepted many of Trump's premises.

 He kept Trump's anti-China tariffs and added more.

 He barred the export of key technologies to China.

 He never sought to revise or revisit the Trans-Pacific Partnership trade deal that the Obama administration had negotiated, which would have reduced trade barriers between the U.S. and several countries on either side of the Pacific Ocean.

 Biden even seemed to accept the way that Trump saw China's manufacturing supremacy as an indictment of the American spirit.

 Somewhere along the way, we stopped investing in ourselves, Biden said in 2021.

 We stopped investing in our people, and we've risked losing our edge as a nation.

 I don't even think it was conscious, but that's just what happened.

 And China and the rest of the world are moving to catch up, and in some cases, in certain areas, move ahead.

 Under Trump, infrastructure week was a meme.

 Under Biden, it became an ethos.

 In his four years in office, Biden put his name to several laws that broke with the anti-build trend of modern politics.

 With the bipartisan infrastructure bill, he signed the largest authorization of infrastructure spending since the Interstate Highway Program of the 1950s.

 With the Chips and Science Act, he announced America's intention to invest billions of dollars in scientific discovery and invention, and tens of billions more to build advanced computer chips within our borders.

 With the Inflation Reduction Act, the U.S.

 passed the largest clean energy bill in its history, with record investments in electric vehicles, batteries, solar and wind manufacturing, and next-generation climate technology, such as carbon removal plants.

 The core of this agenda, subsidies for computer chips and clean energy, historic investments in infrastructure, used the spur of China to get America building and manufacturing at home again.

 As in the 1930s and again in the 1970s, external threats and internal crises are converging and making possible a new kind of politics.

 Abundance Emerging This book has offered a critique of the ways that liberals have governed and thought over the past 50 years.

 It also reflects an opportunity open to liberals now.

 Donald Trump won the 2024 election in part because of the failures of present-day liberalism, but that is very different from saying that he won by offering a compelling vision for America's future.

 Trump could have run on bringing the Texas housing miracle to the nation.

 Instead, he ran on closing the border.

 He could have run on the success of Operation Warp Speed.

 Instead, he has disowned it as his coalition has rebuilt itself around skepticism of scientists and vaccines.

 Elon Musk has led some of the most innovative companies of the modern era, but according to the earliest reports of his role in Trump's government, he is focused on slashing what government does, rather than reimagining what it can do.

 The right is abandoning many of its successes to embrace a politics of scarcity.

 That has left room for liberals to embrace what Republicans have abandoned, a politics of abundance.

 In fact, there are signs that they already are.

 We see it in the rise of the Yes in My Backyard, or YIMBY movement, a motley collection of housing obsessives who went from haranguing officials at public hearings in San Francisco to wielding influence nationally.

 Democratic governors across the nation have passed bill after bill trying to make it easier to build homes.

 In the 2024 election, one of Kamala Harris' first policy proposals was to build 3 million new homes, a supply-side policy that reflected a decade of persuasion and organizing by liberals who'd come to see the suffering that housing scarcity was causing in their cities.

 We see it in the climate movement, which helped persuade the Biden administration to pass a slew of bills intended to expand the supply of clean energy and pull forward needed innovations like green hydrogen.

 Environmentalists realized that sacrifice and scarcity was a losing politics.

 They needed a strategy that married the life Americans want with the clean energy the planet could tolerate.

 Investments in solar and wind installation, in electric vehicle plants, and factories to manufacture next generation batteries have rocketed upwards since.

 But none of this will be easy.

 In California broadly, and San Francisco specifically, dozens of pro-housing bills have not led to the construction of more homes.

 In part because those bills are layered with additional requirements and standards that builders must meet in order to take advantage of the newly streamlined processes.

 For developers we spoke to, the added cost of compliance weren't worth it, so the legislation hadn't led them to build any new homes at all, much less build them faster.

 The breakneck deployment of wind and solar infrastructure and battery manufacturing has been slowed by outdated permitting and procurement rules that split the Democratic coalition.

 A difficulty that Biden and Harris had in trying to run on their record in 2024 was that few communities were yet seeing benefit from all this construction their policies were meant to spark.

 The infrastructure bill, for example, included $7.5 billion to build a national network of 500,000 electric vehicle charging stations.

 By March 2024, more than two years after the bill was passed, only seven new chargers were up and running.

 The bitter irony is that Trump and the Republicans might benefit from legislation Biden and the Democrats passed simply because the government spends and builds so slowly so the changes Biden promised will now happen on Trump's watch.

 The word abundance speaks of a cornucopia, all good things for everybody.

 But the world of abundance has trade-offs, and trade-offs require choices.

 Liberals spent decades working at every level of government and society to make it harder to build recklessly.

 They got used to crafting coalitions and legislation that gave everyone a bit of what they wanted, even if it meant the final product was astonishingly expensive, or slow to construct, or perhaps never found its way to completion at all.

 To unmake this machine will be painful.

 It will require questioning treasured nostrums and splitting old alliances.

 It will also require opposing visions of scarcity that are gaining adherence on the left.

 The values of the de-growther movement have gained momentum among Western intellectuals.

 The environmental devastation that has accompanied modernity seems like an equation with an obvious solution.

 If this is what progress has wrought, then regress is necessary.

 If this is the cost of going forward, then we must go backward.

 In its strongest versions, this philosophy is too politically impractical to gain many adherents or wield much power.

 But its weaker manifestations are everywhere and have been since small is beautiful became a rallying cry in the 70s.

 Comparatively, abundance is a return to an older tradition of leftist thought.

 In the Communist Manifesto, Karl Marx and Friedrich Engels acknowledge that capitalism was superior to its predecessor, feudalism, at producing goods and wealth.

 The bourgeoisie, during its rule of scarce 100 years, has created more passive and more colossal productive forces than have all preceding generations together, they wrote.

 They did not want to end this revolution in production.

 They wanted to accelerate it.

 Just as feudalism blocked production that only capitalism could unleash, so did capitalism constrain an abundance that a new paradigm might unleash.

 Core to this analysis of the economy was an idea that has come to be called the fettering of production.

 Marx observed that many companies' obsession with profit kept the entire economy from exploring ideas that threatened incumbent margins or failed to produce immediate returns.

 Among capitalism's many sins, Marx wrote, was that it prevented the most wondrous and useful technology from being invented and deployed in the first place.

 An economy run amok with useless fettering serves the rich few at the expense of the poorer many.

 Marx's aim was not to turn the production machine off, but to direct its ends toward a shared abundance, to unburden the forces of production and make possible that which had been impossible to imagine.

 There is much he got wrong, but one need not be a communist to see the wisdom in this analysis.

 A Lens, Not a List We considered calling this book The Abundance Agenda.

 We could have easily filled these pages with a long list of policy ideas to ease the blockages we fear.

 On housing, for example, cities should reform their zoning laws to make it easier to build homes and apartments of all sizes, legalize the construction of accessory dwelling units, reduce parking requirements, and pass new laws to create maximum permitting wait times.

 Stopping individuals or developers from building places for people to live on land they own should require unusual cause.

 Building homes at a time when housing is scarce should not.

 The political economy of those ideas is fraught.

 It requires passing law after law in city after city.

 Today's housing policies are exquisitely local, which would be appropriate if housing policy was bound to ground by city limits.

 But the consequences of housing policy reverberate across states and even across the nation.

 Gate the great cities of California and families flee to Texas and Arizona.

 When you allow housing to become scarce where the wages are highest, you shut down a powerful engine that long kept social mobility in America high.

 So what level of government and of society is appropriate for housing policy?

 Should it be run by states?

 By the federal government?

 This is where the shortcomings of a list of policy proposals become clear.

 It is easy to unfurl a policy wish list.

 But what is ultimately at stake here are our values.

 How do we weigh the role that the current inhabitants of a community should have in who enters that community next?

 How do we balance the interests of a town against the interests of a country?

 Changing the processes that make building and inventing so hard now requires confrontations with whether the systems liberals have built really reflect the ends they've sought.

 Much that was designed to foster grassroots participation has been captured by incumbents and special interest.

 It can be difficult in a raucous town meeting to look around and remember who is not there.

 The mother working two jobs.

 The young family who couldn't afford the apartment they so badly wanted to move into.

 This is what democracy looks like is a common chant at protests.

 But what democracy should look like is a devilishly hard question to answer.

 What we are proposing is less a set of policy solutions than a new set of questions around which our politics should revolve.

 What is scarce that should be abundant?

 What is difficult to build that should be easy?

 What inventions do we need that we do not yet have?

 In the 1960s and 70s, environmentalism wasn't just a legislative sea change, a legal revolution, or a cultural phenomenon.

 It was all of them at once.

 Americans developed new ideas about their relationship to land and their stewardship of nature.

 New ideas gave way to new laws, new arguments, and new customs.

 People working at all levels of society, inside and outside government, brought those ideas into their labors.

 The environmentalist movement bequeathed both correction and overcorrection, but it transformed the country for decades.

 It is transforming the country even now because it touched something weightier than the legislator's pen.

 More than a law, it was a lens.

 A U.S. senator could look through it and see the bills that needed to be written.

 A judge could look through it and see new decisions that needed to be made.

 A family could look through it and see that they were wasting too much and recycling too little.

 A heady college student could look through it and see a cause.

 A lens is what we have sought to offer here.

 What keeps an apartment building from being built in San Jose is not what keeps a new transmission line from being built in Oklahoma.

 What keeps the IRS from successfully updating its software is not what has kept a high-speed rail system from being completed in California.

 What keeps an ambitious young scientist from proposing his best ideas is not what keeps us from discovering and scaling new ways to make cement.

 There are rhymes that we have found across these challenges, messages, echoes across these problems, but they are not unified enough to yield a single set of answers.

 Abundance versus scarcity.

 In 1964, at the turning point between two orders, New York City hosted a World's Fair to show off the stuff of our national genius.

 The scene was flushing, a three-mile stretch of natural marshlands in Queens.

 In the 1920s, the area had been so full of trash and vermin that F.

 Scott Fitzgerald described it in the Great Gatsby as the Valley of Ashes.

 But for the World's Fair, this grim meadow was transformed into a glistening global sensation, with 140 pavilions across almost 700 acres celebrating U.S.

 history and accomplishment.

 More than 50 million people passed through the event gates, strolling by inventions that would soon fill their department stores and homes.

 Bell Labs had an exhibition that introduced millions of Americans to their first picture phone.

 Westinghouse showed off a new electric toothbrush and credit card before placing both in a time capsule to be opened in several thousand years.

 At the fair's most popular event, the General Motors Futurama II exhibition, tens of millions of people glided through elaborate dioramas that imagined life at the end of the 20th century.

 It is now tomorrow, on the moon, a voiceover began as the audience rolled up to a model of astronaut farmers building their first lunar bridgehead.

 At another station in the exhibition, the diorama of a cityscape imagined a new system of double-decker highways connecting downtowns, whose skyscrapers had taken on the shape of towering, elongated eggs.

 At the fair's opening ceremony, President Johnson delivered a dramatic keynote address, with this remarkable passage.

 The abundance and the might represented here is far beyond the vision of those early settlers.

 America has been transformed from an outpost of the edge of wilderness to one of the great nations of the world.

 The number of people who will visit your fair will be 70 times the entire population of North America when New York was born.

 The last time New York had a world's fair, we also tried to predict the future.

 A daring exhibit proclaimed that in the 1960s, it would really be possible to cross the country in less than 24 hours, flying as high as 10,000 feet, that an astounding 38 million cars would cross our highways.

 There was no mention of outer space, or atomic power, or wonder drugs that could destroy disease.

 These were bold prophecies back there in 1939.

 But again, the reality has far outstripped the vision.

 Then, Johnson issued a warning.

 Our pride in accomplishment must not ignore the fact that our progress has had two faces, he said.

 Its final direction, abundance or annihilation, development or desolation, is in your hands.

 Six decades later, our technological frontier gleams with greater possibilities than the 1964 World's Fair could imagine.

 Medicines that erase complex diseases.

 Factories that slurp pollution from the sky.

 Intelligent machines that assist in the great project of living longer, healthier, and happier lives.

 But just as Johnson saw his own age, darkened by the possibility of catastrophic politics, so too do we face an existential binary for our own time?

 Abundance or scarcity?

 Abundance reorients politics around a fresh provocation.

 Can we solve our problems with supply?

 Many valuable questions bloom from this deceptively simple prompt.

 If there are not enough homes, can we make more?

 If not, why not?

 If there's not enough clean energy, can we make more?

 If not, why not?

 If the government is repeatedly failing to complete major projects on time and on budget, then what is going wrong, and how do we fix it?

 If the rate of scientific progress is slowing, how can we help scientists do their best work?

 If we need new technologies to solve our important problems, how do we pull these inventions from the future and distribute them in the present?

 To pursue abundance is to pursue institutional renewal.

 One of the most dangerous political pathologies is the tendency to defend whatever your enemies attack.

 Decades of attacks from the state have turned liberals into reflexive champions of government.

 But if you believe in government, you must make it work.

 To make it work, you must be clear-eyed about when it fails and why it fails.

 What has surprised us most in this project have been the blind spots.

 Our own, as much as anyone else's.

 Stories we once saw as exceptions to the rule of well-functioning government.

 A public works project that went over budget and remained unfinished.

 An absurd price tag on a public toilet.

 The explosion of homelessness in blue cities.

 The profusion of lawsuits against even well-meaning infrastructure projects.

 The loss of manufacturing leadership and core technologies.

 The absence of an agenda that harnesses invention to social purpose.

 Now seem frighteningly close to the norm.

 The purpose of a system is what it does.

 If an outcome recurs again and again across time and place, it is the result of choices that became rules.

 Which means it is the result of ideas and movements.

 The ideas and movements of the last few decades are not our villains.

 They were the responses to the crises of another time.

 They succeeded, often brilliantly.

 That we have not matched our institutions to our moment is our failure, not theirs.

 If we succeed, then future generations will have to grapple with our excesses to meet their moment.

 Let us hope.

 But before the future, the present.

 Establishing a political order demands far more than winning an election or two, Gerstle writes.

 It requires deep-pocketed donors and political action committees to invest in promising candidates over the long term.

 The establishment of think tanks and policy networks to turn political ideas into actionable programs.

 A rising political party able to consistently win over multiple electoral constituencies.

 A capacity to shape political opinion both at the highest levels, the Supreme Court, and across popular print and broadcast media.

 And a moral perspective able to inspire voters with visions of the good life.

 Political orders, in other words, are complex projects that require advances across a broad front.

 Political movements succeed when they build a vision of the future that is imbued with the virtues of the past.

 In the 1930s, Franklin D. Roosevelt pitched his expansive view of government as a sentinel for American freedoms.

 Of speech, of worship, from want, from fear.

 Five decades later, Reagan hailed the same virtues.

 This time, by casting government as freedom's nemesis, rather than its protector.

 Just as freedom has historically loomed large in the American consciousness, so has abundance.

 The theme of plenty filled the journals and letters of the first European writers who took stock of the continent.

 Take four of the best kingdoms in Christendom and put them all together.

 They may no way compare with this country either for commodities or goodness of soil.

 Sir Thomas Dale, the deputy governor of Virginia, said of his colony in 1611.

 In the following centuries, visitors and residents gawked at America's wealth of land, food, and opportunities.

 In 1817, William Cobbett, a British writer, wrote of the American diet that such an abundance is spread before you that you instantly lose all restraint.

 It was this abundance, Potter argues, in People of Plenty, that formed the American character.

 It was in the midst of not just actual plenitude, but the belief in plenitude, that our peculiar set of ideals and aspirations could form.

 The abundance of his day, to say nothing of the abundance of the first decades of the American experiment, would be absolute deprivation by our standards.

 That is a measure of our success, but it is a reminder that both abundance and scarcity are stories we tell ourselves.

 Right now, we see an America that is turning toward a story of scarcity.

 That turn is changing not just our politics, but our national character.

 We seek a politics of abundance that delivers real marvels in the real world.

 We want more homes and more energy, more cures, and more construction.

 This is a story that must be built out of bricks and steel and solar panels and transmission lines, not just words.

 But it is a story.

 And we believe it is truer to the American character and experience, truer to both what we have done and what we will do, than the narrow narrative of scarcity that has taken hold.

 Abundance contains within it a bigness that befits the American project.

 It is the promise of not just more, but more of what matters.

 It is a commitment to the endless work of institutional renewal.

 It is a recognition that technology is at the heart of progress and always has been.

 It is a determination to align our collective genius with the needs of both the planet and each other.

 Abundance is liberalism, yes.

 But more than that, it is a liberalism that builds.

 Abundance was written by Ezra Klein and Derek Thompson and read by the authors.

 It was recorded by Craig Russo and Nick Bagwell at SoundPure Studios in Durham, North Carolina, and by Tom McLean at Beat Street in New York City.

 Editing, mix, and post-production by Frog Pond Productions.

 The associate producer was Hana Matsudaira.

 Abundance was directed by Rick Bradley and produced by Tara Thomas.

 This has been a presentation of Simon & Schuster Audio.

 Abundance is available in print from Avid Reader Press.

 Also available from Simon & Schuster Audio, Why We're Polarized by Ezra Klein.

 Read by the author.

 The following is an excerpt from Ezra Klein's Why We're Polarized.

 Read by the author.

 The first thing I need to do is convince you something has changed.

 American politics offers the comforting illusion of stability.

 The Democratic and Republican parties have dominated elections since 1864, grappling for power and popularity the whole time.

 Scour American history and you'll find Democrats and Republicans slandering each other, undermining each other, plotting against each other, even physically assaulting each other.

 In her remarkable history of congressional violence, the field of blood, historian Joanne Freeman found that between 1830 and 1860, there are more than 70 violent incidents between congressmen in the House and Senate chambers or on nearby streets and dueling grounds.

 And those are just ones she could find evidence for.

 She assures me that's a substantial undercount.

 So it's easy to cast a quick glance backward and assume our present a rough match for our past.

 The complaints we have about politics today mirror the complaints past generations had of the politics of their day.

 But the Democratic and Republican parties of today are not like the Democratic and Republican parties of yesteryear.

 We are living through something genuinely new.

 Rewind to 1950.

 That was the year the American Political Science Association, which from here on I'll call APSA, had their Committee on Political Parties release a call to arms that sounds like satire to modern ears.

 It was titled Towards a More Responsible Two-Party System, and a 98-page paper, co-authored by many of the country's most eminent political scientists and covered on the front page of the New York Times, pleaded for a more polarized political system.

 It laments that the parties contain too much diversity of opinion and work together too easily, leaving voters confused about who to vote for and why.

 It's difficult watching the party-line votes and contempt for compromise that defines Congress today to read sentences like, The parties have done little to build up the kind of unity within the Congressional Party that is now so widely desired, and hear the logic behind them.

 Summarized now, the report can sound like a call for fewer puppies, more skin fungus.

 But as Colgate University political scientist Sam Rosenfeld argues in his great book, The Polarizers, Post-War Architects of Our Partisan Era, there are good reasons to worry about the muddle the parties had made of mid-century American politics.

 The activists and politicians who worked relentlessly over years to bring about the polarized political system we see today, they had good reasons for what they did.

 And appreciating the logic of the polarizers' argument, alongside the wreckage produced by their success, is a bracing antidote to both a golden view of the past and any overly confident prescriptions for the future.

 And yes, yes, it would be reasonable to keep that warning in mind when you read the solutions I'm going to offer in the concluding chapter of this book.

 To understand the political scientist's concerns, we need to understand the role political parties are supposed to play in a democracy.

 Consider the issues that you, as a citizen, are routinely asked to render judgment on.

 Should you go to war in Iraq or Syria or Iran or North Korea?

 Does it make sense to organize our health care system around private insurers brought to heel by regulations and an individual mandate, or should we abolish private insurers entirely?

 What is the proper term for copyright?

 Should it last for a decade?

 Four decades?

 A hundred years?

 Or until the sun burns out and dooms this fragile world?

 Should federal tax revenues equal 28% of GDP, 31% of GDP, 39% of GDP over the next decade?

 What's the proper level of immigration each year?

 And how much of it should go to reuniting families?

 And how much of it should go to filling economic needs?

 Would breaching the debt ceiling really damage America's creditworthiness forevermore?

 None of us, none of us, can amass sufficient expertise on such a range of topics.

 Political parties are shortcuts.

 The APSA report called them the indispensable instruments of government because they provide the electorate with a proper range of choice between alternatives of action.

 We may not know the exact right level for taxes or whether it makes sense to create a no-fly zone over Syria, but we know whether we support the Democratic, Republican, Green, or Libertarian party.

 The act of choosing a party is the act of choosing whom we trust to transform our values into precise policy judgments across a vast range of issues that confront the country.

 The authors write, For the great majority of Americans, the most valuable opportunity to influence the course of public affairs is the choice they are able to make between the parties in the principal elections.

 The problem in 1950 was that the nation's two major political parties weren't honoring the intentions of their voters.

 A Minnesota Democrat pulling the lever for Hubert Humphrey, her party's liberal Senate candidate in 1954, was also voting for a Senate majority that would include Strom Thurmond, the South Carolina senator who was among the chamber's most conservative members.

 Rather than offering a choice, the parties were offering a mush.

 Now, it's important to note that not all political scientists agreed with this argument.

 J. Austin Ranney, for instance, published a prophetic dissent arguing that, quote, Unified, disciplined, and responsible parties are appropriate only to a government which seeks to locate full public power in the hands of popular majorities.

 End quote.

 America's political system, by contrast, does not give popular majorities much power.

 It's built to frustrate political majorities, and it requires constant compromise to function.

 For that sort of system, Ranney said, polarized parties are quite inappropriate.

 He turned out to be right.

 That said, muddled parties were the problem as the members of APSA saw it at the time.

 The state parties were organizing politics around lines.

 The national parties were erasing.

 Quote, The national and state party organizations are largely independent of one another, each operating within its own sphere, without appreciable common approach to problems of party policy and strategy.

 End quote.

 The U.S. Congress included Democrats more conservative than many Republicans, Republicans as liberal as most left-leaning Democrats.

 They were robbing voters of their most valuable opportunity to influence the course of public affairs.

 Senator William Borah, an Idaho Republican, put it sharply in 1923.

 Any man who can carry a Republican primary is a Republican, he said.

 He might believe in free trade, in unconditional membership in the League of Nations, in states' rights, and in every policy the Democratic Party ever advocated.

 Yet, if he carried his Republican primary, he would be a Republican.

 That was a Republican senator.

 Being a Republican did not mean being a conservative.

 It meant being a Republican.

 Party affiliation was a tautology for itself, not a rich signifier of principles and perspective.

 In 1950, Thomas Dewey, the former governor of New York and the GOP's 1944 nominee for president, freely admitted that if the measure of a real political party was a unified organization with a national viewpoint on major issues, neither the Republican nor Democratic Party qualified.

 Dewey thought this was a great strength since he said, No single religion or color or race or economic interest is confined to one or the other of our parties.

 Each party is to some extent a reflection of the other.

 This is perhaps part of the secret of our enormous power, that a change from one party to the other has usually involved a continuity of action and policy of the nation as a whole on most fundamentals.

 Now, he allowed there were those who rail at both parties saying they represent nothing but a choice between Tweedledee and Tweedledum.

 If the critics had their way, he said, then, and I'm quoting him again here, they would have everything very neatly arranged indeed.

 The Democratic Party would be the liberal to radical party.

 The Republican Party would be the conservative to reactionary party.

 End quote.

 And you know what?

 The critics would have their way.

 In 1959, then-Vice President Richard Nixon, who would go on as president to create the Environmental Protection Agency, consider a basic minimum income, and propose a national health care plan more ambitious than Obamacare, spoke with derision of those who sought to cleave the parties by their beliefs.

 It would be a great tragedy if we had our two major political parties divide on what we would call a conservative-liberal line.

 The strength of the American political system, he said, is we have avoided generally violent swings in administrations from one extreme to the other.

 And the reason we have avoided that is that in both parties there has been room for a broad spectrum of opinion.

 In this, if in little else, Nixon was joined by Robert F. Kennedy.

 The journalist Godfrey Hodgson recounted a conversation where Kennedy warned that the country was already split vertically between sections, races, and ethnic groups so it would be dangerous to split horizontally too, between liberals and conservatives.

 Politics in this telling was meant to calm our divisions, not represent them.

 In 1959, the Republican National Committee held an internal debate over whether the parties should be driven by a distinct set of ideological values.

 At the inaugural meeting of the Committee on Program and Progress, which was tasked with designing the GOP agenda, the group invited the political scientist Robert Goldwyn to make the case that, quote, it is neither possible nor desirable for a major political party to be guided by principles, end quote.

 Our modern cleavages give Goldwyn's concerns a force they would not have carried in 1959.

 Quote, With both parties including liberals and conservatives within their ranks, those differences which would otherwise be the main campaign issues are settled by compromise within each party, end quote.

 He warned that, quoting again, our national unity would be weakened if the theoretical differences were sharpened, end quote.

 This is a profound enough point to be worth dwelling on for a moment.

 When a division exists inside a party, it gets addressed through suppression or compromise.

 Parties don't want to fight among themselves.

 But when a division exists between the parties, it gets addressed through conflict.

 Without the restraint of party unity, political disagreements escalate.

 An example here is healthcare.

 Democrats and Republicans spend billions of dollars in election ads emphasizing their disagreements on healthcare because a debate motivates their supporters and, they hope, turns the public against their opponents.

 The upside of this is that important issues get aired and sometimes even resolved.

 The downside is that divisions around them become deeper and angrier.

 This debate exploded into the open during Barry Goldwater's 1964 presidential announcement speech.

 The address is now remembered for Goldwater's promise to offer a choice, not an echo.

 Less well-known, but perhaps more telling, is a rationale for his candidacy that comes a few paragraphs earlier.

 Goldwater says, with some disgust, I have not heard from any announced Republican candidate a declaration of conscience or of political position that could possibly offer to the American people a clear choice in the next presidential election.

 This was Goldwater's promise.

 If Republicans nominated him, the election would not be an engagement of personalities.

 It will be an engagement of principles.

 Goldwater, of course, won the nomination and then got destroyed by Lyndon Johnson.

 But Goldwater's convention itself was a harshly factional affair with conservative Republicans doing their damnedest to expel the moderate wing of the party.

 In its aftermath, George Romney, then the governor of Michigan and the leading light of moderate Republicanism, wrote a 12-page letter outlining his disagreements with Goldwater.

 Dogmatic ideological parties tend to splinter the political and social fabric of a nation.

 They lead to government crises and deadlocks and stymie the compromises so often necessary to preserve freedom and achieve progress, he wrote.

 And that was rather prophetic.

 Decades later, his son, who had carried on his father's legacy as a popular moderate governor of Massachusetts, would win the Republican nomination for the presidency by recasting himself as severely conservative.

 Goldwater's electoral destruction entrenched the conventional wisdom of the age.

 Ideologues lose elections.

 In his 1960 book Parties and Politics in America, Clinton Rossiter wrote, There is and can be no real difference between the Democrats and the Republicans because the unwritten laws of American politics demand that the parties overlap substantially in principle, policy, character, appeal, and purpose, or cease to be parties with any hope of winning a national election.

 It's better to be an echo than to be a loser.

 The muddling of the parties carried well into the modern era.

 Stanford University political scientist Morris Fiorina notes that when Gerald Ford ran against Jimmy Carter, only 54% of the electorate believed the Republican Party was more conservative than the Democratic Party.

 Almost 30% said there was no ideological difference at all between the two parties.

 Imagine a world where the ideological difference between the Democratic and Republican parties was so slim as to confuse half the population imagine how much less force party identity must have carried.

 But you know, we don't have to imagine it.

 We can see it.

 Audible hopes you have enjoyed this program.
