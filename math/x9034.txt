,
and so the method diverges, except for Î»
0 = 0, which is the optimal solution.
The method of multipliers converges under conditions that are far more general than the
dual ascent. However, the addition of the penalty term has the negative effect that even if J
is separable, then the Lagrangian LÏ is not separable. Thus the basic method of multipliers
cannot be used for decomposition and is not parallelizable. The next method deals with the
problem of separability.
52.3 ADMM: Alternating Direction Method of
Multipliers
The alternating direction method of multipliers, for short ADMM, combines the decomposï¿¾ability of dual ascent with the superior convergence properties of the method of multipliers.
It can be viewed as an approximation of the method of multipliers, but it is generally supeï¿¾rior.
The idea is to split the function J into two independent parts, as J(x, z) = f(x) + g(z),
and to consider the Minimization Problem (Padmm),
minimize f(x) + g(z)
subject to Ax + Bz = c,
for some p Ã— n matrix A, some p Ã— m matrix B, and with x âˆˆ R
n
, z âˆˆ R
m, and c âˆˆ R
p
. We
also assume that f and g are convex. Further conditions will be added later.
As in the method of multipliers, we form the augmented Lagrangian
LÏ(x, z, Î») = f(x) + g(z) + Î»
> (Ax + Bz âˆ’ c) + (Ï/2) k Ax + Bz âˆ’ ck
2
2
,
with Î» âˆˆ R
p and for some Ï > 0.
Given some initial values (z
0
, Î»0
), the ADMM method consists of the following iterative
steps:
x
k+1 = arg min
x
LÏ(x, zk
, Î»k
)
z
k+1 = arg min
z
LÏ(x
k+1, z, Î»k
)
Î»
k+1 = Î»
k + Ï(Axk+1 + Bzk+1 âˆ’ c).
52.3. ADMM: ALTERNATING DIRECTION METHOD OF MULTIPLIERS 1877
Instead of performing a minimization step jointly over x and z, as the method of multiï¿¾pliers would in the step
(x
k+1, zk+1) = arg min
x,z
LÏ(x, z, Î»k
),
ADMM first performs an x-minimization step, and then a z-minimization step. Thus x and
z are updated in an alternating or sequential fashion, which accounts for the term alternating
direction.
The algorithm state in ADMM is (z
k
, Î»k
), in the sense that (z
k+1, Î»k+1) is a function
of (z
k
, Î»k
). The variable x
k+1 is an auxiliary variable which is used to compute z
k+1 from
(z
k
, Î»k
). The roles of x and z are not quite symmetric, since the update of x is done before
the update of Î». By switching x and z, f and g and A and B, we obtain a variant of ADMM
in which the order of the x-update step and the z-update step are reversed.
Example 52.4. Let us reconsider the problem of Example 52.2 to solve it using ADMM.
We formulate the problem as
minimize 2x + z
2
subject to 2x âˆ’ z = 0,
with f(x) = 2x and g(z) = z
2
. The augmented Lagrangian is given by
LÏ(x, z, Î») = 2x + z
2 + 2Î»x âˆ’ Î»z + 2Ïx2 âˆ’ 2Ïxz +
Ï
2
z
2
.
The ADMM steps are as follows. The x-update is
x
k+1 = arg min
x
ï¿¾
2Ïx2 âˆ’ 2Ïxzk + 2Î»
kx + 2x
 ,
and since this is a quadratic function in x, its minimum is achieved when the derivative of
the above function (with respect to x) is zero, namely
x
k+1 =
1
2
z
k âˆ’
1
2Ï
Î»
k âˆ’
1
2Ï
. (1)
The z-update is
z
k+1 = arg min
z

z
2 +
Ï
2
z
2 âˆ’ 2Ïxk+1z âˆ’ Î»
k
z
 ,
and as for the x-step, the minimum is achieved when the derivative of the above function
(with respect to z) is zero, namely
z
k+1 =
2Ïxk+1
Ï + 2
+
Î»
k
Ï + 2
. (2)
The Î»-update is
Î»
k+1 = Î»
k + Ï(2x
k+1 âˆ’ z
k+1). (3)
1878 CHAPTER 52. DUAL ASCENT METHODS; ADMM
Substituting the right hand side of (1) for x
k+1 in (2) yields
z
k+1 =
Ïzk
Ï + 2
âˆ’
1
Ï + 2
. (4)
Using (2), we obtain
2x
k+1 âˆ’ z
k+1 =
4x
k+1
Ï + 2
âˆ’
Î»
k
Ï + 2
, (5)
and then using (3) we get
Î»
k+1 =
2Î»
k
Ï + 2
+
4Ïxk+1
Ï + 2
. (6)
Substituting the right hand side of (1) for x
k+1 in (6), we obtain
Î»
k+1 =
2Ïzk
Ï + 2
âˆ’
2
Ï + 2
. (7)
Equation (7) shows that z
k determines Î»
k+1, and Equation (1) for k+2, along with Equation
(4), shows that z
k also determines x
k+2. In particular, we find that
x
k+2 =
1
2
z
k+1 âˆ’
1
2Ï
Î»
k+1 âˆ’
1
2Ï
=
(Ï âˆ’ 2)z
k
2(Ï + 2) âˆ’
1
Ï + 2
.
Thus is suffices to find the limit of the sequence (z
k
). Since we already know from Example
52.2 that this limit is âˆ’1/2, using (4), we write
z
k+1 = âˆ’
1
2
+
Ïzk
Ï + 2
âˆ’
1
Ï + 2
+
1
2
= âˆ’
1
2
+
Ï + 2
Ï
 1
2
+ z
k

.
By induction, we deduce that
z
k+1 = âˆ’
1
2
+

Ï + 2
Ï

k+1  1
2
+ z
0

,
and since Ï > 0, we have Ï/(Ï + 2) < 1, so the limit of the sequence (z
k+1) is indeed âˆ’1/2,
and consequently the limit of (Î»
k+1) is âˆ’1 and the limit of x
k+2 is âˆ’1/4.
For ADMM to be practical, the x-minimization step and the z-minimization step have
to be doable efficiently.
It is often convenient to write the ADMM updates in terms of the scaled dual variable
Âµ = (1/Ï)Î». If we define the residual as
r = Ax + bz âˆ’ c,
52.4. CONVERGENCE OF ADMM ~ 1879
then we have
Î»
> r + (Ï/2) k rk
2
2 = (Ï/2) k r + (1/Ï)Î»k
2
2 âˆ’ (1/(2Ï)) k Î»k
2
2
= (Ï/2) k r + Âµk
2
2 âˆ’ (Ï/2) k Âµk
2
2
.
The scaled form of ADMM consists of the following steps:
x
k+1 = arg min
x

f(x) + (Ï/2)
  Ax + Bzk âˆ’ c + Âµ
k


2
2

z
k+1 = arg min
z

g(z) + (Ï/2)
  Axk+1 + Bz âˆ’ c + Âµ
k


2
2

Âµ
k+1 = Âµ
k + Axk+1 + Bzk+1 âˆ’ c.
If we define the residual r
k at step k as
r
k = Axk + Bzk âˆ’ c = Âµ
k âˆ’ Âµ
kâˆ’1 = (1/Ï)(Î»
k âˆ’ Î»
kâˆ’1
),
then we see that
r = u
0 +
k
X
j=1
r
j
.
The formulae in the scaled form are often shorter than the formulae in the unscaled form.
We now discuss the convergence of ADMM.
52.4 Convergence of ADMM ~
Let us repeat the steps of ADMM: Given some initial (z
0
, Î»0
), do:
x
k+1 = arg min
x
LÏ(x, zk
, Î»k
) (x-update)
z
k+1 = arg min
z
LÏ(x
k+1, z, Î»k
) (z-update)
Î»
k+1 = Î»
k + Ï(Axk+1 + Bzk+1 âˆ’ c). (Î»-update)
The convergence of ADMM can be proven under the following three assumptions:
(1) The functions f : R â†’ Râˆª {+âˆ} and g : R â†’ Râˆª {+âˆ} are proper and closed convex
functions (see Section 51.1) such that relint(dom(f)) âˆ© relint(dom(g)) 6 = âˆ….
(2) The n Ã— n matrix A> A is invertible and the m Ã— m matrix B> B is invertible. Equivï¿¾alently, the p Ã— n matrix A has rank n and the p Ã— m matrix has rank m.
(3) The unaugmented Lagrangian L0(x, z, Î») = f(x)+g(z)+Î»
> (Ax+Bz âˆ’c) has a saddle
point, which means there exists x
âˆ—
, zâˆ—
, Î»âˆ—
(not necessarily unique) such that
L0(x
âˆ—
, zâˆ—
, Î») â‰¤ L0(x
âˆ—
, zâˆ—
, Î»âˆ—
) â‰¤ L0(x, z, Î»âˆ—
)
for all x, z, Î».
1880 CHAPTER 52. DUAL ASCENT METHODS; ADMM
Recall that the augmented Lagrangian is given by
LÏ(x, z, Î») = f(x) + g(z) + Î»
> (Ax + Bz âˆ’ c) + (Ï/2) k Ax + Bz âˆ’ ck
2
2
.
For z (and Î») fixed, we have
LÏ(x, z, Î») = f(x) + g(z) + Î»
> (Ax + Bz âˆ’ c) + (Ï/2)(Ax + Bz âˆ’ c)
> (Ax + Bz âˆ’ c)
= f(x) + (Ï/2)x
> A
> Ax + (Î»
> + Ï(Bz âˆ’ c)
> )Ax
+ g(z) + Î»
> (Bz âˆ’ c) + (Ï/2)(Bz âˆ’ c)
> (Bz âˆ’ c).
Assume that (1) and (2) hold. Since A> A is invertible, then it is symmetric positive
definite, and by Proposition 51.37 the x-minimization step has a unique solution (the miniï¿¾mization problem succeeds with a unique minimizer).
Similarly, for x (and Î») fixed, we have
LÏ(x, z, Î») = f(x) + g(z) + Î»
> (Ax + Bz âˆ’ c) + (Ï/2)(Ax + Bz âˆ’ c)
> (Ax + Bz âˆ’ c)
= g(z) + (Ï/2)z
> B
> Bz + (Î»
> + Ï(Ax âˆ’ c)
> )Bz
+ f(x) + Î»
> (Ax âˆ’ c) + (Ï/2)(Ax âˆ’ c)
> (Ax âˆ’ c).
Since B> B is invertible, then it is symmetric positive definite, and by Proposition 51.37
the z-minimization step has a unique solution (the minimization problem succeeds with a
unique minimizer).
By Theorem 51.41, Assumption (3) is equivalent to the fact that the KKT equations are
satisfied by some triple (x
âˆ—
, zâˆ—
, Î»âˆ—
), namely
Axâˆ— + Bzâˆ— âˆ’ c = 0 (âˆ—)
and
0 âˆˆ âˆ‚f(x
âˆ—
) + âˆ‚g(z
âˆ—
) + A
> Î»
âˆ— + B
> Î»
âˆ—
, (â€ )
Assumption (3) is also equivalent to Conditions (a) and (b) of Theorem 51.41. In particular,
our program has an optimal solution (x
âˆ—
, zâˆ—
). By Theorem 51.43, Î»
âˆ—
is maximizer of the dual
function G(Î») = infx,z L0(x, z, Î») and strong duality holds, that is, G(Î»
âˆ—
) = f(x
âˆ—
) + g(z
âˆ—
)
(the duality gap is zero).
We will see after the proof of Theorem 52.1 that Assumption (2) is actually implied by
Assumption (3). This allows us to prove a convergence result stronger than the convergence
result proven in Boyd et al. [28] under the exact same assumptions (1) and (3).
Let p
âˆ— be the minimum value of f+g over the convex set {(x, z) âˆˆ R
m+p
| Ax+Bzâˆ’c = 0},
and let (p
k
) be the sequence given by p
k = f(x
k
)+g(z
k
), and recall that r
k = Axk +Bzk âˆ’c.
Our main goal is to prove the following result.
Theorem 52.1. Suppose the following assumptions hold:
52.4. CONVERGENCE OF ADMM ~ 1881
(1) The functions f : R â†’ Râˆª {+âˆ} and g : R â†’ Râˆª {+âˆ} are proper and closed convex
functions (see Section 51.1) such that relint(dom(f)) âˆ© relint(dom(g)) 6 = âˆ….
(2) The n Ã— n matrix A> A is invertible and the m Ã— m matrix B> B is invertible. Equivï¿¾alently, the p Ã— n matrix A has rank n and the p Ã— m matrix has rank m. (This
assumption is actually redundant, because it is implied by Assumption (3)).
(3) The unaugmented Lagrangian L0(x, z, Î») = f(x) +g(z) +Î»
> (Ax+Bz âˆ’c) has a saddle
point, which means there exists x
âˆ—
, zâˆ—
, Î»âˆ—
(not necessarily unique) such that
L0(x
âˆ—
, zâˆ—
, Î») â‰¤ L0(x
âˆ—
, zâˆ—
, Î»âˆ—
) â‰¤ L0(x, z, Î»âˆ—
)
for all x, z, Î».
Then for any initial values (z
0
, Î»0
), the following properties hold:
(1) The sequence (r
k
) converges to 0 (residual convergence).
(2) The sequence (p
k
) converge to p
âˆ—
(objective convergence).
(3) The sequences (x
k
) and (z
k
) converge to an optimal solution (x, e ze) of Problem (Padmm)
and the sequence (Î»
k
) converges an optimal solution Î»e of the dual problem (primal and
dual variable convergence).
Proof. The core of the proof is due to Boyd et al. [28], but there are new steps because we
have the stronger hypothesis (2), which yield the stronger result (3).
The proof consists of several steps. It is not possible to prove directly that the sequences
(x
k
), (z
k
), and (Î»
k
) converge, so first we prove that the sequence (r
k+1) converges to zero,
and that the sequences (Axk+1) and (Bzk+1) also converge.
Step 1 . Prove the inequality (A1) below.
Consider the sequence of reals (V
k
) given by
V
k = (1/Ï)
  Î»
k âˆ’ Î»
âˆ—

2
2
+ Ï
  B(z
k âˆ’ z
âˆ—
)

2
2
.
It can be shown that the V
k
satisfy the following inequality:
V
k+1 â‰¤ V
k âˆ’ Ï
  r
k+1
 2
2
âˆ’ Ï
  B(z
k+1 âˆ’ z
k
)

2
2
. (A1)
This is rather arduous. Since a complete proof is given in Boyd et al. [28], we will only
provide some of the key steps later.
Inequality (A1) shows that the sequence (V
k
) in nonincreasing. If we write these inequalï¿¾ities for k, k âˆ’ 1, . . . , 0, we have
V
k+1 â‰¤ V
k âˆ’ Ï
  r
k+1
 2
2
âˆ’ Ï
  B(z
k+1 âˆ’ z
k
)

2
2
V
k â‰¤ V
kâˆ’1 âˆ’ Ï
  r
k


2
2
âˆ’ Ï
  B(z
k âˆ’ z
kâˆ’1
)

2
2
.
.
.
V
1 â‰¤ V
0 âˆ’ Ï
  r
1

 2
2
âˆ’ Ï
  B(z
1 âˆ’ z
0
)

2
2
,
1882 CHAPTER 52. DUAL ASCENT METHODS; ADMM
and by adding up these inequalities, we obtain
V
k+1 â‰¤ V
0 âˆ’ Ï
k
X
j=0



r
j+1
 2
2
+
  B(z
j+1 âˆ’ z
j
)

2
2

,
which implies that
Ï
k
X
j=0



r
j+1
 2
2
+
  B(z
j+1 âˆ’ z
j
)

2
2

â‰¤ V0 âˆ’ V
k+1 â‰¤ V
0
, (B)
since V
k+1 â‰¤ V
0
.
Step 2 . Prove that the sequence (r
k
) converges to 0, and that the sequences (Axk+1) and
(Bzk+1) also converge.
Inequality (B) implies that the series P âˆ
k=1 r
k and P âˆ
k=0 B(z
k+1âˆ’z
k
) converge absolutely.
In particular, the sequence (r
k
) converges to 0.
The nth partial sum of the series P âˆ
k=0 B(z
k+1 âˆ’ z
k
) is
nX
k=0
B(z
k+1 âˆ’ z
k
) = B(z
n+1 âˆ’ z
0
),
and since the series P âˆ
k=0 B(z
k+1 âˆ’ z
k
) converges, we deduce that the sequence (Bzk+1)
converges. Since Axk+1 + Bzk+1 âˆ’ c = r
k+1, the convergence of (r
k+1) and (Bzk+1) implies
that the sequence (Axk+1) also converges.
Step 3 . Prove that the sequences (x
k+1) and (z
k+1) converge. By Assumption (2), the
matrices A> A and B> B are invertible, so multiplying each vector Axk+1 by (A> A)
âˆ’1A> , if
the sequence (Axk+1) converges to u, then the sequence (x
k+1) converges to (A> A)
âˆ’1A> u.
Siimilarly, if the sequence (Bzk+1) converges to v, then the sequence (z
k+1) converges to
(B> B)
âˆ’1B> v.
Step 4 . Prove that the sequence (Î»
k
) converges.
Recall that
Î»
k+1 = Î»
k + Ïrk+1
.
It follows by induction that
Î»
k+p = Î»
k + Ï(r
k+1 + Â· Â· Â· + Ï
k+p
), p â‰¥ 2.
As a consequence, we get


Î»
k+p âˆ’ Î»
k

 â‰¤ Ï(
 r
k+1
 + Â· Â· Â· +
  r
k+p


).
52.4. CONVERGENCE OF ADMM ~ 1883
Since the series P âˆ
k=1
  r
k


converges, the partial sums form a Cauchy sequence, and this
immediately implies that for any  > 0 we can find N > 0 such that
Ï(
 r
k+1
 + Â· Â· Â· +
  r
k+p


) < , for all k, p + k â‰¥ N,
so the sequence (Î»
k
) is also a Cauchy sequence, thus it converges.
Step 5 . Prove that the sequence (p
k
) converges to p
âˆ—
.
For this, we need two more inequalities. Following Boyd et al. [28], we need to prove
that
p
k+1 âˆ’ p
âˆ— â‰¤ âˆ’(Î»
k+1)
> r
k+1 âˆ’ Ï(B(z
k+1 âˆ’ z
k
))> (âˆ’r
k+1 + B(z
k+1 âˆ’ z
âˆ—
)) (A2)
and
p
âˆ— âˆ’ p
k+1 â‰¤ (Î»
âˆ—
)
> r
k+1
. (A3)
Since we proved that the sequence (r
k
) and B(z
k+1 âˆ’ z
k
) converge to 0, and that the
sequence (Î»
k+1) converges, from
(Î»
k+1)
> r
k+1 + Ï(B(z
k+1 âˆ’ z
k
))> (âˆ’r
k+1 + B(z
k+1 âˆ’ z
âˆ—
)) â‰¤ p
âˆ— âˆ’ p
k+1 â‰¤ (Î»
âˆ—
)
> r
k+1
,
we deduce that in the limit, p
k+1 converges to p
âˆ—
.
Step 6 . Prove (A3).
Since (x
âˆ—
, yâˆ—
, Î»âˆ—
) is a saddle point, we have
L0(x
âˆ—
, zâˆ—
, Î»âˆ—
) â‰¤ L0(x
k+1, zk+1, Î»âˆ—
).
Since Axâˆ— + Bzâˆ— = c, we have L0(x
âˆ—
, zâˆ—
, Î»âˆ—
) = p
âˆ—
, and since p
k+1 = f(x
k+1) + g(z
k+1), we
have
L0(x
k+1, zk+1, Î»âˆ—
) = p
k+1 + (Î»
âˆ—
)
> r
k+1
,
so we obtain
p
âˆ— â‰¤ p
k+1 + (Î»
âˆ—
)
> r
k+1
,
which yields (A3).
Step 7 . Prove (A2).
By Proposition 51.34, z
k+1 minimizes LÏ(x
k+1, z, Î»k
) iff
0 âˆˆ âˆ‚g(z
k+1) + B
> Î»
k + ÏB> (Axk+1 + Bzk+1 âˆ’ c)
= âˆ‚g(z
k+1) + B
> Î»
k + ÏB> r
k+1
= âˆ‚g(z
k+1) + B
> Î»
k+1
,
since r
k+1 = Axk+1 + Bzk+1 âˆ’ c and Î»
k+1 = Î»
k + Ï(Axk+1 + Bzk+1 âˆ’ c).
In summary, we have
0 âˆˆ âˆ‚g(z
k+1) + B
> Î»
k+1
, (â€ 1)
1884 CHAPTER 52. DUAL ASCENT METHODS; ADMM
which shows that z
k+1 minimizes the function
z 7â†’ g(z) + (Î»
k+1)
> Bz.
Consequently, we have
g(z
k+1) + (Î»
k+1)
> Bzk+1 â‰¤ g(z
âˆ—
) + (Î»
k+1)
> Bzâˆ—
. (B1)
Similarly, x
k+1 minimizes LÏ(x, zk
, Î»k
) iff
0 âˆˆ âˆ‚f(x
k+1) + A
> Î»
k + ÏA> (Axk+1 + Bzk âˆ’ c)
= âˆ‚f(x
k+1) + A
> (Î»
k + Ïrk+1 + ÏB(z
k âˆ’ z
k+1))
= âˆ‚f(x
k+1) + A
> Î»
k+1 + ÏA> B(z
k âˆ’ z
k+1)
since r
k+1 âˆ’ Bzk+1 = Axk+1 âˆ’ c and Î»
k+1 = Î»
k + Ï(Axk+1 + Bzk+1 âˆ’ c) = Î»
k + Ïrk+1
.
Equivalently, the above derivation shows that
0 âˆˆ âˆ‚f(x
k+1) + A
> (Î»
k+1 âˆ’ ÏB(z
k+1 âˆ’ z
k
)), (â€ 2)
which shows that x
k+1 minimizes the function
x 7â†’ f(x) + (Î»
k+1 âˆ’ ÏB(z
k+1 âˆ’ z
k
))> Ax.
Consequently, we have
f(x
k+1) + (Î»
k+1 âˆ’ ÏB(z
k+1 âˆ’ z
k
))> Axk+1 â‰¤ f(x
âˆ—
) + (Î»
k+1 âˆ’ ÏB(z
k+1 âˆ’ z
k
))> Axâˆ—
. (B2)
Adding up Inequalities (B1) and (B2), using the equation Axâˆ— + Bzâˆ— = c, and rearranging,
we obtain inequality (A2).
Step 8 . Prove that (x
k
),(z
k
), and (Î»
k
) converge to optimal solutions.
Recall that (r
k
) converges to 0, and that (x
k
), (z
k
), and (Î»
k
) converge to limits xe, ze, and
e
Î». Since r
k = Axk + Bzk âˆ’ c, in the limit, we have
Axe + Bze âˆ’ c = 0. (âˆ—1)
Using (â€ 1), in the limit, we obtain
0 âˆˆ âˆ‚g(ze) + B
> Î». e (âˆ—2)
Since (B(z
k+1 âˆ’ z
k
)) converges to 0, using (â€ 2), in the limit, we obtain
