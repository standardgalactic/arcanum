w
> = (w1, w2).
Step 1: Write the constraints in matrix form. Let
C =


−u11 −u12 1
−u21 −u22 1
v11 v12 −1
v21 v22 −1


d =


−
−
−
−
1
1
1
1

 . (M)
The constraints become
C

w
b

=


−u11 −u12 1
−u21 −u22 1
v11 v12 −1
v21 v22 −1




w1
w2
b

 ≤


−
−
−
−
1
1
1
1

 . (C)
Step 2: Write the objective function in matrix form.
J(w1, w2, b) = 1
2
￾
w1 w2 b



1 0 0
0 1 0
0 0 0




w1
w2
b

 . (O)
Step 3: Apply Proposition 50.7 to solve for w in terms of λ and µ. We obtain


w
w
1
2
0

 +


−u11 −u21 v11 v21
−u12 −u22 v12 v22
1 1 −1 −1



µ
µ
λ
λ
1
2
1
2

 =


0
0
0

 ,
i.e.
∇J(w,b) + C
>

µ
λ

= 03, λ> = (λ1, λ2), µ> = (µ1, µ2).
Then


w
w
1
2
0

 =


u11 u21 −v11 −v21
u12 u22 −v12 −v22
−1 −1 1 1



µ
µ
λ
λ
1
2
1
2

 ,
which implies
w =

w
w
1
2

= λ1

u11
u12
+ λ2

u21
u22
− µ1

v11
v12
− µ2

v21
v22
(∗1)
50.6. HARD MARGIN SUPPORT VECTOR MACHINE; VERSION II 1765
with respect to
µ1 + µ2 − λ1 − λ2 = 0. (∗2)
Step 4: Rewrite the constraints at (C) using (∗1). In particular C

w
b

≤ d becomes


−u11 −u12 1
−u21 −u22 1
v11 v12 −1
v21 v22 −1




u11 u21 −v11 −v21 0
u12 u22 −v21 −v22 0
0 0 0 0 1




λ1
λ2
µ1
µ2
b


≤


−1
−1
−1
−1

 .
Rewriting the previous equation in “block” format gives us
−


−
−
u
u
11
21
−
−
u
u
12
22
v
v
11
21
v
v
12
22



−u11 −u21 v11 v21
−u12 −u22 v21 v22


λ1
λ2
µ1
µ2


+ b

−
−
1
1
1
1


+


1
1
1
1


≤


0
0
0
0

 ,
which with the definition
X =

−u11 −u21 v11 v21
−u12 −u22 v21 v22
yields
−X
> X

µ
λ

+ b

12
−12

+ 14 ≤ 04. (∗3)
Let us now consider the general case.
Step 1: Write the constraints in matrix form. First we rewrite the constraints as
−u
>i w + b ≤ −1 i = 1, . . . , p
v
>j w − b ≤ −1 j = 1, . . . , q,
and we get the (p + q) × (n + 1) matrix C and the vector d ∈ R
p+q given by
C =


−u
>1
1
.
.
.
.
.
.
−u
>p
1
v
>1 −1
.
.
.
.
.
.
vq
> −1


, d =


−
−
.
.
.
1
1

 ,
so the set of inequality constraints is
C

w
b

≤ d.
1766 CHAPTER 50. INTRODUCTION TO NONLINEAR OPTIMIZATION
Step 2: The objective function in matrix form is given by
J(w, b) = 1
2
￾
w
> b


In 0n
0
>n
0
 
w
b

.
Note that the corresponding matrix is symmetric positive semidefinite, but it is not invertible.
Thus, the function J is convex but not strictly convex. This will cause some minor trouble
in finding the dual function of the problem.
Step 3: If we introduce the generalized Lagrange multipliers λ ∈ R
p and µ ∈ R
q
,
according to Proposition 50.7, the first KKT condition is
∇J(w,b) + C
>

µ
λ

= 0n+1,
with λ ≥ 0, µ ≥ 0. By the result of Example 39.5,
∇J(w,b) =

In 0n
0
>n
0
 
w
b

=

w
0

,
so we get

w
0

= −C
>

µ
λ

,
that is,

w
0

=

−
u1
1
· · ·
· · · −
up
1 1
−v1
· · ·
· · · −
1
vq
 
µ
λ

.
Consequently,
w =
p
X
i=1
λiui −
q
X
j=1
µjvj
, (∗1)
and
q
X
j=1
µj −
p
X
i=1
λi = 0. (∗2)
Step 4: Rewrite the constraint using (∗1). Plugging the above expression for w into the
constraints C

w
b

≤ d we get


−u
>1
1
.
.
.
.
.
.
−u
>p
1
v1
>
.
−1
.
.
.
.
.
vq
> −1



u1 · · · up −v1 · · · −vq 0n
0 · · · 0 0 · · · 0 1 

µ
λ
b

 ≤


−
−
.
.
.
1
1

 ,
50.6. HARD MARGIN SUPPORT VECTOR MACHINE; VERSION II 1767
so if let X be the n × (p + q) matrix given by
X =
￾ −u1 · · · −up v1 · · · vq
 ,
we obtain
w = −X

µ
λ

, (∗
01
)
and the above inequalities are written in matrix form as

X>
1p
−1q
 
−X 0n
0
>p+q
1


µ
λ
b

 ≤ −1p+q;
that is,
−X
> X

µ
λ

+ b

1p
−1q

+ 1p+q ≤ 0p+q. (∗3)
Equivalently, the ith inequality is
−
p
X
j=1
u
>i ujλj +
q
X
k=1
u
>i
vkµk + b + 1 ≤ 0 i = 1, . . . , p,
and the (p + j)th inequality is
p
X
i=1
vj
> uiλi −
q
X
k=1
vj
>
vkµk − b + 1 ≤ 0 j = 1, . . . , q.
We also have λ ≥ 0, µ ≥ 0. Furthermore, if the ith inequality is inactive, then λi = 0, and if
the (p + j)th inequality is inactive, then µj = 0. Since the constraints are affine and since J
is convex, if we can find λ ≥ 0, µ ≥ 0, and b such that the inequalities in (∗3) are satisfied,
and λi = 0 and µj = 0 when the corresponding constraint is inactive, then by Proposition
50.7 we have an optimum solution.
Remark: The second KKT condition can be written as
￾
λ
> µ
>

 −X
> X

µ
λ

+ b

1p
−1q

+ 1p+q
 = 0;
that is,
−
￾ λ
> µ
>
 X
> X

µ
λ

+ b
￾ λ
> µ
>


1p
−1q

+
￾ λ
> µ
>
 1p+q = 0.
Since (∗2) says that P p
i=1 λi =
P
q
j=1 µj
, the second term is zero, and by (∗
01
) we get
w
> w =
￾ λ
> µ
>
 X
> X

µ
λ

=
p
X
i=1
λi +
q
X
j=1
µj
.
1768 CHAPTER 50. INTRODUCTION TO NONLINEAR OPTIMIZATION
Thus, we obtain a simple expression for k wk
2
in terms of λ and µ.
The vectors ui and vj
for which the i-th inequality is active and the (p + j)th inequality
is active are called support vectors. For every vector ui or vj that is not a support vector,
the corresponding inequality is inactive, so λi = 0 and µj = 0. Thus we see that only the
support vectors contribute to a solution. If we can guess which vectors ui and vj are support
vectors, namely, those for which λi 6 = 0 and µj 6 = 0, then for each support vector ui we have
an equation
−
p
X
j=1
u
>i ujλj +
q
X
k=1
u
>i
vkµk + b + 1 = 0,
and for each support vector vj we have an equation
p
X
i=1
vj
> uiλi −
q
X
k=1
vj
>
vkµk − b + 1 = 0,
with λi = 0 and µj = 0 for all non-support vectors, so together with the Equation (∗2) we
have a linear system with an equal number of equations and variables, which is solvable if
our separation problem has a solution. Thus, in principle we can find λ, µ, and b by solving
a linear system.
Remark: We can first solve for λ and µ (by eliminating b), and by (∗1) and since w 6 = 0,
there is a least some nonzero λi0 and thus some nonzero µj0
, so the corresponding inequalities
are equations
−
p
X
j=1
u
>i0
ujλj +
q
X
k=1
u
>i0
vkµk + b + 1 = 0
p
X
i=1
vj
>0
uiλi −
q
X
k=1
vj
>0
vkµk − b + 1 = 0,
so b is given in terms of λ and µ by
b =
1
2
(u
>i0 + vj
>0
)
 
p
X
i=1
λiui −
p
X
j=1
µjvj
!
.
Using the dual of the Lagrangian, we can solve for λ and µ, but typically b is not determined,
so we use the above method to find b.
The above nondeterministic procedure in which we guess which vectors are support vec￾tors is not practical. We will see later that a practical method for solving for λ and µ consists
in maximizing the dual of the Lagrangian.
50.6. HARD MARGIN SUPPORT VECTOR MACHINE; VERSION II 1769
If w is an optimal solution, then δ = 1/ k wk is the shortest distance from the support
vectors to the separating hyperplane Hw,b of equation w
> x − b = 0. If we consider the two
hyperplanes Hw,b+1 and Hw,b−1 of equations
w
> x − b − 1 = 0 and w
> x − b + 1 = 0,
then Hw,b+1 and Hw,b−1 are two hyperplanes parallel to the hyperplane Hw,b and the distance
between them is 2δ. Furthermore, Hw,b+1 contains the support vectors ui
, Hw,b−1 contains
the support vectors vj
, and there are no data points ui or vj
in the open region between
these two hyperplanes containing the separating hyperplane Hw,b (called a “slab” by Boyd
and Vandenberghe; see [29], Section 8.6). This situation is illustrated in Figure 50.14.
v v
v
1 2
j
v
v
v
3
4
5
u
u
u
u
u1
2
3
4
i
Figure 50.14: In R
3
, the solution to Hard Margin SVMh2 is the purple plane sandwiched
between the red plane w
> x − b + 1 = 0 and the blue plane w
> x − b − 1 = 0, each of which
contains the appropriate support vectors ui and vj
.
Even if p = 1 and q = 2, a solution is not obvious. In the plane, there are four possibilities:
(1) If u1 is on the segment (v1, v2), there is no solution.
(2) If the projection h of u1 onto the line determined by v1 and v2 is between v1 and v2,
that is h = (1 − α)v1 + α2v2 with 0 ≤ α ≤ 1, then it is the line parallel to v2 − v1 and
equidistant to u and both v1 and v2, as illustrated in Figure 50.15.
(3) If the projection h of u1 onto the line determined by v1 and v2 is to the right of v2, that
is h = (1 − α)v1 + α2v2 with α > 1, then it is the bisector of the line segment (u1, v2).
(4) If the projection h of u1 onto the line determined by v1 and v2 is to the left of v1, that
is h = (1 − α)v1 + α2v2 with α < 0, then it is the bisector of the line segment (u1, v1).
w x - b = 0
w x - b + 1 = 0
w x - b - 1 = 0
T
T
T
1770 CHAPTER 50. INTRODUCTION TO NONLINEAR OPTIMIZATION
u
v
2
v1
Figure 50.15: The purple line, which is the bisector of the altitude of the isosceles triangle,
separates the two red points from the blue point in a manner which satisfies Hard Margin
SVMh2.
If p = q = 1, we can find a solution explicitly. Then (∗2) yields
λ = µ,
and if we guess that the constraints are active, the corresponding equality constraints are
−u
> uλ + u
> vµ + b + 1 = 0
u
> vλ − v
> vµ − b + 1 = 0,
so we get
(−u
> u + u
> v)λ + b + 1 = 0
(u
> v − v
> v)λ − b + 1 = 0,
Adding up the two equations we find
(2u
> v − u
> u − v
> v)λ + 2 = 0,
that is
λ =
2
(u − v)
> (u − v)
.
By subtracting the first equation from the second, we find
(u
> u − v
> v)λ − 2b = 0,
which yields
b = λ
(u
> u − v
> v)
2
=
u
> u − v
> v
(u − v)
> (u − v)
.
50.7. LAGRANGIAN DUALITY AND SADDLE POINTS 1771
Then by (∗1) we obtain
w =
2(u − v)
(u − v)
> (u − v)
.
We verify easily that
2(u1 − v1)x1 + · · · + 2(un − vn)xn = (u
2
1 + · · · + u
2
n
) − (v1
2 + · · · + vn
2
)
is the equation of the bisector hyperplane between u and v; see Figure 50.16.
u
p
v
Figure 50.16: In R
3
, the solution to Hard Margin SVMh2 for the points u and v is the purple
perpendicular planar bisector of u − v.
In the next section we will derive the dual of the optimization problem discussed in this
section. We will also consider a more flexible solution involvlng a soft margin.
50.7 Lagrangian Duality and Saddle Points
In this section we investigate methods to solve the Minimization Problem (P):
minimize J(v)
subject to ϕi(v) ≤ 0, i = 1, . . . , m.
It turns out that under certain conditions the original Problem (P), called primal problem,
can be solved in two stages with the help another Problem (D), called the dual problem. The
Dual Problem (D) is a maximization problem involving a function G, called the Lagrangian
1772 CHAPTER 50. INTRODUCTION TO NONLINEAR OPTIMIZATION
dual, and it is obtained by minimizing the Lagrangian L(v, µ) of Problem (P) over the
variable v ∈ R
n
, holding µ fixed, where L: Ω × R
m
+ → R is given by
L(v, µ) = J(v) +
mX
i=1
µiϕi(v),
with µ ∈ R
m
+ .
The two steps of the method are:
(1) Find the dual function µ 7→ G(µ) explictly by solving the minimization problem of
finding the minimum of L(v, µ) with respect to v ∈ Ω, holding µ fixed. This is an
unconstrained minimization problem (with v ∈ Ω). If we are lucky, a unique minimizer
uµ such that G(µ) = L(uµ, µ) can be found. We will address the issue of uniqueness
later on.
(2) Solve the maximization problem of finding the maximum of the function µ 7→ G(µ)
over all µ ∈ R
m
+ . This is basically an unconstrained problem, except for the fact that
µ ∈ R
m
+ .
If Steps (1) and (2) are successful, under some suitable conditions on the function J and
the constraints ϕi (for example, if they are convex), for any solution λ ∈ R
m
+ obtained in
Step (2), the vector uλ obtained in Step (1) is an optimal solution of Problem (P). This is
proven in Theorem 50.17.
In order to prove Theorem 50.17, which is our main result, we need two intermediate
technical results of independent interest involving the notion of saddle point.
The local minima of a function J : Ω → R over a domain U defined by inequality con￾straints are saddle points of the Lagrangian L(v, µ) associated with J and the constraints
ϕi
. Then, under some mild hypotheses, the set of solutions of the Minimization Problem
(P)
minimize J(v)
subject to ϕi(v) ≤ 0, i = 1, . . . , m
coincides with the set of first arguments of the saddle points of the Lagrangian
L(v, µ) = J(v) +
mX
i=1
µiϕi(v).
This is proved in Theorem 50.15. To prove Theorem 50.17, we also need Proposition 50.14,
a basic property of saddle points.
50.7. LAGRANGIAN DUALITY AND SADDLE POINTS 1773
Definition 50.7. Let L: Ω × M → R be a function defined on a set of the form Ω × M,
where Ω and M are open subsets of two normed vector spaces. A point (u, λ) ∈ Ω × M is a
saddle point of L if u is a minimum of the function L(−, λ): Ω → R given by v 7→ L(v, λ)
for all v ∈ Ω and λ fixed, and λ is a maximum of the function L(u, −): M → R given by
µ 7→ L(u, µ) for all µ ∈ M and u fixed; equivalently,
sup
µ∈M
L(u, µ) = L(u, λ) = inf
v∈Ω
L(v, λ).
Note that the order of the arguments u and λ is important. The second set M will be the
set of generalized multipliers, and this is why we use the symbol M. Typically, M = R
m
+ .
A saddle point is often depicted as a mountain pass, which explains the terminology; see
Figure 50.17. However, this is a bit misleading since other situations are possible; see Figure
50.18.
>>
x
y
L(u, λ)
Figure 50.17: A three-dimensional rendition of a saddle point L(u, λ) for the function
L(u, λ) = u
2 − λ
2
. The plane x = u provides a maximum as the apex of a downward
opening parabola, while the plane y = λ provides a minimum as the apex of an upward
opening parabola.
Proposition 50.14. If (u, λ) is a saddle point of a function L: Ω × M → R, then
sup
µ∈M
inf
v∈Ω
L(v, µ) = L(u, λ) = inf
v∈Ω
sup
µ∈M
L(v, µ).
Proof. First we prove that the following inequality always holds:
sup
µ∈M
inf
v∈Ω
L(v, µ) ≤ inf
v∈Ω
sup
µ∈M
L(v, µ). (∗1)
1774 CHAPTER 50. INTRODUCTION TO NONLINEAR OPTIMIZATION
M
Ω M
Ω
(0, λ)
M
Ω
