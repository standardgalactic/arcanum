We now consider the problem of finding the minimum of a convex functional J : V â†’ R
over a nonempty, convex, closed subset U of a Hilbert space V . By Theorem 40.13(3), the
functional J has a minimum at u âˆˆ U iff
dJu(v âˆ’ u) â‰¥ 0 for all v âˆˆ U,
which can be expressed as
hâˆ‡Ju, v âˆ’ ui â‰¥ 0 for all v âˆˆ U.
On the other hand, by the projection lemma (Proposition 48.5), the condition for a vector
u âˆˆ U to be the projection of an element w âˆˆ V onto U is
h
u âˆ’ w, v âˆ’ ui â‰¥ 0 for all v âˆˆ U.
49.11. GRADIENT PROJECTION FOR CONSTRAINED OPTIMIZATION 1717
These conditions are obviously analogous, and we can make this analogy more precise as
follows. If pU : V â†’ U is the projection map onto U, we have the following chain of equivaï¿¾lences:
u âˆˆ U and J(u) = inf
vâˆˆU
J(v) iff
u âˆˆ U and hâˆ‡Ju, v âˆ’ ui â‰¥ 0 for every v âˆˆ U, iff
u âˆˆ U and h u âˆ’ (u âˆ’ Ïâˆ‡Ju), v âˆ’ ui â‰¥ 0 for every v âˆˆ U and every Ï > 0, iff
u = pU (u âˆ’ Ïâˆ‡Ju) for every Ï > 0.
In other words, for every Ï > 0, u âˆˆ V is a fixed-point of the function g : V â†’ U given by
g(v) = pU (v âˆ’ Ïâˆ‡Jv).
The above suggests finding u by the method of successive approximations for finding the
fixed-point of a contracting mapping, namely given any initial u0 âˆˆ V , to define the sequence
(uk)kâ‰¥0 such that
uk+1 = pU (uk âˆ’ Ïkâˆ‡Juk
),
where the parameter Ïk > 0 is chosen at each step. This method is called the projectedï¿¾gradient method with variable stepsize parameter . Observe that if U = V , then this is just the
gradient method with variable stepsize. We have the following result about the convergence
of this method.
Proposition 49.18. Let J : V â†’ R be a continuously differentiable functional defined on
a Hilbert space V , and let U be nonempty, convex, closed subset of V . Suppose there exists
two constants Î± > 0 and M > 0 such that
hâˆ‡Jv âˆ’ âˆ‡Ju, v âˆ’ ui â‰¥ Î± k v âˆ’ uk
2
for all u, v âˆˆ V ,
and
kâˆ‡Jv âˆ’ âˆ‡Juk â‰¤ M k v âˆ’ uk for all u, v âˆˆ V .
If there exists two real nunbers a, b âˆˆ R such that
0 < a â‰¤ Ïk â‰¤ b â‰¤
2Î±
M2
for all k â‰¥ 0,
then the projected-gradient method with variable stepsize parameter converges. Furthermore,
there is some constant Î² > 0 (depending on Î±, M, a, b) such that
Î² < 1 and k uk âˆ’ uk â‰¤ Î²
k
k u0 âˆ’ uk ,
where u âˆˆ M is the unique minimum of J.
1718 CHAPTER 49. GENERAL RESULTS OF OPTIMIZATION THEORY
Proof. For every Ïk â‰¥ 0, define the function gk : V â†’ U by
gk(v) = pU (v âˆ’ Ïkâˆ‡Jv).
By Proposition 48.6, the projection map pU has Lipschitz constant 1, so using the inequalities
assumed to hold in the proposition, we have
k
gk(v1) âˆ’ gk(v2)k
2 = k pU (v1 âˆ’ Ïkâˆ‡Jv1
) âˆ’ pU (v2 âˆ’ Ïkâˆ‡Jv2
)k
2
â‰¤ k(v1 âˆ’ v2) âˆ’ Ïk(âˆ‡Jv1 âˆ’ âˆ‡Jv2
)k
2
= k v1 âˆ’ v2k
2 âˆ’ 2Ïkhâˆ‡Jv1 âˆ’ âˆ‡Jv2
, v1 âˆ’ v2i + Ï
2
k kâˆ‡Jv1 âˆ’ âˆ‡Jv2 k
2
â‰¤
 1 âˆ’ 2Î±Ïk + M2
Ï
2
k
 k
v1 âˆ’ v2k
2
.
As in the proof of Proposition 49.14, we know that if a and b satisfy the conditions 0 < a â‰¤
Ïk â‰¤ b â‰¤
2Î±
M2
, then there is some Î² such that

1 âˆ’ 2Î±Ïk + M2
Ï
2
k

1/2
â‰¤ Î² < 1 for all k â‰¥ 0.
Since the minimizing point u âˆˆ U is a fixed point of gk for all k, by letting v1 = uk and
v2 = u, we get
k
uk+1 âˆ’ uk = k gk(uk) âˆ’ gk(u)k â‰¤ Î² k uk âˆ’ uk ,
which proves the convergence of the sequence (uk)kâ‰¥0.
In the case of an elliptic quadratic functional
J(v) = 1
2
h
Av, ai âˆ’ hb, vi
defined on R
n
, the reasoning just after the proof of Proposition 49.14 can be immediately
adapted to show that convergence takes place as long as a, b and Ïk are chosen such that
0 < a â‰¤ Ïk â‰¤ b â‰¤
2
Î»n
.
In theory, Proposition 49.18 gives a guarantee of the convergence of the projected-gradient
method. Unfortunately, because computing the projection pU (v) effectively is generally
impossible, the range of practical applications of Proposition 49.18 is rather limited. One
exception is the case where U is a product Q m
i=1[ai
, bi
] of closed intervals (where ai = âˆ’âˆ
or bi = +âˆ is possible). In this case, it is not hard to show that
pU (w)i =
ï£±
ï£´ï£²
ï£´ï£³
ai
if wi < ai
wi
if ai â‰¤ wi â‰¤ bi
bi
if bi < wi
.
49.12. PENALTY METHODS FOR CONSTRAINED OPTIMIZATION 1719
In particular, this is the case if
U = R
n
+ = {v âˆˆ R
n
| v â‰¥ 0}
and if
J(v) = 1
2
h
Av, ai âˆ’ hb, vi
is an elliptic quadratic functional on R
n
. Then the vector uk+1 = (u
k
1
+1, . . . , uk
n
+1) is given
in terms of uk = (u
k
1
, . . . , uk
n
) by
u
k
i
+1 = max{u
k
i âˆ’ Ïk(Auk âˆ’ b)i
, 0}, 1 â‰¤ i â‰¤ n.
49.12 Penalty Methods for Constrained Optimization
In the case where V = R
n
, another method to deal with constrained optimization is to
incorporate the domain U into the objective function J by adding a penalty function.
Definition 49.11. Given a nonempty closed convex subset U of R
n
, a function Ïˆ: R
n â†’ R
is called a penalty function for U if Ïˆ is convex and continuous and if the following conditions
hold:
Ïˆ(v) â‰¥ 0 for all v âˆˆ R
n
, and Ïˆ(v) = 0 iff v âˆˆ U.
The following proposition shows that the use of penalty functions reduces a constrained
optimization problem to a sequence of unconstrained optimization problems.
Proposition 49.19. Let J : R
n â†’ R be a continuous, coercive, strictly convex function, U
be a nonempty, convex, closed subset of R
n
, Ïˆ: R
n â†’ R be a penalty function for U, and let
J : R
n â†’ R be the penalized objective function given by
J (v) = J(v) + 1

Ïˆ(v) for all v âˆˆ R
n
.
Then for every  > 0, there exists a unique element u âˆˆ R
n
such that
J (u ) = inf
vâˆˆRn
J (v).
Furthermore, if u âˆˆ U is the unique minimizer of J over U, so that J(u) = infvâˆˆU J(v), then
lim7â†’0
u = u.
Proof. Observe that since J is coercive, since Ïˆ(v) â‰¥ 0 for all v âˆˆ R
n
, and J = J + (1/)Ïˆ,
we have J (v) â‰¥ J(v) for all v âˆˆ R
n
, so J is also coercive. Since J is strictly convex and
(1/)Ïˆ is convex, it is immediately checked that J = J + (1/)Ïˆ is also strictly convex.
Then by Proposition 49.1 (and the fact that J and J are strictly convex), J has a unique
minimizer u âˆˆ U, and J has a unique minimizer u âˆˆ R
n
.
1720 CHAPTER 49. GENERAL RESULTS OF OPTIMIZATION THEORY
Since Ïˆ(u) = 0 iff u âˆˆ U, and Ïˆ(v) â‰¥ 0 for all v âˆˆ R
n
, we have J (u) = J(u), and since
u is the minimizer of J we have J (u ) â‰¤ J (u), so we obtain
J(u ) â‰¤ J(u ) + 1

Ïˆ(u ) = J (u ) â‰¤ J (u) = J(u),
that is,
J (u ) â‰¤ J(u). (âˆ—1)
Since J is coercive, the family (u )>0 is bounded. By compactness (since we are in R
n
),
there exists a subsequence (u (i))iâ‰¥0 with limi7â†’âˆ  (i) = 0 and some element u
0 âˆˆ R
n
such
that
lim
i7â†’âˆ
u (i) = u
0 .
From the inequality J(u ) â‰¤ J(u) proven in (âˆ—1) and the continuity of J, we deduce that
J(u
0 ) = limi7â†’âˆ
J(u (i)) â‰¤ J(u). (âˆ—2)
By definition of J (u ) and (âˆ—1), we have
0 â‰¤ Ïˆ(u (i)) â‰¤  (i)(J(u) âˆ’ J(u (i))),
and since the sequence (u (i))iâ‰¥0 converges, the numbers J(u) âˆ’ J(u (i)) are bounded indeï¿¾pendently of i. Consequently, since limi7â†’âˆ  (i) = 0 and since the function Ïˆ is continuous,
we have
0 = lim
i7â†’âˆ
Ïˆ(u (i)) = Ïˆ(u
0 ),
which shows that u
0 âˆˆ U. Since by (âˆ—2) we have J(u
0 ) â‰¤ J(u), and since both u, u0 âˆˆ U
and u is the unique minimizer of J over U we must have u
0 = u. Therfore u
0 is the unique
minimizer of J over U. But then the whole family (u )>0 converges to u since we can use
the same argument as above for every subsequence of (u )>0.
Note that a convex function Ïˆ: R
n â†’ R is automatically continuous, so the assumption
of continuity is redundant.
As an application of Proposition 49.19, if U is given by
U = {v âˆˆ R
n
| Ï•i(v) â‰¤ 0, i = 1, . . . , m},
where the functions Ï•i
: R
n â†’ R are convex, we can take Ïˆ to be the function given by
Ïˆ(v) =
mX
i=1
max{Ï•i(v), 0}.
49.13. SUMMARY 1721
In practice, the applicability of the penalty-function method is limited by the difficulty
to construct effectively â€œgoodâ€ functions Ïˆ, for example, differentiable ones. Note that in
the above example the function Ïˆ is not diferentiable. A better penalty function is
Ïˆ(v) =
mX
i=1
(max{Ï•i(v), 0})
2
.
Another way to deal with constrained optimization problems is to use duality. This
approach is investigated in Chapter 50.
49.13 Summary
The main concepts and results of this chapter are listed below:
â€¢ Minimization, minimizer.
â€¢ Coercive functions.
â€¢ Minima of quadratic functionals.
â€¢ The theorem of Lions and Stampacchia.
â€¢ Laxâ€“Milgramâ€™s theorem.
â€¢ Elliptic functionals.
â€¢ Descent direction, exact line search, backtracking line search.
â€¢ Method of relaxation.
â€¢ Gradient descent.
â€¢ Gradient descent method with fixed stepsize parameter.
â€¢ Gradient descent method with variable stepsize parameter.
â€¢ Steepest descent method for the Euclidean norm.
â€¢ Gradient descent method with backtracking line search.
â€¢ Normalized steepest descent direction.
â€¢ Unormalized steepest descent direction.
â€¢ Steepest descent method (with respect to the norm k k ).
â€¢ Momentum term.
1722 CHAPTER 49. GENERAL RESULTS OF OPTIMIZATION THEORY
â€¢ Newtonâ€™s method.
â€¢ Newton step.
â€¢ Newton decrement.
â€¢ Damped Newton phase.
â€¢ Quadratically convergent phase.
â€¢ Self-concordant functions.
â€¢ Conjugate gradient method.
â€¢ Projected gradient methods.
â€¢ Penalty methods.
49.14 Problems
Problem 49.1. Consider the function J : R
n â†’ R given by
J(v) = 1
2
h
Av, vi âˆ’ hb, vi + g(v),
where A is a real n Ã— n symmetric positive definite matrix, b âˆˆ R
n
, and g : R
n â†’ R is a
continuous (not necessarily differentiable) convex function such that g(v) â‰¥ 0 for all v âˆˆ R
n
,
and let U be a nonempty, bounded, closed, convex subset of R
n
.
(1) Prove that there is a unique element u âˆˆ U such that
J(u) = inf
vâˆˆU
J(v).
Hint. Prove that J is strictly convex on R
n
.
(2) Check that
J(v) âˆ’ J(u) = h Au âˆ’ b, v âˆ’ ui + g(v) âˆ’ g(u) + 1
2
h
A(v âˆ’ u), v âˆ’ ui .
Prove that an element u âˆˆ U minimizes J in U iff
h
Au âˆ’ b, v âˆ’ ui + g(v) âˆ’ g(u) â‰¥ 0 for all v âˆˆ U.
Problem 49.2. Consider n piecewise C
1
functions Ï•i
: [0, 1] â†’ R and assume that these
functions are linearly independent and that
nX
i=1
Ï•i(x) = 1 for all x âˆˆ [0, 1].
49.14. PROBLEMS 1723
Let J : R
n â†’ R be the function given by
J(v) =
nX
i,j=1
aiijvivj +
nX
i=1
bivi
,
where v = (v1, . . . , vn) and
aij =
Z
1
0
Ï•
0i
(t)Ï•
0j
(t)dt, bi =
Z
1
0
Ï•i(t)dt.
(1) Let U1 be the subset of R
n given by
U1 =
( v âˆˆ R
n
|
nX
i=1
bivi = 0) .
Consider the problem of finding a minimum of J over U1. Prove that the Lagrange multiplier
Î» for which the Lagrangian has a critical point is Î» = âˆ’1.
(2) Prove that the map defined on U1 by
k
vk =
ï£«
ï£­
Z
1
0
 
nX
i=1
viÏ•
0i
(x)
!
2
dx
ï£¶
ï£¸
1/2
is a norm. Prove that J is elliptic on U1 with this norm. Prove that J has a unique minimum
on U1.
(3) Consider the the subset of R
n given by
U2 =
( v âˆˆ R
n
|
nX
i=1
(Ï•i(1) + Ï•i(0))vi = 0) .
Consider the problem of finding a minimum of J over U2. Prove that the Lagrange multiplier
Î» for which the Lagrangian has a critical point is Î» = âˆ’1/2. Prove that J is elliptic on U2
with the same norm as in (2). Prove that J has a unique minimum on U2.
(4) Consider the the subset of R
n given by
U3 =
( v âˆˆ R
n
|
nX
i=1
(Ï•i(1) âˆ’ Ï•i(0))vi = 0) .
This time show that the necessary condition for having a minimum on U3 yields the equation
1 + Î»(1 âˆ’ 1) = 0. Conclude that J does not have a minimum on U3.
1724 CHAPTER 49. GENERAL RESULTS OF OPTIMIZATION THEORY
Problem 49.3. Let A be a real n Ã— n symmetric positive definite matrix and let b âˆˆ R
n
.
(1) Prove that if we apply the steepest descent method (for the Euclidean norm) to
J(v) = 1
2
h
Av, vi âˆ’ hb, vi ,
and if we define the norm k vk A
by
k
vk A = h Av, vi 1/2
,
we get the inequality
k
uk+1 âˆ’ uk
2
A â‰¤ kuk âˆ’ uk
2
A
 
1 âˆ’
k
A(uk âˆ’ u)k
4
2
k
uk âˆ’ uk
2
A
k A(uk âˆ’ u)k
2
A
!
.
(2) Using a diagonalization of A, where the eigenvalues of A are denoted 0 < Î»1 â‰¤ Î»2 â‰¤
Â· Â· Â· â‰¤ Î»n, prove that
k
uk+1 âˆ’ uk A â‰¤
cond2(A) âˆ’ 1
cond2(A) + 1 k uk âˆ’ uk A
,
where cond2(A) = Î»n/Î»1, and thus
k
uk âˆ’ uk A â‰¤

cond2(A) âˆ’ 1
cond2(A) + 1
k
k
u0 âˆ’ uk A
.
(3) Prove that when cond2(A) = 1, then A = I and the method converges in one step.
Problem 49.4. Prove that the method of Polakâ€“Ribi`ere converges if J : R
n â†’ R is elliptic
and a C
2
function.
Problem 49.5. Prove that the backtracking line search method described in Section 49.5 has
the property that for t small enough the condition J(uk+tdk) â‰¤ J(uk)+Î±thâˆ‡Juk
, dki will hold
and the search will stop. Prove that the exit inequality J(uk + tdk) â‰¤ J(uk) + Î±thâˆ‡Juk
, dki
holds for all t âˆˆ (0, t0], for some t0 > 0, so the backtracking line search stops with a step
length Ïk that satisfies Ïk = 1 or Ïk âˆˆ (Î²t0, t0].
Problem 49.6. Let dnsd,k and dsd,k be the normalized and unnormalized descent directions
of the steepest descent method for an arbitrary norm (see Section 49.8). Prove that
hâˆ‡Juk
, dnsd,ki = âˆ’ kâˆ‡Juk
k
D
hâˆ‡Juk
, dsd,ki = âˆ’(kâˆ‡Juk
k
D
)
2
dsd,k = arg min
v

hâˆ‡Juk
, vi +
1
2
k
vk
2

.
49.14. PROBLEMS 1725
Problem 49.7. If P is a symmetric positive definite matrix, prove that k zk P = (z
> P z)
1/2 = 

P
1/2
z

2
is a norm. Prove that the normalized steepest descent direction is
dnsd,k = âˆ’(âˆ‡Ju
>k
P
âˆ’1âˆ‡Juk
)
âˆ’1/2P
âˆ’1âˆ‡Juk
,
the dual norm is k zk
D =
  P
âˆ’1/2
z

2
, and the steepest descent direction with respect to k k P
is given by
dsd,k = âˆ’P
âˆ’1âˆ‡Juk
.
Problem 49.8. If k k is the ` 1
-norm, then show that dnsd,k is determined as follows: let i
be any index for which kâˆ‡Juk
k âˆ = |(âˆ‡Juk
)i
|. Then
dnsd,k = âˆ’sign  âˆ‚x
âˆ‚J
i
(uk)
 ei
,
where ei
is the ith canonical basis vector, and
dsd,k = âˆ’
âˆ‚J
âˆ‚xi
(uk)ei
.
Problem 49.9. (From Boyd and Vandenberghe [29], Problem 9.12). If âˆ‡2
f(x) is singular
(or very ill-conditioned), the Newton step dnt = âˆ’(âˆ‡2J(x))âˆ’1âˆ‡Jx is not well defined. Instead
we can define a search direction dtr as the solution of the problem
minimize (1/2)h Hv, vi + h g, vi
subject to k vk 2 â‰¤ Î³,
where H = âˆ‡2
fx, g = âˆ‡fx, and Î³ is some positive constant. The idea is to use a trust
region, which is the closed ball {v | kvk 2 â‰¤ Î³}. The point x+dtr minimizes the second-order
approximation of f at x, subject to the constraint that
k
x + dtr âˆ’ xk 2 â‰¤ Î³.
The parameter Î³, called the trust parameter , reflects our confidence in the second-order
approximation.
Prove that dtr minimizes
1
2
h
Hv, vi + h g, vi + b Î² k vk
2
2
,
for some Î²b.
Problem 49.10. (From Boyd and Vandenberghe [29], Problem 9.9). Prove that the Newton
decrement Î»(x) is given by
Î»(x) = sup
v6=0
âˆ’
hâˆ‡Jx, vi
(hâˆ‡2Jxv, vi )
1/2
.
1726 CHAPTER 49. GENERAL RESULTS OF OPTIMIZATION THEORY
Problem 49.11. Show that the function f given by f(x) = log(e
x + e
âˆ’x
) has a unique
minimum for x
âˆ— = 0. Run Newtonâ€™s method with fixed step size t = 1, starting with x0 = 1,
and then x0 = 1.1. What do you observe?
Problem 49.12. Write a Matlab program implementing the conjugate gradient method.
Test your program with the n Ã— n matrix
An =
ï£«
ï£¬ï£¬ï£¬ï£¬ï£¬ï£­
âˆ’
2
.
.
1 2
âˆ’1 0
âˆ’1
Â· Â· Â·
. . .
0
0
.
.
.
.
.
.
.
.
.
.
.
.
.
0
0
Â· Â· Â· âˆ’
Â· Â· Â· 0
1 2
âˆ’1 2
âˆ’1
ï£¶
ï£·ï£·ï£·ï£·ï£·ï£¸
and various right-hand sides, for various values of n. Verify that the running time is O(n
3/2
).
Chapter 50
Introduction to Nonlinear
Optimization
This chapter contains the most important results of nonlinear optimization theory.
In Chapter 40 we investigated the problem of determining when a function J : â„¦ â†’ R
defined on some open subset â„¦ of a normed vector space E has a local extremum in a subset
U of â„¦ defined by equational constraints, namely
U = {x âˆˆ â„¦ | Ï•i(x) = 0, 1 â‰¤ i â‰¤ m},
where the functions Ï•i
: â„¦ â†’ R are continuous (and usually differentiable). Theorem 40.2
gave a necessary condition in terms of the Lagrange multipliers. In Section 40.3 we assumed
that U was a convex subset of â„¦; then Theorem 40.9 gave us a necessary condition for the
function J : â„¦ â†’ R to have a local minimum at u with respect to U if dJu exists, namely
dJu(v âˆ’ u) â‰¥ 0 for all v âˆˆ U.
Our first goal is to find a necessary criterion for a function J : â„¦ â†’ R to have a minimum
on a subset U, even is this subset is not convex. This can be done by introducing a notion
of â€œtangent coneâ€ at a point u âˆˆ U. We define the cone of feasible directions and then
state a necessary condition for a function to have local minimum on a set U that is not
necessarily convex in terms of the cone of feasible directions. The cone of feasible directions
is not always convex, but it is if the constraints are inequality constraints. An inequality
constraint Ï•(u) â‰¤ 0 is said to be active if Ï•(u) = 0. One can also define the notion of
qualified constraint. Theorem 50.5 gives necessary conditions for a function J to have a
minimum on a subset U defined by qualified inequality constraints in terms of the Karushâ€“
Kuhnâ€“Tucker conditions (for short KKT conditions), which involve nonnegative Lagrange
multipliers. The proof relies on a version of the Farkasâ€“Minkowski lemma. Some of the KTT
conditions assert that Î»iÏ•i(u) = 0, where Î»i â‰¥ 0 is the Lagrange multiplier associated with
the constraint Ï•i â‰¤ 0. To some extent, this implies that active constaints are more important
than inactive constraints, since if Ï•i(u) < 0 is an inactive constraint, then Î»i = 0. In general,
1727
1728 CHAPTER 50. INTRODUCTION TO NONLINEAR OPTIMIZATION
the KKT conditions are useless unlesss the constraints are convex. In this case, there is a
manageable notion of qualified constraint given by Slaterâ€™s conditions. Theorem 50.6 gives
necessary conditions for a function J to have a minimum on a subset U defined by convex
inequality constraints in terms of the Karushâ€“Kuhnâ€“Tucker conditions. Furthermore, if J is
also convex and if the KKT conditions hold, then J has a global minimum.
In Section 50.4, we apply Theorem 50.6 to the special case where the constraints are
equality constraints, which can be expressed as Ax = b. In the special case where the convex
objective function J is a convex quadratic functional of the form
J(x) = 1
2
x
> P x + q
> x + r,
where P is a n Ã— n symmetric positive semidefinite matrix, the necessary and sufficient
conditions for having a minimum are expressed by a linear system involving a matrix called
the KKT matrix. We discuss conditions that guarantee that the KKT matrix is invertible,
and how to solve the KKT system. We also briefly discuss variants of Newtonâ€™s method
dealing with equality constraints.
We illustrate the KKT conditions on an interesting example, the so-called hard margin
support vector machine; see Sections 50.5 and 50.6. The problem is a classification problem,
or more accurately a separation problem. Suppose we have two nonempty disjoint finite sets
of p blue points {ui}
p
i=1 and q red points {vj}
q
j=1 in R
n
. Our goal is to find a hyperplane H
of equation w
> x âˆ’ b = 0 (where w âˆˆ R
n
is a nonzero vector and b âˆˆ R), such that all the
blue points ui are in one of the two open half-spaces determined by H, and all the red points
vj are in the other open half-space determined by H.
If the two sets are indeed separable, then in general there are infinitely many hyperplanes
separating them. Vapnik had the idea to find a hyperplane that maximizes the smallest
distance between the points and the hyperplane. Such a hyperplane is indeed unique and
is called a maximal hard margin hyperplane, or hard margin support vector machine. The
support vectors are those for which the constraints are active.
Section 50.7 contains the most important results of the chapter. The notion of Lagrangian
duality is presented. Given a primal optimization problem (P) consisting in minimizing an
objective function J(v) with respect to some inequality constraints Ï•i(v) â‰¤ 0, i = 1, . . . , m,
we define the dual function G(Âµ) as the result of minimizing the Lagrangian
L(v, Âµ) = J(v) +
mX
i=1
ÂµiÏ•i(v)
with respect to v, with Âµ âˆˆ R
m
+ . The dual program (D) is then to maximize G(Âµ) with
respect to Âµ âˆˆ R
m
+ . It turns out that G is a concave function, and the dual program is an
unconstrained maximization. This is actually a misleading statement because G is generally
a partial function, so maximizing G(Âµ) is equivalent to a constrained maximization problem
in which the constraints specify the domain of G, but in many cases, we obtain a dual
50.1. THE CONE OF FEASIBLE DIRECTIONS 1729
program simpler than the primal program. If d
âˆ—
is the optimal value of the dual program
and if p
âˆ—
is the optimal value of the primal program, we always have
d
âˆ— â‰¤ p
âˆ—
,
which is known as weak duality. Under certain conditions, d
âˆ— = p
âˆ—
, that is, the duality gap
is zero, in which case we say that strong duality holds. Also, under certain conditions, a
solution of the dual yields a solution of the primal, and if the primal has an optimal solution,
then the dual has an optimal solution, but beware that the converse is generally false (see
Theorem 50.17). We also show how to deal with equality constraints, and discuss the use of
conjugate functions to find the dual function. Our coverage of Lagrangian duality is quite
thorough, but we do not discuss more general orderings such as the semidefinite ordering.
For these topics which belong to convex optimization, the reader is referred to Boyd and
Vandenberghe [29].
Our approach in this chapter is very much inspired by Ciarlet [41] because we find it
one of the more direct, and it is general enough to accomodate Hilbert spaces. The field
of nonlinear optimization and convex optimization is vast and there are many books on the
subject. Among those we recommend (in alphabetic order) Bertsekas [16, 17, 18], Bertsekas,
NediÂ´c, and Ozdaglar [19], Boyd and Vandenberghe [29], Luenberger [116], and Luenberger
and Ye [117].
50.1 The Cone of Feasible Directions
Let V be a normed vector space and let U be a nonempty subset of V . For any point u âˆˆ U,
consider any converging sequence (uk)kâ‰¥0 of vectors uk âˆˆ U having u as their limit, with
uk 6 = u for all k â‰¥ 0, and look at the sequence of â€œunit chords,â€
uk âˆ’ u
k
uk âˆ’ uk
.
This sequence could oscillate forever, or it could have a limit, some unit vector wb âˆˆ V . In
the second case, all nonzero vectors Î»wb for all Î» > 0, belong to an object called the cone of
feasible directions at u. First, we need to define the notion of cone.
Definition 50.1. Given a (real) vector space V , a nonempty subset C âŠ† V is a cone with
apex 0 (for short, a cone), if for any v âˆˆ V , if v âˆˆ C, then Î»v âˆˆ C for all Î» > 0 (Î» âˆˆ R). For
any u âˆˆ V , a cone with apex u is any nonempty subset of the form u + C = {u + v | v âˆˆ C},
where C is a cone with apex 0; see Figure 50.1.
Observe that a cone with apex 0 (or u) is not necessarily convex, and that 0 does not
necessarily belong to C (resp. u does not necessarily belong to u + C) (although in the case
of the cone of feasible directions C(u) we have 0 âˆˆ C(u)). The condition for being a cone
only asserts that if a nonzero vector v belongs to C, then the open ray {Î»v | Î» > 0} (resp.
the affine open ray u + {Î»v | Î» > 0}) also belongs to C.
1730 CHAPTER 50. INTRODUCTION TO NONLINEAR OPTIMIZATION
(0,0,1)
V
C
(0,0,0)
(0.25, 0.5, 0.5) = u
(0.25, 0.5, 1.5)
u + C
Figure 50.1: Let C be the cone determined by the bold orange curve through (0, 0, 1) in the
plane z = 1. Then u+C, where u = (0.25, 0.5, 0.5), is the affine translate of C via the vector
u.
Definition 50.2. Let V be a normed vector space and let U be a nonempty subset of V .
For any point u âˆˆ U, the cone C(u) of feasible directions at u is the union of {0} and the
set of all nonzero vectors w âˆˆ V for which there exists some convergent sequence (uk)kâ‰¥0 of
vectors such that
(1) uk âˆˆ U and uk 6 = u for all k â‰¥ 0, and limk7â†’âˆ uk = u.
(2) limk7â†’âˆ
uk âˆ’ u
k
uk âˆ’ uk
=
w
k
wk
, with w 6 = 0.
Condition (2) can also be expressed as follows: there is a sequence (Î´k)kâ‰¥0 of vectors Î´k âˆˆ V
such that
uk = u + k uk âˆ’ uk
w
k
wk
+ k uk âˆ’ uk Î´k, lim
k7â†’âˆ
Î´k = 0, w 6 = 0.
Figure 50.2 illustrates the construction of w in C(u).
Clearly, the cone C(u) of feasible directions at u is a cone with apex 0, and u + C(u) is a
cone with apex u. Obviously, it would be desirable to have conditions on U that imply that
C(u) is a convex cone. Such conditions will be given later on.
Observe that the cone C(u) of feasible directions at u contains the velocity vectors at u of
all curves Î³ in U through u. If Î³ : (âˆ’1, 1) â†’ U is such a curve with Î³(0) = u, and if Î³
0 (u) 6 = 0
50.1. THE CONE OF FEASIBLE DIRECTIONS 1731 U
u u1
u1
u
- u
u1 - u
u1 - u
uk - u
u2
u2 - u
u2 - u
k
uk - u
w
w
Figure 50.2: Let U be the pink region in R
2 with fuchsia point u âˆˆ U. For any sequence
(uk)kâ‰¥0 of points in U which converges to u, form the chords uk âˆ’ u and take the limit to
construct the red vector w.
exists, then there is a sequence (uk)kâ‰¥0 of vectors in U converging to u as in Definition 50.2,
with uk = Î³(tk) for some sequence (tk)kâ‰¥0 of reals tk > 0 such that limk7â†’âˆ tk = 0, so that
uk âˆ’ u = tkÎ³
0 (0) + tk k, lim
k7â†’âˆ

k = 0,
and we get
lim
k7â†’âˆ
uk âˆ’ u
k
uk âˆ’ uk
=
Î³
0 (0)
k
Î³
0 (0)k .
For an illustration of this paragraph in R
2
, see Figure 50.3.
Example 50.1. In V = R
2
, let Ï•1 and Ï•2 be given by
Ï•1(u1, u2) = âˆ’u1 âˆ’ u2
Ï•2(u1, u2) = u1(u
2
1 + u
2
2
) âˆ’ (u
2
1 âˆ’ u
2
2
),
and let
U = {(u1, u2) âˆˆ R
2
| Ï•1(u1, u2) â‰¤ 0, Ï•2(u1, u2) â‰¤ 0}.
The region U is shown in Figure 50.4 and is bounded by the curve given by the equation
Ï•1(u1, u2) = 0, that is, âˆ’u1 âˆ’ u2 = 0, the line of slope âˆ’1 through the origin, and the curve
given by the equation u1(u
2
1 + u
2
2
) âˆ’ (u
2
1 âˆ’ u
2
2
) = 0, a nodal cubic through the origin. We
obtain a parametric definition of this curve by letting u2 = tu1, and we find that
u1(t) = u
u
2
1
2
1
(
(
t
t
)
) +
âˆ’
u
u
2
2
2
2
(
(
t
t
)
)
=
1
1 +
âˆ’
t
t
2
2
, u2(t) = t(1
1 +
âˆ’
t
t
2
2
)
.
The tangent vector at t is given by (u
01
(t), u02
(t)) with
u
01
(t) = âˆ’2t(1 + t
2
) âˆ’ (1 âˆ’ t
2
)2t
(1 + t
2
)
2
=
âˆ’4t
(1 + t
2
)
2
1732 CHAPTER 50. INTRODUCTION TO NONLINEAR OPTIMIZATION
0
0
t t t 1 k 2
t
1 t
k t
2
u
u u u
1 2 k
u
1 u
2
uk
(i.)
Î³ â€˜
(0)
Î³ â€˜
(0)
Î³
Î³
C(u)
(ii.)
U
Figure 50.3: Let U be purple region in R
2 and u be the designated point on the boundary of
U. Figure (i.) illustrates two curves through u and two sequences (uk)kâ‰¥0 converging to u.
The limit of the chords uk âˆ’ u corresponds to the tangent vectors for the appropriate curve.
Figure (ii.) illustrates the half plane C(u) of feasible directions.
and
u
02
(t) = (1 âˆ’ 3t
2
)(1 + t
2
) âˆ’ (t âˆ’ t
3
