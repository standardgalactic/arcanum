x = u
(u,0)
L(u, Î»)
(0, Î»)
(u,0)
(i.)
M
â„¦
(0, Î»)
x = u
(u,0)
(0, Î»)
L(u, Î»)
(ii.)
Figure 50.18: Let â„¦ = {[t, 0, 0] | 0 â‰¤ t â‰¤ 1} and M = {[0, t, 0] | 0 â‰¤ t â‰¤ 1}. In Figure (i.),
L(u, Î») is the blue slanted quadrilateral whose forward vertex is a saddle point. In Figure
(ii.), L(u, Î») is the planar green rectangle composed entirely of saddle points.
Pick any w âˆˆ â„¦ and any Ï âˆˆ M. By definition of inf (the greatest lower bound) and sup
(the least upper bound), we have
inf
vâˆˆâ„¦
L(v, Ï) â‰¤ L(w, Ï) â‰¤ sup
ÂµâˆˆM
L(w, Âµ).
The cases where infvâˆˆâ„¦ L(v, Ï) = âˆ’âˆž or where supÂµâˆˆM L(w, Âµ) = +âˆž may arise, but this is
not a problem. Since
inf
vâˆˆâ„¦
L(v, Ï) â‰¤ sup
ÂµâˆˆM
L(w, Âµ)
and the right-hand side is independent of Ï, it is an upper bound of the left-hand side for
all Ï, so
sup
ÂµâˆˆM
inf
vâˆˆâ„¦
L(v, Âµ) â‰¤ sup
ÂµâˆˆM
L(w, Âµ).
y = Î»
y = Î»
50.7. LAGRANGIAN DUALITY AND SADDLE POINTS 1775
Since the left-hand side is independent of w, it is a lower bound for the right-hand side for
all w, so we obtain (âˆ—1):
sup
ÂµâˆˆM
inf
vâˆˆâ„¦
L(v, Âµ) â‰¤ inf
vâˆˆâ„¦
sup
ÂµâˆˆM
L(v, Âµ).
To obtain the reverse inequality, we use the fact that (u, Î») is a saddle point, so
inf
vâˆˆâ„¦
sup
ÂµâˆˆM
L(v, Âµ) â‰¤ sup
ÂµâˆˆM
L(u, Âµ) = L(u, Î»)
and
L(u, Î») = inf
vâˆˆâ„¦
L(v, Î») â‰¤ sup
ÂµâˆˆM
inf
vâˆˆâ„¦
L(v, Âµ),
and these imply that
inf
vâˆˆâ„¦
sup
ÂµâˆˆM
L(v, Âµ) â‰¤ sup
ÂµâˆˆM
inf
vâˆˆâ„¦
L(v, Âµ), (âˆ—2)
as desired.
We now return to our main Minimization Problem (P):
minimize J(v)
subject to Ï•i(v) â‰¤ 0, i = 1, . . . , m,
where J : â„¦ â†’ R and the constraints Ï•i
: â„¦ â†’ R are some functions defined on some open
subset â„¦ of some finite-dimensional Euclidean vector space V (more generally, a real Hilbert
space V ).
Definition 50.8. The Lagrangian of the Minimization Problem (P) defined above is the
function L: â„¦ Ã— R
m
+ â†’ R given by
L(v, Âµ) = J(v) +
mX
i=1
ÂµiÏ•i(v),
with Âµ = (Âµ1, . . . , Âµm). The numbers Âµi are called generalized Lagrange multipliers.
The following theorem shows that under some suitable conditions, every solution u of
the Problem (P) is the first argument of a saddle point (u, Î») of the Lagrangian L, and
conversely, if (u, Î») is a saddle point of the Lagrangian L, then u is a solution of the Problem
(P).
Theorem 50.15. Consider Problem (P) defined above where J : â„¦ â†’ R and the constraints
Ï•i
: â„¦ â†’ R are some functions defined on some open subset â„¦ of some finite-dimensional
Euclidean vector space V (more generally, a real Hilbert space V ). The following facts hold.
(1) If (u, Î») âˆˆ â„¦ Ã— R
m
+ is a saddle point of the Lagrangian L associated with Problem (P),
then u âˆˆ U, u is a solution of Problem (P), and J(u) = L(u, Î»).
1776 CHAPTER 50. INTRODUCTION TO NONLINEAR OPTIMIZATION
(2) If â„¦ is convex (open), if the functions Ï•i (1 â‰¤ i â‰¤ m) and J are convex and differenï¿¾tiable at the point u âˆˆ U, if the constraints are qualified, and if u âˆˆ U is a minimum of
Problem (P), then there exists some vector Î» âˆˆ R
m
+ such that the pair (u, Î») âˆˆ â„¦ Ã— R
m
+
is a saddle point of the Lagrangian L.
Proof. (1) Since (u, Î») is a saddle point of L we have supÂµâˆˆRm
+
L(u, Âµ) = L(u, Î») which implies
that L(u, Âµ) â‰¤ L(u, Î») for all Âµ âˆˆ R
m
+ , which means that
J(u) +
mX
i=1
ÂµiÏ•i(u) â‰¤ J(u) +
mX
i=1
Î»iÏ•i(u),
that is,
mX
i=1
(Âµi âˆ’ Î»i)Ï•i(u) â‰¤ 0 for all Âµ âˆˆ R
m
+ .
If we let each Âµi be large enough, then Âµi âˆ’ Î»i > 0, and if we had Ï•i(u) > 0, then the term
(Âµi âˆ’ Î»i)Ï•i(u) could be made arbitrarily large and positive, so we conclude that Ï•i(u) â‰¤ 0
for i = 1, . . . , m, and consequently, u âˆˆ U. For Âµ = 0, we conclude that P m
i=1 Î»iÏ•i(u) â‰¥ 0.
However, since Î»i â‰¥ 0 and Ï•i(u) â‰¤ 0, (since u âˆˆ U), we have P m
i=1 Î»iÏ•i(u) â‰¤ 0. Combining
these two inequalities shows that
mX
i=1
Î»iÏ•i(u) = 0. (âˆ—1)
This shows that J(u) = L(u, Î»). Since the inequality L(u, Î») â‰¤ L(v, Î») is
J(u) +
mX
i=1
Î»iÏ•i(u) â‰¤ J(v) +
mX
i=1
Î»iÏ•i(v),
by (âˆ—1) we obtain
J(u) â‰¤ J(v) +
mX
i=1
Î»iÏ•i(v) for all v âˆˆ â„¦
â‰¤ J(v) for all v âˆˆ U (since Ï•i(v) â‰¤ 0 and Î»i â‰¥ 0),
which shows that u is a minimum of J on U.
(2) The hypotheses required to apply Theorem 50.6(1) are satisfied. Consequently if
u âˆˆ U is a solution of Problem (P), then there exists some vector Î» âˆˆ R
m
+ such that the
KKT conditions hold:
J
0 (u) +
mX
i=1
Î»i(Ï•
0i
)u = 0 and
mX
i=1
Î»iÏ•i(u) = 0.
50.7. LAGRANGIAN DUALITY AND SADDLE POINTS 1777
The second equation yields
L(u, Âµ) = J(u) +
mX
i=1
ÂµiÏ•i(u) â‰¤ J(u) = J(u) +
mX
i=1
Î»iÏ•i(u) = L(u, Î»),
that is,
L(u, Âµ) â‰¤ L(u, Î») for all Âµ âˆˆ R
m
+ (âˆ—2)
(since Ï•i(u) â‰¤ 0 as u âˆˆ U), and since the function v 7â†’ J(v) + P i=1 Î»iÏ•i(v) = L(v, Î») is
convex as a sum of convex functions, by Theorem 40.13(4), the first equation is a sufficient
condition for the existence of minimum. Consequently,
L(u, Î») â‰¤ L(v, Î») for all v âˆˆ â„¦, (âˆ—3)
and (âˆ—2) and (âˆ—3) show that (u, Î») is a saddle point of L.
To recap what we just proved, under some mild hypotheses, the set of solutions of the
Minimization Problem (P)
minimize J(v)
subject to Ï•i(v) â‰¤ 0, i = 1, . . . , m
coincides with the set of first arguments of the saddle points of the Lagrangian
L(v, Âµ) = J(v) +
mX
i=1
ÂµiÏ•i(v),
and for any optimum u âˆˆ U of Problem (P), we have J(u) = L(u, Î»).
Therefore, if we knew some particular second argument Î» of these saddle points, then
the constrained Problem (P) would be replaced by the unconstrained Problem (PÎ»):
find uÎ» âˆˆ â„¦ such that
L(uÎ», Î») = inf
vâˆˆâ„¦
L(v, Î»).
How do we find such an element Î» âˆˆ R
m
+ ?
For this, remember that for a saddle point (uÎ», Î»), by Proposition 50.14, we have
L(uÎ», Î») = inf
vâˆˆâ„¦
L(v, Î») = sup
ÂµâˆˆRm
+
inf
vâˆˆâ„¦
L(v, Âµ),
so we are naturally led to introduce the function G: R
m
+ â†’ R given by
G(Âµ) = inf
vâˆˆâ„¦
L(v, Âµ) Âµ âˆˆ R
m
+ ,
1778 CHAPTER 50. INTRODUCTION TO NONLINEAR OPTIMIZATION
and then Î» will be a solution of the problem
find Î» âˆˆ R
m
+ such that
G(Î») = sup
ÂµâˆˆRm
+
G(Âµ),
which is equivalent to the Maximization Problem (D):
maximize G(Âµ)
subject to Âµ âˆˆ R
m
+ .
Definition 50.9. Given the Minimization Problem (P)
minimize J(v)
subject to Ï•i(v) â‰¤ 0, i = 1, . . . , m,
where J : â„¦ â†’ R and the constraints Ï•i
: â„¦ â†’ R are some functions defined on some open
subset â„¦ of some finite-dimensional Euclidean vector space V (more generally, a real Hilbert
space V ), the function G: R
m
+ â†’ R given by
G(Âµ) = inf
vâˆˆâ„¦
L(v, Âµ) Âµ âˆˆ R
m
+ ,
is called the Lagrange dual function (or simply dual function). The Problem (D)
maximize G(Âµ)
subject to Âµ âˆˆ R
m
+
is called the Lagrange dual problem. The Problem (P) is often called the primal problem,
and (D) is the dual problem. The variable Âµ is called the dual variable. The variable Âµ âˆˆ R
m
+
is said to be dual feasible if G(Âµ) is defined (not âˆ’âˆž). If Î» âˆˆ R
m
+ is a maximum of G, then
we call it a dual optimal or an optimal Lagrange multiplier .
Since
L(v, Âµ) = J(v) +
mX
i=1
ÂµiÏ•i(v),
the function G(Âµ) = infvâˆˆâ„¦ L(v, Âµ) is the pointwise infimum of some affine functions of Âµ,
so it is concave, even if the Ï•i are not convex. One of the main advantages of the dual
problem over the primal problem is that it is a convex optimization problem, since we wish
to maximize a concave objective function G (thus minimize âˆ’G, a convex function), and the
constraints Âµ â‰¥ 0 are convex. In a number of practical situations, the dual function G can
indeed be computed.
To be perfectly rigorous, we should mention that the dual function G is actually a partial
function, because it takes the value âˆ’âˆž when the map v 7â†’ L(v, Âµ) is unbounded below.
50.7. LAGRANGIAN DUALITY AND SADDLE POINTS 1779
Example 50.5. Consider the Linear Program (P)
minimize c
> v
subject to Av â‰¤ b, v â‰¥ 0,
where A is an mÃ—n matrix. The constraints v â‰¥ 0 are rewritten as âˆ’vi â‰¤ 0, so we introduce
Lagrange multipliers Âµ âˆˆ R
m
+ and Î½ âˆˆ R
n
+, and we have the Lagrangian
L(v, Âµ, Î½) = c
> v + Âµ
> (Av âˆ’ b) âˆ’ Î½
> v
= âˆ’b
> Âµ + (c + A
> Âµ âˆ’ Î½)
> v.
The linear function v 7â†’ (c + A> Âµ âˆ’ Î½)
> v is unbounded below unless c + A> Âµ âˆ’ Î½ = 0, so
the dual function G(Âµ, Î½) = infvâˆˆRn L(v, Âµ, Î½) is given for all Âµ â‰¥ 0 and Î½ â‰¥ 0 by
G(Âµ, Î½) = ( âˆ’
âˆ’âˆž
b
> Âµ if
otherwise
A> Âµ âˆ’
.
Î½ + c = 0,
The domain of G is a proper subset of R
m
+ Ã— R
n
+.
Observe that the value G(Âµ, Î½) of the function G, when it is defined, is independent of
the second argument Î½. Since we are interested in maximizing G, this suggests introducing
the function Gb of the single argument Âµ given by
Gb(Âµ) = âˆ’b
> Âµ,
which is defined for all Âµ âˆˆ R
m
+ .
Of course, supÂµâˆˆRm
+
b
G(Âµ) and sup(Âµ,Î½)âˆˆRm
+ Ã—Rn
+
G(Âµ, Î½) are generally different, but note that
Gb(Âµ) = G(Âµ, Î½) iff there is some Î½ âˆˆ R
n
+ such that A> Âµâˆ’Î½+c = 0 iff A> Âµ+c â‰¥ 0. Therefore,
finding sup(Âµ,Î½)âˆˆRm
+ Ã—Rn
+
G(Âµ, Î½) is equivalent to the constrained Problem (D1)
maximize âˆ’ b
> Âµ
subject to A
> Âµ â‰¥ âˆ’c, Âµ â‰¥ 0.
The above problem is the dual of the Linear Program (P).
In summary, the dual function G of a primary Problem (P) often contains hidden inequalï¿¾ity constraints that define its domain, and sometimes it is possible to make these domain
constraints Ïˆ1(Âµ) â‰¤ 0, . . . , Ïˆp(Âµ) â‰¤ 0 explicit, to define a new function Gb that depends only
on q < m of the variables Âµi and is defined for all values Âµi â‰¥ 0 of these variables, and
to replace the Maximization Problem (D), find supÂµâˆˆRm
+
G(Âµ), by the constrained Problem
(D1)
maximize Gb(Âµ)
subject to Ïˆi(Âµ) â‰¤ 0, i = 1, . . . , p.
Problem (D1) is different from the Dual Program (D), but it is equivalent to (D) as a
maximization problem.
1780 CHAPTER 50. INTRODUCTION TO NONLINEAR OPTIMIZATION
50.8 Weak and Strong Duality
Another important property of the dual function G is that it provides a lower bound on the
value of the objective function J. Indeed, we have
G(Âµ) â‰¤ L(u, Âµ) â‰¤ J(u) for all u âˆˆ U and all Âµ âˆˆ R
m
+ , (â€ )
since Âµ â‰¥ 0 and Ï•i(u) â‰¤ 0 for i = 1, . . . , m, so
G(Âµ) = inf
vâˆˆâ„¦
L(v, Âµ) â‰¤ L(u, Âµ) = J(u) +
mX
i=1
ÂµiÏ•i(u) â‰¤ J(u).
If the Primal Problem (P) has a minimum denoted p
âˆ— and the Dual Problem (D) has a
maximum denoted d
âˆ—
, then the above inequality implies that
d
âˆ— â‰¤ p
âˆ—
(â€ w)
known as weak duality. Equivalently, for every optimal solution Î»
âˆ— of the dual problem and
every optimal solution u
âˆ— of the primal problem, we have
G(Î»
âˆ—
) â‰¤ J(u
âˆ—
). (â€ w0 )
In particular, if p
âˆ— = âˆ’âˆž, which means that the primal problem is unbounded below, then
the dual problem is unfeasible. Conversely, if d
âˆ— = +âˆž, which means that the dual problem
is unbounded above, then the primal problem is unfeasible.
Definition 50.10. The difference p
âˆ—âˆ’d
âˆ— â‰¥ 0 is called the optimal duality gap. If the duality
gap is zero, that is, p
âˆ— = d
âˆ—
, then we say that strong duality holds.
Even when the duality gap is strictly positive, the inequality (â€ w) can be helpful to find
a lower bound on the optimal value of a primal problem that is difficult to solve, since the
dual problem is always convex.
If the primal problem and the dual problem are feasible and if the optimal values p
âˆ— and
d
âˆ— are finite and p
âˆ— = d
âˆ—
(no duality gap), then the complementary slackness conditions hold
for the inequality constraints.
Proposition 50.16. (Complementary Slackness) Given the Minimization Problem (P)
minimize J(v)
subject to Ï•i(v) â‰¤ 0, i = 1, . . . , m,
and its Dual Problem (D)
maximize G(Âµ)
subject to Âµ âˆˆ R
m
+ ,
50.8. WEAK AND STRONG DUALITY 1781
if both (P) and (D) are feasible, u âˆˆ U is an optimal solution of (P), Î» âˆˆ R
m
+ is an optimal
solution of (D), and J(u) = G(Î»), then
mX
i=1
Î»iÏ•i(u) = 0.
In other words, if the constraint Ï•i is inactive at u, then Î»i = 0.
Proof. Since J(u) = G(Î») we have
J(u) = G(Î»)
= inf
vâˆˆâ„¦
 
J(v) +
mX
i=1
Î»iÏ•i(v)
! by definition of G
â‰¤ J(u) +
mX
i=1
Î»iÏ•i(u) the greatest lower bound is a lower bound
â‰¤ J(u) since Î»i â‰¥ 0, Ï•i(u) â‰¤ 0.
which implies that P m
i=1 Î»iÏ•i(u) = 0.
Going back to Example 50.5, we see that weak duality says that for any feasible solution
u of the Primal Problem (P), that is, some u âˆˆ R
n
such that
Au â‰¤ b, u â‰¥ 0,
and for any feasible solution Âµ âˆˆ R
m of the Dual Problem (D1), that is,
A
> Âµ â‰¥ âˆ’c, Âµ â‰¥ 0,
we have
âˆ’b
> Âµ â‰¤ c
> u.
Actually, if u and Î» are optimal, then we know from Theorem 47.7 that strong duality holds,
namely âˆ’b
> Âµ = c
> u, but the proof of this fact is nontrivial.
The following theorem establishes a link between the solutions of the Primal Problem
(P) and those of the Dual Problem (D). It also gives sufficient conditions for the duality
gap to be zero.
Theorem 50.17. Consider the Minimization Problem (P):
minimize J(v)
subject to Ï•i(v) â‰¤ 0, i = 1, . . . , m,
where the functions J and Ï•i are defined on some open subset â„¦ of a finite-dimensional
Euclidean vector space V (more generally, a real Hilbert space V ).
1782 CHAPTER 50. INTRODUCTION TO NONLINEAR OPTIMIZATION
(1) Suppose the functions Ï•i
: â„¦ â†’ R are continuous, and that for every Âµ âˆˆ R
m
+ , the
Problem (PÂµ):
minimize L(v, Âµ)
subject to v âˆˆ â„¦,
has a unique solution uÂµ, so that
L(uÂµ, Âµ) = inf
vâˆˆâ„¦
L(v, Âµ) = G(Âµ),
and the function Âµ 7â†’ uÂµ is continuous (on R
m
+ ). Then the function G is differentiable
for all Âµ âˆˆ R
m
+ , and
G
0Âµ
(Î¾) =
mX
i=1
Î¾iÏ•i(uÂµ) for all Î¾ âˆˆ R
m.
If Î» is any solution of Problem (D):
maximize G(Âµ)
subject to Âµ âˆˆ R
m
+ ,
then the solution uÎ» of the corresponding problem (PÎ») is a solution of Problem (P).
(2) Assume Problem (P) has some solution u âˆˆ U, and that â„¦ is convex (open), the
functions Ï•i (1 â‰¤ i â‰¤ m) and J are convex and differentiable at u, and that the
constraints are qualified. Then Problem (D) has a solution Î» âˆˆ R
m
+ , and J(u) = G(Î»);
that is, the duality gap is zero.
Proof. (1) Our goal is to prove that for any solution Î» of Problem (D), the pair (uÎ», Î») is a
saddle point of L. By Theorem 50.15(1), the point uÎ» âˆˆ U is a solution of Problem (P).
Since Î» âˆˆ R
m
+ is a solution of Problem (D), by definition of G(Î») and since uÎ» satisfies
Problem (PÎ»), we have
G(Î») = inf
vâˆˆâ„¦
L(v, Î») = L(uÎ», Î»),
which is one of the two equations characterizing a saddle point. In order to prove the second
equation characterizing a saddle point,
sup
ÂµâˆˆRm
+
L(uÂµ, Âµ) = L(uÎ», Î»),
we will begin by proving that the function G is differentiable for all Âµ âˆˆ R
m
+ , in order to be
able to apply Theorem 40.9 to conclude that since G has a maximum at Î», that is, âˆ’G has
minimum at Î», then âˆ’G0Î»
(Âµ âˆ’ Î») â‰¥ 0 for all Âµ âˆˆ R
m
+ . In fact, we prove that
G
0Âµ
(Î¾) =
mX
i=1
Î¾iÏ•i(uÂµ) for all Î¾ âˆˆ R
m. (âˆ—deriv)
50.8. WEAK AND STRONG DUALITY 1783
Consider any two points Âµ and Âµ + Î¾ in R
m
+ . By definition of uÂµ we have
L(uÂµ, Âµ) â‰¤ L(uÂµ+Î¾, Âµ),
which means that
J(uÂµ) +
mX
i=1
ÂµiÏ•i(uÂµ) â‰¤ J(uÂµ+Î¾) +
mX
i=1
ÂµiÏ•i(uÂµ+Î¾), (âˆ—1)
and since G(Âµ) = L(uÂµ, Âµ) = J(uÂµ) + P m
i=1 ÂµiÏ•i(uÂµ) and G(Âµ + Î¾) = L(uÂµ+Î¾, Âµ + Î¾) =
J(uÂµ+Î¾) + P m
i=1(Âµi + Î¾i)Ï•i(uÂµ+Î¾), we have
G(Âµ + Î¾) âˆ’ G(Âµ) = J(uÂµ+Î¾) âˆ’ J(uÂµ) +
mX
i=1
(Âµi + Î¾i)Ï•i(uÂµ+Î¾) âˆ’
mX
i=1
ÂµiÏ•i(uÂµ). (âˆ—2)
Since (âˆ—1) can be written as
0 â‰¤ J(uÂµ+Î¾) âˆ’ J(uÂµ) +
mX
i=1
ÂµiÏ•i(uÂµ+Î¾) âˆ’
mX
i=1
ÂµiÏ•i(uÂµ),
by adding P m
i=1 Î¾iÏ•i(uÂµ+Î¾) to both sides of the above inequality and using (âˆ—2) we get
mX
i=1
Î¾iÏ•i(uÂµ+Î¾) â‰¤ G(Âµ + Î¾) âˆ’ G(Âµ). (âˆ—3)
By definition of uÂµ+Î¾ we have
L(uÂµ+Î¾, Âµ + Î¾) â‰¤ L(uÂµ, Âµ + Î¾),
which means that
J(uÂµ+Î¾) +
mX
i=1
(Âµi + Î¾i)Ï•i(uÂµ+Î¾) â‰¤ J(uÂµ) +
mX
i=1
(Âµi + Î¾i)Ï•i(uÂµ). (âˆ—4)
This can be written as
J(uÂµ+Î¾) âˆ’ J(uÂµ) +
mX
i=1
(Âµi + Î¾i)Ï•i(uÂµ+Î¾) âˆ’
mX
i=1
(Âµi + Î¾i)Ï•i(uÂµ) â‰¤ 0,
and by adding P m
i=1 Î¾iÏ•i(uÂµ) to both sides of the above inequality and using (âˆ—2) we get
G(Âµ + Î¾) âˆ’ G(Âµ) â‰¤
mX
i=1
Î¾iÏ•i(uÂµ). (âˆ—5)
1784 CHAPTER 50. INTRODUCTION TO NONLINEAR OPTIMIZATION
By putting (âˆ—3) and (âˆ—5) together we obtain
mX
i=1
Î¾iÏ•i(uÂµ+Î¾) â‰¤ G(Âµ + Î¾) âˆ’ G(Âµ) â‰¤
mX
i=1
Î¾iÏ•i(uÂµ). (âˆ—6)
Consequently there is some Î¸ âˆˆ [0, 1] such that
G(Âµ + Î¾) âˆ’ G(Âµ) = (1 âˆ’ Î¸)

mX
i=1
Î¾iÏ•i(uÂµ)
 + Î¸

mX
i=1
Î¾iÏ•i(uÂµ+Î¾)

=
mX
i=1
Î¾iÏ•i(uÂµ) + Î¸

mX
i=1
Î¾i(Ï•i(uÂµ+Î¾) âˆ’ Ï•i(uÂµ)) .
Since by hypothesis the functions Âµ 7â†’ uÂµ (from R
m
+ to â„¦) and Ï•i
: â„¦ â†’ R are continuous,
for any Âµ âˆˆ R
m
+ we can write
G(Âµ + Î¾) âˆ’ G(Âµ) =
mX
i=1
Î¾iÏ•i(uÂµ) + k Î¾k  (Î¾), with limÎ¾7â†’0  (Î¾) = 0, (âˆ—7)
for any k k norm on R
m. Equation (âˆ—7) show that G is differentiable for any Âµ âˆˆ R
m
+ , and
that
G
0Âµ
(Î¾) =
mX
i=1
Î¾iÏ•i(uÂµ) for all Î¾ âˆˆ R
m. (âˆ—8)
Actually there is a small problem, namely that the notion of derivative was defined for a
function defined on an open set, but R
m
+ is not open. The difficulty only arises to ensure
that the derivative is unique, but in our case we have a unique expression for the derivative
so there is no problem as far as defining the derivative. There is still a potential problem,
which is that we would like to apply Theorem 40.9 to conclude that since G has a maximum
at Î», that is, âˆ’G has a minimum at Î», then
âˆ’G
0Î»
(Âµ âˆ’ Î») â‰¥ 0 for all Âµ âˆˆ R
m
+ , (âˆ—9)
but the hypotheses of Theorem 40.9 require the domain of the function to be open. Fortuï¿¾nately, close examination of the proof of Theorem 40.9 shows that the proof still holds with
U = R
m
+ . Therefore, (âˆ—8) holds, Theorem 40.9 is valid, which in turn implies
G
0Î»
(Âµ âˆ’ Î») â‰¤ 0 for all Âµ âˆˆ R
m
+ , (âˆ—10)
which, using the expression for G0Î»
given in (âˆ—8) gives
mX
i=1
ÂµiÏ•i(uÎ») â‰¤
mX
i=1
Î»iÏ•i(uÎ»), for all Âµ âˆˆ R
m
+ . (âˆ—11)
50.8. WEAK AND STRONG DUALITY 1785
As a consequence of (âˆ—11), we obtain
L(uÎ», Âµ) = J(uÎ») +
mX
i=1
ÂµiÏ•i(uÎ»)
â‰¤ J(uÎ») +
mX
i=1
Î»iÏ•i(uÎ») = L(uÎ», Î»),
for all Âµ âˆˆ R
m
+ , that is,
L(uÎ», Âµ) â‰¤ L(uÎ», Î»), for all Âµ âˆˆ R
m
+ , (âˆ—12)
which implies the second inequality
sup
ÂµâˆˆRm
+
L(uÂµ, Âµ) = L(uÎ», Î»)
stating that (uÎ», Î») is a saddle point. Therefore, (uÎ», Î») is a saddle point of L, as claimed.
(2) The hypotheses are exactly those required by Theorem 50.15(2), thus there is some
Î» âˆˆ R
m
+ such that (u, Î») is a saddle point of the Lagrangian L, and by Theorem 50.15(1) we
have J(u) = L(u, Î»). By Proposition 50.14, we have
J(u) = L(u, Î») = inf
vâˆˆâ„¦
L(v, Î») = sup
ÂµâˆˆRm
+
inf
vâˆˆâ„¦
L(v, Âµ),
which can be rewritten as
J(u) = G(Î») = sup
ÂµâˆˆRm
+
G(Âµ).
In other words, Problem (D) has a solution, and J(u) = G(Î»).
Remark: Note that Theorem 50.17(2) could have already be obtained as a consequence of
Theorem 50.15(2), but the dual function G was not yet defined. If (u, Î») is a saddle point of
the Lagrangian L (defined on â„¦ Ã— R
m
+ ), then by Proposition 50.14, the vector Î» is a solution
of Problem (D). Conversely, under the hypotheses of Part (1) of Theorem 50.17, if Î» is a
solution of Problem (D), then (uÎ», Î») is a saddle point of L. Consequently, under the above
hypotheses, the set of solutions of the Dual Problem (D) coincide with the set of second
arguments Î» of the saddle points (u, Î») of L. In some sense, this result is the â€œdualâ€ of the
result stated in Theorem 50.15, namely that the set of solutions of Problem (P) coincides
with set of first arguments u of the saddle points (u, Î») of L.
Informally, in Theorem 50.17(1), the hypotheses say that if G(Âµ) can be â€œcomputed
nicely,â€ in the sense that there is a unique minimizer uÂµ of L(v, Âµ) (with v âˆˆ â„¦) such that
G(Âµ) = L(uÂµ, Âµ), and if a maximizer Î» of G(Âµ) (with Âµ âˆˆ R
m
+ ) can be determined, then uÎ»
yields the minimum value of J, that is, p
âˆ— = J(uÎ»). If the constraints are qualified and if
the functions J and Ï•i are convex and differentiable, then since the KKT conditions hold,
the duality gap is zero; that is,
G(Î») = L(uÎ», Î») = J(uÎ»).
1786 CHAPTER 50. INTRODUCTION TO NONLINEAR OPTIMIZATION
Example 50.6. Going back to Example 50.5 where we considered the linear program (P)
minimize c
> v
subject to Av â‰¤ b, v â‰¥ 0,
with A an m Ã— n matrix, the Lagrangian L(v, Âµ, Î½) is given by
L(v, Âµ, Î½) = âˆ’b
> Âµ + (c + A
> Âµ âˆ’ Î½)
> v,
and we found that the dual function G(Âµ, Î½) = infvâˆˆRn L(v, Âµ, Î½) is given for all Âµ â‰¥ 0 and
Î½ â‰¥ 0 by
G(Âµ, Î½) = ( âˆ’
âˆ’âˆž
b
> Âµ if
otherwise
A> Âµ âˆ’
.
Î½ + c = 0,
The hypotheses of Theorem 50.17(1) certainly fail since there are infinitely uÂµ,Î½ âˆˆ R
n
such
that G(Âµ, Î½) = infvâˆˆRn L(v, Âµ, Î½) = L(uÂµ,Î½, Âµ, Î½). Therefore, the dual function G is no help in
finding a solution of the Primal Problem (P). As we saw earlier, if we consider the modified
dual Problem (D1) then strong duality holds, but this does not follow from Theorem 50.17,
and a different proof is required.
Thus, we have the somewhat counter-intuitive situation that the general theory of Laï¿¾grange duality does not apply, at least directly, to linear programming, a fact that is not
sufficiently emphasized in many expositions. A separate treatment of duality is required.
Unlike the case of linear programming, which needs a separate treatment, Theorem 50.17
applies to the optimization problem involving a convex quadratic objective function and a set
of affine inequality constraints. So in some sense, convex quadratic programming is simpler
than linear programming!
Example 50.7. Consider the quadratic objective function
J(v) = 1
2
v
> Av âˆ’ v
> b,
where A is an nÃ—n matrix which is symmetric positive definite, b âˆˆ R
n
, and the constraints
are affine inequality constraints of the form
Cv â‰¤ d,
where C is an m Ã— n matrix and d âˆˆ R
m. For the time being, we do not assume that C has
rank m. Since A is symmetric positive definite, J is strictly convex, as implied by Proposition
40.11 (see Example 40.6). The Lagrangian of this quadratic optimization problem is given
by
L(v, Âµ) = 1
2
v
> Av âˆ’ v
> b + (Cv âˆ’ d)
> Âµ
=
1
2
v
> Av âˆ’ v
> (b âˆ’ C
> Âµ) âˆ’ Âµ
> d.
50.8. WEAK AND STRONG DUALITY 1787
Since A is symmetric positive definite, by Proposition 42.2, the function v 7â†’ L(v, Âµ) has a
unique minimum obtained for the solution uÂµ of the linear system
Av = b âˆ’ C
> Âµ;
that is,
uÂµ = A
âˆ’1
(b âˆ’ C
> Âµ).
This shows that the Problem (PÂµ) has a unique solution which depends continuously on Âµ.
Then for any solution Î» of the dual problem, uÎ» = Aâˆ’1
(b âˆ’ C
> Î») is an optimal solution of
the primal problem.
We compute G(Âµ) as follows:
G(Âµ) = L(uÂµ, Âµ) = 1
2
u
>Âµ AuÂµ âˆ’ u
>Âµ
(b âˆ’ C
> Âµ) âˆ’ Âµ
> d
=
1
2
u
>Âµ
(b âˆ’ C
> Âµ) âˆ’ u
>Âµ
(b âˆ’ C
> Âµ) âˆ’ Âµ
> d
= âˆ’
1
2
u
>Âµ
(b âˆ’ C
> Âµ) âˆ’ Âµ
> d
= âˆ’
1
2
(b âˆ’ C
> Âµ)
> A
âˆ’1
(b âˆ’ C
> Âµ) âˆ’ Âµ
> d
= âˆ’
1
2
Âµ
> CAâˆ’1C
> Âµ + Âµ
> (CAâˆ’1
b âˆ’ d) âˆ’
1
2
b
> A
âˆ’1
b.
Since A is symmetric positive definite, the matrix CAâˆ’1C
> is symmetric positive semidefï¿¾inite. Since Aâˆ’1
is also symmetric positive definite, Âµ
> CAâˆ’1C
> Âµ = 0 iff (C
> Âµ)
> Aâˆ’1
(C
> Âµ) =
0 iff C
> Âµ = 0 implies Âµ = 0, that is, Ker C
> = (0), which is equivalent to Im(C) = R
m,
namely if C has rank m (in which case, m â‰¤ n). Thus CAâˆ’1C
> is symmetric positive definite
iff C has rank m.
We showed just after Theorem 49.8 that the functional v 7â†’ (1/2)v
> Av is elliptic iff
A is symmetric positive definite, and Theorem 49.8 shows that an elliptic functional is
coercive, which is the hypothesis used in Theorem 49.4. Therefore, by Theorem 49.4, if the
inequalities Cx â‰¤ d have a solution, the primal problem has a unique solution. In this case,
as a consequence, by Theorem 50.17(2), the function âˆ’G(Âµ) always has a minimum, which
is unique if C has rank m. The fact that âˆ’G(Âµ) has a minimum is not obvious when C has
rank < m, since in this case CAâˆ’1C
> is not invertible.
We also verify easily that the gradient of G is given by
âˆ‡GÂµ = CuÂµ âˆ’ d = âˆ’CAâˆ’1C
> Âµ + CAâˆ’1
b âˆ’ d.
Observe that since CAâˆ’1C
> is symmetric positive semidefinite, âˆ’G(Âµ) is convex.
Therefore, if C has rank m, a solution of Problem (P) is obtained by finding the unique
solution Î» of the equation
âˆ’CAâˆ’1C
> Âµ + CAâˆ’1
b âˆ’ d = 0,
1788 CHAPTER 50. INTRODUCTION TO NONLINEAR OPTIMIZATION
and then the minimum uÎ» of Problem (P) is given by
uÎ» = A
âˆ’1
(b âˆ’ C
> Î»).
If C has rank < m, then we can find Î» â‰¥ 0 by finding a feasible solution of the linear program
whose set of constraints is given by
âˆ’CAâˆ’1C
> Âµ + CAâˆ’1
b âˆ’ d = 0,
using the standard method of adding nonnegative slack variables Î¾1, . . . , Î¾m and maximizing
âˆ’(Î¾1 + Â· Â· Â· + Î¾m).
50.9 Handling Equality Constraints Explicitly
Sometimes it is desirable to handle equality constraints explicitly (for instance, this is what
Boyd and Vandenberghe do, see [29]). The only difference is that the Lagrange multipliers
associated with equality constraints are not required to be nonnegative, as we now show.
Consider the Optimization Problem (P
0 )
minimize J(v)
subject to Ï•i(v) â‰¤ 0, i = 1, . . . , m
Ïˆj (v) = 0, j = 1, . . . , p.
We treat each equality constraint Ïˆj (u) = 0 as the conjunction of the inequalities Ïˆj (u) â‰¤ 0
and âˆ’Ïˆj (u) â‰¤ 0, and we associate Lagrange multipliers Î» âˆˆ R
m
+ , and Î½
+, Î½âˆ’ âˆˆ R
p
+. Assuming
that the constraints are qualified, by Theorem 50.5, the KKT conditions are
Ju
0 +
mX
i=1
Î»i(Ï•
0i
)u +
p
X
j=1
Î½j
+
(Ïˆj
0
)u âˆ’
p
X
j=1
Î½j
âˆ’
(Ïˆj
0
)u = 0,
and
mX
i=1
Î»iÏ•i(u) +
p
X
j=1
Î½j
+Ïˆj (u) âˆ’
p
X
j=1
Î½j
âˆ’Ïˆj (u) = 0,
with Î» â‰¥ 0, Î½+ â‰¥ 0, Î½âˆ’ â‰¥ 0. Since Ïˆj (u) = 0 for j = 1, . . . , p, these equations can be
rewritten as
Ju
0 +
mX
i=1
Î»i(Ï•
0i
)u +
p
X
j=1
(Î½j
+ âˆ’ Î½j
âˆ’
)(Ïˆj
0
)u = 0,
and
mX
i=1
Î»iÏ•i(u) = 0
50.9. HANDLING EQUALITY CONSTRAINTS EXPLICITLY 1789
