Ï•(u + x, v) = Ï•(u, v)
Ï•(u, v + y) = Ï•(u, v)
for any x âˆˆ F
âŠ¥ and any y âˆˆ E
âŠ¥, we see that we obtain by passing to the quotient a
sesquilinear form
[Ï•]: (E/F âŠ¥) Ã— (F/EâŠ¥) â†’ K
which is nondegenerate.
Proposition 29.12. For any sesquilinear form Ï•: E Ã— F â†’ K, the space E/F âŠ¥ is finiteï¿¾dimensional iff the space F/EâŠ¥ is finite-dimensional; if so, dim(E/F âŠ¥) = dim(F/EâŠ¥).
Proof. Since the sesquilinear form [Ï•]: (E/F âŠ¥) Ã— (F/EâŠ¥) â†’ K is nondegenerate, the maps
l[Ï•]
: (E/F âŠ¥) â†’ (F/EâŠ¥)
âˆ— and r[Ï•]
: (F/EâŠ¥) â†’ (E/F âŠ¥)
âˆ— are injective. If dim(E/F âŠ¥) =
m, then dim(E/F âŠ¥) = dim((E/F âŠ¥)
âˆ—
), so by injectivity of r[Ï•]
, we have dim(F/EâŠ¥) =
dim((F/EâŠ¥)) â‰¤ m. A similar reasoning using the injectivity of l[Ï•] applies if dim(F/EâŠ¥) = n,
and we get dim(E/F âŠ¥) = dim((E/F âŠ¥)) â‰¤ n. Therefore, dim(E/F âŠ¥) = m is finite iff
dim(F/EâŠ¥) = n is finite, in which case m = n by Proposition 29.1(d).
1010 CHAPTER 29. THE GEOMETRY OF BILINEAR FORMS; WITTâ€™S THEOREM
If U is a subspace of a space E, recall that the codimension of U is the dimension of
E/U, which is also equal to the dimension of any subspace V such that E is a direct sum of
U and V (E = U âŠ• V ).
Proposition 29.12 implies the following useful fact.
Proposition 29.13. Let Ï•: EÃ—F â†’ K be any nondegenerate sesquilinear form. A subspace
U of E has finite dimension iff U
âŠ¥ has finite codimension in F. If dim(U) is finite, then
codim(U
âŠ¥) = dim(U), and U
âŠ¥âŠ¥ = U.
Proof. Since Ï• is nondegenerate E
âŠ¥ = {0} and F
âŠ¥ = {0}, so Proposition 29.12 applied
to the restriction of Ï• to U Ã— F implies that a subspace U of E has finite dimension iff
U
âŠ¥ has finite codimension in F, and that if dim(U) is finite, then codim(U
âŠ¥) = dim(U).
Since U
âŠ¥ and U
âŠ¥âŠ¥ are orthogonal, and since codim(U
âŠ¥) is finite, dim(U
âŠ¥âŠ¥) is finite and we
have dim(U
âŠ¥âŠ¥) = codim(U
âŠ¥âŠ¥âŠ¥) = codim(U
âŠ¥) = dim(U). Since U âŠ† U
âŠ¥âŠ¥, we must have
U = U
âŠ¥âŠ¥.
Proposition 29.14. Let Ï•: E Ã—F â†’ K be any sesquilinear form. Given any two subspaces
U and V of E, we have
(U + V )
âŠ¥ = U
âŠ¥ âˆ© V
âŠ¥.
Furthermore, if Ï• is nondegenerate and if U and V are finite-dimensional, then
(U âˆ© V )
âŠ¥ = U
âŠ¥ + V
âŠ¥.
Proof. If w âˆˆ (U + V )
âŠ¥, then Ï•(u + v, w) = 0 for all u âˆˆ U and all v âˆˆ V . In particular,
with v = 0, we have Ï•(u, w) = 0 for all u âˆˆ U, and with u = 0, we have Ï•(v, w) = 0 for all
v âˆˆ V , so w âˆˆ U
âŠ¥ âˆ© V
âŠ¥. Conversely, if w âˆˆ U
âŠ¥ âˆ© V
âŠ¥, then Ï•(u, w) = 0 for all u âˆˆ U and
Ï•(v, w) = 0 for all v âˆˆ V . By bilinearity, Ï•(u + v, w) = Ï•(u, w) + Ï•(v, w) = 0, which shows
that w âˆˆ (U + V )
âŠ¥. Therefore, the first identity holds.
Now, assume that Ï• is nondegenerate and that U and V are finite-dimensional, and let
W = U
âŠ¥ + V
âŠ¥. Using the equation that we just established and the fact that U and V are
finite-dimensional, by Proposition 29.13, we get
WâŠ¥ = U
âŠ¥âŠ¥ âˆ© V
âŠ¥âŠ¥ = U âˆ© V.
We can apply Proposition 29.12 to the restriction of Ï• to U Ã— W (since U
âŠ¥ âŠ† W and
WâŠ¥ âŠ† U), and we get
dim(U/WâŠ¥) = dim(U/(U âˆ© V )) = dim(W/U âŠ¥).
If T is a supplement of U
âŠ¥ in W so that W = U
âŠ¥ âŠ•T and if S is a supplement of W in E so
that E = W âŠ• S, then codim(W) = dim(S), dim(T) = dim(W/U âŠ¥), and we have the direct
sum
E = U
âŠ¥ âŠ• T âŠ• S
29.3. ORTHOGONALITY 1011
which implies that
dim(T) = codim(U
âŠ¥) âˆ’ dim(S) = codim(U
âŠ¥) âˆ’ codim(W)
so
dim(U/(U âˆ© V )) = dim(W/U âŠ¥) = codim(U
âŠ¥) âˆ’ codim(W),
and since codim(U
âŠ¥) = dim(U), we deduce that
dim(U âˆ© V ) = codim(W).
However, by Proposition 29.13, we have dim(U âˆ© V ) = codim((U âˆ© V )
âŠ¥), so codim(W) =
codim((U âˆ© V )
âŠ¥), and since W âŠ† WâŠ¥âŠ¥ = (U âˆ© V )
âŠ¥, we must have W = (U âˆ© V )
âŠ¥, as
claimed.
In view of Proposition 29.12, we can make the following definition.
Definition 29.13. Let Ï•: E Ã— F â†’ K be any sesquilinear form. If E/F âŠ¥ and F/EâŠ¥ are
finite-dimensional, then their common dimension is called the rank of the form Ï•. If E/F âŠ¥
and F/EâŠ¥ have infinite dimension, we say that Ï• has infinite rank.
Not surprisingly, the rank of Ï• is related to the ranks of lÏ• and rÏ•.
Proposition 29.15. Let Ï•: E Ã— F â†’ K be any sesquilinear form. If Ï• has finite rank r,
then lÏ• and rÏ• have the same rank, which is equal to r.
Proof. Because for every u âˆˆ E,
lÏ•(u)(y) = Ï•(u, y) for all y âˆˆ F ,
and for every v âˆˆ F,
rÏ•(v)(x) = Ï•(x, v) for all x âˆˆ E,
it is clear that the kernel of lÏ• : E â†’ F
âˆ—
is equal to F
âŠ¥ and that, the kernel of rÏ• : F â†’ E
âˆ—
is
equal to E
âŠ¥. Therefore, rank(lÏ•) = dim(Im lÏ•) = dim(E/F âŠ¥) = r, and similarly rank(rÏ•) =
dim(F/EâŠ¥) = r.
Remark: If the sesquilinear form Ï• is represented by the matrix n Ã— m matrix M with
respect to the bases (e1, . . . , em) in E and (f1, . . . , fn) in F, it can be shown that the matrix
representing lÏ• with respect to the bases (e1, . . . , em) and (f1
âˆ—
, . . . , fn
âˆ—
) is M, and that the
matrix representing rÏ• with respect to the bases (f1, . . . , fn) and (e
âˆ—
1
, . . . , eâˆ—
m) is M> . It
follows that the rank of Ï• is equal to the rank of M.
1012 CHAPTER 29. THE GEOMETRY OF BILINEAR FORMS; WITTâ€™S THEOREM
29.4 Adjoint of a Linear Map
Let E1 and E2 be two K-vector spaces, and let Ï•1 : E1Ã—E1 â†’ K be a sesquilinear form on E1
and Ï•2 : E2 Ã—E2 â†’ K be a sesquilinear form on E2. It is also possible to deal with the more
general situation where we have four vector spaces E1, F1, E2, F2 and two sesquilinear forms
Ï•1 : E1 Ã—F1 â†’ K and Ï•2 : E2 Ã—F2 â†’ K, but we will leave this generalization as an exercise.
We also assume that lÏ•1 and rÏ•1 are bijective, which implies that that Ï•1 is nondegenerate.
This is automatic if the space E1 is finite dimensional and Ï•1 is nondegenerate.
Given any linear map f : E1 â†’ E2, for any fixed u âˆˆ E2, we can consider the linear form
in E1
âˆ— given by
x 7â†’ Ï•2(f(x), u), x âˆˆ E1.
Since rÏ•1
: E1 â†’ E1
âˆ—
is bijective, there is a unique y âˆˆ E1 (because the vector spaces E1 and
E1 only differ by scalar multiplication), so that
Ï•2(f(x), u) = Ï•1(x, y), for all x âˆˆ E1.
If we denote this unique y âˆˆ E1 by f
âˆ—l (u), then we have
Ï•2(f(x), u) = Ï•1(x, f âˆ—l
(u)), for all x âˆˆ E1, and all u âˆˆ E2.
Thus, we get a function f
âˆ—l
: E2 â†’ E1. We claim that this function is a linear map. For any
v1, v2 âˆˆ E2, we have
Ï•2(f(x), v1 + v2) = Ï•2(f(x), v1) + Ï•2(f(x), v2)
= Ï•1(x, f âˆ—l
(v1)) + Ï•1(x, f âˆ—l
(v2))
= Ï•1(x, f âˆ—l
(v1) + f
âˆ—l
(v2))
= Ï•1(x, f âˆ—l
(v1 + v2)),
for all x âˆˆ E1. Since rÏ•1
is injective, we conclude that
f
âˆ—l
(v1 + v2) = f
âˆ—l
(v1) + f
âˆ—l
(v2).
For any Î» âˆˆ K, we have
Ï•2(f(x), Î»v) = Î»Ï•2(f(x), v)
= Î»Ï•1(x, f âˆ—l
(v))
= Ï•1(x, Î»f âˆ—l
(v))
= Ï•1(x, f âˆ—l
(Î»v)),
for all x âˆˆ E1. Since rÏ•1
is injective, we conclude that
f
âˆ—l
(Î»v) = Î»f âˆ—l
(v).
29.4. ADJOINT OF A LINEAR MAP 1013
Therefore, f
âˆ—l
is linear. We call it the left adjoint of f.
Now, for any fixed u âˆˆ E2, we can consider the linear form in E1
âˆ— given by
x 7â†’ Ï•2(u, f(x)) x âˆˆ E1.
Since lÏ•1
: E1 â†’ E1
âˆ—
is bijective, there is a unique y âˆˆ E1 so that
Ï•2(u, f(x)) = Ï•1(y, x), for all x âˆˆ E1.
If we denote this unique y âˆˆ E1 by f
âˆ—r (u), then we have
Ï•2(u, f(x)) = Ï•1(f
âˆ—r
(u), x), for all x âˆˆ E1, and all u âˆˆ E2.
Thus, we get a function f
âˆ—r
: E2 â†’ E1. As in the previous situation, it easy to check that
f
âˆ—r
is linear. We call it the right adjoint of f. In summary, we make the following definition.
Definition 29.14. Let E1 and E2 be two K-vector spaces, and let Ï•1 : E1 Ã— E1 â†’ K and
Ï•2 : E2 Ã— E2 â†’ K be two sesquilinear forms. Assume that lÏ•1 and rÏ•1 are bijective, so
that Ï•1 is nondegnerate. For every linear map f : E1 â†’ E2, there exist unique linear maps
f
âˆ—l
: E2 â†’ E1 and f
âˆ—r
: E2 â†’ E1, such that
Ï•2(f(x), u) = Ï•1(x, f âˆ—l
(u)), for all x âˆˆ E1, and all u âˆˆ E2
Ï•2(u, f(x)) = Ï•1(f
âˆ—r
(u), x), for all x âˆˆ E1, and all u âˆˆ E2.
The map f
âˆ—l
is called the left adjoint of f, and the map f
âˆ—r
is called the right adjoint of f.
If E1 and E2 are finite-dimensional with bases (e1, . . . , em) and (f1, . . . , fn), then we can
work out the matrices Aâˆ—l and Aâˆ—r corresponding to the left adjoint f
âˆ—l and the right adjoint
f
âˆ—r of f. Assumine that f is represented by the n Ã— m matrix A, Ï•1 is represented by the
m Ã— m matrix M1, and Ï•2 is represented by the n Ã— n matrix M2. Since
Ï•1(x, f âˆ—l
(u)) = (A
âˆ—lu)
âˆ—M1x = u
âˆ—
(A
âˆ—l
)
âˆ—M1x
Ï•2(f(x), u) = u
âˆ—M2Ax
we find that (Aâˆ—l )
âˆ—M1 = M2A, that is (Aâˆ—l )
âˆ— = M2AM1
âˆ’1
, and similarly
Ï•1(f
âˆ—r
(u), x) = x
âˆ—M1A
âˆ—r u
Ï•2(u, f(x)) = (Ax)
âˆ—M2u = x
âˆ—A
âˆ—M2u,
we have M1Aâˆ—r = Aâˆ—M2, that is Aâˆ—r = (M1)
âˆ’1Aâˆ—M2. Thus, we obtain
A
âˆ—l = (M1
âˆ—
)
âˆ’1A
âˆ—M2
âˆ—
A
âˆ—r = (M1)
âˆ’1A
âˆ—M2.
1014 CHAPTER 29. THE GEOMETRY OF BILINEAR FORMS; WITTâ€™S THEOREM
If Ï•1 and Ï•2 are symmetric bilinear forms, then f
âˆ—l = f
âˆ—r
. This also holds if Ï• is

-Hermitian. Indeed, since
Ï•2(u, f(x)) = Ï•1(f
âˆ—r
(u), x),
we get

Ï•2(f(x), u) =  Ï•1(x, f âˆ—r (u)),
and since Î» 7â†’ Î» is an involution, we get
Ï•2(f(x), u) = Ï•1(x, f âˆ—r
(u)).
Since we also have
Ï•2(f(x), u) = Ï•1(x, f âˆ—l
(u)),
we obtain
Ï•1(x, f âˆ—r
(u)) = Ï•1(x, f âˆ—l
(u)) for all x âˆˆ E1, and all u âˆˆ E2,
and since Ï•1 is nondegenerate, we conclude that f
âˆ—l = f
âˆ—r
. Whenever f
âˆ—l = f
âˆ—r
, we use the
simpler notation f
âˆ—
.
If f : E1 â†’ E2 and g : E1 â†’ E2 are two linear maps, we have the following properties:
(f + g)
âˆ—l = f
âˆ—l + g
âˆ—l
idâˆ—l = id
(Î»f)
âˆ—l = Î»f âˆ—l
,
and similarly for right adjoints. If E3 is another space, Ï•3 is a sesquilinear form on E3, and
if lÏ•2 and rÏ•2 are bijective, then for any linear maps f : E1 â†’ E2 and g : E2 â†’ E3, we have
(g â—¦ f)
âˆ—l = f
âˆ—l â—¦ g
âˆ—l
,
and similarly for right adjoints. Furthermore, if E1 = E2 = E and Ï•: E Ã— E â†’ K is

-Hermitian, for any linear map f : E â†’ E (recall that in this case f
âˆ—l = f
âˆ—r = f
âˆ—
), we have
f
âˆ—âˆ— =  f.
29.5 Isometries Associated with Sesquilinear Forms
The notion of adjoint is a good tool to investigate the notion of isometry between spaces
equipped with sesquilinear forms. First, we define metric maps and isometries.
Definition 29.15. If (E1, Ï•1) and (E2, Ï•2) are two pairs of spaces and sesquilinear maps
Ï•1 : E1 Ã— E1 â†’ K and Ï•2 : E2 Ã— E2 â†’ K, a metric map from (E1, Ï•1) to (E2, Ï•2) is a linear
map f : E1 â†’ E2 such that
Ï•1(u, v) = Ï•2(f(u), f(v)) for all u, v âˆˆ E1.
We say that Ï•1 and Ï•2 are equivalent iff there is a metric map f : E1 â†’ E2 which is bijective.
Such a metric map is called an isometry.
29.5. ISOMETRIES ASSOCIATED WITH SESQUILINEAR FORMS 1015
The problem of classifying sesquilinear forms up to equivalence is an important but very
difficult problem. Solving this problem depends intimately on properties of the field K, and
a complete answer is only known in a few cases. The problem is easily solved for K = R,
K = C. It is also solved for finite fields and for K = Q (the rationals), but the solution is
surprisingly involved!
It is hard to say anything interesting if Ï•1 is degenerate and if the linear map f does not
have adjoints. The next few propositions make use of natural conditions on Ï•1 that yield a
useful criterion for being a metric map.
Proposition 29.16. With the same assumptions as in Definition 29.14 (which imply that
Ï•1 is nondegenerate), if f : E1 â†’ E2 is a bijective linear map, then we have
Ï•1(x, y) = Ï•2(f(x), f(y)) for all x, y âˆˆ E1 iff
f
âˆ’1 = f
âˆ—l = f
âˆ—r
.
Proof. We have
Ï•1(x, y) = Ï•2(f(x), f(y))
iff
Ï•1(x, y) = Ï•2(f(x), f(y)) = Ï•1(x, f âˆ—l
(f(y))
iff
Ï•1(x,(id âˆ’ f
âˆ—l â—¦ f)(y)) = 0 for all x âˆˆ E1 and all y âˆˆ E2.
Since Ï•1 is nondegenerate, we must have
f
âˆ—l â—¦ f = id,
which implies that f
âˆ’1 = f
âˆ—l
. Similarly,
Ï•1(x, y) = Ï•2(f(x), f(y))
iff
Ï•1(x, y) = Ï•2(f(x), f(y)) = Ï•1(f
âˆ—r
(f(x)), y)
iff
Ï•1((id âˆ’ f
âˆ—r â—¦ f)(x), y) = 0 for all x âˆˆ E1 and all y âˆˆ E2.
Since Ï•1 is nondegenerate, we must have
f
âˆ—r â—¦ f = id,
which implies that f
âˆ’1 = f
âˆ—r
. Therefore, f
âˆ’1 = f
âˆ—l = f
âˆ—r
. For the converse, do the
computations in reverse.
As a corollary, we get the following important proposition.
1016 CHAPTER 29. THE GEOMETRY OF BILINEAR FORMS; WITTâ€™S THEOREM
Proposition 29.17. If Ï•: E Ã— E â†’ K is a sesquilinear map, and if lÏ• and rÏ• are bijective,
for every bijective linear map f : E â†’ E, then we have
Ï•(f(x), f(y)) = Ï•(x, y) for all x, y âˆˆ E iff
f
âˆ’1 = f
âˆ—l = f
âˆ—r
.
We also have the following facts.
Proposition 29.18. (1) If Ï•: E Ã— E â†’ K is a sesquilinear map and if lÏ• is injective, then
for every linear map f : E â†’ E, if
Ï•(f(x), f(y)) = Ï•(x, y) for all x, y âˆˆ E, (âˆ—)
then f is injective.
(2) If E is finite-dimensional and if Ï• is nondegenerate, then the linear maps f : E â†’ E
satisfying (âˆ—) form a group. The inverse of f is given by f
âˆ’1 = f
âˆ—
.
Proof. (1) If f(x) = 0, then
Ï•(x, y) = Ï•(f(x), f(y)) = Ï•(0, f(y)) = 0 for all y âˆˆ E.
Since lÏ• is injective, we must have x = 0, and thus f is injective.
(2) If E is finite-dimensional, since a linear map satisfying (âˆ—) is injective, it is a bijection.
By Proposition 29.17, we have f
âˆ’1 = f
âˆ—
. We also have
Ï•(f(x), f(y)) = Ï•((f
âˆ—
â—¦ f)(x), y) = Ï•(x, y) = Ï•((f â—¦ f
âˆ—
)(x), y) = Ï•(f
âˆ—
(x), f âˆ—
(y)),
which shows that f
âˆ—
satisfies (âˆ—). If Ï•(f(x), f(y)) = Ï•(x, y) for all x, y âˆˆ E and Ï•(g(x), g(y))
= Ï•(x, y) for all x, y âˆˆ E, then we have
Ï•((g â—¦ f)(x),(g â—¦ f)(y)) = Ï•(f(x), f(y)) = Ï•(x, y) for all x, y âˆˆ E.
Obviously, the identity map idE satisfies (âˆ—). Therefore, the set of linear maps satisfying (âˆ—)
is a group.
The above considerations motivate the following definition.
Definition 29.16. Let Ï•: E Ã— E â†’ K be a sesquilinear map, and assume that E is finiteï¿¾dimensional and that Ï• is nondegenerate. A linear map f : E â†’ E is an isometry of E (with
respect to Ï•) iff
Ï•(f(x), f(y)) = Ï•(x, y) for all x, y âˆˆ E.
The set of all isometries of E is a group denoted by Isom(Ï•).
29.5. ISOMETRIES ASSOCIATED WITH SESQUILINEAR FORMS 1017
If Ï• is symmetric, then the group Isom(Ï•) is denoted O(Ï•) and called the orthogonal
group of Ï•. If Ï• is alternating, then the group Isom(Ï•) is denoted Sp(Ï•) and called the
symplectic group of Ï•. If Ï• is  -Hermitian, then the group Isom(Ï•) is denoted U (Ï•) and
called the  -unitary group of Ï•. When  = 1, we drop  and just say unitary group.
If (e1, . . . , en) is a basis of E, Ï• is the represented by the n Ã— n matrix M, and f is
represented by the n Ã— n matrix A, since Aâˆ’1 = Aâˆ—l = Aâˆ—r = Mâˆ’1Aâˆ—M, then we find that
f âˆˆ Isom(Ï•) iff
A
âˆ—MA = M,
and Aâˆ’1
is given by Aâˆ’1 = Mâˆ’1Aâˆ—M.
More specifically, we define the following groups, using the matrices Ip,q, Jm,m and Am,m
defined at the end of Section 29.1.
(1) K = R. We have
O(n) = {A âˆˆ Mn(R) | A
> A = In}
O(p, q) = {A âˆˆ Mp+q(R) | A
> Ip,qA = Ip,q}
Sp(2n, R) = {A âˆˆ M2n(R) | A
> Jn,nA = Jn,n}
SO(n) = {A âˆˆ Mn(R) | A
> A = In, det(A) = 1}
SO(p, q) = {A âˆˆ Mp+q(R) | A
> Ip,qA = Ip,q, det(A) = 1}.
The group O(n) is the orthogonal group, Sp(2n, R) is the real symplectic group, and
SO(n) is the special orthogonal group. We can define the group
{A âˆˆ M2n(R) | A
> An,nA = An,n},
but it is isomorphic to O(n, n).
(2) K = C. We have
U(n) = {A âˆˆ Mn(C) | A
âˆ—A = In}
U(p, q) = {A âˆˆ Mp+q(C) | A
âˆ—
Ip,qA = Ip,q}
Sp(2n, C) = {A âˆˆ M2n(C) | A
> Jn,nA = Jn,n}
SU(n) = {A âˆˆ Mn(C) | A
âˆ—A = In, det(A) = 1}
SU(p, q) = {A âˆˆ Mp+q(C) | A
âˆ—
Ip,qA = Ip,q, det(A) = 1}.
The group U(n) is the unitary group, Sp(2n, C) is the complex symplectic group, and
SU(n) is the special unitary group.
It can be shown that if A âˆˆ Sp(2n, R) or if A âˆˆ Sp(2n, C), then det(A) = 1.
1018 CHAPTER 29. THE GEOMETRY OF BILINEAR FORMS; WITTâ€™S THEOREM
29.6 Totally Isotropic Subspaces
In this section, we deal with  -Hermitian forms, Ï•: E Ã— E â†’ K. In general, E may have
subspaces U such that U âˆ© U
âŠ¥ 6 = (0), or worse, such that U âŠ† U
âŠ¥ (that is, Ï• is zero on U).
We will see that such subspaces play a crucial in the decomposition of E into orthogonal
subspaces.
Definition 29.17. Given an  -Hermitian forms Ï•: E Ã— E â†’ K, a nonzero vector u âˆˆ E is
said to be isotropic if Ï•(u, u) = 0. It is convenient to consider 0 to be isotropic. Given any
subspace U of E, the subspace rad(U) = U âˆ© U
âŠ¥ is called the radical of U. We say that
(i) U is degenerate if rad(U) 6 = (0) (equivalently if there is some nonzero vector u âˆˆ U
such that x âˆˆ U
âŠ¥). Otherwise, we say that U is nondegenerate.
(ii) U is totally isotropic if U âŠ† U
âŠ¥ (equivalently if the restriction of Ï• to U is zero).
By definition, the trivial subspace U = (0) (= {0}) is nondegenerate. Observe that a
subspace U is nondegenerate iff the restriction of Ï• to U is nondegenerate. A degenerate
subspace is sometimes called an isotropic subspace. Other authors say that a subspace U
is isotropic if it contains some (nonzero) isotropic vector. A subspace which has no nonzero
isotropic vector is often called anisotropic. The space of all isotropic vectors is a cone often
called the light cone (a terminology coming from the theory of relativity). This is not to
be confused with the cone of silence (from Get Smart)! It should also be noted that some
authors (such as Serre) use the term isotropic instead of totally isotropic. The apparent lack
of standard terminology is almost as bad as in graph theory!
It is clear that any direct sum of pairwise orthogonal totally isotropic subspaces is toï¿¾tally isotropic. Thus, every totally isotropic subspace is contained in some maximal totally
isotropic subspace. Here is another fact that we will use all the time: if V is a totally
isotropic subspace and if U is a subspace of V , then U is totally isotropic.
This is because by definition V is isotropic if V âŠ† V
âŠ¥, and since U âŠ† V we get V
âŠ¥ âŠ† U
âŠ¥,
so U âŠ† V âŠ† V
âŠ¥ âŠ† U
âŠ¥, which shows that U is totally isotropic.
First, let us show that in order to sudy an  -Hermitian form on a space E, it suffices to
restrict our attention to nondegenerate forms.
Proposition 29.19. Given an  -Hermitian form Ï•: E Ã— E â†’ K on E, we have:
(a) If U and V are any two orthogonal subspaces of E, then
rad(U + V ) = rad(U) + rad(V ).
(b) rad(rad(E)) = rad(E).
29.6. TOTALLY ISOTROPIC SUBSPACES 1019
(c) If U is any subspace supplementary to rad(E), so that
E = rad(E) âŠ• U,
then U is nondegenerate, and rad(E) and U are orthogonal.
Proof. (a) If U and V are orthogonal, then U âŠ† V
âŠ¥ and V âŠ† U
âŠ¥. We get
rad(U + V ) = (U + V ) âˆ© (U + V )
âŠ¥
= (U + V ) âˆ© U
âŠ¥ âˆ© V
âŠ¥
= U âˆ© U
âŠ¥ âˆ© V
âŠ¥ + V âˆ© U
âŠ¥ âˆ© V
âŠ¥
= U âˆ© U
âŠ¥ + V âˆ© V
âŠ¥
= rad(U) + rad(V ).
(b) By definition, rad(E) = E
âŠ¥, and obviously E = E
âŠ¥âŠ¥, so we get
rad(rad(E)) = E
âŠ¥ âˆ© E
âŠ¥âŠ¥ = E
âŠ¥ âˆ© E = E
âŠ¥ = rad(E).
(c) If E = rad(E) âŠ• U, by definition of rad(E), the subspaces rad(E) and U are orthogonal.
From (a) and (b), we get
rad(E) = rad(E) + rad(U).
Since rad(U) = U âˆ© U
âŠ¥ âŠ† U and since rad(E) âŠ• U is a direct sum, we have a direct sum
rad(E) = rad(E) âŠ• rad(U),
which implies that rad(U) = (0); that is, U is nondegenerate.
Proposition 29.19(c) shows that the restriction of Ï• to any supplement U of rad(E) is
nondegenerate and Ï• is zero on rad(U), so we may restrict our attention to nondegenerate
forms.
The following is also a key result.
Proposition 29.20. Given an  -Hermitian form Ï•: E Ã— E â†’ K on E, if U is a finiteï¿¾dimensional nondegenerate subspace of E, then E = U âŠ• U
âŠ¥.
Proof. By hypothesis, the restriction Ï•U of Ï• to U is nondegenerate, so the semilinear map
rÏ•U
: U â†’ U
âˆ—
is injective. Since U is finite-dimensional, rÏ•U
is actually bijective, so for every
v âˆˆ E, if we consider the linear form in U
âˆ— given by u 7â†’ Ï•(u, v) (u âˆˆ U), there is a unique
v0 âˆˆ U such that
Ï•(u, v0) = Ï•(u, v) for all u âˆˆ U;
that is, Ï•(u, v âˆ’ v0) = 0 for all u âˆˆ U, so v âˆ’ v0 âˆˆ U
âŠ¥. It follows that v = v0 + v âˆ’ v0, with
v0 âˆˆ U and v0 âˆ’ v âˆˆ U
âŠ¥, and since U is nondegenerate U âˆ© U
âŠ¥ = (0), and E = U âŠ• U
âŠ¥.
As a corollary of Proposition 29.20, we get the following result.
1020 CHAPTER 29. THE GEOMETRY OF BILINEAR FORMS; WITTâ€™S THEOREM
Proposition 29.21. Given an  -Hermitian form Ï•: EÃ—E â†’ K on E, if Ï• is nondegenerate
and if U is a finite-dimensional subspace of E, then rad(U) = rad(U
âŠ¥), and the following
conditions are equivalent:
(i) U is nondegenerate.
(ii) U
âŠ¥ is nondegenerate.
(iii) E = U âŠ• U
âŠ¥.
Proof. By definition, rad(U
âŠ¥) = U
âŠ¥ âˆ© U
âŠ¥âŠ¥, and since Ï• is nondegenerate and U is finiteï¿¾dimensional, U
âŠ¥âŠ¥ = U, so rad(U
âŠ¥) = U
âŠ¥ âˆ© U
âŠ¥âŠ¥ = U âˆ© U
âŠ¥ = rad(U).
By Proposition 29.20, (i) implies (iii). If E = U âŠ• U
âŠ¥, then rad(U) = U âˆ© U
âŠ¥ = (0),
so U is nondegenerate and (iii) implies (i). Since rad(U
âŠ¥) = rad(U), (iii) also implies (ii).
Now, if U
âŠ¥ is nondegenerate, we have U
âŠ¥ âˆ© U
âŠ¥âŠ¥ = (0), and since U âŠ† U
âŠ¥âŠ¥, we get
U âˆ© U
âŠ¥ âŠ† U
âŠ¥âŠ¥ âˆ© U
âŠ¥ = (0),
which shows that U is nondegenerate, proving the implication (ii) =â‡’ (i).
If E is finite-dimensional, we have the following results.
Proposition 29.22. Given an  -Hermitian form Ï•: E Ã— E â†’ K on a finite-dimensional
space E, if Ï• is nondegenerate, then for every subspace U of E we have
(i) dim(U) + dim(U
âŠ¥) = dim(E).
(ii) U
âŠ¥âŠ¥ = U.
Proof. (i) Since Ï• is nondegenerate and E is finite-dimensional, the semilinear map lÏ• : E â†’
E
âˆ—
is bijective. By transposition, the inclusion i: U â†’ E yields a surjection r : E
âˆ— â†’ U
âˆ—
(with r(f) = f â—¦ i for every f âˆˆ E
âˆ—
; the map f â—¦ i is the restriction of the linear form f to
U). It follows that the semilinear map r â—¦ lÏ• : E â†’ U
âˆ— given by
(r â—¦ lÏ•)(x)(u) = Ï•(x, u) x âˆˆ E, u âˆˆ U
is surjective, and its kernel is U
âŠ¥. Thus, we have
dim(U
âˆ—
) + dim(U
âŠ¥) = dim(E),
and since dim(U) = dim(U
âˆ—
) because U is finite-dimensional, we get
dim(U) + dim(U
âŠ¥) = dim(U
âˆ—
) + dim(U
âŠ¥) = dim(E).
(ii) Applying the above formula to U
âŠ¥, we deduce that dim(U) = dim(U
âŠ¥âŠ¥). Since
U âŠ† U
âŠ¥âŠ¥, we must have U
âŠ¥âŠ¥ = U.
29.6. TOTALLY ISOTROPIC SUBSPACES 1021
Remark: We already proved in Proposition 29.13 that if U is finite-dimensional, then
codim(U
âŠ¥) = dim(U) and U
âŠ¥âŠ¥ = U, but it doesnâ€™t hurt to give another proof. Observe that
(i) implies that
dim(U) + dim(rad(U)) â‰¤ dim(E).
We can now proceed with the Witt decomposition, but before that, we quickly take care
of the structure theorem for alternating bilinear forms (the case where Ï•(u, u) = 0 for all
u âˆˆ E). For an alternating bilinear form, the space E is totally isotropic. For example in
dimension 2, the matrix
B =

âˆ’
0 1
1 0
defines the alternating form given by
Ï•((x1, y1),(x2, y2)) = x1y2 âˆ’ x2y1.
This case is surprisingly general.
Proposition 29.23. Let Ï•: E Ã— E â†’ K be an alternating bilinear form on E. If u, v âˆˆ E
are two (nonzero) vectors such that Ï•(u, v) = Î» 6 = 0, then u and v are linearly independent.
If we let u1 = Î»
âˆ’1u and v1 = v, then Ï•(u1, v1) = 1, and the restriction of Ï• to the plane
spanned by u1 and v1 is represented by the matrix

âˆ’
0 1
1 0 .
Proof. If u and v were linearly dependent, as u, v 6 = 0, we could write v = Âµu for some Âµ 6 = 0,
but then, since Ï• is alternating, we would have
Î» = Ï•(u, v) = Ï•(u, Âµu) = ÂµÏ•(u, u) = 0,
contradicting the fact that Î» 6 = 0. The rest is obvious.
Proposition 29.23 yields a plane spanned by two vectors u1, v1 such that Ï•(u1, u1) =
Ï•(v1, v1) = 0 and Ï•(u1, v1) = 1. Such a plane is called a hyperbolic plane. If E is finiteï¿¾dimensional, we obtain the following theorem.
Theorem 29.24. Let Ï•: E Ã— E â†’ K be an alternating bilinear form on a space E of
finite dimension n. Then, there is a direct sum decomposition of E into pairwise orthogonal
subspaces
E = W1 âŠ• Â· Â· Â· âŠ• Wr âŠ• rad(E),
where each Wi is a hyperbolic plane and rad(E) = E
âŠ¥. Therefore, there is a basis of E of
the form
(u1, v1, . . . , ur, vr, w1, . . . , wnâˆ’2r),
1022 CHAPTER 29. THE GEOMETRY OF BILINEAR FORMS; WITTâ€™S THEOREM
with respect to which the matrix representing Ï• is a block diagonal matrix M of the form
M =
ï£«
ï£¬ï£¬ï£¬ï£¬ï£¬ï£­
J 0
J
.
.
.
0 0
J
nâˆ’2r
ï£¶
ï£·ï£·ï£·ï£·ï£·ï£¸
,
with
J =

âˆ’
0 1
1 0 .
Proof. If Ï• = 0, then E = E
âŠ¥ and we are done. Otherwise, there are two nonzero vectors
u, v âˆˆ E such that Ï•(u, v) 6 = 0, so by Proposition 29.23, we obtain a hyperbolic plane W2
spanned by two vectors u1, v1 such that Ï•(u1, v1) = 1. The subspace W1 is nondegenerate
(for example, det(J) = âˆ’1), so by Proposition 29.21, we get a direct sum
E = W1 âŠ• W1
âŠ¥.
By Proposition 29.14, we also have
E
âŠ¥ = (W1 âŠ• W1
âŠ¥) = W1
âŠ¥ âˆ© W1
âŠ¥âŠ¥ = rad(W1
âŠ¥).
By the induction hypothesis applied to W1
âŠ¥, we obtain our theorem.
The following corollary follows immediately.
Proposition 29.25. Let Ï•: E Ã— E â†’ K be an alternating bilinear form on a space E of
finite dimension n.
(1) The rank of Ï• is even.
(2) If Ï• is nondegenerate, then dim(E) = n is even.
(3) Two alternating bilinear forms Ï•1 : E1 Ã—E1 â†’ K and Ï•2 : E2 Ã—E2 â†’ K are equivalent
iff dim(E1) = dim(E2) and Ï•1 and Ï•2 have the same rank.
The only part that requires a proof is part (3), which is left as an easy exercise.
If Ï• is nondegenerate, then n = 2r, and a basis of E as in Theorem 29.24 is called a
symplectic basis. The space E is called a hyperbolic space (or symplectic space).
Observe that if we reorder the vectors in the basis
(u1, v1, . . . , ur, vr, w1, . . . , wnâˆ’2r)
to obtain the basis
(u1, . . . , ur, v1, . . . vr, w1, . . . , wnâˆ’2r),
29.6. TOTALLY ISOTROPIC SUBSPACES 1023
then the matrix representing Ï• becomes
ï£«
ï£­
0 Ir 0
âˆ’Ir 0 0
0 0 0nâˆ’2r
ï£¶
ï£¸ .
This particularly simple matrix is often preferable, especially when dealing with the matrices
(symplectic matrices) representing the isometries of Ï• (in which case n = 2r).
As a warm up for Proposition 29.29 of the next section, we prove an analog of Proposition
29.23 in the case of a symmetric bilinear form.
Proposition 29.26. Let Ï•: EÃ—E â†’ K be a nondegenerate symmetric bilinear form with K
a field of characteristic different from 2. For any nonzero isotropic vector u, there is another
nonzero isotropic vector v such that Ï•(u, v) = 2, and u and v are linearly independent. In
the basis (u, v/2), the restriction of Ï• to the plane spanned by u and v/2 is of the form

0 1
1 0 .
Proof. Since Ï• is nondegenerate, there is some nonzero vector z such that (rescaling z if
necessary) Ï•(u, z) = 1. If
v = 2z âˆ’ Ï•(z, z)u,
then since Ï•(u, u) = 0 and Ï•(u, z) = 1, note that
Ï•(u, v) = Ï•(u, 2z âˆ’ Ï•(z, z)u) = 2Ï•(u, z) âˆ’ Ï•(z, z)Ï•(u, u) = 2,
and
Ï•(v, v) = Ï•(2z âˆ’ Ï•(z, z)u, 2z âˆ’ Ï•(z, z)u)
= 4Ï•(z, z) âˆ’ 4Ï•(z, z)Ï•(u, z) + Ï•(z, z)
2Ï•(u, u)
= 4Ï•(z, z) âˆ’ 4Ï•(z, z) = 0.
If u and z were linearly dependent, as u, z 6 = 0, we could write z = Âµu for some Âµ 6 = 0, but
then, we would have
Ï•(u, z) = Ï•(u, Âµu) = ÂµÏ•(u, u) = 0,
contradicting the fact that Ï•(u, z) 6 = 0. Then u and v = 2z âˆ’ Ï•(z, z)u are also linearly
independent, since otherwise z could be expressed as a multiple of u. The rest is obvious.
Proposition 29.26 yields a plane spanned by two vectors u1, v1 such that Ï•(u1, u1) =
Ï•(v1, v1) = 0 and Ï•(u1, v1) = 1. Such a plane is called an Artinian plane. Proposition 29.26
also shows that nonzero isotropic vectors come in pair.
Proposition 29.26 has the following corollary which has applications in number theory;
see Serre [157], Chapter IV.
1024 CHAPTER 29. THE GEOMETRY OF BILINEAR FORMS; WITTâ€™S THEOREM
Proposition 29.27. If Î¦ is any nondegenerate quadratic form (over a field of characteristic
6
= 2) such that there is some nonzero vector x âˆˆ E with Î¦(x) = 0, then for every Î± âˆˆ K,
there is some y âˆˆ E such that Î¦(y) = Î±.
Proof. Since by hypothesis there is some nonzero vector u âˆˆ E with Î¦(u) = 0, by Proposition
29.26 there is another isotropic vector v such that u and v are linearly independent and such
that (after rescaling) Ï•(u, v) = 1. Then for any Î± âˆˆ K, check that
Î¦
 u +
Î±
2
v
 = Î±,
as desired.
Remark: Some authors refer to the above plane as a hyperbolic plane. Berger (and others)
point out that this terminology is undesirable because the notion of hyperbolic plane already
exists in differential geometry and refers to a very different object.
We leave it as an exercice to figure out that the group of isometries of the Artinian plane,
the set of all 2 Ã— 2 matrices A such that
A
>

0 1
1 0 A =

0 1
1 0 ,
consists of all matrices of the form

Î»
0 Î»
0
âˆ’1
 or 
0 Î»
Î»
âˆ’1 0

, Î» âˆˆ K âˆ’ {0}.
In particular, if K = R, then this group denoted O(1, 1) has four connected components.
We now turn to the Witt decomposition.
29.7 Witt Decomposition
From now on, Ï•: E Ã— E â†’ K is an  -Hermitian form. The following assumption will be
needed:
Property (T). For every u âˆˆ E, there is some Î± âˆˆ K such that Ï•(u, u) = Î± +  Î±.
Property (T) is always satisfied if Ï• is alternating, or if K is of characteristic 6 = 2 and

= Â±1, with Î± =
1
2
Ï•(u, u).
The following (bizarre) technical lemma will be needed.
Lemma 29.28. Let Ï• be an  -Hermitian form on E and assume that Ï• satisfies property
(T). For any totally isotropic subspace U 6 = (0) of E, for every x âˆˆ E not orthogonal to U,
and for every Î± âˆˆ K, there is some y âˆˆ U so that
Ï•(x + y, x + y) = Î± +  Î±.
29.7. WITT DECOMPOSITION 1025
Proof. By property (T), we have Ï•(x, x) = Î² +  Î² for some Î² âˆˆ K. For any y âˆˆ U, since Ï•
is  -Hermitian, Ï•(y, x) =  Ï•(x, y), and since U is totally isotropic Ï•(y, y) = 0, so we have
Ï•(x + y, x + y) = Ï•(x, x) + Ï•(x, y) + Ï•(y, x) + Ï•(y, y)
= Î² +  Î² + Ï•(x, y) +  Ï•(x, y)
= Î² + Ï•(x, y) +  (Î² + Ï•(x, y).
Since x is not orthogonal to U, the function y 7â†’ Ï•(x, y) + Î² is not the constant function.
Consequently, this function takes the value Î± for some y âˆˆ U, which proves the lemma.
Definition 29.18. Let Ï• be an  -Hermitian form on E. A weak Witt decomposition of E is
a triple (U, U0 , W), such that
(i) E = U âŠ• U
0 âŠ• W (a direct sum).
(ii) U and U
0 are totally isotropic.
(iii) W is nondegenerate and orthogonal to U âŠ• U
0 .
We say that a weak Witt decomposition (U, U0 , W) is nontrivial if U 6 = (0) and U
0 6 = (0).
Furthermore, if E is finite-dimensional, then dim(U) = dim(U
0 ) and in a suitable basis, the
matrix representing Ï• is of the form
ï£«
ï£­
0 0
0
A
A
0 0
B
0
ï£¶
ï£¸
We say that Ï• is a neutral form if it is nondegenerate, E is finite-dimensional, and if W = (0).
In this case, the matrix B is missing.
A Witt decomposition for which W has no nonzero isotropic vectors (W is anisotropic)
is called a Witt decomposition.
Observe that if Î¦ is nondegenerate, then we have the trivial weak Witt decomposition
obtained by letting U = U
0 = (0) and W = E. Thus a weak Witt decomposition is
informative only if E is not anisotropic (there is some nonzero isotropic vector, i.e. some
u 6 = 0 such that Î¦(u) = 0), in which case the most informative nontrivial weak Witt
decompositions are those for which W is anisotropic and U and U
0 are as big as possible.
Sometimes, we use the notation U1
âŠ¥
âŠ• U2 to indicate that in a direct sum U1 âŠ• U2,
the subspaces U1 and U2 are orthogonal. Then, in Definition 29.18, we can write that
E = (U âŠ• U
0 )
âŠ¥
âŠ• W.
The first step in showing the existence of a Witt decomposition is this.
1026 CHAPTER 29. THE GEOMETRY OF BILINEAR FORMS; WITTâ€™S THEOREM
Proposition 29.29. Let Ï• be an  -Hermitian form on E, assume that Ï• is nondegenerate
and satisfies property (T), and let U be any totally isotropic subspace of E of finite dimension
dim(U) = r â‰¥ 1.
(1) If U
0 is any totally isotropic subspace of dimension r and if U
0 âˆ©U
âŠ¥ = (0), then U âŠ•U
0
is nondegenerate, and for any basis (u1, . . . , ur) of U, there is a basis (u
01
, . . . , u0r
) of U
0
such that Ï•(ui
, u0j
) = Î´ij , for all i, j = 1, . . . , r.
(2) If W is any totally isotropic subspace of dimension at most r and if W âˆ© U
âŠ¥ = (0),
then there exists a totally isotropic subspace U
0 with dim(U
0 ) = r such that W âŠ† U
0
and U
0 âˆ© U
âŠ¥ = (0).
Proof. (1) Let Ï•
0 be the restriction of Ï• to U Ã— U
0 . Since U
0 âˆ© U
âŠ¥ = (0), for any v âˆˆ U
0 ,
if Ï•(u, v) = 0 for all u âˆˆ U, then v = 0. Thus, Ï•
0 is nondegenerate (we only have to check
on the left since Ï• is  -Hermitian). Then, the assertion about bases follows from the version
of Proposition 29.3 for sesquilinear forms. Since U is totally isotropic, U âŠ† U
âŠ¥, and since
U
0 âˆ© U
âŠ¥ = (0), we must have U
0 âˆ© U = (0), which show that we have a direct sum U âŠ• U
0 .
It remains to prove that U + U
0 is nondegenerate. Observe that
H = (U + U
0 ) âˆ© (U + U
0 )
âŠ¥ = (U + U
0 ) âˆ© U
âŠ¥ âˆ© U
0âŠ¥.
Since U is totally isotropic, U âŠ† U
âŠ¥, and since U
0 âˆ© U
âŠ¥ = (0), we have
(U + U
0 ) âˆ© U
âŠ¥ = (U âˆ© U
âŠ¥) + (U
0 âˆ© U
âŠ¥) = U + (0) = U,
thus H = U âˆ© U
0âŠ¥. Since Ï•
0 is nondegenerate, U âˆ© U
0âŠ¥ = (0), so H = (0) and U + U
0 is
nondegenerate.
(2) We proceed by descending induction on s = dim(W). The base case s = r is trivial.
For the induction step, it suffices to prove that if s < r, then there is a totally isotropic
subspace W0 containing W such that dim(W0 ) = s + 1 and W0 âˆ© U
âŠ¥ = (0).
Since s = dim(W) < dim(U), the restriction of Ï• to U Ã— W is degenerate. Since
W âˆ© U
âŠ¥ = (0), we must have U âˆ© WâŠ¥ 6 = (0). We claim that
WâŠ¥ 6âŠ† W + U
âŠ¥.
If we had
WâŠ¥ âŠ† W + U
âŠ¥,
then because U and W are finite-dimensional and Ï• is nondegenerate, by Proposition 29.13,
U
âŠ¥âŠ¥ = U and WâŠ¥âŠ¥ = W, so by taking orthogonals, WâŠ¥ âŠ† W + U
