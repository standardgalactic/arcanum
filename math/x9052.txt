  Âµ
Î»

,
with
P =

XX> âˆ’XX>
âˆ’XX> XX>  .
Let KÎ» and KÂµ be the sets of indices corresponding to points failing the margin,
KÎ» = {i âˆˆ {1, . . . , m} | Î»i = C/m}
KÂµ = {i âˆˆ {1, . . . , m} | Âµi = C/m}.
56.5. Î½-REGRESSION VERSION 2; PENALIZING b 2105
Because Î»iÂµi = 0, the sets KÎ» and KÂµ are disjoint. Observe that from Definition 56.2 we
have pf = |KÎ»| and qf = |KÂµ|. Then by (âˆ—Î¾) and (âˆ—Î¾
0 ), we have
mX
i=1
(Î¾i + Î¾i
0
) = X
iâˆˆKÎ»
Î¾i +
X
jâˆˆKÂµ
Î¾j
0
=
X
iâˆˆKÎ»
(w
> xi + b âˆ’ yi âˆ’  ) + X
jâˆˆKÂµ
(âˆ’w
> xj âˆ’ b + yj âˆ’  )
= w
>

X
iâˆˆKÎ»
xi âˆ’
j
XâˆˆKÂµ
xj
 âˆ’
i
XâˆˆKÎ»
yi +
X
jâˆˆKÂµ
yj + (pf âˆ’ qf )b âˆ’ (pf + qf ).
The optimal value of the dual is given by
âˆ’
1
2
ï¿¾
Î»
> Âµ
>

 P +

1m1
>m âˆ’1m1
>m
âˆ’1m1
>m 1m1
>m
  Âµ
Î»

âˆ’ q
>

Âµ
Î»

,
with
q =

âˆ’
y
y

.
Expressing that the duality gap is zero we have
1
2
w
> w +
1
2
b
2 + CÎ½ +
m
C
mX
i=1
(Î¾i + Î¾i
0
)
= âˆ’
1
2
ï¿¾
Î»
> Âµ
>

 P +

1m1
>m âˆ’1m1
>m
âˆ’1m1
>m 1m1
>m
  Âµ
Î»

âˆ’ q
>

Âµ
Î»

,
that is,
1
2
ï¿¾
Î»
> Âµ
>

 P +

1m1
>m âˆ’1m1
>m
âˆ’1m1
>m 1m1
>m
  Âµ
Î»

+ CÎ½
+
C
m

w
>

X
iâˆˆKÎ»
xi âˆ’
j
XâˆˆKÂµ
xj
 âˆ’
i
XâˆˆKÎ»
yi +
X
jâˆˆKÂµ
yj + (pf âˆ’ qf )b âˆ’ (pf + qf )

= âˆ’
1
2
ï¿¾
Î»
> Âµ
>

 P +

1m1
>m âˆ’1m1
>m
âˆ’1m1
>m 1m1
>m
  Âµ
Î»

âˆ’ q
>

Âµ
Î»

.
Solving for  we get
C
 Î½ âˆ’
pf
m
+ qf

 = âˆ’
ï¿¾ Î»
> Âµ
>

 P +

1m1
>m âˆ’1m1
>m
âˆ’1m1
>m 1m1
>m
  Âµ
Î»

âˆ’
ï¿¾ y
> âˆ’y
>


Âµ
Î»

âˆ’
C
m

w
>

X
iâˆˆKÎ»
xi âˆ’
j
XâˆˆKÂµ
xj
 âˆ’
i
XâˆˆKÎ»
yi +
X
jâˆˆKÂµ
yj + (pf âˆ’ qf )b
 ,
2106 CHAPTER 56. Î½-SV REGRESSION
so we get

= âˆ’
 
m
C

ï¿¾
Î»
> Âµ
>

 P +

1m1
>m âˆ’1m1
>m
âˆ’1m1
>m 1m1
>m
  Âµ
Î»

+
ï¿¾ y
> âˆ’y
>


Âµ
Î»

+ w
>

X
iâˆˆKÎ»
xi âˆ’
j
XâˆˆKÂµ
xj
 âˆ’
i
XâˆˆKÎ»
yi +
X
jâˆˆKÂµ
yj + (pf âˆ’ qf )b
!
 (mÎ½ âˆ’ pf âˆ’ qf ).
Using the equations
w = X
> (Âµ âˆ’ Î»)
b = âˆ’(1
>mÎ» âˆ’ 1
>mÂµ) = ï¿¾ Î»
> Âµ
>


âˆ’1m
1m

,
we see that  is determined by Î» and Âµ provided that (pf + qf )/m < Î½.
By Proposition 56.7(1),
pf + qf
m
â‰¤ Î½,
therefore the condition (pf + qf )/m < Î½ is very natural.
We have implemented this method in Matlab, and we have observed that for some exï¿¾amples the choice of Î½ caused the equation Î½(pf + qf ) = m to hold. In such cases, running
the program again with a slightly perturbed value of Î½ always succeeded.
The other observation we made is that b tends to be smaller and  tends to be bigger in
Î½-SV Regression Version 2, so the fit is actually not as good as in Î½-SV Regression without
penalizing b. Figure 56.16 shows the result of running our program on the data set of Section
56.3. Compare with Figure 56.13.
56.6 Summary
The main concepts and results of this chapter are listed below:
â€¢ Î½-support vector regression (Î½-SV regression).
â€¢ Regression estimate.
â€¢ Kernel Î½-SV regression.
â€¢  -SV regression,  -insensitive SV regression,
â€¢ Î½-SV regression Version 2; penalizing b.
56.7. PROBLEMS 2107
-40 -30 -20 -10 0 10 20 30 40 50 60
-40
-20
0
20
40
60
80
Figure 56.16: Running Î½-SV regression version 2 on a set of 50 points; Î½ = 0.5.
56.7 Problems
Problem 56.1. Prove that if Î½-SV regression succeeds and yields w, b,  > 0, then  -SV
regression with the same C and the same value of  also succeeds and returns the same pair
(w, b).
Problem 56.2. Prove the formulae
b =
ï£«
ï£­

X
i0âˆˆIÎ»
yi0
 /|IÎ»| +

X
j0âˆˆIÂµ
yj0
 /|IÂµ| âˆ’ w
>

X
i0âˆˆIÎ»
xi0
 /|IÎ»| +

X
j0âˆˆIÂµ
xj0
 /|IÂµ|

ï£¶
ï£¸ /2

=
ï£«
ï£­

X
j0âˆˆIÂµ
yj0
 /|IÂµ| âˆ’  X
i0âˆˆIÎ»
yi0
 /|IÎ»| + w
>

X
i0âˆˆIÎ»
xi0
 /|IÎ»| âˆ’  X
j0âˆˆIÂµ
xj0
 /|IÂµ|

ï£¶
ï£¸ /2
stated just before Proposition 56.6.
Problem 56.3. Give the details of the proof of Proposition 56.6. In particular, prove that
C
 Î½ âˆ’
pf
m
+ qf

 = âˆ’
ï¿¾ Î»
> Âµ
>
 P

Âµ
Î»

âˆ’
ï¿¾ y
> âˆ’y
>


Âµ
Î»

âˆ’
C
m

w
>

X
iâˆˆKÎ»
xi âˆ’
j
XâˆˆKÂµ
xj
 âˆ’
i
XâˆˆKÎ»
yi +
X
jâˆˆKÂµ
yj + (pf âˆ’ qf )b
 .
2108 CHAPTER 56. Î½-SV REGRESSION
Problem 56.4. Prove that the matrices
A =
ï£«
ï£¬ï£¬ï£¬ï£¬ï£­
1
>m âˆ’1
>m 0
>m 0
>m 0
1
>m 1
>m 0
>m 0
>m 1
Im 0m,m Im 0m,m 0m
0m,m Im 0m,m Im 0m
ï£¶
ï£·ï£·ï£·ï£·ï£¸
, A2 =
ï£«
ï£¬ï£¬ï£¬ï£¬ï£­
1
>m âˆ’1
>m 0
>m 0
>m
1
>m 1
>m 0
>m 0
>m
Im 0m,m Im 0m,m
0m,m Im 0m,m Im
ï£¶
ï£·ï£·ï£·ï£·ï£¸
have rank 2m + 2.
P
Problem 56.5. Derive the version of Î½-SV regression in which the linear penalty function
m
i=1(Î¾i + Î¾i
0
) is replaced by the quadratic penalty function P m
i=1(Î¾i
2 + Î¾i
0
2
). Derive the dual
program.
Problem 56.6. The linear penalty function P m
i=1(Î¾i + Î¾i
0
) can be replaced by the quadratic
penalty function P m
i=1(Î¾i
2 +Î¾i
0
2
). Prove that for an optimal solution we must have Î¾i â‰¥ 0 and
Î¾i
0 â‰¥ 0, so we may omit the constraints Î¾i â‰¥ 0 and Î¾i
0 â‰¥ 0. We must also have Î³ = 0 so we
may omit the variable Î³ as well. Prove that Î¾ = (m/2C)Î» and Î¾
0 = (m/2C)Âµ. This problem
is very similar to the Soft Margin SVM (SVMs4) discussed in Section 54.13.
Problem 56.7. Consider the version of Î½-SV regression in Section 56.5. Prove that for any
optimal solution with w 6 = 0 and  > 0, if the inequalities (pf + qf )/m < Î½ < 1 hold, then
some point xi
is a support vector.
Problem 56.8. Prove that the matrix
A3 =
ï£«
ï£¬ï£¬ï£­
1
Im
>
m 1
>m 0
>m 0
>m
0m,m Im 0m,m
0m,m Im 0m,m Im
ï£¶
ï£·ï£·ï£¸
has rank 2m + 1.
Problem 56.9. Consider the version of Î½-SV regression in Section 56.5. Prove the following
formulae: If IÎ» 6 = âˆ…, then

= w
>

X
iâˆˆIÎ»
xi
 /|IÎ»| + b âˆ’

X
iâˆˆIÎ»
yi
 /|IÎ»|,
and if IÂµ 6 = âˆ…, then

= âˆ’w
>

X
jâˆˆIÂµ
xj
 /|IÂµ| âˆ’ b +

X
iâˆˆIÂµ
yi
 /|IÂµ|.
Problem 56.10. Implement Î½-Regression Version 2 described in Section 56.5. Run examples
using both the original version and version 2 and compare the results.
Part X
Appendices
2109
Appendix A
Total Orthogonal Families in Hilbert
Spaces
A.1 Total Orthogonal Families (Hilbert Bases),
Fourier Coefficients
We conclude our quick tour of Hilbert spaces by showing that the notion of orthogonal basis
can be generalized to Hilbert spaces. However, the useful notion is not the usual notion of
a basis, but a notion which is an abstraction of the concept of Fourier series. Every element
of a Hilbert space is the â€œsumâ€ of its Fourier series.
Definition A.1. Given a Hilbert space E, a family (uk)kâˆˆK of nonnull vectors is an orï¿¾thogonal family iff the uk are pairwise orthogonal, i.e., h ui
, uj i = 0 for all i 6 = j (i, j âˆˆ K),
and an orthonormal family iff h ui
, uj i = Î´i, j , for all i, j âˆˆ K. A total orthogonal family (or
system) or Hilbert basis is an orthogonal family that is dense in E. This means that for
every v âˆˆ E, for every  > 0, there is some finite subset I âŠ† K and some family (Î»i)iâˆˆI of
complex numbers, such that



v âˆ’
X
iâˆˆI
Î»iui

 < .
Given an orthogonal family (uk)kâˆˆK, for every v âˆˆ E, for every k âˆˆ K, the scalar ck =
h
v, uki /k ukk
2
is called the k-th Fourier coefficient of v over (uk)kâˆˆK.
Remark: The terminology Hilbert basis is misleading because a Hilbert basis (uk)kâˆˆK is
not necessarily a basis in the algebraic sense. Indeed, in general, (uk)kâˆˆK does not span E.
Intuitively, it takes linear combinations of the ukâ€™s with infinitely many nonnull coefficients
to span E. Technically, this is achieved in terms of limits. In order to avoid the confusion
between bases in the algebraic sense and Hilbert bases, some authors refer to algebraic bases
as Hamel bases and to total orthogonal families (or Hilbert bases) as Schauder bases.
2111
2112 APPENDIX A. TOTAL ORTHOGONAL FAMILIES IN HILBERT SPACES
Given an orthogonal family (uk)kâˆˆK, for any finite subset I of K, we often call sums of
the form P iâˆˆI
Î»iui partial sums of Fourier series, and if these partial sums converge to a
limit denoted as P kâˆˆK ckuk, we call P kâˆˆK ckuk a Fourier series.
However, we have to make sense of such sums! Indeed, when K is unordered or uncountï¿¾able, the notion of limit or sum has not been defined. This can be done as follows (for more
details, see Dixmier [51]):
Definition A.2. Given a normed vector space E (say, a Hilbert space), for any nonempty
index set K, we say that a family (uk)kâˆˆK of vectors in E is summable with sum v âˆˆ E iff
for every  > 0, there is some finite subset I of K, such that,



v âˆ’
X
jâˆˆJ
uj

 < 
for every finite subset J with I âŠ† J âŠ† K. We say that the family (uk)kâˆˆK is summable
iff there is some v âˆˆ E such that (uk)kâˆˆK is summable with sum v. A family (uk)kâˆˆK is a
Cauchy family iff for every  > 0, there is a finite subset I of K, such that,



X
jâˆˆJ
uj

 < 
for every finite subset J of K with I âˆ© J = âˆ…,
If (uk)kâˆˆK is summable with sum v, we usually denote v as P kâˆˆK uk. The following
technical proposition will be needed:
Proposition A.1. Let E be a complete normed vector space (say, a Hilbert space).
(1) For any nonempty index set K, a family (uk)kâˆˆK is summable iff it is a Cauchy family.
(2) Given a family (rk)kâˆˆK of nonnegative reals rk â‰¥ 0, if there is some real number B > 0
such that P iâˆˆI
ri < B for every finite subset I of K, then (rk)kâˆˆK is summable and
P
kâˆˆK rk = r, where r is least upper bound of the set of finite sums P iâˆˆI
ri (I âŠ† K).
Proof. (1) If (uk)kâˆˆK is summable, for every finite subset I of K, let
uI =
X
iâˆˆI
ui and u =
X
kâˆˆK
uk
For every  > 0, there is some finite subset I of K such that
k
u âˆ’ uLk < /2
for all finite subsets L such that I âŠ† L âŠ† K. For every finite subset J of K such that
I âˆ© J = âˆ…, since I âŠ† I âˆª J âŠ† K and I âˆª J is finite, we have
k
u âˆ’ uIâˆªJ k < /2 and k u âˆ’ uIk < /2,
A.1. TOTAL ORTHOGONAL FAMILIES, FOURIER COEFFICIENTS 2113
and since
k
uIâˆªJ âˆ’ uIk â‰¤ kuIâˆªJ âˆ’ uk + k u âˆ’ uIk
and uIâˆªJ âˆ’ uI = uJ since I âˆ© J = âˆ…, we get
k
uJ k = k uIâˆªJ âˆ’ uIk < ,
which is the condition for (uk)kâˆˆK to be a Cauchy family.
Conversely, assume that (uk)kâˆˆK is a Cauchy family. We define inductively a decreasing
sequence (Xn) of subsets of E, each of diameter at most 1/n, as follows: For n = 1, since
(uk)kâˆˆK is a Cauchy family, there is some finite subset J1 of K such that
k
uJ k < 1/2
for every finite subset J of K with J1 âˆ© J = âˆ…. We pick some finite subset J1 with the above
property, and we let I1 = J1 and
X1 = {uI | I1 âŠ† I âŠ† K, I finite}.
For n â‰¥ 1, there is some finite subset Jn+1 of K such that
k
uJ k < 1/(2n + 2)
for every finite subset J of K with Jn+1 âˆ© J = âˆ…. We pick some finite subset Jn+1 with the
above property, and we let In+1 = In âˆª Jn+1 and
Xn+1 = {uI | In+1 âŠ† I âŠ† K, I finite}.
Since In âŠ† In+1, it is obvious that Xn+1 âŠ† Xn for all n â‰¥ 1. We need to prove that each Xn
has diameter at most 1/n. Since Jn was chosen such that
k
uJ k < 1/(2n)
for every finite subset J of K with Jn âˆ© J = âˆ…, and since Jn âŠ† In, it is also true that
k
uJ k < 1/(2n)
for every finite subset J of K with In âˆ© J = âˆ… (since In âˆ© J = âˆ… and Jn âŠ† In implies that
Jn âˆ© J = âˆ…). Then for every two finite subsets J, L such that In âŠ† J, L âŠ† K, we have
k
uJâˆ’In k < 1/(2n) and k uLâˆ’In k < 1/(2n),
and since
k
uJ âˆ’ uLk â‰¤ kuJ âˆ’ uIn k + k uIn âˆ’ uLk = k uJâˆ’In k + k uLâˆ’In k
,
we get
k
uJ âˆ’ uLk < 1/n,
2114 APPENDIX A. TOTAL ORTHOGONAL FAMILIES IN HILBERT SPACES
which proves that Î´(Xn) â‰¤ 1/n. Now if we consider the sequence of closed sets (Xn), we
still have Xn+1 âŠ† Xn, and by Proposition 48.4, Î´(Xn) = Î´(Xn) â‰¤ 1/n, which means that
limnâ†’âˆž Î´(Xn) = 0, and by Proposition 48.4, T âˆž
n=1 Xn consists of a single element u. We
claim that u is the sum of the family (uk)kâˆˆK.
For every  > 0, there is some n â‰¥ 1 such that n > 2/, and since u âˆˆ Xm for all m â‰¥ 1,
there is some finite subset J0 of K such that In âŠ† J0 and
k
u âˆ’ uJ0 k < /2,
where In is the finite subset of K involved in the definition of Xn. However, since Î´(Xn) â‰¤
1/n, for every finite subset J of K such that In âŠ† J, we have
k
uJ âˆ’ uJ0 k â‰¤ 1/n < /2,
and since
k
u âˆ’ uJ k â‰¤ ku âˆ’ uJ0 k + k uJ0 âˆ’ uJ k ,
we get
k
u âˆ’ uJ k < 
for every finite subset J of K with In âŠ† J, which proves that u is the sum of the family
(uk)kâˆˆK.
(2) Since every finite sum P iâˆˆI
ri
is bounded by the uniform bound B, the set of these
finite sums has a least upper bound r â‰¤ B. For every  > 0, since r is the least upper bound
of the finite sums P iâˆˆI
ri (where I finite, I âŠ† K), there is some finite I âŠ† K such that





r âˆ’
X
iâˆˆI
ri



 < ,
and since rk â‰¥ 0 for all k âˆˆ K, we have
X
iâˆˆI
ri â‰¤
X
jâˆˆJ
rj
whenever I âŠ† J, which shows that





r âˆ’
X
jâˆˆJ
rj


 
 â‰¤


 
 r âˆ’
X
iâˆˆI
ri



 < 
for every finite subset
P J such that I âŠ† J âŠ† K, proving that (rk)kâˆˆK is summable with sum
kâˆˆK rk = r.
A.1. TOTAL ORTHOGONAL FAMILIES, FOURIER COEFFICIENTS 2115
Remark: The notion of summability implies that the sum of a family (uk)kâˆˆK is independent
of any order on K. In this sense it is a kind of â€œcommutative summability.â€ More precisely,
it is easy to show that for every bijection Ï•: K â†’ K (intuitively, a reordering of K), the
family (uk)kâˆˆK is summable iff the family (ul)lâˆˆÏ•(K)
is summable, and if so, they have the
same sum.
The following proposition gives some of the main properties of Fourier coefficients. Among
other things, at most countably many of the Fourier coefficient may be nonnull, and the
partial sums of a Fourier series converge. Given an orthogonal family (uk)kâˆˆK, we let Uk =
Cuk, and pUk
: E â†’ Uk is the projection of E onto Uk.
Proposition A.2. Let E be a Hilbert space, (uk)kâˆˆK an orthogonal family in E, and V the
closure of the subspace generated by (uk)kâˆˆK. The following properties hold:
(1) For every v âˆˆ E, for every finite subset I âŠ† K, we have
X
iâˆˆI
|ci
|
2 â‰¤ kvk
2
,
where the ck are the Fourier coefficients of v.
(2) For every vector v âˆˆ E, if (ck)kâˆˆK are the Fourier coefficients of v, the following
conditions are equivalent:
(2a) v âˆˆ V
(2b) The family (ckuk)kâˆˆK is summable and v =
P kâˆˆK ckuk.
(2c) The family (|ck|
2
)kâˆˆK is summable and k vk
2 =
P kâˆˆK |ck|
2
;
(3) The family (|ck|
2
)kâˆˆK is summable, and we have the Bessel inequality :
X
kâˆˆK
|ck|
2 â‰¤ kvk
2
.
As a consequence, at most countably many of the ck may be nonzero. The family
(ckuk)kâˆˆK forms a Cauchy family, and thus, the Fourier series P kâˆˆK ckuk converges
in E to some vector u =
P kâˆˆK ckuk. Furthermore, u = pV (v).
See Figure A.1.
Proof. (1) Let
uI =
X
iâˆˆI
ciui
2116 APPENDIX A. TOTAL ORTHOGONAL FAMILIES IN HILBERT SPACES
E
V = span(u )k
v
 form c = k
v, uk
uk
2 u = c k uk
k K
Î£
e
E
V = span(u )k
v
 form c = k
v, uk
uk
2 c k uk
k K
Î£
e
=
(i.)
(ii.)
Figure A.1: A schematic illustration of Proposition A.2. Figure (i.) illustrates Condition
(2b), while Figure (ii.) illustrates Condition (3). Note E is the purple oval and V is the
magenta oval. In both cases, take a vector of E, form the Fourier coefficients ck, then form
the Fourier series P kâˆˆK ckuk. Condition (2b) ensures v equals its Fourier series since v âˆˆ V .
However, if v /âˆˆ V , the Fourier series does not equal v. Eventually, we will discover that
V = E, which implies that that Fourier series converges to its vector v.
for any finite subset I of K. We claim that v âˆ’uI is orthogonal to ui
for every i âˆˆ I. Indeed,
h
v âˆ’ uI , uii =
* v âˆ’
X
jâˆˆI
cjuj
, ui
+
= h v, uii âˆ’X
jâˆˆI
cj h uj
, uii
= h v, uii âˆ’ cik uik
2
= h v, uii âˆ’ hv, uii = 0,
A.1. TOTAL ORTHOGONAL FAMILIES, FOURIER COEFFICIENTS 2117
since h uj
, uii = 0 for all i 6 = j and ci = h v, uii /k uik
2
. As a consequence, we have
k
vk
2 =

  v âˆ’
X
iâˆˆI
ciui +
X
iâˆˆI
ciui


2
=

  v âˆ’
X
iâˆˆI
ciui


2
+

 
X
iâˆˆI
ciui


2
=

  v âˆ’
X
iâˆˆI
ciui


2
+
X
iâˆˆI
|ci
|
2
,
since the ui are pairwise orthogonal, that is,
k
vk
2 =

  v âˆ’
X
iâˆˆI
ciui


2
+
X
iâˆˆI
|ci
|
2
.
Thus,
X
iâˆˆI
|ci
|
2 â‰¤ kvk
2
,
as claimed.
(2) We prove the chain of implications (a) â‡’ (b) â‡’ (c) â‡’ (a).
(a) â‡’ (b): If v âˆˆ V , since V is the closure of the subspace spanned by (uk)kâˆˆK, for every
 > 0, there is some finite subset I of K and some family (Î»i)iâˆˆI of complex numbers, such
that



v âˆ’
X
iâˆˆI
Î»iui

 < .
Now for every finite subset J of K such that I âŠ† J, we have



v âˆ’
X
iâˆˆI
Î»iui


2
=

  v âˆ’
X
jâˆˆJ
cjuj +
X
jâˆˆJ
cjuj âˆ’
X
iâˆˆI
Î»iui


2
=

  v âˆ’
X
jâˆˆJ
cjuj
