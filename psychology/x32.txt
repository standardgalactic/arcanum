“without any further complication or multiplication of entities.” He has
given us a model of how this might work, even if we reject the details of
90 Mind World
his analysis (as we shall see). With that model in mind, let us turn to more
recent efforts to analyze consciousness.
Higher-Order Monitoring
Today’s philosophy of mind – in the tradition of analytic philosophy since
the 1950s and of cognitive science since the 1970s – is rediscovering the issues of consciousness that so engaged Brentano, James, and Husserl. This
latest phase of consciousness theory is surveyed (sans phenomenology)
in the anthology The Nature of Consciousness (1997), edited by Ned Block,
Owen Flanagan, and Guven G ¨ uzeldere. Our purpose here is well served ¨
by the contrast of views gathered there in the section on “Higher-Order
Monitoring Conceptions of Consciousness” and overviewed by Guzeldere ¨
in the closing essay (pp. 789–806).
In these recent discussions, inner awareness (imposing the term I prefer) is analyzed as “higher-order monitoring”: the mind monitors its own
activity in a distinct higher-order state – where all this is realized in the
brain. This second state is higher-order because it is about the mental
state it monitors, the latter being of first order, that is, about something
other than a mental state. Two types of higher-order state have been
posited as doing the monitoring: higher-order perception and higherorder thought. Higher-order perception is like perception but directed
toward a given mental state rather than, say, a frog before one’s eyes.
Higher-order thought differs in that it is a propositional attitude of thinking about the given mental state rather than a kind of perception of the
state.
David Armstrong offered this characterization of higher-order
perception:
What is it that the long-distance truck driver lacks [when driving by skill without
“consciousness” of what he is doing]? I think it is an additional form of perception,
or, a little more cautiously, it is something that resembles perception. But unlike
sense-perception, it is not directed toward our current environment and/or our
current bodily state [proprioception]. It is perception of the mental. Such “inner”
perception is traditionally called introspection, or introspective awareness. (Block
et al., 1997: 724)
In the 1950s Armstrong, U. T. Place, and J. J. C. Smart launched today’s
materialist philosophy of mind with the identity theory, holding that a
mental state is identical with a brain state (token states, not state types).
It is natural on this model to suggest that the brain not only processes
Return to Consciousness 91
information about the environment, say, in seeing the road ahead, but
also processes information about its own states, say, the brain’s processing
the sensory information about the road. This higher-order brain process
is, then, what Armstrong proposes as defining consciousness, as when
the truck driver becomes aware of his driving: his brain now “perceives”
its state of seeing the road ahead. As the visual nervous system tracks
interactions of the eyes with light, and the tactile system tracks interactions of the skin with physical pressure, so another part of the nervous
system tracks neural interactions within the brain, which we experience
as introspective awareness.
Since the 1970s, with the rise of the computer model of mind, the
identity theory has given way to functionalism, holding that a mental
state type is a functional state of a brain – or, indeed, of a computational system realized in a physical system different from a brain. Inner
awareness would then be a type of higher-order information processing,
a function of monitoring another mind/brain/computer activity (which
has its own function). (See William G. Lycan in Block et al. 1997: 755–
71.) On this paradigm, what makes a physical state mental is the type of
causal interaction it mediates, as between a human nervous system and
its environment; and what makes a mental state conscious is this type of
higher-order monitoring of its own activity, a type of causal interaction
within its own neural states.
But our concern is phenomenological: what is the form of inner awareness on the higher-order perception model? (We are seeking not a logical
form of words, but a phenomenological form of mental states.) On the
inner-perception model, introspective awareness is a second-order intentional state, which is to say it is directed toward a first-order mental state.
And it is in some way like perception but it is not a sensory experience.
In an idiom closer to my own, we might describe such “inner perception”
as follows:
I now see that stretch of road ahead and (simultaneously)
I nowintrospectively observe that I am now having this very experience.
The content “this very experience” directs the introspective awareness
toward the visual experience it is monitoring, which lies in the immediate mental context of the introspection. In this respect the awareness
is like perception; it is a form of observation. But the character of the
introspective awareness is not seeing or hearing; the sensory character
belongs rather to the visual experience. What the truck driver lacks when
92 Mind World
driving along “unconsciously,” on this model, is this further observation
of his seeing the road ahead.
An alternative model distinguishes higher-order thought from higherorder perception, while remaining within the materialist theory of mind
(and presumably specifying the causal functionality of a mental state). In
this vein David M. Rosenthal argues, in discerning detail, for the view that
inner awareness (again imposing my term) is a form of thoughtrather than
perception (Block et al. 1997: 740ff.). Perception is too restrictive, even
inappropriate, for introspection, Rosenthal argues, because its objects
are restricted to what is sensible and has sensory qualities, whereas introspection ranges over all kinds of mental activity, with no such restrictions.
Thus, he writes:
We are conscious of something, on this [higher-order thought] model, when we
have a thought about it. So a mental state will be conscious if it is accompanied by
a thought about that state. The occurrence of such higher-order thought (HOT)
makes us conscious of the mental state; so the state we are consicous of is a
conscious state. Similarly, when no such HOT occurs, we are unaware of being
in the mental state in question, and the state is then not a conscious state. The
core of the theory, then, is that a mental state is a conscious state when, and only
when, it is accompanied by a suitable HOT. (Block et al. 1997: 741)
But what is the form of the higher-order “thought” that makes a mental
state conscious? It is not a sensory perception, describable in my idiom by
something like “I see this very experience” or “I see that this experience
occurs” (we do not sense-perceive mental states). It is instead a propositional
mental attitude. But what type of attitude is it (judgment, imagination,
etc.) and what form of proposition is its content? Rosenthal proposes:
The requisite content is that one is, oneself, in a particular mental state. If one
doubts or wonders whether one is in a particular mental state, or desires, hopes,
or suspects that one is, that plainly will not make the state a conscious state.
... Nor will one’s mental states be conscious if accompanied merely by a dispositional higher-order mental state. ... To be transitively [= intentionally] conscious of something, therefore, we must have a thought about it in a relatively
narrow sense: It must be an assertoric, occurrent propositional state. (p. 742)
