HAL Id: ijn_00169837
https://jeannicod.ccsd.cnrs.fr/ijn_00169837
Submitted on 5 Sep 2007
HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not.
The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.
L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.
Body mereology
Frédérique de Vignemont, Manos Tsakiris, Patrick Haggard
To cite this version:
Frédérique de Vignemont, Manos Tsakiris, Patrick Haggard.
Body mereology.
G. Knoblich, I.M.
Thornton, M. Grosjean, M. Shiffrar. Human Body Perception from the Inside Out, Oxford University
Press, pp.147-170, 2005. ￿ijn_00169837￿

 
 
1
 
 
Body mereology 
F. de Vignemont, M. Tsakiris and P. Haggard 
Institute of Cognitive Neuroscience, University College London 
 
 
 
 
In The Body from inside out, edited by G. Knoblich, I.M. Thornton, M. Grosjean, M. 
Shiffrar. New York: Oxford University Press, 147-170. 
 
 
 
 

 
 
2
Introduction: Parts, body and the self 
The body is made up of parts. This basic assumption is central in most neuroscientific 
studies of bodily sensation, body representation and motor action.  Yet, the assumption has 
rarely been considered explicitly. We may indeed ask how the body is internally segmented 
and how body parts can be defined. That is, how can we sketch the mereology of the body? 
Mereology (from the Greek meros, „part‟) is the theory of parthood relations: of the 
relations of part to whole and the relations of part to part within a whole. Traditionally, it 
addresses the metaphysical question of the relation between constitution and identity: is the 
sameness of parts necessary for identity? One of the most famous examples is the story of 
the cat Tibbles who loses his tail. If a cat survives the annihilation of its tail, then the cat 
with tail (before the accident) and the cat without tail (after the accident) are numerically 
the same in spite of their having different proper parts (Wiggins, 1980). Therefore, the cat 
cannot be identified to the corresponding amount of feline tissue, even if it is constituted by 
it. As Wiggins (1968, p. 90) said, “No man is the same as his forearm.”.  
In this chapter, we will not raise the metaphysical issue of personal identity, even if, as 
for Tibbles, we will mention the possibility of deletion of body parts. Rather, we are 
interested in the epistemological and phenomenological dimension of mereology of the 
body.  Is somesthetic experience linked to body parts, or to the body as a whole?  How are 
those parts to be described, and how do they relate to each other?  Can the way I experience 
my body as a whole be reduced to the way I feel each of my body parts?  
The body that we experience cannot be fully reduced to a bundle of tissues and organs. 
As Merleau-Ponty (1945) noticed, the body is an object that never leaves me. While we can 
perceive an object from different perspectives or cease to perceive it, we experience “the 
feeling of the same old body always there” (James, 1890, p. 242). The amount of 
information received on one‟s own body is quantitatively superior to what one can receive 
from any external object: not only can one see or touch one‟s own body, one also always 
receives a continuous flow of proprioceptive and somesthetic inputs. The embodied self is 
thus constructed from sensory inputs, but still cannot be reduced to the representation of 
coextended limbs. In addition to simply pooling information from different senses, body 
representations also synthesize the various signals into an integrated meaningful experience 
by establishing consistent relationships between body parts and the whole. 
 
The simplest scientific approach to bodily experience is a reductive one.  We begin by 
assuming that the phenomenology of the perceiving and acting body is not a primitive fact, 
but can be analysed.  We approach this analysis by considering how the phenomenology of 
the body can be broken down into a phenomenology of body parts.  This approach allows 
us to investigate the “embodied self” by reviewing how recent experimental data address 
three intimately related questions about body mereology: (1) what is the relation between 
the body parts and the body as a whole? (2) how are the various sources of information 
from different body parts combined to form a coherent body representation? (3) what is the 
relation between the body and the self?  
 
1. The mereological organization of the body 

 
 
3
We can perform actions without having first to direct attention to the position of our 
limbs. One might therefore assume that the continuous flow of information about our body 
that we use in action is always present to consciousness: we would always be aware of the 
body in all its details (O‟Shaughnessy, 1980). However, many experiments have shown that 
actions are often performed outside the conscious field (Jeannerod, 1997), and do not 
require conscious representation of body position. For instance, Castiello, Paulignan, and 
Jeannerod (1991) showed that an unexpected target jump becomes available to 
consciousness 200 ms after the sensori-motor adjustment. It has also been demonstrated 
that we tend to adhere to the goal and not to the way it has been achieved (Fourneret & 
Jeannerod, 1998). In fact, it seems that the body remains most of the time at the margin of 
consciousness as an undifferentiated whole (Gurwitsch, 1985; O‟Shaughnessy, 1995).  
On the other hand, we can also allocate specific attention to one part of the body, either 
voluntarily, or because we are attracted by the saliency of a bodily sensation. Itches, pains 
and other bodily sensations can seem very focal indeed, popping out compellingly from the 
background experience of the body. This focality suggests that the localization of bodily 
sensations shows special characteristics. Bodily sensations appear to be encoded in a 
specialized somatotopic frame of reference, which we call “body space”.  Body space is 
characterized by the fact that it is quite distinct from external spatial locations. Body space 
can be interpreted as the mental map of the spatial disposition of body parts and of the 
relationship between the various parts of the body and the whole. It has to be distinguished 
from external objective space: a painful body part can move relatively to the external 
spatial framework without the pain itself moving within the body space. For instance, the 
pain in my thumb is not felt in my mouth just because my thumb is in my mouth (Block, 
1983). 
The outline of my body is a frontier which ordinary spatial relations do not 
cross. (Merleau-Ponty, 1945, p. 98) 
Consequently, we can ask about its internal mereological organization: how is the body 
segmented into parts? 
 
 
Differentiation of body parts 
One of the main problems of mereology is to define the relevant parts of the object. We 
single out the handle of the cup as a proper part because of its functional role, but we could 
as well decide to isolate another part on purely spatial criteria such as the base of the cup. 
The same problem thus arises for the body: how to differentiate the relevant body parts? 
Representations of the body can be segmented at different levels: sensorimotor, visuo-
spatial and semantic (Sirigu et al., 1991). We suggest that body parts could be analysed in 
either of two different ways, through qualitative topology and quantitative geometry.  
Topology means differentiating the whole body into categorically distinct parts (e.g., „arm‟, 
„finger‟).  Geometry means differentiating the body into zones with metric properties such 
as extent.  In this section, we begin by showing that topological mereology of the body 
differs according to whether sensory or motor aspects of the body are considered.  We next 
consider the mental representation of geometric relations among body parts. 
 Somatosensory mereology 

 
 
4
The body surface may be viewed as an undifferentiated tactile sheet, without 
categorical divisions corresponding to anatomical body parts. The connectivity between 
neurons in the cerebral cortex is responsible for imposing an ordered structure on this 
undifferentiated sheet.  The different adjacent regions of the tactile sheet compete with each 
other to “own” cortical representation, by an ongoing process of lateral inhibition between 
cortical neurons, limiting the spread of excitation among adjacents neurons, thereby 
functionally isolating cells that are anatomically near each other. A structured map arises 
because specific patterns of lateral inhibition emerge during sensory experience. Indeed, 
primary somatosensory representations do generally follow the natural anatomical divisions 
of body parts, having receptive fields confined to single fingers or limbs (Penfield and 
Rasmussen, 1950; Blankenburg et al., 2003). Penfield and Boldrey (1937) described the 
somatotopical organization of SI that associates cortical areas to a part of the body surface 
resulting in the metaphor of a “Homunculus”. However, this body-part based organization 
does not imply that the body is naturally differentiated into categorical parts at the level of 
primary representation.  The structure of the homunculus is not a necessary property of the 
network wiring, but the result of plastic changes in tactile input altering the inhibitory 
competition between neurons. Differentiation into distinct body parts at the primary 
somatosensory level may be a reflection of how our bodies have been used, rather than a 
natural unit of neural representation.  
It is only at a more cognitive level that the body space is properly differentiated into 
distinct body parts. The criteria of such differentiation are not fixed and may vary 
according to the function of the body representation. Again, the brain‟s differentiation of 
somatosensory input into body part categories is not innate, but may reflect the pattern of 
sensory inputs generated by our interactions with the environment. Mereological 
organization of the body representation should thus be influenced by tactile experience. 
Indeed, paired associative stimulation of adjacent digits produces confusions between the 
trained digits in identification tasks (Braun et al., 2000), and an increasing overlap between 
their cortical representations (Schweizer et al., 2001). Neuropsychological conditions such 
as finger agnosia suggest that poor differentiation of adjacent body parts can occur at a 
more cognitive level without deficit in primary sensation. For example, Kinsbourne and 
Warrington (1962) suggested that the ring and middle digits lose their separate identities in 
finger agnosia. Their representations become functionally fused. A similar line of argument 
may explain the errors made by autotopagnosic patients in pointing to body parts (Odgen, 
1985, Sirigu et al., 1991). Patients may point either toward the contiguous body part (the 
wrist, rather than the hand) or to the contralateral body part (right hand rather than left 
hand) (Semenza, 1988). 
We suggest that differentiation of the body into parts may reflect a competitive process 
of mutual inhibition occurring at the cognitive level of body representations. This could, for 
example, be a more abstract version of the competitive inhibition process between receptive 
fields known to exist in primary somatosensory representation. Nevertheless, this 
differentiation does not preclude, but rather highlights, the mutual relationship between 
parts that constitutes the body as a whole. Studies show indeed that the overall spatial 
configuration between the limbs plays a central role in body representations. The inversion 
of body parts affects the recognition of the body, while it would not influence the 
recognition of physical objects (see Reed, this volume). Interestingly, the inversion effect 

 
 
5
can be elicited only if the biomechanical posture is motorically possible (Reed et al. 2003). 
This result points out the importance of a motor representation of the body. 
 Motor mereology 
Any object may be broken down into constituent parts based on spatial information.  
However, our own body is a unique object because we can move it voluntarily.  Therefore, 
body mereology may thus differ from other objects because my voluntary actions may 
provide an organizing principle for segmenting the body into parts. Interestingly, a motor 
mereology begins with a different spatial object from a somatosensory mereology.  We 
have already described the somatosensory body surface as an undifferentiated sheet.  In 
contrast, the starting point of motor mereology would be the set of muscles that I can 
voluntarily move.  This is a group of different objects, rather than a continuous sensory 
organ.  Furthermore, intentional actions impose an additional functional organization 
because of the sets of body parts that work together in intentional movements.  For 
example, when I move my forearm my hand and fingers follow.  In contrast, if someone 
touches my forearm, this usually does not tell me anything about the sensation in the hand 
and fingers. Accordingly, the representations in primary somatosensory cortex (SI) and 
primary motor cortex (MI) have quite different organizing principles.  Although both have 
comparable gross somatotopy, fine somatotopy differs sharply between the two areas. 
While the receptive field of each neuron of SI corresponds to a small well-defined part of 
the cutaneous surface (Blankeburg et al., 2003), MI representations of the different body 
parts strongly overlap. MI seems to be organized for representing muscle groups and 
patterns of movement rather than individual muscles (Lemon, 1988). Furthermore, 
accumulating evidence suggest that somatotopical organization in SI allows for additive 
activation, such that the corresponding cortical volume of the movement of three fingers is 
the sum of the volumes for the individual fingers moved alone (Hlustik et al., 2001). This 
does not seem to be the case in MI: 
where the „sum of the parts‟ is qualitatively different than the sum found 
for SI.[…] MI and SI share a common somatotopic principle but the 
somatotopy in SI is more discreet and segregated, in contrast to the more 
integrated and overlapping somatotopy in MI. (Hlustik et al., 2001, p. 319)  
The pattern of activation in MI suggests that the control of any finger movement 
recruits a population of neurons distributed throughout MI, rather than a segregated 
population that would map point-to-point distinct movements based on a somatotopic 
organization (Schieber & Hibbard, 1993).  
INSERT FIGURE 1 AROUND HERE 
A more conceptual way of thinking about body representation may suggest that action 
plays an important role in imposing categorical structure on body space.  In particular, we 
act around our joints and these become body part boundaries. While there seems to be no 
specific natural boundaries for the somatosensory body, we may suggest that the joints 
constitute the landmarks for segmenting the acting body:  
Individual body parts are paradigmatically identified in terms of hinges. 
The forearm, for example, is the volume between the elbow and the wrist 
(…) Using hinges provides a non arbitrary way of segmenting the body 

 
 
6
that accords pretty closely with how we classify body parts in everyday 
thought and speech (Bermudez, 1998, p. 156) 
The topological mereology of the body seems immediately present even in primary 
representations for action, while in the somatosensory system mereology seems to emerge 
only at a more cognitive level. 
 The size of body parts 
Body mereology has qualitative and quantitative aspects. While body topology 
concerns the boundaries between body parts, body geometry refers to metric relations such 
as the relative size of body parts. Information about body part size is essential for planning 
and control of action: for example, if I want to switch on the light, I need to know the 
length of my arm in order to decide whether I can reach the switch without getting up from 
my chair. The afferent somatosensory and proprioceptive systems do not provide any direct 
information about body part size. Moreover, the body maps in primary somatosensory 
cortex are highly distorted: physically small areas of skin such as the fingertips having 
much larger cortical territories than large body parts such as the upper arm or back. Several 
studies suggest that the perceived size of body parts reflects mutual interactions between 
these underlying neural representations. 
First, Gandevia and Phegan (1999) suggested that the perceived size of body parts may 
be modulated by afferent inputs. These authors asked subjects to draw their lips and thumb 
at their currently perceived size, while either of these body parts was temporarily 
anaesthetized. The lip and the thumb were chosen because they are represented in a 
common region of primary somatosensory cortex.  Anaesthesia increased the perceived size 
of the anaesthetized body part, and had a similar but smaller effect on the other 
unanaesthetized part. The transfer from the anesthetized to the unanaesthetised part was 
attributed to the shared cortical representation of the hand and face. This result suggests 
that the cognitive representation of the body is driven by integrating over regions of the 
primary cortical map. 
Taylor-Clarke et al. (2004) investigated how the tactile perception of a stimulus 
depends according to the body part that is touched.  Subjects compared the distance 
between two points touched on the index finger with a second distance presented on the 
forearm. Subjects perceived tactile distances on the finger as larger than identical distances 
on the forearm, presumably due to the relative imbalance of the cortical territories of these 
body parts. However, this effect was significantly reduced after subjects merely viewed a 
distorted image of their body in which the hand was reduced and shown at the end of an 
enlarged forearm. A visual representation of the volumetric size of body parts provides the 
spatial information required to interpret tactile stimuli. This result suggests that the neural 
representation of tactile information local to each body part depends on an internal body 
model in which the size of each part is represented. This body model is driven at least 
partly by vision, and defines the mereological composition of the body. 
Lackner (1988) showed that the internal body model also receives proprioceptive 
inputs.  He induced illusory perception of the size of body parts by vibrating the tendons of 
arm muscles.  Such vibrations induce illusory arm movements.  Subjects were required to 
grasp their nose during the vibration. Subjects reported that they experienced their nose as 
elongating by much as 30 cm. This “Pinocchio illusion” constitutes the solution of a 

 
 
7
sensorimotor conflict: the vibration gives the illusion of arm extension, but the fact that the 
hand maintains contact with the nose means that the nose is also moving.  Since the head 
and the body are stationary, the combined sensory input is interpreted as the nose 
elongating. Body parts are thus represented in their mutual mereological relationship and 
the representation of the body cannot be reduced to independent representations of each 
body part. Therefore, the configuration of the whole body is “inferred” from the various 
inputs, rather than directly perceived.  The body scheme results from the interaction 
between the different body parts and the different sensory modalities 
INSERT FIGURE 2 HERE 
Taken together, all these studies suggest that the geometric mereology of the body is 
fundamentally a product of multisensory integration.  The spatial representation of the body 
depends on the integration of tactile, proprioceptive and visual inputs.  Vision may play a 
special structuring role, by imposing a metric organization based on bounded body parts on 
a relatively continuous sensory sheet. 
 
 
Addition and deletion 
Illusions of body part size show that body space does not constitute a complete and 
accurate display of the body in our mind.  Furthermore, the borders of body space do not 
always coincide with the actual limits of the physical body. Several kinds of neuroscientific 
data clarify the body concept by describing the neural mechanisms and psychological 
consequences of deletion and addition of body parts.   
 
Deletion 
Amputation provides the most obvious example of body part physical deletion. It is 
accompanied by major cortical reorganization giving rise to “phantom” sensations which 
feel as though they originate in the absent body part. Thus, light touch on the face area 
contralateral to the amputation elicits somatotopically mapped sensations on the phantom 
limb (Ramachandran and Ramachandran, 1996). This effect is thought to arise because 
cortical regions previously representing the amputated body part become responsive to 
stimuli on the face after amputation, yet the subjective sensation correlated with the neural 
activity retains the feel of the phantom (Ramachandran and Hirstein, 1998). Studies of 
rapid reorganization of tactile neurons following amputation in animals suggest that these 
sensations arise because cortical neurons which represent the body receive afferent input 
from several body parts. A process of lateral inhibition between inputs ensures that the 
neuron responds to a single body region, while the other latent inputs are suppressed. When 
the body part containing the receptive field of a given neuron is deleted, this inhibitory 
process becomes imbalanced, and these latent connections are unmasked. Thus, neurons 
that represented a finger become responsive to stimulation of adjacent body parts, such as 
the other fingers and palm, within minutes of finger amputation (Merzenich et al., 1984).  
Such experiments have clear implications for body mereology, because they show that 
the differentiation of the whole body into constituent parts reflects a dynamic process of 
neural competition between representations in the somatosensory system. Differentiation of 
body parts may be partly innately encoded. Indeed, aplasic patients born with a limb 
missing still feel the presence of a phantom body part (see Brugger, this volume), implying 

 
 
8
an innate structured body representation. Interestingly, the phenomenon of phantom limb 
can be understood only if we take into account the body as a whole. Indeed, we cannot 
explain the existence of the phantom limb if we consider it independently from others parts 
of the body: where can it come from, as there is no sensory information from the absent 
limb? However, the change induced by amputation is not only local, since the neural 
representation of other regions of the body reorganizes to invade the relevant area of cortex.  
Body parts should thus not be understood in isolation, but always on the background of 
their relationship with other body parts.  
While phantom limbs results from the physical deletion of body parts, personal neglect 
reflects the mental deletion of body parts. Patients forget the existence of one side of their 
body or even deny the ownership of one of their limbs. Indeed, somatosensory information 
does not automatically suffice for feeling a sense of ownership toward the body that I 
directly perceive. For instance, Bottini et al. (2002) reported the case of F.B, an 
asomatognosic patient who was unable to report touches delivered on her left hand and who 
attributed it to her niece. The examiner slightly touched one of her hands and warned F.B. 
that he was going to touch (a) her right hand, (b) her left hand, (c) her niece‟s hand. The 
examiner asked her to report whether she felt a tactile sensation while she was blindfolded. 
The results showed that she was unable to report any tactile sensation on her “alien” hand 
in condition (b), but that her tactile anesthesia completely recovered in condition (c). In 
other words, she could feel the touch only on her so-called “niece‟s hand”. Consequently, 
the mental boundaries of one‟s own body are not only fixed by proprioceptive inputs, but 
result rather from more complex phenomena, that we will investigate in the second part.   
 
 Addition 
What would happen to the neural and psychological representation of the body if a body 
part were added rather than removed?  This question at first seems silly. Although body 
parts change considerably in size and slightly in shape with normal lifespan development 
and disease, their number, differentiation and identity do not normally change. However, 
experimental neuroscience, neurology and neuropsychiatry all suggest that the brain‟s 
mereology of the body is sufficiently plastic to incorporate and subsume new body parts. 
Here, we briefly review addition of body elements in somatoparaphrenic delusions 
involving supernumerary limbs, in tool use and in anosognosia. 
The neurological phenomenon of “supernumerary limb” can be interpreted in terms of 
failure to inhibit a mechanism that maintains body space. In one form of this rare condition, 
the patient reports the presence of an additional arm. The supernumerary arm typically has 
the correct anatomical parts, though its size may be unusual and change over time. 
Interestingly, the arm is often experienced as attached to the body at the midline (Boisson 
& Luaute, 2004). Hari et al. (1998) described a patient with frontal and callosal lesions who 
experienced ghost supernumerary limbs in the location previously occupied by the left arm 
or leg. Subsequent fMRI comparisons between periods when the additional limb was and 
was not experienced showed an increased activity in the supplementary motor area during 
the delusion (McGonigle et al., 2002). The authors speculated that the delusion arose 
because the lesion had produced a fractionation between the normally coherent efferent and 
afferent representations of the body. As a result, the efferent and afferent signals gave rise 

 
 
9
to two separate bodily percepts, rather than a single integrated whole. These results suggest 
that a specific neural mechanism maintains a coherent representation of body parts by 
integrating several sensory and motor inputs.  In the next section of this paper, we describe 
studies of the Rubber Hand Illusion in normal subjects which seem to rely on a similar 
mechanism. 
Tool use is a characteristic feature of many animals, and is often taken as a hallmark of 
intelligence. Several recent studies suggest that neural representations of the body may be 
altered when using a tool to extend the subject‟s reaching space (see Maravita and Iriki, 
2004; Maravita, this volume). Studies of bimodal neurons in monkey parietal cortex have 
focused on the spatial relation between visual and tactile receptive fields. Tactile receptive 
fields on the hand gradually displaced of their visual receptive field from an initial position 
near the hand towards the tip of the tool, as a function of tool learning (Iriki et al. 1996). In 
human subjects with unilateral lesions, active use of a tool improved the cross-modal links 
between visual stimuli at the tool tip and tactile events at the hand (Maravita et al. 2002; 
Farne and Ladavas, 2000). Mereologically, the tool appears to become a new segment of 
the limb within the cognitive body representation. Alternatively, the tool may become 
incorporated into the representation of an existing segment, with an appropriate adjustment 
to segment length. These neural changes may underlie the anecdotal observation that a 
person using a tool experiences tactile sensations located at the tool tip. 
A recent neuropsychological study reinforces the idea of a specific brain process 
associated with addition of elements to body representations. Aglioti et al. (1996) reported 
the case of a patient who denied ownership of her left hand following a right-hemisphere 
lesion. She likewise denied ownership of a ring worn on her left hand. When the same ring 
was worn on the unaffected right hand, she correctly recognized it as belonging to her. The 
ring attached to the body was processed in the same way as the hand to which it was 
attached by the brain processes responsible for creating a coherent sense of the body. That 
is, the ring was incorporated into the mental representation of the hand on which it was 
worn.  These data suggest that body representations are flexible and can dynamically 
include new components under proper conditions that we will investigate in the next 
section. Such cases also demonstrate an intriguing link between sensorimotor 
representation of body parts and the sense of self, which has been discussed elsewhere 
(Haggard et al., 2003). 
In summary, the mental map of the body is characterized both by its internal 
organization and by its borders. Body mereology addresses two main questions: (1) how do 
we differentiate the body into parts (segmenting process)? (2) how are the body parts 
organized (structuring process)? The reply varies according to the somatosensory 
mereology and the motor mereology. 
INSERT TABLE 1 AROUND HERE  
 
2. Multisensory body mereology  
Phenomena of addition and deletion of body parts would remain a mystery if we 
describe the brain as a passive receptor of sensory information. Body representations do not 
merely reflect peripheral inputs, but are the result of an active process of integration of 

 
 
10
afferent information (vision, proprioception, and touch) and efferent signals. The 
consistency between several sources of information provides a strong cue for individuating 
body parts. More particularly, visual information plays an important role in the addition of 
body parts. Indeed, somatosensory perception is often quite local and provides little 
information about the relation between body parts, while vision carries global information 
about the body as a whole and has the capacity to link together the different body parts. 
Multisensory integration can thus provide a window into the investigation of bodily 
synthesis.  
In this section, we use a specific example of multisensory integration, the so-called 
“Rubber Hand Illusion” to illustrate how the mind constructs a synthesis of the body as a 
whole using sensory inputs from specific body parts.  This section therefore emphasizes the 
importance of the holistic component of body representation in the integration of body 
parts.  This corresponds to the key mereological question of how the whole relates to the 
sum of the parts. We will suggest that body parts are individuated on the basis of 
multisensory matching. Furthermore, we will distinguish two kinds of mechanisms 
involved in self-attribution of body parts: a bottom-up process based on Bayesian 
correlation and a top-down process based on the synthetic representation of the body as a 
whole. 
 
2.1 The body as a “common sensible” 
The body space is what Aristotle called a “common sensible”, i.e., a property 
represented by different modalities. The multisensory nature of the body has usually been 
neglected by the philosophical tradition, which has focused more on contrasting the body 
with other physical objects, or bodies of other people (Merleau-Ponty, 1945; Anscombe, 
1959). The multisensory nature of the body has been considered only to emphasize the 
private inner knowledge that we have for our own body. Internal perception such as 
nociception and proprioception may even be considered as the primitive core of self-
consciousness (Bermudez, 1998). However, this approach ignores the fact that our 
knowledge of our bodies typically results from the integration of plurimodal information.  
Several studies show the importance of the interaction between vision, touch and 
proprioception (Driver and Spence, 1998). Indeed, visual information alters tactile 
sensation and tactile stimulation orients visual attention. The sight of body parts increases 
temporal and spatial tactile sensitivity: visual information about your hand can reduce 
tactile target detection time and improve tactile spatial resolution (Kennett et al., 2002). The 
cross-modal effect can be so strong that vision of the hand being touched may elicit a tactile 
sensation, even if no real touch occurs (Halligan et al., 1997).  
These cross-modal effects may rely on two kinds of neural mechanisms. 
Electrophysiological studies in the monkey have shown in the premotor and the parietal 
cortex the existence of bimodal neurons that combine visual and somesthetic signals 
(Duhamel et al., 1997; Graziano, Cooke et Taylor, 2000). Furthermore, recent experiments 
suggest that back-projections from multimodal areas to unimodal areas may also play a role 
(Macaluso, Frith and Driver, 2000; Taylor-Clarke, Kennett and Haggard, 2002).  In brief, 
heteromodal areas integrate the different sources of information, but the perceptual 
consequences of these interactions could be also realized in the so-called unimodal areas 

 
 
11
(Calvert et al., 1998). Thus, primary areas may be unimodal in terms of their afferent 
information, yet they may be affected by other kinds of signals.  
Therefore, despite the fact that all sensory modalities do not always provide the same 
representation of the body, we tend to maintain consistency by the resolution of sensory 
conflicts and we experience a single unified body representation. How is such integration 
possible? The main problem is to understand how the relevant elements to bind as a single 
entity are selected and segregated (Treisman, 1998). In other words, how do I avoid 
combining together proprioceptive information from my own hand and visual information 
from your hand or even from the table? According to Ramachandran, there is no active 
binding process. Mere conjunction between sensory inputs is sufficient to integrate any 
object within the body. However, we will argue from the high consistency of body 
representations that this is not the case.  
In order to be integrated, the different kinds of information have to be considered as 
being from a common source. Then the question is to understand how this source is 
individuated. We may draw a parallel with selective attention: what is the nature of the 
underlying units of attention? Traditional models such as Posner‟s one characterize 
attention in spatial terms: we code one stimulus at a time selected on the basis of its 
location and excluding stimuli from other locations. In contrast, recent models emphasize 
the role of discrete objects: we attend to independent individuals that we can track over the 
time, rather than to spatial regions of the visual field (Scholl, 2001). If we apply the 
distinction between space-based and object-based attention to the problem of multimodal 
body representations, we may sketch two hypotheses. According to the first one, it is 
sufficient to assign a common spatio-temporal source to somesthetic and visual information 
(Armel and Ramachandran, 2003). We will defend instead a second hypothesis that a 
cognitive body representation modulates the integration of visual and somesthetic 
information.  
 
2.2 Self-attribution of a rubber hand 
The Rubber Hand Illusion (RHI), originally reported by Botvinick and Cohen (1998), 
can serve as an experimental paradigm, which can address the relationship between 
multisensory mereology and the body. This claim is supported by the fact that the 
constituting elements of the illusion involve visual and tactile events, and the integration of 
these percepts produces strong phenomenological and behavioral responses that are bodily-
related. 
In the original experiment (Botvinick & Cohen, 1998), subjects sat with their left arm 
resting on a table, hidden behind a screen. They were asked to fixate at a rubber hand 
presented in front of them, and the experimenter stroked with two paintbrushes both the 
subject‟s hand and the fake hand simultaneously. After the stimulation period, subjects 
reported that:  
a. They felt as if the rubber hand were their own hand.  
b. It was as if subjects were feeling the touch of the paintbrush in the location where 
they saw the rubber hand touched.  
c. They did not feel as if their (real) hand were drifting towards the rubber hand.  

 
 
12
Surprisingly, and contrary to the introspective evidence (see point (c) above), when 
subjects were asked to indicate the felt position of their own hand after the stimulation 
period, they perceived their hand to be closer to the rubber hand than it really was. That 
was true only when the two hands were synchronously stimulated, and not when both hands 
were asynchronously stimulated. According to Botvinick and Cohen, “the effect reveals a 
three-way interaction between vision, touch and proprioception, and may supply evidence 
concerning the basis of bodily self-identification” (Botvinick & Cohen, 1998, p.756). In 
other words, vision captured the tactile sensations, and this inter-sensory match led to 
proprioceptive alteration. This result seems to suggest that “intermodal matching can be 
sufficient for self-attribution” (italics added, p.756). This conclusion can be justified by the 
fact that proprioception is generally thought to be the sense of the self par excellence 
(Bermudez, 1998).    
Armel and Ramachandran (2003) stimulated the subjects‟ hand and a rubber hand 
synchronously or asynchronously.  After the stimulation, they “injured” the fake hand and 
measured skin-conductance responses (SCRs) from the subjects‟ unstimulated hand. SCRs 
were stronger after synchronous stimulation compared to asynchronous stimulation 
between the real and fake hands. Even more surprisingly, differences between synchronous 
and asynchronous conditions were also significant when subjects were looking, not at a 
fake hand, but at the table being stroked. The authors concluded that this illusion (“it feels 
like the fake hand/table is my hand”, p.1504) is the result of Bayesian perceptual learning, 
and they observed that “the brain‟s remarkable capacity for extracting statistical 
correlations in sensory input is most apparent in the table condition” (p.1505). That would 
suggest that the RHI is simply the result of an association between synchronous visuo-
tactile events, a purely bottom-up mechanism, and that any object can become part of me, 
simply because strong statistical correlations between different sensory modalities are both 
necessary and sufficient conditions for “deceiving our brains”.  
On this view, psychological concepts such as embodiment and selfhood are 
unnecessary, because purely Bayesian principles of statistical correlation are sufficient to 
extend the body representation, to include even "body parts” as implausible as tables 
(Armel & Ramachandran, 2003). Another hypothesis derived from this Bayesian account of 
the RHI is that proprioceptive drifts should be significant larger only for the stimulated 
body-part, and smaller or even absent for unstimulated body-parts. We tested this 
hypothesis in two experiments, in which contrary to the experiment by Botvinick and 
Cohen, we stimulated only one (experiment 1) or two (experiment 2) fingers, and not the 
whole hand (Tsakiris & Haggard, under revision). 
In experiment 1, subjects viewed a rubber hand being stroked by a paintbrush on either 
the index or the little finger.  The subject was always stroked by a similar paintbrush on the 
same finger as the rubber hand was stroked.  However, the rubber hand and the subject‟s 
hand were stroked either synchronously in the experimental condition, or asynchronously in 
the control condition.  We obtained judgments for the felt position of the index finger or for 
the little finger in different blocks. Participants judged the felt position of their finger(s) by 
indicating a number on a ruler that was presented in front of them and at the same gaze 
depth as the rubber hand. During judgment, both the rubber hand and the participant‟s hand 
were out of view. We used the proprioceptive drift as a convenient, continuous and 
quantitative measure of self-attribution. Proprioception is intimately related to the sense of 

 
 
13
bodily self (Bermudez, 1998), but it is not a direct measure of self-attribution per se.  The 
results showed that only the stimulated finger was perceived to be significantly drifted 
towards the rubber hand (see Figure 3a).  
INSERT FIGURE 3 AROUND HERE 
This effect was further replicated in experiment 2, in which both the index and the little 
fingers were stimulated across all conditions, but the pattern of stimulation was 
manipulated independently on each finger. This manipulation guaranteed that each finger 
received equal amount of stimulation in each condition. Our first analysis focused on the 
differences in the perceived position of index vs. little finger, in the condition where “index 
was stroked synchronously/little asynchronously” compared to the condition where “little 
finger was stroked synchronously/index asynchronously”. The analysis replicated the 
finding of the previous experiment, because only the finger that was synchronously 
stimulated was perceived to be significantly closer to the rubber hand (see Figure 3b), 
suggesting that synchronous visual and tactile correlation is a necessary condition for the 
built-up of the illusion. These data confirm the Bayesian hypothesis because the 
proprioceptive drifts were localized to the stimulated finger(s). 
However, as part of experiment 2, we also stimulated both the index and the little 
fingers synchronously or both asynchronously with respect to the rubber fingers, and 
obtained judgments for the felt position of the middle finger, which was never stimulated. 
By comparing the perceived position of the middle finger when both the little and index 
fingers were stimulated asynchronously to the condition when both fingers were stimulated 
synchronously, we showed that synchronous stimulation caused the unstimulated middle 
finger to drift just as much as the little and index fingers which were stimulated. This 
finding suggests that there is a spreading gradient of the RHI to unstimulated fingers. 
Therefore, the localized proprioceptive drift is not absolute.  A cognitive, mereological 
representation of the arrangements of fingers may explain the observed spreading of the 
effect to the unstimulated middle finger.  A purely Bayesian account can not explain why 
the middle finger drifted at all in the absence of any stimulation. If the RHI can extend to 
body parts that are not stimulated, is it also possible to have synchronous stimulation 
without inducing the RHI?  If so, local multisensory integration would then be neither 
necessary nor sufficient for bodily synthesis.   
The finding of a RHI effect for an unstimulated finger suggests that factors other than 
local multisensory integration may be sufficient for self-attribution. We suggest that 
coherence with a cognitive body representation may be one such factor. To test this 
hypothesis we manipulated the felt and seen hand identities. In experiment 3, we stimulated 
the middle finger of the subject‟s left hand, while they were looking at a left or a right 
rubber hand being stimulated on the middle finger. As shown in Figure 4a, we found large 
proprioceptive drifts when subjects were looking at a congruent rubber hand identity and 
almost no drifts when they were looking at the middle finger of an incongruent rubber hand 
identity. The fact that we observed a negative effect (i.e. no drift) in the presence of 
stimulation suggests that mere statistical correlation between visual and tactile events is not 
sufficient for the inducement of the RHI, as measured by proprioceptive drift. These data 
suggest that the need for compatibility between the felt and seen sensation goes beyond the 
level of spatial and temporal congruency. We suggest that body representations play a 
modulatory top-down role in this process of body-related multisensory integration. 

 
 
14
INSERT FIGURE 4 AROUND HERE 
In experiment 4, we further investigated the role of such body representations. First we 
asked whether the RHI would occur if the rubber hand was in an incongruent posture (e.g. 
rotated by -90°) with respect to the subject‟s own hand. Second, we asked whether a neutral 
object (e.g. a wooden stick) would induce similar effects. The results showed that the 
subjects mislocalized the position of their own hand only when the rubber hand was in 
congruent posture (see Figure 2b). In other words, synchronous stimulation between the 
subject‟s hand and a rubber hand at an incongruent posture or a neutral object did not elicit 
the RHI, at least as it is measured by proprioceptive drifts. These findings imply that mere 
correlation between visual and tactile percepts is not a sufficient condition for self-
attribution of a rubber hand or any other object, at least not when the subject‟s body-
configuration is not respected. 
Overall, the results obtained in these experiments argue against a purely Bayesian 
interpretation of the relationship between intermodal matching and self-attribution. First, a 
neutral object did not elicit any significant difference in the perceived position of the 
subjects‟ hand. Even when this neutral object was replaced by a rubber hand, the 
synchronicity of visual and tactile events did not suffice for the inducement of the RHI, 
because of the incongruence between the rubber hand and the subjects‟ own hand at a level 
that goes beyond synchronous stimulation. Hand posture and hand identity have been 
identified as two kinds of body space influence that modulate the visuo-tactile integration 
underlying the RHI (see also Pavani, Spence & Driver, 2000, and Rorden  et al., 1999). 
Graziano and colleagues made similar observations during the recording of bimodal 
neurons in parietal area 5 (Graziano, Cooke, Taylor, 2000). These bimodal neurons of the 
monkey brain were sensitive to the position of the fake arm when fake and real hands were 
stroked synchronously, but only when the fake arm was aligned with the monkey‟s body. 
Such findings provide support for an active role of body representations in the processes 
underlying the RHI. It seems that attribution requires a plausible and congruent visual 
object to bind with a body part, with respect to the general body space configuration.  
At first sight, the localized effects in experiments 1 and 2 provide support for the 
Bayesian approach, because stronger statistical correlations are expected for the stimulated 
finger(s). Nevertheless, two of our findings challenge a strict Bayesian account.  First, the 
unstimulated middle finger drifted to an equivalent extent when two fingers were 
stimulated synchronously (experiment 2). The experience of ownership of the rubber hand 
is global. In other words, participants did not feel as if only the stimulated finger was their 
own finger, but they felt as if the whole rubber hand was part of them. Second, a 
synchronously stimulated middle finger did not drift when subjects were looking at an 
incongruent rubber hand identity (experiment 3). A purely bottom-up account cannot 
explain either of these effects. 
However, the RHI is a purely passive experience, and to that extent it lacks ecological 
validity. Intermodal matching in real life occurs within a dynamic and active interaction 
between the agent and the environment, during which multimodal sensory and also motor 
signals need to be integrated, but also differentiated on the basis of their origin. A recent 
experiment on self-recognition shows that efferent information clearly contributes to the 
ability to match proprioceptive and visual representations of a remote bodily effect 
(Tsakiris & Haggard, under revision). Subjects experienced a passive extension of the right 

 
 
15
index finger, either as an effect of a movement of their own left hand („self-generated 
action‟), or imposed externally by the experimenter („externally-generated action‟). The 
visual feedback was manipulated so that subjects could see either their own right hand 
(„view own hand‟ condition) or someone else‟s right hand („view other‟s hand condition) 
undergoing an equivalent passive extension of the index finger. Self-recognition was 
significantly more accurate when the passive displacement of the right hand was self-
generated, even though there was congruent visuo-proprioceptive feedback across 
conditions, and despite the fact that it was the affected right hand and not the acting left 
hand that the subjects were watching. In the absence of efferent information, congruent 
visual and proprioceptive feedback, as is the case in the RHI, led to a misattribution of the 
moving hand.  
Taken overall, such results favor an interplay between bottom-up and top-down 
influences in the process of bodily synthesis. Even though intermodal matching seems to be 
a pre-requisite for self-identification and self-attribution, the RHI suggests that our sense of 
our body is more than the sum of the correlated visual and tactile percepts. Therefore, 
multi-sensory percepts are not integrated in a simple additive manner, but instead respect a 
set of conditions that guarantee the functional and phenomenological coherence of the 
experienced body. This set of background conditions constitutes a cognitive model or 
representation of the body and its part relations.  The involvement of this model may 
explain the specific and vivid phenomenology that characterizes multisensory integration of 
bodily information in the RHI.  
 
Conclusion: The body and the self 
Mereology raises the following questions: how do I differentiate the parts of the body? 
what is the relationship between the hand and the body? how do I know that the hand 
belongs to the body? We have investigated the principles of body mereology governing 
segmenting, structuring and grouping. From a phenomenological point of view, bodily 
experiences display a unity and a consistency that have to be explained in the context of the 
body as an integrated agent in interaction with the world.  
The mereology of the sensing body begins with an undifferentiated somatosensory 
sheet.  Here, relationships between the body parts are based on spatial contiguity in a 
cortical map.  The body parts do not seem to be explicitly differentiated in a categorical 
way.  Body part categories seem to arise only at a higher, cognitive level of representation.  
In several cases, vision of body parts may play an important role in providing this structure.  
Finally, the geometric mereology of the body has been studied by judgments of body part 
size.  These studies suggest that the spatial arrangement of body parts is a fusion or 
interpretation of available multi-sensory information from across the whole body.  The 
phenomena of phantom limb and supernumerary limbs illustrate the plasticity of the 
sensing body as well as the relationship between the body parts: what one feels in one body 
part may depend on what one feels in another.  
In contrast, voluntary action seems to presuppose a perfectly segmented and consistent 
representation of the body. If I decide to lift my arm, I must be able to distinguish my arm 
from other body parts.  Action thus plays a dual role.  First, it structures or segments the 
mental representation of the body into functional units of movements defined by the joints. 

 
 
16
Second, action groups disparate body parts together, for example when all my fingers work 
together to grasp a glass in a coordinated grip.  We suggest that phenomenal experience of 
the acting body therefore represents body parts in a more global way than experiences of 
the sensory body. Consequently, the mereology of the sensing body and the mereology of 
the acting body provide different ways of differentiating and grouping body parts. Efferent 
mereology may be more consistent than afferent mereology. However, in both cases, body 
parts are not represented in isolation, but are interpreted in their interaction with other body 
parts as well as with the body as a whole. 
We have thus suggested that somatosensory mereology is based on spatial contiguity, 
while motor mereology is based on functional coherence of body movements during 
intentional actions. In contrast, it seems that multisensory mereology is intimately related to 
the sense of ownership of body parts. Indeed, body parts are experienced not only as parts 
of the body, but also as parts of one’s own body. Therefore, we may ask how one self-
attributes body parts. More particularly, is the sense of ownership the cause or the result of 
the multisensory synthesis of bodily information? We think that this is a modern 
neuroscientific instance of the old contrast between Humean and Kantian views of the self. 
According to Hume, we are confronted with a “bundle” of bodily experiences. The sense of 
ownership results from their synthesis into a consistent representation of the body as a 
whole. The results of Botvinick and Cohen (1998) and Armel and Ramachandran (2003) 
agree with this view.  These authors argue that intermodal matching is sufficient condition 
for the sense of ownership. Developmental psychology also suggests that multimodal 
integration is at the source of the recognition of one‟s own body (Rochat, 1998). However, 
we have presented data from the Rubber Hand Illusion suggesting that it is not in fact 
sufficient. We do not self-attribute a piece of wood or the contralateral hand, at least on the 
basis of the quantitative measures used in our study. Furthermore, if the embodied self is 
merely the result of bodily synthesis, what role does it play? It would be purely 
epiphenomenal.  
In contrast, according to the Kantian hypothesis, self-attribution is a prerequisite of 
multimodal integration: I self-attribute bodily experiences (“I see my hand” and “I feel my 
hand”) before combining them into a unified experience of the multisensory body. I thus 
avoid mistakenly combining the tactile perception of my hand with the visual experience of 
someone else‟s hand. Self-consciousness would thus constitute a prior necessary condition 
of body synthesis. On this view, the RHI should never occur at all, since I know that the 
rubber hand is not part of me. Therefore, I should be unable to include it in an integrated 
multisensory bodily experience. More importantly, the Kantian view leaves open the source 
of self-consciousness: if the embodied self does not result from the multisensory integration 
of bodily information, where does it come from? We suggest that neither of these classical 
theories of the self is consistent with modern neuroscientific and psychophysical data on 
bodily sensation.  Consequently, we would like to suggest a third hypothesis: the sense of 
ownership arises from the integration of afferent, and also efferent sources of information. 
However, this integration process is also modulated by a synthetic cognitive model of the 
body as a whole. 
 

 
 
17
References 
Aglioti, S., Smania, N., Manfredi, M., Berlucchi, G. (1996), Disownership of left hand and 
objects related to it in a patient with right brain damage. NeuroReport, 8, 293-296. 
Anscombe, G.E.M. (1959), Intention. Oxford: Blackwell. 
Armel K.C, Ramachandran V.S. (2003), Projecting sensations to external objects: evidence 
from skin conductance response. Proc R Soc Lond B Biol Sci, 270(1523), 1499-506. 
Bermudez, J.L. (1998), The Paradox of Self-Consciousness. Cambridge (Mass.): MIT 
Press. 
Blankenburg, F., Ruben, J., Meyer, R., Schwiemann, J., Villringer, A. (2003), Evidence for 
a rostral-to-caudal somatotopic organization in human primary somatosensory cortex 
with mirror-reversal in areas 3b and 1. Cereb Cortex, 13(9), 987-93.  
Block, N. (1983), Mental pictures and cognitive science. Philosophical Review, 92, 499-
541. 
Boisson, D. and Luaute, J. (2004), Les somatoparaphrénies. Annales Médico 
Psychologiques, 162, 55-59. 
Bottini, G., Bisiach, E., Sterzi, R., Vallar, G. (2002), „Feeling touches in someone else‟s 
hand‟, Neuroreport, 13, 249-252. 
Botvinick, M., Cohen, J. (1998), Rubber hands 'feel' touch that eyes see. Nature, 391, 756. 
Braun, C., Schweizer, R., Elbert, T., Birbaumer, N., Taub, E. (2000), Differential activation 
in somatosensory cortex for different discrimination tasks. J Neurosci, 20(1), 446-50. 
Calvert, G.A., Brammer, M.J., Iversen, S.D. (1998), Crossmodal identification. Trends in 
Cognitive Sciences, 2 (7), 247-253. 
Castiello, U., Paulignan, Y., & Jeannerod, M. (1991). Temporal dissociation of motor 
responses and subjective awareness. A study in normal subjects. Brain, 114, 2639–
2655. 
Driver, J. and Spence, C. (1998), Attention and the cross-modal construction of space. 
Trends in Cognitive Sciences, 2(7), 254-262.  
Duhamel, J.R., Bremmer, F., BenHamed, S., Graf, W. (1997), Spatial invariance of visual 
receptive fields in parietal cortex neurons. Nature, 389(6653), 845-848. 
Farne, A., Ladavas, E. (2000), Dynamic size-change of hand peripersonal space following 
tool use. Neuroreport, 11(8), 1645-9.  
Fourneret, P. and Jeannerod, M. (1998), Limited conscious monitoring of motor 
performance in normal subjects. Neuropsychologia, 36 (11), 1133-1140. 
Gandevia, S.C., Phegan, C.M. (1999), Perceptual distortions of the human body image 
produced by local anaesthesia, pain and cutaneous stimulation. J Physiol, 514, 609-
16. 
Graziano, M.S., Cooke, D.F., Taylor, C.S. (2000), Coding the location of the arm by sight. 
Science, 290(5497), 1782-6. 

 
 
18
Gurwitsch, A. (1985), Marginal consciousness. Athens: Ohio University Press. 
Haggard P, Taylor-Clarke M, Kennett S. (2003), Tactile perception, cortical representation 
and the bodily self. Current Biology, 13(5), R170-3. 
Halligan, P.W., Marshall, J.C., Hunt, M., Wade, D.T. (1997), Somatosensory assessment: 
can seeing produce feeling? J Neurol, 244(3), 199-203. 
Hari, R., Hanninen, R., Makinen, T., Jousmaki, V., Forss, N., Seppa, M., Salonen, O. 
(1998), Three hands: fragmentation of human bodily awareness. Neurosci Lett, 
240(3), 131-4. 
Hlustik, P., Solodkin, A., Gullapalli, R.P., Noll, D.C., Small, S.L. (2001), Somatotopy in 
human primary motor and somatosensory hand representations revisited. Cereb 
Cortex, 11(4), 312-21.  
Iriki, A., Tanaka, M., Iwamura, Y. (1996), Coding of modified body schema during tool 
use by macaque postcentral neurones. Neuroreport, 7(14), 2325-30. 
James, W. (1890), The principles of Psychology, Vol 1. New York: Holt. 
Jeannerod, M. (1997), The Cognitive Neuroscience of action. Oxford: Blackwell. 
Kennett, S., Spence, C., Driver, J. (2002), Visuo-tactile links in covert exogenous spatial 
attention remap across changes in unseen hand posture. Percept Psychophys, 64(7), 
1083-94. 
Kinsbourne M., Warrington E. (1962), A study of finger agnosia. Brain, 85, 47-66.  
Lackner, J.R. (1988), Some proprioceptive influences on the perceptual representation of 
body shape and orientation. Brain, 111, 281-297. 
Lemon, R. (1988), The output map of the primate motor cortex. Trends in Neuroscience, 11 
(11), 501-506. 
 Macaluso, E., Frith, C., Driver, J. (2000), Selective spatial attention in vision and touch: 
unimodal and multimodal mechanisms revealed by PET. J Neurophysiol, 83(5), 
3062-75. 
Maravita, A. and Iriki, A. (2004), Tools for the body (schema), Trends in Cognitive 
Sciences, 8 ( 2),  79-86. 
Maravita, A., Clarke, K., Husain, M., Driver, J. (2002), Active tool use with the 
contralesional hand can reduce cross-modal extinction of touch on that hand. 
Neurocase, 8(6), 411-6. 
McGonigle, D.J., Hanninen, R., Salenius, S., Hari, R., Frackowiak, R.S., Frith, C.D. (2002), 
Whose arm is it anyway? An fMRI case study of supernumerary phantom limb. 
Brain, 125,  1265-74. 
Merleau-Ponty, M. (1945), Phénoménologie de la perception. Paris: Gallimard. 
Merzenich, M.M., Nelson, R.J., Stryker, M.P., Cynader, M.S., Schoppmann, A. and Zook, 
J.M. (1984), Somatosensory cortical map changes following digit amputation in adult 
monkeys. J. Comp. Neurol. 224, 591–605. 

 
 
19
Ogden, J.A. (1985), Autotopagnosia. Occurrence in a patient without nominal aphasia and 
with an intact ability to point to parts of animals and objects. Brain, 108, 1009-22.  
 O‟Shaughnessy, B. (1980), The will: dual aspect theory. Cambridge: Cambridge 
University Press. 
O'Shaughnessy, B. (1995), Proprioception and the body image. In The body and the self, 
edited by J.L. Bermudez, A. Marcel and N. Eilan, Cambridge (Mass.): MIT Press. 
Pavani F, Spence C, Driver J. (2000), Visual capture of touch: out-of-the-body experiences 
with rubber gloves. Psychological Science, 11(5):353-9. 
Penfield, W., Boldrey, E. (1937), Somatic motor and sensory representation in the cerebral 
cortex of man as studied by electrical stimulation. Brain, 60, 339-448. 
Penfield, W., Rasmussen, T. (1950), The Cerebral Cortex of Man. New York: MacMillan. 
Ramachandran, V.S., Rogers-Ramachandran, D. (1996), Synaesthesia in phantom limbs 
induced with mirrors. Proceedings of the Royal Society of London, 263, 377-386. 
Ramachandran, V.S., Hirstein, W. (1998), The perception of phantom limbs. Brain, 121, 
1603-1630. 
Reed C.L., Stone V.E., Bozova S., Tanaka J. (2003), The body-inversion effect. Psychol 
Sci, 14(4), 302-8.  
Rochat, P. (1998), Self perception and action in infancy. Experimental Brain Research, 
123, 102-109. 
Rorden C, Heutink J, Greenfield E, Robertson IH. (1999), When a rubber hand 'feels' what 
the real hand cannot. Neuroreport, 10(1):135-8. 
Schieber, M.H., Hibbard, L.S. (1993), How somatotopic is the motor cortex hand area? 
Science, 261(5120), 489-92.  
Scholl, B.J. (2001), Objects and attention : the state of the art. Cognition, 80 (1-2), 1-46. 
Schweizer, R., Braun, C., Fromm, C., Wilms, A., Birbaumer, N. (2001), The distribution of 
mislocalizations across fingers demonstrates training-induced neuroplastic changes in 
somatosensory cortex. Exp Brain Res, 139(4), 435-42.  
Semenza, C. (1988), Impairment in localization of body parts following brain damage. 
Cortex, 24(3), 443-9.  
Sirigu, A., Grafman, J., Bressler, K., Sunderland, T. (1991), Multiple representations 
contribute to body knowledge processing. Evidence from a case of autotopagnosia. 
Brain, 114, 629-42. 
Taylor-Clarke, M., Kennett, S., Haggard, P. (2002), Vision modulates somatosensory 
cortical processing. Curr Biol, 12(3), 233-6. 
Taylor-Clarke, M., Jacobsen, P., Haggard, P. (2004), Keeping the world a constant size: 
object constancy in human touch. Nat Neurosci., 7(3), 219-20. 
Treisman, A. (1998), Feature binding, attention and object perception. Philos Trans R Soc 
Lond B Biol Sci, 353(1373), 1295-306. 

 
 
20
Tsakiris, M., Haggard, P., Franck, N., Mainy, N., Sirigu, A. (2004). A specific role for 
efferent information in a self-recognition task. Cognition, under revision.  
Tsakiris, M. and Haggard, P. (2004). Of rubber hands and rubber fingers. Journal of 
Experimental Psychology : Human Perception and Performance, under revision.  
Wiggins, D. (1968), On being in the same place at the same time. The philosophical review, 
77 (1), 90-95. 
Wiggins, D. (1980), Sameness and Substance. Oxford: Blackwell. 

 
 
21
 
 
Somatosensory mereology 
Motor mereology 
Physical origin 
Skin 
Muscle and joints 
Primary cortical area 
SI 
MI 
Internal structure 
Continuous somatotopy 
Integrated and overlapping 
somatotopy 
Segmenting principle 
No intrinsic segmentation 
Action 
Landmarks 
 
for 
body 
segmentation 
None 
Joints  
Structuring principle 
Contiguity 
Coherence 
Organization 
Spatial 
Functional 
Confusion of body parts 
Autotopagnosia 
Motor neglect 
Addition of body parts 
Supernumerary limbs 
Tool use 
Deletion of body parts 
Phantom sensations 
Phantom movements 
 
Table 1.  
 

 
 
22
 
 
Figure 1  

 
 
23
 
 
Figure 2

 
 
24
 
 
Figure 3 
 

 
 
25
 
 
 
 
 
Figure 4

 
 
26
Figure Legends 
 
Table 1: Somatosensory and motor mereology 
 
Figure 1: Body representation in (a) human motor cortex and (b) human somatosensory 
cortex. (Adapted from Penfield and Rasmussen, 1950)  
 
Figure 2: The Pinocchio illusion. Experimental configurations and results with (A) biceps 
brachii vibration and (B) triceps brachii vibration. From Lackner (1998) 
 
Figure 3: Mean perceptual shifts across conditions for experiments 1 and 2. To isolate the 
part of the positional drift due to visual-tactile integration, and obtain a true measure of 
RHI, we subtracted the judgment errors obtained in the asynchronous conditions from the 
judgment errors obtained in the synchronous conditions.  
 
Figure 4: Mean perceptual shifts across conditions for experiments 3 and 4. In experiment 
3, subjects judged the perceived position of the stimulated middle finger. In experiment 4, 
subjects judged the perceived position of the stimulated index finger. 
 

