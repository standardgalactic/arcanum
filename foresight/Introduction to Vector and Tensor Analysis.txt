
introduction to 
I 
I 
11 
I 
/I 
---- --/--1-
/" 
I/ 
I 
- .... 
, 
/ 
)':.-1------
/ 
-..J 
vector and tensor analysis 
ROBERT c. WREDE, PR OFESSOR OF MATHE-
MATICS, SAN JOSE STATE C OLLEGE, 
SAN 
JOSE, 
CALIF ORNIA 
Dover Publications, Inc., New York 

Copyright © 1972 by Dover Publications, Inc. 
Copyright © 1963 by Robert C. Wrede. 
All rights reserved under Pan American and Inter­
national Copyright Conventions. 
Published in Canada by General Publishing Com­
pany, Ltd., 30 Lesmill Road, Don Mills, Toronto, 
Ontario. 
Published in the United Kingdom by Constable 
and Company, Ltd. 
This Dover edition, first published in 1972, is an 
unabridged and corrected republication of the work 
originally published by John Wiley and Sons, Inc., 
in 1963. 
International Standard Book Number: 0-486-61879-X 
Library of Congress Catalog Card Number: 72-79300 
Manufactured in the United States of America 
Dover Publications, Inc. 
180 Varick Street 
New York, N. Y. 10014 

To my Mother 
and the 
Memory of my Father 


pref ace 
Vector and tensor analysis are mathematical tools appropriate for the 
development of concepts in many areas, including geometry, analysis, 
and linear algebra. Even though vector analysis is a proper subset of 
tensor analysis, it has grown up separately. For this reason two distinct 
notations have developed with many variations of each. 
The vector 
notation, introduced primarily by Gibbs, has found wide use in differ­
ential geometry, especially curve theory, and in classical mechanics. The 
vector approach is rapidly finding its way into calculus and various 
engineering texts and into writings on aspects of biology, economics, and 
other sciences which had little use for such a viewpoint a few years 
ago. 
The tensor notation and concepts grew up with the development of 
differential geometry, particularly surface theory and the extension of 
geometric ideas to spaces of n dimensions. For some years the theoretical 
physicist and the applied mathematician have found tensor analysis to be 
a valuable tool. 
In emphasizing the utilitarian aspects of vector and tensor analysis, we 
must not overlook the fact that each theory involves the development of 
a complete mathematical system; that is, with respect to vector analysis, 
basic entities, called vectors, are introduced and the algebra and calculus 
of these objects are developed. The situation for tensor analysis is similar 
but more complex. 
In this text I have tried to point out the role played in the development 
of vector analysis by concepts that are a part of linear algebra. There is 
an emphasis on the interrelationship of geometric and algebraic modes of 
expression. The classical notation of vector analysis is used, but notation 
vii 

Viii 
PREFACE 
more appropriate to tensor analysis is gradually introduced and corre­
lated with the common vector notation. This is done in part to familiarize 
the student with tensor symbols and in part to facilitate the statement of 
proofs. However, the major distinction between this text and others of 
an introductory nature is the emphasis on transformation theory and the 
ramifications of that emphasis. In the first four chapters it is assumed that 
the space is Euclidean, and orthogonal Cartesian, general Cartesian, and 
general coordinate transformations, respectively, are presented. Simul­
taneously n-tuples of real numbers are associated with orthogonal Car­
tesian systems, collections of such n-tuples (a collection consisting of one 
n-tuple from each orthogonal Cartesian system) are defined as Cartesian 
vectors, and the vector concept is extended to the more general trans­
formation groups. Transformation laws relating vector components in 
different coordinate systems are carefully stated. The significance of this 
mode of introduction of the vector form is indicated by various examples. 
In particular, the importance of the invariance of form, accomplished by 
the procedure described, is demonstrated in Chapter 2, Section 6. This 
development of special relativity requires no great depth of mathematical 
knowledge and serves to illustrate the importance of transformation 
theory. I believe that many of my students found it to be a bright spot 
in the courses from which this book is derived. 
I have applied my notes (or I should say series of notes) in two ways. 
The first four chapters with the starred sections deleted were used for a 
one-semester, three-unit vector analysis course, which had a differential 
equations prerequisite but not an advanced calculus prerequisite. The 
students were mostly mathematics, physics, and engineering majors. I 
have also used the starred sections, with Chapter 5, as the basis for a one­
semester, three-unit course in tensor analysis for seniors and beginning 
graduate students. The section on general relativity was not included. 
I have used the material on general relativity in an expanded form, as well 
as material on special relativity, in a three-unit course on applications of 
tensor analysis. I suggest also that this book could serve the purposes of 
an integrated two-semester course in vector and tensor analysis. 
It is my belief that it is particularly suitable as preparation for differ­
ential geometry, applied mathematics, and theoretical physics. I think it 
will also provide a bridge between elementary aspects of linear algebra, 
geometry, and analysis, and I have tried to add some perspective by the 
inclusion of a significant amount of historical information. 
San Jose, California 
Robert C. Wrede 
August 1963 

acknowledgments 
A textbook is necessarily a compilation of historical information con­
cerning the subject at hand. My choice of topics and procedures has 
been influenced by many sources. Of these I would like particularly to 
acknowledge the influence of my former teacher Professor Vaclav Hlavat) 
(Indiana University). 
I am indebted to Professors Erwin Kreyszig (Graz, Austria) and 
Bernard Friedman (University of California, Berkeley), both of whom 
carefully read the manuscript and made many valuable suggestions and 
corrections, and also to Dr. Dale Ruggles (San Jose State College), who 
eliminated numerous errors from the manuscript and discussed the point 
of view of the text with me. 
I wish to express my thanks to my wife Jeanne S. Wrede, who drafted 
the initial set of illustrations for the book and performed many other 
tasks that contributed to its completion. 
I am grateful to Mrs. Gerry Dunckel for typing the manuscript and for 
doing an excellent job in the tedious task of compiling the index. 
Finally I would like to extend my thanks to the staff of John Wiley & 
Sons for their consideration and care in the preparation of this text. 
R.C.W. 
ix 


contents 
chapter 1 the algebra of vectors, 1 
Historical summary, 1 
1. Introductory concepts, 7 
2. Linear dependence or independence of a set of number n-tuples, 23 
3. Transformation equations relating rectangular Cartesian 
coordinate systems, 35 
4. Definitions of Cartesian scalar and vector, 51 
5. The inner product, 56 
5*. General Cartesian coordinates, 65 
6. & systems and determinants, 85 
7. The cross product, 96 
7*. & systems and the cross product in general Cartesian systems, 111 
8. The algebra of matrices, 114 
chapter 2 the differentiation of vectors, 123 
I. The diferentiation of vectors, 123 
2. Geometry of space curves, 139 
3. Kinematics, 147 
4. Moving frames of reference, 155 
4*. A tensor formulation of the theory of rotating frames of 
reference, 166 
5. Newtonian orbits, 171 
6. An introduction to Einstein's special theory of relativity, 176 
xi 

Xii 
CONTENTS 
chapter 3 partial differentiation and associated concepts, 196 
1. Surface representations, 196 
2. Vector concepts associated with partial diferentiation, 205 
3. Identities involving V, 218 
4. Bases in general coordinate systems, 220 
5. Vector concepts in curvilinear orthogonal coordinate systems, 237 
6. Maxima and minima of functions of two variables, 245 
chapter 4 integration of vectors, 254 
1. Line integrals, 255 
2. Surface integrals, 270 
2*. An introduction to surface tensors and surface invariants, 282 
3. Volume integrals, 288 
4. Integral theorems, 291 
chapter 5 tensor algebra and analysis, 304 
1 
.. Fundamental notions in n-space, 305 
2. Transformations and tensors, 315 
3. Riemannian geometry, 324 
4. Tensor processes of diferentiation, 331 
5. Geodesics, 341 
6. The parallelism of Levi-Civita, 348 
7. The curvature tensor, 354 
8. Algebraic properties of the curvature tensor, 361 
9. An introduction to the general theory of relativity, 371 
answers to odd-numbered problems, 383 
index, 411 

chapter 1 the algebra of vectors 
Historical Summary 
The nineteenth century was one of great achievement. Darwin's theory of 
evolution and geological discoveries concerning the formation of the 
earth influenced man's philosophical outlook. Outstanding accomplish­
ments in electricity and magnetism were followed by technological con­
quests that made the fruits of science available to the many. 
These 
developments stimulated discovery in mathematics and attracted more 
individuals to its study. 
The mathematician's station in life changed. 
Previously his existence had often depended on the benevolence of some 
royal personage, but in the nineteenth century more and more mathe­
maticians were employed, primarily as teachers. 
The accompanying 
greater freedom of thought and increased motivation produced an out­
standing era in mathematics. France and Germany were the centers of 
activity, and toward the end of the century Italian mathematics began to 
flourish. On the other hand Britain was just emerging from the shadow 
of Newton's brilliance and made only a few fresh contributions. 
Vector analysis was born in the middle of the nineteenth century. Its 
underlying concepts are due primarily to William Rowan Hamilton 
(1805-1865, Irish) and Herman Grassmann (1809-1877, German). These 
ideas were developed on a foundation of the physical and mathematical 
thought of many centuries. 
The process of addition in vector analysis is derived from, or at least 
correlates with, the parallelogram law of composition of forces. Aristotle 
(384-322 B.C., Greek) was aware of this law for the special case of a 
rectangle. Simon Stevin (1548-1620, Belgian) employed the principle in 
developing ideas in static mechanics. The parallelogram law of forces was 

2 
THE ALGEBRA OF VECTORS 
formally set forth by Galileo Galilei (1564-1642, Italian); however, it is 
not clear that even he recognized its full scope. In any case, the need for a 
mathematical theory embracing an operation satisfying the fundamental 
laws of real number addition, yet different in character, was unmistakable. 
From the mathematical point of view, vector and tensor analysis is a 
study of geometric entities and algebraic forms not dependent on co­
ordinate system. Since this statement is meaningless without the existence 
of coordinate systems and transformation equations relating them, the 
quest for historical perspective carries us back to their inception. 
Rene Descartes (1596-1650, French) and Pierre Fermat (1601-1665, 
French) share in the credit for the discovery of the utility of coordinate 
systems in relating geometry and algebra. 
Today the concept of co­
ordinate system seems almost trivial; hence it is difficult to realize the 
stimulus that was given to the field of mathematics when a method was 
devised that made possible the amalgamation of geometry and algebra. 
Actually we must be careful in assigning credit for the introduction of the 
coordinate system concept, for, although Descartes' La Geometrie (1637) 
gives impetus to the idea, works by Fermat and John Wallis (1616-1703, 
English) correspond much more closely to modern day analytical geom­
etry. And indeed Apollonius had a characterization of conic sections in 
terms of what we now call coordinates. 
With the idea of coordinate system established in the first half of the 
seventeenth century, the second half saw strides taken in terms of the 
geometric representation of complex numbers a + bi1 (a, b real numbers, 
i = .J-1). John Wallis in 1673 published his Algebra in which he repre­
sented the real part of a + bi along what we would call the axis of the 
reals, or horizontal axis, and then measured vertically a distance corre­
sponding to b. 
Although this representation appears to be similar to 
that used today, it was not until 1798 that the idea of an axis of imaginaries 
was introduced. This concept, put forth by Caspar Wessel (1745-1818, 
Norwegian) in a paper entitled "On the Analytic Representation of 
Direction: an Attempt," completed the development of our present-day 
geometric image of the complex numbers. Wessel's name is not always 
associated with the diagrammatic representation of complex numbers. 
In French and English literature we find the term Argand2 diagram, where­
as in German writings it is often called the Gaussian plane. In the northern 
European countries Wessel is usually honored. 
Complex numbers are 
1 The term "complex numbers" was introduced by Carl Fredrich Gauss (1777-1855, 
German). 
• Argand (1768-1822, French) arrived at a similar conclusion in 1806, several years 
after Wessel. 

Historical summary 
3 
important m the historical background of vectors for several reasons. 
Just as the law of composition of forces served as an impetus to the 
development of vector addition, complex numbers provide a mathe­
matical analogy to it. Vector addition is algebraically of the same form 
as complex number addition. 
Furthermore, the representation of a 
complex number by means of a line segment from the origin to a point in 
a plane associated with a number pair (a, b) treads on the toes of the vector 
concept. In fact, for some purposes it is quite convenient to represent a 
complex number by means of a line segment with a direction, sense, and 
magnitude. (We shall see that such a segment is the geometric representa­
tive of a vector.) Multiplication in terms of complex numbers introduces 
a process more general than that associated with real numbers. In par­
ticular, multiplication· by .J -1 has a geometric interpretation as a 90° 
rotation. (For example, .J=l'(2) = 2i.) It is only a small step forward 
to ask how a type of multiplication can be introduced in three-space such 
that the geometric interpretation corresponds to rotation. 
The answer 
to this question assumes fundamental importance in the development of 
vector analysis. 
As we look back on the nineteenth century it is apparent that a mathe­
matical theory in terms of which physical laws could be described and 
their universality checked was needed. The prerequisites for the develop­
ment of such a theory were available. 
Figuratively speaking, two men 
stepped forward to do the job. 
Hamilton and Grassman introduced the fundamental concepts of 
vector analysis from quite divergent modes of thought and in significantly 
different frameworks. Hamilton3 seems to have been inspired mainly by 
a necessity for appropriate mathematical tools with which he could apply 
Newtonian mechanics to various aspects of astronomy and physics. 
From the strictly mathematical standpoint he was perhaps stimulated 
by the desire to introduce a binary operation that could be interpreted 
physically by means of a rotation in space. On the other hand, Grass­
mann's motivations were of a more philosophic nature. His chief desire 
seems to have been that of developing a theoretical algebraic structure 
on which geometry of any number of dimensions could be based. 
Both Hamilton and Grassmann succeeded in one sense but at least 
partially failed in another. Hamilton developed an algebra based on four 
fundamental units (1, i,j, k) with which many aspects of mechanics could 
be handled. In particular, his so-called theory of quaternions introduced 
1 The term "vector" is due to Hamilton. See Felix Klein, Elementary Mathematics 
from an Advanced Viewpoint-Geometry, translated by E. R. Hedrick and C. A. Noble, 
Dover 1939, p. 47. 

4 
THE ALGEBRA .OF VECTORS 
a noncommutative binary operation which is known today under the 
name "cross product." Hamilton's quaternion (a + bi+ cj + dk, where 
i2 = J2 = k2 = ijk = -1) was not completely the product of his own 
imagination. 
August Ferdinand Mobius (1791>-1868, German), a pupil 
of Gauss, had done much work along this line in his Barycentric Calculus 
(1827).4 For this reason, and also because of its revolutionary nature, 
the introduction of a noncommutative operation must be considered as 
Hamilton's outstanding success. His failure, from the viewpoint of having 
his original work live on in the mathematical literature, existed in the fact 
that the theory of quaternions was too complicated in structure. Despite 
the numerous applications pointed out by Hamilton and the devoted 
advocacy of quaternions by P. G. Tait (1831-1900, Scottish) and others, 
the theory of quaternions was not able to survive in its original form. 
Tait, an ardent disciple of Hamilton's quaternions, spent many years 
of his life in a valiant struggle to make the theory a fundamental language 
of mathematics. His success seems to have been limited to the admission 
by James C. Maxwell (1831-1879, Scottish) that these ideas, as distin­
guished from the algebraic structure of quaternions, could become valuable 
in the theoretical development of electricity and magnetism. 
While Hamilton labored with quaternions, the German gymnasium 
teacher Grassmann (roughly equivalent to a high school teacher in the 
United States) was working on a highly theoretical and philosophic work 
Linea/e Ausdehnungslehre (theory of linear extension), published in 1844. 
By defining an n-dimensional manifold as the set of all real number n­
tuples (X1 
• 
• 
• xn) and introducing a set of n fundamental units e1 • 
• 
• e,. 
Grassmann was able to construct the hypercomplex numbers X1e1 + 
... + xnen. In terms of these numbers, he defined two binary operations, 
one of which is an addition of n-tuples that you will encounter in the first 
section of this work. 
The other operation introduced by Grassmann 
was no doubt motivated by real-number multiplication. The basic idea 
can be arrived at by naively multiplying 
(X1e1 + ... + xnen)( Y1e1 + ... + ren). 
By commuting the space variables with the fundamental units, we obtain 
the form 
X1 Y1e1e1 + X1 Y2e1e2 + X2 Y1e2e1 + · 
· 
· 
. 
A variety of results can be derived from this expression by defining the 
binary operation with respect to pairs of unit elements in different ways. 
' The title was a bit long. 
Der barycentrische Calciil, ein neues Huelfsmittel zur 
analytischen Behandlung der Geometrie darstellt und insbesondere auf die Bi/dung neuer 
Classen von Aufgaben und die Entwickelung mehrerer Eigenschaften der Kegelschnitte 
angewendet, Leipzig, Verlag von Johann Ambrosius Barth, pp. 1-454. 

Historical summary 
5 
As the reader proceeds with his examination of the development of the 
text, he will be able to observe that the so-called scalar and vector products 
as well as the tensor of second order are special cases of Grassmann's 
generalized multiplication. 
In spite of the great merit ofGrassmann's work, it made little impression 
on the scientific world. Even a revised edition of his theory of extension, 
published in 1862, which was to some degree simplified and which had 
many amplifications of the original, failed to be clear enough or of a style 
interesting enough to attract the attention of more than a few of his co­
workers. Neither Hamilton nor Grassmann was able to stand back and 
take the objective look at his work needed to bring about a clarity and 
simplicity of form that focuses attention on the important contributions. 
This task was left to others. 
In particular, John Willard Gibbs (1839-1903, United States) one of 
the outstanding mathematical physicists of the nineteenth century, was 
instrumental in developing the form of vector analysis found in present­
day American texts. In lecturing to students at Yale, Gibbs felt a need 
for a simpler mathematical framework for the theoretical aspects of such 
subjects as electromagnetics and thermodynamics. 
His fami^iarity with 
the work of both Hamilton and Grassmann enabled him to pick out 
those of its aspects that seemed to apply best to the needs of theoretical 
physics. Apparently Gibbs did not think of his development of vector 
analysis as a contribution original enough to warrant publication; thus 
his notes on the subject were circulated among only a limited number of 
interested people. It was some twenty years after the development of his 
original notes that Gibbs reluctantly consented to the presentation of his 
work in book form. The book by E. B. Wilson, published in 1901, proved 
valuable in advancing the cause of vector methods. In fact, most of the 
texts on vector analysis·printed to date have adhered to the form set down 
by Gibbs. 
With the support of the use of vector methods in the development of 
theoretical physics by such outstanding men as 0. Heaviside (1850-1925, 
English) in England and A. Foppe! (1854-1924, German) in Germany, 
numerous texts on the subject began to appear in the United States, 
Germany, Britain, France, and Italy. By the beginning of the twentieth 
century vector analysis had become firmly entrenched as a tool for the 
development of geometry and theoretical physics. 
As previously stated, Grassmann's Ausdehnungslehre contained much 
more than a basis for elementary vector analysis. Implicit in the work 
are many of the basic ideas of modern-day tensor analysis.5 
Possibly 
1 The term "tensor" was originated in the study of elasticity. See Dirk J. Struik, A 
Concise History of Mathematics II, Dover, 1948, p. 283. 

6 
THE ALGEBRA OF VECTORS 
because of the more complicated notation, surely because of a lack of 
pressing need, the tensor theory was slower in coming into formal being. 
A realization of the need for the tensor ideas can be closely tied to the 
development of the intrinsic geometry of surfaces by Karl Friedrich Gauss. 
This significant contribution to mathematics was followed up by Riemann's 
generalization of the concepts to a space of n dimensions. 
Bernhard 
Riemann (1826-1866, German) a pupil of Gauss, based the metric 
properties of an n-dimensional space on a fundamental quadratic form. 
n 
n 
ds2 = L L gap dx« dxfl, 
«=l /l=l 
which had the same character as Gauss's first fundamental form on a 
surface. 
He generalized the concept of curvature on a surface to n­
dimensional space and in general set up a form of geometry that was a 
prime target for the algebraic methods existing in the works of Grassmann 
and others. 
Riemann's doctoral thesis "On the Hypotheses Which Lie 
at the Foundations of Geometry," read before the Philosophical Faculty 
of the University of Gottingen in 1854 and published in 1868, after his 
death, stirred much interest in the mathematical world. 
Such men as 
E. Beltrami (1835-1900, Italian), E. B. Christoffel (1829-1900, German), 
and R. Lipschitz (1831-1904, German) made contributions that laid a 
further foundation for the development of the algebra and calculus of 
n-dimensional manifolds. 
At the close of the nineteenth century the ideas were compiled and 
developed by Gregorio Ricci Curbastro (1853-1925, Italian) into what is 
now known as the algebra and calculus of tensors. Ricci's researches are 
enumerated in a memoir published in collaboration with his pupil Tullio 
Levi-Civita, "Methodes de calcul differentiel et leurs applications," 
Math. Ann., 54, 1901. Tullio Levi-Civita (1873-1945, Italian), himself, 
made major contributions to geometry. In particular, his generalization 
of the concept of parallelism to Riemannian spaces was a significant 
addition to the absolute calculus of Ricci. 
In spite of the fact that Ricci and Levi-Civita pointed out many applica­
tions for tensor calculus in both mathematics and physics, the subject 
was at the beginning of the twentieth century little more than the play­
thing of a small group of mathematicians. No great impetus had yet come 
about to enliven the interest of the scientific world. However, fortunately 
for both tensor analysis and physical theory, the elements of the subject 
were passed into the hands of Albert Einstein (1878-1955, Switzerland) 
by M. Grossmann (1878-1936, Switzerland) of Zurich. 
Einstein had revolutionized scientific and philosophic thought with the 
introduction of his special theory of relativity around 1905. With the tool 

Introductory concepts 
7 
of tensor analysis and the n-dimensional space concepts of Riemann at 
hand, he was able to make significant generalizations of the previous theory. 
Einstein's general theory of relativity served to focus attention on tensor 
calculus and its merits. Since 1916 wide areas of application in theoretical 
physics, applied mathematics, and differential geometry have been found. 
Vector and tensor notation is making its way into elementary books in 
analysis, linear algebra, and other areas of mathematics. In a significant 
measure vector and tensor analysis is serving as the universal language 
Hamilton and Grassmann envisioned in their original theories. 
1. Introductory Concepts 
A course in vector algebra and analysis must presuppose a foundation 
of mathematical knowledge and a certain maturity of mind. The original 
intent was to state this desired foundation of knowledge in outline form. 
But it soon became evident that to put forth in an axiomatic way the 
needed fundamental ideas of geometry, algebra, and analysis would lead 
the discussion far afield. Therefore this introductory section is concerned 
only with a few basic ideas which are sometimes not given enough emphasis. 
The concepts of point, line, plane, and space are used without definition, 
a customary viewpoint in the development of geometry since the time of 
David Hilbert.6 
These basic ideas have been abstracted from man's 
experience, along with that which he perceives as reality, and made a 
part of the foundation of geometry. With respect to Euclidean geometry, 
which is to serve as a setting for this development, you can get a firm 
intuitive feeling for point, line, and plane in the pictorial representation 
that you are no doubt familiar with from your high school geometry. 
Depending on previous training, the use of undefined terms may or 
may not seem strange. Indeed in his original collection of mathematical 
works Euclid "defined" point, line, and plane. However, with the evolu­
tion of logical thought over the centuries, it became evident that these 
definitions were meaningless. In fact, a significant development in man's 
mode of thinking is the realization that certain concepts must be taken as 
undefined; otherwise a process of circular reasoning necessarily results. 
By making use of the idea of coordinate systems, algebraic characteriza­
tions for point, line, and plane can be obtained. 
For example, given a 
coordinate system, a point in a plane can be represented by an ordered 
pair of numbers and then a line in a plane can be characterized as the set 
of all points whose coordinates satisfy a linear algebraic equation. 
Such 
8 David Hilbert (1862-1943, German). 
His Grundlagen der Geometrie, 1900, has 
become a model for the modern axiomatic approach to geometry. 

8 
THE ALGEBRA OF VECTORS 
equations are no doubt familiar to the reader. It must be cautioned that to 
construe this as a definition of the Euclidean7 line would only lead to 
circular reasoning, for without line the coordinate system (and Euclidean 
measurements) cannot be conceived and without coordinate system the 
algebraic characterization fades into an animal of a different sort; that is, 
without a coordinate system in the back of one's mind, a linear equation 
has no well-established geometric meaning. 
For example, interpret 
v = u in terms of rectangular Cartesian and then polar coordinates in 
the plane. 
Many of the considerations of the text are made with respect to a three­
dimensional Euclidean space or a two- or one-dimensional subspace. 
However, these ideas are expressed in a notational fashion that is immedi­
ately extendable to 11-dimensional space. 
In some instances this procedure may result in notational devices that 
seem a little more complex than necessary. 
However, many aspects of 
modern-day science cannot be adequately described in terms of a three­
dimensional Euclidean model. Hence it seems appropriate that this intro­
ductory mathematical material should pave the way for that which lies 
ahead. The mathematical necessity of the notational devices is illustrated 
by the development of tensor algebra; physical usage is amply demon­
strated in the development of special and general relativity theory. 
By means of a coordinate system the triples of real numbers can be put 
into one-to-one correspondence with the points of a three-dimensional 
Euclidean space. Probably the simplest type of coordinate system, hence 
the one most appropriate for use at the start of this development, is the 
so-called rectangular Cartesian coordinate system. 
It is assumed that the reader is somewhat familiar with this system. 
Therefore, the discussion that follows is brief, its chief purpose being that 
of introducing the notation and point of view that is used throughout the 
book. 
A rectangular Cartesian coordinate system is constructed by means of 
three concurrent and mutually perpendicular lines called axes. 
The elements of the set of all real numbers are put in one-to-one cor­
respondence with the points of each axis in such a way that the point of 
concurrence corresponds to 0 in each case; a common unit of measure­
ment is employed. The variables of these one-to-one correspondences are 
designated by X1, X2, X3• Hence it is convenient to denote the lines as 
the X1, X2, and X3 axes, respectively. Then, to each point of the three­
dimensional space there corresponds an ordered triple of real numbers 
1 Of course, we can define in a purely algebraic sense a linear equation as a number 
line. However, having done so, the Euclidean line is only one of many possible 
geometric interpretations. 

Introductory concepts 
9 
xs 
x2 
xi 
Fig. 1-1.l 
(X1, X2, X3) and conversely. Note that the word "ordered" is significant. 
For example, given the triple (2, 1, 5), 2, 1, 5, respectively, replace X1, 
X2, X2, and no other ordering of replacement is possible. The reader is 
likely to be more familiar with the symbols X, Y, Z than with X1, X2, X3• 
However, the usage indicated will have notational advantages that will 
become evident as we read further into the book. For example, a linear 
form a1 X1 + a2X2 + a3X3 can be represented by the compact expression 
a;X;.a 
A rectangular Cartesian coordinate system is said to be left-handed or 
right-handed. In order to make the distinction between these two types, 
consider the triangle of Fig. 1-1.1 determined by the unit points U1, U2, 
us. 
Definition 1-1.1. 
If, as observed from the origin (0, 0, 0), the triangle 
orientation U1 - U2 - U3 is clockwise, 
the 
associated 
rectangular 
Cartesian coordinate system is said to be right-handed. Similarly, if the 
orientation U1 --+ U2 --+ U3 is counterclockwise, the coordinate system is 
said to be left-handed. 
Comments on the relation between left- and right-hand coordinate 
systems are deferred until Section 7. By that stage of the game appropriate 
information concerning transformations and elements of volume will be 
8 The summation convention which leads to this representation is introduced in 
Chapter 1, Section 3. 

}Q 
THE ALGEBRA OF VECTORS 
available to facilitate the discussion. (See Example 1-7.7.) For present 
purposes it suffices to say that either type of coordinate system may be 
used, but consistency demands that no switching back and forth be done. 
Convention 1-1.1. 
The rectangular Cartesian coordinate systems used 
in this text are right-handed. 
One of the major objectives of the subject at hand is to place geometry 
on an algebraic and analytic foundation. Such an approach leads to a 
healthy interchange between intuition and rigor. The following introduc­
tion of an n-tuple space provides a stepping stone in this direction. 
Definition 1-1.2. 
Let the elements of S be ordered n-tuples (A1, A2, • 
• · ,  
An) of real numbers that satisfy the following properties: 
(a) (Addition) 
(A1, A2, •
•
•
 'An) + (B1, B2, •
•
• 'Bn) 
= (A1 + B1, A2 + B2, • 
• 
• , An + B"). 
(b) (Multiplication of an ordered n-tuple of real numbers by a real 
number) 
{3(A1, A2, • 
• 
• , A") = ({3Al, {3A2, • 
• 
• 
, {3An), 
where {3 is any real number. 
The set S will be called an n-tuple space.9 An ordered n-tuple of real 
numbers (A1, • ··,An) is also represented by a bold face A and the numbers 
(A1, • 
• 
• , An) are called the components of A. 
Much of the desired algebraic foundation follows immediately from the 
fact that the n-tuples of the set S are defined in terms of real numbers. 
After setting forth the consequences of this fact, it will be my purpose to 
correlate these algebraic properties with the appropriate geometric facts. 
Definition 1-1.3. 
Two n-tuples A and Bare equal if and only if Ai = Bi, 
j =I, 2, · 
· 
· n 
Definition 1-1.4. 
The n-tuple with components (0, 0, · 
· 
· 
, 0) is called 
the zero n-tuple and denoted by 0 
The fundamental laws of n-tuples are established in the next two 
theorems. 
• The reader familiar with the concept of a vector space, as introduced in an algebra 
course or text, will recognize the space introduced above as such. The reason for the 
present use of the term n-tuple space is that, in differential geometry and in areas of 
physics that deal with transformation theory, there is a further restriction on the vector 
concept. In this book the word "vector" is used in the more limited sense. Birkhoff 
and MacLane, A Survey of Modern Algebra, seventh printing, Macmillan, 19.58, 
p. 159-163. 

Introductory concepts 
11 
1beorem 1-1.1. 
Elements of the n-tuple set S satisfy the following laws: 
(a) (Closure law) 
If A and B are elements of S, then so is A + B. 
(b) (Commutative law of addition) 
A+ B = B +A. 
(c) (Associative law of addition) 
(A+ B) + C =A+ (B + C). 
(1-1.1) 
(d) (Identity element for addition) 
The n-tuples 0 is the unique 
element of S with the property A + 0 = 0 + A = A. 
(e) (Additive inverse) 
Corresponding to each A in Sis a unique 
element (-A) such that A + (-A) = 0. 
PROOF. 
These laws (1-1.la-e) are consequences of the corresponding 
real-number laws and the fundamental properties of n-tuples, as described 
in Definition 1-1.2. The proofs of (I-I.lb) and (1-1.l d) are set forth in 
order to illustrate the method of approach. The other proofs are left to 
the student. 
PROOF OF (1-1.lb). 
According to Definition 1-1.2, the n-tuple A+ B 
has components (A1 + B1, ···,A"+ B"). Because the real numbers are 
commutative, 
(A1 + B1, • 
• ·,A" + B") = (B1 + A1, · 
· 
· 
, B" + A"),. 
Since the right-hand member of this relation represents B + A, the proof 
is complete. 
PROOF OF (1-1.ld). 
Let X be an n-tuple such that 
A+X=A. 
There are two questions to be answered. ls X unique? What are the 
components of X? Again the answer is supplied by making use of the 
associated real-number properties. According to definitions (1-1.2) and 
(I-1.3), 
Ai+ Xi =Ai, 
j = 1, · · 
·
,
 n. 
Because the A1 and Xi are real numbers, we obtain the unique solutions 
Xi = 0, 
j = l, · · 
·
,
 n. 
Therefore X is the n-tuple with components (0, · · · , 0), as was to be shown. 
The concept of additive inverse as introduced in (1-1.le) makes possible 
the following definition of subtraction. 
Definition 1-1.5. 
For every pair of n-tuples A and B let 
(1-1.2) 
A - B = A + ( -B). 
We say that B is subtracted from A. 

12 
THE ALGEBRA Of VECTORS 
According to this definition, subtraction is the inverse operation to that 
of addition. 
Theorem 1-1.2. 
Let oc and f3 represent arbitrary elements from the set of 
real numbers, and A and B represent elements of the n-tuple set S. 
(a) (Closure under real number multi-
ocA is an element of S. 
plication) 
(b) (Real number identity element) 
IA = A. 
(c) (Law of distribution of an n-tuple (oc + {3)A = O(A + {3A. 
with real numbers) 
(1-1.3) 
(d) (Law of distribution of a real number oc(A + B) = ocA + ocB. 
with n-tuples) 
(e) (Law of association of real numbers oc(/3A) = (oc/3)A. 
with an n-tuple) 
PROOF. 
As in Theorem 1-1.1, the proofs result from analogous prop­
erties of real numbers. The proof of (1-1.3a) is presented as an illustration 
of the method employed. 
PROOF OF (1-l.3a). 
A has components (A1, ···,A"). 
According to 
Definition 1-l.2b, 
Because the set of real numbers is closed under multiplication, (ocA1, · · · , 
ocA") is an ordered n-tuple of real numbers and therefore an element of S. 
This completes the proof. 
Let us now turn our attention to the geometric significance of n-tuples 
and their properties. Most of the considerations of this book pertain to 
three-dimensional Euclidean space. On occasion examples are presented 
in terms of two- and even one-dimensional Euclidean space. For this 
reason, and because nobody can visualize a space of dimension greater 
than three anyway, the geometric illustrations are three-, two-, or one­
dimensional. 
However, it is worth emphasizing that the corresponding 
algebraic structure is set up so that it is easily extendable to integer values 
of n > 3. Since it is not difficult to find physical examples in which n > 3, 
this approach can be of significant future value. (See Chapter 2, Section 6.) 
Suppose that a rectangular Cartesian coordinate system is given. (See 
Fig. 1-1.2.) Then an n-tuple A can be represented graphically by an arrow10 
with its initial point at the origin and its terminal point at the position 
with coordinates (A1, A2, A3). 
However, this is not the only possible 
arrow representation of the n-tuple. As a matter of fact, any arrow with 
10 The term "arrow" is being used in an intuitive sense. We are to visualize a line 
segment with one end designated as the initial point and the other as the terminal point. 

Introductory concepts 
13 
xa 
Fig. 1-1.2 
initial and terminal points P(X1, X2, X3) and P(X1, X2, X3) respectively, 
such that 
o 
o 
v 
o 
1 
1 
1 
1 
(1-1.4) A1 = x1 - x1, 
1 
0 
A2 = x2 - x2, 
1 
0 
can be considered a representative of the n-tuple. 
A3 = xa - xa 
0 
Therefore an n-tuple has as its geometric analogue a family of arrows, each 
of which has a common magnitude, direction, and sense. According to 
{l-1.4), the components of A can be interpreted as measurements of the 
perpendicular (or parallel) projections of any geometric representative 
onto the coordinate axes. (Again see Fig. 1-1.2) The geometric inter­
pretation of n-tuples gives added meaning to their representation by a 
single boldfaced letter such as A. 
The terms magnitude, direction, and sense are used in an intuitive manner. 
The meaning of each is made precise as follows: the concept of distance 
as based on the Pythagorean theorem is fundamental to Euclidean geom­
etry. This development presupposes knowledge of the theorem. Hence, 
if P(X1, X2, X3) and P(X1, X2, X3) are any two points in Euclidean three-
o 
o 
o 
o 
1
1
 
1 
1 
space and the coordinate system is rectangular Cartesian, the distance 
IPo P1I is given by 
[(X1 _ X1)2 + (X2 _ X2)2 + (Xa "- Xa)2Jl-1!. 
1 
0 
1 
0 
1 
0 
lf we think of the components of A as orthogonal projections on the 
coordinate axes [see (l-1.4)], we have 
[(Al)2 + (A2)2 + (A3)2] J-1 = [c<xl -Xl)2 + (X2 -X2)2 + (X3 -X3)2]  
1 
0 
1 
0 
1 
0 
(l-1.Sa) 

14 
THE ALGEBRA OF VECTORS 
The concept of magnitude of an n-tuple is then correlated to that of 
distance by means of the following definition. 
Definition 1-1.6. 
Let IAI represent the magnitude of A; then 
( l-1.5b) 
The word direction is used in an analogous way to the word parallel, as 
is common in solid analytic geometry when we talk about direction 
numbers. 
Definition 1-1.7. 
Two n-tuples A and B are said to have the same 
direction (are parallel) if and only if their components are proportional; 
that is, if and only if 
(1-1.6) 
(B1, B2, B3) = {J(A1, A2, A3) 
for some nonzero real number {3. 
The geometric terms "same direction" or "parallel" take on intuitive 
significance when associated with the families of arrows representing A 
and B. Representatives of these families are shown in Fig. 1-1.3. 
The word "sense" is used as a refinement of the term direction; that is, 
if two n-tuples are parallel, we can further indicate an orientation by 
specifying that they have the same sense or are oppositely sensed. Again, 
the geometric interpretation is clearly expressed by the arrow representa­
tives. (See Fig. 1-1.3.) 
Definition 1-1.8. 
Suppose two n-tuples, A and B, had the same direction 
[i.e., to satisfy (1-1.6)]. They will have the same sense if f3 > 0 but opposite 
senses if f3 < 0. 
The algebra of n-tuples evolves from the properties of addition and 
multiplication of an n-tuple by a real number. (See Definition 1-1.2.) We 
can supplement our intuition significantly by examining the geometric 
interpretation of these operations. The law of composition, as demon­
strated in Fig. 1-1.4, is a so-called parallelogram law. 
Parallel arrows with 
the same sense. 
Fig. 1-1.3 
Parallel arrows with 
opposite senses. 

Introductory concepts 
15 
x2 
Flg.1-1.4 
The geometric justification for this name is obtained by constructing 
an arrow representative of A, forming that representative of B which has 
its initial point at the terminal point of A, and then constructing the arrow 
that joins the initial point of A to the terminal point of B. This join, which 
is the diagonal of a parallelogram determined by A and B, is a geometric 
representative of A + B. Since forces, linear velocities, and linear accelera­
tions are known from experimentation to compound by means of a paral­
lelogram law, possibly the reader can get a first glimpse of the way in which 
the mathematical structure presently being developed can be used in 
building models for certain physical problems. 
In the last paragraph n-tuple addition was geometrically interpreted. 
Also, the process of multiplication of an n-tuple by a real number can be 
represented simply. According to Definition 1-1.2, {JA has components 
({JA1, {JA2, {JA3). Hence the magnitude as determined by (1-1.5b) is 
(1-1.7) 
lfJAI = [({JA1)2 + {{JA2)2 + {{JA3)2]! = lfJI IAI. 
Therefore {JA is geometrically represented by an arrow parallel to a 
representation of A, with the same or opposite sense to that of A, depending 
on whether fJ   0, and with magnitude differing by the factor lfJI. 
Construction of geometric interpretations associated with the laws of 
Theorems 1-1.1 and 1-1.2 is left to the reader. 
Most of the physical and geometric usages of the structure presently 
being introduced depend on further developments. However, the following 
simple examples are available at this stage. 

16 
THE ALGEBRA OF VECTORS 
x2 
Fig. 1-1.S 
Example 1-1.1. 
The study of a particle at rest is often called statics. 
Since classical mechanics is primarily concerned with problems involving 
motion of a particle, it might be thought that statics could have no real 
interest. However, as soon as we bring to mind the possibility of several 
forces acting on a given particle in such a way that the particle remains in 
a state of equilibrium, the problems of statics take their rightful place as a 
subset of the problems of motion study. As a particular illustration, con­
sider the following. A particle of mass m is suspended by two weightless 
strings as in Fig. 1-1.5. The idealization to weightless strings enables 
us to work with a model in which the strings are replaced by straight 
lines. There is a gravitational force mg acting on the particle. Furthermore, 
if forces (i.e., tensions) F1 and F2 are associated with the strings, 
The components of F1 are 1F1I cos 81, IF11 sin 81, whereas those of F2 are 
IF21cos82 and IF2I sin 02• Therefore 
IF1I cos 81 + IF2I cos 02 = o 
IF1I sin 81 + IF2I sin 02 - m lgl = 0. 
Upon solving for IF11 and IF21, we obtain 
IF1I = -m lgl cos 82 
IF2I = m lgl cos 01 
sin (02 -81) 
sin (02 -81) 

Introductory concepts 
17 
Thus, by identifying a state of equilibrium with the resultant 0 and using 
the basic laws of n-tuples, we are able to obtain the magnitudes of the 
string tensions. 
Example 1-1.2. 
The fact that a line is determined by a point and a 
direction leads at once to an algebraic representation in terms of n-tuples. 
Suppose that the given point is denoted by P0 and the direction is deter­
mined by an n-tuple B. As in Fig. 1-1.6, let r0 be an arrow with the initial 
point at the origin and the end point at P0• For convenience of illustration, 
use that arrow representative of B which has its initial point at P0• Then an 
arrow r, with its initial point at the origin and its end point at an arbitrary 
position on the line, is determined according to the parallelogram law of 
addition by 
(1-1.8) 
r = r0 + B/ (t), 
where /(t) is a continuous function11 with range v&.lues - oo < f(t) < oo. 
Often it is convenient to choose f(t) such that /(t) = 0 for t = 0. The 
requirement that the range values /(t) include the complete set of real 
numbers ensures that the line rather than a segment of it is represented. 
Choices of/such that (1-1.8) represents a line segment are also of interest 
and are used later in the discussion. 
xa 
xi 
Fig.1-1.6 
11 For a discussion of function, see Chapter 2, Section 1. 
x2 

18 
THE ALGEBRA OF VECTORS 
It is left to the reader to show that the vector representation (1-1.8) is 
equivalent either to the set of parametric equations 
(1-1.9a) 
X1 = Xa1 + B1 f(t) 
x2 = Xo2 + B2f(t) 
X3 = X03 + B3 f(t) 
or, when Bi :;4: O,j = 1, 2, 3, to the symmetric form 
(1-1.9b) 
If one of the components Bi is equal to zero, say, for example, B1 = 0, 
then the symmetric form must be replaced by 
x2 - x 0 2 - xa - x 0 3 
B2 
-
Ba 
Therefore the symmetric form is not generally valid but rather subject 
to a variety of exceptions. 
On the other hand, the parametric form 
(1-1.9a) and the equivalent arrow or n-tuple equation (1-1.8) have general 
validity. The universal character of these representations is a significant 
point in favor of their usage. 
Example 1-1.3. 
Suppose that the function of the preceding example 
were 
f(t) = t, 
where t is defined on the set of all real numbers. On the one hand, the 
relation 
r = r0 + Bt 
represents a line. On the other hand, this relation can be interpreted as 
the algebraic analogue of Newton's first law of motion (i.e., every body 
tends to remain in a state of rest or of uniform rectilinear motion unless 
compelled to change its state through the action of an impressed force). 
This analogy is obtained by interpreting the values of the parameter t as 
measures of time and by giving the line the kinematical interpretation of 
a path generated by a moving particle. Such physical interpretations of 
geometric models, as alluded to in this example, are dealt with in the dis­
cussions of kinematics and dynamics in a later chapter. 
Example 1-1.4. 
Suppose the function f of Example 1-1.2 is given by 
the rule 
f(t) =sin t, 

Introductory concepts 
19 
where t is defined on some subset of real numbers. The set of range values 
off lies in the closed interval 
-1 [sin t [ 1. 
Therefore, when this function is used in the form (1-1.8), only a segment 
of a line is represented. 
A fundamental problem of theoretical physics is that of formulating 
universally valid Jaws relating natural phenomena. Often the problem is 
restricted to that of finding relations valid with respect to a certain set of 
frames of reference. Newton's second law of motion (i.e., the rate of 
change of momentum is proportional to the impressed force and occurs 
in the direction of the applied force) provides such an example. The law, 
the simplest form of which is 
F 
= dmv, 
dt 
where F represents force and mv represents momentum, is valid only in 
frames of reference that are in an unaccelerated state of motioD. Such 
frames are called inertial systems and probably exist only ideally. From 
the point of view of mathematics we associate a coordinate system with 
each frame of reference and then ask how the entities in the algebraic 
expression of the physical law transform in order that the form of the 
law may remain the same (i.e., invariant). Because the transformation 
idea is of such importance, the development of vector analysis12 in this 
book is built around it. As stepping stones to the introduction of the 
vector concept, we make use of the set of orthogonal Cartesian coordinate 
systems and the geometric interpretation of n-tuples. 
Having constructed one rectangular Cartesian coordinate system in a 
Euclidean space, 13 it is clear that any number of systems can be constructed, 
each distinct from any other. If an n-tuple in three-space (A1, A2, A3) is 
given with respect to the initially constructed coordinate system, then by 
its arrow representation, and by means of orthogonal projection, we can 
determine triples in each of the other systems. (See Fig. 1-1.7.) This 
thought leads us to the concept of a Cartesian vector. 
Definition 
1-1.9. 
The set {A1, A2, A3} of all triples (A1, A2, A3), 
(A\ A2, A3), etc., determined by orthogonal projections of a common 
arrow representation on the axes of the associated rectangular Cartesian 
11 The term "vector" was introduced by Hamilton. 
18 The existence of a rectangular Cartesian coordinate system is equivalent to the 
space being Euclidean. As an example of a non-Euclidean space, hence one in which a 
Cartesian coordinate system cannot be constructed, consider the surface of a sphere. 

20 
THE ALGEBRA OF VECTORS 
Fig. 1-1.7 
coordinate system is said to be a Cartesian vector. Any two triples of this 
set are related by a particular law of transformation.' (This law has yet 
to be specified.) 
A Cartesian vector has a family of arrows as its geometric representative; 
with respect to a coordinate system it is characterized by a magnitude, a 
direction, and a sense, and its components in any coordinate system satisfy 
the algebraic laws pertaining to n-tuples.14 In most elementary books on 
vector analysis a vector is identified as an arrow. We take the more compli­
cated viewpoint of the preceding definition because by defining a Cartesian 
vector as a collection ofn-tuples, any two of which are related by a specified 
law of transformation, the concept is given an absolute meaning from the 
point of view of algebra. On the one hand, this viewpoint is consistent with 
the absolute geometric meaning for a Euclidean space of dimension n ::; 3. 
On the other hand, the algebraic framework opens the door to a generalized 
definition of the vector concept expressed in terms of a set of transforma­
tions but not dependent on the geometric interpretation as an arrow. 
This general approach has significance for Euclidean spaces of dimensions 
n > 3 and to considerations in non-Euclidean spaces. 
u There are two facts that must not be confused. On the one hand, the term "family 
of arrows" alludes to the fact that there is an arrow at each point of space. On the 
other hand, the expression "sets of triples" refers to the fact that an arrow can be 
projected on an infinite set of orthogonal axes. 

Problems 
21 
The law of transformation alluded to in Definition 1-1.9 is introduced 
for Cartesian vectors in Section 3 and in more generality in later sections. 
Because there is an identification of the geometric representative of a 
Cartesian vector and a 3-tuple, and in order to avoid involvement in a 
complexity of notation, the same boldfaced symbols are used for Cartesian 
vectors that have been used for n-tuples. 
Problems 
1. Graph a right-hand rectangular Cartesian coordinate system for three 
dimensions. 
(a) Construct an arrow with initial point at (1, 2, 0) and end point (2, 5, 0). 
What are the magnitudes of the perpendicular projections of this 
arrow on the three coordinates axes ? 
(b) Construct the arrow of the same family as the arrow of part (a) with 
initial point at the origin. 
(c) Repeat (a) and (b) for an arrow with initial point (1, 2, 3) and terminal 
point (2, 5, 6). 
2. The initial and terminal points, respectively, of several arrows are given. 
Find the n·tuple corresponding to each arrow. 
(a) (5, 1, 3) and (4, 3, 6). 
(b) (0, 0, 0) and (-1, 4, 7). 
(c) (-3, -5, -1) and (-2, 4, 6). 
(d) (2, 5, 1) and (2, 5, 3). 
3. The components of an n-tuple are 2, 5, 
- 1 . What are the components of an 
n-tuple of opposite sense and of the same magnitude? 
4. n-tuples A and B have components 1, 3, -2 and 5, 1, 7, respectively. What 
are the components of C 
= A + B? 
5. What is the magnitude of each of the n-tuples A, B, and C of Problem 4? 
6. (a) Use (1-1.5b) to find the magnitude of an n-tuple with components 
6,9,6v'i 
(b) Find the components of a unit n-tuple with the same direction and 
sense as the n-tuple of (a). 
7. It is found experimentally that forces compound according to the parallelo­
gram law and that they can be represented geometrically by arrows. 
If the forces on a joint of a bridge have components [O, 3, -5], [O, -3, 
-5] and [0, 0, 10] what is the total force? (Find components and magni­
tude.) 
8. Velocities also fall into the arrow category. Jn the accompanying diagram 
the two arrows represent a plane's velocity in still air (PV) and wind 
velocity (WV). If the components are 400 cos 35°, 400 sin 35°, and 
15 cos 320°, 15 sin 320°, respectively, find the components of the resultant 
velocity. (Actually, angular measurements are made clockwise from the 

22 
THE ALGEBRA OF VECTORS 
xz 
north in navigation problems rather than counterclockwise from the 
positive X1 axis as expected here.) 
9. (a) Complete the proof of Theorem 1-1.1. 
(b) Complete the proof of Theorem 1-1.2. 
10. Construct a diagrammatic representation for the associative law of addition 
(1-1.lc). 
11. Prove {JA = 0 and {J ¥< 0 implies that A = 0. 
12. Solve the n-tuple equation 3R + 5B = C for R in each of the following 
cases: 
(a) Band C, respectively, have components (2, 4, 0), (1, 5, 0). 
(b) B and C, respectively, have components (1, -4, 6), (2, 1, 3). 
13. Prove for nonzero n-tuples that if A is parallel to C, B is parallel to D, and 
A is parallel to B then C is parallel to D. 
14. (a) Suppose that JA! 
= JBI; give an example such that A ""'- B. 
(b) Prove that A - B 
= 0 implies that A =B. 
15. Show that the joint of the midpoints of two sides of a triangle is parallel to 
the third side and has a magnitude of one half that of the third side. 
16. Arrows are drawn from the center of a regular pentagon to the vertices. 
Show that the sum of these arrows is zero. 
17. (a) Suppose that in Example 1-1.1 the angles 01 and 02 were 135 and 30°, 
respectively. If m = 10 and Jg! 
= 32, determine the magnitudes of F1 
and F2• 
(b) For what values of 01 and 02 is the solution not valid? 
18. Suppose that a particle of mass m is suspended by three weightless strings. 
Set up the n-tuple equation for this problem. IfF1' F2, F3 have components 
(F,., Fil, Fz), (F,., Fil, Fz), (F,., F11, F,), respectively, write out the set of 
1
1
1
 
2
2
2 
3
3
3
 
equations. Does this set of equations provide sufficient information to 
bring about a solution for JF1J, JF2J, JF3J? 

I 
I 
'f 
mg 
Independence of a set of n-tuples 
23 
x2 
19. Find the parametric and symmetric representations of a line determined by 
(a) P(I, 5, 3) and B = (-1, 4, 6), 
(b) P(-1, 3, 2) and B = (2, -5, 3). 
20. Show that the lines 
x1 = 2 + 21, 
x2 = 1 - 4t, 
X3 =0, 
are perpendicular. 
X1 = 6s, 
X2 = 5 + 3s, 
X3 =0 
21. Consider the line r = r 0 + Bt of Example 1-1.3 as representative of the path 
of a particle in motion and interpret the parameter t as a measure of time. 
Show that the distance traversed in a fixed interval of time, 6.t 
= t2 - t1, 
is independent of t 2 and t 1• 
2. Linear Dependence or Independence of a Set of n-tuples 
The concepts of linear dependence and linear independence permeate 
many areas of mathematics. 
The reader, knowingly or unknowingly, 
was exposed to the ideas while evaluating integrals by partial fractions and 
while considering exact differential equations of the form M dx + N dy = 0. 
If we were to examine some of those books that pioneered the study of 
vector analysis,15 we would not find discussions of linear dependence or 
n See E. B. Wilson, Vector Analysis-Gibbs, Yale University Press, 1901. Kelland, 
Tait, and Knott, Introduction to Quaternions, Macmillan, first edition, 1873. 

24 
THE ALGEBRA OF VECTORS 
independence. The properties associated with these concepts are assumed 
on a purely geometrical basis and are expressed in terms of the arrow16 
representations of the vectors. For example, it is said that two arrows are 
collinear (or parallel) or not collinear, whereas three arrows are coplanar 
or not coplanar. We can obtain a geometric insight into the concepts of 
this section by visualizing the arrow representatives of a pair of dependent 
n-tuples as collinear and a dependent triple as coplanar. 
On the other 
hand, an independent pair determines a plane, whereas three independent 
arrows cannot be in a plane. These statements provide a correct intuitional 
background. 
However, they are not really operational; 
that is, given 
three sets of components (say 2, 5, 3; 1, 4, 7; 5, 14, 13), we cannot 
easily test for linear dependence or independence. 
By resorting to algebraic statements in defining the concepts of linear 
dependence and independence precision is gained and no element of 
geometric intuition need be lost. This is therefore the approach that is 
taken. 
This section is restricted to considerations of linear dependence and 
independence of n-tuples. Corresponding statements concerning Cartesian 
vectors follow in an intuitive sense from the geometric representations and 
can be validated in a precise algebraic sense as soon as appropriate trans­
formation laws are established. (See Sections 3 and 6 of Chapter 1.) 
Definition 1-2.la. 
A set of pn-tuples A1, • 
• 
• , A,, is said to be linearly 
dependent if and only if there are p real numbers {31, • 
• 
·
,
 {3,,, not all zero, 
such that 
(1-2.1) 
p 
! {31A1 = {31A1 + 
· 
· 
· + {3,,A,, = 0. 
i=l 
Definition 1-2.lb. 
A set of n-tuples is linearly independent if and only if 
it is not a linearly dependent set. 
An alternative way of expressing the idea of linear independence is 
stated by the following theorem. The symbol +-+ is to be read "is equiv­
alent to the statement" and thought of as a logical implication in both 
directions. 
Theorem 1-2.1 
(The set of n_tu`les ) 
AI> · 
· 
· , A,, 1s linearly 
independent. 
(the only condition under ) 

 
which (1-2.1) holds is that 
all {3; = 0. 
16 The term "arrow" is not specifically used. 

Independence of a set of n-tuples 
25 
PROOF. 
If the set Ai, • 
• 
· , A:r> is an independent set of n-tuples, it is not 
dependent. 
Hence, according to Definition 1-2.la, all {:J; = 0. 
The 
implication in the other direction is also a direct consequence of the basic 
definiti-ns. 
Theorem 1-2.2. 
Any nonempty subset of a set of linearly independent 
n-tuples is itself linearly independent. 
PROOF. 
Let Ai. · 
· 
• , A:r> be a linearly independent set of n-tuples. 
Suppose that some nonempty subset A,1, • 
• 
• , A,., k < p, were not linearly 
independent. This means that there are real numbers {:J,1, • 
• 
·
,
 p,k, not 
all zero, such that 
k 
(l-2.2a) 
! {JJ;As, = 0. 
i=i 
By simply choosing each of p,k+l' · 
· 
· , p,:P as zero, the relation (l-2.2a) 
can be extended to 
(1-2.2b) 
:P 
! p1,A,, = 0, 
i=i 
where not all Ps, are zero. But this contradicts the linear independence 
of the set Ai, · 
• 
· , A:r>. 
Therefore the supposition that some subset 
A,1, • 
• 
• , A1k is linearly dependent is not valid and the proof is complete. 
It is the purpose of this section to present the ideas of linear dependence 
and independence as simply as possible and with no undue amount of 
generality. Therefore the next two theorems come right down to earth, so 
to speak, and deal with the problem of determining how many n-tuples 
can be independent in a three-dimensional space. 
Theorem 1-2.3. 
In a three-dimensional Euclidean space, referred to a 
rectangular Cartesian coordinate system, the n-tuples (1, 0, 0), (0, I, 0), 
and (0, 0, 1) determine a linearly independent set. 
PROOF. 
Let (1, 0, 0), (0, 1, 0) and (0, 0, 1) be represented by L1, L2, and 
L3, respectively. Then, according to Theorem 1-2.1, we test for linear 
independence by examining the possible sets of values Pi. p2, Pa which can 
satisfy 
(1-2.3 
This equation can be rewritten in the form 
(I-2.3b) 
f3i(l, 0, 0) + p2(0, 1, 0) + Pa(O, 0, 1) = (0, 0, 0), 
which, according to the defining properties of n-tuples, reduces to 
(l-2.3c) 

26 
THE ALGEBRA OF VECTORS 
Since (1-2.3c) constitutes a unique set of values for {31, {32, {33, the n-tuples 
L1, L2, and L3 form a linearly independent set. 
The preceding theorem indicates that in Euclidean three-space a linearly 
independent set of n-tuples can have at least three members. The next 
theorem establishes the fact that this number is maximum. 
Theorem 1-2.4. 
In a three-dimensional Euclidean space any set of four 
n-tuples is linearly dependent. 
PROOF. 
Let the n-tuples be represented by the symbols Ai. · 
· 
· , A4• 
In order to test for linear dependence or independence, we can assume 
that the n-tuples (i.e., their components) are known and determine the 
possible sets of ({31, • • 
·
,
 {34) such that ( l-2.1) is satisfied. The object is to 
show that at least one set, the elements of which are not all zero, exists. 
The form [see (1-2.1)] 
(1-2.4a) {31(Ai1, A12, A13) + {32(Al, A22, A23) + {33(Aa1, A32, A33) 
+ f3iAl, A42, A43) = (0, 0, 0) 
is equivalent to the set of linear equations 
f31Ai1 + f32Al + f3aAa1 + {3,Al = 0, 
(1-2.4b) 
f31A12 + f32A22 + f3sAa2 + {34A,2 
= 0, 
f31A13 + f32A23 + f3aAa3 + {3,Al = 0. 
We employ an inductive process to show that this set of equations has 
nontrivial solutions. Consider one linear equation in two unknowns: 
(1-2.4c) 
If A11 and Al are different from zero, we may choose an arbitrary nonzero 
value for {32 and then solve for {31. If one of A11 and Al is zero but not 
both, say Al = 0 for the sake of argument, then we can choose {31 = 0 
and {32 arbitrarily. If A11 = A21 = 0, then both {31 and {32 can be chosen 
arbitrarily; therefore one equation in two unknowns always has non­
trivial solutions. Next consider two equations in three unknowns: 
f31A11 + f32Al + f3aAa1 = 0, 
(1-2.4d) 
f31Al + f32A22 + {33A23 
= 0. 
If Al = Al = A31 
= 0, then {31, {32, and {33 can be chosen to satisfy the 
second equation and the values will automatically satisfy the first equation. 
Assume that one of these components is nonzero, say A31; then 
(l-2.4e) 

Independence of a set of n-tuples 
27 
When {33 is replaced in the second equation by this expression, we obtain 
the single equation in two unknowns, 
(1-2.4f) 
(A81A12 - A11A82)p1 + (As1A12 - A,,1A32)#2 = 0. 
We have seen that this expression has nontrivial solutions. Any solution 
({31, {32) of this equation determines a value for {33 according to (l-2.4e). 
Therefore we have established that a set of two equations in three un­
knowns has nontrivial solutions. The argument must be carried one 
step further to show that the equations in (l-2.4b) have nonzero solutions. 
We leave this task to the reader.17 
The thoughtful student will find it of interest to prove the following two 
statements which are obvious generalizations of Theorems 1-2.3 and 1-2.4, 
respectively. 
(1-2.Sa) 
There are at least n linearly independent n-tuples in an n­
dimensional Euclidean space. 
(1-2.Sb) 
In an n-dimensional Euclidean space any set of n + 1 n-tuples 
is dependent. 
The set of n-tuples L1, L2, L3, with components (1, 0, 0), (0, 1, 0), (0, 0, 1), 
respectively, will play an important part in the sequel. A typical geometric 
representation of the triple has each initial point at the origin. The com­
ponents are also coordinates of the end points. For future applications it 
is important to realize that the triad may be placed at arty other point of 
space. (See Fig. 1-2.1.) 
xa 
x2 
Fig. 1-2.1 
11 This theorem also may be proved by the method of proof used in Theorem 1-2.6. 

28 
THE ALGEBRA OF VECTORS 
Since Li. L2, and L3 form a linearly independent set of n-tuples, it is 
impossible to represent one of them as a linear combination of the other 
two. 
However, according to Theorem 1-2.4, L1, L2, L3, along with any 
fourth n-tuple of the space, determine a linearly dependent !let; 
and 
therein lies their merit. 
Example 1-2.1. 
Let A be an arbitrary n-tuple in Euclidean three-space. 
Consider 
(l-2.6a) 
where ()(1, ()(2, ()(3 are real numbers yet to be determined. By putting (1-2.6a) 
in the equivalent form, 
(l-2.6b) 
it is immediately observed that 
that is, when an n-tuple A is expressed in terms of the set L1, L2, and L3, 
the coefficients are the components of A. Therefore 
(l-2.6c) 
Furthermore, the n-tuples Li. L2, and L3 are represented by mutually per­
pendicular unit (magnitude I) arrows, as can be seen from geometric 
inspection. These properties further enhance their value for the expression 
of concepts of n-tuple algebra. 
So far in this section no methods other than employment of basic 
definition have been introduced for determining whether a given set of 
n-tuples is dependent. 
The next objective is the development of these 
methods. 
The statement of the next theorem can be made more conveniently if 
the concept of the rank of a matrix 
(A1 
A2 
Aa) 
B
i 
B
2 
Ba 
of numbers is first introduced.18 This is done by means of the following 
definition. 
18 A matrix is simply a rectangular array of numbers. A limited discussion of the 
algebra of matrices and the correlation of matrix concepts with vector concepts appears 
in Section 8. 

Independence of a set of n-tuples 
29 
Definition 1-2.2. 
Consider the three second-order determinants, 
I 
A1 
A2 I· 
BI 
B2 
I 
A1 A3 I· 
Bi 
Ba 
I 
A2 As I· 
B2 
Ba 
associated with the matrix (A1 
A2 
Aa)
· 
Bi 
B2 
Ba 
The rank of the matrix is 
(a) 2 if at least one of the second-order determinants is different from 
zero, 
(b) 1 if at least one element of the array has a value different from zero 
but each second-order determinant has value zero, 
(c) 0 if every element of the matrix has value zero. 
Theorem 1-2.5. 
In a Euclidean three-space a set of two n-tuples A, B is 
linearly dependent if and only if (A1 
A2 Aa) 
rank 
< 2. 
BI B2 Ba 
PROOF. 
If A and B are dependent, 
(l-2.7a) 
1X(A1, A2, Aa) + {3(B1, B2, B3) = (0, 0, 0), 
where not both IX and {3 are zero; (l-2.7a) is equivalent to 
1XA1 + {3B1 = 0, 
(l-2.7b) 
1XA2 + {3B2 = 0, 
1XA3 + {3B3 = 0. 
If any second-order determinant were different from zero, say, for the 
purpose of illustration, 
I 
A1 B1 I 
 0, 
A2 B2 
the pair of equations (1-2.7b) with these coefficients could be satisfied only 
by IX = {3 = 0. But this is contrary to hypothesis. 
Conversely, if the rank of the matrix is less than 2, the fact that the 
second-order determinants have value zero leads to 
(l-2.7c) 
A1B2 - A2B1 = 0, 
A1B3 - A3B1 = 0, 
or 
(1-2.7d) 

30 
THE ALGEBRA OF VECTORS 
that is 
(1-2. 7e) 
Hence A and B are dependent. It is left to the reader to comment on the 
situation in which B1B2B3 = 0. 
Example 1-2.2. 
Let 
then 
A= 2l1 
+ 3l2, 
B = l1 - l2; 
I: 
-'I= 
-
5  0. 
Therefore the arrows A and B are linearly independent. 
Theorem 1-2.6. 
In Euclidean three-space a set of three n-tuples A, B, C 
is linearly dependent if and only if 
(1-2.8) 
A1 A2 Aa 
B1 B2 
Ba = 0. 
cl c2 ea 
PROOF. 
If A, B, and C are linearly dependent, then, according to 
Definition 1-2.la, there are ix, {J, y, not all zero, such that ixA + {JB + 
yC = 0. For the purpose of illustration assume that ix  
O; then 
A1 = 
- ! ({JB1 + yC1), 
IX 
(1.2-9a) 
A2 = 
- ! ({JB2 + yC2), 
IX 
As= 
- ! ({JBa + yes). 
IX 
According to (I-2.9a), one row of the determinant of components is a 
linear combination of the other two; therefore 
(l-2.9b) 
as was to be shown. 
A1 A2 As 
B1 
B2 
B3 = 0, 
. cl 
c2 ea 
Conversely, if (l-2.9b) holds the set of equations 
(l-2.9c) ix(A1, A2, A3) + {J(B1, B2, B3) + y(C1, C2, C3) = (0, 0, 0) 

Independence of a set of n-tuples 
31 
is satisfied by 
(1-2.9d) 
I 
Bz IJ3 I 
ex== 
c2 
cs ' 
I 
Az 
A3 I 
f3 == 
-
c2 
cs , 
=I 
A2 
A I· 
y 
B2 
Bs 
This fact is easily verified by direct substitution. 
The determinants of 
(l-2.9d) are cofactors19 of the elements of the first column of (1-2.9b). 
The cofactors of elements of any other column· might have been chosen, 
and indeed might have to be chosen, if all of those in (l-2.9d) turn out to 
be of value zero. If all cofactors are zero, the n-tuples must be checked 
for dependence in pairs. (See Theorem 1-2.5.) 
Example 1-2.3. 
Let 
then 
A = 2L1 -
L2 + 3L3, 
B = 
L1 -
5L2 + 2L3, 
C = 5L1 - l6L2 + 9L3; 
2 
-1 
3 
1 
-5 
2 = 0. 
5 
-16 
9 
Therefore the given n-tuples are linearly dependent. Geometrically, this 
means that all three arrow representatives are parallel to a common plane. 
If the n-tuples are dependent in pairs, the arrow representatives are 
parallel to a common line. 
Example 1-2.4. 
It is not too difficult to choose a triple of linearly 
independent n-tuples. For example, 
satisfy this criterion, since 
A== Li + 3L2, 
B == 2L1 + 5L2, 
C= Ls 
1 
3 
0 
2 
5 
0 = 
- 1 :;I:. 0. 
0 
0 
1 
Since any four n-tuples are dependent, an arbitrary n-tuple B can be 
expressed in terms of any set of three linearly independent n-tuples, 
11 A cofactor differs from a minor at most by sign. 

32 
THE ALGEBRA OF VECTORS 
A1, A2, A3• This statement is easily verified by writing 
(1-2.10) 
(B1, B2, B3) = f31(A11, A12, A13) + f32(A21, A22, A23) + f3s(Aa1, Aa2, Aa3). 
Since Ah A2, A3 are linearly independent, 
A11 A2 
1 
A1s 
A/ A22 A2a 
 0. 
Aa1 A2 
3 
Aaa 
Therefore the nonhomogeneous system of three equations in three un­
knowns fJi. {32, {33, implied by (1-2.10), has a unique set of solutions. 
The fact that an arbitrary n-tuple in three-dimensional space can be 
represented in terms of any linearly independent set of three n-tuples leads 
to the following definition. 
Definition 1-2.3. 
An n-tuple basis in a three-dimensional Euclidean 
space is constituted by any set of three linearly independent n-tuples. 
A particularly valuable basis is the set '1' i2, i3• Its usefulness will be 
demonstrated in many future situations. 
Example 1-2.5. 
The representation 
r = r0 + Bt 
x3 
x2 
xi 
Fig. 1-2.2 

Problems 
33 
of a line was introduced in Example 1-1.3. Let r1 be an arrow with its 
initial point at the origin and its end point at a position P1 on the line. 
(See Fig. 1-2.2.) Specifically, take B = 11 - 10• The preceding representa­
tion then has the form 
(l-2. 11) 
l = (1 - t)10+ t11• 
If lo and 11 are linearly independent n-tuples, they determine a two­
dimensional basis. The fact that the end point of l generates a line and 
not a two-space is a consequence of the condition on the coefficients; 
that is, if p and q represent the coefficients of 10 and 11, then p + q = 1 for 
all t. (See Problem 8d.) 
Problems 
1. Show 
that the n-tuples A 
= 2L1 + L2 - 51.a, B 
= 3L1 + 2L2 + 1.a. 
and 
C 
= L1 - 11 La are linearly dependent. 
2. Prove that the three n-tuples 2L1 + 3L2, 5L1, and 2L3 are linearly inde­
pendent. 
3. Show 
that the n-tuples A 
= L1 + 3L2 + 3t.a, B 
= 2L1 + L2 - 31.od, 
and 
C 
= L1 + 5L2 - L3 are linearly independent. 
4. Show that 
(a) (1, 5, 7) and (-3, 
- 15, -21) are linearly dependent n-tuples; 
(b) (2, -3, 6) and (1, 4, 7) are linearly independent n-tuples. 
5. Suppose that each of the arrows A(l , -3, 5), B(2, 4, 7), and C(l, 6, 4) has 
its initial point at the origin. Are they coplanar? 
6. (a) Arrow representatives of combinations of the linearly independent 
n-tuples A and B satisfy the triangle relationship indicated by the 
accompanying diagram. Find x and y. 
z:2s'· 
3.xA + 2ya 
(b) Three forces acting at a point of a bridge are expressed in terms of 
linearly independent n-tuples A and B as follows (no other forces act 
at this point): 
2pA + qB, 
qA - 5pB, 
3A - 2B. 
What must the values of p and q be in order to put this point of the 
bridge in equilibrium? 

34 
THE ALGEBRA OF VECTORS 
(c) Arrow representatives of combinations of the linearly independent 
n-tuples A, 8, and C satisfy the relation indicated in the accom­
panying diagram. Find x, y, and z. 
7. (a) An n-tuple C has two representations in terms of the linearly inde­
pendent pair A, 8. 
C = (X - 3)A - Y8, 
C = - YA - (X + 2)8 
Find Xand Y. 
(b) Let a triangle be determined by the end points of the linearly inde­
pendent arrows r1, r2, and r3, each of which has its initial point at 
the origin. Show :that the medians of this triangle intersect at the end 
point of !{r1 + r2 + r3) if the initial point of this arrow is taken to be 
the origin. 
(c) Prove that the diagonals of a parallelogram bisect one another. 
8. (a) Suppose the line of Example 1-2.5 contains the origin; what can be 
said about the n-tuples r1 and r0? 
(b) Assume that the representation in (1-2.11) corresponds to Fig. 1-2.2. 
Denote the end point of r by P. For what values oft is P to the left of 
P0; between P0 and P1; to the right of P1? 
(c) Obtain the midpoint formulas 
from (1-2.11). 
X,/ 
= f(Xo1 + X11) 
Xv2 
= f(Xo2 + X12) 
xvs = f(Xoa + Xia) 
(d) Prove: A necessary and sufficient condition that three points P0, P1, 
P2 be collinear is that 
p + q = 1, 

Transformation equations 
35 
where r0, rh r2 are arrows with initial points fixed at the origin and 
end points at P0, PI> P2, respectively. 
9. Prove: A necessary and sufficient condition that four points be coplanar is 
that 
r1 = pr2 + qr3 + sr4, 
p + q + s = 1, 
where r1, r2, r3, and r, are arrows with their initial points at the origin. 
10. Complete the proof of Theorem 1-2.1. 
11. Express A as a linear combination of B, C, and D if the components of the 
n-tuples are (1, 3, 5), (O, 2, 1), (-2, 1, 4) and (1, 3, 2), respectively. 
12. (a) Is the set consisting of one n-tuple, A 1 0, linearly dependent or 
independent ? 
(b) Show that any set of n-tuples containing the zero n-tuple is a linearly 
dependent set. 
13. A variable X has all but a finite number of reals as its domain. How is 
linear independence involved in expressing (3X + 2)/(X - 2)(X - 5) as a 
sum of fractions A/(X - 2) + B/(X - 5)? 
14. Prove statements 1-2.5a and 1-2.5b. Hint: Use the method of mathematical 
induction to prove 1-2.5b. 
3. Transformation Equations Relating Rectangular 
Cartesian Coordinate Systems 
A rectangular Cartesian coordinate system imposes a one-to-one cor­
respondence between the points of Euclidean three-space and the set of all 
ordered triples of real numbers. A second rectangular Cartesian system 
brings about another correspondence. The purpose of this section is to 
investigate the nature of those transformations that relate such coordinate 
representations of the three-space. 
We shall find that the desired transformations are special types of linear 
transformations; 
that is, they are expressed by means of first-degree 
equations. Linear transformations have an origin that predates the formal 
development of coordinate systems. Francois Viete (1540-1603, French) 
solved quadric, cubic, and quartic equations by a process that made use of 
linear transformations. 
Felix Klein's (1849-1925) famous "Erlanger 
Programm" of 1872 firmly established their importance in the area of 
geometry, for the essence of his program was to classify geometries by 
means of their invariants with respect to given groups of linear transforma­
tions. 
The transformation idea has more than historical interest. 
It plays a 
major role in the present-day study of physical laws. In fact, the use of 
vector analysis as a descriptive language for physical sciences is largely 

36 
THE ALGEBRA OF VECTORS 
based on the invariant -properties of vector relations under certain types 
of transformations. 
The specific transformations studied in this section are called transla­
tions and rotations. It is of some philosophic interest to note that although 
the names connote motion there is, in fact, none. This imposition made 
by the English language on our thought processes probably does no harm 
and has certain intuitional advantages. 
Recall that in Section 1 a Cartesian vector was defined as a collection of 
n-tuples (one n-tuple associated with each rectangular Cartesian coordinate 
system) with any two of its elements related by transformation equations. 
These transformation equations have not yet been specified. However, 
the results of this section make it possible to introduce them. 
Since more than one coordinate system is involved in the considerations 
that follow, we shall begin to employ the term "Cartesian vector," but 
it is convenient and also appropriate to use the word "arrow" to point out 
a geometric property. 
Certain algebraic preliminaries are necessary. The notations and con­
ventions, here introduced, are fundamental throughout the book. 
Definition 1-3.1. 
An arrow is called a position arrow if and only if the 
initial point is fixed at the origin of coordinates. The symbols r, r0, r1, etc., 
are used to denote these arrows. 20 
Since the initial point of r is at the origin of coordinates, the coordinates 
(X1, X2, X3) of the end point are simultaneously components of the arrow 
(i.e., of the n-tuple which the arrow represents). Therefore 
(1-3.1) 
3 
r = X1L1 + X2L2 + X3L3 = ! X1L;. 
i=l 
The summation sign used in (1-3.1) is not really essential; that is, we 
might just as well use the repetition of the index j as a means of indicating 
summation. 
Such is the viewpoint of the so-called Einstein convention 
traditionally used in tensor analysis. This notational concept is precisely 
stated here and is used throughout the book. 
Convention 1-3.1. 
Whenever the same index symbol appears in a term 
of an algebraic expression both as a subscript and a superscript, the 
expression is to be summed over the range of that index, called a dummy 
index. 
20 It will be seen that the property of the initial point of an arrow, being at the origin 
of coordinates, is not maintained under translations. Since the property is not inde­
pendent of the coordinate system, there is no Cartesian vector, that is, class of triples, 
by means of which it can be expressed. For this reason we refrain from using the term 
"position vector" found in most elementary texts on vector analysis. 

Transformation equations 
37 
With Convention 1-3.l in mind, the relation (1-3.1) can be expressed in 
the form 
(l-3.2) 
lr= X\.I 
The so-called Kronecker delta, {J/, named after the German mathe­
matician L. Kronecker (1823-1891), is another notational device that is 
both simple and useful. 
Definition 1-3.2. 
The Kronecker delta is denoted by the symbol {J/ and 
has numerical values 
(1-3.3) 
{J/ = 
if 
J 
• 
{o {"-:;t:.k 
1 
j = k 
Both symbols, {J;k and (Jik, are used with the same meariing as the Kronecker 
delta; that is, if j = k, the value of either symbol is one, whereas, if j -:;t:. k, 
the value of either symbol is zero. 
Example 1-3.1. 
The Kronecker delta is a set of nine numbers (in three­
space). When written out as a square matrix, 
(1-3.4) 
({J/ {Jl 2 {Jl 3) ( 
1 
0 0) 
{J/ {J2 2 {J2 
3 = 0 
1 
0 
. 
(J31 {J3 2 {J3 3 
0 
0 
1 
The relation (1-3.4) is understood by equating corresponding elements. 
A shorthand for the left side of (1-3.4) is ( {Jl), where the lower index repre­
sents the row of the matrix and the upper index represents the column. 
Example 1-3.2. 
If i ranges over the values 1, 2, 3, 
{J/ = {J.1 + {J22 + {Ja3 
= 3. 
Example 1-3.3. 
If i and j range over the values 1, 2, 3, 
(1-3.5a) 
x; 
= a/ Xi 
represents a set of three equations with three terms in each right-hand 
member; that is, the set 
(l-3.5b) 
x1 = a.1x1 + alx2 + aa1xa, 
x2 = a.2x1 + a22x2 + a32xa, 
xa = a.sx1 + a2sx2 + aasxs. 
As previously stated, the index i in (1-3.5a) is a dummy index and could 
be replaced by any other letter except j. Also note that j can be replaced 
by any other letter except i. In other words, 
(l-3.5c) 
X11 = a/Xi 

38 
THE ALGEBRA OF VECTORS 
is equivalent to {l-3.Sa). An index such as j in (l-3.5a), which distin­
guishes between the equations of the set, is called a free index. 
Sets of 
equations expressed in the index notation have a consistency with respect 
to the position of an index which is valuable for purposes of checking 
the accuracy of the set. For example, as in {l-3.5c}, a free index appears 
in the same position in every term of the relation. 
Although the summation convention is simply stated, it can give some 
concern to the beginning student. 
The following examples may be of 
assistance in assimilating the idea. 
Example 1-3.4. 
If i and j have the range 1, 2, 
O;;bii = 01;b1; + a2;b2; = oubn + a12b12 + 021b21 + a22b22. 
Note that whether the summation on i or j is carried out first does not 
matter. It is important to realize that i and j are dummy indices and may 
be replaced by any other two distinct letters; that is, 
Example 1-3.5. 
If p and q range over the values l, 2, 3, the expression 
oJPQ represents a sum of nine terms. 
apqbpq 
= oubn + a1)12 + 01sb1s + 021b21 + 02)22 
+ o2sb2s + Oa1bs1 + 03)s2 + 033b33. 
Note that we would never write o;;b;; because the nature of the summations 
in such an expression is not well defined; that is, we must denote different 
index summations by different letters. 
The first set of transformation equations to be introduced relates the 
coordinates {X1, X2, X3) and (X1, X2, X3) of two rectangular Cartesian 
systems whose corresponding axes are parallel. (See Fig. 1-3.1.) These 
are called equations of translation. 
The Cartesian vector concept is 
employed in obtaining them. 
Theorem 1-3.1. 
Let (X1, X2,X3) and (X1, X2,X3), respectively, represent 
coordinates of rectangular Cartesian coordinate systems, the axes of which 
are parallel. The sets of coordinates are related by means of the trans­
formation equations 
(1-3.6) 
where {X01, X02, X03) represent the unbarred coordinates of the origin of 
the barred system. 
PROOF. 
In Fig. 1-3.1 the arrows r, r0, and f can be associated with 
the unbarred system. 
According to the parallelogram law of addition 

Transformation equations 
39 
Fig. 1-3.1 
(i.e., the law of addition of n-tuples), 
(1-3.7a) 
i' = r - r0• 
On the one hand, i', thought of as a Cartesian vector, has an n-tuple 
representation in the barred system (i.e., X\ X2, X3). Because the axes 
of the two systems are parallel, these same symbols represent the com­
ponents of f in the unbarred system. 
Therefore, either directly from 
(1-3.7a) or from the equivalent n-tuple form, 
we obtain the transformation equations (1-3.6). 
Example 1-3.6. 
A sphere of radius 2 and with center at (I, 2, 3), when 
referred to a coordinate system X1, X2, X3, is algebraically represented by 
the equation 
( l-3.8a) 
(X1 - 1)2 + (X2 - 2)2 + (X3 - 3)2 = 4. 
If a second rectangular Cartesian coordinate system, denoted by a bar, is 
introduced such that 
(1-3.Sb) 
X1 = x1 - 1, 
x2=x2-2, 
X3= X3
- 3, 

40 
THE ALGEBRA OF VECTORS 
then, with respect to this system, the equation of the sphere is 
(X1)2 + (X2)2 + (Xa)2 = 4. 
(See Fig. 1-3.2.) 
The equations of translation are a simple sort, yet they hold an impor­
tant place in the history of classical mechanics and of relativistic mechanics. 
More information on this point appears in Chapter 2. 
xa 
xi 
Fig. 1-3.2 
Let us turn our attention to a discussion of transformations relating 
coordinates X; and X; of rectangular Cartesian systems with a common 
origin. Such transformations are called rotations. 
Theorem 1-3.2. 
The ordered triples (X1, X2, X3) and (X1, X2, X3) 
associated with rectangular Cartesian coordinate systems having a 
common origin and such that there is no change of unit distance along 
coordinate axes are related by the transformation equations 
(l-3.9a) 
where the coefficients of transformation ak; are direction cosines satisfying 
the conditions 
(l-3.9b) 
3 
! a/a/= bkv· 
i=l 

Transformation equations 
41 
PROOF. 
Let i; represent a set of unit orthogonal basis arrows, associated 
with the barred system in the same way as the set L; is associated with the 
unbarred system. 
We interpret r and i' as symbols for n-tuples in the 
respective systems, but as representatives of the same Cartesian vector. 
Furthermore, the barred basis arrows ii. i2, i3, when considered as Car­
tesian vectors, have representations in terms of the unbarred basis 'i. L2, 'a· 
x2 
Fig. 1-3.3 
Therefore the relation r = i' or 
(1-3.10) 
has a significance in a single coordinate system. This fact enables us to 
employ the algebraic properties of n-tuples. Of course, a double interpre­
tation of the symbols Xk is involved. On the one hand they are thought 
of as coordinates in the barred system, and on the other they are considered 
as numbers somehow associated with the unbarred system. 
The next step toward obtaining the relations (1-3.9a) is to express the 
ik in terms of the i1• In particular, consider i1• Since i1 is of length one, its 
projections in the directions of Li. i2, L3 can be represented by the cosines 
of the angles made by i1 with L1, L2, L3, respectively. Let ai1, a12, 0t13 

42 
THE ALGEBRA OF VECTORS 
represent the angles made by i1 with L1, L2, and L3, respectively. Further· 
more, let 
al= cos rx./ 
Then 
i1 = a11L1 + a12L2 + a1aLa = a1iL1· 
If, in general, the angle21 from 'i to ik is designated by rx.1/ and 
(1-3.1 la) 
a/ = cos rxk1, 
then 
(1-3.l lb) 
Lk = a/L;. 
When (1-3.11 b) is substituted into (1-3.10), we obtain 
X1L1 = Xkak1L1, 
(X1 - a/ Xk)L; = 0. 
Since the arrow set L1 is linearly independent, the result is (1-3.9a). 
The relation (1-3.9b) follows from the solid analytic geometry formula 
for the angle between two directions. The formula, as expressed in terms of 
direction cosines, is 
8 
(1-3.12) 
cos()= I a/a,/. 
i-1 
If k = p, then, of course, ik and ij') coincide and cos 0 = 1. If k  p, 
then ik and ij') are orthogonal and cos TT/2 = 0. 
This completes the 
proof. 
Those students who are not familiar with (1-3.12) may defer its con­
sideration until Section 5 has been studied. 
The formula is actually 
developed there. 
The significance of the conditions (1-3.9b) can be made more distinct 
by writing out the coefficients of transformation in the form of a square 
matrix. 
(1-3.13) 
(a/ a12 a18) 
(ak;) = aa1 a22 a2a 
. 
al aa2 aa3 
According to {l-3.9b), the sum of the squares of the elements of any row 
is one, whereas the sum of products of corresponding elements of different­
rows is zero. 
With a square matrix of numbers, such as (1-3.13), we can associate a 
determinant. 
For notational convenience we denote the value of the 
determinant of (a/) by a. The next theorem evaluates this determinant. 
91 The angle ix/ should be thought of as formed by the positive senses of it and l1 
and measured from l1 to ik. However, it should be noted that cosine is an even function, 
and therefore the direction of measurement of the angle is not algebraically significant. 

Transformation equations 
43 
Theorem 1-3.3. 
We have 
(1-3.14) 
a2 = 1. 
PROOF. 
Consider (l-3.9b). 
The determinant of (dkp) is one. 
The 
determinant of the left-hand side of(l-3.9b) is a2• This proves the theorem. 
No doubt some of the readers of this book have not been exposed to 
determinant multiplication, hence do not realize that the determinant of 
the left-hand side of ( l-3.9b) is as indicated. I refer them to Section 6 
in which the fundamental ideas concerning determinants are reviewed 
and elaborated. 
The determinant theory to be developed in Section 6 will enable us to 
see that our previous restriction to a single type of coordinate system 
(right-handed) requires that 
( 1-3.15) 
a= 1. 
It will also be determined that a = -1 if and only if i1, i2, i8 have an 
orientation corresponding to an odd permutation of L1' L2, L3• 
Since a ;Il!: 0, the linear equations in (1-3.9a) can be solved; that is, 
inverse transformation equations can be obtained by a straightforward 
application of determinants (Cramer's rule). The procedure is facilitated 
by means of the following definition. 
Definition 1-3.3. 
Let 
(1-3.16) 
A1
k =
cofactor of a/ in det (a/) .22 
a 
As an immediate consequence of definition (1-3.3), we have 
(1-3.17) 
(a) A/akP = d/, 
(b) A/a,/= d/. 
It need be observed only that (1-3. l 7a, b) represent expansions of the 
determinant of (a/) around a given column (row) so that we obtain the 
determinant divided by itself (i.e., I) or a determinant with repeated 
a,' 
a,1 
a,
s 
a,' 
a,• 
a.
• 
as' 
as
' 
as• 
I 
a.2 
a.
' I· 
I 
a,
· 
a,
· I· 
I 
a,
· 
a,• , 
are 
a,2 
aa' 
a.a 
aa• 
a.• 
a,• 
The cofactor of al is the second-order determinant, obtained by striking out the jth 
row and kth column, multiplied by (-l)IH, 

44 
THE ALGEBRA OF VECTORS 
columns (rows). This statement is illustrated in detail in the following 
example. 
Example 1-3.7. 
Choose j = p = 1 in (1-3.17a). Then 
a/ 
a12 
a1
a 
a2
1 
a2
2 
a2
a 
= 
a/ 
aa
2 
aa
a 
=G=l. 
a 
a 
On the other hand, if we choose j = 1, p = 2, 
a12 
a12 
a 
a 
1 
a2
2 
a.,,,2 
a2
a 
aa
2 
aa
2 
aa
a 
0 
= 
=-
a 
a 
The reader not familiar with the relation (1-3.17a) should experiment with 
other examples. 
The algebraic facility that evolves from the relation (l-3.17b) is demon­
strated in the next theorem in which transformation equations inverse to 
those of (1-3.9a) are obtained. 
Theorem 1-3.4. 
The set of transformation equations inverse to (l-3.9a) 
lS 
(1-3.18) 
XP = A/Xi. 
PROOF. 
According to (1-3.9a), 

Transformation equations 
45 
If the three equations of this set are multiplied by A1P, A2P, A3P and the 
resultant expressions are added [for the sake of brevity we say that (l-3.9a) 
is multiplied and summed with A/], then 
A/X; = A/alXk = {JkPXk = XP. 
The last two members of this equation were obtained by making use of 
relation (1-3.17b) and the definition of the Kronecker delta. 
This com­
pletes the proof. 
Before turning attention to examples of rotational transformations, it is 
worthwhile to establish the following algebraic properties of the coeffi­
cients of transformation. 
Theorem 1-3.S. 
The set of inverse transformation coefficients A/ is 
obtained from the set a., q by interchanging rows and columns of the 
matrix; that is, 
(1-3.19) 
PROOF. 
According to (l-3. 17a), 
A/akP = /J/. 
If this set of relations is multiplied and summed with a/, then 
By making use of (l-3.9b) on the left and the definition of the Kronecker 
delta on the right, we obtain the result 
or 
A/= a/, 
as was to be proved. 
The orthogonality conditions (l-3.9b) hold for columns of the matrix 
of coefficients as well as for rows. This fact is demonstrated in the next 
theorem. 
Theorem 1-3.6. 
We have 
(1-3.20) 
3 
L a/a;k = (Jok. 
i=l 
PROOF. 
According to (1-3. 19), 
Ak; =a/, 

46 
THE ALGEBRA OF VECTORS 
Multiply and sum this relation with a/. Then 
3 
a aA i - "a aa k 
j
k - k
i i • 
i=l 
From (1-3. I 7a) it follows that a/ Al = bk a; therefore the proof is complete. 
The reader should observe that the relation (1-3.19) implies that the 
A1k satisfy the same orthogonality conditions as the a/, The algebraic 
properties of the coefficients of transformation may be summed up as 
follows: 
3 
(a) 2 a/a/ = bik• 
,,=l 
(c) 
a= 1, 
3. 
{l-3.21) 
(e) 2 A/A/= 61k, 
,,=l 
(g) A = 1. 
(1-3.2Ih) 
A/a/= 6/, 
(b) 
(d) 
(f) 
3 
2 a ia k = bik 
" 
" 
' 
,,-1 
A/= a/, 
3 
2 A iA k = tJik 
" 
" 
' 
,,-1 
Akia/ = bka· 
The orthogonality of the transformations (as well as preservation of the 
unit of length) can be characterized by (l-3.2la). As indicated previously, 
( l-3.21c) is an assumed condition that restricts the set of coordinate 
systems to the right-handed type (or to the left-handed type). The other 
relations which are not purely algebraic in nature follow from these. 
Note that relations (1-3.2lh) are purely algebraic; that is, they are a con­
sequence of the definition of the A/ and have nothing to do with the fact 
that transformations of rotation are under discussion. 
The significance of the conditions (1-3.21) is further illustrated by the 
following example. 
Example 1-3.8. 
The matrix of coefficients 
'.f 3 
1 
2 
2 
(1-3.22a) 
(a/)= ..)3 
-3 
-
4 
4 
1 
-..)3 
4 
4 
satisfy the conditions in (l-3.2Ia, b, c), hence are valid coefficients of 
transformation relating two right-handed rectangular Cartesian coordinate 
systems. [Note that (I-3.2lb) is a consequence of (I-3.2la).] To see that 
these conditions are met, the reader must notice that the sum of squares 

Transformation equations 
47 
of any row (column) is one; the sum of products of corresponding ele­
ments of different rows (columns) is zero, and the value of the deter­
minant of coefficients is one. 
Similar remarks hold for the inverse 
transformation coefficients: 
'.j3 .j3 
1 
2 
4 
4 
(1-3.22b) 
(A/)= 
1 
-3 -.j3 
-
2 
4 
4 
0 
1 
-.j3 
2 
2 
Quite legitimately we might wonder how the set of coefficients (1-3.22a) 
is obtained. This question is considered in Section 8, where a simple 
method for generating sets of three-space transformation coefficients is 
introduced. The following example is pertinent to that method. 
Example 1-3.9. 
Rotations in a plane, say the X1, X2 plane, are special 
types of three-space rotations. Therefore the appropriate equations of 
transformation should be contained in our general results. The equations 
of rotation result from (l-3.9a) by noting that Li. L2, and L3, respectively, 
make angles of 71'/2, 7r/2, and 0 with i8. Since cos 7r/2 = 0, cos 0 = I, 
(l-3.9a) reduces to 
(l-3.23a) 
x1 = a11g1 + al..¥2 
x2 = a12g1 + a22g2 
xs= xs. 
I 
I 
x2 
/ 
/ 
I 
Fig. 1-3.4 
:x1 
/ 
/ 

48 
THE ALGEBRA OF VECTORS 
If the angle of rotation is denoted by (), where () is measured from X1 to 
X1, then 
(l-3.23b) 
a/ =COS (i1, L1) =COS (), 
a12 =cos (i1, L2) =cos ( - ()) =sin 0, 
a21 = cos (i2, L1) = cos ( + ()) = -sin 0, 
a22 = COS (i2, L2) = COS 0. 
Therefore (1-3.23a) can be put in the form 
(1-3.23c) 
X1 = cos () x• - sin () X2, 
X2 = sin () x· + cos () X2• 
Intuitively, we can think of a counterclockwise rotation from X1 to X1• 
Using the relation Al = ak1, we determine that the inverse transforma­
tion equations are 
(1-3.23d) 
X1 = cos OX1 + sin OX2, 
X2 = -sin OX1 + cos OX2• 
This rotation can be considered as clockwise from Xi to X1• 
Example 1-3.10. 
As a simple illustration of a transformation of 
rotation in the X1,X2 plane, let () = 7r/6. Then (l-3.23c) takes the form 
x• = .J3 x• -  .x2 
2 
2 
' 
x2 =  x• + .J3 .x2. 
2 
2 
Often the algebraic representation of a geometric configuration is much 
simpler when referred to a particular cooi:-dinate system. 
Consider a 
hyperbola which when referred to the coordinates X1, X2 has the equation 
(X1)2 + 2.J3xi x2 - (X2)2 = 2. 
When expressed in terms of the barred system of coordinates, the equation 
of the hyperbola is of the simpler form, 
(X1)2 _ (X2)2 = t. 
Problems 
l. This problem deals with notational concepts. We define 
6:,'1) = 6/6/, 
6J:'IJ] = ![<5:.'1) - 6f.k]. 
The first expression is a generalization of the Kronecker 6, whereas the 
second symbolizes a particular combination of such generalized entities 
represented by means of a bracket notation. 

Problems 
49 
(a) If the indicesj, s, k, pare placeholders for 1, 2, 3, how many elements 
are in the set {JJ,v ? 
(b) What numerical values do these elements take on? 
(c) Evaluate /jJ:vJ for all possible sets of values j, s, k, p. 
(d) Show that (jlkvJ = -{i[vkJ 
:is 
:Is 
• 
(e) Show that {JJ:vl = {Jf11, where the brackets about j, s imply 
(jfts 1 = tw.v - (j:n. 
2. (a) Evaluate {J/ (jkP ():Pi where j, k, p take on values I, 2, 3. 
(b) Write out the equation {J;;Xi x:1 
= 0. 
i,j 
= 1, 2, 3. 
3. The equation of a sphere in a given rectangular Cartesian coordinate 
system is 
(X1)2 + (X2)2 + (X3)2 - 6X1 + 2x2 - 8X3 + 25 
= o. 
How is this coordinate system related to one with corresponding axes 
parallel and origin at the center of the sphere? 
4. Give an example of a transformation relating a left-hand and a right-hand 
rectangular Cartesian system (i.e., an inversion) and therefore such that 
a= -1. 
5. Illustrate the validity of(l-3.17b); that is, A/aa:i = {Jl, by writing out the 
details for two or three choices of q and k. 
6. Show that the determinant of coefficients ak:i of the transformation equations 
(l-3.9a) can be expressed in terms of partial derivatives as follows: 
ax1 
ax2 
axs 
ax1 
ax1 
ax1 
I ax:1 I = 
ax1 
ax2 
axs 
axk 
ax2 
ax2 
ax2 
ax1 
ax2 
ax8 
aX3 
aX3 
aX3 
7. Consider a transformation of rotation in the X1,X2 plane. Using the equa­
tions in (1-3.23c), find the Xi coordinates of a point whose Xi coordinates 
are (2, 3, 0) when (a) 8 = Tr/4, (b) 8 
= Tr/3. 
8. · (a) Show that the following matrix of numbers satisfies the conditions in 
(1-3.2la, b, c). 
-1 
-1 
-1 
2 
2 
v2 
1 
1 
-1 
-
2 
2 
v2 
1 
-1 
v2 v2 
0 

50 
THE ALGEBRA OF VECTORS 
(b) If the matrix in (a) is considered as a set of coefficients of a rectangular 
Cartesian transformation, find the set of inverse transformation 
coefficients. 
(c) If the Xi coordinates of a point are (1, -2, 3), find the Xi coordinates, 
given that the transformation coefficients al are those of (a). 
9. Suppose that a set of transformation coefficients is given by 
(a) Show that a = 1. 
(b) Find (A/). 
(a/)= 
2 
v'3 
2 
0 
-v'3 
2 
0 
2 
0 
0 
(c) Describe the transformation. 
10. (a) Show that the algebraic form 
3 
! (X.1 - Xoi)2, 
j=l 
representing the square of the distance determined by two points P0 
and P1, is invariant (i.e., remains unchanged) under rectangular· 
Cartesian transformations. 
(b) Suppose that X1 = 4X1, X2 = 4%2, X3 = 4%3; then show that the 
forms 
3 
! (X1i - X0i)2 and 
j=l 
are not equal. Suppose that the X i  coordinate system is rectangular 
Cartesian. Is the Xi system rectangular Cartesian? Why is such a 
transformation excluded from the set of orthogonal Cartesian rota­
tions? 
(c) Assume that X1 
= 4X1, X2 = 3X2, X3 = 2X3• Is the form 
3 
! (X1' - Xoi)2 
j=l 
invariant with respect to this transformation? 
11. Parametric equations of a line are of the form (see Example 1-1.3) 
Xi = X/ + B't. 
Suppose that Bi 
= X'i - X11 (X11, X2i are coordinates of points on the 
line) and t is unchanged by a coordinate transformation. Show that the 
algebraic form of the parametric equations of a line is unchanged by an 
orthogonal Cartesian transformation (i.e., a translation or rotation). 

Definition of Cartesian scalar and vector 
S 1 
4. Definition of Cartesian Scalar and Vector 
A Cartesian vector was initially defined in terms of the set of all rec­
tangular Cartesian coordinate systems. A law of transformation relating 
the vector components in any pair of systems was alluded to but not 
specifically stated. It is the purpose of this section to supply a precise 
mode of transformation for the components of a Cartesian vector as well 
as to introduce the concept of a scalar, which is also dependent on a set of 
transformations. 
The terms vector and scalar are both due to W. R. Hamilton. Each 
constituted a part of his so-called quaternion, with neither having the 
stature of an entity in its own right. A significant measure of the credit 
for dissociating the vector and scalar concepts from the quaternion ideas 
and thereby putting them within a structure convenient to geometry and 
physics belongs to W. Gibbs. 
The definitions that follow specify the meanings of vector and scalar 
with respect to the set of transformations relating rectangular Cartesian 
coordinate systems.t These statements are formulated so that they will 
correlate with the usages of the terms vector and scalar when more general 
sets of transformations are involved. (See Section 5* .) 
In the following definition the symbol { U1, U2, U3} denotes the collection 
of ordered-number triples (U1, U2, U3), (0\ 02, us), etc; 
one triple is 
associated with each possible rectangular Cartesian coordinate system. 
Definition 1-4.1. 
A Cartesian vector is a collection {U1, U2, U3} of 
ordered triples, each associated with a rectangular Cartesian coordinate 
system and such that any two satisfy the transformation law 
(1-4.1) 
u1 = ax' uk 
axk 
· 
The triples (U1, U2, us) etc., are called components of the Cartesian vector 
in the respective coordinate systems. 
As stated in Section 1, it is notationally convenient to use the same 
boldface symbol U that previously has characterized an n-tuple (and the 
family of arrows geometrically representing the n-tuple). 
For a transformation of rotation, that is, X; = ak; Xk, the relation in 
(1-4.1) reduces to 
(1-4.2a) 
whereas for a translation, X1 = Xi + X0;, it takes the form 
( l-4.2b) 
t For clarity of presentation the definitions are phrased for the case n = 3. 

52 
THE ALGEBRA OF VECTORS 
It is worth noting that the components of a Cartesian vector transform 
under rotations as the coordinates transform. Furthermore, the collection 
of coordinate differences {Xi1 - X01} is a Cartesian vector, for when the 
relation in (l-3.9a), that is, 
is applied to the coordinates of P0 and P1, we have 
(1-4.3) 
The coordinate differences clearly satisfy ( l-4.2a). 
A corresponding 
verification of the statement for translations is left to the reader. 
We 
already know that a Cartesian vector can be represented geometrically by 
an arrow (any one of a family of arrows). 
The preceding statement 
establishes the fact that an arrow determined by a pair of points, P0 and 
Pi, gives rise to a Cartesian vector. 
( 
There is some need for caution, as pointed out by the following pair of 
theorems. 
Theorem 1-4.la. 
The concept of position arrow is not a vector concept 
with respect to the set of translations; that is, the components of two 
position arrows rand i' of systems X1 and X1, one translated from the other, 
are not related by the transformation law ( l-4.2b). 
PROOF. 
The proof consists of nothing more than writing down the 
transformation equations 
Xi = Xi + X/ 
Rather than being equal, the components ofr and f differ by the terms X0i. 
Theorem 1-4.lb. 
Suppose that the Xi and Xi systems are related by 
means of a rotation. The components (1 , 0, 0) of the basis arrow L1 are 
not related to the components (1, 0, 0) of the basis arrow i1 by means of the 
law (1-4.2a). 
PROOF. 
We have 
Therefore the components of i1 in the Xi system are (ai1, a12, a13). These 
coefficients of transformation in general do not take on values (1, 0, 0). 
If the components of a Cartesian vector are known in one coordinate 
system, then they can be found in any other coordinate system of the set. 
The procedure for doing so is illustrated in the next example. 
Example 1-4.1. 
Suppose that two coordinate systems X1 and X1 
are related by the transformation equations of Example 1-3.10. If the 

Definition of Cartesian scalar and vector 
53 
x2 
\ 
\ 
\ 
\ 
\ 
\ 
\ \ 
\ \ 
\ 
Fig. 1-4.1 
components of a vector U are (0, t) in the barred system, the components 
in the unbarred system are determined as follows (see Fig. 1-4.1): 
ui = y'3 (O) -! (!) = - ! , 
2 
2 2 
4 
u2 = ! (O) + y'3(!) = y'3. 
2 
2 
2 
4 
The vector concept received much of its early impetus from the theo­
retical physicist. Today it fittingly plays a fundamental role in many aspects 
of physics. Linear velocities, accelerations, and forces fit nicely into the 
vector pattern, as do electric- and magnetic-field strengths. Also, much 
of the vector terminology and structure has wandered far afield and is 
becoming more and more important in biological and social sciences. 
For example, hereditary patterns are studied with the aid of vectors and 
matrices, as are linear programming problems. 23 
A second concept which has evolved in the development of theoretical 
physics is that of the scalar. The definition of "scalar," which has come 
down from Hamilton, 24 states that it is a quantity possessing magnitude 
but no direction. Such entities as mass, time, density, and temperature 
are given as examples. 
However, the prize example is a real number. 
This definition will not satisfy our needs, but it is worth mentioning for 
two reasons. First of all, it is vague, as illustrated by the incorrect prize 
example. A real number does not have to be associated with magnitude. 
••An introduction to these ideas can be found in Kemeny, Snell, Thompson, Finite 
Mathematics, Prentice Hall, 1957. 
u See Gibbs's interpretation, Vector Analysis, Gibbs, Yale University Press, 1947. 

54 
THE ALGEBRA OF VECTORS 
It can be given no interpretation whatsoever, it can denote position, or it 
can distinguish one object from another as in an index. 
Secondly, the 
use of the word "scalar" to denote a real number, or more generally an 
element of a field underlying a vector space, has become prevalent in the 
area of algebra. 
It fits our purpose to use a definition of the term that is common to 
modern-day physics, differential geometry, and other fields in which 
transformation theory plays a prominent part. From a historical point of 
view this approach, which specifies a scalar as any quantity invariant 
under all transformations of coordinates, can be found in the texts of 
Felix Klein.2s The definition is now stated formally. The symbol {<I>} 
denotes a collection of functions, one associated with each rectangular 
Cartesian coordinate system. 
Definition 1-4.2. 
If the elements of {<I>} satisfy the relation 
(1-4.4) 
then the collection {<I>} is called a Cartesian scalar with respect to the 
rectangular Cartesian set of transformations. The functions <I>, ii>, etc., 
represent the scalar in their respective coordinate systems. 
Under this definition such a phenomenon as temperature, which is a 
function of position and not dependent on the coordinate representation 
of that position, can be thought of as a numerical scalar. Other entities, 
such as the magnitude of a vector, have an additional property in that the 
form of their algebraic representation is the same in all coordinate systems 
of a given collection. These entities are said to be invariants. 
Example 1-4.2. 
Suppose that a function f has a domain consisting of 
all triples (X\ X2, X3) that satisfy the relation (X1)2 + (X2)2 + (X3)2=1; 
that is, the ordered triples of the domain correspond to the points of the 
unit sphere. 
If the rule for the function is f (X1 X2 X3) = In r (where 
r = [(XI)2 + (X2)2 + (X3)2]). then this function is a scalar representa­
tive with respect to the group of orthogonal Cartesian rotations. Further­
more, the function has an invariant algebraic form, since 
under all rotations. 
There are many physical ideas that can be represented by the scalar 
concept. For example, electrostatic or magnetostatic potential has scalar 
u Klein, op. cit., p. 47. 

Problems 
55 
representations in terms of integrals containing functions that are pro­
portional to l/r. The very useful innovation of the physicist called "work" 
is also of scalar character. 
In the next section more information of a positive nature concerning 
scalars is discussed, but, before going on, there are a few negative bits of 
information that have some interest. 
Example 1-4.3. 
The components of a Cartesian vector do not repi:.esent 
Cartesian scalars with respect to the rotation transformations in (l.gs.9a). 
This statement follows at once from the fact that the vector components 
satisfy the transformation law 
u; =a/Ok. 
This law is not of the form of(l-4.4). Problem 3b at the end of this section 
deals with the nature of vector components with respect to the set of 
translations. 
Example 1-4.4. 
The distance formula 
(Xi1 - Xo1)2 + (X12 - Xo2)2 + (Xia - Xos)2 
is an invariant with respect to the transformations (l-3.9a, b). 
Problems 
1. The components Ok of a vector in an Xk coordinate system are (!, 0, 0). 
The coefficients of an orthogonal Cartesian rotation relating the Xk and 
Xk systems are 
(0 -1 
(al)= 
1 0 
0 0 
(a) Compute the components Uk. 
(b) Construct the two coordinate systems and a representation of the 
vector. 
2. The components Ok of a vector with respect to an Xk coordinate system are 
(0, 1, 3). Coefficients of an orthogonal Cartesian rotation relating the 
J(k and Xk systems are 
v3 
2 
2 0 
(al)= 
v3 
3 
1 
4 
4 
2 
I 
v3 
v3 
4 
4 
2 
Compute the Uk components of the vector. 

56 
THE ALGEBRA OF VECTORS 
3. (a) Show that distance is a scalar quantity with respect to translations. 
(b) Show that the components of a vector are scalars with respect to trans­
lation. 
4. Suppose the n-tuple representatives pi and Q1 of vectors P and Q are linearly 
dependent; then show that the representatives Pk and Qk in a second 
rectangular Cartesian coordinate system are dependent. Note that this 
result justifies speaking of linearly dependent Cartesian vectors and 
associating the results of Section 2 with them. 
5. The Inner Product 
Many of the concepts studied in a course concerning vector and tensor 
algebra have resulted from fundamental ideas of Hamilton and Grassmann. 
As we pointed out in the historical introduction, these ideas have been 
subject to so much sifting, sorting, and adding that it is difficult to assign 
individual credit for them. 
However, one concept which specifically 
resulted from the ingenuity of Hermann Grassmann is used to introduce 
a second type of vector binary operation. (Addition constituted the first 
type.) 
This process has intimate ties with real-number multiplication. 
In analogy to the procedure of Grassmann, consider two three-space 
Cartesian vectors, each expressed in terms of a basis LI> L2, L3; that is, 
P = P1L1 + P2L2 + P3L3 and Q = Q1L1 + Q2L2 + Q3L3• 
When nai'vely 
multiplied together, 
(1-5.la) PQ = P1Q1L1L1 + P1Q2L1L2 + P1Q3L1L3 + P2Q1L2L1 + P2Q2L2L2 
+ P2Q3L2L3 + P3Q1L3L1 + P3Q2L3L2 + P3Q3L3L3. 
The expression (1-5.la) has no preassigned significance. In fact, a variety 
of binary operations can be specified, each depending on the meaning 
assigned to the nine quantities L;Lk,j, k = 1, 2, 3. 
We introduce a binary operation for a pair of Cartesian vectors P and 
Q, symbolized by 
(1-5.lb) 
P • Q = PiQkL; • Lk, 
in the following definition. 
Definition 1-5.1. 
Let 
(1-5.2) 
We specify that O;k has either the value 7T/2 or 0 and is determined by the 
positive senses of L; and L,. 
As a consequence of this definition, relation (1-5.lb) takes the form 
(I-5.3) 
p. Q = piQk/Jik = p1Q1 + p2Q2 + paQs. 

The inner product 
57 
Because of the notation employed, P · Q is often called the "dot" product 
of P and Q. The term "inner product" is also commonly associated with 
the expression. 
A common practice, when building a mathematical structure, is to look 
toward the set of real numbers for comparison and analogy; that is, we 
ask whether a newly introduced operation satisfies the same laws as a 
corresponding real-number operation. The following theorem points out 
that the inner product conforms to several basic rules of real numbers. 
Theorem 1-S.1. 
The fundamental properties of the inner product are 
the following: 
(1-5.4a) (Commutative law) 
P · Q = Q · P. 
(1-5.4b) (Associative law with respect to a real number) 
(ixP) • Q = ix(P • Q). 
(l-5.4c) 
(Distributive law) 
p -(Q + R) = p. Q + p. R. 
(l-5.4d) (Positive de.finite property) 
P · P  O; 
P · P = 0 	 P = 0. 
PROOF. 
The proofs are left to the reader. The first three follow from 
the definitions of inner product, vector or n-tuple addition, and corre­
sponding properties of real numbers. The proof of (1-5.4d) is trivial with 
respect to the form (1-5.3), since a sum of real-number squares can never 
be negative. 
Note that the inner product of two vectors is not a vector. This is 
described by saying that the operation is not closed. 
The next matter to come under discussion is the behavior of the inner 
product when subjected to transformations of the orthogonal Cartesian 
set. Of course, the symbol P · Q is only a notation for the inner product 
of two vectors P and Q. To investigate the way in which this product 
transforms, we must concentrate attention on the right-hand side of 
(I-5.3). 
3 
Theorem 1-S.2. 
The form 2, p; Q; is an invariant Cartesian scalar. 
[See (l-3.9a) and (l-3.9b).] 
i=l 
PROOF. 
By making use of (l-3.9a) and (l-3.9b), the transformation can 
be carried out as follows: 
3 
8 
3 
2, p;Q; 
= 2, (a/1'')(a/Q") = 2, a/a/r%· 
i=l 
;-1 
i=l 
a 
= b,,P•Q• = 2, PkQk. 
kl 
The last member of the string of equalities results when the meaning of the 
delta symbol is invoked. The proof for translations is trivial. 

58 
THE ALGEBRA OF VECTORS 
In the exercises at the end of the section the reader is asked to show that 
the form (l-5.4b) is not preserved under linear transformations whose 
coefficients do not satisfy the orthogonality conditions in (l-3.9b). This 
illustrates the fact that whether a given algebraic form is invariant depends 
on the group of transformations under consideration. 
The availability of the dot product greatly enhances the procedure for 
exhibiting various geometric concepts in Euclidean three-space. (This 
statement is even more significant for n > 3.) Magnitude and angle are 
fundamental to the metric structure of Euclidean space. These concepts 
are dealt with in the following theorems. 
Theorem 1-S.3. 
The magnitude of a Cartesian vector P is represented 
by the Cartesian scalar {IPI}, where 
(l-5.5) IPI = (P. P)'A = [(Pl)2 + (P2)2 + (P3)2]!.-i = (6;kpipk)'A. 
PROOF. 
The magnitude of a Cartesian vector is expressed in any given 
coordinate system by the representation (1-l.5b), that is J'i:. P1P1• In 
3 
Theorem 1-5.2 it was shown that! P1P1 was a scalar representative; hence 
j=l 
('£. P1P1)1A is a scalar representative. The expression 61kpipk is just another 
3 
notation for !,P'Pi. 
j=l 
If IPI = 1, then P is said to be a unit Cartesian vector. 
The foregoing has been introduced in a manner analogous to the pro­
cedure of Grassmann in order to emphasize that the inner product is only 
one of a possible variety of binary operations. Indeed, another binary 
operation is presented in Section 7. In Gibbs's development of vector 
analysis a geometric form of the scalar product is given. This form, 
(1-5.6a) 
P · Q = IPI IQI cos 8, 
was suggested by physical applications, such as the concept of work, and 
geometric considerations, for example, that of the angle between two 
directions. In the next theorem we verify that the representation (l-5.6a) 
is consistent. 
Theorem 1-S.4. P · Q and IPI IQI cos() are equivalent relations; that is, 
8 
(1-5.6b) 
! P1Q1 = IPI IQI cos 8, 
i=l 
where () is the angle measured from P to Q and such that 0  ()  TT. 
PROOF. 
As a matter of convenience, choose geometric representatives 
of P and Q with their initial points at the origin of coordinates. (See 

The inner product 
59 
Fig. 1-S.1 
Fig. 1-5.1 .) According to the law of cosines, 
(l-5.7a) 
IQ - Pl2 = IPl2 + IQl2 - 2 IPI IQI cos 0. 
This relation can also be expressed in the form 
By writing out the summation in the left member of (l-5.7b) the reader 
can verify that a usual multiplication of the parenthetic expressions, 
followed by a distribution of b1k, is valid. Therefore 
(l-5.7c) 
tJ,kQiQk - 2tJ,,;>iQk + tJ,,;>1pk 
= tJ,kp1pk + fl1kQiQk - 2 IPI IQI cos o. 
Subtracting the appropriate terms from each member and then dividing 
by -2, we obtain 
(l-5.7d) 
Since (l-5.7d) is equivalent to (l-5.6b), the proof is complete. 
By making the association IPl(IQI cos 0) in the right member of 
(l-5.6) we are able to interpret the inner product geometrically as the 
magnitude of P multiplied by the perpendicular projection of Q on P 
taken with the appropriate sign. Of course, P and Q can be interchanged 
in this statement. The interchange would correspond to the association 
IQl(IPI cos 0). 

60 
THE ALGEBRA OF VECTORS 
It is worthy of notice that the relation (1-5.6) should not be new to the 
reader. When written in terms of the components of P and Q, 
plQl + p2Q2 + p8Q3 
(1-5.8) 
cos() = 
------=---'-::._;.._-=-----., 
[(P1)2 + (P2)2 + (p3)2f . .J[(Q1)2 + (Q2)2 + (Qs)2]  
This expression is recognizable as the formula for the angle made by two 
directions, usually presented in a development of solid analytic geometry. 
Other representations of geometric concepts and entities in Euclidean 
three-space depend in a large measure on the relationship between the 
A 
Fig. 1-5.2 
inner product and the ideas of distance 
and angle. The following theorems and 
examples draw attention to some of the 
elementary ideas and configurations. 
Theorem 1-5.5. 
If P and Q are non­
zero vectors, 
(1-5.9) 
P • Q = 0  P and 
Q are orthogonal. 
PROOF. 
From (1-5.6) it follows that, 
if () = TT/2, then P • Q = 0, and con­
versely. 
Example 1-5.la. 
An equation of a 
plane can be obtained by making use of 
the characterization of orthogonality 
stated in Theorem 1-5.5. Take (as in 
Fig. (1-5.2) the geometric representation 
of a fixed vector A whose initial point 
has coordinates X0i. Then the end point of a position vector r, subject to 
the condition, 
(1-5.lOa) 
A • (r - r0) = 0, 
generates a configuration in space, which we call a plane. Note that the 
equation of a plane can be put in the expanded form 
(1-5.lOb) 
A1(X1 - X01) + A2(X2 - X02) + A3(X3 - X03) = 0. 
Another notational form for the equation of a plane, which is sometimes 
useful, is 
(1-5.lOc) 

The inner product 
61 
Example 1-5.lb. 
The plane through (2, 1, 5) and perpendicular to the 
vector A= 3L1 + 5L2 - L3 has the equation 
3(X1 
- 2) + 5(X2 - 1) - l(X3 - 5) = 0. 
Of course, this equation can also be put in the form 
3X1 + 5x2 - X3 = 6. 
An interesting formula for the perpendicular distance between a plane 
and a point follows from writing the equation of the plane in "Hesse's 
normal form" ;26 that is, in the form 
(1-5.11) 
A 
-
• (r - r0) = 0. 
IAI 
The word "normalized" implies, as indicated in (1-5.11), that the direction 
perpendicular to the plane has been expressed in terms of a vector of 
magnitude l, that is, A/IAI. 
Theorem 1-5.6. 
The perpendicular distance D, determined by a point 
with coordinates X1i and a plane with the equation (1-5.11 ), is 
(1-5.12) 
D = I lI • (r1 - r0) I· 
PROOF. 
Let the components of C be given by the coordinate differences 
(I-5.13) 
C1 = X/- X{ 
From the geometric interpretation of the inner product it follows that 
D =I proj. ConM I =I IC! cos Oj. 
!Al 
x/ 
Fig.1-5.3 
11 The form was named after the German mathematician Otto Hesse (1811-1874). 

62 
THE ALGEBRA OF VECTORS 
Since 
it follows that 
A 
C 
cos()= -
·-
IAI ICI' 
D 
= lll·CI. 
The relation (1-5.1) is obtained when C is replaced by r1 - r0, a sub­
stitution justified by ( 1-5.13). 
Example 1-5.2. 
If the point with coordinates (2, 5, 1) and the plane 
whose equation is 3(X1 - 2) + 2(X2 - 1) - 5(X3 + 2) 
= 0 are given, 
the perpendicular distance (1-5.12) is 
D = 1 3(2 - 2) + 2(5 - 1) - 5(1 + 2) I 
= 1- 7 1 = 
7 
. 
9 + 4 + 25 
38 
38 
Example 1-5.3. 
Another common geometric configuration with a 
simple vector representation is the sphere. 
A sphere is geometrically 
defined as the set of all points equidistant from a fixed point. If, as in 
Fig. 1-5.4, the fixed point has coordinates X0; and the radius of tbe sphere 
is denoted by a, then r - r0 is a vector of constant magnitude a. 
The 
algebraic representation of the sphere is 
(I-5.14a) 
I 
I 
I 
x• 
I 
I 
xa 
I 
I 
I 
I 
Fig.1-5.4 

This representation can also be put in the form 
(l-5.14b) 
Problems 
1. Suppose A = 3L1 + 2L2 - 5L3, B = 2L1 - 79 + 4L3• 
(a) Compute A · B, A · A, and B · B. 
Problems 
63 
(b) Determine a unit vector with the sense and direction of A. 
(c) Determine the angle 0 8 8 8TT made by A and B. 
2. Does the relation (1-5.3) in any way define A· B · C? Explain. 
3. Suppose that the coordinates X; and X; of two rectangular Cartesian systems 
are related by means of the transformation equations X; = ak; Xk, where 
v'3 
1 
2 
2 
0 
(ak;) = 
-1 v'3 
2 
2 
0 
0 
0 
(a) Describe the rotation. 
(b) If A = 3i1 + Si2, n = 2i1 - 4i2, find A· Ii. 
(c) Find A and B. 
(d) Compute A· B. 
3 
Remark. Since ! A;B; is an invariant with respect to orthogonal 
j=l 
Cartesian transformations, the result of (d) is known from (b). The 
purpose of the problem is to illustrate this scalar relation through 
numerical calculation. 
4. Perform the tasks analogous to (b), (c), and (d) of Problem 3 if A and B have 
components 1, 3, 5 and -2, 3, 4, respectively, and 
v'3 v'3 
2 
4 
4 
(A/)= 
-3 
-v'3 
2 
4 
4 
-v'3 
0 
2 
2 
5. Show that A = 2L1 - 3L2 + L3 and B = 5L1 + 2L2 - 4L3 are orthogonal. 
6. Suppose that an object is moving along a straight line a distance lr1 - r01 
with a direction and sense corresponding to the vector r1 - r0• Let F 
represent a constant force acting on the object. If the "work" done by 

64 
THE ALGEBRA OF VECTORS 
this force is defined as 
W = F · (r1 - r0), 
(a) when is there no work done? 
(b) Make an analysis of the way in which the work done varies with the 
direction and sense of F. 
7. (a) Show that the diagonals of a square are perpendicular by showing that 
E1 • E2 = 0. (See the accompanying figure.) 
(b) Show that the diagonals of a rhombus are perpendicular. (A rhombus is 
a four-sided polygon, all sides of which are equal in length.) 
8. (a) A line passes through the point (1, -3, 2) and has the direction of 
B 
= 2 L1 - 5 L2 - 4 L3• 
What are the parametric and symmetric 
representations of the line? 
(b) Find the parametric representation of the line in an g; coordinate 
system related to the X; system of (a) by means of the transformation 
equations 
where 
-1 
-1 
-1 
2 
2 
v2 
1 
-1 
(Ak;) 
= 
2 
2 
v2 
1 
-1 
v2 
v2 
0 
9. Show that the two lines with parametric representations 
x1 = s + 21 
x1 
= 2 - 6s 
X2 
= 3 + 1t 
and X2 
= 4 + 2s 
X3 = 2 - 4t 
X3 = 6 + !s, 
respectively, are perpendicular. 
10. What is a necessary and sufficient condition that two lines with vector repre­
sentations r = r1 + B1t and r = r2 + B:tl", respectively, be (a) parallel, 
(b) perpendicular? 

General Cartesian cordinates 
65 
11. (a) What is an equation of the plane through ( -2 , 4, 1) and perpendicular 
to A = 3t1 + ti - 5t3? 
(b) Find the equation of this plane in the Xi system of Problem Sb. 
12. Find a necessary and sufficient condition that two planes be parallel. 
13. What is the meaning of the statement: two planes are perpendicular? 
(Refer to a text on solid analytic geometry.) 
14. Prove that A/IAI is a unit vector. A 'JI: O. 
15. Finj 
the perpendicular distance 
between the 
plane with equation 
2(X1 - 3) - S(X2 + 1) + 3(X3 - 4) = 0 and the point (1, 2, -1). 
16. Is the algebraic representation of a line dependent on a coordinate system? 
17. Show that the angle IJ determined by two vectors P and Q satisfies 
• 2 
_ (P · P)(Q • Q) - (P · Q)2 
sm IJ -
(P • P)(Q. Q) 
• 
18. Find components of a vector C perpendicular to linearly independent 
vectors P and Q. 
Hint: Solve the equations P · C 
= 0 and Q • C 
= 0. 
S*. General Cartesian Coordinates 
Historical perspective on the significance of linear transformations in 
geometry can be obtained from an examination of Felix Klein's "Erlanger 
Programm" of 1872, mentioned in Section 3. This program,27 which was 
inspired by the work of Arthur Cayley (1821-1895, English), defines a 
geometry as a theory of the invariants of a transformation group.18 
From this viewpoint, projective geometry, which was suggested by Cayley 
as the universal geometry, is characterized by the set of transformations 
xi = a1X1 + a2X2 + a3X3 + a, 
d1X1 + d2X2 + daX3 + d, ' 
xz = b1X1 + b2X2 + b3X8 + b, 
e1X1 + e2X2 + e8X3 + e4 ' 
.f8 = C1X1 + c2X2 + c8X3 + c, 
/1X1 + f2X" + /sX8 + f, . 
Incidence relations are among the invariants of this group of transforma­
tions. 
17 Klein, op. cit., 130. 
11 See Definition 1-5*.3. 

66 
THE ALGEBRA OF VECTORS 
Affine geometry29 consists of the study of the invariants of a subset of 
the foregoing transformation relations; that is , 
X1 = a1X1 + a2X2 + a3X3 + a4, 
X2 = b1X1 + b2X2 + b3X3 + b4, 
X3 = c1X1 + c2X2 + c3X3 + C4• 
A significant aspect of affine geometry is its inclusion of the parallel concept 
which plays no part in the more general projective geometry. 
When orthogonality conditions (1-3.21) are imposed on the coefficients 
(a1 
a2 
as) 
bi 
b2 
ba 
' 
C1 
C2 
C3 
the transformations characterize Euclidean metric geometry. Sometimes 
the orthogonality conditions are slightly relaxed to enable inclusion of the 
transformations that change size but do not destroy proportionalities; 
that is, 
Under this circumstance the transformations characterizing Euclidean 
metric geometry are called similarity transformations. 
If a4 = b4 = c4 = 0, the affine transformations leave the origin of 
coordinates fixed and are called centered affine transformations. This is 
the set with which we shall be concerned. 
The centered affine transformations form a transformation group. 
The meaning of the term group is indicated by the next definition. 
Definition 1-5* .1. 
A set of transformations R, S, T, · 
· 
· is said to form 
a group if the following properties hold: 
(a) (Closure) 
Two successive transformations of the set result in a 
transformation of the set. 
(b) (Associative law) 
(RS)Ty1 = R(ST)y1. 
(c) (Existence of an identity element). 
The transformation I with co­
efficients b/ is an element of the set of transformations. 
(d) (Existence of a unique inverse to each transformation of the set). 
To 
each transformation T of the set there is a unique transformation 
r-1 such that the coefficients of T followed by T-1 or r-1 followed 
by Tare (b/). 
21 The term affine apparently goes back to Euler and Mobius. 

General Cartesian cordinates 
67 
Theorem 1-S*.1. 
The centered affine transformations form a group. 
PROOF. 
Consider successive transformations 
(1-5* .la) 
We have 
(1-5*.lb) 
Denote the set of nine numbers represented by Ck0B/ by 
(1-5*. le) 
We have 
(1-5*.ld) 
If the determinant (D/) ':;6 0, the property of closure has been exhibited. 
The fact that D ':;6 0 follows from the knowledge that Band Care nonzero 
and that D represents the product of determinants B and C. (The student 
not familiar with determinant multiplication should see Section 6.) 
To consider the associative property, make use of the relations in 
(1-5*.la) along with a third transformation 
yr= D/yo. 
Then 
y' = (D/Ck0)B/yi = D/(C1/B/)y1 
represents a statement of the associative law. That the law holds is 
fundamentally a consequence of the associative and distributive laws of 
real numbers. This can be verified in the straightforward but tedious 
manner of writing out the summations. 
Since yi = {J/yk is a centered affine transformation, (c) holds. Finally, 
to each transformation gi = B/yk of the set there corresponds yk = b/gi 
such that 
Therefore (d) holds and the theorem is proved. 
The important ideas to be developed in this text could be stated without 
formally introducing the group concept. We might ask, then why intro­
duce it? There are at least two reasons. First of all the existence of a 
well-defined meaning of the term in the mind of the reader adds measurably 
to the fluency of communication. Second, the group concept has played 
such a fundamental role in mathematics, especially the ideas developed 

68 
THE ALGEBRA OF VECTORS 
in the nineteenth century, that the reader should be aware of its presence 
in this discussion. 
The seed of the group idea was planted by Lagrange (1736-1813, 
French) around 1770-1771. By critically examining solutions of equations 
of second, third, and fourth degree (with the purpose of extending his 
examination to equations of higher degree), he made a beginning in the 
theory of permutation groups. The term "group" is actually due to E. 
Galois (1811-1832, French), who was stimulated by interest in showing 
that equations of a degree higher than four could not in general be solved 
by radicals. The group concept entered into geometry principally through 
the writings of Sophus Lie (1842-1899, Norwegian) on continuous groups. 
It culminated in Klein's "Erlanger Programm," in which it was used to 
classify the geometries of that day. 
The properties (a)-(d), which characterize linear transformations as a 
group, have been pointed out. It is left to the reader to show that the 
orthogonal linear transformations, that is, those relating rectangular 
Cartesian coordinate systems, form a group contained in the linear group. 
The "Erlanger Programm," or the definition of a geometry as the set of 
invariants of a transformation group, is to be understood from the view­
point of space mappings; that is, if we think of a transformation as a 
replacement of a space by a new one, the question of finding those entities 
that have an absolute meaning is of prime significance. In this book we 
are interpreting the transformations differently. From our viewpoint the 
space is fixed (i.e., it is a Euclidean metric space), and the transformations 
simply bring about a change of coordinate system. From this standpoint 
we can employ the affine transformation equations when considering 
metric concepts. Of course, representations for distance or angle will not 
have an invariant algebraic form. 
In this section it is shown that the affine transformations relate Cartesian 
coordinate systems (i.e., systems determined by straight-line axes). 
In 
particular, the axes of these systems need not be perpendicular to one 
another. 
Representation of various concepts in the Cartesian systems 
will give us some direction as to which of the concepts considered in the 
framework of rectangular Cartesian systems should be generalized as well 
as how to bring about the generalizations. Moreover, the availability of 
Cartesian systems of reference will be valuable when considering the special 
theory of relativity in a later chapter. 
Perhaps the simplest way of assimilating new ideas is to look at special 
cases. The following example affords this opportunity. 
Example 1-5*.1. 
Let (X1, X2, X3) represent rectangular Cartesian co­
ordinates while the triple ( Y1, Y2, Y3) represents an arbitrary set of 

General Cartesian coordinates 
69 
Fig. 1-s•.1 
Cartesian coordinates. 
(See Fig. 1-5* .1.) 
Consider the linear transfor-
mation equations 
(1-5* .2a) 
Y1 = 2.J3x1 - 2X2, 
y2 = 
_ x1 + .J3x2, 
y3 = X3. 
It follows from these transformation equations that 
y1=0 
if and only if 2.J3xi - 2x2 = o, 
y2 = 0 
if and only if 
-X1 + .J3X2 = 0, 
ys = O 
if and only if X3= 0. 
Therefore Y1 = 0, Y2 = 0, Y3 = 0 can be identified with the coordinate 
planes 2.J?,xi - 2X2 = 0, - X1 + J3x2 = 0, and X3 = 0, respectively. 
The axes of the Yi system correspond to the lines of intersection of these 
planes. The fact that the plane Y3 = 0 corresponds to the plane X3 = 0 
simplifies matters. We are able to interpret the axes Y1 = 0 and Y2 = 0 
as lines in this common plane. Specifically Y2 = 0, that is, the Y1 axis, 
corresponds to the line -X1 + .J3x2 = 0 and the Y2 axis is incident with 
2.J3xi - 2x2 = o. 
Now let us investigate other aspects of this transformation. The matrix 
of coefficients of the transformation is 
(1-5*.2b) 
(2.J3 
(Bl) = 2 

70 
THE ALGEBRA OF VECTORS 
where as usual the lower index represents row and the upper index repre­
sents column. 
Note that the equations in (l-5*.2a) correspond to the 
form 
(1-5* .2c) 
The determinant of the transformation has the value 
(1-5*.2d) 
B= 4. 
Since this value is different from zero, we can obtain the inverse trans­
formation by use of Cramer's rule. More simply, the inverse transforma­
tion coefficients can be obtained from the definition 
(1-5*.3a) 
b 
.k = cofactor of B/ in det (B/) . 
' 
B 
As in Section 3, the definition implies the algebraic conditions 
(1-5*.3b) 
These relations are used freely throughout this section . 
.J3 
1 
0 
4 
4 
(b/) = 
1 
.J3 
(1-5*.3c) 
2 
2 
0 
0 
0 
1 
Note that 
(1-5*.3d) 
1 
b=-
4 
and therefore 
(1-5* .3e) 
Bb = 1. 
It will be seen that the fact that the product of the values of the determinant 
of transformation and its inverse equals one is a general property of 
transformations. 
It has been assumed that the space under consideration is a Euclidean 
metric space. We have defined a Cartesian vector as a collection of n­
tuples, one n-tuple associated with each rectangular Cartesian system, and 
we have taken a family of arrows as the geometric representative of the 
collection. The question that we pose for ourselves is that of extending the 
algebraic formulation of the vector concept to nonorthogonal Cartesian 
coordinate systems. We attack the problem by the consideration of bases 
that can be associated with these systems. A basis that occurs naturally is 

,, - I 
-
-
I 
_ ,,, 
I 
I 
I 
I 
I 
I 
x2 
I 
I 
General Cartesian cordinates 
71 
I 
y2 
I 
geometrically represented by arrows of fixed magnitude, direction, and 
sense along the coordinate axes. Let us examine the set of n-tuples Pi. p2, 
p3, given rise to by the relations 
(1-5* .4) 
With respect to the example under consideration [see (1-5* .3b)], we have 
(1-5* .5) 
.J3 
1 
P1 =-Li +-L2 
4 
4 
1 
.J3 
P2=-L1+-L2 
2 
2 
It is clear that these n-tuples can be represented along the Y1 and Y2 axes, 
since the lines corresponding to these axes have direction numbers ( J3, 1, 0) 
and (2, 2..)3, 0), respectively. (See Fig. 1-5* .2.) It is worth noting that 
the basis Pii introduced by (1-5* .5), is not composed of unit n-tuples. In 
particular, 
IP1I = t. 
In this example it does happen that p2 and p3 are of unit length. 
Before generalizing our observations and specifying the significance of 
introducing a basis as we have just done, it would be convenient to illustrate 
a second way of determining a basis. Suppose that the n-tuples p1, p2, p3 

72 
THE ALGEBRA OF VECTORS 
are given by the relations 
(1-5*.6) 
3 
pi= # Bkitk. 
k=l 
(The significance of the superscript notation 
Again, in terms of our example, we have 
is discussed presently.) 
p1 = 2J3t1 - 2t2 
(1-5* .7) 
P2 = -t1 + .J3t2. 
By straightforward computation, we find that the bases (1-5* .5) and 
(1-5*.7) satisfy the conditions (see Fig. 1-5*.2) 
(1-5* .8) 
that is, 
P; ·Pk= <J/; 
p1 is perpendicular to p2 and p3, 
p2 is perpendicular to p3 and p1, 
p3 is perpendicular to p1 and P2· 
This completes the example. 
The preceding example can be used as a guide to intuition as we proceed 
with a general development of vector concepts in Cartesian coordinates. 
Note that the linear transformations 
(a) 
y; = Bk; Xk, 
(b) 
Xk = b/Y;, 
(1-5* .9) 
BO, 
where the X1 are rectangular Cartesian coordinates, at once establish the 
fact that the Y1 system is Cartesian (i.e., referred to straight-line axes). 
For example, if Y1 = Y2 = 0, the conditions 
B/X1 + B/X2 + B31X3 = 0 
(1-5*.9c) 
B12x1 + B22x2 + Bs2X3 = 0. 
determine a set of points for which only Y3 varies. 
Since each of the 
equations represents a plane, the curve of intersection is a straight. line. 
The next theorem establishes the fact that an arbitrary pair of Cartesian 
coordinate systems is related by a linear transformation. 
Theorem 1-5* .2. 
The coordinates, y; and y;, of a pair of three-space 
Cartesian coordinate systems are related by linear transformations. 
PROOF. 
Let X1 represent rectangular Cartesian coordinates such that 
BO, 

General Cartesian coordinates 
73 
By a straightforward substitution 
y.1 = Bk;d,/Y0• 
The products Bk;d0k give rise to nine constant coefficients of transformation 
which are denoted by c/; that is, 
(1-5*.lOa) 
c/ = B/d/. 
When this notational substitution is made in the preceding relation, we 
have 
(1-5*.lOb) 
Since d  0 and B  0, the inverse transformation equations 
(1-5*.lOc) 
C/ = D,."b/ 
can be uniquely determined. Therefore c  0, which completes the proof. 
We are able to introduce a basis into a Cartesian coordinate system by 
means of the relation (1-5*.4); that is, 
(1-5*.lOd) 
For purposes of identification the basis introduced in this way is called a 
covariant basis. Incidentally, the reader should establish the fact that 
Pi. p2, p3 are linearly independent (see Problem 9); otherwise the term 
basis would be inappropriate. 
Theorem 1-5*.3. 
The covariant basis n-tuples p1 can be geometrically 
represented by arrows along the corresponding coordinate axes. 
PROOF. 
We have 
y; 
= BkiXk. 
If Y1 = Y2 = 0 and the conditions in (1-5* .9c) determining the Y3 axis 
are multiplied by B32 and Ba1, respectively, then subtracted, we have 
x1 
x2 
BIBS 
BllBl-BlBl 
BlB 2' 
3
2 - 8
2 
3
1 -
3
1 
A corresponding elimination of X2 when combined with the preceding 
result leads to the symmetric form of the rectangular Cartesian repre­
sentation of the Y3 axis; 
(1-5*.ll) 
xi 
xz 
xa 
= 
 
-(B81B22 -B82B.,.1) 
-(B32B/ - Ba1B12) --(B21B12 -B22B/). 
The direction numbers exhibited in (1-5*.11) are cofactors in the deter­
minant (B/') and therefore proportional to ba1, b81, baa· 
(See 1-5*.3a.) 

74 
THE ALGEBRA OF VECTORS 
Therefore 
Pa= bail; 
can be represented along the Y3 axis. The corresponding considerations 
for p1 and p2 are left to the reader. 
Theorem 1-S*.4. 
Covariant bases P; and p1, associated with Cartesian 
coordinate systems satisfying (I-5*. I Ob, c ), are related by 
(a) P; = C/Pq, 
(1-5*.12) 
(b) Pq = c/p1. 
PROOF. 
We have (see 1-5*.lOa and 1-5*.lOd) 
P; = b/Lk = b/DkqPq = C/pq. 
This completes the proof of (a); (b) is left to the reader. 
Following the procedure of the example, we introduce a second basis 
in a Cartesian system Yi by means of (1-5*.6); that is, 
3 
pi= I B/Lk. 
k=l 
This basis is called a contravariant basis. 
Consideration of the deter­
minant of the components Bk1 enables us to establish the linear independ­
ence of p1, p2, p3; therefore the term "basis" is justified. A procedure 
similar to that employed in the proof of Theorem 1-5*.3 leads to the 
relations 
(1-5*.13) 
(a) 
p1 = c/pq, 
(b) pq 
= C/p1• 
In the introductory example we were able to determine that the bases 
P; and pi were reciprocal by calculating the appropriate dot products. 
The next theorem exhibits the generality of this reciprocity. 
Theorem 1-S*.S. 
The covariant and contravariant bases, P; and pi, are 
reciprocal; that is, 
(1-5* .14) 
PROOF. 
The proof follows by employment of (1-5*.4) and (1-5*.6). 
We have 
8 
3 
P; ·Pk 
= b/Lq •I BrkLr = I b/B/tJqr = b{Brk 
= tJ/. 
r-1 
r=l 
If a basis Lb L2, Ls associated with a rectangular Cartesian system is 
considered, we find that it is self-reciprocal. In other words, a basis 11, 

General Cartesian cordinates 
7 5 
introduced according to (1-5* .14), that is, 
L;. Lk = d/', 
does not differ from the original basis L;. 
The determination of covariant and contravariant bases for general 
Cartesian systems makes possible a natural interpretation of the vector 
concept for those systems. 
We start with the definitions that follow. In the first it is assumed that 
triples of numbers (G1, G2, G3), (G1, G9, G3), etc., are specified in each 
Cartesian coordinate system. As before, the symbol {G1, G'', G3} denotes 
the collection of all such triples. 
Definition 1-5*.la. 
A contravariant vector is a collection {G1, G9, G3} of 
ordered triples, one triple associated with each Cartesian system, the 
elements of which satisfy the transformation law 
(1-5* 
.15a) 
G; = oY; 
(jk. 
aYk 
The triples (G1,.G2, G3) etc., are called the contravariant component^ of a 
contravariant vector in the respective coordinate systems. 
It is also assumed that ordered triples of functions (G1, G2, G8), 
( G1, G2, Ga) can be associated with the respective Cartesian systems. 
Definition 1-5*.lb. 
A covariant vector30 is a collection {G1, G2, Ga} of 
ordered triples, one triple associated with each Cartesian system, the 
elements of which satisfy the transformation law 
aYk 
(1-5*.15b) 
G; =
(]Yi Gk. 
The triples (Gl> G2, G3), etc., are called the covariant components of a 
covariant vector in the respective coordinate systems. 
The use of subscripts to denote covariant components is adhered to 
throughout the text. 
Since the laws of transformation of the coordinates are linear, that is, 
y1 = bkifk, 
fk= B/Yi, 
the sets of partial derivatives a Y1/ofk and ofk/oY1 are nothing more than 
the sets of constant coefficients b/ and B/', respectively. It should also 
be noted that the orthogonal Cartesian rotations are included as a sub­
group of the more general group of transformations now under con­
sideration. 
'° The terms contravariant, covariant, and invariant were introduced by the English 
mathematician James Joseph Sylvester (1814-1897). 

76 
THE ALGEBRA OF VECTORS 
The next two examples stipulate geometric interpretations of contra­
variant and covariant vectors and their components. 
Example 1-5* .2a. 
Let G1, G2, G3 be the components of a contravariant 
vector in a Cartesian coordinate system y;. 
Consider the form 3Ps· 
Transformation rules for the components 3 and the basis elements P; 
have been formulated so that the form is invariant; that is, by employing 
(1-5*.12) and (1-5*.15a) we obtain the relation 
(l•.5* .16a) 
In particular, with respect to a rectangular Cartesian system X1, we have 
(1-5*.16b) 
Gip1 = G1i1 =G. 
Therefore in a Euclidean metric space referred to affine coordinates the 
contravariant vector components can be interpreted as components of a 
Cartesian vector. This means that a geometric representation by means 
of an arrow (or family of arrows) is valid. We use this fact to find the 
geometric significance of the contravariant components with respect to 
a general Cartesian system. Suppose, for simplicity of geometric presenta­
tion, we consider a contravariant vector with components (G1, G2, O); 
then 
(1-5*.17a) 
The basis n-tuples p1 and p2 are not necessarily of unit magnitude. 
Therefore we replace (l-5*.17a) by 
(1-5*.17b) 
where p1 and p2 are of unit length. 
The fact that G1 IPil and G2 IP21 are measures of the parallel projections 
of the arrow representative of G on the Y1 and Y2 axes, respectively, 
follows immediately from the parallelogram law of addition. (See Fig. 
1-5*.3a.) If the units of measurement along each axis are specified by 
IPil and IP21, the components themselves, G1 and G2, represent parallel 
projections onto the Y1 and Y2 axes, respectively. 
The preceding geometric interpretation of contravariant vector com­
ponents is not dependent on two dimensions in any way; we let G3 = 0 
for simplicity of pictorial representation. 
81 A basis of unit n-tuples {i1, {i., tia is called a physical basis. If we make the identifica­
tions gi = IP1I G1, g1 = IP2I G1, g8 = IPal G8, then gi. g., and g8 are called physical 
components of the vector G. These physical components are geometrically represented 
by parallel projections on the coordinate axis and are often used in making physical 
interpretations. 

General Cartesian coordinates 
77 
y2 
PI 
Fig. 1-5*.3a 
Example 1-5*.2b. 
Suppose that Gl> G3, G3 are the components of a 
covariant vector. As a consequence of the transformation rules for G1 
and p1, we obtain the invariance of the form G1p1. The details are left to 
the reader. With respect to a rectangular Cartesian coordinate system, X'. 
8 
G1p1 = G1i.1 = !Gsi.1 = G; 
1-1 
that is, the contravariant basis in the rectangular system does not differ 
from the covariant basis. 
Therefore the components Gi are Cartesian 
vector components. 
The components of a covariant vector with respect to a general Cartesian 
coordinate system are readily interpreted by the arrow representation of 
the Cartesian vector G. Consider the form 
If we take a dot product of the relation with pk, 
(1-5*.18) 
Fig.1-5*.3b 

78 
THE ALGEBRA OF VECTORS 
In other words, the covariant components Gk are measures of the orthog­
onal projections of the arrow representative of G onto the coordinate 
axes when we measure in units of 1/lp1J, 1/Jp21 and 1/IP31, respectively. 
Geometric interpretations of contravariant and covariant vectors are 
usually given in terms of projections on the covariant-basis arrows, since 
the coordinate axes correspond to them in direction. However, a fully 
analogous interpretation could be given with respect to the contravariant 
basis by an interchange of the association of parallel and orthogonal 
projections. 
In a metric space (i.e., a space in which provision is made for measure­
ment of distance and angle) the concepts of contravariant vector and 
covariant vector are not completely distinct. 
A more detailed investigation of the relationship between contravariant 
and covariant entities is facilitated by the introduction of a matrix of 
numbers (h1J. Later it will be found that .the set h1k has profound geo­
metric significance. 
Definition 1-5* .3. 
Let 
(I-5*.19) 
The numbers h;k are easily expressed in terms of transformation co­
efficients relating the Cartesian coordinate system y; to a rectangular 
Cartesian system Xi. If 
we have 
that is, 
(1-5*.20a) 
3 
h;k = P; •Pk= b/lq • bkrlr = {Jqrb/bkr =I b/b,."; 
q-1 
Either from (1-5*.10) or (1-5*.20a) we can observe that the set h1,. is 
symmetric. In other words, 
(1-5*.20b) 
Example 1-5* .3. 
In Example 1-5* .1 the matrix of coefficients (bl) is 
specifically 
3 
1 
-
0 
4 
4 
(b/) = 
1 
3 
-
0 
2 
2 
0 
0 
1 

General Cartesian coordinates 
79 
Therefore the matrix of h;k is 
1 
,J3 
-
0 
4 
4 
(h;k) = 
v3 
4 
0 
0 
0 
1 
The numbers h;k provide the algebraic link between the covariant and 
contravariant bases. The linear relation between the two is stipulated in 
the next theorem. 
Theorem 1-5* .6. 
We have 
(1-5*.21) 
PROOF. 
According to (1-5*.14), 
P1 ·Pk = bk;· 
Multiplying and summing each side of this expression with ha; leads to 
(l-5*.22a) 
or 
(1-5* .22b) 
The set of Cartesian vectors Pk is a linearly independent set. Therefore 
not all three of P1> p2, p3 can be perpendicular to the expression in paren­
theses. We must conclude that 
ha; - Pa= 0. 
This completes the proof. 
By introducing a set of numbers inverse to the set h;k we obtain a com­
plete reciprocity. 
Definition 1-5*.4. 
The numbers h;k satisfy the relation 
(1-5*.23) 
Theorem 1-5* .7. 
We have 
(1-5*.24) 
PROOF. 
Multiply and sum both members of (l-5*.21) with h'"; then 
h""Pa = h'"ha;P; 
= b/ = p'
. 
This completes the proof. 

80 
THE ALGEBRA OF VECTORS 
In a Euclidean metric space covariant and contravariant vectors are 
not completely independent of one another. Every covariant vector gives 
rise to a contravariant vector and conversely. Corresponding covariant 
and contravariant vectors are equivalent to the same Cartesian vector. 
Suppose that G1, G2, G3 are the components of a contravariant vector. 
Then 
G = G1p1 
represents a Cartesian vector referred to the covariant basis p1• 
The 
reciprocal or contravariant basis pk can be introduced as indicated by 
(1-5*.21). We then have 
G = Gih1kPk· 
This relation points out that linear combinations, G1h1k, of the components 
of the contravariant vector serve as components of a covariant vector. 
We formalize this fact by denoting the combinations with the same symbol 
G; that is, 
(1-5* .25a) 
Note that it does not matter whether we write h1k or hki• since the set is 
symmetric. 
A process of multiplying and summing {l-5* .25a) along with the use 
of (1-5* .23) produces the form 
(1-5* .25b) 
G' = h1kGk. 
From this form it is inferred that each covariant vector gives rise to a 
contravariant vector. 
In the terminology usually employed in tensor 
analysis the components h1k and h1k are said to lower and raise indices, 
respectively. The precise meaning of this terminology, for example, with 
respect to (1-5* .25a), is that linear combinations of the contra variant 
components G1 are replaced by the covariant symbols Gk and that the 
coefficients of the linear combinations are the hkJ· 
A Cartesian vector G can be written in either of the forms 
G = Gip1 = G1p1. 
It is this fact that initiated the statement that covariant and contravariant 
vectors are not entirely independent. This statement actually has meaning, 
not only with respect to a Euclidean metric space but whenever a metric is 
introduced into a space and the algebraic manipulations of raising and 
lowering indices by means of a set of numbers resulting from that metric 
are possible. 
Example 1-5* .4. 
The identity of covariant and contra variant bases, L1 
and L1, with respect to a rectangular Cartesian coordinate system, has 

General Cartesian cordinates 
81 
already been pointed out. This fact can be symbolically expressed by 
writing 
Therefore we have 
where 
Gk = b;kGi = Gk. 
In other words, the covariant and contravariant components do not differ 
in a rectangular Cartesian system. 
Let us turn our attention to the sets of numbers (h;k) and (h1k). These 
matrices have played a part in our previous considerations. The following 
development points up their fundamental importance. 
Theorem 1-S*.Sa. 
With respect to transformations (1-5*.IOa,b), the 
numbers h1k transform according to the law 
(1-5* .26) 
The proof, which follows from the definition of h1k and (1-5* .12a), is 
left to the reader. 
Theorem l-S*.8b. 
With respect to transformations (1-5*.lOa), the 
Kronecker delta, tJ/, transforms according to the law 
(1-5*.27) 
PROOF. 
Because of the inverse relation of the sets of transformation 
coefficients, the expression is merely an identity. 
Theorem 1-S*.9. 
With respect to the transformations in (l-5*.IOa), the 
numbers hik transform according to the law 
(1-5*.28) 
PROOF. 
By definition we have 
h;0iP = (JkP• 
By using (1-5* .26) and (1-5* .27) this relation can be put in the form 
(1-5*.29a) 
c qc r!z J,ip = c •c p J t 
i k ar'' 
k 
t 
s • 
If (1-5* .29a) is multiplied with c/ and summed, 
C/ Jvrlzq,JziP = Jv'c/ J, t 
or 
(1-5* .29b) 

82 
THE ALGEBRA OF VECTORS 
Multiplying with fzvk and summing leads to 
(l -5* .29c) 
Application of the coefficients ck q produces the result 
This completes the proof. 
Now that the transformation rules satisfied by the numbers h;k and h1k 
have been specified, we turn to the role that they play in describing the 
basic structure of the space. 
Theorem 1-5*.10. 
The square of the magnitude of a Cartesian vector 
G is represented by any of the forms 
(1-5* .30) 
The proof is left to the reader. 
Theorem 1-5*.11. 
The cosine of the angle 0, determined by the positive 
senses of two Cartesian vectors V and W, is represented by any of the 
forms 
(1-5*.31) 
cos()= 
V. W 
= h;kV;Wk 
= h;kV;Wk = V;W; 
,Jv • v ,Jw • w 
lvl lwl 
lvl lwl 
lvl lwl 
The proof is left to the reader. 
The matrices (h1k) and (h1k) are instrumental in expressing the metric 
concepts of magnitude and angle. When considerations of non-Euclidean 
spaces are made, the metric ideas are defined in terms of these matrices. 
They provide the nrst examples of tensors of the second order. 
Definition 1-5*.5a. 
The collection {h1k}, the elements of which satisfy 
the transformation law (1-5* .26), is called the fundamental metric tensor 
with respect to the centered affine group. 
It is said to be of covariant 
order 2. 
Definition 1-5*.5b. 
The collection {h1k}, the elements of which satisfy 
the transformation law (1-5* .28), is called the associated metric tensor with 
respect to the centered affine group. It is said to be a tensor of contra­
variant order 2. 
Definition 1-5* .Sc. 
The collection { bl}, the elements of which satisfy 
the transformation law (1-5* .27), is called a mixed tensor, with respect 
to the centered affine group, of contravariant order 1 and of covariant 
order 1. 

Problems 
83 
Definitions 1-5*.Sa,b,c serve as a model for the general tensor defini­
tion. Although it is not the present purpose to pursue the idea in any 
greater depth, the general definition is presented for completeness. 
It is assumed that the Cartesian coordinates yi and '[/ are related by 
means of the transformation equations 
Furthermore, suppose that a set of numbers, Tji::: j;, Tj:::: j;, respectively, 
is associated with each Cartesian coordinate system. 
Definition 1-S* .6. 
The collection {Tj::: j;}, the elements of which 
satisfy the transformation law 
(1-5*.32) 
is said to be a mixed tensor with respect to the centered affine group of 
contravariant order q and covariant order p. 
Problems 
1. Prove (b} of (1-5*.12). 
2. Suppose that a Cartesian vector G is represented in terms of the basis p1 and 
p2 of Example 1-5 • .1. Show that IGI = 1 if G1 = 2 and G2 = 0. 
3. (a) Show that the set of n-tuples p1, p2, Pa is linearly independent. 
(b) Show that the set of n-tuples p1, p2, p3 is linearly independent. 
4. (a) Construct a matrix of coefficients (B/) such that B = 1 but the 
transformation is not rectangular Cartesian. 
(b) Find (b/) and b with respect to the matrix of (a). 
5. (a) Suppose that the X1 coordinates are rectangular Cartesian and that 
the Yi coordinates corresponded to a general Cartesian system. 
(See the accompanying diagram.) 
Let Y3 = X3, thereby reducing 
the problem to one in two dimensions. Show that if p1, p2, and Pa are 
of unit length 
x1 
= Y1 cos a + Y2 cos p, 
X2 = Y1 sin ot + Y2 sin {J, 
xa 
= ya, 
where a is measured counterclockwise from X1 to Y1, whereas {J is 
measured counterclockwise from X1 to Y2• 
Hint: Start with Xi = bkiyk and also use P; = B/Lk· 

84 
THE ALGEBRA OF VECTORS 
(b) Show that the transformation equations inverse to those of (a) are 
X1sin P - X2cos P 
y1= ----
sin (p - ix) 
' 
-X1sin ix + X2cos ex 
y2 = ---,----,-
--
sin <P - ix) 
ya = xa. 
(c) Write out the equations in (a) and (b) if ix = 1T/6, 
p = 1T/3. 
(d) If ix and p are given as in (a), write out the expressions for p1, p2 and 
p1, p2 in terms of L1, L2, L3• 
6. Let Xi represent rectangular Cartesian coordinates. Suppose that 
xi = _.y3y1 + y2, 
x2 = y1 _ y2, 
xs = ya, 
(a) Show that b = v3 -1 
(b) Show that 
(1 + v3) 
(1 + v3) 
yi = -
--2-
xi -
--2-
x2, 
(1 + v3) 
(3 + v3) 
y2 = -
--2-
x1 -
--2-
x2, 
ya 
= X3
. 
(c) Show that B = l/(v3 - 1), hence Bb = 1. 
(d) Show that p1 = -V3L1 + L2, 
P2=L1-7. 
Pa= La. 
7. What form does the formula for the distance between two points take in the 
Cartesian system y; of Problem S ? 
8. (a) Show that the set of rectangular Cartesian rotations form a group. 
(b) Is the set of all translations a group? 

& systems and determinants 
85 
9. Show that 
(a) 
s 
axPaXP 
h;k 
= ! a y; a yk , 
p=l 
s 
ay; ayk 
(b) 
(c) 
hik = 
p1 axp axP, 
hik 
= hki. 
10. Suppose that the Xi coordinates are rectangular Cartesian and that they are 
related to general Cartesian coordinates Yi by means of the transforma­
tion equations 
X1=2Y1, 
x2 = 3y2
, 
Determine 
(a) whether p1, p2, p3 are of unit length, 
(b) expressions for p1, p2, p3 in terms of L1, L2, L3, 
(c) the metric tensor components (h;k), 
(d) the components (hik). 
11. Determine general expressions for the magnitude of a vector A in the coor­
dinate systems of Problems 5 and 6. 
12. Show that Ai A 1 is a scalar with respect to the centered affine group. 
13. With respect to transformations (1-5*.9a), show that 
(a) (;k = B/Gi. Hint: Start with (1-5*.15b). 
(b) h;k = Bpi Blh1Kl. 
6. & Systems and Determinants 
Besides vector addition and the inner product there is one other binary 
operation that is a significant part of the algebraic structure of vector 
analysis-the vector product or cross product. 
Development of its 
fundamental properties is facilitated by using certain notational devices 
and by a firm understanding of determinant theory. Therefore this section 
is devoted to the introduction of these underlying notions. 
The major notational innovation, the so-called & systems, or indicators, 
is introduced in the following definition. 
Definition 1-6.1.32 
(1-6.1) 
Eiik 
= &;;k 
= {- if i, j, k is an {::;ermutation of 1, 2, 3, 
0 
otherwise. 
81 The use of two symbols £ilk and &;1• to represent the same set of numbers has no 
significance at this point other than, perhaps, facilitating the use of the summation 
notation. In Section 7* it is shown that £iik and &11• are not equal, and therefore use 
of two symbols avoids an inconsistency. 

86 
THE ALGEBRA OF VECTORS 
The term otherwise refers to a repetition of a number. For those not 
familiar with the terminology of the definition, the following example may 
be of some help. 
Example 1-6.1. 
Consider the set of numbers I, 2, 3. 
These three 
numbers, used without repetition, may be arranged in six ways: 
l, 2, 3 
2, I, 3 
2, 3, I 
1, 3, 2 
3, 1, 2 
3, 2, I 
Any of the first three arrangements can be put in the order of I, 2, 3 by an 
even number of interchanges of adjacent elements. Hence these are called 
the even permutations of I, 2, 3. The last three combinations, which can 
be put in the order I, 2, 3 by an odd number of adjacent interchanges, are 
called odd permutations of I, 2, 3. Since the triple of symbols i, j, k can 
be freely replaced by the numbers 1, 2, 3, it is also the case that a combina­
tion involving repetition, such as I, 1, 3, might appear. The expression 
otherwise refers to this situation. In particular, 
E12a = E2a1 = Ea12 = 1 
E21a = E1a2 = Ea21 = -1, 
whereas all other symbols have the value zero. An important property 
of the t systems, and one that makes them especially valuable for deter­
minant representation, is that of skew symmetry in any adjacent pair of 
indices. This is the property illustrated by 
eiik = 
-eiik· 
Corresponding remarks can be made with respect to the system Eiik, 
which is introduced in order to facilitate use of the summation notation. 
The purpose of a different kernel letter (i.e., E instead of E) is discussed in 
Section 7*. 
If one of the indices in (1-6.1) is suppressed, we define in an analogous 
way 
{ 1 
{1, 
2, 
Eik 
= Eik = 
-1 
if j, k represents 2, 1, 
0 
otherwise. 
(1-6.2) 
This simplified version is employed in an example illustrating the usage of 
indicators in determinant representation. 
Example 1-6.2. 
Consider the second-order determinant 

e systems and determinants 
87 
This determinant can be represented by either of the forms 
{1-6.3) 
(a) 
a = la/'I = E;ka1;a2k, 
(b) 
a = E;ka/ak2• 
The validity of the statement can be verified by writing out the right-hand 
members of the equations. Furthermore, we can write 
(1-6.4) 
(a) 
E1><fl = E;,/a0k, 
(b) EP<Ia = E;ka/aka. 
If p = 1, q = 2, then the factor E12 = 1 is not detectable and (1-6.4a) 
reduces to the form (l-6.3a). If p = 2, q = 1, the left member of (1-6.4a) 
contains the factor E21 = -1. However, the right-hand member of the 
equation is expressed in a way that corresponds to the interchange of two 
rows; that is, a change of sign is introduced in the right-hand member 
also. Similar remarks can be made about the relation (1-6.4b). 
It is interesting to note that the determinant33 concept played an out­
standing role in the mathematics of the eighteenth and nineteenth cen­
turies. The names of many famous mathematicians appear in a historical 
development of the theory. Leibniz ( 1646-1716, German), who originated 
the concept, Cramer (1704--1752, Swiss), and Bezout (1730-1783, French) 
set forth rules for solving simultaneous linear equations which touched on 
the determinant idea. Improved notations and certain useful identities 
were introduced by Vandermonde (1735-1796, French) and Lagrange. 
The structure of determinant theory was completed by the detailed work 
of Jacobi (1804--1851, German), Cayley,34 Sylvester, and others. Felix 
Klein35 credits Cayley with having said that if he had fifteen lectures to 
devote to mathematics he would devote one of them to determinants. 
Klein's own opinion of the place of determinant theory in the field of 
mathematics was not so high, but he did feel that they were vital in general 
considerations and as a part of the theory of invariants. 
The popularity of tensor algebra, brought about by the advent of 
relativity theory, put in the foreground a notation that in many ways made 
trivial the great body of theory that had been developed. This notation, 
which includes the concepts of summation convention and e systems, is 
used in order to put at our disposal the fundamental facts of determinant 
theory. 
88 The name is due to Cauchy. 
"' The symbolizing of a determinant by a square array with bars about it is the 
handiwork of Cayley. 
85 Klein, op. cit., p. 143. 

88 
THE ALGEBRA OF VECTORS 
Note that the f, systems are nicely designed to fit the definition of a 
determinant. If the order of la/I is p, then we expect its expansion to be a 
sum of p ! terms, each a product of p factors. Exactly one element from 
each row and one element from each column should appear as a factor 
in every term. 
For example, if the superscripts are kept in the order 
1 · 
· 
· p, then each term involving an even permutation of 1 · 
· 
· p with 
respect to the subscripts is prefixed with a plus sign. If there is an odd 
permutation, a minus sign is appended. 
It is clear from the mode of presentation of these notes that some 
familiarity with the determinant concept has been assumed. 
However, 
if the reader has had no previous experience with determinants, the follow­
ing formal definition can serve as a starting point. 
For simplicity we 
restrict ourselves to third-order determinants. 
However, the transition 
to the general theory can pretty much be made by replacing 3 by p. 
Definition 1-6.2. 
A determinant of order 3 is a three-by-three array of 
elements. 
a/ a12 a13 
(1-6.5) 
!all= a/ a22 a23 
' 
a/ a3
2 aa3 
with which a numerical value a is associated. 
The subscripts indicate row and the superscripts indicate column. The 
numerical value a is obtained as follows: 
(1-6.6) 
Example 1-6.3. 
The third-order determinant (1-6.5) has the value 
(1-6.7a) 
that is 
(1-6.7b) 
6123a = a = &12s011a22a33 + &231a12a23aa1 
+ &312a13alaa2 + &21aa12a21aa3 
+ &1s2a11a23aa2 + &a21a13a22as1; 
a = a11a22aaa + a1
2a2saa1 + a1salaa2 
- (a12a21aas + a11a23a3
2 + a1sa22aa1). 
The student who is unfamiliar with the determinant concept will profit 
by letting i, j, k = 2, I, 3 and then writing out (1-6.6). 
The determinant representation (1-6.6) is by no means unique. 
A 
second representation in terms of Eijk is introduced by the following 
theorem. 

t systems and determinants 
89 
Theorem 1-6.1. 
A third-order determinant la/I has the numerical 
representation 
( l-6.8) 
PROOF. 
The order of superscripts i, j, k in (1-6.8) represents a chosen 
column arrangement. To ascertain the equivalence of (1-6.8) and ( l-6.6), 
we can write out (1-6.6), as in Example 1-6.3, and then permute the factors 
of each term until the column indices are in the order i,j, k. Corresponding 
permutations of subscripts occur simultaneously. 
Examination reveals 
that the form (1-6.8) has been obtained. 
Some of the simpler properties of determinants are implicit in the 
notational representation. These properties are stated in the following 
theorem. 
Theorem 1-6.2. 
(1-6.9a) 
If all of the elements of any row (or column) of a determinant 
are zero, the value of the determinant is zero. 
( l-6.9b) 
If all of the elements of a given row (or column) are multiplied 
by the same factor, then the value of the new determinant is that 
of the original multiplied by this factor. 
(1-6.9c) 
An even number of interchanges of rows (or columns) of a 
determinant produces a new determinant whose value is the 
same as that of the original. If an odd number of inter-changes 
of rows (or columns) is made, the value of the resulting deter­
minant differs from the original by a factor (-1). 
(1-6.9d) 
If multiples of the elements of any row (column) are added to 
corresponding elements of another row (column), the new 
determinant has the same value as the original. 
PROOF. (1-6.9a) is an immediate consequence of the fact that every 
term of the determinant expansion [see (1-6.6)] contains an element from 
each column and each row. 
(1-6.9b) follows from the fact that exactly one element from each row 
and each column appears in each term of the expansion. 
To prove ( l-6.9c) for columns, consider (1-6.8). Interchange of columns 
corresponds to interchange of the superscripts i, j, k. The E system is 
such that under an even permutation of i, j, k the sign remains the same, 
whereas with respect to an odd permutation it changes. Since the value 
of the determinant is represented by Eiika, the proof is complete. 
A 
corresponding proof for rows follows from (1-6.6). 
Proofs of(l-6.9b,c) are left to the reader. To prove (1-6.9d) with respect 
to rows, consider (1-6.6). We have 

90 
THE ALGEBRA OF VECTORS 
Suppose that a multiple, {Ja/, of the jth row were added to the ith row; 
the form corresponding to the right-hand side of (1-6.6) is then 
&pqrCa/ + {Ja/)a/ak'• 
&pqr0/a/ak' + {J&pq,a/a/ak'· 
Because of the skew symmetry of the & system in p, q, the term 
(1-6.10) 
(See Problem 1, Section 6.) This completes the proof. 
The & systems when subjected to summation and multiplication with 
one another have some interesting and useful properties. They are 
presented in the following theorem. 
Theorem 1-6.3. 
& systems of order 3 satisfy the properties 
(a) Eiik&ipq = 2d:1, 
{l-6.11) 
(b) E'ik&ila = 2da 
{c) Eiik&m = 3! 
where by definition 
d:1 = t(d/ d/ - d,/ d/). 
(See Problem 1, Section 3.) 
PROOF. All three proofs can be made by examining the validity of the 
equalities for the various possible values of the indices. For example, to 
prove (1-6.1 la), we can write out the left- and right-hand sides as follows: 
(a) Eiik&ifla = Elik&1fla + E2ik&2j)0 + E3ik&afla· 
(b) 
2d[ik] = d i d k - d k d i 
j)Q 
j) 
Q 
j) 
Q 
• 
{l-6.12) 
In both (1-6.12a,b) j, k must be a distinct pair of numbers chosen from 
1, 2, 3, otherwise the expressions will have the value zero. The same 
statement holds for the pair p, q. Furthermore, the pairs j, k and p, q must 
take on the same numbers, but not necessarily in the same order, or again 
both (l-6.12a,b) will have the value zero. To illustrate a nonzero evalua­
tion of expressions (l-6.12a,b) let 
j= l ,  
Then 
k=2, 
p=2, 
Eiik&if)a = 
- 1 . 
2h[ik] - -1 
uflQ 
-
• 
q = 1. 
The proof can be completed by considering the other possible choices of 
number pairs. 

& systems and determinants 
91 
The properties of the 6 systems stated in the last theorem facilitate 
consideration of determinant multiplication. 
A determinant whose 
elements are constants has a specific numerical value. Of course, there is 
no problem involved in multiplying two such numerical values together. 
Therefore the task before us is that of finding a third determinant whose 
numerical value is the same as the product of numerical values of two 
given determinants. This third determinant arises from the first two by a 
process that involves both multiplication and summation. We arbitrarily 
designate the operation by the name multiplication. There is no claim that 
this operation, introduced by the next theorem, is unique. In fact, we 
shall subsequently find that it is not. 
Theorem 1-6.4. 
Let la/I and lb/I be given determinants of order 3. 
A determinant le/I whose elements arise from those of la/I and lb/I by 
means of 
(1-6.13a) 
has the numerical value 
(l-6.13b) 
c = ab. 
PROOF. 
According to the relations in (1-6.8) and (1-6.6), we have 
(1-6.14) 
(a) Eiika/'a/akr = aE'IHlr, 
(b) f,d·"'0dbq•b/ = bf,'IHlr" 
Formation of the sum of the products in (l-6.14a,b) results in 
(l-6.14c) 
When the identification (1-6.13a) is used, (l-6.14c) takes the form 
(1-6.14d) 
According to (1-6.6), this relation is equivalent to 
Therefore employment of (1-6.l l c) produces the result (1-6.13b), as was 
to be shown. 
Definition 1-6.3. 
A determinant lc1kl whose elements arise from those 
of la/I and lb/I by means of the rules (1-6.13a) is called the product 
determinant of the determinants la/I and lb/I. 

92 
THE ALGEBRA OF VECTORS 
Example 1-6.4. 
Determinant multiplication is characterized according 
to (1-6.13a) by a row-by-column multiplication. 
1 
3 
5 
-2 
5 
4 
6 
31 18 
(1-6.15a) 
2 
4 
1 
1 
2 
3 
= 
1 
22 
2 1  
3 
1 
2 
1 
4 
1 
-3 
25 
17 
The reader can evaluate these determinants and observe that the numerical 
values satisfythe relation 
ab =c. 
The numerical values are just real numbers, hence they commute; that is, 
ba =c. 
However, it is of some interest to note that the product lb/I la/I does not 
produce the same square array as la/I lb/I. In particular, 
-2 
5 
4 
1 
3 
5 
20 18 
3 
(1-6.15b) 
1 
2 
3 
2 
4 
1 
= 14 
14 13 
1 
4 
1 
3 
1 
2 
12 
20 
11 
Of course, the numerical value of the right member of (1-6.15b) is the 
same as that of the right-hand member of(l-6.15a). This noncommutative 
aspect of determinant multiplication will come to our attention again in 
Section 8 where matrix theory is discussed. 
We have consistently emphasized the transformation concept that 
underlies many aspects of vector and tensor analysis. We shall consider 
the behavior of the systems 6iik with respect to the orthogonal Cartesian 
group. Similar considerations can be made for the systems Eiik; however, 
they will be deferred until Section 7 *, since there are no distinctions between 
the contravariant and covariant forms in rectangular Cartesian systems. 
(See Section 5*.) 
We assume the existence of sets of numbers 6iik• Eiik• etc., in corre­
sponding rectangular Cartesian systems X1, X1, etc. Each set is defined 
by (1-6.1). The following theorem establishes the way in which two such 
sets are related when the coordinate relation is 
Theorem 1-6.5. We have 
(l-6.16) 
a= I. 

& systems and determinants 
93 
PROOF. 
On the right-hand side of (1-6. 16) we have 
that is, the relation (1-6.16) is simply an identity. 
This completes the 
proof. 
The determinants A and a both have the value 1, so that the inclusion 
of the symbol a in relation (1-6.16) might be questioned. The purpose of 
carrying the symbol is to provide consistency with those considerations 
involving a transformation group of more generality than the orthogonal 
Cartesian group and to identify properly the nature of the e systems. 
Definition 1-6.4. 
The class of e systems {eiik}, the elements of which 
satisfy the transformation rule ( 1-6.16), is said to be a covariant tensor 
density of ordt:r 3 and weight + 1 with respect to the rectangular Cartesian 
group of transformations. 
In one or two spots before this point in the book the concept of a co­
factor of an element in a determinant has been used in numerical calcula­
tions. 
The foundation of determinant theory set forth in this section 
makes it possible to formulate algebraically the cofactor concept. 
Definition 1-6.5. 
The cofactor D/ of d/ in the determinant id/I is 
given by 
(1-6. 1 7) 
Example 1-6.Sa. 
Consider the expression (1-6.17) Suppose we were 
interested in the cofactor of d23• The indices p, q, and i are free and 
therefore may be chosen. In order to obtain D32, pick i = 3, p = 3, and 
q = I. The relation ( 1-6.17) reduces to 
e2a1 Da2 = ba12 da1 di2 + ta21 da2 di1, 
or, upon evaluating the e symbols, 
Da2 = dl d12 - da2 di1. 
Example 1-6.Sb. 
Consider the set of simultaneous linear homogeneous 
equations 
(1-6.18) 
dtkXt=O. 
This set of equations has the trivial solution (0, 0, 0). If Id/I * 0, the 
trivial solution is unique. If ldtkl = 0, then, in general, the equations have 
nontrivial solutions. In particular, they are satisfied by D/, Dl, D;3, that 
is, the cofactors of the elements d1\ d2i, and d3i of any column. 
(See 
Section 2.) The veracity of this remark can be demonstrated as follows. 

94 
THE ALGEBRA OF VECTORS 
By multiplying and summing (1-6.17) with E111q, we have 
D/ = !Et11qt;iik d/ dak· 
The cofactors D/ can be put in place of the X1 in the left side of (1-6.18) 
d/' Dit = !d/• Etpq(;ij• dp; dq' 
= !Ei;s(£1Pg dtk dpf dq'). 
Since the parenthetic expression represents the value of the determinant, 
and that has been assumed to be zero, it follows that the cofactors satisfy 
the system of equations. 
Example 1-6.6. 
Under certain linear transformations of coordinates 
the components P1 of a vector remain fixed or change at most by a common 
factor of proportionality. 
The algebraic conditions that specify this 
behavior are 
(1-6.19a) 
The values of A. which satisfy this relation are commonly called eigenvalues 
of cki and the corresponding vectors pk are called eigenvectors. 
In order to find the values of A. which satisfy (l-6.19a), we rewrite the 
set in the form 
or 
(l-6.19b) 
As indicated in the discussion of Example 1-6.Sb, this system of equations 
has nontrivial solutions (P1, P2, P3) if and only if 
{l-6.19c) 
lcki - A.c5k11 
= 0. 
Let us proceed under the assumption that the determinant is zero. Then 
it can be written in the form 
(l-6.19d) 
E;;kEN'(c,i/ - A.c511i)(c,/ - A.c5,/)(c/ - A.c5/) = 0. 
By expanding this equation by multiplying out the parenthetic expressions 
and using the multiplicative properties of the E systems, we obtain the 
third-order equation in A.. 
(l-6.19e) 
A.3 - c,SA.2 + c,f•c/lA. - c = 0, 
where as previously indicated the brackets imply c.l•c/l = !(c,8c/ - c/c/). 
This is called the characteristic equation. The eigenvector pi corresponding 
to the eigenvalues A. obtained from this equation can be specified as co­
factors in the determinant (l-6.19c), since such cofactors satisfy the set 
{l-6.19b). 

Problems 
95 
Problems 
1. Prove (1-6.10). Hint: Show that the expression is equal to its negative by 
using the facts that p, q are dummy indices and skew symmetric on 
&,,11,.; that is, &111,. = -l;qpr• 
2. Complete the proof of Theorem 1-6.2. 
3. Complete the proof of Theorem 1-6.3. 
4. (a) Suppose that &;;k,, were defined in analogy to (1-6.1). 
How many 
nonzero components does the symbol possess? (i, j, k, p taken from 
the set 1, 2, 3, 4.) 
(b) What can be said if i,j, k,p take values from the set 1, 2, 3? 
5. By writing out the summations involved, show that 
6. Show that the following representation is valid for a third-order determinant 
la/I: 
7. Show that a skew symmetric (al = -ak;) determinant of order 3 has the 
value zero. 
8. Generalize the representations (1-6.6) and (1-6.8) to determinants of order p. 
9. (a) How can the representation in Problem 6 be generalized to higher 
order determinants? 
(b) Can Problem 7 be generalized? 
10. 
(a) Multiply the determinants 
1 
5 
3 
-2 
2 
1 
6 
4 
-2 
2 
1 
5 
3 
-4 
4 
1 
(b) Give a simple example showing that determinant multiplication is not 
commutative, that is, that the array arising from la/I lbk111 is in 
general different from the one produced by Jb/l lak111. (The resulting 
numerical values are the same, of course.) 
11. Explain why b/Bk" = 6;1' implies bB = 1. 
12. Start with the cofactor representation 
Show how multiplication and summation of the relation with d8 i and 
JEt111 leads to 

96 
THE ALGEBRA OF VECTORS 
7. The Cross Product 
Again consider the introductory relation (1-5.la), which is 
PQ = ! piQ"th· 
i.· 
In Section 5 the binary relation, inner multiplication, was defined for 
vectors P and Q. Now we introduce an operation called the cross product 
of P and Q. 
The mode of introduction follows the path indicated by 
Grassman's work in that we begin with algebraic statements. It can also 
be said that the delineation of ideas is not too far removed from the order 
used by Hamilton, for his development of quaternions (from which the 
theory of the cross product can be extracted) started with a search for 
meanings to be associated with the "product" of two directed line segments. 
He then set forth algebraic properties, geometric meanings, and physical 
interpretations in that order. 
A meaning is given to (1-5.1) in the following definition. 
Definition 1-7.1. 
A binary relation between vectors P and Q, called the 
cross product of P and Q, is denoted by 
3 
(1-7.1) 
p X Q = ! t,ErstP"Qt. 
r#l 
By writing out the right-hand side of(l-7.1), we have 
( l-7.2a) 
p 
x Q = (P2Q3 - P3Q2)l1 + (P3Q1 - PIQ3)t2 + (P1Q2 - P2Ql)l3. 
The relation (l-7.2a) is easily remembered when expressed in the symbolic 
determinant form: 
(l-7.2b) 
p x Q = 
p1 
p2 
p3 
Ql Q2 Q3 
The determinant is said to be symbolic because one row contains vectors, 
and therefore a numerical value cannot be associated with it. It is interest­
ing to note that we can expand the symbolic expression (l-7.2b) around 
any row or column just as it i·s possible to do to an ordinary determinant. 
The meaning of various other determinant operations is not clear. 
For 
example, although interchange of the second and third rows is intuitively 
useful (see l-7.4a), an interchange of the first and second rows produces a 
state of confusion.36 
36 It is not implied that meanings cannot be given to ordinary determinant operations 
for this symbolic determinant but only that such meanings do not already exist. 

The cross product 
97 
From either this form or its expansion (1-7.2a) we can determine the 
following table of cross products of the unit arrows. 
L1 
L2 
La 
(1-7.3) 
L1 
0 
La 
-L2 
L2 
-La 
0 
L1 
La 
l2 
-l1 
0 
The table should be read from the left-hand column to the top row. For 
example, L2 x L3 = L1• 
Example 1-7.1. 
Let P = 2L1 + 3L2, 
Q = L1 + St2; then 
l1 
l2 
l3 
PxQ= 2 
3 
0 = 7L3. 
1 
5 
0 
Example 1-7.2. 
Let P = {JQ; then 
l1 
L2 
l3 
PxQ= {3Ql {3Q2 {3Q3 =0. 
Ql 
Q2 
Q3 
Hence, whenever P and Q are parallel, the cross product has the value 
zero. Assuming that neither P nor Q is the zero vector, we can show that 
the converse also holds by writing out the determinant in the form 
(1-7.2a) and by making use of the linear independence of Li. L2, and L3• 
The next objective is to determine the fundamental algebraic properties 
the cross product satisfies and those it does not. 
Theorem 1-7.la. 
The cross product is 
(1-7.4a) 
(Anticommutative) 
(1-7.4b) 
(Distributive) 
P x Q = -Q x P. 
P x (Q + R) = P x Q + P x R. 
(l-7.4c) 
(Real number associative) ix(P x Q) = (ixP) x Q = P x ixQ. 
PROOF. 
Relation (l-7.4a) is an immediate consequence of the skew 
symmetry exhibited by the 8 symbol in (1-7.1) or the parenthetic expres­
sions in (l-7.2a). Relations (1-7.4b,c) can be proved by straightforward 
computation starting with either (1-7.1) or (1-7.2a). The details are left to 
the reader. 

98 
THE ALGEBRA OF VECTORS 
Theorem 1-7.lb. 
(Closure). 
If P and Q are Cartesian vectors, the 
components of P x Q transform as vector components with respect to 
the orthogonal Cartesian group of transformations. 
PROOF. 
Consider the equation of rotational transformation, 
Xi = akiJ(k, 
and recall that 
We have 
&,.1P'Qt = (E,.ia/akt)PiQk. 
If we employ the representation for cofactor as expressed in Definition 
1-6.5, the right-hand side of the expression will take the form 
aA,iE;;kPiQk. 
Since a = 1 and A, i = a{, we have 
3 
(l-7.5a) 
& .. 1P"Q1 
= l at&i1kPiQk. 
i=l 
The correspondence of the form (1-7.5a) with the appropriate transforma­
tion law becomes visually clearer if T, and T; are used to replace &rai-P"Q1 
and E;;kPiQk, respectively. We have 
3 
(1-7.5b) 
T, = latf;. 
i=l 
Consideration of the proof for the group of translations is left to the 
reader. Although this completes the proof, the following pair of remarks 
may be helpful. 
I. The coefficients of transformation A, i are cofactors of the elements 
at in the determinant of the small a's only because a = I. More generally, 
the cofactors are designated by aA,i. This remark not only clarifies that 
step in the proof involving cofactors but also pYints out the interesting 
observation that the components of the cross product satisfy the law of 
transformation for vector components only because of the special trans­
formation group under consideration. 
2. The replacements 
enable us to put (I-7.5b) in the nicer notational form 
(I-7.5c) 
T' = atTi. 
Theorem 1-7.lc. 
The cross product is not associative in general; that is, 
P x (Q x R) 	 (P x Q) x R. 

The cross product 
99 
PROOF. 
In order to show that a property does not hold in general, all 
we need to do is give a contradictory example. Therefore let 
Then 
whereas 
This completes the proof. 
The existence of an identity element, X, such that A x X = A for any 
A must be ruled out. 
(See Problem I at the end of the section.) Since 
there is no identity element, the possibility of an inverse is negated. 
Our consideration of the geometric properties of the cross product 
really begins with Problem 18 of Section 5. 
The perpendicularity con­
ditions 
(I-7.6a) 
are satisfied by 
(1-7.6b) 
C1 = y I: 
p . c = p1c1 + p2c2 + p
a
cs = o, 
Q . c = 
Q
1c1 + 
Q
2C2 + 
Q
sca = o, 
p
a I· 
Q
s 
I 
p
3 
pl I 
C2 = y 
' 
Q
s 
Q
1 
I 
pl 
p
2 I 
Cs= y 
Q
i 
Q
2 ' 
where y is any real number. As an aid to clearly relating this problem to 
the cross product, note that the determinant of the components of L1, L2, 
Ls has the value 
1 
0 
0 
0 
1 
0 
= 1>0, 
0 
0 
1 
whereas that of L1, L2, -L
3 
is 
1 
0 
0 
0 
1 
0 = -1<0. 
0 
0 
-1 
The following definition is consistent with our previous statements con­
cerning right- and left-hand coordinate systems. Furthermore, it includes 
the foregoing introductory illustration. 

100 
THE ALGEBRA OF VECTORS 
Definition 1-7.2. 
Suppose P, Q, R are linearly independent vectors. If 
pl 
p2 
p3 
(1 -7 .7) 
E;;kP;Q;Rk = Qi Q2 Q3 > 0, 
Ri 
R2 
R3 
the vectors P, Q, R, in that order, are said to form a right-hand system. 
If the value of the determinant is less than zero, the vectors in the given 
order determine a left-hand syste.m. 
Theorem 1-7.2. 
The sign of the determinant of the vectors P, Q, C, in 
that order, of Problem 18, Section 5, is the same as the sign of the factory. 
PROOF. 
In order to facilitate the use of the summation notation, let 
pr =Pr> Q• = Q,. Then 
f,iikPiQiCk = f,iikPiQiyEkrsP,Q, 
= y2 b@AslpiQiPrQs = y[(P'P,)(Q'Q,) - (P'Q,)(P'Qr)); 
that is 
E;;kPiQiCk = y IPl2 IQl2 (1 
- cos2 0) = y IPl2 IQl2 sin2 0, 
where () is the angle determined by P and Q, 0  ()  7T. Since y clearly 
determines the sign of the right-hand member of the foregoing expression, 
the proof is complete. 
When y = I, the components (l-7.6b) become precisely those of the 
cross product. Therefore, as a consequence of the preceding definition 
and theorem, it follows that P, Q and P x Q, in that order, form a right­
hand system. Furthermore, P x Q is perpendicular to both P and Q. 
The definition (I-7. I) of the cross product does not demand that P and Q 
be linearly independent. If P and Q are proportional, then P x Q = 0, 
as illustrated in Example 1-7.2. If P = 0 or Q = 0, it is easily seen that 
again P x Q = 0. 
Our considerations are restricted to right-handed rectangular Cartesian 
coordinate systems; therefore a = 1. The vector character of the cross 
product with respect to the transformation group relating these systems 
carries with it the implication that the geometric interpretation of the 
cross product does not depend on a particular one of the coordinate 
frames. This fact is helpful in associating a geometric meaning with the 
magnitude of the cross product. To this purpose, let a coordinate system 
Xi be chosen such that the linearly independent vectors P and Q have 
components (P1, 0, 0), (Q1, Q2, 0), respectively. 
Theorem 1-7.3. 
The magnitude of the cross product is 
(hfll),.,'N-E Fls1e1;c QI = IPI IQI sin fJ, 

The cross product 
101 
xa 
PXO 
n 
xi 
Fig. 1-7.1 
where () is the angle determined by the positive senses of P and Q such 
that 0 ()TT. (See Fig. 1-7.1.) 
PROOF. 
According to (1-7.2b), 
(l-7.9a) 
p X Q = pl 
Q 
Q = p1Q2L3. 
Ql Q2 
0 
From examination of Fig. 1-7.1, we observe that IQ21 = IQI sin e. There­
fore 
(I-7.9b) 
IP x QI= [(P x Q) • (P x Q)]l-i = IP1Q2I = IPI IQI sin e. 
This completes the proof. 
Theorem 1-7.3 points toward the natural association of the cross product 
with a plane area, in particular, the parallelogram area determined by the 
vectors P and Q. In order to correlate this result with the preceding facts 
concerning the cross product, we simply abstract the plane area number 
JPI IQI sin() and reinterpret it as the length of a vector perpendicular to 
P and Q. Then 
(1-7.10) 
IP x Q =IPI IQlsinOo;\ 

102 
THE ALGEBRA OF VECTORS 
where n is a unit vector perpendicular to P and Q and chosen so that 
P, Q, n, in that order, determine a right-hand system. In most texts 
(1-7.10) is used as the definition of the cross product. 
The geometric interpretation of the magnitude of P x Q as a plane 
area points toward meanings not yet expressed. These remaining thoughts 
have both mathematical and physical significance. 
From the mathematical viewpoint, the components 
(1-7.l la) 
2pliQkl = piQk _ pkQi 
of the cross product determine a system of the second order. In general, 
the number of components of such a system in three-space is nine. The 
skew symmetry of the set (1-7.1 la) implies that only six of these components 
are nonzero and that these six can be paired off according to the arrange­
ment 
p11Q2l = _p[2Qll, 
p[2Q3l = _p[3Q2l, p[lQ3l = _p[3Qll. 
In other words, the system of components is specified completely by an 
appropriate choice of three components. Thus the system can be associated 
with a vector by means of the identification 
(1-7.l lb) 
As we have seen, it is this vector that is called the cross product of P and 
Q. It should be noted that the identification (1-7.l lb) has no analogue 
outside three-space. For example, in two-space we might consider identi­
fying 2p[i Qkl by the relation 
(1-7.1 lc) 
B;;P;Q;, 
but this expression produces only a single component, not the pair of 
components needed to determine a two-space vector. 
From the physical point of view the cross product is used to represent 
entities associated with rotational motion. A simple illustration is given by 
the next example. 
Example 1-7.3. 
Suppose that F is a force applied to a body at a pointP. 
The vector moment of the force related to another point 0 is defined by 
(1-7.12) 
M = r x F. 
(See Fig. 1-7.2.) The moment of force is then a measure of the rotational 
effect of F in the plane of r and F. The magnitude of this effect is geo­
metrically expressed by the area of the parallelogram of r and F. The 
sense of rotation is determined by the orientation with which F endows 
the parallelogram. Therefore 
M = r x (-F) = F x r 

I 
10 
I 
I 
I 
I 
I 
I 
'fM' 
The cross product 
103 
Fig. 1-7.2 
represents a moment of the same magnitude as M but with the opposite 
I 
rotation sense. The relationship between M and M represents a combined 
geometric and physical interpretation of the anticommutative property of 
the cross product. (For further remarks see the problem section.) 
Physicists have distinguished vectors (i.e., the cross product) associated 
with plane areas by calling them axial vectors, while using the term polar 
vector for our ordinary free vector. 
There are two important algebraic expressions that involve inter­
relationships in some fashion between the dot and cross products. The 
first of these, the so-called triple scalar product, P · Q x R, is examined 
in the next theorem. 
Theorem 1-7.4. 
The triple scalar product P • Q x R (for rectangular 
Cartesian systems) is represented by 
pl 
p2 
p3 
(1-7.13a) 
P·QxR= Ql 
Q2 
Q3 
, 
R1 
R2 
Ra 
or 
(1-7.13b) 

104 
THE ALGEBRA OF VECTORS 
PROOF. 
To prove (1-7.13a), we simply note that 
Therefore 
P· Q x"R = P1 I Q2 
R2 Q3 I I Q3 Ql I I Ql Q2 I 
+ p
2 
+ p
3 
. 
Ra 
Ra 
R1 
R1 
R2 
Q21 
R2 
. 
The right member of this last expression is equivalent to the determinant 
representation in (l-7.13a). 
The form (l-7.13b) likewise follows directly from the definitions of dot 
and cross products with respect to an orthogonal basis. 
It is interesting to note that the triple scalar product represents a deter­
minant. This fact is clearly exhibited by either (l-7.13a) or (1-7.13b). 
The triple scalar product is more accurately described as a scalar density, 
but with respect to the rectangular Cartesian transformation group it has 
a valid claim to the simpler designation scalar. 
Theorem 1-7.5. 
The quantity 
P • Q x R = &;;,/'i
Q
; Rk 
is a scalar with respect to the rectangular Cartesian transformation group. 
PROOF. 
We have 
"·· pi
Q
;Rk = aA.rA.•A ta ia ;a kc; 
pe?i!Ji.u 
l>uk 
i 
1 
k 
e 
I 
g l>rst 
 
=abr15s15tj_; pei"'ltJi.u 
e 
f 
o rst 
 
= aers1PrQ•Ji.t. 
Since a = 1, the proof is complete. 
The geometric interpretation of the triple scalar product presents the 
possibility of an interplay between algebraic and geometric modes of 
thought. 
Example 1-7.4. 
The absolute value of the triple scalar product 
P • Q x R can be interpreted geometrically as the volume of a parallel­
epiped determined by vectors P, Q, and R. To see this interpretation 
clearly (Fig. 1-7.3), recall that the volume of the parallelepiped is deter­
mined by multiplying the area of the base by the height. According to 
the definition of the dot product [see (1-5.3)], 
p. Q x R = IPI IQ x RI cos() = IQ x RI( IPI cos 0). 

0 
FJg. 1-7.3 
The cros product 
105 
Then IQ x RI is numerically equal to the area of the base, whereas 
IPI lcos 01 represents the height of the parallelepiped. 
It is an interesting sidelight to observe that the volume of a parallelepiped 
is algebraically represented by a determinant. This fact is the basis for 
volume representations when the space dimension is greater than 3. 
Example 1-7.S. 
We might be concerned about the ordering of the 
vectors P, Q, R in the representation of the triple scalar product. In 
particular, the question may be asked whether this ordering has any 
significance with respect to the geometric interpretation of Example 
1-7.4. It can be answered in the negative except for sign, for from either 
(l-7.13a) or (l-7.13b) we can conclude that 
(l-7.14a) P • Q x R = Q ·Rx P = R • P x Q 
= -P ·Rx Q = -R • Q x P = -Q · P x R. 
By commuting R and P x Q in the last member of the first line and then 
by equating it to the first member of that line, we get the rather interesting 
algebraic relation 
(l-7.14b) 
Ip. Q x R = p x Q . R.1 
The implication of this expression is an algebraic property of interchange 
of the dot and cross. 
During the discussion of left-
and right-hand coordinate systems, 
which took place in Section l, it was indicated that more information 
would be supplied in this section. The remarks of the following example 
pertain to that discussion. 
Example 1-7.6. 
Suppose that X; is a right-hand rectangular Cartesian 
coordinate system and that X1 were left-handed. (See Fig. 1-7.4.) Let 
the transformation equations relating the systems be 
(1-7.15) 
x1 = x2, 
g2 = x1, 
ga = xa. 

106 
THE ALGEBRA OF VECTORS 
Fig. 1-7.4 
The determinant of the transformation is 
0 
1 
0 
(l-7.16a) 
a= 
1 
0 
0 
0 
0 
1 
and 
= -1, 
(1-7.16b) 
P • Q x R = -P · Q x It 
Therefore the numerical value of the triple scalar product is not invariant 
with respect to an inversion. 
Under this circumstance the geometric 
interpretation of the triple scalar product as a volume is not completely 
satisfactory. In fact, inversions are classified as transformations that do 
not preserve volume. 
The restriction to right-hand systems eliminates 
the difficulty and the orthogonal Cartesian group with the condition 
a = 1 associated is said to be volume preserving. 
It was indicated that there are two algebraic relations of significance 
to the development of the subject. The second is the so-called "triple 
vector product." It has been shown that, with respect to the rectangular 
Cartesian transformation group, Q x R could be considered a vector. 
Hence P x (Q x R) is also interpretable as a vector. In a specific instance 
this vector can be computed as follows: 

The cross product 
107 
Example 
1-7.7. Let P = 211 + 312 - 18, Q = 11 - 412 + ls, R = 
311 - 212 + 218• Then 
and 
Q x R = 1 
-4 
1 
= -611 + 12 + 1013 
3 
-2 2 
P x (Q x R) = 
2 3 
-1 
= 3h1 - 1412 + 2013• 
-6 
1 
10 
The computation of Example 1-7.7, although not difficult, is a little 
tedious and certainly does not lend itself to theoretical considerations. 
This fact increases the importance of the following discovery. 
Theorem 1-7.6. 
The triple vector cross product has the representation 
(1-7.17a) 
I p x (Q x R) = Q(P • R) - R(P • Q).1 
The component form of this expression is 
(I-7.17b) 
where 
(l-7.17c) 
PROOF. 
The fact that (l-7.17b) is the component form of (1-7.17a) 
follows from Definition 1-7.1 and appropriate use of the summation 
notation. The relation (l-7.17c) is introduced to facilitate this usage of 
the summation process. 
The theorem is proved by starting with (1-7.17b). Beginning with the 
left member, 
Er•ip.f,tikQiRk = Er•if,iikP.QiRk = Eir•E,,6.Q1Rk. 
Employing (1-6.1 la), we can continue the string of equalities 
= 2tJftlP,Q1Rk = 2P,QlrRsl = P,(QrR• - Q'Rr) 
= Qr(P,R') - Rr(P,Q'). 
Any difficulty on the part of the reader in eliminating the tJ}k'l can be 
resolved by expanding the bracketed expressions and applying the defini­
tion of the deltas. 
Although the index notation employed in the last proof may seem some­
what involved to the beginner, some idea of its power and usefulness can 

108 
THE ALGEBRA OF VECTORS 
be obtained by comparing the simplicity of this proof with any of those 
usually given in texts on vector analysis. 37 
Example 1-7.8. 
The computation of Example 1-7.6 can be accom­
plished as follows: 
P • R = 6 - 6 - 2 = 
-2, 
P • Q = 2 - 12 - 1 = -11. 
p x (Q x R) = Q(P. R) - R(P. Q) = -2Q - l lR = -2(L1 - 4L2 + L3) 
+ 11(3L1 - 2L2 + 2L3) = 3h1 - 14L2 + 20L3. 
In Theorem 1-7 .1 c it was shown that the cross product is not associative. 
The rectangular Cartesian representation of the triple vector product 
makes possible a statement of the relation between P x (Q x R) and 
(P x Q) x R. 
Theorem 1-7.7. 
We have 
(1-7.18a) 
Therefore 
(P x Q) x R = Q(P • R) - P(R • Q). 
(1-7.18b) 
P x (Q x R) - (P x Q) x R = P(Q • R) - R(P • Q). 
PROOF. 
Making use of the anticommutative property of the cross 
product and Theorem 1-7.8, we have 
(P x Q) x R =-Rx (P x Q) = -[P(R • Q) - Q(R • P)] 
= Q(R • P) - P(R • Q). 
This completes the proof of (1-7.18a). The relation (1-7.18b) is obtained 
by subtracting. 
It seems appropriate to conclude this section with a few words about the 
possibility of vector division. 
The operation of division is usually thought of as the inverse of multi­
plication. 
The two types of multiplication we have considered are· dot 
and cross products. Hence it is natural to ask whether it is practical to 
introduce inverse operations with respect to these processes. 
A fundamental property of real-number multiplication is its uniqueness 
characteristic; that is, the solution to the problem is unique. It is this 
property that makes possible a simple and useful process of division. 
Now suppose that with respect to the dot product we considered 
P·Q=O, 
87 A variety of proofs can be found in Murray S. Klamkin's article "On the Vector 
Triple Product," American Mathematical Monthly, December 1954. 

The cros product 
109 
where P is given. 
In particular, suppose P = 2L1 - 3L2 + 4L3• 
Then 
Q = 3L1 + 2L2 or Q = 4L2 + 3L3 satisfy the relation. Since Q cannot be 
uniquely determined, division is not defined with respect to the dot 
product. For the same reason division is not defined with respect to the 
cross product. 
There are still other possibilities for the operation of division. Another 
that is ruled out of the present considerations is the quotient constructed 
from the components of a pair of vectors; that is, given vector components 
pi and Qi, Qi =F 0, we can certainly form the quotients Pi/ Qi. This is just a 
real-number division. 
The number of possible quotients involved (for 
n = 3) is, however, nine. 
Therefore the resulting set of components 
cannot represent a vector. For that reason this sort of quotient does not 
enter into our present work. 
A type of pseudo-division with a place in the algebra of vectors is a 
special case of the so-called "quotient law" which is usually stated in a 
development of the algebra of tensors. 
Theorem 1-7.8. 
Suppose that for any vector P 
(1-7.19a) 
then 
P·Q = P·R; 
(1-7.19b) 
Q=R. 
PROOF. 
From (1-7.19a) 
p. (Q _ R) = p1(Q1 _ Rl) + p2(Q2 _ R2) + pa(Qs _ Ra) = o. 
P is arbitrary; therefore we can make the successive component choices 
(1, 0, 0), 
(0, 1, 0), 
and 
(0, 0, 1). 
With respect to these choices, 
Qi= Ri, 
This completes the proof. 
Problems 
1. (a) Prove (1-7.4b) and (1-7.4c). 
j = 1, 2, 3. 
(b) Show that the relation A x X 
= A is satisfied if and only if A 
= 0. 
Hint: Use the form eiikA i Xk 
= A; and show that A is self-perpen­
dicular. 
2. (a) Determine a vector perpendicular to A 
= 2L1 + 3L2 - La 
and B 
= 
L1 - L2 + 2L3• 
(b) Compute B x A and then compare with the result of (a). 

110 
THE ALGEBRA OF VECTORS 
(c) Search the mathematical literature for other examples of noncom­
mutative products. 
3. Compute the area of the parallelogram determined by the vectors A 
= 
5l1 - 2l2 + 3l3, B 
= l1 - 3l2 + l3 
4. Show that P x Q is perpendicular to P and Q by starting with the com­
ponent expression &iil.J'iQk. 
5. Use the cross product to determine an equation of the plane passing through 
the points P1(1, 2, 5), P2(0, 1, 4), and P3(1, 0, 3). 
6. How many components has the system 2P[i Qkl in a four-dimensional space? 
How many are nonzero? If appropriately chosen, what is the least 
number needed to determine them all? 
7. Show that the moments of Example 1-7.3 satisfy the relation M = -M. 
Write a statement interpreting the sense of the moment vector. 
8. Transform r x F with respect to an inversion 
X1 
= X1, 
x2 
= -x2, 
xa = xs. 
9. The representations of two lines are given parametrically by 
x1 = 1 + 31, 
x2 = 2 + 51, 
X3 
= 3 - 2t, 
X1=1s, 
X2 = 4 + 3s, 
X3 
= 2 + 3s. 
(a) Find the parametric equations of a line through (1, 5, 2) and perpen­
dicular to each of the two given lines. 
(b) Show that the given lines are skew (i.e., nonintersecting). 
(c) Find the representation of a line perpendicular to each of the given 
lines and intersecting each of the given lines. 
10. Prove that in three-space there is a unique line that is perpendicular to both 
and intersects each of two given skew lines. (Parallel lines are an exception 
to this statement.) 
11. Given 
(a) compute P · Q x R; 
(b) compute P x Q · R and compare with the result of (a). Why are 
the results the same? 
12. Find the volume of the parallelepiped determined by vectors 
13. Given 

(a) compute P x (Q x R) directly; 
(b) compute P x (Q x R), using (1-7.17a); 
(c) compute (P x Q) x R. 
The cross product 111 
14. Show that (P x Q) x R = Q(P · R) - P(Q · R) by showing that 
Eiik(&;,1P•Qt)Rk = Qi(Pi R;) - pi( Qi R;). 
15. Give an example showing that the solution for Q in P x Q = R is not 
unique. (Choose P and R arbitrarily.) 
16. Given A = Sl1 + 3l2 - 2l3 and A· B = 15, show that B is not unique. 
17. Given B 
= 3l1 + 5L3 and A· B =A· C for all A, find C. 
18. Show that (identity of Lagrange) 
(A x B) -(C x D) 
= (A · C)(B · D) - (A · D)(B · C). 
19. Let P1 be a given point and r 
= r0 + Bt a given line. Show that the distance 
h from point to line is given by 
!(r1 - r0) x BI 
h 
= 
!BI 
' 
where P1 ·is the end point of the position vector r1. 
20. Suppose that unit vectors A and B determine an angle 0. Show that 
!sin °1 
= (I ;: ; r + I ;: ;: r + I;: ;: rr 
· 
21. The determinant 
I
A.A A·B1 
B·A B·B 
is a second-order example of Gram's determinant, or the Gramian of the 
system A, B. Show that a necessary and sufficient condition for the linear 
dependence of A and B is that the Gramian has the value zero. 
Hint: Method 1. Make use of Lagrange's identity (Problem 18). 
Method 2. Start with the algebraic expression ixA + {JB 
= 0 and 
dot with A and then with B. 
'J*. & Systems and the Cross Product in General 
Cartesian Systems 
The discussion of & systems and the cross. product in Sections 6 and 
7 was general enough that much to be said in this section borders on 
repetition. 
It is important, however, that certain concepts be clarified 
and that other ideas be refined. 
The first considerations deal with the seemingly strange procedure of 
using a different kernel letter (E) for the contravariant components Eiik 
from that used for the covariant components &;;k· Recall that in Section 

112 
THE ALGEBRA OF VECTORS 
5* covariant components G; were associated with contravariant compo­
nents by means of the rules 
(a) 
G; = h;kG", 
(b) Gk 
= hkiG;. 
(l-7*.l) 
Of course, in Section 5* the linear combinations (G;) of the Gk were intro­
duced in conjunction with a change to a new basis. The relations in 
(1-7*.la,b) also serve as a starting point in the development of an algebra 
of components. 
The covariant metric tensor and the associated contravariant metric 
tensor are used to introduce linear combinations of given components. 
The processes involved are designated by the terms "lowering indices" 
and "raising indices." For example, associated with the covariant com­
ponents &iik we have 
(l-7*.2a) 
&pqr = h'PihqihrA·&i;k• 
Associated with the contravariant components Ei;k is the system 
(l-7*.2b) 
Epqr 
= hp;hq;hrk£iik, 
Theorem 1-7*.1. 
We have 
(l-7*.3) 
(a) 
&pqr 
= lhikl Epqr, 
(b) 
Epqr = lh1kl &pqr• 
PROOF. 
lf we apply the determinant definition to relations (l-7*.2a,b), 
both results follow. 
Theorem (1-7*.l) explains the use of different kernel letters. The values 
of the determinants of the contra variant and covariant metric tensors are, 
in general, different from 1; hence the values of &pqr and Epqr are not 
defined by (1-6.1 ). 
Suppose that &;;k and £iik satisfy Definition 1-6. l in every Cartesian 
coordinate system. 
The laws of transformation are given by the next 
theorem. 
Theorem 1-7*.2. 
If y; = bkif\ we have 
(l-7*.4) 
(a) 
&;;k = bB/B/B/Evqri 
(b) 
£iik 
= Bb,1/b/b/Epqr. 
PROOF. 
As in theorem (l-6.5), these relations are identities. 
Definition 1-7*.la. 
The class of & systems {&;;k}, the elements of which 
satisfy the transformation relation (l-7*.4a), is said to be a covariant 
tensor density of order 3 and weight + l with respect to the centered 
affine group. 

The cross product 
11 3 
Definition 1-7*.lb. 
The class off, systems {£iik}, the elements of which 
satisfy the transformation rule ( l-7*.4b), is said to be a contravariant 
tensor density of order 3 and weight - I with respect to the centered 
affine group. 
Now let us turn our attention to the cross product. A rectangular 
Cartesian system with coordinates X1 can be conveniently used as a 
connecting link in determining the general rule of transformation. 
Let 
a rectangular Cartesian system be identified by coordinates X1, and 
suppose that Y1, Y1 are coordinates of arbitrary Cartesian systems. 
Denote the equations of transformation as follows: 
(l-7*.5) 
where 
(a) 
Xi = cki Yk, 
Xi = d,r/ YP, 
(b) 
fk = c.kXi = c.kd iYP = b kYP, 
I 
I 
P 
1> 
( l-7*.5c) 
bpk = C/dpi· 
Theorem 1-7*.3. 
The cross product of a pair of contravariant vectors 
is a covariant vector density of weight + I with respect to the centered 
affine group of transformations. 
PROOF. 
If P and Q are given vectors, then, in a manner analogous 
to that employed in Theorem 1-7.lb, we obtain 
· 
(l-7*.6) 
Therefore 
(a) 
&,,1P'Q1 = cC/E1k1PkQ1, 
C ;c, 
PkQ-1 
dD ·'C p=1n 
C 
r "Jkl 
= 
r' "Jfg 
l.:"9 • 
By multiplying this relation by Ccu• and using the properties cC = I 
(see Problem I I, Section 6) and cu•c,J = bu1, we obtain, 
f,ukiPkQ1 = CdB/E11gP1Q11• 
According to the theorem on determinant multiplication, Cd = b. This 
completes the proof. 
The preceding theorem implies that the appropriate representation of 
the cross product is in terms of covariant components. This conclusion is 
enforced further by carrying out the transformation of P x Q rather 
than the components, with respect to the equations, 
Then 
x1 = ckifk. 
3 
s 
p x Q = L L, &,.1.P"Q';,. LC/C/c&;k1PkQ1pq 
r-1 
r-1 
_ hq; 
c pknz _ 
; c pkn1 
-
PqC"ikl 
!.:" 
- P Co;kz 
!.:" • 

114 
THE ALGEBRA OF VECTORS 
The cross product has its simplest representation in terms of the reciprocal 
basis pi (i.e., in terms of covariant components). 
Establishment of the transformation law 
(l-7* .7) 
for the covariant components of the cross product sets the ground work 
for consideration of the triple scalar and triple vector products. 
Theorem 1-7* .4. 
The classes of triple scalar products {&i1kPiQi Rk}, 
{EiikP;Q;Rk} are scalars of weights + 1 and -1, respectively, with respect 
to the centered affine group of transformations. 
PROOF. 
The result is obtained by employing the transformation laws 
of the factors involved. 
Theorem 1-7*.5. 
The class {£iikP1&krsQ• R8} is a contravariant vector of 
weight zero with respect to the centered affine group. 
The proof is obtained by straightforward computation. 
Problems 
1. If Yi = bki Yk, determine the transformation rule.for 
f,iik 
' 
2. Construct a tensor of weight zero from lh;kl and E;;k· 
3. Prove Theorem 1-7*.4. 
4. Prove Theorem 1-7*.5. 
S. Prove that the class Ei1"P;Qk is a vector density of weight -1. 
8. The Algebra of Matrices 
In the preceding development of vector algebra use was made of 
matrices of numbers such as 
The square matrix (a/) was employed in a variety of ways. It represented 
a set of coefficients of a system of linear equations, a set of transformation 
equation coefficients, and a set of elements of a determinant. 
The utility of such sets of elements had become quite apparent by the 
middle of the nineteenth century. Determinants and linear transforma­
tions were under intensive study at that time. The rather natural, and 

The algebra of matrices 
115 
very important, step of formally developing the algebra of matrices of 
numbers was taken by the English mathematician Cayley. 
The following definition serves the purpose of introducing the matrix 
concept. 
Definition 1-8.1. 
Any array of elements arranged in m rows and n 
columns is called a matrix. 
In this book the elements are real numbers or real-valued functions. 
The concepts of vector algebra could be developed without mentioning 
the term matrix. However, the matrix and the algebra of matrices have 
become an important part of modern-day mathematics. 
Therefore a 
discussion of the basic language and some of the ideas of matrix algebra 
should be valuable to the reader in his assimilation of the materials pre­
sented here and elsewhere. 
The matrices of concern are mostly square, one row, or one column 
arrays. 
However, as indicated by Definition 1-8.1, a matrix is not re­
stricted to any one of these forms. 
Example 1-8.1. 
It is quite simple to think of matrices formed from 
everyday experiences. 
For example, the weekly array of prices of three 
"come on" articles, A, B, and C, sold in a supermarket would appear as 
follows: 
(1-8.1) 
S 
M 
T 
W 
TH F 
S 
A 
99 
99 99 
99 
69 
69 
69 
B 
87 
87 
87 
87 49 49 49 
c 98 98 98 98 79 
79 
79 
Some residents of northern California may even be able to identify the 
items. 
The following convention corresponds the notation of this book with 
that commonly used in the development of matrix algebra. 
Convention 1-8.1. 
A matrix of m rows and n columns is denoted either 
by capital letters A, B, · 
· 
·
,
 etc., or by (a/), (b1), (ck), · 
· 
· . 
When the 
index notation is used, the subscript represents row and the superscript 
represents column. 
The fundamental laws of matrices are defined as follows: 
l. When a matrix is multiplied by a number or function, each individual 
element is multiplied by that number or function, that is, 
(l-8.2a) 
c(b/) = (eh/'). 

116 
THE ALGEBRA OF VECTORS 
2. The sum of two matrices is a new matrix, the elements of which are 
sums of corresponding elements of the original matrices. 
( l -8.2b) 
(b/) + (c/) = (b/ + cl). 
According to (1-8.2b), matrix addition has meaning only when the two 
matrices involved have the same number of rows and the same number of 
columns. 
The law of multiplication for matrices is analogous to the rule for 
determinant multiplication. If the matrices are square, there is no dis­
tinction. 
3. The product of two matrices (b/) and (c/) (note that the number of 
columns of (bki) must agree with the number of rows in (c/)] is a new 
matrix (bkic/), summed on j. The product matrix may also be written in 
the form BC. 
Definition 1(.2. 
A matrix whose elements are zero is called a zero 
matrix. 
It is important to have the meaning of the equality sign, as used in 
connection with matrices, clearly in mind. 
Definition 1(.3. 
Two matrices A and B are equal if and only if 
a/= b/, 
Clearly two matrices cannot be equal unless they agree with respect to 
numbers of rows and columns. 
Example 1-8.2. 
As an illustration of matrix multiplication consider 
Then 
1 
2 
-;} 
(b,
 
= ( 
0 
-1 
-3 
0 
(
2+ 8+18) 
(b,/c
;
») = 
-4 -12 
, 
-6 +24 
(c
;
-m 
= [-::l 
Matrix multiplication is not defined in other situations than that 
indicated by 3. Therefore consideration of the foregoing example leads 
to the observation that this type of multiplication is another illustration of 
a noncommutative process. 
In Example 1-8.2 there is no meaning to CB, since the number of 
columns of (c/) does not agree with the number of rows of (b/). However, 

The algebra of matrices 
117 
the noncommutivity of the binary operation does not depend on this cir­
cumstance. Even if both matrices were square, we could not expect the 
product to commute. This fact is pointed out by the following simple 
example. 
Example 1-8.3. 
Let 
Then 
whereas 
(b .k) 
= (1 
, 
0 
(bkiC .P) 
= (2 
, 
0 
(c/bl) 
= G 
). 
(c/) 
= G )-
)· 
:)· 
The two resultant matrices are clearly not equal; therefore 
BC-:P. CB. 
Example 1-8.4. 
If the product of two real numbers is zero, then it 
follows that one or both of the numbers is zero. The cross product of 
two vectors is an example of a binary operation which does not share this 
property. 
If the cross product P x Q 
= 0, it is possible that neither 
P nor Q is zero but rather that P is proportional to Q. 
The matrix operation of multiplication presents another example of a 
type of multiplication such that 
AB= 0, 
but neither A nor B is necessarily zero. 
This fact is illustrated by the 
following: 
( )(-: -:) = ( )· 
The zero matrix is a rather special type. 
Others are introduced in the 
next two definitions. 
Definition 1-8.4. 
The square matrix (<5/) is called the identity matrix. 
Let the symbol I denote this matrix. Then 
I = ( <5/) 
= ( ..  .  . . . ) . 
0 
... 
0 
1 

118 
THE ALGEBRA OF VECTORS 
Definition 1-8.5. 
The matrix A' obtained from A by interchanging rows 
and columns is called the transpose of A. 
A number of interesting facts are concerned with these special matrices. 
Some of the ideas relating to them have been touched on previously in 
terms of the index notation. For example, the Kronecker delta, used to 
introduce the identity matrix, has been a standard tool. 
The following theorems and examples illustrate both properties of the 
special matrices and their relation to the development of preceding 
sections. 
Theorem 1-8.1. 
Transpose matrices are subject to the following sum 
and product rules: 
(1-8.3) 
(a) 
(A + B)' = A' + B'. 
(b) 
(ocA)' 
= ocA'; 
oc is a real number. 
(c) 
(AB)' 
= B'A'. 
PROOF. 
The first two proofs are left to the reader. To prove (l -8.3c), 
let 
where c'Pk =a/bland cP are the elements of the transpose of C. Then, 
starting with the right-hand side of (1-8.3c), we have 
This completes the proof. 
Example 1-8.Sa. 
The identity matrix is its own transpose. 
Example 1-8.Sb. 
The identity matrix commutes with any other square 
matrix of the same order, for 
Definition 1-8.6. 
The inverse A-I of a square matrix A is a matrix that 
satisfies the conditions 
(1-8.4) 
AA-I = A-IA = I. 
Theorem 1-8.2. 
If the determinant of a square matrix A is different 
from zero (i.e., a = la/I -:F 0), the inverse matrix has elements 
A/ = cofactor a/ in I a'P qi . 
a 
PROOF. 
This result was obtained in Section 3. [See (1-3.17).] 

The algebra of matrices 
119 
Example 1-8.6. In rectangular Cartesian rotations the inverse of the 
matrix of transformation coefficients is the same as the transpose. In 
Section 3 it was shown that 
Example 1-8.7. Suppose that Xi, Xi, Xi are coordinates of rectangular 
Cartesian systems with a common origin. In Section 5* it was pointed 
out that the transformations relating such systems determined a trans­
formation group. These fundamental group properties are satisfied by 
the matrices associated with the transformations. In fact, this statement 
is nothing more than a shift in emphasis from the transformations to the 
arrays of transformation coefficients. In particular, if the transformations 
are denoted by 
and A, B, C represent the corresponding matrices, it can be shown that the 
matrices satisfy the group properties. (See Definition 1-5*.1.) We 
illustrate with the closure property. Suppose that (a/), (b/) were orthog­
onal transformation coefficients and cik = a/b/. Then 
3 
3 
3 
 c.kc.P =  a.ib.ka.qb P =  a.1a.qb.kb P 
: i t 
: ,
,
,
q 
k
t
t
3
Q
 
i=l 
il 
i=l 
= (jiqbjkbqp = <Jk1l. 
The corresponding proof in matrix notation would appear as follows. 
We have (as a translation to matrix form of (l-3.21h) 
A'A = I, 
B'B= l, 
where the ' indicates inverse as well as transpose. Therefore 
C'C = (AB)'(AB) = B'A'AB = B'JB = B'B = I, 
as was to be shown. 
Definition 1-8.7. The set of coefficients oftransformation(b/)associated 
with a pair of Cartesian coordinate systems is called a rotation matrix. 
The (a/) associated with rectangular Cartesian systems is called an orthog­
onal rotation matrix. 
In studying Section 3 the reader may have been impressed with the 
seeming difficulty of even making up a specific example of an orthogonal 
rotation matrix. 
The nine cosiees, a/, must meet the rather stringent conditions 
3 
1 a/ a/ = (jik• 
a= 1. 
i=l 

120 
THE ALGEBRA OF VECTORS 
However, construction of examples is made quite easy by the process of 
successive transformations mentioned in example (1-8.7). A two-dimen­
sional rotation is dependent on only one angle, hence is simple to 
determine. By carrying out successive plane rotations, three-dimensional 
transformations can be accomplished. 
Example 1-8.8. Plane rotations 
0 
0 
1 
.j3 
-
0 
1 
.j3 
2 
2 
0 
-
2 
2 
-/3 
1 
-.J3 
2 
2 
0 
1 
0 
-
2 
2 
0 
0 
1 
give rise to the three-space rotation 
1 
.J3 
0 
2 
2 
1 
.J3 
-
4 
4 
2 
3 
-.J3 
1 
4 
4 
2 
The question whether any orthogonal rotation matrix can be obtained 
as a product of plane rotation matrices naturally arises. This question is 
answered by the following theorem. 
Theorem 1-8.3. Any orthogonal rotation matrix can· be obtained as a 
product of not more than three plane orthogonal rotation matrices. 
PROOF. It must be shown that any orthogonal rotation matrix D can 
be obtained according to the following relation: 
(1-8.5) ('d/ d12 d13) .(1 
0 
0) [(b/ 0 b13) (c/ c12 
d/ d22 d23 = 0 a22 a23 
0 
1 
0 
c2
1 c22 
d/ d32 d33 
0 a32 a33 
b/ 0 b33 
0 
0 
There is no claim that the representation in (1-8.5) is unique. 
The orthogonality conditions (1-3.21a,b) are not independent. There­
fore only one set should be considered in determining the number of 
parameters of d/ that are independent. There are six conditions imposed 

The algebra of matrices 
121 
on nine unknowns d/'; hence choice of an appropriate triple of the d/' 
along with the orthogonality conditions determines the set. 
This means that we must show that knowledge of an appropriate three 
of the d/ determines the second-order matrices A, B, and C. 
A first step in this procedure is to carry out the multiplication on the 
right of (l-8.5). We obtain 
By definition of matrix equality 
(l-8.6b) 
b11C12 
a22c22 + a28b/c12 
a32C22 + a3
ab3
1C12 
Each of the three matrices A, B, C must satisfy the orthogonality conditions 
(l-3 2la,b,c). By substituting d13 for b13 the elements of the first row of 
(l-8.6a) are seen to satisfy the relation 
(l-8.6c) 
But 
Therefore 
and 
(1-8.6d) 
If we employ the orthogonality conditions to which B is subject, we can 
determine ba
1, b13, and b33 up to sign. The elements of C can be evaluated 
by assuming knowledge of a second valued/. For example, from (1-8.6a) 
Therefore 
(l-8.6e) 
The other elements of C are obtained as a result of the orthogonality 
conditions. 
Finally, a third value d/' leads to the determination of the 
element of A. The e's must be chosen so that each of the matrices A, B, 
C has a determinant with value +I. This completes the proof. 

122 
THE ALGEBRA OF VECTORS 
Problems 
1. Make up an example of a matrix from everyday life. 
2. (a) Add the matrices 
A=(  ; :) B=( : )· 
-2 
0 
6 
0 
-1 
2 
(b) Can the matrices be multiplied? 
(c) Determine the product AB if it exists. 
3. Find the rotation matrix obtained as a product of 
v2 
-v2 
1 
0 
0 
2 
2 
0 
v3 
v2 
v2 
0 
2 
2 
2 
2 
0 
v3 
0 
0 
1 
0 
2 
2 
4. Show that the matrices of Problem 3 do not commute; hence rotations are 
not commutative. 
5. Is the determinant of the product of two square matrices equal to the product 
of the determinants of the matrices ? 
6. Show that an arbitrary three-space rotation cannot be obtained by means of 
two plane rotations. 
Hint: Set up the product (a/)(b/) = (d/) where the matrices on the left 
represent plane rotations. Show that three values (d/) cannot be arbi­
trarily determined. 
7. Write Xi = aki :Xk in matrix form. 

chapter 2 the differentiation of vectors 
1. The Differentiation of Vectors 
In this chapter many of the ideas of the differential calculus are amal­
gamated with the algebraic theory of vectors previously presented. From 
a modern-day viewpoint two concepts, limit and function, assume 
fundamental importance in its development. The reader who has been 
subjected to a rigorous course in calculus is aware of the inherent 
difficulties associated with these ideas. Indeed, the difficulties are not 
peculiar to beginning students alone. Isaac Newton (1642-1727, English) 
and Gottfreid Wilhelm Leibniz are given the principal credit for the 
origination and compilation of the basic concepts of differential calculus. 
Leibniz originated the term function. Yet, according to the standards of 
our time, neither had a clear idea of the meaning of either function or limit. 
The same can be said of a host of other outstanding mathematicians 
[e.g., Leonard Euler (1707.,.1783, Swiss)] who lived in the eighteenth 
century. 
In fact not until the nineteenth century and the advent of a 
serious study of the foundations of analysis did the limit concept receive a 
rigorous treatment. Then Augustin Cauchy (1789-1857, French) and his 
contemporaries began a study of the foundations that has extended into 
the twentieth century. 
The first section in this chapter deals with functions of one variable and 
their differentiation. Because the meaning of the term function has gone 
through a long evolutionary process and is still used with various shades 
of meaning, a formal statement of the meaning of the term as applied in 
this book is presented. The concept is employed with this significance 
throughout the notes. 
123 

124 
THE DIFFERENTIATION OF VECTORS 
xi 
(a) 
x2 
(b) 
Fig. 2-1.1 
xs 
(c) 
Definition 2-1.1. 
A function/is a set of ordered pairs, no two of which 
have the same first element. The set of first elements of the pairs is called 
the domain of the function, whereas the set of second elements of the pairs 
is called the range. The domain and range elements are related by a given 
rule. 
In this section the domain is either the set of real numbers or some 
subset of real numbers. The independent variable representing the domain 
elements is often referred to as a parameter. (See Figs. 2-la,b,c.) 
Example 2-1.1. 
The following three functions will be useful in the 
future for illustrative purposes. The symbol t is used to represent the 
parameter in each instance. 
(a) Domain: the set of all real numbers. 
Rule: 
X1(t) =cos t. 
Range: 
the set of values X1(t) such that -1 !5: X1(t) !5: 1. 
(b) Domain: the set of real numbers. 
Rule: 
X2(t) = sin t. 
Range: 
the set of values X2(t) such that -1 !5: X2(t) !5: 1. 
(c) Domain: the set of real numbers. 
Rule: 
X3(t) = ltl. 
Range: 
the set of values X3(t) such that X3(t) ;;:: 0. 
From a geometric standpoint, the main interest of this section centers 
around curves in Euclidean three-space. It is assumed that the analytic 
forms for these curves are expressed with respect to a rectangular Cartesian 
coordinate system. 
The kinematical viewpoint of the path traced by a moving particle 
presents us with an intuitive representation of a curve. The following 
three-part definition gives a preciseness to the meaning of the concept. 

The differentiation of vectors 
125 
Definition 2-l.2a. 
Let functions X1, X2, and X3 have continuous 
derivatives of order l, at least, on a closed interval a s t s b. Suppose 
that the first derivatives are not simultaneously zero. Then the rep­
resentation 
(2-1.la) 
j = l, 2, 3 
is saidto be an allowable parameter representation. 
Definition 2-l.2b. 
Suppose that a function 
(2-l.lb) 
t = t(t*) 
'is defined on an interval a* s t* s b* with corresponding range values 
in a s t s b and such that t(a*) = a, t(b*) = b or t(a*) = b, t(b*) = a. 
If the function in (2-l. lb) has a continuous first derivative, at least, which 
is different from zero everywhere on a* s t* s b*, then (2-1.lb) is said 
to be an allowable parameter transformation. 
Definition 2-l.2b makes it possible to construct equivalence classes of 
allowable representations. Two representations are said to be in the same 
equivalence class if they are related by a transformation satisfying 
Definition 2-l .2b. 
Definition 2-l.2c.1 
The set of all points specified by the allowable 
parameter representations of an equivalence class is said to be a smooth 
curve. (Note that a smooth curve is ordered in a certain manner.) 
Quite often a smooth curve2 serves as a mathematical model of the path 
of motion of a physical particle; the parameter t represents time values 
and the coordinates Xi represent the position of the particle. Mathematical 
models of physical motion are developed later in the book and then, as 
just indicated, t should be interpreted as representative of time. However, 
it would be unwise of the reader to allow this connotation to become too 
firmly fixed in his mind. There will be occasions when it will be convenient 
to interpret the parameter otherwise. 
1 See Kreyszig, Erwin, Diferential Geometry, University of Toronto Press, 1959. 
• The definition given is not the most general description of a curve as indicated by 
the adjective "smooth." 
The fact that we are studying the elementary calculus of 
vectors evokes the need for the property of differentiability. It will be found that a 
well-defined tangent at each point of the curve is the geometric manifestation of the 
property. It is cumbersome to continue to attach the word smooth; therefore we shall 
do so only when the emphasis seems useful. The curves in this text are assumed to be 
smooth unless it is specifically stated otherwise. 

126 
THE DIFFERENTIATION OF VECTORS 
The following examples of smooth space curves should familiarize the 
reader with the concept. 
Example 2-1.2. 
A circular helix is represented by the parametric 
equations 
x1 =cost, 
X2 =sin t, 
X3 = t. 
This curve can be thought of intuitively as a spiral on a circular cylinder. 
(See Fig. 2-1.2.) If the domain values t are restricted so that t > 0, a curve 
lying entirely above the X1, X2 plane is obtained. Compare with Example 
2-1.1. The equations 
x1 = cos (t*)3 
X2 = sin (t*)3 
xa = (t*)3 
form another allowable parameter representation of that part of the 
circular helix corresponding to t and t* greater than zero. Note that the 
representations cannot be thought of as in the same equivalence class if 
the domain oft* is extended to include zero for dt/dt* = 0 at t* = 0. 
On the other hand the derivative is different from zero on every closed 
domain of positive t* values. 
Xl 
Fig. 2-1.2 

x2 
The differentiation of vectors 
127 
xi 
Fig. 2-1.3 
Example 2-1.3. 
Parametric equations of an ellipse, in the plane X3 = 0, 
and with its center at the origin are 
X1 = a  cos t, 
X2 = b sin t, 
X3 = 0. 
0 R t < 277', 
If t is interpreted geometrically as a measure of the central angle, then 
0 R t  277' gives rise to the complete ellipse. (See Fig. 2-1.3.) 
In the study of differential calculus we investigate the properties of a 
given curve by examining the behavior of the tangent (i.e., by considering 
the slope function of the curve). Physically it is found that velocity and 
acceleration vectors have a relationship to the path of motion of a particle. 
We prepare the way for a study of these and other considerations by 
introducing the idea of vector and scalar fields with respect to a smooth 
space curve. 
Definition 2-1.3. 
Let X1 = X1(t), t1 R t R t2, represent parametric 
equations of a smooth space curve C. 'Suppose that <I> is a function, 
defined along C, which at any point of C transforms according to the 
scalar law of transformation. (See Chapter 1, Section 4.) Then <I>(X1) is 
the X1 coordinate system representative of a scalar field {<I>} with respect 
to the curve C. 
The function <I> is assumed to be differentiable, and therefore continuous, 
unless otherwise stated. 
Definition 2-1.4. 
Let X1 = X1(t) represent a set of parametric equations 
of a smooth space curve C. 
Let U1 be three functions defined on C. 
Furthermore, suppose that at any point of C the set of three functions 
transform as components of a vector U. Then U is said to represent a 
vector field with respect to C. 

128 
THE DIFFERENTIATION OF VECTORS 
Unless otherwise stated, the functions U1 are assumed to be differ­
entiable. 
Example 2-1.4. 
Let 
where 
Then 
<l>(X1, X2, X3) 
= In (P • Q), 
1 
1 
p = 2L1 + 2l2, 
a 
b 
(X1)2 
(X2)2 
P·Q=
-
+
-
a2 
b2 
is the X1 coordinate system representation of a scalar with respect to the 
orthogonal Cartesian group. 
Since P • Q is a scalar, it follows that 
In (P • Q) is a scalar. 
If P • Q is defined along the curve C of Example 2-1.3, <I> = 0 at every 
point of C; that is, the scalar field is constant over C. 
Example 2-1.5. 
Let a space curve C be given by parametric equations 
Let 
X1 = t, 
0 2 t 3 I, 
x2 = (1)2, 
X3 = 0. 
V1 = I , 
V2 = 2X1, 
U3 = 0. 
The curve is the segment of the parabola X2 = (X1)2 defined on the 
interval 0 2 X1 2 1. (See Fig. 2-1.4.) Since U2/U1 = 2X1 (i.e., the slope 
of the tangent line at any point of the parabola), it follows that the vector 
field U is a tangent vector field along C. 
The tools of elementary calculus suffice for exhibiting the derivative 
properties when dealing with scalar fields. 
If <I> is thought of as a function constructed from <I> = <l>(X1, X2, X3) 
and X1 = X1(t), the ordinary definition of derivative may be employed; 
that is, if <I> is differentiable, 
(2-l.2a) 
d<l>(t) = lim <l>(t + 4t) - <l>(t) ·I 
dt 
4t .. o 
4t 
On the other hand, when <I> is treated as a composite function <I> = <l>[X1(t)], 
(2-l.2b) 
d<l> 
o<l> dX1 
o<l> dX2 
o<l> dX3 
o<l> dX1 
dt 
= 
ax1 dt + ax2 dt + oX3 dt 
= 
ax1 dt . 

x2 
Fig. 2-1.4 
The differentiation of vectors 
129 
The d/dt notation of Leibniz predominates throughout these notes. 
Example 2-1.6. 
Consider the scalar P • Q of Example 2-1.4. Suppose 
that a curve is given by parametric equations 
Then 
x1 = cos t, 
o ::;; t :::;; 7T, 
X2 =sin t, 
X3= 0. 
<l>(X;(t)) = ln ((X1)2 + (X2)2) = ln (cos2 t + sin2 ') 
a2 
ba 
a2 
b2 
is a scalar field along the curve. (See Fig, 2-1.5.) The derivative of the 
scalar field can be calculated from either the middle or the last member 
of the foregoing relation. If we differentiate the last member, we have 
d<I> = 
1 
( -2 cos t sin t + 2 sin t cos ') 
dt 
[(cos2 t/a2) + (sin2 t/b2)] 
a2 
b2 
_ 2 cos t sin t(a2 - b2) 
-
b2 cos2 t + a2 sin2 t 
· 
The process of differentiating a vector field, defined along a curve C, 
is an immediate abstraction from that of scalar field differentiation. 
Definition 2-1.S. 
Let U represent a vector field along a curve C. When 
the limit exists 
(2-1.3) 
dU = lim U(t + Pt) - U(t) 
dt 
4t->O 
Pt 
is called the derivative of the vector field U. 

130 
THE DIFFERENTIATION OF VECTORS 
x2 
Fig. 2-1.5 
If the elements of the n-tuple basis to which U is referred are constants, 
as are Li. L2, and L3, the differentiation (2-1.3) can be carried out component 
by component. We have 
I. 
U(t + At) - U(t) 
Im """"--'--,-- 
4t-+O 
At 
[U1(t + At)L1 + U2(t + At)L2 + U8(t + At)Ls] 
- [U1(t)L1 + U2(t)L2 + U3(t)La] 
= lim 
---------&----'-'-"-----""'""
-'( 
4t-+o 
At 
1. {[U1(t +At) - u1(t)]L1 
[U2(t +At) - u2(t)]L2 
= lffi 
+ -=-)-*
-----'-"'" 
At-+o 
At 
At 
+ [U8(t + At) - U8(t)]L3} 
At 
_ [i· u1(t + At) - u1(t)]. + · u2(t + At) - u2(t)] 
-
* 
4 
* 
4 
4t-+o 
At 
t-+o 
At 
dU1 
dU2 
dU3 
= - L1 + - L2 + - L3. 
dt 
dt 
dt 
+ [tim us(t + At) - ua(t)]La 
At->o 
At 
In other words, for a constant basis L1, L2, L3 
(2-1.4) 
dU 
dU1 
dU2 
dU3 
dU1 
- = - L1 + - Ls + - La = - L;. 
dt 
dt 
dt 
dt 
dt 

U(t) 
Fig. 2-1.6 
The differentiation of vectors 
131 
U(t + -t) 
The derivation of the relation (2-1.4) depended on two important facts. 
First of all the vectors V(t + t) and U(t) were compounded in a com­
ponentwise manner. This procedure is justified by the fact that the basis 
is independent of the curve point under consideration. Second, the basis 
n-tuples were not affected by the limiting process. (See Fig. 2-1.6.) 
In a Euclidean space a constant n-tuple basis may always be introduced. 
Therefore there is meaning associated with the difference V(t + t) - V(t) 
and with the vector field derivative dV/dt as defined in (2-1.3). If the 
space is not Euclidean, a re-examination of the derivative concept is 
necessary. However, even in a Euclidean space, if systems of representation 
are used in which the basis is not constant, the basis elements enter into 
the differentiation process and (2-1.4) is not valid. 
According to (2-1.4), whenever a vector field U is referred to a rectan­
gular Cartesian coordinate system, and more to the point, to the associated 
orthogonal unit basis L1, L2, L3, the vector field differentiation is a component­
by-component differentiation. An immediate consequence of this is that 
the usual laws for differentiation of sums and products carry over from 
calculus. This information is formally set forth in the following theorem. 
Theorem 2-1.1. 
Let U and V be differentiable vector fields defined on a 
curve C. Then 
(2-1.5) 
(a) d(U + V) = dV 
+ dV ' 
dt 
dt 
dt 
(b) 
(c) 
(d) 
dV 
• V = (dU) 
• V + U 
• (dV), 
dt 
dt 
dt 
dV x V = (dU) x V + U x (dV), 
dt 
dt 
dt 
dfU 
= (dl)v + / (du). 
dt 
dt 
dt 

132 
THE DIFFERENTIATION OF VECTORS 
PROOF. 
Our considerations assume the framework of a rectangular 
Cartesian coordinate system and a constant unit orthogonal basis L1, L2, 
and L3• 
Therefore the properties in (2-1.5) follow immediately from the 
corresponding elementary properties concerning derivatives of functions. 
To illustrate this fact, consider (2-l.5c). In order to facilitate use of the 
summation convention, let U1 = {J1kUk and V1 = {J1kVk = V1. Then 
d(U x V) = !!_ (l E11;kU. v;) = l E11ik !!_ (U v;) 
dt 
dt 11 
i k 
11 
dt 
i k 
= l E111k(dU1 v; + U dVk) 
11 
dt 
k 
i dt ' 
dV 
dV 
=-xv+ux-. 
dt 
dt 
The proof of relations (2-1.5a,b,d) is left to the reader. 
Note carefully that the order of U and V must be meticulously observed 
in (2-1.5c). This is because the cross product is anticommutative. In 
(2-l.5a,b,d) the ordering is not so important because the sum and products 
have the commutative property! However, it is worthwhile to form the 
habit of maintaining order. 
The derivative formulas (2-l.5a), (2-l.5c), and (2-l.5d) can be extended 
in the usual manner; that is, for three vectors U, V, and W, (2-1.5a) is 
extended to 
d(V + V + W) = dV + dV + dW . 
dt 
dt 
dt 
dt 
for a set of n vectors U1 • 
· 
· Vn. 
(2-1.6a) 
n 
d!V; ,. dV 
__l:!_ = 2-; . 
dt 
i-1 dt 
Extension of (2-1.5c) involves consideration of the triple vector product. 
Its derivative has the form 
(2-1.6b) d[U x (V x W)] = dV x (V x W) + U x (dV x w) 
dt 
dt 
dt 
+ u x (v x d;'). 
Observe that the cross product is not associative. Therefore the association 
made on the left of (2-1.6b) must be maintained in the right member of 
that expression. The proof of (2-l.6b) is left to the reader. If, in relation 

The differentiation of vectors 
13 3 
(2-1.5d),f is a product of functions, (2-l.5d) can be applied and followed 
by the product formula of elementary calculus with respect to the factor 
df/dt. 
Finally, we observe that there is no meaning to a dot product of more 
than two vectors; hence the derivative formula (2-l.5b) is not subject to 
extension. 
Two questions which may or may not have occurred to the reader are 
asked. 
Assuming that U and V are vectors and f is a scalar, are the 
derivatives expressed in (2-l.5a,c,d) of vector character? Is the derivative 
(2-l.5b) a scalar? These questions are answered for orthogonal Cartesian 
transformations by the following theorem. 
Theorem 2-1.2. 
Let U and V be vector fields along a curve C and 
let f be a s;;alar field along this curve. 
Assume that the derivatives 
(2-l.5a,b,c,d) are well defined on C. Then (dV + V)/dt, [d(V x V)]/dt, 
df U /dt are vector fields on C and (dU · V)/dt is a scalar field on C with 
respect to the group of orthogonal Cartesian transformations. 
PROOF. 
Each proof follows from the fact that the coefficient of trans­
formation are constants. For example, to prove that d(U x V)]/dt has 
vector character (see Theorem 1-7.lb), we simply note that 
3 
-
d(" 
UkVP) 
d! a/&rstO't71 
";kp 
r=l 
dt 
= ----
dt 
a 
de: 
- ·v-i 
= L a/ "rstU· 
r=l 
dt 
In other words, the components of the derivative of the cross product 
satisfy the vector transformation law. It is left to the reader to show that 
the other derivatives satisfy the appropriate vector or scalar transformation 
law. 
One way of studying a curve is by investigating the behavior of the 
tangential field along it. 
This is the viewpoint of differential calculus. 
The question before us is that of extending our analytic tools so that 
curves in three dimensions can be included in these investigations. 
The vector field 
(2-1.7) 
dr 
= Jim r(t + Gt) - r(t) 
dt 
.it-+0 
Gt 
comes to mind for at least two reasons. First of all, in a special case in 
which the curve lies in the X1,X2 plane, the ratio of the components 
dX1/dt and dX2/dt of dr/dt is dX2/dX1• We recognize this derivative as the 

134 
THE DIFFERENTIATION OF VECTORS 
xi 
Fig. 2-1.7 
representative of a slope function. Second, a geometric argument for the 
significance of dr/dt can be made on the basis of Fig. 2-1.7. 
Definition 2-1.6. 
Let a smooth curve C have the vector representation 
r = r(t). Then 
(2-1.8a) 
dr 
= lim r(t + t) - r(t) 
dt 
At-+O 
t 
is called a tangential vector field along C. A line 
(2-l.8b) 
Y = r0 + (dr\ u 
dtlo 
is said to be the tangent line to C at a point P0 of C. The symbols u 
and Y are chosen to represent the parameter values and coordinates, 
respectively, along the line in order to distinguish them from the corre­
sponding entities for the curve. 
The direction of the tangent line at a P 0 of C is unique, but the sense and 
magnitude of a tangential vector depends on the parameterization of the 
curve. (See Fig. 2-1.8.) 
Example 2-1.7. 
Parametric equations of a parabola in the X1,X1 plane 
are 
X1 =I + t2, 
x2 = t, 
X3=0. 

x2 
Fig. 2-1.8 
The differentiation of vectors 
135 
By differentiating, we obtain 
dX1 
- =2t, 
dt 
dX2 
-= 1 , 
dt 
dX3 
-= 0. 
dt 
Therefore the tangent vector field is expressed by 
dt 
-= 2tL1 + L2. 
dt 
The tangent line to the parabola at t = 3 is 
X1 = 10 + 6u, 
X2= 3 + u, 
X3= 0. 
If the parameter t is replaced by v = -t, 
and 
(X1, X2, X3) = (l + v2, -v, 0), 
(dX1 dX2 dXs) 
= (2v -1 0). 
dv ' dv ' dv 
' 
' 
A comparison of these components with those previously determined 
reveals that the change in sign of the parameter corresponds to a change 
in sense of the tangent vector field. 

136 
THE DIFFERENTIATION OF VECTORS 
Fig. 2-1.9 
With few exceptions, intuition adequately guides our notions concerning 
tangent lines to plane curves. 
However, visualization of space-curve 
tangents is not always so easy. Our intuition is helped by the discovery 
that, roughly speaking, the tangent line at a curve point P0 lies in a plane 
determined by P0 and two neighboring curve points. In the following 
paragraphs the equation of the plane is developed, and it is shown that the 
tangent lies in it. (See Fig. 2-1.9.) 
Let r0 = r(t0) be a position vector with end point P0 on C. Let r(t0 + h), 
r(t0 + k) have end points on C in a neighborhood of P. If r(t0 + h) - r0 
and r(t0 + k) - r0 are linearly independent, they determine a plane 
through P. This plane is also determined by a pair of linear combinations 
of the two vectors. In particular, choose 
1 
1 
- [r(t0 + h) - r0] - - [r(t0 + k) - r0] 
r{t0 + h) - r0 h 
k 
h 
h - k 
If we use the Taylor expansion3 for r(t0 + h) and r(t0 + k), these ex­
pressions can be written 
r(t0 + h) - r0 
, + ,, 
= r0 
ro 
h 
1 
1 
h -+ .... 
2 
- [r(t0 + h) - r0] - - [r(t0 + k) - r0] 
h 
k 
= r& + 
h + k r,,, + ... 
h - k 
2 
3! 
0 
where the prime denotes differentiation with respect to t. Ash -+ 0, k - 0, 
the two vectors approach r', tr(. If r' and r) are linearly independent, 
then r' x r" is perpendicular to their plane. 
These remarks serve as 
background for the following definition. 
1 This development assumes the existence of higher ordered derivatives of r. 

The diferentiation ofvectors 
137 
Definition 2-1.7. 
The plane 
(2-1.9) 
(R - r0) • r! x r" = 0 
is called the osculating plane of a curve C at a point P. R represents a 
position vector whose end point assumes values (X1, X2, X3) associated 
with the plane points. 
The word osculating, which means kissing, was introduced by Tinseau 
around 1780. The term is appropriately chosen, for the plane (2-1.9) is 
the plane of closest contact with C in a neighborhood of P0• This fact can 
be established by introducing the concept of order of contact. 
Such 
studies are traditionally a part of differential geometry and are not further 
pursued in this book. 
The relation (2-1.9) can be put into the form 
xi - Xo1 x2 - Xo2 xs - Xos 
(2-1.10) 
(dX1) 
dt 0 (dX2) 
dt 0 
(dX3) 
dt 
0 
=0. 
(d2X1) 
dt2 0 (d2X2) 
dt2 0 (d2Xa) 
dt2 0 
It is clear that a curve Chas a unique osculating plane at a point P0 if 
and only if r# and r$ exist and are linearly independent. 
Theorem 2-1.3. 
Let P0 be a point on a curve Cat which there is an 
osculating plane. The tangent line to C at P lies in the osculating plane. 
PROOF. 
If the vector representation of the curve is r = r(t), the tangent 
line may be represented by 
y = ro + (dr\u, 
dt!o 
where the zero subscript implies evaluation at P0• 
It is seen by direct 
substitution of 
into (2-1.9) or (2-1.10) that the tangent line lies in the osculating plane. 
Problems 
1. Construct a diagram of the curve represented by these parametric equations: 
(a) X1 = cosh t, X2 = sinh t, X3 = t, t + 0. 
(b) X1 =a cost, X2 =a sin t, X3 = e1, t :2:: 0, a > 0. 
(c) X1 =a cost, X2 =a sin t, X3 = e81D1, t + 0, a > 0. 

138 
THE DIFFERENTIATION OF VECTORS 
2. Suppose that a line segment with end points (2, 3, 1) and (5, 7, 9) represented 
the path of an oscillating particle. Complete the mathematical model by 
finding a possible set of parametric equations for the motion. 
3. Determine the tangent vector field dr/dt along each of the curves of 
Problem 1. 
4. Find the derivatives of the scalar fields r • (dr/dt) associated with each curve 
of Problem 1. 
5. Prove the differentiation rules (2-1.Sa,b,c,d) directly from definition; that is, 
in (2-1.Sa,c,d) start with (2-1.3) and use the methods employed in an 
elementary calculus class rather than the results of function differentia­
tion. 
6. If A = cos tL1 + sin tL2 + t2L3, B = sin tL1 +cos tL2 + fL3, 
(a) find (dA • B)/dt in two ways; 
(b) find (dA x B)/dt in two ways. 
7. A vector field V has a constant magnitude, that is, V • V =constant for all t. 
Show that if dV/dt Ji 0 it is perpendicular to V. 
8. A third-order determinant 
Al 
A2 
Aa 
B1 
B2 
Ba 
c1 
c2 
C3 
can be represented in either of the forms 
A• B x C = &mA'BICk. 
Assume that the vectors A, B, and C are differentiable functions along 
some curve and show that the derivative of the determinant is given as 
follows: 
Al 
A2 
A3 
dA1 
dA2 
dA3 
d 
dt 
dt 
dt 
Bl 
B2 
Ba 
B1 
B2 
Ba 
dt 
c1 
c2 
ea 
c1 
c2 
ea 
A1 
A2 
Aa 
Al 
A2 
Aa 
dB1 
dB2 
dB3 
Bl 
B2 
B3 
+ dt 
dt 
dt 
+ 
dC1 
dC2 
dC8 
c1 
c2 
ea 
dt 
dt 
dt 
9. Determine parametric equations of the tangent line to the elliptic helix 
x1 = 2 cost, 
X2 = 3 sin t, 
X8 = t 
at (v2, 3/v2, '1'/4). Also find the equation of the osculating plane at this 
point. 

Geometry of space cunes 
139 
10. In Example 2-1.6 find components of P and Q in a system with coordinates 
X; if Xi = Ak; Xk and 
v3 
1 
2 
2 
0 
(Aki) = 
-1 
v3 
2 
2 
0 
0 
0 
1 
How is the scalar cf> expressed in the barred system? 
11. Find the tangent line to 
x1=1, 
x2 =,a, 
X3 =0, 
at (0, 0, 0). 
12. Find the osculating plane at a point P 0 for each of the curves of Problem 1. 
2. Geometry of Space Curves 
The purpose of this section is to extend the discussion of geometric 
concepts concerning space curves, begun in Section l. 
These ideas are 
used, at least in part, to construct mathematical models of physical 
phenomena. 
The discussion is facilitated by the introduction of the 
concept of length of a space curve. Recall that a smooth space curve C 
is algebraically represented by functions with continuous derivatives that 
are not simultaneously zero. 
Theorem 2-2.1. 
Suppose that the finite smooth space curve C were 
represented algebraically by functions X1 = X1(1) 10 , I , 111• 
Then a 
number L, given by the following formula, can be associated with C. 
(2-2.1) 
itp ( . 
dX1 dXk ) 
L= 
<J1k--
dt, 
to 
dt 
dt 
where Xo' = X1(10) and X/ = X;(t11), respectively, represent the co­
ordinates of the initial and terminal points of C. 
PROOF. 
A partition (10, ···,In) of the common domain of the functions 
X1 (see Fig. 2-2.1) gives rise to a partition [Xk(t0), • 
• 
• , Xk(tn)l of C. 
A polygonal path is determined by joining the points of the partition on 
C by straight-line segments. Denote the length of this path by Ln. Then 
(2'72.2a) 
where 
(2-2.2b) 
" 
L,. = ! ( <>ka t:.x / t:.x />1', 
i-1 

140 
THE DIFFERENTIATION OF VECTORS 
to 
Fig. 2-2,1 
According to the mean value theorem for derivatives, 
(2-2.2c) D.Xl = Xk(t;) - Xk(t;_1) = dXk (7}) D.t, 
dt 
x" 
p 
Since the derivatives are continuous on closed intervals, (2-2.2c) can be 
replaced by 
(2-2.2d) 
that is, the intermediate domain values 7' 1 k, where j and k denote dependence 
on the subinterval of the partition and the particular function, respectively, 
can be replaced by values 7'; which depend only on subinterval of the 
partition.4 When the expression (2-2.2d) is substituted into (2-2.2a), we 
obtain 
(2-2.2e) 
Then, as refinements of the partition (t0, • 
• 
• , 111) are taken, hence with 
corresponding refinements of (X0i, · 
· 
· , X11i), the continuity of the 
functions on closed intervals implies that the summations involving e terms 
approach zero. In the limit we obtain a number given by (2-2.1). This 
completes the proof. 
Definition 2-2.1. 
The number 
L = ftv ({)1k 
dX; dXk')) 
dt 
J1o 
dt dt 
is called the length of the smooth space curve C. 
' The theory relating to continuity of a function on a closed interval (i.e., Wniformly 
continuous function) is properly a part of advanced calculus. It is assumed in this text 
without proof. (See Angus E. Taylor, Advanced Calculus, Ginn, 1955.) 

Geometry of space curves 
141 
The vector field dr/dt associated with a curve C was investigated in 
Chapter 2, Section 1. We found that dr/dt was a tangential vector field 
along C and that in many circumstances it is advantageous that it have a 
constant magnitude of 1. This property can be brought about by rep­
resenting the equation of the curve in terms of a parameter whose values 
represent arc lengths from a fixed point P0 of C to Pon C. This parameter 
is denoted by the symbol s. 
Theorem 2-2.2. 
If C is represented by functions whose domain values 
represent arc lengths s, then dr/ds is a unit tangent vector field. 
PROOF. 
From (2-2.1) it follows that 
(2-2.3a) 
Therefore 
(2-2.3b) 
it11 (dr dr)l-i 
s = 
-·-
dt. 
to dt dt 
ds 
= (dr . dr)J.i
. 
dt 
dt dt 
Ip. other words, ds/dt is the magnitude of the tangent vector field dr/dt. If 
t = s, this magnitude is 1. This completes the proof. 
The properties of space curves to be pointed out in this section constitute 
only a small fragment of those intensively investigated in the nineteenth 
century. Joseph Liouville (1809-1882, French) and several of his associates 
made a thorough study of curves and surfaces by using the methods of 
analysis. The major features of their study of space curves can be developed 
nicely by the introduction of an orthogonal triad of unit vector fields on a 
curve C. 
The primary field of this triad is the unit tangent field dr/ds. 
The other two members of the set, and some concepts which naturally 
appear during their introduction, are represented by the following theorems 
and definitions. 
For simplicity of notation let us use the symbol t in place of the unit 
tangent field dr/ds along C. 
Theorem 2-2.3. 
If dt/ds ':;6 0, 
(2-2.4) 
1 dt 
n = --
where 
K ds 
K = (dt . dt) ).-2 
ds ds 
is a unit vector field orthogonal to t for all s. 
PROOF. 
Because t is a unit vector field for alls, we can write 
(2-2.5) 
t·t=l. 
By differentiating this expression, we see that t and dt/ds are orthogonal, 
for' 
(2-2.5b) 
dt 
t·-= 0. 
ds 

142 
THE DIFFERENTIATION OF VECTORS 
Since the factor K represents the magnitude of dt/ds, it follows that n is also 
a unit vector field. 
Definition 2-2.2. 
The vector field n defined on a curve C is called the 
principal normal field on C. 
In a plane there is only one direction perpendicular to a given direction. 
However, in three dimensions the situation is quite different; there is a 
plane of directions perpendicular to a given direction. Therefore there is 
reason to give a special name to a chosen one of the set of vectors or­
thogonal to t. The following theorem gives still greater meaning to the 
designation of the vector field n of Definition 2-2.2 as the principal normal 
field. 
Theorem 2-2.4. 
At each point of C the principal normal n lies in the 
osculating plane. 
PROOF. 
In Chapter 2, Section 1, it was seen that the equation of the 
osculating plane at a point P0 of C could be put in the form 
xi - Xo1 
X2 - Xo2 
X3 - Xos 
(2-2.6a) 
( dX1), 
ds o 
( dX2), 
ds o 
( dX3), 
ds o 
=0. 
( a2x1), 
ds2 o (a2x2), 
ds2 o (d2Xs), 
ds2 o 
Parametric equations of a line through P0 and with the direction of n are 
(2-2.6b) 
y1 = Xoi + (d2X;), u. 
ds2 o 
We see immediately that the coordinates of any point on this line satisfy 
(2-2.6a). This completes the proof. 
According to this theorem, the osculating plane, or, intuitively speaking, 
the plane that comes closest to containing the part of the curve in a 
neighborhood of P0, is the plane of the tangent vector t and the principal 
normal n. 
The magnitude K of the principal normal is significant in itself. Roughly 
speaking, dt/ds is the change in the tangent vector t caused by a change in 
the arc length values. Since t is a unit vector, this change deals with the 
direction of t. 
Definition 2-2.3. 
K = ldt/dsl is called the curvature of C at the point P 
with coordinates X1(s). 
# 

Geometry of space curves 
143 
Example 2-2.1. 
Consider a straight line with the vector representation 
r = r0 + Bs, 
IBI = I, 
where B is a vector constant. By differentiating, we obtain 
Therefore 
t = dr =B. 
ds 
dt = 0. 
ds 
Hence the curvature, K, of a straight line is zero at every point of the line. 
Example 2-2.2. 
A circle of radius a can be represented by the vector 
form 
s 
. 
s 
r = a cos - 11 + a sm - 12, 
a 
a 
where a is the radius of the circle and 11, 12 is a pair of orthogonal unit 
n-tuples. Then 
Hence 
dr 
. 
s 
s 
t = - = - sm - 11 + cos - 12, 
ds 
a 
a 
dt 
1 ( 
s 
. s ) 
- = - -
cos - 11 + sm - L2 
• 
ds 
a 
a 
a 
1 
1 
(2-2.7) 
K2 = -
K =-. 
a
2' 
a 
Note that, by defining K % 0, n has the same sense as dt/ds. In the 
circle n points inward. (See Fig. 2-2.2.) 
xz 
Fig. 2-2.2 

144 
THE DIFFERENTIATION OF VECTORS 
Examples 2-2.1 and 2-2.2 facilitate a good intuitive grasp of the meaning 
of the curvature K. A straight line has curvature zero at any point. The 
curvature of a circle increases without bound as the radius of the circle 
decreases. 
In general K(s) is a scalar field (with respect to rectangular 
Cartesian transformations) along C. The numerical value K(s) at a point 
of C is small if the curve does not appreciably deviate from the tangent 
line; the number representing K increases as the deviation from the tangent 
line becomes more pronounced. Another way of expressing this idea is to 
say that the curvature of C at a point is the same as that of the circle 
which best fits the curve at that point. 
Indeed, the study of curves by 
examination of the best-fitting circle at each point is a well-developed part 
of differential geometry. 
The concept of curvature, with its associated vector ideas, suffices for a 
study of plane curves. 
However, to describe space curves completely, a 
third unit vector must be introduced. Since t and n are unit orthogonal 
vector fields, the third vector completes the formation of a unit orthogonal 
triad. 
Definition 2-2.4. 
The vector field 
(2-2.8) 
b = t x n 
is called the binormal vector field along C. 
Theorem 2-2.5. 
t, n, b, in that order, form a right-hand orthogonal 
unit triad of vectors at each point of a curve C. 
PROOF. 
b is orthogonal to t and n by definition. Its magnitude of I 
can be computed directly from (2-2.8). The fact that 
I =b·b=b·txn=txn·b=t•nxb 
is also a consequence of (2-2.8). Since the triple scalar product of the last 
member of this expression is equivalent to the determinant oft, n, and b, 
in that order, and since the value of the determinant is greater than zero, 
it follows that the system is right-handed. 
The magnitude of the vector field db/ds also has a geometric significance; 
b is a unit field, so that the change, db/ds, ofb with respect to change in the 
value of s has to do with direction. In this case the deviation in direction 
can be tied in with the variation of the curve from the plane of t and n. 
In particular, we measure the projection of db/ds onto the principal normal. 
Definition 2-2.5. 
r(s) = -n • (db/ds) is called the torsion5 field with 
respect to a curve C. 
6 According to Erwin Kreyszig, op. cit., p. 38, the name "torsion" was introduced by 
L I. de la Vallee in 1825. 
, 

Geometry of space curves 
145 
It is not the purpose of this book to delve deeply into the field of 
differential geometry. Therefore, having introduced the fundamental tools 
used in differential geometry to study smooth space curves, this section is 
brought to a close with a statement of a basic set of relationships. These 
are the so-called Frenet-Serret formulas given by Joseph A. Serret (1819-
1885, French) and F. Frenet.6 
1beorem 2-2.6. 
(Frenet-Serret formulas) 
(a) 
(2-2.9) 
(b) 
(c) 
dt 
- =KD, 
ds 
dn 
- = -Kt + Tb 
ds 
' 
db 
- =-TD. 
ds 
PROOF. 
Relation (2-2.9a) has already been discussed. [See (2-2.4b).] 
To obtain (2-2.9c), first of all note that b · b = l implies (db/ds) • b = 0. 
Hence db/ds lies in the plane oft and n and can be expressed in the form 
(2-2.lOa) 
db 
= ot(s)t + {J(s)n, 
ds 
where ot(s) and {J(s) are unknown. Next note that b • t = 0 implies 
db 
dt 
(2-2.10b) 
t • - = -b • - =-Kb• n = 0. 
ds 
ds 
On the other hand, from (2-2.lOa) we see that 
db 
(2-2.lOc) 
t · - = ot(s). 
ds 
Comparison of (2-2.lOb) and (2-2.lOc) leads to the evaluation 
ot(s) = 0. 
With ot(s) = 0, it follows as a consequence of Definition 2-2.5 that {J = 
-T. 
To prove (2-2,lOb), we note that dn/ds is perpendicular ton, hence can 
be written 
(2•2.10d) 
dn 
- = y(s)t + c5(s)b. 
ds 
e Did<: J. Struik (Concise History of Mathematics, Vol. II, Dover, 1948) attributes the 
French School of mathematicians headed by Liouville with having developed the 
formulas around 1847. On the other hand, Coxeter (Introduction to Geometry, Wiley, 
1961) states that the formulas were presented by Serret in 1851 and Frenet in 1852. 

146 
THE DIFFERENTIATION OF VECTORS 
To evaluate y and c5, we must differentiate both 
t • n = 0 
and 
b • n = 0. 
These differentiations lead to 
dn 
dt 
(2-2.lOe) 
t. -
= -n. - = -KD. n = -K, 
ds 
ds 
dn 
db 
(2-2.lOf) 
b. -
= -n. -
= +TD. n = +T. 
ds 
ds 
By making use of (2-2.IOe,f), we find that 
y(s) = -K(s), 
b(s) = T(s). 
This completes the proof of (2-2.9b). 
In Section 3 we apply some of these ideas in a study of the kinematics 
of motion. 
Problems 
1. Find the length of each of the following space curves: 
 
(a) X1 = t, 
x2 = t2, 
0 ( t ( t. 
I Ans. vi + ! In (v2 + l). J 
(b) X1 =cost, 
X2 =sin t, 
X3 = t, 
0 ( t 0 t'J. I Ans. Y2t'J. J 
2. Express the parametric equations of the circular helix (Problem 1 b) in terms 
of arc length. 
3. Find the magnitude of dr/dt in each of the following cases: 
(a) X1 = 1 + t, 
X2 = t, 
X3 = 0. 
(b) X1 = t, 
X2 = t2, 
X3 = t3• 
(c) X1 = a sin t/a, 
X2 = a cost/a, 
X3 = 0. 
(d) X1 = t, 
X2 = t, 
X8 = sin f. 
4. Does the parameter t represent arc length in any of the parts of Problem 3? 
S. Assume that s and an arbitrary parameter t are functionally related. Further­
more, assume the existence of all necessary derivatives. Show that 
(a) ;: = [ (:. =);: - (:. :):J (:. T
2
· 
d3r 
d3r(dt\8 
d2r dt d2t 
dr d3t 
(b) ds3 
= dt3 ds} + 3 dt2 ds ds2 + dt ds3 • 
6. Using the results of Problem 5 show, that 
2 
_ (dr/dt x d2r/dt2) • (dr/dt x d2r/dt2) 
(a) K 
-
(dr/dt • dr/dt)3 
' 
dr/dt • d2r/dt2 x d3r/dt3 
(b) 
'T 
= (dr/dt x d2r/dt2) • (dr/dt x d2r/dt2) • 

Kinematics 
147 
Hint: In (a) employ the triple vector product and the Lagrange identity, 
Section 7, problem set. 
7. Compute (or comment) K2 and Tin each part of Problem 3. 
8. Compute (or comment) K2 and T if 
(a) X1 = 2 cos t, 
X2 = 3 sin t, 
X8 = 0. 
(b) X1 = cosh t, 
X2 = sinh t, 
X3 = 0. 
(c) X1 = cos 5t, 
X2 = sin 5t, 
X3 = e1• 
9. Find the equation of the osculating plane, the parametric equations of the 
tangent line, and the parametric equations of the normal line to each of 
the curves in Problem 3 at the point corresponding to t 
= 1T/4. 
Let 
a 
= t in (c). 
3. Kinematics 
Kinematics is sometimes called the geometry of motion. 
In this 
approach to mechanics the motion of a physical particle or group of 
particles is represented by means of a mathematical model. The pictorial 
representation of the model plays something of an intermediate role; that 
is, both the physical happening and the corresponding mathematical 
analysis have a common geometric interpretation. 
In this section the motion of a single particle will be studied. 
In a 
kinematical investigation, the particle is idealized as a point. No con­
siderations of mass enter into the discussion. The main objective is to 
describe the motion of a particle by means of a smooth space curve 
(intuitively thought of as traced out by the particle) and then to examine 
the concepts of velocity and acceleration in. terms of this representation. 
Various frames of reference prove to be appropriate for such developments. 
In this section we consider three examples: 
a rectangular Cartesian 
coordinate system and an orthogonal triad of unit vectors which vary 
along the path of motion, a rectangular Cartesian system and the constant 
bases l1, l2, and l3, and polar coordinates in a plane along with an 
appropriate set of basis vectors. 
Definition 2-3.1. 
Let C be a smooth space curve with the vector 
representation r = r(t), where t represents a measure of time. 
Assume 
that at least second derivatives of r exist on C. Then 
(2-3.1) 
v-dr 
a=d2r 
-
dt
' 
dt2
' 
respectively, are called the velocity and acceleration vector fields on C. 
Velocity can be thought of as the rate of change of position with respect 
to time. In the case of one-dimensional motion (say along the X1 axis) 
dr/dt reduces to (dX1/dt, on l1, an expression that might be recognized 

148 
THE DIFFERENTIATION OF VECTORS 
from elementary calculus. Of course, we must realize that direction and 
sense, as well as magnitude, play a part in the present usage of the term 
velocity. Similar remarks hold for the acceleration concept. 
Theorem 2-3.1. 
Let s = s(t) be an increasing differentiable function. 
Then we have 
(2-3.2) 
(a) V = ds 
t = IVI t, I 
dt 
(b) 
PROOF. 
According to Definition 2-3.1, 
(2-3.3) 
V = dr = dr ds 
= t ds 
. 
dt 
ds dt 
dt 
Since t is a unit vector, lds/dtl must represent the magnitude ofV. Because 
s 
= s(t) is an increasing function, ds/dt > 0, and therefore (2-3.2a) is 
proved. 
Relation (2-3.2b) is obtained by differentiating (2-3.2a): 
8 = dV = d2r (ds)2 + dr d2s 
= K
D (ds)2 + t d2s 
. 
dt 
ds2 dt 
ds dt2 
dt 
dt2 
This completes the proof. 
From (2-3.2a) we observe that the velocity vector is a tangential vector. 
The magnitude IVI 
= lds/dtl is usually called the speed. It is interesting 
to note the fact that V is a tangential vector correlates nicely with Newton's 
first law, which indicates that a particle tends to maintain a straight-line 
motion unless outside influence is brought to bear. 
From the relation in (2-3.2b) we learn that the acceleration vector 
always lies in the osculating plane, that is, the plane of the tangent vector 
and the principal normal. 
The reader should also note that the basis t, n, b differs from any we 
have previously considered because the elements t, n, and b are not 
constant. At each point of C the triple of vector fields t, n, and bis a unit 
orthogonal triad, but each element, in general, varies in direction along C. 
Most of the development of these notes has centered around rectangular 
Cartesian coordinates and a basis L1, L2, and L3• In mcy instances it is 
quite convenient to describe the kinematical aspects of particle motion in 
terms of such a system. This description is rather straightforward. 

Kinematics 
149 
The position of the particle is given by the vector representation 
(2-3.4a) 
where 
(2-3.4b) 
Since the basis n-tuples are constants, the rectangular Cartesian rep­
resentations of the velocity and acceleration fields are obtained by 
straightforward differentiations. 
dr 
dX1 
dX2 
dX3 
V = -= - L1 + - L2 + - L3. 
(2-3.4c) 
dt 
dt 
dt 
dt 
(2-3.4d) 
Note that the expressions for velocity and acceleration can also be written 
in the concise forms 
(2-3.4e) 
The following examples illustrate particle motions, as described in 
rectangular Cartesian representations. 
Example 2-3.1. 
Let the motion of a particle be represented by the 
parametric equations 
0  t  I, 
where 
(B1, B2, B3) = (-1, 3, I), 
and e1 is the exponential function. Then 
Furthermore, 
r = (2 - e1)L1 + (I + 3e1)L2 + (3 + e1)L3, 
V = -e1L1 + 3e1L2 + e1L3, 
a = -e1L1 + 3e1L2 + etL3. 
JVJ = -./V • V = -Ju et, 
JaJ =-./a. a= -Ju et. 
Therefore the particle is at (I, 4, 4) at t = 0 and has a speed numerically 
represented by -Ju. (See Fig. 2-3.1.) The acceleration is also indicated 
by -Ju at t = 0. 
The motion is along a straight-line path, with both 
speed and acceleration increasing exponentially. 
Note that both the 
velocity and acceleration vector fields vary in magnitude along the curve 
but are constant in direction. 

150 
THE DIFFERENTJATION OF VECTORS 
I 
I 
I 
I 
I 
/1 
x 
I 
I 
I 
I 
x3 
I 
I 
I 
I 
I 
I 
I 
I 
I 0.4,4> 
I 
}----------x2 
Fig. 2-3.1 
Example 2-3.2. Suppose that a particle moves along the circular helix 
described in Example 2-1.2. Then 
Furthermore, 
and 
r = cos tL1 + sin tL2 + tL3, 
V = -sin tL1 + cos tL2 + L3, 
a = -cos tL1 - sin !L2• 
IVI =)V·V=)2, 
lal = )1, 
V·a =0. 
We observe that the magnitude of the velocity, as well as the magnitude 
of the acceleration field, is constant. Both fields, however, vary in direction 
along the curve. 
Another point of interest is that the velocity and acceleration vectors are 
perpendicular for all t. 
A third way of illustrating kinematical ideas is in terms of a polar 
coordinate system. 
This model represents particle motion which takes 
place in a plane and presents another example of the usage of a non­
constant vector basis. 
A polar coordinate system is constructed by choosing\ pole 0 and a 
polar OP. (See Fig. 2-3.2.) A point is designated by a number pair (p, 0). 

Kinematics 
151 
The parametric equations of a curve are expressed in the form 
(2-3.5) 
p = p(t), 
() = O(t). 
(See Fig. 2-3.3.) As in the preceding discussions, the parametric equations 
are dually interpreted as equations of motion ofa particle and as equations 
of a curve. 
The basis associated with the polar coordinate system consists of the 
pair R, a unit vector with the sense and 
direction of the position vector r, and P, 
a unit vector orthogonal to R. 
Theorem 2-3.2. 
dR/dO is a unit vector 
perpendicular to R. 
PROOF. 
Since R is a unit vector for 
all 0, 
(2-3.6a) 
R·R=l. 
By differentiating with respect to 0, we obtain 
(2-3.6b) 
dR 
2-·R = 0. 
d() 
Therefore dR/d() is perpendicular to R. 
p 
Fig. 2-3.2 
R can be represented in terms of a constant orthogonal basis (with L1 
along OP), as follows: 
(2-3.6c) 
R = cos 0L1 + sin 0L2. 
Therefore 
(2-3.6d) 
p 
dR 
·
o
+ 
0
1
 
-= -sm L1 
cos L2• 
d() 
Fig. 2-3.3 
7 The representations of R and dR/dO in terms of a basis L1 and Lz identifies them as 
Cartesian vectors and therefore justifies the use of the term vector in this discussion of 
polar coordinates. Considerations of a vector as a collection of n-tuples associated 
with nonlinear systems, such as polar coordinate systems, are treated in Chapter 3. 

152 
THE DIFFERENTIATION OF VECTORS 
From (2-3.6d) it can be determined that the magnitude of dR/dO is I. As 
a matter of fact, the orthogonality of R and dR/dO also follows from 
(2-3.6c) and (2-3.6d). This completes the proof. 
Definition 2-3.2. 
R and P = dR/dO are the basis vectors associated 
with a polar coordinate system. 
As a matter of future convenience, the following relations are introduced 
at this time. 
Theorem 2-3.3. 
We have 
(2-3.7) 
d2R 
- = -'R. 
d02 
PROOF. 
When (2-3.6d) is differentiated, we obtain the result 
d2R 
. 
- =-cos (h1 
- sm (h2 = -R. 
d()2 
This completes the proof. 
The expressions for velocity and acceleration of a moving particle can 
be obtained by straightforward differentiation. In the following theorem 
it is assumed that the derivatives exist. 
Theorem 2-3.4. 
The velocity and acceleration vector fields of a particle, 
with parametric equations p = p(t), 0 = O(t), are 
(2-3.8) 
(a) 
V = dp R + p dO 
P. 
dt 
dt 
(d2p 
(d0)2) 
( d26 
dp dO) 
(b) 
a = 
- - p -
R + 
p - + 2 - - P. 
dt2 
dt 
dt2 
dt dt 
PROOF. 
The position of a particle is given by 
r = pR, 
where p is a function with domain t and r is a vector function of a function; 
that is, R depends on 0 and 0 in turn depends on the parameter t. Therefore 
V = dr = dp R + P 
dR dO 
= dp R + 
d() P. 
dt 
dt 
dO dt 
dt 
P dt 
When V is differentiated with respect to t, we obtain a; that is, 
a= d2p R + dp dR dO + dp d() p 
+ p d20 p 
+ p()2 d2R
. 
dt2 
dt dO dt 
dt dt 
dt2 
dt 
d02 

Problems 
153 
Making use of (2-3.7) in the last member of this expression and collecting 
the components of Rand P, we obtain the result (2-3.Sb). 
Example 2-3.3. 
If the acceleration is purely radial, then 
P 
d28 + 2 dp dO = O; 
dt2 
dt dt 
that is (multiplying by an integrating factor), 
and 
 ( 2 dO) = O, 
dt 
p 
dt 
dO 
p2 - = constant. 
dt 
Now the formula for area, as expressed in polar coordinates, is 
Therefore 
area = ! J p2 dO. 
d area 
2 dO 
-- = !p - =constant. 
dt 
dt 
This relation is known as the "law of areas": If the acceleration of a 
particle is always directed toward a fixed point 0, the position vector will 
sweep out area at a constant rate. 
Problems 
1. Suppose that the parametric equations of motion of a particle were given by 
X1 = cos t, 
X2 = sin t, 
X3 = t, 
t * 0. 
(a) Find V, a. 
(b) Show that Vanda are perpendicular for all t. 
(c) Compute 'T. 
(d) Express sin terms oft. 
2. Find V and a if the parametric equations of motion are given as 
(a) X1 = a cos sf a, 
X2 = a sin sf a, 
X3 = o. 
(b) x1 = t, 
x2 = 12, 
X3 = o, 
t * o. 
(c) Find ds/dt in part (b). 
3. Write out the expressions forr, V, a if the parametric equations of the motion 
of a particle are 
(a) X1 = 1 + t2, 
X2 = t, 
X3 = 0. 
(b) x1 = t, 
x2 = ,2, 
xs = ,s. 
(c) X1 = a sin t/a, 
X2 = a cost/a, 
X3 = 0. 
(d) X1 = t, 
X2 = t, 
X3 =sin t. 

1S4 
THB DIFFERENTIATION OF VECTORS 
(e) X1 = 2 cos t, 
X2 = 3 sin t, 
X8 = 0. 
(f) X1 = cosh t, 
X2 = sinh t, 
X8 = 0, 
t > 0. 
(g) X1 = cos St, 
X2 = sin St, 
X8 = et. 
4. If A, B, and w are constants, A and B are linearly independent and 
r = A cos wt + B sin wt 
show that the acceleration vector is directed toward the origin and has a 
magnitude proportional to the magnitude of r. 
5. If the motion of a particle is uniform and rectilinear along a line through 
(X01, X02, X03) and with direction (B1, B2, B8), write down a representa­
tion for the position vector. Then show that the velocity vector is con­
stant and the acceleration vector is zero. 
6. Construct the representation of a motion that traces out the same path as 
that of Problem S, but for which the velocity and acceleration vectors are 
not constants. 
7. The parametric equations of motion of a particle are 
X1 = 3 cost, 
X2 = 3 sin t, 
X3 = t. 
(a) Write down expressions for r, V, and a. 
(b) Construct a unit vector field perpendicular to the plane of r and a 
(for all t). 
(c) Briefly describe the motion. 
(d) What angle does V make with a? 
8. Answer (a), (b), (c) of Problem 7 for a particle with parametric representation 
x1 =et, 
9. Make a proof of 
assuming that 
x2 =et, 
d2R 
d82 = ixR + /3P 
and computing ix and {3. 
X3 =sin t. 
10. Show that the magnitude of the velocity field can be expressed in the form 
IVI = (V. V)+ = [ (!J + p2]
+ I: I· 
11. Find r, V, and a for the motions with the following parametric representa­
tions: 
(a) P = ebt, 
8 = t, 
if 
b > o. 
b <0. 
(b) p = sin t, 
8 
= cost. 
(c) p = cosh t, 
8 = et. 
12. Discuss briefly the nature of the motion in each pa of 11. 

4. Moving Frames of Reference 
Moving frames of reference 
155 
In preceding sections it was assumed that the coordinate systems 
described fixed frames ofreference. In this section transformation relation­
ships between rectangular Cartesian coordinate systems describing 
reference frames in relative motion are investigated. 
A principle of relativity of motion, that is, a statement of the fact that 
the motion of a body has meaning only with respect to surrounding 
bodies, has played a fundamental role in the theoretical development of 
mechanics at least since the time of Newton.8 In particular, Newton, in 
his development of gravitational theory, postulated a principle of relativity 
for bodies in uniform rectilinear motion with respect to one another. 
Today, with man at the threshold of a period of solar and universe 
exploration, mathematical models of bodies in relative motion are of great 
importance. 
Suppose that a frame of reference 0 is assumed fixed and that a frame 0 
is in rotational and translational motion with respect to 0. (See Fig. 2-4.1.) 
Fig. l-4.1 
8 Theoretical knowledge of the nonobjective nature of motion dates back to the 
Greeks. Aristotle defines "place" as the relation of a body to the bodies in its neighbor­
hood. 

156 
THE DIFFERENTIATION OF VECTORS 
Furthermore, let an object P be in motion with respect to 0. A kinematical 
study of the relationships between these bodies can be made by setting up 
the following mathematical model. 
Rectangular Cartesian coordinates g; and X;, respectively, describe the 
systems () and 0. It is assumed that there is a universal time. (This is 
the Newtonian assumption. Its denial leads to Einstein's special theory 
of relativity.) 
(2-4.1) 
t = i. 
Therefore the parametric equations of a particle in motion, that is 
(a) X1 = Xi(t), 
(b) Xk = Xk(t), 
(2-4.2) 
can be expressed in terms of a common domain of values t. 
Our assumption is that the X1 coordinate system is fixed. 
From the 
physical point of view this means that the laws and concepts at the base 
of classical mechanics take on their natural forms when referred to these 
coordinates. In particular, the components of velocity and acceleration 
vectors can be represented as projections on the coordinate axes. Obser­
vations and measurements intrinsic to the X1 system cannot be interpreted 
so simply in general, for the measurements of velocity and acceleration 
exhibit deviations. The outside observer attributes these to the motion; 
the intrinsic observer thinks of them as pseudo-effects. 
To determine 
these effects, we start with the laws of transformation relating the systems 
() and 0. Then appropriate expressions are obtained for velocity and 
acceleration in the moving system by computing the standard forms, 
that is, the first and second derivatives, in the () system. 
According to the results of Chapter I, Section 3, 
(2-4.3a) 
X1(t) = Aki(t) Xk(t) + X01(t), 
where X01 are the () coordinates of the origin of the coordinate system of 0. 
The relation (2-4.3a) can also be described as the component form of the 
vector equation f = f0 + r. (See Fig. 2-4.1.) Because of the motion of 0 
with respect to 0, the translation components X01 and the rotation 
coefficients A/ are functions with domain t. 
The variability of these 
quantities distinguishes this situation from preceding developments. 
Since the() system is assumed fixed (i.e., the motion of other systems is 
judged with the () system as reference), the components of velocity are 
obtained by differentiation of (2-4.3a). 
(2-4.3b) 
dX1 
= dAk; Xk +A 1dXk + dX/. 
dt 
dt 
k dt 
dt 

Moving frames of reference 
157 
Since it is assumed that the components dXi/dt determine the true 
velocity, it is apparent from (2-4.3b) that this velocity cannot be obtained 
from the functions dXi/dt alone. 
We must take into account functions 
dX//dt and dA//dt, respectively, because of translational and rotational 
effects. 
The terms Aki(dXkjdt) are usually called components of the 
"apparent velocity," whereas the (dAki/dt)Xk are designated as components 
of an "angular velocity." 
For the moment, we stop the discussion of 
velocity with the remark that it is not, when defined in the usual sense, a 
vector concept. This fact is pointed out by comparing the transformation 
rule (2-4.3b) with (1-4.1). A way in which velocity can be expressed 
mathematically by means of components that satisfy the transformation 
law (I-4.1), even when the coefficients of the orthogonal Cartesian trans­
formations are dependent on a parameter t, is discussed in Section 4. * 
Our present objective is to investigate the acceleration concept. 
The 
components of acceleration arise by differentiation of (2-4.3b ). 
d5 x; 
d2Ak; k 
dAk; dxk 
1 d2Xk 
d2 x/ 
(2-4.3c) 
-
= 
-- X + 2 
 - + Ak 
- + --
. 
dt2 
dt2 
dt 
dt 
dt2 
dt2 
-The components d2 Xi/dt2 of the fixed 0 system (it is assumed that they 
denote the "true" acceleration) do not arise from the components d2Xkjdt2 
alone. Therefore acceleration, as previously defined, does not fit into the 
vector concept with respect to the group of variable rectangular Cartesian 
transformations now under discussion if a requirement of that concept is 
the transformation law (1-4.1). 
The remaining theoretical development of this section is devoted to 
expressing the velocity and acceleration in a classical form found in most 
texts on vector analysis. We call it the arrow form. In Section 4* it will 
be seen how the concepts of velocity and acceleration can be redefined so 
that they once again fit into the fold of vector concepts. 
In most texts that deal with moving frames of reference we find the 
relations 
V=V0+V.A+wxr, 
dw 
a = a0 + a.A + 2w x VA + w x (w x r) + - x r, 
dt 
where VA and a.A represent apparent velocity and apparent acceleration, 
respectively, whereas the components of w measure angular velocity. 
These relations are algebraically equivalent to the component forms 
(2-4.3b) and (2-4.3c); however, they are expressed in terms of angular 
velocity. 
The following definitions and theorems, which introduce and 
develop the algebraic properties associated with the angular velocity 
concept, establish the connecting link between the foregoing representations 
and the component forms. 

158 
THE DIFFERENTIATION OF VECTORS 
Definition 2-4.1. 
Functions wki are defined by 
(2-4.4a) 
3 
.dA.:1 
(J)ki = L Ak' --· 
. 
i=l 
dt 
Theorem 2-4.la. 
The matrix (wk,) is skew symmetric, that is, 
( Q 
W12 
W13) 
(J)ki = -Wik• 
or 
-W12 
0 
W23 
. 
-W13 
-W23 
Q 
(2-4.4b) 
PROOF. 
For any domain value t the rectangular Cartesian systems X1 
and X1 are related (with respect to the rotation) by the orthogonal trans­
formation equations of Chapter l, Section 3. Therefore the orthogonality 
conditions hold; that is, 
3 
(2-4.Sa) 
L A/ A/ = (Jki• 
1-1 
By differentiating (2-4.Sa) with respect to t, we obtain 
(2-4.Sb) 
i (dAk; A/+ A/ dA/) 
= 
0. 
:l=l 
dt 
dt 
The relation (2-4.Sb) can then be put in the form 
a 
. dAk:1 
s . 
dA/ 
w,k = L A/ --
= -L A/ --
= -wki· 
i=l 
dt 
i=l 
dt 
This completes the proof. 
In general, the matrix (wk,) has six nonzero components. Because of 
the skew symmetry property, these six components can be specified by 
appropriately choosing three of them. 
A set of three components 
emanates by means of the following definition. 
Definition 2-4.2. 
The components wP are defined by 
(2-4.6a) 
The way in which the matrix elements wk, are represented in terms of 
the wP is stated in the next theorem. 
Theorem 2-4.lb. 
We have 
(2-4.6b) 
PROOF. 
When (2-4.6) is multiplied and summed with f;prs> the result 
(2-4.6b) follows as a consequence of the algebraic properties of the f; 
systems developed in Chapter 1, Section 6. 

Moving frames of reference 
159 
We are now in a position to bring about a connection between the two 
forms of expression for velocity and acceleration. 
The next theorem 
introduces the necessary computations. 
Theorem 2-4.lc. 
We have 
(a) 
(2-4.7) 
(b) 
d2A/ 
2)[ra]A i 
1' + 
ic-
dw11 
--
= -
Upk 
q WrW 
aj l>pik --
• 
dt2 
dt 
PROOF. 
According to (2-4.4a) and (2-4.6b), 
(2-4.8a) 
Multiplying and summing (2-4.8a) with a/ produces the result 
(2-4.8b) 
 .I> a dAk
a 
i c-
1J 
k ui 
--
= ai 011ikw 
· 
Q=l 
dt 
When the definition of the Kronecker delta is employed in the left member 
of (2-4.8b), the result in (2-4.7a) is obtained. 
The first step toward realization of the form in (2-4.7b) consists in 
differentiating (2-4.7a). We obtain 
(2-4.8c) 
d2A/ 
" (da/ 
11 
+ 
i dw11) 
---o 
-w 
a-
dt2 
-
1Jik 
dt 
i 
dt 
. 
Since a/ = A/, the first term of the parenthetic expression on the right of 
(2-4.8c) can be' replaced according to (2-4.7a). Then 
(2-4.8d) 
d2Ak
i 
3 
( q 
r 
1' 
i dw1') 
--
2-
= Z &11ik ai &rqiw w 
+ ai -
. 
 
1 
 
When, for convenience of notation, we let wr = wr and replace &rqi by 
Erqi and a/ by A/, (2-4.8d) has the form 
(2-4.8e) 
This completes the proof. 
The arrow form of the velocity and acceleration expressions (2-4.3b) 
and (2-4.3c) now can be obtained. 

160 
THE DIFFERENTIATION OF VECTORS 
Theorem 2-4.2. 
The components of velocity dX1/dt and of acceleration 
d2 Xi /dt2 in an 0 frame of reference (which is assumed fixed) are obtained 
from measurements in an 0 system (which is in rotational and trans­
lational motion with respect to 0) according to the following relations: 
(a) 
dX; 
= dXo; +A/ dXk 
+ I A/8vikwvxk. 
dt 
dt 
dt 
i=l 
PROOF. 
Relation (2-4.9a) is an immediate consequence of substituting 
for the first term of the right-hand member of (2-4.3b), according to the 
result (2-4.7a). 
In order to obtain (2-4.9b), we must appropriately substitute both 
(2-4.7a) and (2-4.7b) into (2-4.3c). This action results in the form 
2 -; 
2 - j 
2 k 
3 
k 
(2-4.lOa) d X 
= d X0 + A 1d X + 2_2 A.i&. wvdX 
dt2 
dt2 
k dt2 
i=l 
' 
'P•k 
dt 
+ (-2c57kalA/wrwv + f A/Bvik dwv)xk. 
i-1 
dt 
The relation (2-4. IOa) also can be given the form 
2 -; 
2 - i 
2 k 
3 
k 
(2_4.lOb) d X 
= d X0 +A 1 d X + 2 _2 A.if, . wv dX 
dt2 
dt2 
k dt2 
i=l 
' vik 
dt 
s . 
dwv 
k 
+ A/[(wrxr)wa - (wrw8Xa] + I A/Bvik - X . 
This completes the proof. 
i-1 
dt 
As previously indicated, the results in (2-4.9a) and (2-4.9b) are commonly 
found in the arrow form, 
(a) 
(2-4.11) 
(b) 
V = V0 +VA+ w x r, 
a= io +a.A+ 2w x VA+ (a) x (w x r) + dw x r, 
dt 
where VA signifies an apparent velocity and a.A indicates an apparent 
acceleration. w, with components -w1, is referred to as an angular velocity 
"vector." We have already noted that the components of velocity and 
acceleration do not transform according to the law (1-4.1). Later it will 
be seen that the same statement can be made concerning angular velocity. 

Moving frames of reference 
161 
In comparing (2-4.9a,b) with (2-4.1 l a,b), we must make the following 
correspondences: 
Arrow 
Vo 
VA 
w x r 
-
•o 
•..t 
2wxV.A 
ea> x (ea> x r) 
dw 
- xr 
dt 
Components 
dX0; 
dt 
dXk 
Ak'--
dt 
3 
! A/&:r>ikwP Xk 
i-1 
d2Xo; 
dt2 
d2Xk 
A/ dt2 
3 
dXk 
2 ! A/&1111cW11 d 
i=l 
t 
A/[(wrXr)wq - Wrwr X<l) 
3 
dwP 
!A/&:r>ik- Xk 
i=l 
dt 
Common Name 
Translation velocity 
ofO 
Apparent velocity 
Apparent velocity 
of rotation 
Translational 
acceleration of 0 
Apparent acceleration 
Coriolis acceleration 
Centripetal acceleration 
The component forms make possible a clear geometric interpretation of 
each arrow. The translational velocity and acceleration terms are straight­
forward projections on the axes of the 0 system. In all other cases a set 
of values referred to the 0 system are operated on by A/. This corresponds 
to projecting arrow representatives in the 0 system onto the axes of the 
0 system. Of course, these projections are dependent on t. 
Now attention will be turned to examples in which relations (2-4.3b,c) 
or (2-4.9a,b) are used to illustrate given kinematical situations. 
Example 2-4.1. 
Let a rigid body be rotated about a fixed axis. Suppose 
the fixed axis is parallel to the X3 axis of the coordinates of a fixed frame 
of reference. 
Furthermore, let an X; coordinate system be associated 
with the rigid body in such a way that the origin is on the axis and the X3 
coordinate line corresponds to the axis. (See Fig. 2-4.2.) Now what is the 
motion from the viewpoint of the fixed system of a surface point P of the 
body that lies on the X1 axis a distance r from the origin 0? The para­
metric equations of such a point with respect to the X; system are simply 
(2-4.12a) 
X1 = r, 
X2= 0, 
X3= 0. 
The parametric equations in the _x; system are 
(2-4.12b) 
X1 = A/Xh + Xl, 

162 
THE DIFFERENTIATION OF VECTORS 
xt 
x3 
Fig. 2-4.2 
where X01 are the coordinates of 0. If 
(2-4.12c) 
(A,') -(::: 
-sine 
cos e 
0 
then 
(2-4.12d) 
x1 = r cos e + x01, 
x2 = -r sin e + x02, 
xa = o + Xoa· 
Note that it is quite convenient to think in terms of matrix9 multi­
plication in order to obtain the relations in (2-4.12d) as well as some of 
those that follow. 
In order to obtain the velocity components, we must first compute 
dAk1/dt. 
(2-4.12e) 
( -sine 
dA 1 
_k_ = 
cose 
dt 
0 
-cos e 
o) 
-sine 
0 de
. 
dt 
0 
0 
9 We would put the first term on the right of (2-4.12b) in the form x•Akl· This 
corresponds to the matrix form 
(A11 
A11 
A18) 
(X1, X2, X8) 
A11 
A11 
A18 , 
A31 
A32 
A88 

Moving frames of reference 
163 
By substituting into (2-4.3b) we have ( -sin() 
dX1 dX2 dX3 
dO 
(
-
-
-) = - (r 0 0) 
cos () 
dt ' dt ' dt 
dt 
' 
' 
0 
-cos() 
0) 
-sin() 
0 
0 
0 
(cos() 
+ (0, 0, 0) si: 
() 
-sin() 
cos() 
0 :) 
+ (0, 0, 0), 
that is, 
(2-4.12f) 
dX1 
• 
de 
-= -r sm O
-, 
dt 
dt 
dX2 
dO 
-
= -rcosO-, 
dt 
dt 
dX3 
-
= 0 . 
dt 
In order to obtain the components of acceleration, we must compute 
d2Aki/dt2. 
(2-4.12g) (d::') 
= ( =::: :: 
6 )()' 
(
-sin () 
-cos () 0) 
d2() 
+ 
cos () 
-sin () 
0 
dt2 
• 
0 
0 
0 
The only term of the right-hand member of (2-4.3c) that contributes to 
the result is the first. This is because the particle is fixed in the Xi system. 
Hence 
(2-4.12h) 
--
= -r cos () -
- r sm () - , 
d2 xi 
(ae)2 
. 
d2e 
dt2 
dt 
dt2 
--
= + r sm () -
- r cos () - , 
d2 x2 
. (de)2 
d2e 
dt2 
dt 
dt2 
d2xa 
- =0. 
dt2 

164 
THE DIFFERENTIATION OF VECTORS 
When considering problems involving rotating frames of reference, it is 
standard practice to start with knowledge of the angular velocity com­
ponents w; and a set of given initial conditions. 
For example, in con­
sidering the motion of a particle in relation to the earth's surface, we 
might assume that a frame of reference, fixed with respect to the earth, 
rotated uniformly in a system associated with the sun. 
The results from 
which the computations of the last example were made are expressed in 
terms of rotation coefficients A/. The way in which the A/ are produced 
by means of an initial state of rotation and a prescribed constant angular 
velocity is indicated in the next theorem. 
Theorem 2-4.3. 
If the angular velocity components wi are constant 
and (A/)0 is a given set of values A/ at t == 0, then 
(2-4.13a) A k == [(A .k) + J_ (d2Al\] - J_ (d2A/\ cos Kt 
; 
' 
° K2 dt2 Jo K2 dt2 Jo 
where 
(2-4.13b) 
PROOF. 
From (2-4.6b) and (2-4.7a) we obtain 
(2-4.14a) 
where 
(2-4.14b) 
+ -
__ ; 
sin Kt, 
1 (dA k) 
K dt o 
is introduced as a notational convenience. The relation (2-4.14a) can be 
put in the form 
(2-4.14c) 
For each value of q (q == 1, 2, 3), relation (2-4.14c) consists of a set of 
three homogeneous first-order differential equations with constant coeffi-
cien
.
ts. 
The solutions of this system are annihilated by ( b/ ; -wi k) . 
Smee 
t 
(2-4.14d) 
det. (b/ !!.. - w1k) == d3 + K2 !!. == !!. ( d: + K2), 
dt 
dt3 
dt dt .dt 
it follows that 
(2-4.14e) 
A,k == c/ + d/ cos Kt + e/ sin Kt, 

Problems 
165 
where c/, d/, e/ are constants of integration which must be determined 
from the initial conditions. (See the problems at the end of the section 
for details. Also see the discussion of eigenvalues at the end of Chapter I, 
Section 6.) Since the Akq are known at t = 0 and the wik are given, from 
(2-4.l4e) and the result obtained by differentiating this expression we can 
compute dAkq/dt and d2Akq/dt2 at t = 0. This enables us to calculate the 
unknown coefficients. At t = 0 
(A/)0 = c/ + d/, 
(2-4.14f) 
(dA/) = Ke.k 
d 
1' 
t 0 
(d2A/\= -K2d k. 
dt2 Jo 
1 
When these relations are substituted into (2-4.14e), the result (2-4.13a) 
follows. 
Problems 
1. Determine the components of i', V, and a as well as the components wik and 
w'P if the parametric equations of a particle in the Xi system are 
(a) 
(b) 
x1 = 2 + 31, 
X2 = I + 41, 
X3 = 3 +St, 
(i.e., straight-line motion) with 
(A/) 
= ( co 0 
0 
sin 0 
-sn o) . O = O(t). 
cos 0 
x1 = t, 
x2 = t2, 
X3 = O, 
(i.e., parabolic motion), with 
(A;')-(:: 
-sin 0 
cos 0 
0 
In each case let 
Xo1 = t, 
X02 = 1 + 2t, 
X03 = 2 + 31. 

166 
THE DIFFERENTIATION OF VECTORS 
2. Repeat Problem 1 if 
X1 = rsinr/>,tf> = t 
x2 = O, 
X3 = rcosr/>, 
where r is constant, <fi is measured from X3, 
(A;')-(: 
and (X0;) = (0, 0, 0). 
-sin (J 0) 
cos (J 
0 ,.9 = 9(t) 
0 
1 
3. Show that -!wrqw<r 
= K2 where K2 is defined by (2-4.13b). 
4. Show that det. [oki(d/dt) - wik] 
= (d3/dt) + K2(d/dt). 
= .!._ t; .. k£1"lr(o i :!. - wi ) (o 1 !!. - wi ) (o k !!. _ wk ) 
3 ! 11 
" dt 
" 
q dt 
q 
r dt 
r • 
5. If w1 = w2 = 0, w3 = w, and (A/)0 = o/, show that 
(
cos wt -sin wt 0) 
(A/) 
= 
sin wt 
cos wt 
O . 
0 
0 
1 
6. If w1 = w2 = 0, w3 = w, show that the Coriolis components are 
( 
dXk 
dXk) 
2w -cos wt&31k dt - sin wt&a2k dt , 
( 
dXk 
dXk) 
2w sin wt&a1k dt - cos wt&a2k dt 
, 
0, 
and, when dX1/dt = .f(t), dX2/dt = dX3/dt = 0, these components reduce 
to 2w(df/dt sin wt, df/dt cos wt, 0) 
4*. A Tensor Formulation of the Theory of Rotating 
Frames of Reference 
In this section the allowable transformation group is the set of orthogonal 
Cartesian rotations with time-dependent coefficients 
(2-4*.l) 
X1 = A/(t)Xk. 
The goal of this section is to determine mathematical formulations of 
the concepts of velocity and acceleration such that the respective com­
ponents transform according to the law (1-4.1). The attainment of this 
objective makes possible the generalization of the vector concept to 

Tensor formulation of theory of rotating frames of reference 
167 
systems of orthogonal Cartesian coordinates related by transformations 
with variable coefficients. The importance of representing physical con­
l:cpts, such as velocity and acceleration, in vector form lies in the 
adaptability of these forms to the expression of physical laws in a universal 
manner. This mode of thought is illustrated in Section 6 of this chapter. 
In a sense, the set of components wki comprises the key to the mathe­
matical formulations to be developed in this chapter. Therefore, as a 
tirst step in the development, the relations (2-4.9a,b) are expressed in 
terms of the components wki· 
Theorem 2-4*.1. 
The relations in (2-4.9a,b), for rotations alone, can be 
written 
(2-4*.2) 
(b) 
where wk; = wki· 
PROOF. 
The relations (2-4*.2a,b) can be obtained most easily by 
computing· dAk1 /dt2 from (2-4.4a) and then appropriately plugging the 
result in (2-4.3b) and (2-4.3c); that is, according to (2-4.4a) and also using 
the fact that A/ =a/, 
(2-4*.3a) 
..,dA/ 
.., 
a1 -- = w k• 
dt 
where wPk is written rather than wPk simply for notational convenience. 
Summing the products of (2-4*.3a) with A..,q, we obtain 
(2-4*.3b) 
dAkq 
= ApQW'l>k' 
dt 
Another differentiation yields 
(2-4*.3c) 
- A awr w.., +A q dw'Pk 
-
r 
P 
k 
P 
dt . 
As previously indicated, when we substitute the results (2-4*.3b) and 
(2-4*.3c) into (2-4.3b,c) the relations in (2-4*.2a,b) follow. This completes 
the proof. 
The next theorem investigates the mode of transformation of the com­
ponents w\. As in the considerations Qf Section 3, it is assumed that 0 
is a fixed frame of reference; 0 and 0 are frames in rotational motion 
with respect to 0. X1, X1, and X1 are rectangular Cartesian coordinates 

168 
THE DIFFERENTIATION OF VECTORS 
associated with 0, 0, and 0, respectively. Furthermore, Ak; and Bk1 are 
coefficients of orthogonal transformations such that 
(2-4*.4) 
Xi=Ak1X", 
Xi=B/Xk. 
As usual, a/ and bk; represent the inverse transformation coefficients. 
Theorem 2-4*.2. 
The transformation rule relating the components 
Wik and cu\ is 
(2-4*.5) 
PROOF. 
From (2-4*.4) we observe that 
(2-4*.6a) ax1 
- A; 
()Xk -
k' 
ax1 
. 
- -B' 
axk -
k
.
 
Therefore 
(2_4 •. 6b) 
i 
i dA/ 
axi d (ax;) 
w k =a; -;ft= 
ax1 dt axk 
oX; oXP d (oX; oX0) 
=
axvax;dt oX0()Xk 
= oJi axv[d(oX;/oX0) oX0 + o-!; d(oX0/oXk)J 
axv oX; 
dt 
()Xk 
oX0 
dt 
oX; oX0 
dB ; 
-
oX; d(oX0/oXk) 
=--=--P-a +Kv--=-
. 
axv oXk ' 
dt 
a axv 
dt 
The desired result is a consequence of making the replacement 
in (2-4*.6b). 
b.vdB/ = wv' 
' 
dt 
a 
It is left as an exercise for the reader to show that the transformation 
rule (2-4*.5) is symmetric in nature. In other words, 
I 
(Oi = axiaLv wa 
axid<ax01axk) ·I 
(2-4*.7) 
k 
axa oXk 
v 
+ 
axa 
dt 
	' 
The reader should note that the 0 system is assumed fixed. Physically, 
this can be interpreted to mean that () has no rotational motion and 
therefore the set of components w\ (which measure the rotation) is a 
zero set, that is, 
{2-4*.8) 
iiJik = 0. 
From the standpoint of the transformation concept we could say that 
the components w'k are obtained by consideration of the identity 

Tensor Formulation of Theory of Rotating Frames of Reference 
169 
transformation; that is, 
. 
. dlJ/ 
w'k 
= b/-
= 0. 
dt 
Now that the transformation rule for the components w\ is determined, 
we can turn our attention to the problem of expressing velocity and 
acceleration in a form in which the respective components will transform 
consistently with the law (1-4.1). If this law is sOtisfied, the entities are 
said to be of vector character. 
Definition 2-4*.1. 
Let {Uk} be a collection of n-tuples Uk, Ok, etc., one 
n-tuple associated with each rectangular Cartesian coordinate system. The 
collection {Uk} is said to be a contravariant10 vector with respect to the 
orthogonal Cartesian group with time-dependent coefficients of trans­
formation. The elements ( U1, U2, U3) are components of the vector. 
The solution to the problem of formulating expressions for velocity and 
acceleration that transform appropriately lies in relation (2-4*.2a) and is 
indicated by the following definition. 
Definition 2-4 * .2. 
Let Uk be the components of a contra variant vector. 
Then 
(2-4*.9) 
are called the components of the rotational derivative of the vector U. 
Theorem 2-4*.3. 
The rotational derivative 'J)Uk/dt is a contravariant 
.vector. 
PROOF. 
Consider the coordinate systems related by 
. 
.-k 
axj =k 
X' = c 'X = -=- X . 
k 
iJXk 
Of course, they are both rectangular Cartesian and the transformation is 
orthogonal. 
By substituting for Uk and wki 
according to their trans­
formation rules, we obtain 
(2-4*.lOa) 
'J) Uk 
= dUk + wkiUi 
dt 
dt 
= d[(oxk;axj)iJi] + [a1:k ax> w'P 
a?k d(ox'P;axi)] a@i iJi 
dt 
ax'P ax· 
q + ax'P 
dt 
ox' 
= aAk (diJ'P + w'P 01) + (d(oxk;axj) + aAk aBi d(ox'P;axi)) fJi. 
ax'P dt 
1 
dt 
ax'Pax1 
dt 
1° For a discussion of the term contravariant see Chapter 1, Section 5*. 

170 
THE DIFFERENTIATION OF VECTORS 
To show that the theorem is valid, we must verify that the second paren­
thetic expression on the right of (2-4*.IOa) has the value zero. This fact 
follows by the differentiation with respect to t of 
oXkox1=bk 
oX1oX'P 
'J . 
When the parenthetic expression is set equal to zero, (2-4*.IOa) reduces to 
'J)Uk 
()Xk 'J)[ii 
(2-4*.lOb) 
- -
--
dt 
- ax1 at 
· 
This completes the proof. 
Since the rotational derivative of a vector is a vector, it follows that 
rotational derivatives of any order are vectors. This fact puts us in a 
position to consider the concepts of velocity and acceleration. In par­
ticular, recall that the transformations being dealt with are rotations, hence 
X; are components of a position vector r. 
Because the X1 are vector 
components, we can take a rotational derivative. 
Definition 2-4*.3. 
Let the velocity and acceleration concepts be defined 
by means of the respective sets of components 
'DX1 
'.D2X1 
'.D('DX1/dt) 
dt, 
di2 = 
dt 
Theorem 2-4*.4. 
Velocity and acceleration as defined in Definition 
2-4*.3 are vector concepts. Furthermore, in a given coordinate system 
they reduce to the usual forms (2-4.9a,b). 
PROOF. 
The rotational derivative was modeled after the parenthetic 
expression in (2-4*.2a). 
Furthermore, the components wk, equal zero. 
Therefore the components of velocity satisfy Definition 2-4*.2. 
The 
computation showing that the components of acceleration satisfy (2-4 * .2b) 
is straightforward and is left to the reader. 
The problem of determining "universal laws of nature" is one of the 
major concerns of theoretical physics. Vector and tensor analysis have 
gained prominence as valuable scientific tools because they, more than 
any other mathematical discipline, lend themselves to this cause. 
Problems 
1. Derive the transformation law (2-4*.7), 
(a) repeating the procedure used to obtain (2-4*.5), and 
(b) starting with (2-4*.5). 
2. Is the transformation rule for the components w'k consistent with the tensor 
transformation rule stated in Chapter l, Section 5 * ? 
3. Show that the components of acceleration 'J)2 Xi/dt2 are in agreement with 
(2-4*.2b). 

Newtonian orbits 
171 
5. Newtonian Orbits 
A problem in dynamics is investigated in this section. 
Studies made 
under the heading of dynamics differ from kinematical investigations in 
that the concept of mass is considered. 
Particles are still idealized as 
points, and their paths are represented by space curves, but because mass 
(m) is taken into account the study of velocity and acceleration fields along 
the curves is replaced by a study of momentum (mv) and force fields (ma). 
To the ancients the earth was a plane in a vast sea. 
Observations 
concerning the nature of the earth and its relationship to the other heavenly 
bodies were made over a long period. By the time of the Greek civilization 
important facts concerning these relations had been established. Hippar­
chus, 160 B.c., and Ptolemy, A.D. 100, developed a theory of epicycles 
which described the motions of the. known planets from an earth-centered 
viewpoint. More than a thousand years later Copernicus11 brought about 
a philosophic revolution with the observation that paths of planets 
could be represented more simply by taking the sun as the center of 
reference. 
By using observed data, obtained by himself and his predecessor Tycho 
Brahe (1546-1601, Danish), Johann Kepler (1571-1630, German) elab­
orated on this view and determined empirically the motion of the planets 
with respect to the sun. Half a century later Isaac Newton published his 
Principia in which he set forth a theory of gravitation that formed a 
theoretical foundation for Kepler's empirical results. No doubt Newton 
fashioned his theory to include Kepler's laws. 
But, as every student of 
physics knows, the Newtonian theory was not sterile. 
It has been the 
working model of the physical sciences for more than two hundred years 
and has formed a foundation stone for much of modern-day physics, 
including Einstein's general theory of relativity. Discrepancies in obser­
vation and Newtonian gravitational theory led to the discovery of the 
planet Neptune. 
Adams (English) and Leverrier (French) obtained 
sufficiently accurate mathematical results to enable astronomers to locate 
the planet. (Neptune was first recognized by Galle (German) in 1846.) 
In fact, still further astronomical investigations, spurred by the discov­
ery of Neptune, led to the discovery of Pluto by C. W. Tombaugh in 
1930. 
The objective of this section is to illustrate the way in which the Kepler 
laws of planetary motion can be obtained from the Newtonian theory. 
11 His proper name was Nicolas Copernik and he was born in Polish Russia. 
Copernicus is the Latinized form of Copernik. 

172 
THE DIFFERENTIATION OF VECTORS 
These laws are as follows: 
(a) 
The planets describe ellipses with the sun at one focus. 
(b) 
The radius vector from the sun to a planet sweeps out equal 
(2-5.1) 
areas in equal times. 
(c) 
The squares of the periods of the planets are proportional to 
the cubes of their mean distances12 from the sun. 
Our starting point is Newton's law of gravitation. 
Newton's Law of Gravitation. Any two bodies whose dimensions are 
negligible in comparison with their distance apart attract each other with 
forces directed along their joining line. 
The force on either body is 
directly proportional to the product of the masses of the bodies and 
inversely proportional to the square of the distances between them. 
The algebraic structure of vectors was not developed until the nineteenth 
century, whereas Newton lived from 1642-1727. Therefore it is clear that 
the vector methods used in this development were not included in the 
original work. To see the degree of simplification brought about by the 
vector concepts, we need only begin writing out the equations in complete 
detail. 
Regard the sun, of mass M, as fixed in space and let the point rep­
resenting it be the initial point of the position vector r = rR. (R is a unit 
radial vector.) Let the mass of a planetary body be represented by m. 
On the one hand, the force vector field associated with the path of planetary 
motion is defined to be F = ma. On the other hand, according to Newton's 
law of gravitation, 
(2-5.2) 
F= -mMGR, 
r2 
where G is a constant of proportionality, the so-called gravitational 
constant. Therefore we have 
(2-5 .3a) 
or 
(2-5.3b) 
dv 
-mMGR 
m-=
----
dt 
r2 
-MGR 
a= --­
r2 
Theroem 2-5.1. 
The planetary motion is planar. 
PROOF. 
By cross multiplication of both members of (2-5.3b) with r, 
we obtain 
(2-5.4a) 
r x a = 0. 
11 The major semiaxis a = !(r1 + r1) is called the planet's mean distance from the 
sun. For earth a ""' 92,900,00 miles. 

Newtonian orbits 
173 
The relation (2-5.4a) is equivalent to 
(2-5.4b) 
since 
d(r xv)= O, 
dt 
d(r x v) = (dr x v) + (r x dv) = (v x v) + (r x a) = r x a. 
dt 
dt 
dt 
Therefore by integration of (2-5.4b) we obtain 
(2-5.4c) 
r xv= h, 
where h is a vector constant. Since r and v are perpendicular to the same 
direction h for all t, the motion is planar. 
Theorem 2-5.2. 
The equation of planetary motion is 
h2/MG 
r=--'---
1 + e cos 0 
(2-5.5) 
where h = Jh • hand e, the magnitude of a vector constant of integration, 
represents the eccentricity of a conic section. 
PROOF. 
As a first step in obtaining the desired equation, cross multiply 
(2-5.4c) with the acceleration vector a. 
(2-5.6a) 
a x (r x v) = a x h. 
On the one hand, the left member of (2-5.6a) can be written 
(2-5.6b) 
a x (r x v) = -- R x rR x - = 
-- R x r2R x -
-MG 
( 
drR) 
-MG 
( 
dR) 
r2 
dt 
r2 
dt 
=-MGR x (Rx) = -MG[ R(R 
• 	) - (R·R)J 
= MG dR. 
dt 
In developing the result (2-5.6b), we must use the triple vector product 
as well as the facts 
Rx R = 0, 
R·R= 1, 
R·dR = 0. 
dt 
On the other hand, the right-hand member of (2-5.6a) can be written 
(2-5.6c) 
a x h = dv x h = d(v x h). 
dt 
dt 

174 
THE DIFFERENTIATION OF VECTORS 
Therefore, by replacing the members of (2-5.6a) according to (2-5.6b,c) 
and putting the terms on the same side of the resulting vector equation, 
we have 
(2-5.6d) 
MG 
dR - d(v x h) = !!._ (MGR - v x h) = 0. 
dt 
dt 
dt 
By integrating, 
(2-5.6e) 
MG R - v x h 
= -MGe, 
where the arbitrary constant of integration is written with the factor-MG 
simply for convenience of the algebraic manipulation that follows. From 
(2-5.6e), 
(2-5.6f) 
v x h = MG(R + e). 
When this expression is dotted with r, we obtain 
(2-5.6g) 
r · v x h = MG(r + re cos 0), 
where r · e =re cos 0. By using the algebraic property of interchange of 
dot and cross on the left of (2-5.6g), as well as relation (2-5.4c), the 
expression (2-5.6g) can be put in the form 
h2 = MGr (l + e cos 0). 
The result of the theorem follows by simple algebraic manipulation. 
The relation (2-5.5) is the polar form of a conic section with eccentricity 
e and with one focus at the origin. The orbit is an ellipse, parabola, or 
hyperbola fore< 1, e = I, and e > 1, respectively. 
Since the orbit of a planet is closed, it must be an ellipse. The closest 
point of the planet's orbit to the focus is called the perihelion, whereas 
the farthest point is called the aphelion. (See Fig. 2-5.1.) 
The second Kepler law is satisfied, since, by assumption [see (2-5.3b) 
and Example 2-3.3], the acceleration is always pointed toward a fixed 
position. This fact may also be determined in the context of the present 
problem, as indicated in the following example. 
Fig. 2-5.1 

Newtonian orbits 
175 
Example 2-5.1. 
The law of areas can be intuitively determined by 
considering the element of area swept out in Fig. 2-5.1. 
(2-5.7) 
Therefore 
AA= ! lrl lr + Arl lsinAOI = ! lr x (r + Ar)I 
= ! lr x Ar!. 
AA=.!.l rxAr, , 
At 
2 
At 
At> 0. 
Then, assuming the existence of the limit, 
dA = Iim AA = ! Iim I r x Ar I = ! lr x vl 
dt 
t-+o At 
At 
= !lhl. 
Therefore dA/dt is constant. 
The third Kepler law is derived as follows. Because the sectorial speed 
! !hi is constant, the period of revolution P in an elliptic orbit is obtained 
by dividing the area of the ellipse by the sectorial speed. As indicated in 
Fig. 2-5. l ,  the length of the major axis (i.e., 2a) is r1 + r2, where r1 and r2 
are the perihelion (0 = 0) and aphelion (0 = 1T) distances, respectively. 
From (2-5.5), 
(2-5.8a) 
Therefore 
and 
(2-5.8b) 
h2/MG 
r1= -- , 
1 + e 
2h2 
2a = r1 + r2 = --­
MG(l - e2) 
h2 
1-e2=--. 
aMG 
h = lhl. 
The area of an ellipse of semiaxis a, b is 
(2-5.8c) 
7Tab = 7Ta2(I -e2)112. 
Hence the period of revolution is 
Therefore 
(2-5.8d) 
7Ta2( 1 - e2)'A. 
27Ta2 
h 
21Ta"A. 
P-
- -
- --
-
!h 
-
h (aMG)1A - (MG)1A . 
The right-hand member of (2-5.8d) is constant. Furthermore, the value is 
not dependent on the particular planet under consideration. 
Hence 
Kepler's third law is valid for all the planets. 

176 
THE DIFFERENTIATION OF VECTORS 
Problems 
1. If h 
= 0 in (2-5.4c), what, then, is the nature of the motion? 
2. The angular momentum of a particle about a point, denoted by L, is defined 
as 
L = r x mv. 
The moment of force or torque of a particle about a point is 
H = r x F, 
where the force 
Show that 
3. If the total torque is zero, show that the angular momentum is conserved. 
6. An Introduction to Einstein's Special Theory 
of Relativity 
Einstein's initial paper concerning the special theory of relativity, "On 
the Electrodynamics of Moving Bodies," was published in 1905. As with 
any other theory of major importance, it was not the product of one man; 
rather, Einstein's work culminated the thoughts of many individuals. To 
examine its origins, we must trace the histories of classical mechanics, 
electromagnetic theory, and the related mathematical and philosophical 
developments. It is not the purpose of this book to go into great detail 
concerning these histories, but a few relevant facts may be useful in setting 
the scene for those aspects of special relativity that are to be presented. 
Alongside the knowledge of the solar system, discussed in Chapter 2, 
Section 5, Galileo placed the mechanics of freely falling bodies. In his 
turn, Newton combined the physical knowledge of the seventeenth century 
with his own physical intuition and mathematical learning to formulate 
the foundations of what is known today as classical mechanics. At the 
base of Newton's theory of mechanics were two assumptions of specific 
importance to the development of the ideas presented in this section. 
According to the theory: 
1. Measurement of time does not depend on a physical frame of 
reference; that is, time has a universal character. 
2. Uniform rectilinear motion cannot be intrinsically determined by 
mechanical experiments. 

An introduction to Einstein's pecial theory of relativity 
177 
Relativity of motion was not a new concept with Newton. The fact that 
an individual's observation of the motion of an object depended on his 
own circumstances13 was known to the Greeks. On the other hand, the 
idea that uniform rectilinear motion could not be determined mechanically 
without reference to another physical object was new. 
From the mathematical point of view, the facts of immediate concern 
may be put as follows: It is assumed that a frame of reference (called by 
the physicist an inertial frame) exists in which Newton's laws of classical 
mechanics hold.14 Any frame in uniform rectilinear motion in relation to 
the original system can be shown to be an inertial frame. We associate a 
rectangular Cartesian coordinate system with each reference frame. The 
transformations relating coordinates, as specified by these various systems, 
form a group, and it is required that the fundamental laws of classical 
mechanics be invariant with respect to this group.15 
These laws are 
invariant under the Galilean transformations 
IA/I= 1, 
where the coefficients of rotation A/ and the velocity components vi are 
constants. It is assumed that at t = 0 the origins of the orthogonal systems 
coincide. The path of motion of one frame with respect to the other is 
illustrated in Fig. 2-6.1. 
Let us turn to the history of electromagnetic theory and, in particular, 
to the developments of the nineteenth century. 
Late in the eighteenth 
century Charles Augustin Coulomb (1736-1806, French) experimentally 
confirmed an inverse square law for the electrostatic force field. Around 
1820 Hans Christian Oersted (1777-1851, Danish) discovered that an 
electric current produces a magnetic field, and a little later in the century 
Michael Faraday (1791-1867, English) and Joseph Henry (1799-1878, 
American) independently determined that a magnetic flux produces an elec­
tric field, thereby establishing the principle of electromagnetic induction. 
The body of knowledge of electromagnetic theory was climaxed by Clerk 
13 Are you moving at this instant? 
14 I. Every body tends to remain in a state of rest or of uniform rectilinear motion 
unless compelled to change its state by action of an impressed force. 
II. The "rate of change of motion," that is, the rate of change of momentum, is 
proportional to the impressed force and ocurs in the direction of the applied force. 
III. To every action there is an equal and opposite reaction, that is, the mutual 
actions of two bodies are equal and opposite. 
16 Klein's Erlanger Programm of 1872 classified geometries in terms of invariants 
of transformation groups. 
The close relationship of this principle for classifying 
geometries to the demand that physical laws have invariant mathematical' forms with 
respect to a given transformation group was pointed out by Klein. See Entwicklung 
der Mathematik 11, Chelsea, New York, 1950. 

178 
THE DIFFERENTIATION OF VECTORS 
Path of 
motion 
Fig. 2-6.1 
Maxwell (1831-1879, English). His famous equations put the theory on 
a postulational basis and opened the door to mathematical speculation. 
The phenomena of electricity and magnetism were destined to have a 
profound influence on the philosophical development of man, for electro­
magnetic theory set forth the physical properties of nonmaterial substances. 
By application of his mathematical talents Lorentz determined that 
although the Maxwell equations were not invariant to the Galilean 
transformations they did preserve their form under a special set of trans­
formations, which subsequently were named after him. For the motion 
of one rectangular Cartesian frame along a z axis common with the z axis 
of another these Lorentz transformations have the form 
y=y 
z - vt 
z- -----..,. 
- [1 - (v /c)2]'A 
_ 
t - (v/c2)z 
t = ---'-''--''--
[ l 
- (v /c)2]'A' 
where v is representative of a constant velocity and c is the velocity of 
light in vacuo. 
Although these transformation equations preserve the 
form of Maxwell's equations, they also suggest from the classical point of 
view a strange relation bo.tween space and time. 
It was not Lorentz's 
destiny to explain this relationship in a satisfactory manner. If he had 
done so, much of the scientific glory which later went to Einstein might 
have been his. 

An introduction to Einstein's special theory of relativity 
179 
To these brief accounts of classical mechanics and electromagnetic 
theory let us add an experimental fact. It was hoped, because of the non­
material aspect of electromagnetic phenomena, that through it the uniform 
rectilinear motion of a physical frame of reference might be determined 
intrinsically {i.e., without reference to any outside body). In particular 
optical experiments were attempted, the most famous of which was the 
series carried out by Albert A. Michelson (1852-1931, American) and 
Edward Williams Morley (1838-1923, American) in the last part of the 
nineteenth century. In these experiments an attempt was made to deter­
mine the velocity of the earth (making the assumption that the earth 
moved along the tangent line to its path of motion at a given instant, hence 
could be considered in uniform rectilinear motion) by compounding its 
velocity with the velocity of light, first in the direction of the earth's 
motion and then orthogonal to this direction. No positive result was 
achieved; that is, the compounding of velocities, in the classical sense, 
failed. Furthermore, these experiments and others pointed to the pos­
sibility that the measurement of the velocity of light did not depend on 
uniform motion of either the source or the receiving agent. 
We have before us two theories, classical mechanics and electro­
magnetics, and the experimental facts of the failure of the composition of 
velocities when light is involved and the constancy of the velocity of light. 
Let us add to these the theoretical physicists' desire for a universal physical 
theory and a suggestion by the French mathematician Henri Poincare 
(1854-1912) that perhaps neither mechanical nor electromagnetic experi­
ments could intrinsically detect uniform rectilinear motion. The stage is 
set for a new theory; in this instance, Einstein's special theory of relativity. 
Let us turn our attention to the mathematical development of the 
previously stated ideas. 
If the axes of two rectangular Cartesian coordinate systems, 0 and 0, 
are parallel and the 0 system is in uniform translatory motion with respect 
to 0, the associated Galilean transformations take the form (Fig. 2-6.2) 
X1 =X1 - vit, 
(2-6.la) 
f = t 
in which throughout the discussion we make the identifications X1 = x, 
X2 = y, X3 = z and correspondingly in the barred system. To interpret 
these equations physically, we associate the coordinates X1 and X1 with a 
particle P moving uniformly and rectilinearly with respect to either system. 
It is assumed that time is measured in a common way for all systems 
related by the transformation equations. Under this assumption a differ­
entiation of the Galilean transformation equations leads to the classical 

180 
THE DIFFERENTIATION OF VECTORS 
xa 
I 
I 
I 
/ 
/ 
/ 
/ 
x2 
/ 
/ 
I 
I 
-------xi 
I 
I 
I 
I 
I 
Fig. 2-6.2 
law of composition of velocities 
dX1 
dXi 
- = - -v'. 
dt 
dt 
This law is a central concept in cla<Jsical mechanics, but, as indicated in the 
introductory remarks, the phenomenon of light does not conform to it. 
Before beginning the search for transformation equations that produce a 
composition of velocities consistent with the physical facts concerning 
light, it is constructive to digress on a brief investigation of the geometric 
interpretation of the Galilean transformations. 
The equations in (2-6.la) were introduced as equations of motion of 
a particle in a three-dimensional Euclidean space. This interpretation 
involves motion and therefore is primarily physical, rather than geometric, 
in nature. A static model can be developed by extending the dimension of 
the space to four. Assume the space to be Euclidean and refer it to a 
rectangular Cartesian coordinate system (x, y, z, t). Then the transfor­
mation equations in (2-6. la), which can also bH written in the form 
(2-6.lb) 
or 
(2-6.lc) 
X" = X" - v1 tJ/X4 
are centered affine transformations. In (2-6.lb) the Greek index ac ranges 
over values I, 2, 3, 4, and X' = t, whereas X4 = i. 
Throughout the 
remainder of this section indices indicated by Greek letters take on values 

An introduction to Einstein's special theory of relativity 
181 
1, 2, 3, 4. The matrix of transformation coefficients is 
1 
0 
0 
0 
0 
1 
0 
0 
"'-6.ld) 
(Bp") = 
0 
0 
1 
0 
-v1 
-v2 
- vs 
1 
As long as some one of the velocity components is different from zero, 
this matrix will not satisfy the orthogonality conditions in (l-3.2l e). 
Therefore the coordinate system founded on it will not be rectangular. 
Specifically, the x, y, and z axes are not changed under the transformation; 
however the i axis differs from the t axis. It is impossible to construct a 
four-dimensional diagram to illustrate the foregoing remarks, but our 
intuition can be stimulated by suppressing one of the space dimensions 
and then constructing the diagram. This is done in Fig. 2-6.3a. In Fig. 
2-6.3b two-space dimensions are suppressed. 
The transformation relation i = t points out the universal nature of 
time in classical space time. This fact is illustrated geometrically by a 
plane of simultaneity in Fig. 2-6.3a. This plane, which is parallel to the 
coincident y, z, and y, z planes, consists of the set of all points with a 
common time coordinate. 
The existence of planes of simultaneity, 
illustrated in Fig. 2-6.3a, and of lines of simultaneity, shown in Fig. 2-6.3b, 
are specifically pointed out so that comparisons can be made with corre­
sponding representations in the relativistic situation. A word of warning 
when interpreting the diagrams: the reader must realize that the unit of 
distance is not the same along the t and i axes. (See Problem 2b.) 
In both Fig. 2-6.3a and Fig. 2-6.3b a line, called a world line, has been 
constructed parallel to the i axis. This line consists of the set of all points 
with the same space coordinates in the barred coordinate system. 
A 
corresponding world line for the unbarred system must be drawn parallel 
to the t axis. The world lines illustrate the fact that the concept of rest 
has no objective meaning in classical space-time. 
The cone drawn in Fig. 2-6.3a degenerates to a pair of intersecting lines 
in Fig. 2-6.3b. 
In both illustrations the lines of the cone represent 
emanations of light rays from a source fixed at the origin of coordinates. 
The cone is symmetric to the t axis but it is not symmetric to the i axis. 
This fact is expressed algebraically by the variance of the equation of the 
cone under a centered affine transformation. 
(See Problem 3.) 
These 
observations concerning the light cone conclude the digression and, at the 
same time, initiate the discussion of the ideas underlying the special theory 
of relativity. 

182 
THE DIFFERENTIATION OF VECTORS 
Classical space-time 
t 
Plane of 
simultaneity 
z 
z 
z 
6""---Y 
.-:;_ 
_______ y 
Space motion diagram 
Fig. 2-6.3a. The concept of rest has no objective meaning in classical space time b11t 
simultaneity has. 
Experiments such as those of Michelson and Morley indicated that the 
measure of the velocity of light is independent of uniform rectilinear 
motions. From the mathematical viewpoint the question is one of obtain­
ing the transformation equations relating coordinate systems 0 and 0 in 
uniform rectilinear motion, with respect to one another, under the con­
dition16 
(2-6.2a) 
-(X1)2 _ (X2)2 _ (X2)2 + (X')2 = -(X1)2 _ (XS)2 _ (XS)s + (X')2 
or 
(2-6.2b) 
18 More precisely, the condition is ha.pxa.xfJ = p•'i,_,.XJ.X,., but it can be shown that 
p = 1. See W. Rindler, Special Relativity, lnterscience, 1960, p. 17. 

where 
An introduction to Einstein's special theory of relativity 
183 
World 
Line of simultaneity 
I 
A 
line 
I 
I 
I 
I I 
I I 
I 
I 
World 
/ 
line 
I 
I 
I 
I 
i= z - vt 
t=t 
z= z- vt 
Space motion diagram 
Cone equation 
-z2+t2=0 
Fig. 2-6.Jb 
-1 
0 
0 
0 
-1 
0 
0 
0 
-1 
0 
0 
0 
t 
z2+2vU+0-v)i2=0 
0 
0 
0 
1 
From the physical point of view, we can think of light radiating from a 
point source (the origin of coordinates) in a spherical wave. 
(See Fig. 
2-6.4.) 
If the velocity of light is denoted by c, and X4 represents the time 
elapsed while a point of the wave reaches the position P, then 
(X1)2 + (X2)2 + (Xa)2 = c2(X4)2. 
By taking our unit of length as the distance traversed by light in one 
second we impose the normalization c = 1 ; the relation then has the form 
-{X1)2 _ (X2)2 _ {Xa)2 + (X')2 = O. 

184 
THE DIFFERENTIATION OF VECTORS 
xa 
xi 
Fig. 2-6.4 
The requirement that precisely the same observations must be made 
from the point of view of an (j coordinate system (the origin of which 
corresponds to that of the 0 system at the emission of the light wave) 
leads to the relation 
hapXaXP = h;,µX;, Xµ. 
The fact that the systems 0 and (j are in uniform rectilinear motion 
with respect to one another implies that the coordinates are linearly 
related; that is 
(2-6.3) 
Xa 
= c/ J(P, 
where the constant coefficients of transformation c/ are not known. 
(See Problems l ,  5, 6.) In order that the form ha.pX"" XfJ may be invariant 
under the transformation, it must be that 
hap = C/C/h;,µ-
Since the matrices (ha.p) and (ha.fJ) are identical, the foregoing conditions 
remind us of the orthogonality conditions associated with the transfor­
mations relating rectangular Cartesian systems. Indeed, these conditions 
are taken as the orthogonality conditions of the four-dimensional space 
which is now before us. It is usually called a Minkowski space because the 
geometrical aspects of the concepts presently under investigation were 
first pointed out by H. Minkowski in 1908. Before pursuing this trend of 
thought, it is convenient to make the following simplifying assumptions. 
Let the axes of the threC-space systems 0 and 0 be parallel. Further­
more, assume that the uniform rectilinear motion of the 0 system is along 
the positive sense of the X3 axis of the 0 frame and that initially the origins 
coincide. For simplicity of notation we also use X3 and X4 interchangeably 

xi 
An introduction to Einstein's special theory of relativity 
185 
r------.-
____ -xa xa 
x2 
1, 
I 
I 
I 
I 
/ 
I 
I 
I 
I 
I 
_x1 
I 
Fig. 2-6.5 
I .x2 
with z and t. 
The corresponding relations hold in the (j system. 
(See 
Fig. 2-6.5.) 
Then 
x1 = x1, 
x2 = x2, 
X3 = C33X3 + C43X4, 
X4 = C34X3 + C,'X', 
and the orthogonality conditions ha,p = Crz).C/n).µ reduce to 
-1 = -(C11)2 
-1 = -(C22)2 
-1 = -(Ca3)2 + (Ca')2 
0 = -Ca3Cl +Ca'C,4 
1 = -(Cl)2 + (C,')2. 
If-we concentrate attention on the relations 
(Cas)2 - {Ca')2 = 1, 
(C,')2 - (C,s)2 = 1, 
a marked resemblance to the orthogonality conditions on plane rotations 
is easily noted. In that case the condition to be satisfied was of the form 
(X')s + (X3)2 = (X')2 + (..f3)2, 
whereas in the present case 
(X')2 _ (Xa)2 = (X')2 _ (Xa)2. 
In the case of the rectangular Cartesian rotations, the coefficients of 
transformation were parameterized by circular functions sin () and cos 8. 
The foregoing considerations suggest that the coefficients of transformation 
associated with the Minkowski metric be parameterized by hyperbolic 
functions sinh and cosh. In particular, choose 
C38 = cosh X• 
C,' = cosh x. 
C3' = -sinh x. 
C43 = -sinh x. 

186 
THE DIFFERENTIATION OF VECTORS 
and the conditions on the coefficients will be satisfied. We have 
(2-6.4a) 
z = z cosh x - t sinh x. 
i = -z sinh x + t cosh X· 
If we consider a particle fixed at the origin of 0, then z = 0 and 
z 
sinh X 
v = - = --
= tanhx; 
t 
coshx 
that is, the uniform velocity of the 0 system with respect to the 0 system 
is represented by tanh X· Furthermore, we can write the transformation 
equations in the form 
z = cosh x(z - t tanh x), 
i = cosh x( -z tanh x + t). 
Use of the identity 
1 - tanh2 x = sech2 x 
immediately leads to a representation of the transformation equations in 
terms of the velocity v; that is, 
_ 
z - vt 
z - ---,.-, 
- (1 
- v2)""'' 
(2-6.4b) 
-
-zv + t 
t = 
(1 - v2)!-i'. 
These are the special Lorentz transformations mentioned in the intro­
ductory remarks. The mathematical development just presented implies 
that the measure of light velocity is an invariant of the Lorentz group of 
transformations. In his paper, "Electromagnetic Phenomena in a System 
Moving with Any Velocity Less than That of Light" (English version in 
Proceedings of the Academy of Sciences of Amsterdam, 6, 1904), Lorentz 
showed that the Maxwell equations were invariant with respect to these 
transformations; 
that is, the Lorentz transformations had the same 
characterizing relation to electromagnetic theory as the Galilean trans­
formations had to Newtonian mechanics. 
The invariance of the form F = (X4)2 - (X3)2 Ied to the special Lorentz 
transformation group just as the invariance of G = (X4)2 + (X3)2 led to 
the orthogonal Cartesian group. 
G imposes the ordinary Euclidean 
metric geometry in the plane, but F imposes a hyperbolic geometry.17 
The development of special relativity as expressed in this hyperbolic 
geometry was first expounded by H. Minkowski in 1908. The plane in 
which the metric form F holds sway is accordingly called the Minkowski 
17 The forms F and G are commonly called fundamental metric forms. 

An introduction to Einstein's special theory of relativity 
187 
plane. Minkowski's method of presentation is advantageous in represent­
ing the kinematical aspects of special relativity: in particular, the concepts 
of "contraction of length" and "dilation of time." 
Figure 2-6.6 illustrates the fundamental notions of the Minkowski plane. 
Suppose that from the ordinary Euclidean point of view a particle is in 
uniform rectilinear motion along the z axis of a coordinate system 0. 
Let an 0 system be associated with the particle with axes parallel to those 
of the 0 system. (See Fig. 2-6.5. As represented in Fig. 2-6.6, the space­
time reference system of the frame 0 is denoted by the z and i axes. Each 
coordinate pair (z, t) is said to represent an event in space time. From the 
viewpoint of the 0 system: 
1. All events whose coordinates satisfy lz2 - t21 = L2 are at an equal 
interval from the origin. 
(This is the set of events represented in the 
diagram along the branches of the conjugate hyperbolas.) 
2. A light particle moving along the z axis in three-space is pictured in 
space time by means of the events satisfying the equation z2 - t2 = 0. 
One branch of this so-called light cone is represented in Fig. 2-6.6. 
3. All events represented on a line parallel to the z axis take place at the 
same time in relation to the 0 system. Therefore such a line is called a 
line of simultaneity with respect to the 0 system. 
4. All events represented on a line parallel to the i axis take place at 
the same spot in relation to the 0 system. Such a line is called a world line. 
Fig. 2-6.6 

188 
THE DIFFERENTIATION OF VECTORS 
5. A particle moves from P0 to P0 in the time interval P0P. Therefore 
z 
ctna. = - = v. 
t 
6. The path of a particle in uniform rectilinear motion with velocity v 
is represented by a line i intermediate to the t axis and the light-cone line 
z - t = 0. Note that the t axis denotes the history of a particle stationary 
at the origin of coordinates, whereas z - t = 0 represents the history of a 
light particle. The intermediacy of the line corresponding to the motion 
of a material particle correlates with the assumption that all velocities are 
less than that of light (i.e., v < 1). 
7. The z and i axes must be symmetric with respect to the light-cone 
line z - t = 0, since the equation of the cone is preserved under the 
Lorentz transformations; that is, c = z/i = 1, or z - i = 0 must be 
invariant. (See Problem 7.) 
A line of simultaneity and a world line associated with the (J system are 
represented in Fig. 2-6.6. A striking feature of the special theory of 
relativity is the breakdown of any absolute meaning to the concept of 
simultaneity. The time relationship of a pair of events takes on precisely 
the same relative aspect as the position relationship of a pair of events and 
is dramatically expressed by the following theorems. 
Theorem 2-6.la. 
Let I be a rod fixed in an (J coordinate system and in 
uniform rectilinear motion in relation to an 0 system. The length measure­
ment of I is shorter when determined from the viewpoint of the 0 system 
than it is when determined by 0 measurements. In particular, 
(2-6.5) 
L0 = (1 - v2)] L0, 
where L0, L0, respectively represent the measures of I from the viewpoint 
of 0 and 0. 
PROOF. 
The end points of the rod must be considered simultaneously 
to be measured. Therefore the length of the rod L0 in the 0 system is 
determined by the events 0 and P0• (See Fig. 2-6.6.) Since P0 is the 
projection of a point of the hYJlerbola on the z axis, the length OP 0 can 
be conveniently represented by L cash X· Furthermore, 
Hence 
tanh x = v = ctna.. 
L0 = OP0 = OP0 - P0P0 = L cosh x - P0Pctna., 
L 
L . 
L (cosh2 x - sinh2 x) 
= 
cash x -
smh x tanh x = 
, 
1 
--
= 
-- L = .J 1 
- v2 L. 
cosh x 
cosh x 

An introduction to Einstein's special theory of relativity 
189 
Since the rod is fixed in the barred system, I and L0 are identical. This 
completes the proof. 
Theorem 2-6.lb. 
Let l be a time interval associated with an 0 co­
ordinate system, which is in uniform rectilinear motion with respect to an 
0 system. The 0 determination of this time interval is then less than the 0 
measurement. We have 
(2-6.6) 
PROOF. 
Let OQ represent the () time interval. (See Fig. 2-6.6.) The 
branch of the hyperbola passing through Q has the representation 
t2 - z2 = L2. 
Therefore the coordinates of Q can be expressed para­
metrically by 
t = i cosh x, 
z =I sinh X· 
The measurement of the time interval I with respect to the 0 system must 
occur at a given place; hence we consider the interval OQ0• In other 
words, these considerations with respect to time interval are symmetric to 
those concerning space interval. To complete the proof, we follow the 
pattern of the preceding theorem. 
The reader should be careful in his interpretation of the result of the 
last theorem. The fact that the observed time interval is shorter in the 0 
system implies that the passage of time in () is judged greater. We can 
summarize the result of the theorem with the statement that clocks appear 
to run fastest in the system in which they are fixed. 
Let us once more turn our attention to the consideration of composition 
of velocities. Since the special Lorentz transformations were obtained by 
denying the classical method of composition, it is clear that they will lead 
to a new law. 
Theorem 2-6.2. 
Let a particle P have a uniform velocity ii along the z 
axis of 0. If the() system is in.uniform rectilinear motion along the z axis 
of 0 with velocity v and u represents the velocity of P with respect to 0, 
then 
(2-6.7) 
ii + v 
u=--. 
1 + iiv 
PROOF. 
The coordinates of P are (z, t), (z, i) in 0 and 0, respectively. 
According to the Lorentz transformations, 
Upon dividing, 
_ 
z - vt 
_ 
-vz + t 
z = (1 - v2)Yt. 
' 
t 
= (1 - v2)Yt. . 
_ 
z 
z - vt 
u - v 
u=-:= 
= 
l 
-vz + t 
-vu + 1 

190 
THE DIFFERENTIATION OF VECTORS 
The final result is obtained by solving the last equation for u. 
It is 
interesting to note that lul < 1, lvl < I implies 
l1u:;vl<1. 
(See the problem section for more information on this statement.) 
The preceding theorem deals with a particle in uniform rectilinear 
motion and therefore is restricted in scope. In order to be in a position to 
consider velocities and accelerations of particles in general motion, it is 
necessary to introduce a certain differential invariant of the Lorentz group. 
This invariant, which is introduced by the next theorem, is analogous to 
the differential form of the expression for arc length in Euclidean three­
space. 
Theorem 2-6.3. 
The form 
(2-6.8) 
ds2 = hap dXa dXP 
is an invariant of the Lorentz transformation group. 
PROOF. 
The linear transformations under consideration are of the form 
XY = C./X;., 
x;. = c/XY 
and the components hAµ have already been seen to satisfy the transformation 
rule 
Therefore we have 
hA,, dX;. dX" = C/C/hapc/ dX'c/ dXY 
= d,a d/hap dX' dXY= hap dXadxP. 
This completes the proof. 
The class {dXA/ds} is a vector,18 since 
Furthermore, 
dX;. 
oXAd'J(Y 
;.dXY 
--=---=c -
ds 
oXY ds 
y ds 
dX;. 
dX;. dt 
dX;. 
1 
--;J; = dt ds = dt (-l--
-v-2)-1 • 
For small values of v, dXA/ds is approximately the same as dXA/dt. For 
these reasons we make the following definition. 
Definition 2-6.1. 
The vector {dXJ./ds} is called the four-space relativistic 
velocity vector of a particle that is in general motion in Euclidean three­
space. 
18 See Chapter 1, Section 5. * 

An introduction to Einstein's special theory of relativity 
191 
With the introduction of a relativistic velocity vector, let us consider 
the relativistic form of Newton's second law. In particular, we approach 
the problem by stating criteria a relativistic form of Newton's law must 
satisfy. We then determine the form of the law by analogy to the classical 
law. Criteria commonly taken are the following: 
(a) The law must have the same form as the classical law. 
(b) For low velocities the relativistic form must reduce to the classical 
form. 
(c) Newton's relativistic second law must be Lorentz-invariant. 
Theore1n 2-6.4. 
(2-6.9a) 
where 
(2-6.9) 
Newton's relativistic second law is 
(b) 
3 
4 
!Fava 19 
( ) p4 __ a@=Al-B 
c 
- (1 - v2)'A . 
PROOF. 
The proof consists of showing that the criteria (a), (b), and (c) 
are satisfied. The first three components of relation (2-6.9a) can be written 
in the form 
(2-6.lOa) 
pa 
= m d{dX"/dt[(l - v2)-'A]} (1 - v2)-l-1 
(1 - v2)'A 
0 
dt 
or 
(2-6.lOb) 
F" = d{[m0/(1 - v2)11] dXa/dt}
. 
dt 
This expression corresponds to Newton's classical second law if 
m0/(1 - v2)'A 
is interpreted as mass. 
This is done in the development of special 
relativity. Some of the consequences of this identification are discussed 
after the completion of this proof. 
For very small values of lvl the relation (2-6.IOa) approximates 
11 See Problem 9. 
tfl'xa 
Fa= mo-2-· 
dt 

192 
THE DIFFERENTIATION OF VECTORS 
This is a classical form of Newton's second law. The fourth component 
can be expressed as 
or 
s 
! Fava 
2 -Ji 
a=l 
= m d[(l - v ) 
] (1 - v2)-!-f 
(1 - v2)"'2 
° 
dt 
3 
dv 
s 
! Fava= m0v-(1 - v2r%. 
a=l 
dt 
When lvl is approximately zero, and therefore the components va are also 
nearly zero, this expression takes the form 0 = 0. 
4 
The Lorentz invariance of (2-6.9a) depends on the assumption that F;. 
are components of a four-space vector and the linearity of the special 
Lorentz transformations. The linearity accounts for the fact that d2 X'/ds2 
are vector components. On the one hand, 
On the other, 
F'" = c1'-F". 
a2x'" 
,_ a2x1 
--=c -- . 
ds2 
1 ds2 
When these relations are applied to (2-6.9a), we have 
4 
a2x'" 
( 4 
a2x'") 
0 = F' - m0 --= c1;. F" - m0 --2 
• 
ds2 
ds 
Note that m0 is a scalar. Since le., 'I ':;6 0, we can sum the products obtained 
by multiplying the preceding relation with C,_µ. When this is done, we have 
4 
d2X" 
Fµ - m0--2 
= 0. 
ds 
Therefore the law in (2-6.9a) is invariant under special Lorentz trans­
formations. This completes the proof. 
As indicated in the foregoing, the first three components of Newton's 
relativistic second law can be expressed in the form [see (2-6.IOb)] 
pa= d{[m0/(1 - v2)li] dXa/dt}. 
dt 
The relation (2-6.10) suggests the identification of m0/(I - v2)1'2 as an 
entity in its own right, for when this is done 
d 
pa= -(mva). 
dt 
This is the classical form of Newton's second law. 

An introduction to Einstein's special theory of relativity 
193 
Definition 2-6.2. 
The quantity 
(2-6.11) 
is called inertial mass; 
m0 is the rest mass. 
The introduction of inertial mass is responsible for a philosophic 
revolution in physics. Mass can no longer be thought of as a constant. 
The inertial mass corresponds to the rest mass if v = 0 and increases as 
lvl increases. Moreover, from (2-69.a) and (2-6.9c) it follows that 
(2-6.12) 
dm 
 pa a 
- = "" 
v .  
dt 
a-1 
The right-hand member of (2-6.12) represents the rate at which the force 
does work on the particle. In classical mechanics a definite integral of the 
expression denotes the difference between the initial and final kinetic 
energies of a particle. We make the assumption that relativistic kinetic 
energy T is defined by 
(2-6.13) 
dT = I F°va, 
dt 
a-1 
with the initial condition that the kinetic energy is zero when the velocity 
is zero. Then 
(2-6.14a) 
and 
(2-6.14b) 
dT 
dm 
-=-, 
dt 
dt 
T = m + constant. 
Since m 
= m0 when T = 0, it follows that 
(2-6.14c) 
T== m - m0• 
From this relation we see that the kinetic energy increases or decreases as 
the mass increases or decreases. Furthermore, a search for an analogue 
to the classical principle of conservation of energy leads us to write (2-6. l 4c) 
in the form 
(2-6.14d) 
m == T+ m0• 
Einstein made one of the most important discoveries related to the special 
theory of relativity when he hypothesized the equivalence of mass and 
energy. 
Under this hypothesis we identify not only the excess of mass 
m - m0 with kinetic energy but also the rest mass m0 with energy. In 

194 
THE DIFFERENTIATION OF VECTORS 
particular, m0 may be thought of as a manifestation of the work done in 
creating the particle or as potential energy. Then the total energy Eis 
(2-6.15a) 
E= m = T+ m0• 
The merit of this hypothesis has been amply demonstrated by the atomic 
energy experiments of more than a decade. 
The relation (2-6. l 5a) is 
usually expressed in the form 
(2-6.15b) 
E = mc2, 
where c represents the speed of light. We have chosen the light second as 
our unit of distance; therefore c = 1. 
There are many other aspects of special relativity that would be interest­
ing to investigate. It is hoped that the reader will be stimulated to pursue 
them. However, it would not be consistent with the purpose of this book 
to carry their development any further. 
Problems 
1. If the motion of a particle is determined by the parametric equations 
Xi 
= Xoi +Bit, 
that is, it is linear and uniform in the X1 coordinate system, show that it is 
uniform and linear in a system based on the Galilean transformations 
(2-6.1). 
2. (a) Compute the components 
4 
8XY 8XY 
n<Y.{J = I 11xrr. aXfJ 
y=l 
of the fundamental metric tensor if the transformation equations are 
denoted by (2-6.la,b,c). (See Chapter 1, Section 5*.) 
Hint: First write down the inverse transformation equations. 
(b) Determine the formula from which interval should be computed in the 
barred system. Find a formula for the special case of an interval 
along the i axis. 
3. Show that -z2 + t2 = 0 transforms to 
-z2 - 2vZi + (1 
- v2)f2 
= 0 
under the transformation 
z = z + vi, 
t =i. 
4. (a) Show that the z axis and z axis coincide under the transformation of 
Problem 3. If v 
= 1, construct the z,i axes under the assumption that 
the z and t axes are perpendicular to each other. 

Problems 
195 
(y = y + v1i 
(b) If z =  + v2i, shows that they axis corresponds to they axis and that 
t = t 
the z and z axes correspond. 
Hint: See Chapter 1, Sections•. 
5. Suppose that h«{J dX"' dXfJ = hAy dJlA aXY. 
(a) Show that 
oXA oXY 
h«{J = oX"' oXfJ hAy' 
(b) Show that if the elements h«fJ as well as the values h«fJ are constants 
the transformation is linear. 
Hint: Start by differentiating the expression of (a) and arrive at the 
conclusion 02XA/oX"' oXfJ = 
O. 
6. (a) Show that the equations (2-6.lc) satisfy the conditions o2XA/oX"' oXf1 = 0. 
(b) Show that 02XA/axa. oXP = o implies that the oXA/oxP are constants. 
7. Show that z/t = 1 is an invariant under the special Lorentz transformations. 
8. (a) If a coordinate system 0 is in uniform rectilinear motion with respect to a 
system 0 with velocity v = i and a particle P has velocity a = i in 
relation to <5, find the velocity of the particle with respect to 0. 
(All 
motions are along a common straight line.) 
(b) Consider the formula in (2-6.7)'for composition of velocities. If lul < 1 
and Jvl < 1, show that lul < I. 
9. Show that 
3 
4 
 F4v" 
F4 
_ a - 1 
- ..;._
(l
...;-'-v2-)""'Q 
results from the relation ha.fJ (dXa./ds) (dXfJ /ds) = I. [See (2-6.8).] 

chapter 3 partial differentiation 
and associated concepts 
1. Surface Representations 
Just as the concept of curve serves as a geometrical bridge between certain 
physical phenomena and mathematical analysis so does that of surface. 
The purpose of this section is to introduce the reader to the idea of surface 
as it is used in this text. 
Elementary representations of surfaces usually take one of three forms. 
That most often met in an analytic geometry or calculus course is the 
explicit form 
(3-1.la) 
xs = f(X1, x2), 
in which X3 is expressed as a function of two independent variables. The 
domain of definition is a region of the X1, X2 plane, and it can be expressed 
in terms of inequalities such as 
a :s; X1 :s; b, 
c :s; X2 :s; d, 
or 
{X1)2 + {X2)2 :s; r2, 
etc. 
A second representation is the implicit form 
(3-1.lb) 
due to the mathematician Gaspard Monge {1746-1810, French), who was 
one of the founders of the differential geometry of curves and surfaces. 
The form (3-1.Ia) can always be expressed implicitly by the simple 
algebraic expedient of putting all the terms on one side of the equation. 
The converse is true when the criteria of the implicit function theorem are 
met. The third form of surface representation, and the one used most 
196 

Surface representations 
197 
often in this book, is the so-called parametric: 
X1 = X1(v1, v2), 
(3-1.lc) 
X2 = X2( v1, v2), 
X3 = X3(v1, v2). 
This form played a fundamental part in the development of surface 
theory by the "father of differential geometry," Carl Fredrich Gauss. It 
has many advantages for theoretic development, some of which are 
utilized in the remainder of this book. 
To make a detailed study of the concept of surface, its representations, 
and their relations would be too great a digression. Therefore only the 
definitions of the previously mentioned representations and some indication 
of the way in which they are connected are discussed. 
Definition 3-1.1. 
Let 'Y(X1, X2, X3) be a continuous function on a 
region R. Furthermore, let 'Y(X1, X2, X3) have continuous first partial 
derivatives on R such that for each triple (X1, X2, X3) at least one of the 
derivatives does not vanish. Then the geometric locus of points whose 
coordinates satisfy 
'Y(X1, X2, X3) = 0 
is said to be an implicitly defined surface.1 
On occasion it will be expedient to follow the lead of Monge and use the 
implicit surface representation (3-1.lb). 
However, most theoretical 
considerations are based on the parametric form indicated in the next defi­
nition. This definition is stated in three parts, like the definition of a curve. 
Definition 3-1.2a. 
Let [J be a domain of real-number pairs (v1, v2) such 
that 
(a) functions X1, expressed as in (3-l.lc) are continuous on fJ; 
(b) there is a domain D in [Jon which the functions X1 have continuous 
partial derivatives of at least the first order; 
(c) the matrix (oX1/ovf3),j = I, 2, 3, f3 = 1, 22 has rank 2 on D.3 Then 
1 See V. Hlavaty, Differentialgeometrie der Kurven und Fliichen und Tensorrechnung, 
(translated to German by M. Pini), P. Noordhoff, Groningen, The Netherlands, 1939. 
• Greek letters used as indices indicate a range 1, 2 in this section. 
8 The rank of the matrix (iJXi/iJvf3) is 2 if and only if at least one of the second-order 
determinants 
ax1 
ax• 
ax1 oX8 
ax• oX8 
ov1 
iJvl 
iJvl 
av1 
ov1 
ov1 
ax• 
ax• 
ax• 
ax• 
ax• 
ax• 
Tv' 
Tv2 
ov• 
ov• 
Tv' avs 
is different from zero. 

J 98 
PARTIAL DIFFERENTIATION AND ASSOCIATED CONCEPTS 
(3-1.lc) is said to be an allowable parameter representation. The 
symbols v1 and v2 are called surface parameters. The pairs (v1, v2) 
in D are called regular, whereas those in fJ, but not in D, are said 
to be singular. 
The parametric representation of the preceding definition determines a 
set of points in a three-dimensional Euclidean space; however, it is not 
the only parameterization that specifies this particular set of points. New 
parameterizations can be obtained by imposing a transformation 
v« = v«(uP). 
In order to satisfy assumptions (a), (b), and (c) in Definition (3-l .2a), we 
stipulate the following. 
Definition 3-l.2b. 
Suppose that the transformation v" = v"(uP) satisfied 
the following conditions: 
(a) It is a one-to-one bicontinuous transformation between domains 
E of the uP and fJ of the v". 
(b) The functions v"(uP) have continuous first partial derivatives, at 
least on a domain E, which corresponds under the transformation 
to D. 
(c) The Jacobian 1av/au1 is different from zero everywhere on E. 
The parameter transformation is then said to be allowable. 
The preceding definition makes it possible to classify parameter re­
presentations. We specify that two-parameter representations are in the 
same equivalence class if they are related by a transformation satisfying 
the conditions of Definition 3-l.2b. With this stipulation in mind, we are 
in a position to give a meaning to the term surface. 
Definition 3-1.2c. 
The set of all points represented by any one of the 
allowable representations of an equivalence class is said to be a surface. 
If a number pair ( v1, v2) is singular, one of two possibilities hold. Either 
the surface is not smooth at the point of consideration (for example, at 
the vertex of a cone) or the parametric equations give rise to the singularity 
even though the surface element could be geometrically classified as 
smooth. (See Example 3-1.2.) 
If the implicit form (3-1.1 b) is given, then, in a neighborhood of a point 
at which a'Y/aXi '#- 0 for some value ofj, (3-1.l c) can be obtained. The 
theoretical development of this fact makes use of an implicit function 
theorem.4 
• See Angus E. Taylor, Advanced Calculus, Ginn, 1955, Chapter VIII. 

Surface representations 
199 
Our definition points out that a parameterization of the implicit form 
(3-1. l b) is not unique. Furthermore, a second parameterization satisfying 
(3-1.1 b) may not represent all of the original surface. 
The following examples illustrate the preceding statement. 
Example 3-1.1. 
A form of the equation of a plane is 
A· (r - r0) = 0. 
When this implicit surface representation is written out, we have 
A1(X1 - Xo1) + A2(X2 - Xo2) + A3(X3 - Xo3) = 0. 
A possible parameterization is 
X1 = v1, 
x2 = v2, 
xa =
a 
[AaXoa + Ai(Xo1 - v1) + A2(Xo2 - v2)], 
where -oo < v1 < oo, - oo < v2 < oo. The reader can verify that the 
parameteric representation satisfies properties (a), (b), (c) of Definition 
3-1.2. 
If the foregoing parameterization is replaced by 
X1 =sin *v1 
X2 =sin *v2 
X = 
a [A3X03 + A1(X01 - sin *v1) + A2(X02 - sin *v2)), 
the whole plane is no longer represented. In particular, X1 and X2 are 
restricted to the interval [-1, l]. The problem of finding and verifying 
the validity of the domain of (*v1, *v2), for which these two representations 
belong to the same equivalence class, is left to the student. 
Example 3-1.2. The implicit representation of a sphere of radius a and 
center at the origin is 
(3-1.2a) 
(X1)2 + (X2)2 + (Xa)2 _ 02 = O. 
A standard parameterization is 
(3-1.2b) 
X1 = a sin () cos cp, 
X2 = a sin () sin cp, 
X3 =a cos 0, 
where we have let v1 = 0, v2 = cp, 0 ::5: () =:; 77', 0 ::5: cp < 277'. (See Fig. 
3-1.1.) 

200 
PARTIAL DIFFERENTIATION AND ASSOCIATED CONCEPTS 
We have 
(3-l.2c) 
xa 
xi 
Fig. 3-1.1 
(oX;) = a( cos 0 cos </> 
cos 0 sin </> 
-sin 0). 
()vi 
-sin 0 sin </> 
sin 0 cos </> 
0 
The second-order determinants associated with (3-l.2c) have the values 
a2 cos 0 sin 0, 
-a2 sin2 0 sin</>, 
-a2 sin2 0 cos cf>. 
By careful examination of these values it is seen that (0, </>)and (7T, </>) are 
the only singular coordinate pairs. Since the surface is smooth at each 
corresponding point, it is the parametric representation that produces the 
singularities. 
A second parameterization associated with the sphere is indicated below. 
In order to satisfy the single-valued property associated with the term 
function, separate representations must be given for that part of the sphere 
corresponding to X3 > 0 and that part corresponding to X3 < 0. It will 
be seen that this parameterization cannot account for X3 
= 0 and still 
meet the requirements of Definition 3-1.2a. Parametric equations repre­
senting the upper hemisphere are 
(3-l.3a) 
x1 
= vl, 
x2 = vz, 
xs = [a2 _ (v1)2 _ (v2)2]l-i. 
Since only real surfaces are to be considered, 

Surface representations 
201 
Parametric equations of the lower hemisphere are 
X1 = v1, 
(3-1.3b) 
x2 = v2, 
xa = -[a2 - (v1)2 - (v2)2](. 
where again 
(v1)2 + (v2)2 < a2. 
The matrix (oX1/otJ) has the following form with respect to the parametric 
representation (3-1.3a) of the upper hemisphere: 
(l 0 
-v1 ) 
(3-1.3c) 
e5) -
o 
I 
[a' -(v',: <"'l'I) 
[a2 
_ (v1)2 
_ (v2)2]li 
The matrix has rank 2 on the domain of definition. Note that the domain 
of definition cannot be extended to 
(v1)2 + (v2)2 = a2. 
The few facts concerning surfaces so far stated will be valuable in the 
geometrical interpretation of vector concepts. A knowledge of what is 
meant by a curve on a surface is also important. The way in which this 
term is to be used is indicated by the following definition. 
Definition 3-1.3.5 
Let v1 and v2 be functions, defined on a real number 
interval a @ t @ b, which possess the following properties: 
(a) At least the first derivatives are continuous and do not vanish 
simultaneously. 
(b) The coordinate pair(v1(t), v2(t)) is in D (see Definition 3-1.2) for all t. 
(c) Not all elements oX1/otJ vanish simultaneously at surface points 
with coordinates (v1(t), v2(t)). 
The set of points with coordinates (v1(t), v2(t)) is said to be a surface 
curve.6 For our purposes, the most important of these curves are the 
parameter curves. 
Theorem 3-1.1. 
If a surface element is given by the parametric rep­
resentation X1 = X1(tJ), the sets of points in D, such that v1 = constant 
for all v2 and the set v2 = constant for all v1, represent surface curves. 
PROOF. 
Consider the points with coordinates v1 = constant for all v2• 
We can take as a parameterization 
v1 = c, 
v2 = t. 
The properties of Definition 3-1.4 are easily checked. 
11 See V. Hlavaty, op. cit., p. 99. 
1 The curve has other parametric representations. See Definitions 2-1.2a, b, c. 

202 
PARTIAL DIFFERENTIATION AND ASSOCIATED CONCEPTS 
X1=0 
Fig, 3-1.2 
Definition 3-1.4. 
The curves of the families v1 
= constant for all v1 and 
v2 
= constant for all v1 are called parametric surface curves. 
Such curves play the same role on a surface as the curves X1 = constant 
and X2 = constant play in the plane, that is, the two f amities determine 
a coordinate net for the surface. (See Fig. 3-1.2.) 
Example 3-1.3. 
Consider the surface (3-1.3a); v1 
= constant and v2 
= 
constant correspond to X1 = constant and X2 = constant. 
Therefore 
' 
' 
' 
\ 
\ 
\ 
I 
I 
I 
\ 
I 
I 
I 
\ 
\ 
I 
\ 
' 
I 
I 
__ ..J._-1. __ L. __ , 
Fig. 3-1.3 
in this situation the parainetric curves 
can be thought of as curves of intersec­
tion of the upper hemisphere and the 
coordinate planes. (See Fig. 3-1.3.) 
Example 3-1.4. 
Consider the para­
metric curves associated with the surface 
representation (3-1.2b). The curves () = 
constant are latitudinal circles and can 
be interpreted geometrically as intersec­
tion curves of cones () = constant with 
the sphere. The curves rf> = constant are longitudinal circles which can 
be thought of as intersections of planes r/> = constant with the sphere. 
(See Fig. 3-1.4.) 
The next example presents a general surface curve on a sphere. 
Example 3-1.5. 
Consider the parametric equations (3-l.2b) of a sphere. 
Let 
(3-1.4a) 
() = t 
r/> = 2t 

Surface representations 
203 
Then 
(3-l.4b) 
X1 = a sin t cos 2t, 
X2 = a sin t sin 2t, 
X3 =a cos t. 
The reader can easily verify that Definition 3-1.3 is satisfied. Note that 
the exclusion of the value t = 0 is quite necessary, A rough sketch of 
the curve is indicated by Fig. 3-1.5. 
Definitions 2-1.3 and 2-1.4 introduce 
the concepts of scalar and vector fields 
over a space curve C. The following defi­
nitions extend these ideas to surfaces and 
space regions. 
Definition 3-1.5a. 
Suppose that the 
class of functions {<I>} is defined on a 
region R and that at each point of R any 
two elements of {<I>} satisfy Definition 
1-4.2. Then {<1>} is said to be a scalar 
field on R with respect to the allowable 
transformation group. 
Fig. 3-1.4 
If R is a space region, then <I>, a representative of the class {<I>}, is a 
function of the coordinates X1• On the other hand, if R is a surface or 
section of a surface, then <I> has a domain consisting of parametric values 
(v1, v2). 
x3 
I 
I 
I 
I 
/ 
I 
. / 
-------r---r---
...... -
I 
/ 
-....... 
",,. 
I// 
.... , 
---------..,IL---------
x2 
/ 
// 
xi 
Fig. 3-1.S 

204 
PARTIAL DIFFERENTIATION AND ASSOCIATED CONCEPTS 
Definition 3-1.Sb. 
Suppose that the class of function triples {U1, U2, U3} 
is defined on a region Rand at each point of R any two triples of {U1, U2, 
U3} satisfy Definition 1-4.1. Then {U1, U2, U8} is said to be a vector field 
on R in relation to the allowable group of transformations. 
The vector field is designated by the symbol U, to be consistent with 
previous usage. 
Example 3-1.6. 
The Newtonian force field, F = (-mMG/r2)R, played 
a part in Chapter 2, Section 5. It was assumed that there existed a curve 
C (the geometric representation of the path of a planet) along which F was 
defined. We then proceeded to find the polar equation of C. Upon reflec­
tion, t11e viewpoint taken toward the vector field F must be considered as 
rather artificial. Actually, the sun sets up a physical condition throughout 
space such that, if a body of mass m = I were placed at any point, a force 
F = -MGR/r2 would be observed; that is, the physical phenomenon is 
described by a vector function whose domain is the set of triples ( X1' X2' X8) 
corresponding to every point of space (except r = 0). 
Example 3-1.7. 
Consider a windowpane. At a given instant of time 
there is a temperature associated with each point of the pane. We can 
introduce a temperature function that is certainly independent of coordin­
ate representation. The domain of the function is a set of number pairs 
(v1, v2) corresponding to the points of a plane region. 
Problems 
1. Set up parametric equations for a plane surface other than those given in 
Example 3-1.1. 
Check to see whether your representation has any 
singularities. 
2. Find parametric representations for each of the following surfaces. Check to 
see that Definition 3-1.2 is satisfied. 
(X1)2 
(X2)2 
(X3)2 
. 
. 
(a) -2- + -b2 
+ -
2 -
= 1, elhps01d. 
a 
c 
(X1)2 
(X2)2 
(X3)2 
(b) E + /j2 - ---;;:-
= 1, hyperboloid of 1 sheet. 
(X1)2 
(X2)2 
(Xa)2 
. 
(c) E + /j2 - ---;;:-
= 0, quadric cone. 
(X1)2 
(X2)2 
(d) 7 - /j2 + 2X3 = 0, hyperbolic paraboloid. 

Vector concepts associated with partial differentiation 
205 
(Xl)2 
(X2)2 
 +---;- = 1, elliptic cylinder. 
3. Let a sphere be represented parametrically by 
X1 = 3 sin (} cos "'· 
X2 = 3 sin (} sin"'· 
X3 = 3 cos(}, 
Construct a sketch of each of the following surface curves. 
(a) (} = t, 
</> = 2t, 
0 M t M 1T. 
(b) (} = t, 
"' = t2• 
0 M t M 1Tj2. 
4. Suppose the parametric equations of a hemisphere were 
x1 = vI 
X2 = v2, 
xa = [4 - (vl)2 - (v2)2]l-l. 
Construct a sketch of each of the surface curves 
(a) v1 = t, 
v2 = t2. 
(b) v1 = cost, 
v2 =sin t. 
(c) v1 = cosh t, 
v2 = sinh t. 
0 M t M 21T. 
OMtMl. 
How might these curves be thought of as intersections of surfaces? 
5. Show that the curve </> =In (ctn (} - csc 0) makes the same angle with each 
of the meridians it crosses. Such a curve is called a loxodrome. 
Hint: Show that 
dr1/d0 • dr2/d0 . 
--- is constant. 
ldr1/d01 ldr2/d0/ 
dr1/d0 and dr2/d0 represent tangential vector fields along a meridian and 
along the given curve, respectively. 
6. With respect to Example 3-1.1, find the domain (*v1, *v2) such that 
v1 =sin *v1 
v2 =sin *v2 
is an allowable parameter transformation. 
7. Find the appropriate parameter transformation for Example 3-1.2 and then 
repeat Problem 6. 
2. Vector Concepts Associated with Partial Differentiation 
Let us suppose that a function <I> represents a scalar field along a given 
curve. The curve may be a space curve, in which case 
(3-2.la) 

206 
PARTIAL DIFFERENTIATION AND ASSOCIATED CONCEPTS 
and the associated derivative field is 
(3-2.lb) 
d'1> 
o'1> dX1 
dt = oX1dt. 
On the other hand, the curve might lie on a given surface. Then 
(3-2.2a) 
'1> = '1>{X1[v P(t)]}, 
and the associated derivative field has the representations 
(3-2.2b) 
d'1> 
oq, ox; dvP 
o'1> dx1 
di= 
ox1 ovP di= ox1Tt · 
Whether the curve in question is a general space curve or one which is 
restricted to a surface, the factors dX1/dt appearing in the representations 
(3-2.lb) and (3-2.2b) are components of the tangent vector field dr/dt to 
the curve. 
For the moment, suppose that '1> were defined along a space curve 
X1 = X1(t). The representation (3-2.lb) has the form of a dot product. 
Furthermore, the factors dX1 /dt have geometric significance. Therefore 
it is quite natural to introduce an expression with components o'1>/oX1 
with the objective of determining its geometric properties. 
This is the 
procedure used in the following development. 
Definition 3-2.1. 
The symbol V (read "del") is an operator whose 
components satisfy the condition 
(3-2.3) 
d'1> = V'l> 
• dr 
. 
dt 
dt 
The operator V was first introduced by Hamilton in the development 
of the theory of ·quaternions. The preceding mode of introduction does 
not coincide with that of Hamilton. The representation introduced by 
him was the rectangular Cartesian form in Theorem 3-2.l.7 
Theorem 3-2.1. 
The rectangular Cartesian form of V is 
(3-2.4) 
0 
0 
0 
3 
0 
V = L1 
- + L2 - + L3 -8 = ! L; -1 
• 
ox1 
ox2 
ox 
1=1 
ox 
PROOF. 
Represent the components of V'l> by (V''1>)1, (V''1>)2, (V''1>)3. 
express the left-hand side of (3-2.3) as indicated by (3-2. lb). Then 
(3_2.Sa) 
o'1>
_ 
dX1 = (V''l>). dX1
• 
oX' dt 
' dt 
7 See Philip Kelland, Peter G. Tait and C. G. Knott, Introduction to Quaternions, 
Macmillan, New York, 1904. In this text the symbol Vis called nabla. 

Vector concepts associated with partial differentiation 
207 
Relation (3-2.5a) can be written just as well in the form 
(3-2.5b) 
[ o<I> 
- (V'<I>) J 
dX; = 0. 
oX1 
; 
dt 
The representation of V at a point P is not dependent on any one-space 
curve through P. Therefore the components dXi/dt can be chosen arbi­
trarily. Because of this fact the parenthetic expression in (3-2.5b) is equal 
to zero. This completes the proof. 
As far as the considerations of this section are concerned, the form 
(3-2.4) of V could be introduced as the definition. However, this would 
lead to future difficulties. In the section on curvilinear coordinates V is 
used in a form consistent with Definition 3-2.1 but distinct from (3-2.4). 
Various uses of the operator V are possible from a purely algebraic 
point of view. We can consider the application of V to a scalar. On the 
other hand, V might be employed in conjunction with the processes of 
dot and cross multiplication. Let us explore these possibilities as well as 
the geometric and physical concepts they initiate. 
Definition 3-2.2. 
Let <I> be a differentiable scalar function (the domain 
can be coordinate n-tuples associated with a space curve, a surface element, 
or a region of space). The quantity V<I> is called the gradient8 field derived 
from <I>. For rectangular Cartesian coordinates 
(3-2.6) 
0<1> 
a<1> 
a<1> 
V<I> - l 
- + l 
- + L 
-
- 1 ax1 
2 ax2 
3 axs . 
Theorem 3-2.2. 
The gradient field V<I> is a vector field with respect to 
the orthogonal Cartesian group of transformations. 
PROOF. 
Reell the coordinate transformation relations in (l-3.9a), 
that is, X1 
= a/ Xk. We have noted that 
oX1 
a ; 
__ 
k - axk· 
Because we are dealing with the orthogonal Cartesian transformations 
(see Section 3), 
(3-2.7a) 
axk 
. 
ax1 
- A k- a ' -
oXi 
-
; 
-
k - a xk . 
Now the components of V<I> satisfy the relation 
a<1> 
a xk a<1> 
s ax 1 a<1> 
<3-2·7b) 
ax1 = ax1 axk = k axk axk 
Therefore the proof is complete. 
•The term "gradient" is taken from meteorology. 

208 
PARTIAL DIFFERENTIATION AND ASSOCIATED CONCEPTS 
It is worth noting that this proof(that the components a<t>;axi transform 
in .a manner contravariant to the way in which the basis n-tuples t; trans­
form) depends specifically on the property (3-2.7a) of the orthogonal 
Cartesian group. More generally, as indicated by the middle member of 
(3-2.7b), the components a<t>;ax; transform in a manner covariant9 to the 
basis n-tuples. 
It is convenient to think of V as a vector operator; in order that it 
may be so the components of V must satisfy the transformation law 
(3-2.7c) 
a 
axk a 
axi 
= 
ax1 axk · 
Because no inconsistency can result from this procedure, it is used when­
ever convenient in the remainder of the book. 
The next theorem serves to determine the major geometric properties 
of the gradient function. 
Theorem 3-2.3. 
If a scalar function <I> is constant on a space curve C, 
the gradient V<I> is perpendicular to the tangent vector dr/dt on C. (Assume 
that V<I> -:F 0.) 
PROOF. 
Since <I> is constant on C, d<P/dt = 0. Therefore 
(3-2.8) 
O = 
d<P 
= V<I> 
• dr ' 
dt 
dt 
and since (3-2.8) is a necessary and sufficient condition for orthogonality 
the proof is complete. 
In the next theorem it is assumed that a surface is given according to the 
representation of Monge, that is, in the form 
(3-2.9a) 
'l"(X1, X2, X3) = 0, 
and that the surface can also be expressed parametrically by 
(3-2.9b) 
x1 = Xi(Ji). 
Theorem 3-2.4. 
At each point of a surface (3-2.9a) where V'I" -:F 0 the 
gradient vector field V'I" is normal to the surface. 
PROOF. 
Let P0 be a point on 'I" with surface coordinates 
(vo1. V02). 
Then 
and 
•See Chapter 1, Section 5. • 

Vector concepts associated with partial differentiation 
209 
are parametric curves passing through P0• 
The surface representation 
'¥(X1, X2, X3) = 0 can also be interpreted as a constant scalar field 
'¥[X1(v01, v2)] or '¥[X1(v1, v02)] defined on either of the parameter curves. 
According to Theorem 3-2.3, V'f" is orthogonal to the tangent vector 
associated with each parameter curve. Therefore V'f" is orthogonal or 
normal to the tangent plane determined by these two tangent vectors. 
Since orthogonality to the tangent plane is equivalent to orthogonality 
to the surface, the theorem is proved. 
It is possible to have a scalar function cl> defined on a surface '¥ = 0 
so that 
(3-2.10) 
cl> =  «l>('f"). 
Since '¥ has the value zero for every point on the surface, it follows that 
the scalar function cl> is constant on the surface. The relation between 
the respective gradient functions is stated in the nc;xt theorem. 
Theorem 3-2.5. 
If cl> is a scalar field defined on a surface 'I" = O in such 
a way that (3-2.10) holds: 
(3-2.11) 
V<l> = o<l> V'¥. 
o'¥ 
, 
that is, V<l> has the same direction as V'JI'. 
PROOF. 
We have 
(3-2.12) 
s 0<1> 
s a«1> o'f" 
a«1> 
V<l> =  - L; =  ---. L; = -V'JI'. 
i=l ax1 
1-1 o'¥ ox' 
o'¥ 
This completes the proof. 
Example 3-2.1. 
The gravitational force vector field has the representa­
tion (see Chapter 2, Section 5) 
(3-2.13a) 
F = -mMGR 
r2 
' 
where R is a unit vector. For simplicity, assume that the center of the 
force field is at the origin of a rectangular Cartesian coordinate system; 
then 
The immediate interest is in the fact that F is proportional to I/ r2; 0-2. l 3a) 
can also be written in the form 
(3-2.13b) 
F = kR = kr
' 
r2 
rs 
k= -mMG. 

210 
PARTIAL DIFFERENTIATION AND ASSOCIATED CONCEPTS 
The introduction of a gravitational potential function 
k 
(3-2.13c) 
Cl> = -
r 
is standard procedure in a theoretical discussion of gravitational concepts. 
Then, as we can show by a straightforward computation, 
(3-2.13d) 
F = -Vel>. 
The function Cl> is defined everywhere except at the origin. In particular, 
let 
(3-2.13e) 
'Y(X1, x2, X3) =: (X1)2 + (X2)2 + (Xa)2 - az = 0. 
The function Cl> is constant on the spherical surface (3-2.13e). We have 
(3-2.13f) 
V'Y = 2(X1L1 + X2L2 + X3L3) = 2r; 
therefore 
(3-2.13g) 
kr 
k 
VcI> = 
-
- = 
- -V'Y. 
r3 
2r3 
The last relation may be compared to (3-2.11) in Theorem 3-2.5. 
Surfaces such as (3-2.13e), on which a given potential function is con­
stant, are called equipotential. It is clear from Theorem 3-2.5 that the 
associated vector force field is normal to the equipotential surfaces. This 
particular fact gives rise to a fruitful geometric interpretation of force 
fields in terms of lines of force and equipotential surfaces. Such representa­
tions were first used by Faraday in his study of electric and magnetic 
phenomena. 
Although potential functions can be associated with many fields of 
force (static electric, static magnetic, gravitational, etc.), it would be 
improper to leave the impression that this can always be done. It is more 
accurate to say that such a representation is possible only in exceptional 
cases. Because these exceptions are important, a special name has been 
established. When a force field F has a representation VcI>, it is said to be 
a conservative field of force. 
Another important property of the gradient of a scalar field Cl> is stated 
in the following theorem. 
Theorem 3-2.6. 
The maximum change of the scalar field Cl> takes place 
in the direction and sense ofVCl>. 
PROOF. 
Let P be a point in the region of space on which Cl> is defined. 
Let C be an arbitrary curve through P0, whose parametric equations are 
represented in terms of arc length s. We have 
(3-2.14) 
del> 
dr 
I 
dr I 
-
= VcI> • - = IVCl>i -
cos 0. 
ds 
ds 
ds 

Vector concepts associated with partial differentiation 
211 
The change of <I> with respect to s is represented by the left-hand member 
of this expression. Examining the right-hand member, we observe that 
V<I> depends only on the coordinates X/ of P0 (in particular, not on the 
choice of C), whereas ldr/dsl = 1 for all C. Therefore d<l>/ds depends on 
cos 0. 
Since cos 0 is maximum when 0 = 0, it follows that d<l>/ds is 
maximum when C is chosen such that the tangential vector dr/ds has the 
same sense and direction as V<I>. 
If() = TT, then 
(3-2.15) 
d<I> 
ds = -\V<l>I ; 
that is d<l>/ds is minimum in the sense opposite that of·V<I>. 
Definition 3-2.3. 
Let a scalar field <I> along a curve C be expressed in 
terms of arc length s. The change of <I> with respect to s, that is, 
d<I> = V<I> 
• dr 
' 
ds 
ds 
is called the directional derivative of the scalar field <I> in the direction 
and sense of dr/ds. 
Note that the directional derivative' of <I> is just the component (or the 
projection with the appropriate sign) of Vet> in the given direction. 
Example 3-2.2. 
Let <I> = <l>(X1, X2) be a scalar function defined on a 
region of the X1, X2 plane. A line, 
X1 = a + s cos (), 
(3-2.16a) 
X2 = b + s sin (), 
expressed in terms of the arc-length parameter s, specifies a direction at 
a point P(a, b) of this region. The unit tangent vector 
(3-2.16b) 
(dX1 dX2) 
- , -
=(cos 0, sin 0), 
ds 
ds 
determines a particular sense. The directional derivative d<l>/ds is then 
d<I> = o<I> dX1 + O<I> dX2 
ds 
oX1 ds 
oX2 ds 
(3-2.16c) 
O<I> 
0 
O<I> 
• 
() 
= ax1 
cos 
+ ax2 
sm 
. 
The values o<l>/oX1, o<l>/oX2 depend only on the point P; therefore the 
directional derivative is just dependent on the direction and sense of the 
tangential vector or, in other words, on the angle 0. (See Figs. 3-2.l and 
3-2.2.) 

212 
PARTIAL DIFFERENTIATION AND ASSOCIATED CONCEPTS 
x2 
Fig. 3-2.1 
xa 
•(a,b,0) 
I 
xi 
Fig. 3·2.2 

Vector concepts associated with partial differentiation 
213 
In the first part of this example <I> was not interpreted geometrically: 
neither were V<I>, nor the directional derivative d<l>/ds. Geometric mean­
ings can be supplied by setting <l>(X1, X2) equal to a dependent variable 
X3• Then 
(3-2. l 7a) 
is the explicit representation of a surface (under the assumption that the 
appropriate derivatives exist). 
The equations in (3-2.16a) represent a 
plane, and the intersection of that plane with the surface in (3-2. l 7a) is a 
surface curve : 
(3-2.17b) 
X1 = a + s cos (). 
X2 = b + s sin (), 
X3 = <l>(a + s cos e. b + s sin()), 
Observe that s does not denote arc length for this curve. (See Problem 15.) 
If (3-2.17a) is expressed in the form 
(3-2.17c) 
'Y(X1, X2, X3) = <l>(X1, X2) - xa, 
then 
(3-2.17d) 
( aqr 
o'Y o'Y) = ( a<1> 
0<1> - i) 
oX1 
• oX2 ' oX3 
oX1 ' oX2 • 
• 
Therefore o<l>/oX1, o<l>/0X2 are the first two components of the normal 
to the surface. A geometric significance for the directional derivative 
itself can be obtained from the expression for a tangential vector field 
to the surface curve (3-2.17b), that is, 
(3-2.17e) 
dr =COS ()l1 +sin ()L2 + (O<f>l COS()+ (}<f> sin ())l3. 
ds 
ox 
oX2 
When this expression is dotted with L3, we have 
dr 
dX3 
0<1> 
o<I> . 
d<I> 
(3-2.17f) 
L3 
• - = - = - cos () + - sm () = - . 
ds 
ds 
oX1 
oX2 
ds 
Therefore the directional derivative of <I> in the direction of () can be 
interpreted as the projection, with appropriate sign, of the tangent vector 
onto the X3 axis. 
We conclude this discussion of the application of the vector operator 
V to scalar functions by considering the differentiation of sums and prod­
ucts. The reader will find these rules easy to assimilate, for they agree 
with those learned in the study of calculus. 
Theorem 3-2.7. 
Let <1>1 and <1>2 be scalar functions defined on a common 
region of space. If the partial derivatives exist, then 
(3-2.18a) 
V(<l>1 + <1>2) = CV<l>1) + CV<l>2). 
(3-2.18b) 
V(<l>1<l>2) = CV<l>1)<l>2 + <l>1(V<l>2). 

214 
PARTIAL DIFFERENTIATION AND ASSOCIATED CONCEPTS 
PROOF. 
As a consequence of the corresponding properties of partial 
derivatives, we have 
a 
a 
. 
a 
" 
a 
" 
V(<l>1 + <1>2) = ! l; -. (<1>1 + <1>2) = ! L; -1 + ! L; -2 . 
;=1 
ax' 
i=l 
ax' 
;=1 
ax1 
The relation (3-2.18b) can be verified in an analogous manner. 
If <1>1 is constant (i.e., <I>= c), then the relation (3-2.18b) reduces to 
(3-2.18c) 
Vc<l> 2 = c V<l> 2• 
A rather obvious next step (at least from the algebraic point of view) 
is that of examining the properties of the vector operator del in connection 
with dot and cross multiplication. Actually, the introduction of a new 
concept is involved. This new entity is presented in analogy with and in 
generalization of an old one. 
Definition 3-2.4. 
If G is a differentiable vector field expressed in terms 
of rectangular Cartesian components, then 
(3-2.19a) 
V. G = aG1 
+ aG2 
+ aGa
. 
ax1 
ax2 
axa 
V • G is read "del dot G" and is called the divergence of the vector field G. 
The name divergence comes about because of the physical uses of the 
concept. Roughly speaking, V • G gives a measure of the variation of the 
field G at each point of definition. The name convergence was given to 
-V · G by Clerk Maxwell and is still found in some writings on physical 
science. 
On occasion it will be convenient to express V • G in notational form 
a;G;, where 
(3-2.19b) 
a 
a;=-. 
ax; 
This convention lends itself to the application of the summation conven­
tion. 
The expression (3-2.19a) looks like the ordinary dot product; however, 
the reader should be wary. In particular, note that V • G is not commuta­
tive; V • G is a function, whereas G ·V is an operator. 
The rules of differentiation associated with the divergence concept 
agree with those of ordinary differentiation. 
Theorem 3-2.8. 
If <I> is a differentiable scalar field and G and H are 
differentiable vector fields, then 
(3-2.20) 
(a) V -(G + H) = V • G + V ·H. 
(b) 
V -(<l>G) = V <I>· G + <l>V ·G. 

Vector concepts associated with partial differentiation 
215 
PROOF. 
The proofs follow from the corresponding properties of partial 
derivatives. The details are left to the reader. 
Ample demonstration of the application of the divergence concept to 
physics are to be found in the chapter on integration. 
The following 
example may serve the immediate purpose of indicating its usefulness. 
Example 3-2.3. 
In Example 3-2.1, as well as in the section on Newtonian 
orbits, it was pointed out that the gravitational force field of a body is 
proportional to r/r3• The same statement is valid for both the electrostatic 
and magnetostatic force fields (under appropriate conditions). For such 
fields we have 
(3-2.21a) 
v. () = 0, 
r  0. 
This fact is demonstrated by the following computations: 
(3-2.21b) 
" 
. 
ax1 
ax2 
oX3 
V·r=o·X'=-
· 
-+-+-=3 
' 
ax1 
ax2 
oX3 
The results in (3-2.2lb) and (3-2.2lc) can be used to verify (3-2.2la). 
The case in which a force field proportional to r/r3 has a zero divergence 
everywhere except at r = 0 corresponds to an idealized physical situation 
in which the field is assumed to originate at a single point. 
Theorem 3-2.9. 
The divergence of a vec,or field G is a scalar field with 
respect to the orthogonal Cartesian group of transformations. 
PROOF. 
With the coordinate transformation equations 
in mind, we have 
This completes the proof. 
In particular, if G is a gradient vector, that is, 
G = VCI>, 

216 
PARTIAL DIFFERENTIATION AND ASSOCIATED CONCEPTS 
then V · V<I> is a scalar field. This expression is called the Laplacian and is 
often written in the symbolic form V2<1>. 
Laplace's partial differential 
equation 
and Poisson•s equation 
V2<1> = 4rrp, 
play significant parts in various aspects of theoretical physics. 
Let us turn our attention to the concept of cross multiplication as it is 
related to the operator V. 
The following definition is suggested by the 
cross product of two vectors. 
Definition 3-2.5. 
If G is a differentiable vector field referred to rec­
tangular Cartesian coordinates, then 
(3-2.22a) 
or 
(3-2.22b) 
VxG-L 
- -
-
L 
- --
( oG3 
aG2) 
( aG1 
oG3) 
-
1 ax2 
oX3 
+ 2 oX3 
ax1 
VxG= 
a 
a 
a 
ax1 
ax2 
oX3 
G1 
G2 
Ga 
The expression V x G (read del cross G) is called the curl of G. 
The determinant (3-2.22b) is merely symbolic. It provides an easy way 
to remember the expression in (3-2.22a). Another form of the curl of a 
vector, which is computationally advantageous, is 
(3-2.22c) 
where 
(3-2.22d) 
s 
v x G =I L"'&"';k a;Gk, 
j)=l 
a;=...£._. 
ax; 
The name "curl" was coined by Clerk Maxwell. 
Maxwell, in his 
Electricity and Magnetism, published in 1873, made use of some of the 
notation and terminology of Hamilton's quaternion theory but pretty 
much avoided the operational methods, probably because he considered 
them too complicated. 
We often find, especially in the German literature, the terms rotor or 
rotation used for V x G. 

Vector concepts associated with partial differentiation 
217 
The next theorem points out the vector character of the curl of a vector 
in relation to the orthogonal Cartesian group of transformations. 
Theorem 3-2.10. 
Let G be a differentiable vector field. Then V x G 
is a vector field with respect to the orthogonal Cartesian group of trans­
formations. 
PROOF. 
The components of V x G are 
We have 
a 
a 
k 
IE11;k-.G. 
;=1 
oX' 
 E 
CJG
k _(A qA rA sc )A u _i_ ( k.t"v) 
k 11;k '.l 
i - k 
jl 
i 
k ()qrs 
i 
-
a,, v 
1=1 
uX 
;=1 
X" 
uu Q"A qc 
0 
,.., 
= u 
Uv 
'P l>qrs -= V -
oX" 
f A qt 
o 
0" 
= 
j) Q'uv 
:tixu 
. 
u=l 
u 
This completes the proof. 
Problems 
1. Put the surface representations of Problem 2 , Section l, in the form 
'F'(X1, X2, X3) = O and find V'F' in each case. 
2. 
(a) Find V'F' if 'F'(X1, X2, X3) = (X1)2 + (X2)2 + (X3)2. 
(b) Let X1 = 3 sin 0 cos <f>, X2 = 3 sin 0 sin</>, X3 = 3 cos 0. Show that 
V'F' = 6 (sin (J cos </>L1 + sin (J sin </>L2 + cos 0L3). 
(c) If (J = O(t), </> = </>(t) show that 
dr ( 
d(J 
d</>) 
dt 
= 3 cos (J cos </> dt 
- sin (J sin </> dt L1 
( 
d() 
d<f>) 
d() 
+ 3 cos () sin</> dt 
+ sin ()cos</> dt 
L2 - 3 sin () dt la· 
[Use the parametric representation of (b).] 
(d) Compute dr/dt in (c) if() = t, </> = t. 
(e) Show by direct computation that V'F' · (dr/dt) = 0 [by using (b) and 
(d)]. 
3. The scalar function Il 
= ln[(X1)2 + (X2)2 + (X3)2]1'2 is constant on the 
surface 
(Xl)2 + (X2)2 + (Xa)2 = a2, 
where a is a constant. Show by direct computation that the gradient of 
the surface and the gradient of Il are proportional at each point of the 
surface. In fact, 
1 
V Il 
= 2a" V'F'. 

218 
PARTIAL DIFFERENTIATION AND ASSOCIATED CONCEPTS 
4. Compute V • G and V x G for each of the following vector fields: 
(a) G = XJL1• 
(b) G = X1X2L1 + (X1)2L2 + x1 x2 X3La. 
(c) G = sin X1 cos X2L1 + cos X2Li + sin X1 cos X3La. 
5. Find the equation of the tangent plane to the ellipsoid 
(X1)2 
(X2)2 
(Xs)2 
-4
-+ 
-2-+ -1- = 1 
at (1, 1, t). 
6. Find a vector normal to the surface X1X2 - X3 = 1 at the point (2, 1, 1). 
7. If <l>(X1, X2, X3) = (X1)2 + (X2)2 + (X3)2, show that V<I> = 2r. 
8. Find H if H 
= -V<l> and <I> = eax• sin bX1 cosh cX2; a, b, care constants. 
9. Given/= f(u, v), u = u(Xi), v = v(Xi), show that 
of 
of 
VJ= au Vu+ 
ov Vv. 
10. If d'l/dt = F • (dr/dt) for arbitrary dr/dt, prove that F1 = O<l>/ oXi. 
11. Show that the parameter s, used to express the curve equations (3-2.17b), 
does not denote arc length by showing that dr/ds is not a unit vector. 
3. Identities Involving V 
This section is devoted to a compilation of the algebraic properties of 
gradient, divergence, and curl. All proofs are referred to rectangular 
Cartesian coordinates. Later it will be seen that the results obtained in 
t his section can be employed in relation to general coordinate systems. It 
is assumed throughout the section that the differentiations are defined. 
Theorem 3-3.1. 
We have 
(3-3.1) 
(a) 
V • r = 3 (for a three-dimensional space), 
(b) 
V x r = 0, 
(c) 
V • ,-ar = 0. 
PROOF. 
The relations in (3-3.la) and (3-3.lc) were developed as part 
of Example 3-2.3. The proof of (3-3.lb) is constructed as follows: 
where 
a 
a 
v x r = I LpEpjk o1 xk = I Ll>Ellik !Jik = 0, 
p-1 
p=l 
a 
01 = 
oX1• 
The reader may verify the last equality by writing out the summations. 
A simpler way of reaching the result is to note that, although !Jik is sym­
metric inj and k, the symbol EpJk is skew symmetric (i.e., E1>Jk = -Epk;). 

Identities involving V 
219 
Theorem 3-3.2. 
We have 
(a) V • V x U = 0 (the divergence of the curl is zero). 
(3-3.2) 
{b) jv x (V x U) = V(V. U) - v2u, I (V2 = v. V). 
(c) 
(V x V) x U = 0. 
PROOF. 
The proofs of the relations in {3-3.2a) and (3-3.2c) are left 
to the reader. The expression in (3-3.2b) can be verified as follows: The 
components of V x (V x U) are 
Em' o.6:1>ik o1Uk = E r•:Pf;:Pik o, o1Uk 
= 26·1 a. o1Uk = 20. ac•u•] 
= ar(o.U') - (o. a·ur). 
The relation in {l-6.l l a), as well as the definition of the brackets [as 
indicated in (l-6.12b)], was used to obtain the equalities. The last member 
of the string of equalities represents the components of the right-hand side 
of (3-3.2b). This completes the proof. 
Theorem 3-3.3. 
We have 
(a) 
U x (V x W) = Vw(W • U) - (U • V)W 
where V w symbolizes the fact that V operates on W alone. The corre­
sponding statement holds for Vu· 
(3-3.3) 
(b) V(U • W) = Vu(U • W) + Vw(U • W) 
= U x (V x W) + W x (V x U) + (U • V)W 
+ (W·V)U. 
(c) 
V • (U x W) = (V x U) • W - (V x W) • U. 
(d) 
V x (U x W) = (W • V)U - W(V • U) + U(V • W) - (U • V)W. 
PROOF. 
The validity of (3-3.3a) is demonstrated as follows (for nota-
tional convenience let uq = u0 and o• = 0 .) : 
U x (V x W) = L:PE:PQ•u 06,,1 o•wt 
= L:P26=q
1Uq o'W1 = L:P2Uq oCl>WQ1 
= lJ>Uq ol>WQ - lJ)UQ oQW:P 
= Vw(W • U) - (U • V)W. 
The other proofs are left to the reader. In particular, (3-3.3b) is easily 
obtained with the help of (3-3.3a). 

220 
PARTIAL DIFFERENTIATION AND ASSOCIATED CONCEPTS 
lbeorem 3-3.4. 
We have 
(3-3.4) 
(a) 
(W·V)r = W, 
(b) dG 
= (dr. v)G, 
dt 
dt 
G = G[X1(t)]. 
PROOF. 
The proof of (3-3.4a) is left to the reader. Starting with the 
right-hand side of (3-3.4b), we have 
dr 
dX1 o 
k 
dG.,. 
dG 
-·V G =  --(G tk) = - L.,. =-. 
dt 
dt iJXi 
dt 
dt 
The relation in (3-3.4b) is nothing more than the vector statement of a 
total derivative formula. 
To memorize the identities of this section would be a tedious task. 
Fortunately, this can be avoided. 
By close examination the observant 
reader can determine that the derivative laws already known from calculus 
actually hold. Of course, a consistency property must be kept in mind; 
that is, V must operate on the same quantities in both members of an 
identity. 
Problems 
1. Prove all identities left to the reader for verification. 
2. Given V x H = 0 and V · H = 0, show that V2H = 0. 
3. Derive an expansion for V • (/G) where f = f(X') is a scalar field and G is a 
vector field. 
4. Derive an expansion for V x (/G). 
5. Show that in a two-dimensional Euclidean space V · r = 2. 
6. If Cl>U satisfies La place's equation (V9Cl>U = 0) and V x (V x Cl>U) = 0 
show that the gradient of (VCI>) · U + Cl> V • U is zero. 
7. Show that V(a · r) =a where a is a constant vector. 
8. Show that V x (a x r) = 2a, a constant. 
9. Prove that with respect to the rectangular Cartesian group of transformations, 
(a) V x (V x U) is a vector, 
(b) U x (V x W) is a vector, 
(c) V(U · W) is a vector. 
4. Bases in General Coordinate Systems 
In this section the groundwork is laid for the task of expressing pre­
viously introduced ideas in terms of coordinate systems that are not 
Cartesian. 
Probably the most familiar examples of non-Cartesian co­
ordinates are the cylindrical and spherical coordinate systems. These are 
introduced by way of example. 

Bases in general coordinate systems 
221 
Two immediate values of developing the vector concepts in terms of 
non-Cartesian systems come to mind. First of all, geometric models of 
many physical problems lend themselves quite naturally to non-Cartesian 
interpretation. For example, the gravitational field of a particle is such 
that spheres with the particle at their common center are equipotential 
surfaces. 
Therefore a spherical coordinate system affords" a simple de­
scription of this phenomenon. 
Second, the general coordinate systems form a natural framework for the 
introduction of concepts fundamental to the development of tensor algebra 
and analysis. 
In order to have specific coordinate systems at hand for purposes of 
illustration, the cylindrical and spherical systems are introduced in the 
following examples. 
The equations of transformation relating each of 
them to rectangular Cartesian coodinates are also presented. 
Example 3-4.1. 
The transformation equations relating cylindrical co­
ordinates to rectangular Cartesian coordinates are 
x1 = p cos e, 
(3-4.l) 
X2 = p sine, 
X3= z. 
The cylindrical coordinate system consists of a polar coordinate system in 
a plane along with a height. The transformation relations can be deter­
mined from Fig. 3-4.1. 
The coordinate surfaces p = constant, () = constant, and z = constant 
are circular cylinders, planes, and planes, respectively. 
x3 
xi 
Fig. 3-4.1 

222 
PARTIAL DIFFERENTIATION AND ASSOCIATED CONCEPTS 
xs 
xi 
Fig. 3-4.2 
Example 3-4.2. 
The transformation equations relating spherical co­
ordinates and rectangular Cartesian coordinates are 
X1 = r sin () cos </>, 
(3-4.2) 
X2 = r sin() sin"'· 
X3 = r cos 0. 
These relations can be read directly from Fig. 3-4.2. 
In this example the coordinate surfaces r = constant, () = constant, 
and </> = constant are, respectively, spheres, cones, and planes. 
The general coordinate transformations discussed in this section are 
symbolized by the form 
(3-4.3) 
j= 1,2,3. 
It is assumed that 
(a) 
each of the functions g; has continuous partial derivatives of 
at least the first order; 
(3-4.4) 
(b) 
the determinant loX;/oXkl  0 for every coordinate triple 
of the domain determined by the function x;. 
It is the province of an advanced calculus course to show that these 
properties ensure that each function has an inverse with continuous first 

Bases in general coordinate systems 
223 
partial derivatives in a neighborhood of a given point. We shall not enter 
into the matter here, but certain consequences of the stated assumptions 
will be derived at the appropriate time. 
As has been the case throughout the book, it is assumed that the space 
is Euclidean. 
Therefore a rectangular Cartesian coordinate system is 
always available. As usual the symbols X1 are reserved for representa­
tion of a rectangular Cartesian system. 
Example 3-4.3. 
The transformation functions relating cylindrical co­
ordinates and rectangular Cartesian coordinates satisfy the conditions in 
(3-4.4a,b), except at p = 0. The determinant loX1/oXkl, in which X1 = p, 
X2 = 0, and X3 = z, is exhibited here. 
ox1 ox2 oX3 
-
-
-
op 
op 
op 
cos 0 
sin 0 
0 
ox1 ox2 oX3 
-p sin 0 p cos 0 
0 
-
-
- = 
= P· 
oo 
oo 
oo 
xi 
x2 
xa 
0 
0 
1 
-
-
-
oz 
oz 
oz 
The determinant loX1/oXkl is called the Jacobian of transformation of 
the X1 coordinate system with respect to the Xi system. It is named after 
C. G. J. Jacobi (1804-1851, German), an honor bestowed on him by 
Sylvester in recognition of his outstanding contributions to mathematics in 
general and the determinant theory in particular. It is notationally con­
venient to suppress the indices and write joX/oXI. 
Definition 3-4.1. 
Allowable coordinate transformations are those of the 
form 
..¥1 = X1(Xk) 
that satisfy assumptions (3-4.4a,b). 
Important properties of the allowable coordinate transformations are 
indicated by the following three theorems. 
Theorem 3-4.la. 
The Jacobians loX/oXI and loX/oXI of an allowable 
coordinate transformation and its inverse, respectively, satisfy the relation 
<3•4·5) 
I I I ;1=1. 
PROOF. 
Since the transformation 

224 
PARTIAL DIFFERENTIATION AND ASSOCIATED CONCEPTS 
has an inverse (at least in a neighborhood of a given point), 
(3-4.6b) 
xk = xk(Xi). 
We can write 
(3-4.6) 
(c) dX1 = 0!._1 dxk 
axk 
' 
(d) dXk= 0dX1• 
oX' 
Because the relations (3-4.6c,d) are linear in the differentials, it is easily 
shown that the sets of partial derivatives satisfy the property. 
(See 
Problem 3.) 
(3-4.6e) 
The definition of determinant multiplication applied to (3-4.6) implies 
the result (3-4.5), as was to be shown. 
Theorem 3-4.tb. 
If allowable transformations 
are defined on a common region and the composition transformation is 
indicated by 
the Jacobians satisfy the relation 
(3-4·7a) 
I:: I 
= I:; II:: I· 
PROOF. 
As a consequence of the properties of partial derivatives, we 
have 
ax1 
ax1 axk 
axj) 
= 
a xk ax1' 
(3-4.7b) 
The desired result is achieved by employing the definition of determinant 
multiplication. 
Theorem 3-4.tc. 
The set of allowable coordinate transformations forms 
a group. 
PROOF. 
The properties of Definition 1"5*.I must be demonstrated. 
Observe the following: 
(a) A composite of continuous functions is continuous; therefore 
x1 = X1[Xk(X")1 = X1(Xi>) 
is continuous. 
Furthermore, from (3-4.7b)we observe that the partial 

Bases in general coordinate systems 
225 
derivatives oX1/oXP are continuous (products and sums of continuous 
functions are continuous), and therefore closure is established. 
(b) If 
R : X-+ X, 
then 
s:x-x, 
= 
= 
T:x-x, 
R(ST) = (RS)T; 
that is, the associative law holds. 
(c) The identity transformation g; = X1 belongs to the set. 
(d) The assumptions (3-4.4a,b) imply the exise of an inverse to each 
transformation of the set. This completes the-proof. 
For the reader who has investigated the ideas introductory to tensor 
analysis discussed in the starred sections the remainder of this section will 
involve a certain amount of repetition. However, the generality of the 
underlying transformation group makes it a little more than just review. 
If the text has been used primarily as an introduction to vector analysis, 
it would be worthwhile to refer to Chapter 1, Section 5*, for comparison 
and analogy. 
As in Section 5*, three bases are to be associated with each coordinate 
system. The primary purpose of introducing this complication is to obtain 
a framework that will make possible a careful discussion of gradient, 
divergence, and curl in terms of general coordinate systems. 
The rectangular Cartesian coordinate systems are allowable systems 
and therefore are at our disposal. The procedure .. going out from" 
these systems, that is, the process of using such a system as a fundamental 
frame of reference and then transforming away, is of much value. 
Consider the position vector r expressed in terms of rectangular Cartesian 
coordinates and the basis Li. L2, La associated with the axes of the system. 
(3-4.8a) 
r = X;L1• 
Let X1 = Xi(t) and g; = X1(t), respectively, be parametric equations of a 
curve C in the rectangular Cartesian coordinates X1 and the general 
coordinates X;. Then 
(3-4.8b) 
The curve C is auxiliary; in fact, (3-4.8b) could just as well be stated in the 
differential form 
Or 
dr = ax
1
dX1• 

226 
PARTIAL DIFFERENTIATION AND ASSOCIATED CONCEPTS 
xs 
xi 
Fig. 3-4.3 
The set of partial derivatives 0r/0X1, 0r/0X2, 0r/0X8 is the key to the 
introduction of a basis for generalized coordinate systems. (See Fig. 3-4.3). 
Such a set can be associated with each general coordinate system X1, ;, 
etc. The significance of the collection {or/CJXi} is illustrated by the follow­
ing theorem. 
Theorem 3-4.2a. 
The elements of the collection {iJr/CJXi} are related by 
the rule of transformation 
(3-4.9a) 
If the initial system is rectangular Cartesian, then 
axk or 
l·=--=-. 
' 
ax1 axk 
(3-4.9b) 
PROOF. 
The equation in (3-4.9a) simply illustrates the usual rule of 
partial differentiation; (3-4.9b) follows from the fact that in terms of a 
basis LI> l2, l3, r = X1L1 + X2L2 + X3L3, and therefore 0rf 0X1 = ll> etc. 
The significance of the theorem lies in the fact that the sets or/oX1 and 
0r/0X; are algebraically related in a manner analogous to that holding 
for rectangular Cartesian bases. 
Theorem 3-4.2b. 
The set of n-tuples or/oXi is a linearly independent 
set. 

Bases in general coordinate systems 227 
PROOF. 
Assume that the set is dependent. Then one of the arrows is 
dependent on the other two; that is, 
(3-4.lOa) 
# 
- $ + P% 
ax11 
- ex o:Xi• 
axia' 
where ex and f3 are not simultaneously equal to zero and j1, j2, js take on 
distinct values from the set 1, 2, 3. From (3-4.lOa) we are able to get a 
contradiction to the fact that the Jacobian of transformation is different 
from zero. If (3-4.lOa) is cross multiplied with 0r/0X;• and dot is multi­
plied with or/oX1•, we obtain 
(3-4.lOb) ±I (J&k I= - .  x 0'. = ex(O) +fJ(O) = 0. 
ax1 
ox'• ax12 ax11 
Since the assumption of linear dependence ads to a contradiction, the 
theorem is valid. 
. 
In the sequel the partial derivatives or(ax'l, 0r/0X2, and 0r/oxa are 
replaced by f1, f2, and fa, respectively. The same notational convention 
is followed with respect to X1, x;, etc., coordinate systems. 
f1, f2, and f3 are Cartesian vectors. The preceding theorems imply that 
such sets will serve as bases in generalized coordinate systems, thereby 
giving us the opportunity to extend the vector concept to them. Because 
of their geometric interpretation, it is convenient to refer to f1, f2, and fa 
as arrows. 
Definition 3-4.2. 
The arrows i\, f2, and fa are said to be covariant basis 
arrows associated with an X; coordinate system. 
Corresponding state-
ments hold for sets rj, f i• etc. 
The basis arrows are of a much more complicated nature than any we 
have dealt with in that they are functions of position. However, at a given 
point they have the direction of the corresponding coordinate curves just 
as the covariant basis arrows associated with the general Cartesian systems 
had. This statement is easily verified by holding two of the variables, say 
X2 and X3, fixed in the expression 
r = r(X1, x2, X3). 
The resulting representation is that of a coordinate curve along which 
X1 varies; 0r/0X1 corresponds to the ordinary derivative along this curve 
and therefore is a tangential vector. The extension of the vector concept 
to general coordinate systems is brought about in a manner similar to the 
extension to general Cartesian systems. (See Chapter I, Section 5*.) 
It should be realized that the Cartesian systems are included in the set of 

228 
PARTIAL DIFFERENTIATION AND ASSOCIATED CONCEPTS 
general coordinate systems even though our attention is primarily focused 
elsewhere. 
We assume that triples of functions 01, 02, 03; 01, 02, 03, etc., are 
defined in the respective coordinate systems. 
Definition 3-4.3. 
A collection {U1, U2, U3} of ordered triples, the 
elements of which satisfy the transformation law 
(3-4.11) 
a;= o!_; fjk 
iJXk 
, 
is said to be a contravariant vector. The triples 0\ 02, 03, etc., are called 
contravariant components of the vector in the respective coordinate 
systems. 
The prototype for this definition is the tangential vector field to a curve 
C, that is, dr/dt. If we supposed that the field were defined in terms of a 
rectangular Cartesian system X;, which is related to a general system by 
means of transformation equations X; = Xi(Xk), then 
dX; 
oX; dXk 
(3-4.12a) 
- = - -
dt 
iJXk dt . 
First of all it should be noted that this relation is the component form of 
(3-4.8b). Second, if we write 
dX; 
oX1 dXk 
(3-4.12b) 
-:it 
=
ox"" di, 
where X1 = Xi(.Xk), then dX1/dt can be eliminated from {3-4.12a) and 
(3-4.12b), thereby producing the relation 
dX; 
ox1 dXk 
Tt 
= 
iJxkTt 
(3-4.12c) 
On the one hand, this expression is independent of a rectangular Cartesian 
system and therefore quite general. On the other, it is precisely of the 
form (3-4.11). 
Another property implicit in Definition 3-4.11 is the algebraic invariance 
of the form U1r,. 
(See Problem 13.) In a Cartesian system this form 
represents a Cartesian vector and is geometrically represented by an arrow 
(more precisely a family of arrows). Therefore it is consistent to write 
(3-4.13) 
and to think in the same geometric terms relevant to the discussion of 
Cartesian systems. Clearly, the components of a contravariant vector are 
naturally expressed in terms of the covariant basis of Definition 3-4.2. 

Bases in general coordinate systems 
229 
Two other types of components are useful in this development of vector 
concepts. 
The first is associated with the basis introduced in the next 
theorem. 
Theorem 3-4.3. 
The set of arrows i';, which satisfy the relation 
(3-4.14a) 
determines a contravariant arrow basis associated with the g; system. 
PROOF. 
We must show that arrows satisfying (3-4.14a) exist and that 
they determine a linearly independent set. Since (3-4.14a) can be construed 
as a set of nine nonhomogeneous equations in nine unknowns (the 
components of i'1, i'2, i'3 expressed in terms of a basis L;) with the deter­
minant of coefficients different from zero, it follows that the F exist. 
In order to prove that the set i'1, i'2, f3 is linearly independent, assume 
the contrary. Then 
(3-4.14b) 
where j1, j2, and ja are distinct. By dot multiplying (3-4.3a) with i';1, we 
obtain the result 
(3-4.14c) 
1 = i';1 • F1 = oc(O) + /3(0) = 0 (no sum onji). 
This is an obvious inconsistency; therefore the set i'; is linearly independent. 
From the geometric standpoint, we see that 
(3-4.14d) 
i'1 is perpendicular to i' 2 and i' 3, 
i'2 is perpendicular to i'3 and i'1, 
i'3 is perpendicular to i'1 and i'2• 
For this reason the basis i'; is said to be reciprocal to i'1 and conversely. 
In case the arrows i'; consist of a mutually orthogonal set of unit elements 
with a right-hand rotation, the ordered sets i'; and i'; coincide. As men­
tioned in Chapter 1, Section 5*, when the basis i'; is the set L1, L2, L3 associ­
ated with a rectangular Cartesian coordinate system, then, according to 
(3-4.14d), the reciprocal basis introduces nothing new. This is precisely 
why the considerations presently being made played no part during the 
portion of the development of the sections that deal with the orthogonal 
Cartesian group of transformations. The immediate purpose in introduc­
ing a second basis is to obtain a measure of freedom in algebraic manipula­
tion which would not otherwise be possible. 
This algebraic flexibility 
depends on the relations indicated in subsequent definitions and theorems. 
The connecting links are matrices (gi;) and (gi;). These arrays not only 
relate the bases i'; and i'; but also determine the fundamental metric 
properties of the space. 

230 
PARTIAL DIFFERENTIATION AND ASSOCIATED CONCEPTS 
Definition 3-4.4a. 
Suppose that X; were the coordinates of a rectangular 
Cartesian system and X; = Xi(.Xk) an allowable transformation. 
The 
elements of (g;k) are given by 
or 
or 
3 oxi oXi 
(3-4.lSa) 
g,k =ox;. oxk = 
il ox' oxk. 
Definition 3-4.4b. 
The matrix (gik) is inverse to (g1k), that is, 
(3-4.15b) 
g;kgi1> = Jk1>• 
Example 3-4.4. 
Rectangular Cartesian and spherical coordinates are 
related by the transformation equations X1 = r sin () cos cp, X2 = r sin () 
sin cp, X3 = r cos 0. (See Example 3-4.2.) By direct computation based 
on (3-4.15a,b), we can show that 
(3-4.16) 
(g;k) = ( 2 
0 
0 
(1 
0 
(gik) = 
0  
0 
0 ,.J.J 
The next theorem indicates a linear relation between the bas.es 'i1 and ri. 
Theorem 3-4.4. 
We have 
(3-4.17) 
(a) 
r1 = g;kr. 
(b) 
r' = g'krk. 
PROOF. 
According to (3-4.14a), 
r,·r = '1/. 
Multiplying and summing the members of this relation with gz>k produces 
the relation 
f;. g'Dkik = g'Dk !J/ = g'Di = i'D. 'i;. 
This expression can be written in the form 
r;. (g'Dkr - r'D) = o. 
Since the elements r1 are linearly independent, it is not possible that all 
three of them are perpendicular to a given nonzero vector. Therefore the 
expression in parentheses must be a zero vector. This completes the proof 
of (a). 
The proof of (b) follows from (a) by making use of (3-4.15b). The 
details are left to the reader. 
To every triple of contravariant components Uk there corresponds a 
second set of elements 
(3-4.18a) 

Bases in general coordinate systems 
231 
By use of the elements gPi we are able to solve (3-4.18a) for the contra­
variant components (Jk. In particular, employment of (3-4.lSb) produces 
the result 
(3-4.18b) 
[IP = gPi O;. 
The notational convention introduced by (3-4.18a) endows the set of 
elements g1k with an algebraic property usually referred to as "lowering 
of an index." The remark that an index is lowered by g;k is simply an 
abbreviation for the statement: for purposes of convenience the com­
ponents (Jk have been replaced by another set 01 obtained through the 
linear relation (3-4.18a). The process involved in (3-4.18b) is denoted by 
the terminology "raising of an index." 
The elements 01 are naturally associated with the contravariant basis 
i', for we have 
0 = O'i; 
= gik(JkgfpfP = ;pk[J
kp = OPP. 
This fact motivates the fol definition. 
Definition 3-4.5. 
A collection {U1, U2, U3}, one element (01, 02, 03) 
from each allowable coordinate system such that 
axk = 
(3-4.19a) 
a,= ax' uk, 
is said to be a covariant vector. The elements O,, etc., are called the 
covariant components of the vector in the respective coordinate systems. 
The rule of transformation (3-4.19a) must be consistent with (3-4.18a) 
if the previously stated expressions are to fit together. This consistency is 
verified by carrying out the transformation. We have 
o 
= 
_. [Jk = 0r 
, l!'._ (p = 
or a xf) . a< a X" a xk iJr 
' 
g 'k 
a x; a Xk 
a.xf) a X; a X" a Xk a xr 
axf)-
= 
= 
axf)-
= 
axf) = 
= oX' gf)fl <J/Ur = oX' gf)rur = oX; U'J. 
The reader should note that in a Euclidean space a Cartesian vector can 
be represented in general coordinate systems by components of either a 
contravariant or a covariant vector. Therefore it is consistent to speak of a 
vector with contravariant and covariant components. 
We use this 
convenient language often. 
The prototype of a covariant vector is the gradient o<l>/oX;. 
This 
statement is initiated by the transformation rule 
(3-4.19b) 
a<I> 
axk a<P 
ax1 = ax1 axk' 
which is of the same form as (3-4.19a). 

232 
PARTIAL DIFFERENATITION AND ASSOCIATED CONCEPTS 
The preceding development made use of the matrix elements (g1k) and 
(gik) to relate covariant and contravariant sets. Let us investigate these 
matrices in more detail. The next theorem introduces an explicit form for 
the elements g1k. 
Theorem 3-4.5. 
We have 
(3-4.20a) 
3 '.3 -1 '.3 -k 
gik = i
i 
•  =    . 
i=l axi axi 
PROOF. 
By dot multiplying the relation (3-4.17b) with i\ we obtain 
This completes the first part of the proof. It remains to be shown that the 
rectangular Cartesian components of i1 are oX1/oXi. 
To obtain this 
result, start with 
Since the components of i1 are (JXi/<JX1, the equations can be written in 
the form 
oX;-k 
'f'k 
-r 
- a 
(jg'i i 
-
i' 
where i/, i;2, i;3, respectively, are the components of fl, i2, r. By multi­
plying and summing with oX1/oXP, we obtain 
or 
(3-4.20b) 
 i -k - 0 X1 
j' k 
U f. 
-
U· 
P • 
(}XP ' 
The last member of(3-4.20a) is obtained by substituting the result (3-4.20b) 
in the middle member. 
The next theorem introduces the transformation laws for the elements 
of (gil.) and (g1k). It also illustrates a point emphasized throughout the 
book, that scalar and vector character depend on the allowable group of 
transformations. 
In particular, the dot product, which is a scalar with 
respect to the group of orthogonal Cartesian transformations, is used to 
introduce a nonscalar entity in relation to the more general group of 
transformations now at our disposal. 
Theorem 3-4.6. 
Let X1 = Xi(.fk) be an allowable coordinate trans­
formation in the sense of Definition 3-4.1. 
Let matrices (g1J, (g1k); 

Bases in general coordinate systems 
233 
(g1k), (i1k) be associated with the respective systems. The matrix elements 
then satisfy the transformation rules 
(3-4.21) 
PROOF. 
We have 
_ 
or 
0r 
oXj)oxa or 
or 
oX1loxa 
= 
gik = o'X1• o'Xk = oX1 o'Xk oXj). oxa 
= oX1 o'Xk g
1la' 
This completes the proof of (a). The proof of (b) follows in the same way 
from (3-4.20a). 
Definition 3-4.6a. 
Let the set of matrices (g1k), (g1k), etc., associated with 
the respective systems X1tc., be denoted by {g;k}· Then {g,1k} is said 
to be the fundamental metric tensor associated with the allowable trans­
formation group. The tensor is of covariant order 2 and the elements g1k 
are called covariant components. 
Definition 3-4.6b. 
The set of matrices {g1k} is said to be the associated 
metric tensor with respect to the allowable transformation group. It is, 
according to its law of transformation (3-4.21b), a contravariant tensor of 
order 2. The elements gik are called contravariant components of order 2. 
The components of the metric tensor take on a special form in rectan­
gular Cartesian systems. In particular, 
(3-4.21c) 
g,1k = lJ.1k· 
Furthermore, the transformation law (3-4.21a) reduces to 
(3-4.21d) 
lJ1,. = a/a.,.q i5N = i51,.. 
Therefore the components can be interpreted as scalars. This rationale 
establishes consistency in calling r1 • r,. a set of scalars with respect to 
rectangular Cartesian transformations and tensor components when 
referred to a more general transformation group. 
Before considering the third of the bases mentioned earlier in the section, 
we digress by illustrating the previously introduced concepts in the follow­
ing example. 
Example 3-4.S. 
Let X1 be the system of cylindrical coordinates 
described in Example 3-4.1. Recall that 
x1 = p, 
x2 = fJ, 
X3 = z. 

234 
PARTIAL DIFERENTIATION AND ASSOCIATED CONCEPTS 
The set of basis arrows ar/ap, ar;ao, ar;az is represented in terms of L1, 
L2, La as follows: 
(3-4.22a) 
i'1 = cos 0L1 + sin 0L2, 
i'2 = 
-p sin 0L1 + p cos 0L2, 
i's = L3. 
It can easily be shown that the elements of the set are mutually orthogonal. 
Furthermore, i'1 and i'3 are unit arrows. However, i'2 has a variable magni­
tude p and therefore has a magnitude of only 1 at those points on the unit 
sphere, p = I. 
Computing from (3-4.15a), we have 
(34.22b) 
(g,.) = ( · ) 
The contravariant components gik are obtained easily from (3-4.l5b). 
The ease of computation is a consequence of the orthogonality of (g1k) 
(i.e., the fact that the off-diagonal elements are zero). 
Since i'1 = fkfk, we have 
(3-4.22c) 
i'1 = cos () L1 + sin () L2, 
i'2 = 
- ! sin () L1 + ! cos () L1, 
f3 = L3. 
p 
p 
The fact that i'1, f2, i'3 correspond to i'1, i'2, i'3, except with respect to the 
magnitudes of f2 and f2, agrees with the orthogonality of the bases. Note 
that the magnitudes of f2 and i'2 are reciprocal, as might be expected. 
The preceding example brings to mind the observation that 
(3-4.23a) 
is equivalent to 
(3-4.23b) 
fj. i',t = 0. 
0 
0 
In other words, the basis elements are mutually perpendicular or orthog­
onal if and only if (3-4.23a) holds. 
The bases i'1 and f1 contribute algebraic flexibility. In particular, they 
introduce an aesthetic quality to that part of the theory involving trans­
formations. The third type of basis to be introduced in this section lends 
itself to geometric and physical interpretation. 

Bases in general coordinate systems 
235 
Definition 3-4. 7. 
Let 
(3-4.24a) 
where 
(3-4.24b) 
Theorem 3-4.7a. 
The set e1, e2, e8, associated with a coordinate system 
X1, is a unit arrow basis. 
PROOF. 
The arrows e1 are proportional to the f1• 
Since each e1 is 
formed by dividing i1 by its magnitude, they are unit arrows. 
Theorem 3-4.7b. 
A vector 0 expressed in terms of the basis e1 has the 
forms 
(3-4.25a) 
(3-4.25b) 
W = (W1gJe1 + (W2gJe2 + (W8ta)es. 
W = (g1k3kt1)e1 + (g2kwkg:Je2 + (g3kWkta)ea. 
PROOF. 
As a consequence of (3-4.24a,b), 
w = W1r1 = W1g1e1 + W2g2e2 + W8g3e3. 
Since W1 = gik W1c, the foregoing t!Xpression can also be written as in 
(3-4.25b). 
Definition 3-4.8. 
The components w1 = W1g1, w2 = W2g2, w8 = W3g8 
associated with a basis el, e2. ea are called physical components of the 
vector W. 
The physical components of a vector represent displacements in the 
directions of the unit arrows e1• 
Furthermore, they are dimensionally 
correct. 
These properties make them useful in many geometrical and 
physical considerations. However, their usage is primarily restricted to a 
single coordinate system, for transformation laws involving physical 
components can become cumbersome. 
In some texts the physical components of Definition 3-4.8 are said to be 
of the first kind. 
Corresponding components of the second kind are 
introduced as coefficients of a basis 
r1 
f2 
r3 
if1i' lr2I ' ir31 . 
If the basis i1 is orthogonal, then so is the basis i1• Under this circum­
stance, the covariant and contravariant components of a vector W satisfy 
the relation 
(3-4.26) 
(no sum on x). 

236 
PARTIAL DIFFERENTIATION AND ASSOCIATED CONCEPTS 
The following theorem concerning the physical components is a con­
sequence of this relation. 
Theorem 3-4.8. 
Let e1 be an orthogonal unit basis. 
The physical 
components of a vector  can be expressed in terms of the covariant 
components: 
(3-4.27) 
1 -
wa = - Wa. 
ga 
PROOF. 
When (3-4.26) is applied to (3-4.25b), the result follows. 
In Section 5 the physical component representations of gradient, diverg­
ence, and curl are among the results obtained. 
Problems 
1. The transformation equations relating spherical and rectangular Cartesian 
coordinates are given by (3-4.2). With respect to them, complete the 
following: 
(a) Compute the matrix (oXi/oXk). 
(b) Evaluate the Jacobian of transformation I oXJ aA''I. 
(c) In light of the conditions in (3-4.4), which coordinate triples (r, 0, </>) 
must be excluded 
(d) Compute the matrix 0Xk/ax1. 
. 
axk 
cofactor (oXi/oXk) ln 1ax/aX1 
Hmt: ax1 
= 
1ax1ax1 
(e) Check the property I oX/ oXI ioX/ oXI 
= 1 by direct computation. 
(f) Express f;, fi, and e1 in terms of 'i· 
(g) Express f; in terms of fk and conversely. 
2. Repeat Problem 1 with respect to the transformation equations 
X1 = p cosh 0 cos </>, 
X2 = p cosh 0 sin </>, 
X3 = p sinh 0. 
Also compute K;k and gik. 
3. Show that relations (3-4.6c,d) imply (3-4.6e). 
Hint: Multiply and sum (3-4.6c) with a set A1P satisfying the property 
Al(oX1/oXk) = ;kp· Use (3-4.6d) to show that Al = oXP/oX1• 
4. Generally speaking, little computation is done with the allowable trans­
formations Xi = X'(Xk). Instead, the vector and tensor concepts are 
built around linear transformations of the form 01 = aX1/oXk, Uk 
arising from the general group. Show that these linear transformations 
form a group. 
5. Show that the orthogonal Cartesian group is a subgroup of the allowable 
group of Definition 3-4.1. 
6. Prove (3-4.17b) (i.e., ri = gikrk). 

Vector concepts in curvilinear orthogonal coordinate systems 237 
7. Prove (3-4.18b) (i.e., Ok 
= gki01). 
8. Prove (3-4.2lb) (i.e., gik 
= (iJXi/iJXP)(iJXk/iJXa)gpq). 
9. (a) Suppose that f1, f2, f3 were an orthogonal basis. Show that the recipro­
cal basis is given by 
(b) If the basis ei. 6. e3 is a unit orthogonal basis, what is the value of 
el. e2 x ea? 
(c) Identify the quantity f1 • f2 x f3• 
10. Determine the transformation rule for the elements of the set {6/} where 
6/ = gjpg'Pk. 
11. Show that both Kik and gik are symmetric in j, k. 
12. If the basis fi is orthogonal, show that g"" = l/g.,.,. 
13. (a) Show that the form Oifi is an algebraic invariant. 
(b) Show that the form 01fi is an algebraic invariant. 
5. Vector Concepts in -€urvilinear Orthogonal 
Coordinate Systems 
Most geometrical and physical problems involve orthogonal coordinate 
systems. To employ other systems would lead us into involved computa­
tions, even on the theoretic level. For this reason the present section is 
devoted to expressing the concepts of gradient, divergence, and curl in 
terms of the orthogonal systems. The algebraic foundation established 
in Section 4 enables us to do the job in a relatively simple way. It also 
makes possible an approach that later can be extended easily to nonor­
thogonal systems. 
If Li. L2, La is a unit orthogonal basis associated with a rectangular 
Cartesian coordinate system Xi, then 
Or 
Or 
(3-5.la) 
gjk = 
axj. ()Xk 
= Lj. Lk 
= bjk• 
Since the reciprocal basis coincides with L1, L2, L3, it is also the case that 
(3-5.lb) 
gik = bik. 
This fact is important in the next theorem. 
The transformation rules 
(3-4.2lb) and (3-4.9b) also play a part. 
Theorem 3-5.1. 
The physical components of the vector operator V 
(in a curvilinear orthogonal coordinate system) are 
G1 a;1' :2 a;2 ':3 a;a) · 

238 
PARTIAL DIFFERENTIATION AND ASSOCIATED CONCEPTS 
Therefore 
(3-5.2) 
v 
1_
a 
1_
a 
1_
a 
= gl 
e1a.x1 + g2 
e2a_x2 + g3 
es
a.xs
· 
PROOF. 
Starting with the rectangular Cartesian representation for V, 
we can simply transform to a curvilinear system; that is, 
	 
a 

 
a 

 
a 
v = ;1 l1 ax1 = b' l; axk = g' l; axk 
(ax1 axk ) (axs or ) (axt a ) 
= ax])axqg'J)q 
ax1ax• 
axkax1 
= J s J t -JHl  __!_ = 
-st  __!__ . 
1J 
qg ax• 0..¥1 
g ax• ax1' 
(g81) is diagonal, therefore, according to (3-4.24a) and the fact that 
g"'"' = 1/gxx, 
Iv= -st or 
 =  .!_ e _i_ 
<3-s.3) 
g ax·ax1 ; 
g1 
1 ax1 · 
This completes the proof. 
The reader should note that the second member of (3-5.3) has all the 
characteristics necessary for a definition of V valid in any of the allowable 
coordinate systems. (See Chapter 3, Section 4, for a definition of an allow­
able coordinate system.) 
Example 3-5.1. 
With respect to the cylindrical coordinate system of 
Examples 3-4.1 and 3-4.S, the covariant components of the fundamental 
metric tensor are 
(3-S.4a) 
Therefore 
and 
(3-S.4b) 
where 
0 0) 
p2 0 . 
0 1 
ga = 1, 
a 
1 
a 
a 
V= p-+-8-+k-
op 
P 
ao 
az 
The derivations of curvilinear coordinate representations for divergence 
and curl require knowledge of certain relationships between the Jacobian 
of transformation and the determinant of the covariant components of 

Vector concepts in curvilinear orthogonal coordinate systems 
239 
the fundamental metric tensor. These facts as well as an extension of the 
E-system concept are now discussed. 
E systems were introduced in Chapter 1, Section 6. The components 
of the respective systems transform according to covariant and contra­
variant laws with appropriate density factors. The major characteristic 
of these systems is that their components have values 1, -1, 0 in every 
allowable coordinate system. 
The next definition extends these systems 
to the generalized coordinates presently under discussion. 
Definition 3-5.1. 
Let { 1 
{an even permutation, 
(3-5.5) 
E1ka = £ika = 
-1 
if jkq is 
an odd permutation of 1, 2, 3, 
0 
otherwise. 
Furthermore, let the components {t::t in any other general coordinate 
system be related to the components {	;'ia by means of the transformation 
rule 
_,---· 
--. 
(3-5.6) 
-
/ axl ax'Pax• axt= 
(a) eika= ox ox1oxkoxae'P•t• 
(b) 
£ikq = I 
I ;;::t£'J•t. 
The set {&1ka} is then said to be a tensor density of covariant order 3 and 
weight + 1; {Eika} is said to be a tensor density of contravariant order 3 
and weight --. 1. 
The Jacobians loX/oXl+i, loX/oXl-1 represent the density factors. A 
comparison with the introduction of t: systems in Chapter 1, Section 6, 
reveals that Definition 3-5.1 preserves the numerical values under trans­
formation of coordinates; that is, 
(3-5.7) 
A proof of this fact based on Definition 3-5.1 is left to the reader. (See 
Problem 9.) 
Now consider the relationship of the Jacobian and the determinant of 
the covariant components of the fundamental metric tensor. 
Theorem 3-5.2. 
Let X' represent a rectangular Cartesian coordinate 
system and X1 represent an allowable general coordinate system. Then 
(3-5.8) 

240 
PARTIAL DIFFERENTIATION AND ASSOCIATED CONCEPTS 
PROOF. 
We have 
(3-5.9a) 
The right-hand side of (3-5.9a) can be thought of as two successive deter­
minant multiplications10; that is, the multiplication bpq(oXP/oX1) followed 
by a multiplication of the resultant determinant with loXq/oXkl. Hence 
(3-5.9b) 
This completes the proof. 
The next theorem represents a slight digression. Its usefulness is demon­
strated in the sequel. 
Theorem 3-5.3. 
Let Id/I be a determinant whose elements are in­
dependent functions defined in some region of space. Suppose that at 
least the first partial derivatives were continuous on the domain of definition. 
Then 
(3-5.lOa) 
where 
(3-5.lOb) 
D/ =cofactor of d11q in ldl. 
PROOF. 
We have 
(3-5.l l a) 
By partial differentiation of (3-5.l la) 
e 
0 ldl - e (b p bid 1 d k + di b p b 1 d k + did 1b11 bk) 
(3-5.11 b) 
rst od q - iik r 
q 
8 
t 
r 
8 
q 
t 
r 
8 
t 
q 
p 
According to Definition 1-6.5, a cofactor has the representation 
(3-5.l l c) 
Therefore by substituting into the last member of (3-5.l Ib) we have 
(3-5.lld) 
Erst 
d! = <5/E.,,1 Dq" - b,PE.,,1 Dq" + b/'E.,r• Dq"· 
p 
10 In order to bring about row-by-column multiplication as indicated in the definition 
of determinant multiplication, it is sometimes necessary to consider the transpose of the 
matrix of determinant elements. This does not effect the numerical value of the product. 

Vector concepts in curvilinear orthogonal coordinate systems 
241 
If we rewrite the right-hand member of (3-5.1 ld) with Dq" as a factor and 
multiply and sum with £••t, then 
(3-5.ll e) 
3 ! 0 ldl = (2£5/ c5,,' +. 2£5/ £5,,• + 2c5t b,,t) Dq'" = 6D/'. 
. 
od?/ 
The proof is completed by dividing each side of (3-5.l le) by six. 
The result (3-5.IOa) is immediately employed in the next theorem. Also 
note that 
Therefore 
(3-5.12) 
iJXk 
cofactor of iJXi/iJXk in loX/oXI 
oX1 = 
loX/oXI 
Theorem 3-5.4. 
Let Xi and Xi represent rectangular Cartesian and 
general coordinates, respectively. Then 
(3-5.13) 
a xk a 2x' 
1 a-.)g 
axi a xk a x2> = -.J"i a x2> · 
PROOF. 
According to m5.7) 
----<:.. I 
0 x I 
-Jg= ax 
· 
By straightforward partial differentiation 
(3-5.14a) 
a-Jg 
a 1ax;ax1 
a 1ax;ax1 
a2x2> 
axk = 
iJXk 
= o(iJX2>/(}Xq) oXkiJXq 
According to (3-5.IOa,b) and (3-5.12), 
a 1ax;ax1 I 
ax I 
axq 
<3-5·14b) 
o(oX2>/iJXq) = ax ax2> 
· 
Again using (3-5.7), we obtain 
a 1ax;ax1 
-= axq 
(3-5·l4c) 
o(iJX2>/oXq) =-Jg iJX2>. 
The proof is completed by substituting (3-5.14c) into (3-5.14a). 
With the appropriate algebraic tools at hand, it becomes a simple 
matter to obtain curvilinear coordinate expressions for divergence and 
curl. 
Theorem 3-5.5. 
Let W be a differentiable vector field. Then 
(3-5.15) 
where the WP are contravariant components of the vector. 

242 
PARTIAL DIFFERENTIATION AND ASSOCIATED CONCEPTS 
PROOF. 
The method of derivation consists of starting with the rect­
angular Cartesian expression for the divergence of W and then performing 
the transformation to a general system of curvilinear coordinates. We 
have 
(3-5.16a) 
axk a2x1 
-2> 
ax; aw:I> 
=ox; oXkoX2> w 
+ 
oX:J>oxk 
By employing (3-5.13) we can put this relation in the form 
(3-5.16b) 
v."' = 	(0J_"i) w:I> + 0
2> 
,Jg ox:J> 
ox:I> 
Careful examination shows that (3-5.16b) is a differentiated form of 
(3-5.15). This completes the proof. 
If, in an orthogonal curvilinear system, the physical components of 
W are represented by w;, then, according to Definition 3-4.8, 
-· 
1 -
W' =-W;. 
g; 
Therefore, in terms of physical components, 
(3-5.17a) 
In orthogonal systems 
Vi= g1g2g3. 
Therefore an equivalent representation for (3-5. l 7a) is 
(3-5.17b) 
Example 3-5.2. 
Again considering the cylindrical coordinate system of 
the preceding example, in terms of physical components 
(3-5.18) 
V. "1 
= l(opw1 + ow2 + opw3) 
p op 
oO 
oz 
= ow1 + l ow2 + Ow3 + ! w1. 
op 
p oO 
oz 
p 
It is of some interest to note that the form oWi/oX; is not preserved 
under general transformations [see (3-5.16a)]; hence it is not of scalar 

Vector concepts in curvilinear orthogonal cordinate systems 
243 
character. The question is asked whether the concept of divergence can 
be expressed in a way that gives it scalar character. It is answered under 
the heading of covariant differentiation. (See Chapter 4.) 
Example 3-5.3 
A special case of the divergence V • W is presented 
when W is a gradient vector; that is 
(3-5.19a) 
W = V<I>. 
In this example the physical components of W are 
(3-5.19b) 
_ 
1 a<i> 
wi = gi ax'. 
[See (3-5.2).] 
Under this circumstance [substitute into (3-5.16b)] 
(3-5.19c) 
[a(e,ea a-1) 
a(e.ea a/2) 
a(e1e2 a0a)] 
v . v <I> = _
1 _ 
g1 ax 
g2 ax 
. 
g3 ax 
e1t2ea 
ax1 
+ 
ax2 
+ 
oX3 
This is the general orthogonal coordinate form of the Laplacian V2'1> 
mentioned in Chapter 3, Section 2. It is named for the French mathe­
matician Pierre-Simon, Marquis de Laplace (1749-1827). The spherical 
and cylindrical forms of Laplace's partial differential equation 
V2'1> = 0 
are often met in problems involving electric and magnetic phenomena 
and in other aspects of mathematical physics. 
The algebraic groundwork preceding the introduction of the curvilinear 
representation for divergence also suffices for the development of the curl 
concept. 
Theorem 3-5.6. 
Let W be a differentiable vector field. Then, in an 
orthogonal system, 
e1e1 e2·e2 eses 
1 
a 
a 
a 
(3-5.20) 
VxW= /i ax1 ax2 oX3 
' 
e1w1 e2w2 gawa 
where (wi. w2, w3) are the physical components of W. 
PROOF. 
V x W can be represented in the rectangular Cartesian form 
t1£ik'P dkW"' where the W,, are covariant components of Wand 

244 
PARTIAL DIFFERENTIATION AND ASSOCIATED CONCEPTS 
Then 
(3-5.21a) 
L E'lt1J 0 w = (ox" o7 )£ik1' ox"  (ox1 w) 
' 
k 1J 
ox' ox" 
oxk ox1 ox1' 
" 
=ox" 8£ik1' ox1( 02x" ox" 
w +ox• d w) 
ox1 ox" 
oxk ox" ox1' ox' 
" 
ox1' 1 " 
=  (£ik1' ox" c5 " o 2 x" w + £ik1' ox" o x1 ox .. 0 w )
' 
ox" 
ox' k ox" ox1' 
.. 
ox' oxk ox1' 1 .. 
= 8(£ik1Jox" 02x" w + E"t"I oxl d w:) . 
ox" 
ox1 oxk ox1' 
" 
ox 
1 " 
Because £ik1J is skew symmetric in the indices k and p, whereas o2X"/ 
oXk oX1' is symmetric ink and p, the product and summation 
£ik1' o2 X" = o. 
oXkoX1' 
Therefore (3-5.2Ia) reduces to (recall loX/oXI = loX/oXl-1 = I /../i. 
(3-5.21b) 
Since 
L £ik1'o w 
=  o7 E"t"o w:. 
1 
1t 1J 
.jg 0 X" 
t 
" 
Wv=g,,w", 
it follows that(3-5.21 b) is equivalent to (3-5.20). 
Example 3-5.4. 
Again considering the cylindrical coordinate system of 
the preceding examples, we have 
(3-5.22) 
-
H 
1 
Vx 
=-
p 
p 
p6 
k 
o 
o 
o 
op 
oO 
oz 
W1 
pw2 
Wa 
= l [ 
p ( OW3 -0 pwI\ + p6 (OW1 -OW3) + k (0 PW2 - OW1) J . 
P 
oo 
oz J 
oz 
o P 
o P 
oo 
Problems· 
1. Show that with respect to the spherical system of Example 3-4.2 V has the 
form 

Maxima and minima of functions of two variables 245 
2. Compute V<I> with respect to the cylindrical coordinate system of Example 
3-4.1 if 
(a) <I> 
= p, 
(b) <1> 
= e, 
(c) <I> 
= pO, 
(d) <I> 
= p sin e. 
3. (a) Compute g for the cylindrical system of Example 3-4.1. 
(b) Compute g for the spherical system of Example 3-4.2. 
4. Determine the form of V · W for the spherical coordinate system of Example 
3-4.2. 
5. For the cylindrical system of Example 3-4.1 compute V · W in each of the 
following: 
(a) W 
= p, 
(b) w =a, 
(c) w 
= sin Op + cos ea. 
6. Show that for orthogonal curvilinear coordinate systems 
-
-
- -a / ax; / 
vx1.vx2 x vx 
= 
-
oXk 
. 
7. What is the form of V · V<I> in the spherical coordinate system of 
Example 3-4.2? 
8. What is the form of V x W in the spherical coordinate system of Example 
3-4.2 
9. Show that Definition llLimplies (3-5.7). 
10. Show that the natural representation of V<I> is in terms of covariant compo­
nents by showing that 
6. Maxima and Minima of Functions of Two Variables 
The cylindrical coordinate system representation of V offers an oppor­
tunity to handle certain maxima and minima problems in an appealing 
way. Since the method utilizes the results concerning maxima and minima 
of functions of one variable, it is worthwhile to review the fundamental 
facts of this theory. 
Suppose that/were a differentiable function on a domain a::; X1::; b. 
Let c be an interior point of the closed interval [a, b ]. Furthermore, assume 
that the second derivative of f exists at c. If f'(c) = 0, then c is called a 
critical value off The nature off at a critical value is explored by examina­
tion of the second derivative. In particular, 
(a)11 iff"(c) > O,fhas a relative minimum at X1 = c, 
11 f has a relative maximum at c is equivalent to the statement: there exists CJ > 0 
such that f(X1) ? f(c) whenever I X1 - cl < CJ. A similar definition holds for relative 
minimum. 

246 
PARTIAL DIFFERENTIATION AND ASSOCIATED CONCEPTS 
(b) 
ifj"(c) < O,fhas a relative maximum at X1 = c, 
(c) 
if /"(c) = 0, no conclusion can be drawn. 
Whenf"(c) = O, /may have a relative maximum, a relative minimum, 
or (c,f(c)) may be coordinates of a point of inflection. 
Example 3-6.la. If X2 = f(X1) = (X1)2 on the 
x2 
domain -1 - X1 - l, then 
J'(X1) = 2X1 
and 0 is a critical value of /; j"(O) = 2 > 0, there­
fore f has a relative minimum at X1 = 0. 
(See 
---"+'°--X1 
Fig. 3-6.1.) 
(a) 
x2 
Example 3-6.lb. 
If X2 = /(X1) = (Xl)3 on the 
domain -1 - X1. - l, then 0 is again a critical 
value off However, in this example f"(O) = 0 
and no conclusion can be reached whether f has a 
maximum or minimum at X1 = 0. Further exam­
ination would show that (0, /(0)) are coordinates 
of a point of inflection. [See Fig. 3-6.1 b.) 
Example 3-6.lc. If X2 = /(X1) = (X1)4 on the 
domain - 1  , X1 ::; l, again it is the case that 0 
--r-<'--X1 
is a critical value off withf"(O) = 0. Detailed 
(b) 
x2 
examination in this instance reveals that f has a 
relative minimum at X1 = 0. 
Having recalled the major results concerning 
relative maxima and minima of functions of one 
variable, let us consider functions of two variables. 
In the remarks that follow it is assumed that/has 
continuous first partial derivatives on a given plane 
region and that (Xa1, X02) are coordinates of an 
interior point of this region. Furthermore, it is 
---"'"+-£--X1 
assumed that the second partial derivatives off 
le) 
Fig. 3-6.1 
exist at (X01, X02). 
Defimtion3-6.1. Let/= /(X1, X2);/has a rela­
tive maximum at (X01, X02) means that there exist b1 
> 0 and <52 > 0 such that /(X1, X2) ::; f(Xa1, X02) 
whenever IX1 - X01I < <51 and IX2 - Xo2l < <52. 
The definition of relative minimum off is acquired by simply reversing 
the inequality relating/(X1, X2) and/(X01, X02). 
Theorem 3-6.1. If/has a relative maximum at (X01, X02), then of/0X1 = 
0, of/o X2 = 0 at (X01, X02). 

Maxima and minima of functions of two variables 
24 7 
PROOF. 
By definition, 
(3-6.la) of(Xo1. Xo2) = Jim /(X01 + *X1, X02) - f(X01, X02) 
ax1 
Ax1 ... o 
*x1 
According to the definition of relative maximum, 
(3-6.l b) 
Therefore the sign of the difference quotient involved in (3-6.l a) depends 
on *X1• This means that the sign changes at (Xl, X02). Since of!oX1 is 
continuous, this can happen only if of!oX1 = 0 at (X01, X02). The proof 
that of!oX2 = 0 at the given coordinate pair follows the same pattern. 
It is important to realize that the converse to Theorem 3-6.1 does not 
hold. This fact is illustrated by subsequent examples. 
Definition 3-6.2. 
If at (X01, X02) 
+=0 
ax1 
' 
of =O 
ax2 
' 
then (X01, X02) is called a critical coordinate pair off, and the point with 
these coordinates is called a critical point off 
Example 3-6.2. 
The theory of maxima and minima of functions of two 
variables is a great deal more complicated than the corresponding theory 
of one variable. For instance, consider 
/() = 1 + (X1)2 
_ (X2)2 
at (0, 0). We can write 
(3-6R2a) 
and interpret (3-6.2a) as a surface. (See Fig. 3-6.2.) We have 
of(Xo1,0) 
= (2X1) = 0 
ax1 
o 
, 
(3-6.2b) 
Furthermore, 
(3-6.2c) 
o2/(X1, 0) 
= 2 
(0X1)2 
' 
02/(0, X2) 
= - 2 . 
o(X2)2 
From the geometric point of view, putting X1 = 0 corresponds to restrict­
ing the considerations to the coordinate plane X1 = 0. Hence we think of 
studying the curve of intersection of X1 = O and X3 = 1 + (X1)2 - (X2)2 

248 
PARTIAL DIFFERENTIATION AND ASSOCIATED CONCEPTS 
xa 
Fig. 3-6.2 
in the plane X1 = 0. From the first parts of the relations in (3-6.2b,c) it 
is seen that this curve has a relative minimum at (0, 0, l). On the other 
hand, the second parts of the relations in (3-6.2b,c) imply that the curve 
X2 = 0, X3 = 1 + (X1)2 - (X2)2 has a relative maximum at (0, 0, I). 
Therefore the function/has neither a relative minimum nor a relative max­
imum at (0, 0). The critical point presented in this example is often called a 
saddle point. 
The last example clearly indicates that af/aX1 = aJ!aX2 = 0 is a neces­
sary condition that f have a relative maxima or relative minima, but it is 
not a sufficient condition. We now utilize cylindrical coordinates to find 
sufficient conditions. 
The value of the cylindrical coordinate system in investigating maxima 
and minima resides in the fact that () = constant represents a plane. (See 
Fig. 3-6.3.) If the critical point lies on the z axis, then for each value of() 
we can investigate the curve z 
= z(p), which is the trace of the surface on 
the plane () = constant. These investigations can be carried out in terms of 
the criteria for a function of one variable. 
If the critical point to be investigated does not lie on the z axis, a new 
coordinate system, obtained from the original by means of a translation, 
can be introduced. 
It is important that the theoretical considerations made in the cylindrical 
coordinate system be set up in vector form, for the vector representation 
simplifies the transformation of the derived information into rectangular 
Cartesian coordinates. The equations of transformation take the form 
X1 = X01 + p cos 0, 
(3-6.3) 
X2 = X02 + p sin 0, 
X3 = z, 

xi 
Maxima and minima of functions of two variables 
249 
xa 
Fig. 3-6.3 
where (X01, X0"') is a critical coordinate pair of a function f. Note that the 
inclusion of the terms X01 and X02 simply provides for a translation such 
that the z axis passes through the point with coordinates (X01, X02) (i.e., 
p = 0, and any 0). 
Theorem 3-6.2. Let f have continuous first partial derivatives on a 
given plane region and be such that the second partial derivatives exist at 
an interior point (X01, X02) of the region. Suppose that/(p, 0) = f[X1(p, 0), 
X"(p, O)]. Then 
(3-6.4) 
(a) 
p ·VI= of
, 
op 
a2r 
(b) 
p • f'J(p • V/) = 
-· 
. 
<Jp2 
PROOF. 
By expressing the gradient in cylindrical coordinates, we have 
(3-6 .Sa) 

250 
PARTIAL DIFFERENTIATION AND ASSOCIATED CONCEPTS 
Taking the dot product of (3-6.Sa) with p produces the result 
(3-6.Sb) 
, 
al 
p ·V; = 
- . 
op 
This proves (3-6.4a). 
By applying the operator V to (3-6.Sb), we have 
02.I 
1 
02/ 
02.I 
(3-6.Sc) 
V( p • V/) = p 
- + 
- e -· 
+ k -
. 
op2 
p oO op 
az op 
Therefore 
02/ 
(3-6.Sd) 
p 
• V(p • V/) = -
. 
ap2 
This completes the proof. 
Quite clearly the criteria for maxima and minima of a function of one 
variable can be employed in the cylindrical case (with the additional under­
standing that it must hold for all 0). Therefore the next task is to determine 
the meaning of this information in terms of rectangular Cartesian repre­
sentations. 
Theorem 3-6.Ja. 
At a domain value (X01, X02) off, o//op = 0 for all 0 
imples that ofloX1 = 0 and ofloX2 = 0. 
PROOF. 
We have 
Therefore 
(3-6.6) 
or 
or oXk 
. 
P = -= - -= cos OL + sm OL 
ax1 
axk ax1 
1 
2' 
of 
of 
of 
V'j-L-+L-+L-
- 1 oXl 
2 ax2 
3 axs . 
0 =of= p 
• v/ = p 
• Vf =cos 0 of +sin of . 
op 
ax1 
ax2 
Suppose that of/oX1 and of/oX2 were not individually zero at (X01, X02). 
Then (3-6.6) determines a discrete set of values for 0. But this is contrary 
to the assumption that (3-6.6) holds for all 0. The contradiction implies the 
validity of the theorem. 
Theorem 3-6.3b. 
At a domain value (X01, X02) off at which the second 
partial derivatives are continuous, 
(3-6.7) 
02/ 
a2f 
02/ 
a2f 
-2 
= cos2 0 --1-2 
+ 2 cos 0 sin 0 a 1 0 2 
+ sin2 0 ( 2 2 
• 
op 
(oX ) 
X 
X 
uX ) 

Maxima and minima of functions of two variables 
251 
PROOF. 
According to (3-6.4b), 
09/ -
· 
(3-6.8) - = p·V(p·V1)= p•V(p·Vf) 
op2 
=(cos lh + sin (JL). [L o(p. VJ)
+ L o( p. VJ)+ L o(p. VJ)]. 
i 
2 
i 
oX1 
2 
oX2 
a 
axs 
Now p ·VJ= cos() (of10X1) + sin fJ (of/oX2) where() is to be thought of 
as a fixed value (i.e., () = constant represents the plane in which the in­
vestigation of maxima and minima takes place). 
Therefore the result 
(3-6.7) is obtained from (3-6.8) by straightforward calculation. 
The theorems (3-6.3a,b) along with the theory of relative maxima and 
minima of one variable lead to the following conclusions: 
If of/fJX1 = 0, fJf/fJX2 = 0 at (X01, X02) the second partial derivatives of 
fare continuous, and (3-6.7), 
(< 0 (/has a relative maximum at (X01, X02), 
> 0 then 
/has a· relative minimum at (X01, X02), 
= 0 
no conclusion can be reached. 
These results can be put in still better form. Let 
aE 
aE 
aE 
A=--
B= 
C=-- . 
(aX1)2 ' 
ax1 ax2 ' 
(ax2)2 
Theorem 3-6.4. 
Suppose that f has continuous first derivatives on a 
plane region. Let (X01, X02) represent coordinates of an interior point 
of this region. Furthermore, suppose the second partials are continuous at 
{X01, X02). If (X01, X02) is a critical coordinate pair (see Definition 3-6.2), 
then 
(3-6.9) 
(a) 
B2 - AC < 0, 
(b) B2 - A 0, 
A < 0--+ /has a relative maximum 
at (X01, X02), 
A > 0 --+ f has a relative minimum 
at (Xo1, Xo2), 
(c) 
B2 - AC> 0--+ /has neither a maximum nor a mini­
mum at (X01, X02), 
(d) 
B2 - AC= 0--+ no conclusion can be drawn. 
PROOF [of (a)]. 
The right-hand member of(3-6.7) can be written in the 
form (whenever cos () :;6- 0) 
(3-6.10) 
P(O) = cos2 ()[A + 2B tan()+ C tan2 OJ, 
where we think of P(O) as a polynomial in 0. Suppose that (3-6.9a) holds 
and that cos() :;6- 0 (cos() = 0 is considered separately). B2 - AC < 0 
guarantees that P(O) will have no zeros, hence is positive for all () or 
negative for all (), Since P(O) = A < 0 and P(O) does not change sign, 
we have P(O) < 0 for all () (excluding () such that cos() = 0). Finally, if 
cos() = 0, it follows from the right-hand member of (3-6.7) that 
P(O) = C. 

252 
PARTIAL DIFFERENTIATION AND ASSOCIATED CONCEPTS 
But C must have the same sign as A. Otherwise B2 - 4AC < 0 could not 
hold. Since P(O) < 0 implies o2/fop2 < 0, it follows that/ has a relative 
maximum at (X01, X02). 
The proof of (3-6.9b) follows the same pattern. In (3-6.9c) the relation 
B2 - AC> 0 implies that P(O) has zeros. [See (3-6.lOa).] Therefore the 
sign of o2/f op2 is dependent on (), and there is neither a minimum nor a 
maximum at (X01, X02). If the relation (3-6.9d) holds, then there are values 
of() for which o2f!op2 = 0. The theory of one variable indicates that in 
this instance no conclusion can be drawn. 
Example 3-6.3. 
Suppose that an ellipsoidal surface were given according 
to the representation of Monge. 
(3-6.lla) <l>(X1 xz X3) = (X1)2 + (X2)2 + (Xa)2 
- 1 = 0. 
' 
' 
4 
9 
16 
Two of the possible functions that can be constructed from <I> have rules: 
(3-6.llb) 
(3.6-llc) 
_ 3 { [(X1)2 
(X1)2] }' 
fl=X =4 1-
- +-
4 
9 
' 
_ 
3 
{ [(X1)2 (X2)2] }' 
/2 = x = -4 1 -
-- + 
-
. 
4 
9 
Let each of these functions have domain [(X1)2/4] + [(X1)2/9] :5: 1. Then, 
examining/1, we have 
o/1 = -x1 {i - [<x1ya + (X2)2]}-' 
(3-6.lld) 
ox1 
4 
9 
o/1 = 
- & x2 {1 - [(X1)2 + (X2)2] }-l-1. 
(3-6.lle) 
oX2 
9 
4 
9 
The critical coordinate pair is (0, 0). This is an interior point of the set; 
therefore we proceed to investigate its nature. 
o2f1 = -{1 - [(X1)2 + (X2)(}-' 
(3-6.llf ) (0X1)2 
4 
9 -J 
- (X1)2 { 1 - [<x22 + ()2)2] r. 
(3-6.llg) 
(3-6.llh) 

Maxima and minima of functions of two variables 
253 
By evaluating at (0, 0), we have 
(3-6.lli) 
Therefore 
A - ( o2f1 ) 
= -1, 
(oX2) co.o> 
B- ( (J2f1 ) 
-0 
- ax2 ax1 co.o> 
-
' 
c- () 
= -t 
- (oX2)2 co,o> 
B2 - AC = -t < 0, 
A= 
- 1 < 0. 
The function /1 has a relative maximum at (0, 0). 
Similarly, it can be 
shown that h has a relative minimum at (0, 0). 
Problems 
1. Find the relative maximum and/or relative minimum for the function with 
domain (X1)2 + (X2)2  1 and rule 
f(Xl, X2) = (Xl)2 + (X2)2 _ x1. 
2. Find the critical coordinate pairs for each of the following functions and test 
for maxima and minima: 
-oo < x1 < oo 
(a) /(X1, X2) = 4 - (X1)2 + (X2)2, -oo < x2 < oo'. 
-oo<X1<oo 
(b) /(X1, x2) = 9 - (X1)2 - (X2)2, -oo > x2 < oo'. 

chapter 4 integration of vectors 
This chapter is concerned with the integration of scalar and vector fields 
over curves, surfaces, and space regions. It is assumed that the reader is 
familiar with the fundamental ideas of integration of continuous functions. 
To attempt to go into detail concerning the foundations of the integration 
concept would involve a long digression into the field of analysis. Therefore 
the discussion is restricted for the most part to extending the ideas of 
integration over line and plane region to integration over curve and surface 
element. Some attention is given to volume integrals. Naturally, the use 
of vector language is emphasized. 
Whether the integration involves a curve, a surface, or a space region, 
it is defined in terms of a summation process. 
When vector fields are 
concerned, the use of a summation process presents a difficulty that is 
worthy of comment. Arithmetic addition of vectors depends on a com­
position of corresponding components. Since the discussion is restricted 
to euclidean space, an orthogonal basis of constant elements Li. L2, L3 always 
exists and therefore this addition can be carried out even though the 
vectors involved are not associated with the same point of space. (Note 
that the existence of the constant basis depends on the space being 
euclidean.) However, if a given integrand is expressed in terms of a non­
constant basis, we cannot remove the basis elements inside the integration 
sign. 
Such variable elements present computational difficulties. 
The 
immediately important aspects of these remarks may be summarized. 
The various integrals to be discussed have meaning in Euclidean three­
space regardless of the nature of the basis used. 
However, more often 
than not, actual evaluation of an integral will depend on a constant basis 
L1, L2, l3. 
254 

Line integrals 
255 
1. Line Integrals 
In an elementary calculus course we consider the integral f: 
f(x) dx 
wherefis a continuous function defined on the closed interval [a, b] of the 
line y = 0. (See Fig. 4-1.1.) The concept of line integral extends this idea 
by replacing f by a scalar function <I> or 
vector function U defined on a space curve 
y 
X1 = X1(t), t0 * t * tn. 
The term line 
integral is a little misleading, since geo­
metric emphasis is placed on a curve over 
which the integration takes place. "Curve 
integral" 
might 
be 
more 
appropriate. 
However, to avoid confusion, we shall stick 
to the standard terminology. 
Suppose that functions X1 = X1(t), with 
continuous derivatives that are not simul­
taneously zero on the domain t0 * t * tn, 
f(xJ 
 
a 
Fig. 4-1.1 
determine a space curve C. Then the concept of line integral can be ex­
pressed as follows. 
Definition 4-1.1. 
Let <l>(X1) be a continuous scalar field defined on C; 
then 
(4-1.la) 
is s.aid to be a scalar line integral on C. 
Definition 4'-1.lb. 
Let G(X1) be a continuous vector field on C; then 
(4-1.lb) 
f11G[X1(t)] dt = Jim i G[X1(7;)] !:iti 
Jto 
l.!.tl ... Oi=l 
is saido be a vector line integral on C. 
The sYrtmolism used in (4-1.la,b) is the usual. In particular, 
and ltl.tl--+ 0 means that all subdivisions of the refinements (t0, • 
• 
• , t11) 
of the partition approaches zero as n--+ oo. 
The symbols -r; represent 
intermediate values in the intervals tl.ti. (See Fig. 4-1.2.) 
It may often be convenient to write i rather than f1". 
C 
J
1
0 
For purposes of analysis we can think of the parameter t as representing 
the domain values of <I> and of G. The continuity of <I> and of G implies 

256 
INTEGRATION OF VECTORS 
to 
xj (to) 
Fig. 4-1.2 
the existence of the integrals. (This is an assumption on our part. The 
proof that continuity of a function on a closed interval is sufficient for the 
existence of the integral is usually given in an elementary calculus course.) 
The evaluation of the vector line integral is usually simplest when the 
basis elements are constant. For a basis L1, L2, L3 we have 
r G dt = lim i G( T;) +ti = lim i G1( T;)L; +ti. 
Jc 
111.tl-+o i=l 
IMI i=l 
Because Lh L2, L3 are constant and therefore do not depend on the limit 
process, 
r G dt = L1 Jim i G1(-r;) +ti + L2 Jim i G2(-r;) +ti 
Jc 
IA1i-+o i=l 
IMl-+o i=l 
n 
+ L3 Jim L G3( -r;) +t 
IMl-+O i=l 
= L1 (tnG1 dt + L2 ff"G2 dt + La ff"G3 dt. 
Ji. 
Ji. 
J,. 
Therefore the evaluation depends on a component-by-component in­
tegration. Difficulties that may exist are independent of the vector process. 
For the most part we are concerned with the scalar line integral in 
which <l> has the form 
(4-1.2) 
dr 
<l> =G·-. 
dt 
Therefore <l> is dependent on the curve. For this reason we demand that 
in general the curve be smooth. 
As defined in Chapter 2, Section l, a 
smooth curve is characterized by continuous derivatives dX1/dt, dX2/dt, 
and dX3/dt, which are not simultaneously zero. The geometric implication 
of these conditions is simply that the curve has a continuously turning 
tangent. 
Our conditions on the curve are slightly relaxed by the following 
definition. 
Definition 4-1.2a. 
A curve is said to be sectionally smooth if it is 
composed of a finite number of smooth curves attached sequentially end 
to end. 

Line integrals 
257 
Definition 4-1.lb. 
The line integral over a sectionally smooth curve is 
the sum of the line integrals over the corresponding smooth pieces. 
The preceding definitions make it possible to include such an intuitively 
simple curve as a broken line segment in our considerations. 
Geometric interpretation is often facilitated by representing a curve in 
terms of a parameter s, which denotes arc length. The tangent vector 
field dr/ds is a unit field and the line integral 
(4-1.3) 
i dr dr 
-·-ds = L, 
ods 
ds 
where Lis the length of C. More generally, the scalar G • (dr/ds) can be 
interpreted as the projection (with appropriate sign) of G onto the tan­
gential direction at each point of C. 
If arc length is not used in the 
parametric representation of the curve, then the preceding statement must 
be modified to include the magnitude of dr/dt. 
The LG• (dr/dt) dt can be evaluated in at least three different ways. 
These methods are presented in the following examples. 
Example 4-1.1. 
As previously indicated, the parametric equations 
(4-1.4a) 
x1 =cost, 
X2 =sin t, 
X3= t. 
t  0, 
represent a circular helix. The position vector r has the form 
(4-l.4b) 
and 
(4-l.4c) 
r = cos tt1 + sin tt2 + tt3 
dr 
. 
-= -sm tt1 +cos tt2 + t3• 
dt 
Suppose that a vector field 
( 4-1.) 
G 
= sin tt1 + cos tt2 + t3 
is defialong the curve; that is, r and G have a common domain such 
that if t 0  gives rise to r0 then G is associated with the curve point with 
coordinates X0; (i.e., with the end point ofr0). Then, as a consequence of 
( 4-l.4c,d), ito 
dr 
fto 
G • - dt = 
(-sin2 t + cos2 t + 1) dt, 
0 
dt 
0 
f10 
( 
Y· 
=Jo 
(1 + cos 2t) dt = t + ! sin 2t Jo
, 
+sin 2t0 
=to -- . 
2 

258 
INTEGRATION OF VECTORS 
In this example both the curve and the vector field are represented in 
terms of the parameter t and the integration was straightforward. The 
next example presents a variation from this method. 
Example 4-1.2. 
The LG 
· (dr/dt) dt also can be expressed in the form 
(4-1.5) 
foG 
• dr = fo Gi dX1 
+ fo G2 dX2 + fo Gs dXa. 
This representation depends on a change of the variable of integration 
from t to X1, X2, X3, respectively. There are certain advantages to this 
procedure. For example, if the curve is given by 
(4-l.6a) 
and 
(4-l.6b) 
then 
(4-1.6c) 
and 
(4-l.6d) 
x2 
= (X1)2, 
X3 = 0, 
o  x1 2. 
(See Fig. 4-l.3a.) Therefore 
(4-l.6e) 
i(2,4l 
i(2,4) 
G 
• dr = 
(X2 dX1 + 2(X1)3 dX1). 
(0,0) 
(0,0) 
x2 
Fig. 4-1.Ja 

Line integrals 
259 
x2 
Fig. 4-1.3b 
Again, using the curve representation, the right member of (4-1.6e) can 
be put entirely in terms of X1 and dX1; that is, 
(4-1.6f) 
G • dr = [(X1)2 + 2(X1)3] dX1 = i + 8 = :!a1• 
i(2,U 
i2 
, 
(0,0) 
0 
Note that if the vector field G of this example is integrated over 
X2= 2X1, 
(4-1.7a) 
then 
(4-1.7b) 
and 
X3=0, 
(4-1.7c) 
f<1G0dr = f<z,,1X2dX1+2(X1)2dX1=f2(2X1+2(X1)2)dX1 
Jco,_,
 
J co,o> 
Jo 
= [<x1)2 + 2(1)1: 
= 4 + !.a§.= \§.. 
(See Fig. 4-l.3b.) Thus, comparing (4-l.6f) and (4-l.7c), it is clear that the 
value of the integral depends on the path joining (O, 0) and (2, 4). 
The next example illustrates a case in which the path of integration is 
of no concern. 
Example 4-1.3. 
Let 
(4-l.Sa) 

260 
INTEGRATION OF VECTORS 
Consider any plane path given by differentiable equations which joins 
(0, 0) and (2, 8). For example, 
x2 = (Xl)a, 
(4-l.8b) 
X3=0, 
dX2 = 3(X1)2 dX1, 
or 
(4-l .8c) 
X2= 4X1, 
X3=0, 
dX2= 4dX1• 
In (4-I.8b) and (4-l.8c), respectively, we obtain 
1(2,8) 
1(2,8) 
(4-l.8d) 
G · dr = 
X2 dX1 + 3(X1)3 dX1 
(0,0) 
(0,0) 
1(2,8) 
= 
[(X1)3 + 3(X1)3] dX1 = 16. 
0,0) 
1(2,8) 
1(2,8) 
(4-l.8e) 
G • dr = 
X1 dX1 + 4X1 dX1 
(0,0) 
(0,0) 
= f 8X1 dx1 = 16. 
Choice of other paths joining (0, 0) and (2, 8) leads to this same numerical 
value of 16; therefore we are led to doubt the importance of any particular 
path in evaluating the integral. Closer examination shows that 
i G . dr =i X2 dX1 + X1 dX2 =l
(2,8
1d(X2X1) = 16; 
c 
c 
(0,0) 
that is, the integrand can be written as a perfect differential, and choice 
of path does not matter. This question is examined more fully later in the 
section. 
Example 4-1.4. 
Consider the curve C whose parameterization is 
x1 = t, 
x2 = 12, 
xs = o, 
o  t < 1 
x1 = 1, 
x2 = 1, 
XS= 1 - t, 
1  t < 2, 
X1 = 3 - t, 
X2 = 3 - t, 
X3 = 1, 
2  t::; 3. 
Let G = X1X2L1 + X2L2 + X3L3• (See Fig. 4-1.4.) This curve is sectionally 
smooth. Therefore the line integral can be written as a sum of three line 
integrals. 
f G· dr dt = f\t3 + 2t3)dt + f2- (l - t)dt + f3[-(3 - t)2 - (3 - t)] dt 
c 
dt 
Jo 
Ji 
J2 
=-i+!-i=1A2. 

Line integrals 
261 
Fig. 4-1.4 
The next example introduces an application of the concept of line 
integral to physics. 
Example 4-1.5. 
In its most elementary form the concept of work1 is 
defined as the product of a constant force by the straight line distance 
over which it acts. Thus, if Frepresents the measure of the constant force, 
!l.r, the distance, and W symbolizes the measure of work, then 
(4-l.9a) 
W = F !l.r. 
A slight generalization of (4-l.9a) consists in representing the constant 
force by means of a vector F and allowing the vector to have a direction 
different from that of the line segment over which it acts. Then 
(4-1.9b) 
W = F !l.r cos O; 
that is, the compq__nent of force in the direction of action is multiplied by 
the distance throuFhich it acts. 
These two elementary definitions of work (the second includes the first) 
were supplemented after the introduction of the integral calculus by 
(4-1.9a) 
i"'l 
W= 
F(x)dx, 
"'• 
where the force is variable along the line of action. 
1 The term work was used by G. G. Coriolis (1792-1843), and later by J. V. Poncelet 
(1789-1867, French). 
These men were among the first to promote reforms in the 
teaching of rational mechanics. 
(See Florian Cajori, A History of Physics, Dover, 
1962, p. 59.) 

262 
INTEGRATION OF VECTORS 
All these representations are included in the more general definition 
given in terms of the line integral; that is, 
(4-1.9d) 
W= L F·dr. 
There will be further occasion to refer to (4-1.9d) after a more detailed 
development of certain ideas associated with the concept of line 
integral. 
The next theorem introduces a property of the line integral that is 
useful in applications in geometry and physics. The function G of Example 
4-1.3 led to a line integral LG· dr, the value of which did not depend on 
the path C. The theorem gives a first answer to the question of what form 
G must take in general in order that the line integral may be independent 
of path. 
Independence of path means that there is a scalar function, 
which we shall call W(X1), such that 
(4-1.10) 
In other words, the value of the integral depends only on the end points 
P0 and P, where P is variable and P0 is fixed. 
Theorem 4-1.1. 
Let G be a vector field that is continuous on R, a 
preassigned region of space. Suppose that C were any smooth curve lying 
in R. Denote the end points of C by P0 and P1. Then 
(4-1 11) 
Po 
 
{the value of l PG 
• dr is in-} {there exists a differentiable} 
· 
dependent of the path C 
scalar field <I> such that 
joining P0 and P 
G = V<l>. 
PROOF. 
Assume that G can be represented as the gradient of a differ­
entiable scalar field <I>. Because <I> is differentiable, a change of variables 
from X1, X2, X3 to <I> is possible. This change takes the form of the chain 
rule of differentiation and V<l> • dr is replaced by d<l>. Thus 
(4-1.12a) 
J 
f 
1P1<X1;> 
G 
• dr = 
V<l> • dr = 
; d<l> = <l>(X/) - <l>(X0;). 
C 
C 
Po<Xo) 
It follows that LG · dr depends on the coordinates X01 and Xl of the 
end points of C but does not depend on C. 

Line integrals 
263 
Conversely, assume that the line integral is independent of path. From 
( 4-1.10) we can derive the expression 
(4-l.12b) 
W(X1 + AX1, X2, X3) - W(X1, X2, X3) 
AX1 
1 (iX+4X1,x2,xa 
ixi,x2,xa 
) 
= -
G • dr -
G • dr 
AX1 
Po 
Po 
1 f xi+4Xi,x. 2 x• 
=-
G·dr. 
AX1 x1,x2 X3 
The path determined by the limits of integration is such that X2 = constant 
and X3 = constant; therefore 
W(X1 + AX1 X2 Xa) - W(X1 X2 Xs) 
1 fxi+llxi.x•,x• 
' 
' 
. ' 
' 
= -
G1 dX1• 
AX1 
AX1 X1,X2,X8 
According to the mean value theorem of integral calculus, there exists Z1 
in (X1, X1 + AX1) such that 
In turn, G1(Z1, X2, X3) can be replaced by G1{X1, X2, X3) + E1 for a 
sufficiently small value of AX1 because G1 is a continuous function. 
Therefore 
oW 
. 
W(X1 + AX1 X2 X3) - W(X1 X2 X3) 
(4-l.12c) 
=ix1 = hm 
' 
'A 
i 
' 
' 
u 
l4X11-+o 
'-"X 
= Iim G1{ X1, x2, X3) + t:1 = G1, 
Elo 
It can be shown in a similar manner that 
Clearly, the function W is the required scalar field and G can be expressed 
as a gradient. This completes the proof. 
Example 4-1.6. 
Suppose that a vector field 
G = {X2X3 + 2)L1 + (x1xs + 5)L2 + x1x2la 
is given. If the vector field is representable as a gradient field, an ap­
propriate scalar function cl> can be found by making the identification 
G=V«l>. 

264 
INTEGRATION OF VECTORS 
Then 
o<I> = xzx3 + 2 
ax1 
' 
From the first of these relations we find on integrating that 
<I> = xix2 x3 + 2x1 + f(X2, X3). 
Therefore 
xix3 + 5 = o<I> = xix3 + of 
ax2 
ax2 
From this relation we ascertain that 
f(X2, X3) = 5X2 + g(X3); 
thus 
<I>= x1x2xa + 2x1 + sx2 +g. 
The given expression for o<l>/oX3 leads to the result 
xix2 = o<I> = xix2 + og(Xa). 
oX3 
oX3 
Consequently 
g(X3) 
= constant. 
By the foregoing process of partial integration we find that 
<I> = X1 X2 X3 + 2X1 + 5X2 + constant. 
The flaw in the method of this example is that it depends on G being a 
gradient field. If G is not a gradient vector field, the method will fail, but 
doubt may linger in our minds whether the failure was actually owing to 
the nonexistence of a function <I> or to personal inadequacy. Fortunately, 
a more powerful test will become available later in the book. 
In the next theorem the symbol f is used to indicate integration over 
a closed path; that is, the initial and end points of the path coincide. 
Theorem 4-1.2. 
Let G be continuous on a region R. Suppose P 0 and P1 
are points in R and both C1 and C2 are smooth paths in R joining these 
points. Then 
(4-1.13) { 
f P1 } 
The line integral J J G 
• dr 
. . 
Po 
 G 
• dr = 0. 
IS mdependent of the path 
f 
joining P0 to P1• 
PROOF. 
To prove the equivalence of (4-1.13), start with the implication 
from left to right. 
According to the preceding theorem, LG 
· dr in­
dependent of path implies that there is a differentiable function <I> such 

Line integrals 
265 
that G = V<l>. Therefore 
J. G • dr = ( G • dr +f G • dr = (P1G • dr + (PoG. dr 
Jc 
Jc1 
C2 
JPo 
JP1 
= rP1d<f> + rPod<f> 
JPo 
JP1 
iP1 
iP1 
= 
d<l> -
d<l> = 0. 
Po 
Po 
Conversely, if f G • dr = 0, then 
J. G • dr = ( G • dr + ( G • dr = 0. 
J 
Jc1 
Jc2 
Consequently, 
(4-1.14a) 
( G. dr = -J G • dr. 
Jc1 
c, 
The relation (4-1.14a) can also be written in the form 
(4-l.14b) 
( G • dr =J G • dr, 
Jc1 
-c. 
where -C2 is oppositely oriented to C2• Therefore the integration over 
path C1 or -C2 (from P0 to P1, see Fig. 4-1.5) produces the same result. 
Since C1 and -C2 are arbitrary curves joining P 0 to P 1 (they must meet the 
restrictions of the hypothesis), this completes the proof. 
Example 4-1.7. 
Disregarding part of the 
hypothesis of a theorem can have disastrous 
results. The function 
<1> = tan-1 (:) 
provides an opportunity for such neglect. 
This function can be expressed in the form 
G = V<l> 
= 
- X2L1 + xi 2 . 
(X1)2 + ( 
)2 
Therefore we might expect the line integral 
Po 
Fig. 4-1.S 
around a closed path to have the value zero. However, consideration of 
the circle 
X1 =cos(), 
X2 =sin(), 
leads to the result 
f 
i
h' cos2 () + sin2 () J
2" 
G • dr = 
= 
dO = 27T. 
c 
0 
1 
0 

266 
INTEGRATION OF VECTORS 
A careful analysis of <I> solves the dilemma. The function <I> is not defined 
for X1 = 0, that is, anywhere along the X2 axis. Therefore the statement 
on the right-hand side of (4-1.11) is not satisfied and the conclusion 
cannot be drawn. 
Fields of force which can be represented as the gradient of a scalar field 
(i.e., by F = -V<I>, where the minus sign is introduced for future con­
venience) play an important role in mathematical physics. Such fields of 
force are called conservative and the scalar function is a potential function. 
Among the physical phenomena that can be so represented are gravita­
tional, electrostatic, and magnetostatic force fields. It follows at once from 
Theorem 4-1.l that the work done by a conservative field of force in 
moving an object from P0 to P1 does not depend on the path of motion. 
Classical Newtonian mechanics makes much use of the concept of 
energy. It is assumed that there are two kinds of energy, potential (a 
measure of the capacity to do work expressed by means of the potential 
function) and kinetic (defined as lmV2, where m is the mass of the particle 
and V is the magnitude of its instantaneous velocity). The next example 
illustrates that for conservative force fields the total energy (i.e., the sum 
of potential and kinetic energy) does not vary. This is one of the three 
famous conservation principles of classical mechanics. 
Example 4-1.8. 
In Newtonian mechanics the force field associated with 
a given path of motion is described in terms of the rate of change of the 
momentum field; that is, 
(4-l.15a) 
F=dmV, 
dt 
where m represents mass (which is constant according to Newtonian 
mechanics) and V represents the velocity vector field along the path of 
motion. 
When Fis conservative (i.e., F = -V<I>), 
(4-l.15b) 
f P F. dr = f P 
- V<I> • dr = - f P d<I> = <l>(P0) - <l>(P). 
JPo 
JPo 
JPo 
From the point of view of relation ( 4-l .15a), 
(4-l.15c) 
iP 
it dmV dr 
m it dV • V 
F 
· dr = 
--
• 
- dt = -
-- dt 
Po 
t0 dt 
dt 
2 t0 dt 
= m J dV2 = m [V2(P) - V2(P0)]. 
2 
2 

Line integrals 
267 
Equating the results in (4-l.l5b) and (4-l.l5c) we obtain 
(4-1.15d) 
Therefore the total energy is the same at any point P (or equivalently at 
any time t) as it was at the initial position of the particle. Hence it is said 
to be conserved. 
Example 4-1.9. 
As a consequence of the conservation of energy 
principle, illustrated in the preceding example, it is possible to predict the 
initial velocity needed by a particle in order that it may escape from the 
earth's gravitational field. 
It is assumed that as the distance from the earth's surface--+ oo, the 
total energy tends toward being all potential energy. On the other hand, 
at the surface of the earth the energy is all kinetic. 
According to Newton's universal law of gravitation, 
(4-l.16a) 
where 
(4-1.6b) 
ymMr 
F = -- = -mV<I>, 
r3 
<I>= yM
' 
r 
R = radius of earth, 
M = mass of earth, 
m = mass of body, 
y = gravitational constant. 
I 
I 
p 
-----------;1------
,.,... 
---- --
IR 
......... , 
" 
I 
' 
1 
Earth 
Fig. 4-1.6 

268 
INTEGRATION OF VECTORS 
Since work is the negative of potential energy, the fact that the total 
energy at the earth's surface (i.e., all kinetic energy) equals the total energy 
at oo (i.e., all potential energy) produces the result 
!mV2 = lim JP 
F • dr = lim - m (P 
V<I> • dr = lim - m (P 
d<I> 
Poo R 
Poo 
JR 
Poo 
JR 
= 
_ lim myMJ
P 
= 
_ lim (myM 
_ myM) 
= myM. 
Poo 
r 
R 
Poo 
p 
R 
R 
Therefore 
(4-l.16c) 
V 
/2yM 
=..;-. 
R 
Using the values 
R = (6.37)108 cm, 
M = (6.1)1027 gm, 
y = (6.67)10-8 dyne/gm2 cm2, 
we find that 
V = {l.13)106 cm/sec, 
or about 7 mi./sec. 
Problems 
1. Find the values of the following line integrals: 
(X1 =a cost, 
r dr dr 
(a) Jc dt. dt dt X2
3 
= a sin t, 
x =0. 
(X1 = a cos sja, 
r dr dr 
(b) Ja ds • ds ds X2
3 
= a sins/a, 
x =0. 
0 # t # 2. 
2. Find the value of Sa G • (dr/dt) dt in each of the following cases: 
{x1 = 12, 
(a) G 
= -X211 + x112 x2 = 21, 
o # t # 2. 
(b) G 
= (X2)211 + (X1)212, 
X1 = Vl - (X2)2, from (0, -1) to (0, 1). 
(X1 =cost, 
(c) G = -sin fl1 + cos fl2 + 13 
X2 = sin t, 
X 3 = t, 
0 # t # 1r. 
-1 # t $ 1. 

Line integrals 
269 
3. If G 
= 2X1 X2L1 + (X1)2L2, evaluate r G 
• dr over each of the following 
paths: 
Jc 
(a) X2 = v1 + (X1)2, X3 = 0, from (0, 1) to (2, v5). 
v5 -1 
-
(b) X2 = -2- x1 + 1, X3 = o, from (0, O) to (2, v5 - 1). 
(c) The line path: 
x1 = t, 
x2 = o, o > t > 2, 
X3 = 0, 
x1 =2, 
x2 = t - 2, 
X3 =0, 
2 > t > vs + 2. 
(d) Is LG· dr independent of path? Prove that your answer is valid. 
4. Suppose that for all t a vector force field F is perpendicular to the tangent 
vector dr/dt along the path of motion. Show that the work done by F is 
zero. 
5. Suppose that a force vector field F 
= r is defined on 
X1 = h + a cos 0, 
X2 = k + a sin 0, 
X3 = 0, 
0 > 0 > 1T. 
(a) Show that the work done is -2ah. 
(b) What is the work done over the interval 0 > 0 > 27T? 
(c) Let k = 0, h =a. Then calculate 
{" G 
• '!_ dO. 
Jo 
dO 
6. Show that { G 
• dr is independent of path for each of the following vector 
fields: Jc 
x2 
x1 
(a) G = (X1)2 L1 - (X1)2 L2, 
(b) G = r. 
x1 7!6 o. 
r 
(c) G = - , 
yn 
n ) 0 and an integer, r 7i6 0. 
Hint: We can show that G · dr is a perfect differential or we can produce Il 
such that G = +v Il. 
7. Prove that LG· dr is not independent of path if 
G 
= -X2L1 + x1?. 

270 
INTEGRATION OF VECTORS 
2. Surface Integrals 
The fundamental ideas of this section are based on Definition 3-l.2c of 
a surface. Analysis is restricted to surface sections, every point of which 
is regular; that is, surface sections which have a parameterization 
X; = X;(v11) 
such that at each point of the section 
(a) the X; are continuous functions, 
( 4-2.1) (b) the first partial derivatives are continuous, 
(c) the matrix (oXij()vf3) has rank 2 (i.e., or/ov1 x or/ov2  0). 
By referring to Definition 3-1.2 we observe that these conditions guarantee 
the coordinate pairs (v1, v2) to be in D. 
Definition 4-2.1. A surface section satisfying conditions ( 4-2.1) is said 
to be smooth. 
The restrictions in (4-2.1) are severe. They eliminate from consideration 
sharp points, such as the vertex of a cone, nonorientable2 surfaces, such 
as the Mobius strip,3 and degenerate representations, such as 
(4-2.2) 
X1 = v1 - v2, 
The equations in (4-2.2) obviously can be expressed in terms of a single 
parameter u = v1 - v2• Therefore they represent a space curve rather 
than a surface. 
Unfortunately, the restrictions go further than our intuition might desire. 
Most so-called surfaces met in analytic geometry and calculus conform to 
the conditions in (4-2.1), except perhaps at isolated points. In particular, 
quadratic surfaces are among those subjects to our considerations. But 
such intuitively simple configurations as cubes, parallelepipeds, and poly­
hedra in general have edges that present difficulties. The problem can be 
overcome by introducing the concept of sectionally smooth surfaces in 
analogy to sectionally smooth curves. Then, for example, an integral 
over a sectionally smooth surface can be defined as a sum of integrals 
over the sections that compose the surface. 
The major difficulty involved in defining sectional smoothness has to do 
with the process of joining. For example, we cannot allow the definition 
2 A surface is orientable if and only if there is a continuous unit normal at every point. 
3 A Mobius strip is a one-sided surface, constructed by half twisting a strip of paper 
and then sticking the ends together. 

Surface integrals 
271 
Fig. 4-2.1 
of a sectionally smooth surface to include a configuration composed of 
two sections with a single point in common. (See Fig. 4-2. l.) 
Definition 4-2.2. 
A surface is said to be sectionally smooth if and only 
if the smooth sections that compose the surface satisfy the following 
conditions: 
(a) Any two sections have no points, 011e point, or an edge in 
common. 
(4_2.3) 
(b) If two sections have exactly one point P in common, then 
there exists a chain of sections with P in common and such 
that each consecutive pair has a common edge. 
(c) No three sections have more than one point in common. 
The preceding definitions and remarks enable us to continue with some 
hope of intelligibility. The reader who is interested in pursuing a detailed 
treatment of the theory of surfaces may begin with Advanced Calculus by 
John Olmsted (Appleton-Century-Crofts, 1961), in which a very nice 
presentation, as well as further references, is given. 
The parameters v;, in terms of which the surface equations are expressed, 
are subject to .two geometric interpretations. 
On the one hand, the set 
(v1, v2) can be designated as coordinates of the points of a plane region. 
From this viewpoint X; = X;(v,) can be thought of as equations of trans­
formation relating the plane coordinates to the space coordinates. 
We 
say that the points of the plane region are mapped onto the surface region 
by means of the transformation. This concept of "mapping" has proved 
fruitful in modern mathematics. The idea is illustrated by the following 
example. 
Example 4-2.1. 
As we saw }rt Chapter 3, Section 1, the parametric 
equations 
/ 
X1 = v1, 
(4-2.4) 

272 
INTEGRATION OF VECTORS 
xi 
Fig. 4-2.2 
are associated with the upper hemisphere of a sphere. From the standpoint 
of mappings, we think of the plane point with coordinates (v1, v2) = 
(X1, X2) as being mapped into the space point (X1, X2, X3). (In this case 
the inverse mapping would be an orthogonal projection of the hemisphere 
onto the plane region (X1)2 + (X2)2 < I.) In Fig. 4-2.2 point P is thought 
of as being mapped into point Q. In particular, P(!, !) is sent into 
(1 1 1 ) 
Q2'2'2· 
On the other hand, the families of parametric curves, v1 = constant, 
v2 = constant, introduce a coordinate net on the surface; that is, each 
surface point is the intersection of a unique pair of curves, one from each 
family. The parameters (v1, v2) can be interpreted as surface coordinates 
of a point. This approach, due to Gauss, leads to the development of 
the intrinsic geometry of surfaces, that is, the study of the geometry of 
surfaces dissociated from an embedded three-space.4 
Example 4-2.2. 
The planes, X1 = constant, X2 = constant, intersect 
the hemisphere 
x1 = vl, 
x2 = v2, 
'Bernhard Riemann followed up Gauss's work on curved surfaces by setting the 
foundations for the development of n-dimensional geometry which included Euclidean 
geometry as a special case. This gave impetus to the introduction by Beltrami and 
others of surface models of non-Euclidean geometries. Furthermore, the studies of 
Riemann have played an important part in modern physical theory and philosophy. 

Surface integrals 
273 
in two sets of curves. By denoting these sets by v1 = constant and v2 = 
constant (see Fig. 4-2.2), we obtain a coordinate net on the surface that is 
analogous to the coordinate net determined in the plane by a rectangular 
Cartesian coordinate system. From the viewpoint of Gauss, we forget the 
correspondence which we have just used to obtain the coordinate net on 
the surface. The intrinsic geometry of the surface is developed by simply 
assuming the existence of some such net (and all those that can be intro­
duced by surface coordinate transformations) and then proceeding with 
an analytical development of the surface geometry. 
In the development of the integral concepts we feel free to use the 
geometrical viewpoint concerning surfaces that best fits the immediate 
need. 
Integrals with either a scalar or a vector integrand are considered. The 
symbol N is used to denote a unit surface normal (i.e., N is, in general, a 
unit vector field defined over the surface region), and dA is symbolic of 
the element of surface area. Before stating a definition of surface integral, 
it is convenient to obtain representations for both N and dA. The following 
theorems lead to this end. 
As in previous considerations of surfaces, 
Greek letters have the range I, 2. 
Theorem 4-2.1. 
The square of the differential element of arc on a 
surface has the form 
(4-2.Sa) 
ds2 =gap dv" dvP = g11(dv1)2 + 2g12 dv1 dv2 + g22(dv2)2, 
where 
or 
or 
(4-2.Sb) 
g.,p = 
ov"
. 
o
vP. 
PROOF. 
We have 
ds2 = dr • dr = .£!. dv" • .£!. dvfJ = g 
dv" dv/J 
ov" 
ov/J 
«/J 
' 
as was to be shown. 
Definition 4-2.3. 
The form (4-2.Sa) is called the fundamental metric 
form of the surface. 
The determination of an expression for the differential element of surface 
area is, of course, the basic step in defining that measurement, associated 
with the surface, which is called at:a. The problems involved in giving a 
meaning, consistent with intuition to the concept of surface area are very 
deep. In fact, it is of some inter st to realize that a completely general 
definition of surface area is of concern to modern research mathematics. 
The obvious approach in defining the surface area as the limiting value of 

274 
INTEGRATION OF VECTORS 
Fig. 4-2.3 
areas of inscribed polyhedra (this approach would be in direct analogy to 
that of determining curve length as a limiting value of lengths of inscribed 
polygons) leads to inconsistent results. 
A simple example, called the 
Schwarz example, which demonstrates this fact, can be found on page 616 
of Advanced Calculus by John Olmsted. We restrict ourselves here to the 
presentation of an intuitional background and a definition valid for 
smooth surface sections. We should expect the forthcoming definition of 
surface area to meet two fundamental requirements. First of all, the 
formula should reduce to the usual thing ifthe surface is a plane. Second, 
the representation of surface area should be invariant with respect to 
surface coordinate transformation. 
The fundamental metric form is an aid in the determination of an 
appropriate representation for dA. Let ds1 and ds2, respectively, denote 
differential elements of arc corresponding to v2 = constant and v1 = 
constant. Then, according to the form (4-2.5a), 
(4-2.6a) 
where 
(4-2.6b) 
The property of magnitude cannot be associated with the differentials. 
However, if dv1, dv2 are momentarily replaced by L\v1 and L\v2, then the 
area of a parameter parallelogram is approximated by 
(4-2.6c) 
L\A = g1g2 L\v1 L\v2 sin fJ, 
0 < () < Tr, 
where () represents the angle determined by the positive senses of parameter 
curves (i.e., the angle determined by or/ov1 and 0r/ov2). The representation 
in (4-2.6c) motivates the following definition. (See Fig. 4-2.3.) 
Definition 4-2.4. 
The differential element of surface area is 
(4-2.7) 
The next two theorems introduce a surface unit normal N. 

Surface integrals 
275 
Theorem 4-2.2. 
The partial derivatives or/ov1 and or/ov2 are tangent 
vector fields along the parameter curves v2 
= constant and v1 = constant, 
respectively. 
PROOF. 
Suppose that the parameter curve v2 = constant is represented 
in terms of its arc length s. Then (dr/ds)1 is a unit tangent vector field 
along the curve. The subscript of 1 simply indicates the particular curve. 
Since v2 
= constant, we have 
(4-2.8) 
Therefore 0r/ov1 is proportional to the unit tangent field (dr/ds)1• 
By 
letting v1 = constant, we can show that or/ov2 is proportional to (dr/ds)2. 
Theorem 4-2.3. 
A unit normal vector field associated with a smooth 
surface section is 
(4-2.9) 
N = or/ov1 x or/ov2 
• 
lor/ov1 x or/ov21 
PROOF. 
The fact that (oXif ovf3) has rank 2 is equivalent to orf ov1 x 
or/ov2 =F- 0. According to the preceding theorem or/ov1 and 0r/ov2 are, 
at a point of the surface, tangent vectors to parametric curves, hence 
determine the tangential plane at the point. 
It follows that the cross 
product is normal to the surface and, when divided by its magnitude, is a 
unit vector. 
The relations in (4-2.7) and (4-2.9) together lead to a vector element of 
surface area. Since 
'or orj 
jor,,or,. 
. 
(4-2.10) 
-1 x -2 
= -1 
-2 
sm () = g1g2 sm (), 
ov 
ov 
ov 
ov 
we obtain 
(4-2.11) 
N dA = .E!._ x .E!._ dv1 dv2• 
ov1 ov2 
0 < () < 11", 
This expression forms the basis for the definition of the integral of a 
scalar over a surface. 
Definition 4-2.Sa. 
Let W be a continuous vector field defined on a 
smooth surface sector S. The scalar surface integral of W on S is 
(4-2.12a) 
W • N dA = 
Jim ! ! <l>(v/, vk2) AA;k• 
L 
n 
m 
8 
1'1Al-+O i=l k=l 
where <I> = W • N. 
 

276 
INTEGRATION OF VECTORS 
Definition 4-2.Sb. 
If W is defined on a sectionally smooth surface S 
composed of surface sectors S1 • 
· 
· S1, then 
(4-2.12b) 
Jsw 
· N dA = t1J8iW. N dA. 
From the analytic point of view, the integral (4-2.12a) is precisely the 
same as that studied in the calculus. Its evaluation depends on the fact 
that the double integral can be represented as an iterated integral. By 
using (4-2.11), we obtain the formula 
(4-2.13) 
Example 4-2.3. 
(See Fig. 4-2.4). Let X3 = (X1)2 + (X2)2, where 
x2 = v2, 
then 
and 
xa 
xi 
Fig. 4-2.4 

Surface integrals 
277 
Therefore the integral over the surface region in the first quadrant and 
otherwise bounded by X1 = v1 = 3 and X2 = v2 = 4 is 
-2 ff [(v1)2 + 2(v2)2] dv1 dv2 = -432. 
The concept of surface area is defined in a manner consistent with 
(4-2.12). In fact, if we let W = N and recall that the expression in (4-2.7) 
for dA is equivalent to lor/ov1 x or/ov21, then (4-2.12) reduces to the 
relation stated in the following definition. 
Definition 4-2.6. 
The area of a smooth surface is given by the following 
integral: 
(4-2.14) 
l 
1111'1"11 I 
or 
or I 
A = 
dA = 
2 1 -1 
x -2 dv1 dv2• 
s 
110
110 
ov 
ov 
Example 4-2.4. 
With respect to the surface region considered in 
Example 4-2.3, we have 
L dA =ff .J 4[(v1)2 + (v2)2] + 1 dv1 dv2• 
It is interesting to note that the area integral can also be represented in 
terms of the determinant g of the surface metric tensor components ga.fJ· 
Theorem 4-2.4. 
We have 
(4-2.15a) 
where 
l 
lv12lv11 
dA = 2 
1 .Jg dv1 dv2, 
S 
vo 
vo 
(4-2.15b) 
g = det (g.,11). 
PROOF. 
Recall Lagrange's identity (Chapter 1, Section 7, Problem 18) 
(A x B) • (C x D) = (A · C)(B • D) - (A • D)(B • C). 
We have 
(or 
or) (or 
or) ( or 
or) 2 
= 
ov1 
• 
ov1 
ov2 
• 
ov2 -
ov1 
• ov2 • 
By making the identifications 
gll 
= 1 ::1 r 
g22 
= 1 ::2 r 

278 
INTEGRATION OF VECTORS 
we obtain 
I 
or
1 
x ar
212 
= I 
gu 
g12 I 
= 
g. 
ov 
ov 
g21 
g22 
The proof is completed by substituting this result in (4-2.14). 
Example 4-2.5. 
Suppose the surface region S is, in fact, a region of the 
X1, X2 plane. (See Fig. 4-2.5.) 
Then 
x1 
= vi, 
x2 
= v2, 
xa 
= 0, 
a  v1  b, 
v02(v1)  v2  v12(v1). 
g 
= 1. 
The area formula (4-2.15a) reduces to 
lbf.v 2 : dv2 dv1• 
a 
VO 
In other words, we obtain the usual result. This confirms that the definition 
of surface area is consistent with that of plane area. The second criterion 
we ask of the definition, that of invariance, is considered in Section 2*. 
Example 4-2.6. 
Suppose that a smooth surface is given by the explicit 
representation 
X3 
= 
X3(X1, X2). 
A parameterization for the surface is 
x1 = vl, 
v2 
Fig. 4-2.5 

Then 
Therefore 
L1 
L2 
or 
or 
1 
0 
L3 
oX3 
Surface integrals 
279 
oX3 
oX3 
-x-= 
ov1 = -
OVl L1 -
0V2 l2 + l3
. 
ov1 
ov2 
0 
1 
oX3 
ov2 
I 
or 
or I [ (
o X3)
2 (
o xs)2J J.-! 
-x-
= 
1+ 
-
+ 
-
ov1 
Ov2 
ov1 
ov2 
By substituting this last relation into (4-2.14) we obtain the formula 
(4-2.16) 
f."i1J.v12 [ (0xsJ2 (0xsJ 
A =  
i 
2 
1 + 
-;-I 
+ 
-2 
dv2 dv1. 
t10 
vo 
CIV 
OV 
The surface integral of a vector field is also a useful idea. This concept 
is defined as follows. 
Definition 4-2.7. 
Let W be a continuous vector field defined on a 
smooth surface. 
(4-2.17) 
The surface integral of W is 
r w dA = lim L W(v/, vk2) LiA;k• 
Js 
lllAl-+01,k 
In order to evaluate surface vector integrals, it is, in general, necessary 
to represent W in terms of a constant basis. Therefore it is convenient to 
think of the factors of the integrand as initially defined in terms of 
rectangular Cartesian coordinates. The surface equations X; = X1(v8) can 
be construed in the sense of a change of variables made for the purpose of 
evaluating the integral. This procedure is illustrated in the example that 
follows the next theorem. 
Theorem 4-2.5. 
The integral of Definition 4-2.7 can be expressed in 
the form 
(4-2.18) 
i 
1 
• 
111 
111 
W dA = J. 1 J. 2 ..;gw dv2 dv1. 
s 
"• 
"• 
PROOF. 
The proof follows from the fact that the relation (4-2.7) for 
dA is equivalent to 
l
or 
or l dld2 
-x-
v 
v 
ov1 
ov2 
which in turn is equivalent to Jg dv1 dv2• 

280 
INTEGRATION OF VECTORS 
Example 4-2.7. 
Suppose that 
W = X111 + X212 
and the region of definition is 
(Xl)2 + (X2)2 + (Xa)2 = 1, 
X3> 0, 
X2> 0, 
x1 > o, 
that is, that part of the unit sphere in the first quadrant. 
In order to 
evaluate Is W dA, we can make use of the usual parametric equations 
In this example 
Therefore 
Problems 
1. Given 
show that 
X1 = sin v1 cos v2, 
X2 = sin v1 sin v2, 
X3 =cos v1• 
.Ji = sin v1• 
X1 = sin v1 cos v2, 
X2 =sin v1 sin v2, 
X3 =cos v1, 
ar 
ar 
av1 x av2 
= sin vlr. 
2. If vP = vll(v°') and I : 17'< 0, show that 
ar 
ar I 
ov°' I 
ar 
ar 
(a) 
av1 x av2 = avP av1 x av2 · 
Hint: Start with &;;k( axJj ov1)( axk/ av2) and transform to the bar system. 
(b) Parameterize X3 - (X1)2 - (X2)2 = 0 in each of the following ways: 
(1) x1 = v1, 
x2 = v2, 
xa = (v1)2 + (v2)2, 
(2) x1 = v1 cos v2, 
x2 = v1 sin v2, 
X3 = (v1)2• 

Surface integrals 
281 
Show that at X1 = v'2, X2 = v2, X3 = 4. 
or 
or 
lor 
or 
ov1 
x ov2 = 2 ov1 
x ov2 · 
3. Suppose that a given surface can be represented by either J (X1, X2, X3) = 0 
or Xi = Xi(vfl). Then ar/ i1v1 x ar/ ov2 and VJ would be normal to the 
surface, hence proportional to one another. 
(a) Show that if 
and 
then 
J(X1, X2, X3) = X8 + g(X1, X2) 
Or 
Or 
VJ = avi 
x ov2 . 
(b) Show that in general 
0r 
0r 
- VJ 
ov1 
x ov2 = '\1g JVJI · 
4. Let 8 be the angle determined by the positive senses of or/ov1 and or/ov2. 
Show that 
Hint: Use the trigonometric identity sin18 = 1 - cos2 8. 
5. Compute each of the following scalar surface integrals L W · N dA. 
(a) 
(x1 = vI, 
W=r X2=v2 
X8 = 1 '_ v1 - v2, 
v1<0, 
v2 < 0, 
vl+v2=1 
(i.e., the surface is a first octant plane area with vertices (1, 0, O), 
(0, 1, 0), (0, 0, 1). 
(b) W = x11.i + 2X2>. sis that part of the surface X1 + X2 = 1 which 
lies in the first octant and is bounded by X3 = 0, X3 = 2, X1 = 0, 
X2 = 0. Determine your own parameterization such that N points 
away from the origin. (X1 =cos v1, 
(c) W = (X2)21.i + X1>, X2 = sin v1, 
0 = v1 < 2 .. 
xs = vz, 
6. Find the surface area in each part of (5) by letting W = N. 
0 = v2 = 3. 

282 
INTEGRATION OF VECTORS 
7. Compute each of the vector surface integrals Is 
W dA : 
(X1 =cos v1, 
(a) W = X1L1 - X2Lii, X2 = sin v1, 
xa = v2, 
(b) 
(X1 = sin v1 cos v2, 
W = r, 
X2 = sin v1 sin v2, 
X3 =cos v2, 
0 % v2 % 2; 
2*. An Introduction to Surface Tensors and Surface 
Invariants 
The purpose of this section is to point out some of the elementary 
aspects of the intrinsic geometry of a surface and to establish the invariance 
of the area integral with respect to allowable surface coordinate trans­
formations. 
Throughout the discussion it is assumed that a smooth 
surface section (see Definition 4-2.1) is under consideration. 
If the surface has the vector equation 
(4-2*.la) 
then 
(4-2*.lb) 
where 
(4-2*.lc) 
r = r(tl), 
or 
p 
dr = -dv 
ovP 
' 
or 
or 
g«P 
= 
ov« • otl . 
In the preceding section we made use of the quantities 0r/oil and ga.p to 
develop the desired integral formulas. Now we emphasize their geometric 
nature and their properties under transformation of surface coordinates. 
At a point P of the surface S the vectors 0r/ov1, 0r/ov2 determine the 
tangential plane. (See Theorem 4-2.2.) Furthermore or/ov1 X or/ov2 "6 0 
implies that or/ov1, 0r/ov2 are linearly independent. Therefore these two 
vectors determine a basis in the tangential plane, T(P), to S at P. The 
building block of the intrinsic geometry of a surface is the geometry of the 
tangential plane. 
Let W be a Cartesian vector defined at a point P of Sand lying in T(P). 
Then 
(4-2*.2a) 

Introduction to surface tensors and surface invariants 
283 
where 
(4-2*.2b) 
Fig. 4-2•.t 
or 
rp 
= ov6• 
w 
(See Fig. 4-2*.1.) The Cartesian vectors rfJ are not unit vectors in general; 
rather they have magnitudes 
g6 = .Jg,, = .Jr6 
• r11• 
If we introduce unit vectors efJ with tne direction and sense of r, then 
(4-2*.2c) 
r 
= g6e1• 
The vector W can now be expressed in the form 
(4-2*.3) 
w 
= W1g1e1 + W2gaes; 
and W1g1, W2g2 are, according to the parallelogram law of addition, the 
parallel projections of W onto the directions of r1 and r2, respectively. 
If it is desired, we can introduce a two-dimensional Cartesian coordinate 
system into T(P) with the coordinate axes along r1 and r2• Hence the 
geometry of T(P) is local Cartesian. 
Example 4-l*.l. 
Suppose that the equations 
X1 
= X1[v6(t)] 
represented a curve on a surface S. The tangent vector 
dr 
or dv6 
dv6 
<4-2*.4) 
dt 
= ov6 dt 
= dt fp 
is a concrete illustration of a vector at a point P in T(P). From the view­
point of the three-dimensional space in which the surface is embedded, 
dr/dt, evaluated at P, is a free vector. In passing over to the intrinsic 
geometry of the surface it is necessary to consider the vector as bound to P. 

284 
INTEGRATION OF VECTORS 
Before commenting in a precise way on the vector concepts employed 
in the intrinsic geometry of a surface, it is necessary to secure information 
about surface coordinate transformations. It has been demonstrated that 
a surface parameterization X; = X;(vfl) is not unique; 
that is, other 
parameterizations of a given surface, for example X; = Xi(ifi), also exist. 
Now it is clear that any one of these parameterizations must satisfy the 
requirements designated by the term smooth surface section. In estab­
lishing the allowable transformations, 
(4-2*.5) 
if= tfl(if), 
we guarantee that the requirements of a smooth surface section will be 
met by making the following assumptions. 
Agreement 4-2 * 
.1 . 
The surface coordinate transformations of the form 
in (4-2*.5) satisfy these properties: 
(a) The functions in (4-2*.5) are defined on a domain D' of ifJ 
values such that the range values rJ include D. [See (4-2.1) 
and (3-1.2).] 
(4-2*.6) 
(b) At least the first partial derivatives otfl/ovrJ. are continuous 
everywhere in D'. 
(c) The Jacobian of transformation, jov/ovl, is different from 
zero everywhere in D'. 
The coordinate transformations satisfying agreement ( 4-2 * .1) are called 
allowable coordinate transformations. 
The preceding agreement establishes the nature of the allowable co­
ordinate transformations; therefore we can proceed with some of the 
elementary aspects of the theory of surface coordinate transformations. 
Example 4-2*.2. 
If vii= vll(vrJ.), then 
dtfl 
ovP dif 
(4-2*.7a) 
- = --
dt 
(}if dt 
Therefore the element of the set {dvfi/dt} are related by a rule previously 
designated contravariant. 
The existence of the class of components 
{ dvll / dt} motivates the following definition. 
Definition 4-2*.1. 
The class {WP}, whose elements satisfy the trans-
formation rule 
(4-2*.7b) 
WP = ovP W'" 
(}if 
is said to be a contravariant vector on the surface S with respect to the 
allowable transformation group. (See Fig. 4-2. * l .) 

Introduction to surface tensors and surface invariants 
285 
At this stage of development it is appropriate to dissociate from the 
embedding three-dimensional space and to concentrate on the intrinsic 
geometry of the surface. In terms of the geometry of the surface, which is 
in general non-Euclidean, a contravariant vector cannot be endowed with 
precise geometric meaning. The intuitional properties we can employ are 
inferred by the expression "locally Euclidean"; that is, at a point P of S, 
the linear algebraic relations to which the components of a vector are 
subjected are precisely the same as those employed in the Cartesian 
geometry of a plane. Therefore the surface can be thought of as Euclidean 
in a small neighborhood of a point, or, in other words,· the algebraic 
relations can be interpreted in the tangential plane at the point. Clearly, 
there are many difficulties awaiting discussion. For example, the tangential 
plane T(P) is a function of P; therefore the linear geometry previously 
mentioned is valid only at a point of S. 
The way· in which we make 
comparisons of vectors at different points of P is discussed in Chapter 5. 
A second basis can be introduced into T(P) in analogy to the develop­
ments of Chapter I, Section 5*, and Chapter 3, Section 4. We define 
contravariant basis arrows by means of the relations 
(4-2*.8) 
r1• rP 
= b/. 
This sets the stage for a complete algebraic duality. 
Just as the components of a tangential vector give rise to the concept 
of a contravariant vector, so do the components of a Cartesian gradient 
vector serve as the prototype of a covariant vector. 
Example 4-2 * .3. 
Let <I> be a scalar function defined on a smooth surface 
section S. 
Let vP = vli(iF) be an allowable coordinate transformation. 
Then 
(4-2*.9a) 
0<1> 
orl 0<1> 
ovli 
= 
ovP ofl . 
Definition 4-2*.2. 
The class {W11}, whose elements satisfy the trans-
formation rule 
(4-2*.9b) 
is said to be a covariant vector on the surface S with respect to the allow­
able transformation group. 
As long as a metric is associated with a given space, covariant and 
contravariant vectors are just different algebraic representations of the 
same geometric entity. The relation between the two types of vector is 
established by use of the components ga/J· The development of these ideas 
is precisely the same as the curvilinear coordinate development of Chapter 

286 
INTEGRATION OF VECTORS 
3, Section 4; therefore we restrict the following to a statement of fun­
damental facts. 
A vector W has the representations 
(4-2*.lOa) 
w - wPr - WPg 
r1 - w r1 
-
p -
py 
-
y 
• 
In particular, the contravariant and covariant components satisfy the 
relations 
(4-2*.lOb) 
w1 = g 1pwP, 
wP = gP1w1, 
where the gllY satisfy the defining equations 
(4-2*.lOc) 
Definition 4-2*.3. 
The class {ga/J}, whose elements satisfy the trans-
formation rule 
(4-2*.lla) 
is called the fundamental metric tensor of the surface and is a tensor of 
covariant order 2. 
It is shown (as in Chapter 3, Section 4) that g°'/J satisfies the contra­
variant rule of transformation 
(4-2*.llb) 
aP - ova ovP -J.1 
g 
- oii a1? 
g 
· 
Definition 4-2*.4. 
The class {g"'/J} is called the associated fundamental 
metric tensor of the surface. It is a tensor of contravariant order 2. 
The determinant of the components of the fundamental metric tensor 
will prove useful in the sequel. Its rule of transformation, as well as that 
of the determinant of the contravariant metric tensor, is indicated by the 
next theorem. 
Theorem 4-2*.1. 
The classes of elements {lga/JI} and {lg<XPI} are scalars 
of weights -2 and +2, respectively, with regard to the allowable group 
of surface transformations. 
PROOF. 
The proofs follow by noting that the determinants of the 
right-hand sides of(4-2*.lla,b), respectively, can be expressed as products 
of three determinants. Thus 
(4-2*.12) 

Introduction to surface tensors and surface invariants 
287 
According to preceding convention, the factors lov/ovj-2, lov/ov!+2 
represent weight factors of -2 and +2, respectively. 
Let us investigate the invariance of the representation for surface area 
under allowable surface coordinate transformations. (See Fig. 4-2*.2.) 
In order to attack this question, we introduce a local plane Cartesian 
coordinate system5 in the tangential plane at a point P of a surface S. 
Suppose the Cartesian system with coordinates Xi,j = 1, 2 and origin at 
P is rectangular. Let U and W be two surface vectors at P [hence in T(P)j. 
If the Cartesian coordinates are related to the surface parameters by means 
of the equations 
(4-2*.13a) 
j = 1, 2 
and &;k• &cx/l satisfy the transformation rule 
(4-2*.13b) 
j, k = 1, 2 
(see Chapter 1, Section 6, for the definition of &;k), the area of the parallelo­
gram determir.ed by U and W is 
(4-2*.14a) 
&. ujwk =I ax I & u«WP 
1k 
av 
«/I 
. 
That the preceding relation represents the indicated area can be made 
clear by considering the left-hand member as the third component, 
&3;kUiWk, of the cross product ofU and W. This statement is made under 
the supposition that a three-dimensional Cartesian system can be intro­
duced by taking X3 perpendicular to the plane of X1, X2• 
x2 
I 
I 
I 
I 
I 
I 
u 
Fig. 4-2•.2 
• The existence of such a local system can be demonstrated. See Synge and Schild, 
Tensor Calculus, University of Toronto Press, 1956, p. 59. 

288 
INTEGRATION OF VECTORS 
According to Theorem 3-5.2, 
'('=Jg. 
Therefore the generalized expression for the area of a parallelogram, as 
indicated by the right-hand member of (4-2*.14a), is 
(4-2*.14b) 
Jg f;apUaWP. 
It is this expression that gives rise to a general definition of the element of 
surface area. 
The procedure established in this development can be generalized to 
elements of volume in a straightforward manner. 
Definition 4-2*.5. 
Let 01v"' = (o1v1, b1v2) and o2v"' = (o2v1, 02v2) be 
differential representations of independent directions in T(P) at a point P 
of a smooth surface section S. The differential element of area determined 
by b1v and b2v is 
(4-2*.15) 
Since Jg is a scalar density of weight -1, e"'P is a covariant density of 
order 2 and weight + 1 and the differentials are contravariant vectors of 
weight zero, it follows that (4-2*.15) is an invariant. Furthermore, if 
(4-2*.16) 
01V1 = dv1, 
02V1 = 0, 
01V2= 0, 
02V2 = dv2; 
that is, if the differential vectors have the directions of the parameter 
curves (4-2*.15) reduces to the expression 
(4-2*.16b) 
This is precisely the area element introduced in the last section. 
Problem 
1. Carry out the proof of the scalar character of .Yg &"'p 61v"' 62vf1. 
3. Volume Integrals 
This section deals with integrals of the types 
(a) L <l>(.X1, _x2, _xa) d V, 
(b) Iv G dV = L1 L G1 dV + L2 Iv G2 dV + L3 L G3 dV. 

Volume integrals 
289 
Fig. 4-3.1 
In both cases the integration theory discussed in the usual calculus course 
applies. 
The standard method for evaluation of the volume integral 
depends on its equivalence to an iterated triple integral. 
A problem which might arise is that of determining the element of 
volume associated with a given coordinate system. 
The key to this 
determination is again the fundamental metric form 
ds2 = g1,. dX; dX,.. 
Because orthogonal curvilinear coordinate systems are most often of 
practical value, this discussion is restricted to them. (For an introduction 
to a more general procedure see Section 2*.) 
For n = 3, each of the equations, X1 = constant, X2 = constant, X3 = 
constant represents a coordinate surface. 
In rectangular Cartesian co­
ordinates each of these surfaces is a plane, whereas in cylindrical coordinates 
p = constant is a circular cylinder and 0 = constant and z = constant 
represent planes. The intersection of two coordinate surfaces determines 
a coordinate curve. 
Therefore three families of coordinate curves are 
associated with each system. It is in terms of the set of three coordinate 
curves associated with each point P (see Fig. 4-3.1) that we offer the 
following intuitive argument leading to a definition of an orthogonal 
differential element of volume. The pattern follows that established for 
surface elements of area. 
Let (ds)1> (ds)2, (ds)3, respectively, represent the differentials obtained 
from the fundamental metric form by holding X2, X3 constant, X1, X3 
constant, and X1, X2 constant. 

290 
INTEGRATION OF VECTORS 
Theorem 4-3.1. 
For orthogonal curvilinear systems, we have 
(4-3.1) 
PROOF. 
Holding X2 and X3 constant reduces ds2 to 
Therefore 
Similarly 
Since the system is orthogonal g1k is diagonal, 
This completes the proof. 
Because magnitude cannot be associated with the quantities (ds);, it is 
necessary to follow the pattern of intuitive development in Chapter 4, 
Section 2; that is, we consider the finite quantities 
Consideration of the finite volume (J g11 !lX1)(J g22 !lX2)(J g33 !lX3) 
inspires the following definition. 
Definition 4-3.1. 
The differential element of volume associated with an 
orthogonal curvilinear coordinate system J(i is 
(4-3.2) 
dV = Jg dX1 dX2 dX3• 
Example 4-3.1. 
The differential volume element for rectangular 
Cartesian coordinates is 
(4-3.3a) 
dV = dX1 dX2 dX3, 
whereas for cylindrical coordinates 
(4-3.3b) 
dV = p dp d() dz, 
and for spherical coordinates 
( 4-3.3c) 
dV = r2 sin () dr d() dtfo. 
The reader may recall having used these forms in a course in calculus. 

Integral theorems 
291 
Problems 
1. According to (4-3.3a), the rectangular Cartesian differential volume element 
is dX1 dX2 dX3• Let o1Xi, o2Xi, o3Xi be defined such that 
(o1X1, o1X2, o1X3) 
= (dX1, 0, 0), 
(o2X1, o2X2, o2X3) = (0, dX2, 0), 
(03%1, osX2, oaXa) = (0, 0, dXa). 
Assume a corresponding definition in any other system. 
Define the 
okXi to transform as contravariant vector components. Then show that 
(a) dX1 dX2 dX3 = Bik:r> o1X1 o2Xk o3X11, 
(b) dX1 dX2 dX3 = v'"'j dX1 dX2 dX3• 
2. Show that v'gEipc llXi llXi llXk is a scalar of weight zero with respect to 
the allowable transformation group. 
3. Find the element of volume in a system of conical coordinates related to 
rectangular Cartesian coordinates by means of the transformation 
equations 
X1 = (s sin ,B + r cos {3) cos 0, 
X2 = (s sin /3 + r cos /3) sin 0, 
X3 = s cos /3 - r sin {3, 
where f3 is a constant. 
4. Integral Theorems 
X1 =r, 
x2 = o, 
X3 =s, 
Certain theorems relating integrals of different types (line, surface, 
volume) have proved to be of value in the development of theoretical 
physics. The purpose of this section is to investigate some of the best 
known. In particular, Stokes's theorem and the divergence theorem are 
discussed. 
The first theorem to be considered is the so-called Green theorem, 
named for the English mathematician G. Green (1793-1841). 
The 
theorem appeared in his "Essay on the application of mathematical 
analysis to the theory of electricity and magnetism," a fundamental work 
in the mathematical formulation of electric and magnetic phenomena. 
From the viewpoint of our present development this theorem serves as 
an aid in obtaining the more general Stokes theorem. 
Definition 4-4.1. 
A closed curve is said to be convex if any line in the 
plane cuts it in, at most, two points. 
Theorem 4-4.t.----{Ciren's theorem in the plane). 
Let R be a plane 
region bounded by a convex, sectionally smooth curve C. Suppose that 
P1(X1, x2), P2(X1, X2), oP1/oX2, oP2/oX1 are continuous on a domain 

292 
INTEGRATION OF VECTORS 
containing C, hence R. Then 
(4-4.1) 
f (0p2 -()pi) dX1 dX2 = J. (P1 dX1 + P2 dX2). 
JR oX1 oX2 
:t'c 
(C is oriented so that an observer moving along the curve always has the 
inside to his left.) 
PROOF. 
The functions P1 and P2 are independent of each other. Hence 
we must show that 
(4-4.2) 
(a) 
f (Jp2 dX1 dX2 = J. P2 dX2, 
JR0X1 
:t'c 
(b) f -()pi dX1 dX2 = J. P1 dX1, 
JR oX2 
:t'c 
where C is a composite of the smooth sections C1, C2 and C3; C3 represents 
the possibility of vertical joins X1 = constant. Suppose we consider 
(4-4.2b). The left-hand integral can be written as an iterated integral. 
(See Fig. 4.4.1.) Therefore 
(4-4.3) 
-J oP12dxidx2 = -Jx1(JYa(Jp12dx2) dx• 
ROX 
Xo Y1 OX 
= -Jx1 dX1[P1(X}Y2) - P1(XFY1)J 
Xo 
=Jx1P1(x1, Y1) dX1 +Jx0P1(X1, Ys) ax• 
Xo 
X1 
=i pi dx1 +i p• dxi + i p• ax• 
01 
 
 
=fcpi dX1. 
C2[X2 = Y2(X1)] 
Ca 
R 
Fig. 4-4.1 

Integral theorems 
293 
Since Xt = constant 
on 
C3, 
it 
follows 
that dXt = 0. 
Therefore 
( pt dX1 = 0 and is included only for completeness. 
By the same 
Joa 
process we can show the validity of (4-4.2a). 
The conclusion of the 
theorem follows by putting these results together. 
It is left as an exercise for the reader to show that Green's theorem in 
the plane can be put in the vector form 
(4-4.4) 
t 
N • V x P dA = f 
0 P • dr, 
where N = L3• 
Example 4-4.1. 
Let P = - X2t1 + X1t2• 
According to Green's theorem (note pt = - X2, P2 = x1), 
2 ( dA = ( ( oX1 - o(-X2)) dX1 dX2 =j - X2 dXt + X1 dX2; 
JR 
JR OX1 
OX2 
'Yo 
that is 
(4-4.5) 
In particular, the area of an ellipse can be calculated by taking as para­
metric equations 
Then 
X1 =a cost, 
X2 = b sin t, 
0  t < 27T. 
112 .. 
A = -
[-b sin t( -a sin t) + a cos t(b cos t)] dt 
2 
0 
1 12.-
= -
ab dt = 1Tab. 
2 
0 
G. G. Stokes (1819-1903, English), a contemporary of Green, was one 
of the leading developers of the English school of mathematical physics. 
The following theorem which bears his name plays a significant role in 
the mathematical development of physical theories such as electro­
magnetism. In fact, as previously hinted, the mathematical expression of 
physical phenomena gave rise to many of the integral ideas being studied 
in this section. 
Recall that thetenn surface implies that the parametric equations 
r = r(v8) have continuous partials of at least order 1. 

294 
INTEGRATION OF VECTORS 
Theorem 4-4.2 (Stokes's theorem). 6 
Suppose that a closed curve C 
bounds a smooth surface section S. If the component functions of r = 
r(vfl) have continuous mixed partials and the image of Con the v1, v2 plane 
is convex, then for a vector field G with continuous partial derivatives on 
S we have 
(4-4.6) 
I Is 
N • V x G dA = c G 
• dr. , 
PROOF. 
The method of proof consists in expressing the left-hand 
member of (4-4.6) as an iterated integral and applying Green's theorem 
in the v1, v2 plane. According to (4-2.11), 
Recall the Lagrange identity 
A x B · C x D = (A • C)(B · D) - (A • D)(B · C). 
By applying this relation to the right member of (4-4.7a), we can express 
the parenthetic factor of the integrand 
(4-4.7b) 
Since 
(4-4.7c) 
or or 
(or )( or) (or )( or) 
-x-·VxG= -·Va G·- - -·Va G·-. 
ov1 ov2 
ov1 
ov2 
ov2 
ov1 
the relation (4-4.7b) assumes the form 
(4-4.7d) or x or ·V x G = oG . - oG . 
ov1 ov2 
ov1 ov2 ov2 ov1 
o[G 
• (or/ov2)] o[G 
• (or/ov1)] 
= --=---'---'--
 
ov1 
ov2 
By putting this result into (4-4.7a), we have 
B(4-4.7e) ( N. V x G dA = (":• (":1{o[G . (o+/ov2)] 
Js 
J,,o J,,. 
ov 
_ o[G 
• (or/ov1)]} d 
1 d 2 
ov2 
v v. 
• This theorem first appeared as a problem in a Cambridge examination paper in 1854. 

Integral theorems 
295 
Now if we identify P1 with G • (or/ov1) and P2 with G. (or/ov2), it can be 
seen that the hypothesis of Green's theorem is satisfied, hence the con­
clusion may be employed; that is, 
f N • V x G dA = ,( (G 
• or dv1 + G • or dv2) = ,( G • dr. 
Js 
:re 
ov1 
ov2 
:re 
This completes the proof. 
Example 4-4.2. 
It has been shown (Chapter 3, Section l) that the 
independence of path of a line integral L 
F • dr was equivalent to the 
field F being conservative, that is, having a representative F = V<l>. To 
show that there is <I> such that Fis the gradient of <I> can be a difficult task. 
With the help of Stoke's theorem, we can show that 
VxF=O 
is a necessary and sufficient condition for the field F to be conservative. 
In particular, if F is conservative, 
V x F = V x V<l> 
= 0. 
On the other hand, if V x F = 0, 
fe
F • dr7 = Jsv x F • N dA = 0. 
Since the left-hand member of this expression represents a way of ex­
pressing the integral's independence of path, we can conclude that F is a 
conservative vector field. 
It should be mentioned that some of the restrictions on the bounding 
curve C can be removed without destroying the validity of the theorem. 
However, easing of the conditions on C makes the proof quite a bit more 
difficult. It is also the case that the theorem can be extended to a surface 
that is a composite of smooth sections by a simple process of addition. 
Stoke's theorem is not restricted to the scalar form in (4-4.6). This 
statement is verified by the following two theorems. 
Theorem 4-4.3a. 
Let the vector field G of Theorem 4-4.2 be replaced 
according to the relation G = /(Xi)a where f is a scalar function of 
7 A vector field F with the property £ F • dr = 0 often is said to be irrotational. The 
term arises from a physical interpretation of F as a velocity vector in a fluid. The 
relation V x F = 0 can be shown to correlate with the lack of rotational velocity of 
the particles of the lruia. -

296 
INTEGRATION OF VECTORS 
position and a is an arbitrary constant vector. Then 
(4-4.8) 
PROOF. 
We have 
(4-4.9a) 
Therefore 
(4-4.9b) 
V x fa = (V/) x a = -a x Vf 
N · V x G = -N ·a x VJ= a· N x Vf 
By employing (4-4.9b) we can put the relation in (4-4.6) in the form 
(4-4.9c) 
a· [L<N xVJ)dA-ffdr] = 0. 
The validity of removing a from the integral sign is a consequence of its 
constancy. Since a is arbitrary, the parenthetic expression must be zero. 
This completes the proof. 
Theorem 4-4.3b. 
Let the vector field G of Theorem 4-4.2 be replaced by 
G = F x a, 
where F is a differentiable vector field on S and a is an arbitrary vector 
constant. Then 
(4-4.10) 
PROOF. 
We have 
(4-4.lla) 
N • V x G = N · V x (F x a)= N x V · (F x a) 
=(NxV)xF·a 
and 
(4-4.llb) 
G • dr = F x a · dr = dr · F x a = dr x F · a. 
Therefore Stoke's formula (4-4.6) can be written 
(4-4.llc) 
a· f8(N x V) x F dA =a· f
0
dr x F, 
where again the constancy of a makes it possible to pull that vector out of 
the integral. Relation (4-4. llc) is equivalent to 
(4-4.lld) 
a· [f8(N x V) x F dA -f/r x FJ = 0. 
Since a is arbitrary, the relation (4-4.10) follows. 
Example 4-4.3. 
Let 
G = - X2'1 + x1'2 + .xa,3· 

Integral theorems 
297 
Suppose G is defined on (X1)2 + (X2)2 + (X3)2 = r2, X3  0. Then, 
according to Stoke's theorem [see (4-4.6)], 
(4-4.12a) 
( ! · (2L8) dA = j -X2 dX1 + X1 dX2 + X3 dX3• 
Jsr 
J'a 
The bounding curve C is a circle in the plane X3 = O; therefore it follows 
from ( 4-4.5) (or by direct use of the parameterization X1 = r cos cp, X2 = 
r sin cp, X3 = 0) that the right-hand line integral has the value 27Tr2• Hence 
from (4-4.12a) 
(4-4.12b) 
( 2X3 dX1 dX2 dX3 = 27Tr2• 
Js r 
The next integral theorem to be considered is the so-called divergence 
theorem, often called Gauss's theorem. It states a relationship between 
an integral over a closed surface and an integral over the enclosed volume. 
As with Stoke's theorem, we cut down on the generality of the theorem, 
in this case by assuming that the surface is oval-shaped. (Any line in 
space cuts the surface in, at most, two points.) This makes possible the 
presentation of a relatively simple proof. 
Theorem 4-4.4. 
Let G be a vector field with continuous derivatives on 
a closed space region R. 
Suppose that S were a smooth oval-shaped 
surface bounding R. Then 
(4-4.13) 
where n is an outwardly drawn normal. 
PROOF. 
Assume that the quantities involved in (4-4.13) are referred to 
a rectangular Cartesian coordinate system. In orthogonally projecting 
the surface S onto a coordinate plane (say the X1, X2 plane) each point P 
of the projection (see Fig. 4-4.2) corresponds to two surface points. 
Suppose n2 and n1 represent the outward drawn normals on the upper 
portion S2 and lower portion S1 of the surface, respectively. The vector 
element of surface area is (assume parameterizations X1 = v1, X2 = v2, 
X3 = zp(v1, v2), p = l, 2, respectively, for the surfaces S1 and S2) 
(4-4.14a) 
N dA = or x or dv1 dv2 
ov1 
ov2 
= (L1 + 1\3) x (L2 + 2\3) dv1 dv2 
( 
oX3 
oX3 ) 
= 
Ls - OV2 L2 - OVl L1 dvl dv2. 

298 
INTEGRATION OF VECTORS 
xs 
p 
xi 
Fig. 4-4.2 
Hence 
(4-4.14b) 
L3 • N dA = dv1 dv2 = dX1 dX2• 
According to ( 4-4. l 4b ), N has the orientation of L3• Therefore 
(4-4.14c) 
L3 • D2 dA = dX1 dX2, 
L3. D1 dA = -dX1 dX2• 
This result will prove useful in the sequel. 
The next step in the proof consists of performing one of the integrations 
indicated by the left-hand member of (4-4.13). We have 
(4-4.15a) 
( V • GdV=iJ.J(aGi + aG2 + aGs) 
dX1dX2dX3
• 
Jv 
ax1 
ax2 
axs 
v 
Consider the third of these integrals; that is, 
(4-4.15b) f.J.J aG: dX8 dX2 dX1 
=f"'1f111dx2 dX1 r•s aG: dX3, 
ax 
"'1 u1 
J.1 ax 
v 
where 

Integral tbeore01s 
299 
By performing the indicated integration, we obtain 
JJJ ;:dX8dX2dX1 = J.,"',·1:1(G8(X1,x2,z2)-G8(X1,X2,z1)]dX2dX1 
v 
=f8 G8L8•ndA. 
In a similar manner, the remaining two integrals of (4-4.15a) can be 
expressed in the forms 
(4-4.16) 
ff f :: dV = f 
8 G2L2 
• D dA, 
v 
ff f :: dV = fs G1L1 • n dA. 
v 
Together these results produce the conclusion (4-4.13). 
Among the integral relations developed during the English upsurge of 
interest in applied mathematics (nineteenth century) were the so-called 
Green identities. 
The formulas, stated in the next two theorems, are 
named after the same George Green previously mentioned in this section. 
Theorem 4-4.Sa (Green's first identity). 
Suppose U(Xi), W(Xi) are 
scalar functions with continuous second partial derivatives on a space 
region R. 
Suppose R is such that the bounding surface S meets the 
conditions of the divergence theorem. Then 
(4-4.17) f
v
[U V2W +(VU)· (VW)] dV =f 
8 Un· (VW) dA, V2 = V 0V 
PROOF. 
Let 
(4-4.18a) 
then 
(4-4.18b) 
G= UVW; 
V • G = VU· V W + U V2 W. 
By making the substitutions (4-4.18a,b) in (4-4.13) we obtain the conclusion 
of the theorem. 
Theorem 4-4.Sb (Green's second identity). 
Under the hypothesis in 
Theorem 4-4.Sa 
(4-4.19) f
v
(UV2w- wv2U)dv=f8n·(UVW- WVU)dA. 

300 
INTEGRATION OF VECTORS 
PROOF. 
Let 
(4-4.20a) 
Form 
G1 = UVW, 
G2 = WVU. 
(4-4.20b) 
G = G1 - G2• 
The result (4-4.19) is obtained by replacing G in (4-4.13) according to 
(4-4.20b). 
Example 4-4.4. 
Maxwell's equations, which serve as a foundation for 
electromagnetic theory, can be expressed in the form (in Gaussian units) 
(4-4.21) 
1 aB 
(a) 
V x E = - - - , 
(b) V • D = 47rp, 
c at 
( c) V x H = ! aD + 47Tj , 
c at 
c 
(d) V · B == 0,8 
where E and H represent electric and magnetic field strengths, respectively, 
whereas B denotes magnetic induction, (I/47T)D signifies displacement 
current, and j is an electric current vector. The constant 
c repre­
sents the velocity of light. For the most part these laws were derived 
from the experiments of Oersted, Faraday, and others. (See Chapter 1, 
Section 6.) However, the form of (4-4.21c), which resulted from experi­
mentation, did not contain the term l/c ('OD/at). This term was added by 
Maxwell on the basis of intuition supported by mathematical consistency. 
Maxwell noticed that the divergence of the left-hand side of (4-4.21c) was 
identically zero, whereas that of the right-hand side, in the absence of the 
partial derivative term, was not. With this inconsistency in mind, he 
considered the flux of electric current through an arbitrary area, i j · n dA. 
According to the divergence theorem, 
8 
(4-4.22a) 
J
8
j • n dA = Jvv 
· j dV. 
Furthermore, Maxwell assumed the conservation of charge, that is, 
(4-4.22b) 
( V . j dV = - aQ . 
Jv 
at 
where Q represents the charge inside the volume at any moment, that is, 
(4-4.22c) 
Q = fv p dV. 
8 A vector field G such that ,( G • n dA = 0 is said to be solenoidal. B is clearly a 
solenoidal vector field. 
is 

Integral theorems 
301 
From (4-4.22b) and (4-4.22c) it results that 
(4-4.22d) 
fv(V·j+::)dV=O. 
Since this relation is independent of the volume V, it follows that the 
integrand is equal to zero. 
(4-4.22e) 
Maxwell assumed the validity of (4-4.21b), which, when solved for p, has 
the form 
1 
p =-V·n. 
47T 
From this it follows that 
(4-4.22f) 
a P = _!_ v . ao . 
at 
47T 
at 
Putting this result in (4-4.22e), we have 
o = v . j + _!_ v . an = v . (j + _!_ an) . 
47 
at 
47 at 
In other words, the divergence of j is not, in general, zero, but the di­
vergence of j + 1/47T(an/ot) is equal to zero. 
Therefore Maxwell 
hypothesized that 
v x H = 47T (j + _!_ an) . 
c 
477 at 
The existence of the displacement current, 1/47T(an;at), was confirmed 
later by experiments carried out by Hertz. 
Problems 
1. Use Green's theorem to evaluate the integral of P over the closed path C: 
{x2 
= (X1)2 + 4 
(a) p 
= X2l1, 
C: 
x2 
= -[(X1)2 - 8) counter-
clockwise. 
C: the unit square with origin as 
center. 
C: counterclockwise 
around the 
ellipse 
(X1)2 
(X2)2 
-9- +-4-
= 1. 

302 
INTEGRATION OF VECTORS 
2. Use Green's theorem and the method of Example 4-4.1 to show that the area 
x = cosh-1 z1• (See the accompanying diagram.) 
3. Let p = U2L1 - U1L2. Show that (4-4.4) can be put in the form 
L V • U dA = 0(U x dr) • L3• 
4. Use Stoke's theorem to evaluate the integral of G over the closed path C 
bounding the region R. 
{x1 = vi, 
x1=1 
C· 
' 
. 
xi = -vl, 
x1 = -1, 
x2 = (vl)2, 
x2 = 1, 
x2 = (vl)2, 
x2 = 1, 
(X1 = v1, 
- 1 :s; v1 :S: 1, 
R: 
x2 = (v1)2, 
X3 = v2, 0 :S: v2 :S: 4. 
X3 =O, 
x3 = v2, 
X3 =4, 
X3 = 4 - v2, 
-1:S:v1:S:1, 
0 :S: v2 :S: 4, 
-l:S:v1(1. 
0 :S: v2 < 4. 
5. Show that the integral of G = -X2L1 + X1C + X3L3 over any surface 
satisfying the properties of Stokes's theorem and bounded by a convex 
curve in the plane X3 = 0 is equal to the integral of G over the plane 
region bounded by C. 
6. If G = X1L1, find the LG· n dA, where Sis the surface (X1)2 + (X2)2 + 
(X3)2 = 1 by (a) direct integration, (b) the divergence theorem. 
7. Find Is G · n dA over (X1)2 + (X2)2 + 2X8 by using the divergence 
theorem, where G is defined in Problem 6. 

8. Suppose that W satisfied Laplace's equation 
v2w =O. 
Show that Green's first identity reduces to 
Integral theore1ns 
303 
fvvu. 
VWdV= i Un·VWdA. 
9. (a) Let P = X2L1 and show that A= -£ X2dX1• 
(b) Let P = X1l:J and show that A = £ X1 dX2• 
(c) Show that the results of (a) and (b) imply the area formula of Example 
4-4.1. 
(d) Use the formula of (a) to obtain the area of the ellipse of Example 
4-4.1. 
10. The experimental laws from which the Maxwell equations arose can be 
regained from these equations. 
(a) Obtain Faraday's law of electromagnetic induction 
,(E·dr = -   ( B·NdA 
Ya 
c iJt Js 
from (4-4.21a) and the use of Stokes's theorem. 
(b) Obtain Oersted's law 
from 
iH·dr = 4n- (j·NdA 
a 
c Js 
47T 
V x H =-j. 
c 
(c) Show that the total magnetic flux (i.e., l B · n dA) through a closed 
oval-shaped surface is zero. 
s 
11. Suppose that a continuous vector function F with continuous first partial 
derivations over a region including a smooth surface section S is identi­
cally zero on S. Show that V x F is either tangential to S or equal to 0. 

chapter 5 tensor algebra and analysis 
Tensor calculus came into prominence with the development of the general 
theory of relativity by Einstein in 1916. It evolved into a cohesive body of 
knowledge through the efforts of Ricci and Levi-Civita, who published a 
paper1 in 1900 illustrating the application of the tensor methods to geom­
etry and mathematical physics. 
Tensor calculus comes near to being a 
universal language in mathematical physics. 
It allows for compact 
expression of equations and also provides a guide to the selection of 
physical laws. 
The role of tensor analysis is that of a theoretic tool. In general we can 
expect qualitative results rather than quantitative; that is, relationships 
can be found and examined but numerical answers are not so likely to be 
obtained. 
From the mathematical point of view, we shall be studying geometric 
invariants and the modes of transformation of their coordinate system 
representations. 
The intuitive background for the formal development 
of the ensuing pages can be found in Chapters l, 2, and 3. In fact, much 
of the present task is simply that of extending the ideas previously developed 
in terms of Euclidean two- or three-space to a generalized space of n 
dimensions. 
This is precisely the process carried out by Riemann in 
extending the surface theory developed by Gauss to a space of n dimensions. 
In carrying out a process of generalization, the results must contain the 
initial information as a special case or as an approximation. Furthermore, 
it is hoped that the generalizations will lead to new results and new applica­
tions. This hope has been realized for the ideas presented in this chapter 
1 Methodes de calcul differential et leurs applications, Math. Ann., 54, 1901. 
304 

Fundamental notions in n-space 
305 
by the development of general relativity and numerous other applications 
to mathematical physics. 
1. Fundamental Notions in n-space 
The term "space" has been used consistently as an undefined concept. 
The nature of man's reality is such that the terms "euclidean two- or 
three-space" have a meaning common to a large group of individuals. It 
is usual ( a  practice on which our previous work depends) to assume a 
one-to-one correspondence between the points of these spaces and the 
sets of all real-number pairs or real-number triples, respectively. In fact, 
it is not uncommon to say, for example, that the set of all real-number 
triples is the three-space. I prefer to preserve the geometric identity of 
the term "space," as well as the language of geometry, as an intermediate 
between the physical and the algebraic. Furthermore, surfaces provide 
examples of non-Euclidean two-spaces, that is, spaces for which the 
pythagorean theorem does not intrinsically determine the metric. For a 
surface it is interesting to note that the set of real number pairs put in 
one-to-one correspondence with the points may be a restricted set. For 
example, in the sphere with parameterization X1 = sin () cos cf>, X2 = 
sin() sin cf>, X3 = cos (), the pairs ((), </>) satisfy the restrictions 0 5; () 5; TT, 
0 5; </> < 27T. 
It is assumed that there is a one-to-one correspondence between the 
points of a general n-space2 and the ordered set of n-tuples of real numbers 
{X1, · 
· 
·
,
 xn}. The real-number domain of any one of the coordinates 
X1, · 
· 
· , xn :may be restricted to a finite interval. Whether then-space can 
be attributed a physical existence is of philosophic importance but need 
not concern us. The usefulness of an n-dimensional structure is pointed 
out by the many physical problems involving more than three independent 
variables; for example, the problem of describing the behavior of a par­
ticle whose velocity does not depend on the position. In this case there are 
six independent variables and the physicist deals with a so-called six­
dimensional configuration space. 
As a first step toward the development of the tensor algebra associated 
with an n-dimensional space, let us fix our attention on a particular 
coordinate system. 
Rules of operation for the following entities are 
introduced. 
Definition 5-1.1. 
Sets of nk elements are called systems of order k. 
•The words "hyperspace," "variety," or "manifold" are often used for n-space in 
order to distinguish it from the usual three-space. 

306 
TENSOR ALGEBRA AND ANALYSIS 
Example 5-1.1. 
The linear homogeneous function 
a;X;, 
j = I,· · ·
,
 n 
is a system of order zero, whereas the sets (al> · ··,an) and (X1, · 
· 
·
,
 xn) 
are systems of order 1. The Kronecker delta 
(5-1.1) 
is a system of order 2. 
Definition 5-1.2. 
A system, Tfi.1 ·. ·. }!q, expressed by means of q super­
scripts and p subscripts is said to have contravariant valence q and co­
variant valence p. 
The Kronecker delta has a contravariant valence I and covariant 
valence I. 
The terms covariant and contravariant were first discussed in Chapter I 
Section 5 •. They refer to modes of transformation, and, of course, it is 
our present purpose to set up an algebraic structure that will be consistent 
with a theory of tensor transformations. 
The systems introduced by Definition 5-1.1 are subject to the following 
rules of operation. 
Definition 5-l.3a. 
If two systems have the same covariant valences and 
the same contra variant valences, the set of elements obtained by component 
addition is a system of the same type (i.e., the covariant and contravariant 
valences agree with those of the original systems). 
Example 5-1.la. 
If a/, b/ are given systems, then 
(5-1 .2) 
d/ =a/+ b/ 
is a system of the same covariant and contravariant valences. The com­
ponents of d/ are n2 in number. For example, if n= 5. 
d11 = a11 + b11 
d25 = a25 + b25, etc. 
Clearly, the addition process can be extended to any number of systems, all 
of which have the same covariant and contra variant valences. 
Definition 5-l.3b. 
Let 1j1:: :f.,q and Rl';:: ;,m, be arbitrary systems. Then 
the system 
(5-1.3a) 

Fundamental notions in n-space 
307 
of contra variant valence q + sand covariant valence p + r is said to be the 
outer product of the two original systems. The number of components of 
the outer product is nPH+r+•. 
Example 5-1.lb. 
If pi and Qk are components of n-space n-tuples, then 
pi Qk is a system of contra variant valence 2. The number of components of 
this system is n2• 
Definition 5-l.3c. 
Let T1:::1q be a system of mixed order; that is, 
p > 0, q > 0. The system 
(5-1.3b) 
is said to be obtained from the original system by means of contraction. 
The summation on ja = kb = c reduces both the covariant and the contra­
variant valence of the system by 1. 
Hence the order of the system is 
reduced by 2. 
Example 5-1.lc. 
If the Kronecker delta is contracted, we obtain a 
scalar; that is, 
(5-1.4) 
b/ = n. 
Definition 5-1.3d. 
Let T::: J; and R:: i,m. be arbitrary systems. The 
system 
(5-1.5) 
obtained by summing on }a and mb is said to result from transvection of 
the original systems. The summation could just as well be with respect to a 
contravariant index of T and a covariant index of R. 
The process of transvection can be thought of as a combination of 
multiplication followed by contraction. 
Example 5-1.ld. 
Suppose that P1 and Qk are components of three-space 
n-tuples. The cross product 
(5-1.6) 
is a system of order 1 obtained by a double application of the process of 
transvection. 
The concepts of symmetry and skew symmetry for double indexed 
systems have been discussed; that is, if 
(5-l .7a) 

308 
TENSOR ALGEBRA AND ANALYSIS 
the system A;k is said to be symmetric, whereas 
(5-l.7b) 
symbolizes the property of skew symmetry. It is advantageous to extend 
the terminology to systems of higher order. 
Definition S-1.4a. 
A system A11 
. . .  ;k' which satisfies the property 
(5-1.7c) 
A 11 · · · ipiq · · · ik 
= A i1 · · • iqip · · · ik 
for all pairs p, q = 1, 2; 2, 3, · 
· 
·
,
 k - I, k is said to b:: completely 
symmetric. 
Definition S-1.4b. 
A system A11 
. . .  'k' which satisfies the property 
(5-1.7d) 
for any two adjacent indices is said to b:: completely skew symmetric. 
Definitions 5-l.4a,b apply to contravariant systems as well. However, 
they are not to be extended to mixed indices. 
Example 5-1.3. 
The &-system E;1k is completely skew symmetric ; 
that is, 
&123 
= &231 
= &312 = 
-&213 
= -&132 = 
- &321 • 
A system Aiik such that 
Aiik = Aiki = Akii = Aiik = Aiki = Akli 
illustrates a completely symmetric set of components. The six possible 
ways of expressing the three index systems found in this example are 
easily obtained by a process of cycling. The procedure can be correlated 
to that of interchanging an even or odd number of adjacent pairs, that is, 
an even or odd transposition. 
In Chapter I, Section 8, equality of matrices A, B was defined as 
A1k 
= B1k for all pairs j, k. Therefore the transpose A' of a matrix A is a 
new entity unless, of course, the matrix is symmetric. 
Just as a given 
matrix gives rise to another matrix (i.e., the transpose), systems give rise 
to other systems. This idea, and the meaning of equality of two systems, 
is expounded in the following definition. 
Definition 5-1.5. 
Two systems Tf;:: :f1Jq and R+,: :i;'q are equal if and 
only if 
(5-1.8) 
Rk1···ka _ Tk1···kq 
ii ... if) -
i 1 •
•
•
 ip• 
A given system, for example A11 
. . .  1"' gives rise to p ! systems by re­
ordering. of the elements of the set. 
Since an interchange of indices is 

Fundamental notions in n-space 
309 
equivalent to either an even number or an odd number of transpositions, 
it is possible to classify the new systems. 
Definition 5-1.6. 
A system T11 . . . ip arising from Tk1 ... kp by means of a 
reordering of components is said to be an isomer of the original system. 
If k1 • 
• 
• k1J is an even permutation of }1 • 
• 
• j1J, the isomer is said to be 
even. If k1 • 
• 
• k1J is an odd permutation of }1 • 
• 
• jp, the isomer is said to 
be odd. 
Since all isomers of a given system are of the same order and valence, 
we can carry the process of construction a step further and combine 
isomers. This leads to the interesting consequence of being able to con­
struct completely symmetric or completely skew symmetric systems from 
a given system. 
Theorem 5-1.1. 
The systems Au1 . . •  ip) and Ali1 
. . •  ipl' defined by 
(5-1.9) 
( ) A . 
= .!_(sum of all even isomers + 
a 
bi· 
.
.
 ip> 
p ! sum of all odd isomers of 
b) A . 
. 
= .!_ (sum of all even isomers -
( 
l11 · · · '"1 
p ! sum of all odd isomers of 
A11 .
•
.
 ;), 
are completely symmetric and completely skew symmetric, respectively. 
Corresponding statements hold for contravariant systems. 
PROOF. 
Consider (5-l.9a). If an interchange of adjacent indices is 
made, the odd isomers become even and vice versa. Since a plus sign joins 
the two groupings, the resulting expression is the same as the original. 
In (5-l.9b) the two groupings are connected by a minus sign. This accounts 
for the skew symmetry. 
Example 5-1.4a. 
Let A1k be a given system. Then the completely 
symmetric systems constructed from A;k are, respectively, 
(5-1.10) 
(a) 
Auk> 
= t(A;k + Ak1), 
(b) Alikl 
= t(A;k - Ak1). 
Suppose that A1k is a symmetric system. Then from (5-1.lOa) 
Ac;k> 
= t(A;k + Ak;) 
= t2A;k 
= A1k· 
Therefore the factor of !, which is not necessary for the symmetry of the 
expression, is needed for conformity. 

310 
TENSOR ALGEBRA AND ANALYSIS 
Example 5-1.4b. 
Let A;k1J be a given system. Then 
1 
(c) 
A(iki:>> = 3! [(Aiki:> + Aki:>i + Ap;k) + (AkiP + A;pk + Apk;)] 
(5-1.10) 
The differential form 
ds2 = g,,p dX" dXP 
plays a part in later considerations concerning Riemannian geometry. 
The form is symmetric in dX« dXfJ. The next two theorems point out that 
grxfJ might as well be chosen as a symmetric system. 
Theorem 5-1.2a. 
A quadratic system A;k can be expressed as a sum of 
its symmetric and skew symmetric parts. The same statement holds for a 
contravariant systeIIJ.. 
PROOF. 
We have 
In the same way, we determine that 
(5-1.11 b) 
Theorem 5-l.2b. 
Suppose that Bik is symmetric and A;k is skew 
symmetric. Then 
(5-1.12) 
PROOF. 
First we use skew symmetry and symmetry, respectively, to 
interchange indices and then replace dummy indices in order to switch 
back. Symbolically, we have 
Therefore 
2A;kB1k 
= 0. 
This completes the proof. 
The task. of applying Theorems 5-1.2a,b to the differential form is left 
to the reader. (See Problem 2.) 
We next consider the extension of 6 systems and related entities to 
n-space. 

Definition 5-1.7. 
Let 
(5-1.13) 
Fundamental notions in n-space 
311 
{ 1 
{even permutation 
611 ... 1,. = E11•••1" = 
- 1 if j1 ···in is an 
odd permutation of l · · · n. 
0 
otherwise 
This definition differs from that in Chapter I, Section 6, only in extent. 
The meaning of the Kronecker delta is unchanged; that is, 
b / = {
1 
if {j 
= k, 
0 
j =;I= k. 
It is convenient to have available the generalized Kronecker delta 
introduced in the next definition. 
Definition 5-1.8. 
Let 
(5-1.14) 
tJk1 · · · ka _ tJk1 tJk1 •
•
•
 tJka 
ii· · · ia -
ii 12 
1a· 
The refation between the covariant and contravariant 6 systems can 
now be stated as follows. 
Theorem 5-1.3. 
We have 
(5-1.15) 
611 ... 1pA:JJ+i' . •  k,.Ek1 ... k,. = p! (n - p) ! b1. '. '. /:1, 
where the bracket notation has the meaning indicated in (5- l.9b). 
PROOF. 
Consider the left-hand member of (5-1.15). When the sum­
mation on kn is carried out, we obtain at most n - p nonzero terms. 
The number of nonzero terms is exactly n - p if j1 • 
• 
• jjl is a distinct set 
chosen from 1 · · · n, and k1 • 
• 
• kjl is some permutation of this set. 
[If 
ji · · · jjl and k1 • 
• 
• kjl are otherwise, (5-1.15) reduces to the identity 
0 = O.] Under this circumstance, next sum on kn-i· The resulting number 
of nonzero terms is (n - p)(n - p - 1). 
Continuing this process of 
writing out tlfe indicated summations, we obtain 
(n - p)(n - p - 1) · · · 1 = (n - p)! 
nonzero terms. One typical term would be 
& 
£k1 .. ·kJJJJ+l . . .  " 
11 • . •  1jJJJ+l ... " 
• 
Since the last n - p sub- and superscripts agree in each term, the value 
(0, 1, -1) of any term is dependent on the subscripts ji · · · jjl and the 
superscripts k1 • 
• 
• kjl. If the one set is an even permutation of the other, 
the product is +I; if it is an odd permutation of the other, the product is 
- 1 . This result is represented exactly by the right-hand side of (5-1.15). 
The p ! compensates for its reciprocal in the bracket notation. 

312 
TENSOR ALGEBRA AND ANALYSIS 
Special examples of products of the type in (5-1.15) are listed in Chapter 
1, Section 6. 
The fundamental ideas concerning determinants were presented in 
Chapter 1, Section 6. It would serve no purpose to repeat the details of 
that development. However, the results were expressed for determinants 
of order 3. Therefore statements of generalization may serve to clarify and 
summarize the conclusions. 
Definition S-1.9. 
A pth order determinant symbolized by 
(5-l.16a) 
la/I= 
a1 i 
a1v 
a/ 
a./' 
has the numerical value a which is obtained in either of the following ways: 
(5-1.16) 
(b) 
(c) 
8 
a - " 
ak1 .
.
•
 akv 
ii"·iv - l>k1 .. ·kv i1 
iv• 
Eii ... iva = Ek1 ... kvak! ... ai:· 
The expressions (5-1. l6b,c) are not independent. One can be obtained 
from the other, as indicated in Chapter 1, Section 6. 
Theorem S-1.4. 
by 
(5-1.17) 
The numerical value a of the determinant la/I is given 
a =_!_£ii··· iv(; 
ak1 ... akv 
k1 .. ·kv 11 
iv 
p! 
The proof of ( 5-1.17) is left to the reader. The forms in ( 5-l.l 6b,c) and 
(5-1.17) make trivial the proofs of the elementary properties of deter­
minants. (See Chapter 1, Section 6.) 
Definition S-1.10. 
A determinant le/I is said to be the product of la/'I 
and lb/I if and only if 
(5-1.l8a) 
cl= a/b/. 
Theorem S-1.5. 
If c is the value of la/b/I and la/I, lb/I have the values 
a and b, respectively, then 
c =ah. 
Again the proof is left to the reader. It differs only in generality from 
that of Chapter 1, Section 6. 
The multiplication in (5-1.18a) is not commutative. If 
(5-l.18b) 
c/ = b/a/, 

then, in general, 
Fundamental notions in n-space 
313 
However, it is true that 
c= c. 
The cofactor of an element a/' in la/I has played and will continue to 
play a part in solving systems of linear equations. By the cofactor of a/ 
we mean the determinant of order p - 1 obtained by striking out the jth 
row and kth column of la/I and prefixed with the sign ( -1)1+k. According 
to our notation, the cofactor Al of a/ is represented by 
(5 119) 
" 
A s - " 
a'2 . . .  a
'P 
-
• 
01'1 • • •  ip k 
-
0ki1 .•• ip i1 
ip' 
Theorem 5-1.6. 
The cofactor A/ of a/ in lap qi can be expressed in the 
form 
(5-1.20a) 
where, according to (5-1.15), 
(5-1.20b) 
15W2 . .  ·ipJ = ..!._E"•"'ipt; 
kqa • · • qp 
p ! 
kq, • • · Qp' 
The proof is left to the reader. 
For n = 3, especially in relation to the development of transformation 
concepts, we used the facts 
(5-1.21) 
a/ Apk = 15/a, 
apk A/ = 15/a, 
a ¥:- 0. 
It was assumed that these expressions were consequences of the definition 
of cofactor. This can be demonstrated rigorously by obtaining (5-1.21) 
from (5-1.20a). (See Problem 7 at the end of the section.) 
The preceding facts concerning determinants are of an algebraic nature. 
The following result concerns a determinant whose elements are functions. 
Theorem 5-1.7. 
Let la/I be a determinant whose elements are in­
dependent functions defined in some region of space. Suppose that at 
least the first partial derivatives were continuous on the domain of defini­
tion. Then 
(5-1.22) 
a la/I = A P. 
a 
Q 
Q 
aP 
Since this theorem imitates Theorem 3-5.3, except for generality, the proof 
is left to the reader. 
Problems 
1. Suppose that A1k were skew symmetric. Evaluate A11kl· 
2. Show that g a.fJ dX« dXfJ reduces to g<a.fJ> dX« dXfJ. 

314 
TENSOR ALGEBRA AND ANALYSIS 
3. If the components of an Euclidean three-space n-tuple A; are defined by 
A; = &1k1BkC1, 
show that Bk and C1 are orthogonal to A1• 
4. (a) Prove Theorem 5-1.4. 
(b) State a corresponding theorem for la1kl. 
5. Prove Theorem 5-1.5. 
6. Prove Theorem 5-1.6. 
7. (a) Show that al A11k = F1ka is a consequence of (5-1.20a). 
(b) Do the same for the right-hand member of (5-1.21). 
(c) Show that IA11kl = an-1• 
8. Use (5-1.21) to establish Kramer's rule for solving simultaneous linear 
equations; that is, show that the solution of the system of p equations in 
p unknowns, 
al Xi 
= bk, 
a .,t:. 0, 
is 
9. Prove Theorem 5-1.7. 
. 
bkAki 
X'=
-­
a 
10. Prove that the determinant of a skew symmetric system A;k is zero whenever 
its order is odd. 
11. If the system A;k satisfies the relation exA1k + {JAki = 0, prove that either 
ex = -{J and A1k is symmetric or ex = {J and An, is skew symmetric. 
12. Put the Maxwell equations (referred to rectangular Cartesian coordinates) 
1 oB 
(a) V x E = - at , 
(b) V • D = 4'rp, 
1 an 
4'r 
(c) V x H = - - + - j, 
(d) V • B = 0, 
c at 
c 
in component form. 
Answer: 
1 oB1 
(a) Eiik a Bk = -
-
-
' 
c at ' 
.. k 
1 oDi 
4'r . 
(c) E" 
o1Hk = -
- + -p, 
c at 
c 
13. Make the identifications 
µ, £, a constants; 
then show that both the systems Hi and Ei satisfy the wave equations 
µ£ o2E11 
4'rµa 0E11 
2aq a[11EqJ + c2 at2 + 7 Tt 
= o, 
µ£ o2H11 
4'rµa oH11 
2()Q a[11HqJ + c2 7 + 7 Tt = o. 

Transformations and tensors 315 
2. Transformations and Tensors 
The major objective of tensor analysis is to determine algebraic repre­
sentations for physical or geometric relations in a form independent of 
coordinate system, that is, we look for the algebraic and geometric in­
variants of a given transformation group. 
We suppose that a set of coordinates X1 • 
• 
• X" can be introduced into 
the given n-space and that other coordinate systems are introduced by 
means of functions 
(5-2.la) 
with unique inverses 
(5-2.lb) 
The allowable transformations, in other words, are introduced by Defini­
tion 3-4.l. 
(The term triple must be replaced by n-tuple.) 
Since this 
definition guarantees the continuity of the partial derivatives oX'/oXk, 
oXk/oX1, the transformations (5-2.Ia,b) give rise to the sets of linear 
transformations 
(5-2.2) 
ax1 
= axi a xk 
axk 
· 
These linear transformations relating the differentials dXi, dX1 form a 
group derived from the general group. This derived group lies at the 
foundation of tensor analysis. In particular, the laws of tensor transforma­
tion are expressed in terms of the coefficients of the linear transformations. 
We suppose that the physical or geometric entities under discussion can 
be represented by a set of one or more functions in every allowable 
coordinate system. Such an entity is called a tensor if its coordinate 
representations satisfy the following definition. 
Definition 5-2.1. 
The class {Tf.1::.j!0} is said to be a tensor of contra­
variant valence q and covariant valence p with respect to the allowable 
transformation group if and only if the elements satisfy the transformation 
law, 
(5-2.3) 
The elements, Tf.1.'.'.j!0, representing the tensor in a particular coordinate 
system, are called the components of the tensor with respect to that system. 
The tensor is said to be of order p + q. 
It is convenient to identify the physical or geometric entity or concept 
represented by the class {7j1:. '. i!0} with the class and refer to it as a tensor. 

316 
TENSOR ALGEBRA AND ANALYSIS 
As long as the distinction between the algebraic class and the physical 
or geometric object is understood, the aforementioned identification is 
valuable in that it enables us to express thoughts concisely. 
It should be clearly noted that in general the components ·:::1a are 
functions of the space coordinates X1• 
Definition 5-2.2a. 
A tensor of contravariant valence 1 and covariant 
valence zero is said to be a contravariant vector with respect to the allow­
able transformation group. According to (5-2.3), the transformation law 
for the components of a contravariant vector is 
(5-2.4a) 
A'= oX1 A,., 
ox" 
· 
Definition 5-2.2b. 
A tensor of covariant valence 1 and contravariant 
valence zero is said to be a covariant vector with respect to the allowable 
transformation group. According to (5-2.3), the transformation law for 
the components of a covariant vector is 
(5-2.4b) 
Definition 5-2.2c. 
A tensor of order zero is said to be a scalar with 
respect to the allowable transformation group. According to (5-2.3), the 
transformation law for scalar representatives is 
(5-2.4c) 
Example 5-2.1. 
Contravariant and covariant vectors have rather 
familiar prototypes. In Euclidean three-space a space curve is represented 
by parametric equations 
X; = Xi(t) 
with continuous first derivatives that do not simultaneously vanish. Let 
us extend this representation of space curve to an arbitrary n-space. 
Then, with respect to a coordinate transformation, 
we have 
(5-2.5a) 
dx1 
ox1 dX" 
dt= oX"dt; 
that is, the class {dX1/dt} is a contravariant vector. Its geometric cor­
respondence is defined as a tangent field, and a possible physical analogue 
is a velocity field. 

Transformations and tensors 
317 
Next consider a scalar function <I>. Then 
(5-2.Sb) 
0<1> 
o xk 0<1> 
ox;
= 
ox; oxk · 
Hence the class of gradients of a function <I> is a covariant vector. In 
structuring an n-dimensional geometry, we use the three-space analogy and 
visualize the class {o<l>/oX1} as the normal field to a surface.3 
<l>(X1) = 0. 
The covariant and contravariant vectors (5-2.5a,b) give rise to a scalar. 
The preceding fact is algebraically determined by the computation 
0<1> dx; = (oxk 0<1> ) (ox; dxp) = J k 0<1> dxp = oii> dxk 
ox; dt 
ox; oxk 
oxP dt 
p oxk dt 
oxk dt 
Example 5-2.2. 
An endless quest of science in investigating the world 
around us is the determination of universal laws. Newton's resolution of 
his laws of motion was an outstanding achievement in this direction. The 
second of his three laws states that the change of momentum of an object 
is proportional to the applied force. The symbolic formulation of the law is 
(5-2.6) 
pi= dmV; 
dt 
' 
where the measure of mass m is considered to be a constant. Associated 
with the Newtonian laws is a principle of relativity of motion which implies 
that if the formulation (5-2.6) is valid with respect to a given frame of 
reference then it is valid in any frame in uniform rectilinear motion with 
respect to the original. We verify this by subjecting (5-2.6) to transforma­
tions relating rectangular Cartesian systems of the form 
(5-2.7a) 
The ak; and bi are constants. It is assumed that F1 is a contravariant vector 
and 
We have 
V; = dX;
. 
dt 
3 In n-space there is the question whether a surface should be defined in terms of two 
or n - 1 independent parameters. Either generalization from three-space is ,possible; 
n - 1 parameters, hence the form <I> = 0, wins out, since the set of points satisfying the 
relation divides the space into two sets, those points for which <I> > 0 and those for 
which <I> < 0. In order to distinguish n > 3 from n = 3, the term hypersurface is often 
employed. 

318 
TENSOR ALGEBRA AND ANALYSIS 
Consequently, 
(5-2.7b) 
dV; 
; 
dfi"k 
-=ak -. 
dt 
dt 
By using this result and noting that oXi/()Xk = aki• we have 
0 = F; - m dV; = o0; (Fk - m dflk) · 
dt 
axk 
dt 
By multiplying and summing the relation 
ax1 (Fk - m dVk) = 0 
a.xk 
dt 
with oXP/oX1, we obtain the result 
(5-2.7c) 
'8/( Fk - m d;k) = o. 
From this it immediately follows that the form (5-2.6) holds in the barred 
system. 
Example S-2.3. 
We have encountered other tensors than those already 
mentioned. For example, in Chapter 3, Section 4, the fundamental metric 
tensor with components 
(5-2.8a) 
s 
axi axi 
gik = ! ::i - . ::i -k 
i=l uX' uX 
was introduced. 
In this instance the X1 coordinates were rectangular 
Cartesian. If the n-dimensional space is euclidean, the fundamental metric 
tensor can be reintroduced by means of 5-2.8a. 
More generally, in the 
manner of Riemann, we can start with a fundamental metric tensor and 
develop the notions concerning the space from it. 
The class { 6/'} is a tensor with respect to an allowable transformation 
group since 
(5-2.8b) 
is an identity. 
The & systems &;;k and £iik are tensor components with respect to the 
orthogonal Cartesian group of transformations, but, as we saw in Chapter 
1, Section 5*, these components transform in terms of more general 
transformation groups with density factors of loX/oXI and loX/oXI, 
respectively. 
In order that they may be included in our theory, we make the following 
definition. 

Transformations and tensors 
319 
Definition 5-2.3. 
The class TJ1:::f,,,q is said to be a tensor density of 
contra variant valence q, covariant valence p, and weight r if and only if the 
elements satisfy the transformation law 
(5-2.9) rk1:: :kq = I oK lr oLk1 ... oMkq ox'.1 ... ox111 r•1:: ._.q. 
ii iv 
oX 0X'1 
ox•q 0X'1 
ox111 ti 
tv 
Theorem 5-2.1. 
The & systems defined according to Definition 5-1. 7 in 
each allowable coordinate system satisfy the transformation laws 
(5-2.10) 
I 
ox I 
0J(k1 
oJ(kn 
_ 
(a) 
&;l". in 
= 
ox oxi1 ... oxin &k1 . . .  kn• 
(b) £ii"·i1= 1 ox1 xii ... xin £k1···kn 
ox J(k1 
J(kn 
• 
hence are components of tensors of weight + 1 and -1, respectively. 
The proof of this theorem is a consequence of the fact that (5-2.lOa,b) 
are identities. 
Example 5-2.4. 
The classification of an entity depends on the underlying 
transformation group. 
This is clearly pointed out by considering the 
components 
-
or 
or 
gik 
= 
oxi. oXk 
in a Euclidean space. With respect to rectangular Cartesian transforma­
tions, each component is a scalar. Hence we have a set of scalars. With 
respect to more general transformations, the gik are interpreted as com­
ponents of a tensor of covariant valence 2. 
The algebra of tensors is based on the algebra of systems, as introduced 
in Section 1. 
The present objective is to formalize the fact that such 
operations with tensors result in tensors. It is understood that the terms 
addition or JDUltiplication applied to tensors is simply shorthand for addi­
tion or multiplication of their components in each coordinate system. 
Theorem 5-2.2a (Addition). 
The sum of two tensors of the same kind 
(i.e., with common contravariant valences and common covariant valences) 
is a tensor of the original kind. 
Theorem 5-2.2b (Outer product). 
The outer product of a tensor of 
covariant valence p and contravariant valence q with a tensor of covariant 
and contravariant valences r and s, respectively, is a tensor of valences 
p +rand q + s, respectively. 
Theorem 5-2.2c (Contraction). 
Given a tensor with component rep­
resentation 1jN1:.: ·iOq, if any contravariant index is set equal to a covariant 

320 
TENSOR ALGEBRA AND ANALYSIS 
index, thereby implying a sum, the resulting entity is a tensor of one less 
contravariant valence and one less covariant valence. 
The proof of Theorem 5-2.2c follows. Proofs of the other two theorems 
are similar and are left to the reader. 
In order to prove Theorem 5-2.2c, it must be shown that the contracted 
systems satisfy the transformation law (5-2.3). We have 
T[····kq_,1 = (()Xk' ... oXkq-• oX1) (oX"' ... ox•v-•()X"v) tr,···rq 
'1···1:i>-1t 
axr• 
OX'a-10X'q 
ax;1 
ax;'J-1 axt 
si···sv 
Since the components satisfy the appropriate transformation law, the 
theorem is proved. 
Other tensor properties of importance are expressed by the following 
theorems. 
Theorem 5-2.3a. 
If the components Ti• · · · iv · · · ;. · 
· 
· ir of a tensor in some 
d. 
1 
1 {symmetric 
. 
. 
. 
th 
one coor mate system are comp ete y 
k 
· 
t . 
m }J • • • )q, 
en 
s ew symme nc 
. 
. 
{symmetric 
the components m every coordinate system are completely 
k 
t . 
s ew symme nc 
in the corresponding indices. 
A corresponding statement holds for 
covariant components. 
PROOF. 
Suppose the components are symmetric in jv · · 
· jq (1   p < 
q   r). Then 
'.:I -k 
'.:I -k 
'.:I -k 
'.:I -k, 
Tk 
.
•
•
 k ... k ... k 
U X 1 
U X V 
U X q 
U X 
T i' .. . ;M ... iq · · · ir 
1 
i> 
a 
r=--· ·· -- · · · -- ··· --
y 
. 
ax1, 
axiv 
axia 
ax1, 
Let kv, 
· 
· · kq, be an arbitrary permutation of kv 
· · · kq. Then 
'.:I -k 
'.:I -k 
'.:I -k 
'.:I -k 
Tk,···kM ···k ···k 
uX ' 
uX v, 
uX q, 
uX ' r1,··· iM ···ia ···ir 
..,1 
'11 
r=-- ···--···--···--
..,1 
1 
·• 
()Xh 
ax1v, 
ax1a, 
ax1, 
The 
partial 
derivatives oxkv,/()Xiv, · 
· · ()Xkq•/oX1q• are commutative 
and can be put in the order kv 
· · · kq. 
Furthermore, the components 
Ti•·
· · iv,··· iq, 
· · · ir by hypothesis are completely symmetric in jp, · · · ja,• 
hence can be replaced by Tii ···iv··· iq · · 
· i,, Therefore the right-hand sides 
of the foregoing expressions are equal and the equality of the left-hand 
sides follows. The proof concerning skew symmetry is carried out in the 
same manner. 

Transformations and tensors 
321 
Theorem 5-2.3b. 
If all components of a tensor are zero in some one 
coordinate system, they are zero in every allowable coordinate system. 
PROOF. 
Suppose that 
Then 
Now we can multiply and sum with the successive sets of partial derivatives 
and arrive at the desired conclusion. 
The preceding theorem plays an important part in determining physical 
laws of an invariant character. The invariance of the Newtonian second 
law illustrated in Example 5-2.2 is a classical instance of its use. 
Suppose the sum of products of tensor components A;k; and B1k is 
formed in each allowable coordinate system. Theorems (5-2.2b,c) assure 
us that the resultant 
comprises tensor components. But what of the converse process? This 
question concerning division is answered in part by the following theorem. 
Theorem 5-2.4. (Quotient law of tensors). 
Suppose that systems of the 
form A(	i 
·.'. '.if) are defined in each allowable coordinate system. 
Let 
Bfi1.'.'.j!q.'.'.J!• be components of an arbitrary tensor. If 
(5-2.11) 
where the cf::{ .'.'t• are tensor components, then the systems A(	i '. '. ·Jfq) 
determine a tensor of covariant valence q and contravariant valence p. 
PROOF. 
In order to reduce the complexity of the notation, an example 
exhibiting the method of proof rather than the general proof is presented. 
Consider the systems Ac) , the arbitrary tensor components B1k, and 
the contravariant vector components Ci. If (5-2.11) holds, we can write 
o =A( _i ) Bik - ci =a+; a,k A( .i )B'J)q 
- a-' c•. 
1k 
ax'J axq 
1k 
ax• 
Since (5-2.11) holds in each coordinate system, C'P can be replaced by 
making use of the relation 

322 
TENSOR ALGEBRA AND ANALYSIS 
Then 
= [()Xi oXk A( i ) _ oX1 x( s )]Bw 
ax'J axq 
ik 
ax· 
pq 
Since the tensor {BM} is arbitrary, we can impose various sets of values on 
the barred system components. For example, 
1 
0 
0 
0 
0 
0 
0 
0 
0 
By making n2 such choices, we exhibit the fact that the parenthetic com­
ponents must be zero; that is, 
(5-2.12a) 
-- A 
--A 
= 0 
ax1 axk ( i) axi ( s ) 
ax'JJ axq 
ik 
ox• 
pq 
· 
Upon multiplication by oX1/()Xi, 
(5-2.12b) 
Therefore the systems Ac#), etc., are elements of a tensor. 
Example 5-2.5. 
A certain caution must be used in the employment of 
Theorem 5-2.4. Suppose that AikWiWk 
= <I> 
held in each coordinate system in which Wi are components of an arbitrary 
contravariant vector and <I> is a scalar representative. By transforming 
the vector components and replacing <I> 
= ii> by its barred system repre­
sentation, we have 
or 
(5-2.13a) 

Transformations and tensors 
323 
In this example the tensor with components 
Bpq = wpwq 
is not completely arbitrary. It has the property of symmetry in p and q. 
If, for example, we choose B12 = I, then B21 = I also. If all other JjPq = 0, 
the expression (5-2.13a) becomes 
( 
ax1 axk 
) ( 
ax1 axk 
) 
(5-2.Bb) 
A;k axi a.xz - .A12 
+ Ask ax2 axi - A21 
= o. 
By interchanging dummy indices in the second term, we can put (5-2.13b) 
in the form 
(5-2.13c) 
oX1 ()Xk 
(Aik + Ak;) a.x1 a.x2 - (A12 + A11) 
= 0. 
The procedure indicated in (5-2.13a,b,c) can be carried out with each pair 
of indices. The consequence of this development is that it cannot be con­
cluded that the systems A;k determine a tensor unless they are symmetric 
inj, k. However, the symmetric systems A;k +Aki do determine a tensor. 
Problems 
1. Show that 5-2.4a and 5-2.4b imply 
(a) The components of a covariant vector satisfy the relations 
_ 
axk 
A;= aXi Ak. 
(b) The components of a contravariant vector satisfy 
ax1 
Ai =-Ak 
axk 
· 
2. Prove Theorems 5-2.2a,b. 
3. Prove that if the contravariant components of a tensor are completely skew 
symmetric in one system they are so in every coordinate system. 
4. Suppose the coordinates Xi are rectangular Cartesian coordinates in an 
n-dimensional Euclidean space. 
(a) What geometric configuration is represented by <I> = A1Xi = constant 
if n = 2, n 
= 3, n > 3? 
(b) What does the set a<1>/aXi represent geometrically in each case of (a)? 
5. Systems A(pqrs) are defined in each allowable coordinate system. Their rule 
of transformation is 
axp axb axe axc1 
A(p, q, r, s) = aXa axq axr ax• A(a, b, c, d). 
Is the class A(p, q, r, s) a tensor? If so, determine the covariant and 
contravariant valences. 

324 
TENSOR ALGEBRA AND ANALYSIS 
6. Suppose AjkBik = cl>, where Bik are components of an arbitrary skew sym­
metric tensor and cl> is a scalar of weight 0. Show that AJk - Ak; are 
tensor components. 
7. Show that the set oiAk of partial derivatives of contravariant vector com­
ponents Ak are not tensor components in general. Under what circum­
stance are they tensor components? 
8. In vacuo, and with the velocity oflight c = 1, the Maxwell equations have the 
form 
oE3 
oE2 
oH1 
oX2 - oX3 + Tt = o, 
oE1 
oE3 
oH2 
oX3 - oX1 + Tt = 0• 
oE3 
oE1 
oH3 
oX1 - oX2 + Tt = 0• 
oH1 
oH2 
oH3 
oX1 + oX2 + oX3 = o
, 
oH3 
oH2 
oE1 
oX2 - oxa - °"i = PoV1, 
oH1 
oH3 
oE2 
oxa - oxi - at =Pov
•
, 
oH2 
oH1 
oE3 
ax1 - ax2 -Tt 
= Pova. 
oE1 
oE2 
oE3 
oX1 + oX2 + oX3 
= Po· 
(These equations result from those in Chapter 5, Section l, Problem 12, 
by puttingµ = i: = c = l, u = 1, j = (1/4rr)V, and p = (1/4rr)p0• 
Make the identifications 
£1 = F'1, 
H1 = £23, 
E3 = F'3, 
Ha= p12. 
and show that with respect to the metric 
0 
0 
(- - 
(ga.p) = 
0 
0 
-1 
0 
0 
the equations can be put in the form 
a1,FpyJ= o, 
3. Riemannian Geometry 
0 ) 
Definition 5-3.la. 
An n-space endowed with a covariant tensor g;t of 
second order, which is symmetric, is said to be a Riemannian space. 
The geometry of the space is said to be Riemannian. 
Definition 5-3.lb. 
A quadratic differential form 
(5-3.1) 
ds2 = g;t dX1 dXt 
can be associated with the tensor g;t· It is called the fundamental metric 
form of the space and g1k is said to be the fundamental metric tensor. 

Riemannian geometry 
325 
We first met with the concept ofa metric tensor in Chapter 1, Section 5*, 
again in Chapter 3, Section 4, and then in Chapter 4, Section 2. In a 
Euclidean space it is possible to introduce rectangular Cartesian coordinate 
systems in which the metric tensor has the form 
(5-3.2a) 
g;k = b;k 
and in which the form (5-3.1) reduces to 
n 
(5-3.2b) 
ds2 
= b;k dX1 dXk 
= _! (dX1)2• 
;-1 
If Cartesian coordinates other than rectangular are used, g;k :;I:. {J1k, but 
the components are still constant. 
Finally, if generalized coordinates, 
such as three-space spherical coordinates, are introduced, the g;k become 
functions of position. 
In Euclidean three-space the g1k enable us to express length, angle, 
and volume in forms independent of coordinate systems. In considering 
surface representations, we saw, at least in part, that the ge<fl were funda­
mental to the intrinsic determination of length, angle, and area on the 
surface. 
With the introduction of generalized coordinates, we could clearly 
perceive the dependence of the metric tensor on the space coordinates. 
Surface representation illustrated the use of the ga.13 in an essentially 
non-Euclidean situation. This is the background on which Riemannian 
geometry was developed. 
Riemann, a pupil of Gauss, was well aware of Gauss's important and 
fundamental contributions to the development of the intrinsic geometry 
of surfaces. The use of parametric curve nets on the surface in analogy to 
coordinate nets in the plane not only served Gauss's immediate purposes 
but it also established a firm basis for generalization of his ideas to n-space. 
The task of generalization was undertaken by Riemann. 
His resulting 
theory, as we would expect, included the motivating three-space Euclidean 
analytic geometry and the intrinsic geometry of surfaces. 
But it went 
further. It tied together the theory of non-Euclidean geometries and it set 
a foundation for the development of the general theory of relativity. In 
fact, Riemannian geometry has played an important role in the construc­
tion of modern physical theories in general. 
In his original paper, "On the Hypotheses which Lie at the Foundation 
of Geometry," Riemann assumed that the fundamental quadratic form 
g;k dX; dXk was positive definite (i.e., g1k dX1 dXk > 0). This assumption 
guaranteed that ds =  g1k dX1 dXk was real. We have not included this 
assumption in Definition 5-3.1, since indefinite forms such as 
dsz = -(dX1)2 _ (dX2)2 _ (dXs)2 + (dX')2 

326 
TENSOR ALGEBRA AND ANALYSIS 
are quite essential in relativity theory and other aspects of geometry and 
physics. Because of this relaxation of the conditions on g<lfJ, we shall have 
to make judicious use of absolute value signs. 
It must be clearly understood that the {g"'p} is assumed given and that 
the geometric structure of a Riemannian space is built up around it by 
definitions that are based on surface or three-space analogies. 
The development of the analytic geometry of a Riemannian space is 
expedited by the introduction of an associated metric tensor {g;k}. It is 
assumed that 
(5-3.3) 
Definition 5-3.2. 
(5-3.4) 
Jg,kl =F 0. 
In each allowable coordinate system 
ik 
cofactor of gk; in lg1kl 
g 
= 
. 
Jg;kl 
According to (5-3.4), the components gik satisfy the properties (these 
properties result frotn determinant expansion by row and by column) 
(5-3.5a) 
(5-3.5b) 
g,kgkp = t>/, 
gkigpk 
= t>/, 
where the inner index represents row and the outer index represents 
column. 
Theorem 5-3.1. 
The system g1k is symmetric; that is, 
(5-3.6a) 
PROOF. 
By multiplying and summing each side of (5-3.5a) with g1q, 
we have 
(5-3.6b) 
According to Definition 5-3.la, g;k is symmetric. If we use this fact and 
then employ (5-3.5a) on the parenthetic factors of (5-3.6b) we are led to 
the expression 
Application of the Kronecker deltas produces the result 
(5-3.6c) 
This completes the proof. 
Theorem 5-3.2. 
The class of systems {tk} is a second-order tensor of 
contravariant valence 2. 

Riemannian geometry 
327 
PROOF. 
We make use of the fact that the class of systems {Cl/} is a 
tensor. (See Example (5-2.3.) We have 
g,kgkp 
= Cl/. 
Since g1k and Cl/ are tensor components, 
oX" axr 
ax'P axr 
(5-3.7a) 
oX' oXk g11rgk'P = oX" oX' b/. 
After multiplication by oX1/oX8, the relation (5-3.7a) has the form 
(5-3.7b) 
oXr -
kp 
= (}XP (J" 
oXk g,rg 
oX" 
• .  
Application of gst results in 
(5-3.7c) 
axt kp -
-qt ax'P 
axkg 
- g ax" · 
When this expression is summed with iJXbjoX1, the following appropriate 
law of transformation is obtained. 
(5-3.7d) 
bp 
axb ax'P -tq 
g 
= axt ax11 g 
· 
This completes the proof. 
Definition 5-3.3. {g1k} is called the conjugate or associated metric tensor. 
The metric tensor and its conjugates play an algebraic role denoted by 
the terms "lowering of indices" and "raising of indices."" For example, 
if Ti1 are the components of a given tensor, then 
Note that the same kernel letter Tis used in each instance. This notational 
device emphaiizes the fact that, although the tensors {Ti1}, {Ti1}, {T/}, 
{Ti1} are distinct from the algebraic point of view, each represents the same 
geometric or physical entity. This sort of situation was illustrated in 
Chapter 3, Section 9, where W1 and Wk = gk; W1 were components of the 
same Cartesian vector, although referred to reciprocal bases.5 We find it 
convenient to speak of a vector in a Riemannian space and to represent 
the vector by means of either covariant or contravariant components. 
The associated metric tensors and the processes of raising and lowering 
'See Chapter 1, Section s•. 
•If a space is not metric, that is, if no tensor g;k is given, these remarks do not apply. 
For example, in a space in which only incidence relations are considered W1, Wi have 
distinct geometric interpretations. 

328 
TENSOR ALGEBRA AND ANALYSIS 
indices endow tensor algebra with a duality that has both beauty and 
utility. 
How should the concepts of magnitude and angle be introduced? 
In other words, what demands should be met? We make two require­
ments. 
I. The definitions introduced in the Riemannian space should reduce 
to the usual ones of solid analytic geometry if the space is taken as 
Euclidean. 
2. Definitions must satisfy an invariance property; that is, the tensor 
form should not depend on coordinate system. 
Magnitude and angle are introduced as follows. 
Definition S-3.4. 
Let W; be the components of a vector. The magnitude 
ofW is 
(5-3.8) 
Definition 5-3.5. 
Let V; and Wk be contravariant components of a pair 
of vectors. 
The angle 0 made by the two vectors satisfies the relation 
(5-3.9) 
cos 0 -
g;kV;Wk 
- (I gab vavbl)li(lgf)q wvwql))i . 
Euclidean space is classified by the following definition. 
Definition S-3.6. 
A Riemannian space is isometric to an Euclidean space 
if and only if there is an allowable coordinate system such that 
(5-3.10) 
gjk = 8jk * 
throughout the space. 
It is easily seen that (5-3.8) and (5-3.9) reduce to the usual formulas 
of analytic geometry when the space is Euclidean. The invariance of each 
relation is likewise quickly deduced. 
The concept of orthogonality is abstracted directly from the Euclidean 
form. 
Definition S-3.7a. 
Two vectors with contravariant components y; and 
Wk are said to be orthogonal if and only if 
(5-3.11) 
g,kv;wk = o. 
Example S-3.1. 
If 
g;k = ;k> 
then (5-3.11) reduces to 
(5-3.12a) 
j, k = l, 2, 3, 
• Two spaces are isometric if measurements of corresponding distances and 
angles are the same in them. For example a circular cylinder is isometric to a portion 
of a plane. See any text on differential geometry for more detail. 

Riemanian geometry 
329 
This is the usual expression from solid analytic geometry. On the other 
hand, suppose 
(5-3.12b) 
(g;k) = (- )· 
Then the orthogonality condition reduces to 
(5-3.12c) 
- viw1 + v2w2 = o. 
Definition 5-3.7b. 
V is a unit vector if and only if 
(5-3.13) 
Example 5-3.2. 
If g1k is a positive definite metric tensor, that is, if 
(5-3.12a) 
for all real sets of components U1 and the equality holds if and only if 
U1 = 0 for each j, then 
(5-3.14b) 
lcos 01 * 1. 
The assertion of the example may be proved by starting with the expression 
(5-3.15a) 
g1k(ocV1 + {JW1)(ocVk + fJWk) ) 0, 
where oc and p are arbitrary parameters not both zero and V and W are 
unit vectors. By multiplying out this expression we obtain 
Let 
Then 
(5-3.15b) 
oc2 + 2(g;k Vi Wk)oc{J + /J2 ) 0. 
oc 
A.=-' 
p 
p ""'0. 
A.2 + 2 cos 0). + 1 ) 0. 
If the inequality holds, the polynomial 
P().) = ).2 + 2 cos 0). + 1 
has no zeros; hence the discriminant of the right-hand side is negative; 
that is 
cos2 0 - 1 < 0. 
Therefore 
!cos 01 < 1. 
If the equality holds in (5-3.15a,b), then, according to the definition of 
a positive definite metric, 
ocV1 + {JW1 = 0. 

330 
TENSOR ALGEBRA AND ANALYSIS 
Consequently, by solving for W; and substituting into (5-3.9), we have 
and 
cos() 
-
gyµVY(A.P) 
-  
- (lg .. , V"V,l)J,.J(A.2 lgqd VqV6l)J.1 - IA.I 
lcos 01 = I. 
Combination of this fact with the preceding result produces the relation 
(5-3.14b). 
Problems 
1. Show that the transformation relating the fundamental metric forms 
(dX1)2 + (dX2)2, 
-(dX1)2 + (dX'2 
is not real. Henceg;1c does not reduce to fi;1c in a space which admits the 
right-hand metric. 
2. Compute the components of the fundamental metric tensor and the conjugate 
metric tensor associated with each of the following surfaces: 
(a) A sphere related to rectangular Cartesian coordinates by means of 
of the transformation equations 
X1 = r sin v1 cos v2, X2 = r sin v1 sin v2, X3 = r cos v1, 
where r is a constant. 
(b) A cylinder related to a rectangular Cartesian system by means of 
X1 = p cos v1, 
X2 = p sin v1, 
X3 = v2, 
where p is a constant. 
3. Suppose that a Riemannian n-space is referred to the coordinates X1 · 
· 
• xn. 
The equations 
X1 = constant. 
x;-i = constant. 
Xi 
= t 
Xi+l = constant. 
xn = constant. 
represent a coordinate curve. Show that the angle 0;1c made by the coor­
dinate curves, along which X; and x1c vary, respectively, is given by 
g;1c 
cos 0;1c = 
(I 
j)W 
g;;g1c1c 

Tensor processes of differentiation 
331 
4. Prove that if the Riemannian space is referred to an orthogonal coordinate 
system 
1 
g"'"'=-. 
g,,,, 
4. Tensor Processes of Differentiation 
In considering the processes of differentiation in a Riemannian space, 
the concept of invariance should be kept in the foreground. The general 
form of a geometric or physical law is independent of coordinate system 
when expressed entirely in terms of tensors. This, of course, is one of the 
principal values of the tensor representation. We must ask the following 
question: do the processes of differentiation and partial differentiation 
transform a tensor into a tensor? In general, the answer is no. Therefore 
what processes should take the place of partial and ordinary differentia­
tion? Historically, a foundation for answering the question was deter­
mined by Elwin Bruno Christoffel, Rudolf Lipschitz, and Eugenio 
Beltrami. Christoffel and Lipschitz wrote papers on quadratic differential 
forms in 1870; Beltrami expounded a theory of differential operators in 
the decade preceding that date. 
The contributions to invariant theory 
made by these men were fully developed by Gregorio Ricci Curbastro 
in his absolute differential calculus of 1884. In particular, it was Ricci 
who introduced the name covariant differentiation. 
This term, which 
signifies a kind of partial differentiation that produces from a tensor a 
tensor of covariant valence one more, is the main topic of this section. 
In order to gather information that will form a basis for answering the 
foregoing question, we start out on familiar ground. Let Vi(X;) be a vector 
field defined on a region of Euclidean space. Suppose that the coordinates 
X; are rectangular Cartesian and that the vector field had continuous 
partial derivatives of at least second order. If 
is an allowable coordinate transformation, then 
(5-4.la) 
and 
(5-4.lb) 
v; =ox; p1c 
ox1c 
It is the relation (5-4.lb) that commands our attention; oV;/oXP transform 
as tensor components of covariant and contravariant valence l each if and 

332 
TENSOR ALGEBRA AND ANALYSIS 
only if the first term of the right-hand member is zero. Because the vector 
field V is arbitrary, this is equivalent to 
a2x1 
(5-4.lc) 
= 0 
ax11 axk 
or, in other words, to the allowable transformation group being linear. 
In any other circumstance we must look for a tensor quantity to replace 
the set of partial derivatives. 
Simply by replacing o2X1/0X11 oXk with fJ/ (o2X1/oX0 oX1) and then 
substituting a product of partials for fJ/, we can put (5-4.lb) in the form 
av1 
ax11 ax1 (axk 
o2X1 
ark) 
(5-4·2) 
oX"' = oX"' oXk oX1 0X110X ' 
P-• + oX" . 
Two facts are of value in examining (5-4.2). First of all, there is an asym­
metry about (5-4.2) in that the parenthetic expression on the right contains 
the term involving second partials. However, we can expect something of 
this sort, for if the transformation group were the linear orthogonal 
Cartesian group the second partials would be zero and (5-4.2) would 
represent the appropriate law of transformation. Second, if we consider a 
second transformation 
X1 = X1(Xk) 
and then eliminate the Cartesian components from the expressions of the 
form (5-4.2), 
(5-4.3a) 
0X11 oX1 (oXk 
o2Xt 
of'"k) 
oX11 oX1 
oX"' oXk oX1 0X11 ox• p• + oX0 
= 
oX"' oXk 
(axk 
a2x1 
-
avk) 
x ax1 a x11ax· v· + ax11 
• 
By multiplying by (oX"'/oXa)(iJXbfoX'), we obtain 
(5-4.3b) 
(axb a2x1 
arb) 
a x"aXb (axk a2x1 
-
avk) 
--
r·+--
=
----
--
v· +--
ax1 axa ax• 
axa 
axa axk ax1 ax11 ax• 
ax11 
• 
The parenthetic expressions are of the same form and are related in tensor 
fashion. Therefore in a Euclidean space in whieh rectangular Cartesian 
coordinate systems are available we could replace partial derivatives by 
the parenthetic expressions. However, we want more generality; hence 
we must go a step farther. 
Following Christoffel, we look for a way of replacing the expressions 
(oXbfoX1)(o2X1/oXa oX') (which still contain references to rectangular 

Tensor proceses of differentiation 
333 
Cartesian coordinates) by quantities involving the components of the 
metric tensor. 
Theorem 5-4.1. 
If the X; coordinate system is rectangular Cartesian 
and X; = Xi(.Kk) is an allowable transformation, then 
(5-4.4a) 
axb 22xt
_ = ! -bc(og;. + ag__ca - ag_."') . 
axt ax" ox' 
2 g 
ax" 
ox• 
ax• 
PROOF. 
We have 
(5-4.4b) 
g
-
- ax110 Xq b 
•• - ox• ax· pq· 
If for notational convenience we let a" = o/oX", then 
(5 4 4c) 
0 g-
= 
a2xp oXq b 
+ oX11 o2Xq 
b 
- . 
a SC 
axa ox• axe 
1JQ 
ax· axa axe 
1JQ' 
Simply by permuting indices we obtain two additional expressions of the 
same type, that is, 
o2X11 oXq 
oX11 o2Xq 
(5 4 4d) 
a g-
= 
- b 
+ -
b 
-
• 
' ea 
ax• ox• oX" 
1JQ 
ox• ax• oX" 
1JQ• 
(5-4.4e) 
o2X11 
xa 
oX11 o2Xq 
o-
= 
-b 
+ -
b 
.gas 
oX0 oX" ax• 
1JQ 
oX" oX" ox• 
1JQ' 
Now we form the parenthetic expression on the right-hand side of (5-4.4a) 
from (5-4.4c,d,e), thereby obtaining 
o2X11 
axa 
(5-4.5a) 
(oagsc + o,gca - o.ga,) = 2 oX" ox• oX" b11a· 
Since 
(5-4.5b) 
-be - axb ax· 15rt 
g 
-
ax' axt 
' 
we can apply the members of this relation to the corresponding members of 
(5-4.5a), thereby obtaining the desired result. This completes the proof. 
Definition 5-4.1. 
(5-4.6) 
With respect to each allowable coordinate system, let 
r.k= .!.gka(og;3 + ogq, _ og;;) · 
•i 
2 
ox• 
oX1 
axa 
The r, which are functions of the g's and their partial derivatives, are 
called Christoffel symbols.6 
6 The r ; are usually referred to as Christotfel symbols of the second kind. The 
quantities gk:Prf; are designated as Christotfel symbols of the first kind. The mathe­
matical forms were introduced into the mathematical literature in a paper by Christotfel 
and Lipschitz in 1870. 

334 
TENSOR ALGEBRA AND ANALYSIS 
With the introduction of the Christoffel symbols, (5-4.3b) can be written 
(5-4.7) 
(()b + r bJ78) 
= aq ()b (av + f k v·). 
axa 
Ba 
axa ox a xq 
sq 
The parenthetic expressions transform as tensor components, reduce to 
partial derivatives in a Cartesian coordinate system, 7 and are intrinsically 
defined (i.e., reference to a third coordinate system as in (5-4.3c) is not 
involved). They are certainly prime candidates as a choice of the generali­
zation of the partial derivative concept. For a Euclidean space we can 
immediately accept them as such. For non-Euclidean spaces some more 
work is necessary. The relations (5-4.3b) and (5-4.7) were obtained by 
making use of an intermediate rectangular Cartesian system. In order to 
verify that relation (5-4.7) is valid when a Cartesian system is not available, 
we must know the law of transformation of the Christoffel symbols. 
Indeed, this is an interesting question in itself, for we might be in doubt 
concerning their tonsor character. 
Theorem 5-4.2. 
The Christoffel symbols satisfy the transformation law 
(5-4.8) 
The proof, which is left to the reader, can be carried out in the same 
fashion as the proof of Theorem 5-4.1. Note that the Christoffel symbols 
are not tensor components. 
With the rule of transformation of Christoffel symbols established, the 
introduction of the partial derivative concept into Riemannian spaces 
follows. 
Definition 5-4.2a. 
In each allowable coordinate system let 
(5-4.9a) 
v.vk = avk 
+ r kp' 
' 
oX; 
1!1 
• 
The set of components V 1 Vk is referred to as the covariant derivative of the 
contravariant vector components Vk. 
Theorem 5-4.3a. 
The class {V1Vk} of covariant derivatives of contra­
variant vector components is a tensor of contravariant valence 1 and of 
covariant valence I. 
7 The Christoffel symbols are all zero in a Cartesian system since the components of 
the metric tensor are constants. See Definition 5-4.6. 

Tensor processes of differentiation 
335 
PROOF. 
We have 
v vk = ovk + r _kp' 
i 
oxi 
p, 
o 
(oXk 
) 
oXk (oX' oX' 
o2 xa ) oX11 -
=
ox; oXq 
ra + 
oXq 0X11 oXi 
r
,.
Q 
+ oX11 ox; oX1 
V' 
o2Xk 
oXa 
oXk orq oX1 
= 
oxa oxa ox; 
r(l + 
oX" oX1 ox; 
+---ra+ 
-r 
oxk (ox• ox• 
02 xq ) ox11 
t 
oXa OX11 oX1 rs 
oX11 oXi 
oX1 
• 
By taking a partial derivative with respect to Xq of the expression 
oXk oxa 
k 
--=15. 
oxa ox; 
'' 
we determine that the sum of those terms involving second derivatives 
is zero. Therefore 
V.Vk = oXk 0X1ora + oXk b,oX'r ayt 
' 
oxa oX1 oX1 
oX" t oX1 ,. 
= oXk ox• (ora + r apt) 
oxa oXi oX' 
ts 
= oWk oxX v r(l. 
oxq ox' 
• 
This completes the proof. 
The introduction of covariant differentiation might just as well have 
been made through consideration of a covariant vector. This procedure 
leads to the following consequences. 
Definition 5-4.2b. 
(5-4.9b) 
In each allowable coordinate system let 
'" v. 
ovk· 
r pv 
v i k = 
--; -
ki 
p• 
ox 
The sets of components V1Vk is referred to as the covariant derivative of 
the covariant vector components Vk. 
Theorem 5-4.3b. 
The class {V1 Vk} of covariant derivatives of covariant 
vector components is a tensor of covariant valence 2. 
The proof is made in the same manner as that of the preceding theorem. 
The covariant derivative of a scalar field <I> of weight W is defined as 
follows. 

336 
TENSOR ALGEBRA AND ANALYSIS 
Definition 5-4.lc. 
In each allowable coordinate system let 
v1<1> = a<1>. + wr,,t<I>, 
(5-4.9c) 
oX' 
where <I> is a scalar field satisfying the transformation rule 
(5-4.9d) 
<I> = I ; lw<i>. 
The set of components V1<1> is said to be the covariant derivative of the 
scalar field <I>. 
Theorem 5-4.3c. 
The class {V 1<1>} of covariant derivatives of scalar fields 
<I> of weight W is a tensor density of covariant valence 1 and of weight W. 
PROOF. 
In this proof we must make use of the fact that the partial 
derivative of a determinant, with respect to one of its elements, is the 
cofactor of that element. In particular, 
a 1ax;ax1 I ax I ax• 
<5•4.lOa) 
o(ax•;ax•) = ax ax• · 
(See Chapter 3, Section 5, also Theorem 5-1.7, page 313.) We have 
v1<1> = a<1>. + wr,,t<I> 
oX' 
=a 1ax;a.x1w axq <i> + I ax lw a<i> axq 
axq ax1 
ax axq ax1 
+ wl ax lw ax" (ax• ax· r q + a2xa )<i> 
oX oXq oX" oX1 " oX" oX1 
• 
The first term of the right member of this expression can be written in the 
form 
wl oX 1w-i o loX/oXI o(oX'/oX8) axa (j) 
ax o(oX'/OX8) axa ax1 
or, upon using (5-4.IOa), as 
( 
b) 
wl ax lw ax· a2xr axa (j) 
54·10 
ax ax· axa ax· ax1 
• 
By returning to our original expression, of which (5-4.lOb) is the first 
term, it can be shown that the terms involving second derivatives add up 
to zero. 
(Differentiate (oX'/oXg)(oXq/oXP) = 8p' with respect to Xi.) 
Therefore 
v <I>= I a@1w axq (aA + wr •<1>) = j a@1w axa v <i>. 
; 
oX oX' axa 
rq 
oX oX1 a 

Tensor processes of differentiation 
337 
This is the appropriate law of transformation. Hence the proof is com­
plete. 
Through Definitions 5-4.2a,b,c and Theorems 5-4.3a,b,c the covariant 
derivatives of contra variant vectors, covariant vectors, and scalar densities 
have been considered. These individual results indicate the form of a type 
of partial differentiation that preserves tensor character. 
In the next 
definition and theorem the preceding results are summarized and extended 
to tensors of any order. 
Definition 5-4.3. 
In each allowable coordinate system let 
(5-4.11) 
n Ti'·· ·iv =  yi1 ···iv+ ri•T'i• ···iv+ ... 
v k ;, ... ia 
axk 
,, ... 'a 
rk ii ... 'a 
+ riv Ti'·· ·ip-1• _ r. 'Ti'·· ·iv. 
_ 
.
.
•
 
rk 
i1 · · · 'a 
,,k 
ri2 · · · 'a 
_ r . 'Ti' · · ·iv 
+ W r• Tu' · · · ip 
3qk 
i1 · · · ia-1• 
rk '' · · · la' 
The set of compqnents V Tj:::: J; is said to be the covariant derivative of 
the tensor density components. 
Theorem 5-4.4. 
The class {V'kTj::::j;} of covariant derivatives of the 
tensor density components is a tensor of the same contravariant valence, 
the same density, and covariant valence one more than the original tensor. 
The proof can be accomplished by combining the ideas used in Theorems 
(5-4.3a,b,c). 
It is tedious but straightforward. 
(See Problem 6, also 
Section 8, Problem 4.) 
It is useful to be aware that the covariant derivative satisfies the following 
rules of elementary calculus. 
Theorem 5-4.S. 
We have 
(a) 
V.(A1, · · · ia + B;, · · · ia) = VA11 · · · ia + V.B;, ... ia 
• 
k1 · .. k:1 
k1 • .
. kv 
• kl . . • kv 
• ki · "kv' 
(5-4.12) 
(b) 
V.Ak····kqBm····m. = (V'Ak·00·ka)Bm,···m, 
• ii· '· iv 
Zi • · · lr 
• ii··· 'v 
!1 • · · lr 
+ Ak1 " ·vat"7.Bm1 · · · m, 
i1 · · · iv v • 
11 · · · lr 
' 
The rules are also valid under contractions. 
The proofs of properties (5-4.12a,b) are straightforward but long. They 
are omitted. (See Problem 8.) 
The process of covariant differentiation must be handled with care. 
For example, examination of Definition 5-4.2a brings forth the fact that 
covariant differentiation of a set of constant vector components Vk does 
not necessarily produce a zero result; rather 
V
1Vk = rv/vv. 
Conversely, if V'1Vk 
= 0, we cannot conclude that the components Vk 
are constants. 

338 
TENSOR ALGEBRA AND ANALYSIS 
Definition 5-4.4. 
A tensor {1j=i:::1>q} is said to be a covariant constant 
if and only if 
(5-4.13) 
 yk1···kq - 0 
v i i1 ... i1) -
• 
The fundamental covariant constants are pointed out by the following 
theorems. 
Theorem 5-4.6a (Ricci's lemma). 
The fundamental metric tensor is a 
covariant constant; that is, 
(5-4.14a) 
PROOF. 
We have (let O; = o/oXi) 
v igk1J 
= a igk1J - r k/ g .. 1> - r 1>/ gkf' 
= o;gk1J - ! d1J·cakgs. + osg.k - a.gk;) 
- ! dk'(o1Jgi• + osg.1> - a.gj)s) 
= 0. 
Theorem 5-4.6b. 
We have 
(5-4.14b) 
PROOF. 
v1 dk1> = a1 d/ + rql dkq - rkiq dq1> = o. 
This completes the proof. 
Theorem 5-4.6c. 
The associated metric tensor is a covariant constant; 
that is, 
(5-4.14c) 
PROOF. 
Let us start with the relation 
d/ = gi7>IJ1>k. 
As a consequence of Theorem 5-4.6b and the product rule stated in 
Theorem 5-4.5, we have 
0 = Vqg;7>1J1Jk 
= (Vqgi1J)g1>k + gi1> Vqg1>k. 
Since g11> is a covariant constant, the first term of the right-hand member 
has the value zero. Multiplication by gir produces the desired result. 
The determinant of the metric tensor is also a covariant constant. 
However, to establish this fact, the following result concerning contracted 
Christoffel symbols is needed. 

Tensor proceses of differentiation 
339 
Theorem 5-4.7. 
We have 
(5-4.15) 
l-1 
r 
; 
_ ()In (lgl>QI) 
ik -
axk 
PROOF. 
According to definition, 
(5-4.16a) 
r1/ = tg1q(o;gkq + okgqi - oqgik) = lgiq okgqi· 
(5_4.16b) 
gia = cofactor ga1 in lga11 
= 
_1_ a lg,.,,I . 
lgr.1 
lgr.1 ogai 
By combining (5-4.16a,b), we obtain 
(5-4.16c) 
r 
; -  _1 () lg,.,,I - o In (lg,,,,l)l-1 
ik -
2 I 
I axk -
axk 
, 
grs 
as was to be shown. 
Theorem 5-4.8. 
The determinant of the metric tensor is a covariant 
constant; that is, 
(5-4.17) 
The proof is left to the reader. Note that g is a scalar density of weight 
-2. 
Thus far we have been considering the Riemannian space analogue of 
the process of partial differentiation. Let us turn our attention to the 
problem of an appropriate generalization of the ordinary derivative. 
Because it is desirable, at least from the geometric point of view, to 
think of tensor fields expressed in terms of a single parameter as defined 
along a space curve, the meaning of the term curve with respect to a 
Riemannian space should be made precise. In actuality, we simply extend 
Definition 2-1.2. 
Definition 5-4.S. 
Let X\ · · 
· , xn be continuous functions defined on a 
common domain with at least the first derivatives continuous and not 
simultaneously zero. The set of all points with coordinates X1(t) · 
· 
· xn(t) 
is called a space curve. Other parameter representations which develop 
from this one through allowable parameter transformations8 designate the 
same curve. 
Xi 
= X1(t) 
are called parametric equations of the curve. 
Suppose that et> is a scalar function defined on a space curve with para­
metric equations X1 
= X1(t). Then 
Cl>(t) 
= (t) 
•See Def. 2-1.2b 

340 
TENSOR ALGEBRA AND ANALYSIS 
for all t. Hence 
«I>(t + At) - «I>(t) 
4(t + At) - 4(t) 
---'--= ---'-----
At 
At 
(5-4.18a) 
By taking the limit as t - 0 of each member of (5-4.18a), we obtain the 
fact that 
(5-4.18b) 
d«I> 
d4 
-=- ; 
dt 
dt 
that is, the derivative of a scalar field is again a scalar field. There is nothing 
new in (5-4.18b); however, it does do more than simply point up the fact 
that this much of prior theory correlates with the generalizations to 
Riemannian space. Relation (5-4.18b) provides a heuristic approach to 
the introduction of the derivative of a tensor field. In particular, for 
Euclidean three-space we have 
d«l> 
0<I> dX1 
di
= ax1Tt · 
Since the tangent field is a vector field and because the process of covariant 
differentiation is the Riemannian space analogue to partial differentiation, 
the following definition is rather natural. 
Definition 5-4.6. 
In any allowable coordinate system let 
(5-4.19) 
The set (D/dt)Tj5•.'.'.j!rz is said to be the absolute9 derivative of the tensor 
field components Tfi•.'.'.j!rz· 
Theorem 5-4.9. 
The class {(D/dt)Tf,•.'.'.';61'} of absolute derivatives is a 
tensor field of the same type as the original tensor field. 
PROOF. 
The proof follows immediately from the fact that the tangential 
field dX1/dt and the covariant derivative field are contravariant and co­
variant vector fields, respectively. 
It is to be noted that the rules for differentiation of sums and products 
are extendable to the absolute derivative. It is also true that covariant 
constants are in the same sense absolute derivative constants. 
Problems 
1. (a) Compute the Christoffel symbols for (1) cylindrical coordinates 
(2) spherical coordinates. 
1 The term intrinsic derivative is used quite often with the same meaning. 

Geodesics 
341 
(b) Prove that the Christoffel symbols are symmetric, that is, 
r;kf. = rk/. 
2. Prove Theorem 5-4.2. 
3. Starting with (5-4.8), show that 
_ p 
aXP(ax; axk 
. 
a2x; ) 
r(lr 
= oXi 0X<1 aXr rik
• 
+ 0X<1 aXr . 
4. Show that V' 1 Vk transforms as a tensor of covariant valence 2. 
5. Show that 
02 x1 
axq 
ax1 ax• 
a2 xq 
oXk aXa 'iJXP + oXq oXk ox• 'iJXP 
= o. 
Hint: 
ax1 axq 
---{ii 
oX<1'iJXP - P. 
6. Show that the covariant derivative of tensor components Tl produces 
tensor components. 
7. Prove Theorem 5-4.8. 
8. (a) Show that V'p(T/ + W/) 
= Y'pT/ + Y'pW/. 
(b) Show that Y';T/WPi 
= (Y';T/)Wpi + T/ Y';W,i. 
9. Show that the absolute derivative of a scalar of weight zero is equal to its 
ordinary derivative. 
10. Assume that Newton's second law has the general form 
DmV 1 
Fi=--
dt 
Express this law in cylindrical and spherical coordinates. 
11. Compute the Christoffel symbols associated with the cylindrical and 
spherical surfaces of Chapter 5, Section 3, Problem 2. 
12. Show that 
. 
1 
0 
-
V'; W' 
= v'- oXi (v' g Wi) 
g 
In curvilinear coordinates the right-hand member of this expression is 
called the divergence of W. (See Chapter 3, Section 5.) The same name 
is often used for V'; Wi in a Riemannian space. 
13. Show that 
5. Geodesics 
In Euclidean three-space a line is the shortest distance between two 
points. The immediate purpose is to generalize the concept of "straight 
line." In particular, given two points, A and B, the objective is to find the 

342 
TENSOR ALGEBRA AND ANALYSIS 
path of minimum length joining the two points consistent with the space 
metric. This is a problem in the calculus of variation. It was first con­
sidered (for a surface in three-space) by Johann Bernoulli (1667-1748, 
Swiss) in 1697. 
Definition S-S.l. 
Suppose that a curve Xi = Xi(t) joins points P 0 and P1 
(the coordinates of P0 and P1 are X0; = X1(t0) and X11 = X1(tJ, respec­
tively); then 
(5-5.1) 
lti 
s = 
f dt, 
to 
- (I 
dX1 dXk IJ' 
f-
gjk 
-
dt 
dt 
is said to be the distance from P0 to P1 along the given curve. 
There are many difficulties associated with the proposed problem of 
determining the curve of minimum distance. Although we have tried to 
point out these difficulties, they are not 
P1 
attacked but rather left for consideration 
as a part of the study of the calculus of 
variations. 
First of all, the existence of a path of 
shortest length is not assured.10 
Second, 
when such a path does exist, a closed form 
representation (i.e., a set of parametric 
equations) more than likely cannot be 
Po 
determined. Therefore, under the assump-
Fig. 5-S.l 
tion that a curve of shortest length does 
exist (for an indication of the nature of 
such conditions, see Bolza, pp. 246-247), we proceed to find a set of 
differential equations which necessarily must be satisfied. 
To consider all curves through P0 and P1 would defy analysis; therefore 
the problem is restricted to a band of curves through P0 and P1 which 
contains the curve of minimum length.11 This hypothesis is valid because 
of the assumption that such a curve exists. If the parametric equation 
Xi = X1(t) 
are associated with a curve of minimum length C, with end points P0 and 
P1, the coordinates of a neighboring curve Care 
(5-5.2a) 
10 See Oskar Bolza, Lectures on the Calculus of Variations, Dover, 1961; University 
of Chicago Press, 1904. 
11 An intuitive feeling for the analysis can be acquired as follows. Stretch a rubber 
band tightly over a surface sector, the end points firmly fixed, slide the center of the 
band from its initial position, and let it return. 

Geodesics 
343 
where the functions w1 have at least continuous first derivatives and 
(5-5.2b) 
(See Fig. 5-5.1.) The parameter e plays a dual role. On the one hand, it 
can be thought of as a constant such that lei is as small as necessary. On 
the other hand, the coordinates X1 are differentiable functions of e (i.e., 
assume that a set of functions w1 has been chosen, and there is one-to-one 
correspondence between values of e and curves C. The coordinates X1 
are linear functions of e and are therefore clearly differentiable.) 
Theorem 5-5.la. 
For a curve C joining P0 and P1 to be of minimum 
length it is necessary that its parametric equations satisfy the Euler­
Lagrange equations 
(5-5.3a) 
where 
(5-5.3b) 
of 
_ d(of/0X1) = 
0 
oX1 
dt 
' 
. . 
dX1 
X'=-. 
dt 
PROOF. 
We have 
(5-5.4a) 
s = f'l f(X1 + ew1, xk + ewk) dt = ('i f(X1, Xk) dt. 
J 
J 
Since s is a differentiable function of e, 
(5-5.4b) 
as 
= r1 ( a ax1c + a! ax1c) 
dt. 
de 
J10 
ax1c de 
oX" de 
By assumption C is of minimum length. 
(5-5.4c) 
0 = (ds) 
= rll ( ofk wk + o!k ) dt, 
de •=0 
J,. ax 
ax 
where the bat notation does not appear in the right-hand expression 
because the particular curve C has come under consideration. 
(5-5.4d) i11 .}1_ ·k 
_ 
k.}L]'i -f'i kd(of/oxk) 
"kW dt-W 
"k 
W 
dt. 
ta OX 
OX 
lo 
t0 
dt 
Since the wk are zero at t0 and t .. the first term on the right-hand side of 
(5-5.4d) is zero. When the remaining term is substituted into (5-5.4c), 
we have 
(5-5.4e) 

344 
TENSOR ALGEBRA AND ANALYSIS 
Because (5-5.4e) must hold for all sets of functions w'' which vanish at the 
end points of the arc, it follows that 
a1 
_ d(af 1a xk> = o. 
axk 
dt 
This completes the proof. 
Theorem 5-5.lb. 
If f is given by (5-5.3b), that is, 
f::/= 0, 
the Euler-Lagrange differential equations (5-5.3a) are equivalent to the set 
(5-5.5a) 
Furthermore, if the parameter t represents arc length s, then (5-5.5a) 
reduces to 
(5-5.5b) 
PROOF. 
By straightforward computation of the terms of the Euler­
Lagrange equations we obtain the following. (Note that gnc is a function 
of position, i.e., of the coordinates X1 only and that the X1 are independent 
of the position coordinates X1; that is, direction at any point may be 
chosen independently of the coordinates of that point.) 
(5-5.6) 
= [- d(lnf) 
xk + og'Pk xqxk + 
xk] 
f 
dt 
g'Pk 
axq 
g'Pk 
' 
where € is the sign of g1kX1 Xk. Furthermore, 
(5-5.6c) 
a1 
= !.. og;k x1 xk. 
ax'J) 
21ax'J) 
By substituting the results (5-5.6b,c) into (5-5.3a), we obtain 
(5-5.6d) 
.!. [1 d(lnf) 
xk - (2 ag'Pk - agik) x1 xk - 2 
Jik = o. 
21 
dt 
g'J)k 
ax1 
ax'J) 
g'Pk 

Geodesics 
345 
The Christoffel symbols can be introduced by considering the fact that 
g1k is a covariant constant. We obtain 
(5-5.7a) 
2 og1J. = 2 r vf grk + 2 rk/ gvr• 
oX' 
ogfk 
r r 
+ r r 
--= 
ivgrk 
kvgir. 
axv 
When these relations are plugged into (5-5.6d) and the summation indices, 
as well as the symmetry of X1 Xk, are taken into account, (5-5.6d) reduces 
to 
(5-5.7b) 
din/ 
"k 
r r ·; "k 
""k_ 
2 --g11kx - 2g11r ik X X - 2g11kx 
- 0. 
dt 
An alternate form of the set of equations in (5-5.7b) is obtained by multi­
plying and summing with ig11q; then 
(5-5.7c) 
Xq + r. q _x; .fk 
= 
d In/ Xq 
1k 
dt 
' 
If t represents arc length, 
I gik 
dXf dXk I 
= 
1. 
ds 
ds 
Therefore f is a constant and d lnf/ds = 0. 
Under this assumption 
(5-5.7c) immediately reduces to the form in (5-5.5b). This completes the 
proof. 
Definition 5-5.2. 
The curves satisfying the differential equations in 
(5-5.5a) or (5-5.5b) are said to be the geodesics of the space.12 
Since the differential equations in (5-5.5a,b) are of second order, a 
unique solution is determined at a point P0 when X01 and X01 are given; 
that is, a point and a direction uniquely determine a geodesic at a given 
point. 
A geodesic joining two points is not necessarily either unique or the 
shortest distance between the points. This statement is simply illustrated 
on the surface of a sphere. It can be shown that great circles (i.e., the 
intersections of planes through the center of the sphere with the sphere) 
are the geodesics, and, in fact, the only geodesics, of the surface. Clearly, 
a geodesic joining the poles is not unique. Furthermore, if we consider 
11 f = (lg1kX1 ktD = 0 identically satisfies the Euler-Lagrange equations (5-5.2a). If 
the direction X1 at each point along a curve is such that f = 0 and the differential 
equations in '(5-5.4b), expressed in terms of a parameter that does not represent arc 
length, are satisfied by the equations of the curve, then the curve is said to be a null 
geodesic. Such geodesics are of importance in the theory of relativity. 

346 
TENSOR ALGEBRA AND ANALYSIS 
two points, other than a diametrically opposite pair, one arc of the geodesic 
joining them is the shortest distance but the other arc joining them is not. 
It can be shown that for two points sufficiently near the joining geodesic 
is both unique and the curve of minimum distance. 
The solution of the differential equations of geodesics in a closed form 
is in general beyond the power of analysis. However, in some simple cases 
complete solutions can be obtained. The circular cylinder is one such case. 
Example S-5.1. 
In dealing with geodesics on a surface an alternative 
form of (5-5.6a) is often useful. If the surface parameters are designated 
by the symbols v1, v2, then (5-5.5a) is equivalent to the pair of equations 
(5-5.8a) 
d2v1 
1 dv11 dva 
d In/ dv1 
dt2 + r 
J>Q 'dt di 
= dt'" di ' 
d2v2 
2 dv11 dva 
d In/ dv2 
dt2 + rpq 'dtdi' 
= Ttdi' 
Either a representation v1 = h(v1) or v1 = g(v2) can be associated with a 
surface curve. A parametric representation of the first is 
(5-5.8b) 
v1 = t, 
v2 = v2(t). 
From (5-5.8b) it follows that 
(5-5.8c) 
dv1 
- = 1 , 
dt 
By use of these results the equations in (5-5.8a) can be expressed in the 
form 
(5-5.8d) 
r l+ 2 r 1 dv2. + r 1 (dv2)2 
= d(Inf) 
11 
12 dv1 
22 dv1 
dv1 
(5-5.8e) 
d2v2 
+ r 2+ 2 r 2 dv2 
+ r 2(dv2)2 
= d(lnf) dv2. 
(dv1)2 
11 
12 dv1 
22 dv1 
dv1 dvi 
By substituting ford lnf/dv1 in (5-5.8e) we have 
(5-5.8f) 
d2v2 
2 
2 
1 dv2 
s 
1 (dv2)2 
1 (dv•)a 
(dv1)2+ru+2rn-r11 dv1+(r.2-2r12 ) 
dv1 - r22 dv1 
= 0. 
If we start with the representation v1 = g(v2), then 
(5-5.8g) 
d2vl 
dv1 
(dv1)2 
(dv1)a 
(dv2)2+r2f+(2r1f-r222) dv2+(r1i1-2r212) 
dvz -ru2 
dv" 
= 0. 
The two forms (5-5.8f,g) determine the geodesics on a surface. 

Geodesics 
347 
In the case of a circular cylinder expressed by the parametric equations 
X1 = p cos v1, X2 = p sin v1, X3 = v2 we have 
(p2 
0) 
(5-5.9a) 
(a) 
(g11;) = 
0 
1 , 
p = constant, 
(5-5.9b) 
(b) 
rkp1= 0. 
The differential equations (5-5.8f,g) reduce to 
(c) 
dav2 
- = 0 
(5-5.9) 
(dv1)2 
' 
dav1 
(d) 
-= 0. 
(dv2)2 
These relations have solutions in the form of 
(5-5.9) 
(e) 
v2 = C1V1 + Cg, 
(f) 
v1 = k1v2 + k2, 
where c1, c11, k., k2 are constants of integration. If c1 = 0, then v2 = c1• 
That the curves v2 = constant are circles can be determined by the fact 
xs 
X 1 
Fig. 5-5.2 

348 
TENSOR ALGEBRA AND ANALYSIS 
that v2 = constant is equivalent to X3 = constant. On the other hand, if 
c1 ':F 0, then 
X1 = p cos v1, 
X2 = p sin v1, 
X3 = C1V1 + C2· 
These are the parametric equations of a circular helix. 
From (5-5.9f) 
with k1 = 0, we get the curves v1 
= k2• These are the rulings on the 
cylinder. If k1 ':F 0, circular helices are obtained again. Hence the geo­
desics on a circular cylinder are rulings, circles, and helices. (See Fig. 
5-5.2.) 
Problems 
1. Show that the differential equations of geodesics (5-5.5b) imply that the 
geodesics in a Euclidean space are straight lines. 
2. Determine the Christoffel symbols from the Euler-Lagrange equations 
for 
of 
d( off oX;) 
. J 
dX; 
oX; -
ds 
= O, 
X = Ts 
(a) the cylindrical coordinate system p, 8, z, 
(b) the spherical coordinate system r, 8, <f>. 
Hints: Note that if one solves (S-S.5b) for d2Xi/ds2 
d2Xi 
dXPdX" 
dss 
= 
-rp/ Ts Ts; 
that is, the Christoffel symbols are coefficients of 
dXPdXq 
ds "'d;. 
For cylindrical coordinates 
f = [ (: J + P2 ( :J + ( :n $ 
Plug this form in the Euler-Lagrange equations and make the appropriate 
computations. Note that f does not vary with change in s. 
6. The Parallelism of Levi-Civita 
In a Euclidean space there is an unambiguous meaning to the term 
"parallel vector field." A vector field is parallel if the components of 
every two members are proportional. In considering surfaces, the only 
intuitive examples of non-Euclidean spaces, the preceding definition of 
parallelism of a vector field has no meaning. For, if we are developing the 
intrinsic geometry of a surface, a member of a surface vector field at a 
point P must be in the tangential plane to the surface at P. If the com­
ponents of surface vectors at distinct points P and Q are proportional 

Fig. 5-6.1 
The parallelism of Levi-Civita 
349 
with respect to one set of surface parameters, they, in general, will not be 
with respect to another set. Thus the concept of proportionality of com­
ponents is not preserved under surface coordinate transformation and 
cannot serve in more general situations. (See Fig. 5-6.1.) 
In casting about for a generalization of the Euclidean concept of paral­
lelism of a vector field, we might again consider the special case of surfaces 
and attempt to make use of the embedding space. However, this line of 
thought must be dropped quickly, since a vector at a surface point P 
parallel in the Euclidean sense to a surface vector at Q would, in general, 
not be a surface vector. 
Note that more often than not comprehensive definitions are induced 
from special examples. In turn, the general definition must be compatible 
with elementary cases. In this instance the special examples consist of 
Euclidean geometry and surface theory. Having stated me_thods of gener­
alizing the concept of parallelism which might come into our minds but 
which must be rejected, we now present the accepted generalization. 
Although the method of presentation may be quite different from the 
original, the following ideas are essentially those of the Italian mathe­
matician Tullio Levi-Civita. Suppose we restrict our considerations to a 
curve C in Euclidean space. Let V1 = V1(t) be components of a vector 
field of parallel vectors of constant magnitude along a curve C (parallel in 
the Euclidean sense) ; then 
(5-6.1) 
dV1 
- =0. 
dt 
A definition of a parallel vector field in a Riemannian space is introduced 
only with respect to a given curve C of that space. The analytic form of the 
concept is inferred directly from ( 5-6. l). 

350 
TENSOR ALGEBRA AND ANALYSIS 
Definition 5-6.1. 
Let V be a vector field along a curve C in a  Riemannian 
space. The vector field is said to be a parallel vector field with respect to 
the curve C if and only if 
(5-6.2) 
DV1 
-= 0. 
dt 
If Vl is the vector field representative at P0 of C, then any other vector 
of the field is said to be obtained from V0; by means of parallel displace­
ment. It is clear that the general definition (5-6.l) includes the Euclidean 
case from which it was inferred, since 
DV1 = dV1 + r ;yi' dXq 
= O 
dt 
dt 
pq 
dt 
reduces to the form (5-6.l) in a Cartesian coordinate system where 
r pq1 = o. 
The fundamental properties of parallelism are pointed out in the next 
theorems. 
Theorem 5-6.1. 
Let V be a parallel vector field with respect to a curve C. 
The magnitude of V is constant. 
PROOF. 
Since the ordinary derivative of a scalar coincides with the 
absolute derivative (Chapter 5, Section 4, Problem 9), we have 
!!:_ ( . V;Vk) = D ( 
V;Vk) = 
. (DV; yk + V; DVk) 
dt g,k 
dt g;k 
g,k dt 
dt 
DVk 
= 2g1kV1 -- = 0. 
dt 
Since the ordinary derivative of the magnitude is zero, that magnitude is 
constant. 
Theorem 5-6.2. 
Let A and B be parallel vector fields along a curve C. 
The angle determined by A and B is constant along C. 
The proof is analogous to that of the preceding theorem. In fact, that 
theorem could be considered a special case of this one. 
A tangential vector field {dX1/ds} along a geodesic, and referred to arc 
length, satisfies the relation. 
(5_6_3) 
D(dX;/ds) 
= O. 
ds 
Hence this tangential field along a geodesic is a parallel vector field. 
According to the preceding theorem, any other parallel vector field along 
the geodesic makes equal angles with the tangential field. This is rather 

The parallelism of Levi-Civita 
351 
pleasing intuitively, since the geodesics are the lines of the space and the 
tangential vector field determines the direction of one of the lines at a given 
point. 
In other words, the property of a parallel vector field along a 
geodesic making a fixed angle with that geodesic harmonizes nicely with 
the Euclidean concept of a parallel field making a constant angle with a 
line. 
It may have occurred to the reader that the relation (5-6.1) from which 
we generalized to obtain the definition of parallel vector field is somewhat 
restricted in that V; was assumed to be of constant magnitude. If this 
restriction is dropped, we have as a unit field V;/(c511qV11Vq) along C 
(assuming that the space is referred to a rectangular Cartesian system). 
Then 
(5-6.4a) 
d(V;/f) = O, 
dt 
After differentiation, we have 
(5-6.4b) 
dV; = ( d lnf)V1 
dt 
dt 
The obvious generalization of (5-6.4b) is 
(5-6.4c) 
DV; = h(t)V1. 
dt 
Vector fields satisfying (5-6.4c) are referred to in the mathematical litera­
ture as "pseudoparallel." 
If h(t) = 0, the German word "pseudoaqui­
pollent" is used. According to Definition 5-6.1, a pseudoaquipollent field 
is a parallel field. 
Parallel vector fields do not satisfy all of the properties that we might 
intuitively cherish. For example, suppose C is a closed curve and vector 
components V0; are associated with a point P0 of C. We cannot expect 
a vector of the field generated by parallel displacement of V/ around C 
to coincide with V0; at P0 again. This fact is illustrated in the next example. 
In the example Greek indices have the range 1, 2. 
Example S-6.1. 
In Euclidean three-space and with respect to a rec­
tangular Cartesian coordinate system the equation of a cone is given by 
(5-6.5a) 
A corresponding parametric representation is 
(5-6.5b) 
X1 = v1 cos v2, 
X2 = v1 sin v2, 
X3 = v1, 

352 
TENSOR ALGEBRA AND ANALYSIS 
where v1, v2 can be thought of as parameters or surface coordinates. To 
study the intrinsic geometry of the surface of the cone, we begin with the 
fundamental metric form 
where as usual 
By means of straightforward computation, we obtain 
(a) 
(g,iy) = ( 
(S-6.6) 
(b) (g") = (: 
v• 
1'221= - -
2' 
Consider a surface curve C: 
(5-6.7a) 
v1 = c 
= constant, 
v2 = t. 
I' 7/ = 0 otherwise. 
Let W be components of a parallel vector field on C. Then 
DWA 
(5-6.7b) 
- = 0 
or 
(5-6.7c) 
dt 
dW.i + I' .iwr dtl = 0. 
dt 
yp 
dt 
By making use of the values determined for the Christoffel symbols and 
the fact that 
dv1 
-=0, 
dt 
dv2 
-=1 
dt 
' 
we can write out the equations (5-6.7c) as 
dW1_"ws=0 
dt 
2 
' 
(5-6.7d) 

The parallelism of Levi-Civita 
353 
where V1 = c along the curve of consideration. 
By differentiating the 
first of these equations and plugging the second into the result, we obtain 
(5-6.Sa) 
dswi + ! w1 = o. 
dt2 
2 
The solution of this differential equation is 
(5-6.Sb) 
Ftom the first of the equations (5-6.7d) 
(5-6.Sc) 
W2 = I! (-A sin J2 t + B cos J2 t) . 
Now suppose that corresponding to t = 0 [i.e., at the curve point (c, O)] 
we have Wll = Wl. Then the constants of integration in (5-6.Sb,c) take 
values 
· 
(5-6.Sd) 
At t = 21T 
(5-6.Se) 
A= W/, 
Thus the vector obtained by parallel displacement around the closed curve 
has a direction different from the original. Of course, the magnitude of the 
vector is the same as that of W/. 
· 
Problems 
1. To study the intrinsic geometry of a sphere, we begin with 
tJsl = g;.,., dJlA dXY, 
J(l = O, 
J(2 = </>. 
The fundamental metric tensor components were computed in Chapter 5, 
Section 3, Problem 2. In Chapter 5, Section 4, Problem 12, the reader 
found that 
and all other Christoffel symbols are zero. Consider the small circle 
0 ,. ot = constant for the purpose of parallel propagation of a vector A;. 
Show that the equations 
DAA 
-
= 0 
d<f> 
' 

354 
TENSOR ALGEBRA AND ANALYSIS 
where the surface coordinate</> is chosen as parameter, reduce to 
dA1 
- - cos ex sin ex A2 = 0 
d<f> 
' 
dA2 
- + cot ex A1 = 0 
d<f> 
• 
and obtain the solution. Finally, choose (A1, A2) = (1, 0) at</> = 0 and 
then compare with the vector obtained by parallel propagation and corre­
sponding to </> = 27T. 
7. The Curvature Tensor 
In studying the calculus of several variables, we find that if second 
partial derivatives o2<l>/oX1 oXk, o2<l>/oXk oX1 of a function <l> are con­
tinuous, they are equal; that is, the second partial derivative is commu­
tative. For simplicity of notation we replace 
(5-7.la) 
by 
(5-7.lb) 
(J2<J> 
(J2<J> 
-- = 0 
ax1 axk 
axk ax1 
In making the generalizations necessary for a proper development of 
transformation theory in Riemannian spaces, it was seen that covariant 
differentiation replaces partial differentiation. Therefore it is natural to 
ask the question whether the covariant derivative satisfies a commutative 
property. 
This question is answered in the negative. 
However, in so 
doing we introduce a mixed tensor of fourth order. This so-called Riemann 
Christoffel mixed tensor, R;1k1, plays a role in the theory of integration of 
systems of differential equations and serves to classify the geometric 
nature of the space. An introduction to these ideas is presented in the 
following theorem. 
Theorem 5-7.1. 
Let V; be the components of an arbitrary covariant 
vector. Suppose that at least the second partial derivatives of the com­
ponents are continuous on an appropriate region of space. Then 
(5-7.2a) 
where 
(5-7.2b) 
R1k/ = 2(-oc1r!1; + r:r1r!1m). 
PROOF. 
We have 
(5-7.3a) 
Vkfli = okfli - r;k1V1 
and 
(5-7.3b) 
V;(VkJ!i) = 01 akV; - (a;rik)Vi - rik101Vi 
- rkrvml'i - rirvkvm. 

The curvature tensor 
355 
By commutingj and k and subtracting, we obtain 
(5-7.3c) 2VuVk1V. = (okr1/ - o;rkf) Vi - (ri1cmr1m1Vi - rirr1cm1Vi). 
Other terms drop out because of the commutivity of the partial derivatives, 
the symmetry of the Christoffel symbols, and straightforward cancellation. 
The relation (5-7.3c) can be written in the form 
(5-7.3d) 
or 
(5-7.3e) 
2V[,V1c1V. = 2(-oufi1i + ri[1ri1m)Vi. 
This completes the proof. 
Theorem S-7.2. 
Suppose that componVnts R;.,,/ are introduced into each 
allowable coordinate system in accord with (5-7.2b). Then the class 
{R;k/} is a mixed tensor of contravariant valence 1 and covariant valence 3. 
PROOF. 
In examining ( 5-7 .2) it is seen that Vu V kl are components of 
an operational tensor of covariant otder two, whereas V, are covariant 
components of an arbitrary tensor. Therefore, according to the quotient 
law of tensor algebra, R11c/ are tensor components of the type indicated. 
Definition S-7.1. 
The tensor {R;1k1} is called the Riemann Christoffel 
tensor of the second kind. The associated tensor with components 
(5-7.4) 
is called the Riemann Christoffel tensor of the first kind. 
The tensors of the foregoing definition are also referred to as the curva­
ture tensor and the covariant curvature tensor, respectively. 
According to (5-7.2a) the covariant derivative is, in general, not com­
mutative. In fact, it is commutative if and only if 
(5-7.5) 
We shall investigate the significance of the condition (5-7.5) at a later 
point. 
At present, attention is focused on the concept of parallel displacement. 
Through this avenue we shall be able to determine, at least in part, the 
geometric significance of the Riemann-Christoffel tensor. In this develop­
ment we follow the lead of Levi-Civita. 
At a point P of space construct a coordinate parallelogram with vertices 
P, Q, S, R. Let the parameters for the two coordinate directions be 
t1 and t2• 
(See Fig. 5-7.la.) 
Represent the tangential vectors at P by 
dX1/dt1 = dX1, dX1/dt2 = dX1• 
1 
2 

356 
TENSOR ALGEBRA AND ANALYSIS 
Q(Xi + l11Xi) 
Fig. 5-7.la 
Theorem 5-7.3a. 
If subjected to parallel displacement the vectors dX;, 
dXi satisfy the parallelogram law of addition.13 
1 
2 
PROOF. 
Figure 5-7.la presents a finite model of the situation at hand. 
The model is not precise, but it does enable us to describe the algebraic 
relationships of the derivatives subject to the process of parallel displace­
ment. In terms of Fig. 5-7.la, our object is to determine the parallel dis9 
placement of dX; at Rand add this displaced vector to dX;. The vector 
1 
2 
resulting should be the same as that obtained by determining the displaced 
vector corresponding to dXi at Q and then adding it to dXi. A schematic 
2 
1 
diagram of the process is indicated by Fig. 5-7.lb where the object is to 
dX.j +ddXj 
i 
_2:._s 
S' 
R ----
Fig. 5-7.lb 
13 In a Euclidean space two vectors A and B are added geometrically by displacing A 
such that its initial point coincides with the end point of B or vice versa. The funda­
mental consideration in our present discussion is the nature of such a parallel displace­
ment in Riemannian spaces. 

The curvature tensor 
357 
determine that S and S' coincide. The formal steps of the proof are as 
follows. Since the vectors are subject to parallel displacement, 
(5-7.6) 
(a) 
D dX1 = ddX; + rv/ dXv dXq = 0, 
2 1 
21 
1 
2 
(b) 
D dXi = ddX1 + r'PQ:1 dXv dXq = 0. 
1 2 
12 
2 
1 
Because the Christoffel symbols are symmetric in p and q, 
Therefore 
(c) 
ddX1 = ddX1, 
2 1 
1 2 
dX1 + (dX1 + ddX1) == dX1 + (dX1 + ddX1), 
2 
1 
21 
1 
2 
12 
as was to be shown. 
Since the symmetry of the Christoffel symbols was essential to the 
parallelogram law of addition just developed, the law in turn can be con­
strued as the geometric interpretation of the symmetry property of the 
Christoffel symbols. Indeed, the Christoffel symbol is a special case of 
the so-called "affine connection." In terms of this more general structure, 
such a geometric interpretation takes on added meaning. As far as the 
purpose of this section is concerned, relation (5-7.6c) will be helpful in 
the next theorem which gets at the significance of the curvature tensor. 
In this theorem we again consider a coordinate parallelogram and ask 
what the change is in vector components V1, defined at P, when displaced 
over a path P to R to S as compared to displacement over a path P to 
Q to S. (See Fig. 5-7.2.) 
Theorem S-7.Jb. 
The difference in displacement vectors resulting from 
parallel displacement along coordinate paths PRS and PQS, respectively, 
is 
(5-7.7) 
ddV' - ddV' = R;ki' dX1 dXkV1• 
12 
21 
2 
1 
PROOF. 
At R we obtain V' + dVi and at s 
(5-7.8a) 
2 
V' + dVi + d(V' + dV'). 
2 
1 
2 
Following the path of propagation P to Q to S produces the result 
(5-7.8b) 
V' + dV' + d(V' + dV'). 
1 
2 
1 
The difference of (5-7.8a) and (5-7.8b) is represented by 
(5-7.8c) 
ddV' - ddV' = 2ddV'. 
1 2 
21 
[12] 

358 
TENSOR ALGEBRA AND ANALYSIS 
Vi+ dV1 + d(V1 + dV1) 
1 
2 
V1 +dV1 + d(V1 + dV1) 
2 
1 
2 
dXj 
1 
Fig. 5-7.2 
For this relation we have, according to the process of parallel displacement, 
2ddVi = -2 d(dXtritiV1) 
[UJ 
[l 2] 
= -2[(ddXk)rikiyi + dX"' dXk(iJ'Priki) V1 + r;ki(-rq/Vq dX" dXk)]. 
[l7 
[l 
7 
[l 
7 
Since, according to (5-7.6c), 
the last relation reduces to 
ddX1 
= 0, 
[12] 
2ddvi = -2(a"'rk; - r1kirq/) dX"' dxkvq 
[l 2] 
[l 
2] 
= 2(-ac"'rk1! + r9c"'r:11) dX"' dxkvq 
= R'Pkai dX"' dXkVq. 
1 
2 
This verifies the conclusion of the theorem. 
1 
2 
According to ( 5-7. 7), the tensor { R1k 1 ;} classifies the given space at a 
point P. It does so in the sense that it provides a measure of the deviation 
of a vector field under parallel displacement with respect to the stated 
paths around an arbitrarily small coordinate rectangle. 
The components R1k/ are defined in terms of the components of the 
metric tensor g1k and its first and second derivatives. Therefore, if the space 
is Euclidean, there is a coordinate system in which the g1k are constants 
and 
(5-7.9) 
R1k/ = 0. 

The curvature tensor 
359 
Of course, if the components of a tensor are all zero in one coordinate 
system, they are all zero in every allowable coordinate system. Therefore 
(5-7.9) categorizes a class of spaces. 
If n = 2 these spaces are called 
developable surfaces.14 It is because the tensor classifies certain spaces 
and because in the special case of surfaces it reduces to Gaussian 
curvature that R1k1i is designated by the term ''curvature tensor." 
Of 
course, the intuitive significance of the term "curvature" becomes clouded 
when the space dimension is greater than 2. 
Definition 5-7.2. 
If in a given Riemannian space a coordinate system 
exists in terms of which the components of the fundamental metric tensor 
are constant, the space is said to be a flat or linear space. 
Theorem 5-7.4a. 
If a space is flat, the Riemann-Christoffel curvature 
tensor is zero. 
The proof is actually stated in the remarks preceding the theorem. 
The really interesting problem is the converse of Theorem 5-7.4a. How­
ever, before tackling it, let us consider the following example. 
Example 5-7.1. 
Parametric equations of a circular cylinder are 
X1 = p cos(), 
X2 = p sin(), 
X3 = z. 
The metric tensor of the surface has components 
(p2 
0) 
(gik) = 
0 
1 ' 
p =constant 
Therefore, as indicated in previous discussion, the circular cylinder surface 
is a flat space and its curvature tensor is zero. 
If we were given the information that in terms of a certain coordinate 
system of a space the components of the metric tensor were 
0 ) 
0 
' 
r2 sin2 () 
where r, () are variables, it would not be clear whether the space were flat. 
(Of course, in this simple example the representation in terms of spherical 
coordinates in a Euclidean space is probably easily recognized.) 
The 
following theorem, which is the converse of Theorem 5-7.4a, is helpful 
in such a circumstance. 
u The developable surfaces are those that can be cut and rolled out on a plane 
without stretching or tearing. In particular, they are tangential surfaces associated with 
given curves, cylinders, and cones. 

360 
TENSOR ALGEBRA AND ANALYSIS 
Theorem 5-7.4b. 
If the curvature tensor of a Riemannian space is zero, 
then the space is flat. 
PROOF. 
Consider the system of partial differential equations 
(5-7.lOa) 
or 
(5-7.lOb) 
axv 
. 
a2xv 
axi r ik• = ax; axk · 
On the one hand, it can be shown by straightforward computation that 
(5-7. lOa) is a particular solution of 
R;k/ = 0. 
On the other hand, consider the transformation law of the Christoffel 
symbols 
(5-7.lOc) 
. axv 
axz axm 
a2xv 
r 
. --
= 
- -- rlmi> + 
. 
ik axi 
ax; axk 
ax; axk 
Employing relation (5-7.IOb) to simplify (5-7.IOc), we obtain 
(5-7.lOd) 
or, on multiplying and summing with (oXi/oXq)(oXk/oX•) 
(5-7.lOe) 
that is, the Christoffel symbols are zero in the barred system. Next con­
sider the covariant derivative of the fundamental metric tensor. We have 
(5-7.lOf) 
Therefore the components of the metric tensor are constant in the barred 
system and the space is a flat space. 
Often a flat space is simply defined as one for which 
R;kzi = 0.1s 
According to Theorems 5-7.4a,b, such a definition is equivalent to Defini­
tion 5-7.2. 
u For comments concerning the equations R1.,1 = 0 as integrability conditions for 
the system (5-7.lOb), see Nathaniel Coburn, Vector and Tensor Analysis, Macmillan, 
1955, p. 184. 

Problems 
1. Show that 
Algebraic properties of the curvature tensor 
361 
is a particular solution of 
R1k1i 
= 0. 
2. Show that a space is flat if and only if there is a coordinate system associated 
with the space in terms of which the Christoffel symbols are identically 
zero. 
8. Algebraic Properties of the Curvature Tensor 
The curvature tensor has a number of interesting algebraic properties. 
We shall begin with a theorem on the decomposition of tensors, which is 
helpful in investigating the algebraic properties, the main objective of this 
section. 
Theorem 5-8.1. 
Any tensor can be expressed as a sum of outer products 
of vectors. 
PROOF. 
An example rather than a formal proof is presented. 
The 
method of the example can be extended to the general case without 
difficulty. 
Consider a tensor of contravariant valence l and covariant valence 2. 
Let Tif" represent the components in some coordinate system. Define n2 
covariant vectors by means of 
(5-8.la) 
(q) 
Ai= Tiva• 
(v) 
where (p), (q) distinguish between vectors and i indicates the indices of a 
vector. Also define 2n vectors according to the relations 
(5-8.lb) 
Then 
(5-8.lc) 
(1J) 
B; = IJ/, 
(q) 
TJ = Ai Bv>ck. 
(1J) 
(q) 
The relation (5-8.lc) is of tensor character; hence its validity in one 
coordinate system implies validity in every allowable coordinate system. 
This completes the verification of the example. 
Now let us investigate the algebraic properties associated with the 
curvature tensor. 

362 
TENSOR ALGEBRA AND ANALYSIS 
Theorem 5-8.2. 
If v• and W, are arbitrary vector components, then 
(5-8.2) 
(a) 
2VuV11V
,. 
= -Rw,.V1, 
(b) 
2Vc.V11W,. = Rw:w,. 
PROOF. 
Relation (5-8.2b) was obtained in Theorem 5-7.l, essentially 
by straightforward computation. The expression (5-8.2a) can be obtained 
in the same way. 
It follows immediately from either of the relations of Theorem 5-8.2 
that the Riemann-Christoffel tensor is skew symmetric in the first two 
indices. This fact can be expressed by either 
(5-8.3a) 
or 
(5-8.3b) 
Theorem 5-8.3. 
We have 
(a) 
2Vc.V11T1/ = R11,.mTM - Riim'T,.m, 
(5-8.4) 
(b) 
2Vc.V11T,.1 = Ril,.mTm1 + RwmTkm• 
(c) 
2Vc.V11Tkl = -RilmkTml - Riim'Tkm. 
PROOF. 
We consider (5-8.4a). According to Theorem 5-8.l, a vector 
decomposition can be determined for the components T,.1• 
(5-8.5a) 
where 
(21) 
(5-8.5b) 
A,.= T/, 
B1 = N211• 
(21) 
Because the covariant derivative possesses the same properties with respect 
to sums and products as the ordinary or partial derivative 
(21) 
( 
(21)) 
(21) 
V1T,.1 = V;A,. B1 = V;A,. 
B1 +A,. V1B1• 
(21) 
(21) 
(21) 
When the covariant derivative operator V, is applied and the skew sym­
metric counterpart of the resulting expression is formed, we have 
( 
(21)) 
(21) 
Vc.V11T,.1 = 
Vc•V11A,. 
B1 +A,. Vc.V11B1• 
(21) 
(21) 
Employment of (5-8.2a,b) and (5-8.5a,b) leads to the conclusion 
2 Vc.V11T1o' = Rrn,mTm' - Riim'T,.m. 
The results (5-8.4b,c) are arrived at in a similar manner. 

Algebraic properties of the curvature tensor 
363 
The two preceding theorems exhibit an operational characteristic of 
Vli V 11 analogous to the form of the covariant derivative itself. This fact 
makes memorization of relations (S-8.2a,b) and (S-8.4a,b,c) relatively easy. 
We shall use the results to establish the set of identities satisfied by the 
curvature tensor. 
In particular, the covariant curvature tensor whose components are 
introduced by the relation 
(S-8.6) 
is considered. 
Theorem 5-8.4. 
We have 
(a) 
Rw>kz = 0, 
(S-8.7) 
(b) 
R11ckz> = 0, 
(c) 
R!iikJl = 0; 
that is, the covariant curvature tensor is skew symmetric in the first pair 
of indices, skew symmetric in the last two indices, and completely symmetric 
in the first three indices. 
PROOF. 
Relation (S-8.7a) follows immediately from (S-8.2a). To prove 
(S-8.7b) we can start with relation (S-8.4b) and let Tkz = gkz· Since the 
fundamental metric tensor is a covariant constant, 
0 = V[;Vilgkl = Riikmgml + R;1tgkm 
= Riikz + R;izk· 
This completes the proof of (b). 
To prove (c), we introduce an arbitrary gradient vector 
(S-8.8) 
W1 = V1<1>. 
Then, according to (S-8.2b) and (S-8.7a), 
R[iik]1Wz = i(Riik1W1 + R1k/W1 + Rk;f Wz) 
= tcv[si]wk + v[ivk1w, + v[kvi1w,). 
When W1 is replaced as indicated by (S-8.8), a straightforward evaluation 
verifies that 
RLiikJ1Wz = O. 
Since W1 is arbitrary, it follows that 
Rliiklz 
= 0, 
hence 
R[iik]i> = gi>IR[iik]1 
= 0. 
A rather interesting identity, which is a consequence of (S-8.7c), is 
presented in the following theorem. 

364 
TENSOR ALGEBRA AND ANALYSIS 
Theorem 5-8.5. 
We have· 
(5-8.9) 
that is, the covariant curvature tensor is symmetric in the pairs i, j and k, I. 
PROOF. 
Four equations result from (5-8.7c): 
R;1k1 + R1ka + Rki;z = 0. 
R;kzi + Rk1;; + R1;ki = 0. 
Rk1i1 + R1iki + R;k11 = 0. 
R1iik + Rmk + Ri!ik = 0. 
By adding these equations and making use of the skew symmetry in the 
first two indices and the last two indices, we obtain 
2Rk;;1 - 2R;1ki = 0. 
This relation is equivalent to the desired result. 
The identities of Theorems 5-8.4 and 5-8.5 make it clear that the n4 
components of the curvature tensor cannot be chosen independently of 
one another; that is, if an appropriate basic set of components is chosen, 
the others are determined by the identities. The next theorem states the 
number of independent components. The proof of the theorem makes 
use of the assumption that the set of identities (5j8.7) is "complete;" 16 
that is, the assumption that any other identity relating the components 
can be obtained algebraically from them. 
Theorem 5-8.6. 
The number of independent components of the curva­
ture tensor { Riikz} in any allowable coordinate system is 
n2(n
2 - 1) 
12 
(5-8.10) 
PROOF. 
According to (5-8.7a), the first two indices must be different; 
otherwise the component is zero and among the remaining pairs only half 
are independent. Therefore the number of distinct choices, disregarding 
order, of these two indices is ![n(n 
- I)]. A similar number of distinct 
choices can be made for the second pair of indices, as pointed out by 
(5-8.7b). Of these {[n(n - l)]/2}2 possibilities, some must be cast out 
because of the identities in (5-8.9). In particular [n(n - 1)/2] things taken 
two at a time, that is, 
(5_8_1la) 
 { n(n; 1) [n(n; 1) _ 1]} 
16 For further remarks see Tracy Y. Thomas, Concepts from Tensor Analysis and 
Diferential Geometry, Academic Press, New York and London, 1961. For proof see 
Tracy Y. Thomas, The Diferential Invariants of Generalized Spaces, Cambridge 
University Press, London and New York, 1934. 

Algebraic properties of the curvature tensor 
365 
can be determined through (5-8.9). The distinct components 
(5-8.llb) 
are still subject to the identities (5-8.7c). 
Since the indices in (5-8.7c) 
must be distinct, the number of conditions imposed by the relations 
corresponds to the number of n things taken four at a time; that is 
(5-8.llc) 
n(n - l)(n - 2)(n - 3) , n > 3. 
24 
When (5-8.11 b) is reduced by the number of conditions (5-8.ll c), we 
obtain the result 
n2(n2 
- 1) 
12 
In certain aspects of the general theory of relativity and in other physical 
and geometric applications we encounter the tensor with components 
Riiki· This is the so-called Ricci tensor, whose components are represented 
by the symbols R;k· Since R;;k; and R;;k k are also candidates for the form 
of representation specified for the Ricci tensor, some clarification is needed. 
We immediately note that R;;k; = -R;;k;· The following theorem shows 
that the components R;;kk are identically zero and that R;;k; is symmetric 
inj and k. 
Theorem 5-8.7. 
We have 
(5-8.12) 
(a) 
Ri;/ = 0, 
(b) R;£ikJ
; = 0. 
PROOF. 
To show the validity of(a) we start with the defining expressions 
for the curvature tensor components; that is, 
(5-8.13a) 
R;;k0= 2(-a[iqJk + r:c;r 11,). 
When a summation is imposed on k and q, 
(5-8. Bb) 
R;;/= 2( -a c;q1k + r:c;r!1"'). 
For the second term in the right-hand member of (5-l.3b) we have, by 
interchanging the dummy indices p and k in the second term below, 
Since 
r Pr k 
r Pr k - r Pr k 
r kr p 
- o 
ki 
jp -
kj 
ip -
ki 
jp -
pj 
ik 
-
• 
it is also the case that 
-2a[ir#1k = -20[;o;i In J"i = o. 
This completes the proof of (a). 

366 
TENSOR ALGEBRA AND ANALYSIS 
In order to prove (b), we must first establish the fact that 
(5-8.14) 
We have 
Riiki = Riik,pi = +R;tpkg'P. 
With (5-8.14) in mind, consider 
(5-8.15a) 
If we make use of the curvature tensor identities, the second term of 
(5-8.15a) can be expressed as 
(5-8.15b) 
Since p and i are dummy indices and g'P is symmetric, the last member of 
(5-8.15b) is equivalent to R1,Pkg'P. Substitution of this result into (5-8.15a) 
leads to the desired consequence. 
Since the components Riikk are identically zero and the set R;;k' is 
symmetric in j and k, the following definition is free of ambiguity. 
Definition 5-8.1. 
The Ricci17 tensor has components 
(5-8.16) 
Since the R;k are symmetric in j and k, the number of independent 
components is t[n(n + l)]. 
In conjunction with the Ricci tensor, it is convenient to introduce the 
following scalar. 
Definition 5-8.2. 
The curvature invariant is expressed by means of the 
relation 
(5-8.17) 
The intuitive significance of R can be determined by an examination of 
the expression in two dimensions. The algebraic part of this task is done 
in the next theorem. 
Theorem 5-8.8. 
In a two-dimensional Riemannian space 
(5-8.18) 
R 
= 2R1212 . 
g 
PROOF. 
We have, according to (5-8.14), (5-8.16), and (5-8.17), 
R 
= -gikR;1p-•11, 
= 
_ gn R1221g22 
_ g12R121.21 
_ g21 R2121g12 _ g22 R211.n, 
= 2( -gi2g21 + gng22)R1212 
= 2 det (gik)R1212· 
17 Gregorio Ricci Curbastro. 

Algebraic properties of the curvature tensor 
367 
Since det (gik) and g = det (g1k) are reciprocal values, the proof is complete. 
By examination of the last theorem we find that the covariant curvature 
tensor has one independent component in two-space. Furthermore, the 
invariant R/2 is expressed as the ratio of that component to g. It can be 
shown18 that this ratio represents the so-called Gaussian curvature, a 
fundamental entity in the development of the differential geometry of a 
surface. 
Example 5-8.1. 
With respect to the surface of a sphere of radius r, 
we have 
(5-8.19) 
R 
1 
2=
· 
In order to establish this fact, we first observe that the parameterization 
X1 = r sin () cos cf>, 
X2 = r sin () sin cf>, 
leads to the fundamenta 1 metric form 
ds2 = r2 d02 + r2 sin2 () d</>2; 
that is 
(5-8.20a) 
( 
) ('2 
O ) 
gik = 
0 
,2 sin2 () 
By straightforward computation we find that 
X3 = r cos() 
(5-8.20c) 
r2/ = -sin() cos(), 
r122 = r212 = ctn 0. 
Therefore 
(5-8.20d) 
Rim = 2g22(-011r!11 - 1r122r122) 
2 . 2 ( 
a ctn () 
2 ) 
= r sm () - --a8 - ctn () 
= r2 sin2 0. 
From (5-8.20b) and (5-8.20d) we obtain the result 
R 
1 
(5-8.20e) 
-= _,. 
2 
,2 
This is the expected constant Gaussian curvature of a spherical surface. 
A special property of the Ricci tensor in two dimensions is that its 
components are proportional to the components of the metric tensor. 
This fact is stated formally in the next theorem. 
ts Vaclav Hlavaty, Differentialgeometrie der Kurven und Fliichen und Tensorrechnung, 
P. Noordhoff, 1939, p. 267. Erwin Kreyszig, Diferential Geometry, University of 
Toronto Press, 1959, p. 145. 

368 
TENSOR ALGEBRA AND ANALYSIS 
Theorem 5-8.9. 
In a two-dimension Riemannian space the components 
of the Ricci tensor are proportional to the components of the metric 
tensor; that is, 
(5-8.21) 
R 
R1212 
ik = 
-- gik• 
PROOF. 
We first note that 
g 
j, k = 1, 2. 
(5-8.22) 
gll = g22' 
g12 = - g21 = - g12 ' 
g22 = gll' 
for 
(5-8.22b) 
g 
g 
g 
ik 
cofactor gki in det (gk;) 
g = 
. 
g 
According to (5-8.16), 
Therefore 
(5-8.22c) 
Ru= -R;npgP' = -R2112/J22 = Ri212/J22, 
R12 = R21 = -R;12pgpi = -R1212/J12, 
R22 = -R;22pgPi = Ri212/J11• 
g 
The proportionalities (5-8.21) are obtained by substituting relations 
(5-8.22a) into the expressions (5-8.22c). This completes the proof. 
The most renowned usage of the tensor calculus is in the development 
of relativity theory, especially the general theory. A particularly useful 
tool in its development is the Bianchi identity presented in the next 
theorem. 
Theorem 5-8.10 (Bianchi's19 identity). 
We have 
(5-8.23) 
Vc;R;k]Pm = 0. 
PROOF. 
Let Wp be an arbitrary covariant vector. Then 
(5-8.24a) 3! VcS;VklW., = 2[V;(Vc;Vk1W.,) + V;(VckVilW.,) + Vk(Vc8ilW.,)] 
= [V;(R;k.,q) + \11(Rkipq) + \1 k(R;;.,q)]Wq 
+ R;k/V;Wq + Rkipq\l;Wq + R;;.,q\lkWq 
= 3(Vc;R;k]2'q)Wq + 3Rc;kl.,1q\1i]wq. 
The notation IPI simply indicates that p is not to be included in the bracket 
symbolism. Note that (5-8.2b) was made use of in this development of a 
first expression for 3! V[;V;Vk1W.,. 
19 Luigi Bianchi (1856-1928, Italian). 

Algebraic properties of the curvature tensor 
369 
On the other hand, we have 
(5-8.24b) 
3! VcS;Vk1W21 = 2(VcS11VkW21 + Vc;Vk1ViW21 + VckVi1V;W21) 
= (Riikq vqwj) + Riii>q VkWq) + (R;kiq VQW2> 
+ R;k21qViWq) + (Rki/VqW21 + Rk;21"V;Wa) 
= 3R[iik]
qvqw21 + 3Rci;1211
q
vk1wq. 
By subtracting (5-8.24b) from (5-8.24a) and employing the identity 
R[iikJq = 0, we obtain the result 
(5-8.24c) 
Vc;R;kJ»qwq = O. 
Since the preceding relation must hold for all sets of vector components 
wq, we obtain 
as was to be shown. 
The preceding proof of the Bianchi identity does not depend on co­
ordinate system. 
When studying invariants of a transformation group, 
as is a major goal of tensor analysis, it is rewarding to find such a proof. 
However, there are some interesting ideas that can be put forward by 
making the proof through the expediency of a special coordinate system. 
Definition 5-8.3. 
Let the Riemannian space be referred to. a coordinate 
system X'. At a point P0, introduce new coordinates by means of the 
transformation equations 
(5-8.25a) 
X; = X; - X0; + ! (r 
mn;)o(Xm. - X0m)(Xn - Xt). 
2 
The coordinates g; are said to be geodesic coordinates at the point P0• 
Since 
(5-8.25b) oxt 
= c5 t + !(r 
;) c5 .m(xn - X n) + !(r t) (Xm - X m) c5 n 
oX; 
; 
2 
mn o , 
o 
2 
mn o 
o 
; 
and 
(5-8.25c) 
it follows that the Jacobian of transformation is nonzero at P0• 
Hence 
the transformation is allowable. 
The particular advantage to the geodesic coordinate system introduced 
by the last definition lies in the fact that· the Christoffel symbols are all 
zero at P0 in that system. The following theorem discusses this idea. 
Theorem 5-8.11. 
In a geodesic coordinate system g; at P 0 we have 
(5-8.26) 
(r iki
)o = o. 

370 
TENSOR ALGEBRA AND ANALYSIS 
PROOF. 
According to the rule of transformation of the Christoffel 
symbols, 
(5-8.27a) 
The set ()Xi/()XP is evaluated at P0 by (5-8.25c). To evaluate the elements 
o2XP/(}Xi oXk, we first multiply and sum (5-8.25b) with oXi/oX\ thereby 
obtaining 
(5-8.27b) 
.. i axi ax· er 
i) cxn x n) 
Ok 
= axk + ()Xk 
Bn 0 
-
0 
• 
The result of differentiating this expression with respect to X1 is 
(5-8.27c) 
When (5-8.27c) is evaluated at P0, we obtain 
(5-8.27d) 
( a2xi ) 
(ax•) (axn) , 
oX1 oXk o 
= -
o'Xk o oX 1 o(rsn )o· 
The Christoffel symbols r;k i may now be evaluated at P0 by plugging the 
results (5-8.25c) and (5-8.25d) into (5-8.27a). We obtain 
(r ;k
i)0 
= -4v' (:)0 (:tcrsn1J)o + 4Pi (1 (·kt(I' n/)o 
= 0, 
as was to be shown. 
Example 5-8.2. 
In a geodesic coordinate system at P 0 we have 
V'[iRikJpa = o[;R;kJva = -2o[io;r51v = 0. 
The evaluation of the foregoing expression follows from the fact that it is 
both symmetric and skew symmetric in i, j. 
We close this section with the introduction of another tensor relation 
which plays a part in the development of general relativity theory. 
Definition 5-8.4. 
The components 
(5-8.28) 
are components of the so-called Einstein tensor. 
Theorem 5-8.12. 
The components of the Einstein tensor satisfy the 
properties 
(5-8.29) 
Vi G;; = 0, 
where 

An introduction to the general theory of relativity 
371 
PROOF. 
The Bianchi identity 
Y'c;R1klv
q 
= 0, 
may be expanded to the form 
(5-8.30a) 
Summing on i and q, we obtain 
(5-8.30b) 
Upon multiplication of (5-8.30b) with g;v, it follows that 
(5-8.30c) 
VigivR;kvi + VvRkv - VkgivR1v = 0. 
This relation can also be written in the form 
(5-8.30d) 
Finally (5-8.30d) is equivalent to 
Vi(Rk; - igk;R) = 0. 
This completes the proof. 
Problems 
1. Decompose T;/1 into sums and products of vector components. 
2. Prove that relation (5-8.2a) is valid. 
3. Prove that relations (5-8.4b,c) hold. 
4. Use the decomposition property of tensors to prove that the covariant 
derivative of a tensor is a tensor with covariant valence one more than 
that of the original. (See Theorem 5-4.4.) 
5. Prove that Rtik k = 0 by means of the relation V ;gik = 0. 
6. Show that R = 2R1212/g can be written in the tensor form 
R(g;kg;1 - g;kgil) = 2R;ikl 
7. Show that Ris a scalar of weight +2 in a Riemannian two space. 
9. An Introduction to the General Theory of 
Relativity 
In the special theory of relativity (1905) the fundamental laws of 
mechanics and electromagnetic theory are formulated so that their algebraic 
forms are invariant with respect to the special Lorentz group of trans­
formations. 
Physically this means that the inertial systems whose co­
ordinates are related by these transformations are equivalent. A uniform 
rectilinear motion of any one of the systems is relative to some other. 

372 
TENSOR ALGEBRA AND ANALYSIS 
From the kinematical point of view it is well known that all motion is 
relative. Therefore the question of producing a structure in which frames 
of reference in accelerated motion are equivalent for the purpose of 
formulating physical laws develops in a natural way. Mathematically, 
this requires algebraic statements of fundamental laws which are invariant 
under general transformations of coordinates. 
In the years following 1905 Einstein considered the problem of general­
ization stated in the preceding paragraph. 
He found that the tensor 
calculus, learned from his friend H. Grossman, met the challenge of 
generalization. 
But another problem of major character existed. 
The 
special theory of relativity did not include a gravitational theory as part 
of its structure. 
The "action at a distance" concept on which the 
Newtonian gravitational theory was based no longer had meaning because 
of the relative nature of the simultaneity of events. Einstein met this 
second problem in the discovery of the equivalence of inertial and 
gravitational mass. The essence of this discovery is that all motions in a 
homogeneous gravitational field can just as well be considered as motions 
in the absence of a gravitational field, but with respect to a uniformly 
accelerated frame of reference. This viewpoint makes it possible to 
develop a completely geometric structure as the model for a gravitational 
theory. The gravitational force is thought of as a pseudo-force, just as 
centrifugal and coriolis forces are in the classical theory, and is included 
in the metric structure of a Riemannian space. 
It is the purpose of this section to give a brief outline of the geometric 
structure associated with general relativity. 
No attempt is made to 
penetrate into the background of the physical quantities and laws that 
become involved. 
Assume that a fundamental metric tensor, gA,..• and a corresponding 
differential form, 
ds2 = KmtJ dX« dXfl 
are given. (Greek indices have a range of I,···, 4.) When considering 
surfaces, we found that the components of the metric tensor could be 
determined by a parametric representation of the surface valid in the 
three-dimensional embedding space. In the present situation we have no 
obvious way of determining the g's, and the precise nature of the Rie­
mannian space is not known. For the moment, we proceed abstractly. 
The problem of evaluating the g's will arise at a later point. 
The geodesics in the space of special relativity are straight lines 
represented by 
(5-9.la) 
d(dX'"fds) 
= O. 
ds 

An introduction to the general theory of relativity 
373 
We have seen that geodesics in a Riemannian space are signified in general 
by 
(5-9.lb) 
or, in more detail, 
(5-9.lc) 
D(dX'"fds) = 
O 
ds 
' 
The assumption is made that "particles subject to gravitational forces 
only move along geodesics of the space." This postulate embodies the 
assertion that inertial and gravitational mass are equivalent, for an 
inequality of the two would bring about deviations, because of inertial 
mass, from the geodesics determined by the gravitational field. [With 
respect to relations (5-9.la,b,c), note that the dXA/ds transform as com­
ponents of a contravariant vector under general transformations, and 
therefore they can play the role of velocity components in the general 
theory.] 
The preceding paragraph makes the implication that the gravitational 
field should somehow determine the components of the fundamental 
metric tensor. 
This determination is realized by identifying the com­
ponents g;k with gravitational potential. Classically gravitational potential 
is represented by a single function <I>, subject to Poisson's equation 
(5-9.2) 
b;k 
a2<1> 
= 41T 
ax; axk 
µ, 
where the function µ represents the density of matter. The discovery of 
an appropriate generalization of Poisson's equation occupied Einstein for 
a long period of time. On the basis of physical considerations, he decided 
that the right-hand side should generalize to a tensor density TAY of weight 
-1 representative of the momentum and energy of continuously distributed 
matter and an associated electromagnetic field. 20 The left-hand side of 
Poisson's equation is a linear function in the second derivatives of the 
gravitational potential <I>. Therefore the left-hand side of its generalization 
is required to be linear in the second partials of the components gAY" 
The tensor on the left-hand side must be geometric in character. Einstein 
indicates21 that he spent two years rejecting the Riemann curvature tensor 
•0 In particular, TAY = M'-Y - E'-Y, where MAY = Vlgl u.i(dX1/ds)(dXY/ds) and 
E'-Y = v'jgl (F"-'-Fa.Y + f;gY'-p>.fJ Fa.fJ>· The skew symmetric tensor {Fa.fJ} represents the 
electromagnetic field and µ0 is a scalar. 
11 Einstein, Essays in Science, The Wisdom Library, New York, 1934, p. 83. 

374 
TENSOR ALGEBRA AND ANALYSIS 
before deciding that it would do the job. Specifically, he made use of the 
so-called Einstein tensor density 
(5-9.3) 
The conditions imposed on the components of the fundamental metric 
tensor are 
(5-9.4) 
I ).y 
= 
C
T;.y -I 
The underlying space of the general theory of relativity whose metric 
tensor is defined by (5-9.4) is said to be a Riemannian space. 
The equations in (5-9.4) are complicated. 
A special case of much 
importance is one in which 
(5-9.5) 
T;.1 = 0. 
This assumption corresponds to a physical problem in which matter is 
represented by the sun. The electromagnetic field is considered to be 
negligible, as is matter outside the sun (but in a neighborhood confined 
to the solar system). The best known solution of the field equations in 
(5-9.4) under the conditions in (5-9.5) is due to K. Schwarzschild.22 It is 
essentially this solution that follows. It is presumed that the matter is 
homogeneous and spherical so that the chosen coordinates r, 0, cp, t are 
essentially spherical coordinates, along with a time variable, at great 
distances from the matter generating the space. Furthermore, we assume 
that the field is static and reversible in time. These suppositions lead to a 
fundamental metric form 
(5-9.6a) 
ds2 = -;(r) dr2 - r2 d()2 - r2 sin2 () dc/>2 + 17(r) dt2, 
where ;(r) and 17(r) are positive functions such that 
(5-9.6b) 
;(r)--+ 1, 
ri(r)--+ 1, 
as r--+ oo. 
Since 
T.1.r = 0, 
we have 
(5-9.7a) 
When the products of this relation with g.1.r are summed, we obtain 
4 
R - -R = 0 
2 
or 
(5-9.7b) 
11 Berlin Sitzungsberichte, 1916, p. 189. 
R = 0. 

An introduction to the general theory of relativity 
375 
Therefore (5-9.7a) reduces to 
(5-9.7c) 
I R;.1 = 0. 1 
It is these conditions that determine the components of the fundamental 
metric tensor. 
In order to investigate them further, it is necessary to 
compute the Christoffel symbols on the basis of the known information; 
that is, 
-+(r) 0 
0 
0 
0 -r2 
0 
0 
(5-9.8a) 
(gap)= 
0 
0 -r2 sin2 () 
0 
0 
0 
0 
1J(r) 
The computations are left as an exercise for the reader. We obtain 
(5-9.8b) 
1 
+' 
ru = -
' 
2+ 
rss2 = -sin() cos(), 
• 
2 () 
r s/ = _ r SI; ' 
r133 = ! ' 
r233 = r323 = ctn (), 
r 
r144 = r414 = '1-' 
the remaining r,,/ = 0, 
21j 
where 
f = d+' 
"I'= d1J 
dr 
dr 
With the Christoffel symbols at hand, we can write out the relations 
(5-9.7c). It is convenient to express the results in terms of R/ = g1'"R;..,­
Then 
(5-9.9) 
R/=0, 
A.-:;i: y. 
The consequence of these computations is set forth in the following 
theorem 

376 
TENSOR ALGEBRA AND ANALYSIS 
Theorem 5-9.1. 
The fundamental metric tensor determined by the 
Schwarzschild solution is represented by the components 
1 
0 
0 
0 
'Y/ 
(5-9.lOa) 
(g).y) = 
0 
-r2 
0 
0 
0 
0 
-r2 sin2 () 0 
0 
0 
0 
'Y/ 
where 
(5-9.lOb) 
?)=1-2:'. 
r 
and y is a constant of integration. 
PROOF. 
The equations in (5-9.9) may be solved as follows. 
4 
1 (r;' e') 
R4 - R1 i = er ;; + "f = 0. 
The solution of this separable differential equation is 
M'Y/ = constant. 
By an appropriate choice of the unit of time, this constant can be evaluated 
as 1 ; therefore 
(5-9. l la) 
When this result is substituted into the second of the relations (5-9.9), we 
obtain 
(5-9.llb) 
 [-rr;' + (1 - r;)] = 0. 
r 
The result is an immediate consequence of this relation. 
According to the relation (5-9.lOb), r = 0 is a singular point. We 
assumed that r; > 0; therefore for a positive constant there is a neighbor­
hood, r < y, about r = 0, for which the solution is not valid. 
The Schwarzschild solution may be summarized as a spherically sym­
metric, static solution with the metric of special relativity as the limiting 
metric when r increases indefinitely. 
Mathematically, the effect of the 
gravitational field is expressed by taking the components of the Ricci 
tensor equal to zero. It should be noted that to set the components of the 
curvature tensor itself equal to zero would characterize a flat space and a 
physical situation in which the gravitational field had no effect outside 
the generating matter. 

An introduction to the general theory of relativity 
377 
The general theory of relativity has been given a great deal of credence 
in three experiments concerning the advance of the perihelion of Mercury, 
the deflection of light rays by the sun, and the shift toward the red end of 
the spectrum of spectral lines of light originating in dense stars. We 
examine next the relativistic predictions concerning the first phenomenon. 
It is assumed that the mass of a planet is negligible in comparison to 
that of the sun. Therefore planets can be thought of as moving along 
geodesics in a spherically symmetric static field. The defining equations 
of the motion are 
(5-9.12) 
(a) 
g;.. + r,./ f{'· XP = 0, 
·2 
(b) 
!... + r2fJ2 + r2 sin2 02 - 1)12 = -1, 
1) 
where the · denotes differentiation with respect to the parameter s. 
Observations of planetary motions indicate that the Newtonian pre­
diction for their trajectory is not far from wrong. Therefore the equations 
(5-9.12a,b) should produce certain correspondence with the classical 
results. One such common fact is determined by the following con­
siderations. The last three of the equations in (5-9.12a) may be written out 
in the form 
(5-9.13) 
(a) 0 +  ;(J - sin ()cos 02 = 0, 
r 
(b) ef, +  f + 2 ctn ()(J = 0, 
r 
(c) 
i' + ft= 0. 
1) 
If we assume the initial conditions 
7T 
Oo = -
' 
2 
then from (5-9.13a) it follows that 00 = 0. By differentiation of (5-9.13a) 
and a process of induction we find that 
(k) 
00 = 0, 
k = 1, 2, 3 .... 
Next we write a Taylor series expansion for 0. We have 
(5-9.14) 
(s 
S )1 
() = 00 + (s - s0)fJ0 + 
- 0 00 + · 
· 
· 
. 
2! 

378 
TENSOR ALGEBRA AND ANALYSIS 
Therefore () = TT/2 for all values for which the expansion is valid. It is 
assumed that the expansion can be made at any point along the geodesic; 
therefore () = TT/2 all along it. Consequently, () = 0 along the geodesic. 
This result reminds us that the classical Newtonian trajectory lies in a plane. 
The relativistic result just obtained has the same physical interpretation. 
The first of the equations in (5-9.13) reduces to an identity as a con­
sequence of the constancy of 0. The other two equations take the form 
(5-9.15) 
.. 
2 
. 
(a) 
</> + - fcp = 0, 
r 
I 
(b) 
i' +  fi = o. 
'Y/ 
From these equations we find that 
r2 = h, 
(5-9.16) 
iri = k, 
where h, k are constants of integration. With these results in mind, let us 
make the substitution 
(5-9.17) 
1 
U=-; 
r 
the differential equation (5-9.12b) can then be put in the more convenient 
form 
(5-9.18a) 
(dU)2 + u2 = ). - J'. U + yUs 
d</> 
h2 
' 
where y, )., and hare constants such that 
(5-9.18b) 
A=k2-1. 
h'J. 
Recall that y entered into our considerations in (5-9.lOb) as a constant of 
integration. 
In order to investigate relativistic trajectories of planets, the differential 
equation (5-9.18a) is compared to the corresponding classical equation 
(5-9.19a) 
(dU)2 + us = 2M U + K . 
d</> 
H2 
H8 
In this equation M represents the mass of the. sun. 
(5-9.19b) 
2M 
K=V·V-­
r 

An introduction to the general theory of relativity 
379 
is the total energy and 
(5-9.19c) 
x 
y 
H 
= 
dx dy 
dt 
dt 
is the area swept out by the radius vector per unit time. Since the 
relativistic orbit differs only slightly from the classical orbit, it is assumed 
that the distinction in the differential equations is due to the term U8 and, 
in particular, that 
!.u+k2-1:,2Mu+ K 
hs 
h2 
H2 
H2' 
where :, means approximately equal. This assumption can also be 
implemented by identification of the constants 
h :, H, 
y :, 2M, 
k2 :, K + 1. 
For all the planets other than Mercury the Newtonian prediction of 
the trajectory agrees with observation within the range of probable error. 
In the case of Mercury there is a discrepancy. A slight advance of peri­
helion (or rotation of the elliptic orbit) of about 42" of arc per century has 
been observed and no acceptable explanation on the basis of classical 
theory has been found. 
If in the classical theory we use polar coordinates, as indicated by the 
differential equation (5-9.19a}, and find the extreme values of U(</>), they 
will correspond to perihelion and aphelion. Let (Uv </>J and (U2, </>J, 
respectively, indicate the points of perihelion and aphelion; then U2 < 
U < U1• We find that 
</>1 - </>2 
= 
7T. 
In the relativistic case we make the identifications previously mentioned 
so that the differential equation under consideration is 
(5-9.20) 
(dU)2 + U2 :, K + 2M U + 2MUa. 
d</> 
H2 
H2 
Theorem 5-9.2. The relativistic prediction of the advance of perihelion 
is (6 TT M)/[a(l - e2)] per revolution of the planet, where a represents the 
semimajor axis of the elliptic trajectory and e represents its eccentricity. 
PROOF. 
If the term U2 is put on the right of (5-9.20) and the zeros of 
the cubic polynomial are denoted by U1, U2, and U3, then (5-9.20) can be 
expressed in the form 
(5-9.21a) 
(dU)2 
d</> 
:, 2M(U - U1)(U - U2)(U - U3). 

380 
TENSOR ALGEBRA AND ANALYSIS 
The relation (5-9.2Ia) can be written23 
d.1. ..!. 
dU 
-
 
{(U1 - U)(U - U2)[1 - 2M(U + U1 + U2)]} 
If it is desired to integrate this expression from U1 to U1, the integration 
is expedited by the substitution 
U - U2 
a 
--_=sin'{J. 
U1 - U2 
We find tha` 
* ir/2 
2d{3 
a-b= 
. 
I 
o 
[1 - 2M(U1 + U2 + U1 sin2 f3 + U2 cos1 {3)]!-t 
By expanding the integrand in a binomial series and dropping the higher 
degree terms, we have 
i7r/2 
t/>1 - t/>2 ( 
0 2[1 + M(U1 + U2 + U1 sin2 f3 + U2 cos2 {3)] d{J. 
As a consequence of the half-angle formulas, 
. 2 f3 
1 - cos 2(3 
2 f3 
1 + cos 2(3 
SlO 
= 
, 
COS 
= 
, 
2 
2 
we obtain the resultM 
Therefore 
t/>1 - t/>2 ( '1T + !M'fl'(U1 + U2) 
2 
= '1T + }M'fl' --­
a(l - e2) 
6'1TM 
2(</>1 - ) = 2'1' + a(l - e2) 
This concludes the proof. 
11 If the polynomial to which (dU/dt/>)1 is equated is set equal to mro, that is, 
1 
1 
K 
u•--u•+-u+--=O 
2M 
H1 
2MH1 
' 
the sum of the roots is equal to the negative of the coefficient of u•, that is, 
1 
ui+u.+u,=2M. 
" If c represents the distance from the center of the ellipse to a focus, then 
r1 = a + c = a + ae, 
r1 = a - c = a - ae. 
Therefore r1 + r1 = 2a, 
r1r1 = a1(l - el). 

An introduction to the general theory of relativity 
381 
In the case of the planet Mercury the discrepancy between observed 
results and the Newtonian prediction is close to 67TM/[a(l - e2)] so 
that it appears that the relativistic prediction is the better of the two. 
Problems 
1. (a) The equation a;.[µ(dX''fds)] = 0 is called the relativistic continuity 
equation in discussions of special relativity. The generalized form of 
this equation is obtained by replacing partial differentiation with 
covariant differentiation. If µ is a scalar density of weight -1, show 
that V;p (axA/ds) 
= 0 reduces to the partial derivative form. 
(b} If 
show that 
-
-
-
dX;.dX"I 
µ 
= µ0 v' lgl 
and ,,,.,, 
= v' lgl M;..,, = v' lgl µo ds ds ' 
;. 
D(dXY/ds) 
V,.M,, = µo 
ds 
• 
2. (a) Compute the Christoffel symbols listed in (5-9.8b). 
(b) Derive the equations in (5-9.9). 


answers to odd-numbered problems 
Chapter 1 
SECTION I 
1. (a) I, J, 0. 
3. -2, -5, l. 
5. vi4, sv3, v11, respectively. 
7. Components 0, 0, 0 magnitude 0. 
9. Hint. Make use of the corresponding properties of real numbers. 
11. /J(A1, · ·
·
, An) = (O · · · 0). 
According to the definition of equality of 
n-tuples, (3Ai 
= 0, i = 1 · · · n. Since f3 >6 0, it follows that Ai = 0 for 
all i. 
1 
r 
rq 
13. Since A = pC, B = qD, A 
= rB, one has C 
= - A 
= - B 
= - D. 
p 
p 
p 
15. If two sides of a triangle with a common vertex are represented by arrows A 
and B, the third side is represented by B - A. Midpoints of the original 
sides are at the tips of A/2 and B/2. Hence their join is represented by 
(B - A)/2. It has magnitude t(B - A). 
J1ov6 
640 
17. 
' 
. 
1 + vJ 
I + vJ 
19. (a) 
x1 = 1 - t 
x2 = s + 4t 
x3 = J + 6t 
X1 - l 
X2 - 5 
X3 - J 
--=-1 
= -4-
= -6-
J8J 

384 Answers to odd-numbered problems 
21. r2 - r1 = B(t2 - t1) = B M. 
The magnitude lr2 - r11 is dependent on 
M but not on particular 11 and 12• 
SECTION 2 
1. 
A1 A2 
A3 
Bl 
B2 
Ba 
ci 
c2 
ea 
2 
3 
2 
-5 
1 = 0. Therefore the n-tuples are linearly 
0 
-11 
dependent. 
3. 
2 
3 
3 
5. 
2 
-3 
/ 0. 
5 
-1 
5 
2 
03 
4 
6 
7 
/ 0. 
Therefore the arrows are independent and not 
4 
coplanar. 
7. X=t, Y=i. 
9. Assume that Pi. P2, P3, and P4 are coplanar points. Let r1, r2, r3, and r4 be 
position arrows from an origin outside the plane to these points. Then 
r1 - r2 = 1X(r3 - r2) + /3(r4 - r2). 
Therefore: r1 = pr2 + qr3 + sr4, where p = 1 - IX 
- /3, q =IX, s = {3. 
Conversely: r1 = pr2 + qr3 + sr4,p + q + s = 1 
implies that 
r1 = (1 
- q - s)r2 + qr3 + sr4 
or 
This last relation indicates the coplanar nature of the end points of the 
arrows. 
I 
/ 
1 
I 
/ 
I 
// 
I 
/ 
· 
P2i
 P3 
I 
I 
/ 
,, 
0 

Answers to odd-numbered problems 
385 
11. (1, 3, S) = a(O, 2, 1) + {J(-2, 1, 4) + y(l, 3, 2), 
IX 
= -t. {J = f, y = i. 
13. The validity of the relation (A + B - 3)X +(-SA -
2B -
2) = 0 on an 
interval of real numbers leads to the conditions A + B - 3 
= 0, 
-SA -
2B -
2 
= 0 on A and B. 
SECTION 3 
(1 
( 
· 
_ k 
_ 
· T 
• 
J -
's - p,j r- s, 
1. (a) 81, (b) f, -!. 0, (c) oH:p) = ..;.l 
if 
j = p, s = k,j ""'s, 
0 
otherwise. 
(d) 0CkPJ 
= i cok" _ o"kJ = _1£o"k 
_ ok"J 
= _0(,,kl 
h 
"2" 
N 
h 
"2" 
H 
H 
H 
• 
(e) 15[kp) - l[o .ko p - 0 Po k) - 1(0 .ko p - 0 ko .P) - 0kP 
i• 
- "2" ' 
• 
i 
• 
- "2" ' 
• 
• ' -
[Js]• 
3. Upon completing squares, we have 
(Xi _ 3)2 + (X2 + 1)2 + (Xa _ 4)2 
= 1. 
Therefore 
xi = xi - 3, X2 = X2 + 1, X3 = X3 - 4. 
5. See Example 1-3.7. 
( 
1 
s ) 
3vj -
1. (a) 
- vz, vz, o . (b) 1 - -2-, 
v
3 + !. 
9. (b) (A/) 
 ( -v! T ;) . Not•. u., A;' - a,'. 
(c) Comparing with (l-3.23c), we note that cos 0 = l, sin 0 
= -VJ/2 . 
Therefore 0=-1T/3 and the coefficients represent a clockwise rotation 
of 1T/3 radians of the Xi system from the X' system. The rotation 
is in the plane X3 = 0. 
11. O = Xi - Xii - Bit = aki Xk - aki Xik - aki lJkt, where JJk = X2k - Xik 
Therefore 
0 
= aki(Xk - Xik - lJkt). 
Upon multiplying by Al, we obtain 
o = ok"(Xk - Xl - JJkt) = XP - Xi" - JJPt. 
SECTION 4 
LOO 
)=*+,-.+/0+12 
Therefore 
ui = O(l) + 1(0) + 0(0) = 0, 
U2 = -l(l) + 0(0) + O(O) = -l, 
U3 = om + 0(0) + 1(0) = 0. 
3. (a) 
Xai - Xii= X2i + Xoi - (Xii + Xoi) = X2i -Xii· 
3 
3 
Therefore 
d2 
= ! (X21 - Xi1)2 = ! (Xi - X1')2, 
j=l 
j-1 

386 Answers to odd-numbered problems 
and it is seen that the algebraic form for d2 is not dependent on the 
particular rectangular Cartesian coordinate system. 
(b) According to (1-4.1) we have U' = 01. Therefore the components are 
scalars under translation. 
SECTION 5 
1. A· B 
= -28, A· A = 38, B • B 
= 69. 
3. (a) A rotation of -rr/6 radians in the X1 X2 plane. 
(b) .A· D = -14. 
-
v'3 
1 
v'3 
1 
(c) A1 
= ak1Ak 
= 2(3) - z(5), 
B1 
= 2(2) - zC-4), 
1 
v'3 
B2 = 2(2) + 2< -4). 
(d) A· B 
= -14. This result should have been expected since A· B is an 
invariant with respect to rotations. 
5. A· B 
= 10 - 6 - 4 = 0, therefore the vectors are orthogonal. 
7. E1 
• E2 
= (A + B) · (B - A) 
= B • B - A • A = 0, 
Since A and B have equal magnitudes. 
9. The directions of the lines are determined by (2, 7, -4) and ( -6, 2, t). We 
have -12 + 14 - 2 = O; therefore the lines are perpendicular. 
11. (3L1 + L2 - 5L3) · ((X1 + 2)L1 + (X2 - 4)L2 + (X3 - l)L3] = 0, 
i.e., 
3(X1 + 2) + (X2 - 4) - 5(X3 - I) 
= 0. 
13. Their normals are perpendicular. 
15. 
d = 1 2(1 - 3) - 5(2 + 1) + 3(-1 - 4) I 
= 34 
. 
v' 4 + 25 + 9 
v'38 
17. sin2 (J 
= 1 - cos2 (J 
= 1 
SECTION 6 
(P · Q)2 
(P · P)(Q · Q) - (P · Q)2 
(P · P)(Q · Q) 
(P · P)(Q · Q) 
1. Consider the expression &81,a/a/akr· Because s and t are dummy indices, 
we may replace this expression by either &JJqra/a/akr or &q1Jra/a/akr· 
Considering the second of these and employing the fact that &q1Jr is skew 
symmetric in q and p, we have (also note that a/al = a/a/) 
Taking into account the opening remark of this proof, we conclude that 
and therefore 

Answers to odd-numbered problems 
387 
3. Proof of (1-6.11 b) : 
Eiik&;;q = EJik&i;q + £2ik&2Jq + £3ik&a;q 
= (£12k&12q + £l3k&13q) + (£2lk&21q + £23k&23q) + (£3lk&31q +£32k&32q). 
Examining the three parenthetic expressions, we see that if q °" k every 
term is equal to zero. For q = k there are two nonzero terms and each 
has the value 1. For example, if q = k = 3, then E123&123 = E213&213 = 1, 
we conclude that Eiik&;;q = 26/. Equation 1-6.l l c  can be verified by 
writing out the summations. 
5. fJiPfJkq&pq = fJilfJkl&11 + fJi2fJkl&21 + fJ11clk2&12 + cli2clk2&22 
= cli2clkl&21 + clilclk2&12
. 
For j, k = 1, 1; 1, 2; 2, 1; 2, 2, we obtain values 0, 1, -1, 0. This 
completes the proof, since E11, E12, E21, and E22 have values 0, 1, -1, O 
respectively. 
7. Express the third-order determinant in the form 
- 2_ £iik£Pqr 
a - 3 ! 
a;1P;qakr· 
Use the method of replacing dummy indices indicated in the answer to 
Problem 1 with the information auv = -avu to conclude that a = -a, 
hence a= 0. 
1 
. 
. 
9. (a) a = - & · 
• • •  · E81 · • 
• 
8na 
'1 
· · 
· a 
•n 
n ! 
t1 
tn 
81 
Bn 
or 
1 
. 
. 
a = - E»" · ·•n£•1 · · 
· •na. 
. . .  0. 
n ! 
tnBn 
1.nBn • 
(b) Yes: prove that any skew symmetric determinant of odd order has the 
value zero. 
11. bB = c where c is the numerical value of a determinant with elements 
b/Bk
P = c/. 
0 
0 
In this case c/ = cl/ and 0 
0 
= 1. 
0 
0 
SECTION 7 
3 
1. (a) p X (Q + R) = I &ikrl;Pk(Qr + Rr) = I &ikrL;PkQr 
j=l 
j 
3 
+ I &ikrl;Pk Rr = (P X Q) + (P X R). 
j 
(b) cx(P X Q) = ex L &ikrL;PkQr = L &ikrL;(cxP"')Qr. 
j=l 
In both parts (a) and (b) the proofs depend on the corresponding real 
number properties. 

388 
Answers to odd-numbered problems 
3. Area 
= IA x BI 
= v (A x B) · (A x B), 
A x B 
= 
5 
-2 
3 
= 7L1 - 2l2 - 13l3, 
-3 
IA x BI 
= v222. 
--+ 
--+ 
S. The plane is spanned by the arrows P1P2 and P1P3, hence is orthogonal to 
their cross product. 
 
--+ 
P1P2 
x P1P3 
= 
-1 
-1 
-1 
0 
-2 
-2 
The equation of the plane is 
-2(X2 - 2) + 2(X3 - 5) 
= 0. 
7. The cross produced is anticommutative: therefore 
M 
= r x F 
= -F x r 
= -M'. 
li 
9. (a) Compute 3 
7 
5 
-2 
= 2h1 - 2312 - 26l3 
3 
3 
The parametric equations of the desired line are 
x1 = 1 + 21µ 
x2 = s - 23µ 
X3 
= 2 - 26µ 
(b) The assumption that the two lines have a point in common (say with 
coordinates X01, X02, X03) leads to the inconsistent set of equations 
1 + 3!0 
= 7s0, 
2 + 5t0 
= 4 + 3s0, 
3 - 2t0 = 2 + 3s0• 
That these equations are inconsistent can be seen by solving two of them 
for t0 and s0 and then showing that the solutions obtained do not satisfy 
the third equation. 
(c) The desired line has direction numbers (21, -23, -26) [see part (a)]. 
Its parametric equations may be written 
X1 = X01 + 21µ, 
X2 = X02 - 23µ, 
X3 = X03 - 26µ. 

11. 
Answers to odd-numbered problems 
389 
Suppose this line has P1 in common with the line expressed through the 
parameter t and that µ = 0 corresponds to the point of the line in 
coincidence with the second given line. Then we can form the equations 
1 + 3t1 = X01 + 21µ1 
7s0 = X01 
2 + St1 = X02 - 23µ1 
4 + 3s0 = X02 
3 - 2t1 = X03 - 26µ1 
2 + 3s0 = X03 
This is a set of 6 equations in six unknowns. In particular the values 
obtained for X01, X02, X03 complete the desired information. 
2 
-5 
P•QXR= 
1 
3 
3 
1 
0 = 3, 
3 
PxQ·R=R·PXQ= 
2 
-1 
5 
3 
0 
The two determinants differ by an even number of intercharges of 
rows, hence have the same numerical value. 
SECTION 8 
1. The scores from a three-set tennis match might be listed as follows: 
3. 
A probability matrix in genetics might have the form 
D 
D(l 
H t 
R 0 
H 
R 
0 
t 
0 
The reader should be able to construct many other examples. 
v'2 
v'6 
v'2 
2 
4 
4 
v'2 
v'6 
v'2 
2 
4 
4 
v'3 
0 
2 
2 

390 
Answers to odd-numbered problems 
5. Yes. 
13. (a) P x (Q x R) = P x 
2 
-3 
0 
4 
2 
= -l6L1 
- 48L2 - 44L3. 
(b) According to (1-7.17a), 
1 
-4 
-10 
-4 
4 
8 
P x (Q x R) = Q(P · R) - R(P · Q) = (2L1 - 3L2 + La)( -8) 
-(4L2 + 2L3)18, 
= -l6L1 - 48Lz -44L3. 
15. Consider L1 x Q 
= L3. Let Q = L2 and L1 + Lz, in turn. 
17. If A· B =A· C for any A, then B =C. 
. 
I 
(r1 - r0) 
B I 
19. 
h = lr1 - r01 sm 8 = lr1 - r01 
lri 
_ rol 
X IBI 
= I (r1 - r0) x ,:11. 
I 
I 
I 
I 
Pi 
I 
/ 
h 
/r1 
Po 
6 
\ 
I 
\ 
I 
ro\ 
/ 
\ 
I 
\ 
I 
v' 
p 
I 
I 
I 
21. If B = ixA, then I A . A 
A . BI = A · A 1
1 
B·A 
B·B 
IX <XI 
= 0. 
<X2 
If I 
A • A 
A • BI 
= 0, then (A x B) • (A x B) = 0 and A X B = 0. 
B·A 
B·B 
If A or Bis a zero vector, the dependence is immediate. If A ¥= 0 and 
B ¥= 0, then IA x BI 
= IAI IBI sin 0. 
Therefore sin 8 = 0 and 8 = 0 
or TT. 

Chapter 2 
SECTION 1 
Answers to odd-numbered problems 
391 
1. (a) The orthogonal projection of the curve into the X1, X2 plane is that part 
of the hyperbola (X1)2 - (X2)2 = l lying in the first quadrant. The curve 
makes a constant angle with the X2 axis and is called a helix. 
(b) The orthogonal projection of the curve into the X1, X2 plane is the 
circle (X1)2 + (X2)2 = a2; X3increases exponentially and without bound. 
(c) This is a segment of the curve of part (b) determined by the inequality 
1/e ! X3 !e. 
(dX1 dX2 dX3) 
3. (a) 
dt , dt , dt 
= (sinh t, cosh t, 1) 
(dX1 dX2 dX3) 
(b) 
= (-a sin t, a cos t, et) 
dt ' dt ' dt 
(c) 
= (-a sin t, a cos t, esin t cos t) 
(dX1 dX2 dX3) 
dt ' dt ' dt 
5. Proof of (2-1.Sa): 
dU + V 
= lim {[U(t + h) + V(t + h)] - [U(t) + V(t)]} 
dt 
h-0 
h 
_ . L-(t + h) - U(t) 
V(t + h) - V(t)J 
-hm 
h 
+ 
h 
h-0 
. 
U(t + h) - U(t) 
. 
V(t + h) - V(t) 
dU 
dV 
= 3 
+3 
=-+-
h-o 
h 
h-o 
h 
dt 
dt 
The validity of the limit theorem for vector sums is a consequence of the 
corresponding theorem for sums of functions. 
Proof of (2-1.Sb): 
d(U · V) 
. 
U(t + h) • V(t + h) - U(t) · V(t) 
d 
= hm 
h 
. 
t 
h-o 
The proof can be completed by adding and subtracting U(t) • V(t + h) 
in the numerator of the difference quotient and regrouping and employing 
the limit theorems for products and sums. Proofs of (2-1.5c,d) follow the 
same pattern. 
7. V • V = c; c is a constant. Therefore 
dV·V 
dV 
dV 
dV 
""df = V 
. dt + 
dt 
• V = 2V . dt = 0. 
Since V _,, 0 and dV/dt _,, 0, they must have perpendicular directions. 
9. Parametric equations of the tangent line at v2, 3/ v2, 7r/4: 
-
-
3 
3 
7T 
xi = v2 - v2u, 
x2 = v2: 
+ 
v2. 
u, 
X3 = 4 + u. 

392 
Answers to odd-numbered problems 
Osculating plane at (.Yi, 3/ ¥2, 1T/4): 
11. x1 = 
u, 
SECTION 2 
3. (a) ¥2, 
(c) 1, 
-
3 
1T 
x1 - .Y2 x2 ---= xs --
-¥2 
-.Y2 
x2 =O, X3=0. 
(b) .Yt + 4t2 + 9t4, 
(d) .Y2 + cos2 t. 
3 
.Y2 
3 
.Y2 
4 
.Y2 
0 
=0 
5. 
drdt 
1 = '!_ • dr = (dr . dr) (,)2. 
ds ds dt dt ds ' 
dr 
Therefore 
(dt)2 = (<!. . <!.)-1. 
ds 
dt dt 
These relations and straightforward application of the rules of differen­
tiation lead to the results. 
2 
4(1 + 9t2 + 9t4) 
7, (a) Kz = 0, T = 0, 
(b) K = (1 + 412 + 914)3 
3 
T = } + 9t2 + 9t4 
1 
(C) K2 = 2 , T = 0, 
a 
2 
2 sin2 t 
(d) K = (2 + cos2 t)3 
9. Curves a, c, and d have T = 0, hence are plane curves. This means that each 
lies in its own osculating plane. 
(a) X3 = 0 X2 = 1T/4 + u, 
X2 = 1T/4 + v, 
(X
. 
1 = (I + 1T/4) + u, \X1 = (1 + 1T/4) - v, 
(b) 
xi - + 
4 
0 
X3 
= 0, 
X8 = 0. 
x2 - (r 
xa - (r 
2 
3(i)2 
2 
=0, 

Answers to odd-numbered problems 
393 
fr 
X1=-+u, 
4 
(c) X8 = 0 { 
1 
x1 = -
2' 
x2 = -u, 
X3 =0, {x1 =  - 2v, 
x2 =O, 
X3 =0. 
(d) 
xi - ?!: 
x2 - 
 
4 
4 
1 
0 
fr 
X1=-+u 
4 
' 
fr 
X2=-+u 
4 
' 
1 
0 
1 
1 
xs = 
v'2 + 
v'2 u, 
SECTION 3 
1 
xa--= 
v'2 
1 
v'2 
= 
0 
1 
- v'2 
fr 
x1 =4· 
fr 
x• =4, 
1 
1 
xs = 
v'2 -
v'2 v. 
1. (a) V = -sin 11.i + cos tL2 + L3, 
a = -cos 1'1. - sin tL2• 
(b) V ·a == 0 for all t3 therefore Vand a are perpendicular vector fields. 
(c) 7' = -!. 
(d) s = J: v'2 dt = v'2 t. 
3. (a) r = (1 + t2)1.i + tL2, 
(b) r = tL1 + t2L2 + t3L3, 
V = 2t'1_ + l2; 
V = 'i + 2flz + 3t2L3, 
a = 2L1• 
a = 2tLs + 6tLa. 
The expressions for r, V, and a in parts (c), (d), (e), and (f) are produced 
by straightforward differentiations following the pattern given above. 
dr 
d2r 
5. 
r = r0 + Bt, 
V = - = B 
a = -= 0 
dt 
' 
dt2 
7. (a) 
r = 3 cos t1.i + 3 sin tL2 + tL8, 
V .. -3 sin ILi + 3 cos tL2 + L3, . 
a = -3 cos tL1 - 3 sin tL8, 
rxa 
(b) -1 --1 =sin 11.i - cos tL2 
rxa 

394 
Answers to odd-numbered problems 
(c) The path of motion is a circular helix. 
V•a 
(d) cos 0 = lvl lal = O; therefore v 
and a are perpendicular. 
9. Take the dot product of (d2R/d02) = ixR + (JP and R; since R • R = 1 and 
d2R 
R • P = 0, it follows that ix = R · d02 
• Since P · (d2R/d02) = 0, a similar 
procedure produces the result (J = 0. 
11. (a) r = ebtR, 
V = bebtR + ebtP, 
a = (b2 - l)el'tR + 2bebtp. 
Corresponding results are obtained for parts (b) and (c) by making direct 
substitutions in (2-3.Sa) and (2-3.Sb). 
SECTION 4 
1. (a) X1 = A/ Xi + X01 = (2 + 3t) + t = 2 + 4t, 
g2 = (1 + 4t) cL+ (3 + St) sin() + (1 + 2t), 
X3 = -(4 + 4t) sin() + (3 +St) cos 6 + (2 + 3t). 
dAk1 
dXk 
dXl 
dX1 
dX01 
p1 = dt Xk + Aki dt + dt = dt + dt = 3 + 1 = 4, 
d() 
"P2 = [ -(1 + 4t) sin 6 + (3 + St) cos O] dt + 4 cos 6 + S sin 6 + 2, 
d6 
i78 = [ -(1 + 4t) cos 6 
- (3 + St) sin 6] dt 
- 4 sin 6 + 5 cos 6 + 3. 
d2Ak1 
dA i dXk 
d2Xk 
d2X.1 
al= -- Xk + 2 -k 
___ +A i  
__ +--o = 0 
dt2 
dt 
dt 
k 
dt2 
dt2 
' 
(d())2 
d6 
d2 = [ -(1 + 4t) cos 6 - (3 + St) sin 6] dt 
+ 2( -4 sin 6 + 5 cos 6) dt 
d26 
+ [ -(1 + 4t) sin 6 + (3 + St) cos 6] dt2 
(d6)2 
d6 
a3 = [(1 + 4t) sin 6 - (3 + St) cos 6] dt 
+ 2( -4 cos 6 - 5 sin 6) dt 
. 
d 26 
+ [(1 + 4t) cos () -(3 + St) sin 6] dt2 
• 
(w;k) = (  ) 	. 
0 
-1 
0 
wP =  £Pikwik 
. . 
(wl, w2, w3) = (' 0, 0)
. 
The corresponding values for part (b) are obtained by substituting into 
(2-4.3b), (2-4.3c) (2-4.4a), and (2-4.6a). 

Answers to odd-numbered problems 
395 
3. iwr q<»qr = t ! WrqWqr = ! ! &.,rqw"&.,qrw" 
r,q 
r,q 
= - !&,.qrE"q'w"w,, = -b{w"w,, = -w"w.,. 
5. Substitute into (2-4.13a). 
SECTION 4• 
., 
* 
dBl' 
* oXPd(oXP/iJXk) 
1. (a) w k =,,:,, B/-- = ,,,:,, --;;-: ---
P 
dt 
p ax• 
dt 
ax11 oX" d[(oXP/iJXr)(axr/oXk)J 
= t oX" ax' 
dt 
= 
oXP a-:q [d(iJXP/iJX') a:r 
+ oXPd(iJXr/iJXk)J 
t oX" oX' 
dt 
iJXk 
axr 
dt 
oX" axr 
oX" d(iJXr/iJXk) 
=--;;-----=- Wqr + bqr-=-: 
• 
ax• axk 
ax• 
dt 
Since the transformations are orthogonal Cartesian rotations, axq/ 
ax• = a'Xtt oX", and the result can be written in the form (2-4• .7). 
(b) The set of equations (2-4•.5) is solved for the W:1" by summing and 
multiplying with oX•/ oX1, then iJXk/ oXt. Finally we employ the relation 
obtained by differentiating (iJXk/oX1)(oX"/oXk) = t"· 
3. The rotational velocity components DX'fdt have vector character. When 
U1 is replaced in (2-4•.9) with these components, we obtain 
D2Xi 
d (DXi) 
. DX' 
--=- -- +w.i--
dt2 
dt
dt 
'dt" 
If DXi/dt is replaced in the right-hand member according to (2-4•.9) we 
obtain (2-4•.2b). 
SECTION 5 
1. If h = 0 then the motion is linear 
dL 
3. dt 
= H = 0. Therefore L is constant. 
SECTION 6 
1. The galilean transformations have the linear form 
X' = X' - v't, 
l = t. 
Therefore vector components !Ji transform according to the law 
ax1 
!Ji = 
_ Bk = <5 i Bk = Bi 
and 
iJXk 
k 
' 
Xi - (Jl0i + !Jil) = Xi - vit - (X0i - vit + Bit) 
= Xi - (X0i + Bit). 

396 
Answers to odd-numbered problems 
3. 
-z2 + t2 = -(z + vf)2 + i2 = -(z)2 - 2vU + (1 - v2)l2. 
!. If h""/J dX"" dXfJ = TiAy dX" dXY, then by employing the transformation law 
of the differential we obtain 
7. 
aXA aXY 
h""fJ dxa. dXfJ = ""Y axa. axP dxa. dXfJ 
or 
( 
a.KA aXY ) 
h""/J 
- ax"" axP TiAy dxa. dXfJ 
= o. 
Since this expression holds for all sets of differentials dX1, • 
• 
• , dX', 
it follows that the parenthetic expression is identically zero. 
Ifz/t = 1,-thm_ 
z 
z - vt 
t 
= -vz + t 
z/t - v 
-vz/t + 1 · 
z 
1 - v 
-=-
.
-= 1 . 
i 
-v + 1 
9. Differentiation of h""p(dX«/ds)(dXfJ/ds) = 1 with respect to s leads to the 
form 
d2X«dXfJ 
h,.p ds2 ds ... 0. 
When this expression is multiplied by m0, we obtain according to (2-6.9a) 
' dXfJ 
or 
Chapter 3 
SECTION l 
1. X1 = v1, 
h,.pF,.E 
= 0, 
1 
xa 
= - {A3 x 3 + Al(X 1 - v1) 
A3 
o 
o 
(
:;':) -(: 
The origin is a singular point of this representation. 

3. (a) {X1 = 3 sin t cos 2t 
X2=3sintsin2t 
X3 = 3 cost. 
I 
, 
I 
I 
I 
I 
-------t
---{ 
__ _ 
Answers to od-numbered problems 
0 = t 
"' 
0 
0 
'1r 
'1r 
8 
4 
'1r 
'1r 
4 
2 
,,"" 
I 
/ I 
... , 
" 
I 
/ 
I 
' 
y 
__ ..J._ ____ _ 
3'1r 
3'1r 
/ 
I 
, 
I 
/ 
I 
/ 
/ 
{vl = 0 
5. Make the identifications 
2 
v =</>. 
8 
'1r 
2 
3'1r 
4 
'1r 
<5vl 
<5v2 
Meridian</> = </>0: <50 = 1, 
<50 , 
4 
'1r 
3'1r 
2 
2'" 
curve</> = In tan (; + 	), 
dv1 
dO 
= l, 
(dv2/d0) = sec 0 
dr 1/ dO • dr 2/ dO 
g a.fJ( <5v"' / dO)( <5vfi / dO) 
ldr1/dOI Jdr2/dOJ = [gA/dvA/dO)(dvµ/dO)]'A[gY'l(ovY/dO)(ov"/)dO]'A. 
The result follows upon substitution into this relation. 
7. Parameter transformation: *v1 = a sin v1 cos v2 
*v2 = a sin v1 sin v2 • 
--
= 
= a2 sin v1 cos v1. 
I 
a*v"' I I 
a cos v1 cos v2 
a cos v1 sin v2 I 
avfi 
-a sin v1 sin v2 
a sin v1 cos v2 
391 
The domain of definition for the transformation involving the upper 
hemisphere cannot include v1 = 0 or v1 = '"/2 . 

398 
Answers to odd•numbered problems 
SECTION 2 
2x1 
2x2 
2X3 
2x1 
2x2 
2X3 
l, (a) -2 l1 + - b2 L2 + -2 l3, 
a 
c 
(b) -2 L1 + -b2 L2 - -2 L3, 
a 
c 
2x1 
2x2 
2X3 
(c) -2 l1 + -b2 L2 - -2- l3, 
a 
c 
1 
3. V<l> 
= 2r, 
a 
V'I' = 2r; 
1 
therefore V<l> = 2
a
2 V'I'. 
5. The tangent plane may be expressed in the form V'I' · (r - r0) = 0, in 
particular (V'l')1,1.t = tL1 + L2 + L3; 
therefore the equation of the 
tangent plane is 
!(X1 - 1) + (X2 - 1) + (X3 - t) = 0. 
7. V<I> = 2X1L1 + 2X2L2 + 2X3L3 = 2r. 
of 
of 
f 
(of ou 
of 
ov ) 
9• V/ = ax1 Li + oX2 l2 + oX3 la 
= 
ou oX1 + ov ax1 Li 
(of OU 
of ov ) 
( f OU 
of ov ) 
ou oX2 + ov ax2 
l2 + OU oX3 + ov axs 
la 
of 
ar 
= - Vu + --'-- Vv. 
ou 
ov 
(dx1 dx2 dx3) 
( 
o<l> 
o<l> 
) 
11. 
ds ds ds 
= 
cos 8, sin 8, ax1 cos 8 + oX2 sin 8 . 
SECTION 3 
l
drl [ 
(a<1>)
2 
(0<1>)
2 
o<l> o<I> 
JJ.i 
ds 
= 
1 + oXl 
cos2 8 + oX2 
sin2 8 + oXl oX2sin28 
1. We prove (3-3.2a) 
a 
a 
a2 
V • V x U 
= - E;;k - U 
= Eiik 
. U 
axi 
ax1 
k 
ax• ax1 
k· 
The indicator Eiik is skew symmetric in i and j and o2/ oX1 oX1 is a 
symmetric operator with respect to i and j, therefore 
V·VX U 
= 0. 
ofGi 
of 
. 
oGi 
3
. 
V·(fG) = oXi = ax1G' +f oXi =Vf·G +fV·G. 
(n = 2). 

Answers to odd-numbered problems 
399 
Oa•r 
Oa•r 
aa·r 
7. V(a . r) = l1 ax1 + l2 ax2 + la axa 
= a1li + a2l2 + a3l3 =a, 
since 
aa;Xi 
a· r = a1X1 + a2X2 + a3X3 and 
ax; = a; 
(no sum on j). 
9. We prove that the expression of part (a) is of vector character. Consider the 
rotation equations Xi = ak; Xk where the ak; are constants. The com­
ponents of V x (V x U) are-
Ei;P a.& 
aqur-£iiPA.•aE aqatarOv 
' pqr 
-
' 
s pqr t 
v 
= £iiPA.• a e 
A" atOv =a i£CSU a E 
";itOv 
1 
s u tv 
v 
c 
s u tv 
• 
Note that a; 
= a/ axi, a; has the same meaning, and 
SECTION 4 
1. (a) 
( sin 0 cos <f> 
sin (J sin <f> 
= 
r cos (J cos <f> 
r cos (J sin <f> 
-r sin (J sin <f> 
r sin (J cos <f> 
(b) 
I :1 
= 
,
2 sin o. 
cos (J ) 
-rinO . 
(c) Those coordinate triples for which r = 0 or 0 = 0 or 0 = 1T. 
sin 0 cos</> 
cos Ocos <f> 
r 
(d) 
C'fk) 
sin (J sin</> 
cos (J sin <f> 
ax' 
r 
sin 8 
cos(} 
r 
sin</> 
---
r sin 8 
cos</> 
r sin(} 
0 
(e) Perform the row by column multiplication of (aXi/aXk)(aXP/aXi) and 
obtain (c5kP). 
ar 
ar axk 
(f) r; = ax; 
= axk ax; · 
Therefore 
ax1 
ax2 
ax3 
i'1 = l1 agi + l2 agi +la agi = l1SinOcos<f> + l2Sin0sin<f> + l3 cos 8. 
i'2 and i'3 are computed in a similar manner. The expressions r1 result 
i'· 
i'; 
from r1 = gikrk, whereas e; = lr,
'·I 
= --= . 
v'/;; 

40 
Answers to odd-numbered problems 
3. Let (A/) be defined so that A/( oXi/ iJXk) = 6k'P; then 
aX' 
= 
= 
= 
oXP 
A.P dXi = A·P--dXk = 6k'P dXk = dXP = --dXi 
' 
' axk 
aXi 
. 
From this relation we obtain 
( A;P -:;) dXi = 
0 
for arbitrary sets dXi. Therefore 
iJXP 
Al= aXi · 
5. The properties in (3-4.4a,b) are satisfied, since for the rectangular Cartesian 
transformations iJXi/iJXk = ak; are constant and la/I = 1. 
7. According to (3-4.l Sa), O; = K;kOk, If we multiply and sum this expression 
with gil!,-.then giPO; = giPg;kOk = 6kPUk = OP, as was to be shown. 
9. (a) We need to demonstrate that ri · i';, = 6k'· This can be done by straight­
forward computation. For example, 
whereas 
(b) e1 • e2 x e3 = 
1. 
(c) i'1 • i'2 x i'3 
= I ::I 
· i.e., the Jacobian of transformation. 
11. K;k = i'; • ik. 
The symmetry follows from the commutivity of the dot 
product. According to (3-4.20a), a similar remark can be made for g•k. 
_ 
ax1 
= 
ar ax'P 
= 
= 
ar 
= 
_ 
13. (a) Uii =  Uk--;--. = 6k'Pljk--;;- = Ukr . 
1 
iJXk 
iJXP 0X1 
iJXP 
k 
The proof of part (b) follows the same pattern. 
SECTION 5 
l. (K;k) = ( 0
0
1 	2 
 ) , 
0 
r2 sin2 8 
e1 
a 
e2 
a 
e3 
a 
v = -- +---- +----
..;Kn °X1 
..; K22 °x2 
..; ff33 aX3• 
Therefore the result follows by direct substitution. 

Answers to odd-numbered problems 
3. (a) 
0 
0 
g= 0 p2 0 =p2. 
0 
0 
(b) 
0 
0 
g= 0 ,2 
0 
= r' sin2 8. 
0 
0 
r2 sin2 8 
5. Upon substitution into (3-5.17b), we obtain 
-
-
1 
-
-
(a) V • W = 
-
(b) V • W = 0, 
p' 
-
-
1 
1 
(c) V • W = - - cos 8 + - sin 8. 
p 
p 
1 
401 
_. 
_ 
_ _
1
_ { o[r2 sin 8( o<I>/ or)] 
o[sin 8 ( o<I>/ 08) 
o[Sii 8 (o<I>/ 08)} 
7• v V<l> 
- r2 sin 8 
or 
+ 
08 
+ 
08 
9. According to (3-5.6a) 
_ 
I 
oXI oXP ox• oxt = 
I 
oXI I 
ox, -
-
E;kq = 
oX oX; oXk oXq E,,st = 
ox 
oX E;kq = E;kq 
as was to be shown. The verification in part (b) follows the same form. 
SECTION 6 
2 
( o2f \2 
o2f 
o2f 
1. B - AC= ox1 ox2J - (ox1)2 (0X2)2 
o2f 
= o 
- 2(2) = 
-4, 
A = 0x12 = 2 > o. 
of 
of 
ox1 = 2x1 - t, 
ox2 = 2x2. 
(X1, X2) = (}, 0) is a critical point pair. B2 - AC < 0, A > 0 every· 
where. Therefore the surface has a relative minimum at this point. 
Chapter 4 
SECTION 1 (dX1 . dX2 dX3) 
1 (a) 
- - -
=(-a sin t, a cos t, O), 
• 
dt ' dt ' dt 
therefore 
f2 dr.  dt = r2 a2 dt = 2a2. 
Jo dt dt 
Jo 
(b) (dx1 dX2 dX3) 
= (
- sin : cos  
o) 
. 
ds'ds'ds 
a' 
a'
' 
Therefore 
i2"dr dr 
i2" 
- • -ds = 
ds = 27T. 
0 dsds 
0 

402 
Answers to odd-numbered problems 
3. LG · dr = L (2X1 X2 dX1) + (X1)2 dX2. 
(a) X2 = [1 + (X1)2Jl-i; therefore we evaluate 
r2 
r.,r 
Jo 
2X1[1 + (X1)2]'-' dX1 +Ji 
5 [(X2)2 - 1] dX2. 
We obtain i[5'% - 1] + [!% - 5!-i + iJ = 4v'5. 
vs - 1 
vs - 1 
(b) x2 = 
x1 + 1 
dX2 = 
dX1 
2 
• 
2 
• 
f [<v5 - l)(X1)2 + 2Xl) + v's 
2
- 1 (Xl)2] dX1 
= fo\i(vS - l)(X1)2 + 2X1] dX1 = 4VS. 
(c) On the portion of the path corresponding to 0  t  2 
!5. (a) 
dX1 = dt, 
dX2 = 0, 
X2 = 0. 
On the portion of the path corresponding to 2  t  v's + 2 
We have 
dX1 = 0, 
dX2 = dt. 
fv5+2 
-
Jz 
4dt=4v'5. 
(d) JG· dr is independent of path since G = Vil>, 
where 
'1> = (X1)2X2• 
W = f F . dr = f 
"
r . 
dr 
d8 = f 
"
a[ -(h + a cos 8) sin 8 
Ja 
Jo 
d8 
Jo 
+ (k + a sin 8) cos 8] d8, 
= -2ah. 
(b) o. 
(c) 
-2ah. 
7. We only need to show J. G • dr / 0. 
. 
Ya 
X1 = cos8, 
Consider C: 
2 
• 
0  0 < 2 .. , 
X = sm8, 
then 
12,. ( 
dX1 
dX2) 
-X2- + X1-
d8 = 2 .. 
0 
d8 
d8 
. 

SECTION 2 
Answers to odd-numbered problems 
403 
1. 
L1 
lz 
La 
or 
or 
- x -= 
cos v1 cos v2 
cos v1 sin v2 
-sin v1 
ov1 
ov2 
or 
or 
-sin v1 sin v2 
sin v1 cos v2 
0 
=sin v1r. 
l1 
l2 
l3 
oX3 
0 
oX3 
oX3 
-X-= 
ov1 
ov2 
Tv1 = - Tv1 l1 -  l2 + l3. 
oX3 
0 
a2 
Since X3 = -g(X1, X2), we see that V/ = or/ov1 x or/ov2• 
(b) In Theorem 4-2.4 we found that 
I Or 
Or i 
-
ov1 x ov2 = V' g · 
or/ ov1 x or/ ov2 
Vf 
. 
I or/ ovl x or/ ov2I 
and 
IV/I are umt normals to the surface. Therefore 
the equality expressed in Problem 3b holds except possibly for sign. 
5. (a) ir • N dA = 1111 
-v•
dv1 dv2 = 11 (l - v2) dv2 = -!. 
(b) Let X1 = -v1, 
X2 = 1 + v1, 
X3 = v2• 
( W. N dA = f2 (
0
(2 + v1) dv1 dv2 = !(2)= 3. 
Js 
Jo J-1 
(c) l W • N dA = 1
31
2
"(sin2 v1 cos v1 + sin v1 cos v1) dv1 dv2 
= 0. 
7. (
a) 1212" 
WI ;;1 X ;;21 dv1 dv2 = 1
21"(cos v1 L1 - sin v1 L2) dv1 dv2 
= -4L2. 
f2" f" 
(b) Jo Jo (sin v1 cos v2 L1 + sin v1 sin v2L2 + cos v213) sin v1 dv1 dv2 
= 12" ( cos v2Li +  sin v212 + 2 cos v2L3) dv2• 
=0. 

404 
Answers to odd-numbered problems 
SECTION 2• 
-
I ov I -1 ov I 
ov1 avr -
ov°' ovfl 
1. v' g s 
<5"°' 611/J = 1-
v' g - - - s - - dV" dV" 
°'{J 1 2 
ov 
ojj OV°' ov/J l°' oijl' oi}Y l 2 
SECTION 3 
= Yff 3 A ;5° Y S 
6iJµ diJ" = Vff S 
di}µ di}" 
µ 
• 
ly 1 2 
µv 1 2 • 
1. (a) According to the definition of the components of dXi, dX;, dX;, al 
1 2 3 
terms of B;k11dXidXkdX" are zero except corresponding to (j,k,p) = 
1 2 
3 
(1, 2, 3); that term is dX1dX2dX3• 
(b) Following the procedure of Problem 1 in Chapter 4, Section 2•, we see 
that v'gB;k'J dXi dXk dXP is invariant. The result follows from this fact. 
1 
2 
3 
( 
cosPcosO 
cosPsinO 
3. (g ,.p) = -[s sin P + r cos ,8) sin 0 
s(sin ,8 + r cos p) cos 8 
sin ,8 cos 0 
sin ,8 sin 0 
lg °'pi = [s sin ,8 + r cos ,8) therefore the element of volume is 
(s sin P + r cos p)# dr dO ds. 
SECTION 4 
. f 
Jy'2 
1
-(Xl)2+s 
2"2 
1. (a) 
· P · dr 
= 
_ 
-dX1 dX2 = -
C 
-y'2 (X1)2+4 
3 
(b) £P ·dr =f i1 
- X2dX2dXl = -t 
f 
J
a 
J
%[9-(X1)2]J.2 
(c) 
P ·dr = 
2X1X2dX2dX1 = o. 
C 
-3 
-%[9-(Xl)2]# 
3. By straightforward computation we find that 
N·Vx P 
= -V·U, 
where 
also 
P · dr = U2dX1 - U1dX2 = -U x dr. 
5. If c is in the plane %3 = 0, then 
-sinP) 
0 
. 
cos ,8 
L N • v x G dA 
= f 
c G • dr =£ -X2 dX1 + x1 dX2. 
According to the result in Example 4-4.1, this last integral represents the 
area of the plane region bound by C. 
7. The surface is not closed; hence the theorem is not applicable for any G. 

Answers to odd-numbered problems 
405 
9. Substituting into the Green's theorem conclusion, we obtain 
(a) £ X2dX1 = L -dX1dX2 = -A. 
(b) £ X1dX2 = L dX1dX2 =A. 
(c) Subtract (a) from (b). 
(d) We use the parameterization of Example 4-4.1: 
Chapter 5 
SECTION 1 
-A =£ X2dX1 = i2" b sin t (-a sin t) dt = -al>r. 
1. A1;k> = !(A;1, + Ak;) = !(A;k - A;k) = 0. 
3. B1A1 
= G;ki B1BkC1 
= 0. 
Note that E;ki is skew symmetric in j, k and that Bi Bk is symmetric in these 
indices. 
We show that Ci A; 
= 0 by the same procedure. 
5. Write 
E;, ... ;,.b = ei,···inb;/' · · · b;,.in 
Eh···i,.a = Ek..-·knak/1 ... ak,.
;,._ 
By multiplying and summing these two expressions, we obtain 
n! ab 
= £k1···kn[;i1···i,.(ak/1b;1i1) ... (ak,.i"bj,.in) 
n! ab = E"..-·k,.ei..-·i,.ck/1 · · ·ck,.;,. 
= £k,.···k,.[;k1···k,.c = n! c. 
Therefore 
ab = c, 
as was to be shown. 
7. (a) If A ; = p £5[ii2"ipla. q2 · • ·a· qp • 
k 
kq2···q'P 
1.2 
1.p 
, 
then 
P 
..
. e 
= -E''2··-ip 
. 
. a 
p ! 
rc,··-ip 
p 
. 
. 
= 1(p - 1)! r5/a = r5/a. 
P· 
(b) Follow the procedure in Part (a) 
(c) 
la/Ak11 = lr5/al, 
la/I IAk11 
= 1'5/1 a
n
, 
1Ak11 
= lr5/I 
= a
t•-1• 

406 
Answers to odd-numbered problems 
9. See Theorem 3-5.3. 
11. We can write 
aAik + {JAki = 0, 
aAki + {JA1k = 0. 
When the second of these is subtracted from the first, we obtain 
a(Aik - Aki) + {J(Aki - Aik) = 0, 
that is, 
(a - {J)(Aik - Aki) = 0. 
The result follows from this expression. 
13. If we take the curl of relation (a) of Problem 12, 
,, a 
V x (V x E) = - - - (V x H). 
c iJt 
If we use the vector identity of Chapter 3, Section 3, on the left of this 
expression and relation (c) of Problem 12 on the right, 
V(V • E) - V2E = - - -
- - + -
, 
µ a (e iJE 
41TaE) 
c iJt c iJt 
c 
µe o2E 
%µa iJE 
V(V. E) - v2E = -
c2 iJt2 - -;r-Tt' 
µe iJ2Eq 
%µa oEq 
CJP a E - CJP a .,. 
+ -
-- + -- -- = o 
q 
"' 
p-'-Jq 
c2 012 
c2 
ot 
· 
This is the desired form. The second relation follows in a corresponding 
way from Problem 12c. 
SECTION 2 
1. (a) According to (5-2.4b), 
3. 
iJJ(k -
A;= ax1Ak 
If we multiply and sum this relation with iJXi/ oXP, 
ax1 
ax1 axk 
_ 
_ 
_ 
-A ---A -t5kA -A 
oXP 
i - oX"' axi 
k -
"' 
k -
"'' 
as was to be shown. 
(b) This relation follows from (5-2.4a) in a manner similar to that of part (a). 
. 
. . 
. 
iJJ(i1 
aJ(ir iJJ{ir+i 
(Jj(i'D 
T1i"""Jr1r+i"""J'D = --
.
.
 • -- -- .. • -- Tk1···krkr+1•··k'D 
0Xk1 
iJXkr 0Xkr+1 
oXk'D 
. 
. 
. 
. 
ax11 
ax1•+1 0g1,+1 
ax1'D 
TJi••"Jr+i1r"""J'D = 
__ ... ____ .. . __ Tk100·kr+lkr··k'D 
0Xk1 
iJXkr+l iJXkr+l 
iJXkp 

Answers to odd-numbered problems 
407 
If we add these expressions, 
. . . 
. 
_ 
. 
. 
. 
i)J{i1 
i)J{ir i)J{ir+l 
i)J{ip 
f"J1"""3rlr+i''"Jp + T1l'""Jr+13r""")p = --
• 
• 
• 
--
--. .. --
iJXk1 
iJXkr iJXkr+l 
iJXk» 
x (Tk1• .. k,k,+i· .. k» + Tk, .. ·kr+1k, .. k»). 
Suppose the system Tk1· .. krkr+1""·k» is completely skew symmetric; the 
right-hand expression is then equal to zero. 
Therefore the left-hand 
expression is equal to zero, hence skew symmetric injrir+l· The statement 
is valid for r = I 
· 
· · p - 1, and the components 'fici» are completely 
skew symmetric. 
5. Yes, contravariant valence I and covariant valence 3. 
iJAk 
i)J{P o[ i)Xk/ oXq)Aq] 
oXP( i)Xk oAq 
o2 Xk 
) 
7• 
ax1 = ax; 
oXP 
= 
ax; 
axq oXP 
+ 
oXP axq 
Aq 
This law of transformation is not tensor in character; it becomes so if 
and only if o2Xkji)J(P oXq = 0, that is, when the transformations are 
linear with constant coefficients. 
SECTION 3 
1. X1 = v-=lX1, X2 = X2 is the required transformation. 
The allowable 
transformations of our considerations have real coefficients. 
3. In general, the angle made by two tangent vectors dXi/du, oXi/dv is 
g;k(dXi /du)('5Xk/dv) 
If we consider the coordinate curves X1 = constant, · · · Xi = u, · · · , 
X" = constant 
and X1 = constant, · · · , Xk = v, · · · , X" = constant. 
Then only the derivatives of these coordinates are nonzero, 
g;k 
cos ()jk = -.,=='=--== 
v'Jg11I v
'
Jgkkl 
SECTION 4 
1. (a) The nonzero Christoffel symbols in cylindrical coordinates which are 
related to rectangular Cartesian coordinates by 
x1 = P cos e, 
are 
X2 = p sine, 
1 
r2 = r2 = -
12 
21 
p 
X3 = z 
The nonzero Christoffel symbols in spherical coordinates related to 
rectangular Cartesian components by 
X1 = r sin () cos </>, 
X2 = r sin 6 sin </>, 
X3 = rcos () 

408 
Answers to odd-numbered problems 
are 
r:2 = -r, 
1 
r2 = r2 = -
21 
12 
r 
1 
r3 =r3 =-
31 
13 
r 
r;s = 
- r sin2 0, 
r;s = -sin 0 cos 0, 
(b) r}1c =tgiq(i\g1cq + 01cgq; - aqg;1c). 
The symmetry of the Christoffel symbols follows immediately from the 
symmetry of the g;k· 
oXi( oXq aXr -
a2xp ) 
3· 
r;k = oXP ax1 axk r:r + ax1 ax1c 
· 
5. If 
If we multiply and sum with ( aX•/ oXi) ( oXi/ oX") ( oXk/ oX"), 
ax• ax1 ax1c 
- (-
-
-
ax1 ax1c 
a2XP ) 
oXi axu axv r;k = IV o .. o otlrr:r + oX" oX" ax1 oXk . 
The Proof can be completed by using the result of Problem 5 of this 
this section. 
ax1 axq 
--
-01 
oXq oXP -
P 
is differentiated partially with respect to Xk, then 
o2Xi 
oXq 
oXi 
o2Xq 
axr 
oXk oXq oXP + oXq axr oXP oXk 
= 
O, 
as was to be shown. 
7. Write 
oXP axq 
ffsc 
= ax• axc gpq 
and follow the procedure of Theorem 5-4.1. 
D<I> 
dXi 
dX1( o<I> 
k ) 
9. 
di 
= di V;<I> 
= di ax1 + wr ki<I> 
. 
If the scalar is of weight zero, W = 0 and 
D<I> 
dXi o<I> 
d<I> 
di = di ax1 
= dt · 
11. The nonzero Christoffel symbols associated with the spherical surface of 
Chapter 5, Section 3, Problem 2, are 
q2 = -sin 0 cos 0, 
q2 = r<l = ctn 0. 
13. v[jw1c1 
= a[jkw1c1 - I'f1cnWq 
= a[jwkJ· 
The last equality results from the fact that the Christoffel symbols are 
symmetric in the lower indices. 

Answers to odd-numbered problems 
409 
SECTION 5 
1. In a Euclidean space there can always be found a coordinate system such 
that g;k = fJik• and therefore r:1 = 0. 
The differential equations of 
geodesies [D(dXi/ds)]/ds = 0 then reduce to 
<J2Xi 
ds2 = 0. 
These equations have the solutions 
Xi = c1is + ci, 
that is, equations of straight lines. 
SECTION 6 
1. 
at</> = 21T 
Therefore 
A1 =cos [(cos cx.)21T] 
1 
A2 = - -.- sin [(cos cx.)2n]. 
smcx. 
1T 
(Al, A2);=2,, = (A1, A2)</>=0 
if and only if 
ex. = 2
. 
SECTION 7 
1. If 
. 
o2Xi oX• o2X'P 
oXi 
o3Jl'P 
arrj,. = oX• oX'P_o_X_'" oXi oX" + -ax-:v-ax_r_o_X_i_o_X_ " 
a2xi 
ax• 
a2x:v 
(a) °CrJk = oX• oX'P axcr oXil oXk 
also 
Differentiation of ( oX•/ oXi)( oXi/ oX•) = fJ/ produces the result 
a2x• 
ax; 
ax• 
a2x; 
oXP 
(c) axm oXi oX• = -
oXi oX'P oX• axm. 
When (c) is applied to (b), we obtain (a); therefore 
R,../ = 2[ - o[,.rli + rrc,.rJml = 0, 
as was to be shown. 

410 
Answers to odd-numbered problems 
SECTION 8 
1. Define: 
(r) 
Ck 
= 15,k, 
D' = 15,', 
(8) 
(t) 
where the symbols in parentheses distinguish vectors and other indices 
signify components. Then 
(B,I) (r) 
A; B; Ck D1 = T;/1• 
(r) 
(•) 
(t) 
3. Let the tensor [Tkzl have a vector decomposition represented in terms of 
components by Tkl 
= AkB1; then 
2Y'c;V;]AlcBI 
= 2[(v(,v;)Ak)B, + A/cv[,v;B,]. 
Relatio._5-8.4b follows by employing this relation and (5-8.2b). The 
expression (5-8.4c) may be verified in the same way. 
5. We have 
0 
= 2v(,v;J8ik 
= -Rrimi gmk - Rrimk g;m, 
If we multiply and sum with g Pk• 
Rrip; = -Rrimk8Pk 8im. 
If we contract in this expression on p and j, 
Rri'IJP 
= -Rrimkskm 
= -Rrlkk; 
therefore 
R.;/ 
= 0. 
7. The result follows immediately from the form of R expressed in Problem 6 
and the fact that g is a scalar density of weight -2. 
SECTION 9 ( dXA) 
1. (a) V';. µ ds 
o[t,(dXA/ds)] 
axA 
( dXA dX') 
( dXA) dX• 
dX;. 
dX• 
(b) \;.m"• 
= Y;. µ ds ds 
. 
= v, µ ds 
ds 
+ µ ds Y,1 ds · 
Since v!gi is a covariant constant and the first term on the right of the 
foregoing expression corresponds to the relativistic continuity equation, 
we obtain 
-
.i 
-
D(dX'/ds) 
v lgl 'il ,m • 
= V lgl µo 
ds 
. 

index 
Absolute calculus, 6 
Absolute derivative of tensor field, 340 
Acceleration, apparent, 160, 161 
arrow form, 157. 160 
centripetal, 161, 174 
components, 160, 163, 169 
Coriolis, 161 
field, 147-149, 152 
linear, 15 
radial, 153 
translational, 161 
vector concept, 127, 155, 157, 167, 
170 
Adams, 171 
Affine connection, 357 
Affine transformation group, 66, 67, 
113-114, 180 
Angle, 42, 60, 65, 68, 82, 328, 329 
Angular momentum, 176 
Angular velocity, 157, 158, 160, 167 
Aphelion, 174, 379 
Apolonius, 2 
Arc length, 141, 190 
Area, 153, 172, 175,293,350 
Argand diagram, 2 
Aristotle, 1 
Arrow, 12-20, 31, 52, 76, 77 
basis, 27, 42 
collinear, 24 
components, 161 
coplanar, 24 
dependent, 24, 25 
magnitude, 15 
Arrow, parallel, 14 
position, 36 
unit, 25-28, 97 
Associated metric tensor, 81, 82, 233, 
237,286,326 
Associativity, cross product, 97, 132 
dot product, 57 
group,66-67 
n-tuple, 11, 12 
Axial vector, 103 
Basis, 70 
arrow, 27, 42 
constant, 131, 147, 254 
contravariant, 74, 77, 80, 229, 285 
covariant, 73, 74, 77, 227, 228 
generalized coordinate systems, 225, 
234 
linear independence, 32, 33 
nonconstant, 131, 254, 282 
n-tuple, 32, 130, 131 
orthogonal, 28 
physical, 76 
polar coordinate system, 151, 152 
reciprocal, 74, 80, 114 
unit triad, 27, 97, 131, 144, 147, 148 
Beltrami, 6, 272, 331 
Bernouli,Johann,342 
Bezout, 87 
Bianchi's identity, 368, 369, 371 
Binary operation, 3, 4, 56, 96 
Binormal, 144 
Bolza, 342 
411 

412 
INDEX 
Bound vector, 283 
Brahe, 171 
Cartesian coordinates, 8, 9, 10, 19, 35, 
38-40, 51, 68-72, 78, 92, 112, 155, 
177-179,227, 325 
Cartesian metric tensor, 78, 83, 93 
Cauchy, 123 
Cayley, 65, 87, 115 
Characteristic equation, 94 
Christoffel, 6, 331, 333 
Christoffel symbols, 333, 345, 348, 369, 
375 
contracted, 339 
symmetry, 341, 357 
transformation, 334 
Circle, vector equation, 143 
Circular functions, 185 
Coefficients of transformation, 42, 45, 
46, 78, 98, 119, 133 
Cofactor, 31, 43, 93, 98, 118 
Collinear arrows, 24 
Column, index, 37, 88, 89, 115 
interchange, 89 
operation, 89 
zero element, 89 
Commutivity, cross product, 97 
divergence, 214 
dot product, 57 
matrix, 116, 117 
n-tuple, 11 
Components, 10, 75-77, 156, 160 
Composition transformation, 224 
Composition of velocities, 180, 189 
Cone, 198,204,359 
light, 181, 187-188 
Conic section, 173 
Conjugate 
metric tensor, 
see Associ-
ated metric tensor 
Conservation laws, 193, 267, 300 
Conservative force, 210, 266 
Contravariant, basis, 74, 77 
8-system, 111 
tensor, 112-113 
transformation, 75, 208 
vector, 75, 76, 81, 169 
Coordinate curve, 201-202, 289 
surface, 289 
Coordinate system, 2, 7, 43 
curvilinear, 207 
Coordinate 
system, 
cylindrical, 
220, 
221, 233, 248 
general Cartesian, 68-72, 78, 112 
inversion of triple scalar product, 106 
left-handed, 9, 100 
polar, 150-152 
rectangular Cartesian, 8, 9, 10, 19, 
35, 38-40, 51, 92, 131, 155, 177-
179 
right-handed, 9, 10, 100, 144 
spherical, 220, 222, 230 
transformation, 2, 40, 66, 78, 133, 
155, 177-178 
Copernicus, 171 
Coplanar arrows, 24 
Coriolis, G. G., 261 
Coriolis acceleration, 161 
Coulomb, 177 
Covariant constant, 338, 340 
Covariant derivative, 334-339, 354, 362 
operator, 362 
Covariant differentiation, 3 31 
Covariant vector, 75, 81, 112-113 
basis, 73, 74, 77 
transformation, 75, 208 
Cramer, 87 
Cramer's rule, 43 
Critical value, 246, 248 
Cross product, 4, 96-114 
algebraic properties, 97-99, 117, 132 
axial vector, 103 
curl, 216, 218 
determinant form, 96 
differentiation, 131, 13 2 
geometric interpretation of the mag­
nitude as the area of a parallelo­
gram, 100, 101 
linearly independent vectors, 100 
magnitude, 100 
moment of force, 102 
orthogonality, 100 
parallel vectors, 97 
proportional vectors, 100 
reciprocal basis representation, 114 
transformation, 98, 113-114 
of unit arrows, 97 
Curl, 216, 238, 243 
transformation, 217 
Curvature, 141, 142, 144 
Gaussian, 6, 359, 367 

Curvature, invariant, 366 
tensor, 355, 361-371 
Curve, arc length, 141, 190 
convex,291 
latitudinal, 202 
length, 139-140 
longitudinal, 202 
smooth, 125 
surface, 201, 202, 206, 213 
tangent to, 134-137, 141 
vector representation, 125 
Curvilinear coordinates, 207, 238, 289 
Cylinder, 205, 346, 348, 359 
Dependence, linear, 23-33 
Derivative, directional, 211, 213 
of scalar field, 128, 206 
vector field, 129-132, 206 
vector sums, 131 
vector triple product, 132 
Descartes, 2 
Determinant, 42, 85-95, 88 
algebraic properties, 89 
cofactor of, 31, 43, 93, 98, 118, 240, 
313 
expansion of, 43, 89 
of metric tensor, 239, 277, 286, 339 
multiplication of, 91, 240, 312 
order of, 88, 89 
partial derivative of, 313 
product of, 91 
of transformation coefficients, 42, 43, 
49 
triple scalar product as, 103 
value of, 43, 88, 91 
Differentiability, 125, 127 
vectors, 128-135, 213 
Directional derivative, 211, 213 
Direction cosines, 40-42 
Direction numbers, 14, 73 
Displacement, parallel, 356 
Displacement current, 301 
Distance, 13, 55, 61, 342 
invariance of, 57 
Divergence, 214, 218, 238, 241-243 
differentiation, 214 
noncommutativity, 214 
theorem, 297 
transformation of, 242 
Domain, 124 
Index 
413 
Dot product, 56-65, 131, 206, 214-215 
algebraic properties, 57 
Dummy index, 36 
Dynamics, 171 
Eccentricity, 173-174 
Eigenvalue, 94 
Einstein, 6, 155, 171, 176, 178, 179, 
193,304, 372 
Einstein convention, 36 
Einstein tensor, 370 
Electrostatic force field, 177, 266 
Ellipse, 127, 174 
Ellipsoid, 204 
Elliptic cylinder, 205 
Energy, 193-194,266, 267 
Equipotential surface, 210, 221 
Erlanger Programm, 35, 65, 68, 177 
e-systems, 85-95, 111-114, 239, 287, 
311,318 
permutation, 89 
transformation, 92, 112, 239 
Euclidean line, 8 
Euclidean metric geometry, 66, 186 
Euclidean space, 8, 19, 26, 131, 328 
Euler, 66, 123 
Euler-Lagrange equations, 343, 344, 345 
Faraday, 177, 210,300 
Fermat, 2 
Field, conservative, 210, 266, 295 
force, 171, 172, 177,204,215, 266 
gravitational, 172, 209, 266, 373 
irrotational, 295 
momentum, 171, 266 
scalar, 127, 128, 133, 203, 210, 215 
tangent, 133, 134, 141, 206, 213 
vector, 127, 133, 141, 147, 152, 204, 
206-207 
parallel, 348-353 
pseudoparallel, 3 51 
Flat space, 359, 360 
Foppe!, 5 
Four-dimensional space, 184 
Frame of reference, 147, 184 
motion of, 155-164, 176-179, 187, 
188 
Free vector, 283 
Frenet-Serret formulas, 145 

414 
INDEX 
Function, 124 
two-variable, 246 
Fundamental metric form, 6, 190, 273, 
324,372, 374 
Fundamental metric tensor, see Tensor, 
metric 
Galilean transformations, 177-180, 186 
Galileo, 2, 176 
Galle, 171 
Galois, 68 
Gauss, 2, 6, 197, 272, 304, 325 
theorem, 297 
Gaussian curvature, 6, 359, 367 
Gaussian plane, 2 
Geodesic, 345, 346, 348, 372, 373, 377 
coordinates, 369 
Geometry, 65 
affine, 66 
Euclidean metric, 66, 186 
hyperbolic, 186 
intrinsic, 284 
non-Euclidean, 325 
projective, 65 
Riemannian, 31 O 
Gibbs, 5, 51, 58 
Gradient, 207-209, 215, 218, 231, 249, 
262, 263,266 
transformation, 208 
Gram's determinant (Gramian), 111 
Grassman, 1, 3, 4, 5, 7, 56, 58, 96 
Gravitational constant, 172, 210 
Gravitational field, 172, 209, 221 
Gravitation law, 172 
Green, G., 291 
Green's identities, 299 
Green's theorem, 291, 293 
Grossman, 6, 372 
Group, centered affine, 66, 67, 113 
coordinate 
transformations 
as, 65, 
66, 93, 177, 208,224 
transformation coefficient matrices as, 
119 
Hamilton, 1, 3-5, 7, 19, 51, 53, 56, 96, 
206,216 
Heaviside, 5 
Helix, 126, 150, 348 
Henry, 177 
Hertz, 301 
Hesse's normal form, 61 
Hilbert, 7 
Hipparchus, 171 
Hlavaty, Vacalav, 99, 201, 367 
Hyperbola, 173, 204 
Hypersurface, 3 17 
Implicit function theorem, 198 
Independence, linear, 23-33, 73, 100 
Independence of path, 262, 264, 295 
Index, column, 88, 89, 115 
dummy, 36 
free, 37 
interchange, 89 
lowering, 80, 112, 231 
permutation, 86, 88 
position, 3 7 
raising, 80, 112, 231 
row, 88, 115 
Indicators in determinant representa-
tion, 85-87 
Inertial frame, 177 
Inertial mass, 193 
Inertial system, 19, 371 
Inflection point, 246 
Inner product, 57 
Integral, area, 277 
double, 276 
iterated, 276, 289 
line,255-269 
surface scalar, 270-282 
surface vector, 270-282 
Integration, path of, 259 
Invariants, 35, 54, 55, 57, 65, 66, 186, 
190, 192, 228, 288, 315 
Inverse, 11 
matrix, 118-119 
transformation, 43-45, 66, 67 
Inverse square law, 177 
Irrotational field, 29 5 
Isomer, 309 
Iterated integral, 276 
Jacobi, 87, 223 
Jacobian, 223, 224, 227, 239, 369 
Kepler law, 171-174 
Kernel letter, 86, 111 
Kinematics, 147-153, 187 
Kinetic energy, 193-194, 266, 267 

Klein, 35, 54, 65, 68,87, 177 
Kreyszig, Erwin, 125 
Kronecker delta, 37, 40, 43, 45, 46, 
48, 81, 117, 306, 318 
generalization, 311 
Lagrange, 68, 87 
identity, 111, 294 
Laplacian, 216 
Latitudinal curves, 202 
Law of addition, parallelogram, 1, 14, 
15 
Law of areas, 153, 172, 175 
Law of cosines, 59 
Leibniz, 87, 123 
Length of curve, 139-140 
Leverrier, 171 
Levi-Civita, 6, 304, 349, 354 
Lie, 68 
Light cone, 181, 187-188 
Linear dependence, 23-33 
Linear equation, 7, 8 
Linear independence,23-33, 100 
of basis, 32-33, 226, 229 
Linear 
transformations 
derived 
from 
general transformations, 315 
Line, world, 181, 187 
Line integral, 255-269 
Line representation, 18, 32-33 
Line of simultaneity, 181, 187 
Liouville, 141 
Lipschitz, 6, 331, 333 
Longitudinal curves, 202 
Lorentz, 178 
transformations, 178, 186, 189-192, 
371 
Lowering of index, 80, 112, 327 
Loxodrome, 205 
Magnetic field, 177, 266 
Magnitude, 14, 15, 58, 82, 148 
of cross product, 100 
invariance of, 57 
Mass, 191, 193, 372 
Matrix, 114-122, 229 
equality, 116 
group property, 119 
identity, 117, 118 
inverse, 118, 119 
Kronecker delta, 37 
Index 
415 
Matrix, multiplication, 115-118 
noncommutativity, 116, 117 
notation, 115 
rank, 28, 29, 197 
sum, 116 
transformation, 42, 45, 119 
transpose, 118, 119 
zero, 116 
Maxima, 245-253 
Maxwell, 4, 214, 216, 300, 301 
equations, 178, 186, 300, 314 
Mercury, 377, 379, 381 
Metric tensor, see Tensor, metric 
Michelson, 179, 182 
Minima, 245-253 
Minkowski, 184, 186 
metric, 185 
plane, 186-187 
space, 184 
Minor, 31 
Mtibius, 4 
strip, 270 
Moment of force, 102, 176 
Momentum, 171, 176 
Monge, 196 
Morley, 179, 182 
Motion, planetary, 171-173 
Moving frames of reference, 155, 176-
179, 184, 187-188 
Neptune, 171 
Newton, 123, 155, 171, 176 
laws, 18, 19, 148, 172, 191-192, 317, 
321 
Newtonian orbit, 173, 377, 378 
Non-Euclidean geometry, 285 
Non-Euclidean space, 19, 20 
Nonhomogeneous equations, 32 
Normal, principal, 141, 142 
to a surface, 208, 218, 275 
Normalized vector, 61 
n-space, 6, 7 
n-tuple, 10, 11, 20-26, 29-33 
Oersted, 177, 300 
law, 303 
Olmsted, 271 
Operator, 206, 213-216 
Orbit, 174 
Order of contact, 137 

416 
INDEX 
Order of determinant, 88, 89 
Order of tensor, 82, 83, 112 
Orthogonality conditions, 60, 66, 119-
121, 158, 184-185, 328, 329 
basis, 25-28, 41, 148 
gradient, 208-209 
vectors, 40, 45, 60 
Orthogonal projection, 78 
Orthogonal unit basis triad, 148 
Orthogonal vectors, 100 
Osculating plane, 136, 137, 142, 148 
Parabola, 134-135, 174 
Parallel arrows, 14, 15, 29-30 
Parallel displacement, 356 
Parallelepiped, triple scalar product as 
reprx
ntation of volume, 104 
Parallelis 
6, 349 
Parallelogr 
, area, 101 
law of addition, l, 14, 15, 76, 356 
Parallel projection, 76, 78 
Parallel vector, 97 
Parallel vector field, 348-353 
Parameter transformation, 198 
Parametric equations, 18, 125-129, 134, 
142, 151, 161, 197, 199-202 
Perehelion, 17 4, 3 77, 3 79 
Period of revolution, 175 
Permutation, 86 
Physical basis, 76 
Physical components, 76, 235, 236, 237, 
243 
Plane, 7, 211, 213 
Hesse's normal form, 61 
Minkowski, 184, 186 
of simultaneity, 181 
vector equation, 60, 199 
Planetary motion, 171-173, 377 
Pluto, 171 
Poincare, 179 
Point, 7 
Poisson's equation, 216, 373 
Polar coordinate system, 150-152, 174 
Poncelet, 261 
Position vector, 36, 149, 170 
Positive definite property, 57, 325 
Potential, 54, 210, 266, 267 
Projection, 76-78, 156, 161, 213 
Pseudoparallel vector field, 3 51 
Ptolemy, 171 
Quadric cone, 204 
Quaternions, 3, 4, 51, 96, 206, 216 
Quotient law, 109 
Raising index, 80, 112, 327 
Range, 17, 124 
Rank of matrix, 28, 29, 197 
Reciprocal basis, 74, 80, 114 
Rectangular Cartesian coordinates, 8, 
10, 19, 35, 51, 177-179 
Regular point on a surface, 198 
Relativity of motion, 155, 177, 317 
Relativity theory, 6, 7, 156, 171, 176, 
179-194, 304, 325, 368, 371-381 
Rest mass, 193 
Ricci, 6, 304, 331 
le:nma, 338 
tensor, 365, 366, 367, 376 
Riemann,6, 7,272, 304,325 
Riemann Christoffel mixed tensor, 354-
361, 361-371, 373 
Riemannian curvature tensor, 355, 361-
374 
Rotation, 3, 36, 40, 47, 51, 119-121, 
170, 216 
orthogonal Cartesian, 75, 119-121 
successive plane, 119-122 
Rotational derivative, 169-170 
Rotational effect, 102 
Rotor, 216 
Rule of the middle factor, 107 
Saddle point, 248 
Scalar, 53, 54, 58, 316 
density, 104 
field, 127, 128, 133, 203, 206, 210, 
215 
product, 45, 56-65, 131, 206, 214-
215 
triple product, 103-106, 114 
Schwarzschild, K., 374, 376 
Sectorial speed, 175 
Sense, 14 
Serret, 145 
Simultaneity, 181, 187 
Singular point, 197-198 
Skew symmetry, 86, 90, 307, 308, 362 
Smooth curve, 125 
Solenoidal vector field, 300 

Space, 7, 305 
Euclidean, 8, 19, 254 
four-dimensional, 184 
Minkowski, 186-187 
n-, 6, 7 
non-Euclidean, 19, 20 
n-tuple, 10 
Riemannian, 6, 324, 328, 349, 366, 
372 
vector, 10 
Space curve, 206, 316, 339 
Spectral shift, 3 77 
Sphere, 19, 199-202,210,367 
vector equation, 62, 63 
Stevin, 1 
Stokes, G. G., 293 
Stokes's theorem, 291, 294, 295, 297 
Struik, Dirk, 145 
Summation convention, 36, 37 
Surface, 270 
area, 273, 274,275,287,288 
continuity conditions, 197 
curvature, 6 
curve,201-202,206, 213,346 
developable, 359 
equipotential, 210 
equivalent representations, 198 
explicit form, 196, 213 
fundamental metric 
form, 
6, 190, 
273 
implicit form, 196, 197, 198, 199 
integral, 270-282 
normal, 209-210, 215 
orientable, 270 
parametric representation, 197 
regular point on, 198 
scalar field, 203 
singular point, 197-198, 200 
smooth, 198, 270 
tangential, 359 
tangent to, 211 
transformation, 198, 274, 284 
vector field, 204, 211, 213 
Sylvester, 75, 87, 223 
Symmetric equations, 18 
Tait, 4 
Tangent, 133-134, 141, 148, 256 
line, 127, 134, 137, 211 
plane, 209, 282 
Index 
417 
Tangent, surface, 275 
vector field, 133, 141, 148, 206, 211, 
257,350 
Tensor, 5, 82, 315 
addition, 306, 319 
algebra, 6 
analysis, 2, 5, 7, 315 
associated, 81, 82 
calculus, 6, 7, 304, 372 
contraction, 307, 319 
contravariant, 111 
covariant, 111 
covariant curvature, 355, 361-371 
decomposition, 361, 362 
density, 112, 239, 319 
Einstein, 370 
metric, 81, 82, 194, 233, 237, 238, 
286, 318,324,367,372 
associated, 81, 82, 233, 237, 286, 
326 
mixed, 81, 83 
name, 5 
order, 82, 83, 93, 112, 315 
outer product, 307, 319, 361 
quotient law, 321 
Ricci, 365, 366, 367, 376 
Riemann Christoffel mixed, 354-361, 
361-371, 373 
skew symmetry, 307, 308, 320, 362 
symmetry, 307, 308, 320, 322, 326 
systems leading to, 305-314 
transformation law, 315 
transvection, 307 
valence, 306, 319 
weight, 93, 112, 319 
Time, 176, 181, 187; 189 
Tinseau, 137 
Tombaugh, 171 
Torque, 176 
Torsion, 144 
Transformation, 35, 36 
affine,66, 67, 113-114, 180 
associated metric tensor, 81 
basis arrow, 42 
Cartesian coordinate system, 78, 133, 
155, 177-178 
Christoffel symbols, 334 
coefficients, 42-46, 49, 78, 98, 119, 
133 
contravariant, 15, 208 

418 
INDEX 
Transformation, covariant, 75, 208 
cross product, 98, 114 
curl, 217 
dot product, 67 
e-systems, 92, 112 
fundamental metric tensor, 81 
general coordinate system, 221-226 
Kronecker delta, 81 
mixed metric tensor, 81 
rotation, 40, 51 
scalar, 54 
similarity, 66 
surface parameter, 198 
translation, 38, 51 
vector, 20, 40, 44, 51 
components, 77 
operator v, 206, 213-216, 238 
wk components, 167-168 
Translation, 36, 38, 51, 52 
Transpose of matrix, 118, 119 
Transvection, 307 
Triple scalar product, 103-106, 114 
dot and cross interchange, 105 
inversion, 106 
Triple vector product, 106-108, 114, 
132 
Universal law of gravitation, 267 
Valence, contravariant, 306 
covariant, 306 
Vandermonde, 87 
Vector, 20, 21 
acceleration, 147, 148, 152, 156-
157, 170 
addition, 3, 254 
analysis, 2, 3, 5, 7 
axial, 103 
binormal, 144 
bound,283 
Cartesian, 51, 52, 76, 151 
components, 55, 75-78, 156-157 
contravariant, 75, 76, 80, 81, 169, 
228,284,316 
covariant, 75, 80, 81, 113, 231, 316, 
385 
density, 113 
division, 108 
field, 127, 129-133, 141, 147, 172, 
204, 206, 209-210 
free, 283 
Vector, gradient, 207, 215 
magnitude, 58, 82, 148 
operator V, 206, 213-216, 238 
origin of term, 3 
orthogonality, 40, 45, 60, 208-209 
parametric equations, 18 
position, 36, 149, 170 
principal normal, 141, 142 
product, 5 
cross, 96 
dot, 56 
triple, 106 
quotient law, 109 
rotational derivative, 169 
solenoidal field, 300 
space, 10 
sum, 131 
symmetric form, 18 
tangential, 133, 141, 148, 206, 211, 
213, 228 
transformation law, 20 
triple product, 106-108, 114, 132 
velocity, 127, 147-149, 153, 156, 
157, 170, 190 
unit, 211 
Velocity, angular, 157, 158, 160, 161 
apparent, 157, 160 
arrow form, 157 
components, 156, 157, 160, 162, 167, 
169 
composition, 180, 181 
field, 127, 147-149, 152 
light, 177-179, 182, 183, 186, 188 
linear, 15 
Lorentz 
transformation 
equations, 
186 
rotation, 161 
translation, 161 
Viete, 35 
Volume, integral, 288-291 
representation, 105, 290 
Wallis, 2 
Weight of tensor, 93, 112 
Wessel, 2 
Wilson, 5 
Work,55,261,266 
World line, 181, 187 
Zero matrix, 116 
Zero n-tuple, 10 

