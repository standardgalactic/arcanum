ANALYSIS AND SYNTHESIS OF
INDUCTIVE FAMILIES
Hsiang-Shang Ko
University College, Oxford
Thesis submitted in partial fulﬁlment of the requirements for the degree of
Doctor of Philosophy at the University of Oxford
Hilary 2014


ANALYSIS AND SYNTHESIS OF INDUCTIVE FAMILIES
Hsiang-Shang Ko
University College, Oxford
D.Phil. thesis
Hilary 2014
Abstract
Based on a natural uniﬁcation of logic and computation, Martin-Löf’s intuitionis-
tic type theory can be regarded simultaneously as a computationally meaningful
higher-order logic system and an expressively typed functional programming
language, in which proofs and programs are treated as the same entities. Two
modes of programming can then be distinguished: in externalism, we construct
a program separately from its correctness proof with respect to a given speci-
ﬁcation, whereas in internalism, we encode the speciﬁcation in a sophisticated
type such that any program inhabiting the type also encodes a correctness
proof, and we can use type information as a guidance on program construction.
Internalism is particularly effective in the presence of inductive families, whose
design can have a strong inﬂuence on program structure. Techniques and
mechanisms for facilitating internalist programming are still lacking, however.
This dissertation proposes that internalist programming can be facilitated by
exploiting an interconnection between internalism and externalism, expressed
as isomorphisms between inductive families into which data structure invari-
ants are encoded and their simpler variants paired with predicates expressing
those invariants. The interconnection has two directions: one analysing inductive
families into simpler variants and predicates, and the other synthesising induc-
tive families from simpler variants and speciﬁc predicates. They respectively
give rise to two applications, one achieving a modular structure of internalist
libraries, and the other bridging internalist programming with relational speciﬁ-
cations and program derivation. The datatype-generic mechanisms supporting
the applications are based on McBride’s ornaments. Theoretically, the key or-
namental constructs — parallel composition of ornaments and relational algebraic
ornamentation — are further characterised in terms of lightweight category the-
ory. Most of the results are completely formalised in the Agda programming
language.


Acknowledgements
I tend to link the appearance of my supervisor Jeremy Gibbons with that of
Professor Smith in PhD Comics, but, very fortunately, Jeremy’s personality is
just the opposite of Smith’s. I can’t hope for a more supportive supervisor than
Jeremy: he is always eager to help when I encounter various problems, quickly
responds to my email even when he’s away or on holiday, and patiently listens
to me as I struggle to ﬁnd the right word to use during our meetings. It is a
great reassurance that he is there to offer advice — usually I can quickly get
unexpected yet perfectly sensible and clear suggestions from him, which are
really the kind of suggestions one needs.
Besides Jeremy, I am very lucky to meet Richard Bird, Kwok-Ho Cheung,
Daniel James, Geraint Jones, Tom Harper, Ralf Hinze, José Pedro Magalhães,
Maciej Piróg, Meng Wang, and Nicolas Wu, who were present at the Algebra
of Programming group meetings. I probably won’t fully realise how precious
these meetings are until I leave — it’s inspiring to be in these meetings where
people having similar interests so enthusiastically and freely share and discuss
their ﬁndings.
Just a few days after my arrival in Oxford, at the orientation programme
for international graduate students I met Frank Chen 陳韋宇, who had given
me a lot of support since then. I still remember those morning walks around
Christ Church Meadow. Another person I met in my ﬁrst year is Jackie Wang
王震維. Especially memorable are the days when we worked on our respective
dissertations together in the ofﬁce, with lunch at the Bangkok House. I also
enjoyed many friendly chats with Lihao Liang and Di Chen.
During my second and third year, I lived in 45 Marlborough Road with
v

vi
Acknowledgements
Yen-Chen Pan 潘彥丞and Eric Liang 梁智超. (We were joined by Nien-Ti Tzou
鄒年棣and Lilya Lee for a year and then Giovanni Bassolino and Chih-Suei
Shaw 蕭植穗for the other year.) With their kind consent and tolerance, I had the
luxury of renting a Knight K10 piano — which has a beautifully bright and deep
tone — and practising daily. Joined by Wilson Chen 陳煒昕, Yun-Ju Chen 陳韻如,
Fu-Lien Hsieh 謝馥蓮, Tao-Hsin Chang 張道欣, and Duen-Wei Hsu 許惇偉, we
had three unforgettable evenings which started with dinner, followed by thirty
minutes of my piano playing (mostly Chopin’s works), and ending with a cosy
chat going on late into the night. Special thanks to Pan for keeping me company
— in particular, patiently responding to my endless (and sometimes pointless)
Skype messages and travelling with me to London for concerts.
The concerts. It’s really a privilege to be able to live near London and
regularly go to the superb concerts at the Southbank Centre, notably the per-
formances of London Philharmonic Orchestra and Philharmonia Orchestra at
the Royal Festival Hall. The lively culture of Southbank Centre is pleasant and
healing, and the amazing musicians showed me how natural it can be to strive
for beauty and perfection.
All of these would probably not have been possible without the generous
ﬁnancial support from the University’s Clarendon Fund, to which the College
also contributes. It is thanks to this support that I can concentrate on my study
and even live a high-quality life (with so much music). I was also supported by
the UK Engineering and Physical Sciences Research Council project “Reusability
and Dependent Types”, so I could travel to conferences and workshops without
having to worry about where to get funding.
Special thanks to Liang-Ting Chen 陳亮廷for numerous intellectual dis-
cussions, either on Facebook or in person, and hosting me several times in
Birmingham. I’d also like to give special thanks to Shin-Cheng Mu 穆信成老師,
who led me into programming languages research, and brought me to Oxford
in 2008 to see what academia is like for the ﬁrst time. Thanks also go to Justin
Chiu 邱亮德, Ting-Sung Hsieh 謝廷松, Ching-Hao Wang 王敬皓, and Wei-Jin
Zheng 鄭爲晋for regularly chatting with me on Facebook and Skype, hosting
me in the US, and crossing the Atlantic Ocean to visit me in Oxford.

Acknowledgements
vii
My parents Jung-Feng Ko 柯榮豐and Hsiu-Ching Tsai 蔡秀晴have always
deeply cared for my well-being and provided unconditional support. It is
always heartwarming to see them on Skype every Sunday or when I’m back
home in Taiwan, taking a break from the exhausting work. I’m always ﬁlled
with delicious food while I’m home, either by my mother’s excellent cooking or
going to various restaurants, many of which are carefully chosen by my older
sister Lien-Fang Ko 柯歛芳.
On 18 March, when I was working on the last part of this dissertation, news
about the Sunﬂower Movement in Taiwan swept through Facebook, causing
quite some disruptions to my write-up plan. I have my doubts about nation-
alism, but I’m happy with the idea when the name Taiwan is simply used to
collectively refer to the people on the island, many of whom have helped me as
I grow up and become who I am. My experience in the UK has already shown
how much advancement Taiwan still needs, and the Sunﬂower Movement re-
vealed how urgently the advancement should happen. Perhaps I will be able to
contribute towards that advancement, as a big thanks to Taiwan.
Josh Ko 柯向上
Oxford & Changhua, 2014

viii
Acknowledgements

Contents
1
Introduction
1
2
From intuitionistic type theory to dependently typed programming
7
2.1
Propositions as types . . . . . . . . . . . . . . . . . . . . . . . . . .
8
2.2
Elimination and pattern matching . . . . . . . . . . . . . . . . . .
12
2.2.1
Pattern matching and interactive development . . . . . . .
14
2.2.2
Pattern matching on intermediate computation . . . . . .
16
2.3
Equality
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
19
2.4
Universes and datatype-generic programming . . . . . . . . . . .
24
2.4.1
Index-ﬁrst datatypes . . . . . . . . . . . . . . . . . . . . . .
25
2.4.2
Universe construction . . . . . . . . . . . . . . . . . . . . .
27
2.5
Externalism and internalism . . . . . . . . . . . . . . . . . . . . . .
34
3
Reﬁnements and ornaments
43
3.1
Reﬁnements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
44
3.1.1
Reﬁnements between individual types
. . . . . . . . . . .
44
3.1.2
Upgrades
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
48
3.1.3
Reﬁnement families
. . . . . . . . . . . . . . . . . . . . . .
53
ix

x
Contents
3.2
Ornaments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
55
3.2.1
Universe construction . . . . . . . . . . . . . . . . . . . . .
56
3.2.2
Ornamental descriptions
. . . . . . . . . . . . . . . . . . .
60
3.2.3
Parallel composition of ornaments . . . . . . . . . . . . . .
64
3.3
Reﬁnement semantics of ornaments . . . . . . . . . . . . . . . . .
71
3.3.1
Optimised predicates
. . . . . . . . . . . . . . . . . . . . .
71
3.3.2
Predicate swapping for parallel composition . . . . . . . .
75
3.4
Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
78
3.4.1
Insertion into a list . . . . . . . . . . . . . . . . . . . . . . .
79
3.4.2
Binomial heaps . . . . . . . . . . . . . . . . . . . . . . . . .
82
3.4.3
Leftist heaps . . . . . . . . . . . . . . . . . . . . . . . . . . .
93
3.5
Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101
4
Categorical organisation of the ornament–reﬁnement framework
107
4.1
Categories and functors
. . . . . . . . . . . . . . . . . . . . . . . . 109
4.1.1
Basic deﬁnitions
. . . . . . . . . . . . . . . . . . . . . . . . 109
4.1.2
Categories and functors for reﬁnements and ornaments . 114
4.1.3
Isomorphisms . . . . . . . . . . . . . . . . . . . . . . . . . . 118
4.2
Pullback properties of parallel composition . . . . . . . . . . . . . 119
4.3
Consequences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127
4.3.1
The ornamental conversion isomorphisms . . . . . . . . . 127
4.3.2
The modularity isomorphisms . . . . . . . . . . . . . . . . 129
4.4
Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 132
5
Relational algebraic ornamentation
137

Contents
xi
5.1
Relational programming in Agda . . . . . . . . . . . . . . . . . . . 138
5.2
Deﬁnition of algebraic ornamentation . . . . . . . . . . . . . . . . 144
5.3
Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 146
5.3.1
The Fold Fusion Theorem . . . . . . . . . . . . . . . . . . . 147
5.3.2
The Streaming Theorem for list metamorphisms . . . . . . 151
5.3.3
The Greedy Theorem and the minimum coin change prob-
lem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 157
5.4
Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 169
6
Categorical equivalence of ornaments and relational algebras
173
6.1
Ornaments and horizontal transformations . . . . . . . . . . . . . 176
6.2
Ornaments and relational algebras . . . . . . . . . . . . . . . . . . 182
6.3
Consequences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 190
6.3.1
Parallel composition and the banana-split law . . . . . . . 190
6.3.2
Ornamental algebraic ornamentation . . . . . . . . . . . . 192
6.4
Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 194
7
Conclusion
197
Bibliography
201
Index of global deﬁnitions
211

xii
Contents

Chapter 1
Introduction
Programs are a unique engineering material as they can be constructed and
reasoned about entirely abstractly and even mathematically: while solutions
to engineering problems in general require more than mathematical reasoning,
program correctness with respect to their formal speciﬁcations — a mathemati-
cal subject in itself — is a concern separable from others, like suitability of the
speciﬁcations with respect to the actual engineering problems (see, e.g., Dijkstra
[1982]). One possible approach to program correctness is by veriﬁcation, in
which a program is ﬁrst written and then proved correct separately. For ex-
ample, let a speciﬁcation for imperative programs be a pair of predicates on
machine states — called the precondition and the postcondition — expressed in
ﬁrst-order logic; a program meets the speciﬁcation exactly when its execution
transforms any state satisfying the precondition to one satisfying the postcondi-
tion, which can be proved with Hoare logic [Hoare, 1969], i.e., by annotating the
program with Hoare triples. With this approach, however, the construction of a
program is in general detached from the construction of its correctness proof;
program development becomes strictly harder, since in addition to program
construction, there is now the extra burden of proof construction. The approach
was dismissed by Dijkstra as “putting the cart before the horse” [Dijkstra, 1974],
who instead argued that correctness proofs should be developed hand in hand
with — and even slightly ahead of — the programs, so correctness proofs can
“act as an inspiring heuristic guidance” on the exploration of the program space,
1

2
1
Introduction
thereby facilitating program construction rather than merely being an extra
burden. This leads to the methodology of program correctness by construction.
For example, instead of verifying the correctness of an imperative program
by subsequent annotation, we can simultaneously derive the program and its
correctness proof from the speciﬁcation in the ﬁrst place using the weakest
precondition calculus [Dijkstra, 1976; Gries, 1981; Kaldewaij, 1990], with the
whole development driven by the force of transforming the postcondition to
the precondition.
On the other hand, Martin-Löf developed intuitionistic type theory [Martin-
Löf, 1975, 1984b; Nordström et al., 1990] to serve as a foundation for intuitionistic
mathematics [Heyting, 1971; Dummett, 2000], like Bishop’s renowned work
on constructive analysis [Bishop and Bridges, 1985]. Central to the design of
intuitionistic type theory (which we simply call “type theory” henceforth) is the
propositions-as-types principle, which states that the notion of propositions
and proofs is subsumed by the notion of types and programs (see Section 2.1).
Consequently, type theory can be regarded simultaneously as a computationally
meaningful higher-order logic system and an expressively typed functional
programming language (whose type system is commonly referred to as de-
pendent types) — proof rules for constructing formal derivations in logic are
typed primitive terms in the programming language, and valid derivations of
propositions are typechecked programs. Compared with Hoare logic, in which
an imperative program can be similarly regarded as a formal derivation of a
transformation from one predicate to another, type theory is a more natural
and powerful system for achieving program correctness: A speciﬁcation for
functional programs is simply a proposition — i.e., a type — rather than a
predicate transformer (an apparently more complicated notion). Moreover, in
type theory, the proof rules available for deriving propositions are the standard,
structural ones from natural deduction [Gentzen, 1964; Prawitz, 2006], whereas
in Hoare logic, the available primitive transformers are more contrived, catering
for state-based computation. Most importantly, Hoare logic merely imposes a
special-purpose proof system on imperative programs, whereas type theory is
based on a fundamental uniﬁcation of proofs and programs, allowing them to
coexist in a uniform language and interact freely — in particular, we can state

1
Introduction
3
and prove various properties about existing programs all in the same language,
with the proving process being just additional programming.
The methodological distinction between program correctness by veriﬁcation
and by construction exists for type theory as well. With the former methodology,
we ﬁrst write a program under a simple type (just informative enough for
sanity checking) and then separately prove that the program satisﬁes some
correctness property; with the latter methodology, the correctness property
is encoded into a more sophisticated type such that any program having the
type is automatically guaranteed to be correct by typechecking. The distinction
is most signiﬁcant when inductive families [Dybjer, 1994] — simultaneously
inductively deﬁned families of types, sometimes simply referred to as “indexed
datatypes” — come into play. A type in general can be thought of as expressing
a programming problem to be solved (which was Kolmogorov’s interpretation
of intuitionistic propositions; see, e.g., Martin-Löf [1987]); the use of an inductive
family in a type suggests a particular decomposition of the problem into sub-
problems (see Section 2.2), and hence has a strong inﬂuence on the structure
of programs having that type. When inductive families are used for deﬁning
predicates that state properties about existing programs, they can inﬂuence
strategies for discharging proof obligations; more interestingly, when they are
used as datatypes that are directly programmed with, they can effectively
guide program construction by directly dictating what structure conforming
programs should have. The latter mode of programming, called internalism
in this dissertation, is the most distinguishing feature of dependently typed
programming [McBride, 2004; McKinna, 2006], while the former mode is called
externalism.
Both internalism and externalism are indispensable in dependently typed
program development (see Section 2.5): key correctness properties can provide
useful guidance on program construction and are best treated in the internalist
way, but there are also some other properties that are separable concerns and
thus should be dealt with separately via externalism. Whereas externalism is
a well understood concept, being deeply rooted in the mathematical tradition,
techniques and mechanisms for facilitating internalist programming are still
lacking. To provide more support for internalism, this dissertation proposes that

4
1
Introduction
internalist programming can be facilitated by exploiting an interconnection
between internalism and externalism, expressed as isomorphisms for converting
between internalist and externalist representations of data structures. Here an
internalist representation refers to an inductive family used as a datatype with
some built-in data structure invariant, while an externalist representation is
a basic datatype paired with a separate predicate stating the invariant. The
interconnection consists of two directions:
• one analysing any internalist datatype D into a basic datatype D′ known to
be related to D and a predicate on D′ stating the invariant encoded in D, and
• the other synthesising new internalist datatypes from a basic datatype and a
given class of predicates on the basic datatype.
More speciﬁcally, this dissertation shows that
• the analytic direction can be exploited for achieving a modular structure of
libraries of internalist datatypes, and
• the synthetic direction can bridge internalist programming with relational
speciﬁcations and program derivation [Bird and de Moor, 1997].
After Chapter 2 covers some preliminary background on dependently typed
programming, the above two applications and their supporting mechanisms are
respectively presented in Chapters 3 and 5. The supporting mechanisms are
based on McBride’s ornaments [2011]:
• modular library structure in Chapter 3 is achieved with parallel composition
of ornaments, and
• the bridging of internalism with relational programming in Chapter 5 is done
by (relational) algebraic ornamentation.
Some further theoretical characterisations of the two mechanisms using light-
weight category theory are respectively presented in Chapters 4 and 6. Finally
Chapter 7 concludes.
The dependently typed programming language Agda [Norell, 2007, 2009;
Bove and Dybjer, 2009] is chosen as the expository language of this disser-
tation.
Except for a major part of Chapter 6, the results in this disserta-
tion are completely formalised in Agda; the code base is available at https:

1
Introduction
5
//github.com/josh-hs-ko/Thesis.
Previous publications.
Chapter 3 is based on the paper Modularising inductive
families published in Progress in Informatics [Ko and Gibbons, 2013a], and Chap-
ter 5 on the paper Relational algebraic ornaments presented at the Workshop on
Dependently Typed Programming [Ko and Gibbons, 2013b]. All technical contribu-
tions of both papers are from the ﬁrst author.
□

6
1
Introduction

Chapter 2
From intuitionistic type theory to
dependently typed programming
This preliminary chapter serves three purposes:
• The general theme of the dissertation is set up by describing the propositions-
as-types-principle (Section 2.1) and its inﬂuence on program construction (Sec-
tion 2.5).
• It is explained that, while we adopt Agda as the expository language, we make
sure that every Agda program in this dissertation can at least in principle
be translated down to well-studied aspects of type theory — no mysterious
Agda-speciﬁc feature is used. Speciﬁcally, we brieﬂy discuss foundational
aspects of pattern matching (Section 2.2) and equality (Section 2.3).
• Most Agda-speciﬁc syntax, notational conventions, and basic constructions
used throughout the dissertation are also introduced. In particular, a universe
for “index-ﬁrst” inductive families is constructed (Section 2.4), which is the
basis of essentially all later constructions.
7

8
2
From intuitionistic type theory to dependently typed programming
2.1
Propositions as types
Mathematics is all about mental constructions, that is, the intuitive grasp and
manipulation of mental objects, the intuitionists say [Heyting, 1971; Dummett,
2000]. Take the natural numbers as an example. We have a distinct idea of
how natural numbers are built: start from an origin 0, and form its successor 1,
and then the successor of 1, which is 2, and so on. In other words, it is in our
nature to be able to count, and counting is just the way the natural numbers
are constructed. This construction then gives a speciﬁcation of when we can
immediately (i.e., directly intuitively) recognise a natural number, namely when
it is 0 or a successor of some other natural number, and this speciﬁcation of
immediately recognisable forms is one of the conditions of forming the set of
natural numbers in Martin-Löf’s intuitionistic type theory [Martin-Löf, 1975,
1984b; Nordström et al., 1990]. In symbols, we are justiﬁed by our intuition to
have the formation rule
Nat : Set
saying that we can conclude (below the line) that Nat is a set from no assump-
tions (above the line), and the two introduction rules
zero : Nat
n : Nat
suc n : Nat
specifying the canonical inhabitants of Nat, i.e., those inhabitants that are im-
mediately recognisable as belonging to Nat, namely zero and suc n whenever n is
an inhabitant of Nat. There are natural numbers which are not in canonical form
(like 1010) but instead encode an effective method for computing a canonical
inhabitant. We accept them as non-canonical inhabitants of Nat, as long as
they compute to a canonical form so we can see that they are indeed natural
numbers. Thus, to form a set, we should be able to recognise its inhabitants,
either directly or indirectly, as bearing a certain form and thus belonging to the
set, so the inhabitants of the set are intuitively clear to us as a certain kind of
mental construction.
What is more characteristic of intuitionism is that the intuitionistic interpreta-
tion of propositions — in particular the logical constants/connectives — follows

2.1
Propositions as types
9
the same line of thought as the speciﬁcation of the set of natural numbers.
A proposition is an expression of its truth condition, and since intuitionistic
truth follows from proofs, a proposition is clearly speciﬁed exactly when what
constitutes a proof of it is determined [Martin-Löf, 1987]. What is a proof of a
proposition, then? It is a piece of mental construction such that, upon inspection,
the truth of the proposition is immediately recognised. For a simple example,
in type theory we can formulate the formation rule for conjunctions
A : Set
B : Set
A ∧B : Set
and the introduction rule
a : A
b : B
(a , b) : A ∧B
saying that an immediately acceptable proof (canonical inhabitant) of A ∧B
is a pair consisting of a proof (inhabitant) of A and a proof (inhabitant) of B.
Any other (non-canonical) way of proving a conjunction must effectively yield
a proof in the form of a pair. The relationship between a proposition and its
proofs is thus exactly the same as the one between a set and its inhabitants —
the proofs must be effectively recognisable as proving the proposition. Hence, in
type theory, the notion of propositions and proofs is subsumed by the notion of
sets and inhabitants. This is called the propositions-as-types principle, which
reﬂects the observation that proofs are nothing but a certain kind of mental
construction.
Notice that the notion of “effective methods” — or computation — was
presumed when the notion of sets was introduced, and at some point we need
to concretely specify an effective method. Since the description of every set
includes an effective way to construct its canonical inhabitants, it is possible to
express an effective method that mimics the construction of an inhabitant by
saying that the computation has the same structure as how the inhabitant is
constructed, and the computation is guaranteed to terminate since the construc-
tion of the inhabitant is ﬁnitary. For a typical example, let us look again at the
natural numbers. Suppose that we have a family of sets P : Nat →Set indexed
by inhabitants of Nat. (Since we only aim to present a casual sketch of type

10
2
From intuitionistic type theory to dependently typed programming
theory, we take the liberty of using Agda functions (including Set-computing
ones like P above) in places where terms under contexts should have been
used.) If we have an inhabitant z of P zero and a method s that, for any n : Nat,
transforms an inhabitant of P n to an inhabitant of P (suc n), then we can
compute an inhabitant of P n for any given n by essentially the same counting
process with which we construct n, but the counting now starts from z instead
of zero and proceeds with s instead of suc. For instance, if a proof of P 2 is
required, we can simply apply s to z twice, just like we apply suc to zero twice to
form 2, so the computation was guided by the structure of 2. This explanation
justiﬁes the following elimination rule
P : Nat →Set
z : P zero
s : (n : Nat) →P n →P (suc n)
n : Nat
Nat-elim P z s n : P n
(The type of s illustrates Agda’s syntax for dependent function types — the
value n of the ﬁrst argument is referred to in the types of the second argument
and the result.) The symbol Nat-elim symbolises the method described above,
which, given P, z, and s, transforms any natural number n into an inhabitant
of the set P n. The actual computation performed by Nat-elim is stated as two
computation rules in the form of equality judgements (see Section 2.3):
P : Nat →Set
z : P zero
s : (n : Nat) →P n →P (suc n)
Nat-elim P z s zero = z ∈P zero
P : Nat →Set
z : P zero
s : (n : Nat) →P n →P (suc n)
n : Nat
Nat-elim P z s (suc n) = s n (Nat-elim P z s n) ∈P (suc n)
From the logic perspective, predicates on Nat are a special case of Nat-indexed
families of sets like P; Nat-elim then delivers the induction principle for natural
numbers, as it produces a proof of P n for any n : Nat if proofs z and s of the
base case and the inductive case can be constructed. In general, the propositions-
as-types principle treats logical entities as ordinary mathematical objects; the
logic hence inherits the computational meaning of intuitionistic mathematics
and becomes constructive.
By enabling the interplay of various sets governed by rules like the above
ones, type theory is capable of formalising various mental constructions we

2.1
Propositions as types
11
manipulate in mathematics in a fully computational way, making it a powerful
programming language. As Martin-Löf [1984a] noted: “If programming is
understood [. . .] as the design of the methods of computation [. . .], then it
no longer seems possible to distinguish the discipline of programming from
constructive mathematics”. Indeed, sets are easily comparable with inductive
datatypes in functional programming — a formation rule names a datatype,
the associated introduction rules list the constructors of the datatype, and the
associated elimination rule and computation rules deﬁne a precisely typed
version of primitive recursion on the datatype. Consequently, we identify “sets”
with “types”, and regard them as interchangeable terms.
The uniform treatment of programs and proofs in type theory reveals new
possibilities regarding proofs of program correctness. Traditional mathematical
theories employ a standalone logic language for talking about some postulated
objects. For example, Peano arithmetic is set up by postulating axioms about
natural numbers in the language of ﬁrst-order logic. Inside the postulated
system of natural numbers, there is no knowledge of logic formulas or proofs
(except via exotic encodings) — logic is at a higher level than the objects it
is used for talking about.
Programming systems based on such principle
(e.g., Hoare logic) then need to have a meta-level logic language to reason
about properties of programs. In dependently typed languages based on type
theory, however, the two traditional levels are coherently integrated into one, so
programs and their correctness proofs can be constructed together in the same
language. For example, the proposition ∀a : A. ∃b : B. R a b is interpreted as
the type of a function taking a : A to a pair consisting of b : B and a proof
of the proposition R a b, so the output of type B is guaranteed to be related
by R to the input of type A. Checking of proof validity reduces to typechecking,
and correctness proofs coexist with programs, as opposed to being separately
presented at a meta-level.
The propositions-as-types principle, however, can lead to a more intimate
form of program correctness by construction by blurring the distinction between
programs and proofs even further; this form of program correctness — called
internalism — is introduced in Section 2.5, which opens the central topic
studied in this dissertation. Before that, we make a transition from type theory

12
2
From intuitionistic type theory to dependently typed programming
to practical programming in Agda, starting with its pattern matching notation.
2.2
Elimination and pattern matching
The formation rules and introduction rules for sets in type theory directly
translate into inductive datatype declarations in functional programming. For
example, the set of natural numbers is translated into Agda as an inductive
datatype with two constructors, with their full types displayed:
data Nat : Set where
zero : Nat
suc
: Nat →Nat
In type theory, computations on inductive datatypes are speciﬁed using elimina-
tors like Nat-elim, whose style corresponds to recursion schemes [Meijer et al.,
1991] in functional programming. (In particular, Nat-elim is a more informatively
typed version of paramorphism [Meertens, 1992] on natural numbers.) One
reason for making elimination as the only option is that programs in type
theory are required to terminate — which is a consequence of the requirement
that an inhabitant should be effectively recognisable as belonging to a set, and
results in decidable typechecking — and using eliminators throughout is a
straightforward way of enforcing termination. On the other hand, in func-
tional programming, the pattern matching notation is widely used for deﬁning
programs on (inductive) datatypes (see, e.g., Hudak et al. [2007, Section 5])
in addition to recursion schemes. Pattern matching is vital to the clarity of
functional programs because it not only allows a function to be intuitively
deﬁned by equations suggesting how the function computes, but also clearly
conveys the programming strategy of splitting a problem into sub-problems by
case analysis.
When it comes to dependently typed programming, the situation becomes
more complicated due to the presence of inductive families [Dybjer, 1994], i.e.,
simultaneously inductively deﬁned families of sets, like the following:
data
⩽N
(m : Nat) : Nat →Set where
reﬂ
: m ⩽N m

2.2
Elimination and pattern matching
13
step : (n : Nat) →m ⩽N n →m ⩽N suc n
(An Agda name with underscores (like
⩽N ) can be applied to arguments
either by preﬁxing (like “ ⩽N
m n”) or by substituting the arguments for the
underscores with proper spacing (like “m ⩽N n”).) Reading the declaration
logically, the types of the two constructors reﬂand step give the two proof rules
for establishing that one natural number is less than or equal to another. More
generally, we read the declaration as a datatype parametrised by m : Nat (as
signiﬁed by its appearance right next to data
⩽N ) and indexed by Nat. For
any m : Nat, the type family
⩽N
m : Nat →Set as a whole is inductively
populated: we have an inhabitant reﬂin the set ( ⩽N
m) m, and whenever we
have an inhabitant p : ( ⩽N
m) n for some n : Nat, we can make a larger
inhabitant step n p in another set ( ⩽N
m) (suc n) in the family. (From now
on we usually refer to inductive families simply as datatypes, especially when
emphasising their use in programming and de-emphasising the distinction with
non-indexed datatypes like Nat.)
With inductive families, splitting a problem into sub-problems by case
analysis often leads to nontrivial reﬁnement of the goal type and the context,
and such reﬁnement can be tricky to handle with eliminators. Admittedly,
in terms of expressive power, pattern matching and elimination are basically
equivalent, as eliminators can be easily deﬁned by dependent pattern matching,
and conversely, it has been shown that dependent pattern matching can be
reduced to elimination if uniqueness of identity proofs — or, equivalently,
the K axiom [Streicher, 1993] — is assumed [McBride, 1999; Goguen et al.,
2006]. (See Section 2.3 for more on uniqueness of identity proofs.) Nevertheless,
there is a signiﬁcant notational advantage of recovering pattern matching in
dependently typed programming, especially with the support of an interactive
development environment for managing detail about datatype indices. Below
we look at an example of interactively constructing a program with pattern
matching in Agda, whose design was inspired by Epigram [McBride, 2004;
McBride and McKinna, 2004].

14
2
From intuitionistic type theory to dependently typed programming
2.2.1
Pattern matching and interactive development
Suppose that we are asked to prove that
⩽N
is transitive, i.e., to construct the
program
trans : (x y z : Nat) →x ⩽N y →y ⩽N z →x ⩽N z
(The “telescopic” quantiﬁcation “(x y z : Nat) →” is a shorthand for “(x :
Nat) (y : Nat) (z : Nat) →”, which, in turn, is a shorthand for “(x : Nat) →(y :
Nat) →(z : Nat) →”.) We deﬁne trans interactively by ﬁrst putting pattern
variables for the arguments on the left of the deﬁning equation and then
leaving an “interaction point” — also called a “goal” — on the right, which is
numbered 0. Agda then tells us that a term of type x ⩽N z is expected (shown
in the goal).
trans : (x y z : Nat) →x ⩽N y →y ⩽N z →x ⩽N z
trans x y z p q = { x ⩽N z }0
We instruct Agda to perform case analysis on q, and there are two cases: reﬂ
and step w r where r has type y ⩽N w. The original Goal 0 is split into two
sub-goals, and uniﬁcation is triggered for each sub-goal.
trans : (x y z : Nat) →x ⩽N y →y ⩽N z →x ⩽N z
trans x .z z
p x⩽N z reﬂ
= { x ⩽N z }1
trans x y .(suc w) p x⩽N y (step w r y⩽N w) = { x ⩽N suc w }2
In Goal 1, the type of reﬂdemands that y be uniﬁed with z, and hence the
pattern variable y is replaced with a “dot pattern” .z indicating that the value
of y is determined by uniﬁcation to be z. Therefore, upon enquiry, Agda tells
us that the type of p in the context — which was originally x ⩽N y — is now
x ⩽N z (shown in superscript next to p, which is not part of the Agda program
but only appears when interacting with Agda). Similarly for Goal 2, z is uniﬁed
with suc w and the goal type is rewritten accordingly. We see that the case
analysis has led to two sub-problems with different goal types and contexts,
where Goal 1 is easily solvable as there is a term in the context with the right
type, namely p.
trans : (x y z : Nat) →x ⩽N y →y ⩽N z →x ⩽N z
trans x .z z
p
reﬂ
= p

2.2
Elimination and pattern matching
15
trans x y .(suc w) p x⩽N y (step w r y⩽N w) = { x ⩽N suc w }2
The second goal type x ⩽N suc w looks like the conclusion in the type of the
term step w : x ⩽N w →x ⩽N suc w, so we use this term to reduce Goal 2 to
Goal 3, which now requires a term of type x ⩽N w.
trans : (x y z : Nat) →x ⩽N y →y ⩽N z →x ⩽N z
trans x .z z
p
reﬂ
= p
trans x y .(suc w) p x⩽N y (step w r y⩽N w) = step w { x ⩽N w }3
Now we see that the induction hypothesis term trans x y w p r : x ⩽N w has
the right type. Solving Goal 3 with this term completes the program.
trans : (x y z : Nat) →x ⩽N y →y ⩽N z →x ⩽N z
trans x .z z
p reﬂ
= p
trans x y .(suc w) p (step w r) = step w (trans x y w p r)
In contrast, if we stick to the default elimination approach in type theory, we
would use the eliminator
⩽N-elim : (m : Nat) (P : (n : Nat) →m ⩽N n →Set) →
P m reﬂ→
((n : Nat) (t : m ⩽N n) →P n t →P (suc n) (step n t)) →
(n : Nat) (t : m ⩽N n) →P n t
and write
trans : (x y z : Nat) →x ⩽N y →y ⩽N z →x ⩽N z
trans x y z p q = ⩽N-elim y (λ y′
7→x ⩽N y →x ⩽N y′)
(λ p′ 7→p′) (λ w r ih p′ 7→step w (ih p′)) z q p
We are forced to write the program in continuation passing style, where the two
continuations correspond to the two clauses in the pattern matching version
and likewise have more speciﬁc goal types, and the relevant context (p in this
case) must be explicitly passed into the continuations in order to be reﬁned
to a more speciﬁc type. Even with interactive support, the eliminator version
is inherently harder to write and understand, especially when complicated
dependent types are involved. If a function deﬁnition requires more than one
level of elimination, then the advantage of using pattern matching over using
eliminators becomes even more apparent.

16
2
From intuitionistic type theory to dependently typed programming
2.2.2
Pattern matching on intermediate computation
It is often the case that we need to perform pattern matching not only on an ar-
gument but also on some intermediate computation. In simply typed languages,
this is usually achieved by “case expressions”, a special case being if-then-else
expressions for booleans. But again, pattern matching on intermediate computa-
tion can make reﬁnements to the goal type and the context in dependently typed
languages, so case expressions — being more like eliminators — become less
convenient. McBride and McKinna [2004] thus proposed with-matching, which
generalises pattern guards [Peyton Jones, 1997] and shifts pattern matching on
intermediate computations from the right of an equation to the left, thereby
granting them equal status with pattern matching on arguments, in particular
the power to reﬁne contexts and goal types.
Example (insertion into a list).
To demonstrate the syntax of with-matching,
we give a simple example of writing the function inserting an element into a
list as used in, e.g., insertion sort. (More precisely, the element is inserted at the
rightmost position to the left of which all elements are strictly smaller.) First we
deﬁne the usual list datatype:
data List (A : Set) : Set where
[]
: List A
::
: A →List A →List A
and (throughout this dissertation) let Val : Set be equipped with a decidable
total preorder, i.e., there is a relation
⩽
: Val →Val →Set
with the following operations:
⩽-reﬂ
: {x : Val} →x ⩽x
⩽-trans
: {x y z : Val} →x ⩽y →y ⩽z →x ⩽z
⩽?
: (x y : Val) →Dec (x ⩽y)
-- see below
≰-invert : {x y : Val} →¬ (x ⩽y) →y ⩽x
where Dec is the following datatype witnessing whether a set is inhabited or
not:
data Dec (A : Set) : Set where

2.2
Elimination and pattern matching
17
yes :
A →Dec A
no : ¬ A →Dec A
-- ¬ A = A →⊥, where ⊥is the empty set
(Quantiﬁcations like {x : Val} are implicit arguments to a function. They can
be omitted when applying the function, and Agda will try to infer them.) The
insertion function is then written as
insert : Val →List Val →List Val
insert y [] = y :: []
insert y (x :: xs) with y ⩽? x
insert y (x :: xs) | yes
= y :: x :: xs
insert y (x :: xs) | no
= x :: insert y xs
The result of the intermediate computation y ⩽? x : Dec (y ⩽x) is matched
against yes and no on the left-hand side of the last two equations, just like we are
performing pattern matching on a new argument. (In fact, Agda implements
with-matching exactly by synthesising an auxiliary function with an additional
argument [Norell, 2007, Section 2.3].) The witnesses carried by yes and no are
ignored in this case (their names are suppressed by underscores), but in general
these can be proofs that are further matched and change the context and the
goal type. (Admittedly, this is a trivial example with regard to the full power of
with-matching, but insert will be used in later examples in this dissertation.) □
An important application of with-matching is McBride and McKinna’s
adaptation [2004] of Wadler’s views [1987] — or “customised pattern matching”
— for dependently typed programming. Suppose that we wish to implement
a snoc-list view for cons-lists, i.e., to say that a list is either empty or has the
form ys ++ (y :: []) (where
++ is list append, a deﬁnition of which is shown
in Section 2.4.2). We would deﬁne the following view type
data SnocView {A : Set} : List A →Set where
nil
: SnocView []
snoc : (ys : List A) (y : A) →SnocView (ys ++ (y :: []))
and write a covering function for the view:
snocView : {A : Set} (xs : List A) →SnocView xs
snocView [] = nil
snocView (x :: xs)
with snocView xs

18
2
From intuitionistic type theory to dependently typed programming
snocView (x :: .[])
| nil
= snoc [] x
snocView (x :: .(ys ++ (y :: []))) | snoc ys y = snoc (x :: ys) y
Note that the type of snocView ensures that every list is covered under one
constructor of SnocView. Also, this is a nontrivial example of with-matching,
because performing pattern matching on the result of snocView xs reﬁnes xs in
the context to either [] or ys ++ (y :: []), and the reﬁnement is propagated to the
goal type. Now, for example, the function init which removes the last element
(if any) in a list can be implemented simply as
init : {A : Set} →List A →List A
init xs
with snocView xs
init .[]
| nil
= []
init .(ys ++ (y :: [])) | snoc ys y = ys
Views are not enough for dependently typed programming, though; they
offer customised case analysis but not terminating recursion. McBride and
McKinna [2004] proposed a general mechanism for invoking any programmer-
deﬁned eliminator using the pattern matching syntax, so the programmer can
choose whichever recursive problem-splitting strategy they needs and express
it conveniently with pattern matching. This mechanism is not implemented in
Agda, but it is implemented in Epigram, and greatly improves readability of
dependently typed programs. Speciﬁcally, Epigram syntax makes it clear which
and in what order eliminators are invoked, so programs are easily guaranteed to
be based on elimination — and thus be terminating — while remaining readable.
Agda’s design does not emphasise reducibility to elimination, but almost all
the recursive programs in this dissertation are written with this in mind, so
termination is evident even without understanding Agda’s termination checker
in detail. Also, although Agda provides pattern matching only for datatype
constructors, all but one of the recursive programs in this dissertation use
default structural induction (without need of programmer-deﬁned elimination),
so Agda syntax sufﬁces. (The exception is the ﬁnal program in Section 5.3.3,
where we use an explicit eliminator.)

2.3
Equality
19
2.3
Equality
In logic, the intension of a concept is its deﬁning description, while the ex-
tension of the concept is the range of objects it refers to. Two concepts can
differ intensionally yet agree extensionally when they use different ways to
describe the same range of objects. Classical mathematics cares about extensions
only (e.g., the axiom of extensionality in set theory deﬁnes that two sets are
equal exactly when they have the same inhabitants, regardless of how they
are described), whereas in intuitionistic mathematics, objects are given to us
as mental constructions, which are inherently intensional descriptions. As a
consequence, the fundamental equality for intuitionistic mathematics is inten-
sional [Dummett, 2000, Section 1.2], since we can only compare the intensional
descriptions given to us, and furthermore it might be impossible to effectively
recognise whether two intensionally different constructions are extensionally
the same. For example, functions describing different computational procedures
are intensionally distinguished even when they always map the same input
to the same output, as it is well known that pointwise equality of functions
is undecidable. We can, of course, still talk about extensional equalities in
intuitionistic mathematics, but they are just treated as ordinary propositions.
The fundamental equality is formulated in type theory as judgemental
equality, a meta-level notion for determining whether two types match in type-
checking, which also involves determining whether two terms match because
types can contain terms. (The computation rules for Nat-elim in Section 2.1 are
examples of judgemental equalities between terms.) If we take the position
of intuitionistic mathematics seriously, judgemental equality would be chosen
to be the intensional, syntactic equality — also called deﬁnitional equality —
which can be implemented by reducing two types/terms to normal forms and
checking whether the normal forms match. The resulting type theory is called
an intensional type theory; its characteristic feature is decidable typecheck-
ing (enabling effective recognition of set membership) due to decidability of
judgemental equality. Agda, in particular, is intensional in this sense.
Judgemental equality — being a meta-level notion — is not an entity inside
the theory. To state equality between two terms as a proposition and have proof

20
2
From intuitionistic type theory to dependently typed programming
for that proposition inside the theory, we need propositional equality, which
can be deﬁned in Agda by the following inductive family:
data
≡
{A : Set} (x : A) : A →Set where
reﬂ: x ≡x
The canonical way to prove an equality proposition x ≡y is reﬂ, which is
permitted when x and y are judgementally equal. Under contexts, however, it
is possible to prove that two judgementally different terms are propositionally
equal. For example, the following “catamorphic” identity function on natural
numbers
id′ : Nat →Nat
id′ zero
= zero
id′ (suc n) = suc (id′ n)
can be shown to be pointwise equal to the polymorphic identity function
id : {A : Set} →A →A
id x = x
That is, given n : Nat in the context, even though the two open terms id n
(which is deﬁnitionally just n) and id′ n are judgementally different, we can
still prove id n ≡
id′ n by induction (elimination) on n, whose two cases
instantiate n to a more speciﬁc form and make computation on id′ n happen.
One might say that propositional equality — in this most basic, inductive form —
is “delayed” judgemental equality as a proposition: the judgementally different
terms id n and id′ n would compute to the same canonical term — and hence
become judgementally equal — after substituting a canonical natural number
for n, turning them into closed terms and allowing the computation to complete.
Formally, this is stated as the “reﬂection principle”: two propositionally equal
closed terms are judgementally equal (see, e.g., Luo [1994, Section 5.1.3] and
Streicher [1993, Section 1.1]).
A propositional equality satisfying the reﬂection principle — e.g., the Agda
one — can sometimes be too discriminating. For example, in category theory
(which we use in Chapters 4 and 6), a universal function (i.e., a universal
morphism in the category of sets and total functions) is unique up to extensional
(i.e., pointwise) equality, but pointwise propositionally equal functions are

2.3
Equality
21
usually not propositionally equal themselves. (If, under the empty context, two
pointwise propositionally equal functions are propositionally equal themselves,
then by the reﬂection principle they are also judgementally equal, but the two
functions can well have different intensions.) Of course, we can explicitly work
with pointwise equality on functions, i.e., establishing and using properties
formulated in terms of the relation
.=
: {A B : Set} →(A →B) →(A →B) →Set
.= {A} f g = (x : A) →f x ≡g x
(The implicit argument A is explicitly displayed in curly braces on the left-hand
side of the equation since we need to refer to it on the right-hand side.) Not
being able to identify extensionally equal functions propositionally, however,
means that for extensionally equal functions we do not automatically get basic
properties like
cong : {A B : Set} (f : A →B) {x y : A} →x ≡y →f x ≡f y
i.e., a function maps equal arguments to equal results, and
subst : {A : Set} (P : A →Set) {x y : A} →x ≡y →P x →P y
i.e., inhabitants in an indexed set can be transported to another set with an
equal index. We would need to prove such properties for every entity like
f and P on a case-by-case basis, which quickly becomes tedious.
Several foundational modiﬁcations to intensional type theory have been
proposed to obtain a more liberal notion of equality. While this dissertation
sticks to Agda’s intensional approach and does not adopt any of the alternatives,
it is interesting to reﬂect on the relationship between these alternatives and our
development.
• A simple yet radical approach is to add the equality reﬂection rule to the
theory, injecting propositional equality back into judgemental equality.
x : A
y : A
eq : x ≡y
x = y ∈A
Extensionally equal functions become judgementally equal (and thus propo-
sitionally equal) in such a theory: Suppose that f and g are functions of type
A →B and we have a proof

22
2
From intuitionistic type theory to dependently typed programming
fgeq : (x : A) →f x ≡g x
Then, judgementally,
f
=
{ η-expansion }
λ x 7→f x
=
{ equality reﬂection — f x = g x ∈B since fgeq x : f x ≡g x }
λ x 7→g x
=
{ η-contraction }
g
∈A →B
The judgemental equality is thus able to identify pointwise equal functions
and becomes extensional, and such a theory is called an extensional type the-
ory (see, e.g., Nordström et al. [1990, Section 8.2]). In extensional type theory,
combinators like subst become unnecessary, since having a proof of x ≡y
means that x and y are identiﬁed judgementally and hence are regarded as
the same during typechecking, so P x and P y are simply the same type —
no explicit transportation is needed. Consequently, programs become very
lightweight, with all the equality justiﬁcations moved to typing derivations
at the meta-level. The downside is that typechecking in extensional type
theory is undecidable, because whenever there is possibility that the equality
reﬂection rule is needed, the typechecker would have to somehow determine
whether there is a suitable equality proof, for which there is no effective
procedure. This is not a big problem for proof assistants like Nuprl [Con-
stable et al., 1985], in which the programmer instructs the proof assistant
to construct typing derivations and can supply the right proof when using
the equality reﬂection rule. (Nuprl, in fact, simply identiﬁes judgemental
equality and propositional equality and does not have the equality reﬂection
rule explicitly.) But for programming languages like Ωmega [Sheard and
Linger, 2007], equality reﬂection does present a problem, since the program-
mer constructs a term only, and the typing derivation has to be constructed by
the typechecker, which then has to search for proofs. Ωmega can take hints
from the programmer so the proof search is more likely to succeed, but the
fundamental problem is that justiﬁcation of program correctness now relies

2.3
Equality
23
on the proof searching algorithm and is tied to the implementation detail
of a speciﬁc programming system. Since the focus of this dissertation is on
dependently typed programming, extensional type theory is not a satisfactory
foundation.
• Altenkirch et al. [2007] proposed a variant of intensional type theory called
observational type theory, which deﬁnes propositional equality to be an ex-
tensional one — in particular, propositional equality on functions is pointwise
equality — but retains computational behaviour (strong normalisation and
canonicity) and decidable typechecking of intensional type theory. We step
away from observational type theory merely for a practical reason: the theory
is not implemented natively in any programming system yet. While it might
be possible to model observational equality in Agda to some extent and
then construct the universes of descriptions (Section 2.4) and ornaments (Sec-
tion 3.2) inside the observational model, developing and programming within
the nested model would be too complex to be worthwhile.
• A new direction is being pursued by homotopy type theory [The Univalent
Foundations Program, 2013], which gives propositional equality a higher-
dimensional homotopic interpretation and broadens its scope with the uni-
valence axiom and higher inductive types, but the computational meaning
of the theory remains an open problem. Its investigations into the higher
dimensional structure of propositional equality might eventually lead to a
systematic treatment of equality in dependently typed programming. For this
dissertation, however, we conﬁne ourselves to the zero-dimensional setting,
in which we freely invoke uniqueness of identity proofs, which is deﬁnable
in Agda by pattern matching:
UIP : {A : Set} {x y : A} (p q : x ≡y) →p ≡q
UIP reﬂreﬂ= reﬂ
In particular, in deﬁnitions of speciﬁc categories in Chapter 4, we employ
McBride’s “John Major” heterogeneous equality [McBride, 1999], which was
shown by McBride to be equivalent to propositional equality equipped with
uniqueness of identity proofs. Our identiﬁcation of types and sets is thus
consistent with the terminology of homotopy type theory: types on which
identity proofs are unique (and hence lack higher dimensional structure) are

24
2
From intuitionistic type theory to dependently typed programming
indeed termed “sets” by homotopy type theorists [The Univalent Foundations
Program, 2013, Section 3.1].
With only Agda’s intensional equality, we have to explicitly work with
equality-like propositions (like pointwise equality on functions) and manage
them with the help of setoids [Barthe et al., 2003] in this dissertation — Chapters
4 and 6, speciﬁcally. We will discuss to what extent the intensional approach
works at the end of Section 4.4.
2.4
Universes and datatype-generic programming
Martin-Löf [1984b] introduced the notion of universes to support “large elimina-
tion”, i.e., arbitrary computation of sets, which is necessary for establishing the
fourth Peano axiom that zero is not the successor of any natural number [Smith,
1988]. A universe (à la Tarski) is a set of codes for sets, which is equipped
with a decoding function translating codes to sets. Large elimination is then
computing an inhabitant in the universe (via ordinary elimination like Nat-elim)
and decoding the result to a set. Another important purpose of universes is
to support quantiﬁcation over sets while precluding paradoxical formation of
self-referential sets — Agda, for example, has a universe hierarchy (Set, Set1,
Set2, . . .) for this purpose. From the programming perspective, however, the
most interesting case is when the universe is supplied with an elimination
rule [Nordström et al., 1990, Section 14.2]: allowing computation on universes
turns out to roughly correspond to datatype-generic programming [Gibbons,
2007a], whose idea is that the “shapes” of datatypes can be encoded so programs
can be deﬁned in terms of these shapes. Universes can encode such shapes, and
since universes are just ordinary sets, datatype-generic programming becomes
just ordinary programming in dependently typed languages [Altenkirch and
McBride, 2003].
In this dissertation we not only use but also need to compute a class of
inductive families which we call index-ﬁrst datatypes [Chapman et al., 2010;
Dagand and McBride, 2014], and hence need to construct a universe for them.
Before that, we give a high-level introduction to these datatypes ﬁrst.

2.4
Universes and datatype-generic programming
25
2.4.1
Index-ﬁrst datatypes
In Agda, an inductive family is declared by listing all possible constructors
and their types, all ending with one of the types in that inductive family. This
conveys the idea that the index in the type of an inhabitant is synthesised in a
bottom-up fashion following the construction of the inhabitant. For example,
consider the following datatype of vectors, i.e., length-indexed lists:
data Vec (A : Set) : Nat →Set where
[]
: Vec A zero
::
: A →{n : Nat} →Vec A n →Vec A (suc n)
The cons constructor
::
takes a vector at some index n and constructs a
vector at suc n — the ﬁnal index is computed bottom-up from the index of the
sub-vector. This synthetic view is not always helpful in dependently typed
programming, though (see, e.g., McBride [2014]); also, it can yield redundant
representation — the cons constructor for vectors has to store the index of the
sub-vector, so the representation of a vector would be cluttered with all the
intermediate lengths. If we switch to the opposite perspective, determining
top-down from the targeted index what constructors should be supplied, then
the representation can usually be signiﬁcantly cleaned up — for a vector, if
the index of its type is known to be suc n for some n, then we know that its
top-level constructor can only be cons and the index of the sub-vector must
be n. To reﬂect this important reversal of logical order, Dagand and McBride
[2014] proposed a new notation for index-ﬁrst datatype declarations, in which
we ﬁrst list all possible patterns of (the indices of) the types in the inductive
family, and then specify for each pattern which constructors it offers. Below we
use a slightly more Agda-like adaptation of the notation.
For a ﬁrst example, natural numbers are declared by
indexﬁrst data Nat : Set where
Nat ∋zero
| suc (n : Nat)
We use the keyword indexﬁrst to explicitly mark the declaration as an index-
ﬁrst one, distinguishing it from an Agda datatype declaration. The only possible
pattern of the datatype is Nat, which offers two constructors zero and suc, the

26
2
From intuitionistic type theory to dependently typed programming
latter taking a recursive argument named n. We declare lists similarly, this time
with a uniform parameter A : Set:
indexﬁrst data List (A : Set) : Set where
List A ∋[]
|
::
(a : A) (as : List A)
The declaration of vectors is more interesting, fully exploiting the power of
index-ﬁrst datatypes:
indexﬁrst data Vec (A : Set) : Nat →Set where
Vec A zero
∋[]
Vec A (suc n) ∋
::
(a : A) (as : Vec A n)
Vec A is a family of types indexed by Nat, and we do pattern matching on
the index, splitting the datatype into two cases Vec A zero and Vec A (suc n)
for some n : Nat. The ﬁrst case only offers the nil constructor [], and the
second case only offers the cons constructor
:: . Because the form of the index
restricts constructor choice, the recursive structure of a vector as : Vec A n must
follow that of n, i.e., the number of cons nodes in as must match the number
of successor nodes in n. We can also declare the bottom-up vector datatype in
index-ﬁrst style:
indexﬁrst data Vec′ (A : Set) : Nat →Set where
Vec′ A n ∋nil (neq : zero ≡n)
| cons (a : A) (m : Nat) (meq : suc m ≡n) (as : Vec′ A m)
Besides the ﬁeld m storing the length of the tail, two more ﬁelds neq and meq
are inserted, demanding explicit equality proofs about the indices. When a
vector of type Vec′ A n is demanded, we are “free” to choose between nil or
cons regardless of the index n; however, because of the equality constraints, we
are indirectly forced into a particular choice.
Remark (recursive families).
Vectors can also be deﬁned as a “recursive fam-
ily” [Capretta, 2000], i.e., an indexed family of types deﬁned by induction on
the index:
Vec : Set →Nat →Set
Vec A zero
= ⊤
Vec A (suc n) = A × Vec A n

2.4
Universes and datatype-generic programming
27
Recursive families are not subject to the usual “strict positivity” condition
imposed on inductive datatypes (see, e.g., Coquand and Paulin-Mohring [1990]).
With recursive families, however, the index in the type of a sub-object has to be
structurally smaller, whereas inductive families do not have this restriction. An
example is the BHeap datatype in Section 3.4.2.
□
Remark (detagging).
The transformation from bottom-up vectors to top-down
vectors is exactly what Brady et al.’s detagging optimisation [2004] does. With
index-ﬁrst datatypes, however, detagged representations are available directly,
rather than arising from a compiler optimisation.
□
2.4.2
Universe construction
Now we proceed to construct a universe for index-ﬁrst datatypes. An inductive
family of type I →Set is constructed by taking the least ﬁxed point of a base
endofunctor on I →Set. For example, to get index-ﬁrst vectors, we would
deﬁne a base functor (parametrised by A : Set)
VecF A : (Nat →Set) →(Nat →Set)
VecF A X zero
= ⊤
VecF A X (suc n) = A × X n
and take its least ﬁxed point. (⊤is a singleton set whose only inhabitant is “ ”,
and
× is cartesian product.) If we ﬂip the order of the arguments of VecF A:
VecF′ A : Nat →(Nat →Set) →Set
VecF′ A zero
= λ X 7→⊤
VecF′ A (suc n) = λ X 7→A × X n
we see that VecF′ A consists of two different “responses” to the index request,
each of type (Nat →Set) →Set. It sufﬁces to construct for such responses a
universe
data RDesc (I : Set) : Set1
with a decoding function specifying its semantics:
[[ ]] : {I : Set} →RDesc I →(I →Set) →Set

28
2
From intuitionistic type theory to dependently typed programming
Inhabitants of RDesc I will be called response descriptions. A function of type
I →RDesc I, then, can be decoded to an endofunctor on I →Set, so the type
I →RDesc I acts as a universe for index-ﬁrst datatypes. We hence deﬁne
Desc : Set →Set1
Desc I = I →RDesc I
with decoding function
F : {I : Set} →Desc I →(I →Set) →(I →Set)
F D X i = [[ D i ]] X
Inhabitants of type Desc I will be called datatype descriptions, or descriptions
for short. Actual datatypes are manufactured from descriptions by the least
ﬁxed point operator:
data µ {I : Set} (D : Desc I) : I →Set where
con : F D (µ D) ⇒µ D
where
⇒
is deﬁned by
⇒
: {I : Set} →(I →Set) →(I →Set) →Set
⇒
{I} X Y = {i : I} →X i →Y i
Remark (presentation of universes and their decoding).
We always present uni-
verses (e.g., RDesc) along with their decoding (e.g., [[ ]] for RDesc) to emphasise
the meaning of the codes, even when the decoding is not logically tied to the
codes (cf. Martin-Löf’s universe [1984b], which is inductive-recursive [Dybjer,
1998] and must be presented with its decoding simultaneously).
□
Notation (dependent pairs and Agda records).
Cartesian product is a special
case of Σ-types, also known as dependent pairs, which are deﬁned in Agda as
a record:
record Σ (A : Set) (X : A →Set) : Set where
constructor
,
ﬁeld
outl : A
outr : X outl
inﬁxr 4
,

2.4
Universes and datatype-generic programming
29
open Σ
syntax Σ A (λ a 7→T) = Σ[ a : A ] T
An inhabitant of Σ A X is a pair where the type of the second component
depends on the ﬁrst component; it is written by listing values for the ﬁelds like
record { outl = a
; outr = x }
(where a : A and x : X a) — a cartesian product A × B is thus a special case,
which is deﬁned as Σ A (λ
7→B). The constructor declaration gives rise to a
constructor function
,
: {A : Set} {X : A →Set} →(a : A) →X a →Σ A X
which associates to the right when used as an inﬁx operator because of the
inﬁxr statement below, and can be used in pattern matching. The two ﬁeld
declarations give rise to two projection functions, qualiﬁed by “Σ.”:
Σ.outl : {A : Set} {X : A →Set} →Σ A X →A
Σ.outr : {A : Set} {X : A →Set} →(p : Σ A X) →X (Σ.outl p)
We can drop the qualiﬁcations and refer to them simply as outl and outr due to
the open statement. Finally, we can treat Σ as a binder and write, e.g., Σ A X as
Σ[ a : A ] X a, due to the syntax statement.
□
We now deﬁne the datatype of response descriptions — which determines
the syntax available for deﬁning base functors — and its decoding function:
data RDesc (I : Set) : Set1 where
v : (is : List I) →RDesc I
σ : (S : Set) (D : S →RDesc I) →RDesc I
[[ ]] : {I : Set} →RDesc I →(I →Set) →Set
[[ v is
]] X = P is X
-- see below
[[ σ S D ]] X = Σ[ s : S ] [[ D s ]] X
The operator P computes the product of a ﬁnite number of types in a type
family, whose indices are given in a list:
P : {I : Set} →List I →(I →Set) →Set
P []
X = ⊤
P (i :: is) X = X i × P is X

30
2
From intuitionistic type theory to dependently typed programming
Thus, in a response, given X : I →Set, we are allowed to form dependent
sums (by σ) and the product of a ﬁnite number of types in X (via v, suggesting
variable positions in the base functor).
Convention.
We informally refer to the index part of a σ as a ﬁeld of the
datatype. Like Σ, we sometimes regard σ as a binder and write σ[ s : S ] D s for
σ S (λ s 7→D s).
□
Example (natural numbers).
The datatype of natural numbers is considered
to be an inductive family trivially indexed by ⊤, so the declaration of Nat
corresponds to an inhabitant of Desc ⊤.
data ListTag : Set where
‘nil
: ListTag
‘cons : ListTag
NatD : Desc ⊤
NatD
= σ ListTag λ { ‘nil
7→v []
; ‘cons 7→v ( :: []) }
The index request is necessarily , and we respond with a ﬁeld of type ListTag
representing the constructor choices. A pattern-matching lambda function
(which is syntactically distinguished by enclosing its body in curly braces)
follows, which computes the trailing responses to the two possible values ‘nil
and ‘cons for the ﬁeld: if the ﬁeld receives ‘nil, then we are constructing zero,
which takes no recursive values, so we write v [] to end this branch; if the
ListTag ﬁeld receives ‘cons, then we are constructing a successor, which takes a
recursive value at index , so we write v ( :: []).
□
Example (lists).
The datatype of lists is parametrised by the element type. We
represent parametrised descriptions simply as functions producing descriptions,
so the declaration of lists corresponds to a function taking element types to
descriptions.
ListD : Set →Desc ⊤
ListD A
= σ ListTag λ { ‘nil
7→v []
; ‘cons 7→σ[
: A ] v ( :: []) }

2.4
Universes and datatype-generic programming
31
ListD A is the same as NatD except that, in the ‘cons case, we use σ to insert a
ﬁeld of type A for storing an element.
□
Example (vectors).
The datatype of vectors is parametrised by the element type
and (nontrivially) indexed by Nat, so the declaration of vectors corresponds to
VecD : Set →Desc Nat
VecD A zero
= v []
VecD A (suc n) = σ[
: A ] v (n :: [])
which is directly comparable to the index-ﬁrst base functor VecF′ at the begin-
ning of this section.
□
There is no problem deﬁning functions on the encoded datatypes, except
that it has to be done with the raw representation. For example, list append is
deﬁned by
++
: µ (ListD A)
→µ (ListD A)
→µ (ListD A)
con (‘nil
,
) ++ bs = bs
con (‘cons , a , as , ) ++ bs = con (‘cons , a , as ++ bs , )
To improve readability, we deﬁne the following higher-level terms:
List : Set →Set
List A = µ (ListD A)
[] : {A : Set} →List A
[] = con (‘nil , )
::
: {A : Set} →A →List A →List A
a :: as = con (‘cons , a , as , )
List append can then be rewritten in the usual form:
++
: List A →List A →List A
[]
++ ys = ys
(x :: xs) ++ ys = x :: (xs ++ ys)
(Agda supports such deﬁnitions of higher-level terms by “pattern synonyms”,
which we do not explicitly use in this dissertation.) Later on, encoded data-
types are almost always accompanied by corresponding index-ﬁrst datatype
declarations, which are thought of as giving deﬁnitions of higher-level terms

32
2
From intuitionistic type theory to dependently typed programming
mutual
fold : {I : Set} {D : Desc I} {X : I →Set} →(F D X ⇒X) →(µ D ⇒X)
fold {I} {D} f {i} (con ds) = f (mapFold D (D i) f ds)
mapFold : {I : Set} (D : Desc I) (D′ : RDesc I) →
{X : I →Set} →(F D X ⇒X) →[[ D′ ]] (µ D) →[[ D′ ]] X
mapFold D (v [])
f
=
mapFold D (v (i :: is)) f (d , ds) = fold f d , mapFold D (v is) f ds
mapFold D (σ S D′)
f (s , ds) = s , mapFold D (D′ s) f ds
Figure 2.1
Deﬁnition of the datatype-generic fold operator.
for type and data constructors — the terms List, [], and
::
above, for example,
can be considered to be deﬁned by the index-ﬁrst declaration of lists given in
Section 2.4.1. Index-ﬁrst declarations will only be regarded in this dissertation
as informal hints at how encoded datatypes are presented at a higher level;
we do not give a formal treatment of the elaboration process from index-ﬁrst
declarations to corresponding descriptions and deﬁnitions of higher-level terms.
(One such treatment was given by Dagand and McBride [2012].)
Direct function deﬁnitions by pattern matching work ﬁne for individual
datatypes, but when we need to deﬁne operations and to state properties for
all the datatypes encoded by the universe, it is necessary to have a generic fold
operator parametrised by descriptions:
fold : {I : Set} {D : Desc I} {X : I →Set} →(F D X ⇒X) →(µ D ⇒X)
The implementation of fold, shown in Figure 2.1, is adapted for our two-level
universe from those in McBride’s original work [2011]. As McBride, we would
have wished to deﬁne fold by
fold : {I : Set} {D : Desc I} {X : I →Set} →(F D X ⇒X) →(µ D ⇒X)
fold {I} {D} f {i} (con ds) = f (mapRD (D i) (fold f) ds)
where the functorial mapping mapRD on response structures is deﬁned by
mapRD : {I : Set} (D : RDesc I) →
{X Y : I →Set} (g : X ⇒Y) →[[ D ]] X →[[ D ]] Y

2.4
Universes and datatype-generic programming
33
mapRD (v [])
g
=
mapRD (v (i :: is)) g (x , xs) = g x , mapRD (v is) g xs
mapRD (σ S D)
g (s , xs) = s , mapRD (D s) g xs
Agda does not see that this deﬁnition of fold is terminating, however, since the
termination checker does not expand the deﬁnition of mapRD to see that fold f
is applied to structurally smaller arguments. To make termination obvious
to Agda, we instead deﬁne fold mutually recursively with mapFold, which is
mapRD specialised by ﬁxing its argument g to fold f.
Example (list length).
The function length : {A : Set} →List A →Nat can be
deﬁned in terms of the datatype-generic fold:
length : {A : Set} →List A →Nat
length = fold length-alg
where the algebra length-alg is deﬁned by
length-alg : {A : Set} →F (ListD A) (const Nat) ⇒const Nat
length-alg (‘nil
,
) = zero
length-alg (‘cons , a , n , ) = suc n
(The function const is deﬁned as λ x y 7→x.)
□
It is helpful to form a two-dimensional image of our datatype manufacturing
scheme: We manufacture a datatype by ﬁrst deﬁning a base functor, and then
recursively duplicating the functorial structure by taking its least ﬁxed point.
The shape of the base functor can be imagined to stretch horizontally, whereas
the recursive structure generated by the least ﬁxed point grows vertically. This
image works directly when the recursive structure is linear, like lists. (Otherwise
one resorts to the abstraction of functor composition.) For example, we can
typeset a list two-dimensionally like
con (‘cons , a ,
con (‘cons , b ,
con (‘nil
,
) , ) , )
Ignoring the last line of trailing ’s, things following con on each line — includ-
ing constructor tags and list elements — are shaped by the base functor of lists,

34
2
From intuitionistic type theory to dependently typed programming
whereas the con nodes — aligned vertically — are generated by the least ﬁxed
point.
Remark (ﬁrst-order vs higher-order representation).
The functorial structures gen-
erated by descriptions are strongly reminiscent of indexed containers [Morris,
2007, Chapter 8]; this will be explored and exploited in Chapter 6. For now,
it is enough to mention that we choose to stick to a ﬁrst-order datatype man-
ufacturing scheme, i.e., the datatypes we manufacture with descriptions use
ﬁnite product types rather than dependent function types for branching, but it
is easy to switch to a higher-order representation that is even closer to indexed
containers (allowing inﬁnite branching) by storing in v a collection of I-indices
indexed by an arbitrary set S:
v : (S : Set) (f : S →I) →RDesc I
whose semantics is deﬁned in terms of dependent functions:
[[ v S f ]] X = (s : S) →X (f s)
The reason for choosing to stick to ﬁrst-order representations is merely to obtain
a simpler equality for the manufactured datatypes (Agda’s default equality
would sufﬁce); the examples of manufactured datatypes in this dissertation
are all ﬁnitely branching and do not require the power of higher-order rep-
resentation anyway. This choice, however, does complicate some subsequent
datatype-generic deﬁnitions (e.g., ornaments in Chapter 3). It would probably
be helpful to think of the parts involving v and P in these deﬁnitions as special-
isations of higher-order representations to ﬁrst-order ones.
□
2.5
Externalism and internalism
The use of “such that” to describe objects that have certain properties is universal
in mathematics. If the objects in question have type A, then objects with certain
properties form a subset of A, and using “such that” to describe such objects
means that the subset is formed by specifying a suitable predicate on A. In
type theory, this can be modelled by Σ-types. In a type Σ A P, when A is
interpreted as a ground set and P as a predicate on A, an inhabitant of Σ A P

2.5
Externalism and internalism
35
is an inhabitant a of A paired with a proof that P a holds. When programs are
the objects we reason about, this style naturally suggests a distinction between
programs and proofs: programs are written in the ﬁrst place, and proofs are
conducted afterwards with reference to existing programs and do not interfere
with their execution. This conception underlies many developments in type
theory and theorem proving. For example: Luo [1994] consistently argued that
proofs should not be identiﬁed with programs, one of the reasons being that
logic should be regarded as independent from the objects being reasoned about.
A type theory of subsets was given by Nordström et al. [1990] to suppress the
second component — i.e., the proof part — of Σ-types. The proof assistant
Coq [Bertot and Castéran, 2004] uses a type-theoretic foundation [Coquand and
Huet, 1988; Coquand and Paulin-Mohring, 1990] which distinguishes programs
and proofs, and proofs are written in a tactic-based language, differently from
programs; it is also famous for the ability to extract executable portions of proof
scripts into programs [Paulin-Mohring, 1989; Letouzey, 2003], as used in the
CompCert project developing a veriﬁed C compiler [Leroy, 2009], for example.
On the other hand, having uniﬁed programs and proofs in type theory (Sec-
tion 2.1), it seems a pity if the uniﬁcation is not exploited to a deeper level. In
Dijkstra’s proposal for program correctness by construction, proofs and pro-
grams should be conceived “hand in hand” [Dijkstra, 1976], and the uniﬁcation
of programs and proofs brings us unprecedentedly closer to this ideal, since we
can start thinking about programs that also serve as correctness proofs them-
selves. The dependently typed programming community has been exploring
the use of inductive families not only for deﬁning predicates on data (like ⩽N )
but also for representing data with embedded constraints (like Vec). Programs
manipulating such datatypes would also deal with the embedded constraints
and are thus correct by construction. Vector append is a classic (albeit somewhat
trivial) example: Deﬁning addition on natural numbers as
+
: Nat →Nat →Nat
zero
+ n = n
(suc m) + n = suc (m + n)
vector append is then deﬁned by
++
: {A : Set} {m n : Nat} →Vec A m →Vec A n →Vec A (m + n)

36
2
From intuitionistic type theory to dependently typed programming
[]
++ ys = ys
(x :: xs) ++ ys = x :: (xs ++ ys)
The program for vector append looks exactly like the one for list append except
for the more informative type, which makes it possible for the program to meet
its speciﬁcation — the length of the result of append should be the sum of the
lengths of the two input lists — by construction. For list append, whose type
uses the plain list datatype, we need to separately produce the following proof:
append-length :
{A : Set} (xs ys : List A) →length (xs ++ ys) ≡length xs + length ys
append-length []
ys = reﬂ
append-length (x :: xs) ys = cong suc (append-length xs ys)
But by switching to the vector datatype, the proof dissolves into the typing
of the program and needs no separate handling. This is possible because list
append and the proof append-length share the same structure; consequently,
by careful type design, the vector append program alone is able to carry
both of them simultaneously.
We propose to call this programming style
internalism, suggesting that proofs are internalised in programs, while the
traditional proving-after-programming style is called externalism. Externalism
is necessary when we wish to show that an existing program satisﬁes additional
properties, especially when the proofs are complicated and do not follow the
structure of the program. On the other hand, writing a (simply typed) program
and an externalist proof following the structure of the program is like stating
the same thing twice: even though the programmer knows the meaning of the
program, they has to ﬁrst state the meaningless symbol manipulation aspect
and then explain its meaning via a separate proof, doubling the effort. In
contrast, internalism is programming with informative datatypes so as to give
precise description of meaningful computations, so explanations via separate
proofs become unnecessary. As McBride [2004] aptly put it, internalism makes
programs and their explanations via proofs “not merely coexist but coincide”.
In addition, by encoding meanings in datatypes, semantic considerations are
(at least partially) reduced to syntax and can be aided mechanically — Agda’s
interactive development environment (Section 2.2.1) is one form of such aid.
With interactive development, internalist types not only passively rule out

2.5
Externalism and internalism
37
nonsensical programs, but can actively provide helpful information to guide
program construction. We will see several examples of such type-directed
programming in this dissertation.
Internalism comes with its own problems, however. For one: internalist
type design is difﬁcult, yet there is almost no effective guideline or discipline
for such design. Carelessly designed internalist types can lead to less natural
programs. A simple example is when we switch the order of the arguments of
the addition in the type of vector append,
++
: {A : Set} {m n : Nat} →Vec A m →Vec A n →Vec A (n + m)
[]
++ ys = subst (Vec A) { n ≡n + zero }0 ys
(x :: xs) ++ ys = subst (Vec A) { suc (n + m) ≡n + suc m }1 (x :: (xs ++ ys))
we would be forced to perform two type-casts that could have been avoided.
Not only does the program look ugly, but this can also cause a cascade effect
when we need to write other programs whose types depend on this program
(e.g., externalist proofs about it), which would have to deal with the type-casts.
McBride [2012] gave a more interesting example: to prove the polynomial test-
ing principle (two polynomial functions of degree n are pointwise equal if they
agree at n + 1 different points), McBride started with a datatype of encodings
of polynomial functions indexed by degree but, after trying to program with
the datatype, quickly found out that the datatype should instead be indexed by
an arbitrary upper bound of the degree so a relaxed form of the polynomial
testing principle can be naturally programmed (two polynomial functions of
degree at most n are pointwise equal if they agree at n + 1 different points).
Manageability is another issue, especially when the only tool we have is the
primitive language of datatype declarations: writing a datatype declaration
with a sophisticated property internalised is comparable to programming a so-
phisticated algorithm in assembly language, and understanding the meaning of
a complicated datatype declaration takes thorough reading and some inductive
guessing and reasoning. In short, the complexity of internalist types has made
type design a nontrivial programming problem, and we are in serious lack of
type-level programming support.
Internalist library design also poses a problem: Since internalism requires
differently indexed versions of the same data structure, an internalist library

38
2
From intuitionistic type theory to dependently typed programming
should provide more or less the same set of operations for all possible variants
of the data structure. Without a way to manage these formally unrelated
datatypes and operations modularly, an ad hoc library would need to duplicate
the same structure and logic for all the variants and becomes hard to expand.
For example, suppose that we have constructed a library for lists that include
vectors, ordered lists, and ordered vectors, and now wish to add a new ﬂavour
of lists, say, association lists indexed with the list of keys. Operations need
to be reimplemented not only for such key-indexed lists, but also for key-
indexed vectors, ordered key-indexed lists, and ordered key-indexed vectors,
even though key-indexing is the only new feature. An ideal structure for
such a library would be having a separate module for each of the properties
about length, ordering, and key-indexing. These modules can be developed
independently, and there would be a way to assemble components in these
modules at will — for example, ordered vectors and related operations would
be synthesised from the components in the modules about length and ordering.
This ideal library structure calls for some form of composability of internalist
datatypes and operations.
Composability has never been a problem for externalism, however. In an
externalist list library, we would have only one basic list datatype and several
predicates on lists about length, ordering, key-indexing, etc. Lists are “promoted”
to vectors, ordered lists, or ordered vectors by simply pairing the list datatype
with the length predicate, the ordering predicate, or the pointwise conjunction
of the two predicates, respectively. Common operations are implemented for
basic lists only, and their properties regarding length or ordering are proved
independently and invoked when needed. Can we somehow introduce this
beneﬁcial composability to internalism as well? The answer is yes, because there
are isomorphisms between externalist and internalist datatypes to be exploited.
To illustrate, let us go through a small case study about upgrading the insert
function on lists (Section 2.2.2) for vectors, ordered lists, and ordered vectors.
The externalist would deﬁne vectors as a Σ-type,
ExtVec : Set →Nat →Set
ExtVec A n = Σ[ xs : List A ] length xs ≡n
prove that insert increases the length of a list by one,

2.5
Externalism and internalism
39
insert-length : (y : Val) {n : Nat} (xs : List Val) →
length xs ≡n →length (insert y xs) ≡suc n
and deﬁne insertion on vectors as
insertEV : Val →{n : Nat} →ExtVec Val n →ExtVec Val (suc n)
insertEV y (xs , len) = insert y xs , insert-length y xs len
which processes the list and the length proof by insert and insert-length respec-
tively. Similarly for ordered lists (indexed with a lower bound), the externalist
would use the Σ-type
ExtOrdList : Val →Set
ExtOrdList b = Σ[ xs : List Val ] Ordered b xs
where the Ordered predicate is deﬁned by
indexﬁrst data Ordered : Val →List Val →Set where
Ordered b []
∋nil
Ordered b (x :: xs) ∋cons (leq : b ⩽x) (ord : Ordered x xs)
Insertion on ordered lists is then
insertEO : (y : Val) {b : Val} →ExtOrdList b →
{b′ : Val} →b′ ⩽y →b′ ⩽b →ExtOrdList b′
insertEO y (xs , ord) b′⩽y b′⩽b = insert y xs , insert-ordered y xs ord b′⩽y b′⩽b
where insert-ordered proves that insert preserves ordering:
insert-ordered : (y : Val) {b : Val} (xs : List Val) →Ordered b xs →
{b′ : Val} →b′ ⩽y →b′ ⩽b →Ordered b′ (insert y xs)
Now the externalist has arrived at a modular list library (albeit a tiny one),
which contains
• a basic module consisting of the basic list datatype and insertion on basic
lists, and
• two independent upgrading modules about length and ordering, each con-
sisting of a predicate on lists and a related proof about insertion.
It is easy to mix all three modules and get ordered vectors and insertion on
them. The Σ-type uses the pointwise conjunction of the two predicates,

40
2
From intuitionistic type theory to dependently typed programming
ExtOrdVec : Val →Nat →Set
ExtOrdVec b n = Σ[ xs : List Val ] Ordered b xs × length xs ≡n
and insertion simply uses insert-ordered and insert-length to process the two
proofs bundled with a list:
insertEOV : (y : Val) {b : Val} {n : Nat} →ExtOrdVec b n →
{b′ : Val} →b′ ⩽y →b′ ⩽b →ExtOrdVec b′ (suc n)
insertEOV y (xs , ord , len) b′⩽y b′⩽b = insert
y xs ,
insert-ordered y xs ord b′⩽y b′⩽b ,
insert-length y xs len
(Note that the variable of type b′ ⩽y (with spaces around ‘⩽’) is named b′⩽y
(without spaces) — a subtle but useful convention.) This is the kind of library we
are looking for, except that the types are all externalist. The externalist and inter-
nalist types are not unrelated, however. For example, internalist and externalist
vectors are related by the indexed family of conversion isomorphisms:
Vec-iso A : (n : Nat) →Vec A n ∼= ExtVec A n
Fixing n : Nat, the left-to-right direction of the isomorphism
Iso.to (Vec-iso A n) : Vec A n →Σ[ xs : List A ] length xs ≡n
computes the underlying list of a vector and a proof that the list has length n,
and the right-to-left direction
Iso.from (Vec-iso A n) : (Σ[ xs : List A ] length xs ≡n) →Vec A n
promotes a list to a vector when there is a proof that the list has length n. (The
deﬁnition of ∼= , which is actually an instance of a record datatype Iso, appears
in Section 4.1.) To get insertion on internalist vectors, we convert the input
vector to its externalist representation, make insertEV do the work, and convert
the result back to the internalist representation; more formally, the operation
insertV : Val →{n : Nat} →Vec Val n →Vec Val (suc n)
is deﬁned by the commutative diagram:

2.5
Externalism and internalism
41
Vec Val n
Vec Val (suc n)
Σ[ xs : List Val ]
length xs ≡n
Σ[ xs : List Val ]
length xs ≡suc n
insertV y
Iso.to (Vec-iso Val n)
insert y ∗
insert-length y
Iso.from (Vec-iso Val (suc n))
(The
∗
operator is deﬁned by (f ∗g) (x , y) = (f x , g y), and the underscore
leaves out the term for Agda to infer.) Similarly, we can get insertion for
internalist ordered lists and ordered vectors (deﬁnitions to appear in Chapter 3)
from the externalist library by suitable conversion isomorphisms of the same
form as Vec-iso. It is due to these conversion isomorphisms between internalist
and externalist representations that we can analyse internalist datatypes into
externalist components, which can then be modularly processed. This analysis
of internalist datatypes and its application to modular library structuring is
explored in Chapter 3 (in particular, the insertion example is concluded in
Section 3.4.1).
The interconnection between internalism and externalism (in the form of
conversion isomorphisms) also sheds some light on supporting internalist type
design. The synthetic direction of the interconnection goes from basic types and
predicates to internalist types. It is conceivable that, for externalist predicates
of some particular form, we can manufacture corresponding internalist types
on the other side of the interconnection. The externalist side of the intercon-
nection is usually kept non-dependently typed, so it is possible to use existing
non-dependently typed calculi to derive suitable externalist predicates from
speciﬁcations, which are then used to manufacture datatypes on the internalist
side for type-directed programming. Chapter 5 presents one such approach,
using relational calculus [Bird and de Moor, 1997] as a design language for
internalist datatypes. Rather than improvising internalist types and hoping
that they will work, we write speciﬁcations in the form of relational programs,
which are amenable to algebraic transformation and can be much more concise
and readable than the language of datatype declarations, making it easier to
arrive at helpful and comprehensible internalist types.

42
2
From intuitionistic type theory to dependently typed programming
To sum up: While internalism offers type-directed program construction
and reduces the burden of producing correctness proofs, additional or more
complicated properties of existing programs can only be established by external-
ism, which naturally gives rise to a modular organisation. Both internalism and
externalism are here to stay, since the two styles serve different purposes and
have their own advantages and disadvantages. Exploiting their interconnection
can lead to interesting programming patterns, which the rest of this dissertation
explores.

Chapter 3
Reﬁnements and ornaments
This chapter begins our exploration of the interconnection between internalism
and externalism by looking at the analytic direction, i.e., the decomposition
of a sophisticated datatype into a basic datatype and a predicate on the basic
datatype. More speciﬁcally, we assume that the sophisticated datatype and the
basic datatype are known and their descriptions (Section 2.4.2) are straightfor-
wardly related by an ornament (Section 3.2), and derive from the ornament an
externalist predicate and an indexed family of conversion isomorphisms. As
discussed in Section 2.5, one purpose of such decomposition is for internalist
datatypes and operations to take a round trip to the externalist world so as to
exploit composability there. The task can be broken into two parts:
• coordination of relevant conversion isomorphisms for upgrading basic op-
erations satisfying suitable properties to have more sophisticated (function)
types, and
• manufacture of conversion isomorphisms between the datatypes involved.
Reﬁnements (Section 3.1), which axiomatise conversion isomorphisms between
internalist and externalist datatypes, are the abstraction we introduce for bridg-
ing the two parts. The ﬁrst part is then formalised with upgrades (Section 3.1.2)
which use reﬁnements as their components, and the second part is done by
translating ornaments to reﬁnements (Section 3.3). To actually exploit external-
ist composability, we need conversion isomorphisms in which the externalist
43

44
3
Reﬁnements and ornaments
predicates involved are pointwise conjunctions (as in the case of externalist
ordered vectors in Section 2.5). Such conversion isomorphisms come from
parallel composition of ornaments (Section 3.2.3), which not only gives rise to
pointwise conjunctive predicates on the externalist side (Section 3.3.2) but also
produces composite datatypes on the internalist side (e.g., the internalist data-
type of ordered vectors incorporating both ordering and length information).
The above framework of ornaments, reﬁnements, and upgrades are illustrated
with several examples in Section 3.4, followed by some discussion (including
related work) in Section 3.5.
3.1
Reﬁnements
We ﬁrst abstract away from the details of the construction of conversion isomor-
phisms and simply axiomatise their existence as reﬁnements from basic types
to more sophisticated types. There are two versions of reﬁnements:
• the non-indexed version between individual types (Section 3.1.1), and
• the indexed version between two families of types — called reﬁnement
families (Section 3.1.3) — which collect reﬁnements between speciﬁed pairs
of individual types in the two families.
Section 3.1.2 then explains how reﬁnements between individual types can be
coordinated to perform function upgrading, and the actual construction of a
class of reﬁnement families is described in Section 3.3 after the introduction of
ornaments (Section 3.2).
3.1.1
Reﬁnements between individual types
A reﬁnement from a basic type A to a more informative type B is a promotion
predicate P : A →Set and a conversion isomorphism i : B ∼= Σ A P. As an
Agda record datatype:
record Reﬁnement (A B : Set) : Set1 where
ﬁeld

3.1
Reﬁnements
45
P : A →Set
i
: B ∼= Σ A P
forget : B →A
-- explained after the two examples below
forget = outl ◦Iso.to i
Reﬁnements are not guaranteed to be interesting in general. For example,
B can be chosen to be Σ A P and the conversion isomorphism simply the
identity. Most of the time, however, we are only interested in reﬁnements
from basic types to their more informative — often internalist — variants. The
conversion isomorphism tells us that the inhabitants of B exactly correspond
to the inhabitants of A bundled with more information, i.e., proofs that the
promotion predicate P is satisﬁed. Computationally, any inhabitant of B can
be decomposed (by Iso.to i) into an underlying value a : A and a proof that
a satisﬁes the promotion predicate P (which we will call a promotion proof
for a), and conversely, if an inhabitant of A satisﬁes P, then it can be promoted
(by Iso.from i) to an inhabitant of B.
Example (reﬁnement from lists to ordered lists).
Consider the internalist data-
type of ordered lists (indexed by a lower bound; the type Val and associated
operations are postulated in Section 2.2.2):
indexﬁrst data OrdList : Val →Set where
OrdList b ∋nil
| cons (x : Val) (leq : b ⩽x) (xs : OrdList x)
Fixing b : Val, there is a reﬁnement from List Val to OrdList b whose promotion
predicate is Ordered b, since we have an isomorphism of type
OrdList b ∼= Σ (List Val) (Ordered b)
which, from left to right, decomposes an ordered list into the underlying list and
a proof that the underlying list is ordered (and bounded below). Conversely, a
list satisfying Ordered b can be promoted to an ordered list of type OrdList b by
the right-to-left direction of the isomorphism.
□
Example (reﬁnement from natural numbers to lists).
Let A : Set (which we will
directly refer to in subsequent text and code as if it is a local module parameter).
We have a reﬁnement from Nat to List A
Nat-List A : Reﬁnement Nat (List A)

46
3
Reﬁnements and ornaments
for which Vec A serves as the promotion predicate — there is a conversion
isomorphism of type
List A ∼= Σ Nat (Vec A)
whose decomposing direction computes from a list its length and a vector
containing the same elements. We might say that a natural number n : Nat is
an incomplete list — the list elements are missing from the successor nodes
of n. To promote n to a List A, we need to supply a vector of type Vec A n,
i.e., n elements of type A. This example helps to emphasise that the notion of
reﬁnements is proof-relevant: an underlying value can have more than one
promotion proof, and consequently the more informative type in a reﬁnement
can have more inhabitants than the basic type does. Thus it is more helpful to
think that a type is more reﬁned in the sense of being more informative rather
than being a subset.
□
Given a reﬁnement r, we denote the forgetful computation of underlying
values — i.e., outl ◦Iso.to (Reﬁnement.i r) — as Reﬁnement.forget r. (This is
done by deﬁning an extra projection function forget in the record deﬁnition
of Reﬁnement.) The forgetful function is actually the core of a reﬁnement, as
justiﬁed by the following facts:
• The forgetful function determines a reﬁnement extensionally — if the forgetful
functions of two reﬁnements are extensionally equal, then their promotion
predicates are pointwise isomorphic:
forget-iso : {A B : Set} (r s : Reﬁnement A B) →
(Reﬁnement.forget r .= Reﬁnement.forget s) →
(a : A) →Reﬁnement.P r a ∼= Reﬁnement.P s a
• From any function f, we can construct a canonical reﬁnement which uses a
simplistic promotion predicate and has f as its forgetful function:
canonRef : {A B : Set} →(B →A) →Reﬁnement A B
canonRef {A} {B} f = record
{ P = λ a 7→Σ[ b : B ] f b ≡a
; i
= record
{ to
= f
▽
(id
▽
(λ b 7→reﬂ))
-- (g
▽
h) x = (g x , h x)
; from = outl ◦outr

3.1
Reﬁnements
47
; proofs of laws } }
-- proofs of inverse properties omitted
We call λ a 7→Σ[ b : B ] f b ≡a the canonical promotion predicate, which
says that, to promote a : A to type B, we are required to supply a complete
b : B and prove that its underlying value is a.
• For any reﬁnement r : Reﬁnement A B, its forgetful function is deﬁnition-
ally that of canonRef (Reﬁnement.forget r), so from forget-iso we can prove
that a promotion predicate is always pointwise isomorphic to the canonical
promotion predicate:
coherence :
{A B : Set} (r : Reﬁnement A B) →
(a : A) →Reﬁnement.P r a ∼= Σ[ b : B ] Reﬁnement.forget r b ≡a
coherence r a = forget-iso r (canonRef (Reﬁnement.forget r)) (λ b 7→reﬂ)
This is closely related to an alternative “coherence-based” deﬁnition of reﬁne-
ments, which will shortly be discussed.
The reﬁnement mechanism’s purpose of being is thus to express intensional
(representational) optimisations of the canonical promotion predicate, so that it
is possible to work on just the residual information of the more reﬁned type
that is not present in the basic type.
Example (promoting lists to ordered lists).
Consider the reﬁnement from lists to
ordered lists using Ordered as its promotion predicate. A promotion proof of
type Ordered b xs for the list xs consists of only the inequality proofs necessary
for ensuring that xs is ordered and bounded below by b. Thus, to promote a
list to an ordered list, we only need to supply the inequality proofs without
providing the list elements again.
□
Coherence-based deﬁnition of reﬁnements
There is an alternative deﬁnition of reﬁnements which, instead of the conver-
sion isomorphism, postulates the forgetful computation and characterises the
promotion predicate in term of it:
record Reﬁnement′ (A B : Set) : Set1 where
ﬁeld

48
3
Reﬁnements and ornaments
P
: A →Set
forget : B →A
p
: (a : A) →P a ∼= Σ[ b : B ] forget b ≡a
We say that a : A and b : B are coherent when forget b
≡
a, i.e., when
a underlies b. The two deﬁnitions of reﬁnements are equivalent. Of particular
importance is the direction from Reﬁnement to Reﬁnement′:
toReﬁnement′ : {A B : Set} →Reﬁnement A B →Reﬁnement′ A B
toReﬁnement′ r = record { P
= Reﬁnement.P r
; forget = Reﬁnement.forget r
; p
= coherence r }
We prefer the deﬁnition of reﬁnements in terms of conversion isomorphisms
because it is more concise and directly applicable to function upgrading. The
coherence-based deﬁnition, however, can be more easily generalised for function
types, as we will see below.
3.1.2
Upgrades
Reﬁnements are less useful when we move on to function types. A presuppo-
sition here is that we want reﬁnement relationship between function types to
be compositional — for example, we are interested in stating how the function
type List Nat →List Nat reﬁnes the function type Nat →Nat in terms of the
reﬁnement Nat-List Nat : Reﬁnement Nat (List Nat) (which states that the under-
lying natural number of a list is its length): a function f : Nat →Nat underlies
another function g : List Nat →List Nat exactly when g transforms the under-
lying natural number in the same way as f, i.e., length (g xs) ≡f (length xs)
for all xs : List Nat. It is not possible to have such a reﬁnement between the
two function types, though: Having such a reﬁnement means, in particular,
that we can extract an underlying function from any g : List Nat →List Nat,
but the behaviour of g may depend essentially on the list elements, which is
not available to a function taking a natural number. For example, given input
xs : List Nat, the function g might compute the sum s of xs and emit a list of
length s whose elements are all zero; apparently there is no function of type
Nat →Nat that can compute s from length xs for all xs.

3.1
Reﬁnements
49
It is only the decomposing direction of reﬁnements that causes problems in
the case of function types, however; the promoting direction is perfectly valid
for function types. For example, to promote the function doubling a natural
number
double : Nat →Nat
double zero
= zero
double (suc n) = suc (suc (double n))
to a function of type List A →List A for some ﬁxed A : Set, we can use
Q = λ f 7→(n : Nat) →Vec A n →Vec A (f n)
as the promotion predicate: Given a promotion proof of type Q double, say
duplicate′ : (n : Nat) →Vec A n →Vec A (double n)
duplicate′ zero
[]
= []
duplicate′ (suc n) (x :: xs) = x :: x :: duplicate′ n xs
we can synthesise a function duplicate : List A →List A by
duplicate : List A →List A
duplicate = Iso.from iso ◦(double ∗duplicate′
) ◦Iso.to iso
-- (f ∗g) (x , y) = (f x , g y)
where iso : List A ∼= Σ Nat (Vec A)
iso = Reﬁnement.i (Nat-List A)
That is, we decompose the input list into the underlying natural number (i.e., its
length) and a vector of elements, process the two parts separately with double
and duplicate′, and ﬁnally combine the results back to a list. (This is what we
did for insertV in Section 2.5.) The relationship between the promoted function
duplicate and the underlying function double is characterised by the coherence
property
double ◦length .= length ◦duplicate

50
3
Reﬁnements and ornaments
or as a commutative diagram:
List A
List A
Nat
Nat
duplicate
double
length
length
which states that duplicate preserves length as computed by double, or in more
generic terms, processes the recursive structure (i.e., nil and cons nodes) of its
input in the same way as double.
We thus deﬁne upgrades to capture the promoting direction and the coher-
ence property abstractly. An upgrade from A : Set to B : Set is
• a promotion predicate P : A →Set,
• a coherence property C : A →B →Set relating inhabitants of the basic
type A and inhabitants of the more informative type B,
• an upgrading (promoting) operation u : (a : A) →P a →B, and
• a coherence proof c : (a : A) (p : P a) →C a (u a p) saying that the result of
promoting a : A is necessarily coherent with a.
As an Agda record datatype:
record Upgrade (A B : Set) : Set1 where
ﬁeld
P : A →Set
C : A →B →Set
u : (a : A) →P a →B
c : (a : A) (p : P a) →C a (u a p)
Like reﬁnements, arbitrary upgrades are not guaranteed to be interesting, but
we will only use the upgrades synthesised by the combinators we deﬁne below
speciﬁcally for deriving coherence properties and upgrading operations for
function types from reﬁnements between component types.

3.1
Reﬁnements
51
Upgrades from reﬁnements
As we said, upgrades amount to only the promoting direction of reﬁnements.
This is most obvious when we look at the coherence-based reﬁnements, of
which upgrades are a direct generalisation: we get from Reﬁnement′ to Upgrade
by abstracting the notion of coherence and weakening the isomorphism to only
the left-to-right computation. Any coherence-based reﬁnement can thus be
weakened to an upgrade:
toUpgrade′ : {A B : Set} →Reﬁnement′ A B →Upgrade A B
toUpgrade′ r = record { P = Reﬁnement′.P r
; C = λ a b 7→Reﬁnement′.forget r b ≡a
; u = λ a 7→outl ◦Iso.to (Reﬁnement′.p r a)
; c = λ a 7→outr ◦Iso.to (Reﬁnement′.p r a) }
and consequently any reﬁnement gives rise to an upgrade:
toUpgrade : {A B : Set} →Reﬁnement A B →Upgrade A B
toUpgrade = toUpgrade′ ◦toReﬁnement′
Composition of upgrades
The most representative combinator for upgrades is the following one for
synthesising upgrades between function types:
⇀
: {A A′ B B′ : Set} →
Reﬁnement A A′ →Upgrade B B′ →Upgrade (A →B) (A′ →B′)
Note that there should be a reﬁnement between the source types A and A′,
rather than just an upgrade. (As a consequence, we can produce upgrades
between curried multi-argument function types but not between higher-order
function types.) This is because, as we see in the double–duplicate example, we
need to be able to decompose the source type A′.
Let r : Reﬁnement A A′ and s : Upgrade B B′. The upgrading operation
takes a function f : A →B and combines it with a promotion proof to get a
function f ′ : A′ →B′, which should transform underlying values in a way that
is coherent with f. That is, as f ′ takes a′ : A′ to f ′ a′ : B′ at the more informative

52
3
Reﬁnements and ornaments
level, correspondingly at the underlying level, the value underlying a′, i.e.,
Reﬁnement.forget r a′ : A, should be taken by f to a value coherent with f ′ a′.
We thus deﬁne the statement “f ′ is coherent with f” as
(a : A) (a′ : A′) →Reﬁnement.forget r a′ ≡a →Upgrade.C s (f a) (f ′ a′)
As for the type of promotion proofs, since we already know that the underlying
values are transformed by f, the missing information is only how the residual
parts are transformed — that is, we need to know for any a : A how a promotion
proof for a is transformed to a promotion proof for f a. The type of promotion
proofs for f is thus
(a : A) →Reﬁnement.P r a →Upgrade.P s (f a)
Having determined the coherence property and the promotion predicate, it is
then easy to construct the upgrading operation and the coherence proof. In
particular, the upgrading operation
• breaks an input a′ : A′ into its underlying value a = Reﬁnement.forget r a′ :
A and a promotion proof for a,
• computes a promotion proof q for f a : B using the given promotion proof
for f, and
• promotes f a to an inhabitant of type B′ using q,
which is an abstract version of what we did in the double–duplicate example. The
complete deﬁnition of
⇀is
⇀
: {A A′ B B′ : Set} →
Reﬁnement A A′ →Upgrade B B′ →Upgrade (A →B) (A′ →B′)
r ⇀s = record
{ P = λ f 7→(a : A) →Reﬁnement.P r a →Upgrade.P s (f a)
; C = λ f f ′ 7→(a : A) (a′ : A′) →
Reﬁnement.forget r a′ ≡a →Upgrade.C s (f a) (f ′ a′)
; u = λ f h 7→Upgrade.u s
◦uncurry h ◦Iso.to (Reﬁnement.i r)
-- uncurry = λ { f (x , y) 7→f x y }
; c = λ { f h .
a′ reﬂ7→let (a , p) = Iso.to (Reﬁnement.i r) a′
in Upgrade.c s (f a) (h a p) } }
Example (upgrade from Nat →Nat to List A →List A).
Using the
⇀combi-

3.1
Reﬁnements
53
nator on the reﬁnement
r = Nat-List A : Reﬁnement Nat (List A)
and the upgrade derived from r by toUpgrade, we get an upgrade
u = r ⇀toUpgrade r : Upgrade (Nat →Nat) (List A →List A)
The type Upgrade.P u double is exactly the type of duplicate′, and the type
Upgrade.C u double duplicate is exactly the coherence property satisﬁed by double
and duplicate.
□
3.1.3
Reﬁnement families
When we move on to consider reﬁnements between indexed families of types,
a reﬁnement relationship exists not only between the member types but also
between the index sets: a type family X : I →Set is reﬁned by another type
family Y : J →Set when
• at the index level, there is a reﬁnement r from I to J, and
• at the member type level, there is a reﬁnement from X i to Y j whenever i : I
underlies j : J, i.e., Reﬁnement.forget r j ≡i.
In short, each type X i is reﬁned by a particular collection of types in Y,
the underlying value of their indices all being i. We will not exploit the full
reﬁnement structure on indices, though, so in the actual deﬁnition of reﬁnement
families below, the index-level reﬁnement degenerates into just the forgetful
function.
FReﬁnement : {I J : Set} (e : J →I) (X : I →Set) (Y : J →Set) →Set1
FReﬁnement {I} e X Y = {i : I} (j : e −1 i) →Reﬁnement (X i) (Y (und j))
The inverse image type
−1
is deﬁned by
data
−1 (e : J →I) (i : I) : Set where
ok : (j : J) →e −1 (e j)
That is, e −1 i is isomorphic to Σ[ j : J ] e j ≡i, the subset of J mapped to i by e.
An underlying J-value is extracted by

54
3
Reﬁnements and ornaments
und : {I J : Set} {e : J →I} {i : I} →e −1 i →J
und (ok j) = j
Introducing this type will offer some slight notational advantage when, e.g.,
writing ornamental descriptions (Section 3.2.2). We also deﬁne an alternative
name Inv =
−1
to make partial application look better.
Example (reﬁnement family from ordered lists to ordered vectors).
The datatype
OrdList : Val →Set is a family of types into which ordered lists are classiﬁed
according to their lower bound. For each type of ordered lists having a particular
lower bound, we can further classify them by their length, yielding the datatype
of ordered vectors OrdVec : Val →Nat →Set:
indexﬁrst data OrdVec : Val →Nat →Set where
OrdVec b zero
∋nil
OrdVec b (suc n) ∋cons (x : Val) (leq : b ⩽x) (xs : OrdVec x n)
This further classiﬁcation is captured as a reﬁnement family of type
FReﬁnement outl OrdList (uncurry OrdVec)
which consists of reﬁnements from OrdList b to OrdVec b n for all b : Val and
n : Nat.
□
Reﬁnement families are the vehicle we use to express conversion relation-
ship between inductive families. For now, however, they have to be prepared
manually, which requires considerable effort. Also, when it comes to acquir-
ing externalist composability for internalist datatypes, we need to be able to
compose reﬁnements such that the promotion predicate of the resulting reﬁne-
ment is the pointwise conjunction of existing promotion predicates, so we get
conversion isomorphisms of the right form. For example, we should be able to
compose the two reﬁnements from lists to ordered lists and to vectors to get
a reﬁnement from lists to ordered vectors whose promotion predicate is the
pointwise conjunction of the promotion predicates of the two reﬁnements. This
is easy for the externalist side of the reﬁnement, but for the internalist side, we
need to derive the datatype of ordered vectors from the datatypes of ordered
lists and vectors, which is not possible unless we can tap more deeply into the
structure of datatypes and manipulate such structure — that is, we need to
do datatype-generic programming (Section 2.4). Hence enter ornaments. With

3.2
Ornaments
55
ornaments, we can express intensional relationship between datatype declara-
tions, which can be exploited for deriving composite datatypes like ordered
vectors. This intensional relationship is easy to establish and induces reﬁnement
families (Section 3.3), so the difﬁculty of preparing reﬁnement families is also
dramatically reduced.
3.2
Ornaments
One possible way to establish relationships between datatypes is to write
conversion functions. Conversions that preserve the vertical structure and make
only modiﬁcations to the horizontal structure like copying, projecting away, or
assigning default values to ﬁelds, however, may instead be stated at the level
of datatype declarations, i.e., in terms of natural transformations between base
functors. For example, a list is a natural number whose successor nodes are
decorated with elements, and to convert a list to its length, we simply discard
those elements. The essential information in this conversion is just that the
elements associated with cons nodes should be discarded, which is described by
the following natural transformation between the two base functors F (ListD A)
and F NatD:
erase : {A : Set} {X : ⊤→Set} →F (ListD A) X ⇒F NatD X
erase (‘nil
,
) = ‘nil
,
-- ‘nil copied
erase (‘cons , a , x , ) = ‘cons , x ,
-- ‘cons copied, a discarded,
-- and x retained
The transformation can then be lifted to work on the least ﬁxed points, yielding
an alternative deﬁnition of length.
length : {A : Set} →µ (ListD A) ⇒µ NatD
length {A} = fold (con ◦erase {A} {µ NatD})
(Implicit arguments can be explicitly supplied in curly braces.) Our goal in this
section is to construct a universe for such horizontal natural transformations
between the base functors arising as decodings of descriptions. The inhabitants
of this universe are called ornaments. By encoding the relationship between
datatype descriptions as a universe, whose inhabitants are analysable syntactic

56
3
Reﬁnements and ornaments
objects, we will not only be able to derive conversion functions between data-
types, but even compute new datatypes that are related to old ones in prescribed
ways (e.g., by parallel composition in Section 3.2.3), which is something we
cannot achieve if we simply write the conversion functions directly.
3.2.1
Universe construction
The deﬁnition of ornaments has the same two-level structure as that of datatype
descriptions. We have an upper-level datatype Orn of ornaments
Orn : {I J : Set} (e : J →I) (D : Desc I) (E : Desc J) →Set1
Orn e D E = {i : I} (j : e −1 i) →ROrn e (D i) (E (und j))
which is deﬁned in terms of a lower-level datatype ROrn of response ornaments.
ROrn contains the actual encoding of horizontal transformations and is decoded
by the function erase:
data ROrn {I J : Set} (e : J →I) : RDesc I →RDesc J →Set1
erase : {I J : Set} {e : J →I} {D : RDesc I} {E : RDesc J} →
ROrn e D E →{X : I →Set} →[[ E ]] (X ◦e) →[[ D ]] X
The datatype Orn is parametrised by an erasure function e : J →I on the
index sets and relates a basic description D : Desc I with a more informative
description E : Desc J. As a consequence, from any ornament O : Orn e D E we
can derive a forgetful map:
forget O : µ E ⇒(µ D ◦e)
By design, this forgetful map necessarily preserves the recursive structure of
its input. In terms of the two-dimensional metaphor mentioned towards the
end of Section 2.4.2, an ornament describes only how the horizontal shapes
change, and the forgetful map — which is a fold — simply applies the changes
to each vertical level — it never alters the vertical structure. For example, the
length function discards elements associated with cons nodes, shrinking the
list horizontally to a natural number, but keeps the vertical structure (i.e., the
con nodes) intact. Look more closely: Given y : µ E j, we should transform
it into an inhabitant of type µ D (e j). Deconstructing y into con ys where

3.2
Ornaments
57
ys : [[ E j ]] (µ E) and inductively assuming that the (µ E)-inhabitants at the
recursive positions of ys have been transformed into (µ D ◦e)-inhabitants, we
horizontally modify the resulting structure of type [[ E j ]] (µ D ◦e) to one of
type [[ D (e j) ]] (µ D), which can then be wrapped by con to an inhabitant
of type µ D (e j). The above steps are performed by the ornamental algebra
induced by O:
ornAlg O : F E (µ D ◦e) ⇒(µ D ◦e)
ornAlg O {j} = con ◦erase (O (ok j))
where the horizontal modiﬁcation — a transformation from [[ E j ]] (X ◦e) to
[[ D (e j) ]] X parametric in X — is decoded by erase from a response ornament
relating D (e j) and E j. The forgetful function is then deﬁned by
forget O : µ E ⇒(µ D ◦e)
forget O = fold (ornAlg O)
Hence an ornament of type Orn e D E contains, for each index request j, a
response ornament of type ROrn e (D (e j)) (E j) to cope with all possible
horizontal structures that can occur in a (µ E)-inhabitant. The deﬁnition of
Orn given above is a restatement of this in an intensionally more ﬂexible form
(whose indexing style corresponds to that of reﬁnement families).
Now we look at the deﬁnitions of ROrn and erase, followed by explanations
of the four cases.
data ROrn {I J : Set} (e : J →I) : RDesc I →RDesc J →Set1 where
v : {js : List J} {is : List I} (eqs : E e js is) →ROrn e (v is) (v js)
σ : (S : Set) {D : S →RDesc I} {E : S →RDesc J}
(O : (s : S) →ROrn e (D s) (E s)) →ROrn e (σ S D) (σ S E)
∆: (T : Set) {D : RDesc I} {E : T →RDesc J}
(O : (t : T) →ROrn e D (E t)) →ROrn e D (σ T E)
∆
: {S : Set} (s : S) {D : S →RDesc I} {E : RDesc J}
(O : ROrn e (D s) E) →ROrn e (σ S D) E
erase : {I J : Set} {e : J →I} {D : RDesc I} {E : RDesc J} →
ROrn e D E →{X : I →Set} →[[ E ]] (X ◦e) →[[ D ]] X
erase (v []
)
=
erase (v (reﬂ:: eqs)) (x , xs) = x , erase (v eqs) xs
-- x retained

58
3
Reﬁnements and ornaments
erase (σ S O)
(s , xs) = s , erase (O s)
xs
-- s copied
erase (∆T O)
(t , xs) =
erase (O t)
xs
-- t discarded
erase (
∆
s O)
xs
= s , erase O
xs
-- s inserted
The ﬁrst two cases v and σ of ROrn relate response descriptions that have
the same outermost constructor, and the transformations decoded from them
preserve horizontal structure.
• The v case of ROrn states the condition when a response description v js
reﬁnes another response description v is, i.e., when [[ v js ]] (X ◦e) can be
transformed into [[ v is ]] X. The source type [[ v js ]] (X ◦e) expands to a
product of types of the form X (e j) for some j : J and the target type [[ v is ]] X
to a product of types of the form X i for some i : I. There are no horizontal
contents (i.e., ﬁelds) and thus no horizontal modiﬁcations to make, and the
input values should be preserved. We thus demand that js and is have the
same number of elements and the corresponding pairs of indices e j and i are
equal; that is, we demand a proof of map e js ≡is (where map is the usual
functorial map on lists). To make it easier to analyse a proof of map e js ≡is
in the v case of erase, we instead deﬁne the proposition inductively as E e js is,
where the datatype E is deﬁned by
data E {I J : Set} (e : J →I) : List J →List I →Set where
[]
: E e [] []
::
: {j : J} {i : I} (eq : e j ≡i) →
{js : List J} {is : List I} (eqs : E e js is) →E e (j :: js) (i :: is)
• The σ case of ROrn states when σ S E reﬁnes σ S D — note that both response
descriptions start with the same ﬁeld of type S. The intended semantics —
the σ case of erase — is to preserve (copy) the value of this ﬁeld. To be able
to transform the rest of the input structure, we should demand that, for any
value s : S of the ﬁeld, the remaining response description E s reﬁnes the
other remaining response description D s.
The other two cases ∆and
∆
of ROrn deal with mismatching ﬁelds in the two
response descriptions being related and prompt erase to perform nontrivial
horizontal transformations.
• The ∆case of ROrn states when σ T E reﬁnes D, the former having an

3.2
Ornaments
59
additional ﬁeld of type T whose value is not retained — the ∆case of erase
discards the value of this ﬁeld. We still need to transform the rest of the input
structure, and thus should demand that, for every possible value t : T of
the ﬁeld, the response description D is reﬁned by the remaining response
description E t.
• Conversely, the
∆
case of ROrn states when E reﬁnes σ S D, the latter having
an additional ﬁeld of type S. The value of this ﬁeld needs to be restored by
the
∆
case of erase, so the
∆
constructor demands a default value s : S for
the ﬁeld. To be able to continue with the transformation, the
∆
constructor
also demands that the response description E reﬁnes the remaining response
description D s.
Convention.
Again we regard ∆as a binder and write ∆[ t : T ]
O t for
∆T (λ t 7→O t). Also, even though
∆
is not a binder, we write
∆
[ s ] O for
∆
s O to avoid the parentheses around O when O is a complex expression.
□
Example (ornament from natural numbers to lists).
For any A : Set, there is
an ornament from the description NatD of natural numbers to the description
ListD A of lists:
NatD-ListD A : Orn ! NatD (ListD A)
NatD-ListD A (ok ) = σ ListTag λ { ‘nil
7→v []
; ‘cons 7→∆[
: A ] v (reﬂ:: []) }
where the index erasure function ‘!’ is λ
7→
. There is only one response
ornament in NatD-ListD A since the datatype of lists is trivially indexed. The
constructor tag is preserved (σ ListTag), and in the cons case, the list element
ﬁeld is marked as additional by ∆. Consequently, the forgetful function
forget (NatD-ListD A) { } : List A →Nat
discards all list elements from a list and returns its underlying natural number,
i.e., its length.
□
Example (ornament from lists to vectors).
Again for any A : Set, there is an
ornament from the description ListD A of lists to the description VecD A of
vectors:
ListD-VecD A : Orn ! (ListD A) (VecD A)

60
3
Reﬁnements and ornaments
ListD-VecD A (ok zero
) =
∆
[ ‘nil ]
v []
ListD-VecD A (ok (suc n)) =
∆
[ ‘cons ] σ[
: A ] v (reﬂ:: [])
The response ornaments are indexed by Nat, since Nat is the index set of the
datatype of vectors. We do pattern matching on the index request, resulting
in two cases. In both cases, the constructor tag ﬁeld exists for lists but not for
vectors (since the constructor choice for vectors is determined from the index),
so
∆
is used to insert the appropriate tag; in the suc case, the list element ﬁeld
is preserved by σ. Consequently, the forgetful function
forget (ListD-VecD A) : {n : Nat} →Vec A n →List A
computes the underlying list of a vector.
□
It is worth emphasising again that ornaments encode only horizontal trans-
formations, so datatypes related by ornaments necessarily have the same re-
cursion patterns (as enforced by the v constructor) — ornamental relationship
exists between list-like datatypes but not between lists and binary trees, for
example.
3.2.2
Ornamental descriptions
There is apparent similarity between, e.g., the description ListD A and the orna-
ment NatD-ListD A, which is typical: frequently we deﬁne a new description
(e.g., ListD A), intending it to be a more reﬁned version of an existing one (e.g.,
NatD), and then immediately write an ornament from the latter to the former
(e.g., NatD-ListD A). The syntactic structures of the new description and of
the ornament are essentially the same, however, so the effort is duplicated. It
would be more efﬁcient if we could use the existing description as a template
and just write a “relative description” specifying how to “patch” the template,
and afterwards from this “relative description” extract a new description and
an ornament from the template to the new description.
Ornamental descriptions are designed for this purpose. The related deﬁni-
tions are shown in Figure 3.1 and closely follow the deﬁnitions for ornaments,
having a upper-level type OrnDesc of ornamental descriptions which refers
to a lower-level datatype ROrnDesc of response ornamental descriptions. An

3.2
Ornaments
61
data ROrnDesc J e : RDesc I →Set1 where
v : {is : List I} (js : P is (Inv e)) →ROrnDesc J e (v is)
σ : (S : Set) {D : S →RDesc I}
(OD : (s : S) →ROrnDesc J e (D s)) →ROrnDesc J e (σ S D)
∆: (T : Set) {D : RDesc I} (OD : T →ROrnDesc J e D) →ROrnDesc J e D
∆
: {S : Set} (s : S) {D : S →RDesc I}
(OD : ROrnDesc J e (D s)) →ROrnDesc J e (σ S D)
P-toList : {X : I →List} →(X ⇒const J) →(is : List I) →P is X →List J
P-toList f []
= []
P-toList f (i :: is)
(x , xs) = f x :: P-toList f is xs
toRDesc : {D : RDesc I} →ROrnDesc J e D →RDesc J
toRDesc (v {is} js) = v (P-toList und is js)
toRDesc (σ S OD) = σ[ s : S ] toRDesc (OD s)
toRDesc (∆T OD) = σ[ t : T ] toRDesc (OD t)
toRDesc (
∆
s OD)
= toRDesc OD
toEq : {i : I} (j : e −1 i) →e (und j) ≡i
toEq (ok j) = reﬂ
P-toEq : (is : List I) (js : P is (Inv e)) →E e (P-toList und is js) is
P-toEq []
= []
P-toEq (i :: is) (j , js) = toEq j :: P-toEq is js
toROrn : {D : RDesc I} (OD : ROrnDesc J e D) →ROrn e D (toRDesc OD)
toROrn (v {is} js) = v (P-toEq is js)
toROrn (σ S OD) = σ[ s : S ] toROrn (OD s)
toROrn (∆T OD) = ∆[ t : T ] toROrn (OD t)
toROrn (
∆
s OD)
=
∆
[ s ] toROrn OD
OrnDesc J e : Desc I →Set1
OrnDesc J e D = {i : I} (j : e −1 i) →ROrnDesc J e (D i)
⌊⌋: {D : Desc I} →OrnDesc J e D →Desc J
⌊OD⌋j = toRDesc (OD (ok j))
⌈⌉: {D : Desc I} (OD : OrnDesc J e D) →Orn e D ⌊OD⌋
⌈OD⌉(ok j) = toROrn (OD (ok j))
Figure 3.1
Deﬁnitions for ornamental descriptions, where I, J : Set and e : J →I.

62
3
Reﬁnements and ornaments
ornamental description looks like an annotated description, on which we can
use a greater variety of constructors to mark differences from the template
description. We think of an ornamental description
OD : OrnDesc J e D
as simultaneously denoting a new description of type Desc J and an ornament
from the template description D to the new description, and use ﬂoor and
ceiling brackets ⌊⌋and ⌈⌉to resolve ambiguity: the new description is
⌊OD⌋: Desc J
and the ornament is
⌈OD⌉: Orn e D ⌊OD⌋
Convention.
The ambiguity is also adopted informally for ornaments in gen-
eral: when we mention an ornamentation of a datatype µ D, it can either refer
to an ornament whose less informative end is D or a more informative datatype
µ E with which µ D has an ornamental relationship.
□
Example (ordered lists as an ornamentation of lists).
We can deﬁne ordered lists
by an ornamental description, using the description of lists as the template:
OrdListOD : OrnDesc Val ! (ListD Val)
OrdListOD (ok b) =
σ ListTag λ { ‘nil
7→v
; ‘cons 7→σ[ x : Val ] ∆[ leq : b ⩽x ] v (x , ) }
If we read OrdListOD as an annotated description, we can think of the leq ﬁeld
as being marked as additional (relative to the description of lists) by using ∆
rather than σ. We write
⌊OrdListOD⌋: Desc Val
to decode OrdListOD to an ordinary description of ordered lists (in particular,
turning the ∆into a σ) and
⌈OrdListOD⌉: Orn ! (ListD Val) ⌊OrdListOD⌋
to get an ornament from lists to ordered lists.
□
Example (singleton ornamentation).
Consider the following singleton datatype
for lists:

3.2
Ornaments
63
indexﬁrst data ListS A : List A →Set where
ListS A []
∋nil
ListS A (a :: as) ∋cons (s : ListS A as)
For each type ListS A as, there is exactly one (canonical) inhabitant (hence the
name “singleton datatype” [Sheard and Linger, 2007, Section 3.6]), which is
devoid of any horizontal content and whose vertical structure is exactly that
of as. We can encode the datatype as an ornamental description relative to
ListD A:
ListSOD : (A : Set) →OrnDesc (List A) ! (ListD A)
ListSOD A (ok []
) =
∆
[ ‘nil ] v
ListSOD A (ok (a :: as)) =
∆
[ ‘cons ]
∆
[ a ] v (ok as , )
which does pattern matching on the index request, in each case restricts the
constructor choice to the one matched against, and in the cons case deletes the
element ﬁeld and sets the index of the recursive position to be the value of the
tail. In general, we can deﬁne a parametrised ornamental description
singletonOD : {I : Set} (D : Desc I) →OrnDesc (Σ I (µ D)) outl D
called the singleton ornamental description, which delivers a singleton data-
type as an ornamentation of any datatype. The complete deﬁnition is
erode : {I : Set} (D : RDesc I) {J : I →Set} →
[[ D ]] J →ROrnDesc (Σ I J) outl D
erode (v is)
js
= v (P-map (λ {i} j 7→ok (i , j)) is js)
erode (σ S D) (s , js) =
∆
[ s ] erode (D s) js
singletonOD : {I : Set} (D : Desc I) →OrnDesc (Σ I (µ D)) outl D
singletonOD D (ok (i , con ds)) = erode (D i) ds
where
P-map : {I : Set} {X Y : I →Set} →(X ⇒Y) →
(is : List I) →P is X →P is Y
P-map f []
=
P-map f (i :: is) (x , xs) = f x , P-map f is xs
Note that erode deletes all ﬁelds (i.e., horizontal content), drawing default values
from the index request, and retains only the vertical structure. We can then
deﬁne

64
3
Reﬁnements and ornaments
singleton : {I : Set} {D : Desc I}
{i : I} (x : µ D i) →µ ⌊singletonOD D⌋(i , x)
which computes the single inhabitant of a singleton type.
We will see in
Section 3.3 that singleton ornamentation plays a key role in the ornament–
reﬁnement framework.
□
Remark (index-ﬁrst universes).
The datatype of response ornamental descrip-
tions is a good candidate for receiving an index-ﬁrst reformulation. Since the
structure of a response ornamental description is guided by the template re-
sponse description, ROrnDesc is much more clearly presented in the index-ﬁrst
style:
indexﬁrst data ROrnDesc {I : Set} (J : Set) (e : J →I) : RDesc I →Set1
where
ROrnDesc J e (v is)
∋v (js : P is (Inv e))
ROrnDesc J e (σ S D) ∋σ (OD : (s : S) →ROrnDesc J e (D s))
|
∆
(s : S) (OD : ROrnDesc J e (D s))
ROrnDesc J e D
∋∆(T : Set) (OD : T →ROrnDesc J e D)
If the template response description is v is, then we can specify a list of indices
reﬁning is (by v); if it is σ S D, then we can either copy (σ) or delete (
∆
) the
ﬁeld; ﬁnally, whatever the template is, we can always choose to create (∆) a new
ﬁeld. (This dissertation maintains a separation between Agda datatypes and
index-ﬁrst datatypes, in particular using the former to construct a universe for
the latter, but it is conceivable that ornaments and ornamental descriptions can
be incorporated into a type theory with self-encoding index-ﬁrst universes like
the one presented by Chapman et al. [2010].)
□
3.2.3
Parallel composition of ornaments
Recall that our purpose of introducing ornaments is to be able to compute
composite datatypes like ordered vectors. This can be achieved by composing
two ornaments from the same description in parallel. The generic scenario is as
follows (think of the direction of an ornamental arrow as following its forgetful
function):

3.2
Ornaments
65
record
▷◁
{I J K : Set} (e : J →I) (f : K →I) : Set where
constructor
,
ﬁeld
{i} : I
-- implicit ﬁeld
j
: e −1 i
k
: f −1 i
pull : {I J K : Set} {e : J →I} {f : K →I} →e ▷◁f →I
pull =
▷◁.i
outl▷◁: {I J K : Set} {e : J →I} {f : K →I} →e ▷◁f →J
outl▷◁= und ◦
▷◁.j
outr▷◁: {I J K : Set} {e : J →I} {f : K →I} →e ▷◁f →K
outr▷◁= und ◦
▷◁.k
Figure 3.2
Deﬁnitions for set-theoretic pullbacks.
I
J
K
e ▷◁f
e
f
pull
outl▷◁
outr▷◁
D : Desc I
E : Desc J
F : Desc K
⌊O ⊗P⌋: Desc e ▷◁f
O
P
⌈O ⊗P⌉
diffOrn-l O P
diffOrn-r O P
Given three descriptions D : Desc I, E : Desc J, and F : Desc K and two
ornaments O : Orn e D E and P : Orn e D F independently specifying how D is
reﬁned to E and to F, we can compute an ornamental description
O ⊗P : OrnDesc (e ▷◁f) pull D
where e ▷◁f is the set-theoretic pullback of e : J →I and f : K →I, i.e., it is
isomorphic to Σ[ jk : J × K ] e (outl jk) ≡f (outr jk); related deﬁnitions are
shown in Figure 3.2. Intuitively, since both O and P encode modiﬁcations to the
same basic description D, we can commit all modiﬁcations encoded by O and P

66
3
Reﬁnements and ornaments
to D to get a new description ⌊O ⊗P ⌋, and encode all these modiﬁcations
in one ornament ⌈O ⊗P⌉. The forgetful function of the ornament ⌈O ⊗P⌉
removes all modiﬁcations, taking µ ⌊O ⊗P ⌋all the way back to the basic
datatype µ D; there are also two difference ornaments
diffOrn-l O P : Orn outl▷◁E ⌊O ⊗P⌋
-- left difference ornament
diffOrn-r O P : Orn outr▷◁F ⌊O ⊗P⌋
-- right difference ornament
which give rise to “less forgetful” functions taking µ ⌊O ⊗P⌋to µ E and µ F,
such that both
forget O ◦forget (diffOrn-l O P)
and
forget P ◦forget (diffOrn-r O P)
are extensionally equal to forget ⌈O ⊗P ⌉. (The diagrams foreshadow our
characterisation of parallel composition as a category-theoretic pullback in
Chapter 4; we will make their meanings precise there.)
Example (ordered vectors).
Consider the two ornaments ⌈OrdListOD ⌉from
lists to ordered lists and ListD-VecD Val from lists to vectors. Composing them
in parallel gives us an ornamental description
OrdVecOD : OrnDesc (! ▷◁!) pull (ListD Val)
OrdVecOD = ⌈OrdListOD⌉⊗ListD-VecD Val
from which we can decode a new datatype of ordered vectors by
OrdVec : Val →Nat →Set
OrdVec b n = µ ⌊OrdVecOD⌋(ok b , ok n)
and an ornament ⌈OrdVecOD ⌉whose forgetful function converts ordered
vectors to plain lists, retaining the list elements. The forgetful functions of
the difference ornaments convert ordered vectors to ordered lists and vectors,
removing only length and ordering information respectively.
□
The complete deﬁnitions for parallel composition are shown in Figure 3.3.
The core deﬁnition is pcROD, which analyses and merges the modiﬁcations
encoded by two response ornaments into a response ornamental description at
the level of individual ﬁelds. Below we discuss some representative cases of
pcROD.

3.2
Ornaments
67
fromEq : {I J : Set} (e : J →I) {j : J} {i : I} →e j ≡i →e −1 i
fromEq e {j} reﬂ= ok j
pc-E : {I J K : Set} {e : J →I} {f : K →I} →
{is : List I} {js : List J} {ks : List K} →
E e js is →E f ks is →P is (Inv pull)
pc-E
[]
[]
=
pc-E {e := e} {f} (eeq :: eeqs) (feq :: feqs) = ok (fromEq e eeq , fromEq f feq) ,
pc-E eeqs feqs
mutual
pcROD : {I J K : Set} {e : J →I} {f : K →I}
{D : RDesc I} {E : RDesc J} {F : RDesc K} →
ROrn e D E →ROrn f D F →ROrnDesc (e ▷◁f) pull D
pcROD (v eeqs) (v feqs)
= v (pc-E eeqs feqs)
pcROD (v eeqs) (∆T P) = ∆[ t : T ] pcROD (v eeqs) (P t)
pcROD (σ S O) (σ .S P) = σ[ s : S ] pcROD (O s)
(P s)
pcROD (σ f O) (∆T P) = ∆[ t : T ] pcROD (σ f O) (P t)
pcROD (σ S O) (
∆
s P)
=
∆
[ s ]
pcROD (O s)
P
pcROD (∆T O) P
= ∆[ t : T ] pcROD (O t)
P
pcROD (
∆
s O) (σ S P) =
∆
[ s ]
pcROD O
(P s)
pcROD (
∆
s O) (∆T P) = ∆[ t : T ] pcROD (
∆
s O) (P t)
pcROD (
∆
s O) (
∆
s′ P) = ∆(s ≡s′) (pcROD-double
∆
O P)
pcROD-double
∆
:
{I J K S : Set} {e : J →I} {f : K →I}
{D : S →RDesc I} {E : RDesc J} {F : RDesc K} {s s′ : S} →
ROrn e (D s) E →ROrn f (D s′) F →
s ≡s′ →ROrnDesc (e ▷◁f) pull (σ S D)
pcROD-double
∆
{s := s} O P reﬂ=
∆
[ s ] pcROD O P
⊗
: {I J K : Set} {e : J →I} {f : K →I}
{D : Desc I} {E : Desc J} {F : Desc K} →
Orn e D E →Orn f D F →OrnDesc (e ▷◁f) pull D
(O ⊗P) (ok (j , k)) = pcROD (O j) (P k)
Figure 3.3
Deﬁnitions for parallel composition of ornaments.

68
3
Reﬁnements and ornaments
• When both response ornaments use σ, both of them preserve the same ﬁeld
in the basic description — no modiﬁcation is made. Consequently, the ﬁeld is
preserved in the resulting response ornamental description as well.
pcROD (σ S O) (σ .S P) = σ[ s : S ] pcROD (O s) (P s)
• When one of the response ornaments uses ∆to mark the addition of a
new ﬁeld, that ﬁeld would be added into the resulting response ornamental
description, like in
pcROD (∆T O) P = ∆[ t : T ] pcROD (O t) P
• If one of the response ornaments retains a ﬁeld by σ and the other deletes
it by
∆
, the only modiﬁcation to the ﬁeld is deletion, and thus the ﬁeld is
deleted in the resulting response ornamental description, like in
pcROD (σ S O) (
∆
s P) =
∆
[ s ] pcROD (O s) P
• The most interesting case is when both response ornaments encode deletion:
we would add an equality ﬁeld demanding that the default values supplied
in the two response ornaments be equal,
pcROD (
∆
s O) (
∆
s′ P) = ∆(s ≡s′) (pcROD-double
∆
O P)
and then pcROD-double
∆
puts the deletion into the resulting response or-
namental description after matching the proof of the equality ﬁeld with
reﬂ.
pcROD-double
∆
{s := s} O P reﬂ=
∆
[ s ] pcROD O P
(The implicit argument {s := s} is the one named s in the type of the function
pcROD-double
∆
— the ‘s’ to the left of ‘:=’ is the name of the argument, while
the ‘s’ to the right is a pattern variable. This syntax allows us to skip the
nine implicit arguments before this one.) It might seem bizarre that two
deletions results in a new ﬁeld (and a deletion), but consider this informally
described scenario: A ﬁeld σ S in the basic response description is reﬁned by
two independent response ornaments
∆[ t : T ]
∆
[ g t ]
and

3.2
Ornaments
69
∆[ u : U ]
∆
[ h u ]
That is, instead of S-values, the response descriptions at the more informative
end of the two response ornaments use T- and U-values at this position,
which are erased to their underlying S-value by g : T →S and h : U →S
respectively. Composing the two response ornaments in parallel, we get
∆[ t : T ] ∆[ u : U ] ∆[
: g t ≡h u ]
∆
[ g t ]
where the added equality ﬁeld completes the construction of a set-theoretic
pullback of g and h. Here indeed we need a pullback: When we have an
actual value for the ﬁeld σ S, which gets reﬁned to values of types T and U,
the generic way to mix the two reﬁning values is to store them both, as a
product. If we wish to retrieve the underlying value of type S, we can either
extract the value of type T and apply g to it or extract the value of type U
and apply h to it, and through either path we should get the same underlying
value. So the product should really be a pullback to ensure this.
Example (ornamental description of ordered vectors).
Composing the ornaments
⌈OrdListOD⌉and ListD-VecD Val in parallel yields the following ornamental
description of ordered vectors relative to ListD Val:
λ { (ok (ok b , ok zero
)) 7→
∆
[ ‘nil ] v
; (ok (ok b , ok (suc n))) 7→
∆
[ ‘cons ] σ[ x : Val ]
∆[ leq : b ⩽x ] v (ok ( ok x , ok n ) , ) }
where lighter box indicates modiﬁcations from ⌈OrdListOD⌉and darker box
from ListD-VecD Val.
□
Finally, the deﬁnitions for the left difference ornament are shown in Fig-
ure 3.4. The left difference ornament has the same structure as parallel compo-
sition, but records only modiﬁcations from the right-hand side ornament. For
example, the case
diffROrn-l (σ S O) (
∆
s P) =
∆
[ s ] diffROrn-l (O s) P
is the same as the corresponding case of pcROD, since the deletion comes from
the right-hand side response ornament, whereas the case
diffROrn-l (∆T O) P = σ[ t : T ] diffROrn-l (O t) P

70
3
Reﬁnements and ornaments
und-fromEq :
{I J : Set} (e : J →I) {j : J} {I : I} (eq : e j ≡i) →und (fromEq e eq) ≡j
und-fromEq e reﬂ= reﬂ
diff-E-l :
{I J K : Set} {e : J →I} {f : K →I} →
{is : List I} {js : List J} {ks : List K} →
(eeqs : E e js is) (feqs : E f ks is) →E outl▷◁(P-toList und is (pc-E eeqs feqs)) js
diff-E-l
[]
[]
= []
diff-E-l {e := e} (eeq :: eeqs) (feq :: feqs) = und-fromEq e eeq :: diff-E-l eeqs feqs
mutual
diffROrn-l :
{I J K : Set} {e : J →I} {f : K →I} →
{D : RDesc I} {E : RDesc J} {F : RDesc K} →
(O : ROrn e D E) (P : ROrn f D F) →ROrn outl▷◁E (toRDesc (pcROD O P))
diffROrn-l (v eeqs) (v feqs)
= v (diff-E-l eeqs feqs)
diffROrn-l (v eeqs) (∆T P) = ∆[ t : T ] diffROrn-l (v eeqs) (P t)
diffROrn-l (σ S O) (σ .S P) = σ[ s : S ] diffROrn-l (O s)
(P s)
diffROrn-l (σ S O) (∆T P) = ∆[ t : T ] diffROrn-l (σ S O) (P t)
diffROrn-l (σ S O) (
∆
s P)
=
∆
[ s ]
diffROrn-l (O s)
P
diffROrn-l (∆T O) P
= σ[ t : T ] diffROrn-l (O t)
P
diffROrn-l (
∆
s O) (σ S P) =
diffROrn-l O
(P s)
diffROrn-l (
∆
s O) (∆T P) = ∆[ t : T ] diffROrn-l (
∆
s O) (P t)
diffROrn-l (
∆
s O) (
∆
s′ P) = ∆(s ≡s′) (diffROrn-l-double
∆
O P)
diffROrn-l-double
∆
:
{I J K S : Set} {e : J →I} {f : K →I} →
{D : S →RDesc I} {E : RDesc J} {F : RDesc K} {s s′ : S} →
(O : ROrn e (D s) E) (P : ROrn f (D s′) F) (eq : s ≡s′) →
ROrn outl▷◁E (toRDesc (pcROD-double
∆
O P eq))
diffROrn-l-double
∆
O P reﬂ= diffROrn-l O P
diffOrn-l : {I J K : Set} {e : J →I} {f : K →I} →
{D : Desc I} {E : Desc J} {F : Desc K} →
(O : Orn e D E) (P : Orn f D F) →Orn outl▷◁E ⌊O ⊗P⌋
diffOrn-l O P (ok (j , k)) = diffROrn-l (O j) (P k)
Figure 3.4
Deﬁnitions for left difference ornament.

3.3
Reﬁnement semantics of ornaments
71
produces σ (a preservation) rather than ∆(a modiﬁcation) as in the correspond-
ing case of pcROD, since the addition comes from the left-hand side response
ornament. We can then see that the composition of the forgetful functions
forget O ◦forget (diffOrn-l O P)
is indeed extensionally equal to forget ⌈O ⊗P ⌉, since forget (diffOrn-l O P)
removes modiﬁcations encoded in the right-hand side ornament and then
forget O removes modiﬁcations encoded in the left-hand side ornament. The
right difference ornament diffOrn-r is deﬁned analogously and is omitted from
the presentation.
3.3
Reﬁnement semantics of ornaments
We now know how to do function upgrading with reﬁnements (Section 3.1)
and how to relate datatypes and manufacture composite datatypes with orna-
ments (Section 3.2), and there is only one link missing: translation of ornaments
to reﬁnements. Every ornament O : Orn e D E induces a reﬁnement family
from µ D to µ E. That is, we can construct
RSem : {I J : Set} {e : J →I} {D : Desc I} {E : Desc J} →
Orn e D E →FReﬁnement e (µ D) (µ E)
which is called the reﬁnement semantics of ornaments. The construction of
RSem begins in Section 3.3.1 and continues into Chapter 4. Another important
aspect of the translation is from parallel composition of ornaments to reﬁne-
ments whose promotion predicate is pointwise conjunctive. This begins in
Section 3.3.2 and also continues into Chapter 4.
3.3.1
Optimised predicates
Our task in this section is to construct a promotion predicate
OptP : {I J : Set} {e : J →I} {D : Desc I} {E : Desc J} →
(O : Orn e D E) {i : I} (j : e −1 i) (x : µ D i) →Set

72
3
Reﬁnements and ornaments
which is called the optimised predicate for the ornament O. Given x : µ D i, a
proof of type OptP O j x contains information for complementing x to form an
inhabitant y of type µ E (und j) with the same recursive structure — the proof is
the “horizontal” difference between y and x. Such a proof should have the same
vertical structure as x, and, at each recursive node, store horizontally only those
data marked as modiﬁed by the ornament. For example, if we are promoting
the natural number
two = con (‘cons ,
con (‘cons ,
con (‘nil
,
) , ) , ) : µ NatD
to a list, an optimised promotion proof would look like
p = con (a ,
con (a′ ,
con (
) , ) , ) : OptP (NatD-ListD A) (ok ) two
where a and a′ are some elements of type A, so we get a list by zipping together
two and p node by node:
con (‘cons , a ,
con (‘cons , a′ ,
con (‘nil
,
) , ) , ) : µ (ListD A)
Note that p contains only values of the ﬁeld marked as additional by ∆in the
ornament NatD-ListD A. The constructor tags are essential for determining the
recursive structure of p, but instead of being stored in p, they are derived from
two, which is part of the index of the type of p. In general, here is how we
compute an ornamental description for such proofs, using D as the template:
we incorporate the modiﬁcations made by O, and delete the ﬁelds that already
exist in D, whose default values are derived, in the index-ﬁrst manner, from
the inhabitant being promoted, which appears in the index of the type of a
proof. The deletion is independent of O and can be performed by the singleton
ornamentation for D (Section 3.2.2), so the desired ornamental description is

3.3
Reﬁnement semantics of ornaments
73
produced by the parallel composition of O and ⌈singletonOD D⌉:
OptPOD : {I J : Set} {e : J →I} {D : Desc I} {E : Desc J} →
Orn e D E →OrnDesc (e ▷◁outl) pull D
OptPOD {D := D} O = O ⊗⌈singletonOD D⌉
where outl has type Σ I (µ D) →I. The optimised predicate, then, is the least
ﬁxed point of the description.
OptP : {I J : Set} {e : J →I} {D : Desc I} {E : Desc J} →
(O : Orn e D E) {i : I} (j : e −1 i) (x : µ D i) →Set
OptP O {i} j x = µ ⌊OptPOD O⌋(j , (ok (i , x)))
Example (index-ﬁrst vectors as an optimised predicate).
The optimised predicate
for the ornament NatD-ListD A from natural numbers to lists is the datatype
of index-ﬁrst vectors. Expanding the deﬁnition of the ornamental description
OptPOD (NatD-ListD A) relative to NatD:
λ { (ok (ok
, ok ( , zero ))) 7→
∆
[ ‘nil ] v
; (ok (ok
, ok ( , suc n))) 7→
∆
[ ‘cons ] ∆[
: A ]
v (ok ( ok
, ok ( , n) ) , ) }
where lighter box indicates contributions from the ornament NatD-ListD A
and darker box from the singleton ornament ⌈singletonOD NatD⌉, we see that
the ornamental description indeed yields the datatype of index-ﬁrst vectors
(modulo the fact that it is indexed by a heavily packaged datatype of natural
numbers).
□
Example (predicate characterising ordered lists).
The optimised predicate for the
ornament ⌈OrdListOD⌉from lists to ordered lists is given by the ornamental
description OptPOD ⌈OrdListOD⌉relative to ListD Val, which expands to
λ { (ok (ok b , ok ( , []
))) 7→
∆
[ ‘nil ] v
; (ok (ok b , ok ( , x :: xs))) 7→
∆
[ ‘cons ]
∆
[ x ] ∆[ leq : b ⩽x ]
v (ok ( ok x , ok ( , xs) ) , ) }
where lighter box indicates contributions from ⌈OrdListOD⌉and darker box
from ⌈singletonOD (ListD Val) ⌉. This yields the Ordered predicate deﬁned in
Section 2.5. Compare Ordered with the traditional version:

74
3
Reﬁnements and ornaments
data Ordered′ : Val →List Val →Set where
nil
: {b : Val} →Ordered′ b []
cons : {b : Val} {x : Val} {xs : List Val} →
b ⩽x →Ordered′ x xs →Ordered′ b (x :: xs)
A proof of Ordered b xs consists of exactly the inequality proofs necessary
for ensuring that xs is ordered and bounded below by b, whereas a proof
of Ordered′ b xs also redundantly contains all the intermediate lower bounds
and the elements of xs. The proof representation of Ordered is thus optimised,
justifying the name “optimised predicate”.
□
Example (inductive length predicate on lists).
The optimised predicate for the
ornament ListD-VecD A from lists to vectors is produced by the ornamental
description OptPOD (ListD-VecD A) relative to ListD A:
λ { (ok (ok zero
, ok ( , []
))) 7→∆[
: ‘nil ≡‘nil ]
∆
[ ‘nil ] v
; (ok (ok zero
, ok ( , a :: as))) 7→∆( ‘nil ≡‘cons ) λ ()
; (ok (ok (suc n) , ok ( , []
))) 7→∆( ‘cons ≡‘nil ) λ ()
; (ok (ok (suc n) , ok ( , a :: as))) 7→∆[
: ‘cons ≡‘cons ]
∆
[ ‘cons ]
∆
[ a ] v (ok ( ok n , ok ( , as) ) , ) }
where lighter box indicates contributions from ListD-VecD A and darker box
from ⌈singletonOD (ListD A)⌉. Both ornaments perform pattern matching and
accordingly restrict constructor choices by
∆
, so the resulting four cases all start
with an equality ﬁeld demanding that the constructor choices speciﬁed by the
two ornaments are equal.
• In the ﬁrst and last cases, where the speciﬁed constructor choices match, the
equality proof obligation can be successfully discharged and the response
ornamental description can continue after installing the constructor choice
by
∆
;
• in the middle two cases, where the speciﬁed constructor choices mismatch,
the equality is obviously unprovable and the rest of the response ornamental
description is (extensionally) the empty function λ ().
Thus, in effect, the ornamental description produces the following inductive
length predicate on lists:
indexﬁrst data Length : Nat →List A →Set where

3.3
Reﬁnement semantics of ornaments
75
Length zero
[]
∋nil
Length zero
(a :: as) ∋
Length (suc n) []
∋
Length (suc n) (a :: as) ∋cons (l : Length n as)
where the middle two cases are uninhabited.
□
We have thus determined the promotion predicate used by the reﬁnement
semantics of ornaments to be the optimised predicate:
RSem : {I J : Set} {e : J →I} {D : Desc I} {E : Desc J} →
Orn e D E →FReﬁnement e (µ D) (µ E)
RSem O j = record { P = OptP O j
; i
= ornConvIso O j }
We call ornConvIso the ornamental conversion isomorphisms, whose type is
ornConvIso :
{I J : Set} {e : J →I} {D : Desc I} {E : Desc J} (O : Orn e D E) →
{i : I} (j : e −1 i) →µ E (und j) ∼= Σ[ x : µ D i ] OptP O j x
The construction of ornConvIso is deferred to Section 4.3.1.
3.3.2
Predicate swapping for parallel composition
An ornament describes differences between two datatypes, and the optimised
predicate for the ornament is the datatype of differences between inhabitants of
the two datatypes. To promote an inhabitant from the less informative end to
the more informative end of the ornament using its reﬁnement semantics, we
give a proof that the object satisﬁes the optimised predicate for the ornament.
If, however, the ornament is a parallel composition, say ⌈O ⊗P ⌉, then the
differences recorded in the ornament are simply collected from the component
ornaments O and P. Consequently, it should sufﬁce to give separate proofs that
the inhabitant satisﬁes the optimised predicates for O and P, instead of a proof
that it satisﬁes the monolithic optimised predicate induced by ⌈O ⊗P⌉. We
are thus led to prove that the optimised predicate for ⌈O ⊗P⌉amounts to the
pointwise conjunction of the optimised predicates for O and P. More precisely:

76
3
Reﬁnements and ornaments
if O : Orn e D E and P : Orn f D F where D : Desc I, E : Desc J, and F : Desc K,
then we expect the existence of the modularity isomorphisms
OptP ⌈O ⊗P⌉(ok (j , k)) x ∼= OptP O j x × OptP P k x
for all i : I, j : e −1 i, k : f −1 i, and x : µ D i.
Example (promotion predicate from lists to ordered vectors).
The optimised predi-
cate for the ornament ⌈⌈OrdListOD⌉⊗ListD-VecD Val⌉from lists to ordered
vectors is
indexﬁrst data OrderedLength : Val →Nat →List Val →Set where
OrderedLength b zero
[]
∋nil
OrderedLength b zero
(x :: xs) ∋
OrderedLength b (suc n) []
∋
OrderedLength b (suc n) (x :: xs) ∋cons (leq : b ⩽x)
(ol : OrderedLength x n xs)
which is monolithic and inﬂexible.
We can avoid using this predicate by
exploiting the modularity isomorphisms
OrderedLength b n xs ∼= Ordered b xs × Length n xs
for all b : Val, n : Nat, and xs : List Val — to promote a list to an ordered
vector, we can prove that it satisﬁes Ordered and Length instead of OrderedLength.
Promotion proofs from lists to ordered vectors can thus be divided into ordering
and length aspects and carried out separately.
□
Along with the ornamental conversion isomorphisms, the construction of
the modularity isomorphisms is deferred to Section 4.3.2. Here we deal with
a practical issue regarding composition of modularity isomorphisms: for ex-
ample, to get pointwise isomorphisms between the optimised predicate for
⌈O ⊗⌈P ⊗Q ⌉⌉and the pointwise conjunction of the optimised predicates
for O, P, and Q, we need to instantiate the modularity isomorphisms twice
and compose the results appropriately, a procedure which quickly becomes
tedious. What we need is an auxiliary mechanism that helps with organising
computation of composite predicates and isomorphisms following the paral-
lel compositional structure of ornaments, in the same spirit as the upgrade
mechanism (Section 3.1.2) helping with organising computation of coherence
properties and proofs following the syntactic structure of function types.

3.3
Reﬁnement semantics of ornaments
77
We thus deﬁne the following auxiliary datatype Swap, parametrised with a
reﬁnement whose promotion predicate is to be swapped for a new one:
record Swap {A B : Set} (r : Reﬁnement A B) : Set1 where
ﬁeld
P : A →Set
i
: (a : A) →Reﬁnement.P r a ∼= P a
An inhabitant of Swap r consists of a new promotion predicate for r and a proof
that the new predicate is pointwise isomorphic to the original one in r. The
actual swapping is done by the function
toReﬁnement : {A B : Set} {r : Reﬁnement A B} →Swap r →Reﬁnement A B
toReﬁnement s = record { P = Swap.P s
; i
= { }0 }
where Goal 0 is the new conversion isomorphism
B ∼= Σ A (Reﬁnement.P r) ∼= Σ A (Swap.P s)
constructed by using transitivity and product of isomorphisms to compose
Reﬁnement.i r and Swap.i s. We can then deﬁne the datatype FSwap of swap
families in the usual way:
FSwap : {I J : Set} {e : J →I} {X : I →Set} {Y : J →Set} →
(rs : FReﬁnement e X Y) →Set1
FSwap rs = {i : I} (j : e −1 i) →Swap (rs j)
and provide the following combinator on swap families, which says that if there
are alternative promotion predicates for the reﬁnement semantics of O and P,
then the pointwise conjunction of the two predicates is an alternative promotion
predicate for the reﬁnement semantics of ⌈O ⊗P⌉:
⊗-FSwap : {I J K : Set} {e : J →I} {f : K →I} →
{D : Desc I} {E : Desc J} {F : Desc K} →
(O : Orn e D E) (P : Orn f D F) →
FSwap (RSem O) →FSwap (RSem P) →FSwap (RSem ⌈O ⊗P⌉)
⊗-FSwap O P ss ts (ok (j , k)) = record
{ P = λ x 7→Swap.P (ss j) x × Swap.P (ts k) x
; i
= λ x 7→{ }1 }

78
3
Reﬁnements and ornaments
Goal 1 is straightforwardly discharged by composing the modularity isomor-
phisms and the isomorphisms in ss and ts:
OptP ⌈O ⊗P⌉(ok (j , k)) x ∼= OptP O j x
× OptP P k x
∼= Swap.P (ss j) x × Swap.P (ts k) x
Example (modular promotion predicate for the parallel composition of three ornaments).
To use the pointwise conjunction of the optimised predicates for ornaments O,
P, and Q as an alternative promotion predicate for ⌈O ⊗⌈P ⊗Q⌉⌉, we use the
swap family
⊗-FSwap O ⌈P ⊗Q⌉id-FSwap (⊗-FSwap P Q id-FSwap id-FSwap)
where
id-FSwap : {I : Set} {X Y : I →Set} {rs : FReﬁnement X Y} →FSwap rs
simply retains the original promotion predicate in rs.
□
Example (swapping the promotion predicate from lists to ordered vectors).
From the
swap family
OrdVec-FSwap : FSwap (RSem ⌈OrdVecOD⌉)
OrdVec-FSwap =
⊗-FSwap ⌈OrdListOD⌉(ListD-VecD Val) id-FSwap (Length-FSwap Val)
we can extract a reﬁnement family from lists to ordered vectors using
λ b n xs 7→Ordered b xs × length xs ≡n
as the promotion predicate, where
Length-FSwap A : FSwap (RSem (ListD-VecD A))
swaps Length for λ n xs 7→length xs ≡n.
□
3.4
Examples
To demonstrate the use of the ornament–reﬁnement framework, in Section 3.4.1
we ﬁrst conclude the example about insertion into a list introduced in Section 2.5,
and then we look at two dependently typed heap data structures adapted from

3.4
Examples
79
Okasaki’s work on purely functional data structures [1999]. Of the latter two
examples,
• the ﬁrst one about binomial heaps (Section 3.4.2) shows that Okasaki’s idea
of numerical representations can be elegantly captured by ornaments and
the coherence properties computed with upgrades, and
• the second one about leftist heaps (Section 3.4.3) demonstrates the power
of parallel composition of ornaments by treating heap ordering and leftist
balancing properties modularly.
3.4.1
Insertion into a list
To recap: we have an externalist library for lists which supports one operation
insert : Val →List Val →List Val
and has two modules about length and ordering, respectively containing the
following two proofs about insert:
insert-length
: (y : Val) {n : Nat} (xs : List Val) →
length xs ≡n →length (insert y xs) ≡suc n
insert-ordered : (y : Val) {b : Val} (xs : List Val) →Ordered b xs →
{b′ : Val} →b′ ⩽y →b′ ⩽b →Ordered b′ (insert y xs)
To upgrade the library to also work as an internalist one, all we have to do is
add to the two modules the descriptions of vectors and ordered lists and the
ornaments from lists to vectors and ordered lists (or equivalently and more
simply, just the ornamental descriptions). Now we can manufacture
insertV : Val →{n : Nat} →Vec Val n →Vec Val (suc n)
starting with writing the following upgrade, which marks how the types of
insert and insertV are related:
upg : Upgrade (Val →
List Val
→List Val
)
(Val →{n : Nat} →Vec Val n →Vec Val (suc n))
upg = ∀[
: Val ] ∀+[[ n : Nat ]] r n ⇀toUpgrade (r (suc n))
where r : (n : Nat) →Reﬁnement (List Val) (Vec Val n)
r n = toReﬁnement (Length-FSwap Val (ok n))

80
3
Reﬁnements and ornaments
-- the upgraded function type has an extra argument
new : {A : Set} (I : Set) {X : I →Set} →
((i : I) →Upgrade A (X i)) →Upgrade A ((i : I) →X i)
new I u = record { P = λ a 7→(i : I) →Upgrade.P (u i) a
; C = λ a x 7→(i : I) →Upgrade.C (u i) a (x i)
; u = λ a p i 7→Upgrade.u (u i) a (p i)
; c = λ a p i 7→Upgrade.c (u i) a (p i) }
syntax new I (λ i 7→u) = ∀+[ i : I ] u
-- implicit version of new
new′ : {A : Set} (I : Set) {X : I →Set} →
((i : I) →Upgrade A (X i)) →Upgrade A ({i : I} →X i)
new′ I u = record { P = λ a 7→{i : I} →Upgrade.P (u i) a
; C = λ a x 7→{i : I} →Upgrade.C (u i) a (x {i})
; u = λ a p {i} 7→Upgrade.u (u i) a (p {i})
; c = λ a p {i} 7→Upgrade.c (u i) a (p {i}) }
syntax new′ I (λ i 7→u) = ∀+[[ i : I ]] u
-- the underlying and the upgraded function types have a common argument
ﬁxed : (I : Set) {X : I →Set} {Y : I →Set} →
((i : I) →Upgrade (X i) (Y i)) →Upgrade ((i : I) →X i) ((i : I) →Y i)
ﬁxed I u = record { P = λ f 7→(i : I) →Upgrade.P (u i) (f i)
; C = λ f g 7→(i : I) →Upgrade.C (u i) (f i) (g i)
; u = λ f h i 7→Upgrade.u (u i) (f i) (h i)
; c = λ f h i 7→Upgrade.c (u i) (f i) (h i) }
syntax ﬁxed I (λ i 7→u) = ∀[ i : I ] u
-- implicit version of ﬁxed
ﬁxed′ : (I : Set) {X : I →Set} {Y : I →Set} →
((i : I) →Upgrade (X i) (Y i)) →Upgrade ({i : I} →X i) ({i : I} →Y i)
ﬁxed′ I u = record { P = λ f 7→{i : I} →Upgrade.P (u i) (f {i})
;
C = λ f g 7→{i : I} →Upgrade.C (u i) (f {i}) (g {i})
;
u = λ f h {i} 7→Upgrade.u (u i) (f {i}) (h {i})
;
c = λ f h {i} 7→Upgrade.c (u i) (f {i}) (h {i}) }
syntax ﬁxed′ I (λ i 7→u) = ∀[[ i : I ]] u
Figure 3.5
More combinators on upgrades.

3.4
Examples
81
That is, the type of insertV has a common ﬁrst argument with the type of insert
and a new implicit argument n : Nat, and reﬁnes the two occurrences of List Val
in the type of insert to Vec Val n and Vec Val (suc n). The function insertV is then
simply deﬁned by
insertV : Val →{n : Nat} →Vec Val n →Vec Val (suc n)
insertV = Upgrade.u upg insert insert-length
which satisﬁes the coherence property
insertV-coherence :
(y : Val) {n : Nat} (xs : List Val) (xs′ : Vec Val n) →
forget (ListD-VecD Val) xs′ ≡xs →
forget (ListD-VecD Val) (insertV y xs′) ≡insert y xs
insertV-coherence = Upgrade.c upg insert insert-length
That is, insertV manipulates the underlying list of the input vector in the same
way as insert. Similarly we can manufacture insertO for ordered lists by using an
appropriate upgrade that accepts insert-ordered as a promotion proof for insert.
For ordered vectors, the datatype is manufactured by parallel composition, and
the operation
insertOV : (y : Val) {b : Val} {n : Nat} →OrdVec b n →
{b′ : Val} →b′ ⩽y →b′ ⩽b →OrdVec b′ (suc n)
is manufactured with the help of the upgrade
∀[ y : Val ] ∀+[[ b : Val ]] ∀+[[ n : Nat ]] r b n ⇀
∀+[[ b′ : Val ]] ∀+[
: b′ ⩽y ] ∀+[
: b′ ⩽b ] toUpgrade (r b′ (suc n))
where
r : (b : Val) (n : Nat) →Reﬁnement (List Val) (OrdVec b n)
r b n = toReﬁnement (OrdVec-FSwap (ok (ok b , ok n)))
The type of promotion proofs for insert speciﬁed by this upgrade is
(y : Val) {b : Val} {n : Nat} (xs : List Val) →
Ordered b xs × length xs ≡n →
{b′ : Val} →b′ ⩽y →b′ ⩽b →
Ordered b′ (insert y xs) × length (insert y xs) ≡suc n
and is inhabited by

82
3
Reﬁnements and ornaments
weight
binary number
binomial heap
20
1
z
21
1
x
y
22
0
7→
20
0
21
0
22
1
x
y
z
w
Figure 3.6
Left: a binomial heap of size 3 consisting of two binomial trees storing
elements x, y, and z.
Right: a possible result of inserting an element w into the heap.
(Note that the digits of the underlying binary numbers are ordered with the least
signiﬁcant digit ﬁrst.)
λ { y xs (ord , len) b′⩽y b′⩽b 7→insert-ordered y xs ord b′⩽y b′⩽b ,
insert-length y xs len }
which is strikingly similar to insertEOV in Section 2.5.
3.4.2
Binomial heaps
We are all familiar with the idea of positional number systems, in which we
represent a number as a list of digits. Each digit is associated with a weight,
and the interpretation of the list is the weighted sum of the digits. (For example,
the weights used for binary numbers are powers of 2.) Some container data
structures and associated operations strongly resemble positional representa-
tions of natural numbers and associated operations. For example, a binomial
heap (illustrated in Figure 3.6) can be thought of as a binary number in which
every 1-digit stores a binomial tree — the actual place for storing elements —
whose size is exactly the weight of the digit. The number of elements stored in
a binomial heap is therefore exactly the value of the underlying binary number.
Inserting a new element into a binomial heap is analogous to incrementing a
binary number, with carrying corresponding to combining smaller binomial
trees into larger ones. Okasaki thus proposed to design container data struc-

3.4
Examples
83
rank
0
suc r
r
r
1
2
3
Figure 3.7
Left: inductive deﬁnition of binomial trees.
Right: decomposition of
binomial trees of ranks 1 to 3.
tures by analogy with positional representations of natural numbers, and called
such data structures numerical representations. Using an ornament, it is easy
to express the relationship between a numerically represented container data-
type (e.g., binomial heaps) and its underlying numeric datatype (e.g., binary
numbers). But the ability to express the relationship alone is not too surprising.
What is more interesting is that the ornament can give rise to upgrades such
that
• the coherence properties of the upgrades semantically characterise the resem-
blance between container operations and corresponding numeric operations,
and
• the promotion predicates give the precise types of the container operations
that guarantee such resemblance.
We use insertion into a binomial heap as an example, which is presented in
detail below.
Binomial trees
The basic building blocks of binomial heaps are binomial trees, in which
elements are stored. Binomial trees are deﬁned inductively on their rank, which
is a natural number (see Figure 3.7):
• a binomial tree of rank 0 is a single node storing an element of type Val, and

84
3
Reﬁnements and ornaments
• a binomial tree of rank suc r consists of two binomial trees of rank r, with one
attached under the other’s root node.
From this deﬁnition we can readily deduce that a binomial tree of rank r
has 2r elements. To actually deﬁne binomial trees as a datatype, however, an
alternative view is more helpful: a binomial tree of rank r is constructed by
attaching binomial trees of ranks 0 to r −1 under a root node. (Figure 3.7 shows
how binomial trees of ranks 1 to 3 can be decomposed according to this view.)
We thus deﬁne the datatype BTree : Nat →Set — which is indexed with the
rank of binomial trees — as follows: for any rank r : Nat, the type BTree r has a
ﬁeld of type Val — which is the root node — and r recursive positions indexed
from r −1 down to 0. This is directly encoded as a description:
BTreeD : Desc Nat
BTreeD r = σ[
: Val ] v (descend r)
BTree : Nat →Set
BTree = µ BTreeD
where descend r is a list from r −1 down to 0:
descend : Nat →List Nat
descend zero
= []
descend (suc n) = n :: descend n
Note that, in BTreeD, we are exploiting the full computational power of Desc,
computing the list of recursive indices from the index request. Due to this, it is
tricky to wrap up BTreeD as an index-ﬁrst datatype declaration, so we will skip
this step and work directly with the raw representation, which looks reasonably
intuitive anyway: a binomial tree of type BTree r is of the form con (x , ts)
where x : Val is the root element and ts : P (descend r) BTree is a series of
sub-trees.
The most important operation on binomial trees is combining two smaller
binomial trees of the same rank into a larger one, which corresponds to carrying
in positional arithmetic. Given two binomial trees of the same rank r, one can
be attached under the root of the other, forming a single binomial tree of rank
suc r — this is exactly the inductive deﬁnition of binomial trees.

3.4
Examples
85
attach : {r : Nat} →BTree r →BTree r →BTree (suc r)
attach t (con (y , us)) = con (y , t , us)
For use in binomial heaps, though, we should ensure that elements in binomial
trees are in heap order, i.e., the root of any binomial tree (including sub-trees)
is the minimum element in the tree. This is achieved by comparing the roots of
two binomial trees before deciding which one is to be attached to which:
link : {r : Nat} →BTree r →BTree r →BTree (suc r)
link t u with root t ⩽? root u
link t u | yes
= attach u t
link t u | no
= attach t u
where root extracts the root element of a binomial tree:
root : {r : Nat} →BTree r →Val
root (con (x , ts)) = x
If we always build binomial trees of positive rank by link, then the elements in
any binomial tree we build will be in heap order. This is a crucial assumption
in binomial heaps (which is not essential to our development, though).
From binary numbers to binomial heaps
The datatype Bin : Set of binary numbers is just a specialised datatype of lists
of binary digits:
data BinTag : Set where
‘nil
: BinTag
‘zero : BinTag
‘one : BinTag
BinD : Desc ⊤
BinD
= σ BinTag λ { ‘nil
7→v []
; ‘zero 7→v ( :: [])
; ‘one 7→v ( :: []) }
indexﬁrst data Bin : Set where
Bin ∋nil

86
3
Reﬁnements and ornaments
| zero (b : Bin)
| one (b : Bin)
The intended interpretation of binary numbers is given by
toNat : Bin →Nat
toNat nil
= 0
toNat (zero b) = 0 + 2 × toNat b
toNat (one b) = 1 + 2 × toNat b
That is, the list of digits of a binary number of type Bin starts from the least
signiﬁcant digit, and the i-th digit (counting from zero) has weight 2i. We refer
to the position of a digit as its rank, i.e., the i-th digit is said to have rank i.
As stated in the beginning, binomial heaps are binary numbers whose
1-digits are decorated with binomial trees of matching rank, which can be
expressed straightforwardly as an ornamentation of binary numbers. To ensure
that the binomial trees in binomial heaps have the right rank, the datatype
BHeap : Nat →Set is indexed with the starting rank: if a binomial heap of type
BHeap r is nonempty (i.e., not nil), then its ﬁrst digit has rank r (and stores a
binomial tree of rank r when the digit is one), and the rest of the heap is indexed
with suc r.
BHeapOD : OrnDesc Nat ! BinD
BHeapOD (ok r) = σ BinTag λ { ‘nil
7→v
; ‘zero 7→v (ok (suc r) , )
; ‘one 7→∆[ t : BTree r ] v (ok (suc r) , ) }
indexﬁrst data BHeap : Nat →Set where
BHeap r ∋nil
| zero (h : BHeap (suc r))
| one (t : BTree r) (h : BHeap (suc r))
In applications, we would use binomial heaps of type BHeap zero, which encom-
passes binomial heaps of all sizes.
Increment and insertion, in coherence
Increment of binary numbers is deﬁned by

3.4
Examples
87
incr : Bin →Bin
incr nil
= one nil
incr (zero b) = one b
incr (one b) = zero (incr b)
The corresponding operation on binomial heaps is insertion of a binomial tree
into a binomial heap (of matching rank), whose direct implementation is
insT : {r : Nat} →BTree r →BHeap r →BHeap r
insT t nil
= one t nil
insT t (zero
h) = one t h
insT t (one u h) = zero (insT (link t u) h)
Conceptually, incr puts a 1-digit into the least signiﬁcant position of a binary
number, triggering a series of carries, i.e., summing 1-digits of smaller ranks
into 1-digits of larger ranks; insT follows the pattern of incr, but since 1-digits
now have to store a binomial tree of matching rank, insT takes an additional
binomial tree as input and links binomial trees of smaller ranks into binomial
trees of larger ranks whenever carrying happens. Having deﬁned insT, inserting
a single element into a binomial heap of type BHeap zero is then inserting, by
insT, a rank-0 binomial tree (i.e., a single node) storing the element into the
heap.
insV : Val →BHeap zero →BHeap zero
insV x = insT (con (x , ))
It is apparent that the program structure of insT strongly resembles that
of incr — they manipulate the list-of-binary-digits structure in the same way.
But can we characterise the resemblance semantically? It turns out that the
coherence property of the following upgrade from the type of incr to that of
insT is an appropriate answer:
upg : Upgrade (
Bin
→Bin
)
({r : Nat} →BTree r →BHeap r →BHeap r)
upg = ∀+[[ r : Nat ]] ∀+[
: BTree r ] ref r ⇀toUpgrade (ref r)
where ref : (r : Nat) →Reﬁnement Bin (BHeap r)
ref r = RSem ⌈BHeapOD⌉(ok r)

88
3
Reﬁnements and ornaments
The upgrade upg says that, compared to the type of incr, the type of insT has
two new arguments — the implicit argument r : Nat and the explicit argument
of type BTree r — and that the two occurrences of BHeap r in the type of
insT reﬁne the corresponding occurrences of Bin in the type of incr using the
reﬁnement semantics of the ornament ⌈BHeapOD⌉(ok r) from Bin to BHeap r.
The type Upgrade.C upg incr insT (which states that incr and insT are coherent
with respect to upg) expands to
{r : Nat} (t : BTree r) (b : Bin) (h : BHeap r) →
toBin h ≡b →toBin (insT t h) ≡incr b
where toBin extracts the underlying binary number of a binomial heap:
toBin : {r : Nat} →BHeap r →Bin
toBin = forget ⌈BHeapOD⌉
That is, given a binomial heap h : BHeap r whose underlying binary number
is b : Bin, after inserting a binomial tree into h by insT, the underlying binary
number of the result is incr b. This says exactly that insT manipulates the
underlying binary number in the same way as incr.
We have seen that the coherence property of upg is appropriate for charac-
terising the resemblance of incr and insT; proving that it holds for incr and insT
is a separate matter, though. We can, however, avoid doing the implementation
of insertion and the coherence proof separately: instead of implementing insT
directly, we can implement insertion with a more precise type in the ﬁrst place
such that, from this more precisely typed version, we can derive insT that satis-
ﬁes the coherence property automatically. The above process is fully supported
by the mechanism of upgrades. Speciﬁcally, the more precise type for insertion
is given by the promotion predicate of upg (applied to incr), the more precisely
typed version of insertion acts as a promotion proof of incr (with respect to upg),
and the promotion gives us insT, accompanied by a proof that insT is coherent
with incr.
Let BHeap′ be the optimised predicate for the ornament from Bin to BHeap r:
BHeap′ : Nat →Bin →Set
BHeap′ r b = OptP ⌈BHeapOD⌉(ok r) b
indexﬁrst data BHeap′ : Nat →Bin →Set where

3.4
Examples
89
BHeap′ r nil
∋nil
BHeap′ r (zero b) ∋zero (h : BHeap′ (suc r) b)
BHeap′ r (one b) ∋one (t : BTree r) (h : BHeap′ (suc r) b)
Here a more helpful interpretation is that BHeap′ is a datatype of binomial
heaps additionally indexed with the underlying binary number. The type
Upgrade.P upg incr of promotion proofs for incr then expands to
{r : Nat} →BTree r →(b : Bin) →BHeap′ r b →BHeap′ r (incr b)
A function of this type is explicitly required to transform the underlying binary
number structure of its input in the same way as incr. Insertion can now be
implemented as
insT′ : {r : Nat} →BTree r →(b : Bin) →BHeap′ r b →BHeap′ r (incr b)
insT′ t nil
nil
= one t nil
insT′ t (zero b) (zero
h) = one t h
insT′ t (one b) (one u h) = zero (insT′ (link t u) h)
which is very much the same as the original insT. It is interesting to note that
all the constructor choices for binomial heaps in insT′ are actually completely
determined by the types. This fact is easier to observe if we desugar insT′ to
the raw representation:
insT′ : {r : Nat} →BTree r →(b : Bin) →BHeap′ r b →BHeap′ r (incr b)
insT′ t (con (‘nil
,
)) (con
) = con (t , con
, )
insT′ t (con (‘zero , b , )) (con (
h , )) = con (t , h
, )
insT′ t (con (‘one , b , )) (con (u , h , )) = con (
insT′ (link t u) b h , )
in which no constructor tags for binomial heaps are present. This means that
the types would determine which constructors to use when programming insT′,
establishing the coherence property by construction. Finally, since insT′ is a
promotion proof for incr, we can invoke the upgrading operation of upg and
get insT:
insT : {r : Nat} →BTree r →BHeap r →BHeap r
insT = Upgrade.u upg incr insT′
which is automatically coherent with incr:
incr-insT-coherence : {r : Nat} (t : BTree r) (b : Bin) (h : BHeap r) →

90
3
Reﬁnements and ornaments
toBin h ≡b →toBin (insT t h) ≡incr b
incr-insT-coherence = Upgrade.c upg incr insT′
To sum up: We deﬁne Bin, incr, and then BHeap as an ornamentation of
Bin, describe in upg how the type of insT is an upgraded version of the type
of incr, and implement insT′, whose type is supplied by upg. We can then
derive insT, the coherence property of insT with respect to incr, and its proof,
all automatically by upg. Compared to Okasaki’s implementation, besides rank-
indexing, which elegantly transfers the management of rank-related invariants
to the type system, the extra work is only the straightforward markings of
the differences between Bin and BHeap (in BHeapOD) and between the type
of incr and that of insT (in upg).
The reward is huge in comparison: we
get a coherence property that precisely characterises the structural behaviour
of insertion with respect to increment, and an enriched function type that
guides the implementation of insertion such that the coherence property is
satisﬁed by construction. This example is thus a nice demonstration of using
the ornament–reﬁnement framework to derive nontrivial types and programs
from straightforward markings.
Shifting and halving
We turn to another example and contrast our approach using reﬁnements and
upgrades with the usual externalist approach. In a binary number, we can
decrease the ranks of all the bits by one and discard the bit of rank zero, i.e.,
“shifting” all the bits to the left:
shift : Bin →Bin
shift nil
= nil
shift (zero b) = b
shift (one b) = b
This operation corresponds to “halving” of binomial heaps: Suppose we are
given a function of type {r : Nat} →BTree (suc r) →BTree r — which shrinks
a binomial tree of rank suc r to one of rank r — and a binomial heap starting
from rank r. After discarding the binomial tree of rank r in the heap (if any),

3.4
Examples
91
we apply the shrinking function to all binomial trees in the remaining heap,
obtaining a binomial heap starting from rank r again. The shrinking function
may extract the largest sub-tree,
left : {r : Nat} →BTree (suc r) →BTree r
left (node x (t , ts)) = t
remove the largest sub-tree,
right : {r : Nat} →BTree (suc r) →BTree r
right (node x (t , ts)) = node x ts
or even perform some more complicated computations. Halving a binomial
heap twice with left and right discards the binomial tree at the ﬁrst position
of the heap (if any) and splits the rest of the heap into two smaller heaps of
the same size. To implement halving in our framework, we start by writing an
upgrade
upg : Upgrade (Bin →Bin) (({r : Nat} →BTree (suc r) →BTree r) →
{r : Nat} →BHeap r →BHeap r)
upg = ∀+[
: {r : Nat} →BTree (suc r) →BTree r ]
∀+[[ r : Nat ]] let ref = RSem ⌈BHeapOD⌉(ok r)
in ref ⇀toUpgrade ref
and construct a promotion proof speciﬁed by this upgrade, which amounts to
the halving operation on BHeap′:
halve′ : ({r : Nat} →BTree (suc r) →BTree r) →
{r : Nat} (b : Bin) →BHeap′ r b →BHeap′ r (shift b)
halve′ f nil
nil
= nil
halve′ f (zero
) (zero h) = mapBHeap′ f h
halve′ f (one
) (one t h) = mapBHeap′ f h
where the auxiliary operation mapBHeap′ is the usual mapping operation on
binomial heaps with a particular type:
mapBHeap′ : ({r : Nat} →BTree (suc r) →BTree r) →
{r : Nat} {b : Bin} →BHeap′ (suc r) b →BHeap′ r b
mapBHeap′ f {r} {nil
} nil
= nil
mapBHeap′ f {r} {zero
} (zero h) = zero
(mapBHeap′ f h)
mapBHeap′ f {r} {one
} (one t h) = one (f t) (mapBHeap′ f h)

92
3
Reﬁnements and ornaments
Now the upgrade mechanism directly gives us the halving operation on BHeap
and a proof that it is coherent with shift:
halve : ({r : Nat} →BTree (suc r) →BTree r) →
{r : Nat} →BHeap r →BHeap r
halve = Upgrade.u upg shift halve′
shift-halve-coherence :
(f : {r : Nat} →BTree (suc r) →BTree r)
{r : Nat} (b : Bin) (h : BHeap r) →
toBin h ≡b →toBin (halve f h) ≡shift b
shift-halve-coherence = Upgrade.c upg shift halve′
In contrast, had we bypassed the upgrade mechanism and implemented
mapping and halving directly,
mapBHeap : ({r : Nat} →BTree (suc r) →BTree r) →
{r : Nat} →BHeap (suc r) →BHeap r
mapBHeap f nil
= nil
mapBHeap f (zero h) = zero
(mapBHeap f h)
mapBHeap f (one t h) = one (f t) (mapBHeap f h)
halve : ({r : Nat} →BTree (suc r) →BTree r) →
{r : Nat} →BHeap r →BHeap r
halve f nil
= nil
halve f (zero h) = mapBHeap f h
halve f (one t h) = mapBHeap f h
which take roughly the same amount of effort to implement as mapBHeap′ and
halve′, we would have needed to construct an extra proof for each of the two
operations to establish coherence:
toBin-mapBHeap : (f : {r : Nat} →BTree (suc r) →BTree r)
{r : Nat} (h : BHeap (suc r)) →
toBin (mapBHeap f h) ≡toBin h
toBin-mapBHeap f nil
= reﬂ
toBin-mapBHeap f (zero h) = cong zero (toBin-mapBHeap f h)
toBin-mapBHeap f (one t h) = cong one (toBin-mapBHeap f h)
shift-halve-coherence : (f : {r : Nat} →BTree (suc r) →BTree r)

3.4
Examples
93
Tree : Set
skeletal binary trees
ITree Val : Set
internally labelled trees
Heap : Val →Set
heap-ordered trees
LTree : Nat →Set
(rank-biased) leftist trees
WLTree : Nat →Set
weight-biased leftist trees
LHeap : Val →Nat →Set
(rank-biased) leftist heaps
WLHeap : Val →Nat →Set
weight-biased leftist heaps
Figure 3.8
Datatypes involved in leftist heaps and their ornamental relationships.
{r : Nat} (b : Bin) (h : BHeap r) →
toBin h ≡b →toBin (halve f h) ≡shift b
shift-halve-coherence f .nil
nil
reﬂ= reﬂ
shift-halve-coherence f .(zero (toBin h)) (zero h) reﬂ= toBin-mapBHeap f h
shift-halve-coherence f .(one (toBin h)) (one t h) reﬂ= toBin-mapBHeap f h
These proofs are implicitly embedded into mapBHeap′ and halve′ by the extra
indexing of BHeap′. Note that, in this partially externalist development, the
structural invariants of binomial trees and binomial heaps are still maintained
by internalist indexing of BTree and BHeap. There would have been even more
externalist proof obligations had we used a more externalist representation, like
List (Σ Nat BTree) for binomial heaps.
3.4.3
Leftist heaps
Our last example is about treating the ordering and balancing properties of
leftist heaps modularly. In Okasaki’s words [1999]:
Leftist heaps [. . .] are heap-ordered binary trees that satisfy the leftist

94
3
Reﬁnements and ornaments
property: the rank of any left child is at least as large as the rank of
its right sibling. The rank of a node is deﬁned to be the length of its
right spine (i.e., the rightmost path from the node in question to an
empty node).
From this passage we can immediately analyse the concept of leftist heaps into
three: leftist heaps (i) are binary trees that (ii) are heap-ordered and (iii) satisfy
the leftist property. This suggests that there is a basic datatype of binary
trees together with two ornamentations, one expressing heap ordering and the
other the leftist property. The datatype of leftist heaps is then synthesised by
composing the two ornamentations in parallel. All the datatypes involved in
leftist heaps, including later variations, are shown in Figure 3.8, together with
their ornamental relationships.
Datatypes leading to leftist heaps
The basic datatype Tree : Set of “skeletal” binary trees, which consist of empty
nodes and internal nodes not storing any elements, is deﬁned by
data TreeTag : Set where
‘nil
: TreeTag
‘node : TreeTag
TreeD : Desc ⊤
TreeD
= σ TreeTag λ { ‘nil
7→v []
; ‘node 7→v ( ::
:: []) }
indexﬁrst data Tree : Set where
Tree ∋nil
| node (t : Tree) (u : Tree)
Leftist trees — skeletal binary trees satisfying the leftist property — are then
an ornamented version of Tree. The datatype LTree : Nat →Set of leftist trees
is indexed with the rank of the root of the trees. The constructor choices can be
determined from the rank: the only node that can have rank zero is the empty
node nil; otherwise, when the rank of a node is non-zero, it must be an internal
node constructed by the node constructor, which enforces the leftist property.

3.4
Examples
95
(Below we overload
⩽to also denote the natural ordering on Nat.)
LTreeOD : OrnDesc Nat ! TreeD
LTreeOD (ok zero
) =
∆
[ ‘nil ] v
LTreeOD (ok (suc r)) =
∆
[ ‘node ] ∆[ l : Nat ] ∆[ r⩽l : r ⩽l ] v (ok l , ok r , )
indexﬁrst data LTree : Nat →Set where
LTree zero
∋nil
LTree (suc r) ∋node {l : Nat} (r⩽l : r ⩽l) (t : LTree l) (u : LTree r)
Independently, heap-ordered trees are also an ornamented version of Tree.
The datatype Heap : Val →Set of heap-ordered trees can be regarded as a
generalisation of ordered lists: in a heap-ordered tree, every path from the root
to an empty node is an ordered list.
HeapOD : OrnDesc Val ! TreeD
HeapOD (ok b) =
σ TreeTag λ { ‘nil
7→v
; ‘node 7→∆[ x : Val ] ∆[ b⩽x : b ⩽x ] v (ok x , ok x , ) }
indexﬁrst data Heap : Val →Set where
Heap b ∋nil
| node (x : Val) (b⩽x : b ⩽x) (t : Heap x) (u : Heap x)
Composing the two ornaments in parallel gives us exactly the datatype of leftist
heaps.
LHeapOD : OrnDesc (! ▷◁!) pull TreeD
LHeapOD = ⌈HeapOD⌉⊗⌈LTreeOD⌉
indexﬁrst data LHeap : Val →Nat →Set where
LHeap b zero
∋nil
LHeap b (suc r) ∋node (x : Val) (b⩽x : b ⩽x)
{l : Nat} (r⩽l : r ⩽l)
(t : LHeap x l) (u : LHeap x r)
Operations on leftist heaps
The analysis of leftist heaps as the parallel composition of the two ornamen-
tations allows us to talk about heap ordering and the leftist property inde-

96
3
Reﬁnements and ornaments
pendently. For example, a commonly used operation on heap-ordered trees
is relaxing the lower bound. It can be regarded as an upgraded version of
the identity function on Tree, since it leaves the tree structure intact, changing
only the ordering information. With the help of the optimised predicate for
⌈HeapOD⌉,
Heap′ : Val →Tree →Set
Heap′ b t = OptP ⌈HeapOD⌉(ok b) t
indexﬁrst data Heap′ : Val →Tree →Set where
Heap′ b nil
∋nil
Heap′ b (node t u) ∋node (x : Val) (b⩽x : b ⩽x)
(t′ : Heap x t) (u′ : Heap x u)
we can give the type of bound-relaxing in predicate form, stating explicitly in
the type that the underlying tree structure is unchanged:
relax : {b b′ : Val} →b′ ⩽b →{t : Tree} →Heap′ b t →Heap′ b′ t
relax b′⩽b {nil
} nil
= nil
relax b′⩽b {node
} (node x b⩽x t u) = node x (⩽-trans b′⩽b b⩽x) t u
Since the identity function on LTree can also be seen as an upgraded version
of the identity function on Tree, we can combine relax and the predicate form
of the identity function on LTree to get bound-relaxing on leftist heaps, which
modiﬁes only the heap-ordering portion of a leftist heap:
lhrelax : {b b′ : Val} →b′ ⩽b →{r : Nat} →LHeap b r →LHeap b′ r
lhrelax = Upgrade.u upg id (λ b′⩽b t 7→relax b′⩽b ∗id)
where
ref : (b : Val) (r : Nat) →Reﬁnement Tree (LHeap b r)
ref b r = toReﬁnement
(⊗-FSwap ⌈HeapOD⌉⌈LTreeOD⌉id-FSwap id-FSwap
(ok (ok b , ok r)))
upg : Upgrade
(
Tree
→Tree
)
({b b′ : Val} →b′ ⩽b →{r : Nat} →LHeap b r →LHeap b′ r)
upg = ∀+[[ b : Val ]] ∀+[[ b′ : Val ]] ∀+[
: b′ ⩽b ]
∀+[[ r : Nat ]] ref b r ⇀toUpgrade (ref b′ r)

3.4
Examples
97
In general, non-modifying heap operations do not depend on the leftist property
and can be implemented for heap-ordered trees and later lifted to work with
leftist heaps, relieving us of the unnecessary work of dealing with the leftist
property when it is simply to be ignored. For another example, converting a
leftist heap to a list of its elements by preorder traversal has nothing to do with
the leftist property. In fact, it even has nothing to do with heap ordering, but
only with the internal labelling. We hence deﬁne the internally labelled trees
as an ornamentation of skeletal binary trees:
ITreeOD : Set →OrnDesc ⊤! TreeD
ITreeOD A
= σ TreeTag λ { ‘nil
7→v
; ‘node 7→∆[
: A ] v (ok
, ok
, ) }
indexﬁrst data ITree (A : Set) : Set where
ITree A ∋nil
| node (x : A) (t : ITree A) (u : ITree A)
on which we can do preorder traversal:
preorderIT : {A : Set} →ITree A →List A
preorderIT nil
= []
preorderIT (node x t u) = x :: preorderIT t ++ preorderIT u
This operation can be upgraded to accept any argument whose type is more
informative than ITree A. Thus we parametrise the upgraded operation preorder
by an ornament:
preorder : {A I : Set} {D : Desc I} →Orn ! ⌊ITreeOD A⌋D →
{i : I} →µ D i →List A
preorder {A} {I} {D} O = Upgrade.u upg preorderIT (λ t p 7→
)
where upg : Upgrade (
ITree A →List A)
({i : I} →µ D i
→List A)
upg = ∀+[[ i : I ]] RSem O (ok i) ⇀toUpgrade idRef
where idRef is the identity reﬁnement:
idRef : {A : Set} →Reﬁnement A A
idRef = record { P = λ
7→⊤
; i
= record { to
= λ a 7→(a , )

98
3
Reﬁnements and ornaments
; from = λ { (a , ) 7→a }
; proofs of laws } }
There is an ornament from ITree to LHeap, which can be written either directly
or by sequentially composing the following ornament from ITree to Heap with
the ornament diffOrn-l ⌈HeapOD⌉⌈LTreeOD⌉from Heap to LHeap:
ITreeD-HeapD : Orn ! ⌊ITreeOD Val⌋⌊HeapOD⌋
ITreeD-HeapD (ok b) =
σ TreeTag λ { ‘nil
7→v []
; ‘node 7→σ[ x : Val ] ∆[
: b ⩽x ] v (reﬂ:: reﬂ:: []) }
(Sequential composition of ornaments will be introduced in Chapter 4.) Special-
ising preorder by the ornament gives preorder traversal of a leftist heap.
For modifying operations, however, we need to consider both heap ordering
and the leftist property at the same time, so we should program directly with
the composite datatype of leftist heaps. For example, a key operation is merging
two heaps:
merge : {b0 : Val} {r0 : Nat} →LHeap b0 r0 →
{b1 : Val} {r1 : Nat} →LHeap b1 r1 →
{b
: Val} →b ⩽b0 →b ⩽b1 →Σ[ r : Nat ] LHeap b r
with which we can easily implement insertion of a new element (by merging
with a singleton heap) and deletion of the minimum element (by deleting the
root and merging the two sub-heaps). The deﬁnition of merge is shown in Fig-
ure 3.9. It is a more precisely typed version of Okasaki’s implementation, split
into two mutually recursive functions to make it clear to Agda’s termination
checker that we are doing two-level induction on the ranks of the two input
heaps. When one of the ranks is zero, meaning that the corresponding heap is
nil, we simply return the other heap (whose bound is suitably relaxed) as the
result. When both ranks are non-zero, meaning that both heaps are nonempty,
we compare the roots of the two heaps and recursively merge the heap with
the larger root into the right branch of the heap with the smaller root. The
recursion is structural because the rank of the right branch of a nonempty
heap is strictly smaller. There is a catch, however: the rank of the new right
sub-heap resulting from the recursive merging might be larger than that of the

3.4
Examples
99
makeT : (x : Nat) →{r0 : Nat} (h0 : LHeap x r0) →
{r1 : Nat} (h1 : LHeap x r1) →Σ[ r : Nat ] LHeap x r
makeT x {r0} h0 {r1} h1 with r0 ⩽? r1
makeT x {r0} h0 {r1} h1 | yes r0⩽r1 = suc r0 , node x ⩽-reﬂr0⩽r1
h1 h0
makeT x {r0} h0 {r1} h1 | no r0≰r1 = suc r1 , node x ⩽-reﬂ(≰-invert r0≰r1) h0 h1
mutual
merge : {b0 : Val} {r0 : Nat} →LHeap b0 r0
→
{b1 : Val} {r1 : Nat} →LHeap b1 r1
→
{b
: Val} →b ⩽b0 →b ⩽b1 →Σ[ r : Nat ] LHeap b r
merge {b0} {zero } nil h1 b⩽b0 b⩽b1 =
, lhrelax b⩽b1 h1
merge {b0} {suc r0} h0 h1 b⩽b0 b⩽b1 = merge′ h0 h1 b⩽b0 b⩽b1
merge′ : {b0 : Val} {r0 : Nat} →LHeap b0 (suc r0) →
{b1 : Val} {r1 : Nat} →LHeap b1 r1
→
{b
: Val} →b ⩽b0 →b ⩽b1 →Σ[ r : Nat ] LHeap b r
merge′ h0
{b1} {zero } nil
b⩽b0 b⩽b1 =
, lhrelax b⩽b0 h0
merge′ (node x0 b0⩽x0 r0⩽l0 t0 u0) {b1} {suc r1} (node x1 b1⩽x1 r1⩽l1 t1 u1) b⩽b0 b⩽b1 with x0 ⩽? x1
merge′ (node x0 b0⩽x0 r0⩽l0 t0 u0) {b1} {suc r1} (node x1 b1⩽x1 r1⩽l1 t1 u1) b⩽b0 b⩽b1 | yes x0⩽x1 =
, lhrelax (⩽-trans b⩽b0 b0⩽x0) (outr (makeT x0 t0 (outr (merge u0 (node x1 x0⩽x1 r1⩽l1 t1 u1) ⩽-reﬂ⩽-reﬂ))))
merge′ (node x0 b0⩽x0 r0⩽l0 t0 u0) {b1} {suc r1} (node x1 b1⩽x1 r1⩽l1 t1 u1) b⩽b0 b⩽b1 | no x0≰x1 =
, lhrelax (⩽-trans b⩽b1 b1⩽x1) (outr (makeT x1 t1 (outr (merge′ (node x0 (≰-invert x0≰x1) r0⩽l0 t0 u0) u1 ⩽-reﬂ⩽-reﬂ))))
Figure 3.9
Merging two leftist heaps. Proof terms about ordering are coloured grey to aid comprehension (taking
inspiration from — but not really employing — Bernardy and Guilhem’s “type theory in colour” [2013]).

100
3
Reﬁnements and ornaments
left sub-heap, violating the leftist property, so there is a helper function makeT
that swaps the sub-heaps when necessary.
Weight-biased leftist heaps
Another advantage of separating the leftist property and heap ordering is
that we can swap the leftist property for another balancing property. The
non-modifying operations, previously deﬁned for heap-ordered trees, can be
upgraded to work with the new balanced heap datatype in the same way, while
the modifying operations are reimplemented with respect to the new balancing
property. For example, the leftist property requires that the rank of the left
sub-tree is at least that of the right one; we can replace “rank” with “size” in its
statement and get the weight-biased leftist property. This is again codiﬁed as
an ornamentation of skeletal binary trees:
WLTreeOD : OrnDesc Nat ! TreeD
WLTreeOD (ok zero
) =
∆
[ ‘nil ] v
WLTreeOD (ok (suc n)) =
∆
[ ‘node ] ∆[ l : Nat ] ∆[ r : Nat ]
∆[
: r ⩽l ] ∆[
: n ≡l + r ] v (ok l , ok r , )
indexﬁrst data WLTree : Nat →Set where
WLTree zero
∋nil
WLTree (suc n) ∋node {l : Nat} {r : Nat}
(r⩽l : r ⩽l) (n≡l+r : n ≡l + r)
(t : WLTree l) (u : WLTree r)
which can be composed in parallel with the heap-ordering ornament ⌈HeapOD⌉
and gives us weight-biased leftist heaps.
WLHeapD : Desc (! ▷◁!)
WLHeapD = ⌊⌈HeapOD⌉⊗⌈WLTreeOD⌉⌋
indexﬁrst data WLHeap : Val →Nat →Set where
WLHeap b zero
∋nil
WLHeap b (suc n) ∋node (x : Val) (b⩽x : b ⩽x)
{l : Nat} {r : Nat}
(r⩽l : r ⩽l) (n≡l+r : n ≡l + r)

3.5
Discussion
101
(t : WLHeap x l) (u : WLHeap x r)
The weight-biased leftist property makes it possible to reimplement merging
in a single, top-down pass rather than two passes: With the original rank-biased
leftist property, recursive calls to merge are determined top-down by comparing
root elements, and the helper function makeT swaps a recursively computed
sub-heap with the other sub-heap if the rank of the former is larger; the rank
of a recursively computed sub-heap, however, is not known before a recursive
call returns (which is reﬂected by the existential quantiﬁcation of the rank
index in the result type of merge), so during the whole merging process makeT
does the swapping in a second bottom-up pass. On the other hand, with the
weight-biased leftist property, the merging operation has type
wmerge : {b0 : Val} {n0 : Nat} →WLHeap b0 n0 →
{b1 : Val} {n1 : Nat} →WLHeap b1 n1 →
{b
: Val} →b ⩽b0 →b ⩽b1 →WLHeap b (n0 + n1)
The implementation of wmerge is largely similar to merge and is omitted here.
For wmerge, however, the weight of a recursively computed sub-heap is known
before the recursive merging is actually performed (so the weight index can
be given explicitly in the result type of wmerge). The counterpart of makeT can
thus determine before a recursive call whether to do the swapping or not, and
the whole merging process requires only one top-down pass.
3.5
Discussion
Ornaments were ﬁrst proposed by McBride [2011]. This dissertation deﬁnes
ornaments as relations between descriptions (indexed with an index erasure
function), and rebrands McBride’s ornaments as ornamental descriptions. One
obvious advantage of relational ornaments is that they can arise between existing
descriptions, whereas ornamental descriptions always produce new descriptions
at the more informative end. This makes it possible to complete the commutative
square of parallel composition with difference ornaments. Another consequence
is that there can be multiple ornaments between a pair of descriptions. For

102
3
Reﬁnements and ornaments
example, consider the following description of a datatype consisting of two
ﬁelds of the same type:
TwinD : (A : Set) →Desc ⊤
TwinD A
= σ[
: A ] σ[
: A ] v []
Between TwinD A and itself, we have the identity ornament
λ {
7→σ[
: A ] σ[
: A ] v [] }
and the “swapping” ornament
λ {
7→∆[ x : A ] ∆[ y : A ]
∆
[ y ]
∆
[ x ] v [] }
whose forgetful function swaps the two ﬁelds. The other advantage of relational
ornaments is that they allow new datatypes to arise at the less informative
end. For example, coproduct of signatures as used in, e.g., data types à la
carte [Swierstra, 2008], can be implemented naturally with relational ornaments
but not with ornamental descriptions. Below we sketch a simplistic implemen-
tation: Consider (a simplistic version of) tagged descriptions [Chapman et al.,
2010], which are descriptions that, for any index request, always respond with
a constructor ﬁeld ﬁrst. A tagged description indexed by I : Set thus consists
of a family of types C : I →Set, where each C i is the set of constructor tags
for the index request i : I, and a family of subsequent response descriptions for
each constructor tag.
TDesc : Set →Set1
TDesc I = Σ[ C : I →Set ] (i : I) →C i →RDesc I
Tagged descriptions are decoded to ordinary descriptions by
⌊⌋T : {I : Set} →TDesc I →Desc I
⌊C , D⌋T i = σ (C i) (D i)
We can then deﬁne binary coproduct of tagged descriptions — which sums the
corresponding constructor ﬁelds — as follows:
⊕
: {I : Set} →TDesc I →TDesc I →TDesc I
(C , D) ⊕(C′ , D′) = (λ i 7→C i + C′ i) , (λ i 7→D i ▽D′ i)
where the coproduct type
+ and the join operator
▽are deﬁned as usual:
data
+ (A B : Set) : Set where
inl : A →A + B

3.5
Discussion
103
inr : B →A + B
▽
: {A B C : Set} →(A →C) →(B →C) →A + B →C
(f ▽g) (inl a) = f a
(f ▽g) (inr b) = g b
Now given two tagged descriptions tD = (C , D) and tD′ = (C′ , D′) of type
TDesc I, there are two ornaments from ⌊tD ⊕tD′⌋T to ⌊tD⌋T and ⌊tD′⌋T:
inlOrn : Orn id ⌊tD ⊕tD′⌋T ⌊tD⌋T
inlOrn (ok i) = ∆[ c : C i ]
∆
[ inl c ] idROrn (D i c)
inrOrn : Orn id ⌊tD ⊕tD′⌋T ⌊tD′⌋T
inrOrn (ok i) = ∆[ c′ : C′ i ]
∆
[ inr c′ ] idROrn (D′ i c′)
(where idROrn : {I : Set} (D : RDesc I) →ROrn id D D is the identity
response ornament) whose forgetful functions perform suitable injection of
constructor tags. Note that the manufactured new description ⌊tD ⊕tD′⌋T is
at the less informative end of inlOrn and inrOrn. It is thus actually biased to
refer to the less informative end of an ornament as “basic”, but the examples in
this dissertation are indeed biased in this sense, being inﬂuenced by McBride’s
original formulation.
Dagand and McBride [2014] later adapted McBride’s original ornaments
to index-ﬁrst datatypes, and also proposed “reornaments” as a more efﬁcient
representation of promotion predicates, taking full advantage of index-ﬁrst
datatypes. Reornaments are reimplemented in this dissertation as optimised
predicates using parallel composition, as a result of which we can derive
properties about optimised predicates using pullback properties of parallel
composition in Chapter 4. Dagand and McBride also extended the notion of
ornaments to “functional ornaments”, which we generalise to reﬁnements and
upgrades. The reﬁnement–upgrade approach is logically clearer and more
ﬂexible as it allows us to decouple two constructions:
• ornamental relationship between inductive families, whose reﬁnement se-
mantics gives particular conversion isomorphisms between corresponding
types in the inductive families, and
• how conversion isomorphisms in general enable function upgrading, as
encoded by the upgrade combinators.

104
3
Reﬁnements and ornaments
Also, compared to functional ornaments, which are formulated syntactically as
a universe and then interpreted to types and operations, upgrades skip syntactic
formulation and simply bundle relevant types and operations together, which
are then composed semantically by the upgrade combinators. The upgrade
mechanism can thus be more easily extended by deﬁning new combinators
(which we actually do in Section 5.3.1). In contrast, had we deﬁned upgrades as
a universe, we would have had to employ more complex techniques like data
types à la carte [Swierstra, 2008] to gain extensibility. The complexity would
not have been justiﬁed, because constructing a universe for upgrades in their
present form offers no beneﬁt: A universe is helpful only when it is necessary to
determine the range of syntactic forms, either for nontrivial computation on the
syntactic forms or for facilitation of deﬁning new interpretations of the syntactic
forms. Neither is the case with upgrades: we do not need to manipulate
the syntactic forms of upgrades, nor do we need to obtain semantic entities
other than those captured by the ﬁelds of Upgrade. In contrast, ornaments do
need a universe: we need to know all possible syntactic forms of ornaments
in order to compose them in parallel, which cannot be done if all we have
are the optimised predicates and ornamental conversion isomorphisms, i.e.,
the reﬁnement semantics. Indeed, this was what prompted us to go from
reﬁnements to ornaments, right before Section 3.2. The universe of ornaments
might appear complex, but the complexity is justiﬁed by, in particular, the
ability to compose ornaments in parallel.
The idea of viewing vectors as promotion predicates was ﬁrst proposed by
Bernardy [2011, page 82], and is later generalised to “type theory in colour”
[Bernardy and Guilhem, 2013], which uses modalities inspired by colours in
typing to manage relative irrelevance of terms and erasure of irrelevant terms.
For simple applications like the ones offered in Section 3.4, type theory in
colour and ornamentation offer similar approaches, with the former providing
more native support for erasure of terms and derivation of promotion pred-
icates. Ornaments, however, are fully computational due to the presence of
deletion (
∆
), which allows arbitrary computations, and can thus specify rela-
tionship between datatypes beyond erasure. (Section 6.1 will offer a clearer
view on the computational power of ornaments.)

3.5
Discussion
105
It is worth noting that
• constructing functions that are coherent with existing ones via upgrades and
• manufacturing internalist operations via externalist composition
are both achieved by extra indexing. For the ﬁrst case, an upgrade on function
types is about constructing a function coherent with a given one, where coher-
ence is deﬁned (in
⇀) as mapping related arguments to related results. (The
coherence property of upgrades is thus comparable to free theorems [Wadler,
1989], but the preserved relation we use in upgrades is the “underlying” relation
derived from reﬁnements.) To guarantee that a function on more informative
types (e.g., a function on lists) is coherent with a given function on basic types
(e.g., a function on natural numbers), we index the more informative types with
the underlying value, the results of which are the promotion predicates (e.g.,
vectors). A promotion proof (e.g., a function on vectors) is then a disguised
version of the function we wish to implement in the ﬁrst place, whose type
now has extra indexing for enforcing coherence by construction. For the second
case, suppose that we are asked to combine the internalist operations insertO
on ordered lists and insertV on vectors to insertOV on ordered vectors, which
involves fusing the ordered list and vector computed by the two operations
into an ordered vector as the ﬁnal result. Not all pairs of ordered lists and
vectors can be sensibly fused together, however — they must share the same
underlying list for the fusion to make sense. Our solution is to further index
the two datatypes with the underlying list, and implement operations on these
new datatypes, which are insert-ordered and insert-length. Now we can easily
keep track of the underlying list: the types of the new operations guarantee
that, when the input ordered list and vector share the same underlying list, so
do the results. Thus the operations can be sensibly combined.
Parallel composition provides logical support for manufacturing composite
internalist datatypes, but eventually the central problem is about when and
how properties of and operations on actual data structures can be analysed and
presented in a meaningful way. Decomposition of a property does not always
make sense even when it is logically feasible, and when a decomposition does
make sense, it is not the case that the resulting properties should always be
treated separately. For example, while it is perfectly logical to analyse red-black

106
3
Reﬁnements and ornaments
trees as internally labelled trees satisfying the red and black properties, the
red or black property by itself is useless in practice, and hence it is pointless
to develop modules separately for the red and black properties. In contrast,
we decomposed the leftist heap property into the leftist property and heap
ordering for good reasons: there are operations meaningful for heap-ordered
trees without the leftist property, and we can impose different leftist properties
on these heap-ordered trees while reusing the operations previously deﬁned
for heap-ordered trees. Decomposition of the leftist heap property thus makes
sense, but this does not mean that we can treat the leftist property and heap
ordering separately all the time — merging of leftist heaps, for example, should
be done by considering the leftist property and heap ordering simultaneously,
since both properties are essential to the correctness of the merging algorithm —
they are not “separable concerns” in this case, in Dijkstra’s terminology [1982].
Parallel composition is thus merely one small step towards a modular internalist
library, since all it provides is logical support of property decomposition, which
does not necessarily align with meaningful separation of concerns. It requires
further consideration to reorganise data structures and algorithms — together
with the various properties they satisfy, which are now ﬁrst-class entities — in
a way that makes proper use of the new logical support.

Chapter 4
Categorical organisation of the
ornament–reﬁnement framework
Chapter 3 left some obvious holes in the theory of ornaments. For instance:
• When it comes to composition of ornaments, the following sequential com-
position is probably the ﬁrst that comes to mind (rather than parallel compo-
sition), which is evidence that the ornamental relation is transitive:
⊙
: {I J K : Set} {e : J →I} {f : K →J} →
{D : Desc I} {E : Desc J} {F : Desc K} →
Orn e D E →Orn f E F →Orn (e ◦f) D F
-- deﬁnition in Figure 4.4
Correspondingly, we expect that
forget (O ⊙P)
and
forget O ◦forget P
are extensionally equal. That is, the sequential compositional structure of
ornaments corresponds to the compositional structure of forgetful functions.
We wish to state such correspondences in concise terms.
• While parallel composition of ornaments (Section 3.2.3) has a sensible def-
inition, it is deﬁned by case analysis at the microscopic level of individual
ﬁelds. Such a microscopic deﬁnition is difﬁcult to comprehend, and so are
any subsequent deﬁnitions and proofs. It is desirable to have a macroscopic
characterisation of parallel composition, so the nature of parallel composition
107

108
4
Categorical organisation of the ornament–reﬁnement framework
Orn
Fam
Fref
Fun
RSem
Ind
FRefF
FRefC
Com
FamF
∼=
Figure 4.1
Categories and functors for the ornament–reﬁnement framework.
is immediately clear, and subsequent deﬁnitions and proofs can be done in a
more abstract manner.
• The ornamental conversion isomorphisms (Section 3.3.1) and the modularity
isomorphisms (Section 3.3.2) were left unimplemented. Both sets of isomor-
phisms are about the optimised predicates (Section 3.3.1), which are deﬁned
in terms of parallel composition with singleton ornamentation (Section 3.2.2).
We thus expect that the existence of these isomorphisms can be explained in
terms of properties of parallel composition and singleton ornamentation.
A lightweight organisation of the ornament–reﬁnement framework in basic
category theory [Mac Lane, 1998] can help to ﬁll in all these holes. In more
detail:
• Categories and functors are abstractions for compositional structures and
structure-preserving maps between them. Facts about translations between
ornaments, reﬁnements, and functions can thus be neatly organised under
the categorical language (Section 4.1). The categories and functors used in
this chapter are summarised in Figure 4.1.
• Parallel composition merges two compatible ornaments and does nothing
more; in other words, it computes the least informative ornament that con-
tains the information of both ornaments. Characterisation of such universal
constructions is a speciality of category theory; in our case, parallel composi-
tion can be shown to be a categorical pullback (Section 4.2).

4.1
Categories and functors
109
• Universal constructions are unique up to isomorphism, so it is convenient
for establishing isomorphisms about universal constructions. The status
of parallel composition being a pullback can thus help to construct the
ornamental conversion isomorphisms (in Section 4.3.1) and the modularity
isomorphisms (in Section 4.3.2).
Section 4.4 concludes with some discussion.
4.1
Categories and functors
We deﬁne the general notions of categories and functors in Section 4.1.1 and then
concrete categories and functors speciﬁcally about ornaments and reﬁnements
in Section 4.1.2.
Categories and functors by themselves are uninteresting,
though; it is the purely categorical structures deﬁned on top of categories and
functors that make the categorical language worthwhile. We introduce the ﬁrst
such deﬁnition — categorical isomorphisms — in Section 4.1.3, and more in
Section 4.2.
4.1.1
Basic deﬁnitions
A ﬁrst approximation of a category is a (directed multi-) graph, which consists
of a set of objects (nodes) and a collection of sets of morphisms (edges) indexed
with their source and target objects:
record Graph {l m : Level} : Set (suc (l ⊔m)) where
ﬁeld
Object : Set l
⇒
: Object →Object →Set m
For example, the underlying graph of the category Fun of (small) sets and
(total) functions is
Fun-graph : Graph
Fun-graph = record { Object = Set
;
⇒
= λ A B 7→A →B }

110
4
Categorical organisation of the ornament–reﬁnement framework
A category is a graph whose morphisms are equipped with a monoid-like
compositional structure — there is a morphism composition operator of type
·
: {X Y Z : Object} →(Y ⇒Z) →(X ⇒Y) →(X ⇒Z)
which has left and right identities and is associative.
Remark (universe polymorphism).
Many deﬁnitions in this chapter (like Graph
above) employ Agda’s universe polymorphism [Harper and Pollack, 1991],
so the deﬁnitions can be instantiated at suitable levels of the Set hierarchy
as needed. (For example, the type of Fun-graph is implicitly instantiated as
Graph {1} {0}, since Set is of type Set1 and any A →B (where A, B : Set) are
of type Set (= Set0), and Graph {1} {0} itself is of type Set2, whose level is
computed by taking the successor of the maximum of the two level arguments.)
We will give the ﬁrst few universe-polymorphic deﬁnitions with full detail about
their levels, but will later suppress the syntactic noise wherever possible.
□
Before we move on to the deﬁnition of categories, though, special attention
must be paid to equality on morphisms, which is usually coarser than deﬁni-
tional equality — in Fun, for example, it is necessary to identify functions up
to extensional equality (so uniqueness of morphisms in universal properties
would make sense). As stated in Section 2.3, such equalities need to be explicitly
managed in Agda’s intensional setting, and one way is to use setoids [Barthe
et al., 2003] — sets with an explicitly speciﬁed equivalence relation — to repre-
sent sets of morphisms. Subsequently, functions deﬁned between setoids need
to be proved to respect the equivalences. The type of setoids can be deﬁned as
a record which contains a carrier set, an equivalence relation on the set, and the
three laws for the equivalence relation:
record Setoid {c d : Level} : Set (suc (c ⊔d)) where
ﬁeld
Carrier : Set c
≈
: Carrier →Carrier →Set d
reﬂ
: {x : Carrier} →x ≈x
sym
: {x y : Carrier} →x ≈y →y ≈x
trans : {x y z : Carrier} →x ≈y →y ≈z →x ≈z
For example, we can deﬁne a setoid of functions that uses extensional equality:

4.1
Categories and functors
111
FunSetoid : Set →Set →Setoid
FunSetoid A B = record { Carrier = A →B
;
≈
=
.=
; proofs of laws }
Proofs of the three laws are omitted from the presentation.
The type of categories is then deﬁned as a record containing a set of objects,
a collection of setoids of morphisms indexed by source and target objects, the
composition operator on morphisms, the identity morphisms, and the identity
and associativity laws for composition. The deﬁnition is shown in Figure 4.2.
Two notations are introduced to improve readability: X ⇒Y is deﬁned to be
the carrier set of the setoid of morphisms from X to Y, and f ≈g is deﬁned to
be the equivalence between the morphisms f and g as speciﬁed by the setoid to
which f and g belong. The last two laws cong-l and cong-r require morphism
composition to preserve the equivalence on morphisms; they are given in this
form to work better with the equational reasoning combinators commonly used
in Agda (see, e.g., the AoPA library [Mu et al., 2009]).
Now we can deﬁne the category Fun of sets and functions as
Fun : Category
Fun = record { Object
= Set
; Morphism = FunSetoid
;
·
=
◦
; id
= λ x 7→x
; proofs of laws }
Another important category that we will make use of is Fam (Figure 4.3), the
category of indexed families of sets and indexed families of functions, which
is useful for talking about componentwise structures. An object in Fam has
type Σ[ I : Set ] I →Set, i.e., it is a set I and a family of sets indexed by I
(forming this Σ-type requires a universe-polymorphic revision of the deﬁnition
of Σ); a morphism from (J , Y) to (I , X) is a function e : J →I and a
family of functions from Y j to X (e j) for each j : J. Morphism composition
is componentwise composition, and morphism equivalence is deﬁned to be
componentwise extensional equality. (The morphism equivalence is formulated

112
4
Categorical organisation of the ornament–reﬁnement framework
record Category {l m n : Level} : Set (suc (l ⊔m ⊔n)) where
ﬁeld
Object
: Set l
Morphism : Object →Object →Setoid {m} {n}
⇒
: Object →Object →Set m
X ⇒Y = Setoid.Carrier (Morphism X Y)
≈
: {X Y : Object} →(X ⇒Y) →(X ⇒Y) →Set n
≈
{X} {Y} = Setoid. ≈
(Morphism X Y)
ﬁeld
·
: {X Y Z : Object} →(Y ⇒Z) →(X ⇒Y) →(X ⇒Z)
id
: {X : Object} →(X ⇒X)
id-l
: {X Y : Object} (f : X ⇒Y) →id · f ≈f
id-r
: {X Y : Object} (f : X ⇒Y) →f · id ≈f
assoc
: {X Y Z W : Object} (f : Z ⇒W) (g : Y ⇒Z) (h : X ⇒Y) →
(f · g) · h ≈f · (g · h)
cong-l : {X Y Z : Object} {f g : Y ⇒Z} (h : X ⇒Y) →f ≈g →f · h ≈g · h
cong-r : {X Y Z : Object} (h : Y ⇒Z) {f g : X ⇒Y} →f ≈g →h · f ≈h · g
record Functor {l m n l′ m′ n′ : Level}
(C : Category {l} {m} {n}) (D : Category {l′} {m′} {n′}) :
Set (l ⊔m ⊔n ⊔l′ ⊔m′ ⊔n′) where
ﬁeld
object
: Object C →Object D
morphism : {X Y : Object C} →X ⇒C Y →object X ⇒D object Y
equiv-preserving : {X Y : Object C} {f g : X ⇒C Y} →
f ≈C g →morphism f ≈D morphism g
id-preserving
: {X : Object C} →morphism (id C {X}) ≈D id D {object X}
comp-preserving : {X Y Z : Object C} (f : Y ⇒C Z) (g : X ⇒C Y) →
morphism (f ·C g) ≈D (morphism f ·D morphism g)
Figure 4.2
Deﬁnitions of categories and functors. Subscripts are used to indicate to
which category an operator belongs.

4.1
Categories and functors
113
Fam : Category
Fam = record
{ Object
= Σ[ I : Set ] I →Set
; Morphism = λ { (J , Y) (I , X) 7→record
{ Carrier = Σ[ e : J →I ] Y ⇒(X ◦e)
;
≈
= λ { (e , u) (e′ , u′) 7→
(e .= e′) × ((j : J) →u {j} ˙≊u′ {j}) }
; proofs of laws } }
;
·
= λ { (e , u) (f , v) 7→e ◦f , (λ {k} 7→u {f k} ◦v {k}) }
; id
= (λ x 7→x) , (λ {i} x 7→x)
; proofs of laws }
Fref : Category
Fref = record
{ Object
= Σ[ I : Set ] I →Set
; Morphism = λ { (J , Y) (I , X) 7→record
{ Carrier = Σ[ e : J →I ] FReﬁnement e X Y
;
≈
= λ { (e , rs) (e′ , rs′) 7→
(e .= e′) ×
((j : J) →Reﬁnement.forget (rs (ok j)) ˙≊
Reﬁnement.forget (rs′ (ok j))) }
; proofs of laws } }
; proofs of laws }
Orn : Category
Orn = record
{ Object
= Σ[ I : Set ] Desc I
; Morphism = λ { (J , E) (I , D) 7→record
{ Carrier = Σ[ e : J →I ] Orn e D E
;
≈
= λ { (e , O) (f , P) 7→OrnEq O P }
; proofs of laws } }
;
·
= λ { (e , O) (f , P) 7→e ◦f , O ⊙P }
; id
= λ { {I , D} 7→(λ i 7→i) , idOrn D }
; proofs of laws }
Figure 4.3
(Partial) deﬁnitions of the categories Fam, Fref, and Orn.

114
4
Categorical organisation of the ornament–reﬁnement framework
with the help of McBride’s “John Major” heterogeneous equality
≊
[McBride,
1999] — the equivalence
˙≊
is pointwise heterogeneous equality — since given
y : Y j for some j : J, the types of u {j} y and u′ {j} y are not deﬁnitionally
equal but only provably equal.)
Categories are graphs with a compositional structure, and functors are
transformations between categories that preserve the compositional structure.
The deﬁnition of functors is shown in Figure 4.2: a functor consists of two
mappings, one on objects and the other on morphisms, where the morphism
part preserves all structures on morphisms, including equivalence, identity,
and composition. For example, we have two functors from Fam to Fun, one
summing components together
Com : Functor Fam Fun
-- the comprehension functor
Com = record { object
= λ { (I , X) 7→Σ I X }
; morphism = λ { (e , u ) 7→e ∗u }
; proofs of laws }
and the other extracting the index part.
FamF : Functor Fam Fun
-- the family ﬁbration functor
FamF = record { object
= λ { (I , X) 7→I }
; morphism = λ { (e , u ) 7→e }
; proofs of laws }
Proofs of the functor laws are omitted from the presentation.
4.1.2
Categories and functors for reﬁnements and ornaments
Some constructions in Chapter 3 can now be organised under several categories
(whose deﬁnitions are shown in Figure 4.3) and functors. For a start, we already
saw that reﬁnements are interesting only because of their intensional contents;
extensionally they amount only to their forgetful functions. This is reﬂected
in an isomorphism of categories between the category Fam and the category
Fref of type families and reﬁnement families (i.e., there are two functors back
and forth inverse to each other). An object in Fref is an indexed family of
sets as in Fam, and a morphism from (J , Y) to (I , X) consists of a function

4.1
Categories and functors
115
e : J →I on the indices and a reﬁnement family of type FReﬁnement e X Y. As
for the equivalence on morphisms, it sufﬁces to use extensional equality on the
index functions and componentwise extensional equality on reﬁnement families,
where extensional equality on reﬁnements means extensional equality on their
forgetful functions (extracted by Reﬁnement.forget), which we have shown in
Section 3.1.1 to be the core of reﬁnements. Note that a reﬁnement family from
X : I →Set to Y : J →Set is deliberately cast as a morphism in the opposite
direction from (J , Y) to (I , X); think of this as suggesting the direction of
the forgetful functions of reﬁnements. We can then deﬁne the following two
functors, forming an isomorphism of categories between Fref and Fam:
• We have a forgetful functor FRefF : Functor Fref Fam which is identity on
objects and componentwise Reﬁnement.forget on morphisms (which preserves
equivalence automatically):
FRefF : Functor Fref Fam
FRefF = record
{ object
= id
; morphism = λ { (e , rs) 7→e , (λ j 7→Reﬁnement.forget (rs (ok j))) }
; proofs of laws }
Note that FRefF remains a familiar covariant functor rather than a contravari-
ant one because of our choice of morphism direction.
• Conversely, there is a functor FRefC : Functor Fam Fref whose object part
is identity and whose morphism part is componentwise canonRef:
FRefC : Functor Fam Fref
FRefC = record
{ object
= id
; morphism = λ { (e , u) 7→e , λ { (ok j) 7→canonRef (u {j}) } }
; proofs of laws }
The two functors FRefF and FRefC are inverse to each other by deﬁnition.
There is another category Orn, which has objects of type Σ[ I : Set ] Desc I,
i.e., descriptions paired with index sets, and morphisms from (J , E) to (I , D) of
type Σ[ e : J →I ] Orn e D E, i.e., ornaments paired with index erasure functions.
To complete the deﬁnition of Orn:

116
4
Categorical organisation of the ornament–reﬁnement framework
E-reﬂ: (is : List I) →E id is is
E-reﬂ[]
= []
E-reﬂ(i :: is)
= reﬂ:: E-reﬂis
idROrn : (E : RDesc I) →ROrn id E E
idROrn (v is)
= v (E-reﬂis)
idROrn (σ S E) = σ[ s : S ] idROrn (E s)
idOrn : {I : Set} (D : Desc I) →Orn id D D
idOrn {I} D (ok i) = idROrn (D i)
E-trans : {I J K : Set} {e : J →I} {f : K →J} →
{is : List I} {js : List J} {ks : List K} →
E e js is →E f ks js →E (e ◦f) ks is
E-trans
[]
[]
= []
E-trans {e := e} (eeq :: eeqs) (feq :: feqs) = trans (cong e feq) eeq :: E-trans eeqs feqs
scROrn : {I J K : Set} {e : J →I} {f : K →J} →
{D : RDesc I} {E : RDesc J} {F : RDesc K} →
ROrn e D E →ROrn f E F →ROrn (e ◦f) D F
scROrn (v eeqs) (v feqs)
= v (E-trans eeqs feqs)
scROrn (v eeqs) (∆T P) = ∆[ t : T ]
scROrn (v eeqs) (P t)
scROrn (σ S O) (σ .S P) = σ[ s : S ]
scROrn (O s)
(P s)
scROrn (σ S O) (∆T P) = ∆[ t : T ]
scROrn (σ S O) (P t)
scROrn (σ S O) (
∆
s P)
=
∆
[ s ]
scROrn (O s)
P
scROrn (∆T O) (σ .T P) = ∆[ t : T ]
scROrn (O t)
(P t)
scROrn (∆T O) (∆U P) = ∆[ u : U ] scROrn (∆T O) (P u)
scROrn (∆T O) (
∆
t P)
=
scROrn (O t)
P
scROrn (
∆
s O) P
=
∆
[ s ]
scROrn O
P
⊙
: {I J K : Set} {e : J →I} {f : K →J} →
{D : Desc I} {E : Desc J} {F : Desc K} →
Orn e D E →Orn f E F →Orn (e ◦f) D F
⊙{f := f} O P (ok k) = scROrn (O (ok (f k))) (P (ok k))
Figure 4.4
Deﬁnitions for identity ornaments and sequential composition of orna-
ments.

4.1
Categories and functors
117
• We need to devise an equivalence on ornaments
OrnEq : {I J : Set} {e f : J →I} {D : Desc I} {E : Desc J} →
Orn e D E →Orn f D E →Set
such that it implies extensional equality of e and f and that of ornamental
forgetful functions:
OrnEq-forget : {I J : Set} {e f : J →I} {D : Desc I} {E : Desc J} →
(O : Orn e D E) (P : Orn f D E) →OrnEq O P →
(e .= f) × ((j : J) →forget O {j} ˙≊forget P {j})
The actual deﬁnition of OrnEq is deferred to Section 6.1.
• Morphism composition is sequential composition
⊙, which merges two
successive batches of modiﬁcations in a straightforward way. There is also
a family of identity ornaments, which simply use σ and v everywhere to
express that a description is identical to itself, and can be proved to serve as
identity of sequential composition. Their deﬁnitions are shown in Figure 4.4.
A functor Ind : Functor Orn Fam can then be constructed, which gives
the ordinary semantics of descriptions and ornaments: the object part of Ind
decodes a description (I , D) to its least ﬁxed point (I , µ D), and the morphism
part translates an ornament (e , O) to the forgetful function (e , forget O), the
latter preserving equivalence by virtue of OrnEq-forget.
Ind : Functor Orn Fam
Ind = record { object
= λ { (I , D) 7→I , µ D
}
; morphism = λ { (e , O) 7→e , forget O }
; proofs of laws }
To translate Orn to Fref, a naive way is to use the composite functor
FRefC ⋄Ind : Functor Orn Fref, where composition F ⋄G of functors
F : Functor D E and G : Functor C D is deﬁned by
F ⋄G : Functor C E
F ⋄G = record { object
= object F ◦object G
; morphism = morphism F ◦morphism G
; proofs of laws }

118
4
Categorical organisation of the ornament–reﬁnement framework
(We assume that there is an Agda statement “open Functor” in scope throughout
the dissertation, so Functor.object and Functor.morphism can simply be referred to
as object and morphism.) The resulting reﬁnements would then use the canonical
promotion predicates. However, the whole point of incorporating Orn in the
framework is that we can construct an alternative functor RSem directly from
Orn to Fref. The functor RSem is extensionally equal to the above composite
functor but intensionally different. While its object part still takes the least
ﬁxed point of a description, its morphism part is the reﬁnement semantics of
ornaments given in Section 3.3, whose promotion predicates are the optimised
predicates and have a more efﬁcient representation.
RSem : Functor Orn Fam
RSem = record { object
= λ { (I , D) 7→I , µ D
}
; morphism = λ { (e , O) 7→e , RSem O }
; proofs of laws }
4.1.3
Isomorphisms
So far the categorical organisation offers no obvious beneﬁts, because we
have not started talking about mapping purely categorical structures between
categories, which is our main reason for employing the categorical language.
One simplest example of such purely categorical structures is isomorphisms:
the type of isomorphisms between two objects X and Y in a category C is
deﬁned by
record Iso C X Y : Set
where
ﬁeld
to
: X ⇒Y
from : Y ⇒X
from-to-inverse : from · to ≈id
to-from-inverse : to · from ≈id
(We assume that, by introducing the category C in the text, there is implicitly a
statement open Category C, so
⇒refers to Category. ⇒C and so on.) The
relation ∼= we have been using is formally deﬁned as Iso Fun. Isomorphisms

4.2
Pullback properties of parallel composition
119
are preserved by functors, i.e., for any F : Functor C D we have
Iso C X Y →Iso D (object F X) (object F Y)
which is proved by mapping all objects, morphisms, compositions, and equiva-
lences in C appearing in the input isomorphism into D by F. This fact immedi-
ately tells us, for example, that when two ornaments are inverse to each other,
so are their forgetful functions, by taking F = Ind.
Another useful class of purely categorical structures are introduced next.
4.2
Pullback properties of parallel composition
One of the great advantages of category theory is the ability to formulate
the idea of universal constructions generically and concisely, which we will
use to give parallel composition a useful macroscopic characterisation. An
intuitive way to understand the idea of a universal construction is to think
of it as a “strongly best” solution to some speciﬁcation. More precisely: The
speciﬁcation is represented as a category whose objects are all possible solutions.
A morphism from X to Y is evidence that Y is (non-strictly) “better” than X, and
there can be more than one piece of such evidence. A “strongly best” solution
is a terminal object in this category, meaning that it is “uniquely evidently
better” than all objects in the category. Formally: an object Y in a category C is
terminal when it satisﬁes the universal property that for every object X there
is a unique morphism from X to Y, i.e., the setoid Morphism X Y has a unique
inhabitant:
Terminal C Y : Set
Terminal C Y = (X : Object) →Singleton (Morphism X Y)
where Singleton is deﬁned by
Singleton : (S : Setoid) →Set
Singleton S = Setoid.Carrier S × ((s t : Setoid.Carrier S) →s ≈S t)
(The universe levels of Terminal C Y and Singleton S can be inferred from those
of C and S. We instruct Agda to do the inference by writing Set
.) The
uniqueness condition ensures that terminal objects are unique up to (a unique)

120
4
Categorical organisation of the ornament–reﬁnement framework
isomorphism — that is, if two objects are both terminal in C, then there is an
isomorphism between them:
terminal-iso C : (X Y : Object) →Terminal C X →Terminal C Y →Iso C X Y
terminal-iso C X Y tX tY =
let f : X ⇒Y
f = outl (tY X)
g : Y ⇒X
g = outl (tX Y)
in record { to
= f
; from = g
; from-to-inverse = outr (tX X) (g · f) id
; to-from-inverse = outr (tY Y) (f · g) id }
Thus, to prove that two constructions are isomorphic, one way is to prove that
they are universal in the same sense, i.e., they are both terminal objects in the
same category. This is the main method we use to construct the ornamental
conversion isomorphisms in Section 4.3.1 and the modularity isomorphisms
in Section 4.3.2, both involving parallel composition. The goal of the rest of
this section is to ﬁnd suitable universal properties that characterise parallel
composition, preparing for Sections 4.3.1 and 4.3.2.
Span categories and products
As said earlier, parallel composition computes the least informative ornament
that contains the information of two compatible ornaments, and this is exactly
a categorical product. Below we construct the deﬁnition of categorical products
step by step. Let C be a category and L, R two objects in C. A span over L and R
is deﬁned by
record Span C L R : Set
where
constructor
, ,
ﬁeld
M : Object
l
: M ⇒L
r
: M ⇒R

4.2
Pullback properties of parallel composition
121
or diagrammatically:
L
M
R
l
r
If we interpret a morphism X ⇒Y as evidence that X is more informative than Y,
then a span over L and R is essentially an object which is more informative
than both L and R. Spans over the same objects can be “compared”: deﬁne a
morphism between two spans by
record SpanMorphism C L R (s s′ : Span C L R) : Set
where
constructor
, ,
ﬁeld
m : Span.M s ⇒Span.M s′
triangle-l : Span.l s′ · m ≈Span.l s
triangle-r : Span.r s′ · m ≈Span.r s
or diagrammatically (abbreviating Span.M s′ to M′ and so forth):
M
L
R
M′
l
r
l′
r′
m
where the two triangles are required to commute (i.e., triangle-l and triangle-r
should hold). Thus a span s is more informative than another span s′ when
Span.M s is more informative than Span.M s′ and the morphisms factorise
appropriately. We can now form a category of spans over L and R:
SpanCategory C L R : Category
SpanCategory C L R = record
{ Object
= Span C L R
; Morphism =
λ s s′ 7→record
{ Carrier = SpanMorphism C L R s s′
;
≈
= λ f g 7→SpanMorphism.m f ≈SpanMorphism.m g
; proofs of laws }
; proofs of laws }
Note that the equivalence on span morphisms is deﬁned to be the equivalence
on the mediating morphism in C, ignoring the two triangular commutativity

122
4
Categorical organisation of the ornament–reﬁnement framework
proofs. A product of L and R is then a terminal object in this category:
Product C L R : Span C L R →Set
Product C L R = Terminal (SpanCategory C L R)
In particular, a product of L and R contains the least informative object in C
that is more informative than both L and R.
Slice categories
We thus aim to characterise parallel composition as a product of two compatible
ornaments. This means that ornaments should be the objects of some category,
but so far we only know that ornaments are morphisms of the category Orn.
We are thus directed to construct a category whose objects are morphisms in
an ambient category C, so when we use Orn as the ambient category, parallel
composition can be characterised as a product in the derived category. Such
a category is in general a “comma category” [Mac Lane, 1998, § II.6], whose
objects are morphisms in the ambient category with arbitrary source and target
objects, but here we should restrict ourselves to a special case called a slice
category, since we seek to form products of only compatible ornaments (whose
less informative end coincide) rather than arbitrary ones. A slice category is
parametrised with an ambient category C and an object B in C, and has
• objects: all the morphisms in C with target B,
record Slice C B : Set
where
constructor
,
ﬁeld
T : Object
s : T ⇒B
and
• morphisms: mediating morphisms giving rise to commutative triangles,
record SliceMorphism C B (s s′ : Slice C B) : Set
where
constructor
,
ﬁeld

4.2
Pullback properties of parallel composition
123
m : Slice.T s ⇒Slice.T s′
triangle : Slice.s s′ · m ≈Slice.s s
or diagrammatically:
objects
T
B
s
and
morphisms
T
T′
B
s
s′
m
The deﬁnitions above are assembled into the deﬁnition of slice categories in
much the same way as span categories:
SliceCategory C B : Category
SliceCategory C B = record
{ Object
= Slice C B
; Morphism =
λ s s′ 7→record
{ Carrier = SliceMorphism C B s s′
;
≈
= λ f g 7→SliceMorphism.m f ≈SliceMorphism.m g
; proofs of laws }
; proofs of laws }
Objects in a slice category are thus morphisms with a common target, and when
the ambient category is Orn, they are exactly the compatible ornaments that
can be composed in parallel.
Pullbacks
We have arrived at the characterisation of parallel composition as a product
in a slice category on top of Orn. The composite term “product in a slice
category” has become a multi-layered concept and can be confusing; to facilitate
comprehension, we give several new deﬁnitions that can sometimes deliver
better intuition. Let C be an ambient category and X an object in C. We refer to
spans over two slices f, g : Slice C X alternatively as squares over f and g:
Square C f g : Set
Square C f g = Span (SliceCategory C X) f g

124
4
Categorical organisation of the ornament–reﬁnement framework
since diagrammatically a square looks like
X
Y
Z
W
l
r
f
g
which is the same as
X
X
X
Y
Z
W
=
=
l
r
f
g
In a square q, we will refer to the object Slice.T (Span.M q), i.e., the node W in
the diagrams above, as the vertex of q:
vertex : Square C f g →Object
vertex = Slice.T ◦Span.M
A product of f and g is alternatively referred to as a pullback of f and g; that is,
it is a square over f and g satisfying
Pullback C f g : Square C f g →Set
Pullback C f g = Product (SliceCategory C X) f g
Equivalently, if we deﬁne the square category over f and g as
SquareCategory C f g : Category
SquareCategory C f g = SpanCategory (SliceCategory C X) f g
then a pullback of f and g is a terminal object in the square category over
f and g — indeed, Product (SliceCategory C X) f g is deﬁnitionally equal to
Terminal (SquareCategory C f g). This means that, by terminal-iso, there is an
isomorphism between any two pullbacks p and q of the same slices f and g:
Iso (SquareCategory C f g) p q
Subsequently, since there is a forgetful functor from SquareCategory C f g to C
whose object part is vertex, and functors preserve isomorphisms, we also have
an isomorphism
Iso C (vertex p) (vertex q)
(4.1)
which is what we actually use in Sections 4.3.1 and 4.3.2.
Like isomorphisms, we can talk about preservation of pullbacks: any functor
F : Functor C D maps a square in C into one in D; if the resulting square
in D is a pullback whenever the input square in C is, then F is said to be
pullback-preserving. Formally:

4.2
Pullback properties of parallel composition
125
Pullback-preserving F :
{B : Category.Object C} {f g : Slice C B} (s : Square C f g) →
Pullback C f g s →Pullback D (object (SliceMap F) f) (object (SliceMap F) g)
(object (SquareMap F) s)
where
SliceMap
: (F : Functor C D) →
Functor (SliceCategory C B) (SliceCategory D (object F B))
SquareMap : (F : Functor C D) →
Functor (SquareCategory C f g)
(SquareCategory D (object (SliceMap F) f)
(object (SliceMap F) g))
are straightforward liftings of functors on ambient categories to functors on slice
and square categories. Unlike isomorphisms, pullbacks are not preserved by all
functors, but the functors Ind : Functor Orn Fam and Com : Functor Fam Fun
are pullback-preserving, which we use below.
Parallel composition as a pullback
For any O : Orn e D E and P : Orn f D F where D : Desc I, E : Desc J, and
F : Desc K, the following square in Orn is a pullback:
I , D
J , E
K , F
e ▷◁f , ⌊O ⊗P⌋
e , O
f , P
pull , ⌈O ⊗P⌉
outl▷◁, diffOrn-l O P
outr▷◁, diffOrn-r O P
(4.2)
We assert that the square is a pullback by marking its vertex with “
”. The
Agda term for the square is
pc-square O P : Square Orn ((J , E) , (e , O)) ((K , F) , (f , P))
pc-square O P = ((e ▷◁f , ⌊O ⊗P⌋) , (pull , ⌈O ⊗P⌉)) ,
((outl▷◁, diffOrn-l O P) , { }0 ) ,
((outr▷◁, diffOrn-r O P) , { }1 )

126
4
Categorical organisation of the ornament–reﬁnement framework
where Goal 0 has type OrnEq (O ⊙diffOrn-l O P) ⌈O ⊗P ⌉and Goal 1 has
type OrnEq (P ⊙diffOrn-r O P) ⌈O ⊗P ⌉, both of which can be discharged.
Comparing the commutative diagram (4.2) and the Agda term pc-square O P,
it should be obvious how concise the categorical language can be — the com-
mutative diagram expresses the structure of the Agda term in a clean and
visually intuitive way. Since terms like pc-square O P can be reconstructed from
commutative diagrams and the categorical deﬁnitions, from now on we will
present commutative diagrams as representations of the corresponding Agda
terms and omit the latter. A proof sketch of (4.2) is deferred to Section 6.1.
The pullback property (4.2) by itself is not too useful in this chapter, though:
Orn is a quite restricted category, so a universal property established in Orn
has limited applicability. Instead, we are more interested in the following two
pullback properties: the image of (4.2) under Ind in Fam:
I , µ D
J , µ E
K , µ F
e ▷◁f , µ ⌊O ⊗P⌋
e , forget O
f , forget P
pull, forget ⌈O ⊗P⌉
outl▷◁, forget (diffOrn-l O P)
outr▷◁, forget (diffOrn-r O P)
(4.3)
and the image of (4.3) under Com in Fun:
Σ I (µ D)
Σ J (µ E)
Σ K (µ F)
Σ (e ▷◁f) (µ ⌊O ⊗P⌋)
e ∗forget O
f ∗forget P
pull ∗forget ⌈O ⊗P⌉
outl▷◁∗forget (diffOrn-l O P)
outr▷◁∗forget (diffOrn-r O P)
(4.4)
The pullback property of (4.3) can be directly established. (Together with the
pullback property of (4.2), this ensures that Ind is pullback-preserving — a
functor is pullback-preserving if a speciﬁc square and its image under that
functor are both pullbacks.) Then the pullback property of (4.4) follows from
pullback preservation of Com.

4.3
Consequences
127
4.3
Consequences
Characterising parallel composition as a pullback immediately allows us to
instantiate standard categorical results, like commutativity (
, ⌊O ⊗P⌋) ∼=
(
, ⌊P ⊗O⌋) and associativity (
, ⌊⌈O ⊗P⌉⊗Q⌋) ∼= (
, ⌊O ⊗⌈P ⊗Q⌉⌋)
up to isomorphism in Orn (which can then be transferred by isomorphism
preservation to Fam, for example). Our original motivation, on the other hand,
is to implement the ornamental conversion isomorphisms and the modularity
isomorphisms, which we carry out below.
4.3.1
The ornamental conversion isomorphisms
We restate the ornamental conversion isomorphisms as follows: for any orna-
ment O : Orn e D E where D : Desc I and E : Desc J, we have
µ E j ∼= Σ[ x : µ D (e j) ] OptP O (ok j) x
for all j : J. Since the optimised predicates OptP O are deﬁned by parallel
composition of O and the singleton ornamentation S = singletonOD D, the
isomorphism expands to
µ E j ∼= Σ[ x : µ D (e j) ] µ ⌊O ⊗⌈S⌉⌋(ok j , ok (e j , x))
(4.5)
How do we derive this from the pullback properties for parallel composition?
It turns out that the pullback property (4.4) in Fun can help.
• Set-theoretically, the vertex of a pullback of two functions f : A →C and
g : B →C is isomorphic to Σ[ p : A × B ] f (outl p) ≡g (outr p); the
more information f and g carries into C, the stronger the equality constraint.
An extreme case is when C is just B and g is the identity (which retains all
information): the equality constraint reduces to f (outl p) ≡outr p, so the
second component of p is completely determined by the ﬁrst component, and
thus the vertex is isomorphic to just A. The same situation happens for the

128
4
Categorical organisation of the ornament–reﬁnement framework
following pullback square:
Σ I (µ D)
Σ J (µ E)
Σ (Σ I (µ D)) (µ ⌊S⌋)
Σ J (µ E)
e ∗forget O
outl ∗forget ⌈S⌉
e ∗forget O
id
(e ∗forget O)
▽
(singleton ◦forget O ◦outr)
(4.6)
Since singleton ornamentation does not add information to a datatype, the
vertical slice on the right-hand side
s = (Σ (Σ I (µ D)) (µ ⌊S⌋)) , (outl ∗forget ⌈S⌉)
retains all information like an identity function, and thus behaves like a “mul-
tiplicative unit” (viewing pullbacks as products of slices): any (compatible)
slice s′ alone gives rise to a product of s and s′. In particular, we can use the
bottom-left type Σ J (µ E) as the vertex of the pullback. This pullback square
is over the same slices as the pullback square (4.4) with P substituted by ⌈S⌉,
so by (4.1) we obtain an isomorphism
Σ J (µ E) ∼= Σ (e ▷◁outl) (µ ⌊O ⊗⌈S⌉⌋)
(4.7)
• To get from (4.7) to (4.5), we need to look more closely into the construction
of (4.7). The right-to-left direction of (4.7) is obtained by applying the universal
property of (4.6) to the square (4.4) (with P substituted by ⌈S⌉), so it is the
unique mediating morphism m that makes the following diagram commute:
Σ J (µ E)
Σ J (µ E)
Σ (Σ I (µ D)) (µ ⌊S⌋)
Σ (e ▷◁outl) (µ ⌊O ⊗⌈S⌉⌋)
id
(e ∗forget O)
▽
(singleton ◦forget O ◦outr)
outl▷◁∗forget (diffOrn-l O P)
outr▷◁∗forget (diffOrn-r O P)
m
From the left commuting triangle, we see that, extensionally, the morphism m
is just outl▷◁∗forget (diffOrn-l O P).

4.3
Consequences
129
• The above leads us to the following general lemma: if there is an isomorphism
Σ K X ∼= Σ L Y
whose right-to-left direction is extensionally equal to some f ∗g, then we
have
X k ∼= Σ[ l : f −1 k ] Y (und l)
for all k : K. For a justiﬁcation: ﬁxing k : K, an element of the form
(k , x) : Σ K X must correspond, under the given isomorphism, to some
element (l , y) : Σ L Y such that f l ≡k, so the set X k corresponds to exactly
the sum of the sets Y l such that f l ≡k.
• Specialising the lemma above for (4.7), we get
µ E j ∼= Σ[ jix : outl▷◁−1 j ] µ ⌊O ⊗⌈S⌉⌋(und jix)
(4.8)
for all j : J. Finally, observe that a canonical element of type outl▷◁−1 j must
be of the form ok (ok j , ok (e j , x)) for some x : µ D (e j), so we perform a
change of variables for the summation, turning the right-hand side of (4.8)
into
Σ[ x : µ D (e j) ] µ ⌊O ⊗⌈S⌉⌋(ok j , ok (e j , x))
and arriving at (4.5).
4.3.2
The modularity isomorphisms
The other important family of isomorphisms we should construct from the
pullback properties of parallel composition is the modularity isomorphisms,
which is restated as follows: Suppose that there are descriptions D : Desc I,
E : Desc J and F : Desc K, and ornaments O : Orn e D E, and P : Orn f D F.
Then we have
OptP ⌈O ⊗P⌉(ok (j , k)) x ∼= OptP O j x × OptP P k x
for all i : I, j : e −1 i, k : f −1 i, and x : µ D i. The isomorphism expands to
µ ⌊⌈O ⊗P⌉⊗⌈S⌉⌋(ok (j , k) , ok (i , x))
∼= µ ⌊O ⊗⌈S⌉⌋(j , ok (i , x)) × µ ⌊P ⊗⌈S⌉⌋(k , ok (i , x))
(4.9)

130
4
Categorical organisation of the ornament–reﬁnement framework
where again S = singletonOD D. A quick observation is that they are compo-
nentwise isomorphisms between the two families of sets
M = µ ⌊⌈O ⊗P⌉⊗⌈S⌉⌋
and
N = λ { (ok (j , k) , ok (i , x)) 7→
µ ⌊O ⊗⌈S⌉⌋(j , ok (i , x)) × µ ⌊P ⊗⌈S⌉⌋(k , ok (i , x)) }
both indexed by pull ▷◁outl where pull has type e ▷◁f →I and outl has type
Σ I X →I. This is just an isomorphism in Fam between (pull ▷◁outl , M) and
(pull ▷◁outl , N) whose index part (i.e., the isomorphism obtained under the
functor FamF) is identity. Thus we seek to prove that both (pull ▷◁outl , M) and
(pull ▷◁outl , N) are vertices of pullbacks of the same slices.
• We look at (pull ▷◁outl , N) ﬁrst. For ﬁxed i, j, k, and x, the set
N (ok (j , k) , ok (i , x))
along with the cartesian projections is a product, which trivially extends to a
pullback since there is a forgetful function from each of the two component
sets to the singleton set µ ⌊S⌋(i , x), as shown in the following diagram:
µ ⌊S⌋(i , x)
µ ⌊O ⊗⌈S⌉⌋(j , ok (i , x))
µ ⌊P ⊗⌈S⌉⌋(k , ok (i , x))
N (ok (j , k) , ok (i , x))
forget (diffOrn-r O ⌈S⌉)
forget (diffOrn-r P ⌈S⌉)
outl
outr
Note that this pullback square is possible because of the common x in the
indices of the two component sets — otherwise they cannot project to the
same singleton set. Collecting all such pullback squares together, we get the

4.3
Consequences
131
following pullback square in Fam:
Σ I (µ D) , µ ⌊S⌋
e ▷◁outl , µ ⌊O ⊗⌈S⌉⌋
f ▷◁outl , µ ⌊P ⊗⌈S⌉⌋
pull ▷◁outl , N
outr▷◁, forget (diffOrn-r O ⌈S⌉)
outr▷◁, forget (diffOrn-r P ⌈S⌉)
, outl
, outr
(4.10)
• Next we prove that (pull ▷◁outl , M) is also the vertex of a pullback of the
same slices as (4.10). This second pullback arises as a consequence of the
following lemma (illustrated in the diagram below): In any category, consider
the objects X, Y, their product X ⇐X ⊠Y ⇒Y, and products of each of the
three objects X, Y, and X ⊠Y with an object Z. (All the projections are shown
as solid arrows in the diagram.) Then (X ⊠Y) ⊠Z is the vertex of a pullback
of the two projections X ⊠Z ⇒Z and Y ⊠Z ⇒Z.
X
Y
Z
X ⊠Y
X ⊠Z
Y ⊠Z
(X ⊠Y) ⊠Z
We again intend to view a pullback as a product of slices, and instantiate
the lemma in SliceCategory Fam (I , µ D), substituting all the objects by
slices consisting of relevant ornamental forgetful functions in (4.9). The
substitutions are as follows:
X
7→
, (
, forget O)
Y
7→
, (
, forget P)
X ⊠Y
7→
, (
, forget ⌈O ⊗P⌉)
Z
7→
, (
, forget ⌈S⌉)
X ⊠Z
7→
, (
, forget ⌈O ⊗⌈S⌉⌉)
Y ⊠Z
7→
, (
, forget ⌈P ⊗⌈S⌉⌉)
(X ⊠Y) ⊠Z
7→
, (
, forget ⌈⌈O ⊗P⌉⊗⌈S⌉⌉)

132
4
Categorical organisation of the ornament–reﬁnement framework
where X ⊠Y, X ⊠Z, Y ⊠Z, and (X ⊠Y) ⊠Z indeed give rise to prod-
ucts in SliceCategory Fam (I , µ D), i.e., pullbacks in Fam, by instantiat-
ing (4.3). What we get out of this instantiation of the lemma is a pullback in
SliceCategory Fam (I , µ D) rather than Fam. This is easy to ﬁx, since there is
a forgetful functor from any SliceCategory C B to C:
SliceF : Functor (SliceCategory C B) C
SliceF = record { object
= Slice.T
; morphism = SliceMorphism.m
; proofs of laws }
which is pullback-preserving. We thus get a pullback in Fam of the same
slices as (4.10) whose vertex is (pull ▷◁outl , M).
Having the two pullbacks, by (4.1) we get an isomorphism in Fam between
(pull ▷◁outl , M) and (pull ▷◁outl , N), whose index part can be shown to be
identity, so there are componentwise isomorphisms between M and N in Fun,
arriving at (4.9).
4.4
Discussion
The categorical organisation of the ornament–reﬁnement framework effectively
summarises various constructions in the framework under the succinct cate-
gorical language. For example, the functor Ind from Orn to Fam is itself a
summary of the following:
• the least ﬁxed-point operation on descriptions (the object part of the functor),
• the ornamental forgetful functions (the morphism part of the functor),
• the equivalence on ornaments, which implies extensional equality on orna-
mental forgetful functions (since functors respect equivalence),
• the identity ornaments, whose forgetful functions are extensionally equal to
identity functions (since functors preserve identity),
• sequential composition of ornaments, and the fact that the forgetful function
for any sequentially composed ornament O ⊙P is extensionally equal to the
composition of the forgetful functions for O and P (since functors preserve

4.4
Discussion
133
composition).
Most importantly, a categorical pullback structure emerges from the frame-
work, which gives a macroscopic meaning to the microscopic type-theoretical
deﬁnition of parallel composition (thus ensuring that the deﬁnition is not an
arbitrary one), and enables constructions of the ornamental conversion isomor-
phisms and the modularity isomorphisms on a more abstract level. Compared
to the constructions of the isomorphisms using datatype-generic induction in
previous work [Ko and Gibbons, 2013a], the constructions presented in this
chapter offer more insights and are easier to understand: after establishing
the pullback properties of parallel composition, at the root of the ornamental
conversion isomorphisms is the intuition that singleton ornamentation does not
add information, and the modularity isomorphisms stem from the fact that the
pointwise conjunction of optimised predicates trivially extends to a pullback.
Also, the categorical constructions are impervious to change of representation
of the universes of descriptions and ornaments; modiﬁcation to the universes
only affects constructions logically prior to the pullback property (4.3). This
statement is empirically veriﬁed — the representation of the universes really
had to be changed once after carrying out the categorical constructions, but the
consequences of this change of representation were limited.
Dagand and McBride [2013] provided a purely categorical treatment of orna-
ments using ﬁbred category theory [Jacobs, 1999], which is quite independent
of the development in this chapter, though. They established correspondences
between descriptions and “polynomial functors” [Gambino and Kock, 2010]
and between ornaments and “cartesian morphisms”, and sketched how several
operations on ornaments correspond to certain categorical notions (including
pullbacks), all of which are ultimately based on the abstract notion of locally
cartesian closed categories. Methodologically, there is a notable difference be-
tween their work and the categorical development in this dissertation: Dagand
and McBride distinguish “software” (e.g., descriptions and ornaments) and
“mathematics” (e.g., polynomial functors and cartesian morphisms) and then
make a connection between them, so they can use mathematical notions as
inspiration for software constructs. In the light of the propositions-as-types
principle, though, a further step should be taken: rather than merely making a

134
4
Categorical organisation of the ornament–reﬁnement framework
connection between software artifacts that have the necessary level of detail and
mathematical objects that possess desired abstract properties, we should design
the software artifacts such that they satisfy the abstract properties themselves,
all expressed in one uniform language, so the detail of the artifacts can be
effectively managed by reasoning in terms of the abstract properties. In this
spirit, category theory is regarded in this dissertation as merely providing an
additional set of abstractions formulated within type theory, as opposed to
being an independent formalism. (As a consequence, the reasoning is still
essentially type-theoretical, rather than insisting on purely categorical argu-
ments.) Ornaments are complex, but the complexity is necessary (as justiﬁed
in Section 3.5) and hence can only be somehow managed rather than being
neglected by turning attention to similar mathematical objects. Fortunately,
ornaments themselves exhibit useful categorical structure that can be expressed
type-theoretically, so we are able to tame the complexity of ornaments by rea-
soning abstractly in terms of this categorical structure without switching to a
fundamentally different formalism.
The results of this chapter are completely formalised in Agda. The setoid
approach to managing morphism equivalence works reasonably well, being
able to express extensional equality (e.g., in Fun and Fam), proof irrelevance
(e.g., in SpanCategory and SliceCategory), and layered deﬁnitions of equality
(e.g., morphism equivalence in SquareCategory is ultimately deﬁned in terms
of morphism equivalence in the ambient category). However, the approach
works only because the formalised theory is still simple enough: for example,
isomorphisms of categories in general cannot be deﬁned sensibly, since that
requires us to turn sets of objects into setoids as well, and then the setoids of
morphisms have to be indexed by setoids and proved to respect equalities of
the latter, which quickly becomes unmanageable. Our modelling of categories
is able to evade this problem because both of the isomorphisms of categories in
this dissertation (one is between Orn and Fref, and the other will appear in
Section 6.1) use identities as their object parts. As for formalisation of proofs,
while the purely categorical lemmas can be encoded by equational reasoning
combinators with a reasonable amount of effort, formalisation in general is
rather difﬁcult due to Agda’s intensionality and lack of a tactic language for

4.4
Discussion
135
constructing proofs efﬁciently, which together result in the need of manually
constructing proof terms that require complicated handling of equalities. Also,
not all the reasoning presented can be faithfully encoded: For the last two steps
of the argument in Section 4.3.1, it is possible to formalise the lemma and the
change of variables individually and chain them together, but the resulting
isomorphisms would have a very complicated deﬁnition containing plenty of
suspended substs. If these isomorphisms are used to construct the reﬁnement
family in the morphism part of RSem, it would be terribly difﬁcult to prove that
the morphism part of RSem preserves equivalence. The actual formalisation
circumvents the problem by fusing the lemma and the change of variables into
one step to get a clean Agda deﬁnition such that RSem preserves equivalence
automatically. While this kind of change of arguments for formalisation seems
to be the norm (see, e.g., Avigad et al. [2007, Section 4.5]), it could occur more
frequently in dependently typed programming due to the requirement that the
constructed terms had better be “pretty” if they are to be referred to in later
types, so even a powerful tactic language probably would not help much, since
it is hard to control the form of proofs constructed by tactics. More experience
in tackling this kind of proof-relevant formalisation is needed.

136
4
Categorical organisation of the ornament–reﬁnement framework

Chapter 5
Relational algebraic ornamentation
This chapter turns to the synthetic direction of the interconnection between
internalism and externalism. As stated in Section 2.5, internalist types can
be hard to read and write, and it would be helpful to be able to switch to an
alternative language for understanding and deriving internalist types. The alter-
native language adopted in this chapter is the relational language (Section 5.1),
of which Bird and de Moor [1997] gave an authoritative account. Unlike the
datatype declaration language, using relations we can give concise yet com-
putationally intuitive speciﬁcations, which are amenable to manipulation by
algebraic laws and theorems. A particularly expressive relational construction
is relational folds, and when ﬁxing a basic datatype and casting a relational
fold as the externalist predicate, we can synthesise a corresponding internalist
datatype on the other side of the conversion isomorphism. More speciﬁcally,
every relational algebra gives rise to an algebraic ornamentation (Section 5.2),
whose optimised predicate (Section 3.3.1) can be swapped (Section 3.3.2) for
the relational fold with the algebra. Speciﬁcations involving relational folds
can then be met by constructing internalist programs whose types involve
corresponding algebraically ornamented datatypes. Several examples are given
in Section 5.3, followed by some discussion in Section 5.4.
137

138
5
Relational algebraic ornamentation
5.1
Relational programming in Agda
Functional programs are known for their amenability to algebraic calculation
(see, e.g., Backus [1978] and Bird [2010]), leading to one form of program
correctness by construction: one begins with a speciﬁcation in the form of a
functional program that expresses a straightforward but possibly inefﬁcient
computation, and transforms it into an extensionally equal but more efﬁcient
functional program by applying algebraic laws and theorems. Using functional
programs as the speciﬁcation language means that speciﬁcations are directly
executable, but the deterministic nature of functional programs can result in less
ﬂexible speciﬁcations. For example, when specifying an optimisation problem
using a functional program that generates all feasible solutions and chooses an
optimal one among them, the program necessarily enforces a particular way of
choosing the optimal solution, but such enforcement should not in general be
part of the speciﬁcation. To gain more ﬂexibility, the speciﬁcation language was
later generalised to relational programs (see, e.g., Bird [1996]). With relational
programs, we specify only the relationship between input and output without
actually specifying a way to execute the programs, so speciﬁcations in the form
of relational programs can be as ﬂexible as possible. Though lacking a directly
executable semantics, most relational programs can still be read computationally
as potentially partial and nondeterministic mappings, so relational speciﬁcations
largely remain computationally intuitive as functional speciﬁcations.
To emphasise the computational interpretation of relations, we will mainly
model a relation between sets A and B as a function sending each inhabitant
of A to a subset of B. We deﬁne subsets by
P : Set →Set1
PA = A →Set
That is, a subset s : PA is a characteristic function that assigns a type to
each inhabitant of A, and a : A is considered to be a member of s if the type
s a : Set is inhabited. We may regard PA as the type of computations that
nondeterministically produce an inhabitant of A. A simple example is
any : {A : Set} →PA
any = const ⊤

5.1
Relational programming in Agda
139
The subset any : PA associates the unit type ⊤with every inhabitant of A.
Since ⊤is inhabited, any can produce any inhabitant of A. While P cannot be
made into a conventional monad [Moggi, 1991; Wadler, 1992] because it is not
an endofunctor, it can still be equipped with the usual monadic programming
combinators (giving rise to a “relative monad” [Altenkirch et al., 2010]):
• The monadic unit is deﬁned as
return : {A : Set} →A →PA
return =
≡
The subset return a : PA for some a : A simpliﬁes to λ a′ 7→a ≡a′, so a is
the only member of the subset.
• The monadic bind is deﬁned as
>>=
: {A B : Set} →PA →(A →PB) →PB
>>= {A} s f = λ b 7→Σ[ a : A ] s a × f a b
If s : PA and f : A →PB, then the subset s >>= f : PB is the union of all
the subsets f a : PB where a ranges over the inhabitants of A that belong
to s; that is, an inhabitant b : B is a member of s >>= f exactly when there
exists some a : A belonging to s such that b is a member of f a.
(We omit the proofs that the two combinators satisfy the (relative) monad laws
up to pointwise isomorphism.) On top of return and
>>= , the functorial map
on P is deﬁned as
⟨$⟩: {A B : Set} →(A →B) →PA →PB
f
⟨$⟩s = s >>= λ a 7→return (f a)
and we also deﬁne a two-argument version for convenience:
⟨$⟩2 : {A B C : Set} →(A →B →C) →PA →PB →PC
f
⟨$⟩2 s t = s >>= λ a 7→t >>= λ b 7→return (f a b)
(The notation is a reference to applicative functors [McBride and Paterson, 2008],
allowing us to think of functorial maps of P as applications of pure functions
to effectful arguments.)
We deﬁne a relation between two families of sets as a family of relations
between corresponding sets in the families:

140
5
Relational algebraic ornamentation
⇝
: {I : Set} →(I →Set) →(I →Set) →Set1
⇝{I} X Y = {i : I} →X i →P(Y i)
which is the usual generalisation of
⇒
to allow nondeterminacy. Below we
deﬁne several relational operators that we will need.
• Since functions are deterministic relations, we have the following combinator
fun that lifts functions to relations using return.
fun : {I : Set} {X Y : I →Set} →(X ⇒Y) →(X ⇝Y)
fun f x = return (f x)
• The identity relation is just the identity function lifted by fun.
idR : {I : Set} {X : I →Set} →(X ⇝X)
idR = fun id
• Composition of relations
•
is easily deﬁned with
>>= : computing R
• S
on input x is ﬁrst computing S x and then feeding the result to R.
•
: {I : Set} {X Y Z : I →Set} →(Y ⇝Z) →(X ⇝Y) →(X ⇝Z)
(R
• S) x = S x >>= R
• Some relations do not carry obvious computational meaning, but can still be
deﬁned pointwise, like the meet of two relations:
∩
: {I : Set} {X Y : I →Set} →(X ⇝Y) →(X ⇝Y) →(X ⇝Y)
(R ∩S) x y = R x y × S x y
• Unlike a function, which distinguishes between input and output, inherently
a relation treats its domain and codomain symmetrically. This is reﬂected by
the presence of the following converse operator:
◦: {I : Set} {X Y : I →Set} →(X ⇝Y) →(Y ⇝X)
(R ◦) y x = R x y
A relation can thus be “run backwards” simply by taking its converse. The
nondeterministic and bidirectional nature of relations makes them a powerful
and concise language for speciﬁcations, as will be demonstrated in Sections
5.3.2 and 5.3.3.
• We will also need relators, i.e., functorial maps on relations:

5.1
Relational programming in Agda
141
mapRDR : {I : Set} (D : RDesc I) {X Y : I →Set} →
(X ⇝Y) →[[ D ]] X →P([[ D ]] Y)
mapRDR (v [])
R
= return
mapRDR (v (i :: is)) R (x , xs) =
,
⟨$⟩2 (R x) (mapRDR (v is) R xs)
mapRDR (σ S D)
R (s , xs) = ( ,
s) ⟨$⟩(mapRDR (D s) R xs)
R : {I : Set} (D : Desc I) {X Y : I →Set} →(X ⇝Y) →(F D X ⇝F D Y)
R D R {i} = mapRDR (D i) R
Figure 5.1
Deﬁnitions for relators.
R : {I : Set} (D : Desc I) {X Y : I →Set} →
(X ⇝Y) →(F D X ⇝F D Y)
If R : X ⇝Y, the relation R D R : F D X ⇝F D Y applies R to the recursive
positions of its input, leaving everything else intact. The deﬁnition of R is
shown in Figure 5.1. For example, if D = ListD A, then R (ListD A) is, up
to isomorphism,
R (ListD A) : {X Y : I →Set} →
(X ⇝Y) →(F (ListD A) X ⇝F (ListD A) Y)
R (ListD A) R (‘nil
,
) = return (‘nil , )
R (ListD A) R (‘cons , a , x , ) = (λ y 7→‘cons , a , y , ) ⟨$⟩(R x)
Laws and theorems about relational programs are formulated with relational
inclusion:
⊆
: {I : Set} {X Y : I →Set} (X ⇝Y) →(X ⇝Y) →Set
⊆
{I} R S = {i : I} (x : X i) (y : Y i) →R x y →S x y
or equivalence of relations, i.e., two-way inclusion:
≃
: {I : Set} {X Y : I →Set} (R S : X ⇝Y) →Set
R ≃S = (R ⊆S) × (R ⊇S)
where R ⊇S is deﬁned to be S ⊆R as usual. For example, a relator preserves
identity, composition, and converse, i.e.,
R D idR
≃idR

142
5
Relational algebraic ornamentation
R D (R
• S) ≃R D R
• R D S
R D (R ◦)
≃(R D R) ◦
and is monotonic, i.e.,
R D R ⊆R D S
whenever
R ⊆S
Also, many concepts can be expressed in a surprisingly concise way with
relational inclusion. For example, a relation R is a preorder if it is reﬂexive and
transitive. In relational terms, these two conditions are expressed simply as
idR ⊆R
and
R
• R ⊆R
and are easily manipulable in calculations. Another important notion is mono-
tonic algebras [Bird and de Moor, 1997, Section 7.2]: an algebra S : F D X ⇝X
is monotonic on R : X ⇝X (usually an ordering) if
S
• R D R ⊆R
• S
which says that if two input values to S have their recursive positions related
by R and are otherwise equal, then the output values would still be related by R.
(For example, let
D = λ {
7→v ( ::
:: []) } : Desc ⊤
be a trivially indexed description with two recursive positions, and deﬁne
plus = fun (λ { (x , y , ) 7→x + y }) : F D (const Nat) ⇝const Nat
Then plus is monotonic on
leq = λ x y 7→y ⩽x : const Nat ⇝const Nat
which maps a natural number x to any natural number y that is at most x.
Pointwise, the monotonicity statement expands to
(x y x′ y′ : Nat) →(x ⩽x′) × (y ⩽y′) →x + y ⩽x′ + y′
i.e., addition is monotonic on its two arguments.) In the context of optimisation
problems, monotonicity can be used to capture the principle of optimality, as
will be shown in Section 5.3.3. Section 5.3.1 contains some simple relational
calculations involving the above properties.
Having deﬁned relations as nondeterministic mappings, it is straightforward
to rewrite the datatype-generic fold with the subset combinators to obtain a

5.1
Relational programming in Agda
143
mutual
([ ]) : {I : Set} {D : Desc I} {X : I →Set} →(F D X ⇝X) →(µ D ⇝X)
([ ]) {I} {D} R {i} (con ds) = mapFoldR D (D i) R ds >>= R
mapFoldR : {I : Set} (D : Desc I) (D′ : RDesc I) →
{X : I →Set} →(F D X ⇝X) →[[ D′ ]] (µ D) →P([[ D′ ]] X)
mapFoldR D (v [])
R
= return
mapFoldR D (v (i :: is)) R (d , ds) =
,
⟨$⟩2 (([ R ]) d)
(mapFoldR D (v is) f ds)
mapFoldR D (σ S D′)
R (s , ds) = ( ,
s) ⟨$⟩(mapFoldR D (D′ s) f ds)
Figure 5.2
Deﬁnition of relational folds.
relational version, which is denoted by the “banana bracket” [Meijer et al.,
1991]:
([ ]) : {I : Set} {D : Desc I} {X : I →Set} →(F D X ⇝X) →(µ D ⇝X)
The deﬁnition of ([ ]) is shown in Figure 5.2 (cf. the deﬁnition of fold in Fig-
ure 2.1). For example, the relational fold on lists is, up to isomorphism,
([ ]) {⊤} {ListD A} : {X : ⊤→Set} →
(F (ListD A) X ⇝X) →(µ (ListD A) ⇝X)
([ R ]) []
= R (‘nil , )
([ R ]) (a :: as) = ([ R ]) as >>= λ x 7→R (‘cons , a , x , )
The functional and relational fold operators are related by the following lemma:
fun-preserves-fold : {I : Set} (D : Desc I) {X : I →Set} →
(f : F D X ⇒X) {i : I} (d : µ D i) (x : X i) →
fun (fold f) d x ∼= ([ fun f ]) d x
which is a strengthened version of fun (fold f) ≃([ fun f ]).

144
5
Relational algebraic ornamentation
5.2
Deﬁnition of algebraic ornamentation
We now turn to algebraic ornamentation, the key construct that bridges inter-
nalist and relational programming, and look at a special case ﬁrst. Let
R : F (ListD A) (const X) ⇝const X
where
X : Set
be a relational algebra for lists. We can deﬁne a datatype of “algebraically
ornamented lists” as
indexﬁrst data AlgList A R : X →Set where
AlgList A R x ∋nil (rnil : R (‘nil , ) x)
| cons (a : A) (x′ : X) (rcons : R (‘cons , a , x′ , ) x)
(as : AlgList A R x′)
There is an ornament from lists to algebraically ornamented lists which marks
the ﬁelds rnil, x′, and rcons in AlgList as additional and reﬁnes the index of the
recursive position from
to x′. The optimised predicate (Section 3.3.1) for this
ornament is
indexﬁrst data AlgListP A R : X →List A →Set where
AlgListP A R x []
∋nil (rnil : R (‘nil , ) x)
AlgListP A R x (a :: as) ∋cons (x′ : X) (rcons : R (‘cons , a , x′ , ) x)
(p : AlgListP A R x′ as)
A simple argument by induction shows that AlgListP A R x as is in fact iso-
morphic to ([ R ]) as x for any as : List A and x : X — that is, we can do
predicate swapping for the reﬁnement semantics of the ornament from lists
to algebraically ornamented lists (Section 3.3). Thus we get the conversion
isomorphisms
(x : X) →AlgList A R x ∼= Σ[ as : List A ] ([ R ]) as x
(5.1)
That is, an algebraically ornamented list is exactly a plain list and a proof
that the list folds to x using the algebra R. The traditional bottom-up vector
datatype is a special case of AlgList: the datatype AlgList A (fun length-alg),
where length-alg is the algebra for length, is exactly Vec′ A in Section 2.4.1.
By (5.1) we have
(n : Nat) →Vec′ A n ∼= Σ[ as : List A ] ([ fun length-alg ]) as n

5.2
Deﬁnition of algebraic ornamentation
145
algROD : {I : Set} (D : RDesc I) {X : I →Set} →
P ([[ D ]] X) →ROrnDesc (Σ I X) outl D
algROD (v is)
{X} P = ∆[ xs : P is X ] ∆[
: P xs ]
v (P-map (λ {i} x 7→ok (i , x)) is xs)
algROD (σ S D)
P = σ[ s : S ] algROD (D s) (curry P s)
-- curry = λ f x y 7→f (x , y)
algOD : {I : Set} (D : Desc I) {X : I →Set} →
(F D X ⇝X) →OrnDesc (Σ I X) outl D
algOD D R (ok (i , x)) = algROD (D i) ((R ◦) x)
Figure 5.3
Deﬁnitions for algebraic ornamentation.
from which we can further derive
Vec′ A n ∼= Σ[ as : List A ] length as ≡n
by fun-preserves-fold.
The above can be generalised to all datatypes encoded by the Desc universe.
Let D : Desc I be a description and R : F D X ⇝X (where X : I →Set) an
algebra. The algebraic ornamentation of D with R is an ornamental description
algOD D R : OrnDesc (Σ I X) outl D
(where outl : Σ I X →I). The optimised predicate for ⌈algOD D R⌉is pointwise
isomorphic to ([ R ]), i.e.,
(i : I) (x : X i) (d : µ D i) →OptP ⌈algOD D R⌉(ok (i , x)) d ∼= ([ R ]) d x
which is proved by induction on d. These isomorphisms give rise to a swap
family
algOD-FSwap D R : FSwap (RSem ⌈algOD D R⌉)
such that Swap.P (algOD-FSwap D R (ok (i , x))) = λ d 7→([ R ]) d x, so we
arrive at the following conversion isomorphisms
(i : I) (x : X i) →µ ⌊algOD D R⌋(i , x) ∼= Σ[ d : µ D i ] ([ R ]) d x
(5.2)
AlgList is obtained by deﬁning AlgList A R x = µ ⌊algOD (ListD A) R⌋( , x).
The deﬁnition of algOD, shown in Figure 5.3, is an adaptation and generalisation

146
5
Relational algebraic ornamentation
of McBride’s original deﬁnition of functional algebraic ornamentation [2011].
Roughly speaking, it retains (in the σ case of algROD) all the ﬁelds of the basic
description and inserts (in the v case of algROD) before every v
• a new ﬁeld of indices for the recursive positions (e.g., the ﬁeld x′ in AlgList)
and
• another new ﬁeld requesting a proof that
– the indices supplied in the previous ﬁeld and
– the values for the ﬁelds originally in the basic description
compute to the targeted index through R (e.g., the ﬁelds rnil and rcons in
AlgList).
Algebraic ornamentation is a convenient method for adding new indices
to inductive families. (We will see in Chapter 6 that it is actually a canonical
way of reﬁning inductive families by ornamentation.) Most importantly, the
conversion isomorphisms (5.2) state clearly what the new indices mean in terms
of relations. We can thus easily translate relational expressions into internalist
types for type-directed programming, as demonstrated in the next section.
5.3
Examples
We give three examples involving three relational theorems.
• Section 5.3.1 shows how the Fold Fusion Theorem [Bird and de Moor, 1997,
Section 6.2] gives rise to conversion functions between algebraically orna-
mented datatypes.
• Section 5.3.2 implements a relational version of the Streaming Theorem [Bird
and Gibbons, 2003, Theorem 30] as an internalist program, whose type directly
corresponds to the “metamorphic” speciﬁcation stated by the theorem.
• Section 5.3.3 uses the Greedy Theorem [Bird and de Moor, 1997, Theo-
rem 10.1] to nontrivially derive a suitable type for an internalist program that
solves the minimum coin change problem.

5.3
Examples
147
5.3.1
The Fold Fusion Theorem
The statement of the Fold Fusion Theorem [Bird and de Moor, 1997, Section 6.2]
is as follows: Let D : Desc I be a description, R : X ⇝Y a relation, and
S : F D X ⇝X and T : F D Y ⇝Y algebras. If R is a homomorphism from S
to T, i.e.,
R
• S ≃T
• R D R
which is referred to as the fusion condition, then we have
R
• ([ S ]) ≃([ T ])
The above is, in fact, a corollary of two variations of Fold Fusion that replace
relational equivalence in the statement of the theorem with relational inclusion.
One variation is
R
• S ⊆T
• R D R
→
R
• ([ S ]) ⊆([ T ])
(5.3)
and the other variation simply reverses the direction of inclusion:
R
• S ⊇T
• R D R
→
R
• ([ S ]) ⊇([ T ])
(5.4)
Both of them roughly state that one fold can be conditionally transformed
into another. Since algebraically ornamented datatypes are datatypes with
constraints expressed as a fold, we should be able to transform these constraints
by the Fold Fusion Theorem while leaving the underlying data unchanged, thus
converting one algebraically ornamented datatype into another.
We look at (5.3) ﬁrst. Assume that we have a proof of the antecedent
fcond⊆: R
• S ⊆T
• R D R
Expanding the conclusion of (5.3) pointwise: if d : µ D i folds to x : X i
with S, which is “relaxed” to y : Y i by R, then d folds to y with T. This can be
translated to a conversion function from a datatype algebraically ornamented
with S to one with T:
fusion-conversion⊆D R S T fcond⊆:
{i : I} (x : X i) →µ ⌊algOD D S⌋(i , x) →
(y : Y i) →R x y →µ ⌊algOD D T⌋(i , y)

148
5
Relational algebraic ornamentation
new-Σ : (I : Set) {A : Set} {X : I →Set} →
((i : I) →Upgrade A (X i)) →Upgrade A (Σ I X)
new-Σ I u = record { P = λ a 7→Σ[ i : I ] Upgrade.P (u i) a
; C = λ { a (i , x) 7→Upgrade.C (u i) a x
}
; u = λ { a (i , p) 7→i , Upgrade.u (u i) a p }
; c = λ { a (i , p) 7→Upgrade.c (u i) a p
} }
syntax new-Σ I (λ i 7→u) = Σ+[ i : I ] u
×+
: {X Y : Set} →Upgrade X Y →(Z : Set) →Upgrade X (Y × Z)
u ×+ Z = record { P = λ x 7→Upgrade.P u x × Z
; C = λ { x (y , z) 7→Upgrade.C u x y
}
; u = λ { x (p , z) 7→Upgrade.u u x p , z }
; c = λ { x (p , z) 7→Upgrade.c u x p
} }
Figure 5.4
Two additional upgrade combinators.
This function does not alter the underlying (µ D)-data, which can be easily
expressed by upgrading (Section 3.1.2) the identity function on µ D to its type.
We thus write the following upgrade
upg⊆: Upgrade ({i : I} →µ D i →µ D i)
({i : I} {x : X i} →µ ⌊algOD D S⌋(i , x) →
{y : Y i} →R x y →µ ⌊algOD D T⌋(i , y))
upg⊆= ∀[[ i : I ]] ∀+[[ x : X i ]] ref-S i x ⇀
∀+[[ y : Y i ]] ∀+[
: R x y ] toUpgrade (ref-T i y)
where the reﬁnements are deﬁned by
ref-S : (i : I) (x : X i) →Reﬁnement (µ D i) (µ ⌊algOD D S ⌋(i , x))
ref-S i x = toReﬁnement (algOD-FSwap D S (ok (i , x)))
ref-T : (i : I) (y : Y i) →Reﬁnement (µ D i) (µ ⌊algOD D T⌋(i , y))
ref-T i y = toReﬁnement (algOD-FSwap D T (ok (i , y)))
and implement the conversion function by
Upgrade.u upg⊆id { }0
Goal 0 demands a promotion proof of type

5.3
Examples
149
{i : I} {x : X i} (d : µ D i) →([ S ]) d x →{y : Y i} →R x y →([ T ]) (id d) y
which is exactly the pointwise expansion of the conclusion of (5.3). The coher-
ence property
{i : I} {x : X i} (d : µ D i) (d′ : µ ⌊algOD D S⌋(i , x)) →
forget ⌈algOD D S⌉d′ ≡d →
{y : Y i} →R x y →
forget ⌈algOD D T⌉(fusion-conversion⊆D R S T fcond⊆d′) ≡id d
then states that the conversion function transforms the underlying (µ D)-data
in the same way as id, i.e., it leaves the underlying data unchanged. Similarly
for (5.4), assuming that we have
fcond⊇: R
• S ⊇T
• R D R
we should be able to construct the conversion function
fusion-conversion⊇D R S T fcond⊇:
{i : I} (y : Y i) →µ ⌊algOD D T⌋(i , y) →
Σ[ x : X i ] µ ⌊algOD D S⌋(i , x) × R x y
as an upgraded version of the identity function with the upgrade
upg⊇: Upgrade ({i : I} →µ D i →µ D i)
({i : I} {y : Y i} →µ ⌊algOD D T⌋(i , y) →
Σ[ x : X i ] µ ⌊algOD D S⌋(i , x) × R x y)
upg⊇= ∀+[[ i : I ]] ∀+[[ y : Y i ]] ref-T i y ⇀
Σ+[ x : X i ] toUpgrade (ref-S i x) ×+ R x y
in which we need two new combinators to deal with upgrading to product
types, which are deﬁned in Figure 5.4.
For a simple application, suppose that we need a “bounded” vector datatype,
i.e., lists indexed with an upper bound on their length. A quick thought might
lead to this deﬁnition
BVec : Set →Nat →Set
BVec A m = µ ⌊algOD (ListD A) (geq
• fun length-alg)⌋( , m)
where geq = leq ◦: const Nat ⇝const Nat maps a natural number x to any
natural number that is at least x. The conversion isomorphisms (5.2) specialise
for BVec to

150
5
Relational algebraic ornamentation
BVec A m ∼= Σ[ as : List A ] ([ geq
• fun length-alg ]) as m
for all m : Nat. But is BVec really the bounded vectors? Indeed it is, because
we can deduce
geq
• ([ fun length-alg ]) ≃([ geq
• fun length-alg ])
by Fold Fusion. The fusion condition is
geq
• fun length-alg ≃geq
• fun length-alg
• R (ListD A) geq
The left-to-right inclusion is easily calculated as follows:
geq
• fun length-alg
⊆
{ identity }
geq
• fun length-alg
• idR
⊆
{ relator preserves identity }
geq
• fun length-alg
• R (ListD A) idR
⊆
{ geq reﬂexive; relator is monotonic }
geq
• fun length-alg
• R (ListD A) geq
And from right to left:
geq
• fun length-alg
• R (ListD A) geq
⊆
{ fun length-alg monotonic on geq }
geq
• geq
• fun length-alg
⊆
{ geq transitive }
geq
• fun length-alg
Note that these calculations are good illustrations of the power of relational
calculation because of their simplicity — they are straightforward symbol
manipulations, hiding details like quantiﬁer reasoning behind the scenes. As
demonstrated by the AoPA library [Mu et al., 2009], they can be faithfully
formalised with preorder reasoning combinators in Agda and used to discharge
the fusion conditions of fusion-conversion⊆and fusion-conversion⊇. Hence we
get two conversions, one of type
Vec A n →(n ⩽m) →BVec A m
which relaxes a vector of length n to a bounded vector whose length is bounded
above by some m that is at least n, and the other of type

5.3
Examples
151
BVec A m →Σ[ n : Nat ] Vec A n × (n ⩽m)
which converts a bounded vector whose length is at most m to a vector of length
precisely n and guarantees that n is at most m. Both conversions preserve the
underlying list by construction.
5.3.2
The Streaming Theorem for list metamorphisms
A metamorphism [Gibbons, 2007b] is an unfold after a fold — it consumes a
data structure to compute an intermediate value and then produces a new data
structure using the intermediate value as the seed. In this section we will restrict
ourselves to metamorphisms consuming and producing lists. As Gibbons noted,
(list) metamorphisms in general cannot be automatically optimised in terms
of time and space, but under certain conditions it is possible to reﬁne a list
metamorphism to a streaming algorithm — which can produce an initial
segment of the output list without consuming all of the input list — or a parallel
algorithm [Nakano, 2013]. In the rest of this section, we prove a relational
version of the Streaming Theorem [Bird and Gibbons, 2003, Theorem 30] by
implementing the streaming algorithm given by the theorem with algebraically
ornamented lists such that the algorithm satisﬁes its metamorphic speciﬁcation
by construction.
Our ﬁrst step is to formulate a metamorphism as a relational speciﬁcation
of the streaming algorithm.
• The fold part needs a twist since using the conventional fold — known as the
right fold for lists since the direction of computation on a list is from right to
left (cf. wind direction) — does not easily give rise to a streaming algorithm.
This is because we wish to talk about “partial consumption” naturally: for
a list, partial consumption means examining and removing some elements
of the list to get a sub-list on which we can resume consumption, and the
natural way to do this is to consume the list from the left, examining and
removing head elements and keeping the tail. We should thus use the left
fold instead, which is usually deﬁned as
foldl : {A X : Set} →(X →A →X) →X →List A →X

152
5
Relational algebraic ornamentation
foldl f x []
= x
foldl f x (a :: as) = foldl f (f x a) as
The connection to the conventional fold (and thus algebraic ornamentation)
is not lost, however — it is well known that a left fold can be alternatively
implemented as a right fold by turning a list into a chain of functions of type
X →X transforming the initial value to the ﬁnal result:
foldl-alg : {A X : Set} →(X →A →X) →
F (ListD A) (const (X →X)) ⇒const (X →X)
foldl-alg f (‘nil
,
) = id
foldl-alg f (‘cons , a , h , ) = h ◦ﬂip f a
foldl : {A X : Set} →(X →A →X) →X →List A →X
foldl f x as = fold (foldl-alg f) as x
The left fold can thus be linked to the relational fold by
fun (foldl f x) ≃fun (λ h 7→h x)
• ([ fun (foldl-alg f) ])
(5.5)
• For the unfold part, a relational unfold is exactly the converse of a fold. Given
a functional list coalgebra g : const X ⇒F (ListD B) (const X) for some
X : Set, we take its converse, turning it into a relational algebra, and use the
converse of the relational fold with this algebra.
([ fun g ◦]) ◦: const X ⇝const (List A)
Note that a relational unfold (conceptually) produces inductive lists rather
than coinductive ones.
Thus, given a “left algebra” for consuming List A
f : X →A →X
and a coalgebra for producing List B
g : const X ⇒F (ListD B) (const X)
which together satisfy a streaming condition that we will see later, the stream-
ing algorithm we implement, which takes as input the initial value x : X for
the left fold, should be included in the following metamorphic relation:
meta f g x = ([ fun g ◦]) ◦
• fun (foldl f x) : const (List A) ⇝const (List B)

5.3
Examples
153
Next we devise a type for the streaming algorithm that fully guarantees its
correctness. By (5.5), the speciﬁcation meta f g x is equivalent to
([ fun g ◦]) ◦
• fun (λ h 7→h x)
• ([ fun (foldl-alg f) ])
Inspecting the above relation, we see that a conforming program takes a List A
that folds to some h : X →X with fun (foldl-alg f) and unfolds a List B from
h x : X with fun g (i.e., computes a List B that folds to h x with fun g ◦). We thus
implement the streaming algorithm by
stream f g : (x : X) {h : X →X} →
AlgList A (fun (foldl-alg f)) h →AlgList B (fun g ◦) (h x)
from which we can extract
stream′ f g : X →List A →List B
which is guaranteed to satisfy
fun (stream′ f g x) ⊆meta f g x
The extraction of stream′ f g from stream f g is done with the help of the
conversion isomorphisms (5.2) for the two AlgList datatypes involved:
consumption-iso :
(h : X →X) →
AlgList A (fun (foldl-alg f)) h ∼= Σ[ as : List A ] fold (foldl-alg f) as ≡h
production-iso :
(x : X) →AlgList B (fun g ◦) x ∼= Σ[ bs : List B ] ([ fun g ◦]) bs x
(where consumption-iso has been simpliﬁed by fun-preserves-fold). Given x : X,
what stream′ f g x does is
• lifting the input as : List A to an algebraically ornamented list of type
AlgList A (fun (foldl-alg f)) (fold (foldl-alg f) as)
using the right-to-left direction of consumption-iso (fold (foldl-alg f) as) (with
the equality proof obligation discharged trivially by reﬂ),
• transforming this algebraically ornamented list to a new one of type
AlgList B (fun g ◦) (foldl f x as)
using stream f g x, and

154
5
Relational algebraic ornamentation
• demoting the new algebraically ornamented list to List B using the left-to-right
direction of production-iso (foldl f x as).
The use of production-iso in the last step ensures that the result stream′ f g x as :
List B satisﬁes
([ fun g ◦]) (stream′ f g x as) (foldl f x as)
which easily implies
(([ fun g ◦]) ◦
• fun (foldl f x)) as (stream′ f g x as)
i.e., fun (stream′ f g x) ⊆meta f g x, as required.
What is left is the implementation of stream f g. Operationally, we maintain
a state of type X (and hence require an initial state as an input to the function),
and we can try either
• to update the state by consuming elements of A with f, or
• to produce elements of B (and transit to a new state) by applying g to the
state.
Since we want stream f g to be as productive as possible, we should always try
to produce elements of B with g ﬁrst, and only try to consume elements of A
with f when g produces nothing. In Agda:
stream f g : (x : X) {h : X →X} →
AlgList A (fun (foldl-alg f)) h →AlgList B (fun g ◦) (h x)
stream f g x
as
with g x
| inspect g x
stream f g x {h} as
| next b x′ | [ gxeq ] = cons b (h x′) { }0
(stream f g x′ as)
stream f g x
(nil
reﬂ
) | nothing
| [ gxeq ] = nil gxeq
stream f g x
(cons a h′ reﬂas) | nothing
| [ gxeq ] = stream f g (f x a) as
We match g x with either of the two patterns next b x′ = (‘cons , b , x′ , ) and
nothing = (‘nil , ).
• If the result is next b x′, we should emit b and use x′ as the new state; the
recursively computed algebraically ornamented list is indexed with h x′, and
we are left with a proof obligation of type g (h x) ≡next b (h x′) at Goal 0;
we will come back to this proof obligation later.
• If the result is nothing, we should attempt to consume from the input list.

5.3
Examples
155
x
x′
h x
h x′
consume as with h
consume as with h
produce b with g
produce b with g
Figure 5.5
State transitions involved in commutativity of production and consumption
(cf. Gibbons [2007b, Figures 1 and 2]).
– If the input list is empty, implying that the index h of its type is just id, both
production and consumption have ended, so we return an empty list. The
nil constructor requires a proof of (fun g ◦) nothing (h x), which reduces
to g x ≡nothing and is discharged with the help of the “inspect idiom”
in Agda’s standard library (which, in a with-matching, gives a proof that
the term being matched (in this case g x) is propositionally equal to the
matched pattern (in this case nothing)).
– Otherwise the input list is nonempty, implying that h is h′ ◦ﬂip f a where
a is the head of the input list, and we should continue with the new state
f x a, keeping the tail for further consumption. Typing directly works out
because the index of the recursive result h′ (f x a) and the required index
(h′ ◦ﬂip f a) x are deﬁnitionally equal.
Now we look at Goal 0. We have
gxeq : g x ≡next b x′
in the context, and need to prove
g (h x) ≡next b (h x′)
This is commutativity of production and consumption (see Figure 5.5): The
function h : X →X is the state transformation resulting from consumption of
the input list as. From the initial state x, we can either
• apply g to x to produce b and reach a new state x′, and then apply h to
consume the list and update the state to h x′, or

156
5
Relational algebraic ornamentation
• apply h to consume the list and update the state to h x, and then apply g
to h x to produce an element and reach a new state,
and we need to prove that the outcomes are the same: doing production using g
and consumption using h in whichever order should emit the same element
and reach the same ﬁnal state. This cannot be true in general, so we should
impose some commutativity condition on f and g, which is called the streaming
condition:
StreamingCondition f g : Set
StreamingCondition f g =
(a : A) (b : B) (x x′ : X) →g x ≡next b x′ →g (f x a) ≡next b (f x′ a)
The streaming condition is commutativity of one step of production and con-
sumption, whereas the proof obligation at Goal 0 is commutativity of one step
of production and multiple steps of consumption (of the entire list), so we
perform a straightforward induction to extend the streaming condition along
the axis of consumption:
streaming-lemma :
(b : B) (x x′ : X) →g x ≡next b x′ →
{h : X →X} →AlgList A (fun (foldl-alg f)) h →g (h x) ≡next b (h x′)
streaming-lemma b x x′ eq (nil
reﬂ
) = eq
streaming-lemma b x x′ eq (cons a h reﬂas) =
streaming-lemma b (f x a) (f x′ a) (streaming-condition f g a b x x′ eq) as
where streaming-condition : StreamingCondition f g is a proof term that should
be supplied along with f and g in the beginning. Goal 0 is then discharged by
the term streaming-lemma b x x′ gxeq as.
We have thus completed the implementation of the Streaming Theorem,
except that stream f g is non-terminating, as there is no guarantee that g produces
only a ﬁnite number of elements. In our relational setting, where the output list
is speciﬁed to be ﬁnite, we can additionally require that g is well-founded and
revise stream accordingly (see, e.g., Nordström [1988]). The general way out is
to switch to a different setting incorporating coinductive datatypes, allowing
the output list to be inﬁnite. This, however, falls outside the scope of this
dissertation.

5.3
Examples
157
Remark (coinductive datatypes).
While coinductive families are outside the
scope of this dissertation, it is conceivable that the ornament framework can be
easily adapted to coinductive families, since ornaments operate at the functor
level, independently from the least/greatest ﬁxed-point datatype manufacturing
mechanism.
□
It is interesting to compare our implementation with the proofs of Bird and
Gibbons [2003]. While their Lemma 29 turns explicitly into our streaming-lemma,
their Theorem 30 goes implicitly into the typing of stream and no longer needs
special attention. The structure of stream already matches that of Bird and
Gibbons’s proof of their Theorem 30, and the principled type design using
algebraic ornamentation elegantly loads the proof onto the structure of stream —
this is internalism at its best.
5.3.3
The Greedy Theorem and the minimum coin change prob-
lem
Suppose that we have an unlimited number of 1-penny, 2-pence, and 5-pence
coins, modelled by the following datatype:
data Coin : Set where
1p : Coin
2p : Coin
5p : Coin
The minimum coin change problem asks for the least number of coins that
make up n pence for any given n : Nat. We can give a relational speciﬁcation
of the problem with the following minimisation operator:
min
• Λ
: {I : Set} {X Y : I →Set} (R : Y ⇝Y) (S : X ⇝Y) →(X ⇝Y)
min
• Λ
{Y := Y} R S {i} x y = S x y × ((y′ : Y i) →S x y′ →R y′ y)
An input x : X i for some i : I is mapped by min R
• Λ S to y : Y i if y is a
possible result in S x : P(Y i) and is the smallest such result under R, in the
sense that any y′ in S x : P(Y i) must satisfy R y′ y. (We think of R as mapping
larger inputs to smaller outputs.) Intuitively, we can think of min R
• Λ S
as consisting of two steps: the ﬁrst step Λ S computes the set of all possible

158
5
Relational algebraic ornamentation
results yielded by S, and the second step min R nondeterministically chooses a
minimum result from that set. We use bags of coins as the type of solutions,
and represent them as decreasingly ordered lists indexed with an upper bound.
(This is a deliberate choice to make the derivation work, but one would naturally
be led to this representation having attempted to apply the Greedy Theorem,
which will be introduced shortly.) If we deﬁne the ordering on coins as
⩽C
: Coin →Coin →Set
c ⩽C d = value c ⩽value d
where the values of the coins are deﬁned by
value : Coin →Nat
value 1p = 1
value 2p = 2
value 5p = 5
then the datatype of coin bags we use is
CoinBagOD : OrnDesc Coin ! (ListD Coin)
CoinBagOD = OrdListOD Coin (ﬂip
⩽C )
-- specialising Val to Coin and
⩽to ﬂip
⩽C
indexﬁrst data CoinBag : Coin →Set where
CoinBag c ∋nil
| cons (d : Coin) (leq : d ⩽C c) (b : CoinBag d)
The total value of a coin bag is the sum of the values of the coins in the bag,
which is computed by a (functional) fold:
total-value-alg : F ⌊CoinBagOD⌋(const Nat) ⇒const Nat
total-value-alg (‘nil
,
) = 0
total-value-alg (‘cons , d ,
, n , ) = value d + n
total-value : CoinBag ⇒const Nat
total-value = fold total-value-alg
and the number of coins in a coin bag is computed by an ornamental forgetful
function shrinking ordered lists to natural numbers:
size-alg : F ⌊CoinBagOD⌋(const Nat) ⇒const Nat
size-alg = ornAlg (NatD-ListD Coin ⊙⌈CoinBagOD⌉)

5.3
Examples
159
size : CoinBag ⇒const Nat
size = fold size-alg
-- which is deﬁnitionally forget (NatD-ListD Coin ⊙⌈CoinBagOD⌉)
The speciﬁcation of the minimum coin change problem can now be written as
min-coin-change : const Nat ⇝CoinBag
min-coin-change = min (fun size ◦
• leq
• fun size)
• Λ (fun total-value ◦)
Intuitively, given an input n : Nat, the relation fun total-value ◦computes an arbi-
trary coin bag whose total value is n, so min-coin-change ﬁrst computes the set of
all such coin bags and then chooses from the set a coin bag whose size is small-
est. Our goal, then, is to write a functional program f : const Nat ⇒CoinBag
such that fun f ⊆min-coin-change, and then f {5p} : Nat →CoinBag 5p would
be a solution. (The type CoinBag 5p contains all coin bags, since 5p is the largest
denomination and hence a trivial upper bound on the content of bags.) Of
course, we may guess what f should look like, but its correctness proof is much
harder. Can we construct the program and its correctness proof in a more
manageable way?
The plan
In traditional relational program derivation [Bird and de Moor, 1997], we would
attempt to reﬁne the speciﬁcation min-coin-change to some simpler relational
program and then to an executable functional program by applying algebraic
laws and theorems. With algebraic ornamentation, however, there is a new
possibility: if, for some algebra R : F ⌊CoinBagOD⌋(const Nat) ⇝const Nat,
we can derive
([ R ]) ◦⊆min-coin-change
(5.6)
then we can manufacture a new datatype
GreedyBagOD : OrnDesc (Coin × Nat) outl ⌊CoinBagOD⌋
GreedyBagOD = algOD ⌊CoinBagOD⌋R
GreedyBag : Coin →Nat →Set
GreedyBag c n = µ ⌊GreedyBagOD⌋(c , n)

160
5
Relational algebraic ornamentation
and construct a function of type
greedy : (c : Coin) (n : Nat) →GreedyBag c n
from which we can assemble a solution
sol : Nat →CoinBag 5p
sol = forget ⌈GreedyBagOD⌉◦greedy 5p
The program sol satisﬁes the speciﬁcation because of the following argument:
For any c : Coin and n : Nat, by (5.2) we have
GreedyBag c n ∼= Σ[ b : CoinBag c ] ([ R ]) b n
In particular, since the ﬁrst half of the left-to-right direction of the isomorphism
is forget ⌈GreedyBagOD⌉, we have
([ R ]) (forget ⌈GreedyBagOD⌉g) n
for any g : GreedyBag c n. Substituting g by greedy 5p n, we get
([ R ]) (sol n) n
which implies, by (5.6),
min-coin-change n (sol n)
i.e., sol satisﬁes the speciﬁcation. Thus all we need to do to solve the minimum
coin change problem is
• reﬁne the speciﬁcation min-coin-change to the converse of a fold, i.e., ﬁnd the
algebra R in (5.6), and
• construct the internalist program greedy.
Reﬁning the speciﬁcation
The key to reﬁning min-coin-change to the converse of a fold lies in the following
version of the Greedy Theorem, which is a specialisation of Bird and de Moor’s
Theorem 10.1 modulo indexing: Let D : Desc I be a description, R : µ D ⇝µ D
a preorder, and S : F D X ⇝X an algebra. Consider the speciﬁcation
min R
• Λ (([ S ]) ◦)

5.3
Examples
161
That is, given an input value x : X i for some i : I, we choose a minimum
under R among all those elements of µ D i that computes to x through ([ S ]).
The Greedy Theorem states that, if the initial algebra
α = fun con : F D (µ D) ⇝µ D
is monotonic on R, i.e.,
α
• R D R ⊆R
• α
and there is a relation (ordering) Q : F D X ⇝F D X such that the greedy
condition
α
• R D (([ S ]) ◦)
• (Q ∩(S ◦
• S)) ◦⊆R ◦
• α
• R D (([ S ]) ◦)
is satisﬁed, then we have
([ (min Q
• Λ (S ◦)) ◦]) ◦⊆min R
• Λ (([ S ]) ◦)
The Greedy Theorem essentially reduces a global optimisation problem (as
indicated by the outermost min R) to a local optimisation problem (as indicated
by the min Q inside the relational fold). The theorem admits an elegant calcula-
tional proof, which can be faithfully reprised in Agda. Here we offer an intuitive
explanation: The monotonicity condition states that if ds : F D (µ D) i for some
i : I is better than ds′ : F D (µ D) i under R D R, i.e., ds and ds′ are equal except
that the recursive positions of ds are all better than the corresponding recursive
positions of ds′ under R, then con ds : µ D i would be better than con ds′ : µ D i
under R. This implies that, when solving the optimisation problem, better solu-
tions to sub-problems would lead to a better solution to the original problem, so
the principle of optimality applies — to reach an optimal solution, it sufﬁces to
ﬁnd optimal solutions to sub-problems, and we are entitled to use the converse
of a fold to ﬁnd optimal solutions recursively. The greedy condition further
states that there is an ordering Q on the ways of decomposing the problem
that has signiﬁcant inﬂuence on the quality of solutions: Suppose that there are
two decompositions xs and xs′ : F D X i of some problem x : X i for some
i : I, i.e., both xs and xs′ are in (S ◦) x : P(F D X i), and assume that xs is
better than xs′ under Q. Then for any solution resulting from xs′ (computed
by α
• R D (([ S ]) ◦)) there always exists a better solution resulting from xs, so
ignoring xs′ would only rule out worse solutions. The greedy condition thus

162
5
Relational algebraic ornamentation
guarantees that we will arrive at an optimal solution by always choosing the
best decomposition, which is done by min Q
• Λ (S ◦) : X ⇝F D X.
Back to the minimum coin change problem. By fun-preserves-fold, the speciﬁ-
cation min-coin-change is equivalent to
min (fun size ◦
• leq
• fun size)
• Λ (([ fun total-value-alg ]) ◦)
which matches the form of the generic speciﬁcation given in the Greedy Theo-
rem, so we try to discharge the two conditions of the theorem. The monotonicity
condition reduces to monotonicity of fun size-alg on leq, and can be easily proved
either by relational calculation or pointwise reasoning. As for the greedy condi-
tion, an obvious choice for Q is an ordering that leads us to choose the largest
possible denomination, so we go for
Q : F ⌊CoinBagOD⌋(const Nat) ⇝F ⌊CoinBagOD⌋(const Nat)
Q (‘nil
,
) = return (‘nil , )
Q (‘cons , d ,
) = (λ e rest 7→‘cons , e , rest) ⟨$⟩2 ( ⩽C
d) any
where, in the cons case, the output is required to be also a cons node, and
the coin at its head position must be one that is no smaller than the coin d at
the head position of the input. It is nontrivial to prove the greedy condition
by relational calculation. Here we offer instead a brute-force yet conveniently
expressed case analysis by pattern matching. Deﬁne a new datatype CoinBag′
by composing two algebraic ornaments on ⌊CoinBagOD⌋in parallel:
CoinBag′OD : OrnDesc (outl ▷◁outl) pull ⌊CoinBagOD⌋
CoinBag′OD = ⌈algOD ⌊CoinBagOD⌋(fun total-value-alg)⌉⊗
⌈algOD ⌊CoinBagOD⌋(fun size-alg)⌉
CoinBag′ : Coin →Nat →Nat →Set
CoinBag′ c n l = µ ⌊CoinBag′OD⌋(ok (c , n) , ok (c , l))
whose two constructors can be specialised to
bnil
: {c : Coin} →CoinBag′ c 0 0
bcons : {c : Coin} {n l : Nat} →(d : Coin) →d ⩽C c →
CoinBag′ d n l →CoinBag′ c (value d + n) (1 + l)
By predicate swapping using the modularity isomorphisms (Section 3.3.2) and

5.3
Examples
163
data CoinOrderedView : Coin →Coin →Set where
1p1p
: CoinOrderedView 1p 1p
1p2p
: CoinOrderedView 1p 2p
1p5p
: CoinOrderedView 1p 5p
2p2p
: CoinOrderedView 2p 2p
2p5p
: CoinOrderedView 2p 5p
5p5p
: CoinOrderedView 5p 5p
view-ordered-coin : (c d : Coin) →c ⩽C d →CoinOrderedView c d
data CoinBag′View : {c : Coin} {n : Nat} {l : Nat} →CoinBag′ c n l →Set where
empty : {c : Coin} →CoinBag′View {c} {0} {0} bnil
1p1p
: {m l : Nat} {lep : 1p ⩽C 1p}
(b : CoinBag′ 1p m l) →CoinBag′View {1p} {1 + m} {1 + l} (bcons 1p lep b)
1p2p
: {m l : Nat} {lep : 1p ⩽C 2p}
(b : CoinBag′ 1p m l) →CoinBag′View {2p} {1 + m} {1 + l} (bcons 1p lep b)
2p2p
: {m l : Nat} {lep : 2p ⩽C 2p}
(b : CoinBag′ 2p m l) →CoinBag′View {2p} {2 + m} {1 + l} (bcons 2p lep b)
1p5p
: {m l : Nat} {lep : 1p ⩽C 5p}
(b : CoinBag′ 1p m l) →CoinBag′View {5p} {1 + m} {1 + l} (bcons 1p lep b)
2p5p
: {m l : Nat} {lep : 2p ⩽C 5p}
(b : CoinBag′ 2p m l) →CoinBag′View {5p} {2 + m} {1 + l} (bcons 2p lep b)
5p5p
: {m l : Nat} {lep : 5p ⩽C 5p}
(b : CoinBag′ 5p m l) →CoinBag′View {5p} {5 + m} {1 + l} (bcons 5p lep b)
view-CoinBag′ : {c : Coin} {n l : Nat} (b : CoinBag′ c n l) →CoinBag′View b
Figure 5.6
Two views for proving greedy-lemma.

164
5
Relational algebraic ornamentation
greedy-lemma : (c d : Coin) →c ⩽C d →(m n : Nat) →value c + m ≡value d + n →
(l : Nat) (b : CoinBag′ c m l) →Σ[ l′ : Nat ] CoinBag′ d n l′ × (l′ ⩽l)
greedy-lemma c
d c⩽d m
n
eq
l
b with view-ordered-coin c d c⩽d
greedy-lemma .1p .1p
.n
n
reﬂl
b CoinBag′ 1p n l | 1p1p = { Σ[ l′ : Nat ] CoinBag′ 1p n l′ × (l′ ⩽l) }0
greedy-lemma .1p .2p
.(1 + n) n
reﬂl
b | 1p2p with view-CoinBag′ b
greedy-lemma .1p .2p
.(1 + n) n
reﬂ.(1 + l′′) .
| 1p2p | 1p1p {.n} {l′′} b CoinBag′ 1p n l′′ =
{ Σ[ l′ : Nat ] CoinBag′ 2p n l′ × (l′ ⩽1 + l′′) }1
greedy-lemma .1p .5p
.(4 + n) n
reﬂl
b | 1p5p with view-CoinBag′ b
greedy-lemma .1p .5p
.(4 + n) n
reﬂ.
.
| 1p5p | 1p1p b with view-CoinBag′ b
greedy-lemma .1p .5p
.(4 + n) n
reﬂ.
.
| 1p5p | 1p1p .
| 1p1p b with view-CoinBag′ b
greedy-lemma .1p .5p
.(4 + n) n
reﬂ.
.
| 1p5p | 1p1p .
| 1p1p .
| 1p1p b with view-CoinBag′ b
greedy-lemma .1p .5p
.(4 + n) n
reﬂ.(4 + l′′) .
| 1p5p | 1p1p .
| 1p1p .
| 1p1p .
| 1p1p {.n} {l′′} b CoinBag′ 1p n l′′ =
{ Σ[ l′ : Nat ] CoinBag′ 5p n l′ × (l′ ⩽4 + l′′) }2
greedy-lemma .2p .2p
.n
n
reﬂl
b CoinBag′ 2p n l | 2p2p = { Σ[ l′ : Nat ] CoinBag′ 2p n l′ × (l′ ⩽l) }3
greedy-lemma .2p .5p
.(3 + n) n
reﬂl
b | 2p5p with view-CoinBag′ b
greedy-lemma .2p .5p
.(3 + n) n
reﬂ.
.
| 2p5p | 1p2p b with view-CoinBag′ b
greedy-lemma .2p .5p
.(3 + n) n
reﬂ.
.
| 2p5p | 1p2p .
| 1p1p b with view-CoinBag′ b
greedy-lemma .2p .5p
.(3 + n) n
reﬂ.(3 + l′′) .
| 2p5p | 1p2p .
| 1p1p .
| 1p1p {.n} {l′′} b CoinBag′ 1p n l′′ =
{ Σ[ l′ : Nat ] CoinBag′ 5p n l′ × (l′ ⩽3 + l′′) }4
greedy-lemma .2p .5p
.(3 + n) n
reﬂ.
.
| 2p5p | 2p2p b with view-CoinBag′ b
greedy-lemma .2p .5p
.(3 + n) n
reﬂ.(2 + l′′) .
| 2p5p | 2p2p .
| 1p2p {.n} {l′′} b CoinBag′ 2p n l′′ =
{ Σ[ l′ : Nat ] CoinBag′ 5p n l′ × (l′ ⩽2 + l′′) }5
greedy-lemma .2p .5p
.(4 + k) .(1 + k) reﬂ.(2 + l′′) .
| 2p5p | 2p2p .
| 2p2p {k} {l′′} b CoinBag′ 2p k l′′ =
{ Σ[ l′ : Nat ] CoinBag′ 5p (1 + k) l′ × (l′ ⩽2 + l′′) }6
greedy-lemma .5p .5p
.n
n
reﬂl
b CoinBag′ 5p n l | 5p5p = { Σ[ l′ : Nat ] CoinBag′ 5p n l′ × (l′ ⩽l) }7
Figure 5.7
Cases of greedy-lemma, generated semi-automatically by Agda’s interactive case-split mechanism. Goal types
are shown in the interaction points, and the types of some pattern variables are shown in subscript beside them.

5.3
Examples
165
fun-preserves-fold, CoinBag′ is characterised by the isomorphisms
CoinBag′ c n l ∼= Σ[ b : CoinBag c ] (total-value b ≡n) × (size b ≡l)
(5.7)
for all c : Coin, n : Nat, and l : Nat. Hence a coin bag of type CoinBag′ c n l
contains l coins that are no larger than c and sum up to n pence. The greedy
condition then essentially reduces to this lemma:
greedy-lemma : (c d : Coin) →c ⩽C d →
(m n : Nat) →value c + m ≡value d + n →
(l : Nat) (b : CoinBag′ c m l) →
Σ[ l′ : Nat ] CoinBag′ d n l′ × (l′ ⩽l)
That is, given a problem (i.e., a value to be represented by coins), if c : Coin is a
choice of decomposition (i.e., the ﬁrst coin used) no better than d : Coin (i.e.,
c ⩽C d — recall that we prefer larger denominations), and b : CoinBag′ c m l is a
solution of size l to the remaining sub-problem m resulting from choosing c, then
there is a solution to the remaining sub-problem n resulting from choosing d
whose size l′ is no greater than l. We deﬁne two views (Section 2.2.2) to aid the
analysis, whose datatypes and covering functions are shown in Figure 5.6:
• the ﬁrst view analyses a proof of c ⩽C d and exhausts all possibilities of
c and d, and
• the second view analyses some b : CoinBag′ c n l and exhausts all possibilities
of c, n, l, and the ﬁrst coin in b (if any).
The function greedy-lemma can then be split into eight cases by ﬁrst exhausting
all possibilities of c and d by the ﬁrst view and then analysing the content
of b by the second view. Figure 5.7 shows the case-split tree generated semi-
automatically by Agda; the detail is explained as follows:
• At Goal 0 (and similarly Goals 3 and 7), the input bag is b : CoinBag′ 1p n l,
and we should produce a CoinBag′ 1p n l′ for some l′ : Nat such that l′ ⩽l.
This is easy because b itself is a suitable bag.
• At Goal 1 (and similarly Goals 2, 4, and 5), the input bag has type
CoinBag′ 1p (1 + n) l, i.e., the coins in the bag are no larger than 1p and the
total value is 1 + n. The bag must contain 1p as its ﬁrst coin; let the rest of
the bag be b : CoinBag′ 1p n l′′. At this point Agda can deduce that l must be
1 + l′′. Now we can return b as the result after the upper bound on its coins

166
5
Relational algebraic ornamentation
is relaxed from 1p to 2p, which is done by
cb′-relax :
{c d : Coin} {n l : Nat} →c ⩽C d →CoinBag′ c n l →CoinBag′ d n l
• The remaining Goal 6 is the most interesting one: The input bag has type
CoinBag′ 2p (3 + n) l, which in this case contains two 2-pence coins, and the
rest of the bag is b : CoinBag′ 2p k l′′. Agda deduces that n must be 1 + k
and l must be 2 + l′′. We thus need to add a penny to b to increase its total
value to 1 + k, which is done by
add-penny :
{c : Coin} {n l : Nat} →CoinBag′ c n l →CoinBag′ c (1 + n) (1 + l)
and relax the bound of add-penny b from 2p to 5p.
The above case analysis may look tedious, but Agda is able to
• produce all the cases (modulo some cosmetic revisions) after the program-
mer decides to use the two views and instructs Agda to do case splitting
accordingly, and
• manage all the bookkeeping and deductions about the total value and the
size of bags with dependent pattern matching,
so the overhead on the programmer’s side is actually less than it seems. The
greedy condition can now be discharged by pointwise reasoning, using (5.7) to
interface with greedy-lemma. We conclude that the Greedy Theorem is applicable,
and obtain
([ (min Q
• Λ (fun total-value-alg ◦)) ◦]) ◦⊆min-coin-change
We have thus found the algebra
R = (min Q
• Λ (fun total-value-alg ◦)) ◦
which will help us to construct the ﬁnal internalist program.
Constructing the internalist program
As planned, we synthesise a new datatype by ornamenting CoinBag using the
algebra R derived above:

5.3
Examples
167
GreedyBagOD : OrnDesc (Coin × Nat) outl ⌊CoinBagOD⌋
GreedyBagOD = algOD ⌊CoinBagOD⌋R
GreedyBag : Coin →Nat →Set
GreedyBag c n = µ ⌊GreedyBagOD⌋(c , n)
whose two constructors can be given the following types:
gnil
: {c : Coin} {n : Nat} →
total-value-alg (‘nil , ) ≡n →
((ns : F ⌊CoinBagOD⌋(const Nat)) →
total-value-alg ns ≡n →Q ns (‘nil , )) →
GreedyBag c n
gcons : {c : Coin} {n : Nat} (d : Coin) (d⩽c : d ⩽C c) →
{n′ : Nat} →total-value-alg (‘cons , d , d⩽c , n′ , ) ≡n →
((ns : F ⌊CoinBagOD⌋(const Nat)) →
total-value-alg ns ≡n →Q ns (‘cons , d , d⩽c , n′ , )) →
GreedyBag d n′ →GreedyBag c n
and implement the greedy algorithm by
greedy : (c : Coin) (n : Nat) →GreedyBag c n
Let us ﬁrst simplify the two constructors of GreedyBag. Each of the two con-
structors has two additional proof obligations coming from the algebra R:
• For gnil,
– the ﬁrst obligation total-value-alg (‘nil ,
) ≡n reduces to 0 ≡n, so we
may discharge the obligation by specialising n to 0;
– for the second obligation, ns is necessarily (‘nil , ) if total-value-alg ns ≡0,
and indeed Q maps (‘nil , ) to (‘nil , ), so the second obligation can be
discharged as well.
We thus obtain a simpliﬁed version of gnil:
gnil′ : {c : Coin} →GreedyBag c 0
• For gcons,
– the ﬁrst obligation reduces to value d + n′ ≡n, so we may just specialise n
to value d + n′ and discharge the obligation;

168
5
Relational algebraic ornamentation
– for the second obligation, any ns satisfying total-value-alg ns ≡value d + n′
must be of the form (‘cons , e , e⩽c , m′ , ) for some e : Coin, e⩽c : e ⩽C c,
and m′ : Nat since the right-hand side value d + n′ of the equality is
non-zero, and Q maps ns to (‘cons , d , d⩽c , n′ , ) if e ⩽C d, so d should be
the largest “usable” coin if this obligation is to be discharged. We say that
d : Coin is usable with respect to some c : Coin and n : Nat if d is bounded
above by c and can be part of a solution to the problem for n pence:
UsableCoin : Nat →Coin →Coin →Set
UsableCoin n c d = (d ⩽C c) × (Σ[ n′ : Nat ] value d + n′ ≡n)
The obligation can then be rewritten as
(e : Coin) →UsableCoin (value d + n′) c e →e ⩽C d
which requires that d is the largest usable coin with respect to c and
value d + n′.
This obligation is the only one that cannot be trivially
discharged, since it requires computation of the largest usable coin.
We thus specialise gcons to
gcons′ : {c : Coin} (d : Coin) →d ⩽C c →
{n′ : Nat} →
((e : Coin) →UsableCoin (value d + n′) c e →e ⩽C d) →
GreedyBag d n′ →GreedyBag c (value d + n′)
Because of gcons′, we are directed to implement a function maximum-coin that
computes the largest usable coin with respect to any c : Coin and non-zero
n : Nat:
maximum-coin :
(c : Coin) (n : Nat) →n > 0 →
Σ[ d : Coin ] UsableCoin n c d × ((e : Coin) →UsableCoin n c e →e ⩽C d)
This takes some theorem proving but is overall a typical Agda exercise in
dealing with natural numbers and ordering. Finally, the greedy algorithm
is implemented as the following internalist program, which repeatedly uses
maximum-coin to ﬁnd the largest usable coin and unfolds a GreedyBag:
greedy : (c : Coin) (n : Nat) →GreedyBag c n
greedy c n = <-rec P f n c

5.4
Discussion
169
where
P : Nat →Set
P n = (c : Coin) →GreedyBag c n
f : (n : Nat) →((n′ : Nat) →n′ < n →P n′) →P n
f n
rec c with compare-with-zero n
f .0
rec c | is-zero = gnil′
f n
rec c | above-zero n>z with maximum-coin c n n>z
f .(value d + n′) rec c | above-zero n>z | d , (d⩽c , n′ , reﬂ) , guc =
gcons′ d d⩽c guc (rec n′ { }8 d)
In greedy, the combinator
<-rec : (P : Nat →Set) →
((n : Nat) →((n′ : Nat) →n′ < n →P n′) →P n) →
(n : Nat) →P n
is for well-founded recursion on
< , and the function
compare-with-zero : (n : Nat) →ZeroView n
is a covering function for the view
data ZeroView : Nat →Set where
is-zero
: ZeroView 0
above-zero : {n : Nat} →n > 0 →ZeroView n
At Goal 8, Agda deduces that n is value d + n′ and demands that we prove
n′ < value d + n′ in order to make the recursive call, which is easily discharged
since value d > 0.
5.4
Discussion
Section 5.1 heavily borrows techniques from the AoPA (Algebra of Programming
in Agda) library [Mu et al., 2009] while making generalisations and adaptations:
AoPA deals with non-dependently typed programs only, whereas to work
with indexed datatypes we need to move to indexed families of relations;
to work with the ornamental universe, we parametrise the relational fold
with a description, making it fully datatype-generic, whereas AoPA has only

170
5
Relational algebraic ornamentation
specialised versions for lists and binary trees; we deﬁne min
• Λ
as a single
operator (which happens to be the “shrinking” operator proposed by Mu and
Oliveira [2012]) to avoid the struggle with predicativity that AoPA had. All
of the above are not fundamental differences between the work presented in
this chapter and AoPA, though — the two differ essentially in methodology:
in AoPA, dependent types merely provide a foundation on which relational
program derivations can be expressed formally and checked by machine, but
the programs remain non-dependently typed throughout the formalisation;
whereas in this chapter, relational programming is a tool for obtaining nontrivial
inductive families that effectively guide program development as advertised
as the strength of internalist programming. In short, the focus of AoPA is on
traditional relational program derivation (expressed in a dependently typed
language), whereas our emphasis is on internalist programming (aided by
relational programming).
Algebraic ornamentation was originally proposed by McBride [2011], which
deals with functions only. Generalising algebraic ornamentation to a relational
setting allows us to write more speciﬁcations (like the one given by the Stream-
ing Theorem in Section 5.3.2, which involves converses) and employ more
powerful theorems (like the Greedy Theorem in Section 5.3.3, which involves
minimisation). In particular, since relational coalgebras coincide with the con-
verses of algebras, we are no longer tied to the bottom-up view of datatype
indices and can switch to the top-down view — for example, in the internalist
implementation of the Streaming Theorem, we can think of the output list as
being unfolded from the index of its type. We will show in Chapter 6 that the
generalisation is in fact a “maximal” one: any datatype obtained via ornamenta-
tion can be obtained via relational algebraic ornamentation up to isomorphism.
Atkey et al. [2012] also investigated algebraic ornamentation via a ﬁbrational,
syntax-free perspective. While their “partial reﬁnement” (which generalises
functional algebraic ornamentation) is subsumed by relational algebraic or-
namentation (since relational algebras allow partiality), they were able to go
beyond inductive families to indexed inductive-recursive datatypes [Dybjer and
Setzer, 2006], which are out of the scope of this dissertation. (Unlike coinductive
families, the ornament framework will require a signiﬁcant revision to work

5.4
Discussion
171
for inductive-recursive families; in particular, we will need to rethink what it
means for an inductive-recursive functor to reﬁne another.)
Let us contemplate the interplay between internalist programming and
relational programming, especially the one in Section 5.3.3. As mentioned
in Section 2.5, internalist programs can encode more semantic information,
including correctness proofs; we can thus write programs that directly explain
their own meaning. The internalist program greedy is such an example, whose
structure carries an implicit inductive proof; the program constructs not merely a
list of coins, but a bag of coins chosen according to a particular local optimisation
strategy (i.e., min Q
• Λ (fun total-value-alg ◦)). Internalist programming alone
has limited power, however, because internalist programs should share structure
with their correctness proofs, but we cannot expect to have such coincidences all
the time. In particular, there is no hope of integrating a correctness proof into a
program when the structure of the proof is more complicated than that of the
program. For example, it is hard to imagine how to integrate a correctness proof
for the full speciﬁcation of the minimum coin change problem into a program
for the greedy algorithm. In essence, we have two kinds of proofs to deal with:
the ﬁrst kind follow program structure and can be embedded in internalist
programs, and the second kind are general proofs of full speciﬁcations, which
do not necessarily follow program structure and thus fall outside the scope
of internalism. To exploit the power of internalism as much as possible, we
need ways to reduce the second kind of proof obligation to the ﬁrst kind —
note that such reduction involves not only constructing proof transformations
but also determining what internalist proofs are sufﬁcient for establishing
proofs of full speciﬁcations. It turns out that relational program derivation is
precisely a way in which to construct such proof transformations systematically
from speciﬁcations. In relational program derivation, we identify important
forms of relational programs (i.e., relational composition, recursion schemes,
and various other combinators), and formulate algebraic laws and theorems
in terms of these forms. By applying the laws and theorems, we massage
a relational speciﬁcation into a known form which corresponds to a proof
obligation that can be expressed in an internalist type, enabling transition to
internalist programming. For example, we now know that a relational fold can

172
5
Relational algebraic ornamentation
be turned into an inductive family for internalist programming by algebraic
ornamentation. Thus, given a relational speciﬁcation, we might seek to massage
it into a relational fold when that possibility is pointed out by known laws and
theorems (e.g., the Greedy Theorem). To sum up, we get a hybrid methodology
that leads us from relational speciﬁcations towards internalist types for type-
directed programming, providing hints on internalist type design in the form
of relational algebraic laws and theorems.

Chapter 6
Categorical equivalence of
ornaments and relational algebras
Consider the AlgList datatype in Section 5.2 again. The way it is reﬁned relative
to List looks canonical, in the sense that any ornamentation of List can be
programmed as a special case of AlgList: by setting the carrier of the algebra R,
we can choose whatever index set we want, and by carefully programming R,
we can insert ﬁelds into the list datatype that add more information or put
restriction on ﬁelds and indices. For example, if we want some new information
in the nil case, we can program R such that R (‘nil ,
) x contains a ﬁeld
requesting that information; if, in the cons case, we need to relate the targeted
index x, the head element a, and the index x′ of the recursive position in
some way, we can program R such that R (‘cons , a , x′ ,
) x expresses that
relationship.
The above observation leads to the following general theorem: Let O :
Orn e D E be an ornament from D : Desc I to E : Desc J. Then there is a
classifying algebra for O
clsAlg O : F D (Inv′ e) ⇝Inv′ e
whose carrier type is deﬁned by
Inv′ e : I →Set
Inv′ e i = Σ[ j : J ] e j ≡i
173

174
6
Categorical equivalence of ornaments and relational algebras
such that there are isomorphisms
(j : J) →µ ⌊algOD D (clsAlg O)⌋(e j , j , reﬂ) ∼= µ E j
That is, the algebraic ornamentation of D using the classifying algebra derived
from O produces a datatype isomorphic to µ E, so intuitively the algebraic
ornamentation has the same content as O. We may interpret this theorem as
saying that algebraic ornamentation is “complete” for the ornament language:
any relationship between datatypes that can be described by an ornament can
be described up to isomorphism by an algebraic ornamentation. The name
“classifying algebra” is explained after the examples below.
Examples (classifying algebras for two ornaments).
The following relational alge-
bra R serves as a classifying algebra for the ornament ⌈OrdListOD⌉from lists
to ordered lists:
R : F (ListD Val) (Inv′ !) ⇝Inv′ !
-- where ! : Val →⊤
R (‘nil
,
) (b , reﬂ) = ⊤
R (‘cons , x , (b′ , reﬂ) , ) (b , reﬂ) = (b ⩽x) × (b′ ≡x)
The nil case says that the empty list can be mapped to any b : Val (since any b
is a lower bound of the empty list); for the cons case, where x : Val is the head
element of a nonempty list and b′ : Val is a possible result of folding the tail
(i.e., b′ is a lower bound of the tail), the list can be mapped to b : Val if b is
a lower bound of x and x is exactly b′. The type of proofs that a list xs folds
with R to some b is isomorphic to Ordered b xs, and hence
AlgList Val R (b , reﬂ) ∼= Σ[ xs : List Val ] ([ R ]) xs (b , reﬂ)
∼= Σ[ xs : List Val ] Ordered b xs
∼= OrdList b
For another example, consider the ornament NatD-ListD A, for which we
can use the following algebra S as a classifying algebra:
S : F NatD (Inv′ !) ⇝Inv′ !
-- where ! : ⊤→⊤
S (‘nil
,
) ( , reﬂ) = ⊤
S (‘cons , ( , reﬂ) , ) ( , reﬂ) = A
The result of folding a natural number n with S is uninteresting, as it can only
be ‘ ’. The fold, however, requires an element of type A for each successor node

6
Categorical equivalence of ornaments and relational algebras
175
it encounters, so a proof that n goes through the fold consists of n elements of
type A and amounts to an inhabitant of Vec A n. Thus
µ ⌊algOD NatD S⌋( ,
, reﬂ) ∼= Σ[ n : Nat ] ([ S ]) n ( , reﬂ)
∼= Σ[ n : Nat ] Vec A n
∼= List A
This example helps to emphasise proof-relevance of our relational language,
deviating from Bird and de Moor [1997], which (implicitly) adopts the tradi-
tional proof-irrelevant semantics of relations (in the sense that all one cares
about proofs of set membership is their existence).
□
The completeness theorem brings up a nice algebraic intuition about induc-
tive families. Consider the ornament from lists to vectors, for example. This
ornament speciﬁes that the type List A is reﬁned by the collection of types
Vec A n for all n : Nat. A list, say a :: b :: [] : List A, can be reconstructed
as a vector by starting in the type Vec A zero as [], jumping to the next type
Vec A (suc zero) as b :: [], and ﬁnally landing in Vec A (suc (suc zero)) as
a :: b :: []. The list is thus classiﬁed as having length 2, as computed by the fold
function length, and the resulting vector is a fused representation of the list and
the classiﬁcation proof. In the case of vectors, this classiﬁcation is total and de-
terministic: every list is classiﬁed under one and only one index. But in general,
classiﬁcations can be partial and nondeterministic. For example, promoting a
list to an ordered list is classifying the list under an index that is a lower bound
of the list. The classiﬁcation process checks at each jump whether the list is still
ordered; this check can fail, so an unordered list would “disappear” midway
through the classiﬁcation. Also there can be more than one lower bound for
an ordered list, so the list can end up being classiﬁed under any one of them.
Compared with McBride’s original functional algebraic ornamentation [2011],
which can only capture part of this intuition about classiﬁcation (namely those
classiﬁcations that are total and deterministic), relational algebraic ornamen-
tation allows partiality and nondeterminacy and thus captures the idea about
classiﬁcation in its entirety — a classiﬁcation is just a relational fold computing
the index that classiﬁes an inhabitant. All ornaments specify classiﬁcations, and
thus can be transformed into algebraic ornamentations.
There is a dual to the completeness theorem: every relational algebra is
isomorphic to the classifying algebra for the algebraic ornament using the

176
6
Categorical equivalence of ornaments and relational algebras
algebra. More precisely: Let D : Desc I be a description and R : F D X ⇝X
an algebra (where X : I →Set). There is a family of isomorphisms between
X i and Inv′ outl i for every i : I (where outl : Σ I X →I); call the forward
direction of this family of isomorphisms h : X ⇒Inv′ outl. Then we have
fun h
• R ≃clsAlg ⌈algOD D R⌉
• R D (fun h)
or diagrammatically:
X
F D X
Inv′ outl
F D (Inv′ outl)
R
clsAlg ⌈algOD D R⌉
R D (fun h)
∼=
∼=
fun h
Together with the completeness theorem, we see that algOD and clsAlg are, in
some sense, inverse to each other up to isomorphism. This suggests that we can
seek to construct a categorical equivalence between SliceCategory Orn (I , D)
and a suitable category of D-algebras and homomorphisms by extending algOD
and clsAlg to functors between the two categories and proving that the two
functors are inverse up to (natural) isomorphism. This we do in Section 6.2, after
we look at ornaments from a more semantic perspective in Section 6.1, where we
also deal with some unresolved issues in Chapter 4. The categorical equivalence
shows that ornaments and relational algebras are essentially the same entities,
which lets us associate some ornamental and relational algebraic constructions
in Section 6.3. The results in this chapter are only partially formalised, largely
due to the difﬁculty of manipulating complicatedly typed terms. This issue,
along with some others, is discussed in Section 6.4.
6.1
Ornaments and horizontal transformations
We ﬁrst aim to ﬁnd a semantic perspective on ornaments, so we can step away
from the syntactic detail and handle ornaments more easily, in preparation for
Section 6.2. Consider the equivalence on ornaments that was left undeﬁned in
Section 4.1.2:

6.1
Ornaments and horizontal transformations
177
OrnEq : {I J : Set} {e f : J →I} {D : Desc I} {E : Desc J} →
Orn e D E →Orn f D E →Set
Here we aim for an extensional equality — for example, if two ornaments
between the same pair of descriptions differ only in either
• that one uses σ S and the other uses ∆[ s : S ]
∆
[ s ], both expressing copying,
or
• that one uses
∆[ s : S ] ∆[ t : T ]
∆
[ f s ]
∆
[ g t ]
and the other uses
∆[ s : S ]
∆
[ f s ] ∆[ t : T ]
∆
[ g t ]
the latter swapping the order of the middle two independent markings,
then they describe precisely the same relationship between the pair of descrip-
tions and are considered equal extensionally. Since the direct semantics of
ornaments is decoded componentwise by erase, we might deﬁne OrnEq as point-
wise equality of erase, which requires a rather tricky type to express. However,
it turns out that we can focus on only one aspect of erase: ﬁxing two response
descriptions related by at least one response ornament, the two response de-
scriptions necessarily have the same pattern of recursive positions and erase
always copies the values at the positions, so the only behaviour of erase that
can vary with response ornaments is how the values of the ﬁelds are trans-
formed. This suggests that, in an inhabitant of [[ D ]] X where D : RDesc I and
X : I →Set, we can separate the values of the ﬁelds from the values at the
recursive positions, and focus on how erase acts on the ﬁrst part.
Here indexed containers [Morris, 2007, Chapter 8] can provide a helpful
perspective: An I-indexed container is
• a set S of shapes,
• a shape-indexed family of sets P : S →Set of positions, and
• a function next : (s : S) →P s →I associating each position with an index
of type I.
(The terminology slightly deviates from that of Morris, whose indexed contain-
ers refer to indexed families of the above indexed containers, directly compara-

178
6
Categorical equivalence of ornaments and relational algebras
ble with the two-level structure of descriptions.) The container is interpreted as
the type
λ X 7→Σ[ s : S ] ((p : P s) →X (next s p)) : (I →Set) →Set
That is, given a type family X : I →Set, an inhabitant of the container type starts
with a speciﬁc shape — from which we derive a set of positions and associated
indices — and contains an element of type X i for each of the positions where
i is the index associated with the position. (For example, take S to be the set of
natural numbers, and let the set of positions derived from a natural number n
be a ﬁnite set of size n, enumerable in a ﬁxed order. The container type is then
isomorphic to the type of lists, whose elements are indexed in accordance with
the next function.) Response descriptions can be regarded as a special case of
indexed containers: values of ﬁelds constitute a shape, and sets of positions are
restricted to enumerable ﬁnite sets; consequently, next s : P s →I for any s : S
can be represented by a List I, and there is no longer need to specify P. We thus
deﬁne the set of shapes derived from a response description by
S : {I : Set} →RDesc I →Set
S (v is)
= ⊤
S (σ S D) = Σ[ s : S ] S (D s)
and the function next by
next : {I : Set} (D : RDesc I) →S D →List I
next (v is)
= is
next (σ S D) (s , ss) = next (D s) ss
We can then express that a piece of horizontal data of type [[ D ]] X can be
separated into a shape and a series of contained elements via the following
isomorphism:
horizontal-iso : {I : Set} (D : RDesc I) (X : I →Set) →
[[ D ]] X ∼= Σ (S D) (ﬂip P X ◦next D)
The implementation is just rearrangement of data — for example, the left-to-
right direction is deﬁned by
hori-decomp : {I : Set} (D : RDesc I) (X : I →Set) →
[[ D ]] X →Σ (S D) (ﬂip P X ◦next D)

6.1
Ornaments and horizontal transformations
179
hori-decomp (v is)
X xs
=
, xs
hori-decomp (σ S D) X (s , xs) = ( ,
s ∗id) (hori-decomp (D s) X xs)
Back to the semantic equivalence of ornaments. Deﬁne a specialised version
of erase on shapes:
eraseS : {I J : Set} {e : J →I} {D : RDesc I} {E : RDesc J}
(O : ROrn e D E) →S E →S D
eraseS (v eqs)
=
eraseS (σ S O) (s , ss) = s , eraseS (O s) ss
eraseS (∆T O) (t , ss) =
eraseS (O t) ss
eraseS (
∆
s O) ss
= s , eraseS O
ss
This is the aspect of erase that we are interested in, and we can now deﬁne
equivalence of ornaments as
OrnEq : {I J : Set} {e f : J →I} {D : Desc I} {E : Desc J} →
Orn e D E →Orn f D E →Set
OrnEq {I} {J} {e} {f} O P =
(e .= f) × ((j : J) →eraseS (O (ok j)) ˙≊eraseS (P (ok j)))
which can be proved to imply pointwise equality of forget O and forget P: With
the help of horizontal-iso, the general erase can be seen as ﬁrst separating a piece
of horizontal data into a shape and a series of recursive values, processing the
shape by eraseS, and combining the resulting shape with the recursive values.
Since the real work is done by eraseS, requiring extensional equality of eraseS is
sufﬁcient. This argument is then extended vertically by induction.
We have seen that response ornaments induce shape transformations (by
eraseS). Conversely, can we derive response ornaments from shape transforma-
tions? More speciﬁcally: Let D : RDesc I, E : RDesc J, and t : S E →S D, and
we wish to construct a response ornament from D to E. The shape transforma-
tion t expects a complete S E as its argument, which, in the response ornament,
can be assembled by ﬁrst marking all ﬁelds of E as additional by ∆. We then
apply t to the assembled shape ss : S E, resulting in a shape t ss : S D, and ﬁll
out all ﬁelds of D using values in this shape by
∆
. Finally, we have to use v to
end the response ornament, which requires an index coherence proof of type
E e (next E ss) (next D (t ss)) for some e : J →I — this is the extra condition

180
6
Categorical equivalence of ornaments and relational algebras
that we need to impose on the shape transformation for deriving a response
ornament. We thus deﬁne horizontal transformations as
record HTrans {I J : Set} (e : J →I) (D : RDesc I) (E : RDesc J) : Set
where
constructor
,
ﬁeld
t : S E →S D
c : (ss : S E) →E e (next E ss) (next D (t ss))
The response ornaments derived by the above process are called normal re-
sponse ornaments, which are deﬁned by
normROrn-
∆
: {I J : Set} {e : J →I} {D : RDesc I} {js : List J} →
(ss : S D) →E e js (next D ss) →ROrn e D (v js)
normROrn-
∆
{D := v is
}
eqs = v eqs
normROrn-
∆
{D := σ S D} (s , ss) eqs =
∆
[ s ] normROrn-
∆
{D := D s} ss eqs
normROrn : {I J : Set} {e : J →I} {D : RDesc I} {E : RDesc J} →
HTrans e D E →ROrn e D E
normROrn {E := v js
} tr = normROrn-
∆
(HTrans.t tr ) (HTrans.c tr )
normROrn {E := σ S E} tr =
∆[ s : S ] normROrn {E := E s} (curry (HTrans.t tr) s , curry (HTrans.c tr) s)
The top-level function normROrn exhausts all ﬁelds of E by ∆, partially applying
the transformation along the way, and then normROrn-
∆
takes over and inserts
values obtained from the result of the transformation into ﬁelds of D by
∆
,
ending with the placement of the index coherence proof.
We can now easily arrange a category FHTrans of descriptions and hor-
izontal transformations, which is isomorphic to Orn. Its objects are of type
Σ Set Desc as in Orn, and its sets of morphisms are
λ { (J , E) (I , D) 7→Σ[ e : J →I ] FHTrans e D E }
where FHTrans is the type of families of horizontal transformations:
FHTrans : {I J : Set} →(J →I) →Desc I →Desc J →Set
FHTrans {I} {J} e D E = (j : J) →HTrans e (D (e j)) (E j)

6.1
Ornaments and horizontal transformations
181
Morphism equivalence is deﬁned to be pointwise equality of the shape trans-
formations extracted by HTrans.t, and identities and composition are deﬁned
in terms of functional identities and composition. We then have two functors
Erase : Functor Orn FHTrans and Normal : Functor FHTrans Orn back
and forth between the two categories: the object parts of both functors are iden-
tities, and for the morphism parts, Erase maps ornaments to componentwise
eraseS (with suitable coherence proofs) and Normal maps families of horizontal
transformations to normal ornaments (i.e., componentwise normal response
ornaments). For any tr : HTrans e D E, we can prove that
eraseS (normROrn tr) .= HTrans.t tr
which guarantees that the morphism parts of Erase and Normal are inverse
to each other.
Knowing that Orn and FHTrans are isomorphic means that, extensionally,
we can regard ornaments and horizontal transformations as the same entities
and freely switch between the two notions. For example, in Section 4.2, where
we did not have the notion of horizontal transformations yet, it was hard
to establish the pullback property of parallel composition in Orn (4.2) by
reasoning in terms of ornaments. Switching to FHTrans, however, the proof
becomes conceptually much simpler: Due to the isomorphism between Orn
and FHTrans, it sufﬁces to prove that the image of the square (4.2) under Erase
in FHTrans is a pullback. We have the following functor Shape from FHTrans
to Fam, which maps descriptions to indexed sets of shapes and discards index
coherence proofs in horizontal transformations:
Shape : Functor FHTrans Fam
Shape = record
{ object
= λ { (I , D) 7→I , λ i 7→S (D i)
}
; morphism = λ { (e , ts) 7→e , λ {j} 7→HTrans.t (ts j) }
; proofs of laws }
The functor can be proved to be pullback-reﬂecting: if the image of a square
in FHTrans under Shape is a pullback in Fam, then the square itself is a
pullback in FHTrans. (The proof proceeds by manipulating shape transforma-
tions in Fam and then constructing the missing index coherence proof.) The

182
6
Categorical equivalence of ornaments and relational algebras
problem is thus reduced to proving that the square (4.2) mapped into Fam by
Shape ⋄Erase is a pullback, which boils down to the isomorphism
pcROD-iso O P : S (toRDesc (pcROD O P))
∼= Σ[ p : S E × S F ] eraseS O (outl p) ≡eraseS P (outr p)
with the two equations
eraseS (diffROrn-l O P) .= outl ◦outl ◦Iso.to (pcROD-iso O P)
eraseS (diffROrn-r O P) .= outr ◦outl ◦Iso.to (pcROD-iso O P)
for any O : ROrn e D E and P : ROrn f D F, provable by induction on O and P.
The isomorphism and equations allow us to prove that the derived square in
Fam is isomorphic to the componentwise set-theoretic pullback, and thus the
square itself is also a pullback.
6.2
Ornaments and relational algebras
We now seek to characterise ornaments and relational algebras as essentially the
same entities via a categorical equivalence, which subsumes the completeness
theorem (and its dual) at the beginning of this chapter. The deﬁnition of
categorical equivalence is unfolded below:
• An equivalence between two categories consists of two functors back and
forth such that their compositions are naturally isomorphic to the identity
functors.
– A natural isomorphism between two functors F , G : Functor C D is
an isomorphism in the functor category from C to D, whose objects are
functors from C to D and morphisms are natural transformations.
■A natural transformation from F to G is a way of relating the image
of C under F to the image of C under G: it consists of a morphism
φ X : object F X ⇒D object G X for each object X in C, which we call
the components of the natural transformation, and for any morphism

6.2
Ornaments and relational algebras
183
m : X ⇒C Y the following naturality diagram commutes:
object F X
object G X
object F Y
object G Y
φ X
φ Y
morphism F m
morphism G m
Both equivalence and composition for natural transformations are com-
ponentwise.
– Natural isomorphism is an equivalence relation on functors, so we can
assemble a category whose objects are (smaller) categories and morphisms
are functors, with natural isomorphism as the equivalence on morphisms.
A categorical equivalence is then an isomorphism in this category of cate-
gories and functors.
Fixing D : Desc I, the completeness theorem is a consequence of one direction
of the object part of an equivalence between SliceCategory Orn (I , D) — which
we denote by Orn/(I , D) from now on — and the category RAlg D whose
objects are relational D-algebras
record RAlgebra D : Set1 where
constructor
,
ﬁeld
Carrier : I →Set
Alg
: F D Carrier ⇝Carrier
and morphisms are algebra homomorphisms (on which we will elaborate later):
The two functors forming the equivalence are
ClsAlg
: Functor (Orn/(I , D)) (RAlg D)
and
AlgOrn : Functor (RAlg D) (Orn/(I , D))
and their object parts are respectively
J , E
I , D
Inv′ e
F D (Inv′ e)
e , O
clsAlg O
7→
and
Σ I X , ⌊algOD D R⌋
I , D
X
F D X
outl , ⌈algOD D R⌉
R
7→

184
6
Categorical equivalence of ornaments and relational algebras
The natural isomorphism between AlgOrn ⋄ClsAlg and the identity functor
on Orn/(I , D) consists of two natural transformations componentwise inverse
to each other; their components constitute, for each ornament O : Orn e D E,
the following isomorphism in Orn/(I , D):
Σ I (Inv′ e) , ⌊algOD D (clsAlg O)⌋
J , E
I , D
outl , ⌈algOD D (clsAlg O)⌉
e , O
∼=
(6.1)
The completeness theorem is then obtained by mapping these isomorphisms
into Fam by Ind ⋄SliceF.
For the morphisms of RAlg D, a ﬁrst thought might be adopting relational
homomorphisms, which we have seen in Section 5.3.1 — a relational homomor-
phism from an algebra (X , R) to another algebra (Y , S) is a relation H : X ⇝Y
such that H
• R ≃S
• R D H, or diagrammatically:
X
Y
F D X
F D Y
R
S
H
R D H
Morphism equivalence is the equivalence of the relations between carriers,
ignoring the homomorphism condition. It turns out, however, that this is not
the right notion of homomorphisms for establishing the categorical equivalence.
The right notion will surface as we construct the morphism part of AlgOrn
below.
The morphism part of AlgOrn maps a homomorphism from (X , R) to
(Y , S) to a morphism in Orn/(I , D):
Σ I X , ⌊algOD D R⌋
Σ I Y , ⌊algOD D S⌋
I , D
{ }0 , { }1
outl , ⌈algOD D R⌉
outl , ⌈algOD D S⌉
To make the diagram commute, Goal 0 should be of the form id ∗h for some
function h : X ⇒Y, but the closest thing we have is merely a relation between

6.2
Ornaments and relational algebras
185
X and Y — to have an ornament between descriptions, we need to specify
computation on the index sets of the descriptions, which correspond to the
carriers of relational algebras, and hence we should restrict RAlg D to include
only functional homomorphisms:
X
Y
F D X
F D Y
R
S
fun h
R D (fun h)
The equivalence on them is reﬁned to pointwise equality of the functions
between carriers.
We continue with Goal 1, which requires an ornament from ⌊algOD D S⌋
to ⌊algOD D R⌋. Switching to the perspective of horizontal transformations,
we should construct a shape transformation which essentially replaces a proof
about R with a proof about S within a shape derived from algebraic ornamenta-
tion: For such shapes we have the following isomorphisms
algROD-iso : {I : Set} (D′ : RDesc I) {X : I →Set} (P : P ([[ D′ ]] X)) →
S (toRDesc (algROD D′ P)) ∼= Σ ([[ D′ ]] X) P
whose implementation is, again, just rearrangement of data — for example, the
left-to-right direction is deﬁned by
algROD-decomp :
{I : Set} (D′ : RDesc I) (X : I →Set) (P : P ([[ D′ ]] X)) →
S (toRDesc (algROD D P)) →Σ ([[ D′ ]] X) P
algROD-decomp (v is)
X P (xs , p , ) = xs , p
algROD-decomp (σ S D′) X P (s , ss)
=
( ,
s ∗id) (algROD-decomp (D′ s) X (curry P s) ss)
By algROD-iso and horizontal-iso, the type of shapes for an algebraic response
ornamentation can be decomposed into three parts:
• the type of shapes for the basic response description,
• the type of series of indices of the recursive positions, and
• the type of proofs about the basic shape and the indices.

186
6
Categorical equivalence of ornaments and relational algebras
(For example, in the case of AlgList A R, the three parts are
• the constructor ﬁeld and the element ﬁeld a : A from ListD A,
• the ﬁeld x′ : X, and
• the rnil and rcons ﬁelds.)
Expanding the deﬁnition of algOD (Figure 5.3), at Goal 1 we should construct
for every i : I and x : X i a shape transformation
S (toRDesc (algROD (D i) ((R ◦) x)))
Σ ([[ D i ]] X) ((R ◦) x)
Σ ([[ D i ]] Y) ((S ◦) (h x))
S (toRDesc (algROD (D i) ((S ◦) (h x))))
Iso.to (algROD-iso (D i) ((R ◦) x)
mapRD (D i) h ∗{ }2
Iso.from (algROD-iso (D i) ((S ◦) (h x))
(6.2)
where Goal 2 requires a function of type
{xs : [[ D i ]] X} →R xs x →S (mapRD (D i) h xs) (h x)
which, when suitably quantiﬁed, is a pointwise form of
fun h
• R ⊆S
• R D (fun h)
i.e., one direction of the homomorphism condition. This is actually the only di-
rection of the homomorphism condition that we should impose on the functions
between carriers; we denote it by the inclusion sign in the “semi-commutative”
diagram:
X
Y
F D X
F D Y
R
S
fun h
R D (fun h)
⊆
(The reason for requiring only one direction will become clear when we consider
the morphism part of ClsAlg.) In short, the morphism part of AlgOrn treats

6.2
Ornaments and relational algebras
187
the input homomorphism condition as a proof transformer, and apply that
transformer to the proof encapsulated in the input shape.
One of the functor laws we should prove for AlgOrn is that its morphism
part preserves equivalence, and it is when doing so that we encounter the ﬁnal
problem: we need to prove that the shape transformation (6.2) — whose be-
haviour depends on the computational content of the homomorphism condition
— is extensionally the same for equivalent homomorphisms, but homomor-
phism equivalence as we deﬁned it does not include any information about the
homomorphism condition and is not strong enough. We thus see that proofs
of the homomorphism condition should not be treated irrelevantly since they
are used computation-relevantly in the shape transformations; we must take
their behaviour into account when deﬁning homomorphism equivalence. This
brings us to the right notion of algebra homomorphisms, deﬁned by
record RAlgMorphism D (X , R) (Y , S) : Set1 where
constructor
,
ﬁeld
h : X ⇒Y
c : (i : I) (xs : [[ D i ]] X) (x : X i) →R xs x →S (mapRD (D i) h xs) (h x)
the equivalence on which is pointwise equality on both components h and c.
At the beginning of this chapter, we saw in the example about the classifying
algebra for the ornament from natural numbers to lists that the relational
language is used proof-relevantly, deviating from traditional relational theories;
that deviation is fully manifested in this proof-relevant category of relational
algebras and homomorphisms.
Before we move on to the natural isomorphisms, it still remains to deﬁne
ClsAlg. In particular, we should deﬁne the function clsAlg used in its object
part:
clsAlg O : F D (Inv′ e) ⇝Inv′ e
clsAlg O js (j , reﬂ) =
let (ss , ps) = Iso.to (horizontal-iso (D (e j)) (Inv′ e)) js
in Σ[ ts : S (E j) ] eraseS (O (ok j)) ts ≡ss ×
P-toList outl (next (D (e j)) ss) ps ≡next (E j) ts

188
6
Categorical equivalence of ornaments and relational algebras
The condition for saying that js : [[ D (e j) ]] (Inv′ e) is mapped by clsAlg O to
j : J is stated in terms of the two parts of js decomposed by horizontal-iso:
• For the shape part ss : S (D (e j)), considering the completeness theorem,
there should be enough information for promoting ss to an inhabitant of
S (E j). Here for simplicity we require a complete inhabitant of S (E j) that
erases to the given inhabitant of S (D (e j)) by eraseS (O (ok j)). (In the
example about the classifying algebra for the ornament from lists to ordered
lists given at the beginning of this chapter, the representation of this part of
the condition is optimised — only an inhabitant of b ⩽x is required.)
• As for ps, which is a series of recursively computed indices when clsAlg O is
used in a fold, they should be equal to next (E j) ts when coerced to a List J,
ensuring that the recursive classiﬁcations are successful. (This part of the
condition corresponds to the proof obligation b′ ≡x in the aforementioned
example.)
The morphism part of ClsAlg can then be constructed:
J , E
K , F
I , D
e , O
f , P
g , Q
7→
Inv′ e
Inv′ f
F D (Inv′ e)
F D (Inv′ f)
clsAlg O
clsAlg P
fun { }3
R D (fun
)
{ ⊆}4
Goal 3 has type
{i : I} →(Σ[ j : J ] e j ≡i) →Σ[ k : K ] f k ≡i
and can be easily discharged by g and the proof f ◦g .= e extracted from the
commutative triangle. At Goal 4, we should transform a proof about clsAlg O to
one about clsAlg P; expanding the deﬁnition of clsAlg, we should transform an
inhabitant of S (E j) to one of S (F (g j)) for every j : J, so eraseS (Q (ok j)) does
the job, modulo manipulation of the associated equations. (Here we see clearly
that the homomorphism condition can only require the left-to-right direction,
since it is the only direction that can be constructed from Q.)
Now we look at the natural isomorphism between AlgOrn ⋄ClsAlg
and the identity functor on Orn / (I , D) — the construction of the other
natural isomorphism between ClsAlg ⋄AlgOrn and the identity functor on

6.2
Ornaments and relational algebras
189
RAlg D is based on a similar analysis and omitted from the presentation.
The components (indexed by ornaments) of the natural isomorphism were
shown in (6.1). Switching to horizontal transformations, we should construct
an isomorphism between
S (toRDesc (algROD (D (e j)) ((clsAlg O ◦) (j , reﬂ))))
and
S (E j)
for each j : J, and make sure that its two directions make the corresponding
triangles commute.
For the left-to-right direction, by algROD-iso, the left-
hand side decomposes into some js : [[ D (e j) ]] (Inv′ e) and a proof of
clsAlg O js (j , reﬂ) — the latter contains an inhabitant of S (E j), which is
exactly what we need. Conversely, any ss : S (E j) by itself uniquely determines
a js : [[ D (e j) ]] (Inv′ e) and a proof of clsAlg O js (j , reﬂ) that contains ss,
since the equations in clsAlg completely speciﬁes what js should be. The two
directions are inverse to each other because all that is involved is rearrangement
of data, and the corresponding triangles commute because (in particular) the
ﬁelds from D are not modiﬁed. We also need to establish naturality of one
of the natural transformations (naturality of the other natural transformation
can be derived from the componentwise isomorphisms); here we choose the
left-to-right direction. Let m be a morphism in Orn/(I , D):
J , E
K , F
I , D
e , O
f , P
g , Q
Because the equivalence on slice morphisms ignores the commutative triangles,
we only need to establish commutativity of the following square in Orn:
Σ I (Inv′ e) , ⌊algOD D (clsAlg O)⌋
J , E
Σ I (Inv′ f) , ⌊algOD D (clsAlg P)⌋
K , F
φ O
φ P
morphism (SliceF ⋄AlgOrn ⋄ClsAlg) m
g , Q
where φ denotes the components of the natural transformation sketched above.
Switching to horizontal transformations, the vertical morphisms essentially
replace a shape of type S (E j) (for some suitable j : J) with one of type

190
6
Categorical equivalence of ornaments and relational algebras
S (F (g j)) by eraseS (Q (ok j)), while the horizontal ones extract those shapes.
The two operations are independent, and hence the diagram commutes.
6.3
Consequences
We began this chapter with the completeness theorem, and, with some effort,
have extended it to a categorical equivalence. The extra effort is not wasted:
the categorical equivalence allows us to perform reasoning across the boundary
between ornaments and relational algebras easily. Below we give two exam-
ples that connect ornamental and relational algebraic constructions via the
categorical equivalence.
6.3.1
Parallel composition and the banana-split law
A standard categorical result is that any functor taking part in a categorical
equivalence necessarily preserves all universal constructions (limits and colimits,
to be precise). The same type of universal constructions in two equivalent
categories can then be thought of as being in correspondence. For example:
We have seen in Section 4.2 that parallel composition gives rise to a pullback
square (4.2) in Orn, which is a product in Orn/(I , D). The functor ClsAlg
— being part of a categorical equivalence — preserves products, so the image
of (4.2) under ClsAlg in RAlg D is also a product, and is thus isomorphic to
any product in RAlg D; conversely, any product in RAlg D when mapped
to Orn/(I , D) by AlgOrn is also isomorphic to (4.2). Below we look at a
consequence of the latter direction.
In RAlg D, a construction of products is inspired by the banana-split
law [Fokkinga, 1992, page 88], whose original, functional form is as follows:
Deﬁne the functorial mapping F-map D by
F-map D : {Z W : I →Set} →(Z ⇒W) →(F D Z ⇒F D W)
F-map D f {i} = mapRD (D i) f
For any f : F D X ⇒X and g : F D Y ⇒Y we have

6.3
Consequences
191
fold f
▽
fold g .= fold ((f ◦F-map D outl)
▽
(g ◦F-map D outr))
The left-hand side of the equation traverses a (µ D)-inhabitant by two inde-
pendent folds, while the right-hand side combines the two traversals into a
single fold using a composite algebra. This composite algebra, when gener-
alised straightforwardly to relations, gives rise to a product in RAlg D: Let
R : F D X ⇝X and S : F D Y ⇝Y. We deﬁne the “banana-split algebra” of
R and S by
BSAlg R S : F D (X ˙× Y) ⇝(X ˙× Y)
BSAlg R S xys (x , y) = R (F-map D outl xys) x × S (F-map D outr xys) y
where (X ˙× Y) i = X i × Y i. We can then construct the following span
X ˙× Y
F D (X ˙× Y)
X
F D X
Y
F D Y
BSAlg R S
R
S
fun outl
fun outr
R D (fun outl)
R D (fun outr)
⊇
⊆
where the homomorphism conditions are simply projections, and it is easy to
prove that the span is a product. The categorical equivalence between RAlg D
and Orn/(I , D) implies that the image of the product under AlgOrn is a
pullback in Orn:
I , D
Σ I X , ⌊algOD D R⌋
Σ I Y , ⌊algOD D S⌋
Σ I (X ˙× Y) , ⌊algOD D (BSAlg R S)⌋
outl , ⌈algOD D R⌉
outl , ⌈algOD D S⌉
outl ,
id ∗outl ,
id ∗outr ,
which is isomorphic to the pullback square derived from parallel composition:
I , D
Σ I X , ⌊algOD D R⌋
Σ I Y , ⌊algOD D S⌋
outl ▷◁outl , ⌊⌈algOD D R⌉⊗⌈algOD D S⌉⌋
outl , ⌈algOD D R⌉
outl , ⌈algOD D S⌉
pull ,
outl▷◁,
outr▷◁,

192
6
Categorical equivalence of ornaments and relational algebras
This shows, in particular, that the parallel composition of the two algebraic
ornamentations using R and S respectively is isomorphic to the algebraic
ornamentation using BSAlg R S.
6.3.2
Ornamental algebraic ornamentation
In previous work [Ko and Gibbons, 2011], promotion predicates were computed
from ornaments by “ornamental algebraic ornamentation”, i.e., algebraic orna-
mentation with an ornamental algebra. This dissertation, on the other hand,
uses parallel composition with singleton ornamentation to compute (optimised)
ornamental promotion predicates. Using a part of the categorical equivalence,
we can show that the two approaches indeed yield isomorphic predicates by
reasoning in terms of relational algebras.
Let O : Orn e D E where D : Desc I and E : Desc J. Our goal is to show that
the datatype obtained by algebraic ornamentation of E using the ornamental
algebra
fun (ornAlg O) : F E (µ D ◦e) ⇝(µ D ◦e)
is isomorphic to the optimised predicate datatype for O, i.e.,
Iso Fam (Σ J (µ D ◦e) , µ ⌊algOD E (fun (ornAlg O))⌋)
(e ▷◁outl
, µ ⌊O ⊗⌈S⌉⌋)
where S = singletonOD D. By isomorphism preservation of Ind, it sufﬁces to
establish
Iso Orn (Σ J (µ D ◦e) , ⌊algOD E (fun (ornAlg O))⌋)
(e ▷◁outl
, ⌊O ⊗⌈S⌉⌋)
(6.3)
We are attempting to establish that an algebraic ornamentation of E is iso-
morphic to some other description; if that description is also an algebraic
ornamentation of E, then we can just reason in terms of their algebras. This is
easy: from any ornament P : Orn f E ⌊O ⊗⌈S⌉⌋we get an isomorphism
Iso Orn (e ▷◁outl
, ⌊O ⊗⌈S⌉⌋)
(Σ J (Inv′ f) , ⌊algOD E (clsAlg P)⌋)

6.3
Consequences
193
and there is an obvious choice of P — diffOrn-l O ⌈S⌉. The proof obligation
thus reduces to
Iso Orn (Σ J (µ D ◦e)
, ⌊algOD E (fun (ornAlg O))⌋)
(Σ J (Inv′ outl▷◁) , ⌊algOD E (clsAlg (diffOrn-l O ⌈S⌉))⌋)
which, by isomorphism preservation of SliceF ⋄AlgOrn, is further reduced to
Iso (RAlg E) (µ D ◦e
, fun (ornAlg O))
(Inv′ outl▷◁, clsAlg (diffOrn-l O ⌈S⌉))
(6.4)
Through the categorical equivalence, reasoning about datatypes is now reduced
to reasoning about algebras. For the carriers, we need to show
µ D (e j) ∼= Σ[ p : e ▷◁outl ] outl▷◁p ≡j
for every j : J, which is easy since the canonical form of p is (ok j , ok (e j , d))
for some d : µ D (e j). Call the left-to-right direction of the isomorphism wrap:
wrap : {j : J} →µ D (e j) →Σ[ p : e ▷◁outl ] outl▷◁p ≡j
wrap {j} d = (ok j , ok (e j , d)) , reﬂ
For the algebras, however, it seems that we can only dig painfully into the
deﬁnitions. Here is an informal (but already painful) analysis explaining why
the two algebras express the same relationship: Let j : J, ds : [[ E j ]] (µ D ◦e),
and d : µ D (e j).
• The type fun (ornAlg O) ds d reduces to con (erase O ds) ≡d. Matching d
with con ds′ where ds′ : [[ D (e j) ]] (µ D), we get to an isomorphic type
erase O ds ≡ds′. Since erase modiﬁes only the shape part, this decomposes
into two conditions: (i) that the result of applying eraseS (O (ok j)) to the
shape part of ds is equal to the shape part of ds′, and (ii) that the series of
(µ D)-inhabitants contained in ds and ds′ are equal.
• On the other hand, setting wds = mapRD (E j) wrap ds, a proof of type
clsAlg (diffOrn-l O ⌈S⌉) wds (wrap (con ds′))
contains a shape of type
S (toRDesc (pcROD (O (ok j)) (⌈S⌉(ok (e j , con ds′)))))
satisfying the associated equations. By pcROD-iso, this decomposes into two
shapes ts : S (E j) and ss : S (⌊S⌋(e j , con ds′)) such that

194
6
Categorical equivalence of ornaments and relational algebras
eraseS (O (ok j)) ts ≡eraseS (⌈S⌉(ok (e j , con ds′))) ss
The right-hand side is equal to the shape part of ds′, and by the ﬁrst equa-
tion associated with ts, the left-hand side is equal to the result of applying
eraseS (O (ok j)) to the shape part of wds, i.e., the shape part of ds — this
corresponds to condition (i). For condition (ii), ⌊S⌋uses the (µ D)-inhabitants
contained in ds′ as the indices at the recursive positions, which, by the second
equation associated with ts, are just the (µ D)-inhabitants contained in wds,
i.e., those contained in ds.
6.4
Discussion
As mentioned at the beginning of the chapter, these results are only partially
formalised. Speciﬁcally, the formalised results include
• everything in Section 6.1,
• general deﬁnition of categorical equivalences (which, unlike general iso-
morphisms of categories, can be easily deﬁned with our formalisation of
categories),
• deﬁnition of RAlg,
• the isomorphism algROD-iso,
• the completeness theorem (6.1) for a different version of classifying algebras,
and
• the banana-split algebra as a product in RAlg.
The rest are worked out on paper, skipping over impractically tedious type-
theoretic detail — the problems about formalisation mentioned in Section 4.4
escalate into unmanageable ones for the constructions in this chapter due to
their greater complexity. In general, while the internalist typing of constructions
about descriptions and ornaments works well in Chapter 3, ensuring that every
expression we write down makes sense, the encoded constraints need to be
reasoned about non-trivially in this chapter, and this is greatly hindered because
the constraints are implicitly coupled with the expressions in a particular way —
here externalism could be much more helpful. For a simplest example, in this

6.4
Discussion
195
chapter we silently abandon the internalist type Inv and switch to the externalist
type Inv′; Goal 3 is much easier to discharge as a consequence. Another example
is classifying algebras, which (as mentioned above) were deﬁned differently
such that they were directly related to optimised predicates (Section 3.3.1). This
alternative deﬁnition yields optimised representation of membership proofs
about classifying algebras, but the representation is more complicated and
makes the categorical equivalence more difﬁcult to construct. Hence in this
dissertation we switch to an externalist deﬁnition of classifying algebras instead.
The categorical equivalence prompts us to contemplate again why we need
ornaments: if relational algebras can express the same reﬁnement relationship
between datatypes as ornaments, and can offer corresponding constructions as
shown in Section 6.3.1, what extra beneﬁt do ornaments provide that justiﬁes
their existence? Firstly, relational algebras describe how to classify inhabitants
of existing datatypes to obtain more informative datatypes, and hence cor-
respond more closely to ornamental descriptions, which are more restrictive
than ornaments as explained in the beginning of Section 3.5 — indeed, the
categorical equivalence is between RAlg and the slice category on top of Orn.
Even when we restrict the comparison to one between relational algebras and
ornamental descriptions, the latter still offer ﬁner-grained control of representa-
tion, down to the level of individual ﬁelds. For example, while we can get a
datatype of vectors by specialising AlgList with a suitable algebra, the index-ﬁrst,
representation-optimised version can only be obtained via ornamentation. We
can thus think of ornamental descriptions as a form of relational algebras that
allow us to additionally specify representation optimisation, and the categorical
equivalence lets us switch between the two forms of speciﬁcations of datatype
reﬁnement relationships.
The example about ornamental algebraic ornamentation in Section 6.3.2
shows that we can reduce reasoning about datatypes to reasoning about alge-
bras via the categorical equivalence. The discharging of the proof obligation (6.4)
is unsatisfactory, however — discharging the earlier proof obligation (6.3) could
in fact be more straightforward. For the reduction to be justiﬁed, reasoning
about algebras has to be easier, e.g., in the calculational style of Bird and
de Moor [1997]. This requires formulation of calculational laws for algebras

196
6
Categorical equivalence of ornaments and relational algebras
deﬁned datatype-generically on top of the universes of descriptions and orna-
ments; furthermore, these laws have to be strengthened to establish isomor-
phisms — rather than merely bi-implications — between algebras. (The lemma
fun-preserves-fold stated at the end of Section 5.1 is an example.) In short: the
categorical equivalence points out not only the possibility of reasoning about
datatypes algebraically, but also the need for algebraic reasoning to receive a
proof-relevant revision for that purpose.

Chapter 7
Conclusion
We have shown that an interconnection between internalism and external-
ism (Section 2.5) can be established in the form of conversion isomorphisms
between inductive families and their less informative variants paired with suit-
able predicates. Using ornaments (Section 3.2), two datatype-generic ways of
computing components in conversion isomorphisms are proposed:
• analytically, given two variants of inductive families related by an ornament,
we can compute the optimised predicate (Section 3.3.1) that captures the
residual part of the more informative variant relative to the less informative
one;
• synthetically, given a relational fold (Section 5.1) — which is a predicate —
on an inductive family, we can compute the algebraically ornamented version
of the inductive family (Section 5.2), into which proofs about the relational
fold are embedded.
Actual conversion isomorphisms are computed by the reﬁnement semantics of
ornaments (Section 3.3), which completes the analytic direction; the conversion
isomorphisms for the synthetic direction are indirectly computed through the
reﬁnement semantics and predicate swapping (Section 3.3.2). The analysis
and synthesis of inductive families then respectively lead to two applications
in internalist programming, both supported by several examples (Sections
3.4 and 5.3):
197

198
7
Conclusion
• By computing the optimised predicates, we can consider their pointwise
conjunction, which corresponds to the composite inductive family computed
by parallel composition (Section 3.2.3). With the help of the mechanism of
reﬁnements (Section 3.1) and upgrades (Section 3.1.2), we are then able to
synthesise composite internalist datatypes and operations from externalist
library modules.
• Starting from a relational speciﬁcation, which involves relational folds or can
be transformed to one involving relational folds, we translate the speciﬁcation
into an internalist type involving algebraically ornamented datatypes for
type-directed programming. Any program inhabiting this internalist type
can be analysed to yield proofs about relational folds for discharging the
speciﬁcation.
In respective applications, analysis and synthesis are followed by synthesis and
analysis. Hence both applications essentially rely on change of representation:
internalist datatypes and operations are switched to their externalist represen-
tations for modular composition, and externalist relational speciﬁcations are
converted to internalist types to be discharged by type-directed programming —
both deriving beneﬁt from the other side by changing representation back and
forth.
Theoretically, both parallel composition and algebraic ornamentation receive
further characterisation by category-theoretic notions, the former as a pull-
back (Section 4.2) and the latter as part of a categorical equivalence (Section 6.2).
Consequently:
• parallel composition is pinned down extensionally up to isomorphism, and
from its pullback properties we can construct the ornamental conversion
isomorphisms and the modularity isomorphisms (Section 4.3), abstracting
away from encoding detail of the universes;
• the categorical equivalence in which algebraic ornamentation takes part
establishes a correspondence between ornamental and relational algebraic
universal constructions, like parallel composition and the banana-split alge-
bra (Section 6.3.1); it also reveals the possibility of reasoning about datatypes
in terms of relational algebras (Section 6.3.2).

7
Conclusion
199
The whole development of this dissertation is a demonstration of the need for
internalism and externalism to coexist: The datatype of ornaments is indexed
by descriptions such that every typechecked ornament is a valid one between
the descriptions in its type; various subsequent constructions (e.g., parallel
composition) then manipulate valid ornaments only, without having to deal
with nonsensical cases. Categorical properties, on the other hand, can hardly
be encoded into the types of these constructions, and hence need to be proved
separately. Formal reasoning about complicatedly typed terms in Agda is
exceedingly difﬁcult, however — the actual proof terms are skipped over
throughout the presentation since most of them are incomprehensible if not
boring. Given that the formalisation of Chapter 4 already demonstrates the
possibility, complete formalisation of Chapter 6 is deemed unfruitful since it can
further demonstrate nothing but perseverance that should actually be avoided
— instead, better ways to manage such reasoning are needed.
Putting formalisation aside, the theoretical development in Chapters 4 and 6
— while achieving the goals successfully — is admittedly rather brute-force, and
has much room for improvement. In particular, the apparent similarity among
the indexing structures of Orn, Fref, Fam, and FHTrans points to a more
systematic treatment by ﬁbred category theory [Jacobs, 1999]. On the practical
side, efﬁciency is an important issue yet to be investigated: both the synthesis of
internalist operations using upgrades and the analysis of internalist programs
for discharging relational speciﬁcations rely on change of representation com-
puted from ornaments, but it is not yet clear how much of the representation
change can be optimised away. Also, while Agda already provides helpful
syntax (e.g., implicit arguments and dependent pattern matching) and we have
invoked the yet-to-exist elaboration mechanism from higher-level presentations
of datatypes and functions to their encodings throughout the dissertation, it is
still desirable to have more notational innovation to improve readability and
even some degree of automation to suppress obvious proofs. An excellent
example is McBride’s treatment of ordered data structures [2014] using Agda’s
instance arguments [Devriese and Piessens, 2011] as a lightweight proof search-
ing mechanism to pass around ordering proofs silently — a technique that can
dramatically improve the appearance of, e.g., the merge function on leftist heaps

200
7
Conclusion
shown in Figure 3.9.
We conclude this dissertation with a ﬁnal remark on internalism. The most
important technique used in this dissertation is undoubtedly type computa-
tion, ranging from simpler ones like upgrades and predicate swaps to more
sophisticated ones involving universes like various ornamental constructions.
With internalism, this seems to be a natural tendency: as types start to play a
more signiﬁcant role of speciﬁcations (as opposed to the traditional, minor role
that ensures only basic sanity) and have direct inﬂuence on program structure,
their design requires more attention and mechanisation to the extent that it has
really become programming. Thus it probably should not come as a surprise
that relational program derivation is employed in this dissertation for type
derivation. Stretching the imagination, perhaps internalism will eventually
lead to a uniﬁcation of types and programs, yielding a uniform and scalable
system for program correctness by construction that consists of only levels of
programs, one level acting as speciﬁcations for the next, such that the idea of
“levels of abstraction” (see, e.g., Dijkstra [1972]) can be formally captured, and
programming techniques can be uniformly applied to all levels.

Bibliography
Thorsten Altenkirch, James Chapman, and Tarmo Uustalu [2010]. Monads
need not be endofunctors. In Foundations of Software Science and Computational
Structures, volume 6014 of Lecture Notes in Computer Science, pages 297–311.
Springer-Verlag. doi: 10.1007/978-3-642-12032-9_21. ↰page 139
Thorsten Altenkirch and Conor McBride [2003].
Generic programming
within dependently typed programming. In IFIP TC2/WG2.1 Working Con-
ference on Generic Programming, pages 1–20. Kluwer, B.V.
doi: 10.1007/
978-0-387-35672-3_1. ↰page 24
Thorsten Altenkirch, Conor McBride, and Wouter Swierstra [2007]. Obser-
vational equality, now! In Programming Languages meets Program Veriﬁcation,
PLPV’07, pages 57–68. ACM. doi: 10.1145/1292597.1292608. ↰page 23
Robert Atkey, Patricia Johann, and Neil Ghani [2012]. Reﬁning inductive types.
Logical Methods in Computer Science, 8(2:9). doi: 10.2168/LMCS-8(2:9)2012.
↰page 170
Jeremy Avigad, Kevin Donnelly, David Gray, and Paul Raff [2007].
A
formally veriﬁed proof of the prime number theorem. ACM Transactions on
Computational Logic, 9(1):2. doi: 10.1145/1297658.1297660. ↰page 135
John Backus [1978]. Can programming be liberated from the von Neumann
style? A functional style and its algebra of programs. Communications of the
ACM, 21(8):613–641. doi: 10.1145/359576.359579. ↰page 138
Gilles Barthe, Venanzio Capretta, and Olivier Pons [2003]. Setoids in type
201

202
Bibliography
theory.
Journal of Functional Programming, 13(2):261–293.
doi: 10.1017/
S0956796802004501. ↰pages 24 and 110
Jean-Philippe Bernardy [2011]. A Theory of Parametric Polymorphism and an
Application. Ph.D. thesis, Chalmers University of Technology. ↰page 104
Jean-Philippe Bernardy and Moulin Guilhem [2013]. Type theory in color.
In International Conference on Functional Programming, ICFP’13, pages 61–72.
ACM. doi: 10.1145/2500365.2500577. ↰pages 99 and 104
Yves Bertot and Pierre Castéran [2004]. Interactive Theorem Proving and Program
Development — Coq’Art: The Calculus of Inductive Constructions. Springer-Verlag.
ISBN: 978-3540208549. ↰page 35
Richard Bird [1996]. Functional algorithm design. Science of Computer Program-
ming, 26(1–3):15–31. doi: 10.1016/0167-6423(95)00033-X. ↰page 138
Richard Bird [2010]. Pearls of Functional Algorithm Design. Cambridge University
Press. ISBN: 978-0521513388. ↰page 138
Richard Bird and Oege de Moor [1997]. Algebra of Programming. Prentice-Hall.
ISBN: 978-0135072455. ↰pages 4, 41, 137, 142, 146, 147, 159, 160, 175, and 195
Richard Bird and Jeremy Gibbons [2003].
Arithmetic coding with folds
and unfolds.
In Advanced Functional Programming, volume 2638 of Lec-
ture Notes in Computer Science, pages 1–26. Springer-Verlag. doi: 10.1007/
978-3-540-44833-4_1. ↰pages 146, 151, and 157
Errett Bishop and Douglas Bridges [1985]. Constructive Analysis. Springer-
Verlag. ISBN: 978-3642649059. ↰page 2
Ana Bove and Peter Dybjer [2009].
Dependent types at work.
In Lan-
guage Engineering and Rigorous Software Development, volume 5520 of Lec-
ture Notes in Computer Science, pages 57–99. Springer-Verlag. doi: 10.1007/
978-3-642-03153-3_2. ↰page 4
Edwin Brady, Conor McBride, and James McKinna [2004]. Inductive families
need not store their indices. In Types for Proofs and Programs, volume 3085

Bibliography
203
of Lecture Notes in Computer Science, pages 115–129. Springer-Verlag. doi: 10.
1007/978-3-540-24849-1_8. ↰page 27
Venanzio Capretta [2000]. Recursive families of inductive types. In Theorem
Proving in Higher Order Logics, volume 1869 of Lecture Notes in Computer Science,
pages 73–89. Springer-Verlag. doi: 10.1007/3-540-44659-1_5. ↰page 26
James Chapman, Pierre-Évariste Dagand, Conor McBride, and Peter Morris
[2010]. The gentle art of levitation. In International Conference on Functional
Programming, ICFP’10, pages 3–14. ACM. doi: 10.1145/1863543.1863547.
↰pages 24, 64, and 102
R. L. Constable, S. F. Allen, H. M. Bromley, W. R. Cleaveland, J. F. Cremer,
R. W. Harper, D. J. Howe, T. B. Knoblock, N. P. Mendler, P. Panangaden,
J. T. Sasaki, and S. F. Smith [1985]. Implementing Mathematics with the Nuprl
Proof Development System. Prentice-Hall. ISBN: 978-1468059106. ↰page 22
Thierry Coquand and Gérard Huet [1988]. The Calculus of Constructions.
Information and Computation, 76(2–3):95–120. doi: 10.1016/0890-5401(88)
90005-3. ↰page 35
Thierry Coquand and Christine Paulin-Mohring [1990].
Inductively de-
ﬁned types. In International Conference on Computer Logic, volume 417 of
Lecture Notes in Computer Science, pages 50–66. Springer-Verlag. doi: 10.1007/
3-540-52335-9_47. ↰pages 27 and 35
Pierre-Évariste Dagand and Conor McBride [2012]. Elaborating inductive
deﬁnitions. arXiv:1210.6390. ↰page 32
Pierre-Évariste Dagand and Conor McBride [2013]. A categorical treatment
of ornaments. In Logic in Computer Science, LICS’13, pages 530–539. IEEE.
doi: 10.1109/LICS.2013.60. ↰page 133
Pierre-Évariste Dagand and Conor McBride [2014]. Transporting functions
across ornaments. Journal of Functional Programming, 24(2–3):316–383. doi: 10.
1017/S0956796814000069. ↰pages 24, 25, and 103

204
Bibliography
Dominique Devriese and Frank Piessens [2011]. On the bright side of type
classes: Instance arguments in Agda. In International Conference on Functional
Programming, ICFP’11, pages 143–155. ACM. doi: 10.1145/2034773.2034796.
↰page 199
Edsger W. Dijkstra [1972]. Notes on structured programming. In Structured
Programming, pages 1–82. Academic Press. ISBN: 978-0122005503. ↰page 200
Edsger W. Dijkstra [1974]. Programming as a discipline of mathematical nature.
American Mathematical Monthly, 81(6):608–612. doi: 10.2307/2319209. ↰page 1
Edsger W. Dijkstra [1976].
A Discipline of Programming.
Prentice-Hall.
ISBN: 978-0132158718. ↰pages 2 and 35
Edsger W. Dijkstra [1982].
On the role of scientiﬁc thought.
In Selected
Writings on Computing: A Personal Perspective, pages 60–66. Springer-Verlag.
doi: 10.1007/978-1-4612-5695-3_12. ↰pages 1 and 106
Michael Dummett [2000]. Elements of Intuitionism. Oxford University Press,
second edition. ISBN: 978-0198505242. ↰pages 2, 8, and 19
Peter Dybjer [1994]. Inductive families. Formal Aspects of Computing, 6(4):440–465.
doi: 10.1007/BF01211308. ↰pages 3 and 12
Peter Dybjer [1998]. A general formulation of simultaneous inductive-recursive
deﬁnitions in type theory. Journal of Symbolic Logic, 65(2):525–549. doi: 10.
2307/2586554. ↰page 28
Peter Dybjer and Anton Setzer [2006]. Indexed induction-recursion. Journal
of Logic and Algebraic Programming, 66(1):1–49. doi: 10.1016/j.jlap.2005.07.
001. ↰page 170
Maarten M. Fokkinga [1992]. Law and Order in Algorithmics. Ph.D. thesis,
University of Twente. ↰page 190
Nicola Gambino and Joachim Kock [2010]. Polynomial functors and polynomial
monads. arXiv:0906.4931. ↰page 133

Bibliography
205
Gerhard Gentzen [1964]. Investigations into natural deduction. American
Philosophical Quarterly, 1(4):288–306. URL: http://www.jstor.org/stable/
20009142. ↰page 2
Jeremy Gibbons [2007a]. Datatype-generic programming. In Spring School
on Datatype-Generic Programming, volume 4719 of Lecture Notes in Computer
Science, pages 1–71. Springer-Verlag. doi: 10.1007/978-3-540-76786-2_1.
↰page 24
Jeremy Gibbons [2007b]. Metamorphisms: Streaming representation-changers.
Science of Computer Programming, 65(2):108–139. doi: 10.1016/j.scico.2006.
01.006. ↰pages 151 and 155
Healfdene Goguen, Conor McBride, and James McKinna [2006]. Eliminating
dependent pattern matching. In Algebra, Meaning, and Computation, volume
4060 of Lecture Notes in Computer Science, pages 521–540. Springer-Verlag.
doi: 10.1007/11780274_27. ↰page 13
David
Gries
[1981].
The Science of Programming.
Springer-Verlag.
ISBN: 978-0387964805. ↰page 2
Robert Harper and Robert Pollack [1991]. Type checking with universes. The-
oretical Computer Science, 89(1):107–136. doi: 10.1016/0304-3975(90)90108-T.
↰page 110
Arend Heyting [1971].
Intuitionism: An Introduction.
Amsterdam: North-
Holland Publishing, third revised edition. ISBN: 978-0720422399. ↰pages 2
and 8
C. A. R. Hoare [1969]. An axiomatic basis for computer programming. Commu-
nications of the ACM, 12(10):576–580. doi: 10.1145/363235.363259. ↰page 1
Paul Hudak, John Hughes, Simon Peyton Jones, and Philip Wadler [2007]. A
history of Haskell: Being lazy with class. In History of Programming Languages,
HOPL-III, pages 1–55. ACM. doi: 10.1145/1238844.1238856. ↰page 12
Bart Jacobs [1999].
Categorical Logic and Type Theory.
Elsevier B.V.
ISBN: 978-0444508539. ↰pages 133 and 199

206
Bibliography
Anne Kaldewaij [1990]. Programming: The Derivation of Algorithms. Prentice-Hall.
ISBN: 978-0132041089. ↰page 2
Hsiang-Shang Ko and Jeremy Gibbons [2011]. Modularising inductive families.
In Workshop on Generic Programming, WGP’11, pages 13–24. ACM. doi: 10.
1145/2036918.2036921. ↰page 192
Hsiang-Shang Ko and Jeremy Gibbons [2013a]. Modularising inductive families.
Progress in Informatics, 10:65–88. doi: 10.2201/NiiPi.2013.10.5. ↰pages 5
and 133
Hsiang-Shang Ko and Jeremy Gibbons [2013b]. Relational algebraic ornaments.
In Dependently Typed Programming, DTP’13, pages 37–48. ACM. doi: 10.1145/
2502409.2502413. ↰page 5
Xavier Leroy [2009]. A formally veriﬁed compiler back-end. Journal of Automated
Reasoning, 43(4):363–446. doi: 10.1007/s10817-009-9155-4. ↰page 35
Pierre Letouzey [2003]. A new extraction for Coq. In Types for Proofs and
Programs, volume 2646 of Lecture Notes in Computer Science, pages 200–219.
Springer-Verlag. doi: 10.1007/3-540-39185-1_12. ↰page 35
Zhaohui Luo [1994]. Computation and Reasoning: A Type Theory for Computer
Science. Clarendon Press. ISBN: 978-0198538356. ↰pages 20 and 35
Saunders Mac Lane [1998]. Categories for the Working Mathematician. Springer-
Verlag, second edition. ISBN: 978-0387984032. ↰pages 108 and 122
Per Martin-Löf [1975]. An intuitionistic theory of types: Predicative part.
In Logic Colloquium ’73, volume 80 of Studies in Logic and the Foundations
of Mathematics, pages 73–118. Elsevier B.V. doi: 10.1016/S0049-237X(08)
71945-1. ↰pages 2 and 8
Per Martin-Löf [1984a]. Constructive mathematics and computer program-
ming. Philosophical Transactions of the Royal Society of London, 312(1522):501–518.
doi: 10.1098/rsta.1984.0073. ↰page 11
Per Martin-Löf [1984b]. Intuitionistic Type Theory. Bibliopolis, Napoli. ↰pages 2,
8, 24, and 28

Bibliography
207
Per Martin-Löf [1987]. Truth of a proposition, evidence of a judgement, validity
of a proof. Synthese, 73(3):407–420. doi: 10.1007/BF00484985. ↰pages 3 and 9
Conor McBride [1999]. Dependently Typed Functional Programs and their Proofs.
Ph.D. thesis, University of Edinburgh. ↰pages 13, 23, and 114
Conor McBride [2004]. Epigram: Practical programming with dependent types.
In Advanced Functional Programming, volume 3622 of Lecture Notes in Computer
Science, pages 130–170. Springer-Verlag. doi: 10.1007/11546382_3. ↰pages 3,
13, and 36
Conor McBride [2011]. Ornamental algebras, algebraic ornaments. URL: https:
//personal.cis.strath.ac.uk/conor.mcbride/pub/OAAO/LitOrn.pdf.
↰pages 4, 32, 101, 103, 146, 170, and 175
Conor McBride [2012]. A polynomial testing principle. URL: https://personal.
cis.strath.ac.uk/conor.mcbride/PolyTest.pdf. ↰page 37
Conor McBride [2014]. How to keep your neighbours in order. URL: https:
//personal.cis.strath.ac.uk/conor.mcbride/Pivotal.pdf.
↰pages 25
and 199
Conor McBride and James McKinna [2004]. The view from the left. Journal
of Functional Programming, 14(1):69–111. doi: 10.1017/S0956796803004829.
↰pages 13, 16, 17, and 18
Conor McBride and Ross Paterson [2008].
Applicative programming
with effects. Journal of Functional Programming, 18(1):1–13. doi: 10.1017/
S0956796807006326. ↰page 139
James McKinna [2006]. Why dependent types matter. In Principles of Pro-
gramming Languages, POPL’06, page 1. ACM. doi: 10.1145/1111037.1111038.
URL: http://www.cs.nott.ac.uk/~txa/publ/ydtm.pdf. ↰page 3
Lambert Meertens [1992].
Paramorphisms.
Formal Aspects of Computing,
4(5):413–424. doi: 10.1007/BF01211391. ↰page 12

208
Bibliography
Erik Meijer, Maarten Fokkinga, and Ross Paterson [1991]. Functional pro-
gramming with bananas, lenses, envelopes and barbed wire. In Functional
Programming Languages and Computer Architecture, number 523 in Lecture
Notes in Computer Science, pages 124–144. Springer-Verlag. doi: 10.1007/
3540543961_7. ↰pages 12 and 143
Eugenio Moggi [1991]. Notions of computation and monads. Information and
Computation, 93(1):55–92. doi: 10.1016/0890-5401(91)90052-4. ↰page 139
Peter Morris [2007]. Constructing Universes for Generic Programming. Ph.D.
thesis, University of Nottingham. ↰pages 34 and 177
Shin-Cheng Mu, Hsiang-Shang Ko, and Patrik Jansson [2009]. Algebra of
Programming in Agda: Dependent types for relational program deriva-
tion.
Journal of Functional Programming, 19(5):545–579.
doi: 10.1017/
S0956796809007345. ↰pages 111, 150, and 169
Shin-Cheng Mu and José Nuno Oliveira [2012]. Programming from Galois
connections. Journal of Logic and Algebraic Programming, 81(6):680–704. doi: 10.
1016/j.jlap.2012.05.003. ↰page 170
Keisuke Nakano [2013]. Metamorphism in jigsaw. Journal of Functional Program-
ming, 23(2):161–173. doi: 10.1017/S0956796812000391. ↰page 151
Bengt Nordström [1988]. Terminating general recursion. BIT Numerical Mathe-
matics, 28(3):605–619. doi: 10.1007/BF01941137. ↰page 156
Bengt Nordström, Kent Peterson, and Jan M. Smith [1990].
Program-
ming in Martin-Löf’s Type Theory: An Introduction. Oxford University Press.
ISBN: 978-0198538141. ↰pages 2, 8, 22, 24, and 35
Ulf Norell [2007]. Towards a Practical Programming Language based on Dependent
Type Theory. Ph.D. thesis, Chalmers University of Technology. ↰pages 4 and 17
Ulf Norell [2009]. Dependently typed programming in Agda. In Advanced
Functional Programming, volume 5832 of Lecture Notes in Computer Science,
pages 230–266. Springer-Verlag. doi: 10.1007/978-3-642-04652-0_5. ↰page 4

Bibliography
209
Chris Okasaki [1999]. Purely functional data structures. Cambridge University
Press. ISBN: 978-0521663502. ↰pages 79, 82, 90, 93, and 98
Christine Paulin-Mohring [1989]. Extracting Fω’s programs from proofs in
the Calculus of Constructions. In Principles of Programming Languages, pages
89–104. ACM. doi: 10.1145/75277.75285. ↰page 35
Simon Peyton Jones [1997]. A new view of guards. URL: http://research.
microsoft.com/en-us/um/people/simonpj/Haskell/guards.html. ↰page 16
Dag Prawitz [2006]. Natural Deduction: A Proof-theoretical Study. Dover Publica-
tions. ISBN: 978-0486446554. ↰page 2
Tim Sheard and Nathan Linger [2007].
Programming in Ωmega.
In
Central-European Functional Programming School, volume 5161 of Lecture
Notes in Computer Science, pages 158–227. Springer-Verlag. doi: 10.1007/
978-3-540-88059-2_5. ↰pages 22 and 63
Jan M. Smith [1988]. The independence of Peano’s fourth axiom from Martin-
Löf’s type theory without universes. Journal of Symbolic Logic, 53(3):840–845.
doi: 10.2307/2274575. ↰page 24
Thomas Streicher [1993]. Investigations into intensional type theory. Habilita-
tion thesis, Ludwig Maximilian Universität. ↰pages 13 and 20
Wouter Swierstra [2008]. Data types à la carte. Journal of Functional Program-
ming, 18(4):423–436. doi: 10.1017/S0956796808006758. ↰pages 102 and 104
The Univalent Foundations Program [2013]. Homotopy Type Theory: Uni-
valent Foundations of Mathematics. Institute for Advanced Study, Princeton.
URL: http://homotopytypetheory.org/book/. ↰pages 23 and 24
Philip Wadler [1987]. Views: A way for pattern matching to cohabit with
data abstraction. In Principles of Programming Languages, pages 307–313. ACM.
doi: 10.1145/41625.41653. ↰page 17
Philip Wadler [1989]. Theorems for free! In Functional Programming Languages
and Computer Architecture, FPCA’89, pages 347–359. ACM. doi: 10.1145/
99370.99404. ↰page 105

210
Bibliography
Philip Wadler [1992]. The essence of functional programming. In Principles
of Programming Languages, POPL’92, pages 1–14. ACM. doi: 10.1145/143165.
143169. ↰page 139

Index of global deﬁnitions
α, 161
∆, 57, 61
µ, 28
Σ, 28
σ, 29, 57, 61
!, 59
∆
, 57, 61
⩽-reﬂ, 16
⩽-trans, 16
⩽N-elim, 15
≰-invert, 16
⊗-FSwap, 77
⊤, 27
, 27
⊥, 17
⌈⌉, 61
⌊⌋, 61
⌊⌋T, 102
[[ ]], 29
1p, 157
2p, 157
5p, 157
<-rec, 169
[], 16, 25, 26, 31, 58
• , 140
−1 , 53
⇝, 140
⇀, 52
⇒, 28
∧, 9
∩, 140
:: , 16, 25, 26, 31, 58
≃, 141
∼= , 118
˙≊, 114
≊, 114
.= , 21
≡, 20
⩽? , 16
⩽C , 158
⩽N , 12
⩽, 16
⊆, 141
⊇, 141
⊕, 102
⊗, 67
⊙, 116
⋄, 117
211

212
Index of global deﬁnitions
▷◁, 65
▽
, 46
▽, 103
∗, 41
++ , 31, 35
+ , 35, 102
, , 28, 65, 122, 180, 187
, , , 120, 121
/ , 183
⟨$⟩, 139
⟨$⟩2, 139
>>= , 139
([ ]), 143
◦, 140
×+ , 148
˙× , 191
× , 29
‘cons, 30
‘nil, 30, 85, 94
‘node, 94
‘one, 85
‘zero, 85
¬, 17
AlgList, 144
AlgListP, 144
AlgOrn, 183
above-zero, 169
algOD, 145
algOD-FSwap, 145
algROD, 145
algROD-decomp, 185
algROD-iso, 185
any, 138
append-length, 36
attach, 85
BHeap, 86
BHeap′, 88
BHeapOD, 86
BSAlg, 191
BTree, 84
BTreeD, 84
BVec, 149
Bin, 85
BinD, 85
BinTag, 85
bcons, 162
bnil, 162
Category, 112
ClsAlg, 183
Coin, 157
CoinBag, 158
CoinBag′, 162
CoinBag′OD, 162
CoinBag′View, 163
CoinBagOD, 158
CoinOrderedView, 163
Com, 114
canonRef, 46
cb′-relax, 166
clsAlg, 187
coherence, 47
compare-with-zero, 169
con, 28
cong, 21
cons, 26, 45, 63, 144
const, 33

Index of global deﬁnitions
213
consumption-iso, 153
curry, 145
Dec, 16
Desc, 28
descend, 84
diff-E-l, 70
diffOrn-l, 70
diffOrn-r, 71
diffROrn-l, 70
diffROrn-l-double
∆
, 70
double, 49
duplicate, 49
duplicate′, 49
E, 58
E-reﬂ, 116
E-trans, 116
Erase, 181
ExtOrdList, 39
ExtOrdVec, 40
ExtVec, 38
erase, 57
eraseS, 179
erode, 63
F, 28
F-map, 190
FHTrans, 180
FHTrans, 180
Fref, 113
FRefC, 115
FRefF, 115
FReﬁnement, 53
FSwap, 77
Fam, 113
FamF, 114
Fun, 111
Fun-graph, 109
FunSetoid, 111
Functor, 112
ﬁxed, 80
ﬁxed′, 80
fold, 32
foldl, 152
foldl-alg, 152
forget, 57
forget-iso, 46
fromEq, 67
fun, 140
fun-preserves-fold, 143
fusion-conversion⊆, 147
fusion-conversion⊇, 149
Graph, 109
GreedyBag, 167
GreedyBagOD, 167
gcons, 167
gcons′, 168
geq, 149
gnil, 167
gnil′, 167
greedy, 168
greedy-lemma, 164
HTrans, 180
Heap, 95
Heap′, 96
HeapOD, 95
halve, 92

214
Index of global deﬁnitions
halve′, 91
hori-decomp, 178
horizontal-iso, 178
ITree, 97
ITreeD-HeapD, 98
ITreeOD, 97
Ind, 117
Inv, 54
Inv′, 173
Iso, 118
id, 20
id′, 20
id-FSwap, 78
idOrn, 116
idR, 140
idROrn, 116
idRef, 97
incr, 87
incr-insT-coherence, 89
init, 18
inl, 102
inr, 103
inlOrn, 103
inrOrn, 103
insT, 89
insT′, 89
insV, 87
insert, 17
insertEO, 39
insertEOV, 40
insertEV, 39
insertO, 81
insertOV, 81
insertV, 81
insertV-coherence, 81
insert-length, 39
insert-ordered, 39
is-zero, 169
LHeap, 95
LHeapOD, 95
LTree, 95
LTreeOD, 95
Length, 74
Length-FSwap, 78
List, 16, 26, 31
ListD, 30
ListD-VecD, 59
ListS, 63
ListSOD, 63
ListTag, 30
left, 91
length, 33, 55
length-alg, 33
leq, 142
lhrelax, 96
link, 85
makeT, 99
mapBHeap, 92
mapBHeap′, 91
mapFold, 32
mapFoldR, 143
mapRD, 32
mapRDR, 141
maximum-coin, 168
merge, 99
merge′, 99

Index of global deﬁnitions
215
meta, 152
min-coin-change, 159
min
• Λ , 157
Nat, 12, 25
Nat-List, 45
Nat-elim, 10
NatD, 30
NatD-ListD, 59
Normal, 181
new, 80
new′, 80
new-Σ, 148
next, 178
next, 154
nil, 17, 26, 45, 63, 85, 86, 94–96, 100, 144
no, 17
node, 94–96, 100
normROrn, 180
normROrn-
∆
, 180
nothing, 154
OptP, 73
OptPOD, 73
OrdList, 45
OrdListOD, 62
OrdVec, 54
OrdVec-FSwap, 78
OrdVecOD, 66
Ordered, 39
OrderedLength, 76
Orn, 56
Orn, 113
OrnDesc, 61
OrnEq, 179
OrnEq-forget, 117
ok, 53
one, 86
ornAlg, 57
ornConvIso, 75
outl, 28
outl▷◁, 65
outr, 28
outr▷◁, 65
P, 29
P, 138
P-map, 63
P-toEq, 61
P-toList, 61
Product, 122
Pullback, 124
Pullback-preserving, 125
pc-E, 67
pc-square, 125
pcROD, 67
pcROD-double
∆
, 67
pcROD-iso, 182
preorder, 97
preorderIT, 97
production-iso, 153
pull, 65
R, 141
RAlg, 183
RAlgMorphism, 187
RAlgebra, 183
RDesc, 29
ROrn, 57
ROrnDesc, 61

216
Index of global deﬁnitions
RSem, 118
RSem, 75
Reﬁnement, 44
Reﬁnement′, 47
reﬂ, 20
relax, 96
return, 139
right, 91
root, 85
S, 178
Setoid, 110
Shape, 181
Singleton, 119
Slice, 122
SliceCategory, 123
SliceF, 132
SliceMap, 125
SliceMorphism, 122
SnocView, 17
Span, 120
SpanCategory, 121
SpanMorphism, 121
Square, 123
SquareCategory, 124
SquareMap, 125
StreamingCondition, 156
Swap, 77
scROrn, 116
shift, 90
shift-halve-coherence, 92
singleton, 64
singletonOD, 63
size, 159
size-alg, 158
snoc, 17
snocView, 17
step, 13
stream, 154
stream′, 153
streaming-lemma, 156
subst, 21
suc, 12, 25
TDesc, 102
Terminal, 119
Tree, 94
TreeD, 94
TreeTag, 94
TwinD, 102
terminal-iso, 120
toBin, 88
toBin-mapBHeap, 92
toEq, 61
toNat, 86
toRDesc, 61
toROrn, 61
toReﬁnement, 77
toReﬁnement′, 48
toUpgrade, 51
toUpgrade′, 51
total-value, 158
total-value-alg, 158
trans, 14
UIP, 23
Upgrade, 50
UsableCoin, 168
uncurry, 52

Index of global deﬁnitions
217
und, 54
und-fromEq, 70
Val, 16
Vec, 25, 26
Vec′, 26
Vec, 26
Vec-iso, 40
VecD, 31
VecF, 27
VecF′, 27
v, 29, 57, 61
value, 158
vertex, 124
view-CoinBag′, 163
view-ordered-coin, 163
WLHeap, 100
WLHeapD, 100
WLTree, 100
WLTreeOD, 100
wmerge, 101
wrap, 193
yes, 17
ZeroView, 169
zero, 12, 25, 86

