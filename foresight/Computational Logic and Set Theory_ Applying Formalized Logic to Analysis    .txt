
Computational Logic and Set Theory


Jacob T. Schwartz  Domenico Cantone 
Eugenio G. Omodeo
Computational
Logic and Set
Theory
Applying Formalized Logic to Analysis
Foreword by Martin Davis

Prof. Dr. Jacob T. Schwartz
(January 9, 1930–March 2, 2009)
New York University
New York, NY
USA
Prof. Domenico Cantone
Dept. of Mathematics & Computer Science
University of Catania
Viale Andrea Doria 6
95125 Catania
Italy
cantone@dmi.unict.it
Prof. Eugenio G. Omodeo
Dept. of Mathematics & Computer Science
University of Trieste
Via Valerio 12/1
34127 Trieste,
Italy
eomodeo@units.it
ISBN 978-0-85729-807-2
e-ISBN 978-0-85729-808-9
DOI 10.1007/978-0-85729-808-9
Springer London Dordrecht Heidelberg New York
British Library Cataloguing in Publication Data
A catalogue record for this book is available from the British Library
Library of Congress Control Number: 2011934034
© Springer-Verlag London Limited 2011
Apart from any fair dealing for the purposes of research or private study, or criticism or review, as per-
mitted under the Copyright, Designs and Patents Act 1988, this publication may only be reproduced,
stored or transmitted, in any form or by any means, with the prior permission in writing of the publish-
ers, or in the case of reprographic reproduction in accordance with the terms of licenses issued by the
Copyright Licensing Agency. Enquiries concerning reproduction outside those terms should be sent to
the publishers.
The use of registered names, trademarks, etc., in this publication does not imply, even in the absence of a
speciﬁc statement, that such names are exempt from the relevant laws and regulations and therefore free
for general use.
The publisher makes no representation, express or implied, with regard to the accuracy of the information
contained in this book and cannot accept any legal responsibility or liability for any errors or omissions
that may be made.
Cover design: VTeX UAB, Lithuania
Printed on acid-free paper
Springer is part of Springer Science+Business Media (www.springer.com)


Jacob Theodore “Jack” Schwartz (January 9, 1930–March 2, 2009), courtesy of Diana Robinson
Schwartz

Foreword
Jack Schwartz, the principal, but alas posthumous, author of this book, turned his
serious attention to computer science in the mid 1960s. At the time he had already
been recognized as a brilliant young mathematician, and the two volumes of the
magisterial Dunford–Schwartz Linear Operators already in print were widely ad-
mired. Jack saw that computers were going to have a revolutionary effect and that
the expansions of their use would give rise to many fundamental problems, and he
wanted to be part of that. He realized that as software became more complex the
question of how its correctness could be ensured would become ever more critical.
Moreover he saw formal logic embodied in computer programs as an important part
of the answer.
A substantial part of Jack’s research program in computer science derived from
his appreciation of the possibility of expressing mathematical discourse in the lan-
guage of set theory. In much the same way that the seventeenth century work of
Descartes and Fermat had shown that propositions of Euclid’s geometry could be
regarded as statements in the language of algebra, so the twentieth century con-
tributions of Russell, Zermelo, and von Neumann showed how propositions of the
various branches of mathematics could be regarded as statements in the language of
set theory. This appreciation led him in three directions:
1. He designed SETL, a general purpose high level programming language based
on the language of set theory. The need to achieve acceptable performance from
software written in a language that made no concessions to the vagaries of com-
puter architecture led to work on compiler optimization in fruitful collaboration
with researchers from IBM.
2. After studying Heinrich Behmann’s algorithm for the decision problem of sec-
ond order monadic predicate calculus, Jack saw that these methods could be ex-
tended to yield algorithms for decidable fragments of set theory. Over a period of
decades, working with a group of collaborators almost all from Italy, who were
ﬁrst students at New York University and then became distinguished scientists in
their own right, a surprising collection of non-trivial mathematics was found to
lie within the scope of such algorithms.
vii

viii
Foreword
3. Working with some of these same Italian researchers, a computer program was
designed and implemented (at least as a prototype) that could verify the cor-
rectness of mathematical proofs presented in the language of set theory. Jack
proposed to use this veriﬁer to certify the correctness of a substantial body of the
fundamentals of mathematical analysis. This was to include proofs of the basic
properties of the real and complex number systems deﬁned in set-theoretic terms,
the fundamental properties of limits, continuity and the differential and integral
calculus, and was to culminate in a proof of the Cauchy Integral Theorem of
complex analysis.
The present volume is concerned with this veriﬁer, its use and its context. How-
ever this context is to be understood in an extremely broad sense. Some of the work
on decidable fragments of set theory is presented in a context that includes other
algorithms from various sources for branches of logic as well. The main metamath-
ematical theorems covered in a modern course in mathematical logic are here: the
completeness theorem and the two incompleteness theorems of Gödel. Such topics
as reﬂection principles and large cardinals are here as well. Those familiar with Jack
Schwartz’s mode of thought and with his way of putting his own stamp on a ﬁeld
will have no trouble hearing his voice in this important thought-provoking book.
Martin Davis
Professor Emeritus, Courant Institute, New York University
Visiting Scholar, University of California, Berkeley

Preface
In June 2000, the third named author visited New York University and was invited
by Jack Schwartz to read what he called the (“common shared”) scenario: a wide,
carefully assembled sequence of deﬁnitions, theorems, and proofs, leading from
the bare rudiments of set theory to the beginning of mathematical analysis. Proofs
began to be gappy after a few hundred pages, and then totally absent, but the ﬂow
of deﬁnitions and theorems went on, to culminate in the deﬁnition of complex line
integral and ﬁnally in the celebrated Cauchy integral theorem of complex analysis.
With an implementation appearing all but imminent, Jack had cast a signiﬁcant
piece of mathematics in rigorous formal detail, honestly asking himself whether a
computer program could conceivably process and validate every single step. The
resulting large-scale proof scenario was meant—in Jack’s own words—“to serve as
an essential part of the feasibility study that must precede the development of any
ambitious proof-checker”. Eventually, it would also serve as a testing-bench for the
concrete implementation of the proof-checker.
The conception of this book on computational logic began then. According to our
initial plans, the book would have described the structure of a proof veriﬁer rooted
in set theory and would also have surveyed a twenty-year long stream of results on
decidable fragments of set theory.
One year later, the second named author visited New York in his turn; at his re-
quest Jack advanced the implementation work, speedily bringing into existence the
proof-checker Referee, also known as Ref, or as ÆtnaNova. This is still a proto-
type, but it is reliable and fast enough to give us the possibility of debugging our
proof scenarios. Some, though not all, of the content of this book is thus related to
concrete experience, which we are now pleased to share with our readers.
A very large proof scenario is available today as a LATEX-generated PDF-ﬁle. But
given its size (over a thousand pages), it seems appropriate to publish it on the web
(and eventually as a CD) rather than to print it. As for the proof veriﬁer, it is usable
on the web, but it depends on a SETL2 implementation. Since there is hardly anyone
maintaining the SETL system today, Jack undertook with us a re-implementation of
the proof veriﬁer in a currently more popular language. But this will take some time;
it should not be permitted to delay the publication of this book.
ix

x
Preface
This is a posthumous publication, as its principal author passed away on March 2,
2009. In spite of his long illness, until the end of his life, Jack showed unbelievable
resources of energy in the preparation of this book, in implementing and debug-
ging Ref, and in drafting and writing the scenario. With the inspirer of this work
gone, the book may not have achieved the degree of perfection that had been Jack
Schwartz’s goal; nevertheless we believe that the material he left behind will attract
many readers and that its publication will be an appropriate tribute to a distinguished
scientist.
A Word on the Audience for Whom This Book Is Intended
Any technical book must, by emphasizing certain details and leaving others unspo-
ken, make deﬁnite assumptions about the prior knowledge of the reader.
This book assumes that the reader has a good knowledge of standard program-
ming techniques, particularly of string manipulation and parsing, and also a general
familiarity with those parts of mathematics that are analyzed in detail in the main
series of deﬁnitions and proof scenarios to which much of the book is devoted.
On the other hand, little knowledge of formal logic is assumed. For this reason
we try to present what is needed from logic in a reasonably self-contained way,
emphasizing concepts likely to be important in continuations of the work begun
here, rather than technicalities. Foundational issues, for example consideration of
the strength or necessity of axioms, or the precise relationship of our formalism to
other weaker or stronger formalisms studied in the literature, are neglected.
Because we expect our readers to be programmers of some sophistication, syn-
tactic details of the kind that often appear early in books on logic are underplayed,
and we repeatedly assume that anything programmable with relative ease can be
taken as routine, and that the properties of such programmable operations can be
proved when necessary to some theoretical discussion. This reﬂects our feeling that
understanding develops top-down, focusing on details only as these become neces-
sary.
We believe that too much detail is more likely to impede than to promote under-
standing. Who reads, or would want to read, the Whitehead–Russell Principia, or
could testify that its hundreds of formula-ﬁlled pages are without error? But since
we ask this question, why do we include hundreds of formula-ﬁlled pages in this
book, which would not exist without the pioneering work of Whitehead and Russell?
The reason lies in the fact that our formal proof text is, to a large extent, computer-
checked. Though relatively useless to the human reader unless their correctness can
be veriﬁed mechanically, long lists of formulae become useful once such veriﬁca-
tion becomes possible.

Preface
xi
Content of This Book
Chapter 1 gives rapid overviews of the authors’ approach to automated proof ver-
iﬁcation and of the large-scale formalized proof scenario whose development has
accompanied the writing of this book.
Chapter 2 prepares for an extensive account of our proof veriﬁer ÆtnaNova,
by surveying three traditional branches of logic: propositional calculus, ﬁrst-order
predicate calculus, set theory. Completeness proofs are provided for the ﬁrst two
of these deductive systems; the much-debated issue of the consistency of Zermelo–
Fraenkel set theory and of some of its proposed extensions is highlighted.
Chapter 3 provides an extended survey of inference mechanisms. Some of these
belong to the initial endowment of ÆtnaNova, others are candidates for inclusion
in that endowment should our proof veriﬁer be re-implemented or enhanced. In
some cases efﬁciency considerations show that an inference mechanism cannot be
applied at its fullest; notwithstanding we present it because of the mathematical
insight it provides. Two classics of the automated deduction ﬁeld, Robinson’s reso-
lution principle and the Knuth–Bendix equational method, are also surveyed in this
chapter.
Chapter 4 describes our veriﬁer and its underlying design in more detail. In Chap-
ter 5 we expand a broad survey of main deﬁnitions and theorems, showing the salient
steps of a formalized proof scenario leading toward the (as yet) unachieved goal of
proving the Cauchy integral theorem.
In Chapter 6, for completeness sake and to enjoy the intellectual insight that these
results provide, we derive several of the main classical results on undecidability
and unsolvability; in particular, Chaitin’s theorem and the two celebrated Gödel’s
incompleteness theorems.
To convey the character of a scenario veriﬁable by means of our ÆtnaNova sys-
tem, we conclude with Chapter 7 showing formalized proofs of many facts about
ordinals, of various properties of the transitive closure operation, of ﬁnite and trans-
ﬁnite induction principles, and of Zorn’s lemma.
Acknowledgements
We are grateful to Martin Davis, to Alfredo Ferro, and to Alberto Policriti for en-
couraging, through decades of scientiﬁc interaction with the authors, the maturation
of many ideas in this book; to Salvatore Paxia, who enabled us to keep the ÆtnaNova
system alive; to Alexandru Ioan Tomescu, who contributed to the development of
proof scenarios. Various results reported in this book stem from joint work with
Gianluca Cincotti, Piero Ursino, and Calogero Zarba; Emanuele Giaquinta gave us
precious advice concerning LATEX.
Diana Robinson Schwartz gave us major support throughout the preparation of
this book.

xii
Preface
This research was partially funded by MIUR/PRIN project 2006/2007 “Large-
scale development of certiﬁed mathematical proofs” No. 2006012773, and by IN-
dAM/GNCS (Istituto Nazionale di Alta Matematica “F. Severi”, Gruppo Nazionale
per il Calcolo Scientiﬁco).
Domenico Cantone
Eugenio G. Omodeo
Catania, Italy
Trieste, Italy

Contents
1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1.1
Loomings
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1.1.1
The Special Nature of Mathematical Reasoning Within
Human Reason in General . . . . . . . . . . . . . . . . . .
5
1.2
Proof Veriﬁers . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6
1.3
Informal Introduction to the Formalism in which We Will Work . .
7
1.3.1
(A) Immediate Deduction . . . . . . . . . . . . . . . . . .
7
1.3.2
(B) Proof by ‘Supposition’ and ‘Discharge’ (‘Natural
Deduction’)
. . . . . . . . . . . . . . . . . . . . . . . . .
8
1.3.3
(C) Use of Deﬁnitions . . . . . . . . . . . . . . . . . . . .
8
1.4
More About Our Formalism . . . . . . . . . . . . . . . . . . . . .
10
1.4.1
Propositional and Predicate Calculus . . . . . . . . . . . .
10
1.4.2
Set Theory: The Third Main Ingredient of Our Formalism .
13
1.5
An Informal Overview of the Sequence of Formal Set-Theoretic
Proofs to Be Given Later
. . . . . . . . . . . . . . . . . . . . . .
25
1.5.1
Basic Elementary Results . . . . . . . . . . . . . . . . . .
25
1.5.2
Ordinals . . . . . . . . . . . . . . . . . . . . . . . . . . .
25
1.5.3
Well Ordering: The Principle of Transﬁnite Enumerability .
27
1.5.4
Cardinal Numbers . . . . . . . . . . . . . . . . . . . . . .
29
1.5.5
Survey of the Major Sequence of Deﬁnitions and Proofs
Considered in This Text . . . . . . . . . . . . . . . . . . .
32
2
Propositional- and Predicate-Calculus Preliminaries . . . . . . . . .
37
2.1
The Propositional Calculus
. . . . . . . . . . . . . . . . . . . . .
37
2.2
The Predicate Calculus
. . . . . . . . . . . . . . . . . . . . . . .
44
2.2.1
Proof Rules of the Predicate Calculus . . . . . . . . . . . .
51
2.2.2
The Gödel Completeness Theorem . . . . . . . . . . . . .
52
2.2.3
Working with Universally Valid Predicate Formulae. A
Few Simple Examples of Predicate Proof . . . . . . . . . .
54
2.2.4
The Prenex Normal Form of Predicate Formulae . . . . . .
60
2.2.5
The Deduction Theorem . . . . . . . . . . . . . . . . . . .
60
xiii

xiv
Contents
2.2.6
Deﬁnitions in Predicate Calculus; the Notion of
‘Conservative Extension’
. . . . . . . . . . . . . . . . . .
62
2.2.7
Proof of the Gödel Completeness Theorem . . . . . . . . .
65
2.3
Predicate Calculus with Equality as a Built-in
. . . . . . . . . . .
75
2.4
Set Theory as an Axiomatic Extension of Predicate Calculus . . . .
77
2.4.1
Zermelo–Fraenkel Theory with the Axiom of Choice
. . .
77
2.4.2
Concerning the Consistency of ZFC and Various
Interesting Extensions of It
. . . . . . . . . . . . . . . . .
79
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
91
3
A Survey of Inference Mechanisms . . . . . . . . . . . . . . . . . . .
93
3.1
The Davis–Putnam Propositional Decision Algorithm . . . . . . .
93
3.1.1
Horn Formulae and Sets of Formulae . . . . . . . . . . . .
95
3.1.2
Reducing Collections of Propositional Formulae to
Collections of Standardized Disjunctions . . . . . . . . . .
96
3.2
Elementary Boolean Theory of Sets . . . . . . . . . . . . . . . . .
97
3.2.1
Elementary Boolean Theory of Sets, Plus the Predicates
‘Finite’ and ‘Countable’ . . . . . . . . . . . . . . . . . . . 100
3.2.2
Elementary Boolean Operators on Sets, with the
Cardinality Operator and Additive Arithmetic on Integers . 102
3.2.3
Quantiﬁed Predicate Formulae Involving Predicates of
One Argument Only . . . . . . . . . . . . . . . . . . . . . 104
3.3
MLSS: Multilevel Syllogistic with Singletons . . . . . . . . . . . . 109
3.4
MLSS Plus the Predicates ‘Finite’ and ‘Countable’ . . . . . . . . . 113
3.5
The Tableau Method . . . . . . . . . . . . . . . . . . . . . . . . . 115
3.6
Elementary Booleans Plus Map Primitives . . . . . . . . . . . . . 120
3.7
Various Commonly Occurring Decidable Extensions of MLSS . . . 122
3.7.1
Extension Conditions in the Other Cases Listed Above . . . 126
3.7.2
The Case of Mutually Inverse Functions
. . . . . . . . . . 129
3.8
More Examples of Decidable Sublanguages
. . . . . . . . . . . . 131
3.8.1
Presburger’s Decidable Quantiﬁed Language of Additive
Arithmetic . . . . . . . . . . . . . . . . . . . . . . . . . . 131
3.8.2
A Decidable Quantiﬁed Theory Involving Ordinals . . . . . 134
3.8.3
A Language of Additive Inﬁnite Cardinal Arithmetic . . . . 148
3.8.4
Behmann’s Quantiﬁed Language of Elementary
Set-Theoretic Formulae . . . . . . . . . . . . . . . . . . . 151
3.9
A Decision Algorithm for the Theory of Totally Ordered Sets . . . 157
3.10 A Decision Algorithm for Ordered Abelian Groups . . . . . . . . . 159
3.11 A Fragment of Analysis: Theory of Reals and Single-Valued
Continuous Functions with Predicates ‘Monotone’, ‘Convex’,
‘Concave’, Real Addition, and Comparison . . . . . . . . . . . . . 165
3.11.1 Syntax of RMCF+ . . . . . . . . . . . . . . . . . . . . . . 165
3.11.2 Semantics of RMCF+
. . . . . . . . . . . . . . . . . . . . 166
3.11.3 Preparing a Set of RMCF+ Statements for Satisﬁability
Testing . . . . . . . . . . . . . . . . . . . . . . . . . . . . 169
3.12 The Resolution Method for Pure Predicate-Calculus Proving . . . . 177

Contents
xv
3.12.1 Resolution in the Propositional Calculus . . . . . . . . . . 179
3.12.2 Resolution and Syntactic Uniﬁcation in the Predicate
Calculus . . . . . . . . . . . . . . . . . . . . . . . . . . . 180
3.13 Universally Quantiﬁed Predicate Sentences Involving Function
Symbols of One Argument Only
. . . . . . . . . . . . . . . . . . 190
3.14 The Knuth–Bendix Equational Method . . . . . . . . . . . . . . . 193
3.14.1 Overview of the Method . . . . . . . . . . . . . . . . . . . 193
3.14.2 Details . . . . . . . . . . . . . . . . . . . . . . . . . . . . 195
3.14.3 Testing Completeness by Superposition of Reductions:
The Knuth–Bendix Completion Process
. . . . . . . . . . 199
3.14.4 More Details . . . . . . . . . . . . . . . . . . . . . . . . . 200
3.14.5 Examples of the Knuth–Bendix Procedure . . . . . . . . . 200
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 202
4
More on the Structure of the Veriﬁer System . . . . . . . . . . . . . . 205
4.1
Introduction to the General Syntax and Overall Structure of Proofs
205
4.1.1
The Syntax of Proofs
. . . . . . . . . . . . . . . . . . . . 205
4.1.2
The ELEM Primitive and ‘Blobbing’
. . . . . . . . . . . . 208
4.1.3
The Suppose_not, QED, Suppose, Discharge Primitives . . 210
4.1.4
THEORY Application . . . . . . . . . . . . . . . . . . . . 211
4.1.5
Context of an Inference Step
. . . . . . . . . . . . . . . . 213
4.2
The Syntax and Semantics of Deﬁnitions . . . . . . . . . . . . . . 215
4.3
Other Techniques Used in the Veriﬁer as Implemented . . . . . . . 218
4.3.1
Supplementary Proof Mechanisms for the ELEM Rule . . . 218
4.3.2
Limited Predicate Proof . . . . . . . . . . . . . . . . . . . 219
4.3.3
Proof by Equality
. . . . . . . . . . . . . . . . . . . . . . 224
4.3.4
Proof by Monotonicity . . . . . . . . . . . . . . . . . . . . 224
4.3.5
Algebraic Deduction . . . . . . . . . . . . . . . . . . . . . 227
4.3.6
Proof by Closure . . . . . . . . . . . . . . . . . . . . . . . 229
4.3.7
The Behind-the-Scenes Activity of Proof by Structure . . . 230
4.3.8
‘Blobbing’ More General Formulae Down to a Speciﬁed
Decidable or Semi-decidable Sublanguage of Set Theory
. 235
4.3.9
Accelerated Instantiation of Quantiﬁers and Set Formers . . 236
4.3.10 Computation with Hereditarily Finite Sets
. . . . . . . . . 238
4.4
Dividing Long Proof Veriﬁcations into Multiple Separate ‘Sessions’ 253
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 255
5
A Closer Examination of the Sequence of Deﬁnitions and Theorems
Presented in this Book . . . . . . . . . . . . . . . . . . . . . . . . . . 257
5.1
Basic Operations of Set Theory and the Theory of Ordinals
. . . . 258
5.1.1
Pairs, Set Formers, and Maps . . . . . . . . . . . . . . . . 258
5.1.2
Transﬁnite Induction . . . . . . . . . . . . . . . . . . . . . 260
5.1.3
Ordinals . . . . . . . . . . . . . . . . . . . . . . . . . . . 260
5.1.4
The Ordinal Enumerability Theorem . . . . . . . . . . . . 261
5.2
Elementary Laws on Map Constructs . . . . . . . . . . . . . . . . 262
5.3
Cardinality of a Set; Cardinal Numbers . . . . . . . . . . . . . . . 268

xvi
Contents
5.3.1
Finiteness
. . . . . . . . . . . . . . . . . . . . . . . . . . 270
5.4
The Set of All Integers, Basic Arithmetic of Integers and Cardinals 273
5.5
The Cardinal Product Theorem . . . . . . . . . . . . . . . . . . . 279
5.6
The Signed Integers . . . . . . . . . . . . . . . . . . . . . . . . . 281
5.7
Induction Principles for Ordinals
. . . . . . . . . . . . . . . . . . 285
5.7.1
Mathematical Induction for Integers
. . . . . . . . . . . . 287
5.8
Equivalence Relationships and Classes; the General Summation
Operator; Recursion . . . . . . . . . . . . . . . . . . . . . . . . . 287
5.9
Formal Fractions and Rational Numbers
. . . . . . . . . . . . . . 289
5.10 Real Numbers . . . . . . . . . . . . . . . . . . . . . . . . . . . . 295
5.11 Complex Numbers . . . . . . . . . . . . . . . . . . . . . . . . . . 300
5.12 Functions of Real and Complex Variables . . . . . . . . . . . . . . 302
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 311
6
Undecidability and Unsolvability . . . . . . . . . . . . . . . . . . . . 313
6.1
Chaitin’s Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . 313
6.1.1
Undecidability Results Derivable from Chaitin’s Theorem . 315
6.2
The Two Gödel Theorems . . . . . . . . . . . . . . . . . . . . . . 319
6.2.1
Programming Considerations . . . . . . . . . . . . . . . . 320
6.2.2
Programming and Proof; ‘Mirroring’ Programmable
Set-Theoretic Functions . . . . . . . . . . . . . . . . . . . 323
6.2.3
Additional Comments on the Legitimacy of Recursive
Deﬁnitions . . . . . . . . . . . . . . . . . . . . . . . . . . 328
6.2.4
Properties of Integers
. . . . . . . . . . . . . . . . . . . . 329
6.2.5
A Final Remark on Proof and Computation . . . . . . . . . 336
6.2.6
A Technical Adjustment . . . . . . . . . . . . . . . . . . . 336
6.2.7
The ‘Provability’ Predicate Pr(s) . . . . . . . . . . . . . . 337
6.2.8
Proof Visibility Lemma . . . . . . . . . . . . . . . . . . . 339
6.2.9
Gödel’s Trick Sentence
. . . . . . . . . . . . . . . . . . . 343
6.2.10 Rosser’s Variant of Gödel’s Trick Sentence . . . . . . . . . 344
6.2.11 Proof of Rosser’s Variant of Gödel’s First Theorem
. . . . 345
6.2.12 Proof of Gödel’s Second Theorem
. . . . . . . . . . . . . 346
6.3
Axioms of Reﬂection
. . . . . . . . . . . . . . . . . . . . . . . . 346
6.3.1
Statement of the Axioms of Reﬂection . . . . . . . . . . . 359
6.4
A Digression Concerning Foundations
. . . . . . . . . . . . . . . 367
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 371
7
A Self-contained Beginning for Ref’s Main Proof Scenario . . . . . . 373
7.1
Axioms of Set Theory . . . . . . . . . . . . . . . . . . . . . . . . 373
7.2
Pairs and Maps . . . . . . . . . . . . . . . . . . . . . . . . . . . . 374
7.3
From Reachability to Transﬁnite Induction . . . . . . . . . . . . . 378
7.3.1
Reachability in a Big Graph . . . . . . . . . . . . . . . . . 378
7.3.2
Full Sets and Ordinals . . . . . . . . . . . . . . . . . . . . 386
7.3.3
The Transitive Closure Operation . . . . . . . . . . . . . . 390
7.3.4
A Basic Form of the Principle of Transﬁnite Induction . . . 392
7.3.5
Some Basic Facts on Ordinal Numbers . . . . . . . . . . . 393

Contents
xvii
7.4
Zorn’s Lemma . . . . . . . . . . . . . . . . . . . . . . . . . . . . 398
7.5
Finiteness
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 405
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 409
Index
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 411


Chapter 1
Introduction
[···] This then is the advantage of our method: that immediately [···] guided only by char-
acters in a safe and really analytic way, we bring to light truths that others have barely
achieved by an immense effort of mind and by chance. And therefore we are able to present
results within our century which otherwise would hardly be attained in the course of mil-
lennia.
(Gottfried Wilhelm Leibniz, 1679)
1.1 Loomings
Logic begins with Aristotle’s systematic enumeration of the forms of syllogism, as
an attempt to improve the rigor of philosophical (and possibly also political) rea-
soning. Euclid then demonstrated that reasoning at Aristotle’s syllogistic level of
rigor could cover a substantial body of knowledge, namely the whole of geome-
try as known in his day. Subsequent mediaeval work, ﬁrst in the Islamic world and
later in Europe, began to uncover new algebraic forms of symbolic reasoning. Fif-
teen centuries after Euclid, Leibniz proposed that algebra be extended to a larger
symbolism covering all rigorous thought. So two basic demands, for rigor and for
extensive applicability, are fundamental to logic.
Leibniz did little to advance his proposal, which only began to move forward with
the much later work of Boole (on the algebra of propositions), the 1879 Concept-
Notation (Begriffsschrift) of Frege, and Peano’s axiomatization of the foundations
of arithmetic. This stream of work reached a pinnacle in Whitehead and Russell’s
1910 demonstration that the whole corpus of mathematics could be covered by an
improved Frege-like logical system.
Developments in mathematics had meanwhile prepared the ground for the White-
head–Russell work. Mathematics can be seen as the combination of two forms of
thought. Of these, the most basic is intuitive, and, as shown by geometry (or more
primitively by arithmetic), often inspired by experience with the physical world
which it captures and abstracts. But mathematics works on this material by sys-
tematically manipulating collections of statements about it. Thus the second face
of mathematics is linguistic and formal. Mathematics attains rigor by demanding
J.T. Schwartz et al., Computational Logic and Set Theory,
DOI 10.1007/978-0-85729-808-9_1, © Springer-Verlag London Limited 2011
1

2
1
Introduction
that the statement sequences which it admits as proofs conform to rigid formal con-
straints. For this to be possible, the pre-existing, intuition-inspired content of math-
ematics must be progressively resolved into carefully formalized concepts, and thus
ultimately into sentences which a Leibniz-like formal logical language can cover.
A major step in this analysis was Descartes’ reduction, via his coordinate method,
of 2- and 3-dimensional geometry to algebra. To complete this, it became necessary
to solve a nagging technical problem, the ‘problem of the continuum’, concerning
the system of numbers used. An intuition basic to certain types of geometric reason-
ing is that no continuous curve can cross from one side of a line to another without
intersecting the line in at least one point. To capture this principle in an algebraic
model of the whole of geometry one must give a formal deﬁnition of the system of
‘real’ numbers which models the intuitively conceived real axis, must top this by
giving a formal deﬁnition of the notion of continuity, and must use this deﬁnition
to prove the fundamental theorem that a continuous function cannot pass from a
positive to a negative value without becoming zero somewhere between.
This work was accomplished gradually during the 19th century. The necessary
deﬁnition of continuity appeared in Cauchy’s Cours d’Analyse of 1821. A formal
deﬁnition of the system of ‘real’ numbers rigorously completing Cauchy’s work was
given in Dedekind’s 1872 study Continuity and Irrational Numbers. Together these
two efforts showed that the whole of classical calculus could be based on the sys-
tem of fractions, and so, by a short step, on the whole numbers. What remained was
to analyze the notion of number itself into something more fundamental. Such an
analysis, of the notion of number into that of sets of arbitrary objects standing in 1-1
correspondence, appeared in Frege’s 1884 Foundations of Arithmetic, was general-
ized and polished in Cantor’s transﬁnite set theory of 1895, and was approached in
alternative, more conventionally axiomatic terms by Peano in his 1894 Mathemati-
cal Formulary. Like Whitehead and Russell’s Principia Mathematica, the series of
deﬁnitions and theorems found later in this work walks the path blazed by Cauchy,
Dedekind, Frege, Cantor, and Peano.
As set theory evolved, its striving for ultimate generality came to be limited by
certain formal paradoxes, which become unavoidable if the doors of formal set-
theoretic deﬁnition are opened too widely. These arise very simply. Suppose, for
example, that we allow ourselves to consider ‘the set of all sets that are not members
of themselves’. In a formal notation very close to that continually used below, this is
simply s = {x | x /∈x }. But now consider the proposition s ∈s. On formal grounds
this is equivalent to s ∈{x |x /∈x}, and so, by the very deﬁnition of set membership,
to the proposition s /∈s. So in these few formal steps we have derived the proposition
s ∈s ↔s /∈s,
a situation around which no coherent logical system can be built. The means adopted
to avoid this immediate collapse of the formal structure that one wants to build is to
restrict the syntax of the set formers which can legally be written, in a way which
forbids constructions like {x | x /∈x} without ruling out the similar but somewhat
more limited expressions needed to express the whole of standard mathematics.

1.1
Loomings
3
These ﬁne adjustments to the formal structure of logic were worked out, ﬁrst by
Whitehead and Russell, later and a bit differently by their successors.
A higher technical polish was put on all this work by 20th century efforts. Can-
tor’s work was extended, and began to be formalized, by Zermelo in 1908, and
more completely formalized by Fraenkel in 1923. The axiomatization of set theory
at which they arrived is called Zermelo–Fraenkel set theory. Starting in 1905 the
great German mathematician David Hilbert began the inﬂuential series of studies
of the algebra of logic, later summarized in his 1939 work Foundations of Math-
ematics (with Paul Bernays). First in his 1925 paper ‘An Axiomatization of Set
Theory’, and then in a fuller 1928 version, John von Neumann elegantly recast the
Zermelo–Fraenkel set formalism, along with Frege’s analysis of the concept of num-
ber, by encoding the integers set-theoretically: the number 0 as the empty set, 1 as
the singleton-set {0}, 2 as the set {0,1}, and, more generally, each integer n as the
n-element set {0,1,...,n −1}. A corresponding, equally elegant deﬁnition of the
notions of ordinal and cardinal numbers (both ﬁnite and inﬁnite) was given in von
Neumann’s carefully honed formalism, from which the more computer-oriented ex-
position found later in the present work derives very closely.
Especially at ﬁrst, Hilbert’s logical studies stood in a positive relation to the pro-
gram proposed by Leibniz, since it was hoped that close analysis of the algebra
of logic might in principle lead to a set of algorithms allowing any mathematical
statement to be decided by a suitable calculation. But the radical attack on the in-
tuitive soundness of non-constructive Cantorian reasoning and of the conventional
foundations of mathematics published by the Dutch mathematician L.E.J. Brouwer
in 1918 led Hilbert’s work in a different direction. Hilbert hoped that the ‘meta-
mathematical’ tools he was developing could be used to reply to Brouwer’s critique.
For this reply, a combinatorial analysis of the algebra of logic, to which Brouwer
could have no objections since only constructive arguments would be involved,
would be used metamathematically to demonstrate formal limits on what could be
proved within standard mathematics, and in particular to show that no contradic-
tion could follow from any standard proof. Once done, this would demonstrate the
formal consistency of standard mathematics within a Brouwerian framework. But
things turned out differently. In a startling and fundamentally new development, the
metamathematical techniques pioneered by the Hilbert school were used in 1931
by Kurt Gödel to show that Hilbert’s program was certainly unrealizable, since no
logical system of the type considered by Hilbert could be used to prove its own
consistency. The brilliance of this result changed the common professional view of
logic, which came to be seen, not as a Leibnizian engine for the formal statement and
veriﬁcation of ordinary mathematics, but as a negatively-oriented tool for proving
various qualitative and quantitative limits on the power of formalized mathematical
systems.
In the late 1940s the coming of the computer brought in new inﬂuences. Expres-
sion in a rigorously deﬁned system of formulae makes mathematics amenable to
computer processing, and daily work with computer programs makes the absolute
rigor of formalized mathematical systems obvious. The possibility of using com-
puter assistance to lighten the tedium (so evident in Whitehead and Russell) of fully

4
1
Introduction
formalized proof began to make the Leibniz program seem more practical. (Initially
it was even hoped that suitably pruned computer searches could be used rather di-
rectly to ﬁnd many of the ordinary proofs used in mathematics.) The fact that the
methods of formalized proof could be used to check and verify the correctness of
computer programs gave economic importance to what would otherwise remain an
esoteric endeavor. Computerized proof-veriﬁer systems, emphasizing various styles
of proof and potential application areas, began to appear in the 1960s. The system
described in the present text belongs to this stream of work.
A fully satisfactory formal logical system should be able to digest ‘the whole of
mathematics’, as this develops by progressive extension of mathematics-like reason-
ing to new domains of thought. To avoid continual reworking of foundations, one
wants the formal system taken as basic to remain unchanged, or at any rate to change
only by extension as such efforts progress. In any fundamentally new area, work and
language will initially be controlled more by guiding intuitions than by precise for-
mal rules, as when Euclid and his predecessors ﬁrst realized that the intuitive prop-
erties of geometric ﬁgures in 2 and 3 dimensions, and also some familiar properties
of whole numbers could be covered by modes of reasoning more precise than those
used in everyday life. Similarly, the initially semiformal languages that developed
around studies of the ‘complex’ and ‘imaginary’ roots of algebraic equations, the
‘inﬁnitesimal’ quantities spoken of in early versions of the calculus, the ‘random’
quantities of the probabilist, and the physicist’s ‘Dirac delta functions’, all need to
be absorbed into a single formal system. This is done by modeling the intuitively
grasped objects appearing in important semiformalized languages by precisely de-
ﬁned objects of the formal system, in a way that maps all the useful statements of
the imprecise initial language into corresponding formulae. If less than vital, state-
ments of the initial language that do not ﬁt into its formalized version can then be
dismissed as ‘misunderstandings’.
The mathematical developments surveyed in the preceding discussion succeeded
in re-expressing the intuitive content of geometry, arithmetic, and calculus (‘anal-
ysis’) in set-theoretic terms. The geometric notion of ‘space’ maps into ‘set of all
pairs (or triples) of real numbers’, preparing the way for consideration of the ‘set of
all n-tuples of real numbers’ as ‘n-dimensional space’, and of more general related
constructs as ‘inﬁnite dimensional’ and ‘functional’ spaces. The ‘ﬁgures’ originally
studied in geometry map, via the ‘locus’ concept, into sets of such pairs, triples, etc.
The next necessary step is to analyze the notion of real number into something more
basic, the essential technical requirement for this being to ensure that no function
roots (e.g. Pythagoras’ square root of 2) are ‘missing’. As noted above, this was
accomplished by Dedekind, who reduced ‘real number x’ to ‘nonempty set x of ra-
tional numbers, bounded above, such that every rational not in x is larger than every
rational in x’. To eliminate everything but set theory from the formal foundations of
mathematics, it only remains (since ‘fractions’ can be seen as pairs of numbers) to
reduce the notion of ‘integer’ to set-theoretic terms. This was done by Cantor and
Frege: an integer is the class of all ﬁnite sets in 1-1 correspondence with any one
such set. None of the other important mathematical developments enumerated in
the preceding paragraph required fundamental extension of the set-theoretic foun-
dation thereby attained. Gauss realized that the ‘complex’ numbers used in algebra

1.1
Loomings
5
could be modeled as pairs of real numbers, Kolmogorov modeled ‘random’ vari-
ables as functions deﬁned on an implicit set-theoretic measure space, and Laurent
Schwartz interpreted the initially puzzling ‘delta functions’ in terms of a broader
notion of generalized function deﬁned systematically in set-theoretic terms. So all
of these concepts were digested without forcing any adjustment of the set-theoretic
foundation constructed for arithmetic, analysis, and geometry. This foundation also
supports all the more abstract mathematical constructions elaborated in such 20th
century ﬁelds as topology, abstract algebra, and category theory. Indeed, these were
expressed set-theoretically from their inception. So (if we ignore a few ongoing ex-
plorations whose signiﬁcance remains to be determined) set theory currently stands
as a comfortable and universal basis for the whole of mathematics.
It can even be said that set theory captures a set of reality-derived intuitions
more fundamental than such basic mathematical ideas as that of number. Arithmetic
would be very different if the real-world process of counting did not return the
same result each time a set of objects was counted, or if a subset of a ﬁnite set
S of objects proved to have a larger count than S. So, even though Peano showed
how to characterize the integers and derive many of their properties using axioms
free of any explicit set-theoretic content, his approach robs the integers of much of
their intuitive signiﬁcance, since in his reduced context they cannot be used to count
anything. For this and the other reasons listed above, we will work with a thoroughly
set-theoretic formalism, contrived to mimic the language and procedures of standard
mathematics closely.
1.1.1 The Special Nature of Mathematical Reasoning Within
Human Reason in General
The syllogistic patterns characteristic of mathematical reasoning derive from, and
thus often reappear in, other reasoned forms of human discourse, for example in
arguments offered by lawyers and philosophers. Mathematical reasoning is distin-
guished within this world of reason by its rigorous adherence to the pattern origi-
nally set by Euclid. Some ﬁxed set of statements, the axioms, perhaps carrying some
insight about an observed or intuited world, must be ﬁrmly set down. Certain named
predicates (and perhaps also function symbols) will appear in these axioms. The en-
suing discourse (which may be lengthy) must work exclusively with properties of
these predicates (and symbols) which follow formally from the axioms, precisely
as if these predicates had no meaning other than that which the axioms give them.
When new vocabulary is introduced (as will generally be necessary to provide in-
tellectual variety and sustain interest) this must be by formal deﬁnition in terms of
predicates (and function symbols) which either are those found in the axioms or
which appear earlier in the discourse. Such extensions of vocabulary are subject to
rules which ensure that all new symbols introduced can be regarded as tools of art
which add nothing fundamental to the axioms. That is, mathematics’ rules of deﬁni-
tion ensure that allowed extensions of vocabulary cannot make it possible to prove

6
1
Introduction
any statement made in the original vocabulary that could not be proved, in the ax-
ioms’ original vocabulary, from the axioms. This rule, which insists that deﬁnitions
must be devoid of all hidden axiomatic content, is fundamental to mathematics. It
will appear in our later technical discussions as the conservative extension principle.
Legal, philosophical, and scientiﬁc reasoning commonly fail to observe the rules
which restrict mathematical discourse, since these styles of argument allow new
terms with explicitly or implicitly assumed properties to be introduced far more
freely. Science cannot avoid this, since it is dedicated to exploration of the world
in all its variety, and must therefore speak of what it ﬁnds as best it can. But un-
constrained introduction, into a line of reasoning, of even a few new terms having
implicitly assumed properties can readily become an engine of deception (and of
self-deception). Science tries to avoid such self-deception by taking all of its rea-
soned outcomes as provisional subject to comparison with observed reality. If obser-
vation conﬂicts with the outcome of a line of scientiﬁc reasoning, the assumptions
and informal deﬁnitions entering into it will be adjusted until better agreement is
attained. Legal and philosophical reasoning, lacking this mechanism, remain more
permanently able to be used as engines of deception (perhaps deliberate) or of self-
deception (which has its intellectual delights).
1.2 Proof Veriﬁers
A Proof veriﬁer is an interactive program for manipulation of the state of a mathe-
matical discourse. It allows computer checking of such discourse in full detail, and
collection of the resulting theorems for subsequent re-use. It must
(a) only allow theorems to be derived;
(b) allow all theorems to be derived.
Besides their theoretical interest, proof veriﬁers have one potential practical use:
Program Veriﬁcation. To adapt a proof veriﬁer to this use, we can simply annotate
(ordinary procedural) programs with assertions Ai breaking every loop in their con-
trol ﬂow. Then, for every path forward through the annotated program P and its
assignments
x1 := expn(x1,...,xn)
running from an assertion A1 immediately before such an assignment to an assertion
A2 immediately after the assignment we must show that

∀x1,...,xn | A1(x1,...,xn) →A2

expn(x1,...,xn), x2,...,xn

holds. Once this has been done systematically throughout the program, we can be
sure that the program is correct.
To give proofs acceptable to a programmed veriﬁer, i.e. proofs every one of
whose details can be checked by a computer, we must ‘walk in shackles’; but then
we want these shackles to be as light as possible. That is, we want the ordinary

1.3
Informal Introduction to the Formalism in which We Will Work
7
small steps of mathematical discourse to remain small, rather than expanding into
tedious masses of detail. We aim for a formalized interactive conversation with the
computer whose general ‘feel’ resembles that of ordinary mathematical exposition.
The better we succeed in achieving this, the closer the veriﬁer comes to passing the
‘Turing test’, at least in the restricted mathematical setting in which it is designed
to operate. So the internal structure of a successful proof veriﬁer can be seen as a
model both of mathematics and of mathematical intelligence, which is an important,
albeit limited, form of intelligence in general.
1.3 Informal Introduction to the Formalism in which We Will
Work
A proof veriﬁer must provide various tools. First of all, it must allow the elementary
steps of proofs to be expressed by formulae in some agreed-on system. These for-
mulae become the elementary steps which the system allows. The system-provided
tools, which embody the system’s ‘deduction rules’, must allow manipulation of
these formulae in ways which mimic the normal ﬂow of a mathematical discourse.
The collection of proofs presented to a veriﬁer for validation is expressed as a
sequence of logical formulae, to which we may attach formalized annotations to
guide the action of the veriﬁer. Given such a sequence of formulae, the veriﬁer ﬁrst
checks all the statements presented to it for syntactic legality, and then goes on to
verify the successive statements of each proof. As in ordinary proof, the veriﬁer’s
user aims to guide discourse along paths which bring designated target theorems
into the collection of proved statements. This is done by arranging the formulae
(proof steps) of the discourse in such a way as to ensure that each step encountered
satisﬁes the conditions required for it to be accepted as a consequence of what has
gone before. This will be the case in various situations, each corresponding to one
of the basic deduction rules which the system allows. Broadly speaking, these are
as follows.
1.3.1 (A) Immediate Deduction
The collection of statements already accepted as proved are always included in a
‘penumbra’ D of additional statements which follow from them as elementary con-
sequences. The veriﬁer as programmed is able to check that each statement in D
follows immediately from statements already accepted. Some well-known exam-
ples are as follows:
(a) If a formula F in a proof is preceded by an (already accepted) formula G, and
by a second (already accepted) formula of the form G →F , where ‘→’ is the
operator sign designating implication, then F will be accepted.

8
1
Introduction
(b) If a formula x ∈E in a proof is preceded by an (already accepted) formula
x ∈H, and by a second (already accepted) formula E ⊇H, where ‘⊇’ is the
operator sign designating set-theoretic inclusion, then x ∈E will be accepted.
(c) If (c.1) we are given a formula having the syntactic structure P(e), where P(x)
is a formula containing a variable x, and P(e) is the result of replacing each of
the occurrences of x in P with an occurrence of the (syntactically well-formed)
subexpression e; (c.2) the formula P(e) is preceded by an (already accepted)
formula (∀x | P(x)), where the symbol ‘∀’ designates the ‘universal quantiﬁer’
construct of logic, then P(e) will be accepted.
The more we can enlarge the available family of immediate deductions by ex-
tending a veriﬁer’s immediate-deduction algorithms, the more we will succeed in
reducing the number of steps needed to reach our target theorems. Means for doing
this are explored later in this chapter, and then more systematically in Chap. 3.
1.3.2 (B) Proof by ‘Supposition’ and ‘Discharge’ (‘Natural
Deduction’)
At any point in a proof, any syntactically well-formed statement S can be introduced
for provisional use by including a veriﬁer directive of the form
Suppose =⇒S.
Conclusions can be drawn from such statements in the normal way, but such
conclusions are not accepted as having been deﬁnitively proved, but only as having
been ‘provisionally proved’, subject to the ‘assumption’ expressed by S. However,
if such an assumption S can be shown to lead to the impossible conclusion ‘false’,
then S can be ‘discharged’, i.e. its negation ¬S can be accepted as a deﬁnitely
proved formula. This manner of proceeding mimics the familiar method of ‘proof
by contradiction’ (also called ‘reductio ad absurdum’) of ordinary mathematical
discourse.
1.3.3 (C) Use of Deﬁnitions
Statements which introduce entirely new constant or function names can be true
‘by deﬁnition’. Suppose, for example, that constants b and c, and a dyadic function
symbol f , have already been introduced into a discourse, and that d is a name not
previously used. Then the statement
d = f

b,f (c,b)


1.3
Informal Introduction to the Formalism in which We Will Work
9
can be accepted immediately, since it merely deﬁnes d, i.e. makes an initial reference
to an object d concerning which we know nothing else. Such deﬁnitions are subject
to rules which serve to ensure that the new symbols introduced by such deﬁnitions
imply only those properties of previously introduced symbols which are entailed by
our previous knowledge concerning them. For example, a statement like
b = f

b,f (d,b)

is not a valid deﬁnition for a new constant d, since at the very least it implies that
there exists some x for which b = f (b,f (x,b)) (and this may be false).
Deﬁnitions serve various purposes. At their simplest they are merely abbrevia-
tions which concentrate attention on interesting constructs by assigning them names
which shorten their syntactic form. (But of course the compounding of such abbre-
viations can change the appearance of a discourse completely, transforming what
would otherwise be an exponentially lengthening welter of bewildering formulae
into a sequence of sentences which carry helpful intuitions.) Beyond this, deﬁni-
tions serve to ‘instantiate’, that is, to introduce the objects whose special properties
are crucial to an intended argument. Like the selection of crucial lines, points, and
circles from the inﬁnity of geometric elements that might be considered in a Eu-
clidean argument, deﬁnitions of this kind often carry a proof’s most vital ideas.
As explained in more detail below, we use the dictions of set theory, in particular
its general set formers, as an essential means of instantiating new objects. As we
will show later by writing a hundred or so short statements which deﬁne all the
essential foundations of standard mathematics, set theory gives us a very ﬂexible
and powerful tool for making deﬁnitions.
Our system allows four forms of deﬁnition. The ﬁrst of these is deﬁnition using
set formers (or ‘algebraic constructions’ more generally), as exempliﬁed by

s =Def {y : x ∈s, y ∈x}
(which deﬁnes ‘the set of all elements of elements of s’, i.e. ‘the union of all el-
ements of s’), and assigns it the symbol ‘’ (which must never have been used
previous to this deﬁnition). A second example is
less_usual(s) =Def {y : x ∈s, y ∈x} \ s
(which deﬁnes ‘the set of all elements of elements of s which are not directly ele-
ments of s’).
The second form of deﬁnition allowed generalizes this kind of set-theoretic def-
inition in a less commonly used but very powerful way. In ordinary deﬁnitions, the
symbol being deﬁned can only appear on the left-hand side of the deﬁnition, not on
its right. This standard rule prohibits ‘circular’ deﬁnitions. In a recursive deﬁnition
this rule is relaxed. Here the symbol being deﬁned, which must designate a function
of one or more variables, can also appear on the right of the deﬁnition, but only in a
special way. More speciﬁcally, we allow function deﬁnitions like
f (s,t) =Def d

g

f

x,h1(t)

, s,t

: x ∈s | P

x, f

x,h2(t)

, s,t

,

10
1
Introduction
where it is assumed that d,g,h1,h2, and P are previously deﬁned symbols and that
f is the symbol being deﬁned by the formula displayed. Here circularity is avoided
by the fact that the value of f (s,t) can be calculated from values f (x,t′) for which
we can be sure that x is a member of s, so x must come before s in the implicit
(possibly inﬁnite) sequence of steps which build sets up from their members, starting
with the empty set as the only necessary foundation object for the so-called ‘pure’
theory of sets.
‘Transﬁnite recursive’ deﬁnitions like that displayed above give us access to the
sledgehammer technique called ‘transﬁnite induction’, which like other sledgeham-
mers we use occasionally to break through key obstacles, but generally set aside.
The third and fourth forms of deﬁnition allowed, ‘Skolemization’ and use of
‘theories’, are explained later.
1.4 More About Our Formalism
Any formalism begins with some initial ‘endowment’, i.e. system of allowed for-
mulae and built-in rules for the derivation of new formulae from old. If one intends
to use such a formalism as a basis for metamathematical reasoning, one may aim
to simplify the implied combinatorial analyses of the formalism by minimizing this
endowment. But we intend to use our formalism to track ordinary mathematical rea-
soning as closely and comfortably as we can; hence we streamline the endowment
of formulae and formula transformations with which our system begins, but try to
maximize its power. Accordingly, the system we propose incorporates various very
powerful means for deﬁnition of objects and proof of their properties.
1.4.1 Propositional and Predicate Calculus
First consider what is most necessary, which we will handle in entirely standard
ways. The apparatus of Boolean reasoning is needed if we are to make such state-
ments as ‘a and b are both true’, ‘a or b is true’, ‘a implies b’, etc. The ‘propo-
sitional calculus’ required for this is elementary, and easily automated. We simply
adopt this calculus, writing its operators as ‘&’ (conjunction), ‘∨’ (disjunction), ‘¬’
(negation), ‘→’ (implication), ‘↔’ (logical equivalence). Our system is decidable,
in the sense it includes an algorithm able to detect statements which are universally
true by virtue of their propositional form. This will, for example, automatically de-
tect that
(p →q) →

(¬q) →(¬p)

and

F(x+y) = F

F(x)

→F

F(x)

= 0

→

F

F(x)

̸= 0 →F(x+y) ̸= F

F(x)


1.4
More About Our Formalism
11
are both always true. The ﬁrst of these formulae belongs directly to the propositional
calculus. Automatic treatment of the second formula uses a fundamental internal
system operation called ‘blobbing’, which works by reducing formulae to skeletal
forms legal in some tractable sublanguage of the full set-theoretic language in which
we work. Applied to the second formula displayed above, blobbing sees it to have
a Boolean skeleton identical to that of the ﬁrst. More is said about this important
technique below.
Statements of the form ‘for all ...’ and ‘there exists ...’, as in ‘for all integers
n greater than 2 there exists a unique non-decreasing sequence of prime integers
whose product is n’, are obviously needed for mathematics. To handle these, we
adopt the standard apparatus of the ‘predicate calculus’ (or more properly ‘ﬁrst-
order predicate calculus’). This extends the propositional calculus by allowing its
proposition-symbols p,q,... to be replaced by predicate subformulae constructed
recursively out of the following.
1. Constants c and variables x denoting speciﬁed or arbitrary objects drawn from
some (implicit) ‘universe’ U of objects.
2. Named predicates, e.g. P(x,y), Ord(x), Between(x,c,z), depending on some
given number of constants and variables, which for each combination x,y,...
chosen from the ‘universe’ U yield some true/false (i.e. Boolean) value.
3. Named function symbols, e.g. f (x), g(x,y), h(x,c,z), depending on some given
number of constants and variables, which for each combination x,y,... chosen
from the ‘universe’ U yield an object belonging to this same universe.
4. Two ‘quantiﬁers’,

∀x | P(x)

and

∃x | P(x)

,
respectively, representing the universal quantiﬁcation construct ‘for all possible
values of the variable x, P(x) (the statement which follows the vertical bar) is
true’ and the existential quantiﬁcation construct ‘there exists some value of the
variable x for which P(x) (the statement which follows the vertical bar) is true’.
For example, to express the condition that at least one of the predicates P(x) and
Q(x) is true for each possible value of the variable x, we write

∀x | P(x) ∨Q(x)

.
To state that exactly one of these conditions is true for every possible value of
the variable x, we can write

∀x
 
P(x) ∨Q(x)

&

¬

P(x) & Q(x)

.
To state that for each possible value of the variable x having the property P(x)
there exists a value standing in the relationship R(x,y) to it, we can write

∀x | P(x) →

∃y | R(x,y)

,
(1.1)
or equivalently

∀x
 
∃y | P(x) →R(x,y)

.
(1.2)

12
1
Introduction
It should be plain that this predicate notation allows us to write universally and
existentially quantiﬁed statements generally, provided only that names are available
for all the multivariable predicates in which we are interested.
Intuitively speaking, a universally quantiﬁed (resp. existentially quantiﬁed) for-
mula represents the conjunction (resp. disjunction) of all possible cases of the for-
mula; e.g., (∀x |P(x)) can be regarded as a formalized abbreviation for the ‘inﬁnite
conjunction’ that might be written informally as
P(x1) & P(x2) & P(x3) & ··· ,
where x1,x2,x3,... is an enumeration of all the values which the variable x can
assume. Similarly, an existentially quantiﬁed statement like (∃x | P(x)) can be re-
garded as a formalized abbreviation for the ‘inﬁnite disjunction’ that might be writ-
ten as
P(x1) ∨P(x2) ∨P(x3) ∨··· .
This shows us why the two predicate formulae (1.1) and (1.2) displayed above are
equivalent, namely this informal style of interpretation explicates

∀x | P(x) →

∃y | R(x,y)

as

P(x1) →

∃y | R(x1,y)

&

P(x2) →

∃y | R(x2,y)

& ···
and hence as

P(x1) →

R(x1,x1) ∨R(x1,x2) ∨R(x1,x3) ∨···

&

P(x2) →

R(x2,x1) ∨R(x2,x2) ∨R(x2,x3) ∨···

& ··· . (1.3)
Expansion of (∀x | (∃y | P(x) →R(x,y))) in exactly the same way results in

P(x1) →R(x1,x1)

∨

P(x1) →R(x1,x2)

∨

P(x1) →R(x1,x3)

∨···

&

P(x2) →R(x1,x1)

∨

P(x2) →R(x1,x2)

∨

P(x2) →R(x1,x3)

∨···

& ··· .
(1.4)
Applying the standard propositional reduction of the implication operator p →q
to (¬p) ∨q, we can rewrite the ﬁrst line of (1.3) as

¬P(x1)

∨

R(x1,x1) ∨R(x1,x2) ∨R(x1,x3) ∨···

and the ﬁrst line of (1.4) as

¬P(x1) ∨R(x1,x1)

∨

¬P(x1) ∨R(x1,x2)

∨

¬P(x1) ∨R(x1,x3)

··· ,

1.4
More About Our Formalism
13
respectively, and similarly for all later lines. But then, using the associativity and
commutativity of the disjunction operator ∨, and since disjunction is idempotent,
i.e.
p ∨p ∨p ∨···
is exactly equivalent to p, the two propositional expansions seen above are equiva-
lent. Hence the claimed equivalence of

∀x | P(x) →

∃y | R(x,y)

and

∀x
 
∃y | P(x) →R(x,y)

is intuitively apparent. We will explain later how the predicate calculus manages to
handle all of this formally.
1.4.2 Set Theory: The Third Main Ingredient of Our Formalism
We view set theory as the established language of mathematics and take a rich ver-
sion of it as fundamental. In particular, the language with which we will work in-
cludes a full sublanguage of set formers, constrained just enough to avoid para-
doxical constructions like the {x | x /∈x} set former discussed above. Set-former
expressions like

e(x): x ∈s | P(x)

,

e(x,y): x ∈s(y)| P(x,y)

,

e(x,y,z): x ∈s(z), y ∈s′(x,z)| P(x,y,z)

,
and even

e(x,y,z,w): x ∈s(w), y ∈s′(x,w), z ∈s′′(x,y,w)| P(x,y,z,w)

,
are all allowed, as are

e(x): x ⊆s | P(x)

,

e(x,y): x ⊆s(y)| P(x,y)

,

e(x,y,z): x ⊆s(z), y ⊆s′(x,z)| P(x,y,z)

,
and

e(x,y,z,w): x ⊆s(w), y ∈s′(x,w), z ⊆s′′(x,y,w)| P(x,y,z,w)

,

14
1
Introduction
which use the sign ‘⊆’ designating set inclusion in place of one or more occurrences
of the sign ‘∈’ (designating set membership).
Set formers have several crucial advantages as language elements. First of all,
they give us very powerful means for deﬁning most mathematical objects of strate-
gic interest. This allows the very succinct series of mathematical deﬁnitions given
later, which lead in roughly 100 lines from rudimentary set-theoretic concepts to
core statements in analysis (e.g. the Cauchy integral theorem). A second advantage
of set formers traces back to the fact that the human mind is ‘perception dominated’,
in the sense that we all depend heavily upon many innate perceptual abilities, which
operate rapidly and subconsciously, and by which the conscious (and reasoning)
abilities of the mind are largely limited. Perceivable things and relationships can
be dealt with rapidly. Where direct perception fails, we must fall back on more
tortuous processes of reconstruction and detection, slowing progress by orders of
magnitude. Hence the importance of notations, diagrams, graphs, animations, and
scientiﬁc visualization techniques generally (e.g. the Arabic numerals, algebra, cal-
culus, ‘commutative diagrams’ in topology, etc.). Among innate perceptual abilities
we count the ability to decode spoken and written language, to remember phrases
and simple relationships among them, and to recognize various language-like but
somewhat more abstract syntactic structures. From this point of view, much of the
importance of set theory and its set-former notations lies in the fact that their syn-
tax reveals various simpliﬁcations and relationships with which the mind operates
comfortably. These include:
(i) Various algebraic transformations of set formers, of which

e(x): x ∈

e′(y): y ∈s | Q(y)
 P(x)

=

e

e′(y)

: y ∈s | P

e′(y)

& Q(y)

and

e(x): x ∈

e′(y,z): y ∈s1, z ∈s2 | Q(y,z)
 P(x)

=

e

e′(y,z)

: y ∈s1, z ∈s2 | P

e′(y,z)

& Q(y,z)

are typical.
(ii) Set-former expressions make various important monotonicity and domination
relationships visible. For example, a glance at

e(x): x ∈s | F(x) ∈s \ t

tells us that this expression is monotone increasing in s and monotone decreas-
ing in t. From this, a statement like

g(a) ⊇g(b) & h(a) ⊆h(b)

→

e(x):x ∈s |F(x) ∈g(a)\h(a)

⊇

e(x):x ∈s |F(x) ∈g(b)\h(b)


1.4
More About Our Formalism
15
is obvious by elementary reasoning concerning set unions, differences, and in-
clusions, which an algorithm can handle very adequately.
Deductions like this are frequent in the long sequence of steps which we will
use to verify the standard mathematical material at which this text aims. Hence
the stress we lay on deduction methods like that just explained, which we make
available within our system under such names as ELEM (‘elementary set-theoretic
deduction’, expanded as much as we dare), SIMPLF (deduction methods based on
algebraic simpliﬁcation), etc. Hence also the special methods provided to deal with
set-theoretic, predicate, and algebraic monotonicity.
The set-former constructs described above, and the other elementary operations
of set theory, play two roles. On the one hand, they deﬁne operations on ﬁnite sets
which can be implemented explicitly, for example by programming them systemat-
ically so as to create a full programming language which allows free use of ﬁnite
sets as data objects. On the other hand, they deﬁne a language in which one can
talk about a much larger universe of inﬁnite sets, even though such sets can have
no explicit representation other than the formulae used to speak of them. Since the
formulae used to speak of inﬁnite sets are the same as those used for ﬁnite sets, and
since much the same axioms are assumed for sets of both kinds, many of the proper-
ties deduced for inﬁnite sets stand in analogy to the more directly visible properties
of ﬁnite sets.
1.4.2.1 A Few Simple but Basic Set Constructs
The operation {x,y} which forms the (unordered) pair of two sets is an important
but entirely elementary set operation. For this we have
z ∈{x,y} ↔(z = x ∨z = y).
Then plainly {x,x} satisﬁes z ∈{x,x} ↔z = x, so {x,x} is the singleton {x} whose
only member is x.
The set-former expression

x =Def {z: y ∈x, z ∈y}
deﬁnes the set of all z which are elements of some element of x. This is the so-called
‘general union set’ of x, which can be thought of as ‘the union of all elements of
x’. Since we have
z ∈

{x,y} ↔(z ∈x ∨z ∈y),
{x,y} is the set of all z which are either members of x or of y. This very com-
monly used operation is generally written as x ∪y. Given any two sets x and y, it
gives us a way of constructing a set at least as large as either of them, of which both
are subsets.

16
1
Introduction
We can use the union operator to deﬁne the sets having three, four, etc. given
elements by writing
{x,y,z} = {x,y} ∪{z},
{x,y,z,w} = {x,y,z} ∪{w},....
It is easily proved from these deﬁnitions that
u ∈{x,y,z} ↔(u = x ∨u = y ∨u = z),
u ∈{x,y,z,w} ↔(u = x ∨u = y ∨u = z ∨u = w),
etc. The intersection operator, which gives the common part of two sets s and t, can
be deﬁned directly by a set former:
s ∩t =Def {x : x ∈s | x ∈t}.
The powerset operator, which gives the set of all subsets of a set s, can also be
deﬁned by a set-former expression:
P(s) =Def {x : x ⊆s}.
1.4.2.2 The Choice Operator ‘arb’
The less elementary ‘choice’ operation arb(s) reﬂects the intuition, veriﬁably true
in the hereditarily ﬁnite case discussed in Sects. 2.4.2.1 and 4.3.10 that all sets can
be constructed in an order in which all the elements of set s are constructed before s
itself is constructed. Since, as we shall see, a ﬁnite string representation is available
for each hereditarily ﬁnite set, we can arrange such sets in order of the length of
their string representations. Then arb(s) can be deﬁned for each ﬁnite set as the ﬁrst
member of s, in this standard order. We complete this deﬁnition for the one special
case in which s has no members, i.e. is the null set, by agreeing that arb(∅) = ∅.
Then, for each nonempty set s, arb(s) must be disjoint from s, since if x were
a common member of s and arb(s), x would have to be an element of s coming
earlier than arb(s) in standard order, contradicting our deﬁnition of arb(s) as the
ﬁrst element of s in this order. Hence, whenever this notion of ‘construction in some
standard order’ applies, we can expect the ‘arb’ operator, deﬁned in the manner just
explained, to satisfy

∀s
 
s = ∅& arb(s) = ∅

∨

arb(s) ∈s & arb(s) ∩s = ∅

.
This statement, intuitively justiﬁed in the manner just explained, is taken as an
axiom in the version of set theory used in this book. It is assumed to apply to all sets,
whether ﬁnite or inﬁnite. In conventional terms, this axiom states a very strong form
of the so-called ‘axiom of choice’: arb chooses a ﬁrst element from each nonempty
set, ‘ﬁrst’ in the sense that there exists no other element of s which is also an element
of arb(s).

1.4
More About Our Formalism
17
It follows that there can exist no set x for which x ∈x. For if there were, we
would have arb({x}) = x, and so x would be a common element of {x} and arb({x}),
contradicting our assumption concerning ‘arb’. It follows similarly that there can
exist no ‘membership cycle’, i.e. no sequence x1,x2,...,xn of sets of which each
is a member of the next and for which the last is a member of the ﬁrst. For if there
were, we would have arb({x1,x2,...,xn}) = xj for some j, and then either xj−1 or
xn would be a common element of arb({x1,x2,...,xn}) and {x1,x2,...,xn}. Much
the same argument shows that there can exist no inﬁnite sequence x1,x2,...,xn,...
for which each xj+1 is a member of xj. Note, however, that x,{x},{{x}},... is
always a sequence each of whose components is an element of the next following
component.
1.4.2.3 The ‘arb’ Operator as the Basis for Proofs by Transﬁnite Induction
The standard (Peano) principle of mathematical induction is equivalent to the state-
ment that every nonempty set s of integers contains a smallest element n0. For sup-
pose that P(n) is a predicate, deﬁned for integers, for which the implication

∀n
 
∀m| (m < n) →P(m)

→P(n)

has been established, that is, for which P(n) must be true for a given n if it is true
for all smaller m. Then P(n) must be true for all integers n. For if not, the set of all
integers n such that P(n) is false will be nonempty, and so will contain a smallest
integer n0. But then P(m) is clearly true for all m < n0, implying that P(n0) is true,
contrary to assumption.
Use of the ‘arb’ operator allows us to extend this very convenient style of in-
ductive reasoning to entirely general sets, irrespective of whether they are ﬁnite or
inﬁnite. Suppose, more speciﬁcally, that P(s) is a predicate, deﬁned for sets, for
which the implication

∀s
 
∀t | (t ∈s) →P(t)

→P(s)

has been established. That is, we suppose that P(s) must be true for a given s if
it is true for all members of s. Then P(s) must be true for all sets s. For if not,
then P(s) must be false for some member s1 of s. Repeating this argument, we see
that there must exist a member s2 of s1 for which P(s2) is false, then a member
s3 of s2 for which P(s3) is false, and so forth. This gives us an inﬁnite sequence
s = s0,s1,s2,...,sn,..., each component of which is a member of the preceding
component, which we have seen to be impossible.
This very broad generalization of the ordinary principle of mathematical induc-
tion is called the principle of transﬁnite induction. It plays much the same role for
the inﬁnite ordinals discussed in the next section that the ordinary principle of math-
ematical induction plays for integers.

18
1
Introduction
1.4.2.4 Ordered Pairs
We need, in many situations, not the unordered pair construct {x,y} described
above, but rather an ordered pair construct [x, y]. The only properties of [x, y]
that we require are: (i) [x, y] is deﬁned for any two sets x,y and is itself a set; (ii)
the pair [x, y] deﬁnes its two components x and y uniquely, i.e. there exist opera-
tions z[1] and z[2] such that [x, y][1] = x and [x, y][2] = y for all x and y. It is not
necessary to add these statements as additional set-theoretic axioms, since the nec-
essary pairing operations can be deﬁned using the unordered pair construct {x,y}
and the arb operator, in any number of (artiﬁcial) ways (none of them having any
particular signiﬁcance). For example, we can use the deﬁnition
[x, y] =Def

{x},

{x},

{y},y

.
Then arb([x, y]) = {x}, since the only other element of {{x},{{x},{{y},y}}} has the
element {x} in common with [x, y]. Thus the expression arb(arb([x, y])) always
reconstructs x from [x, y]. Moreover

{x},

{x},

{y},y

\

{x}

=

{x},

{y},y

,
so
arb

arb

[x, y] \

arb

[x, y]

\

arb

[x, y]

=

{y},y

,
and therefore the expression arb(arb(arb([x, y] \ {arb([x, y])}) \ {arb([x, y])})) re-
constructs y from [x, y]. The reader is invited to amuse him/herself by inventing
other like constructions having similar properties.
Once ordered pairs and the operators which extract their components have been
deﬁned in this way, it is easy to deﬁne the general set-theoretic notion of ‘relation-
ship’ and the associated notions of ‘single-valued mapping’, ‘inverse relationship’,
and ‘1-1 relationship’. A relationship or mapping, or just map, is simply a set of
ordered pairs. To formalize this, we have only to write
Is_map(f ) =Def

f =
	
x[1],x[2]
: x ∈f

.
The domain and range of a relationship are then deﬁned in the usual way as
domain(f ) =Def

x[1] : x ∈f

and
range(f ) =Def

x[2] : x ∈f

,
respectively. A relationship is single-valued if the ﬁrst component u of each pair
[u,v] in it deﬁnes the associated second component v uniquely. Formally this is
Svm(f ) ↔Def Is_map(f ) &

∀x ∈f
 
∀y ∈f
 
x[1] = y[1]
→(x = y)

.

1.4
More About Our Formalism
19
The inverse of a relationship is deﬁned by
f −1 =Def
	
x[2],x[1]
: x ∈f

.
A relationship is 1-1 if it and its inverse are both single-valued:
1_1(f ) ↔Def Svm(f ) & Svm

f −1
.
Other standard constructs involving mappings, for example the composition of two
mappings, are equally easy to deﬁne.
1.4.2.5 Integers and Ordinal Numbers in Set Theory
As noted above, John von Neumann suggested that the fundamental mathemati-
cal notion of ‘integer’ be expressed set-theoretically by encoding 0,1,...,n,... as
∅,{0},...,{0,1,...,n −1},... . The set N of all integers is then
{0,1,...,n,...}.
All of these sets s, including the inﬁnite set N, have the following properties:
(i) any member of a member of s is also a member of s;
(ii) given any two distinct members x,y of s, one of x and y must (come earlier in
the sequence in which we have enumerated the members of s, and so must) be
a member of the other.
Von Neumann then realized that sets having these two properties had exactly the
properties of ‘ordinal numbers’ as originally deﬁned by Cantor, so that (i) and (ii)
can be taken as the deﬁnition of the notion of ordinal number. Besides its striking
directness and simplicity, this deﬁnition has the advantage (over Cantor’s original
deﬁnition) of representing each ordinal number by a unique set. Moreover, all the
basic operations on inﬁnite ordinals which Cantor introduced take on simple set-
theoretic forms if ordinals are deﬁned in this way. For example, for the integers
in their von Neumann representation, each integer m less than an integer n is a
member of n; hence the arithmetic relationship m < n can be deﬁned m ∈n, i.e.
by the simplest of all set-theoretical relationships. We use this deﬁnition, i.e. ‘s less
than t’ means simply s ∈t, for arbitrary ordinals s.
1.4.2.6 Instantiation and Proof by Use of ‘Theories’
The ‘theory’ mechanism which our system provides relates to logical proof in some-
thing like the way in which the use of ‘procedures’ relates to programming practice.
It facilitates introduction of symbol groups or single symbols (like the standard
mathematical summation operator  and the rather similar product operator )
which derive from previously deﬁned functions and constants (‘+’ and ‘0’ in the

20
1
Introduction
case of , multiplication and ‘1’ in the case of ), that have the properties re-
quired for deﬁnition of the new symbols. As these examples indicate, our ‘theory’
mechanism eases an important class of instantiations which need to be justiﬁed by
supporting theorems. It adds a touch of second-order logic capability to the ﬁrst-
order system in which we work.
The syntax used to work with ‘theories’ is described by the following procedure-
like template:
THEORY theory_name( list_of_assumed_symbols )
assumptions
=⇒( list_of_deﬁned_symbols )
conclusions
END theory_name.
The formal description of the important ‘theory of Sigma’, which we will use as
a running example, illustrates the way in which we set up and use theories. This the-
ory captures a construction, ubiquitous in mathematical practice, which is normally
written using ‘three dots’ notation, e.g. as f1 + f2 + ··· + fk.
THEORY Sigma_theory( s, u ⊕v, e )
e ∈s &

∀x ∈s| (∀y ∈s| x ⊕y ∈s)

(∀x ∈s| x ⊕e = x)

∀x ∈s| (∀y ∈s| x ⊕y = y ⊕x)


∀x ∈s
 
∀y ∈s|

∀z ∈s| (x ⊕y) ⊕z = x ⊕(y ⊕z)

=⇒(ΣΘ) -- ΣΘ(f ) is about being deﬁned for any ﬁnite
-- single-valued mapping f with values in s

∀f
 
Finite(f ) & Svm(f ) & range(f ) ⊆s

→

ΣΘ(f ) ∈s & ΣΘ(∅) = e &

∀x,y | f =

[x, y]

→ΣΘ(f ) = y

&

∀t | ΣΘ(f ) = ΣΘ(f|t) ⊕ΣΘ(f|domain(f )\t)

&

∀x ∈domain(f )| ΣΘ(f ) = ΣΘ(f|domain(f )\{x}) ⊕arb

f {x}

&

∀g |

Svm(g) & domain(f ) = domain(g)

→
ΣΘ(f ) = ΣΘ
	
y,ΣΘ(f|g↰{y})

: y ∈range(g)

END Sigma_theory.
(The ﬁnal conclusion displayed encapsulates a general ‘rearrangement of sums’
principle.) The assumed_symbols of this theory are s, ⊕, and e, and its only
deﬁned_symbol is ΣΘ, to which we are attaching the Θ subscript to stress that
ΣΘ is, in a sense, a ‘formal output-parameter’ of the theory. ‘Finite’ and ‘Svm’ are
standard set-theoretic predicates, which we assume to have been deﬁned prior to the
introduction of the theory displayed: ‘Finite(f )’ states that f is ﬁnite, and ‘Svm(f )’
states that f is a single-valued map. Similarly, ‘domain(f )’ and ‘range(f )’ denote
the domain and range of f , respectively, ‘f|d’ denotes the restriction of f to d

1.4
More About Our Formalism
21
(namely the largest possible map which is included in f and whose domain is in-
cluded in d), ‘g ↰{y}’ denotes the set of all elements of the domain of g which
g maps into the element y, ‘f {x}’ designates the range of f on the set {x}, and
‘arb(f {x})’ the unique element of this range, i.e. the image of x under the single-
valued mapping f .
Were the mechanisms of second-order predicate calculus available to us, the
meaning of the theory could be rendered precisely by

∀s
 
∀⊕
 
∀e
 
∃Σ


e ∈s &

∀x ∈s | (∀y ∈s | x ⊕y ∈s)

&

∀x ∈s | x ⊕e = x

&

∀x ∈s
 (∀y ∈s | x ⊕y = y ⊕x)

&

∀x ∈s
 
∀y ∈s
 
∀z ∈s | (x ⊕y) ⊕z = x ⊕(y ⊕z)

→
∀f
 
Finite(f ) & Svm(f ) & range(f ) ⊆s

→

Σ(f ) ∈s & Σ(∅) = e &

∀x,y | f =

[x, y]

→ΣΘ(f ) = y

&

∀t | Σ(f ) = Σ(f|t) ⊕Σ(f|domain(f )\t)

&

∀x ∈domain(f )| Σ(f ) = Σ(f|domain(f )\{x}) ⊕arb

f {x}

&

∀g
 
Svm(g) & domain(f ) = domain(g)

→
Σ(f ) = Σ
	
y,Σ(f|g↰{y})

: y ∈range(g)

.
Informally speaking, this second-order formula states that given any set s and
commutative-associative operator deﬁned on it, there must exist a monadic function
Σ which relates to them in the manner stated in the conclusion of the quantiﬁed for-
mula displayed. If our formalism allowed the second-order mechanisms (of quan-
tiﬁcation over function and relation symbols, which it does not) seen here, and were
this second-order formula proved, we could substitute any three actual symbols for
which the hypotheses of the formula had been proved for the three universally quan-
tiﬁed function symbols s, ⊕, and e which appear, thereby obtaining the existentially
quantiﬁed conclusion

∃Σ


e ∈s &

∀x ∈s | (∀y ∈s | x ⊕y ∈s)

&
(∀x ∈s | x ⊕e = x) &

∀x ∈s | (∀y ∈s | x ⊕y = y ⊕x)

&

∀x ∈s
 
∀y ∈s
 
∀z ∈s | (x ⊕y) ⊕z = x ⊕(y ⊕z)


22
1
Introduction
→
∀f
 
Finite(f ) & Svm(f ) & range(f ) ⊆s

→

Σ(f ) ∈s & Σ(∅) = e &

∀x,y | f =

[x, y]

→ΣΘ(f ) = y

&

∀t | Σ(f ) = Σ(f|t) ⊕Σ(f|domain(f )\t)

&

∀x ∈domain(f )| Σ(f ) = Σ(f|domain(f )\{x}) ⊕arb

f {x}

&

∀g |

Svm(g) & domain(f ) = domain(g)

→
Σ(f ) = Σ
	
y,Σ(f|g↰{y})

: y ∈range(g)

.
This last statement (still second-order, since it is quantiﬁed over the function
symbol Σ) would allow us to introduce a new symbol ΣΘ for which

e ∈s &

∀x ∈s | (∀y ∈s | x ⊕y ∈s)

&
(∀x ∈s | x ⊕e = x) &

∀x ∈s | (∀y ∈s | x ⊕y = y ⊕x)

&

∀x ∈s |

∀y ∈s
 
∀z ∈s | (x ⊕y) ⊕z = x ⊕(y ⊕z)

→
∀f
 
Finite(f ) & Svm(f ) & range(f ) ⊆s

→

ΣΘ(f ) ∈s & ΣΘ(∅) = e &

∀x,y | f =

[x, y]

→ΣΘ(f ) = y

&

∀t | ΣΘ(f ) = ΣΘ(f|t) ⊕ΣΘ(f|domain(f )\t)

&

∀x ∈domain(f )| ΣΘ(f ) = ΣΘ(f|domain(f )\{x}) ⊕arb

f {x}

&

∀g |

Svm(g) & domain(f ) = domain(g)

→
ΣΘ(f ) = ΣΘ
	
y,ΣΘ(f|g↰{y})

: y ∈range(g)

is known. This ﬁnal statement is now ﬁrst-order.
The second-order mechanisms needed to proceed in just the manner explained
are not available in our ﬁrst-order setting. The theory mechanism that is provided
serves as a partial but adequate substitute for it.
After these introductory remarks we return to a detailed consideration of the
general theory template displayed at the start of this section. In it, ‘theory_name’
names the theory in which we are interested. A theory’s ‘list_of_assumed_symbols’
is analogous to the parameter list of a procedure. It is a comma-separated
list of symbol names, which stand for other symbols which must replace the
‘assumed_symbols’ whenever the theory is applied. The members of the list of
‘assumptions’ which follow must be formulae which, aside from basic predicate
and set-theoretic constructions (quantiﬁers and set formers), involve only elements
of the ‘list_of_assumed_symbols’, possibly along with other symbols that have been
deﬁned previously to introduction of the theory, in the context in which the theory is
introduced. The formal description of the ‘theory of Sigma’ given above illustrates
these rules.

1.4
More About Our Formalism
23
The ‘conclusions’ which follow the syntactic delimiter ‘=⇒’ in the general
template must be formulae which, aside from basic predicate and set-theoretic
constructions, involve only elements of the ‘list_of_assumed_symbols’ and the
‘list_of_deﬁned_symbols’, along with other symbols that have previously been de-
ﬁned in the context in which the theory is introduced. The elements of the (comma-
delimited) ‘list_of_deﬁned_symbols’ are symbol names (usually carrying the Θ sub-
script), which must be deﬁned within the theory, more precisely as part of a proof
(given within the theory), of the theory’s stated conclusions. Each ‘deﬁned_symbol’
is replaced with a previously unused symbol whenever the theory is applied.
Once a theory has been introduced in the manner just explained, and before it can
be used, a sequence of theorems and deﬁnitions culminating in those which appear
as the conclusions of the theory must be proved in the theory. The syntax used to
begin this process, which temporarily ‘enters’ the theory, is simply
ENTER_THEORY theory_name.
This statement creates a subordinate proof context in which the ‘assumed_sym-
bols’ of the theory, together with all its stated assumptions, are available. Then,
using these assumptions, one must give deﬁnitions of all the theory’s ‘deﬁned_sym-
bols’, and proofs of all its conclusions. Once this has been done, one can return
from the subordinate logical context to the parent context from which it was entered
by executing another ENTER_THEORY command, which now must name the parent
theory to which we are returning. (Proof always begins in a top-level context named
‘Set_theory’.) After return, the theory’s conclusions become available for applica-
tion. Note also that theories previously developed in the parent context of a new
theory T are available for application during the construction of T.
The syntax (analogous to that for ‘calling’ procedures) used to apply theories is
APPLY(deﬁned_symbol_of_theory : new_symbol,... )
theory_name( list_of_replacements_for_assumed_symbols ).
As indicated, the keyword ‘APPLY’ is followed by a comma-delimited sequence
of colon-separated pairs which associates each ‘deﬁned_symbol’ of the theory with
a previously unused symbol, which then replaces the ‘deﬁned_symbol’ in the set of
conclusions that results from successful application of the theory. Next there must
follow a comma-delimited list of symbols deﬁned previously, equal in length to
the theory’s list of ‘assumed_symbols’, which speciﬁes the symbols which are to re-
place the ‘assumed_symbols’ at the point of application. Our veriﬁer replaces all the
‘assumed_symbols’ appearing in the theory’s assumptions with these replacement
symbols, and searches the logical context available at the point of theory applica-
tion for theorems identical with the resulting formulae. If any of these is missing,
the requested theory application is refused. If all are found, then the conclusions of
the theory are turned into theorems by replacing every occurrence of the theory’s
deﬁned symbols by the corresponding ‘new_symbol’ and every occurrence of the
theory’s assumed symbols by its speciﬁed replacement symbol.

24
1
Introduction
Assume, for example, that the ‘SIGMA_theory’ displayed above has been made
available (in the way explained above), and that theorems
0 ∈N,

∀x ∈N| (∀y ∈N| x + y ∈N)

,
(∀x ∈N| x + 0 = x),

∀x ∈N| (∀y ∈N| x + y = y + x)

,

∀x ∈N
 
∀y ∈N
 
∀z ∈N| (x + y) + z = x + (y + z)

have been proved (separately from the theory) for the integers N, and integer addi-
tion. Then the veriﬁer instruction
APPLY(ΣΘ : SIG) SIGMA_theory(N, +, 0)
makes the symbol SIG (which must not have been deﬁned previously) available, and
gives us the theorem

∀f
 
Finite(f ) & Svm(f ) & range(f ) ⊆N

→

SIG(f ) ∈N & SIG(∅) = 0 &

∀x,y | f =

[x, y]

→SIG(f ) = y

&

∀t | SIG(f ) = SIG(f|t) + SIG(f|domain(f )\t)

&

∀x ∈domain(f )| SIG(f ) = SIG(f|domain(f )\x) + arb

f {x}

&

∀g
 
Svm(g) & domain(f ) = domain(g)

→
SIG(f ) = SIG
	
y, SIG(f|g↰{y})

: y ∈range(g)

without further proof.
The theory of equivalence classes is a second important ‘theory’ example.
THEORY equiv_classes( E(u,v), s )

∀x ∈s
 E(x,x)


∀x ∈s
 
∀y ∈s
 
∀z ∈s
 E(x,y) →

E(y,z) ↔E(z,x)

=⇒( EqcΘ, fΘ ) -- ‘quotient’-set and globalized ‘canonical embedding’

∀x ∈s
 fΘ(x) ∈EqcΘ


∀y ∈EqcΘ
 arb(y) ∈s & fΘ

arb(y)

= y


∀x ∈s
 
∀y ∈s
 E(x,y) ↔

fΘ(x) = fΘ(y)


∀x ∈s
 E

x, arb

fΘ(x)


∀x ∈s
 x ∈fΘ(x)

END equiv_classes.
This states that any dyadic ‘equivalence relation’ E(x,y) can be represented
in the form E(x,y) ↔(fΘ(x) = fΘ(y)) by some monadic function fΘ. (Conven-
tionally, one speaks of fΘ(x) as the equivalence class of x; notice, however, that

1.5
An Informal Overview of the Sequence of Formal Set-Theoretic Proofs
25
we are deliberately ‘hiding’ such secondary facts as ∅/∈EqcΘ, s = 
EqcΘ, and
(∀y ∈EqcΘ, x ∈y | fΘ(x) = y)).
The theory of equivalence classes is one of a family of easy but widely applicable
results which represent various kinds of monadic relationships in terms of elemen-
tary relationships which are especially easy to work with (often because decision
algorithms apply to them). For example, one can easily show that any partial order-
ing on set elements x,y can be represented in the form gΘ(x) ⊆gΘ(y). Results of
this kind lend particular importance to the relationships to which they apply.
1.5 An Informal Overview of the Sequence of Formal
Set-Theoretic Proofs to Be Given Later
This text culminates in the sequence of deﬁnitions and theorems found in Chap. 5,
of which we offer a brief overview here. There, theorems will be stated without
proofs, even though very many proofs have already been set up to be veriﬁable by
our system—a sample of them will be shown in Chap. 7. In this section some of
the theorems surveyed are accompanied by semiformal proofs, which can serve as
intuitive guides to the larger mass of detail appearing in their completely formalized
versions.
The theorems found in Chap. 5 fall into the following categories.
1.5.1 Basic Elementary Results
(i)
Deﬁnition and basic properties of ordered pairs. These are fundamental to
many of the following deﬁnitions, e.g. of maps and of the Cartesian product.
(ii)
Deﬁnition of the notions of map, single-valued map, 1-1-map, map restric-
tion, domain, range, map product, etc. and derivation of the ubiquitous elementary
properties of maps, as a long series of elementary theorems. Some of these proper-
ties of maps are captured for convenience in a theory called ‘fcn_symbol’ which can
be used to prove basic properties of set formers deﬁning single-valued maps.
1.5.2 Ordinals
(iii)
Deﬁnition of the notion of ‘ordinal’, and proof of the basic properties of ordi-
nals. Completely formal proofs of all the basic properties of ordinal numbers will be
given in Sects. 7.3.2 and 7.3.5 of Chap. 7. But to make these proofs more compre-
hensible it is well to translate some of them, and some of the key deﬁnitions used in
them, into the more comfortable language of ordinary mathematics. We follow von

26
1
Introduction
Neumann in deﬁning an ordinal as a set (I) properly ordered by membership,1 and
for which (II) members of members are also members. The key results proved are:
(a) the collection of all ordinals is itself properly ordered by membership, and mem-
bers of ordinals are ordinals, but (b) the collection of all ordinals is not a set. Also,
(c) proceeding recursively in the manner explained in Sect. 1.5.3, we deﬁne a stan-
dard enumeration for every set and show that this puts the members of the set in 1-1
correspondence with an ordinal. This is the ‘enumerability principle’ fundamental
to our subsequent work with cardinal numbers.
The von Neumann representation ties the ordinal concept very directly to the
most basic concepts of set theory, allowing the properties of ordinals to be estab-
lished by reasoning that uses only elementary properties of sets and set formers,
with occasional use of transﬁnite induction. (For ease of use, statement and proof
of this general principle are captured as a theory called ‘transﬁnite_induction’: the
principle follows very directly from our strong form of the axiom of choice.)
For example, in the von Neumann representation, the next ordinal after an ordinal
s is simply s ∪{s}. To see that s′ = s ∪{s} must be an ordinal, note ﬁrst that each
member of a member of s′ is either a member of a member of s, or directly a member
of s; and hence in any case a member of s′; thus s′ has property (II). The proof that
s′ also has property (I) is equally elementary and is left to the reader. Together these
show that s′ is an ordinal. Other equally elementary results concerning ordinals,
whose proof is also left to the reader are:
a. The intersection s ∩t of any two ordinals is an ordinal.
b. Any member t of an ordinal s is an ordinal.
Let s be an ordinal. Since any member of a member t of s is a member of s by
(II), any member t of s is a subset of s. Thus for ordinals the membership relation
t ∈s implies the inclusion relation t ⊆s. On the other hand, if t is also an ordinal
and t ⊆s, then either t = s or t ∈s. To prove this, suppose that t ̸= s, and consider
the element x = arb(s \ t). Any element y of t is also an element of s, so by (I)
we have either y ∈x, y = x, or x ∈y. Both y = x and x ∈y would imply x ∈t
which is impossible. Thus we must have y ∈x whenever y ∈t, i.e. t ⊆x. But x \ t
must be null. Indeed, let z ∈x \ t. Then z ∈x, but also z ∈s \ t, contradicting the
fact that x = arb(s \ t) is disjoint from s \ t. Hence x = t, i.e. t is an element of s,
proving our assertion that any subset t of s which is also an ordinal must either be
identical to s or must be a member of s. That is, for ordinals the relationship ‘⊆s’
is equivalent to the condition ‘is a member of s or is equal to s.’
Next we show that, given any two distinct ordinals s and t, one is a member of
the other. Suppose that this is not the case. Then if s = s ∩t then s is a subset of t,
and hence, by the result just proved, is a member of t. Similarly, if t = s ∩t then t is
a member of s. So it follows that s ̸= s ∩t and t ̸= s ∩t. Since s ∩t is an ordinal and
a subset of s, it follows by the result just proved that s ∩t ∈s; similarly s ∩t ∈t,
so s ∩t ∈s ∩t, which is impossible since the membership operator can admit no
cycles. This proves our claim.
1By proper order, we mean strict and total order.

1.5
An Informal Overview of the Sequence of Formal Set-Theoretic Proofs
27
It follows that if s and t are both ordinals, the intersection s ∩t is the smaller
of s and t, while the union s ∪t is the larger of s and t. If O is any non-empty set
of ordinals, then x = arb(O) is a member of O and hence an ordinal. By deﬁnition
of arb, x must be disjoint from O. Hence if y is any other member of O, y ∈x
is impossible so x ∈y must be true. That is, arb(O) must be the smallest of all
the elements of O. Moreover the union O of all the elements of O must be an
ordinal, since if x ∈O and y ∈x then there is an s ∈O such that x ∈s, from
which it follows that y ∈s and so y ∈O, proving that O has property (II).
Moreover if x ∈O and y ∈O, then there must exist s ∈O and t ∈O such that
x ∈s and y ∈t. Then one of s and t, say s, must include the other, and so x and
y must both be members of s. Since s is an ordinal and therefore has property (I),
it follows that either x ∈y, x = y, of y ∈x. Hence O also has property (I). This
shows that the union O of any set of ordinals must itself be an ordinal, which is
easily seen to be the smallest ordinal including all the members of O.
Using the statements just proved it is easy to show that if s is an ordinal, then
s′ = s ∪{s} is the least ordinal greater than s. Indeed, we have shown above that s′
is an ordinal. Moreover s ∈s′, so s′ is larger than s in the ordering of ordinals. If
t is any ordinal larger than s, i.e. s ∈t, then either s′ ∈t, s′ = t, or t ∈s′ by what
has been proved above. But t ∈s′ is impossible, since it would imply that either
t ∈s or t = s, and so in either case would lead to an impossible membership cycle.
Therefore either s′ ∈t or s′ = t, i.e. t is no smaller than s′, proving that s′ is the
least ordinal greater than s, as asserted. It is therefore reasonable to write s ∪{s} as
next(s).
Any ordinal s which is greater than every integer n must have all such n as
members, proving that the set N of all integers must be a subset of the set s. Hence
N must be the smallest ordinal which is greater than every integer n. Therefore the
smallest members of the collection of all ordinals can be written as
0, 1, ..., n, ..., N, next(N), next

next(N)

, ...
in their natural order (of membership). In his initial series of papers on ordinals
Georg Cantor introduced a variety of constructions for ordinals which generalize
various arithmetic constructions for ordinary integers and which allow the sequence
of ordinal notations shown above to be extended systematically.
1.5.3 Well Ordering: The Principle of Transﬁnite Enumerability
The ordinal numbers, as we (or von Neumann, or Cantor) have deﬁned them, capture
an abstract notion of sequential enumeration, even for sets which are not restricted
to be ﬁnite. A crucial property of the ordinals is that they allow any set s to be
enumerated, irrespective of whether s is ﬁnite or inﬁnite. This is the so-called Well-
Ordering Theorem. This famous result is not hard to prove given the very generous
variant of set theory which we allow, which as explained earlier lets us write very

28
1
Introduction
general recursive deﬁnitions in set-theoretic notation, and also admits free use of the
choice operator ‘arb’.
To prove the well-ordering theorem, we ﬁrst show that the collection Ord of all
ordinals is not a set, i.e. that there is no set O such that s is an ordinal if and only
if s ∈O. For otherwise s = O would be an ordinal by what we have just proved,
and so as shown above s ∪{s} would also be an ordinal, implying that s is a member
of a member of O, and so s ∈s, which is impossible.
Next deﬁne a function enum(X,S) of two parameters by writing
enum(X,S) =Def if S ⊆

enum(y,S): y ∈X

then S
else arb

S \

enum(y,S): y ∈X

end if .
That is, we deﬁne enum(X,S) to be the element of S \{enum(y,S):y ∈X} chosen
by ‘arb’ if {enum(y,S): y ∈X} differs from S; otherwise enum(X,S) is simply S.
This deﬁnition implies that the elements
enum(0,S), enum(1,S), enum(2,S), ... , enum(N,S), ...
have the following values:
enum(0,S) = arb(S),
enum(1,S) = arb

S \

arb(S)

,
enum(2,S) = arb

S \

arb(S), enum(1,S)

,
···
enum(N,S) = arb

S \

arb(S), enum(1,S), enum(2,S),...

,
···
The crucial fact, proved in the next paragraph, is that the elements enum(x,S)
remain distinct, for distinct ordinals x, as long as {enum(y,S): y ∈x} is a proper
subset of S. Note also that as the ordinal x increases, so does the set {enum(y,S):
y ∈x}.
It is easy to prove that enum(x,S) and enum(y,S) must be distinct if x and
y are distinct ordinals and both enum(x,S) and enum(y,S) are different from S.
Indeed, one of x and y, say y, must be a member of the other, and then by deﬁ-
nition we must have enum(x,S) = arb(S \ {enum(z,S): z ∈x}), so enum(x,S) ∈
S \ {enum(z,S): z ∈x}, while enum(y,S) ∈{enum(z,S): z ∈x}. It follows from
this that there must exist an ordinal x for which S = {enum(z,S): z ∈x}. For if
this is false, then by what we have just proved the mapping z →enum(z,S) maps
the collection of all ordinals in 1-1 fashion into a subset of the set S. But an axiom
of set theory (the so-called ‘Axiom of Replacement’, detailed below) tells us that
every collection which can be put in 1-1 correspondence with a set must itself be a
set. Hence it would follow that the collection of all ordinals is a set, contradicting
what has been proved above.

1.5
An Informal Overview of the Sequence of Formal Set-Theoretic Proofs
29
Since we have just shown that there exists an ordinal x such that {enum(z,S):z ∈
x} = S, there must exist a least such ordinal y, which we can deﬁne as
arb

y ∈next(x)| S =

enum(z,S): z ∈y

.
It is easily seen (we leave details to the reader) that z →enum(z,S) maps this y in
1-1 fashion onto S, completing our proof of the Well-Ordering Theorem.
1.5.4 Cardinal Numbers
(iv)
Deﬁnition of ‘cardinality’ and of the operator #s which gives the (possibly
inﬁnite) number of members of a set s. The cardinality of a set is deﬁned as the
smallest ordinal which can be put into 1-1 correspondence with the set, and it is
proved that (a) there is only one such ordinal, and (b) this is also the smallest ordinal
which can be mapped onto s by a single-valued map.
The proof of the Well-Ordering Theorem puts us in position to introduce the no-
tion of cardinal number and to prove the basic elementary properties of these num-
bers. We deﬁne the cardinals as a subcollection of the ordinals; an ordinal x is called
a cardinal if x cannot be put into 1-1 correspondence with any smaller ordinal. By
the Well-Ordering Theorem, any set s can be put in 1-1 correspondence with some
ordinal, and arguing as above it follows that s can be put in 1-1 correspondence
with some smallest ordinal x. Since the composition of two 1-1 mappings is itself
1-1, it follows that this unique x must itself be a cardinal. We call this cardinal the
cardinality of s, and write it (using the standard number sign) as #s.
In this section we also deﬁne the notions of cardinal sum and product of two sets
a and b. These are, respectively, deﬁned as #(copy_a ∪copy_b), where copy_a and
copy_b are disjoint copies of a and b, and the cardinality of the Cartesian product
a × b of a and b. Using these deﬁnitions, it is easy to prove the associative and
distributive laws of cardinal arithmetic. We also prove a few basic properties of the
#s operator, e.g. its monotonicity.
(v)
A set s is then deﬁned to be ﬁnite if it has no 1-1 mapping into a proper subset
of itself, or, equivalently, is not the single-valued image of any such proper subset.
We prove that the null set and any singleton are ﬁnite, and (using transﬁnite induc-
tion) that the collection of ﬁnite sets is closed under the union, Cartesian product,
and power set operators. It is proved that s is ﬁnite if and only if its cardinality #s is
ﬁnite. We then prepare for the introduction of signed integer arithmetic by proving
all the basic arithmetic properties of unsigned integers and then deﬁning the cardinal
subtraction operator a −b and showing that for ﬁnite cardinals subtraction has its
expected properties. We also prove that integer division with remainder is always
possible. These results are proved with the help of a modiﬁed version of the princi-
ple of induction which is demonstrated for ﬁnite sets: given any predicate P(x) not
true for all ﬁnite sets, there exists a ﬁnite set s for which P(s) is false, but P(s′)
is true for all proper subsets of s. Like the rather similar transﬁnite induction, this
principle is captured for convenience in a theory.

30
1
Introduction
(vi)
Sets which are not ﬁnite are said to be inﬁnite. By considering the cardinality
#s∞of the inﬁnite set s∞whose existence is assumed in an axiom of inﬁnity, we
prove that there exists an inﬁnite cardinal, and so can deﬁne the set N of integers
as the least inﬁnite ordinal, and show that this is a cardinal, and is in fact the set of
all ﬁnite cardinals. The set N of all integers is inﬁnite, since the 1-1 correspondence
n →next(n) maps N to a subset of itself (the zero integer, i.e. ∅, is not in the range
of ‘next’). It is not hard to see that if the set s is ﬁnite, so is next(s) = s ∪{s}. Indeed,
if s ∪{s} is inﬁnite, there exists a 1-1 mapping f of s ∪{s} to a proper subset of
itself. The range of the mapping f must therefore omit some element of s ∪{s}, i.e.
must either omit s or some element x of s. Consider the latter of these two cases.
We can plainly construct a 1-1 mapping g of s ∪{s} onto itself which interchanges x
and s. Then the composition of f and g is a 1-1 mapping of s ∪{s} into itself whose
range omits the value s. This shows that if next(s) is inﬁnite, there must always exist
a 1-1 mapping f of next(s) into s, but then f maps s into s \ {f (s)}, so s is also
inﬁnite. I.e., s is inﬁnite if next(s) is inﬁnite, implying that next(s) is ﬁnite if s is
ﬁnite.
It follows that all the integers 0 = ∅, 1 = next(0), 2 = next(1),... are ﬁnite, and
so each of these ordinals must also be a cardinal. Moreover, the inﬁnite ordinal
N must also be a cardinal. Indeed, if this is not the case, there would exist a 1-1
mapping f of N into a smaller ordinal, i.e. to some integer n ∈N. But then f would
also map the subset next(n) of N into its proper subset n, implying that next(n)
is inﬁnite, which we have seen to be impossible. Thus N is not only the smallest
inﬁnite ordinal but also the smallest inﬁnite cardinal. This implies that
#0 = 0, #1 = 1, #2 = 2, ..., #N = N
(every cardinal is its own cardinality, and every ordinal less than or equal to N is
a cardinal). On the other hand, the cardinality of next(N) = N ∪{N} is simply N.
Indeed, we have seen that there exists a 1-1 mapping f of N into itself whose range
omits the integer 0; this can plainly be extended to a 1-1 mapping of N ∪{N} into
N. This same argument shows that if #s = N then #next(s) = N also. Therefore the
sequence of cardinalities of the ordinals
0, 1, 2, ..., N, next(N), next

next(N)

, next

next

next(N)

, ...
is
0, 1, 2, ..., N, N, N, N, ....
That is, all the inﬁnite ordinals displayed, though distinct, have the same cardinality.
Any set s whose cardinality #s is N is said to be denumerable, or countably inﬁnite;
and a set which is either ﬁnite or denumerable is said to be countable. Our next
question is: how can we be sure that uncountable sets, namely sets whose cardinality
exceeds N, actually exist?
(vii)
Another idea is plainly needed if we are to show that there exist any cardinals
larger than N. As a digression, we prove that the sum and product of any two inﬁnite

1.5
An Informal Overview of the Sequence of Formal Set-Theoretic Proofs
31
cardinals degenerates to their maximum (hence there are no more rational numbers
than there are integer numbers), but (Cantor’s Theorem) that the power set of any
cardinal always has a larger cardinality. Cantor noted that for any set s, the set
P(s) of all subsets of s must have cardinality larger than that of s. For suppose
the contrary, i.e. suppose that there exists a 1-1 mapping f of s onto P(s). Then
consider the subset {x : x ∈s | x /∈f (x)} of s. This must have the form f (y) for
some y ∈s; hence f (y) = {x : x ∈s | x /∈f (x)}. But then y ∈f (y) is equivalent
to y ∈{x : x ∈s | x /∈f (x)}, i.e. to y /∈f (y), which is impossible. (Incidentally,
since a 1-1 correspondence between reals and P(N) can be found, this implies that
real numbers form an uncountable set.)
Since s always has a 1-1 embedding into P(s) (we can simply map each x in s
into the singleton {x}), the cardinality of s is never greater than that of P(s). The
theorem of Cantor proved in the preceding paragraph shows that in fact we always
have #s < #P(s), i.e. #s ∈#P(s). Hence #P(N) is an inﬁnite cardinal which is
deﬁnitely larger than N; similarly #P(#P(N)) is larger than #P(N) and so forth,
proving that there must exist inﬁnitely many inﬁnite cardinals. In fact, we can easily
prove that there exists a 1-1 correspondence between the collection of all ordinals
and the collection of all cardinals. For this, we simply need to make the transﬁnite
inductive deﬁnition
alph(x) =Def arb

z:z ∈

next

#P

alph(y): y ∈x

\

alph(y):y ∈x

 Is_cardinal(z)

,
where ‘Is_cardinal’ is the predicate, easily expressible in elementary set-theoretic
terms, which states that its argument y is a cardinal number. Since all the occur-
rences of ‘alph’ on the right-hand side of this deﬁnition lie in the scope of con-
straints of the form ‘y ∈x’, this is a legal transﬁnite deﬁnition according to the rule
stated earlier. For each ordinal x, this formula deﬁnes alph(x) to be the smallest
cardinal (if any) which is not more than #P({alph(y): y ∈x}) but is not one of
the cardinals alph(y) for any ordinal y less than x. Since we have seen above that
u = {alph(y): y ∈x} is an ordinal at least as large as any of the alph(y) for y ∈x,
and also that #P(u) is larger than u, the set next(#P(u)) \ {alph(y): y ∈x}) must
be nonempty, and so alph(x) must indeed be the smallest cardinal greater than all
of the cardinals alph(y) for any ordinal y ∈x. It is easily seen (details are left to the
reader) that alph(y) < alph(z) if y < z. Hence the function ‘alph’ is a 1-1, monotone
increasing map of the collection of all ordinals to the collection of all cardinals. It is
not hard to prove that every cardinal must appear as one of the alph(y). Thus ‘alph’
actually puts the collection of all ordinals in 1-1 correspondence with the collection
of all cardinals. For small ordinals we have
alph(0) = 0, alph(1) = 1, alph(2) = 2, ..., alph(N) = N.
A mystery, ﬁrst encountered by Cantor, occurs at the very next position in this
sequence. alph(next(N)) is the smallest cardinal greater than N. We have seen that

32
1
Introduction
the cardinal number #P(N) is larger than N; hence alph(next(N)) ⩽#P(N). But is
this inequality actually an equality, or does there exist a cardinal number between N
and #P(N)? Indeed, do there exist inﬁnitely many cardinal numbers in this range?
This is the so-called ‘Continuum problem’, originally stated by Cantor. Its very sur-
prising resolution, ultimately achieved by Kurt Gödel and Paul Cohen, required over
60 years of penetrating work: the statement alph(next(N)) = #P(N) is independent
of the axioms of set theory, which admit both of models in which this statement is
true and of many structurally distinct models in which it is false.
1.5.5 Survey of the Major Sequence of Deﬁnitions and Proofs
Considered in This Text
(viii)
The set of signed integers is then introduced as the set of pairs [x,0] (repre-
senting the positive integers) and [0,x] (representing the integers of negative sign).
[0,0] is the ‘signed integer’ 0, and the 1-1 mapping x →[x,0], whose inverse is
simply y →y[1], embeds N into the set of signed integers, in a manner allowing
easy extension of the addition, subtraction, multiplication, and division operators to
signed integers. In preparation for introduction of the set of rational numbers, it is
proved that the set of signed integers is an ‘integral domain’. At this point, we are
well on the royal road of standard mathematics.
(ix)
Next we introduce two important ‘theories’ mentioned above: the theory of
equivalence classes and the theory of Sigma. As previously noted, the theory of
Sigma is a formal substitute for the common but informal mathematical use of ‘three
dot’ summation (and product) notations like
a1 + a2 + ··· + an
and
a1 ∗a2 ∗··· ∗an.
The theory of equivalence classes characterizes the dyadic predicates R(x,y)
which can be represented in terms of the equality predicate using a monadic func-
tion, i.e. as R(x,y) ↔(f (x) = f (y)). These R are the so-called ‘equivalence rela-
tionships’, and for each such R deﬁned for all x belonging to a set s, the theory of
equivalence classes constructs f (for which arb turns out to be an inverse), and the
set into which f maps s. This range is the ‘family of equivalence classes’ deﬁned
by the dyadic predicate R. The construction seen here, which traces back to Gauss,
is ubiquitous in 20th century mathematics.
(x)
Next the family Q of rational numbers is deﬁned as the set of equivalence
classes arising from the set of all pairs [n,m] of signed integers for which m ̸= 0.
To do this we consider the equivalence relationship
Same_frac

[n,m],[n′,m′]

↔Def n ∗m′ = n′ ∗m.

1.5
An Informal Overview of the Sequence of Formal Set-Theoretic Proofs
33
The mapping n →[n,1], whose inverse is simply x[1], embeds the signed inte-
gers into the rationals in a manner preserving all elementary algebraic operations,
and also preserving order. From the fact that the set of signed integers is an ordered
integral domain we easily prove that the rationals are an ordered ﬁeld.
(xi)
Our next step, following Cantor, is to deﬁne real numbers as equivalence
classes of ‘Cauchy sequences’ si of rationals. Here, a sequence is a Cauchy sequence
if it satisﬁes2

∀ε ∈Q
 
∃n ∈N
 
∀i,j ∈N| (ϵ > 0 & i > n & j > n) →|si −sj| < ϵ

.
The equivalence relation used is
Same_real(s,t) ↔Def

∀ε ∈Q
 
∃n ∈N
 
∀i ∈N| (ε > 0 & i > n) →|si −ti| < ε

.
Arithmetic operations for these equivalence classes are easily derived from the
corresponding functions for rationals, and the ‘completeness’ of the set of real num-
bers, a key goal of early 19th century foundational work on analysis, can be proved
without difﬁculty.
Since it is required for the elementary discussion of complex numbers, we prove
the existence and basic properties of the square root, which is shown to exist for any
non-negative real number.
(xii)
Next the complex numbers are introduced as pairs of real numbers, and their
elementary properties are established. In particular, they are shown to constitute a
ﬁeld, within which the ﬁeld of real numbers has a natural embedding. The modulus
of a complex number is deﬁned and its basic properties demonstrated.
(xiii)
This completes our preliminary work. What remains is to give the formal de-
tails of those parts of standard mathematical analysis needed to state and prove our
assigned target result, the Cauchy integral theorem. For this, various familiar results
concerning differentiation and integration are needed, ﬁrst for functions of a real
variable, then for functions of a complex variable. Our approach is as follows. The
space of all real functions of a real variable is deﬁned, along with the (pointwise)
operations of addition, subtraction, and multiplication for functions, function com-
parison, the positive part of a function, and the least upper bound of a set of func-
tions. Various elementary facts concerning this space of functions are established. In
particular, it is shown that they form a ring under addition and multiplication. This
allows application of the previously developed ‘theory of Sigma’ to deﬁne the sum
of an arbitrary ﬁnite sequence of real functions. In preparation for the deﬁnition of
2Conciser, but less classical, characterizations of Cauchy sequences and of equivalence between
them will be seen in Sect. 4.1.4.

34
1
Introduction
the (ordinary Lebesgue) integral, the sum of an absolutely convergent series of pos-
itive real numbers is deﬁned, and the basic properties of such sums are established.
This prepares for deﬁnition of the sum of an absolutely convergent series of positive
real functions, and for a proof of a few basic properties of such series.
In more direct preparation for deﬁnition of the integral, we deﬁne ‘block’ func-
tions as real-valued functions of a real variable which are constant inside some ﬁnite
interval of the real axis, and zero outside this interval. The integral of such a function
is simply the area under its graph, which is an elementary rectangular block.
The greatest lower bound of a set of real numbers bounded below is then deﬁned.
This is immediately used to deﬁne the (Lebesgue) ‘upper’ integral of an arbitrary
non-negative real function of a real variable. This is the greatest lower bound of the
sum the integrals of all inﬁnite sequences of non-negative block functions, extended
over all such sequences whose (pointwise) sum exceeds the value f (x) at each real
point x. Using this, we can deﬁne the integral of an arbitrary real function f (which
now can have values of both signs) as the difference of the upper integrals of its
positive and negative parts.
A function f of a real value is deﬁned to be continuous if it satisﬁes the standard
‘epsilon–delta’ condition. To deﬁne the derivative of such functions by the technique
we adopt, the extension of this deﬁnition to the space of real-valued functions of
two real variables is needed. To set this up, we ﬁrst deﬁne n-dimensional Euclidean
space as the set of all real-valued maps whose domain is the set of integers less than
n. The standard Euclidean distance function is deﬁned in this space and its basic
properties are proved. Once this has been done, the space of continuous real-valued
functions on a Euclidean space of any number of dimensions can be deﬁned by
extending the ‘epsilon–delta’ formulation to this slightly more general setting. We
can then deﬁne a real-valued function f of one real variable to be (continuously)
differentiable if there exists a real-valued function g of two real variables such that
(x −y)∗g(x,y) = f (x)−f (y) for all real x and y. We prove that if such a g exists
it is unique, in which case we deﬁne the derivative of f as the function h of one
variable satisfying h(x) = g(x,x).
Next this whole discussion is carried over to complex functions of a complex
variable. We successively deﬁne the space of all such functions, the complex Eu-
clidean space of n dimensions with its norm, and the sum, difference, and product
for complex-valued functions, either of a single complex variable, or of a point in
complex Euclidean space. The ‘epsilon–delta’ deﬁnition of continuity is extended
to the complex case for both these classes of functions. This allows direct exten-
sion of the notion of derivative, and of its elementary properties, to complex-valued
functions of a complex variable.
A set of points in the complex plane is deﬁned to be open if it is the union of the
interiors of a set of circles, and a complex function deﬁned in such a set is deﬁned
to be analytic if it is differentiable within the set.
Next we deﬁne the complex exponential function cexp as the unique com-
plex function analytic everywhere in the complex plane and satisfying the equa-
tions Dcexp = cexp and cexp([0,0]) = [1,0], where Dcexp denotes the deriva-
tive of cexp. The constant π is then deﬁned as the smallest positive real root of
cexp([0,x]) = [−1,0].

1.5
An Informal Overview of the Sequence of Formal Set-Theoretic Proofs
35
Directly after this, we deﬁne the notion of a continuous complex function of a
real variable by extending the ‘epsilon–delta’ formulation to this case in the obvious
way. A similar extension of the construction used in the real case gives us the no-
tion of a differentiable complex-valued function of a real variable (i.e. of a smooth
curve in the complex plane), and of its derivative. The complex line integral of a
complex function g deﬁned on such a curve is then taken to be the ordinary integral
of the complex product of g by Df (where as before Df is the derivative of f );
the integral of the complex-valued function h = g ∗Df (which is a function of a
single real variable) is by deﬁnition obtained by adding the real integrals of the real
and imaginary parts of h. We show that the line integrals of an analytic function g
over any two curves lying in its domain of analyticity are the same, provided that
the two curves lie sufﬁciently close to one another. Using this, we show that the line
integral over the periphery of the unit circle of the quotient function f/(z −w) is
2 ∗π ∗i ∗f [w] for every function f analytic in an open set including the unit circle
and its interior, and for every point interior to the unit circle.
Satisﬁed with this somewhat special form of the Cauchy integral theorem, we
rest from our labors.


Chapter 2
Propositional- and Predicate-Calculus
Preliminaries
This chapter prepares for the extensive account of our veriﬁer system given in
Chap. 4 by describing and analyzing two of the system’s basic ingredients, the
propositional calculus, from which we take all necessary properties of the logical
operations &, ∨, ¬, →, and ↔, and the (ﬁrst-order) predicate calculus, which to
these propositional mechanisms adds compound functional and predicate construc-
tions and the two quantiﬁers ∀and ∃. Then we will show the axioms of a classical
speciﬁcation of set theory in predicate calculus; to end, we will highlight the much-
debated issue of the consistency of this Zermelo–Fraenkel–Skolem theory and of
some of its proposed extensions.
Why Predicate Calculus?
Our aim is to develop a mechanism capable of en-
suring that the logical formulae in which we are interested are universally valid.
Since, as we shall see in Chap. 6, there can exist no algorithm capable of making
this determination in all cases, we must use the mechanism of proof. This embeds
the formulae in which we are interested in some system of sequences of formulae,
within which we can deﬁne a property Is_a_proof(p) capable of being veriﬁed by an
algorithm, such that we can be certain that the ﬁnal component t of any sequence p
satisfying Is_a_proof(p) is universally valid. Then we can use intuition freely to ﬁnd
aesthetically pleasing sequences p, the proofs, leading to interesting end goals t, the
theorems. In principle, any system of formulae and sequences of formulae having
this property is acceptable. The propositional/predicate calculus and set theory in
which we work is merely one such formalism, of interest because of its convenience
and wide use, and because much effort has gone into ensuring its reliability.
2.1 The Propositional Calculus
The propositional calculus constitutes the ‘bottom-most’ part of the full logical for-
malism with which we will work in this book. It provides only the operations &,
∨, ¬, →, and ↔and the two constants ‘true’ and ‘false’, all other symbolic con-
J.T. Schwartz et al., Computational Logic and Set Theory,
DOI 10.1007/978-0-85729-808-9_2, © Springer-Verlag London Limited 2011
37

38
2
Propositional- and Predicate-Calculus Preliminaries
structions being reduced (‘blobbed’) down to single letters when propositional de-
ductions must be made. An example given earlier, i.e. the formula

F(x+y) = F

F(x)

→F

F(x)

= 0

→

F

F(x)

̸= 0 →F(x+y) ̸= F

F(x)

whose ‘blobbed’ propositional skeleton is
(p →q) →

(¬q) →(¬p)

,
illustrates what is meant.
Formulae of the propositional calculus are built starting with string names desig-
nating propositional variables and combining them using the dyadic inﬁx operators
‘&’, ‘∨’, ‘→’, and ‘↔’ and the monadic operator ‘¬’. Parentheses are used to group
the subparts of formulae. The only precedence relation supported is the rule that ‘&’
binds more tightly than ‘∨’, so parentheses must normally be used rather liberally.
Syntactically, the propositional calculus is a simple operator language, whose (syn-
tactically valid) formulae parse unambiguously into syntax trees, each of whose
internal nodes is marked either with one of the allowed inﬁx operators, in which
case it has two descendants, or with the monadic operator ‘¬’, in which case it
has one descendant. Each leaf of such a tree is marked either with the name of a
propositional variable or with one of the two allowed constant symbols ‘true’ and
‘false’.
An example is
(pan →quack) →

(¬quack) →(¬true)

.
Here the propositional variables which appear are ‘pan’ and ‘quack’, and the con-
stant ‘true’ also appears.
Since the derivation of the syntax tree of a propositional formula from its string
form (‘parsing’) and of the string form from the syntax tree (‘unparsing’) are both
standard programming operations, we generally regard these two structures as being
roughly synonymous and use whichever is convenient without further ado.
As in other logical systems we can think of our formulae either in terms of the
values of functions which they represent, or as statements deducible from one an-
other under certain circumstances, and so as the ingredients of some system of for-
malized proof. We begin with the ﬁrst approach. In this way of looking at things,
each propositional variable represents one of the truth values 1 or 0, which the
propositional operators combine in standard ways. The following more formal deﬁ-
nition captures this idea:
Deﬁnition 2.1 An assignment for a collection of propositional formulae is a single-
valued function A mapping each of its constants and variables into one of the two
values 1 and 0. Each assignment is required to map ‘true’ into 1 and ‘false’ into 0.
The assignment is said to cover each of the formulae in the collection.
Given any such assignment A, and a formula F which it covers, the value
Val(A,F) of the assignment A for the expression F is the Boolean value deﬁned
in the following recursive way.

2.1
The Propositional Calculus
39
(i) If the formula F is just a variable x or is one of the constants ‘true’ and ‘false’,
then Val(A,F) = A(F).
(ii) If the formula F has the form ‘G & H’, then Val(A,F) is the minimum of
Val(A,G) and Val(A,H).
(iii) If the formula F has the form ‘G ∨H’, then Val(A,F) is the maximum of
Val(A,G) and Val(A,H).
(iv) If the formula F has the form ‘¬G’, then Val(A,F) = 1 −Val(A,G).
(v) If the formula F has the form ‘G →H’, then Val(A,F) = Val(A, ‘(¬G) ∨H’).
(vi) If the formula F has the form ‘G ↔H’, then
Val(A,F) = Val

A, ‘(G & H) ∨

(¬G) & (¬H)

’

.
Deﬁnition 2.2 A propositional formula F is a tautology if Val(A,F) = 1 for all the
assignments A covering it.
So tautologies are propositional formulae which evaluate to true no matter what
truth values are assigned to their variables. Examples are
p ∨(¬p),
q →(p →q),
p →

q →(p & q)

,
and many others, some listed below. These are the propositional formulae which
possess ‘universal logical validity’.
Since the number of possible assignments A for a propositional formula F is
at most 2n, where n is the number of variables in the formula, we can determine
whether F is a tautology by evaluating Val(A,F) for all such A. An alternative
approach is to establish a system of proof by singling out some initial collection of
tautologies (which we will call ‘axioms’) from which all remaining tautologies can
be derived using rules of inference, which must also be deﬁned. (This is the ‘logical
system’ approach.) The axioms and rules of inference can be chosen in many ways.
Though not at all the smallest possible set, the following collection has a familiar
and convenient algebraic ﬂavor.
(i) (p & q) ↔(q & p)
(ii) ((p & q) & r) ↔(p & (q & r))
(iii) (p & p) ↔p
(iv) (p ∨q) ↔(q ∨p)
(v) ((p ∨q) ∨r) ↔(p ∨(q ∨r))
(vi) (p ∨p) ↔p
(vii) (¬(p & q)) ↔((¬p) ∨(¬q))
(viii) (¬(p ∨q)) ↔((¬p) & (¬q))
(ix) ((p ∨q) & r) ↔((p & r) ∨(q & r))
(x) ((p & q) ∨r) ↔((p ∨r) & (q ∨r))
(xi) (p ↔q) →((p & r) ↔(q & r))
(xii) (p ↔q) →((p ∨r) ↔(q ∨r))

40
2
Propositional- and Predicate-Calculus Preliminaries
(xiii) (p ↔q) →((¬p) ↔(¬q))
(xiv) (p ↔q) →(q →p)
(xv) (p →q) ↔((¬p) ∨q)
(xvi) (p ↔q) ↔((p →q) & (q →p))
(xvii) (p & q) →p
(xviii) (p ↔q) →((q ↔r) →(p ↔r))
(xix) (p ↔q) →(q ↔p)
(xx) (p ↔p)
(xxi) (p & (¬p)) ↔false
(xxii) (p ∨(¬p)) ↔true
(xxiii) (¬(¬p)) ↔p
(xxiv) (p & true) ↔p
(xxv) (p & false) ↔false
(xxvi) (p ∨true) ↔true
(xxvii) (p ∨false) ↔p
(xxviii) (¬true) ↔false
(xxix) (¬false) ↔true
(xxx) true
The preceding are to be understood as axiom ‘templates’ or ‘schemas’, in the
sense that all formulae resulting from one of them by substitution of syntactically
legal propositional formulae P,Q,... for the letters p,q,... occurring in them are
also axioms. For example,

(p ∨q) ∨(r →r)

&

(p ∨q) ∨(r →r)

↔

(p ∨q) ∨(r →r)

is a substituted instance of (iii) and therefore is also regarded as an axiom.
The reader can verify that all of the axioms listed are in fact tautologies.
In the presence of this lush collection of axioms we need only one rule of infer-
ence (namely the ‘modus ponens’ of mediaeval logicians). From any two formulae
of the form p and p →q this allows us to deduce q. As with the axioms, this rule
is to be understood as a template, covering all of its substituted instances.
To ensure that the tautologies are exactly the derivable propositional formulae
we must prove soundness, namely that (I) only tautologies can be derived, and com-
pleteness, namely that (II) all tautologies can be derived. (I) is easy. We reason as
follows. All the axioms are tautologies. Moreover, since
Val(A, p →q) = max

1 −Val(A,p), Val(A,q)

,
it follows that if Val(A,p →q) and Val(A,p) are both 1, so is Val(A,q). So if
‘p →q’ and p are both tautologies, then so is q. This proves our claim (I).
Proving claim (II) takes a bit more work, whose general pattern is much like that
used to reduce multivariate polynomials to their canonical form. Starting with any
syntactically well-formed propositional formula F , we can proceed in the following
way to derive a chain of formulae equivalent to F (via an explicit chain of equiva-
lences Fi ↔Fi+1). Note that axioms (xviii–xx) ensure that the equivalence relator

2.1
The Propositional Calculus
41
‘↔’ has the same transitivity, symmetry, and reﬂexivity properties as equality, while
(xi–xiii) allow us to replace any subexpression of an expression formed using only
the three operators &, ∨, ¬ by any equivalent subexpression.
Using these facts and (xv–xvi) we ﬁrst descend recursively through the syntax
tree of F , replacing any occurrence of one of the operations →, ↔by an equiv-
alent expression involving only &, ∨, ¬. This reduces F to an equivalent formula
involving only the operators &, ∨, ¬. Then, using (vii–viii) and (x), we systemat-
ically push ‘¬’ and ‘∨’ operators down in the syntax tree, moving ‘&’ operators
up. Subformulae of the form (¬(¬p)) are simpliﬁed to p using axiom (xxiii). Ax-
ioms (xxiv–xxix) can be used to simplify expressions containing the constants ‘true’
and ‘false’. When this work is complete F will been have reduced to an equivalent
formula F ′ which is either one of the constants ‘true’ or ‘false’ or has the form
a1 & ··· & ak, where each aj is a disjunction of the form
b1 ∨··· ∨bh,
each bm being either a propositional variable or the negation of a propositional vari-
able. (ii) and (v) allow us to think of these conjunctions and disjunctions without
worrying about how they are parenthesized. Then (iv) and (vi) can be used to bring
all the bm involving a particular propositional variable together within each aj.
Now assume that F is a tautology, so that every one of the formulae to which
we have reduced it must also be a tautology (since the substitutions performed all
convert tautologies to tautologies), and so our ﬁnal formula F ′ is a tautology. We
will now further reduce F ′, so that it becomes the formula ‘true’. Unless F ′ is
already ‘true’, in each aj, there must occur at least one pair bm, bn of disjuncts such
that bm is a propositional variable of which bn is the negation, ‘¬bm’. Indeed, if this
is not the case, then any propositional variable which occurs in aj will occur either
negated or non-negated, but not both. Given this, we can assign the value 0 to each
non-negated variable and the value 1 to each negated variable. Then every bm in aj
will evaluate to 0, so the whole expression b1 ∨···∨bh will evaluate to 0, that is, aj
will evaluate to 0. But as soon as this happens the whole formula a1 & ··· & ak will
evaluate to 0. This shows that there exists an assignment A such that Val(A,F ′) = 0,
contradicting the fact that F ′ is a tautology. This contradiction proves our claim that
each aj must contain at least one pair bm, bn of disjuncts which agree except for the
presence of a negation operator in one but not in the other.
Given this fact, (xxii) tells us that ‘bm ∨bn’ simpliﬁes to ‘true’, so that (xxvi)
can be used repeatedly to simplify aj to ‘true’. Since this is the case for each aj,
repeated use of (xxiv) allows us to reduce any tautology to ‘true’ using a chain
of equivalences. Since this chain of equivalences can as well be traversed in the
reverse direction, we can equally well expand the axiom ‘true’ (axiom (xxx)) into
our original formula F using a chain of equivalences. Then (xiv) can be used to
convert this chain of equivalences into a chain of implications, giving us a proof of
F , by repeated uses of modus ponens.
Any set of axioms from which all the statements (i–xxx) can be derived as theo-
rems can clearly be used as an axiomatic basis for the propositional calculus. This

42
2
Propositional- and Predicate-Calculus Preliminaries
allows much leaner sets of axioms to be used. We refrain from exploring this point,
which lacks importance for the rest of our discussion.
However, it is worth embedding the notion of ‘tautology’ in a wider, relativized,
set of ideas. Suppose that we write
|= F
to indicate that the formula F is a tautology, and
⊢F
to indicate that F is a provable formula of the propositional calculus. The preceding
discussion shows that |= F , and ⊢F , are equivalent conditions. This result can be
generalized as follows. Let S designate any ﬁnite set of syntactically well-formed
formulae of the propositional calculus. We can then write
S |= F
to indicate that, for each assignment A covering both F , and all the formulae in S,
we have Val(A,F) = 1 whenever Val(A,G) = 1 for all G in S. Also, we write
S ⊢F
to indicate that F follows by propositional proof if the statements in S are added to
the axioms of propositional calculus (each of them acting as an individual axiom,
not as a template). Then it is easy to show that
S |= F
if and only if
S ⊢F.
To show this, ﬁrst suppose that S |= F . Let C designate the conjunction
G1 & ··· & Gk
of all the formulae in S. Then since Val(A,H1 & H2) = min(Val(A,H1), Val(A,H2))
for any two formulae H1,H2, it follows that Val(A,C) = 1 if and only if
Val(A,G) = 1 for all G in S. We have
Val(A, C →F) = Val

A, (¬C) ∨F

= max

1 −Val(A,C), Val(F)

for all assignments A covering C →F , (i.e. covering both F , and all the formulae
in S). It follows that for each assignment A covering both F , and all the formulae
in S, we have Val(A,C →F) = 1, since if 1 −Val(A,C) ̸= 1 then Val(A,C) must
be 1 and so Val(F) must be 1. Thus
|= C →F,
and so it follows that ⊢C →F , i.e. C →F can be proved from the axioms of
propositional calculus alone. But then if the statements in S are added as additional

2.1
The Propositional Calculus
43
axioms we can prove F , by ﬁrst proving C →F , and then using the statements in
S to prove the conjunction C. This shows that S |= F implies S ⊢F .
Next suppose that S ⊢F , and let A be an assignment covering both F , and all the
formulae in S so that Val(A,G) = 1 for every statement G in S. Then Val(A,G) = 1
for every statement G that can be used as an axiom in the proof of F , from the
standard axioms of propositional calculus and the statements in S as additional ax-
ioms. But we have seen above that if Val(A,p →q) and Val(A,p) are both 1, so
is Val(A,q). Since derivation of q from p and p →q is the only inference step al-
lowed in propositional calculus proofs, it follows that S |= F , completing our proof
that the conditions S |= F , and S ⊢F , are equivalent.
We shall see that similar statements apply to the much more general predicate
calculus studied in the following section. In that section, we will need the following
extension of the preceding results to countably inﬁnite collections of propositional
formulae.
Deﬁnition 2.3 A (ﬁnite or inﬁnite) collection S of formulae of the propositional
calculus is said to be consistent if the proposition ‘false’ cannot be deduced from S,
i.e.
S ⊢false
is false. We say that S has a model A if there exists some assignment A covering
all the formulae of S such that Val(A,F) = 1 for every F in S.
Theorem 2.1 (Compactness) Let S be a denumerable collection of formulae of the
propositional calculus. Then the following three conditions are equivalent:
(i) S is consistent.
(ii) Every ﬁnite subset of S is consistent.
(iii) S has a model.
Proof Since subsets of a consistent S are plainly consistent, (i) implies (ii). On
the other hand, any proof of ‘false’ from the statements of S is of ﬁnite length by
deﬁnition, and so uses only a ﬁnite number of the statements of S. Thus (ii) implies
(i), so (ii) and (i) are equivalent.
Next suppose that S is not consistent, so that ‘false’ can be proved from some
ﬁnite subset S′ of the statements in S. Let C be the conjunction of all the statements
in S′. It follows from the discussion immediately preceding the statement of the
present theorem that ⊢C →false, and so Val(A,‘C →false’) = 1 for any assign-
ment A covering all the propositional symbols in S. This gives Val(A,C) = 0 for all
such A, so that S has no model. This proves that (iii) implies (i).
Next we show that (i) implies (iii). For this, let {Sj} be an increasing sequence of
ﬁnite subsets of S whose union is all of S. Each Sj is plainly consistent, so
Sj ⊢false

44
2
Propositional- and Predicate-Calculus Preliminaries
is false for each j, and therefore
Sj |= false
is false, since we have shown above that these two conditions are equivalent for ﬁnite
Sj. That is, for each j there must exist an assignment Aj covering all the variables
appearing in any formula of Sj, such that Val(Aj, Sj) = 1. Let v1,v2,v3,... be an
enumeration of all the variables appearing in any of the formulae of S. Then each
vk must be in the domain of all Aj for all j beyond a certain point j = jk.
Let I0 designate the sequence of all integers. Since Aj(v1) must have one of the
two values 0 and 1, there must exist an inﬁnite subsequence I1 of I0 for all j of
which Aj(v1) has the same value. Call this value B(v1). Arguing in the same way
we see that here must exist an inﬁnite subsequence I2 of I1 and a Boolean value
B(v2) such that
B(v2) = Aj(v2)
for all j in I2.
Arguing repeatedly in this way we eventually construct values B(vk) for each k such
that for each ﬁnite m, there exist inﬁnitely many j such that
B(vn) = Aj(vn)
for all n from 1 to m.
Now consider any of the formulae G of S. Since G can involve only ﬁnitely many
propositional variables vj, all its variables will be included in the set {v1,...,vk}
for each sufﬁciently large k. Take any Aj for which B(vn) = Aj(vn) for all n from
1 to k. Then it is clear that for some i greater than j, we have
Val(B,G) = Val(Ai,G) = 1.
Hence Val(B,G) = 1 for all G in S, so that B is a model of S, proving that (i)
implies (iii), and thereby completing the proof of our theorem.
□
Using the Compactness Theorem, we can show that the conditions S ⊢F , and
S |= F , are equivalent even in the case in which S is an inﬁnite set of propositional
formulae.
To show this, ﬁrst assume that S |= F . Then the set S ∪{¬F} of propositions is
plainly not consistent, and so by the Compactness Theorem S must contain some
ﬁnite subset S0 such that S0 ∪{¬F} is not consistent. Then plainly S0 |= F , so we
have S0 ⊢F . This clearly implies S ⊢F ; so S ⊢F , follows from S |= F .
But, as noted at the end of the proof of the Compactness Theorem, S |= F follows
from S ⊢F , even if S is inﬁnite, completing the proof of our claim.
2.2 The Predicate Calculus
The predicate calculus constitutes the next main part of the logical formalism used
in this book. This calculus enlarges the propositional calculus, preserving all its

2.2
The Predicate Calculus
45
operations but also allowing compound functional and predicate terms and the two
quantiﬁers ∀and ∃. An example is the formula

∀x,y | F(x + y) = F

F(x)

→F

F(x)

= 0

→

∃x | F

F(x)

̸= 0

→

F(x + y) ̸= F

F(x)

.
Formulae of the predicate calculus are built starting with string names of three
kinds, respectively, designating ‘individual’ variables, function symbols, and pred-
icate symbols. These are combined into ‘terms’, ‘atomic formulae’, and ‘formulae’
using the following recursive syntactic rules.
(i) Any variable name is a term. (We assume variable names to be alphanumeric
and to start with lower case letters.)
(ii) Each function symbol has some ﬁxed ﬁnite number k of arguments. If f
is a function symbol of k arguments, and t1,...,tk are any k terms, then
f (t1,...,tk) is a term. (We assume function names to be alphanumeric and
to start with lower case letters.)
(iii) Each predicate symbol has some ﬁxed ﬁnite number k of arguments. If P
is a predicate symbol of k arguments, and t1,...,tk are any k terms, then
P(t1,...,tk) is an atomic formula. (We assume predicate names to be alphanu-
meric and to start with upper case letters.)
(iv) Formulae are formed starting from atomic formulae and using the operators
and syntactic rules of the propositional calculus and the two quantiﬁers ∀and
∃. More precisely, if e and f are any two predicate formulae and v1,...,vn are
any n variable names, with n > 0, then the following expressions are predicate
formulae:
e & f,
e ∨f,
¬e,
e →f,
e ↔f,
(∀v1,...,vn | e),
(∃v1,...,vn | e).
Like propositional formulae, the formulae of predicate calculus parse unambigu-
ously into syntax trees each of whose internal nodes is marked either (i) with one of
the propositional operators, and then has as many descendants as the corresponding
propositional node, or (ii) with a function or predicate symbol, in which case its
descendants correspond to the arguments of the function or predicate symbol; (iii) a
quantiﬁer ∀or ∃involving n variable names, in which case the node has n + 1 de-
scendants, the ﬁrst n marked with the n variable names appearing in the quantiﬁer
and the n + 1-st which is the syntax tree of the expression e that is being quantiﬁed.
Each leaf of such a tree is marked either with the name of an individual variable or a
function symbol of zero arguments. (Such function symbols are called ‘constants’.)
Each occurrence of a variable v at a leaf of the syntax tree of a valid predicate
formula is either free or bound. A variable v is considered to be bound if it appears
as the descendant of some syntax tree node which is marked with a quantiﬁer in

46
2
Propositional- and Predicate-Calculus Preliminaries
whose associated list of variables v occurs; otherwise the occurrence is a free occur-
rence. These notions clearly translate back into corresponding notions for variable
occurrences in the unparsed string forms of the same formulae. For example, in the
predicate formula

∀x,z,x | F(x + y + z)

∨

∃y,y | F(x + y)

the ﬁrst three occurrences of x are bound, but the fourth occurrence of x is free.
Likewise the last three occurrences of y are bound, but its ﬁrst occurrence is free.
Note that, as this example shows, repeated occurrences of a variable in the list fol-
lowing one of the quantiﬁer symbols ∀or ∃are legal. However, we will see, when
we come to deﬁne the semantics of predicate formulae, that such repetitions are al-
ways superﬂuous since any variable occurrence repeated later in the list following
a quantiﬁer symbol can simply be dropped. For example, the formula shown above
has the same meaning as

∀z,x | F(x + y + z)

∨

∃y | F(x + y)

.
Bound variables are considered to belong to the scope of the nearest ancestor quan-
tiﬁer in whose list of variables they appear; this quantiﬁer is said to bind them. For
example, in

∀x | F(x) ∨

∃x | G(x)

∨H(x)

the ﬁrst, second, and ﬁnal occurrences of x are in the scope of the ﬁrst quantiﬁer
‘∀’, but the third and fourth occurrences are in the scope of the second quantiﬁer
‘∃’.
As was the case for the propositional calculus, we can think of predicate formulae
either as representing certain functions, or as the ingredients of a system of formal-
ized proof. Again we begin with the ﬁrst approach. Here the required deﬁnitions are
a bit trickier.
Deﬁnition 2.4 An interpretation framework for a collection PF of predicate formu-
lae is a triple (U ,I,A) such that
(i) U is a nonempty set, called the universe or domain of the interpretation frame-
work. We write U k for the k-fold Cartesian product of U with itself.
(ii) I is a single-valued function, called an interpretation, which maps each of the
function and predicate symbols occurring in the collection in accordance with
the following rules:
(ii.a) Each function symbol f of k arguments occurring in the collection of
formulae is mapped into a function I(f ) which sends U k into U .
(ii.b) Each predicate symbol P of k arguments occurring in the collection of
formulae is mapped into a function I(P) which sends U k into the set
{0,1} of values.
(iii) A is a single-valued function, called an assignment, which maps each of the
individual variables occurring freely in the collection PF of formulae into an
element of U .

2.2
The Predicate Calculus
47
As previously we speak of such an interpretation framework as covering the col-
lection PF of predicate formulae.
Suppose that we are given any such interpretation I and assignment A with uni-
verse U , and an expression F which they cover. (Note that F can be either a term
or a predicate formula.) Then the value Val(I,A,F) of the assignment for the ex-
pression is the value deﬁned in the following recursive way.
(i) If F is just an individual variable x, then Val(I,A,F) = A(x).
(ii) If F is a term having the form g(t1,...,tk), and G is the corresponding
mapping I(g) from U k to U , then Val(I,A,F) = G(Val(I,A,t1),...,
Val(I,A,tk)).
(iii) If F is an atomic formula having the form P(t1,...,tk), and p is the corre-
sponding mapping I(P) from U k to {0,1}, then Val(I,A,F) is the 0/1 value
p(Val(I,A,t1),...,Val(I,A,tk)).
(iv) If F is a formula having the form G & H, then Val(I,A,F) is the minimum
of Val(I,A,G) and Val(I,A,H).
(v) If F is a formula having the form G ∨H, then Val(I,A,F) is the maximum
of Val(I,A,G) and Val(I,A,H).
(vi) If F is a formula having the form ¬G, then Val(I,A,F) = 1 −Val(I,A,G).
(vii) If F is a formula having the form G →H, then Val(I,A,F) = Val(I,A,
‘(¬G) ∨H’).
(viii) If F is a formula having the form G ↔H, then Val(I,A,F) = Val(I,A,
‘(G & H) ∨((¬G) & (¬H))’).
(ix) If F is a formula having the form (∀v1,...,vn | e), then Val(I,A,F) is
the minimum of Val(I,A′,e), extended over all assignments A′ such that A′
covers the formula e and A′(x) = A(x) for every variable x not in the list
v1,...,vn.
(x) If F is a formula having the form (∃v1,...,vn | e), then Val(I,A,F) is the
maximum of Val(I,A′,e), extended over all assignments A′ such that A′
covers the formula e and A′(x) = A(x) for every variable x not in the list
v1,...,vn.
Since, as seen in (ix) and (x) above, the variables appearing in the lists follow-
ing quantiﬁer symbols ‘∀’ and ‘∃’ merely serve to mark occurrences of the same
variables in the quantiﬁer’s scope as being ‘bound’ and hence subject to minimiza-
tion/maximization when values Val(I,A,F) are calculated, it follows that these
variables can be replaced with any others provided that this replacement is made
uniformly over the entire scope of each quantiﬁer, and that no variable occurring
freely in the original formula thereby becomes bound. For example, the formula

∀x
 F(x) ∨

∃x | G(x)

∨H(x)

appearing above can as well be written as

∀x
 F(x) ∨

∃y | G(y)

∨H(x)

or as

∀y
 F(y) ∨

∃x | G(x)

∨H(y)

.

48
2
Propositional- and Predicate-Calculus Preliminaries
A convenient way of performing this kind of ‘bound variable standardization’ is as
follows. We make use of some standard list L of bound variable names, reserved for
this purpose and used for no other. We work from the leaves of a formula’s syntax
tree up toward its root, processing all quantiﬁers more distant from the root before
any quantiﬁer closer to the root is processed. Suppose that a quantiﬁer like
(∀v1,...,vn | e)
or
(∃v1,...,vn | e)
is encountered at a tree node Q during this process. We then take the ﬁrst n variables
b1,...,bn from the list L that do not already appear in any descendant of the node
Q, replace v1,...,vn by b1,...,bn, respectively, and make the same replacements
for every free occurrence of any of the v1,...,vn in e.
This standardization will for example transform

∀y
 
∀y
 F(y) ∨

∃x | G(x)

∨H(y)

into

∀b3
 
∀b1
 F(b1) ∨

∃b2 | G(b2)

∨H(b3)

.
Such standardization of bound variables makes it easier to see what quantiﬁer each
bound variable occurrence relates to. It also uncovers identities between quantiﬁed
subexpressions that might otherwise be missed, and so is a valuable preliminary to
examination of the propositional structure of predicate formulae.
It also follows from (ix) and (x) that the value assigned to any quantiﬁed formula
(∀v1,v2,...,vn | e)
(2.1)
is exactly the same as that assigned to

∀v1
 
∀v2
 
∀··· | (∀vn | e)···

(2.2)
and, likewise, the value assigned to any quantiﬁed formula
(∃v1,v2,...,vn | e)
(2.3)
is exactly the same as that assigned to

∃v1
 
∃v2
 
∃··· | (∃vn | e)···

.
(2.4)
Accordingly, we shall regard (2.1) and (2.3) as abbreviations for (2.2) and (2.4).
This allows us to assume (wherever convenient) that each quantiﬁer examined in
the following discussion involves only a single variable.
Deﬁnition 2.5
A predicate formula F is universally valid if Val(I,A,F) = 1 for
every interpretation framework (U ,I,A) covering it.

2.2
The Predicate Calculus
49
In predicate calculus, universally valid formulae are those which evaluate to true
no matter what ‘meanings’ are assigned to the variables, function symbols, and pred-
icate symbols that occur within them. Examples are
P(x,y) ∨

¬P(x,y)

,

∀ya
 Q(x) →

P(x,y) →Q(x)

,

∀x
 P(x,y) →

∃y
 
Q(x) →

P(x,y) & Q(x)

.
However, the problem of determining whether a given predicate formula is uni-
versally valid is of a much higher order of difﬁculty than the problem of recognizing
propositional tautologies, since the collection of interpretation frameworks that must
be considered is inﬁnite rather than ﬁnite. There is no longer any reason for believ-
ing that this determination can be made algorithmically, and indeed it cannot, as we
shall see in Chap. 6. Thus we have little alternative to setting up the predicate calcu-
lus as a logical system in which universally valid formulae are found by proof. We
now begin to do this, starting with a special subclass of universally valid formulae,
the predicate tautologies, which are deﬁned as follows.
Deﬁnition 2.6 A predicate formula F is a tautology if it reduces to a propositional
tautology by descending through its syntax tree and reducing each node not marked
with a propositional operator to a single propositional variable, identical subnodes
always being reduced to the same propositional variable. (In what follows we will
call this latter formula the propositional blobbing of F.)
As an example, note that the indicated reduction sends
P(x,y) ∨

¬P(x,y)

into A ∨(¬A),

∀y
 Q(x) →

P(x,y) →Q(x)

into B,
P(x,y) →

∃y
 
Q(x) →

P(x,y) & Q(x)

into A →C.
Thus the ﬁrst of these three formulae is a predicate tautology, but the two others are
not.
The recursive computation of Val(I,A,F) assigns some 0/1 value to each sub-
tree of the syntax tree of F, and plainly assigns the same value to identical subtrees
of the syntax tree of F. This makes it clear that every predicate tautology is uni-
versally valid. But there are other basic forms of universally well-formed predicate
formulae, of which the most crucial are listed in the following deﬁnition.
Deﬁnition 2.7 A formula is an axiom of the predicate calculus if it is either
(i) any predicate tautology;
(ii) any formula of the form

(∀y | P →Q) & (∀y | P)

→(∀y | Q);

50
2
Propositional- and Predicate-Calculus Preliminaries
(iii) any formula of the form

¬(∀y | ¬P)

↔(∃y | P);
(iv) any formula of the form P ↔(∀y | P), where the variable y does not occur in
P as a free variable;
(v) any formula of the form (∀y | P) →P(y →e), where P(y →e) is the for-
mula obtained from P by substituting the syntactically well-formed term e for
each free occurrence of the variable y in P , provided that no variable free in e
is bound at the point of occurrence of any such y in P .
We can easily see that all of these predicate axioms are universally valid. Given
a formula P of the predicate calculus, let P ′ designate its propositional blobbing.
Predicate tautologies are universally valid since the ﬁnal stages of computation of
Val(I,A,P) always use the values assigned to certain basic subformulae of P in the
same way that values assigned to corresponding propositional variables are used in
the propositional computation of Val(I,A,P ′). To see that (iii) is universally valid,
we have only to note that for 0/1 valued functions f of any number of arguments
we always have
max(f ) = 1 −min(1 −f ).
(iv) is universally valid because if y does not occur in P as a free variable, we have
Val

I,A,‘(∀y | P)’

= Val(I,A,P)
for every interpretation I and assignment A covering P .
(v) is universally valid because any interpretation I and assignment A cover-
ing P(y →e) will assign some value a0 to e, and then Val(I,A,P(y →e)) =
Val(I,A′,P), where A′ is the assignment identical to A except that it assigns
the value a0 to y. Since Val(I,A′,(∀y | P)) is by deﬁnition the minimum of
Val(I,B,P) extended over all assignments B which are identical to A except on
the variable y, it follows that Val(I,A,‘(∀y | P)’) = 1 implies Val(I,A,P(y →
e)) = 1, so that
max

1 −Val

I,A,‘(∀y | P)’

, Val

I,A,P(y →e)

is identically 1, i.e. (∀y | P) →P(y →e) is universally valid.
To show that (ii) is universally valid, note that for any interpretation I and as-
signment A covering (ii)
Val

I,A,‘(∀y | P →Q)’

and
Val

I,A,‘(∀y | P)’

are, respectively, the minimum of max(1 −Val(I,A′,P), Val(I,A′,Q)) and of
Val(I,A′,P), extended over all assignments A′ which are identical to A except

2.2
The Predicate Calculus
51
on the variable y. If both of these minima are 1, then 1 −Val(I,A′,P) must
be 0 for all such A′, so Val(I,A′,Q) must be 1 for all such A′, proving that
Val(I,A,‘(∀y | Q)’) = 1. This implies the universal validity of (ii), completing our
proof that all predicate axioms are universally valid.
2.2.1 Proof Rules of the Predicate Calculus
The predicate calculus has just two proof rules. The ﬁrst is identical with the modus
ponens rule of propositional calculus. The second is the Rule of Generalization,
which states that if P is any previously proved result, then
(∀x | P)
can be deduced.
A stronger variant of the Rule of Generalization, which turns out to be very useful
in practice, allows us to deduce the formula
P →(∀x | Q)
from P →Q, provided that the variable x does not occur free in P . This variant can
be justiﬁed as follows. Let us assume that the formula P →Q has been derived and
that x is a variable which does not have free occurrences in P . By generalization
and as instance of the predicate axiom (ii) we can derive the formulae
(∀x | P →Q),

(∀x | P →Q) & (∀x | P)

→(∀x | Q).
By propositional reasoning these imply the formula
(∀x | P) →(∀x | Q).
Since we are assuming that the variable x does not occur free in P , we can derive
the formula
P ↔(∀x | P)
using predicate axiom (iv), and it follows by propositional reasoning that
P →(∀x | Q),
which establishes the strong form of the rule of generalization that we have stated.
In what follows we will not always distinguish between the two variants of the
rule of generalization and we will use whichever version is more convenient for the
purposes at hand. The argument given above shows that any proof which uses the
strong variant of the Rule of Generalization can be transformed mechanically into a
proof which uses only the standard form of this Rule.

52
2
Propositional- and Predicate-Calculus Preliminaries
We can easily see that any formula deduced from universally valid formulae us-
ing the two proof rules just explained must also be universally valid. For the modus
ponens rule this follows as in the propositional case. For the rule of generalization
we reason as follows. If Val(I,A,P) = 1 for every interpretation I and assign-
ment A covering P , then since for every assignment B covering (∀x | P) the value
v = Val(I,B,‘(∀x | P)’) is the minimum of Val(I,A,P) extended over all assign-
ments A which give the same value as B to all variables other than x, it follows that
v = 1 also.
In analogy with the case of the propositional calculus we write
|= F
to indicate that the formula F is a universally valid formula of the predicate calculus,
and write
⊢F
to indicate that F is a provable formula of the predicate calculus.
The following very important theorem is the predicate analog of the statement
that a propositional formula is a tautology if and only if it is provable.
2.2.2 The Gödel Completeness Theorem
For any predicate formula, the conditions
|= F
and
⊢F
are equivalent.
Half of this theorem is just as easy to prove as in the propositional case. Speciﬁ-
cally, suppose that ⊢F . Then since all the axioms of predicate calculus are univer-
sally valid and the predicate-calculus rules of inference preserve universal validity,
F must be universally valid, i.e. |= F .
The other, more difﬁcult half of this theorem will be proved later, after some
preparation. Much as in the case of the propositional calculus, this result can be
generalized as follows. Let S designate any set of syntactically well-formed formu-
lae of the predicate calculus. Write
S |= F
to indicate that, for each interpretation I and assignment A covering both F and all
the formulae in S, we have Val(I,A,F) = 1 whenever Val(I,A,G) = 1 for all G
in S. Also, write
S ⊢F
to indicate that F follows by predicate proof if the statements in S are added to the
axioms of predicate calculus. Suppose that none of the formulae in S contain any

2.2
The Predicate Calculus
53
free variables (formulae with this property are usually called sentences). Then for
any predicate formula, the conditions
S |= F
and
S ⊢F
are equivalent. (An easy example, given below, shows that we cannot omit the con-
dition ‘none of the formulae in S contain any free variables’.) The derivation of this
from the more restricted result given by the Gödel completeness theorem is almost
the same as the corresponding propositional proof. For the moment we will consider
only the case in which S is ﬁnite. Suppose ﬁrst that S |= F and let C designate the
conjunction
G1 & ··· & Gk
of all the formulae in S. Let I and A be, respectively, an interpretation and an assign-
ment which cover C →F (i.e. cover both F and all the formulae in S). Then as in
the propositional case it follows that Val(I,A,C) = 1 if and only if Val(I,A,G) = 1
for all G in S. Hence
Val(I,A,C →F) = Val

I,A,(¬C) ∨F

= max

1 −Val(I,A,C), Val(I,A,F)

= 1,
for all such I and A. Hence
|= C →F
follows using the Gödel Completeness Theorem, as stated above, and so it follows
that
⊢C →F,
i.e. C →F can be proved from the axioms of predicate calculus alone. But then if
the statements in S are added as additional axioms we can prove F by ﬁrst proving
C →F , then using the statements in S to prove the conjunction C, and ﬁnally
proving F by modus ponens from C →F and C. This shows that S |= F implies
S ⊢F .
Next suppose that there exists a formula F such that S ⊢F , but that S |= F is
false. Let F be such a formula with the shortest possible proof from S, and let I
and A be, respectively, any interpretation and assignment A covering both F and
all the formulae in S such that Val(I,A,G) = 1 for every statement G in S, but
Val(I,A,F) = 0. The ﬁnal step of a shortest proof of F from S cannot be either the
citation of an axiom or the citation of a statement of S, since in both these cases we
would have Val(I,A,F) = 1. Hence this ﬁnal step is either a modus ponens infer-
ence from two formulae p, p →F appearing earlier in the proof, or a generalization
inference from one such formula p. In the modus ponens case we must have S |= p,
S |= p →F by inductive assumption. Hence Val(I,A,p →F) and Val(I,A,p) are
both 1, and therefore so is Val(I,A,F), a contradiction.
In the remaining case, i.e. that of a generalization inference, we must have S |= p,
where F has the form (∀x | p), for some predicate variable x. Since the statements

54
2
Propositional- and Predicate-Calculus Preliminaries
in S have no free variables we have Val(I,A′,G) = 1 for every statement G in S
and every assignment A′ which is identical to A except on the variable x, so that
Val(I,A′,p) = 1. But then
Val

I,A,‘(∀x | p)’

is the minimum of Val(I,A′,p), taken over all such A′, and therefore it follows that
Val(I,A,‘(∀x | p)’) = 1, i.e. Val(I,A,F) = 1, which is again a contradiction. This
shows that S ⊢F implies S |= F , completing our proof that the conditions S |= F
and S ⊢F are equivalent, at least in the case in which S is ﬁnite. We will see later
that the condition that the set S is ﬁnite can be dropped. In fact, we can notice right
away that the derivation given above of S |= F from S ⊢F holds also in the case in
which S is inﬁnite. Thus, in order to fully establish the generalization of the Gödel
completeness theorem, we are only left with proving that S |= F implies S ⊢F ,
for every inﬁnite set S of predicate formulae none of which has occurrences of free
variables.
We conclude this subsection by noting that the result just stated fails if the for-
mulae in S are allowed to contain free variables. To see this, consider the simple
case in which S consists of the single formula P(x). If this formula were added to
the set of axioms of the predicate calculus, we could give the proof
P(x)
[axiom]

∀x | P(x)

[generalization]

∀x | P(x)

→P(y)
[predicate axiom (v)]
P(y)
[modus ponens]
Hence we could have {P(x)} ⊢P(y). But {P(x)} |= P(y) is false, since we can
set up a 2-point universe U = {a,b}, the assignment A(x) = a, A(y) = b, and the
interpretation I such that I(P)(a) = 1 and I(P)(b) = 0.
2.2.3 Working with Universally Valid Predicate Formulae. A Few
Simple Examples of Predicate Proof
A few basic theorems of predicate calculus are needed for later use. One such is

(∀x | P →Q) & (∃x | P)

→(∃x | Q).
The following proof of this statement, and two other sample proofs given later in this
section, illustrate some of the techniques of direct, fully detailed predicate proof. By
predicate axiom (v) we have
(∀x | P →Q) →(P →Q),

2.2
The Predicate Calculus
55
and from this by purely propositional reasoning we have
(∀x | P →Q) →

(¬Q) →(¬P)

.
By the (strong) rule of generalization this gives
(∀x | P →Q) →

∀x
 
(¬Q) →(¬P)

.
Axiom (ii) now tells us that

∀x
 
(¬Q) →(¬P)

&

∀x | (¬Q)

→

∀x | (¬P)

,
so by propositional reasoning we have
(∀x | P →Q) →

∀x | (¬Q)

→

∀x | (¬P)

,
and also
(∀x | P →Q) →

¬

∀x | (¬P)

→

¬

∀x | (¬Q)

.
Since by predicate axiom (iii) we have

¬

∀x | (¬P)

↔(∃x | P)
and

¬

∀x | (¬Q)

↔(∃x | Q),
our target statement

(∀x | P →Q) & (∃x | P)

→(∃x | Q)
now follows propositionally.
The following is a useful general principle of the predicate calculus whose uni-
versal validity is readily understood intuitively, and which can also be proved for-
mally within the predicate calculus.
Suppose that a predicate formula of the form
A ↔B
has been proved and that F is a syntactically legal predicate formula such that A
appears as a subformula of F . Let G be the result of replacing some such occurrence
of A in F by an occurrence of B. Then F ↔G is also a theorem.
To show this, note that F can be built up starting from A by steps, each of which
either joins subformulae together using a propositional operator, or quantiﬁes a for-
mula. Hence it is enough to show that if
H2 ↔H3
(2.5)
has already been proved, then

56
2
Propositional- and Predicate-Calculus Preliminaries
(a) (H1 & H2) ↔(H1 & H3)
(b) (H1 ∨H2) ↔(H1 ∨H3)
(c) (H1 ↔H2) ↔(H1 ↔H3)
(d) (H1 →H2) ↔(H1 →H3)
(e) (H2 →H1) ↔(H3 →H1)
(f) (¬H2) ↔(¬H3)
(g) (∀x | H2) ↔(∀x | H3)
(h) (∃x | H2) ↔(∃x | H3)
can be proved as well. Notice that (a)–(f) follow readily from (2.5) by propositional
reasoning. So to prove our claim we have only to establish that (g) and (h) follow
from (2.5) too. This can be shown as follows. By propositional reasoning and the
predicate rule of generalization, statement (2.5) yields
(∀x | H2 →H3).
By axiom (ii) we have

(∀x | H2 →H3) & (∀x | H2)

→(∀x | H3),
so by propositional reasoning we get
(∀x | H2) →(∀x | H3).
The formula
(∀x | H3) →(∀x | H2)
can be derived in the same way, and so we have
(∀x | H2) ↔(∀x | H3).
Since (2.5) yields
(¬H2) ↔(¬H3)
by propositional reasoning, it follows in the same way that

∀x | (¬H2)

↔

∀x | (¬H3)

and so

¬

∀x | (¬H2)

↔

¬

∀x | (¬H3)

.
It follows by predicate axiom (iii) and propositional reasoning that
(∃x | H2) ↔(∃x | H3),
completing the proof of our claim.
The following ‘change of bound variables’ law is still another rule of obvious
universal validity, which as usual can be proved formally within the predicate cal-
culus.

2.2
The Predicate Calculus
57
Let F be a syntactically well-formed predicate formula containing x as a free
variable, let y be a variable not occurring in F , and let F(x →y) be the result of
replacing every free occurrence of x by an occurrence of y. Then
(∀x | F) ↔

∀y | F(x →y)

and
(∃x | F) ↔

∃y | F(x →y)

are universally valid predicate formulae. To show this, we ﬁrst use predicate axiom
(v) to get
(∀x | F) →F(x →y),
and so
(∀x | F) →

∀y | F(x →y)

follows by the (strong) rule of generalization, since y does not occur freely in
(∀x | F).
Since replacing each free occurrence of x in F by y and then each y by x brings
us back to the original x, we have
F(x →y)(y →x) = F.
Thus the argument just given can be used again to show that

∀y | F(x →y)

→(∀x | F),
and so it results propositionally that

∀y | F(x →y)

↔(∀x | F).
Applying the same argument to ‘¬F ’ we can get

¬

∀y | ¬F(x →y)

↔

¬(∀x | ¬F)

,
and so

∃y | F(x →y)

↔(∃x | F),
using predicate axiom (iii).
The observations just made allow any predicate formula F to be transformed, via
a sequence of formulae all provably equivalent to each other, into an equivalent for-
mula G all of whose quantiﬁers appear to the extreme left of the formula. To achieve
this, we must also use the following auxiliary group of predicate rules, which apply
if the variable x does not occur freely in Q:
(a) (∀x | P ∨Q) ↔((∀x | P) ∨Q)
(b) (∀x | P & Q) ↔((∀x | P) & Q)

58
2
Propositional- and Predicate-Calculus Preliminaries
(c) (∀x | P →Q) ↔((∃x | P) →Q)
(d) (∀x | Q →P) ↔(Q →(∀x | P))
(e) (∃x | P ∨Q) ↔((∃x | P) ∨Q)
(f) (∃x | P & Q) ↔((∃x | P) & Q)
(g) (∃x | P →Q) ↔((∀x | P) →Q)
(h) (∃x | Q →P) ↔(Q →(∃x | P)).
These rules can be proved as follows. Predicate axiom (v) gives
(∀x | P) →P,
and so by propositional reasoning from the tautology

(∀x | P) →P

→

(∀x | P) ∨Q

→(P ∨Q)

,
we get

(∀x | P) ∨Q

→(P ∨Q).
Since x does not occur freely in ((∀x | P) ∨Q), generalization now gives

(∀x | P) ∨Q

→(∀x | P ∨Q).
Conversely we get
(∀x | P ∨Q) →(P ∨Q)
from predicate axiom (v), and so

(∀x | P ∨Q) & (¬Q)

→P.
Since x does not occur freely in ((∀x | P ∨Q) & (¬Q)), by generalization we get

(∀x | P ∨Q) & (¬Q)

→(∀x | P),
and then
(∀x | P ∨Q) →

(∀x | P) ∨Q

,
so altogether
(∀x | P ∨Q) ↔

(∀x | P) ∨Q

,
proving (a).
To prove (b) we reason as follows.
(∀x | P & Q) →(P & Q)
by axiom (v), so
(∀x | P & Q) →P

2.2
The Predicate Calculus
59
by propositional reasoning. Since x does not occur freely in (∀x | P & Q), by gen-
eralization we derive
(∀x | P & Q) →(∀x | P)
from this. Thus, by propositional reasoning, we obtain
(∀x | P & Q) →

(∀x | P) & Q

.
Conversely, since

(∀x | P) & Q

→(∀x | P)
we have

(∀x | P) & Q

→P
by axiom (v) and propositional reasoning. Since

(∀x | P) & Q

→Q
is propositional, we get

(∀x | P) & Q

→(P & Q),
and now

(∀x | P) & Q

→(∀x | P & Q)
follows by generalization, since x does not occur freely in (∀x |P) & Q. Altogether
this gives

(∀x | P) & Q

↔(∀x | P & Q),
i.e. (b).
Statement (c) now follows via the chain of equivalences
(∀x | P →Q) ↔

∀x | (¬P) ∨Q

↔

∀x | (¬P)

∨Q

↔

¬

∀x | (¬P)

→Q

↔

(∃x | P) →Q

.
Similarly statement (d) follows via the chain of equivalences
(∀x | Q →P) ↔

∀x | (¬Q) ∨P

↔

(¬Q) ∨

∀x | P

↔

Q →

∀x | P

.
The proofs of (e–h) are left to the reader.

60
2
Propositional- and Predicate-Calculus Preliminaries
2.2.4 The Prenex Normal Form of Predicate Formulae
The prenex normal form of a predicate formula F is a logically equivalent formula
in which quantiﬁers ∀and ∃appear only at the very start of the formula. Rules
(a–h) can now be used iteratively in the following way to put an arbitrary formula F
into prenex normal form. We ﬁrst change bound variables, using the equivalences
derived above for this purpose, to ensure that all bound variables are distinct and
that no bound variable is the same as any variable occurring freely. Then we use
equivalences
(P ↔Q) ↔

(P →Q) & (Q →P)

to replace all ‘↔’ operators in our formula with combinations of implication and
conjunction operators. After this, we search the syntax tree of the formula, looking
for all quantiﬁer nodes whose parent nodes are not already quantiﬁer nodes, and
moving them upward in a manner to be described. If there are no such nodes, then all
the quantiﬁers occur in an unbroken sequence starting at the tree root, and so in the
unparsed form of the formula they all occur at the left of the formula. The quantiﬁer
node moved at any moment should always be one that is as close as possible to the
root of the syntax tree. Given that the parent of this quantiﬁer is not itself a quantiﬁer
node, the parent must be marked with one of the Boolean operators &, ∨, →, ¬. If
the operator at the parent node is ‘¬’, we use one of the equivalences
(∀x1,...,xk | ¬P) ↔

¬(∃x1,...,xk | P)

and
(∃x1,...,xk | ¬P) ↔

¬(∀x1,...,xk | P)

to interchange the positions of the ‘¬’ operator and the quantiﬁer. In the remaining
cases we use one of the equivalences (a–h) to achieve a like interchange. When
this process, each of whose steps transforms our original formula into an equivalent
formula, can no longer continue, the formula that remains will clearly be in prenex
normal form.
2.2.5 The Deduction Theorem
The Deduction Theorem of predicate calculus, which will be useful below, states
that (provided that neither F or any of the statements in S contain any free variables)
the implication F →G can be proved from a set S of predicate axioms if and only
if G can be proved if F is added to the set S of axioms. Note that this is an easy
consequence of the Gödel Completeness Theorem in the generalized form discussed
at the start of this section. But in what follows we need to know that this result can
be proved directly. This will now be shown.

2.2
The Predicate Calculus
61
Theorem 2.2 (Deduction) Let S be a collection of predicate formulae with no free
variables and let S′ be obtained from S by adding to it a predicate formula F with
no free variables. Then
S ⊢F →G
if and only if
S′ ⊢G,
for any predicate formula G.
Proof Let S, S′, F , and G be as above. First assume that S ⊢F →G holds and let
H1,H2,...,Hn,
with Hn = F →G, be a proof of F →G from S. Then it follows immediately that
H1,H2,...,Hn,F,G
is a proof of G from S′.
Conversely, assume that S′ ⊢G and let
H1,H2,...,Hn,
(2.6)
with Hn = G, be a proof of G from S′. We can suppose without loss of generality
that this proof does not use the strong variant of the rule of generalization stated
earlier, but only the weaker form of this rule. Consider the sequence of predicate
formulae
F →H1, F →H2, ..., F →Hn.
(2.7)
We will show that by inserting suitable auxiliary formulae into this sequence we
can turn it into a proof from S of F →G. Indeed, for each i = 1,2,...,n one of
the following cases will apply:
(i) Hi may be a predicate axiom or Hi may be an element of S. In this case we
insert the formulae
Hi
Hi →(F →Hi)
(of which the latter is a tautology) into (2.7) just before the formula F →Hi.
(ii) Hi may follow from Hj and Hk = Hj →Hi by modus ponens step. In this
case we insert the formulae
(F →Hj) →

F →(Hj →Hi)

→(F →Hi)


F →(Hj →Hi)

→(F →Hi)
(of which the former is a tautology) into (2.7) just before the formula F →Hi.
(iii) In the remaining possible cases, namely if Hi is derived from some earlier
statement of (2.6) by the rule of generalization, or if Hi = F , we need not add
any formula to (2.7).

62
2
Propositional- and Predicate-Calculus Preliminaries
Let
K1,K2,...,Km
be the sequence of predicate formulae generated in the manner just described. It
is easy to check that this sequence constitutes a proof of Km = F →G from S,
provided that we now allow use of the strong variant of the rule of generalization.
Since, as shown above, any such proof can be transformed into one in which all uses
of the strong variant of the rule of generalization have been eliminated and only the
weak form of this rule is used, it follows that S ⊢F →G, concluding our proof of
the deduction theorem.
□
The deduction theorem admits the following semantic version, whose proof is
left to the reader.
Theorem 2.3 Let S, S′, F , and G be as in the statement of the deduction theorem.
Then
S |= F →G
if and only if
S′ |= G.
2.2.6 Deﬁnitions in Predicate Calculus; the Notion
of ‘Conservative Extension’
Since the use of deﬁnitions to introduce new predicate and function symbols is fun-
damental to ordinary mathematical practice, it is important to understand the sense
in which the predicate calculus accommodates this notion. The simplest deﬁnitions
are algebraic, i.e. they simply introduce names for compound expressions written
in terms of previously deﬁned predicate and function symbols. Such deﬁnitions are
unproblematical, since any use of them can be eliminated by expanding the new
name back into the underlying expression which it abbreviates. But another, less
trivial kind of deﬁnition is also essential. This is known as deﬁnition by introduction
of Skolem functions. More speciﬁcally, once we have proved a formula of the form

∀y1,...,yn
 
∃z| P(y1,...,yn,z)

(2.8)
using the axioms of predicate calculus and some set S of additional axioms (none
of which should have any free variables), we can introduce any desired new, never
previously used function name f and add the statement

∀y1,...,yn | P

y1,...,yn,f (y1,...,yn)

(2.9)
to S. The point is that, although this added statement clearly allows us to prove new
statements concerning the newly introduced symbol f , it does not make it possible
to prove any statement not involving f that could not have been proved without its
introduction.

2.2
The Predicate Calculus
63
This very important result can be called the fundamental principle of deﬁnition.
To prove it we argue as follows. (But note that the following proof uses the Gödel
Completeness Theorem, and so is entirely nonconstructive, i.e. it does not tell us
how to produce the deﬁnition-free proof whose existence it asserts.) Let P , S, and
f be as above, and let S′ be obtained from S by adjoining the formula (2.9) to S.
Let F be a formula not involving the symbol f , and suppose that S′ ⊢F . Then we
have S′ |= F by the Gödel completeness theorem (as extended above). Our goal is
to show that S ⊢F . By the Gödel completeness theorem it is enough to show that
S |= F . To this purpose, let (U ,I,A) be an interpretation framework covering F
and the statements in S and such that Val(I,A,G) = 1 for each G in S. Then we
must show that Val(I,A,F) = 1.
Introduce an auxiliary Boolean function p(u1,...,un,un+1), mapping the Carte-
sian product U n+1 of n + 1 copies of U into {0,1}, by setting
p(u1,...,un,un+1) = Val

I,A(u1,...,un,un+1), ‘P(y1,...,yn,z)’

,
where A(u1,...,un,un+1) is the assignment which agrees with A everywhere ex-
cept on the variables y1,...,yn and z, for which variables we take
A(u1,...,un,un+1)(y1) = u1,
...
...
...
A(u1,...,un,un+1)(yn) = un,
A(u1,...,un,un+1)(z) = un+1.
Since
S ⊢

∀y1,...,yn
 
∃z| P(y1,...,yn,z)

,
we have
S |=

∀y1,...,yn
 
∃z| P(y1,...,yn,z)

and therefore
1 = Val

I,A,

∀y1,...,yn
 
∃z| P(y1,...,yn,z)

= minu1,...,un

maxun+1

Val

I,A(u1,...,un,un+1), P(y1,...,yn,z)

= minu1,...,un

maxun+1

p(u1,...,un,un+1)

,
where the minima and maxima over the subscripts seen extend over all values in U .
Hence there exists a function h from U n into U such that
p

u1,...,un,h(u1,...,un)

= 1
for all u1,...,un in U . Let I ′ be an interpretation which agrees with I everywhere
except on the function symbol f and such that I ′(f ) is the function h just deﬁned

64
2
Propositional- and Predicate-Calculus Preliminaries
(which is, as required, a mapping from U n to U ). Hence
1 = minu1,...,un

p

u1,...,un,h(u1,...,un)

= minu1,...,un

Val

I ′,A(u1,...,un), P

y1,...,yn,f (y1,...,yn)

= Val

I ′,A,

∀y1,...,yn | P

y1,...,yn,f (y1,...,yn)

,
where A(u1,...,un) is the assignment which agrees with A everywhere except on
the variables y1,...,yn, for which variables we take
A(u1,...,un)(y1) = u1,
...
...
...
A(u1,...,un)(yn) = un.
Since no formula G in S involves the function symbol f , we have
Val(I ′,A,G) = Val(I,A,G) = 1,
for all G in S.
Therefore
Val(I ′,A,F) = 1,
since, as observed above, S′ |= F . But since the formula F does not involve the
function symbol f , we have
Val(I,A,F) = 1,
proving that S |= F , and so S ⊢F . This concludes our proof of the fundamental
principle of deﬁnition.
The central notion implicit in the preceding argument is worth capturing for-
mally.
Deﬁnition 2.8 Let S be a set of predicate formulae not involving any free variables,
and let S′ be a larger such set (possibly involving function and predicate symbols
that do not occur in S). Then S′ is called a conservative extension of S if
S′ ⊢F
implies
S ⊢F,
for every formula F involving no predicate or function symbols not present in one
of the formulae of S.
The argument just given shows that the addition of formula (2.9) to any set S
of formulae not containing free variables for which (2.8) can be proved yields a
conservative extension.

2.2
The Predicate Calculus
65
2.2.7 Proof of the Gödel Completeness Theorem
Now we come to the proof of the Gödel completeness theorem. To prove it we
ﬁrst show, without using it, that the theorem holds for a certain very limited form
of Skolem deﬁnition, namely if we introduce a single new constant symbol C (i.e.
function symbol of 0 arguments) satisfying P(C), provided that we have previously
proved a predicate formula of the form

∃z| P(z)

.
These constants are traditionally called Henkin constants, after Leon Henkin, who
introduced the technique that we will use. Our ﬁrst key lemma is as follows.
Lemma 2.1 Let S be a collection of (syntactically well-formed) predicate formulae
without free variables and let C be a constant symbol not appearing in any of the
formulae of S. For each formula H, let H(C →x) denote the result of replacing
each occurrence of C in H by an occurrence of x, where x designates a variable
not otherwise used. Then, if S ⊢H, we have
S ⊢H(C →x).
In intuitive terms, this lemma tells us that if the axioms S can be used to prove
some statement about a constant which they never mention, they can be used to
prove the same statement in which C is replaced by a variable.
Proof Suppose that Lemma 2.1 fails for some H. Then, proceeding inductively, we
can suppose that Lemma 2.1 holds for all statements having proofs shorter than that
of H. Without loss of generality, we can assume that the variable x is not used
in the proof of H. Consider the ﬁnal step in the proof of H. This must either be
(i) a citation of a predicate axiom; (ii) a citation of some statement in S; (iii) a
modus ponens step involving two formulae G and G →H proved earlier; (iv) a
generalization step from a formula G proved earlier. Concerning case (i), if H is a
predicate axiom so is H(C →x). In case (ii), namely if H is a member of S, H
cannot involve the constant C, so that H(C →x) = H and therefore we plainly
have S ⊢H(C →x).
Next consider case (iii). Since in this case G and G →H both have shorter
proofs than that of H, it follows by inductive assumption that S ⊢G(C →x) and
S ⊢(G →H)(C →x), i.e. S ⊢G(C →x) →H(C →x). Therefore it follows by
a modus ponens step that S ⊢H(C →x).
Finally we consider case (iv). In this case G has a shorter proof than that of its
generalization H = (∀z| G). Hence by inductive assumption S ⊢G(C →x), so
that, by the rule of generalization, S ⊢(∀z|G(C →x)) and therefore S ⊢H(C →
x), since
H(C →x) = (∀z| G)(C →x) =

∀z| G(C →x)

,
proving our claim in case (iv) and thus completing our proof of Lemma 2.1.
□

66
2
Propositional- and Predicate-Calculus Preliminaries
Next we prove the following consequence of Lemma 2.1.
Lemma 2.2 Let S be a collection of (syntactically well-formed) predicate formulae
without free variables. Let F be a predicate formula involving the one free variable
y. Let C be a constant symbol not appearing in any of the formulae of S or in F , and
let F(y →C) denote the formula obtained from F by replacing each occurrence of
y by an occurrence of C. Suppose that
S ⊢(∃y | F).
Let S′ be the union of S and the statement F(y →C). Then S′ is a conservative
extension of S.
Proof Let H be a formula involving only the symbols appearing in S, so that in par-
ticular the constant C does not occur in H. Suppose that S′ ⊢H. By the Deduction
Theorem we have
S ⊢F(y →C) →H.
By Lemma 2.1 this last formula yields
S ⊢

F(y →C) →H

(C →x),
where x is a variable not otherwise used. Therefore
S ⊢F(y →x) →H,
since F(y →C)(C →x) = F(y →x) and H(C →x) = H. Applying the rule of
generalization we obtain
S ⊢

∀x | F(y →x) →H

.
We have shown above that

∀x | F(y →x) →H

&

∃x | F(y →x)

→(∃x | H)
and
(∃y | F) ↔

∃x | F(y →x)

are universally valid. Thus, by propositional reasoning,
S ⊢(∃x | H).
But since the variable x does not occur freely in H, we have
⊢

∀x | (¬H)

↔(¬H)
by predicate axiom (iv), and so it follows propositionally that
⊢¬

∀x | (¬H)

↔H.

2.2
The Predicate Calculus
67
Predicate axiom (iii) then gives
⊢(∃x | H) ↔H
and so S ⊢H, proving that S′ is a conservative extension of S.
□
2.2.7.1 The Remainder of the Proof: Predicate Consistency Principle
We will now complete our proof of the Gödel completeness theorem. For this, it is
convenient to restate it in the following way.
Predicate consistency principle Let S be a set of formulae, none containing free
variables, such that S is consistent, i.e. S ⊢false is false. Then there exists a model
for S, i.e. an interpretation framework (U ,I,A) covering all the predicate and
function symbols appearing in S, such that Val(I,A,F) = 1 for each F in S. Con-
versely if there is a model for S then S is consistent.
This is simply the statement that S ⊢false is false iff S |= false is false. For ‘S |=
false is false’ means that there is an interpretation framework (U ,I,A) covering all
the statements F in S such that Val(I,A,F) = 1 for each F in S, but nonetheless
satisfying the (required) condition that Val(I,A, false) = 0.
It is an easy matter to see that the predicate consistency principle implies that
for every set S of predicate formulae with no free variables and for every predicate
formula F the following condition holds:
if S |= F then S ⊢F.
(2.10)
Indeed,
assume
that
S |= F
holds
and
that
S ⊢F
is
false.
Then
S ⊢(∀v1,...,vn | F), where v1,...,vn are the free variables of F , must also be
false, because otherwise by repeated use of axiom (v) and the rule of modus ponens
S ⊢F would follow. Let S′ be the set of predicate formulae obtained by adding the
formula ¬(∀v1,...,vn | F) to S. Then S′ ⊢false must be false, because otherwise
by the deduction theorem
S ⊢¬(∀v1,...,vn | F) →false
would hold and therefore, by propositional reasoning, S ⊢(∀v1,...,vn | F)
would hold. Therefore the predicate consistency principle implies that S′ has
a model, namely there exists an interpretation framework (U ,I,A) covering
all the statements G of S′ and such that Val(I,A,G) = 1 for all such G.
Thus, in particular, we have Val(I,A,C) = 1 for all the formulae C in S and
Val(I,A,¬(∀v1,...,vn | F)) = 1. This last statement implies that there exists an
assignment A′ such that Val(I,A′,F) = 0. Since all formulae in S have no free
variables, it follows that Val(I,A′,C) = Val(I,A,C) = 1 for each formula C in S,
thus contradicting our initial assumption that S |= F holds, and thereby proving
statement (2.10).

68
2
Propositional- and Predicate-Calculus Preliminaries
But the statement (2.10) implies, and indeed is a bit more general than, the Gödel
completeness theorem. This shows that the Gödel completeness theorem will follow
if we can prove the predicate consistency principle.
Proof To this end assume ﬁrst that S is not consistent. Then S ⊢false holds. But
then, as was shown earlier, S |= false follows, so that S cannot have any model.
For the converse, assume that S is consistent, in which case we must show that
S has a model. We can and shall suppose that all our formulae are in prenex normal
form, since we have seen that given any set of formulae there is an equivalent set
of prenex normal formulae. We proceed in a kind of ‘algorithmic’ style, to generate
a steadily increasing collection of formulae known to be consistent. At the end of
this process it will be easy to construct a model of the set S of statements using
these formulae and a bit of purely propositional reasoning. The idea of the proof is
to introduce enough new constants C to ensure that, for each original existentially
quantiﬁed formula
(∃x | F),
there exists a C for which
F(x →C)
is known to be true. To this end, we maintain the following lists and sets of formulae,
along with one set of auxiliary constants. These lists and sets can be (countably)
inﬁnite and will steadily grow larger. In order to be certain that there exist only
ﬁnitely many constants with names below any given length, it will be convenient
for us to suppose that all constants have names like ‘C’, ‘CC’, ‘CCC’, ... . The lists
and sets we maintain are then:
SC:
the set of all constants introduced so far.
SUF: the set of all universally quantiﬁed formulae generated so far.
SNQ: the set of all formulae containing no quantiﬁers generated so far.
LEF: the list of all existentially quantiﬁed formulae generated so far.
This list is always kept in order of increasing length of the formulae on it.
Formulae of the same length are arranged in alphabetical order. Each formula
on the list LEF is marked either as ‘processed’ or ‘unprocessed’.
These data objects are initialized as follows. SC initially contains all the constants
appearing in functions of S. SUF contains all the formulae of S which start with a
universal quantiﬁer. SNQ contains all the formulae of S which contain no quanti-
ﬁers. LEF contains all the formulae of S which start with an existential quantiﬁer.
These are arranged in the order just described. All the formulae on LEF are origi-
nally marked ‘unprocessed’.
The auxiliary set FS consists of all function symbols appearing in formulae of S.
The following processing steps are repeated as often as they apply, causing our
four data objects to grow steadily. Note that SC is always ﬁnite, becoming inﬁnite
only in the limit, but that SUF, SNQ, and LEF can be inﬁnite during the process that
we now describe.

2.2
The Predicate Calculus
69
(a) Whenever new constants are added to SC or new universally quantiﬁed for-
mulae to SUF, all the constants on SC are combined in all possible ways with
function symbols of FS to create new terms, and these terms are substituted in
all possible ways for initial universally quantiﬁed variables in formulae of SUF
(all the variables up to the ﬁrst existentially quantiﬁed variable, if any), thereby
generating new formulae, some starting with existential quantiﬁers (these are
added to LEF if not already there, following which LEF is rearranged into its
required order), others with no quantiﬁers at all (these are added to SNQ if not
already there).
(b) After each step (a), or if no step (a) is needed, we examine LEF to ﬁnd the
ﬁrst formula (∃x | F) on it not yet marked ‘processed’. For this formula, we
generate a new constant symbol C, build the formula F(x →C) produced by
replacing each free occurrence of x in F by C, and add this formula to SUF or
LEF or SNQ, depending on whether it starts with a universal quantiﬁer, starts
with an existential quantiﬁer, or has no quantiﬁers at all, and ﬁnally add the new
constant C to SC. It is understood that the list LEF must always be maintained
in lexicographic order. Finally, the formula (∃x | F) on LEF is then marked
‘processed’.
Processing begins as if the set of constants appearing in the formulae of S have just
been added to SC, and so with step (a). (If there are no such constants, we must
generate one initial constant symbol C to start processing.)
At the end of this (perhaps inﬁnitely long) sequence of processing steps, we may
have generated a countably inﬁnite list of constants as SC, and put inﬁnitely many
formulae into both of the sets SUF and SNQ and on the list LEF. But we can be
sure that it is never possible to prove a contradiction from our set of formulae. For
otherwise a contradiction would result from some ﬁnite set of formulae, all of which
would have been added to our collection at some stage in the process we have de-
scribed. But by assumption our formulae are consistent to begin with. Moreover no
step of type (a) can spoil consistency, since only predicate consequences of previ-
ously added formulae are added during such steps. Nor can steps of type (b) spoil
consistency, since it was proved above that steps of this kind yield conservative
extensions of the set of formulae previously present.
It follows that at the end of the process we have described the set SNQ of un-
quantiﬁed formulae that results is consistent, i.e. that every ﬁnite subset of this set
of formulae is consistent. We have proved above that this implies that SNQ has a
propositional model, i.e. that we can assign a 0/1 value Va(T ) to each atomic for-
mula T appearing in any of the formulae F of SNQ, in such a way that each such
F evaluates to ‘true’ if the atomic formulae appearing in it are replaced by these
values, and the standard rules for calculating Boolean truth values of propositional
combinations are then applied. Note for use below that each of the atomic formulae
T of the set AT of all such formulae appearing in any F has the form P(t1,...,tk),
where P is a predicate symbol and t1,...,tk are ‘constant’ terms (i.e. terms devoid
of variables).
Now we show that there exists a model whose universe is the set CT of all con-
stant terms generated by applying the function symbols in FS to the constants in

70
2
Propositional- and Predicate-Calculus Preliminaries
SC in all possible ways. (The resulting set of terms is the so called free universe
FU generated by these constants and the function symbols in FS.) Each k-adic func-
tion symbol f in FS is trivially associated with a mapping I(f ) from the Cartesian
product FUk of k copies of FU into FU, namely we can put
I(f )(t1,...,tk) = f (t1,...,tk)
for all lists t1,...,tk of terms. For this I and every possible assignment A it is
immediate that
Val(I,A,t) = t
for each term t in FU. A 0/1 valued function on FUk can now be associated with
each predicate symbol P appearing in a formula of S, namely we can write
I(P)(t1,...,tk) = Va

P(t1,...,tk)

for each atomic formula P(t1,...,tk) appearing in one of the formulae of SNQ,
and deﬁne I(P)(t1,...,tk) arbitrarily for all other atomic formulae; here ‘Va’ is the
Boolean assignment of truth values described in the preceding paragraph. It is then
immediate that for every assignment A we have
Val(I,A,F) = 1,
for each formula of SNQ. It remains to be shown that we must have Val(I,A,F) = 1
for the quantiﬁed formulae of SUF and LEF also and for every assignment A. Sup-
pose that this is not the case. Then there exists a formula F with n > 0 quanti-
ﬁers for which Val(I,A,F) = 0. Proceeding inductively, we may suppose that n is
the smallest number of quantiﬁers for which this is possible. If F belongs to LEF,
then it has the form (∃x | G), and by construction we will have added a formula
of the form G(x →C), with some constant symbol C, to our collection. Since
G(x →C) has fewer quantiﬁers than n, we must have Val(I,A,G(x →C)) = 1,
and so Val(I,A,F), which is the maximum over a collection of values including
Val(I,A,G(x →C)), must be 1 also.
It only remains to consider the case in which F belongs to SUF, and so has the
form
(∀x1,...,xm | G)
for some G. In this case, all formulae G(x1 →t1,...,xm →tm), where t1,...,tm
are any terms in our universe, namely the set TERM of all constant terms generated
by applying the function symbols in FS to the constants in SC in all possible ways,
will have been added to our collection. All these formulae have fewer quantiﬁers
than n, and so we must have
Val

I,A,G(x1 →t1,...,xm →tm)

= 1
for all these terms. Hence the minimum of all these values, namely
Val

I,A,(∀x1,...,xm | G)


2.2
The Predicate Calculus
71
must also have the value 1. This completes our proof of the predicate consistency
principle and in turn of the Gödel completeness theorem.
□
The argument just given clearly leads to the following slightly stronger result.
Corollary 2.1 Let S be a set of formulae in prenex normal form, and let SNQ be
the set of all unquantiﬁed formulae generated by the process described above. Then
S is consistent, i.e. it has a model, if and only if SNQ, regarded as a collection
of propositions whose propositional symbols are the atomic formulae appearing in
SNQ, is propositionally consistent.
Proof As shown above, the set of statements in SNQ must be consistent if S is
consistent. The argument given above establishes the converse, i.e. it shows that S
has a model if SNQ is propositionally consistent.
□
2.2.7.2 Immediate Consequences of the Gödel Completeness Theorem
The preceding corollary implies that in situations in which we can be sure that the
procedure described in the proof of the predicate consistency principle will pro-
duce sets SC, SUF, SNQ, and a list LEF all of which remain ﬁnite, this procedure
can be used as an algorithm to decide in a ﬁnite number of steps whether or not a
given ﬁnite set S of prenex normal formulae (none of which involves free variables)
is consistent. One case in which this remark applies is that of pure ‘∃···∃∀···∀’
formulae, as deﬁned by the following conditions:
i. S is a ﬁnite set of formulae in prenex normal form not involving free variables.
ii. No formula in S involves function symbols of arity greater than zero (i.e., the
only terms allowed in these formulae are variables and constant terms). Of
course, any number of predicate symbols can be used.
iii. No existential quantiﬁer can follow a universal quantiﬁer in any formula of S.
Note that the condition iii, implies that the sequence of quantiﬁers preﬁxed to
any ‘∃···∃∀···∀’ formula has the form
(∃y1,...,ym | (∀x1,...,xn | ···
To see why in this case the procedure described in the proof of the predicate con-
sistency principle must converge after a ﬁnite number of steps, note ﬁrst of all that
since there are no function symbol the only terms substituted for universally quan-
tiﬁed variables in step (a) of that procedure are constants. These constants must
either be present in our initial formulae or be generated in some step of the proce-
dure described. But since all existential quantiﬁers precede all universal quantiﬁers,
the aforesaid step (a) will never generate any new formula containing existential
quantiﬁers. Hence the number of constants generated is no greater than the number
of existential quantiﬁers contained in our original collection of formulae, and sub-
stitution of these for all the universally quantiﬁed variables present will generate no
more than a ﬁnite set of formulae.

72
2
Propositional- and Predicate-Calculus Preliminaries
Decidability for the Bernays–Schönﬁnkel Sentences
An interesting special
case of the foregoing is that when we are given a ﬁnite set S of pure ‘∃···∃∀···∀’
formulae, involving no free variables, as described above, and one additional for-
mula F of the same kind and in which no universal quantiﬁer follows an existential
quantiﬁer, and we want to determine whether S ⊢F holds. Let S′ be the set of for-
mulae obtained by adding the formula ‘¬F ’ to S. Then we know that S ⊢F holds
if and only S′ is inconsistent. But by moving the connective ¬ in ‘¬F ’ across the
quantiﬁer preﬁx of F , we obtain another set S∗which is equivalent to S′ and is still
a ﬁnite set of pure ‘∃-∀’ formulae, whose consistency can be tested algorithmically
in the manner just explained.
The Löwenheim–Skolem Theorem
The argument given in the proof of the pred-
icate consistency principle allows us to derive another interesting fact, known as the
Löwenheim–Skolem Theorem. This states that any consistent countable set of sen-
tences has a countable model. Indeed, if S is countable (as was implicitly assumed
in our proof of the predicate consistency principle) then all the sets SC, SUF, SNQ,
FS, and the list LEF maintained by the process described in the proof of the predi-
cate consistency principle are countable at each stage, and so must also be countable
in the limit. Therefore the model constructed from SNQ using the technique seen
above must also be countable.
The Compactness Theorem
A set S of predicate formulae is said to be satisﬁable
if it has a model. The Compactness Theorem states that if S is a set of predicate
sentences such that every ﬁnite subset of S is satisﬁable, then the whole inﬁnite set
S is satisﬁable. This theorem is an easy consequence of the predicate consistency
principle. Indeed, let S be a set of predicate sentences such that every ﬁnite subset of
S has a model, and assume that S is not satisﬁable. Then S |= false holds, so that by
the predicate consistency principle we have S ⊢false also, i.e. there exists a proof of
‘false’ from S. Since any proof from S can involve at most ﬁnitely many formulae
of S, there must exist a ﬁnite subset S′ of S such that S′ ⊢false holds, and so by the
predicate consistency principle S′ |= false must hold. That is, S′ is not satisﬁable,
contradicting our initial hypothesis that every ﬁnite subset of S is satisﬁable.
2.2.7.3 Some Other Consequences of the Gödel Completeness Theorem
Skolem Normal Form
Let S be a countable (i.e. ﬁnite or denumerable) collection
of syntactically well-formed predicate sentences. Putting each of these formulae into
prenex normal form gives an equivalent set S′ of formulae, so that if S has a model
(i.e. it is consistent) so does S′. We will now describe a second normal form, called
the Skolem normal form, into which the formulae of S′ can be put. We will see that
if S∗∗denotes the set of formulae in Skolem normal form derived from S′, then S∗∗
is consistent if and only if S′ (and S) is consistent. However, the formulae of S∗∗
are generally not equivalent to the formulae of S′ from which they derive. Thus S∗∗
and S′ (and S) are only equiconsistent, not equivalent.

2.2
The Predicate Calculus
73
By deﬁnition, a formula in prenex normal form is in Skolem normal form if and
only if its preﬁxed list of quantiﬁers contains no existential quantiﬁers. To derive the
Skolem normal form of a formula F in S′, which must already be in prenex normal
form, suppose that F has the form

∀x1,...,xk | (∃y | G)

.
(2.11)
Introduce a new function symbol f of k variables, along with a statement of the
form

∀x1,...,xk | G(y →e)

,
(2.12)
where G(y →e) is derived from G by replacing every free appearance of the vari-
able y in G by an appearance of the subexpression e = f (x1,...,xk). Let S1 be the
result of adding (2.12) to S′. We have seen above that S1 is a conservative extension
of S′. Hence if S′ ⊢false is false, so is S′
1 ⊢false, and conversely. That is, S′ and S1
are equiconsistent.
Let S∗be the set of statements obtained by dropping (2.11) from S1. We shall
show that S′ and S∗are equiconsistent. But in S∗the existentially quantiﬁed state-
ment (2.11) has been replaced by (2.12) which has one fewer existential quantiﬁer.
It should be clear that by repeating this step as often as necessary, we can eliminate
all existential quantiﬁers from our original set of statements, introducing function
symbols in their stead. The resulting set of statements is the Skolem normal form of
our original set. To prove that S′ and S∗are equiconsistent, note ﬁrst of all that, as
we have already noted, S∗is consistent if S′ is consistent. Suppose conversely that
S∗is consistent. We can deduce G(y →e) from (2.12) by k successive applications
of predicate axiom (v) and the rule of modus ponens. More speciﬁcally, we have

∀x1,...,xk | G(y →e)

⊢G(y →e).
But since
⊢(∀y | ¬G) →

¬G(y →e)

by the same axiom (v), it follows that

∀x1,...,xk | G(y →e)

⊢¬(∀y | ¬G).
Thus by predicate axiom (iii) we have

∀x1,...,xk | G(y →e)

⊢(∃y | G)
and so, by repeated application of the rule of generalization, we obtain

∀x1,...,xk | G(y →e)

⊢

∀x1,...,xk | (∃y | G)

.
The deduction theorem now implies
⊢

∀x1,...,xk | G(y →e)

→

∀x1,...,xk | (∃y | G)


74
2
Propositional- and Predicate-Calculus Preliminaries
so that
S∗⊢

∀x1,...,xk | (∃y | G)

.
This implies that exactly the same formulae can be derived from S1 and S∗, so that
these two sets of formulae are equiconsistent. Hence S′ and S∗are equiconsistent,
as required.
The Herbrand Theorem
Herbrand’s theorem, which gives a semi-decision pro-
cedure for the satisﬁability of sets of predicate formulae given in Skolem normal
form, can be stated as follows.
Theorem 2.4 (Herbrand) Let S be a countable collection of predicate sentences,
all having Skolem normal form. Let D be the set of all function symbols appearing
in the formulae of S. Let SC be the set of individual constants (function symbols of
zero variables) appearing in the formulae of S. (If there are no such constants, let
SC consist of just one artiﬁcially introduced individual constant, distinct from all the
other symbols in D.) Let T be the set of all terms which can be generated from the
constants in SC using the function symbols appearing in formulae of S. Let S′ be the
set of formulae generated from S by stripping off their quantiﬁers and substituting
terms in T for the variables of the resulting formulae in all possible ways. Then the
set S is consistent if and only if every ﬁnite subset of S′ is consistent when regarded
as a collection of propositional formulae in which two atomic formulae correspond
to the same propositional variable if and only if they are syntactically identical.
Proof This is just the Corollary of the Gödel completeness theorem stated above,
in the special case in which the formulae of S have Skolem normal form, i.e. they
contain no existential quantiﬁers. For in this case the construction we have used to
prove that Theorem and Corollary generates no new constant symbols.
□
Herbrand’s theorem is often used as a technique for searching automatically for
predicate-calculus proofs. If none of the formulae concerned have any free variables,
we can show that a predicate formula F follows from a set S of such formulae
by adjoining the negative of F to S, then putting all the resulting formulae into
Skolem normal form, and ﬁnally searching for the propositional contradiction of
whose existence Herbrand’s theorem assures us.
As a very simple example, consider the predicate theorem

∃y
 
∀x | P(x,y)

→

∀x
 
∃y | P(x,y)

(2.13)
whose negation is

∃y
 
∀x | P(x,y)

&

∃x
 
∀y | ¬P(x,y)

,
(2.14)
or, in Skolem normal form,

∀x | P(x,B)

&

∀y | ¬P(A,y)

.

2.3
Predicate Calculus with Equality as a Built-in
75
A substitution then gives the propositional contradiction P(A,B) & (¬P(A,B)),
showing the impossibility of the negated statement (2.14), and so conﬁrming the
universal validity of (2.13).
A very large literature has developed concerning optimization of searches of this
kind. Some of the resulting search techniques will be reviewed in Chap. 4.
2.3 Predicate Calculus with Equality as a Built-in
The simplicity of the equality relationship and its continual occurrence in mathemat-
ical arguments make it appropriate to extend the predicate calculus as deﬁned above
to a slightly larger version in which equality is a built-in. Syntactically we have
only to make ‘=’ a reserved symbol; semantically we need to introduce axioms for
equality strong enough for the Gödel completeness theorem to remain valid. The
following axioms sufﬁce.
The axioms of the equality-extended predicate calculus are all the axioms of the
(ordinary) predicate calculus (cf. Deﬁnition 2.7), plus
(vi) Any formula of the form

∀x,y,z| x = x &

(x = y) →(y = x)

&

(x = y & y = z) →(x = z)

.
(vii) Any formula of the form

∀x,y | (x = y) →

f (xj →x) = f (xj →y)

,
where f is a k-adic functional expression f (x1,...,xk), and f (xj →x)
(resp. f (xj →y)) is the result of replacing the jth variable in it by an occur-
rence of x (resp. y).
(viii) Any formula of the form

∀x,y | (x = y) →

P(xj →x) ↔P(xj →y)

,
where P is a k-adic predicate expression P(x1,...,xk), and P(xj →x)
(resp. P(xj →y)) is the result of replacing the jth variable in it by an occur-
rence of x (resp. y).
No new rules of inference are added.
The notion of ‘model’ is extended to this slightly enlarged version of the predi-
cate calculus by agreeing that
(xi) If the formula F is of the form ‘t1 = t2’, then
Val(I,A,F) = if Val(I,A,t1) = Val(I,A,t2) then 1 else 0 end if ,
for every interpretation framework (U ,I,A).

76
2
Propositional- and Predicate-Calculus Preliminaries
That is, the predicate which models the equality sign is simply the standard predicate
of equality.
As before we want to show that the added predicate axioms evaluate to 1 in
every model. This is clear for (vi), since it simply states the standard properties of
equality. Similarly, since replacement of the arguments of any set-theoretic mapping
by an equal argument never changes the map value, (vii) and (viii) must evaluate to
1 in any model.
Additionally we can show that the Gödel completeness theorem carries over to
our extended predicate calculus. For this, we argue as follows. If (U ,I,A) is an in-
terpretation framework covering a set S of sentences in our extended calculus, then it
follows as previously that if Val(I,A,F) = 1 for each F in S, then Val(I,A,G) = 1
for every G such that S ⊢G. Hence, as previously, if such a set S has a model it
is consistent. Suppose conversely that S is consistent. Add the equality axioms (vi–
viii) to S (this preserves consistency since only axioms are added to S) and proceed
as above to build the sets SC, SUF, SNQ, and the list LEF. Then the collection of
statements in SNQ must be propositionally consistent, and so must have a proposi-
tional model V for which every statement in SNQ takes on the value ‘true’. It was
seen above that this gives a model (U ,I,A) of all the statements in our collection,
with universe U equal to the set of all terms formed from the constants in SC using
the function symbols appearing in formulae of S. This is not quite a model of S in
the sense required when we take ‘=’ as a built-in predicate symbol which must be
modeled by the standard equality operator, since there may well exist formulae of
the form t1 = t2 such that Val(I,A,t1 = t2) = 1 even though t1 and t2 are syntacti-
cally distinct. However, the binary relationship
R(t1,t2) =

Val(I,A,t1 = t2) = 1

(2.15)
between terms of U must be an equivalence relation, since whenever terms t1, t2
and t3 are generated we will have added all the assertions
t1 = t1 &

(t1 = t2) →(t2 = t1)

&

(t1 = t2 & t2 = t3) →(t1 = t3)

to our collection. Moreover, since in the same situation statements like

t1 = t2 →

f (···t1 ···) = f (···t2 ···)

and

t1 = t2 →

P(···t1 ···) ↔P(···t2 ···)

will have been added to our collection for all function and predicate symbols, the
terms must always be equivalent whenever their lead function symbols are the same
and their arguments are equivalent, and also we must have Val(I,A,P(···t1 ···)) =
Val(I,A,PP(···t2 ···)) for atomic formulae when their lead function symbols are
the same and their arguments are equivalent. Therefore we can form a model of our
set of statements by replacing the universe U by the set U ′ of equivalence classes
on it deﬁned by the equivalence relation (2.15), and in this new model the symbol
‘=’ is represented by the standard equality operation. This concludes our proof that
the Gödel completeness theorem carries over to our extended predicate calculus.

2.4
Set Theory as an Axiomatic Extension of Predicate Calculus
77
2.4 Set Theory as an Axiomatic Extension of Predicate Calculus
In most of the present book we take a rather free version of set theory (perhaps
this should be called ‘brutal’ set theory) as basic, and use it to hurry onward to
our main goal of proving the long list of theorems found in Chap. 5. The standard
treatment of set theory ties it more carefully to predicate calculus. Speciﬁcally, to
ensure applicability of the foundational results presented earlier in this chapter, set
theory is cast as a collection of predicate axioms. In this form it is customarily
referred to as Zermelo–Fraenkel set theory (ZF) if no version of the axiom of choice
is necessarily included, or ZFC if an axiom of choice is present. Here is the standard
list of ZFC axioms.
2.4.1 Zermelo–Fraenkel Theory with the Axiom of Choice
(1) (Axiom of extension) (∀s, t | (s = t) ↔(∀x | (x ∈s) ↔(x ∈t))).
(2) (Axioms of elementary sets) There is an empty set ∅; for each set t there is a
set Singleton(t) whose only member is t; if s and t are sets then there is a set
Unordered_pair(s,t) whose only members are s and t. That is, we have

∀s | ¬(s ∈∅)

,

∀t, u|

u ∈Singleton(t)

↔(u = t)

,

∀s, t, u
 
u ∈Unordered_pair(s,t)

↔

(u = s) ∨(u = t)

.
(3) (Axiom of power set) To every set A there corresponds a set P(A) whose
members are precisely the subsets of A:

∀s, t
 
s ∈P(t)

↔

∀x | (x ∈s) ↔

∀y | (y ∈x) →(y ∈t)

.
(4) (Axiom of union) To every set A there corresponds a set A whose members
are precisely those elements belonging to elements of A:

∀s, t


s ∈

t

↔

∃x | (x ∈t) & (s ∈x)

.
(5) (Axiom of inﬁnity) There is at least one set Inf such that
(∅∈Inf) &

∀s | (s ∈Inf) →

Singleton(s) ∈Inf

.
(6) (Axiom of regularity)
¬

∃x | (x ̸= ∅) &

∀y | (y ∈x) →

∃z| (z ∈x) & (z ∈y)

.
(7) (Axiom schema of subsets) If F(y,z1,...,zn) is any syntactically valid for-
mula of the language of ZF that has no free variables other than those shown,
and neither x nor z occur in the list y,z1,...,zn, then

∃z|

∀y | (y ∈z) ↔

(y ∈x) & F(y,z1,...,zn)


78
2
Propositional- and Predicate-Calculus Preliminaries
is an axiom. Here and below, a formula is said to be a formula of the language
of ZF if it is formed using only the built-in symbols of predicate calculus (i.e.
the propositional operators, ∀, ∃, =) plus the membership operator. (Note that in
stating this axiom, we mean to assert the formula which results by quantifying
it universally over all the free variables z1,...,zn.)
(8) (Axiom schema of replacement) If F(u,v,z1,...,zn) is any syntactically
valid formula of the language of ZF that has no free variables other than those
shown, and neither u nor v occur in the list z1,...,zn, then

∀u,v1,v2
 
F(u,v1,z1,...,zn) & F(u,v2,z1,...,zn)

→(v1 = v2)

→

∀b
 
∃c
 
∀y | (y ∈c) ↔

∃x | (x ∈b) & F(x,y,z1,...,zn)

is an axiom. (Here again, in stating this axiom, we mean to assert the formula
which results by quantifying it universally over all the free variables z1,...,zn.)
This statement is obscure enough for a brief clarifying discussion of its
equivalent in our informal version of set theory to be helpful. In that less for-
mal system we would proceed by deﬁning an auxiliary ‘Skolem’ function h
satisfying

∀x,z1,...,zn
 
∃y | F(x,y,z1,...,zn)

↔F

x,h(x,z1,...,zn),z1,...,zn

.
Then, since the replacement axiom assumes that F(x,y,z1,...,zn) deﬁnes y
uniquely in terms of x and z1,...,zn, we have

∀x,y,z1,...,zn | F(x,y,z1,...,zn) →

y = h(x,z1,...,zn)

,
and so the set c whose existence is asserted by the axiom of replacement can be
written in our ‘working’ version of set theory as
	
h(x,z1,...,zn): x ∈b | F

x,h(x,z1,...,zn),z1,...,zn

.
This ‘set-former’ expression is the form in which such constructs will almost
always be written.
(9) (Axiom of choice)

∀x
 
∃f | Svm(f ) &

domain(f ) = x

&

∀y
 
(y ∈x) & (y ̸= ∅)

→

f [y] ∈y

.
Note that this form of the axiom of choice is weaker than the assumption con-
cerning ‘arb’ which our ‘brutal’ set theory uses in its place. Speciﬁcally, while
‘arb’ is a universal choice function applicable to any non-null set, the axiom of
choice just stated provides a separate such choice function for each set of sets.

2.4
Set Theory as an Axiomatic Extension of Predicate Calculus
79
Most axioms appear in Skolemized version in the above list. Other authors prefer
to write those in unskolemized form, e.g. to write our axiom (∀s | ¬(s ∈∅)) in the
form

∃z
 
∀s | ¬(s ∈z)

.
Similarly the axiom of union will often be written as

∀t
 
∃u
 
∀s | (s ∈u) ↔

∃x | (x ∈t) & (s ∈x)

.
The main respects in which the ZFC formulation of set theory differs from our
‘brutal’ version is that no built-in set-former construct is provided, nor are ‘trans-
ﬁnite recursive’ deﬁnitions like those freely allowed in our version of set theory.
An issue of relative consistency therefore arises: can our version of set theory be
reduced to ZFC in some standard way, or, if ZFC is assumed to be consistent, can it
be demonstrated that our ‘brutal’ version is consistent also?
2.4.2 Concerning the Consistency of ZFC and Various Interesting
Extensions of It
To open a discussion of this problem we ﬁrst consider the general question of con-
sistency for set-theoretic axioms like the ZFC axioms. Since equality can be treated
as an operator of logic, these axioms involve only one non-logical symbol, the pred-
icate symbol ‘∈’. The Gödel completeness theorem tells us that the ZFC axioms are
consistent if and only if they have a model. How can such models be found? Are
there many of them having an interesting variety of properties, or just a few? Since
von Neumann’s 1928 paper on the axioms of set theory and Gödel’s 1938 work on
the continuum hypothesis, many profound studies have addressed these questions.
We can get some initial idea of the issues involved by looking a bit more closely at
the hereditarily ﬁnite sets. We will see that these are of interest in the present context
since they model all the axioms of set theory other than the axiom of inﬁnity.
2.4.2.1 Basic Facts Concerning Hereditarily Finite Sets
In intuitive terms, the ‘hereditarily ﬁnite’ sets s are those which can be constructed
by using the pair formation operation {x,y} and union operation x ∪y repeatedly,
starting from the null set {} (same as ∅). Any such set has a string representation r
consisting of a properly matched arrangement of opening brackets ‘{’ and closing
brackets ‘}’, ‘properly matched’ in the sense that there are equally many opening
and closing brackets, and that no initial substring of r contains more closing than
opening brackets. Moreover, the string representation r of any such set is inde-
composable, in the sense that no initial substring of r is properly matched. Three
examples are
{}
	
{}

	
{}
	
{}


.

80
2
Propositional- and Predicate-Calculus Preliminaries
The ‘height’ of any such set is one less than the maximum depth of bracket nesting
in its string representation. For example, the three sets just displayed have heights
0, 1, and 2, respectively. The general transﬁnite induction techniques described in
the preceding section make it possible to prove that the hereditarily ﬁnite sets are
precisely those sets which are ﬁnite and all of whose elements are themselves hered-
itarily ﬁnite; this point is discussed in greater detail in Sect. 4.3.10 and in Chap. 6.
Hereditarily ﬁnite sets can be represented in many ways by computer data struc-
tures which allow the basic operations on them, namely {x,y}, x ∪y, and x ∈y, to
be realized by simple code fragments, and therefore allow translation of set-former
expressions and recursive function deﬁnitions of all kinds into computer programs.
One way of doing this is to make direct use of string representations like those just
displayed. To this end, note that each properly matched arrangement of brackets is
a concatenation of one or more indecomposable properly matched arrangements of
brackets, and that every indecomposable arrangement has the form {s} where s itself
is properly matched. Moreover the decomposition of any properly matched arrange-
ment of brackets into indecomposable properly matched substrings is unique. (The
reader is invited to prove these elementary facts, and to describe an algorithm for
separating any properly matched arrangement of brackets into its indecomposable
parts.)
It follows from the facts just stated that each hereditarily ﬁnite set t has a string
representation, itself indecomposable, of the form
{s1 s2 ··· sm},
(2.16)
where each of the sj is properly matched and indecomposable, and where all these
sj, which are simply the string representations of the elements of t, are distinct.
We can make this string representation unique by insisting that the sj be arranged
in order of increasing length, members having string representations of the same
length then being arranged in alphabetical order of their representations. We can
call a string representation (2.16) having these properties at every recursive level
(and in which all the sj are distinct at every level) a ‘nicely arranged’ properly
matched arrangement of brackets.Then every hereditarily ﬁnite set has a unique
string representation of this kind, and conversely every nicely arranged properly
matched arrangement of brackets represents a unique set. Hence these arrangements
give an explicit, 1-1 representation of the family of all hereditarily ﬁnite sets.
In this representation, the two elementary operations {x,y} and x ∪y which suf-
ﬁce for construction of all such sets have the following simple implementations.
The representation of {x,y} is obtained by taking the representations sx and sy of
x and y, respectively, checking them for equality and eliminating one of them if
they are equal, arranging them in order of length (or alphabetically if their lengths
are equal), and forming the string {sx sy} (or simply {sx} if sx and sy are identi-
cal). To compute the standard string representation of x ∪y, let {s1 s2 ··· sm } and
{t1 t2 ··· tn } be the standard string representations of x and y, respectively. Then
form the concatenation
s1s2 ···smt1t2 ···tn,

2.4
Set Theory as an Axiomatic Extension of Predicate Calculus
81
rearrange its indecomposable parts in the standard order described above, eliminate
duplicates, and enclose the result in an outermost ﬁnal pair of brackets.
In this, or any other convenient representation, it is easy to construct a code frag-
ment which will calculate the value of any set former of the type we allow, for
example
	
e(x): x ∈s | P(x)

,
provided that s is hereditarily ﬁnite, and that e is any set-valued expression and
P(x) any predicate expression which can be calculated by procedures which have
already been constructed. For this, we have only to set up an iterative loop over all
the elements of s, and use an operation which calculates e(x) for each element x
of s satisfying P(x) and then inserts all such elements into an initially empty set,
eliminating duplicates.
The powerset operation P(s) (set of all subsets of s) satisﬁes the recursive rela-
tionship
P(s) = if s = ∅then
	
∅

else P

s \
	
arb(s)


∪
	
x ∪
	
arb(s)

: x ∈P

s \
	
arb(s)


end if
which can be used to calculate P(s) recursively for each hereditarily ﬁnite s. This
makes it possible to calculate set formers of the second allowed form
	
e(x): x ⊆s | P(x)

,
by translating them into
	
e(x): x ∈P(s)| P(x)

.
Set formers involving multiple bound variables, for example
	
e(x,y,z): x ∈s, y ∈a(x), z ∈b(x,y)| P(x,y,z)

,
can be calculated in much the same way using multiply nested loops, provided that
all the sets which appear are hereditarily ﬁnite and that e, a, and b are set-valued
expressions, and P(x,y,z) a predicate expression, which can be calculated by pro-
cedures which have already been constructed. Similar loops can be used to calculate
existentially and universally quantiﬁed expressions like

∀x ∈s, y ∈a(x), z ∈b(x,y)| P(x,y,z)

and

∃x ∈s, y ∈a(x), z ∈b(x,y)| P(x,y,z)

,
or such simpler quantiﬁers as

∀x ∈s | P(x)

and

∃x ∈s | P(x)

.

82
2
Propositional- and Predicate-Calculus Preliminaries
Note, however, that the predicate calculus in which we work also allows quantiﬁers
involving bound variables not subject to any explicit limitation, for example

∀x | P(x)

and

∃x | P(x)

.
Since translation of expressions of this form into a programmed loop would require
iteration over the inﬁnite collection of all hereditarily ﬁnite sets, we can no longer
claim that the values of these unrestricted iterators are effectively calculable. Thus
they represent a ﬁrst step into the more abstract world of the actually inﬁnite, where
symbolic reasoning must replace explicit calculation.
All the kinds of deﬁnition we allow translate just as readily into computer codes
as long as only hereditarily ﬁnite sets are considered. Algebraic deﬁnitions like

x =Def {z: y ∈x & z ∈y}
translate directly into procedures whose body consists of a single nested iteration.
Recursive deﬁnitions like
enum(X,S) =Def if
S ⊆
	
enum(y,S): y ∈X

then S
else arb

S \
	
enum(y,S): y ∈X


end if
translate just as directly into recursive procedures. Thus, as long as we conﬁne our-
selves to hereditarily ﬁnite sets, the whole of the set theory in which we work (ex-
cepting only unrestricted quantiﬁers of the kind shown above) can be thought of
both as a language for the description of mathematical relationships and as an im-
plementable (indeed, implemented) programming language for actual manipulation
of a convenient class of ﬁnite objects. This parallelism between language of deduc-
tion and language of computation will be explored more deeply in Chaps. 4 and 6.
We can summarize the preceding discussion in the following way. All hereditar-
ily ﬁnite sets can be given explicit ﬁnite representations, so that these sets constitute
a ‘universe of computation’ in which all of the properties we assume for sets can be
checked by explicit computation, at least in individual cases. We will see below that
the collection of hereditarily ﬁnite sets models all the axioms of set theory, save one:
there is no inﬁnite set, for example no hereditarily ﬁnite set t having the property
t ̸= ∅&

∀x ∈t | {x} ∈t

which we will use as our axiom of inﬁnity. By including this statement in our collec-
tion of axioms we cross from the world of computation deﬁned by the hereditarily
ﬁnite sets into a more abstract world of objects which can no longer be enumerated
explicitly but which are known only through the statements about them that we can
deduce formally, i.e. as elements of a world of formal computation, whose main
elementary property is simply its formal consistency. Nevertheless, mathematical
experience has shown that the statements that we can prove about the objects of
this abstract world are both beautiful and extremely useful tools for deriving many
properties of hereditarily ﬁnite sets which it would be harder or impossible to prove
if we refused to enlarge our universe of discourse to allow free reference to inﬁnite
sets.

2.4
Set Theory as an Axiomatic Extension of Predicate Calculus
83
2.4.2.2 Hereditarily Finite Sets: Formal Deﬁnition Within General Set Theory
Hereditarily ﬁnite sets can be deﬁned formally in either of two ways: either as all
sets satisfying a predicate Is_HF, or as all the members of a set HF. The predicate
Is_HF is deﬁned in the following recursive way (we continue to designate the set of
all integers by N):
Is_HF(x) ↔Def

(#x ∈N) &

∀y ∈x | Is_HF(y)

.
To deﬁne the corresponding set HF (thereby showing that the collection of all x sat-
isfying Is_HF(x) is really a set), a bit more work is needed. We proceed as follows.
Begin with the following recursive deﬁnition (informally speaking, this deﬁnes the
collection of all sets of ‘rank x’):
HF_(x) =Def if x = ∅then ∅else
	
P

HF_(y)

: y ∈x

end if .
It is easily proved by induction that

∀y ∈HF_(x)| HF_(x) ⊇y

.
Indeed, if there exists an x for which ‘HF_(x) ⊇z’ is false for some z in HF_(x),
there exists a smallest such x, which, after renaming, we can take to be x itself.
Then there is a u such that z ∈HF_(x), u ∈z, u /∈HF_(x). Since z ∈HF_(x), we
have
z ∈
	
P

HF_(y)

: y ∈x

,
so z ∈P(HF_(y)) for some y ∈x, i.e. z ⊆HF_(y) for some y ∈x. Then u ∈
HF_(y) for some y ∈x. Since x has no member y for which

∀w ∈HF_(y)| HF_(y) ⊇w

is false, it follows that HF_(y) ⊇u, so u ∈P(HF_(y)), and therefore
u ∈
	
P

HF_(y)

: y ∈x

,
i.e. u ∈HF_(x), proving our claim. Note also that the function HF_ is increasing in
its parameter, in the sense that if y ∈x, then HF_(x) ⊇HF_(y). Indeed if u is an
element of HF_(y), then {u} ∈P(HF_(y)), so
{u} ∈
	
P

HF_(y)

: y ∈x

,
and therefore {u} ∈HF_(x), so by what we have just proved u ∈HF_(x).
In what follows we also need the fact that

∀n ∈N| #HF_(n) ∈N

,

84
2
Propositional- and Predicate-Calculus Preliminaries
i.e. that all the sets HF_(n) are themselves ﬁnite. To prove this, suppose that it fails
for some smallest n. Then
HF_(n) =
	
P

HF_(m)

: m ∈n

,
all the sets HF_(m) for which m ∈n are ﬁnite, and so are their power sets. Thus
HF_(n) is the union of a sequence of sets, each of ﬁnite cardinality, over a domain
of cardinality less than N (i.e. of ﬁnite cardinality). Hence HF_(n) is itself ﬁnite, i.e.
#HF_(n) belongs to N, as asserted.
Now we can deﬁne the set HF by
HF =Def
	
HF_(n): n ∈N

.
(2.17)
To come to the desired goal we must prove that

∀y | Is_HF(y) ↔y ∈HF

.
This can be done as follows. Suppose that y ∈HF. Then we have y ∈HF_(n) for
some n ∈N. To prove that Is_HF(y), suppose that this is false, and, proceeding
inductively, that n is the smallest element of N for which HF_(n) has an element y
such that Is_HF(y) is false. Then, since
y ∈
	
P

HF_(m)

: m ∈n

,
we have y ∈P(HF_(m)) for some m ∈n. All the elements u of y are therefore
elements of HF_(m), and so satisfy Is_HF(u). We have also proved that HF_(m) is
ﬁnite, so all its subsets are ﬁnite, and therefore #y ∈N, proving that Is_HF(y), a
contradiction implying that
(y ∈HF) →Is_HF(y)
for all y.
Suppose conversely that Is_HF(x), and that x /∈HF. Proceeding inductively, we
can suppose that x is a minimal element with these properties, i.e. that y ∈HF for
each y ∈x. Then it follows from (2.17) that for each y in x there is an n = n(y) in
N for which y ∈HF_(n(y)). But then since x is ﬁnite by deﬁnition of Is_HF(x), the
maximum m of all these n(y) is ﬁnite, so every y in x belongs to HF_(m) since the
sets HF_(m) clearly increase with their parameter m. Therefore x ∈P(HF_(m)),
x ∈HF_(m + 1), and x ∈HF, a contradiction implying that
Is_HF(y) →(y ∈HF)
for all y, which leads to the desired conclusion.
It is easily seen that HF is a model of all the ZFC axioms other than the axiom
of inﬁnity. To show this, we simply need to check that all these axioms remain
valid if we interpret all quantiﬁers as extending over the set HF rather than over the
‘universe of all sets’ that the initial ZFC axioms assume. This can be done as follows.

2.4
Set Theory as an Axiomatic Extension of Predicate Calculus
85
(1) The axiom of extension remains true since HF is transitive, i.e. every member
of a member of HF belongs to HF. (2) The null set, singleton, and unordered pair
constructions take elements of HF into themselves since they construct ﬁnite sets
all of whose elements are drawn from HF. (3) The power set axiom remains valid
since every subset of an hereditarily ﬁnite set is hereditarily ﬁnite, and for s in HF,
P(s) consists only of such elements and also is ﬁnite. (4) The union set axiom
remains valid since every member of a member of s, where s is an hereditarily
ﬁnite set, is hereditarily ﬁnite, and for s ∈HF, s is the union of ﬁnitely many
sets and so is ﬁnite. (5) The axiom of inﬁnity fails. (6) The axiom of regularity
clearly remains true, since each z ∈HF has the same members as an element of
HF that it does as a set. (7) The axiom schema of subsets, which in informal terms
asserts the existence of the set y = {u: u ∈x | F(x,z1,...,zn)} for every x and
z1,...,zn, remains true since the y whose existence it asserts is a subset of the x
which it assumes, and so must be hereditarily ﬁnite if x is hereditarily ﬁnite. (8) In
informal terms, the axiom schema of replacement asserts the existence of the set
y = {u: x ∈b | F(x,u,z1,...,zn)} for every b and z1,...,zn if the predicate F
deﬁnes u uniquely in terms of x and z1,...,zn. This remains true if only hereditarily
ﬁnite sets are allowed, since if b is ﬁnite and each u is required to be hereditarily
ﬁnite the set of whose existence it asserts is a ﬁnite set of elements, each of which
is hereditarily ﬁnite, and so must be hereditarily ﬁnite. (9) The axiom of choice
remains true since the f whose existence it asserts is a single-valued map whose
pairs have their ﬁrst components in x and their second components in x: assuming
that x ∈HF, each such pair plainly belongs to HF and therefore, since f consists of
ﬁnitely many such pairs, we conclude that f ∈HF. (If ∅∈x, we can carry out a
similar argument, after replacing the image f (∅) by ∅.)
2.4.2.3 Large Cardinal Axioms
The preceding observations concerning the set HF suggest that it may be possible
to ﬁnd a model of set theory, which would imply the consistency of set theory, by
replacing N, the smallest inﬁnite cardinal, by something larger in the crucial formula
(2.17) seen above. If this is done, the argument that we have given can be shown to
go through almost without change for any cardinal having the two properties of N
used in the argument. The following deﬁnition gives names to these properties:
Deﬁnition 2.9 A non-null cardinal number N is inaccessible if (a) Any set of car-
dinals, all less than N, which has a cardinality smaller than N also has a supremum
less than N. (Cardinals having this property are called regular cardinals.) (b) If M
is a cardinal less than N, then 2M (which is #P(M) by deﬁnition) is less than N.
(Cardinals which have this property are called strong limit cardinals.)
Note that the set N of integers is inaccessible according to this deﬁnition. In-
tuitively speaking, a cardinal number N is inaccessible if it cannot be constructed
from smaller cardinals using any ‘explicit’ set-theoretic operation, so that the very

86
2
Propositional- and Predicate-Calculus Preliminaries
existence of N would seem to involve some new assumption, in the same way that
assuming the existence of an inﬁnite set takes a step beyond anything that follows
from the properties of hereditarily ﬁnite sets x ∈HF.
If we make the following quite straightforward deﬁnition, which simply general-
izes the preceding construction of HF to arbitrary cardinal numbers N,
Deﬁnition 2.10 H (N) =Def
{ HF_(n): n ∈N} for every cardinal number N,
then the preceding discussion shows that
Theorem 2.5 If N is an inaccessible cardinal larger than N, then H (N) is a model
of the ZFC axioms of set theory.
Corollary 2.2 It there exists any inaccessible cardinal larger than N, then the ZFC
axioms have a model, and so are consistent.
A theorem of Gödel to be proved in Chap. 6 shows that no system having at
least the expressive power and proof capability of HF can be used to prove its own
consistency. Thus the corollary just stated implies the following additional result:
Corollary 2.3 Adding the assumption that there exists an inaccessible cardinal
larger than N to the ZFC axioms allows us to construct a model of the ZFC ax-
ioms and hence implies that these axioms are consistent. Therefore the ZFC axioms
cannot sufﬁce to prove that there exists an inaccessible cardinal larger than N.
The situation described by this last corollary is much like that seen in the case of
HF. The ZFC axioms, which include the axioms of inﬁnity, allow us to deﬁne the
inﬁnite cardinal number N and so the model HF of the theory of hereditarily ﬁnite
sets. The theory of hereditarily ﬁnite sets can be formalized by dropping the axiom
of inﬁnity (keeping the other axioms of ZFC, and adding a suitable principle of
induction); but the resulting set of ‘HF axioms’ do not sufﬁce to prove the existence
of even one inﬁnite set.
The technique for forming models of set theory seen in the preceding discussion,
namely identiﬁcation of some transitive set H in which the ZFC axioms remain
true if we redeﬁne all quantiﬁers to extend over the set H only, does not change the
deﬁnition of ordinal numbers, since an element t of s is an ordinal (in the overall
ZFC theory) iff its members are totally ordered by membership and each member
of a member of t is a member of t. Since the collection of members of t remains
the same in H , this deﬁnition is plainly invariant. Thus the ordinal numbers of
the model H , seen from the vantage point of the overall ZFC universe, are just
those ordinals which are members of H . But the situation is different for cardinal
numbers, which are deﬁned as those ordinals O which cannot be mapped to smaller
ordinals by a 1-1 mapping, i.e. those which do not satisfy
not_cardinal(O) ↔Def

∃f | 1_1(f ) & domain(f ) = O & range(f ) ∈O

.

2.4
Set Theory as an Axiomatic Extension of Predicate Calculus
87
When we cut the whole ZFC universe of sets down to the set H , the collection of
ordinals will grow smaller, but so will the set of 1-1 mappings (‘1_1s’) f appearing
in the formula seen above, making it unclear how the collection of cardinals (relative
to H ), or the structure of this set, will change. The power set operation can also
change, since for s ∈H the power set relative to H is the set P(s) ∩H of the
ZFC universe. Thus properties and statements involving the power set can change
meaning also. But the union set s retains its meaning. (Note also that if f is a
member of H , then the property 1_1(f ) holds relative to H if and only if it holds
in the ZFC universe, since it is deﬁned by a formula quantiﬁed over the members of
f , and these are the same in both contexts.)
However, in the particularly simple case in which we restrict our universe of
sets to H (N) where N is an inaccessible cardinal, the property ‘not_cardinal’ does
not change. This is because any 1_1 in the ZFC universe for which domain(f ) ∈
H (N) & range(f ) ∈H (N) must itself belong to H (N), since it is a set of or-
dered pairs of elements all belonging to H (N), whose cardinality is at most that
of domain(f ), and so is less than N. It readily follows that the cardinals of H (N)
are simply those cardinals of the ZFC universe which lie below N; likewise for the
regular, strong limit, and inaccessible cardinals.
It follows that ZFC, plus the assumption that there are two inaccessible cardi-
nals, allows us to construct a set H (N) in which there is one inaccessible cardinal
(namely we take N to be the second inaccessible cardinal), and so implies the con-
sistency of ZFC plus the axiom that there is at least one inaccessible cardinal. Gen-
erally speaking, axioms which imply the existence of many and large inaccessible
cardinals imply the consistency of ZFC as extended by statements only implying the
existence of fewer and smaller inaccessible cardinals, but not conversely. Thus the
addition of stronger and stronger axioms concerning the existence of large cardinal
numbers exempliﬁes a basic consequence of the incompleteness theorems presented
in Chap. 6, namely that no ﬁxed set of axioms can exhaust all of mathematics, so
that signiﬁcant extension of consistent systems by the addition of new axioms will
always remain possible. The fact that large cardinal axioms can be formulated in-
dependently of any detailed reference to the syntax of the language of set theory
makes them interesting in this regard, and so has encouraged the study of axioms
which imply the existence of more and more, larger and larger, cardinal numbers.
It is worth reviewing a few of the key deﬁnitions that have appeared in such
studies:
Deﬁnition 2.11 Let S be a set of cardinal numbers all of whose members are less
than a ﬁxed cardinal number N.
(i) S is said to be closed relative to N if the union of every sequence of elements
of S whose length is less than N is a member of S.
(ii) S is said to be unbounded in N if every cardinal less than N is also less than
some member of S.
(iii) S is said to be thin in N if there exists a closed unbounded set relative to N
which does not intersect S.

88
2
Propositional- and Predicate-Calculus Preliminaries
Deﬁnition 2.12 A nonempty set F of nonempty subsets of a set S is called a ﬁlter
on S if the intersection of any two elements of F is an element of F and any superset,
included in S, of an element of F is an element of S. A ﬁlter F is an ultraﬁlter if
whenever the union of ﬁnitely many subsets of S belongs to F , one of these subsets
belongs to F . Given a cardinal number N, a ﬁlter F is said to be N-complete if
whenever the union of fewer than N subsets of S belongs to F , one of these subsets
belongs to F . An ultraﬁlter F is said to be nontrivial if it is not the collection of all
sets having a given point p as member.
Note that if F is an N-complete ﬁlter on S, the intersection IT of any collection
T of sets in F such that #T is less than N belongs to F . Indeed, S belongs to F , and
if G belongs to F then S \ G is not in F , since otherwise F would contain the null
set G ∩(S \ G). But now S is the union of IT and the collection of all complements
S \ G for G ∈T , and since #T is less than N and F is N-complete, the union of all
these complements must lie outside F , so IT must belong to F .
The following deﬁnition lists two of the various kinds of large cardinal numbers
that have been considered in the literature.
Deﬁnition 2.13
(i) A cardinal number N is a Mahlo cardinal if it is inaccessible and the set of
regular cardinals less than N is not thin.
(ii) A cardinal number N is measurable if there is a nontrivial N-complete ultraﬁl-
ter for N.
Note that if there is a Mahlo cardinal N, then the number of inaccessible cardinals
below N must be at least N. For if there were fewer, then since N is inaccessible
the supremum M of all these cardinals would also be less than N. But then the
set SLC of all strong limit cardinals between M and N is unbounded and closed,
contradicting the assumption that N is Mahlo. Indeed, for each K between M and
N, the supremum of the sequence 2K, 22K , ... must be a strong limit cardinal,
showing that SLC is unbounded in N. Also the supremum L of any collection of
strong limit cardinals must itself be a strong limit cardinal, since any L1 less than
L must plainly be less than some cardinal of the form 2K. This shows that SLC
is closed. Now, no member K of SLC can be regular, since if it were it would be
inaccessible, contradicting the fact that M is the largest inaccessible below N. This
shows that the set of regular cardinals below N is thin, contradicting the assumption
that N is Mahlo, and so completes our proof of the fact that every Mahlo cardinal
N must be the Nth inaccessible.
It follows that the assumption that there is a Mahlo cardinal is much stronger
than the assumption that there is an inaccessible cardinal, since it implies that there
are inaccessibly many inaccessible cardinals.
Suppose next that the cardinal number N is measurable, and let F be an
N-complete nontrivial ultraﬁlter on N. Then any set consisting of just one point p
must lie outside F (or else F would be the trivial ultraﬁlter consisting of all sets hav-
ing p as member). Since F is N-complete, it follows that every subset of N having

2.4
Set Theory as an Axiomatic Extension of Predicate Calculus
89
fewer than N points lies outside F, and therefore so does every union of fewer than
N such sets. Hence every measurable cardinal is regular. We will now show that if
K is a cardinal less than N, then 2K is less than N also, showing that every measur-
able cardinal is inaccessible. Suppose the contrary, so that there exists a collection
CF of binary-valued functions f (j) deﬁned for all j in K, but having cardinality N,
and so standing in 1-1 correspondence with N. This correspondence maps f to an
N-complete nontrivial ultraﬁlter F ′ on CF. For each j in K, let a(j) be that one of
the two Boolean values {0,1} for which the set of functions {f ∈S | f (j) = a(j)}
belongs to F ′. Then, since F ′ is N-complete, it follows, as was shown above, that
the intersection of all the sets {f ∈S | f (j) = a(j)} must belong to F ′, and so F ′
contains a singleton and must therefore be trivial, contrary to assumption.
This proves that any measurable cardinal N is inaccessible. Thomas Jech (whose
[Jec97] is a general reference for this area of set theory) proves the much stronger
result (Lemma 28.7 and Corollary, p. 313) that N must be Mahlo, and in fact must
be the Nth Mahlo cardinal. He goes on to deﬁne yet a third class of cardinals,
the supercompact cardinals (p. 408), and to show that each supercompact cardinal
N must be measurable, and in fact must be the Nth measurable cardinal (Lemma
33.10 and Corollary, p. 410).
In light of the preceding, we can say that various axioms implying the existence
of very many large inaccessible cardinals have been considered in the literature,
with some hope that they can be used to deﬁne consistent extensions of the axioms
of set theory.
The preceding discussion suggests the following transﬁnite recursive deﬁnition,
which generalizes some of the properties of very large cardinals considered above:
Px(N) ↔Def if x = ∅then Is_inaccessible(N)
else

∀y ∈x | #
	
M : M ∈N | Py(M)

= N

end if .
(2.18)
Thus P0(N) is true iff N is inaccessible, P1(N) is true iff N is the Nth inaccessible
(which we have seen to be true for Mahlo cardinals), P2(N) is true iff N is the
Nth cardinal having property P1 (which we have seen to be true for measurable
cardinals), etc. So the axiom

∀x | Ord(x) →

∃N | Px(N)

implies the existence of many and very large cardinals. And, if one likes, one can
repeat this construction after replacing the predicate ‘Is_inaccessible’ in (2.18) by

∃K
 
∀x ∈K | Ord(x) →

∃N | Px(N)

.
These particular statements do not seem to have been studied enough for surmises
concerning their consistency or inconsistency to have developed. But if they are all
consistent, there will exist inner models of set theory, in the sense described in the
next section, in which any ﬁnite collection of them are true. This will allow theories
containing such axioms to be covered by ‘axioms of reﬂection’ of the kind that will
be discussed in Sect. 6.3. Of course, all of this resembles the play of children with
large numbers: ‘a thousand trillion gazillion plus one’.

90
2
Propositional- and Predicate-Calculus Preliminaries
2.4.2.4 More General ‘Inner’ Models of Set Theory
A predicate model of the Zermelo–Fraenkel axioms must provide some set U as
universe and assign a two-variable Boolean function E on U to represent the non-
logical symbol ‘∈’. The most direct (but of course not the only) way of doing this is
to choose a set U having appropriate properties and simply to deﬁne E as
E(x,y) = if x ∈y then 1 else 0 end if ,
which can be written more simply as
E(x,y) ↔(x ∈y)
if we agree to represent predicates by true/false-valued, rather than 0/1-valued, func-
tions. (An element A(x) of U must be assigned to each free variable x appearing
in a term or formula whose value is to be calculated.) Using this convention, and
noting that the ZFC axioms involve no function symbols and so they do not require
formation of any terms, we can write our previous recursive rules for calculating the
value associated with each predicate expression F (cf. Sect. 2.2) in the following
slightly specialized way:
(i) If the expression F is just an individual variable x, then Val(A,F) = A(x).
(ii) If F is an atomic formula having the form ‘x ∈y’, then Val(A,F) is the
Boolean value A(x) ∈A(y).
(iii) If F is a formula having the form (∀v1,...,vk | e), then Val(A,F) is

∀x1,...,xk | (x1 ∈U & ··· & xk ∈U ) →Val

A(x1,...,xk),e

,
where A(x1,...,xk) assigns the same value as A to every free variable of e,
but assigns the value xj to each vj, for j from 1 to k.
(iv) If F is a formula having the form (∃v1,...,vk | e), then Val(A,F) is

∃x1,...,xk | (x1 ∈U & ··· & xk ∈U ) & Val

A(x1,...,xk),e

,
where A(x1,...,xk) assigns the same value as A to every free variable of e,
but assigns the value xj to each vj, for j from 1 to k.
(v) If the formula F has the form ‘G & H’, then Val(A,F) is Val(A,G) &
Val(A,H).
(vi) If the formula F has the form ‘G ∨H’, then Val(A,F) is Val(A,G) ∨
Val(A,H).
(vii) If the formula F has the form ‘¬G’, then
Val(A,F) =

¬Val(A,G)

.
(viii) If the formula F has the form ‘G →H’, then Val(A,F) is
Val(A,G) →Val(A,H).

References
91
(ix) If the formula F has the form ‘G ↔H’, then Val(A,F) is
Val(A,G) ↔Val(A,H).
The set U deﬁnes a model of ZFC if and only if each of the ZFC axioms eval-
uates to ‘true’ under these rules. We shall pinpoint in Sect. 6.3 conditions on U
sufﬁcient for this to be the case.
We will generally suppose that U is transitive, i.e. that each member of a mem-
ber of U is also a member of U . Then axiom (1) of ZFC evaluates to

∀s,t | (s ∈U & t ∈U ) →

s = t ↔

∀x | (x ∈U ) →

(x ∈s) ↔(x ∈t)

.
This formula clearly has the value true. Indeed, if s = t, then (x ∈s) ↔(x ∈t) for
every x ∈U , so clearly

∀x | (x ∈U ) →

(x ∈s) ↔(x ∈t)

(2.19)
must be true. Suppose conversely that s ̸= t. Then by the ZFC axiom of extension-
ality, one of these sets, say s, has a member x that is not in the other. Since U is
transitive we have x ∈U , so (2.19) must be false.
ZFC axiom (6) (axiom of regularity) evaluates to
¬

∃x | (x ∈U ) & (x ̸= ∅)
&

∀y
 
(y ∈U ) & (y ∈x)

→

∃z| (z ∈U ) & (z ∈x) & (z ∈y)

,
and this also must be true. Indeed, if x in U is non-null, then by the ZFC axiom
of regularity it must have an element y which is disjoint from it, and since U is
transitive this y is also in U .
References
[Jec97]
Jech, T.J.: Set Theory, 2nd edn. Perspectives in Mathematical Logic. Springer, Berlin
(1997)


Chapter 3
A Survey of Inference Mechanisms
In this chapter we provide an extended survey of inference mechanisms which are
candidates for inclusion in the veriﬁer’s initial endowment, and note the efﬁciency
considerations which limit the complexity of the sets of statements to which each
inference mechanism can be applied.
In addition to discourse-manipulation mechanisms that will be described in
Sects. 4.1 and 4.4, the veriﬁer depends critically on a collection of routines which
work by combinatorial search. These are able to examine certain limited classes of
logical and set-theoretic formulae and determine their logical validity or invalid-
ity directly. Together they constitute the veriﬁer’s inferential core. In the following
paragraphs we will examine a variety of candidate algorithms of this kind. While
all of these (plus many others too complex to be described here) are interesting in
their own right, not all are worth including in the veriﬁer’s initial endowment of
deduction procedures, since some are too inefﬁcient to be practical, while others
are too specialized to be applied more than rarely in ordinary mathematical dis-
course. The selection actually made in the veriﬁer will be detailed once the collec-
tion of candidates that suggest themselves has been reviewed. We begin this review
by discussing one of the most elementary but important decision procedures, the
Davis–Putnam–Logemann–Loveland technique for deciding the validity of sets of
propositional formulae [DP60].
3.1 The Davis–Putnam Propositional Decision Algorithm
The Davis–Putnam algorithm works on collections C of propositional formulae,
each supposed to be a disjunction of the form
P1 ∨P2 ∨··· ∨Pn
(3.1)
with n ⩾1, where each Pj is either a propositional symbol or its opposite. It deter-
mines, for each such collection, whether it is satisﬁable, i.e. whether there exists an
J.T. Schwartz et al., Computational Logic and Set Theory,
DOI 10.1007/978-0-85729-808-9_3, © Springer-Verlag London Limited 2011
93

94
3
A Survey of Inference Mechanisms
assignment of truth values to the propositional symbols appearing in the statements
of C which makes all these statements true, or unsatisﬁable.
The ﬂavor of the collections of propositional formulae (3.1) which the Davis–
Putnam procedure takes as input can best be understood by moving all the negated
symbols Pj = (¬Qj) to the left side of each formula and then rewriting it as
(Q1 & Q2 & ··· & Qk) →(Pk+1 ∨··· ∨Pn),
(3.2)
where now all propositional symbols are non-negated. This allows us to recognize
Davis–Putnam input disjunctions (3.1) as implications in which multiple conjoined
hypotheses Qj imply one of several alternate conclusions Pi. We see at once that
sets of clauses of this type are quite typical for ordinary mathematical discourse,
and that most typically they will contain just one conclusion Pi rather than several
alternative conclusions. We also are forewarned that if many of the clauses in our
input set C contain multiple alternative conclusions, the argument necessary to ana-
lyze C’s satisﬁability will probably involve inspection of an exponentially growing
set of possible cases.
The Davis–Putnam procedure is designed to work very efﬁciently on sets of
clauses which can be written as implications containing no or few alternative con-
clusions. It works as follows in a set of input formulae (3.1).
(1) If possible, ﬁnd a formula F in C consisting of just one propositional atom Q,
either negated (i.e. F is ‘¬Q’) or non-negated (i.e. F is Q). Assign Q the value
‘false’ if it occurs negated; otherwise assign it the value ‘true’.
(2) If step (1) succeeds, remove F from C, along with every formula G in which
Q occurs with the same sign as in F . This reﬂects the fact that all these G
are already satisﬁed, since ‘H ∨true’ is propositionally equivalent to ‘true’ for
every proposition H. Also, remove the negation of F from every formula G in
which Q occurs with sign opposite to that seen in F . This reﬂects the fact that
‘H ∨false’ is propositionally equivalent to H, for every proposition H.
If step (2) ever generates an empty set of propositions, then the whole ini-
tial set is clearly satisﬁed by the sequence of truth values assigned. If it ever
generates an empty disjunction (resulting from the fact that two opposed propo-
sitions Q and ‘¬Q’ have been seen), then the search ends in failure, since a
propositional contradiction has been found.
(3) If step (1) fails, we can ﬁnd no propositional symbol whose truth value is im-
mediately evident. In this case, we proceed nondeterministically, by choosing
some symbol Q that appears in one of the formulae remaining in C, and guess-
ing it to have one of the two possible truth values ‘true’ and ‘false’. Guessing
that Q is true amounts to adding to C the formula F consisting of Q alone,
and guessing that Q is false amounts to inserting the negation of Q into C.
Thus, in either case, the recursive execution of step (1) is enabled. If this even-
tually leads to truth values satisfying all the remaining propositions of C we
are done; otherwise we backtrack to the (last) point at which we have made a
nondeterministic guess, and try the opposite guess. If both guesses fail, then we
fail overall. A chain of failures back to the point of our very ﬁrst guess implies
that the input set C of propositions in not satisﬁable.

3.1
The Davis–Putnam Propositional Decision Algorithm
95
It is easily seen that if we think of a set of Davis–Putnam input clauses as having
the form (3.2), then the maximum number of nondeterministic trials that can occur
in steps (3) is at most the product K of the numbers n −k of possible alternative
conclusions appearing in clauses of the input. Although this can be exponentially
large in the worst possible case, it will not be large in typical mathematical situ-
ations. Thus we can generally rely on the Davis–Putnam algorithm to handle the
propositional side of our veriﬁer’s work very effectively.
The Davis–Putnam algorithm can easily be adapted to generate the set of all
truth-value assignments which satisfy a given set C of input clauses. For this, we
search as above, until a satisfying assignment is found, then collect this assignment
into a set of all such assignments, but signal the algorithm to behave as if search
has failed, so that it will backtrack in the manner described above until it has found
the next possible assignment. When no more satisfying assignments can be found,
we have collected the set TVA of all truth-value assignments which satisfy all the
clauses in C. Note that the argument given in the previous paragraph shows that the
number of elements in TVA can be no larger than the product K considered there.
If we are using the Davis–Putnam algorithm simply to search for one truth-value
assignment satisfying the set of clauses C, rather than searching for the set of all
such assignments, then it can be improved by including the following step (2b)
immediately after the step (2) seen above:
(2b) If any propositional symbol Q occurs in all remaining statements of C with
the same sign (that is, either always negated or always non-negated), then give
Q the corresponding truth-value (i.e. ‘false’ if it always occurs negated, ‘true’
otherwise), and remove all the clauses containing Q from C.
This must work since if our clauses have any satisfying assignment, we can
change the assignment to give Q the truth value speciﬁed by rule (2b), since all
clauses not containing Q will clearly still be satisﬁed, but equally clearly the clauses
not containing Q will be satisﬁed also.
3.1.1 Horn Formulae and Sets of Formulae
A propositional formula
P1 ∨P2 ∨··· ∨Pn
is called a Horn formula if at most one of the propositional symbols in it occurs
non-negated, and a set C of such formulae is called a Horn set. It is easily seen
that any such set C which does not contain (either the empty disjunction or) at least
one ‘linked’ positive ‘unit’ formula A (i.e. a formula consisting of just the single
propositional symbol A that also occurs negated in some other formula) must be
satisﬁable. For clearly if we give the value ‘true’ to every symbol A that appears
as a positive unit clause of C, and ‘false’ to every symbol that occurs negated in
a formula of C, all the formulae in C will be satisﬁed. It follows from this that in

96
3
A Survey of Inference Mechanisms
the case of an unsatisﬁable set C of Horn clauses the Davis–Putnam algorithm will
never run out of unit clauses before deducing an empty clause, and so need never
use its recursive step (3). In this case, the algorithm will run in time linear in the
total length of its input.
For later use it is worth noting that we can look at such ‘Horn’ cases in a dif-
ferent, somewhat more ‘algebraic’, way. The non-negated unit formulae A can be
considered to be ‘inputs’, and the formulae
(¬B1) ∨(¬B2) ∨··· ∨(¬Bm)
which only consist of negated propositional symbols to be ‘goals’. The remaining
clauses, which must all have the form
(A1 & A2 & ··· & An) →B,
can be seen as ‘multiplication rules’ which allow collections A1,A2,...,An of in-
puts to be combined to generate new inputs B. Proof of unsatisﬁability results once
a sequence of multiplications leading to the opposites Bj of all constituents ‘¬Bj’
of a goal formula is found. Note that this observation shows that a Horn set is un-
satisﬁable if and only if some one of its subsets obtained by dropping all but one of
its goal formulae is unsatisﬁable.
3.1.2 Reducing Collections of Propositional Formulae to
Collections of Standardized Disjunctions
Since ordinary mathematical statements generally have the form
multiple_hypotheses →single_conclusion,
most of the propositional inferences arising in ordinary mathematical practice con-
vert very readily into the disjunctive Horn form favourable for application of the
Davis–Putnam algorithm as soon as their non-propositional elements are reduced
(‘blobbed down’) to propositional symbols. Other formulae can be converted into
collections of disjunctions using the following straightforward procedure:
1. Express all other propositional operators in the given collection of propositional
formulae by their expressions in terms of the operators ‘&’, ‘∨’, and ‘¬’.
2. Move all the negations down in the syntax trees of these formulae by using de
Morgan’s rules: ‘¬(a & b)’ is equivalent to ‘(¬a) ∨(¬b)’, etc. Use the rule
(¬(¬a)) ↔a to eliminate all double negations.
3. Use the fact that disjunction is distributive over conjunction to ‘multiply out’
wherever a disjunction of conjunctions is encountered, thereby reducing each
formula to a conjunction of disjunctions, each such disjunction involving only
propositional atoms and their opposites.

3.2
Elementary Boolean Theory of Sets
97
Although in most cases encountered in ordinary mathematical practice this recipe
will work well, in some cases its third step can expand one of the initial formulae
into exponentially many conjunctions. This will, for example, be the case if we
multiply out a formula of the form
(a1 & b1) ∨(a2 & b2) ∨··· ∨(an & bn).
In such cases we can use an alternative, equally easy, approach, which, however,
replaces our original set of propositional formulae, not by logically equivalent for-
mulae, but by equisatisﬁable formulae (since new variables are introduced). This
alternative method is guaranteed to increase the length of our original collection by
no more than a constant factor. It works as follows: after applying the above steps
(1) and (2), progressively reduce the syntax tree of each of the resulting collection
of formulae by working progressively upwards in the tree, replacing each conjunc-
tion ‘a & b’ and each disjunction ‘a ∨b’ introducing a new variable c which re-
places ‘a & b’ (resp. ‘a ∨b’), along with a conjoined clause ‘c ↔(a & b)’ (resp.
‘c ↔(a ∨b)’), which we can write as

(¬a) ∨(¬b) ∨c

&

(¬c) ∨a

&

(¬c) ∨b

in the ﬁrst case and as

(¬c) ∨a ∨b

&

(¬a) ∨c

&

(¬b) ∨c

in the second. After elimination of double negatives, the resulting collection of for-
mulae clearly has the asserted properties, proving our claim.
A reduction technique very similar to this reappears in the following discussion
of the decidability of the elementary unquantiﬁed theory of Boolean set operators,
where it will be called secondary decomposition.
3.2 Elementary Boolean Theory of Sets
Now we move on from the easily decidable statements of the purely propositional
calculus to a somewhat larger but still practicable case, namely that of statements
formed using the propositional operators plus the elementary Boolean operators and
comparators of set theory: ∩, ∪, \, ⊇, ⊆, and ‘=’. It is convenient to allow the null
set ∅, as a constant. Simple examples of statements that can be formed using these
operators are
(a ⊇b & b ⊇c) →(a ⊇c)
and
(a ⊇b & b ∩c = ∅) →(a \ c ⊇b),
both of which are universally valid.

98
3
A Survey of Inference Mechanisms
Statements of this general form can be considered in either of two possible set-
tings, that in which quantiﬁers are forbidden (as in the examples seen above), and
that in which quantiﬁers are allowed, as in the example

∀a
 
¬(a ∩b = ∅)

→(a ⊇b)

.
If quantiﬁers are forbidden we describe the language which confronts us as being
unquantiﬁed; in the opposite case we speak of the quantiﬁed case. Both cases are
decidable, but unsurprisingly the quantiﬁed case (which is analyzed in a later section
of this chapter) is substantially more complex. Indeed, the last formula displayed is
readily seen to be equivalent to #b = 1 ∨#b = 0. This hints at the fact that analysis
of such quantiﬁed statements must involve consideration of the number of elements
in the sets which appear, a perception which we will see to be true when we come
to analyze this case. For this reason we conﬁne ourselves in this section to the much
more elementary unquantiﬁed case.
This case is quite easy, and can be handled in any one of a number of ways.
With an eye on what is to follow, we choose to pursue an approach based on the no-
tion of place, which can be described as follows. Given a collection of unquantiﬁed
statements formed using propositional connectives and the elementary set opera-
tors and comparators listed above, and having the goal of testing these statements
for satisﬁability, we can begin by using the Davis–Putnam algorithm (or any other
propositional-level algorithm of the same kind) to determine all the propositional-
level truth-value assignments which would verify all the statements in our collec-
tion. Each of these truth-value assignments gives rise to some collection of negated
and non-negated atomic formulae of our language, no longer containing any propo-
sitional operators. These collections of formulae must then be tested for satisﬁabil-
ity. If any such collection is found to be satisﬁable, then so are our original formulae.
If no truth-value pattern satisfying our original formulae at the propositional level
gives rise to a collection of atomic formulae which can be satisﬁed at the underly-
ing set-theoretic level, then our original formula collection is plainly unsatisﬁable.
We shall refer to this preliminary propositional level step as decomposition at the
propositional level.
We can equally readily eliminate all compound expressions such as a ∪(b ∩c)
formed using the available operators ∩, ∪, \, by introducing new auxiliary variables
t and equalities like t = b ∩c, which allows compound expressions like a ∪(b ∩c)
to be rewritten as a ∪t. Similarly, inequalities like ¬(a = b ∪c) can be reduced to
inequalities of the simpler form ¬(a = t) by introducing auxiliary variables t and
replacing ¬(a = b ∪c) by the equisatisﬁable pair of statements t = b ∪c, ¬(a = t).
Once simpliﬁcations of this second kind, which we will call secondary decomposi-
tion, have been applied systematically, what remains is a collection of literals, each
having one of the forms
x = y ∩z, x = y ∪z, x = y \ z, x = ∅, x = y, x ⊇y, ¬(x = y),
(3.3)
where x,y,z stand for set-valued variables. Note that all uses of the comparator ⊆
can be eliminated, since ‘x ⊆y’ is just ‘y ⊇x’.
Next we make use of the following concept.

3.2
Elementary Boolean Theory of Sets
99
Deﬁnition 3.1 A place p for a collection C of literals of the forms (3.3), formed
using the null set constant ∅and the operators and comparators ∩, ∪, \, ⊇, and ‘=’,
is a Boolean-valued map p(x) deﬁned on all of the set-valued variables appearing
in propositions of C for which we have
• p(x) ↔(p(y) & p(z)) whenever x = y ∩z appears in C,
• p(x) ↔(p(y) ∨p(z)) whenever x = y ∪z appears in C,
• p(x) ↔(p(y) & (¬p(z))) whenever x = y \ z appears in C,
• p(x) ↔p(y) whenever x = y appears in C,
• p(x) ↔false whenever x = ∅appears in C,
• p(y) →p(x) whenever x ⊇y appears in C .
Note that this notion depends only on the subcollection of non-negated formulae
in C. We also observe that the number of distinct places for C is bounded by 2m,
where m is the number of the distinct variables occurring in the propositions of C.
Deﬁnition 3.2 A collection S of places for C is ample if, for each negated statement
¬(x = y) in C, there exists a p in S such that ¬(p(x) ↔p(y)).
Theorem 3.1 A collection C of literals of the forms (3.3), formed using the opera-
tors and comparators ∩, ∪, \, ⊇, and ‘=’, and the null set constant ∅is satisﬁable
if and only if it has an ample set A of places.
Proof First suppose that C is satisﬁable, so that it has a model M , i.e. there exists
an assignment M (a) of an actual set to each variable a appearing in the statements
of C, such that replacement of each of these variables by the corresponding set
M (a) makes all the statements of C true. Let U be the ‘universe’ of this model,
i.e. the union of all the sets M (a), and let x range over the variables appearing in
the statements of C. Then, for each point u in U , the formula
pu(x) ↔

u ∈M (x)

(3.4)
deﬁnes a place. Indeed, if x = y ∩z appears in C, we have M (x) = M (y)∩M (z),
so pu(x) ↔(pu(y) & pu(z)), and similarly if x = y ∪z appears in C, etc. For
negated statement in C like ‘¬(x = y)’ we must have M (x) ̸= M (y), and so there
must exist a point u in U such that u ∈M (x) and u ∈M (y) have different truth
values, that is, ¬(pu(x) ↔pu(y)). Hence the set of places deriving from M via the
formula (3.4) is ample.
Conversely let A be an ample set of places. Then we can build a model M with
universe A by setting
M (x) =

p : p ∈A| p(x)

.
The conditions on places displayed above clearly imply that M is a model of all the
positive statements in C. But since A is ample, we have M (x) ̸= M (y) whenever
a statement ‘¬(x = y)’ is present in C, so that the negative statements in C are
modelled correctly also.
□

100
3
A Survey of Inference Mechanisms
The preceding result implies easily the decidability of the elementary Boolean
theory of sets, since the number of distinct places for each collection of literals of
the forms (3.3) is exponentially bounded, as observed earlier.
Note that the places p deriving via formula (3.4) from a model M of any set C of
statements serve to classify the points u in the universe of the model into nonempty
pairwise disjoint subsets
sp = {u ∈U | pu = p }
which are either contained in or disjoint from each of the sets M (x): in fact, these
are the nonempty regions of the Venn diagram of the sets M (x). Conversely if we
assign nonempty disjoint sets Mp to the places p in an ample set A of places in any
way, then the union set
M (x) =

Mp : p ∈A| p(x)

(3.5)
is a model of the statements in C. Hence altogether, we see that all models of state-
ments in C have this form. This observation will be applied just below.
The technique used in this section, of simplifying collections of statements whose
satisﬁability is to be determined, ﬁrst by removing all propositional operators using
a preliminary decomposition step, and then reducing all compound expressions by
introducing auxiliary variables, will be used repeatedly and implicitly in what fol-
lows.
3.2.1 Elementary Boolean Theory of Sets, Plus the Predicates
‘Finite’ and ‘Countable’
We now generalize the unquantiﬁed language considered in the preceding section by
allowing two additional predicates on sets, namely Finite(s), which states that s is
ﬁnite, and Countable(s), which states that s is either ﬁnite or denumerably inﬁnite.
(As usual this allows us to write the corresponding negated predicates ‘¬Finite(x)’
and ‘¬Countable(x)’.) In this expanded language we can test candidate statements
like

a ∪b ⊇c & Countable(a) & Countable(b)

→Countable(c)
(3.6)
for satisﬁability.
To see how statements in this expanded language can be tested for satisﬁability,
we have only to use the formula (3.5) shown above. We saw above that any model
M of a collection C of statements involving only Boolean operators and compara-
tors can be analyzed into this form. Let ﬁ(resp. co) be the set of all places p for
which Mp is ﬁnite (resp. countably inﬁnite), and let Fi and Co be the two union sets
Fi =

{Mp : p ∈ﬁ},

3.2
Elementary Boolean Theory of Sets
101
Co =

{Mp : p ∈ﬁ∪co}.
Then, plainly, for any variable x for which a statement Finite(x) (resp. Countable(x))
is present in C, the statement
Fi ⊇M (x)
(resp. Co ⊇M (x))
must hold. Also, for any variable x for which a statement ‘¬Finite(x)’ (resp.
‘¬Countable(x)’) is present in C, the statement
¬

Fi ⊇M (x)

(resp. ¬(Co ⊇M (x)))
must hold.
Conversely, suppose that we are given any collection of statements C involv-
ing Boolean operators and comparators only, along with assertions of the forms
Finite(x), Countable(x), ¬Finite(x), and ¬Countable(x) for some of the sets x men-
tioned in the statements of C. Introduce two new variables Fi and Co, and for these
variables introduce the following statements:
Co ⊇Fi;
for each x for which a statement Finite(x) is present,
a statement Fi ⊇x;
for each x for which a statement Countable(x) is present,
a statement Co ⊇x;
for each x for which a statement ¬Finite(x) is present,
a statement ¬(Fi ⊇x);
for each x for which a statement ¬Countable(x) is present,
a statement ¬(Co ⊇x).
(3.7)
Then drop from C all statements of the forms
Finite(x), Countable(x), ¬Finite(x), ¬Countable(x).
It is plain from what was said above that if our original collection of statements has
a model, so does our modiﬁed collection. Conversely, if this modiﬁed collection has
a model, then we can assign disjoint sets Mp to the places p associated with this
model according to the following rule:
if p(Fi), then let Mp be some single element set;
otherwise, if p(Co), then let Mp be some countably inﬁnite set;
otherwise, let Mp be some uncountable set.
It then follows from the collection of statements (3.7) that M (x) is ﬁnite
(resp. countable) for each variable x for which a statement ‘Finite(x)’ (resp.
‘Countable(x)’) was originally present. Moreover if a statement ‘¬Finite(x)’ was
originally present, we must have ¬(Fi ⊇x), so there must exist a place p for which
p(Fi) is false and p(x) is true, and then plainly M (x) is not ﬁnite. Since much

102
3
A Survey of Inference Mechanisms
the same argument can be used to handle statements ‘¬Countable(x)’ originally
present, it follows that our original set of statements has a model if and only if the
modiﬁed version described above has a model. As an example, note that the negative
of the statement

a ∪b ⊇c & Countable(a) & Countable(b)

→Countable(c)
considered above is
a ∪b ⊇c & Countable(a) & Countable(b) &

¬Countable(c)

.
The procedure we have described transforms this into
a ∪b ⊇c & Co ⊇a & Co ⊇b &

¬(Co ⊇c)

.
Since this is clearly unsatisﬁable, the universal validity of our original statement
follows.
3.2.2 Elementary Boolean Operators on Sets, with the Cardinality
Operator and Additive Arithmetic on Integers
We will now generalize the results described above in this Sect. 3.2 by allowing in
addition to set-valued variables also a different type of variables i, now denoting
non-negative integers, and a set-to-integer operation #x. For variables i,j of integer
type we allow the operations i + j (integer addition) and i −j (integer subtraction);
also, the integer comparators i > j and i = j and two constants designating the
integers 0 and 1 are allowed. A simple example of a statement that can be formed
using these operators is

#x = 1 & ¬(x ∩y = ∅)

→(y ⊇x),
which is universally valid.
By means of decomposition steps of the kind described earlier (decomposition at
the propositional level and secondary decomposition), the satisﬁability problem for
collections of unquantiﬁed statements involving
• the null set constant ∅,
• the set operators and comparators ∩, ∪, \, ⊇, and ‘=’,
• the integer constant 0,
• the integer operators and comparators #(·), +, −, ‘>’, and ‘=’
can be reduced to the satisﬁability problem for collections of literals of the forms
x = y ∩z, x = y ∪z, x = y \ z, x = ∅, x = y, x ⊇y, ¬(x = y),
(3.8)
i = #x, i = j + k, i > j, i = 0,
(3.9)

3.2
Elementary Boolean Theory of Sets
103
where x,y,z stand for set-valued variables and i,j,k stand for integer-valued vari-
ables. Note that all uses of integer subtraction can be eliminated, because we regard
‘i = j −k’ as being equivalent to ‘j = i + k’.
Let C be a collection of literals of the forms (3.8) and (3.9) and let A be an
ample set of places for C. For each place p in A, we introduce a new integer-valued
variable ip, which is supposed to denote the (ﬁnite) cardinality of the set to be later
assigned to p. It is convenient to associate to C and A the following system BC,A of
arithmetic conditions over the integer-valued variables occurring in the statements
of C plus the new variables ip. To begin with, we place in BC,A all statements in C
of type
i = j + k, i > j, i = 0.
Then, for each literal i = #x in C, we add to BC,A the equation
i = ip1 + ··· + ipk,
where p1,...,pk are all the places p in A such that p(x) = true. Finally, for each
statement ¬(x = y) in C, we place in BC,A the inequality
iq1 + ··· + iqℓ> 0,
where q1,...,qℓare all the places q in A such that ¬(q(x) ↔q(y)).
Theorem 3.2 A collection C of literals of the forms (3.8) and (3.9) is satisﬁable if
and only if it has an ample set A of places such that the system BC,A of arithmetic
conditions associated with C and A admits a non-negative integer solution.
Proof Assume ﬁrst that C is satisﬁable and let M be a model for C with universe
U . Let A be the collection of all places pu deﬁned by (3.4), for u ∈U . By arguing
as in the proof of Theorem 3.1, it follows that the set of places A is ample, when
restricted to set-valued variables. It remains to extend M over the integer-valued
variables ip, for p in A. As above, for each place p in A, we let
sp = {u ∈U | pu = p }.
Then, if sp is ﬁnite we put
M (ip) = #sp,
otherwise we leave M (ip) undeﬁned, as in the latter case the variable ip does not
occur in any arithmetic condition in the system BC,A.
It is an easy matter to verify that the restriction to the integer-valued variables
of the assignment M so extended is a solution for the system BC,A of arithmetic
conditions associated to C and A.
Conversely, let A be an ample set of places for C, and let us assume that the sys-
tem BC,A of arithmetic conditions associated with C and A admits a non-negative

104
3
A Survey of Inference Mechanisms
integer solution M . We assign disjoint sets Mp to the places p in A so as to satisfy
the condition
#Mp = M (ip).
Then for each set-valued variable x occurring in some statement of C we put
M (x) =

Mp : p ∈A| p(x)

.
It can easily be veriﬁed that the assignment M so extended is a model for C. For
instance, let ¬(x = y) be a statement in C and let q1,...,qℓbe all the places q in
A such that ¬(q(x) ↔q(y)). Since A is ample, ℓ⩾1. By construction, the system
BC,A of arithmetic conditions associated with C and A must contain the inequality
iq1 + ··· + iqℓ> 0,
and therefore
M (iq1) + ··· + M (iqℓ) > 0
holds. Without loss of generality, we can therefore assume that M (iq1) > 0 holds,
so that Mq1 ̸= ∅. Since
M (x) ⊇Mq1
if and only if
M (y) ̸⊇Mq1,
we can conclude that M (x) ̸= M (y), proving that M satisﬁes the statement
¬(x = y). Similarly it can be shown that M satisﬁes also all statements in C of
the remaining types, concluding the proof of the theorem.
□
Solvability of systems of arithmetic conditions of the types present in BC,A can
be tested algorithmically by a method originally developed by M. Presburger in
[Pre30]. Therefore the above result readily entails the decidability of the elemen-
tary Boolean theory of sets with the cardinality operator and additive arithmetic on
integers. Presburger’s decision method will be reviewed in detail in Sect. 3.8.1.
3.2.3 Quantiﬁed Predicate Formulae Involving Predicates of One
Argument Only
Quantiﬁed formulae of the predicate calculus involving only predicates of a single
argument and no function symbols can be decided rather easily as for satisﬁability
by relating them to elementary set-theoretic formulae of the kind considered above.
This can be done as follows. Let F be any such formula. First remove all propo-
sitional ‘→’ and ‘↔’ operators by replacing them with appropriate combinations
of the operators ‘&’, ‘∨’, and ‘¬’. Then introduce a set name p for each predicate
name P appearing in the original formula, and using these rewrite each atomic for-
mula P(x) as ‘x ∈p’. This step is justiﬁed since if the original formula has a model

3.2
Elementary Boolean Theory of Sets
105
M with universe U , then M will associate a Boolean-valued function M (P) with
each predicate name P appearing in F , and we can simply interpret each corre-
sponding p as the set

u: u ∈U | M (P)(u)

.
Next, working upward in the syntax tree from its twigs toward its root, process
successive quantiﬁers in the following way, so as to remove them. (The approach
we are using is accordingly known as quantiﬁer elimination.)
(i) Rewrite universal quantiﬁers ‘(∀x | ···)’ as the corresponding existential quan-
tiﬁers ‘¬(∃x | ¬···)’.
(ii) Use the algebraic rules for the operators ‘&’, ‘∨’, ‘¬’ to rewrite the body of each
existential (∃x | ···) (i.e. the part of it following the sign ‘| ’) as a disjunction
of conjunctions, that is, in the form
(A1 & A2 & ··· & Ai) ∨(B1 & B2 & ··· & Bj) ∨··· ,
where each elementary subpart A,B,... which appears is either of the form
‘x ∈p’, or of the negated form ‘¬(x ∈p)’, or is a subformula not involving x
as a free variable. Then use the predicate rules

∃x | A(x) ∨B(x)

↔

∃x | A(x)

∨

∃x | B(x)

and

∃x | A(x) & C

↔

∃x | A(x)

& C

(where x has no free occurrences in C) to reduce the existential quantiﬁer being
processed to the form
(∃x | A1 & A2 & ··· & An),
where each Ai appearing is either of the form ‘x ∈p’ or ‘x /∈p’.1 This con-
fronts us with an existential formula of the form
(∃x | x ∈p1 & ··· & x ∈pm & x /∈pm+1 & ··· & x /∈pn),
which we can rewrite as

p1 ∩··· ∩pm ∩(U \ pm+1) ∩··· ∩(U \ pn)

̸= ∅
(s1 ̸= s2 is short for ¬(s1 = s2)).
It is clear that we can apply this procedure until no quantiﬁers remain, at which
point we will have derived a formula F ′ of the unquantiﬁed language of elementary
1x /∈p is short for ¬(x ∈p).

106
3
A Survey of Inference Mechanisms
Boolean-set operations considered previously which is equisatisﬁable with our ini-
tial quantiﬁed formula F . By testing F ′ for satisﬁability using the method described
above, we therefore can determine whether F is satisﬁable. Note that clauses
U ⊇pj
and a clause U ̸= ∅implying that the universe U is non-null and includes all the
other sets which appear in our formula must be added just before the ﬁnal satisﬁa-
bility check is applied.
Note also that this procedure converts our original collection of quantiﬁed for-
mulae into a collection of purely Boolean statements about the sets {u: u ∈
U | P(u)}, which can, however, involve arbitrary intersections of these sets and
their complements.
As an example of this procedure, consider the formula

∃x
 
∃y | P(y)

→P(x)

(3.10)
examined in an earlier section. The negation of this is
¬

∃x
 
¬

∃y | P(y)

∨P(x)

.
Processing this as above we get
¬(p = ∅∨p ̸= ∅) & U ⊇p & U ̸= ∅,
which is clearly unsatisﬁable. Hence (3.10) is universally valid.
Various somewhat more general quantiﬁed cases can be reduced to the case just
treated. For example, suppose that as above we take quantiﬁed formulae of the pred-
icate calculus involving only predicates of a single argument, but now also allow
function symbols of a single variable. If the function symbols sometimes appear
compounded within predicates, as in the example P(f (g(h(x)))), we can introduce
auxiliary new predicate symbols P f and P fg along with deﬁning clauses

∀x | P f (x) ↔P

f (x)

&

∀x | P fg(x) ↔P f 
g(x)

,
and then rewrite P(f (g(h(x)))) as P fg(h(x)).
Suppose that there exists a model M with universe U of the collection of state-
ments, which must therefore model all the predicates P and functions f in such a
way as to make all the quantiﬁed statements in our original collection C of state-
ments true. Associate the set
SP =

u ∈U | M (P)(u)

with each predicate P , and the set
SPf =

u ∈U | M (P)

M (f )(u)


3.2
Elementary Boolean Theory of Sets
107
with each predicate symbol P and function symbol f . Then SPf is the inverse im-
age of SP under the map M (f ) modelling f . Let P1,...,Pn be all the predicate
symbols inside of which f appears (as Pj(f (x)) for some variable x), let
SP1 ∩SP2 ∩··· ∩SPk \ (SPk+1 ∪··· ∪SPn)
(3.11)
be some intersection of the sets SPj and their complements, and let
SP1f ∩SP2f ∩··· ∩SPkf \ (SPk+1f ∪··· ∪SPnf )
(3.12)
be the corresponding intersection of the sets SPjf .
It follows that if the ﬁrst of these sets is empty so is the other, and conversely.
Hence, if a model M for our collection of quantiﬁed statements exists, there must
exist a model for the collection of sets SPj and SPjf which satisﬁes all the conditions
SP1 ∩SP2 ∩··· ∩SPk \ (SPk+1 ∪··· ∪SPn) = ∅
↔SP1f ∩SP2f ∩··· ∩SPkf \ (SPk+1f ∪··· ∪SPnf ) = ∅.
(3.13)
Earlier in this section we developed a systematic method for converting every
collection of quantiﬁed statements involving only predicates of the form P(x) to an
equisatisﬁable collection C′ of statements about the sets SP = {x | P(x)}, together
with their intersections and complements. If we employ this procedure in the present
case, we get a collection C′′ of statements about the sets SP = {x |P(x)} and SPf =
{x | P(f (x))}, together with their intersections and complements, which must be
satisﬁed even if the conditions (3.13) are added. Conversely, suppose that we can
ﬁnd a set-theoretic model for the collection of statements C′′ plus all statements of
type (3.13). Then we can deﬁne the predicates P(x) as ‘x ∈SP ’, and the predicates
P(f (x)) as ‘x ∈SPf ’. To be sure that these predicates can derive from some model
of these same predicates in which there do exist maps for which ‘x ∈SPf ↔f (x) ∈
SP ’, we can argue as follows. In the assumed model M ′ of the sets SP , any two sets
of the form (3.11) will be disjoint if the pattern of intersections and complements
deﬁning them are different. Hence we can map the whole of each non-null set (3.11)
into some selected point p of the (also non-null) set (3.12). This plainly maps each
set SP into the set SPf , establishing that we do have a model of the original collection
of quantiﬁed statements.
The following formula illustrates the technique just described:
⎛
⎜⎝

∀x
 
P(x) & P

f (x)

→P

f ′(x)

&

∀x | P

f (x)

→P(x)

&

∃x | P

f (x)

⎞
⎟⎠→

∃x | P

f ′(x)

.
(3.14)
The negative of this is the conjoined collection of formulae

∀x
 
P(x) & P

f (x)

→P

f ′(x)

,

∀x | P

f (x)

→P(x)

,

108
3
A Survey of Inference Mechanisms

∃x | P

f (x)

,
¬

∃x | P

f ′(x)

.
The transformed set C′ of formulae derived from this in the manner described above
is

∀x
 
P(x) & Pf (x)

→Pf ′(x)

,

∀x | Pf (x) →P(x)

,

∃x | Pf (x)

,
¬

∃x | Pf ′(x)

.
If we now consider the predicate symbols to designate sets, this gives
pf ′ ⊇p ∩pf & p ⊇pf & pf ̸= ∅& pf ′ = ∅.
(3.15)
Here there appear two sets pf and pf ′ derived from predicate terms involving func-
tion symbols, one for each of the function symbols f and f ′. The additional condi-
tions which need to be added to guarantee equisatisﬁability are
p = ∅↔pf = ∅,
U \ p = ∅↔U \ pf = ∅,
p = ∅↔pf ′ = ∅,
U \ p = ∅↔U \ pf ′ = ∅,
together with conditions stating that all other sets are included in U and that U is
non-null, so that U must designate the universe of any model. Since the conjunction
of all these Boolean conditions is clearly unsatisﬁable (in fact, the conjunction (3.15)
by itself is already unsatisﬁable), formula (3.14) must be universally valid.
We can allow the use of both the MLSS constructs deﬁned in the next section,
namely membership statements ‘x ∈y’ and singleton terms ‘{x}’, and of quantiﬁed
predicates P(x), Q(y) of a single variable, under the very restrictive but easy-to-
check condition that no quantiﬁed variable x can appear in any set-theoretic expres-
sion or relationship other than atomic expressions of one of the forms
x = e or x ∈e or P(x),
where the expression e does not involve any quantiﬁed variable. As explained above,
a nominal set p can be associated with each predicate P , and P(x) then written as
x ∈p. The reductions described above apply easily to the somewhat generalized
statements that result. Note that a quantiﬁed expressions like
(∃x | x = e & x ∈p1 & ··· & x ∈pm & x /∈pm+1 & ··· & x /∈pn)
can be rewritten as
e ∈p1 ∩··· ∩pm ∩(U \ pm+1) ∩··· ∩(U \ pn),

3.3
MLSS: Multilevel Syllogistic with Singletons
109
while

∃x
 
¬(x = e)

& x ∈p1 & ··· & x ∈pm & x /∈pm+1 & ··· & x /∈pn

can be rewritten as

U \ {e}

∩p1 ∩··· ∩pm ∩(U \ pm+1) ∩··· ∩(U \ pn) ̸= ∅,
so that removal of quantiﬁers in the manner explained always generates statements
belonging to MLSS.
Certain limited classes of statements involving set formers reduce to the kinds of
statements considered above. For example, the inclusion

x ∈s | P(x)

⊇

e(y): y ∈t | Q(y)

can be written as

∀y
 
y ∈t & Q(y)

→

e(y) ∈s & P

e(y)

.
On the other hand, the converse inclusion

x ∈s | P(x)

⊆

e(y): y ∈t | Q(y)

translates into

∀x
 
∃y
 
x ∈s & P(x)

→

x = e(y) & y ∈t & Q(y)

which involves the binary equality operator and so is not covered by the preceding
discussion. This indicates that statements involving set formers can only be handled
by the method just described in particularly favourable cases.
3.3 MLSS: Multilevel Syllogistic with Singletons
MLSS is the (unquantiﬁed) extension of the elementary Boolean theory of sets ob-
tained by allowing the membership relator ‘x ∈y’ and the singleton operator {x}
in addition to the elementary operators and relators ∩, ∪, \, ⊇, and ‘=’. Given a
collection C of statements in this language, we begin as usual by applying decom-
position at the propositional level, and then secondary decomposition. This allows
us to assume for decidability purposes that C consists of statements each having one
of the forms
x = y ∪y′, x = y ∩y′, x = y \ y′, x = y, ¬(x = y), y ∈x, ¬(y ∈x), x = {y}.
We then eliminate all the statements ‘x = y’ by selecting a representative of any
group of set variables known to be equal, and replacing each occurrence of a variable
in the group by its selected representative.

110
3
A Survey of Inference Mechanisms
Next we prepare C for the analysis given below by enlarging it, but in a manner
preserving satisﬁability. This is done by collecting all the variables y which appear
in statements of the form ‘y ∈x’, ‘¬(y ∈x)’, or ‘x = {y}’. We will call these y the
left-hand variables. Then, for each pair y1, y2 of such variables we add the statement
y1 = y2 ∨¬(y1 = y2).
Since the indicated statements are universally valid, these additions evidently pre-
serve satisﬁability. Subsequently, we apply decomposition at the propositional level
once more, and again eliminate all statements x = y by selecting representatives in
the manner described above. This leaves us with a modiﬁed collection C of state-
ments, each having one of the forms
x = y ∪y′, x = y ∩y′, x = y \ y′, ¬(x = y), y ∈x, ¬(y ∈x), x = {y}. (3.16)
But now, after the steps of preparation we have described, we can be sure that for
any two distinct left-hand variables y1 and y2, an explicit inequality ‘¬(y1 = y2)’ is
present in C. We denote by Lvars the collection of left-variables of C.
Now suppose our collection C of statements has a model M with universe U .
As in our previous discussion of the elementary Boolean case, the set A of places
pu deﬁned by
pu(x) ↔u ∈M (x),
where u ranges over the points of U , must be ample for the subcollection of ele-
mentary Boolean statements in C, namely those not of the form y ∈x, ¬(y ∈x), or
x = {y}. The points M (y) ∈U corresponding to left-hand variables y appearing
in C deﬁne places py (via our standard formula py(x) ↔M (y) ∈M (x)),2 which
plainly must have the following properties:
py(x) is true if a statement ‘y ∈x’ appears in C;
py(x) is false if a statement ‘¬(y ∈x)’ appears in C;
py(x) is true if a statement ‘x = {y}’ appears in C.
We call a place py having these three properties a place at y. Some of the places
corresponding to points in the model M will be places at y for some variable y in
the set C of statements, others will not.
We now look a bit more closely at the structure of the model M , with an eye
toward accumulating enough properties of its places to guarantee the existence of at
least one model. Note ﬁrst of all that since set theory forbids all cycles
s1 ∈s2 ∈··· ∈sn ∈s1
of membership, it must be possible to arrange the sets M (x) of our model into an
order for which the variable x comes before y whenever M (x) is a member of
2Strictly speaking, places py should be denoted by pM(y).

3.3
MLSS: Multilevel Syllogistic with Singletons
111
M (y). We will call any such order an acceptable ordering of the variables of C.
Note that for any acceptable ordering, and any variables y and x, py(x) can only be
true if y precedes x in this ordering.
For each place p of the model we can let Mp be the collection of all points u of
U such that (u ∈M (x)) ↔(p(x) = true) for every variable x appearing in a state-
ment of C, minus all points having the form M (z) for some left-hand variable z.
This allows us to write each set M (x) of the model in the following way for each
variable y appearing in C:
M (x) =

M (z): z ∈Lvars| pz(x)

∪

Mp : p ∈A| p(x)

.
(3.17)
The sets Mp are clearly disjoint for distinct p, i.e. Mp ∩Mq = ∅if p ̸= q. If a
statement ‘x = {y}’ appears in C, then M (x) must be a singleton, so that
• py must be the only place p of the model M for which p(x) is true,
• there is no left-hand variable z distinct from y such that pz = py, and also
• Mpy must be null.
The following theorem shows that the conditions on the collection of places of
M that we have just enumerated are sufﬁcient to guarantee the existence of a model
of C, and so gives us a procedure for determining the satisﬁability of C.
Theorem 3.3 Let C be a collection of statements of the form (3.16), and suppose
that if y1, y2 are two distinct left-hand variables of C, an inequality ‘¬(y1 = y2)’
or ‘¬(y2 = y1)’ is present in C.
Then the following conditions are necessary and sufﬁcient for C to be satisﬁable,
i.e. to have a model M :
(i) There exists an ample set A of places p for the subcollection of elementary
Boolean statements in C.
(ii) For each left-hand variable y appearing in a statement of C, there is a place
py at y in A. Moreover, the variables appearing in the statements of C can be
arranged in an order ≺such that py(x) is false unless y ≺x.
(iii) If a statement ‘x = {y}’ appears in C, then py is the only place p in A for
which p(x) is true, and y is the only left-hand variable z such that pz = py.
Proof We saw above that the conditions (i–iii) are necessary.
Suppose conversely that they are satisﬁed. For each place p in A choose a set Mp
in such a way that all these sets are disjoint and non-null; however, if a statement
‘x = {y}’ appears in C (so that y is a left-hand variable) we take Mpy to be null.
We also suppose that each member of any set Mp has larger cardinality than the
total number m of variables appearing in C, plus K · #A, where K is the largest
cardinality of any set Mp. (One way of doing this is to let the non-null sets Mp be
distinct singletons {u}, where each u has a number of members exceeding m + #A.)
Then use formula (3.17) to deﬁne M (x) for each variable x appearing in C. This
is possible since by condition (ii) the variables appearing in the statements of C can
be arranged in an order for which all the M (z) appearing in the deﬁnition (3.17)

112
3
A Survey of Inference Mechanisms
of M (x) have been deﬁned before (3.17) is used to deﬁne M (x). Note that the
cardinality condition we have imposed ensures that every one of the sets

M (z): z ∈Lvars| pz(x)

appearing ﬁrst on the right of any formula (3.17) is disjoint from every one of the
sets

Mp : p ∈A| p(x)

,
appearing second on the right of any formula (3.17), every set M (x) has cardinality
at most m + K · #A, while all the members of a set {Mp : p ∈A| p(x)} must
be members of some Mp, and hence must have cardinality greater than m + K · #A.
We now show that all the statements ‘¬(x = y)’ in C are correctly modelled by
the function M deﬁned by (3.17). This is clear if there exists any Mp ̸= ∅for which
p(x) and p(y) are different, say p(x) = true and p(y) = false, since in this case
it follows from (3.17) that Mp will be a subset of M (x) and will be disjoint from
M (y) (since the ﬁrst and second terms of (3.17) are always disjoint and the Mq’s
are pairwise disjoint). But we must prove it in general.
Suppose that our claim is false, and let x be the ﬁrst variable, in the ordering ≺
mentioned in condition (ii), for which there exists some statement ‘¬(x = y)’ or
‘¬(y = x)’ in C such that M (x) = M (y). Since the set A of places is ample, there
must exist a place p in A such that one of p(x), p(y) is true and the other is false.
Suppose for deﬁniteness that p(x) is true, so p(y) is false. We have already observed
that if Mp were nonempty, M (x) ̸= M (y), contrary to assumption. Hence Mp = ∅,
so that p must be of the form p = pw, for some left-hand variable w. Then pw(x) is
true, w ≺x by condition (ii), and M (w) belongs to M (x) by (3.17). Hence M (w)
belongs to M (y) also. But M (w) cannot belong to the second term of
M (y) =

M (z): z ∈Lvars| pz(y)

∪

Mp : p ∈A| p(y)

,
since if it did it would belong to some Mp such that p(w) is true, whereas all the
members of all Mp have cardinality larger than M (w). Therefore M (w) must be-
long to the ﬁrst term of M (y), i.e. must be identical with some M (z) for a left-
hand variable z for which pz(y) is true, therefore distinct from w. Since w and z
are distinct left-hand variables, by hypothesis C must contain a clause ‘¬(w = z)’
or ‘¬(z = w)’. But now M (w) = M (z) contradicts our assumption that x is the
ﬁrst variable in the order ≺for which there exists some statement ‘¬(x = y)’ or
‘¬(y = x)’ in C such that M (x) = M (y). This contradiction proves our claim that
M (x) ̸= M (y) whenever a clause ‘¬(x = y)’ is present in C, and so shows that all
such clauses are correctly modelled by M .
Next we show that all other statements of C are correctly modelled also. For
statements x = {y} this follows immediately from condition (iii) of our theorem and
the fact that Mpy = ∅. Statements ‘y ∈x’ are correctly modelled since the presence
of such a statement implies that M (y) must belong to the ﬁrst term of (3.17). State-
ments ‘¬(y ∈x)’ are correctly modelled, since by its cardinality a set of the form
M (z) can only belong to the ﬁrst term of (3.17); but since all the M (z) are distinct

3.4
MLSS Plus the Predicates ‘Finite’ and ‘Countable’
113
for distinct left-hand variables, M (y) will only belong to the ﬁrst term of (3.17) if
py(z) is true, which is impossible if ‘¬(y ∈x)’ appears in C.
Statements x = y ∪y′ are correctly modelled since
M (x) =

M (z): z ∈Lvars| pz(x)

∪

M (p): p ∈A| p(x)

=

M (z): z ∈Lvars| pz(y) ∨pz(y′)

∪

M (p): p ∈A| p(y) ∨p(y′)

=

M (z): z ∈Lvars| pz(y)

∪

M (p): p ∈A| p(y)

∪

M (z): z ∈Lvars| pz(y′)

∪

M (p): p ∈A| p(y′)

= M (y) ∪M (y′).
Similarly, for statements x = y ∩y′ we have
M (x) =

M (z): z ∈Lvars| pz(x)

∪

M (p): p ∈A| p(x)

=

M (z): z ∈Lvars| pz(y) & pz(y′)

∪

M (p): p ∈A| p(y) & p(y′)

=

M (z): z ∈Lvars| pz(y)

∪

M (p): p ∈A| p(y)

∩

M (z): z ∈Lvars| pz(y′)

∪

M (p): p ∈A| p(y′)

= M (y) ∩M (y′)
since all the sets Mp are disjoint, no M (x) belongs to any of them, and all the sets
M (x) for x ∈Lvars are distinct. The same argument handles the case of statements
‘s = t \ u’, completing the proof of our theorem.
□
3.4 MLSS Plus the Predicates ‘Finite’ and ‘Countable’
We can easily generalize MLSS by allowing the two additional set predicates
‘Finite(s)’ and ‘Countable(s)’ studied above.
Given a collection C of statements each of which has one of the following forms
x = y ∪y′, x = y ∩y′, x = y \ y′, x = y, ¬(x = y), y ∈x, ¬(y ∈x), x = {y},
Finite(x), Countable(x), ¬Finite(x), ¬Countable(x),

114
3
A Survey of Inference Mechanisms
much as before, we can introduce two new variables Fi and Co, and for these vari-
ables introduce the following statements:
Co ⊇Fi;
for each x for which a statement Finite(x) is present in C,
a statement Fi ⊇x;
for each x for which a statement Countable(x) is present in C,
a statement Co ⊇x;
for each x for which a statement ¬Finite(x) is present in C,
a statement ¬(Fi ⊇x);
for each x for which a statement ¬Countable(x) is present in C,
a statement ¬(Co ⊇x);
for each statement x = {y} which is present in C,
a statement Fi ⊇x.
(3.18)
Then drop from C all statements of the form
Finite(x), Countable(x), ¬Finite(x), ¬Countable(x),
and let C′ be the resulting modiﬁed collection of statements. Arguing much as in
Sect. 3.2.1, it follows easily that if our original collection C of statements has a
model, so does our modiﬁed collection C′. Conversely, if C′ has a model, then as
above there must exist an ample set of places for C′ and to these places we can
assign disjoint sets Mp according to the following rule:
if p is of the form py for some variable y appearing in a statement x = {y},
let Mp be null;
otherwise, if p(Fi) = true, then let Mp be some single element;
otherwise, if p(Co) = true, then let Mp be some countably inﬁnite set;
otherwise, let Mp be some uncountable set.
We also suppose, as in the preceding discussion of MLSS, that each member of Mp
has larger cardinality than m + K · #A, where m, A, and K are as in that discussion,
and then use (3.17) to deﬁne a model M . The analysis given in the preceding sec-
tion shows that this M correctly models all statements not involving the predicates
‘Finite’ and ‘Countable’. It is plain that M (Fi) is ﬁnite and M (Co) is countable;
hence all statements ‘Finite(x)’ and ‘Countable(x)’ originally present are correctly
modelled also.
If any statement ‘¬Finite(x)’ is present in C, then there exists a place p such
that p(x) is true and p(Fi) is false. p cannot have the form py for any variable
y appearing in any statement z = {y} appearing in C, since if it did then the fact
that py(z) must be true and the statement Fi ⊇z present in C′ would imply that
py(Fi) is true. Hence Mp is inﬁnite and so by (3.17) M (x) is inﬁnite also. This
shows that all statements ‘¬Finite(x)’ are correctly modelled. The case of statements
‘¬Countable(x)’ can be handled in much the same way, showing that our original
and modiﬁed sets of statements are equisatisﬁable.

3.5
The Tableau Method
115
3.5 The Tableau Method
The Davis–Putnam method for testing propositional satisﬁability, which we dis-
cussed in Sect. 3.1, attains efﬁciency by making all possible ‘deterministic’ infer-
ences (using clauses containing just one propositional symbol) before making any
‘nondeterministic’ inference (by exploring both possible truth values of some propo-
sitional symbol, when no more clauses containing just one propositional symbol re-
main. The tableau method to be described in this section generalizes this approach,
ﬁrst to statements in the unquantiﬁed language MLSS discussed earlier, and then to
various extensions of MLSS.
Given an initial set of clauses, the tableau method ﬁnds their consequences tran-
sitively. The strategy used resembles that which we have already seen in the Davis–
Putnam case. The deduction rules used for this are segregated into two classes: those
which act ‘deterministically’ (like the use of a singleton clause in the Davis–Putnam
algorithm), and those which act ‘nondeterministically’ (like the choice of a single-
ton to be given an arbitrary truth-value when there exists no singleton clause in
the Davis–Putnam algorithm). This implicitly assumes that completion of a set of
clauses using only the ﬁrst class of rules will, in polynomial time, generate a rel-
atively small clause set, so that exponentially growing costs will result only from
nondeterministic application of the second, smaller, nondeterministic class of rules.
This makes it reasonable to apply the deterministic rules as long as possible, check-
ing for contradictions which might terminate many paths of expansion before more
than a few nondeterministic rules need to be applied. In this strategy, we only apply
a nondeterministic rule when no deterministic rule remains applicable. This strategy
is also basic to the Davis–Putnam algorithm.
In the case of MLSS, which for convenience we now consider in a version allow-
ing the operators ‘∪’, ‘∩’, ‘\’, {x}, and the relators ‘∈’, ‘⊇’, and ‘=’, we work with
two sets of propositions, one of which collects all currently available propositions
of the forms
x = y, x ⊇y, x ∈y, ¬(x = y), ¬(x ⊇y), ¬(x ∈y),
and the other of which collects all propositions of the forms
x = y ∪z, x = y ∩z, x = y \ z, x = {y}.
Initially these two collections contain propositions representing the set of state-
ments to be tested for satisﬁability. A statement ‘y ∈x’ is added for each statement
‘x = {y}’ initially present.
The initial collections of statements deﬁned in this way are progressively modi-
ﬁed as deductions are made. The deduction process will sometimes proceed deter-
ministically, but sometimes branch nondeterministically, i.e. open a path of explo-
ration which may need to be abandoned if it ends in a contradiction. Only statements
of the form ‘x ∈y’, ‘¬(x ∈y)’, and ‘x = y’ are added in the course of deduction.
However, the variables appearing in some of the other statements may change as

116
3
A Survey of Inference Mechanisms
equalities are deduced. Exploration of a branch fails immediately whenever two di-
rectly opposed statements such as ‘x ∈y’ and ‘¬(x ∈y)’ are detected.
The working of the algorithm can be clariﬁed by considering the way in which
it will build a model of the set of statements with which it is working if one exists.
This is done by examining the collection of all membership relationships ‘x ∈y’
deduced, ﬁrst making sure that this contains no cycles (which are impossible if a
model exists). If this check is passed we assign distinct sets of sufﬁciently large
cardinality to all the variables which do not appear on the right of any deduced
relationship ‘x ∈y’, and then process all the other variables in topologically sorted
order of the membership relation ‘x ∈y’, modelling each y as the collection of all
M (x) for which a statement relationship ‘x ∈y’ has been deduced.
Equality is handled in a special way, which ensures that all statements ‘x = y’
are modelled properly, and that all the operations ‘y ∪z’, ‘y ∩z’, ‘y \ z’ are deﬁned
uniquely by their arguments. Speciﬁcally, whenever ‘x = y’ has been deduced we
choose one of x and y as a representative of the other, all of whose occurrences are
then replaced by occurrences of the representative. This process may identify the
right-hand sides of some statements of the form ‘x = y ∪z’, ‘x = y ∩z’, ‘x = y \z’,
‘x = {y}’; whenever this happens we immediately deduce that the left-hand sides are
also equal. If a model is subsequently found we give each variable replaced in this
way the same value as its representative.
The rules stated below will sometimes introduce new variables. These variables
can only appear in statements of the form ‘x ∈y’ and ‘¬(x ∈y)’, and only on the
left of such statements. It will follow that whenever an equality ‘x = y’ is deduced,
one of x and y must be a variable initially present; in choosing representatives we
always choose such a variable.
For the model-building procedure described above to work, we must be sure
that every statement ‘x ⊇y’, ‘¬(x ⊇y)’, ‘¬(x = y)’, ‘x = y ∪z’, ‘x = y ∩z’,
‘x = y \ z’, and ‘x = {y}’ is properly modelled. To this end, we make the following
deductions:
• ‘x ∈z’ is deduced whenever ‘x ∈y’ and ‘z ⊇y’ are present.
• A new variable x and statements ‘x ∈y’, ‘¬(x ∈z)’ are set up whenever ‘¬(z ⊇
y)’ is present.
• ‘x ∈z’ is deduced whenever ‘x ∈y1’ and ‘z = y1 ∪y2’ are present. Likewise,
‘x ∈z’ is deduced whenever ‘x ∈y2’ and ‘z = y1 ∪y2’ are present. These two
rules ensure that in the model eventually constructed, M (z) is no smaller than
M (y1) ∪M (y2).
• ‘x ∈y1’ and ‘x ∈y2’ are deduced whenever ‘x ∈z’ and ‘z = y1 ∩y2’ are present.
This ensures that in the model eventually constructed, M (z) is no larger than
M (y1) ∩M (y2).
• Whenever the statement ‘x ∈y’ has been deduced, and a statement ‘y = {z}’ is
present, the statement ‘x = z’ is deduced. This ensures that the model of y can
contain at most one element.
• ‘x ∈y1’ and ‘¬(x ∈y2)’ are deduced whenever ‘x ∈z’ and ‘z = y1 \ y2’ are
present. This ensures that in the model eventually constructed, M (z) is no larger
than M (y1) \ M (y2).

3.5
The Tableau Method
117
The set of rules stated above are all deterministic, but a few nondeterministic
rules are required also. These are as follows.
• If ‘x ∈z’ and ‘¬(y ∈z)’ have both been deduced, we deduce an inequality
‘x ̸= y’, setting this up as an alternation ‘(x ̸⊇y) ∨(y ̸⊇x)’. This ensures that
x and y will have different models, implying that all statements ‘¬(y ∈z)’ are
correctly modelled. It is only necessary to do this when both x and y belong to the
collection of variables initially present, since, as previously explained, variables
not in this collection will always be assigned distinct sets as models.
• An alternation ‘x ∈y1∨x ∈y2’, both of whose branches may need to be explored,
is set up whenever ‘x ∈z’ and ‘z = y1 ∪y2’ are present. This ensures that in the
model eventually constructed, M (z) is no larger than M (y1) ∪M (y2).
• Similarly, an alternation ‘x ∈z ∨x /∈y2’ is set up whenever ‘x ∈y1’ and ‘z =
y1 ∩y2’ are present. Likewise an alternation ‘x ∈z ∨x /∈y1’ is set up whenever
‘x ∈y2’ and ‘z = y1 ∩y2’ are present. This ensures that in the model eventually
constructed, M (z) is no smaller than M (y1) ∩M (y2).
• Similarly, an alternation ‘x ∈z ∨x ∈y2’ is set up whenever ‘x ∈y1’ and ‘z =
y1 \ y2’ are present. This ensures that in the model eventually constructed, M (z)
is no smaller than M (y1) \ M (y2).
These rules are sufﬁcient, but to accelerate discovery of contradictions (which
can cut off a branch of exploration before multiple alternations need to be resolved,
an exponentially expensive matter when necessary) all possible deterministic de-
ductions are made. These are:
• ‘x /∈y’ is deduced whenever ‘x /∈z’ and ‘z ⊇y’ are present.
• ‘x /∈y1’ is deduced whenever ‘x /∈z’ and ‘z = y1 ∪y2’ are present.
• ‘x /∈y2’ is deduced whenever ‘x /∈z’ and ‘z = y1 ∪y2’ are present.
• ‘x /∈z’ is deduced whenever ‘x /∈y1’ and ‘z = y1 ∩y2’ are present.
• ‘x /∈z’ is deduced whenever ‘x /∈y2’ and ‘z = y1 ∩y2’ are present.
• ‘x /∈z’ is deduced whenever ‘x /∈y1’ and ‘z = y1 \ y2’ are present.
• ‘x /∈z’ is deduced whenever ‘x ∈y2’ and ‘z = y1 \ y2’ are present.
To further clarify the style of proof discussed above, we consider its application
to the example
¬

{x} = x ∪y

→

x = ∅& y = {x}

which, decomposed propositionally and then initialized in the manner described
above, breaks down into the two cases
z = {x}, x ∈z, z = x ∪y, ¬(x = ∅)
and
z = {x}, x ∈z, z = x ∪y, ¬

y = {x}

.
In the ﬁrst of these two cases we progressively deduce
y′ ∈x, y′ ∈z, y′ = x, x ∈x,

118
3
A Survey of Inference Mechanisms
leading to a contradiction. The second case splits nondeterministically into the two
cases
¬

y ⊇{x}

and
¬

{x} ⊇y

.
In the ﬁrst of these cases we deduce
y′ ∈{x}, ¬(y′ ∈y), y′ ∈z, y′ ∈x, y′ = x , x ∈x,
leading to a contradiction as before. In the second case we deduce
y′ ∈y, ¬

y′ ∈{x}

, ¬(y′ ∈z), y′ ∈z,
leading again to a contradiction and so eliminating the last possible case.
The preceding discussion assumes that the collection of statements with which
we deal has been resolved at the propositional level before the analysis described
begins. However, it may often be better to integrate the propositional and the set-
theoretic levels of exploration, so as to allow the impossibility of a set-theoretic
exploration to rule out a whole family of propositional branches which otherwise
might need to be explored individually before their (predictable) failure became
apparent. This can be done as follows. By introducing additional intermediate vari-
ables we can suppose that all the atomic subformulae of our formulae have simple
forms like x ⊇y, x = y, x ∈y (and their negatives), along with statements like
x = y ∪z, x = y ∩z, x = y \ z, x = {y}. Propositional calculus rules can be used
in the standard way to write all the top-level propositions in our set as disjunctions
like
x ⊇y ∨x = y ∨x ∈y ∨···
(3.19)
in which some of the atoms present may be negated. We now arrange all the propo-
sitions (3.19) in order of increasing number of their atomic parts and work through
them in the following way. Starting with the ﬁrst proposition F , we select its atomic
parts A in order for processing. Each such A is, when selected, added to our col-
lection AP of atomic propositions, where it will remain unless/until the branch of
exploration opened by this addition fails. If such a branch of exploration fails, the
atomic formula A that opened the branch is removed and its negative (which will
now remain permanently) is added to AP. At the same time the next atomic for-
mula A′ after A is selected and added to AP. If there is no such A′, then the branch
of exploration opened by the selection of A fails; if A belongs to the ﬁrst formula
F , then all possibilities have failed and the given set of propositions is unsatisﬁable.
Once a branch of exploration is opened we make all possible deterministic and
nondeterministic deductions from it, in the manner described above. Eventually ei-
ther the branch will fail, or run out of deductions to make. In the latter case we
examine all the formulae (3.19) following the F containing the A that opened the
current branch of exploration. Formulae containing atoms B present in our deduced
collection of atoms are bypassed (since they must be satisﬁed already, and so tell us
nothing new). The negatives of all such B are removed from the formulae still to be
processed (since these propositions are known to be false; note that this duplicates

3.5
The Tableau Method
119
a deterministic deduction step of the Davis–Putnam algorithm). If any one of these
formulae is thereby made null, the branch of exploration opened by A fails. Other-
wise the formulae following F are rearranged in order of increasing number of their
remaining atomic parts, and we move on to select an atomic subformula of the next
formula F ′ following F .
We illustrate this integrated style of proof, again using the example
¬

{x} = x ∪y

→

x = ∅& y = {x}

whose negative is now expressed as the following set of three clauses
z = {x}, x ∈z, z = x ∪y,

¬(x = ∅) ∨¬(y = z)

.
A branch of exploration is opened by adding ‘¬(c = ∅)’ to the ﬁrst three clauses,
giving the deductions
z = {x}, x ∈z, z = x ∪y, ¬(y = ∅), y′ ∈x, y′ ∈z, y′ = x, x ∈x
which fails. The alternate path then begins with
z = {x}, x ∈z, z = x ∪y, x = ∅,

¬(y ⊇z)

∨

¬(z ⊇y)

,
from which we deduce
z = {x}, x ∈z, z = x ∪y, x = ∅,

¬(y ⊇z)

∨

¬(z ⊇y)

, z = y,
and so
z = {x}, x ∈z, x = ∅, ¬(z ⊇z), y′ ∈z, ¬

y′ ∈z

,
which fails, conﬁrming the validity of our original formula.
Tableau-based proof approaches have the interesting property that if they are
sound, and even if they are not complete (so that there can exist contradictory sets
of clauses which they are not able to extend to an obvious contradiction), any fam-
ily of statements found to be contradictory because all branches of exploration fail
really is unsatisﬁable. This is because the tableau method implicitly makes and then
discharges a sequence of suppositions, every one of which has led to a contradic-
tion. So systems of tableau rules can be used even if they are incomplete as long as
they converge, and, as a matter of fact, can be used in any individual case whose
exploration does terminate, even if the system does not terminate for every possible
input. All that is necessary is that such systems should be sound. Therefore if we use
a ﬁxed, table-driven tableau code, we can be certain of the rigor of its deductions
as long as we know that all rules entered into each driving table are sound. This
will necessarily be the case if all such rules are instances of universally quantiﬁed,
previously proved theorems. For example, once cons, car, and cdr have been given
their set-theoretic deﬁnitions and it has been proved that

∀x,y,u,v
[x, y][1] = x & [x, y][2] = y &

[x, y] = [u, v]

→(x = u & y = v)


120
3
A Survey of Inference Mechanisms
we can be sure that the tableau rules derived from this statement are sound, and so
we can add them to the table driving a generic tableau code.
A tableau-based proof approach which is sound but not complete can be regarded
as a mechanism for searching, not all, but only certain possible lines of argument,
namely those deﬁned by its set of saturation and fulﬁlling rules. If we believe that a
proof can result along these lines, this is a good way of searching for it.
3.6 Elementary Booleans Plus Map Primitives
Next we consider another unquantiﬁed generalization of the elementary Boolean
language of sets with which we started in Sect. 3.2. This introduces variables desig-
nating maps between sets, which to ensure decidability we treat here as objects of
a kind different from sets, designated by variables of a syntactically different, rec-
ognizable kind. (For convenience we will write set variables as letters x,y,z, etc.,
taken from the initial part of the alphabet, and designate maps by letters like f,g.)
In addition to the elementary Booleans operators and comparators, the unquantiﬁed
language we now wish to consider allows the map primitives
f = g, range(f ) = x, domain(f ) = x, f|x = g (map restriction),
Svm(f ) (f is a single-valued map), and
Singinv(f ) (f is the inverse of a single-valued map).
We will show that this language is decidable by reducing collections of statements
in it to equisatisﬁable collections of statements in which all variables designating
maps, and all map-related operations, have been removed. As usual, we begin by
applying decomposition at the propositional level, and then secondary decomposi-
tion, to the collection of statements originally given us. This means that we have
only to deal with collections C of statements each having one of the allowed ele-
mentary forms
x = y ∪z, x = y, ¬(x = y), range(f ) = x, domain(f ) = x, f|x = g,
f = g, ¬(f = g), Svm(f ), ¬Svm(f ), Singinv(f ), ¬Singinv(f ).
Now we proceed as follows.
(i) All equalities between sets or between maps are removed by selecting a repre-
sentative of any group of set or map variables known to be equal, and replacing
each occurrence of a variable in the group by its selected representative.
(ii) We replace each statement ¬(f = g) by a statement of the form
¬

range(f|xnew) = range(g|xnew)

.
This reﬂects the fact that if two maps are different, there must exist a set s on
which their ranges are different. (For example, this can be a singleton whose
one member either belongs to the domain of one of the maps but not the other,
or to both domains, but at which the functions have different values.)

3.6
Elementary Booleans Plus Map Primitives
121
(iii) All the map-related statements which remain at the end of step (ii) have one of
the forms
range(f ) = x, domain(f ) = x, f|x = g,
Svm(f ), ¬Svm(f ), Singinv(f ), ¬Singinv(f ).
We now proceed in the following way to eliminate all statements of the form
f|x = g. We enumerate all the set variables x1,...,xk which appear in state-
ments of the form f|x = g, and form the collection of all their ‘Venn pieces’.
These ‘Venn pieces’ are newly introduced symbols Vi1,...,ik for all intersections
of the sets xj or their complements, with the obvious relationships deﬁning the
Vi1,...,ik in terms of the sets xj and vice versa. More speciﬁcally, the subscripts
i1,...,ik of the Venn pieces are all possible sequences of 0’s and 1’s of length
k (which we also denote by I, to enhance readability), distinct Venn pieces are
disjoint, and each xj is the union of all the Venn pieces
Vi1,...,ij−1,1,ij+1,...,ik,
for i1,...,ij−1,ij+1,...,ik ranging over {0,1}.
Next we introduce the ‘Venn pieces’ of the maps f . These are symbols fI
for all restrictions f|VI , for I ranging over the collection {0,1}k of binary k-
tuples. We also introduce symbols rf
I and df
I for their ranges and domains,
respectively, and statements expressing each f|xj in terms of these rf
I and df
I .
More speciﬁcally, for each symbol fI , with I ∈{0,1}k, we add the state-
ments
rf
I ̸= ∅↔df
I ̸= ∅
and
df
I ⊆VI.
Additionally, for each relationship f|xj = g we add the statements
rf
I = rg
I ,
df
I = dg
I ,
and
fI = gI,
for all binary k-tuples I whose jth component is equal to 1, and the statements
rg
J = ∅
and
dg
J = ∅,
for all binary k-tuples J whose jth component is equal to 0.
Then we drop all statements of the form f|x = g and eliminate all simple
equalities fI = gI by closing them transitively and choosing a representative
of each class.
(iv) Statements of the forms range(f ) = x and domain(f ) = x can be eliminated
as follows. For each statement range(f ) = x, we add the statement
rf
I1 ∪··· ∪rf
IN = x,
where I1,...,IN are all binary k-tuples. Likewise, for each statement
domain(f ) = x we add the statement
df
I1 ∪··· ∪df
IN = x.

122
3
A Survey of Inference Mechanisms
Then we drop all statements of type range(f ) = x and domain(f ) = x.
(v) Let C′ be the resulting collection of statements. If C′ has a model M so does
the original C (ignoring statements Svm(f ) and Singinv(f ), and their nega-
tions) since we can construct the M (fI) as either single-valued or non-single-
valued maps (having single-valued or non-single-valued inverse) of each non-
null M (df
I ) onto the corresponding M (rf
I ), making all these sets countable.
To model a collection of statements Svm(f ) and ¬Svm(f ) we need only
assign a truth value to each condition Svm(fI), insisting that Svm(f ) be equiv-
alent to the conjunction of all the statements Svm(fI), extended over all the
Venn pieces of f .
To model a collection of statements Singinv(f ) and ¬Singinv(f ) we must
add conditions rf
I ∩rf
J = ∅for each clause Singinv(f ) and for all the distinct
pieces rf
I into which each original range(f ) is decomposed, since then the
union map of the Venn pieces fI of f can have a single-valued inverse or not,
as desired. We must also assign a truth value to each condition Singinv(fI),
and insist that Singinv(f ) be equivalent to the conjunction of all the statements
Singinv(fI), extended over all the Venn pieces of f .
3.7 Various Commonly Occurring Decidable Extensions
of MLSS
The decision algorithm for MLSS presented in Sect. 3.3 can be extended in useful
ways by allowing otherwise uninterpreted function symbols subject to certain uni-
versally quantiﬁed statements to be intermixed with the other operators of MLSS.
Note, however, that the statements decided by the method to be described remain
unquantiﬁed; the quantiﬁed statements to which we refer appear only as implicit
‘side conditions’.
The ‘pairing’ operator ‘cons’ and the two associated component extraction op-
erators ‘car’ and ‘cdr’ exemplify the operator families to which our extension
technique is applicable. As noted earlier, these operators can be given formal set-
theoretic deﬁnitions:
[x, y] :=

{x},

{x},

{y},y

,
p[1] := arb

arb(p)

,
p[2] := arb

arb

arb

p \

arb(p)

\

arb(p)

.
However, in most settings, the details of these deﬁnitions are irrelevant. Only the
following properties of these operators matter:
• The object [x, y] can be formed for any two sets x,y.
• Both of the sets x,y from which [x, y] is formed can be recovered uniquely from
the single object [x, y], since [x, y][1] = x and [x, y][2] = y.

3.7
Various Commonly Occurring Decidable Extensions of MLSS
123
Almost all proofs in which the operators ‘cons’, ‘car’, and ‘cdr’ appear use only
these facts about this triple of operators. That is, they implicitly treat these operators
as a family of three otherwise uninterpreted operators, subject only to the conditions

∀x,y
 [x, y][1] = x

&

∀x,y
 [x, y][2] = y

.
The treatment of ‘cons’, ‘car’, and ‘cdr’ throws away information about these op-
erators (e.g. [x, y] has cardinality 2 and x[1] is always a member of a member of
x) that may become relevant in unusual situations, but this very rarely makes any
difference.
Even though the underlying deﬁnitions are not always so strongly irrelevant as in
the case of ‘cons’, ‘car’, and ‘cdr’, similar remarks apply to many other important
families of operators. We list some of these, along with the universally quantiﬁed
statements associated with them:
(i) arb:

∀x
 
x = ∅& arb(x) = ∅

∨

arb(x) ∈x & arb(x) ∩x = ∅

;
(ii) pairs of mutually inverse functions on a set w:

∀x ∈w | f (x) ∈w & g(x) ∈w & f

g(x)

= x & g

f (x)

= x

;
(iii) monotone functions:

∀x,y | (x ⊇y) →

f (x) ⊇f (y)

;
(iv) monotone functions having a known order relationship:

∀x,y | (x ⊇y) →

f (x) ⊇f (y)

&

∀x,y | (x ⊇y) →

g(x) ⊇g(y)

&

∀x | f (x) ⊇g(x)

;
(v) monotone functions of several variables:

∀x,y,u,v | (x ⊇y & u ⊇v) →

f (x,u) ⊇f (y,v)

;
(vi) idempotent functions on a set w:

∀x ∈w | f (x) ∈w & f

f (x)

= f (x)

;
(vii) self-inverse functions on a set:

∀x ∈w | f (x) ∈w & f

f (x)

= x

;
(viii) total ordering relationships on a set:

∀x ∈w, y ∈w
 
R(x,y) ∨R(y,x)

& R(x,x)

&

∀x ∈w, y ∈w, z ∈w
 
R(x,y) & R(y,z)

→R(x,z)

;

124
3
A Survey of Inference Mechanisms
(ix) (multiple) functions with known ranges wj and domains vj:

∀x ∈vj | fj(x) ∈wj

,
for multiple indices j and k.
These are all mathematically signiﬁcant relationships, as the existence of names
associated with them attests.
These cases can all be handled by a common method under the following condi-
tions. Suppose that we are given an unquantiﬁed collection C of statements involv-
ing the operators of MLSS plus certain other function symbols f , g of various num-
bers of arguments. After decomposing compound terms in the manner described
earlier, we can suppose that all occurrences of these additional symbols are in sim-
ple statements of forms like
y = f (x), y = g(x,z), etc.
From these initially given statements we must be able to draw a ‘complete’ collec-
tion S of consequences, involving the variables which appear in them, along with
some ﬁnite number of additional variables that it may be necessary to introduce. The
resulting collection of formulae, comprising S and some ‘residue’ of the original C,
will be entirely within the language of MLSS. ‘Completeness’ means that any model
of the translated formula can be extended to include the original function symbols
f , g, etc. in such a way that their interpretation M (f ), M (g), etc. actually satisﬁes
the desired properties (monotonicity, etc.).
In all cases listed above, S will include at least single-valuedness conditions
x = u →y = v
for all pairs y = f (x), v = f (u) originally present in C, so S will consist of these
statements plus others appropriate to the case being considered, as detailed below.
Call these added statements S the extension conditions for the given set of func-
tions. We must ﬁnd extension conditions comprising S which encapsulate every-
thing which the appearance of the functions in question tells us about the set vari-
ables which also appear.
If extension conditions can be found, satisﬁability can be determined by replac-
ing all the statements y = f (x), y = g(x,z) in our original collection by the exten-
sion conditions derived from them.
This gives us a systematic way of reducing various languages extending MLSS
to pure MLSS. As we will see, this approach can be exploited, to some extent, with
predicates too, thanks to the fact that certain properties of predicates can be repre-
sented using associated functions.
Note that this ‘extension conditions’ technique can be applied even if the recipe
for removing universal quantiﬁers by adding compensating extension clauses is not
complete, as long as it is sound, i.e. all the clauses added do follow from known
properties of the functions or predicates removed.

3.7
Various Commonly Occurring Decidable Extensions of MLSS
125
Take Case (iii) above (the ‘monotone functions’ case) as an example. Here the
extension conditions can be derived as follows. Let the function symbols known
to designate monotone functions be f , etc. Replace all the statements y = f (x),
v = f (u) originally present by statements
x ⊇u →y ⊇v.
(3.20)
(Note that this implies the single-valuedness condition for f .) The added clauses
ensure that if a model M exists, the set of pairs [M (x),M (y)], formed for all
the x and y initially appearing in clauses y = f (x), deﬁnes a function F which is
monotone on its domain. This can be extended to a function F ′ deﬁned everywhere
by deﬁning F ′(s) as the union of all the F(t), extended over all the elements t of
the domain of F for which s ⊇t. It is clear that the F ′ deﬁned in this way is also
monotone and extends F . This proves that the clauses (3.20) express the proper
extension condition in Case (iii). Note that the number of clauses (3.20) required is
roughly as large as the square of the number of clauses y = f (x) originally present.
To make this method of proof entirely clear we give an example. Suppose that
we need to prove the implication
f

f (x ∪y)

⊇f

f (x)

(3.21)
under the assumption that the function f is monotone. By decomposing the com-
pound terms which appear in this statement, we get the collection
z = x ∪y,
u = f (z),
w = f (u),
u′ = f (x),
v′ = f (u′),
¬(w ⊇v′),
which we must prove to be unsatisﬁable. The four statements
u = f (z),
w = f (u),
u′ = f (x),
v′ = f (u′)
in this collection give rise to the 12 extension conditions
(z ⊇u) →(u ⊇w),
(u ⊇z) →(w ⊇u),
(z ⊇x) →(u ⊇u′),
(x ⊇z) →(u′ ⊇u),
(z ⊇u′) →(u ⊇v′),
(u′ ⊇z) →(v′ ⊇u),
(u ⊇x) →(w ⊇u′),
(x ⊇u) →(u′ ⊇w),
(u ⊇u′) →(w ⊇v′),
(u′ ⊇u) →(v′ ⊇w),
(x ⊇u′) →(u′ ⊇v′),
(u′ ⊇x) →(v′ ⊇u′),
which replace the four initial statements. It now becomes possible to see that
z = x ∪y,
(z ⊇x) →(u ⊇u′),
(u ⊇u′) →(w ⊇v′),
¬(w ⊇v′)
is an unsatisﬁable conjunction, proving the validity of (3.21).

126
3
A Survey of Inference Mechanisms
3.7.1 Extension Conditions in the Other Cases Listed Above
We shall now describe the extension conditions applicable in the remaining cases
listed above. In Case (i) (the arb case) the extension conditions are simply

x = ∅& arb(x) = ∅

∨

arb(x) ∈x & arb(x) ∩x = ∅

&

x = u →arb(x) = arb(u)

.
(3.22)
(This last clause is the condition of ‘single-valued functional dependence’.) Suppose
now that M is a model of a collection of MLSS clauses, plus statements of the form
x = arb(y), after ﬁrst replacing all the y = arb(x), v = arb(u) originally given by
the derived clauses
(x = ∅& y = ∅) ∨(y ∈x & y ∩x = ∅) & (x = u →y = v).
Then plainly the set of pairs [M (x),M (y)], formed for all the x and y appearing
in the statements ‘y = arb(x)’ originally present, deﬁnes a single-valued function A
on its ﬁnite domain which satisﬁes

s = ∅& A(s) = ∅

∨

A(s) ∈s & A(s) ∩s = ∅

,
for all the elements of its domain. We can extend this to a function A′ deﬁned ev-
erywhere by writing
A′(s) = if s ∈domain(A) then A(s) else arb(s) end if ,
where arb is the built-in choice operator of our version of set theory. A′ then satisﬁes
the originally universally quantiﬁed condition for arb, verifying our claim that the
clauses (3.22) are the proper extension conditions.
Case (iv) (monotone functions having a known order relationship) can be treated
in much the same way as the somewhat simpler case (iii) discussed above. Given
two such functions f , g, where it is known that f (x) ⊇g(x) is universally true,
ﬁrst force the known part of their domains to be equal by introducing a u satisfying
g(x) = u for each initially given clause f (x) = y and vice versa. Then proceed as
in case (iii), but now add inclusions
x = v →y ⊇u
for every pair g(v) = u, f (x) = y of clauses present. It is clear that the extensions
of g and f deﬁned in our discussion of the simpler case (iii) stand in the proper
ordering relationship.
Case (v) (monotone functions of several variables) is also easy. We can proceed
as follows. Given a function f (x,y) which is to be monotone in both its variables,
and also a set of clauses like z = f (x,y), w = f (u,v), introduce clauses
(x ⊇u & y ⊇v) →(z ⊇w).

3.7
Various Commonly Occurring Decidable Extensions of MLSS
127
As above, let M be a model for our set of clauses. Then plainly the set of pairs
[[M (x),M (y)],M (z)], formed for all the x,y,z initially appearing in clauses z =
f (x,y), deﬁnes a function F of two arguments which is monotone on its domain.
This can be extended to a function F ′ deﬁned everywhere by deﬁning F ′(s,t) as
the union of all the F(p,q), extended over all the pairs p,q of the domain of F for
which s ⊇p and t ⊇q.
The related case of additive functions of a set variable can also be treated in the
way which we will now explain (but the very many clauses which this technique
introduces hints that ‘additivity’ is a signiﬁcantly harder case than ‘monotonicity’).
A set-valued function f of sets is called ‘additive’ if
f (x ∪y) = f (x) ∪f (y)
for all x and y. Given an otherwise uninterpreted function f which is supposed to be
additive, and clauses y = f (x), introduce all the ‘atomic parts’ of all the variables x
which appear in such clauses. These are variables representing all the intersections
of some of these sets x with the complements of the other sets x. In terms of these
intersections, which clearly are all disjoint, express each x in terms of its atomic
parts, namely as
x = aj1 ∪··· ∪ajk.
Likewise, after introducing clauses bj = f (aj) giving names to the range elements
f (aj), write out all the relationships
y = bj1 ∪··· ∪bjk
that derive from clauses y = f (x). Finally, writing ∅and f (∅) for uniformity as a0
and b0, add statements
aj = a0 →bj = b0
and
b0 ⊆bj,
along with statements
aj ∩ai = ∅
(with i ̸= j)
which express the disjointness of distinct sets aj. Now suppose that the set of clauses
we have written has a model M in which the aj, bj, x, y, etc. appearing above are
represented by sets aj, bj, x, y, etc. and for each s, deﬁne the set-valued function
F(s) to be the union of all the sets bj for which s intersects aj. The function F
deﬁned in this way is clearly additive. It is also clear that if a clause y = f (x) is
present in our initial collection, and the variables x and y are represented by sets x
and y, then y = F(x). Hence F can represent f in the model we have constructed,
so f can be represented by an additive function, proving that the clauses we have
added to our original collection are the appropriate extension conditions.
Cases (vi) (idempotent functions on a set) and (vii) (self-inverse functions on
a set) are also easy. In the case of idempotent function we can proceed as before,

128
3
A Survey of Inference Mechanisms
but adding a clause y = f (y) whenever a clause y = f (x) is present. Then we add
implications
w = x →z = y
whenever two clauses y = f (x), z = f (w) are present, and remove all the clauses
y = f (x). The added clauses ensure that if a model M exists, the mapping F which
sends M (x) to M (y) for each clause y = f (y) initially present is single-valued,
and since a clause
y = f (y)
has been added whenever a clause y = f (x) is present this mapping is clearly idem-
potent where deﬁned. It can be extended by mapping all elements not in the domain
of F to any selected element of the range of F .
The self-inverse function case (vii) can be handled in much the same way. Here
one adds a clause
x = f (y)
whenever the clause y = f (x) is present, and then adds all the implications needed
to force a model of the pairs [x, y] deriving from clauses y = f (x) initially present
to deﬁne a single-valued map which can model the original f . If a model M exists
for the resulting set of clauses, the model F of f is self-inverse on its domain, which
is the same as its range. F can then be extended to a mapping deﬁned for all s by
writing f (s) = s for all elements not in its domain/range.
Predicates representable by functions in one of the classes analyzed above can be
removed automatically by ﬁrst replacing them by the functions that represent them,
and then removing these functions by writing the appropriate extension conditions.
For example, equivalence relationships R(x,y) can be written as f (x) = f (y) using
a representing function f ; f only needs to be single-valued. Partial ordering rela-
tionships can be written as f (x) ⊇f (y) where f only needs to be single-valued.
f is monotone iff the ordering relationship R(x,y) is compatible with inclusion, in
the sense that

∀x,y | (x ⊇y) →R(x,y)

.
Monadic predicates P(x) satisfying the condition

∀x,y
 
P(x) & P(y)

→P(x ∪y)

&

∀x,y
 
P(x) & x ⊇y

→P(y)

can be written in the form P(x) ↔(p ⊇x). The predicates Finite(x), Countable(x),
and Is_map(x) illustrate this remark.
Case (viii) (total ordering relationships on a set) can be handled in the following
way, which derives from the preceding remarks. Let R be such a relationship. Intro-
duce a representing function f for it, i.e. f (x) ⊇f (y) ↔R(x,y). Then R is a total
ordering iff the range elements f (x) all belong to a collection of sets totally ordered
by inclusion. So write a clause
y ⊇v ∨v ⊇y

3.7
Various Commonly Occurring Decidable Extensions of MLSS
129
for each pair of clauses y = f (x), v = f (u), and also write the conditions needed to
ensure that f is single-valued. If a model M exists for the resulting set of clauses,
the model F of f plainly maps its domain into a collection of sets totally ordered
by inclusion, and then F can be extended to all other sets by sending them to ∅.
Case (ix) (multiple functions with known ranges and domains) is also very easy.
For clarity, we will consider the special subcase of this in which two functions f ,
g are given, along with two domain sets d1, d2, and two range sets r1, r2. The
universally quantiﬁed conditions which must be satisﬁed are

∀x ∈d1 | f (x) ∈r1

,
(3.23)

∀x ∈d2 | g(x) ∈r2

,
(3.24)
along with some collection of unquantiﬁed clauses of MLSS.
We proceed as follows. For any two clauses y = f (x), y′ = f (x′) present in our
set C of clauses write a condition
x = x′ →y′ = y′,
(3.25)
and similarly for g. As usual, these reﬂect the single-valuedness of f and g. For any
clause y = f (x) in C, write a condition
x ∈d1 →y ∈r1,
(3.26)
and similarly for g, d2, and r2. Finally, write the conditions
d1 ̸= ∅→r1 ̸= ∅,
d2 ̸= ∅→r2 ̸= ∅.
(3.27)
Then seek a model of the resulting set S of clauses, which must plainly exist if our
original set C of clauses is consistent.
Conversely, suppose that the clauses S have a model M . Deﬁne a preliminary
function F (resp. G) as the set of all pairs [M (x),M (y)] for which a clause
y = f (x) (resp. y = g(x)) is present in C. The clauses (3.25) plainly imply that F
is single-valued on its domain, and the clauses (3.26) ensure that F maps the inter-
section of its domain with d1 into r1. If M (d1) = ∅, the quantiﬁed condition (3.23)
is automatically satisﬁed. If M (d1) ̸= ∅, the clause (3.27) ensures that Mr1 ̸= ∅, so
we can extend F to map all elements of d1 not in its initial domain to any element of
r1 we choose. Repeating this construction for g, d2, and r2 plainly gives us a model
of all our clauses in which f and g are represented by single-valued functions satis-
fying (3.23) and (3.24). Hence the clauses (3.25), (3.26), and (3.27) we have added
are the extension conditions we require.
3.7.2 The Case of Mutually Inverse Functions
Extension conditions for Case (ii) (pairs of mutually inverse functions f , g on a set
w) can be formulated as follows. Write the clauses, described above, that force f

130
3
A Survey of Inference Mechanisms
and g to be single-valued. To these, add clauses
y = v →x = u
derived from all the given statements y = f (x),v = f (u). These force f to be 1-1
on the collection of elements x known to be in its domain. (Note that this much also
handles the case of functions known to be 1-1.) Do the same thing for g. Then add
clauses
y = u ↔x = v
derived from all the statement pairs y = f (x), v = g(u). Then, in the resulting
model M , the model functions F and G of f and g must both be 1-1 on their
domains (e.g. for F this is the collection of sets M (x) modelling points x for which
some clause y = f (x) appears in our original set of statements), and G must be the
inverse of F on domain(G) ∩range(F). Since G is 1-1 on its domain, it follows
that the range of G on domain(G) \ range(F) must be disjoint from domain(F).
Indeed, if a set s is in domain(F) ∩range(G) it must have the form s = M (x)
where clauses y = f (x) and v = g(u) both appear in our original set of statements.
But then M (u) = M (y) is implied by an added clause, and hence M (u) is in the
range of F . Similarly the range of F on domain(F) \ range(G) must be disjoint
from domain(G). F can therefore be extended to
range(G|domain(G)\range(F))
(the range on the restriction) as the inverse of G, and similarly G extended to
range(F|domain(F)\range(G))
as the inverse of F . Let F ′ and G′ be these extensions. Then plainly domain(F ′) =
domain(F) ∪range(G), and so range(G′) = range(G) ∪domain(F) = domain(F ′)
and vice versa. Hence the extensions F ′ and G′ are mutually inverse with
domain(F ′) = range(G′) and vice versa. F ′ and G′ can now be extended to mu-
tually inverse maps deﬁned everywhere by using any 1-1 map of the complement of
domain(F ′) onto the complement of range(F ′). This shows that the clauses listed
above are the correct extension conditions for case (ii).
The extension conditions for the important car, cdr, and cons case can be worked
out in similar fashion as follows. Regard [x, y] as a family of one-parameter func-
tions consx(y) dependent on the subsidiary parameter x. The ranges of all the
functions consx in the family are disjoint (since [x, y] can never equal [u, v]
if x ̸= u). For the same reason, each consx is 1-1, and cdr is its (left) inverse,
i.e. consx(y)[2] = y. Also, consx(y)[1] = x everywhere. The extension conditions
needed can then be stated as follows:
(i) ‘cons’ must be ‘doubly 1-1’ and well deﬁned: add clauses

(x = u) & (y = v)

↔(z = w)
derived from all pairs of initial clauses z = [x, y],w = [u, v].

3.8
More Examples of Decidable Sublanguages
131
(ii) ‘car’ and ‘cdr’ must stand in the proper inverse relationship to ‘cons’: add
clauses
u = z →x = v
derived from all pairs z = [x, y], v = u[1], and all clauses
u = z →y = v
derived from all pairs z = [x, y], v = u[2] of initial statements.
Various other cases which can be handled by the ‘extension conditions’ tech-
nique, e.g. uninterpreted commutative functions of two variables, having the prop-
erty

∀x,y | f (x,y) = f (y,x)

,
can readily be handled by this technique. It might be possible to treat associativity
also, possibly based on a prior MLSS-like theory of the concatenation operator.
Quite a number of decidable extensions of multilevel syllogistic have been
treated in [CFO89, COP01].
3.8 More Examples of Decidable Sublanguages
3.8.1 Presburger’s Decidable Quantiﬁed Language of Additive
Arithmetic
In [Pre30], Moj˙zesz Presburger showed that the language of quantiﬁed statements
whose variables all represent integers, and in which the only operations allowed are
arithmetic addition and subtraction and the comparators n > m and n ⩾m, has a
decidable satisﬁability problem. (We will see in Chap. 6 that if the multiplication
operator is added to this mix, the class of formulae that results admits of no algo-
rithm for testing satisﬁability.)
The technique used by Presburger is progressive elimination of quantiﬁers by
replacement of existentially quantiﬁed set expressions by equivalent unquantiﬁed
expressions of the same kind. This method of ‘quantiﬁer elimination’ applies to a
language L if, given any formula

∃x | P(x)

(3.28)
formed using just one quantiﬁer, together with the operators allowed by the lan-
guage, also the bound variable x and various free variables a1,...,an, we can ﬁnd
an equivalent unquantiﬁed formula of the language, involving only the free variables
a1,...,an, which is equivalent to (3.28). Note that universally quantiﬁed subformu-
lae can always be reduced to existentially quantiﬁed form by use of the de Morgan
rule

∀x | P(x)

↔

¬

∃x | ¬P(x)

.

132
3
A Survey of Inference Mechanisms
If an unquantiﬁed formula equivalent to (3.28) always exists, we can work system-
atically through the syntax tree of any formula, from bottom to top, replacing all
quantiﬁed subformulae with equivalent unquantiﬁed formulae, until no quantiﬁers
remain. For (3.28) to be equivalent to an unquantiﬁed formula of the language L, it
may be necessary to enlarge L by adding some ﬁnite collection of supplementary
operators and predicates. If quantiﬁcation à la (3.28) of formulae written using every
such operator collection requires the introduction of still more operators, quantiﬁer
elimination will fail; otherwise it can be applied.
A typical means of re-expressing (3.28) in unquantiﬁed form is to show that
if (3.28) has a solution at all, some one of a ﬁnite collection of unquantiﬁed ex-
pressions e1,...,ek (‘canonical solutions’) written in terms of the free variables of
(3.28) must be a solution. This allows (3.28) to be rewritten as the disjunction
P(e1) ∨··· ∨P(ek),
in which the quantiﬁed variable x has been eliminated.
To apply these ideas to the Presburger language of additive arithmetic formulae
described above, we need to introduce one additional operator into the language.
This is the divisibility operator, which we will write in the next few paragraphs
as c |n. In such expressions c will always be a positive integer constant, and n an
integer-valued variable or expression.
In considering ‘innermost’ existentially quantiﬁed Presburger-formulae

∃n| P(n)

(that is, quantiﬁed formulae not containing any quantiﬁed subformulae) we can ex-
pand the (unquantiﬁed) ‘body’ P(x) into a disjunction of conjunctions, and then use
the predicate rule

∃x | P(x) ∨Q(x)

↔

∃x | P(x)

∨

∃x | Q(x)

to move the existential quantiﬁer in over the ‘∨’ operators. In the resulting formulae
each P is a conjunction of literals. These, in view of the equivalences
(ak · n > Ak) ↔(ak · n ⩾Ak + 1)
¬

ck |(dk · n + Ck)

↔
ck−1

j=1

ck |(dk · n + Ck + j)

,
can therefore be written as

∃n

I
&
k=1(ak · n ⩾Ak) &
J
&
k=1(bk · n ⩽Bk) &
L
&
k=1

ck |(dk · n + Ck)


,
(3.29)

3.8
More Examples of Decidable Sublanguages
133
where the ak, bk, ck, and dk are positive integer constants, ‘·’ and ‘+’ designate in-
teger multiplication and addition, respectively,3 and Ak, Bk, and Ck are well-formed
Presburger terms not containing n.
Suppose for the sake of deﬁniteness that I > 0 in (3.29), and that (3.29) admits
a solution m. Then among these solutions, all of which exceed the largest among
the quotients Ak/ak, there must exist a smallest m0. This m0 will have the form
(Ai + j)/ai, for some i and some non-negative integer j. Let c′
k denote the quotient
ck/GCD(ck,dk), for k = 1,...,L. Since m0 is smallest, it must be impossible to
subtract any multiple of ℓi = ai ·lcm(c′
1,...,c′
L) from j and still have a non-negative
integer. Hence
0 ⩽j < ℓi,
so that
m0 ∈

(Ai + j)/ai : 1 ⩽i ⩽I, 0 ⩽j < ℓi

.
Thus (3.29) is equivalent to the following ﬁnite disjunction:
I
i=1
ℓi−1

j=0
 I
&
k=1

ak · (Ai + j) ⩾ai · Ak

&
J
&
k=1

bk · (Ai + j) ⩽ai · Bk

&
L
&
k=1

ai · ck |dk · (Ai + j) + ai · Ck

& (ai |Ai + j) & (Ai + j ⩾0)

.
(3.30)
Note that (3.30) has substantially the same form as (3.29), but has one less existential
quantiﬁer. In passing from (3.29) to (3.30) we have essentially ‘solved’ for n:
“n is (ai + j)/ai, where (3.30) serves to locate i andj within the ﬁnite set

[i, j]: 1 ⩽i ⩽I,0 ⩽j < Li

.”
The case I = 0 can be reduced to the previous one, by pretending that the trivially
true conjunct n ⩾0 is present. This corresponds to letting I = 1, a1 = 1, A1 = 0,
and ℓ1 = lcm(c′
1,...,c′
L), so that (3.30) simpliﬁes to
ℓ1−1

j=0
 J
&
k=1(bk · j ⩽Bk) &
L
&
k=1

ck |dk · j + Ck


.
Decidability of the satisﬁability problem for Presburger’s language of quantiﬁed
purely additive arithmetic now follows in the manner explained above.
3Notice that in the context of additive arithmetic, integer multiplication is admitted only in terms
of the form c · A, where c is a positive integer constant and A is a well-formed Presburger term;
thus c · A can be considered as a short for A + ··· + A



c times
.

134
3
A Survey of Inference Mechanisms
3.8.2 A Decidable Quantiﬁed Theory Involving Ordinals
Various interesting algebraic operations can be deﬁned on the collection of all ordi-
nals, in the following way. A set s is said to be well-ordered if it is ordered by some
ordering relationship x > y for which x > y is incompatible both with x = y and
y > x, and which is such that every nonempty subset t of s contains a smallest ele-
ment x, which we can write as Smallest(t). Given a well-ordered set s, if we make
the recursive deﬁnition
Enu(x) =Def if s ⊆

Enu(y): y ∈x

then s
else Smallest

s \

Enu(y): y ∈x

end if ,
it is not hard to see that for any two ordinals x and y we have
(x ⊋y) →Enu(x) > Enu(y) ∨s ∪{s} =

Enu(z): z ∈x

,
and from this then Enu, restricted to the inverse image of s, is a one-to-one, order-
preserving mapping of some unique ordinal α onto s (where, as usual, ordinals are
ordered by inclusion, or, equivalently, membership). The ordinal α derived from s
in this way is called the order type of s, and it can easily be seen that
α = Min

β ∈Ord| s ⊆

Enu(y): y ∈β

.
The algebraic operations alluded to above are then deﬁned by forming various well-
ordered sets from pairs of ordinals and taking the order types of these sets.
Perhaps the easiest case is that of the Cartesian product {[x, y]:x ∈α1, y ∈α2 },
with α1 and α2 ordinal numbers, which can be ordered lexicographically. The order
type of this product is the so-called ordinal product, which we will write as α1 ∗o α2.
In much the same way we can order the set

[x1, x2,...,xk]: x1 ∈α1, x2 ∈α2, ..., xk ∈αk

of k-tuples lexicographically, thereby deﬁning the k-fold ordinal product
α1 ∗o α2 ∗o ··· ∗o αk,
where α1,α2,...,αk are ordinal numbers. Since there is an evident order isomor-
phism (i.e. 1-1, order-preserving map) between α1 ∗o α2 ∗o α3 and each of the or-
dered sets

[y,x3]: y ∈α1 ∗o α2, x3 ∈α3

and

[x1, z]: x1 ∈α1, z ∈α2 ∗o α3

,
it follows that ordinal multiplication satisﬁes the associative law
(α1 ∗o α2) ∗o α3 = α1 ∗o (α2 ∗o α3).

3.8
More Examples of Decidable Sublanguages
135
Given any two ordinals α1 and α2, we can form a well-ordered set by ordering
the collection

[0, x]: x ∈α1

∪

[1, y]: y ∈α2

of pairs lexicographically. The order type of this set is called the ordinal sum of
α1 and α2, which we will write as α1 +o α2. The k-fold ordinal sum α1 +o α2 +o
··· +o αk of k ordinal numbers α1,α2,...,αk can be deﬁned as the order type of
the set of pairs

[0, x]: x ∈α1

∪

[1, x]: x ∈α2

∪··· ∪

[k −1, x]: x ∈αk

,
ordered lexicographically. It is not hard to see that if α1,α2,α3 are ordinals, then
both (α1 +o α2) +o α3 and α1 +o (α2 +o α3) have the order type of the set

[0, x]: x ∈α1

∪

[1, y]: y ∈α2

∪

[2, y]: y ∈α3

,
ordered lexicographically. Hence ordinal addition is also associative, i.e.
(α1 +o α2) +o α3 = α1 +o (α2 +o α3).
Note, however, that ordinal addition is not commutative. Indeed, if we denote by ω
the set of all integers as is customary in the theory of ordinal numbers, we ﬁnd that
ω +o 1 is larger than ω, but 1 +o ω is easily seen to be ω. Note also that α +o 1
is easily seen to be the successor ordinal of α for each ordinal α, and so is always
strictly larger than α.
The smallest ordinals are the ﬁnite integers 0,1,2,... followed by the set ω of
all integers, which is the smallest inﬁnite ordinal. From these, we can form other
ordinals using the operations just introduced:
ω +o 1, ω +o 2,...,ω +o ω = 2 ∗o ω, 3 ∗o ω,...,ω ∗o ω, ω ∗o ω ∗o ω,....
We shall now have a look at the ordering and ordinal arithmetic relationships be-
tween these and related ordinals.
Suppose that we indicate the dependence of the Enu(x) function described above
on the well-ordered set s appearing in its deﬁnition by writing Enu(x) as Enus(x).
Then it is easily proved by (transﬁnite) induction that if t is a well-ordered set and
t ⊇s we have Enus(α) ⩾Enut(α) for any ordinal α such that Enus(α) ∈s. (Hint:
ﬁrst prove by induction that
t \

Enut(y): y ∈β

⊇s \

Enus(y): y ∈β

for every ordinal β.) It follows that the order type of any subset s of an ordinal α
is the image under the Enu function of an ordinal no larger than α. Since, as seen
above, any well-ordered set is order-isomorphic to some ordinal, it follows at once
that the order type of a subset of a well-ordered set s can be no larger than the order
type of s.

136
3
A Survey of Inference Mechanisms
Using this last result it is easy to see that both addition and multiplication are
non-decreasing functions of both their arguments. For example, if α1, α2, β1, and
β2 are all ordinals, with α1 ⊇β1 and α2 ⊇β2, then α1 ∗o α2 is the order type of
the lexicographically ordered Cartesian product C of α1 and α2, and β1 ∗o β2 is
the order type of the Cartesian product of β1 and β2, which is a subset of C and
has the same lexicographic order. Hence α1 ∗o α2 is an ordinal no smaller than
β1 ∗o β2, showing that the operation of ordinal multiplication is monotone in both
its arguments. The proof of the corresponding statement for ordinal addition, which
is similar, is left to the reader.
Ordinal multiplication is right-distributive over ordinal addition. That is, we have
(α1 +o α2) ∗o β = (α1 ∗o β) +o (α2 ∗o β),
whenever α1, α2, and β are ordinals. To see this, note that (α1 +o α2) ∗o β is easily
seen to be the order type of the set

[0, x,y]: x ∈α1, y ∈β

∪

[1, x,y]: x ∈α2, y ∈β

and (α1 ∗o β) +o (α2 ∗o β) can be identiﬁed with equal ease with the same set. This
implies that the ordinal sum α +o α +o ··· +o α of k copies of an ordinal α is the
same as k ∗o α. On the other hand, the corresponding left distributive law fails for
inﬁnite ordinals: although 2 ∗o ω is ω +o ω (the order type of two copies of the
integers, the second positioned after the whole of the ﬁrst), ω ∗o 2 is the order type
of the lexicographically ordered set of pairs

[x, 0]: x ∈ω

∪

[x, 1]: x ∈ω

,
which is order-isomorphic to ω by the (integer arithmetic) mapping [x, i] →2 ∗
x + i.
A kind of subtraction can be deﬁned for ordinals. More speciﬁcally, if α1 and α2
are ordinals and α1 ⊇α2, then we can write α1 as an ordinal sum α1 = α2 +o α3.
(Conversely, by the result proved in the preceding paragraph, α2 +o α3 can never
be less than α2, since α2 can be written as α2 +o 0.) Indeed, α1 is the union of α2
and α1 \ α2, whose elements are all larger than all elements in α2, from which it is
easily seen that the order type of α1 is the ordinal sum of the order types of α2 and
α1 \ α2.
Using the ordinal subtraction operation just described we can now show that the
ordinal addition operation α +o β is strictly monotone in its second (though not in
its ﬁrst) argument. Indeed, if β′ > β, then β′ can be written as β +o γ for some non-
zero ordinal γ , and so α +o β′ = α +o β +o γ is larger than α +o β. On the other
hand we have 2 +o ω = 1 +o ω = ω, showing that ordinal addition is not strictly
monotone on its ﬁrst argument.
For any two ordinals α1 and α2, of which the ﬁrst is at least 2 and the second
is non-zero, the ordinal product α1 ∗o α2 is strictly larger than α2. Indeed we have
(α1 ∗o α2) ⊇(2 ∗o α2) = (α2 +o α2) ⩾(α2 +o 1) > α2.

3.8
More Examples of Decidable Sublanguages
137
The equation α +o β = β, of which 1 +o ω = ω is a special solution, is worth
studying more closely. Note ﬁrst of all that if β ⩾ω ∗o α, then using ordinal sub-
traction we can write β as ω ∗o α +o γ for some ordinal γ , so that
α +o β = α +o ω ∗o α +o γ = (1 +o ω) ∗o α +o γ = ω ∗o α +o γ = β.
That is, we must have α +o β = β whenever β ⩾ω ∗o α. Conversely, if α +o β = β,
then
2 ∗o α +o β = (α +o α) +o β = α +o (α +o β) = α +o β = β,
and so inductively (k ∗o α) +o β = β for every ﬁnite integer k, and so k ∗o α ⩽β for
every ﬁnite integer k. It follows from this that ω ∗o α ⩽β. For if not, then we must
have β < ω ∗o α, so β is isomorphic to a proper initial segment s of the Cartesian
product C of ω and α. Let [m, x] = Smallest(C −s) with m ∈ω and x ∈α. Then
s is a proper initial segment of the Cartesian product of m and α, whose order type
is m ∗o α. Thus β < m ∗o α, which contradicts the inequality m ∗o α ⩽β derived
above. Therefore ω ∗o α ⩽β, as stated. Together all this proves that α +o β = β
if and only if β ⩾ω ∗o α, i.e. if and only if β is ‘substantially’ larger than α, in
this sense. Note that our argument also proves that if n and m are ordinals, and
m ⩾k ∗o m for every ﬁnite integer k, then m ⩾ω ∗o m.
Write the k-fold product of any ordinal α with itself as αk. The associative law
for ordinal multiplication implies that αj ∗o αk = αj+k (where j + k denotes the
integer sum of j and k.) If α is greater than 1, and in particular if α = ω, then the
sequence of powers α, α2, α3,... is strictly increasing. Indeed we have
αi+1 = α ∗o αi ⩾2 ∗o αi = αi +o αi
⩾αi +o 1 > αi.
We will call an ordinal α a polynomial ordinal if it has the form
ck ∗o ωk +o ck−1 ∗o ωk−1 +o ck−2 ∗o ωk−2 +o ··· +o c1 ∗o ω +o c0,
where all the coefﬁcients ci are ﬁnite integers. These ordinals, which we shall write
as Pord(ck,ck−1,...,c0), have the following properties:
(i) Two polynomial ordinals
p = Pord(ck,ck−1,...,c0)
and
p′ = Pord

c′
k′,c′
k′−1,...,c′
0

are distinct if their coefﬁcient sequences ck,ck−1,...,c0 and c′
k′,c′
k′−1,...,c′
0
are distinct, up to leading zeroes.
(ii) Two polynomial ordinals compare in the lexicographic order of their coefﬁ-
cients. (If one of the sequences of coefﬁcients is shorter, it should be preﬁxed
with zeroes to give it the length of the other sequence of coefﬁcients.)
(iii) The ordinal sum of two polynomial ordinals p = Pord(ck,ck−1,...,c0) and
p′ = Pord(c′
k′,c′
k′−1,...,c′
0) with k ⩾k′ is given by the following rule:

138
3
A Survey of Inference Mechanisms
If p′ = 0, i.e. all its coefﬁcients are zeroes, then the ordinal sum of p and p′
is Pord(c′
k′,c′
k′−1,...,c′
0). Otherwise, locate the leftmost position i in which
the second argument has a non-zero coefﬁcient; take the coefﬁcients of the ﬁrst
argument to the left of this position; in the ith position, add ci and c′
i; in later
positions take the coefﬁcients of the second argument. This rule is expressed
by the formula
Pord(ck,ck−1,...,c0) +o Pord(c′
k′,c′
k′−1,...,c′
0)
= Pord(ck,ck−1,...,ci+1,ci + c′
i,c′
i−1,...,c′
0)
for the sum of these two polynomial ordinals, where
c′
k′ = c′
k′−1 = ··· = c′
i+1 = 0
and
c′
i ̸= 0.
To prove (i–iii), note that (ii) implies (i), so that only (ii) and (iii) need be proved.
(ii) can be proved as follows. Consider two polynomial ordinals p and p′, having
the general forms
p = Pord(ck,ck−1,...,c0)
and
p′ = Pord

c′
k,c′
k−1,...,c′
0

(3.31)
and suppose that the ﬁrst difference between their coefﬁcients occurs at the posi-
tion i. Since it is obvious from the deﬁnition of (3.31) and by associativity that
Pord(ck,ck−1,...,c0)
= Pord(ck,ck−1,...,ci+1,0,...,0) +o Pord(ci,ci−1,...,c0),
and since the ordinal addition operator is strictly monotone in its second argu-
ment, we can suppose without loss of generality that i = k, and therefore need only
prove that if two polynomial ordinals (3.31) differ in their ﬁrst coefﬁcient, the one
with the larger ﬁrst coefﬁcient is larger. This is simply a matter of proving that
Pord(ck,ck−1,...,c0) < (ck + 1) ∗o ωk, i.e. that Pord(ck−1,...,c0) < ωk. But it is
easily seen that Pord(ck−1,...,cj) +o ωk = Pord(ck−1,...,cj+1) +o ωk for every
j ⩽k, from which it follows inductively that Pord(ck−1,...,c0) +o ωk = ωk. It is
easily seen from this that Pord(ck−1,...,c0) < ωk, as claimed, thus proving (ii).
To calculate the sum of two non-zero polynomial ordinals Pord(ck,ck−1,...,c0)
and Pord(c′
i,c′
i−1,...,c′
0) (both written with non-zero leading coefﬁcients) we can
note ﬁrst of all that if k < i then we can show, as at the end of the preceding para-
graph, that Pord(ck,ck−1,...,c0) +o c′
i ∗o ωi = c′
i ∗o ωi. From this, (iii) follows
immediately by associativity of ordinal addition in the special case in which k < i.
Now suppose that k ⩾i. Then by associativity of ordinal addition we have
Pord(ck,ck−1,...,c0) +o Pord

c′
i,c′
i−1,...,c0

=

Pord(ck,ck−1,...,ci+1) +o ci ∗o ωi +o Pord(ci−1,...,c0)

+o

c′
i ∗o ωi +o Pord

c′
i−1,...,c′
0


3.8
More Examples of Decidable Sublanguages
139
= Pord(ck,ck−1,...,ci+1) +o

ci + c′
i

∗o ωi +o Pord

c′
i−1,...,c′
0

= Pord

ck,ck−1,...,ci+1,ci + c′
i,c′
i−1,...,c′
0

,
proving (iii).
By the rule (ii) stated above, Pord(ck,ck−1,...,c0) < ωk+1. Conversely, we will
show that if α is any ordinal such that α < ωk+1, then α is a polynomial ordinal of
the form Pord(ck,ck−1,...,c0). To see this, argue inductively on k, and so suppose
that our statement is true for all k′ < k. Then ﬁnd the largest integer c such that α ⩾
c ∗o ωk; this must exist since we have seen above that if α ⩾c ∗o ωk for all integers
c, it would follow that α ⩾ωk+1, which is impossible. By the subtraction principle
stated above, we can write α = c ∗o ωk +o β for some ordinal β. If β ⩾ωk, then
α ⩾c ∗o ωk +o ωk = (c + 1) ∗o ωk,
contradicting the deﬁnition of c. It follows by induction that β is a polynomial
ordinal and can be written as Pord(ck−1,...,c0), from which it follows immediately
that α = Pord(c,ck−1,...,c0), as asserted.
It follows that the smallest ordinals are precisely the polynomial ordinals, and
that the ﬁrst positive ordinal larger than all the polynomial ordinals is the union
of all the powers ωk for integer k. This is the order type of the collection of all
inﬁnite sequences [...,ni,ni−1,...,n0] of integers which contain all but ﬁnitely
many non-zeroes, lexicographically ordered.
We will say that an ordinal α is post-polynomial if, whenever β < α and p is
a polynomial ordinal, β +o p < α also. The ﬁrst post-polynomial ordinal is the
zero ordinal ∅; this is the only post-polynomial ordinal which is also polynomial.
Moreover the sum α1 +o α2 of any two post-polynomial ordinals is itself post-
polynomial. For if β is an ordinal such that β < α1 +o α2 and p is a polynomial
ordinal, then if β < α1 we have β +o p < α1 also, and therefore β +o p < α1 +o α2.
On the other hand, if β ⩾α1, we can write β = α1 +o γ for some ordinal γ , and
by the strict monotonicity of ordinal addition in its second argument we must have
γ < α2, so γ +o p < α2, and therefore
β +o p = α1 +o γ +o p < α1 +o α2,
proving that β +o p < α1 +o α2 in all cases.
We shall now show that any ordinal α can be decomposed uniquely as an ordinal
sum α = μ +o p, where μ is post-polynomial and p is a polynomial ordinal (μ and
p will be referred to as the post-polynomial and the polynomial parts of α, respec-
tively). Moreover, in this decomposition, ordinals α have exactly the lexicographic
ordering of the corresponding pairs [μ,p]. To show this, note ﬁrst of all that the
union U of all the elements of any set s of post-polynomial ordinals must itself be
post-polynomial. Indeed, if γ < u, then γ is a member of U and hence of some δ
in u, so that γ +o p < δ for all polynomial ordinals p, and hence γ +o p < U. It
follows that the union ν of all the post-polynomial ordinals not greater than α is
itself post-polynomial. Clearly μ is the largest post-polynomial ordinal not greater
than α. By the subtraction principle for ordinals stated above, there exists an ordinal

140
3
A Survey of Inference Mechanisms
ξ such that α = ν +o ξ. The ordinal ξ cannot be greater or equal to the ﬁrst non-zero
post-polynomial ordinal λ, since if it were, then we would have α ⩾ν +o λ, but we
have seen above that ν +o λ is post-polynomial, and since it is clearly greater than
ν we have a contradiction. Hence ξ is less than λ, and so is polynomial, proving
that α can be decomposed as an ordinal sum α = μ +o p of the type stated above.
Uniqueness is proved in the next paragraph.
The decomposition α = μ +o p of an ordinal α into the sum of a post-polynomial
and a polynomial ordinal is unique, since if μ +o p = μ′ +o p′ for distinct post-
polynomial μ,μ′, then one of these two, say μ, must be larger than the other.
But then μ + p ⩾μ > μ′ +o p′, a contradiction. Similarly, if μ +o p > μ′ +o p′,
with μ,μ′ post-polynomial ordinals and p,p′ polynomial ordinals, we must have
μ ⩾μ′, and if μ = μ′, then p > p′ by the monotonicity of ordinal addition. This
shows that the lexicographic ordering of the pairs [μ, p] corresponds exactly to the
standard ordering of the corresponding ordinals α = μ +o p.
In what follows we shall say that a polynomial ordinal is of degree k if it has
the form Pord(ck,ck−1,...,c0) with either ck ̸= 0 or k = 0. The function Cfj(p)
is deﬁned to return the jth coefﬁcient of the polynomial ordinal p, or, if j ex-
ceeds the degree of p, to return 0. We extend this function to all ordinals by writing
Cfj(β +o p) = Cfj(p) if p is a polynomial ordinal and β is post-polynomial. If
p = Pord(ck,ck−1,...,c0) is a polynomial ordinal of degree k and j an integer, we
let
Hij(p) =

Pord(ck,ck−1,...,cj+1)
if j < k
0
otherwise
and
Lowj(p) =

Pord(cj,cj−1,...,c0)
if j < k
p
otherwise.
These operations are extended to general ordinals in the same way we extended Cfj.
Using these functions, we deﬁne three auxiliary functions α ˚−p, α ⌢p, and α ∽p
for use below. These are deﬁned for any ordinal α and polynomial ordinal p: If p is
of degree d and c is its leading coefﬁcient and if μ is the post-polynomial part of α,
then we have
α ˚−p = μ +o Hid(α) ∗o ωd+1 +o c′ ∗o ωd +o Lowd−1(p)
α ⌢p = μ +o Hid(α) ∗o ωd+1 +o Lowd−1(p)
α ∽p = μ +o Hid(α) ∗o ωd+1 +o p
(where c′ is Cfd(α) −c, if this is positive, otherwise 0). Then we have Hid(α ˚−
p) = Hid(α); Cfd(α ˚−p) is Cfd(α) −c if this is positive, otherwise 0; and
Lowd−1(α ˚−p) = Lowd−1(p). Similarly Hid(α ⌢p) = Hid(α); Cfj(α ⌢p) is 0;
and Lowd−1(α ⌢p) = Lowd−1(p). Finally Hid(α ∽p) = Hid(α) and Lowd(α ∽
p) = Lowd(p).
We will also need to use various properties of these operators, as used in combi-
nation with each other and in combination with the comparator ‘>’ and the equality

3.8
More Examples of Decidable Sublanguages
141
‘=’. These are as follows (where y,z are arbitrary ordinals, and p,q are polynomial
ordinals of degrees d and d′ and leading coefﬁcients c and c′, respectively):
(i) (α +o p) +o q = α +o (p +o q)
(ii) (α +o p) ˚−q = if d > d′ then α +o (p ˚−q)
elseif d′ > d then α ˚−q
elseif c ⩾c′ then α +o (p ˚−q)
else α ˚−((q ˚−p) ∽(q ⌢q)) end if
(iii) (α +o p) ⌢q = if d > d′ then α +o (p ⌢q)
else α ⌢q end if
(iv) (α +o p) ∽q = if d > d′ then α +o (p ∽q)
else α ∽q end if
(v) (α ˚−p) +o q = if d > d′ then α ˚−(p +o q)
elseif d′ > d then α +o q
elseif Cfd(α) < c then α ∽q
elseif c ⩾c′ then α ˚−(p ˚−q)
else α +o (q ˚−p) end if
(vi) (α ˚−p) ˚−q = if d > d′ then α ˚−(p ˚−q)
elseif d′ > d then α ˚−q
else α ˚−(p +o q) end if
(vii) (α ˚−p) ⌢q = if d > d′ then α ˚−(p ⌢q)
else α ⌢q end if
(viii) (α ˚−p) ∽q = if d > d′ then α ˚−(p ∽q)
else α ∽q end if
(ix) (α ⌢p) +o q = if d > d′ then α ⌢(p +o q)
elseif d′ > d then α +o q
elseif d′ = d then α ∽q end if
(x) (α ⌢p) ˚−q = if d > d′ then α ⌢(p ˚−q)
elseif d′ > d then α ˚−q
else α ⌢q end if
(xi) (α ⌢p) ⌢q = if d ⩾d′ then α ⌢(p ⌢q)
else α ⌢q end if
(xii) (α ⌢p) ∽q = if d ⩾d′ then α ⌢(p ∽q)
else α ∽q end if
(xiii) (α ∽p) +o q = if d > d′ then α ∽(p +o q)
elseif d′ > d then α +o q
elseif d′ = d then α ∽(p +o q) end if
(xiv) (α ∽p) ˚−q = if d > d′ then α ∽(p ˚−q)
elseif d′ > d then α ˚−q
elseif d′ = d then α ∽(p ˚−q) end if
(xv) (α ∽p) ⌢q = if d ⩾d′ then α ∽(p ⌢q)
else α ⌢q end if
(xvi) (α ∽p) ∽q = if d ⩾d′ then α ∽(p ∽q)
else α ∽q end if

142
3
A Survey of Inference Mechanisms
(xvii) (α +o p > z) ↔(α ⩾z +o r′
∨(α ⩾z ⌢r & (Cfd(z) < c
∨(α ⩾ω ˚−r∗& p ⌢p > Lowd−1(z))))
(Here r and r′ are, respectively the polynomial ordinals ωd and ωd+1,
and r∗is the polynomial ordinal of degree d whose leading coefﬁcient is
Cfd(p) and whose remaining coefﬁcients are 0.)
(xviii) ((α ˚−p) > z) ↔(α ⩾(z +o r′)∨
(α ⩾(z ⌢r) &
((Cfd(α) ⩽c & p ⌢p > Lowd(z))
∨(Cfd(α) > c & (α > ω + r∗
∨(α ⩾ω + r∗& p ⌢p > Lowd−1(z)))))))
(Here r, r′, and r∗are as in (xvii).)
(xix) ((α ⌢p) > z) ↔if (p ⌢p) > Lowd(z) then α ⩾ω ⌢r
else α ⩾ω +o r′ end if
(Here r and r′ are as in (xvii).)
(xx) ((α ∽p) > z) ↔ω ↔if p > Lowd(z) then α ⩾ω ⌢r
else α ⩾ω +o r′ end if
(Here r and r′ are as in (xvii).)
(xxi) ((α +o p) > z) ↔(α ⩾(z +o r′)
∨(α ⩾(z ⌢r) & ((Cfd(z) < c)
∨(α ⩾ω ˚−r∗& p ⌢p ⩾Lowd−1(z))))
(Here r and r∗are as in (xvii).)
(xxii) ((α ˚−p) ⩾z) ↔(α ⩾(z +o r′)∨
(α ⩾(z ⌢r) &
((Cfd(α) ⩽c & p ⌢p ⩾Lowd(z))
∨(Cfd(α) > c & (α > ω + r∗
∨(α ⩾ω + r∗& p ⌢p ⩾Lowd−1(z)))))))
(Here r and r∗are as in (xvii).)
(xxiii) ((α ⌢p) ⩾z) ↔if (p ⌢p) ⩾Lowd(z) then α ⩾ω ⌢r
else α ⩾ω +o r′ end if
(Here r and r′ are as in (xvii).)
(xxiv) ((α ∽p) ⩾z) ↔if p ⩾Lowd(z) then α ⩾ω ⌢r
else α ⩾ω +o r′ end if
(Here r and r′ are as in (xvii).)
(xxv) Cfj(α +o p) = if j > d then Cfj(α) else Cfj(α) + Cfj(p) end if
(xxvi) Cfj(α ˚−p) = if j > d then Cfj(α)
elseif Cfj(α) ⩾Cfj(p) then Cfj(α) −Cfj(p) else 0 end if
(xxvii) Cfj(α ⌢p) = if j > d then Cfj(α) else Cfj(p′) end if ,
where p′ is the polynomial ordinal having the same coefﬁcients as p, ex-
cept that Cfd(p′) is zero.
(xxviii) Cfj(α ∽p) = if j > d then Cfj(α) else Cfj(p) end if .
These rules have the following proofs. (i) is a consequence of the associative law
for ordinal addition. For (ii), note that if d > d′ then in the range of coefﬁcients rel-
evant to the formation of (y +o p) ˚−q the coefﬁcients of y will have been replaced,
in y +o p, by those of p, from which the ﬁrst case of (ii) follows immediately. On

3.8
More Examples of Decidable Sublanguages
143
the other hand, if d′ > d, then the difference between y and y +o p is irrelevant to
the formation of (y +o p) ˚−q, and thus the second case of (ii) follows. Finally, if
d′ = d, then the coefﬁcient Cfd((y +o p) ˚−q) is Cfd(y) + (Cfd(p) −Cfd(q)) if p
has a larger leading coefﬁcient than q. However, if q has a larger leading coefﬁcient
than p, then Cfd((y +o p) ˚−q) is Cfd(y)−(Cfd(q)−Cfd(p)), or 0 if this difference
is negative. In both these cases, all lower coefﬁcients are those of q, proving rule (ii)
in the remaining cases.
In regard to rule (iii), note that if d ⩾d′ then in the range of coefﬁcients relevant
to the formation of (y +o p) ⌢q the coefﬁcients of y will have been replaced (in
y +o p) by those of p, from which the ﬁrst case of (iii) follows immediately. On
the other hand, if d′ > d, then the difference between y and y +o p is irrelevant to
the formation of (y +o p) ˚−q, and thus the second case of (iii) follows. The proofs
of (iv), (vii), (viii), (xi), (xii), (xv), and (xvi) are essentially the same, so we leave
details to the reader.
The proofs of the ﬁrst two cases of rules (v), (vi), (ix), (x), (xiii), and (xiv) are
much the same as that of the corresponding cases of rule (ii) and are also left to the
reader. In the remaining cases of these rules, p and q have the same degree d. In
all these cases, the coefﬁcients Cfj of the result being formed are always those of
q for j < d; only the coefﬁcients Cfd requires closer consideration. In regard to the
d = d′ case of rule (v), note that in this case if the leading coefﬁcient c of p is larger
than the corresponding coefﬁcient of y, y ˚−p will have a zero dth coefﬁcient, so
(y ˚−p) +o q will simply be y ∽q. But if c is not larger than the corresponding
coefﬁcient of y, then the dth coefﬁcient of (y ˚−p) +o q will be Cfd(y) + c −c′,
i.e. is that of y ˚−(p ˚−q) if c ⩾c′, but that of y +o (p ˚−q) otherwise. Since the
remaining coefﬁcients of (y ˚−p) +o q are those of q in any case, Rule (v) follows.
The d = d′ case of rule (vi) follows in the same way since the dth coefﬁcient
of (y ˚−p) ˚−q is always that of y ˚−(p +o q), and the remaining coefﬁcients of
(y ˚−p) ˚−q are those of q. In the d = d′ case of rule (ix), the dth coefﬁcient of
y ⌢p is zero, hence the dth coefﬁcient (y ⌢p) ˚−q is that of q, while the remaining
coefﬁcients are those of q, proving rule (ix) in this case. The d = d′ cases of rules
(x), (xiii), and (xiv) follow by similar elementary observations, whose details are
left to the reader.
Rules (xxv–xxvii) follow directly from the deﬁnitions of the operators +o, ˚−, ⌢,
and ∽and the coefﬁcient functions Cfj. Their proofs are left to the reader.
To prove rule (xvii), note ﬁrst of all that (y +o p) > ω will hold either if
Hid(y) > z, in which case the values of Lowd(y +o p) and Lowd(z) are all irrelevant,
or otherwise if Hid(y) = Hid(z) (which in this case we can write as Hid(y) ⩾Hid(z)),
in which case we must have Lowd(y +o p) > Lowd(z). But Hid(y) > ω is equiv-
alent to y > ω +o r′, and Hid(y) ⩾ω is equivalent to y ⩾ω ⌢r, where r and
r′ are as in (xvii). (This last remark applies in the proofs of all the rules (xvii–
xxv).) In the y ⩾ω ⌢r case of (xvii), if c > Cfd(z) then (y +o p) > ω is cer-
tainly true, while if c <= Cfd(z) then we must have both Hid−1(y) ⩾Hid(z ˚−p)
and Lowd−1(p) ⩾Lowd−1(z). The ﬁnal clauses in (xvii) merely restate these condi-
tions, by rewriting Hid−1(y) ⩾Hid(z ˚−p) as ω ˚−rd and Lowd−1(p) ⩾Lowd−1(z)
as p ⌢p > Lowd−1(z).

144
3
A Survey of Inference Mechanisms
The proofs of rules (xviii–xxiv) generally resemble that just given for rule (xvii),
and in some cases are distinctly simpler. To prove rule (xviii), we note as above that
(y ˚−p) > ω will hold either if Hid(y) > z, or otherwise if (y ˚−p) ⩾ω & Lowd(y ˚−
p) > Lowd(z). If Cfd(y) ⩽c then Lowd(y ˚−p) = p ˚−p; otherwise Lowd(y ˚−p) >
Lowd(z) is equivalent to
Cfd(y) > c ∨

Cfd(y) = c & Lowd−1(p) > Lowd−1(z)

,
which rule (xviii) merely restates.
The proofs of rules (xix), (xx), (xxiii), and (xxiv) are similar but simpler, and are
left to the reader. The proof of rule (xxi) is almost the same as that of (xvii), merely
involving a change from p ⌢p > Lowd−1(z) to p ⌢p ⩾Lowd−1(z). The proof of
rule (xxii) is like that of (xviii), merely involving the change of p ⌢p > Lowd−1(z)
and p ⌢p > Lowd(z) to p ⌢p ⩾Lowd−1(z) and p ⌢p ⩾Lowd(z), respectively.
These observations complete our proofs of all the rules (i–xxvii) stated above.
Let LO be the language of quantiﬁed formulae whose variables designate ordi-
nals and whose only allowed operation is that which forms the maximum of two
ordinals x and y, which for convenience we will write as x ⊔y. In addition to the
operator ‘⊔’, we also assume that the language LO allows one to compare ordinal
terms by means of the relators ‘>’ and ‘=’. We say that a subexpression

∃x | P(x)

of a formula of LO is of level k if it contains level k −1 subexpressions, but none
of any higher level; quantiﬁers not containing any quantiﬁed subexpression will be
said to be of level 0. Using this notion, we will show that the satisﬁability problem
for the language LO is decidable. The following result implies this, and gives a
convenient form to the necessary decision procedure.
Theorem 3.4 Let S be a statement, in the language LO, containing no free vari-
ables, and suppose that L is the maximum level, in the sense deﬁned above, of any
quantiﬁed subexpression of S. Then the truth value of S, quantiﬁed over the collec-
tion of all ordinals, is the same as the truth value obtained if all the quantiﬁers in S
are restricted to range over polynomial ordinals of degree at most L.
Since every polynomial ordinal of degree at most L is described by a set of L+1
integer coefﬁcients, and comparisons between two such ordinals and the maximum
of two such ordinals can be written as expressions involving only integer compar-
isons and sums, it follows from this theorem that the satisﬁability problem for the
language LO reduces to a special decision problem for Presburger’s language of
additive arithmetic, and so, by the result presented in the previous section, is decid-
able.
As an example illustrating the use of the theorem just stated, we consider the
formula

∃x
 
∀x′ | (x′ < x) →(∃x∗| x∗> x′ & x∗< x)

& (∃y | y < x)

.
(3.32)

3.8
More Examples of Decidable Sublanguages
145
The universal clause in (3.32) states that x is a limit ordinal, and the following ex-
istential clause states that x is non-null. Thus the smallest possible x satisfying the
condition displayed in (3.32) is ω. This example makes it plain that the predicate
Is_limit(x) stating that x is a limit ordinal can be deﬁned in the language LO. There-
fore so can the predicates
Is_limit_2(x) ↔Def

∃x
 
∀x′ | (x′ < x) →

∃x∗| x∗> x′ & x∗< x
& Is_limit(x∗)

Is_limit_3(x) ↔Def

∃x
 
∀x′ | (x′ < x) →

∃x∗| x∗> x′ & x∗< x
& Is_limit_2(x∗)

and so forth. From this, it is easy to see that one can write formulae in LO whose
smallest solutions are the ordinals ω2, ω3,..., and indeed any polynomial ordinal.
The theorem stated above tells us that ordinals larger than every polynomial ordinal
cannot be described by formulae of LO, and bound the size of the ordinals that can
be described by formulae of any speciﬁed quantiﬁer nesting level.
To prove Theorem 3.4 stated above, we ﬁrst note that any quantiﬁed formula S of
LO can be replaced by an equivalent formula of LO containing no occurrences of
the binary operator ‘⊔’ which returns the maximum of its arguments. To see this, we
note that every atomic formula appearing in S must be a comparison having either
the form t1 > t2 or t1 = t2, where t1 and t2 are either simple variables or literals
formed using the ‘⊔’ operator. But if t1 has the form x ⊔t, where x is some variable
chosen for processing, we can rewrite t1 > t2 as
(x = t & x > t2) ∨(x > t & x > t2) ∨(t > x & t > t2),
and similarly rewrite t1 = t2 as
(x = t & x = t2) ∨(x > t & x = t2) ∨(t > x & t = t2).
Similar remarks apply if t2 has the form t2 = x ⊔t. Applying these transformations
repeatedly, as often as necessary, we eventually remove all occurrences of ‘⊔’ from
S, replacing it by a formula written only with quantiﬁers and the comparisons ‘>’
and ‘=’. Note that the transformation we have described leaves the level of each
quantiﬁer in S unchanged.
But now, having removed all occurrences of ‘⊔’, we re-complicate our language
LO by introducing the four additional operators +o, ˚−, ⌢, and ∽described above,
plus the family of auxiliary predicates Cfj, into it. Note once more that in occur-
rences t +o p, t ˚−p, t ⌢p, and t ∽p of the operators +o, ˚−, ⌢, and ∽the second
argument p is required to be some polynomial ordinal with coefﬁcients known ex-
plicitly. Let LO′ designate the language LO, extended in this way, but with occur-
rences of ‘⊔’ forbidden.
With this understanding, we process the existentially quantiﬁed subexpressions

∃x | P(x)

(3.33)

146
3
A Survey of Inference Mechanisms
of our given formula of LO′ in bottom-to-top syntax tree order. As processing pro-
ceeds, we continually apply rules (i–xvi) and (xxv–xxviii). This reduces all the lit-
erals appearing in P(x) to forms like y +o p, y ˚−p, y ⌢p, and y ∽p, where y is
a simple variable and p an explicitly known polynomial ordinal, and every occur-
rence of a predicate Cfj to the form Cfj(y) = c, where y is a simple variable and
both j and c are explicitly known integers. Note in this conditions that inequali-
ties like Cfj(y) ⩽c, where c is some explicit integer constant, can be written as a
disjunction of the equalities Cfj(y) = e, over all e ⩽c, and so do not violate our
requirement that all occurrences of Cfj must be in contexts Cfj(y) = c. Likewise,
inequalities Cfj(y) > c are disjunctions of negated equalities Cfj(y) = e, over all
e ⩽c. p conditions like p ⌢p > Lowd−1(z), which appear in rules like (xvii) and
(xviii), can be rewritten, if we use the fact that the order of polynomial ordinals is
the lexical order of their coefﬁcients, in terms of inequalities between the coefﬁ-
cients Lowj(z) and known integer constants, and then also as Boolean combinations
of equalities Cfj(y) = c.
As the processing described in the preceding paragraph goes on, we always push
conditionals introduced by applications of rules (i–xxviii) using relationships like
if C1 then A1 elseif C2 then A2 elseif ··· else Ck end if +o p
= if C1 then A1 +o p elseif C2 then A2 +o p elseif ··· else Ak +o p end if .
When the predicate level is reached we use rules (xvii–xxviii), plus rules like
if C′
1 then A′
1 elseif C′
2 then A′
2 elseif ··· else C′
k end if ↔
(C′
1 & A′
1)∨

(¬C′
1) & C′
2 & A′
2

∨···∨

(¬C′
1) & (¬C′
2) & ··· & (¬C′
k−1) & A′
k

to eliminate any conditional expressions that may have accumulated. The ﬁnal
Boolean combination that results is then reduced to a disjunction of conjunctions.
We will prove recursively that this process can be used to reduce any level k ex-
istential (in the sense deﬁned above) to an equivalent disjunction of conjunctions,
each involving only variables free in the existential, together with expressions of the
form y +o p, y ˚−p, y ⌢p, and y ∽p, where p is a polynomial ordinal of degree
at most k with explicitly known constant integer coefﬁcients, also the comparators
‘>’, ‘⩾’, and conditions of the form Cfj(y) = c, where c is a known integer constant
no greater than k.
To prove this by induction on k, suppose that it is already known for all exis-
tentials of level lower than k, and consider an existential (3.33) of level k involving
only the operators listed above. Then P(x) begins (before application of the rules
(i–xvi) and (xxv–xxviii)) as an expression involving combinations t +o p, t ˚−p,
t ⌢p, and t ∽p with p of degree at most k −1, plus Cfj with j no larger than
k −1, and comparisons involving ‘>’ and ’⩾’. Application of the rules (i–xvi) and
(xxv–xxviii) does not introduce any polynomial ordinals of higher degree, or any
Cfj with j larger than k −1. Call a subexpression of P(x) x-free if it does not in-
volve the bound variable x. When the predicate level is reached, comparisons of the

3.8
More Examples of Decidable Sublanguages
147
form y > ω and y ⩾ω are reduced using rules (xvii–xxiv), unless they are x-free,
in which case they are left as they stand. Non x-free comparisons can have either
one or two arguments in which x appears. If x appears only in the ﬁrst of these
two arguments, we use rules (xvii–xxiv) to rewrite the comparison as a conjunc-
tion of comparisons of the form x > t and x ⩾t, where t is x-free, but where now
polynomial ordinals of degree k can appear in t (e.g. as the polynomial r′ seen in
rules (xvii–xx)). Conditions of the form Cfj with j no larger than k −1 can also
appear. Cases in which x appears only in the second of the two arguments of a com-
parison can be handled by rewriting a > b as ¬(b ⩾a) and a ⩾b as ¬(b > a).
Cases in which x appears in both arguments of a comparison will have forms like
x +o p > x ˚−q and x ⌢p ⩾x ˚−q. To handle these, we observe that all such com-
parisons can be expressed as Boolean combinations of comparisons between known
integers and coefﬁcients Cfj(x) with j < k, and so are in accord with the inductive
condition we require.
Once the P(x) of (3.33) has been rewritten in the manner described in the pre-
ceding paragraph, it can be further rewritten as a disjunction of conjunctions. Then
we can use predicate relationships like

∃x | Q(x) ∨R(x)

↔

∃x | Q(x)

∨

∃x | R(x)

to replace existentials of disjunctions by disjunctions of existentials. We can also
move all x-free conjuncts out of the existential, at which point it only remains to
consider existentially quantiﬁed subexpressions of the form (3.33) in which P(x) is
a conjunct W of conditions of the following forms:
(a) x > t, where t is x-free, and involves no polynomial ordinal of degree greater
than k;
(b) x ⩾t, where t is x-free, and involves no polynomial ordinal of degree greater
than k;
(c) negations of comparisons of the forms (a) and (b);
(d) conditions Cfj(x) = c, where j ⩽k, and j and c are both known integers;
(e) conditions Cfj(x) ̸= c, where j and c are as in (d).
If such a conjunction W can be satisﬁed (i.e. if the existential (3.33) can have
the value ‘true’), then for each j it can contain at most one conjunct Cfj(x) = c,
since a second conjunct Cfj(x) = c′ with x ̸= c′ would be inconsistent with this.
Moreover, if there is such a conjunct, then any other conjunct Cfj(x) ̸= c′ must
either be inconsistent with or implied by this, and hence could be dropped. Also,
conjuncts x > t can be written as x ⩾t +o 1. Hence we can suppose without loss of
generality that we have
(a′) no conjuncts of the form (a) and no negations of such conjuncts;
(b′) for each j, at most one conjunct of the form (d), and if so no conjuncts (e);
(c′) some ﬁnite collection of conjuncts of the form (e).
If, for particular values of the free variables which appear in it, such a W is
satisﬁed by some ordinal value of the bound variable x, it is satisﬁed by a smallest
such x, which we shall call x0. Of all the t that appear in conditions of the form (b),

148
3
A Survey of Inference Mechanisms
let t0 be the largest (for the same particular values of the free variables which appear
in (3.33)). Then (by the subtraction principle stated earlier) x0 can be written as x0 =
t0 +o u for some ordinal u. Write u = u′ +o p, where u′ is a post-polynomial ordinal
and p is a polynomial ordinal. Then t0 +o p is no larger than t0 +o u′ +o p, but
satisﬁes all the conjuncts (b–e) present in W. Hence x0 must have the form t0 +o p,
where p is a polynomial ordinal. We can show in much the same way that the degree
of p can be no larger than k. If, for a given j, W contains a conjunct of kind (c), it
speciﬁes the corresponding coefﬁcient of t0 +o p uniquely, and in particular gives us
an explicit upper limit for the corresponding coefﬁcient of p. Moreover, if conjuncts
(e) occur for a given j, and we let c0 be the maximum of all the c that occur in these
conditions, then if there is a polynomial ordinal p with Cfjf (p) > c0 + 1 for which
t0 +o p satisﬁes all the conjuncts in W, then the same is true for t0 +o p′, where p′
is the same as p except that its coefﬁcient Cfjf (p) is reduced to c0 + 1. We see in
much the same way that if, for a given j, W contains neither a conjunct of form (d)
nor of form (e), then the p corresponding to the smallest t0 +o p satisfying W must
have Cfjf (p) = 0. Overall we see that explicit upper limits are available for each
of the Cfjf (p) coefﬁcients of the polynomial ordinal corresponding to the smallest
t0 +o p satisfying W. Hence, if we let p1,...,pn be an enumeration of all these
polynomial ordinals, let t vary over all the x-free expressions t1,...,tm appearing
in conjuncts (b) of W, and let x vary over all the corresponding sums ti +o pj (doing
this for all the disjuncts into which (3.33) has been decomposed), then one of these
x will satisfy the quantiﬁed condition (3.33) if there exists any x which satisﬁes it. It
follows that (3.33) is equivalent to a disjunction of ﬁnitely many alternatives of the
form P(ti +o pj), completing our inductive step and thereby completing our proof
of the theorem stated above.
3.8.3 A Language of Additive Inﬁnite Cardinal Arithmetic
The decision algorithm just described carries over easily to the following quanti-
ﬁed language LC. Variables in LC designate inﬁnite cardinal numbers, and the only
operation allowed is cardinal addition. Moreover, the language LC allows one to
compare cardinal terms by means of the relators ‘>’ and ‘=’. As was shown by
A. Tarski in [Tar56], the additive theory LC of inﬁnite cardinals is decidable. To
show this, let α be any ordinal, and let ℵα designate the αth member, in increasing
order, of the collection of all inﬁnite cardinals. Since the sum (or product) of any
two inﬁnite cardinals is the larger of the two, the function ℵis an order isomorphism
of the collection of all inﬁnite cardinals, taken with the operation of cardinal addi-
tion, onto the collection of all ordinals, taken with the operation which forms the
maximum of two ordinals. This operation evidently maps the satisﬁability problem
for LC to the satisﬁability problem for the language LO studied above, and so is
solved using the algorithm we have just given for determining the satisﬁability of
statements in LO.
More speciﬁcally, given a statement S in the language LC, containing no free
variables, for each cardinal variable ν occurring in S we introduce a fresh ordinal

3.8
More Examples of Decidable Sublanguages
149
variable αν and substitute each subexpression in S of the form

∃ν | P(ν)

by the equivalent expression

∃αν | P(ℵαν)

.
Then, we substitute each cardinal term of the form
ℵβ + ℵγ
in the resulting statement by the equivalent term
ℵβ⊔γ ,
until no term of the form ℵβ + ℵγ is left (we recall that the binary operator ‘⊔’
returns the maximum of its arguments). Finally, we substitute each cardinal term
ℵβ in the resulting statement by the corresponding ordinal term β. Let S′ be the
statement so obtained. Plainly S′ is a statement in LO which is equisatisﬁable with
our initial statement S, as the reader can readily check, so that satisﬁability of S
can be determined by applying to S′ the decision method outlined in the previous
section.
By combining the above decidability result with the Presburger decision algo-
rithm given in Sect. 3.8.1, we can obtain an algorithm for deciding the satisﬁability
of the quantiﬁed language LC∗obtained from LC by letting variables denote cardi-
nals which are allowed to be both ﬁnite and inﬁnite.
To be more speciﬁc, it is convenient to extend the language LC∗with an inﬁnite
endowment of integer variables, which are allowed to range over ﬁnite cardinals
only, and inﬁnite cardinal variables, which are allowed to range over inﬁnite car-
dinals only. Then, given a statement S in the language LC∗, containing no free
variables, for each cardinal variable ν occurring in S we introduce a fresh integer
variable nν and a fresh inﬁnite cardinal variable κν, and substitute each subexpres-
sion in S of the form

∃ν | P(ν)

by the equivalent expression

∃nν | P(nν)

∨

∃κν | P(κν)

.
Let S′ be the statement resulting after the above substitutions. Plainly S and S′
are equivalent. We call a term of the form n1 + ··· + nℓof the extended language
LC∗, with n1,...,nℓinteger variables, a ﬁnite term. Likewise, a term of the form
κ1 + ··· + κg, with κ1,...,κg inﬁnite cardinal variables, is called an inﬁnite term.
Finally, a term t of the form t1 + t2 or t2 + t1, with t1 a ﬁnite term and t2 an inﬁnite
term, is called a mixed-type term, and in this case t1 is referred to as the ﬁnite part
of t and t2 as its inﬁnite part. We perform the following simpliﬁcation steps on S′:

150
3
A Survey of Inference Mechanisms
(i) we substitute each mixed-type term in S′ with its inﬁnite part, until no mixed-
type term is left in S′;
(ii) we substitute each atomic subformula in S′ of the form t1 < t2, where t1 is a
ﬁnite term and t2 is an inﬁnite term, with the Boolean constant true;
(iii) we substitute each atomic subformula in S′ having one of the following types
t1 = t2,
t2 = t1,
t2 < t1,
where t1 is a ﬁnite term and t2 is an inﬁnite term, with the Boolean constant
false;
(iv) proceeding in bottom-to-top syntax tree order, we eliminate all occurrences
of the Boolean constants true and false introduced by step (iii), following the
elementary laws of propositional and ﬁrst-order logics (for instance, P ∨false
is simpliﬁed to P and (∃x|true) is simpliﬁed to true);
(v) proceeding in bottom-to-top syntax tree order, for any formula Q which does
not contain any free occurrence of the variable x, we replace
– each subformula of the form (∃x | Q) by Q,
– each subformula of the form (∃x | P & Q) by (∃x | P) & Q,
– each subformula of the form (∃x | P ∨Q) by (∃x | P) ∨Q,
– etc.
Let S′′ be the resulting statement after simpliﬁcation steps (i-v). Plainly, S′′ and S
are equivalent. Since by steps (i–iii) no atomic subformula of S′′ can contain both
integer and inﬁnite cardinal variables, after the execution of step (v) no existential
quantiﬁer over an integer variable can fall within the scope of an existential quanti-
ﬁer over an inﬁnite cardinal variable, and conversely. It follows that S′′ is a propo-
sitional combination of statements (containing no free variables) of Presburger’s
quantiﬁed language of additive arithmetic and of the language LC. Therefore its
truth value is a propositional function of the truth values of its components, which
can be calculated algorithmically by the decision tests for Presburger’s arithmetic
and for the language LC, thus proving the decidability of the language LC∗.
As an example, let us consider the formula

∀λ
 
∃μ| (∃ν | μ < λ & ν < λ & λ = μ + ν)

(3.34)
which is equivalent to
¬

∃λ
 ¬

∃μ| (∃ν | μ < λ & ν < λ & λ = μ + ν)

.
(3.35)
Plainly (3.34) is false, both for λ ﬁnite (when λ = 0,1) and for λ inﬁnite. After the
substitution in (3.35) of the variables λ, μ, and ν with nλ, κλ, nμ, κμ, nν, and κν,

3.8
More Examples of Decidable Sublanguages
151
formula (3.35) becomes
¬

∃nλ
 ¬

∃nμ | (∃nν | nμ < nλ & nν < nλ & nλ = nμ + nν)
∨(∃κν | nμ < nλ & κν < nλ & nλ = nμ + κν)

∨

∃κμ | (∃nν | κμ < nλ & nν < nλ & nλ = κμ + nν)
∨(∃κν | κμ < nλ & κν < nλ & nλ = κμ + κν)

∨

∃κλ
 ¬

∃nμ | (∃nν | nμ < κλ & nν < κλ & κλ = nμ + nν)
∨(∃κν | nμ < κλ & κν < κλ & κλ = nμ + κν)

∨

∃κμ | (∃nν | κμ < κλ & nν < κλ & κλ = κμ + nν)
∨(∃κν | κμ < κλ & κν < κλ & nλ = κμ + κν)

.
After simpliﬁcation steps (i–v), the latter becomes
¬

∃nλ
 ¬

∃nμ | (∃nν | nμ < nλ & nν < nλ & nλ = nμ + nν)

∨

∃κλ
 ¬

(∃κν | κν < κλ & κλ = κν) ∨(∃κμ | κμ < κλ & κλ = κμ)

,
which is unsatisﬁable since

∃nλ
 ¬

∃nμ | (∃nν | nμ < nλ & nν < nλ & nλ = nμ + nν)

is true (as can be computed by Presburger’s decision test). Therefore our initial
formula (3.34) is unsatisﬁable too. The same undecidability result could have been
established by observing that

∃nλ
 ¬

∃nμ | (∃nν | nμ < nλ & nν < nλ & nλ = nμ + nν)

is true (as can be computed by a decision test for the language LC).
3.8.4 Behmann’s Quantiﬁed Language of Elementary
Set-Theoretic Formulae
We now turn our attention to the class of formulae studied by Heinrich Behmann
in [Beh22], namely quantiﬁed formulae in which the unquantiﬁed expressions and
predicates which appear are set-theoretic expressions formed from set-valued vari-
ables by use of the elementary set operators a ∩b, a ∪b, a \ b and the set inclusion
operators a ⊇b and a ⊆b (but excluding the membership operator a ∈b, with a
and b set-valued variables, which if allowed in the quantiﬁed setting we consider
would at once make our formulae too general to be decidable by any algorithm).
We shall call the class of quantiﬁed set-theoretic formulae limited in this way the
Behmann formulae.

152
3
A Survey of Inference Mechanisms
It is easy to see that these formulae are powerful enough to restrict the cardinality
of the sets which appear within them. For example, the condition
s ̸= ∅&

¬(∃x | s ⊇x & s ̸= x & x ̸= ∅)

is readily seen to express the condition Is_singleton(s) that s should be a singleton.
Then, using this formula as a component we can write the formula

∃x,y | x ∩y = ∅& x ∪y = s & Is_singleton(x) & Is_singleton(y)

which is easily seen to express the condition #s = 2. It should be plain that the
condition #s = n can be expressed in much the same way for any given integer n.
Thus Behmann’s class of formulae is strong enough to express theorems like
#s = 10 →

#(s \ t) > 4 ∨#(s ∩t) > 4

,
i.e. to express elementary facts about the cardinality of sets. Hence any algorithm
able to decide the satisﬁability of all Behmann formulae must be strong enough to
decide certain elementary arithmetic statements. Behmann gave such an algorithm,
which we will generalize in Sect. 3.8.4.1. We shall see that the decision procedure
to be presented there uses as subprocedures the Presburger algorithm described in
Sect. 3.8.1 and the decision algorithm for additive inﬁnite cardinal arithmetic dis-
cussed in Sect. 3.8.3.
We begin our examination of Behmann’s class of quantiﬁed formulae by conﬁn-
ing ourselves to the case of formulae of type

∃x | P(x)

(3.36)
in which the predicate P is a conjunction of Boolean set-theoretic expressions
formed from set-valued variables by use of the set operators a ∩b, a ∪b, a \ b,
and the set inclusion operator a ⊇b. If we allow ourselves to write set union as a
sum, set intersection as an ordinary product, and the complement of the set x as x,
then any formula (3.36) can be written as (a disjunction of formulae of the form)

∃x

n
&
k=1(ak x + bk x = ∅) &
m
&
k=1(ck x + dk x ̸= ∅)

.
(3.37)
To see this, note that the only operators allowed in Behmann’s language are
union, intersection, and complementation, and the only comparators are a ⊇b and
a ⊆b. Inclusions of the form a ⊇b can be written as b a = ∅, and similarly for
a ⊆b. Thus we can drop the ‘⊇’ and ‘⊆’ comparators and use equality with the
nullset as our only comparator. Let x be the variable which is quantiﬁed in the
Behmann formula or subformula (∃x | B) that concerns us. Using the equivalence
(∃x | P ∨Q) ↔(∃x | P) ∨(∃x | Q)
as often as necessary, we can suppose without loss of generality that B is a conjunc-
tion of comparisons, some negated, and so all having the form t = ∅or t ̸= ∅, where

3.8
More Examples of Decidable Sublanguages
153
the term t that appears is formed using the union, intersection, and complementation
operators. Using De Morgan’s rules for the complement, the distributivity of union
over intersection, and the fact that y y = y for any set y, we can rewrite t as the
union of three terms t = t1 x + t2 x + t3, where t1, t2, and t3 are all set terms not
containing the variable x. Then, making use of the fact that
t1 x + t2 x + t3 = ∅
is equivalent to
t1 x + t2 x = ∅& t3 = ∅,
we can move the x-independent clause t3 = ∅out from under the quantiﬁer, leaving
us with an existentially quantiﬁed conjunction of equalities and inequalities of just
the form seen in (3.37), as asserted.
In addition, since (a = ∅& b = ∅) ↔(a + b = ∅), we can always assume n = 1
in (3.37). The detailed treatment of (3.37) rapidly grows complicated as m increases;
its general treatment, due to Behmann, will be reviewed below. However, since this
treatment is hyperexponentially inefﬁcient, we ﬁrst examine the two simplest cases
m = 0 and m = 1, in which easy and efﬁcient techniques are available.
In the case m = 0 we must consider

∃x | (a x + b x) = ∅

,
(3.38)
which is to say (∃x |b ⊆x & x a = ∅). Here a (minimal) solution is x = b, so (3.38)
is equivalent to a b = ∅.
Recursive use of this observation allows some multivariable cases resembling
(3.38) to be solved easily, e.g. to solve
(∃x,y | a11 x y + a10 x y + a01 y x + a00 x y = ∅)
(3.39)
we use (3.38) to rewrite it as

∃x | (a11 x + a01 x)(a10 x + a00 x) = ∅

.
(3.40)
‘Multiplying out’, we see that this is equivalent to
(∃x | a11 a10 x + a01 a00 x = ∅),
and so to a11 a10 a01 a00 = ∅.
We see in the same way that (3.40) has the solution x = a01 a00, from which we
obtain the solution
y = a10 a01 a00 + a00 a01 a00
= a10 a01 a00 + a00 a01
for y.
Proceeding to the next level of recursion we can now treat

154
3
A Survey of Inference Mechanisms
(∃x,y,z| a111 x y z + a110 x y z + a101 x y z + a100 x y z + a011 x y z + a010 x y z
+ a001 x y z + a000 x y z = ∅).
Using our solution of (3.39) we can rewrite this as

∃x | (a111 x + a011 x)(a110 x + a011 x)(a101 x + a001 x)(a100 x + a000 x) = ∅

.
‘Multiplying out’, it follows as above that a solution exists if and only if
a111 a110 a101 a100 a011 a010 a001 a000 = ∅.
The reader will readily infer the condition for solvability of the corresponding
k-variable case.
Next let m = 1 and consider

∃x | (a x + b x = ∅) & (c x + d x ̸= ∅)

↔

∃x | (b ⊆x) & (x a = ∅) & (c x + d x ̸= ∅)

.
(3.41)
By adding a point z ∈c a to a solution x of (3.41) we never spoil the solution,
and hence if (3.41) has a solution it has one of the form
b + c a + y,
where y must neither be included in a nor in c a. Since the choice of y will only
affect the term d x of (3.41), which we want to be as large as possible to maximize
our chance of having d x ̸= ∅, it is best to take y = ∅. Thus, if (3.41) has a solution,
it has the solution b + c a. Therefore a solution will exist if and only if
a b = ∅& c a + d b ̸= ∅.
These conditions, like (3.41), involve one set equality and one inequality, so that
inductive treatment of the n variable case corresponding to (3.41) is possible. For
example, we can consider

∃x,y | (a11 x y + a10 x y + a01 x y + a00 x y = ∅)
& (b11 x y + b10 x y + b01 x y + b00 x y) ̸= ∅

.
(3.42)
The inner existential of this can be written as the case of (3.41) in which
a = a11 x + a01 x,
b = a10 x + a00 x,
c = b11 x + b01 x,
d = b10 x + b00 x
and so has a solution if and only if
(a11 x + a01 x) · (a10 x + a00 x) = ∅

3.8
More Examples of Decidable Sublanguages
155
and
(b11 a11 x + b01 a01 x) · (b10 a10 x + b00 a00 x) ̸= ∅.
It follows that (3.42) is equivalent to
(∃x | a11 a10 x + a01 a00 x = ∅& b11 a11 b10 a10 x + b01 a01 b00 a00 x ̸= ∅)
and hence, applying the solution of (3.41) once more, has a solution if and only if
a11 a10 a01 a00 = ∅
and

b11 a11 b10 a10(a11 a10)

·

b01 a01 b00 a00(a01 a00)

̸= ∅.
Moreover, if (3.42) has a solution at all, it has the solution
x0 = a01 a00 + b11 a11 b10 a10(a11 a10),
from which a value for y can be calculated as follows. Substitute x0 into (3.42),
getting
(a11 x0 y + a10 x0 y + a01 x0 y + a00 x0 y = ∅)
& (b11 x0 y + b10 x0 y + b01 x0 y + b00 x0 y ̸= ∅)
as the condition that y must satisfy. This is a case of (3.41), and therefore using the
solution b + c a of (3.41) derived above we have
y = a10 x0 + a00 x0 + (b11 x0 + b01 x0) ·

a11 x0 + a01 x0

.
The common theme of these elementary examples is the progressive elimination
of quantiﬁers. This same method will be generalized below to give a procedure for
testing the satisﬁability of any (extended) Behmann formula.
As another interesting elementary case we can consider quantiﬁed formulae built
around a single set-theoretic equation e(x1,...,xn) = ∅but involving no set in-
equalities. Here we can allow arbitrary sequences of existential and universal quanti-
ﬁers, and do not always insist that e(x1,...,xn) only involve Boolean operators, but
suppose that existentially quantiﬁed variables only appear as arguments of Boolean
operators. The simplest case is
(∃x | ∀y | ay x + by x = ∅) ↔

∃x


y
ay

x +

y
by

x = ∅

,
(3.43)
where 
y ay designates the union of all the set values ay, etc. Hence, by the above
discussion of formula (3.38), (3.43) is equivalent to (∀y,z| aybz = ∅), and has
the solution 
y by if the truth-value of (3.43) is ‘true’. Similar elementary cases
involving more complex sequences of existential and universal quantiﬁers can be
treated in much the same way.

156
3
A Survey of Inference Mechanisms
3.8.4.1 The Extended Behmann Case
[Beh22] describes an algorithm for calculating the truth value of any formula quan-
tiﬁed over sets and involving only Boolean operators, set inclusion and inequality.
This can be generalized to a decision procedure for formulae quantiﬁed over both
sets and cardinals involving besides the operators just mentioned, also integer con-
stants, the set cardinality operator #S, cardinal addition, and inequalities. Such for-
mulae will be called TPB-formulae (after the initials of Tarski, Presburger, and
Behmann). As noted previously, in considering any existentially quantiﬁed TPB-
formula (∃ν | P(ν)) or (∃x | P(x)) (where, here and below, ν designates a cardinal
and x a set) we can assume that P is a conjunction of literals. In fact, existentially
quantiﬁed TPB-formulae over cardinals of the form (∃ν | P(ν)) can be rewritten as

∃xν | P(#xν)

,
where xν stands for a fresh set-valued variable denoting a set having cardinality ν.
Hence, we only need to consider set-theoretic TPB-formulae of the form

∃x | P(x)

,
(3.44)
with x a set-valued variable and P a conjunction of literals. Arguing much as in the
preceding section, these can be written as

∃x

N
&
k=1
 Pk

j=1
#(Ckj x + Dkj x) + Ak ⩾
Rk

j=Pk+1
#(Ckj x + Dkj x) + Bk

& Q,
(3.45)
where the Pk, Rk and N are integer constants, the Ak and Bk are valid cardinal-
valued TPB-terms, the Ckj and Dkj are valid set-valued TPB-terms, and Q is a
valid TPB-formula, none of which involving the variable x.
To handle (3.45), we form all possible intersections Hi of the sets Ckj, Dkj, and
their complements. This gives us a collection H1,...,HR of sets. Each of the sets
Ckj, Dkj can then be written as a disjoint union of these Hi:
Ckj =

i∈Gkj
Hi,
Dkj =

i∈Ekj
Hi,
for k = 1,...,n and j = 1,...,Qk, and where Gkj and Ekj are subsets of
{1,...,R}.
Thus we have
Ckj x =
 
i∈Gkj
Hi

x

3.9
A Decision Algorithm for the Theory of Totally Ordered Sets
157
and
Dkj x =
 
i∈Ekj
Hi

x,
for k = 1,...,n and j = 1,...,Qk, from which we see that (3.45) constrains only
the cardinality of the sets Hi x and Hi x, for i = 1,...,R. This observation allows
(3.45) to be rewritten as

∃ν1,...,νR,μ1,...,μR

 R
&
k=1(νk + μk = #Hk)
&
N
&
k=1
 Pk

j=1

i∈Gkj
(νi + μi) + Ak ⩾
Rk

j=Pk+1

i∈Gkj
(νi + μi) + Bk

.
(3.46)
Once having put (3.45) into the form (3.46), we can apply the technique described
in Sect. 3.8.3, using this repeatedly to eliminate the cardinal quantiﬁers
(∃ν1,...,νR,μ1,...,μR | ··· ).
This will ultimately yield a valid TPB-formula equivalent to (3.45) but containing
one less quantiﬁer.
3.9 A Decision Algorithm for the Theory of Totally Ordered Sets
The (unquantiﬁed) theory of totally ordered sets allows variables designating ele-
ments of such a set, and un-negated or negated comparisons ‘>’ and ‘=’ between
such elements. The comparison operator is assumed to satisfy all the assumptions
standard for such comparators, i.e.

∀x,y,z| (x > y & y > z) →(x > z)

,

∀x,y | (x > y) →

¬(y > x ∨y = x)

,

∀x,y,z| x > y ∨y > x ∨x = y

.
Since for the elements of such a set ¬(x > y) is equivalent to (y > x ∨y = x) and
x ̸= y is equivalent to (x > y ∨y > x), we can eliminate all the negated comparisons
and thus have only to decide the satisﬁability of a conjunction of comparisons, some
of the form x > y and others of the form x = y. By identifying all pairs of variables
x,y for which a conjunct x = y is present, we can eliminate all occurrences of the
‘=’ operator, and so have only to consider conjunctions of inequalities x > y. Such
a conjunct is satisﬁable if and only if it contains no cycle of relationships x > y.
Indeed, if there is such a cycle it is clear that the given set of statements admits of
no model by the elements of a totally ordered set. Conversely, if there is no such

158
3
A Survey of Inference Mechanisms
cycle, our variables can be topologically sorted into an order in which x comes later
than y whenever x > y, and this very ordering gives us the desired model.
A related and equally easy decision problem is that for the (unquantiﬁed) EL-
EMENTARY THEORY OF SUBSETS OF TOTALLY ORDERED SETS. This is the lan-
guage whose variables s,t designate subsets of some totally ordered set U , whose
operators are the elementary set union, intersection, and difference operators ∪, ∩,
and \, whose comparators are ‘⊇’ and ‘=’, but where we also allow the comparator
s > t (and also s ⩾t) which states that every element of s is greater (in the given
ordering of U ) than every element of t. We want this language to describe subsets
of some universe of totally ordered sets, so we deﬁne models of any collection S′ of
statements in the language to be a mapping of the variables which appear in S′ into
subsets of some totally ordered set U with ordering ‘>’, such that s > t and s ⩾t
are, respectively, equivalent to
(∀x ∈s, y ∈t | x > y)
and
(∀x ∈s, y ∈t | x ⩾y).
To handle this language, it is convenient to make use of the notion of ‘place’
introduced in our earlier discussion of decision algorithms for the language of el-
ementary set operators and of the properties of that notion deﬁned in Sect. 3.2.
As usual, we reduce the satisﬁability problem that confronts us to the satisﬁability
problem for a collection of conjuncts, each having one of the following forms:
s = t ∪u;
s = t \ u;
s = t ∩u;
s = ∅;
s ̸= ∅;
s > t;
s ⩾t;
¬(s > t);
¬(s ⩾t).
(3.47)
Let S′ be the set of all conjuncts listed above, and let S be the subset consisting
of all those conjuncts listed in the ﬁrst line of (3.47). We saw in Sect. 3.2 that, given
any model M of S, and any point p in the universe U of such a model, the function
fp(s) ↔(p ∈M s) deﬁnes a place for S, i.e. a Boolean-valued mapping of the
variables and elementary expressions appearing in S, such that
fp(s ∪t) = fp(s) ∨fp(t),
fp(s ∩t) = fp(s) & fp(t),
fp(s \ t) = fp(s) &

¬fp(t)

,
fp(∅)
= false.
We also saw in Sect. 3.2 that the set of all points p in U deﬁned an ample set of
places, in the sense that for any conjunct of the form s ̸= ∅there must exist a place
fp such that fp(s) = true. Conversely, given any ample set P of places, the formula
M s = {f ∈P | f (s) = true} deﬁnes a model of the set S of conjuncts.
For our present purposes we need a slight reformulation of this result which al-
lows individual places f to be used more than once in a model. In this reformulation
we use not simply a set P of places, but a ﬁnite sequence P ′ of places. We call such
a sequence of places ample if the set of places fi that occur in it is ample. In this
case, it is easily seen that the modiﬁed formula
M s =

i | fi(s) = true

(3.48)

3.10
A Decision Algorithm for Ordered Abelian Groups
159
also deﬁnes a model of the subset S of conjuncts. Suppose now that the full set S
of conjuncts has a model with some universe U , where as said above U must be
ordered and its ordering ‘>’ must model the operator s > t of our language in the
manner indicated above. For every conjunct ¬(s > t) (resp. ¬(s ⩾t)) in S′ choose
a pair of points p,q in U such that p ∈M s, q ∈M t, and q ⩾p (resp. q > p).
To these points, add a point p in M s for every conjunct s ̸= ∅in the set S′ of
conjuncts. It is then clear that if we restrict our universe to this collection U ′ of
points, i.e. take M ′s = M s ∩U ′ for every variable s of S′, we still have a model of
the full set S′ of conjuncts. If these points pj are arranged in their ‘<’ order, we will
have pj > pk if j > k. Now consider the sequence of places fj corresponding to
these points, i.e. fj = fpj . These have the property that if fj(s) = true (equivalent
to pj ∈M s), and also fk(t) = true, then the presence in S′ of a conjunct s > t
(resp. s ⩾t) implies j > k (resp. j ⩾k). Moreover, the presence in S′ of a conjunct
¬(s > t) (resp. ¬(s ⩾t)) implies the existence of indices j,k satisfying k ⩾j (resp.
k > j) and such that fj(s) = true and fk(t) = true. Hence, if we take the M deﬁned
by formula (3.48), whose universe U is simply the set of integer indices of the ﬁnite
sequence P ′ of places, and give these points their ordinary integer ordering, M is
a model of our full set S′ of conjuncts. This establishes the following conclusion,
which clearly implies that the language presently under consideration has a solvable
satisﬁability problem:
A collection S′ of conjuncts of the form (3.47) is satisﬁable if and only if it
admits an ample sequence fj of places, in which no place occurs more than n + 1
times, where n is the total number of conjuncts having either the form ¬(s > t), or
the form ¬(s ⩾t).
3.10 A Decision Algorithm for Ordered Abelian Groups
Ordered Abelian groups G are characterized by the presence of an associative-
commutative addition operator ‘+’, with identity ‘0’ and inverse ‘−’, and also a
comparison operator x > y satisfying

∀x ∈G, y ∈G| ¬(x > x ) & (x > y ∨x = y ∨x < y )

,

∀x ∈G, y ∈G, z ∈G| (x > y & y > z) →(x > z)

,

∀x ∈G, y ∈G, z ∈G| (x > y ) →(z −y > z −x )

(where x −y abbreviates x + −y). The last axiom plainly implies that

∀x ∈G, y ∈G, z ∈G| (x > y ) →(x + z > y + z)

.
Familiar structures satisfying the above axioms are the standard additive groups
based on Z, Q, and R, to mention a few.
The decision problem for the fully quantiﬁed theory of ordered Abelian groups
was solved by Yu. Gureviˇc in [Gur65]; here we will only show that the satisﬁability

160
3
A Survey of Inference Mechanisms
of any ﬁnite collection C of unquantiﬁed statements in this theory is decidable (more
detail about this specialized decision algorithm is provided in [COSU03, Sect. 3]).
Assume hence that C is the conjunction, subject to the above axioms, of unquanti-
ﬁed statements written using the operators ‘+’, ‘−’, ‘>’, the constant 0, and vari-
ables. Note that if such a conjunction C is satisﬁable, i.e. has some model which is
an ordered Abelian group G′, it can plainly be modelled in the subgroup G of G′
generated by the elements of G′ which correspond to the variables appearing in C.
Hence C has a model which is an ordered Abelian group with ﬁnitely many gener-
ators. Conversely, if there exists such a model, then C is satisﬁable. Thus we can
base our analysis on an understanding of the structure of ﬁnitely generated ordered
Abelian groups G.
The additive group of reals contains many such ordered subgroups with ﬁnitely
many generators, as does the additive group of real vectors of dimension d for any
d, if we order these vectors lexicographically. We will see in what follows that these
examples are generic, in the sense that any ordered Abelian group endowed with
a ﬁnite number m of generators can be embedded into the additive group of real
vectors of dimension (at most) m by an order-preserving isomorphism (we will call
such isomorphisms ‘order isomorphisms’ hereinafter).
This can be done as follows: By a well-known result (cf., e.g., [Fuc70]), Abelian
groups with ﬁnitely many generators are decomposable, in an essentially unique
way, as direct sums of ﬁnitely many copies of the group Z and of ﬁnitely many ﬁ-
nite cyclic groups. The order axiom plainly rules out any ﬁnite cyclic components,
so G must be the direct sum of ﬁnitely many copies of the signed integers. We
denote by rank(G) the number of these copies that appear in the direct sum repre-
senting G. A standard result, whose proof we will repeat below, tells us that this
number depends only on G, not on the way in which G is represented.
To see how the order in G must be represented (cf. [KK74]), we will consider
two cases separately: that in which G has ‘inﬁnitesimals’, and that in which it does
not. To this end, we deﬁne the subgroup Inf(G) of inﬁnitesimals of G (inclusive of
0, although this shall not be regarded as an inﬁnitesimal) as follows:
Inf(G) =Def {x ∈G| there exists a y in G such that mx ⩽y
holds for all signed integers m},
where for m > 0, mx designates the sum of m copies of x; mx is the zero element
of G if m = 0, and mx = −(−m)x if m < 0. It is easy to show that Inf(G) is indeed
a subgroup of G, and we leave this to the reader.
First suppose that G contains no inﬁnitesimals, i.e. Inf(G) = {0}; then for each
x > 0 and y > 0 there exists a positive integer m such that mx > y. In this case we
can show that the group must be order-isomorphic to an ordered subgroup of the
additive group of reals. In the easy case in which there is just one generator, G is
plainly isomorphic to the ordered group of integers.
More generally, choose some y > 0 and then, for each x, consider the set S(x)
of all rationals m/n with positive denominator n such that nx > my:
S(x) =Def {m/n: m ∈N, m ∈N| n > 0 & nx > my }.

3.10
A Decision Algorithm for Ordered Abelian Groups
161
This is deﬁned independently of the way that m/n is represented by a fraction, since
the order axioms imply that if nx > my then knx > kmy for each positive k, and
conversely if knx > kmy then nx ⩽my is impossible. Also, for every x ∈G, there
is a positive integer n such that (¬(n ∈S(x))) & (−n ∈S(x)), so S(x) is neither
empty nor all the rationals; moreover S(x) is bounded above, because if ¬(m/n ∈
S(x)) (i.e., my ⩾nx) and m′/n′ > m/n (i.e., nm′ > mn′), then ¬(m′/n′ ∈S(x))
(i.e., m′y ⩾n′x); ﬁnally, if m/n ∈S(x) then there are m′, n′ such that m′/n′ ∈
S(x) & m′/n′ > m/n. Together these facts imply that, for each x ∈G, S(x) is a
cut in the set of rationals, i.e. that there is a unique smallest real r(x) such that
S(x) = {a ∈Q| a < r(x)}.
We will now see that this mapping x →r(x) is an injective order-preserving
homomorphism of G into the reals. Suppose in fact that m/n < r(x) and m′/n′ <
r(x′) hold, both denominators n and n′ being positive. Then nx > my and n′x >
m′y, so nn′x > mn′y and nn′x > m′ny, and therefore
nn′(x + x′) > (mn′ + m′n)y,
from which it follows that m/n + m′/n′ belongs to S(x + x′). This proves that
(x + x′) ⩾r(x) + r(x′). Now suppose that r(x + x′) > r(x) + r(x′), and let m/n
and m′/n′, respectively, be rationals which approximate r(x) (resp. r(x′)) well
enough from above so that we have m/n + m′/n′ < S(x + x′), while m/n > r(x)
and m′/n′ > r(x′). This implies that nx ⩽my, n′x ⩽m′y, and nn′(x + x′) >
(mn′ + m′n)y. This is impossible since our ﬁrst two inequalities imply that nn′(x +
x′) ⩽(mn′ + m′n)y. It follows that r(x + x′) > r(x) + r(x′) is impossible, so
r(x + x′) = r(x) + r(x′), i.e. r is a homomorphism of G into the additive group
of reals. Suppose next that r(x) = 0. Then we cannot have x > 0, since if we did
then nx > y would be true for some positive n, so 1/n would be a member of S(x),
implying that r(x) ⩾1/n, which is impossible. Similarly if x < 0 it would follow
that r(−x) ⩾1/n for some positive n, also impossible. Since r has been seen to
be additive, r(−x) = −r(x), and it follows that x must be 0, proving the injec-
tivity of r. To see that r is order preserving, consider x,x′ ∈G such that x′ > x,
and let the rational number m/n (with positive denominator) belong to S(x); then
nx > my, and so nx′ > my also, proving that m/n belongs to S(x′). That is, x′ > x
implies that S(x′) ⊇S(x), and thus plainly implies that r(x′) ⩾r(x); but we must
exclude the possibility r(x′) = r(x), which by what we have seen above would im-
ply r(x′ −x) = 0, hence x′ −x = 0, and hence x′ = x. This completes our treatment
of the case in which G has no inﬁnitesimals.
Next we will show that in the presence of inﬁnitesimals, namely when Inf(G) is
non-trivial, G can be embedded into the lexicographically ordered additive group
of real vectors of dimension K, for some K not exceeding rank(G). To handle this
case, we need to use a few more standard results about ﬁnitely generated Abelian
groups, which we pause to derive. The ﬁrst of these is the fact that rank(G) is in-
dependent of the way in which we represent G as the sum of a ﬁnite collection of
cyclic groups, i.e. as an additive group Nk of integer vectors of length k. To see this,
suppose that two such groups Nk and Nk′ are isomorphic, and that k > k′. Let f be
an isomorphism of Nk onto Nk′. If we embed Nk and Nk′ into the corresponding

162
3
A Survey of Inference Mechanisms
spaces N∗
k and N∗
k′ of vectors with rational coefﬁcients, and extend f to a linear
mapping of N∗
k into N∗
k′, then, since the dimension k of N∗
k exceeds that of N∗
k′,
there exists a non-zero rational vector, and hence a non-zero integer vector in N∗
k
which f maps to zero. This contradicts the fact that f is an isomorphism, and so
proves our assertion concerning rank(G).
Next we will show that any subgroup S of a ﬁnitely generated ordered group G is
also ﬁnitely generated, and has rank no greater than the rank of S, again a standard
result. By what has been proved above, we can suppose without loss of generality
that G is the additive group of integer vectors of dimension d. If there is no vector v
in S whose ﬁrst component is non-zero, then S is a subgroup of the group of integer
vectors of dimension d −1, and so (by our inductive hypothesis) there is nothing to
prove. Otherwise let v be such a vector with smallest possible ﬁrst component c1.
Then any other v′ in S must have a ﬁrst component c′
1 which is divisible by c1, since
otherwise the greatest common divisor of c′
1 and c1, which is the ﬁrst component of
some vector of the form k ∗v +k′ ∗v′, where k and k′ are integers, would be positive
and smaller. It follows that every v in S can be written in the form k ∗v + u, where
u is a vector in S whose ﬁrst component is 0. Therefore, if we let S′ be the subgroup
of S consisting of all vectors whose ﬁrst component is 0, S′ is a subgroup of the
additive group of integer vectors of dimension d −1. By inductive hypothesis, S′ is
a ﬁnitely generated group with at most d −1 generators. If we add v to this set of
generators, we clearly have a set of generators for S, proving our assertion.
In what follows we will also need to use the following facts.
Lemma 3.1 Let (G,<) be a ﬁnitely generated ordered Abelian group, and let B be
a subgroup of G such that
x < y for each x in B and each positive y in G \ B.
(3.49)
Then:
(1) If given the ordering ‘<’ deﬁned by
(g + B) < (g′ + B)
iff
g < g′ & (g + B) ̸= (g′ + B),
the quotient group G/B becomes an ordered Abelian group.
(2) The Cartesian product H of G/B and B, given the lexicographic order ‘<’
deﬁned by
[x,y] < [x′,y′]
iff
x < x′ ∨(x = x′ & y < y′)
(in the ordering of G/B described just above)
is an ordered Abelian group.
(3) (G,<) and H are order-isomorphic and rank(G) = rank(G/B) + rank(B).
Proof To prove (1), note ﬁrst of all that the relationship (g + B) < (g′ + B), i.e.
g < g′, is independent of the elements g and g′ chosen to represent (g + B) and

3.10
A Decision Algorithm for Ordered Abelian Groups
163
(g′ + B). For if other g and g′ were chosen, the difference g′ −g will change to
g′ −g + b, where b is some element of B. But since g′ −g is positive, we must
have −b < g′ −g by assumption (3.49), so g′ −g + b is positive also. Knowing
this, we see at once that the relationship (g + B) < (g′ + B) is transitive, and that if
(g + B) < (g′ + B) and (h + B) < (h′ + B), then ((g + h) + B) < ((g′ + h′) + B),
proving (1).
(2) follows immediately from (1), since the Cartesian product of any two groups,
lexicographically ordered, is always an ordered group. To prove (3), note that
(a) B is a subgroup of a ﬁnitely generated Abelian group, and so (as proved above)
is ﬁnitely generated.
(b) If g1,...,gn is a system of generators of G, then (g1 + B),...,(gn + B) is a
system of generators of G/B (not necessarily a minimal set of generators), so
that G/B is ﬁnitely generated.
Let {h1 + B,...,hp + B} be a minimal set of generators of G/B. Let T be the
map from G onto G/B deﬁned as follows:
For each g in G there exist unique integers k1,...,kp such that
g + B = k1(h1 + B) + ··· + kp(hp + B).
Using these kj, put
T (g) =

g + B, g −(k1h1 + ··· + kphp)

.
It is not difﬁcult to verify that for any two g, g′ in G we have T (g −g′) =
T (g) −T (g′). Moreover, if T (g) = 0, we must have g + B = 0, so k1,...,kp must
all be zero, and therefore g = 0. This shows that T is an isomorphism of G onto
the Cartesian product group H of G/B and B. Since the rank of a ﬁnite group is
independent of its representation, we also have rank(G) = rank(G/B) + rank(B).
To show that T is also an order isomorphism from (G,<) onto the lexicographically
ordered Cartesian product H of G/B and B, suppose that g′ > g, and write g′ + B
as
g′ + B = k′
1(h1 + B) + ··· + k′
p(hp + B).
Then if g′ + B ̸= g + B we have g′ + B > g + B by (1) above, so

g + B, g −(k1h1 + ··· + kphp)

>

g′ + B, g′ −

k′
1h1 + ··· + k′
php

.
On the other hand, if g′ + B = g + B we have kj = k′
j for all j, and so

g + B, g −(k1h1 + ··· + kphp)

>

g′ + B, g′ −(k1h1 + ··· + kphp)

in this case also. Hence this inequality holds in any case, i.e. T is both an isomor-
phism and an order isomorphism.
□
Assume as above that Inf(G) is non-trivial. Then the condition (3.49) of the pre-
vious lemma holds for the proper subgroup Inf(G) of G. Indeed, if x is inﬁnitesimal

164
3
A Survey of Inference Mechanisms
and y is positive and not inﬁnitesimal, and x < y is false, then y < x. Since x is
inﬁnitesimal there exists some positive z such that mx < z for all integers m. Then
plainly my < z for all positive integers m, and since y is positive this holds for all
negative integers m also. It follows that y is inﬁnitesimal, a contradiction proving
our assertion.
It follows from (2) and (3) above that (G,<) is isomorphic to the lexicograph-
ically ordered Cartesian product H of G/Inf(G) and Inf(G), and that rank(G) =
rank(G/Inf(G)) + rank(Inf(G)). Moreover
(i) G/Inf(G) is non-trivial, i.e. rank(G/Inf(G)) > 0;
(ii) G/Inf(G) has no inﬁnitesimals, i.e. Inf(G/Inf(G)) = {0}.
To prove (i), note that if G/Inf(G) were trivial, i.e. Inf(G) = G, all elements,
and in particular all generators, of G would be inﬁnitesimals. Thus for each gen-
erator gj there would exist a yj in G such that mgj < yj for every signed inte-
ger m. Let y = y1 + ··· + yp be the sum of all these yj. Then y is itself a sum
y = k1g1 + ··· + kpgp and therefore we have
y1 + ··· + yp = k1g1 + ··· + kpgp < y1 + ··· + yp,
a contradiction which shows that G/Inf(G) is non-trivial.
To prove (ii) we argue as follows. Suppose that g + Inf(G) is inﬁnitesimal in
G/Inf(G), i.e. that there exists a positive y + Inf(G) in G/Inf(G) such that m(g +
Inf(G)) < y + Inf(G) for all integers m. This gives mg < y for all integer m, and
then g is plainly inﬁnitesimal in G, so it must belong to Inf(G), i.e. g + Inf(G) must
be the zero element of G/Inf(G), proving (ii).
Since G/Inf(G) is non-trivial by (i), we must have rank(Inf(G)) < rank(G). Now
applying (3) inductively, it follows that G is isomorphic to the lexicographically
ordered Cartesian product of the sequence
G/Inf(G), Inf(G)/Inf2(G), ..., Infk−1(G)/Infk(G), Infk(G)
of groups for each k < rank(G), where by deﬁnition Infi(G) = Inf(Infi−1(G)). By
(ii), each group in this sequence is a ﬁnitely generated Abelian group with no non-
trivial inﬁnitesimals. Since, as was shown above, each such group can be embedded
into the additive group of reals, it follows that G can be embedded into the additive
group of real vectors of dimension rank(G), ordered lexicographically. This is the
key conclusion at which the preceding arguments aimed.
It follows from what has now been established that, given any quantiﬁer-free con-
junction C of statements in the theory of ordered Abelian groups which contains n
distinct variables, C is satisﬁable in some ordered Abelian group if and only if it is
satisﬁed in the additive group of real vectors of dimension n, ordered lexicograph-
ically. But it is easy to reduce the satisﬁability problem for the lexicographically
ordered additive group of real vectors of dimension n to the satisﬁability problem
for the additive group of reals. Indeed, a real vector of dimension n simply consists
of n real numbers x1,...,xn, addition of two such vectors is just addition of their

3.11
Theory of Reals and Single-Valued Continuous Functions
165
individual components, and the condition x < y for two vectors x and y can be
written as the disjunction
x1 < y1 ∨(x1 = y1 & x2 < y2) ∨··· ∨(x1 = y1 & ··· & xn−1 = yn−1 & xn < yn).
This observation shows that the satisﬁability problem for any collection of un-
quantiﬁed statements in the theory of ordered Abelian groups reduces without difﬁ-
culty to the problem of satisfying a corresponding collection of real linear equations
and inequalities. This is the standard problem of linear programming, which can be
tested for solvability using any convenient linear programming algorithm (cf., e.g.,
[IC94]). In conclusion, we have the following.
Corollary 3.1 The collection of unquantiﬁed statements of the theory of ordered
Abelian groups has a decidable satisﬁability problem.
3.11 A Fragment of Analysis: Theory of Reals and Single-Valued
Continuous Functions with Predicates ‘Monotone’,
‘Convex’, ‘Concave’, Real Addition, and Comparison
In this section we study the decision problem for a fragment of real analysis, which,
besides the real operators ‘+’, ‘−’, ‘·’, and ‘/’, also provides predicates express-
ing strict and non-strict monotonicity, concavity, and convexity of continuous real
functions over bounded or unbounded intervals, as well as strict and non-strict com-
parisons ‘>’ and ’⩾’ between real numbers and functions. Decidability of the deci-
sion problem for this unquantiﬁed language, which is called RMCF+, is demon-
strated by proving that if a formula in it is satisﬁable, then it has a model in
which its function-designating variables are mapped into piecewise combinations
of parametrized quadratic polynomial and/or exponential functions, where the pa-
rameters are constrained only by conditions expressible in the decidable language
of real numbers. We recall that the decision problem for RMCF+ has been solved in
[CCG06].
3.11.1 Syntax of RMCF+
The language RMCF+ has two types of variables, namely numerical variables, de-
noted by x,y,... , and function variables, denoted by f,g,... . Numerical and func-
tion variables are supposed to range, respectively, over the set R of real numbers and
the set of one-parameter continuous real functions over R. RMCF+ also provides the
numerical constants 0 and 1 and the function constants 0 and 1.
The language also includes two distinguished symbols, −∞and +∞, which are
restricted to occur only as ‘range deﬁning’ parameters, as explained in the following
deﬁnitions.

166
3
A Survey of Inference Mechanisms
Numerical terms of RMCF+ are deﬁned recursively as follows:4
• every numerical variable x,y,... or constant 0,1 is a numerical term;
• if t1,t2 are numerical terms, then so are (t1 + t2), (t1 −t2), (t1 · t2), and (t1/t2);
• if t is a numerical term and f is a function variable or constant, then f (t) is a
numerical term.
An extended numerical variable (resp. term) is a numerical variable (resp. term)
or one of the symbols −∞and +∞.
Function terms of RMCF+ are deﬁned recursively as follows:
• every unary function variable f,g,... or constant 0 and 1 is a function term;
• if F1,F2 are function terms, then so are (F1 + F2) and (F1 −F2).
An atomic formula of RMCF+ is an expression having one of the following
forms:
t1 = t2,
t1 > t2,
(F1 = F2)[E1,E2],
(F1 > F2)[t1,t2],
Up(F)[E1,E2],
Strict_Up(F)[E1,E2],
Down(F)[E1,E2],
Strict_Down(F)[E1,E2],
Convex(F)[E1,E2],
Strict_Convex(F)[E1,E2],
Concave(F)[E1,E2],
Strict_Concave(F)[E1,E2],
where t1,t2 stand for numerical terms, F1,F2 stand for function terms, and E1,E2
stand for extended numerical terms such that E1 ̸= +∞and E2 ̸= −∞.
A formula of RMCF+ is any propositional combination of atomic formulae, con-
structed using the logical connectives &, ∨, ¬, →, etc.
3.11.2 Semantics of RMCF+
Next we deﬁne the intended semantics of RMCF+.
A (real) assignment M for the language RMCF+ is a map deﬁned over terms
and formulae of RMCF+ in the following way:
Deﬁnition of M for RMCF+-terms
• M x ∈R for every numerical variable x.
• M 0 = 0, M 1 = 1, M (+∞) = +∞, and M (−∞) = −∞.
• For every function variable f , M f is a continuous real function over R.
• M 0 and M 1 are, respectively, the zero function and the constant function of
value 1, i.e. (M 0)(r) = 0 and (M 1)(r) = 1 for every r ∈R.
4Throughout this section, ‘·’ denotes multiplication, often designated by ‘∗’ in the rest of the book.

3.11
Theory of Reals and Single-Valued Continuous Functions
167
• M (t1 ⊙t2) = M (t1) ⊙M (t2), for every numerical term t1 ⊙t2, where ⊙is any
of +, −, ·, and /.
• M (f (t)) = (M f )(M t), for every function variable f and numerical term t.
• M (F1 ⊙F2) is the real function (M F1) ⊙(M F2), where ⊙is either of the
allowed functional operators + and −and (M F1) ⊙(M F2) is deﬁned by the
condition that (M (F1 ⊙F2))(r) = (M F1)(r) ⊙(M F2)(r) for every r ∈R.
Deﬁnition of M for RMCF+-formulae
In the following t1,t2 will stand for numerical terms, E1,E2 for extended nu-
merical terms, and F1,F2 for function terms.
• M (t1 = t2) = true iff M t1 = M t2.
• M (t1 > t2) = true iff M t1 > M t2.
• M ((F1 > F2)[t1,t2]) = true
iff
either M t1 > M t2, or M t1 ⩽M t2 and
(M F1)(r) > (M F2)(r) for every r in [M t1,M t2]. (Observe that for decidabil-
ity purposes literals of type (F1 > F2)[t1,t2] have been restricted to ﬁnite intervals
[t1,t2] only.)
• M ((F1 = F2)[E1,E2]) = true iff either M E1 > M E2, or M E1 ⩽M E2 and
(M F1)(r) = (M F2)(r) for every r in [M E1,M E2]. (Here and below we use
the interval notation [x, y] even if x = −∞and/or y = +∞.)
• M (Up(F)[E1,E2]) = true (resp. M (Strict_Up(F)[E1,E2]) = true)
iff
either
M E1 ⩾M E2, or M E1 < M E2 and the function M F1 is monotone non-
decreasing (resp. strictly increasing) in the interval [M E1,M E2].
• M (Down(F)[E1,E2]) = true (resp. M (Strict_Down(F)[E1,E2]) = true)
iff
ei-
ther M E1 ⩾M E2, or M E1 < M E2 and the function M F1 is monotone non-
increasing (resp. strictly decreasing) in the interval [M E1,M E2].
• M (Convex(F)[E1,E2]) = true (resp. M (Strict_Convex(F)[E1,E2]) = true) iff ei-
ther M E1 ⩾M E2, or M E1 < M E2 and the function M F1 is convex (resp.
strictly convex) in the interval [M E1,M E2].
• M (Concave(F)[E1,E2]) = true (resp. M (Strict_Concave(F)[E1,E2]) = true)
iff either M E1 ⩾M E2, or M E1 < M E2 and the function M F1 is concave
(resp. strictly concave) in the interval [M E1,M E2].
Logical connectives are interpreted in the standard way; thus, for instance,
M (P1 & P2) = (M P1) & (M P2).
Let P be an RMCF+-formula and let M be an assignment for the language
RMCF+. Note once more that we say that M is a model for P iff M (P) = true.
If P has a model, then it is satisﬁable, otherwise it is unsatisﬁable. If P is true in
every RMCF+-assignment, then P is a theorem of RMCF+.5 As usual, two formu-
lae are equisatisﬁable if either both of them are unsatisﬁable, or both of them are
satisﬁable, and the satisﬁability problem for RMCF+ is the problem of ﬁnding an al-
gorithm which can determine whether or not a given RMCF+-formula is satisﬁable.
Such an algorithm is given below.
5Thus to show that a given formula of RMCF+ is a theorem, one can prove that its negation is
unsatisﬁable by any RMCF+-assignment.

168
3
A Survey of Inference Mechanisms
Here are a few examples of statements which can be proved automatically using
this decision algorithm.
A strictly convex curve and a concave curve deﬁned over the same interval can meet
in at most two points.
This statement can be formalized in RMCF+ as follows:
⎛
⎜⎜⎜⎜⎜⎜⎜⎝
Strict_Convex(f )[E1,E2]
& Concave(g)[E1,E2]
&
3
&
i=1(f (xi) = g(xi))
&
3
&
i=1(E1 ⩽xi & xi ⩽E2)
⎞
⎟⎟⎟⎟⎟⎟⎟⎠
→(x1 = x2 ∨x1 = x3 ∨x2 = x3).
A second example is as follows:
Let g be a linear function. Then a function f , deﬁned over the same domain as g, is
strictly convex if and only if f + g is strictly convex.
Introduce a predicate symbol Linear(f )[E1,E2] standing for
Convex(f )[E1,E2] & Concave(f )[E1,E2].
Note that if M is a real assignment for RMCF+, then M (Linear(f )[E1,E2]) =
true if and only if the function M f is linear in the interval [M E1,M E2].
It is plain that the proposition shown above is equivalent to the following formula:
Linear(g)[E1,E2] →

Strict_Convex(f )[E1,E2] ↔Strict_Convex(f + g)[E1,E2]

.
The following is a somewhat more interesting example.
Let f and g be two real functions which take the same values at the endpoints of
a closed interval [a,b]. Assume also that f is strictly convex in [a,b] and that g
is linear in [a,b]. Then f (c) < g(c) holds at each point c interior to the interval
[a,b].
This proposition can be formalized in the following way in the language RMCF+.

Strict_Convex(f )[x1,x2] & Linear(g)[x1,x2] & f (x1) = g(x1)
& f (x2) = g(x2) & x2 > x & x > x1

→

g(x) > f (x)

.

3.11
Theory of Reals and Single-Valued Continuous Functions
169
3.11.3 Preparing a Set of RMCF+ Statements for Satisﬁability
Testing
We shall prove the decidability of formulae of RMCF+ using a series of satisﬁability-
preserving steps which reduce the satisﬁability problem for RMCF+ to a more easily
decidable satisﬁability problem for an unquantiﬁed set of statements involving real
numbers only.
We begin by noting that the decidability problem for RMCF+ can be reduced in
the usual way to that for statements which are conjunctions of basic literals, where
each conjunct must have one of the following forms:
x = y + w,
x = y · w,
x > y,
y = f (x),
(f = g + h)[z1,z2],
(f > g)[x,y],
(¬)Up(f )[z1,z2],
(¬)Strict_Up(f )[z1,z2],
(¬)Down(f )[z1,z2],
(¬)Strict_Down(f )[z1,z2],
(¬)Convex(f )[z1,z2], (¬)Strict_Convex(f )[z1,z2],
(¬)Concave(f )[z1,z2], (¬)Strict_Concave(f )[z1,z2].
Here x,y,w stand for numerical variables or constants, z1,z2 for extended numer-
ical variables (where z1 is not equal to +∞nor z2 to −∞), f,g,h for function
variables or constants, and the expression (¬)A denotes both the un-negated and
negated literals A and (¬A). Note that reduction of the full set of constructs allowed
in RMCF+ to the somewhat more limited set seen above requires application of the
following equivalences to eliminate subtraction, division, and various negated cases:
(f1 = f2 −f3)[z1,z2] ↔(f2 = f1 + f3)[z1,z2],
(f1 = f2)[z1,z2] ↔(f1 = f2 + 0)[z1,z2],
t1 = t2 −t3 ↔t2 = t1 + t3,
t1 = t2 ↔t1 = t2 + 0,
t1 = t2/t3 ↔(t3 ̸= 0) & (t2 = t1 · t3),
t1 ̸= t2 ↔(t2 > t1) ∨(t1 > t2),

¬(t1 > t2)

↔(t1 = t2) ∨(t2 > t1).
It is also easy to eliminate the negated forms of the predicates Up, Down, Convex,
and Concave and the negated forms of the strict versions of these predicates. For
example, to re-express the assertion (¬Up(f )[z1,z2]), we can simply introduce two
new variables x and y representing real numbers, and replace (¬Up(f )[z1,z2]) by
x > y & z2 ⩾x & y ⩾z1 & f (y) > f (x).
We leave it to the reader to verify that something quite similar to this can be done
for the negations of all the relevant predicates.

170
3
A Survey of Inference Mechanisms
In further preparation for what follows, we deﬁne a variable x appearing in one
of our formulae to be a domain variable if it appears either in a term y = f (x)
or as one of the z1 or z2 in a term like (f = g + h)[z1,z2], Up(f )[z1,z2], or
Strict_Concave(f )[z1,z2], etc. We can assume without loss of generality that for each
such domain variable and for every function variable f there exists a variable y for
which a conjunct y = f (x) appears in our collection. (This y simply represents the
value of f on the real value of x.) Indeed, if there is no such clause for f and x, we
can simply introduce a new variable y and add y = f (x) to our collection of con-
juncts. It should be obvious to the reader that this addition preserves satisﬁability.
Next we make the following observation. Let x1,...,xr be the domain variables
which appear in our set of conjuncts. If a model M of these conjuncts exists, then
M x1,...,M xr will be real numbers, of which some may be equal, and where the
distinct values on this list will appear in some order along the real axis, and so di-
vide it into subintervals. Each possible ordering of M x1,...,M xr will correspond
to some permutation of x1,...,xr which puts M x1,...,M xr into increasing or-
der, and so to some collection of conditions xi < xi+1 or xi = xi+1, which need to
be written for all i = 1,...,r −1. Where conditions xi = xi+1 appear, implying
that two or more domain variables are equal, we identify all these variables with the
ﬁrst of them, and then also add statements y = z + 0 for any variables y,z appear-
ing in conjuncts y = f (xi), z = f (xj) involving domain variables that have been
identiﬁed. It is understood that all possible orders of M x1,...,M xr, and all possi-
ble choices of inequalities xi < xi+1 or equalities xi = xi+1 must be considered. If
any of these alternatives leads to a set of conjuncts which can be satisﬁed, then our
original set of conjuncts can be satisﬁed, otherwise not. This observation allows us
to focus on each of these orderings separately, and so to consider sets of conjuncts
supplied with clauses x > y which determine the relative order of all the domain
variables that appear.
Note that this last preparatory step can be expensive, so special care must be
taken in implementing it. Nevertheless it clearly can be implemented, and after it is
applied we are left with a set of conjuncts satisfying the two following conditions:
(i) Each conjunct in the set must have one of the following forms:
x = y + w,
x = y · w,
x > y,
y = f (x),
(f = g + h)[z1,z2], (f > g)[x,y]
Up(f )[z1,z2],
Strict_Up(f )[z1,z2],
Down(f )[z1,z2],
Strict_Down(f )[z1,z2],
Convex(f )[z1,z2],
Strict_Convex(f )[z1,z2],
Concave(f )[z1,z2], Strict_Concave(f )[z1,z2],
(3.50)
where x,y,w stand for numerical variables or constants, z1,z2 for extended
numerical variables (but with z1 not equal to +∞nor z2 to −∞), and f,g,h
for function variables.

3.11
Theory of Reals and Single-Valued Continuous Functions
171
(ii) The collection x1,...,xr of domain variables present in this set is arranged in
a sequence for which a conjunct xi < xi+1 is present for all i = 1,...,r −1.
Removal of function literals
Having simpliﬁed the satisﬁability problem for RMCF+ in the manner just de-
scribed, we will now show how to reduce it to a solvable satisﬁability problem
involving real numbers only. We use the following idea. If a set of conjuncts of the
form (3.50) has a model M , the domain variables x1,...,xr which appear in it will
be represented by real numbers M x1,...,M xr which occur in strictly increasing
order. Consider a conjunct like Up(f )[x,y] or Convex(f )[x,y] or (f > g)[x,y]. For
simplicity, at least in the case of the ﬁrst two conjuncts, we ﬁrst suppose that neither
of x and y is inﬁnite and that the interval [x,y] is nonempty. Then we must have
x = xj and y = xk for some j and k such that j < k. For f to be non-decreasing
in the range [xj,xk], it is necessary and sufﬁcient that it should be non-decreasing
in each of the subranges [xi,xi+1] for each i from j to k −1. For f to be convex
in the range [xj,xk], it is necessary and sufﬁcient that it should be convex in the
overlapping set of ranges [xi,xi+2] for each i from j to k −2 or, if k = j + 1,
convex in [xj,xj+1]. (The proof of this elementary fact is left to the reader.) For f
to dominate g (pointwise) in [xj,xk], i.e. f (x) > g(x) for each x in [xj,xk], it is
necessary and sufﬁcient that f dominates g in each of the subintervals [xi,xi+1],
for each i from j to k −1. For f to be non-decreasing in [xi,xi+1] it is necessary
that we should have f (xi) ⩽f (xi+1), and if f is piecewise linear with corners only
at the points xi this is also sufﬁcient. Hence the necessary and sufﬁcient condition
for such a non-decreasing function to exist in [xj,xk] is
f (xj) ⩽f (xj+1) & ··· & f (xk−1) ⩽f (xk).
For f to be convex in [xi,xi+2] it is necessary that the slope of the line connecting
the points (xi,f (xi)) and (xi+1,f (xi+1)) be no larger than that of the line con-
necting the points (xi,f (xi)) and (xi+2,f (xi+2)). This condition can be written
algebraically as
f (xi+1) −f (xi)
xi+1 −xi
⩽f (xi+2) −f (xi)
xi+2 −xi
or, equivalently, as

f (xi+1) −f (xi)

· (xi+2 −xi) ⩽

f (xi+2) −f (xi)

· (xi+1 −xi).
Conjoining all these conditions gives (when k > j + 1)

f (xj+1) −f (xj)

· (xj+2 −xj) ⩽

f (xj+2) −f (xj)

· (xj+1 −xj) &
···
&

f (xk−1) −f (xk−2)

· (xk −xk−2) ⩽

f (xk) −f (xk−2)

· (xk−1 −xk−2).
If f is piecewise linear with corners only at the points xi this is also sufﬁcient.
Hence the conjunction just shown is necessary and sufﬁcient for such a convex func-
tion to exist. Plainly the same remarks carry over to the non-increasing and concave

172
3
A Survey of Inference Mechanisms
cases if we simply reverse the inequalities appearing in the last few conditions dis-
played.
For f to dominate g in [xi,xi+1] it is necessary that we should have f (xi) >
g(xi) and f (xi+1) > g(xi+1) and if both f and g are piecewise linear with corners
only at the points xi this is also sufﬁcient. Therefore the necessary and sufﬁcient
condition for f to dominate g in the interval [xj,xk] is
f (xj) > g(xj) & ··· & f (xk) > g(xk).
In the strictly increasing case the necessary conditions become
f (xj) < f (xj+1) & ··· & f (xk−1) < f (xk).
A piecewise linear function satisfying these conditions is also strictly increasing,
so these conditions are those necessary and sufﬁcient for a function with the given
values, and strictly increasing over the range [xj,xk], to exist. For there to exist a
strictly convex function in this range, the conditions

f (xj+1) −f (xj)

· (xj+2 −xj) <

f (xj+2) −f (xj)

· (xj+1 −xj) &
···
&

f (xk−1) −f (xk−2)

· (xk −xk−2) <

f (xk) −f (xk−2)

· (xk−1 −xk−2)
are necessary. However, a piecewise linear function satisfying these conditions is not
yet strictly convex, as the slope of such a function is constant, rather than increasing,
in each of its intervals of linearity. But it is easy to correct this, simply by passing
to functions which are piecewise quadratic (still with corners only at the points
xi), rather than linear. Such functions are determined by their end values f (xi) and
f (xi+1) and by one auxiliary value f (x) at any point x interior to [xi,xi+1]. It is
convenient to let x be the midpoint x′
i of the interval [xi,xi+1]. Then for f to be
convex it is necessary that
2 · f

x′
i

⩽f (xi) + f (xi+1),
and for f to be strictly convex it is necessary that
2 · f

x′
i

< f (xi) + f (xi+1).
(Here and below, the same remarks apply, with appropriate changes of sign, to the
concave and strictly concave cases also.) If the function f is known to be non-
decreasing in the interval [xi,xi+1] (because [xi,xi+1] is included in some interval
[xj,xk] for which a statement Up(f )[xj,xk] appears among our conjuncts), we must
also write the conditions
f (xi) ⩽f

x′
i

& f

x′
i

⩽f (xi+1).

3.11
Theory of Reals and Single-Valued Continuous Functions
173
Similarly, if f is known to be non-increasing we must write the conditions
f (xi) ⩾f

x′
i

& f

x′
i

⩾f (xi+1).
Likewise, if f is known to dominate g in [xi,xi+1] we must add the condition
f

x′
i

> g

x′
i

.
Note that if f is known to be non-decreasing and strictly convex (resp. strictly con-
cave) in an interval [xi,xi+1], the strict inequality
f (xi) < f (xi+1)
follows, since this is implied by the three known conditions
• f (xi) ⩽f (x′
i),
• f (x′
i) ⩽f (xi+1), and
• 2 · f (x′
i) < f (xi) + f (xi+1) (resp., 2 · f (x′
i) > f (xi) + f (xi+1)).
Plainly, the strict inequalities
f (xi) > f

x′
i

and
f

x′
i

> f (xi+1)
must hold as well. In all such cases we will therefore replace
f (xi) ⩽f (xi+1), f (xi) ⩽f

x′
i

, f

x′
i

⩽f (xi+1)
by
f (xi) < f (xi+1), f (xi) < f

x′
i

, f

x′
i

< f (xi+1),
respectively, in our set of conjuncts, and similarly for intervals in which f is known
to be monotone non-increasing and strictly convex or concave. After these supple-
mentary replacements, we can be sure that f must be strictly monotone in every
interval [xi,xi+1] in which it needs to be both monotone and strictly convex or con-
cave.
As already remarked, to model correctly conjuncts of the types Strict_Convex
and Strict_Concave in the whole ﬁnite range [x1,xr], we add a very small quadratic
polynomial of the form
ci · (x −xi) · (xi+1 −x)
vanishing at the two endpoints of the interval [xi,xi+1] to the linear function we
initially have in each such interval at which strict concavity or convexity is required.
The small constant ci should be chosen to be negative if strict convexity is required,
but positive if strict concavity is required. Since this sign will always be the same as
that of the difference
di = 2 · f

x′
i

−f (xi) −f (xi+1),

174
3
A Survey of Inference Mechanisms
we can always take ci = ϵ · di, where ϵ is any sufﬁciently small positive constant.
Note that this will never spoil either the monotonicity or strict monotonicity of f
in the interval affected, since if ϵ is small enough strict monotonicity will never
be affected, while the adjustments described in the preceding paragraph ensure that
strict monotonicity rather than simple monotonicity will be known in every interval
in which strict convexity or concavity is also required. Likewise, domination of g
by f is not spoiled either, since ϵ can be taken small enough to maintain g and f
separated in the interval affected.
It follows that the simple, purely algebraic inequalities on the points x1,...,xr,
the intermediate midpoints x′
1,...,x′
r−1, and the corresponding function values
f (x1),...,f (xr) and f (x′
1),...,f (x′
r−1) derived in the two preceding paragraphs
are both necessary and sufﬁcient for the existence of a continuous function satisfy-
ing all the monotonicity and convexity conditions from which they were derived, at
least in the ﬁnite interval [x1,xr]. We shall now extend this result to the two inﬁnite
end-intervals [−∞,x1] and [xr,+∞], thereby deriving a set of purely algebraic
conditions fully equivalent to the initially given monotonicity and convexity condi-
tions. It will then follow immediately that replacing the monotonicity and convexity
conditions by the algebraic conditions derived from them replaces our initial set of
conjuncts by an equisatisﬁable set.
Of the two inﬁnite end-intervals, ﬁrst consider [xr,+∞]. Choose the two auxil-
iary points xr+1 and xr+2 in this interval, satisfying the inequalities
xr < xr+1
and
xr+1 < xr+2.
Then we can write monotonicity and convexity conditions as above for the val-
ues f (xr−1), f (xr), f (xr+1), and f (xr+2). As previously, if f is both mono-
tone non-decreasing and strictly concave or convex in [xr,+∞], it follows that
f (xr) < f (xr+1) and f (xr+1) < f (xr+2), so we replace the monotonicity inequal-
ities f (xr) ⩽f (xr+1) and f (xr+1) ⩽f (xr+2) by their strict versions in this case.
Then we can take f to be piecewise linear with corners at the points xr, xr+1, and
xr+2, extending f to the inﬁnite range [xr+2,+∞] with the same slope that it has
on the interval [xr+1,xr+2]. This deﬁnition satisﬁes all the monotonicity and con-
vexity conditions already present, except for that of strict convexity (or concavity)
in the intervals [xr,xr+1],[xr+1,xr+2], and [xr+2,+∞], if this is required. But, as
in the cases considered above, these strict conditions can be forced in [xr,xr+1] and
[xr+1,xr+2] by adding a sufﬁciently small quadratic term, whereas in the interval
[xr+2,+∞] we add the decaying exponential
ϵdr ·

exp(−xr+2) −exp(−x)

instead, where dr = 2·f (xr+1)−f (xr)−f (xr+2) and, as before, ϵ is an extremely
small positive number. This has the same convexity properties as the quadratic term
seen above, and, for ϵ sufﬁciently small, is also without effect on the monotonicity
properties of every strictly monotone linear function.
We leave it to the reader to verify that the same argument applies to the second
inﬁnite end-interval [−∞,x1], but by introducing two auxiliary points x−1,x0 in

3.11
Theory of Reals and Single-Valued Continuous Functions
175
this interval, which satisfy the inequalities x−1 < x0 and x0 < x1. It follows that the
conditions on the points x−1,x0,x1,...,xr,xr+1,xr+2, the intermediate midpoints
x′
1,...,x′
r−1, and function values f (xj) and f (x′
i), for j = −1,0,...,r + 1,r + 2
and i = 1,...,r −1, that we have stated are necessary and sufﬁcient for the exis-
tence of a continuous function having these values at the stated points and all the
monotonicity and convexity properties from which these conditions were derived.
Since all the piecewise quadratic and exponential functions f of which we make
use are determined linearly by their values y = f (x) at points x which appear ex-
plicitly in our algorithm, any condition of the form (f = g +h)[z1,z2] which appears
in our initial collection of conjuncts can be replaced by writing the corresponding
conditions f (x) = g(x) + h(x) for all of the domain variables appearing in these
conjuncts.
We now summarize the results obtained in the last few paragraphs, putting them
into an obviously programmable form.
Let a collection of conjuncts of the form (3.50) with domain variables x1,...,xr
be given, and suppose that these satisfy the conditions (i) and (ii) found in the
paragraph containing (3.50). Introduce additional variables x′
i satisfying x′
i = (xi +
xi+1)/2, for each i = 1,...,r −1, and also x′
r, x′
r+1, x′
0 and x′
−1 satisfying
x′
r = xr + 1,
x′
r+1 = xr + 2,
x′
0 = x1 −1,
x′
−1 = x1 −2.
For each variable xj and x′
j in this extended set, and each function symbol f ap-
pearing in the set (3.50) of conjuncts for which there exists no conjunct of the form
yf
j = f (xj) or y′
j
f = f (x′
j), introduce a new variable to play the role of yf
j or y′
j
f ,
along with the missing conjunct. Then replace all the conjuncts appearing in lines 3
through 7 of (3.50) in the following ways:
(a) Replace each conjunct (f = g + h)[z1,z2] by the conditions yf
j = yg
j + yh
j and
y′
j
f = y′
j
g + y′
j
h, for all xj and x′
j belonging to the ﬁnite interval [z1,z2]. (A
slight adaptation of this formulation, which we leave to the reader to work out,
is needed in the case of the two inﬁnite end-intervals [−∞,x1] and [xr,+∞].)
(b) Replace each conjunct (f > g)[x,y] by the conditions yf
j > yg
j and y′
j
f > y′
j
g,
for all xj and x′
j belonging to the interval [x,y]. (We recall that in this case the
interval [x,y] is restricted to be ﬁnite.)
(c) Replace each conjunct Up(f )[z1,z2] (resp. Strict_Up(f )[z1,z2]) by the conditions
yf
j ⩽y′
j
f and y′
j
f ⩽yf
j+1 (resp. yj f < y′
j
f and y′
j
f < yf
j+1), for all subinter-
vals [xj,xj+1] of the ﬁnite interval [z1,z2]. (A slight adaptation of this formu-
lation, which we leave to the reader to work out, is needed in the case of the two
inﬁnite end-intervals [−∞,x1] and [xr,+∞].)
(d) Replace each conjunct Down(f )[z1,z2] (resp. Strict_Down(f )[z1,z2]) by the con-
ditions yf
j ⩾y′
j
f and y′
j
f ⩾yf
j+1 (resp. yf
j > y′
j
f and y′
j
f > yf
j+1), for all
subintervals [xj,xj+1] of the ﬁnite interval [z1,z2]. (A slight adaptation of this
formulation, which we leave to the reader to work out, is needed in the case of
the two inﬁnite end-intervals [−∞,x1] and [xr,+∞].)

176
3
A Survey of Inference Mechanisms
(e) Replace each conjunct Convex(f )[z1,z2] (resp. Strict_Convex(f )[z1,z2]) by the
conditions

yf
i+1 −yf
i

· (xi+2 −xi) ⩽

yf
i+2 −yf
i

· (xi+1 −xi)
and
2 · y′
i
f ⩽yf
i + yf
i+1
(resp. the same conditions, but with the inequality signs ⩽changed to strict
inequality signs ‘<’), the ﬁrst replacement being made for each subinterval
[xi,xi+2] of the ﬁnite interval [z1,z2], and the second for each subinterval
[xi,xi+1] of the interval [z1,z2]. (This formulation must be adapted in the man-
ner sketched previously to the cases of the two inﬁnite end-intervals [−∞,x1]
and [xr,+∞]. We leave to the reader to formulate the required details.) More-
over, if a subinterval [xi,xi+1] of a [z1,z2] for which strict convexity is asserted
is also one to which the predicate Up(f )[xi,xi+1] or Down(f )[xi,xi+1] applies in
virtue of a replacement (c) or (d), change the unstrict inequalities replacing these
latter predicates to strict inequalities.
(f) Replace each conjunct Concave(f )[z1,z2] (resp. Strict_Concave(f )[z1,z2]) by the
conditions

yf
i+1 −yf
i

· (xi+2 −xi) ⩾

yf
i+2 −yf
i

· (xi+1 −xi)
and
2 · y′
i
f ⩾yf
i + yf
i+1
(resp. the same conditions, but with the inequality signs ⩾changed to strict
inequality signs ‘>’), the ﬁrst replacement being made for each subinterval
[xi,xi+2] of the interval [z1,z2], and the second for each subinterval [xi,xi+1]
of the interval [z1,z2]. (This formulation must be adapted in the manner
sketched previously to the cases of the two inﬁnite end-intervals [−∞,x1] and
[xr,+∞]. We leave to the reader to formulate the required details.) Moreover, if
a subinterval [xj,xj+1] of a [z1,z2] for which strict convexity is asserted is also
one to which the predicate Up(f )[xi,xi+1] or Down(f )[xi,xi+1] applies in virtue
of a replacement (c) or (d), change the unstrict inequalities replacing these latter
predicates to strict inequalities.
These replacements convert our original set (3.50) of conjuncts into an equisat-
isﬁable set of purely algebraic conditions.
To conclude our work we need an algorithm capable of determining whether the
set of algebraic conditions (all of which are either linear or quadratic) to which the
foregoing algorithm reduces our original set of conjuncts is satisﬁable or unsatis-
ﬁable. Since this problem is a special case of the decision algorithm for Tarski’s
quantiﬁed algebraic language of real numbers [Tar51], such an algorithm certainly
exists. This observation completes our proof that the language RMCF+ has a decid-
able satisﬁability problem.

3.12
The Resolution Method for Pure Predicate-Calculus Proving
177
A Final Example
To make the foregoing considerations somewhat more vivid,
consider the way in which the proof of the third sample proposition listed above re-
sults from our algorithm, which can just as easily be used to prove it in the following
generalized form.
Let f and g be two real functions which take the same values at the endpoints of
a closed interval [a,b]. Assume also that f is strictly convex in [a,b] and that g
is concave in [a,b]. Then f (c) < g(c) holds at each point c interior to the interval
[a,b].
This can be formalized as follows:

Strict_Convex(f )[x1,x2] & Concave(g)[x1,x2] & f (x1) = g(x1)
& f (x2) = g(x2) & x2 > x & x > x1

→

g(x) > f (x)

.
In this case the domain variables are x1,x2, and x, and it is clear that the only order
in which they need to be considered is x1,x,x2. The negation of our theorem is then
the conjunction of
Strict_Convex(f )[x1,x2] & Concave(g)[x1,x2]
& f (x1) = g(x1) & f (x2) = g(x2) & f (x) ⩾g(x).
The rules stated above replace the ﬁrst two conjuncts by the algebraic conditions

f (x) −f (x1)

· (x2 −x1) <

f (x2) −f (x1)

· (x −x1)
and

g(x) −g(x1)

· (x2 −x1) ⩾

g(x2) −g(x1)

· (x −x1).
The other algebraic conditions generated are not needed; these two conditions, to-
gether with the facts f (x1) = g(x1) and f (x2) = g(x2) plainly imply that f (x) <
g(x), which is inconsistent with f (x) ⩾g(x), an inconsistency which the Tarski
algorithm alluded to above will detect.
3.12 The Resolution Method for Pure Predicate-Calculus
Proving
Since all the set-theoretic concepts which we use can be expressed within the pred-
icate calculus by adding predicate symbols and axioms, without any new rules of
inference being needed, all the proofs in which we are interested can in principle
be given without leaving this calculus. This observation has focussed attention on
techniques for automatic discovery of predicate proofs. A very extensive literature

178
3
A Survey of Inference Mechanisms
concerning this built up over the past four decades. This section will explain some
of the principal techniques used for this, even though (for reasons that will be set
forth at the end of the section) the authors believe that the size of the collections of
formulae which such techniques need to explore prevents them from contributing
more than marginally to a veriﬁer of the kind in which we are interested.
The standard predicate-calculus proof-search technique begins by putting all of
the formulae of a collection C of predicate statements to be tested for satisﬁability
ﬁrst into prenex, and then into Skolem, normal form. All of the formulae in C then
have the form
(∀x1,x2,...,xn | P),
where P contains no quantiﬁers. Propositional calculus rules can then be used to
rewrite the ‘matrix’ P of this formula as a conjunction of disjunctions, each dis-
junction containing only atomic formulae, some of them possibly negated. We can
then use the predicate rule
(∀x1,x2,...,xn | P & Q) ↔

(∀x1,x2,...,xn | P) & (∀x1,x2,...,xn | Q)

to break up the conjunctions, thereby reducing C to an equisatisﬁable set consisting
only of formulae of the form
(∀x1,x2,...,xn | A1 ∨··· ∨Ak),
where each Aj is an atomic formula built from the predicate and function symbols
(including constants) which appear in C, or possibly the negative of such an atomic
formula. It is this standardized conjunctive normal form input on which predicate-
proof searches then concentrate.
Herbrand’s theorem tells us that such a collection C is unsatisﬁable if and only
if a propositional contradiction can be derived by substituting elements e of the
Herbrand universe for the variables of the resulting formulae in all possible ways.
These elements are all the terms that can be formed using the constants and function
symbols which appear in the formulae of C (one initial constant being added if no
such constant is initially present in C). But if one tries to base a search technique
directly on this observation, the problem of the exponential growth of the Herbrand
universe with the length of the terms allowed arises immediately. For example, even
if C contains only one constant d and two monadic function symbols f and g, the
collection of possible Herbrand terms includes all the combinations
f

f

g

f

g

g

···(d)···

,
whose number clearly grows exponentially with their allowed length.
Some more efﬁcient way of searching the Herbrand universe is therefore vital.
The input formulae themselves must somehow be made to guide the search. A gen-
eral technique for accomplishing this, the so-called resolution method, was intro-
duced by J. Alan Robinson in 1965 in his well-known paper [Rob65]. We can best
explain how this works by stepping back for a moment from the predicate to the
simpler propositional calculus.

3.12
The Resolution Method for Pure Predicate-Calculus Proving
179
3.12.1 Resolution in the Propositional Calculus
Suppose then that we are given a collection C of formulae F of the propositional
calculus, each such F being a disjunction of propositional symbols, some possibly
negated. The resolution algorithm works on such sets by repeatedly ﬁnding pairs of
formulae F1, F2 which have not yet been examined and which both contain some
common atom A, but with opposite sign, and so have forms like
A ∨G1
and
(¬A) ∨G2
where G1 and G2 are subdisjunctions, and deducing the formula
G1 ∨G2
from them (this is an instance of the tautology ((A →B) & (¬A →D)) →(B ∨
D)).
If an empty proposition can be deduced in this way, then the original collection
C of propositions is clearly unsatisﬁable, since the last resolution step must involve
two directly opposed propositions A, ¬A. We will show that, conversely, if the
original collection C of propositions is unsatisﬁable, then an empty proposition can
be deduced by resolution. Thus the ability to deduce an empty proposition via some
sequence of resolution steps is necessary and sufﬁcient for our original collection C
of propositions to be unsatisﬁable.
To establish this claim, we proceed by induction on the total length, in characters,
of all the propositions in C. So suppose that C is unsatisﬁable and that no empty
proposition can be deduced from C by resolution, but that for every unsatisﬁable
collection C′ of propositions of smaller total length there must exist a sequence of
resolution steps which produces an empty proposition from C′.
Choose some propositional variable A that occurs in C. Clearly C has no model
in which A has the truth value true, so if we drop all the statements of C in which
A occurs non-negated (since these are already satisﬁed by the choice of true for
the truth-value of A), and use the tautology ((¬true) ∨B) ↔B to remove A from
all the remaining statements of C, we get a collection C′ of statements, clearly of
smaller total length than C, which is unsatisﬁable. Hence, by inductive assumption,
there must exist some sequence of resolution steps which, applied to C′, yield the
empty proposition. But then the very same sequence s1 of resolutions, applied to
the statements of C′ but before occurrences of ¬A are removed, will succeed in
deducing ¬A by resolution.
In just the same way we can form a collection C′′ of statements by dropping all
the statements of C in which A occurs negated and drop A from the remaining state-
ments. Since C′′ must also be unsatisﬁable, we can argue just as in the preceding
paragraph to show that there must exist a deduction-by-resolution sequence s2 from
C which produces the single-atom conclusion A. Putting s1 and s2 one after an-
other, followed by a resolution step involving the formulae ¬A and A, clearly gives
a deduction by resolution from C which produces the empty proposition from C,
verifying our claim.

180
3
A Survey of Inference Mechanisms
Suppose that we write the result of a resolution step acting on two formulae F1
and F2 and involving the propositional symbol A as F1[A]F2. Then our overall
sequence of resolution steps can be written as
...

F1[A]F2

[B]

F3[D]F4

...,
the ﬁnal result being an empty formula. Since each initial formula F of C occurs in
this display only some ﬁnite number of times, we can give our sequence of resolu-
tions the following form:
(i) Each of the formulae of C is copied some number of times.
(ii) The resulting formulae, and the results produced from them by resolution steps,
are used only once as inputs to further resolution steps.
(iii) An empty proposition results.
3.12.2 Resolution and Syntactic Uniﬁcation in the Predicate
Calculus
In the predicate case, handled in the manner characterized by Herbrand’s theorem,
each of the resolution steps described above will involve an atomic formula A and
its negative ¬A. Both of these will be obtained by substituting elements of the Her-
brand universe for variables appearing in atomic formulae A1 and A2 that are parts
of formulae
F1 = A1 ∨B1 ∨···
and
F2 = (¬A2) ∨B2 ∨···
of C. The substitutions applied must clearly make A1 and A2 identical. Robinson’s
predicate resolution method results from a close inspection of conditions necessary
for there to exist a substitution
x1 →t1,...,xn →tn
of Herbrand tj terms for the variables x1,...,xn appearing in A1 and A2 which
does this, i.e. makes the two substituted forms identical.
To see what is involved, note that since such substitutions can never change the
predicate symbols P1 and P2 with which the atomic formulae A1 and A2 begin,
identity can never be produced if these two predicate symbols differ. More generally,
if we walk the syntax trees of A1 and A2 in parallel down from their roots, identity
can never result by substitution if we ever encounter a pair of corresponding nodes
at which different function symbols or constants f1 and f2 appear. In this case we
say that our parallel tree-walks reveal a conﬂict. If this never happens, then, when
we reach an end-branch in one or another of these trees, we must ﬁnd either

3.12
The Resolution Method for Pure Predicate-Calculus Proving
181
(a) a variable x of the ﬁrst tree matched to a compound term t of the second tree
(momentarily, in this section, we call ‘compound’ any term which is not a vari-
able, even if it is just a constant);
(b) a variable y of the second tree matched to a compound term t′ of the ﬁrst tree;
(c) a variable x of the ﬁrst tree matched to a variable y of the second tree.
Only in these cases can there exist a substitution for the variables of A1 and A2
which makes the two substituted forms identical. It also follows that (a), (b), and (c)
together give us an explicit representation of the most general substitution S (called
the Most General Uniﬁer of A1 and A2 and written Mgu(A1,A2)) for the variables
of A1 and A2 which makes the two substituted forms identical. This is obtained
simply by collecting all the substitutions
x →t,...,y →t′,...,x →y,...
(3.51)
which appear in (a), (b), and (c), respectively, and whose role is to convert each
of the pairs [x,t] into an identity x = t after the indicated substitutions have been
performed for all variables.
As shown by the pair of formulae
P(x,x)
and
P

f (y),g(y)

,
it is entirely possible that the collection (3.51) should contain multiple substitutions
x →t1, x →t2 with the same left-hand sides. In this case, we must ﬁnd further
substitutions which make t1 and t2 identical. This is done by walking the syntax trees
of t1 and t2 in parallel, and applying the collection process just described, following
which we can drop x →t2 from our collection since the additional substitutions
collected make it equivalent to x →t1. Since this process replaces substitutions
x →t2 with substitutions having smaller right-hand sides it can be continued to
completion, eventually either revealing a conﬂict or giving us a collection (3.51) of
substitutions in which each left-hand variable x appears in just one substitution.
However, as the following example shows, one more condition must be satisﬁed
for the presumptive substitution (3.51) to be legal, i.e. to deﬁne a pattern of sub-
stitutions which allows all the substitutions (3.51) into equalities. Consider the two
formulae
P

x,f (x)

and
P

f (y),y

.
Applying the procedure just described to these two formulae yields the substitutions
x →f (y),
y →f (x).
The problem here is that there exists a cycle of variables x,y,x such that each
appears in the term to be substituted for the previous variable, i.e. y appears in the
term to be substituted for x and x in the term to be substituted for y. Any such
substitution of compound terms x′ and y′ for x and y, respectively, would give rise
to identities
x′ = f (y′)
and
y′ = f (x′),
and hence to x′ = f (f (x′)), which is impossible.

182
3
A Survey of Inference Mechanisms
The same argument applies in any case in which the collected substitutions (3.51)
allow any cycle of variables such that each appears in the term to be substituted for
the previous variable. On the other hand, if there is no such cycle of variables, then
we can arrange the collection of all variables appearing in (3.51) in an order such
that each variable on the left comes later in order than all the variables appearing on
the right, and then progressive application of all these substitutions to the variables
appearing on the right clearly reduces all of them to identities. In this case we say
that a most general uniﬁer Mgu(A1,A2) exists for the two atomic formulae A1,A2;
otherwise we say that uniﬁcation fails, either by conﬂict or by a cycle.
We can just as easily ﬁnd the most general substitution which reduces multi-
ple pairs A1,A2, B1,B2 to equality simultaneously. An easy way to do this is to
introduce an otherwise unused artiﬁcial symbol Y, and then apply the uniﬁcation
technique just described to the pair of formulae
Y(A1,B1,...)
and
Y(A2,B2,...).
Clearly a substitution makes these two formulae identical if and only if it reduces
all the pairs A1,A2, B1,B2 to equality simultaneously.
For use in the next section we will need a somewhat more precise statement
concerning the relationship between the most general uniﬁer of two sets of atoms or
compound terms, and the other substitutions which unify these same atoms/terms.
In deriving this statement it will be convenient to write
Mgu

[t1,...,tn],[t′
1,...,t′
n]

(3.52)
for the most general simultaneous uniﬁer of all the atoms/terms tj with the corre-
sponding t′
j, and
All_u

[t1,...,tn],[t′
1,...,t′
n]

(3.53)
for the collection of all substitutions which unify all the atoms/terms tj simultane-
ously with the corresponding t′
j. Using these notations, take any tj, t′
j in the se-
quences shown. If these are atomic formulae or terms and have distinct initial sym-
bols, uniﬁcation is impossible. Otherwise if they are atoms/terms and have identical
initial symbols, they will unify if and only if their arguments unify; hence we can
replace tj and t′
j by their argument sequences in (3.52) without changing its value.
The same argument gives the same conclusion for (3.53).
If no further replacements of the kind just described are possible, then for each
pair tj,t′
j either tj and t′
j must be identical constants, or at least one of tj, t′
j must be
a variable. We collect all pairs in which both are variables, which the substitutions
in which we are interested must convert to identical terms, choose a representa-
tive for each of the groups of equivalent variables thereby deﬁned, and, in all other
terms/atoms, replace all occurrences of variables having such representative by their
representative. Again it is obvious that this transformation of the tj and t′
j changes
neither (3.52) nor (3.53). Once this standardization of variables has been accom-
plished, we collect all cases in which a given variable v appears as a tj or t′
j and

3.12
The Resolution Method for Pure Predicate-Calculus Proving
183
is mapped to a non-trivial t′
j or tj. All but one of these pairs are removed from the
argument sequences of (3.52) and (3.53), and replaced with other pairs implying
that each of the remaining terms must be equal to the term retained. Again this is a
transformation that changes neither (3.52) nor (3.53).
The step just described may allow the whole sequence of steps that we have
described to restart, so we keep iterating till none of the steps we have described
are possible. At this point each tj in (3.52) will be matched either to an identical
constant t′
j, or one of tj and t′
j will be a variable that appears only once, while the
other is a variable or term. Neither (3.52) nor (3.53) will have changed.
Whenever we have a corresponding pair tj,t′
j in which one member is a vari-
able, we say that the term expands the variable. We shall call variables x which ap-
pear somewhere in t1,...,tn,t′
1,...,t′
n, but do not have representatives and are not
matched to non-trivial terms in pairs tj,t′
j base variables. We complete our calcula-
tion of Mgu by repeatedly replacing all variables that expand into non-trivial terms t
by these terms t. Again this transformation changes neither (3.52) nor (3.53). Since
we have seen that uniﬁcation is only possible if there is no cycle of expansions,
this process must converge, at which point every remaining variable will either be a
base variable, have a base variable as its representative, or be expanded into a term
in which only base variables appear. Now let S be a member of the set (3.53) of
substitutions, i.e. a substitution which makes each tj equivalent to its corresponding
t′
j. If tj and t′
j are both variables then it is clear that S must substitute the same term
for both of them. If one of them, say tj, is a variable and the other t′
j is a term, then
it is clear that the term which S substitutes for tj must be the same as that which
results by ﬁrst substituting t′
j for tj, and then substituting Sx for each base vari-
able x remaining in t′
j. Thus, if we let S0 designate the restriction of S to the base
variables, it follows that the substitution S (regarded as a mapping of variables into
terms) factors as the product M ◦S0, where M is the most general uniﬁer (3.52). We
state this observation as a lemma.
Lemma 3.2 If two sequences t1,...,tn and t′
1,...,t′
n consisting of atomic formulae
and/or terms can be uniﬁed by a substitution S which makes each tj identical to its
corresponding t′
j, then each substitution S having this effect can be written as a
product S = M ◦S0, where M is the most general uniﬁer
Mgu

[t1,...,tn],

t′
1,...,t′
n

,
and the substitution S0 replaces some of the base variables of M by other variables
or non-trivial terms. Conversely, by applying any substitution S of the form M ◦S0
to all of the tj and t′
j we make each tj identical to its corresponding t′
j.
The preceding discussion of resolution and uniﬁcation gives us the following
general way of handling the problem of ﬁnding a Herbrand contradiction which will
show that a collection C of predicate formulae given in our normal form
(∀x1,x2,...,xn | A1 ∨··· ∨Ak)
(3.54)
is unsatisﬁable.

184
3
A Survey of Inference Mechanisms
(Res-i) Guess, or search for, the pattern in which resolution steps can (or will) occur
in a sequence of such steps (for substituted instances of our collection C of
formulae) leading to a propositional contradiction.
(Res-ii) The guess (or search) (i) implies that designated atomic formulae A oc-
curring in C, perhaps in multiple copies of formulae like (3.54) (but with the
quantiﬁers in (3.54) removed), must unify in the pattern determined by the se-
quence of resolution steps. Check that this uniﬁcation is actually possible. If so,
the substitutions forced by the required uniﬁcations identify a collection of ele-
ments in the Herbrand universe which allow the pattern of resolutions found in
step (i) to be executed, and thereby show that the set C of predicate statements
is unsatisﬁable.
We can use the formula

∃x
 
∀y | P(x,y)

→

∀y
 
∃x | P(x,y)

as a particularly simple example of the proof method just described. The negative
of this implication, rewritten as a pair of clauses in Skolem normal form, is

∀y | P(d1,y)

,

∀x
 
¬P(x, d2)

.
(3.55)
The substitutions x →d1 and y →d2 unify P(d1,y) with ¬P(x, d2), giving
P(d1, d2) and ¬P(d1, d2), a clear contradiction which proves the unsatisﬁability of
(3.55), and so the universal validity of our original formula. Note that if we started
with the reverse implication

∀y
 
∃x | P(x,y)

→

∃x
 
∀y | P(x,y)

whose Skolemized inverse is

∀y | P

f1(y),y

,

∀x
 
¬P

x,f2(x)

,
we would need to unify P(f1(y),y)) and P(x,f2(x))), which leads to the (cyclic)
impossibility
x →f1(y),
y →f2(x).
This shows that the reverse implication is not universally valid.
A great variety of methods which aim to reduce the cost of the combinatorial
search implicit in (Res-i) and (Res-ii) above have been published. Some are deter-
ministic pruning schemes, which aim to eliminate whole subtrees of the search tree
by showing that none of their descendant searches can succeed. Others are standard-
ization techniques, which eliminate redundant work by performing the necessary
searches in an order and manner allowing many redundancies to be eliminated, per-
haps by detecting and bypassing them. Still others are heuristics guided by guesses
concerning favourable uniﬁcations and sets of statements. These may involve some

3.12
The Resolution Method for Pure Predicate-Calculus Proving
185
implicit or explicit notion of the distance separating an intermediate set of resolution
steps from the full set needed to demonstrate unsatisﬁability.
A short summary of some of these methods will be given below. The commonly
encountered Horn case, in which each quantiﬁer-stripped formula of the input con-
tains at most one non-negated predicate atom, serves to illustrate some of the issues
involved. Since every substituted instance of a Horn formula is also Horn, we can
use the observation made in our earlier discussion of Horn sets in the propositional
case to establish that only resolutions involving at least one positive unit formula
need be considered, and that if the null clause can be deduced it can be deduced
using just one of the negative unit formulae, and that only once.
We will use the set of (quantiﬁer-stripped) formulae seen below as an example.
Their unsatisﬁability expresses the following theorem of elementary group theory:
in a group with left inverse and a left identity, each element also has a right in-
verse. In these formulae, the normal group-theoretic operation x ∗y is recast in pure
predicate form by introducing a predicate P(x,y,z) representing the relationship
z = x ∗y. Inspection of the formulae displayed below shows that only this predicate
is needed. The ﬁrst two statements, respectively, express the hypotheses ‘there is a
left inverse’ and ‘there is a left identity’. The next two statements allow reassocia-
tion of products to the left and to the right. The ﬁnal statement is the negative of the
desired conclusion: ‘there is an element a with no right inverse’.
P

i(x),x,e

P(e,x,x)

¬P(x,y,u)

∨

¬P(y,z,v)

∨

¬P(u,z,w)

∨P(x,v,w)

¬P(x,y,u)

∨

¬P(y,z,v)

∨

¬P(x,v,w)

∨P(u,z,x)
¬P(a,x,e)
Since the set C of formulae shown is evidently Horn, we can (in accordance with
our earlier discussion of Horn sets) regard the two ﬁrst formulae as ‘inputs’, the
last formula as a ‘goal’, and the two remaining formulae as ‘multiplication rules’
which allow triples of inputs to be combined (if the simultaneous uniﬁcations re-
quired for this are possible) to produce new unit-formula inputs. We must then aim
to ﬁnd a sequence of such multiplications which reaches the negative of our ‘goal’
formula. This is a path-ﬁnding problem resembling others studied in the artiﬁcial
intelligence literature. It is easily organized for efﬁciency in the following way. At
any given moment a collection Uc of positive unit formulae will be available. We
form all triples of these formulae which can be combined using the two available
‘multiplication rules’ and generate new positive unit formulae. This step is repeated
until either our goal formula is reached or the resulting computation becomes infea-
sible.
This way of looking at things reveals a (deep) pitfall that can affect resolution
searches, even in particularly favourable Horn cases like the one under considera-
tion. Since each of our two ‘multiplication rules’ allows the available inputs to be
combined in up to three possible ways, each cycle of ‘multiplication’ can in the

186
3
A Survey of Inference Mechanisms
worst conceivable case increase the number n of available atomic formulae to as
much as 2n3 + n. Even starting from n = 2 this iteration increases very rapidly:
2;18;11,682;3,188,464,624,818;... Unless this exponential increase in the size
of our search space is strongly limited by the failure of most of the uniﬁcations
required by the ‘multiplication’ operations considered, we could hardly expect to
search more than four levels deep without using some other idea to prune our search
very drastically.
Deduction succeeds in the example shown above, in part because a quite ‘shal-
low’ proof is possible. This is a proof involving only two successive multiplications.
Even without additional search optimizations, the proof is found after 75 uniﬁcation
attempts, of which seven successfully generate new atomic formulae. Two, rather
than 16, formulae are added to the list of available atoms at the end of the ﬁrst cy-
cle of multiplication, so the branching factor is not nearly as bad as is indicated by
the worst-case estimate given above, making it reasonable to estimate that proofs as
much as six levels deep may be within reach of the resolution method in the pure
Horn-clause case. The proof found is
P

i

i(X)

, e,X

from:

P

i(X),X, e

,P

i(X),X,e

,P(e,X,X)

using:

P(X,Y,U),P(Y,Z,V ),P(U,Z,W),P(X,V,W)

P

X,i(X),e

from:

P

i

i(X)

, e,X

,P(e,X,X),P

i(X),X, e

using:

P(X,Y,U),P(Y,Z,V ),P(X,V,W),P(U,Z,W)

The following formulae are generated but not used in the proof found:
P(e, e, e),
P

i(e),X,X

,
P

i(e), e,e

,
P

i

i

i(X)

,X, e

,
P

i

i

i(e)

,e, e

,
P

i

i(e)

,X,X

,
P

i

i(e)

,e, e

,
P

i

i

i

i(X)

,e,X

, P

i

i

i(e)

,X,X

.
Note that a few of these formulae are special cases of others or of input formulae,
and so could be omitted. For example, P(e, e, e) is a special case of P(e,X,X), and
P(i(e), e, e) is a special case of P(i(e),X,X).
Examination of the above list of useless atomic formulae reveals that some of
them are subsumed by, i.e. are special cases of others, and hence visibly unneces-
sary. For example, P(e, e, e) is a special case of P(e,X,X), and P(i(i(e)), e, e)
is a special case of P(i(i(e)),X,X). The uniﬁcation procedure can be used to test
for and eliminate these redundancies. If this is done, the number of uniﬁcations at-
tempted in the preceding example falls to 87, and only the following four unneeded
atomic formulae are generated:
P

i(e),X,X

,
P

i

i

i(X)

,X, e

, P

i

i(e)

,X,X

,
P

i

i

i

i(X)

, e,X

, P

i

i

i(e)

,X,X

.
The following is a second Horn example (taken, like the example above, from
[CL73, p. 160]).

3.12
The Resolution Method for Pure Predicate-Calculus Proving
187
D(x,x)
L(m, a)

¬P(x)

∨D

g(x),x


¬P(x)

∨L

m,g(x)


¬P(x)

∨L

g(x),x


¬D(x, a)

∨P(x)

¬D(x,y)

∨

¬D(y,z)

∨D(x,z)

¬L(m,x)

∨

¬L(x, a)

∨D

f (x),x


¬L(m,x)

∨

¬L(x, a)

∨

¬P

f (x)

∨Q
¬Q
Here we have two inputs, seven multiplication rules (of these, four involve just
one input, two involve two inputs each, and one involves three inputs), and one
target, which in this case is a disjunction of three atoms rather than a single atom.
Deduction succeeds in this case after ﬁve levels of multiplication, involving 123
uniﬁcation attempts of which 17 generate new atomic formulae, eight being used in
the proof found, which is
P(a)
from:

D(X,X)

using:

D(X, a),P(X)

D

g(a), a

from:

P(a)

using:

P(X),D

g(X),X

L

m,g(a)

from:

P(a)

using:

P(X),L

m,g(X)

L

g(a), a

from:

P(a)

using:

P(X),L(g(X),X)

D

f

g(a)

,g(a)

from:

L

m,g(a)

,L

g(a), a

using:

L(m,X),L(X,a),D

f (X),X

D

f

g(a)

, a

from:

D

f

g(a)

,g(a)

,D

g(a), a

using:

D(X,Y),D(Y,Z),D(X,Z)

P

f

g(a)

from:

D

f

g(a)

, a

using:

D(X, a),P(X)

Q
from:

L

m,g(a)

,L

g(a), a

,P

f

g(a)

using:

L(m,X),L(X,a),P

f (X)

,Q


188
3
A Survey of Inference Mechanisms
No subsumption cases occur during the processing of this example. Here the
branching factor is seen to be quite small. The following atomic formulae are gen-
erated but not used in the ﬁnal proof.
P

g(a)

,
D

f

g(a)

,g(a)

,
D

g

g(a)

,g(a)

,
L

m,g

g(a)

,
L

g

g(a)

,g(a)

, D

g

g(a)

,a

,
D

g

f

g(a)

,f

g(a)

,
L

m,g

f

g(a)

, L

g

f

g(a)

,f

g(a)

, P

g

g(a)

.
In this case the search efﬁciency can be improved by using a simple heuristic,
which attempts to ﬁnd ‘easy’ proofs (those involving relatively short formulae) be-
fore trying harder ones. As new atomic formulae are generated, we prefer the shorter
of the new formulae over the longer by sorting the newly generated formulae into
order of increasing string length and adding just one new formula, the shortest, to
the collection of inputs used during each cycle of multiplication. With this improve-
ment we ﬁnd the same proof after 48 uniﬁcation attempts of which 12 generate new
atomic formulae.
Another small group-theoretic example from Chang and Lee shows some of the
difﬁculties that slow or block resolution proofs in more general cases. This states
the axioms of group theory in the same ternary form as above, but also introduces
a predicate S(x) which asserts that x is an element of a particular subgroup of the
group implicit in the axioms. An axiom states that this subgroup is closed under
the operation x ∗I(y), and we are simply required to prove that the inverse of an
element b of the subgroup belongs to the subgroup. The input axioms are
P

i(x),x, e

P

x,i(x), e

P(e,x,x)
P(x,e,x)
S(b)
¬S

i(b)


¬P(x,y,u)

∨

¬P(y,z,v)

∨

¬P(u,z,w)

∨P(x,v,w)

¬P(x,y,u)

∨

¬P(y,z,v)

∨

¬P(x,v,w)

∨P(u,z,w)

¬S(x)

∨

¬S(y)

∨

¬P

x,i(y),z

∨S(z).
The proof found involves just two steps:
S(e)
from:

S(b),S(b),P

X,i(X), e

using:

S(X),S(Y),P

X,i(Y),Z

,S(Z)

S

I(b)

from:

S(e),S(b),P(e,X,X)

using:

S(X),S(Y),P

X,i(Y),Z

,S(Z)

.

3.12
The Resolution Method for Pure Predicate-Calculus Proving
189
However, the search required makes many uniﬁcation attempts and generates
many useless formulae having forms like
P

e,X,i

i

i

i

i

i(X)

P

i(X),X,i

i

i(e)

P

i

i

i

i(e)

, e,i(e)

etc.
In this case the ‘easy proofs’ heuristic considered above greatly improves search
efﬁciency, ﬁnding a proof after 139 uniﬁcation attempts and the generation of 12
atomic formulae.
Next we present a technique that realizes the ideas of (Res-i) and (Res-ii) very
directly in non-Horn cases. Before giving the details of this scheme, we need to
take notice of a technical point overlooked in the preceding discussion. For reso-
lution to work as claimed, even at the propositional level, duplicate occurrences of
propositional symbols must be eliminated. For example, the two statements
A ∨A,
(¬A) ∨(¬A)
(3.56)
are clearly contradictory and a null proposition follows immediately by resolution
if these are simpliﬁed to A, ¬A. But if we resolve without eliminating duplicates,
resolution leads only to A ∨(¬A) and thence back to the original statements (3.56),
and so we can never reach an empty proposition. Both in the purely propositional
and the predicate cases, we must remember to eliminate duplicate atomic formulae
whenever resolution produces them.
Here is one way in which the steps (Res-i) and (Res-ii) above can be organized.
(a) We begin by guessing the number of times each of our input formulae (3.54)
need to be used to generate distinct substituted instances in the refutation by
resolution for which we are searching. This creates an initial collection C of
formulae F which we strip of quantiﬁers. Distinct variables are used in each of
these formulae, and the set Initial_atoms of all atomic formulae A which they
contain is formed. Each such A is associated with the F in C in which it appears,
and with the sign (negated or non-negated) with which it appears. The F in C
are given some order, which is then extended to a compatible ordering of all the
atomic formulae A in these F .
(b) A preliminary survey is made of all the pairs A1,A2 in Initial_atoms, to deter-
mine the cases in which A1 and A2 can be uniﬁed. These are collected into two
maps: can_rev(A1) holds all the A2 of sign opposite to A1 with which A1 can
unify, and can_same(A1) holds all the A2 of the same sign as A1 with which
A1 can unify.
(c) Once these maps have been collected we search for a combinatorial pattern rep-
resenting a successful refutation by resolution. These must have the following
properties:
(c.i) Each atomic formula A1 must be mapped into an element either of
can_rev(A1) or can_same(A1) by a single-valued mapping match(A1).

190
3
A Survey of Inference Mechanisms
(c.ii) If A2 = match(A1) belongs to can_rev(A1), then we must have A1 =
match(A2).
(c.iii) It must be possible to unify all the atomic formulae A1 with the corre-
sponding match(A1) simultaneously.
(c.iv) No two formulae F1, F2 in C containing atomic formulae A1, match(A1)
of opposite sign can be connected by a prior chain of links between
matching atomic formulae of opposite signs.
(c.v) The collection of propositions generated from the F in C by identifying
A1 and A2 whenever A2 = match(A1) is unsatisﬁable.
Review of the conditions (c.i–c.v) shows them to be equivalent to the condition
that corresponding substitutions into the formulae of C deﬁne a group of resolution
steps leading to an empty statement. The matches for which match(A1) and A1 have
opposite signs correspond to resolution steps involving the atomic formulae A1 and
match(A1); the matches for which match(A1) and A1 are of identical sign corre-
spond to eliminations of duplicate atomic formulae. Condition (c.ii) states that the
pairs of atomic formulae A1, match(A1) entering into resolution steps are symmet-
rically related. Condition (c.i) states that all the necessary uniﬁcations must be indi-
vidually possible; (c.iii) states that all must be simultaneously possible. Condition
(c.iv) excludes tautologous intermediate formulae containing two identical atoms of
opposite sign. Condition (c.v) ensures that the pattern of resolutions chosen can lead
to a null formula.
The uniﬁability check required in step (c.iii) above can be organized in the fol-
lowing way.
(c.iii.i) All the formulae F in C are parsed, and each node in the resulting syntax
trees is marked with its associated predicate symbol, function symbol, or
variable, and with all its descendant variables.
(c.iii.ii) When two groups of atomic formulae A1,A2,...,An and B1,B2,...,Bn
are to be checked for simultaneous uniﬁability, we collect all the top-level
terms t1,...,tm and t′
1,...,t′
m from them in order, form two corresponding
atomic formulae Z(t1,...,tm) and Z(t′
1,...,t′
m) using an auxiliary predi-
cate symbol Z, and test these two formulae for uniﬁability. All of the nec-
essary operations can be managed efﬁciently using lists and sets of pointers
to syntax tree nodes. Topological sorting can be used to check that a pur-
ported collection of substitutions leads to no cycles among variables.
To eliminate the repeated examination of failed uniﬁcation patterns, some of the
optimization heuristics that have been used in the many other resolution approaches
described in the literature can be worked into the scheme presented above.
3.13 Universally Quantiﬁed Predicate Sentences Involving
Function Symbols of One Argument Only
We shall now use some of the ideas developed in the preceding section to derive an
algorithm for determining the satisﬁability of sets of pure predicate sentences of the

3.13
Universally Quantiﬁed Predicate Sentences Involving Function Symbols
191
restricted form
(∀x | P),
(3.57)
whose ‘matrix’ P is a Boolean combination of atomic formulae A(t1,t2,...,tk),
where the argument terms tj must be built from constants and from the universally
quantiﬁed variable using monadic function symbols only.
A

x,f (x),...,f

g

f

h

f

f (x)

is an example of such an atomic formula. Note that Skolemization of formulae

∀y | (∃x1,x2,...,xn | Q)

,
(3.58)
where the matrix Q is subject to the same restriction, always leads to formulae of
this kind, so that the algorithm we present will also decide the validity of formulae
(3.58).
We begin our analysis by transforming P propositionally into a conjunction of
disjunctions of atomic formulae, each of which is either negated or non-negated.
Since the predicate identity
(∀y | R & R′) ↔

(∀y | R) & (∀y | R′)

can be used to decompose the conjunctions, we can suppose that each of the matrices
P in (3.57) is a disjunction of negated and non-negated atomic formulae.
Herbrand’s theorem ensures us that (3.57) is satisﬁable if and only if no propo-
sitional contradiction arises among any of the instances of (3.57) formed by substi-
tuting elements of the Herbrand universe H for the x in (3.57). The appearance of
such a contradiction will reﬂect the pattern in which substituted instances of atomic
formulae A and B appearing in the matrices P of such formulae become equal. For
two such A and B to be made equal by any substitution they must unify. The dis-
cussion of uniﬁcation developed in the preceding Sect. 3.12.2 tells us that two such
atoms A and B (initially transformed to have different variables x and y) will only
unify in one of the following cases:
(i) They are made equal by replacing one of x and y by the other.
(ii) They are made equal by replacing the variable x by some constant term t and
the variable y by some other constant term t′.
(iii) They are made equal by replacing the variable x by some term formed from the
variable y using the available monadic function symbols, for example replacing
x by f (g(f (h(f (f (y)))))).
(iv) They are made equal by replacing the variable y by some term formed from
the variable x using the available function symbols.
In case (i) the two atomic formulae are equal if written using the same variable
x. In case (ii) we have A(t) = B(t′) for the two constant terms t and t′. In case (iii)
we have the identity A(t(y)) = B(y) for some term t(y) formed using the available
function symbols, and similarly in case (iv) we have A(x) = B(t(x)). In the ﬁrst

192
3
A Survey of Inference Mechanisms
of these two cases we say that B is expressible in terms of A. in the second that
A is expressible in terms of B. Note that expressibility in this sense is transitive.
Moreover, if any B is expressible in terms of two distinct A1 and A2, then there is
clearly a substitution which makes A1 and A2 identical, so one of A1 and A2 must
be expressible in terms of the other. Thus in each group of atomic formulae related
by a chain of expressibility relationships there must be one, which we shall call A,
in terms of which all the others are expressible, and which is such that A is not
expressible in terms of any other atomic formula B. We call such A basic atomic
formulae. Note that given two different basic atomic formulae A and B, there can
be no substitutions for the variables x and y they contain which makes A and B
identical.
We now take the matrices P of all the formulae of our collection, and introduce
a new monadic predicate symbol Q(x) for each basic atomic formula A which ap-
pears in them. All the other atomic formulae B can then be expressed uniquely in
terms of these Q, as Q(t), where t is a term formed by applying the available func-
tion symbols to the variable x appearing in B, or possibly t is a constant term formed
by applying these function symbols to a constant. Let P ′ by the matrix formed by
replacing each of the atomic formulae in P by its corresponding Q, or, if A is not
basic, by the appropriate Q(t). Since each basic atom A(x) in P has a unique cor-
responding Q, it is clear that if the set of formulae (3.57) has a model, so does the
set of formulae
(∀x | P ′)
(3.59)
derived from it in the manner just explained. Suppose conversely that (3.59) has
a model M , whose universe we may, by Herbrand’s theorem, take to be the Her-
brand universe H . For each predicate symbol Q appearing in one of the formulae
(3.59), let QM be the Boolean function corresponding to it in the model M . If
Q(x) has been used to represent a basic atomic formula A(t1(x),...,tk(x)), deﬁne
AM (x1,...,xk) to be Q(x) for all tuples x1,...,xk of arguments in the Herbrand
universe H which have the form [t1(x),...,tk(x)] for some x in H , but to be
false for all other argument tuples. Since the tuples [t1(x),...,tk(x)] which appear
as arguments of different basic atomic formulae in (3.57) must always be different if
the predicate symbols A appearing in these formulae are the same (since otherwise
some substitution would unify the distinct basic atomic formulae, which is impos-
sible), it follows that this deﬁnition of Boolean values is unique. Since no other ar-
gument tuples appear in (3.57), it follows that this assignment of Boolean mappings
to the predicate symbols appearing in (3.57) gives a model of (3.57). Thus the sets
(3.57) and (3.59) of formulae are equisatisﬁable. But all of the predicate symbols
which appear in (3.59) are monadic, so the satisﬁability of (3.59) can be decided by
a classical procedure described, e.g., in [Ack54]. It follows at once that the reduc-
tion which we have just described, used together with this procedure, decides the
satisﬁability of sets (3.57) of formulae.

3.14
The Knuth–Bendix Equational Method
193
3.14 The Knuth–Bendix Equational Method
3.14.1 Overview of the Method
The equational method introduced by Donald E. Knuth and Peter B. Bendix in their
well-known paper [KB70] offers a general and systematic treatment of the algebraic
process of ‘simpliﬁcation’.
It assumes that all the hypotheses to be dealt with are universally quantiﬁed equa-
tions of the form
(∀x1,x2,...,xn | t = t′),
and determines whether these entail another such identity t0 = t′
0.
Given a set C of identities t = t′ whose implications are to be analyzed, one
begins by arranging them in a ‘downhill’ direction t ⇝t′, with the ‘simpler’ side
of each identity on the right. The identities will always be used in this direction.
One then determines whether these simpliﬁcations always lead to a unique ultimate
reduction of every term t.
For this approach to be possible, some systematic notion of ‘expression com-
plexity’ is required. Knuth and Bendix deﬁne such a complexity measure by adding
up the total number of symbols in each expression, possibly with auxiliary assigned
‘weights’. Expressions having the same total weight are ordered in a suitable lex-
icographic way. For this easy notion of complexity to be stable in the presence of
substitution for variables, in a manner which guarantees that if exp is ‘simpler’ than
exp′ then every substituted form of exp is ‘simpler’ than the corresponding substi-
tuted form of exp′, we also require that the number of occurrences of every variable
in t be at least as large as the corresponding number in t′. (Thus, systems includ-
ing identities like f (x,y,y) = f (x,x,y) are out of reach of the Knuth–Bendix
method.)
When a clear direction of simpliﬁcation can be deﬁned in the way explained,
we can reduce any expression exp to (a possibly non-unique) ‘canonical’ or ‘irre-
ducible’ form by repeatedly (and nondeterministically) ﬁnding some subexpression
e of exp which is identical with a substituted version of the left-hand side of some
simpliﬁcation t ⇝t′, and then replacing e within exp by the corresponding substi-
tuted version e′ of the right-hand side t′ of this same simpliﬁcation. If the irreducible
form of each expression turns out to be unique, we will have an easy test for deter-
mining whether the equality of two expressions exp, exp′ is entailed by a collection
of identities: reduce both exp and exp′ to their irreducible forms, and see if these are
equal. Thus the essential point is to be able to determine when the irreducible form
of every expression exp is unique.
Given an expression e which contains another expression e′ as a subexpression,
we can write e as a ...e′ ...b, where a ... (resp. ...b) is the part of e that precedes
(resp. follows) its subexpression e′. If s denotes a substitution xj →ej which re-
places each of a collection of variables by some expression and e denotes an expres-
sion in which these variables appear, we will write ‘(es)’ for the result of replacing

194
3
A Survey of Inference Mechanisms
all occurrences of each of the variables xj by the corresponding ej. We temporarily
reserve the letter s (possibly subscripted) for substitutions of this kind.
We will see that the irreducible form of an expression e, i.e. a simpliﬁcation of e
which cannot be simpliﬁed further, can only be non-unique when e contains some
subexpression se, which in turn has a sub-sub-expression sse, having the following
property:
(i) se must have the form (ts1), where t is the left-hand side of some simpliﬁcation
t ⇝t′ and s1 is a substitution (as above).
(ii) sse must have the form (T s2), where T is the left-hand side of some simpliﬁ-
cation T ⇝T ′ and s2 is also a substitution (as above).
(iii) In this situation we can write e in either of two ways, namely either as
a ...(ts1)...b or as a ...a′ ...(T s2)...b′ ...b, and accordingly can simplify
it in either of two ways, namely either to
a ...(t′s1)...b
or to
a ...a′ ...(T ′s2)...b′ ...b.
These can only fail to have the same irreducible form if a′ ...(T ′s2)...b′ and
(t′s1) can have different irreducible forms.
Now we can note that (ts1) (resp. (T s2)) is a substituted form of the entire left-
hand side of the simpliﬁcation t ⇝t′ (resp. T ⇝T ′). Hence there can exist an
expression e having two different ultimate simpliﬁcations only if there are a pair of
simpliﬁcations t ⇝t′ and T ⇝T ′ such that
(a) Some subexpression s of t can be ‘uniﬁed’ with T by a pair s1,s2 of substitu-
tions s which make ss1 and T s2 syntactically identical.
(b) The two simpliﬁcations (t′s1) and a′ ...(T ′s2)...b′ of t thereby generated
(where t ≡a′′ ...s ...b′′) have distinct irreducible forms r1 and r2.
In this case the identity r1 = r2 is plainly a consequence of our initial set of
identities since it is obtained by simplifying (t′s1) in two different ways. It may be
possible to arrange this ‘new’ identity as a simpliﬁcation r1 ⇝r2 and add it to our
initial set of simpliﬁcations, thereby getting an expanded set E of simpliﬁcations,
in which plainly r1 and r2 have the same simpliﬁed form r2. If we are lucky, this
expanded set of simpliﬁcations will give every expression a unique irreducible form,
in which case we say that E has ‘attained completion’. If this is not the case, we can
repeat the procedure just described to ﬁnd a further expansion of E, and hope that
E attains completion after some ﬁnite number of expansion steps.
As this process goes along we must always arrange the equalities t = t′ with
which we are working as reductions t ⇝t′, which means that some appropriate way
of ordering the terms e appearing in these clauses must always be kept available. In
many cases the new equations r = r′ generated will ﬁt immediately into the ordering
of terms used previously. In such situations the term-ordering used need not be
changed. If this is not the case, a new ordering can be adopted at any time (since the
role of the ordering is merely subsidiary, i.e. serves only to deﬁne the direction of
reduction). But when a new ordering is adopted one may well want to examine the
existing equations to see if any can be dropped.

3.14
The Knuth–Bendix Equational Method
195
3.14.2 Details
3.14.2.1 Ordering of Ground Terms
We suppose that a collection C of (implicitly universal) identities t = t′ is given, and
form the Herbrand universe H of all terms that can be built from the constants of
C using the function symbols which appear in C. (As usual, we add one ‘priming’
constant if none is available in C.) Assume that a non-negative integer weight w(f )
is associated with each constant c and function symbol f , and that all the constants
and function symbols have been arranged in some order, so that we can write f > g
if f comes later than g in this order. Function symbols of more than one argument
can have 0 weight, but we assume that at most one monadic function symbol f can
have 0 weight and that all constants have positive weight.
Given this assumption we can deﬁne the weight w(t) of a ground term (i.e. a
term containing no variables, only constants and function symbols) to be the sum of
the weights of all its constants and function symbols.
Note that each argument a of a term t of the form f (a1,...,an) must have weight
smaller than w(t) unless f is the unique monadic operator L with weight 0, in which
case a and L(a) have the same weight.
Using these weights we order the Herbrand universe H of ground terms t as
follows:
if
w(t1) > w(t2) then t1 > t2 (i.e., lighter terms come ﬁrst)
elseif w(t1) = w(t2), t1 ≡f (a1,...,an), t2 ≡g(b1,...,bm) and f > g
then
t1 > t2 (i.e. terms of the same weight are ordered by their principal operator;
note that either n or m can be zero, i.e. either f or g can be a constant rather
than a function symbol);
elseif w(t1) = w(t2), t1 ≡f (a1,...,an) and t2 ≡f (b1,...,bn), then t1 > t2
if (a1,...,an) > (b1,...,bn) in lexicographic order (i.e. terms of the same
weight and principal operator are given the lexicographic order of their argu-
ment strings).
This recursive deﬁnition assigns a position in order to all ground terms. It is
legitimate since in its recursive third case each of the arguments of a term like t1 ≡
f (a1,...,an) is either of smaller weight than t1, or shorter than t1.
Lemma 3.3 The ordering of ground terms just deﬁned is a well-ordering, i.e. there
can exist no inﬁnite descending sequence t1 > t2 > t3 > ··· of ground terms.
Proof Suppose that such an inﬁnite descending chain did exist. Then the weights
w(tj) are also non-increasing, and so would necessarily reach their lower limit at
some point. Hence we can assume without loss of generality that all the tj have the
same weight and can assume inductively that this is the smallest weight for which
an inﬁnite descending sequence
t1 > t2 > ···

196
3
A Survey of Inference Mechanisms
can exist. Consider the sequence fj of leading operators of the terms tj. These
must be non-increasing (in our assumed ordering of all function symbols of ground
terms), and so must also reach their lower limit, so we can assume without loss of
generality that all the fj are identical. Then the fj cannot be constants (i.e. param-
eterless function symbols) since if they were we would have fj = tj, contradicting
t1 > t2 > ···. If they are all function symbols of positive weight, then their argument
sequences (a1,a2,...,an) are sequences of elements of smaller weight descending
in lexicographic order, and so by our inductive assumption there cannot be inﬁnitely
many of them. It remains to consider the case in which all the fj are monadic oper-
ators f of weight 0, in which case f must be the last operator in the assigned order
of operators. In this case, we can write the tj as f nj (bj), where nj designates the
number of successive occurrences of f as the principal operator of tj. Since all the
bj are of equal weight, and f is the last operator in the assigned order of operators,
f nj (bj) > f nk(bk) if nj > nk. Hence the integers nj must form a non-increasing
sequence, which will therefore reach its lower limit n at some point. In this case, we
can assume without loss of generality that all the nj are equal, so that our sequence
of terms has the form f n(bj) for some ﬁxed n, where all bj have lead operator dif-
ferent from f . Since the bj must form a decreasing sequence of terms, it follows by
what we have already shown that the sequence bj cannot be inﬁnite, so that we have
a contradiction in all cases.
□
3.14.2.2 A Substitution-Invariant Partial Ordering of Non-ground Terms
To extend the ordering described above to non-ground terms, we give each variable
the smallest weight of any constant, and order non-ground terms as follows:
if
w(t1) > w(t2) and each variable occurs at least as often in t1 as it does in t2,
then t1 > t2;
elseif w(t1) = w(t2) and each variable occurs at least as often in t1 as it does in t2,
while t1 ≡f (...) and t2 ≡g(...) with f > g (in the ordering of operators), then
t1 > t2
elseif t1 ≡f (a1,...,an) and t2 ≡f (b1,...,bn), then we order t1 and t2 in the
lexicographic order of their argument strings.
Otherwise t2 > t1 (symmetrically), or t1 and t2 are unrelated (which we shall write
as t1? t2).
g(x,y,y) and f (x,y,y) give us an example of unrelated terms.
Plainly, if t1 > t2 and we make a common substitution s for the variables that
they contain, writing the substituted results as (t1s) and (t2s), then (t1s) > (t2s).
Corollary 3.2 There can be no inﬁnite descending sequence t1 > t2 > ··· of non-
ground terms.
Proof Let s replace all variables by some constant c of smallest possible weight.
Then (t1s) > (t2s) > ··· will be an inﬁnite descending chain of ground terms, which
is impossible.
□

3.14
The Knuth–Bendix Equational Method
197
Lemma 3.4 If t1 > t2 and t is obtained from a term t′ by replacing one occurrence
of t1 by an occurrence of t2, then t′ > t.
Proof Plainly w(t′) ⩾w(t), and every variable occurs at least as often in t′ as in t.
Also, at every level in its syntax tree, t′ has function arguments which are at least as
large as those of t.
□
3.14.2.3 Sets of Reductions
A set of identities t = t′ is called a set of reductions (relative to an ordering of all
ground and non-ground terms) if, for each of its members, we have either t > t′ or
t′ > t. In this case we order the identities so that the left side is larger, and write the
identity t = t′ as t ⇝t′.
We can use the elementary identities of group theory as an example of this notion.
These involve just two operators, multiplication and inversion, which for ease of
reading we write in their usual inﬁx and postﬁx forms as x ⋆y and x−, respectively.
The standard elementary identities can be written as simpliﬁcations, and then
e ⋆x ⇝x;
x−⋆x ⇝e;
(x ⋆y) ⋆z ⇝x ⋆(y ⋆z).
To order terms formed using these operators, we can use weights w(e) =
1,w(−) = 0,w(⋆) = 0, and let ‘−’ be the last operator. Note that in this order-
ing of terms (x ⋆y) ⋆z > x ⋆(y ⋆z) since the leading operators are the same, but
x ⋆y > x. That is, ‘right-associations are smaller’.
Given a general set of reductions, any term t can be fully reduced (in a non-
unique way) by the following procedure;

Repeatedly ﬁnd a subterm of t having the form (ℓs), where s is a substitution and
ℓ⇝r is some reduction, and replace this subterm by (rs).
This process must terminate, since it steadily reduces t, in the ordering of terms
we have deﬁned.
Deﬁnition 3.3 If every t reduces to a unique ﬁnal form t∗, the set of reductions is
said to be complete.
We write t ⇛t′ if t has a subterm of the form (ℓs) where ℓ⇝r is some member
of our set of reductions, and t′ is obtained by replacing this subterm by (rs).
We write t ⇛∗t′ if some such sequence of subterm reductions leads from t to t′.
Lemma 3.5 (The ‘PPW’—‘Permanent parting of the ways’ Lemma) A set of re-
ductions is complete iff, given any t and two reductions t ⇝t′ and t ⇝t′′ of it, there
exists some t∗such that t′ ⇛∗t∗, t′′ ⇛∗t∗.

198
3
A Survey of Inference Mechanisms
Proof If a set of reductions is complete, and t∗is the unique full reduction of t,
where t ⇝t′ and t ⇝t′′, then clearly t′ ⇛∗t∗and t′′ ⇛∗t∗. Conversely, suppose
that t can be fully reduced to two different irreducibles t∗and t∗∗, so t ⇛∗t∗and
t ⇛∗t∗∗. Let t be a minimal element for which this can happen. Then the ﬁrst steps
of these two different reductions must be different. Hence we must have t ⇝t1 ⇛∗
t∗and t ⇝t2 ⇛∗t∗∗, where t1 and t2 are different. By assumption, t1 and t2 can
be reduced to a common element t3, which can then be reduced fully to some t∗∗∗.
Thus we have t1 ⇝t3 ⇛∗t∗∗∗and t2 ⇝t3 ⇛∗t∗∗∗. One of t∗and t∗∗must be
different from t∗∗∗; suppose by symmetry that this is t∗. Then t1 ⇛∗t∗∗∗, but also
t1 ⇛∗t∗. That is, t1 can be reduced to two different irreducible elements. Since t1 is
less than t, this must be impossible.
□
Deﬁnition 3.4 We write t ∼t′ if there is a chain of subterm substitutions t ≡t1 ↭
t2 ↭t3 ↭··· ↭tn ≡t′, where each tj+1 is obtained from the preceding tj by
replacing some subterm of tj having the form (ℓs), where s is a substitution and
ℓ⇝r is some reduction, by the corresponding (rs), or possibly tj is obtained from
tj+1 in this way.
Lemma 3.6 A set of reductions is complete iff any two t ∼t′ have the same full
reduction t∗.
Proof If t has two different full reductions t∗, t∗∗, then plainly t∗∼t ∼t∗∗, while
both t∗and t∗∗are their own full reductions. Hence if any two equivalent irre-
ducibles are identical, the set R of reductions is complete. Conversely, let R be
complete. Suppose that n is the smallest integer for which there exists a chain
t1 ↭t2 ↭t3 ↭··· ↭tn for which t1 and tn have different ﬁnal reductions.
Then irrespective of whether t1 ⇝t2 or t2 ⇝t1 both have the same ﬁnal reductions.
Hence the two ends t2 and tn of the smaller chain t2 ↭t3 ↭··· ↭tn would also
have different ﬁnal reductions, a contradiction which proves our lemma.
□
The ﬁrst lemma stated above implies that if a set of productions is not complete,
there exists a ‘parting of the ways’ t ⇝t1 ⇛∗t∗
1 and t ⇝t2 ⇛∗t∗
2 where t∗
1 and t∗
2
are fully reduced and different, and where t1 and t2 have no common reduction. We
call this a ‘permanent parting of the ways’. In this case the reduction t ⇝t1 replaces
a subterm w1 ≡(ℓ1s1) of t by (r1s1). The reduction t ⇝t2 replaces a subterm
w2 ≡(ℓ2s2) of t by (r2s2). The two subterms w1 and w2 cannot be disjoint (or the
paths of reduction would be rejoinable). Hence one replaced part, say w2 ≡(ℓ2s2),
must be a subterm of the other, i.e. of w1 ≡(ℓ1s1).
Let (ℓ′
1s1) be the subterm of (ℓ1s1) that is actually matched by w2, i.e. (ℓ′
1s1) ≡
(ℓ2s2). We can of course write the two identities ℓ1 ⇝r1 and ℓ2 ⇝r2 that we are
using with disjoint sets of variables. If this is done, then the substitution s1 on the
variables of ℓ′
1 and the substitution s2 on the variables of ℓ2 can be seen as a common
substitution s on all the variables together, and we have (ℓ′
1s) ≡(ℓ2s). That is, s is a
uniﬁcation of ℓ′
1 and ℓ2. Hence, by the analysis of uniﬁcation given in the preceding
Sect. 3.12.2, there is a most general uniﬁer m such that (ℓ′
1m) ≡(ℓ2m), and we can
write s as the product s ≡m ◦t of m and some other substitution t.

3.14
The Knuth–Bendix Equational Method
199
Let ℓ′′
1 be the result of replacing the subterm (ℓ′
1m) of (ℓ1m) by (ℓ2m). Then
(r1m) and ℓ′′
1 are two direct reductions of (ℓ1m), i.e. (ℓ1m) ⇝(r1m) and (ℓ1m) ⇝
ℓ′′
1. These two reductions must themselves be a ‘permanent parting of the ways’,
since if there were further reductions
(ℓ1m) ⇝(r1m) ⇛∗s
and
(ℓ1m) ⇝ℓ′′
1 ⇛∗s,
we would also have

(ℓ1m)t

⇝

(r1m)t

⇛∗(st)
and

(ℓ1m)t

⇝(ℓ′′
1t) ⇛∗(st),
implying the existence of reductions t ⇝t1 ⇛∗(some t∗) and t ⇝t2 ⇛∗
(the same t∗), and so the two reductions t ⇝t1 and t ⇝t2 would not be a ‘perma-
nent parting of the ways’, contrary to assumption. Therefore, if a set R of reductions
is not complete, we can ﬁnd a ‘parting of the ways’ by unifying the left-hand side of
one reduction ℓ2 ⇝r2 with a subword of the left-hand side of some other reduction
ℓ1 ⇝r1, and then converting the resulting identity to an identity of the form t = t′,
where both t and t′ are irreducible. If the new identity t = t′ is not simply t = t, we
call it a superposition of the two reductions ℓ1 ⇝r1 and ℓ2 ⇝r2. As we shall now
see, this gives us the key to the Knuth–Bendix procedure.
3.14.3 Testing Completeness by Superposition of Reductions: The
Knuth–Bendix Completion Process
We saw in the preceding discussion that if a set of reductions is not complete, there
exists a pair of reductions ℓ1 ⇝r1, ℓ2 ⇝r2, such that we can unify the left-hand
side of the second reduction with a subterm of the left-hand side of the ﬁrst, i.e. ﬁnd
substituted versions of both which allows the left-hand side of the ﬁrst to be reduced
either as a whole or by replacement of a subterm. This yields a pair of versions t, t′
of the substituted left-hand side known to be equal. We now reduce both t and t′ to
their irreducible forms t∗, t∗∗. If these are identical, then nothing new results. But
if t∗and t∗∗are not identical (in spite of the fact that their equality is entailed by
the other equalities in our set of reductions) and we can arrange them as a reduction
t∗⇝t∗∗, then we can extend our set of reductions by adding t∗⇝t∗∗to it. Adding
t∗⇝t∗∗to our original set of reductions clearly reﬁnes our notion of reduction, i.e.
a term t which was previously irreducible may now admit of further reductions. The
Knuth–Bendix method consists in repeatedly adding all non-trivial superpositions
of an existing set R of reductions to R, in the hope of eventually reaching a complete
set, for which all terms then have a unique canonical form. As we have seen, this
would allow us to test two terms to determine whether or not their identity is entailed
by our set of reductions just by reducing both of them to the irreducible form and
checking these irreducible forms for identity.

200
3
A Survey of Inference Mechanisms
3.14.4 More Details
When no reorderings of terms become necessary during its operation, the Knuth–
Bendix completion process just described is a ‘semi-decision algorithm’ for deter-
mining whether the identity of two terms is entailed by a set of identities. That is, it
searches for a completion of the given set of identities, either continuing to search
indeﬁnitely and endlessly ﬁnding new reductions, or eventually attaining comple-
tion. The overall procedure is that implied by the preceding discussion. In more
detail, it is as follows.
Suppose that a set ℓi ⇝ri of reductions is given.
• Repeatedly resolve the left-hand sides of these reductions with subterms of the
right-hand sides of these reductions in all possible ways, generating new pairs of
irreducible terms t∗, t∗∗known to be equal, in the manner described in the pre-
ceding section. Arrange t∗and t∗∗as a reduction ℓ∗⇝r∗. Add these reductions
ℓ∗⇝r∗to the set of reductions, using the same weights and operator ordering if
possible.
• Change the weights and operator ordering if necessary. (These play only an aux-
iliary role.)
• Each time a new reduction ℓ∗⇝r∗is added, retest every other to see if it is now
subsumed, and if so drop it from the set of reductions.
Deﬁnition 3.5 A reduction ℓ⇝r belonging to a set C of reductions is subsumed
by the other members of C iff ℓand r are both reducible to a common element by
the set C \ {ℓ⇝r} obtained from C by dropping the reduction ℓ⇝r.
We continue adding new reductions until the resulting set becomes complete, or
until whatever conclusion t = t′ we wish to test reduces to t = t. If this process runs
unduly long we stop it.
3.14.5 Examples of the Knuth–Bendix Procedure
3.14.5.1 Simple Associativity
First we consider what is almost the simplest possible system, that involving just a
single dyadic operation (which we will write in inﬁx form), and just one identity,
namely the associative law
(x ⋆y) ⋆z = x ⋆(y ⋆z).
All weights, including w(⋆), are taken to be 1. The Knuth–Bendix ordering rule
then gives
(x ⋆y) ⋆z > x ⋆(y ⋆z)

3.14
The Knuth–Bendix Equational Method
201
since (x ⋆y) > x, and so our system is seen to consist of the one reduction
(x ⋆y) ⋆z ⇝x ⋆(y ⋆z).
This makes it clear that, in this system, term reduction consists in using the associa-
tive law to move parentheses to the right, so that the irreducible form of a term is its
fully right-parenthesized form. This makes it clear that irreducible forms are unique
in this simple system, so that our single reduction R is already complete. To verify
this using the formal Knuth–Bendix criterion, note that the only way of unifying
the left side of R with a subterm of the left side of R (ﬁrst rewritten using different
variables) is to unite (x ⋆y) ⋆z with the subword (u ⋆v) of (u ⋆v) ⋆w. The unifying
substitution converts this second term to ((x ⋆y) ⋆z) ⋆w, which as we have seen in
our general discussion can be reduced in two ways to produce (x ⋆(y ⋆z)) ⋆w and
(x ⋆y) ⋆(z ⋆w). But in this case nothing new results since both of these terms have
the same right-parenthesized form.
3.14.5.2 Minimal Axioms for the Theory of Free Groups
We now examine a more elaborate and interesting example, that of the elementary
identities of group theory touched on earlier. These involve just two operators, mul-
tiplication and inversion, which for ease of reading we write in their usual inﬁx and
postﬁx forms as x ⋆y and x−, respectively. As before, we use weights w(e) = 1,
w(−) = 0, w(⋆) = 0, and let ‘−’ be the last operator. We begin with identities which
state the existence of a left identity and left inverses, along with associativity. These
are:
[P1]
e ⋆x
⇝x;
[P2]
x−⋆x
⇝e;
[P3]
(x ⋆y) ⋆z ⇝x ⋆(y ⋆z).
Knuth–Bendix analysis of these identities will show that these initial identities
imply that the left identity is also a right identity and that the left inverse is also a
right inverse. (The reader may want to improve his/her appreciation of the Knuth–
Bendix procedure by working out direct proofs of these facts.) We begin as follows.
Superpose [P2] on [P3], getting:
[P4]
x−⋆(x ⋆z) ⇝z.
Now superpose [P1] on [P4], getting:
[P5]
e−⋆z ⇝z.
Superpose [P2] on [P4], getting x−−⋆(x−⋆x) ⇝x, or
[P6]
x−−⋆e ⇝x.

202
3
A Survey of Inference Mechanisms
Superpose [P6] on [P3], getting (x−−⋆e) ⋆z ⇝x−−⋆⋆(e ⋆z), or
[P7]
x−−⋆z ⇝x ⋆z.
Now replace [P6] by
[P8]
x ⋆e ⇝x.
Thus the left identity is a right identity, and [P6] reduces to
[P9]
x−−⇝x.
Now [P8], [P5] superpose to give
[P10]
e−⇝e.
Now [P2] and [P9] superpose to x−−⋆x−⇝e, or
[P11]
x ⋆x−⇝e.
Thus the left inverse is also a right inverse. Two more derived identities complete
the set:
e ⋆x ⇝x;
x ⋆e ⇝x;
x−⋆x ⇝e ;
x ⋆x−⇝e;
e−⇝e;
x−−⇝x;
(x ⋆y) ⋆z ⇝x ⋆(y ⋆z);
x−⋆(x ⋆z) ⇝z;
x ⋆(x−⋆z) ⇝z;
(x ⋆y)−⇝y−⋆x−.
The normal form of any term in this theory is obtained by expanding it out using
(x ⋆y)−⇝y−⋆x−as often as possible, associating to the right, performing as
many cancellations x ⋆x−⇝e, x−⋆x ⇝e, x−−⇝x as possible, and removing e
from all products. This is of course a standard normal form for the elements of free
groups.
References
[Ack54]
Ackermann, W.: Solvable Cases of the Decision Problem. North-Holland, Amsterdam
(1954)
[Beh22]
Behmann, H.: Beiträge zur Algebra der Logik insbesondere zum Entscheidungsprob-
lem. Math. Ann. 86, 163–220 (1922)
[CCG06]
Cantone, D., Cincotti, G., Gallo, G.: Decision algorithms for fragments of real anal-
ysis. I. Continuous functions with strict convexity and concavity predicates. J. Symb.
Comput. 41(7), 763–789 (2006)
[CFO89]
Cantone, D., Ferro, A., Omodeo, E.G.: Computable Set Theory. International Series
of Monographs on Computer Science, vol. 6, p. 347. Clarendon, Oxford (1989)
[CL73]
Chang, C.-L., Lee, R.C.-T.: Symbolic Logic and Mechanical Theorem Proving. Com-
puter Science and Applied Mathematics. Academic Press, New York (1973)

References
203
[COP01]
Cantone, D., Omodeo, E.G., Policriti, A.: Set Theory for Computing. From Decision
Procedures to Declarative Programming with Sets. Monographs in Computer Science.
Springer, Berlin (2001)
[COSU03] Cantone, D., Omodeo, E.G., Schwartz, J.T., Ursino, P.: Notes from the logbook of
a proof-checker’s project. In: Dershowitz, N. (ed.) Veriﬁcation: Theory and Practice
(Essays Dedicated to Zohar Manna on the Occasion of His 64th Birthday). LNCS, vol.
2772, pp. 182–207. Springer, Berlin (2003)
[DP60]
Davis, M., Putnam, H.: A computational procedure for quantiﬁcation theory. J. ACM
3(7), 201–215 (1960)
[Fuc70]
Fuchs, L.: Abelian Groups. Academic Press, New York (1970)
[Gur65]
Gureviˇc, Y.: Elementary properties of ordered Abelian groups. Transl. AMS 46, 165–
192 (1965)
[IC94]
Ignizio, J.P., Cavalier, T.M.: Linear Programming. International Series in Industrial
and Systems Engineering. Prentice Hall, New York (1994)
[KB70]
Knuth, D.E., Bendix, P.B.: Simple word problems in universal algebras. In: Leech, J.
(ed.) Computational Problems in Abstract Algebra, pp. 263–297. Pergamon, Oxford
(1970)
[KK74]
Kokorin, A.I., Kopytov, V.M.: Fully Ordered Groups. Wiley, New York (1974)
[Pre30]
Presburger, M.: Über die Völlständigkeit eines gewissen Systems der Arithmetik
ganzer Zahlen, in welchem die Addition als einzige Operation hervortritt. In: Comptes-
rendus du premier Congrès des mathematiciens des Pays Slaves, Warsaw, pp. 92–101
(1930)
[Rob65]
Robinson, J.A.: A machine-oriented logic based on the resolution principle. J. ACM
12(1), 23–41 (1965). Reprinted in Siekmann, J., Wrightson, G.: Automation of Rea-
soning I and II. Springer (1983)
[Tar51]
Tarski, A.: A Decision Method for Elementary Algebra and Geometry. Berkeley Uni-
versity Press, Berkeley (1951)
[Tar56]
Tarski, A.: Ordinal Algebras. North-Holland, Amsterdam (1956)


Chapter 4
More on the Structure of the Veriﬁer System
In this chapter we describe our veriﬁer and its underlying design in more detail.
The chapter falls into two parts: (i) An account of the general syntax and overall
structure of proofs acceptable to the veriﬁer. (ii) A listing of the mechanisms actually
chosen from the list of candidate inference mechanisms surveyed in the preceding
chapter for inclusion in the veriﬁer’s initial endowment. We explain the syntax used
to invoke each of the veriﬁer’s built-in inference mechanisms.1
4.1 Introduction to the General Syntax and Overall Structure
of Proofs
4.1.1 The Syntax of Proofs
The Ref veriﬁer (also known as Referee or as ÆtnaNova), accessible on the Web,2
is fed script ﬁles, called scenarios, consisting of successive deﬁnitions, theorems,
and auxiliary commands, which Ref either certiﬁes as constituting a valid sequence
or rejects as defective. In the case of rejection, the veriﬁer attempts to pinpoint the
troublesome locations within a scenario, so that errors can be located and repaired.
Step timings are produced for all correct proofs, to help the user in spotting places
where appropriate modiﬁcations could speed up proof processing.
The bulk of the text normally submitted to the veriﬁer consists of theorems and
proofs. Some theorems (and their proofs) are enclosed within so-called theories,
whose external conclusions these internal theorems serve to justify. This lets sce-
narios be subdivided into modules, which increases readability and supports proof
reuse (cf. Sects. 1.4.2.6 and 4.1.4).
1For additional information and more detailed information, cf. http://setl.dyndns.org/EtnaNova/
login/Ref_user_manual.html.
2Cf. http://setl.dyndns.org/EtnaNova/login/.
J.T. Schwartz et al., Computational Logic and Set Theory,
DOI 10.1007/978-0-85729-808-9_4, © Springer-Verlag London Limited 2011
205

206
4
More on the Structure of the Veriﬁer System
The veriﬁer allows input and checking of the text to be veriﬁed to be divided into
multiple sessions (cf. Sect. 4.4).
The following example, which appears early in Ref’s main proof scenario to be
surveyed in the next chapter (cf. Sect. 5.1), illustrates the syntactic form of Ref
proofs:3
THEOREM 8a: [Members of ordinals are ordinals] Ord(S) & T ∈S →Ord(T).
PROOF:
Suppose_not(s, t) =⇒
AUTO
-- We proceed by contradiction. If our theorem is false, there is an
ordinal s having a member t which is not an ordinal.
Use_def(Ord) =⇒
Stat1: ¬(⟨∀x ∈t| x ⊆t⟩&
⟨∀x ∈t, y ∈t| x ∈y ∨y ∈x ∨x = y⟩)
-- Hence, by deﬁnition of ordinal, t must either have a member a not
included in t, or a pair b, c of distinct members not related by mem-
bership.
⟨a, b, c⟩→Stat1 =⇒
AUTO
-- But since s is an ordinal, it must include its member t, so that
the second case is impossible.
Use_def(Ord) =⇒
Stat2: ⟨∀x ∈s| x ⊆s⟩&
Stat3: ⟨∀x ∈s, y ∈s| x ∈y ∨y ∈x ∨x = y⟩
⟨t⟩→Stat2 =⇒
AUTO
Suppose =⇒
b, c ∈t & ¬(b ∈c ∨c ∈b ∨b = c)
⟨b, c⟩→Stat3 =⇒
AUTO
Discharge =⇒
Stat4: a ̸⊆t & a ∈t
-- Thus we need only consider the ﬁrst case, in which a is a member
but not a subset of t. In this case there plainly exists a d in a but not
in t. Plainly a is a member of s, and thus a subset of s; so d is also a
member of s.
⟨d⟩→Stat4 =⇒
d ∈a & d /∈t
⟨a⟩→Stat2 =⇒
a ⊆s
ELEM =⇒
d ∈s
-- By deﬁnition of ordinal, it follows that d either equals t, is a
member of t, or that t is a member of d. But all three of these
cases are impossible, since any would imply the existence of a
membership cycle. This contradiction proves our theorem.
⟨d, t⟩→Stat3 =⇒
d ∈t ∨t ∈d ∨t = d
⟨Stat4⟩Discharge =⇒
QED
3As seen here, we often enclose quantiﬁed formulae within ‘⟨’ and ‘⟩’—instead of within ‘(’ and
‘)’—to make matching parentheses more visible.

4.1
Introduction to the General Syntax and Overall Structure of Proofs
207
As seen in this example, each theorem owns a label (in the case at hand: ‘8a’).
This label (optionally followed by a comment, as shown above) is followed by a
syntactically valid logical formula: the conclusion or ‘claim’ of the theorem. This
claim should be terminated by a ﬁnal period (i.e. ‘.’) and be followed by the theo-
rem’s proof, which must be introduced by the keyword ‘Proof :’, and terminated by
the reserved symbol ‘QED’.
As the above example illustrates, a theorem’s proof consists of a sequence of
statements (also called inference steps), each of which consists of a hint portion
(e.g.: Use_def(Ord), ⟨a, b, c⟩→Stat1, Discharge, ELEM) separated by the sign
=⇒from the assertion of the statement. Each assertion must be a syntactically
well-formed formula in Ref’s set-theoretic language; each hint must reference one
of the basic inference mechanisms that Ref provides (see list below), and may also
supply this inference mechanism with auxiliary parameters (e.g.: Use_def(Ord),
Suppose_not(s, t)), including the context of preceding statements in which it should
operate (e.g., ⟨Stat4⟩Discharge draws a contradiction from the conjunction of all
assertions following the label Stat4). When no ambiguity or obscurity ensues from
this, an assertion can be represented laconically by the keyword AUTO. Thus, in the
above proof: when AUTO occurs in the initial Suppose_not-statement, it obviously
stands for the assertion Ord(s) & t ∈s & ¬Ord(t), contrary to the sought conclusion;
when it occurs in the ⟨a,b, c⟩→Stat1-statement, it stands for the formula
(a ∈t & a ̸⊆t) ∨

b ∈t & c ∈t & ¬(b ∈c ∨c ∈b ∨b = c)

,
because this is what results from the assertion bearing the label Stat1 when its bound
occurrences of variables get replaced by the new constants a, b, c; dually, in the
⟨t⟩→Stat2 and in the ⟨b, c⟩→Stat3 statement AUTO stands for t ∈s →t ⊆s and
for (b ∈s & c ∈s) →(b ∈c ∨c ∈b ∨b = c), respectively.
The following table lists the main inference mechanisms which currently consti-
tute the inferential armory of Ref:
1. ELEM =⇒··· Proof by extended elementary set-theoretic reasoning. (Cf.
Sect. 4.1.2.)
TELEM =⇒··· Variant of ELEM (see below).
2. Suppose =⇒··· Introduces hypothesis, available in a local range of the proof,
to be ‘discharged’ subsequently. (Cf. Sect. 4.1.3.)
3. Discharge
=⇒··· Closes the proof range opened by the last previous
‘Suppose’ statement, and makes negation of prior supposition available. (Cf.
Sect. 4.1.3.)
4. Suppose_not =⇒··· Specialized form of ‘Suppose’, used to open proof-by-
contradiction arguments. (Cf. Sect. 4.1.3.)
5. ⟨e1,...,en⟩→Stat_label =⇒··· Substitutes given expressions or newly gen-
erated constants into a prior labelled statement. (Cf. Sect. 4.3.9.)
6. ⟨e1,...,en⟩→Theorem_name =⇒··· Substitutes given expressions into a
prior universally quantiﬁed theorem. (Cf. Sect. 4.3.9.)
7. Use_def(symbol) =⇒··· Expands a deﬁned symbol into its deﬁnition. (Cf.
Sect. 4.2.)

208
4
More on the Structure of the Veriﬁer System
8. Loc_def =⇒symbol_name(params) = ··· Deﬁnes a new function symbol,
constant, or predicate symbol for use within a single proof.
9. EQUAL =⇒··· Makes deduction by substitution of equals for equals, possibly
in a universally quantiﬁed formula. (Cf. Sect. 4.3.3.)
10. SIMPLF =⇒··· Makes deduction by removal of set-former expressions nested
within other set formers or quantiﬁers.
11. ALGEBRA =⇒··· Deduces an algebraic consequence using statements proved
or assumed previously. (Cf. Sect. 4.3.5.)
12. Set_monot =⇒··· Handles set formers and exploits set-theoretic monotonic-
ity relationships. (Cf. Sect. 4.3.4.)
Pred_monot =⇒··· Handles quantiﬁers and the ﬁniteness predicate and ex-
ploits set-theoretic monotonicity relationships. (Cf. Sect. 4.3.4.)
13. Assump =⇒··· Cites an available theory assumption during a proof being
conducted within a theory.
14. APPLY··· =⇒··· Draws conclusions from theorems previously proved in a
theory. Note that ‘Skolemization’ is handled as a special case of APPLY. (Cf.
Sect. 4.1.4.)
In the ﬁve sections which follow, after outlining the inference mechanisms give
our veriﬁer most of its special ﬂavour, we explain its notion of inference step context
and describe how contexts can be restricted by means of statement labels.
4.1.2 The ELEM Primitive and ‘Blobbing’
Among Ref’s inference primitives, ELEM is the most central (its use being, often,
tacitly combined with other forms of inference). ELEM implements multilevel syl-
logistic, a decision algorithm which determines whether a given unquantiﬁed set-
theoretic formula involving individual variables (which designate sets) and a re-
stricted collection of set operators is satisﬁable. (A tableau-fashioned account of
a decision procedure for this fragment of set theory is given in Sect. 3.5.) Using
the ELEM algorithm, the Ref veriﬁer can identify many cases in which a conjunc-
tion constructed by negating one statement of a proof and conjoining a selection of
earlier statements is unsatisﬁable, so that the statement follows from the preceding
context. When not all the constructs appearing in this context (e.g. quantiﬁers and set
formers) are part of Ref’s built-in syllogistic, a preprocessing step, called blobbing,
replaces all parts of the current context whose principal operators are not recognized
by the decision algorithm by ‘blobs’, i.e. by new variables designating either sets
(when they occur as terms) or propositions (when they occur as subformulae). This
blobbing operation replaces syntactically identical (or recognizably equal) parts of
a conjunction by the same variable. It is also able to treat as equal well-formed parts
which only differ by the renaming of bound variables in quantiﬁers or set formers,
and also treats existential quantiﬁers as negated universal quantiﬁers.
The primary function of blobbing is to reduce all the constructs that appear in
proof statements submitted to ELEM to the ones which multilevel syllogistic can

4.1
Introduction to the General Syntax and Overall Structure of Proofs
209
handle. Blobbing is also used to introduce other simpliﬁcations which extend the
power of ELEM beyond that of simple multilevel syllogistic and improve system
performance.
Blobbing consists of three subphases: (1) pre-blobbing, which makes reductions
such as the reduction of any part of the form Finite(#X) to Finite(X) (justiﬁed by the
remark that the cardinality of a set X is ﬁnite if and only if X is ﬁnite); (2) blobbing
proper, during which subterms whose lead constructs are not known to the mul-
tilevel syllogistic algorithm are replaced by set names and quantiﬁed subformulae
are replaced by propositional variables; (3) post-blobbing, which drops parts of a
purported contradiction when it is clear that they can play no role in establishing its
contradictory nature.
In some cases the veriﬁer provides a few efﬁciency-oriented variants of the ELEM
deduction primitive. These are invoked by preﬁxing the keyword ELEM with a
parenthesized label (as we will see again in Sect. 4.1.5) which may include various
special characters. Including the character “*” just before the closing parenthesis of
the preﬁx suppresses the normal internal examination of special functions like cons,
car, and cdr (the ordered pair constructor x,y →[x, y] and its associated projec-
tions p →p[1], p →p[2], normally treated by the method discussed in Sect. 3.7.2),
i.e. it treats these as unknown functions whose occurrences must be ‘blobbed’. This
treats statements like

x,[y,z]

=

x2,[y2,z2]

&

x,[y,z]

=

x3,[y3,z3]

&

x,[y,z]

=

x4,[y4,z4]

as if they read
xyz = xyz2 & xyz = xyz3 & xyz = xyz4,
and so makes deduction of

x2,[y2,z2]

=

x3,[y3,z3]

from the conjunction shown above easy. Without modiﬁcation of the ELEM primi-
tive’s operation this same deduction would require many seconds. This coarse treat-
ment is of course incapable of deducing the implication

x,[y,z]

=

x2,[y2,z2]

→(x = x2 & y = y2 & z = z2)
which it sees as
xyz = xyz2 →(x = x2 & y = y2 & z = z2) .
In such cases we must simply allow a more extensive search than is generally
used. (The veriﬁer normally cuts off ELEM deduction searches after about 10 sec-
onds.) Including the character “+” instead of “∗” in a preﬁx attached to ELEM raises
this limit to 40 seconds. Note that an empty preﬁx, i.e. “⟨⟩”, can be used to indicate
that a statement is to be derived without additional context, i.e. that it is universally

210
4
More on the Structure of the Veriﬁer System
valid as it stands. Therefore the right way of obtaining the implication just displayed
by ELEM deduction is to write it as
⟨+ ⟩ELEM =⇒

x,[y,z]

=

x2,[y2,z2]

→

(x = x2) & (y = y2) & (z = z2)

.
4.1.3 The Suppose_not, QED, Suppose, Discharge Primitives
Suppose_not statements occur, exclusively and always, as the ﬁrst inference step in
Ref proofs. They have the form
Suppose_not(c1,...,cn) =⇒··· ,
where c1,...,cn are distinct constants local to a proof, which correspond in number
and in positions to the distinct unquantiﬁed variables appearing in the statement
T of the corresponding theorem. Such theorem variables (whose ﬁrst letters are
always capitalized for emphasis) are in fact understood to be universally quantiﬁed;
and in a proof by contradiction the constants ci replace them during deduction of a
contradiction. Accordingly, the statement which follows =⇒in the Suppose_not
step must be logically equivalent to the negation of an instantiated version of T . At
the end of the proof there must appear a statement of the form
Discharge =⇒QED
which matches the Suppose_not and indicates that a contradiction was derived by
assuming the existence of a counterexample to T .
A Suppose statement has the form
Suppose =⇒B ··· ,
where the formula B that follows =⇒can involve no constants save those already
available in the part of the proof preceding it (including globally deﬁned constants,
constants of the form c local to the current theory, constants generated within the
proof by substitution of an existentially bound variable, and constants generated by
application of a THEORY—cf. Sect. 4.1.4).
Every step C coming after a Suppose =⇒B can exploit the temporary assump-
tion B as part of its context, until the following Discharge statement which matches
this Suppose statement and so eliminates this assumption, along with all the inter-
mediate steps C which were derived from it.
As already said, Discharge statements always match Suppose and Suppose_not
statements within a proof, in the same balanced way in which closed paren-
theses match open parentheses within an arithmetic expression. A matching
Suppose/Discharge pair of statements is often used to encapsulate parts of the proof
which constitute a digression from the main stream of the proof.

4.1
Introduction to the General Syntax and Overall Structure of Proofs
211
To see how this inference primitive works, let us consider the following proof
fragment:
C
Suppose =⇒B
D
Discharge =⇒A.
Here the Suppose and Discharge are taken to match each other, so that C repre-
sents the overall context available before the Suppose, D represents the context
portion derived from the temporary assumption B , and A is the assertion which the
Discharge yields. Ref will only regard this derivation as legitimate if it can ﬁnd an
intermediate formula D′ implied by C&B&D and such that A ‘trivially’ follows
from the formula C&(B →D′).
Our veriﬁer’s ‘Suppose’ and ‘Discharge’ capabilities make a convenient form
of ‘natural deduction’ available. Any syntactically well-formed formula can be the
assertion of a ‘Suppose’ statement, i.e. you can suppose what you like. For example,
Suppose =⇒2 + 2 = 4
and
Suppose =⇒2 + 2 = 5
are both perfectly legal. However, all the assumptions made in the course of a theo-
rem’s proof must be Discharged before the end of the proof. A Discharge statement
of the form
Discharge =⇒some_conclusion
constructs its conclusion as p →q, where p is the assertion of the matching
Suppose statement and q is the assertion of the last inference preceding the
Discharge. For example, the following sequence of ‘Suppose’ and ‘Discharge’
statements proves the propositional tautology P →((P →Q) →Q):
Suppose =⇒P
Suppose =⇒P →Q
ELEM =⇒Q
Discharge =⇒(P →Q) →Q
Discharge =⇒P →

(P →Q) →Q

.
4.1.4 THEORY Application
Ref incorporates a technical notion of ‘theory’ designed, for large-scale proof-
development, to play a role similar to the notion of object class in large-scale pro-

212
4
More on the Structure of the Veriﬁer System
gramming. As discussed in [OS02], such a mechanism can be very useful for ‘proof-
engineering’.
The theories we allow, like procedures in a programming language, have lists of
formal parameters. Each ‘theory’ requires its parameters to meet a set of assump-
tions. When ‘applied’ to a list of actual parameters that have been shown to meet the
assumptions, a theory will instantiate several additional ‘output’ set, predicate, and
function symbols, and then supply a list of theorems initially proved explicitly (rel-
ative to the formal parameters) by the user inside the theory itself. These theorems
will generally involve the new symbols.
As an illustration of the usefulness of the THEORY construct, let us now exploit
the familiar theory of equivalence relations seen in Sect. 1.4.2.6 in order to deﬁne
the set R of all real numbers. Since the apparent simplicity of the reals as Dedekind
cuts is marred by problems concerning the treatment of negative reals, we opted for
Cantor’s approach based on rational Cauchy sequences. Thus our construction of
the reals runs as follows:
-- The set of rational sequences
DEF 46. SeqQ =Def

f: f ⊆N × Q| domain(f) = N & Svm(f)

-- The constant 0 rational sequence
DEF 47. 0QS =Def N × {0Q}
-- The constant 1 rational sequence
DEF 48. 1QS =Def N × {1Q}
-- Pointwise sum of rational sequences
DEF 49. F+QSG =Def

p[1], p[2] +Q G

p[1]
: p ∈F

-- Pointwise additive inverse of rational sequence
DEF 50. RevQS(F) =Def

p[1], RevQ

p[2]
: p ∈F

-- Pointwise absolute value of rational sequence
DEF 51. |F|QS =Def

p[1],
p[2]
Q

: p ∈F

-- Pointwise difference of rational sequences
DEF 52. F−QSG =Def F+QSRevQS(G)
-- Product of rational sequences
DEF 53. F∗QSG =Def

p[1], p[2] ∗Q G

p[1]
: p ∈F

-- Pointwise reciprocal of rational sequence
DEF 54. RecipQS(F) =Def Shifted_seq

i, RecipQ

F[i]

: i ∈N

,
arb

h ∈N
 	
∀i ∈N\h| F[i] ̸= 0Q


-- Pointwise quotient of rational sequences
DEF 55. F/QSG =Def F∗QSRecipQS(G)
-- Rational Cauchy sequences
DEF 56. CauQ =Def

f: f ∈SeqQ
 	
∀ε ∈Q| ε >Q 0Q →
Finite

i ∩j: i ∈N, j ∈N|
f[i] −Q f[j]

Q >Q ε


-- Equivalence of rational sequences
DEF 57. F≈QSG ↔Def
	
∀ε ∈Q| ε >Q 0Q →
Finite

x: x ∈domain(F)|
F[x] −Q G[x]

Q >Q ε


4.1
Introduction to the General Syntax and Overall Structure of Proofs
213
THEOREM 465: F ∈CauQ →F≈QSF. PROOF: ···
THEOREM 466: F, G, H ∈CauQ →

F≈QSG →(G≈QSH ↔H≈QSF)

. PROOF: ···
-- Now that we know that ≈QS is an equivalence relationship,
we can apply the equiv_classes theory to it, to derive
APPLY ⟨Eqc : R, f : Cau_to_R⟩equiv_classes

E(f, g) 
→f≈QSg, s 
→CauQ

=⇒
THEOREM 467: ⟨∀f ∈CauQ, g ∈CauQ | f≈QSg ↔Cau_to_R(f) = Cau_to_R(g)⟩
& ⟨∀r ∈R| arb(r) ∈CauQ & Cau_to_R(arb(r)) = r⟩
& ⟨∀f ∈CauQ | Cau_to_R(f) ∈R⟩& ⟨∀f ∈CauQ | f≈QSarb(Cau_to_R(f))⟩.
Let us observe, as an incidental remark, that in spite of its relative length this
list of statements works better than Dedekind’s approach, because it allows us to
‘lift’ laws already proved for rational numbers into corresponding laws for rational
Cauchy sequences, and thereby into laws concerning the reals (which are viewed
here as the ≈QS-classes of such sequences).
Use of External Provers
In order to provide the Ref proof veriﬁer with the ability
to accept proofs generated by various external provers, as explained and exempli-
ﬁed in [FO10, pp. 44–47]), one can resort to a syntactic extension of the normal Ref
APPLY directive. I.e., external provers shall be regarded as sources of variant Ref
THEORYs. When such a prover is being used, the normal keyword APPLY used to
invoke a THEORY must be changed to “APPLY_provername”, where “provername”
names the external prover in question. In this case, the normal Ref THEORY dec-
laration is expanded to list Ref-syntax translations of all the theorems being drawn
from the external prover, and of all the external symbol deﬁnitions on which these
depend. An external ﬁle, also named in the modiﬁed Ref APPLY directive, must be
provided as certiﬁcation of each such THEORY. Ref will then examine this ﬁle to
establish that it is a valid proof, by the external prover named, of all the theorems
which the THEORY claims.
4.1.5 Context of an Inference Step
Until a proof is complete and acceptable to the Ref veriﬁer, it is undesirable to
let efﬁciency concerns interfere with one’s focus on the logic of the proof. Once an
initial version of the proof has been accepted by Ref, one can speed up its processing
by supplying contexts (see above) for the most time-consuming proof steps. Ref
allows one to optimize proof steps by automated context discovery.
Statement assertions and parts of compounds connected by the conjunction sign
“&” can be labelled for explicit subsequent reference within a proof by appending a

214
4
More on the Structure of the Veriﬁer System
reserved notation of the form ‘Statnnn :’ to them, where nnn designates any integer.
These are the labels used in hints of statements of the form
⟨e1,...,em⟩→Statnnn =⇒···
The context of a hint deﬁnes the collection of preceding statements, within the
proof in which the hint appears, which the inference mechanism invoked by the
hint should use in deducing the assertion to which the hint is attached. Since the
efﬁciency of an inference mechanism often degrades very rapidly (e.g. exponen-
tially or worse) with the size of the context with which it is working, appropriate
restriction of context can be crucial to successful completion of an inference. Infer-
ences which the veriﬁer cannot complete within a reasonable amount of time are
abandoned with a diagnostic message “Abandoned...”, or with the more speciﬁc
message “Failure...” if the inference method is able to certify that the inference
ﬁnally attempted is impossible. Hint keywords like ELEM, EQUAL, SIMPLF, and
ALGEBRA can be supplied with context indications by preﬁxing them (in the cases
of ELEM and Discharge) or sufﬁxing them (in all other cases) with a statement label,
or a comma-separated list of such labels, as in the examples
⟨Stat3⟩ELEM =⇒s /∈

x ⊆o | Ord(x)&P(x)

and
⟨Stat3, Stat4,Stat9⟩ELEM =⇒s /∈

x ⊆o | Ord(x)&P(x)

.
The ﬁrst form of preﬁx deﬁnes the context of an inference to be the collection
of all statements in the proof, back to the point of last previous occurrence of the
statement label in the proof (but not within ranges of the proof that are already
closed in virtue of the fact that they are included between a preceding Discharge
statement and its matching Suppose statement—see below). The second form of
preﬁx deﬁnes the context of an inference to be the collection of statements explicitly
named in the preﬁx. If no context is speciﬁed for an inference, then its context is
understood to be the collection of all preceding statements in the same proof (not
including statements enclosed within previously closed Suppose/Discharge ranges).
This unrestricted default context is workable for simple enough inferences in short
enough proofs.
The Ref Proof Step Optimizer
Ref’s automated proof optimizer attempts to de-
termine, for each line L in a proof, a close-to-minimal subset of the set of all prior
lines in the proof which is large enough to serve as a context for the proof of L,
i.e. large enough to be inconsistent with the negation ¬L of L. To this end, it col-
lects a list of prior statements, called ‘critical’, which it believes to be necessary
for the desired inconsistency. Initially this list of critical statements consists of all
the statements preceding L. A ﬁrst binary search over ranges of statements shortens
this to the smallest range R of statements preceding L which is large enough to be
inconsistent with ¬L. The ﬁrst statement F in this range is added to an (initially

4.2
The Syntax and Semantics of Deﬁnitions
215
empty) list C. This reﬂects the fact that if F is removed from R, the set R ∪{¬L}
of statements is no longer inconsistent.
Let R′ be R after F is removed. Plainly C ∪R′ ∪{¬L} is inconsistent. But R′
may be larger than it need be to guarantee this property. So a second binary search
is made, to shorten R′ to the smallest range R′′ of statements which is large enough
for C ∪R′′ ∪{¬L} to be inconsistent. The ﬁrst statement of R′′ is then moved from
R′′ to C. This operation is repeated as often as needed to produce a ﬁnal list C of
critical statements such that C ∪{¬L} is inconsistent. This list C of statements is
returned by the proof optimizer as the context to be used in proving L.
The code described in the preceding paragraphs is organized using a
procedure test_range(critical_list,range_tup,statement)
which sets up the inconsistency tests described and then calls Ref’s underlying
ELEM procedure.
To mark a proof for invocation of the automated analysis just described, one
simply changes the normal “ =⇒” mark of its initial Suppose_not to “⇛”. To mark
a single step of a proof for application of this analysis, one changes its “ =⇒” mark
to “⇛”. The ﬁrst such mark encountered in a proof (if any) turns off the ‘analyze by
default’ option if this has been set by marking the initial Suppose_not.
Here are a few illustrative examples of the output produced by Ref’s automated
proof optimizer:
The lines of context needed to prove citation of theorem T116 in line 9, namely:
(domain(f ) ⊆N) & (range(f ) ⊆Q) are T116 plus [1, 5]
The lines of context needed to prove citation of theorem T220 in line 10, namely:
g ⊆(N × Q) are T220 plus [1, 7, 9]
The lines of context needed to prove citation of theorem T85 in line 12, namely:
domain(f ◦h) = domain(h) are T85 plus [1, 7]
4.2 The Syntax and Semantics of Deﬁnitions
Deﬁnitions introduce new predicate and function symbols into the ken of our veri-
ﬁer. Predicate deﬁnitions have the syntactic form
P(x1,x2,...,xn) ↔Def pexp.
Function deﬁnitions have the form
f (x1,x2,...,xn) =Def fexp.
In both these cases, x1,x2,...,xn must be a list of distinct variables; only these
variables can occur unbound on the right of the deﬁnition, and P (resp. f ) must
be a predicate (resp. function) symbol that has never been deﬁned previously. In
the ﬁrst (resp. second) case pexp (resp. fexp) must be a syntactically well-formed

216
4
More on the Structure of the Veriﬁer System
predicate expression (resp. function expression).4 Two cases of each form of deﬁ-
nition, the non-recursive and the recursive, arise. In non-recursive predicate (resp.
function) deﬁnitions, pexp (resp. fexp) can only contain previously deﬁned predi-
cate and function symbols, plus the free variables x1,x2,...,xn (and, of course, any
other bound variables). In recursive deﬁnitions the predicate (resp. function) symbol
being deﬁned is allowed to appear on the right-hand side of the deﬁnition, but then
other syntactic conditions must be imposed to guarantee the legality of the deﬁni-
tion. More speciﬁcally, in the function case, we allow recursive deﬁnitions of the
general form
f (s,x2,...,xn) =Def d

g

f

x, h2(s,x,x2,...,xn),h3(s,x,x2,...,xn),...,
hn(s,x,x2,...,xn)

,s,x,x2,...,xn

: x ∈s

P

f

x, h2(s,x,x2,...,xn),h3(s,x,x2,...,xn),...,
hn(s,x,x2,...,xn)

,s,x,x2,...,xn

,s,x2,...,xn

.
Here g, d, and h2,...,hn must be previously deﬁned functions of the indicated
number of arguments, and P must be a previously deﬁned predicate of the indicated
number of arguments.
The following informal argument indicates why it is reasonable to expect deﬁni-
tions of the general form displayed above to specify a function that is well deﬁned
for each possible argument list s,x2,...,xn. If the initial argument s is the null set
∅, the deﬁnition reduces to
f (∅,x2,...,xn) =Def d(∅, ∅, x2,...,xn),
i.e. to an ordinary set-theoretic deﬁnition in which the function being deﬁned does
not appear on the right. Since, in intuitive terms, we can think of the collection of all
sets as being arranged in a members-ﬁrst order, we can suppose that f (x,y2,...,yn)
is known for each x ∈s and for all y2,...,yn before the value f (s,x2,...,xn) is
required. But then the deﬁnition shown above clearly speciﬁes f (s,x2,...,xn) in
terms of (i) values of f which are already known, (ii) known functions and predi-
cates, along with (iii) a single set-former operation.
Although it is not hard to convert this informal line of reasoning into a more
formal argument involving transﬁnite induction, we shall not do so, but will simply
allow free use of inductive deﬁnitions of the form shown above.
In the predicate case, the same line of reasoning shows that we can allow recur-
sive deﬁnitions of the form
P(s,x2,...,xn) ↔Def
d

g(s,x,x2,...,xn): x ∈s | P(x,x2,...,xn)

,s,x2,...,xn

= ∅,
4We keep the sign ↔Def distinct from =Def for clarity, but this distinction is not very important.

4.2
The Syntax and Semantics of Deﬁnitions
217
where again g and d must be previously deﬁned functions of the indicated number
of arguments. In the special case in which the function d has the form
d(t,s,x2,...,xn) =

x : x ∈t | ¬Q(s,x,x2,...,xn)

,
where Q is some previously deﬁned predicate, the recursive predicate deﬁnition
seen above can be recast in the form
P(s,x2,...,xn) ↔Def

∀x ∈s | P(x,x2,...,xn) →Q

s,g(s,x,x2,...,xn),x2,...,xn

.
Accordingly, we allow recursive predicate deﬁnitions of this latter form also.
To illustrate the use of recursive deﬁnitions, we show how one can deﬁne func-
tions on sets which, when they are restricted to natural numbers in the von Neumann
representation, become the usual operations of unitary incrementation and decre-
mentation, addition, multiplication, subtraction, quotient, remainder, and greatest
common divisor (for this, we use an auxiliary operation ‘coRem(X,Y)’, which ﬁnds
the maximum multiple of Y less than or equal to X):
next(W) =Def W ∪{W},
prec(V ) =Def arb

w : w ∈V | next(w) = V

,
plus(X,Y) =Def X ∪
next

plus(X,v)

: v ∈Y

,
times(X,Y) =Def

plus

times(X,v),X

: v ∈Y

,
minus(X,Y) =Def arb

v : v ∈next(X)| plus(v,Y) = X

,
coRem(X,Y) =Def

next(X) ∩

plus

coRem(v,Y),Y

: v ∈X

,
Divides(X,Y) ↔Def coRem(X,Y) = X,
quot(X,Y) =Def

next

quot(v,Y)

: v ∈X |
plus

coRem(v,Y),Y

∈next(X)

,
rem(X,Y) =Def arb

w : w ∈Y | plus

coRem(X,Y),w

= X

,
gcd(X,Y) =Def if X = ∅then Y else

next(w): w ∈X | Divides

next(w),X

& Divides

next(w),Y

end if .
An alternative characterization of the greatest common divisor, equally conve-
nient but more procedural in ﬂavour (indeed, inspired by the classical Euclid algo-
rithm) can be given by
gcd(X,Y) = if Y = 0 then X else gcd

Y, rem(X,Y)

end if .
This cannot be proposed as a deﬁnition, though, because the form of recursion seen
here does not have the same syntactic evidence of legitimacy as the forms of recur-
sions used in the deﬁnitions above.

218
4
More on the Structure of the Veriﬁer System
4.3 Other Techniques Used in the Veriﬁer as Implemented
4.3.1 Supplementary Proof Mechanisms for the ELEM Rule
Because of their special importance, the treatment of arb and of the ‘cons-car-cdr’
group is built into ELEM. The use of supplementary proof mechanisms for handling
other extended ELEM deductions like those described in Sect. 3.7 is switched on in
the following way. Each of the cases listed there is given a name, speciﬁcally5
(ii) INVERSE_PAIR,
(iii) MONOTONE_FCN,
(iv) MONOTONE_GROUP,
(v) MONOTONE_MULTIVAR,
(vi) IDEMPOTENT,
(vii) SELF_INVERSE,
(viii) TOTAL_ORDERING,
(ix) RANGE_AND_DOMAIN.
To enable the use of supplementary inferencing for a particular operator belonging
to one of these named classes, one writes a veriﬁer command of a form like
ENABLE_ELEM(class_name; operator_list),
where class_name is one of the names in the preceding list, and operator_list lists
the operator symbols for which the designated style of inferencing is to be applied.
An example is
ENABLE_ELEM(MONOTONE_FCN; Un)
which states that during ELEM inferencing the ‘union of elements’ operator Un is to
be treated as an otherwise uninterpreted symbol for a monotone increasing set oper-
ator. The operator_list parameter of an ‘ENABLE_ELEM’ command must consist of
the number of operators appropriate to the class_name used, e.g. IDEMPOTENT calls
for a single operator as its operator list but MONOTONE_GROUP and INVERSE_PAIR
each call for a list of two operators f,g.
The ENABLE_ELEM command scans the list of all currently available theorems
for theorems of form suitable to the type of inference deﬁned by the class_name
parameter. For example, MONOTONE_FCN calls for a theorem of the form

∀x,y | (x ⊇y) →

f (x) ⊇f (y)

,
where f is the function symbol that appears as operator_list in this case;
IDEMPOTENT calls for a theorem of the form

∀x,y | f

f (x)

= f (x)

.
5Case (i) in Sect. 3.7 referred to the operator arb, which, as remarked above, is built into ELEM.
Treatment of the other cases is unimplemented as yet in the Ref veriﬁer.

4.3
Other Techniques Used in the Veriﬁer as Implemented
219
Thus, for example, the command ENABLE_ELEM(MONOTONE_FCN; Un) calls for
the theorem

∀x,y | (x ⊇y) →

Un(x) ⊇Un(y)

.
Cardinality is another example; the command ENABLE_ELEM(MONOTONE_FCN; #)
calls for the theorem

∀x,y | (x ⊇y) →(#x ⊇#y)

.
If the required theorem is not found an error message is issued; otherwise the de-
clared style of inferencing becomes available for the operator or operators listed.
Since extension of ELEM inferencing is not without its efﬁciency costs, one may
wish to switch it on and off selectively. To switch off extended ELEM inferencing of
a speciﬁed kind for speciﬁed operators one uses a command
DISABLE_ELEM(class_name,operator_list)
whose class_name parameter must reference one of the names which could occur
in an ENABLE_ELEM(class_name; ···) directive. This disables use of the ELEM
extensions described above for the indicated operators. Of course, a subsequent EN-
ABLE_ELEM command can switch this back on.
4.3.2 Limited Predicate Proof
In some situations, we can combine the ELEM style of unquantiﬁed proof described
in the preceding pages with predicate reasoning, provided that we hold down the
computational cost of proof searches by imposing artiﬁcial limitations on the infor-
mation used. An example of such a situation is that in which a deduction is to be
made by combining a collection of statements in the unquantiﬁed language of MLSS
with one or more universally quantiﬁed statements like

∀s,t
 
Ord(s) & Ord(t)

→(s ∈t ∨t ∈s ∨s = t)

,
where Ord(s) is the predicate stating that s is an ordinal. Although in the full con-
text of set theory use of such statements opens a path to very many subsequent
deductions, and so has consequences that are quite undecidable, the special case
of universally quantiﬁed statements which contain no symbols designating opera-
tors and only uninterpreted predicates is more tractable. This limited case can be
handled in the following way. Suppose that we deal with a collection C of unquan-
tiﬁed statements of the language MLSS, together with a collection U of universally
quantiﬁed statements of the form
(∀x1,...,xn | P),
(4.1)

220
4
More on the Structure of the Veriﬁer System
where P is built from some collection of uninterpreted predicates Q(x1,...,xn) and
contains no function symbols. Gather all the variables s that appear in the statements
of C, substitute them in all possible ways for the bound variables of (4.1), and
decompose the resulting collection of statements at the propositional level. To the
original collection C this would add a ﬁnite number of statements of the form
Q(s1,...,sn),
some of which may be negated. But instead of adding these statements, which in-
volve predicate constructions, proceed as follows. For each such Q(s1,...,sn) in-
troduce a unique propositional symbol Qs1,...,sn and add Qs1,...,sn, negated in the
pattern inherited from the Q(s1,...,sn), instead of the Q(s1,...,sn) to C. Then,
for all pairs of argument tuples s1,...,sn and t1,...,tn which appear in such state-
ments (with the same Q) add an implication
(s1 = t1 & ··· & sn = tn) →

Qs1,...,sn = Qt1,...,tn
.
(4.2)
This gives a collection C′ of statements, all of which are in MLSS. It is clear that
C′ is satisﬁable if C and U are simultaneously satisﬁable. Conversely, let C′ have
a model M . The conditions (4.2) that we have added to C imply that the Boolean
values Qs1,...,sn derive from a single-valued predicate function via the relationship
Qs1,...,sn = Q(s1,...,sn).
Let D be the collection of all the elements of the model M that correspond to
symbols which appear in statements belonging to C.
Then plainly
(∀x1 ∈D,...,xn ∈D | P).
(4.3)
Choose some s0 in D and let r be the idempotent map of the entire universe of sets
onto D deﬁned by
r(x) =Def if x ∈D then x else s0 end if .
If we show the dependence of the predicate P on its free variables x1,...,xn by
writing it as P(x1,...,xn), then (4.3) is clearly equivalent to

∀x1,...,xn | P

r(x1),...,r(xn)

.
(4.4)
Extend each of the predicates QM from its restriction to the Cartesian product
D × D × ··· × D to a universally deﬁned predicate QM
+ by taking
QM
+ (x1,...,xn) = Q

r(x1),...,r(xn)

.
Then it is clear that the predicates QM
+
model both the statements of C and the
universally quantiﬁed statement (4.1). This shows that the collection C′ has a model

4.3
Other Techniques Used in the Veriﬁer as Implemented
221
if and only if the union of C and U has a model, proving that the satisﬁability of
C ∪U is decidable.
Given any collection of universally quantiﬁed statements U and collection C of
unquantiﬁed statements of MLSS, we can treat them as if the predicates appear-
ing in the statements of U were uninterpreted, i.e. had no known properties except
those given explicitly by the statements in U. Even though this throws away a great
deal of information that can be quite useful, there are many situations in which it
achieves an inference step needed for a particular argument. Note that the inference
mechanism described need not treat predicates like x ∈y and x ⊇y present in a uni-
versally quantiﬁed statement as uninterpreted predicates if they contain no operator
signs not available in MLSS, even though the preceding argument fails if this is not
done: the inference method used remains sound nevertheless. However, compounds
like #t ⊆#s must be treated as uninterpreted multiparameter predicates, just as if
they read Q#(s,t). Similarly a compound like Finite(domain(f )) must be treated as
if it involved a special predicate Fd(f ). Any information that this loses lies out of
reach of the elementary extension of MLSS described in the preceding paragraphs.
Our veriﬁer provides an inference mechanism, designated by the keyword
‘THUS’,6 which extends ELEM deduction in the manner just explained. To make
a universally quantiﬁed statement available to this mechanism, one writes
ENABLE_THUS(statement_of_theorem),
for example
ENABLE_THUS

Ord(S) & T ∈S

→Ord(T )

.
To disable use of a theorem by ‘THUS’ inferencing, one can write
DISABLE_THUS(statement_of_theorem).
The following list shows some of the commonly occurring theorems suitable for use
with the ‘THUS’ inferencing mechanism.
ENABLE_THUS

∀s,t |

Ord(s) & Ord(t)

→(s ⊆t ∨t ⊆s)

ENABLE_THUS

∀s,t |

Ord(s) & Ord(t)

→(s ∈t ∨t ∈s ∨s = t)

ENABLE_THUS

∀s,t |

Ord(s) & t ∈s

→Ord(t)

ENABLE_THUS

∀s,t |

Ord(s) & Ord(t)

→

t ⊆s ↔(t ∈s ∨t = s)

6The mechanisms described in the ongoing of this section are unimplemented as yet in Ref.

222
4
More on the Structure of the Veriﬁer System
ENABLE_THUS

∀s |
Is_cardinal(s) →Ord(s)

ENABLE_THUS

∀f,g |
(g ⊆f ) & Is_map(f ) →Is_map(g)

ENABLE_THUS

∀f,g |
(g ⊆f ) & Svm(f ) →Svm(g)

ENABLE_THUS

∀f,g |
(g ⊆f ) & 1_1(f ) →1_1(g)

ENABLE_THUS

∀f,g |

Is_map(f ) & Is_map(g)

→Is_map(f ∪g)

ENABLE_THUS

∀f,s |
Is_map(f ) →Is_map(f|s)

ENABLE_THUS

∀f,s |
Svm(f ) →Svm(f|s)

ENABLE_THUS

∀f,s |
1_1(f ) →1_1(f|s)

ENABLE_THUS

∀f,g |

Svm(f ) & Svm(g)

→Svm(f ◦g)

ENABLE_THUS

∀f,g |

1_1(f ) & 1_1(g)

→1_1(f ◦g)

ENABLE_THUS

∀s,t |
(t ⊆s) →(#t ⊆#s)

ENABLE_THUS

∀s |
Is_cardinal(#s)

ENABLE_THUS

∀f |
1_1(f ) →

#range(f ) = #domain(f )

ENABLE_THUS

∀f |
Svm(f ) →

#range(f ) = #domain(f )

ENABLE_THUS

∀f |
Svm(f ) →

#domain(f ) = #f


4.3
Other Techniques Used in the Veriﬁer as Implemented
223
ENABLE_THUS

∀s |
Is_cardinal(s) ↔(s = #s)

ENABLE_THUS

∀s,t |

Finite(s) & s ⊇t

→Finite(t)

ENABLE_THUS

∀f |
1_1(f ) →

Finite(domain(f )) ↔Finite

range(f )

ENABLE_THUS

∀f |

Svm(f ) & Finite

domain(f )

→Finite

range(f )

ENABLE_THUS

∀s |
Finite(s) ↔Finite(#s)

ENABLE_THUS

∀s,t |

Finite(s) & t ⊆s & t ̸= s

→(#t ∈#s)

ENABLE_THUS

∀x |

Ord(N) & ¬Finite(N)

&

Is_cardinal(X) & Finite(X)

↔(X ∈N)

ENABLE_THUS

∀n,m|

Finite(n) & Finite(m)

↔Finite(n ∪m)

ENABLE_THUS

∀n,m|
Finite(n + m) ↔Finite(n ∪m)

ENABLE_THUS

∀n,m|

Finite(n) & Finite(m)

↔Finite(n + m)

Besides using all the MLSS statements available in the context in which it is
invoked, the inference mechanism invoked by the keyword ‘THUS’ makes use of
all the explicit and implicit universally quantiﬁed statements found in that context,
including non-membership statements like
b /∈

e(x): x ∈s | P(x)

,
which are equivalent to

∀x | ¬

b = e(x) & x ∈s & P(x)

.
This extends the reach of the automatic substitution mechanism invoked by ‘THUS’.

224
4
More on the Structure of the Veriﬁer System
4.3.3 Proof by Equality
Proof by equality tests two expressions for equality or two atomic formulae for
equivalence, by standardizing their bound variables and then descending their syn-
tax trees in parallel until differing nodes are found. These differing nodes are then
examined to determine if the context of the equality proof step contains theorems
which imply that the syntactically different constructs seen are in fact equal or
equivalent. Suppose, for example, that an assertion

g

e(x),f (y)

: x ∈s, y ∈t | P(x,y)

= a
has been proved, and that

g

e′(x),f ′(y)

: x ∈s, y ∈t | P ′(x,y)

= a
is to be deduced from it. Syntactic comparison reveals the differences between e and
e′, f and f ′, P and P ′. Our veriﬁer’s proof by equality procedure will then generate
the three statements

∀x ∈s | e(x) = e′(x)

,

∀y ∈t | f (y) = f ′(y)

,

∀x ∈s,y ∈t | P(x,y) ↔P ′(x,y)

and attempt to ﬁnd all of them in the available context. If this succeeds, the proof by
equality inference will be accepted. If not, the equality procedure will go one step
higher in the syntax tree of these two formulae, generate the pair of statements

∀x ∈s, y ∈t | g

e(x),f (y)

= g

e′(x),f ′(y)

,

∀x ∈s, y ∈t | P(x,y) ↔P ′(x,y)

and search for them in the available context. This gives a second way in which proof
by equality can succeed.
Proof by equality uses the equalities available in its context transitively. Since
the inner suboperations of the proof by equality routine are either purely syntactic
or are simple searches, this kind of inference is quite efﬁcient.
4.3.4 Proof by Monotonicity
Our veriﬁer includes a ‘proof-by-monotonicity’ feature which keeps track of all
operators and predicates for which monotonicity properties have been proved, and
also of all relationships of domination between monadic operators and predicates.
This mode of inference uses an efﬁcient, syntactic mechanism and so works quite

4.3
Other Techniques Used in the Veriﬁer as Implemented
225
rapidly when it applies. Proof by monotonicity allows statements like
(n ⊇k & m ⊇j) →#

[x, 0]: x ∈n

∪

[x, 1]: x ∈m

⊇
#

[x, 0]: x ∈k

∪

[x, 1]: x ∈j

(4.5)
and
(n ⊇k & m ⊇j) →#

[x, y]: x ∈n, y ∈m

⊇#

[x, y]: x ∈k, y ∈j

to be derived immediately. Since the formulae appearing on the right are essentially
the deﬁnitions of the cardinal addition and multiplication operators, respectively,
this easily gives us the formulae
(n ⊇k & m ⊇j) →(n + m ⊇k + j)
and
(n ⊇k & m ⊇j) →(n ∗m ⊇k ∗j),
which can then be used as the basis for further inferences by monotonicity.
Proof by monotonicity works in the following way. The monotonicity proper-
ties of all of the veriﬁer’s built-in predicates and operators are known a priori. For
example, x ∈s is monotone increasing in its second parameter, whereas s ⊇t is
monotone increasing in its ﬁrst parameter and monotone decreasing in its second
parameter. s ∪t and s ∩t are monotone increasing in both their parameters; s \ t is
monotone increasing in its ﬁrst parameter and monotone decreasing in its second.
Quantiﬁers and set formers like
(∀x,y ∈s | P)
and
(∃x,y ∈s | P)
and
{x,y ∈s | P }
depend in known monotone fashion on the sets which restrict their bound variables,
and preserve the monotonicity properties of their qualifying clauses P . The same
remark applies to set formers like

e(x,y): x ∈s, y ⊆t | P

.
The propositional operators &, ∨, ¬, →transform the monotonicity properties of
their predicate arguments in known ways. a & b and a ∨b are monotone increasing
in both their parameters; ¬a is monotone decreasing. a →b is monotone increasing
in its second parameter and monotone decreasing in its ﬁrst parameter.
These rules allow the monotonicity properties of compound expressions like

e(x,y): x ∈s, y ⊆t
 
∀z,w
 
[z, x], [w, y]

∈u →z ∈v

(4.6)
to be calculated directly by a procedure which processes its syntax tree bottom up
and assigns a dependency characteristic to each node encountered. For example,

226
4
More on the Structure of the Veriﬁer System
the expression just displayed is monotone increasing in s, t, and v, but monotone
decreasing in u.
Besides the properties ‘monotone increasing’ and ‘monotone decreasing’, there
is one other property which it is easy and proﬁtable to track in this way. As pre-
viously explained, an operator f (x,...) of one or more parameters is said to be
additive in a parameter x if
f (x ∪y,...) = f (x,...) ∪f (y,...)
for all x and y, and a predicate P(x,...) is said to be additive if
P(x ∪y,...) ↔

P(x,...) & P(y,...)

.
Using this notion we can easily see that an example like (4.6) is additive in s, but
not necessarily in its other parameters.
Many of the operators and predicates which appear repeatedly in the sequence of
theorems and proofs to which Chap. 5 and Chap. 7 are devoted have useful mono-
tonicity properties. These include
Is_map, domain, range additive
Is_map, Svm, 1_1
decreasing
,P,#
increasing
f|a
additive in both parameters
, Finite
additive
∪,+,∩,∗
increasing in both parameters
∈,⊆
increasing in second parameter
⊇,\,−,/
increasing in ﬁrst parameter, decreasing in second.
The three commands7
ENABLE_ELEM(MONOTONE_FCN; operator_and_predicate_list)
ENABLE_ELEM(MONOTONE_GROUP; operator_and_predicate_list)
ENABLE_ELEM(MONOTONE_MULTIVAR; operator_and_predicate_list)
discussed in the previous Sect. 4.3.1 can be used to make the monotonicity proper-
ties of other operators available for use in proof-by-monotonicity deductions once
these properties have been proved. This enlarges the class of expressions which can
be handled automatically. For example, it follows immediately that
#P

domain(f ) ∪range(f )

is monotone increasing in f .
7Primitives Set_monot and Pred_monot supporting proof by monotonicity are available in the Ref
system as implemented, but the ENABLE_ELEM directive is not implemented yet.

4.3
Other Techniques Used in the Veriﬁer as Implemented
227
Many of the monotonicity properties which appear in the table shown above
follow readily using proof by monotonicity. For example, from the deﬁnition of the
predicate Is_map, namely
Is_map(f ) ↔Def f =

x[1], x[2]
: x ∈f

it is not hard to show that
Is_map(f ) ↔

∀x ∈f | x =

x[1], x[2]
.
But the predicate on the right is obviously monotone decreasing in f , and so it fol-
lows that Is_map(f ) has this same property. The facts that the predicates Svm(f ) (f
is a single-valued function) and 1_1(f ) are also monotone decreasing then follow
immediately from the deﬁnitions of these predicates, which are
Svm(f ) ↔Def Is_map(f ) &

∀x ∈f, y ∈f
 
x[1] = y[1]
→(x = y)

and
1_1(f ) ↔Def Svm(f ) &

∀x ∈f, y ∈f
 
x[2] = y[2]
→(x = y)

.
Similarly the fact that f|a is additive in both its parameters follows immediately
from its deﬁnition, which is
f|a =Def

p ∈f | p[1] ∈a

.
Many small theorems used later in this book follow more or less immediately using
proof by monotonicity. Some of these are
Theorem:

(G ⊆F) & Is_map(F)

→Is_map(G),
Theorem:

(G ⊆F) & Svm(F)

→Svm(G),
Theorem:

(G ⊆F) & 1_1(F)

→1_1(G),
Theorem:

Is_map(F) & Is_map(G)

→Is_map(F ∪G),
Theorem: F|A∪B = F|A ∪F|B,
Theorem: (F ∪G)|A = F|A ∪G|A.
The veriﬁer’s proof-by-monotonicity mechanism can examine statements whose
topmost operator (after explicit or implicit universal quantiﬁers have been stripped
off) is ‘→’ to see if the conclusion of the implication found is an inclusion derivable
from the implication’s hypotheses via proof by monotonicity. This allows a one-step
derivation of statements like (4.5) considered above.
4.3.5 Algebraic Deduction
Once the sequence of set-theoretic proofs with which we will be concerned in
Chap. 5 has moved along to the point at which the integers, rationals, and reals have

228
4
More on the Structure of the Veriﬁer System
been deﬁned and their main properties established, the normal apparatus of algebraic
proof becomes important. One relies on this to establish useful elementary identities
on algebraic expressions, and also to show that algebraic combinations of elements
belonging to particular sets (e.g. integers, reals, real functions and sequences, etc.)
belong to these same sets. Inferences of this latter sort follow readily by syntac-
tic transitivity arguments of the kind discussed already. Algebraic identities follow
readily by expansion of multivariate polynomials to normal form, or by systematic
or randomized testing of the values of polynomials and rational functions. Expan-
sion to normal form can be used even for non-commutative multiplication operators.
To enable ‘proof by algebra’ for particular addition, subtraction, and multiplica-
tion operators, one issues a veriﬁer command of a form like8
ENABLE_ALGEBRA(s;⊕;⊗)
or
ENABLE_ALGEBRA

s;⊕(zero_constant);⊖;⊗

or
ENABLE_ALGEBRA

s;⊕(zero_constant);⊖;⊗(unit_constant)

etc. An example is
ENABLE_ALGEBRA

N;+(∅);·

{∅}

where N denotes the set of integers. In these commands ‘s’ should designate the
set in which the algebraic operators work and on which they are closed. If a
‘zero_constant’ is supplied with the ⊕, it should designate the additive identity for
the system. Similarly, if a ‘unit_constant’ is supplied with the ⊗, it should designate
the multiplicative identity for the system.
The ENABLE_ALGEBRA command scans the list of all currently available theo-
rems for theorems which reference the operators and object s appearing as ENABLE-
_ALGEBRA parameters, collecting all those which state required algebraic rules like

∀x ∈s,y ∈s | (x ⊕y) ∈s & (x ⊕zero_constant) = x

and similar commutative, associative, and distributive rules. Automatic algebraic
reasoning is turned on if proofs of all the basic axioms of polynomial arithmetic are
found. To suspend the use of algebraic reasoning for a given collection of operators
one writes a command like
DISABLE_ALGEBRA(⊕),
where ⊕designates the addition operator that must be present in the group of oper-
ators whose automated treatment is being disabled.
8A primitive, ALGEBRA, supporting algebraic deduction is available in the Ref system as imple-
mented, but the ENABLE_ALGEBRA directive is not implemented yet.

4.3
Other Techniques Used in the Veriﬁer as Implemented
229
4.3.6 Proof by Closure
Proof by closure is an important special case of the more general ‘proof by structure’
technique explained in the next section. It works in those common cases in which
certain small theorems of the general form

P1(x) & P2(y) & ··· & Pk(y)

→Q

f (x,y)

will be applied repeatedly. The three statements
(x ∈N & y ∈N) →(x + y) ∈N,

x ∈Z & y ∈Z & Is_nonnegZ(x) & Is_nonnegZ(y)

→Is_nonnegZ(x ∗Z y),

x ∈Z & y ∈Z & Is_nonzeroZ(x) & Is_nonzeroZ(y)

→Is_nonzeroZ(x ∗Z y),
where N denotes the set of integers and Z the set of all signed integers are examples.
Common arguments involving obvious uses of such results can be handled by
examining the syntax tree of functional expressions e mentioned in the course of
a proof, and marking each with all of the monadic attributes the veriﬁer has been
instructed to track. All the nodes in the syntax tree of such e are then marked with
the attributes which visibly apply, by a ‘workpile’ algorithm which works by tran-
sitive closure, examining each parent node one of whose children has just acquired
a new attribute, until no additional attributes result. The propositions generated by
this technique are then made available in the current proof context without explicit
mention, for use in other proof steps.
To enable this kind of automatic treatment of particular predicates, one issues a
veriﬁer command of forms like9
WATCH

x : x ∈Z; x : Is_nonnegZ(x); x : Is_nonzeroZ(x)

.
The veriﬁer then scans the list of all currently available theorems for theorems
whose hypotheses are all conjunctions of statements involving the currently enabled
predicates with a single variable as argument, and whose conclusions are clauses
asserting that some combination of these variables also has a property deﬁned by a
predicate being watched. To drop one or more predicates from watched status, one
issues a veriﬁer command of a form like
DONT_WATCH

x : x ∈Z; x : Is_nonnegZ(); x : Is_nonzeroZ()

.
The conclusions produced by the WATCH mechanism automatically become
available to the veriﬁer’s other proof mechanisms, but can also be captured explicitly
by an inference introduced by the special keyword THUS, which also has access to
the conclusions produced by the algebraic inference mechanisms described above.
9As of today, the directives WATCH and DONT_WATCH have not been implemented in Ref.

230
4
More on the Structure of the Veriﬁer System
This makes accelerated inferences like the following possible. Suppose that a state-
ment ‘x ∈Z’ has been established. Then the inference
THUS =⇒

(x ∗Z x) +Z

(x ∗Z x) ∗Z (x ∗Z x)

∈Z
& Is_nonnegZ

(x ∗Z x) +Z

(x ∗Z x) ∗Z (x ∗Z x)

is immediate.
4.3.7 The Behind-the-Scenes Activity of Proof by Structure
Ref’s typelessness contrasts with the more elaborate type systems common in some
other automated proof systems. Setting efﬁciency considerations aside (Ref typi-
cally veriﬁes roughly 200 proofs per minute, so these are not of central interest), the
advantage of a type system from the point of view of a proof system’s user is that
numerous small statements concerning the membership of variables in sets key to
mathematical discourse (such as the reals, the integers, the real sequences, etc.) are
handled implicitly. Once an appropriate type system has been set up, this implicit
treatment makes such statements available without further user effort. But a famil-
iar disadvantage of static typing is that, once introduced into a system’s foundations,
it tends to become over-rigid. This inspires efforts to generalize type systems, and
tends to generate baroque intellectual structures unfamiliar to the working mathe-
matician.
For this reason Ref prefers the ‘lean and mean’ typeless approach of Zermelo–
Fraenkel–von Neumann set theory. But then, to recapture the main advantages of a
typed approach, it provides the internal, dynamic, type-like mechanism called ‘proof
by structure’ described in the following paragraphs.
Proof by structure uses a simple internal language of structure descriptors
(“types”, in a weak sense) to keep track of the top structural levels of sets appearing
in scenario proofs. Any special set deﬁned in a scenario, for example N, the set of
all integers, or R, the set of all reals, can be used as a primary structure symbol in
this language. This descriptor attaches to all members of the set, for instance any
integer has the descriptor N. A signiﬁcant but less basic example is Z+, the set of
all non-negative signed integers, which does not occur in our present scenarios but
could easily be deﬁned. Structure descriptors need not be conﬁned to sets, but can
also designate classes, like the classes Ord and Card of all ordinals and of all car-
dinals, the classes Finite and Inﬁnite of all ﬁnite and of all inﬁnite sets, the class
NonVoid of all nonnull sets and the class V of all sets.
Given any symbols S,S1,S2,... representing structures, we can then form new
structure descriptors:
1. {S} describes a set all of whose elements have the descriptor S. For example,
the set N has the descriptor {N}; the set P(N) of all sets of integers has the
descriptor {{N}}.

4.3
Other Techniques Used in the Veriﬁer as Implemented
231
2. [S1,S2] describes a pair whose components have, respectively, the descriptors S1
and S2.
These constructions can be compounded. For example
1. {[N,N]} describes a set of integer pairs (and so applies to Z, the set {[i,j]: i ∈
N,j ∈N| i = 0 ∨j = 0} of signed integers);
2. {[N,V ]} describes a map from integers to elements of any kind, e.g. it describes
any ﬁnite or inﬁnite(ly denumerable) sequence.
A given set can have several descriptors. For example, a ﬁnite sequence of signed
integers has the descriptors {[N,Z]} and Finite. Since Z itself has the descriptor
{[N,N]}, a sequence of signed integers also has the descriptor {[N,[N,N]]}, which
in any given situation we may wish either to use or ignore. Inﬁnite sequences of
rationals have the descriptors {[N,Q]} and Inﬁnite. Real numbers in Cantor’s rep-
resentation are equivalence classes of such sequences, and accordingly have the
descriptors {{[N,Q]}} and {Inﬁnite}.
The veriﬁer’s internal proof-by-structure mechanism tracks the descriptors of
variables and expressions appearing in proofs as precisely as it can. For example, a
variable x known to satisfy a clause x ∈N has the descriptor N, while if x is known
to satisfy x ∈Z it gets the descriptors Z and [N,N].
Setformers and other basic constructors operate in a known way on structure
descriptors. Suppose, for example, that s is a set known to have some descriptor
{D}, and that e(x) is an expression having the free variable x. Suppose that e(x) can
be seen to map elements having the descriptor D into elements having the descriptor
D′. Then

e(x): x ∈s | P

has the descriptor {D′}, while

x,e(y)

: x ∈s, y ∈s | P

has the descriptor {[D,D′]}.
When a set s is known to have a descriptor {D}, any element x for which x ∈s
has been proved is known to have the descriptor D. If D is a primitive descriptor rep-
resenting a special set, this gives us the assertion x ∈D, for example x ∈N, which
may be needed as an auxiliary hypothesis for the application of some theorem. Sim-
ilarly any set s having the descriptor {[N,N]} is known to satisfy Is_map(s), and
also

∀x ∈s | x[1] ∈N & x[2] ∈N

.
Deriving conclusions of this kind automatically is the principal function of the sys-
tem of structure descriptors.
Many other basic set-theoretic operations have known effects on descriptors.
These often follow from the deﬁnitions of the operators in question. For example:
(1) If s has the descriptor {D}, then so does every one of its subsets, and P(s)
has the descriptor {{D}}.

232
4
More on the Structure of the Veriﬁer System
(2) If s has the descriptor {{D}}, then s has the descriptor {D}. Note hat this
follows automatically from the deﬁnition
{x : y ∈s, x ∈y }
of s, since the bound variable y in the iterator has the descriptor {D}, so
each of the x has the descriptor D, and the set as a whole has the descriptor
{D}.
(3) If s1 and s2 both have a descriptor {D}, then so does s1 ∪s2.
(4) If s1 and s2 both have the descriptor Finite, then so does s1 ∪s2.
(5) If s1 and s2 have descriptors {D1} and {D2}, respectively, then s1 ∩s2 has both
descriptors {D1} and {D2}. Even if s2 has no descriptor, s1 ∩s2 and s1 \s2 have
the descriptor {D1}, as does any set s for which an assertion s ⊆s1 has been
proved.
(6) If s1 has the descriptor Finite, so do s1 ∩s2 and s1 \ s2, as does any set s for
which an assertion s ⊆s1 has been proved.
(7) If s1 and s2 have the descriptor Finite, so does any set former
{e : x ∈s1, y ∈s2 | P },
or any set former {e : x ∈s1 | P}.
(8) #s always has the descriptor Card. Since the class of cardinals has the descrip-
tor {Ord}, #s also has the descriptor Ord, as does any x known to be a cardinal.
If s has the descriptor Finite, then #s has the descriptor N. Since N itself has
the descriptor {Finite}, #s also has the descriptor Finite.
(9) If s has the descriptor {D}, then any set former like {x : x ⊆s | P} is known
to have the descriptor {{D}}; this result obviously generalizes.
(10) If sets s and t have the descriptors {D} and {D′}, respectively, then their Carte-
sian product s × t has the descriptor {[D,D′]}. If s and t both have the de-
scriptor Finite, so does s × t.
(11) If s and t have descriptors {[D,D′]} and {[D′,D′′]}, respectively, then t ◦s
has the descriptor {[D,D′′]}. If s and t both have the descriptor Finite, so does
t ◦s.
(12) If s and t have descriptors D,D′, respectively, then [s,t] has the descriptor
[D,D′]. If u has the descriptor [D,D′], then u[1] has the descriptor D and
u[2] has the descriptor D′.
(13) If F has the descriptor {[D,D′]}, then its inverse (F)−1 has the descriptor
{[D′,D]}, and any of its domain restrictions F|s has the descriptor {[D,D′]}.
If F has the descriptor Finite, then (F)−1 and F|s both have the descriptor
Finite also.
There may be useful extensions of these ideas to single-valued and one-one maps;
also to topological situations, spaces of continuous functions, etc.
Some important conclusions result immediately by use of structure descriptors.
For example, the cardinal sum of s1 with s2 is deﬁned as
#

[x,0]: x ∈s1

∪

[x,1]: x ∈s2

,

4.3
Other Techniques Used in the Veriﬁer as Implemented
233
making it obvious that the sum of two integers is an integer. Similarly, the deﬁnition
of cardinal product, namely
#

[x,y]: x ∈s1, y ∈s2

makes it obvious that the product of two integers is an integer. Since the difference of
integers n,m is deﬁned by #(n \ m), it also follows immediately that the difference
of integers is an integer.
Ordinals also have the descriptor {Ord}, since any element of an ordinal is an
ordinal. Any s of a set having the descriptor {Ord} has the descriptor Ord. It may
be worth carrying the set next(N) as an additional descriptor. If this is done, s will
be known to have the descriptor next(N) if s has the descriptor {N}, and so to have
the descriptor N (i.e. to be an integer) if there is another s′ having the descriptor
next(N) for which a statement s ∈s′ is available.
In many cases a deﬁnition or theorem appearing in a scenario will characterize
the action on structure descriptors of one or more of the function symbols appearing
in it. The examples given just above illustrate this. Such facts, combined with the
other rules given above, extend the veriﬁer’s ability to track the structures of objects
appearing in proofs. For example, if s, t, and u are sets known to have the descriptor
{N}, then

(x ∗y) + z: x ∈s, y ∈t, z ∈u | P

is also known to have the descriptor {N}.
The theory of summation yields the fact that f has the descriptor D if f has
the descriptors {[d,D]} and Finite, and if the ⊕operator appearing in the summation
can be shown to map pairs of objects having the descriptor D into objects having
this same descriptor. Thus, for example, the sum or product of any set former like

[x,y,z],(x ∗y) + z

: x ∈s, y ∈t, z ∈u | P

is also known to be an integer if s, t, and u are sets known to have the descriptors
{N} and Finite.
The structure deﬁnition mechanism explained above carries over in a useful way
to recursively deﬁned functions (in our set-theoretic context, these can be functions
deﬁned by transﬁnite induction). To see why such extension is possible, we ﬁrst note
that the system of descriptors extends readily to function symbols, since these are
very close semantically to sets of pairs. For example, the descriptor {[D1,D2]} can
be ascribed to any one-parameter function symbol which maps each object having
the descriptor D1 into an object having the descriptor D2. Similarly, the descrip-
tor {[[D1,D2],D3]} can be ascribed to any two-parameter function symbol which
yields an object having the descriptor D3 whenever its two parameters have the re-
spective descriptors D1 and D2. (For example, the integer addition operator + has
the descriptor {[[N,N],N]}, but also the descriptors {[[V ,V ], Ord]}, since it always
produces an ordinal, and the descriptor {[[Finite,Finite],N]}, since it produces an in-
teger for any two ﬁnite inputs.) In the three-parameter case, {[[[D1,D2],D3],D4]}

234
4
More on the Structure of the Veriﬁer System
can be ascribed to any three-parameter function symbol which yields an object hav-
ing the descriptor D4 whenever its three parameters have the respective descriptors
D1, D2, and D3.
Using these descriptors, we can state the rule for function application as follows:
If a one-parameter function symbol f has the descriptor {[D1,D2]}, and x has the
descriptor D1, then f (x) has the descriptor D2. Similarly, if a two-parameter func-
tion symbol f has the descriptor {[[D1,D2],D3]}, and its two arguments x1,x2
have the descriptors D1,D2, then f (x1,x2) has the descriptor D3. We leave it to the
reader to formulate the rules for more than two arguments.
Function compounding acts in an obvious way on descriptors, for example if f
has the descriptor {[D1,D2]} and g has the descriptor {[D2,D3]}, then g(f (·)) has
the descriptor {[D1,D3]}. Rules like this make it obvious why
#

[x,0]: x ∈s1

∪

[x,1]: x ∈s2

,
yields an integer for every pair of integer arguments: the functional expression
{[x,0]: x ∈s1} has the descriptor {[Finite, Finite]} simply because it is a set for-
mer with s1 as its only free variable, and likewise for {[x,1]: x ∈s2}. Since the
union operator ∪has the descriptor {[[Finite, Finite], Finite]}, it follows immediately
that {[x,0]: x ∈s1} ∪{[x,1]: x ∈s2} has the descriptor {[[Finite, Finite], Finite]}
also. Since # has the descriptors {[Finite,Finite]} and {[V , Ord]}, #({[x,0]: x ∈
s1} ∪{[x,1]: x ∈s2}) has the descriptors {[[N,N],Finite]} and {[[N,N],Ord]}, and
therefore {[[N,N],N]}. Much the same argument applies to the integer product.
Next consider a transﬁnite recursive deﬁnition of one of the general types we
allow, namely
f (s,t) =Def d

g

f

x,h(s,t)

,s,t

: x ∈s
 P

x,f

x,h(s,t)

,s,t

,s,t

,
where we assume that the functions d, g, and h have been deﬁned prior to the
occurrence of the recursive deﬁnition shown. In working with this deﬁnition one
needs to establish that f has some descriptor {[[D1,D2],D3]}, i.e. that it yields
an element having descriptor D3 for any input arguments with descriptors D1,D2,
respectively.
This conclusion is valid under the following circumstances: we need to know that
the null set has descriptor D1, that one can ascribe the descriptor {D1} to any set
which has the descriptor D1, and that there exists a descriptor D′ such that
(a) h has the descriptor {[[D1,D2],D2]};
(b) g has the descriptor {[[[D3,D1],D2],D′]};
(c) d has the descriptor {[[[{D′},D1],D2],D3]}.
Then in the ground case of the transﬁnite recursive deﬁnition f (∅,t) has the value
d(∅,s,t), and so must produce an element with the descriptor D3. In the remaining
case it follows inductively (given that s and t have the respective descriptors D1,D2)
that f (x,h(s,t)) has the descriptor D3 for every x ∈s, so that g(f (x,h(s,t)),s,t)
has the descriptor D′, and so

g

f

x,h(s,t)

,s,t

: x ∈s
 P

x,f

x,h(s,t)

,s,t

(4.7)

4.3
Other Techniques Used in the Veriﬁer as Implemented
235
has the descriptor {D′}. Therefore the right side of the recursive deﬁnition seen
above has the descriptor D3, and it follows inductively that f has the descriptor
{[[D1,D2],D3]}.
If s has the descriptor Finite, then the set (4.7) will have this descriptor also, and
so if d has the descriptor {[[[Finite, Finite],D2], Finite]}, f will have the descriptor
{[[Finite,D2], Finite]}. On the other hand, if d is a monadic operator like the selector
arb (which is postulated to satisfy arb(∅) = ∅& (X ̸= ∅→arb(X) ∈X)), and so
has the descriptor {[{D3},D3]} (where the null set must have the descriptor D3),
then g must have the descriptor {[[[Finite, Finite],D2], Finite]}, and s the descriptors
{Finite} and Finite, for f (s,t) to have the descriptor Finite. In this case f has once
again the descriptor {[[Finite,D2], Finite]}.
4.3.8 ‘Blobbing’ More General Formulae Down to a Speciﬁed
Decidable or Semi-decidable Sublanguage of Set Theory
‘BLOBBING’ captures Aristotle’s insight that statements true in logic are true be-
cause their form can be matched to some template known to generate true statements
only. The basic syntactic technique which it involves can be explained as follows:
Suppose that we are given a language L for which a full or partial decision algorithm
is available. Then any formula F can be ‘reduced’ or ‘blobbed down’ to a formula
in the language L, in the following way. Work top-down through the syntax tree
of F , until some operator not belonging to the language L is encountered. Replace
the whole subexpression G below this level by a ‘blob’, i.e. by a freshly generated
variable (either individual or propositional, as appropriate).
‘Blobs’ generated in this way from separate subformulae of F should be made
identical wherever possible; this can be done whenever they are structurally iden-
tical up to renaming of bound variables, or where part of the structure belongs to
an equational theory for which a decision or quasi-decision algorithm is available.
The ‘blobbed’ variant of F is the formula that results from this replacement. If the
blobbed version of F is a consequence of the blobbed versions of the union of all
our previous assumptions and conclusions, then F follows from these assumptions
and conclusions, and can therefore be added to the set of available conclusions.
‘Default’ or ‘ELEM’ deduction is the special case of this general observation which
results when we blob down to an extended multilevel syllogistic, of the kind de-
scribed above.
The following is an example of ‘blobbing’. Given the input formula

m(x): x ∈s | x ⊆t

⊆

m(x): x ∈s | x ∈t

&

m(x): x ∈s | x ∈t

⊆

m(x): x ∈s | x ⊆t ∨r

→

m(y): y ∈s | y ⊆t

⊆

m(x): x ∈s | x ⊆t ∨r

,

236
4
More on the Structure of the Veriﬁer System
its blobbed version (blobbed down to the elementary theory of sets and inclusion
relationships) is
(1_ ⊆2_ & 2_ ⊆3_) →1_ ⊆3_
which makes the truth of our original, rather enigmatic formula obvious.
4.3.9 Accelerated Instantiation of Quantiﬁers and Set Formers
Steps which simply generate instances of quantiﬁed formulae and implicitly quan-
tiﬁed formulae involving set formers are common in the proofs in which we will be
interested. For example, we may need to deduce the contradiction
¬

e(c) = e(a) & a ∈s

,
for some fresh symbol a, from the set-theoretic statement
e(c) /∈

e(x): x ∈s

,
or to deduce

a ∈s & c = e(a) & P(a)

& ¬

a ∈s & c = e′(a) & P ′(a)

∨

¬

b ∈s & c = e(b) & P(b)

&

b ∈s & c = e′(b) & P ′(b)

,
where a and b are two newly generated symbols, from a previously proved set-
theoretic statement

c ∈

e(x): x ∈s | P(x)

& ¬

c ∈

e′(x): x ∈s | P ′(x)

∨

¬

c ∈

e(x): x ∈s | P(x)

& c ∈

e′(x): x ∈s | P ′(x)

.
Our veriﬁer handles steps of this common kind in the following friendly way.
All variable names which are not explicitly bound by quantiﬁers (or bound in set
formers) are temporarily regarded as ‘constants’, i.e. substitutions for them are tem-
porarily forbidden. We ﬁrst search for quantiﬁers, which may be nested several lev-
els deep within propositional structures like

∀x | P(x)

& ···

∃y | Q(y)

···

∨··· →···¬

∀z| R(z)

···
but not nested within other quantiﬁers. We generate unique bound variables for each
of these quantiﬁers, also making sure that they are distinct from any free variables
that appear.
Each quantiﬁer in such a propositional structure has an implicit ‘sign’, deter-
mined by the following simple rules:

4.3
Other Techniques Used in the Veriﬁer as Implemented
237
(i) Un-nested universals are positive, while un-nested existentials are negative.
(ii) The nesting of a quantiﬁer within a construction a & b or a ∨b does not affect
its sign.
(iii) Each level of nesting of a quantiﬁer within a negation ¬a reverses its sign, e.g.
¬···¬···¬···(∃y | Q(y)) is positive.
(iv) a →b is simply (¬b) ∨a.
In nested propositional constructs like those shown above, we could if we wanted
move any quantiﬁer out to the front by using the standard rules

∀x |

P(x) & A

↔

∀x | P(x)

& A


∀x |

P(x) ∨A

↔

∀x | P(x)

∨A


∃x |

P(x) & A

↔

∃x | P(x)

& A


∃x |

P(x) ∨A
 ↔

∃x | P(x)

∨A

,
where we assume that the variable x is not free in A. Once moved out these quanti-
ﬁers could be instantiated, subject to the normal rules:
(a) Only a previously unused constant symbol can be substituted for a negatively
(existentially) quantiﬁed bound variable.
(b) Any constant expression at all can be substituted for a positively (universally)
quantiﬁed bound variable.
It is clear that the instantiations allowed by these rules can be performed without
the preliminary step of moving the quantiﬁer to the front. Any number of negative
quantiﬁers can be replaced, one after another, by hitherto unused constant symbols.
Then any number of positive quantiﬁers can be replaced by any desired expressions.
It is clear that these rules apply also to nested quantiﬁers, which can be subjected to
sequences of instantiations moving inward. Note, however, that an existential nested
within a universal can never be instantiated unless the universal is ﬁrst instantiated
in accordance with the rule we have stated.
Given a formula F and a second F ′, it is easy to determine, by comparing their
syntax trees, whether F ′ arises from F by such a set of instantiations. If it does, then
F ′ is valid deduction from F . Our veriﬁer allows steps of this kind to be indicated
simply by writing the keyword INSTANCE.10
Here are a few examples showing that this works well for various familiar pure-
predicate cases:
To prove

∀x | P(x)

→

∃x | P(x)

we form its negative

∀x | P(x)

& ¬

∃x | P(x)

10While the accelerated instantiation mechanism is implemented in the current Ref system, the
INSTANCE facility is not available yet: the instantiating substitution must be indicated explicitly.

238
4
More on the Structure of the Veriﬁer System
and then the instance
P(c) & ¬P(c)
which is clearly impossible, proving the validity of our ﬁrst statement. Similarly we
can prove the validity of

∃y
 
∀x | P(x,y)

→

∀x
 
∃y | P(x,y)

by forming its negative, which is

∃y
 
∀x | P(x,y)

&

¬

∀x
 
∃y | P(x,y)

,
and then instantiating this to the impossible P(d,c) & ¬P(d,c).
Statements involving membership in set formers can be treated in much the same
way, since
a ∈

e(x): x ∈s | P(x)

is a synonym for

∃x | a = e(x) & x ∈s & P(x)

.
Thus every membership (resp. non-membership) statement counts initially as nega-
tive (resp. positive) and instantiates to a = e(c) & c ∈s & P(c) (resp. a ̸= e(c)∨c /∈
s ∨¬P(c)), where c must be a new constant if the context of the set former makes it
negative, but can be any expression if the context of the set former makes it positive.
This observation makes it possible to recognize the deduction shown at the very
start of this section as an instantiation, which can be written as
INSTANCE(Stat1) =⇒¬

e(c) = e(c) & c ∈s

in our veriﬁer. Similarly, the deduction in the second example at the start of this
section is a combination of positive and negative instantiations which can be written
as
INSTANCE(Stat2) =⇒

a ∈s & c = e(a) & P(a)

& ¬

a ∈s & c = e′(a) & P ′(a)

∨

¬

b ∈s & c = e(b) & P(b)

&

b ∈s & c = e′(b) & P ′(b)

.
Note ﬁnally that the Boolean equivalence operator ‘↔’ must be decomposed into
its two parts a & b ∨(¬b) & (¬a), since these give different signs to quantiﬁers or
set formers nested within them.
4.3.10 Computation with Hereditarily Finite Sets
Set theory, as we will work with it later in this book, is a family of sentences con-
cerning objects, some of which lie far beyond the ﬁnite realm within which conven-

4.3
Other Techniques Used in the Veriﬁer as Implemented
239
tional computational mechanisms can operate. But the hereditarily ﬁnite sets consid-
ered earlier are accessible to computation and can model all standard computational
processes in quite a satisfactory way. These are the sets which can be constructed
starting from the null set {} by repeatedly forming sets of the form {s1, s2,...,sn }
using elements s1,s2,...,sn previously deﬁned. Five examples are
{},

{}

,

{},

{}

,

{},

{}

,

{}

,

{},

{}

, etc.
We can readily deﬁne the standardized representation rep(s) of each such set s
recursively as
rep(s) =

rep(s1), rep(s2),..., rep(sn)

,
where we assume that (after duplicates have been removed) the elements on the right
are arranged in lexicographic order. This is the particular ordering which places a
set d before another set t (where both d and t are hereditarily ﬁnite and d ̸= t) when
the following holds: if the elements of the ‘symmetric difference’ (d \ t) ∪(t \ d)
are recursively arranged in lexicographic order, then the largest of them happens to
belong to t.
Any suitable computer encoding of the system of strings deﬁned in this way can
be used as the basis of a system for programmed computation with (entirely general)
hereditarily ﬁnite sets.
Hereditarily ﬁnite sets satisfy several general induction principles. If there exists
a hereditarily ﬁnite set (resp. ﬁnite) t satisfying P(t), where P is any predicate, then
there also exists a hereditarily ﬁnite (resp. ﬁnite) set t′ satisfying
P(t′) &

∀t ⊆t′ | (t ̸= t′) →¬P(t)

.
A second induction principle that is sometimes easier to apply is as follows. If
there exists a hereditarily ﬁnite set t satisfying P(t), where P is any predicate, then
there also exists a hereditarily ﬁnite set t′ satisfying
P(t′) &

∀t ∈t′ | ¬P(t)

.
This second induction principle remains valid for inﬁnite sets.
An adequate computational system based on hereditarily ﬁnite sets needs only
the following modest collection of primitives.
(i) Given a set s, we can form the singleton set {s}. (This primitive function maps
sets to sets.)
(ii) Any two sets can be tested for equality (they are equal if and only if their
standard representations are the same). (The primitive s1 = s2 maps pairs of
sets to Boolean values.)
(iii) Any set s can be tested for membership in any other. s1 is a member of s2 if
and only if s1 is equal to one of the items in the list of members deﬁning s2.
(The primitive s1 ∈s2 maps pairs of sets to Boolean values.)

240
4
More on the Structure of the Veriﬁer System
(iv) We can ﬁnd an element arbb(s) of any set s other than the null set. (This
primitive function maps sets to sets.) It is convenient to let x = arbb(s) be
the ﬁrst element of s in the lexicographic order described above. This ensures
that arbb(s) and s have no element in common, since if there were any such
element y, then y would come before x in the standard order of elements of x
(indeed, an easy inductive argument shows that v lexicographically precedes
u whenever v ∈u), contradicting our assumption that x is the ﬁrst of these
elements. (To complete the deﬁnition of the function arbb, it is convenient to
put arbb({}) = {}.)
(v) Given two sets s1, s2 we can form the set s1 with s2 obtained by adding s2 to
the list of elements of s1. If s2 is already on this list, then s1 with s2 is just s1.
(This primitive maps sets to sets.)
(vi) Given two sets s1, s2 we can form the set s1 less s2 obtained by removing s2
from the list of elements of s1. If s2 is not on this list, then s1 with s2 is just s1.
(This primitive also maps sets to sets.)
(vii) New set-valued and new Boolean-valued functions of hereditarily ﬁnite sets
can be introduced by writing (direct or recursive) deﬁnitions
function name(s1,s2,...,sn);
return if cond1 then expn1
elseif cond2 then expn2
···
elseif condm then expnm
else expnm+1 end if ;
end name.
Here all the cond1,...,condm must be nested, Boolean-valued expressions
built using primitive or previously deﬁned function names, plus the elemen-
tary Boolean operations &, ∨, ¬, etc., the constant ∅representing {}, and the
variables s1,s2,...,sn. Either all the expn1,expn2,...,expnm+1 must be set-
valued, in which case the deﬁned function ‘name’ is also set-valued, or all the
expn1,expn2,...,expnm+1 must be Boolean-valued, in which case the deﬁned
function ‘name’ is also Boolean-valued.
Function deﬁnitions of this type can be used to program many other basic and
advanced set-theoretic functions. For example, we can write
function union(s1,s2);
return if s1 = ∅then s2
else union

s1 less arbb(s1), s2

with arbb(s1) end if ;
end union;
function difference(s1,s2);
return if s2 = ∅then s1
else difference

s1 less arbb(s2), s2 less arbb(s2)

end if ;
end difference;

4.3
Other Techniques Used in the Veriﬁer as Implemented
241
function incs(s1,s2);
return difference(s2,s1) = ∅;
end incs;
function intersection(s1,s2);
return difference

s1, difference(s1,s2)

;
end intersection;
function next(s); return s with s; end next;
function last(s);
return if s = ∅then ∅elseif s =

arbb(s)

then arbb(s)
else last

s less arbb(s)

end if ;
end last;
function prev(s); return s less last(s); end prev;
function is_integer(s);
return if s = ∅then true
else s = next

prev(s)

& is_integer

prev(s)

end if ;
end is_integer.
Note that the hereditarily ﬁnite sets s for which is_integer(s) is true are precisely
those of the recursive form

{},

{}

,

{},

{}

,...,prev(s)

,
which represent integers in their von Neumann encoding. For such integers n we
have last(n) = n −1, last(n −1) = n −2, etc.
From here we can easily go on to deﬁne the cardinality operator and all the
standard arithmetic operations, e.g.
function #s;
return if s = ∅then ∅
else next

#

s less arbb(s)

end if ;
end #;
function sum(s1,s2);
return if s1 = ∅then #s2
else next

sum

prev(s1),s2

end if ;
end sum;
function product(s1,s2);
return if s1 = ∅then ∅
else sum

s2, product

prev(s1),s2

end if ;
end product;

242
4
More on the Structure of the Veriﬁer System
function exp(s1,s2);
return if s2 = ∅then {∅}
else product

s1, exp

s1, prev(s2)

end if ;
end exp;
function minus(s1,s2); return #difference(s1,s2); end minus.
Our next group of procedures lets us work with maps:
function ordered_pair(s1,s2);
return

{s1},

{s1},

s2, {s2}

;
end ordered_pair;
function s[1]; return arbb

arbb(s)

; end _ [1];
function s[2];
return arbb

s less arbb(s)

less arbb(s)[1];
end _ [2];
function is_pair(s);
return s = ordered_pair

s[1],s[2]
;
end is_pair;
function is_map(s);
return if s = ∅then true
else is_pair

arbb(s)

& is_map

s less arbb(s)

end if ;
end is_map;
function domain(s);
return if s = ∅then ∅
elseif is_pair

arbb(s)

then
domain

s less arbb(s)

with arbb(s)[1]
else domain

s less arbb(s)

end if ;
end domain;
function range(s);
return if s = ∅then ∅
elseif is_pair

arbb(s)

then
range

s less arbb(s)

with arbb(s)[2]
else range

s less arbb(s)

end if ;
end range;
function is_single_valued(s);
return #s = #domain(s);
end is_single_valued;

4.3
Other Techniques Used in the Veriﬁer as Implemented
243
function restriction(s1,s2);
return if s1 = ∅then ∅
elseif is_pair

arbb(s1)

& arbb(s1)[1] ∈s2 then
restriction

s1 less arbb(s1), s2

with arbb(s1)
else restriction

s1 less arbb(s1), s2

end restriction;
function values_at(s1,s2);
return range

restriction

s2,{s1}

;
end values_at;
function value_at(s1,s2);
return arbb

values_at(s1,s2)

;
end value_at;
function last_of(s); return value_at

prev(#s), s

; end last_of.
Another useful notion is ‘s1 is a sequence of elements of s2’:
function is_sequence(s);
return is_map(s) & is_single_valued(s)
& is_integer

domain(s)

;
end is_sequence;
function is_sequence_of(s1, s2);
return is_sequence(s1)
& incs

s2, range(s1)

= ∅;
end is_sequence_of.
Function deﬁnitions like those seen above are said to be ‘mirrored in logic’ if for
each function deﬁnition
function name(s1,s2,...,sn);
return if cond1 then expn1
elseif cond2 then expn2
···
elseif condm then expnm
else expnm+1 end if ;
end name

244
4
More on the Structure of the Veriﬁer System
we have deﬁned a corresponding logical symbol ‘Name’ for which the statement

∀s1 ∈HF, s2 ∈HF,..., sn ∈HF|
Name(s1,s2,...,sn) = if cond1 then expn1
elseif cond2 then expn2
···
elseif condm then expnm
else expnm+1 end if

is available as a theorem. (In case ‘name’ is Boolean-valued, ‘↔’ must supersede
‘=’ in the above statement.) It will now be shown that every one of the function
deﬁnitions given above and all others like them can be mirrored in logic. This lets
us use the following general lemma as one of our mechanisms of deduction.
4.3.10.1 Mirroring Lemma
Lemma 4.1 (Mirroring) Let name(s1,s2,...,sn) be a set-valued function ap-
pearing in a sequence of functions deﬁned in the manner described above, and
let c1,c2,...,cn+1 be hereditarily ﬁnite sets represented by logical terms e1,e2,
...,en+1 as described above. Suppose that the calculated value of name(c1,c2,
...,cn) is cn+1. Suppose that ‘Name’ is the logical function symbol which mirrors
‘name’. Then the formula
Name(e1,e2,...,en) = en+1
is a theorem. Similarly, if ‘name’ is a Boolean-valued function, then
Name(e1,e2,...,en) ↔en+1
is a theorem.
Proof Our proof will proceed by induction on the number h of steps involved in an
evaluation of a function having a deﬁnition like
function name(s1,s2,...,sn);
return if cond1(s1,s2,...,sn) then expn1(s1,s2,...,sn)
elseif cond2(s1,s2,...,sn) then expn2(s1,s2,...,sn)
···
elseif condm then expnm(s1,s2,...,sn)
else expnm+1(s1,s2,...,sn) end if ;
end name
on the actual parameters c1,...,cn.
To get started, we must check that each primitive of our programming language
(singleton formation, equality, etc.) is properly mirrored by a suitable construct of

4.3
Other Techniques Used in the Veriﬁer as Implemented
245
our basic system of logic, which is trivial save for the case of arbb, which can-
not simply be mirrored by the choice operator arb. To see where the difﬁculty lies,
consider e.g. the doubleton set s = {{}, {{{}}}}; it is then plain that whereas the pro-
gramming operation arbb must give the result arbb(s) = {}, the logical operator arb
is not committed to do the same. However, we can introduce in logic a correspon-
dent ‘Arbb’ of arbb in the following fashion. We recursively deﬁne the lexicographic
strict ordering as
Smaller(x,y) ↔Def

v ∈y
 
w ∈(x ∪y)| Smaller(v,w)

⊆(x ∩y)

\ x ̸= ∅,
and then state that ‘Arbb’ must pick the smallest element out of any set x:
Arbb(x) =Def arb

v ∈x
 
w ∈x | Smaller(w,v)

= ∅

.
Suppose now that the assertion of the mirroring lemma is true for all evaluations
having fewer steps than h. The ﬁnal step in an evaluation of the recursive function
displayed above will end at some branch, say the kth branch, of the conditional
expression following the keyword ‘return’, and will be preceded by evaluation of
all the conditions
cond1(c1,c2,...,cn), cond2(c1,c2,...,cn),...,condk(c1,c2,...,cn)
which appear before this branch, and of the expression
expnk(c1,c2,...,cn)
occurring in the kth branch. This last expression will return some value ‘val’, which
then becomes the value cn+1 returned by the function ‘name’. In the situation con-
sidered, the ﬁrst k −1 Boolean conditions must have the value ‘false’ and the kth
must have the value ‘true’. Since all of these subevaluations must involve fewer
steps than h, there must exist proofs of the theorems
¬Cond1(e1,e2,...,en), ¬Cond2(e1,e2,...,en),...,
¬Condk−1(e1,e2,...,en),Condk(e1,e2,...,en),
and there must also exist a proof of the statement
Expnk(e1,e2,...,en) = en+1,
where ei designates ci for i = 1,...,n and en+1 designates val.
It follows from these results that we can prove
if Cond1(e1,e2,...,en) then Expn1(e1,e2,...,en)
elseif Cond2(e1,e2,...,en) then Expn2(e1,e2,...,en)
···
elseif Condm then Expnm(e1,e2,...,en)
else Expnm+1(e1,e2,...,en) end if = en+1.

246
4
More on the Structure of the Veriﬁer System
Since

∀s1 ∈HF, s2 ∈HF,...,sn ∈HF| Name(s1,s2,...,sn) =
if Cond1(s1,s2,...,sn) then Expn1(s1,s2,...,sn)
elseif Cond2(s1,s2,...,sn) then Expn2(s1,s2,...,sn)
···
elseif Condm(s1,s2,...,sn) then Expnm(s1,s2,...,sn)
else Expnm+1(s1,s2,...,sn) end if

,
this proves that Name(e1,e2,...,en) = en+1.
□
Note that the mirroring lemma only provides us with a way of proving statements
giving particular constant values of recursively deﬁned functions and predicates, but
not a way of proving any universally quantiﬁed statement. For example,
Domain

With

Ordered_pair(0,0)

, Ordered_pair(1,1)

= With

{0},1

follows by mirroring, but no universally quantiﬁed statement like

∀x | Is_integer(x) →

x = ∅∨

x = Next

Prev(x)

& Is_integer

Prev(x)

can be proved simply by mirroring. In fact, even a statement like
Domain

With

Ordered_pair(0,x)

, Ordered_pair(1,y)

= With(0,1)
lies beyond the reach of the mirroring lemma, since it involves the symbolic vari-
ables x and y.
4.3.10.2 Deduction by Semi-symbolic Computation
A useful and much more general ‘Deduction by semi-symbolic computation’ prim-
itive is included in our veriﬁer. This operation lets us use recursive relationships as
means of easy computational deduction within the completely controlled environ-
ment in which a veriﬁer must operate. The idea is to evaluate certain elementary
operations on hereditarily ﬁnite sets explicitly, while leaving all other expressions
unchanged. Recursive relationships are used as long as they apply, allowing complex
identities and logical equivalences to be derived by single deduction steps. We shall
see that this makes a wide variety of ‘Mathematica’-like (cf. [Wol03]) conclusions
directly available within the veriﬁer.
A prototypical example is furnished by the recursive identity

Is_seq(B) & m ∈domain(B) & range(B) ⊆N

→

(B|m) = if m = 0 then 0 else

(B|m) =

B|(m−1)

+ B[m] end if

4.3
Other Techniques Used in the Veriﬁer as Implemented
247
(where N denotes the set of integers, and the predicate Is_seq(t) is true if t is a
sequence, i.e. a mapping whose domain is either a ﬁnite integer or the set N of all
integers). This simple general theorem is easily proved using the deﬁnition of the
summation operator  that we shall see in Sect. 5.8. Deduction by semi-symbolic
computation lets us apply this in the case m = 100 to get the theorem

Is_seq(B) & 100 ∈domain(B) & range(B) ⊆N

→

(B|100) = 0 + B[0] + B[1] + ··· + B[100],
as an immediate conclusion. Clearly derivations of statements like this would other-
wise require tediously lengthy and repetitive sequences of steps. Another common
case is the evaluation of expressions like
Value_at

j,

Ordered_pair(0,x0), Ordered_pair(1,x1),..., Ordered_pair(k,xk)

,
which it would otherwise be tedious to deal with but which are easily handled by
semi-symbolic computation.
But in fact the method of deduction by semi-symbolic computation is much more
general. To explain this assertion, we must ﬁrst deﬁne an appropriate relationship
between the language of computation with hereditarily ﬁnite sets and the purely set-
theoretic language of the veriﬁer. This can be done as follows. We ﬁrst deﬁne the
relator x ∈+ s (“x is an eventual member of s”) by the following formula:

x ∈+ s

↔Def

x ∈s ∨

∃y ∈s | x ∈+ y

.
As highlighted above, operations on hereditarily ﬁnite sets which can be deﬁned
and evaluated recursively include all the propositional connectives, s1 ∪s2, s1 ∩s2,
s1 \s2, all elementary set comparisons, all quantiﬁers over hereditarily ﬁnite ranges,
all set formers over hereditarily ﬁnite ranges, #s, all elementary arithmetic opera-
tions, the pair-former [x, y], the operations s[1] and s[2] for pairs (note, however,
that the choice operator arb(s) cannot be calculated in this way), the set operators
range(s), domain(s), s, P(s), the predicate is_single_valued(s), set and tuple
formers by enumeration, the operator which evaluates the range of the restriction
f|s of a hereditarily ﬁnite map f to an hereditarily ﬁnite set s, the Cartesian product
operator s1 ×s2, the inverse-map operator f −1, the map-restriction operator f|s, the
concatenation operator s1 cat s2, if-expressions, case-expressions, and various oth-
ers. By the mirroring lemma proved above, the value produced when one evaluates
such an expression is always logically equal to the original expression, provided
of course that the operator signs appearing in the expression have their standard
meanings.

248
4
More on the Structure of the Veriﬁer System
Next suppose that an implication of the form

P(B) & s ∈HF

→F(s,B) = if C1(s) then e1(s,B)
elseif C2(s) then e2(s,B)
···
elseif Cn(s) then en(s,B)
else F(s,B) end if
has been shown to hold for all hereditarily ﬁnite sets s. We assume here that the
conditions Cj(s) involve only the elementary operations listed above. However, the
expressions ej(s,B) on the other hand can be more general, and involve:
(i) subexpressions e(1)
j (s) in which only elementary operations appear;
(ii) recursive appearances F(e(2)
j (s),B) of the function F , in which the parts
e(2)
j (s) contain only elementary operations;
(iii) other subexpressions;
(iv) other recursive appearances F(e(3)
j (s,B), e(4)
j (s,B)) of F .
This implication can be used as a recursive procedure in the following way: sup-
pose that P(B) is true and that s is a hereditarily ﬁnite set given explicitly. Cal-
culate all the conditions Cj(s) one after another, until one evaluating to ‘true’ is
found. (If none such is found, stop the computation; F(s,B) simply evaluates to
itself.) If some ﬁrst Cj(s) evaluates to ‘true’, calculate the corresponding ej(s,B)
recursively. This is done by going through the syntax tree of ej(s,B) in bottom-
to-top order, evaluating all elementary subexpressions of the form exp(s) directly,
expanding each recursive occurrence of F having the form F(e(s),B), where e(s)
is elementary, recursively, and leaving all other subexpressions untouched. If this
process fails to terminate it can simply be stopped after a while, but if it terminates
it will yield an identity F(s,B) = expn(s,B). Deduction by semi-symbolic compu-
tation makes this identity available as a theorem, in the form

P(B) & s ∈HF

→F(s,B) = expn(s,B).
A typical, relatively elaborate application of this general form of deduction by
semi-symbolic computation makes it possible to obtain ‘Mathematica’-like con-
clusions by syntactic means in a very direct way. Many of the ‘formula-driven’
parts of elementary and intermediate-level mathematics are covered by this tech-
nique.
Derivative manipulations in calculus furnish a characteristic example. Suppose,
e.g., that one has deﬁned the derivative ‘Deriv’ as a map from smooth functions of
a real variable to their derivative functions, and that the speciﬁc real functions ‘sin’,
‘cos’, ‘exp’, along with the basic rules for differentiation and the derivatives of these
speciﬁc functions, have also been deﬁned. This basic information can then be built
up in the following way into general symbolic-manipulation mechanisms allowing

4.3
Other Techniques Used in the Veriﬁer as Implemented
249
direct derivation of composite relationships like
Deriv

x, cos

cos(x)

: x ∈R

=

x, sin

cos(x)

∗R sin(x)

: x ∈R

, (4.8)
where R designates the set of real numbers. For this, we ﬁrst deﬁne an appropriate
class of (hereditarily ﬁnite) syntax trees as follows:
wf(t)↔Def

is_tuple(t) & #t = 3 & t[0] ∈{“ + ”,“ ∗”,“ −”} & wf

t[1]

& wf

t[2]

∨

is_tuple(t) & #t = 2 & t[0] ∈{“sin”,“cos”,“exp”} & wf

t[1]

∨

is_string(t) & t = “x”

∨is_integer(t).
Next we write a deﬁnition for the intended semantic meaning of a well-formed
tree, which for the example at hand is an elementary function of reals to reals:
tree_value(t) =Def if is_tuple(t) & #t = 3 & t[0] = “ + ” then
tree_value

t[1]

+′ tree_value

t[2]

elseif is_tuple(t) & #t = 3 & t[0] = “ ∗” then
tree_value

t[1]

∗′ tree_value

t[2]

elseif is_tuple(t) & #t = 3 & t[0] = “ −” then
tree_value

t[1]

−′ tree_value

t[2]

elseif is_tuple(t) & #t = 2 & t[0] = “cos” then
cos ◦tree_value

t[1]

elseif is_tuple(t) & #t = 2 & t[0] = “sin” then
sin ◦tree_value

t[1]

elseif is_tuple(t) & #t = 2 & t[0] = “exp” then
exp ◦tree_value

t[1]

elseif is_string(t) & t = “x” then

[x, x]: x ∈R

else

x, ﬂoat(t)

: x ∈R

end if.
(4.9)
Here the predicate is_tuple(t) states that t is a ﬁnite sequence (i.e. a mapping
whose domain is an integer). The operator +′ designates the pointwise sum of two
functions, namely
f +′ g =

x, f [x] + g[x]

: x ∈domain(f ) ∩domain(g)

,
and similarly for ∗′ and −′; note that “ + ” symbolizes real rather than integer sum-
mation here, and similarly for “ ∗” and “ −”. Also f ◦g will designate the compo-
sition of the two functions f and g. ‘ﬂoat’ is the function which embeds the integers
into the reals.

250
4
More on the Structure of the Veriﬁer System
The next step is to deﬁne the operation on trees which builds their formal deriva-
tives. This is
formal_deriv(t) =Def if wf(t) & #t = 3 & t[0] = “ + ” then

“ + ”, formal_deriv

t[1]

, formal_deriv

t[2]

elseif wf(t) & #t = 3 & t[0] = “ ∗” then

“ + ”,

“ ∗”, formal_deriv

t[1]

,t[2]

,

“ ∗”,t[1], formal_deriv

t[2]

elseif wf(t) & #t = 3 & t[0] = “ −” then

“ −”, formal_deriv

t[1]

, formal_deriv

t[2]

elseif wf(t) & #t = 2 & t[0] = “cos” then

“ −”,0,

“ ∗”,

“sin”,t[1]

, formal_deriv

t[1]

elseif wf(t) & #t = 2 & t[0] = “sin” then

“ ∗”,

“cos”,t[1]

, formal_deriv

t[1]

elseif wf(t) & #t = 2 & t[0] = “exp” then

“ ∗”,

“exp”,t[1]

, formal_deriv

t[1]

elseif wf(t) & t = “x” then 1
else 0 end if.
Given these deﬁnitions, it is not hard to prove the following recursive relation-
ship:

t ∈HF & wf(t)

→Deriv

tree_value(t)

= tree_value

formal_deriv(t)

.
In sketch, the proof is as follows: suppose not, i.e. suppose that there exists a t
such that
t ∈HF & wf(t) & Deriv

tree_value(t)

̸= tree_value

formal_deriv(t)

& wf

t[1]

& wf

t[2]

.
Choose a smallest such t, in the ordering deﬁned by the relationship ∈+. For this,
we must have
(j ∈N & 0 < j & j < #t) →

Deriv

tree_value

t[j]

= tree_value

formal_deriv

t[j]

.
(4.10)
From this, we can derive a series of conclusions which collectively contradict our
supposition. For example, if
is_tuple(t) & #t = 3 & t[0] = “ + ” & wf

t[1]

& wf

t[2]

,

4.3
Other Techniques Used in the Veriﬁer as Implemented
251
then we have
Deriv

tree_value

t[1]

= tree_value

formal_deriv

t[1]

&
Deriv

tree_value

t[2]

= tree_value

formal_deriv

t[2]

,
since t[1] ∈+ t & t[2] ∈+ t. Thus if
wf(t) & #t = 3 & t[0] = “ + ” & wf

t[1]

& wf

t[2]

,
so that tree_value(t) = tree_value(t[1]) +′ tree_value(t[2]) by (4.9), we must also
have
Deriv

tree_value(t)

= Deriv

tree_value

t[1]

+′ Deriv

tree_value

t[2]

by the standard theorem on the derivative of the sum of two real functions, which
we assume to have been proved separately, along with the corresponding elementary
results for products, quotients, sin and cos, exp, etc. Hence in this case the conjunct
(4.10) seen above cannot hold.
To apply this in the most convenient manner, we will sometimes require one more
inductive relationship for use as a computational rule, namely
tree_value(t)[x] = if wf(t) & #t = 3 & t[0] = “ + ” then
tree_value

t[1]

[x] + tree_value

t[2]

[x]
elseif wf(t) & #t = 3 & t[0] = “ ∗” then
tree_value

t[1]

[x] ∗tree_value

t[2]

[x]
elseif wf(t) & #t = 3 & t[0] = “ −” then
tree_value

t[1]

[x] −tree_value

t[2]

[x]
elseif wf(t) & #t = 2 & t[0] = “cos” then
cos

tree_value

t[1]

[x]

elseif wf(t) & #t = 2 & t[0] = “sin” then
cos

tree_value

t[1]

[x]

else wf(t) & #t = 2 & t[0] = “exp” then
exp

tree_value

t[1]

[x]

elseif wf(t) & t = “x” then x
else ﬂoat(t) end if.
We also need to show that

t ∈HF & wf(t)

→Is_single_valued

tree_value(t)

,
which follows readily by an induction like that sketched above.
Putting all this together, it follows that we can:

252
4
More on the Structure of the Veriﬁer System
(i) Deduce a general theorem, like that outlined above, which relates the syntax
trees of a class of formulae of interest to the semantic (set-theoretic) values of
these trees;
(ii) Supply the well-formed tree t of the formula we want;
(iii) Then Deriv(tree_value(t)) and tree_value(formal_deriv(t)) can be evaluated
automatically, and the identity
Deriv

tree_value(t)

= tree_value

formal_deriv(t)

can be made available as a theorem directly.
This allows derivative calculations like (4.8) to become theorems without fur-
ther proof, if we simply supply an appropriate syntax tree to a deduction by semi-
symbolic computation.
Since the tree t required for this little procedure is available directly from the
formula of interest (e.g. cos(cos(x))), we can even package very useful theorem-
generators of this form as Mathematica-like computational tools, i.e. introduce aux-
iliary system commands having forms like
DIFFERENTIATE : cos

cos(x)

.
This command can simply parse its input formula to obtain the tree of interest,
generate the additional boilerplate seen in (4.8), and make this available as a theo-
rem.
Simple system-extension tools for doing just this are described below.
In addition to the speciﬁc use just sketched, deduction by semi-symbolic compu-
tation is applicable in a wide variety of other circumstances. These include:
• computations with partial derivatives;
• symbolic integration and differentiation;
• manipulation of series and of combinatorial coefﬁcients;
• other Mathematica-like symbolic computations;
• elementary arguments concerning continuity and smoothness;
• elementary reasoning concerning object types;
• polynomial computations in one and several variables;
• use of trigonometric identities;
• matrix computations and linear algebra;
• some asymptotic estimates;
• some numerical computation, e.g. approximate evaluation of integrals;
• Boolean computations;
• computations with ﬁnite groups, sets of permutations, and computations in mod-
ular arithmetic.

4.4
Dividing Long Proof Veriﬁcations into Multiple Separate ‘Sessions’
253
Deduction by semi-symbolic computation is also available for Boolean equiva-
lences of the form

P(B) & s ∈HF

→

Q(s,B) ↔if C1(s) then e1(s,B)
elseif C2(s) then e2(s,B)
···
elseif Cn(s) then en(s,B)
else F(s,B) end if

and yields implications of the form

P(B) & s ∈HF

→

Q(s,B) ↔expn(s,B)

.
Deduction by semi-symbolic computation can also be given nondeterministic
and/or interactive form. To make it nondeterministic, we can supply a set of identi-
ties,

P(B) & s ∈HF

→F(s,B) = if C1j(s) then e1j(s,B)
elseif C2j(s) then e2j(s,B)
···
elseif Cnj(s) then enj(s,B)
else F(s,B) end if ,
j = 1,...,k, rather than a single such identity. In the presence of such a set SI of
initial identities and of the assumption P(B) we can supply a target identity, and
then explore the set of substitutions generated by SI nondeterministically in all pos-
sible patterns, until either the target identity is generated or all possible substitutions
have been examined.
4.4 Dividing Long Proof Veriﬁcations into Multiple Separate
‘Sessions’
Several seconds of computer time may be required to certify conclusions depen-
dent on contexts that are at all complex. For this reason, it is often appropriate to
divide the veriﬁcation of lengthy sequences of proofs into multiple successive veri-
ﬁer sessions. The following veriﬁer mechanism makes this possible.11 Two special
veriﬁer directives ‘SAVE(ﬁle_name)’ and ‘RESTART(ﬁle_name1, ﬁle_name2)’ are
provided. In both of these commands, ‘ﬁle_name’ should name some ﬁle available
in the ﬁle system of the computer on which the veriﬁer is running. When encoun-
tered, SAVE(ﬁle_name) writes all the theorems, deﬁnitions, and theories established
prior to the point at which it is encountered. These are written to the named ﬁle along
with one half H1 of a cryptographically secure checksum for the ﬁle. The other half
H2 of the checksum is retained by the veriﬁer in a hidden data structure that allows
11The feature described in this section is as yet unimplemented in the Ref system.

254
4
More on the Structure of the Veriﬁer System
H2 to be retrieved if H1 is given. The ﬁle names of any session record written in this
way can be passed to the RESTART(ﬁle_name1, ﬁle_name2) command as its ﬁrst
parameter. The second parameter ‘ﬁle_name2’ should be the name of a text ﬁle of
purported proofs of additional theorems which are to be veriﬁed. The veriﬁer then
reads all the deﬁnitions, theorem statements, and theory descriptors previously writ-
ten to ﬁle_name1, which it can accept as valid without additional veriﬁcation once
the fact that the text in the ﬁle conforms to the two available checksum halves is
veriﬁed. These deﬁnitions, theorem statements, and theories then become available
for use in the session opened by the RESTART(ﬁle_name1, ﬁle_name2) statement.
Once some or all of the new text supplied in ﬁle_name2 has been brought to the
point at which it will verify, a new ‘SAVE(ﬁle_name)’ statement can be executed
to store the newly certiﬁed deﬁnitions, theorem statements, and theory descriptors.
In this way large libraries of theorems can be accumulated through multiple veri-
ﬁer sessions. Note that proof ﬁles written by the SAVE(ﬁle_name) operation can be
copied without losing their validity, and so can be made available over the Web as
community resources.
A few supplementary commands are provided to increase the ﬂexibility of the
veriﬁer’s multisession capability. The commands
DELETE_THEOREM(theorem_label1,...,theorem_labeln)
and
DELETE_THEORY(theory_label1,...,theory_labeln)
delete comma-separated lists of labelled theorems and theories, respectively. The
command
DELETE_DEFINITION(symbol1,...,symboln)
deletes the deﬁnition of all labelled symbols, along with all theorems and further
deﬁnitions in which any symbol with a deleted deﬁnition appears. The parameter of
the command
RENAME(old_symbol1,new_symbol1;...;old_symboln,new_symboln)
must be a semicolon-separated list of symbol pairs delimited by commas. The
new_symbols which appear must be predicate and function symbols never used be-
fore. This command replaces each occurrence of every old_symbolj in every the-
orem, deﬁnition, and theory known at the point of the RENAME command by the
corresponding new_symbolj.
The RESTART command is available in the generalized form
RESTART(ﬁle_name1,..., ﬁle_namen, ﬁle_namen+1).
Here ﬁle_name1,..., ﬁle_namen must be a list of ﬁles, each written by some pre-
ceding SAVE(ﬁle_name) command, and ﬁle_namen+1 should be the name of a text
ﬁle of purported proofs of additional theorems which are to be veriﬁed. After ex-
amining the checksums of ﬁle_name1,..., ﬁle_namen to ensure their validity, the

References
255
contents of these ﬁles are scrutinized to verify that all symbols deﬁned in more than
one of these ﬁles have identical deﬁnitions in all the ﬁles in which they are deﬁned,
and that all theorems and theories with identical labels are completely identical. If
the ﬁles pass this test, their contents are combined and the new-text ﬁle ﬁle_namen+1
is then processed in the normal way.
References
[FO10]
Formisano, A., Omodeo, E.: Theory-speciﬁc automated reasoning. In: Dovier, A., Pon-
telli, E. (eds.) A 25-Year Perspective on Logic Programming—Achievements of the Ital-
ian Association for Logic Programming, GULP. LNCS, vol. 6125, pp. 37–63. Springer,
Berlin (2010). Chap. 3
[OS02]
Omodeo, E.G., Schwartz, J.T.: A ‘Theory’ mechanism for a proof-veriﬁer based on ﬁrst-
order set theory. In: Kakas, A., Sadri, F. (eds.) Computational Logic: Logic Program-
ming and beyond—Essays in honour of Bob Kowalski, Part II, vol. 2408, pp. 214–230.
Springer, Berlin (2002)
[Wol03] Wolfram, S.: The Mathematica Book, 5th edn., p. 1464. Wolfram Media, Champaign
(2003)


Chapter 5
A Closer Examination of the Sequence
of Deﬁnitions and Theorems Presented
in this Book
As recalled in the preface, before undertaking the writing of this book J. Schwartz
began to develop a large-scale proof scenario which was meant to serve as “an essen-
tial part of the feasibility study that must precede the development of any ambitious
proof-checker” [OS02, p. 229].
Ideally, this proof scenario should have culminated in the proof of the celebrated
Cauchy integral theorem on analytic functions shown at the end of this chapter;
but then we, the authors, decided to rush into the implementation of the veriﬁer
ÆtnaNova presented in Chap. 4. This absorbed much of our energies; moreover,
as soon as the proof-checker became available, we tended to explore into diverg-
ing directions (the Stone representation theorem for Boolean algebra, ﬁnite state
automata, correctness of the Davis–Putnam–Logemann–Loveland procedure, etc.).
As a consequence, our work on the foundations of analysis became slower, and we
have developed perhaps a half—take this as a rough estimate—of the proofs neces-
sary for the achievement of our initial goal.
This chapter shows the salient steps leading towards that (as yet) unachieved
goal. We expand a broad survey of main deﬁnitions and theorems. Proof-checked
proofs are available for virtually all of the theorems listed in the following Sects. 5.1
through 5.11 (albeit, occasionally, these were cast in slightly different terms), and
for many other theorems not shown here;1 but the more advanced material surveyed
in Sect. 5.12 still awaits formalized proofs.
1The largest proof scenario ever submitted to our veriﬁer is available at http://setl.dyndns.org/
EtnaNova/login/common_scenario.txt as raw text, and at http://setl.dyndns.org/EtnaNova/login/
search_folder/scenario.pdf as a pretty-printed pdf-ﬁle.
J.T. Schwartz et al., Computational Logic and Set Theory,
DOI 10.1007/978-0-85729-808-9_5, © Springer-Verlag London Limited 2011
257

258
5
A Closer Examination of the Sequence of Deﬁnitions and Theorems
5.1 Basic Operations of Set Theory and the Theory of Ordinals
5.1.1 Pairs, Set Formers, and Maps
Our ﬁrst step is to give the following deﬁnition of the notion of ordered pair. Its
details are unimportant; all that matters is that the ﬁrst and second components of
an ordered pair can be reconstructed uniquely from the pair itself. The ﬁve theorems
which follow Deﬁnition 1 ensure us that this is the case, and give explicit (but sub-
sequently irrelevant) formulae for extracting the ﬁrst and second components of an
ordered pair.
Def 1 : [Ordered pair] [x, y] =Def

{x},

{x},

{y},y

Theorem 1 : arb

{X}

= X
Theorem 1a : X ∈Y →arb

{Y,X}

= X
Theorem 2 : arb

[X, Y]

= {X}
Theorem 3 : arb

arb

[X, Y]

= X
Theorem 4 : arb

arb

arb

[X, Y] \

arb

[X, Y]

\

arb

[X,Y]

= Y
The two following deﬁnitions simply capture the two formulae which extract the
ﬁrst and second components of an ordered pair.
Def 2 : p[1] =Def arb

arb(p)

Def 3 : p[2] =Def arb

arb

arb

p \

arb(p)

\

arb(p)

All our subsequent work with ordered pairs uses only the properties stated in The-
orems 5, 6, and 7, which now follow immediately. These are the properties which
are built into our veriﬁer’s ELEM deduction mechanism.
Theorem 5 : [X,Y][1] = X
Theorem 6 : [X,Y][2] = Y
Theorem 7 : [X, Y] =

[X, Y][1], [X, Y][2]
Next we give a few small theories which make elementary properties of set for-
mers available in a convenient form. These are

5.1
Basic Operations of Set Theory and the Theory of Ordinals
259
THEORY setformer

e(x), e′(x), s, P(x), P ′(x)


∀x ∈s| e(x) = e′(x)

&

∀x ∈s| P(x) ↔P ′(x)

=⇒
e(x): x ∈s| P(x)

=

e′(x): x ∈s| P ′(x)

END setformer;
THEORY setformer0

e(x), s, P(x)

=⇒
(s ̸= ∅) →

e(x): x ∈s

̸= ∅


x ∈s| P(x)

̸= ∅

→

e(x): x ∈s| P(x)

̸= ∅

END setformer0;
THEORY setformer2

e(x), e′(x), f (x,y), f ′(x,y), s, P(x,y), P ′(x,y)

[Elementary properties of setformers]

∀x ∈s| e(x) = e′(x)

&

∀x ∈s
 
∀y ∈e(x)| f (x,y) = f ′(x,y)

&

∀x ∈s
 
∀y ∈e(x)| P(x,y) ↔P ′(x,y)

=⇒
f (x,y): x ∈s, y ∈e(x)| P(x,y)

=

f ′(x,y): x ∈s, y ∈e′(x)| P ′(x,y)

END setformer2;
The ﬁrst and third of the above theories simply allow equals-by-equals replace-
ment in set formers involving single and double iterations, respectively. The second
ensures us that set formers involving non-empty iterations must deﬁne non-empty
sets. All the required proofs involve tedious elementary detail which the availability
of these theories allows us to elide subsequently.
We go on to deﬁne the basic notions of mapping (a mapping is simply a set all
of whose elements are ordered pairs), the domain and range of a mapping, and the
notions of single-valued and one-to-one mappings. This is done by the ﬁve following
deﬁnitions.
Def 4 : Is_map(f ) ↔Def f =

x[1], x[2]
: x ∈f

Def 5 : domain(f ) =Def

x[1] : x ∈f

Def 6 : range(f ) =Def

x[2] : x ∈f

Def 7 : Svm(f ) =Def Is_map(f )&

∀x ∈f
 
∀y ∈f
 
x[1] = y[1]
→(x = y)

Def 8 : 1_1(f ) ↔Def Svm(f ) &

∀x ∈f
 
∀y ∈f
 
x[2] = y[2]
→(x = y)


260
5
A Closer Examination of the Sequence of Deﬁnitions and Theorems
5.1.2 Transﬁnite Induction
Next we state, and subsequently prove, a general principle of transﬁnite induction.
For ease of use, this is captured as a theory called ‘transﬁnite_induction’. It states
that, given any predicate P(·) which is true for some set, there must exist a set m for
which P is true, but for all whose members P is false. This principle, which follows
very directly from our strong form of the axiom of choice, is encapsulated in the
following theory.
THEORY transﬁnite_induction

n,P(x)

P(n)
=⇒(mΘ)
P(mΘ) &

∀k ∈mΘ | ¬P(k)

END transﬁnite_induction;
5.1.3 Ordinals
Our next strategic aim is to deﬁne the notion of ‘ordinal number’, and to prove the
basic properties of ordinals. We follow von Neumann in deﬁning an ordinal as a
set properly ordered by membership, and for which members of members are also
members. This ties the ordinal concept very directly to the most basic concepts of set
theory, allowing the properties of ordinals to be established by using only elemen-
tary properties of sets and set formers, with occasional use of transﬁnite induction.
The key results proved are: (a) the collection of all ordinals is itself properly ordered
by membership, and members of ordinals are ordinals, but (b) this collection is not
a set; (c) any set can be put into 1-1 correspondence with an ordinal.
The formal statement of the property ‘s in an ordinal’ is as follows.
Def 10 : Ord(s) ↔Def (∀x ∈s | x ⊆s) &

∀x ∈s
 
∀y ∈s | (x ∈y ∨y ∈x ∨x = y)

Since we have deﬁned ordinals in a directly set-theoretic way, the notion of ‘suc-
cessor ordinal’ (the next ordinal after a given ordinal) also has an elementary set-
theoretic deﬁnition: the set obtained from s by adding s itself as a (necessarily new)
member. Formally, this is as follows.
Def 11 : next(s) =Def s ∪{s}
Next we prove the basic properties of ordinals. Theorem 9, which serves as an
auxiliary lemma, states that each proper sub-ordinal T of an ordinal S is the smallest
element of the complement (S \ T ). We then prove that the intersection of any two
ordinals is an ordinal, and that, given any two ordinals, one is a subset of the other
(so that their intersection is simply the smaller of the two and their union is the

5.1
Basic Operations of Set Theory and the Theory of Ordinals
261
larger). Somewhat more precisely, given any two distinct ordinals one is a member
of the other (which tells us that comparison between ordinals can be expressed either
by inclusion or by membership). Every element of an ordinal is also an ordinal, and
if s is an ordinal then next(s) is a larger, and indeed the next larger, ordinal.
The class of sets cannot be a set (i.e. there can be no set of which all sets are
members, since if there were this would have to be a member of itself). Similarly,
there can be no ordinal of which all ordinals are members (since if there were, the
union of all elements of this set would have to be the largest ordinal, and hence
would be a member of itself). These two facts, which tell us that ‘all sets’ and ‘all
ordinals’ are both too large to be sets, are Theorems 12 and 13 in the following
group.
Theorem 8 :

Ord(S) & T ∈S

→

Ord(T ) & T ⊆S

Theorem 9 :

Ord(S) & Ord(T ) & T ⊆S

→

T = S ∨

T = arb(S \ T ) & T ∈S \ T

Theorem 10 : Ord(∅) &

Ord(S) & Ord(T )

→

(S ⊆T ∨T ⊆S) & Ord(S ∩T ) & Ord(S ∪T )

Theorem 11 :

Ord(S) & Ord(T )

→(S ∈T ∨T ∈S ∨S = T )
Theorem 12 : [The class of all sets is not a set] ¬(∀y | y ∈X))
Theorem 13 : [The class of ordinals is not a set] ¬

∀x |

x ∈Os ↔Ord(x)

Theorem 14 :

Ord(S) & Ord(T )

→(T ⊆S ↔T ∈S ∨T = S)
Theorem 15 :

Ord(S) & Ord(T )

→(T /∈S ↔S ⊆T )
Theorem 16 : Ord(S) →

Ord

next(S)

&

T ∈next(S) ↔

T ⊆S & Ord(T )

5.1.4 The Ordinal Enumerability Theorem
Next we prove that every set s can be put into one-to-one correspondence with an
ordinal. This is done by deﬁning a correspondence between ordinals and elements of
s recursively: the element corresponding to any ordinal o is the ﬁrst element, if any,
not corresponding to any smaller ordinal. Since we have already proved that the col-
lection of all ordinals is too large to be a set, this enumeration must ultimately cover
the whole of s. This is the ‘enumeration theorem’ fundamental to our subsequent
work with cardinal numbers.
The following deﬁnition formalizes the enumeration technique just described.

262
5
A Closer Examination of the Sequence of Deﬁnitions and Theorems
Def 9 : [The enumeration of a set] enum(X,S) =Def if S ⊆

enum(y,S): y ∈X

then S else arb

S \

enum(y,S): y ∈X

end if
The following six theorems do the work necessary to prove the Enumeration
theorem, which is the last of them. Theorem 17 is a lemma for Theorems 18 and
19, which state that enum(X,S) is always either a member of S, or, past a certain
point, the whole of S. Theorem 20 states that if an ordinal is large enough to enu-
merate S, so is every larger ordinal. Theorem 20 states that enum(X,S) deﬁnes a
1-1 correspondence up to the point at which the whole of S has been enumerated,
and Theorem 21 states that the whole of S must eventually be enumerated (since
otherwise we would have a 1-1 correspondence of all ordinals with a subset of S,
contradicting the fact that there are too many ordinals to constitute a set).
Theorem 17 :

Ord(X) & S ∈

enum(y,S): y ∈X

→

S ⊆

enum(y,S): y ∈X

Theorem 18 : enum(X,S) = S ∨enum(X,S) ∈S
Theorem 19 :

enum(X,S) = S & Y ⊇X

→

enum(Y,S) = S

Theorem 20 : [The enumeration of a set is 1-1]

Ord(X) & Ord(W) & X ̸= W

→

S ∈

enum(y,S): y ∈X

∨S ∈

enum(y,S): y ∈W

∨
enum(X,S) ̸= enum(W,S)

Theorem 21 : [Enumeration lemma]

∃x | Ord(x) & S ∈

enum(y,S): y ∈x

Theorem 22 : [Enumeration theorem]

∃x | Ord(x) & S =

enum(y,S): y ∈x

&

∀y ∈x
 
∀z ∈x | (y ̸= z) →

enum(y,S) ̸= enum(z,S)

5.2 Elementary Laws on Map Constructs
Our next goal is to deﬁne the notion of the cardinality of a set s, i.e. the number,
ﬁnite or inﬁnite, of its elements. As appears in deﬁnition 15 below, this is simply
the smallest ordinal which can be put into 1-1 correspondence with s. But in prepa-
ration for this deﬁnition we ﬁrst deﬁne a few more elementary set-theoretic notions
and prove a few more elementary properties of maps. The notions deﬁned are: the
restriction of a map to a set, the inverse map of a map, the identity map on a set, and
map composition. The image of a point x under a map2 is deﬁned as the unique el-
ement (or, if not unique, the element chosen by ‘arb’) of the range of the restriction
2To distinguish the image resulting from application of a map f to an element x from the image
of the same x under a global function g, we will denote the former as f [x] and the latter as g(x).

5.2
Elementary Laws on Map Constructs
263
of the map to the singleton {x}. The following block of deﬁnitions formalize these
ideas.
Def 12 : [Map restriction] f|a =Def

p ∈f | p[1] ∈a

Def 13 : [Value of single-valued function] f [x] =Def arb(f|{x})[2]
Def 14 : [Map product] f ◦g =Def

x[1], y[2]
: x ∈g, y ∈f | x[2] = y[1] 
Def 14a : [Inverse map] f −1 =Def

x[2], x[1]
: x ∈f

Def 14b : [Identity map] ids =Def

[x, x]: x ∈s

Def 14c : [Inverse image] f ↰{s} =Def range

f −1|s

A collection of elementary theorems expressing familiar set-theoretic facts is
proved next: the restriction of a map to a set is a submap of the original map; a
set is a map if and only if all its elements are ordered pairs; a subset of a map is a
map. A subset of a single-valued map is a map. A subset of a one-to-one map is a
one-to-one map. Theorems 24 and 25 just express the intersection and difference of
two sets as set formers.
Theorem 23 : F|A ⊆F
Theorem 24 : S ∩T = {x ∈S | x ∈T }
Theorem 25 : S \ T = {x ∈S | x /∈T }
Theorem 26 : Is_map(F) ↔

∀x ∈f | x =

x[1], x[2]
Theorem 27 :

G ⊆F & Is_map(F)

→Is_map(G)
Theorem 28 :

G ⊆F & Svm(F)

→Svm(G)
Theorem 29 :

G ⊆F & 1_1(F)

→1_1(G)
Continuing this series of elementary set-theoretic propositions, we have the fol-
lowing results: The ﬁrst and second components of any element of a map belong
to the map’s domain and range, respectively. The union of two maps is a map. The
restriction of a map to a union set is the union of the separate restrictions. The re-
striction of the union of two maps to a set is the union of their separate restrictions.
A map is its restriction to its own domain. Map products are associative.
Theorem 30 : (X ∈F) →

X[1] ∈domain(F)


264
5
A Closer Examination of the Sequence of Deﬁnitions and Theorems
Theorem 31 : (X ∈F) →

X[2] ∈range(F)

Theorem 33 :

Is_map(F) & Is_map(G)

→Is_map(F ∪G)
Theorem 34 : F|(A∪B) = (F|A) ∪(F|B)
Theorem 35 : [Associativity of map multiplication] F ◦(G ◦H) = (F ◦G) ◦H
Theorem 36 : (F ∪G)|A = (F|A) ∪(G|A)
Theorem 37 : F|domain(F) = F
Three additional theorems in this elementary group state that (i) the image under
a map of any element of its domain belongs to its range; (ii) A single-valued map can
be written as the set of all pairs built from images of its domain elements; (iii) The
range of a single-valued map is the collection of all image elements of its domain.
Theorem 38 :

X ∈domain(F)

→

F[X] ∈range(F)

Theorem 39 : Svm(F) ↔F =

x, F[x]

: x ∈domain(F)

Theorem 39a : Svm(F) →

F =

x, F[x]

: x ∈domain(F)

&
range(F) =

F[x]: x ∈domain(F)

It is convenient to repackage the elementary results just stated as a theory which
puts every one-parameter function symbol f onto correspondence with a single-
valued map g which sends each element x of the map’s domain into g(x) as image
element. The theory shown below does this, and also expresses the range of g and
the condition that g should be one-to-one in terms of f .
THEORY fcn_symbol

f (x), g, s

g =

x, f (x)

: x ∈s

=⇒
domain(g) = s

∀x ∈s| g[x] = f (x)

(X /∈s) →

g[X] = ∅

range(g) =

f (x): x ∈s

Svm(g)

∀x ∈s
 
∀y ∈s
 
f (x) = f (y)

→(x = y )

→1_1(g)
END fcn_symbol;
In working with maps we often need to use elementary properties of ordered
pairs. The following theorems are two such: Any ordered pair can be written in

5.2
Elementary Laws on Map Constructs
265
standard fashion in terms of its formal ﬁrst and second component. Any element of
a map is an ordered pair. The small utility theory which follows states that every set
former involving only ordered pairs deﬁnes a map.
Theorem 40 :

U = [A, B]

→

U =

U [1], U[2]
Theorem 41 :

Is_map(F) & U ∈F

→

U =

U [1], U[2]
THEORY Iz_map

a(x), b(x), s

=⇒
Is_map

a(x), b(x)

: x ∈s

&
domain

a(x), b(x)

: x ∈s

=

a(x): x ∈s

&
range

a(x), b(x)

: x ∈s

=

b(x): x ∈s

END Iz_map
More elementary utility results on maps and their ranges and domains now fol-
low. The domain and range operators are both additive, and if one is null so is the
other. A single-valued map sends the ﬁrst component of any pair in it to the sec-
ond component of the same pair. The union of two single-valued maps with disjoint
domains is a single-valued map. The union of two one-to-one maps with disjoint
domains and ranges is a one-to-one map. Any restriction of a map is a map; any
restriction of a single-valued map is a single-valued map; any restriction of a one-
to-one map is a one-to-one map. The range of any restriction of a map is a subset of
the map’s range, and the domain of a map’s restriction to a set s is the intersection
of s and the map’s domain. If the range of a map g is included in the domain of a
map f , the domain of the composite map f ◦g is the domain of g, and its range is
the range of the restriction of f to the range of g. Hence if the range of g equals the
domain of f , the range of the composite map equals the range of f .
Theorem 42 : domain(F ∪G) = domain(F) ∪domain(G)
Theorem 43 : range(F ∪G) = range(F) ∪range(G)
Theorem 44 : domain(F) = ∅↔range(F) = ∅
Theorem 45 :

Svm(F) & x ∈F

→

F

X[1]
= X[2]
Theorem 46 : [Union of single-valued maps]

Svm(F) & Svm(G) &
domain(F) ∩domain(G) = ∅

→Svm(F ∪G)
Theorem 47 : Is_map(F) →Is_map(F|S)

266
5
A Closer Examination of the Sequence of Deﬁnitions and Theorems
Theorem 48 : Svm(F) →Svm(F|S)
Theorem 49 : 1_1(F) →1_1(F|S)
Theorem 50 : range(F|S) ⊆range(F)
Theorem 50a : domain(F|S) = domain(F) ∩S
Theorem 51 :

range(G) ⊆domain(F)

→

range(F ◦G) = range(F|range(G)) & domain(F ◦G) = domain(G)

Theorem 51a :

range(G) = domain(F)

→

range(F ◦G) = range(F) & domain(F ◦G) = domain(G)

Theorem 52 : [Union of 1-1 maps] (1_1(F) & 1_1(G) &
range(F) ∩range(G) = ∅& domain(F) ∩domain(G) = ∅) →1_1(F ∪G)
Next we have a block of elementary results on map inverses. The inverse of a
map f is a map, whose domain is the range of f and vice versa. The inverse of
the inverse of a map is the map itself. If a map is one-to-one, so is its inverse. The
inverse of a one-to-one map f sends the image under f of each element x of the
domain of f into x, and vice versa. The composite of a map and its inverse sends
every element x of the map’s domain into x, and symmetrically the composite of
the inverse of f and f sends each element y of the range of f into y.
Theorem 53 : Is_map

F −1
& range

F −1
= domain(F) &
domain

F −1
= range(F)
Theorem 54 : Is_map(F) →

F =

F −1−1
Theorem 55 : 1_1(F) →

1_1

F −1
& F =

F −1−1 &
range

F −1
= domain(F) & domain

F −1
= range(F)

Theorem 56 : 1_1(F) →

∀x ∈domain(F)| F −1
F[x]

= x

Theorem 57 : 1_1(F) →

∀x ∈range(F)| F

F −1[x]

= x

Next we give a few elementary results on identity maps, i.e. maps which send
every element of some set s into itself. Every such map is one-to-one, inverse to
itself, and has s as its range and domain. The composite of any single-valued map
f with its inverse is the identity map on the range of f , and, if f is one-to-one, the
composite in the reverse order is the identity map on the domain of f .

5.2
Elementary Laws on Map Constructs
267
Theorem 58 : [Elementary Properties of identity maps] 1_1(idS) &
domain(idS) = S & range(idS) = S &
(idS)−1 = idS &

∀x ∈S | idS[x] = x

&

Is_map(F) →

domain(F) ⊆S

→(F ◦idS = F)

&

range(F) ⊆S

→(idS ◦F = F)

Theorem 59 : Svm(F) →

F ◦F −1 = idrange(F)

Theorem 60 : 1_1(F) →

F ◦F −1 = idrange(F) & F −1 ◦F = iddomain(F)

The ﬁnal theorems in our collection of elementary results focus on composite
maps. If two maps are one-to-one and inverse to each other, their composite is the
identity map on the domain of one of them, and the composite in the opposite order
is the identity map on the corresponding range. The composite of two maps is a map,
the composite of two single-valued maps is a single-valued map, and the composite
of two one-to-one maps is a one-to-one map. If f and g are two single-valued maps
with the range of g included in the domain of f , then their composite sends each x
in the domain of f into the g-image of the f -image of x, and both the composite
map and its range can be written as set former expressions. Map composition is
distributive over map union.
Theorem 61 : [An inverse pair of maps must be 1-1 and must be each others inverses]

Is_map(F) & Is_map(G) &
domain(F) = range(G) &
range(F) = domain(G) &
F ◦G = idrange(F) &
G ◦F = iddomain(F)

→

1_1(F) & G = F −1
Theorem 62 : Is_map(F ◦G)
Theorem 63 :

Svm(F) & Svm(G)

→Svm(F ◦G)
Theorem 64 :

Svm(F) & Svm(G) & x ∈domain(G) &
range(G) ⊆domain(F)

→

(F ◦G)[X] = F

G[X]

Theorem : [Map product formula]

Svm(F) & Svm(G) &
range(G) ⊆domain(F)

→

F ◦G =

x, F

G[x]

: x ∈domain(G)

&

X ∈domain(G) →(F ◦G)[X] = F

G[X]

&
domain(F ◦G) = domain(G) &
range(F ◦G) =

F

G[x]

: x ∈domain(G)

&
range(F ◦G) ⊆range(F)

Theorem 65 :

1_1(F) & 1_1(G)

→1_1(F ◦G)

268
5
A Closer Examination of the Sequence of Deﬁnitions and Theorems
Theorem 66 : (F ∪H) ◦G = (F ◦G) ∪(H ◦G)
Theorem 67 : G ◦(F ∪H) = (G ◦F) ∪(G ◦H)
5.3 Cardinality of a Set; Cardinal Numbers
Now we are ready to go on to the theory of cardinal numbers, in preparation for
which we Skolemize the theorem which states that any set has a standard enumer-
ation, to get the following deﬁnition, which gives a name to the ordinal which enu-
merates each set in the standard way.
Def_by_app 14d :
Ord

enum_Ord(S)

& S =

enum(y,S): y ∈enum_Ord(S)

&

∀y ∈enum_Ord(S)
 
∀z ∈enum_Ord(S)|
(y ̸= z) →

enum(y,S) ̸= enum(z,S)

We can now deﬁne the cardinal number of a set s to be the least ordinal with
which it can be put into one-to-one correspondence. Accordingly an ordinal is a
cardinal if it can not be put into one-to-one correspondence with any smaller ordinal.
The two following deﬁnitions capture these ideas.
Def 15 : [Cardinality] #s =Def arb


x : x ∈next

enum_Ord(s)


∃f
 
1_1(f ) & domain(f ) = x & range(f ) = s

Def 16 : [Cardinal] Is_cardinal(s) ↔Def Ord(s) &

∀y ∈s
 
∀f | ¬

domain(f ) = y

∨¬

range(f ) = s

∨¬

Svm(f )

In working with cardinals (and in particular with products of cardinals) we will
need various elementary facts about Cartesian products. The Cartesian product of
two sets s and t is simply the set of all pairs whose ﬁrst component belongs to s and
whose second component belongs to t. Formally this is
Def 17 : [Cartesian Product] s×t =Def

[x, y]: x ∈s, y ∈t

The two following theorems state associativity and commutativity properties of
the Cartesian product: (A×B)×C and A×(B×C) are always in natural one-to-one
correspondence, as are (A×B) and (B×A). These facts will subsequently imply the
associativity and commutativity of cardinal multiplication.
Theorem 68 :

F =

[x, y], z

,

x, [y, z]

: x ∈A, y ∈B, z ∈C

→

1_1(F) & domain(F) =

(A×B)×C

& range(F) =

A×(B×C)


5.3
Cardinality of a Set; Cardinal Numbers
269
Theorem 69 :

F =

[x, y], [y, x]

: x ∈A, y ∈B

→

1_1(F) & domain(F) = (A×B) & range(F) = (B×A)

Now we go on to the study of cardinals, beginning with a few relevant facts about
ordinals, stated in the next block of theorems. Theorem 70 states that the standard
enumeration function enum(x,s) = enum_s(x) deﬁned earlier is the identity (in
x) if s is an ordinal. Theorem 71 states that every set can be put into one-to-one
correspondence with a certain smallest ordinal. Then we show that the enumerating
ordinal of a set has the same cardinality as the set, and that if a set s of ordinals
includes a set t, then arb(s) is smaller than arb(t). These are both lemmas needed
later. Theorem 74 states a related lemma, needed later to prove that the cardinal
number of a set s is at least as large as the cardinal number of any of its subsets.
Theorem 70 :

Ord(S) & X ∈S

→

enum(X,S) = X

Theorem 71 : [Cardinality Lemma] Ord(#S) &

∃f | 1_1(f ) & range(f ) = S & domain(f ) = #S

&

¬

∃o ∈#S
 
∃g | 1_1(g) & range(g) = S & domain(g) = o

Theorem 72 : [The enumerating ordinal of a set has the same cardinality as the set]

∃o
 
Ord(o) & S =

enum(x,S): x ∈o

& #o = #S

Theorem 73 : [‘arb’ is monotone decreasing for non-empty sets of ordinals]

Ord(R) & R ⊇S & S ⊇T

→

arb(S) ∈arb(T ) ∨arb(S) = arb(T ) ∨T = ∅

Theorem 74 : [Lemma for following theorem]

Ord(S)&T ⊆S &X ∈S &Y ∈X

→

enum(Y,T ) ∈enum(X,T ) ∨enum(X,T ) ⊇T

Theorem 75 : [Subsets enumerate at least as rapidly]

Ord(S)&T ⊆S &X ∈S

→

enum(X,T ) ⊇X

Theorem 76 :

Ord(S) & T ⊆S

→

enum(x,T ): x ∈S

⊇T

Theorem 77 :

Ord(S) & T ⊆S

→

∃x ⊆S
 
Ord(x) & T =

enum(y,T ): y ∈x

&

∀y ∈x
 
∀z ∈x | (y ̸= z) →

enum(y,T ) ̸= enum(z,T )

The block of theorems which now follow encapsulate a few basic properties of
the #s operator, e.g. its monotonicity.
Theorem 78 : [Single-valued maps have 1-1 partial inverses] Svm(F) →

∃h
 
domain(h) = range(F) & range(h) ⊆domain(F) &
1_1(h) &

∀x ∈range(F)| F

h[x]

= x

Theorem 79 : [One-one maps are cardinality preserving]
1_1(F) →

#range(F) = #domain(F)


270
5
A Closer Examination of the Sequence of Deﬁnitions and Theorems
Theorem 80 : [Cardinality theorem] Is_cardinal(#S) & Ord(#S)

∃f
 
1_1(f ) & range(f ) = S & domain(f ) = #S

Theorem 81 : #S = ∅↔S = ∅
Theorem 82 : [Uniqueness of Cardinality]

Is_cardinal(C) &

∃f
 
1_1(f ) & range(f ) = S & domain(f ) = C

→(C = #S)
Theorem83: [Subsets of an ordinal have a cardinality that is no larger than the ordinal]

Ord(S) & T ⊆S

→(#T ⊆S)
Theorem 84 : [Subset cardinality theorem] (T ⊆S) →(#T ⊆#S)
Theorem 85 : [Single-valued mapping cannot increase cardinality]
Svm(F) →

#range(F) ⊆#domain(F)

5.3.1 Finiteness
All the preceding results are as true for inﬁnite sets, ordinals, and cardinals as for
ﬁnite objects. We now go on to introduce the important notion of ﬁniteness and to
prove its basic properties. The deﬁnition is as follows: a set s is ﬁnite if it cannot be
mapped into any proper subset of itself by a one-to-one mapping.3
Def 18 : [Finiteness] Finite(s) ↔Def
¬

∃f | 1_1(f ) & domain(f ) = s & range(f ) ⊆s & s ̸= range(f )

An equivalent property is that s should not be the single-valued image of any
proper subset of itself. To begin work with the basic notion of ﬁniteness, we prove
that the null set is ﬁnite, that any subset of a ﬁnite set is ﬁnite, and that a set is
ﬁnite if and only if its cardinality (with which it is in one-to-one correspondence)
is ﬁnite. It is also proved (Theorems 102, 103, and 104) that two sets in one-to-one
correspondence are both ﬁnite if either is, and that the image of a ﬁnite set under a
single-valued map is always ﬁnite.
Along the way we prove a utility collection of results on the ﬁniteness and car-
dinality of maps, and of their ranges and domains. These are as follows. Both the
range and domain of a mapping have a cardinality no larger than that of the map
3Following Tarski [Tar24] we could have adopted the following alternative deﬁnition of ﬁnite sets,
equivalent for any practical purpose to the deﬁnition given here:
Finite(f ) ↔Def

∀g ∈P

P(f )

\ {∅}
 
∃m| g ∩P(m) = {m}

,
i.e., f is ﬁnite if and only if every non-null set g constituted by subsets of f owns an inclusion-
minimal element m. This will be shown in Sect. 7.5.

5.3
Cardinality of a Set; Cardinal Numbers
271
itself. If a map is single-valued, it has the same cardinality as its domain. If t is a
non-null subset of s, then there exists a single-valued mapping whose domain is s
and whose range is t; this map can be one-to-one if and only if s and t have the same
cardinality. A set s is a cardinal if and only if it is its own cardinality, i.e. s = #s. The
cardinality operator ‘#’ is idempotent, and the membership operation for cardinals
has the trichotomy and transitivity properties of a comparison operator.
We also prove the basic lemmas (Theorems 96 and 97) that we will use to show
that cardinal multiplication is associative and commutative once this multiplication
operation has been deﬁned, and the lemma (Theorem 100) needed to show that the
power operation 2C is well-deﬁned for cardinal numbers C.
Theorem 86 : [∅is a ﬁnite cardinal] Ord(∅) & Finite(∅) & Is_cardinal(∅)
Theorem 87 : #domain(F) ⊆#F
Theorem 88 : #range(F) ⊆#F
Theorem 89 : Svm(F) →

#domain(F) = #F

Theorem 90 : [Condition for existence of a single-valued map between two sets]
#S ⊇#T ↔

T = ∅∨

∃f
 
Svm(f ) & domain(f ) = S & range(f ) = T

Theorem 91 : #S = #T ↔

∃f
 
1_1(f ) & domain(f ) = S & range(f ) = T

Theorem 92 : Is_cardinal(S) ↔S = #S
Theorem 93 : #S = ##S
Theorem 94 : [All cardinals are comparable] #S ∈#T ∨#S = #T ∨#T ∈#S
Theorem 95 : [Cardinal comparison is transitive]
(#S ∈#T & #T ∈#R) →(#S ∈#R)
Theorem 96 : [Associative law for cardinals] #

(A×B)×C

= #

A×(B×C)

Theorem 97 : [Commutative law for cardinals] #(A×B) = #(B×A)
Theorem 98 : [A subset of a ﬁnite set is ﬁnite]

Finite(S) & S ⊇T

→Finite(T )
Theorem 100 : [A 1-1 map on a set induces a 1-1 map on the power set of its domain]

1_1(F) & S ⊆domain(F) & T ⊆domain(F) & S ̸= T

→

range(F|S) ̸= range(F|T )


272
5
A Closer Examination of the Sequence of Deﬁnitions and Theorems
Theorem 103 : [One-one maps preserve ﬁniteness]
1_1(F) →

Finite

domain(F)

↔Finite

range(F)

Theorem 104 : [A single-valued map with ﬁnite domain has a ﬁnite range]

Svm(F) & Finite

domain(F)

→Finite

range(F)

Theorem 105 : Finite(S) ↔Finite(#S)
Our next block of theorems works further into the properties of ﬁnite sets. We
show that any proper subset of a ﬁnite set s has a smaller cardinality than s (this
condition is equivalent to ﬁniteness), that any member of a ﬁnite ordinal is ﬁnite
(so that any inﬁnite ordinal is larger than any ﬁnite ordinal), that the addition of a
singleton to a ﬁnite set gives a ﬁnite set. This implies that any singleton is ﬁnite, and
that the successor set next(s) of a ﬁnite set is always ﬁnite. We prove the equivalence
of a second possible deﬁnition of ﬁniteness: s is ﬁnite if and only if it cannot be the
single-valued image of any of its proper subsets.
Theorem 110 is a simple utility lemma asserting that any two elements of a set
can be interchanged by a one-to-one mapping of the set into itself. Theorem 111
collects various elementary properties of single-valued maps, their domains, and
their restrictions.
Theorem 106 : [Proper subsets of a ﬁnite set have fewer elements]

Finite(S) & T ⊆S & T ̸= S

→(#T ∈#S)
Theorem 107 : Finite(S) ↔¬

∃f
 
Svm(f ) & range(f ) = S
& domain(f ) ⊆S & S ̸= domain(f )

Theorem 108 :

Ord(S) & Finite(S) & T ∈S

→Finite(T )
Theorem 109 : [Any inﬁnite ordinal is larger than any ﬁnite ordinal]

Ord(S) & Ord(T ) &

¬Finite(S)

& Finite(T )

→(T ∈S)
Theorem 110 : [Interchange Lemma] (X ∈S & Y ∈S) →

∃f |

1_1(f ) &
range(f ) = S & domain(f ) = S & f [X] = Y & f [Y] = X

Theorem 111 : Svm(F) →

F|S =

x, F[x]

: x ∈domain(f )| x ∈S &
domain(F|S)

=

x ∈domain(F)| x ∈S

&
range(F|S) =

F[x]: x ∈domain(f )| x ∈S

Theorem 113 : Finite(S) ↔Finite

S ∪{X}

Theorem 114 : Finite(S) →Finite

next(S)


5.4
The Set of All Integers, Basic Arithmetic of Integers and Cardinals
273
5.4 The Set of All Integers, Basic Arithmetic of Integers and
Cardinals
Our next main goal is to prove that the collection of all ﬁnite ordinals is a set (this
set, which is also the set of all ﬁnite cardinals, is of course the set of integers, and
hence the foundation stone of all traditional mathematics). This is done by using
the inﬁnite set s∞whose existence is assumed in the axiom of inﬁnity to prove that
there exists an inﬁnite ordinal. The set N of integers can then be deﬁned as the least
inﬁnite ordinal, which we show is also a cardinal. We also show that a cardinal is
ﬁnite if and only if it is a member of N, and deﬁne the standard integers 1,2,3, etc.
as next(∅), next(1), next(2), etc., and prove that these are all distinct.
Theorem 115 : ¬Finite(s∞)
Theorem 116 : [Inﬁnite cardinality theorem] ¬Finite(#s∞)
Theorem 117 : [All ﬁnite ordinals are cardinals]

Ord(X) & Finite(X)

→Is_cardinal(X)
Def 18a : [The set of integers] N =Def arb

x ∈next(#s∞)| ¬Finite(x)

Theorem118: [The set of integers is an inﬁnite ordinal consisting of all ﬁnite ordinals]
Ord(N) &

¬Finite(N)

&

Is_cardinal(X) & Finite(X)

↔X ∈N

Def 18b : [Standard deﬁnitions of the ﬁnite integers]
1 = next(∅) & 2 = next(1) & 3 = next(2) & ···
Theorem 119 : Ord(∅) & ∅∈N & 1 ∈N & 2 ∈N & 3 ∈N
Theorem 120 : [The set of integers is a cardinal] Is_cardinal(N)
Theorem 121 : {∅,1,2,3} ⊆N &
1 ̸= ∅& 2 ̸= ∅& 3 ̸= ∅& 1 ̸= 2 & 1 ̸= 3 & 2 ̸= 3
Our next block of theorems continues to develop the basic principles of arith-
metic, and hence brings us into standard mathematics. The notions of addition, mul-
tiplication, (unsigned) subtraction, division, and remainder after division are ﬁrst
deﬁned using simple set-theoretic constructions. (The sum of two cardinals n and
m is the cardinality of the union of any two disjoint sets in 1-1 correspondence with
n and m, respectively; the product of n and m is the cardinality of the Cartesian
product of the sets m and n; their difference is the cardinality of the difference set
m \ n.) The quotient of m over n is the largest k whose product with n is included in
m, and the remainder is m −((m/n) ∗n) as usual. All this is formalized in the six
following deﬁnitions, which also include the deﬁnition of the notion of powerset.

274
5
A Closer Examination of the Sequence of Deﬁnitions and Theorems
Def 19 : [Cardinal sum] n + m =Def #

[x, ∅]: x ∈n

∪

[x, 1]: x ∈m

Def 20 : [Cardinal product] N ∗M =Def #(N×M)
Def 21 : P(s) =Def {x : x ⊆s }
Def 22 : [Cardinal difference] N −M =Def #(N \ M)
Def 23 : [Integer quotient] M/N =Def
	{k ∈N| k ∗N ⊆M }
[Note that x/∅= N for x ∈N]
Def 24 : [Integer Remainder] M mod N =Def M −

(M/N) ∗N

Next a few necessary lemmas are proved. The sets which appear in the deﬁnition
of cardinal summation are disjoint and have the same cardinality as the sets from
which they are formed; the null set is a one-to-one map with null range and domain;
and a single ordered pair deﬁnes a one-to-one map. We also prove a simple utility
formula for maps constructed out of just two ordered pairs.
Theorem 122 :

[x, ∅]: x ∈N

∩

[x, 1]: x ∈M

= ∅
Theorem 123 : Is_map(∅) & Svm(∅) &
1_1(∅) & range(∅) = ∅& domain(∅) = ∅
Theorem 124 : Svm

[X, Y]

& 1_1

[X, Y]

&

[X, Y]

[X] = Y
Theorem 125 : (X ̸= Z) →

[X, Y], [Z, W]

[X] = Y

Theorem 126 : #

[x, ∅]: x ∈M

= #M & #

[x, 1]: x ∈N

= #N
In preparation for a closer examination of the rules of cardinal arithmetic, we
prove next that the cardinal sum and product of two sets can be calculated either
from the sets or from their cardinal numbers. We so show that any proper subset of
a ﬁnite set has a smaller cardinal number.
Theorem 127 : N + M = #N + #M
Theorem 128 : N + M = N + #M
Theorem 129 : N ∗M = #N ∗#M
Theorem 130 : N ∗M = N ∗#M
Theorem 131 :

Finite(N) & M ⊆N & M ̸= N

→(#M ∈#N)

5.4
The Set of All Integers, Basic Arithmetic of Integers and Cardinals
275
Since the following discussion will occasionally use inductive arguments which
refer to the subsets of a ﬁnite set, it is convenient to make these available in a theory.
This states that, given any predicate P(x) which is true for some ﬁnite set, there ex-
ists a ﬁnite set s for which P(s) is true, but P(s′) is false for all proper subsets of s.
THEORY ﬁnite_induction

n, P(x)

Finite(n) & P(n)
=⇒(mΘ)
mΘ ⊆n & P(mΘ) &

∀k ⊆mΘ | (k ̸= mΘ ) →

¬P(k)

END ﬁnite_induction
Now we are ready to prove the main elementary properties of integer arithmetic.
We show that the union of two ﬁnite sets is ﬁnite, and that a cardinal sum of two sets
is ﬁnite if and only if the union of the two sets (i.e. both of the two sets) is ﬁnite. The
statements ‘zero times any n equals zero’, and ‘one times any n equals n’ are proved
in several convenient equivalent forms. We show that n ∩m is at least as large as m
if n is not zero, and show how to express the cardinal sum as the cardinality of two
distinct Cartesian product sets, whose disjointness is then demonstrated. Then the
distributive and commutative laws for cardinal (and hence integer) arithmetic are
established by relating them to corresponding set-theoretic constructions. Finally
we show that the Cartesian product of two ﬁnite sets is ﬁnite, and that the converse
holds as long as neither of the sets is empty.
Theorem 132 :

Finite(N) & Finite(M)

↔Finite(N ∪M)
Theorem 133 : Finite(N + M) ↔Finite(N ∪M)
Theorem 134 :

Finite(N) & Finite(M)

↔Finite(N + M)
Theorem 135 : N×∅= ∅& ∅×N = ∅
Theorem 136 : N ∗∅= ∅
Theorem 137 : ∅∗N = ∅
Theorem 138 : #N + ∅= #N
Theorem 139 : #

{C}×N

= #N
Theorem 140 : #

N×{C}

= #N
Theorem 141 : 1 ∗N = #N

276
5
A Closer Examination of the Sequence of Deﬁnitions and Theorems
Theorem 142 : N ∗1 = #N
Theorem 143 : (M ̸= ∅) →

#(N×M) ⊇#N

Theorem 144 : N + M = #

N×{∅}

∪

M×{1}

Theorem 145 : (A ∩B = ∅) →

(X×A) ∩(Y×B) = ∅

Theorem 146 : N + M = M + N
Theorem 147 : N ∗M = M ∗N
Theorem 148 :

(A×X) ∩(B×X)

= (A ∩B)×X &

(A×X) ∪(B×X)

= (A ∪B)×X &

(X×A) ∩(X×B)

= X×(A ∩B) &

(X×A) ∪(X×B)

= X×(A ∪B)
Theorem 149 : N + (M + K) = (N + M) + K
Theorem 150 : N ∗(M ∗K) = (N ∗M) ∗K
Theorem 151 : N ∗(M + K) = (N ∗M) + (N ∗K)
Theorem 152 :

Finite(N) & Finite(M)

→Finite(N ∗M)
Theorem 153 :

Finite(N) & Finite(M)

∨(N = ∅∨M = ∅)

↔
Finite(N ∗M)
Next a few well-known results concerning power sets and their cardinalities are
proved. The power set of the null set is the singleton {∅}. The power set of a set s is
ﬁnite if and only if s is ﬁnite, but (Cantor’s theorem, the historical root of the whole
theory of inﬁnite cardinals) always has a larger cardinality than s.
Theorem 154 : P(∅) = {∅}
Theorem 155 : Finite(N) ↔Finite

P(N)

Theorem 156 : [Cantor’s Theorem] #N ∈#P(N)
Next we prove some properties of cardinal subtraction, along with some auxiliary
properties of the cardinal sum: n −n is always ∅, n −∅is n, (n −m) + m and
m+(n−m) are both n if m is no larger than n. The cardinality of the union set s ∪t
is the cardinal sum of s and t if the two sets are disjoint, and this value depends only
on the cardinalities of the sets involved.

5.4
The Set of All Integers, Basic Arithmetic of Integers and Cardinals
277
Theorem 157 : N −N = ∅
Theorem 158 : N −∅= #N
Theorem 159 : [Disjoint sum Lemma] (N ∩M = ∅) →

N + M = #(N ∪M)

Theorem 160 : (N ∩M = ∅& N′ ∩M′ = ∅& #N = #N′ & #M = #M′) →

#(N + M) = #(N′ + M′)

Theorem 161 : [Subtraction lemma] (M ⊆N) →

#N = #M + (N −M)

Theorem 162 : [Subtraction lemma] (#M ∈#N ∨#M = #N) →

#N = #M + (#N −#M)

Because of the set-theoretic way in which we have deﬁned ordinals, the maxi-
mum of a set s of ordinals is simply the union of all the ordinals. This fact is captured
in our next block of theorems, which begins with the very simple deﬁnition of the
concept ‘union set’.
Def 25 : [Union set] 	S =Def {x : x ∈y, y ∈S }
Our next two theorems capture the fact stated just above: the union of a set s of
ordinals is always an ordinal, and is the least upper bound of s.
Theorem 163 : [Union set as an upper bound]

∀x ∈S | x ⊆	S

&

(∀x ∈S | x ⊆T ) →
	S ⊆T

Theorem 164 : [The union of a set of ordinals is an ordinal]

∀x ∈S | Ord(x)

→Ord
	S

Now we prove two basic elementary properties of division: n/m is no larger than
n unless m is ∅, and is an integer if n and m are both integers. We also show that the
sum, product, and difference of integers is an integer.
Theorem 165 : (M ̸= ∅) →(N/M ⊆N)
Theorem 166 : (M ̸= ∅& N ∈N) →(N/M ∈N & N/M ⊆N)
Theorem 167 : (N ∈N & M ∈N) →
(N + M ∈N & N ∗M ∈N & N −M ∈N)
Next several results on the monotonicity of addition, multiplication, and subtrac-
tion are given. Once we have extended the notion of ‘integer’ to that of ‘signed
integer’ these will become the standard monotonicity properties for algebraic com-
binations of signed integers, and ultimately of rational numbers and of reals. We

278
5
A Closer Examination of the Sequence of Deﬁnitions and Theorems
show that: integer addition is strictly monotone in both of its arguments (several
variants of this result are given); integer multiplication is monotone in both of its
arguments (but not strictly, unless ∅is excluded as a factor). We also prove that
subtraction is strictly monotone in its arguments, and establish the cancellation rule
for unsigned addition needed later to justify the deﬁnition of signed addition and its
relationship to signed subtraction.
Theorem 169 : [Strict monotonicity of addition] (M ∈N & N ∈N & N ̸= ∅) →
(M ∈M + N)
Theorem 170 : [Strict monotonicity of addition] (M ∈N & N ∈N & K ∈N) →
(M + K ∈M + N)
Theorem 171 : [Cancellation] (M ∈N & N ∈N & K ∈N & M + K = N + K)
→(M = N)
Theorem 172 : [Monotonicity of addition] (M ⊆N) →(M + K ⊆N + K)
Theorem 173 : [Monotonicity of multiplication] (M ⊆N) →(M ∗K ⊆N ∗K)
Theorem 174 : [Monotonicity of addition] (M ∈N & N ∈N & K ∈N) →
(M + K ⊆N + K ↔M ⊆N)
Theorem 175 : [Strict monotonicity of subtraction] (N ∈N & K ∈N & M ⊇N)
→(M −N ∈M −K)
Our next, rather miscellaneous block of theorems show that subtraction stands in
the correct relationship to addition, and prove some related facts on the monotonic-
ity of addition. We also show that the cardinality of any singleton is 1, that only
the empty set has cardinality zero, and that if a cardinal product is zero one of its
two factors must be zero. This last statement is subsequently used in constructing
rational numbers.
Theorem 176 : (M ∈N & N ∈N & K ∈N & N ⊇M & N −M ⊇K) →

N ⊇M + K & N −(M + K) = (N −M) −K

Theorem 177 : (M ∈N & N ∈N) →

(M + N) −N = M

Theorem 178 : [Integer division with remainder] (M ∈N & N ∈N & N ̸= ∅) →

M/N ∈N & M ⊇

(M/N) ∗N

& M mod N ∈N

Theorem 179 : #{S} = {∅}
Theorem 180 : (#N = ∅) →(N = ∅)

5.5
The Cardinal Product Theorem
279
Theorem 181 : #N ∗#M = ∅↔(N = ∅∨M = ∅)
Theorem 182 : (N ⊇M) →

(N −K) ⊇(M −K)

Theorem 183 :

Finite(N) & N ⊇M

→

#(N \ M) = #(#N \ #M)

Theorem 184 : (N ∈N & M ∈N) →

(N + M) −M = N

Theorem 185 : (N ∈N & M ∈N & K ∈N) →

(N ⊇M) ↔

(N + K) ⊇(M + K)

Theorem 186 : (N ⊇M) →

#N = #M + #(N \ M)

Theorem 187 : (N ∈N & M ∈N & K ∈N & N ⊇M) →

(N + K) −(M + K) = N −M

Theorem 188 : (N ∈N & M ∈N) →

N = M + (N −M) ∨N = M −(M −N)

5.5 The Cardinal Product Theorem
Although our main goal is now to move on to the principal notions and theorems of
analysis, we digress to prove that the sum and product of any two inﬁnite cardinals
degenerates to their maximum. The two following theories prepare for this. Given
any ordinal-valued function f on a set s, the ﬁrst theory constructs the subset ‘rngΘ’
of s on which f assumes its minimum. The second theory tells us that any well-
ordering of a set s deﬁnes a one-to-one mapping of some ordinal o onto s which
realizes an isomorphism of the natural ordering of o (by the ‘∈’ relator) to the given
ordering of s. It also asserts that the mapping sends all ordinals larger than o onto
s, and all smaller ordinals onto an initial slice of s, i.e. all elements of s up to some
given v in s.
THEORY ordval_fcn( s, f(x)); [Elementary functions of ordinal-valued functions]
s ̸= ∅&

∀x ∈s| Ord

f (x)

=⇒(rngΘ)
rngΘ =

x : x ∈s| f(x) = arb

f(y): y ∈s

&
rngΘ ̸= ∅&

∀x ∈rngΘ
 
∀y ∈s
 
f(x) = f(y)

→y ∈rngΘ

&
rngΘ ⊆s &

∀x ∈rngΘ
 
∀y ∈s| f(x) ⊆f(y)

END ordval_fcn;

280
5
A Closer Examination of the Sequence of Deﬁnitions and Theorems
THEORY well_ordered_set( s, x ◁y );
(∀x ∈s| ¬x ◁x) &

∀x ∈s
 
∀y ∈s
 
∀z ∈s| (x ◁y & y ◁z) →x ◁z

&

∀t ⊆s
 (t ̸= ∅) →

∃x ∈t
 
∀y ∈t | (x ◁y ∨x = y )

=⇒(ordenΘ)
(X ∈s & Y ∈s) →(X ◁Y ∨Y ◁X ∨X = Y)
s ⊆

ordenΘ(y): y ∈X

↔ordenΘ(X) = s

ordenΘ(X) ̸= s

→

ordenΘ(X) ∈s

[Well-ordering is isomorphic to ordinal enumeration]

Ord(U) & Ord(V ) & ordenΘ(U) ̸= s & ordenΘ(V ) ̸= s

→

ordenΘ(U) ◁ordenΘ(V ) ↔U ∈V


Ord(U) & ordenΘ(U) ̸= s

→

ordenΘ(U) =

ordenΘ(x): x ∈U


Ord(U) & Ord(V ) & ordenΘ(U) ̸= s & ordenΘ(V ) ̸= s & U ̸= V

→

ordenΘ(U) ̸= ordenΘ(V )


∃o| Ord(o) & s =

ordenΘ(x): x ∈o

&

∀x ∈o| ordenΘ(x) ̸= s

& 1_1

x, ordenΘ(x)

: x ∈o


Ord(V ) & ordenΘ(V ) ̸= s

→

1_1

x, ordenΘ(x)

: x ∈V

&
domain

x, ordenΘ(x)

: x ∈V

= V &
range

x, ordenΘ(x)

: x ∈V

=

u ∈s: u ◁ordenΘ(V )

END well_ordered_set;
Instrumental to the theory just seen, it is convenient to develop before it this one:
THEORY well_founded_set( s, x ◁y );

∀t ⊆s| t ̸= ∅→

∃x ∈t | (∀y ∈t | ¬y ◁x)

=⇒(ordenΘ, oΘ)
(X ∈s & Y ∈s) →

(X ◁Y →¬Y ◁X ) & ¬X ◁X

s ⊆

ordenΘ(y): y ∈X

↔ordenΘ(X) = s

ordenΘ(X) ̸= s

→

ordenΘ(X) ∈s


Ord(U) & Ord(V ) & ordenΘ(U) ̸= s & ordenΘ(U) ◁ordenΘ(V )

→U ∈V

u: u ∈s| u ◁ordenΘ(V )

⊆

ordenΘ(x): x ∈V

···

oΘ ∈next

#P(s)

& Ord(oΘ) & s =

ordenΘ(x): x ∈oΘ

&

∀x ∈oΘ | ordenΘ(x) ̸= s

& 1_1

x, ordenΘ(x)

: x ∈oΘ

END well_founded_set;

5.6
The Signed Integers
281
The next seven theorems lead up to the Cardinal Square theorem which is the
main result of our digression. The main theorems are 194 and 195, which state that
the cardinal product of any inﬁnite cardinal n with itself, or with any smaller non-
zero cardinal, is simply n, and 192, which states that the sum of two inﬁnite cardinals
is simply the larger of the two. The remaining theorems in the block displayed are
preparatory. Theorem 189 states that addition of a single new element to an inﬁnite
set does not change its cardinality. Theorems 190 and 191 tell us that any inﬁnite set
s can be divided into two parts, both of the same cardinality as s. Theorem 193 tells
us that any inﬁnite set is in 1-1 correspondence with the Cartesian product of some
other set t with itself.
Theorem 189 : [One-more lemma]

¬Finite(S)

→

#S = #

S ∪{C}

Theorem 190 : [Division-by-2 lemma]

¬Finite(S)

→

∃T | #

T ×{∅,1}

= #S

Theorem 191 : [Cardinal doubling theorem]

Is_cardinal(S) &

¬Finite(S)

→

#

S×{∅,1}

= #S

Theorem 192 :

¬Finite(S)

→

S + T = #S ∪#T & #(S ∪T ) = #S ∪#T

Theorem 193 : [Cardinal square-root lemma]

¬Finite(S)

→

∃T | #(T ×T ) = #S

Theorem 194 : [Cardinal square theorem]

¬Finite(S)

→

#(S×S) = #S

Theorem 195 : [Cardinal product theorem]

T ∈S \ {∅} & Is_cardinal(S) &

¬Finite(S)

→(S ∗T = S)
5.6 The Signed Integers
Returning to our main line of development, we now introduce the set Z (from the
German: ‘Zahlen’) of signed integers as the set of pairs [x, ∅] (representing the
positive integers) and [∅, x] (representing the integers of negative sign). The formal
deﬁnition is as follows.
Def 26 : [Signed Integers] Z =Def

[x, y]: x ∈N,y ∈N| x = ∅∨y = ∅

Any pair of integers can be reduced to a signed integer by subtracting the smaller
of its two components from the larger. This operation, introduced by the following
deﬁnition, appears repeatedly in our subsequent proofs of the properties of signed
integers.
Def 27 : [Signed integer reduction to normal form] Red(p) =Def

p[1] −

p[1] ∩p[2]
, p[2] −

p[1] ∩p[2]

282
5
A Closer Examination of the Sequence of Deﬁnitions and Theorems
Next we extend the notions of sum, product, and difference to signed integers,
and also deﬁne three elementary operators, the absolute value, negative, and sign of
a signed integer, that have no direct analog for unsigned integers. The sum of two
signed integers i andj is simply the reduction of their componentwise sum. The
absolute value of i is the maximum of its two components (only one of which will be
non-zero). The negative of i is simply i with its components reversed. The difference
of two signed integers is then simply the sum of the ﬁrst and the negative of the
second. The product of signed integers is deﬁned as the reduction of an algebraic
combination of their components, formed in a way that reﬂects the standard ‘law of
signs’. A signed integer is positive if its second component is null; otherwise it is
negative.
[∅, ∅] is the ‘signed integer’ ∅, and the 1-1 mapping x →[x, ∅], whose inverse
is simply y →y[1], embeds N into the set of signed integers, in a manner allowing
easy extension of the addition, subtraction, multiplication, and division operators to
signed integers.
The relevant formal deﬁnitions are as follows.
Def 28 : [Signed sum] m +Z n =Def Red

m[1] + n[1], m[2] + n[2]
Def 28a : [Absolute value] |m|Z =Def

m[1] + m[2], ∅

Def 28b : [Negative] −Z(m) =Def

m[2], m[1]
Def 29 : [Signed product] m ∗Z n =Def
Red

m[1] ∗n[1]
+

m[2] ∗n[2]
,

m[1] ∗n[2]
+

n[1] ∗m[2]
Def 32 : [Signed difference] n −Z m =Def Red

m[2] + n[1], m[1] + n[2]
Def 33 : [Sign of a signed integer] Is_nonneg(x) ↔Def x[1] ⊇x[2]
The sequence of about 30 theorems which follows establishes all the main prop-
erties of signed integers, deriving these from the properties of unsigned integers
established previously. The proofs involved are all elementary, though sometimes
a bit tedious. Theorem 196 is a lemma asserting that the reduction of any pair of
unsigned integers is a signed integer. Theorem 197 merely restates the way in which
signed integers are deﬁned using integers. Theorem 199 begins our main work, by
showing that the set of signed integers is closed under addition and multiplication.
Theorem 196 : (M ∈N & N ∈N) →Red

[M, N]

∈Z
Theorem 197 : (N ∈Z) →

N =

N[1], N[2]
&

N[1] = ∅∨N[2] = ∅

&
N[1] ∈N & N[2] ∈N & Red(N) = N &

N[1] ∩N[2]
= ∅

Theorem 199 : (N ∈Z & M ∈Z) →(N +Z M ∈Z & N ∗Z M ∈Z)

5.6
The Signed Integers
283
To move toward our goal of establishing all the basic elementary properties of
signed integers, we ﬁrst prove some auxiliary properties of the reduction mapping
‘Red’ which normalizes pairs of integers by subtraction, sending them into equiva-
lent signed integers. We show that Red([n, m]) remains invariant if a common inte-
ger is added to n and m, that Red([n, n]) is always the signed zero element [∅, ∅],
and that the signed addition and multiplication operations remain invariant if one of
their arguments [n, m] is replaced by Red([n, m]). The proofs are all elementary,
but many involve examination of multiple cases.
Theorem 200 : (N ∈N) →

Red

[N, N]

= [∅, ∅]

Theorem 201 : (J ∈N & K ∈N & M ∈N) →

Red

[J +Z M, K +Z M]

= Red

[J, K]

Theorem 202 : (J ∈N & K ∈N & N ∈N & M ∈N) →

[J, K] +Z [N, M] = [J, K] +Z Red

[N, M]

Theorem 203 : (K ∈Z & N ∈N & M ∈N) →

K +Z [N, M] = K +Z Red

[N, M]

Theorem 204 : (K ∈Z & N ∈N & M ∈N) →

K ∗Z [N, M] = K ∗Z Red

[N, M]

Moving on toward proof of the basic properties of signed integers, we ﬁrst prove
commutativity of signed integer addition via two preliminary lemmas which give
commutativity for corresponding sums of ordered pairs of integers, and then com-
mutativity, associativity, and distributivity of signed integer multiplication. Next,
after a lemma which states that the reduction of a signed integer is the signed in-
teger itself, we show that the mapping of n into [n, ∅] sends integers into signed
integers in a manner which makes unsigned addition, multiplication, and subtrac-
tion correspond to signed addition, multiplication, and subtraction, respectively.
Theorem 205 : [Commutativity lemma, 1] (K ∈Z & N ∈N & M ∈N)
→

K +Z [N, M] = [N, M] +Z K

Theorem 206 : [Commutativity lemma, 2] (J ∈N & K ∈N & N ∈N & M ∈N)
→

[J, K] +Z [N, M] = [N, M] +Z [J, K]

Theorem 207 : [Commutative law for addition] (N ∈Z & M ∈Z) →
(N +Z M = M +Z N)
Theorem 208 : (J ∈N & K ∈N & N ∈N & M ∈N) →

[J, K] +Z [N, M] = Red

[J, K]

+Z Red

[N, M]

Theorem 209 : [Commutative law for multiplication] (N ∈Z & M ∈Z) →
(N ∗Z M = M ∗Z N)

284
5
A Closer Examination of the Sequence of Deﬁnitions and Theorems
Theorem 210 : [Associative law] (K ∈Z & N ∈Z & M ∈Z)
→

N +Z (M +Z K) = (N +Z M) +Z K

Theorem 211 : [Distributive law] (K ∈Z & N ∈Z & M ∈Z)
→

N ∗Z (M +Z K) = (N ∗Z M) +Z (N ∗Z K)

Theorem 212 : (N ∈N) →

Red

[N, ∅]

= [N, ∅]

Theorem 213 : [Embedding of integers in signed integers] (N ∈N & M ∈N)
→

[N + M, ∅] = [N, ∅] +Z [M, ∅]

&

[N ∗M, ∅] = [N, ∅] ∗Z [M, ∅]

&

N ⊇M →

[N, ∅] −Z [M, ∅] = [N −M, ∅]

Next we give a few elementary theorems on the operation of sign reversal for
signed integers: the law of signs for multiplication, the rule that −(−n) is n, and the
fact that n + (−n) is ∅.
Theorem 214 : (N ∈N & M ∈N) →

−Z

Red

[M,N]

= Red

[N, M]

Theorem 215 : (N ∈Z & M ∈Z) →

N ∗Z −Z(M) = −Z(N ∗Z M)

Theorem 216 : [Inversion lemma] (N ∈Z & M ∈Z)
→

−Z(N ∗Z M) = −Z(N) ∗Z M & −Z(N ∗Z M) = N ∗Z −Z(M)

Theorem 217 : [Double inversion] (K ∈Z) →

−Z

−Z(K)

= K

Theorem 218 : (N ∈Z) →

−Z(N) ∈Z & −Z(N) +Z N = [∅, ∅] & −Z

−Z(N)

= N

Our next four theorems lead up to the proof that signed integer multiplication is
associative. The ﬁrst three results state this in special cases. This stepwise approach
is needed since a large number of cases need to be examined.
Theorem 219 : [Associativity lemma, 1] (K ∈N & N ∈N & M ∈N)
→

[N, ∅] ∗Z

[M, ∅] ∗Z [K, ∅]

=

[N, ∅] ∗Z [M, ∅]

∗Z [K, ∅]

Theorem 220 : [Associativity lemma, 2] (K ∈Z & N ∈N & M ∈N)
→

[N, ∅] ∗Z

[M, ∅] ∗Z K

=

[N, ∅] ∗Z [M, ∅]

∗Z K

Theorem 221 : [Associativity lemma, 3] (K ∈Z & N ∈N & M ∈Z)
→

[N, ∅] ∗Z (M ∗Z K) =

[N, ∅] ∗Z M

∗Z K

Theorem 222 : [Associativity law] (K ∈Z & N ∈Z & M ∈Z)
→

N ∗Z (M ∗Z K) = (N ∗Z M) ∗Z K

The ﬁnal block of theorems in this ‘signed integer’ group show that n + (−m)
is n −m, that −(n + m) is −n −m, that [1, ∅] is the multiplicative identity for

5.7
Induction Principles for Ordinals
285
signed integer multiplication, and that [∅, ∅] is the additive identity. All the proofs
are elementary.
Theorem 223 : (N ∈Z & M ∈Z) →

N −Z M = N +Z −Z(M)

Theorem 224 : (N ∈Z & M ∈Z) →

N = M +Z (N −Z M)

Theorem 225 : (N ∈Z & M ∈Z) →

−Z(N +Z M) = −Z(N) +Z −Z(M)

Theorem 226 : [∅, 1] ∗Z [∅, 1] = [1, ∅]
Theorem 227 : (K ∈Z) →

K ∗Z [1, ∅] = K

Theorem 228 : (K ∈Z & M ∈Z) →

K −Z M = K +Z

M ∗Z [∅, 1]

Theorem 229 : (K ∈Z) →

K −Z K = [∅, ∅]

Theorem 230 : (K ∈Z) →

K +Z [∅, ∅] = K

Theorem 231 : (K ∈Z) →

[∅, ∅] +Z K = K

Next, in direct preparation for the introduction of the set of rational numbers, we
prove that the set of signed integers is an ‘integral domain’ in which multiplication
has the standard algebraic cancellation property. This is done in Theorems 232 and
234. We also show that multiplication is distributive over subtraction, and that the
negative of a signed integer can be expressed as its product with the signed integer
−1, i.e. [∅, 1].
Theorem 232 : [Z is an integral domain] (N ∈Z & M ∈Z)
→

M ∗Z N = [∅, ∅]

→

M = [∅, ∅] ∨N = [∅, ∅]

Theorem 233 : [Distributivity of subtraction]

(N ∈Z) & (M ∈Z) & (K ∈Z)

→

(M ∗Z N) −Z (K ∗Z N) = (M −Z K) ∗Z N

Theorem 234 : [Z cancellation]

(N ∈Z) & (M ∈Z) & (K ∈Z)

→

(M ∗Z N = K ∗Z N) &

N ̸= [∅, ∅]

→(M = K)

Theorem 235 : [Multiplication by −1] (N ∈Z) →

−Z(N) = [∅, 1] ∗Z N

This completes our work on the basic properties of signed integers.
5.7 Induction Principles for Ordinals
To prepare for what will come later we give various results stating principles of
induction. Many of these are cast as theories, for convenience of use. We also prove

286
5
A Closer Examination of the Sequence of Deﬁnitions and Theorems
various auxiliary results on the set of ‘ultimate members’ of a set s, i.e. all those t
which can be connected to s via a ﬁnite chain of membership relations. These are
used in some of the work with the principles of induction in which we are interested.
The main result is simply that the collection of ultimate members of a set is also a
set.
The ﬁrst theory developed simply tells us that any predicate P(·) of an ordinal
which is not always false admits some ordinal for which it is true, but for which
the P is false for all smaller ordinals. This tailored variant of the more general
principle of transﬁnite induction stated earlier is sometimes the most convenient
form in which to carry out a transﬁnite inductive proof.
THEORY ordinal_induction

o, P(x)

Ord(o) & P(o)
=⇒(t)
Ord(t) & P(t) & t ⊆o &

∀x ∈t
 
¬P(x)

END ordinal_induction
Next we deﬁne the set Ult_membs(s) of ‘ultimate members’ of a set s, which
plays a role in some of our versions of transﬁnite induction, and prove its properties.
The deﬁnition is as follows.
Def 35a : Ult_membs(s) =Def s ∪

y : u ∈

Ult_membs(x): x ∈s

, y ∈u

.
The eight elementary theorems which follow state various basic properties of
Ult_membs(s). Theorems 236, 239, and 242 state that Ult_membs(s) always in-
cludes s, is increasing in s, but is identical to s if s is an ordinal. Theorem 240 states
that Ult_membs({s}) is almost the same as Ult_membs(s), containing the set s as
its only additional member; Theorem 241 specializes this result to ordinals. Theo-
rem 237 gives a convenient inductive deﬁnition of Ult_membs(s), and Theorem 238
states that Ult_membs(s) contains all members of members of s. Theorem 243 tells
us that if y ∈s, then Ult_membs(y) is a subset of Ult_membs(s).
Theorem 236 : S ⊆Ult_membs(S)
Theorem 237 : Ult_membs(S) = S ∪

y : x ∈S, y ∈Ult_membs(x)

Theorem 238 : (X ∈S & Y ∈X) →

Y ∈Ult_membs(S)

Theorem 239 : Ord(S) →

Ult_membs(S) = S

Theorem 240 : Ult_membs

{S}

= {S} ∪Ult_membs(S)
Theorem 241 : Ord(S) →

Ult_membs

{S}

= S ∪{S}

Theorem 242 :

Y ∈Ult_membs(S)

→

Ult_membs(Y) ⊆Ult_membs(S)

Theorem 243 :

Y ∈Ult_membs(S)

→

Y ⊆Ult_membs(S)


5.8
Equivalence Relationships and Classes; the General Summation Operator
287
5.7.1 Mathematical Induction for Integers
Next we give four variants of the principle of mathematical induction, one based on
the preceding work with ‘Ult_membs’, two others specialized to the set of integers.
Two of these are designed to facilitate arguments by ‘double induction’ on a pair of
indices.
THEORY transﬁnite_member_induction

n, P(x)

P(n)
=⇒(m)
m ∈Ult_membs

{n}

& P(m) &

∀k ∈m|

¬P(k)

END transﬁnite_member_induction;
THEORY double_transﬁnite_induction

n, k, R(x,y)

R(n,k)
=⇒(m,j)
R(m,j) &

∀h ∈m
 
∀i
 
¬R(h,i)

&

∀i ∈j
 
¬R(m,i)

END double_transﬁnite_induction;
THEORY mathematical_induction

n, P(x)

n ∈N & P(n)
=⇒(m)
m ∈N & P(m) &

∀k ∈m
 
¬P(k)

END mathematical_induction;
THEORY double_induction

n, k, R(n,k)

{n,k} ⊆N & R(n,k)
=⇒(m,j)
m ∈N & j ∈N & R(m,j) &

∀h ∈m
 
∀i ∈N
 
¬R(h,i)

&

∀i ∈j
 
¬R(m,i)

END double_induction.
5.8 Equivalence Relationships and Classes; the General
Summation Operator; Recursion
This is where the two important ‘theories’ mentioned earlier, viz. the theory of
equivalence classes and the theory of Sigma, enter into game. The former of these,
given a set s and a dyadic relation which behaves as an equivalence relationship
over it, splits s into maximal sets of mutually equivalent elements, also selecting
arb(κ) within each such equivalence class κ as a convenient standard representative
for the class. We do not enter into further detail on this issue, which has already
been discussed.
As previously noted, the theory of Sigma is a formal substitute for the common
but informal mathematical use of ‘three dot’ summation (and product) notations like

288
5
A Closer Examination of the Sequence of Deﬁnitions and Theorems
a1 + a2 + ··· + an and a1 ∗a2 ∗··· ∗an. In the following formulation (slightly more
general than the one seen in Sect. 1.4.2.6), ‘Sigma_theory’ allows us to associate
an overall sum of range values with any map having a ﬁnite domain and range
included in a set for which a commutative and associative addition operator with a
zero element is deﬁned. It also tells us that summation is additive for pairs of such
maps having disjoint domains.
THEORY Sigma_theory(s,u ⊕v,e)
e ∈s &

∀x ∈s| (∀y ∈s| x ⊕y ∈s)

(∀x ∈s| x ⊕e = x) &

∀x ∈s| (∀y ∈s| x ⊕y = y ⊕x)


∀x ∈s
 
∀y ∈s
 
∀z ∈s| (x ⊕y) ⊕z = x ⊕(y ⊕z)

=⇒(ΣΘ) -- ﬁnite summation over a commutative monoid
ΣΘ(∅) = e &

Y ∈s →ΣΘ

[X, Y]

= Y


Finite(F) & range(F) ⊆s

→

ΣΘ(F) ∈s & ΣΘ(F) = ΣΘ(F ∩G) ⊕ΣΘ(F \ G)


Finite(F) & range(F) ⊆s & Is_map(F)

→

ΣΘ(F) = ΣΘ(F|T ) ⊕ΣΘ(F|domain(F)\T )


Finite(F) & range(F) ⊆s & Svm(F) & Svm(G) &
domain(F) = domain(G)

→
ΣΘ(F) = ΣΘ

y, ΣΘ(F|G↰{y})

: y ∈range(G)


Finite(F) & range(F) ⊆s & Svm(F) & 1_1(G) &
domain(F) = domain(G)

→
ΣΘ(F) = ΣΘ

y, F

G−1[y]

: y ∈range(G)

END Sigma_theory.
Inside Sigma_theory, a recursive characterization of ΣΘ is provided so as to
enforce the equality
ΣΘ(F) = if F = ∅then e
elseif arb(F)[2] ∈s then
arb(F)[2] ⊕ΣΘ

F \

arb(F)

else ΣΘ

F \

arb(F)

end if
for every ﬁnite set F.
Legitimizing such a recursive construction in our formal setting is in fact possible
on the basis of the remark that the strict inclusion relation ⊊is well-founded over
the ﬁnite sets. To do this, we ﬁrst develop a theory which allows construction of a
function by recursion over a set endowed with a well-founded relationship:
THEORY wellfdd_recursive_fcn

s, y ◁x, f(b, x, t), g(r, y, x, t), P(r, y, x, t)


∀t ⊆s| t ̸= ∅→

∃x ∈t | (∀y ∈t | ¬y ◁x)

-- ◁is thereby assumed to be irreﬂexive and well-founded on s

5.9
Formal Fractions and Rational Numbers
289
=⇒( recΘ, rkΘ )

∀x, t | x ∈s →recΘ(x, t) =
f

g

recΘ(y, t), y, x, t

: y ∈s| y ◁x &
P

recΘ(y, t), y, x, t

, x, t


∀x, t | x ∈s →rkΘ(x, t) =

next

rkΘ(y, t)

: y ∈s| y ◁x &
[y, x] ∈t

END wellfdd_recursive_fcn.
This form of recursion cannot be exploited directly for the class of all ﬁnite sets
ordered by ⊊, because ﬁnite sets form a proper class. But consider a pair of functions
rec and rec′, both of which satisfy the same recursive relationship (based on ⊊) on
their domains d, which are assumed to be such that every subset of a member of d is
ﬁnite and belongs to d. (For example, d might be {x :x ⊆s |Finite(x)}.) One easily
sees that rec and rec′ necessarily agree on the intersection of their domains, and so
have a common single-valued extension. Thanks to this possibility of amalgamation,
we make the following theory, through which we can carry out constructions of the
kind needed inside the theory of Sigma:
THEORY ﬁnite_recursive_fcn

f(b, x, t), g(r, y, x, t), P(r, y, x, t)

=⇒(recΘ )

∀x, t | Finite(x) →recΘ(x, t) =
f

g

recΘ(y, t), y, x, t

: y ⊆x | y ̸= x & P

recΘ(y, t), y, x, t

, x, t

END ﬁnite_recursive_fcn.
5.9 Formal Fractions and Rational Numbers
Returning again to our main line of development, we prepare for the intended in-
troduction of rational numbers (which follows a bit later) by deﬁning the set of
formal fractions of signed integers and establishing the algebraic properties of these
fractions. This will allow us to deﬁne rational numbers as equivalence classes of
fractions under the usual ‘equality of cross-products’ equivalence relationship. Note
that the path followed is that of the standard algebraic construction of a ﬁeld from
an integral domain.
The set of fractions is simply the set of ordered pairs of signed integers, of which
the second (the ‘denominator’) must be non-zero.
Def 35 : Fr =Def

[x, y]: x ∈Z,y ∈Z| y ̸= [∅, ∅]


290
5
A Closer Examination of the Sequence of Deﬁnitions and Theorems
Two fractions are equivalent, i.e. stand in the relationship Same_frac(p,q), if
their cross-products are equal.
Def 36 : Same_frac(p,q) ↔Def p[1] ∗Z q[2] = p[2] ∗Z q[1]
The ‘Same_frac’ relationship is an equivalence relationship.
Theorem 245 : (X ∈Fr & Y ∈Fr)
→

Same_frac(X,Y) ↔Same_frac(Y,X)

& Same_frac(X,X)

Theorem 246 : (X ∈Fr & Y ∈Fr & Z ∈Fr)
→

Same_frac(X,Y) & Same_frac(Y,Z)

→Same_frac(X,Z)

At this point, the theory of equivalence classes can be used to introduce the set
Q of rational numbers (i.e. the equivalence classes of fractions), and a map Fr_to_Q
of fractions into rationals such that Same_frac(x,y) is equivalent to Fr_to_Q(x) =
Fr_to_Q(y).
Theorem 247 :

∀y ∈Q| arb(y) ∈Fr & Fr_to_Q

arb(y)

= y

&

∀x ∈Fr| Fr_to_Q(x) ∈Q

&

∀x ∈Fr
 
∀y ∈Fr| Same_frac(x,y) ↔Fr_to_Q(x) = Fr_to_Q(y)

&

∀x ∈Fr| Same_frac

x,arb

Fr_to_Q(x)

Having now introduced rationals as equivalence classes of fractions, we can de-
ﬁne the zero and unit rationals, and the algebraic operations on rationals, from the
corresponding notions for fractions. The reciprocal of a rational is obtained by sim-
ply inverting any of the fractions which represent it. These familiar ideas are cap-
tured by the following sequence of deﬁnitions. Note that multiplication of fractions
is componentwise, but that to add one must ﬁrst multiply their denominators to put
the two fractions being added over a ‘common denominator’. Division of rationals
is deﬁned as multiplication by the reciprocal, subtraction as addition of the negative.
A rational is non-negative if any (hence all) of its representative fractions have nu-
merator and denominator of the same sign; x is greater than (or equal to) y if x −y
is non-negative. These standard notions are formalized by the following group of
deﬁnitions.
Def 37 : [The zero rational] 0Q =Def Fr_to_Q

[0, 0], [1, 0]

Def 37a : [The unit rational] 1Q =Def Fr_to_Q

[1, 0], [1, 0]

Def 38 : [Rational sum] x +Q y =Def
Fr_to_Q

arb(x)[1] ∗Z arb(y)[2]
+Z

arb(y)[1] ∗Z arb(x)[2]
,
arb(x)[2] ∗Z arb(y)[2]
Def 39 : [Rational product] x ∗Q y =Def
Fr_to_Q

arb(x)[1] ∗Z arb(y)[1], arb(x)[2] ∗Z arb(y)[2]

5.9
Formal Fractions and Rational Numbers
291
Def 40 : [Reciprocal] Recip(x) =Def Fr_to_Q

arb(x)[2], arb(x)[1]
Def 41 : [Rational quotient] x/Q y =Def x ∗Q Recip(y)
Def 42 : [Rational negative] −Q(x) =Def Fr_to_Q

−Z

arb(x)[1]
, arb(x)[2]
Def 43 : [Non-negative rational] Is_nonnegQ(x) =Def
Is_nonneg

arb(x)[1] ∗Z arb(x)[2]
Def 44 : [Rational subtraction] x −Q y =Def x +Q −Q(y)
Def_by_app 45 : [Rational comparison]
x ⩾Q y ↔Is_nonnegQ(x −Q y)
Our subsequent work with rationals and reals will involve a great deal of elemen-
tary work with inequalities between sums and differences, for which the following
theory of addition in ordered sets (just now, though tacitly, referred to) prepares.
THEORY Ordered_add

g, e,X ⊕Y,X ⊖Y,rvz(X), nneg(X)

e ∈g &

∀x ∈g| x ⊕e = x & x ⊕rvz(x) = e & rvz(x) ∈g


∀x ∈g
 
∀y ∈g| x ⊕y ∈g & x ⊕y = y ⊕x & x ⊕rvz(y) = x ⊖y


∀x ∈g
 
∀y ∈g
 
∀z ∈g| (x ⊕y ) ⊕z = x ⊕(y ⊕z)


∀x ∈g
 
∀y ∈g
 
nneg(x) & nneg(y)

→nneg(x ⊕y)


∀x ∈g
 
nneg(x) ∨nneg

rvz(x)

&

nneg(x) & nneg

rvz(x)

→(x = e)

=⇒(⩾g,⩽g,>g,<g)
X ⩾g Y ↔nneg

X ⊕rvz(Y)

X ⩽g Y ↔Y ⩾g X
X >g Y ↔X ⩾g Y & X ̸= Y
X <g Y ↔Y >g X

X ∈g & Y ∈g &

X = Y ∨¬(X ⩾g Y)

→Y ⩽g X
END Ordered_add
The next four theorems give miscellaneous ordering properties of the signed inte-
gers used to prove corresponding properties of the rationals. If n is a signed integer,
either n or −n is non-negative, and if both are non-negative then n is 0. The sum and
product of two non-negative integers is non-negative, and the square of any signed
integer is non-negative.
Theorem 248 : (X ∈Z) →

Is_nonneg(X) ∨Is_nonneg

−Z(X)

&

Is_nonneg(X) & Is_nonneg

−Z(X)

→

X = [0, 0]

Theorem 249 :

X ∈Z & Y ∈Z & Is_nonneg(X) & Is_nonneg(Y)

→

Is_nonneg(X +Z Y) & Is_nonneg(X ∗Z Y)


292
5
A Closer Examination of the Sequence of Deﬁnitions and Theorems
Theorem 250 : (X ∈Z) →Is_nonneg(X ∗Z X)
Theorem 251 :

X ∈Z & Y ∈Z & X ̸= [0, 0] & Is_nonneg(X)

→

Is_nonneg(X ∗Z Y ) ↔Is_nonneg(Y)

Now we begin to work with rationals. Any fraction is a pair of signed integers
with non-zero second component. Any member of a rational is a pair of signed
integers, and, indeed, a fraction. If two pairs of fractions x,y and w,z are equivalent
as rationals, then the sum of x and w is equivalent to the sum of y and z, and
similarly for the products. The rational sum of a rational x with the class containing
a fraction [y, z] can be obtained by adding any fraction in x to [y, z], and then
forming the equivalence class of the result. Much the same statement applies to
products of rationals.
Theorem 252 : X ∈Fr ↔

X =

X[1], X[2]
& X[1] ∈Z & X[2] ∈Z & X[2] ̸= [0, 0]

Theorem 253 : (N ∈Q) →

arb(N) ∈Fr & arb(N) =

arb(N)[1], arb(N)[2]
& arb(N)[1] ∈Z & arb(N)[2] ∈Z & arb(N)[2] ̸= [0, 0]

Theorem 254 :

X ∈Fr & Y ∈Fr & Same_frac(X,Y) & W ∈Fr &
Z ∈Fr & Same_frac(W,Z)

→
Same_frac

X[1] ∗Z W [2]
+Z

W [1] ∗Z X[2]
, X[2] ∗Z W [2]
,

Y [1] ∗Z Z[2]
+Z

Z[1] ∗Z Y [2]
, Y [2] ∗Z Z[2]
Theorem 255 :

X ∈Fr & Y ∈Fr & Same_frac(X,Y) & W ∈Fr &
Z ∈Fr & Same_frac(W,Z)

→
Same_frac

X[1] ∗Z W [1], X[2] ∗Z W [2]
,

Y [1] ∗Z Z[1], Y [2] ∗Z Z[2]
Theorem 256 :

X ∈Q & Y ∈Z & Z ∈Z & Z ̸= [0, 0]

→

X +Q Fr_to_Q

[Y, Z]

=
Fr_to_Q

arb(X)[1] ∗Z Z

+Z

arb(X)[2] ∗Z Y

,

arb(X)[2] ∗Z Z

Theorem 257 :

X ∈Q & Y ∈Z & Z ∈Z & Z ̸= [0, 0]

→

X ∗Q Fr_to_Q

[Y, Z]

= Fr_to_Q

arb(X)[1] ∗Z Y, arb(X)[2] ∗Z Z

Continuing our work with rationals, we have: The fractions [n, m] and [−n, −m]
are equivalent as rationals. If two equivalent fractions both have non-negative de-
nominators, they both have non-negative numerators, and in this case so does their
product. A fraction [n, m] is non-negative if and only if [−n, −m] is non-negative.
If one of two equivalent fractions is non-negative, so is the other. Rational addi-
tion and multiplication are both commutative and associative. The rational sum of
a rational x with the class containing a fraction [y, z] can be obtained by adding
any fraction in x to [y, z] in the reverse order from that considered just above, and
then forming the equivalence class of the result; similarly for products of rationals.

5.9
Formal Fractions and Rational Numbers
293
The sum of a rational with its negative is the zero rational. The zero rational is
the additive identity for rationals. The standard laws of subtraction apply to ratio-
nals.
Theorem 258 : (X ∈Fr) →Same_frac

X,

−Z

X[1]
, −Z

X[2]
Theorem 259 :

X ∈Fr & Y ∈Fr & Same_frac(X,Y) & Is_nonneg

X[2]
&
Is_nonneg

Y [2]
→

Is_nonneg

X[1]
∨X[1] = [0, 0]

↔

Is_nonneg

Y [1]
∨Y [1] = [0, 0]

Theorem 261 :

X ∈Fr & Y ∈Fr & Same_frac(X,Y)

→

Is_nonneg

X[1] ∗Z X[2]
↔Is_nonneg

Y [1] ∗Z Y [2]
Theorem 262 : (X ∈Fr) →

Is_nonnegQ(X) ↔Is_nonnegQ

−Z

X[1]
, −Z

X[2]
Theorem 263 :

X ∈Fr & Y ∈Fr & Same_frac(X,Y)

→

Is_nonnegQ(X) ↔Is_nonnegQ(Y)

Theorem 264 : [Commutativity of Addition] (N ∈Q & M ∈Q) →
(N +Q M = M +Q N)
Theorem 265 :

X ∈Q & Y ∈Z & Z ∈Z & N ̸= [0, 0]

→

Fr_to_Q

[Y, Z]

+Q X =
Fr_to_Q

arb(X)[1] ∗Z Z

+Z

arb(X)[2] ∗Z Y

,

arb(X)[2] ∗Z Z

Theorem 266 :

X ∈Z & Y ∈Z & Z ∈Z & W ∈Z & Y ̸= [0, 0] &
W ̸= [0, 0]

→

Fr_to_Q

[X, Y]

+Q Fr_to_Q

[Z, W]

=
Fr_to_Q

(X ∗Z W) +Z (Z ∗Z Y), Y ∗Z W

Theorem 267 : [Commutativity of Multiplication] (N ∈Q & M ∈Q) →
(N ∗Q M = M ∗Q N)
Theorem 268 :

X ∈Q & y ∈Z & Z ∈Z & Z ̸= [0, 0]

→

Fr_to_Q

[Y, Z]

∗Q X = Fr_to_Q

arb(X)[1] ∗Z Y, arb(X)[2] ∗Z Z

Theorem 269 : (K ∈Q & N ∈Q & M ∈Q) →

N +Q (M +Q K) = (N +Q M) +Q K

Theorem 270 : (M ∈Q) →(M = M +Q 0Q)
Theorem 271 : (M ∈Q) →

M +Q −Q(M) = 0Q

Theorem 272 : (N ∈Q & M ∈Q) →

N = M +Q (N −Q M)


294
5
A Closer Examination of the Sequence of Deﬁnitions and Theorems
Theorem 273 : (K ∈Q & N ∈Q & M ∈Q) →

N ∗Q (M ∗Q K) = (N ∗Q M) ∗Q K

The next ﬁfteen theorems complete our collection of elementary results concern-
ing rationals.
Theorem 274 :

K ∈Z & N ∈Z & M ∈Z & K ̸= [0, 0] & M ̸= [0, 0]

→

Fr_to_Q

[N, M]

= Fr_to_Q

[K ∗Z N, K ∗Z M]

Theorem 275 : (K ∈Q & N ∈Q & M ∈Q) →

N ∗Q (M +Q K) = (N ∗Q M) +Q (N ∗Q K)

Theorem 276 :

X ∈Z & y ∈Z & Y ̸= [0, 0]

→

Is_nonnegQ

Fr_to_Q

[X, Y]

↔Is_nonneg(X ∗Z Y)

Theorem 277 : (M ∈Q) →(M = M ∗Q 1Q)
Theorem 278 : (M ∈Q & M ̸= 0Q) →

Recip(M) ∈Q & M ∗Q Recip(M) = 1Q

Theorem 279 : (N ∈Q & M ∈Q & M ̸= 0Q) →

N = M ∗Q (N/Q M)

Theorem 280 : Is_nonnegQ(0Q) & Is_nonnegQ(1Q)
Theorem 281 : (X ∈Q) →

Is_nonnegQ(X) ∨Is_nonnegQ

−Q(X)

&

Is_nonnegQ(X) & Is_nonnegQ

−Q(X)

→(X = 0Q)

Theorem 282 : (X ∈Q) →(X = X ∗Q 1Q)
Theorem 283 : (X ∈Q) →

X = 0Q ↔arb(x)[1] = [0, 0]

Theorem 284 :

X ∈Q & Y ∈Q & Is_nonnegQ(X) & Is_nonnegQ(Y)

→

Is_nonnegQ(X +Q Y) & Is_nonnegQ(X ∗Q Y)

Theorem 291 : (X ∈Q & Y ∈Q & X1 ∈Q & X >Q Y & X1 >Q 0Q) →
(X ∗Q X1 >Q Y ∗Q X1)
Theorem 292 : 1Q >Q 0Q
Theorem 293 : (X ∈Q & X >Q 0Q) →

Recip(X) >Q 0Q

Theorem 294 : (X ∈Q & Y ∈Q & X >Q Y) →

X >Q (X +Q Y)/Q (1Q + 1Q) & (X +Q Y)/Q (1Q + 1Q) >Q Y


5.10
Real Numbers
295
5.10 Real Numbers
We have now proved enough about the rational numbers to be able to go on to deﬁne
the set of real numbers and prove their basic properties. Historically this has been
done in several ways, which offer competing advantages when computer-based veri-
ﬁcation is intended. In Dedekind’s approach, which is the most directly set-theoretic
of all, a real number is deﬁned simply as a set of rational numbers, bounded above,
which contains no largest element and which contains each rational y smaller than
any of its members. Sums are easily deﬁned for real numbers deﬁned in this way,
but it is only easy to deﬁne products for positive reals directly. This forces separate
treatment of real products involving negative reals, causing the proof of statements
like the associativity of multiplication to break up into an irritating number of sep-
arate cases. For this reason, we choose a different approach, originally developed
by Cantor in 1872 (cf. [Can72]), in which real numbers are deﬁned as follows. Call
an inﬁnite sequence xn of rational numbers a Cauchy sequence if, for every positive
rational r, there exists an integer N such that the absolute value |xn −xm| is less
than r whenever m and n are both larger than N. Sequences of this kind can be
added, subtracted, and multiplied componentwise and their sums, differences, and
products are still Cauchy sequences. We can now introduce an equivalence relation-
ship Same_real between pairs x,y of such sequences: Same_real(x,y) is true if and
only if, for every positive rational r, there exists an integer N such that the absolute
value |xn −yn| is less than r whenever n is larger than N. The set of equivalence
classes of Cauchy sequences, formed using the equivalence relationship Same_real,
is then the set of real numbers. If two pairs of Cauchy sequences x,y and w,z are
equivalent, then the (componentwise) sum of x and w is equivalent to the sum of
y and z, and similarly for the products and differences. Hence these operations de-
ﬁne corresponding operations on the real numbers, which are easily seen to have
the same properties of associativity, commutativity, and distributivity, and the same
relationship to comparison operators deﬁned similarly.
Given any rational number r we can form a sequence repeating r inﬁnitely often,
and then map r to the equivalence class (under Same_real) of this sequence. This
construction is readily seen to embed the rationals into the reals, in a manner that
preserves addition, multiplication, and subtraction. The zero rational maps in this
way into an additive identity for real addition, and the unit rational into the multi-
plicative identity for reals. If a Cauchy sequence yn is not equivalent to the zero of
reals, then it is easily seen that for all sufﬁciently large n the absolute values |yn| are
non-zero and have a common lower bound. Hence for any other Cauchy sequence
xn we can form the rational quotients xn/yn for all sufﬁciently large n, and it is easy
to see that this gives a Cauchy sequence whose equivalence class depends only on
that of x and y. It follows that this construction deﬁnes a quotient operator x/y for
real numbers, and it is not hard to prove that this quotient operator relates to real
multiplication in the appropriate inverse way.
This approach, based on rational Cauchy sequences, for introducing reals has
been outlined in more formal terms in Sect. 4.1.4. We have opted for it, on the
basis of pragmatic considerations; but we initially inclined towards the charming

296
5
A Closer Examination of the Sequence of Deﬁnitions and Theorems
simplicity of the deﬁnition of the reals as Dedekind cuts over the rationals. The list
below shows the most basic deﬁnitions and theorem streamlining this competing
approach:
Def 46 : [The real numbers as the set of Dedekind cuts] R =Def

s : s ⊆Q


∀x ∈s | (∃y ∈s | y >Q x)

&

∀x ∈s
 
∀y ∈Q| (x >Q y) →(y ∈s)

\{∅,Q}
Def 47 : [Real 0 and 1] 0R =Def {x ∈Q| 0Q >Q x } &
1R =Def {x ∈Q| 1Q >Q x}
Def 48 : [Real sum] X +R Y =Def {u +Q v : u ∈X, v ∈Y }
Def 49 : [Real negative] −R(X) =Def

−Q(u) +Q v : u ∈Q \ X, v ∈0R

Def 50 : [Real subtraction] X −R Y =Def X +R −R(Y)
Def 51 : [Absolute value] |X| =Def X ∪−R(X)
[i.e. the larger of X and −R(X)]
Def 52 : [Real multiplication of absolute values] X | ∗| RY =Def

u ∗Q v : u ∈|X| & v ∈|Y|| ¬(0Q >Q u ∨0Q >Q v)

∪0R
Def 53 : [Real multiplication] X ∗R Y =Def
if X ⊇0R ↔Y ⊇0R then X | ∗| RY else −R (X | ∗| RY) end if
Def 54 : [Real absolute reciprocal] | 1
· |(X) =Def
	
y : y ∈R| |X| ∗R y ⊆

r ∈Q| Fr_to_Q

[1, 1]

>Q r

Def 55 : [Real reciprocal] RecipR(X) =Def
if X ⊇0R then
 1
·
(X) else −R
 1
·
(X)

end if
Def 56 : [Real quotient] X/R Y =Def x ∗R RecipR(Y)
Def 56a : [Non-negative real] Is_nonnegR(X) =Def 0R ⊆X
Def 56b : [Real comparison, 1] X >R Y ↔Def
Is_nonnegR(X −R Y) &

¬(X = Y)

Def 56c : [Real comparison, 2] X ⩾R Y ↔Def Is_nonnegR(X −R Y)
Def 57 : [Real square root]
√
X =Def
	
y : y ∈R| (y ∗R y) ⊆X

Theorem 295 : (X ∈Q) →

{y : y ∈Q| x >Q y} ∈R


5.10
Real Numbers
297
Theorem 297 : (N ∈R) →(N ⊆Q)
Theorem 298 : (N ∈R) →

∃m ∈Q| (∀x ∈N | m >Q x)

Theorem :

N ∈Z & M ∈Z & M ̸= [0, 0] & Is_nonneg(M)

→

∃k ∈Z| Is_nonneg

N −Z (k ∗Z M)

&
Is_nonneg

k +Z [1, 0]

∗Z M

−Z N

Theorem : (N ∈R) →

N = N +R −R(N) = 0R

Theorem : (N ∈R & M ∈R) →(N | ∗| RM = M | ∗| RN)
Theorem :

N ∈R & M ∈R & Is_nonnegR

−R(M)

→
(N >R N +R M ∨N = N +R M)
Theorem : (N ∈R & M ∈R) →(N ∪M ∈R)
Theorem : [Least upper bound] (S ̸= ∅& S ⊆R) →(	S ∈R ∨	S = Q)
After the foregoing series of deﬁnitions and preparatory theorems we now begin
to prove the basic properties of the real numbers.4 The sum, product, and quotient
of two real numbers is a real number. The zero and unit reals are both non-negative,
and the unit is larger. The zero real is the additive identity for reals. The sum and
product of two reals and the negative of a real are both reals. The sum of any real
and its negative is the zero real. Real addition and multiplication are commutative.
The absolute value of a real x is a real which is non-negative and at least as large as
x. The absolute value of a real x is x if x is non-negative, otherwise it is the negative
of x. The absolute value of a real x is also the absolute value of the negative of x.
Theorem 296 : 0R ∈R & 1R ∈R &
Is_nonnegR(0R) & Is_nonnegR(1R) & 1R >R 0R
Theorem 299 : (N ∈R & M ∈R) →(N +R M ∈R)
Theorem 300 : (N ∈R & M ∈R) →(N +R M = M +R N)
Theorem 301 : (N ∈R) →(N = N +R 0R)
Theorem 302 : (N ∈R) →

−R(N) ∈R

Theorem : (N ∈R & M ∈R) →

N = M +R (N −R M)

4From this point on it is immaterial whether the reals have been introduced as Dedekind cuts or as
equivalence classes of rational Cauchy sequences.

298
5
A Closer Examination of the Sequence of Deﬁnitions and Theorems
Theorem : (N ∈R & M ∈R) →(N ∗R M ∈R)
Theorem : (N ∈R & M ∈R) →(N ∗R M = M ∗R N)
Theorem : [The reals are a linearly ordered set]
(N ∈R & M ∈R) →

(N ⩾R M ∨M ⩾R N ) &

(N ⩾R M & M ⩾R N ) →N = M

Theorem : (N ∈R) →

|N| ∈R & |N| ⩾R N

Theorem : (N ∈R) →

|N| = if Is_nonnegR(N) then N else −R (N) end if

Theorem : (N ∈R) →

|N| =
−R(N)

Continuing our series of theorems giving elementary properties of real numbers,
we have the following. The absolute value of a real number n is at least as large
as n, and is non-negative. The sum of a non-negative real n and a negative real m
has an absolute value which is less than or equal to either n or the reverse of m.
The sum of n and the absolute value of m is at least as large as n. The absolute
value of n + m is no larger than the sum of the absolute value of m and the absolute
value of n. The absolute value of the product of n and m equals the product of
the two separate absolute values, and a similar result holds for the quotient. Real
addition and multiplication are commutative and associative, and multiplication is
distributive over addition. The sum of two non-negative reals is non-negative. The
negative of the negative of a real n is n. The unit real is the multiplicative identity,
and the product of any non-zero real with its reciprocal is the unit real. Division of
reals is the inverse of real multiplication. The only real number n for which n and
−n are both non-negative is the real zero. If the sum of two non-negative reals m
and n is zero, then both m and n are zero. If n is greater than n and k is positive,
all being reals, then the product of n and k is greater than the product of m and
k. The reciprocal of a positive real is positive. The average of two reals n and m
lies between n and m. There is one and only one non-negative square root of a non-
negative real. If both m and n are non-negative reals, the square root of their product
is the product of their separate square roots.
Theorem : (N ∈R) →

|N| ∈R &

|N| >R N ∨|N| = N

&

|N| >R 0R ∨|N| = 0R

Theorem :

N ∈R & M ∈R & Is_nonnegR(N) &

¬Is_nonnegR(M)

→

N >R |N +R M| ∨N = |N +R M| ∨−R(M) >R |N +R M|∨
−R(M) = |N +R M|

Theorem : (N ∈R & M ∈R) →

N +R |M| >R N ∨N +R |M| = N


5.10
Real Numbers
299
Theorem : (N ∈R & M ∈R) →

|N| +R |M| >R |N +R M| ∨|N| +R |M| = |N +R M|

Theorem : (N ∈R & M ∈R) →

|N| +R |M| >R |N −R M| ∨|N| +R |M| = |N −R M|

Theorem : (N ∈R & M ∈R) →

|N| ∗R |M| = |N ∗R M|

Theorem : (N ∈R & M ∈R & M ̸= 0R) →

|N|/R |M| = |N/R M|

Theorem : (K ∈R & N ∈R & M ∈R) →

N +R (M +R K) = (N +R M) +R K

Theorem : (N ∈R) →−R

−R(N)

= N
Theorem : (K ∈R & N ∈R & M ∈R) →

N ∗R (M ∗R K) = (N ∗R M) ∗R K

Theorem : (K ∈R & N ∈R & M ∈R) →

N ∗R (M +R K) = (N ∗R M) +R (N ∗R K)

Theorem :

X ∈R & Y ∈R & Is_nonnegR(X) & Is_nonnegR(Y)

→

Is_nonnegR(X +R Y) & Is_nonnegR(X ∗R Y)

Theorem : (M ∈R) →(M = M ∗R 1R)
Theorem : (M ∈R & M ̸= 0R) →

RecipR(M) ∈R & M ∗R RecipR(M) = 1R

Theorem : (N ∈R & M ∈R & M ̸= 0R) →

N = M ∗R (N/R M)

Theorem : (X ∈R) →

Is_nonnegR(X) ∨Is_nonnegR

−R(X)

&

Is_nonnegR(X) & Is_nonnegR

−R(X)

→(X = 0R)

Theorem : (X ∈R) →(X = X ∗R 1R)
Theorem :

X ∈R & Y ∈R & Is_nonnegR(X) & Is_nonnegR(Y)
& X +R Y = 0R

→(X = 0R & Y = 0R)
Theorem : (X ∈R & Y ∈R & X′ ∈R & X >R Y & X′ >R 0R) →
(X ∗R X′ >R Y ∗R X′)
Theorem : (X ∈R & X >R 0R) →

Recip(X) >R 0R


300
5
A Closer Examination of the Sequence of Deﬁnitions and Theorems
Theorem : [The average of two real numbers lies between them]
(X ∈R & Y ∈R & X >R Y) →

X >R (X +R Y)/R (1R +R 1R) & (X +R Y)/R (1R +R 1R) >R Y

Theorem :

X ∈R & Is_nonnegR(X)

→
√
X ∈R & Is_nonnegR
√
X

&
√
X ∗R
√
X = X

Theorem :

X ∈R & Y ∈R & Y ∗R Y = X & Is_nonnegR(Y)

→

Y =
√
X

Theorem :

X ∈R & Is_nonnegR(X) & Y ∈R & Is_nonnegR(Y)

→
√X ∗R Y =
√
X ∗R
√
Y

5.11 Complex Numbers
This completes the elementary part of our work with real numbers. Since one of our
main goals is to state and prove the Cauchy integral theorem, we must also deﬁne
the complex numbers and prove their basic properties. This is done in the entirely
standard way, which traces back to Gauss. Complex numbers are deﬁned as pairs of
real numbers. They are added componentwise, and multiplied in a manner reﬂecting
the desire to make [0, 1] a square root of −1. The norm of a complex number is its
length as a two-dimensional vector. The reciprocal of a complex number is obtained
by reversing its second component and then dividing both components of the result
by the square of its norm. The quotient of two complex numbers is the ﬁrst times the
reciprocal of the second. The zero complex number is the pair whose components
are both the zero real. The unit complex number has the unit real number as its ﬁrst
component.
Def 58 : [Complex numbers] C =Def R×R
Def 59 : [Complex sum] x +C y =Def

x[1] +R y[1], x[2] +R y[2]
Def 60 : [Complex product] x ∗C y =Def

x[1] ∗R y[1]
−R

x[2] ∗R y[2]
,

x[1] ∗R y[2]
+R

x[2] ∗R y[1]
Def 61 : [Complex norm] |x|C =Def

x[1] ∗R x[1]
+R

x[2] ∗R x[2]
Def 62 : [Complex reciprocal] RecipC(x) =Def

x[1]/R

|x|C ∗R |x|C

, −R

x[2]/R

|x|C ∗R |x|C

Def 63 : [Complex quotient] x/C y =Def x ∗C RecipC(y)

5.11
Complex Numbers
301
Def 63a : −C(x) =Def

−R

x[1]
, −R

x[2]
Def 63b : n −C m =Def n +C −C(m)
Def 63x : 0C =Def [0R, 0R]
Def 63y : 1C =Def [1R, 0R]
The basic elementary properties of the complex numbers are now established by
a series of elementary algebraic proofs. Any pair of reals is a complex number and
vice versa. The complex sum and product of any two complex numbers is a com-
plex number. The zero complex number is the additive identity, and the unit complex
number is the multiplicative identity. The negative of a complex number is its addi-
tive inverse. Complex addition and multiplication are commutative and associative;
multiplication is distributive over addition. The norm of any complex number is a
non-negative real number. The negative of a complex number z has the same norm
as z. The norm of a complex product is the product of the separate norms. The norm
of a complex quotient is the quotient of the separate norms. Any non-zero complex
number has a multiplicative inverse, the inverse of multiplication being given by the
complex division operator, which is easily deﬁned using the complex reciprocal.
Theorem :

(X ∈R & Y ∈R) →

[X, Y] ∈C

&

(M ∈C) →

M =

M[1], M[2]
& M[1] ∈R & M[2] ∈R

Theorem : (N ∈C & M ∈C) →(N +C M ∈C)
Theorem : (N ∈C & M ∈C) →(N +C M = M +C N)
Theorem : (N ∈C) →(N = N +C 0C)
Theorem : (N ∈C) →

−C(N) ∈C & −C

−C(N)

= N

Theorem : (N ∈C) →

N +C −C(N) = 0C

Theorem : (N ∈C & M ∈C) →

N = M +C (N −C M)

Theorem : (N ∈C & M ∈C) →(N ∗C M = M ∗C N)
Theorem : (N ∈C) →

|N|C ∈R & Is_nonnegR

|N|C

Theorem : (N ∈C) →

|N|C = |−C(N)|C

Theorem : (N ∈C & M ∈C) →

|N|C +C |M|C

>R |N +C M|C ∨

|N|C +C |M|C = |N +C M|C


302
5
A Closer Examination of the Sequence of Deﬁnitions and Theorems
Theorem : (N ∈C & M ∈C) →

|N|C ∗C |M|C = |N ∗C M|C

Theorem : (N ∈C & M ∈C & M ̸= 0C) →

|N|C/R |M|C = |N/C M|C

Theorem : (N ∈C & M ∈C) →(N ∗C M ∈C)
Theorem : (K ∈C & N ∈C & M ∈C) →

N +C (M +C K) = (N +C M) +C K

Theorem : (K ∈C & N ∈C & M ∈C) →

N ∗C (M ∗C K) = (N ∗C M) ∗C K

Theorem : (K ∈C & N ∈C & M ∈C) →

N ∗C (M +C K) = (N ∗C M) +C (N ∗C K)

Theorem : (M ∈C) →(M = M ∗C 1C)
Theorem : (M ∈C & M ̸= 0C) →

RecipC(M) ∈C & M ∗C RecipC(M) = 1C

Theorem : (N ∈C & M ∈C & M ̸= 0C) →

N = M ∗C (N/C M)

Theorem : 0C ∈C & 1C ∈C
5.12 Functions of Real and Complex Variables
Now we take our ﬁrst steps into analysis proper, i.e. take up the theory of functions
of real and complex variables. The set RF of real functions is deﬁned as the set of
all single-valued functions whose domain is the set R of all real numbers and whose
range is a subset of R. The zero function is that element of RF all of whose values
are zero. Functions in RF are added and multiplied pointwise, reversed pointwise,
and compared pointwise. The least upper bound of any set of functions in RF is
formed by taking the least upper bound of the function values at each point.5 The
positive part of a real function is formed by taking its pointwise maximum with the
identically zero real function.
5Let the view of real numbers as Dedekind cuts momentarily surface again. To be consistent with
the approach that sees reals as equivalence classes of rational Cauchy sequences, in the formal
speciﬁcation given below we should apply an ad hoc ‘least upper bound’ operation (rather than the
union operation) to a set of reals. Sloppiness on this point gives us the opportunity to signal a little
advantage of the approach based on Dedekind cuts, which can represent the l.u.b. operation, −∞,
and +∞by 	, ∅, and Q, respectively.

5.12
Functions of Real and Complex Variables
303
Def 64 : [Real functions of a real variable] RF =Def

f ⊆(R×R)| Svm(f ) & domain(f ) = R

Def 66 : [Sum of real functions] f +RF g =Def

x, f [x] +R g[x]

: x ∈R

Def 67 : [Product of real functions] f ∗RF g =Def

x, f [x] ∗R g[x]

: x ∈R

Def 68 : [LUB of a set of real functions] LUB(s) =Def

x, 	
f [x]: f ∈s

: x ∈R

Def 69 : [Constant zero function] 0RF =Def

[x, 0R]: x ∈R

Def 70 : [Comparison of real functions] f >RF g ↔Def
f ̸= g &

∀x ∈R| f [x] ⊇g[x]

Def 71 : [Positive part of real function] PosPart(f ) =Def

x, if f [x] ⩾R 0R then f [x] else 0R end if

: x ∈R

Def 72 : [Reverse of a real function] −RF(f ) =Def

x, −R

f [x]

: x ∈R

The most elementary properties of real functions follow directly and trivially
from these deﬁnitions. Addition and multiplication of real functions are commuta-
tive and associative; multiplication of such functions is distributive over addition.
Theorem : (N ∈RF & M ∈RF) →(N +RF M = M +RF N)
Theorem : (N ∈RF & M ∈RF) →(N +RF M = M +RF N)
Theorem : (N ∈RF & M ∈RF) →(N ∗RF M = M ∗RF N)
Theorem : (K ∈RF & N ∈RF & M ∈RF) →

N +RF (M +RF K) = (N +RF M) +RF K

Theorem : (K ∈RF & N ∈RF & M ∈RF) →

N ∗RF (M +RF K) = (N ∗RF M) +RF (N ∗RF K)

Theorem : (K ∈RF & N ∈RF & M ∈RF) →

N ∗RF (M ∗RF K) = (N ∗RF M) ∗RF K

Theorem : (K ∈RF & N ∈RF & M ∈RF) →

N ∗RF (M +RF K) = (N ∗RF M) +RF (N ∗RF K)

To progress to less trivial results in real analysis we need to deﬁne various basic
notions of summation and convergence. In order to arrive at our target, the Cauchy
integral theorem, with minimal delay, we ruthlessly omit all results not lying along

304
5
A Closer Examination of the Sequence of Deﬁnitions and Theorems
the direct path to this target, even though inclusion of many of these results would
usefully illuminate the lines of thought that enter into the deﬁnitions, theorems,
and proofs we are compelled to include. This may lead the reader not previously
familiar with analysis to feel that we are giving many bones with little meat. For a
fuller account of the historical and technical background of the results from analysis
presented in this book, any introductory account of real and complex function theory
can be consulted. Among these we note [Bri97]; also the older classic [Lan66].
The sum of the values of any real-valued mapping having a ﬁnite domain is de-
ﬁned by specializing the general ‘Theory of Sigma’ described above to this general
case. We can then deﬁne the sum of a convergent series of positive real values (on
any domain) as the least upper bound of all its ﬁnite sub-sums. (Note, however,
that it can easily be shown that this value will only be a ﬁnite real if no more than
a countable number of the function values are non-zero.) By further specializing
the ‘Theory of Sigma’ using real function addition rather than real addition we can
deﬁne the notion of sum for ﬁnite series of real functions, and then by taking least
upper bounds we can deﬁne the sum of a convergent series of positive real functions.
Def_by_app 73 : [Sums for real maps with ﬁnite domains]

Svm(F) & range(F) ⊆R & Finite(F)

→
(F) ∈R

&

(P ∈F) →

{P}

= P [2]
&
(F) =
(F|A) +R
(F|domain(F)\A)

Def 73b : [Sums of absolutely convergent inﬁnite series of positive values]
∞(F) =Def
	(F|s): s ⊆domain(F)| Finite(s)

Def_by_app 74 : [Sums for series of real functions]

Svm(Ser) & range(Ser) ⊆RF & Finite(Ser)

→

F(Ser) ∈RF

&

(P ∈Ser) →

F

{P}

= P [2]
&

F(Ser) =

F(Ser|A) +RF

F(Ser|domain(Ser)\A)

Def 75 : [Sums of absolutely convergent inﬁnite series of real functions]
∞
F (Ser) =Def LUB

F(Ser|s): s ⊆domain(Ser)| Finite(s)

It is now easy to give the basic deﬁnitions of the theory of integration of real
functions. We ﬁrst deﬁne the notion of a ‘block function’. This is simply a func-
tion of a real variable which is zero everywhere outside a bounded interval of reals,
and constant inside this interval. We introduce a name for the set of all such func-
tions. The ‘integral’ of any such function is the length of the interval on which it is
non-zero, times its value. The Lebesgue ‘upper integral’ of any positive real-valued
function f of a real number is the greatest lower bound of all sums of integrals of
countable sequences fi of positive block functions for which the pointwise sum of
the sequence of values fi[x] is at least as large as f [x] for each real x. (It is easily
seen that this value depends only on the positive part of f .) The (Lebesgue) integral
of any real function f is the upper integral of f minus the upper integral of the
negative of f . The key result at which these deﬁnitions hint (but, of course, do not

5.12
Functions of Real and Complex Variables
305
prove) is that this integral is additive for a very wide class of functions, and that if a
sequence gn of functions in this class converges (in an appropriate sense) to a limit
function g, then the integrals of the gn converge to the integral of g.
Def 76 : [Block function] Bl_f(A,B,C) =Def

[x, if x ⩾R A & B ⩾R x then C else 0R end if ]: x ∈R

Def 77 : [Block function integral] BFInt(F) =Def
arb

c ∗R (b −R a): a ∈R, b ∈R, c ∈R| Bl_f(a,b,c) = F

Def 78 : [Block functions] RBF =Def

Bl_f(a,b,c): a ∈R, b ∈R, c ∈R

Def 79 : [Product of a non-empty family of sets] GLB(S) =Def

x : x ∈arb(S)| (∀y ∈S | x ∈y)

Note that this last deﬁnition describes the product of an arbitrary collection s of
sets; this is the set of all members of any chosen member of s which belong to all
the other members of s.
Def 80 : [Lebesgue Upper Integral of a Positive Function]
 +(F) =Def
GLB

n, BFInt

ser[n]

: n ∈N

: ser ⊆N×RBF|
Svm(ser) &
∞
F (ser) >RF F

Def 81 : [Lebesgue Integral]

(F) =Def
 +
PosPart(F)

−R
 +
PosPart

−RF(F)

We also need to develop some of the results concerning continuity and differen-
tiability which lie at the traditional heart of analysis. We begin by giving the standard
‘epsilon-delta’ deﬁnition of continuity: a single-valued, real-valued function f of a
real variable is continuous if for each x in its domain, and each positive real value
ε, there exists some real value δ such that the absolute value of the real difference
f [x] −f [y] is less than ε whenever y belongs to the domain of f and the absolute
value of the real difference x −y is less than δ. Since for later use we will need to
generalize notions like this to the multivariable case, we also deﬁne the notion of
Euclidean n-space (namely as the collection of all real-valued sequences of length
n, i.e. the set of all real-valued functions deﬁned on the integer n), and the standard
norm, i.e. vector length in this space, which is the square root of the sum of squares
of the components of a vector (i.e. the values of the corresponding function). We
also need the notion of the (componentwise) difference of two n-dimensional vec-
tors, which we deﬁne as the pointwise difference of the functions corresponding
to these vectors. This lets us extend the ‘epsilon-delta’ deﬁnition of continuity from
real functions of real variables to vector-valued functions of vector-valued variables,
and also real-valued functions of vector-valued variables. A vector-valued function
f of a vector-valued argument x is continuous if for each x in its domain, and each
positive real value ε, there exists some real value δ such that the norm of the vector
difference f [x] −f [y] is less than ε whenever y belongs to the domain of f and

306
5
A Closer Examination of the Sequence of Deﬁnitions and Theorems
the norm of the vector difference x −y is less than δ. The deﬁnition of continuity
for real-valued functions of vector-valued variables is similar.
Def 82 : [Continuous function of a real variable] Is_continuous_RF(F) ↔Def
F ⊆(R×R) & Svm(F) &

∀x ∈domain(F)
 
∀ε ∈R
 
∃δ ∈R
 
∀y ∈domain(F)| δ >R 0R &

ε >R 0R & δ >R |x −R y|

→

ε >R
F[x] −R F[y]

Def 83 : [Euclidean n-space] E(N) =Def

f ⊆(N×R)| Svm(f ) & domain(f ) = N

Def 84 : [Euclidean norm] ∥F∥=Def
(F)
Def 85 : [Difference of real functions] F −RF G =Def

x, F[x] −R G[x]

: x ∈domain(F)

Def 86 : [Continuous vector-valued function on Euclidean n-space]
Is_continuous_REnF(F,M,N) ↔Def F ⊆

E(M)×E(N)

& Svm(F) &

∀x ∈domain(F)|

∀ε ∈R|

∃δ ∈R|

∀y ∈domain(F)|
δ >R 0R &

ε >R 0R & δ >R ∥x −RF y∥

→

ε >R
F[x] −RF F[y]

Def 86a : [Continuous real-valued function on Euclidean n-space]
Is_continuous_REnF(F,N) ↔Def F ⊆

E(N)×R

& Svm(F) &

∀x ∈domain(F)
 
∀ε ∈R|

∃δ ∈R
 
∀y ∈domain(F)|
δ >R 0R &

ε >R 0R & δ >R ∥x −RF y∥

→

ε >R
F[x] −R F[y]

Our next aim is to deﬁne the notion of derivative in some convenient way. We
do this by considering pairs of real-valued functions f , df of a real variable x, and
forming the function g of two real variables x and y which equals the difference-
quotient (f [x]−f [y])/(x −y) if x and y are different, but df[x] if x = y. Then f is
said to be (continuously) differentiable in its domain D if there exists some continu-
ous function df having the same domain such that the function g, formed in this way,
is continuous on the product set of D with itself. It is easily seen that if f is differen-
tiable there can exist only one df which makes g continuous, allowing us to speak of
the derivative of f if f has a derivative. It is also easy to see that if two functions f
and h of a real variable have derivatives df and dh, respectively, then so do their sum
and product, and that the derivative of the sum is df + dh, while the derivative of the
product is df ∗h + f ∗dh. (However, we do not give the proofs of these results.)
Def 87 : [Difference-and-diagonal trick] DD(F,Df) =Def

if x[0] ̸= x[1] then

F

x[0]

−R F

x[1]

/R

x[0] −R x[1]

else Df

x[0]

end if : x ∈E(2)


5.12
Functions of Real and Complex Variables
307
Def 88 : [Derivative of function of a real variable] Der(F) =Def
arb

df ∈RF| domain(F) = domain(df) &
Is_continuous_REnF

DD(F,df)|domain(F)×domain(F),2

Next we extend the preceding notions to complex functions of a complex variable
(i.e. single-valued functions deﬁned on the set of complex numbers whose range is
included in the set of complex numbers), and to complex-valued functions on com-
plex Euclidean n-space. This space is deﬁned as the collection of all real-valued
sequences of length n, i.e. the set of all complex-valued functions deﬁned on the
integer n, and the difference of vectors is deﬁned as the pointwise difference of
the corresponding functions. The norm for such vectors is deﬁned as the sum of
the squares of the absolute values of their (complex) components. Using this sim-
ple deﬁnition of norm, the standard ‘epsilon-delta’ deﬁnition of continuity extends
readily to the complex case.
Def 89 : [Complex functions of a complex variable] CF =Def

f ⊆(C×C)| Svm(f ) & domain(f ) = C

Def 90 : [Complex Euclidean n-space] EC(N) =Def

f ⊆(N×C)| Svm(f ) & domain(f ) = N

Def 91 : [Complex Euclidean norm] ∥F∥C =Def

m,
F[m]

C ∗R
F[m]

C

: m ∈domain(F)

Def 92 : [Difference of complex functions] F −CF G =Def

x, F[x] −C G[x]

: x ∈C

Def 93 : [Continuous function of a complex variable] Is_continuous_CF(F) ↔Def
F ⊆(C×C) & Svm(F) &

∀x ∈domain(F)
 
∀ε ∈R
 
∃δ ∈R
 
∀y ∈domain(F)|
δ >R 0R &

ε >R 0R & δ >R |x −C y|C

→

ε >R
F[x] −C F[y]

C

Def 94 : [Continuous complex-valued function on complex Euclidean n-space]
Is_continuous_CEnF(F,N) ↔Def
F ⊆

EC(N)×C

& Svm(F) &

∀x ∈domain(F)
 
∀ε ∈R
 
∃δ ∈R
 
∀y ∈domain(F)|
δ >R 0R &

ε >R 0R & δ >R ∥x −CF y∥C

→

ε >R
F[x] −C F[y]

C

It is now easy to extend the ‘difference-and-diagonal trick’ used to deﬁne the
derivative of real-valued functions of a real variable to the complex case. Again
we consider pairs of functions f , df , this time complex-valued functions of a com-
plex variable x, and form the function g of two complex variables x and y which
equals the difference-quotient (f [x] −f [y])/(x −y) if x and y are different, but

308
5
A Closer Examination of the Sequence of Deﬁnitions and Theorems
df[x] if x = y. Then f is said to be (continuously) differentiable in its domain
D if there exists some continuous function df having the same domain as f such
that the function g, formed in this way, is continuous on the product set of D with
itself.
Def 95 : [Difference-and-diagonal trick, complex case] CDD(F,Df) =Def

if x[0] ̸= x[1] then

F

x[0]

−C F

x[1]

/C

x[0] −C x[1]

else Df

x[0]

end if : x ∈EC(2)

Def 96 : [Derivative of function of a complex variable] CDer(F) =Def
arb

df ∈CF| domain(F) = domain(df) &
Is_continuous_CEnF

CDD(F,df)|domain(F)×domain(F),2

It has been known since the 1821 work of Cauchy that the consequences of differ-
entiability for complex functions of a complex variable (deﬁned in an open subset of
the complex plane) are much stronger than the corresponding assumption in the real
case, a fact for which our target theorem, the Cauchy integral theorem, is central.
Here a subset of the complex plane is said to be open if it contains some sufﬁciently
small disk around each point of its domain. Functions of a complex variable dif-
ferentiable in an open set are said to be analytic functions of the complex variable.
One such function, of particular importance, is the complex exponential function,
which can be deﬁned as the unique analytic function exp having the entire com-
plex plane as its domain which is equal to its own derivative and takes on the unit
complex value at the zero point of the complex plane. The two mathematical con-
stants e and π can both be deﬁned in terms of this function, in the following way:
e is the value which exp takes on at the point [1R, 0R] of the complex plane, and
π is the smallest real positive x for which exp([0R, x]) is −R(1R). That is, we
deﬁne π as the smallest positive root of Euler’s famous, indeed ineffable, formula
ei∗π = −1.
Def 97 : [Open set in the complex plane] Is_open_C_set(S) ↔Def

∀z ∈S
 
∃ε ∈R
 
ε >R 0R &

∀w ∈S
 
ε >R |z −C w|C

→(w ∈S)

Def 98 : [Analytic function of a complex variable] Is_analytic_CF(F) ↔Def
Is_continuous_CF(F) & Is_open_C_set

domain(F)

& CDer(F) ̸= 0
Def 99 : [Complex exponential function] C_exp_fcn =Def
arb

F ⊆C×C: domain(F) = C & Is_analytic_CF(F) & CDer(F) = F &
F

[0R, 0R]

= [1R, 0R]

Def 100 : [The constant π] π =Def
arb

x ∈R| x >R 0R & C_exp_fcn

[0R, x]

=

−R(1R), 0R

&

∀y ∈R
 
C_exp_fcn

[0R, y]

=

−R(1R), 0R

→(0R >R y ∨y ⩾R x)


5.12
Functions of Real and Complex Variables
309
To move on to the statement, and eventually the proof, of Cauchy’s integral the-
orem we must deﬁne the notion of ‘complex line integral’ involved in that the-
orem. For this, we need various slight modiﬁcations of the foregoing material,
and in particular the notions of continuity and differentiability for complex-valued
functions of a real variable. These involve the following easy modiﬁcations of the
‘epsilon-delta’ deﬁnition and the difference-and-diagonal trick described above. A
(‘closed’) real interval is the set of all points lying between two real values (includ-
ing these values themselves). A continuously differentiable curve in the complex
plane is a continuous complex-valued function deﬁned on an interval of the real
line which is continuously differentiable on its domain. The complex line integral
of a complex-valued function f deﬁned on such a curve is deﬁned by taking the
complex product of f by the derivative of the curve, integrating the real part (i.e.
pointwise ﬁrst component) and the imaginary part (pointwise second component)
of the resulting product function, and rejoining these two values into a complex
number.
Def 101 : [Continuous complex function on the reals] Is_continuous_CoRF(F)
↔Def F ⊆(R×C) & Svm(F) &

∀x ∈domain(F)
 
∀ε ∈R
 
∃δ ∈R
 
∀y ∈domain(F)|

(δ >R 0R) & (ε >R 0R) & δ >R |x −R y|

→

ε >R
F[x] −C F[y]

C

Def 102 : [Difference-and-diagonal trick, real-to-complex case] CRDD(F,Df) =Def

if x[0] ̸= x[1] then

F

x[0]

−C F

x[1]

/C

x[0] −C x[1]

else Df

x[0]

end if : x ∈E(2)

Def 103 : [Continuous complex function on E(n)] Is_continuous_CREnF(F,N)
↔Def F ⊆(E(N)×C) & Svm(F) &

∀x ∈domain(F)
 
∀ε ∈R
 
∃δ ∈R
 
∀y ∈domain(F)|

(δ >R 0R) & (ε >R 0R) &

δ >R ∥x −RF y∥

→

ε >R
F[x] −CF F[y]

C

Def 104 : [Derivative of complex function of a real variable] CRDer(F) =Def
arb

df ∈CF| domain(F) = domain(df) &
Is_continuous_CREnF

CRDD(F,df)|domain(F)×domain(F),2

Def 105 : [Real Interval] Interval(A,B) =Def {x ∈R| x ⩾R A & B >R x }
Def 106 : [Continuously differentiable curve in the complex plane]
Is_CD_curv(F,A,B)
↔Def Is_continuous_CoRF(F) & domain(F) = Interval(A,B) &
Is_continuous_CoRF

CRDer(F)


310
5
A Closer Examination of the Sequence of Deﬁnitions and Theorems
Def 107 : [Complex line integral]
 B
A (F,Crv) =Def
 
x, if x /∈Interval(A,B)

then 0R else

F

Crv[x]

∗C CRDer(Crv)[x]
[1] : x ∈R

,
 
x, if x /∈Interval(A,B)

then 0R else

F

Crv[x]

∗C CRDer(Crv)[x]
[2] : x ∈R

Now ﬁnally we can state the Cauchy integral theorem and the Cauchy integral
formula derived from it. The Cauchy integral formula states that if f is an analytic
function deﬁned in some open subset of the complex plane, and if c1 and c2 are
two continuously differentiable closed curves (i.e. curves which end where they
start), both having ranges in s, and if each of the values of c1 differs sufﬁciently
little from the corresponding value of c2, then the two line integrals of f over the
two curves must be equal. This is proved by deforming the ﬁrst curve smoothly
into the second, and proving that the derivative of the resulting line integral in the
deformation parameter must be zero: a function of a real parameter whose derivative
is zero in an interval must be constant in that interval.
To avoid topological complications we state the Cauchy integral formula, which
follows from the Cauchy integral theorem, in a somewhat special case: If f is a
function analytic in an open set including the closed unit circle of the complex
plane, and z is any point interior to that circle, then the line integral of the quotient
f [w]/(2 ∗π) ∗(w −z) over the unit circle is always f [z]. Note that in the formal
statement of this theorem given below, the unit circle is represented by the curve
w = C_exp_fcn([0R, x]), where the real parameter value x varies between 0 and
2 ∗π. Though we do not follow up on its possible generalizations, Cauchy integral
formula can be stated much more generally: it is true whenever f is analytic in a
domain of any shape including the whole of any smooth closed complex curve in
the complex plane and its interior, provided that w is a point interior to the curve
about which the curve winds just once. But to state and prove the Cauchy integral
formula in this generalized form we would need to develop the theory of winding
numbers, which would extend the present work beyond its appointed length.
Theorem : [Cauchy integral theorem]
Is_analyticCF(F) →

∃ε ∈R| ε >R 0R &

∀crv1, crv2 |
Is_CD_curv(crv1, 0R, 1R) & Is_CD_curv(crv2, 0R, 1R) &
crv1[0R] = crv1[1R] & crv2[0R] = crv2[1R] &

∀x ∈Interval(0R, 1R)| ε ⩾R
crv1[x] −C crv2[x]

C

→
 1R
0R (F,crv1) =
 1R
0R (F,crv2)

Theorem : [Cauchy integral formula]

Is_analyticCF(F) & domain(F) ⊇

z ∈C: 1R ⩾R |z|C
 
→

∀z ∈C
 
1R >R |z|C

→F[z] =
 π+Rπ
0R

x, F[x]/C (x −C z)

: x ∈C \ {z}

,

x, C_exp_fcn

[0R, x]

: x ∈R


References
311
References
[Bri97]
Bridges, D.S.: Foundations of Real and Abstract Analysis. Graduate Texts in Mathemat-
ics, vol. 174. Springer, Berlin (1997)
[Can72] Cantor, G.: Über die Ausdehnung eines Satzes aus der Theorie der trigonometrischen
Reihen. Math. Ann. 5, 123–132 (1872)
[Lan66] Landau, E.: Foundation of Analysis. The Arithmetic of Whole, Rational, Irrational and
Complex Numbers, 3rd edn. Chelsea, New York (1966)
[OS02]
Omodeo, E.G., Schwartz, J.T.: A ‘Theory’ mechanism for a proof-veriﬁer based on ﬁrst-
order set theory. In: Kakas, A., Sadri, F. (eds.) Computational Logic: Logic Program-
ming and Beyond—Essays in honour of Bob Kowalski, Part II, vol. 2408, pp. 214–230.
Springer, Berlin (2002)
[Tar24]
Tarski, A.: Sur les ensembles ﬁni. Fundam. Math. VI, 45–95 (1924)


Chapter 6
Undecidability and Unsolvability
For completeness sake and to enjoy the intellectual insight that these results provide,
we derive several of the main classical results on undecidability and unsolvability
in this chapter.
6.1 Chaitin’s Theorem
Some of the most famous results concerning undecidability and unsolvability are
easy to prove using an elegant line of argument due to Gregory Chaitin. Deﬁne the
information content I(s) of a binary sequence s as the length (measured, like s, in
bits) of the shortest program P which prints s and then stops. P should be written
in some agreed-upon programming language L. We will see below that changing L
to some other language L′ leaves I(s) unchanged except for addition of a quantity
bounded by a constant C(L,L′) depending only on the languages L and L′. Thus,
asymptotically speaking, I(s) is independent of L.
Let |s| designate the length of the binary sequence s. Then, since s can always
be printed by the program ‘print(s)’ (in which s appears as an explicit constant),
it is clear that I(s) must be bounded above by |s| + C, where C depends only on
the programming language L being used. Of course, this upper bound is sometimes
far too large, since there are sequences s whose information content is much less
than their length. For example, the information content of the decimal sequence
consisting of the digit 1 followed by one trillion zeros is not much larger than that
of its deﬁning expression 101024, whose binary form is only a few dozen bits long.
On the other hand, a simple counting argument shows that most sequences of length
n must have an information content close to n. Indeed, the number of programs
representable by binary sequences of length at most n −c is less than 2n−c+1, and
not all of these programs print anything or stop, so the number of binary sequences
of information content at most n −c (i.e. the set of outputs of all these programs)
is less than 2n−c+1. But, since the number of sequences of length n is 2n, it follows
immediately that the fraction of these sequences having information content no more
J.T. Schwartz et al., Computational Logic and Set Theory,
DOI 10.1007/978-0-85729-808-9_6, © Springer-Verlag London Limited 2011
313

314
6
Undecidability and Unsolvability
than n −c is at most 2−c+1. For c large enough this fraction will be very small, so
most binary sequences of length n must have a larger information content.
Chaitin’s theorem can now be stated as follows.
Theorem 6.1 If A is any consistent set of axioms for mathematics, then there is
a constant c = c(A), depending only on A (and, indeed, only on the information
content of A), such that no statement of the form I(s) > c can be proved using only
the axioms A.
Proof The proof is deliciously simple. For any constant k, let P(k) be the program
which
1. Generates all possible sequences of formulae, in order of increasing length.
2. Checks these sequences to verify that their component formulae are syntactically
well-formed and that each formula in the sequence follows directly (in terms of
the rules of logical inference available) from the formulae which precede it. Se-
quences not having this property should immediately be dropped, and P should
go on to examine the next sequence in turn.
(As we have already emphasized, it is inherent in the very deﬁnition of formal
logic that there must exist procedures for testing the well-formedness of formu-
lae, and for determining whether one formula is an immediate consequence of
others, since otherwise the logical system used would not meet Leibniz’ funda-
mental criterion that arguments in it must be ‘safe and really analytic’.)
3. Checks the ﬁnal formula in each surviving sequence (this is the ‘theorem
proved’) to determine whether it has the form ‘I(s) > k’. If so, it prints s and
stops. If not, it goes on to examine the next sequence in turn.
Observe that the length of the program P(k) equals L + logk, for a suitable
constant L, if we assume that a binary encoding of k occurs in P(k). Let c be any
constant such that c > L + logc.
If there exists any proof of a statement of the form ‘I(s) > c’ then plainly the
procedure P(c) will eventually ﬁnd a statement of this form, along with its proof.
But then our program, whose length is less than c, prints a sequence s whose in-
formation content is provably greater than c, so that s cannot be printed by any
program of length at most c. Our logical system is therefore inconsistent, contrary
to assumption.
□
The following variant of Chaitin’s theorem can be proved in much the same way.
Theorem 6.2 There exists no program R which can determine the information con-
tent I(s) of an arbitrary binary sequence s.
Proof Suppose that R exists, and write the program P which
1. generates all binary sequences s, in order of increasing length;
2. uses R to determine their information content;

6.1
Chaitin’s Theorem
315
3. stops when this content is seen to be large, say one million, and prints the se-
quence s; otherwise continues.
Since there are sequences of information content at least one million, P will
eventually ﬁnd one such and print it. But then this sequence is printed by the pro-
gram P that we have just described, whose length is clearly much less than one
million bits. Hence we have a contradiction, proving that R cannot exist.
□
To see that the information content I(s) of a binary sequence varies only slightly
when the programming language L used to deﬁne it is changed, we simply argue
as follows. Programs written in any language L can be compiled to run on any
adequate hardware system S. The size of the compiler required depends only on
L, and so can be written as c(L). The instructions of S can be simulated in any
other reasonable programming language L′, and the size of the interpreter required
for this depends only on L′ and can therefore be written as c′(L′). This gives us
a way of transforming any program P of length k and written in the language L
into a program P ′ of length k + c(L) + c′(L′) written in the language L′ which
produces the same results. Note also that P ′ eventually halts if and only if P does.
Hence the minimum-length program in L′ for producing s is of length no greater
than k + c(L) + c′(L′). Since this same argument applies in the reverse direction, it
follows that |I(s) −I ′(s)| is bounded above by a constant.
6.1.1 Undecidability Results Derivable from Chaitin’s Theorem
It is now easy to derive the following results, some directly from Chaitin’s theorem
and the variant of it which we have stated, others by adapting Chaitin’s line of
argument.
Theorem 6.3 (Existence of undecidable statements) Let A be any consistent set of
axioms for mathematics. Then there exists a mathematical formula F which is such
that neither F nor its negation ¬F can be proved using only the axioms A.
Proof Consider the set of all binary sequences s of length c + k whose information
content I(s) exceeds c, where c is the constant c appearing in Chaitin’s theorem and
k will be speciﬁed below. We know by Chaitin’s theorem that none of the formu-
lae I(s) > c involving these sequences s can be proved (even though all are true).
Consider the set of such sequences s for which ‘¬(I(s) > c)’ can be proved (several
such proofs may be possible without inconsistency, even though all these statements
are false). There can be at most 2c+1 such sequences, since we can prove (and in-
deed, have proved) that the total number of sequences of information content less
than c is at most 2c. For all the others, i.e. for all but a fraction 2−k of statements
of the form I(s) > c, neither the statement nor its negative is provable. So all these
statements are undecidable in terms of the axioms A.
□

316
6
Undecidability and Unsolvability
Theorem 6.4 (Turing: Unsolvability of the halting problem) There exists no proce-
dure R which, given the text of a program P , determines whether P eventually halts.
Proof Let s be a binary sequence. Set up the program P which
1. generates all programs Q of length up to the length |s| of s;
2. uses R to determine whether Q eventually halts, and if not immediately elimi-
nates Q;
3. progressively increments an integer number_of_steps, and then runs each of the
remaining programs Q (i.e., under simulation) for number_of_steps, determin-
ing whether it has stopped or not, and if so whether it has printed s;
4. stops immediately once a program which prints s is found; otherwise continues;
5. stops once all the programs Q to be examined have halted.
It is clear from the description of this program that it will eventually halt (since it
simulates only a ﬁnite number of programs, each of which eventually halts). When
P halts it will have determined the information content of s (possibly by showing
that this is at least the length of s). But, by the variant of Chaitin’s theorem proved
above, this is impossible.
□
Theorem 6.5 (Nonexistence of a decision algorithm for elementary arithmetic)
There exists no procedure R which, given a (quantiﬁed) formula of elementary arith-
metic, determines whether or not P is true.
Proof Since programs written in any programming language can be compiled to run
(in assembly language) on any adequate hardware system, it follows from Turing’s
theorem that there exists no procedure which, given some adequate computer sys-
tem S, can determine whether an arbitrary assembly-language program for S stops.
We take S to be a system easily modelled using arithmetic operations only. Specif-
ically, we model the memory M of S as a large positive integer divided into W-bit
‘words’ (so that the jth word of M is extracted by the operation

M/2jW 
mod 2W.
Each of the registers of S, including its ‘instruction location counter’ ILC, is then
modelled by an additional W-bit integer, which we can store at ﬁxed low addresses
in the memory integer M. To simulate one cycle of S’s operation, we simply extract
the instruction word addressed by ILC using the formula just displayed, use a similar
formula to extract the memory words this instruction involves, and calculate the
instruction result, which can always be expressed as a Boolean, and hence algebraic,
combination of the registers it involves. The next value of ILC can be calculated in
the same way for the same reason. To store a W-bit word x into memory location j,
we simply change the integer M into

M −

M mod 2jW 
+ X 2(j−1)W +

M mod 2(j−1)W
.
This makes it plain that the effect of any individual operation of S can be ex-
pressed as an elementary operation on the integers used to represent the states of S.

6.1
Chaitin’s Theorem
317
Hence, if the state of S on its jth cycle is M, then the state of S on its (j + 1)st cy-
cle will be F(M), where F is some elementary arithmetic operation whose details
reﬂect the architectural details of S.
Now suppose that the memory of S is initialized to M0, and start S running. It will
eventually halt iff there exists a sequence of Mi integers satisfying the quantiﬁed but
otherwise elementary arithmetic formula
(i = 0 →Mi = M0) &

∀i | Mi+1 = F(Mi)

&

∃j | H(Mj)

,
where H(M) is the elementary arithmetic predicate which expresses the condition
that the operation executed when S is in state M is the ‘Halt’ instruction. So, if there
existed an algorithm which could decide the truth of all formulae of the kind just
displayed, we could use it to determine whether an arbitrary program P eventually
halts, contradicting Turing’s theorem.
□
Theorem 6.6 (Church: Nonexistence of a decision algorithm for predicate calculus)
There exists no procedure R which, given a (quantiﬁed) sentence of pure predicate
calculus, determines whether or not P is valid, i.e. true irrespective of the meanings
assigned to the constants and function symbols which appear in it.
Proof We can encode the integers (in ‘monadic’ notation) as
0, Succ(0), Succ

Succ(0)

, Succ

Succ

Succ(0)

, ...
In this universe of data objects, every integer except 0 has a predecessor Pred(n)
such that n = Succ(Pred(n)). We can then express all other arithmetic functions
recursively starting only with the constant ‘0’ and the function symbols ‘Succ’ and
‘Pred’, e.g. as
function plus(n,m); return if m = 0 then n
else Succ

plus

n, Pred(m)

end if ; end plus;
function times(n,m); return if m = 0 then 0
else plus

times

n, Pred(m)

,n

end if ; end times;
function exp(n,m); return if m = 0 then Succ(0)
else times

exp

n, Pred(m)

,n

end if ; end exp;
function minus(n,m); return if n = 0 then 0 elseif m = 0 then n
else minus

Pred(n), Pred(m)

end if ; end minus;
function gt(n,m); return minus(n,m) ̸= 0; end gt;
function len_le(n,m); return gt

exp

Succ

Succ(0)

,m

,n

; end len_le;
function div(n,m); return if m = 0 ∨gt(m,n) then 0
else Succ

div

minus(n,m),m

; end div;
function rem(n,m); return minus

n, times

m, div(n,m)

; end rem.

318
6
Undecidability and Unsolvability
Continuing in the same way, we can build up a recursive function
stops_and_outputs(P,m,s)
which is true iff the program P (written in the assembly language of the abstract
computer which appears in the proof of the immediately preceding theorem “Nonex-
istence of a decision algorithm for elementary arithmetic”) halts after m steps, hav-
ing then produced the output s.
Such recursive functions can readily be mirrored in predicate calculus, e.g. by
the quantiﬁed predicate statements

∀n
 
n = 0 ∨Succ

Pred(n)

= n


∀n| Succ(n) ̸= 0

&

∀n,m| Succ(n) = Succ(m) →n = m


∀n,m| Plus(n,0) = n & Plus

n, Succ(m)

= Succ

Plus(n,m)


∀n,m| Times(n,0) = 0 & Times

n, Succ(m)

= Plus

Times(n,m),n


∀n,m| Exp(n,0) = Succ(0) & Exp

n, Succ(m)

= Times

Exp(n,m),n


∀n,m| Minus(0,m) = 0 & Minus(n,0) = n &
Minus

Succ(n), Succ(m)

= Minus(n,m)


∀n,m| Gt(n,m) ↔Minus(n,m) ̸= 0


∀n,m| Len_le(n,m) ↔Gt

Exp

Succ

Succ(0)

,m

,n


∀n,m
 
Gt(n,m) →Div(n,m) = 0

&

¬Gt(n,m)

→
Div(n,m) = Succ

Div

Minus(n,m),m


∀n,m| Rem(n,m) = Minus

n, Times

m,Div(n,m)

and so on, up to the point at which the function stops_and_outputs(P,m,s) is
mirrored by a similar predicate formula. Since predicate substitution of formu-
lae for variables, followed by simpliﬁcation, generalizes the process of recur-
sive evaluation of the procedures listed above, each recursive evaluation translates
immediately into a predicate proof, so that whenever one of our functions, e.g.
stops_and_outputs(P0,m0,s0) evaluates to true for given constant values P0, m0,
s0 there will exist a predicate-calculus proof of the statement
stops_and_outputs(P0,m0,s0).
(This observation appears in Sect. 4.3.10.1 as the ‘Mirroring Lemma’.)
Now choose any sufﬁciently large integer k, and consider the predicate statement

∃P,n| Stops_and_outputs(P,n,s) & Len_le(P,k)
&

¬Len_le

s, Times

Succ(Succ(0)),k

.
Call this formula F . It simply states that the length of s is at least 2k and that the
information content of s is no more than half its length k = (2k)/2. We have seen

6.2
The Two Gödel Theorems
319
at the start of the present section that F can only be true for a small minority N of
all sufﬁciently long sequences. This fact was established by an entirely elementary
counting argument, readily translatable into predicate-calculus terms.
It follows that, given any sufﬁcient large k, the formula F can only be proved
for a small minority of the sequences s0 of length k. Indeed, if F could be proved
for too many individual sequences s0, the count N would be exceeded, and so the
Peano axioms of elementary arithmetic would be self-contradictory within predicate
calculus. Hence for any sufﬁciently large k there will exist many s for which F =
F(s) is not provable.
Now suppose that a procedure R for deciding the provability of predicate-
calculus formulae exists. Using R, construct the program which
1. examines all programs P , and sequences s of length at least k, in order of in-
creasing total length;
2. uses R to determine whether F(s) is provable;
3. stops as soon as it ﬁnds an s such that F(s) is not provable, and prints s.
Since we have seen that there must exist many s such that F(s) is not provable,
this procedure must eventually stop and print some such s. The s which is printed
must have complexity at least k. Indeed, if this were false, there would exist a pro-
gram P0 of length less than k which stopped after some ﬁnite number n0 of steps and
printed s. Hence the value of the recursive functions stops_and_outputs(P0,n0,s),
and len_le(P0,k) would be true, implying, as we have seen above, that
Stops_and_outputs(P0,n0,s) & Len_le(P0,k)
is provable; but we have chosen an s for which this is false.
Hence s has complexity at least k. But it is the output of the short program listed
above. This is a contradiction for all sufﬁciently large k. Hence R cannot exist, and
Church’s theorem follows.
□
6.2 The Two Gödel Theorems
Next we turn to the proof of Gödel’s two famous theorems. These rest upon the
construction of a trick proposition G which asserts its own unprovability, and which
therefore can be regarded as a technically precise rendering of the ancient paradox-
ical sentence ‘This sentence is false’. Note that this sentence is troublesome for any
system of formalized discourse in which it or anything like it can be given meaning,
since it plainly can neither be true nor false.
Gödel’s ﬁrst theorem (in the improved form given to it by Rosser) asserts that
(if we assume that the logical system in which G is being considered is consistent)
neither G nor its negative can be proved; hence G must be undecidable. (This is no
longer as surprising as it was when ﬁrst discovered by Gödel, since theorems like
Chaitin’s show the existence of large classes of undecidable statements.) Gödel’s

320
6
Undecidability and Unsolvability
second theorem uses much the same statement G as an auxiliary to prove that the
logical theory containing G cannot be used to prove its own consistency.
All of Gödel’s reasonings will become easy once we have clariﬁed the founda-
tions on which they rest. Since the line of argument used is somewhat more delicate
than those needed in the preceding sections of this chapter, we begin with a more
careful discussion of technical foundations than was given above. This more detailed
discussion continues to emphasize the basic role of set theory. Note that the prepara-
tory considerations which follow fall naturally into two parts, a ﬁrst ‘programming
part’ which is followed by a short discussion of the relationship of ‘programming’
to ‘proof’.
6.2.1 Programming Considerations
The mechanism of computation with hereditarily ﬁnite sets discussed earlier (cf.
Sect. 4.3.10) can easily be used to deﬁne strings and such basic operations on them
as concatenation, slicing, and substring location. To this end, we use the deﬁnition of
‘sequence of elements of a set s’ given previously. We apply this to deﬁne the notion
of ‘a sequence of decimal digits’, and of the integer value that such a sequence
represents. This is done as follows:
function two(); return

∅, {∅}

; end two;
function four(); return sum

two(), two()

; end four;
function ten(); return sum

sum

two(), four()

, four()

; end ten;
function is_decimal_sequence(s);
return is_sequence_of

s, ten()

;
end is_decimal_sequence;
function decimal_value_of(s);
return if (s = ∅) ∨¬is_decimal_sequence(s) then ∅
else sum

last_of(s), product

ten(),
decimal_value_of

s less ordered_pair

prev(#s), last_of(s)

end if ;
end decimal_value_of.
The standard abbreviations 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 for the ten members of
ten() can now be introduced:
0 = ∅, 1 = next(0), 2 = next(1), 3 = next(2), 4 = next(3), 5 = next(4),...
along with the convention that a sequence d0d1 ...dn of such digit characters desig-
nates the decimal_value_of the decimal sequence

ordered_pair(0,d0), ordered_pair(1,d1),..., ordered_pair(n,dn)

.
(6.1)

6.2
The Two Gödel Theorems
321
We also adopt the ‘ASCII’ convention that a character is simply an integer less
than 256, and a string is simply a sequence of characters. That is,
function is_string(s); return is_sequence_of(s, 256); end is_string.
We also adopt the standard manner of writing strings within double quotes and
the convention that a quoted sequence “d0d1 ...dn” of characters designates the
sequence (6.1). For example, “Abba” designates the sequence

ordered_pair(0,65), ordered_pair(1,98), ordered_pair(2,98),
ordered_pair(3,97)

.
The string concatenation, slicing, and substring location functions now have the
following forms.
function shift(s, n);
return if s = ∅then ∅
else shift

s less arb(s), n

with
ordered_pair

sum

arb(s)[1], n

, arb(s)[2] 
end if ;
end shift;
function concatenate(s1, s2);
return union

s1, shift(s2, #s1)

;
end concatenate;
function slice_starting(s, n);
return if ¬is_sequence(s) then ∅
elseif n ∈#s then
slice_starting

restriction

s, prev(#s)

, n

with
ordered_pair

minus

prev(#s), n

, last_of(s)

else ∅end if ;
end slice_starting
function slice(s, n, m);
return slice_starting

restriction(s, m), n

;
end slice;
function location_in(s1, s2);
return if s1 = ∅then 0
elseif #s2 ∈#s1 then next(#s2 )
elseif slice

s2, 0, prev(#s1)

= s1 then 0
else next

location_in

s1, slice_starting(s2,1)

end if ;
end location_in.
The next two functions, respectively, deﬁne the result of appending an additional
component to each of the elements of a set s of sequences, and the collection of all
ordered subsequences of a sequence s.

322
6
Undecidability and Unsolvability
function append_to_elements(s,x);
return if s = ∅then ∅
else append_to_elements

s less arb(s), x

with
concatenate

arb(s),

ordered_pair(0,x)

end if ;
end append_to_elements;
function subsequences(s);
return if ¬is_sequence(s) then ∅
elseif s =

arb(s)

then {∅, s }
else union

subsequences

restriction

s, prev(#s)

,
append_to_elements

restriction

s, prev(#s)

, last_of(s)

end if ;
end subsequences.
It should be clear that, having arrived at this point, we can go on to deﬁne any
of the more advanced string-manipulation functions familiar from the computer-
science literature, including functions which test a string for well-formedness ac-
cording to any reasonable grammar, functions which detect and list the free vari-
ables of predicate and set-theoretic formulae, and functions which substitute speci-
ﬁed terms for these free variables.
One such function that is needed below is that which tests an arbitrary hereditar-
ily ﬁnite set to determine whether it is a sequence of strings. This is
function is_string_sequence(s);
return if s = ∅then true
elseif ¬is_string

last_of(s)

then false
else is_string_sequence

s less ordered_pair

prev(#s), last_of(s)

end if ;
end is_string.
We will not carry all of this out in detail, but simply note that full programming
details, very close to those alluded to here, form part of the code libraries which
implement the veriﬁer system discussed in Chap. 4. (These are written in the SETL
language of [SDDS86], which is very close to the more restricted set-theoretic lan-
guage considered above.)
One other simple but more specialized string-manipulation function, which we
call subst(s1,s2), will be used below. This is deﬁned in the following way. Un-
less s1 is a syntactically well-formed string of our language, subst(s1,s2) is the
empty string {}. Otherwise the ‘subst’ operator ﬁnds the ﬁrst free variable in s1
and replaces every occurrence of this variable by an occurrence of the string s2. For
example,
subst

“

∀z| F

x,g(x,y),z

”, “Abba”

= “

∀z| F

Abba,g(Abba,y),z

”,
but
subst

“

∀z| F

x,g(x,y),z

”, “Abba”

= {}
since its ﬁrst argument string is syntactically ill-formed.

6.2
The Two Gödel Theorems
323
Note ﬁnally that any other universal form of computation, for example com-
putation with strings or computation with integers, can substitute for the style of
set-theoretic computation we have outlined. This follows from the fact that our set-
theoretic computations can be programmed to run on any standard computer, sim-
ply by encoding all hereditarily ﬁnite sets by bitstrings in any way that supports the
primitive operations listed above and the simple style of recursion that we have as-
sumed. It is even easier to program all the above set-theoretic operations in a string
language. To program them in pure arithmetic, one can simply regard strings as
integers written to base 256.
6.2.2 Programming and Proof; ‘Mirroring’ Programmable
Set-Theoretic Functions
A sequence of strings, every one of which is a syntactically legal formula of the
language of logic, is a proof if every string in it is either an axiom or is derived via
some allowed rule of inference from some ﬁnite subcollection of strings, each of
which appears earlier in the sequence.
This deﬁnition can be applied in very general settings. We need not insist that the
axioms allowed form a ﬁnite collection, but only that it must be possible to program
the function
is_axiom(s)
which tests statements s to see if they are axioms. Similarly, we need not insist on
any particular form for the rules of inference, but must only demand that we can
program the function
last_is_consequence(s)
which tests a ﬁnite sequence of statements to verify that the last component
s(prev(#s)) of the sequence is a valid immediate consequence of the formulae which
precede it in s. We insist that ‘last_is_consequence’ (and ‘is_axiom’) must be pro-
grammable in order to prevent the acceptability of a proof from being a matter of
debate. As a matter of convenience we assume that
is_axiom(x) ↔last_is_consequence

ordered_pair(0,x)

.
Note that, given a procedure for testing ‘last_is_consequence’, the condition that
a sequence of statements should be a proof is unambiguous, since this condition can

324
6
Undecidability and Unsolvability
be tested by calculating the value of the second function shown below.
function follows_from_element(list_of_subsequences, conclusion);
return if list_of_subsequences = ∅then is_axiom(conclusion)
else
last_is_consequence

concatenate

arb(list_of_subsequences),

ordered_pair(0, conclusion)

∨
follows_from_element

list_of_subsequences less
arb(list_of_subsequences), conclusion

end if ;
end follows_from_element;
function is_proof(s);
return if s = ∅∨¬is_string_sequence(s) then false
elseif s =

arb(s)

then is_axiom

s[2]
else
is_proof

s less ordered_pair

prev(#s), last_of(s)

&
follows_from_element

subsequences

s less last_of(s)

, last_of(s)

end if ;
end is_proof.
A string is then a theorem if and only if it is the last element of some sequence
of strings which is a proof.
The preceding deﬁnitions allow us to formulate the notion of ‘logical system’ in
very general ways. But to relate a logical system to a computational system in the
most useful way it is appropriate to impose a few additional conditions. First of all,
we want each of the objects with which we will compute to have a representation
in our logical system. The techniques described in our earlier discussion of compu-
tation with hereditarily ﬁnite sets can be used for this.To be sure that all such sets
can be represented in our language, we can simply agree that some standard string
representation of each such set must count as a syntactically well-formed term of
our language, and that there should be a predicate Is_HF(s) which is true whenever
s is the standardized string representation of such a set. Note that the condition that
a string s is such a representation can easily be tested by a programmable func-
tion. Next, we agree that our system must include an equality predicate having all
the customary properties, and must also include a collection of function symbols
Singleton(s), Arb(s), With(s1,s2), Less(s1,s2) having the indicated number of pa-
rameters. Moreover, every statement of a form like
Singleton(s1) = s2, Arb(s1) = s2, With(s1,s2) = s3, ...,
for which s1, s2, s3, etc., are standard string representations of hereditarily ﬁnite sets
and the corresponding Boolean values {s1} = s2, arb(s1) = s2, etc., are true, must be
an axiom (or theorem). There must also exist a predicate symbol In(s1,s2) of two
variables for which the statement
In(s1,s2)

6.2
The Two Gödel Theorems
325
is an axiom or theorem whenever s1 and s2 are standard string representations of
hereditarily ﬁnite sets and
s1 ∈s2
is true. Similarly, we require that there must exist a predicate symbol Incs(s1,s2) for
which the statement
Incs(s1,s2)
is a theorem whenever s1 and s2 are standard string representations of hereditarily
ﬁnite sets and
s1 ⊇s2
is true.
We also assume that the function Arb satisﬁes

s = ∅& Arb(s) = ∅

∨

In

Arb(s), s

&

∀x | Is_HF(x) →¬

In

x, Arb(s)

& In(x,s)

,
whenever s is the standard representation of a hereditarily ﬁnite set, and that ax-
ioms are at hand allowing us to deduce such elementary set-theoretic statements
as
In

x, Singleton(y)

↔x = y,
In

x, With(s,y)

↔

In(x,s) ∨x = y

,
etc., whenever the variables involved are standard string representations of hered-
itarily ﬁnite sets. Elementary set-theoretic facts of this kind will be used in what
follows, where we will sometimes write predicates like In(x,s) in their more stan-
dard inﬁx form.
We also wish to impose conditions that allow our logical system to imitate
any function deﬁnition legal in the system for computation with hereditarily ﬁnite
sets described earlier, and which ensure that any legal computation can be mod-
elled by a corresponding proof. This can most conveniently be done as follows.
We suppose our logical system to allow (1) variables, (2) predicate and function
symbols of any number of arguments, which must be nestable to form expres-
sions, (3) existential and universal quantiﬁers subject to the usual rules (so that
our logical system must always include all the standard mechanisms of the ordi-
nary predicate calculus), and (4) conditional expressions formed using the keywords
‘if ··· then ··· elseif ··· else ··· end if ’ in the usual way.

326
6
Undecidability and Unsolvability
Recursive deﬁnition of new function and predicate symbols, for example in a
style like
deﬁne Name(s1, s2,...,sn) =Def if cond1 then expn1
elseif cond2 then expn2
···
elseif condm then expnm
else expnm+1 end if ,
(6.2)
must also be possible under the same conditions in which the corresponding function
deﬁnition would be allowed and would be certain to converge. (As for function def-
initions in a programming language, in such deﬁnitions the variables s1,s2,...,sn
must all be distinct and the symbol ‘Name’ being deﬁned must never have been used
before.) For function symbols such a deﬁnition must imply the universally quanti-
ﬁed equality

∀s1, s2,...,sn


Is_HF(s1) & ··· & Is_HF(s1)

→
Name(s1,s2,...,sn) = if cond1 then expn1
elseif cond2 then expn2
···
elseif condm then expnm
else expnm+1 end if

and for predicate symbols the corresponding universally quantiﬁed logical equiva-
lence. (More is said later about the situations in which such recursive deﬁnitions are
legitimate, i.e. situations in which we can be sure, on essentially syntactic grounds,
that the corresponding recursive functions would be certain to converge.)
Provided that the conditions necessary for convergence discussed below are sys-
tematically respected, any sequence of set- and Boolean-valued function deﬁnitions
in our set-theoretic programming language can be ‘mirrored’ simply by translating
each function deﬁnition
function name(s1, s2,...,sn);
return if cond1 then expn1
elseif cond2 then expn2
···
elseif condm then expnm
else expnm+1 end if ;
end name

6.2
The Two Gödel Theorems
327
into the above deﬁnition (6.2) of a similarly-named logical symbol. For example,
the deﬁnition
function union(s1, s2);
return if s1 = ∅then s2
else union

s1 less arb(s1),s2

with arb(s1) end if ;
end union
of the function ‘union’ translates into the logical deﬁnition
deﬁne Union(s1, s2) =Def if s1 = ∅then s2
else With

Union

Less

s1, Arb(s1)

, s2

, Arb(s1)

end if .
We will use the term ‘mirroring’, or more speciﬁcally ‘mirroring in logic’, for
the systematic translation process just described. The ‘mirrored’ versions of the el-
ementary set-theoretic functions appearing in our earlier discussion of computation
with hereditarily ﬁnite sets will be written using the same names as the programmed
functions, but the ﬁrst letter of the name will be capitalized to indicate that it is a
symbol of logic rather than a function name used in programming.
The elementary axioms and stipulations listed in the preceding paragraphs serve
to ensure that all computations with hereditarily ﬁnite set described previously can
be ‘mirrored’ by elementary logical proofs, in the manner described by our earlier
‘Mirroring Lemma’. Note that the condition that a string should be any one of these
required axioms (or theorems) can easily be tested by a programmable function.
In addition to these required axioms (or some subset from which the rest of these
required assertions can be proved), any number of other axioms are allowed.
We also want our logical system to include a principle of induction strong enough
to subsume the ordinary principle of mathematical induction. Since integers are de-
ﬁned objects, rather than primitive objects, of our system, it is convenient to for-
mulate our principle of induction in set-theoretic rather than integer-related terms.
This can be done as follows. Since the sets spoken of in our logical system are all
assumed to be ﬁnite (in fact, to be hereditarily ﬁnite), there can exist no indeﬁnitely
long descending sequence of subsets of any of our sets. Hence any predicate which
is true for the null set and true for a set s whenever it is true for all proper subsets of
s must be true for all sets s. In formal terms this is

P(∅) &

∀x
 
Is_HF(x) &

∀y
 
Is_HF(y) & Incs(x,y) & x ̸= y

→P(y)

→P(x)

→

∀z| Is_HF(z) →P(z)

.
Similarly, since the standard representation of any member of a set s must be shorter
than that of s, there can be no indeﬁnitely long sequence of sets, each of which is a
member of the preceding set in the sequence. Hence any predicate which is true for
the null set and true for a set s whenever it is true for all the members of s must be

328
6
Undecidability and Unsolvability
true for all sets s. In formal terms this second principle of induction is

P(∅) &

∀x
 
Is_HF(x) &

∀y
 
Is_HF(y) & y ∈x

→P(y)

→P(x)

→

∀z| Is_HF(z) →P(z)

.
The ﬁrst of these inductive principles (subset induction) is valid only for ﬁnite
sets; the second (membership induction) carries over to the general set theory con-
sidered later in this book, which also allows inﬁnite sets.
These statements are taken as axioms for every syntactically legal predicate for-
mula P of our theory. Note that the condition that a formula should arise in this way,
i.e. by substitution of a predicate formula for the symbol P appearing in the two pre-
ceding axiom templates, is computationally testable. Thus no incompatibility arises
with our general demand that there must always exist a programmed function which
tests formulae to determine whether they are legal axioms.
6.2.3 Additional Comments on the Legitimacy of Recursive
Deﬁnitions
Recursive deﬁnitions are legitimate in situations in which the corresponding func-
tion deﬁnitions are certain to converge. Consider a deﬁnition of the form
deﬁne Name(s1, s2,...,sn) =Def if cond1 then expn1
elseif cond2 then expn2
···
elseif condm then expnm
else expnm+1 end if .
If this deﬁnition is not recursive, i.e. if all the predicate and function symbols
which appear in it have been deﬁned previously, it is legitimate whenever it is syn-
tactically legal. But if the deﬁned function ‘Name’ appears within the body of the
deﬁnition, then conditions must be imposed on the arguments of each such appear-
ance for its legitimacy to be guaranteed. More speciﬁcally, consider any such ap-
pearance of ‘Name’, and suppose that it has the form Name(e1,e2,...,en). Then we
must be able to prove that the sequence e1,e2,...,en is ‘lexicographically smaller’
than s1,s2,...,sn, in the sense that there exists an integer k no larger than n such
that
s1 ⊇e1, s2 ⊇e2,...,sk ⊇ek
can be proved in the context in which Name(e1,e2,...,en) appears, and that
ej ̸= sj can also be proved for some j between 1 and k. These assertions must
be proved under the hypothesis that all the conditions cond1,cond2,...,condh−1
appearing on if-statement branches preceding the branch containing the occurrence
Name(e1,e2,...,en) are false, while condh is true if Name(e1,e2,...,en) appears
within expnh.

6.2
The Two Gödel Theorems
329
As an example, consider the previously cited deﬁnition
deﬁne Union(s1, s2) =Def if s1 = ∅then s2
else With

Union

Less

s1, Arb(s1)

, s2

, Arb(s1)

end if ;
Since the function ‘Union’ being deﬁned also appears on the right of the deﬁnition,
this deﬁnition is recursive. To be sure that it is legitimate, we must show that the one
appearance of ‘Union’ on the right, which is as the expression
Union

Less

s1, Arb(s1)

,s2

,
has arguments certain to be lexicographically smaller than the initial arguments
s1,s2, in the context in which Union( Less(s1, Arb(s1)) appears. This is so because
we can show that its ﬁrst argument Less(s1, Arb(s1)) is included in and not equal to
s1 in the context in which it appears. Indeed, in this context we can be certain that
s1 ̸= ∅, so
s1 ⊇Less

s1, Arb(s1)

by elementary set theory, and since s1 ̸= ∅, Arb(s1) is in s1 but not in
Less(s1, Arb(s1)), so
Less

s1, Arb(s1)

̸= s1.
Elementary arguments of this kind can be given in for each logical predicate and
function-symbol deﬁnitions mirroring the programmed functions appearing in our
earlier discussion of computation with hereditarily ﬁnite sets. We leave the work of
verifying this to the reader. However, some of the arguments necessary appear in the
following section on basic properties of integers.
6.2.4 Properties of Integers
To show that the inductive principles formulated above subsume ordinary integer
induction, we can prove the few needed basic properties of integers as given by the
set-theoretic encodings and deﬁnitions given earlier. For convenience, we list the
recursive deﬁnitions corresponding to the relevant function deﬁnitions appearing in

330
6
Undecidability and Unsolvability
our earlier discussion of computation with hereditarily ﬁnite sets. These are
deﬁne Next(s) =Def With(s, s);
deﬁne Last(s) =Def if s = ∅then ∅
elseif s = Singleton

Arb(s)

then Arb(s)
else Last

Less

s,Arb(s)

end if ;
deﬁne Prev(s) =Def Less

s, Last(s)

;
deﬁne Is_integer(s) ↔Def if s = ∅then true
else s = Next

Prev(s)

& Is_integer

Prev(s)

end if .
We begin by showing that

∀x
 
Is_integer(x) →

x = ∅∨

x = Next

Prev(x)

& Is_integer

Prev(x)

,
a statement which we will call the ‘Next_Prev’ lemma. To prove this, suppose that
it is false. Then there exists an x such that
Is_integer(x) & (x ̸= ∅) &

x ̸= Next

Prev(x)

∨

¬Is_integer

Prev(x)

.
On the other hand, by deﬁnition of ‘Is_integer’ we have
Is_integer(x) ↔if x = ∅then true
else

x = Next

Prev(x)

& Is_integer

Prev(x)

end if .
It follows from the above that
x = Next

Prev(x)

& Is_integer

Prev(x)

&

x ̸= Next

Prev(x)

∨

¬Is_integer

Prev(x)

,
a contradiction proving the ‘Next_Prev’ lemma.
Another simple lemma of this kind needed below is what might be called the
‘Prev_Next’ lemma:

∀x | Is_HF(x) →x = Prev

Next(x)

.
By the deﬁnition of ‘Next’ this is equivalent to

∀x | Is_HF(x) →x = Prev

With(x,x)

.
Suppose that this is false, so that there exists a w such that
Is_HF(w) & w ̸= Prev

With(w,w)

.
By deﬁnition of ‘Prev’, this means that
w ̸= Less

With(w,w), Last

With(w,w)

,

6.2
The Two Gödel Theorems
331
so Last( With(w,w)) ̸= w. Hence our assertion will follow if we can prove that

∀x | Is_HF(x) →x = Last

With(x,x)

.
It is most convenient to prove this in the generalized form

∀x,y
 
Is_HF(x) & Is_HF(y)

→

Incs(x,y) →

x = Last

With(y,x)

.
Suppose that this last statement is false. Then there exist u and v such that
Is_HF(u) & Is_HF(v) & Incs(u,v) &

u ̸= Last

With(v,u)

.
Consider the predicate Q(x) deﬁned by
Incs(u,x) →

u = Last

With(x,u)

.
Applying the above-discussed subset induction principle to Q, noting that Q(v) is
false, gives

¬Q(∅)

∨
¬

∀x
 
Is_HF(x) &

∀y
 
Is_HF(y) & Incs(x,y) & x ̸= y

→Q(y)

→Q(x)

.
If x = ∅, then With(x,u) = Singleton(u), and therefore Last(With(x,u)) = u. This
shows that Q(∅) is true, so the formula just displayed simpliﬁes to its second dis-
junct, implying the existence of an x such that

∀y
 
Is_HF(y) & Incs(x,y) & x ̸= y & Incs(u,y)

→u = Last

With(y,u)

&
Is_HF(x) & Incs(u,x) & u ̸= Last

With(x,u)

.
Using the deﬁnition of Last, and noting that With(x,u) ̸= ∅, we have
Last

With(x,u)

= if With(x,u) = Singleton

Arb

With(x,u)

then Arb

With(x,u)

else Last

Less

With(x,u), Arb

With(x,u)

end if .
It follows that we cannot have With(x,u) = Singleton(Arb(With(x,u))), since
u is in With(x,u), so this would imply that With(x,u) = Singleton(u), and so
Last(With(x,u)) = u, contradicting u ̸= Last(With(x,u)). Hence x ̸= ∅and also
Last

With(x,u)

= Last

Less

With(x,u), Arb

With(x,u)

.
Since With(x,u) ̸= ∅, we must have
Arb

With(x,u)

∈With(x,u),
so either Arb(With(x,u)) = u or Arb(With(x,u)) ∈x.

332
6
Undecidability and Unsolvability
But Arb(With(x,u)) = u is impossible, since if y is any element of x, then, since
Incs(u,x), y would also be an element of u, contradicting
Intersection

Arb

With(x,u)

, With(x,u)

= ∅.
It follows that we must have
Arb

With(x,u)

∈x,
from which it follows that
Less

With(x,u), Arb

With(x,u)

= With

Less

x, Arb

With(x,u)

, u

.
Then plainly
Incs

x,Less

x, Arb

With(x,u)

& x ̸= Less

x, Arb

With(x,u)

,
so from

∀y
 
Incs(x,y) & x ̸= y & Incs(u,x)

→

u = Last

With(y,u)

we have
u = Last

With

Less

x, Arb

With(x,u)

,u

,
and therefore u = Last(With(x,u)), a contradiction completing our proof of the
‘Prev_Next’ lemma.
For what follows we also need the lemma

∀x | Is_HF(x) →

x = ∅∨Last(x) ∈x

.
To prove this, suppose that it is false, so that there exists a u such that
Is_HF(u) & u ̸= ∅& ¬

Last(u) ∈u

.
Consider the predicate Q(x) deﬁned by x = ∅∨(Last(x) ∈x). Applying the
subset induction principle to Q, and noting that Q(u) is false, gives

¬Q(∅)

∨
¬

∀x
 
Is_HF(x) &

∀y
 
Is_HF(y) & Incs(x,y) & x ̸= y

→Q(y)

→Q(x)

,
so, since Q(∅) is true, there exists an x for which

∀y
 
Is_HF(y) & Incs(x,y) & x ̸= y

→Q(y)

& Is_HF(x) & ¬Q(x),
where plainly x ̸= ∅. That is,

∀y
 
Is_HF(y) & Incs(x,y) & x ̸= y

→

y = ∅∨Last(y) ∈y

& Is_HF(x) & x ̸= ∅& ¬

Last(x) ∈x

.

6.2
The Two Gödel Theorems
333
Using the deﬁnition of ‘Last’ we have
Last(x) = if x = ∅then ∅
elseif x = Singleton

Arb(x)

then Arb(x)
else Last

Less

x, Arb(x)

end if .
Since x ̸= ∅the ﬁrst of the cases appearing in this last formula is ruled out, and
since it then follows that Arb(x) ∈x, the second of these cases is excluded also.
Hence we have Last(x) = Last(Less(x,Arb(x))). But then we also have
Incs

x, Less

x, Arb(x)

& Less

x, Arb(x)

̸= x,
and so it follows from

∀y
 
Is_HF(y) & Incs(x,y) & x ̸= y

→

y = ∅∨Last(y) ∈y

that
Last

Less

x,Arb(x)

∈Less

x,Arb(x)

.
Since Incs(x, Less(x, Arb(x))) and Last(Less(x, Arb(x))) = Last(x), we see that
Last(x) ∈x, completing our proof of the statement

∀x | x = ∅∨Last(x) ∈x

.
6.2.4.1 Peano’s Principle of Mathematical Induction
Now we prove that Peano’s standard principle of mathematical induction applies to
integers as we have deﬁned them. This is done by showing that for every formula P
of our theory with one free variable we have
P(0) &

∀y
 
Is_integer(y) & P(y)

→P

Next(y)

→

∀x | Is_integer(x) →P(x)

.
To prove this statement, suppose that it is false, so that there exists an x such that
P(0) &

∀y
 
Is_integer(y) & P(y)

→P

Next(y)

& Is_integer(x) &

¬P(x)

.
Consider the predicate expression Q(y) deﬁned by ‘Is_integer(y) →P(y)’. Since
(∀z| Q(z)) is false (for z = x in particular), an application of the subset induction
principle to Q gives

¬Q(0)

∨

¬

∀x
 
Is_HF(x) &

∀y
 
Is_HF(y) & Incs(x,y) & x ̸= y

→Q(y)

→Q(x)

,

334
6
Undecidability and Unsolvability
so that there exists an x such that

¬Q(0)

∨

∀y
 
Is_HF(y) & Incs(x,y) & x ̸= y

→
Q(y)

& Is_HF(x) & ¬Q(x)

,
that is

Is_integer(0) & ¬P(0)

∨

∀y
 
Is_HF(y) & Incs(x,y) & x ̸= y

→

Is_integer(y) →P(y)

&
Is_HF(x) & Is_integer(x) & ¬P(x)

.
Since P(0) must be true and Is_integer(y) implies Is_HF(y), this simpliﬁes to

∀y
 
Incs(x,y) & x ̸= y & Is_integer(y)

→P(y)

& Is_integer(x) & ¬P(x).
Since P(0) is true, we have x ̸= 0, so by the Next_Prev lemma we have

∀y
 
Incs(x,y) & x ̸= y & Is_integer(y)

→P(y)

&
Is_integer(x) & Is_integer

Prev(x)

& ¬P

Next

Prev(x)

.
Thus, since (∀y | (Is_integer(y) & P(y)) →P(Next(y))), we must have

∀y
 
Incs(x,y) & x ̸= y & Is_integer(y)

→P(y)

&
Is_integer

Prev(x)

&

¬P

Prev(x)

.
Using the deﬁnition of ‘Prev’ we have
Prev(x) = Less

x, Last(x)

,
and so, since it was proved above that Last(x) is in x whenever x ̸= 0, it follows that
Incs

x, Prev(x)

& x ̸= Prev(x) & Is_integer

Prev(x)

.
But then

∀y
 
Incs(x,y) & x ̸= y & Is_integer(y)

→P(y)

implies that P(Prev(x)), contradicting ¬P(Prev(x)), and so completing our proof
of Peano’s standard axiom of induction.
To complete our discussion it is worth proving the remaining Peano axioms for
integers, which in our set-theoretic formulation are
(i) Is_integer(0);
(ii) (∀x | Is_integer(x) →Is_integer(Next(x)));
(iii) (∀x | Next(x) ̸= 0);
(iv) (∀x,y | (Is_integer(x) & Is_integer(y) & Next(x) = Next(y)) →x = y).

6.2
The Two Gödel Theorems
335
The ﬁrst two statements follow from the deﬁnition

∀x | Is_integer(x) ↔if x = ∅then true
else x = Next

Prev(x)

& Is_integer(x) end if

.
Since by deﬁnition Next(x) = x with x, Next(x) ̸= ∅follows by elementary set-
theoretic reasoning.
Finally, since it has been shown above that Is_integer(x) implies x =
Prev(Next(x)), statement (iv) follows immediately.
This completes our discussion of the relationship between standard integer in-
duction and the set-theoretic induction principles stated above.
The inductive proofs given in the preceding pages are intended to typify the large
but generally straightforward family of proofs needed to show that the elementary
functions of sequences, lists of sequences, strings, etc. deﬁned above necessarily
have their familiar properties. For example, it can be shown in this way that string
concatenation is associative, i.e. that

∀x1,x2,x3
 
Is_string(x1) & Is_string(x2) & Is_string(x3)

→

Concatenate

Concatenate(x1,x2),x3

=
Concatenate

x1,Concatenate(x2,x3)

.
Or, as another example, we can show that the same ﬁnal string is obtained by ﬁrst
deleting the ﬁnal character of a (non-empty) string x2 and then appending the result
to a string x1 as would be obtained by ﬁrst appending the two strings and then
deleting the ﬁnal character of what results. In formal terms this is

∀x1,x2
 
Is_string(x1) & Is_string(x2)

→
Concatenate

x1, Less

x2, Ordered_pair

Prev(#x2), Last_of(x2)

= Less

Concatenate(x1,x2),
Ordered_pair

Prev

#Concatenate(x1,x2)

,
Last_of

Concatenate(x1,x2)

.
Since many such proofs will be given later in this book in full, computer-veriﬁed
detail (albeit in a somewhat different setting, viz. general set theory rather than the
more limited theory of hereditarily ﬁnite sets on which the present section concen-
trates), we prove no theorems of the kind illustrated by our two examples, other
than those already proved above. Instead, we content ourselves with the broad claim
that all the results of this elementary kind of whose correctness one could convince
oneself after careful examination can also be proved formally. To attain conviction
that this is so, the reader may wish to try his/her hand at a few such proofs, for ex-
ample the proofs of the two examples just given. The line of reasoning found below
depends on a few theorems of this kind, of which the statement

∀x1,x2
 
Is_proof(x1) & Is_proof(x2)

→Is_proof

Concatenate(x1,x2)

,

336
6
Undecidability and Unsolvability
where ‘Is_proof’ is the logical symbol mirroring the recursive function ‘is_proof’,
is typical. Computer veriﬁcation of the line of reasoning given below would require
systematic, computer-veriﬁed proof of a ﬁnite collection of such statements.
6.2.5 A Final Remark on Proof and Computation
The mirroring lemma shows that our logical system ‘envelops’ the process of com-
putation with hereditarily ﬁnite sets, in the sense that any value name(c1,c2,...,cn)
derivable by computation can also be derived in another way, namely by proving a
theorem of the form Name(e1,e2,...,en) = en+1. In cases favourable for proof, the
length of the proof required may be considerably shorter than the computation it re-
places, even allowing for the great difference in speed between human thought and
electronic computation. For example, we can easily prove that
Exp(10,40) = 10000000000000000000000000000000000000000,
supplying the required proof in a time much shorter than that needed to verify this
same fact by direct computation. Similarly, given two functions f (s1,s2,...,sn)
and g(s1,s2,...,sn) and the symbols F and G which mirror them, we may be able
to prove a theorem of the form

∀s1,s2,...,sn | F(s1,s2,...,sn) = G(s1,s2,...,sn)

,
thus allowing replacement of f by g, whose computation may be much faster.
More generally, the mirroring lemma gives us the following result. Suppose that
some logical system in which we are able to embed our computational system is
consistent, and let the logical symbol ‘Fcn’ mirror some recursively deﬁned function
‘fcn’. Then, given representations of two hereditarily ﬁnite sets s1 and s2, there
exists a proof of the logical statement ‘Fcn(s1) = s2’ if and only if fcn(s1) evaluates
to s2. Indeed, the mirroring lemma shows that ‘Fcn(s1) = s2’ must be a theorem
if fcn(s1) evaluates to s2. Conversely, if our logical system is consistent, there can
exist at most one s2 for which ‘Fcn(s1) = s2’ is provable, and so by the mirroring
lemma the one s2 for which this is provable must be the value of fcn(s1) derivable
by computation.
6.2.6 A Technical Adjustment
To avoid a technical issue that would otherwise arise it is convenient to formulate
the ‘follows_from_element’ function deﬁned at the start of Sect. 6.2.2 in a slightly
different way. To this end, we ﬁrst deﬁne the auxiliary function
function ax(x); return if is_axiom(x) then x else “true” end if ; end ax.

6.2
The Two Gödel Theorems
337
Then is_axiom(ax(x)) is always true, and in fact the expressions is_axiom(x) and
x = ax(x) are always equal.
We also introduce the following function
function lic(x);
return if is_sequence(x) & last_is_consequence(x) then x
else ordered_pair(0, “true”) end if ;
end lic;
so that
last_is_consequence

lic(x)

is true for every x.
This enables us to write the follows_from_element in the following modiﬁed way,
which will be more convenient in what follows:
function follows_from_element(list_of_subsequences, conclusion);
return if list_of_subsequences = ∅then conclusion = ax(conclusion)
else concatenate

arb(list_of_subsequences),

ordered_pair(0,conclusion)

=
lic

concatenate

arb(list_of_subsequences),

ordered_pair(0, conclusion)

∨
follows_from_element

list_of_subsequences less
arb(list_of_subsequences), ordered_pair(0, conclusion)

end if ;
end follows_from_element.
It is convenient to assume that there exists some reasonably small integer k0
such that every sequence s for which last_is_consequence(s) is true has length at
most k0. All common logic systems satisfy this condition (generally with k0 not
much larger than 4), which in any case is easily replaced if necessary. At any rate,
assuming this condition, we may as well assume that every sequence x for which
last_is_consequence(x) is true is of length exactly k0, since shorter sequences of
hypotheses can be left-padded with an appropriate number of copies of the trivial
hypothesis ‘true’.
6.2.7 The ‘Provability’ Predicate Pr(s)
Given the availability of existential and universal quantiﬁers within a logic system,
we can at once deﬁne a predicate which states that the string s is provable. This is
simply
deﬁne Pr(s) ↔Def

∃p | Is_proof(p) & Last_of(p) = s

,

338
6
Undecidability and Unsolvability
which we can also write as
deﬁne Pr(s) ↔Def

∃p | Is_proof_of(p,s)

,
if we introduce the intermediate deﬁnition
deﬁne Is_proof_of(p,s) ↔Def Is_proof(p) & Last_of(p) = s
which states that p is a proof culminating in the statement s.
This predicate differs from those previously considered in one important respect.
All of these others correspond to recursive functions which converge to some def-
inite set-theoretic value whenever they are applied to the appropriate number of
hereditarily ﬁnite arguments. Pr is a more abstract existential, which if programmed
would correspond to a search loop not guaranteed to converge.
We shall now establish several important properties of this predicate, for subse-
quent use. Note ﬁrst that the concatenation Concatenate(p1,p2) of any two proofs
is also a proof, since each element of the ﬁrst part of the concatenation is either
an axiom or a consequence of preceding statements, and similarly for the second
part of the concatenation. Moreover, if p is a proof and we concatenate any formula
which is a valid consequence of a subsequence of the formulae in p to p, then the
result is also a proof.
Next note that given s1,s2, and s3 for which s3 has the form s1 →s2 (i.e., s3 =
Concatenate(Concatenate(s1,“ →”),s2)) then

Pr(s1) & Pr(s3)

→Pr(s2).
For if not we would have Pr(s1) & Pr(s3) & (¬Pr(s2)), and so using the deﬁnitions
of Pr(s1) and Pr(s3) we could ﬁnd p1 and p3 for which we have
Is_proof(p1) & Last_of(p1) = s1 & Is_proof(p3) & Last_of(p3) = s3.
But then the concatenation of p1, p3, and the single formula s2 is a proof of s2, since
s2 follows by propositional implication from the two formulae s1 and s3.
We can write this result as the implication
Pr

Concatenate

Concatenate(s1,“ →”),s2

→

Pr(s1) →Pr(s2)

,
or, in a more drastically abbreviated notation,
Pr(s1 →s2) →

Pr(s1) →Pr(s2)

.
We can show in much the same way that given s1, s2, and s3, if s3 has the form
s1 & s2 (i.e., s3 = Concatenate(Concatenate(s1,“ & ”),s2)), then

Pr(s1) & Pr(s2)

→Pr(s3).
This result can be written as the implication

Pr(s1) & Pr(s2)

→Pr

Concatenate

Concatenate(s1,“ & ”),s2

,

6.2
The Two Gödel Theorems
339
or, again abbreviating more drastically, as

Pr(s1) & Pr(s2)

→Pr(s1 & s2).
Next suppose that Q(x) is any expression involving one free variable x for which
we have
Pr

∀y | Q(y)

.
Then Is_proof_of(p,(∀y |Q(y))) for some p. But then, for any x, the concatenation
p′ of p with the single statement Q(x) is also a proof, so
Is_proof_of

Concatenate

p,Singleton

Ordered_pair

0,Q(x)

,Q(x)

,
where x denotes the standard representation of any hereditarily ﬁnite set. This shows
that
Pr

∀y | Q(y)

→

∀x | Pr

Q(x)

.
Finally, if s is an axiom, i.e. if Is_axiom(s) where ‘Is_axiom’ is the predicate sym-
bol that mirrors the Boolean function ‘is_axiom’, then the one-element sequence
{ Ordered_pair(∅,s)} is easily shown to satisfy Is_proof({ Ordered_pair(∅,s)}).
Since we must also have Cdr(Arb({ Ordered_pair(∅,s)})) = Cdr(Ordered_pair(∅,s))
= s, it follows that Is_proof_of({ Ordered_pair(∅,s)},s). Conversely any proof of
length 1 must have the form { Ordered_pair(∅,s)} where s is an axiom, i.e. satisﬁes
Is_axiom(s).
Our next goal is to prove the following.
6.2.8 Proof Visibility Lemma
Let s be any string representing a syntactically well-formed logical formula. Then
Pr(s) →Pr

Pr(s)

.
In intuitive terms this simply states that any proof of s can be turned (rather
explicitly) into a proof that s has a proof; i.e. the existence of a proof of s is always
‘visible’ rather than ‘cryptic’. We prove this as follows. Assuming that it is false,
there is an s such that Pr(s) & ¬Pr(Pr(s)), and so there exists a sequence p of
strings such that
Is_proof(p) & s = Last_of(p) & ¬Pr

Pr(s)

.
Hence, since Last_of(p) = Value_at(p, Prev(#p)), there exists an integer n such
that
Is_proof(p) & n ∈#p & ¬Pr

Pr

Value_at(p,n)

.

340
6
Undecidability and Unsolvability
Let n be the smallest such integer. Then, by deﬁnition of Is_proof, either
Value_at(p,n) = Ax

Value_at(p,n)

,
or there exists a ﬁnite sequence n1,n2,...,nk of integers, all smaller than n, such
that
Last_is_consequence


Value_at(p,n1), Value_at(p,n2),..., Value_at(p,n1), Value_at(p,n)

which, as noted previously, means in more formal terms that there exists an x such
that
Value_at(p,n1) = Value_at

Lic(x),0

& ··· &
Value_at(p,nk) = Value_at

Lic(x),k −1

&
Value_at(p,n) = Value_at

Lic(x),k

,
where the function symbol ‘Lic’ mirrors the function ‘lic’ introduced above. In the
ﬁrst of these cases (Value_at(p,n) = Ax(Value_at(p,n))) we reason as follows. For
every x the sequence of formulae
Is_proof

Singleton

Ordered_pair

0, Ax(x)

Is_proof_of

Singleton

Ordered_pair

0, Ax(x)

, Ax(x)


∃p | Is_proof_of

p,Ax(x)

Pr

Ax(x)

is the skeleton of a proof whose intermediate details the reader should easily be able
to ﬁll in. If we denote this completed proof
···
Is_proof

Singleton

Ordered_pair

0, Ax(x)

···
Is_proof_of

Singleton

Ordered_pair

0, Ax(x)

, Ax(x)

···

∃p | Is_proof_of

p,Ax(x)

···
Pr

Ax(x)

by cp, then cp is an explicit proof whose ﬁnal statement is Pr(Ax(x)), allowing us
to conclude that Pr(Pr(Ax(x))) for every x. Thus, if Axiom(s), so that s = Ax(s), we
have Pr(Pr(s)). This proves that the implication
Axiom(s) →Pr

Pr(s)


6.2
The Two Gödel Theorems
341
holds for all s, so that if Axiom(Value_at(p,n)) we have Pr(Pr(Value_at(p,n))),
contradicting
(¬Pr(Pr(Value_at(p,n)))),
and
so
ruling
out
the
case
Axiom(Value_at (p,n)).
Next suppose that there exists a ﬁnite sequence n1,n2,...,nk0−1 of integers, all
smaller than n, such that
Last_is_consequence

Value_at(p,n1),Value_at(p,n2),...,Value_at(p,nk0−1), Value_at(p,n)

.
(Here and in what follows, k0 is the common length of sequences x for which
Last_is_consequence(x) is true.) Then by inductive hypothesis we have
Pr

Pr

Value_at(p,nj)

for each j from 1 to k0 −1. Also the sequence of formulae
Suppose :

∃y | Pr

Value_at

Lic(y),0

& ··· &
Pr

Value_at

Lic(y),k0 −2

&

¬Pr

Value_at

Lic(y),k0 −1

Skolemize : Pr

Value_at

Lic(x),0

& ··· &
Pr

Value_at

Lic(x),k0 −2

&

¬Pr

Value_at

Lic(x),k0 −1

Skolemize : Is_proof_of

Value_at

Lic(x),0

···
Skolemize : Is_proof_of

Value_at

Lic(x),k0 −2

Is_proof_of

Concatenate

Concatenate

···
Concatenate

Concatenate(p1,p2)··· ,pk0−2

,
Pr

Value_at

Lic(y),k0 −1


∃p | Is_proof_of

p, Value_at

Lic(x),k0 −1

Pr

Value_at

Lic(x),k0 −1

false
Discharge :

∀y
 
Pr

Value_at

Lic(y),0

& ··· &
Pr

Value_at

Lic(y),k0 −2

→
Pr

Value_at

Lic(y),k0 −1


342
6
Undecidability and Unsolvability
is the skeleton of a proof whose intermediate details the reader should again be able
to ﬁll in. This proof (when completed) shows explicitly that

∀y
 
Pr

Value_at

Lic(y),0

& ··· &
Pr

Value_at

Lic(y),k0 −2

→
Pr

Value_at

Lic(y),k0 −1

and so we have
Pr

∀y
 
Pr

Value_at

Lic(y),0

& ··· &
Pr

Value_at

Lic(y),k0 −2

→
Pr

Value_at

Lic(y),k0 −1

.
From this it follows, as noted above, that

∀x | Pr

Pr

Value_at

Lic(x),0

& ··· &
Pr

Value_at

Lic(x),k0 −2

→
Pr

Value_at

Lic(x),k0 −1

.
By deﬁnition of ‘Last_is_consequence’ we have

∃y | Value_at(p,n1) =
Value_at

Lic(y),0

& ··· & Value_at(p,nk0) =
Value_at

Lic(y),k0 −2

&
Value_at(p,n) = Value_at

Lic(y),k0 −1

so
Value_at(p,n1) = Value_at

Lic(x0),0

& ···
& Value_at(p,nk0) =
Value_at

Lic(x0),k0 −2

&
Value_at(p,n) = Value_at

Lic(x0),k0 −1

for some x0. From this it follows, using the last universally quantiﬁed formula ap-
pearing above, that
Pr

Pr

Value_at(p,n1)

& ··· & Pr

Value_at(p,nk)

→Pr

Value_at(p,n)

.
Hence, using the previously established implication (Pr(a →b) →(Pr(a) →
Pr(b)), we have
Pr

Pr

Value_at(p,n1)

& ··· & Pr

Value_at(p,nk)

→Pr

Pr

Value_at(p,n)


6.2
The Two Gödel Theorems
343
and then by repeated use of the implication Pr(a) & Pr(b) →Pr(a & b) established
earlier it follows that

Pr

Pr

Value_at(p,n1)

& ··· & Pr

Pr

Value_at(p,nk0)

→Pr

Pr

Value_at(p,n)

.
Since
Pr(Pr(Value_at(p,nj))) for all j
from 1 to k0, it follows that
Pr(Pr(Value_at(p,n)), completing our demonstration of the Proof Visibility Lem-
ma.
6.2.9 Gödel’s Trick Sentence
Gödel’s trick sentence G is now simply
¬Pr

Subst

“¬Pr

Subst(x,x)”,“¬Pr

Subst(x,x)

”

,
where ‘Subst’ is the logical symbol that mirrors the two-parameter string function
‘subst’ introduced above.
In this statement, and repeatedly in what follows, the quoted string
“¬Pr(Subst(x,x))” appears. It should be kept in mind that this is simply an ab-
breviation for the character sequence
10,111,116,32,80,114,40,83,117,98,115,116,40,120,44,120,41,41,
that is, for the set constant

ordered_pair(0,110), ordered_pair(1,111), ordered_pair(2,116),
ordered_pair(3,32), ordered_pair(4,80), ordered_pair(5,114),
ordered_pair(6,40), ordered_pair(7,83), ordered_pair(8,117),
ordered_pair(9,98), ordered_pair(10,115),
ordered_pair(11,116),
ordered_pair(12,40), ordered_pair(13,120),
ordered_pair(14,44), ordered_pair(15,120),
ordered_pair(16,41), ordered_pair(17,41)

.
Note that since x is the only free variable of the syntactically well-formed string
“¬Pr(Subst(x,x))”, the functional expression
subst

“¬Pr

Subst(x,x)”,“¬Pr

Subst(x,x)”

evaluates to
“¬Pr

Subst

“¬Pr

Subst(x,x)”,“¬Pr

Subst(x,x)”

”

344
6
Undecidability and Unsolvability
and therefore the logical statement
Subst

“¬Pr

Subst(x,x)”,“¬Pr

Subst(x,x)”

=
“¬Pr

Subst

“¬Pr

Subst(x,x)

”,“¬Pr

Subst(x,x)

”

”
which mirrors this evaluation is a theorem. Therefore so is
Pr

Subst

“¬Pr

Subst(x,x)

”,“¬Pr

Subst(x,x)

”

↔
Pr

“¬Pr

Subst

“¬Pr

Subst(x,x)

”,“¬Pr

Subst(x,x)

”

.
Hence

¬Pr

Subst

“¬Pr

Subst(x,x)

”,“¬Pr

Subst(x,x)

”

↔

¬Pr

“¬Pr

Subst

“¬Pr

Subst(x,x)

”,“¬Pr

Subst(x,x)

”

”

is a theorem. Deﬁning G as

¬Pr

Subst

“¬Pr

Subst(x,x)

”,“¬Pr

Subst(x,x)

”

,
we see that
G ↔

¬Pr(“G”)

is also a theorem.
6.2.10 Rosser’s Variant of Gödel’s Trick Sentence
This variant is obtained by replacing the predicate ‘¬Pr(s)’, i.e.

∀p | ¬Is_proof_of(p,s)

,
by the modiﬁed predicate Prr(s) deﬁned by
Prr(s) =Def

∀p
 
¬Is_proof_of(p,s)

∨

∃q | Shorter(q,p) & Is_proof_of

q, Neg(s)

.
Here ‘Neg’ is a function symbol which mirrors the operation which simply
negates a string by prepending ‘¬’ to it, and Shorter is a predicate symbol which
mirrors the function shorter(q,p) that tests one sequence of strings (its ﬁrst param-
eter q) to verify that it is shorter than its second parameter.
Note that whereas ‘¬Pr(s)’ states that s has no proof, Prr(s) states that either
s has no proof or that, if it does, there exists a shorter proof of the negation of s.
In a consistent logical system these two conditions are the same, since the added
clause (∃q | Shorter(q,p) & Is_proof_of(q,Neg(s)) implies that the negation of s
has a proof and hence implies that s can have no proof. Nevertheless this technical

6.2
The Two Gödel Theorems
345
reformulation of the condition ‘¬Pr(s)’ is advantageous for the argument given two
paragraphs below.
Rosser’s trick sentence is now
¬Prr

Subst

“Prr

Subst(x,x)”,“Prr

Subst(x,x)

”

,
where ‘Subst’ is as before. Reasoning as above we ﬁnd that since x is the only free
variable of the syntactically well-formed string “Prr(Subst(x,x))”, the functional
expression
subst

“Prr

Subst(x,x)”,“Prr

Subst(x,x)”

evaluates to
“Prr

Subst

“Prr

Subst(x,x)”,“Prr

Subst(x,x)”

”
and so the logical statement
Subst

“Prr

Subst(x,x)”,“Prr

Subst(x,x)”

=
“Prr

Subst

“Prr

Subst(x,x)

”,“Prr

Subst(x,x)

”

”
which mirrors this evaluation is a theorem. Therefore so is
Prr

Subst

“Prr

Subst(x,x)

”,“Prr

Subst(x,x)

”

↔
Prr

“Prr

Subst

“Prr

Subst(x,x)

”,“Prr

Subst(x,x)

”

.
Deﬁning Gr as Prr(Subst(“Prr(Subst(x,x))”,“Prr(Subst(x,x))”))), we see that
Gr ↔Prr(“Gr”) is also a theorem.
6.2.11 Proof of Rosser’s Variant of Gödel’s First Theorem
Given that we have just exhibited a proof of the statement Gr ↔¬Prr(“Gr”), it is
now easy to complete the proof that (if the proof system T in which we reason is
consistent) neither Gr nor (¬Gr) can be provable, showing that Gr is undecidable in
T , which is Rosser’s strengthened version of Gödel’s ﬁrst theorem.
For suppose ﬁrst that Gr is provable. Then using Gr ↔Prr(“Gr”), we can con-
clude Prr(“Gr”), i.e. that

∀p

¬Is_proof_of(p,“Gr”)

∨

∃q |Shorter(q,p) & Is_proof_of

q, Neg(“Gr”)

.
So either Gr is not provable, or there exists a proof of the negation of Gr. But if our
logical system is consistent, this last implies that Gr is not provable in either case.
Suppose next that ‘¬Gr’ is provable, and let q0 be a proof of ‘¬Gr’. Using Gr ↔
Prr(“Gr”) once more we can deduce that (¬Prr(“Gr”)), i.e. that

∃p | Is_proof_of(p,“Gr”) &

∀q
 
¬Shorter(q,p)

∨

¬Is_proof_of

q, Neg(“Gr”)

.

346
6
Undecidability and Unsolvability
Let p0 be a proof satisfying this existential statement, so that
Is_proof_of(p0, Gr) &

¬Shorter(q0,p0)

.
It follows that the length of the proof p0 is less than or equal to the length of q0, so
that we can ﬁnd p0 explicitly by searching the ﬁnite collection of proofs that are no
longer than q0. But then we have proofs of both Gr and the negation of Gr, and so a
contradiction, which we have assumed to be impossible.
6.2.12 Proof of Gödel’s Second Theorem
This states that if our logical system is consistent it must be impossible to prove
‘¬Pr(false)’ in it. To show this, let p0 denote the proof of the theorem G ↔
(¬Pr(“G”)) derived above. The implication G →(¬Pr(“G”)) follows by one ad-
ditional step. Hence, if p is a proof of G, then the concatenation of p and p0, plus
two additional steps, gives a proof of ‘¬Pr(“G”)’, showing that Pr(“G”) implies
Pr(“¬Pr(G)”). Thus we have proved Pr(“G”) →Pr(“¬Pr(G)”).
Now, if a statement and its negative can both be proved, then by concatenating
these two proofs and adding one more step we obtain a proof of Pr(false). Hence if
our logical system is consistent and its consistency, i.e. the statement ‘¬Pr(false)’,
can be proved within it, then the implication
Pr

“¬Pr(G)”

→

¬Pr

“Pr(G)”

,
and so Pr(“G”) →(¬Pr(“Pr(G)”)), follows from Pr(“G”) →(¬Pr(“Pr(G)”)).
But the implication Pr(“G”) →Pr((“Pr(G)”) was proved in the earlier Sect. 6.2.8
(Proof Visibility lemma). This proves that (¬Pr(“G”)), and since G ↔(¬Pr(“G”))
we have a proof of G, whose existence immediately implies Pr(“G”), a contradic-
tion. Thus it must be impossible to prove ‘¬Pr(false)’ within our logical system, as
asserted.
6.3 Axioms of Reﬂection
The large-cardinal axioms discussed in Sect. 2.4.2.3 give one way of extending the
axioms of set theory to increase their power, but as these stand they have been of
little direct interest for our subsequent work, since their most immediate conse-
quences are relatively specialized theorems in set theory which we do not need or
prove. There is, however, a different (but, as we shall see, not entirely unrelated)
class of axioms, the so called axioms of reﬂection, which can be added to the ax-
ioms of set theory and are of more direct practical interest. These are axioms of the
form
Pr(‘F’) →F,

6.3
Axioms of Reﬂection
347
that is, statements which assert that if a formula F has a proof (a fact that we may,
for example, be able to establish nonconstructively), then F follows. The potential
practical importance of statements of this type is that they make the collection of
proof mechanisms available to us indeﬁnitely extensible, since we may be able to
establish general theorems of the form

∀s | A(s) →Pr

B(s)

,
where A and B have recursive deﬁnitions that allow them to be calculated mechan-
ically, or at least established easily, for hereditarily ﬁnite sets s. Then, whenever a
formula F is seen to satisfy ‘F’ = B(s) for some s satisfying A(s), we may be able
to deduce Pr(‘F ’) easily or automatically, and then F immediately by an axiom of
reﬂection.
However, Gödel’s second theorem tells us that the additional axioms we desire
must be set up carefully, since it is not immediately obvious that added axioms
of reﬂection do not introduce contradictions. Let T be a logical system to which
Gödel’s second theorem applies. That theorem implies that we cannot expect to
prove all statements of the form
PrT (‘F’) →F
(6.3)
in any consistent logical system, and indeed there is a strengthening of Gödel’s
theorem, known as Löb’s theorem, which shows that (6.3) can only be proved in
T if F itself can be proved in T . Nevertheless, one can ask whether the addition
of all the statements (6.3) to a consistent system T produces a more powerful but
still consistent system T ′, and in particular whether the collection T of statements
can be modelled in some more powerful system T ∗in which (6.3) can be proved.
We shall show in the following pages that if T ∗is the collection ZFC of Zermelo–
Fraenkel axioms of set theory extended by some assumption implying the existence
of a large inaccessible cardinal N, so that H (N) is the universe for the model
of ZFC considered in Sect. 2.4.2.3, and if T is the weakening of T ∗which only
asserts the existence of those inaccessible cardinals smaller than N, then (6.3) can
be proved in T ∗, and hence T ∗implies the consistency of the system obtained from
T by adding the desired axioms of reﬂection.
Several technical problems must be handled along the way to this goal. The ﬁrst
of these lies in the fact that the axioms we want to add involve the predicate Pr(s),
which is substantially more composite than the ordinary axioms of set theory. To
handle this we write a set of auxiliary axioms, whose consistency with the axioms
of set theory is not at issue since with suitable deﬁnition of the symbols appearing in
them they are all provable consequences of the ZFC axioms. These auxiliary axioms
allow us to write a formula for the needed predicate Pr. To avoid the addition of
too much clutter to set-theory’s streamlined basic axiom set, we will put these new
axioms rather more succinctly than is done in our main series of deﬁnitions and
proofs, but always in a provably equivalent way. The series of statements which we

348
6
Undecidability and Unsolvability
will now develop accomplishes this. We begin with
−

x ∈{a,b}

↔(x = a ∨x = b),
−(x ∈a ∪b) ↔(x ∈a ∨x ∈b),
−[x, y] =

{x},

{x},

{y},y

,
−Is_next(s,t) ↔

∀x | (x ∈t) ↔(x ∈s ∨x = s)

,
−Is_integer(n) ↔

∀x | (x ∈n ∨x = n) →

x = ∅∨

∃y ∈x | Is_next(y,x)

,
−Svm(f ) ↔

∀x ∈f
 
∃y,z| x = [y, z]

&

∀x,y,z
 
[x, y] ∈f & [x, z] ∈f

→y = z

,
−Is_seq(f ) ↔

Svm(f )
&

∃n| Is_integer(n) &

∀x | (x ∈f ) ↔

∃y, m ∈n| x = [m, y]

.
The above statements deﬁne the notions of integers n and sequences of length n.
Our next aim is to deﬁne the notion of (ZFC) ‘formula’, which for succinctness we
deﬁne as what would normally be called the syntax tree of a formula. We encode
these trees as collections of nodes, each node being a sequence whose ﬁrst com-
ponent is an integer encoding the node type and whose remaining components are
the syntactic subparts appropriate for the type of node. The allowed node types, and
their distinguishing codes, are as follows:
0: variable or constant,
1: &-operator,
2: ∨-operator,
3: →-operator,
4: ↔-operator,
5: ¬-operator,
6: false,
7: true,
8: equality sign,
9: ∀,
10: ∃,
11: ∈,
12: atomic formula involving predicate,
13: term involving function symbol.
Note that all of the ‘encoded’ forms of axioms which appear in the following dis-
cussion are written using only the elementary set-theoretic constructions
– {x},
– {x,y},
– [x, y],
– x ∪y,
– Seq2(x,y), which is deﬁned as {[0, x],[1, y]},
– Seq3(x,y,z), which is deﬁned as Seq2(x,y) ∪{[2, z]}, and
– operators of propositional and predicate calculus.

6.3
Axioms of Reﬂection
349
These conventions for encoding formulae are captured in the following (neces-
sarily case-ridden) deﬁnition of the predicate Is_formula, which the reader will want
to analyze closely.
Is_formula(f ) ↔

Is_seq(f ) &

∃g,h| Is_formula(g) & Is_formula(h) &

∃v | Is_integer(v) & f = Seq2(0,v)

∨f = Seq3(1,g,h) ∨f = Seq3(2,g,h) ∨f = Seq3(3,g,h)
∨f = Seq3(4,g,h) ∨f = Seq2(5,g) ∨f =

[0, 6]

∨f =

[0, 7]

∨

f = Seq3(8,g,h) & [0, 13] ∈g & [0, 13] ∈h

∨

f = Seq3(11,g,h) & [0, 13] ∈g & [0, 13] ∈h

∨

[0,9] ∈f & [1, g] ∈f &

∀j | (1 ∈j) →

∃v
 
j, [0, v]

∈f

∨

[0,10] ∈f & [1, g] ∈f &

∀j | (1 ∈j) →

∃v
 
j, [0, v]

∈f

∨

[0,12] ∈f &

∃v | Is_integer(v) &

1, Seq2(0,v)

∈f

&

∀j | (1 ∈j) →

∃sf | Is_formula(sf) &

[0,0] ∈sf ∨[0, 13] ∈sf

∨

[0,13] ∈f &

∃v | Is_integer(v) &

1, Seq2(0,v)

∈f

&

∀j | (1 ∈j) →

∃sf | Is_formula(sf) &

[0, 0] ∈sf ∨[0, 13] ∈sf

.
Note that the encoding of formulae deﬁned by the above formula uses sequences
Seq2(0,v), where v can be any integer, to encode variables, function symbols, and
predicate symbols, without explicitly stating that the integers v appearing in these
three different usages must be distinct. Thus in one setting Seq2(0,1) may desig-
nate a particular variable, but in another this same pair may designate a predicate
or function symbol, quite a different thing. Confusion is avoided by the fact that
these usages are distinguished by the contexts in which these pairs appear. Specif-
ically, predicate symbols (resp. function symbols) will only appear as the second
component of a sequence whose ﬁrst component is the code ‘12’ (resp. ‘13’), where
variables cannot appear. For example, in

[0, 12],

1, Seq2(0,1)

,

2, Seq2(0,1)

the ﬁrst occurrence of Seq2(0,1) unambiguously designates a predicate symbol and
the second occurrence of Seq2(0,1) unambiguously designates a variable. Thus if
we associate some predicate name like ‘Foo’ with appearances of Seq2(0,1) in
predicate contexts and choose to associate strings like ‘vn’ with appearances of
Seq2(0,n) as variables, the sequence seen above will decode unambiguously as
‘Foo(v1)’.
It is now easy to state a comprehensive set of rules for the operation ‘Subst’
which replaces every free occurrence of a variable x in a formula F with a des-
ignated subformula G. We also need the operation which calculates the set of all

350
6
Undecidability and Unsolvability
bound variables of a formula, and the operation which calculates all the free vari-
ables of a formula.
The following axiom deﬁnes the operation ‘Subst’.

f = Seq2(0,x) →Subst(f,x,g) = g

&

∃y
 
f = Seq2(0,y)

&

¬(y = x)

→Subst(f,x,g) = f

&

[0, 9] ∈f ∨[0, 10] ∈f

&

∃j | 1 ∈j & [j, x] ∈f

→
Subst(f,x,g) = f

&

[0, 9] ∈f ∨[0, 10] ∈f

&

¬

∃j | 1 ∈j & [j, x] ∈f

→

∃j,h,tail
 
f = Seq2(j,h) ∪tail

&

∀k,h2 | [k, h2] ∈tail →1 ∈k

& Subst(f,x,g) = Seq2

j, Subst(h,x,g)

∪tail

&

[0, 1] ∈f ∨[0, 2] ∈f ∨[0, 3] ∈f ∨[0, 4] ∈f ∨[0, 8] ∈f ∨[0, 11] ∈f

&

∃j,b,c | f = Seq3(j,b,c)
& Subst(f,x,g) = Seq3

j, Subst(b,x,g), Subst(c,x,g)

&

[0, 5] ∈f

&

∃j,b | f = Seq2(j,b) & Subst(f,x,g) = Seq2

j, Subst(b,x,g)

&

[0, 6] ∈f ∨[0, 7] ∈f

& Subst(f,x,g) = f
&

[0,12] ∈f ∨[0, 13] ∈f

&

∀y
 
[0, y] ∈f

↔

[0, y] ∈Subst(f,x,g)

&

∀y
 
[1, y] ∈f

↔

[1, y] ∈Subst(f,x,g)

&

∀y,j
 
1 ∈j →

[j, y] ∈f

↔

j, Subst(y,x,g)

∈Subst(f,x,g)

.
The following axiom deﬁnes the set of all bound variables of a formula.

¬Is_formula(f )

∨[0, 6] ∈f ∨[0, 7] ∈f

→Bound_vars(f ) = ∅

&

[0, 1] ∈f ∨[0, 2] ∈f ∨[0, 3] ∈f ∨[0, 4] ∈f ∨[0, 8] ∈f ∨[0, 11] ∈f

→

∃g,h| [1, g] ∈f & [2, h] ∈f
& Bound_vars(f ) = Bound_vars(g) ∪Bound_vars(h)

&

[0, 5] ∈f

→

∃g | [1, g] ∈f & Bound_vars(f ) = Bound_vars(g)

&

[0, 12] ∈f ∨[0, 13] ∈f

→Bound_vars(f ) = ∅

&

[0, 9] ∈f ∨[0, 10] ∈f

→

∃s
 
∀x | (x ∈s) ↔

∃j
 
[j, x] ∈f & 1 ∈j

&

∃g | [1, g] ∈f & Bound_vars(f ) = Bound_vars(g) ∪s

.

6.3
Axioms of Reﬂection
351
The following axiom deﬁnes the set of all free variables of a formula.

¬Is_formula(f ) ∨[0, 6] ∈f ∨[0, 7] ∈f

→

Free_vars(f ) = ∅

&

[0, 12] ∈f ∨[0, 13] ∈f

→

∀x
 
x ∈Free_vars(f )

↔

∃j,g | 1 ∈j & [j, g] ∈f
& x ∈Free_vars(g)

&

[0, 0] ∈f

→

∀x
 
x ∈Free_vars(f )

↔

[1, x] ∈f

&

[0, 1] ∈f ∨[0, 2] ∈f ∨[0, 3] ∈f ∨[0, 4] ∈f ∨
[0, 8] ∈f ∨[0, 11] ∈f

→

∃g,h| [1, g] ∈f & [2, h] ∈f
& Free_vars(f ) = Free_vars(g) ∪Free_vars(h)

&

[0, 5] ∈f

→

∃g | [1, g] ∈f & Free_vars(f ) = Free_vars(g)

&

[0, 9] ∈f ∨[0, 10] ∈f

→

∃s
 
∀x | (x ∈s) ↔

∃j | [j, x] ∈f & 1 ∈j

&

∃g | [1, g] ∈f &

∀y |

y ∈Free_vars(f )

↔

y ∈Free_vars(g) &

¬(y ∈s)

.
Our next step is to deﬁne the notion of predicate axiom in coded form. This
merely formalizes the statements made in our earlier discussion of the predicate
calculus. We begin with encodings of the list of propositional axioms given ear-
lier. Then encodings of predicate axioms (ii–v) follow, and ﬁnally encodings of the
equality-related predicate axioms (vi–viii). Predicate axiom (v) is simpliﬁed slightly
(but to an equivalent axiom) by insisting that a term substituted for a free vari-
able in a formula F must have no variables in common with the bound variables
of F .
Is_propositional_axiom(s) ↔

∃p,q,r | Is_formula(p) & Is_formula(q) & Is_formula(r) &

s = Seq3

4, Seq3(1,p,q), Seq3(1,q,p)

∨

s = Seq3

4, Seq3

1,p, Seq3(1,q,r)

, Seq3

1, Seq3(1,p,q),r

∨

s = Seq3

4, Seq3(1,p,p),p

∨

s = Seq3

4, Seq3(2,p,q), Seq3(2,q,p)

∨

s = Seq3

4, Seq3

2,p, Seq3(2,q,r)

, Seq3

2, Seq3(2,p,q),r

∨

s = Seq3

4, Seq3(2,p,p),p


352
6
Undecidability and Unsolvability
∨

s = Seq3

4, Seq2

5, Seq3(1,p,q)

,Seq3

2, Seq2(5,p), Seq2(5,q)

∨

s = Seq3

4, Seq2

5, Seq3(2,p,q)

,Seq3

1, Seq2(5,p), Seq2(5,q)

∨

s = Seq3

4, Seq3

1, Seq3(2,p,q),r

,
Seq3

2, Seq3(1,p,r),Seq3(1,q,r)

∨

s = Seq3

4, Seq3

2, Seq3(1,p,q),r

,
Seq3

1, Seq3(2,p,r),Seq3(2,q,r)

∨

s = Seq3

3, Seq3(4,p,q), Seq3

4,Seq3(1,p,r),Seq3(1,q,r)

∨

s = Seq3

3, Seq3(4,p,q), Seq3

4,Seq3(2,p,r),Seq3(2,q,r)

∨

s = Seq3

3, Seq3(4,p,q), Seq3

4,Seq2(5,p), Seq2(5,q)

∨

s = Seq3

4, Seq3(3,p,q), Seq3

2,Seq2(5,p),q

∨

s = Seq3

4, Seq3(4,p,q), Seq3

1,Seq3(3,p,q),Seq3(3,q,p)

∨

s = Seq3

3, Seq3(1,p,q),p

∨

s = Seq3

3, Seq3

1, Seq3(4,p,q),Seq3(4,q,r)

, Seq3(4,p,r)

∨

s = Seq3

3, Seq3(4,p,q), Seq3(4,q,p)

∨

s = Seq3(4,p,p)

∨

s = Seq3

4, Seq3

1,p, Seq2(5,p)

,Seq2(0,6)

∨

s = Seq3(4, Seq3

2,p, Seq2(5,p)

, Seq2(0,7))

∨

s = Seq3

4, Seq2

5, Seq2(5,p)

,p

∨

s = Seq3

4, Seq3

1,p, Seq2(0,7)

,p

∨

s = Seq3

4, Seq3

1,p, Seq2(0,6)

,Seq2(0,6)

∨

s = Seq3

4, Seq3

2,p, Seq2(0,7)

,Seq2(0,7)

∨

s = Seq3

4, Seq3

2,p, Seq2(0,6)

,p

∨

s = Seq2(0,7)

∨

s = Seq3

4, Seq3

1, Seq3(3,p,q),Seq3(3,q,p)

.
Having now deﬁned the notion of ‘propositional axiom’, we go on to describe
that of ‘predicate axiom’. Note that the coded forms of the predicate axioms listed
previously appear in the following formula in the order Axiom (ii), Axiom (iii),
Axiom (iv), Axiom (v).

6.3
Axioms of Reﬂection
353
Is_predicate_axiom(s) ↔

Is_propositional_axiom(s)∨

∃p,q,x,y,z,u,v,w,c,c1|
Is_formula(p) & Is_formula(q) & x = [0, u]
& y = [0, v] & z = [0, w] & c = [0, c1]
&

s = Seq3

3, Seq3

1, Seq3

9, Seq3(3,p,q), Seq2(0,x)

,
Seq3

9,p, Seq2(0,x)

,Seq3

9,q,Seq2(0,x)

∨

s = Seq3

4,Seq2

5,Seq3

9, Seq2(5,p), Seq2(0,x)

,
Seq3

10,p, Seq2(0,x)

∨

s = Seq3

4,p, Seq3(9,p, Seq2(0,x))

&

¬

x ∈Free_vars(p)

∨

∃g | Is_formula(g) & [0, 13] ∈g
&

¬

∃v | v ∈Free_vars(g) & v ∈Bound_vars(p)

&

s = Seq3

3,Seq3

9,p, Seq2(0,x)

, Subst(p,x,g)

.
The collection of axioms speciﬁc to set theory can now be deﬁned in coded form.
Of course, we need to deﬁne codes for the function and predicate symbols which
appear in these axioms. We do this as follows:
20: unordered pair,
21: ordered pair,
22: union sign ∪,
23: Is_next,
24: Is_integer,
25: Svm,
26: Is_seq,
27: Seq2,
28: Seq3,
29: null set symbol ∅,
30: power set symbol P.
Note that the axioms needed fall into two groups, a ﬁrst ‘specialized’ group corre-
sponding to the ten set-theoretic axioms displayed earlier in this section, and a re-
maining ‘general’ group corresponding to the standard ZFC axioms. The ﬁrst group
is needed to deﬁne various predicates and operators which appear along the path to
our ﬁnal deﬁnition of the provability predicate ‘Pr’, which we must deﬁne formally
in order to state our desired axioms of reﬂection. The second serve to ensure that
the set theory in which we are working behaves in the standard way.
With this understanding, we can encode the collection of ZFC axioms as follows.
Note that the ﬁrst two axioms encoded in what follows are the axiom of subsets and

354
6
Undecidability and Unsolvability
the axiom of replacement, the latter of these in the form

∀x,y,z
 
f & Subst(f,y,z)

→(y = z)

→

∀z
 
∃c
 
∀y | (y ∈c) ↔(∃x | x ∈z & f )

.
The remaining encoded axioms occur in the following order: axiom of subsets,
nullset axiom, power set axiom, union set axiom. axiom of inﬁnity, of choice, def-
inition of ‘Is_integer’, of ‘Is_map’, of ‘Is_seq’, axiom of extensionality, deﬁnition
of unordered pair, axiom of union of two sets, deﬁnition of ordered pair, and of
‘Is_ext’.
Is_ZF_axiom(s) ↔

∃a,b,f,m,n,n,s,t,u,w,x,y,z,
a1,b1,f 1,m1,n1,n1,s1,t1,u1,w1,x1,y1,z1|
a = Seq2(0,a1) & b = Seq2(0,b1) & f = Seq2(0,f 1) & m = Seq2(0,m1)
& n = Seq2(0,n1) & s = Seq2(0,s1) & t = Seq2(0,t1) & u = Seq2(0,u1)
& x = Seq2(0,x1) & y = Seq2(0,y1) & z = Seq2(0,z1)
&

Is_formula(f ) & x /∈Free_vars(f ) & z /∈Free_vars(f )

&

s = Seq3

9, Seq3

10, Seq3

9, Seq3

4, Seq3(11,y,z),
Seq3

1, Seq3(11,y,x),f

,y

,z

,x

∨

Is_formula(f ) & c /∈Free_vars(f ) & z /∈Free_vars(f )

&

s = Seq3

3, Seq3

9, Seq3

3, Seq3

1,f, Subst(f,y,z)

,
Seq3(8,y,z)

,x

∪

[3,y]

∪

[4,z]

,Seq3

9, Seq3

10, Seq3

9, Seq3

4,
Seq3(11,y,c), Seq3

10, Seq3

1, Seq3(11,x,z),f

,x

,y

,c

,z

∨

s = Seq2

9, Seq3

5, Seq3

11,x, Seq2

13,Seq2(0,29)

,x

∨

s = Seq3

9, Seq3

8, Seq3

11,z, Seq3

13, Seq2(0,30),t

,
Seq3

9, Seq3

4, Seq3(11,x,z), Seq3

9, Seq3

3, Seq3(11,y,x),
Seq3(11,y,t)

,y

,x

,z

∪

[3,t]

∨

s = Seq3

9, Seq3

10, Seq3

9, Seq3

4, Seq3(11,y,u),
Seq3

10, Seq3

1, Seq3(11,y,x), Seq3(11,x,z)

,x

,y

,u

,z

∨

s = Seq3

10,Seq3

1, Seq3

11, Seq2

13, Seq2(0,29)

,u

,
Seq3

9, Seq3

3, Seq3(11,z,u), Seq3

11,
Seq3

13, Seq2(0,20),z

∪

[3,z]

,u

,z

,u


6.3
Axioms of Reﬂection
355
∨

s = Seq2

5, Seq3

10, Seq3

1, Seq2

5, Seq3

8,x,
Seq2

13, Seq2(0,29)

, Seq3

9, Seq3

3, Seq3(11,y,x),
Seq3

10, Seq3

1, Seq3(11,z,x), Seq3(11,z,y)

,z

,y

,x

∨

s = Seq3

9, Seq3

4, Seq3

12, Seq2(0,24),n

, Seq3

9,
Seq3

3, Seq3

2, Seq3(11,x,n), Seq3(8,x,n)

, Seq3

2,
Seq3

8,x,Seq2

13,Seq2(0,29)

,Seq3

10,Seq3

1,
Seq3(11,y,x), Seq3

12, Seq2(0,23),x

∪

[3,y]

,y

,x

,n

∨

s = Seq3

9, Seq3

4, Seq3

13, Seq2(0,25),f

, Seq3

1, Seq3

9,
Seq3

3, Seq3(11,x,f ),Seq3

10, Seq3

8,x,Seq3

13,
Seq2(0,21),y

∪

[3,z]

,y

∪

[3,z]

,x

, Seq3

9, Seq3

3,
Seq3

1, Seq3

11, Seq3

13, Seq2(0,21),x

∪

[3,y]

,f

,
Seq3

11, Seq3

13, Seq2(0,21),x

∪

[3,z]

,f

,
Seq3(8,y,z)

,x

∪

[3,y],[4,z]

,f

∨

s = Seq3

9, Seq3

4, Seq3

12, Seq2(0,26),f

, Seq3

1, Seq3

12,
Seq2(0,25),f

, Seq3

10, Seq3

1, Seq3

12, Seq2(0,24),n

,
Seq3

9, Seq3

4, Seq3(11,x,f ), Seq3

10, Seq3

1, Seq3(11,m,n),
Seq3

8,x,Seq3

13,Seq2(0,21),m

∪

[3,y]

,y

∪

[3,m]

,x

,n

,f

∨

s = Seq3

9, Seq3

4, Seq3(8,a,b),Seq3

9, Seq3

4, Seq3(11,x,a),
Seq3(11,x,b)

,x

,a

∪

[3,b]

∨

s = Seq3

9, Seq3

4, Seq3

11,x, Seq3

13,Seq2(0,20),a

∪

[3,b]

, Seq3

2, Seq3(8,x,a), Seq3(8,x,b)

∪

[3,x],[4,a]

∪

[5,x]

,x

∪

[3,a]

∪

[4,b]

∨

s = Seq3

9, Seq3

4, Seq3

11,x, Seq3

13,Seq2(0,22),a

∪

[3,b]

, Seq3

2, Seq3(11,x,a), Seq3(11,x,b)

∪

[3,x]

∪

[4,a]

∪

[5,x]

,x

∪

[3,a]

∪

[4,b]

∨

s = Seq3

9, Seq3

8, Seq3

13, Seq2(0,21),x

∪

[3,y]

, Seq3

13,
Seq2(0,20), Seq3

13,Seq2(0,20), Seq3

13, Seq2(0,20),

356
6
Undecidability and Unsolvability
Seq3

13, Seq2(0,20),y

∪

[3,y]

∪

[3,y]

∪

3, Seq3

13, Seq2(0,20),x

∪

[3,x]

∪

3, Seq3

13, Seq2(0,20),x

∪

[3,x]

,x

∪

[3,y]

∨

s = Seq3

9, Seq3

4, Seq3

12, Seq2(0,23),s

∪

[3,t]

,
Seq3

9, Seq3

4, Seq3(11,x,t), Seq3

2, Seq3(11,x,s),
Seq3(8,x,s)

,x

,s

∪

[3,t]

.
We may also want to include some large-cardinal axiom. We saw in our discus-
sion of these axioms that multiple possibilities suggest themselves. Here is what is
required for a formal statement of one of them.
Ord(o) ↔

∀x ∈o,y
 
(y ∈x) →(y ∈o)

&

(y ∈o) →(x = y ∨x ∈y ∨y ∈x)

As_many(s,t) ↔

∃f | Svm(f ) &

∀y ∈t
 
∃x ∈s | [x,y] ∈f

Is_cardinal(o) ↔Ord(o) &

¬

∃x ∈o| As_many(x,o)

Is_regular_cardinal(o) ↔

¬

∃s,u
 
¬As_many(s,o)

&

∀y | (y ∈u)
↔(∃w ∈s | y ∈w)

&

∀y ∈s


¬As_many(y,o)

& As_many(u,o)

Is_strong_limit_cardinal(o) ↔

∀x ∈o
 
∃y ∈o| As_many

y,Pow(x)

Is_inaccessible_cardinal(o) ↔

Is_regular_cardinal(o)
& Is_strong_limit_cardinal(o)

Large_cardinal_axiom_1 ↔

∃o,s | Is_inaccessible_cardinal(o)
& As_many(s,o)
&

∀x ∈s | Is_inaccessible_cardinal(x) & x ∈o

.
The last formula in the group just shown asserts that there is an inaccessible car-
dinal M which is the Mth inaccessible cardinal. We saw in our earlier discussion of
large-cardinal axioms that this is implied by the assumption that there exists a Mahlo
cardinal. A somewhat weaker statement applies if we use H (M) as our model of
set theory. In this case all the inaccessible cardinals in M remain inaccessible, but
now there are too many of them to constitute a set. The statement that applies is then
Large_cardinal_axiom_2 ↔

∃o| Is_inaccessible_cardinal(o)

&

¬

∃s
 
∀x | x ∈s ↔Is_inaccessible_cardinal(x)

.

6.3
Axioms of Reﬂection
357
It results from our earlier discussion of set-theory models of the form H (n) that
if the ﬁrst set of large-cardinal axioms is assumed, it follows that there is a car-
dinal M such that H (M) is a model for the set of axioms obtained by replacing
Large_cardinal_axiom_1 with the weaker Large_cardinal_axiom_2.
The encodings of the large-cardinal axioms just stated constitute the set of
large_cardinal axioms, whose formal deﬁnition is as follows. Note that we use the
following codes for the function and predicate symbols which appear:
31: Ord,
32: As_many,
33: Card,
34: Is_regular_cardinal,
35: Is_strong_limit_cardinal,
36: Is_inaccessible_cardinal.
Note also that the encoded forms of the axioms listed above appear in what fol-
lows in the order deﬁnition of ordinal, of ‘As_many’, of ‘Is_regular_cardinal’, of
‘Is_limit_cardinal’, of ‘Inacessible_cardinal’, statement of Large_cardinal_axiom_1,
of Large_cardinal_axiom_2.
Is_largeN_axiom(s) ↔

∃v,o,x,u,y,w,s,s1,t,t1,f,f1 | o = Seq2(0,v) & x = Seq2(0,u)
& y = Seq2(0,w) & s = Seq2(0,s1) & t = Seq2(0,t1) & f = Seq2(0,f1)
&

s = Seq3

9, Seq3

4, Seq3

13, Seq2(0,31),o

, Seq3

9,Seq3

3,
Seq3(11,x,o), Seq3

1,Seq3

3, Seq3(11,y,x), Seq3(11,y,o)

, Seq3

3,
Seq3(11,y,o), Seq3

2,Seq3

2, Seq3(8,x,y),
Seq3(11,x,y)

, Seq3(11,y,x)

,x

∪

[3,y]

,o

∨

s = Seq3

9,Seq3

4, Seq3

13, Seq2(0,32),z

∪

[3,t]

, Seq3

10,
Seq3

1, Seq3

12, Seq2(0,25),f

, Seq3

9, Seq3

3,
Seq3(11,y,t), Seq3

10, Seq3

3, Seq3(11,x,z), Seq3

11, Seq3

12,
Seq2(0,21),x

∪

[3,y]

,f

,x

,y

,f

,z

∪

[3,t]

∨

s = Seq3

9,Seq3

4, Seq3

13, Seq2(0,34),o

, Seq2

5, Seq3

10,
Seq3

1, Seq2

5, Seq3

13, Seq2(0,32),s

∪

[3,o]

, Seq3

1, Seq3

9,
Seq3

4, Seq3(11,y,t), Seq3

10, Seq3

1, Seq3(11,x,s),
Seq3(11,y,x)

,x

,y

, Seq3

1, Seq3

9, Seq3

3, Seq3(11,y,s),
Seq2

5, Seq3

13, Seq2(0,32),y

∪

[3,o]

,y

,
Seq3

13, Seq2(0,32),t

∪

[3,o]

,s

∪

[3,t]

,o


358
6
Undecidability and Unsolvability
∨

s = Seq3

9,Seq3

1, Seq3(12,35,o), Seq3

9, Seq3

3, Seq3(11,x,o),
Seq3

10, Seq3

1, Seq3(11,y,o), Seq3

13, Seq2(0,32),y

∪

3,P(x)

,y

,x

,o

∨

s = Seq3

9,Seq3

4, Seq3

12, Seq2(0,36),o

, Seq3

1, Seq3

12,
Seq2(0,34),o

, Seq3

12, Seq2(0,35),o

,o

∨

s = Seq3

10,Seq3

1,Seq3

12,Seq2(0,36),o

, Seq3

1, Seq3

13,
Seq2(0,32),y

∪

[3,o]

,Seq3

9, Seq3

3, Seq3(11,x,y), Seq3

1,
Seq3

12, Seq2(0,36),x

, Seq3(11,x,o)

,x

,o

∪

[3,y]

∨

s = Seq3

10,Seq3

1,Seq3

12,Seq2(0,36),o

, Seq2

5,

Seq3

10,
Seq3

9, Seq3

4, Seq3(11,x,s), Seq3

12,
Seq2(0,36),x

,s

,o

.
The slightly weakened large-cardinal axiom displayed above is encoded by the
ﬁnal clause of this last display.
We can now assert that a formula is an axiom if and only if it belongs to one of
the three preceding groups of axioms, and go on to deﬁne the notions ‘a sequence
of statements is a proof’, and ﬁnally our target ‘f is provable’.
Is_axiom(f ) ↔

Is_predicate_axiom(f ) ∨Is_ZF_axiom(f ) ∨Is_largeN_axiom(f )

Is_proof(p) ↔

Is_seq(p) &

∀y ∈p
 
∃n,g | y = [n, g] & Is_formula(g) &

Is_axiom(g) ∨

∃m ∈n,h
 
[m, h] ∈s

&

∃v | g = Seq3(9,v,h)

∨

∃m ∈n, k ∈n,h
 
[m, h] ∈s

&

k, Seq3(3,h,g)

∈s

Pr(f ) ↔

∃p,n| Is_proof(p) & [n, f ] ∈p

.
Note in connection with the preceding that

∃v | g = Seq3(9,v,h)

states that g arises from h by a generalization step, and that

k, Seq3(3,h,g)

∈s
states that g arises from h and some preceding formula by a modus ponens step.

6.3
Axioms of Reﬂection
359
6.3.1 Statement of the Axioms of Reﬂection
Having now managed to include the ‘provability’ predicate that concerns us in an
extension of the ZFC axioms in whose consistency we have some reason to believe,
we can reach our intended goal by stating the axioms of reﬂection. These are simply
all statements of the form
Pr(‘F’) →F,
where F is any syntactically well-formed formula of our set-theoretic language, and
‘F ’ is its syntax tree, encoded in the manner described above.
Potential uses of these axioms have been explained above. Of course, we only
want to add axioms of reﬂection to our basic set if inconsistency does not result.
We shall now prove that this must be true if we assume that there exists at least one
inaccessible cardinal but do not include this assumption in the set of axioms which
enter into the deﬁnition of the predicate Pr. More generally, consistency is ensured
if we assume that there exists an inaccessible cardinal, but in the axioms which enter
into the deﬁnition of the predicate Pr we include only a large-cardinality statement
that is true for the set of all cardinals M less than N.
So the setting in which we work is as follows. We let N be an inaccessible car-
dinal, and let U = H (N) be the set deﬁned recursively by
H_(x) =Def if x = ∅then ∅
else
	
P

H_(y)

: y ∈x

end if
and
H (N) =Def
	
H_(n): n ∈N

,
as in Chap. 2, so that, as shown there, all of the axioms of set theory remain valid if
we restrict our universe of sets to U . This statement makes reference to the set U ,
hence to N, and so is a theorem of the extension ZFC+ of ZFC in which an axiom
stating the necessary properties of N, for example stating that it is an inaccessible
cardinal, is present.
For each syntactically well-formed formula F, we let F U be the result of rela-
tivizing F to U in the following way. We process the syntax tree of F, modifying
quantiﬁer nodes but leaving all other nodes unchanged. Each universal quantiﬁer
(∀x1,...,xn | P)
is changed into

∀x1,...,xn | (x1 ∈U & ··· & xn ∈U ) →P

.
Each existential quantiﬁer
(∃x1,...,xn | P)

360
6
Undecidability and Unsolvability
is changed into
(∃x1,...,xn | x1 ∈U & ··· & xn ∈U & P).
We let A0 be the assignment which maps the collection of predicate and func-
tion symbols which appear in the chain of deﬁnitions leading up to the deﬁnition
of the provability predicate Pr (or, more properly, maps the integers which encode
these symbols) in the following way. (The symbols in question are: =, ∈, {·,·} (un-
ordered pair), [·,·] (ordered pair), ∪, Is_next, Is_integer, Svm, Is_seq, Seq2, Seq3,
{} (nullset), P.)
=
is mapped into {[[x,y], if x = y then 1 else 0 end if ]: x ∈U ,y ∈U }
∈
is mapped into {[[x,y], if x ∈y then 1 else 0 end if ]: x ∈U ,y ∈U }
{·,·}
is mapped into {[[x,y],{x,y}]: x ∈U ,y ∈U }
[·,·]
is mapped into {[[x,y],[x,y]]: x ∈U ,y ∈U }
∪
is mapped into {[[x,y],x ∪y]: x ∈U ,y ∈U }
Is_next
is mapped into {[[x,y], if y = x ∪{x} then 1 else 0 end if ]:
x ∈U ,y ∈U }
Is_integer is mapped into {[x, if x ∈N then 1 else 0 end if ]: x ∈U }
(where as usual N is the set of ﬁnite ordinals)
Svm
is mapped into {[f, if
(∃x ∈U ,y ∈U ,z ∈U | [z,x] ∈f
& [z,y] ∈f & x ̸= y)
∨(∃z ∈f | (∀x ∈U ,y ∈U | z ̸= [x,y])) then 0
else 1 end if ]: f ∈U }
Is_seq
is mapped into {[x, if Svm(x) & domain(x) ∈N then 1
else 0 end if ]: x ∈U }
Seq2
is mapped into {[[x,y], {[0,x],[1,y]}]: x ∈U ,y ∈U }
Seq3
is mapped into {[[x,y,z], {[0,x],[1,y],[2,z]}]: x ∈U ,y ∈U ,z∈U }
P
is mapped into {[x,{y : y ⊆x}]: x ∈U }
{}
is mapped into ∅
The following lemma states the intuitively obvious property of this assignment
that we need below.
Lemma 6.1 (Evaluation lemma) Let N, H (N), U , ZFC+, and A0 be as above,
and for each syntactically well-formed formula F let F U be as above, and let ‘F ’
denote the syntax tree of F . Given any list of variables v1,...,vn and an equally
long list x1,...,xn of elements of U let A0(v1 →x1,...,vn →xn) be the assign-
ment which maps each vj into the corresponding xj.
Then if x1,...,xn is the list of free variables of F , and ‘xj’ designates the symbol
naming the jth of these variables for each j between 1 and n, it follows that

∀x1 ∈U ,...,xn ∈U
 
Val

A0(‘x1’ →x1,...,‘xn’ →xn),‘F ’

= 1

↔F U 
is a theorem of ZFC+.

6.3
Axioms of Reﬂection
361
Lemma 6.2 (Evaluation lemma for terms) Let N, H (N), U , and A0 be as above,
and for each syntactically well-formed term F let F U be as above, and let ‘F ’
denote the syntax tree of F .
Then if x1,...,xn is the list of variables of F , and ‘xj’ designates the symbol
naming the jth of these variables for each j between 1 and n, it follows that

∀x1 ∈U ,...,xn ∈U | Val

A0(‘x1’ →x1,...,‘xn’ →xn),‘F ’

= F

is a theorem of ZFC+.
Corollary 6.1 Under the same hypotheses as above, suppose that the formula F
contains no free variables. Then

Val(A0,‘F ’) = 1

↔F U
is a theorem of ZFC+.
We prove the evaluation lemmas by induction on the size of the syntax tree of F ,
starting with the evaluation lemma for terms. If a term is just a variable x, then
Val

A0(‘x’ →x), ‘x’

= x
for each x, so the lemma holds in this case. If a term is formed directly from one
of the primitives used above by supplying the appropriate number of variables as
arguments to the primitive, as for example in ‘{x,y}’, then we have
Val

A0(‘x’ →x0,‘y’ →y0),‘{x,y}’

=

[x,y],{x,y}

: x ∈U ,y ∈U

(x0,y0) = {x0,y0}
for all x0 and y0 in U , so the lemma holds in this case also. Similarly elementary
observations cover all the other function symbols appearing in the list of symbols
displayed above, namely [·,·], ∪, Seq2, Seq3, and P. The reader is invited to sup-
ply details.
Now suppose that the evaluation lemma for terms fails for some F , and, proceed-
ing inductively, that it fails for no term having a syntax tree smaller than that of F .
Then F must have the form
f (t1,...,tk),
where f is one of the primitive function symbols appearing in the list displayed
above and t1,...,tk are subterms. By deﬁnition we have
Val

A0(v1 →x1,...,vn →xn),‘f (t1,...,tk)’

= A0(‘f ’)

Val

A0(v1 →x1,...,vn →xn),‘t1’

,...
..., Val

A0(v1 →x1,...,vn →xn),‘tk’

.

362
6
Undecidability and Unsolvability
By inductive hypothesis, the statement

∀x1 ∈U ,...,xn ∈U | Val

A0(‘x1’ →x1,...,‘xn’ →xn),‘tj’

= tj

is a theorem of ZFC+ for each j from 1 to k, where x1,...,xn is the list of all free
variables appearing in any of the terms tj. Hence we have

∀x1 ∈U ,...,xn ∈U | Val

A0(‘x1’ →x1,...,‘xn’ →xn),
‘f (t1,...,tk)’

= A0(‘f ’)(t1,...,tk)

.
Now we need to consider the function symbols appearing in the list displayed above,
namely {·,·}, [·,·], ∪, Seq2, Seq3, and P. The argument is much the same in all of
these cases. For example, for the powerset symbol P we have
A0(‘P’)(t1) =

x,

y : y ⊆x

: x ∈U

(t1) = {y : y ⊆t1} = P(t1),
so

∀x1 ∈U ,...,xn ∈U | Val

A0(‘x1’ →x1,...,‘x1’ →xn),‘P(t1)’

= P(t1)

,
proving our claim in this case. The reader is invited to supply the corresponding
details in the remaining cases, namely {·,·}, [·,·], ∪, Seq2, and Seq3. Together,
these prove the evaluation lemma for terms in all cases.
Next we prove the evaluation lemma for formulae, beginning with atomic for-
mulae, whose lead symbols must be one of the predicate symbols appearing in the
list above, namely =, ∈, Is_next, Is_integer, Svm, Is_seq. Consider for example the
case of an atomic formula whose lead symbol is ∈. This must have the form
t1 ∈t2
where t1 and t2 are terms, and so by deﬁnition and using the evaluation lemma for
terms we have

∀x1 ∈U ,...,xn ∈U | Val

A0(‘x1’ →x1,...,‘xn’ →xn),‘t1 ∈t2’

↔A0(‘∈’)

Val

A0(‘x1’ →x1,...,‘xn’ →xn),‘t1’

,
Val

A0

‘x1’ →x1,...,‘xn’ →xn

,‘t2’

= A0(‘∈’)(t1,t2)
=

[x,y],if x ∈y then 1 else 0 end if

: x ∈U ,y ∈U

(t2,t2)
= if t1 ∈t2 then 1 else 0 end if .
Hence

∀x1 ∈U ,...,xn ∈U
 
Val

A0(‘x1’ →x1,...,‘xn’ →xn),‘t1 ∈t2’

= 1

↔
t1 ∈t2

,

6.3
Axioms of Reﬂection
363
proving our claim for atomic formulae whose lead symbol is ∈. The reader is in-
vited to supply the corresponding details in the remaining cases, namely =, Is_next,
Is_integer, Svm, Is_seq. Together, these cover all atomic formulae.
General formulae are built from atomic formulae by repeated application of the
propositional operators &, ∨, →, ↔, ¬, and the two predicate quantiﬁers. Inductive
arguments like those just given apply in all these cases. For example, if f has the
form ‘g & h’, where g and h both satisfy the conclusion of the Evaluation Lemma,
and our notations are as above, then

Val

A0(‘x1’ →x1,...,‘xn’ →xn),‘g & h’

= 1

↔min

Val

A0(‘x1’ →x1,...,‘xn’ →xn),‘g’

,
Val

A0(‘x1’ →x1,...,‘xn’ →xn),‘h’

= 1
↔

Val

A0(‘x1’ →x1,...,‘xn’ →xn),‘g’

= 1
& Val

A0(‘x1’ →x1,...,‘xn’ →xn),‘h’

= 1
↔

gU & hU 
↔(g & h)U ↔f U .
Next suppose that f has the form
(∀y1,...,yk | g),
(6.4)
where g satisﬁes the conclusion of the Evaluation Lemma. Since both f U and
Val(A′′,f ) (for any suitable assignment A′′) are unchanged if variables yj not free
in g and repeated copies of variable are dropped from y1,...,yk, we can suppose
that there are none such. Hence, if the free variables of formula (6.4) are x1,...,xn,
then the free variables of g are x1,...,xn,y1,...,yk. Therefore

Val

A0(‘x1’ →x1,...,‘xn’ →xn),‘(∀y1,...,yk | g)’

= 1

↔
min

Val(A′
0,‘g’)

,
where the minimum is extended over all assignments A′
0 which cover all the vari-
ables ‘x1’,...,‘xn’ and ‘y1’,...,‘yk’, and which agree with
A0(‘x1’ →x1,...,‘xn’ →xn)
except possibly on the variables ‘y1’,...,‘yk’. That is,

Val

A0(‘x1’ →x1,...,‘xn’ →xn),‘(∀y1,...,yk | g)’

= 1

↔min

A0(‘x1’ →x1,...,‘xn’ →xn,‘y1’ →y1,...,‘yk’ →yk),‘g’

,
where now the minimum is extended over all possible values of y1,...,yk, all be-
longing to U . Hence, since by inductive assumption we have

364
6
Undecidability and Unsolvability

∀x1,...,xn,y1,...,yk
 
Val

A0(‘x1’ →x1,...,‘xn’ →xn,
‘y1’ →y1,...,‘yk’ →yk),‘g’

= 1

↔g

,
it follows that

Val

A0(‘x1’ →x1,...,‘xn’ →xn),‘(∀y1,...,yk | g)’

= 1

↔

∀y1,...,yk | Val

A0(‘x1’ →x1,...,‘xn’ →xn,
‘y1’ →y1,...,‘yk’ →yk),‘g’

= 1

↔(∀y1,...,yk | g),
verifying the Evaluation Lemma in this case also.
The reader is invited to supply the details of the remaining cases.
This concludes our proof of the Evaluation Lemma.
Next we note and will prove the following fact concerning the value Val(A0,F)
for every formula provable from the axioms of ZFC, as possibly extended by a
collection of large-cardinal axiom like those displayed above. To avoid too much
obscuring detail, we shall state and prove this fact using English in the normal way
to abbreviate formal set-theoretic details.
Lemma 6.3 Let ZFC∗be the collection of axioms of ZFC, possibly extended by a
set of large-cardinal axioms like those displayed above. Let Pr be the proof predicate
deﬁned by these axioms in the manner detailed above. Let CFP all the function and
predicate symbols that appear in the axioms ZFC∗. Let Is_assignment(A,U ) be the
set-theoretic formula which asserts that A is an assignment with universe U , and
let True_on_ax(A) be the formula which asserts that Val(A,s) = 1 for the encoded
form of every axiom of ZFC∗. (The reader is invited to write out the details of these
formulae.) Then

∀s
 
Pr(s) & Is_assignment(A0,U ) & True_on_ax(A0)
& domain(A0) ⊇

Free_vars(s) ∪CFP

→Val(A0,s) = 1

is a theorem of ZFC.
Proof Suppose not, so that there exist A0, U , and s satisfying
Pr(s) & Is_assignment(A0,U ) & True_on_ax(A0)
& domain(A0) ⊇

Free_vars(s) ∪CFP

& Val(A0,s) = 0.
Using the deﬁnition of ‘Pr’, it follows that there exists a p such that

6.3
Axioms of Reﬂection
365
Is_proof(p) & Is_integer(n) & [n,s] ∈p & Is_assignment(A0,U ) &
True_on_ax(A0) & domain(A0) ⊇

Free_vars(s) ∪CFP

& Val(A0,s) = 0.
The induction principle available in ZF set theory allows us to improve this last
statement to
Is_proof(p) & Is_integer(n) & [n,s] ∈p & Is_assignment(A0,U )
& True_on_ax(A0)
& domain(A0) ⊇

Free_vars(s) ∪CFP

& Val(A0,s) = 0
&

∀m ∈n,t | [m,t] ∈p →

∀A1
 
Is_assignment(A1,U ) & True_on_ax(A1)
& domain(A1) ⊇

Free_vars(t) ∪CFP

→

Val(A1,t) = 1

.
By the deﬁnition of Is_proof, we have
Is_axiom(s) ∨

∃m ∈n,h| ([m,h] ∈p)

&

∃v | s = Seq3(9,v,h)

∨

∃m ∈n,k ∈n,h|

[m,h] ∈p

&

k,Seq3(3,h,s)

∈p

.
(6.5)
The alternative Is_axiom(s) of (6.5) is ruled out since in this case we have
Val(A0,s) = 1 from True_on_ax(A0). In the second case of (6.5) there exist m,
h, and v such that
m ∈n & [m,h] ∈p & s = Seq3(9,v,h).
It follows from ‘m ∈n’ that

domain(A) ⊇

Free_vars(g) ∪CFP

→

Val(A,h) = 1

for any assignment A that agrees with A0 on CFP. Since s = Seq3(9,v,h), which
states that the decoded version of s has the form
(∀v | d)
where d is the decoded form of h, it follows that for each assignment A′ for which
domain(A′) ⊇

Free_vars(s) ∪CFP

that agrees with A0 on CFP we must have Val(A′,s) = 1, since this is a minimum of
values Val(A,h), extended over assignments A that agree with A′ on Free_vars(s)∪
CFP . Hence Val(A0,s) = 0 is impossible in the second case of (6.5) also. In the
remaining case there exist formulae h and g, and integers m and k ∈n, such that
[m,h] ∈p & [k,g] ∈p & m ∈n & k ∈n & g = Seq3(3,h,s).

366
6
Undecidability and Unsolvability
It follows as above that

domain(A) ⊇

Free_vars(g) ∪CFP

→

Val(A,h) = 1 & Val(A,g) = 1

,
for each assignment A that agrees with A0 on CFP. From this it follows that

domain(A) ⊇

Free_vars(g) ∪CFP

→

Val(A,s)

,
since g = Seq3(3,h,s) states that the decoded form of g is e →d, where e and d
are the decoded forms of h and s, respectively. But any assignment A′ such that

domain(A′) ⊇

Free_vars(s) ∪CFP

can be extended to an assignment satisfying domain(A) ⊇(Free_vars(g) ∪CFP)
by deﬁning it arbitrarily on the elements of the difference set Free_vars(g) \
Free_vars(s), and plainly Val(A′,s) = Val(A,s) for any such assignment. Hence

domain(A′) ⊇

Free_vars(s) ∪CFP

→

Val(A,s′)

,
for each assignment A that agrees with A0 on CFP. This rules out the third alterna-
tive of (6.5) and so concludes our proof of the lemma.
□
The following statement now follows easily from the lemmas proved above.
Theorem 6.7 Let ZFC+ be the ZFC axioms of set theory, supplemented by an axiom
stating that there exists at least one inaccessible cardinal N. Let A0 be the model of
set theory with universe H (N) described above. Then it is a theorem of ZFC+ that
A0 is a model in which all the axioms of ZFC, plus all the reﬂection axioms
Pr(‘F’) →F,
where F is any syntactically legal formula and ‘Pr’ means ‘provable from the ax-
ioms of ZFC’ (without the axiom of existence of an inaccessible cardinal) are true.
Hence it follows from the axioms of ZFC+ that this set of axioms is consistent.
Proof The proof is simply as follows. Let F be a syntactically legal formula without
free variables. Corollary 6.1 tells us that

Val(A0,‘F’) = 1

↔F U
is a theorem of ZFC+, and Lemma 2 tells us that
Pr(‘F’) →

Val(A0,s) = 1

is a theorem of ZFC. Our theorem follows immediately from these two state-
ments.
□
The authors are indebted to Prof. Mark Fulk for suggesting the line of thought
developed in this section. Prof. Luigia Carlucci Aiello and Richard Weyhrauch have
explored similar ideas in [AW80].

6.4
A Digression Concerning Foundations
367
6.4 A Digression Concerning Foundations
Absolute, true, and mathematical time, of itself, and from its own nature ﬂows equably
without regard to anything external [··· ] Absolute space, in its own nature, without regard
to anything external, remains always similar and immovable.
Isaac Newton, Principia, 1687
Much has been written about the broader signiﬁcance of Gödel’s results. The ﬁrst
Gödel theorem (undecidability) is best viewed as a special case of Chaitin’s more
general result, which states a general limit on the power of formal logical reasoning.
Speciﬁcally, Chaitin exhibits a large class of statements which can be formalized
but not formally proved. But why, in hindsight, should it ever have been expected
that every statement which can be written in a formalism can also be proved in the
formalism? There is plainly no reason why this should be so, and much prior math-
ematical experience points in the opposite direction (for example, few elementary
functions have elementary integrals).
Gödel’s theorems cast some light on the classical philosophical distinction be-
tween analytic (a priori) knowledge and the kind of inductive knowledge for which
the scientist strives. The boundary lines drawn between these two realms of knowl-
edge have shifted in the course of time. As illustrated by the famous nineteenth
century changes in the dominant view of geometry, the analytic realm has steadily
lost ground to the inductive realm. Originally the axioms of geometry were seen as
statements about the physical universe, involving idealizations (e.g. consideration
of points of zero extension and lines of zero thickness) which did not misrepre-
sent physical reality in any signiﬁcant way. Now the dominant view is that space is
probably not Euclidean, and may not even be continuous. This means that classical
geometry is but a crudely approximate model of some aspects of physical reality,
and that the best evidence for the consistency of its traditional axioms is the fact
that they have a formal set-theoretic model. Few will now include more than arith-
metic, and perhaps abstract set theory, in the analytic realm. But if the theorems of
arithmetic are analytic knowledge, but not knowledge of the physical world, what
are they knowledge about? Perhaps they represent a priori knowledge about com-
putation. Let us consider this possibility.
To use reasoning in a particular logical system as a surrogate for computation, we
need only be certain that the logical system in which we reason should be consistent.
But, since Gödel’s second theorem tells us that formal proof of the consistency of a
system L requires use of a system different from L and probably stronger than L,
how can such certainty ever be achieved? One way in which such a belief, though of
course no certainty, can arise is by the accumulation of experience with the objects
of a certain realm, leading to formulation of statements concerning the entities of
that realm. Generalized and formalized, these can subsequently become the axioms
and theorems of a fully elaborated formal system. If experience then seems to show
that the resulting formal system is consistent, this may be taken as evidence that its
theorems are true statements about objects of some kind.
The hope of grounding mathematics, and hence the analytic truths which it may
claim to embody, on a set of intuitions less tenuous than those available in a set

368
6
Undecidability and Unsolvability
theory incorporating Cantor’s aggressive linguistic extensions has lent interest to
various narrower formalisms. The most important of these is the pure theory of
integers, in the form given it by Peano. Integers originally come into one’s ken as the
words ‘zero, one, two, three, ...’ of a kind of poem which, as a child, one learns to
repeat, and with whose indeﬁnite extensibility one becomes familiar. (The simplest,
though not the most convenient, form of the number poem is its monadic version:
‘one, one-and-one, one-and-one-and-one, ...’) Experience with such collections of
words leads to the following generalizations: (i) given any such word, there is a way
of forming the very next word in the series; (ii) no word occurs twice in the series
thereby generated; (iii) If one starts with any word in the sequence and repeatedly
steps back from words to their predecessors, one will eventually reach zero.
Peano’s axioms formalize these intuitions. They can be stated as follows:
1. (i) 0 is a natural number.
2. (ii) For every natural number x there exists another natural number x′ called
the successor of x.
3. (iii) ¬(0 = x′) for every natural number x (x′ being the successor of x).
4. (iv) If x′ = y′ then x = y.
5. (v) If Q is a property of natural numbers and x is a number such that Q(0) ̸=
Q(x), then there exists a natural number y such that Q(y) ̸= Q(y′).
A compelling way of linking Peano’s axioms to primitive physical experience is
to regard them as statements about integers in monadic notation, i.e. sequences of
marks having the form
/ // /// //// ···
(The empty sequence is allowed.) In physical terms, two such sequences are equal
if their ends match when the sequences are set side by side. An extra mark can be
added to the end of any such sequence, giving Peano’s successor operation x′. If
a sequence s is non-empty, we can erase one mark from its end, giving the ‘Prev’
operation. Experience indicates that Prev(x′) = x (erasing a mark just added to x
restores x), and that if x is not empty Prev(x)′ = x (adding back a mark just removed
from x restores x). Peano’s axioms (ii–iv) follow readily from these statements.
Experience also indicates that if marks are repeatedly erased from the end of any
such x the empty string will eventually result. If Q(x) is any stable property of such
sequences of marks, this gives us a systematic way of searching for two successive
integers y, y′ for which Q(y) and Q(y′) are different, and so justiﬁes Peano’s axiom
(v) of induction.
But the following objection can be raised to the universal quantiﬁcation of these
axioms. Physics tells us that sufﬁciently large sequences of marks need not behave
in the same way as shorter sequences. For example, even if marks are stored in the
most compact way likely to be feasible, as states of single atoms, it is probably not
possible to store more than 1027 marks per kilogram of matter. 1057 marks would
therefore have a mass roughly equal to that of the sun, and so could be expected to
ignite a nuclear chain reaction spontaneously. The mass of our galaxy is unlikely to
be more that 1013 times larger, so 1070 marks would have a mass larger than that

6.4
A Digression Concerning Foundations
369
of our galaxy. Compactly arranged, these marks would promptly disappear into a
black hole. This makes it plain that integers larger than 21070 are ﬁctive constructs,
which can never be written out fully even in monadic notation. This suggests that
denotations like 1010101010
of much larger integers should be viewed as logical speci-
ﬁcations Exp(10, Exp(10, Exp(10, Exp(10,10)))) of hypothetical computations that
can in fact never be carried out. However, this does not make them useless, since
we can reason about them in a system believed to be consistent, and such reasoning
may lead us to useful conclusions about other, perfectly feasible, computations.
Note also that the direct evidence we have for the consistency of any logical
system can never apply to proofs more than 1070 steps in length, since for the rea-
sons stated above we can never expect to write out any such proof. Of course, this
does not prevent us from reasoning about much longer proofs, but as above it may
be best to regard such reasoning as the manipulation of marks in some formalized
meta-logical system believed to be consistent.
Any attempt to move the consistency of Peano’s full set of statements from ‘be-
lief’ to ‘certainty’ would therefore seem to rest on a claim that there really exists
a Platonic universe of objects, for example idealized integers, about which our ax-
ioms are true statements, and hence necessarily consistent. But how can truths about
such Platonic universes be known reliably? Two methods, direct intuition and rea-
soning from consequences, suggest themselves. Claims concerning direct intuition
are doubtful. If direct intuition is admitted as a legitimate source of knowledge, how
can we decide between the rival claimants to direct intuition, if their claims dif-
fer? And, even if we can convince ourselves that all normal humans have the same
intuition, why should the objective truth of this intuition be admitted? In biological
terms the human differs little from the nematode, except for possessing limbs and an
enlarged nervous system. Like the squid, we have a highly elaborated visual system.
Beyond this, we have an ability to deal with language, and so to deal with abstract
patterns. But, as work with visual illusions shows plainly, even stable, immediate,
compelling, and universally shared perceptions about physical reality can be wrong.
Even such immediate perceptions do not tell us what the world really contains, but
only how our nervous systems react to that content. Why should the far more elu-
sive mechanisms of logical intuition be more trustworthy? To move towards truth
we must employ the patient and never conclusive methods of experimental science,
and experience shows science to progress best when it tries actively to probe the
limits of its own best current view.
A ‘realist’ or ‘Platonist’ view, reﬂecting the belief that the statements of mathe-
matics are truths about some partly but progressively comprehended class of ideal
objects can be stated as follows. Of all formally plausible axioms (for example,
statements asserting the existence of various kinds of very large cardinal numbers)
not provable from assumptions presently accepted, a growing and coherent collec-
tion, this view predicts, will prove to be particularly rich in consequences, including
consequences for questions that can be stated in currently accepted terms, but not
settled. These new axioms may be taken to hint at an underlying truth. The nega-
tives of these progressively discovered axioms will prove to be unfruitful and so will
gradually die out as dead ends.

370
6
Undecidability and Unsolvability
In contrast, a more purely formalist view of the situation suggests that this may
not prove to be the case, but that as collections of axioms rich in interesting conse-
quences are found these collections will prove to be mutually contradictory and so
not suggestive of any progressively revealed underlying truth. It further suggests that
a useful path to progress may lie in the attempt to undercut existing axiom systems
by looking for competing and incompatible systems identical with current systems
only in areas covered by actual experience.
The theory of hereditarily ﬁnite sets presented in the preceding pages is logically
equivalent to Peano’s theory of integers, in the sense that (as we have shown) in-
tegers can be modelled within this restricted theory of sets, while conversely the
hereditarily ﬁnite sets can be encoded as integers. However the theory of hereditar-
ily ﬁnite sets has a considerably richer intuitive content. Peano’s system captures
only the process of counting, but without anything to count, or indeed any evident
way of capturing the notion of 1-1 correspondence fundamental to the actual use of
counting. The axiomatization of hereditarily ﬁnite sets given above is better in this
regard, since it makes notions like mapping and function value more accessible.
Cantor’s full theory of inﬁnite sets goes beyond Peano’s system, and is in fact
strong enough to allow proof that Peano’s system is consistent. However, in formal
terms the step from the theory of hereditarily ﬁnite sets to the full Cantor theory is
slight. Three changes sufﬁce. First, an axiom of inﬁnity (existence of at least one
inﬁnite set) must be added, and the subset induction principle abandoned in favour
of the more limited principle of membership induction. Then the existence of the set
of all subsets of a given set, which follows as a theorem in the theory of hereditarily
ﬁnite sets, must be assumed as an axiom. Why do we assume that these changes
leave set theory consistent?
The answer is in part historical. The application of set-theoretic reasoning in ge-
ometric and analytic situations dominated by the notion of the ‘continuum’ led to
Cantor’s theory of inﬁnite sets. In Descartes’ approach to geometry the real line is
ultimately seen as the collection of all inﬁnite decimals, which naturally introduces
work with sets whose elements have no natural enumerated order. Further geometric
and analytic studies of important point loci lead to work with increasingly general
subsets of the real line. Out of such work the conviction grows that much of what
can be said about inﬁnite collections is entirely independent of the manner in which
they are ordered, and so requires no particular ordering. This linguistic generaliza-
tion was made systematically by Cantor, who then moved on to unrestrained discus-
sions of sets, involving such notions as the set of all subsets of an inﬁnite set. This
led him to consider statements concerning sets which are (more and more) uncount-
ably inﬁnite. Of course, as such generalized language moves away from the areas
of experience in which it originates, the evidence that what is being said is more
than word-play destined to collapse either in self-contradiction or in collision with
some more useful logical system, becomes increasingly tenuous. Fears of this kind
certainly surrounded Cantor’s work in its early decades, as indicated by his 1883
remark “[···] I realise that in this undertaking I place myself in a certain opposition
to views widely held concerning the mathematical inﬁnite and to opinions on the
nature of numbers frequently defended”, and by Kronecker’s remark that Cantor’s

References
371
new set theory was ‘a humbug’. And in fact set theory, in the over-generalized form
initially given it by Cantor, does lead to inconsistencies if pushed to the limit, as
Cantor was pushing so many of his set-theoretic ideas. However, this fact did not
lead to the collapse of the theory, but only to its repair. Such repair, in a manner
preserving the validity of Cantor’s general approach and all of his appealing state-
ments concerning inﬁnite sets, underlies the formalized set theory used in this book.
It leads to a formalism that, as far as we know, is consistent, and that provides a
good foundation for the now immense accumulation of work in mathematical anal-
ysis. Cumulatively this work gives evidence for the consistency of set theory that
is just as compelling as the like evidence of the consistency of arithmetic. Only the
existence of a set-theoretic proof that arithmetic is consistent, and of an arithmetic
proof that no such proof is possible in pure arithmetic, would seem to justify a much
greater degree of conﬁdence in the consistency of the one rather than the other of
these systems.
The remarks made in the preceding paragraphs suggest the following cautious
view of the distinction between analytic and inductive knowledge. Inductive knowl-
edge is the always uncertain knowledge of the physical universe gained by studying
it closely and manipulating it in ways calculated to uncover initially unremarked
properties of reality stable enough to be understood. Analytic knowledge is knowl-
edge of an aspect of reality, speciﬁcally certain aspects of the behaviour of marks
and signs (e.g. on paper or computer tape) limited enough for guessed generaliza-
tions to have a good chance of being correct. (It is in fact hard to do without these
guesses, since the marks and signs to which they relate are the tools we use to reason
in all other areas of science.) What we believe about these signs is that a certain way
of manipulating them (by logical reasoning) that is somewhat more general than
the standard process of automated computation seems to be formally consistent. Al-
though inconsistencies, requiring some kind of intellectual repair, might possibly be
found in still unexplored areas of the realm of these signs, we still have no idea of
how to convert this suspicion into something useful.
References
[AW80]
Aiello, L., Weyhrauch, R.W.: Using meta-theoretic reasoning to do algebra. In: Bibel,
W., Kowalski, R. (eds.) Proc. of the 5th Conference on Automated Deduction, Les
Arcs, France. LNCS, vol. 87, pp. 1–13. Springer, Berlin (1980)
[SDDS86] Schwartz, J.T., Dewar, R.K.B., Dubinsky, E., Schonberg, E.: Programming with Sets:
An Introduction to SETL. Texts and Monographs in Computer Science. Springer,
Berlin (1986)


Chapter 7
A Self-contained Beginning for Ref’s Main Proof
Scenario
This chapter presents in full a group of formalized proofs that reaches in a small
number of pages many results about ordinals, various properties of the transitive clo-
sure operation, transﬁnite induction, and then Zorn’s lemma. We end with the proofs
of a few basic facts concerning ﬁnite sets, including a ﬁnite induction principle.
7.1 Axioms of Set Theory

The regularity postulate and the inﬁnity postulate are the only ones explicitly
present in the THEORY ‘Set_theory’ underlying the proof-checker Ref. All other
axioms typical of set theory—and, to some extent, even the two just recalled—,
are built into the inferential machinery of Ref. We now recast the said postulates in
the form of two theorems: citing them will thus become handier, because universal
quantiﬁers are left understood.
THEOREM 0: [Global choice]

X = ∅& arb(X) = ∅

∨

arb(X) ∈X & arb(X) ∩X = ∅

. PROOF:
Suppose_not(x0) ⇒
Stat0 : ¬

x0 = ∅& arb(x0) = ∅

∨

arb(x0) ∈x0 & arb(x0) ∩x0 = ∅

Assump ⇒
Stat1 :

∀s
 
s = ∅& arb(s) = ∅

∨

arb(s) ∈s & arb(s) ∩s = ∅

⟨x0⟩→Stat1(Stat0⋆) ⇒
false; Discharge ⇒
QED

In the statement of the following it would be easy, but pointless, to replace s∞by
a new constant s′
∞satisfying the stronger (more conventional) condition
∅∈s′
∞&

X ∈s′
∞→{X} ∈s′
∞

.
THEOREM 00: [Axiom of Inﬁnity] s∞̸= ∅& (X ∈s∞→{X} ∈s∞). PROOF:
Suppose_not(x0) ⇒
AUTO
J.T. Schwartz et al., Computational Logic and Set Theory,
DOI 10.1007/978-0-85729-808-9_7, © Springer-Verlag London Limited 2011
373

374
7
A Self-contained Beginning for Ref’s Main Proof Scenario
Assump ⇒
Stat1 :

∀x ∈s∞| {x} ∈s∞

& s∞̸= ∅
⟨x0⟩→Stat1 ⇒
false; Discharge ⇒
QED
7.2 Pairs and Maps

We now begin by making a trick, purely set-theoretic deﬁnition of the notion of
ordered pair. We also give formal deﬁnitions of both ordered-pair component ex-
tractor functions. These deﬁnitions are shown only for completeness: all that really
counts, about them, being that they enforce the ‘unique retrieval’ law

∀s, d| [s, d][1] = s & [s, d][2] = d

,
which could have been encapsulated inside a THEORY such as
THEORY ordPair( )
⇒(ordpΘ, fstΘ, sndΘ)

∀p,ℓ,r| p = ordpΘ(ℓ, r) →fstΘ(p) = ℓ& sndΘ(p) = r

END ordPair
and which, anyway, is built-in in the extended version of multilevel syllogistic
encompassed by the most central among Ref’s inference primitives, named ELEM.
DEF pairs · 0: [Ordered pair]
[L, R] =Def

{L},

{L},

{R},R
			
DEF pairs · 1: [1st component of ordered pair] P[1] =Def arb(arb(P))
DEF pairs · 2: [2nd component of ordered pair] P[2] =Def
arb

arb

arb

P\

arb(P)
	
\

arb(P)
	

The following operations are usually applied to sets of ordered pairs, here called
maps:
DEF maps · 1: [Map domain]
domain(F) =Def

p[1] : p ∈F
	
DEF maps · 2: [Map restriction]
F|A =Def

p ∈F| p[1] ∈A
	
DEF maps · 3: [Value of single-valued function]
F↾X =Def arb

F|{X}
[2]

It is convenient to summarize some of the key results about maps in auxiliary
THEORYs, such as the following one, that ease their use. We focus here on maps
of the form {[x, f(x)] : x ∈s}, which are always single-valued.
THEORY fcn_symbol

f(X), g,s

-- Contains some elementary lemmas about single-valued functions
g =

x, f(x)

: x ∈s
	
END fcn_symbol
ENTER_THEORY fcn_symbol

7.2
Pairs and Maps
375

Note: till we return from ‘fcn_symbol’ to set theory, we are reasoning within the
theory, so g = {[x, f(x)] : x ∈s} is available as an axiom, and all theorems proved
are added to the set of conclusions of the theory, rather than to the set of con-
clusions of the top-level set-theory. First we show that the domain of g is sim-
ply s.
THEOREM fcn_symbol · 1: [Mapformer domain] domain(g) = s. PROOF:
Suppose_not ⇒
domain(g) ̸= s

For in the contrary case we would have {x[1] : x ∈{[x, f(x)] : x ∈s}} ̸= s by deﬁni-
tion, so there would exist an x ∈s such that [x, f(x)][1] ̸= x, which is impossible.
Use_def(domain) ⇒

x[1] : x ∈g
	
̸= s
Assump ⇒
g =

y, f(y)

: y ∈s
	
EQUAL ⇒

x[1] : x ∈g
	
=

x[1] : x ∈

y,f(y)

: y ∈s
		
ELEM ⇒

x[1] : x ∈

y, f(y)

: y ∈s
		
̸= s
SIMPLF ⇒

y,f(y)
[1] : y ∈s
	
̸= {x : x ∈s}
Set_monot ⇒

y, f(y)
[1] : y ∈s
	
= {y : y ∈s}
Discharge ⇒
QED
∥Next we show that g↾x = f(x) for any x ∈s.
THEOREM fcn_symbol · 2: [Image by a mapformer] X′ ∈s →g↾X′ = f(X′). PROOF:
Suppose_not(c) ⇒
c ∈s & g↾c ̸= f(c)

For suppose not, and let c ∈s be a counterexample, so that by deﬁnition of func-
tional application (and map restriction) we would have
arb

x,f(x)

: x ∈s
 
x,f(x)
[1] ∈{c}
	[2] ̸= f(c).
Use_def(↾) ⇒
arb(g|{c})[2] ̸= f(c)
Use_def(|) ⇒
arb

p ∈g| p[1] ∈{c}
	[2] ̸= f(c)
Assump ⇒
g =

x, f(x)

: x ∈s
	
EQUAL ⇒
arb

p ∈

x, f(x)

: x ∈s
	 p[1] ∈{c}
	[2] ̸= f(c)
SIMPLF ⇒
arb

x, f(x)

: x ∈s
 
x, f(x)
[1] ∈{c}
	[2] ̸= f(c)

376
7
A Self-contained Beginning for Ref’s Main Proof Scenario

We can simplify {[x, f(x)] : x ∈s| [x, f(x)][1] ∈{c}} to {[x,f(x)] : x ∈s| x ∈{c}},
for if these sets were different there would be a d ∈s such that the conditions
[d, f(d)][1] ∈{c} and d ∈c were inequivalent, which is impossible.
Suppose ⇒
Stat1 :

x, f(x)

: x ∈s
 
x, f(x)
[1] ∈{c}
	
̸=

x, f(x)

: x ∈s| x ∈{c}
	
⟨d⟩→Stat1 ⇒
d ∈s & ¬

d, f(d)
[1] ∈{c} ↔d ∈{c}

Discharge ⇒

x, f(x)

: x ∈s|

x, f(x)
[1] ∈{c}
	
=

x,f(x)

: x ∈s| x ∈{c}
	

But {[x, f(x)] : x ∈s| x ∈{c}} simpliﬁes in two steps to {[x, f(x)] : x ∈{c}},
which is the same as {[c,f(c)]}. Hence if our theorem is false we would have
arb({[c, f(c)]})[2] ̸= f(c), a contradiction proving the theorem.
Suppose ⇒
Stat2 :

x, f(x)

: x ∈s| x ∈{c}
	
̸=

x, f(x)

: x ∈{c}
	
⟨e⟩→Stat2 ⇒

e ∈

x, f(x)

: x ∈s| x ∈{c}
	
& e /∈

x, f(x)

: x ∈{c}
	
∨
e /∈

x, f(x)

: x ∈s| x ∈{c}
	
& e ∈

x, f(x)

: x ∈{c}
	
Suppose ⇒
Stat3 : e ∈

x,f(x)

: x ∈s| x ∈{c}
	
&
Stat4 : e /∈

x, f(x)

: x ∈{c}
	
⟨e1⟩→Stat3 ⇒
e =

e1, f(e1)

& e1 ∈s & e1 ∈{c}
⟨e1⟩→Stat4 ⇒
false; Discharge ⇒
Stat5 : e /∈

x,f(x)

: x ∈s| x ∈{c}
	
&
Stat6 : e ∈

x, f(x)

: x ∈{c}
	
⟨e2⟩→Stat6 ⇒
e =

e2, f(e2)

& e2 ∈{c}
⟨e2⟩→Stat5 ⇒
false; Discharge ⇒

x, f(x)

: x ∈s| x ∈{c}
	
=

x, f(x)

: x ∈{c}
	
SIMPLF ⇒

x,f(x)

: x ∈{c}
	
=

c,f(c)
	
EQUAL ⇒

c, f(c)
	[2] ̸= f(c)
Discharge ⇒
QED
∥Our next theorem rounds out the preceding result by showing that g↾x = ∅for x /∈s.
THEOREM fcn_symbol · 3: [Mapformer image in general]
g↾X′ = if X′ ∈s then f(X′) else ∅ﬁ. PROOF:
Suppose_not(c) ⇒
g↾c ̸= if c ∈s then f(c) else ∅ﬁ

For suppose not, and (as the possibility c ∈s gets readily discarded) let c /∈s
be a counterexample. Then by deﬁnition of functional application (and map re-
striction) the value arb({[x, f(x)] : x ∈s| [x, f(x)][1] ∈{c}}) must be nonzero, and
then—since arb(∅) = ∅—so is the set {[x, f(x)] : x ∈s| [x, f(x)][1] ∈{c}}.

7.2
Pairs and Maps
377
Suppose ⇒
c ∈s
⟨c⟩→Tfcn_symbol · 2 ⇒
g↾c = f(c)
Discharge ⇒
Stat1 : c /∈s & g↾c ̸= ∅
Use_def(↾) ⇒
c /∈s & arb(g|{c})[2] ̸= ∅
Suppose ⇒
arb(g|{c}) = ∅
EQUAL ⇒
∅[2] ̸= ∅
Use_def(·[2]) ⇒
arb

arb

arb

∅\

arb(∅)
	
\

arb(∅)
	
̸= ∅
TELEM ⇒
∅\

arb(∅)
	
= ∅
EQUAL ⇒
arb

arb

arb(∅)\

arb(∅)
	
̸= ∅
⟨∅⟩→T 0 (⋆) ⇒
arb(∅) = ∅
TELEM ⇒
arb(∅)\

arb(∅)
	
= ∅
EQUAL ⇒
arb

arb(∅)

̸= ∅
EQUAL ⇒
arb(∅) ̸= ∅
EQUAL ⇒
false; Discharge ⇒
arb(g|{c}) ̸= ∅
Use_def(|) ⇒
g|{c} =

p ∈g| p[1] ∈{c}
	
EQUAL ⇒
arb

p ∈g| p[1] ∈{c}
	
̸= ∅
Assump ⇒
g =

x, f(x)

: x ∈s
	
EQUAL ⇒
arb

p ∈

x, f(x)

: x ∈s
	
| p[1] ∈{c}
	
̸= ∅
SIMPLF ⇒
Stat2 : arb

x, f(x)

: x ∈s
 
x, f(x)
[1] ∈{c}
	
̸= ∅

x, f(x)

: x ∈s
 
x, f(x)
[1] ∈{c}
	
→T 0 (Stat2⋆) ⇒
Stat3 :

x, f(x)

: x ∈s
 
x, f(x)
[1] ∈{c}
	
̸= ∅

Hence there would exist a d ∈s such that [d, f(d)][1] ∈{c}, implying c ∈s, a con-
tradiction which proves our assertion.
⟨d⟩→Stat3() ⇒
Stat4 : d ∈s &

d,f(d)
[1] ∈{c}
(Stat1,Stat4)Discharge ⇒
QED
ENTER_THEORY Set_theory
DISPLAY fcn_symbol
THEORY fcn_symbol

f(X), g, s

-- Contains some elementary lemmas about single-valued functions
g =

x, f(x)

: x ∈s
	
⇒
domain(g) = s

∀x′ | x′ ∈s →g↾x′ = f(x′)


∀x′ | g↾x′ = if x′ ∈s then f(x′) else ∅ﬁ

END fcn_symbol

378
7
A Self-contained Beginning for Ref’s Main Proof Scenario
7.3 From Reachability to Transﬁnite Induction
7.3.1 Reachability in a Big Graph

The following theory has two predicates, one monadic and the other dyadic, as
arguments: these represent nodes (or ‘vertices’) and arcs (or ‘edges’) of a system.
What we mean by ‘system’, following Aczel [Acz88], is a structure akin to a graph
but whose nodes and arcs might form proper classes. Anyway, we insist that the
immediate descendants of each node x must be included in a set (possibly a set
which depends on x).
THEORY reachability

V(X), E(X, Y)


∀x| V(x) →

∃c,∀y| E(x, y) & V(y) →y ∈c

END reachability
ENTER_THEORY reachability

Inside this THEORY ‘reachability’, we will now use Skolemization to associate
with every node the set of its children in the system. For each node x, we own a set c
comprising all the immediate descendants of x; hence separation enables us to form
the set ch = {y ∈c| E(x,y) & V(y)} of all nodes which are immediate descendants
of x in the system. This set will be named children(x) by the subsequent application
of Skolemization. When x is not a node, a forthcoming theorem will arrange things
so that children(x) = ∅.
THEOREM reachability · 0: [Every node has a set of children]

∃ch,∀y| E(X, y) & V(X) & V(y) ↔y ∈ch

. PROOF:
Suppose_not(x0) ⇒
Stat0 : ¬

∃ch,∀y| E(x0,y) & V(x0) & V(y) ↔y ∈ch

Suppose ⇒
¬V(x0)
⟨∅⟩→Stat0(Stat0⋆) ⇒
Stat1 : ¬

∀y| E(x0, y) & V(x0) & V(y) ↔y ∈∅

⟨y⟩→Stat1(Stat0⋆) ⇒
false; Discharge ⇒
AUTO
Assump ⇒
Stat2 :

∀x| V(x) →

∃c,∀y| E(x, y) & V(y) →y ∈c

⟨x0⟩→Stat2(Stat0⋆) ⇒
Stat3 :

∃c,∀y| E(x0, y) & V(y) →y ∈c

& V(x0)
⟨k⟩→Stat3(Stat3⋆) ⇒
Stat4 :

∀y| E(x0, y) & V(y) →y ∈k

Loc_def ⇒
kh =

y ∈k| E(x0,y) & V(y)
	
⟨kh⟩→Stat0(Stat4⋆) ⇒
Stat5 : ¬

∀y| E(x0,y) & V(x0) & V(y) ↔y ∈kh

⟨y0⟩→Stat5(Stat3⋆) ⇒
E(x0,y0) & V(y0) ̸= y0 ∈kh
Suppose ⇒
Stat6 : E(x0, y0) & V(y0)
(Stat4⋆)ELEM ⇒
Stat7 : y0 /∈

y ∈k| E(x0, y) & V(y)
	
⟨y0⟩→Stat4(Stat6⋆) ⇒
y0 ∈k

7.3
From Reachability to Transﬁnite Induction
379
⟨y0⟩→Stat7(Stat6⋆) ⇒
false;
(Stat4⋆)Discharge ⇒
Stat8 : y0 ∈

y ∈k| E(x0, y) & V(y)
	
& ¬

E(x0, y0) & V(y0)

⟨⟩→Stat8(Stat8⋆) ⇒
false; Discharge ⇒
QED
∥Skolemize this last statement, rewriting it in the form:
APPLY ⟨v1Θ : children⟩Skolem⇒
THEOREM reachability · 1a: [Children lemma, 0]

∀x, y| E(x, y) & V(x) & V(y) ↔y ∈children(x)

.
 Then recast the ‘children lemma’ just obtained in a form with tacit universal quan-
tiﬁers.
THEOREM reachability · 1: [Children lemma] E(X, Y) & V(X) & V(Y) ↔
Y ∈children(X). PROOF:
Suppose_not(x, y) ⇒
AUTO
Treachability · 1a ⇒
Stat1 :

∀x, y| E(x, y) & V(x) & V(y) ↔y ∈children(x)

⟨x⟩→Stat1 ⇒
Stat2 :

∀y| E(x, y) & V(x) & V(y) ↔y ∈children(x)

⟨y⟩→Stat2 ⇒
false; Discharge ⇒
QED

Now we start to prepare more closely for the proof of a preliminary version of the
principle of transﬁnite induction by making an auxiliary deﬁnition: we introduce
the set descsΘ(s) of those x which either belong to s or are descendants of ele-
ments of s (i.e., children of s, children of children of s, and so on recursively).
The construction of descsΘ(s) will proceed in stages; as a preliminary, in fact,
we deﬁne the sets descs_x(s, le) of all nodes that are reachable from s through
paths of given ‘length’ le. In an intuitive discussion, we think that the length of
a path is a natural number; but, as we do not own from the outset the set of all
natural numbers, we exploit the basic inﬁnite set s∞as a convenient surrogate of
this set.
DEF reachability · 0: [Recursively deﬁned iterated children] descs_x(S, Le) =Def
if Le = arb(s∞) then S else

u : w ∈arb

descs_x(S, y) : y ∈Le| y ∈s∞
	
, u ∈children(w)
	
ﬁ

380
7
A Self-contained Beginning for Ref’s Main Proof Scenario

Explanation: We know that s∞is a nonnull set satisfying the property that {X} ∈
s∞follows from X ∈s∞. Hence arb(s∞) = a, and {a}, {{a}}, ... are members of
s∞; and since each of them belongs to its immediate follower and membership
does not form cycles (as one can deduce from regularity), they differ from one
another and hence their supply is inﬁnite. As natural numbers have not been in-
troduced yet, we can exploit a in the role of 0, {a} in the role of 1, {{a}} of 2,
etc. We have deﬁned descs_x(S, Le) in such a way that when Le varies over a,
{a}, {{a}}, ... the sets descs_x(S,Le) come to form a sequence descs_x(S, a),
descs_x(S,{a}), descs_x(S,{{a}}), ... whose ﬁrst component is S and hence is
formed by the same elements as S, the second is formed by the children of elements
of S, the third by the children of children of S, and so on. At the end, by forming
the union of all components of this sequence (see our next deﬁnition), we obtain
the set of all nodes reachable from S along paths formed by arcs of the system.
DEF reachability · 1: [Ultimate descendants of a node] descsΘ(S) =Def

u : i ∈s∞,u ∈descs_x(S, i)
	

The set just deﬁned includes S; moreover, we will show that it is transitively closed
under E. First we need the following simple lemma:
THEOREM reachability · 2: [Descendants indexed by the singletons in the basic
inﬁnite set] X ∈s∞→
descs_x

S,{X}

=

u : w ∈descs_x(S,X), u ∈children(w)
	
.
PROOF:
Suppose_not(x, s) ⇒
AUTO

Since x ∈s∞, {x} ̸= arb(s∞), and so descs_x(s,{x}) =
{u : v ∈arb({descs_x(s, y) : y ∈{x}}), u ∈children({x})} by deﬁnition.
Use_def(descs_x) ⇒
descs_x

s,{x}

=
if {x} = arb(s∞) then s else

u : w ∈arb

descs_x(s, y) : y ∈{x}| y ∈s∞
	
, u ∈children(w)
	
ﬁ
⟨s∞⟩→T 0(⋆) ⇒
descs_x

s,{x}

=

u : w ∈arb

descs_x(s, y) : y ∈{x}| y ∈s∞
	
, u ∈children(w)
	
EQUAL ⇒
Stat1 :

u : w ∈arb

descs_x(s, y) : y ∈{x}| y ∈s∞
	
, u ∈children(w)
	
̸=

u : w ∈descs_x(s,x), u ∈children(w)
	

The left-hand side of this inequality reduces to {u : w ∈descs_x(s,x), u ∈
children(w)}, which contradicts the initial hypothesis, and so proves our lemma.

7.3
From Reachability to Transﬁnite Induction
381
Suppose ⇒
Stat2 :

descs_x(s, y) : y ∈{x}| y ∈s∞
	
̸=

descs_x(s, x)
	
Set_monot ⇒

descs_x(s, y) : y ∈{x}| y ∈s∞
	
⊆

descs_x(s, y) : y ∈{x}
	
SIMPLF ⇒

descs_x(s, y) : y ∈{x}
	
=

descs_x(s,x)
	
(Stat2⋆)ELEM ⇒
Stat3 : descs_x(s, x) /∈

descs_x(s, y) : y ∈{x}| y ∈s∞
	
⟨x⟩→Stat3(⋆) ⇒
false; Discharge ⇒

descs_x(s, y) : y ∈{x}| y ∈s∞
	
=

descs_x(s, x)
	

{descs_x}(s, x)

→T 0(⋆) ⇒
arb

descs_x(s, x)
	
= descs_x(s, x)
EQUAL ⟨Stat1⟩⇒
false; Discharge ⇒
QED
∥Now we can prove, for any set s, that descsΘ(s) includes s and is E-transitive.
THEOREM reachability · 3: [Stepwise reachability] S ⊆descsΘ(S) &

X ∈descsΘ(S) & V(X) & V(Y) & E(X, Y) →Y ∈descsΘ(S)

. PROOF:
Suppose_not(s, x, y) ⇒
AUTO
∥Arguing by contradiction, we must consider the following alternative:
⟨x, y⟩→Treachability · 1 ⇒
s ̸⊆descsΘ(s) ∨

x ∈descsΘ(s) & y ∈children(x) & y /∈descsΘ(s)


The ﬁrst of these cases is impossible, since an x′ in s but not in descsΘ(s) could
not be in any of the sets descs_x(s, v) where v belongs to s∞, contradicting the
fact that arb(s∞) belongs to s∞, while descs_x(s,arb(s∞)) = s. Hence we need
only consider the second case.
Suppose ⇒
Stat1 : s ̸⊆descsΘ(s)
⟨x′⟩→Stat1 ⇒
x′ ∈s & x′ /∈descsΘ(s)
Use_def(descsΘ) ⇒
Stat2 : x′ /∈

y : v ∈s∞,y ∈descs_x(s, v)
	
⟨s∞⟩→T 0(⋆) ⇒
AUTO

arb(s∞)

→T 0(⋆) ⇒
arb(s∞) ∈s∞

arb(s∞),x′
→Stat2 ⇒
x′ /∈descs_x

s,arb(s∞)

Use_def(descs_x) ⇒
descs_x

s,arb(s∞)

= s
(Stat1⋆)Discharge ⇒
Stat4 : x ∈descsΘ(s) & y ∈children(x) & y /∈descsΘ(s)

But in this case there must exist some d in s∞such that x in descs_x(s, d), and
then descs_x(s,{d}) = {w : v ∈descs_x(s, d),w ∈v} must have y as a member.
Since {d} is a member of s∞, this contradicts the fact that y /∈descsΘ(s), and so
proves our theorem.

382
7
A Self-contained Beginning for Ref’s Main Proof Scenario
Use_def(descsΘ) ⇒
Stat5 : x ∈

w : v ∈s∞, w ∈descs_x(S,v)
	
⟨d, w⟩→Stat5 ⇒
Stat6 : d ∈s∞& x ∈descs_x(s, d)
⟨d⟩→T 0 ⇒
{d} ∈s∞
Use_def(descsΘ) ⇒
Stat7 : y /∈

w : v ∈s∞, w ∈descs_x(s,v)
	

{d}, y

→Stat7 ⇒
y /∈descs_x

s,{d}

⟨d, s⟩→Treachability · 2 ⇒
Stat8 : y /∈

u : w ∈descs_x(s,d), u ∈children(w)
	
⟨x, y⟩→Stat8(Stat8,Stat6⋆) ⇒
Stat9 : y /∈children(x)
⟨x, y⟩→Treachability · 1 ⇒
false; Discharge ⇒
QED

Transitivity of the reachability relation is proved next: if y is reachable from x and
z is reachable from y, then z is reachable from x.
THEOREM reachability · 4: [Transitivity of reachability]
Y ∈descsΘ

{X}

& Z ∈descsΘ

{Y}

→Z ∈descsΘ

{X}

. PROOF:
Suppose_not(y0, x, z) ⇒
AUTO

Assume that y0 is reachable from {x} and that z is reachable from {y0}; however,
to start an argument by contradiction, assume that z is unreachable from {x}.
Suppose ⇒

s ∈s∞| descs_x

{y0}, s

̸⊆descsΘ

{x}
	
= ∅

It follows from the deﬁnition of the set descsΘ({y0}) of all sets reachable from
{y0} that at least one of the layers descs_x({y0}, i) (with i ∈s∞) which compose
descsΘ({y0}) has an element that is unreachable from {x}.
Use_def

descsΘ

{y0}

⇒
AUTO
ELEM ⇒
Stat1 : z ∈

u : i ∈s∞, u ∈descs_x

{y0},i
	
& z /∈descsΘ

{x}

⟨i, u⟩→Stat1 ⇒
i ∈s∞& z ∈descs_x

{y0}, i

& Stat2 :
i /∈

s ∈s∞| descs_x

{y0},s

̸⊆descsΘ

{x}
	
⟨i⟩→Stat2(Stat1⋆) ⇒
false; Discharge ⇒
AUTO

So we can pick s0 ∈s∞in such a way that descs_x({y0}, s0) ̸⊆descsΘ({x})
whereas descs_x({y0}, s) ⊆descsΘ({x}) holds for all s ∈s0 ∩s∞.
Loc_def ⇒
s0 = arb

s ∈s∞| descs_x

{y0}, s

̸⊆descsΘ

{x}
	

s ∈s∞| descs_x

{y0}, s

̸⊆descsΘ

{x}
	
→T 0(⋆) ⇒
Stat3 :
s0 ∈

s ∈s∞| descs_x

{y0}, s

̸⊆descsΘ

{x}
	
&

7.3
From Reachability to Transﬁnite Induction
383
s0 ∩

s ∈s∞| descs_x

{y0}, s

̸⊆descsΘ

{x}
	
= ∅
⟨⟩→Stat3(⋆) ⇒
Stat4 :
descs_x

{y0},s0

̸⊆descsΘ

{x}

& s0 ∈s∞& y0 ∈descsΘ

{x}


The selected s0 cannot coincide with arb(s∞), because descs_x({y0},arb(s∞)) =
{y0}, whose only element we have assumed to be reachable from {x}.
Use_def

descs_x

{y0}, s0

⇒
AUTO
Suppose ⇒
s0 = arb(s∞)
(Stat4⋆)ELEM ⇒
descs_x

{y0}, s0

= {y0}
(Stat4⋆)Discharge ⇒
descs_x

{y0},s0

=

u : w ∈arb

descs_x

{y0},y

: y ∈s0 | y ∈s∞
	
, u ∈children(w)
	

But then, observe that the expression arb({descs_x({y0}, y) : y ∈s0 | y ∈s∞}) oc-
curring in the speciﬁcation of descs_x({y0}, s0) designates a set of the form
a = descs_x({y0}, s1), with s1 ∈s0 ∩s∞. There must exist a child u0 of an ele-
ment w0 of this set that is unreachable from {x}.
⟨u0⟩→Stat4(Stat4⋆) ⇒
Stat5 :
u0 ∈

u : w ∈arb

descs_x

{y0}, y

: y ∈s0 | y ∈s∞
	
, u ∈children(w)
	
& u0 /∈descsΘ

{x}

⟨w0, u1⟩→Stat5(Stat5⋆) ⇒
Stat6 :
w0 ∈arb

descs_x

{y0}, y

: y ∈s0 | y ∈s∞
	
& u0 ∈children(w0)
Loc_def ⇒
Stat7 : a = arb

descs_x

{y0}, y

: y ∈s0 | y ∈s∞
	

descs_x

{y0}, y

: y ∈s0 | y ∈s∞
	
→T 0 (Stat5⋆) ⇒
Stat8 :
a ∈

descs_x

{y0},y

: y ∈s0 | y ∈s∞
	
⟨s1⟩→Stat8(Stat6,Stat7,Stat3⋆) ⇒
Stat9 :
s1 /∈

s ∈s∞| descs_x

{y0}, s

̸⊆descsΘ

{x}
	
&
s1 ∈s0 & s1 ∈s∞& w0 ∈descs_x

{y0},s1


By the minimality of s0, it turns out that descs_x({y0},s1) ⊆descsΘ({x}), and
therefore w0 ∈descs_x({x0}), holds. But then every child of w0, including u0,
must belong to descsΘ({x}), as we know from Theorem reachability.1 that the
children of any w are the nodes directly accessible from w, ...
⟨s1⟩→Stat9(Stat5,Stat6⋆) ⇒
Stat10 : w0 ∈descsΘ

{x}

⟨w0, u0⟩→Treachability · 1 ⇒
E(w0,u0) & V(w0) & V(u0)

384
7
A Self-contained Beginning for Ref’s Main Proof Scenario

...and this, with the aid of the previous Theorem reachability.3, leads us to a fact,
u0 ∈descsΘ({x}), which blatantly conﬂicts with a fact established earlier.
⟨{x}, w0, u0⟩→Treachability · 3 ⇒
AUTO
∥This contradiction gives us the desired conclusion.
(Stat5⋆)Discharge ⇒
QED

Then we show that the set of all descendants of a set s is inclusion-minimal among
all sets t that include s and are closed relative to the children-formation operation.
THEOREM reachability · 5: [Minimality of the reachability set]
S ⊆T &

∀x,y| x ∈T & E(x, y) & V(x) & V(y) →y ∈T

→descsΘ(S) ⊆T. PROOF:
Suppose_not(s, t) ⇒
Stat1 :

∀x, y| x ∈t & E(x,y) & V(x) & V(y) →y ∈t

& s ⊆t & descsΘ(s) ̸⊆t

Assume that s ⊆t and that every node which is directly accessible from a node in
t belongs to t; however, to start an argument by contradiction, assume that not all
sets reachable from s are in t.
Use_def

descsΘ(s)

⇒
AUTO
(Stat1⋆)ELEM ⇒
Stat2 :

u : i ∈s∞, u ∈descs_x(s, i)
	
̸⊆t

It follows from the deﬁnition of the set descsΘ(s) of the descendants of s, that at
least one of the layers descs_x(s, i) (with i ∈s∞) which compose descsΘ(s) is not
included in t.
Suppose ⇒
Stat3 :

i ∈s∞| descs_x(s, i) ̸⊆t
	
= ∅
⟨u0⟩→Stat2(Stat2⋆) ⇒
Stat4 : u0 ∈

u : i ∈s∞, u ∈descs_x(s, i)
	
& u0 /∈t
⟨i, u⟩→Stat4(Stat4⋆) ⇒
i ∈s∞& descs_x(s, i) ̸⊆t
⟨i⟩→Stat3(Stat3⋆) ⇒
false; Discharge ⇒
AUTO

So we can pick i0 ∈s∞in such a way that descs_x(s, i0) ̸⊆t whereas
descs_x(s, i) ⊆t holds for all i ∈i0 ∩s∞.
Loc_def ⇒
i0 = arb

i ∈s∞| descs_x(s, i) ̸⊆t
	

7.3
From Reachability to Transﬁnite Induction
385

i ∈s∞| descs_x(s, i) ̸⊆t
	
→T 0(⋆) ⇒
Stat5 :
i0 ∈

i ∈s∞| descs_x(s, i) ̸⊆t
	
& i0 ∩

i ∈s∞| descs_x(s, i) ̸⊆t
	
= ∅
⟨⟩→Stat5(Stat5⋆) ⇒
Stat6 : i0 ∈s∞& descs_x(s, i0) ̸⊆t
Use_def

descs_x(s, i0)

⇒
AUTO
 The selected i0 cannot coincide with arb(s∞), because descs_x(s,arb(s∞)) = s,
which we have assumed to be included in t.
Suppose ⇒
i0 = arb(s∞)
(Stat6⋆)ELEM ⇒
Stat7 : descs_x(s, i0) = s
(Stat7,Stat6,Stat1⋆)Discharge ⇒
Stat8 :

u : w ∈arb

descs_x(s, y) : y ∈i0 | y ∈s∞
	
, u ∈children(w)
	
̸⊆t

But then, observe that the expression arb({descs_x(s,y) : y ∈i0 | y ∈s∞}) oc-
curring in the speciﬁcation of descs_x(s,i0) designates a set of the form
a = descs_x(s, i1), with i1 ∈i0 ∩s∞. There must exist a child u1 of an element
w0 of this set that does not belong to t.
⟨u1⟩→Stat8(Stat8⋆) ⇒
Stat9 : u1 ∈

u : w ∈arb

descs_x(s, y) : y ∈i0 | y ∈s∞
	
, u ∈children(w)
	
& u1 /∈t
⟨w0, u2⟩→Stat9(Stat9⋆) ⇒
w0 ∈arb

descs_x(s, y) : y ∈i0 | y ∈s∞
	
& u1 ∈children(w0)
Loc_def ⇒
a = arb

descs_x(s, y) : y ∈i0 | y ∈s∞
	

descs_x(s, y) : y ∈i0 | y ∈s∞
	
→T 0 (Stat9⋆) ⇒
Stat10 :
a ∈

descs_x(s, y) : y ∈i0 | y ∈s∞
	
⟨i1⟩→Stat10(Stat9⋆) ⇒
Stat11 : i1 ∈i0 & i1 ∈s∞& w0 ∈descs_x(s, i1)

By the minimality of i0, it turns out that descs_x(s, i1) ⊆t, and therefore w0 ∈t,
holds. But then every child of w0, including u1, must belong to t, as we know from
Theorem reachability.1 that the children of any w are the nodes directly accessible
from w, ...
(Stat11,Stat5⋆)ELEM ⇒
Stat12 : i1 /∈

i ∈s∞| descs_x(s,i) ̸⊆t
	
⟨i1⟩→Stat12(Stat11⋆) ⇒
w0 ∈t
⟨w0, u1⟩→Treachability · 1 ⇒
E(w0,u1) & V(w0) & V(u1)

...and we have initially assumed that nodes directly accessible from t belong to t.
This leads us into a contradiction, which gives us the desired conclusion.

386
7
A Self-contained Beginning for Ref’s Main Proof Scenario
⟨w0, u1⟩→Stat1(Stat9⋆) ⇒
false; Discharge ⇒
QED
ENTER_THEORY Set_theory
DISPLAY reachability
THEORY reachability

V(X), E(X,Y)


∀x| V(x) →

∃c,∀y| E(x, y) & V(y) →y ∈c

⇒(descsΘ)

∀s, x, y| s ⊆descsΘ(s) &

x ∈descsΘ(s) & V(x) & V(y) & E(x,y) →y ∈descsΘ(s)


∀y, x, z| y ∈descsΘ

{x}

& z ∈descsΘ

{y}

→z ∈descsΘ

{x}


∀s, t| s ⊆t &

∀x, y| x ∈t & E(x, y) & V(x) & V(y) →y ∈t

→descsΘ(s) ⊆t

END reachability
7.3.2 Full Sets and Ordinals
DEF powerset: [family of all subsets of a set]
PX =Def {y : y ⊆X}
DEF unionset: [family of all members of members of a set]

X =Def {u : v ∈X, u ∈v}

Our next theorem characterizes the powerset formation operation in more usable
terms than the very deﬁnition of this construct. It also proves that no set can equal
its own powerset (else it should belong to itself, against the acyclicity of member-
ship).
THEOREM 1: [characterization of powerset; also: no set equals its own powerset]
(X ⊇Y ↔Y ∈PX) & X ̸= PX. PROOF:
Suppose_not(x0, y0) ⇒
AUTO
∥We begin by excluding the possibility that x0 = Px0:
Use_def(Px0) ⇒
AUTO
Suppose ⇒
x0 = Px0
ELEM ⇒
Stat0 : x0 /∈{y : y ⊆x0}
⟨x0⟩→Stat0 ⇒
false; Discharge ⇒
AUTO

Arguing by contradiction, if x0,y0 constituted a counterexample, then either one
of the literals x0 ⊇y0 and y0 ∈{y : y ⊆x0} would be true and the other one would
be false.
EQUAL ⇒
Stat1 : x0 ⊇y0 ̸↔y0 ∈{y : y ⊆x0}

7.3
From Reachability to Transﬁnite Induction
387

If it is the second that is true then, via a substitution in the setformer, we would
contradict the falsity of the ﬁrst.
Suppose ⇒
Stat2 : y0 ∈{y : y ⊆x0}
⟨y1⟩→Stat2(Stat1⋆) ⇒
false; Discharge ⇒
Stat3 : y0 /∈{y : y ⊆x0}

But then the literals x0 ⊇y0 and y0 /∈{y : y ⊆x0} should hold together, which gives
us a contradiction if we replace the bounded variable y of the setformer by y0.
⟨y0⟩→Stat3(Stat1⋆) ⇒
false; Discharge ⇒
QED

Next we show that the union set of a set s is the set-theoretic ‘upper bound’ of all
its elements, i.e. the smallest set which includes all these elements.
THEOREM 2: [Union set as an upper bound] (X ∈S →X ⊆
S) &

∀y ∈S| y ⊆X

→
S ⊆X

. PROOF:
Suppose_not(t, s) ⇒
(t ̸⊆
s & t ∈s) ∨

⟨∀y ∈s| y ⊆t⟩& 
s ̸⊆t


For if not, one of the two clauses of our theorem must be false. By deﬁnition of
, this cannot be the ﬁrst clause, so it must be the second.
Use_def(
s) ⇒
AUTO
Suppose ⇒
Stat1 : t ̸⊆
s & t ∈s
⟨c⟩→Stat1 ⇒
Stat2 : c /∈{z : y ∈s, z ∈y} & c ∈t
⟨t, c⟩→Stat2 ⇒
false; Discharge ⇒
Stat3 : 
s ̸⊆t & ⟨∀y ∈s| y ⊆t⟩

But a second use of the deﬁnition of  shows that this case is also impossible,
proving our theorem.
⟨d⟩→Stat3 ⇒
Stat4 : d ∈{z : y ∈s, z ∈y} & ⟨∀y ∈s| y ⊆t⟩& d /∈t
⟨b, a, b⟩→Stat4 ⇒
false; Discharge ⇒
QED

One says that a set is full, or ‘transitive’, if any of its elements is also a subset of it;
otherwise stated, a set is full if its members comprise all members of its members.
DEF fullness: [full, or ‘transitive’ set] Is_full(T) ↔Def {y ∈T| y ̸⊆T} = ∅

388
7
A Self-contained Beginning for Ref’s Main Proof Scenario

Various alternative, more concise, characterizations of this ‘fullness’ notion, equiv-
alent to one another, could be given, e.g., ‘T is full if and only if 
T ⊆T’. We
content ourselves with the following:
THEOREM 3: [Alternative characterization of a full set] Is_full(T) →
T ⊆PT & (X ∈T →X ⊆T). PROOF:
Suppose_not(t0, x0) ⇒
AUTO
Use_def(Is_full) ⇒
Stat1 : {y ∈t0 | y ̸⊆t0} = ∅& t0 ̸⊆Pt0 ∨(x0 ∈t0 & x0 ̸⊆t0)
Suppose ⇒
Stat2 : t0 ̸⊆Pt0
⟨e⟩→Stat2 ⇒
e /∈Pt0 & e ∈t0
⟨e⟩→Stat1 ⇒
e ⊆t0
⟨t0, e⟩→T 1 ⇒
false; Discharge ⇒
x0 ∈t0 & x0 ̸⊆t0
⟨x0⟩→Stat1(Stat1⋆) ⇒
AUTO
Discharge ⇒
QED

The following is, in essence, the lemma
‘every strict subset s of a full set t includes a set belonging to t\s’
of [Ped62]. It readily yields (when t = ∅) that ∅belongs to every nonnull full set.
THEOREM 4: [Full-set comparison lemma] Is_full(T) & S ⊆T & S ̸= T →
arb(T\S) ∈T\S & arb(T\S) ⊆S. PROOF:
Suppose_not(t, s) ⇒
AUTO

For if our assertion is false, t must have s as a proper subset, in which case Theorem
0 tells us that a = arb(t\s) is a member of t\s disjoint from t\s. Plainly a is also
a member of the superset t of t\s.
Loc_def ⇒
a = arb(t\s)
⟨t\s⟩→T 0 (⋆) ⇒
a ∈t\s & a ∩(t\s) = ∅

But then, by deﬁnition of full set, a must be a subset of s, since it is disjoint from
t\s.
Use_def(Is_full) ⇒
Stat1 : {y ∈t| y ̸⊆t} = ∅
⟨a⟩→Stat1(⋆) ⇒
false; Discharge ⇒
QED
DEF Is_ord: [‘Is-an-ordinal’ predicate] O(X) ↔Def
⟨∀x ∈X| x ⊆X⟩& ⟨∀x ∈X, y ∈X| x ∈y ∨y ∈x ∨x = y⟩
∥The successor of an ordinal has a simple and very general deﬁnition:

7.3
From Reachability to Transﬁnite Induction
389
DEF next: [successor (deﬁned for any set, including ordinals and integers)]
next(X) =Def X ∪{X}
THEOREM 5: [Ordinals are full] O(T) →Is_full(T) & (Y ∈T →Y ⊆T). PROOF:
Suppose_not(t0, y0) ⇒
AUTO
Use_def(O) ⇒
Stat1 : ⟨∀x ∈t0 | x ⊆t0⟩
⟨y0⟩→Stat1(⋆) ⇒
¬Is_full(t0)
Use_def(Is_full) ⇒
Stat2 : {y ∈t0 | y ̸⊆t0} ̸= ∅
Loc_def ⇒
a1 = arb({y ∈t0 | y ̸⊆t0})
(Stat2)ELEM ⇒
Stat3 : a1 ∈{y ∈t0 | y ̸⊆t0}
⟨⟩→Stat3 ⇒
Stat4 : a1 ∈t0 & a1 ̸⊆t0
⟨a1⟩→Stat1(Stat4⋆) ⇒
false; Discharge ⇒
QED
THEOREM 6: [Condition for a subset of an ordinal to be an ordinal]
O(T) & S ⊆T & ⟨∀x ∈S| x ⊆S⟩→O(S). PROOF:
Suppose_not(t, s) ⇒
AUTO
Use_def

O(s)

⇒
AUTO
ELEM ⇒
Stat1 : ¬⟨∀x ∈s, y ∈s| x ∈y ∨y ∈x ∨x = y⟩& s ⊆t
⟨b, c⟩→Stat1 ⇒
b, c ∈s & ¬(b ∈c ∨c ∈b ∨b = c)
Use_def(O) ⇒
Stat3 : ⟨∀x ∈t, y ∈t| x ∈y ∨y ∈x ∨x = y⟩
⟨b, c⟩→Stat3(Stat1⋆) ⇒
false; Discharge ⇒
QED
 Next we prove a ﬁrst basic property of ordinals: any member of an ordinal is an
ordinal.
THEOREM 7: [Members of ordinals are ordinals] O(T) & S ∈T →O(S). PROOF:
Suppose_not(t, s) ⇒
AUTO
 We proceed by contradiction. If our theorem is false, there is an ordinal t having a
member s which is not an ordinal.
⟨t, s⟩→T 5 ⇒
Stat1 : O(t) & s ∈t & s ⊆t & ¬O(s)
⟨t, s⟩→T 6 ⇒
Stat2 : ¬⟨∀x ∈s| x ⊆s⟩
Use_def(O) ⇒
Stat3 : ⟨∀x ∈t, y ∈t| x ∈y ∨y ∈x ∨x = y⟩

Hence, by the deﬁnition of ordinals, s must either have a member a not included
in s, or a pair b,c of distinct members not related by membership. The latter pos-
sibility is ruled out by the preceding theorem; thus we need only consider the ﬁrst
case, in which a is a member but not a subset of s. In this case there plainly exists
a d in a but not in s. Plainly a is a member of t, and thus a subset of t; so d is also
a member of t.
⟨a⟩→Stat2(Stat2⋆) ⇒
Stat4 : a ̸⊆s & a ∈s

390
7
A Self-contained Beginning for Ref’s Main Proof Scenario
⟨t, a⟩→T 5 (Stat1,Stat4⋆) ⇒
a ⊆t
⟨d⟩→Stat4(Stat1⋆) ⇒
d ∈a & d /∈s & d ∈t

By the deﬁnition of ordinals, it follows that d either equals s, is a member of s,
or that s is a member of d. But all three of these cases are impossible, since any
would imply the existence of a membership cycle. This contradiction proves our
theorem.
⟨d, s⟩→Stat3(Stat1⋆) ⇒
d ∈s ∨s ∈d ∨s = d
(Stat4⋆)Discharge ⇒
QED
∥It is easy to show that the successor of a successor is an ordinal.
THEOREM 8: [Ordinals are closed under the successor operation] S ̸= next(S) &

O(S) →O

S ∪{S}

& O

next(S)

. PROOF:
Suppose_not(s0) ⇒
AUTO
Use_def(next) ⇒
O(s0) & ¬O

s0 ∪{s0}

Use_def(O) ⇒
Stat1 : ⟨∀x ∈s0, y ∈s0 | x ∈y ∨y ∈x ∨x = y⟩&
Stat2 : ⟨∀x ∈s0 | x ⊆s0⟩
Use_def

O

s0 ∪{s0}

⇒
AUTO
Suppose ⇒
Stat3 : ¬

∀x ∈s0 ∪{s0}| x ⊆s0 ∪{s0}

⟨x0⟩→Stat3 ⇒
x0 ∈s0 ∪{s0} & x0 ̸⊆s0 ∪{s0}
⟨x0⟩→Stat2(Stat3⋆) ⇒
false; Discharge ⇒
Stat4 : ¬

∀x ∈s0 ∪{s0}, y ∈s0 ∪{s0}| x ∈y ∨y ∈x ∨x = y

⟨x1, y1⟩→Stat4 ⇒
AUTO
⟨x1, y1⟩→Stat1 ⇒
false; Discharge ⇒
QED
7.3.3 The Transitive Closure Operation
THEOREM act_reachability: [Activation of reachability]

∀x| ∅= ∅→⟨∃c,∀y| y ∈x & ∅= ∅→y ∈c⟩

. PROOF:
Suppose_not( ) ⇒
Stat1 : AUTO
⟨x⟩→Stat1(⋆) ⇒
Stat2 : ¬⟨∃c,∀y| y ∈x & ∅= ∅→y ∈c⟩
⟨x⟩→Stat2 ⇒
Stat3 : ¬⟨∀y| y ∈x & ∅= ∅→y ∈x⟩
⟨y⟩→Stat3 ⇒
false; Discharge ⇒
QED

7.3
From Reachability to Transﬁnite Induction
391
APPLY ⟨descsΘ : trCl⟩reachability

V(X) 
→∅= ∅, E(X, Y) 
→Y ∈X

⇒
THEOREM 9a: [Recursively deﬁned iterated members]

∀s, x, y| s ⊆trCl(s) &

x ∈trCl(s) & ∅= ∅& ∅= ∅& y ∈x →y ∈trCl(s)

&

∀y, x, z| y ∈trCl

{x}

& z ∈trCl

{y}

→z ∈trCl

{x}

&

∀s, t| s ⊆t & ⟨∀x,y| x ∈t & y ∈x & ∅= ∅& ∅= ∅→y ∈t⟩→trCl(s) ⊆t

.
 Now we can prove that, for any set s, trCl(s) includes s and is membership-
transitive.
THEOREM 9: [Stepwise reachability of ultimate members]
S ⊆trCl(S) &

X ∈trCl(S) & Y ∈X →Y ∈trCl(S)

. PROOF:

We proceed by contradiction. Suppose that our theorem is false, and let s, x, and y
be a counterexample.
Suppose_not(s, x, y) ⇒
AUTO
T 9a ⇒
Stat1 :

∀s, x,y| s ⊆trCl(s) &

x ∈trCl(s) & ∅= ∅& ∅= ∅& y ∈x →y ∈trCl(s)

⟨s, x, y⟩→Stat1 ⇒
false; Discharge ⇒
QED
THEOREM 10: [Transitivity of iterated membership]
Y ∈trCl

{X}

& Z ∈trCl

{Y}

→Z ∈trCl

{X}

. PROOF:
Suppose_not(y, x, z) ⇒
AUTO
T 9a ⇒
Stat1 :

∀y, x, z| y ∈trCl

{x}

& z ∈trCl

{y}

→z ∈trCl

{x}

⟨y, x, z⟩→Stat1 ⇒
false; Discharge ⇒
QED
THEOREM 11: [Minimality of the set of ultimate members] S ⊆T & Is_full(T) →
trCl(S) ⊆T. PROOF:
Suppose_not(s, t) ⇒
AUTO
T 9a ⇒
Stat1 :

∀s, t|
s ⊆t & ⟨∀x, y| x ∈t & y ∈x & ∅= ∅& ∅= ∅→y ∈t⟩→trCl(s) ⊆t

⟨s, t⟩→Stat1(Stat1⋆) ⇒
s ⊆t & ⟨∀x, y| x ∈t & y ∈x & ∅= ∅& ∅= ∅→y ∈t⟩→trCl(s) ⊆t
ELEM ⇒
x ∈t & y ∈x & ∅= ∅& ∅= ∅↔x ∈t & y ∈x
EQUAL ⇒
⟨∀x, y| x ∈t & y ∈x →y ∈t⟩→trCl(s) ⊆t
ELEM ⇒
Stat2 : ¬⟨∀x, y| x ∈t & y ∈x →y ∈t⟩

392
7
A Self-contained Beginning for Ref’s Main Proof Scenario
⟨x, y⟩→Stat2 ⇒
x ∈t & y ∈x & y /∈t
⟨t, x⟩→T 3 ⇒
false; Discharge ⇒
QED
7.3.4 A Basic Form of the Principle of Transﬁnite Induction

Next we state a basic form of the principle of transﬁnite induction, which simply
asserts that if there is any n satisfying a property P(X), there is a membership-
minimal m such that P(m). We formulate this as a theory providing just one theo-
rem.
THEORY transﬁnite_induction(n, P(X))
P(n)
END transﬁnite_induction
ENTER_THEORY transﬁnite_induction
DEF transﬁnite_induction · 0: [Witness for transﬁnite induction argument]
mt1Θ =Def arb

m : m ∈trCl

{n}
 P(m)
	
THEOREM transﬁnite_induction · 1: [Transﬁnite membership induction]
P(mt1Θ) &

K ∈mt1Θ →¬P(K)

. PROOF:
Suppose_not(k) ⇒
¬P(mt1Θ) ∨

k ∈mt1Θ & P(k)


Proceed by contradiction, ﬁrst noting that {m : m ∈trCl({n})| P(m)} cannot be null
since n belongs to it.
Suppose ⇒
Stat1 :

m : m ∈trCl

{n}
 P(m)
	
= ∅
Assump ⇒
P(n)

{n}, junk, bunk

→T 9 ⇒
n ∈trCl

{n}

⟨n⟩→Stat1 ⇒
false; Discharge ⇒
AUTO

The regularity axiom now tells us that there is an ∈-minimal element mt1Θ of
{m : m ∈trCl({n})| P(m)}. This necessarily satisﬁes mt1Θ ∈trCl({n}) & P(mt1Θ).

m : m ∈trCl

{n}
  P(m)
	
→T 0 ⇒
arb

m : m ∈trCl

{n}
 P(m)
	
∈

m : m ∈trCl

{n}
 P(m)
	
&
arb

m : m ∈trCl

{n}
 P(m)
	
∩

m : m ∈trCl

{n}
 P(m)
	
= ∅

7.3
From Reachability to Transﬁnite Induction
393
Use_def(mt1Θ) ⇒
Stat2 :
mt1Θ ∈

u : u ∈trCl

{n}
 P(u)
	
& mt1Θ ∩

u : u ∈trCl

{n}
 P(u)
	
= ∅
⟨mt1Θ⟩→Stat2 ⇒
mt1Θ ∈trCl

{n}

& P(mt1Θ)

The negative of our theorem now tells us that there is a k ∈mt1Θ such that P(k);
but such a k would clearly belong to {u : trCl({n})| P(u)}, and so would contradict
the minimality of mt1Θ. This contradiction proves our theorem.

{n}, mt1Θ, k

→T 9 ⇒
k ∈trCl

{n}

Suppose ⇒
Stat3 : k /∈

u : u ∈trCl

{n}
 P(u)
	
⟨k⟩→Stat3 ⇒
false; Discharge ⇒
k ∈

u : u ∈trCl

{n}
 P(u)
	
Discharge ⇒
QED
ENTER_THEORY Set_theory

Now we have a preliminary form of the principle of transﬁnite induction, which is
given by the following theory:
DISPLAY transﬁnite_induction
THEORY transﬁnite_induction

n, P(X)

P(n)
⇒(mt1Θ)

∀k| P(mt1Θ) &

k ∈mt1Θ →¬P(k)

END transﬁnite_induction
7.3.5 Some Basic Facts on Ordinal Numbers

Now we begin more serious development of the theory of ordinals, along von
Neumann’s line. Our ﬁrst theorem uses induction to show that if one ordinal t is
included in another ordinal s but not equal to s, then t must be a member of s, and
in fact must be the smallest element of s\t.
THEOREM 12: [Ordinal comparison lemma] O(S) & O(T) & T ⊆S →
T = S ∨

T = arb(S\T) & T ∈S\T

. PROOF:
Suppose_not(s, t) ⇒
O(s) & O(t) & t ⊆s & t ̸= s & ¬

t = arb(s\t) & t ∈s


394
7
A Self-contained Beginning for Ref’s Main Proof Scenario

For if our assertion is false, s must have as a proper subset t, in which case the
regularity axiom tells us that s\t has an element arb(s\t) disjoint from s\t. Plainly
arb(s\t) is also a member of the superset s of s\t. But then, by deﬁnition of
ordinal, arb(s\t) must be a subset of s ∩t, since it is disjoint from s\t. Therefore
arb(s\t) cannot include t, otherwise the initial assumption t ̸= arb(s\t) would be
contradicted.
Loc_def ⇒
Stat1 : a = arb(s\t)
⟨s⟩→T 5(⋆) ⇒
Is_full(s)
⟨s, t⟩→T 4 ⇒
Stat2 : t ̸⊆a & a ∈s & O(s) & O(t) & t ⊆s & t ̸= s

Since arb(s\t) fails to include t, there must be some b in t but not in arb(s\t). By
the deﬁnition of ordinals, this implies that arb(s\t) = b ∨arb(s\t) ∈b.
⟨b⟩→Stat2(Stat2⋆) ⇒
b ∈t & b /∈a
Use_def(O) ⇒
Stat3 : ⟨∀x ∈s, y ∈s| x ∈y ∨y ∈x ∨x = y⟩
⟨a, b⟩→Stat3(Stat2⋆) ⇒
a ∈b ∨a = b

Using the deﬁnition of ordinals once more, this time for t, we see that b must be
a subset of t, which rules out both arb(s\t) ∈b and arb(s\t) = b, because either
of these would yield arb(s\t) ∈t, which is impossible. We have contradicted our
original assumption, and so proved our theorem.
⟨t, b⟩→T 5 (Stat1⋆) ⇒
b ⊆t
(Stat1)Discharge ⇒
QED
THEOREM 13: [2nd ordinal comparison lemma; Boolean closure properties of O]
O(∅) &

O(S) & O(T) →(S ⊆T ∨T ⊆S) & O(S ∩T) & O(S ∪T)

. PROOF:
Suppose_not(s, t) ⇒
AUTO
Suppose ⇒
¬O(∅)
Use_def(O) ⇒
Stat0 : ¬⟨∀x ∈∅| x ⊆∅⟩∨¬⟨∀x ∈∅, y ∈∅| x ∈y ∨y ∈
x ∨x = y⟩
⟨x2, x1, y1⟩→Stat0 ⇒
false; Discharge ⇒
AUTO
Use_def(O) ⇒
Stat1 : ⟨∀x ∈s| x ⊆s⟩& ⟨∀x ∈t| x ⊆t⟩
Suppose ⇒
¬O(s ∩t)
⟨t, s ∩t⟩→T 6 ⇒
Stat2 : ¬⟨∀x ∈s ∩t| x ⊆s ∩t⟩
⟨x0⟩→Stat2(Stat2⋆) ⇒
x0 ∈s ∩t & x0 ̸⊆s ∩t
⟨x0, x0⟩→Stat1(Stat2⋆) ⇒
false; Discharge ⇒
AUTO

Now we prove the related but slightly less elementary result that one of any pair
of ordinals must include the other. For if not, neither of these ordinals is included
in the other, so neither can equal the intersection of the two, which is an ordinal as
just seen.

7.3
From Reachability to Transﬁnite Induction
395
Suppose ⇒
s ̸⊆t & t ̸⊆s

It now follows, using Theorem 12 twice, that s ∩t is equal to both arb(s\s ∩t)
and arb(t\s ∩t), and so, since neither of these sets is empty, is a member of both
s\s ∩t and t\s ∩t, which is impossible since the intersection of these two sets is
empty. This contradiction proves our theorem.
⟨s, s ∩t⟩→T 12 (⋆) ⇒
Stat3 : s ∩t ∈s\s ∩t
⟨t, s ∩t⟩→T 12 (⋆) ⇒
s ∩t ∈t\t ∩s
(Stat3⋆)Discharge ⇒
AUTO

We are now left with only one case to consider, namely that ¬O(s ∪t). Taking into
account the facts already proved along the way, this case is settled easily, leading
us the overall conclusion.
Suppose ⇒
s ⊆t
ELEM ⇒
s ∪t = t & s ∩t = s
EQUAL ⇒
false; Discharge ⇒
s ∪t = s & s ∩t = t
EQUAL ⇒
false; Discharge ⇒
QED

Next we show that the class of all ordinals (we will see soon that this is not a set)
is totally (and strictly) ordered by membership.
THEOREM 14: [Ordinal membership comparison] O(S) & O(T) →
S ∈T ∨T ∈S ∨S = T. PROOF:
Suppose_not(s, t) ⇒
Stat0 : O(s) & O(t) & s /∈t & t /∈s & s ̸= t

For if we suppose the contrary, and note that by Theorems 13 and 12 one must
include the other but not be equal to it, it follows (by the regularity axiom) that one
must be a member of the other, a contradiction which proves our theorem.
⟨s, t⟩→T 13 ⇒
s ⊆t ∨t ⊆s
⟨s, t⟩→T 12 (Stat0,Stat0⋆) ⇒
t ̸⊆s
⟨t, s⟩→T 12 (Stat0⋆) ⇒
false; Discharge ⇒
QED
∥Next we show that the class of ordinals is not a set.
THEOREM 15: [The class of ordinals is not a set] ¬

∀x| x ∈OS ↔O(x)

. PROOF+:
Suppose_not(o) ⇒
Stat1 : AUTO

396
7
A Self-contained Beginning for Ref’s Main Proof Scenario

For suppose the contrary, so that there is a set o consisting of all ordinals. But we
can show that o must be an ordinal. Indeed, if it were not, then by the deﬁnition of
ordinals there would exist a, b, c such that either a was a member but not a subset
of o, or b and c are two members of o not related by membership.
Suppose ⇒
¬O(o)
Use_def(O) ⇒
Stat2 : ¬

⟨∀x ∈o|x ⊆o⟩& ⟨∀x ∈o, y ∈o|x ∈y ∨y ∈x ∨x = y⟩

⟨a, b, c⟩→Stat2 ⇒
(a ∈o & a ̸⊆o) ∨

b, c ∈o & ¬(b ∈c ∨c ∈b ∨b = c)


In the second of these cases b and c are both plainly ordinals, so that this case is
ruled out by Theorem 14. Hence only the ﬁrst case need be considered.
Suppose ⇒
b, c ∈o & ¬(b ∈c ∨c ∈b ∨b = c)
⟨b⟩→Stat1 ⇒
O(b)
⟨c⟩→Stat1 ⇒
O(c)
⟨b, c⟩→T 14 ⇒
false; Discharge ⇒
Stat3 : a ∈o & a ̸⊆o

In this case the set a, which must plainly be an ordinal, must have a member d
which is not in o, and hence not an ordinal by Stat1 above, which is impossible, so
our theorem is proved.
⟨a⟩→Stat1 ⇒
O(a)
⟨d⟩→Stat3 ⇒
d ∈a & d /∈o
⟨d⟩→Stat1 ⇒
false; Discharge ⇒
O(o)
⟨o⟩→Stat1 ⇒
false; Discharge ⇒
QED

Our next theorem shows that, for ordinals, inclusion is equivalent to the disjunction
of identity and membership.
THEOREM 16: [Third ordinal comparison lemma] O(S) & O(T) →
(T ⊆S ↔T ∈S ∨T = S). PROOF:
Suppose_not(s, t) ⇒
AUTO

For in the contrary case there must exist two ordinals s and t such that either t is a
member but not a subset of s, or t is a subset of s but neither a member of, or equal
to, s;
ELEM ⇒
(t ̸⊆s & t ∈s) ∨(t ⊆s & t /∈s & t ̸= s)

but the ﬁrst case is ruled out by deﬁnition of ordinal and the second case by Theo-
rem 12, proving our theorem.

7.3
From Reachability to Transﬁnite Induction
397
⟨s, t⟩→T 5 ⇒
Stat1 : t ⊆s & t /∈s & t ̸= s
⟨s, t⟩→T 12 ⇒
false; Discharge ⇒
QED
∥It is sometimes convenient to use this theorem in the following modiﬁed form.
THEOREM 17: [Ordinal membership and comparison] O(S) & O(T) →
(T /∈S ↔S ⊆T). PROOF:
Suppose_not(s, t) ⇒
O(s) & O(t) & t /∈s & s ̸⊆t

Since t ∈s & s ⊆t is impossible, a counterexample to our assertion must satisfy
t /∈s & s ̸⊆t. But by Theorems 14 and 13 we then have s ⊆t, a contradiction which
proves the present corollary.
⟨s, t⟩→T 14 ⇒
s ∈t ∨s = t
⟨t, s⟩→T 13 ⇒
false; Discharge ⇒
QED

Our next lemma tells us that, for ordinals, membership in the successor of an ordi-
nal s is equivalent to inclusion in s.
THEOREM 18: [Membership in the successor of an ordinal s] O(S) →

T ∈next(S) ↔T ⊆S & O(T)

. PROOF:
Suppose_not(s, t) ⇒
AUTO
Use_def(next) ⇒
Stat1 : O(s) & ¬

t ∈s ∪{s} ↔t ⊆s & O(t)

Suppose ⇒
Stat2 : t ∈s ∨t = s & ¬

t ⊆s & O(t)

Suppose ⇒
Stat3 : t = s
EQUAL ⟨Stat1,Stat3⟩⇒
false;
(Stat4)Discharge ⇒
Stat5 : t ∈s
⟨s, t⟩→T 7 (Stat1,Stat5) ⇒
Stat6 : O(t)
⟨s, t⟩→T 16 (Stat1,Stat2,Stat5,Stat6) ⇒
Stat7 : false
(Stat7)Discharge ⇒
Stat8 : ¬

t ∈s ∨t = s & ¬

t ⊆s & O(t)

⟨s, t⟩→T 16 (Stat1,Stat8) ⇒
Stat9 : false
(Stat9)Discharge ⇒
QED
THEOREM 19: [Membership of s in an ordinal t implies inclusion of next(s) in t]
O(T) & S ∈T →next(S) ⊆T. PROOF+:
Suppose_not(m, i) ⇒
O(m) & i ∈m & Stat1 : next(i) ̸⊆m
⟨j⟩→Stat1 ⇒
j ∈next(i) & j /∈m
Use_def(next) ⇒
j ∈i
⟨j, m⟩→T 16 ⇒
m ̸⊆j

The following step exploits the fact, derived by means of proof-by-structure behind
the scenes, that j is an ordinal. Indeed, since i belongs to m which is an ordinal, it
is an ordinal in its turn and the same holds for next(i) and for j which belongs to it.
⟨m, j⟩→T 17 ⇒
false; Discharge ⇒
QED

398
7
A Self-contained Beginning for Ref’s Main Proof Scenario
7.4 Zorn’s Lemma

For subsequent use, we reformulate a few special cases of the principle of trans-
ﬁnite deﬁnition as THEORYs that can be applied internally within the proofs of
theorems.
THEORY transﬁnite_def_0_params

g(X), h1(X′)

END transﬁnite_def_0_params
ENTER_THEORY transﬁnite_def_0_params
DEF transﬁnite_def_0_params · 0a: [Function deﬁned by a one-parameter
transﬁnite recursion] fΘ(X) =Def g

h1

fΘ(t)

: t ∈X
	
THEOREM transﬁnite_def_0_params1: [One-parameter transﬁnite recursive
function deﬁnition] fΘ(X) = g

h1

fΘ(t)

: t ∈X
	
.
PROOF:
Suppose_not(x) ⇒
fΘ(x) ̸= g

h1

fΘ(t)

: t ∈x
	
Use_def(fΘ) ⇒
fΘ(x) = g

h1

fΘ(t)

: t ∈x
	
Discharge ⇒
QED
ENTER_THEORY Set_theory
DISPLAY transﬁnite_def_0_params
THEORY transﬁnite_def_0_params

g(X), h1(X′)

⇒(fΘ)

∀x| fΘ(x) = g

h1

fΘ(t)

: t ∈x
	
END transﬁnite_def_0_params

Our next proof establishes a ﬁrst, purely set-theoretic form of the well-known
Zorn’s Lemma. We prove that if t is any collection of sets such that every sub-
family of t linearly ordered by inclusion admits an upper bound in t, then t has an
element maximal for inclusion, i.e. not strictly included in any other element of t.
THEOREM 20: [Zorn’s lemma]

∀x ⊆T| ⟨∀u ∈x,v ∈x| u ⊇v ∨v ⊇u⟩→⟨∃w ∈T,∀y ∈x| w ⊇y⟩

→

∃y ∈T,∀x ∈T| ¬(x ⊇y & x ̸= y)

. PROOF+:
Suppose_not(t) ⇒
Stat1 :

∀x ⊆t| ⟨∀u ∈x, v ∈x| u ⊇v ∨v ⊇u⟩→⟨∃w ∈t,∀y ∈x| w ⊇y⟩

&
Stat2 : ¬

∃y ∈t,∀x ∈t| ¬(x ⊇y & x ̸= y)


7.4
Zorn’s Lemma
399

For supposing the contrary, we can deﬁne a mapping of t into t which sends each
element of t into a strictly larger element, and also a mapping of every subset of t
linearly ordered by inclusion into an upper bound for it in t.
Loc_def ⇒
larger =

x,arb

{y ∈t| y ⊇x & y ̸= x}

: x ∈t
	
APPLY ⟨⟩fcn_symbol

f(X) 
→arb

{y ∈t| y ⊇X & y ̸= X}

, g 
→larger, s 
→t

⇒
Stat3 :

∀x| larger↾x = if x ∈t then arb

{y ∈t| y ⊇x & y ̸= x}

else ∅ﬁ

Loc_def ⇒
upper_bound =

x,arb

y ∈t| ⟨∀u ∈x| y ⊇u⟩
	
: x ∈Pt
	
APPLY ⟨⟩fcn_symbol

f(X) 
→arb

y ∈t| ⟨∀u ∈X| y ⊇u⟩
	
,g 
→upper_bound, s 
→Pt

⇒
Stat4 :

∀x| upper_bound↾x = if x ∈Pt then arb

y ∈t| ⟨∀u ∈x| y ⊇u⟩
	
else ∅ﬁ


Now we use the functions ‘upper_bound’ and ‘larger’ to introduce the following
(recursively deﬁned) function, which we will then show maps each ordinal into t,
and is strictly monotone increasing.
APPLY⟨fΘ : Zo⟩transﬁnite_def_0_params

g(x) 
→larger↾(upper_bound↾x),h1(x) 
→x

⇒
Stat5 :

∀x| Zo(x) = larger↾

upper_bound↾

Zo(y) : y ∈x
	
Suppose ⇒
Stat6 :

∃x| O(x) & Zo(x) /∈t ∨

∃u ∈x| ¬

Zo(x) ⊇Zo(u) & Zo(x) ̸= Zo(u)


For if there exists some counterexample to this last assertion, then by transﬁnite
induction there exists a smallest such counterexample c.
⟨d⟩→Stat6 ⇒
O(d) & Zo(d) /∈t ∨

∃u ∈d|¬

Zo(d) ⊇Zo(u) & Zo(d) ̸= Zo(u)

APPLY ⟨mt1Θ : c⟩transﬁnite_induction

n 
→d, P(x) 
→

O(x) & Zo(x) /∈t ∨

∃u ∈x| ¬

Zo(x) ⊇Zo(u) & Zo(x) ̸= Zo(u)

⇒
Stat7 :

∀x
 
O(c) & Zo(c) /∈t ∨

∃u ∈c| ¬

Zo(c) ⊇Zo(u) & Zo(c) ̸= Zo(u)

&

x ∈c →
¬

O(x) & Zo(x) /∈t ∨

∃u ∈x| ¬

Zo(x) ⊇Zo(u) & Zo(x) ̸= Zo(u)

⟨∅⟩→Stat7 ⇒
O(c) & Zo(c) /∈t ∨

∃u ∈c| ¬

Zo(c) ⊇Zo(u) & Zo(c) ̸= Zo(u)

Suppose ⇒
Stat8 : ¬

∀x ∈c|
¬

O(x) & Zo(x) /∈t ∨

∃u ∈x| ¬

Zo(x) ⊇Zo(u) & Zo(x) ̸= Zo(u)

⟨x0⟩→Stat8 ⇒
x0 ∈c & O(x0) & Zo(x0) /∈t ∨

∃u ∈x0 | ¬

Zo(x0) ⊇Zo(u) & Zo(x0) ̸= Zo(u)

⟨x0⟩→Stat7 ⇒
false; Discharge ⇒
Stat9 :
¬

O(x) & Zo(x) /∈t ∨

∃u ∈x| ¬

Zo(x) ⊇Zo(u) & Zo(x) ̸= Zo(u)


400
7
A Self-contained Beginning for Ref’s Main Proof Scenario

For this minimal counterexample c, the set {Zo(y) : y ∈c} must be a collection of
subsets of t and must be linearly ordered by inclusion.
Suppose ⇒
Stat10 : t ̸⊇

Zo(y) : y ∈c
	
⟨x1⟩→Stat10 ⇒
Stat11 : x1 ∈

Zo(y) : y ∈c
	
& x1 /∈t
⟨y1⟩→Stat11 ⇒
y1 ∈c & x1 = Zo(y1)
⟨y1⟩→Stat9 ⇒
¬

O(y1) & Zo(y1) /∈t

& O(y1)
(Stat11)Discharge ⇒
t ⊇

Zo(y) : y ∈c
	
Suppose ⇒
Stat12 : ¬

∀u ∈

Zo(y) : y ∈c
	
, v ∈

Zo(y) : y ∈c
	u ⊇v ∨v ⊇u

⟨a, b⟩→Stat12 ⇒
Stat13 : a, b ∈

Zo(y) : y ∈c
	
& ¬(a ⊇b ∨b ⊇a)
⟨o1, o2⟩→Stat13 ⇒
Stat14 : o1, o2 ∈c
& ¬

Zo(o1) ⊇Zo(o2) ∨Zo(o2) ⊇Zo(o1)

& O(o1) & O(o2)
⟨o1⟩→Stat9 ⇒
Stat15 : ¬

∃u ∈o1 | ¬

Zo(o1) ⊇Zo(u) & Zo(o1) ̸= Zo(u)

⟨o2⟩→Stat9 ⇒
Stat16 : ¬

∃u ∈o2 | ¬

Zo(o2) ⊇Zo(u) & Zo(o2) ̸= Zo(u)

⟨o1, o2⟩→T 14 ⇒
o1 ∈o2 ∨o2 ∈o1 ∨o1 = o2
Suppose ⇒
o1 = o2
EQUAL ⇒
Zo(o1) = Zo(o2)
(Stat14)Discharge ⇒
o1 ∈o2 ∨o2 ∈o1
Suppose ⇒
o2 ∈o1
⟨o2⟩→Stat15 ⇒
false; Discharge ⇒
o1 ∈o2
⟨o1⟩→Stat16 ⇒
false; Discharge ⇒

∀u ∈

Zo(y) : y ∈c
	
, v ∈

Zo(y) : y ∈c
	
| u ⊇v ∨v ⊇u


Thus, by deﬁnition, {Zo(y) : y ∈c} must have an upper bound cb which is a subset
of t, and therefore, by the axiom of choice, upper_bound↾{Zo(z1) : z1 ∈c} must
belong to t and include every element of {Zo(y) : y ∈c}.

Zo(z1) : z1 ∈c
	
→Stat1 ⇒
Stat17 :

∃w ∈t,∀y ∈

Zo(z1) : z1 ∈c
	
| w ⊇y

⟨cb⟩→Stat17 ⇒
cb ∈t &

∀y ∈

Zo(z1) : z1 ∈c
	
| cb ⊇y


Zo(z1) : z1 ∈c
	
→Stat4 ⇒
upper_bound↾

Zo(z1) : z1 ∈c
	
=
if

Zo(z1) : z1 ∈c
	
∈Pt
then arb

y ∈t
 
∀u ∈

Zo(z1) : z1 ∈c
	
| y ⊇u
	
else ∅ﬁ
Suppose ⇒

Zo(z1) : z1 ∈c
	
/∈Pt

t,

Zo(z1) : z1 ∈c
	
→T 1 (Stat9⋆) ⇒
false; Discharge ⇒
upper_bound↾

Zo(z1) : z1 ∈c
	
=
arb

y ∈t
 
∀u ∈

Zo(z1) : z1 ∈c
	 y ⊇u
	
Suppose ⇒
Stat19 :

y ∈t
 
∀u ∈

Zo(z1) : z1 ∈c
	 y ⊇u
	
= ∅

7.4
Zorn’s Lemma
401
⟨cb⟩→Stat19 ⇒
false; Discharge ⇒

y ∈t
 
∀u ∈

Zo(z1) : z1 ∈c
	 y ⊇u
	
̸= ∅

y ∈t
 
∀u ∈

Zo(z1) : z1 ∈c
	  y ⊇u
	
→T 0 ⇒
arb

y ∈t
 
∀u ∈

Zo(z1) : z1 ∈c
	 y ⊇u
	
∈

y ∈t
 
∀u ∈

Zo(z1) : z1 ∈c
	 y ⊇u
	
(Stat17)ELEM ⇒
Stat20 : upper_bound↾

Zo(z1) : z1 ∈c
	
∈

y ∈t
 
∀u ∈

Zo(z1) : z1 ∈c
	 y ⊇u
	
⟨⟩→Stat20 ⇒
upper_bound↾

Zo(z1) : z1 ∈c
	
∈t & Stat21 :

∀u ∈

Zo(z1) : z1 ∈c
	 upper_bound↾

Zo(z1) : z1 ∈c
	
⊇u


It
follows
by
a
second
use
of
the
axiom
of
choice
that
larger↾(upper_bound↾{Zo(z1) :
z1 ∈c}) = Zo(c) is an element of t properly
including every element of {Zo(y) : y ∈c}. This refutes our earlier supposition,
and so lets us conclude that Zo sends ordinals into t and is strictly monotone
increasing.

upper_bound↾

Zo(z1) : z1 ∈c
	
→Stat3 ⇒
larger↾

upper_bound↾

Zo(z1) : z1 ∈c
	
=
arb

y ∈t| y ⊇upper_bound↾

Zo(z1) : z1 ∈c
	
&
y ̸= upper_bound↾

Zo(z1) : z1 ∈c
		

upper_bound↾

Zo(z1) : z1 ∈c
	
→Stat2 ⇒
Stat22 : ¬

∀x ∈t| ¬

x ⊇
upper_bound↾

Zo(z1) : z1 ∈c
	
& x ̸= upper_bound↾

Zo(z1) : z1 ∈c
	
⟨cu⟩→Stat22 ⇒
cu ∈t & cu ⊇upper_bound↾

Zo(z1) : z1 ∈c
	
&
cu ̸= upper_bound↾

Zo(z1) : z1 ∈c
	
Suppose ⇒
Stat23 :

y ∈t| y ⊇upper_bound↾

Zo(z1) : z1 ∈c
	
& y ̸= upper_bound↾

Zo(z1) : z1 ∈c
		
= ∅
⟨cu⟩→Stat23 ⇒false; Discharge ⇒

y ∈t|y ⊇upper_bound↾

Zo(z1) : z1 ∈c
	
& y ̸= upper_bound↾

Zo(z1) : z1 ∈c
		
̸= ∅

y ∈t| y ⊇upper_bound↾

Zo(z1) : z1 ∈c
	
& y ̸= upper_bound↾

Zo(z1) : z1 ∈c
		
→T 0 ⇒
arb

y ∈t| y ⊇upper_bound↾

Zo(z1) : z1 ∈c
	
& y ̸= upper_bound↾

Zo(z1) : z1 ∈c
		
∈

y ∈t| y ⊇upper_bound↾

Zo(z1) : z1 ∈c
	
& y ̸= upper_bound↾

Zo(z1) : z1 ∈c
		
(Stat20)ELEM ⇒
larger↾

upper_bound↾

Zo(z1) : z1 ∈c
	
∈

y ∈t| y ⊇upper_bound↾

Zo(z1) : z1 ∈c
	
& y ̸= upper_bound↾

Zo(z1) : z1 ∈c
		
⟨c⟩→Stat5 ⇒
Stat24 : Zo(c) ∈

y ∈t| y ⊇upper_bound↾

Zo(z1) : z1 ∈c
	

402
7
A Self-contained Beginning for Ref’s Main Proof Scenario
& y ̸= upper_bound↾

Zo(z1) : z1 ∈c
		
⟨⟩→Stat24 ⇒
Zo(c) ∈t & Zo(c) ⊇upper_bound↾

Zo(z1) : z1 ∈c
	
&
Zo(c) ̸= upper_bound↾

Zo(z1) : z1 ∈c
	
ELEM ⇒
Stat25 :

∃u ∈c| ¬

Zo(c) ⊇Zo(u) & Zo(c) ̸= Zo(u)

⟨cv⟩→Stat25 ⇒
cv ∈c & ¬

Zo(c) ⊇Zo(cv) & Zo(c) ̸= Zo(cv)

(Stat22)ELEM ⇒
upper_bound↾

Zo(z1) : z1 ∈c
	
̸⊇Zo(cv)
⟨Zo(cv)⟩→Stat21 ⇒
Stat26 : Zo(cv) /∈

Zo(z1) : z1 ∈c
	
⟨cv⟩→Stat26 ⇒
false; Discharge ⇒
Stat27 :
¬

∃x| O(x) & Zo(x) /∈t ∨

∃u ∈x| ¬

Zo(x) ⊇Zo(u) & Zo(x) ̸= Zo(u)


Thus Zo is a 1-1 map of all ordinals into the set t, a thing impossible. One way of
seeing this is to consider the inverse zoInv of the restriction of Zo to the ordinals,
extended arbitrarily so that all of its images are ordinal numbers. Then the set
{zoInv(x) : x ∈t} should coincide with the class of all ordinals, which is known to
be a proper class.
Suppose ⇒
Stat30 : ¬

∀y,∃x| O(x) & Zo(x) = y ∨¬

∃x′ | O(x′) & Zo(x′) = y

⟨y2⟩→Stat30(Stat30⋆) ⇒
Stat31 :
¬

∃x| O(x) & Zo(x) = y2 ∨¬

∃x′ | O(x′) & Zo(x′) = y2

& O(∅)
Suppose ⇒
Stat32 :

∃x′ | O(x′) & Zo(x′) = y2

⟨x2⟩→Stat32 ⇒
AUTO
⟨x2⟩→Stat31(Stat31⋆) ⇒
false; Discharge ⇒
AUTO
⟨∅⟩→Stat31(Stat31⋆) ⇒
false; Discharge ⇒

∀y,∃x| O(x) & Zo(x) = y ∨¬

∃x′ | O(x′) & Zo(x′) = y

APPLY ⟨v1Θ : zoInv⟩Skolem ⇒
Stat33 :

∀y| O

zoInv(y)

& Zo

zoInv(y)

= y ∨¬

∃x′ | O(x′) & Zo(x′) = y


zoInv(x) : x ∈t
	
→T 15 ⇒
Stat34 : ¬

∀x| x ∈

zoInv(x) : x ∈t
	
↔O(x)

⟨e⟩→Stat34(Stat34⋆) ⇒
e ∈

zoInv(x) : x ∈t
	
̸= O(e)
Suppose ⇒
Stat35 : e ∈

zoInv(x) : x ∈t
	
⟨x3⟩→Stat35(Stat34⋆) ⇒
x3 ∈t & e = zoInv(x3) & ¬O(e)
⟨x3⟩→Stat33(Stat33,Stat33⋆) ⇒
O

zoInv(x3)

EQUAL ⟨Stat35⟩⇒
false; Discharge ⇒
AUTO
⟨e⟩→Stat27(Stat34⋆) ⇒
Stat36 : e /∈

zoInv(x) : x ∈t
	
& O(e) & Zo(e) ∈t &
Stat37 : ¬

∃u ∈e| ¬

Zo(e) ⊇Zo(u) & Zo(e) ̸= Zo(u)


Zo(e)

→Stat36(Stat36,Stat36⋆) ⇒
e ̸= zoInv

Zo(e)

Suppose ⇒
Stat38 : ¬

∃x′ | O(x′) & Zo(x′) = Zo(e)

⟨e⟩→Stat38(Stat36⋆) ⇒
false; Discharge ⇒
AUTO

7.4
Zorn’s Lemma
403

Zo(e)

→Stat33(Stat36⋆) ⇒
O

zoInv

Zo(e)

& Zo

zoInv

Zo(e)

= Zo(e)

e, zoInv

Zo(e)

→T 14 (Stat36⋆) ⇒
e ∈zoInv

Zo(e)

∨zoInv

Zo(e)

∈e
Suppose ⇒
zoInv

Zo(e)

∈e

zoInv

Zo(e)

→Stat37(Stat36⋆) ⇒
false; Discharge ⇒
AUTO

zoInv

Zo(e)

→Stat27(Stat34⋆) ⇒
Stat39 : ¬

∃u ∈zoInv

Zo(e)

¬

Zo

zoInv

Zo(e)

⊇Zo(u) & Zo

zoInv

Zo(e)

̸= Zo(u)

⟨e⟩→Stat39(Stat36⋆) ⇒
false; Discharge ⇒
QED

The following corollary of the preceding theorem shows that if s is any member
of a family t of sets satisfying the hypotheses of that theorem, then s is contained
in an element of t maximal in t.
THEOREM 21: [Zorn’s lemma, generalized form]

∀x ⊆T| ⟨∀u ∈x,v ∈x| u ⊇v ∨v ⊇u⟩→⟨∃w ∈T,∀y ∈x| w ⊇y⟩

→

∀u ∈T,∃y ∈T| y ⊇u & ⟨∀x ∈T| x ⊇y →x = y⟩

. PROOF:
Suppose_not(t) ⇒
Stat1 :

∀x ⊆t| ⟨∀u ∈x, v ∈x| u ⊇v ∨v ⊇u⟩→⟨∃w ∈t,∀y ∈x| w ⊇y⟩

&
Stat2 : ¬

∀u ∈t,∃y ∈t| y ⊇u & ⟨∀x ∈t| x ⊇y →x = y⟩


For suppose that u ∈t contradicts the conclusion of our theorem, and consider the
subset tt of all elements of t which contain u. It is clear that every collection of
subsets of tt linearly ordered by inclusion has an upper bound in tt, and so by the
preceding theorem tt contains an element ma inclusion-maximal among all the sets
in tt.
⟨u⟩→Stat2 ⇒
u ∈t & Stat3 : ¬

∃y ∈t| y ⊇u & ⟨∀x ∈t| x ⊇y →x = y⟩

Loc_def ⇒
tt = {x ∈t| x ⊇u}
Suppose ⇒
Stat4 : t ̸⊇tt
⟨c⟩→Stat4 ⇒
c /∈t & Stat5 : c ∈{x ∈t| x ⊇u}
⟨⟩→Stat5 ⇒
false; Discharge ⇒
t ⊇tt
Suppose ⇒
Stat6 :
¬

∀x ⊆tt| ⟨∀u ∈x, v ∈x| u ⊇v ∨v ⊇u⟩→⟨∃w ∈tt,∀y ∈x| w ⊇y⟩

⟨d⟩→Stat6 ⇒
d ⊆tt & ⟨∀u ∈d, v ∈d| u ⊇v ∨v ⊇u⟩& Stat7 :
¬⟨∃w ∈tt,∀y ∈d| w ⊇y⟩
⟨d⟩→Stat1 ⇒
Stat8 : ⟨∃w ∈t,∀y ∈d| w ⊇y⟩
⟨wd⟩→Stat8 ⇒
wd ∈t & Stat9 : ⟨∀y ∈d| wd ⊇y⟩

Since u ∈tt, d cannot be null, from which it is easily seen that wd must contain u,
and so wd ∈tt. Thus it follows by Theorem 20 that tt has an element ma maximal
(for inclusion) in tt.

404
7
A Self-contained Beginning for Ref’s Main Proof Scenario
Suppose ⇒
u /∈tt
ELEM ⇒
Stat10 : u /∈{x ∈t| x ⊇u}
⟨⟩→Stat10 ⇒
false; Discharge ⇒
u ∈tt
Suppose ⇒
d = ∅
⟨u⟩→Stat7 ⇒
Stat11 : ¬⟨∀y ∈d| u ⊇y⟩
⟨a⟩→Stat11 ⇒
false; Discharge ⇒
Stat12 : d ̸= ∅
⟨b⟩→Stat12 ⇒
b ∈d
⟨b⟩→Stat9 ⇒
wd ⊇b
ELEM ⇒
Stat13 : b ∈{x ∈t| x ⊇u}
⟨⟩→Stat13 ⇒
wd ⊇u
Suppose ⇒
wd /∈tt
ELEM ⇒
Stat14 : wd /∈{x ∈t| x ⊇u}
⟨⟩→Stat14 ⇒
false; Discharge ⇒
wd ∈tt
⟨wd⟩→Stat7 ⇒
false; Discharge ⇒

∀x ⊆tt| ⟨∀u ∈x, v ∈x| u ⊇v ∨v ⊇u⟩→⟨∃w ∈tt,∀y ∈x| w ⊇y⟩

⟨tt⟩→T 20 ⇒
Stat15 :

∃y ∈tt,∀x ∈tt| ¬(x ⊇y & x ̸= y)

⟨ma⟩→Stat15 ⇒
ma ∈tt & Stat16 :

∀x ∈tt| ¬(x ⊇ma & x ̸= ma)


But it is easily seen that ma is maximal in the whole collection t, and so our theo-
rem is proved.
⟨ma⟩→Stat3 ⇒
¬

ma ⊇u & ⟨∀x ∈t| x ⊇ma →x = ma⟩

ELEM ⇒
Stat17 : ma ∈{x ∈t| x ⊇u}
⟨⟩→Stat17 ⇒
ma ⊇u
ELEM ⇒
Stat18 : ¬⟨∀x ∈t| x ⊇ma →x = ma⟩
⟨e⟩→Stat18 ⇒
e ∈t & e ⊇ma & e ̸= ma
ELEM ⇒
e ⊇u
Suppose ⇒
e /∈tt
ELEM ⇒
Stat19 : e /∈{x ∈t| x ⊇u}
⟨⟩→Stat19 ⇒
false; Discharge ⇒
e ∈tt
⟨e⟩→Stat16 ⇒
false; Discharge ⇒
QED

Next we note a special case common in applications of Theorem 21, namely that
in which the union of any linearly ordered collection of elements of t is a subset
of t.
THEOREM 22: [Zorn’s lemma for union-closed collections]

∀x ⊆T| ⟨∀u ∈x,v ∈x| u ⊇v ∨v ⊇u⟩→
x ∈T

→

∀u ∈T,∃y ∈T| y ⊇u & ⟨∀x ∈T| x ⊇y →x = y⟩

. PROOF:

7.5
Finiteness
405
Suppose_not(t) ⇒
Stat1 :

∀x ⊆t| ⟨∀u ∈x, v ∈x| u ⊇v ∨v ⊇u⟩→
x ∈t

&
¬

∀u ∈t,∃y ∈t| y ⊇u & ⟨∀x ∈t| x ⊇y →x = y⟩


For given any subcollection of t linearly ordered by inclusion, 
t plainly includes
all the sets in t, and so our present assertion follows immediately from the preced-
ing theorem.
T 21 ⇒
Stat2 : ¬

∀x ⊆t| ⟨∀u ∈x, v ∈x| u ⊇v ∨v ⊇u⟩→
⟨∃w ∈t,∀y ∈x| w ⊇y⟩

⟨a⟩→Stat2 ⇒
a ⊆t & ⟨∀u ∈a,v ∈a| u ⊇v ∨v ⊇u⟩&
Stat3 : ¬⟨∃w ∈t,∀y ∈a| w ⊇y⟩
⟨a⟩→Stat1 ⇒

a ∈t
⟨
a⟩→Stat3 ⇒
Stat4 : ¬⟨∀y ∈a| 
a ⊇y⟩
⟨b⟩→Stat4 ⇒
b ∈a & Stat5 : 
a ̸⊇b
⟨b, a⟩→T 2 ⇒
false; Discharge ⇒
QED
7.5 Finiteness

Traditionally, ﬁniteness is deﬁned through the notion of cardinality of a set: a set
is ﬁnite if its cardinality precedes the ﬁrst inﬁnite ordinal. As a shortcut, to begin
developing an acceptable formal treatment of ﬁniteness without much prepara-
tory work, we adopt here the following deﬁnition (reminiscent of Tarski’s 1924
paper [Tar24]): a set F is ﬁnite if every nonnull family of subsets of F owns an
inclusion-minimal element. This notion can be speciﬁed very succinctly in terms
of the powerset operator.
THEOREM 23: [Monotonicity of powerset] S ⊇X →PX ∪{∅, X} ⊆PS. PROOF:
Suppose_not(s0, x0) ⇒
AUTO
Set_monot ⇒
{x : x ⊆x0} ⊆{x : x ⊆s0}
Use_def(P) ⇒
Stat1 : ∅/∈{x : x ⊆s0} ∨x0 /∈{x : x ⊆s0}
⟨∅, x0⟩→Stat1 ⇒
false
Discharge ⇒
QED
DEF Fin: [Finiteness property] Fin(X) ↔Def

∀g ∈P(PX)\{∅},∃m| g ∩Pm = {m}

THEOREM 24: [Monotonicity of ﬁniteness] Y ⊇X & Fin(Y) →Fin(X). PROOF:
Suppose_not(y0, x0) ⇒
AUTO
⟨y0, x0⟩→T 23 (⋆) ⇒
Py0 ⊇Px0
Use_def(Fin) ⇒
Stat1 : ¬

∀g ∈P(Px0)\{∅},∃m| g ∩Pm = {m}

&

406
7
A Self-contained Beginning for Ref’s Main Proof Scenario

∀g′ ∈P(Py0)\{∅},∃m| g′ ∩Pm = {m}

⟨Py0,Px0⟩→T 23 (⋆) ⇒
P(Py0) ⊇P(Px0)
⟨g0, g0⟩→Stat1(Stat1⋆) ⇒
¬

∃m| g0 ∩Pm = {m}

&

∃m| g0 ∩Pm = {m}

Discharge ⇒
QED
THEORY ﬁniteInduction

s0, P(S)

Fin(s0) & P(s0)
END ﬁniteInduction
ENTER_THEORY ﬁniteInduction
THEOREM ﬁniteInduction1.

∃m
 
s ⊆s0 | P(s)
	
∩Pm = {m}

. PROOF:
Suppose_not() ⇒
AUTO
Assump ⇒
Fin(s0) & P(s0)
Use_def(Fin) ⇒
Stat1 :

∀g ∈P(Ps0)\{∅},∃m| g ∩Pm = {m}


{s ⊆s0 | P(s)}

→Stat1 ⇒

s ⊆s0 | P(s)
	
/∈P(Ps0)\{∅}
Suppose ⇒
Stat2 : s0 /∈

s ⊆s0 | P(s)
	
⟨s0⟩→Stat2 ⇒
false; Discharge ⇒

s ⊆s0 | P(s)
	
/∈P(Ps0)
Use_def(P) ⇒
Stat3 :

s ⊆s0 | P(s)
	
/∈

y : y ⊆{z : z ⊆s0}
	

s ⊆s0 | P(s)
	
→Stat3 ⇒
Stat4 :

s ⊆s0 | P(s)
	
̸⊆{z : z ⊆s0}
⟨s1⟩→Stat4 ⇒
Stat5 : s1 ∈

s : s ⊆s0 | P(s)
	
& s1 /∈{z : z ⊆s0}
⟨s, s1⟩→Stat5(Stat5⋆) ⇒
false
Discharge ⇒
QED
APPLY ⟨v1Θ : ﬁnΘ⟩Skolem⇒
THEOREM ﬁniteInduction0.

s ⊆s0 | P(s)
	
∩PﬁnΘ = {ﬁnΘ}.
THEOREM ﬁniteInduction2: [Minimal ﬁnite set satisfying P]
S ⊆ﬁnΘ →s0 ⊇S & Fin(S) &

P(S) ↔S = ﬁnΘ

. PROOF:
Suppose_not(s1) ⇒
AUTO
T ﬁniteInduction0 ⇒

s ⊆s0 | P(s)
	
∩PﬁnΘ = {ﬁnΘ}
ELEM ⇒
Stat1 : ﬁnΘ ∈

s ⊆s0 | P(s)
	
⟨⟩→Stat1 ⇒
ﬁnΘ ⊆s0 & P(ﬁnΘ)
Assump ⇒
Fin(s0)
⟨s0, ﬁnΘ⟩→T 24 ⇒
Fin(ﬁnΘ)
⟨ﬁnΘ, s1⟩→T 24 ⇒
P(s1) ̸= s1 = ﬁnΘ
Suppose ⇒
s1 = ﬁnΘ
EQUAL ⇒
false; Discharge ⇒
s1 /∈

s ⊆s0 | P(s)
	
∩PﬁnΘ & P(s1)

7.5
Finiteness
407
Suppose ⇒
s1 /∈PﬁnΘ
Use_def(P) ⇒
Stat2 : s1 /∈{y : y ⊆ﬁnΘ}
⟨s1⟩→Stat2 ⇒
false
Discharge ⇒
Stat3 : s1 /∈

s ⊆s0 | P(s)
	
⟨s1⟩→Stat3 ⇒
false
Discharge ⇒
QED
ENTER_THEORY Set_theory
DISPLAY ﬁniteInduction
THEORY ﬁniteInduction

s0, P(S)

Fin(s0) & P(s0)
⇒(ﬁnΘ)

∀s| s ⊆ﬁnΘ →s0 ⊇s & Fin(s) &

P(s) ↔s = ﬁnΘ

END ﬁniteInduction
THEOREM 25: [Finiteness of the union of a ﬁnite set with a singleton]
Fin(F) →Fin

F ∪{X}

. PROOF:
Suppose_not(f0, x0) ⇒
AUTO

Arguing by contradiction, suppose that f0 and x0 are such that f0 is ﬁnite but
f0 ∪{x0} is not. A nonnull family g0 of subsets of f0 ∪{x0} must then exist none
of whose elements is minimal. On the other hand {y\{x0} : y ∈g0}, which is
also nonnull but consists entirely of subsets of f0, must have a minimal element
m0 = y0\{x0}, with y0 ∈g0.
Use_def(Fin) ⇒
Stat0 : ¬

∀g ∈P

P

f0 ∪{x0}

\{∅},∃m| g ∩Pm = {m}

&
Stat1 :

∀h ∈P(Pf0)\{∅},∃m| h ∩Pm = {m}

⟨g0⟩→Stat0(Stat0) ⇒
Stat2 : ¬

∃m| g0 ∩Pm = {m}

&
g0 ∈P

P

f0 ∪{x0}

& g0 ̸= ∅
Loc_def ⇒
Stat3 : h0 =

y\{x0} : y ∈g0
	
Suppose ⇒
h0 /∈P(Pf0)\{∅}
Suppose ⇒
Stat4 :

y\{x0} : y ∈g0
	
= ∅
⟨arb(g0)⟩→Stat4(Stat2,Stat2) ⇒
false;
Discharge ⇒
AUTO
Use_def(P) ⇒
Stat5 : h0 /∈

h : h ⊆{k : k ⊆f0}
	
⟨h0⟩→Stat5(Stat5⋆) ⇒
Stat6 : h0 ̸⊆{k : k ⊆f0}
⟨k0⟩→Stat6(Stat3⋆) ⇒
Stat7 : k0 ∈

y\{x0} : y ∈g0
	
& k0 /∈{k : k ⊆f0}
⟨y1, k0⟩→Stat7(Stat7⋆) ⇒
y1 ∈g0 & y1 ̸⊆f0 ∪{x0}

408
7
A Self-contained Beginning for Ref’s Main Proof Scenario
Use_def(P) ⇒
Stat8 : g0 ∈

h : h ⊆

k : k ⊆f0 ∪{x0}
		
⟨h1⟩→Stat8(Stat7⋆) ⇒
Stat9 : y1 ∈

k : k ⊆f0 ∪{x0}
	
⟨k1⟩→Stat9(Stat7⋆) ⇒
false
Discharge ⇒
AUTO
⟨h0, m0⟩→Stat1(Stat3⋆) ⇒
Stat10 : m0 ∈

y\{x0} : y ∈g0
	
& h0 ∩Pm0 = {m0}
⟨y0⟩→Stat10(Stat10⋆) ⇒
Stat11 : m0 = y0\{x0} & y0 ∈g0

We will reach the desired contradiction by showing that either m0 or y0 = m0 ∪{x0}
is minimal in g0. We check ﬁrst that m0 itself must be minimal when m0 ∈g0.
Suppose ⇒
m0 ∈g0
⟨m0⟩→Stat2(Stat10⋆) ⇒
Stat12 : g0 ∩Pm0 ̸⊆{m0}
Use_def(Pm0) ⇒
AUTO
⟨z0⟩→Stat12(Stat3⋆) ⇒
Stat13 : z0 ∈{h : h ⊆m0} & z0 /∈

y\{x0} : y ∈g0
	
& z0 ∈g0
⟨h2, z0⟩→Stat13(Stat11⋆) ⇒
false
Discharge ⇒
AUTO

Suppose next that m0 /∈g0; we will reach a contradiction by showing that y0 is
minimal in g0.
⟨y0, y0⟩→T 23 (Stat11⋆) ⇒
y0 ∈Py0
⟨y0⟩→Stat2(Stat11⋆) ⇒
Stat14 : g0 ∩Py0 ̸⊆{y0}
Use_def(Py0) ⇒
AUTO
⟨z1⟩→Stat14(Stat11⋆) ⇒
Stat15 : z1 ∈{h : h ⊆y0} & z1 ∈g0 & z1\{x0} ̸= y0\{x0}
EQUAL ⟨Stat10⟩⇒
h0 ∩P

y0\{x0}

=

y0\{x0}
	
Suppose ⇒
z1\{x0} /∈P

y0\{x0}

Use_def(P) ⇒
Stat16 : z1\{x0} /∈

h : h ⊆y0\{x0}
	

z1\{x0}

→Stat16(Stat16⋆) ⇒
z1\{x0} ̸⊆y0\{x0}
⟨h3⟩→Stat15(Stat16⋆) ⇒
false;
Discharge ⇒
AUTO
Suppose ⇒
Stat17 : z1\{x0} /∈

y\{x0} : y ∈g0
	
⟨z1⟩→Stat17(Stat15⋆) ⇒
false; Discharge ⇒
z1\{x0} ∈h0
(Stat15⋆)Discharge ⇒
QED
THEOREM 26: [Finiteness of the union of two ﬁnite sets]
Fin(X) & Fin(Y) →Fin(X ∪Y). PROOF:

References
409
Suppose_not(x0, y1) ⇒
AUTO

Arguing by contradiction, suppose that x0 and y1 are ﬁnite sets whose union is not
ﬁnite. Then ﬁnite induction enables us to take a minimal subset y0 of y1 for which
x0 ∪y0 is not ﬁnite.
APPLY ⟨ﬁnΘ : y0⟩ﬁniteInduction

s0 
→y1, P(S) 
→¬Fin(x0 ∪S)

⇒
Stat1 :

∀s| s ⊆y0 →y1 ⊇s & Fin(s) &

¬Fin(x0 ∪s) ↔s = y0

⟨y0⟩→Stat1(Stat1⋆) ⇒
Fin(y0) & ¬Fin(x0 ∪y0)
Loc_def ⇒
a0 = arb(y0)

Since
y0
cannot be
empty, the
union
x0 ∪y0
can
be
decomposed as
x0 ∪(y0\{arb(y0)}) ∪{arb(y0)}, where x0 ∪(y0\{arb(y0)}) is ﬁnite by inductive
hypothesis. But then x0 ∪y0 must also be ﬁnite, by the preceding theorem.
Suppose ⇒
x0 ∪y0 = x0
EQUAL ⟨Stat1⟩⇒
¬Fin(x0)
Discharge ⇒
Stat2 : y0\{a0} ̸= y0 & x0 ∪

y0\{a0}

∪{a0} = x0 ∪y0

y0\{a0}

→Stat1(Stat1⋆) ⇒
Fin

x0 ∪

y0\{a0}


x0 ∪

y0\{a0}

,a0

→T 25 (Stat2⋆) ⇒
Fin

x0 ∪

y0\{a0}

∪{a0}

EQUAL ⇒
false
Discharge ⇒
QED

The
proof
of
the
following
is
left
as
an
exercise
for
the
reader:
THEOREM 27: [“All that ends is short”] Fin(∅).
References
[Acz88] Aczel, P.: Non-Well-Founded Sets. CSLI Lecture Notes, vol. 14. CLSI, Stanford (1988)
[Ped62] Peddicord, R.: The number of full sets with n elements. Proc. Am. Math. Soc. 13(5),
825–828 (1962)
[Tar24] Tarski, A.: Sur les ensembles ﬁni. Fundam. Math. VI, 45–95 (1924)


Index
A
ℵ, 148
ÆtnaNova, 205, 257
Acceptable ordering of variables, 111
Acyclicity (of membership), 17
Additivity, 226
Algebraic deduction, 227, 228
Analytic set, 34
APPLY, 23, 24, 213
arb, 16
Arithmetic
Peano’s integer a., 333–335
Presburger’s additive integer a., 131–133
Assertion (of a proof statement), 207
Assignment
a. covering a collection of predicate
formulae/terms, 46, 47
a. covering a collection of propositional
formulae, 38
a. for formulae of the propositional
calculus, 38
value of an a. for a predicate expression, 47
value of an a. for a propositional formula,
38
Associativity, 200, 201
AUTO, 207
Average (real a.), 300
Axiom, 39
a. of reﬂection, 89, 346–358
a. of ZFC, 77, 78
a. of choice, 78
a. of elementary sets, 77
a. of extension, 77
a. of inﬁnity, 30, 77
a. of power set, 77
a. of regularity, 77
a. of union, 77
a. schema of replacement, 78
a. schema of subsets, 77
a. schema, 40
logical a. for equality-extended predicate
calculus, 75
logical a. for the predicate calculus, 49–51
logical a. for the propositional calculus, 39,
40
B
Behmann, 151
B. formula, 151
decision algorithm for B. formulae,
152–157
Bernays-Schönﬁnkel sentence, 72
Blobbing, 11, 208, 209, 235, 236
C
Calculus
equality-extended predicate c., 75, 76
(ﬁrst-order) predicate c., 11–13, 37, 44–52
formulae of the predicate c., 45
unsolvability of the validity problem for
predicate c., 37
propositional c., 10, 11, 37–44
connectives of the propositional c., 38
constants of the propositional c., 38
formulae of the propositional c., 38
solvability of the validity problem for
propositional c., 39
variables of the propositional c., 38
(second-order) predicate c., 21, 22
Cantor, 27, 33
C.’s theorem, 31
car, 18, 258
Cardinal, 29–32, 268–270
a decidable language about c., 148–151
J.T. Schwartz et al., Computational Logic and Set Theory,
DOI 10.1007/978-0-85729-808-9, © Springer-Verlag London Limited 2011
411

412
Index
Cardinal (cont.)
closed set of c., 87
inaccessible c., 85, 359
Mahlo c., 88
measurable c., 88
regular c., 85
strong limit c., 85
supercompact c., 89
thin set of c., 87
unbounded set of c., 87
Cardinality, 29, 269–272
Cauchy, 2
C. integral formula, 310
C. integral theorem, 33, 35, 310
C. sequence of rationals, 33
cdr, 18, 258
Chaitin’s theorem, 313–315
Choice
axiom of c., 78
c. operation, 16, 17
Church’s theorem, 317
Closure (proof by c.), 229, 230
Coefﬁcient (of a polynomial ordinal), 137
leading c., 138
Compactness theorem
for the predicate calculus, 72
for the propositional calculus, 43, 44
Completeness
of equality-extended predicate calculus, 76
of the predicate calculus, 52, 65–71
of the propositional calculus, 40, 41
Completion (of a set of simpliﬁcations), 194,
200
Complex numbers, 33, 300–302
Composition (of maps), 19, 263
Computation (with hereditarily ﬁnite sets),
238–246
Conclusion (of a theorem), 207
cons, 18, 258
Conservativeness, see extension
Consistency
c. within propositional calculus, 43
predicate c. principle, 67
Context (of an inference step), 208, 213–215
Countable set, 30
Cut (Dedekind c.), see also reals, 161, 296
D
Davis–Putnam algorithm, 93, 257
Decision algorithm
for a language about ordinals, 144
for Behmann formulae, 152–157
for Bernays-Schönﬁnkel sentences, 72
for MLSS, 109–113
for MLSS extensions, 113, 114, 122–131
for ordered Abelian groups, 159–165
for RMCF+-formulae, 165–177
for TPB-formulae, 156, 157
for unquantiﬁed formulae about totally
ordered sets, 157–159
Deduction
algebraic d., 227
d. rule, 7
immediate d., 7, 8
natural d., 8, 210, 211
Deduction theorem, 60–62
Deﬁnition, 8–10
algebraic d., 9
d. by use of ‘theories’, 20
fundamental principle of d., 63
recursive d., 9, 10, 216, 217, 328, 329
Degree (of a polynomial ordinal), 140
Denumerable set, 30
Derivative (of a function), 34, 35
Differentiable
continuously d. complex-valued function,
308
continuously d. curve, 309
continuously d. real-valued function, 306
Discharge, 8, 210, 211
Divisibility, 132
Domain, see also universe of an interpretation
d. of a relationship, 18, 259
DPLL (Davis-Putnam-Logemann-Loveland
procedure), 257
E
ELEM, 15, 208, 209
Endowment, 10, 93, 205
ENTER_THEORY, 23
enum, 28, 262
Enumerability, 27–29
Enumeration theorem, 261, 262
Equality (proof by e.), 224
Equivalence relation, 24, 25, 212, 213, 287
Extension (conservative e.), 64
F
Filter, 88
N-complete f., 88
Finiteness, 29, 270–272, 405–409
Form
conjunctive normal f., 178
prenex normal f., 60, 178
Skolem normal f., 72–74, 178
Formula
atomic f. of the predicate calculus, 45

Index
413
Formula (cont.)
f. of the predicate calculus, 45
f. of the propositional calculus, 38
Fraction (of signed integers), 289–294
Framework
interpretation f. for predicate formulae, 46
Full (or ‘transitive’) set, 387–389
Function
analytic f., 308
block f., 34, 304, 305
complex f. of complex variable, 307–310
continuous f., 34, 35, 306, 307
differentiable f., 34, 35, 306, 308
exponential f. cexp, 34
real f. of real variable, 302–307
Function symbol, 45
G
Gödel completeness theorem, 52, 65–71
Gödel’s ﬁrst incompleteness theorem, 345, 346
Gödel’s second incompleteness theorem, 346
Gödel’s trick sentence, 343, 344
Group
complete set of reductions for free g., 201,
202
ordered Abelian g., 159–165
H
Halting problem (unsolvability of), 316
Henkin constant, 65
Herbrand universe, 74, 191, 195
Herbrand’s theorem, 74, 178
Hereditarily ﬁnite set, 79–85, 238–248
HF1, see also hereditarily ﬁnite set, 84
Hint (of a proof statement), 207
Horn formula, 95
I
Induction
membership i., 327, 328
principle of mathematical i., 17, 333–335
principle of transﬁnite i., 17, 26
subset i. principle (for ﬁnite sets), 29, 327,
328, 331, 333
Ineffable formula, 308
Inference
context of an i. step, 208, 213–215
i. rule, 7, 8
i. step, 207
Inﬁnite set, 30
countably i., 30
Inﬁnitesimals (of an ordered Abelian group),
160
Information content, 313
Instantiation (of bound variables)
accelerated i., 236–238
Integer
signed i., 32
unsigned i., 19, 30
Integral
complex line i., 35
Lebesgue i., 34, 304, 305
Interpretation
i. framework for predicate formulae, 46
i. of a function symbol, 46
i. of a predicate symbol, 46
Intersection
dyadic i. operation, 16
Irreducible form (of an expression), 193
Isomorphism
order i. between ordered Abelian groups,
160
L
LC (a decidable language about cardinals),
148
LC∗(a decidable language about cardinals),
149–151
Lebesgue integral, 34
Left-hand variable, 110
Level (of a formula of LO), 144
LO (a decidable language about ordinals), 144
Löwenheim–Skolem theorem, 72
M
Map[ping], 18, 25, 259
1-1 m., 19, 259
identity m., 263
inverse image of m., 263
inverse of a m., 19, 263
m. composition, 19, 263
m. restriction, 263
single-valued m., 18, 259, 263
Mirroring (in logic), 324–327
m. lemma, 244–246
MLSS (multilevel syllogistic with singletons),
109, 208
decision algorithm for MLSS, 109–113
extensions of MLSS, 113, 114, 122–131
tableau method for MLSS, 115–119
Model (inner m.), 89
Modulus, 33
Modus ponens, 40
Monoid (commutative m.), 20
Monotonicity
proof by m., 224–227

414
Index
N
Next, 260
Number
cardinal n., 29–32, 268–271
complex n., 33, 300–302
ordinal n., 19, 25–27
rational n., 32, 289–294
real n., 33, 295–300
signed integer, 32
unsigned integer, 19, 30
O
Occurrence
bound o. of a variable, 45
free o. of a variable, 45
Open set, 34, 308
Order, 26
lexicographic o. of HF, 239
lexicographic o. of ground terms, 195
lexicographic o. of vectors, 160, 165
o. type, 134
Ordinal, 19, 25–27, 388–390, 393–397
next o., 26, 27, 260
o. product, 134
o. subtraction, 136
o. sum, 135
ordering of o., 26
polynomial o., 137–139
post-polynomial o., 139, 140
P
π, 34
Pair
ordered p., 18, 25, 258
unordered p., 15
Parsing, 38
Peano’s induction principle, 333–335
Place, 99
ample collection of p., 99
p. at a variable, 110
Polynomial ordinal, 137–139
Post-polynomial ordinal, 139, 140
PPW (‘permanent parting of the ways’), 197,
198
Precedence relation, 38
Predicate consistency principle, 67
Predicate symbol, 45
Presburger’s additive arithmetic, 131–133
Product
Cartesian p., 25
map p., see map composition
ordinal p., 134
Programming
set-based p., 15, 82, 322
Proof, 37, 207, 208, 323, 324
limited predicate p., 219–223
modus ponens p. rule, 40
p. by algebraic deduction, 227
p. by closure, 229
p. by contradiction, 8, 207
p. by equality, 224
p. by monotonicity, 224
p. by semi-symbolic computation, 246–253
p. by structure, 230
p. rule for the predicate calculus, 51, 52
p. visibility, 339–343
p. within the predicate calculus, 49–52,
54–59
p. within the propositional calculus, 40–43
Provability, 337–339
Q
QED, 210
Quantiﬁer, 45
meaning of a quantiﬁed formula, 47
q. elimination, 105, 131, 132, 155, 157
universal, existential, 11
R
Range
r. of a relationship, 18, 259
Rank
r. of an hereditarily ﬁnite set, 83
r. of an ordered Abelian group, 160
Rationals, 32, 289–294
Reals, 295–300
r. as Dedekind cuts, 212, 295–297, 302
r. as rational Cauchy sequences, 33, 212,
213, 295
Rearrangement of sums, 20, 288
Recursion, 9
legitimacy of recursive deﬁnition, 328, 329
r. over a well-founded relation, 288, 289
r. over the ﬁnite sets, 289
Reductio ad absurdum, 8
Reduction
complete set of r., 197
set of r., 197
subsumed r., 200
Ref[eree], 205, 257
Relationship, see also map, 18
Resolution
r. in the predicate calculus, 180–190
r. in the propositional calculus, 179, 180
Restriction (of a map), 263

Index
415
RMCF+(a decidable fragment about reals),
165–177
domain variable, 170
real assignment, 166
RMCF+ (a decidable fragment about reals)
satisﬁability problem for RMCF+, 167
RMCF+(a decidable fragment about reals)
semantics of RMCF+, 166
syntax of RMCF+, 165
Rosser’s trick sentence, 344, 345
Rule
proof r. for the predicate calculus, 51, 52
Russell’s antinomy, 2
S
Scenario, 205, 257
Scope
s. to which a bound variable belongs, 46
Sentence, 53
Bernays-Schönﬁnkel s., 72
Series
absolutely convergent s., 34
Set-former, 9, 10, 13–16, 78, 81, 258, 259
paradoxical, 2
Set_theory, 23
Sigma, see ‘THEORY’, 20, 287
SIMPLF, 15
Simpliﬁcation (algebraic s.), 193
Singleton, 15
Skolem function, 62, 78
Skolemization, 62, 208
Skolemized version of the axioms of ZF, 79
Soundness
of equality-extended predicate calculus, 76
of the predicate calculus, 50, 51
of the propositional calculus, 40
Space
n-dimensional Euclidean s., 34
s. of real functions of a real variable, 33
Square root, 296
Standardization
bounded variable s., 47, 48
Statement, see also inference step, 207
Structure
proof by s., 230–235
s. descriptor, 230, 231
Sum
of absolutely convergent series of real
functions, 304
of absolutely convergent series of reals, 304
of ﬁnite indexed set of real functions, 304
of ﬁnite indexed set of reals, 304
ordinal sum, 135
Superposition (of two reductions), 199
Suppose, 8
Suppose, 210, 211
Suppose_not, 207, 210
Syllogistic (multilevel s.), see also MLSS, 208
Syntax
s. of the predicate calculus, 45
s. of the propositional calculus, 38
System
logical s., 39, 324–328
T
 subscript, 20, 23
Tableau method, 115
for MLSS, 115–119
Tautology
t. in the predicate calculus, 49
t. in the propositional calculus, 39
Term
ground t., 195
t. of the predicate calculus, 45
Theorem, 37
‘THEORY’, 19–25
t. of equivalence classes, 24, 25, 32, 287
t. of Sigma, 20, 21, 32, 287, 288
TPB-formula, 156
decision algorithm for TPB-f., 156, 157
Transitive (or ‘full’) set, 85, 91
U
Ultraﬁlter, 88
nontrivial u., 88
Uncountable set, 30
Undecidability
u. of a formula, 315
u. of elementary arithmetic, 316
u. of predicate calculus, 317
Uniﬁcation (syntactic u.), 180–183
Uniﬁer
most general u., 183, 198
Union
dyadic u. operation, 15
general u. set, 15
Universe
Herbrand u., see also Herbrand, 74
u. of an interpretation framework, 46
Unparsing, 38
V
Validity
universal logical v., 39
Value
v. of an assignment for a predicate
expression, 47

416
Index
v. of an assignment for a propositional
formula, 38, 39
Variable
bound occurrence of a v., 45
bounded v. standardization, 47, 48
free occurrence of a v., 45
individual v., 45
propositional v., 38
Veriﬁer
program v., 6
proof v., 6, 7
Visibility (proof v. lemma), 339–343
Von Neumann, 19
W
Weight
of a ground term, 195
of a symbol, 195
Well-foundedness of membership, 17
Well-ordering, 134
well-ordering theorem, 27–29, 261, 262
Z
Zermelo–Fraenkel set theory, 77
ZF, ZFC, 77
axioms of ZFC, 77, 78
ZFC+, 366
Zorn’s lemma, 398–405

