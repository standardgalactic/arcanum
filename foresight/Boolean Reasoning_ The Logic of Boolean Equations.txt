Boolean Reasoning 

Boolean Reasoning 
The Logic of Boolean Equations 
by 
Frank Markham Brown 
Air Force Institute of Technology 
..... " 
Springer Science+Business Media, LLC 

Conndtin, EdItor: JOlUlthtm Allm 
Ubrary of CoDlreIS eaUloaml-ID-PDbIkatloD Da .. 
Brown, Frank Markham, 1930-
Boolean reasoning / by Frank Markham Brown. 
p. cm. 
Includes bibliographical references (p. 247-264). 
Includes index. 
ISBN 978-1-4757-2080-8 
ISBN 978-1-4757-2078-5 (eBook) 
DOI 10.10071978-1-4757-2078-5 
1. Algebra, Boolean. I. Title. 
QAI0.3.B76 1990 
511.3 , 24-dc20 
90-4714 
CIP 
Copyrlpt © 1990 by Springer Sciem:e+Business MediaNew YOIk 
Originally pubHshed by Kluwer Academic Publisbers in 1990 
Sotb:over n:print of1he hardcover 1st edition 1990 
All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or 
transmitted in any form or by any means, mechanical, photocopying, recording, or otherwise, 
without the prior written permission of the publisher, Springer Scicnce+-Business Media, Il.C 

Contents 
Preface 
Two Logical Languages ........ . 
Boolean Reasoning . . . . . . . . . . . . 
Boolean Algebra and Switching Theory 
An Approach to Boolean Problem-Solving. 
Boolean Reasoning vs. Predicate Logic . 
Outline ..... . 
Acknowledgments. . . . . . 
1 Fundamental Concepts 
1.1 
Formulas ...... . 
1.2 
Propositions and Predicates 
1.3 
Sets ....... . 
1.4 Operations on Sets 
1.5 Partitions 
1.6 Relations ..... 
1. 7 Functions . . . . . 
1.8 
Operations and Algebraic Systems 
2 Boolean Algebras 
2.1 
Postulates for a Boolean Algebra ........ . 
2.2 
Examples of Boolean Algebras ......... . 
2.2.1 
The Algebra of Classes (Subsets of a Set) 
2.2.2 
The Algebra of Propositional Functions 
2.2.3 
Arithmetic Boolean Algebras .... 
2.2.4 
The Two-Element Boolean Algebra. 
2.2.5 
Summary of Examples . . . . 
2.3 
The Stone Representation Theorem. 
v 
xi 
xi 
xii 
xiii 
xiv 
xv 
xvi 
xviii 
1 
1 
2 
5 
9 
11 
11 
16 
18 
23 
23 
24 
24 
25 
26 
26 
26 
27 

vi 
2.4 The Inclusion-Relation. 
2.4.1 
Intervals ..... 
2.5 
Some Useful Properties 
2.6 n-Variable Boolean Formulas 
2.7 n-Variable Boolean Functions 
2.8 
Boole's Expansion Theorem. 
2.9 The Minterm Canonical Form. 
2.9.1 
Truth-tables ...... . 
2.9.2 
Maps ......... . 
2.10 The Lowenheim-Miiller Verification Theorem 
2.11 Switching Functions ........... . 
2.12 Incompletely-Specified Boolean Functions 
2.13 Boolean Algebras of Boolean Functions 
2.13.1 Free Boolean Algebras .. 
2.14 Orthonormal Expansions ..... 
2.14.1 Lowenheim's Expansions. 
2.15 Boolean Quotient ........ . 
2.16 The Boolean Derivative .... . 
2.17 Recursive Definition of Boolean Functions 
2.18 What Good are "Big" Boolean Algebras? 
CONTENTS 
28 
30 
30 
33 
34 
36 
39 
41 
42 
44 
45 
45 
47 
48 
48 
50 
53 
56 
58 
60 
3 The Blake Canonical Form 
71 
3.1 
Definitions and Terminology. . . . . . . 
72 
3.2 Syllogistic & Blake Canonical Formulas 
73 
3.3 Generation of Be F(J) . . 
75 
3.4 Exhaustion of Implicants . 
76 
3.5 Iterated Consensus . . . . 
77 
3.5.1 
Quine's method. . 
78 
3.5.2 
Successive extraction . 
80 
3.6 Multiplication......... 
80 
3.6.1 
Recursive multiplication 
81 
3.6.2 
Combining multiplication and iterated consensus 
83 
3.6.3 
Unwanted syllogistic formulas. . . . . . . . . . . 
85 

CONTENTS 
vii 
4 Boolean Analysis 
87 
4.1 
Review of Elementary Properties . . . . . . . . . . . . . . 
87 
4.2 
Boolean Systems . . . . . . . . . . . . . . . . . . . . . . . 
88 
4.2.1 
Antecedent, Consequent, and Equivalent Systems. 
89 
4.2.2 
Solutions ........... 
89 
4.3 Reduction............... 
89 
4.4 The Extended Verification Theorem 
91 
4.5 
Poretsky's Law of Forms. 
92 
4.6 
Boolean Constraints 
93 
4.7 Elimination . . . . . . 
95 
4.8 Eliminants....... 
100 
4.9 
Rudundant Variables . 
107 
4.10 Substitution. . . . . . 
113 
4.11 The Tautology Problem 
115 
4.11.1 Testing for Tautology 
115 
4.11.2 The Sum-to-One Theorem. 
116 
4.11.3 Nearly-Minimal SOP Formulas 
117 
5 Syllogistic Reasoning 
123 
5.1 
The Principle of Assertion. 
124 
5.2 
Deduction by Consensus 
126 
5.3 
Syllogistic Formulas .... 
127 
5.4 Clausal Form . . . . . . . . 
129 
5.5 Producing and Verifying Consequents 
132 
5.5.1 
Producing Consequents 
132 
5.5.2 
Verifying Consequents . 
133 
5.5.3 
Comparison of Clauses . 
134 
5.6 
Class-Logic . . . . . 
134 
5.7 
Selective Deduction. . . . . . 
136 
5.8 
Functional Relations . . . . . 
138 
5.9 Dependent Sets of Functions 
140 
5.10 Sum-to-One Subsets . 
143 
5.11 Irredundant Formulas .... 
145 

viii 
CONTENTS 
6 Solution of Boolean Equations 
153 
6.1 
Particular Solutions and Consistency . 
154 
6.2 
General Solutions . . . . . . . . 
156 
6.3 
Subsumptive General Solutions . . . . 
158 
6.3.1 
Successive Elimination. . . . . 
159 
6.3.2 
Deriving Eliminants from Maps . 
161 
6.3.3 
Recurrent Covers and Subsumptive Solutions 
162 
6.3.4 
Simplified Subsumptive Solutions . . . . 
166 
6.3.5 
Simplification via Marquand Diagrams . 
167 
6.4 Parametric General Solutions . . . . . . . . . . 
167 
6.4.1 
Successive Elimination. . . . . . . . . . 
169 
6.4.2 
Parametric Solutions based on Recurrent Covers 
172 
6.4.3 
Lowenheim's Formula . . . . . . . . . . . . . . . 
175 
7 Functional Deduction 
181 
7.1 
Functionally Deducible Arguments 
182 
7.2 
Eliminable and Determining Subsets 
187 
7.2.1 
u-Eliminable Subsets. . . . . 
187 
7.2.2 
u-Determining Subsets. . . . 
189 
7.2.3 
Calculation of Minimal u-Determining Subsets 
190 
8 Boolean Identification 
193 
8.1 
Parametric and Diagnostic Models 
195 
8.1.1 
Parametric Models. . . . . 
195 
8.1.2 
The Diagnostic Axiom . . . 
197 
8.1.3 
Diagnostic Equations and Functions 
197 
8.1.4 
Augmentation ........... 
199 
8.2 Adaptive Identification . . . . . . . . . . . 
201 
8.2.1 
Initial and Terminal Specifications 
201 
8.2.2 
Updating the Model 
204 
8.2.3 
Effective Inputs . 
205 
8.2.4 Test-Procedure... 
208 

CONTENTS 
9 Recursive Realizations of Combinational Circuits 
9.1 
The Design-Process ..... . 
9.2 
Specifications .......... . 
9.2.1 
Specification-Formats .. 
9.2.2 
Consistent Specifications. 
9.3 Tabular Specifications ..... . 
9.4 Strongly Combinational Solutions. 
9.5 Least-Cost Recursive Solutions . 
9.6 
Constructing Recursive Solutions . 
9.6.1 
The Procedure ...... . 
9.6.2 
An Implementation using BORIS . 
A Syllogistic Formulas 
A.l Absorptive Formulas 
A.2 Syllogistic Formulas 
A.3 Prime Implicants .. 
A.4 The Blake Canonical Form 
Bibliography 
Index 
ix 
211 
212 
213 
214 
218 
219 
223 
224 
229 
232 
234 
239 
240 
240 
244 
245 
247 
265 

Preface 
This book is about the logic of Boolean equations. Such equations were 
central in the "algebra of logic" created in 1847 by Boole [12, 13] and devel-
oped by others, notably Schroder [178], in the remainder of the nineteenth 
century. Boolean equations are also the language by which digital circuits 
are described today. 
Logicians in the twentieth century have abandoned Boole's equation-
based logic in favor of the more powerful predicate calculus. As a result, 
digital engineers-and others who use Boole's language routinely-remain 
largely unaware of its utility as a medium for reasoning. The aim of this 
book, accordingly, is to is to present a systematic outline of the logic of 
Boolean equations, in the hope that Boole's methods may prove useful in 
solving present-day problems. 
Two Logical Languages 
Logic seeks to reduce reasoning to calculation. Two main languages have 
been developed to achieve that object: Boole's "algebra of logic" and the 
predicate calculus. Boole's approach was to represent classes (e.g., happy 
creatures, things productive of pleasure) by symbols and to represent logical 
statements as equations to be solved. His formulation proved inadequate, 
however, to represent ordinary discourse. A number of nineteenth-century 
logicians, including Jevons [94], Poretsky [159], Schroder [178], Venn [210], 
and Whitehead [212, 213], sought an improved formulation based on ex-
tensions or modifications of Boole's algebra. These efforts met with only 
limited success. A different approach was taken in 1879 by Frege [60], whose 
system was the ancestor of the predicate calculus. The latter language has 
superseded Boolean algebra as a medium for general symbolic reasoning. 
xi 

xii 
Preface 
The elementary units of discourse in the predicate calculus are the pred-
icates, or atomic formulas. These are statements such as "X likes Mary," 
and "X > Y + 2," which, for any allowed values of their variables, are 
either true or false. The variables in a predicate may be quantified, by 
the symbols V ("for all") or 3 ("there exists"), to form statements such 
as VX(X likes Mary) or 3X(X likes Mary); these statements mean, respec-
tively, "everyone likes Mary" and "someone likes Mary." Predicates may 
be assembled into more complex structures, called well-formed formulas, by 
means of logical connectives such as conjunction (AND), disjunction (OR), 
and negation (NOT). 
Boolean Reasoning 
Boolean reasoning builds on the Boole-Schroder algebra of logic, which is 
based on Boolean equations, rather than on the predicate calculus. Al-
though Boolean equations are predicates-statements that are either true 
or false for any values of their arguments-almost none of the apparatus of 
predicate logic is employed in Boolean reasoning. Neither the disjunction of 
two Boolean equations nor the negation of a Boolean equation is a Boolean 
equation; thus neither of these operations is generally allowed in Boolean 
reasoning (see Rudeanu [172, Chapt. 10] for results concerning disjunc-
tion and negation of Boolean equations). As shown by Boole, however, the 
conjunction of two or more Boolean equations is a Boolean equation. The 
conjunction of a system of equations is therefore expressed by its equivalent 
single equation, rather than by a symbolic conjunction of equations. Thus 
the only well-formed formulas of interest in Boolean reasoning are Boolean 
equations. 
Boole and other nineteenth-century logicians based symbolic reasoning 
on an equation of the O-normal form, i.e., 
(1) 
derived from, and equivalent to, a given system of Boolean equations (the 
equivalent I-normal form, i.e., f'(xt, ... , xn) = 1, may also be used). A 
dissertation published in 1937 by A. Blake [10] showed that the consequents 
of (1) are readily derived from the prime implicants of f. The concept of a 
prime implicant was re-discovered (and named) in 1952 by W.V.O. Quine, 
who investigated the problem of minimizing the complexity of Boolean for-
mulas. Quine established the theoretical foundations of minimization-theory 

Preface 
xiii 
in a series of papers [161, 162, 163, 164] in the 1950s. The theory of prime 
implicants has thus arisen independently to serve two quite different ends, 
viz., Boolean reasoning (Blake) and formula-minimization (Quine). 
The approach to Boolean reasoning outlined in this book owes much 
to Blake's work. Blake's formulation (outlined in Appendix A) anticipates, 
within the domain of Boolean algebra, the widely-applied resolution principle 
in predicate logic, given in 1965 by Robinson [168]. Blake's "syllogistic 
result," for example, corresponds to Robinson's "resolvent." 
Boolean Algebra and Switching Theory 
Although Boole's algebra did not succeed in expressing, as he had intended, 
"those operations of the mind by which reasoning is performed" [13, p. 1], 
it remains in daily use to deal with the simpler mentality of switching cir-
cuits. The. possibility of applying Boolean algebra to the design of switching 
systems was first suggested in 1910 by the physicist P. Ehrenfest [54], who 
proposed in a review of a text by Couturat [41] that Boolean algebra. be used 
in the design of automatic telephone exchanges. Ehrenfest did not, however, 
supply details as to how it might be done. Papers providing such details ap-
peared independently between 1936 and 1938 in Japan, the United States, 
and the Soviet Union (it seems that only the results published in the Soviet 
Union, by Shestakov [185], were based on Ehrenfest's suggestion). The most 
influential of these papers was Shannon's "Symbolic Analysis of Relay and 
Switching Circuits" [183], based on his M.S. thesis at the Massachusetts In-
stitute of Technology. Shannon formulated a "calculus of switching circuits," 
which he showed to be analogous to the calculus of propositions. In a paper 
published in Japan in 1937, Nakasima [146] identified the same switching 
calculus with the algebra of sets. Nakasima's paper, the earliest to apply 
Boolean algebra to switching theory, discussed methods of solving Boolean 
equations, with the aim of finding an unknown component switching-path 
when the composite path is known. Nakasima's work seems to have been 
little noticed in the United States; in the 1950s, however, a number of papers 
appeared in the U.S. which applied Boolean equation-solving to the design 
of switching systems [2, 4, 113, 155]. 
Motivated by problems arising in the design of switching circuits, A. 
Svoboda [191] proposed construction of a "Boolean Analyzer," a hardware-
adjunct to a general-purpose computer, specialized to solve Boolean equa-
tions. The applications of such a unit, and of APL programs for solving 

xiv 
Preface 
Boolean equations, are described in Svoboda and White [193]. 
Klir and Marin [103] have stated that "The most powerful tool of the 
modern methodology of switching circuits seems to be the Boolean equa-
tions. Their importance for switching theory reminds one of the application 
of differential equations in electric circuit theory." There remains a curi-
ous difference, however, between the way differential equations and Boolean 
equations are typically applied: Boolean equations are rarely solved. They 
are manipulated in form but are seldom the basis for systematic reasoning. 
Contemporary research on Boolean methods in switching tends instead to 
emphasize formula-minimization. Many writers on applications of Boolean 
methods believe in fact that the only useful thing to do with Boolean for-
mulas is to simplify them. A widely-used text [84, p. 60] announces that 
"Almost every problem in Boolean algebra will be found to be some variation 
of the following statement: 'Given one of the 22" functions of n variables, 
determine from the large number of equivalent expressions of this function 
one which satisfies some criteria for simplicity.'" Boole would doubtless 
deem that to be less than full employment for the algebra he designed as an 
instrument for reasoning. 
Although the processes of Boolean reasoning should for practical rea-
sons keep their internal representations relatively simple, minimization is 
a topic essentially distinct from reasoning. Minimization is therefore not 
emphasized in this book, notwithstanding its importance both theoretically 
and in practice. See Brayton, et al., [18] for an an excellent contemporary 
treatment of minimization and its applications in the design of VLSI (Very 
Large-Scale Integration) circuits. 
An Approach to Boolean Problem-Solving 
The central idea in Boolean reasoning, first given by Boole, is to reduce a 
given system of logical equations to a single equivalent equation of standard-
ized form (e.g., 1= 0), and then to carry out the desired reasoning on that 
equation. This preliminary abstraction enables the processes of reasoning to 
be independent of the form of the original equations. 
The primary tactic employed by Boole and later nineteenth-century lo-
gicians was to solve I(x, y, . .. ) = 0 for certain of its arguments in terms of 
others. A solution of an equation is a particular kind of antecedent, however, 
and not necessarily a consequent, of the equation. An important advance 
was made in 1937 by Blake [10], who showed that the consequents of f = 0 

Preface 
xv 
are represented economically in the disjunction of the prime implicants of 
I. We call this disjunction the Blake canonicallorm for I and denote it by 
BCF(f). 
The task of solving a problem based on a collection of Boolean equations 
may thus be carried out in three major steps: 
1. Reduction. Condense the equations into a single Boolean equation 
of the form I = o. 
2. Development. Construct the Blake canonical form for I, i.e., gener-
ate the prime implicants of I. 
3. Reasoning. Apply a sequence of reasoning-operations, beginning with 
the Blake form, to solve the problem. 
Steps 1 and 2 are independent of the problem to be solved and are readily 
automated. The sequence of operations to be applied in Step 3, on the 
other hand, is dependent upon the problem. To employ Boolean reasoning, 
therefore, the principal task is to select an appropriate sequence of operations 
to apply to the formula BCF(f). The operational (i.e., functional) basis of 
Boolean reasoning differentiates it from from the predicate calculus, whose 
basis is relational. Other differences between the two languages are discussed 
below. 
Boolean Reasoning vs. Predicate Logic 
The need to incorporate systematic reasoning into the design of switch-
ing systems has attracted the attention of engineers to the theorem-proving 
methods of the predicate calculus. Design based on these methods is sum-
marized by Kabat and Wojcik [95] as follows: "The basic philosophy of the 
design approach using theorem proving is to represent the elements of the 
design process as a set of axioms in a formal system (a theory), state the 
problem of realizability of the target function as a theorem, and prove it in 
the context of the theory. Once the theorem is proved, an automatic proce-
dure for the recovery of the logic circuit is to be executed to complete the 
design." 
Boolean reasoning differs from the theorem-proving methodology ofpred-
icate logic in a number of important ways. Predicates (propositional func-
tions) and propositions are two-valued. Boolean functions, on the other 
hand, take on values over an underlying set, the carrier of the associated 

xvi 
Preface 
Boolean algebra; the number of elements in the carrier may be 2 or any 
higher power of 2. The following properties-valid in propositional logic-
do not hold in other than two-valued Boolean algebras: 
=> 
=> 
F = 1 
or G = 1 
F=O. 
Applying propositional calculation-rules to Boolean problems can there-
fore lead to incorrect results. The denial of a biconditional in propositional 
logic, for example, can be expressed as a biconditional; thus ...,( a +--+ b) is 
equivalent to a +--+ ...,b. The denial of a Boolean equation, however, cannot 
in general be expressed as a Boolean equation; denying the Boolean equation 
a = b is not the same as asserting the equation a = b'. 
The principal problem-solving technique in predicate logic is theorem-
proving via refutation, i.e., reductio ad absurdum. This technique entails 
the denial of the theorem to be proved. As noted above, however, the denial 
of a Boolean equation is not a Boolean equation, and thus refutation-based 
reasoning is not possible in Boolean algebras having other than two values. 
Problem-solving in predicate logic entails assigning values to variables 
over some domain. Any set, e.g., {5, John,", cat,*}, may be the domain for 
a problem in predicate logic. The domain in a Boolean problem, however, 
is an ordered structure-the carrier of a Boolean algebra. Consequently, 
the information produced by Boolean reasoning is typically expressed by 
intervals (cf. Section 2.4.1). 
Outline 
Chapters 1 through 4 of this book outline the mathematical basis for Boolean 
reasoning. Chapter 1, included to make the book self-contained, is a brief 
survey of fundamental concepts such as propositions, predicates, sets, rela-
tions, functions and algebraic systems. Chapter 2 treats the classical Boole-
Schroder algebra of logic via Huntington's postulates. Several examples 
of Boolean algebras are discussed, and important theorems are presented; 
among the latter are the Stone representation theorem, Boole's expansion 
theorem, and the Lowenheim-Miiller verification theorem. Boolean formulas 
and Boolean functions are defined and the distinction between these two 
concepts is emphasized. Orthonormal expansions are defined and their util-
ity is examined. The utility of "big" Boolean algebras (those comprising 
more than two elements) is discussed. Chapter 3 outlines Blake's theory of 

Preface 
xvii 
canonical formulas [10], and the employment of such formulas in deriving and 
verifying consequents of Boolean equations. Several methods are presented 
for constructing the Blake canonical form. The Blake form is employed fre-
quently in the remainder of the book; a number of theorems concerning this 
form, based on Blake's dissertation [10], are given in Appendix A. Chapter 
4 introduces the basic operations from which reasoning procedures may be 
composed. Among such operations are reduction, elimination, expansion, 
division, and substitution. 
Chapters 5 through 7 treat two categories of Boolean reasoning: syllo-
gistic (Chapter 5) and functional (Chapters 6 and 7). Syllogistic reasoning, 
a direct approach to the solution of problems in propositional logic, is based 
on constructing a simplified representation of the consequents of the Boolean 
equation 1 = o. Functional reasoning, on the other hand, produces func-
tional equations, i.e., statements of the form x = g(y, z, .. . ), related to the 
equation 1(x, y, z, ... ) = o. Functional antecedents, solutions of 1 = 0, 
were investigated by Boole and have been the object of much study since; 
see Rudeanu [172] for an authoritative survey and a complete bibliography. 
Functional consequents, on the other hand, seem to have received little at-
tention; we discuss the theory of such consequents as well as a number of 
their applications. 
The last two chapters present applications of Boolean reasoning in dig-
ital technology. Chapter 8 discusses the identification of a Boolean "black 
box" by means of an input-output experiment. Chapter 9 concerns multiple-
output combinational switching circuits. Emphasis is placed on the problem 
of specification; the design-problem is formulated as one of solving the speci-
fication. A particular class of solutions, which we call recursive, corresponds 
to loop-free circuits which may employ output-signals to help in generating 
other output-signals. 
Proofs are supplied for new results; a proof is given for an established 
result, however, only if it is particularly instructive. The Boolean calcu-
lations entailed in the examples-and those underlying the new results-
were carried out using a set of software-tools which the author calls BORIS 
(Boolean Reasoning In Scheme); these tools are programmed in PC Scheme, 
a microcomputer-based dialect of Lisp available from Texas Instruments, 
Inc. BORIS has been invaluable in the exploration and testing of conjec-
tures, building confidence in good conjectures and rudely puncturing bad 
ones. 

xviii 
Preface 
Acknowledgments 
The author's interest in Boolean methods owes much to the example and 
assistance of Professor Sergiu Rudeanu of the Faculty of Mathematics, Uni-
versity of Bucharest, Romania. I am indebted to Professor Rudeanu for his 
careful reading of a preliminary version of this book; full many a logical rock 
and mathematical shoal was avoided thanks to his comments. I am indebted 
also to Captain James J. Kainec, U.S. Army, for reading several generations 
of this book and supplying a large number of helpful comments. Several 
chapters were read by Dr. Albert W. Small, who made useful suggestions 
and corrections. 
I wish finally to acknowledge a debt beyond measure-to my dear wife, 
Roberta. Her steadfast support and encouragement made this book possible. 

Boolean Reasoning 

Chapter 1 
Fundamental Concepts 
This chapter surveys basic mathematical ideas and language needed in the 
remainder of the book. The material in this chapter is provided for readers 
having little experience with the concepts and terminology of modern alge-
bra; other readers may wish to proceed directly to the next chapter. The 
discussion is informal and only those topics directly applicable to Boolean 
reasoning are considered. The reader unacquainted with set-theory is cau-
tioned that the sets discussed in this chapter are restricted to be finite, i. e., 
to comprise only a finite number of elements. A text such as that by Hal-
mos [77) should be consulted to gain a balanced understanding of the theory 
of sets. 
1.1 
Formulas 
If we put a sheet of paper into a typewriter and strike some keys, we produce 
a formula or expression. If we strike only the parenthesis-keys, some of the 
formulas we might type are the following: 
( ) 
)() 
( ( ) ( ( ) ) ) 
( ( ( ( ( ) ) ) 
(1.1) 
(1.2) 
(1.3) 
(1.4) 
Formulas may be discussed in terms of two attributes. The first is syntax, 
which is concerned with the way the symbols in a formula are arranged; 
the second is semantics, which is concerned with what the symbols mean. 
1 

2 
CHAPTER 1. FUNDAMENTAL CONCEPTS 
An important question of syntax is whether a formula in a given class is 
well-formed, i.e., grammatical or legal according to the rules governing that 
class. We will discuss the syntax of well-formed parenthesis-strings later in 
this chapter; our experience with parentheses should tell us, however, that 
formulas (1.1) and (1.3) are well-formed, whereas (1.2) and (1.4) are not. 
Let us venture beyond the parenthesis-keys, to type more elaborate for-
mulas: 
3S;2 
2 is a prime number. 
140 IF C=40 THEN 120 
140 IF 120 THEN C=40 
QxRPch 
x++5« 
('Vx)[x E 0 ===} x E {1,2}] 
There is life beyond our galaxy. 
This statement is false. 
(1.5) 
(1.6) 
(1.7) 
(1.8) 
(1.9) 
(1.10) 
(1.11) 
(1.12) 
(1.13) 
The formulas above belong to several syntactic classes. The legality of (1.7) 
and (1.8), for example, must be judged by the rules for BASIC statements, 
whereas (1.9) is to be judged by the rules of chess-notation [87]. It is nev-
ertheless fairly obvious that (1.8) and (1.10) are not well-formed, and that 
the other formulas are well-formed. 
One isn't much interested in formulas that are not well-formed; from now 
on, therefore, "formula" will mean "well-formed formula." An important 
semantic issue concerning such a formula is whether it can be assigned a 
truth-value (true or false). We now examine that issue. 
1.2 
Propositions and Predicates 
A proposition is a formula that is necessarily true or false, but cannot be 
both. We do not attribute truth or falsehood to parenthesis-strings; hence 
formulas (1.1) through (1.4) are not propositions. Formulas (1.5), (1.6), and 
(1.11), however, are propositions; they are false, true, and true, respectively. 
Formula (1.12) is a proposition, but determining its truth-value requires 
more information than we now possess. Formula (1.13) is not a proposition: 
if we assume it to be true, then its content implies that it is false; if we 
assume it to be false, then its content implies that it is true. 

1.2. PROPOSITIONS AND PREDICATES 
3 
Predicates. The formula 
is not a proposition. It becomes a proposition, however, if any particular pair 
of numbers is substituted for x and y. Such a formula is called a predicate 
(or propositional form). 
More precisely, suppose P( Xl, ••• ,Xn ) represents a formula involving vari-
ables Xl, .•• ,Xn , and suppose that each of the variables can take on values 
within a certain domain. The domain of Xl might be certain numbers, that of 
X2 might be animals that chew their cud, that of X3 might be certain propo-
sitions, and so on. We say that the formula represented by P( Xl, ••• ,xn ) is 
an n-variable predicate if it becomes a proposition for each allowable sub-
stitution of values for Xl, ••• , xn • A proposition is therefore a O-variable 
predicate. 
For notational convenience we write P(X) for P(Xl,"" xn) and we refer 
to the domains of the variables Xl, .•• ,Xn collectively as the domain of X. 
Quantifiers. 
Given a predicate P(X), where X is assigned values on 
some domain D, we may wish to announce something about the number of 
values of X for which P(X) is true. Two statements of this kind, namely 
For every X in D, P( X) is true 
(1.14) 
and 
For at least one X in D, P(X) is true, 
(1.15) 
are particularly useful. We use the shorthand (VX) to mean "for every X 
in D" (the domain D being understood) and (3X) to mean "for at least 
one X in D." The symbol V is called the universal quantifier; the symbol 
3 is called the existential quantifier. Using these quantifiers, we represent 
formula (1.14) by 
(VX)P(X) 
and we represent (1.15) by 
(3X)P(X) . 
The formula P(X) is not in general a proposition, because its truth-
value may depend on the value assigned to X. The formulas (VX)P(X) and 
(3X)P(X), however, are propositions. Suppose, for example, that P(x,y) 
is the predicate 

4 
CHAPTER 1. FUNDAMENTAL CONCEPTS 
and D is the set ofreal numbers. Then the formula (Vx)(Vy)P(x, y) is a false 
proposition while ("Ix )(3y)P(x, y) is a true proposition. The latter form may 
be read "for all x there exists a y such that P(x, y)," indicating a dependence 
of the possible values of y upon the value of x. This form therefore has a 
meaning different from that of (3y )(Vx )P( x, y)," read "there is a y such that, 
for all x, P(x, y). 
Implication. 
A predicate P(X) is said to imply a predicate Q(X), 
written 
P(X) ~ 
Q(X), 
(1.16) 
in case, for every X in its domain, Q(X) is true if P(X) is true. Put another 
(and frequently more useful) way, P(X) implies Q(X) if it cannot happen, 
for any X, that P(X) is true and Q(X) is false. Formula (1.16) is called an 
implication. P(X) is called the antecedent of the implication; Q(X) is called 
the consequent. 
Here are some examples of implications: 
x is a real number ~ x 2 ~ 0 
There is life beyond our galaxy ~ 5 is odd 
3 :5 2 ~ It is raining 
(1.17) 
(1.18) 
(1.19) 
Formula (1.17) accords with our customary understanding of the word "im-
plies"; there is a logical connection, that is, enabling us to deduce the conse-
quent Q from the antecedent P. In neither (1.18) nor (1.19), however, does 
such a connection exist. Each of these formulas nevertheless satisfies the 
definition of an implication. It cannot happen in (1.18) that P is true and 
Q is false, because Q is true; similarly, it cannot happen in (1.19) that Pis 
true and Q is false, because P is false. 
Implications in which the antecedent and consequent have no apparent 
connection are not as removed from everyday reasoning as one might sup-
pose. We often hear statements of the form, "If the Cubs win the pennant 
this year, then I'm Sigmund Freud." 
Suppose P(X) and Q(X) are predicates. Then each of the following 
formulas conveys the same information: 
P(X) 
~ Q(X) 
(1.20) 
[not Q(X)] 
~ [not P(X)] 
(1.21 ) 

1.3. SETS 
5 
('v'X)[[P(X) and not Q(X)] is false] 
(1.22) 
('v'X)[[[not P(X)] or Q(X)] is true] 
(1.23) 
If we wish to prove a theorem of the form (1.20), it may be convenient 
instead to prove the equivalent statement (1.21). Such an approach is called 
proof by contraposition, or contrapositive proof, 
Equivalence. Two predicates P(X) and Q(X) are said to be equivalent, 
written 
P(X) 
¢:::} Q(X), 
(1.24) 
provided P(X) and Q(X) are either both true or both false for each X in the 
domain. Formula (1.24) is called an equivalence. The formula 
x 2 = -1 
¢:::} x = i or x = -i , 
for example, is an equivalence over the domain of complex numbers. 
Comparing the definition of equivalence with that of implication, we see 
that P(X) and Q(X) are equivalent in case the condition 
[P(X) ==? Q(X)] 
and 
[Q(X) ==? P(X)] 
(1.25) 
is satisfied. 
1.3 
Sets 
A set is a collection of objects; the objects in the collection are called its ele-
ments. Having said that, in order to affirm the view of a set doubtless shared 
by the reader, we back away and declare the words "set" and "element" to 
be primitive. They can be described but not defined, being analogous in 
this respect to the words "line" and "point" in geometry. Our intent there-
fore is not to say what sets are but to discuss a few of the things that may 
done with them legally, inasmuch as they provide us with great notational 
convenience. 
An important caution: we consider only finite sets, i.e., sets possessing 
a finite number of elements, in this book. The assumed finiteness of sets 

6 
CHAPTER 1. FUNDAMENTAL CONCEPTS 
pervades the discussion in this and subsequent chapters, enabling us to think 
about sets in ways that might not be applicable were the sets infinite. 
We write 
xEA 
to signify that x is an element (or member) of a set named A. 
Ways of describing sets. 
A set may be described by enumemtion, 
i.e., by an explicit listing of its elements, written within curly braces. Thus 
the Jones family may be specified by the formula 
{Mrs. Jones, Mr. Jones, Emily Jones, Fido}. 
A second way to describe a set is by means of a membership-property. 
To specify a set S in this way, we write 
S = {xIP(xH 
where P( x) is a predicate that is true if and only if XES. The set E of even 
numbers is thus described by 
E = { x I x is a number divisible by 2 } . 
Some sets are described conveniently either by enumeration or by a 
membership-property; the choice between the two equivalent specifications 
S = {I, -1, i, -i} 
and 
S = {xlx4 = I}, 
for example, is clearly a matter of taste. The set {s, Fido, $}, on the other 
hand, would be difficult to describe by means of a membership-property that 
does not amount to enumeration. 
A third way to describe a set is by means of a recursive rule. Consider 
the set 
0 0 0 
0 0 1 
B~{[n·[! ~l· 
0 1 0 
0 1 1 , ... } 
1 0 0 
1 0 1 
1 1 0 
1 1 1 

1.3. SETS 
of binary codes. This set is described by the following statements: 
1. 
[~] is an element of B. 
o 
x 
1 
2. If [Xl is an element of B, then so is 
o 
X 
1 
3. Nothing else is an element of B. 
7 
The first statement in the foregoing definition is called the base of the 
definition; it puts certain objects (in this case just one) explicitly in the set. 
The second statement, called the recursion, is a construction-rule, telling 
us how to manufacture members of the set from other members of the set. 
The third statement (which is often omitted, being understood) is called the 
restriction; it allows membership in the set only to those objects appointed 
either by the base or by the recursion. Any of the foregoing parts of a 
recursive definition may itself have several parts. 
Let us consider again the well-formed parenthesis-strings discussed ear-
lier in this chapter. The set of such strings (let us call it P) is described 
recursively by the statements that follow: 
BASE: () is an element of P. 
RECURSION: If X and Yare elements of P, 
then so are (X) and XY. 
RESTRICTION: Nothing else is an element of P. 
Suppose we want to show that some property holds for every member of 
a set S. We can do so, if S is described recursively, in two steps: 
Step 1. Show that the property holds for all of the members of S 
specified by the base. 
Step 2. Show that if the property holds for all the members of an 
arbitrary subset of S, then it must hold for all additional 
members generated from that subset by recursion. 
Abstractness of sets. The elements of a set may be concrete or ab-
stract. A set, however, is always abstract; the only quality a set S possesses 

8 
CHAPTER 1. FUNDAMENTAL CONCEPTS 
is its ability to attach membership-tags to objects. It is important not to 
confuse properties of a set with properties of the objects it comprises. The 
set {2}, for example, is not a number and the set {Fido} cannot bark. 
Sets vs. sequences. 
A sequence (Xl, X2,"" xn) is an ordered col-
lection of objects that are not necessarily distinct. Sequences are some-
times called ordered sets, n-tuples, arrays, or vectors; the delimiters [ ... ] or 
< ... > are sometimes used instead of ( ... ). In a sequence, unlike a set, 
the order of enumeration of elements is important. Thus (a, b,c) f; (b, c,a), 
whereas {a, b, c} = {b, c, a}. Another difference between sets and sequences 
is that the elements in a set, unlike those in a sequence, must be dis-
tinct; thus {Fido, $, Fido, 5} is an illegal representation for a set, whereas 
(Fido, $, Fido, 5) is a legal sequence. 
Inclusion. If a set S consists entirely of elements that are also members 
of a set T, then we say that S is included in (or is a subset of) T and we 
write 
Sc;;,T. 
More formally, we define the relation c;;, by the equivalence 
[S c;;, T] ~ 
('v'x)[x E S ==> X E T]. 
(1.26) 
Unlike the membership-relation E, which relates elements to sets, the 
inclusion-relation ~ relates sets to sets. 
Equality. 
Two sets Sand T are equal, written S = T, provided each 
comprises exactly the same elements. Equality of sets is therefore defined 
by the statement 
[S = T] ~ 
[S c;;, T and T c;;, S]. 
We say that S is properly included in T in case S is included in T but Sis 
not equal to T. 
Cardinality. 
The number of elements in a finite set S is called the 
cardinality of S and is denoted by # S (the notations lSI, n(S), and card(S) 
are also used). Thus #{Fido, I} = 2. 
The concept of cardinali ty ( or cardinal number) is defined also for infini te 
sets (see, e.g., Halmos [77]), but clearly entails a generalization of "number 
of elements." Our concern in this book, however, is exclusively with finite 
sets. 

1.4. OPERATIONS ON SETS 
9 
The empty set. 
A useful concept is that of the empty (or null) set, 
denoted by 0. This is the set comprising no elements at alIi thus 0 is defined 
by the statement 
#0=0. 
The empty set is included in every set, i.e., 0 ~ T for any set T. To prove 
that this is the case, based on the definition (1.26) ofthe relation ~, we must 
show that the proposition 
(V'x)[x E 0 ==> x E T] 
is true for any set T. The left side of the implication in (1.3), i.e., x E 0, is 
false for all Xi hence the implication is true for all x-and we conclude that 
o is a subset of any set. Thus, for example, 
{ x I x is a flying elephant} ~ {Fido,l} 
is a valid inclusion. 
We speak of "the" empty set because 0 is unique (the proof is assigned 
as homework). Thus 
{x I x is a flying elephant} = {x I x is an even integral divisor of 5} 
is a valid statement. 
1.4 
Operations on Sets 
We now discuss some useful ways to make sets out of other sets. 
Cartesian product. 
The cartesian (direct, cross) product of sets S 
and T, written S X T, is the set defined by 
S X T = {{x, y)lx E S and YET}. 
(1.27) 
Thus 
{a,b} X {a,b,c} = {{a, a), (a,b),(a,c), (b,a),(b,b),(b,c)} . 
(1.28) 
The cartesian product is not commutative, i.e., S X T '" T X S except 
for special S, T pairs. The cardinality of S X T is related to that of the 
individual sets S and T by 
#(S X T) = (#S)· (#T). 
(1.29) 

10 
CHAPTER 1. FUNDAMENTAL CONCEPTS 
Thus the sets S X T and T X S have the same cardinality. In (1.28), for 
example, #S = 2, #T = 3, and #(S X T) = #(T X S) = 6. 
The cartesian product is a set of ordered pairs. We define a three-fold 
cartesian product as a set of ordered triples, i.e., 
R X S X T = {(x,y,z)lx E R,y E S,Z E T}. 
(1.30) 
Higher-order cartesian products are defined by obvious extension. We write 
sn to signify the n-fold cartesian product of S with itself, i.e., 
n times 
.. 
sn=SxSx···xs'. 
(1.31) 
Power set. The power set of a set S, written 28 , is the set of subsets 
of S, i.e., 
28 = {RIR ~ S}. 
(1.32) 
Thus 
2{a,b} = {0,{a},{b},{a,b}}. 
(1.33) 
The notation 28 serves to remind us that the cardinality of 28 is deter-
mined from the cardinality of S by the relation 
(1.34) 
An alternative notation for the power set is P(S). 
Union, intersection, and complement. Let Sand T be sets. Then 
the union of Sand T, written S U T, is defined by 
Su T = {xix E S or x E Torboth}. 
(1.35) 
Thus {a,b,c} U {a,b,d} = {a,b,c,d}. 
The intersection of Sand T, written S n T, is defined by 
S n T = {xix E S and x E T}. 
(1.36) 
Thus {a, b, c} n {a, b, d} = {a, b}. Two sets Sand T are said to be disjoint 
if S n T = 0, i.e., if they have no elements in common. 
The relative complement of T with respect to S, written S - Tor S \ T, 
is defined by 
S - T = {xix E S and x ¢ T} . 
(1.37) 

1.5. PARTITIONS 
11 
Thus {a, b, c} - {a, b, d} = {c}. In many situations it is natural to think of 
a universal set, U, such that every set of interest is a subset of U; in such 
situations we define the absolute complement of T, written T, by 
T = U - T = {xix E U and x fI T}. 
(1.38) 
The statement "x E U" is redundant, however, in the given context; thus 
we may define T by the simpler statement 
T = {xix fiT}. 
1.5 
Partitions 
A partition 'Ir of a nonempty set S is a set 
of nonempty subsets of S, called blocks, such that the conditions 
(i) BinBj =0 (il=i) 
(ii) Uf=l Bi 
= S 
(1.39) 
(1.40) 
are satisfied. Thus every element of S is a member of exactly one block of 
'Ir. 
Suppose that 'irA = {At, A2, ••• } and 'lrB = {Bt, B2, ••• } are two parti-
tions of a set S. Then we say that 'irA is a refinement of 'lrB, written 
(1.41) 
in case each block of 'irA is a subset of some block of 'lrB. Equivalently, 
(1.41) holds in case every block of 'lrB is a union of blocks of 'irA. Suppose 
for example that S = {a,b,c,d,e}, 'irA = {{a,c},{b},{d,e}} and 'lrB = 
{{ a, b, c}, {d, e}}. Then 'irA ~ 'lrB. 
1.6 
Relations 
Given two sets Sand T, a relation R from S into Tis a subset of S X T. We 
define a predicate xRy, read "x has the relation R to y," by the formula 
xRy ¢:::::} (x, y) E R . 
(1.42) 

12 
CHAPTER 1. FUNDAMENTAL CONCEPTS 
Example 1.6.1 Let S = {O, 3, 5} and let T = {1, 4, 7}. If R means "less 
than", then R S; S X T is enumerated as follows: 
R = {(O, 1), (0,4), (0,7), (3,4), (3, 7), (5, 7)} . 
If R means "equal to" , then 
R=0. 
We define a relation on a set S to be a subset of S X S. 
The relations discussed above are called binary because they involve two 
sets. It is sometimes useful to extend the concept of relation to three or 
more sets. Thus a subset of R X S X T is a ternary relation on the triple 
(R,S,T). 
Equivalence-relations. A relation R on a set S is called an equivalence-
relation in case, for all x, y, z E S, R is 
(i) reflexive: 
(x,x) E R 
(ii) symmetric: (x,y) E R ===? (y,x) E R 
(iii) transitive: 
[(x, y) E Rand (y, z) E R] ===? (x, z) E R. 
Consider for example the set S = {a, b, c, d, e, f} and the relation 
R = {(a,a),(b,b),(c,c),(d,d),(e,e),(j,j),(a,b), 
(b,a),(a,c),(c,a),(b,c),(c,b),(d,e),(e,d)} 
(1.43) 
on S. It is readily verified that R is an equivalence-relation on S, i.e., that 
it is reflexive, symmetric, and transitive. 
If R is an equivalence-relation on S, then the equivalence-class containing 
an element y, denoted by [y], is the set of all members of S that are R-related 
(i.e., equivalent) to y. That is, 
[y] = {xl(x,y) E R}. 
The equivalence-classes defined by the relation (1.43) are 
[a] = 
[b] 
= 
[c] 
= {a,b,c} 
[d] = 
[e] 
= {d,e} 
[I] = {f}. 
(1.44) 
The set of all equivalence-classes associated with an equivalence-relation 
on a set S constitutes a partition of Sj conversely, any partition of S is the set 

1.6. RELATIONS 
13 
of equivalence-classes of an equivalence-relation on S. Thus the equivalence-
relations on S are in one-to-one correspondence with the partitions of S. The 
partition of {a, b, c, d, e, J} corresponding to the equivalence-relation (1.43), 
for example, is 
{{a,b,c},{d,e},{J}} = {[a], [d],[f]} . 
The elements a, d, and f in the latter set are called "representatives" of 
their equivalence-classes; any element of an equivalence-class may be chosen, 
clearly, to be the representative of its class. 
Equivalence is a generalization of equality. We say that two things be-
longing to a set S are equivalent, even if they aren't equal, if they belong to 
the same block of a partition of S generated by some classification-scheme. 
Suppose that S is the set of all people in the world. Then we might say that 
two people are equivalent if they are of the same sex (thereby partitioning 
S into two equivalence-classes). Under other schemes of classification, we 
might say that two people are equivalent if they have the same nationality 
or are of the same age. As another example, suppose S to be the set of 
all arithmetic formulas. The elements x2 - y2 and (x + y)(x - y) of S are 
clearly not equal (as formulas). They produce the same numerical result, 
however, if specific numbers are substituted for x and y; hence, we call the 
two formulas equivalent. 
Suppose, as a further example, that S is the set of integers, i.e., S = 
{ ... , -2, -1, 0,1,2, ... } and that a relation R is defined on S by the formula 
(x, y) E R ~ 
x - y is divisible by 3. 
(1.45) 
The relation R is reflexive, symmetric and transitive (the proof is assigned 
as homework); hence R is an equivalence-relation. This relation has three 
equi valence-classes, namely, 
[0] = { ... , -6, -3,0,3,6, ... } 
[1] = { ... , -5, -2, 1,4, 7, ... } 
[2] = { ... ,-4,-1,2,5,8, ... } . 
The associated partition of S is {[OJ, [1], [2]}. 
The typical symbol for an equivalence-relation is ==; we write x == y, that 
is, in case (x, y) is a member of the set == of ordered pairs. Another way to 
say this is that x == y if and only if [x] = [y] with respect to the relation 

14 
CHAPTER 1. FUNDAMENTAL CONCEPTS 
_. Referring to the foregoing example, we write -6 == 3, 4 == 7, etc. In this 
example, the relation == is called congruence modulo 3. 
Partial-order relations. 
Just as an equivalence-relation is a gener-
alization of the relation "equals," a partial order is a generalization of the 
relation "is less than or equal to." We say that a relation R on a set S is a 
partial order on S in case, for all x, y, z E S, the relation is 
(i) reflexive: 
(x,x) E R 
(ii) anti-symmetric: [(x,y) E R and (y,x) E R] ~ 
x = Y 
(iii) transitive: 
[(x, y) E R and (y, z) E R] ~ 
(x, z) E R. 
The following are some examples of partial-order relations: 
• The relation ~ on the set of real numbers is a partial order of a special 
kind: for any pair x, y of real numbers, either x ~ y or y ~ x holds. 
Because of this property, ~ is called a total order on the set of real 
numbers. 
• If P is the set of partitions on a set S, then the relation of refinement 
is a partial order on P. 
• It S is any set, then the inclusion-relation ~ is a partial order on the 
set 25. 
• If S is the set {I, 2, 3, ... } of natural numbers, then the relation "is a 
divisor of" is a partial order on S. 
Partially-ordered sets and Hasse diagrams. A set S, together with 
a partial order ~ on S, is an entity called a partially-ordered set, designated 
by the ordered pair (S, ~). (We use the symbol ~ as a generic representation 
for a partial-order relation.) In the third of the relations listed above, for 
example, the pair (25,~) is a partially-ordered set. 
A convenient representation for a partially-ordered set (S,~) is a Hasse 
diagram. Each element of S is represented as a point in the diagram; the 
points are connected by lines in such a way that one may trace continuously 
upward from a point x to another point y if and only if x ~ y. To achieve 
this result with the fewest possible lines, a line is drawn directly upward 
from x to y if and only if 
• 
x ~ y and 
• 
there is no third point z such that x ~ z ~ y. 
Figure 1.1 shows Hasse diagrams for several partially-ordered sets. 

1.6. RELATIONS 
{{a,b,c}} 
3 
/1" 
I 
{{a,b},{c}} {{a,c},{b}} {{a},{b,c}} 
2 
,,1/ 
{{ a},{b },{ c}} 
1 
(a) 
(b) 
{a,b,c} 
30 
/1"" 
/1"" 
{a,b} 
{a,c} 
{b,c} 
6 
10 
15 
IXXI 
IXXI 
{a} 
{b} 
{c} 
2 
3 
5 
""1/ 
""1/ 
o 
1 
(c) 
(d) 
(a) ( {11" I 11" is a partition of {a, b, c}}, "is a refinement of" ) 
(b) ({I, 2, 3}, "less than or equal to" ) 
(c) 
(2{a,b,c}, 
~) 
(d) ({1,2,3,5,6,10,15,30}, "is a divisor of" ) 
Figure 1.1: Hasse diagrams. 
15 

16 
CHAPTER 1. FUNDAMENTAL CONCEPTS 
1. 7 
Functions 
A function f from a set S into a set T, written 
f:S--+T, 
(1.46) 
assigns to every element XES an element f( x) E T called the image of x. 
The set S is called the domain of f; the set T is called the co-domain of f. 
The range of f is the set of images of elements of Sunder f. The range of 
f is clearly a subset of its co-domain; if the range of f is equal to T, we say 
that the function (1.46) is onto T. 
A function is a specialized relation. We recall that a relation from S 
to T is a subset of S x T, i.e., a collection of ordered pairs each of which 
takes its first element from S and its second element from T. Accordingly, 
we define a function f from S into T as a relation from S to T having the 
property that each element of S appears as a first element in exactly one of 
the ordered pairs in f. Thus the formulas "f(x) = y" and "(x,y) E f" are 
equivalent predicates. 
Example 1.7.1 Suppose S = {a,b,c}, T = {a,c,d}, and define a function 
f from S into T by the statements 
f(a) 
a 
f(b) 
d 
(1.47) 
f(c) = a. 
Then f is the relation 
f = {(a,a),(b,d),(c,a)}. 
(1.48) 
An alternative way to specify a function-one that is sometimes more con-
venient than either of the tabulations (1.47) or (1.48)-is by means of a 
function-table. Such a table for the present example is shown in Table 1.1. 
n-variable functions. A function 
f: Sn --+ T 
(1.49) 
is called an n-variable function from S into T. Thus the temperature-values 
in a 10' X 10' X 10' room are described by a 3-variable function from S = 
{xix is a real number between 0 and 10} into T = {xix is a real number}. 

1.7. FUNCTIONS 
17 
x f(x) 
a 
a 
b 
d 
c 
a 
Table 1.1: A function-table. 
Propositional functions. A function whose co-domain is {true, false} 
is called a propositional function. Every predicate, e.g., 
(1.50) 
represents a propositional function, inasmuch as a predicate becomes a propo-
sition for any allowable substitution of values for its arguments. The formula 
(1.50) represents a function 
f: S1 X S2 --+ {true, false} , 
where S1 and S2 are sets of numbers. For simplicity, let us take S1 = S2 = 
{O, 1, 2}. The corresponding propositional function f is a relation comprising 
nine ordered pairs, namely, 
f = {( (0,0), true), «0, 1), true), «0, 2), true), 
«1,0), true), «1,1), true), «1, 2), false), 
«2,0), true), «2, 1), false), «2,2), false)} . 
Functions vs. formulas. A formula such as 
is clearly simpler to work with than is the set of ordered pairs defining the 
functionf. The convenience of using formulas to represent functions may 
lead us to ignore the distinction between these two entities. The distinction 
is important, however, in the applications of Boolean reasoning. The desired 
behavior of a digital system, for example, is specified by a Boolean function 
f, whereas the structure of the system is specified by an associated Boolean 
formula. There are typically many equivalent formulas that represent a 
given function; correspondingly there are typically many circuit-structures 
that produce a given specified behavior. 

18 
CHAPTER 1. FUNDAMENTAL CONCEPTS 
1.8 
Operations and Algebraic Systems 
An operation, 0, on a set 8 = {81, 82,"'} is a function from 8 X 8 into 8, 
i.e., 
0:8x8-8. 
(1.51) 
To each ordered pair (a, b) E 8 X 8, the operation 0 assigns an element 
a 0 bE 8. We may specify an operation 0 by an operation-table having the 
following form: 
81 
81 0 81 
81 0 82 
82 
82 0 81 
82 0 82 
The pair (8,0) is called an algebraic 8Y8tem. An example is ([0,1],.), 
the set of real numbers on the closed interval from ° 
to 1, together with the 
operation of multiplication. An algebraic system may have more than one 
operation. We are familiar, for example, with the complex field (K, +",0,1); 
here K is the set of complex numbers and + and . are addition and multi-
plication, respectively, of complex numbers. In labelling an algebraic system 
it is sometimes convenient to name parts of the system in addition to its set 
and its operations. A Boolean algebra 8 (to be discussed in Chapter 3), for 
example, is labelled by the quintuple 
(B,+,·,O,l) . 
(1.52) 
The first element in the foregoing specification is a set, the next two elements 
are operations, and the last two elements are special members of B. The 
quintuple (1.52) provides five "slots" into which particular sets, operations, 
and special members may be inserted to form particular Boolean algebras. 
The algebraic system (25, U, n, 0, 8), for example, is the Boolean algebra of 
subsets of the set 8. 

EXERCISES 
19 
Exercises 
1. Assuming the domain of x to be the set of real numbers, which of the 
following is a valid implication? 
(a) x2 =-2 
==? x=5 
(b) x$3 
==? x2 ~ 0 
(c) x=4 
==? x$1 
(d) x+l=2 ==? x$3 
2. Give a recursive definition of the set 
0 0 0 
0 0 1 
B={[n,[~ IJ. 
0 1 1 
0 1 0 , ... } 
1 1 0 
1 1 1 
1 0 1 
1 0 0 
of reflected Gray codes. 
3. Let 0 denote the empty set. 
(a) For an arbitrary set S, which of the following is true? 
(b) Exhibit the following sets explicitly and state the cardinality of 
each. 
4. Given S = {0, {I, 2}}, exhibit 28. 

20 
CHAPTER 1. FUNDAMENTAL CONCEPTS 
5. Let S = {0,2,{4,5},4}. Decide the truth of each of the following 
statements: 
(a) 
{4,5} 
~ S 
(b) 
{4,5} 
E S 
(c) 
{2,4} 
~ S 
(d) 
{2,4} 
E S 
(e) 
0 
~ S 
(f) 
0 
E S 
(g) 
{0} 
~ S 
(h) 
{0} 
E S 
(i) 
{{4,5}} 
~ S 
(j) 
2 
~ S 
(k) 
2 
E S 
(1) 
{2} 
~ S 
(m) 
{2} 
E S 
6. Given that S is any non-empty set, decide the truth of each of the 
following statements. Explain your reasoning in each case. 
(a) 
S 
E 2S 
(b) 
S 
~ 2S 
(c) is} E 2S 
(d) is} 
~ 2S 
7. Using the fact that 0 ~ T for any set T, if0 is an empty set, show that 
there is only one empty set. 
8. Prove or disprove the following statements: 
(a) For all sets S, S X 0 = 0 X S. 
(b) If S and T are non-empty sets, then 
SxT=TxS 
<==> 
S=T. 
9. How many relations are there from an m-element set to an n-element 
set? 
10. Given sets D and R, define a set F as follows: 
F = {II! : D --+ R} . 
F is the set of functions, that is, that map D into R. Express # F in 
terms of # D and # R. 

EXERCISES 
21 
11. Let S be a set comprising k elements, and let n be a positive integer. 
(a) How many elements are there in sn? 
(b) How many n-variable functions are there from S into S? 
12. Decide, for each of the following sets of ordered pairs, whether the set 
is a function. 
(a) {(x, y) I x and y are people and x is the mother of y} 
(b) {(x, y) I x and yare people and y is the mother of x} 
(c) {(x, y) I x and yare real numbers and x2 + y2 = I} 
(d) {(x, y) I [x = 1 and y = 2] or [x = -1 and y = 2]} 

Chapter 2 
Boolean Algebras 
We outline in this chapter the ideas concerning Boolean algebras that we 
shall need in the remaining chapters. For a formal and complete treatment, 
see Halmos [78], Mendelson [137], Rudeanu [172], or Sikorski [187]. For 
an informal approach and a discussion of applications, see Arnold [3], Car-
vallo [35], Hohn [86], Kuntzmann [110], Svoboda & White [193], or White-
sitt [214]. Rudeanu's text [172] is unique as a complete and modern treat-
ment of Boolean functions and the solution of Boolean equations. 
We begin by stating a set of postulates for a Boolean algebra, adapted 
from those given by Huntington [92]. 
2.1 
Postulates for a Boolean Algebra 
Consider a quintuple 
(B, +, ·,0, 1) 
(2.1) 
in which B is a set, called the carrierj + and . are binary operations on Bj 
and ° 
and 1 are distinct members of B. The algebraic system so defined is 
a Boolean algebra provided the following postulates are satisfied: 
1. Commutative Laws. For all a, bin B, 
a+b = b+a 
a·b = b·a 
2. Distributive Laws. For all a, b, c in B, 
a+(b·c) = (a+b).(a+c) 
a·(b+c) = (a.b)+(a.c) 
23 
(2.2) 
(2.3) 
(2.4) 
(2.5) 

24 
CHAPTER 2. BOOLEAN ALGEBRAS 
3. Identities. For all a in B, 
O+a = a 
l'a = 
a 
(2.6) 
(2.7) 
4. Complements. To any element a in B there corresponds an element a' 
in B such that 
a + a' = 
1 
a· a' = 0 
(It is readily shown that the element a' is unique.) 
(2.8) 
(2.9) 
We shall be concerned in this book only with finite Boolean algebras, i.e., 
Boolean algebras whose carrier, B, is a finite set; thus "Boolean algebra" 
should be taken invariably to mean "finite Boolean algebra." Although a 
Boolean algebra is a quintuple, it is customary to speak of "the Boolean 
algebra B," i.e., to refer to a Boolean algebra by its carrier. 
As in ordinary algebra, we may omit the symbol "." in forming Boolean 
products, except where emphasis is desired. Also, we may reduce the number 
of parentheses in a Boolean expression by assuming that multiplications are 
performed before additions. Thus the formula (a . b) + c may be expressed 
more simply as ab + c. 
2.2 
Examples of Boolean Algebras 
2.2.1 
The Algebra of Classes (Subsets of a Set) 
Suppose in a given situation that every set of interest is a subset of a fixed 
nonempty set S. Then we call S a universal set and we call its subsets the 
classes of S. If S = {a, b}, for example, then the classes of S are 0, {a}, {b}, 
and {a,b}. 
The algebra of classes consists of the set 25 (the set of subsets of S), 
together with two operations on 25 , namely, U (set-union) and n (set-
intersection). This algebra satisfies the postulates for a Boolean algebra, 
provided the substitutions 

2.2. EXAMPLES OF BOOLEAN ALGEBRAS 
25 
B 
+---+ 28 
+ +---+ 
U 
+---+ n 
0 
+---+ ° 
1 
+---+ 
S 
are carried out, i.e., the system 
(28,U,n,0,S) 
is a Boolean algebra. The "algebra of logic" of Boole [13], Carroll [34], 
Venn [210], and other nineteenth-century logicians was formulated in terms 
of classes. Carroll's problems, involving classes such as "my poultry," "things 
able to manage a crocodile," and "persons who are despised," remain popular 
today as logical puzzles. 
2.2.2 The Algebra of Propositional Functions 
A proposition is a statement that is necessarily true or false, but which can-
not be both. Propositions are elementary units of reasoning; they may be 
operated upon, and assembled in various patterns, by a system of calcula-
tion called the algebra of propositions, or the propositional calculus. Let P 
and Q be propositions. The conjunction of P and Q, read "P and Q" and 
symbolized P /I. Q, is a proposition that is true if and only if both P and 
Q are true. The disjunction of P and Q, read "P or Q" and symbolized by 
P V Q, is a proposition that is false if and only if both P and Q are false. 
The negation of P, read "not P" and symbolized by ..,P, is a proposition that 
is true if P is false and false if P is true. The conditional with antecedent 
P and consequent Q, read "if P then Q" and symbolized by P -+ Q, is de-
fined to have the same truth-value, for all truth-values of P and Q, as the 
propositional function ..,P V Q. 
Let P be the set of propositional functions of n given variables, let 0 be 
the formula that is always false (contradiction), and let _ be the formula 
that is always true (tautology). Then the system 
(P, V, /I., 0,_) 
is a Boolean algebra (see Arnold [3] Goodstein [72] or Hohn [86] for a fuller 
discussion) . 

26 
CHAPTER 2. BOOLEAN ALGEBRAS 
2.2.3 
Arithmetic Boolean Algebras 
Let n be the product of distinct relatively prime numbers, let Dn be the set 
of all divisors of n, and let lem and ged denote the operations "least common 
multiple" and "greatest common divisor," respectively. Then the system 
(Dn,lem,ged,l,n) 
is a Boolean algebra, a fact first pointed out, apparently, by Bunitskiy [31]. 
The symbol 1 denotes the integer 1; it is necessary to distinguish the integer 
1 from the Boolean I-element because the integer 1 is the O-element of an 
arithmetic Boolean algebra. 
Example 2.2.1 The arithmetic Boolean algebra for n = 30 is 
({l, 2, 3,5,6, 10, 15,30}, lem,ged, l, 30), 
giving rise to operations such as the following: 
o 
6 + 15 = 30 
6 ·15 = 3. 
2.2.4 The Two-Element Boolean Algebra 
The system 
({O, I}, +,·,0,1) 
is a Boolean algebra provided + and· are defined by the following operation-
tables: 
+ 0 
1 
0 
0 
1 
1 
1 
1 
2.2.5 
Summary of Examples 
ffiBJ
o 1 
o 0 
0 
101 
A summary of the foregoing examples of Boolean algebras is given in Ta-
ble 2.1. 

2.3. THE STONE REPRESENTATION THEOREM 
27 
II 
Algebra 
B 
+ 
o 
1 
Subsets 
of S 
28 
U 
n 
0 
S 
(Classes) 
n-Variable 
Propositions 
Propositional 
V 
A 
0 
• 
Functions 
Arithmetic 
Divisors 
Boolean 
of 
lcm 
gcd 
1 
n 
Algebra 
n 
Two-element 
+ 0 
1 
0 
1 
Boolean 
{0,1} 
0 
0 
1 
0 
0 
0 
0 
1 
Algebra 
1 
1 
1 
1 
0 
1 
Table 2.1: Examples of Boolean Algebras. 
2.3 
The Stone Representation Theorem 
The following theorem, first proved by Stone [190], establishes the important 
result that any finite Boolean algebra (i.e., one whose carrier is of finite size) 
has the same structure as a class-algebra. 
Theorem 2.3.1 Every finite Boolean algebra is isomorphic to the Boolean 
algebra of subsets of some finite set S. 
Stone proved that an infinite Boolean algebra is also isomorphic to a set-
algebra, though not necessarily to the simple algebra of subsets of a universal 
set (see Mendelson [137, Chapter 5] or Rosenbloom [170, Chapter 1]). 
Some Boolean algebras have exclusive properties, i.e., properties that do 
not hold for all Boolean algebras. The properties 
x + y = 1 iff x = 1 or y = 1 
x . y = 0 iff x = 0 or y = 0 , 
(2.10) 
(2.11) 
for example, hold only in two-element algebras. The Stone Representation 
Theorem tells us that finite class-algebras, however, are not specialized; we 
may reason, with no lack of generality, in terms of the specific and easily 
visualized concepts of union, intersection, 0, and S (where S is the "univer-
sal set") rather than in terms of the abstract concepts +, ., 0, and 1. In 
II 

28 
CHAPTER 2. BOOLEAN ALGEBRAS 
particular, we are always justified in using the intuitive properties of class-
algebras, rather than going back to the postulates, to prove properties valid 
for all finite Boolean algebras. 
2.4 
The Inclusion-Relation 
We define the relation ~ on a Boolean algebra as follows: 
a ~ b if and only if ab' = 0 . 
This relation is is a partial order, i.e., it is 
(a) reflexive: 
a ~ a 
(b) antisymmetric: a ~ b and b ~ a ==> a = b 
(c) transitive: 
a ~ b and b ~ c ==> a ~ c 
A property analogous to (2.12), viz., 
A ~ B if and only if A n B' = 0 , 
(2.12) 
holds in the algebra of subsets of a set. A and B are arbitrary classes, i.e., 
subsets of a universal set S. The relation An B' = 0 is easily visualized by 
means of an Euler diagram, as shown in Figure 2.1. 
Because the relation ~ in a Boolean algebra B corresponds to the relation 
!; in the subset-algebra isomorphic to B, we call :S the inclusion-relation. 
It is useful in practice to recognize the equivalence of the following state-
ments: 
a 
~ b 
(2.13) 
ab' = 0 
(2.14) 
a' + b = 1 
(2.15) 
b' 
~ a' 
(2.16) 
a+b = b 
(2.17) 
ab = a. 
(2.18) 
The equivalence of (2.13) and (2.14) is announced by definition in (2.12); 
the equivalence of the remaining pairs is readily verified. 
In Table 2.2 we tabulate several relations, defined in specific Boolean 
algebras, that correspond to the general inclusion-relation ~. 

2.4. THE INCLUSION-RELATION 
29 
S 
Figure 2.1: Euler diagram illustrating the relation An B' = 0. 
Boolean Algebra 
Relation Corresponding to < 
Subset-Algebra 
~ 
Arithmetic Boolean Algebra 
"divides" 
Algebra of Propositions 
--+ 
Two-element Algebra 
{(O,O),(O,I),(I,I)} 
Table 2.2: The inclusion-relation in several Boolean algebras. 

30 
CHAPTER 2. BOOLEAN ALGEBRAS 
2.4.1 
Intervals 
The solutions to many kinds of Boolean problems occur in sets defined by 
upper and lower bounds. Let a and b be members of a Boolean algebra 
B, and suppose that a ~ b. The interval (or segment) [a, b] is the set of 
elements of B lying between a and b, i.e., 
[a, b] = {x I x E B and a ~ x ~ b} . 
Example 2.4.1 Let B = {I, 2, 3, 5, 6,10,15, 3D} be the 8-element arith-
metic Boolean algebra of Example 2.2.1. The inclusion-relation in this alge-
bra is arithmetic divisibility; thus [3,30] is the interval 
[3,30] = {3, 6,15, 3D} . 
o 
If (B, +,·,0,1) is a Boolean algebra and a and b are distinct elements of 
B such that a ~ b, then the system 
([a, b], +,', a, b) 
is a Boolean algebra. 
2.5 
Some Useful Properties 
We list below some properties-valid for arbitrary elements a, b, e in a 
Boolean algebra-that are useful in manipulating Boolean expressions. 
Property 1 (Associativity): 
a+(b+e) 
(a+b)+e 
(2.19 ) 
a(be) 
(ab)e 
(2.20) 
Property 2 (Idempotence): 
a+a = 
a 
(2.21) 
aa = 
a 
(2.22) 
Property 3: 
a+l = 
1 
(2.23) 
a·O = 
0 
(2.24) 

2.5. SOME USEFUL PROPERTIES 
Property 4 (Absorption): 
Property 5 (Involution): 
a + (ab) 
a(a + b) 
a 
a 
(a')' = a 
Property 6 (De Morgan's Laws): 
Property 7: 
(a + b)' 
(ab)' = 
a + a'b 
a(a' + b) 
a'b' 
a' + b' 
a+b 
ab 
Property 8 (Consensus): 
Property 9: 
ab + a'e + be = 
(a + b)(a' + e)(b + e) 
ab + a'e 
(a + b)(a' + e) 
a < a+b 
ab 
~ a 
31 
(2.25) 
(2.26) 
(2.27) 
(2.28) 
(2.29) 
(2.30) 
(2.31 ) 
(2.32) 
(2.33) 
(2.34) 
(2.35) 
Property 10 (The principle of duality): Every identity deducible from 
the postulates of a Boolean algebra is transformed into another identity if 
(i) 
the operations + and " 
(ii) 
the left and right members of inclusions, and 
(iii) 
the identity-elements 0 and 1 
are interchanged throughout. 
The postulates themselves, together with the foregoing properties, pro-
vide good examples of the duality-principle. Because of that principle, only 
one of each of the statement-pairs above need be established; the other mem-
ber of the pair follows by duality. 

32 
CHAPTER 2. BOOLEAN ALGEBRAS 
Proposition 2.5.1 Let a and b be members of a Boolean algebra. Then 
a = 0 and b = 0 
iff a + b = 0 
(2.36) 
a = 1 and b = 1 
iff 
ab = 1 . 
(2.37) 
Proof. 
We prove (2.36)j the proof of (2.37) follows by dual statements. 
If a = 0 and b = 0, then it follows from additive idempotence (2.21) that 
a+b = 0+0 = o. Conversely, suppose that a+b = o. Multiplying both sides 
by a and applying distributivity (2.4), multiplicative idempotence (2.22), and 
property (2.24), we obtain a + ab = 0, from which the result a = 0 follows 
by absorption (2.25). We deduce similarly that b = o. 0 
Proposition 2.5.2 Let a and b be members of a Boolean algebra. Then 
a = b iff a'b + ab' = 0 . 
(2.38) 
Proof. Suppose a = b. Then a'b + ab' = a' a + aa' = 0 + 0 = o. Suppose on 
the other hand that a'b+ab' = o. If a is added to both sides, the result, after 
simplification, is a + b = aj if instead b is added to both sides, the simplified 
result is a + b = b. Thus a = b. 0 
Proposition 2.5.2 enables an arbitrary Boolean equation to be recast 
equivalently in the standard form f = o. We will make frequent use of this 
form. Proposition 2.5.2 also provides a direct means of verifying Boolean 
identities of the form a = bj it is more convenient in many cases to evaluate 
a'b + ab' than it is to manipulate one side of an identity until it becomes the 
same as the other. 
Example 2.5.1 Let us verify identity (2.30), which has the form u = v, 
where u = a + a'b and v = a + b. Thus 
u'v + uv' = (a + a'b)'(a + b) + (a + a'b)(a + b)' . 
The latter expression is readily evaluated to be the O-elementj hence, (2.30) 
is valid. 0 
Exclusive OR and Exclusive NOR. The formula a'b + ab' in (2.38) 
occurs often enough to justify our giving it a special name. It is called the 
"exclusive OR" (or modulo-2 sum) of a and b and is denoted by a $ b. This 
was the sum-operator employed by Boole [13], who denoted it by +j the 
operation we denote by + (the "inclusive OR") was introduced by Jevons 
[94], who modified Boole's essentially arithmetic algebra to create the more 
"logical" semantics of modern Boolean algebra. The complement of a $ b is 
called the "exclusive NOR" of a and b, and is denoted by a 0 b. 

2.6. N -VARIABLE BOOLEAN FORMULAS 
33 
2.6 
n-Variable Boolean Formulas 
We shall be concerned throughout this book with two kinds of objects: for-
mulas (strings of symbols) and functions. A Boolean function is a mapping 
that can be described by a Boolean formula; we therefore need to character-
ize Boolean formulas before discussing Boolean functions. 
Given a Boolean algebra B, the set of Boolean formu.las on the n symbols 
Xl, X2, ••• ,Xn is defined by the following rules: 
1. The elements of B are Boolean formulas. 
2. The symbols Xl, X2, • •. , Xn are Boolean formulas. 
3. If 9 and h are Boolean formulas, then so are 
(a) (g) + (h) 
(b) (g)(h) 
(c) (g)' . 
4. A string is a Boolean formula if and only if its being so follows from 
finitely many applications of rules 1, 2, and 3. 
We refer to the strings defined above as n-variable Boolean formu.las. 
The number of such formulas is clearly infinite. Given the Boolean algebra 
B = {a, l,a',a}, the strings 
a 
(a) + 
(a) + 
(a) + 
(a) 
«a) + (a» 
«a) + «a) + (a») , ... 
for example, are all distinct n-variable Boolean formulas for any value of n. 
Our definition rejects as Boolean formulas such reasonable-looking strings 
as b + X2 and aXI because they lack the parentheses demanded by our rules. 
We therefore relax our definition by calling a string a Boolean formula if it 
can be derived from a Boolean formula by removing, without introducing 
ambiguity, a parenthesis-pair ( ... ). Thus, the Boolean formula (b) + (X2) 
yields, by removal of a parenthesis-pair, the Boolean formula (b) + X2; the 
latter, by another removal, yields the Boolean formula b + X2. 
We are accustomed to thinking of the formulas (g) + (h) and (g)(h) as 
representing operations (addition and multiplication) in a Boolean algebra. 

34 
CHAPTER 2. BOOLEAN ALGEBRAS 
In the present discussion, however, we are concerned only with syntax, i.e., 
rules for the formation of strings of symbols. We shall shortly need to view 
the same formulas as representing functions. In cases where it is necessary 
to distinguish Boolean formulas from Boolean functions, we indicate that 
(g) + (h) is a formula by calling it a disjunction (rather than a sum) and 
that (g) (h) is a formula by calling it a conjunction (rather than a product). 
We denote formulas in such situations by upper-case symbols and functions 
by lower-case. Thus 9 + h is a function (the sum of functions g and h), 
whereas G + H is a formula (the disjunction of formulas G and H). 
2.7 
n-Variable Boolean Functions 
An n-variable function f: Bn~ B is called a Boolean function if and only 
if it can be expressed by a Boolean formula. To make this definition precise 
we must associate a function with each n-variable Boolean formula on B. 
The set of such formulas is defined recursively by rules given in Section 2.6; 
we therefore define the n-variable Boolean functions on B by a parallel set 
of rules: 
1. For any element b E B, the constant function, defined by 
is an n-variable Boolean function. 
2. For any symbol Xi in the set {Xl, X2, ... , xn}, the projection-function, 
defined, for any fixed i E {1,2, ... ,n}, by 
is an n-variable Boolean function. 
3. If 9 and hare n-variable Boolean functions, then the functions 9 + h, 
gh and g', defined by 
(a) 
(b) 
(c) 
(g + h)(XI, X2, ... , xn) 
(gh)(Xb X2,"" xn) 
(g')(XI,X2," .,xn) 
= g(XI, X2, ... , xn) + h(Xll X2, ... , xn) 
= 9(Xb X2,···, xn) . h(XI, X2, ... , xn) 
(g(xt, X2,···, xn))' , 
for all (Xl, X2, ... , Xn) E Bn, are also n-variable Boolean functions. 
These functions are said to be defined pointwise on the mnge. 

2.7. N -VARIABLE BOOLEAN FUNCTIONS 
35 
4. Nothing is an n-variable Boolean function unless its being so follows 
from finitely many applications of rules 1, 2, and 3 above. 
Example 2.7.1 Given B = {O, 1,a',a}, let us construct the function-table 
for the two-variable Boolean function I: B2 ---7 B corresponding to the 
Boolean formula a'x + ay'. We observe that the domain, 
B X B = {(O,O),(O,l), ... ,(a,a)}, 
has 16 elements; hence, the function-table has 16 rows, as shown in Table 2.3. 
o 
Formula 
a'x + ay' 
Function - Table 
x 
y 
I(x, y) 
° ° 
a 
0 
1 
0 
0 
a' 
a 
0 
a 
0 
1 
0 
1 
1 
1 
a' 
1 a' 
1 
1 
a 
a' 
a' 
0 
1 
a' 
1 
a' 
a' a' 
1 
a' a 
a' 
a 
0 
a 
a 
1 
0 
a 
a' 
a 
a 
a 
0 
Table 2.3: Function-table for a' x + ay' over {O, 1, a'a}. 
The rules defining the set of Boolean functions translate each n-variable 
Boolean formula into a corresponding n-variable Boolean function (which is 
said to be represented by the formula), and every n-variable Boolean function 
is produced by such a translation. 

36 
CHAPTER 2. BOOLEAN ALGEBRAS 
The number of n-variable Boolean formulas over a finite Boolean alge-
bra B is infinite; however, the number of n-variable function-tables over B, 
of which Table 2.3 is an example, is clearly finite. Thus, the relationship 
between Boolean formulas and Boolean functions is not one-to-one. The 
distinct Boolean formulas 
a+z 
az' +z 
a + a'z 
a+a+z 
(a + z )a + a' z , 
for example, all represent the same Boolean function. 
An important task in many applications of Boolean algebra is to select 
a good formula-given some definition of "good"-to represent a Boolean 
function. 
The range of a Boolean function. The range (cf. Section 1.7) of a 
Boolean function f: Bn __ B is the set of images of elements of Bn under 
f. It was shown by Schroder [178, Vol. 1, Sect. 19] that the range of f is 
the interval 
[ II f(A) , Ef(A)]. 
(2.39) 
Ae{o,l}n 
Ae{O,l}n 
A proof for this result is given by Rudeanu [172, Theorem 2.4]. 
2.8 
Boole's Expansion Theorem 
The basis for computation with Boolean functions is the expansion theo-
rem given below. Called "the fundamental theorem of Boolean algebra" 
by Rosenbloom [170], it was discussed in Chapter V of Boole's Laws of 
Thought [13] and was widely applied by Boole and other nineteenth-century 
logicians. It is frequently attributed to Shannon [184], however, in texts on 
computer design and switching theory. 
Theorem 2.8.1 If f: Bn __ B is a Boolean function, then 
f(zlt Z2,· .. , zn) = z~ . f(O, Z2,· .. , zn) + Zl • f(l, Z2, ••• , zn) 
for all (Zit Z2, ••• ,zn) in Bn. 
(2.40) 

2.8. BOOLE'S EXPANSION THEOREM 
37 
Proof. We show that (2.40) holds for every n-variable Boolean function. 
For notational convenience, we write f(xI, .. . ), f(O, . .• ), and f(l, . .. ), the 
arguments X2, ••• , Xn being understood. 
1. Suppose f is a constant junction, defined by f(X) = b for all X E Bn, 
where b is a fixed element of B. Then 
thus f satisfies (2.40). 
2. Suppose f is a projection-function, defined by f(X) = Xi for all X E Bn, 
where i E {I, ... , n}. If i = 1, then 
x~f(O, . .. ) + xt/(l, ... ) = x~ ·0+ Xl ·1 = Xl = f(X) . 
If i :/:1, then 
Thus f satisfies (2.40). 
3. Suppose (2.40) to hold for n-variable Boolean functions 9 and h, i.e., 
suppose the conditions 
g(X1" .. ) = 
x~g(O, ... ) + x1g(1, ... ) 
h(X1"") = 
x~h(O, ... ) + x1h(1, ... ) 

38 
CHAPTER 2. BOOLEAN ALGEBRAS 
to be satisfied for all (Xl, ... ) E Bn. We show that (2.40) then holds 
for the n-variable functions 9 + h, gh, and g'. 
(a) (g + h)(x!, ... ) 
= g(x!, ... ) + h(x!, ... ) 
= (xig(O, ... ) + xIg(l, ... )) + (xih(O, ... ) + xlh(l, .. . )) 
= xi(g(O, ... ) + h(O, ... )) + xI(g(l, ... ) + h(l, .. . )) 
= xi[(g + h)(O, .. . )] + XI[(g + h)(l, .. . )]. 
(b) (gh)(Xb . .. ) 
= (g(x!, ... ))(h(Xb .. . )) 
= (xig(O, ... ) + xIg(l, ... )). (xih(O, ... ) + xlh(l, .. . )) 
= xi (g(O, ... )h(O, .. . )) + xI(g(l, .. . )h(l, ... )) 
= xi[(gh)(O, .. . )] + xI[(gh)(l, .. . )] 
(c) 
(g')(x!, ... ) 
= (g(XI' .. . ))' 
= (xig(O, ... ) + xIg(l, ... ))' 
= (Xl + (g(O, ... )),)(xi + (g(l, ... ))') 
= xi[(g')(O, .. . )] + xl[(g')(1, .. . )] + [(g')(O, ... )][(g')(1, .. . )] 
= xi[(g')(O, .. . )] + xI[(g')(l, ... )]. 
The final step above is justified by (2.32), the rule of consensus. 0 
Corollary 2.8.1 If f is an n-variable Boolean function, then 
f(xt.x2, ... ) = [xi + f(1,x2, . .. )]. [Xl + f(0,X2, .. . )]. 
(2.41) 
If f: B n ---+ B is an n-variable Boolean function and if a is an element of 
B, then the (n - I)-variable function g: Bn-l---+B defined by 
is also a Boolean function (the proof is left as an exercise). Thus the func-
tions f(O, X2, ... , xn) and f(l, X2, . .. , xn) appearing in Theorem 2.8.1 and 
its corollary are Boolean. 

2.9. THE MINTERM CANONICAL FORM 
39 
2.9 
The Minterm Canonical Form 
A Boolean function may be represented by an infinite number of Boolean for-
mulas. It is often useful, however, to work with a restricted class of Boolean 
formulas, one in which any Boolean function is represented by exactly one 
formula. A formula in such a class is called a canonical form. An important 
canonical form for Boolean reasoning was given by Blake [10]; we discuss 
Blake's canonical form in Chapter 3. A canonical form due to Zhegalkin 
[223], known in the U.S. as the Reed-Muller form [165, 141], is based on 
the Boolean ring (see Rudeanu [172, Chapt. 1, Sect. 3]). We now consider 
the minterm canonical form, first discussed in Boole's Laws of Thought [13, 
Chapt. V]. 
Let us develop a 3-variable Boolean function f by repeated application 
of Boole's expansion theorem (Theorem 2.8.1): 
f(x,y,z) 
x'f(O,y,z)+xf(l,y,z) 
x'[y' f(O, 0, z) + yf(O, 1, z)] + x[y' f(l, 0, z) + yf(l, 1, z)] 
= x'y'z' f(O, 0, 0) + x'y'zf(O, 0,1) 
+x'yz' f(O, 1, 0) + x'yzf(O, 1, 1) 
+xy' z' f(l, 0, 0) + xy'zf(l, 0,1) 
+xyz' f(l, 1, 0) + xyzf(l, 1, 1) . 
By obvious extension, an arbitrary n-variable Boolean function f may 
be expanded as 
f( Xl, .•. , Xn-l, xn ) = 
f(O, ... ,0, 0) x~ ... x~_l x~ 
+ f(O, ... ,0, 1) x~ .. ·X~_lXn 
(2.42) 
+ f(l, ... , 1, 1) Xl ••• Xn-lXn • 
The values 
f(O, ... , 0, 0), 
f(O, ... , 0,1), ... , f(l, ... ,l,l) 
are elements of B called the discriminants of the function f; the elementary 
products 
are called the minterms of X = (Xl, ••• , xn ). (Boole called these prod-
ucts the constituents of X.) The discriminants carry all of the information 

40 
CHAPTER 2. BOOLEAN ALGEBRAS 
concerning the nature of fj the minterms, which are independent of f, are 
standardized functional building-blocks. We call the expansion (2.42) the 
minterm canonical form of f and denote it by MCF(j). 
For convenience in expressing expansions such as (2.42), we introduce 
the following notation: for x E B and a E {O, I}, we define X4 by 
(2.43) 
This notation is extended to vectors as follows: for X = (Xl, X2, • •• , xn) E Bn 
and A = (at,a2, ... ,an) E {o,l}n, we define XA by 
X A _ ... 41 ... 42 
... 4n 
-""1 ""2 •• ·""n . 
(2.44) 
Let A = (at,a2, ... ,an) and B = (b1,b2, ... ,bn) be members of {o,l}n. 
Then 
AB = { 1 if A = B 
o otherwise. 
(2.45) 
The notation defined above enables us to give the following concise char-
acterization of Boolean functions. 
Theorem 2.9.1 A function f: Bn----+ B is Boolean if and only if it can be 
expressed in the min term canonical form 
f(X) = E f(A)XA. 
(2.46) 
Ae{O,l}n 
Proof. 
Suppose that f is Boolean. We have deduced by repeated 
application of Theorem 2.8.1 (Boole's expansion theorem) that f can then 
be expressed by the minterm form (2.42), which is written equivalently as 
(2.46). Suppose on the other hand that f can be expressed in the form 
(2.46). It is clear that (2.46) satisfies the rules given in Section 2.6 for a 
Boolean formulaj thus (2.46) represents a Boolean function. 0 
Constructing M C F(j) consists in determining the discriminants of f. 
If f is specified by a function-table, then its discriminants are exhibited 
explicitly. If f is specified by a Boolean formula, its discriminants may 
be found by repeated substitutions of Os and Is into that formula. Other 
methods for transforming a Boolean formula into its minterm canonical form 
are given in texts on logical design and switching theory [106, 122, 136, 218]. 

2.9. THE MINTERM CANONICAL FORM 
41 
Example 2.9.1 Suppose, as in Example 2.7.1, that a two-variable Boolean 
function I: B2--+B is defined over B = {O, 1, a', a} by the formula a'x +ay'. 
The corresponding 16-row function-table is shown in Table 2.3. The four 
discriminants of I are obtained from that table as follows: 
1(0,0) = a 
1(0,1) = ° 
1(1,0) = 1 
1(1,1) = a' . 
Thus 
MCF(J) = ax'y' + xy' + a'xy. 
(2.47) 
o 
2.9.1 
Truth-tables 
If B has k elements, then the number of rows in the function-table for an 
n-variable function is (#Domain)fI = kfl. Theorem 2.9.1 implies, however, 
that a Boolean lunction is completely defined by the 0,1 assignments 01 its 
arguments. More precisely, an n-variable Boolean function is defined by the 
2f1 rows of its function-table for which each argument is either ° or Ii the 
sub-table thus specified is called a truth-table. The 2-variable function lof 
Examples 2.7.1 and 2.9.1 is known to be Boolean, inasmuch as it is repre-
sented by a Boolean formula. Hence the 4-row truth-table shown in Table 2.4 
completely specifies Ii the remaining 12 entries in the full function-table 
(Table 2.3) are determined by the minterm canonical form (2.47), whose 
coefficients are the entries in Table 2.4. 
x y I(x, y) 
° ° 
a 
° 
1 ° 
1 ° 
1 
1 1 
a' 
Table 2.4: Truth-table for a'x + ay' over {O, 1, a', a}. 

42 
CHAPTER 2. BOOLEAN ALGEBRAS 
Example 2.9.2 Given B = {O, 1, a', a}, let a I-variable function 1 be de-
fined by the function-table shown below. Is 1 Boolean? 
x I(x) 
0 
a 
1 
1 
a' 
a' 
a 
1 
The function 1 is Boolean if and only if the values of I( x) listed in the table 
agree, for all x E B, with the values of I(x) produced by substitution in 
the minterm canonical form, i.e., I(x) = x'· 1(0) + X· 1(1) = x' . a + X· 1. 
Substituting the trial-value x = a yields I(a) = a' ·a+a·l; thus, I(a) = a if 1 
is a Boolean function. The function-table, however, specifies that I(a) = 1; 
thus 1 is not a Boolean function. 0 
2.9.2 
Maps 
A truth-table for a Boolean function I, e.g., Table 2.4, is a one-dimensional 
display of the discriminants of I. The same information displayed in two-
dimensional form is called a map, chart or diagram. The display proposed 
by Karnaugh [99], called a map, is widely used by logical designers, and is 
discussed at length in virtually any text on switching theory or logical de-
sign. Karnaugh maps are practical and effective instruments for simplifying 
Boolean formulas; formula-simplification is a secondary question in Boolean 
reasoning, however, and a proper discussion of the use of maps would take 
us afield. We therefore discuss maps only as another way to display the 
discriminants of a Boolean function. If B is the two-element algebra {O, I}, 
then the displays we discuss are the ones customarily treated in engineering 
texts; if B is larger, the displays are those usually called "variable-entered" 
[32, 39, 57, 93, 173, 179]. 
The ancestor of the Karnaugh map was the "logical diagram" proposed 
by Marquand [131] in 1881. Marquand's diagram was re-discovered by 
Veitch [208] in 1952; Veitch called it a "chart" and discussed its utility in 
the design of switching circuits. 
Let us develop a Marquand-Veitch diagram for the Boolean function 
I(x,y,z) = a'z' + ay'z + xz + bx'y' , 
(2.48) 

2.9. THE MINTERM CANONICAL FORM 
43 
defined over the free Boolean algebra B = FB(a,b) (c/. Section 2.12). In 
minterm canonical form, 
f(x, y, z) 
(a' + b)x'y'z' + (a + b)x'y'z + (a')x'yz' + (O)x'yz 
+ 
(l)xy'z' 
+ (a)xy'z 
+ (l)xyz' 
+ (O)xyz. 
The corresponding Marquand-Veitch diagram, shown in Table 2.5, displays 
the discriminants f(O, 0, O),J(O, 0,1), ... , f(l, 1,1) in a 2 X 4 array according 
to the natural binary ordering of the arguments in {O, 1 p. The discriminants 
of a four-variable function would be displayed in a 4 X 4 array, those of a 
five-variable function in a 4 X 8 array, and so on. An 8 X 8 Marquand diagram 
is shown in Venn's book on symbolic logic [210, p. 140]. Comparing it with 
his own diagram, Venn said of Marquand's that "there is not the help for 
the eye here, afforded by keeping all the subdivisions of a single class within 
one boundary." This visual disadvantage was largely overcome through a 
modification suggested by Karnaugh in 1953. Karnaugh's map orders the 
arguments of the discriminants according to the reflected binary code, also 
called the Gray code [74]. In a Karnaugh map of four or less arguments, 
the cells for which a given variable is assigned the value 1 form a contiguous 
band. For maps of more than four variables, not all variables are associated 
with such bands, but as much help as possible (within the limits of two-
dimensional topology) is provided for the eye. A Karnaugh map for the 
function (2.48) is shown in Table 2.6; the bands for the variables x, y, and 
z are indicated by lines adjacent to the map. 
yz 
00 
01 
10 
a' 
1 
11 
o 
o 
Table 2.5: Marquand-Veitch diagram for /(x, y, z) = a'z' + ay'z + xz+ bx'y'. 
Marquand, Veitch, and Karnaugh discussed only 0 and 1 as possible cell-
entries. The generalization to larger Boolean algebras is immediate, however, 
if their displays are defined simply as arrays of discriminant-values. 

44 
CHAPTER 2. BOOLEAN ALGEBRAS 
z 
00 
01 
11 
o o 
y 
10 
a' 
1 
Table 2.6: Karnaugh map for f(x, y, z) = a'z' + ay'z + xz + bx'y'. 
2.10 
The Lowenheim-Miiller Verification Theorem 
We define an identity in a Boolean algebra B to be a statement involving 
constants (elements of B) and arguments Xt, X2, ••• , Xn that is valid for all 
argument-substitutions on Bn (Boolean identities are discussed further in 
Section 4.6). 
Suppose we wish to verify that an identity, e.g., 
xy ~ x, 
(2.49) 
is valid in all Boolean algebras, and to do so without going back to the 
postulates. We cannot substitute all possible values for the variables x and 
y, because no limit has been specified for the size of the carrier, B. We 
have seen, however, that a Boolean function is completely defined by the 0,1 
assignments of its arguments. Thus 0,1-substitutions are adequate to verify 
a Boolean identity. This result, called the Lowenheim-Miiller Verification 
Theorem [124, 142], may be stated as follows: 
Theorem 2.10.1 An identity expressed by Boolean formu.las is valid in an 
arbitrary Boolean algebra if and only if it is valid in the two-element Boolean 
algebra. 
The Verification Theorem applies only to identities, and not to other 
kinds of properties. Thus the properties (2.10) and (2.11), which are not 
identities, are valid in the two-element algebra, but not in larger Boolean 
algebras. 
To verify that an identity on n variables is valid for all Boolean algebras, 
then, it suffices to employ a truth-table, which enables us systematically 
to make all substitutions on {0,1}n. Table 2.7 illustrates the process for 
identity (2.49); the identity is valid inasmuch as the asserted relationship 
(inclusion) holds between xy and x for all argument-substitutions. 

2.11. SWITCHING FUNCTIONS 
45 
x 
y 
xy x 
0 0 
0 
0 
0 1 
0 
0 
1 0 
0 
1 
1 1 
1 
1 
Table 2.7: Truth-table verifying xy ::; x. 
2.11 
Switching Functions 
An n-variable switching function is a mapping of the form 
f: {O, l}n __ {O, I}. 
(2.50) 
The domain of (2.50) has 2n elements and the co-domain has 2 elements; 
hence, there are 22n n-variable switching functions. 
A truth-table, as we have noted, is a sub-table of a function-table. If B 
is the two-element Boolean algebra {O, I}, however, a truth-table is identical 
to the function-table from which it is derived, which leads to the following 
result. 
Proposition 2.11.1 Every switching function is a Boolean function. 
The term "switching function" may convey the impression that the two-
element Boolean algebra suffices to design switching systems. We discuss 
the utility of larger Boolean algebras for such design in Section 2.18. 
Rudeanu [172, p. 
17] defines a useful class of functions, the simple 
Boolean functions, that lie between the switching functions and general 
Boolean functions. A function f: Bn __ B, B being an arbitrary Boolean 
algebra, is a simple Boolean function if f can be represented by a formula 
built from variables by superposition of the basic operations. Constants, 
except 0 and 1, are not allowed. 
2.12 
Incompletely-Specified Boolean Functions 
Reasoning in a Boolean algebra B frequently entails working with a nonempty 
interval of Boolean functions, i.e., a set :F defined by 
:F = { f I g(X) ::; f(X) ::; heX) 'IX E Bn} , 
(2.51) 

46 
CHAPTER 2. BOOLEAN ALGEBRAS 
where g: Bn---+ Band h: Bn---+ B are Boolean functions such that g(X) ::; 
heX) for all X E Bn. Inasmuch as 9 and h are completely defined by their 
truth-tables, i.e., by their values for argument-assignments on {O,l}n, the 
definition (2.51) for the set :F may be stated equivalently as follows: 
:F = { f I g(X)::; f(X) ::; heX) "IX E {O, l}n} . 
(2.52) 
Let S be the set of intervals on Bj that is, 
S = { [a, b]1 a E B, bE B, a::; b} . 
(2.53) 
Then we may represent the set :F by a single mapping f: Bn -- S, defined 
as follows: 
f(X) = [g(X), heX)] 
"IX E {O, l}n . 
(2.54) 
A mapping associated in this way with an interval [g, h] is called an incompletely-
specified Boolean function. 
Example 2.12.1 Let B = {O,a',a,l} and let 2-variable Boolean functions 
9 and h be defined by the formulas 
g(x, y) = ax' + a'xy 
h(x,y) = ax' + a'x + y' . 
(2.55) 
Then the 2-variable incompletely-specified function defined by the interval 
[g,h] is given by the truth-table shown in Table 2.8. 
x 
y 
f(x,y) 
° ° 
[a, 1] = {a,l} 
° 
1 
[a, a] = {a} 
1 ° 
[0,1] = {O,a',a,l} 
1 
1 
[a', a1 = {a'} 
Table 2.8: Truth-table for an incompletely-specified function. 
o 
Incompletely-specified Boolean functions are most often employed in sit-
uations where B is the two-element Boolean algebra {O, 1}, in which case 
9 and h are switching functions, and the elements [O,O],[O,l],and [1,1] of S 
are renamed 0, X, and 1, respectively. The "value" X (sometimes denoted 
by the symbol d) indicates a choice between ° and 1j it is referred to as a 
"don't-care" value. 

2.13. BOOLEAN ALGEBRAS OF BOOLEAN FUNCTIONS 
47 
Example 2.12.2 Let B = {O, 1} and let 2-variable Boolean functions 9 and 
h be defined by the formulas 
g(x, y) = x'y + xy' 
hex, y) = x + y . 
(2.56) 
Then the 2-variable incompletely-specified function defined by the interval 
[g, h] is given by the truth-table shown in Table 2.9. 
x 
y 
f(x,y) 
° 
0 
0 
° 
1 
1 
1 ° 
1 
1 
1 
X 
Table 2.9: Truth-table for an incompletely-specified switching function. 
o 
2.13 
Boolean Algebras of Boolean Functions 
Let B be a Boolean algebra comprising k elements and let Fn(B) be the set 
of n-variable Boolean functions on B. Then the algebraic system 
(Fn(B), +, ',0, 1) 
is a Boolean algebra in which 
+ signifies addition of functions; 
signifies multiplication of functions; 
° signifies the zero-function; and 
1 
signifies the one-function. 
Example 2.13.1 Suppose B = {0,1}. Then Fl(B) comprises 4 functions, 
denoted by 0,1, x', and x. The corresponding truth-tables are shown below. 
x ° 
1 x' x 
° ° 
1 
1 
0 
1 ° 
1 ° 
1 
o 

48 
CHAPTER 2. BOOLEAN ALGEBRAS 
2.13.1 
Free Boolean Algebras 
The elements of Fn(B) are mappings-abstractions for which formulas in-
volving symbols Xl, X2, .•• , Xn are merely representations; the symbols them-
selves are arbitrary. In many applications, however, the symbols Xl, X2, ... ,Xn 
have concrete interpretations. The symbols may in such cases be used to con-
struct a 22n -element Boolean algebra as follows: each element of the algebra 
is the disjunction of a subset of the 2n minterms built from Xl, X2, ... , Xn. 
The null disjunction is the O-element of the Boolean algebra; the disjunc-
tion of all of the minterms is the I-element of the algebra. The resulting 
structure is called the free Boolean algebra on the n generators Xl, X2, ... , Xn 
and is denoted by F B(xt, X2, .. . , xn). It is shown by Nelson [148, p. 39] 
that F B( Xl, X2, ... ,xn ) is isomorphic to the Boolean algebra of switching 
functions of n variables. 
Example 2.13.2 The carrier of the free Boolean algebra F B(Xl, X2) is the 
16-element set of disjunctions of subsets of the set {x~x~, X~X2' XlX~, XlX2}. 
Each of these formulas is the representative of an equivalence-class of formu-
las; thus the disjunction x~ x~ + x~ X2 of minterms is equivalent, by the rules 
of Boolean algebra, to the formula x~. 0 
2.14 
Orthonormal Expansions 
A set {l/J1, l/J2, ... , l/J,,} of n-variable Boolean functions is called orthonormal 
provided the conditions 
l/J,l/Jj = 
" 
El/J, = 
,=1 
0 
1 
(i 1= j) 
(2.57) 
(2.58) 
are satisfied. A set satisfying (2.57) is called orthogonal; a set satisfying 
(2.58) is called normal. An example of an orthonormal set is the set of 
minterms on Xl, X2, ... , Xn. 
Given a Boolean function f, an orthonormal expansion of f is an expres-
sion of the form 
" 
f(X) = E a,(X)l/J,(X) , 
(2.59) 
,=1 
where at, a2, ... , a" are n-variable Boolean functions and {l/J1,"" l/J,,} is 
an orthonormal set. The expansion (2.59) is said to be with respect to the set 

2.14. ORTHONORMAL EXPANSIONS 
49 
{4>1, ... , 4>k}. The connection between that set and the coefficients a1, ... , ak 
is given by the following result. 
Proposition 2.14.1 Let {4>1,4>2," .,4>k} be an orthonormal set and let I 
be a Boolean lunction. Then I is given by the expansion (2.59) il and only 
il 
ai(X)4>i(X) = I(X)4>i(X) 
('Vi E {l, ... ,k}). 
(2.60) 
Proof. 
Suppose the expansion (2.59) to be valid. Then, for any element 
4>j of{ 4>1,4>2, ... , 4>k}, 
k 
I(X) . 4>j(X) = L ai(X)4>i{X)4>j{X) . 
i=1 
The set {4>1, 4>2, ... , 4>d satisfies the orthogonality-condition (2.57); hence 
verifying condition (2.60). Suppose on the other hand that condition (2.60) 
holds. Then 
k 
k 
L ai{X)4>i{X) 
L I{X)4>i(X) 
i=1 
i=1 
k 
I{X)· L 4>i{X) 
i=1 
= I{X), 
where we have invoked normality-condition (2.58). 0 
Using equation-solving techniques discussed in Chapter 6, it can be 
shown that the set of solutions of equation (2.60) for the coefficient ai is 
expressed by 
ai E [!. 4>i,1 + 4>il· 
An obvious (if uninteresting) solution, therefore, is ai = I. Typically, how-
ever, coefficients are arrived at directly by expansion of I, as shown in the 
following example. 
Example 2.14.1 Let a 3-variable Boolean function I{x, y, z) be expressed 
by the formula a' xy' + bx' z {the Boolean algebra B is not specified, but 

50 
CHAPTER 2. BOOLEAN ALGEBRAS 
includes the symbols a and b), and suppose we choose the orthonormal set 
{xy',xy,x'}. Then an orthonormal expansion of I is 
I(x, y, z) = a'(xy') + O(xy) + bz(x') j 
that is, 
a1 
a' 
<P1 = xy' 
a2 = 0 
<P2 = xy 
a3 = bz 
<P3 = x' . 
An expansion of the same function with respect to the orthonormal set 
{x', x} is 
I(x,y,z) = (bz)x' + (a'y')x j 
that is, 
a1 = bz 
<P1 = x' 
a2 = a'y' 
<P2 = x . 
0 
2.14.1 
Lowenheim's Expansions 
Suppose that 9 and h are Boolean functions expressed by expansions with 
respect to a common orthonormal set {<P1,"" <Pk}, i.e., 
k 
9 = Eg;<p; 
(2.61) 
;=1 
k 
h = E h;<p; . 
(2.62) 
;=1 
It was shown by Lowenheim [124] that orthonormal expansions of the func-
tions 9 + h, gh, and g' are given by 
k 
g+h = E(g; + h;)<p; 
(2.63) 
;=1 
k 
gh = E(g;h;)<p; 
(2.64) 
;=1 
k 
g' = E(gi)<p; . 
(2.65) 
;=1 

2.14. ORTHONORMAL EXPANSIONS 
51 
The foregoing expansions are useful in manipulating Boolean expressions, as 
the following example illustrates. 
Example 2.14.2 Suppose that a Boolean function 9 is expressed by the 
formula 
9 = vx' y + wxz' 
(2.66) 
and that a formula for g' is desired. A direct application of De Morgan's 
Laws yields 
g' = (v'+x+y')(w'+x'+z) 
= v'w' + v'x' + v'z + w'x + xz + w'y' + x'y' + y'z . 
(2.67) 
The complement is easier to calculate, however, and the result has simpler 
form, if (2.65) is applied. To do so, we seek a simple orthonormal set involv-
ing arguments that appear relatively frequently in the formula (2.66). Let 
us choose the set {x', x}. An orthonormal expansion of 9 with respect to 
this set is 
9 = (vy)x' + (wz')x , 
whence, applying (2.65), the complement of 9 is given by 
g' = (vy)'x' + (wz')'x 
= (v' + y')x' + (w' + z)x 
= v'x'+x'y'+w'x+xz. 
(2.68) 
Formula (2.68) has simpler form, and is obtained more easily (albeit with 
more planning), than is (2.67). 0 
Theorem 2.14.1 Let g: Bn ---+ Band h: Bn ---+ B be Boolean func-
tions expressed by expansions with respect to a common orthonormal set 
{4>1o" ., 4>k}, i.e., 
i=l 
i=l 
Let f be a two-variable Boolean function. Then f(g, h) is expressed by the 
expansion 
k 
f(g,h) = 'Ef(gi,hi)4>i. 
(2.69) 
i=l 

52 
CHAPTER 2. BOOLEAN ALGEBRAS 
Proof. We begin by applying Theorem 2.8.1 to expand I(g, h): 
I(g, h) = g'h'I(O, 0) + g'hl(O, 1) + gh'I(1, 0) + ghl(1, 1). 
We then apply the relations (2.63) through (2.65) to produce the further 
expansion 
I(g, h) = 
(Egih~<Pi)' 1(0,0) + (Egihi<Pi)' 1(0, 1) + 
i 
i 
+(E9ih~<Pi)' 1(1,0) + (Egihi<Pi)' 1(1, 1) 
i 
i 
= E [gihi!(O, 0) + gihd(O, 1) + gihi!(1, 0) + gihd(1, 1)] <Pi 
= E I(gi, hi)<Pi , 
which is the desired result. 0 
Relations (2.63) through (2.65) express three particular "functions of 
functions" as orthonormal expansions. Theorem 2.14.1 extends these rela-
tions to arbitrary two-argument functions; this extension generalizes readily 
to more than two arguments. 
Example 2.14.3 Define 1 by the formula 
1 = 9 $ h' , 
where 9 and h are given by 
9 = a'x' + bxy' + aby 
h = bxy + a' x' . 
The orthonormal set {x', xy', xy}, for example, leads to the following expan-
sions of 9 and h: 
9 = (a' + by)x' + (b)xy' + (ab)xy 
h = 
( a')x' + (O)xy' + 
(b)xy 
Thus 
1 = 
[( a' + by) $ (a')']x' + [b $ (O)']xy' + 
lab $ (b )']xy 
= [a'(1 $ 0) + a(by $1)]x' + 
[b $1]xy' + [b'(O $1) + b( a $ O)]xy 
= 
[a' + a(b' + y')]x' + 
[b']xy' + 
[b' + ba]xy 

2.15. BOOLEAN QUOTIENT 
53 
To simplify computation and avoid error, the coefficients of z' and zy have 
been been calculated by further expansion, with respect to a and h, respec-
tively. After simplification: 
I = h' + azy + a' z' + z' y' . 
The utility of orthonormal expansion for hand-computation may be gauged 
by re-doing the foregoing calculation, applying De Morgan's laws and the 
definition of Exclusive-OR directly. Orthonormal expansions are advanta-
geous also for machine-computation. 0 
2.15 
Boolean Quotient 
Let us define a letter in a Boolean formula to be a constant or a variable, 
and a liteml to be a letter or its complement. We define a term or product 
to be either 1, a single literal, or a conjunction of literals in which no letter 
appears more than once. 
Given a function I and a term t, we define the quotient 01 I with respect 
to t, denoted by I It, to be the function formed from I by imposing the 
constraint t = 1 explicitly (fIt is called a mtio by Ghazala [70)). 
Example 2.15.1 Let a Boolean function I be given by 
I(w,z,y,z) = w'zz + zy'z' + wz'z. 
The quotient of I with respect to wy' is 
o 
Ilwy' = 1(I,z,O,z) 
= zz' + z'z. 
It is clear that the function I It can be represented by a formula that does 
not involve any variable appearing in the term t. The quotient 110 does not 
exist, because 0 is not a term (the constraint 0 = 1, moreover, cannot be 
satisfied); the quotient I II, on the other hand, is simply I itself, i.e., 
I II = I , 
because the constraint 1 = 1 is a satisfied identically. Given terms s and t 
such that st 'f; 0, the quotient I I st may be calculated as follows: 
lIst = (fls)/t = (flt)ls. 

54 
CHAPTER 2. BOOLEAN ALGEBRAS 
Theorem 2.15.1 Let t}, t2,"" tk: Bn~ B be terms and suppose the set 
T = {t1' t2, ... , tk} to be orthonormal. Let f: Bn~ B be a Boolean function. 
Then f is given by the expansions 
k 
f(X) 
"LU Iti)(X) . ti(X) . 
(2.70) 
;=1 
k 
f(X) = IJ[u Iti)(X) + ti(X)] . 
(2.71) 
;=1 
Proof. 
To prove that expansion (2.70) is valid, we make use of Theo-
rem 2.10.1, the Lowenheim-Miiller verification theorem, i.e., we substitute 
values for X only on {o,l}n. Let X = A be such a substitution. There is 
exactly one member ofT, call it tj, such that tj(A) = 1 (for i '" j, ti(A) = 0). 
Thus (2.70) becomes 
f(A) = U Itj)(A) 
(tj(A) = 1) 
which is a valid identity. To verify expansion (2.71), we use the Lowenheim 
expansion (2.81) to represent f'(X), beginning with the expansion (2.70), 
yielding 
k 
f'(X) = EU Iti)'(X) . ti(X) , 
i=l 
from which (2.71) follows by De Morgan's laws. 0 
Proposition 2.15.1 Let f and 9 be n-vanable Boolean functions and let t 
be an m-variable term (m ~ n). Then 
f~g =} 
f/t~glt. 
(2.72) 
Proof. The statement f ~ 9 means that f( Xl, ••• , Xn) ~ g( X}, ••• , xn) for 
any choice of the variables x}, • •• , X n , in particular for any choice satisfying 
the constraint t = 1. 0 
Proposition 2.15.2 Let f be a Boolean function and let t be a term. Then 
f'lt = U It)'. 
(2.73) 

2.15. BOOLEAN QUOTIENT 
55 
Proof. 
(By induction on n, the number of arguments appearing in t). 
Suppose n = 1, i.e., t = x, where x is a literal. Then 
f'(x,y,· .. )lx = f'(I,y, ... ) = (f(I,y, ... )), = (fIx)', 
where f is evaluated pointwise on the range, i.e., f'( a, b, . .. ) = (f( a, b, . .. ))'. 
Suppose now that the proposition holds for n = p, and let s be a term having 
p arguments, whence the augmented term xs has p + 1 arguments. Then 
J'(x, y, .. ·)Ixs 
f'(I, y, . . . )1 s 
(f(I,y, .. ·)ls)' 
(f(x, y, .. ·)Ixs)' . 
Thus the proposition holds for n = p + 1. 0 
Proposition 2.15.3 Let I be a Boolean lunction and let t be a term. Then 
t . I = t· (fIt) 
t' + I 
t' + (fIt) . 
(2.74) 
(2.75) 
Proof. 
By Theorem 2.10.1 (the Lowenheim-Miiller verification theorem), 
identities (2.74) and (2.75) need only be verified for X E {o,l}n. For any 
such value of X, t(X) E {0,1}. Suppose t(X) = OJ then (2.74) becomes 
the identity 0 = O. Suppose on the other hand that t(X) = Ij then (2.74) 
becomes I(X) = (f It)(X), which is an identity for t(X) = 1 in view of the 
definition of (fIt). Identity (2.75) is verified by similar steps. 0 
Proposition 2.15.4 Let f be a Boolean function and let t be a term. Then 
t . I ::; I It ::; t' + I . 
(2.76) 
Proof. 
Equation (2.74) is expressed equivalently as (t· f) EB (t· lit) = 0, 
which is equivalent in turn, after expansion with respect to I It, to 
(f It)'[t . Il + (f It)[t . J'l = 0 . 
The latter equation is equivalent to the system 
(f It)'[t . Il = 0 
(f It)[t . J'l = 0, 
from which (2.76) follows directly. 0 

56 
CHAPTER 2. BOOLEAN ALGEBRAS 
Proposition 2.15.5 Let p, q, and r be terms such that pq :f: O. Then 
pq ~ r 
=> 
q ~ rip. 
Proof. Form a term q from q by deleting any literals in q that are also in 
p (if every literal in q is also a literal in p, then q = 1). Then pq = pq and 
pq ~ r => pq ~ r 
(2.77) 
=> pqr' = 0 
(2.78) 
=> q~p'+r 
(2.79) 
=> 
q~p'+(rlp) 
(2.80) 
=> q ~ rip 
(2.81) 
=> q ~ rip 
(2.82) 
We invoke Proposition 2.15.3 to produce consequent (2.80). Consequent 
(2.81) follows from (2.80) because (a) the letters in p, and thus those in p', 
are distinct from the letters in q and (b) the letters in p' are distinct from 
those in rip. Finally, (2.82) follows from (2.81) because q ~ q. 0 
Proposition 2.15.6 Let I and 9 be Boolean lunctions and let t be a term. 
Then 
9 ~ I It 
=> 
t . 9 ~ I . 
(2.83) 
Proof. We evaluate (t. g). I': 
(t·g)·I' = g. (t . I') 
= g. t· (f'lt) 
(Proposition 2.15.3) 
= g. t· (fIt)' 
(Proposition 2.15.2) 
= t . (g . (fIt)') 
If the left member of (2.83) is true then (g. (fIt)') = OJ hence (t. g) . f' = 0, 
verifying the right member of (2.83). 0 
2.16 
The Boolean Derivative 
Let I be a Boolean function and let x be an argument. We define 011 ox, the 
Boolean derivative of I with respect to x, in terms of the Boolean quotient 
as follows: 
01 
I' I 
ax = I x €a I x . 
(2.84) 

2.16. THE BOOLEAN DERIVATIVE 
57 
The concept of such a derivative was introduced by Reed [165] in a discus-
sion of error-correcting codes. Huffman [89] employed the same concept in 
connection with the solution of Boolean equations and the characterization 
of information-Iossless circuits. Akers [2] called (2.84) the Boolean differ-
ence. Inasmuch as the term "difference" has another meaning in set-theory 
and Boolean algebra, we prefer Huffman's term, "derivative." A compre-
hensive study of Boolean derivatives and their generalizations is to be found 
the monograph [46] by Davio, Deschamps, and Thayse. 
Let us briefly consider an important application of the Boolean deriva-
tive, viz., the detection of faults in logical circuits. Suppose that such a 
circuit has input-signals x, y, . .. and a single output-signal whose value is 
specified to be f(x, y, . .. ) for a given function f. Suppose further that the 
circuit has a logical fault, i.e., a condition causing the output to realize a 
function, g, which differs from f. A test for the fault is an input-vector A 
for which g(A) is different from f(A); thus a vector (x, y, ... ) is a test for 
the fault provided it is a solution of the Boolean equation 
g(x,y, ... ) = J'(x,y, ... ). 
(2.85) 
Many faults arising in practice cause the output to behave as if one of 
the input-lines, say x, is "stuck" at logical value k (either 0 or 1), so that 9 
is given by 
g(x,y, ... ) = f(k,y, ... ). 
In such a case, a test is a solution of the equation 
f(k, y, ... ) = J'(x, y, ... ) , 
which is equivalent, as we show below, to the system 
x 
of 
ox 
k' 
= 
1. 
(2.86) 
(2.87) 
(2.88) 
(2.89) 
Thus a vector (x, y, ... ) is a test for x stuck-at-k if and only if x satisfies 
(2.88) and the vector (y, ... ) satisfies (2.89). 
Example 2.16.1 Suppose that a circuit is designed to produce the function 
f = xy + z. 

58 
CHAPTER 2. BOOLEAN ALGEBRAS 
Applying (2.88) and (2.89), a vector (x, y, z) is a test for x stuck-at-k if and 
only if it is a solution of the system 
x = k' 
yz' = 1. 
Thus a test for x stuck-at-O is (1,1,0) and a test for x stuck-at-1 is (0,1,0). 
Tests for y stuck-at-k and z stuck-at-k are similarly derived. 0 
It remains to show that (2.87) is equivalent to the system (2.88), (2.89). 
We first observe that (2.87) is equivalent by Proposition 2.5.2 to the equation 
f(k, y, ... ) (fJ f'(x, y, ... ) = 0 . 
(2.90) 
Expanding the left side of (2.90) with respect to k and x yields the 
equation 
(f(O, y, . .. ) (fJ f(l, y, ... )]' + [x (fJ k'] = 0 , 
(2.91) 
which is equivalent, in view of definition (2.84), idempotence, and Proposi-
tion 2.5.2, to the system composed of (2.88) and (2.89). 
The Boolean derivative has been the foundation for research on Boolean 
calculus [11, 202, 203]. The Boolean integral [112, 194, 199], for example, 
has proven to be a useful concept. 
2.17 
Recursive Definition of Boolean Functions 
Suppose that Boolean functions 9 and h are expressed by expansions with 
respect to a common orthonormal set {<PI. . .. , <Pk}, i. e., 
k 
9 = Lgi<Pi 
i=l 
i=l 
Let It and h be Boolean functions of one and two variables, respectively. 
The expansions 
k 
It(g) = LIt(9i)<Pi 
i=l 
k 
h(g,h) = L h(gi, hi)<Pi 
i=l 

2.17. RECURSIVE DEFINITION OF BOOLEAN FUNCTIONS 
59 
follow from Theorem 2.14.1. If the orthonormal set is {x',x}, then the 
foregoing expansions take the form 
ft(g) 
== 
ft(giJx')· x' + ft(giJx)· x 
h(g,h) 
== h(giJx', hi/X') . x' + h(gi/x, hi/X) . x 
(2.92) 
(2.93) 
These expansions (and their obvious extensions to functions of 3, 4, or more 
variables) are recursive; thus they provide a convenient basis for defining 
Boolean functions and for calculating with functions of functions. 
Let us put the expansions (2.92) and (2.93) in more concrete terms. 
Suppose F to be a Boolean formula and x to be an argument explicit in 
F. Assume that the quotient-formula F/x is expressed so as not to involve 
x explicitly. A recursive definition for a one-variable Boolean function FCN 
may then be organized as follows: 
BASE-CASES: 
RECURSION: 
FCN(O) 
FCN(1) 
FCN(F) 
== 
special definition 
== 
special definition 
== 
FCN(F/x')· x' + FCN(F/x) . x 
The Boolean complement, for example, is defined recursively by the rules 
COHPLEHENT(O) 
== 
1 
COHPLEHENT(1) 
== 
0 
COHPLEHENT(F) 
COHPLEHENT(F/x') . x' + COHPLEHENT(F/x) . x 
Multi-variable functions are similarly defined. The conjunction, CONJ (F • G), 
for example, is defined by the rules 
CONJ(O.G) = 0 
CONJ(F.O) = 0 
CONJ(1.G) = G 
CONJ(F.1) = F 
CONJ(F.G) = CONJ(F/x' .G/x') . x' + CONJ(F/x.G/x) . x 
Such definitions are programmed naturally in non-procedural languages 
such as Lisp and Prolog, and have been shown by Brayton, et al., [18] to 
provide an efficient basis for procedural programming. 

60 
CHAPTER 2. BOOLEAN ALGEBRAS 
2.18 
What Good are "Big" Boolean Algebras? 
We have seen (Section 2.3) that the carrier, B, of a finite Boolean algebra 
may be any set isomorphic to the set of subsets of some finite set. We have 
also seen that an n-variable Boolean function / is defined by its discrimi-
nants, /(0, ... ,0,0),/(0, ... ,0,1), ... ,/(1, ... ,1,1). Although the discrim-
inants are found by assigning values on {O,I}n to the argument-vector of 
/, the value of a discriminant may be any element of B; these values are 
displayed equivalently by a minterm-expansion, a truth-table, or a map. 
The specialized two-valued Boolean algebra, B = {O, I}, has properties 
not shared by its larger cousins; the implication 
xy = ° ==} 
x = 0 or y = 0 , 
for example, holds only in the two-valued algebra. Thus two-valued thinking 
does not always translate safely to larger Boolean algebras. 
"Big" Boolean algebras (those whose carriers have more than two el-
ements) are needed for the reasoning-techniques discussed in subsequent 
chapters. In this section, however, we consider the utility of such algebras 
in everyday applications of Boolean methods, particularly in the design and 
analysis of switching systems. 
The two-valued assumption. The word "Boolean" is often taken in 
computer science and engineering to mean "two-valued." This interpretation 
is standard in programming languages; a typical language-manual [14, p. 
39] states that "Boolean expressions have one of two possible values: True 
or False." A term such as "propositional" or "logical" would be better 
than "Boolean"; however, the expressions defined as Boolean in a procedural 
programming language are clearly two-valued and are not manipulated as 
expressions; hence the issue is one simply of terminology. Although the 
signals in a switching system are also two-valued, the issue in the design of 
such systems involves more than terminology. 
Some writers of texts on logical design define Boolean algebras in a gen-
eral way but conclude that only the two-valued Boolean algebra is of practical 
use: 
This algebra is useful for digital switching circuits when [the carrier] 
is restricted to contain exactly two elements. [61, p. 16]. 
The two-valued Boolean algebra (called simply Boolean algebra 
further on) suffices for our purposes .... [104, p. 67]. 

2.18. WHAT GOOD ARE "BIG" BOOLEAN ALGEBRAS? 
Among all the Boolean algebras, the two-element Boolean algebra 
B2 ... , known as switching algebra, is the most useful. It is the mathe-
matical foundation of the analysis and design of switching circuits that 
make up digital systems. [121, p. 6]. 
61 
Other-typically older-texts on switching systems [33, 55, 82, 106, 109, 
136] work from the outset within an explicitly two-valued switching algebra, 
following Shannon's [183] propositional formulation of switching theory. We 
argue however that big algebras play a part in logical design that is both 
unavoidable (in a certain sense) and useful. 
Big algebras can't be avoided. The use of big Boolean algebras in 
the analysis and design of switching systems is unavoidable, even if unrec-
ognized. Consider for -example a digital circuit whose inputs are labelled x, 
y, and z and whose output, I, is related to its inputs as follows: 
1= xy + xz' + x'z . 
(2.94) 
One may view equation (2.94) as specifying the value of I in two ways. At 
any time, the values of the inputs x, y, and z are either 0 or 1; hence, when 
these values are given, the value of I is determined to be either 0 or 1. 
An alternative view is that the value of I is a member of the 256-element 
Boolean algebra of Boolean functions mapping {O, 1P into {O, I}. The latter 
view of the value of I is necessary in digital design, but is often unconscious. 
Dietmeyer [50, p. 80] notes in this connection that "many practicing logic 
designers are unaware that other Boolean algebras exist, even when they use 
them." 1 
Big algebras are useful. 
Given a Boolean algebra with carrier B, 
let us recall from Theorem 2.9.1 that a function I mapping Bn into B is 
Boolean if and only if it can be expressed in the minterm canonical form 
I(X) = L I(A)X A , 
(2.95) 
Ae{o,l}n 
where each discriminant, I(A), is an element of B. The minterm expansion 
(2.95) of I, like a truth-table or Karnaugh map, is a way to display the dis-
criminants of I. If B = {O, I}, therefore, the standard representation-forms 
IThe situation is analogous to that of M. Jourdain in Moliere's Le Bourgeois Gentil-
homme, who was astonished to discover that he had been speaking prose for more than 
forty years. 

62 
CHAPTER 2. BOOLEAN ALGEBRAS 
(expansions, truth-tables, or maps) all display Os and Is, fostering the idea 
that these are the only useful (or even possible) discriminant-values. The 
practical utility of larger Boolean algebras has nevertheless manifested itself 
in specialized bendings of the 0-1 assumption. An example is the "variable-
entered" Karnaugh map [32, 39, 93, 173, 179], whose entries are allowed to 
be other than 0 or 1. On p. 157 of his text on digital design, Fletcher 
[57] writes, "You will find that VEM [Variable-Entered Map] will be one of 
the most useful design aids discussed and its use permeates the rest of this 
text in a wide variety of applications." Such maps (and the corresponding 
minterm-expansions and truth-tables) arise naturally if switching theory is 
placed on a general Boolean footing. 
Example 2.18.1 Let us consider again the Boolean function defined by 
equation (2.94). Viewed as a three-variable function II over B = {O, I}, this 
function has the min term-expansion 
II = (O)x'y'z' + (l)x'y'z + (O)x'yz' + (l)x'yz + 
(l)xy'z' + (O)xy'z + (l)xyz' + (l)xyz. 
The corresponding eight-row truth-table is shown on the left in Figure 2.2. 
An alternative view (one of several possible) is that equation (2.94) defines a 
two-variable function fz over B = {O, 1, x', x}; this function has the minterm-
expansion 
fz = (x)y'z' + (x')y'z + (x)yz' + (l)yz. 
The four-row truth-table for fz is shown on the right in Figure 2.2. 0 
A Boolean function II (x}, ... , xm, ... , xn ) may thus be treated, for 0 ~ 
m ~ n, as a Boolean function fz(x}, ... , x m ) over the free Boolean algebra 
FB(xm+l,"" x n ). 
Example 2.18.2 An n-variable Boolean function f may be realized by a 
2n-to-1 multiplexer or data-selector [201], which acts as an electronic rotary-
switch. A minterm-expansion or truth-table for f translates directly to 
circuit-connections to the multiplexer. The 2n discriminants define signals 
connected to "data" inputs Do, D1 , ... , D 2n_l. The n arguments of f de-
fine signals connected to "select" inputs Sn-l, ... , So; the bit-pattern of the 
select-inputs defines a number, in binary code, which determines which of 
the data-inputs is transmitted to the output. Multiplexer-realizations for the 

2.18. WHAT GOOD ARE "BIG" BOOLEAN ALGEBRAS? 
63 
x y z h(x,y,z) 
° 
0 0 
0 
0 0 1 
1 
y z 
h(y, z) 
0 1 0 
0 
0 0 
x 
0 1 1 
1 
0 1 
x' 
1 0 0 
1 
1 0 
x 
1 0 1 
0 
1 1 
1 
1 1 0 
1 
1 1 1 
1 
B = {O,x',x,1} 
B = {O,1} 
Figure 2.2: Truth-tables for h and h. 
equivalent functions hand h of Example 2.18.1 are shown in Figure 2.3. 
If the cost of an inverter (to generate x') plus the cost of the 4-to-1 multi-
plexer is less than the cost ofthe 8-to-1 multiplexer, then the "big" Boolean 
algebra {O,x',x, I} results in a more economical realization than does the 
two-valued algebra. 0 
Example 2.18.3 Consider the problem of describing the behavior of a JK 
flip-flop. The inputs exciting the flip-flop are labelled J and K; the flip-flop's 
present state is labelled Q. The value of the next state, Q+ , may be expressed 
in many ways, depending on the choice of the carrier B. The left-hand truth-
table in Figure 2.2 expresses Q+ as a three-variable function over B = {O,1}; 
the right-hand truth-table expresses Q+ as a two-variable function over B = 
{O,Q',Q,1}. The four-row table based on B = {O,Q',Q, 1} expresses the 
flip-flop's behavior in a more intuitive (and obviously more compact) way 
than does the eight-row table based on B = {O, I}. 0 
Conclusion. Variable-assignments other than 0 or 1 (e.g., those to the 
data-inputs of a multiplexer) are carried out routinely by logical designers. 
What is sometimes missing is a unified Boolean foundation for such assign-
ments. That foundation is provided by Huntington's postulates and the 
recognition that (a) the discriminants of a Boolean function may be taken 
from an arbitrary Boolean algebra, and (b) truth-tables, minterm-expansions 
and maps serve as equivalent displays of those discriminants. 

64 
CHAPTER 2. BOOLEAN ALGEBRAS 
0 
DO 
1 
D1 
0 
D2 
z 
DO 
1 
D3 
z' 
D1 
1 
D4 
h(z,y,z) 
h(y,z) 
z 
D2 
0 
D5 
1 
D6 
1 
D3 
1 
D7 
Sl SO 
S2 Sl SO 
y z 
z 
y z 
Figure 2.3: Two multiplexer-realizations of f = XY + xz' + x' z. 
J 
K 
Q Q+(J,K,Q) 
0 
0 
0 
0 
0 
0 
1 
1 
J K 
Q+(J,K) 
0 
1 
0 
0 
0 
0 
Q 
0 
1 
1 
0 
0 
1 
0 
1 
0 
0 
1 
1 
0 
1 
1 
0 
1 
1 
1 
1 
Q' 
1 
1 
0 
1 
1 
1 
1 
0 
B = {O,Q',Q,l} 
B = {O,l} 
Figure 2.4: Truth-tables for the JK flip-flop. 

EXERCISES 
65 
Exercises 
1. The relation ~ in a Boolean algebra is defined by 
iff 
ab' = 0. 
Prove that the following properties hold for all a, b, e: 
(a) 
ab~a~a+e 
(b) 
a=b 
{:::::> 
a ~ band b ~ a 
(c) 
a~b 
{:::::> 
ae ~ be (Ve E B) 
(d) 
a~O 
{:::::> a=O 
(e) 
l~a 
{:::::> a=1 
(I) 
a~b 
{ 
ae 
~ be 
} 
==> 
a+e < b+e 
(g) g 
< ; i 
a ~ be 
~ 
==> 
(h) 
~ 
==> 
a+b~e 
~ 
2. Prove or disprove each of the following, assuming that a, b, and care 
elements of a Boolean algebra. 
(a) 
a+b=a+e 
==> b=e 
(b) 
ab=ac 
==> b=e 
( c) {a +a! : 
:e+ e} ==> 
b = e 
3. Given B = {O, 1, a', a}, let I be a 2-variable Boolean function for which 
1(0,0) = ° 
1(0,1) 
1 
1(1,0) = a' 
1(1,1) = a. 
Find f(a,I). 

66 
CHAPTER 2. BOOLEAN ALGEBRAS 
4. Let B = {O, l,a',a}. Which ofthe functions f, g, h specified below is 
a Boolean function? 
x 
f(x) g(x) hex) 
° 
a 
a' 
a' 
1 
a 
1 
1 
a 
a' 
1 
a' 
a' 
a' 
a' 
1 
5. Given the 256-element free Boolean algebra B = FB(a,b,c), let f: 
B3--+B be a Boolean function for which 
f(O,O,O) = f(O,O,I) = a 
f(O, 1,0) = a+b 
f(O,I,I) = f(I,O,I) = f(I,I,I) 
f(I,O,O) = a + c' 
f(l, 1,0) = b+ c' 
(a) Display f by means of a truth-table. 
(b) Write the minterm canonical form for f. 
(c) Write a simplified formula for f. 
= 1 
(d) Determine f(a',c,b) in as simple a form as you can. 
6. Let B = {O,I,a',a}. Find a relation between f(O) and f(l) that is 
necessary and sufficient for the condition f(J( x)) = f( x) to hold on 
a Boolean function f: Bn--+ B. Make use of the relation to find all 
Boolean functions satisfying the given condition. Express each such 
function by a simplified Boolean formula. 
7. (McColl [135, 1877-80], cited in Rudeanu [172, Chapter 1]) Show that 
a function f: Bn--+ B is Boolean if and only if 
8. Given that f is a Boolean function of one variable, prove the following: 
(a) f(x + y) + f(xy) = f(x) + fey) 
(b) f(J(O)) = f(O)· f(l) ::; f(x) ::; f(O) + f(l) = f(J(I)) 
(c) If x ::; y, then f(J(x)) ::; f(J(y)). 

EXERCISES 
67 
9. (Poretsky [158], Couturat [41]) Prove the equivalence 
a ::; x ::; b 
<===:> 
x = ax' + bx 
10. (a) Prove or disprove: for any Boolean function f of one variable, if 
x::; y, then f(x) ::; fey). 
(b) If the assertion (a) is not true for all Boolean functions, give a 
precise characterization of the Boolean functions for which it is 
true. 
11. (a) How many n-variable functions f: Bn __ B (Boolean or not) are 
there if the set B has k elements? 
(b) How many of them are Boolean functions? 
(c) How many 3-variable functions are there on B = {O, 1, a', a}? 
(d) What fraction of them are Boolean? 
12. Let f: Bn -- B be an n-variable Boolean function, and let a be an 
element ofB. Define an (n-I)-variable function g: Bn-l __ B by the 
prescription 
g(X2, ... ,Xn ) = f(a,x2, ... ,Xn ). 
Show that 9 is a Boolean function. 
13. Let f, g, and h be Boolean functions expressed as 
where the fi, gi, and hi are Boolean functions and {4>1. 4>2, ... , 4>k} is 
an orthonormal set of Boolean functions. Let us consider the expanded 
functions 
f = 
a'(x'y') + b(x'Y) + 
O(x) 
9 = (a + b)(x'y') + I(x'y) + ab'(x) 
h = 
ab'(x'y') + a(x'Y) + 
b'(x) 
for which the orthonormal set is {x'y',x'y,x}. Suppose that a is a 
3-variable Boolean function whose arguments are f, g, and h. Then 
an orthonormal expansion for a is given as follows in terms of the 
corresponding expansions for f, g, and h: 
k 
aU, g, h) = L aUi, gi, hi) . 4>i . 
i=1 

68 
CHAPTER 2. BOOLEAN ALGEBRAS 
Use this expansion-form to calculate the following functions: 
(a) I' 
(b) 1+ g' 
(c) al+gh. 
14. Use Boole's expansion theorem to prove the following: 
(a) 
(b) 
(c) 
(d) 
ul(u,v,w) 
u'/(u,v,w) 
u + I(u,v,w) 
u' + I(u,v,w) 
= 
= = 
= 
ul(l,v,w) 
u'/(O, v, w) 
u + I(O,v,w) 
u'+/(I,v,w). 
15. If (B, +",0,1) is a Boolean algebra and a and b are distinct elements 
of B such that a :::; b, then the system 
([a,b],+,·,a,b) 
is a Boolean algebra. Denote by x* the complement of an element x 
in this Boolean algebra. Show that 
x* = a + bx' 
where x' is calculated in B. 
16. Given 
I 
A' C' D' + A' B' E + A' D' E' + ABC'D' + AC D + B' D E 
9 
A'BCE + AC'D + A'C'D' + BC'DE' + ABC'E' 
(a) Expand I and 9 with respect to Band D, simplifying the dis-
criminants. 
(b) Use the expanded forms to calculate 
. I' 
1. 
ii. 1+ g' 
iii. fg 
iv. feg 

EXERCISES 
17. Let B be the set {O, l,a',a} and let 
f:B-+B 
be Boolean functions. Given 
f(O) = a 
f(l) = a' 
g(x, y) = f(x + y) + (J(xy))' , 
express 9 by a simplified Boolean formula in terms of a, x, and y. 
69 
18. For any Boolean algebra B, the Boolean functions f: B -+ B in a 
certain set satisfy the identity 
f(J(x)) = (J(x»' 
for all elements x E B. Describe this set of functions in simple terms. 
Explain your method clearly. 
19. Let B = {O, 1, a', a}. List the Boolean functions f: B -+ B that satisfy 
both of the conditions 
(a) f(J(x)) = f(x) 
(b) f(O) = a'. 
("Ix E B) 
Express each such function by a simplified Boolean formula. Em-
ploy systematic reasoning rather than exhaustive trials. Explain your 
method clearly. 
20. Let B be the set {O, l,a',a}. How many Boolean functions f: B2-+B 
are there that satisfy the condition 
xy $ f(x, y) $ x' + y 
for all (x, y) E B2? Do not determine the functions explicitly. 
21. Given the set B = {O, l,a',a}, how many two-variable functions f: 
B2-+ B are there? How many of these are Boolean functions? 
22. Let 9 and h be single-variable Boolean functions. For each of the 
following cases, express f(O) and f(l) as simplified formulas involving 
g(O), g(I), h(O), and h(I). 
(a) f(x) = g(h(x» 
(b) f(x) = g(g'(x» 

Chapter 3 
The Blake Canonical Form 
Boole's object in inventing an "algebra of logic" [12, 13] was to reduce the 
processes of reasoning to those of calculation. He showed that a system of 
logical equations, unlike a system of ordinary equations, can be reduced to a 
single equivalent equation (we consider the reduction-process in Chapter 4). 
He chose the standard reduced form 1 = 0, where 1 is a Boolean function. 
Reasoning is carried out in Boole's formulation by solving that equation for 
certain of its arguments in terms of others. 
In spite of the efforts of a number of nineteenth-century logicians to 
extend and generalize Boole's algebra, it proved incapable of representing 
ordinary discourse. Modern symbolic logic is therefore based on a differ-
ent system, the predicate calculus, which grew out of the work of Frege [60]. 
Boole's approach is specialized, moreover, even within the domain of Boolean 
problems. His system of reasoning, i.e., equation-solving, does not produce 
logical consequents of 1 = OJ instead, it produces specialized logical an-
tecedents. Boolean equation-solving, which we discuss in Chapter 6, never-
theless has many useful applications, 
The first general treatment of both antecedent and consequent Boolean 
reasoning was that of Poretsky [159] in 1898. Poretsky's system was based 
on exhaustive tables of antecedents and consequents. The growth of these 
tables with the number of variables is so rapid, however, as to make them 
useless for applications. 
A more practical approach to Boolean reasoning was developed by Blake 
[10] in 1937. Blake showed that all of the consequents of 1 = 0, i.e., all 
Boolean equations 9 = 0 such that the implication 
1=0 
=? 9=0 
71 

72 
CHAPTER 3. THE BLAKE CANONICAL FORM 
holds, can easily be generated if f is expressed in a certain canonical form. 
This form turns out to be the disjunction of all of the prime implicants of 
f. The term"prime implicant," as well as the theory of systematic formula-
minimization in terms of prime implicants, comes from a series of papers by 
V. W. Quine [161, 162, 163, 164] published between 1952 and 1959. Quine 
demonstrated that a simplified sum-of-products (SOP) formula for f is nec-
essarily a disjunction of prime implicants of f. He also presented methods for 
generating all of the prime implicants of f and gave a tabular procedure for 
selecting a subset of the prime implicants whose disjunction is a simplified 
SOP formula for f. 
While Quine's objective was Boolean minimization, i.e., the discovery 
of simplified formulas representing a given Boolean function f, Blake's ob-
jective was Boolean inference, i.e., the extraction of conclusions from a col-
lection of Boolean data. The theory of prime implicants has thus arisen 
independently for two quite different applications. 
The approach to Boolean inference developed in this book is grounded in 
Blake's theory of syllogistic formulas. We outline that theory in Appendix 
A, which is adapted from Chapter II of Blake's dissertation. We discuss rea-
soning based on syllogistic formulas in Chapter 5; our object in this chapter 
is to define Blake's canonical form (a specialized syllogistic formula) and to 
describe several methods for its construction. 
3.1 
Definitions and Terminology 
The concept of a Boolean formula on the symbols Xl, X2, ••• ,Xn was defined 
in Section 2.6, principally as a stepping-stone to the concept of a Boolean 
function on the same symbols. Our investigation now focuses on Boolean 
formulas; hence further definitions are required. 
A Boolean function f: Bn __ B may be expressed by a variety of formu-
las. These are built up from letters, i.e., constants at, a2, . •• , ak (elements of 
B) and variables Xl, X2, ••• ,Xn , together with the notations of complemen-
tation, conjunction, and disjunction. A literal is a letter or its complement. 
A term or product is either 1, a single literal, or a conjunction of literals 
in which no letter appears more than once; an alterm is either 0, a single 
literal, or a disjunction of literals in which no letter appears more than once. 
A sum-of-products (SOP) formula is either 0, a single term, or a disjunction 
of terms; a product of sums (POS) formula is either 1, a single alterm, or a 
conjunction of alterms. 

3.2. SYLLOGISTIC & BLAKE CANONICAL FORMULAS 
73 
We assume in this chapter, unless stated otherwise, that Boolean func-
tions are expressed by SOP formulas. A Boolean function will be denoted 
by a lower-case letter (e.g., f) and an SOP formula expressing that func-
tion by the corresponding upper-case letter (F). Terms, viewed either as 
formulas or functions, will be represented by the lower-case letters p, q, r, . ... 
Given an m-term SOP formula F and an n-term SOP formula G, F + G is 
an (m + n)-term formula containing all of the terms of F together with all 
those of G. 
Two SOP formulas will be called equivalent (=) in case they represent the 
same Boolean function, i.e., in case one can be transformed into the other, 
in a finite number of steps, by application of the rules of Boolean algebra. 
Following Blake, we call two SOP formulas congruent (,g,) in case one can be 
transformed into the other using only the commutative rule. Thus congruent 
SOP formulas may differ only in the order of enumeration of their terms and 
in the order of the literals in any term. 
Given two Boolean functions g and h, we say that g is included in h, 
written g :s; h , in case the identity gh' = 0 is satisfied. When applied to 
formulas (e.g., G:S; H), the relation :s; is inherited from the functions those 
formulas represent. 
An implicant of a Boolean function f is a term p such that p :s; f . Any 
term of an SOP formula for f is clearly an implicant of f. A prime implicant 
of f is an implicant of f that ceases to be so if any of its literals is removed. 
It is shown in Appendix A that an implicant p of f is a prime implicant of 
f in case, for any term q, 
p:S;q:S;f => p=q. 
An SOP formula F will be called absorptive in case no term in F is 
absorbed by any other term in F. If F is not absorptive, then an equivalent 
absorptive formula, which we call ABS(F), may be obtained from F by 
successive deletion of terms absorbed by other terms in F. It is shown in 
Appendix A that, for any SOP formula F, the formula ABS(F) is unique 
to within congruence. 
3.2 
Syllogistic & Blake Canonical Formulas 
Let F and G be SOP formulas. We say that G is formally included in F, 
written G ~ F, in case each term of G is included in some term of F. We 
write G <j;:. F if G is not formally included in F. Formal inclusion clearly 

74 
CHAPTER 3. THE BLAKE CANONICAL FORM 
implies inclusion, i.e., G <: F ===? G ~ F for any F, G pair. The converse 
does not hold, however, as the following example illustrates. 
Example 3.2.1 Let SOP formulas Fh G, and H be defined as follows: 
FI = wy' + w'z + w'x'y + wx'yz' 
G = w'y' z + w'x'y 
H 
= xy'z + x'yz' . 
(3.1) 
(3.2) 
(3.3) 
The relations G ~ FI and H ~ FI hold for the foregoing formulas. Each 
term of G is included in a term of FI ; hence G <: Fl. Such is not the case, 
however, for H, i.e., H -t. Fl. 
A Formula F will be called syllogistic in case, for every SOP formula G, 
G~F===?G<:F. 
Thus F is syllogistic if and only if every implicant of F is included in some 
term of F. 
Example 3.2.2 The formula 
F2 = wy' + w'z + w'x'y + x'yz' + y'z + wx'z' 
(3.4) 
is a syllogistic formula equivalent to the formula FI in Example 3.2.1 (we 
discuss the construction of such formulas in the remainder of this chapter). 
Every SOP formula included in F2 (or, equivalently, included in FI) is there-
fore formally included in F2 • In particular, as the reader should verify, the 
formulas G and H in Example 3.2.1 are formally included in F2 • 
Given SOP formulas F and G, we define F X G to be the SOP formula 
produced by multiplying out the conjunction FG, using the distributive laws. 
If F = Ei Si and G = Ej tj, then 
F X G = E Z::Si . tj , 
. i 
j 
where repeated literals are dropped in each product Si ·tj of terms, Si·1 = Si, 
and 1· tj = 1. A product is dropped if it contains a complementary pair of 
literals. Thus, for exam!lle, 
(x'y + xz) X (wx + y + z) = x'y + x'yz + wxz + xyz + xz . 

3.3. GENERATION OF BCF(F) 
75 
Let a be any letter. Two terms will be said to have an opposition in 
case one term contains the literal a and the other the literal a'. (If the 
symbol x stands for the literal a', then we shall understand x' to stand for 
a.) The terms x'yz and wy'z, for example, have a single opposition, in the 
letter y. Suppose two terms r and s have exactly one opposition. Then 
the consensus [161] of rand s, which we shall denote by c(r, s), is the term 
obtained from the conjunction rs by deleting the two opposed literals as 
well as any repeated literals. Thus c(x'yz, wy'z) = wx'z. The consensus 
c( r, s) does not exist if the number of oppositions between r and s is other 
than one. The consensus of two terms was called their "syllogistic result" 
by Blake. 
Let F be a syllogistic formula for a Boolean function I. We call the for-
mula ABS(F) the Blake canonicallorm for I, and we denote it by BCF(J). 
Blake showed that BC F(J) is minimal within the class of syllogistic formu-
las for I, i.e., the set of terms in any syllogistic formula for I is a superset 
of the set of terms in BCF(J). 
The following results are proved in Appendix A: 
1. If formulas F I , F2, ... ,Fk are syllogistic, then the formula FI X F2 X 
••• X Fk is also syllogistic. 
2. If an SOP formula F is not syllogistic, it contains terms p and q, having 
exactly one opposition, such that c(p, q) is not formally included in F. 
3. Let F be an SOP formula for a Boolean function f. Then F is syllogistic 
if and only if every prime implicant of I is a term of F. 
4. BCF(J) is the disjunction of all of the prime implicants of I. 
3.3 
Generation of Be F(f) 
Quine's minimization theory [161, 162, 163, 164] has stimulated a large body 
of research concerning the efficient generation of BC F(J). We outline in this 
section the principal approaches; for more details see the survey by Reusch 
and Detering [167]. 
BCF(J) is defined to be ABS(F), where F is a syllogistic formula for I; 
therefore BC F(J) may be generated by the following two-step procedure: 
Step 1. 
Step 2. 
Find a syllogistic formula for f. 
Delete absorbed terms. 

76 
CHAPTER 3. THE BLAKE CANONICAL FORM 
Blake discussed three approaches for carrying out Step 1; we categorize 
these as exhaustion 0/ implicants, iterated consensus, and multiplication. 
Each of the techniques in the extensive literature on the generation of prime 
implicants appears to belong to one of these categories. 
3.4 
Exhaustion of Implicants 
An obviously syllogistic formula for / is the disjunction of all of the impli-
cants of / (i.e., all terms t such that t 5 f). This disjunction was called the 
"complete canonical form" by Blake. A number of special-purpose logical 
computers have been designed to perform Step 1 of the foregoing two-step 
procedure by generating the complete canonical form. These machines em-
ploy an n-digit ternary counter, each digit of which corresponds to a letter. 
The three values of a digit correspond to the ways in which a letter may ap-
pear in a term: uncomplemented, complemented, or not at all. The machines 
designed by Svoboda [191, 192] (USA) and Florine [58, 59] (Belgium) gener-
ate all possible terms on the given letters; the machine of Gomez-Gonzalez 
[73] (Spain) stops generating terms when certain conditions are met. Step 
2 (absorption) is typically incorporated by such machines into the process 
of generating, testing, and storing terms as follows: the one-letter terms are 
generated first, then the two-letter terms, and so on. A given term is stored 
if and only if it is an implicant of / and is not an implicant of a term already 
stored. 
Although the foregoing method is simple in conception and readily pro-
grammed (or implemented in hardware) for low values of n, the number of 
candidate-terms that must be stored, and the time required for the requisite 
scanning, rises exponentially with n. The number of terms on n letters is 
3n -
1; for 20 letters, this number is about 3.5 billion. Also, many terms 
are likely to be annihilated in Step 2 of the two-step procedure discussed 
above. Much effort, beginning in the mid-1950s, has therefore been devoted 
to finding more efficient ways to generate prime implicants. Two basic ap-
proaches, iterated consensus and multiplying (both given in 1937 by Blake), 
have emerged from this work. We discuss these approaches in the next two 
sections. 

3.5. ITERATED CONSENSUS 
77 
3.5 
Iterated Consensus 
Theorem A.2.3 guarantees that any SOP formula is transformed into a syl-
logistic formula by repeated application of the following rule: 
If the formula contains a pair r, s of terms whose consen-
sus c(r,s) exists and is not included in any term of the 
formula, then adjoin c( r, s) to the formula. 
This method, usually called "iterated consensus," was presented in Blake's 
dissertation. It was re-discovered by Samson and Mills [174], by Quine [163] 
and by Bing [8, 9]. To apply it, we begin with an SOP formula F. At each 
application of the rule cited above, we determine, for a pair r, s of terms in 
F, whether c(r,s) exists, i.e., whether rand s are opposed in exactly one 
variable. If so, and if c(r,s) is not included in any term in F, we modify F 
by adjoining to it the term c( r, s). We persevere in this process until every 
term-pair (involving adjoined terms as well as those originally in F) has been 
considered. F is then syllogistic. 
The process of iterated consensus terminates in a finite number of steps, 
because 
• if a pair r, s of terms meets the specified condition at a given step, it 
cannot meet that condition at any subsequent step, and 
• the number of pairs of terms to be considered is finite, inasmuch as 
no more than 3n terms can be produced from n letters. (NB: Some 
writers put this number at 3n - 1, excluding 1 as a term.) 
We say that a consensus is applicable to the formula from which it is 
derived if the consensus is not included in any term of that formula. 
Example 3.5.1 Let us find BCF(J) for the function f expressed by the 
formula 
F = w'x'yz + xy'z + wy'z' + xyz' + wx'z' . 
(3.5) 
An organized way to consider all pairs of terms is to compare each term with 
all those that precede it, adjoining applicable consensus-terms to the end of 
the formula. To help with bookkeeping, each term should be marked after 
it has been compared with all preceding terms. The process ends when the 
consensus of the last term with each of its predecessors either does not exist 

78 
CHAPTER 3. THE BLAKE CANONICAL FORM 
or is not applicable. The first few stages in the evolution of F, using the 
foregoing scheme, are shown below: 
F 
= w'x'yz + xy'z + wy'z' + xyz' + wx'z' 
F = w'x'yz + xy'z + wy'z' + xyz' + wx'z' + wxy' 
F = w'x'yz + xy'z + wy'z' + xyz' + wx'z' + wxy' + wxz' . 
The final formula is 
F = w'x'yz + xy'z + wy'z' + xyz' + wx'z' + wxy' + wxz' + wyz' + wz' . 
F is now in syllogistic form; hence, 
BCF(J) = ABS(F) = w'x'yz + xy'z + xyz' + wxy' + wz'. 
(3.6) 
It follows from Lemma A.2.1 that the set of formulas formally included 
in an SOP formula F is not changed by removal from F of absorbed terms. 
Thus the work of iterated consensus may be simplified at any stage by dele-
tion of absorbed terms as they are noticed. It is not necessary in hand-
calculation to be systematic; absorptions missed while generating consensus-
terms may be carried out in a final absorption-step. 
A variety of iterated-consensus procedures have been investigated, based 
on specializations of 
• the initial SOP formula or 
• the interleaving of consensus-generation and absorption. 
We now describe two of the more important of such procedures, viz., Quine's 
method and successive extraction. 
3.5.1 
Quine's method 
A procedure given by Quine [161] is a specialization of iterated consensus 
in which stages of consensus-generation alternate in a fixed way with stages 
of absorption. Let us consider again the function given in Example 3.5.1. 
Quine's method is conveniently explained by organizing the work as shown 
in Table 3.1. The minterms of j, each containing n literals, are written in 
column 1. The consensus-terms derived from column 1 (containing n - 1 
literals each) are written in column 2, after which the terms in column 1 

3.5. ITERATED CONSENSUS 
79 
absorbed by terms in column 2 are checked, indicating deletion. This process 
is carried out repeatedly, column 3 being derived from column 2, column 4 
from column 3, and so on. Each column generates the succeeding column by 
consensus and may suffer absorption of some of its terms by the succeeding 
column. The terms surviving unchecked (i.e., unabsorbed) are the terms of 
BCF(f). 
wx'y'z' .j 
w'x'yz 
wx'z' .j 
w'xy'z .j wy'z' .j 
w'xyz' .j 
wx'yz' .j 
wxy'z' .j 
wxy'z 
.j xy'z 
wz' 
wxyz' 
.j wxy' 
xyz' 
wyz' .j 
wxz' .j 
Table 3.1: Organization of work for Quine's method. 
The operations in each pass are on terms of fixed length and all operations 
(consensus and absorption) derive from the single rule x'p+xp = p, where x 
is a single letter and p is a term. Thus the work involves simple operations 
organized in convenient stages. Quine's method is made simpler by grouping 
the minterms in column 1, as shown in Table 3.1, according to the number of 
their complemented literals. The consensus-operation is then possible only 
between terms in vertically adjacent groups; this property is inherited by all 
subsequent columns, as shown in Table 3.1. Further simplification results 
from introducing binary [134] or octal [6] notation. 
The computational advantages of Quine's method are offset by the ne-
cessity to begin with a listing of the minterms of j, and by the need therefore 
to process a large number of terms. 

80 
CHAPTER 3. THE BLAKE CANONICAL FORM 
3.5.2 
Successive extraction 
Blake [10] observed that iterated consensus can be carried out letter by let-
ter. This method is called "successive extraction" in the Reusch & Detering 
survey [167] and is commonly credited to Tison [204, 205]. Suppose an SOP 
formula involves the letters a, b, c, . ... To generate an equivalent syllogistic 
formula by successive extraction, one first adjoins to the formula all applica-
ble consensuses arising from pairs of terms opposed in the letter a, i.e., from 
pairs of the form a'p and aq, where p and q are terms not involving a. Using 
the resulting formula as a basis, one then adjoins all applicable consensuses 
arising from terms opposed in the letter b. This process is repeated until all 
letters are exhausted. 
The method of successive extraction typically generates fewer consensus-
terms than does the general method of iterated consensus; however successive 
extraction (unlike the general method) may require that a given pair of terms 
be compared more than once. 
3.6 
Multiplication 
Step 1 of Blake's procedure for generating Be F(J) is to find a syllogistic 
formula for f. The following procedure is guaranteed by Theorem A.2.1 to 
produce such a formula: 
Express f as a conjunction of syllogistic formulas and 
then multiply out to obtain an SOP formula, using the 
distributive laws and dropping duplicate literals. 
An alterm (disjunction of literals) is clearly syllogistic; hence a syllogistic 
formula may be produced by multiplying out a conjunction of alterms, i.e., a 
POS formula. Blake states that the latter method was known to C.S. Peirce 
[152] and his students. That technique is now frequently attributed to Nelson 
[147]; Blake's more general technique of multiplying out a conjunction of 
syllogistic formulas was re-discovered (specialized to a conjunction of Blake 
canonical forms) by Samson and Mills [174] and by House and Rado [88]. 
Example 3.6.1 Let us find the prime implicants of the Boolean function f 
expressed by 
f = a'd + abc' + ac'd' . 
(3.7) 
To apply the method of multiplying, we must first convert formula (3.7) to 
a conjunction of syllogistic formulas. Let us adopt the specialized tactic of 

3.6. MULTIPLICATION 
converting (3.7) to a POS formula: 
f 
= 
[a' + bc' + c'd'][a + d] 
f 
= 
[a' + c'][a' + c + b + d'][a + d] . 
81 
(3.8) 
(3.9) 
The foregoing conversion is carried out by repeated application of Corollary 
2.8.1 (the dual form of Boole's expansion theorem). Specifically, formula 
(3.8) results from expanding (3.7) with respect to the argument a, i.e., 
f( a, b, c, d) = [a' + f(l, b, c, d)][a + f(O, b, c, d)] , 
(3.10) 
while formula (3.9) is derived by expanding the first factor of (3.8) with 
respect to the argument c. Multiplying out (3.9) produces the syllogistic 
formula 
F = a'd + a'cd + a'bd + a'c'd + abc' + bc'd + ac'd' . 
(3.11) 
The terms in (3.11) surviving absorption are the prime implicants of fj thus 
BCF(f) = ABS(F) = a'd + abc' + bc'd + ac'd' . 
(3.12) 
The same result can be obtained by multiplying out (3.8) rather than (3.9), 
because (as we now show) each of the two factors of (3.8) is syllogistic. By 
Theorem A.2.3, an SOP formula that is not syllogistic must contain a pair 
p, q of terms, having exactly one opposition, such that the consensus c(p, q) is 
not formally included in the formula. Neither of the factors of (3.8) contains 
such a pair of termsj hence, each factor is syllogistic. 
3.6.1 
Recursive multiplication 
A Blake canonical form is syllogistic. Hence, it follows from Theorem A.2.1 
that multiplying out a conjunction of Blake canonical forms produces a syl-
logistic formula. If absorption is then carried out, the result is a Blake 
canonical form. Thus BCF(f) may be generated recursively. 
Theorem 3.6.1 Let f be a Boolean function and let x be one of its argu-
ments. Then the Blake canonical form of f is given by 
BCF(f) = ABS«x' + BCF(f/x» X (x + BCF(f/x'») , 
(3.13) 
where X (cf. Section A.2) denotes the term-by-term product of SOP formu-
las. 

82 
CHAPTER 3. THE BLAKE CANONICAL FORM 
Proof. 
The set {x',x} is orthonormalj hence, by Theorem 2.15.1, 
f = (x' + fix)· (x + fix'). Thus, 
BCF(J) = ABS(BCF(x' + fix) X BCF(x + fix')). 
(3.14) 
The non-vacuous arguments of fix are disjoint from Xj therefore 
BCF(x' + fix) = BCF(x') + BCF(Jlx) = x' + BCF(Jlx) j 
similarly, 
BCF(x + fix') = x + BCF(J Ix') . 
Equation (3.13) thus follows from (3.14). 0 
Assuming that F is an SOP formula, BCF(F) is produced by the fol-
lowing recursive procedure: 
Rule 1. If the term 1 appears in F, then BCF(F) = 1. 
Rule 2. If F = 0 or F has a single term, then BCF(F) = F. 
Rule 3. Otherwise, 
BCF(F) = ABS( (x' + BCF(Flx)) X (x + BCF(Flx')) ) 
where x is an argument explicit in F and FIx is expressed by a formula 
not involving x. 
The efficiency of the foregoing procedure may be improved by restrict-
ing the scope of the operator ABS. Applying the distributive laws, equa-
tion (3.13) may be expressed equivalently as 
BCF(F) = ABS(G + H) 
(3.15) 
where 
G = (x' X BCF(Flx')) + (x X BCF(Flx)) 
(3.16) 
H = BCF(Flx) X BCF(Flx') . 
(3.17) 
It is not possible for any term in G to absorb any other term in Gj nor can 
any term in G absorb a term in H. Thus the following absorptions suffice 
in (3.15): 

3.6. MULTIPLICATION 
83 
• 
absorptions within H j and 
• 
absorptions of G-terms by H-terms. 
Let us define a relative-absorption operator, ABSREL, on two SOP 
formulas P and Q, as follows: 
ABSREL(P, Q) 
= 
the formula constructed from P 
by removing all terms 
absorbed by terms of Q. 
Then BCF(F) is expressed recursively by 
BCF(F) = ABS(H) + ABSREL(G, ABS(H)) , 
where G and H are defined by (3.16) and (3.17). 
(3.18) 
A variation of the foregoing development replaces term-by-term mul-
tiplication by Boolean multiplication of arbitrary form. Define SOP for-
mula I to be the Blake canonical form of H as defined above. Then I = 
BCF(BCF(F/x) X BCF(F/x')), whence I may be expressed by 
1= BCF((F/x) * (F/x')) , 
(3.19) 
where * refers to the product of Boolean functions, the form being irrelevant. 
Equation (3.18) then takes the simplified form 
BCF(F) = 1+ ABSREL(G,I). 
(3.20) 
3.6.2 
Combining multiplication and iterated consensus 
We consider in this section a variant of recursive multiplication that is useful 
for hand-computation. It is based on the observation that BCF(F) may be 
computed rapidly by hand if the number of terms in F is relatively small. 
Beginning with an SOP formula F, 
Rule 1. If F is a relatively simple formula, calculate BCF(F) using 
iterated consensus. 
Rule 2. Otherwise, 
BCF(F) = ABS( (x' + BCF(F/x)) X (x + BCF(F/x')) ) , 
where x is an argument appearing with relatively high frequency in F 
and F/x is expressed by a formula not involving x. 

84 
CHAPTER 3. THE BLAKE CANONICAL FORM 
The foregoing procedure is a guide to calculation rather than an algo-
rithm, because Rule 1 requires a decision based on simplicity, a property 
difficult to quantify. For hand-calculation, however, we have found this pro-
cedure to be markedly faster and less conducive to error than any other 
method, especially when applied to functions yielding large numbers of prime 
implicants. An analysis of the efficiency of this method in comparison with 
other methods is given in [25]. 
Example 3.6.2 Let us apply the foregoing procedure to calculate the Blake 
canonical form of the formula 
F = a'e'd' + abd'e' + b'ee + b'e'd'e + abe'd + 
+b' e' de' + a'bed + aed' e' + be' de . 
(3.21) 
We decide that it is not convenient to calculate BCF(F) using Rule 1, and 
we note that no argument appears in more terms than does ej hence we 
calculate BC F( F) using Rule 2: 
BCF(F) = ABS( (e' + BCF(F/e)) X (e + BCF(F/e')) ) 
(3.22) 
where 
F/e = abd'e' + b'e + a'bd + ad'e' 
F/e' = a'd' + abd'e' + b'd'e + abd + b'de' + bde . 
We decide that the formula F/e is simple enough for application of Rule 1, 
yielding 
BCF(F/e) = b'e + a'bd + ad'e' + a'de + ab'd' . 
We now decide that it is not convenient to calculate BCF(F/e') using Rule 
1, and (noting that the variable d appears with maximal frequency in F/e') 
we apply Rule 2, i.e., 
BCF(F/e') = ABS( (d' + BCF«F/e')d)) X (d + BCF«F/e')d')) ) , 
where 
(F/e')/d = F/c'd = ab + b'e' + be 
(F/e')/d' = F/c'd' = a' + abe' + b'e . 
These formulas are relatively simple, hence, we calculate their Blake canon-
ical forms using Rule 1, with the following results: 
BCF(F/e'd) = ab + b'e' + be + ae' 
BCF(F/e'd') = a' + b'e + be' 

3.6. MULTIPLICATION 
Thus BCF(F/e') is given by the formula 
ABS«d' + ab + b'e' + be + ae') X (d + a' + b'e + be'» 
which yields 
BCF(F/e') = a'd' + b'd'e + bd'e' + abd + abe' + 
+b'de' + a'b'e' + bde + a'be + ade' . 
We now continue the computation (3.22): 
BCF(F) = ABS«e' + b'e + a'bd + ad'e' + a'de + ab'd') X 
(e + a'd' + b'd'e + bd'e' + abd + abe' + 
+b'de' + a'b'e' + bde + a'be + ade'» . 
The result, 
BCF(J) = b'd'e + abe'd + b'e'de' + be'de + ae'de' + a'e'd' + 
+a'b'e'e' + a'be'e + be'd'e' + abe'e' + b'ee + 
+a'bed + a'bde + aed'e' + abd'e' + a'ede + ab'ed' , 
85 
requires 31 "intelligent" multiplications and 3 deletions. By intelligent multi-
plications, we mean those that make use of the identities (p+q)(p+r) = p+qr 
and (ps + q)(p + r) = ps + pq + qr to minimize subsequent absorptions. The 
more commonly-used multiplying technique, on the other hand, begins with 
a transformation of (3.21) to POS form, a simple example of which is 
f = (a+b+e'+e)(b+e+d'+e')(a'+b+e+d+e) 
(a' + e' + d' + e)( a' + b' + d + e')( a + b' + e + d' + e) 
(a + b' + e' + d)( a' + b' + e' + e') . 
Performing the x-operation and absorption on this form (once again assum-
ing intelligent multiplications) requires 117 multiplications and 44 deletions. 
3.6.3 
Unwanted syllogistic formulas 
The fact that multiplying out a POS formula produces a syllogistic result 
may sometimes be disadvantageous. Suppose that our object is to obtain 
an SOP representation (not necessarily syllogistic) of the complement of f. 
If we apply De Morgan's laws to an SOP formula for f, we obtain a POS 

86 
CHAPTER 3. THE BLAKE CANONICAL FORM 
formula for I', which we may then multiply out to produce an SOP formula 
for I'. Multiplying out a POS formula for I', however, produces a syllogistic 
result, which may be a more complex formula than one wishes. Let us recall 
Example 2.14.2. The complement of the formula 1= vx'y + wxz', obtained 
by De Morgan's laws, was shown in that example to be 
I' = v'w' + v'x' + v'z + w'x + xz + w'y' + x'y' + y'z . 
This formula is in fact BCF(j'), inasmuch as it is the result of multiplying 
out a POS formula and there are no terms in the formula that are absorbed 
by other terms. The simpler formula I' = v'x' + x'y' + w'x + xz is obtained 
by expansion-techniques discussed in Section 2.14. 
Exercises 
1. Express in Blake canonical form: 
be'de + ab'c'd + aede + a'b'ee + ab'ed' + b'ede'+ 
+a'bde' + ae'de' + bed'e' + abee' 
2. Express in Blake canonical form: 
AE' F' + DEF + BDE' + A' B' E' F' + BCD' F+ 
+BDEF' + B'D'EF+ BD'E'F' 
3. Express in Blake canonical form: 
A' BD + AB' D' E + BCD' E + ABD E' + A' E' F + 
+ AD E + A' BD' E' + A' B' E' F' 

Chapter 4 
Boolean Analysis 
In this chapter we consider methods for analyzing systems of Boolean equa-
tions. These methods are of central importance in Boolean reasoning. We 
first consider ways in which systems of Boolean equations may be related. In 
particular, we define consequents, antecedents, equivalents, and solutions of 
Boolean systems. We also discuss several processes useful for Boolean rea-
soning. Among such processes are the reduction of a system of equations to 
a single equivalent equation, the elimination of a variable from an equation, 
the detection of redundant variables in an interval, and the substitution of 
an expression for a variable in a Boolean formula. 
A problem that arises in diverse applications is to decide whether a given 
SOP formula is equivalent to the I-formula. We consider how such a decision 
may be made, and apply the results to the problem of finding a near-minimal 
SOP formula for a given Boolean function. 
4.1 
Review of Elementary Properties 
We repeat for convenient reference some equivalences developed in Chap-
ter 2. For elements a, b, c in a Boolean algebra, 
a~b <==> ab' = 0 
(4.1) 
a~b~e <==> ab' + be' = 0 
(4.2) 
a=b <==> aE]1b=O 
(4.3) 
a = 0 and b = 0 <==> a+b=O 
(4.4) 
a = 1 and b = 1 <==> 
ab = 1 
(4.5) 
87 

88 
CHAPTER 4. BOOLEAN ANALYSIS 
Equivalences (4.4) and (4.5) extend readily to more than three variables; 
thus 
a = 0 and b = 0 and c = 0 
$=} a + b + c = 0 
is an obvious generalization of (4.4). 
Boole's expansion theorem (Theorem 2.8.1), together with property (4.2), 
establishes 
Proposition 4.1.1 (Schroder [17S}) The statements 
I(x,y, ... ) = 0 
and 
1(0, y, ... ) ~ x ~ 1'(1, y, .. . ) 
are equivalent. 
4.2 
Boolean Systems 
An n-variable Boolean system on a Boolean algebra B is a collection 
(4.6) 
of simultaneously-asserted equations. The Pi and qi are n-variable Boolean 
functions on B; X denotes the vector (Xl, X2,"', x n ). We have defined a 
Boolean system to consist entirely of equations; inclusions are readily trans-
formed into equations, however, via the equivalence (4.1). 
Given any substitution A E Bn for X, a truth-value is assigned to a 
Boolean system S(X) as follows: S(A) is true in case each of its component 
equations is an identity; otherwise S(A) is false. A Boolean system, and thus 
a Boolean equation, is therefore a predicate (c/. the discussion in Section 
1.2). 

4.3. REDUCTION 
89 
4.2.1 
Antecedent, Consequent, and Equivalent Systems 
Let Sl(X) and S2(X) be two n-variable Boolean systems on B. We say 
that Sl(X) is an antecedent of S2(X), written Sl(X) ==? S2(X), in case 
every substitution for X that ca.uses Sl(X) to be true also causes S2(X) 
to be true; we say in this case also that S2(X) is a consequent of Sl(X), 
Two Boolean systems Sl(X) and S2(X) are said to be equivalent, written 
Sl(X) ~ 
S2(X), if each is a consequent of the other. 
4.2.2 
Solutions 
A system having the specialized form 
(4.7) 
where bI, b2,···, bn are elements of B, is called a solution of a system S(X) 
provided (4.7) implies (i.e., is an antecedent of) S(X). Thus (4.7) is a 
solution of S(X) in case the substitutions defined by (4.7) cause each ofthe 
equa.tions in S(X) to become an identity; it is sometimes convenient to refer 
to the vector (bI, b2, •• " bn ) itself as a solution. A Boolean system is said 
to be consistent if it has at least one solution; otherwise, it is said to be 
inconsistent. Methods for constructing solutions are discussed in Chapter 7. 
4.3 
Reduction 
Unlike a system of equations in "ordinary" algebra, a Boolean system may 
be reduced to a single equivalent equation. 
Theorem 4.3.1 (Boole [13], Chapter VIII) The Boolean system (4.6) 
is equivalent to the single equation 
f(X) = 0, 
(4.8) 
where f is defined by 
k 
f = L(Pi EB qi) . 
(4.9) 
i=l 

90 
CHAPTER 4. BOOLEAN ANALYSIS 
Proof. System 4.8 is equivalent, by property (4.3), to the system 
which is in turn equivalent, by property (4.4), to the single equation (4.8), 
where f is the Boolean function defined by (4.9). 0 
By similar reasoning, invoking (4.5) instead of (4.4), we arrive at 
Corollary 4.3.1 The system (4.6) is equivalent to the single equation 
F(X) = 1, 
where F is a Boolean function defined by 
k 
F = II (Pi $ qi)'. 
i=l 
(4.10) 
(4.11) 
Any Boolean system can therefore be reduced to a single equivalent equa-
tion whose right-hand side is either zero or one. More generally, as shown in 
Theorem 4.5.1 (Poretsky's Law of Forms), the right-hand side may be any 
preassigned Boolean function. 
Example 4.3.1 The system 
is equivalent to the system 
ax = b+ y 
ab < ax' + y' 
ab'xy' + a'b + a'y + bx' + x'y 
0 
ab(a'y + xy) = 0 
which is equivalent, in turn, to the single equation 
ab'xy' + a'b + a'y + bx' + x'y + abxy = O. 
o 

4.4. THE EXTENDED VERIFICATION THEOREM 
91 
Example 4.3.2 Suppose an AND-gate to have inputs Xl and X2 and output 
Zl' The behavior of the gate is described by any of the three equivalent 
statements below. 
o 
4.4 
The Extended Verification Theorem 
( 4.12) 
(4.13) 
(4.14) 
We discuss in this section a result, due to Lowenheim [124] and Muller 
[142], which enables an implication between two Boolean equations to be 
transformed into an equivalent Boolean inclusion. The presentation in this 
section is adapted from that of Rudeanu [172]. 
Let s be a single element of B and let V = (VI, V2,' .. , vn ) be a vector on 
B, i.e., s E B and V E Bn. Then sV and Vs are defined by 
sV = Vs = (SVt.SV2,···,svn). 
Lemma 4.4.1 Let f: Bn __ B be a Boolean function and let A be an element 
ofBn such that f(A) = O. Then 
f(Af(X) + X f'(X)) = 0 
Proof. By Boole's expansion theorem (Theorem 2.8.1), 
f(G(u)) = u'· f(G(O)) + u· f(G(1)) j 
thus, setting G(u) = Au + Xu' and u = f(X), 
f(Af(X) + X f'(X» = f'(X)f(X) + f(X)f(A) . 
(4.15) 
Each term on the right-hand side of the foregoing equation has the value 
zero, for any X E Bn, verifying (4.15). 0 
Theorem 4.4.1 (Extended Verification Theorem) Let f: Bn -- B 
and g: Bn __ B be Boolean functions, and assume equation f(X) = 0 
to be consistent. Then the following statements are equivalent: 
(a) 
(b) 
(c) 
f(X) = 0 ==> g(X) = 0 
g(X)::;: f(X) 
g(X)::;: f(X) 
(VX E Bn) 
(VX E Bn) 
(VX E {O, 1}n) . 

92 
CHAPTER 4. BOOLEAN ANALYSIS 
Proof. 
(a) ~ 
(b): Let A E Bn be a solution of f(X) = 0, i.e., let f(A) = 0 
be an identity. Then g(A) = 0 because of the assumed implication. By 
Lemma 4.4.1, the equation f(X f'(X) + Af(X)) = 0 is satisfied for any 
X E Bnj hence g(Xf'(X) + Af(X)) = 0 is also satisfied. Thus 
J'(X)g(X) + f(X)g(A) = f'(X)g(X) = 0, 
i.e., g(X) ~ f(X), proving (b). 
(b) ~ 
(c): Immediate. 
( c) ~ 
(a): The functions f and 9 are Boolean; hence they may be 
written in minterm canonical form, i.e., 
f(X) = L 
f(K)X K and g(X) = L 
g(K)XK 
KE{O,l}" 
KE{O,l}" 
for all X E Bn. Assume (c), i.e., assume g(K) ~ f(K) for all K E {0,1}n, 
and let A E Bn be a solution of f(X) = o. Then 
f(X) = L 
f(K)AK = 0, 
KE{O,l}" 
which implies that J(K)AK = 0 for all K E {0,1}n, and therefore that 
g(K)AK = ° for all K E {0,1}n. Thus g(A) = 0, proving (a). 0 
Corollary 4.4.1 Let f: Bn __ Band g: Bn -- B be Boolean functions, 
and assume the equation f(X) = 0 to be consistent. Then the following 
statements are equivalent: 
(a) 
(b) 
(c) 
f(X) = 0 {:::::} g(X) = 0 
g(X) = f(X) 
g(X) = f(X) 
(\IX E Bn) 
(\IX E Bn) 
(\IX E {O, 1}n). 
Proof. Immediate from Theorem 4.4.1 and the definition of equivalent 
systems. 0 
4.5 
Poretsky's Law of Forms 
Theorem 4.3.1 and its corollary enable us to reduce a Boolean system to one 
of the equivalent forms f(X) = 0 or F(X) = 1. Suppose, however, that we 

4.6. BOOLEAN CONSTRAINTS 
93 
wish the right-hand side to be something other than ° 
or 1. Poretsky [159] 
showed that once a Boolean system has been reduced to the form f(X) = 0, 
it may be re-expressed equivalently in the form g(X) = heX), where his 
any specified Boolean function. The function 9 associated with a given h is 
determined uniquely by the following theorem. 
Theorem 4.5.1 (Poretsky's Law of Forms) Let f,g,h: Bn --+ B be 
Boolean functions and suppose the equation f(X) = ° 
to be consistent. Then 
the equivalence 
f(X) = 0 
g(X) = heX) 
(4.16) 
holds for all X E Bn if and only if 
g=f(JJh. 
(4.17) 
Proof. Equivalence (4.16) may be written in the form 
f(X) = ° 
g(X) (JJ heX) = ° , 
which is equivalent by Corollary 4.4.1 to (4.17). 0 
Example 4.5.1 Suppose a Boolean function, g, is sought having the prop-
erty that the equation XIX~ + X3 = ° 
is equivalent to 9 = X2X3. The first 
equation is consistent (a solution, for example, is (XbX2,X3) = (0,0,0»; 
hence, 9 is determined uniquely by (4.17), i.e., 
o 
9 = 
(XIX~ + X3) (JJ (X2 X3) 
= 
X~(XI + X3). 
4.6 
Boolean Constraints 
Given a Boolean algebra B, a constraint on a vector X = (x}, X2,· •• , xn) 
is a statement confining X to lie within a subset of Bn. A constraint is 
therefore a predicate that is true provided X is a member of the subset. The 
operation of the AND-gate of Example 4.3.2, for instance is specified by the 
constraint 
(x}, X2, zt} E {(O, 0,0), (0, 1,0), (1, 0, 0), (1,1, In, 
(4.18) 

94 
CHAPTER 4. BOOLEAN ANALYSIS 
where B = {a, I} and X = (x}, X2, zt). 
Two constraint-statements on the vector X are equivalent if they are 
equivalent as predicate!!, i.e., if they confine X to the same subset of Bn. 
Thus statement (4.18) is equivalent to equation (4.12), as well as to equations 
(4.13) and (4.14). 
An identity on X = (Xl! X2,"', xn) is a constraint equivalent to the 
statement 
XEBn. 
An identity, in other words, is a constraint that doesn't really do any con-
straining. The constraints x + y = x + x'y and x'y ~ y, for example, are 
both identities on (x, y). 
A constraint on X = (Xl, X2, ... , Xn) will be called a Boolean constraint 
if it is equivalent to a Boolean equation, i.e., if it can be expressed by the 
equation 
f(X) = 0, 
(4.19) 
where f: Bn __ B is a Boolean function. IfB = {a, I}, then every constraint 
on X is Boolean; if B is larger than {a, I}, however, then not all constraints 
on X are Boolean. 
Example 4.6.1 Suppose that B = {a, l,a',a}. Then the constraint 
(X,y) E {(O,O),(a,O)} 
(4.20) 
is Boolean because it is equivalent to the Boolean equation 
a'x + y = 0, 
( 4.21) 
i.e., the set of solutions of (4.21) is {(O,O),(a,O)} for B = {O,I,a',a}. 0 
Example 4.6.2 Suppose again that B = {O,I,a',a}. The constraint 
(X,y) E {(O,O), (a, I)} , 
( 4.22) 
is not a Boolean constraint, i.e., it is not equivalent to a Boolean equation. 
To show this, let us assume that there is a two-variable Boolean function f 
whose solution-set is {( 0, 0), (a, I)}. Then 
x = ° 
and y = ° ==> f = ° 
x = a and y = 1 ==> f = ° , 

4.7. ELIMINATION 
i.e., 
x+y=O ==> 1=0 
ax' + a' x + y' = 0 ==> 1 = 0 . 
95 
By Theorem 4.4.1, the extended verification theorem, the latter implications 
are equivalent to the inclusions 
1 ~ x + y 
1 < ax' + a' x + y' . 
These inclusions are equivalent together to the single inclusion 
1 ~ g, 
where the Boolean function g is defined by 
9 = (x+y).(ax'+a'x+y') 
= a' x + xy' + ax' y . 
( 4.23) 
Invoking the extended verification theorem again shows that the inclusion 
(4.23) is equivalent to the implication 
g(x, y) = 0 ==> I(x, y) = 0 
thus every solution of g(x, y) = 0 is also a solution of I(x, y) = o. Try-
ing all values for (x, y) in B2 shows that the solution-set of g(x, y) = 0 is 
{(O,O),(O,a'),(a,a),(a,1)}. Thus the solution-set of I(x,y) = 0 must con-
tain these four elements, contradicting the assumption that its solution-set 
is {(O,O),(a,1)}. Hence (x,y) E {(O,O),(a,O)} is not a Boolean constraint. 
o 
4.7 
Elimination 
A fundamental process in Boolean reasoning is that of elimination. To 
eliminate a variable x from a Boolean equation means to derive another 
Boolean equation that expresses all that can be deduced from the original 
equation without reference to x. The central fact concerning elimination was 
announced by Boole [13, Chapt. VII, Proposition I] as follows: 

96 
CHAPTER 4. BOOLEAN ANALYSIS 
If f( x) = 0 be any logical equation involving the class symbol 
x, with or without other class symbols, then will the equation 
f(1)f(0) = 0 
be true, independently of the interpretation of Xj and it will 
be the complete result of the elimination of x from the above 
equation. 
In other words, the elimination of x from any given equation, 
f( x) = 0, will be effected by successively changing in that equa-
tion x into 1, and x into 0, and multiplying the two resulting 
equations together. 
Similarly, the complete result of the elimination of any class 
symbol, x, y, &c., from any equation of the form V = 0, will 
be obtained by completely expanding the first member of that 
equation in constituents of the given symbols, and multiplying 
together all the coefficients of those constituents, and equating 
the product to o. 
Let X = (Xt,X2, ... ,Xm), let Y = (Yl,Y2, ... ,Yn), and let f: Bm+n--+B 
be a Boolean function. Following Boole, we define the resultant of elimina-
tion of X from the equation f(X, Y) = 0 to be the equation 
II f(A,Y) = O. 
(4.24) 
AE{o,l}m 
It follows that the resultant of elimination of X from F(X, Y) = 1 is the 
equation 
E F(A,Y) = 1. 
( 4.25) 
AE{O,l}m 
To demonstrate that the resultant of elimination is Boole's "complete re-
sult," we must show that an equation heY) = 0 is a consequent of f(X, Y) = 
o if and only if it is a consequent of the resultant (4.24). 
Theorem 4.7.1 Let X = (Xt,X2, ... ,Xm) and Y = (Yt.Y2, ... ,Yn) be dis-
joint argument-vectors, and let f: Bm+n --+ a be a Boolean function. For 
any Boolean function h: Bn--+ B, the implications 
f(X,Y) =0 
II f(A,Y) = 0 
AE{O,l}m 
are equivalent. 
heY) = 0 
heY) = 0 
(4.26) 
(4.27) 

4.7. ELIMINATION 
97 
Proof. If equation !(X, Y) = 0 is inconsistent, then (4.26) and (4.27) are 
both true because their premises are false. Otherwise a repeated application 
of the Verification Theorem and its variants yields successively the following 
equivalent forms of (4.26): 
h(Y) 
~ 
h(Y) 
~ 
h(Y) 
~ 
!(X,Y) 
!(A,Y) 
TIAE{o,l}m!(A, Y) 
The latter inclusion is equivalent to (4.27). 0 
VXeB'" 
VA e {O, I}'" 
Example 4.7.1 The AND-gate of Example 4.3.2 is characterized by either 
of the equations !(XItX2,ZI) = 0 or F(XI,X2,ZI) = 1, the functions! and 
F being defined by 
(4.28) 
(4.29) 
Let us eliminate X2. Applying the definitions (4.24) and (4.25), the resultant 
of elimination of X2 is expressed by either of the equations g( XIt Zl) = 0 or 
G(XI,Zt} = 1, where 
9 = !(XI, 0, Zl)' !(Xl. 1, Zl) = (X~ZI + ZI)(X~ZI + xlzD 
= X~ZI 
G = F(xIt 0, Zl) + F(Xb 1, Zl) = (x~z~ + zD + (x~z~ + XIZI) 
= Xl + z~. 
All that is known concerning the AND-gate's input Xl and output Zl, in the 
absence of knowledge concerning its input X2, is therefore expressed by any 
of the following equivalent statements: 
X~ZI = 0 
Xl + z~ = 1 
Zl 
~ Xl 
(Xl,ZI) e {(O, 0), (1, 0), (1,1)} . 
If we eliminate the output-argument Zl from (4.13), the resultant is 

98 
CHAPTER 4. BOOLEAN ANALYSIS 
i.e., 
0= O. 
The latter constraint allows (z}, Z2) to be chosen freely on {O, 1p-confirming 
our expectation that the inputs to a gate are unconstrained if nothing is 
known concerning the value of the output. 0 
C.1. Lewis [123, p. 155] has observed that "For purposes of application 
of the algebra to ordinary reasoning, elimination is a process more impor-
tant than solution, since most processes of reasoning take place. through the 
elimination of 'middle' terms." Boole [13, p. 99] writes of such terms that it 
"usually happens in common reasoning, and especially when we have more 
than one premiss, that some of the elements [in the premiss] are not required 
to appear in the conclusion. Such elements, or, as they are commonly called, 
"middle terms," may be considered as introduced into the original proposi-
tions only for the sake ofthat connexion which they assist to establish among 
the other elements, which are alone designed to enter into the expression of 
the conclusion." 
The following example illustrates the process of reasoning by elimination 
of such middle terms. 
Example 4.7.2 Let us connect the output, Zt, of the AND-gate of Example 
4.7.1 to the input of an OR-gate whose second input is labelled Z3 and whose 
output is labelled Z2. The complete circuit is thus defined by the system 
Zt = 
Zt Z2 
Z2 
= 
Z3 + Zt • 
( 4.30) 
The relationship between the circuit's overall output, Z2, and its inputs, Zb 
Z2, and Z3 is expressed only implicitly by the foregoing equations. We deduce 
an explicit relationship by eliminating the "middle term," Zt. To do so, we 
first reduce the system (4.30) to a single equation, viz., I(z}, Z2, Z3, Zt, Z2) = 
0, the Boolean function 1 being given by 
The resultant of elimination of Zt from 1 = 0 is the equation 
(4.31) 

4.7. ELIMINATION 
where 9 is given by (4.24) as follows: 
9 = 
= 
= 
!(XbX2,X3,0,Z2)· !(Xl,X2,X3, 1,Z2) 
(XIX2 + X3Z~ + X~Z2)· (X~ + X~ + X3Z~ + Z~) 
X3Z~ + XIX2Z~ + X~ X~Z2 + X~X~Z2 • 
99 
Proposition 4.1.1 enables us to express equation (4.31) equivalently in a form 
which isolates Z2: 
Thus 
i.e., 
Z2 = X3 + XIX2 • 
Suppose now that we wish to express what the system (4.30) tells us about 
the value of X3, if we know only the values of X2 and Z2. To do so, we eliminate 
Xl and Zl from !(XbX2,X3,ZbZ2) = 0 or, equivalently, we eliminate Xl from 
9(Xb X2, X3, Z2) = O. The resultant of the latter elimination is 
i.e., 
X3Z~ + X~X~Z2 = 0 , 
which is equivalent to the interval 
This interval tells us the following about X3: 
1. If X2 = 0 and Z2 = 1, then X3 = 1. 
2. If Z2 = 0, then X3 = O. 
A point of difference between Boolean and other algebras with reference 
to elimination should be noted. As usual, Boole [13, p. 99] states the matter 
best: "In the [common] algebraic system we are able to eliminate one symbol 
from two equations, two symbols from three equations, and generally n - 1 
symbols from n equations. There thus exists a definite connexion between 

100 
CHAPTER 4. BOOLEAN ANALYSIS 
the number of independent equations given and the number of symbols of 
quantity which it is possible to eliminate from them. But it is otherwise with 
the system of Logic. No fixed connexion there prevails between the number 
of equations given representing propositions or premises, and the number 
of typical symbols of which the elimination can be effected. From a single 
equation an indefinite number of such symbols may be eliminated." 
4.8 
Eliminants 
As shown in Section 4.7, the resultant of elimination of variable Xl from 
equation l(xI, X2, ••• ) = ° 
is equation 1(0, X2, •• .)-1(1, X2, ••• ) = 0; similarly, 
the resultant of elimination of Xl from l(xI, X2, ••• ) = 1 is 1(0, X2, ••• ) + 
1(1, X2, ••• ) = 1. 
We call functions 1(0, X2, • •• )·/(1, X2, • •• ) and 1(0, X2, ••• ) + 1(1, X2, ••• ), 
and their generalizations to more than one eliminated variable, eliminants; 
they are of central importance in Boolean reasoning. An eliminant (a func-
tion) is often needed in situations where the corresponding resultant of elim-
ination (an equation) is not needed; therefore it will prove useful to define 
eliminants in a way that is independent of the process of elimination. A com-
puter program performing tasks of Boolean reasoning will spend much of its 
time computing eliminants; these functions therefore deserve close study. 
Let I: Bn----+ B be a Boolean function expressed in terms of arguments 
XI. X2, ••• , Xn , and let R, S, and T be subsets of {Xl, X2, ••• , x n }. We define 
a Boolean function ECON(f, T) by the following rules: 
(i) 
ECON(f, 0) 
(ii) 
ECON(f, {Xl}) 
(iii) ECON(f,RUS) 
=1 
= 1(0, X2, ••• , Xn) • 1(1, X2, • •• , Xn) 
= ECON(ECON(f,R),S) 
We define another Boolean function, ED/S(f, T), by the rules 
(i) 
ED/S(f, O) 
(ii) 
ED/S(f, {xIl) 
(iii) EDIS(f,RUS) 
=1 
= 1(0, X2, ••• , xn) + 1(1, X2, ••• , xn) 
= EDIS(EDIS(f,R),S) 
We call ECON(f, T) the conjunctive eliminant, and ED/S(f, T) the 
disjunctive eliminant, of 1 with respect to the subset T. We note that if T 
is a singleton, i. e., if T = {x}, then the eliminants of 1 are related to the 

4.8. ELIMINANTS 
quotients 1 lx' and 1 Ix (Section 2.15) as follows: 
ECON(f,{x}) = flx'·flx 
EDIS(f,{x}) = flx'+llx 
101 
(4.32) 
(4.33) 
Theorem 4.8.1 Let I: Bn -- B be a Boolean lunction and let T be an 
m-element subset of its argument-set, X = {Xl, X2, ... , xn}. We assume 
without loss of generality that T comprises the first m elements 01 X, i.e., 
that T = {Xl, ... , xm}. Then ECON(f, T) and EDIS(f, T) are determined 
as lollows: 
ECON(f,T) = II I(A,xm+h""Xn) 
(4.34) 
AE{O,I}m 
EDIS(f,T) = E I(A,xm+h' .. ,xn). 
(4.35) 
AE{O,I}m 
Proof. 
Equation (4.34) is verified for the case m = 1 by the definition 
of the conjunctive eliminant. Suppose (4.34) to hold for m = k > 1, and 
consider the case m = k + 1: 
ECON(f(XI,'" ,Xk, Xk+1, Xk+2,"" xn), {Xl>" .,Xk,Xk+1}) 
ECON(ECON(f, {Xl,"" Xk}), {Xk+l}) 
= ECON( II/(A,Xk+1,Xk+2, ... ,xn),{Xk+I}) 
AE{O,I}lc 
= II I(A, 0, Xk+2,' .. , Xn) . II I(A, 1, XkH,' .. , xn) 
AE{O,I}lc 
AE{O,I}l' 
= 
II I(A,xk+2,""Xn) 
AE{O,I}lc+l 
Equation (4.34) thus holds for m = k + 1, completing the verification of 
(4.34). Equation (4.35) is verified by dual computations. 0 
Example 4.8.1 
o 
ECON(f(w,x,y,z),{w,y}) = 
I(O;x,O,z)'/(O,x,l,z)'/(l,x,O,z)'/(l,x,l,z) 
EDIS(f(w,x,y,z),{w,y}) = 
1(0, x, 0, z) + 1(0, x, 1, z) + 1(1, x, 0, z) + 1(1, x, 1, z). 

102 
CHAPTER 4. BOOLEAN ANALYSIS 
Corollary 4.8.1 Let X = (X},X2,""Xm ) andY = (Y1,Y2, ... ,Yn) be dis-
joint argument-vectors, and let f: Bm+n_ B be a Boolean function. Then 
the resultant of elimination of X from f(X, Y) = 0 is 
EGON(j,X) = O. 
The resultant of elimination of X from f(X, Y) = 1 is 
EDIS(j,X) = 1. 
( 4.36) 
(4.37) 
Calculation of Eliminants. It is clear that either the conjunctive or 
the disjunctive eliminant of a Boolean function f with respect to a subset T 
may be expressed by a formula not involving any ofthe arguments appearing 
in T. The calculation of such formulas is simplified by application of the 
results which follow. 
Proposition 4.8.1 (Schroder [178], Vol. I, Sect. 21). If a Boolean 
function f is expressed as 
f(x, y, ... ) = x'p(y, ... ) + xq(y, ... ) + r(y, ... ) 
then the conjunctive eliminant EGO N (j, {x}) is given by 
EGON(j, {x}) = pq + r. 
Proof. EGON(j, {x}) = f(O, y, ... )f(1, y, ... ) = [p + r][q + r] = pq + r . 
Lemma 4.8.1 Let f: Bn_ B be a Boolean function expressed in terms of 
arguments x, y, ... . Then 
BG F( EGO N (j, {x} » = E (terms of BG F(j) not involving x or x') . 
Proof. The literals x and x' may be factored from the terms of BG F(j) in 
such a way that f is expressed as 
L 
M 
N 
f = Ex'p; + Exq; + Er;, 
;=1 
;=1 
k=1 
where P1, ... , PL, q17 ... , qM, , r17 ••• , rN are terms (products) not involving 
the argument x. Thus EGON(j,{x}) = f(0,y, ... )f(1,y, ... ) may be ex-
pressed as 
L 
N 
M 
N 
LM 
N 
[Ep; + E rk] [Eq; + Erk] = EEp;qj + Erk. 
;=1 
k=1 
;=1 
k=1 
;=1 ;=1 
k=1 

4.8. ELIMINANTS 
103 
Every consensus formed by terms of BC F(J) is absorbed by a term of 
BCF(J). In particular, every consensus of the form Piqj is absorbed by 
one of the T-terms; thus 
L 
M 
LLPiqj 
i=l j=l 
and we conclude that ECON(J,{x}) = Ef'=l Tk. Thus ECON(J, {x}) may 
be expressed as the portion of BCF(J) that remains after each of its terms 
that involves x or x' is deleted; let us call this portion G. It remains only 
to show that G is in Blake canonical form. Suppose not. It is clear that G 
is absorptive, since it is a fragment of a Blake canonical form; hence it must 
not be syllogistic. By Theorem A.2.3, therefore, there must be terms sand t 
in G such that the consensus c(s, t) exists and is not formally included in G. 
Thus c(s,t), which does not contain x or x', is included in one of the terms 
dropped from BCF(J) in the formation of G. But each such term contains 
either x or x', which is a contradiction. 0 
Theorem 4.8.2 Let f: Bn~ B be a Boolean function expressed in terms 
of arguments x, y, ... and let T be a subset of {x, y, .. . }. Then 
BC F( ECO N (J, T)) = L terms of BCF(fJ not involving 
arguments in T J . 
(4.38) 
Proof. By Lemma 4.8.1, (4.38) is valid if #T = 1, i.e., if T is a singleton-
set. Suppose (4.38) to be valid if #T = k, and consider the case #T = k+ 1, 
i.e., let T = R u {x}, where #R = k and x rt R. Then 
BCF(ECON(J, T)) 
BCF(ECON(ECON(J, R), {x})) 
L (terms of BCF(ECON(J, R)) 
not involving x or x') 
L(terms of 
[ E (terms of BC F(J) not 
] 
involving arguments in R) 
not involving x or x') 
Thus (4.38) is valid for T = R u {x}. 0 

104 
CHAPTER 4. BOOLEAN ANALYSIS 
Conjunctive eliminants of a Boolean function are therefore found by sim-
ple term-deletions, provided the function is expressed in Blake canonical 
form. The resulting eliminants inherit the property of being in Blake canon-
ical form. 
Example 4.8.2 The Boolean function 
f = wx'y + v'w'x' + xz + XV' + vx'y' 
is expressed as follows in Blake canonical form: 
BCF(f) = vy' + w'y' + XV' + xz + wx'y + wyz + v'yz + 
+ v'x'y + v'w'x' + v'w'z + vwz + vwx' . 
The conjunctive eliminants expressed below may therefore be constructed 
by inspection of BC F(f), using Theorem 4.8.2. 
o 
BCF(ECON(f, {v})) 
BCF(ECON(f, {v,z})) 
BCF(ECON(f, {x, y})) 
BCF(ECON(f, {x, y, z})) = o. 
w'y' + XV' + xz + wx'y + wyz 
= w'y' + XV' + wx'y 
= v'w'z + vwz 
Theorem 4.8.3 Let f: Bn---+ B be a Boolean function expressed in terms 
of the arguments x, y, ... . Then EDIS(f, {x}) is obtained from any sum-
of-products (SOP) formula for f by replacing x and x', wherever they appear 
in the formula, by 1. 
Proof. As in Proposition 4.8.1, the terms in an SOP formula for f may be 
segregated into those containing x', those containing x, and those containing 
neither x' nor x. The literals x' and x may then be factored from the terms 
in which they appear, to produce an expression of the form 
f(x, y, ... ) = x' P(y, ... ) + xQ(y, ... ) + R(y, ... ) , 
where P, Q, and R are SOP formulas (some possibly null) not involving x. 
Hence 
f(O, y, ... ) = P(y, . .. ) + R(y, . .. ) 
and 
f(l, y, ... ) = Q(y, .. . ) + R(y, . .. ) . 

4.8. ELIMINANTS 
105 
By definition, 
EDIS(J(x, y, .. . ), {x}) = 1(0, y, ... ) + 1(1, y, ... ) ; 
hence 
EDIS(J(x,y, .. . ), {x}) = P(y, ... ) + Q(y, ... ) + R(y, ... }. 
Thus EDIS(J(x,y, ... ),{x}) is produced by replacing the literals x' and x 
by 1 in the original SOP formula. 0 
We refer to the foregoing procedure, apparently first given by Mitchell 
[138], as the "replace-by-one trick." 
Example 4.8.3 Let 1 be given, as in Example 4.8.2, by the formula 
1 = wx'y + v'w'x' + xz + xy' + vx'y' . 
Then 
EDIS(J,{v}) 
= wx'y + w'x' + xz + xy' + x'y' 
= x'+y'+z 
EDIS(J, {w}) 
= x'y + v' x' + xz + xy' + vx'y' 
= x' + y' + z 
EDIS(J,{w,x}) = EDIS(EDIS(J, {w}), {x}) 
= l+y'+z=1. 
o 
Example 4.8.4 We use the following (correct) calculations to illustrate po-
tential pitfalls in applying the replace-by-l trick: 
(a) 
EDIS(u'+vw,{u}) = 1+vw= 1 
(b) 
EDIS«u+ v)', {u}) = EDIS(u'v',{u}) = v' 
(c) 
EDIS«u+v)(u'+w),{u}) = EDIS(uw+u'v+vw,{u}) 
= w+v. 
Calculation (a) illustrates that EDIS(J,{u}) is not found simply by delet-
ing u' and u (which would produce vw rather than 1 in this case), but by 
replacing both u' and u by 1. Calculations (b) and (c) illustrate the need to 
express 1 in sum-of-products form before the literals u' and u are replaced 
by 1. If the replacements are made in the original formulas, the resulting 
erroneous calculations are: 
(b') 
EDIS«u+v)',{u}) = (1+v)'=0 
(c') 
EDIS«u+v)(u'+w),{u}) = (1+v)(1+w)=1. 
o 

106 
CHAPTER 4. BOOLEAN ANALYSIS 
It is apparent from Theorems 4.8.2 and 4.8.3, and from the accompa-
nying examples, that ECON(f, T) tends to be "smaller" than f and that 
EDIS(f, T) tends to be "bigger" than f. We formalize this observation as 
follows: 
Theorem 4.8.4 Let f: B"-- B be a Boolean function expressed in terms 
of arguments x, y, ... and let T be a subset of {x, y, .. . }. Then 
ECON(f,T) ~ f ~ EDIS(f,T). 
Proof. By Theorem 4.8.1, ECON(f,T) may be expressed by a formula 
comprising only terms of BCF(f). Expressed in such form, ECON(f,T) 
is formally included (Sect. A.2) in BCF(f)i thus ECON(f,T) ~ f. To 
prove that f ~ EDIS(f,T), we express f in the SOP form f = EiPi, 
whence EDIS(f,T) = EDIS(Eipi, T) = Ei EDIS(pi,T), the latter equal-
ity following from Theorem 4.8.3. It also follows from Theorem 4.8.3 that 
Pi ~ EDIS(pi, T) for all values of the index i. Hence 
f = EPi 
~ EEDIS(pi,T) = EDIS(f,T). 
o 
Theorem 4.8.5 Let f be an n-variable Boolean function, let U be a p-
element subset of the argument-set {Xl, ... , x,,}, and let t be a q-argument 
term whose arguments are disjoint from those in U. Then 
(a) 
ECON(flt,U) = (ECON(f,U» 
I t 
(b) 
EDIS(flt,U) = (EDIS(f,U» It 
Proof. Let the arguments in {Xl, ... ,x,,} be ordered, without loss of gen-
erality, into blocks X = {T, U, V} such that the term t comprises the argu-
ments in T. Let K be the unique vector in {0,1}Q such that t = TK.Then 
identity (a) is proved by direct calculation: 
ECON(f It, U) = II f(K, A, V) = (II f(T, A, V» I t 
Ae{o,l}p 
Ae{O,l}p 
Identity (b) is proved by similar calculation, putting a Boolean sum in place 
of the foregoing product. 0 

4.9. REDUNDANT VARIABLES 
107 
Theorem 4.8.6 Let f: Bn_ B be a Boolean function ezpressed in terms 
of arguments z}, Z2, ... ,Zn and let S be a subset of {z}, Z2, ... , zn}. Then 
(ECON(f, S»' = EDIS(f', S) 
(EDIS(f, S))' = ECON(f', S) . 
(4.39) 
(4.40) 
Proof. We assume without loss of generality that S ::::; {z}, ... , zm}, and 
define T = {zm+},"" zn}. Invoking Theorem 4.8.1 and De Morgan's laws, 
(ECON(f(S, T), S»' = (IT f(A, T) )' 
Ae{o,1}m 
= 
E f'(A,T) 
Ae{o,1}m 
= EDIS(f'(A, T), S) , 
verifying (4.39). Equation (4.40) is verified by dual computations. 0 
Theorem 4.8.7 Let f: Bn_ B be a Boolean function whose first m argu-
ments are denoted Z1, Z2, ... , Zm. If the condition 
f(X,Y) = 0 
(4.41) 
is satisfied, then so is the condition 
EDIS(f,X) = o. 
(4.42) 
Proof. 
Condition (4.41) implies that f(A,Y) = 0 for all A in {O,l}mj 
hence 
E f(A,Y) = 0, 
Ae{O,1}m 
from which (4.42) follows by Theorem 4.8.1. 0 
4.9 
Redundant Variables 
An important problem in the practical application of Boolean algebra is to 
represent Boolean functions by formulas that are as simple as possible. One 
approach to the simplification of a Boolean formula is to minimize the num-
ber of variables appearing in it explicitly. This approach was investigated 

108 
CHAPTER 4. BOOLEAN ANALYSIS 
in 1938 by Shannon [183], who noted that a Boolean function f does not 
actually involve the variable Xk in case the condition 
( 4.43) 
holds identically. We say in this case that the variable Xk is redundant in 
f; the terms "vacuous" and "inessential" are also used to describe such a 
variable. 
The functions of interest in Boolean reasoning typically occur as inter-
vals, (cf. Section 2.4), i.e., as sets of the form 
[g,h] = {f I g ~ f ~ h}, 
(4.44) 
where g,h: Bn~ B are Boolean functions. Interval (4.44) is non-empty 
if and only if the condition g ~ h is satisfied. An "incompletely-specified" 
function (cf. Section 2.12), for example, is an interval of Boolean functions; 
as a further example, the set of solutions of a Boolean equation (Chapter 6) 
may be expressed as a system of intervals. 
Let X = {x}, . .. , xn} denote the set of arguments of g and h, and let S 
be a subset of X. We say that S is a redundancy subset on an interval in case 
there is a function belonging to that interval in which all of the arguments 
in S are redundant. We say that S is a maximal redundancy subset on the 
interval in case (a) it is a redundancy subset on the interval and (b) S is not 
a proper subset of any redundancy subset on the interval. 
The problem of finding maximal redundancy subsets has been investi-
gated from a number of points of view: Hight [83] employs decomposition-
charts [5]; Dietmeyer [50] applies array-operators; Kambayashi [98] reduces 
the location of such subsets to a covering problem; Halatsis and Gaitanis [76] 
generate a Boolean function whose prime implicants correspond to the max-
imal redundancy subsets; and Grinshpon [75] carries out a search-process 
aided by a numerical criterion. We approach the problem from yet another 
point of view in this section, based on the elimination-operators discussed 
in Section 4.8. 
Theorem 4.9.1 Let g, h: Bn~B be Boolean functions expressed in terms 
of arguments Xl, •.. , Xn , and let S be a subset of those arguments. 
1. If f is a Boolean function in the interval [g, h], and S is redundant in 
f, then f belongs to the interval 
[EDIS(g,S), ECON(h,S)]. 
(4.45) 

4.9. REDUNDANT VARIABLES 
109 
o 
2. If the interval (4.45) is non-empty, then there is a Boolean function in 
[g, h] in which S is redundant. 
Proof. 
1. (By induction on the number of elements in S.) Suppose f to be a 
member of [g, h], whence the conditions 
g/Xk $ 
f/xk $ 
h/xk 
9/Xk $ 
f/Xk $ h/xk 
(4.46) 
hold for any argument Xk in {x}, ... , xn }. If the argument Xk is re-
dundant in f, then the constraint 
(4.47) 
follows from (4.43) and (4.46), inasmuch as the redundancy of Xl im-
plies that f(X},X2, ... ) = f(O,X2, ... ) = f(1,x2, ... ). Thus (4.45) 
is verified for the case in which S has one member. Assume next 
that the theorem holds if S has m members, i.e., that if the variables 
x}, X2, ... , Xm are redundant in f, then f belongs to the interval (4.45), 
where S = {Xl' X2, ... , xm}. If the variable Xm+1 is also redundant in 
f, then f belongs by the induction hypothesis to the interval 
[EDIS(EDIS(g, S), {xm+1}) EGON(EGON(h, S), {xm+1})] . 
(4.48) 
Recalling the definition of EDIS and EGON, however, we may ex-
press interval (4.48) as follows: 
[EDIS(g, S U {xm+1}), EGON(h, S U {xm+1})] . 
(4.49) 
Thus the theorem holds if S has m + 1 members, proving Part 1 of the 
theorem. 
2. It follows from Theorem 4.8.4 that interval (4.45) is a subset of [g, h]. If 
(4.45) is non-empty, then EDIS(g,S) is a function belonging to (g,h] 
in which S is redundant, proving Part 2 of the theorem. 
We define the resultant of removal of variable X from interval (p, q] to 
be the interval [EDIS(p,{x}), EGON(q,{x})]. As noted in the proof of 
Theorem 4.9.1, the resultant of removal of a variable from an interval is a 

110 
CHAPTER 4. BOOLEAN ANALYSIS 
subset of that interval. It should be noted that the resultant of removal of x 
from (p, q] is different from the resultant of elimination of x from (p, q] The 
latter resultant takes the form [ECON(p, {x}), EDIS(q, {x})] (the proof is 
assigned as an exercise), which is a superset of the interval (p, q]. 
Theorem 4.9.1 shows that the maximal redundancy subsets on an interval 
[g, h] may be determined by a tree-search through a space of intervals derived 
from [g, h]. The root of the tree is [g, h]i each child-node of a node (p, q] is 
the resultant of removal of a variable not yet removed in the path leading to 
(p, q]. A variable is removed from an interval (and thus the search proceeds 
beyond the corresponding node) only if the resultant of removal of that 
variable is non-empty, i.e., only ifthat variable is redundant on that interval. 
If no variable is redundant on a given interval in the search-space, then the 
variables removed in the path leading to that interval constitute a maximal 
redundancy subset. 
The efficiency of the search-process clearly depends on the efficiency with 
which the redundancy of a given variable on a given interval can be decided. 
It follows from Theorem 4.9.1 that variable x is redundant on (p, q] if and 
only if the condition 
EDIS(p,{x}) :5 ECON(q,{x}) 
( 4.50) 
is satisfied. If p is expressed in arbitrary sum-of-products form and q is 
expressed in Blake canonical form, then 
• EDIS(p, {x}) is found by deleting x and x' wherever they occur in a 
term (if either x or x' appears alone as a term, then EDIS(p, {x}) = 1)i 
• ECON(q, {x}) is found by deleting any term in q that contains either 
x or x' (the result remains in Blake canonical form)i and 
• condition (4.50) is satisfied if and only if each term of EDIS(p,{x}) 
is included in some term of ECON(q,{x}). 
The termwise comparison described above suffices as a test for inclusion 
because ECON(q, {x}) is expressed in Blake canonical form. A formula 
whose included sum-of-products formulas may be tested by termwise com-
parison is called syllogistic. Syllogistic formulas are discussed in Appendix 
A, where it is demonstrated that a Blake canonical form is syllogistic. 
We call a subset T of X a minimal determining subset on the interval 
[g, h] provided T has the following properties: 

4.9. REDUNDANT VARIABLES 
111 
1. the variables in T suffice to describe at least one function in [g, hl, and 
2. no proper subset of T has property 1. 
Each minimal determining subset, T, on [g,hl (and nothing else) is the 
relative complement with respect to X of a maximal redundancy subset, S, 
on [g,hl i.e., T = X - S. 
Example 4.9.1 Let us determine the minimal determining subsets on the 
interval [g, hl, where 9 and h are given by the formulas 
9 = v'w'xy'z + vw'x'yz' 
h = v' x + vx' + w' + y + z . 
(4.51) 
( 4.52) 
A depth-first search through the space of intervals derived from [g, hl by 
variable-removals is indicated in Table 4.1. The maximal redundancy sub-
sets found in this search are {v,w,x}, {v,x,y,z}, and {w,y,z}. The cor-
responding minimal determining subsets are, respectively, {y, z}, {w}, and 
{v, x}. The function-intervals associated with these subsets are shown in 
Table 4.2. 0 
Example 4.9.2 (Grinshpon [75]) 
An incompletely-specified switching 
function I: {a, 1}6 __ {a, 1} is described by the statements 
4>o(X) = 1 ==> I(X) = ° 
<l>1(X) = 1 ==> I(X) = 1 , 
( 4.53) 
the functions <1>0 and <1>1 being expressed as follows: 
<1>0 = x~[x~x~x~ + x~(xi(x~ + x~ + x~) + x~x~)l 
<1>1 = XIX2[X3X5X~ + X6(X~ + x~ + x~)l + X5X6(XIX~X4 + X~X3). (4.54) 
Thus I is any function in the interval [g, hl, where 
9 = 
<1>1 
h = 
<I>~. 
(4.55) 
Repeating the search-process described in Example 4.9.1 to find the maximal 
redundancy subsets, and computing complements of those subsets relative 
to {x}, x2, x3, x4, x5, X6}, we derive the following minimal determining sub-
sets: {Xl,X3,X6}, {X2,X3;X4}, {X2,X5,X6}, {X3,X5,X6}, {XI.X2,X3,X5}, and 
{XbX2,X6}. 0 

112 
CHAPTER 4. BOOLEAN ANALYSIS 
Subset 
Test 
Redundant? 
0 
v'w'xy' z + vw'x'yz' < v' x + vx' + w' + y + z 
yes 
{v} 
w'xy'z + w'x'yz' 
~ w' + y + z 
yes 
{v,w} 
xy'z + x'yz' 
~ y+z 
yes 
{v,w,x} 
y'z+yz' < y+z 
yes 
{v,w,x,y} 
z + z' < z 
no 
{v,w,x,z} 
y' + y < y 
no 
{v,x} 
w'y'z + w'yz' < w'+y+z 
yes 
{v,x,y} 
w'z + w'z' < w' + z 
yes 
{v,x,y,z} 
w' 
~ w' 
yes 
{w} 
v'xy'z + vx'yz' < v' x + vx' + y + z 
yes 
{w,x} 
v'y'z + vyz' < y+z 
yes 
{w,x,y} 
v'z+vz' 
~ z 
no 
{w,x,z} 
v'y' + vy < y 
no 
{w,y} 
v'xz + vx'z' < v'x+vx'+z 
yes 
{w,y,z} 
v'x + vx' < v'x + vx' 
yes 
Table 4.1: Development of maximal redundancy subsets. 
Minimal Determining Subset 
{y,z} 
{w} 
{v,x} 
Function-Interval 
[y'z + yz', y + z] 
[w', w'] 
[v'x + vx', v'x + vx'] 
Table 4.2: Minimal determining subsets and associated intervals. 

4.10. SUBSTITUTION 
113 
4.10 
Substitution 
We have seen that a variable may be removed from a Boolean formula by 
calculating one of the following with respect to that variable: 
• 
its quotient, 
• 
its conjunctive eliminant, 
• 
its disjunctive eliminant, or 
• 
its Boolean derivative. 
Another way to remove a variable is by substitution. Suppose we are 
given the formula 
a'xy + bx'z 
and we wish to remove x by the substitution 
x = cy. 
( 4.56) 
( 4.57) 
If we replace each appearance of x in the original formula by the formula cy, 
and each appearance of x' by c' + y', the result after simplification is 
a'cy + bc'z + by'z. 
( 4.58) 
Such direct replacement is natural for hand-calculation, but can be awk-
ward to automate. A more readily-automated procedure is provided by the 
following theorem. 
Theorem 4.10.1 Let f and 9 be Boolean formulas on a common Boolean 
algebra B, and let x be one of the variables appearing in the formula f. 
The result of substituting g for x in the formula f is given by either of the 
following formulas: 
ECON(J + (x EB g), {x}) 
EDIS(J· (x' EB g), {x}). 
( 4.59) 
( 4.60) 
Proof. The result of substituting x = 9 into the formula f(x, y, ... ) is the 
formula f(g, y, .. . ), which has the expanded form 
[1(0, y, . .. ) + g] [f(1, y, . .. ) + g'] . 
The latter formula may be expressed equivalently as 
ECON(x'(J(O, y, ... ) + g) + x(J(l, y, ... ) + g'), {x}), 
which is equivalent in turn to (4.59). Similar calculations verify (4.60). 0 

114 
CHAPTER 4. BOOLEAN ANALYSIS 
Example 4.10.1 Applying (4.59), the result of substituting x = cy in for-
mula (4.56) is the formula 
ECON(a'xy + bx'z + (x $ cy), {x}), 
i.e., 
[bz + cy] [a'y + c' + y'] , 
which takes the form (4.58) when multiplied out and simplified. 0 
Example 4.10.2 The circuit of Example 4.7.2 is described by the equations 
Zl = XIX2 
Z2 
X3 + Zl • 
The consequent 
(4.61 ) 
(4.62) 
(4.63) 
was obtained in that example by eliminating Xl. An alternative approach is 
to perform the substitution (4.61) in the right-hand side of equation (4.62). 
Applying (4.59), we write 
Z2 
= ECON(X3 + Zl + (Zl $ XIX2), {ztJ) 
which yields (4.63). If we apply (4.60), viz., 
Z2 
= EDIS({x3 + zd . (z~ $ XIX2), {ztJ) , 
we obtain the same result. 0 
Example 4.10.3 Given a Boolean function f and a term t, the Boolean 
quotient fit (Section 2.15) is the function that results when the substitution 
t = 1 is carried out in f. Thus 
fit = ECON(J + (t $1),T) 
= ECON(J+t',T) 
where T is the set of variables in the term t. Let us apply formal substitution 
to evaluate the quotient f{x, y, z)lxy': 
f(x,y,z)lxy' 
ECON(J + x' + y,{x,y}) 
= (J{O, 0, z) + 1)(J(0, 1, z) + 1)(J{1, 0, z) + 0)(J{1, 1, z) + 1) 
= f(1,0,z). 
Thus formal substitution produces the same result as do the methods of 
Section 2.15. 0 

4.11. THE TAUTOLOGY PROBLEM 
115 
4.11 
The Tautology Problem 
A basic problem in propositional logic and Boolean reasoning is to decide 
whether the members of a given set of terms (products) sum to one. Specif-
ically, the problem is to determine whether the relation 
(4.64) 
is an identity, where tl, ... , tm are products of variables (complemented or 
uncomplemented) from the set X = {Xl, ... ,Xn }. 
This problem arises in proving theorems in the propositional calculus [47, 
51,53], in deciding the consistency (i.e., solvability) of a Boolean equation 
[221] and in determining minimal formulas for switching functions [18, 37, 
70, 175, 176]. See Galil [62] for a detailed study of the complexity of this 
problem. 
4.11.1 
Testing for Tautology 
A boolean formula is a tautology, clearly, if evaluating its Blake canonical 
form produces the I-formula. More efficient tests [175,51,47,222] are based 
on the fact that a Boolean formula F is a tautology if and only if its Boolean 
quotients with respect to x' and x are tautologies, where x is anyone of its 
arguments. Each such test employs an elaboration of the following rules: 
1. If F is is empty (i.e., it contains no terms), then F is not a tautology. 
2. If F contains the term 1, then F is a tautology. 
3. Otherwise, F is a tautology if and only if Flu' is a tautology and Flu 
is a tautology, where u is an argument of F. 
Example 4.11.1 To improve efficiency in hand-calculation, we amend the 
second of the foregoing rules to read as follows: "If F contains the term 1, 
or a pair u and u' of single-letter terms, then F is a tautology." Let us apply 
the amended rule-set to the formula 
F = w'y'z + xy + yz + x'z' + w'x + wy' . 
F does not satisfy Rule 1 or Rule 2; therefore we evaluate Fix' and Fix' 
(variable x is chosen arbitrarily): 
Fix' = w'y'z + yz + z' + wy' 
Fix = w'y'z+y+yz+w'+wy'. 

116 
CHAPTER 4. BOOLEAN ANALYSIS 
F is a tautology if and only if each of the foregoing quotients is a tau-
tology. Neither quotient satisfies Rule 1 or Rule 2; therefore we divide each 
by some letter and its complement: 
(Fjx')jy' 
(Fjx')jy = 
(Fjx)jy' = 
(Fjx)jy 
= 
Fjx'y' 
Fjx'y 
Fjxy' 
Fjxy 
= 
= 
= 
= 
w'z+z'+w 
z+ z' 
w'z+w'+w 
1+z+w' 
The only one of the foregoing quotients not verified to be a tautology by 
either Rule 1 or the amended Rule 2 is (Fjx')jy' = Fjx'y' = w'z + z' + w. 
We therefore generate quotients with respect either to w or to Z; we choose 
w: 
(Fjx'y')jw' = Fjx'y'w' = z + z' 
(Fjx'y')jw = Fjx'y'w = z' + 1 
Every formula has thus been verified by one of the rules to be a tautology; 
hence F is a tautology. 0 
4.11.2 
The Sum-to-One Theorem 
It is frequently necessary in Boolean calculations to determine if a given term 
is included in a given Boolean function. The following theorem, employed 
by Samson & Mueller [175] and Ghazala [70] to simplify switching formulas, 
transforms the problem of determining such inclusion into one of determining 
the tautology of an associated function. 
Theorem 4.11.1 Let f be a Boolean function and let t be a term. Then 
t ~ f 
{:::::} 
f jt = 1 . 
( 4.65) 
Proof. The implication =::} follows from Proposition 2.15.1 for f ~ t 
and 9 ~ f, while the converse implication follows from Proposition 2.15.4. 
o 
Example 4.11.2 Let f = xy' +x'z+yz' and let t = y'z. To decide ift ~ f, 
we evaluate f jt: 
(xy' + x'z + yz')jy'z = x + x' = 1 . 
Thus y'z ~ xy' + x'z + yz'. 0 

4.11. THE TAUTOLOGY PROBLEM 
117 
4.11.3 
Nearly-Minimal SOP Formulas 
A much-studied problem in switching theory is to find minimal SOP formulas 
for Boolean functions. This problem has little direct importance in Boolean 
reasoning; for computational efficiency, however, it is useful to be able to 
represent a function by a nearly-minimal formula. The sum-to-one theorem 
enables this to be done conveniently for a function expressed (as is usual in 
reasoning-computations) in Blake canonical form. 
It was shown by Quine [161] that the terms of a least-cost SOP formula 
for a Boolean function I are necessarily prime implicants of I-provided that 
the cost of a formula increases if the number of literals in a term increases. 
We assume such a cost-measurej thus a simplified SOP formula for I is a 
subformula of BCF(J). An irredundant formula for I is a disjunction of 
prime implicants of I that (a) represents I and (b) ceases to represent I if 
any of its terms is deleted. The search for simplified SOP formulas therefore 
need only be over the irredundant formulas. 
The following procedure converts BC F(J) into an irredundant formula 
for I by a succession of term-deletions. The cost of an SOP formula is 
assumed to be the total number of literals in the formula. The procedure 
attempts to minimize this cost by considering the most expensive terms 
(those comprising the most literals) first for deletion. This procedure does 
not guarantee minimality, but typically produces minimal or near-minimal 
costs. 
Step 1. Sort the terms of BC F(J) according to the number of literals they 
contain, putting those having the most literals first. Denote by F the 
resulting formula. 
Step 2. Let T be a term of F and let F - T denote the formula that results 
when T is removed from F. Beginning with the first term in F, carry 
out the following process until all terms T have been considered: 
If (F - T)/T is a tautology, replace F with F - Tj otherwise 
do nothing. 
Return the resulting formula. 
Step 1 generates all of the candidate-terms for an irredundant formula, 
and arranges that the most costly terms (those having the largest number 
of literals) will be considered first for removal. Step 2 makes use ofthe sum-
to-one theorem (Theorem 4.11.1) to produce an irredundant representation 
F for I; no term of F is included in the remainder of F. 

118 
CHAPTER 4. BOOLEAN ANALYSIS 
Example 4.11.3 To produce a nearly-minimal formula corresponding to 
the formula 
f = ABE' + GD'E + AG'D'E' + ABDE + A'B'GD + AB'G + A'B'G'D' , 
we first carry out Step 1 of the foregoing procedure, i.e., we generate the 
terms of BG F(J) and arrange them in descending order of the number of 
literals they contain: 
BGF(J) 
B'G'D'E' + A'B'D'E + A'B'G'D' + ABE' + AD'E' + 
= +B'GE+GD'E+ABD+B'GD+AG. 
The formula remaining after completion of Step 2 is 
f = G D' E -+ ABD + B' G D + A' B' G' D' + AD' E' . 
( 4.66) 
It can be shown that there are four irredundant formulas for f; each has the 
form 
f = GD'E + ABD + B'GD+ < OTHER TERMS> 
where < OTHER TERMS> may be one of the following: 
A' B'G' D' + AD' E' 
B'G'D'E' + A'B'D'E + AD'E' 
B'G'D'E' + A'B'G'D' + ABE' 
B'G'D'E' + A'B'D'E + ABE' 
+ AG 
+ AG 
Thus 4.66 is a least-cost formula for the given function. 0 

EXERCISES 
119 
Exercises 
1. Prove or disprove: any two inconsistent Boolean systems are equiva-
lent. 
2. (Couturat [41, p. 36]) Prove the following equivalence: 
{a < bEflC} 
{a = 
b 
~ aEflc 
<==> 
b = 
C 
~ aEflb 
c = 
bEflc } 
aEflc 
aEflb 
3. Prove that the following implication is valid: 
4. (Lowenheim [124], Rudeanu [172]). Let J, g, and h be Boolean func-
tions and assume that J(X) = 0 is consistent. Show that 
[J(X) = 0 => g(X) = h(X)] <==> [gJ' = hJ'] . 
5. Let J, g, and h be Boolean functions. Show that 
[J(X) = 0 => g(X) = 0] => 
[ [g(X) = 0 => h(X) = 0] => [J(X) = 0 => h(X) = 0] ] 
6. (Rudeanu [172, p. 100]). Show that S => [T <==> U] is valid, where 
S, T, and U are defined as follows: 
s: x ~ a + b' and y ~ a' + b 
T: b'x + ay' = a and bx' + a'y = b 
U: x ~ ab' and y ~ a'b 
7. The RS-Iatch, a basic component in digital circuits, is characterized 
by the coupled equations 
Q = S+X' 
X = R+Q', 
(4.67) 
( 4.68) 
where R and S are the latch's inputs and Q and X are its outputs. 
For proper operation, the inputs should be constrained to satisfy the 

120 
CHAPTER 4. BOOLEAN ANALYSIS 
condition RS = 0, in which case we wish to verify that the outputs 
will satisfy the condition X = Q'. The problem: show that the system 
(4.67, 4.68) implies the condition 
RS = ° ==> 
X = Q' . 
8. In the earliest published work applying Boolean algebra to switching 
circuits, Nakasima [146] lists rules, shown below, to assist in the solu-
tion of Boolean equations. Verify each rule. 
( a) If A + X = A, then X ~ A. 
(b) If AX = A, then A ~ X. 
(c) If A + X = B, then A' B ~ X ~ A + B. 
(d) If AX = B, then AB ~ X ~ A' + B. 
(e) If AX + B = C, then B' C ~ AX ~ B + C 
and (A + B)C ~ B + X ~ A'B' + C. 
(f) If (A + X)B = C, then BC ~ A + X ~ B' + C 
and (A' + B')C ~ BX ~ AB + C. 
(g) If A + X = B and A' + X = C, then X = BC. 
(h) If AX = B and A' X = C, then X = B + C. 
(i) If A + X = B and AX = C, then X = B(A' + C). 
9. Assume that B = {O, 1, a', a}. It is asserted in the text that: 
(a) the set of solutions of the equation a'x + y = ° 
is {(O,O),(a,O)}; 
and 
(b) if f(x,y) = ° 
has solutions (0,0) and (a, 1) then it must also have 
solutions (0, a') and (a,a). 
Prove these assertions. 
10. Given the Boolean system 
awx' + bx = b'x'y' 
by'+a 
~ x+y, 
(a) Reduce to a single equivalent equation of equals-zero form. 
(b) Reduce to a single equivalent equation of equals-one form. 

EXERCISES 
121 
(c) Eliminate x, expressing the resultant in equals-one form. 
Express all resulting formulas in Blake canonical form. 
11. Let B = {O, 1, a', a} and define a constraint on (x, y) as follows: 
(x,y) E {(O,a),(l,a'),(a',On. 
Decide whether this is a Boolean constraint, making your reasoning 
explicit. 
12. A constraint on the variables x, y, z is expressed by the Boolean equa-
tion 
ax'y + bz = a'yz + xz' . 
Express the same constraint by an equation of the form 
g(x,y,z)=a+z, 
representing the function g in Blake canonical form. 
13. The equation ab + x = b' is equivalent to the equation f( x) = ° and 
also to the equation g = a + b. Express the functions f and g by 
simplified formulas. 
14. Given 
f = AE' F' + DE F + B DE' + A' B' E' F' + BCD' F + 
+BDEF' + B'D'EF+ BD'E'F', 
( a) Express f in Blake canonical form. 
(b) Assume the resultant of elimination of the variables Band C from 
the equation f = ° 
to be the equation g = 0. Express the function 
g in simplified form. Explain your method. 
15. The system 
ax + y 
xy 
x' + y < a+ y 
expresses a constraint on the variables x and y over the Boolean algebra 
B = {O, 1, a', a}. Express the same constraint by the equation ax = 
g(x, y), writing g(x, y) as a simplified formula. 

122 
CHAPTER 4. BOOLEAN ANALYSIS 
16. Let B = {O, 1, a', a} and define constraints on (x, y) as follows: 
(a) (x,y) E {(a, a), (1, I)} 
(b) (x,y) E {(a, a), (a, 1),(1, I)} 
Decide in each case whether the constraint is Boolean, making your 
reasoning explicit. 
17. Given 
f = AE'F'+DEF+BDE'+A'B'E'F'+BCD'F+ 
+BDEF' + B'D'EF+ BD'E'F' , 
(a) Express f in Blake canonical form. 
(b) Assume the resultant of elimination of the variables B and C from 
the equation f = 0 to be the equation 9 = o. Express the function 
9 in simplified form. Explain your method. 
18. Let S be a subset of the arguments in formulas representing Boolean 
functions 9 and h. Show that the resultant of elimination of the argu-
ments in S from the interval 
is the interval 
ECON(g,S)::5 x::5 EDIS(h,S). 
19. Show that the conditions 
(4.69) 
and 
EDIS(f,Xl) = ECON(f,xt} 
(4.70) 
are equivalent. 
20. Derive the minimal determining subsets listed in Example 4.9.2 by 
application of the search-procedure described in Section 4.9. 
21. Devise a procedure to convert a given SOP formula into an equivalent 
orthogonal SOP formula having the fewest possible terms (cf. Section 
2.13). 

Chapter 5 
Syllogistic Reasoning 
We outline in this chapter an approach, which we call "syllogistic," to the 
solution oflogical problems. The essential features of the syllogistic approach 
were formulated by Blake [10]. 
The examples we consider are expressed either in the algebra of propo-
sitions or the algebra of classes; these algebras are discussed in Chapter 2. 
The elementary units of reasoning in class-logic are classes, i.e., subsets of 
a universal set. George Boole's "algebra of logic" [12, 13], for example, was 
formulated in terms of classes. The elementary units in propositional logic, 
on the other hand, are propositions, i.e., statements that are necessarily ei-
ther true or false. Although the examples we present are in terms either of 
propositions or classes, the methods we discuss are applicable in any Boolean 
algebra. 
Syllogistic reasoning makes use of just one rule of inference, rather than 
the many rules conventionally employed. It proceeds by applying the opera-
tion of consensus repeatedly to a formula I representing given logical data. 
We have seen (Chapter 3) that such repeated consensus-generation produces 
BCF(J), the Blake canonical form for I, together possibly with additional 
terms that are absorbed by the terms in BC F(J). Syllogistic reasoning is 
thus intimately associated with the Blake canonical form. 
Syllogistic reasoning is related to the resolution-based techniques em-
ployed in predicate logic. The terms of syllogistic formulas are the duals, 
in the Boolean domain, of the clauses of predicate logic. The operation of 
consensus is the Boolean dual of resolution. Syllogistic reasoning differs from 
reasoning in predicate logic, however, in one important way. Resolution in 
the predicate calculus is employed as part of a strategy of theorem-proving 
123 

124 
CHAPTER 5. SYLLOGISTIC REASONING 
by refutation; a problem is formulated as a theorem, which is proved (possi-
bly assigning values to variables as aside-effect) by conjoining the theorem's 
denial with the premises and deducing a contradiction. In syllogistic reason-
ing, on the other hand, the strategy is to chain forward from the premises, 
represented by an equation of the form f = 0, until all of the "prime" con-
sequents are generated. A given consequent (theorem) can then be verified 
from the prime consequents by simple term-by-term comparisons. 
Forward chaining is not feasible in predicate logic because it is not guar-
anteed to terminate. Even in the finite Boolean domain (where termination 
is guaranteed), theorem-proving typically requires more computation by for-
ward chaining than by refutation. In most applications, however, Boolean 
problems are not formulated as theorems to be proved. Forward chaining is 
typically the first step in the solution of such problems by Boolean reason-
ing, after which appropriate operations of Boolean analysis (e.g., elimination, 
division, substitution, solution) are performed. 
Example 5.0.1 Suppose that our knowledge concerning the endeavors of a 
certain college student is expressed by the following statements [97]: 
1. If Alfred studies, then he receives good grades. 
2. If Alfred doesn't study, then he enjoys college. 
3. If Alfred doesn't receive good grades, then he doesn't enjoy college. 
What may we conclude concerning Alfred's academic performance? 
A correct (but probably not obvious!) conclusion is that Alfred receives 
good grades. Our object in this chapter is to show how syllogistic reasoning 
enables us to arrive at such a conclusion mechanically. 
5.1 
The Principle of Assertion 
Information is conveyed in ordinary algebra by equations. Boole and other 
nineteenth-century logicians therefore found it natural to write logical state-
ments as equations. To analyze a collection of statements in Boole's algebra 
of logic, the corresponding equations are reduced to a single equivalent equa-
tion of the form 
f(A,B,C, ... ) = 0, 
(5.1) 

5.1. THE PRINCIPLE OF ASSERTION 
125 
where f is a Boolean function and A, B, C, ... are symbols which, in Boole's 
formulation, represent classes of objects. 
All of the properties of Boolean equations remain valid if the symbols 
A, B, C, ... in (5.1) are propositions, rather than classes, and if 0 and 1 repre-
sent, respectively, the identically false and identically true propositions. Cer-
tain statements not involving equations, however, are valid only for propo-
sitions. These statements derive from an axiom peculiar to the calculus of 
propositions, called the principle of assertion (see Couturat [41]), which may 
be stated as follows: 
[A = 1] = A. 
(5.2) 
In Couturat's words, "To say that a proposition A is true is to state the 
proposition itself." It is therefore possible in the calculus of propositions to 
dispense entirely with equations. If f(A, B, C, ... ) is a propositional (Le., 
two-valued) function, then equation (5.1) may be stated equivalently by the 
proposition 
i'(A,B,C, ... ) . 
(5.3) 
Modern logicians have abandoned equations in the formulation of propo-
sitionallogic. We shall employ the classical equation-based approach, how-
ever, in order to apply the techniques of Boolean analysis without modifica-
tion to problems in propositional logic. 
Let us convert the set of premises in Example 5.0.1, concerning Alfred's 
collegiate endeavors, to a single equivalent equation of the form (5.1). We 
begin by expressing the three given premises by the system 
1. 
S 
--+ 
G 
2. 
S' 
--+ 
E 
3. 
G' --+ 
E' 
of propositions, the symbols E, G, and S being defined as follows: 
E = 
G 
S = 
"Alfred enjoys college" 
"Alfred gets good grades" 
"Alfred studies". 
(5.4) 
The premises in (5.4) may be represented equivalently by the system 
SG' = 
S'E' = 
G'E = 
o 
o 
0, 
(5.5) 

126 
CHAPTER 5. SYLLOGISTIC REASONING 
of propositional equations. We thus arrive at a single equation equivalent to 
the set of premises given in Example 5.0.1, i.e., 
SG' + S' E' + G' E = 0 . 
(5.6) 
5.2 
Ded uction by Consensus 
In traditional logic, deduction is carried out by invoking a number of rules of 
inference; these rules announce that certain conclusions follow from certain 
sets of premises. Some logic-texts, e.g., [97], list hundreds of such rules. 
A cardinal advantage of syllogistic reasoning is that it employs only one 
rule of inference, that of hypothetical syllogism. This rule states that the 
conclusion given below follows from its premises (we express the components 
of this syllogism both as conditionals and as equations): 
Major Premise 
Minor Premise 
Conclusion 
Conditional 
A~B 
B~C 
A~C 
Equation 
AB' = 0 
BC' =0 
AC' = 0 
The two premises may be expressed by the single equation f = 0, where 
f is given by 
f = AB' +BC'. 
(5.7) 
The conclusion is expressed by the equation 9 = 0, where 
9 = AC'. 
(5.8) 
The problem of deduction in this case is that of obtaining the term AC' 
(representing the conclusion) from the terms AB' and BC' (representing 
the premises). We note that AC' is the consensus of the terms AB' and 
BC'; thus, reasoning by the rule of hypothetical syllogism is carried out by 
producing the consensus (which Blake called the "syllogistic result") of the 
terms representing the premises. The utility of the consensus-operation is not 
confined, however, to simple syllogisms. The single operation of consensus 
suffices to produce a simple representation of all conclusions to be inferred 
from any set of premises in propositional logic. Repeated application of 
consensus to an SOP formula f, followed by absorption, produces BCF(J), 
i.e., the disjunction of all of the prime implicants of f. Thus, given a set of 
premises reducible to an equation of the form (5.1) , the formula BCF(J) 

5.3. SYLLOGISTIC FORMULAS 
127 
represents (in a way we shall subsequently make precise) all of the conclusions 
that may be inferred from those premises. 
Let us continue our study of Alfred's collegiate endeavors. Converting 
the left side of (5.6) to Blake canonical form, we represent everything we 
know about Alfred by the equation 
S'E' + G' = O. 
Equation (5.9) is equivalent to the system 
S'E' 
0 
G' = 0, 
whose components may be given the verbal interpretations 
(a) 
"Alfred studies or Alfred enjoys college." 
(b) 
"Alfred gets good grades." 
(5.9) 
(5.10) 
(5.11) 
Statement (a) is a re-phrasing of one of the original premises; statement 
(b) is the not-very-obvious conclusion announced at the beginning of this 
chapter. 
5.3 
Syllogistic Formulas 
Let A, B, C, ... be Boolean variables and suppose that we are given a system 
of statements (premises) reducible to the equation (5.1). Let us suppose 
further that (5.1) is consistent. A consequent (or conclusion) of (5.1) is a 
statement or system of statements reducible to the equation 
g(A,B,C, ... ) = 0 
(5.12) 
such that the implication 
f=O 
==> 
g=O 
(5.13) 
is satisfied. Thus, by Theorem 4.4.1, (the Extended Verification Theorem), 
equation (5.12) is a consequent of equation (5.1) if and only if the relation 
g'S,f 
(5.14) 
holds. Looking for consequents ofthe equation f = 0 is equivalent, therefore, 
to looking for functions 9 included in f. Let p be a prime implicant of f. 

128 
CHAPTER 5. SYLLOGISTIC REASONING 
Then we call the equation p = 0, which is clearly a consequent of f = 0, a 
prime consequent of f = 0. 
We assume henceforth that all Boolean functions are expressed by SOP 
(sum-of-products) formulas. Deciding whether a given SOP formula is in-
cluded in another is not in general an easy task. It is not obvious, for 
example, that the function 
9 = BC'D + AD' 
(5.15) 
is included in the function 
f = AC' + CD' + A'D. 
(5.16) 
Comparing two SOP formulas for inclusion becomes much easier, however, if 
we confine ourselves to formal inclusion. Recalling the the definition given 
in Chapter 3, we say that 9 is formally included in f, written 9 ~ f, in case 
each term of 9 is included in (Le., has all the literals of) some term in f. It 
is clear that formal inclusion implies inclusion; that is, 
(5.17) 
for all SOP formulas f and g. We call an SOP formula f syllogistic in case 
the converse of (5.17) also holds, Le., in case the implication 
(5.18) 
holds for all Boolean formulas g. Thus an SOP formula is syllogistic if and 
only if every SOP formula that is included in it is also formally included in 
it. 
It is shown in Appendix A (Theorem A.3.1) that an SOP formula for 
a Boolean function f is a syllogistic representation of f if and only if it 
contains all the prime implicants of f. It follows directly that the simplest 
syllogistic formula for f is BCF(J). 
Suppose that a Boolean function f is expressed by a syllogistic formula, 
e.g., by BC F(J). Then one may tell by inspection (or conveniently program 
a computer to tell) if any given SOP formula is included in f. Consider for 
example the function defined by (5.16); in Blake canonical form, 
BCF(J) = AC' + CD' + A'D + AD' + C'D + A'C . 
(5.19) 
Deciding whether the function 9 defined by (5.15) is included in (5.19), 
unlike deciding whether 9 is included in the equivalent formula (5.16), is 
a simple matter of inspection. The terms BC'D and AD' of (5.15) are 
included, respectively, in the terms C'D and AD' of BCF(J); hence, 9 is 
formally included in (5.19), and therefore included in (5.16). 

5.4. CLAUSAL FORM 
129 
5.4 
Clausal Form 
Suppose a Boolean function f is expressed as an SOP formula, i.e., 
f = PI + P2 + ... + Pic, 
(5.20) 
where PI, ... ,Pic are terms (products). Then the equation f = 0 is equivalent 
to the system 
Consider any term 
PI = 0 
P2 = 0 
Pic = O. 
Pi = al" .amb~ .. . b~ 
(5.21) 
of (5.20). (If m = 0, i.e., if no a's are present, we consider Pi to have the 
form 1 . b~ ... b~; if n = 0, we consider Pi to have the form al ... am ·0'.) The 
equation Pi = 0 may be written in the equivalent form 
al ... am . b~ ... b~ = 0 . 
(5.22) 
We call a statement having the specialized form (5.22) a clause, and say 
that it is in clausal form. A clause whose left-hand side is a prime implicant 
of f will be called a prime clause of f = O. If the a's and b's are propositions, 
then we may write the clause (5.22) equivalently as a conditional, i.e., 
(5.23) 
which we also call a clause and which we read as 
"IF al AND··· AND am, THEN bl OR··· OR bn". 
(5.24) 
If m = 0, then (5.24) degenerates to 1 --+ bl + ... + bn , which may be read 
"bl OR ... OR bn". 
If n = 0, then (5.24) degenerates to al" ·am --+ 0, for which a direct (if 
awkward) reading is 
"IT IS NOT THE CASE THAT al AND· .. AND am". 

130 
CHAPTER 5. SYLLOGISTIC REASONING 
Some examples of equations of the form Pi = 0, together with their 
corresponding clauses, are tabulated below. 
Equation 
AB'CD'E' = 0 
abx = 0 
U'V'W' = 0 
Clause 
AC --
B+D+E 
abx --
0 
1 --
U+V+W 
Example 5.4.1 Alice, Ben, Charlie, and Diane are considering going to a 
Halloween party. The social constraints governing their attendance are as 
follows: 
1. If Alice goes then Ben won't go and Charlie will. 
2. If Ben and Diane go, then either Alice or Charlie (but not both) will 
go. 
3. If Charlie goes and Ben does not, then Diane will go but Alice will not. 
Let us define A to be the proposition "Alice will go to the party" , B to be 
"Ben will go to the party," etc. Then statements 1 through 3 above may be 
translated as follows: 
Conditional 
Equation 
1. 
A --
B'C 
AB+AC' = 0 
2. 
BD --
A'C + AC' 
BD(A'C' + AC) = 0 
3. 
B'C --
A'D 
AB'C +B'CD' = 0 
The given data are therefore equivalent to the propositional equation j = 0, 
where j is given by 
j = A(B + C') + BD(A'C' + AC) + B'C(A + D') . 
(5.25) 
The Blake canonical form for j, Le., 
BCF(J) = BC'D + B'CD' + A, 
(5.26) 
is found from (5.25) by multiplying out to obtain an SOP formula, applying 
consensus repeatedly, and deleting absorbed terms. The prime clauses for 

5.4. CLAUSAL FORM 
131 
the Halloween party are therefore the following: 
BD 
~ C 
"If Bill and Diane go to the party, 
then Charlie will go." 
C 
~ B+D 
"If Charlie goes to the party, 
then either Bill or Diane will go." 
A 
~ 0 
"Alice will not go to the party." 
We show in Section 5.5 that clauses derived in this way constitute a complete 
and simplified representation of all conclusions that may be inferred from 
the given premises. 
Example 5.4.2 The RS flip-flop is defined by the equations 
Y = S+yR' 
o = RS 
(characteristic equation) 
(input constraint) 
where R (Reset) and S (Set) are input-excitation signals and y and Yare 
the present state and next states, respectively. The foregoing equations are 
equivalent to the single equation f = 0, where BC F(J) is given as follows: 
BCF(J) = RS + RY + SY' + R'yY' + S'y'Y . 
The associated prime clauses, viz., 
1. 
RS 
~ 0 
2. 
RY 
~ 0 
3. 
S 
~ Y 
4. 
Y 
~ R+Y 
5. 
Y 
~ S+y 
may be interpreted as follows: 
1. "Set and Reset cannot be high simultaneously." 
2. "Reset and the next state cannot be high simultaneously." 
3. "If Set is high, the next state will be high." 
4. "If the present state is high, then Reset is high or the next state will 
be high." 
5. "If the next state will be high, then Set is high or the present state is 
high." 

132 
CHAPTER 5. SYLLOGISTIC REASONING 
These statements, though doubtless not as intuitive to a designer as are 
the characteristic equation and input constraint, provide a standardized and 
complete specification for the RS flip-flop. The specification is complete in 
that any clause that can be inferred from the given premises is a superclause 
of one of the prime clauses. Thus all simplified deduced clauses are present 
among the prime clausesj clause 1 for example may be deduced from clauses 
2 and 3. 
5.5 
Producing and Verifying Consequents 
Let us consider two collections of logical data, one reducible to the equation 
f = 0 and the other reducible to the equation 9 = O. We assume as before 
that the functions f and 9 are expressed as SOP formulas. As we have seen, 
the equation 9 = 0 is a consequent of f = 0 if and only if each term of 9 
is included in some term of BCF(J). Given BCF(J), therefore, the task of 
verifying consequents of f becomes a matter of term-by-term comparison. 
The task of producing consequents may similarly be performed, as we now 
demonstrate, on a termwise basis. 
5.5.1 
Producing Consequents 
To illustrate the process of producing consequents systematically, let us 
return to Example 5.0.1, concerning Alfred's collegiate endeavors. The 
premises reduce to the equation f = 0, where 
BCF(J) = E'S' + G' . 
(5.27) 
An equation 9 = 0 is therefore an Alfred-consequent if and only if each term 
of 9 is included in either E'S' or G'j we tabulate the possible terms of g, in 
terms of propositions E, G, and S, in Table 5.l. 
Every function 9 forming a consequent 9 = 0 of the Alfred- premises (and 
nothing else) is assembled as the disjunction of a subset (possibly empty) of 
the eleven distinct terms enumerated in Table 5.1 (the term E'G'S' appears 
twice). Some of the consequents thus assembled are the following: 
E'S' + E'G' + G'S = 0 
EG'S = 0 
E'GS' + EG'S = 0 
0 = o. 

5.5. PRODUCING AND VERIFYING CONSEQUENTS 
133 
Terms included in E'S' Terms included in G' 
E'S' 
G' 
E'G'S' 
E'G' 
E'GS' 
EG' 
G'S' 
G'S 
E'G'S' 
E'G'S 
EG'S' 
EG'S 
Table 5.1: Terms included in E'S' + G'. 
There are 211 = 2048 SOP g-formulas, distinct to within congruence, in the 
three letters E, G, and S that may be assembled in this way. The function 
j, however, covers 5 minterms on E, G, and Sj thus there are only 25 = 32 
distinct g-functions included in j. Although there is redundancy from a 
functional standpoint, each of the 2048 g-formulas represents a distinct set 
of clauses deducible from the premises. The third of the four consequents 
above, for example, corresponds to the following set of clauses: 
G --+ E+S 
ES --+ G 
"If Alfred gets good grades 
then Alfred enjoys college 
or Alfred studies." 
"If Alfred enjoys college 
and studies 
then Alfred gets good grades." 
5.5.2 Verifying Consequents 
Let us decide whether the following proposition is a consequent of the Hal-
loween-party premises of Example 5.4.1: 
"If Alice and Ben both go to the party, or if neither of them goes, 
then Diane will go or Charlie will not go." 
As a symbolic conditional: 
A' B' + AB --+ C' + D . 
(5.28) 

134 
CHAPTER 5. SYLLOGISTIC REASONING 
As an equation: 
A' B'CD' + ABCD' = 0 . 
(5.29) 
To verify that (5.29) is a valid consequent of the Halloween-party premises, 
we recall the Blake canonical form (5.26): 
BCF(J) = BC'D + B'CD' + A . 
The term A' B'CD' of (5.29) is included in the term B'CD' of BCF(J)j 
likewise, the term ABCD' of (5.29) is included in the term A of BCF(J). 
Hence, 9 <:: BCF(J) , and thus 9 ~ f. We conclude therefore that the 
proposed consequent is valid. 
5.5.3 Comparison of Clauses 
The procedure we have just employed is to compare terms of 9 with terms 
of Be F(J). We may also proceed by expressing a proposed consequent as 
a system of clauses, each of which we compare with the prime clauses. Let 
us suppose that terms p and q correspond, respectively, to clauses P and Q. 
Then p is included in q if and only if P is a superclause of Q, i.e., if and only 
if each letter appearing in the clause Q also appears, on the same side, in 
the clause P. The relevant clauses for the Halloween party are listed below. 
Prime Clauses 
BD -
C 
C 
-
B+D 
A 
-
0 
Clauses of Proposed Consequent 
C 
-
A+B+D 
ABC -
D 
We observe that C -_ A + B + D is a superclause of the prime clause 
C -
B + D and that ABC -
D is a superclause of the prime clause 
A _ 
0, verifying that the system of clauses shown on the right above is a 
valid consequent of the system of prime clauses shown on the left. 
5.6 
Class-Logic 
Our examples thus far have been propositional. Let us now consider a prob-
lem in class-logic. 

5.6. CLASS-LOGIC 
135 
Example 5.6.1 On p. 112 of his Symbolic Logic [34], Lewis Carroll asks 
his readers to find conclusions deducible from the following premises: 
(1) 
Babies are illogical. 
(2) 
Nobody is despised who can manage a crocodile. 
(3) 
Illogical persons are despised. 
An appropriate universe is the set of human beings, among whose classes 
are the following: B = babies; M = able to manage a crocodile; D = de-
spised; and L = logical. We write the premises as inclusions and as equations: 
Inclusions 
(1) B 
~ L' 
(2) M 
~ D' 
(3) L' 
C D 
Equations 
BL 
0 
MD 
0 
L'D' 
= o. 
(We have used the set-notation ~ for inclusion; the generic notation ~ for 
inclusion in a Boolean algebra may also be used.) 
The premises are equivalent to the single Boolean equation f = 0, where 
f = B L + M D + L'D'. Converting f to Blake canonical form, we obtain 
BCF(f) = BL + MD + L'D' + BD' + ML' + BM. 
The prime consequents, in clausal form, are the following: 
(a) BL 
C 
0 
(b) 
MD 
C 
0 
(c) 
1 
C L+D 
(d) B 
C D 
(e) M 
~ L 
(f) BM 
C O. 
Prime consequents (a), (b), and (c) are the clausal forms, respectively, of 
premises (1), (2), and (3). Prime consequents (d), (e), and (f) may be given 
the following interpretations: 
(d) 
Babies are despised. 
(e) 
Anybody who can manage a crocodile is logical. 
(f) 
No baby can manage a crocodile. 
All of the premises survive as prime consequents because Carroll's ex-
ample has a specialized logical form, called "sorites," which may be resolved 
into a chain of simple inclusions. The inclusion-chain for this example is 
BeL' CDC M'. 

136 
CHAPTER 5. SYLLOGISTIC REASONING 
5.7 
Selective Deduction 
An important class of logical problems involves selective deduction from 
given hypotheses. The following example is a. modification of one given by 
Ledley [113]. 
Example 5.7.1 Enzyme biochemistry has two characteristic features. First, 
it is usually difficult to isolate an enzyme in pure form, and thus the chemist 
must deal with imprecise and indirect knowledge of the enzyme content of 
the experimental ingredients. Second, usually more than one chemical reac-
tion takes place at once, and even these are observed indirectly. Suppose a 
chemist is studying enzymes A, B, and C in relation to reactions X, Y, and 
Z. He has completed the following experiments: 
1. In the first experiment, a solution containing neither A, B, nor C 
produced reaction Y but neither X nor Z. 
2. In the second experiment, the solution contained A and either B or C 
or both (the chemist could not be sure); the reaction was neither Y 
nor was it X and Z together. 
3. In the third experiment, the solution had B but not A, or did not have 
B but had C. Reactions X and Y occurred, or reaction X did not 
occur but Z did. 
4. In the fourth experiment, the chemist obtained a solution from a source 
that had C, together with A or B or both, or else had neither A nor 
C. Either reaction X did not take place, or both Y and Z did. 
5. In the fifth experiment, a solution containing A but not B either failed 
to produce reaction X or failed to produce reaction Z. 
Having made the foregoing observations, the chemist seeks answers, in the 
simplest possible form, to the following questions: 
(a) What is known concerning the reactions X, Y, and Z, independent of 
any knowledge of enzyme content? 
(b) What is known concerning the enzymes A, B, and C, given each ofthe 
following reactions? 

5.7. SELECTIVE DEDUCTION 
i) 
X occurred; 
ii) 
X did not occur; 
iii) 
Z occurred; 
iv) 
Z did not occur. 
137 
Our approach will be to reduce the information provided by experiments 
1 through 5 to a single equation f = 0, and then to express the function f 
in Blake canonical form. This form enables the chemist to eliminate conve-
niently the variables not of current interest. 
The experimental information is expressed by the following system of 
conditionals: 
(1) A' B'C' 
(2) A(B + C) 
(3) A'B + B'C 
(4) C(A + B) + A'C' 
(5) AB' 
---7 
---7 
---7 
---7 
---7 
X'YZ' 
Y'(X' + Z') 
XY+X'Z 
X'+YZ 
X'+ Z' 
This system is equivalent to the single equation f = 0, where f is expressed 
by 
f = A'B'C'(X+Y'+Z)+ 
+A(B + C)(Y + XZ) + 
+(A' B + B'C)(XY' + X'Z') + 
+(AC + BC + A'C')X(Y' + Z') + 
+AB'XZ. 
In Blake canonical form: 
BCF(J) = ACX + AXZ + ACY + AB'CZ' + ABY + A'XY' + CXY' + 
+Xy'Z + A'y'Z' + B'CY'Z' + A'CX'Z' + CX'YZ' + 
+B'CX'Z' + A'B'C'X + B'C'XZ + A'B'C'y' + A'B'C'Z + 
+A'BZ' + BCXZ' + BYZ' + A'C'XZ' . 
To answer question (a) posed by the chemist, we eliminate A, B, and C 
from the equation f = O. This may be done simply by deleting from the 
equation BCF(f) = 0 every term involving A, B, or C (cf. Theorem 4.8.2). 
The result, 
Xy'Z = 0, 

138 
CHAPTER 5. SYLLOGISTIC REASONING 
takes the clausal form 
XZ--+Y. 
Thus the following is known, independent of any knowledge of enzyme con-
tent: if reactions X and Z occur together, then reaction Y occurs also. To 
answer the first and second parts of question (b), we eliminate Y and Z from 
BC FU) = 0; to answer the third and fourth parts of (b), we eliminate X 
and Y. The resultants of elimination are: 
Eliminating Y and Z: 
A' B' C' X + AC X 
= 0 
Eliminating X and Y: AB' C Z' + A' B' C' Z + A' B Z' = 0 
The foregoing equations enable us to answer the chemist's question (b), in 
clausal form, as follows: 
i) AC --+ 0 
1 
--+ A+B+C 
ii) NO INFORMATION 
iii) 1 
--+ A + B + C 
iv) AC --+ B 
B 
--+ A 
5.8 
Functional Relations 
Suppose we wish to look for relations among a collection ft, 12, .. ·, 1m 
Bn --+ B of Boolean functions. Let the functions in such a collection be 
represented, respectively, by formulas Ft , F2 , ••• , Fm on the argument-vector 
X = (Xl! ... ,xn ). The system 
At = Ft(X) 
A2 = F2(X) 
(5.30) 
associates the symbols in the vector A = (At. ... , Am) with the correspond-
ing formulas. All of the relations implied among the original functions are 
therefore encoded economically in those prime consequents of (5.30) which 
do not involve any of the X -arguments; let us call these the A-consequents 
of (5.30). Such consequents are equations whose right-hand sides are zero; 
let us call their left-hand sides the A-consequent terms. 

5.8. FUNCTIONAL RELATIONS 
139 
The label-and-eliminate procedure. 
The A-consequent terms of 
(5.30) are generated by reducing (5.30) to a single equivalent equation of 
the form g(A,X) = 0, expanding g(A,X) into Blake canonical form, and 
selecting those terms not involving X -variables. Computational efficiency is 
improved if the X -variables are eliminated prior to the Blake-expansion. In 
detail: 
Step 1. Reduce (5.30) to the single equivalent equation 
g(A,X) = o. 
(5.31) 
Step 2. Eliminate X from (5.31), yielding the resultant 
ECON(g(A,X),X) = o. 
(5.32) 
Step 3. Express the left side of (5.32) in Blake canonical form, i.e., 
BCF(ECON(g(A,X),X)) = o. 
(5.33) 
Example 5.8.1 Consider the Boolean functions labelled by the system 
Al = Xl + X2 
A2 = Xl 
(5.34) 
A3 
Xl X2 
A4 = x' 2 
The output of a program to derive the A-consequent terms from (5.34) 
is listed below: 
Al A2'A4 
A2'A3 
A2 A3'A4' 
Al' A2 
Al'A3 
A3 A4 
Al'A4' 

140 
CHAPTER 5. SYLLOGISTIC REASONING 
The corresponding clauses, Le., the prime clauses of (5.34), are as follows: 
Ai A4 
---) A2 
A3 
---) A2 
A2 
---) A3 + A4 
A2 
---) Ai 
A3 
---) Ai 
A3 A4 
---) 0 
1 
---) Ai + A4 
These seven clauses, corresponding to the terms on the left side of (5.33), 
constitute a simplified and complete representation of the relations holding 
among the original functions. Typically only relations of specialized form 
are sought; three such specializations are discussed in the following sections. 
5.9 
Dependent Sets of Functions 
Questions concerning the dependence of collections of sets, propositions, or 
Boolean functions have been widely investigated; see Marczewski [128] for 
citations to early work. A set of k propositional or switching functions is 
customarily said to be independent in case all 2k combinations of values are 
possible. This interpretation of independence has been applied to the de-
sign of switching circuits by Muller [141], Kjellberg [102], and Ledley [118]. 
Ledley has applied it also to problems in enzyme biochemistry [115]. Kuntz-
mann [110] and Small [189] have employed this interpretation to arrive at 
results concerning the decomposition of switching functions. 
The foregoing interpretation is applicable to two-valued sets such as those 
comprising axioms, propositions, or switching functions, but is inadequate 
for sets of Boolean functions on an arbitrary Boolean algebra. Let B be 
such a Boolean algebra, let T = {h, 12, ... , fm} be a set of Boolean func-
tions mapping Bn into B, and let S = {h, 12, ... , fk} be a subset of T 
(the first k elements of T are selected, without loss of generality). As in 
Brown & Rudeanu [26, 29] (see also Marczewski [128]), we call the subset 
S functionally dependent provided there is a non-constant Boolean function 
h: Bk----+ B for which the identity 
hChCX), ... , hCX)) = 0 
(5.35) 
is fulfilled; otherwise S will be called functionally independent. 

5.9. DEPENDENT SETS OF FUNCTIONS 
141 
We consider two problems concerning the set T. The first is to establish 
whether a given subset of T is dependent. The second is to produce an 
economical representation for the family of all dependent subsets of T and 
the complementary family of all independent subsets. 
Every subset of of an independent set is independent; in particular, the 
empty set is independent. Every superset of a dependent set is also depen-
dent; if the family of dependent subsets is not empty, therefore, the entire 
set T is dependent. An independent set is maximal in case there is no inde-
pendent set strictly including it; a dependent set is minimal in case there is 
no dependent set strictly included in it. A subset of T is dependent (inde-
pendent), therefore, if and only if it includes a minimal dependent set (it is 
included in a maximal independent set). Let us denote by 1M AX the class 
of maximal independent subsets of T and by DMIN the class of minimal 
dependent subsets of T. 
It follows from our definition of functional dependence and from the dis-
cussion in Section 5.8 that a subset S of T is dependent if and only if all of the 
letters in an A-term derived from (5.30) belong to the set {AI, A2 , • •• , Ak} 
ofletters associated with S. 
To derive the maximal independent and minimal dependent subsets of T, 
we construct a complement-free SOP formula W from (5.33) as follows. If 
BGF(EGON(g(A,X),X)) is null, then W is defined to be null; otherwise, 
the terms of Ware formed in one-to-one correspondence with the terms of 
BGF(EGON(g(A, X), X)) by 
(i) 
deleting all constants (elements of B), and 
(ii) 
replacing either Ai or A~ by Ai (i = 1,2, ... , m). 
Each term of the formula BG F( EGO N (g( A, X), X)) contains at least one 
A-letter; hence step (i) cannot annihilate a term. 
Let w: {O, 1}n --+ {0,1} be the Boolean function represented by the 
formula W; we call w the dependency function associated with the system 
(5.30). In the case of independence (Le., internal stability) of the vertices 
of a graph, the complement w' of w is the Boolean function introduced by 
Maghout [126, 127] and Weissman [211]. 
The following result is proved in Brown & Rudeanu [29]: 

142 
CHAPTER 5. SYLLOGISTIC REASONING 
Theorem 5.9.1 Let T = {It, 12, ... , fm} be a set of Boolean functions, let 
S = {It, ... , fk} be a subset of T, let S' = T - S be the set-complement of 
S relative to T and let w be the function defined above. Then 
(a) S is a minimal dependent subset ofT if and only if AI·· ·Ak is a term 
of BCF(w). 
(b) S' is a maximal independent subset of T if and only if A~ ... Ak is a 
term of BCF(w' ). 
Example 5.9.1 Let us find the maximal independent and minimal depen-
dent subsets of the set T = {It, 12, h, f4} of Boolean functions specified by 
the system 
Al = bx + y 
A2 = bx 
A3 = X + biZ 
A4 = Y 
on the Boolean algebra B = {O, 1, b', b}. 
We first produce the set of A-terms: 
Al A3'A4' 
At A4'B' 
At A2' A4' 
Al'A4 
A2'A3 B 
A2 A3' 
A2 B' 
At'A2 
Al'A3 B 
Hence 
BCF(w) = AIA3 + A2 + AIA4 
BC F( Wi) = A;A;A~ + A~ A; . 
We conclude from Theorem 5.9.1 that 
DMIN = HIt,h},{h},{It,f4}} 
IMAX = Hit}, {h,f4}} . 
The family D MIN generates 11 dependent subsets of {It, 12, h, f4}; the 
family 1M AX generates 5 independent subsets. 

5.10. SUM-TO-ONE SUBSETS 
143 
5.10 
Sum-to-One Subsets 
The tautology problem is discussed in Section 4.11. An associated prob-
lem arising in a number of applications is to find all minimal sum-to-one 
subsets of a set T = {tI(X),t2(X), ... ,tm(X)} of terms (products). Such 
subsets correspond to the A-terms implied by (5.30) consisting entirely of 
complemented literals. In Example 5.8.1, therefore, there is only one min-
imal sum-to-one subset, corresponding to the A-term AIA4 (if AIA4 = 0, 
then Al + A4 = 1). 
It is readily verified that the subset {iI, f4} sums to one and no other 
subsets (save supersets of {iI, f4}) sum to one. 
Although the process just discussed (searching for A-terms of (5.30) con-
sisting entirely of complemented literals) generates minimal sum-to-one sub-
sets, it is an unnecessarily complex way to do the job. A more direct ap-
proach is based on the auxiliary summation 
The utility of this formula is based on the following result: 
Lemma 5.10.1 Let T = {tI(X), t2(X), ... , tm(X)} be a set of terms, where 
X = (x}, ... , xn ), and let AI, A2, ... , Am be Boolean variables. Let S = 
{tI(X), t2(X), ... , tk(X)} (1::; k ::; m) be a subset ofT. Then the conditions 
(a) 
tI(X) + t2(X) + ... + tk(X) = 1 
(b) 
AIA2 .. ·Ak ::; AltI(X) + ... + Amtm(X) 
are equivalent for all X E {O,l}n. 
Proof. Condition (b) is equivalent to the equation 
which may be expressed equivalently as 
A~ + ... + Ale + tI(X) + ... + tk(X)+ 
+Ak+ltk+I(X) + ... + Amtm(X) = 1. 
(5.36) 
Thus (a) implies (b). To show that (b) implies (a) for all X E {O, 1}n, let us 
suppose that there is a member, K, of {O, 1}n such that (a) is false, i.e., for 
which tI(K) + ... + tk(K) = 0. Then (5.36) becomes 
A~ + ... + Ale + Ak+Itk+I(K) + ... + Amtm(K) = 1 , 

144 
CHAPTER 5. SYLLOGISTIC REASONING 
which is not an identity; thus (b) is false. Hence (b) implies (a). 0 
Constructing Minimal sum-to-one subsets. Lemma 5.10.1 shows 
that the problem of finding sum-to-one subsets of a set T of terms reduces to 
that of finding A-products included in a summation associated with T. Any 
superset of a sum-to-one subset is a sum-to-one subset; hence, the entire 
collection of sum-to-one subsets is generated conveniently by the minimal 
sum-to-one subsets. The task of finding such subsets is eased by the following 
theorem: 
Theorem 5.10.1 Let T = {tl(X),t2(X), ... ,tm(Xn be a set of terms, 
where X = (xt, ... ,xn ), and let A1,A2, ... ,Am be Boolean variables. Let 
S = {tl(X),t2(X), ... ,tk(Xn (1 $ k $ m) be a subset ofT. Then S is a 
minimal sum-to-one subset of T if and only if the product AIA2 ... All: is a 
term of BCF(A1tl(X) + ... + Amtm(X». 
Proof. 
Denote by G(A,X) the function Altl(X) + ... + Amtm(X). 
The following statements are equivalent: 
(i) 
S is a sum-to-one subset of T. 
(ii) 
A I A2· .. Ak $ G(A,X). 
(iii) 
A1A2·· ·Ak $ p, where p is a term of BCF(G(A,X». 
The equivalence between (i) and (ii) follows from Lemma 5.10.1; that be-
tween (ii) and (iii) from Lemma A.3.2. Thus S is a sum-to-one subset of T 
if and only if a subproduct of AI A2·· ·Ak is a term of BCF(G(A,X». The 
set S is therefore a minimal sum-to-one subset of T if and only if Al A2 ... Ak 
is a term of BCF(A1tl(X) + ... + Amtm(X», 0 
Example 5.10.1 Consider the collection of terms named in the system 
tl = X 
t2 = x'y 
t3 = y'z' 
t4 = Z 
ts = x'y' 
t6 = yz' 
We derive from this system the formula 
Alx + A2x'y + A3Y' z' + A4Z + Asx'y' + A6yz' 
and generate the associated a-terms as follows: 

5.11. IRREDUNDANT FORMULAS 
Ai A2 A3 A4 
Ai A2 A5 
Ai A4 A5 A6 
A3 A4 A6 
145 
The minimal sum-to-one subsets, corresponding to the foregoing A-terms, 
are {It, 12, 13, /4}, {It, 12, Is}, {It, /4, 15, 16}, and {f3, /4, 16}. 
5.11 
Irredundant Formulas 
The problem of minimizing the complexity of Boolean formulas is important 
in technology, and has received extensive attention in the literature. We 
show in this section that minimal sum-of-products (SOP) formulas for a 
Boolean function may be generated via syllogistic reasoning. 
Let us review, from Section 4.11, the major points concerning the prob-
lem of finding a simplified SOP formula for a Boolean function I. Such a 
formula is necessarily a subformula of BCF(f). An irredundant formula for 
/ is a subformula of BCF(f) that (a) represents I and (b) ceases to repre-
sent I if any of its terms is deleted. The search for simplified SOP formulas 
therefore need only be over the irredundant formulas. 
Quine [161] presented a tabular method for finding all of the irredundant 
formulas for a given function. Algebraic alternatives have been suggested by 
Samson & Mueller [175], Petrick [154], Ghazala [70], Mott [140], Cutler & 
Muroga [43] and others. 
Incompletely-specified functions. 
Associated with the foregoing 
problem is the more general problem of finding simplified SOP formulas for 
an incompletely specified Boolean function /. Such a function is defined by 
an interval, i.e., 
g(X) ~ I ~ h(X) 
(5.37) 
(c/. Section 2.4) in which 9 and h are given Boolean functions. Each function 
in the interval (5.37) is represented by a set of irredundant SOP formulas; 
call it the I-set for that function. We define a formula to be an irredundant 
formula for the incompletely-specified function I provided (a) it belongs to 
one of the I-sets associated with the interval (5.37) and (b) none of its proper 
subformulas belongs to such an I-set. 
It is a well-known result in switching theory that the irredundant formu-
las for the incompletely-specified function (5.37) are the minimal subformu-

146 
CHAPTER 5. SYLLOGISTIC REASONING 
las of BCF(h) that cover gj therefore an SOP formula S is an irredundant 
formula for (5.37) if and only if 
(a) 
S is a subformula of BCF(h), 
(b) 
9 ~ S, and 
(c) 
no proper subformula of S has property (b). 
All of the formulas satisfying the foregoing conditions are readily found 
by syllogistic reasoning, using a variation of the label-and-eliminate tech-
nique described in Section 5.8. 
Theorem 5.11.1 Let 9 and h be the Boolean functions specified by interval 
(5.37), let PI, ... , Pm be the prime implicants of h, let <p = 0 be equivalent to 
the system 
u = g(X) 
PI(X) = Al 
Pm(X) = Am, 
(5.38) 
and let Aap ... , Aak be symbols in the set {AI. ... , Am}. Then the SOP 
formula 
Pal + ... + Pak 
(5.39) 
is an irredundant formula for (5.37) if and only if 
(5.40) 
is a prime implicant of <p. 
Proof. Formula (5.40) is a prime implicant of <p if and only if the relation 
u ~ Aal + ... + Aak is a prime consequent of system (5.38), i.e., if and only 
if the function 9 satisfies the conditions 
(i) 
9 :5 
Pal + ... + Pak 
(ii) 9 1: any proper subformula of Pal + ... + Pak , 
where Pal + ... + Pak is a subformula of BCF(f). 0 
The process of deduction is simplified if the X-variables are eliminated 
from (5.38) before the prime implicants are sought, i.e., if we follow the 
label-and-eliminate procedure of Section 5.8. 

5.11. IRREDUNDANT FORMULAS 
147 
Example 5.11.1 Let an incompletely-specified function f be defined by the 
interval (5.37), where 9 and h are given by the formulas 
g(x,y,z) 
x'yz + xy' 
h(x,y,z) = 
x' z + xy' + yz' . 
Thus (5.38) takes the form 
u 
x'yz + xy' 
x'z = 
Al 
xy' 
A2 
yz' 
A3 
(5.41) 
y'z 
A4 
x'y 
As 
xz' 
A6 . 
System (5.41) is equivalent to an equation 4>(AI , ... , A6 , U, x, y, z) = 0 for 
which the prime implicants of ECON(4), {x,y,z}) are 
Ai A4'U' 
A2' AS U 
AS AS 
Ai'A4 U' 
A3 U 
Ai A2 
A2 U' 
Ai AS'U 
A2 A3 
A3'AS U' 
Ai' AS U 
A2 AS 
A3'AS U' 
Ai'A2'U 
A2 A4'AS' 
Ai AS U' 
Ai AS 
A3 A4 
Ai'A4'AS'U 
Ai A3 
A4 A6 
A4'AS'A6'U 
A2'A3'AS 
A4 AS 
Ai A4 U 
Ai' A3' AS 
Ai'A2'A4 
A2'A4 U 
A3 AS'A6' 
Ai A4'AS' 
A2'AS'U 
The prime implicants corresponding to irredundant formulas are those hav-
ing the form A~l ... A~k u, viz., A~ A~A~u, A~A~A~u, A~A~u, and A~ A~u. 
Thus the irredundant formulas in the given interval are 
x'z + y'z + xz' 
y'z + x'y + xz' 
x'y' + x'y 
x'z + x'y' . 

148 
CHAPTER 5. SYLLOGISTIC REASONING 
Of the 31 prime implicants in the foregoing example, only four have the 
form corresponding to an irredundant formula. A modification of system 
(5.38) leads to more economical results: 
Corollary 5.11.1 Let g, hand Pt, ... ,Pm be as defined in Theorem 5.11.1 
and let 4> = 0 be the equation to which the system 
U 
~ g(X) 
Pt(X) < At 
Pm(X) < Am 
(5.42) 
reduces. Then the prime implicants of ECON(4), X) are in one-to-one cor-
respondence, in the manner described in Theorem 5.11.1, to the irredundant 
formulas in the interval (5.37). 
Proof. The proof is left as an exercise. 
Example 5.11.2 For the incomplete function f specified in Example 5.11.1, 
system (5.42) takes the form 
U < 
x'z 
~ 
xy' < 
yz' < 
y'z < 
x'y < 
xz' < 
which is equivalent to 4> = 0, where 
4> = ux'y' + ux' z' + UXll + 
x'yz + xy' 
At 
A2 
A3 
A4 
As 
A6 , 
+A~x'z + A~xy' + A~yz' + A~y'z + A~x'y + A~xz' . 
Hence, in Blake canonical form, 
(5.43) 
ECON(4), {x, y, z}) = A~A~u + A~A~A~u + A~A~u + A~A~A~u. 
The prime implicants of ECON(4), {x, y, z}) are thus precisely those found 
in Example 5.11.1 to correspond to irredundant formulas. 

EXERCISES 
149 
Completely-specified functions. An ordinary (completely-specified) 
function may be regarded as a one-element interval of the form (5.37), Le., 
one for which g(X) = heX). The procedure for generating the irredun-
dant formulas for an ordinary function is therefore identical to that for an 
incompletely-specified function. 
Exercises 
1. Five workers-V, W, X, Y, and Z-are available to perform a cer-
tain task. In choosing a hiring-list, the following conditions must be 
satisfied: 
(a) Either X and Yare both hired, or neither is hired. 
(b) At least one of V, X, or Z must be hired. 
( c) If V is hired, then X or Y (or both) must be hired. 
(d) If X and Yare hired, then Z must be hired. 
(e) If Z is not hired, then W must be hired. 
Express the prime consequents in clausal form. 
2. The state of a mechanism under test is shown by 5 indicators, labelled 
A, B, C, D, and E. After watching the indicators for a long time, an 
observer characterizes the mechanism as follows: 
(a.) If A or D is on (but not both), then C is on. 
(b) Looking just at C, D, and E, the number of on-indicators is 
alwa.ys odd. 
( c) If E is off, then A and D are both off. 
(d) If Band C are both on, then E is on. 
(e) At least one of the following conditions always exists: 
L A on. 
ii. C off. 
iii. Don. 
Express the prime consequents in clausal form. 

150 
CHAPTER 5. SYLLOGISTIC REASONING 
3. Test the validity of the following argument. 
PREMISES 
CONCLUSION 
PQ 
--+ (R + S)(R' + S') 
P 
--+ Q' 
S 
--+ (QR + Q'R') + P' 
QR --+ S 
4. Let P, Q, R, and S be elements of a Boolean algebra and suppose we 
are given the following premises: 
.Q+R=l 
• P' + Q = P'R' + PQ 
• If PQ' = 1, then R' + S' = 1. 
• QS=O 
• If P = Q, then R = 1. 
(1) List the prime consequents. 
(2) Test the validity of each of the following proposed consequents of 
the given premises. 
(a) If Q = 1, then P = R'. 
(b) P+Q = R 
(c) If P = R, then P + Q = o. 
(d) P'S'(QR + Q'R') = o. 
5. (Keynes [101], Part IV) At a certain examination, 
(a) all the candidates who were entered for Latin were also entered 
for either French, German, or Spanish, but not for more than one 
of these languages; 
(b) all the candidates who were not entered for German were entered 
for at least two of the other languages; and 
(c) no candidate who was entered for both French and Spanish was 
entered for German, but all candidates who were entered for nei-
ther French nor Spanish were entered for Latin. 
Show that each candidate was entered for exactly two of the four lan-
guages. 

EXERCISES 
151 
6. The following problem, given in Chapter IX of Boole's Laws of Thought, 
was used as an example by Schroder [178], Venn [210], Peirce [151]' 
Ladd [111], and other nineteenth-century logicians; Schroder called it 
the "touchstone" for his work. It was also used by Blake [10] in the 
first published example of the generation of prime implicants. 
Suppose that an analysis of properties a, b, e, d, and 
e of a particular class of substances leads to the following 
statements: 
(1) Whenever properties a and e are missing, then property 
e is found, together with one of the properties band d, 
but not both. 
(2) Whenever the properties a and d are found while e is 
missing, then both band e will either both be found or 
both be missing. 
(3) Whenever property a is found in conjunction with either 
b or e, or both of them, then e or d will also be found, 
but not both of them. Conversely, whenever e or d (but 
not both) is found, then a will be found in conjunction 
with either b or e or both of them. 
(a) Reduce all of the foregoing data to a single Boolean equation of 
the form f(a,b,e,d,e) = o. 
(b) Construct BCF(f). 
( c) What independent relations among b, e, and d may be inferred? 
What among these three may be inferred if a = I? 
(d) What independent relations among a, e, and d may be inferred? 
What with the further hypothesis b = I? 
(e) Which of the following is a valid consequent of the premises (1), 
(2), (3)? 
i. ad ---+ b' e' + e' e 
ii. a' e' ---+ be 
lll. a + be ---+ ee 
iv. abc ---+ 0 

152 
CHAPTER 5. SYLLOGISTIC REASONING 
7. Suppose that our knowledge of aardvarks (class A), creatures who kiss 
babies (K), courteous creatures (C), and politicians (P) is expressed 
by the following statements: 
(a) Politicians who do not kiss babies are courteous. 
(b) Courteous aardvarks are not politicians. 
(c) Aardvarks who kiss babies are courteous politicians. 
(d) All politicians either kiss babies, or are aardvarks, or both. 
State all of the prime consequents, in clausal form, of the foregoing 
data. 
8. (Venn [210], Chapter XIII) There is a certain class ofthings from which 
A picks out the X that is Z and the Y that is not Z, and B picks out 
from the remainder the Z which is Y and the X that is not Y. It is 
then found that what is left exactly comprises Z which is not X. 
(a) State the implied constraint (if any) relating X, Y, and Z. 
(b) Assuming the constraint to be satisfied, what can be determined 
about the original class? 
9. The RST flip-flop is defined by the equations 
Y = S + yR'T' + y'T 
0= RS+RT+ ST 
(characteristic equation) 
(input constraint) 
where y and Yare the present state and next states, respectively, of 
the flip-flop. List the prime consequents in clausal form. Each such 
consequent represents a fundamental property of the RST flip-flop. 
10. (Corollary 5.11.1) Let g, hand Pb'" ,Pm be as defined in Theo-
rem 5.11.1 and let 1> = 0 be the equation to which the system 
u 
~ g(X) 
PI(X) 
~ Al 
Pm(X) < Am 
reduces. Show that the prime implicants of ECON(1), X) are in one-
to-one correspondence, in the manner described in Theorem 5.11.1, to 
the irredundant formulas in the interval (5.37). 

Chapter 6 
Solution of Boolean 
Equations 
Many problems in the application of Boolean algebra may be reduced to 
that of solving a Boolean equation of the form 
f(X) = 0, 
(6.1) 
over a Boolean algebra B. The specifications for a digital circuit, for ex-
ample, typically take the form of Boolean equations relating a collection 
X = (X1,X2, ••• ,Xn ) of output variables to a collection I = (ib i2, ••. ,ir ) of 
input-symbols. These specifications may be reduced (by Theorem 4.3.1) to 
a single equivalent equation of the form (6.1) over the free Boolean algebra 
(cf. Section 2.13.1) generated by the input-symbols. The designer's task is 
to construct a system 
Xl = 91 
(6.2) 
Xn = 9n 
of Boolean equations in which 91, ... , 9n are formulas in F B( i1 , ••• , ir) that 
(a) specify circuit-structure and (b) accord with the original specifications. 
To meet the latter condition, system (6.2) should imply equation (6.1), i.e., 
it should be an antecedent of (6.1) (cf. Section 4.2). An antecedent system 
of the form (6.2) is a functional antecedent, i.e., a solution, of (6.1). The 
latter term is more common and will be used henceforth. 
153 

154 
CHAPTER 6. SOLUTION OF BOOLEAN EQUATIONS 
Formal procedures for producing solutions of (6.1) were developed by 
Boole himself as a way to treat problems of logical inference, and Boolean 
equations have been studied extensively since Boole's initial work. See 
Rudeanu [172] for a comprehensive modern treatment of Boolean equations 
and a bibliography of nearly 400 sources; among the classical sources are 
Schroder's three-volume text [178] and Couturat's brief and lucid mono-
graph [41]. 
Boolean equation-solving as an approach to the design of relay-networks 
was discussed by Nakasima [145, 146] as early as 1936, and later by Ashen-
hurst [4], Semon [181], and Ledley [113]. Ledley considered applications to 
the design of gate-networks (adders and squaring circuits); he also discussed 
applications in medical diagnosis, enzyme biochemistry, and agricultural ex-
periments. Applications in the design of digital computers were first sug-
gested in the texts by Phister [155] and Ledley [118]; other work has been 
done by Cerny and Marin [36] and by Svoboda and White [193]. 
Among the many fields to which Boolean equation-solving has been ap-
plied systematically are biology, grammars, graph theory, chemistry, law, 
medicine and spectroscopy. Klir and Marin [103] have noted of Boolean 
equations that "their importance for switching theory reminds one of the 
application of differential equations in electric circuit theory." Applications 
in logical design include functional decomposition, fault-diagnosis, binary 
codes, a variety of approaches to combinational synthesis, flip-flop design 
and excitation, hazard-free synthesis, information-Iossless machines, and the 
design of sequential circuits (the latter application has given rise to a special-
ized field of investigation, viz., sequential Boolean equations). An extensive 
survey of applications is given in Rudeanu [172]. 
6.1 
Particular Solutions and Consistency 
A particular solution (or, simply, a solution) of (6.1) is an element 
A = (at. .. . ,an) of Bn such that f(A) = 0 is an identity. A Boolean 
equation is consistent provided it has at least one solution. 
The one-variable Boolean equation f(x) = 0 is an important special case, 
whose consistency we now study. We recall from Sections 4.7 and 4.8 that 
the resultant of elimination of x from the equation f(x) = 0 is the equation 
ECON(J,{x}) = O. 

6.1. PARTICULAR SOLUTIONS AND CONSISTENCY 
155 
Lemma 6.1.1 The Boolean equation f(x) = 0 is consistent if and only if 
the condition 
EGON(f, {x}) = 0 
(6.3) 
is satisfied. 
Proof. 
Suppose a E B is a solution of f( x) = 0, i.e., suppose that 
f(a) = O. Then a'f(O) + af(l) = 0, by Boole's expansion theorem, whence 
a' f(O) + af(l) + f(O)f(l) = 0 by consensus. Thus f(O)f(l) = 0, i.e., 
EGON(f,{x}) = O. Suppose on the other hand that EGON(f,{x}) = O. 
Then the element f(O) is a solution of f(x) = 0, for 
f(f(O» = (f(O»'f(O) + f(O)f(l) = 0 + EGON(f(x), {x}) = 0 + 0 = o. 
Thus f( x) = 0 is consistent, proving the theorem. 0 
We call the equation EGO N (f, {x}) = 0 the consistency condition for 
f(x) = o. The consistency condition for an n-variable Boolean equation is a 
direct extension, as we now show, of that for a one-variable equation. 
Theorem 6.1.1 The n-variable Boolean equation (6.1) is consistent if and 
only if the condition 
(6.4) 
is satisfied. 
Proof. 
Suppose (6.1) is consistent, i.e., f(A) = 0 for some n-tuple A 
in Bn. Then (6.4) follows by Theorem 4.8.4. Conversely, suppose that 
condition (6.4) is satisfied. We show by induction that (6.1) is consistent for 
all n ;;:: 1. If n = 1, then (6.1) is consistent by Lemma 6.1.1. Suppose (6.1) 
to be consistent if n = k (k > 1) and consider the (k + I)-variable equation 
f(xll ... ,Xk,Xk+1) = O. Condition (6.4) then takes the form 
EGON(f,RU {XHI}) = 0, 
(6.5) 
where R = {X}, ... ,Xk}' Let us define g: Bk __ B by 
g(XI, ... ,Xk) = f(XI, ... ,Xk,O)f(XI, ... ,Xk,I). 
Condition (6.5) implies that EGON(EGON(f, {Xk+1}), R) = 0, which im-
plies by the induction hypothesis that EGON(f, {XHI}) = 0 is consistent, 
i.e., that g( a}, ... , ak) = 0 for some k-tuple (a}, ... , ak) in Bk. Therefore 
f(all ... ,ak,O)f(a}, ... ,ak,l) = 0, whence by Lemma 6.1.1 the equation 
f(all ... ,ak,xHd = 0 has a solution, call it ak+}' in B. Thus the equation 
f(x}, . .. , Xk, XHI) = 0 is consistent. 0 

156 
CHAPTER 6. SOLUTION OF BOOLEAN EQUATIONS 
6.2 
General Solutions 
A general solution of a Boolean equation is a representation of the set, S, of 
its particular solutions. Although S may be represented by an explicit list, 
such a representation may obscure regularities in the form of the solutions. 
The number of solutions, moreover, may be so large that enumeration is 
not feasible. Fortunately, the solutions of a Boolean equation are related 
in such a way that condensed representations for S are readily constructed. 
One such representation is an interval (or intervals) defined by lower and 
upper bounds. Another representation is by means of a formula (or formu-
las) involving arbitrary parameters. The following theorem specifies such 
representations for the solutions of a single-variable Boolean equation. 
Theorem 6.2.1 Let f: B--B be a Boolean function for which the equation 
f(x) = 0 is consistent, and let S = {x I f(x) = O} be the set of its solutions. 
Define subsets of B as follows: 
Then 1= P = S . 
(a) 
I = {x I f(O) ~ x ~ f'(l)} 
(b) P = {f(0) + p!'(l) I p E B} . 
Proof. For notational simplicity we write fo and ft, respectively, in place 
of f(O) and f(l). The equivalence of fo ::; x ::; fl and f( x) = 0 (Proposition 
4.1.1) implies that I = {x I f(x) = O} = S. To prove that P = S, we first 
show that P ~ S : 
f(fo + pfD = (fo + pfD'fo + (fo + pfDft = foft = ECON(f, {x}) = O. 
Thus P ~ S. To verify that S ~ P, we show that for all a in B, the 
implication [a E S ==> a E P] holds, i.e., that for any element a E B there 
is an element p E B such that 
f( a) = 0 
==> 
fo + p f~ = a . 
Noting that f(a) has the expanded form a'fo+aft, applying Theorem 4.4.1 
(the Extended Verification Theorem), and doing some computing, we reduce 
the foregoing implication to an equivalent equation, viz., 
f~f~[PE£) a] = 0, 

6.2. GENERAL SOL UTIONS 
157 
which is satisfied for p = a. Hence S ~ P. 0 
Theorem 6.2.1 shows that the set of solutions of f( z) = 0, if not empty, 
may be expressed either as an intenJal, 
f(O) 5 x 5 f'(I) , 
(6.6) 
or as a parametric formula, 
z = f(O) + pf'(I) , 
(6.7) 
where the symbol p represents an arbitrary parameter, i.e., a freely-chosen 
member of B. Thus each of the two forms (6.6) and (6.7) is a general 
solution of f(x) = O. These forms are condensed, relatively easy to produce, 
and provide a basis for enumerating, if necessary, the entire set of solutions. 
If the consistency-condition (6.4) is not satisfied identically, it should be 
stated as part of the solution. 
Example 6.2.1 Let us find a general solution, having the interval-based 
form (6.6), ofthe equation 
az = b, 
(6.8) 
where a and b are fixed elements of a Boolean algebra B. Equation (6.8) 
reduces to the equivalent equation 
ab' x + a'b + bx' = 0 . 
The general solution (6.6) therefore takes the form 
a'b + b::; x ::; (ab' + a'b)' . 
(6.9) 
(6.10) 
Interval (6.10) constitutes a general solution of (6.9) only if solutions exist, 
i.e., only if (6.9) is consistent. To determine the consistency-condition, given 
by equation (6.4), we calculate the conjunctive eliminant, ECON(f,{x}): 
ECON(j,{x}) = f(O)f(I) 
= (a'b + b)(ab' + a'b) . 
Thus equation (6.8) is consistent if and only if the condition 
a'b = 0 
is satisfied; this condition should accompany (6.10) as a complete statement 
of the general solution. 

158 
CHAPTER 6. SOLUTION OF BOOLEAN EQUATIONS 
It often happens that the the consistency-condition can be used to sim-
plify the form of a general solution. For example, the implication 
a'b = 0 ==> 
a'b' + ab = a' + b 
enables the general solution (6.10) to be written in the simpler form 
a'b = 0 
b 
~ x 
~ a' + b. 
(6.11) 
(6.12) 
The system (6.11,6.12) is equivalent to the original equation, (6.8); however 
(6.12) alone is not equivalent to (6.8). Thus the consistency-condition is 
an essential part of the general solution (6.11, 6.12). The solution (6.10), 
however, is equivalent to (6.8) and therefore implies its own consistency-
condition, i.e., (6.8) =:} b ~ (a'b' +ab) ==> a'b = O. It is good practice in 
any case to state the consistency-condition as an explicit part of a general 
solution. 
Example 6.2.2 Let us now construct a parametric general solution of equa-
tion (6.8), making use of formula (6.7). From the equivalent equation (6.9) 
we derive the discriminants 1(0) = band 1(1) = ab' + a'b; thus a general 
solution of (6.8) is 
x = b + p(a'b' + ab) , 
i.e., 
x = b+ pa' , 
with consistency-condition a'b = O. 
6.3 
Subsumptive General Solutions 
In this section we extend the interval-based general solution (6.6) to apply to 
Boolean equations having more than one unknown. We omit proofs, which 
are given in Brown & Rudeanu [28]. Let us consider an n-variable Boolean 
system of the form 
80 
< 0 
81 < 
Xl < tl 
82(Xt} 
~ X2 < t2(Xt} 
(6.13) 
83(Xl, X2) < 
X3 
~ t3(Xb X2) 
8n (Xt, .•. , xn-t} < 
Xn < tn(Xb ••• , xn-d 

6.3. SUBSUMPTIVE GENERAL SOL UTIONS 
159 
where So, SI, and tl are constants (elements of B) and the remaining Si and 
ti are Boolean functions having the indicated number of arguments. We say 
that the system (6.13) is a subsumptive general solution of the n-variable 
Boolean equation 
f(xt. X2, • •• , xn ) = 0 
(6.14) 
if So ~ 0 (Le., So = 0) is the consistency-condition of (6.14) and if, pro-
vided (6.14) is consistent, every particular solution (at. ... ,an ) of (6.14), 
and nothing else, is generated by the following procedure: 
1) 
Select al in the range SI ~ x ~ tl 
2) 
Select a2 in the range s2(at} ~ x ~ t2(at} 
n) 
Select an in the range sn(ab ... ,an-t} ~ x ~ tn(al, ... ,an-t}. 
This procedure enables all of the solutions of (6.14) to be enumerated 
as a tree. The form of the tree (but not the set of particular solutions it 
represents) depends on the sequence in which argument-values are gener-
ated. The argument-sequence Xt. X2, • •• , xn , which is explicit in (6.13), will 
henceforth be assumed. 
Example 6.3.1 A subsumptive general solution of the Boolean equation 
yz + a' x' + a' z' + xy = 0 
is 
0 = 0 
a' < x < 1 
0 
~ y 
~ x' 
a' 
~ z 
~ y' . 
This general solution yields five particular solutions, which are listed in Ta-
ble 6.1. 
6.3.1 
Successive Elimination 
The classical method for producing a subsumptive general solution is by 
successive elimination of variables. This technique is part of the folklore of 
the subject; the first formal proof of its adequacy was apparently given by 
Rudeanu [171]. 

160 
CHAPTER 6. SOLUTION OF BOOLEAN EQUATIONS 
x 
y 
z 
a' 0 a' 
a' 0 
1 
a' a 
a' 
1 
0 a' 
1 0 
1 
Table 6.1: Particular solutions of yz + a/x' + a'z' + xy = o. 
The idea behind successive elimination is to transform the problem of 
solving a single n-variable equation into that of solving n single-variable 
equations. The process begins with the elimination of Xn from (6.14). We call 
the conjunctive eliminant fn-1; hence, the resultant is fn-1(X1, ... ,Xn-1) = 
O. The variable Xn-1 is then eliminated from the latter equation, yielding 
the equation fn-2(Xt. ... ,Xn-2) = 0, the resultant of elimination of Xn and 
Xn-1 from (6.14). This process is continued until the resultants h(X1) and, 
finally, fo are produced. The latter equation, the resultant of elimination of 
all variables from (6.14), is the necessary and sufficient condition for (6.14) 
to be consistent, i.e., solvable. If that condition is satisfied, then the single-
variable equation h (Xl) = 0 is solved for Xl. For any solution Xl = a1, 
the single-variable equation heat. X2) = 0 is solved for X2; for any solution 
X2 = a2 of the latter equation, the single-variable equation h( at, a2, X3) = 0 
is solved for X3; this process is continued, working back up the sequence of 
resultants until a solution (a1, a2, . .. , an) of (6.14) is achieved. We formalize 
this procedure in the following theorem. 
Theorem 6.3.1 Given the Boolean function f: Bn __ B define n + 1 elimi-
nants fo, h(X1), h(x1, X2)' ... ' fn(X1, ... , xn) of f by means of the recursion 
(i) 
fn 
f 
(ii) 
fi-1 
= 
ECON(Ji, {Xi}) 
(i = n, n - 1, ... , 1) . 
(6.15) 
( 6.16) 
Then (6.13) is a subsumptive general solution of (6.14) provided the Boolean 
functions so, St. ... , Sn, tt. ... , tn are defined by 
So 
= 
fo 
(6.17) 
Si(Xt. ... , xi-d 
fi(Xt. ... , Xi-t. 0) 
(i=1, ... ,n) 
(6.18) 
ti(Xt. ... ,Xi-t) = 
f[(X1, ... , Xi-t. 1) 
(i=1, ... ,n). 
(6.19) 

6.3. SUBSUMPTIVE GENERAL SOL UTIONS 
161 
Example 6.3.2 Let us apply the method of successive elimination to find 
a general solution of the equation I( Xl, X2, X3) = 0, where I is represented 
by the formula 
(6.20) 
The eliminants of I defined by the recursion (6.15,6.16) are represented as 
follows: 
h 
h 
It 
10 = 
Thus the system 
foregoing formula for I 
bXl + b'X~X2 + a'xlx; + a'x~x2 + a'bx; 
bXl + a'bx~ 
a'b. 
a'b = 0 
a'b < 
Xl < b' 
a'b + a'xl + bXl < X2 < b'Xl + abx~ 
(6.21) 
a'x~ + bXl + b'X~X2 + a'x; < X3 < b' x~ X; + abx~ X2 + ab' X; + a'b' Xl X2 
is a subsumptive general solution of I(Xl, X2, X3) = o. The SOP formulas 
in (6.21) may be simplified, as shown below, by introducing the condition 
a'b = 0 explicitly: 
a'b 
0 
0 < 
Xl 
::; 
b' 
(6.22) 
a'xl + bXl < X2 
::; 
b'Xl + bx~ 
a'x~ + bXl + b'X~X2 + a'x; < X3 < b' " 
b' 
b" 
, 
Xlx2+ XlX2+ a x2+ axl x2· 
6.3.2 
Deriving Eliminants from Maps 
The eliminants 10, It, ... , In are readily derived if I( Xl, ••• , Xn) is repre-
sented by a 2n-row map, each row of which represents I(al, ... , an), where 
(al, ... ,an) is one of the elements of {O, l}n. The recursion (6.15,6.16) im-
plies that each row of the 2i - l -row map representing li-l is the result of 
intersecting a pair of rows of the 2(row map representing Ii. The result is 
particularly convenient if I is represented by a Karnaugh map [99], in which 
the rows and columns are arranged according to a reflected Gray code, or 

162 
CHAPTER 6. SOLUTION OF BOOLEAN EQUATIONS 
by a Marquand diagram [131], in which the rows and columns are arranged 
in natural binary order. For either of these representations, the map rep-
resenting li-l is constructed from the map representing Ii by intersecting 
successive pairs of rows, beginning with the top pair. Karnaugh maps are 
easier to construct and read than are Marquand diagrams; however, the 
rules for using Marquand diagrams to solve Boolean equations are easier to 
state than are those for using Karnaugh maps. We therefore specialize to 
Marquand diagrams, inasmuch as the Marquand-rules are readily converted 
in practice to Karnaugh-rules. 
Example 6.3.3 The function given in Example 6.3.2 is represented in Fig-
ure 6.1 as Marquand diagram h. Each row of diagram 12 is formed by 
intersecting (element-by-element ANDing) a pair of rows of h; thus row 00 
of diagram 12 is the intersection ofrows 000 and 001 of diagram h. Diagram 
it is constructed in a similar way from diagram 12, and so on. 
6.3.3 Recurrent Covers and Subsumptive Solutions 
The general solution produced by successive elimination is only one among 
many subsumptive general solutions typically possessed by a Boolean equa-
tion. The eliminants 10, it, ... , In defined by (6.15, 6.16) may be used, how-
ever, to generate the full class of subsumptive general solutions; knowing 
that class, we may select a general solution best suited to our purposes. 
We show in Theorem 6.3.4 that each subsumptive general solution of 
the Boolean equation (6.14) is associated with a sequence (90,9b ... , 9n) of 
Boolean functions. We say that such a sequence is recurrent in case 90 E B 
and also that 9i: Bi--+ B is a Boolean function of the variables Xl, X2, ... , Xi 
satisfying the condition 
i-I 
ECON(gi,{Xi}) ~ L9j(Xb ... ,Xj) 
j=o 
for i = 1,2, ... , n. The sequence (go,9}, ... ,9n) will be called a recurrent 
cover of an n-variable Boolean function I in case the sequence is recurrent 
and also 

6.3. SUBSUMPTIVE GENERAL SOL UTIONS 
163 
ab 
X1 X2X3 00 01 10 11 
000 
1 
1 
0 
0 
001 
0 
1 
0 
1 
fa 
010 
= 
011 
1 
1 
1 
0 
1 
1 
1 
0 
100 
1 
1 
0 
1 
101 
1 
1 
0 
1 
110 
0 
1 
0 
1 
111 
0 
1 
1 
1 
X1 X2 
00 
0 
1 
0 
0 
h = 
01 
1 
1 
1 
0 
10 
1 
1 
0 
1 
11 
0 
1 
0 
1 
Xl 
It = 
0 I ~ I 
1 I ~ I ~ I 
1 
1 
fo = 
I 0 I 1 I 0 I 0 I 
Figure 6.1: Marquand diagrams for the eliminants of (6.20). 

164 
CHAPTER 6. SOLUTION OF BOOLEAN EQUATIONS 
Theorem 6.3.2 Let fo, It, ... , fn be the eliminants, defined by (6.15, 6.16), 
of an n-variable function f. Then (gO, g}, ... , gn) is a recummt cover of f 
if and only if the conditions 
fo 
= 
go 
f~1t 
~ gl 
~ It 
ffh 
~ g2 
~ h 
f~-dn ~ gn 
~ fn 
are satisfied. 
Corollary 6.3.1 The sequence (fo, It, ... , fn) of eliminants defined by the 
system (6.15, 6.16) is a recurrent cover of f. 
Given the eliminants fo, It, ... , fn of an n-variable Boolean function f, 
Theorem 6.3.2 expresses the set of recurrent covers of f by a system of inter-
va.ls, i.e., of "incompletely specified" functions. Thus well-known methods of 
minimization may be used to find a recurrent cover expressed by the simplest 
possible SOP formulas. The next theorem shows, however, that a recurrent 
cover of f may be constructed directly from the prime implicants of f. 
Theorem 6.3.3 Given an n-variable Boolean function f, a recurrent cover 
(go, g}, ... , gn) of f is given by the prescriptions 
go = L (prime implicants of f not involving 
any of the arguments Xl, ••• , Xn) 
gi = L (prime implicants of f involving Xi 
but not involving any of Xi+!, ... , Xn) 
(i = 1,2, ... ,n). 
(6.23) 
(6.24) 
It is convenient in practice to produce the g-sequence specified by (6.23, 
6.23) in reverse order, i.e., beginning with gn rather than with go. Let F be 
the set of prime implicants of f, and denote by Gi the set of terms comprised 
by gi(i = O, ••. ,n). Then the sets Gn,Gn-l, ... ,Go (which constitute a 
partition of F) are generated by procedure shown in Figure 6.2, in which T 
is a subset of F. 

6.3. SUBSUMPTIVE GENERAL SOLUTIONS 
165 
1 begin 
2 
T:= F 
3 
for i = n dovnto 1 do 
4 
begin 
5 
Gi := {terms in T involving Xi} 
6 
T:= T-Gi 
7 
end 
8 
Go := T 
9 
end 
Figure 6.2: Procedure to generate a recurrent cover of f from the prime 
implicants of f. 
Example 6.3.4 Let us apply the procedure of Figure 6.2 to produce a re-
current cover of the Boolean function f discussed in Example 6.3.2. The 
Blake canonical form of f, i.e., the disjunction of its prime implicants, is 
BCF(f) = bXl + bX~X3 + b'X~X2 + a'x~x; + a'xlx~ + a'x~x2 + 
ab'x2x3 + a'b + aXlx2x3 + a'x~x; . 
The procedure of Figure 6.2 enables us to read off the components of a 
recurrent cover by inspection of BCF(f): 
93 
= 
bX~X3 + a'x~x; + ab'x2x3 + aXlx2x3 + a'x~x; 
92 
= 
b'X~X2 + a'xlx~ + a'x~x2 
(6.25) 
91 
bXl 
90 
= a'b. 
The following theorem shows the intimate relation between recurrent 
covers and subsumptive general solutions. 
Theorem 6.3.4 The system (6.13) is a subsumptive general solution of 
equation f(x1, X2, ... , xn) = 0 if and only if so, S1,.", 8n, tI, ... , tn are 
Boolean functions 9iven by 
So 
= 90 
8i(X1,"" xi-d = 
9i(X1," .,Xi-1, O) (i=1, ... ,n) 
ti(Xl, ... , Xi-I) = 9Hxl,"" Xi-I, 1) (i=1, ... ,n) 

166 
CHAPTER 6. SOLUTION OF BOOLEAN EQUATIONS 
where (gO, g}, ... , gn) is a recurrent cover of f. 
Example 6.3.5 The method of successive elimination was applied in Ex-
ample 6.3.2 to construct a general solution of the equation f( Xl, X2, X3) = 0, 
the function f being specified by (6.20). Let us now apply Theorem 6.3.4 
to construct another general solution of the same equation, based on the 
recurrent cover (6.25). 
a'b 
= 0 
o $ 
Xl 
$ 
b' 
(6.26) 
a' Xl 
$ 
X2 
$ 
ab + Xl 
a'xi + a'x~ < X3 < 
b'x~ + a'X2 + bxix2 
The formulas in the general solution (6.26) are clearly simpler than those in 
either (6.21) or (6.22); 
6.3.4 
Simplified Subsumptive Solutions 
The method of successive eliminations tends to produce unnecessarily com-
plex formulas for the Si and ti in a subsumptive general solution, even if 
the consistency-condition fo = 0 is introduced, as in (6.22), for purposes of 
simplification. Such complex formulas mask the nature of the solutions and 
complicate the task of enumerating particular solutions. 
We call subsumptive solution (6.13) simplified in case each of the func-
tions so,s}, ... ,sn,h, ... ,tn is expressed as a simplified SOP formula. The 
following theorem establishes that each of these functions (like each of the 
gi in a recurrent cover of J) is defined by an interval based on the eliminants 
fo, h,.··, fn. Thus we may apply standard procedures for minimizing the 
complexity of SOP formulas. 
Theorem 6.3.5 Let fo, h, ... , fn be the eliminants, defined by (6.15, 6.16), 
of an n-variable Boolean function f. Then (6.13) is a subsumptive general 
solution of f(xl, X2, ... , xn) = 0 if and only if 
and the conditions 
So = fo 
(6.27) 
Ii(O)f[(l) $ 
Si 
$ 
fiCO) 
f[(l) $ 
ti $ 
fiCO) + fHl) 
(6.28) 
(6.29) 
are satisfied for i = 1,2, ... , n, where fiCO) and fi(1) denote, respectively, 
fi(xlt ... ,xi-l,O) and fi(Xl, ... ,Xi-},I). 

6.4. PARAMETRIC GENERAL SOLUTIONS 
167 
6.3.5 
Simplification via Marquand Diagrams 
If fo, iI, ... , fn are represented by Marquand diagrams, as in Example 6.3.3, 
then diagrams representing all possible values of So, s}, . .. , Sn, tIl, .. , tn are 
readily derived by use ofrelations (6.27, 6.28, 6.29). Each column ofthe dia-
grams for Si(X}, ... , xi-d and ti(X1,"" Xi-1) is derived from the correspond-
ing column of fi(Xt, ... , Xi). The element in row k (k = 0,1, ... , 2i- 1 - 1) 
for any column of the Si and ti diagrams is related as shown in Table 6.2 to 
the elements in rows 2k and 2k + 1 of the diagram for fi. 
row 2k of fi 
0 
0 
1 
1 
row 2k + 1 of fi 
0 
1 
0 
1 
row k of Si 
0 
0 
1 X 
row k of ti 
1 
0 
1 X 
Table 6.2: Diagram-entries for Si and ti in terms of diagram-entries for k 
Example 6.3.6 The eliminants offunction (6.20) are represented by Mar-
quand diagrams in Example 6.3.3. Those diagrams, together with the corre-
sponding diagrams for Si and ti, are exhibited in Figure 6.3. The Marquand 
diagrams for Si and ti specify the set of all possible subsumptive general 
solutions for the Boolean equation of Example 6.3.2. A simplified member 
of that set is 
a'b 
0 
0 < Xl 
::; 
b' 
a'X1 
::; 
X2 < b+ Xl 
a'x~ < X3 
::; 
a' + b'x~ + bX2 
The form of this general solution should be compared with that of the general 
solutions produced in Examples 6.3.2 and 6.3.5. 
6.4 
Parametric General Solutions 
Formula (6.7) expresses a parametric general solution of the single-variable 
Boolean equation f(x) = O. We now consider parametric general solutions 
of n-variable Boolean equations. 

168 
CHAPTER 6. SOLUTION OF BOOLEAN EQUATIONS 
ab 
ab 
ab 
XIX2X3 00 01 10 11 
XIX2 00 01 10 11 
XIX2 00 01 10 11 
000 
001 
010 
011 
100 
101 
110 
111 
1 
1 
0 
0 
0 
1 
0 
1 
1 
1 
1 
0 
1 
1 
1 
0 
1 
1 
0 
1 
1 
1 
0 
1 
0 
1 
0 
1 
0 
1 
1 
1 
0 
1 
0 
0 
1 
1 
1 
0 
1 
1 
0 
1 
0 
1 
0 
1 
fo 
101 1 I 0 101 
00 
01 
10 
11 
1 
X 
0 
0 
X X X 
0 
X X 
0 
X 
0 
X 
0 
X 
10 I X 10 101 
So 
101 1 I 0 101 
00 
01 
10 
11 
1 
X 
X 
1 
Figure 6.3: Marquand diagrams associated with (6.20). 
X 
1 
0 
X X 
1 
X 
1 
X 
X 
0 
X 

6.4. PARAMETRIC GENERAL SOLUTIONS 
169 
Let X, G, and P denote, respectively, the vectors (Xl, . .. , xn), (g1, ... ,gn), 
and (pt, ... ,Pk), where gt, ... ,gn are k-variable Boolean functions and where 
the symbols PI, ... , Pk designate arbitrary parameters, i.e., freely-chosen el-
ements of B. Then a parametric general solution of the Boolean equation 
f(X) = 0 
(6.30) 
is a system 
0 = go 
(6.31) 
X = G(P) 
(6.32) 
such that the conditions 
go 
= ECON(J,X) 
(6.33) 
f(G(P)) = ECON(J,X) 'liP E Bk 
(6.34) 
f(A) = ECON(J, X) ~ 3P E Bk such that G( P) = A (6.35) 
are satisfied. 
Condition (6.33) specifies that equation (6.31) is to be the consistency-
condition for (6.30). Suppose condition (6.33) to be satisfied. Then condi-
tion (6.34) demands that G(P) generate nothing but solutions of (6.30) for 
all values of the parameter-vector Pj condition (6.35), on the other hand, 
demands that G(P) generate all solutions of (6.30). If (6.30) is consistent, 
therefore, conditions (6.34) and (6.35) taken together demand that the set of 
all of its solutions-and nothing else-be generated by G(P) as P is assigned 
values on Bk. 
6.4.1 
Successive Elimination 
The method of successive elimination of variables, which we applied earlier 
to find subsumptive general solutions, can also be used to find paramet-
ric general solutions. To acquaint ourselves with the main features of the 
procedure, let us solve the 3-variable equation 
f(Xt,X2,X3) = O. 
(6.36) 
We begin, as before, by calculating the eliminants fo, h, 12, 13: 
h(xt, X2, X3) = ECON(J,0) 
h(xl, X2) = ECON(h, {X3}) = 
h(Xl) = ECON(h, {X2}) 
fo = ECON(h, {xd) = 
f 
ECON(J, {X3}) 
ECON(J, {X2' X3}) 
ECON(J, {Xl, X2, X3}) 

170 
CHAPTER 6. SOLUTION OF BOOLEAN EQUATIONS 
The consistency-condition for equation (6.36) is 0 = 90, where 90 = fo. 
Equation !t(xd = 0 is the resultant of elimination of X2 and X3 from (6.36). 
This is a single-variable equation stating all that is known about Xl in the 
absence of knowledge concerning X2 and X3j hence, we may employ the 
parametric formula (6.7) to express the set of allowable values of Xl, i.e., 
Xl = 91(pd = !teO) + pd~(l) . 
(6.37) 
Equation h(xI, X2) = 0 is the resultant of elimination of X3 from (6.36)j 
it therefore expresses all that is known about Xl and X2 in the absence of 
knowledge concerning X3. We substitute 91(pd for Xl, re-expressing this re-
sultant by the single-variable equation h(91(pd, X2) = OJ a general solution 
of the latter equation is 
X2 
= 92(PI,P2) 
= h(91(pd, 0) + P2!~(91(PI)' 1) . 
(6.38) 
The final step in this process is to substitute 91(PI) and g2(Pl,P2) for Xl 
and X2, respectively, in (6.36). The result, !J(91(pd,g2(Pl,P2), X3) = 0, is 
a single-variable equation in X3 whose general solution is expressed by the 
parametric formula 
X3 
= g3(PI,P2,P3) 
= !J(gl(Pt), 92 (PI, P2), 0) + P3f~(gl(pt),g2(pI,p2)' 1). (6.39) 
The system 
0 = go 
Xl = gl(PI) 
X2 = g2(PI,P2) 
X3 = g3(PI,P2,P3) 
therefore constitutes a parametric general solution of (6.36), the functions 
go, g1. g2, and g3 being defined by (6.37,6.38,6.39). 
Example 6.4.1 The RST flip-flop is defined by the equations 
Y 
S + yR'T' + y'T 
o = RS + RT + ST , 
(6.40) 
(6.41) 

6.4. PARAMETRIC GENERAL SOLUTIONS 
171 
where y is the present state of the flip-flop, Y is its next state, and R, S, 
and T are the "reset", "set", and "toggle" inputs to the flip-flop. Equation 
(6.40) is the characteristic equation [155] of the flip-flop and (6.41) is an 
input-constraint specifying that no more than one input may be at logical 1 
at any time. To design input-logic for this flip-flop, it is necessary to solve 
the system (6.40, 6.41) for R, S, and T (which we regard as variables) in 
terms of y and Y (which we regard as elements of B). We begin by reducing 
the system (6.40,6.41) to the single equivalent equation 
I(R,S,T) = 0, 
where I is defined by 
I = Y'S + y'Y'T + yY'R'T' + y'Y S'T' + yY RS' + yY S'T 
+RS+RT+ST. 
(6.42) 
Let us now employ successive elimination to form a parametric general solu-
tion. To make direct use of the results given above concerning the formation 
of such a solution, we re-name variables as follows: Xl = R, X2 = S, and 
X3 = T. The RST flip-flop is therefore defined by I(x}, X2, X3) = 0, where I 
is given by 
I = Y'X2 + y'Y'x3 + yY'x~x~ + y'Yx~x~ + yYxlx~ + yYx~X3 
+XIX2 + XIX3 + X2 X3 . 
Accordingly, the eliminants are 
h( x}, X2, X3) 
= 
hex}, X2) 
h(xI) = 
10 = 
f 
ECON(h, {X3}) 
ECON(h,{x2}) 
ECON(h,{xIl) 
= expression (6.43) 
= YXI + Y'X2 
= YXI 
= o. 
(6.43) 
Substituting the foregoing results in the parametric expressions (6.37,6.38, 
6.39) we arrive at the general solution 
0 = 0 
Xl = 0+ PlY' 
X2 = 0+ P2Y 
X3 = [P~yY' + p~y'Y] + P3[PIY' + P2Y + yY + y'Y'l' . 

172 
CHAPTER 6. SOLUTION OF BOOLEAN EQUATIONS 
After replacement of Xl! X2, and X3, by R, S, and T, respectively, and 
simplification of the result, the foregoing general solution takes the form 
0 = 0 
R = PlY' 
(6.44) 
S = P2Y 
T = p~yY' + p~y'Y . 
The first equation in the system (6.44),0 = 0, signifies that the RST flip-flop 
equation is unconditionally consistent; for any combination of present-state 
and next-state, that is, the equation has a solution for R, S, and T. Partic-
ular solutions are obtained from (6.44) by assignment of particular values in 
the Boolean algebra B to the arbitrary parameters. The Boolean algebra B 
is not specified in the foregoing example, but includes as a subalgebra the 
free Boolean algebra F B(y, Y). Suppose we make the assignment PI = 1, 
P2 = y. The corresponding particular solution is R = Y', S = yY, T = y'Y. 
The method of successive elimination demonstrates that a parametric 
general solution of an n-variable Boolean equation need involve no more 
than n arbitrary parameters. In some cases, as shown by the foregoing 
example, fewer than n parameters suffice. 
6.4.2 
Parametric Solutions based on Recurrent Covers 
As we found in discussing subsumptive general solutions, the sequence 
10, ft,···, In of eliminants of I is a special form of recurrent cover of I. 
We also found that the eliminants of I constitute one of the more complex 
recurrent covers of I, and that simpler recurrent covers may be constructed 
in a systematic way; the procedure of Theorem 6.3.3, for example, develops 
a relatively simple recurrent cover of I directly from its prime implicants. 
The method of successive elimination may be generalized directly to em-
ploy any recurrent cover of I as the basis for constructing a parametric gen-
eral solution of I(X) = o. We now present several results, without proof, 
concerning the use of recurrent covers for this purpose. 
Our first observation is that if (go, gt, ... , gn) is a recurrent cover of 
f: Bn---+ B, then the "triangular" system 

6.4. PARAMETRIC GENERAL SOLUTIONS 
173 
° = 90 
Xl = 9l(Pt} 
X2 = 92(Pl,P2) 
Xn = 9n(Pl,P2, ... ,Pn) 
is a parametric general solution of the Boolean equation f( Xl, ... , Xn) = ° 
if the functions 90,91, ... , fin are given by the recursion 
90 = 90 
9l(Pt} = 91(0) + P19~(1) 
9i(Pt,···,Pi) = 9i(9l(Pt},···,9i-l(Pt,···,Pi-t},0)+ 
(6.45) 
(6.46) 
+Pi9i(9l(Pt}, ... ,9i-l(Pb ... ,Pi-t}, 1) 
(6.47) 
(i = 2,3, ... ,n). 
We note further that the functions 90,fll(Pt},92(PbP2),···,9n(Pt, ... ,Pn) 
are independent of the recurrent cover (90,91, ... , 9n) of f on which they are 
based, provided f(X) = 0 is consistent [28]. Thus all recurrent covers lead 
via the system (6.45, 6.46, 6.47) to the same general solution of a consistent 
Boolean equation. 
Example 6.4.2 Let us form a parametric general solution of the Boolean 
equation 
(6.48) 
which is equivalent to the equation f(xt, X2) = 0, where f is given by 
f 
' 
b ' 
'b' 
"b" 
" 
= ae Xl + e X2 + a e + a eX2 + eXl + eXl X2 . 
The foregoing expression is in Blake canonical form; hence, we may form 
a recurrent cover by inspection of its terms, using the procedure of Theo-
rem 6.3.3: 
90 
a'b'e 
9l(Xl) = ae'xl + b'ex~ 
( 
) 
b ' 
" 
" 
92 xl, X2 
= 
e X2 + a eX2 + exlx2 . 

174 
CHAPTER 6. SOLUTION OF BOOLEAN EQUATIONS 
Thus, applying the recursion (6.45,6.46,6.47), 
90 = 
go 
= a'b'c 
9l(Pl) = 
b' c + PI [ac']' 
= b'c + PI [a' + c] 
(6.49) 
92(Pl,112) = a'c + cg~(Pl) + 112[bc']' 
= a'c + p~bc + P2[b' + c] , 
from which we form the parametric general solution 
o = a'b'c 
Xl = b'c+Pl[a'+c] 
X2 
a' c + p~ bc + 112[b' + c] . 
Example 6.4.3 The recurrent cover 
b ' 
'" 
b' 
'" 
g3 = 
X2X3 + a X2X3 + a X2X3 + aXlX2X3 + a X1X3 
g2 = 
b'X~X2 + a'X1X~ + a'X~X2 
gl = bXl 
go = a'b 
was developed in Example 6.3.4 for the function I given in Example 6.3.2. 
Thus a parametric general solution of l(xl,x2,x3) = 0 is 
0 = 
a'b 
Xl 
= Plb' 
X2 
= 
a'b'Pl + 112[b'Pl + ab] 
X3 = p~ a' + a'b + P3[P~ b' + 112b + a' + p~b'] . 
We observe finally that if I(X) = 0 is consistent, the general solution 
defined by the recursion (6.45, 6.46, 6.47) is reproductive; that is, the equiv-
alence 
I(X) = 0 
¢:::::? 
X = a(x) 
(6.50) 
holds for all X in Bn. (See Rudeanu [172] for a full discussion of reproductive 
general solutions.) 

6.4. PARAMETRIC GENERAL SOL UTIONS 
175 
Example 6.4.4 To illustrate the equivalence (6.50), let us assume that 
(6.48) is consistent and take at random one of its particular solutions: 
Xl 
a'b' + b'c 
X2 = be. 
That this is a solution is verified by substituting in (6.48); the result, 
a(a'b' + b'e) + b(be) = c, 
becomes an identity provided that the consistency-condition, 0 = a'b'e, is an 
identity. Thus the left side of (6.50) is satisfied. To verify the right side, we 
make the substitutions PI = a'b' + b'e and P2 = be in (6.49): 
fJ1(a'b' + b'c) = b'e + (a'b' + b'e)(a' + c) 
a'b' + b'e 
92(a'b' + b'e, be) = a'e + (a'b' + b'e)'be + be(b' + c) 
a'e + be 
= be 
(assuming consistency). 
6.4.3 
Lowenheim's Formula 
In cases where it is inconvenient to construct a general solution of a Boolean 
equation, it may be relatively simple to find a particular solution. The 
following theorem enables us to form a parametric general solution in a 
mechanical way from any particular solution. 
Theorem 6.4.1 (Lowenheim [124]) Let U = (ut, ... , un) be a particular 
solution of a consistent Boolean equation f( x) = 0, and let P = (PI, ... ,Pn) 
be an n-tuple of arbitrary parameters. Then the system (6.31, 6.32) is a 
parametric general solution provided the vector G( P) = (91 (P), ... , 9n( P)) 
is defined by 
G(P) = U f(P) + P !,(P) . 
(6.51) 
Proof. Condition (6.33) of the definition of a parametric general solution is 
verified because f(X) = 0 is assumed to be consistent, i.e., ECON(f, X) = 0 
identically. Condition (6.34) is verified, for k = n, by Lemma 5.4.1. To verify 
(6.35), let us suppose that A E En is any particular solution of f(X) = o. 
Choosing P = A, 
G(P) = U f(A) + Af'(A) = U· 0 + A·1 = A. 
o 

176 
CHAPTER 6. SOLUTION OF BOOLEAN EQUATIONS 
Example 6.4.5 The RST flip-flop is characterized by the Boolean equation 
feR, S, T) = 0, where f is given by (6.42). An easily-obtained particular 
solution of the RST equation is 
R = Y' 
S = Y 
T = O. 
The value of n for this example is 3; thus, the parameter-vector P has three 
components, which we call p,q,and r for simplicity. Formula (6.51) therefore 
becomes 
[ ~~~;j 1 = [~' 1 
f(p,q,r)+ [: 1 
j'(p,q,r) 
93(P) 
0 
r 
The resulting parametric general solution is found after some calculation to 
be 
0 
0 
R = (p + q + r'y + ry')Y' 
S = (p+ q + ry + r'y')Y 
T 
p'q'r(y'Y + yY') . 
Lowenheim's formula generates an n-parameter solution of an n-variable 
Boolean equation. As Example 6.4.1 shows, however, fewer than n parame-
ters will often suffice. As a further example, a two-parameter general solution 
of the RST flip-flop equation can be formed from the solution given in Ex-
ample 6.4.5 by replacing the parameter-sum p + q by the single parameter 
p, yielding 
0 = 0 
R 
(p + r'y + ry')Y' 
S = (p + ry + r'y')Y 
T 
p'r(y'Y + yY') . 
It is possible, although the details will not be treated here, to generate 
least-parameter general solutions in a systematic way [23]; the Boolean equa-
tions characterizing all of the useful flip-flops (RS, JK, D, RST), for example, 

EXERCISES 
177 
can be solved using no more than one parameter [24]. A one-parameter gen-
eral solution of the RST flip-flop equation, for example, is 
0 = 0 
R = pY' 
S = pY 
T = p'(y'Y + yY') . 
Exercises 
1. Prove that f(x) = x is equivalent to f(O) ~ x ~ f(I). 
2. Give necessary and sufficient conditions on f(O) and f(l) in order for 
the equation f( x) = 0 to have a unique solution. 
3. Let f be symmetrical with respect to x and x', i.e., let f( x) = f( x'). 
Discuss the solutions of f( x) = O. 
4. Construct simplified general solutions of the following systems of equa-
tions; state the consistency condition in each case. 
(a) 
bx' + a = 
x 
a'x + b' = b'x 
(b) 
abx' + by + a' x = 1 
(c) 
x + y' 
= 
1 
axy' + by = b'x' 
xy 
= 
a 
5. Consider the Boolean equation f( Xl, X2, X3) = 0, where 
f 
' +" 
" 
= a2xl + a2x2x3 
a2xlx2 + alx2x3 
+al Xl x~ + al xi X2 + ai a~X2X3 . 
(a) Find BCF(f). 
(b) Construct a general solution using successive eliminations. 
(c) Construct a general solution using BCF(f) directly. 
(d) Construct a general solution using maps. 

178 
CHAPTER 6. SOLUTION OF BOOLEAN EQUATIONS 
6. How may the number of solutions of the Boolean equation f( x) = 0 
be determined from a Karnaugh map representing f? 
7. The RST flip-flop is defined by the equations 
Y = S + yR'T' + y'T 
o = RS+RT+ST 
( characteristic equation) 
(input constraint) 
where y and Yare the present state and next state, respectively, of 
the flip-flop. The problem in the design of excitation-logic is to find 
economical solutions for R, S, and T in terms of Y (a given function 
of input and state variables) and y. Write a general solution for R, S, 
and T in the form 
o:(y, Y) 
0 
o:(y, Y) < R 
~ (3(y, Y) 
o:(y, Y, R) < S < (3(y, Y, R) 
o:(y, Y, R, S) < T < (3(y, Y, R, S) 
Simplify the o:'s and {3's. 
8. The JK, SR, D and T flip-flops are defined by 
JK: Y = y' J + yK' 
SR: Y=S+yR' 
and 
SR=O 
D: Y=D 
T: 
Y = yEBT 
Write general solutions and simplified particular solutions for 
(a) Sand R in terms of J, K, and Yj 
(b) D in terms of J, K, and Yj 
(c) J and K in terms of T and Yj 
(d) T in terms of S, R, and y. 
9. Let the equation a'xI + a'x2 + ax~ = 1 be defined on the Boolean 
algebra B = {O, 1, a', a}. 

EXERCISES 
179 
(a) Display a general solution in the form 
al 
~ Xl 
~ {31 
a2(XI) 
~ X2 
~ {32(Xt) 
Express the a and {3 functions by simplified formulas. 
(b) Use your general solution in a systematic way to enumerate all 
particular solutions (Xl. X2)' 
10. Given the Boolean algebra {O, 1, a, a'}, find the particular solutions of 
the Boolean equation y' z' + a'y + ax' = O. 
11. (a) We are given Boolean functions f: B-B and cf>: B-B. De-
scribe the steps needed to prove that cf>(t) is a parametric general 
solution of the Boolean equation 
f(x) = 0 . 
(b) Suppose that B = {O,a',a, I}. Show that the system 
cf>l(t) = at 
cf>2( t) = a't 
is a parametric general solution of the Boolean equation 
a' Xl + aX2 = 0 . 
Your demonstration should not entail enumeration of all particu-
lar solutions. 
12. (Boole [13], Chapter IX) Let us assume wealth to be defined as follows: 
"Wealth consists of things transferable, limited in supply, and either 
productive of pleasure or preventive of pain." Thus wealth is defined 
by the class-equation 
w = st(p+ r), 
where w stands for wealth, s for things limited in supply, t for things 
transferable, p for things productive of pleasure, and r for things pre-
ventive of pain. State a general solution for the things transferable and 
productive of pleasure, i.e., the class pt, in terms of the classes r, s, 
and w. State a condition on the latter three classes that is necessary 
and sufficient for the existence of your solution. 

Chapter 7 
Functional Deduction 
The central process of Boolean reasoning is the extraction of a derived system 
from a given Boolean system (cf. Section 4.2). The derived system may be 
categorized as 
• 
functional (of the form X = F(Y» or general 
( i. e., not necessarily functional). 
• 
antecedent or consequent. 
The primary reasoning tactic employed by Boole and later nineteenth-
century logicians was to solve a logical equation for certain of its arguments 
in terms of others. Boole's approach may thus be classified as functional and 
antecedent. We discuss such reasoning in Chapter 6. 
Methods of general Boolean reasoning, both antecedent and consequent, 
were devised by Poretsky [159} at the end of the nineteenth century; these 
methods, however, entail computation of impractical complexity. A practical 
approach to general consequent reasoning in Boolean algebras was given by 
Blake [10} in 1937. Blake's "syllogistic" approach, which we describe in 
Chapter 5, is the Boolean precursor of Robinson's resolution principle [168} 
in the predicate calculus. 
The object of the present chapter is to discuss functional consequents of a 
Boolean equation. Unlike functional antecedents (i.e., solutions), which have 
been the object of much study since Boole's time, functional consequents 
seem to have received little attention. 
We proceed throughout this chapter from a given consistent Boolean 
equation of the form 
(7.1) 
181 

182 
CHAPTER 7. FUNCTIONAL DEDUCTION 
(The I-normal form (7.1) is chosen, in place of the O-normal form used 
earlier in this book, for computational convenience.) Our objective is to find 
consequents of (7.1) having the form 
Xl = g(X2, .•. , xn) . 
Such consequents were called "consequent solutions" by Ledley [115, 118], 
who discussed their utility in circuit-design and proposed matrix methods 
for their construction. 
We present criteria in Section 7.1 for determining the variables that are 
functionally deducible from equation (7.1). The associated functions are 
defined as intervals, i.e., as incompletely-specified functions, enabling the 
methods of switching theory to be employed for minimization. In Section 7.2 
we consider the following problem: given that a variable, 1.£, is functionally 
deducible from (7.1), what are the minimal sets of variables from which the 
value of 1.£ may be computed? 
7.1 
Functionally Deducible Arguments 
Assume as before that (7.1) is consistent, and consider a Boolean system 
having the form 
1.£1 
= gl(V) 
(7.2) 
where U = (ut, ... , ur ) and V = (VI, •.• , v_) are disjoint subvectors of X = 
(Xl, •.. ,Xn ) and where gt, .•. ,gr: B---B are Boolean functions. If (7.1) 
=* (7.2), we say that (7.2) is afunctional consequent of (7.1), and that each 
of the arguments 1.£1, ••• , ur is functionally deducible from (7.1). 
We confine our study of functionally deducible arguments to the case 
r = 1. Given a partition {{u},V} of {Xl, ... ,Xn }, therefore, we define 1.£ 
to be functionally deducible from (7.1) in case there is a Boolean function 
g: Bn-l __ B such that the equation 
1.£ = g(V) 
(7.3) 
is a consequent of (7.1). 

7.1. FUNCTIONALLY DEDUCIBLE ARGUMENTS 
Theorem 7.1.1 The following statements are equivalent: 
(i) 
u is functionally deducible from (7.1). 
(ii) 
EDIS(J',{u}) = 1. 
(iii) 
ECON(J,{u}) = 0. 
(iv) 
u or u' appears in every term of BCF(f). 
Proof. 
(i) <==> (ii) <==> (iii) 
183 
The equivalence of the statements below follows from elementary prop-
erties of Boolean analysis. 
(a) 
(3g) 
(Vu, V) [J( u, V) = 1 ==} u = g(V)] 
(b) 
(3g) 
(Vu, V) [J( u, V) ~ u' EB g(V)] 
(c) 
(3g) 
(VV) 
[ f(O, V) 
~ g'(V)] 
f(l, V) 
~ g(V) 
(d) 
(3g) 
(VV) 
[J(1, V) ~ g(V) ~ f'(O, V)] 
(e) (VV) [J(1, V) ~ f'(O, V)] 
(f) (VV) [J'(1, V) + f'(O, V) = 1] 
i.e., EDIS(f',{u}) = 1 
(g) (VV) [f(l, V)f(O, V) = 0] 
i.e., ECON(f,{u}) = ° 
(iii) <==> (iv) 
The equivalence of (iii) and (iv) follows directly from Lemma 5.8.1. 
o 
Statement (d) in the foregoing proof, together with Proposition 3.14.2, 
leads to 
Corollary 7.1.1 The Boolean equation u = g(V) is afunctional consequent 
of (7.1) if and only if 9 lies in the interval 
flu 
~ 9 
~ (flu')'. 
(7.4) 
The function 9 is thus "incompletely specified" in the terminology of 
switching theory. The set of g-functions defined by (7.4) may be displayed 

184 
CHAPTER 7. FUNCTIONAL DEDUCTION 
on a Karnaugh map whose arguments are those appearing explicitly in Ilu. 
A "1" is marked in the cells corresponding to the function I I u, a "0" in 
the cells corresponding to the function II u', and an "x" (don't-care) in the 
remaining cells. 
Example 7.1.1 The operation of the most significant stage of a binary 
two's-complement adder is defined by the system 
d = ab+ac+bc 
s = a$b$c 
(7.5) 
u = abs' + a'b's 
where a and b are the sign-bits of the addends, s is the sign-bit of the 
sum, c and d are the input and output carries, respectively, and u is the 
two's-complement overflow signal. (Non-standard variable-names have been 
chosen to avoid subscripts.) System (7.5) is equivalent to an equation ofthe 
form I = 1, where I is given by 
I 
= a'b' c' d' s' u' + a'b' cd' su + a'bc' d'su' + a'bcds' u' + 
ab'c'd'su' + ab'cds'u' + abc'ds'u + abcdsu' . 
(7.6) 
Formula (7.6) is in Blake canonical form; hence, we may apply criterion 
(iv) of Theorem 7.1.1 to determine the deducible variables. Each of the 
variables a, b, c, d, s, u appears in each of the terms of Be F(f); hence, each 
variable is functionally deducible from the equation I( a, b, c, d, s, u) = 1. Let 
us investigate in particular the possible functions 9 such that the overflow-
variable, u, is given by 
u =g(a,b,c,d,s). 
Applying Corollary 7.1.1, the set of g-functions is defined by the interval 
fI u $ 9 $ (f I u')' , 
where flu and Ilu' are given as follows: 
Ilu 
= a'b'cd's + abc'ds' 
Ilu' = a'b'c'd's' + a'bc'd's + a'bcds'+ 
ab' c' d' s + ab' cds' + abcds . 
(7.7) 
(7.8) 
There are 224 5-variable g-functions in the interval (7.7), one of which, nec-
essarily, is specified by the third equation in (7.5). Another, 
u=c$d, 
(7.9) 

7.1. FUNCTIONALLY DEDUCIBLE ARGUMENTS 
185 
is found by inspection of a 5-variable Karnaugh map, using the mapping 
rules cited earlier. Formula (7.9) is commonly employed in the design of 
arithmetic circuits. 0 
Example 7.1.2 (Bennett & Baylis [7], p. 218) What may one infer as 
to the structure of A + BC from the simultaneous relations A ~ B + C, 
B ~ A + C, and C ~ A + B? 
Solution: 
We introduce a variable, X, to stand for A + BC. Thus the 
given information is represented by the system 
X = A+BC 
A 
~ B+C 
B 
~ A+C 
C 
~ A+B, 
which reduces to f = 1, where f is given in Blake canonical form by 
BCF(f) = A'B'C'X' + BCX + ACX + ABX . 
The variable X, and no other, appears in every term of the foregoing formula. 
Hence, by criterion (iv) of Theorem 7.1.1, the variable X, and no other, is 
functionally deducible. Applying Corollary 7.1.1, the set of values of X is 
specified by the interval 
AB+AC+BC 
~ X < A+B+C. 
o 
Example 7.1.3 A sequential digital circuit is one possessing memory; the 
present output of such a circuit depends not only on the present input but 
on the sequence of prior inputs. An asynchronous sequential circuit is a 
sequential circuit whose operation is not timed by an external clock-signal. 
Changes in the output and memory-state of an asynchronous circuit occur 
only in response to changes in the input. The memory of an asynchronous 
circuit is embodied in the values of one or more signal-lines, called state-
variables, connected in closed feedback-loops. These variables "lock up" in 
stable states in the intervals between input-changes. 

186 
CHAPTER 7. FUNCTIONAL DEDUCTION 
Suppose that an engineer wishes to design an asynchronous circuit having 
inputs al and ao and output z. The output is to have the value 1 if and only 
if the present value of the pair alaO, viewed as a binary number, is greater 
than the preceding value; otherwise the output is to be O. It is assumed that 
al and ao cannot change simultaneously. 
U sing standard techniques of asynchronous design, the engineer finds 
that the circuit should realize the equations z = alaO + alY' + aoY' and 
Y = alaO + alY + aoY, where Y is a state-variable. (Note the feedback of the 
state-variable Y implied in the latter equation.) The engineer notes that if al, 
ao and Y are connected to the 3 inputs of a full adder (a standard component), 
one of the two outputs of the adder produces the desired y-function. The 
adder's second output, which we label s, produces the function s = al €aao€ay. 
The engineer decides to use the full adder to generate the y function; the 
second adder-output, s, is "free," so he will use the information it provides, 
if he can, to assist in generating the output z. He has now accumulated the 
following set of Boolean equations characterizing the design: 
z = alaO + alY' + aoy' 
y = alaO + alY + aoy 
s = al €a ao €a y . 
(7.10) 
This set of equations is equivalent to the single equation / = 1, where / is 
given, in Blake canonical form, by 
BCF(f) = a~a~s'y'z' + ala~sy'z + a~aOsy'z + 
a~aos'yz' + ala~s'yz' + alaosyz . 
The variable z appears in every term of the foregoing formula; by crite-
rion (iv) of Theorem 7.1.1, therefore, z is functionally deducible. Applying 
Corollary 7.1.1, the set of deducible z-values is the interval [/ / z, (f / z')'] , 
where 
f/z 
(f /z'), 
, , +' 
, 
= 
al aosy 
al aosy + al aosy 
= 
(a~a~s'y' + a~aos'y + ala~s'y)' 
= s + alao + alY' + aoy' + a~a~y . 
The foregoing formulas show that one member of [J / z, (f / z')'] is s; hence, 
z = s, 

7.2. ELIMINABLE AND DETERMINING SUBSETS 
187 
i.e., 
is deducible from the system (7.10). (The validity of this equality, in view 
of the constraints imposed by (7.10), should be verified.) Happily for the 
designer, the adder produces both y and Zj the design is complete. 0 
7.2 
Eliminable and Determining Subsets 
In this section we consider the following problem: given that a variable u is 
functionally deducible, what are the sets of variables from which the value 
of u may be computed? We will call such sets u-determining subsets. 
7.2.1 
u-Eliminable Subsets 
Let {{ u}, V, W} be a collection of subsets of {Xl..'.' xn}, the set of argu-
ments of equation (7.1), having the property that each argument appears in 
exactly one ofthe subsets. The subset W may be emptyj hence the collection 
may not be a partition. We say that W is u-eliminable from (7.1) provided 
an equation of the form 
u = g(V) 
is a consequent of (7.1). The empty set is trivially u-eliminable from (7.1) 
if u is functionally deducible from (7.1). 
Lemma 7.2.1 Let X = {Xl. ... ,Xn }, V = {Vl. ... ,Vs}, W = {Wl. ... ,Wt}, 
and let {V, W} be a partition of the argument-set X. Let p and q be Boolean 
functions and let p(V, W) = 1 be consistent. Then the following implications 
are equivalent for all V E BS and W E Bt: 
p(V, W) = 1 ==> q(V) = 1 
EDIS(p(V, W), W» = 1 ==> q(V) = 1 
(7.11) 
(7.12) 

188 
CHAPTER 7. FUNCTIONAL DEDUCTION 
Proof. The following statements are equivalent for all V E BB and W E Bt: 
(a) (7.11) 
(b) p(V, W) :5 q(V) 
(c) p(V, W) . q'(V) = 0 
(d) EAEBt(P(V,A) . q'(V)) = 0 
(e) EDIS(p(V, W), W)):5 q(V) 
(f) (7.12) 
The equivalence of (a) and (b), and of (e) and (f), follows from the Extended 
Verification Theorem (Theorem 5.4.1). The pair (b) and (c) are equivalent 
by the definition of inclusion, and the pair (c) and (d) because a property 
true for all values of W is true for any particular value. Finally, the pair (d) 
and (e) are equivalent by the definition of the disjunctive eliminant. 0 
Theorem 7.2.1 The subset W is u-eliminable from equation (7.1) if and 
only if u is deducible from the equation 
EDIS(f, W) = 1. 
(7.13) 
Proof. W is u-eliminable from (7.1) if and only if the implication 
f( u, V, W) = 1 
=> 
u = g(V) 
(7.14) 
holds. It follows from Lemma 7.2.1, however, that (7.14) is equivalent to the 
implication 
EDIS(f(u, V, W), W) = 1 
=> 
u = g(V) , 
(7.15) 
which establishes the theorem. 0 
Theorem 7.2.2 The following statements are equivalent: 
(i) 
W is u-eliminable from (7.1). 
(ii) 
EDIS(ECON(f', W),{u}) = 1. 
(iii) 
ECON(EDIS(J, W),{u}) = O. 
(iv) 
u or u' appears in every term of BCF(EDIS(f, W)). 
Proof. Follows directly from Theorems 7.1.1 and 7.2.1. 0 

7.2. ELIMINABLE AND DETERMINING SUBSETS 
189 
Example 7.2.1 System (7.5) in Example 7.1.1 was found to possess the 
consequent u = c EB d. Thus a u-eliminable subset is {a, b, 8}. Let us employ 
criterion (iv) of Theorem 7.2.2 to verify that {a, b, 8} is u-e1iminable: 
BCF(EDIS(J,{a,b,s}» = BCF(c'd'u' + cd'u + c'd'u' + cdu' + 
c'd' u' + cdu' + c'du + cdu') 
= c'd'u' + cd'u + cdu' + c'du . 
The variable u appears in each term of BCF(EDIS(J,{a,b,s}»i hence, 
{ a, b, s} is u-eliminable. 0 
Statement (iii) of Theorem 7.2.2, together with Theorem 5.8.6, leads to 
Corollary 7.2.1 The argument-subset W is u-eliminable from (7.1) if and 
only if the condition 
EDIS(J lu', W)· EDIS(J lu, W) = 0 
(7.16) 
is satisfied identically. 
7.2.2 
u-Determining Subsets 
Consider as before a collection { {u}, V, W} of subsets of the set {Xl, ... , xn} 
of arguments of equation (7.1), having the property that each argument 
appears in exactly one of the subsets. As before the subset W may be 
empty. We say that V is a u-determining subset of the arguments of (7.1) 
provided W is u-eliminable from (7.1). 
The subset W is u-eliminable, by Corollary 7.2.1, if and only if con-
dition (7.16) is satisfied. Let us assume that flu' and flu are expressed 
as sum-of-products formulas. From Theorem 5.8.4, therefore, the disjunc-
tive eliminants EDIS(Jlu', W) and EDIS(Jlu, W) are formed as sum-of-
products formulas from flu' and flu, respectively, by deleting all literals 
corresponding to letters in W (any term all of whose literals are thus deleted 
is replaced by 1). Then W is u-eliminable if and only if the product of any 
term of EDIS(Jlu',W) and any term of EDIS(Jlu,W) is zero. Such a 
product is zero, however, if and only if at least one letter, call it X, appears 
opposed in the two terms, i.e., if the literal X appears in one term and the 
literal x' appears in the other. 
The foregoing observations are the basis for a procedure, outlined be-
low, which generates the minimal u-determining subsets. This procedure 

190 
CHAPTER 7. FUNCTIONAL DEDUCTION 
employs Boolean calculations to arrive at a family of minimal sets; variants 
of this approach have been used to find irredundant formulas [154], maximal 
compatibles [129], and maximal independent subgraphs [126, 127, 156, 211]. 
7.2.3 Calculation of Minimal u-Determining Subsets 
We assume that u is functionally deducible from (7.1). The following steps 
produce a sum-of-products formula, Fu, each of whose terms corresponds to 
a minimal u-determining subset. 
1. Express flu and flu' as sum-of-products formulas, viz., 
M 
flu = EPi 
i=l 
N 
flu' = Eqj 
;=1 
where PI, ... ,PM and Q1, ••• ,qN are terms, i.e., products of literals. 
2. Associate with each pair (Pi,Qj) a complement-free alterm (sum of 
Ii terals) Sij defined by 
Sij = E (letters that appear opposed in Pi and qj) . 
3. Define a Boolean function Fu by the product-of-sums formula 
M 
N 
Fu = II II Si; . 
i=l;=l 
4. Multiply out, to form a complement-free sum-of-products formula for 
Fu , and delete absorbed terms. With each term ofthe resulting formula 
associate a set of arguments having the same letters; the resulting sets 
are the minimal u-determining subsets. 

7.2. ELIMINABLE AND DETERMINING SUBSETS 
191 
Example 7.2.2 Let us employ the foregoing procedure to find the minimal 
u-determining subsets for the system (7.5) of Example 7.1.1. We carry out 
step 1 by labeling the terms shown in (7.8): 
PI = a'b'cd's 
ql = a'b'c'd's' 
P2 = abc'ds' 
q2 = a'bc'd's 
q3 = a'bcds' 
q4 = ab'c'd's 
q5 = ab'cds' 
q6 = abcds 
The resulting Sij (step 2) are as follows: 
S11 
= c+s 
S21 
= a+b+d 
S12 
= b+c 
S22 = a+d+s 
S13 = b+d+s 
S23 = a+c 
S14 = a+c 
S24 = b+d+s 
SIS = a+d+s 
S25 = b+c 
S16 = a+b+d 
S26 = c+s 
Carrying out step 3, and deleting repeated factors, we obtain 
Fu = (c + s)(b + c)(b + d + s)(a + c)(a + d + s)(a + b + d) . 
The result of multiplying out and deleting absorbed terms is 
Fu = abc + cd + abs + bcs + acs , 
to which correspond the minimal u-determining subsets {a, b, c}, {c, d}, 
{a,b,s}, {b,c,s}, and {a,c,s}. The third subset is the one implied by 
the third equation of (7.5); the second is the one arrived at via Karnaugh-
mapping in Example 7.1.1. 0 
It has come to the author's attention that the method given above for 
calculating minimal u-determining subsets was given (in a different context) 
by Halatsis and Gaitanis [761, who called such subsets minimal dependence 
sets. 

192 
CHAPTER 7. FUNCTIONAL DEDUCTION 
Exercises 
1. (Halatsis & Gaitanis [76]) A switching circuit has inputs Xl, ••• , x6 
and output z. The behavior of the circuit is specified in terms of an 
orthogonal pair {4>0, 4>d of 6-variable switching functions as follows: 
• If 4>O(Xl, ••• , X6) = 1, then z = o. 
• If 4>l(Xt. ... , X6) = 1, then z = 1. 
• Otherwise, z = 0 or z = 1. 
Given that 
4>0 
x~ x2x~X4X5X6 + x~ x2X3X4XSX6 + XlX2X~X~X5X~ 
4>1 
X~ X2X~X4XSX~ + X~ X2X3X~XSX6 + X~ X2X3X~XSX~+ 
XlX2X~X4XSX~ + XlX2X3X~XSX6 + XlX2X3X~XSX~ , 
show that the minimal z-determining subsets are {Xl, X2}, {X3, X4, xs}, 
and {X3,X4,X6}. 
2. The clocked D-latch is a digital circuit whose excitation-logic is speci-
fied by the equations 
R = CD 
S = CD'. 
C is the clock-input, D is the excitation-input, and Sand R ("Set" and 
"Reset") are output-signals. 
(a) Which of the four variables C, D, R, S is functionally deducible 
from the remaining three? 
(b) For each of each of the variables identified in (a), 
i. Express the set of deduced values of that variable as an in-
terval involving the remaining variables. 
ii. Find the minimal determining subsets for that variable. 

Chapter 8 
Boolean Identification 
We have been concerned until now with techniques of Boolean reasoning. In 
this chapter and the next, we apply those techniques to the solution of partic-
ular kinds of problems. The problems are chosen to illustrate the techniques; 
no attempt is made to catalogue the problem-areas to which Boolean rea-
soning might usefully be applied. In the present chapter, we consider how a 
Boolean "black box" may be identified by means of an adaptive input-output 
experiment. 
Let us suppose that each system or process (which we shall call a trans-
ducer) in a certain class is equipped with a collection X = (Xl, X2, ••• ,xm ) of 
binary inputs, together with a single binary output, z. Each such transducer 
is characterized by the relation 
(8.1) 
for some Boolean function f. The inputs can be manipulated by an experi-
menter and the resulting output observed. 
We assume that the transducers in the given class are described by a 
Boolean model, i.e., a Boolean equation 
4>(X, Y,z) = 0, 
(8.2) 
where Y is a vector (Yl, Y2, ... , Yn) of binary parameters. For each parameter-
setting, Y = A E {O,l}n, the model (8.2) implies equation (8.1) for some 
Boolean function f. The mapping from parameter-setting to transducer 
is typically not reversible; a given transducer may be described by more 
than one parameter-setting. The transducers thus partition the parameter-
settings into equivalence-classes. 
193 

194 
CHAPTER 8. BOOLEAN IDENTIFICATION 
We suppose an unidentified transducer in the given class to be presented 
to an experimenter, who is presumed to have perfect powers of deduction. 
The experimenter knows the function tP in equation (8.2); thus he knows how 
to characterize the entire class parametrically. He does not, however, know 
the function f in equation (8.1), which characterizes the transducer in his 
possession. His task is to identify that transducer, i.e., to determine f and 
the associated equivalence-class of Y-values, by means of an input-output 
experiment. 
This model may be employed in a variety of diagnostic applications. The 
transducer-class might consist of patients undergoing medical diagnosis, in 
which case equation (8.2) represents the body of knowledge linking a certain 
category of diseases with the associated symptoms. Each of of the parame-
ters Yl, ... , Yn is in this case a disease, which is either present (Yi = 1) or not 
present (Yi = 0) in the patient. Each combination of x-values represents a 
symptom (or test to elicit that symptom). The output z represents the pres-
ence (z = 1) or absence (z = 0) of the symptom corresponding to the vector 
X, in the presence of disease-pattern Y. This formulation of the problem of 
medical diagnosis is a variation of that given by Ledley [116, 117, 119]; Led-
ley advocated the systematic use of Boolean methods in diagnosis as early 
as 1954 [113]. 
The problem of diagnosing multiple stuck-type faults in a combinational 
logic-circuit was formulated as one of Boolean identification by Poage [157] 
and by Bossen & Hong [15]. 
The class of possible circuits (faulty and 
fault-free) is characterized by a system of equations reducible to the model 
(8.2); the vector Y consists of parameters each of which indicates the stuck-
condition (stuck at 1, stuck at 0, or normal) at a point in the circuit. Breuer, 
Chang, and Su [22] proposed a method for solving the associated Boolean 
equations, based on an input-output experiment. Kainec [96] has developed 
a system (written in the Scheme language) which locates multiple faults in a 
combinational circuit, using Poage's model and Bossen & Hong's checkpoint-
concept, by means of adaptive experiment. Kainec's system accepts a de-
scription of a combinational circuit, either by means of Boolean equations 
or by a VHDL (VHSICI Hardware Description Language) specification; the 
system then assigns internal check-points, suggests test-inputs to the exper-
imenter, accepts the test-results, and provides a report at the end of the 
experiment on the nature and location (to within an equivalence-class) of 
faults in the circuit. 
1 Very High-Speed Integrated Circuit 

8.1. PARAMETRIC AND DIAGNOSTIC MODELS 
195 
The problem of identifying the parameters in a Boolean model for the 
adrenal gland is discussed by Gann, Schoeffler, and Ostrander [63, 177]. In 
discussing this model, they note that "two essential ingredients of physiolog-
ical research are the formulation of hypotheses about the operation of the 
system and the experimental testing of these hypotheses resulting in either 
its verification (followed by further testing) or else a change in the hypothesis 
to account for the latest observations. A problem arises when the amount 
of data is large, for it becomes difficult to determine whether a hypothesis is 
consistent with all of the observations. Moreover, there are so many possi-
ble experiments to perform, it is not practical to choose the experiments at 
random-rather it is necessary to select so-called critical experiments, the 
most instructive experiments possible." 
Our object in this chapter is to show how Boolean reasoning may be 
employed to devise such instructive experiments. 
8.1 
Parametric and Diagnostic Models 
Our experimenter employs (8.2) as a repository of knowledge and as a guide 
to experimentation, modifying 4>( X, Y, z) as knowledge is acquired. The 
parameters Yb Y2, ••• , Yn in (8.2) may serve only a "curve-fitting" purposej 
alternatively, they may represent physical values, e.g., of switch-settings or 
of binary voltage-levels. The two cases cannot be distinguished by experi-
ment. Let us assume for concreteness that the parameters specify physical 
properties of the transducer under examination. 
The experimenter's tasks are 
• to determine the function / relating the output to input, for the exist-
ing fixed setting of the parameters, and 
• to deduce as much as possible concerning the parameter-settings. 
8.1.1 
Parametric Models 
To be useful for identification, equation (8.2) should imply the equation 
z = j(X,Y) 
(8.3) 
for some Boolean function jj equivalently, the variable z should be function-
ally deducible (c/. Section 7.1) from (8.2). We say that (8.2) is a parametric 

196 
CHAPTER 8. BOOLEAN IDENTIFICATION 
model if such is the case. If (8.2) is a parametric model, then it implies 
an input-output relation of the form z = f(X) for any fixed setting of the 
parameter-vector Y. 
Theorem 8.1.1 Equation (8.2) is a parametric model if and only if the 
condition 
EDIS(4), {z}) = 1 
(8.4) 
is satisfied identically. 
Proof. Follows directly from Theorem 7.1.1. 0 
If (8.2) is a parametric model, then the function j in the implied relation 
(8.3) is any member of the interval [4>'(X, Y, 1), 4>(X, Y, 0)] (cf. the proof of 
Theorem 7.1.1). 
Example 8.1.1 Let 4>(Xb Yb Y2, z) = 0 describe a class of Boolean trans-
ducers, the function 4> being given by 
Substituting z = 0 and z = 1 in turn, we derive 
4>(X, Y, 0) = 
y~ + xy~ 
4>(X, Y, 1) = x'Yt + XY2 . 
The functions 4>(X, Y, 0) and 4>(X, Y, 1) sum to 1 identically; hence equation 
(8.4) is an identity. By Theorem 8.1.1, therefore, 4> = 0 is a parametric 
model. Applying Corollary 7.1.1, this model implies the relation (8.3) pro-
vided j is in the range 
4>'(X, Y, 1) ~ j ~ 4>(X, Y, 0) , 
i.e., 
" 
'<f"<' 
, 
x Yt + xY2 _ 
_ Yt + xY2 . 

8.1. PARAMETRIC AND DIAGNOSTIC MODELS 
197 
8.1.2 The Diagnostic Axiom 
The resultant of elimination of z from the Boolean model (8.2) is 
ECON(4)(X, Y,z), {z}) = o. 
(8.5) 
This equation expresses the knowledge relating X and Y, in the absence of 
knowledge concerning z, that is deducible from (8.2). We assume, however, 
that X is freely manipulable; hence X is unconstrained if nothing is known 
about the value of z. Equation (8.5) is therefore universally quantified in X, 
i.e., (8.5) holds for all X in {o,l}m. When combined with Theorem 4.8.8, 
these observations lead to what we shall call the diagnostic axiom: 
If 4>( X, Y, z) = 0 represents a class of transd ucers, then 
the parameter-vector Y is constrained by the equation 
EDIS(ECON(4>(X, Y, z), {z}),X) = O. 
(8.6) 
8.1.3 
Diagnostic Equations and Functions 
The diagnostic axiom is based on the "physics" ofthe identification-problem; 
a parametric model may not itself constrain Y as announced by (8.6). We 
call the model (8.2) a diagnostic equation, however, (and 4> a diagnostic 
function), in case it is a parametric model that satisfies the diagnostic axiom, 
i.e., in case it is a parametric model that implies (8.6). Thus (8.2) is a 
diagnostic equation if and only if the conditions 
EDIS(4), {z}) = 1 
EDIS(ECON(4>, {z}),X) < 
4> 
are satisfied identically. 
(8.7) 
(8.8) 
Theorem 8.1.2 The model (8.2) is a diagnostic equation if and only if it is 
a parametric model and there are Boolean functions j and iJ for which (8.2) 
is equivalent to the system 
z 
o 
j(X, Y) 
iJ(Y) . 
(8.9) 
(8.10) 
Proof. Equation (8.2) is equivalent to the system (8.9, 8.10) if and only if 
the equation 
4>(X, Y, z) = (z EEl j(X, Y)) + g(Y) 
(8.11) 

198 
CHAPTER 8. BOOLEAN IDENTIFICATION 
is an identity. Suppose (8.2) is a diagnostic equation, i.e., suppose that 
conditions (8.7) and (8.8) hold. Then for the choices 
j(X, Y) = 4>(X, Y,O) 
D(Y) = 4>(X,Y,O)'4>(X,Y,I) 
the following calculations verify (8.11): 
(8.12) 
(8.13) 
(z EI1 j(X, Y» + D(Y) = (z EI14>(X, Y, 0» + (4)(X, Y,O)· 4>(X, Y, 1» 
= z'( 4>(X, Y, 0» + z( 4>'(X, Y, 0) + 4>(X, Y, 1» 
= z'· 4>(X, Y, 0) + z . 4>(X, Y, 1) 
= 4>(X, Y, z) . 
To obtain the third line from the line before, we impose condition (8.7), 
in the form 4>'(X,Y, 0) . 4>'(X,Y,I) = 0. If (8.2) is a diagnostic equation, 
therefore, there are Boolean functions j(X, Y) and D(Y) such that (8.2) is 
equivalent to the system (8.9, 8.10). To prove the converse, let us set z = ° 
and z = 1 successively in (8.11), to deduce the system 
Hence 
4>(X, Y, 0) = j(X, Y) + D(Y) 
4>(X, Y, 1) = j'(X, Y) + D(Y) . 
EDIS(4),{z}) = 4>(X,Y,O) + 4>(X,Y,l) = 1 
ECON(4), {z}) = 4>(X,Y,O) 
. 4>(X,Y,I) = D(Y). 
The upper equation verifies condition (8.7). The lower equation shows that 
ECO N (4), {z} ) is independent of X; hence 
EDIS(ECON(4>, {z} ),X) = ECON(4), {z}). 
By Theorem 4.8.4, therefore, condition (8.8) is verified. 0 
It is left as an exercise to show that if (8.2) is diagnostic, then the function 
j in equation (8.9) is any member of the interval 
4>'(X, Y, 1) ~ j(X, Y) ~ 4>(X, Y, 0) , 
and that the function D in equation (8.10) is uniquely specified by 
D(Y) = ECON(4), {z}) = 4>(X, Y,O)· 4>(X, Y, 1). 

8.1. PARAMETRIC AND DIAGNOSTIC MODELS 
199 
8.1.4 
Augmentation 
A parametric model defining a class of transducers may fail to be diagnostic. 
Any parametric model, 4>(X, Y,z) = 0, may be converted, however, to a 
diagnolltic model, AUG(4))(X,Y,z) = 0, which specifies the same class of 
transducers. The function AUG(4)) is defined as follows: 
AUG(4)) = 4> + EDIS(ECON(4>, {z} ),X). 
(8.14) 
We call AUG(4)) the augmentation of 4>. 
To show that AUG(4)) = 0 is diagnostic, we require a preliminary result: 
Lemma 8.1.1 Let 4>(X, Y, z) be a Boolean function. Then 
ECON(AUG(4»,{z}) = EDIS(ECON(4>,{z}),X). 
(8.15) 
Proof. In the following development, denote by heY) the function 
EDIS(ECON(4>, {z}),X): 
ECON(AUG(4»,{z}) = ECON«4>(X,Y,z)+h(Y)),{z}) 
= 
[4>1 z' + hey)] . [4>1 z + heY)] 
= (4)lz'. 4>Jz) + heY) 
= ECON(4),{z})+ EDIS(ECON(4>,{z}),X) 
= EDIS(ECON(4>,{z}),X). 
The last line is deduced from the one preceding because a ~ EDI S( a, X) for 
any Boolean function a (Theorem 4.8.4); the remaining calculations resort 
only to elementary Boolean algebra. 0 
Theorem 8.1.3 Let 4>(X, Y, z) = 0 be a parametric model defining a class 
of transducers. Then AUG(4))(X,Y,z) = 0 is a diagnostic model defining 
the same class of transducers. 
Proof. The equation AU G( 4»( X, Y, z) = 0 is equivalent to the system 
4>(X, Y,z) = 0 
EDIS(ECON(4>(X,Y,z),{z}),X) = 0; 
hence it follows from the diagnostic axiom that AUG(4))(X,Y,z) = 0 de-
fines the same class of transducers as does 4>(X, Y, z) = O. To show that 

200 
CHAPTER 8. BOOLEAN IDENTIFICATION 
AU G( </»( X, Y, z) = 0 is a diagnostic model, we show that the following are 
identities: 
EDIS(AUG(</»,{z}) = 1 
(8.16) 
EDIS(ECON(AUG(</»,{z}),X) 
~ AUG(</». 
(8.17) 
It is known that EDIS(</>,{z}) = 1, inasmuch as </>(X,Y,z) = 0 is a para-
metric model. Hence 
EDIS(AUG(</»,{z}) 
= EDIS(</>+ EDIS(ECON(</>,{z}),X),{z}) 
= EDIS(</>, {z}) + EDIS(EDIS(ECON(</>, {z} ),X), {z}) 
= 1 + EDIS(EDIS(ECON(</>,{z}),X),{z}) 
= 
1, 
verifying (8.16). We begin the verification of (8.17) by expanding its left 
member, invoking Lemma 8.1.1 and the identity EDIS(EDIS(a,X),X) = 
EDIS(a,X): 
EDIS(ECON(AUG(</», {z} ),X) = EDIS(EDIS(ECON(</>, {z}),X),X) 
= EDIS(ECON(</>,{z}),X). 
We make use of definition (8.14) to complete the expansion of (8.17) as 
follows: 
EDIS(ECON(</>, {z} ),X):S:; </> + EDIS(ECON(</>, {z} ),X) . 
This formula is clearly an identity; hence AUG(</»(X, Y, z) = 0 is diagnostic, 
completing the proof. 0 
Example 8.1.2 Let us consider again the parametric model discussed in 
Example 8.1.1. The function EDIS(ECON(</>(X,Y,z),{z}),X) evaluates 
in this case to yiY2, which is not included in </>, i.e., the condition (8.8) is 
not satisfied. Thus </> is not diagnostic. The augmentation of </> is 
AUG(</» = </>+ EDIS(ECON(</>,{z}),X) 
= (Y~z' + XY2Z + xy~z' + X'YIZ) + (Y~Y2) 
= y~z' + Y2Z + xy~z' + X'YIZ . 
The model AUG(</» = 0 is diagnostic; hence, it is equivalent to the system 
(8.16,8.17), where j and fJ are specified as follows: 
xY~+YiY~ ~ j 
~ xY~+Yi 
fJ = YIY~· 

8.2. ADAPTIVE IDENTIFICATION 
201 
8.2 
Adaptive Identification 
We assume that the experimenter supplies a sequence (At, A2 , ••• ) of X-
values to the transducer under test and observes the corresponding sequence 
(J(A1),f(A2), ••• ) of z-values. We call the X-values test-inputs and we call 
the pair (Ai, f(Ai)) a test. A sequence of tests for which the test-inputs are 
distinct will be called an experiment. 
A given test (Ai, f(Ai)) may supply no new information; f(Ai) may be 
deducible, that is, from tests earlier in the experiment and from information 
supplied prior to the experiment. It is clear that there are situations, e.g., 
medical diagnosis, in which such superfluous tests should be avoided. In this 
section we describe a procedure for conducting an adaptive experiment, i.e., 
one in which the selection of each test-input is based on the outcomes of 
earlier tests. Each test in the resulting experiment is guaranteed to supply 
information not deducible from earlier tests or from information supplied 
prior to testing. 
We call an experiment definitive if, upon its completion, the experimenter 
has enough information to deduce the Boolean function f, i.e., if he can 
specify f(Ai) for any test-input Ai in {O,l}m. An exhaustive experiment, 
i.e., one which includes all 2m test-inputs in {O, l}m, is clearly definitive. Our 
object, however, is to construct definitive experiments based on a subset 
(preferably a small subset) of all possible inputs; those test-outcomes not 
found by experiment can be found if needed by deduction. 
8.2.1 Initial and Terminal Specifications 
After test i, the experimenter's knowledge concerning the transducer is rep-
resented by a diagnostic model, viz., 
</>i{X, Y, z) = 0 . 
(8.18) 
The index i indicates the number of tests already conducted in the experi-
ment. The transducer is thus characterized initially by the model <1>0 (X, Y, z) = 
O. Because <1>0 is diagnostic, there are Boolean functions io and go such that 
the initial model is equivalent to the system 
z = io(X, Y) 
o = go(Y). 
(8.19) 
(8.20) 
We call the pair (8.19, 8.20) an initial specification of the system, and we 
refer to io and go as initial functions. 

202 
CHAPTER 8. BOOLEAN IDENTIFICATION 
Equations (8.19,8.20) express the information available at the beginning 
of an experiment. Equation (8.20) specifies the y-constraints, and (8.19) the 
dependence of z upon X and Y, known prior to testing. The function io 
is not unique, but all allowable choices of io induce the same dependence 
of z upon X and Y for values of Y satisfying (8.20). The constraint (8.20) 
introduces "don't-care" conditions, in other words, into the specification of 
io (cf. Example 8.1.2). 
Theorem 8.2.1 Let a class of transducers be described in terms of initial 
functions io and go. At the completion of a definitive experiment, the infor-
mation concerning the transducer under test is expressed by the system 
z = f(X) 
° = g(Y), 
(8.21) 
(8.22) 
where f and 9 are unique Boolean functions and where g is given in terms 
of io, go, and f by the relation 
g(Y) = go(Y) + EDIS«(J(X) E9 io(X, Y», X) . 
(8.23) 
Proof. The information acquired by means of any definitive experiment is 
the same as that acquired by means of an exhaustive experiment; the latter 
information is expressed by the system 
z = io(X, Y) 
° 
go(Y) 
f(O, ... ,O,O) = io(O, ... ,0,0, Y) 
f(0, ... ,0,1) = io(O, ... ,0,1, Y) 
(8.24) 
f(0, ... ,1,0) = io(O, ... ,1,0, Y) 
f(1, ... ,1,1) = io(1, ... ,1,1,Y) . 
The first two equations are the initial specifications. Each of the 2m remain-
ing equations denotes the information supplied by a single test. In view of 
the latter equations, and making use of minterm expansion (cf. Theorem 
2.9.1), the first equation may be re-cast equivalently as follows: 

8.2. ADAPTIVE IDENTIFICATION 
203 
z = io(x,Y) 
= 
L: io( A, Y)X A 
Ae{O,I}m 
= 
L: f(A)XA 
Ae{O,I}m 
= f(X) . 
By Theorem 4.3.1, the remaining 2m + 1 equations in system (8.24) are 
equivalent to the single equation 
90(Y) + L (f(A) Ef) io(A, Y» = 0 , 
Ae{o,l}m 
which is re-written equivalently, in view of Theorem 4.8.1, as 
90(Y) + EDIS«(f(X) Ef) io(X, Y», X) = 0 . 
(8.25) 
The system (8.24) is thus equivalent to the system (8.21, 8.22), with g(Y) 
expressed by the left side of (8.25). The uniqueness of f and 9 is guaranteed 
by the disjointness ofthe arguments appearing in (8.21) from those in (8.22). 
o 
We call the pair (8.21,8.22) the terminal specification of the system, and 
we refer to f and 9 as the terminal functions. Equation (8.21) expresses the 
dependence of z upon X, for the existing fixed value of Y j equation (8.22) 
specifies the parameter-vector Y to within an equivalence-class, namely, the 
set of solutions of 0 = g(Y). 
Example B.2.1 Let io, 90, and f be given by the formulas 
io(X, Y) = XIY~ + X~Y2 + X~X~Y3 
90(Y) = YIY3 
f(X) = Xl + x~ . 
Applying Theorem 8.2.1, 
g(Y) 
YIY3 + EDIS([(XI + x~) Ef) (XIY~ + X~Y2 + X~X~Y3)],X) 
YIY3 + EDIS«x~x~y~y~ + XIX2YI + XIYIY~)'X) 
= 
YIY3 + (y~y~ + YI + YIY~) 
= 
YI + y~y~ . 

204 
CHAPTER 8. BOOLEAN IDENTIFICATION 
8.2.2 
Updating the Model 
The experimenter's knowledge after the test (Ai, I(Ai» is expressed by the 
pair of equations 
<Pi-t(X,Y,Z) = 0 
<Pi-t(Ai, Y, I(Ai» = O. 
(8.26) 
(8.27) 
The first equation expresses the experimenter's knowledge prior to the testj 
the second expresses the new information supplied by the test. The new 
state of affairs is therefore expressed by the model 
<Pi(X, Y, z) = 0 , 
(8.28) 
where <Pi, the updated model-function, is given by the recursion 
(8.29) 
If <Pi-1 = 0 is diagnostic and <Pi is defined by (8.29), then <Pi = 0 is also 
diagnostic (the proof is left as an exercise). 
Example 8.2.2 Assume again the initial functions 10 and 90, and the ter-
minal function I, given in Example 8.2.1. The experimenter knows 10 and 
90 (or, equivalently, the initial model-function, <Po), but does not know Ij 
his object is to determine the terminal functions I and g. The initial model-
function, <Po, is given by 
<Po 
(z EB 10) + 90 
, " 
" 
'" '" 
X2Y2 Z + Xl X2Z + X2Y3Z + X2Yt Z + Y1Y2Z + X1Y1 Z + Xt Y2Y3Z + Y1Y3 . 
The experimenter applies the test-vector X = (0,0), chosen at random, and 
observes that the resulting output-value is z = 1. The information supplied 
by this test is expressed by equation (8.27), which in the present instance 
takes the form 
YtY3 + Y~Y~ = 0 . 
(8.30) 
Applying the recursion (8.29) enables the experimenter to calculate <PI: 
<PI 
<Po + Y1Y3 + Y~Y~ 
= x~z' + X2Y1Z + X~X2Z + X1Y~Z' + Y1Y3 + Y~Y~ . 

8.2. ADAPTIVE IDENTIFICATION 
205 
8.2.3 
Effective Inputs 
The updated model tl>l(X, Y, z) = ° 
in Example 8.2.2, resulting from the test 
((0,0),1) (i.e., X = (0,0) => z = 1), supplies strictly more information 
concerning the transducer than does the initial model, t/>o(X, Y, z) = 0. If 
the test-input had been chosen to be X = (0,1), however, the test would 
have supplied no new information; the output (z = 0) is predictable from the 
initial model. The updated model-function resulting from the test ((0,1),0), 
is thus the same as the initial model-function, i.e., 
We wish to avoid such useless tests; hence we desire that the test-vector 
X = Ai+l be chosen so that the resulting output is not predictable from 
knowledge of the current model, tl>i = 0. Such a test-vector will be called 
effective. 
Input-equation. To assess the effectiveness of test-inputs, we associate 
a Boolean input-equation, 
tPi(X) = ° , 
(8.31) 
with the model tl>i = 0. The input-function, tPi, is defined as follows: 
tPi(X) = EDIS(ECON(tI>i, Y), {z}). 
(8.32) 
The utility of the input-equation is indicated in the next theorem. 
Theorem 8.2.2 Let the current state of knowledge concerning a class of 
transducers be expressed by the diagnostic model tl>i(X, Y, z) = 0, and let the 
Boolean function tP be defined by {8.32}. Then the effective inputs are the 
solutions of the equation 
tPi(X) = ° . 
(8.33) 
Proof. The relation between X and z is found by eliminating Y from the 
current model, tl>i = 0. The resultant is 
ECON(tI>i,Y) = 0. 
(8.34) 
The input-vector X = Ai+! supplied for the next test is effective in case the 
output z is not functionally deducible from (8.34). By Theorem 8.1.1, z is 
functionally deducible from (8.34) if and only if the condition 
EDIS(ECON(tI>i,Y),{z}) = 1 
(8.35) 

206 
CHAPTER 8. BOOLEAN IDENTIFICATION 
is satisfied. The left side of (8.34), i.e., "pi(X), is a two-valued function; hence 
the denial of (8.34) (the necessary and sufficient condition for an effective 
input) is expressed by (8.33). 0 
Example 8.2.3 Applying (8.32), the input-function "po corresponding to 
the initial model given in Example 8.2.2 is 
"po(X) = Z~Z2 . 
Thus the effective test-inputs, i.e., the solutions of z~ Z2 = 0, are (0,0), (1,0), 
and (1,1). The test-input employed in Example 8.2.2, X = (0,0), is thus 
verified as effective. The information supplied by test «0,0),1) is employed 
in Example 8.2.2 to derive an updated model, <PI = 0. The associated input-
equation is "pl(X) = 0, where 
"pI (X) = z~ + z~ . 
Thus there is now just one effective test-input, viz., X = (1,1). The ex-
perimenter determines that the response to that input is z = 1; hence the 
updated model is <P2 = 0, where 
<P2 
= <Pl(X,Y,Z) + <Pl(I,I,YhY2,Y3,1) 
= 
(z~z' + Z2YIZ + Z~Z2Z + ZIY~Z' + YIY3 + Y~Y~) + (Yl + Y~Y~) 
= 
z l z' + Z2Z' + z~ Z2Z + Yl + Y2Y~ . 
The input-equation is now"p2 = 0, where "p2 is determined by (8.32) to have 
the value 1. The equation 1 = ° has no solutions; thus there are at this 
point no effective inputs. The experiment «(0,0),1), «1,1),1» is therefore 
definitive. The final model-function has the expansion 
<P2 = (z EB (ZI + z~» + Yl + Y~Y~ ; 
hence the terminal functions are 
f(X) = 
ZI + z~ 
g(Y) = Yl + Y~Y~ . 
The function f (unknown to the experimenter at the outset) agrees with 
that given in Example 8.2.1. The equivalence-class of parameter-vectors is 
the set of solutions of g(Y) = 0; for the transducer just identified, the class 
is {(O, 0,1), (0, 1,0), (0, 1, 1 n. 

8.2. ADAPTIVE IDENTIFICATION 
207 
Terminal model. 
The number of distinct test-inputs is finite and 
no effective test-input repeats an earlier one. Thus if all test-inputs are 
effective, there is some index, k ~ 2m (as shown in the foregoing example), 
such that tP" = 1 is an identity. This indicates that no further effective test-
inputs exist, i.e., that the k tests performed thus far constitute a definitive 
experiment. Consequently we call 4>,,(X, Y, z) = ° 
a terminal model. 
Theorem 8.2.3 Let 4>,,(X, Y,z) = ° 
be a terminal model Jor a tmnsducer 
under test. Then the terminal Junctions J and 9 are given by 
J(X) = ECON(4),,(X,Y,O),Y) 
g(Y) = ECON(4),,(X,Y,z), {z}) . 
(8.36) 
(8.37) 
Proof. 
By Theorem 8.2.1, the model 4>,,(X, Y,z) = ° 
is equivalent to the 
system (8.21,8.22), from which' we conclude that 
4>,,(X, Y, z) = (z Ea J(X» + g(Y) . 
Thus 
ECON(4),,,Y) = II «z Ea J(X» + g(A» 
Ae{o,l}n 
= (z Ea J(X» + II g(A) 
Ae{O,l}n 
= zEaJ(X). 
The last line is derived from the assumption that the equivalence-class of 
parameter-vectors, i.e., the set of solutions of (8.21), is not empty. Thus the 
consistency-condition, 
II g(A) = 0, 
Ae{o,l}n 
(cJ. Theorem 6.1.1) is satisfied. Hence, 
ECON(4),,(X,Y,O),Y) = OEaJ(X) 
= J(X) , 
verifying (8.36). The following computations verify (8.37): 
o 
ECON(4),,,{z}) = «OEaJ(X»+g(Y»·«IEaJ(X»+g(Y» 
= (f(X) + g(Y» . (f'(X) + g(Y» 
= g(Y). 

208 
CHAPTER 8. BOOLEAN IDENTIFICATION 
8.2.4 
Test-Procedure 
Given the initial model, 4>o(X, Y, z) = 0, the experimenter's object is to 
determine the terminal functions f(X) and g(Y) by carrying out a sequence 
of effective tests. 
The algorithm shown in Figure 8.1 enables the experimenter to choose an 
effective test-input at each stage of an experiment. The algorithm is based 
on a diagnostic model-function, 4>(X, Y, z), from which the input-function 
t/J(X) is derived (subscripts are omitted). The test-input at each stage is 
obtained by solving the input-equation, t/J(X) = 0; the resulting observed 
output is used to re-calculate 4>(X, Y, z) and t/J(X), after which the process is 
repeated. The test-inputs derived in this way are necessarily distinct; hence, 
the updated model becomes equivalent ultimately to a terminal description; 
this condition is signaled when t/J(X) becomes equal identically to 1. 
1 
t/J(X):= EDIS(ECON(4>,Y), {z}) 
2 
while t/J(X) '" 1 do 
3 
begin 
4 
Select a solution, A, of t/J(X) = 0. 
5 
Apply X = A as a test-input. 
6 
Observe the corresponding output, z = f(A). 
7 
4>(X, Y, z):= 4>(X, Y,z) + 4>(A, Y, f(A» 
8 
t/J(X):=EDIS(ECON(4>,Y),{z}) 
9 
end 
10 
end 
11 
Return the terminal functions 
12 
f(X) = ECON(4)(X,Y,O),Y) 
13 
g(Y) = ECON(4)(X,Y,z),{z}) 
14 
end 
Figure 8.1: Algorithm for a definitive experiment. 
Example 8.2.4 Let us apply the foregoing procedure to identify a trans-
ducer in the class characterized by the diagnostic equation 4>0 = 0, where 4>0 
is given by 
4>0 = Y2Y~ + X~Y2Z + x~y~z + xlx~y~z' + X~X2Y~Z + XIX3Y~Z + 
XIX~X3Z + XIX3YIZ + X~X3Y2z' + X2X3Y~Y2Z' + x~x~Y~Y3Z' • 

EXERCISES 
209 
The following steps (shown with arguments indexed) constitute a definitive 
experiment: 
1/;0 
= X~X2X~ + XIX~X3 
Al 
= (1,1,1) 
!(Al ) = ° 
CPl 
= tPo + Y2Y~ + Y{Y2 
= Y2Y~ + yiY2 + XIX3Z + X~Y2Z + x~Y~z 
+XlX~Y~Z' + X~X2Y~Z + X~X3Y2Z' + X~X~Y~Y3z' 
1/;1 
= X~ X2X~ + Xl X3 
A2 
= (0,0,0) 
!(A2) = 1 
CP2 
= CPl+Y2+Y~ 
= Y2 + Y~ + XlX3Z + XlX~Z' + X~X2Z + X~X2Z' 
1/;2 
= 1 
!(X) = ECON(tP2(X,Y,O),Y) = XlX~ + x~x~ 
g(Y) = ECON(cp2(X,Y,z),{z}) = Y2 + Y~ 
The test-vectors Al and A2 were selected arbitrarily from among the so-
lutions, respectively, of 1/;0 = ° and 1/;1 = 0. The adaptive nature of this 
process enables us to identify the transducer after only two tests; an exhaus-
tive experiment would have required 23 = 8 tests. 
Exercises 
1. Show that if (8.2) is diagnostic, then the function j in equation (8.9) 
is any member of the interval 
cp'(X, Y, 1) ::; j(X, Y) ::; cp(X, Y,O), 
and that the function 9 in equation (8.10) is uniquely specified by 
g(Y) = ECON(cp,{z}). 
2. Given that CPi-l(X, Y,z) = ° is a diagnostic equation and that the 
Boolean function CPi is defined by 
show that CPi = 0 is also diagnostic. 

210 
CHAPTER 8. BOOLEAN IDENTIFICATION 
3. Line 7 of the algorithm shown in Figure 8.1 is the assignment 
4>(X, Y, z) := 4>(X, Y, z) + 4>(A, Y, f(A)) . 
Show that if 4> is diagnostic, then 
4>(X, Y,z) + 4>(A, Y, f(A)) = AUG(4)(X, Y,z) + XAzfl(A}) , 
whence line 7 of the algorithm may be replaced by 
4>(X, Y, z) := AUG(4)(X, Y,z) + XAzfl(A}) . 

Chapter 9 
Recursive Realizations of 
Combinational Circuits 
In this chapter we illustrate some applications of Boolean reasoning in the 
design of multiple-output switching circuits. The stimulus applied to the 
circuit shown in Figure 9.1 is an input-vector, X = (Xb X2, •.• , xm ), of bi-
nary signals; its response is an output-vector, Z = (Zb Z2, .•. , zn), of binary 
signals. We assume the circuit to be combinational, by which we mean that 
the value of Z at any time is a function of the value of X at that time. A 
sequential circuit, on the other hand, is one for which the value of Z may 
depend on past values of X as well as on its present value. 
Xl ---+I 
X2 ---+I 
Xm---+I 
Figure 9.1: Multiple-Output Circuit. 
Boolean methods for combinational circuit-design have been investigated 
for more than fifty years [145, 146, 183, 185]. The field nevertheless remains 
211 

212 
CHAPTER 9. RECURSIVE REALIZATIONS 
an area of active research; see Brand [16] and Brayton, et al. [18, 20] for 
summaries of recent work. 
It is not our intent to discuss the extensive and highly-developed theory 
of digital circuit design. The presentation in this chapter is arranged instead 
with the following objectives in mind: 
• to formulate the problem of multiple-output combinational circuit-
design within the framework of Boolean reasoning; and 
• to show how this formulation may be applied to solve a particular 
problem in circuit-design for which customary Boolean methods have 
proved inadequate. 
9.1 
The Design-Process 
Combinational circuit-design customarily proceeds by means of the following 
steps: 
1. Specification. Describe a class of circuits suitable to one's purpose 
by stating a relation between X and Z. A common specification-format 
is a truth-table. 
2. Solution. Solve the specification, i.e., find a vector switching func-
tion, F = (fl, 12, ... , In), such that the system 
Z = F(X) 
(9.1) 
implies the specification. The solution is chosen so that It, 12, ... , In 
can be represented by simplified formulas. 
3. Transformation. Transform the solution (9.1) into a system 
Z = G(X,Y) 
Y = H(X,Y) 
(9.2) 
such that the resultant of elimination of Y from (9.2) (cJ. Chapter 4) is 
equivalent to the solution (9.1). The transformation from (9.1) to (9.2) 
is carried out so as to optimize selected measures of cost and perfor-
mance. The transformation-process, whether automated or manual, is 
typically carried out by a sequence of local changes. The elements of 
the vector Y = (Yb Y2,' .. , Yk) represent "internal" signals, introduced 
as the transformation proceeds. 

9.2 SPECIFICATIONS 
213 
The problem we consider is how best to use a circuit's output signals-in 
addition to its inputs-to assist in the generation of its outputs. The ad-
vantageous use of available signals-including outputs-is a part of skilled 
manual design, but has thus far been automated only in limited ways. The 
text Synthesis of Electronic Computing and Control Circuits, published in 
1951 by the Staff of the Harvard Computation Laboratory [82] devotes a 
chapter to this problem; further work has been reported by Ho [85], Kobrin-
sky [105], Mithani [139], and Pratt [160]. 
The process of design outlined in this chapter differs in the following 
respects from the three-step procedure outlined earlier: 
• Specification-Format. 
The specification may be expressed ini-
tially in a number of ways, e.g., by an enumeration of (X, Z)-pairs, 
by a truth-table, or by a system of Boolean equations. It is reduced, 
however, to a single Boolean equation of the form 
4>(X,Z) = 1. 
(9.3) 
We call (9.3) the normal form for the specification. Reducing the spec-
ification to a single equation enables global dependencies and "don't-
care" conditions to be handled uniformly and systematically . 
• Nature of the Transformed System. 
The transformed system 
has the form 
Z = F(X, Z) 
(9.4) 
rather than that of (9.2). Thus the output-values may depend not only 
on the values of inputs but also on those of outputs. The function-
vector F in (9.4) is chosen to have the following properties: 
- Stability. 
The feedback implied by the presence of Z as an 
argument of F does not cause oscillation. 
- Economy. 
The total cost of the formulas expressing the func-
tions II, 12, ... , fk is as small as design-constraints will permit. 
9.2 
Specifications 
Let I = {O,l}m and 0 = {o,l}n be the input-space and output-space, 
respectively, of the combinational circuit shown in Fig. 9.1. A specification 
for the circuit is a relation 'R from I to 0, i.e., a subset of I X 0 (cf. Section 

214 
CHAPTER 9. RECURSIVE REALIZATIONS 
1.6). Thus an input-output pair (X, Z) is allowed by the specification if and 
only if (X, Z) E 'R 
Example 9.2.1 A 2-input AND-gate, for which X = (Xl,X2) and Z = Zl, 
is specified by the subset 
'R = {«O, 0), 0), «0,1),0), «1,0),0), «1, 1), I)} 
(9.5) 
of {O, 1}2 X {O, I}. 0 
A specification 'R will be called complete in case it defines a function 
from I into 0, i.e., in case each member of I appears exactly once as a left 
element of a pair in 'R. A specification will be called incomplete in case it is 
not complete, i.e., in case one or both of the following conditions occurs: 
(b) 
there is a vector A E I that appears in more than one pair in 'R 
as a left element; or 
( a) 
there is a vector A E I that fails to appear in any pair in 'R 
as a left element. 
These are referred to in circuit-design as "don't-care" conditions. If a vector 
A E I appears more than once as a left member of a pair (A, Z) E 'R 
(condition (a», then the circuit may be designed to produce whichever of 
the corresponding Z-values best meets the designer's objectives. If a vector 
A E I fails to appear as a left element of a pair in 'R (condition (b», then 
X = A is a forbidden input. The circuit-designer cannot enforce a condition 
of type (b), which is a constraint on the signal-source producing X. 
Any actual m-input, n-output circuit is defined by a set :F E <fIxo of 
ordered pairs denoting a function. The circuit will be said to realize a spec-
ification 'R provided the condition 
(X, Z) E :F 
==? 
(X, Z) E 'R 
(9.6) 
is satisfied if X appears as a left element of a pair in 'R. 
9.2.1 
Specification-Formats 
A specification 'R may be represented in a number of ways, e.g., by an enu-
meration of (X, Z)-pairs (as exhibited in Example 9.2.1), by verbal state-
ments, by a predicate-calculus formula, by a truth-table, or by a system of 

9.2 SPECIFICATIONS 
215 
Boolean equations. The explicit enumeration shown in (9.5), for example, 
may be represented by the equivalent specification 
(9.7) 
For most purposes, clearly, the form (9.7) is to be preferred over the enu-
merative form (9.5) 
Example 9.2.2 The information needed to convert between the JK and 
RST flip-flop types is expressed by the system 
Q'J + QK' 
o = 
S + Q'T + QR'T' 
RS+RT+ST 
(9.8) 
of Boolean equations. The first equation relates the next-state behavior of 
the two flip-flops; the second equation is an excitation-constraint on the RST 
flip-flop. If X = (J, K, Q) and Z = (R, S, T), then (9.8) specifies the logic to 
convert from an RST to a JK flip-flop; if X = (Q, R, S, T) and Z = (J, K), 
then (9.8) specifies the logic to convert from a JK to an RST flip-flop (the 
directions of these conversions may seem at first glance to be reversed!). 0 
Normal Form. 
A specification n, as defined above, is a Boolean 
constraint (c/. Section 4.6). Hence any specification may be expressed as a 
Boolean equation of the form 
¢>(X,Z) = 1 . 
(9.9) 
The function ¢> is defined in terms of the specification n as follows: for all 
(A,B) E {O,I}m+n, 
¢>(A, B) = 1 
{:=> (A, B) En. 
(9.10) 
The normal-form representation (9.9) is advantageous for a number of rea-
sons. It provides a standardized representation on which to base analysis 
and synthesis. The function ¢> corresponding to a given specification, n, is 
unique; the function ¢>, as we shall show, is directly related to a truth-table 
if expanded in minterms of X. Finally, the normal form provides a uniform 
and convenient way to represent and deal with "don't-care" conditions. 
Henceforth a specification will be assumed to be in normal form if not 
announced to be otherwise. 

216 
CHAPTER 9. RECURSIVE REALIZATIONS 
Example 9.2.3 The normal form of specification (9.8) is 
</>(J,K,Q,R,S,T) = 1, 
where </> is given by 
o 
</>(J, K, Q, R, S, T) = J'Q'S'T' + JQ' R' S'T + JQ'R'ST' 
+K'QR'T' + KQRS'T' + KQR'S'T. 
(9.11) 
(9.12) 
Theorem 9.2.1 Let a specification n ~ I X 0 be represented by the normal 
form </>( X, Z) = 1. Then </> is given by the expansion 
</>(X, Z) = L x P ZQ . 
(P,Q)E'R 
Proof. We show that, for all (A, B) E {O, 1 }m+n, the equivalence 
(9.13) 
L AP BQ = 1 
¢:::} 
(A, B) E n 
(9.14) 
(P,Q)E'R 
holds. Suppose for (A, B) E {O,l}m+n that the equation on the left side of 
(9.14) is satisfied. Each term in the summation has a value of either ° 
or 1. 
We therefore deduce from the relation 
AP BQ = {I if A = -: and B = Q 
(9.15) 
° otherwIse 
that (A, B) E R. Let us suppose on the other hand that (A, B) E n. Then 
(9.15) guarantees that one of the terms in the summation on the left of 
(9.14), and therefore the summation itself, has the value 1. 0 
Example 9.2.4 Let a specification be given by the following set of pairs: 
n = («0,0,0),(1,0», 
«0,0,0), (1, 1», 
«0,1,0), (1, 1», 
«1,0,0),(0,0», 
«1,0,0), (1,0», 
«1,0,1), (0,0», 
«1,0,1), (0, 1», 
«1,1,0), (0, 1», 
«1,1,1), (0,0», 
«1,1,1), (0,0», 
«1,1,1), (0, 0», 
«1,1,1),(0,0»} . 
(9.16) 

9.2 SPECIFICATIONS 
217 
Applying Theorem 9.2.1, n is equivalent to the normal-form specification 
¢ = 1, where ¢ is given by 
o 
¢ = x~X~X~ZIZ~ + x~X~X~ZIZ2 + X~X2X~ZIZ2 + xlx~x~ziz~+ 
XIX~X~ZIZ~ + XIX~X3Ziz~ + XIX~X3Ziz2 + XIX2X~ziz2+ 
XIX2X3Zi z~ + XIX2X3Zi Z2 + XIX2X3ZIZ~ + XIX2X3ZlZ2 • 
(9.17) 
Corollary 9.2.1 A specification (9.9) is complete if and only if the condi-
tion 
¢(A, Z) is a minterm on the Z-variables 
(9.18) 
is satisfied. 
Example 9.2.5 Suppose that X = (J,K,Q) and Z = (R,S,T). The speci-
fication (9.8) is incomplete because ¢(O, 0, 0, R, S, T) = S'T' is not a minterm 
on R,S,T. 0 
Example 9.2.6 Consider the specification 
Zl < 
X~X~ 
Xl + X~ 
~ Z2 < 
Xl + Zl , 
(9.19) 
for which X = (Xl, X2) and Z = (zt, Z2). The normal form for this specifica-
tion is the equation 
(9.20) 
in which ¢ is given by 
(9.21) 
Thus 
¢(O, 0, Zl, Z2) 
ZlZ2 
¢(O, 1, Zl, Z2) = ziz~ 
¢(1, 0, Zl, Z2) = ZiZ2 
(9.22) 
¢(1, 1, Zt, Z2) 
Zi Z2. 
Each of the foregoing is a Z-minterm; hence, the specification (9.19) is com-
plete. 0 

218 
CHAPTER 9. RECURSIVE REALIZATIONS 
9.2.2 
Consistent Specifications 
A specification is consistent (c/. Section 6.1) in case it can be solved for Z 
in terms of X, i.e., in case there is a system 
Z = G(X) , 
(9.23) 
such that the result of substituting (9.23) into (9.9), i.e., 
<fJ(X, G(X» = 1 , 
(9.24) 
is an identity. It is a direct consequence of Theorem 6.1.1 that (9.9) is 
consistent if and only if the condition 
e(X) = 1 
is satisfied; the function e is defined by 
e(X) = EDIS(<fJ(X, Z), Z). 
In view of Theorem 9.2.1, equation (9.26) takes the form 
e(X) = EDIS( L XPZQ,Z) 
(P,Q)e'R. 
= 
L X p • 
(P,Q)e'R. 
(9.25) 
(9.26) 
Thus specification n is consistent if and only if the input satisfies the con-
straint 
E x P = 1. 
(p,Q)e'R. 
(9.27) 
A specification may be consistent identically, i.e., (9.27) may be an iden-
tity. It may be also be consistent physically, i.e., the input-vector X may 
be constrained in such a way that (9.27) is satisfied for all values of X that 
are allowed physically to occur. The question of input-constraints, however, 
is extrinsic to the specification. We therefore take it as an axiom of circuit-
design that a given· specification is consistent, i.e., that the input-vector is 
constrained so as to satisfy condition (9.27). 

9.3 TABULAR SPECIFICATIONS 
219 
9.3 
Thbular Specifications 
To design a circuit realizing a specification 4>(X, Z) = 1 entails solving the 
specification, implicitly or explicitly, for Z in terms of X. Applying the 
methods discussed in Chapter 6, a general solution of 4>(X, Z) = 1, repre-
senting the set of all particular solutions, may be expressed by a system of 
recurrent subsumptions. Because of its recurrent nature (c/. Section 6.3) 
such a general solution is not convenient for locating particular solutions 
having desired properties. A more convenient form for a general solution is 
a non-recurrent system 
01(X) < ZI < fJl(X) 
02(X) ::; 
Z2 < fJ2(X) 
03(X) < Z3 < fJ3(X) 
(9.28) 
on(X) < Zn 
::; fJn(X) , 
in which the Zi are expressed by independent subsumptions. It is not possible 
in the general case to express a general solution as a system of the form 
(9.28). It is always possible, however, to express a general solution as a 
collection of such systems. This possibility was first investigated by Davio 
and Deschamps [45], and subsequently by Deschamps [49] and Brown [27]. 
We say that a specification is tabular in case it is equivalent to a system 
of the form (9.28). A specification is tabular (as we shall show) if and only if 
it can be expressed by a truth-table. Nearly all current approaches to digital 
design are based therefore on tabular specifications. 
To characterize tabular specifications, we note that (9.28) is equivalent 
to the system 
where 
4>1 (X, ZI) 
= 1 
4>2(X, Z2) = 1 
4>i(X, Zi) = oi(X)zi + fJi(X)Zi 
(9.29) 
(9.30) 
for i = 1,2, ... , n. Thus (9.28) is a general solution of the normal-form 
specification 4>(X, Z) = 1, where 4> is related to the functions 4>1,4>2, ••. , 4>n 
of (9.29) as follows: 
(9.31) 

220 
CHAPTER 9. RECURSIVE REALIZATIONS 
We conclude that a specification equivalent to 4>(X, Z) = 1 is tabular if and 
only if there are switching functions 4>10 4>10 ... , 4>n: {O, l}m+1--+ {O, I} such 
that the multiplicative expansion (9.31) holds. 
Theorem 9.3.1 A specification equivalent to 
(9.32) 
is tabular if and only if, for each A E {O,l}m, the discriminant 4>(A, Z) is 
either zero or reduces to a term on the z-variables. 
Proof. 
Suppose that (9.32) is tabular, i.e., suppose 4>10 4>10 ... , 4>n 
exist such that the expansion (9.31) holds. It is clear that the condition 
4>i(A,Zi) E {O,Z:,Zi,l} holds; hence, for each A E {o,l}m, 4>(A,Z) is either 
zero or is a Z-term. 
Suppose conversely that, for all A E {o,l}m, the discriminant 4>(A, Z) 
is either zero or reduces to a Z-term. Define Boolean functions 4>i(A, Zi) 
for A E {O,l}m and i E {1,2, ... ,n} as follows: if 4>(A,Z) is zero, then 
4>i(A, Zi) = 0; if 4>(A, Z) is a Z-term, then 
If z: is present in the term 4>(A, Z), 4>i(A, Zi) = z: . 
If Zi is present in the term 4>(A, Z), 4>i(A, Zi) = Zi . 
If neither z: nor Zi is present, 
4>i( A, Zi) = 1 . 
We may thus express 4>(A, Z) as lli=l 4>i(A, Zi), enabling us to develop 4>(X, Z) 
in X -maxterms as follows: 
4>(X,Z) = 
Ae{o,l}m 
n 
= 
II [[II 4>i(A, Zi)] + (XA)'] 
Ae{o,l}m i=l 
n 
= 
II II [4>i(A, Zi) + (XA)'] 
Ae{O,l}m i=l 
n 
= 
II II 
[4>i(A, Zi) + (XA)'] 
i=l Ae{o,l}m 
n 
= 
II 4>i(X, Zi) . 
i=l 
Thus (9.32) is tabular. 0 

9.3 TABULAR SPECIFICATIONS 
221 
Example 9.3.1 Equation (9.12) is a tabular specification for J and K in 
terms of Q, R, S, and T, because each ofthe discriminants 4>( J, K, 0, 0, 0, 0), 
4>(J,K,O,O,O,l), ... , 4>(J,K,l,l,l,l) is either zero or reduces to a J,K-
term. Equation (9.12) is not, however, a tabular specification for R, S, and 
T in terms of J, K, and Qj the discriminant 4>(l,O,O,R,S,T), for example, 
evaluates to R'S'T + R'ST', which does not reduce to a term on R,S,T. 0 
Example 9.3.2 Let the function 4> in a normal-form specification be given 
by 
4>(X, Z) = x~ X~ZlZ2 + X1X2X3 + X1X2Z~ Z2+ 
+X~X~ZlZ~ + X1X~Z~ z~ + X1X3Z~ . 
The discriminants of 4>(X, Z) with respect to X are 
4>(0,0,0, Z) 
Zl 
4>(0,0,1, Z) = ° 
4>(0,1,0, Z) = ZlZ2 
4>(0,1,1, Z) = ° 
4>(1,0,0, Z) 
z~ 
4>(1,0,1, Z) 
Z' 1 
4>(1,1,0, Z) 
Z~Z2 
4>(1,1,1, Z) 
1, 
(9.33) 
(9.34) 
each of which is either ° 
or a term on Z. Thus the specification is tabular. 
o 
Given a tabular specification 4>(X, Z) = 1, the functions 4>1, 4>1, .•. , 4>n in 
the expansion (9.31) are not unique. The set (9.28) of intervals derived from 
these functions, however, and thus the set of particular solutions, is unique. 
A convenient set of functions is the one constructed in the proof of Theorem 
9.3.1. These are found by the following rule: for i E {I, 2, ... , n}, 
4>i(X,Zi) = EDIS(4)(X,Z),Z - {Zi}) , 
If Z = {Zl' Z2, Z3}, for example, the functions 
4>1 (X, Zl) = EDIS(4)(X, Z), {Z2' Z3}) 
4>2(X,Z2) = EDIS(4)(X,Z),{Z1, Z3}) 
4>3(X,Z3) = EDIS(4)(X,Z),{ZI, Z2}) 
(9.35) 
(9.36) 

222 
CHAPTER 9. RECURSIVE REALIZATIONS 
Xl 
X2 
X3 
Zl 
Z2 
0 
0 
0 
1 X 
0 
1 
0 
1 
1 
1 
0 
0 
X 
0 
1 
0 
1 
0 
X 
1 
1 
0 
0 
1 
1 
1 
1 
X X 
Table 9.1: Sample Truth-table. 
are functions suitable for the expansion (9.31). 
Tabular specifications are precisely those that can be represented by a 
truth-table. To clarify the connection, let us examine Table 9.1. 
We notice two kinds of don't-care specifications in Table 9.1. The first, 
represented by an absent row, is a forbidden input-combination; the second 
kind of don't-care, represented by an X in the table, denotes an output 
variable (corresponding to an input-combination that may occur) that may 
be freely assigned on {O, I}. 
Let us reduce the specification expressed by Table 9.1 to normal form. 
We begin by noting that the input-combinations forbidden by the table are 
X = (0,0,1) and X = (0,1,1). These prohibitions are represented by the 
system 
XtX2X3 = 0 
X~X2X3 = o. 
The six rows of the table are expressed by the implications 
XtX2X~ = 1 ~ Zl = 1 
xlx2x~ = 1 ~ ZlZ2 = 1 
Xlx2x~ = 1 ~ ~ = 1 
Xlx2X3 = 1 ~ 
z~ = 1 
XlX2X~ = 1 ~ Z~Z2 = 1 
XlX2X3 = 1 ~ 
1 = 1 
(9.37) 
(9.38) 

9.4 STRONGLY COMBINATIONAL SOLUTIONS 
which are equivalent collectively to the system 
X~X~X~(Zl)' 
= 
I 
I ( 
)' 
X1X2X3 ZlZ2 = 
X1X~X~(Z~)' 
= 
I 
(')' 
X1 X2X3 Zl 
= 
I (' )' 
X1 X2X3 ZlZ2 = 
X1X2X3(1)' 
= 
o 
o 
o 
o 
o 
o 
223 
(9.39) 
of equations. The system composed of (9.37) and (9.39) (and thus the orig-
inal truth-table) is equivalent to the single equation 
4>(X,Z) = 1. 
The function 4> in (9.4b) is given by 
4>(X, Z) = 
x~ X~X~Zl + x~ X2X~ZlZ2 + X1X~X~Z~+ 
Xl X~X3Z~ + Xl X2X~Z~ Z2 + Xl X2X3 
(9.40) 
(9.41) 
in terms of the minterms of X j this is the same function as that shown in 
(9.33). There is a direct connection between truth-table (Table 9.1) and 
formula (above): each term of the formula specifies a row ofthe truth-table. 
This direct relationship is an advantage of standardizing on the I-normal 
form for a specification. 
9.4 
Strongly Combinational Solutions 
A system of the form 
Z=P(X,Z) 
(9.42) 
will be called an implicit solution of a specification 'R in case (9.42) implies 
'R. An implicit solution of'R having the specialized form 
Z = F(X) 
(9.43) 
will be called an explicit solution of 'R. 
Iterates. Define the iterates p1, p2, ... of P(X, Z) in (9.42) as follows: 
P1(X, Z) 
= P(X, Z) 
pk+1(X, Z) = P(X, pk(X, Z)) k = 1,2, ... 
(9.44) 
If there is an integer k such that the iterate pk(X, Z) depends only on 
X, then pi(X, Z) = pk(X, Z) for j > k. It can be shown that the least 

224 
CHAPTER 9. RECURSIVE REALIZATIONS 
such integer, if one exists, is less than 2n. If no such integer exists, then the 
sequence FI, F2, . .. ultimately becomes cyclic, all of its members depending 
essentially on Z. 
Example 9.4.1 The iterates of the system 
Zl 
XIZ~ 
Z2 = Xl + Zl 
(9.45) 
are the following: 
pO(X,Z) = 
[ 
XIZ~ ] 
Xl + Zl 
FI(X,Z) = 
[ Xl (Xl + Zl)' ] 
[ ~l ] 
Xl + (XIZ~) 
(9.46) 
Fi(X, Z) = 
FI(X, Z) 
j = 2,3, ... 
o 
Let us suppose that a circuit is characterized by the implicit solution 
(9.42), and that Fk(X, Z) depends only on X for some integer k. Then 
the circuit's outputs are guaranteed to stabilize, after the signal-waveform 
traverses k "loops" within the circuit, to values depending uniquely on the 
input-values. We thus define the implicit specification (9.42) to be strongly 
combinational in case the iterate F2n-I(X, Z) is independent of Z. 
Example 9.4.2 The sequence FI, F2, ... shown in Figure 9.2 is based on 
the implicit specification Fl. This specification is strongly combinational 
because pEl-and therefore all subsequent iterates-is dependent only on X. 
o 
9.5 
Least-Cost Recursive Solutions 
Given a consistent Boolean specification (9.9) for a multiple-output combi-
national circuit, we seek to design a realization that achieves economy by 
making use of outputs, as well as inputs, to produce outputs. Thus we seek 

9.5 LEAST-COST RECURSIVE SOL UTIONS 
225 
F1: 
Zl = Z2 Z3'+ X Zl + X'Z3' 
Z2 = X'+ Zl'Z3 + Z2 Z3' 
Z3 = Z2'+ X Zl 
F2: 
Zl = Z2 + X Zl 
Z2 = X'+ Zl' 
Z3 = X Z3'+ X Zl 
F3: 
Zl = Z3 + Z2 + X'+ Zl 
Z2 = X'+ Zl'Z3 + Zl'Z2' 
Z3 = X Z2 + X Zl 
F4: 
Zl = 1 
Z2 = X'+ Zl'Z2' 
Z3 = X Z3 + X Zl + X Z2 
F5: 
Zl = 1 
Z2 = X'+ Zl'Z2'Z3' 
Z3 = X 
F6: 
Zl = 1 
Z2 = X' 
Z3 = X 
F7: 
Zl = 1 
Z2 = X' 
Z3 = X 
Figure 9.2: An Iterate-Sequence. 

226 
CHAPTER 9. RECURSIVE REALIZATIONS 
functions ft, h, ... , / n such that the system 
Zl = ft(X, Z) 
Z2 
= h(X,Z) 
Zn = /n(X,Z) 
satisfies the following requirements: 
• it implies the specification (9.9); 
• it is strongly combinational; and 
• it minimizes some reasonable measure of cost. 
(9.47) 
The first requirement ensures that the implemented circuit is a solution 
of (i.e., does the job specified by) (9.9). The second requirement is needed 
because a circuit corresponding to (9.47) may involve feedback-loops that 
lead to physical paradoxes or oscillation. Some properly-operating combina-
tional circuits do include feedback-loops [90, 100, 133, 186]; we adopt a safe 
approach, however, by forbidding such loops. 
A particular solution of the specification (9.9) is a system of the form 
(9.1) that implies (9.9). The set of all particular solutions of (9.9) may be 
represented by a general solution (c/. Chapter 6) expressed as a system 
aleX) 
::::; Ul ::::; 
f3l(X) 
a2(X, Ul) 
::::; U2 ~ f32(X, Ul) 
a3(X, Ut, U2) 
~ U3 ~ f33(X, Ut, U2) 
(9.48) 
Qn(X,Ul,U2, ... ,Un-l) 
~ Un ~ f3n(X, Ul, U2,' .. , un-d 
of recurrent subsumptions, where (UI, U2, ... , un) is a permutation of the 
output-vector (Zl' Z2, ... , zn). Although the set of particular solutions rep-
resented by a general solution is unique, the form of a general solution (9.48) 
may vary widely from one permutation of the output-variables to another. 
Every particular solution 
UI = <PI (X) 
U2 = <P2(X) 
Un = <Pn(X) 
of (9.9) (and nothing else) is produced from (9.48) as follows: 
(9.49) 

9.5 LEAST-COST RECURSIVE SOL UTIONS 
227 
• choose <PI in the interval 
aleX) ~ <PI(X) ~ ,aleX); 
• choose <P2 in the interval 
a2(X, <PI (X» ~ <P2(X) ~ ,a2(X, <PI(X»; 
• etc. 
From a general solution (9.48), we may construct solutions of the form 
UI = heX) 
U2 = h(X,uI) 
(9.50) 
Un = In(X, UI, U2,"" Un-I) , 
by independent selection of the functions h, 12, ... , In in the intervals dis-
played in (9.48). 
We call an implicit solution of the form (9.50) recursive. Such a solu-
tion satisfies the first two of the requirements listed at the beginning of this 
section. It implies the specification (9.9) because it is a solution of that 
specification. It is physically realizable because its recursive structure corre-
sponds to a circuit free offeedback-Ioops: output UI depends only on inputs; 
output U2 depends only on inputs and UI; output U3 depends only on inputs, 
UI and U2; etc. 
The third of the requirements at the beginning of this section is that 
the system (9.50) should minimize some reasonable measure of cost, i.e., 
a measure related to circuit-complexity. The measure chosen should also 
be relatively easy to derive from the form of a solution. Solutions will be 
expressed by means of SOP (sum-of-products) formulas; hence a reasonable 
cost-measure is gate-input count, i.e., the number of inputs that would be 
supplied to gates if the solution were implemented in a two-level AND-to-OR 
circuit. (Input-signals and their complements are assigned zero cost.) Some 
formulas and their associated gate-input costs are shown below. 
a'bc + ab' 
a + b' 
a' + bcd' 
abc' 
Cost = 5 + 2 = 7 
Cost = 0 + 2 = 2 
Cost = 3 + 2 = 5 
Cost = 3 + 0 = 3 
Each cost is indicated as the sum of two numbers. The first number is the 
total count of inputs to first-level AND-gates; the second number is the count 
of inputs to the second-level OR-gate. A one-literal term does not require an 
AND-gate; a one-term formula does not require an OR-gate. Although the 

228 
CHAPTER 9. RECURSIVE REALIZATIONS 
gate-input cost is discussed in terms of gates, it is intended to measure the 
complexity of a collection of Boolean formulas and does not imply a specific 
implementation. 
To clarify some of the foregoing ideas, let us consider an example. 
Example 9.5.1 The system 
, 
I 
Zl = Xl + X2 X 3 + X2 X 3 
Z2 = X~X2 + X~X3 
(9.51) 
Z3 = X~X2X3 
has a gate-input cost of 7 + 6 + 3 = 16. This system is equivalent to 
(and is also the unique explicit solution of) a specification of the form 
I( Xl, X2, X3, Z}, Z2, Z3) = 1, where I is given by 
(9.52) 
Choosing the "natural" permutation (Ub U2, U3) = (z}, Z2, Z3) of the output-
variables, a general solution of I = 1 is 
Xl + x~x~ + X2X3 < 
Zl < 
Xl + x~x~ + X2X3 
xi X~X3Z~ + xi X2X~Z~ + xi X2 X3 Z1 < 
Z2 < xi X2 + xi X3 + z~ 
xix2x3zlz2 < 
Z3 < 
Z~Z~+ZIZ2+X~X~Z~+XIZ~ 
X~ X2X3 + X~ X3Z1 + X~ X2Z1 • 
(9.53) 
A large number of recursive particular solutions, all reducible to the unique 
explicit solution (9.51), can be derived from (9.53). Among the simplest of 
these is 
Zl = Xl + x~x; + X2X3 
Z2 = 
X~X2 + z~ 
Z3 = ZIZ2, 
for which the cost 7 + 4 + 2 = 13. 
(9.54) 
The permutation (UI' U2, U3) = (Z2' Z3, zd leads to a general solution for 
which a simplified recursive solution is 
Z2 = X~X2 + X~X3 
Z3 = X~X2X3 
(9.55) 
Zl = z~ + Z3, 

9.6 CONSTRUCTING RECURSIVE SOLUTIONS 
229 
with an associated cost of 6 + 3 + 2 = 11, a savings of 5 gate-inputs over the 
original explicit solution (9.51). 0 
9.6 
Constructing Recursive Solutions 
Our objective is to find a least-cost recursive solution of a specification 
</I(X,Z) = 1. 
(9.56) 
Let Zi be an argument in Z and denote the arguments in Z other than 
Zi by Z-i, i.e., 
Z-i = Z - {zd , 
and let V be a subset of Z-i. Given the specification (9.56), we associate 
three sets, n(Zi), S(Zi' V), and T(Zi), as follows with Zi and V: 
n(Zi) = [(</Ilzi)', (</IIZi)] 
S(Zi' V) = [(EDIS(</I, V)lzD', EDIS(</I, V)IZi] 
T(Zi) = [(</Ilzi)'· (</IIZi), (</Ilzi)' + (</IIZi)] . 
(9.57) 
(9.58) 
(9.59) 
A subsumptive general solution of the specification, if produced by the 
method of successive eliminations, defines the set of allowable Zi by 
Zi E S(Zi' V) , 
(9.60) 
the subset V being determined by the permutation of (ZI, Z2,' •• , zn) em-
ployed in constructing the solution. Example 9.5.1 illustrates that the forms 
(and therefore the costs) ofrecursive solutions are dependent upon that per-
mutation. One approach to finding a least-cost recursive solution, therefore, 
is to construct a general solution corresponding to each of the n! permu-
tations of the output-variables, to determine a least-cost solution based on 
each, and to select the best of such solutions. We describe an alternative 
approach, based on T(Zi) rather than on S(Zi, V). 
Lemma 9.6.1 If (9.56) is a tabular specification, Zi E Z, and V ~ Z-i, 
then 
(9.61) 
Proof. 
It follows from the tabular property of (9.56) that there are 
switching functions 9 and h such that 
</I(X, Z) = g(X, Zi) . h(X, Z-i) , 
(9.62) 

230 
CHAPTER 9. RECURSIVE REALIZATIONS 
whence 
(4)/ Zi) 
EDIS(4), V)/Zi 
= g(X, 1)· heX, Z-i) 
g(X, 1). EDIS(h(X, Z-i), V) . 
(9.63) 
(9.64) 
Theorem 4.8.4 guarantees that heX, Z-i) ~ EDIS(h(X, Z-i), V)j thus 
The relationship 
(4)/ zD' + (4)/ Zi) = g'(X, 0) + g(X, 1) + h'(X, Z-i) 
(9.65) 
follows from (9.62), and thus the inclusion 
(9.66) 
is verified on comparison of (9.64) and (9.65). We have thus verified the first 
inclusion-pair of the system 
(4)/Zi) 
~ EDIS(4),V)/zi 
~ (4)/zi)'+(4>/zi) 
(9.67) 
(4)/zi)'· (4)/Zi) 
~ (EDIS(4>, V)/zD' ~ (4)/zi)'. 
(9.68) 
The second inclusion-pair, (9.68), is verified by similar reasoning. 0 
Example 9.6.1 Given the tabular specification 
(9.69) 
the intervals R( zt) and T( zt} are given by 
R( zt} = [Xl + X2z2 , Xl X~Z2Z~ + xi X2Z~] 
T(ZI) = 
[Xlx2z2Z~ 
, 
Xl + X2] . 
The interval S( Zl, V), for various subsets V, is listed below: 
S(Z},{Z2}) 
= [Xl 
, 
xlx2z~+xix21 
S(Z},{Z3}) 
= [XI+X2Z2 , 
xlx2z2+xix2z~1 
S(Zt,{Z2,Z3}) = [Xl 
, XIX2+xix2]. 
Comparisons among the foregoing intervals verify the inclusions in (9.61). 
o 

9.6 CONSTRUCTING RECURSIVE SOL UTIONS 
231 
Theorem 9.6.1 Let (9.56) be a tabular specification and let Zi be an argu-
ment in Z. If the arguments in X U Z-i are constrained so that (9.56) can 
be solved for Zi, then 
(9.70) 
Proof. Equation (9.56) can be solved for Zi if and only if the consistency-
condition 
EDIS(¢,{zi}) = 1 
(9.71) 
holds. Assume that the arguments in XUZ_i are constrained so that (9.71), 
i.e., 
(¢/zD + (¢/Zi) = 1 , 
is satisfied, whence the equations 
(¢/zD' 
(¢/ Zi) 
become identities. The set-equality 
(¢/zi)'· (¢/Zi) 
(¢/zi)' + (¢/Zi) 
therefore holds, whence (9.70) follows from Lemma 9.6.1. 0 
(9.72) 
(9.73) 
(9.74) 
(9.75) 
Neither Lemma 9.6.1 nor Theorem 9.6.1 holds for a non-tabular specifi-
cation, as the following example shows. 
Example 9.6.2 The specification ¢(Xb Xz, Zb zz) = 1, where ¢ is given by 
(9.76) 
is non-tabular: ¢(O, 0, Zb zz), for example, evaluates to Zl + zz, which is not 
reducible to a term on (Zl' zz). The interval S(Zb {zz}) is given by 
[(EDI S( ¢, {zz})/ zi)', EDI S( ¢, {zz})/ Zi] 
= [X~X2' x~] . 
The interval T(Zi), on the other hand, is given by 
(9.77) 
The element X~X2 belongs to S(Zl' {Z2}) but not to T(Zi); hence S(Zl' {Z2}) 
is not a subset of T(Zi). 0 

232 
CHAPTER 9. RECURSIVE REALIZATIONS 
9.6.1 
The Procedure 
The following procedure produces a least-cost recursive solution of a consis-
tent tabular specification 4J(X, Z) = 1. 
1. For each Zi E Z, calculate T(Zi) by use of the relation (9.59), and 
determine the minimal determining subsets (c/. Section 4.9) on T(Zi). 
A minimal determining subset, M, on T(Zi) is a subset of XUY having 
the following properties: 
(a) the arguments of M suffice to express at least one function in 
T(Zi)j and 
(b) none of the proper subsets of M has property (a). 
2. Assign a cost, c(M), to each minimal determining subset M found in 
Step 2. Examples of possible cost-measures are 
• c(M) = the number of arguments comprised by M . 
• c(M) = the cost of a formula, expressed by the arguments in M 
and representing a function in the set T(Zi), that has least cost 
over all functions in T(Zi). 
3. Select a minimal determining subset, call it M(Zi), corresponding to 
each Zi E Z. This selection should meet the following conditions: 
(a) There is a permutation (Ub U2,"" un) of(zt, Z2, ••• , zn) such that 
• M(Ul) ~ X, and 
• M(Uk)~XU{Ul, ... ,Uk-d 
(l$k$n). 
(b) The total cost, i.e., 
%iEZ 
is minimized over all permutations (a). 
This procedure avoids the construction of a general solution, and sub-
sequent location of a least-cost recursive solution, for each permutation of 
Z. Instead, the minimal determining subsets (and their associated costs) 
are determined at the outset for each variable Zi. Only the contents and 
costs of the minimal determining subsets are then required to complete the 
procedure. 
The procedure has a number of limiting characteristics, summarized as 
follows: 

9.6 CONSTRUCTING RECURSIVE SOL UTIONS 
233 
1. The specification must be tabular. 
The restriction to tabular 
specifications is not as serious as it might appear. Essentially all exist-
ing design-techniques assume a tabular specification; thus no novelty 
in specification is introduced. A non-tabular specification can be han-
dled by decomposing it into a collection of tabular specifications; a 
solution of any of the component tabular specifications is a solution of 
the original non-tabular specification. Methods for carrying out such 
decomposition are discussed in [27]. 
2. Cost is measured by gate-inputs. The cost of a recursive solution 
is defined (in the program whose operation is described in the next 
subsection) to be gate-input count (c/. Section 9.5). This cost-function 
measures the number of inputs to gates in a two-level (AND-to-OR 
or NAND-to-NAND) realization of the formula, assuming that the 
complemented input-signals x~, x2' ... , x~ are available. The cost of a 
solution is the sum of the costs of its component formulas. 
3. Feedback is excluded. 
The organization of a recursive solution 
excludes closed loops, thereby guaranteeing that the corresponding cir-
cuit is strongly combinational. Kautz [100] has shown that such loops 
may be necessary to achieve minimal cost in a combinational circuit-
design, and Pratt [160] has developed transformation-techniques that 
produce strongly combinational designs incorporating closed loops. 
Restricting ourselves to recursive solutions, however, greatly reduces 
computational complexity. This reduction is gained, we believe, with-
out significant increase in gate-input cost. 
4. Redundant variables are excluded. The candidate argument-sets 
to generate output Zi E Z, for any value of i, are the minimal determin-
ing subsets of T(Zi). There are cases in which additional (and logically 
superfluous) arguments are needed to attain minimal cost; such a case 
is exhibited in Example 9.6.3. Such cases seem rare and the cost-
advantage to be gained by introducing superfluous arguments seems 
minor; the exclusive use of minimal determining subsets is therefore 
justified by the drastic reduction it induces in the space of formulas to 
be searched. 

234 
CHAPTER 9. RECURSIVE REALIZATIONS 
Example 9.6.3 The following example-specification was given in an early 
text [82, p. 90] on digital design: 
Zl = 
X~X2X3 + XIX~X~ + XIX~X3 + XIX2X~ 
Z2 = 
x~ X2X3 + XIX~X3 + XIX2X~ 
Z3 = 
x~x~x~ + X~X2X3 + XIX~X3 + XIX2X~ • 
The transformed system shown in [82] is 
Zl = 
X~X2X3 + XIX~ + XIX~ 
Z2 = X2 Z1 + X3Z1 
Z3 = 
x~x~x~ + Z2 , 
(9.78) 
(9.79) 
which has a gate-input cost of 21. The argument-set used to compute Z3, 
viz., {Xt,X2,X3,Z2}, is not minimal; one of its proper subsets, {Xt,X2,X3}, 
clearly suffices to determine Z3. A least-cost system based solely on minimal 
determining subsets is 
Zl = 
X~X2X3 + XIX~ + XIX~ 
Z2 = 
ZlZ3 
Z3 = X3Z1 + X2Z1 + x~x~z~ , 
which has a gate-input cost of 22. 0 
9.6.2 
An Implementation using BORIS 
(9.80) 
A program has been written using the reasoning-toolset BORIS (Boolean 
Reasoning In Scheme) to construct a least-cost recursive solution for a tab-
ular specification. 
The program accepts a system of Boolean equations or a representation 
of an incompletely-specified truth-table as input; either format is reduced by 
the program to a specification of the form 4> = I, where 4> is a Boolean func-
tion. After printing the terms of an SOP formvla for 4>, the program deter-
mines and prints the minimal zi-determining subsets for each output-variable 
Zi. These subsets are the basis for the subsequent search for an ordering of 
the output-variables leading to a least-cost recursive solution. Partial per-
mutations are built up during the search-process; the first output-variable in 
such a partial permutation, Ut, must depend only on input-variables. The 
next output-variable, U2, may depend on Ul as well as on inputs; U3 may 
depend on Ul and and U2 as well as on inputs, and so on. The search-process 

9.6 CONSTRUCTING RECURSIVE SOLUTIONS 
235 
is branch-and-bound, maintaining open and closed sets of partial permuta-
tions, using gate-input count (discussed in Section 9.5) as a measure of cost. 
In the example discussed below, the sequence of best partial permutations 
generated during the search is 
(8 (V 8 A CD» 
(11 (W 11 ABC D» 
(14 (V 8 A C D) (U 6 B V» 
(15 (V 8 A C D) (W 7 A B V» 
(15 (U 15 ABC D» 
A partial permutation is represented, as shown above, by a list of the form 
where "Cost" denotes total accumulated gate-input cost and each sublist 
P( Uj) (j = 1, ... , k) has the form 
(Uj c(M(uj» Ml(Uj) M2(Uj) ... ). 
The list 
(14 (V 8 A C D) (U 6 B V» 
represents a typical partial permutation. This shows that V is the first 
output-variable in the permuted sequence, with functional dependence on 
variables A, C, D, and gate-input cost 8. The second output-variable in the 
sequence is U, with dependence on B and V, and cost 6. The total cost, 8 
+ 6 = 14, is displayed first in the list. 
Example 9.6.4 A circuit is to be designed in conformity with the 14-row 
truth-table shown in Table 9.2. The inputs are a, b, c, and dj the outputs 
are u, v, and w. Using standard design-techniques, taking advantage of the 
"don't-care" entries in the table, a least-cost realization is 
U = be + bd + a'cd + a'b'c'd' 
v = a'cd + a'c'd' 
w 
a + b' c + b'd + bc'd' 
with costs for u, v, and w of 15, 8, and 11, respectively. Thus the least cost 
using conventional techniques is 34. 

236 
CHAPTER 9. RECURSIVE REALIZATIONS 
a 
b 
c 
d 
u 
v 
w 
0 
0 
0 
0 
1 
1 
0 
0 
0 
0 
1 
0 
0 
1 
0 
0 
1 
0 
0 
0 
1 
0 
0 
1 
1 
1 
1 
X 
0 
1 
0 
0 
0 
1 
1 
0 
1 
0 
1 
1 
0 
0 
0 
1 
1 
0 
1 
0 
0 
0 
1 
1 
1 
X 
X 
X 
1 
0 
0 
0 
0 
0 
1 
1 
0 
0 
1 
X 
X 
1 
1 
0 
1 
0 
X 
0 
1 
1 
0 
1 
1 
0 
0 
X 
1 
1 
0 
0 
X 
0 
X 
1 
1 
0 
1 
1 
0 
1 
Table 9.2: Truth-table for sample design. 
Figure 9.3 shows the BORIS-output in designing a recursive realization 
of the circuit. The Scheme-function DESIGN has two arguments: the first, 
named SAMPLE in this case, denotes a specification, n (a truth-table in this 
example); the second argument denotes the output-vector, Z. The result, 
v 
a'cd + a'c'd' 
u 
b'v + bv' 
w = u + a' , 
has a gate-input cost of 16. 

9.6 CONSTRUCTING RECURSIVE SOL UTIONS 
[10] (DESIGN SAMPLE '(U V V» 
Function: 
A'B'C'D'U V V' 
A'B'C'D U'V'V 
A'B'C D'U'V'V 
A'B'C D U V 
A'B C'D'U'V V 
A'B C'D U V'V' 
A'B C D'U V'V' 
A'B C D 
A B'C'D'U'V'V 
A B'C'D V 
A B'C D'V'V 
A B'C D U'V' 
A B C'D'V' 
A B C'D U V'V 
Minimal Determining Subsets: 
U «B V) (A BCD) (A C D V» 
V «A B U) (A CD» 
V «A U) (A B V) (A BCD» 
(0) 
(8 (V 8 A CD» 
(11 (V 11 ABC D» 
(14 (V 8 A C D) (U 6 B V» 
(15 (V 8 A C D) (V 7 A B V» 
(15 (U 15 ABC D» 
(16 (V 8 A C D) (U 6 B V) (V 2 AU» 
U = B'V + B V' 
V = A'C D + A'C'D' 
V = U'+ A 
DONE 
Figure 9.3: BORIS-output for sample design. 
237 

Appendix A 
Syllogistic Formulas 
Our approach to Boolean reasoning owes much to the work of A. Blake [10]. 
In this Appendix we outline Blake's theory of syllogistic Boolean formulas, 
modifying his notation and some details of his proofs, but retaining insofar 
as possible his point of view. 
The reader is assumed to be familiar with the definitions given at the 
beginning of Chapter 4 concerning Boolean formulas; some definitions, how-
ever, are repeated for convenience. We assume that Boolean functions are 
expressed by disjunctive normal (SOP) formulas; thus "formula" will invari-
ably mean "disjunctive normal formula." A Boolean function will be denoted 
by one of the lower-case letters f, g, h and a formula representing that func-
tion by the corresponding upper-case letter (F, G, or H). A term (conjunct) 
will be represented by one of the lower-case letters p, q, r, s, t; a term will be 
treated either as a function or as a formula, depending on context. Literals 
are denoted by x, y, or z. 
Two formulas will be called equivalent (=) in case they represent the 
same function, i.e., in case one can be transformed into the other, in a finite 
number of steps, by application of the laws of Boolean algebra. Two formulas 
will be called congruent (,g,) in case one can be transformed into the other 
using only the commutative law. Thus congruent formulas may differ only 
in the order of enumeration of their terms and in the order of the literals 
comprised by any term. 
Given two Boolean functions 9 and h, we say that 9 is included in h, 
written 9 ::; h, in case the identity gh' = 0 is fulfilled. When applied to 
formulas (e.g., G ::; H), the relation::; will refer to the functions those 
formulas represent. 
239 

240 
APPENDIX A. SYLLOGISTIC FORMULAS 
A.1 
Absorptive Formulas 
An SOP formula F will be called absorptive in case no term in F is absorbed 
by any other term in F. If F is not absorptive, then an equivalent absorptive 
formula, which we call ABS(F), may be obtained from F by successive 
deletion of terms absorbed by other terms in F. 
Lemma A.I.1 The formula ABS(F) is unique to within congruence. 
Proof. Suppose G1 and G2 are two absorptive formulas derived from F 
by the deletion, in different order, of absorbed terms. Let p be a term of G1. 
Then p is a term of F that is not absorbed by any other distinct term of Fj 
hence, p must be a term of G2 • Similarly, any term of G2 must be a term of 
G1 • Hence, G1 ~ G2 • 0 
It is clear that ABS(F) is equivalent to F. There may be absorptive 
formulas equivalent to F, however, that are not congruent to ABS(F). Let 
F, for example, be the formula 
ac' + b'c + a'b + a'b'c . 
Then ABS(F) is the formula ac' + b'c + a'b. The absorptive formula 
a'c + be' + ab' 
is equivalent to F, but not congruent to ABS(F). 
A.2 
Syllogistic Formulas 
Let F and G be SOP formulas. We say that G is formally included in F, 
written G ~ F, in case each term of G is included in some term of F. We 
write G ~ F if G is not formally included in F. Formal inclusion clearly 
implies inclusion, i.e., G ~ F => G::; F for any F, G pair. Formula F will 
be called syllogistic in case the converse also holds, i.e., in case, for every 
SOP formula G, 
G:::;F=>G~F. 
Thus F is syllogistic if and only if every implicant of F is included in some 
term of F. 
Lemma A.2.1 Let F, G, and H be SOP formulas. If F ~ G + Hand 
G ~ H, then F ~ H. 

A.2. SYLLOGISTIC FORMULAS 
241 
Proof. 
Consider any term p of F, and suppose that p f::. H. Then there 
is a term q of G such that p ::::; q. Since G <:: H, there is a term r of H such 
that q ::::; r. Thus p ::::; r, whence p <:: H, a contradiction. Thus every term 
of F is formally included in H. 0 
Lemma A.2.2 Let F be an SOP formula. F is syllogistic if and only if 
ABS(F) is syllogistic. 
Proof. Suppose F is syllogistic and let p be an implicant of ABS(F). Then 
p::::; F, whence p <:: F, Le., there is a term q of F such that p:5 q. Let r be 
a maximal term of F (Le., a term made up of a minimal number of letters), 
possibly q, such that q :5 r. Now p :5 rand r must be a term of ABS(F)j 
therefore p :5 ABS(F) and we conclude that ABS(F) is syllogistic. Suppose, 
conversely, that ABS(F) is syllogistic. Every term of ABS(F) is a term of 
Fj hence F must also be syllogistic. 0 
Lemma A.2.3 Let Fl and F2 be syllogistic. If Fl == F2 then ABS(Ft) ,g, 
ABS(F2). 
Proof. Suppose Fl and F2 to be equivalent syllogistic formulas. We deduce 
from LemmaA.2.2 that ABS(F) <:: ABS(G) and that ABS(G) <:: ABS(F). 
Let p be a term of ABS(F). There is a term q of ABS(G) such that p::::; qj 
also, there is a term r of ABS(F) such that q :5 r. Thus p ::::; r, whence 
p = r (because ABS(F) is absorptive) and therefore p = q. We conclude 
that every term of ABS(F) is a term of ABS(G)j similarly, every term of 
ABS(G) is a term of ABS(F). Hence, ABS(F) ,g, ABS(G). 0 
Given SOP formulas F and G, we define F x G to be the SOP formula 
produced by mUltiplying out the conjunction FG, using the distributive laws. 
If F = L:i Si and G = L:j tj, then 
F x G = E E Si • tj , 
i 
j 
where repeated literals are dropped in each product Si· tj of terms, Si·1 = Si, 
and 1 . tj = 1j also a product is dropped if it contains a complementary 
pair of literals. The operation X is commutative and associativej hence, 
Fl X F2 X ••• X Fk denotes without ambiguity the SOP formula produced by 
multiplying out FlF2 ... Fk in the manner discussed above. 
Theorem A.2.1 Let Fl , ... , Fk be syllogistic formulas. Then Fl X ••• X Fk 
is syllogistic. 

242 
APPENDIX A. SYLLOGISTIC FORMULAS 
Proof. Let t be an implicant of Fl X· ··X Fk. Then t ~ Fi for i = 1,2, ... , k; 
further, t <: Fi, since the Fi are syllogistic. Thus each of the Fi contains a 
term Pi such that t ~ Pi, and therefore t ~ n~=l Pi. But n~=l Pi is a term of 
Fl X ••• X Fk; hence Fl X ••• X Fk is syllogistic. 0 
Let a be any letter. Two terms will be said to have an opposition in case 
one term contains the literal a and the other the literal a'. (If the symbol x 
stands for the literal a', then we shall understand x' to stand for a.) 
Lemma A.2.4 [fterms rand s have no oppositions, then r+s is syllogistic. 
Proof. 
We assume that neither r nor s is the term 1, for which case the 
lemma holds trivially. Suppose the lemma to be false, i.e., suppose that there 
are terms rand s having no oppositions such that r + s is not syllogistic. 
Then there is a term t such that t ~ r + s, t 1: r, and t 1: s. Thus each of the 
terms r and s contains a literal not in t, i.e., r = XP and s = yq, where x and 
yare literals not in t, p is a term not involving x, and q is a term not involving 
y. Now t ~ r + s => tr's' = 0 => t(x' + P')(y' + q') = 0 => tx'y' = o. 
Thus, either x'y' = 0 or one of the literals x or y appears in t. The former 
is ruled out by the hypothesis that rand s have no oppositions, the latter 
by explicit assumption; hence, we have arrived at a contradiction. 0 
Theorem A.2.2 Let rand s be terms. The formula r + s is non-syllogistic 
if and only if rand s have exactly one opposition. 
Proof. Let k be the number of oppositions between r and s. If k = 0, then 
r + s is syllogistic by Lemma A.2.4. Suppose k ~ 1, i.e., suppose r = x'p 
and s = xq, where x is a literal and p and q are terms not involving x' or x 
(if r = x', then p = 1; if s = x, then q = 1). Consider first k = 1, in which 
case pq -I O. Let t be the term formed from pq by deleting duplicate literals. 
Then t ~ r + s, since tr's' = pq(x + p')(x' + q') = O. However t 1: r, because 
tr' = pq( x + p') = pqx -I o. It follows similarly that t 1: s. Thus r + s is not 
syllogistic if k = 1. Consider now k > 1, in which case pq = 0, and let t be 
any term such that t ~ r+s, so that tr's' = t(x+P')(x'+q') = txq'+tx'p' = o. 
Then tx ~ q and tx' ~ p, from which we deduce that tx ~ qx = sand 
tx' ~ px' = r. Either x or x' must appear in t, for suppose neither appears. 
Then txq' + tx'p' = 0 => tq' + tp' = 0 => t ~ pq. But pq = 0 for k > 1; 
hence t = 0, contradicting the assumption that t is a term. If x appears 
in t, then tx = t and therefore t ~ s. If x' appears in t, then tx' = t and 
therefore t ~ r. If k > 1, therefore, t ~ r + s implies that either t ~ r OJ 

A.2. SYLLOGISTIC FORMULAS 
243 
t ::; s for every term t, Le., r + s is syllogistic. We conclude that r + s is 
non-syllogistic if k = 1 and is syllogistic otherwise. 0 
Suppose two terms rand s have exactly one opposition. Then the con-
sensus [161] of rand s, which we shall denote by c( r, s), is the term obtained 
from the conjunction rs by deleting the two opposed literals as well as any 
repeated literals. The consensus c( r, s) does not exist if the number of op-
positions between rand s is other than one. The consensus of two terms 
was called their "syllogistic result" by Blake. 
Lemma A.2.5 Let r + s be a non-syllogistic SOP formula. Then 
(i) r+s+c(r,s)=r+s 
(ii) 
r + s + c(r,s) is syllogistic. 
Proof. 
Applying Theorem A.2.2, r + s is non-syllogistic if and only if 
r = x'p and s = xq, where p and q are terms such that pq :f O. The 
consensus c( r, s) is the term formed from pq by deleting duplicate literalsj 
let pq henceforth denote that term. To prove (i), we re-express r + s + c( r, s) 
as x'p + xq + pq, which is equivalent, by Property 8, Section 3.5, to x'p + xq. 
To prove (ii), we show that if a term t is such that t ::; r + sand t ~ r + s, 
then t ::; pq (recalling that c( r, s) = pq). The condition t ::; r + s holds if 
and only if tr's' = txq' + tx' p' = O. Now t cannot involve x, for otherwise 
txq' = 0 =} tx( q' + x') = 0 =} txs' = 0 =} ts' = 0 =} t ::; s. Similarly, t 
cannot involve x'. Thus txq' +tx'p' = 0 =} tq' +tp' = t(pq)' = 0 =} t ::; pq. 
o 
Theorem A.2.3 If an SOP formula F is not syllogistic, it contains terms 
p and q, having exactly one opposition, such that c(p, q) is not formally 
included in F. 
Proof. Let n be the number of distinct letters appearing in F and define R 
to be the set of implicants of F that are not formally included in F. Define 
the degree of any member of R to be the number of its literals. Let t be any 
member of R of maximal degreej this degree is less than n because a term of 
degree n (Le., a minterm) is formally included in any SOP formula in which it 
is included. There is therefore some letter, x, that appears in F but is absent 
from t. The terms tx' and tx are implicants of F whose degree is higher than 
that of tj hence, tx' ~ F and tx ~ F, i.e., F contains terms p and q such 
that tx' ::; p and tx ::; qj hence t ::; p + q. But t is not formally included in 

244 
APPENDIX A. SYLLOGISTIC FORMULAS 
p + q and thus p + q is not syllogistic; from Theorem A.2.2, therefore, p and 
q have exactly one opposition. From part (ii) of Lemma A.2.5, moreover, 
t $ c(p, q). Suppose c(p, q) < F; then t < F. But t <t. F because t is a 
member of R. Hence c(p,q) <t. F. 0 
Corollary A.2.1 If an SOP formula F is not syllogistic, then ABS(F) 
contains terms p and q, having exactly one opposition, such that c(p, q) <t. 
ABS(F). 
Proof. 
By Lemma A.2.3, if F is not syllogistic, then ABS(F) is not 
syllogistic; hence Theorem A.2.3 is applicable to ABS(F). 0 
A.3 
Prime Implicants 
An implicant of a Boolean function f is a term p such that p $ f. A prime 
implicant of f is an implicant of f that ceases to be so if any of its literals 
is removed. The concept of a prime implicant (due to Quine [161]) does not 
appear in Blake's development; however, prime implicants are intimately 
related, as we show, to syllogistic formulas. 
Lemma A.3.1 An implicant p of a Boolean function f is a prime implicant 
of f in case the implication 
p$q$f 
==? 
p=q 
(A.l) 
holds for every term q. 
Proof. 
Suppose that p is an implicant of f satisfying (A.l) and that 
p is not a prime implicant of f. Then p is congruent to one of the forms 
xr or x'r, where x is a literal and r is an implicant of f, i.e., r $ f. Thus 
p $ r $ f and p :j:. r, and we conclude that p does not satisfy (A.l), which 
is a contradiction; thus p is a prime implicant of f. Suppose on the other 
hand that p is a prime implicant of f, i.e., that p $ f and that if r is a 
proper sub product of p, then r 1: f. Suppose further that p $ q $ f for 
some term q. The condition p $ q holds between terms if and only if either 
p = q or q is a proper subproduct of p. The latter is ruled out because no 
proper sub product of a prime implicant of f is an implicant of f, and we 
have assumed that q $ f. Hence p = q, establishing condition (A.l). 0 

A.4. THE BLAKE CANONICAL FORM 
245 
Lemma A.3.2 If r is an implicant of f, then there is a prime implicant p 
of f such that r ~ p. 
Proof. If r is a prime implicant of f, then p = r. If r is not a prime 
implicant of f, then there is an implicant ql '" r of f such that t ~ ql ~ f. 
If ql is not a prime implicant of f, then there is an implicant q2 '" ql of f 
such that ql ~ q2 ~ f. This process must ultimately terminate, yielding a 
prime implicant p of f such that t ~ p. 0 
Theorem A.3.1 Let F be an SOP formula for a Boolean function f. Then 
F is syllogistic if and only if every prime implicant of f is a term of F. 
Proof. Suppose F is syllogistic and let p be a prime implicant of f. Then 
p ~ f, whence p ~ F, i.e., p ~ q ~ F, where q is a term of F. Thus p = q 
by the definition of a prime implicant, whence p is a term of F. Suppose 
on the other hand that every prime implicant of f is a term of F. Let t be 
a term such that t ~ Fj by Lemma A.3.2 there is a prime implicant p of f 
(possibly t) such that t ~ p. But p is a term of F, and therefore t ~ F. 
Thus F is syllogistic. 0 
AA The Blake Canonical Form 
Let F be a syllogistic formula for a Boolean function f. We call the formula 
ABS(F) the Blake canonical form for f, and we denote it by BCF(f). The 
function f determines the formula BCF(f), by Lemma A.2.2, to within 
congruence. Blake called this formula the "simplified canonical form" and 
showed that it is minimal within any class of syllogistic formulas for f, i.e., 
if F is syllogistic, then F == BCF(f) implies that every term of BCF(f) is 
a term of F. 
Theorem A.4.1 Let f be a Boolean function. Then BCF(f) is the dis-
junction of all of the prime implicants of f. 
Proof. 
BCF(f) is syllogistic (Lemma A.2.1)j hence, by Theorem A.3.1, 
every prime implicant of f is a term of BCF(f). It only remains to show 
that every term of BCF(f) is a prime implicant of f. Suppose the contrary, 
i.e., suppose there is a term p of BCF(f) that is not a prime implicant of f. 
From the relation p ~ BCF(f) it follows that there is a term q '" p such that 
p ~ q ~ BCF(f). Since BCF(f) is syllogistic, q ~ BCF(f), i.e., BCF(f) 
contains a term r such that q ~ r. Thus BC F(f) has distinct terms p and r 
such that p ~ r, which is a contradiction because BCF(f) is absorptive. 0 

Bibliography 
[1] Adam, A., "An application of truth-functions in formalized diagnos-
tics," Acta Cybernetica, vol. 2, pp. 291-298, 1976. 
[2] Akers, S.B., "On a theory of Boolean functions," J. Soc. Indust. Appl. 
Math., vol. 7, no. 4, pp. 487-498, Dec. 1959. 
[3] Arnold, B.H., Logic and Boolean Algebra. Englewood Cliffs, N.J.: 
Prentice-Hall, 1962. 
[4] Ashenhurst, R.L., "Simultaneous equations in switching theory," Re-
port BL-5, Harvard Computation Lab., Harvard University, 1954, pp. 
1-8. 
[5] Ashenhurst, R.L., "The decomposition of switching functions," Proc. 
International Symposium on the Theory of Switching, April, 1957. Vol. 
29 of Annals of the Computation Laboratory of Harvard University, pp. 
74-116, 1959 (Included in [42] as an appendix). 
[6] Beatson, T.J., "Minimization of components in electronic switching 
circuits," Trans. A.I.E.E., Part I, Communications and Electronics, 
vol. 77, pp. 283-291, 1958. 
[7] Bennett, A.A. and C.A. Baylis, Formal Logic: A Modern Introduction. 
New York: Prentice-Hall, 1939. 
[8] Bing, K., "On simplifying propositional formulas" (abstract) Bull. 
Amer. Math. Soc., vol. 61, p. 560, 1955. 
[9] Bing, K., "On simplifying truth-functional formulas," J. Symbolic 
Logic, vol. 21, pp. 253-254, 1956. 
247 

248 
BIBLIOGRAPHY 
[10] Blake, A., "Canonical expressions in Boolean algebra," Dissertation, 
Dept. of Mathematics, Univ. of Chicago, 1937. Published by Univ. of 
Chicago Libraries, 1938. 
[11] Bochmann, D., "Boolean differential calculus. A survey," (in Russian), 
Izv. Akad. Nauk SSSR Tech. Kibernet., no. 5, pp. 125-133, 1977. En-
glish translation: Engrg. Cybernet., vol. 15, no. 5, pp. 68-75. 
[12] Boole, George, The Mathematical Analysis of Logic. London: G. Bell, 
1847 (Reprinted by Philosophical Library, New York, 1948). 
[13] Boole, George, An Investigation of the Laws of Thought. London, Wal-
ton, 1854 (Reprinted by Dover Books, New York, 1954). 
[14] Borland International, Turbo Pascal Owner's Handbook, Scotts Valley, 
CA,1987. 
[15] Bossen, D.C. & S.J. Hong, "Cause-effect analysis for multiple fault 
detection in combinational networks," IEEE Trans. on Computers, 
vol. C-20, pp. 1252-1257, Nov. 1971. 
[16] Brand, D., "Logic Synthesis," in Design Systems for VLSI Circuits, 
ed. by G. De Micheli, A. Sangiovanni-Vincentelli, and P. Antognetti. 
Boston: Martinus Nijhoff Publishers, 1987. 
[17] Brayton, R.K. & C. McMullen, "The decomposition and factorization 
of Boolean expressions," Proc. Int'l. Symp. on Circuits and Systems, 
pp. 49-54, 1982. 
[18] Brayton, R.K., G.D. Hachtel, C.T. McMullen, and A.L. Sangiovanni-
Vincentelli, Logic Minimization Algorithms for VLSI Synthesis. 
Boston: Kluwer Academic Publishers, 1984. 
[19] Brayton, R.K., "Factoring logic functions," IBM J. Res. Develop., vol. 
31, no. 2, pp. 1877-198, March 1987. 
[20] Brayton, R.K., "Algorithms for Multi-Level Logic Synthesis and Opti-
mization," in Design Systems for VLSI Circuits, ed. by G. De Micheli, 
A. Sangiovanni-Vincentelli, and P. Antognetti. Boston: Martinus Ni-
jhoff Publishers, 1987. 
[21] Bredeson, J.G. and P.T. Hulina, "Generation of prime implicants by 
direct multiplication," IEEE Trans. on Computers, vol. C-20, pp. 475-
476, 1971. 

BIBLIOGRAPHY 
249 
[22] Breuer, M.A., S.J. Chang, and S.Y.H. Su, "Identification of multiple 
stuck-type faults in combinational networks," IEEE Transactions on 
Computers, vol. C-25, no. 1, pp. 44-54, January 1976. 
[23] Brown, F.M., "Reduced solutions of Boolean equations," IEEE Trans. 
on Computers, vol. C-19, pp. 976-981, 1970. 
[24] Brown, F.M., "Single-parameter solutions of flip-flop equations," IEEE 
Trans. on Computers, vol. C-20, pp. 452-454, April, 1971. 
[25] Brown, F.M., "On a convenient division of labor in the generation of 
prime implicants," Computers and Electrical Engineering, vol. 6, pp. 
267-271, 1979. 
[26] Brown, F.M. and S. Rudeanu, "Consequences, consistency and inde-
pendence in Boolean algebras," Notre Dame J. Formal Logic, vol. 22, 
no. 1, pp. 45-62, 1981. 
[27] Brown, F.M., "Segmental solutions of Boolean equations," Discrete 
Applied Mathematics, vol. 4, pp. 87-96, 1982. 
[28] Brown, F .M. and S. Rudeanu, "Recurrent covers and Boolean equa-
tions," Proc. Colloq. on Lattice Theory, Szeged, Hungary, Aug. 1980. 
Published in Colloquia Mathematica Societatis Janos Bolyai, North-
Holland Pub. Co., vol. 33, pp. 55-86, 1983. 
[29] Brown, F.M. and S. Rudeanu, "Prime implicants of dependency func-
tions," Analele UniversitaJii Bucure§ti, vol. 37, no. 2, pp. 16-11, 1988. 
[30] Brzozowski, J.A. and M. Yoeli, Digital Networks. Englewood Cliffs, 
NJ: Prentice-Hall, 1976. 
[31] Bunitskiy, E., "Some applications of mathematical logic to the the-
ory of the greatest common divisor and least common multiple" (in 
Russian), Vestnik Opytnoy Jiziki i elem. mat., no. 274, 1899. 
[32] Burgoon, R., "Improve your Karnaugh mapping skills," Electronic De-
sign, 21 December 1972, pp. 54-56. 
[33] Caldwell, S.H., Switching Circuits and Logical Design. New York: Wi-
ley, 1958. 
[34] Carroll, 1., Symbolic Logic. (Fourth Edition) London, 1896 (reprinted 
by Dover Publications, 1958). 

250 
BIBLIOGRAPHY 
[35] Carvallo, M., Principes et Applications de l'Analyse Booleenne. Paris: 
Gauthier-Villars, 1965. 
[36] Cerny, E. and M.A. Marin, "An approach to unified methodology of 
combinational switching circuits," IEEE Trans. Comput., vol. C-26, 
no. 8, pp. 745-756, August 1977. 
[37] Chang, D.M.Y. and T.H. Mott, "Computing irredundant normal forms 
from abbreviated presence functions," IEEE Trans. on Computers, 
vol. EC-14, pp. 335-342, June, 1965. 
[38] Chang, C.L. and R.C.T. Lee, Symbolic Logic and Mechanical Theorem 
Proving. New York: Academic Press, 1973. 
[39] Clare, C.R., Designing Logic Systems Using State Machines. New 
York: McGraw-Hill, 1973. 
[40] Clocksin, W.F. and C.S. Mellish, Programming in Prolog. New York: 
Springer-Verlag, 1981. 
[41] Couturat, L., L'algebre de la Logique. Paris: Scientia, 1905. English 
translation (by Lydia G. Robinson): Open Court Pub. Co., Chicago 
& London, 1914. 
[42] Curtis, H.A., A New Approach to the Design of Switching Circuits. 
Princeton, N.J.: Van Nostrand, 1962. 
[43] Cutler, R.B. and S. Muroga, "Derivation of minimal sums for com-
pletely specified functions," IEEE Trans. Comput., vol. C-36, no. 3, 
pp. 277-292, March 1987. 
[44] Darringer, J.A., Joyner, W., Berman, L. & Trevillyan, 1., "Logic syn-
thesis through local transformations," IBM J. of R. and D., vol. 25, 
pp. 272-280, July 1981. 
[45] Davio, M. and J .-P. Deschamps, "Classes of solutions of Boolean equa-
tions, Philips Research Reports, vol. 24, pp. 373-378, October 1969. 
[46] Davio, M., J.-P. Deschamps and A. Thayse, Discrete and Switching 
Functions. New York: McGraw-Hill, 1978. 
[47] Davis, M. and H. Putnam, "A computing procedure for quantification 
theory," J. Assoc. for Computing Machinery, vol. 7, pp. 201-215, 1960. 

BIBLIOGRAPHY 
251 
[48] Delobel, C. and R.G. Casey, "Decomposition of a data base and the 
theory of Boolean switching functions," IBM J. Res. (3 Develop., vol. 
17, pp. 374-386, 1973. 
[49] Deschamps, J.P., "Maximal classes of solutions of Boolean equations," 
Philips Research Reports, vol. 26, pp. 249-260, August 1971. 
[50] Dietmeyer, D.L., Logic Design of Digital Systems, Second Edition. 
Boston: Allyn & Bacon, 1978. 
[51] Dunham, B., R. Fridshal, and G.L. Sward, "A nonheuristic program 
for proving elementary logical theorems," Proc. Int'l. Conf. on Inf. 
Processing (Paris: UNESCO), 1959, pp. 282-284. 
[52] Dunham, B. and J.H. North, "Theorem testing by computer," Sym-
posium on Mathematical Theory of Automata, Polytechnic lnst. of 
Brooklyn, 1962. 
[53] Dunham, B. and H. Wang, "Towards feasible solutions to the tautology 
problem," Ann. Math. Logic, vol. 10, pp. 117-154, 1976. 
[54] Ehrenfest, P., "Review of L. Couturat, 'The Algebra of Logic'," Journ. 
Russian Phys. (3 Chem. Soc., sec. 2, vol. 42, no. 10, p. 382, 1910. 
[55] Elgot, C.C., Lectures on Switching and Automata Theory, Technical 
Report, University of Michigan, Ann Arbor, Mich., Jan. 1959. 
[56] Ewing, A.C. et aI., "Algorithms for logical design," Comm. (3 Elec-
tronics, no. 56, pp. 450-458, 1961. 
[57] Fletcher, W.I., An Engineering Approach to Digital Design, Engle-
wood Cliffs, NJ: Prentice-Hall, 1980. 
[58] Florine, J., "Optimization of binary functions with a special-purpose 
electronic computer," Automation and Remote Control, vol. 28, pp. 
956-962, 1967. 
[59] Florine, J., The Design of Logical Machines. New York: Crane, Russak 
& Co., 1973. 
[60] Frege, G., Begriffsschrift, Eine Der Arithmetischen Formalsprache Des 
Reinen Denkens. Halle: Nebert, 1879 (Translated in [207]). 

252 
BIBLIOGRAPHY 
[61] Friedman, A.D., Logical Design of Digital Systems. Woodland Hills, 
CA: Computer Science Press, 1975. 
[62] Galil, Z., "The complexity of resolution procedures for theorem prov-
ing in the propositional calculus," Department of Computer Science, 
Cornell University, TR 75-239, 1975. 
[63] Gann, D., J.D. Schoeffler, and 1.E. Ostrander, "A finite-state model 
for the control of adrenal cortical steroid secretion," in M.D. Mesarovic 
(Ed.), Systems Theory and Biology. New York: Springer-Verlag, 1968. 
[64] Gardner, M., Logic Machines and Diagrams. McGraw-Hill, 1958. 
[65] Garey, M.R. and D.S. Johnson, Computers and Intractability. San 
Francisco: W.H. Freeman, 1979. 
[66] Gavrilov, M.A. and A.D. Zakrevskii (Ed's.), LYaPAS: A Programming 
Language for Logic and Coding Algorithms. NY: Academic Press, 1969. 
[67] Genesereth, M.R., "The role of design descriptions in automated diag-
nosis," Artificial Intelligence, vol. 24, pp. 411-436, Dec. 1984. 
[68] Genesereth, M.R. and M.L. Ginsberg, "Logic Programming," Com-
munications of the ACM, vol. 28, no. 9, Sept. 1985. 
[69] Genesereth, M.R. and N.J. Nilsson, Logical Foundations of Artificial 
Intelligence. Los Altos, CA: Morgan Kaufmann, 1987. 
[70] Ghazala, M.J. "Irredundant disjunctive and conjunctive forms of a 
Boolean function," I.B.M. Journal of Research and Development, vol. 
1, pp. 171-176, April 1957. 
[71] Givone, D.G., Introduction to Switching Circuit Theory. New York: 
McGraw-Hill, 1970. 
[72] Goodstein, R.L., Boolean Algebra. New York: Macmillan, 1963. 
[73] G6mez-Gonza.J.ez, 1., Estudio teorico, concepcion y realizacion de un 
sistema electronico para simplificar funciones logicas, Dissertation, 
Dpto. Electricidad y Electronica, Facultad de Ciencias, Universidad 
de Granada, Spain, 1977. 
[74] Gray, F., "Pulse Code Communication," U.S. Patent 2,632,058, 17 
Mar., 1953. 

BIBLIOGRAPHY 
253 
[75] Grinshpon, M.S., "Selection criterion for a potentially inessential ar-
gument to be eliminated from an incompletely-specified logical func-
tion," Automatic Control and Computer Sciences vol. 9, no. 5, pp. 16-
18 (translated from Automatika i Vychislitel'naya Tekhnika, USSR), 
1975. 
[76] Halatsis, C. and N. Gaitanis, "Irredundant normal forms and minimal 
dependence sets of a Boolean function," IEEE Trans. on Computers" 
vol. C-27, no. 11, pp. 1064-1068, Nov. 1978. 
[77] Halmos, P.R., Naive Set Theory. Princeton, N.J.: D. Van Nostrand 
Co., 1960. 
[78] Halmos, P.R., Lectures on Boolean Algebras. New York: Springer-
Verlag, 1974. 
[79] Hammer, P.L. and S. Rudeanu, Boolean Methods in Operations Re-
search. New York: Springer-Verlag, 1968. 
[80] Harrison, M.A., Introduction to Switching and Automata Theory. New 
York: McGraw-Hill, 1965. 
[81] Hartmanis, J., "Symbolic analysis of a decomposition of information 
processing machines," Information and Control, vol. 3, no. 2, pp. 154-
178, June 1960. 
[82] Harvard Computation Laboratory Staff, Synthesis of Electronic Com-
puting and Control Circuits, Annals of the Computation Lab., vol. 
27. Cambridge, Mass.: Harvard Univ. Press, 1951. Chapter VII, 
"M ultiple-output circuits." 
[83] Hight, S.L., "Minimal input solutions," IEEE Trans. on Computers" 
vol. C-20, no. 8, pp. 923-925, Aug. 1971. 
[84] Hill, F.J. and G.R. Peterson, Switching Theory and Logical Design, 
Third Edition. New York: Wiley, 1981. 
[85] Ho, B., "NAND synthesis of multiple-output combinational logic us-
ing implicants containing output variables," Ph.D. Dissertation, U. of 
Wisconsin, 1976. 
[86] Hohn, F., Applied Boolean Algebra. Second Edition. New York & Lon-
don: Macmillan, 1966. 

254 
BIBLIOGRAPHY 
[87] Horowitz, LA., Chess for Beginners. Irvington-on-Hudson, N.Y.: 
Capitol Publ. Co., 1950. 
[88] House, R.W. and T. Rado, "A generalization of Nelson's algorithm for 
obtaining prime implicants," J. Symb. Logic, vol. 30, pp. 8-12, 1965. 
[89] Huffman, D.A., "Solvability criterion for simultaneous logical equa-
tions," M.LT. Research Lab. of Electronics, Quarterly Progress Report 
No. 48, AD 156-161,15 Jan. 1958. 
[90] Huffman, D.A., "Combinational circuits with feedback," Chapter 2 of 
Recent Developments in Switching Theory (ed. A. Mukhopadhyay), pp. 
27-55, Academic Press, N.Y., 1971. 
[91] Hulme, B.L. and R.B. Worrell, "A prime implicant algorithm with 
factoring," IEEE Trans. on Computers, vol. C-24, pp. 1129-1131,1975. 
[92] Huntington, E.V., "Sets of independent postulates for the algebra of 
logic," Trans. Amer. Math. Soc., vol. 5, pp. 288-309, 1904. 
[93] Jesse, J.E., "A more efficient use of Karnaugh Maps," Computer De-
sign, February 1972, pp. 80-82. 
[94] Jevons, W.S., Pure Logic, or the Logic of Quality Apart from Quantity. 
London: Stanford, 1864. 
[95] Kabat, W.C. and A.S. Wojcik, "Automated synthesis of combinational 
logic using theorem-proving techniques," Proc. Twelfth Int'l. Symp. on 
Multiple- Valued Logic, pp. 178-199, (May 1982); IEEE Trans. Com-
puters, vol. C-34, no. 7, pp. 610-632, July 1985. 
[96] Kainec, James J., "A diagnostic system using Boolean reasoning," 
M.S. Thesis, Air Force Institute of Technology, Wright-Patterson AFB, 
Ohio, December 1988. 
[97] Kalish, D. and R. Montague, Logic: Techniques of Formal Reasoning. 
New York: Harcourt Brace Jovanovich, 1964. 
[98] Kambayashi, Y., "Logic design of programmable logic arrays," IEEE 
Trans. on Computers, vol. C-28, pp. 609-617, Sept. 1979. 
[99] Karnaugh, M., "The map method for synthesis of combinational logic 
circuits," AlEE Trans. on Comm. (3 Electronics, vol. 9, pp. 593-599, 
1953. 

BIBLIOGRAPHY 
255 
[100] Kautz, W.H., "The necessity of closed circuit loops in minimal com-
binational circuits," IEEE Trans. on Computers, vol. C-19, no. 2, pp. 
162-164, Feb. 1970. 
[101] Keynes, J.N., Studies and Exercises in Formal Logic, Second Edition. 
London: Macmillan, 1887. 
[102] Kjellberg, G. "Logical and other kinds of independence," Proc. of an 
Int'l. Symp. on the Theory of Switching, Annals of the Computer Lab. 
of Harvard U., vol. 39, Part I, pp. 117-124, Harvard U. Press, 1959. 
[103] Klir, G.J. and M.A. Marin, "New considerations in teaching switching 
theory," IEEE Trans. on Education, vol. E-12, pp. 257-261, 1969. 
[104] Klir, G.J., Introduction to the Methodology of Switching Circuits. New 
York: D. Van Nostrand Co., 1972. 
[105] Kobrinsky, N.E. & Trakhtenbrot, B.A., Introduction to the Theory of 
Finite Automata. Amsterdam: North-Holland Publ. Co., 1965. Chap-
ter VI, Section 3, "Synthesis of a multi-output logical net." 
[106] Kohavi, Z., Switching and Finite Automata Theory. New York: 
McGraw-Hill, 1970. 
[107] Korfhage, R.R., Logic and Algorithms, With Applications to the Com-
puter and Information Sciences. New York: Wiley, 1966. 
[108] Kowalski, R., Logic for Problem Solving. Amsterdam, New York: 
North-Holland, 1979. 
[109] Krieger, M., Basic Switching Circuit Theory. New York: Macmillan, 
1967. 
[110] Kuntzmann, J., Algebre de Boole. Paris: Dunod, 1965. 
[111] Ladd, Christine, "On the algebra of logic," in Studies in Logic, ed. by 
C. S. Peirce. Boston: Little, Brown & Co., 1883, pp. 17-71. 
[112] Lazarev, V.G. and E.!. Piil', "On the integration of potential-pulse 
forms," Soviet Physics - Doklady, vol. 6, no. 7, 1962. 
[113] Ledley, R.S., "A digitalization, systematization, and formulation ofthe 
theory and methods of the propositional calculus," NBS Report 3363, 

256 
BIBLIOGRAPHY 
Nat'l. Bureau of Standards, U.S. Dep't. of Commerce, (U.S. Gov't, 
document no. AD56-412), 1 Feb. 1954. 
[114] Ledley, R.S., "Mathematical foundations and computational methods 
for a digital logic machine," J. Ops. Res. Soc. Amer., vol. 2, pp. 249-
274,1954. 
[115] Ledley, R.S., "Digital computational methods in symbolic logic, with 
examples in biochemistry," Proc. Nat 'I. Acad. Sci., vol. 41, pp. 498-
511, July 1955. 
[116] Ledley, R.S., "Logical aid to systematic medical diagnosis (and oper-
ational simulation in medicine)," J. Ops. Res. Soc. Amer., vol. 4, no. 
3, p. 392, Aug. 1956. 
[117] Ledley, R.S. and L.B. Lusted, "Reasoning foundations of medical di-
agnosis," Science, vol. 130, no. 3366, pp. 9-21, 3 July, 1959. 
[118] Ledley, R.S., Digital Computer and Control Engineering. New York: 
McGraw-Hill Book Co, 1960. 
[119] Ledley, R.S., Use of Computers in Biology and Medicine. New York: 
McGraw-Hill Book Co, 1965. Chapter 12, "Medical diagnosis and med-
ical record-keeping." 
[120] Lee, R.C.T., "An algorithm to generate prime implicants and its ap-
plication to the selection problem," Inf. Sciences, vol. 4, pp. 251-254, 
July 1972. 
[121] Lee, S.C., Digital Circuits and Logic Design. Englewood Cliffs, NJ: 
Prentice-Hall, 1976. 
[122] Lee, S.C., Modern Switching Theory and Digital Design. Englewood 
Cliffs, NJ: Prentice-Hall, 1978. 
[123] Lewis, C.I., A Survey of Symbolic Logic. Berkeley: U. of Cal. Press, 
1918. Reprinted by Dover Pub's., Inc., New York, 1960. Chapt. II, 
"The Classic, or Boole-Schroder Algebra of Logic." 
[124] Lowenheim, L., "Uber die Auflosung von Gleichungen im logischen 
Gebietekalkul," Math. Ann, vol. 68, 1910, pp. 169-207. Translation: 
"The solution of equations in the calculus of logic," AFCRL-69-0149, 
Air Force Cambridge Research Laboratories, April, 1969. 

BIBLIOGRAPHY 
257 
[125] Luckham, D., "The resolution principle in theorem-proving," in Ma-
chine Intelligence 1 (N.L. Collins and D. Michie, ed's.), Edinburgh & 
London: Oliver & Boyd, 1967. 
[126] Maghout, K., "Determination des nombres de stabilite et du nombre 
chromatique d'un graphe." C. R. Acad. Sci. Paris, vol. 248, pp. 3522-
23,1959. 
[127] Maghout, K., "Applications de l'algebra de Boole a. la theorie des 
graphes et aux programmes lineaires et quadratiques," Cahiers Centre 
Edudes Rech. Oper., vol. 5, pp. 21-99, 1963. 
[128] Marczewski, E., "Independence in algebras of sets and Boolean alge-
bras," Fundamenta Mathematicae, vol. 48, pp. 135-145, 1960. 
[129] Marcus, M.P., "Derivation of maximal compatibles using Boolean al-
gebra," I.B.M. J. Res. (3 Devel., vol. 8, pp. 537-538, 1964. 
[130] Marin, M.A., "Investigation of the field of problems for the Boolean 
Analyzer," Report No. 68-28, Dep't. of Engineering, U. of Calif. at Los 
Angeles, 1968. 
[131] Marquand, A., "A logical diagram for n terms," Philosophical Maga-
zine, vol. 12, pp. 266-270, 1881. 
[132] May, A., "Adaptive location of multiple faults in combinational cir-
cuits," M.S. thesis, Department of Electrical Engineering, University 
of Kentucky, Lexington, KY, August, 1984. 
[133] McCaw, C.R., "Loops in directed combinational switching circuits," 
Stanford Electronics Lab's., T.R. No. 6208-1, April 1963. 
[134] McCluskey, E.J., "Minimization of Boolean functions," Bell Sys. Tech. 
J., vol. 35, pp. 1417-1444,1956. 
[135] McColl, H., "The calculus of equivalent statements," Proc. London 
Math. Soc., vol. 9 (1877/78), pp. 9-20; vol. 10 (1878), pp. 16-28; vol. 
11 (1879/80), pp. 113-121. 
(136) McCluskey, E.J., Introduction to the Theory of Switching Circuits. 
New York: McGraw-Hill, 1965. 
[137] Mendelson, E., Boolean Algebra and Switching Circuits. New York: 
McGraw-Hill (Schaum's Outline Series), 1970. 

258 
BIBLIOGRAPHY 
[138] Mitchell, O.H., "On a new algebra of logic," in Studies in Logic, ed. 
by C.S. Peirce. Boston: Little, Brown, & Co, 1883. 
[139] Mithani, D., "Implementation of NAND synthesis using implicants 
containing output variables," M.S. thesis, Dep't. of Electrical Engi-
neering, Univ. of Wisconsin, 1977. 
[140] Mott, T .H., "Determination of the irredundant normal forms of a truth 
function by iterated consensus of the prime implicants," IRE Trans. 
on Electronic Computers, vol. EC-9, pp. 245-252, June 1960. 
[141] Muller, D.E., "Application of Boolean algebra to switching circuit de-
sign and to error detection," Trans. IRE, vol. EC-3, pp. 6-12, Sept. 
1954. 
[142] Miiller, E., Abriss der Algebra der Logik, 1909-10. (Appendix to vol. 
III of [178]). 
[143] Muroga, S., Logic Design and Switching Theory. New York: Wiley-
Interscience, 1979. 
[144] Naito, S., "Algebraic analysis for asynchronous sequential circuits," 
NEC Research and Development, No. 34, pp. 80-89, July 1974. 
[145] Nakasima, A., "The theory of equivalent transformation of simple par-
tial paths in relay circuits" (in Japanese), J. Inst. Elec. Commun. 
Engrs. Japan, no. 165, 167, Dec. 1936, Feb. 1937. 
[146] Nakasima, A., "Algebraic expressions relative to simple partial paths 
in the relay circuit" (in Japanese), J. Inst. Electrical Communication 
Engineers of Japan, no. 173, August 1937 (condensed English transla-
tion: Nippon Electrical Comm. Engineering, no. 12, pp. 310-314, Sept. 
1938). Section V, "Solutions of acting impedance equations of simple 
partial paths." 
[147] Nelson, R.J., "Simplest normal truth functions," J. Symb. Logic, vol. 
20, pp. 105-108,1955. 
[148] Nelson, R.J., Introduction to Automata. New York: Wiley, 1968. 
[149] Nilsson, N.J., Problem-Solving Methods in Artificial Intelligence. New 
York: McGraw-Hill, 1971. Chapter 6: "Theorem-Proving in the Pred-
icate Calculus." 

BIBLIOGRAPHY 
259 
[150] Nilsson, N.J., Principles of Artificial Intelligence. Palo Alto, Calif.: 
Tioga Publ. Co., 1980. 
[151] Peirce, C.S., "On the algebra of logic," Amer. J. of Math., vol. 3, pp. 
15-57,1880. 
[152] Peirce, C.S., ed., Studies in Logic. By Members of the Johns Hopkins 
University. Boston: Little Brown & Co, 1883. 
[153] Peirce, C.S., "Logical machines," Amer. J. Psychology, vol. 1, pp. 165-
170,1887. 
[154] Petrick, S.R., "A direct determination of the irredundant forms of a 
Boolean function from a set of prime implicants," A.F. Cambridge Res. 
Center, Bedford, Mass., Report AFCRC-TR-56-110, 1956. 
[155] Phister, M., Logical Design of Digital Computers. New York: John 
Wiley, 1958. 
[156] Pichat, E., "Algorithms for finding the maximal elements of a finite 
universal algebra," Information Processing 68, Proc. IFIP Congress, 
pp. 214-218, 1968. 
[157] Poage, J.F., "Derivation of optimum tests to detect faults in combina-
tional circuitry," Mathematical Theory of Automata, MRI Symposium 
Series, Volume XII, Polytechnic Institute of Brooklyn, 1963 
[158] Poretsky, P., "On methods for solving logical equations and on the 
inverse method for mathematical logic" (in Russian), Bull. de la Soc. 
Physico-Mathematique de Kasan, vol. 2, pp. 161-130, 1884. 
[159] Poretsky, P., "Sept lois fondamentales de la theorie des egalites 
logiques," Bull. de la Soc. Physico-Mathematique de Kasan, ser. 2, 
vol. 8, pp. 33-103, 129-181, 183-216, 1898. 
[160] Pratt, W.C., "Transformation of Boolean equations for the design 
of multiple-output networks," Dissertation, Electrical Engrg. Depart-
ment, University of Illinois, 1976. 
[161] Quine, W.V., "The problem of simplifying truth functions," Am. Math. 
Monthly, vol. 59, pp. 521-531, 1952. 
[162] Quine, W.V., "Two theorems about truth functions," Bol. Soc. Math. 
Mexicana, vol. 10, pp. 64-70, 1953. 

260 
BIBLIOGRAPHY 
[163] Quine, W.V., "A way to simplify truth functions," Am. Math. 
Monthly, vol. 62, pp. 627-631, 1955. 
[164] Quine, W.V., "On cores and prime implicants oftruth functions," Am. 
Math. Monthly, vol. 66, pp. 755-760, 1959. 
[165] Reed, 1.S., "A class of multiple error-correcting codes and the decoding 
scheme," IRE Trans. on Information Theory, vol. IT-4, pp. 38-49, 
Sept. 1954. 
[166] Reusch, B., "Generation of prime implicants from subfunctions and a 
unifying approach to the covering problem," IEEE Trans. on Comput-
ers, vol. C-24, no. 9, pp. 924-930, September 1975. 
[167] Reusch, B. and L. Detering, "On the generation of prime implicants," 
Annales Societatis Mathematicae Polonae, Series IV: Fundamenta In-
formaticae II, pp. 167-186, 1979. 
[168] Robinson, J.A., "A machine oriented logic based on the resolution 
principle," Journal of the Association for Computing Machinery, vol. 
12, no. 1, pp. 23-41, January 1965. 
[169] Rose, A., Computer Logic. New York: Wiley-Interscience, 1971. 
[170] Rosenbloom, P., The Elements of Mathematical Logic. New York: 
Dover Publications, 1950. 
[171] Rudeanu, S., "Boolean equations and their applications to the study 
of bridge circuits. I," Bull. Math. Soc. Math. Phys. R. P. Roumaine, 
vol. 3, pp. 445-473, 1959. 
[172] Rudeanu, S., Boolean Functions and Equations. Amsterdam-London-
New York: North-Holland Publ. Co. & American Elsevier, 1974. 
[173] Rushdi, A.M., "Improved variable-entered Karnaugh map proce-
dures," Computers and Electrical Engineering, vol. 13, no. 1, pp. 41-52, 
1987. 
[174] Samson, E.W.-and B.E. Mills, "Circuit minimization: algebra and al-
gorithms for new Boolean canonical expressions," Air Force Cambridge 
Research Center, AFCRC TR 54-21, April, 1954. 

BIBLIOGRAPHY 
261 
[175] Samson, E.W. and R.K. Mueller, "Circuit minimization: sum to one 
process for irredundant sums," Air Force Cambridge Research Center, 
Report AFCRC-TR-55-118, August 1955. 
[176] Sasao, T., "HART: a hardware for logic minimization and verification," 
Internat'l. Conf. on Computer-Aided Design, ICCD-8S, pp. 713-718, 
1985. 
[177] Schoeffler, J.D., L.E. Ostrander, and D.S. Gann, "Identification of 
Boolean mathematical models," in M.D. Mesarovic (Ed.), Systems 
Theory and Biology. New York: Springer-Verlag, 1968. 
[178] Schroder, E., Vorlesungen tiber die Algebra der Logik. Leipzig: Vol. 1, 
1890; Vol. 2, 1891; Vol. 3, 1895; Vol. 2, Part 2, 1905. Reprint: Chelsea 
Pub. Co., Bronx, N.Y., 1966. 
[179] Schultz, G.W., "An algorithm for the synthesis of complex sequential 
networks," Computer Design, March, 1969, pp. 49-55. 
[180] Sellers, F.F., M.Y. Hsiao and L.W. Bearnson, "Analyzing errors with 
the Boolean difference," IEEE Trans. Computers, vol. C-17. 7, pp. 676-
683, July 1968. 
[181] Semon, W., "The application of matrix methods in the theory of 
switching," Doctoral thesis, Compo Lab., Harvard Univ., Cambridge, 
Mass., April 1954. 
[182] Semon, W., "A class of Boolean equations," Report SRRC-RR-17, 
Sperry Rand Research Center, Sudbury, Mass., 1962. 
[183] Shannon, C.E., "A symbolic analysis of relay and switching circuits," 
Trans. Amer. Inst. Elec. Engrs., vol. 57, pp. 713-723, 1938. 
[184] Shannon, C.E., "The synthesis of two-terminal switching circuits," Bell 
System Tech. J., vol. 28, no. 1, pp. 59-98, 1949. 
[185] Shestakov, V.I., "Some mathematical methods for construction and 
simplification of two-terminal electrical networks of class A" (in Rus-
sian), Dissertation, Lomonosov State University, Moscow, 1938. 
[186] Short, R.A., "A theory of relations between sequential and combina-
tional realizations of switching functions," Stanford Electronics Labo-
ratories, T.R. No. 098-1, 12 Dec., 1960. 

262 
BIBLIOGRAPHY 
[187] Sikorski, R., Boolean Algebms. New York: Springer-Verlag, 1969. 
[188] Slagle, J .R., et al., "A new algorithm for generating prime implicants," 
IEEE Trans. on Computers, vol. C-19, pp. 304-310, 1970. 
[189] Small, A.W., "A new approach to functional decomposition," Air Force 
Cambridge Research Laboratories, Report AFCRL-71-001O, 28 Dec., 
1970. 
[190] Stone, M.H., "The theory of representations for Boolean algebras," 
Trans. Amer. Math. Soc., vol. 40, pp. 37-111, 1936. 
[191] Svoboda, A., "Boolean analyzer," Information Processing 68 (Proc. 
IFIP Congress, Edinburgh). Amsterdam: North-Holland, pp. 824-830, 
1969. 
[192] Svoboda, A., "Parallel processing in Boolean algebra," IEEE Trans. 
on Computers, vol. C-22, pp. 848-851, 1973. 
[193] Svoboda, A. and D.E. White, Advanced Logical Circuit Design Tech-
niques. New York: Garland STPM Press, 1979. 
[194] Talantsev, A.D., "On the analysis and synthesis of certain electrical 
circuits by means of special logical operators," Automation and Remote 
Control, vol. 20, no. 9, pp. 874-883, 1959. 
[195] Tapia, M.A., J.H. Tucker and A.W. Bennett, "Boolean integration," 
Proc. IEEE Southeast-Con, Clemson, SC, April 1976. 
[196] Tapia, M.A., J.H. Tucker and A.W. Bennett, "Boolean differentiation 
and integration using Karnaugh Map," Proc. IEEE Southeast-Con, 
1977. 
[197] Tapia, M.A., "Application of Boolean calculus to digital system de-
sign," Proc. IEEE Southeast-Con, Nashville, Tenn., 14-16 April, 1980. 
[198] Tapia, M.A. and J.H. Tucker, "Complete solution of Boolean equa-
tions," IEEE Trans. on Comput., vol. C-29, no. 7, pp. 662-665, July 
1980. 
[199] Tapia, M.A. "Boolean integral calculus for digital systems," IEEE 
Trans. on Comput., vol. C-34, no. 1, pp. 78-81, Jan. 1985. 

BIBLIOGRAPHY 
263 
[200] Taylor, D.K., "Analyzing Relational Databases using Propositional 
Logic," M.S. Thesis, Department of Electrical Engineering, University 
of Kentucky, December, 1981. 
[201] Texas Instruments, Inc., The TTL Data Book for Design Engineers, 
1973. 
[202] Thayse, A., "Boolean differential calculus," Philips Res. Rept's., vol. 
26, pp. 229-246, 1971. 
[203] Thayse, A. and M. Davio, "Boolean differential calculus and its ap-
plications in switching theory," IEEE Trans. Comput., vol. C-22, pp. 
409-420, 1973. 
[204] Tison, P., Theorie des consensus, Dissertation, University of Grenoble, 
France, 1965. 
[205] Tison, P., "Generalization of consensus theory and application to the 
minimization of Boolean functions," IEEE Trans. Electronic Comput-
ers, vol. EC-16, pp. 446-456, 1967. 
[206] Uehara, T. and N. Kawato, "Logic circuit synthesis using Prolog," New 
Generation Computing, vol. 1, no. 2, 1983. 
[207] van Heijenoort, J. (Ed.), From Frege To Gijdel: A Source Book Of 
Mathematical Logic, 1897-1931. Cambridge, Mass.: Harvard Univer-
sity Press, 1967. 
[208] Veitch, E.W., "A chart method for simplifying truth functions," Proc. 
ACM Conference, Pittsburgh, Pa., 2-3 May, 1952, pp. 127-133. 
[209] Venn, J., "On the employment of geometrical diagrams for the sensible 
representation of logical propositions," Proc. Cambridge Philosophical 
Society, vol. 4, pp. 35-46, 1880. 
[210] Venn, J., Symbolic Logic, 2nd edition. London, Macmillan, 1894. 
(Reprinted by Chelsea Pub. Co., New York, 1971). 
[211] Weissman, J., "Boolean algebra, map coloring and interconnections," 
Amer. Math. Monthly, vol. 69, pp. 606-613, 1962. 
[212] Whitehead, A.N., A Treatise on Universal Algebra, with Applications. 
Cambridge: The University Press, 1898. 

264 
BIBLIOGRAPHY 
[213] Whitehead, A.N., "Memoir on the algebra of symbolic logic, Part I," 
Am. J. of Math., vol. 23, pp. 139-165,297-316, 1901. 
[214] Whitesitt, J.E., Boolean Algebra and its Applications. Reading, MA: 
Addison-Wesley, 1961. 
[215] Wojciechowski, W.S. and A.S. Wojcik, "Multiple-valued logic design 
by theorem proving," Proc. Ninth. lnt'l. Symp. on Multiple- Valued 
Logic, Bath, England, 1979, pp. 196-199. 
[216] Wojciechowski, W.S., Multiple-valued combinational logic design using 
theorem proving. Dissertation, Ill. lnst. of Tech., 207 pp. University 
Microfilms No. KRA80-2162, May 1980. 
[217] Wojciechowski, W.S. and A.S. Wojcik, "Automated design of multiple-
valued logic circuits by automated theorem-proving techniques," IEEE 
Trans. on Computers, vol. C-32, pp. 785-798, Sept. 1983. 
[218] Wood, P.E., Jr., Switching Theory. New York: McGraw-Hill, 1968. 
[219] Wos, 1., R. o verbeek , E. Lusk & J. Boyle, Automated Reasoning: 
Introduction And Applications. Englewood Cliffs, N.J.: Prentice-Hall, 
1984. 
[220] Yamada, K. and K. Yoshida, "An application of Boolean algebra in 
practical situations," Hitotsubashi J. Arts (3 Sciences, vol. 5, pp. 41-57, 
1965. 
[221] Zakrevskii, A.D. and A.Yu. Kalmykova, "The solution of systems of 
logical equations," in [66], pp. 193-206. 
[222] Zakrevskii, A.D., "Testing for identities in Boolean algebra," in [66], 
pp. 207-213. 
[223] Zhegalkin, 1.1., "On the calculation of propositions in symbolic logic," 
(in Russian), Math. Sbornik, vol. 34, pp. 9-28, 1927. 

Index 
0-normal form xii 
I-normal form xii, 213 
A-consequent 138 
ABS(f) 245 
absorption 31 
absorptive formula 240 
adaptive identification 201 
adder, two's-complement 184 
adrenal gland 195 
Akers, S.B. 57 
algebra of logic xi 
algebraic system 18 
alterm 72 
AND-gate, specification for 214 
antecedent 4, 25, 71, 89 
functional 153 
arbitrary parameter 157 
arithmetic Boolean algebras 26 
Arnold, B.H. 23, 25 
Ashenhurst, R.L. 154 
associativity 30 
atomic formula xi 
augmentation 199 
axiom, diagnostic 197 
Baylis, C.A. 185 
BCF(f) xiv, 245 
Bennett, A.A. 185 
Bing, K. 77 
black box, Boolean 193 
265 
Blake, A. xii, xiv, 39, 71, 80, 126, 
151, 181, 239 
Blake canonical form xiv, 75, 117, 
245 
combined method 83 
exhaustion of implicants 76 
generation of 75 
iterated consensus 77 
multiplying method 80 
of conjunctive eliminant 103 
Quine's method 78 
recursive multiplication 81 
successive extraction 79 
block 11 
Boole, G. xi, xiii, 25, 32, 89, 95, 
99,123,151,179 
Boole's Expansion Theorem 36, 68 
Boolean algebra, 23 
big 60 
examples 24 
class-algebra 24 
propositional algebra 25 
subset-algebra 24 
two-element algebra 26 
free 48 
of Boolean functions 47 
postulates 23 
Boolean Analyzer xiii 
Boolean calculus 58 
Boolean constraint 93 
Boolean derivative 56 

266 
Boolean difference 57 
Boolean equation 153 
consistency of 155 
general solution 156 
parametric 167 
reproductive 174 
subsumptive 158 
particular solution 154 
sequential 154 
solution of 153 
Boolean equations, applications of 
154 
Boolean formula 32 
Boolean function 34 
incompletely-specified 45 
range of 36 
recursive definition 58 
simple 45 
switching function 45 
Boolean functions 
normal set 48 
orthogonal set 48 
orthonormal set 48 
Boolean identification 193 
Boolean integral 58 
Boolean model 193 
Boolean quotient 53 
eliminant of 106 
Boolean reasoning xii 
Boolean ring 39 
Boolean system 88 
antecedent 89 
as a predicate 88 
consequent 89 
consistent 89 
reduction of 89 
solution of 89 
Boolean systems, equivalent 89 
BORIS xvii, 234 
Bossen, D.C. 194 
Brand, D. 212 
INDEX 
Brayton, R.K. xiv, 59, 212 
Breuer, M.A. 194 
Brown, F.M. 140, 141, 158,219 
Bunitskiy, E. 26 
cardinality 8 
carrier xv 
Carroll, Lewis 25, 135 
cartesian product 9 
Carvallo, M. 23 
Cerny, E. 154 
Chang, S.J. 194 
chart 42 
checkpoints 194 
circuit, combinational 211 
circuit, multiple-output 211 
circuit, sequential 211 
class xi, 123 
class-algebra 24 
class-logic 134 
classes, algebra of 25 
clausal form 129 
clause, prime 129 
closed loop 224 
combinational circuit 211 
combinational solution 223 
complement, of a set 10 
completely-specified function 149 
congruent formulas 73, 239 
conjunction 25 
consensus 31, 75, 243 
consensus, deduction by 126 
consequent 4, 25, 71, 89, 127 
functional 181 
prime 128 
consequents, production of 132 
consequents, verification of 133 

INDEX 
consistency condition 155 
consistent specification 218 
constituent 39 
constraint 93 
contradiction 25 
cont;apositive proof 5 
cost, gate-input 227,233 
Couturat, L. 66, 118, 125, 154 
Cutler, R.B. 145 
D-Iatch 192 
data-selector 62 
Davio, M. 57, 219 
De Morgan's Laws 31 
deduction 126 
by consensus 126 
selective 136 
definitive experiment 201 
algorithm 208 
dependency function 141 
dependent functions 140 
dependent set, minimal 141 
derivative, Boolean 56 
Deschamps, J.-P. 57,219 
design-process 212 
Detering, L. 75 
determining subsets 189 
deVelopment xv 
diagnostic axiom 197 
diagnostic equation 197 
diagnostic function 197 
Dietmeyer, D.L. 61, 108 
difference, Boolean 57 
digital design, two-valued assump-
tion in 60 
discriminant 39 
disjunction 25 
don't-care 46, 214 
don't-care specification 222 
duality 31 
effective input 205 
Ehrenfest, P. xiii 
eliminant 100 
calculation of 102 
conjunctive 100 
267 
of Blake canonical form 103 
derived from maps 161 
disjunctive 100 
calculation of 104 
replace-by-one trick 105 
elimination 95 
resultant of 96 
vs. removal 110 
empty set 9 
enzyme biochemistry 136 
equation, diagnostic 197 
equation, input 205 
equivalence 5 
equivalence-class 12 
equivalence-relation 12 
equivalent formulas 73, 239 
Euler diagram 28 
Exclusive NOR 32 
Exclusive OR 32 
exhaustion of implicants 76 
existential quantifier 3 
expansion theorem 36 
experiment 201 
definitive 201 
explicit solution 223 
expression 1 
fault 57 
logical 57 
stuck-at 57 
test for 57 
faults, stuck-type 194 

268 
feedback-loop 224, 226, 233 
Fletcher, W.I. 62 
flip-flop 176 
conversion 215 
characteristic equation 171 
one-parameter solution 177 
D 178 
JK 178,215 
RS 131, 178 
RST 152, 170, 176, 178, 215 
T 178 
Florine, J. 76 
form, clausal 129 
form, zero-normal xii 
formal inclusion 73, 128,240 
formula 1 
absorptive 240 
Boolean 32 
irredundant 117, 145 
SOP 72 
syllogistic 72,74,110,127,239, 
240 
well-formed xii, 2 
formula-minimization xiv 
formulas 
congruent 73, 239 
equivalent 73, 239 
unwanted syllogistic 85 
forward chaining 124 
free Boolean algebra 48, 153 
generator 48 
Frege, G. xi, 71 
full adder 186 
function 16 
as a relation 16 
Boolean 34 
co-domain 16 
completely-specified 149 
dependency 141 
INDEX 
dependent 140 
diagnostic 197 
domain 16 
incompletely-specified 145 
propositional 17 
vs. formula 17 
function-table 16 
functional antecedent 153 
functional consequents 181 
functional relation 138 
functionally deducible arguments 182 
Gaitanis, N. 108,191, 192 
Galil, Z. 115 
Gann, J.D. 195 
gate-input cost 227 
general solution 156, 226 
simplification via Marquand di-
agrams 167 
generator 48 
Ghazala, M.J. 53, 116, 145 
Gomez-Gonzalez, L. 76 
Goodstein, R.L. 25 
graph, internal stability of vertices 
141 
Gray code 43 
Grinshpon, M.S. 108, 111 
Halatsis, C. 108, 191, 192 
Halmos, P.R. 1,23 
Harvard Computation Laboratory 
213 
Hasse diagram 14 
Hight, S.L. 108 
Ho, B. 213 
Hohn, F. 23, 25 
Hong, S.J. 194 
House, R.W. 80 
Huffman, D.A. 57 

INDEX 
Huntington's postulates 23 
hypothetical syllogism 126 
idempotence 30 
identification, adaptive 201 
implicant 73, 244 
implication 4 
implicit solution 223 
inclusion 8 
formal 73, 128, 240 
of formulas 239 
inclusion-relation 28 
incompletely-specified function 45, 
145 
independent functions 140 
independent set, maximal 141 
inessential variable 108 
inference, rule of 126 
input, effective 205 
input-equation 205 
intersection 10 
interval 28, 108 
involution 31 
irredundant formula 117, 145 
iterate 223 
iterated consensus 76 
Jevons, W.S. xi, 32 
JK flip-flop 63, 215 
Kabat, W.C. xv 
Kainec, J.J. xviii, 194 
Kambayashi, Y. 108 
Karnaugh map 42, 161 
Kautz, W.H. 233 
Keynes, J.N. 150 
Kjellberg, G. 140 
Klir, G.J. xiii, 154 
Kobrinksy, N .E. 213 
Kuntzmann, J. 23, 140 
label-and-eliminate 139 
Ladd, C. 151 
latch, D 192 
latch, RS 119 
least-cost solution 224 
269 
Ledley, R.S. 136, 140, 154, 182, 
194 
letter 53 
Lewis, C.l. 98 
Lisp 59 
literal 53, 72 
logic, algebra of xi 
logic, class 134 
logical computers 76 
Lowenheim, L. 44, 50, 119, 175 
Lowenheim's expansions 50 
Lowenheim's formula 175 
Maghout, K. 141 
map 42 
Karnaugh 161 
variable-entered 42 
Marczewski, E. 140 
Marin, M.A. xiii, 154 
Marquand diagram 42, 162 
maximal independent set 141 
McColl, H. 66 
Mendelson, E. 23, 27 
middle term, elimination of 98 
Mills, B.E. 77, 80 
minimal dependent set 141 
minimal determining subset 110, 
232 
minimization xiv 
minterm canonical form 39 
Mitchell, O.H. 105 
Mithani, D. 213 
model 193 
Boolean 193 

270 
parametric 195 
terminal 207 
Mott, T .R. 145 
Mueller, R.K. 116,145 
Miiller, E. 39,44, 140 
multiple-output circuit 211 
multiplexer 62 
Muroga 145 
N akasima, A. xiii, 119, 154 
Nelson, R.J. 48 
non-tabular specification 233 
normal form 215 
null set 9 
operation 18 
operation-table 18 
opposition 242 
order, partial 14 
order, total 14 
orthogonal SOP formula 122 
orthogonol set 48 
orthonormal expansion 48 
orthonormal set 48 
Ostrander, L.E. 195 
parameter, arbitrary 157 
parametric general solution 167 
based on recurrent covers 172 
by successive elimination 169 
Lowenheim's Formula 175 
parametric model 195 
partial order 14 
partition 11 
block of 11 
refinement of 11 
Peirce, C.S. 80, 151 
Petrick, S.R. 145 
Phister, M. 154 
Poage, J.F. 194 
INDEX 
Poretsky, P. xi, 66, 71, 92, 181 
Poretsky, Law of Forms 92 
power set 10 
Pratt, W.C. 213, 233 
predicate xi, 3, 88 
predicate calculus xi 
predicate logic xv 
prime clause 129 
prime consequent 128 
prime implicant xii, 72, 117, 244 
Principle of Assertion 124 
product, cartesian 9 
Prolog 59 
proposition 2 
propositional logic 25 
equations in 125 
principle of assertion 125 
propositions, algebra of 25 
quantifier xii 
existential 3 
universal 3 
Quine, W.V.O.xii, 72, 77,78,117, 
244 
quotient, Boolean 53 
Rado, T. 80 
reasoning, syllogistic 123 
recurrent cover 162, 172 
from prime implicants 164 
recursion, base 7 
recursive solution 224, 227 
reduction xv, 89 
redundancy subsets 108 
maximal 108 
computing by tree-search 110 
redundant variables 107 
Reed, I.S. 39, 57 
refinement 11 

INDEX 
reflexive relation 12 
refutation xvi, 124 
relation 11 
anti-symmetric 14 
equivalence 12 
functional 138 
inclusion 28 
partial-order 14 
reflexive 12 
symmetric 12 
transitive 12 
removal vs. elimination 110 
replace-by-one trick 105 
reproductive general solution 174 
resolution 123 
resultant of elimination 98 
resultant of removal 109 
Reusch, B. 75 
Robinson, J .A. xiii, 181 
Rosenbloom, P. 27, 36 
RS flip-flop 131 
RS latch 119 
RST flip-flop 152, 170, 215 
Rudeanu, S. xviii, 23, 36, 39, 45, 
66,91,119,140,141,154, 
158,159,174 
rule of inference 126 
Samson, E.W. 77, 80,116,145 
Scheme xvii, 234 
Schoeffler, J.D. 195 
Schroder xi, 36, 88, 102, 151, 154 
segment 28 
selective deduction 136 
semantics 1 
Semon, W. 154 
sequence 8 
sequential circuit 185, 211 
asynchronous 185 
set 5 
abstractness of 7 
and sequence 8 
cardinality 8 
element 5 
empty 9 
enumeration 6 
finite 5 
inclusion 8 
member 5 
membership-property 6 
partition of 11 
power set 10 
recursive definition 6 
relation on 12 
subset of 8 
universal 11 
sets, equality of 8 
sets, operations on 9 
cartesian product 10 
complement 10 
intersection 10 
union 10 
Shannon, C., xiii, 36, 61, 108 
Shestakov, V.I. xiii 
Sikorski, R. 23 
simple Boolean function 45 
Small, A.W. xviii, 140 
solution 89, 153 
explicit 223 
general 156 
implicit 223 
least-cost 224 
of design-specification 212 
particular 154 
recursi ve 224 
271 
strongly combinational 223 
SOP formula 72, 117 
absorptive 73 

272 
nearly-minimal 117 
orthogonal 122 
sorites 135 
specification 201, 212, 213 
complete 214, 217 
consistent 218 
don't-care in 222 
incomplete 214 
initial 201 
non-tabular 233 
tabular 219 
terminal 201 
stability 213 
Stone Representation Theorem 27 
strongly combinational solution 223 
stuck-type faults 194 
Su, S.Y.H. 194 
subset 8 
subset, sum-to-one 143 
subset-algebra 24 
subsets, determining 189 
subsets, eliminable 187 
substitution 113 
subsumptive general solutions, sim-
plified 166 
successive elimination 159, 169 
sum-to-one subsets 143 
construction of 144 
sum-to-one theorem 116 
Svoboda, A. xiii, 23, 76, 154 
switching function 45 
switching theory xiii 
syllogism, hypothetical 126 
syllogistic formula 110, 127, 239, 
240 
syllogistic formulas, unwanted 85 
syllogistic reasoning 123 
syllogistic result 75, 126, 243 
symmetric relation 12 
syntax 1 
system, algebraic 18 
tabular specification 219 
tautology 25, 115 
tautology problem 115 
tautology, testing for 115 
term 53,72 
term, A-consequent 138 
terminal model 207 
terms, opposition in 242 
Thayse, A. 57 
transducer 193 
INDEX 
transformation, of solution 212 
transitive relation 12 
truth-table 41 
truth-value 2 
union 10 
universal quantifier 3 
vacuous variable 108 
variable 
elimination of 97 
functionally deducible 182 
inessential 108 
redundant 107 
removal by substitution 113 
removal of 109 
resultant of removal of 109 
vacuous 108 
variable-entered map 42, 62 
variables, successive elimination of 
159 
Veitch chart 42 
Venn, J. xi, 25, 43, 151, 152 
Verification Theorem 44, 91 
extended 91 
vertices, internal stability 141 
VHDL 194 

INDEX 
VLSI xiv 
Weissman, J. 141 
well-formed formula xii 
White, D.E. xiii, 23, 154 
Whitehead, A.N. xi 
Whitesitt, J .E. 23 
Wojcik, A.S. xv 
zero-normal form xii 
Zhegalkin, 1.1. 39 
273 

