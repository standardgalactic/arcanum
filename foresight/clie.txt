User-friendly ontology authoring using a controlled language
Valentin Tablan, Tamara Polajnar, Hamish Cunningham, Kalina Bontcheva
Department of Computer Science
University of Shefﬁeld
Regent Court, 211 Portobello Street
S1 4DP, Shefﬁeld, UK
{V.Tablan, T.Polajnar, H.Cunningham, K.Bontcheva}@dcs.shef.ac.uk
Abstract
In recent years, following the rapid development in the Semantic Web and Knowledge Management research, ontologies have become
more in demand in Natural Language Processing. An increasing number of systems use ontologies either internally, for modelling the
domain of the application, or as data structures that hold the output resulting from the work of the system, in the form of knowledge
bases. While there are many ontology editing tools aimed at expert users, there are very few which are accessible to users wishing to
create simple structures without delving into the intricacies of knowledge representation languages. The approach described in this paper
allows users to create and edit ontologies simply by using a restricted version of the English language. The controlled language described
within is based on an open vocabulary and a restricted set of grammatical constructs. Sentences written in this language unambiguously
map into a number of knowledge representation formats including OWL and RDF-S to allow round-trip ontology management.
1.
Introduction
Research work in recent years in the ﬁelds of Semantic
Web (SW) and Knowledge Management (KM) has pro-
duced tools that are useful in a variety of contexts and sce-
narios. Many of these tools require a structuring of the in-
formation space most commonly in the form of ontologies.
A growing trend is the use of natural language processing
(NLP) methods, from the area of Information Extraction,
for automatic derivation of semantic meta-data, from ex-
isting textual documents, in order to bootstrap the layer of
formal knowledge required by Semantic Web tools. Out-
side of the SW ﬁeld, ontologies are also a popular method
of representing domain information used internally by NLP
systems. All these create a need for user-friendly methods
of authoring ontological data.
A number of ontology editing tools, such as Prot´eg´e (Noy
et al., 2001), are available to knowledge engineers; how-
ever, these tools require some training and an understand-
ing of underlying representation formalisms. The ontol-
ogy representation languages such as OWL (Dean et al.,
2004) or RDF-S (Lassila and Swick, 1999) are quite com-
plex and descriptive, but not easy to comprehend for non-
expert users. Our experience has shown that in many cases
where ontologies are used within NLP systems, only a few
of the features supported by languages such as OWL are
actually used. In most cases the requirements only include
representing a taxonomy of classes, being able to deﬁne
properties that apply to class members, and the ability to
describe new instances for the classes and the property val-
ues for them; however, in order to assure compatibility, the
format used for data interchange needs to comply with the
standards. This creates a situation where relatively simple
information, i.e. that people would ﬁnd easy to put into
words, needs to be represented using an advanced mecha-
nism that requires a deep understanding of the intricacies
of the representation formalism.
The approach proposed by this paper bridges that gap by
deﬁning a controlled language which, while restricted, still
feels natural to people and at the same time is unambiguous
and simple enough for the machines to process. This allows
non-specialists to create and edit ontological data while in-
sulating them from the complex syntax and semantics of
the ontology representation language.
2.
Context and Related Work
Human language is the most natural method of communi-
cation for people; however, it has very complex structures
and a large degree of ambiguity. This makes it difﬁcult to
process automatically and machines can currently only ex-
tract a limited amount of the information contained within.
People are able to understand language by using the con-
text of the discourse or extraneous information such as our
world-knowledge, clues like facial expressions, or tone of
voice. On the other side of the coin, formal data that is
rigidly structured is easily processed by machines but hard
and unnatural for people to use.
One way of resolve this dichotomy is by deﬁning controlled
languages. A controlled language (CL) is a subset of a natu-
ral language which is generally designed to be less complex
than the complete language and to include only certain vo-
cabulary terms and grammar rules which are relevant for a
speciﬁc task. The reduced complexity and the lack of am-
biguity makes it “understandable” by machines. Design-
ing a CL requires ﬁnding the right balance between power
of expression and simplicity, so that, while some linguis-
tic choices are restricted, the resulting language still feels
natural to the people using it.
The idea of controlled languages is not new, early con-
trolled languages can trace their roots to 1970’s Caterpillar
Fundamental English (CFE). CFE was designed to restrict
the complexity of the language used (it only had 850 terms)
so that the text is unambiguous enough that it can reliably
translated automatically into a variety of other languages.
Further examples are the Caterpillar Technical English
(CTE) which had 70,000 carefully chosen domain-speciﬁc
terms, the KANT (Kamprath et al., 1998) system developed
at Carnegie Mellon University, ClearTalk1 (Skuce, 2003),
1http://www.factguru.com

or Attempto Controlled English which is directly translat-
able into ﬁrst order logic (Schwertel, 2000). The approach
taken here differs from the previous work in that the gram-
mar is quite small while the vocabulary is quite broad. CTE,
KANT, ClearTalk, and Attempto all have more complex
grammars and limited vocabularies. The advantage of our
approach is that virtually no training is required to master
using a grammar which only allows a few constructs.
Given the aim to develop a user-friendly ontology authoring
system for NLP research, the choice of using a controlled
language to serve that purpose is reinforced by several fac-
tors. The previous work in CLs proves that it can be done
and provides pointers on how to approach the task. The
task of parsing CL input is essentially a language process-
ing task so it can make use of the existing infrastructure for
NLP. This also makes it easily customisable by language
engineers. While ontology authoring is mainly a task for
system developers, situations can be foreseen where the end
user will need to perform it as well, e.g. for customising an
existing system or in order to manually correct the results
of NLP systems. Because the input is text, the step of on-
tology maintenance will be easier to integrate in the overall
work-ﬂow of the system which is designed to work with
text anyway.
3.
From Text to Ontologies
The controlled language proposed here is modelled to al-
low maximum expressibility within the smallest set of syn-
tactic structures. The limited number of allowed syntactic
sentence structures makes the language easier to learn, and
much easier to use than OWL, RDF, or SQL. While the syn-
tactic structure of the sentences is constrained, the vocab-
ulary permitted is unrestricted: apart from a small number
of key-phrases that are used to mark phenomena of interest,
any terms can be used freely. This allows for the ontologies
created to be open-domain.
The possible types of actions are: deﬁnition of new classes,
creation of hierarchies between classes, deﬁnition of object
and data-type properties, creation of instances, and setting
of property values for instances.
The greatest advantage of this approach is that it requires
essentially no training; there are no complicated user inter-
faces to be learnt, there are no complex formalisms to be
understood. The user can simply start from a simple ex-
ample which shows all of the types of utterances accepted
by the system and continue the ontology authoring work
by re-using and modifying the provided examples. After
the editing is ﬁnished, the resulting ontology can then be
previewed using a simple ontology viewer implemented for
this purpose. Once the output has been validated, the ontol-
ogy can be saved into a variety of formats including RDF-S
and OWL variants.
The language analysis is carried out by a Controlled Lan-
guage Information Extraction (CLIE) application based on
the GATE language processing framework (Cunningham et
al., 2002a). The application is a pipeline comprising the
GATE English tokeniser, the Hepple part-of-speech tag-
ger, a morphological analyser, a transducer that identiﬁes
quoted strings, a list look-up component that recognises
useful key-phrases, followed by two more ﬁnite-state trans-
Figure 1: The CLIE application.
ducers, one for ﬁnding noun phrases and the last one that
actually parses the CL text and generates the ontology. All
the transducers are implemented using GATE’s JAPE pat-
tern matching language (Cunningham et al., 2002b). The
work-ﬂow of the application is depicted in Figure 1.
There are publications and authors.
Papers, articles and books are a type
of publication.
Publications have
authors.
Publications have textual
titles.
Paper 1 is a paper.
John Smith is an
author.
Paper 1 has author with value
John Smith.
Paper 1 has title with
value "A Paper About Something".
Figure 2: Example of input text
Figure 3: The resulting ontology.
The ﬁrst three components are standard NLP tools and are
used here to pre-process the input text while the quote
ﬁnder and the NP chunker are simple JAPE transducers.
The work of actually parsing CL input is mainly performed
by the CLIE transducer together with the key-phrase ﬁnder.
The key-phrase ﬁnder is implemented using the GATE
Gazetteer component and has the role of ﬁnding and an-
notating words and phrases that are part of the controlled
language. After all of the processing by the components
upstream is done, the CLIE parser needs only to look for
sentences that contain pre-determined types of key-phrases
at given locations inside. The remaining tokens from the
sentence that are not part of the key-phrases are used to
generate the names of the ontological objects that are cre-
ated.
An example of valid CL input is presented in Figure 2 while
the resulting ontology is shown in Figure 3. The full list of
constructs known by the CLIE parser is included in Table 1.

Sentence Pattern
Usage
Example
There are <class>.
Declares new classes
There are publications.
<sub-class> is a type of <super-
class>.
Declares a new class as a subclass of
an existing class.
Book is a type of publication.
<sub-class>, ..., <sub-class> are a
type of <super-class>.
Declares several new classes as sub-
classes of an existing class.
Books and articles are a type of pub-
lication.
<class> (can) have <class>.
Declares a new property linking two
classes.
Publications have authors.
<class> (can) have textual <property
name>.
Declares a new datatype property of
type string.
Publications have textual title.
<instance
name>
has
<instance
name>.
Gives a value for a property of an in-
stance. The name of the property is
obtained from the domain and range
restrictions of the known properties.
Book1 has John Smith.
<instance
name>
has
property
<property
name>
with
value
<instance name>.
Gives a value for a speciﬁed property
of an instance. This variant can be
used when there are several proper-
ties that might apply for the given in-
stance types.
Book1 has author with value John
Smith.
Table 1: Controlled language constructs
The Controlled Language IE application (CLIE) employs a
deterministic approach, so that each sentence can be parsed
in one way only. Allowed sentences are unambiguous, so
each sentence type is translated to one type of statement. If
parsing fails it will result in a warning and no ontological
output.
The use of linguistic analysis allows for small variations
in the surface form used to name objects, for instance the
use of plurals where it feels appropriate from a linguistic
point of view, without affecting the capability of the system
to identify different references for the same entity. For in-
stance, in the example provided in Figure 2, the sentence
‘‘There are publications.’’
will lead to the
creation of a new ontology class called ‘Publication’.
The
sentence
‘‘Papers, articles and books
are a type of publication.’’
will
create
three new ontology classes that are sub-classes of
‘Publication’. The class ‘Publication’ is re-
ferred to in two different ways – one in plural and capi-
talised and another one in singular form and all lowercase.
The use of the morphological analyser allows the system
to recognise that the two words have the same root. As al-
ready exempliﬁed above, listing several ontological objects
in the same statement is also allowed.
The names of ontological objects (classes, properties and
instances) are normalised – ﬁrst letters are capitalised,
spaces are replaced with underscores and the head word in
the case of noun phrases is shown un-inﬂected. If this is
undesirable, names can be included in single quotes which
will cause them to be used as they appear in the text.
The growing ontology that is generated from the parsed
text is also used as a parsing aid. The CLIE parser veriﬁes
each statement that it reads for inconsistencies with regard
to the data already in the ontology. For example if we were
to remove the ‘‘Publications have authors’’
sentence from the input, then an error message stating
‘‘Error (hasPropertyValue):
Property
does not exist:
has Author’’ will be issued
when the penultimate sentence is reached. The types of the
objects used for values of properties are also checked for
validity.
In order to provide feedback during editing, a simple ontol-
ogy viewer (seen in Figure 3) has been implemented. The
left panel shows the ontology as a tree containing the class
hierarchy and the instances, while the right panel shows de-
tails for the node currently selected in the tree.
4.
Round-trip Ontology Authoring
The previous section described how one can use CL text
to generate a new ontology. The tool described in this pa-
per, however, is a round-trip ontology authoring tool which
also allows an existing ontology to be translated into natu-
ral language. This is useful for either enriching an existing
ontology or for manually correcting the output of a system
that saves its results into an ontology.
In order to address this use case, a language generator has
been implemented that can produce text starting from an
ontology. The generator together with the CLIE application
form a round-trip ontology authoring environment: one can
start with either an empty ontology or an existing one, gen-
erate CL text from it using the generator, modify the text as
required and parse the resulting text back into an ontology
using the CLIE application. This process can be repeated
as necessary until the required result is obtained.
The text generation component has been implemented as a
GATE resource. It is conﬁgured using an XML ﬁle that
contains text templates that are instantiated and ﬁlled in
with values from the ontology. An example of a template
that is used to generate the text for declaring new top-level
classes is presented in Figure 4. The process of converting
an ontology to text has several phases. First the ontology is
converted into triples of type <subject, property, object> in

<!-- Template for defining top classes -->
<template>
<in>
<triple id="t1">
<property ns="rdf" name="type"/>
<object ns="owl" name="Class"/>
</triple>
</in>
<out>
<singular>
<phrase>There are <ref ref="t1.subject" number="plural"/>. </phrase>
</singular>
<plural>
<phrase>There are <ref ref="t1.subject" number="plural"/>. </phrase>
</plural>
</out>
<ignoreIf>
<triple id="t2">
<subject ref="t1.subject"/>
<property ns="rdfs" name="subClassOf"/>
</triple>
</ignoreIf>
</template>
Figure 4: Example of a generation template.
the style of RDF. Next all generation templates are used to
ﬁnd triples that match their input speciﬁcation. For all the
triples that have been matched with a template, a group-
ing process, which ﬁnds sets of triples that can be used to-
gether to generate a single sentence, is performed. Finally,
for each set of triples matched to a template, a sentence is
generated and written to the output.
The generation of triples from the input ontology is fairly
trivial. First, the class hierarchy is traversed in breadth-ﬁrst
manner to create a list of classes where the super-classes are
always mentioned before their corresponding subclasses.
For each class in the list, one or more triples are generated
that include the declaration of a new class, the link with any
super-class through the rdfs:subClassOf property and
the list of all the instances for the new class. After the pro-
cessing of the classes and their instances has been ﬁnished,
the properties are next to be converted. Finally, triples that
declare property values for all the instances are generated.
At the end of this process, the entire ontology has been con-
verted into a list of triples.
The next step matches the generation templates from the
conﬁguration ﬁle with triples from the list obtained in the
previous step. A generation template (see the example in
Figure 4) has three main components: an in element con-
taining a list of triple speciﬁcations, an out element con-
taining phrases that are generated when a successful match
has occurred, and an optional ignoreIf element that can
be used to specify additional triple speciﬁcations that cause
the match speciﬁed in the in element to be ignored if the
conditions are satisﬁed.
The in part of a template consists of a list of triple speci-
ﬁcations, where each triple may have a subject, a property,
and an object element. A triple speciﬁcation should be seen
as a restriction – it lists the conditions required for an input
triple to match this template. If there is more than one triple
included in the in element, they should be seen as a con-
junction of restrictions: the template will only match when
several triples have been found, one for each triple spec-
iﬁcation included. References from one triple to another
are permitted: one can specify for instance that the second
triple should have the same object as the subject of
the ﬁrst triple. The triples in the in element are matched in
the order they were listed in the template so only backward
references are permitted – a triple can only refer to a previ-
ously deﬁned one. An example of using references can be
seen in the ignoreIf element of the template presented
in Figure 4.
The out section of a template speciﬁcation describes the
text that gets generated when a successful match occurs.
It contains phrase templates that have text elements and
references to values that were matched from the in part.
The phrases are divided into singular and plural forms,
the plural variants being used when several triples are
grouped together and are used to generate a single sen-
tence using a list of ontology objects (e.g. saying “There
are publications and authors.”
will declare
two new top classes in the same sentence). The text el-
ements inside a phrase template are simply copied to the
output while the reference elements are replaced with the
actual values based on the triples that were matched with
the speciﬁcations from the in section. The out section of
a template can include several phrase templates for each of
the singular and plural sections. These are seen as
alternative variants of expressing the same message and are
used by rotation. This facility was added to avoid tedious
repetitions of similar phrases.
Generation templates can also include an ignoreIf sec-
tion which is similar to the in section in the sense that

it also contains a list of triple speciﬁcations. References
to triples matched in the in section are permitted. For a
template that contains an ignoreIf section, there is an
additional step before a match is accepted. If the restric-
tions from the in section are satisﬁed, then the restrictions
from the ignoreIf section are also checked. If additional
triples are found to satisfy those conditions, then the match
is cancelled and the generation template is not applied.
After a generation template has been used to check for
matches in the list of triples, the next step groups the
matches together into sets that can be expressed together
by a single phrase using the plural variant. For this to be
possible, the condition is that the only difference between
the matches in a set occurs in only one of the references
used in the phrase template, i.e. that the singular variants
of the phrases that would be generated for each individual
match would only differ by one value. If that is the case,
then all the matches in the set can be grouped into a plural
phrase. Once all the matched triples have been grouped into
sets, an output sentence is written for each resulting set.
There are also a special type of generation template that in-
clude no in restrictions. These can be used to include text
into the output that does not depend on any input triples. As
the generation templates are applied in the order they were
deﬁned in the conﬁguration ﬁle, an empty template will be
applied after all the normal templates before it have been
used.
5.
Future Work
The current state of the work described here is that of proof-
of-concept prototype. The system can generate ontologies
starting from CL text and can also generate CL text start-
ing from an ontology. Support is only provided for basic
features of the ontological formalisms – the taxonomy of
classes, instances of classes, properties and their values.
Currently only object and string datatype properties are
supported. The system could be extended to support more
types of datatype properties, such as numbers, dates, etc.
This would require adding new constructs to the controlled
language that will allow the declaration of such types and
functionality for parsing values of these types.
Another possible improvement would be to add more alter-
natives of expressing the same message; currently only one
or at most two constructs are supported for any operation.
Adding more variants would make it more likely that the
language contains whatever variant that a user might chose
thus reducing the number of errors that new users get and
minimising the amount of training required for using the
system.
While these additions to the language would increase the
number of features that are supported and might make the
language feel more natural, care should be taken not to
make the language too complex. The aim of this work is to
simplify the problem up to a point where a simple solution
can be applied, while keeping the results useful. A CL that
covers all the features of an ontology representation lan-
guage such as OWL is possible but probably not desirable
– as it would be difﬁcult to learn and use. A simple con-
trolled language, such as the one described here, requires
essentially no training. When starting from an existing on-
tology, the generator will convert it into CL text which can
then be used as example for adding information to the on-
tology.
6.
Conclusions
The use of ontologies in NLP systems is becoming more
and more frequent, a trend encouraged by the rapid de-
velopments in the ﬁelds of Semantic Web and Knowledge
Management. Formal standards for representing ontologies
have now been created and ratiﬁed by bodies such as the
World Wide Web Consortium and are being widely used
in applications. These standards, such as RDF, RDF-S or
OWL, are very rich in features which leads to very com-
plex authoring environments which can be overwhelming
to new users.
This work proposes an alternative to the graphical inter-
faces in the form of a controlled language that can be used
to describe ontologies. Tools for automatically converting
from the CL to the ontology and from an ontology to the
CL have been implemented forming a text-based ontology
authoring environment. As these tools have been integrated
with the GATE language engineering platform, they make
use of GATE’s ontology API for reading and writing ex-
ternal ontologies, which means that standard representation
formats are supported.
The use of a text-based interface for authoring ontologies
can be advantageous in many scenarios: when it needs
to integrate into an existing text-based work-ﬂow, when it
needs to run on platforms with limited graphical capabili-
ties (e.g. withing the editor of a wiki-style web application)
or when the target users would feel more comfortable with
editing text rather than being faced with a complex graphi-
cal interface.
7.
Acknowledgements
The research for this paper was conducted as part of the
European Union Sixth Framework Program projects SEKT
(EU IST IP 2003-506826) and PrestoSpace (FP6- 507336).
8.
References
H. Cunningham, D. Maynard, K. Bontcheva, and V. Tablan.
2002a. GATE: A Framework and Graphical Develop-
ment Environment for Robust NLP Tools and Applica-
tions. In Proceedings of the 40th Anniversary Meeting of
the Association for Computational Linguistics (ACL’02).
H. Cunningham, D. Maynard, K. Bontcheva, V. Tablan,
and
C.
Ursu.
2002b.
The
GATE
User
Guide.
http://gate.ac.uk/.
M. Dean, G. Schreiber, S. Bechhofer, Frank van Harmelen,
J. Hendler, I. Horrocks, D. L. McGuinness, P. F. Patel-
Schneider, and L. A. Stein. 2004. OWL web ontology
language reference. W3C recommendation, W3C, Feb.
http://www.w3.org/TR/owl-ref/.
C. Kamprath, E. Adolphson, T. Mitamura, and E. Nyberg.
1998. Controlled Language for Multilingual Document
Production: Experience with Caterpillar Technical En-
glish. In Second International Workshop on Controlled
Language Applications (CLAW ’98).

O. Lassila and R.R. Swick.
1999.
Resource Descrip-
tion Framework (RDF) Model and Syntax Speciﬁca-
tion. Technical Report 19990222, W3C Consortium,
http://www.w3.org/TR/REC-rdf-syntax/.
N.F. Noy, M. Sintek, S. Decker, M. Crubzy, R.W. Ferger-
son, and M.A. Musen. 2001. Creating Semantic Web
Contents with Prot´eg´e-2000. IEEE Intelligent Systems,
16(2):60–71.
Uta Schwertel. 2000. Controlling plural ambiguities in At-
tempto Controlled English. In Proceedings of the 3rd In-
ternational Workshop on Controlled Language Applica-
tions, Seattle, Washington.
D.
Skuce.
2003.
A
Controlled
Language
for
Knowledge
Formulation
on
the
Semantic
Web.
http://www.site.uottawa.ca:4321/factguru2.pdf.

