HAL Id: tel-00277993
https://tel.archives-ouvertes.fr/tel-00277993
Submitted on 7 May 2008
HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not.
The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.
L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.
Quaternions et Algèbres Géométriques, de nouveaux
outils pour les images numériques couleur
Patrice Denis
To cite this version:
Patrice Denis. Quaternions et Algèbres Géométriques, de nouveaux outils pour les images numériques
couleur. Interface homme-machine [cs.HC]. Université de Poitiers, 2007. Français. ￿tel-00277993￿

THÈSE
pour l’obtention du Grade de
DOCTEUR DE L’UNIVERSITÉ DE POITIERS
(Faculté des Sciences Fondamentales et Appliquées)
(Diplôme National - Arrêté du 7 Août 2006)
École Doctorale
: Sciences Pour l’Ingénieur et Aéronautique
Secteur de Recherche
: Traitement du Signal et des Images
Présentée par :
Patrice DENIS
Quaternions et Algèbres Géométriques, de
nouveaux outils pour les images numériques
couleur
Directeurs de Thèse :
Christine FERNANDEZ-MALOIGNE
Philippe CARRÉ
Soutenue le 13 décembre 2007 devant la Commission d’Examen composée de :
J.M. Chassery, Directeur de Recherche CNRS, INP Grenoble, GIPSA-LAB, UMR 5216 . . . . . . . . . . . . . . . . . . . . . . . .Rapporteur
P. Lambert, Professeur, Université de Savoie, LISTIC, EA 3703 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Rapporteur
J. Angulo, Chercheur Associé, Ecole des Mines de Paris, Centre de Morphologie Mathématique . . . . . . . . . . . . . . . Examinateur
M. Berthier, Professeur, Université de La Rochelle, MIA, EA 3165 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Examinateur
P. Carré, Maître de Conférences, Université de Poitiers, XLIM-SIC, UMR 6172 . . . . . . . . . . . . . . . . . . . . . Co-directeur de Thèse
C. Fernandez-Maloigne, Professeur, Université de Poitiers, XLIM-SIC, UMR 6172 . . . . . . . . . . . . . . . . . . . . . Directeur de Thèse
Laboratoire XLIM, Département SIC : Signal Image Communications, UMR CNRS 6172


Quaternions et Algèbres Géométriques, de nouveaux outils pour les
images numériques couleur
Résumé Les travaux de cette thèse s’inscrivent dans le contexte du traitement et de l’analyse des images
couleur. Les premiers travaux pour traiter ces images consistaient à appliquer des traitements déjà existant
en niveaux de gris marginalement sur les trois composantes constituant la couleur et le plus généralement
dans l’espace RV B. Ces traitements ont été peu à peu améliorés notamment par l’utilisation d’espaces
couleur d’avantage liés à la perception humaine mais aussi par des approches vectorielles. Dans ce tra-
vail de thèse nous nous plaçons dans la continuité de ces travaux et nous proposons une modélisation
mathématique de la dimension vectorielle dans le but de manipuler les couleurs de manière globale.
Trois formalismes sont présentés pour représenter la couleur : les complexes, les quaternions et les al-
gèbres géométriques. Dans ce cadre, il est proposé de déﬁnir de nouveaux outils d’analyse couleur avec
notamment une caractérisation numérique fréquentielle de chacun de ces modèles. Une étude approfon-
die de leurs utilisations permet de faire ressortir leurs propriétés ainsi que leurs principaux avantages et
inconvénients à savoir : impossibilité des complexes à représenter les vecteurs couleurs qui par nature
s’expriment en trois dimensions minimum contrairement aux quaternions et aux algèbres géométriques ;
distinction entre objets manipulés (vecteurs couleur) et opérations effectuées sur ces objets (projections,
rotations,. . . ) pour les algèbres géométriques contrairement aux quaternions . . . Enﬁn nous avons mon-
tré que la transformée de Fourier quaternionique analyse la couleur avec une direction indiquée par un
vecteur couleur, tandis que la transformée de Fourier déﬁnie au moyen de l’algèbre G3, plus générique,
répartit l’information couleur sur des composantes fréquentielles indépendantes. L’utilisation de modèles
algébriques pour représenter l’information couleur permet la déﬁnition et le développement d’un ﬁltre
spatial de détection de contours tenant compte de la dispersion dans l’espace couleur.
Quaternions and Geometric Algebras, new tools for digital colour images
Abstract
The main subject of this PhD thesis is colour image processing. The ﬁrst methods dealing
with these images consisted in applying existing greyscale processing alorithms on each of the three
colour components. Colour processing has improved using perceptual colour spaces but also by consi-
dering colours as vectors. In this work, we follow the idea of colour modelization and we propose to
encode their vectorial information into mathematical models in order to manipulate them globally and
geometrically. Three formalisms are presented to cope with colour : complex numbers, quaternions and
geometric algebras (also called Clifford algebras). New colour tools are proposed to analyse the digital
spectrum embedded in each of these formalisms and the deﬁnition of Fourier transforms. We give the
main advantages and drawbacks of each model, namely : impossibility for the complex numbers to re-
present whole colour vectors that needs at least three components to be described properly ; distinction
between objects and operations on objects (projections, rotations, . . . ) with geometric algebras whereas it
is not possible with quaternions. We then showed that the quaternionic Fourier transform analyse colours
with a direction whereas the Clifford G3 Fourier transform has not got any direction to analyse the colour
so it treats every colour channel independently. Eventually one of the main applications is the deﬁnition
of a spatial colour edge detector ﬁlter using these formalisms.
Discipline : traitement du signal et des images.
Mots clés : Analyse d’images, espace numérique couleur, quaternions, algèbres géométriques, transfor-
mations de Fourier, ﬁltrage spatial et fréquentiel.
Patrice Denis - Laboratoire Signal Image Communication
Bât. SP2MI - Téléport 2, Bd Marie et Pierre Curie - BP 30179 - 86962 Futuroscope Cedex
III


REMERCIEMENTS
J’aimerais remercier un certain nombres de personnes qui m’ont accompagné au cours de ces trois
dernières années et sans lesquelles je n’aurais pas pu achever ses travaux de thèse.
Tout d’abord, je tiens à remercier tout particulièrement Philippe CARRÉ ainsi que Christine FER-
NANDEZ-MALOIGNE pour avoir accepté d’encadrer mes travaux de recherche. Philippe m’a de nom-
breuses fois éclairé lors de nos discussions scientiﬁques grâce notamment à son recul sur les approches
fréquentielles. Christine, avec sa maîtrise du domaine de la couleur, bien que n’ayant suivi mes travaux
que de plus loin, était disponible à chaque sollicitation et m’a également beaucoup apporté. Enﬁn tous
les deux m’ont accueilli chaleureusement et m’ont fait bénéﬁcier de leurs qualités humaines.
Je tiens à également remercier Pascal LIENHARD pour son accueil au sein du laboratoire SIC dans
lequel mes travaux ont été effectués.
Ensuite, ma reconnaissance va à l’ensemble des membres de mon jury de thèse. Tout d’abord Patrick
LAMBERT et Jean-Marc CHASSERY : merci beaucoup à eux d’avoir accepté la tâche de rapporteur,
ainsi que pour toutes leurs remarques qui m’ont permis d’améliorer la rédaction de ce mémoire. Je tiens
aussi à exprimer une sincère gratitude envers mes deux autres examinateurs, Michel BERTHIER et Jesus
ANGULO qui m’ont également fourni de nombreuses observations détaillées et critiques constructives
là encore vraiment bienvenues pour ﬁnaliser ce mémoire.
Maintenant, je proﬁte aussi de cette page de remerciements pour faire « coucou » aux personnes qui
ont partagé mon quotidien pendant ces trois ans.
D’abord merci aux super secrétaires : les deux Françoises (je mets un s même s’il faut pas), Sylvie,
Jacqueline et Nicole. Avec ces personnes, j’ai toujours pris plaisir à discuter et surtout à bien rigoler,
coucou aussi à Philippe et Nora.
Ensuite je remercie tous mes collègues et/ou amis (doctorants, docteurs ou même aucun des deux
d’ailleurs) au labo : François, Samuel, Pascal, Fred, Benjamin, Fred, Loé, Hung, Sylvain, Antoine, Hond-
jack, les Oliviers (encore un s là ou il en faut pas !), Windu, Patience, Philou, Chimène, Sybille, Karim,
Sadouanouan, Wassim, Ahmed, Kamel, Idir, Dung, Hieu, Luc, Jeff, Martin, Seb, Peff, Mathieu (MAC
Team), Stéphane, Bruno, Guillaume, Yannick et toutes les autres personnes du SIC et du LISI que je
n’oublie pas. Heureusement qu’ils étaient là pour faire du quotidien des jours très agréables.
Je remercie aussi tous les copains du « petit foot entre amis » et du « Championnat inter-labos » avec
qui j’ai réussi à me faire violence en faisant du « sport » dans le rôle du gardien de but (si, si, un gardien
se dépense !).
J’en proﬁte aussi pour dire coucou aux amis parce que c’est marrant de les voir dans le manuscrit de
thèse : Pollux, Tetelle, Sylvain, Djay, Leïla, Stéphouille, Damino, Katya et Christian.
Pour terminer, je remercie évidemment toute ma famille, mes parents pour leur soutien ainsi que
les tâches ingrates telles que la relecture pour l’orthographe par exemple. Enﬁn je remercie Laëtitia, ma
Chacha mougnonne, pour l’anglais, pour m’avoir supporté pendant tout ce temps mais surtout le support
qu’elle m’a fourni dans les moments plus difﬁciles.
V


SOMMAIRE
1
Introduction
1
2
Modélisation des couleurs par les nombres complexes
5
2.1
Les Complexes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5
2.1.1
Plan complexe
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5
2.2
Transformées de Fourier pour les signaux bi-dimensionnels . . . . . . . . . . . . . . . .
6
2.2.1
Transformée de Fourier 2D discrète . . . . . . . . . . . . . . . . . . . . . . . .
7
2.2.2
Bases de l’interprétation des transformées de Fourier à deux dimensions . . . . .
8
2.3
Espaces Couleur . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
13
2.3.1
Les espaces de primaires . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
14
2.3.2
Les espaces dédiés à la télévision
. . . . . . . . . . . . . . . . . . . . . . . . .
16
2.3.3
Les espaces perceptuels
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
18
2.3.4
Les espaces perceptuellement uniformes . . . . . . . . . . . . . . . . . . . . . .
19
2.3.5
Les espaces couleur indépendants . . . . . . . . . . . . . . . . . . . . . . . . .
20
2.3.6
Étude numérique de l’espace Y UV
. . . . . . . . . . . . . . . . . . . . . . . .
21
2.4
Analyse spatio-chromatique d’images couleur . . . . . . . . . . . . . . . . . . . . . . .
23
2.4.1
La transformation de Fourier spatio-chromatique . . . . . . . . . . . . . . . . .
24
2.4.2
Le module du spectre fréquentiel UV sur des images couleur . . . . . . . . . . .
34
2.5
Filtrage fréquentiel UV . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
34
2.6
Conclusion
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
35
3
Modélisation des couleurs par les quaternions
37
3.1
Déﬁnition des quaternions et propriétés
. . . . . . . . . . . . . . . . . . . . . . . . . .
37
3.1.1
Historique . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
37
3.1.2
Déﬁnition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
37
3.1.3
Notations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
38
3.1.4
Vocabulaire . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
38
3.1.5
Représentation cartésienne . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
38
3.1.6
Représentation vectorielle
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
38
3.1.7
Produit quaternionique . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
38
3.1.8
Représentation exponentielle . . . . . . . . . . . . . . . . . . . . . . . . . . . .
39
3.1.9
Représentation polaire . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
39
3.1.10 Représentation de Cayley-Dickson . . . . . . . . . . . . . . . . . . . . . . . . .
40
3.1.11 Représentation symplectique . . . . . . . . . . . . . . . . . . . . . . . . . . . .
40
3.1.12 Transformations géométriques . . . . . . . . . . . . . . . . . . . . . . . . . . .
41
3.1.13 Représentation parallèle/perpendiculaire . . . . . . . . . . . . . . . . . . . . . .
41
3.2
Approche spatiale quaternionique pour les images couleur
. . . . . . . . . . . . . . . .
41
3.2.1
Quaternions et images couleur . . . . . . . . . . . . . . . . . . . . . . . . . . .
41
VII

3.2.2
Séparation partie simplexe et partie perplexe
. . . . . . . . . . . . . . . . . . .
42
3.2.3
Transformations couleur . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
42
3.2.4
Détection de contours
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
43
3.3
Transformées de Fourier quaternioniques
. . . . . . . . . . . . . . . . . . . . . . . . .
51
3.3.1
TFQ utilisant j et k dans les exponentielles
. . . . . . . . . . . . . . . . . . . .
51
3.3.2
TFQ utilisant i et j dans les exponentielles . . . . . . . . . . . . . . . . . . . . .
52
3.3.3
TFQ directionelle à droite
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
53
3.3.4
TFQ directionelle à gauche . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
53
3.3.5
TFQ directionelle à deux côtés . . . . . . . . . . . . . . . . . . . . . . . . . . .
53
3.3.6
Inversibilité . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
53
3.4
Approche fréquentielle quaternionique pour les images en niveaux de gris . . . . . . . .
53
3.4.1
Transformée de Fourier quaternionique pour les images en niveaux de gris . . . .
54
3.4.2
Symétries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
54
3.4.3
Notion d’amplitude et de phase instantanées . . . . . . . . . . . . . . . . . . . .
56
3.5
Approche fréquentielle quaternionique pour les images couleur . . . . . . . . . . . . . .
58
3.5.1
Déﬁnition numérique de l’espace de Fourier quaternionique
. . . . . . . . . . .
58
3.5.2
Interprétation du spectre quaternionique . . . . . . . . . . . . . . . . . . . . . .
61
3.5.3
Applications
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
72
3.6
Conclusion
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
74
4
Modélisation des couleurs par les algèbres géométriques
77
4.1
Algèbres Géométriques . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
77
4.1.1
Déﬁnition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
77
4.1.2
Vocabulaire . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
78
4.1.3
Les produits . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
79
4.1.4
Propriété du produit géométrique
. . . . . . . . . . . . . . . . . . . . . . . . .
81
4.1.5
Notions Complémentaires
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
81
4.1.6
Transformations géométriques . . . . . . . . . . . . . . . . . . . . . . . . . . .
84
4.1.7
Notation exponentielle et rotation
. . . . . . . . . . . . . . . . . . . . . . . . .
85
4.1.8
Comparaison de deux 1-vecteurs par le produit géométrique . . . . . . . . . . .
86
4.1.9
Quaternions et algèbres géométriques . . . . . . . . . . . . . . . . . . . . . . .
87
4.2
Approche fréquentielle par algèbres géométriques pour les images en niveaux de gris . .
88
4.3
Approche fréquentielle par algèbres géométriques pour les images couleur . . . . . . . .
89
4.3.1
G2 et Images Couleur . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
89
4.3.2
G3 et images couleur . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
94
4.4
Approche spatiale par algèbres géométriques pour les images couleur
. . . . . . . . . .
98
4.4.1
Exprimer les couleurs RV B dans un espace Teinte Saturation Intensité
. . . . .
98
4.4.2
Transformations géométriques couleur . . . . . . . . . . . . . . . . . . . . . . . 102
4.5
Filtrage spatial par algèbre de Clifford . . . . . . . . . . . . . . . . . . . . . . . . . . . 107
4.5.1
Approche détection de Sangwine . . . . . . . . . . . . . . . . . . . . . . . . . . 107
4.5.2
Approche par gradient de saturation . . . . . . . . . . . . . . . . . . . . . . . . 108
4.5.3
Approche par gradient de saturation et produit géométrique . . . . . . . . . . . . 109
4.6
Conclusion
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112
5
Conclusion
117
A Algèbre géométrique G2
121
A.1
Simpliﬁcation par transformées de Fourier Rapides . . . . . . . . . . . . . . . . . . . . 121
A.2
Conditions d’initialisation du spectre . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122
A.3
Interprétation de l’inﬂuence d’un Dirac dans le spectre
. . . . . . . . . . . . . . . . . . 122
A.3.1
Initialisation sur la composante scalaire . . . . . . . . . . . . . . . . . . . . . . 123
A.3.2
Initialisation sur la composante bivectorielle . . . . . . . . . . . . . . . . . . . . 123
VIII

A.3.3
Initialisation sur une composante vectorielle . . . . . . . . . . . . . . . . . . . . 123
B
Algèbre Géométrique G3
125
B.1
Simpliﬁcation par transformées de Fourier rapides . . . . . . . . . . . . . . . . . . . . . 125
B.2
Calcul numérique de la transformée de Fourier
. . . . . . . . . . . . . . . . . . . . . . 126
B.3
Calcul numérique de la transformée de Fourier inverse
. . . . . . . . . . . . . . . . . . 126
B.4
Conditions d’initialisation du spectre . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127
B.5
Interprétation de l’inﬂuence d’un Dirac dans le spectre
. . . . . . . . . . . . . . . . . . 129
B.5.1
Initialisation sur une composante vectorielle . . . . . . . . . . . . . . . . . . . . 129
B.5.2
Initialisation sur une composante bi-vectorielle . . . . . . . . . . . . . . . . . . 130
C Transformée en ondelette quaternionique
131
C.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131
C.2
Quaternion
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 132
C.2.1
Deﬁnition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 132
C.2.2
Frequency analysis : the Quaternionic Fourier Transform.
. . . . . . . . . . . . 133
C.3
Colour quaternion spectrum properties . . . . . . . . . . . . . . . . . . . . . . . . . . . 134
C.3.1
Spectrum analysis
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 134
C.3.2
Graphical Illustration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 135
C.4
Quaternionic Filters Bank . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 137
C.4.1
Filtering operation : convolution product
. . . . . . . . . . . . . . . . . . . . . 139
C.4.2
Deﬁnition of the downsampling . . . . . . . . . . . . . . . . . . . . . . . . . . 140
C.4.3
Deﬁnition of the upsampling . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141
C.4.4
Quaternionic Filter banks with perfect reconstruction . . . . . . . . . . . . . . . 141
C.4.5
An example : the Quaternionic Shannon ﬁlter bank . . . . . . . . . . . . . . . . 142
C.4.6
Experimentation
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144
C.5
Conclusion
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144
D Spatial and spectral Quaternionic approaches for Colour Images
147
D.1
Quaternions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 148
D.1.1
Concept . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 148
D.1.2
R3 Transformations with Quaternions . . . . . . . . . . . . . . . . . . . . . . . 149
D.2
Discrete Quaternion Fourier Transform . . . . . . . . . . . . . . . . . . . . . . . . . . . 150
D.2.1
Deﬁnition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 150
D.2.2
Colour quaternion spectrum properties . . . . . . . . . . . . . . . . . . . . . . . 150
D.2.3
Digital study of the colour spectrum . . . . . . . . . . . . . . . . . . . . . . . . 151
D.2.4
Quaternionic Graphical Spectrum Illustration . . . . . . . . . . . . . . . . . . . 151
D.3
Quaternionic ﬁltering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 152
D.3.1
Spatial ﬁltering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 152
D.3.2
Frequency ﬁltering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 158
D.4
Conclusion
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 160
D.5
Appendix . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 162
D.5.1
Digital study of the colour spectrum . . . . . . . . . . . . . . . . . . . . . . . . 162
D.5.2
Quaternionic Graphical Spectrum Illustration . . . . . . . . . . . . . . . . . . . 163
Bibliographie
169
IX


NOTATIONS
Domaine de déﬁnitions
R
ensemble des nombres réels
C
ensemble des nombres complexes
H
ensemble des quaternions
P
ensemble des quaternions purs
S
ensemble des quaternions unitaires
E
espace vectoriel E
Gn
algèbre géométrique de dimension 2n construite à partir d’un espace vectoriel de dimension n
Transformées de Fourier
TF ou FT
Transformée de Fourier (ou Fourier Transform en anglais)
TFD ou DFT
Transformée de Fourier Discrète
TFDI ou IDFT
Transformée de Fourier Discrète Inverse
TFQ ou QFT
Transformée de Fourier Quaternionique
TFQD ou DQFT
Transformée de Fourier Quaternionique Discrète
TFC ou CFT
Transformée de Fourier Cliffordienne
TFCD ou DCFT
Transformée de Fourier Cliffordienne Discrète
TFR ou FFT
Transformée de Fourier Rapide
XI

Signaux
f(.)
fonction continue
F(.)
TF de la fonctionf
f[.]
fonction discrète
F[.]
TFD de la fonctionf
t, x, y
variables continues temporelles ou spatiales
ω, u, v
variables continues fréquentielles
m, n
variables discrètes temporelles ou spatiales
o, p
variables discrètes fréquentielles
Quaternions
q = a + ib + jc + kd
quaternion quelconque
qr
partie réelle d’un quaternion q
qi
première partie imaginaire d’un quaternion q
qi
seconde partie imaginaire d’un quaternion q
qk
dernière partie imaginaire d’un quaternion q
Algèbres géométriques
A ou A ∈Gn
A ou A sont des multivecteurs quelconques de Gn
a ou a ∈Gn
a ou a sont des 1-vecteurs de Gn
f ∈Gn
fonction 1-vectorielle de Gn
Mi
partie vectorielle d’un multivecteur M de Gn avec i ∈1 . . . n
Mij
partie bivectorielle d’un multivecteur M de Gn avec i ∈1 . . . n, j ∈1 . . . n et i ̸= j
XII

CHAPITRE 1
INTRODUCTION
Les travaux présentés dans ce mémoire ont été ﬁnancés par la Région Poitou-Charentes et réalisés
au sein du laboratoire Signal Image et Communications de l’Université de Poitiers sous la direction de
Christine Fernandez-Maloigne, Professeur et de Philippe Carré, Maître de Conférences.
Dans ce travail nous nous intéresserons spéciﬁquement aux images numériques couleur et étudie-
rons l’opportunité donnée par certains formalismes mathématiques pour encoder l’information couleur.
Précisément, nous étudions des objets déﬁnis de la façon suivante :
f : (m, n) 7→(fr, fg, fb)
Z × Z →(R, R, R)
Historiquement les travaux portant sur les transformations numériques des images couleur ont d’abord
consisté à appliquer des traitements marginaux sur chacun des trois canaux composant la couleur. Ces
traitements n’utilisent cependant pas la couleur comme une information globale mais bien comme la
juxtaposition des trois composantes indépendantes. La conséquence de ce type de traitement marginal
est que la plupart des résultats fournis par ces traitements entrainent l’apparition de fausses couleurs. En
effet, rien n’indique que le traitement individuel de chaque composante d’un vecteur couleur entraine
un vecteur couleur proche de celui d’origine. En représentation Rouge, Vert, Bleu (RV B1) notamment,
chaque canal apporte sa contribution colorée et est ajouté aux autres en respectant le principe de la syn-
thèse additive des couleurs. Des phénomènes isolés sur une composante particulière peuvent donc se
trouver réhaussés perceptuellement du fait de leur addition avec les autres composantes couleur. Si ce
phénomène existe aussi sur des images en niveaux de gris, sa perception est minimisée par rapport aux
images couleur où il s’accumule avec chacun des canaux couleur. La couleur d’un pixel obtenue par un
tel traitement marginal peut donc être représentée par un vecteur couleur perceptuellement très éloigné
de la couleur du vecteur couleur d’origine entrainant une image visuellement altérée.
Plus tard est apparue la possibilité de considérer l’information couleur comme une information vec-
torielle. Dans ce cas, la couleur est vue comme un vecteur de R3 décrivant une coordonnée au sein d’un
espace couleur. Différents espaces ont alors été proposés aﬁn de représenter la couleur de manière plus ou
moins proche de ce que la vision humaine pouvait percevoir des couleurs. Des traitements d’images ont
ainsi vu le jour utilisant des conversions entre ces différents espaces couleur et la représentation classique
jusqu’alors utilisée à savoir le RV B qui correspond à l’information directement exploitable par les pé-
riphériques informatiques classiques comme les écrans par exemple. La manipulation des vecteurs d’un
espace en trois dimensions présente cependant des difﬁcultés. Par exemple, il est difﬁcile d’ordonner des
vecteurs entre eux bien que des tentatives de déﬁnitions de relations d’ordre plus ou moins cohérentes
1en anglais le RGB pour red, green, blue.
1

2
CHAP 1 - INTRODUCTION
sur le plan perceptuel aient été proposées. Ensuite, il convient de déﬁnir la façon d’effectuer un traite-
ment vectoriel appliqué à des vecteurs couleur à trois dimensions. La difﬁculté consiste alors à redéﬁnir
pour la couleur les opérations classiques de traitement des images en niveaux de gris, par exemple le
produit de convolution, la dérivabilité (et donc le gradient couleur) ou encore plus généralement toutes
les approches permettant l’analyse d’une image. Notons de plus l’absence d’une analyse fréquentielle
spéciﬁque à l’utilisation de la couleur.
Dans ce contexte nous proposons d’étudier l’opportunité de coder l’information couleur des images
en utilisant des représentations algébriques. Ces représentations utilisent l’information d’un vecteur cou-
leur comme un nombre de l’algèbre utilisée. Ceci permet alors de manipuler les couleurs en utilisant
les opérations fournies par l’algèbre. Les vecteurs couleur sont considérés et manipulés avec des opéra-
tions courantes de type sommes et/ou de produits déﬁnis, de façon unique pour l’algèbre. Ceci permet,
en outre, d’alléger considérablement l’écriture d’opérations s’écrivant souvent de manière plus com-
plexe en utilisant la géométrie vectorielle. Cette notion de simpliﬁcation par l’algèbre est déjà utilisée
en traitement du signal car on utilise les nombres complexes, qui sont des éléments d’une algèbre, pour
représenter de manière différente une information. Précisément, la transformée de Fourier, qui nécessite
l’utilisation des nombres complexes, permet de passer d’une vision spatiale pour une image par exemple
à son équivalent en terme de fréquence. L’idée fondatrice de ces travaux est d’introduire une caractéri-
sation fréquentielle adaptée à la spéciﬁcité de la dimension couleur des images. Nous nous intéresserons
donc à l’opportunité d’utiliser les nombres complexes dans ce but. Une étude sera, pour cela, effectuée
sur la transformée de Fourier complexe utilisée par McCabe aﬁn de décrire les informations spectrales
associées à la partie chromatique des couleurs. Nous montrerons alors que seule, cette chromaticité ne
sufﬁt pas à caractériser pleinement les couleurs. Ainsi nous nous intéresserons, tout comme Sangwine
avant nous, à l’utilisation du formalisme des quaternions associé aux images couleur. Ces nombres hy-
percomplexes, car ils sont une généralisation des nombres complexes, peuvent contenir l’information
couleur complète. Les vecteurs couleur sont donc représentés par des quaternions purs (dont la partie
réelle est nulle) et sont manipulés au moyen d’opérations algébriques simples. Les quaternions ainsi que
leur généralisation, les algèbres géométriques, seront donc utilisés dans une démarche de caractérisa-
tion fréquentielle des images couleur numériques. Nous ne nous arrêterons cependant pas au domaine
des fréquences mais montrerons de plus, que ces formalismes permettent aussi de manipuler les cou-
leurs spatialement. Nous proposerons ainsi des gradients couleur déﬁnis dans le domaine spatial avec
des opérations géométriques sur les vecteurs couleur.
Ce mémoire est ainsi divisé en trois principaux chapitres qui analysent l’utilisation pouvant être faite
de trois représentations algébriques différentes pour effectuer des traitements d’images couleur.
Tout d’abord, dans le chapitre 2, nous étudierons l’opportunité d’utiliser les nombres complexes
aﬁn d’effectuer des traitements d’images. Après avoir donné un bref rappel des propriétés générales
concernant les nombres complexes, nous redonnerons la déﬁnition de la transformée de Fourier pour les
signaux bidimensionnels mais surtout les bases de l’analyse de ces signaux pouvant être déduite de cette
transformation.
La deuxième partie de ce chapitre posera la question de l’utilisation des nombres complexes pour
effectuer des traitements d’images couleur. Pour cela, nous introduirons différents espaces numériques
couleur aﬁn d’en identiﬁer un susceptible de convenir à la manipulation des couleurs par les nombres
complexes. L’un des points centraux de nos travaux est la déﬁnition d’une approche fréquentielle spéciﬁ-
quement dédiée à la couleur considérée dans sa globalité. C’est dans cet esprit que dans la dernière partie
du chapitre 2 nous étudierons les propriétés de variations numériques des couleurs pouvant être obtenues
en utilisant les composantes U et V de l’espace Y UV . Ces composantes associées à des initialisations
rudimentaires dans le domaine fréquentiel permettent de faire apparaître des « chemins couleur » élé-
mentaires déﬁnis initialement par McCabe dans le domaine spatial obtenu après une transformation de
Fourier « chromatique » inverse.
A partir des limites de cette approche, nous proposerons dans le chapitre 3 d’utiliser les quaternions
pour encoder la totalité de l’information couleur des images que les nombres complexes ne peuvent
pas contenir entièrement. On donnera tout d’abord les déﬁnitions et propriétés relatives aux quaternions

CHAP 1. INTRODUCTION
3
ainsi que différentes manières de les représenter. Ensuite, nous étudierons comment des opérations géo-
métriques, déﬁnies grâce à ce formalisme dans les espaces couleur, peuvent être utilisées pour effectuer
des traitements élémentaires spatiaux sur les images couleur. Nous déﬁnirons alors, à partir des travaux
de Sangwine, un nouveau détecteur de contours utilisant les opérations géométriques disponibles avec
les quaternions. Après avoir illustré les propriétés des quaternions dans la manipulation spatiale des
images couleur numériques, nous décrirons comment ils ont été utilisés dans la littérature pour l’étude
fréquentielle des images en niveaux de gris au travers des travaux de Sommer et al. ainsi que des images
couleur avec les travaux de Sangwine et al.. Nous apporterons ﬁnalement notre propre interprétation de
l’information fréquentielle obtenue par la transformée de Fourier quaternionique appliquée aux images
couleur. Cette interprétation est basée sur l’étude numérique des interactions entre le domaine spatial
et le domaine fréquentiel quaternionique. Nous constaterons qu’il existe notamment des propriétés de
symétrie à la fois sur le spectre et sur son signal d’origine dues à l’utilisation de cette transformée par-
ticulière. De plus nous verrons que la transformée de Fourier quaternionique est directionnelle et que
l’analyse du spectre obtenu par celle-ci dépend de cette direction.
Le dernier chapitre, qui peut être considéré comme une généralisation du chapitre 3, montrera l’ap-
port dans le traitement des images numériques couleur de l’encodage au moyen des algèbres géomé-
triques des pixels. Ces algèbres géométriques, aussi appelées algèbres de Clifford, seront d’abord étu-
diées de manière générale, comme cela est fait pour les nombres complexes ainsi que les quaternions, de
manière à se familiariser avec le vocabulaire et les concepts utilisés avec ce formalisme. Nous étudierons
alors comment elles ont été utilisées pour analyser les images en niveaux de gris. La suite consistera
à décrire l’opportunité d’utiliser l’algèbre G2 pour encoder les images couleur à travers une étude fré-
quentielle utilisant ce formalisme. Nous verrons qu’il est plus pertinent d’utiliser l’algèbre G3 dans le
domaine fréquentiel si l’on souhaite une analyse globale des couleurs en utilisant une transformée de
Fourier unique, ainsi que dans le domaine spatial. C’est d’ailleurs dans celui-ci que sera présentée une
approche de détection de contours basée sur la manipulation géométrique des couleurs dans l’espace.
Ainsi nous utiliserons comme base le gradient de saturation déﬁni dans le chapitre 3 et nous l’améliore-
rons en utilisant des caractéristiques géométriques obtenues par l’utilisation du produit géométrique.
La conclusion nous amènera alors à discuter des différentes perspectives issues de ce travail.


CHAPITRE 2
MODÉLISATION DES COULEURS PAR LES
NOMBRES COMPLEXES
Les nombres complexes sont utilisés de manière systématique à travers la déﬁnition de la transformée
de Fourier qui est un outil de base dans l’analyse et le traitement des images numériques. Une des
premières pistes que nous avons suivies au cours de cette thèse a consisté à chercher si l’utilisation de ce
formalisme pouvait être généralisé à l’étude des images couleur. C’est pour cela que ce premier chapitre
est consacré à l’évaluation du potentiel fourni par les nombres complexes pour l’analyse des données
contenues dans les images numériques couleur.
La première partie consistera à redécouvrir brièvement comment sont déﬁnis les nombres complexes.
Puis, la transformée de Fourier discrète à deux dimensions, qui permet de caractériser le contenu fréquen-
tiel des images numériques en niveaux de gris, sera présentée. Ensuite, aﬁn de pouvoir déﬁnir un outil
d’analyse des images couleur utilisant les complexes nous étudierons les caractéristiques numériques
d’un espace couleur approprié. Celui-ci sera enﬁn associé à la connaissance de l’analyse fréquentielle
dans la déﬁnition d’une transformée de Fourier complexe chromatique que nous étudierons en détail aﬁn
de savoir si elle permet d’analyser et/ou de traiter les images couleur de manière pertinente.
2.1
Les Complexes
On rappelle qu’un nombre complexe, noté z ∈C, est déﬁni de manière unique z = a + ib. a, b
sont des réels, tandis que i est le nombre imaginaire pur tel que i2 = −1. Dans ce chapitre, nous nous
servirons des notions classiques de parties réelle/imaginaire, conjugué, notation exponentielle, module,
argument, formes cartésienne/trigonométrique/exponentielle.
2.1.1
Plan complexe
2.1.1.1
Historique
Jean-Robert Argand, mathématicien amateur suisse, est le premier à proposer de représenter une
interprétation géométrique des nombres complexes comme points dans le plan en 1806 en faisant corres-
pondre au nombre a + ib le point de coordonnées (a, b) [1]. Ce n’est seulement que lorsque ces travaux
furent repris par Gauss et Cauchy que la communauté accepta cette nouvelle idée. Pour cela le plan
complexe est aussi bien nommé comme le plan d’Argand que celui de Cauchy.
5

6
CHAP 2 - MODÉLISATION DES COULEURS PAR LES NOMBRES COMPLEXES
Le plan muni du repère orthonormé direct (O, −→
e1, −→
e2) est appelé plan complexe. z = a + ib est
représenté par le point M = a−→
e1 + b−→
e2. On dit que M est l’image de z, ou encore que z est l’afﬁxe de
M, ou du vecteur −−→
OM.
De plus, la longueur OM vaut le module ρ de z, et une mesure de l’angle orienté
\
(−→
e1, −−→
OM) est
l’argument θ de z.
Les coordonnées du point M dans le repère cartésien sont donc (a, b) tandis qu’elles sont (ρ, θ) dans
le repère polaire comme nous l’illustrons dans la ﬁgure 2.1.
FIG. 2.1 – Le plan complexe
Après avoir déﬁni les nombres complexes de manière générale, nous allons maintenant les utiliser
dans le cadre du traitement des signaux et des images.
L’une des transformations les plus utilisées dans l’analyse des images numériques est la transformée
de Fourier, la section suivante permet de redécouvrir l’analyse de signaux bidimensionnels en utilisant
cette transformation. Celle-ci sera utilisée comme base de compréhension de l’information fréquentielle
lors de la généralisation de la transformée de Fourier aux signaux multi-spectraux que nous utiliserons
avec les images couleur.
2.2
Transformées de Fourier pour les signaux bi-dimensionnels
Les travaux de Joseph Fourier (1768-1830) ont permis de résoudre les équations de propagation de
la chaleur dans les corps solides [33]. La méthode utilisée démontre que toute fonction ﬁnie f ∈L2(R)
(autrement dit :
R
R |f(t)|2dt < +∞), peut se décomposer en une somme inﬁnie de fonctions en sinus
et en cosinus. Par ce moyen, la transformée de Fourier permet de décrire dans le domaine fréquentiel un
signal temporel par les fréquences de sinus et cosinus qui le constituent. On appelle cette représentation
du signal son spectre de fréquence.
Les signaux bi-dimensionnels sont des fonctions à deux dimensions, souvent notées x et y. On s’en
sert notamment pour décrire les images. En effet celles-ci sont des signaux à au moins deux dimensions
non plus temporelles comme dans le cas des signaux sonores 1D par exemple mais spatiales car permet-
tant de décrire des positions dans le plan. Les images informatiques sont une version discrète de signaux

2.2. Transformées de Fourier pour les signaux bi-dimensionnels
7
2D qui sont échantillonés puis quantiﬁés. Elles sont stockées par exemple dans un tableau ou une matrice
d’intensités. Généralement, pour chaque point d’une image en niveaux de gris, aussi appelé pixel1, on
quantiﬁe l’intensité lumineuse par un entier codé sur un octet, donc de valeur comprise entre 0 et 255.
On peut appliquer une transformée de Fourier sur une image en niveaux de gris aﬁn de connaître
l’équivalent en fréquence de l’information contenue dans l’image spatiale. On choisit alors souvent d’af-
ﬁcher le résultat d’une telle transformée de Fourier au moyen d’une autre image en niveaux de gris. On
afﬁche en fonction des besoins le module, la phase, la partie réelle ou la partie imaginaire de la matrice
complexe représentant le résultat de la transformation de Fourier de l’image d’origine.
Dans la suite de ce chapitre, nous déﬁnirons une transformée de Fourier chromatique appliquée aux
images couleur. Aﬁn de comprendre l’information spectrale obtenue par une transformée de Fourier
utilisant un signal non plus réel comme pour les images en niveaux de gris mais bien complexe, la
partie réelle et la partie imaginaire seront utilisées, nous allons cependant d’abord revoir brièvement les
principes de l’analyse de Fourier pour les signaux 2D.
2.2.1
Transformée de Fourier 2D discrète
La transformée de Fourier 2D est donc souvent employée dans le domaine des images. Elle permet
en effet de passer d’une représentation du domaine spatial dans le cadre des images (coordonnées (x, y))
à une représentation dans le domaine fréquentiel (coordonnées (u, v)).
La transformée discrète de Fourier d’une séquence 2D correspondant au signal discret f[x, y], déﬁni
sur Z2, s’exprime sous la forme :
F[u, v] =
∞
X
x=−∞
∞
X
y=−∞
f[x, y].e−2iπ(ux+vy)
(2.1)
En pratique, une image f[m, n] est un ensemble de points ﬁni et borné, avec m et n entiers et
0 ≤m ≤M −1 et 0 ≤n ≤N −1, par exemple. La transformée de Fourier discrète d’un signal 2D
échantillonné ou TFD2D est donc donnée par :
F[o, p] =
1
√
MN
M−1
X
m=0
N−1
X
n=0
f[m, n].e−2iπ( om
M + pn
N )
(2.2)
avec 0 ≤o ≤M −1 et 0 ≤p ≤N −1
Les deux variables o et p représentent les fréquences « spatiales » de l’image selon les directions
horizontales et verticales respectivement. Elles s’expriment en cycles ou en radians par unité de longueur,
alors que les fréquences « temporelles » qui sont utilisées pour des signaux temporels s’expriment en
cycles ou en radians par unité de temps.
On peut calculer la transformée de Fourier de deux façons différentes :
– Soit on calcule cette transformée directement à partir de la formule précédente ;
– Soit on effectue un calcul en deux temps. D’abord une transformée de Fourier 1D sur chaque
vecteur colonne de l’image, et ensuite une transformée de Fourier 1D sur chaque ligne obtenue
précédemment.
On calcule la transformée de Fourier discrète inverse 2D ou TFDI2D de la manière suivante :
f[m, n] =
1
√
MN
M−1
X
o=0
N−1
X
p=0
F[o, p].e2iπ( om
M + pn
N )
(2.3)
1Pour picture element, le plus petit élément de l’image.

8
CHAP 2 - MODÉLISATION DES COULEURS PAR LES NOMBRES COMPLEXES
2.2.2
Bases de l’interprétation des transformées de Fourier à deux dimensions
2.2.2.1
Transformée de Fourier 2D avec des images en niveaux de gris
Dans le plan spatial, pour représenter une image, chacun de ses pixels sera codé par un nombre entier
ou réel qui représente l’intensité lumineuse du pixel en niveau de gris par exemple. En revanche le spectre
est à valeurs complexes. De par cette nature complexe, ces pixels possèdent une amplitude et une phase,
on peut choisir de représenter soit l’une soit l’autre. En général, on choisit plutôt l’amplitude que l’on
afﬁche à travers le logarithme. Ce logarithme atténue les différences de module et permet ainsi d’obtenir
une meilleure lisibilité du spectre.
2.2.2.2
Analyse de signaux 2D en sinus et cosinus
La transformée de Fourier 2D d’une image représente le degré de ressemblance entre l’image et les
fonctions cosinus et sinus à différentes fréquences.
Dans la ﬁgure 2.2, la première image représente un cosinus horizontal de huit cycles et la deuxième
un cosinus vertical de 32 cycles. Chaque transformée de Fourier pour ces deux images est théoriquement
constituée de trois points :
– Le point central représente la moyenne de l’intensité de l’image d’origine. D’une façon générale,
dans une image, l’information basse fréquence (autour du point central de la TF) code globalement
les formes de l’image. Ces formes seront ﬂoues si l’on ne conserve que les basses fréquences. C’est
en rajoutant de l’information à plus haute fréquence que ces formes se distinguent par des contours
de plus en plus nets.
– Les deux autres points représentent la fréquence (horizontale à gauche ou verticale à droite) consti-
tuant les signaux. Il apparaît les deux pics en symétrie. Plus la fréquence d’oscillation des signaux
est importante et plus les pics caractérisant cette fréquence dans le spectre sont éloignés du point
central d’origine.
Cependant, il apparaît pour les deux images le phénomène de fenêtrage appelé généralement en
image « effets de bords ». Les effets de bords se manifestent dans les spectres de nos deux images par
de nombreux autres pics d’amplitude réduite sur la ligne horizontale à gauche ou verticale à droite. Ces
lignes correspondent au sinus cardinal.
FIG. 2.2 – Première ligne : Images en cosinus ; deuxième ligne : le module de leur transformée de Fourier
(les spectres sont inversés pour la lisibilité)

2.2. Transformées de Fourier pour les signaux bi-dimensionnels
9
2.2.2.3
Effets de bord
Nous pouvons interpréter géométriquement le phénomêne de bord ; en effet la transformée de Fourier
considère l’image traitée comme un élément de motif d’une image de taille inﬁnie contenant ce motif de
manière périodique. La ﬁgure 2.3 montre comment peut être considérée une image contenant un cosinus
oscillant sur la diagonale (du point bas-gauche au point haut-droit). La même image est donc dupliquée
autour de l’image d’origine et de manière périodique. La ﬁgure 2.3 ne présente que les juxtapositions à
l’est, au sud et au sud-est de l’image d’origine en haut à gauche. Il faut imaginer que cette juxtaposition
se fait dans toutes les directions et de manière inﬁnie. On remarque que sur la zone de passage d’une
image à sa voisine il apparait une rupture franche. Cette rupture est due au fait que la fenêtre ne coupe
pas notre cosinus sur un nombre de périodes complètes selon les directions horizontales x et verticales
y.
FIG. 2.3 – Périodicité englobante de la TF et apparition de zones de rupture
La ﬁgure 2.4 illustre ces effets de bords : ainsi pour chacune des images, on voit apparaître sur le
spectre un sinus cardinal suivant la direction perpendiculaire aux ruptures de l’image d’origine.
FIG. 2.4 – Effets de bord ; Première ligne : cosinus horizontal à gauche et diagonal à droite ; deuxième
ligne : les modules de leur TF(les spectres sont inversés pour la lisibilité).

10
CHAP 2 - MODÉLISATION DES COULEURS PAR LES NOMBRES COMPLEXES
Une manière de contourner ce problème est de « lisser » les bords de l’image pour atténuer les zones
de rupture. Pour lisser l’image, on multipliera celle-ci par une fenêtre de type gaussienne, par exemple,
qui conservera inchangée le centre de l’image, et atténuera les bords.
La ﬁgure 2.5 nous montre les différences obtenues à partir du même signal en cosinus diagonal. On
calcule trois transformées de Fourier de manière différente.
– en haut à droite le spectre de l’image d’origine sans modiﬁcation ;
– en haut à gauche le signal d’origine multiplié par une gaussienne pour lisser les ruptures sur les
bords de l’image ;
– en bas à gauche le spectre obtenu avec ce lissage gaussien ;
– en bas à droite le spectre idéal obtenu s’il n’y avait pas d’effets de bord.
On remarque que les effets de bords du spectre obtenu après lissage de l’image d’origine par une
gaussienne sont atténués. Cependant cette opération entraîne une imprécision dans le spectre. En effet,
alors que le spectre en bas à droite de la ﬁgure 2.5 permet de distinguer clairement la fréquence consti-
tuant notre cosinus diagonal, les pics de fréquences dans le module du spectre de l’image lissée sont
moins nets du fait du produit de convolution avec la gaussienne dans le domaine des fréquences.
FIG. 2.5 – Diminution des effets de bord (les spectres sont inversés pour la lisibilité).
2.2.2.4
Transformées de Fourier d’images naturelles
La transformée de Fourier2 de la ﬁgure 2.6 comporte les deux lignes horizontale et verticale passant
par l’origine dues aux effets de bords des images naturelles. Cela dit, il est difﬁcile d’interpréter plus
d’informations contenues dans le spectre d’énergie d’images complètes tant les détails fourmillent. Le
spectre de l’image du babouin présente cependant des pics d’intensité de manière symétrique dans les
coins. Ces pics d’amplitude se situent dans les hautes fréquences et pourraient donc correspondre par
exemple au pelage du babouin. En effet, ce pelage est caractérisé par de l’information de texture qui est
donc présente dans les hautes fréquences.
2.2.2.5
Notion de contours et de texture dans le domaine fréquentiel
La transformée de Fourier peut être un outil intéressant pour détecter certaines informations spa-
tiales contenues dans des images. Par exemple les contours qui représentent des ruptures franches seront
2On devrait plutôt dire le module de la transformée de Fourier mais comme l’afﬁchage d’une TF est le plus souvent une
image en niveaux de gris représentant le module, on emploie parfois la transformée de Fourier pour n’exprimer en fait que son
module

2.2. Transformées de Fourier pour les signaux bi-dimensionnels
11
FIG. 2.6 – TF d’une image naturelle : le babouin et son spectre avec en plus un zoom sur les fréquences
intéressantes.
traduits par de l’information dans les fréquences hautes du spectre de l’image. En effet localement au
niveau de cette rupture, le signal peut être vu comme la fonction porte dont la TF est un sinus cardinal.
Il va donc apparaître dans le spectre un sinus cardinal perpendiculaire à la rupture (fonction porte) du
domaine spatial (cf. ﬁgure 2.7). Bien que le spectre contienne des informations correspondant aux rup-
tures spatiales, il n’est cependant pas possible de déterminer une quelconque localisation géométrique
de ces ruptures car le spectre ne contient en effet que de l’information fréquentielle. Autrement dit, si
l’information spatiale de rupture est traduite dans les hautes fréquences du spectre de l’image, le module
du spectre ne fait apparaître que la perpendiculaire aux directions porteuses de toutes les accumulations
de ruptures qui suivent cette direction dans le domaine spatial.
La ﬁgure 2.7 permet aussi d’illustrer comment les informations de texture apparaissent au sein du
spectre. Une texture peut être par déﬁnition un motif qui se reproduit avec une certaine fréquence. Cette
fréquence sera donc logiquement visible dans le spectre correspondant à l’image texturée. On retrouve
donc dans le spectre du mur qui est zoomé des lignes horizontales et verticales qui correspondent à
la répétition de ruptures verticales et horizontales rencontrées. Il faut faire attention cependant car cer-
tains pics d’amplitude fréquentielle peuvent aussi être dus au sinus cardinal caractéristique des ruptures
franches. Finalement, on comprend qu’il n’est pas facile d’interpréter l’information du spectre d’une
image naturelle même texturée.
2.2.2.6
Filtres de fréquence
L’implication directe de l’analyse du spectre est la déﬁnition de ﬁltres avec des supports déﬁnis dans
le domaine fréquentiel. On peut ainsi se concentrer sur les fréquences que l’on souhaite conserver par
l’opération de ﬁltrage pour effectuer des tâches de traitement d’images.
Le ﬁltrage peut se caractériser par une « boite noire ». Cette boite possède une entrée e et une sortie s
dans le domaine spatial. Dans le domaine fréquentiel, le ﬁltrage correspond au produit du spectre d’entrée
E[o, p] à la fonction fréquentielle du ﬁltre H[o, p]. Ce produit fréquentiel correspond à un produit de
convolution dans le domaine spatial.
Pour un signal discret 2D, le ﬁltrage dans le domaine fréquentiel est exprimé de la façon suivante :
S[o, p] = E[o, p].H[o, p]
(2.4)

12
CHAP 2 - MODÉLISATION DES COULEURS PAR LES NOMBRES COMPLEXES
FIG. 2.7 – Deux images texturées (en haut) et leur spectre respectif (en bas).
Ce qui est équivalent à la relation suivante dans le domaine spatial :
s[m, n] = (e ∗h)[m, n] =
X
m0
X
n0
e[m −m0, n −n0]h[m0, n0]
(2.5)
La fonction h[m, n] est appelée « la réponse impulsionnelle » du ﬁltre 2D (ou « masque »).
Etudions donc maintenant quelques ﬁltres.
Passe-Bas
L’application d’un ﬁltre passe-bas sur une image permet de lisser les bruits et de conserver
les formes grossières de celle-ci. Cela revient également à multiplier son spectre par une fenêtre qui ne
laisse passer que les basses fréquences. La ﬁgure 2.8 illustre ce principe en montrant les différences entre
l’image originale à gauche et l’image ﬁltrée à droite en première ligne ainsi que leur spectres respectifs
en seconde ligne. Les contours des objets ou des formes représentant des ruptures d’intensités dans le
domaine spatial sont portés entre autre par les hautes fréquences de l’espace fréquentiel. En appliquant
un ﬁltrage passe-bas on atténue donc ces détails et l’image ﬁltrée devient plus ﬂoue comme l’image de
droite le montre. Notons que nous voyons apparaître des oscillations du fait du fenêtrage dans le domaine
fréquentiel.
Passe-Haut
L’opération duale s’appelle le ﬁltrage passe-haut. Il permet de faire ressortir les détails
de l’image ﬁltrée comme des contours ou des textures. La ﬁgure 2.9 illustre ce type de ﬁltrage avec de
gauche à droite l’image originale et l’image ﬁltrée en première ligne ainsi que leur spectre en seconde.
L’image de Lenna ﬁltrée est dépourvue de ses régions homogènes cependant les bords ou les éléments de

2.3. Espaces Couleur
13
FIG. 2.8 – Illustration d’un ﬁltrage passe-bas
texture, comme les plumes de son chapeau par exemple sont réhaussés conﬁrmant leur caractère « haute
fréquence ».
Enﬁn, il existe le ﬁltrage passe-bande, une solution intermédiaire qui permet de conserver l’informa-
tion sélectionnée dans le spectre d’une image sur une bande de fréquence choisie.
Tout comme nous l’avions fait avec des signaux 1-D, nous venons de voir qu’il est possible de
représenter des images de manière fréquentielle avec la transformée de Fourier. Les premiers traitements
numériques effectués sur les images une fois le spectre caractérisé sont les ﬁltrages en fréquences. Ainsi
il est possible de ne conserver que l’information d’une image sur la bande de fréquence de son choix.
Cependant, nous voulons rajouter à cette analyse spectrale la notion de couleur qui pour l’instant n’a
pas été abordée. En effet nous n’avons appliqué l’analyse de Fourier que sur des images en niveaux de
gris et souhaitons étendre la caractérisation spectrale aux données vectorielles caractérisant les images
couleur. Pour cela, nous devons avant tout étudier différents espaces couleur aﬁn d’en déterminer un qui
permettrait de déﬁnir une transformée de Fourier adaptée aux images numériques couleur.
2.3
Espaces Couleur
Aﬁn de pouvoir coder des images en couleur, nous avons besoin d’étudier au préalable comment on
exprime de manière générale la couleur numériquement. La couleur est une information que l’on peut
décrire avec au minimum trois composantes, elle est donc par nature vectorielle. On peut manipuler les

14
CHAP 2 - MODÉLISATION DES COULEURS PAR LES NOMBRES COMPLEXES
FIG. 2.9 – Illustration du ﬁltrage passe-haut
couleurs au moyen d’opérations vectorielles dans un espace en trois dimensions que l’on appelera espace
couleur. Les espaces couleur ont fait l’objet de nombreuses recherches et certains ont été normalisés par
la Commission Internationale de l’Éclairage (CIE). L’éclairage étant un élément important pour pouvoir
reconnaître des couleurs et les comparer, des standards d’éclairage ont aussi été mis au point par la CIE
[70].
Lors de cette étude, nous avons choisi d’étudier certains espaces couleur de façon numérique. Cette
démarche se distingue de la démarche adoptée par de nombreux auteurs qui se basent sur les espaces
couleur théoriques pour effectuer leur travaux. Ils utilisent pour effectuer leurs traitements d’images
couleur les conversions entre l’espace couleur matériel RGB et des espaces couleur déﬁnis de manière
théorique. Nous voulons également effectuer des opérations sur des images en utilisant différents espaces
couleur, cependant nous souhaitons comprendre comment s’opèrent les transitions numériques entre ces
différents espaces. Pour cela, nous avons fait une analyse en deux temps :
– présentation de différents espaces couleur tels qu’ils nous sont présentés habituellement ;
– étude numérique de deux d’entre eux à savoir RGB et Y UV .
2.3.1
Les espaces de primaires
2.3.1.1
Espace RV B ou RGB
Cet espace est l’espace le plus utilisé en traitement d’image. Il est constitué de trois composantes,
celles-ci codées en général sur huit bits. En fait, cet espace est celui utilisé par le matériel informatique
produisant ou afﬁchant des images. Les images utilisent les trois composantes suivantes : R pour rouge,

2.3. Espaces Couleur
15
V pour vert et enﬁn B pour bleu. Plusieurs déﬁnitions cohabitent pour l’espace RV B car l’expression des
primaires qui le composent n’est pas unique. Cependant on utilise plus souvent le standard CIE RGB
(cf. ﬁgure 2.10) (pour red, green et blue) déﬁni en 1931 par la CIE [15]. Les trois composantes primaires
monochromatiques de couleur rouge, verte et bleue sont chacune associée à une longueur d’onde :
– 700.0 nm pour le rouge ;
– 546.1nm pour le vert ;
– 435.8 nm pour le bleu.
FIG. 2.10 – Cube RGB
2.3.1.2
Espace XY Z
L’espace couleur RGB déﬁni par la CIE présente l’inconvénient de posséder une partie négative
dans le spectre des couleurs visibles (cf. ﬁgure 2.11). Autrement dit, il n’est pas possible de représenter
toutes les couleurs si on souhaite utiliser le principe de la synthèse additive qui n’utilise que des valeurs
positives. Pour combler ces inconvénients, la CIE a déﬁni un espace de représentation de la couleur basé
sur trois primaires non visibles X, Y et Z. Dans cet espace, chaque primaire est déﬁnie par une fonction
colorimétrique qui prend des valeurs de longueur d’onde positive (cf. ﬁgure 2.12). Notons que la fonction
Y (λ) représente approximativement la sensibilité de l’œil humain à la luminosité.
Le passage de l’espace RGB à l’espace XY Z s’effectue par une transformation linéaire dont les
coefﬁcients dépendent du blanc de référence choisi [69].
2.3.1.3
Espace CMY ou CMJ
L’espace CMY ou CMJ3 est l’espace dédié à l’impression des couleurs. L’encre imprimée absorbe
de la lumière et en renvoie moins que la feuille blanche, l’impression utilise donc le principe de la
synthèse soustractive. Cet espace couleur est donc représenté par un cube comme l’espace RGB mais
l’origine est le blanc au lieu du noir et les axes sont le cyan, le magenta et le jaune qui sont les trois
primaires de la synthèse soustractive. Le passage entre RGB et CMY est donné par :
3CMY en anglais pour cyan, magenta et yellow ou CMJ en français pour cyan, magenta jaune.

16
CHAP 2 - MODÉLISATION DES COULEURS PAR LES NOMBRES COMPLEXES
FIG. 2.11 – Les fonctions colorimétriques R(λ), G(λ) et B(λ) de l’espace RGB.
FIG. 2.12 – Les fonctions colorimétriques X(λ), Y (λ) et Z(λ) de l’espace XY Z.





C = 1 −R
M = 1 −G
Y = 1 −B
(2.6)
2.3.2
Les espaces dédiés à la télévision
Le passage de la diffusion des programmes en noir et blanc à la couleur sur les nouveaux postes entre
les années 1950 et 1960 a été possible grâce à la déﬁnition de standards de télévision. Ces standards
devaient permettre la diffusion en couleur sur les nouveaux postes mais aussi conserver la possibilité
d’afﬁcher des programmes diffusés en noir et blanc. Il fallait aussi assurer la compatibilité avec les
anciens modèles et pouvoir afﬁcher en noir et blanc des programmes diffusés en couleur. Pour cela
l’information de couleur diffusée par les chaînes de télévision sépare la luminosité et la chrominance.
On obtient l’information de luminosité directement à partir de la composante Y de l’espace XY Z et les

2.3. Espaces Couleur
17
deux autres parties de chrominances sont des combinaisons linéaires des composantes de l’espace RGB.
Différentes déﬁnitions cohabitent et distinguent les différents espaces couleur utilisés en télévision.
2.3.2.1
Espace Y IQ
L’espace Y IQ est celui déﬁni par le standard de télévision NTSC dans les années 1950, il utilise
une combinaison linéaire de l’espace RGB déﬁni lui aussi dans le standard NTSC (National Television
Standards Committee) et qui diffère de l’espace RGB déﬁni par la CIE dont nous avons parlé précé-
demment. Ce standard de télévision est destiné aux formats vidéo 525 lignes/60 Hz ; pour les DVD, la
résolution est de 480 lignes. Le NTSC est utilisé en Amérique du Nord, dans une partie de l’Amérique
du Sud (NTSC −M) et de l’Asie dont le Japon (NTSC −J).
La chrominance étant composée de deux informations élémentaires : U=R-Y (différence de rouge)
et V=B-Y (différence de bleu), il faut théoriquement deux porteuses pour véhiculer l’information. Pour
n’en utiliser qu’une seule, le signal est modulé en amplitude et en phase avec une seule porteuse.
2.3.2.2
Espace Y UV
L’espace Y UV est l’espace couleur déﬁni par le standard allemand PAL (Phase Alternation by
Line) en utilisant le blanc de référence D654. Les composantes de chrominances sont déﬁnies à partir de
combinaisons linéaires pondérées de R, G et B en fonction du blanc et de l’observateur de référence.
C’est un standard de la télévision européenne à 25 images secondes en 625 lignes (576 seulement sont
afﬁchées car 8% des lignes servent à la synchronisation). Il est utilisé principalement en Europe de
l’Est, mais également en Australie, et dans certaines régions d’Afrique et d’Amérique Latine. Même si
d’autres matrices de transposition peuvent être trouvées dans la littérature (les différences étant basées
sur les illuminants utilisés), la transformation utilisée pour passer de RGB à Y UV dans la suite de cette
étude est la suivante :


Y
U
V

=


0.472854
1.423527
−0.043981
−0.607735
−1.141775
0.75891
0.585846
−0.393292
0.044646

∗


R
G
B


(2.7)
2.3.2.3
Espace Y DrDb
L’espace Y DrDb est déﬁni par le standard de télévision SECAM (SEquentiel Couleur A Memoire).
Il est utilisé en France à partir de 1967, en Russie et dans des pays d’Afrique avec des normes spéciﬁques
supplémentaires. Ce format est aussi destiné aux formats vidéo 625 lignes mais cette fois pour un rafrai-
chissemnt de 50Hz. Le principe est basé là encore sur des modulations de phase et d’amplitude pour
pouvoir faire passer les trois composantes sur une seule porteuse.
2.3.2.4
Espace Y CrCb
L’espace Y CrCb est le standard international dédié au codage digital des images de la télévision
numérique. Il fait actuellement partie du nouveau standard de compression JPEG 2000. L’espace Y CrCb
est différent des autres standards de télévision car il n’impose aucune règle quant au blanc de référence.
Notons que la composante de luminosité est la même que dans les autres standards de télévision.
4Un illuminant est déﬁni par une répartition spectrale relative d’énergie, qui n’est pas nécessairement fournie directement
par une source de lumière ni obligatoirement réalisable à l’aide d’une source. Plusieurs illuminants ont été standardisés par la
CIE, ils sont souvent déﬁnis par une lettre allant de A à F. Les illuminants D correspondent par exemple à différentes lumières
du jour, alors que les F correspondent aux lumières émises par des lampes ﬂuorescentes. Le standard de télévision NTSC de
la section précédente est déﬁni pour un illuminant C correspondant à une lumière moenne du jour.

18
CHAP 2 - MODÉLISATION DES COULEURS PAR LES NOMBRES COMPLEXES
2.3.3
Les espaces perceptuels
Les espaces perceptuels tendent à correspondre à la perception humaine des couleurs. Une couleur
sera associée à une primaire (rouge, vert, bleu, etc.), un taux de blanc (clair, foncé, etc.) et la pureté
de la primaire (pastelle, délavée, etc.). Les espaces perceptuels reprennent ces descriptions en séparant
l’information de couleur en teinte, saturation et intensité (ou encore clarté).
2.3.3.1
Le modèle de Munsell
Ce modèle colorimétrique, qui a été redéﬁni par la société américaine d’optique (Optical Society
of America) en 1943, a été introduit initialement par Munsell en 1898. Ce modèle ressemble aux sys-
tèmes perceptuels utilisés de nos jours mais il possède des composantes beaucoup plus faiblement échan-
tillonnées. La teinte (hue) est divisée en dix valeurs qui correspondent aux teintes suivantes : rouge R,
jaune-rouge YR, jaune Y, jaune-vert GY, vert G, bleu-vert BG, bleu B, bleu-pourpre PB, pourpre P et
rouge-pourpre RP. Les abréviations précédentes sont données en anglais telles qu’elles ont été déﬁnies
par Munsell (cf. ﬁgure 2.13a). La ﬁgure 2.13b montre qu’un secteur peut être subdivisé en sous-sections
pour une meilleure précision. Dans ce cas, un numéro précédera le label donné à la section (3YR par
exemple).
FIG. 2.13 – Modèle colorimétrique de Munsell représentant les couleurs en teinte, saturation et clarté.
(a) représentation sous forme solide ; (b) représentation circulaire.
2.3.3.2
Le système de coordonnées triangulaires HSI ou TSI
Ce modèle est utilisé communément en traitement d’images couleur. Sa modélisation est issue de
la déformation du cube des couleurs RGB. A partir du cube RGB, on obtient l’axe achromatique des
intensités I en suivant l’axe qui relie le noir au blanc. Ensuite on obtiendra les composantes chromatiques
par une position sur un palier circulaire où la saturation S représente le rayon et la teinte T ou H (hue en
anglais) représente l’angle.
Les formules exprimant la transformation de l’espace RGB à l’espace HSI sont données par :

















H = arccos
 
0.5 × (R −G) + (R −B)
p
(R −G)2 + (R −B)(G −B)
!
S = 1 −3 × min(R, G, B)
R + G + B
I = R + G + B
3
(2.8)

2.3. Espaces Couleur
19
2.3.3.3
Le système de cône hexagonal HSV et HSL
Le système HSV , déﬁni par Travis, est équivalent au système HSI, il différe dans sa représentation
qui est donnée sous la forme d’un cône hexagonal. Deux modèles peuvent être distingués : le modèle de
cône hexagonal simple et le modèle hexagonal double (cf. ﬁgure 2.14). Ils représentent la couleur sous
forme d’un triplet : teinte H (Hue), Saturation S et clarté V (Value).
FIG. 2.14 – Le modèle hexagonal de Travis : (a) cône hexagonal simple HSV ; (b) cône hexagonal
double HSL.
2.3.4
Les espaces perceptuellement uniformes
Les espace que nous avons vu précédemment ne répondent pas aux deux critères qui permettent de
déﬁnir des espaces perceptuellement uniformes :
– la distance d(c1, c2) entre les deux couleurs c1 et c2 est correcte, si et seulement si, la valeur issue
de cette distance se rapproche de la différence perçue par l’œil humain ;
– la distance d(ci, c1) = n ∗d(ci, c2) est correcte, si et seulement si, l’œil humain perçoit la couleur
c1 n-fois plus éloignée de la couleur ci que la couleur c2.
Ici, la distance employée est la distance euclidienne. En 1976, la CIE a proposé deux espaces uni-
formes qui sont depuis reconnus et utilisés par la communauté comme standards. Ces deux espaces sont
le CIELab (ou L∗a∗b∗) et le CIELuv (ou L∗u∗v∗).
2.3.4.1
Espace CIELab
Cet espace s’obtient par des relations non linéaires à partir du système XY Z. Le blanc de référence
utilisé est caractérisé par les trois composantes trichromatiques (X0, Y0, Z0) prises dans l’espace XY Z.
Les trois composantes se comportent différemment. La composante L∗représente la clarté et les compo-
santes a∗et b∗représentent respectivement l’opposition de couleur vert-rouge et l’opposition de couleur
bleu-jaune.
On obtient la première composante L∗avec :
L∗=









116 ∗
 Y
Y0
 1
3
−16 si Y
Y0
> 0.008856
903.3 ∗Y
Y0
si Y
Y0
≤0.008856
(2.9)

20
CHAP 2 - MODÉLISATION DES COULEURS PAR LES NOMBRES COMPLEXES
On obtient ensuite les composantes chromatiques par :







a∗=500

f
 X
X0

−f
 Y
Y0

b∗=300

f
 Y
Y0

−f
 Z
Z0

(2.10)
avec :
f(x) =



x
1
3 si x > 0.008856
7.787x + 16
116 si x ≤0.008856
(2.11)
2.3.4.2
Espace CIELuv
La composante L∗représente encore la clarté qui est la même que dans l’espace L∗a∗b∗(cf. équa-
tion 2.9) ainsi que des composantes u∗et v∗qui représentent respectivement l’opposition de couleurs
vert-rouge et l’opposition de couleur bleu-jaune. Ces composantes chromatiques sont données par les
équations suivantes :
(
u∗=13L∗(u′ −u′
0)
v∗=13L∗(v′ −v′
0)
(2.12)
où les quantités u′, v′, u′
0, v′
0 sont calculées comme suit :























u′ =
4X
X + 15Y + 3Z
v′ =
9Y
X + 15Y + 3Z
u′
0 =
4X0
X0 + 15Y0 + 3Z0
v′
0 =
9Y0
X0 + 15Y0 + 3Z0
(2.13)
2.3.5
Les espaces couleur indépendants
Ces espaces reposent sur une décomposition des composantes couleur de manière à obtenir trois
composantes couleur décorrélées.
2.3.5.1
L’espace X1X2X3
Cet espace est obtenu à partir d’une analyse en composantes principales (ACP). Cette méthode ap-
pliquée aux composantes de l’espace RGB permet de décorréler les informations sur trois composantes
X1, X2 et X3 qui pourront donc être traitées indépendamment. La première valeur est celle qui possède
la plus grande quantité d’information et elle correspond à la clarté. Les deux autres composantes, né-
cessaires à la descrition complète de la couleur, apportent de l’information supplémentaire mais avec un
apport décroissant. On remarque cependant que cette décomposition de l’information couleur utilisant
l’analyse en composante principale sera dépendante de chaque image, en effet les couleurs deux images
différentes se décomposeront suivant des axes différents avec l’ACP.
2.3.5.2
L’espace d’Otha ou l’espace I1I2I3
Cet espace a été introduit par Otha [51] dans les années 80. Il est lui aussi basé sur la transformation
de Karhunen-Loeve (un autre nom pour la décomposition en composantes principales) aﬁn de déterminer

2.3. Espaces Couleur
21
les trois axes de plus grande variance de l’ensemble des couleurs. Ici I1 correspond à la composante
d’intensité et I2 et I3 représentent respectivement les oppositions bleu-rouge et magenta-vert. On obtient
les composantes de cet espace par une transformation linéaire à partir de l’espace RGB déﬁnie par les
formules suivantes :













I1 =R + G + B
3
I1 =R −B
2
I1 =2G −R −B
4
(2.14)
Maintenant que nous avons présenté différents espaces couleur connus et utilisés par la commu-
nauté, nous allons étudier numériquement l’un d’entre eux qui nous servira par la suite dans une étude
fréquentielle numérique utilisant les nombres complexes.
2.3.6
Étude numérique de l’espace Y UV
En traitement d’image, l’afﬁchage, le stockage des images est donc souvent codé dans l’espace RGB,
chaque composante étant stockée sur 8 bits variant ainsi entre 0 et 255. Nous avons une compréhension
globale physique de cet espace, car elle correspond à la sensation colorée qui arrive sur notre rétine et
qui est reçue par les trois familles de cônes L, M et S respectivement sensibles aux longueurs d’onde
proches du rouge, du vert et du bleu. Ce codage se comprend aussi intuitivement, ainsi, par exemple,
si on ﬁxe R = 0 et B = 0 on comprend qu’en faisant varier la dernière composante entre 0 et 255, la
couleur variera du vert sombre au vert clair. Ceci n’est pas vrai pour des espaces plus évolués comme
Y UV . Nous avons donc voulu faire apparaître les liens entre les variations numériques des coefﬁcients
et les variations physiques ou d’aspect (couleur). Pour cela, nous ﬁxons une ou plusieurs composantes
et nous étudions comment réagit la couleur (celle que l’on voit) face à une variation numérique de la
dernière composante.
Prenons l’espace Y UV , cet espace est déﬁni sur un domaine de déﬁnition qui est différent de celui de
l’espace RV B. Ce que nous cherchons à comprendre c’est comment se déplacent les points numériques
aux couleurs extrèmes des espaces qui leur sont associés. En effet, au cours du changement d’espace,
la manipulation numérique va déplacer géométriquement des points de l’espace couleur d’origine pour
qu’ils puissent être déﬁnis dans l’espace couleur d’arrivée. En effectuant un changement d’espace à partir
de RV B dont chacune des composantes est codée sur huit bits, nous obtenons les bornes suivantes pour
l’espace Y UV :
Ymin ∼−11
Ymax ∼483
Umin ∼−446
Umax ∼193
Vmin ∼−100
Vmax ∼160
(2.15)
Comme la déﬁnition de l’espace Y UV nous indique que la composante Y est une information d’in-
tensité uniquement (ainsi que les autres espaces contenant cette composante), nous avons écarté Y et
nous avons caractérisé de manière numérique la chromaticité avec les composantes U et V .
La ﬁgure 2.15 représente le cube de couleur RGB en fonction des valeurs de Y , de U et de V . En
analysant cette ﬁgure, on remarque qu’il existe des valeurs de U et V dans leur intervalle de déﬁni-
tion pour lesquelles les couleurs RGB correspondantes ne sont pas déﬁnies (par exemple le (U, V ) =
(−400, −80) et ceux quelquesoit Y . Il existe donc des valeurs de U et de V telles que U ∈[−447; 194]
et V ∈[−101; 161] où la transposition en RGB ne sera pas « cohérente5 ».
La ﬁgure 2.15 nous indique que si l’on fait varier par exemple U entre 0 et 100 avec un V ﬁxé à 30
et Y quelconque (puisque qu’il ne contient pas d’information de chrominance), nous devons obtenir une
variation de couleur dont la teinte sera bleue. Nos expérimentations nous ont montré que les couleurs
5une couleur sera dire « cohérente » lorsque la conversion de sa représentation de Y UV vers RGB sera un triplet inclus
dans [0 ; 255]3

22
CHAP 2 - MODÉLISATION DES COULEURS PAR LES NOMBRES COMPLEXES
(a)
(b)
(c)
FIG. 2.15 – (a) et (b) Les couleurs du cube RGB en fonction de Y , U et V ; (c) projection sur un plan
UV
obtenues ne sont pas forcément celles attendues. La ﬁgure 2.16 illustre des variations couleur obtenues
en ﬁxant une valeur pour V et en faisant varier la composante U (les variations de U sont faites en suivant
la direction verticales des images). On remarque que ces variations de couleur diffèrent en fonction de
la composante Y . De plus, il apparaît des sauts de couleurs dans deux des imagettes qui sont liés au fait
que la correspondance entre l’espace Y UV et l’espace numérique RGB n’est pas maintenue au cours
des variations de U sur ces deux exemples.
Aﬁn de montrer que la composante Y correspondant à la clarté joue un rôle dans la perception
colorée, nous avons donc réétudié l’espace Y UV , en effectuant des variations de couleur en modiﬁant
uniquement les composantes de chromaticité, la composante Y restant ﬁxe.
En réitérant cette méthode pour différents Y choisis entre les bornes de son ensemble de déﬁnition,
c’est à dire entre −11 et 483, on obtient la correspondance entre les couleurs RGB et les composantes

2.4. Analyse spatio-chromatique d’images couleur
23
Y= -10
Y= 15
Y= 150
Y= 450
FIG. 2.16 – Dans toutes les imagettes de cette ﬁgure on a la même variation de U entre 0 et 100 et V ﬁxé
à 30, cependant les variations couleur sont différentes en fonction d’Y .
U et V pour chaque Y donné. Les ﬁgures 2.17 à 2.18 illustrent cette correspondance avec différentes
valeurs de Y .
On remarque ﬁnalement que suivant Y , toutes les couleurs de l’espace numérique RGB ne sont pas
déﬁnies sur le plan UV . Les ﬁgures 2.17 à 2.18 illustrent donc que les couleurs numériques de RGB
dépendent de la composante Y . En effet les bleus sont déﬁnis plutôt sur Y = [0 ; 150], les rouges sur
Y = [100 ; 200], les verts sur Y = [200 ; 350] et enﬁn les jaunes sur Y = [350 ; 460].
L’analyse numérique de l’espace Y UV nous a permis de conﬁrmer que la composante Y qui est une
combinaison linéaire des composantes R, G, et que B n’est donc bien pas uniquement de l’information
d’intensité mais elle contribue également à la formation et à la perception colorée. Ceci montre que la
déﬁnition théorique n’est pas vériﬁée en pratique.
2.4
Analyse spatio-chromatique d’images couleur
Les variations de couleur dans l’espace Y UV étant acquises, nous allons pouvoir nous en servir dans
cette section pour traiter l’analyse spatio-chromatique d’images couleur. En effet, ici sera décrit com-
ment des variations géométriques de couleur peuvent être détectées dans le plan fréquentiel couleur UV .
Pour cela, nous effectuons l’analyse fréquentielle numérique d’un espace couleur proposé initialement
par McCabe et al. [48] pour décrire les contrastes de couleur. Dans cette analyse, le formalisme des com-
plexes est utilisé pour déﬁnir un espace fréquentiel couleur. L’analyse de l’information fréquentielle sera
faite en utilisant une notion de chemin couleur. On pourra ensuite utiliser l’information de l’espace de
Fourier couleur pour décrire les images couleur.

24
CHAP 2 - MODÉLISATION DES COULEURS PAR LES NOMBRES COMPLEXES
v
u
Y variable
Y= -10
Y= 0
Y= 50
Y= 100
Y= 150
FIG. 2.17 – Les couleurs en fonction de U et V avec différents Y .
2.4.1
La transformation de Fourier spatio-chromatique
L’utilisation de la transformée de Fourier dans l’analyse d’image n’est pas nouvelle comme nous
l’avons vu dans la partie sur les transformées de Fourier. Pour les images couleur, la transformation doit
être appliquée sur une image composée d’un ensemble de pixels à valeurs vectorielles. Il est proposé de
se placer dans un espace couleur qui idéalement sera indépendant de l’intensité aﬁn de pouvoir effectuer
des opérations uniquement sur les composantes chromatiques de l’image. Une représentation en nombres
complexes est utilisée : la partie réelle étant allouée pour représenter l’une des composantes chromatiques
pour chaque pixel, la composante imaginaire représentant l’autre.

2.4. Analyse spatio-chromatique d’images couleur
25
Y= 200
Y= 250
Y= 300
Y= 350
Y= 400
Y= 440
FIG. 2.18 – Les couleurs en fonction de U et V avec différents Y (suite).
Théoriquement l’espace couleur Y UV peut représenter un tel espace et c’est pour cela qu’il a été
choisi pour les expérimentations de McCabe et Caelli [48]. En chaque pixel de l’image, nous déﬁnissons
un nombre complexe codant l’information couleur suivant :
u[m, n] + iv[m, n]
(2.16)
Le couple (m, n) correspond aux coordonnées spatiales de l’image d’où u[m, n] et v[m, n] sont les
deux composantes chromatiques de l’image au point de coordonnées (m, n) (avec le pixel de coordon-
nées (0, 0) dans le coin haut gauche de l’image).

26
CHAP 2 - MODÉLISATION DES COULEURS PAR LES NOMBRES COMPLEXES
La transformation de Fourier chromatique est déﬁnie pour les composantes u et v6 des pixels d’une
image obtenue à partir d’une conversion de l’espace RGB vers Y UV . Nous obtenons pour chaque pixel
ses composantes fréquentielles complexes chromatiques U et V avec la déﬁnition de la transformée de
Fourier suivante :
U[o, p] + iV [o, p] = 1
N
N−1
X
m=0
N−1
X
n=0
(u[m, n] + iv[m, n])e
−2iπ(mo+np)
N
(2.17)
On suppose ici que l’image est de taille N × N. Le couple (o, p) correspond aux coordonnées fré-
quentielles de la transformée de Fourier de l’image, ces coordonnées sont mesurées en cycles par pixel.
Les valeurs U et V au point de coordonnées (o, p) déterminent l’intensité fréquentielle qui décrit com-
ment la couleur change spatialement dans l’image.
Puisque les données de départ sont complexes, notons qu’à la suite de la transformée de Fourier, la
symétrie hermitienne disparaît, c’est-à-dire que des fréquences opposées, comme par exemple U[o0, p0]
et U[−o0, −p0] (resp. V [o0, p0] et V [−o0, −p0]), peuvent avoir des amplitudes complètement différentes
(avec o0 et p0 entre 0 et N
2 et en supposant le centre du repère au centre de l’image) (cf. ﬁgure 2.19).
FIG. 2.19 – Représentation du plan complexe fréquentiel couleur
Nous proposons dans la suite de cette partie d’essayer de donner une signiﬁcation à l’information
fréquentielle obtenue par cette transformée de Fourier chromatique comme nous l’avions fait avec les
images en niveaux de gris.
2.4.1.1
Notion de chemin couleur
Une interprétation de l’espace fréquentiel obtenu à partir de la transformée de Fourier complexe
contenant les composantes chromatiques u et v est proposée par McCabe et all. [48] en utilisant la notion
de chemin couleur (cf. ﬁgure 2.20). Nous proposons tout d’abord d’illustrer cette notion de chemin à
partir de deux images élémentaires présentant une seule valeur non nulle dans le domaine fréquentiel.
6Notation : on choisira dans cette partie de représenter les composantes couleur spatiales d’un pixel en minuscule tandis que
les majuscules seront utilisées pour le domaine fréquentiel.

2.4. Analyse spatio-chromatique d’images couleur
27
Image 1 :|U[o, p] + iV [o, p]|
=
k pour (o, p) = (o0, p0)
=
0 sinon
Image 2 :|U[o, p] + iV [o, p]|
=
k pour (o, p) = (−o0, −p0)
=
0 sinon
avec k ∈R une constante.
La transformation de Fourier chromatique inverse de cette matrice s’exprime par :
u[m, n] + iv[m, n] = 1
N
N−1
X
o=0
N−1
X
p=0
(U[o, p] + iV [o, p])e(2iπ om+pn
N
)
(2.18)
Après TF inverse, le résultat de telles initialisations dans le domaine des fréquences est une matrice
complexe décrivant les composantes u et v de l’image dans le domaine spatial. Cette matrice est ensuite
associée à une composante de clarté ﬁxe pour donner une image couleur. Cette image couleur décrit une
variation spatiale de couleurs correspondant à l’initialisation effectuée dans le domaine spectral (l’ini-
tialisation sera effectuée aux coordonnées de fréquence (o0, p0) déterminant le nombre d’oscillations du
signal dans le domaine spatial : plus ces paramètres o0 et p0 seront élevés, plus il y aura d’oscillations).
Chaque variation de couleur balaye ce qui est appelé un « chemin » circulaire à travers l’espace des cou-
leurs [48]. Ces chemins couleur sont déﬁnis par deux paramètres d’initialisation qui sont les suivants :
– θ qui est « l’angle couleur » de départ ;
– m qui est le rayon de balayage du chemin représentant l’amplitude de la variation de couleur.
Ces deux paramètres sont déﬁnis à partir des valeurs des coefﬁcients fréquentiels initiaux U[o0, p0],
U[−o0, −p0], V [o0, p0] et V [−o0, −p0] de la transformée de Fourier complexe par :
θ
= tan−1 
V [o0,p0]
U[o0,p0]

(2.19)
m
=
p
U[o0, p0]2 + V [o0, p0]2
(2.20)
L’initialisation de ces paramètres déﬁnit le sens de balayage de la couleur. Le sens trigonométrique
est caractérisé par une initialisation aux coordonnées (o0, p0) et le sens anti-trigonométrique aux coor-
données (−o0, −p0).
Nous proposons d’illustrer cette notion de chemin couleur en effectuant une initialisation dans le do-
maine des fréquences. Nous souhaitons initialiser des valeurs U et V aux points (o0, p0) et/ou (−o0, −p0)
du plan complexe spectral chromatique et ensuite par une transformée de Fourier inverse retrouver à quoi
correspondent ces initialisations dans l’image résultat. Nous devrions ainsi retrouver des variations de
couleur ayant des caractéristiques semblables aux chemins de couleurs décrits par McCabe et all.
Supposons donc que l’on crée une matrice complexe de dimension N × N et que l’on initialise les
points (o0, p0) et (−o0, −p0) à une certaine valeur.
On fera attention aux changements de repère : en effet lorsque l’on voit des coordonnées opposées
comme (o, p) et (−o, −p), celles-ci sont exprimées dans un repère où le centre de l’image représente le
point de coordonnées (0, 0) correspondant à sa moyenne. Cependant la déﬁnition donnée par l’équation
(2.18) de l’inverse de la transformée de Fourier ne travaillant que sur des fréquences positives, il est
préférable d’utiliser la version de la TF dans laquelle les coordonnées sont centrées :
u[m, n] + iv[m, n] = 1
N
N
2
X
o=−N
2 +1
N
2
X
p= N
2 +1
(U[o, p] + iV [o, p])e(2iπ om+pn
N
)
(2.21)
A partir de cette déﬁnition, on peut développer le calcul :

28
CHAP 2 - MODÉLISATION DES COULEURS PAR LES NOMBRES COMPLEXES
u[m, n] + iv[m, n] = 1
N
N
2
X
o=−N
2 +1
N
2
X
p= N
2 +1
(U[o, p] + iV [o, p])
×

cos

2πom + pn
N

+ i sin

2πom + pn
N

= 1
N
N
2
X
o=−N
2 +1
N
2
X
p= N
2 +1

U[o, p] cos

2πom + pn
N

+ iU[o, p] sin

2πom + pn
N

+

iV [o, p] cos

2πom + pn
N

−V [o, p] sin

2πom + pn
N

= 1
N
N
2
X
o=−N
2 +1
N
2
X
p= N
2 +1

U[o, p] cos

2πom + pn
N

−V [o, p] sin

2πom + pn
N

+

iU[o, p] sin

2πom + pn
N

+ V [o, p] cos

2πom + pn
N

d’où :
u[m, n] = 1
N
N
2
X
o=−N
2 +1
N
2
X
p= N
2 +1

U[o, p] cos

2πom + pn
N

−V [o, p] sin

2πom + pn
N

(2.22)
v[m, n] = 1
N
N
2
X
o=−N
2 +1
N
2
X
p= N
2 +1

U[o, p] sin

2πom + pn
N

+ V [o, p] cos

2πom + pn
N

(2.23)
La partie réelle (resp. imaginaire) obtenue après transformée de Fourier inverse est donc composée
d’un cosinus (resp. sinus) associé à l’axe U et d’un sinus (resp. cosinus) associé à V .
Il est maintenant possible de décrire les différents cas de variation de couleur obtenus à partir d’ini-
tialisations dans le domaine fréquentiel.
Chemins couleur de même base fréquentielle
Dans ce paragraphe, la notion de chemins couleur est
illustrée par la juxtaposition des schémas qui leur sont associés et leur résultat en terme de variation
couleur dans le domaine spatial. Tous les exemples seront donnés avec le même couple de coordonnées
fréquentielle (o0, p0) et son équivalent dans les fréquences négatives (−o0, −p0). De plus, on notera par
un quadruplet toute combinaison de (U[o0, p0], V [o0, p0], U[−o0, −p0], V [−o0, −p0]) pour simpliﬁer
l’écriture.
Un premier exemple est donné avec la ﬁgure 2.20. La première ligne illustre dans des plans com-
plexes les chemins couleur en fonction de leurs paramètres θ et m déﬁnis à l’équation (2.20). θ repré-
sente l’angle initial dans l’espace chromatique UV du chemin couleur alors que m est son amplitude.
Ici sont représentés deux chemins couleur c1 et c2, qui additionnés ensembles, permettent d’obtenir un
troisième chemin c3. On remarque que les deux chemins c1 et c2 ont le même angle θ = 0 et la même
amplitude m = k. La particularité du troisième chemin est qu’il correspond en terme spatial à une va-
riation de couleur qui suit l’axe u des réels, ce troisième chemin possède lui aussi les mêmes angles et
amplitudes. La seconde ligne illustre les résultats obtenus après une transformée inverse. Ces images
sont donc concrètement l’illustration spatiale des chemins couleur.

2.4. Analyse spatio-chromatique d’images couleur
29
chemin c1
chemin c2
chemin c3
Sens anti-trigonométrique
Sens trigonométrique
Somme des deux chemins
initialisation avec (k, 0, 0, 0)
initialisation avec (0, 0, k, 0)
initialisation avec (k, 0, k, 0)
FIG. 2.20 – Le chemin couleur c3 est obtenu à partir de la somme des chemins couleur c1 et c2, il est
décrit uniquement sur l’axe des réels.
Pour obtenir de telles variations de couleur, on initialise les composantes fréquentielles comme suit
avec les quadruplets (k, 0, 0, 0) pour les coordonnées positives (chemin c1) et (0, 0, k, 0) pour coordon-
nées négatives (chemin c2), on obtient donc le chemin c3 en utilisant le quadruplet (k, 0, k, 0) avec k ∈R
pour l’initialisation fréquentielle. En utilisant la déﬁnition des paramètres de l’équation (2.20), on obtient
θ = 0 et m = k pour les deux chemins c1 et c2.
Avec les résultats précédents, en se rappellant que ∀x ∈R cos(−x) = cos(x) et sin(−x) =
−sin(x), on obtient en passant par une transformée de Fourier inverse :
u[m, n] + iv[m, n] = 1
N

k cos

2πo0m + p0n
N

−0

+ i 1
N

k sin

2πo0m + p0n
N

+ 0

+ 1
N

k cos

2πo0p + m0n
N

+ 0

−i 1
N

k sin

2πo0m + p0n
N

+ 0

= 2k cos
 2π o0m+p0n
N

N
Ce résultat est décrit par un signal cosinusoïdal sur R car il ne comporte pas de partie imaginaire
et suit donc uniquement l’axe u. Ce résultat calculatoire est en adéquation avec la notion de chemins
couleur proposée par McCabe qui concluait qu’avec une initialisation dans le domaine complexe des
valeurs U[o0, p0] et U[−o0, −p0] à une valeur k ∈R et en gardant les valeurs V nulles, on obtenait,
après transformée de Fourier inverse, une variation de couleur suivant l’axe des réels dans le domaine

30
CHAP 2 - MODÉLISATION DES COULEURS PAR LES NOMBRES COMPLEXES
spatial, ce qui correspond à une variation entre le bleu et le jaune. On peut aussi interpréter l’information
spectrale associée à ce chemin couleur. En effet, comme le signal obtenu est de type cosinusoïdal, on
peut dire que le chemin couleur c3 correspond à des variations spatiales paires sur l’axe u, autrement dit
les oppositions de couleur entre le bleu et le jaune.
De la même façon, une variation de couleur qui suit l’axe des imaginaires est possible en initialisant
le spectre par le quadruplet (0, k, 0, k) qui est la somme des deux chemins c4 et c5 d’angle θ = π
2 et
d’amplitude m = k caractérisés par les quadruplets (0, k, 0, 0) et (0, 0, 0, k) illustrés à la ﬁgure 2.21.
Chacun d’entres eux apportant un signal de type cosinus le résultat ﬁnal décrivant le chemin couleur c6
vaut :
u[m, n] + iv[m, n] = 2k cos
 2π o0m+p0n
N

N
i
(2.24)
Cette fois ci, le chemin couleur est associé aux variations spatiales sur l’axe v autrement dit les
oppositions de couleur entre le rouge et le vert.
chemin c4
chemin c5
chemin c6
Sens anti-trigonométrique
Sens trigonométrique
Somme des deux chemins
initialisation avec (0, k, 0, 0)
initialisation avec (0, 0, 0, k)
initialisation avec (0, k, 0, k)
FIG. 2.21 – Le chemin couleur c5 est obtenu à partir de la somme des chemins couleur c4 et c5, il est
décrit uniquement sur l’axe des imaginaires.
De même que les quadruplets (k, 0, 0, 0) et (0, 0, k, 0) (resp. (0, k, 0, 0) et (0, 0, 0, k)) s’ajoutent pour
former le quadruplet et (k, 0, k, 0) (resp. (0, k, 0, k)), on peut effectuer d’autres combinaisons :
– somme des quadruplets (k, 0, 0, 0) et (0, k, 0, 0) : on obtient un chemin couleur correspondant au
quadruplet (k, k, 0, 0) dont l’angle vaut θ = π
4 et l’amplitude vaut m = k2. C’est le chemin c7
illustré à gauche dans la ﬁgure 2.22.
– somme des quadruplets (0, 0, k, 0) et (0, 0, 0, k) : on obtient un chemin couleur correspondant au
quadruplet (0, 0, k, k) dont l’angle et l’amplitude sont les mêmes que l’exemple précédent. C’est
le chemin c8 correspondant au schéma du milieu de la ﬁgure 2.22.
– le chemin c9 à droite de la ﬁgure 2.22 correspond quand à lui à la somme des deux précédents et
on peut donc lui associer le quadruplet (k, k, k, k).

2.4. Analyse spatio-chromatique d’images couleur
31
chemin c7
chemin c8
chemin c9
Sens anti-trigonométrique
Sens trigonométrique
Somme des deux chemins
initialisation avec (k, k, 0, 0)
initialisation avec (0, 0, k, k)
initialisation avec (k, k, k, k)
FIG. 2.22 – Le chemin couleur c9 est obtenu à partir de la somme des chemins couleur c7 et c8.
On remarque que même si la variation de couleur obtenue ne suit pas l’axe des réels ou celui des
imaginaires, les changements de couleurs perçus se retrouvent entre le magenta et le vert, ce qui est
complémentaire aux deux autres variations de couleurs étudiées précédemment.
Chemins couleur moins réguliers.
Il est également possible de faire des combinaisons linéraires des
chemins couleur de base que nous venons de citer, comme illustré à la ﬁgure 2.23. Par exemple, si on
souhaite additionner les deux chemins représentés par les quadruplets (0, 0, k1, 0) et (0, k2, 0, 0). Le
premier, c10, à gauche dans le sens trigonométrique, possède un angle θ1 nul et une amplitude m1 = k1.
Le second, c11, au milieu possède un angle et une amplitude différents car θ2 =
π
2 et m2 = k2. Le
résultat de cette somme est le chemin elliptique c12 illustré à droite. La forme de l’ellipse est déﬁnie par
les amplitudes m1 et m2 et l’orientation de la couleur par les angles θ1 et θ2. Le chemin c12 est différent
de c10 même si cela n’est pas perceptuellement très visible sur la ﬁgure.
On peut aussi décrire le chemin couleur c12 par le calcul, il sera caractérisé par l’équation suivante :
u[m, n] + iv[m, n] = (k1 + k2) cos
 2π o0m+p0n
N

+ i(k2 −k1) sin
 2π o0m+p0n
N

N
Ici l’information entre la partie sinus et la partie cosinus est mélangée, en effet la variation de couleur
correspondant au chemin couleur ne sera pas facile à identiﬁer. Cette variation sera le résultat d’une pon-
dération de chemins couleur élémentaires en fonction de l’amplitude qui leur est attachée. La variation
de couleur obtenue ajoutera les participations de chacun de ces chemins élémentaires couleur pondérés
avec la synthèse additive.
Nous avons vu qu’il est possible de décrire l’information spectrale obtenue par la transformée de
Fourier déﬁnie dans équation (2.18) au moyen de la notion de chemin couleur. Plusieurs chemins élé-
mentaires sont déﬁnis en utilisant les différents quadruplets d’initialisation du spectre couleur par des
constantes. Chaque chemin couleur correspond à un point d’initialisation des composantes U et V dans
le spectre. Il apparaît donc possible d’analyser des images couleur au moyen de l’information spectrale

32
CHAP 2 - MODÉLISATION DES COULEURS PAR LES NOMBRES COMPLEXES
chemin c10
chemin c11
chemin c12
Sens anti-trigonométrique
Sens trigonométrique
Somme des deux chemins
initialisation avec (0, 0, k1, 0)
initialisation avec (0, 0, 0, k2)
initialisation avec (0, 0, k1, k2)
FIG. 2.23 – Le chemin couleur c12 est obtenu à partir de la somme des chemins couleur c10 et c11. Ici
même si les couples de coordonnées (o0, p0) et (−o0, −p0) restent inchangés, les deux chemins c10 et
c11 ont des amplitudes (m1 et m2) et des phases (θ1 et θ2) différentes.
obtenue à partir de cette lecture de transformée de Fourier. Cependant les variations passent par de nom-
breuses couleurs en parcourant chaque chemin, il peut alors paraître difﬁcile d’isoler une couleur plutôt
qu’une autre avec l’analyse obtenue. Pour réussir, il faudra décomposer le spectre aﬁn d’obtenir tous
les chemins couleurs élémentaires utilisés pour obtenir telle ou telle variation. Les chemins c3 et c6 per-
mettent par contre de mettre en évidence les oppositions de couleur entre bleu - jaune et rouge - vert
respectivement. Nous sommes plus habitués à analyser des couleurs avec ce type d’opposition car d’une
part le système visuel humain est plus sensible aux notions de contraste qu’aux couleurs elles-mêmes et
d’autre part, ce codage antagoniste est celui réalisé pour la transmission des informations de la rétine au
cortex visuel, via le nerf optique. L’analyse couleur en utilisant cette transformée de Fourier sera donc
basée sur des oppositions de couleurs caractéristiques des chemins élémentaires adaptés au système vi-
suel humain car basé sur les contrastes de couleur (oppositions). Cependant cette représentation reste
difﬁcile à utiliser dans la pratique.
2.4.1.2
Variation spatiale
L’initialisation d’une ou plusieurs constantes dans le domaine spectral agit également sur la fréquence
du signal 2D obtenue après transformée de Fourier inverse. Plus le point initialisé dans le spectre se
trouvera éloigné du point central correspondant à la fréquence nulle, plus le signal 2D obtenu contiendra
de périodes complètes décrites dans la même image.
Ainsi, par exemple, lorsque que l’on souhaite obtenir un signal horizontal contenant une période
complète, il sufﬁt d’initialiser le point de coordonnées fréquentielles (1, 0). Pour avoir deux périodes,
ce sera le point de coordonnées (2, 0) (un autre point d’initialisation est possible : (−2, 0) la différence
n’étant que dans le chemin couleur parcouru et non sur le nombre de périodes du signal obtenu). La

2.4. Analyse spatio-chromatique d’images couleur
33
ﬁgure 2.24 illustre différents signaux obtenus en changeant uniquement les coordonnées d’initialisation
fréquentielle pour faire varier la période du signal 2D obtenu après transformée de Fourier inverse.
(a)
(b)
(c)
(d)
FIG. 2.24 – Variation du nombre d’oscillations horizontales des signaux 2D de couleur ; initialisations
aux points de coordonnées (a) (1, 0), (b) (2, 0), (c) (−2, 0), (d) (4, 0).
Il est également possible d’inﬂuer sur l’orientation du signal 2D obtenu après transformée de Fourier
inverse. En effet, comme le domaine fréquentiel permet de représenter les différentes fréquences de
signaux 2D (en sinus et cosinus) qui apparaissent dans l’image, si on modiﬁe les coordonnées de la ou
les constantes d’initialisation, on modiﬁe l’axe porteur du signal 2D résultant dans le domaine spatial.
La ﬁgure 2.25 illustre ainsi différents signaux 2D obtenus en modiﬁant leur axe porteur dans le domaine
spectral.
Les parties fréquentielles ont été initialisées aux points de coordonnées suivants :
– (a) (4, 4) et (−4, −4)
– (b) (−4, 4) et (4, −4)
– (c) (−2, 3) et (2, −3)
– (d) (0, 4) et (0, −4)
– (e) (2, 0) et (−2, 0)
On peut donc repérer des variations géométriques sur des images couleur en analysant leur spectre.
En utilisant l’information fréquentielle associée au chemin couleur qui met en opposition le bleu et le
jaune par exemple, on pourrait repérer les structures spatiales de l’image associée à ce type de chemin,
autrement dit, les contours qui séparent une zone bleue d’une autre zone jaune au niveau du contour.
Toutefois, nous avons vu que les seules informations de chrominance de l’espace Y UV ne sufﬁsent
pas à décrire convenablement les couleurs. Cependant, il est tout de même possible de mettre les couleurs
en relation notamment par l’intermédiaire de chemins couleur qui les opposent ou les juxtaposent. Il
existe une multitude de chemins couleur et il y en aura forcément un qui contiendra les deux couleurs.
Ces deux couleurs seront alors soit en opposition dans le chemin soit proches l’une de l’autre. Nous avons
voulu illustrer quel type d’information nous pouvons extraire de la transformée de Fourier chromatique.
Pour cela nous proposons de visualiser le module du spectre UV obtenu à partir d’images naturelles
ainsi que d’appliquer à des images couleur un ﬁltrage fréquentiel basé sur cette transformée de Fourier
chromatique.

34
CHAP 2 - MODÉLISATION DES COULEURS PAR LES NOMBRES COMPLEXES
(a)
(b)
(c)
(d)
(e)
FIG. 2.25 – Variations géométriques des signaux 2D
2.4.2
Le module du spectre fréquentiel UV sur des images couleur
Pour obtenir une vue de ce module nous avons tout d’abord converti les images dans l’espace cou-
leur Y UV à partir de l’espace RGB dans lequel elles étaient encodées équation (2.7). Ensuite nous
avons extrait les parties U et V que nous avons encodées dans une matrice de complexes. Nous avons
effectué la transformée de Fourier et calculé le logarithme de son module. L’information est enregistrée
dans une image en niveaux de gris (cf. ﬁgure 2.26). Les spectres obtenus semblent équivalents à ceux
qui illustrent les spectres classiques d’images en niveaux de gris. En effet l’information du module cor-
respond à la notion d’énergie du signal dans le domaine spectral. Cette information serait sensiblement
équivalente pour une image en niveaux de gris étant donné qu’elle permet par exemple de représenter
les composantes fréquentielles qui composent les objets de l’image. Nous pouvons donc en conclure que
même si l’information UV n’est pas sufﬁsante pour décrire la couleur, l’énergie du signal obtenue par la
transformée de Fourier complexe chromatique correspond à celle obtenue par une analyse fréquentielle
classique. En effet pour l’image comportant des blocs de couleur par exemple, la notion de texture ap-
paraît par des motifs géométriques dans le spectre lui correspondant. L’énergie n’est pas une notion qui
dépend uniquement des composantes chromatiques mais la transformée de Fourier chromatique utilisée
ici la conserve correctement.
2.5
Filtrage fréquentiel UV
Une application à l’étude de cet espace fréquentiel numérique couleur déﬁni à partir des composantes
U et V de l’espace Y UV après transformée de Fourier est la déﬁnition de ﬁltres fréquentiels. En effet,
il est possible de déﬁnir de tels ﬁltres qui une fois appliqués sur des images couleur devraient permettre
de mettre en évidence certaines fréquences dans des images et plus particulièrement certaines ruptures
couleur. Le principe de tels ﬁltres a été expliqué à la section 2.2.2.6. Pour créer un ﬁltre passe-haut sur
une image par exemple, on retire les informations de basse-fréquences contenues dans son spectre. Pour
cela nous avons choisi simplement de déﬁnir un seuil de fréquences au-delà duquel les informations
fréquentielles seraient conversées. Dans la ﬁgure 2.27, un tel ﬁltre qui conserve 20% de l’information
haute fréquence est illustré avec deux images. Pour une meilleure lisibilité à l’impression, les résultats
après ﬁltrage ont été réhaussés. On remarque cependant que même s’il apparaît des artefacts (cf. ﬁgure
2.27b) liés au fait que la fenêtre de sélection spectrale n’est qu’une simple fonction porte, l’information

2.6. Conclusion
35
FIG. 2.26 – Images couleur (première ligne) et le module du spectre fréquentiel UV obtenue par la
transformée de Fourier couleur (deuxième ligne)
haute fréquence est mise en évidence par ce type de ﬁltrage. En effet, on peut reconnaître aisément les
contours des objets de l’image. De plus, on remarquera que les contours obtenus par cette méthode de
ﬁltrage passe-haut, conservent les couleurs des objets d’origine. Ce constat permet de valider le fait qu’il
n’est pas incohérent d’appliquer ce type de transformée de Fourier sur des images couleur. On remarque
cependant que le résultat du ﬁltrage fait apparaître les contours du cercle rouge avec l’opposition de
couleur rouge/vert tout comme les contours du quadrilatère apparaissent avec l’opposition bleu/jaune
(cf. ﬁgure 2.27c). Même si les couleurs sont exprimées uniquement suivant U et V et que la composante
Y est manquante pour pouvoir caractériser complètement les couleurs, le résultat reste cohérent car il
illustre le principe des chemins couleur qui mettent en opposition les couleurs antagonistes.
2.6
Conclusion
Au cours de ce premier chapitre, nous avons étudié comment le traitement des images couleurs était
possible en utilisant le formalisme des complexes. Pour cela nous avons d’abord effectué un rappel sur
l’analyse fréquentielle obtenue par la transformée de Fourier pour des signaux bidimensionels tels que
des images en niveaux de gris. Nous avons ensuite effectué une étude numérique de l’espace Y UV aﬁn
de montrer comment les informations chromatiques contenues dans les composantes U et V se com-
portaient numériquement lors du changement d’espace couleur à partir des composantes RV B. Nous
avons montré que l’information chromatique décrite par les composantes U et V est dépendante de la
composante de clarté Y dans cet espace. Cependant nous avons tout de même pu observer qu’il n’était
pas incohérent de déﬁnir une transformée de Fourier chromatique utilisant les deux composantes U et V
pour décrire les variations fréquentielles de couleur. Pour interpréter l’information spectrale chromatique,
nous avons utilisé la notion de chemin couleur. Ces chemins couleur déﬁnis dans le domaine de Fourier
permettent de décrire des variations de couleur dans le domaine spatial. En effet, à chaque chemin couleur
initialisé par un couple de fréquences correspond une variation de couleur dans le domaine spatial. Il est
possible de décrire plusieurs types de variations de couleur au moyen de différents chemins élémentaires.
Pour montrer que cette transformée de Fourier pouvait être utilisée avec les images, nous l’avons utilisée
dans un schéma de ﬁltrage fréquentiel permettant d’obtenir des images ﬁltrées cohérentes. Nous conﬁr-
mons cependant que l’information couleur qui comporte intrinsèquement trois dimensions ne peut être

36
CHAP 2 - MODÉLISATION DES COULEURS PAR LES NOMBRES COMPLEXES
(a)
(c)
(b)
FIG. 2.27 – Filtrage Passe-Haut sur le spectre UV : image d’origine (a) ; image ﬁltrée et rehaussée (b) ;
zoom sur l’image ﬁltrée (c)
réduite aux deux seules composantes offertes par l’utilisation des complexes car la chrominance n’est pas
sufﬁsante pour décrire complètement une couleur. Dans le chapitre suivant, nous montrons comment, en
rajoutant par le formalisme des quaternions de la place libre pour coder l’information couleur dans sa
globalité, il est possible d’obtenir des résultats plus complets pour traiter et analyser les images couleur.

CHAPITRE 3
MODÉLISATION DES COULEURS PAR LES
QUATERNIONS
Nous avons vu dans le premier chapitre de ce document qu’il était possible d’utiliser les nombres
complexes aﬁn d’effectuer des traitements sur des images numériques couleur. En effet, nous avons décrit
comment les nombres complexes pourraient analyser la partie chromatique des couleurs. Cependant les
nombres complexes ne peuvent pas prendre en compte la nature tri-dimensionnelle des couleurs. Dans
ce chapitre, les quaternions, qui sont une extension des nombres complexes et qui possèdent une capacité
de stockage de quatre composantes, vont être utilisés pour encoder des couleurs. Après une introduction
présentant les quaternions ainsi que les différentes manières de les représenter, nous étudierons comment
ils peuvent être utilisés pour effectuer des traitements sur des images couleur numériques dans le domaine
spatial. Ensuite nous présenterons différentes transformées de Fourier déﬁnies dans la littérature et nous
nous intéresserons à l’utilisation de deux d’entres elles en analyse d’image. Enﬁn nous évaluerons la
possibilité d’utiliser les quaternions pour effectuer une analyse fréquentielle des images numériques
couleur.
3.1
Déﬁnition des quaternions et propriétés
3.1.1
Historique
Les quaternions ont été inventés par Sir William Rowan Hamilton en 1843. Il raconte lui-même qu’il
a eu l’inspiration le 16 octobre 1843 alors qu’il se promenait le long du Royal Canal à Dublin. Tout excité
par cette découverte, en traversant le Brougham Bridge, il aurait inscrit sur une des pierres du pont la
formule de multiplication i2 = j2 = k2 = ijk = −1.
3.1.2
Déﬁnition
L’ensemble des quaternions est déﬁni avec q = a + bi + cj + dk où :
– a, b, c et d sont des nombres réels ;
– i, j et k sont des nombres imaginaires, qui vériﬁent :
i2 = j2 = k2 = −1
ij = −ji = k
jk = −kj = i
ki = −ik = j
(3.1)
37

38
CHAP 3 - MODÉLISATION DES COULEURS PAR LES QUATERNIONS
La multiplication de deux quaternions est déﬁnie par associativité à partir des formules précédentes.
Ceci munit l’ensemble des quaternions, noté H, d’une structure de corps (cf. sous-section 3.1.4 pour la
déﬁnition de l’inverse) non commutatif (par exemple, ij = −ji). Cette absence de commutativité fait
apparaître certaines propriétés « singulières ». Ainsi, l’équation x2 + 1 = 0 admet plus de deux racines
dans H : i, −i, j, −j, k, −k sont par exemple six racines mais il en existe en fait une inﬁnité.
3.1.3
Notations
Soit un quaternion quelconque q, on pourra également le voir décrit sous la notation suivante :
q = qr + qii + qjj + qkk
(3.2)
Avec qr la partie réelle de q et qi, qj et qk ses parties imaginaires.
3.1.4
Vocabulaire
Soit q = a + ib + jc + kd un quaternion quelconque :
– q = a −ib −jc −kd est appelé le conjugé de q ;
– si q est non nul, alors q−1 =
q
|q|2 est l’inverse de q ;
– ℜ(q) = a est la partie réelle de q. Si ℜ(q) = q, alors q est dit réel ;
– ℑ(q) = ib + jc + kd est la partie imaginaire de q. Si ℑ(q) = q, alors q est dit pur ;
– le module ou la norme du quaternion q est déﬁni comme suit :
√
a2 + b2 + c2 + d2 = √qq et est
noté |q| ;
– P = {q ∈H | q = ℑ(q)} est l’ensemble des quaternions purs ;
– S = {q ∈H | |q| = 1} est l’ensemble des quaternions unitaires. De plus, S forme un groupe.
3.1.5
Représentation cartésienne
Le quaternion q ∈H est représenté sous sa forme cartésienne dans l’equation suivante (avec a, b, c, d ∈
R) :
q = a + ib + jc + kd
(3.3)
3.1.6
Représentation vectorielle
On considère avec cette représentation qu’un quaternion q est composé d’une partie scalaire S(q) =
ℜ(q) et d’une partie vectorielle V(q) = ℑ(q).
q = S(q) + V(q)
(3.4)
Il est possible de représenter à partir de cette notation les vecteurs de R3 avec des quaternions purs.
Dans le repère orthonormal (O, ⃗e1, ⃗e2, ⃗e3) le vecteur v = x⃗e1 + y ⃗e2 + z ⃗e3 de coordonnées (x, y, z) sera
donc représenté par le quaternion pur V(q) = q = xi + yj + zk.
3.1.7
Produit quaternionique
Avec l’aide des représentations cartésienne et vectorielle nous pouvons désormais présenter le produit
de deux quaternions quelconques. Soient q1 et q2 ∈H tels que
q1 = a1 + ib1 + jc1 + kd1 = S(q1) + V(q1)
q2 = a2 + ib2 + jc2 + kd2 = S(q2) + V(q2)
(3.5)
Le produit q1q2 s’exprime alors en représentation cartésienne :

3.1. Déﬁnition des quaternions et propriétés
39
q1q2 = a1a2 −b1b2 −c1c2 −d1d2
+ (a1b2 + b1a2 + c1d2 −d1c2)i
+ (a1c2 + c1a2 + d1b2 −b1d2)j
+ (a1d2 + d1a2 + b1c2 −c1b2)k
(3.6)
On peut aussi exprimer q1q2 avec la représentation vectorielle :
q1q2 = S(q1)S(q2) −V(q1).V(q2)
+ S(q1)V(q2) + S(q2)V(q1)
+ V(q1) ∧V(q2)
(3.7)
On remarque que le produit quaternionique fait apparaitre V(q1).V(q2) le produit scalaire et V(q1) ∧
V(q2) le produit vectoriel des vecteurs V1 et V2 ∈R3 représentant les parties imaginaires des quaternions
q1 et q2.
3.1.8
Représentation exponentielle
Les quaternions unitaires peuvent être représentés suivant une forme exponentielle Cette représenta-
tion est l’extension de la forme exponentielle complexe obtenue avec les formules d’Euler[8].
Si q = q0 + iq1 + jq2 + kq3 ∈H alors ∃ϕ ∈R, ν ∈P tels que
q = |q|eνϕ = |q| (cos ϕ + ν sin ϕ)
(3.8)
où ν est unitaire pur et est l’axe de q, et ϕ son angle. Ces deux quantités sont données par les
relations :











ν = V(q)
|V(q)| = iq1 + jq2 + kq3
p
q2
1 + q2
2 + q2
3
ϕ = arctan
|V(q)|
S(q)

= arctan
 p
q2
1 + q2
2 + q2
3
q0
!
(3.9)
3.1.9
Représentation polaire
3.1.9.1
Déﬁnition
Dans son manuscrit de thèse, Bülow montre le calcul qui permet d’exprimer les quaternions sous
forme polaire. Cette représentation comporte le module |q| et les trois phases φ, θ et ψ. Tout quaternion
peut ainsi être représenté de la manière suivante [8] :
q = |q|eiφekψejθ avec (φ, θ, ψ) ∈[−π, π[×[−π
2 , π
2 [×[−π
4 , π
4 ]
(3.10)
Nous avons donc dans cette notation la notion d’amplitude d’un quaternion qui vaut ρ(q) et la notion
de phase angulaire arg(q) qui est représentée par un triplet :



ρ(q) = |q|
arg(q) = (φ, θ, ψ) ∈[−π, π[×[−π
2 , π
2 [×[−π
4 , π
4 ]
(3.11)

40
CHAP 3 - MODÉLISATION DES COULEURS PAR LES QUATERNIONS
3.1.9.2
Méthode de calcul
Soit q = a+ib+jc+kd un quaternion unitaire ; Alors le triplet (φ, θ, ψ) ∈[−π, π[×[−π
2 , π
2 [×[−π
4 , π
4 ],
tel que q = eiφekψejθ, peut être déterminé par le calcul suivant :
1. calculer α = 2(bc −ad) ;
2. si |a| = 1 alors
a ˆφ = 0 ;
b θ = 1
2 arctan
2(ac−bd)
a2−b2−c2+d2 ;
c ψ = −απ
4 ;
sinon
a ˆφ = 1
2 arctan
2(ab+cd)
a2−b2+c2−d2 ;
b θ = 1
2 arctan
2(ac+bd)
a2+b2−c2−d2 ;
c ψ = 1
2 arcsin α ;
3. si eiφekψejθ = −q alors
a si ˆφ ≥0 alors φ = ˆφ −π ;
b si ˆφ < 0 alors φ = ˆφ + π ;
sinon ˆφ = φ.
3.1.10
Représentation de Cayley-Dickson
Pour tout q = a + ib + jc + kd ∈H on peut écrire q sous sa forme de Cayley-Dickson [26] :
q = z1 + z2j
(3.12)
avec z1, z2 ∈C tels que z1 = a + ib et z2 = c + id.
3.1.11
Représentation symplectique
Cette représentation est la généralisation de la notation de Cayley-Dickson, en effet tout quater-
nion étant exprimé dans la base d’origine (1, i, j, k) peut être exprimé dans une autre base orthonormée
(1, µ1, µ2, µ3) avec des quaternions purs µ1, µ2, µ3 tels que µ2
1 = µ2
2 = µ2
3 = −1, |µ1| = |µ2| = |µ3| =
1 et µ1µ2 = µ3 = −µ2µ1. Avec ces quaternions µ1 et µ2 tels µ1 ⊥µ2 on peut donc représenter un
quaternion q sous une forme complexe généralisée appelée représentation symplectique[27] :
q = q1 + q2µ2
(3.13)
avec q1, q2 tels que q1 = a′ + b′µ1 et q2 = c′ + d′µ1 donc :
q = (a′ + b′µ1) + (c′ + d′µ1)µ2
(3.14)
On appelle souvent q1 la partie simplexe et q2 la partie perplexe.
La décomposition symplectique sépare l’information contenue dans un quaternion en deux plans
perpendiculaires qui s’intersectent à l’origine de l’espace en 4 dimensions. Chacun de ces plans peut être
vu comme un plan d’Argand1[1]. Le premier est le plan d’Argand de la partie simplexe et son axe des
réels est identique à la partie scalaire du quaternion tandis que son axe des imaginaires correspond à µ1.
La partie perplexe est représentée par un autre plan d’Argand perpendiculaire au premier. L’axe des réels
sur ce plan correspond à µ2 tandis que la partie imaginaire est liée à µ3.
1Le plan ou diagramme d’Argand également appelé d’Argand-Gauss, d’Argand-Cauchy correspond simplement au plan
complexe. En termes actuels, un point M du plan d’Argand de coordonnées (a, b) est l’image de z = a + ib dans le plan afﬁne
euclidien du repère orthonormal direct (O, 1, i) avec i2 = −1.

3.2. Approche spatiale quaternionique pour les images couleur
41
3.1.12
Transformations géométriques
Les quaternions peuvent être utilisés pour décrire des vecteurs de R3, en utilisant uniquement leur
partie vectorielle (ou de manière équivalente leur partie imaginaire). Il apparaît que des transformations
géométriques simples sur des vecteurs de R3 peuvent être exprimées en utilisant que des additions et des
multiplications de quaternions [66]. Ces transformations sont illustrées dans la ﬁgure 3.1.
FIG. 3.1 – Les différentes transformations géométriques : q est un quaternion pur représentant un vecteur
couleur ; µ représente un autre vecteur couleur ; qrefl = −µqµ est la réﬂexion de q par rapport à µ ;
qrej = 1
2(q + µqµ) est la réjection de q par rapport à µ ; qproj = 1
2(q −µqµ) est la projection de q par
rapport à µ.
En posant q ∈P, µ ∈S ∩P et φ ∈R :
Réﬂexion qrefl = −µqµ est la réﬂexion de q par rapport à µ ;
Projection qproj = 1
2(q −µqµ) est la projection de q par rapport à µ ;
Réjection qrej = 1
2(q + µqµ) est la réjection de q par rapport à µ ;
Rotation qrot = eµ φ
2 qe−µ φ
2 est la rotation de q autour de l’axe µ et d’angle φ.
3.1.13
Représentation parallèle/perpendiculaire
Soient p, q ∈P alors on déﬁnit q∥et q⊥[27] par :





q∥= 1
2(q + pqp)
q⊥= 1
2(q −pqp)
(3.15)
On peut écrire q = q∥+ q⊥pour tout quaternion q pur avec q∥la partie de q parallèle au quaternion
pur p et q⊥la partie de q perpendiculaire à p. q∥est simplement la projection du vecteur représentant q
par rapport à p tandis que q⊥en est la réjection.
Comme nous allons le voir, toutes ces propriétés peuvent être utilisées pour manipuler les images.
3.2
Approche spatiale quaternionique pour les images couleur
3.2.1
Quaternions et images couleur
Les premiers travaux proposant de coder les images couleur en utilisant des quaternions pour per-
mettre d’éviter notamment des traitements marginaux sur les couleurs ont été proposés simultanément

42
CHAP 3 - MODÉLISATION DES COULEURS PAR LES QUATERNIONS
par S.J. Sangwine [60] et S.C. Pei [54]. Ils ont proposé d’utiliser la représentation cartésienne des qua-
ternions pour coder les pixels couleur des images. Ainsi une image couleur de dimension M × N sera
représentée par une matrice de quaternions de dimension M × N. Une couleur ne contenant que trois
composantes dans l’espace RVB, il a été proposé de décrire l’information couleur sur la partie imaginaire
des quaternions. Le pixel d’une image f aux coordonnées (m, n) sera donc codé de la manière suivante :
f[m, n] = fr[m, n]i + fv[m, n]j + fb[m, n]k
(3.16)
avec fr[m, n], fv[m, n] et fb[m, n] respectivement les composantes rouge, verte et bleue du pixel de
coordonnées (m, n).
Nous allons dans cette section nous intéresser aux traitements spatiaux possibles avec le formalisme
des quaternions. Tout d’abord on montrera comment une image couleur peut être décomposée en par-
tie simplexe et partie perplexe, cette décomposition permettant d’expliquer l’analyse fréquentielle des
images couleur de Sangwine et Ell[29]. Ensuite nous verrons qu’il est possible d’utiliser des transforma-
tions géométriques déﬁnies par des quaternions avec des couleurs de l’espace RV B pour exprimer ces
couleurs sous forme de teinte, saturation et luminosité. Enﬁn nous illustrerons comment de telles opé-
rations géométriques effectuées sur des couleurs représentées par des quaternions peuvent être utilisées
dans une approche de détection de contours.
3.2.2
Séparation partie simplexe et partie perplexe
La décomposition symplectique (cf. section 3.1.11) a été utilisée sur les pixels couleurs des images
codées avec des quaternions [27, 29] aﬁn de séparer l’information de couleur en une partie de luminosité
et une partie de chromaticité. Deux quaternions purs sont utilisés pour cette décomposition : le premier
µ1 est l’axe des niveaux de gris (µ1 = µgris = i+j+k
√
3 ) ; le second est l’axe perpendiculaire à µ1 dans la
direction de la couleur rouge (µ2 =
q
2
3(i, −j
2, −k
2)) (car le rouge sera souvent utilisé comme référence
pour une teinte de valeur nulle dans le plan de chromaticité).
Lorsque l’on décompose une image couleur en parties parallèle et perpendiculaire à µ1, il apparait
que cette décompostion permet de séparer l’information de luminosité sur la partie parallèle et l’informa-
tion chromatique sur la partie perpendiculaire à µ1 comme nous le montrent les résultats de la ﬁgure 3.2.
En effet la partie parallèle à µ1 (un réel codé sur la partie imaginaire de la partie simplexe) correspond
à la projection de tous les pixels couleur sur l’axe des niveaux de gris : c’est une information d’intensité
lumineuse. La partie perpendiculaire (nécessitant deux réels, respectivement associés à µ2 et µ1µ2, pour
coder les coefﬁcients de la partie perplexe) correspond quant à elle à la projection des pixels de l’image
sur le plan perpendiculaire à µ1 et qui passe par le vecteur µ2 (on passe par un changement de base pour
revenir dans la base i,j,k qui correspond à l’espace rgb). Cette seconde partie est donc considérée comme
de l’information chromatique. Si on somme les deux parties simplexe f1 et perplexe f2, on obtient de
nouveau l’image originale f. Cette décomposition symplétique est utilisée comme nous le verrons plus
tard dans l’analyse des images couleur par Ell et Sangwine dans [29], pour séparer l’information spectrale
obtenue après transformée de Fourier en parties chromatique et achromatique.
3.2.3
Transformations couleur
Pour chaque couleur décrite par un quaternion dans l’espace couleur RV B on peut faire corres-
pondre son équivalent dans un espace couleur de teinte, saturation et intensité. Nous considérons que
cette dernière information est représentée par la norme de la projection du vecteur couleur q sur l’axe des
niveaux de gris µgris = i+j+k
√
3 . La saturation et la teinte peuvent être représentées sur le plan orthogonal
à µgris à l’intersection de cet axe et de l’extrémité du vecteur projeté de q sur µgris. La saturation est
la distance entre l’extrémité du vecteur couleur q et l’axe µgris. La teinte correspond à l’angle entre la
réjection du vecteur q par rapport à µgris et un vecteur ν (vecteur de référence pour une teinte d’angle
nul) pris sur le plan orthogonal à µgris. La teinte de référence, c’est à dire celle d’angle nul, est souvent

3.2. Approche spatiale quaternionique pour les images couleur
43
(a)
(b)
(c)
(d)
(e)
(f)
(g)
(h)
(i)
FIG. 3.2 – Décomposition symplectique sur des images couleur : première colonne images originales ;
seconde colonne : parties parallèles ; dernière colonne : parties perpendiculaires
prise rouge, donc le vecteur ν est la réjection du vecteur couleur correspondant au rouge par rapport à
l’axe des niveaux de gris. Ces différentes valeurs sont illustrées dans la ﬁgure 3.3.
Pour un vecteur couleur q, les valeurs correspondantes de teinte (T), clarté (L pour Luminance en
anglais) et saturation (S) ont été déﬁnies antérieurement dans l’équipe [35], elles peuvent être obtenues
avec le vecteur µ = µgris ∈S ∩P et le vecteur de référence ν ∈S ∩P en utilisant les opérations
quaternioniques suivantes qui seront utilisées plus tard pour déﬁnir un gradient quaternionique couleur :





T=tan−1 |q−µνqνµ|
|q−νqν|
L=|1
2(q −µqµ)|
S=|1
2(q + µqµ)|
(3.17)
avec |1
2(q −µqµ)| la norme de la projection de q par rapport à µ et |1
2(q + µqµ)| la norme de la
réjection de q par rapport à µ (cf. équation 3.15).
3.2.4
Détection de contours
Dans cette partie nous nous focalisons sur l’aspect ﬁltrage spatial couleur et plus particulièrement
l’étude de la détection des discontinuités ou contours qui est une problématique fondamentale du trai-
tement des images en général, mais plus particulièrement en couleur car elle n’est pas encore résolue
dans ce cadre. Nous commencerons d’abord par revoir les méthodes traditionnellement utilisées pour la
détection des contours. Puis nous aborderons différentes solutions proposées utilisant le formalisme des

44
CHAP 3 - MODÉLISATION DES COULEURS PAR LES QUATERNIONS
FIG. 3.3 – Teinte (Hue), Saturation et Clarté (Value) obtenues avec µgris et T(ν) = 0
quaternions et enﬁn nous présenterons une nouvelle méthode calculant un gradient couleur à partir des
quaternions.
3.2.4.1
Méthodes marginales
Les méthodes marginales reposent sur l’extension des traitements sur les images en niveaux de gris
en effectuant séparément sur chaque canal couleur un traitement (cf. ﬁgure 3.4a). Elles bénéﬁcient donc
d’une implémentation relativement simple car il sufﬁt d’adapter les traitements déjà existants sur chacune
des matrices de pixels correspondant aux composantes couleur. Cependant, comme elles ne prennent pas
l’information couleur dans sa globalité car elles ne prennent pas en compte les corrélations (interactions)
entre les composantes, les résultats font souvent apparaître des incohérences en terme de perception
(fausses couleurs).
3.2.4.2
Méthodes vectorielles
Pour éviter les inconvénients des méthodes marginales, les méthodes vectorielles considèrent les
pixels des images comme des vecteurs couleur (cf. ﬁgure 3.4b). Les traitements sont alors effectués de
manière globale sur la couleur. Le problème de ce type de méthodes repose à la fois sur le choix de l’es-
pace de codage, pour faire correspondre l’information couleur à une information vectorielle et surtout
sur la modélisation et l’exploitation mathématiques des données. Par exemple Di Zenzo [21] déﬁnit un
gradient vectoriel couleur basé sur la géométrie différentielle des surfaces en utilisant un tenseur multis-
pectral. Celui-ci, associé à un champ vectoriel, permet de rechercher les variations locales de l’image,
autrement dit les contours. La plus grande valeur propre du tenseur correspond alors à la norme de ce
gradient vectoriel qui détecte les contours couleur. Comparées aux méthodes marginales, les méthodes
vectorielles obtiennent de meilleurs résultats perceptuels mais au prix d’une plus grande complexité.
3.2.4.3
Méthodes perceptuelles
Les méthodes perceptuelles [32, 39, 72, 57] sont basées sur des caractéristiques du système visuel
humain (SVH). Par exemple, dans [11], Carron utilise une méthode reposant sur un gradient marginal

3.2. Approche spatiale quaternionique pour les images couleur
45
(a)
(b)
FIG. 3.4 – Les méthodes marginales (a) travaillent de manière indépendante sur chacune des composantes
couleur tandis que les méthodes vectorielles (b) travaillent de manière globale sur les couleurs.
composé des informations de luminance, de saturation et de teinte. Deux méthodes sont proposées, la
première considère qu’à faible niveau de saturation, la teinte n’est pas pertinente, elle n’est alors pas
utilisée. Cependant lorsque la saturation est faible, le gradient proposé rajoute l’information de teinte.
La deuxième méthode privilégie l’information de teinte, les informations de saturation et de luminance
ne sont prises en compte que lorsque celle-ci n’est pas pertinente pour séparer les couleurs en terme
de perception humaine. En effet, à teinte égale, deux couleurs auront l’air de présenter une plus grande
différence lorsqu’elles sont fortement saturées que lorsqu’elles le sont moins. La ﬁgure 3.5 montre ce
phénomène avec les deux vecteurs couleur q1 et q2 qui semblent moins éloignés entre eux que les vecteurs
couleurs q3 and q4 même si cela n’est pas vrai en terme de teinte.
FIG. 3.5 – La distance couleur perçue entre les vecteurs q1 et q2 paraît moins importante qu’entre les vec-
teurs q3 et q4 même si la différence de teinte est la même : d
q1q2 = d
q3q4. qnoir, qblanc et µgris représentent
dans l’ordre le vecteur couleur nul noir, blanc et l’axe des niveaux de gris.

46
CHAP 3 - MODÉLISATION DES COULEURS PAR LES QUATERNIONS
Les méthodes perceptuelles donnent souvent de meilleurs résultats que les méthodes marginales et
vectorielles car elles intègrent des caractéristiques du système visuel humain à partir de modélisation
mathématiques simples. Cette prise en compte de la perception permet d’éviter l’apparition des artefacts
de couleurs dans les images résultats. Un autre gros avantage de ces méthodes est la détection des zones
ombragées à l’intérieur des modèles perceptifs, évitant par exemple la surdétection en tant que contours
des ombres d’une scène. En effet la couleur d’une ombre sera composée de la même teinte que celle
de l’objet sur lequel l’ombre apparaît mais sa clarté et sa saturation seront différentes. La complexité
algorithmique de ces méthodes est accrue comparée aux méthodes marginales mais pas forcément par
rapport à certaines méthodes vectorielles.
3.2.4.4
L’approche quaternionique de Sangwine
Les travaux de Sangwine et al. [63, 50] sur le ﬁltrage spatial proposent de généraliser les ﬁltres
linéaires classiques à l’utilisation des quaternions pour les images couleur. Une fois un ﬁltre linéaire
quaternionique déﬁni, il sufﬁt de le convoluer avec l’image couleur pour obtenir l’image couleur ﬁltrée.
Etant donné que le produit quaternionique n’est pas commutatif, il est possible de déﬁnir plusieurs
produits de convolution, le produit de convolution à droite est déﬁni ici pour un signal en deux dimen-
sions :
(f ∗h)[m, n] =
M−1
X
τ1=0
N−1
X
τ2=0
[|m −τ1|M, |n −τ2|N] h [|τ1|M, |τ2|N]
(3.18)
avec h le ﬁltre de dimension M × N (M et N des entiers impairs) et la notation |m|N qui indique
l’opérateur modulo N.
Sangwine a proposé un détecteur de contours basé sur la rotation des couleurs des pixels de l’image
d’un angle π autour de l’axe des gris. Le vecteur couleur résultat de cette rotation est comparé aux
vecteurs couleurs des pixels voisins (cf. ﬁgure 3.6).
FIG. 3.6 – Schéma du détecteur de contours de Sangwine : µ est l’axe des gris ; µq1µ (resp. µq3µ) est
la rotation du vecteur q1 (resp. q3) autour de µ et d’angle π ; le vecteur de comparaison entre q1 et q2
(resp. entre q3 et q4) est donné par q2 + µq1µ (resp. q4 + µq3µ) ; q4 + µq3µ est proche de l’axe des gris
et q2 + µq1µ en est plus éloigné donc le détecteur de Sangwine peut détecter un contour avec ce vecteur
qui est plus coloré que le précédent.
L’opération de ﬁltrage proposée par Sangwine est la suivante :
ffiltrée[m, n] = (h1 ⋆f ⋆h2)[m, n]
(3.19)

3.2. Approche spatiale quaternionique pour les images couleur
47
où les ﬁltres h1 et h2 sont une paire de ﬁltres conjugués avec Q = eµ π
2 et µ = µgris = i+j+k
√
3
l’axe
des gris tels que :
h1 = 1
6


1
1
1
0
0
0
Q
Q
Q


et
h2 = 1
6


1
1
1
0
0
0
Q
Q
Q


(3.20)
L’image résultat (cf. ﬁgure 3.6) ne donne à première vue pas l’impression d’être pertinente pour
détecter les contours. En effet, il semble qu’elle soit constituée uniquement d’information en termes de
niveaux de gris. Cependant ce n’est pas le cas, car si on y regarde de plus près, seules les zones de
couleurs homogènes de l’image d’origine apparaissent en niveaux de gris. En effet, le résultat afﬁche
le vecteur de comparaison qui est un quaternion pur représentant des couleurs rvb. Ce vecteur est le
résultat de l’opération géométrique qui consiste à ajouter deux vecteurs couleur entre eux. Le premier
terme de la somme est le pixel couleur à analyser. Le second terme est calculé par la rotation du vecteur
correspondant à la moyenne des pixels voisins du pixel analysé d’un angle de π par rapport à l’axe des
gris. Lorsque le pixel analysé est situé dans une zone homogène de l’image d’origine, comme c’est le cas
des vecteurs q3 et q4 dans l’exemple,le vecteur résultat, q4 + µq3µ sur l’exemple, est un vecteur couleur
très proche de l’axe des niveaux de gris, autrement dit, il a une faible saturation. Le résultat apparaîtra
comme une couleur proche d’un niveau de gris. En revanche, si le pixel analysé se situe sur une zone de
contour, autrement dit, ses pixels voisins sont en opposition de couleur (comme q1 et q2 sur l’exemple),
le vecteur couleur de comparaison (q2 + µq1µ) sera éloigné de l’axe des niveaux de gris. Autrement dit,
ce vecteur aura une forte saturation et par conséquent les contours apparaîtront colorés du fait de cette
plus grande distance.
Malgré ses bonnes performances, ce détecteur produit des fausses couleurs notamment lorsque le
vecteur couleur de comparaison produit « déborde » du domaine de déﬁnition de l’espace couleur. Cela
arrive lorsque deux pixels voisins ont une différence colorimétrique très importante. De plus nous pou-
vons voir sur la ﬁgure 3.7 que le chapeau de Lenna n’est pas détecté avec la même couleur dans les
images résultats (c) ou (d) pourtant dans ces deux cas, le ﬁltre est composé de ﬁltres horizontaux. La dif-
férence est due au sens d’application des ﬁltres h1 et h2 dans la convolution, en inversant l’ordre de leur
application dans le schéma de convolution, les vecteurs couleurs de comparaison produits sont différents.
Nous proposons donc par la suite une méthode évitant ces inconvénients.
3.2.4.5
Détection de contours par Maximum de distance couleur
Déﬁnition
En reprenant le principe du détecteur de contours de Sangwine nous proposons de créer
un gradient quaternionique [20]. Pour chaque pixel par exemple q1 (resp. q3) nous avons un vecteur de
comparaison2 avec son voisin q2 (resp. q4) obtenu par la méthode de Sangwine. Nous avons vu que plus
la différence de couleur était grande entre pixels voisins et plus le vecteur de comparaison résultant était
éloigné de l’axe des niveaux de gris. Nous proposons donc de calculer la distance qdist entre ce vecteur
de comparaison et l’axe des niveaux de gris µ (qsum = q2 + µq1µ ou qsum = q4 + µq3µ). La ﬁgure
3.8 résume notre approche. Cette distance peut être calculée au moyen d’opérations quaternioniques
élémentaires (cf. section 3.2.3) car cette distance est la norme de la réjection du vecteur de comparation
par rapport à µ. L’équation (3.17) nous indique qu’il s’agit de la saturation du vecteur de comparaison.
Cette distance est donc calculée par la norme du vecteur qdist avec :
qdist = 1
2(qsum + µqsumµ)
(3.21)
2On peut aussi dire que ce vecteur de comparaison est la somme de la réﬂexion de q1 par rapport à l’axe des gris avec q2 ou
encore la somme du symétrique de q1 par rapport à µ avec q2.

48
CHAP 3 - MODÉLISATION DES COULEURS PAR LES QUATERNIONS
(a)
(b)
(c)
(d)
FIG. 3.7 – Résultat du détecteur de contours de Sangwine : (a) image originale ; (b) image traitée par
un ﬁltrage de Sangwine horizontal ; (c) zoom sur les contours du chapeau dans (b) ; (d) le même zoom
que dans (c) mais sur l’image traitée par un ﬁltrage dans lequel h1 et h2 ont été permutés. Les zones
homogène apparaissent en niveaux de gris tandis que les contours détectés sont mis en évidance par des
pixels colorés.
De ce fait, lorsque la méthode de ﬁltrage de Sangwine nous donne deux vecteurs de comparaison
différents q1 + µq2µ et q2 + µq1µ pour comparer les couleurs portées par les vecteurs q1 et q2, la ﬁgure
3.9 montre que les deux distances S1 et S2 calculées avec notre approche sont bien sûr identiques. Cette
nouvelle approche est indépendante du sens d’application de la paire de ﬁltres conjugués utilisés dans la
convolution.
Cette opération de ﬁltrage est appliquée en utilisant des ﬁltres horizontaux, verticaux et dans les deux
directions diagonales. On sélectionne ensuite la distance maximale de saturation obtenue pour chacune
de ces directions pour obtenir le gradient couleur ﬁnal. Nous remarquons que ces opérations sont linéaires
mais que le résultat ﬁnal ne l’est pas. Le gradient ﬁnal étant obtenu par l’utilisation d’une norme, on perd
la linéarité en utilisant la norme L∞liée à l’opérateur « maximum »également assez sensible au bruit. Au
contraire lorsque l’on utilise la norme L2 l’approche est complètement linéaire 3. La ﬁgure 3.10 montre
les deux gradients obtenus avec les normes L2 et L∞. On remarque quelques petites différences et le
choix de la norme s’effectuera donc en fonction des besoins de l’application.
3du fait de la linéarité de la norme euclidienne

3.2. Approche spatiale quaternionique pour les images couleur
49
FIG. 3.8 – Le schéma de l’approche proposée : µ est l’axe des niveaux de gris ; µq1µ (resp. µq3µ) est
le vecteur résultant de la rotation de q1 (resp. q3) par rapport à µ d’un angle de π. Nous comparons
les vecteurs q1 et q2 (resp. q3 et q4) par la distance qdist =
1
2(qsum + µqsumµ) entre le vecteur de
comparaison de Sangwine qsum = q2 + µq1µ (resp. qsum = q4 + µq3µ) et l’axe µ (ﬂèches oranges).
Un contour pourra être détecté par une grande distance de l’axe des gris comme par exemple la ﬂèche
orange entre µ et q2 + µq1µ.
FIG. 3.9 – Différence entre le détecteur de contours de Sangwine et le notre : µ est l’axe des gris ; µq1µ
(resp. µq2µ) est le symétrique de q1 (resp. q2) par rapport à µ ;
La ﬁgure 3.11 montre les résultats de notre approche avec pour chaque ligne l’image originale suivie
du gradient couleur, ensuite le logarithme du gradient couleur (pour ampliﬁer les contours détectés par le
gradient) et enﬁn une carte de contours obtenue par seuillage empirique du gradient. Nous observons que
la méthode permet de détecter correctement les contours couleur avec par exemple l’image de la maison
où les murs, le toit et le ciel sont bien séparés. On remarque aussi dans la carte des contours obtenue avec
l’image de Lenna que son épaule est convenablement séparée du menton. Pour l’image du babouin, les
régions texturées sont aussi dissociées des régions homogènes. Cependant, comme notre méthode n’est
basée que sur une mesure de saturation, les différences de luminosité ne sont pas détectées comme nous
le remarquons avec les détails de la fenêtre de la maison par exemple.

50
CHAP 3 - MODÉLISATION DES COULEURS PAR LES QUATERNIONS
(a)
(b)
FIG. 3.10 – Différence des gradients de saturation obtenus avec la norme L2 pour (a) et L∞pour (b) à
partir de l’image de la maison. Les images ont été inversées pour une meilleure lisibilité.
(a)
(b)
(c)
(d)
(e)
(f)
(g)
(h)
(i)
(j)
(k)
(l)
FIG. 3.11 – De gauche à droite : images originales, gradient couleur, logarithme du gradient couleur et
carte des contours
Comparaison
La ﬁgure 3.12 montre des cartes de contours obtenues par différentes méthodes sur
l’image de la maison. Les méthodes marginales (ﬁgure 3.12b) et de Di Zenzo (ﬁgure 3.12c) semblent
plus sensibles au bruit. Les contours obtenus par notre approche (ﬁgure 3.12f and g) sont plus épais et
fermés. On rappelle que la première approche de Carron (ﬁgure 3.12d) est basée sur une différence de
teinte pour pondérer un gradient marginal tandis que sa seconde méthode utilise aussi la luminosité et
la saturation lorsque la teinte n’est pas sufﬁsante. Ces deux approches permettent d’obtenir des contours
fermés et non sensibles au bruit contrairement aux méthodes marginales et de Di Zenzo. Comparés à

3.3. Transformées de Fourier quaternioniques
51
la seconde approche de Carron (ﬁgure 3.12e), nos résultats ne permettent pas de tenir compte aussi
efﬁcacement des ombres car nous n’avons inclus qu’une mesure de saturation. Nos résultats dépendent
de plus de la valeur manuelle donnée au seuillage du gradient. En effet nous pouvons faire disparaître
les contours des ombres mais ceci au prix de contours plus ﬁns partout ailleurs (cf. ﬁgure 3.11d par
exemple).
Pour améliorer nos résultats, nous devrons vériﬁer si la mesure de saturation est sufﬁsante et dans
le cas contraire ajouter de l’information pour détecter les contours. En effet, deux couleurs peuvent être
différentes en ayant la même saturation comme nous l’avons vu par exemple avec les couleurs q1 et
q2 d’un côté et des couleurs q3 et q4 de l’autre dans la ﬁgure 3.5. Heureusement, ces couleurs peuvent
être différenciées par leur teinte ou leur clarté. Rajouter une information de clarté lorsque la saturation
n’est pas sufﬁsante peut améliorer nos résultats, ce qui sera présenté dans la section traitant des images
couleurs associées aux algèbres géométriques.
Cependant, même sans ces améliorations, notre détecteur de contours est performant. L’implanta-
tion utilisant les couleurs RV B avec le formalisme des quaternions permet de ne pas avoir d’artefacts
comme ceux obtenus en changeant d’espace couleur du fait des imprécisions numériques obtenues par
ces différents changements d’espaces. On notera aussi que notre méthode est une méthode vectorielle
car nous encodons les couleurs sur la partie vectorielle des quaternions. De plus, elle ne nécessite pas
une quelconque déﬁnition pour ordonner les vecteurs couleur entre eux. Notre distance est une mesure
de saturation qui ne donne donc pas plus d’importance à une couleur qu’à une autre lorsqu’elles ont la
même saturation. Enﬁn notre méthode est plus proche d’une approche perceptuelle que celles basées sur
l’espace couleur RV B car elle utilise la géométrie de cet espace couleur cartésien grâce aux quaternions
pour se rapprocher des méthodes utilisant les espaces couleur en teinte, clarté et saturation.
Nous allons maintenant introduire l’analyse dans le domaine complémentaire à savoir Fourier.
3.3
Transformées de Fourier quaternioniques
Les transformées de Fourier quaternioniques (ou aussi TFQ) ont été introduites par Todd A. Ell en
1992 alors qu’il cherchait à généraliser la transformée de Fourier complexe pour les images couleur.
On entend aussi parler de QFT de l’anglais Quaternionic Fourier Transform. Comme pour la version
complexe, les transformées de Fourier quaternioniques permettent de passer d’une information spatiale
à son équivalent en terme de fréquence ou inversement. Il existe plusieurs versions de transformées de
Fourier notamment parce que le produit quaternionique n’est pas commutatif. Ces différentes versions
ne sont pas tout à fait identiques cependant elles sont étroitement liées. Alors que Bülow utilisa une TFQ
pour analyser les structures 2D des images en niveaux de gris, Sangwine fut l’un des premiers à associer
les images couleur aux transformées de Fourier quaternioniques. Du fait de l’utilisation de celles-ci pour
les images numériques, nous nous contenterons d’analyser les versions discrètes des transformées.
3.3.1
TFQ utilisant j et k dans les exponentielles
Cette version est celle déﬁnie par Todd Ell [26] dans sa thèse et utilisée par Sangwine en 1996 dans
[60]. Ici l’emploi des quaternions imaginaires j et k est uniquement réservé à la déﬁnition d’une TF de
nature quaternionique. Aucune information spectrale n’est dans ce cas donnée à ces deux composantes.
Soit f une fonction discrète à deux variables m et n à valeurs quaternioniques, une transformée de Fou-
rier quaternionique (ou TFQ) est une fonction à valeurs quaternioniques pouvant s’écrire de la manière
suivante :
Fjk[o, p] =
1
√
MN
M−1
X
m=0
N−1
X
n=0
e−2jπ om
M f[m, n]e−2kπ pn
N
(3.22)
avec m et n (respectivement o et p) les coordonnées spatiales (resp. fréquentielles).

52
CHAP 3 - MODÉLISATION DES COULEURS PAR LES QUATERNIONS
(a)
(b)
(c)
(d)
(e)
(f)
(g)
FIG. 3.12 – Comparaison de différentes méthodes de détection de contours avec l’image de la maison :
(a) image originale ; (b) gradient marginal ; (c) approche de Di Zenzo ; (d) première approche de Carron ;
(e) seconde approche de Carron ; (f) notre approche ; (g) notre approche avec le logarithme du gradient.
3.3.2
TFQ utilisant i et j dans les exponentielles
Cette version est une variante de la précédente qui a été déﬁnie par Thomas Bülow dans sa thèse [8]
pour analyser les images en niveaux de gris. Dans ce cas, on verra par la suite que la dimension horizon-
tale est associée à l’imaginaire pur i tandis que la dimension verticale de l’image est liée à l’imaginaire
j.
Fij[o, p] =
1
√
MN
M−1
X
m=0
N−1
X
n=0
e−2iπ om
M f[m, n]e−2jπ pn
N
(3.23)

3.4. Approche fréquentielle quaternionique pour les images en niveaux de gris
53
3.3.3
Transformée de Fourier quaternionique directionelle à droite
Par la suite, Sangwine a apporté des modiﬁcations aux transformées précédentes en ajoutant à l’ex-
pression de l’exponentielle une direction caractérisée par un quaternion unitaire pur µ [61]. Le plus sou-
vent pour ne privilégier aucune couleur pour l’analyse spectrale on prend le quaternion neutre µgris =
i+j+k
√
3
qui correspond à l’axe achromatique de l’espace RVB. La déﬁnition est la suivante :
Fdroite[o, p] =
1
√
MN
M−1
X
m=0
N−1
X
n=0
f[m, n]e−2µπ( om
M + pn
N )
(3.24)
3.3.4
Transformée de Fourier quaternionique à gauche
Il est possible de basculer l’expression de l’exponentielle à gauche de la fonction f, on obtient la
déﬁnition d’une autre transformée de Fourier car le produit quaternionique n’est pas commutatif :
Fgauche[o, p] =
1
√
MN
M−1
X
m=0
N−1
X
n=0
e−2µπ( om
M + pn
N )f[m, n]
(3.25)
3.3.5
Transformée de Fourier quaternionique directionelle à deux côtés
Il est également possible de séparer l’exponentielle en deux parties, un peu à la manière des deux
premières déﬁnitions données mais en conservant le fait de rajouter une direction exprimée par des
quaternions unitaires purs (ici µ1 et µ2) à l’intérieur des exponentielles. Plusieurs combinaisons sont
possibles comme par exemple :
Fcˆotés1[o, p] =
1
√
MN
M−1
X
m=0
N−1
X
n=0
e−2µ1π om
M f[m, n]e−2µ2π pn
N
(3.26)
ou bien :
Fcˆotés2[o, p] =
1
√
MN
M−1
X
m=0
N−1
X
n=0
e−2µ1π pn
N f[m, n]e−2µ2π om
M
(3.27)
Dans tous les cas, la différence entre ces transformées réside essentiellement dans le fait que le
produit quaternionique n’est pas commutatif. La plupart du temps donc, un signe positif ou négatif au
sein d’une expression entraînera un développement ﬁnal différent.
3.3.6
Inversibilité
Dans tous les cas pour obtenir les transformées inverses il sufﬁt de remplacer le signe négatif par un
signe positif à l’intérieur des exponentielles du fait de la propriété eµe−µ = 1.
3.4
Approche fréquentielle quaternionique pour les images en niveaux de
gris
Avant d’étudier l’utilisation des quaternions pour l’analyse fréquentielle des images couleur, nous
présentons la première approche qui associa les quaternions aux images numériques. Les quaternions
furent en effet tout d’abord associés aux images numériques en niveaux de gris au moyen de la déﬁnition
d’une transformée de Fourier quaternionique déﬁnie par Bülow [8] dont nous donnerons tout d’abord un
rappel. Ensuite, nous verrons quelles symétries apparaissent dans le spectre associé à cette transformée
de Fourier quaternionique. Enﬁn, nous verrons comment Bülow réussit à caractériser les structures 2D
au sein des images en niveaux de gris par l’intermédiaire de la généralisation du signal analytique 1D
aux signaux à deux dimensions.

54
CHAP 3 - MODÉLISATION DES COULEURS PAR LES QUATERNIONS
3.4.1
Transformée de Fourier quaternionique pour les images en niveaux de gris
Soit f un signal quaternionique sur les deux dimensions réelles spatiales m et n alors la transformée
de Fourier de f, notée F q sur les dimensions fréquentielles o et p est donnée par :
F q[o, p] =
1
√
MN
M−1
X
m=0
N−1
X
n=0
e−2iπ om
M f[m, n]e−2jπ pn
N
(3.28)
Cette TFQ peut être utilisée sur des signaux réels, complexes et quaternioniques car l’ensemble
des quaternions H contient l’ensemble des nombres complexes C qui contient lui-même l’ensemble de
nombres réels R. Pour la suite des ces travaux, la TFQ sera utilisée sur des signaux à valeurs réelles
qui correspondent à l’information d’intensité des pixels en niveaux de gris. Les facteurs dans les inté-
grales peuvent aussi être changés, mais uniquement dans la déﬁnition de la TFQ, car changer leur ordre
modiﬁerait le résultat du fait de la non-commutativité des quaternions. Par conséquent, une fois la TFQ
déﬁnie, l’ordre des coefﬁcients ne doit donc plus changer.
Bülow a déﬁni cette transformée de Fourier en associant la direction horizontale m à la première
exponentielle décrite avec le quaternion i et la direction verticale n à la deuxième exponentielle liée au
quaternion j.
Nous allons maintenant étudier les propriétés de symétries qui sont associées au spectre obtenu par
cette transformée.
3.4.2
Symétries
Le fait qu’un signal soit une fonction paire ou impaire joue un rôle important dans l’analyse de Fou-
rier. On peut écrire n’importe qu’elle fonction comme la somme d’une fonction paire et d’une fonction
impaire f = fp + fi 4. Il est connu [5] que la transformée de Fourier d’un signal 1D pair est paire tandis
que celle d’un signal 1D impair est impaire. De plus, la TF d’un signal réel (resp. imaginaire) pair est
réelle (resp. imaginaire) alors que la TF d’un signal réel (resp. imaginaire) impair est imaginaire (resp.
réelle). Le diagramme ci-dessous résume ces informations :
L’idée de Bülow est d’étendre ces notions de symétries au cas de signaux 2D. Ainsi pour étudier les
propriétés de symétrie sur la TFQ de Bülow, les signaux 2D sont séparés en plusieurs signaux selon les
parties paires et impaires le long des axes m et n. Tous les signaux 2D peuvent donc être écrits sous la
forme f = fpp + fip + fpi + fii avec fpp correspondant à la partie de f qui est paire le long de m et n,
fip correspondant à la partie qui est impaire le long de m et paire le long de n, etc.
La transformée de Fourier Quaternionique de Bülow peut être réécrite de la manière suivante (pour
des signaux 2D f réels) :
4Dans toute cette section on notera fi pour une propriété de symétrie impaire et non pas pour la première partie imaginaire
du quaternion f.

3.4. Approche fréquentielle quaternionique pour les images en niveaux de gris
55
F q[o, p] =
1
√
MN
 M−1
X
m=0
N−1
X
n=0
cos(2πom
M ) cos(2πpn
N )f[m, n]
−i
M−1
X
m=0
N−1
X
n=0
sin(2πom
M ) cos(2πpn
N )f[m, n]
−j
M−1
X
m=0
N−1
X
n=0
cos(2πom
M ) sin(2πpn
N )f[m, n]
+k
M−1
X
m=0
N−1
X
n=0
sin(2πom
M ) sin(2πpn
N )f[m, n]
!
(3.29)
A partir de cette équation, Bülow a pu déduire les propriétés de symétrie de sa transformée de Fourier
quaternionique qui sont illustrées ici :
On remarque que pour un signal uniquement réel les variations paires suivant les axes m et n seront
reportées sur la partie réelle du spectre quaternionique, les variations impaires suivant m et paires sui-
vant n seront représentées dans la première partie imaginaire du spectre, les variations paires suivant m
et impaires suivant n seront elles sur la seconde partie imaginaire du spectre et qu’enﬁn les variations
impaires suivant m et n seront sur la dernière partie imaginaire du spectre. On aura donc une caractéri-
sation de toutes les symétries spatiales possibles en 2D séparées dans le spectre quaternionique. De plus,
même si cette information n’est pas nécessaire à l’analyse d’un signal réel, avec un signal décrit sur un
quaternion quelconque, les mêmes propriétés de symétries séparent les parties paires et impaires suivant
m et n dans le spectre pour chaque composante du quaternion (partie réelle, première partie imaginaire,
deuxième partie imaginaire et troisième partie imaginaire) de manière indépendante.

56
CHAP 3 - MODÉLISATION DES COULEURS PAR LES QUATERNIONS
3.4.3
Notion d’amplitude et de phase instantanées
Dans la partie suivante la notion de signal analytique qui permet de caractériser l’amplitude et la
phase instantanée d’un signal 1D sera présentée brièvement. Ensuite, nous verrons comment Bülow
réussit à étendre cette notion de signal analytique aux signaux à deux dimensions.
3.4.3.1
Le signal analytique 1D
Un signal 1D f variant dans le temps peut être représenté à l’instant t0 par un vecteur oscillant sur
l’axe réel entre 0 et f(t). Cependant à l’instant t0 le vecteur f(t0) ne donne aucune information sur
l’amplitude ou la phase instantanée de l’oscillation. Autrement dit, on ne peut ni savoir si f augmente
vers la droite ou au contraire revient dans l’autre sens, ni connaître l’amplitude de l’oscillation. Le signal
analytique fA(t) = f(t) + ifHi(t) déﬁni par Gabor[34] et construit à partir de f(t) et de sa transformée
de Hilbert fHi(t) (cf. équation 3.30) comble ces manques. En effet il permet de connaître à un instant t0
l’amplitude et la phase du signal. La ﬁgure 3.13 présente cette notion de signal analytique en montrant le
vecteur fA à l’instant t0 en fonction de f et fHi. L’amplitude instantanée à l’instant t0 vaut |fA(t0)| et la
phase instantanée vaut atan2(IfA(t0) + RfA(t0)). Le vecteur fA(t0) peut être vu comme un vecteur de
rotation dans le plan complexe. On remarque aussi que la projection de fA(t0) sur l’axe des réels donne
le vecteur f(t0) et sur l’axe des imaginaires donne le vecteur fHi(t0). On remarque donc que la partie
réelle du signal analytique fA correspond au signal f lui même.
fHi(t) = f(t) ∗
 1
πt

(3.30)
avec ∗le produit de convolution 1D.
On notera que la fonction
1
πt est égale à la transformée de Hilbert de la distribution de Dirac :
δHi(x) =
1
πt. Ainsi, la transformée de Hilbert d’une fonction f est égale au produit de convolution de
celle-ci avec la transformée de Hilbert de la distribution de Dirac.
FIG. 3.13 – Capture du vecteur oscillant f et du vecteur fA à l’instant t0
A partir de l’expression donnée dans le domaine temporel ou spatial on exprime la transformée de
Hilbert FHi du signal 1D f (dont la TF est F) dans le domaine des fréquences par :
FHi(ω) = −isign(ω)F(ω) avec sign(ω) =





1 si ω > 0
0 si ω = 0
−1 si ω < 0
(3.31)
Le signal analytique 1D dans le domaine de Fourier s’exprime donc par :
FA(ω) = F(ω) + iFHi(ω)
= F(ω)(1 + sign(ω))
(3.32)

3.4. Approche fréquentielle quaternionique pour les images en niveaux de gris
57
Une propriété que l’on déduit de l’équation (3.32) est que le spectre d’un signal analytique ne possède
pas de fréquences négatives.
A partir de cette expression du signal analytique pour des signaux 1D, Bülow généralise l’approche
aux signaux 2D. Pour cela, il utilise les propriétés de symétries du spectre obtenu par sa transformée de
Fourier ainsi que de la transformée de Hilbert étendue au cas 2D.
3.4.3.2
Le signal analytique quaternionique
Soit f un signal réel à deux dimensions et F q sa transformée de Fourier quaternionique (cf. équation
3.28). Le signal analytique quaternionique, aussi appelé signal monogénique, est déﬁni dans le domaine
fréquentiel par [8] :
F q
A(u, v) = (1 + sign(u))(1 + sign(v))F q(u, v)
(3.33)
Bülow déﬁnit la transformée de Hilbert totale quaternionique par :
fHT (x, y) = f(x, y) ∗

1
π2xy

(3.34)
Son équivalent dans le domaine des fréquences vaut :
FHT (u, v) = −F(u, v)sign(u)sign(v)
(3.35)
Il déﬁnit de plus les transformées de Hilbert partielles dans les directions x et y dans le domaine
spatial par :
fH1(x, y) = f(x, y) ∗
δ(y)
πx

fH2(x, y) = f(x, y) ∗
δ(x)
πy

(3.36)
avec δ(x) et δ(y) les distributions de Dirac dans les directions x et y.
Ce qui correspond dans le domaine fréquentiel à :
FH1(u, v) = −iF(u, v)sign(u)
FH2(u, v) = −iF(u, v)sign(v)
(3.37)
L’expression du signal analytique quaternionique f q
A(x, y) dans le domaine spatial est ainsi déﬁnie
par :
f q
A(x, y) = f(x, y) + fH1(x, y)i + fH2(x, y)j + fHT (x, y)k
(3.38)
Bülow déﬁnit ainsi l’amplitude et la phase instantanées du signal 2D à partir du signal analytique
quaternionique (cf. équation (3.11) pour arg(q)) :



|f q
A(x, y)| =
q
f 2(x, y) + f 2
H1(x, y) + f 2
H2(x, y) + f 2
HT (x, y)
φ(f q
A(x, y)) = arg[f(x, y) + fH1(x, y)i + fH2(x, y)j + fHT (x, y)k]
(3.39)
Comme pour le signal analytique 1D, la partie réelle du signal analytique fA est constituée du signal
f lui-même. De plus, on remarque que les fréquences positives sur les deux axes du spectre du signal
analytique quaternionique sont les seules non nulles. Cette propriété est équivalente à celle du signal
analytique 1D dont le spectre ne contient que des fréquences positives.
L’intérêt d’utiliser le signal analytique quaternionique est qu’il comprend une analyse généralisée
d’un signal 2D. Tout d’abord, la partie réelle du signal analytique quaternionique est le signal lui-même.
Cependant cette partie ne permet pas d’accéder aux informations du signal à un instant donné. Pour cela

58
CHAP 3 - MODÉLISATION DES COULEURS PAR LES QUATERNIONS
l’ajout des parties imaginaires est très intéressant. On remarque notamment que la première partie imagi-
naire correspond à l’équivalent d’un signal analytique sur la direction horizontale tandis que la deuxième
comprend l’équivalent d’un signal analytique sur la direction verticale. Enﬁn, la dernière partie imagi-
naire nous permet d’accéder comme pour le signal analytique 1D à la caractérisation à un instant donné
de l’amplitude ainsi que de la phase du signal d’origine mais cette fois avec les directions horizontale
et verticale rassemblées. On a ainsi avec cette déﬁnition accès à une information qui nous permet de
connaitre les amplitudes et les phases instantanées pour les directions horizontale et verticale séparément
et de manière globale.
3.5
Approche fréquentielle quaternionique pour les images couleur
Dans cette étude, nous cherchons à analyser des signaux spatiaux quaternioniques complètement dif-
férents de ceux utilisés par Bülow car ils encodent des couleurs. Une couleur ayant généralement besoin
de trois composantes pour être caractérisée, nous avons choisi d’utiliser les trois parties imaginaires d’un
quaternion pour les stocker (cf. section 3.2). Cette distinction de la nature des signaux que nous utilisons
nous fait donc perdre l’analyse de Bülow des structures 2D des signaux qui n’est pertinente que si ces
signaux sont réels. Par la suite, nous avons choisi arbitrairement d’utiliser dans cette étude la transformée
de Fourier quaternionique à gauche (cf. équation 3.25). Aussi lorsqu’on mentionnera une TFQ il s’agira
de celle-ci.
3.5.1
Déﬁnition numérique de l’espace de Fourier quaternionique
Nous avons remarqué dans le premier chapitre que les traitements des images couleur par transfor-
mées de Fourier complexes n’étaient pas sufﬁsamment pertinents pour décrire complétement la couleur.
La transformée de Fourier quaternionique discrète est le résultat de l’extension de la transformée de Fou-
rier complexe discrète au domaine des quaternions. Nous avons rappelé qu’un signal réel présente lors
de l’analyse par transformée de Fourier complexe une symétrie hermitienne dans le domaine de Fourier.
Dans cette partie nous allons nous poser le problème de la déﬁnition numérique de l’espace de Fourier
quaternionique dans le cadre applicatif des images couleur. Nous voulons donc déﬁnir quelles proprié-
tés sont nécessaires en terme de symétries dans le domaine fréquentiel pour correspondre à un espace
quaternionique spatial dans lequel la partie réelle soit nulle ce qui permettra de représenter une image
numérique couleur.
3.5.1.1
Développement de la TFQI sous forme cartésienne
On veut obtenir, après une TFQI (transformée de Fourier quaternionique inverse), une fonction dans
laquelle la partie réelle sera nulle pour respecter l’espace de départ de trois composantes couleur. En se
reportant à la déﬁnition de la TFQ (cf. équation 3.25) nous en déduisons la déﬁnition de la TFQI :
f[m, n] =
1
√
MN
M−1
X
o=0
N−1
X
p==0
e2µπ( om
M + pn
N )F[o, p]
(3.40)
avec µ un quaternion unitaire pur donnant la direction de l’analyse tel que µ = µii + µjj + µkk (µi,
µj et µk ∈R).
Pour simpliﬁer les calculs, on va exprimer les transformées de Fourier pour les fréquences déﬁnies
sur [(−M
2 + 1, −N
2 + 1); (M
2 , N
2 )], l’expression de la TFQI devient alors :
f[m, n] =
1
√
MN
M
2
X
o=−M
2 +1
N
2
X
p=−N
2 +1
e2µπ( om
M + pn
N )F[o, p]
(3.41)
L’information spectrale est décrite sur des quaternions a priori quelconques, elle a donc la forme
suivante :

3.5. Approche fréquentielle quaternionique pour les images couleur
59
F[o, p] = Fr[o, p] + Fi[o, p]i + Fj[o, p]j + Fk[o, p]k
(3.42)
pour le point du spectre de coordonnées fréquentielles (o, p).
Cependant après TFQI, on voudrait obtenir fr = 0 pour décrire ainsi l’information couleur sur les
composantes rouge, verte et bleue du quaternion imaginaire pur de coordonnées spatiales (m, n).
Nous devons donc calculer les conditions pour que la partie réelle soit nulle.
f[m, n] =
1
√
MN
M
2
X
o=−M
2 +1
N
2
X
p=−N
2 +1
exp2πµ( om
M + pn
N ) F[o, p]
=
1
√
MN
X
o
X
p
h
cos

2π
om
M + pn
N

+ µ sin

2π
om
M + pn
N
i
.[Fr[o, p] + Fi[o, p]i + Fj[o, p]j + Fk[o, p]k]
=
1
√
MN
X
o
X
p
h
cos

2π
om
M + pn
N

+ µi sin

2π
om
M + pn
N

i
+µj sin

2π
om
M + pn
N

j + µk sin

2π
om
M + pn
N

k
i
.[Fr[o, p] + Fi[o, p]i + Fj[o, p]j + Fk[o, p]k]
Nous pouvons ﬁnir de développer le calcul sur chaque composante du résultat ainsi :
fr[m, n] =
1
√
MN
X
o
X
p
h
cos

2π
om
M + pn
N

Fr[o, p]
−sin

2π
om
M + pn
N

[µiFi[o, p] + µjFj[o, p] + µkFk[o, p]]
i
(3.43)
De la même façon nous pouvons exprimer fi, fj et fk, expressions utiles pour la compréhension de
la TFQ :
fi[m, n] =
1
√
MN
X
o
X
p
h
cos

2π
om
M + pn
N

Fi[o, p]
+ sin

2π
om
M + pn
N

[−µiFr[o, p] −µjFk[o, p] + µkFj[o, p]]
i
(3.44)
fj[m, n] =
1
√
MN
X
o
X
p
h
cos

2π
om
M + pn
N

Fj[o, p]
+ sin

2π
om
M + pn
N

[µiFk[o, p] −µjFr[o, p] + µkFi[o, p]]
i
(3.45)
fk[m, n] =
1
√
MN
X
o
X
p
h
cos

2π
om
M + pn
N

Fk[o, p]
+ sin

2π
om
M + pn
N

[−µiFj[o, p] + µjFi[o, p] −µkFr[o, p]]
i
(3.46)
3.5.1.2
Propriétés de symétrie pour les images couleur
Symétries du spectre
A partir de l’expression de la partie réelle de f[m, n], on déﬁnit les fonctions
SA[m, n] et SB[m, n] ∈R comme suit :

60
CHAP 3 - MODÉLISATION DES COULEURS PAR LES QUATERNIONS
fr[m, n] =
1
√
MN
X
o
X
p


SA[m,n]
z
}|
{
cos

2π
om
M + pn
N

Fr[o, p]
SB[m,n]
z
}|
{
−sin

2π
om
M + pn
N

[µiFi[o, p] + µjFj[o, p] + µkFk[o, p]]


(3.47)
On cherche les conditions dans lesquelles cette partie réelle du quaternion f[m, n] est nulle, il faut
donc annuler les fonctions SA[m, n] et SB[m, n].
SA[m, n] =
−1
X
o=−M
2 +1
−1
X
p=−N
2 +1
cos

2π
om
M + pn
N

Fr[o, p] + cos (0) Fr[0, 0]
+
M
2 −1
X
o=1
N
2 −1
X
p=1
cos

2π
om
M + pn
N

Fr[o, p] + cos (π(m + n)) Fr[M
2 , N
2 ]
(3.48)
On a Fr(0, 0) + (−1)m+nFr(N
2 , M
2 ) = 0 donc ∀m, n ∈Z il faut que Fr(0, 0) = Fr(N
2 , M
2 ) = 0.
Ensuite on a :
SA[m, n] =
−1
X
o=−M
2 +1
−1
X
p=−N
2 +1
cos

2π
om
M + pn
N

Fr[o, p]
+
M
2 −1
X
o=1
N
2 −1
X
p=1
cos

2π
om
M + pn
N

Fr[o, p]
=
M
2 −1
X
o=1
N
2 −1
X
p=1
cos

2π
−om
M
+ −pn
N

Fr[−o, −p]
+
M
2 −1
X
o=1
N
2 −1
X
p=1
cos

2π
om
M + pn
N

Fr[o, p]
(3.49)
comme ∀x ∈R cos(−x) = cos(x), pour obtenir SA[m, n] = 0 il faut donc que :





Fr[−o, −p] = −Fr[o, p] pour (o, p) ∈[1; M
2 −1] × [1; N
2 −1]
et Fr(0, 0) = Fr(M
2 , N
2 ) = 0

3.5. Approche fréquentielle quaternionique pour les images couleur
61
SB[m, n] =
−1
X
o=−M
2 +1
−1
X
p=−N
2 +1
sin

2π
om
M + pn
N

[µiFi[o, p] + µjFj[o, p] + µkFk[o, p]]
+ sin (0) [µiFi[0, 0] + µjFj[0, 0] + µkFk[0, 0]]
+
M
2 −1
X
o=1
N
2 −1
X
p=1
sin

2π
om
M + pn
N

[µiFi[o, p] + µjFj[o, p] + µkFk[o, p]]
+ sin (π(m + n))

µiFi
M
2 , N
2

+ µjFj
M
2 , N
2

+ µkFk
M
2 , N
2

=
M
2 −1
X
o=1
N
2 −1
X
p=1
sin

2π
−om
M
+ −pn
N

[µiFi[−o, −p] + µjFj[−o, −p] + µkFk[−o, −p]]
+
M
2 −1
X
o=1
N
2 −1
X
p=1
sin

2π
om
M + pn
N

[µiFi[o, p] + µjFj[o, p] + µkFk[o, p]]
(3.50)
comme ∀x ∈R sin(−x) = −sin(x), pour obtenir SB[m, n] = 0 il faut que Fi[−o, −p] = Fi[o, p],
Fj[−o, −p] = Fj[o, p] et Fk[−o, −p] = Fk[o, p] pour (o, p) ∈[0; M
2 ] × [0; N
2 ].
Propriété [20]
Soit F une fonction quaternionique représentant le spectre d’une image couleur. Les
conditions suivantes permettent d’obtenir une fonction quaternionique pure f associée à cette image cou-
leur après une transformée de Fourier quaternionique inverse. Ainsi il faut que Fr[0, 0] = Fr[M
2 , N
2 ] = 0
et pour tout o ∈[1; M
2 −1] et p ∈[1; N
2 −1] :
Fr[−o, −p] = −Fr[o, p]
(3.51)
Il faut de plus, pour tout o ∈[0; M
2 ] et p ∈[0; N
2 ] :
Fi[−o, −p] = Fi[o, p]
Fj[−o, −p] = Fj[o, p]
Fk[−o, −p] = Fk[o, p]
(3.52)
On retrouve donc une propriété équivalente à celle déjà connue avec l’analyse de Fourier complexe, à
savoir que le spectre quaternionique d’une image couleur contient comme une symétrie anti-hermitienne.
3.5.2
Interprétation du spectre quaternionique
Une fois la transformée de Fourier quaternionique déﬁnie pour les images couleur[60], les auteurs
ont cherché à donner une interprétation de ce que représentait l’information décrite par les coefﬁcients
du spectre. Une première façon d’expliquer l’information spectrale a été de décrire le spectre quaternio-
nique avec la représentation exponentielle (cf. section 3.1.8), c’est l’objet de la première partie de cette
section. Ensuite, on a séparé chaque coefﬁcient spectral en deux, avec la notation en partie simplexe
et partie perplexe pour séparer l’information de luminosité de celle de chrominance. Cette séparation
permet d’exprimer comment les couleurs évoluent dans le spectre quaternionique en fonction de la lumi-
nosité et de la chromaticité [65, 29]. Cependant l’analyse proposée par ces auteurs, comme nous verrons
en deuxième partie, est dépendante de la direction donnée à la transformée de Fourier quaternionique. En
effet, elle n’est valable que si cette direction correspond à l’axe des niveaux de gris déﬁni par le quater-
nion pur µgris = i+j+k
√
3 . Nous présenterons, dans la dernière partie de cette section, la stratégie que nous
avons développé pour appréhender le contenu fréquentiel de cette transformée de Fourier quaternionique.

62
CHAP 3 - MODÉLISATION DES COULEURS PAR LES QUATERNIONS
3.5.2.1
Interprétation du spectre quaternionique avec la notation exponentielle
On peut exprimer le spectre de Fourier en utilisant la notion de phase de module et d’axe qui caracté-
risent la notation exponentielle d’un quaternion. Les illustrations de la ﬁgure 3.14 permettent d’illus-
trer ces notions avec le calcul d’une transformée de Fourier quaternionique sur l’image Lenna : en
haut à gauche l’image originale puis à droite le module, viennent ensuite en bas à gauche la phase et
à droite l’axe de cette transformée de Fourier quaternionique. La direction utilisée ici est la direction
µ = µgris = i+j+k
√
3
car elle ne donne pas plus d’importance à une composante qu’à une autre.
(a)
(b)
(c)
(d)
FIG. 3.14 – Les différentes représentations de la transformée de Fourier quaternionique : (a) image
originale ;(b) module ; (c) phase et (d) axe.
On rappelle que si q = q0 + iq1 + jq2 + kq3 ∈H alors ∃ϕ ∈R, ν ∈P tels que :
q = |q|eνϕ = |q| (cos ϕ + ν sin ϕ)
où ν est unitaire pur et est l’axe de q, et ϕ son angle. Ces deux quantités sont données par les relations
de l’équation (3.9).
On choisit de représenter le logarithme du module de la transformée de Fourier quaternionique
comme cela est utilisé dans les visualisations de spectres.
Pour la phase et pour l’axe de la transformée de Fourier, il a été choisi de moduler les informations par
un seuil sur l’amplitude du module aﬁn de ne pas interpréter des informations non pertinentes. En effet
lorsque l’amplitude du module n’est pas sufﬁsament importante, il y a instabilité des valeurs numériques
de phase et d’axe.

3.5. Approche fréquentielle quaternionique pour les images couleur
63
La phase est exprimée entre −π
2 et π
2 , nous avons alors choisi de l’illustrer en codant cette variation
sur la composante de Teinte d’un espace couleur « Teinte, Saturation, Clarté » (HSV).
L’axe est lui codé sur trois composantes couleur d’un espace RVB car c’est un quaternion pur.
Nous allons tenter d’interpréter les représentations graphiques précédentes de la transformée de Fou-
rier quaternionique.
Module
La représentation graphique du module ne pose pas de difﬁculté car elle est identique à celle
que nous connaissons lorsque nous effectuons une transformée de Fourier complexe, elle correspond bien
à une mesure d’énergie suivant les fréquences spatiales. La ﬁgure 3.15 illustre ce point avec différentes
images et leur module quaternionique.
FIG. 3.15 – Images et leur modules par la TFQ
Phase et axe
Il est difﬁcile d’exprimer exactement ce qu’apportent les notions de phase et d’axe avec
l’illustration d’une image complexe comme celle de Lenna. Nous remarquons toutefois que lorsque la
direction de la TFQ peut être représentée par un vecteur couleur perpendiculaire aux couleurs contenues
dans l’image analysée, l’angle obtenu par la TFQ reste le même et est associé à la couleur verte. Ce vert
correspond à un angle de π
2 qui est la valeur limite de la fonction arctan. Autrement dit, quand l’angle
est de π
2 , l’information de phase n’est pas pertinente. Par exemple pour la ﬁgure 3.16 la direction de la
TFQ est µ = i ; pour les images bleue, verte et cyan, images dans lesquelles aucun pixel n’est fonction
du « rouge », l’angle apparaît non pertinent avec une valeur de π
2 . Au contraire pour les autres images on
retrouve une variation de la couleur représentant l’angle, synonyme que celui-ci apporte de l’information
pour ces images. Nous pouvons donc conclure que si l’information d’angle apparait avec une teinte verte,
et ce quelque soit la direction de la transformée de Fourier, la phase n’est pas pertinente.
Nous n’avons cependant pas pu tirer d’autres conclusions générales quand aux informations conte-
nues dans l’angle et l’axe obtenus après QFT pour une direction d’analyse quelconque. Cependant, si
nous choisissons la direction d’analyse de la transformée de Fourier suivant l’axe des niveaux de gris, il
est possible d’avoir un peu plus d’information sur ces deux notions. Ell et Sangwine[29] effectuent une
transformée de Fourier quaternionique de direction µgris sur une image comportant un fond uni de cou-
leur jaune saturé à la moitié de la valeur maximale et un petit carré sur le côté supérieur gauche dont la
couleur est opposée dans l’espace couleur HSV à celle du fond, soit le bleu, lui aussi à moitié saturé. Ils
illustrent le résultat en afﬁchant les vues de module, d’angle et de phase déﬁnis de la même manière que
précédemment. Nous effectuons la même analyse que nous illustrons avec deux images aﬁn de pouvoir
comparer les résultats dans la ﬁgure 3.17. La deuxième image est construite comme la première mais
avec les couleurs inversées.

64
CHAP 3 - MODÉLISATION DES COULEURS PAR LES QUATERNIONS
FIG. 3.16 – Images et leur angle par la TFQ avec µ = µRouge = i
La vue du module nous montre une forme de lobe caractéristique d’une impulsion donc elle est
cohérente. On observe qu’il n’y a pas de couleur verte pour caractériser la phase ce qui revient à dire
qu’elle est déﬁnie partout dans l’image. On remarque également des oscillations des valeurs de la phase
ainsi que de l’angle dans la direction attendue, en effet ces oscillations suivent une direction « Sud-
Est » correspondant à l’axe sur lequel se situe le petit carré en haut à gauche. La deuxième ﬁgure
montre qu’en échangeant les couleurs dans l’image d’origine on ne change pas le module, ni même
l’orientation des oscillations de phase et d’axe comme attendu. De plus, on constate que la phase obtenue
avec la deuxième image suit des oscillations complémentaires à celles obtenues avec la première image
ce qui est cohérent car les couleurs analysées par la TFQ sont complémentaires. On observe le même
comportement entre les deux vues de l’axe. Cependant, ces observations ne nous permettent pas d’en
dire d’avantage tout comme les auteurs [29].
3.5.2.2
Interprétation du spectre quaternionique en y associant luminosité et chromaticité
Une autre façon d’analyser le contenu fréquentiel obtenu par transformée de Fourier quaternionique
est donnée dans [29]. Cette fois, on sépare les coefﬁcients du spectre en utilisant les notations paral-
lèle/perpendiculaire et la décomposition symplectique (cf. sections 3.1.13 et 3.1.11). Cependant, pour
commencer, on choisit d’extraire quatre coefﬁcients du spectre aux coordonnées (O0, P0) et ses symé-
triques dans les trois autres quadrants fréquentiels du spectre.
On applique la TFQ inverse de direction µ = µgris à partir des quatre coefﬁcients symétriques et on
obtient, après simpliﬁcation, une somme partielle f ′[m, n] de la transformée qui correspond à l’apport
des quatre combinaisons de fréquences horizontales et verticales, positives et négatives dans l’image
spatiale f[m, n] :

3.5. Approche fréquentielle quaternionique pour les images couleur
65
(a)
(b)
(c)
(d)
(e)
(f)
(g)
(h)
FIG. 3.17 – Images originales (a) et (e) ; leur module (b) et (f) ; leur phase (c) et (g) et leur axe (d) et (h)
par la TFQ
f ′[m, n] = exp2πµ
“ O0m
M + P0n
N
”
F[O0, P0]
+ exp−2πµ
“ O0m
M + P0n
N
”
F[−O0, −P0]
+ exp2πµ
“ O0m
M −P0n
N
”
F[O0, −P0]
+ exp−2πµ
“ O0m
M −P0n
N
”
F[−O0, P0]
(3.53)
Il est expliqué dans [29] que chaque exponentielle déﬁnit la normale du plan de chrominance dans
l’espace couleur pour le cas où l’on choisit pour direction de la transformée µ = µgris.
N’importe quel coefﬁcient du spectre peut être séparé en deux parties parallèle et perpendiculaire à
l’axe µgris de la transformée en utilisant la décomposition symplectique :

66
CHAP 3 - MODÉLISATION DES COULEURS PAR LES QUATERNIONS
F[O0, P0] = F∥[O0, P0] + F⊥[O0, P0]
(3.54)
avec F∥[O0, P0] = F1[O0, P0] et F⊥[O0, P0] = F2[O0, P0]µ2. Donc la partie parallèle est la partie
simplexe de F[O0, P0] et la partie perpendiculaire est le résultat de la multiplication de la partie perplexe
de F[O0, P0] avec µ2 (un quaternion pur perpendiculaire à µgris). La forme polaire est ensuite utilisée
pour exprimer les parties parallèle et perpendiculaire avec :
F[O0, P0] = A∥expµθ1 +A⊥expµθ2 µ2
(3.55)
Les parties parallèle et perpendiculaire du coefﬁcient F[O0, P0] multiplient les fonctions exponen-
tielles de la transformée de Fourier quaternionique pour produire une image cosinusoïdale. Cette image
cosinusoïdale est caractérisée par les fréquences horizontales et verticales données par les indices O0 et
P0, et possède une amplitude, une phase et une orientation données par la valeur du coefﬁcient F[O0, P0].
La partie parallèle intéragit avec les exponentielles de la transformée sans changer son axe :
expµ(αm+βn) A∥expµθ1 = A∥expµ(αm+βn+θ1)
(3.56)
avec α = 2π Oo
M et β = 2π Po
N les fréquences horizontales et verticales.
La phase θ1 est donc simplement celle de la partie parallèle et A∥est son amplitude.
Cependant lorsque que l’on multiplie les exponentielles de la transformée par la partie perpendi-
culaire A⊥eµθ2µ2, on agit sur l’axe des exponentielles de la transformée de Fourier comme suit (ceci
seulement parce que µ2 est perpendiculaire à µ) :
eµ(αm+βn)A⊥eµθ2µ2 = A⊥eµ(αm+βn+θ2)µ2
(3.57)
Ainsi comme la direction de la transformée de Fourier utilisée ici est µgris, l’angle θ2 représente
l’angle initial du vecteur µ2 qui est perpendiculaire au vecteur µgris. Comme µ2 tourne autour de µgris,
il déﬁnit un plan. Un plan perpendiculaire à l’axe des niveaux de gris est un plan de chrominance et
l’angle θ2 est utilisé pour donner une valeur initiale au vecteur µ2 dans ce plan, il représente donc une
notion de teinte. A⊥matérialise l’amplitude de la rotation.
On voit qu’avec cette approche on analyse le contenu de l’information fréquentielle avec des vec-
teurs qui effectuent des rotations dans l’espace couleur. Ces rotations peuvent être caractérisées par des
chemins couleur comme nous l’avons vu lors du premier chapitre puisque l’on effectue les rotations
sur le plan de chrominance. La théorie de Mc-Cabe[48] est alors utile pour appréhender la construction
de chemins couleur qui sont des sommes de chemins de bases. Le chemin couleur total décrivant la
participation des fréquences O0, P0 ainsi que leurs symétriques dans le spectre est donné ici :
f ′[m, n] = eµ(αm+βn) 
A+
∥eµθ+
1 + A+
⊥eµθ+
2 µ2

+ eµ(αm−βn) 
B+
∥eµφ+
1 + B+
⊥eµφ+
2 µ2

+ e−µ(αm−βn) 
B−
∥e−µφ−
1 + B−
⊥e−µφ−
2 µ2

+ e−µ(αm+βn) 
A−
∥e−µθ−
1 + A−
⊥e−µθ−
2 µ2

(3.58)
avec
F[O0, P0] = A+
∥eµθ+
1 + A+
⊥eµθ+
2 µ2
F[−O0, −P0] = A−
∥e−µθ−
1 + A−
⊥e−µθ−
2 µ2
F[O0, −P0] = B+
∥eµφ+
1 + B+
⊥eµφ+
2 µ2
F[−O0, P0] = B−
∥e−µφ−
1 + B−
⊥e−µφ−
2 µ2
(3.59)

3.5. Approche fréquentielle quaternionique pour les images couleur
67
On obtient, grâce aux symétries comprises dans le spectre quaternionique, un chemin couleur dont
la variation de luminosité suit l’axe des niveaux de gris. Par contre, pour la variation de chromaticité, le
chemin total décrit une ellipse dans le plan chromatique.
3.5.2.3
Interprétation du spectre par initialisation de Dirac
Aﬁn d’expliciter d’une autre manière l’information fréquentielle incluse dans l’espace numérique
fréquentiel quaternionique nous proposons une autre stratégie. Pour cela, nous avons choisi d’étudier
l’inﬂuence de l’initialisation d’un Dirac dans le domaine fréquentiel sur une image (domaine spatial
obtenu après transformée de Fourier inverse).
Insertion d’une singularité
En initialisant un point dans le domaine fréquentiel par une constante,
on veut interpréter le résultat obtenu dans le domaine spatial après transformée de Fourier Inverse. Ceci
permet de mettre en évidence les atomes élémentaires liés au spectre quaternionique.
f[m, n] =
1
√
MN
M
2
X
o=−M
2 +1
N
2
X
p=−N
2 +1
exp2πµ( om
M + pn
N ) F[o, p]
=
1
√
MN
X X
exp2πµ om
M exp2πµ pn
N F[o, p]
(3.60)
On initialise Fr
Fr[0, 0] = Fr[M
2 , N
2 ] = 0
Fr[−o, −p] = −Fr[o, p]
Dans ce cas, il faut insérer deux points de la manière suivante : Fr[o0, p0] = Kr et Fr[−o0, −p0] =
−Kr
on obtient donc :
– fr[m, n]
fr[m, n] = Krcos

2π
o0m
M
+ p0n
N

−Krcos

2π
−o0m
M
+ −p0n
N

donc
fr[m, n] = (Kr −Kr)cos

2π
o0m
M
+ p0n
N

= 0
La partie réelle est donc bien nulle comme nous l’avons décidé en initialisant le spectre quaternio-
nique correctement. Intéressons nous maintenant aux autres composantes :
– fi[m, n]
fi[m, n] = Krµisin

2π
o0m
M
+ p0n
N

−Krµisin

2π
−o0m
M
+ −p0n
N

donc
fi[m, n] = 2Krµisin

2π
o0m
M
+ p0n
N

– fj[m, n] et fk[m, n]
Le calcul est le même que pour fi[m, n], on obtient donc :
fj[m, n] = 2Krµjsin

2π
o0m
M
+ p0n
N


68
CHAP 3 - MODÉLISATION DES COULEURS PAR LES QUATERNIONS
et
fk[m, n] = 2Krµksin

2π
o0m
M + p0n
N

On constate que la partie réelle du spectre quaternionique est associée aux évolutions impaires suivant
les trois composantes couleur pondérées par la direction d’analyse µ.
On initialise Fi
Fi[−o, −p] = Fi[o, p]
Dans ce cas, il faut insérer deux points de la manière suivante : Fi[o0, p0] = Fi[−o0, −p0] = Ki
on obtient donc :
– fr[m, n]
fr[m, n] = −Kiµisin

2π
o0m
M
+ p0n
N

−Kiµisin

2π
−o0m
M
+ −p0n
N

donc
fr[m, n] = (−Kiµi + Kiµi)sin

2π
o0m
M
+ p0n
N

= 0
– fi[m, n]
fi[m, n] = Kicos

2π
o0m
M
+ p0n
N

+ Kicos

2π
−o0m
M
+ −p0n
N

donc
fi[m, n] = 2Kicos

2π
o0m
M
+ p0n
N

– fj[m, n]
fj[m, n] = −Kiµksin

2π
o0m
M
+ p0n
N

−Kiµksin

2π
−o0m
M
+ −p0n
N

donc
fj[m, n] = (−Kiµk + Kiµk)sin

2π
o0m
M
+ p0n
N

= 0
– fk[m, n]
fk[m, n] = −Kiµjsin

2π
o0m
M
+ p0n
N

−Kiµjsin

2π
−o0m
M
+ −p0n
N

donc
fk[m, n] = (−Kiµj + Kiµj)sin

2π
o0m
M
+ p0n
N

= 0
On constate que la partie associée à « i » capte les évolutions paires suivant la première composante
couleur et ceci quelque soit la direction d’analyse de la TFQ.

3.5. Approche fréquentielle quaternionique pour les images couleur
69
On initialise Fj
Fj[−o, −p] = Fj[o, p]
Dans ce cas, il faut insérer deux points de la manière suivante : Fj[o0, p0] = Fj[−o0, −p0] = Kj
fj[m, n] = 2Kjcos

2π
o0m
M + p0n
N

Les valeurs de fr[m, n], fi[m, n] et fk[m, n] étant nulles (cf. calculs partie précédente). Les résultats
se calculent de manière similaire à ceux de la constante initialisée à Ki, on obtient donc une variation
paire sur la composante « j ».
On initialise Fk
Fk[−o, −p] = Fk[o, p]
Dans ce cas, il faut insérer deux points de la manière suivante : Fk[o0, p0] = Fk[−o0, −p0] = Kk
La même chose est à remarquer dans ce cas.
fk[m, n] = 2Kkcos

2π
o0m
M
+ p0n
N

Les valeurs de fr[m, n], fi[m, n] et fj[m, n] étant nulles (cf. calculs partie précédente), on obtient
une variation en cosinus sur la composante « k ».
Inﬂuence du choix de µ
L’interprétation de l’initialisation du domaine fréquentiel quaternionique par
un Dirac peut alors se diviser en deux parties :
– L’atome associé à une composante imaginaire est une variation paire sur la couleur associée. Donc
un Dirac dans le fréquentiel sur une composante « i » donnera une variation de couleur suivant
la composante « i » dans le domaine spatial. Il apparaît également que le coefﬁcient µ n’a pas
d’inﬂuence lors de l’initialisation de la constante si elle est prise seulement sur les composantes
imaginaires de l’espace d’insertion fréquentiel.
– Lorsqu’on affecte un point de l’espace fréquentiel par un Dirac sur la composante réelle, il en
résulte une variation impaire de couleur suivant la direction donnée par le terme µ.
Nous illustrons ci-dessous l’initialisation du spectre avec des images en couleur dans l’espace RV B
(cf. ﬁgure 3.18).
Initialisation sur les parties imaginaires du spectre avec un µquelconque
Lorsqu’on initialise un point
fréquentiel sur une ou plusieures parties imaginaires du spectre, en utilisant la transformée de Fourier
quaternionique inverse, nous obtenons comme décrit dans la partie précédente des oscillations de cou-
leurs. La couleur dominante de ces oscillations correspond à ou aux axes concernés par l’initialisation
c’est à dire que lorsqu’on initialise la première composante imaginaire du spectre par exemple, l’os-
cillation obtenue sera décrite sur la première composante de l’image spatiale soit le rouge (cf. ﬁgure
3.18).
Pour chacune des images l’initialisation a été faite comme suit
– 1ere ligne, 1ere image : init avec µLum Fi[o, p] = Ki et Fi[−o, −p] = Ki
– 1ere ligne, 2ie image : init avec µLum Fj[o, p] = Kj et Fj[−o, −p] = Kj
– 1ere ligne, 3ie image : init avec µLum Fk[o, p] = Kk et Fk[−o, −p] = Kk
– 2ie ligne, 1ere image : init avec µLum Fi[o, p] = Ki, Fj[o, p] = Kj, Fi[−o, −p] = Ki et
Fj[−o, −p] = Kj
– 2ie ligne, 2ie image : init avec µLum Fi[o, p] = Ki, Fk[o, p] = Kk, Fi[−o, −p] = Ki et
Fk[−o, −p] = Kk
– 2ie ligne, 3ie image : init avec µLum Fj[o, p] = Kj, Fk[o, p] = Kk, Fj[−o, −p] = Kj et
Fk[−o, −p] = Kk
– 3ie ligne : initialisation avec µLum Fi[o, p] = Ki, Fj[o, p] = Kj, Fk[o, p] = Kk, Fi[−o, −p] =
Ki, Fj[o, p] = Kj et Fk[−o, −p] = Kk

70
CHAP 3 - MODÉLISATION DES COULEURS PAR LES QUATERNIONS
Nous constatons que les couleurs obtenues respectent aussi la loi de la synthèse additive car ajoutées
entre elles, elles forment le blanc.
FIG. 3.18 – Exemples d’initialisation avec un µLum
Initialisation sur la partie réelle du spectre avec µ ̸= µLum
Comme nous avons vu dans la partie
calculatoire, il est aussi possible d’initialiser le spectre sur sa partie réelle. Dans ce cas, en respectant
les conditions d’initialisation, on peut obtenir aussi des variations de couleur. Il faut alors jouer sur la
direction de la transformée de Fourier quaternionique pour obtenir des couleurs différentes (cf. ﬁgure
3.19).
Pour chacune des images l’initialisation a été faite comme suit
– 1ere image : init avec µLum = i+j+k
√
3 , Fr[o, p] = Kr et Fr[−o, −p] = −Kr
– 2ie image : init avec µRouge = i, Fr[o, p] = Kr et Fr[−o, −p] = −Kr
– 3ie image : init avec µMagenta = i+k
√
2 , Fr[o, p] = Kr et Fr[−o, −p] = −Kr
On remarque donc que la variation de couleur obtenue est fonction de la direction donnée à la trans-
formée de Fourier. Par exemple, si la direction µ vaut i+k
√
2 , le résultat sera une variation impaire sur les
deux composantes i et k (cf. ﬁgure 3.19b). Ceci équivaut à une variation avec autant d’amplitude dans le
rouge que le bleu soit d’après la synthèse additive le magenta.

3.5. Approche fréquentielle quaternionique pour les images couleur
71
(a)
(b)
(c)
FIG. 3.19 – Exemples d’initialisation avec un µ ̸= µLum
Variations géométriques
Comme nous l’avons vu, le spectre quaternionique vériﬁe la notion de dis-
tributivité de l’énergie en fonction de la géométrie. Nous pouvons donc régler l’orientation des variations
de couleur suivant les coordonnées des points affectés en amplitude dans le domaine fréquentiel. Cette
orientation suivra un axe perpendiculaire à la droite reliant les deux points affectés par l’initialisation
d’amplitude fréquentielle et passant par l’origine.
Nous choisissons, par exemple, pour la ﬁgure suivante (cf. ﬁgure 3.20) d’illustrer différentes orien-
tations spatiales en fonction des points du plan fréquentiel initialisés en amplitude (oscillations dans le
jaune).
Pour chacune des images l’initialisation a été faite comme suit
– 1ere ligne, 1ere image : init avec µJauneFr[o, p] = Kr et Fr[−o, −p] = −Kr
– 1ere ligne, 2ie image : init avec µJauneFr(o, −p) = Kr et Fr(−o, p) = −Kr
– 2ie ligne, 1ere image : init avec µJauneFr(0, p) = Kr et Fr(0, −p) = −Kr
– 2ie ligne, 2ie image : init avec µJauneFr(−o, 0) = Kr et Fr(o, 0) = −Kr
FIG. 3.20 – Exemples de variations géométriques des raies de couleur

72
CHAP 3 - MODÉLISATION DES COULEURS PAR LES QUATERNIONS
Nous allons maintenant illustrer une utilisation possible du spectre de Fourier caractérisant des
images couleur. L’application que nous développons est la même que celle utilisée par les complexes, à
savoir un schéma de ﬁltrage.
3.5.3
Applications
A notre connaissance, on ne peut trouver dans la littérature que quelques applications à la transformée
de Fourier quaternionique. L’information fréquentielle contenue dans le spectre quaternionique est par
exemple utilisée en tatouage d’image numérique [2, 3]. La TFQ a aussi été utilisée pour calculer des
corrélations d’images couleur [64, 50, 53]. A partir de l’étude fréquentielle que nous avons menée, nous
pouvons proposer une approche de ﬁltrage fréquentiel, ceci aﬁn d’effectuer des traitements bas-niveaux
sur le spectre quaternionique d’images couleur.
3.5.3.1
Filtrage fréquentiel
Pour faire du ﬁltrage fréquentiel, notre approche est la même que celle avec des images en niveaux
de gris à savoir un simple fenêtrage. Nous appliquons donc une transformée de Fourier quaternionique
sur une image couleur pour obtenir son équivalent en terme de fréquence. Nous appliquons ensuite
un masque correspondant au gabarit du ﬁltre désiré sur le spectre obtenu, en réduisant au choix les
informations de basses ou de hautes fréquences. Finalement, nous appliquons une transformée de Fourier
quaternionique inverse et nous obtenons l’image ﬁltrée :
fF ilt = TFQI{H.F}
(3.61)
avec F = TFQ(f) la transformée de Fourier quaternionique de l’image originale et H la réponse
fréquentielle du ﬁltre.
La ﬁgure 3.21 illustre les résultats obtenus pour un ﬁltrage passe-haut avec cette méthode (on a
H[o, p] = 1 ∀o, p ∈[−M
2 + 1; M
2 ] × [−N
2 + 1; N
2 ]). Cette ﬁgure montre que ce ﬁltrage fréquentiel
conserve les couleurs des images originales et que le contenu haute-fréquence est bien isolé du reste
des images. En effet les contours des rectangles dans la ﬁgure 3.21g, du cercle et du quadrilatère dans
la ﬁgure 3.21h sont de la même couleur que dans l’image originale. Les mêmes constatations sont pos-
sibles avec les détails du chapeau de l’image de Lenna ﬁltrée dans la ﬁgure 3.21c et de la bouche dans
la ﬁgure 3.21d. Toutefois, nous avons utilisé un simple fenêtrage dans le domaine fréquentiel et cela a
pour conséquence d’introduire des phénomènes d’oscillations sur les contours des images ﬁltrées. Même
si le produit fréquentiel n’est pas équivalent au produit de convolution spatial avec les quaternions, nous
remarquons donc qu’il apparaît un type d’artefacts équivalent à ceux introduits par un fenêtrage fréquen-
tiel par une fonction porte sur des images en niveaux de gris. On remarque que les oscillations induites
par notre fenêtrage fréquentiel varient entre les couleurs originales des images et leurs complémentaires5
dans l’espace RV B. Par exemple, pour le cercle la variation est entre le rouge et son complémentaire le
vert et pour le quadrilatère la variation est entre le bleu et son complémentaire le jaune. On illustre ainsi
l’interprétation du spectre dont les coefﬁcients traversent des chemins elliptiques sur le plan chromatique
tandis qu’ils gardent à peu près la même clarté, en effet la direction utilisée ici est l’axe des niveaux de
gris µgris.
La ﬁgure 3.22 illustre le résultat du même ﬁltrage mais effectué en utilisant des directions de trans-
formées différentes. On remarque que les résultats sont les mêmes quelque soit la direction utilisée pour
effectuer la transformée de Fourier même pour des images ne comportant qu’une seule couleur alors que
la direction de l’analyse n’est pas celle-ci. En fait à partir de notre analyse précédente sur le domaine de
Fourier, il n’est pas étonnant de retrouver les mêmes résultats avec des directions différentes. En effet,
nos images couleurs sont encodées en utilisant les trois composantes imaginaires d’un quaternion. Que
5On parle du complémentaire en synthèse additive. Si on se place dans le cercle des couleurs primaires, le complémentaire
d’une couleur est celle qui lui est directement opposée dans le cercle. Autrement dit si l’on trace une ligne passant par l’origine
et une couleur, sa complémentaire se trouve à l’intersection de cette ligne et de l’autre extrémité du cercle.

3.5. Approche fréquentielle quaternionique pour les images couleur
73
(a)
(b)
(c)
(d)
(e)
(f)
(g)
(h)
FIG. 3.21 – Résultats du ﬁltrage quaternionique passe-haut : (a) image originale de Lenna ; (b) pass-
haut appliqué sur (a) ; (c) détails du chapeau ; (d) détails du visage ; (e) image couleur simple ; (f) pass-
haut appliqué sur (e) ; (g) détails des contours des rectangles vert et blanc ; (h) détails des contours du
cercle rouge et du quadrilatère bleu. On remarque que le ﬁltrage fréquentiel préserve les couleurs des
images originales.
se passe t-il une fois l’information spatiale traduite en information fréquentielle ? Et bien tout comme
une initialisation sur une composante imaginaire du spectre décrit la variation de couleur spatiale sur la
même direction et quelque soit la direction d’analyse, il en va de même lors de l’analyse pratique. Nous
remarquons même que pour l’image constituée uniquement des formes de couleur plus ou moins rouge,
le ﬁltrage passe-haut détecte la couleur même avec une direction suivant le bleu.
La ﬁgure 3.23 montre que cette stratégie de ﬁltrage est sufﬁsante pour pouvoir détecter des contours.
Une carte des contours est obtenue par seuillage des valeurs absolues des images ﬁltrées. Cette approche
peut être généralisée au ﬁltrage par bande de fréquences. De plus, les résultats montrés sont obtenus
en utilisant le paramètre de direction µgris de la TFQ qui ne privilégie aucune couleur par rapport aux
autres.
3.5.3.2
Banc de ﬁltres quaternioniques
A partir de notre étude du domaine de Fourier quaternionique, un premier banc de ﬁltre quaternio-
nique à reconstruction parfaite, appliqué aux images couleur, a été développé au sein de l’équipe [10].
La difﬁculté principale repose sur la déﬁnition des différents ﬁltres fréquentiels permettant d’obtenir une
reconstruction parfaite de l’image. La ﬁgure 3.24 illustre les résultats obtenus par cette méthode sur une
image couleur test composée de formes simples ainsi qu’une image naturelle. Nous pouvons observer

74
CHAP 3 - MODÉLISATION DES COULEURS PAR LES QUATERNIONS
(a)
(b)
(c)
(d)
(e)
(f)
FIG. 3.22 – Résultats du ﬁltrage quaternionique passe-haut avec des directions différentes : (a)
image originale ; (b) passe-haut avec direction µ = I (réhaussé) ; (c) passe-haut avec direction µ = µgris
(réhaussé) ; (d) image originale ne comportant que des nuances de rouge ; (e) passe-haut avec direction
µ = I donc associé à la couleur rouge (réhaussé) ; (f) passe-haut avec direction µ = K soit associé à la
couleur bleue (réhaussé).
avec les résultats que la représentation contient tous les éléments attendus : la partie passe-bas corres-
pond à l’approximation grossière de l’image d’origine tandis que l’information haute fréquence paraît
plus dispersée : les coefﬁcients sont importants uniquement si des contours sont présents dans le support
de l’ondelette. De plus, les couleurs représentées par les coefﬁcients comportent de l’information sur
les couleurs des discontinuités que les coefﬁcients détectent (couleurs complémentaires). Une copie de
l’article est présentée à l’annexe C.
3.6
Conclusion
Nous avons pu au cours de ce chapitre étudier l’opportunité d’utiliser les quaternions pour encoder
les trois composantes nécessaires pour décrire une couleur. Une couleur étant encodée sur la partie vec-
torielle d’un quaternion, il devient plus facile de manipuler les couleurs entres elles. Après avoir déﬁni
quelques transformations géométriques en utilisant les quaternions nous avons développé une approche
spatiale de détection de contours. Ce détecteur de contour est basé sur la déﬁnition d’un gradient de
saturation et détecte correctement les ruptures chromatiques, cependant il est inefﬁcace pour les rup-
tures achromatiques. Ensuite, nous avons effectué une étude des différentes déﬁnitions des transformées
de Fourier quaternioniques dont deux d’entre elles ont été détaillées. La première, déﬁnie par Bülow,
permet de faire apparaître des attributs locaux sur des images réelles c’est à dire en niveaux de gris.
Cette analyse permet ainsi la caractérisation de structures 2D de ce type de signaux. Ensuite, nous avons

3.6. Conclusion
75
(a)
(b)
(c)
(d)
(e)
(f)
FIG. 3.23 – Détection de contours par ﬁltrage quaternionique passe-haut : (a) image originale de
Lenna ; (b) carte des contours par passe-haut à partir de (a) ; (c) image originale du babouin ; (d) carte
des contours par passe-haut à partir de (c) ; (e) image originale de la maison ; (f) carte des contours par
passe-haut à partir de (e).
étudié précisément la transformée de Fourier quaternionique appliquée aux images couleur déﬁnie par
Sangwine. Nous avons tout d’abord analyser comment se comportait numériquement cette transformée,
c’est à dire quelles contraintes étaient ajoutées à la transformée du fait de son utilisation dans le cadre
spéciﬁque des images numériques couleur. Une série de symétries dues à ces contraintes est d’ailleurs
apparue. Ensuite, plusieurs interprétations du contenu fréquentiel ont été apportées mais des problèmes
d’interprétation de l’information spectrale persistent. Lorsque la direction de la transformée est l’axe des
niveaux de gris, une interprétation qui reprend l’analyse spectrale de McCabe par les chemins couleur
est possible. Cependant, lorsque cette direction est différente, l’information spectrale semble bien plus
difﬁcile à interpréter. On sait cependant que les parties imaginaires du spectres sont associées, indépen-
damment à la direction, à des variations paires dans le domaine spatial. La partie réelle du spectre est
par contre associée à des variations impaires dans le domaine spectral mais aussi à la direction de la
transformée. Dans le chapitre suivant, nous nous intéresserons au formalisme des algèbres géométriques
qui étend un peu plus les possibilités des quaternions pour traiter les images numériques couleurs.

76
CHAP 3 - MODÉLISATION DES COULEURS PAR LES QUATERNIONS
(a)
(b)
(c)
(d)
FIG. 3.24 – La décomposition en ondelette : (a) image originale simple ; (b) les coefﬁcients d’ondelettes
normalisés pour chaque plan couleur ; (c) image naturelle ; (d) les coefﬁcients d’ondelette normalisés

CHAPITRE 4
MODÉLISATION DES COULEURS PAR LES
ALGÈBRES GÉOMÉTRIQUES
Les algèbres géométriques permettent la généralisation des quaternions. Elles permettent de plus, de
comparer des éléments de l’algèbre appelés multivecteurs par des relations géométriques évoluées déﬁ-
nies de manière algébrique. Nous proposons, dans ce chapitre, d’utiliser ce formalisme en l’appliquant
aux images numériques couleur avec une caractérisation numérique fréquentielle et des opérations de
manipulation des couleurs dans le domaine spatial.
4.1
Algèbres Géométriques
4.1.1
Déﬁnition
Une algèbre de Géométrique ou aussi appelé algèbre de Clifford est déﬁnie comme solution d’un
problème universel dont la donnée de base est un espace vectoriel E (sur R) de dimension ﬁnie n muni
d’une forme quadratique Q (voir par exemple le livre de M. Postnikov [58]). Pratiquement, et pour faire
simple, en notant C(E, Q) l’algèbre de Clifford obtenue à partir du couple (E, Q) :
– C(E, Q) est de dimension 2n (en tant qu’espace vectoriel sur R) ;
– E s’injecte dans C(E, Q) de telle sorte que l’on peut identiﬁer les vecteurs de E à des éléments de
C(E, Q) ;
– on a pour tout vecteur v de E : v2 = Q(v) (où v2 désigne le produit de v par lui même dans
C(E, Q)) ;
– une base de C(E, Q) est donnée par l’ensemble :
{ei1ei2 · · · eik, i1 < i2 < · · · ik, k ∈{1, · · · , n}}
(4.1)
auquel on adjoint 1 = e0 (ici (e1, · · · , en) désigne une base de E).
Dans ce qui suit, E sera soit R2 soit R3 et Q la forme quadratique euclidienne correspondante.
Nous noterons G2 (resp. G3) les algèbres de Clifford associées (notées aussi quelquefois R2,0 et
R3,0).
Chacun des éléments de la base d’une algèbre de Clifford est appelé un multivecteur. Cette notion de
multivecteurs correspond à l’extension de l’interprétation géométrique que nous nous faisons des vec-
teurs à une dimension supérieure à 1. En effet, intuitivement, nous associons à un vecteur une ﬂèche qui
est une interprétation de ce vecteur. Cette ﬂèche est en fait un segment de droite qui possède une origine,
une longueur ainsi qu’une orientation déﬁnie par le sens de l’extrémité du vecteur. Une droite est un
77

78
CHAP 4 - MODÉLISATION DES COULEURS PAR LES ALGÈBRES GÉOMÉTRIQUES
sous-espace vectoriel de dimension 1. Lorsqu’on se place dans l’algèbre géométrique Gn, elle corres-
pond à un 1-vecteur de l’espace vectoriel Gn. Les multi-vecteurs sont l’extension de cette interprétation
géométrique aux dimensions supérieures de l’espace. Un bivecteur correspondra donc à une portion de
plan orientée du fait de ses deux dimensions. De même un trivecteur sera représenté par une portion
3D orientée de l’espace. La ﬁgure 4.1 illustre cette notion en montrant une représentation de l’ensemble
des multivecteurs composant l’algèbre géométrique G3. Il est possible d’effectuer des opérations géomé-
triques en utilisant les multivecteurs (sous-espaces vectoriels de dimension k < n) et en leur appliquant
des opérations algébriques. Ceci présente un grand intérêt car on évite ainsi la manipulation des vecteurs
par l’utilisation des produits de matrices.
Comme indiqué juste avant, nous n’utiliserons dans cette partie, pour manipuler les images numé-
riques couleur caractérisées par trois composantes, qu’uniquement les algèbres géométriques G2 et G3
obtenues à partir des espaces vectoriels R2 et resp. R3 munis de leur base canonique (e1, e2) et resp.
(e1, e2, e3), associés à la forme quadratique euclidienne correspondante. Comme nous serons amené à
considérer les couleurs dans l’espace couleur rvb, le choix de la forme quadratique euclidienne s’impose
du fait de la nature euclidienne de l’espace rvb.
FIG. 4.1 – Les éléments de la base constituant l’algèbre géométrique G3 : l’espace est décrit par les
vecteurs e1, e2 et e3, les bivecteurs e12, e23 et e31 et le trivecteur ou pseudoscalaire e123.
Les algèbres géométriques sont décrites par de nombreux travaux dans la littérature, on pourra se
reporter par exemple à [14, 22, 30, 38, 37, 40].
4.1.2
Vocabulaire
– Un multi-vecteur est un vecteur de l’algèbre pouvant s’écrire par combinaison linéaire des vecteurs
de la base de l’algèbre. On déﬁnit de manière générale un multi-vecteur de Gn par :
A =
n
X
k=0
⟨A⟩k
(4.2)
avec ⟨A⟩k la partie k-vectorielle de A ou l’opérateur de grade k.
Par exemple, on peut donc exprimer un multi-vecteur A quelconque de G3 de la manière suivante :
A = A0e0 + A1e1 + A2e2 + A3e3 + A23e23 + A31e31 + A12e12 + A123e123
(4.3)
Suivant les références dans la littérature, e0 est parfois remplacer par 1.

4.1. Algèbres Géométriques
79
– On peut donc aussi décomposer le multi-vecteur A suivant ces parties k-vectorielles, par exemple
grade 0 de A :⟨A⟩0 = A0, ou grade 2 de A : ⟨A⟩2 = A23e23 + A31e31 + A12e12.
– Un multi-vecteur simple A dans G3 est un multi-vecteur pour lequel il existe un et un seul k,
0 ≤k ≤3, tel que ⟨A⟩k est non nul.
4.1.3
Les produits
La manipulation des k-vecteurs se fait par l’utilisation de différents produits. Le premier produit
utilisé est le produit géométrique, en prenant (e1, e2, e3, · · · , en) les 1-vecteurs formant la base de Rn
on obtient par le produit géométrique, les bivecteurs, les trivecteurs et ainsi de suite jusqu’au n-vecteur
ou pseudo-scalaire e123···n formant les éléments de la base de l’algèbre Gn. Ensuite différents autres
produits sont déﬁnis comme le produit interne et le produit externe qui nous permettront de déﬁnir des
transformations géométriques dans l’algèbre.
4.1.3.1
Produit Géométrique
Comme nous l’avons dit, le produit géométrique nous sert d’abord à construire les différents élé-
ments de la base de Gn à partir des 1-vecteurs de la base de Rn en appliquant la loi d’associativité, de
distributivité par rapport à l’addition de Gn.
On donne dans les tableau 4.1 et tableau 4.2 les différents produits géométriques entre les éléments
des bases de G2 et G3 qui sont les algèbres géométriques que nous utiliserons avec les images numériques.
1
e1
e2
e12
1
1
e1
e2
e12
e1
e1
1
e12
e2
e2
e2
−e12
1
−e1
e12
e12
−e2
e1
−1
TAB. 4.1 – Produits géométriques des éléments de la base de G2
1
e1
e2
e3
e23
e31
e12
e123
1
1
e1
e2
e3
e23
e31
e12
e123
e1
e1
1
e12
−e31
e123
−e3
e2
e23
e2
e2
−e12
1
e23
e3
e123
−e1
e31
e3
e3
e31
−e23
1
−e2
e1
e123
e12
e23
e23
e123
−e3
e2
−1
−e12
e31
−e1
e31
e31
e3
e123
−e1
e12
−1
e23
−e2
e12
e12
−e2
e1
e123
−e31
e23
−1
−e3
e123
e123
e23
e31
e12
−e1
−e2
−e3
−1
TAB. 4.2 – Produits géométriques des éléments de la base de G3
On peut maintenant obtenir par combinaison linéaire le produit géométrique de deux multivecteurs
quelconques de G2 ou G3.
– pour G2 il est calculé de la manière suivante avec A, B ∈G2 :
AB = (a0 + a1e1 + a2e2 + a12e12)(b0 + b1e1 + b2e2 + b12e12)
= (a0b0 + a1b1 + a2b2 −a12b12) + (a0b1 + a1b0 −a2b12 + a12b2)e1
+ (a0b2 + a1b12 + a2b0 −a12b1)e2 + (a0b12 + a1b2 −a2b1 + a12b0)e12

80
CHAP 4 - MODÉLISATION DES COULEURS PAR LES ALGÈBRES GÉOMÉTRIQUES
– pour G3 on peut le calculer par un produit matriciel suivant avec A = A0e0 + A1e1 + A2e2 +
A3e3 + A23e23 + A31e31 + A12e12 + A123e123 et B = B0e0 + B1e1 + B2e2 + B3e3 + B23e23 +
B31e31 + B12e12 + B123e123 appartenant à G3 :
AB ≡












A0
A1
A2
A3
A23
A31
A12
A123
A1
A0
A12
−A31
−A123
A3
−A2
−A23
A2
−A12
A0
A23
−A3
−A123
A1
−A31
A3
A31
−A23
A0
A2
−A1
−A123
−A12
A23
A123
−A3
A2
A0
A12
−A31
A1
A31
A3
A123
−A1
−A12
A0
A23
A2
A12
−A2
A1
A123
A31
−A23
A0
A3
A123
A23
A31
A12
A1
A2
A3
A0
























B0
B1
B2
B3
B23
B31
B12
B123












Nous allons donc maintenant nous intéresser aux différents autres produits pouvant être utilisés dans
les algèbres géométriques.
4.1.3.2
Produit Externe
Le produit externe, noté ∧, permet de caractériser les sous-espaces vectoriels générés par une famille
libre de vecteurs (non linéairement indépendants). Par exemple en utilisant le produit externe sur deux
1-vecteurs indépendants, on obtient un bivecteur, si de plus on multiplie celui-ci par un autre 1-vecteur
indépendant, on obtient un trivecteur représentant par exemple le plus grand sous-espace vectoriel de G3.
On déﬁnit le produit externe dans Gn par rapport au produit géométrique de la manière suivante avec
A et B ∈Gn :
A ∧B =
n
X
r=0
n
X
s=0
⟨⟨A⟩r ⟨B⟩s⟩r+s
(4.4)
La formule donnée ici est très générale mais permet de calculer le produit externe de deux multi-
vecteurs n’ayant pas forcément la même dimension. En effet, le multivecteur A est de grade r là où le
multivecteur B est de grade s. On effectue le produit géométrique entre les deux multivecteurs et on
garde uniquement les coefﬁcients qui représentent la partie r + s-vectorielle.
Pour donner un exemple, on peut obtenir le produit externe de deux multivecteurs comme A =
A0e0 + A1e1 + A2e2 + A3e3 + A23e23 + A31e31 + A12e12 + A123e123 et B = B0e0 + B1e1 + B2e2 +
B3e3 + B23e23 + B31e31 + B12e12 + B123e123 quelconques de G3 par le produit matriciel suivant :
A ∧B ≡












A0
0
0
0
0
0
0
0
A1
A0
0
0
0
0
0
0
A2
0
A0
0
0
0
0
0
A3
0
0
A0
0
0
0
0
A23
0
−A3
A2
A0
0
0
0
A31
A3
0
−A1
0
A0
0
0
A12
−A2
A1
0
0
0
A0
0
A123
A23
A31
A12
A1
A2
A3
A0
























B0
B1
B2
B3
B23
B31
B12
B123












4.1.3.3
Produit Scalaire
Le produit scalaire, noté ., est souvent utilisé pour donner une notion de distance ou de norme (cf.
4.1.5.2) aux multivecteurs, il se déﬁnit par la partie scalaire du produit géométrique avec A, B ∈Gn :
A.B =
n
X
r=0
n
X
s=0
⟨⟨A⟩r ⟨B⟩s⟩0
(4.5)

4.1. Algèbres Géométriques
81
4.1.4
Propriété du produit géométrique
Une propriété remarquable du produit géométrique est que pour deux 1-vecteurs x et y de Rn, le
produit géométrique se décompose à l’aide des produits scalaire et externe que nous venons de déﬁnir :
xy = x.y + x ∧y
(4.6)
Lorsque x et y sont orthogonaux, leur produit scalaire est nul. Il ne reste plus que leur produit externe,
or les éléments e1, e2, e3, · · · , en de la base de Rn sont par déﬁnition tous orthogonaux entre eux. On
obtient donc, en les multipliant, les bi-vecteurs de Gn. Les trivecteurs e123, e124, e(n−3)(n−2)(n−1), · · ·
sont le résultat des produits géométriques d’un 1-vecteur de la base avec un bivecteur orthogonal. On
construit ensuite les 4-vecteurs de la base et ainsi de suite jusqu’au n-vecteur de la base qui est unique et
aussi appelé pseudoscalaire. La base complète de Gn est constituée de 2n multivecteurs.
4.1.4.1
Produit Interne
Pour le produit interne, on utilise la Contraction à gauche notée ⌋, cette notion permet de généraliser
la notion d’orthogonalité déﬁnie par le produit scalaire canonique de deux vecteurs de Rn à deux k-
vecteurs, sous-espaces vectoriels de Gn. Si les deux k-vecteurs sont orthogonaux, leur produit interne est
nul. Il se déﬁnit à partir du produit géométrique avec A, B ∈Gn :
A⌋B =
n
X
r=0
n
X
s=0
⟨⟨A⟩r ⟨B⟩s⟩s−r
(4.7)
Encore une fois avec des multivecteurs A et B ∈G3 on peut obtenir le produit interne par le produit
matriciel suivant :
A⌋B ≡












A0
A1
A2
A3
A23
A31
A12
A123
0
A0
0
0
0
A3
−A2
−A23
0
0
A0
0
−A3
0
A1
−A31
0
0
0
A0
A2
−A1
0
−A12
0
0
0
0
A0
0
0
A1
0
0
0
0
0
A0
0
A2
0
0
0
0
0
0
A0
A3
0
0
0
0
0
0
0
A0
























B0
B1
B2
B3
B23
B31
B12
B123












Soient u = u1e1 + u2e2 + u3e3 et v = v1e1 + v2e2 + v3e3 deux 1-vecteurs de G3, dans ce cas, le
produit interne est égal au produit scalaire et vaut :
u.v = u1v1 + u2v2 + u3v3
(4.8)
4.1.5
Notions Complémentaires
4.1.5.1
Réversion
La réversion est une notion qui servira pour déﬁnir notamment l’inverse et aussi la norme. Soit le
multi-vecteur quelconque A = Pn
k=0⟨A⟩k de Gn, sa réversion eA est déﬁnie par :
eA =
n
X
k=0
g
⟨A⟩k
=
n
X
k=0
(−1)
k(k−1)
2
⟨A⟩k
(4.9)
La réversion vériﬁe les propriétés suivantes :

82
CHAP 4 - MODÉLISATION DES COULEURS PAR LES ALGÈBRES GÉOMÉTRIQUES
g
AB = eB eA
^
A + B = eA + eB
(4.10)
De (4.9) on déduit que la réversion d’un multivecteur M de G2 vaut :
f
MG2 = ⟨M⟩0 + ⟨M⟩1 −⟨M⟩2
(4.11)
et celle d’un multivecteur M de G3 vaut :
f
MG3 = ⟨M⟩0 + ⟨M⟩1 −⟨M⟩2 −⟨M⟩3
(4.12)
La notion de réversion correspond à l’équivalent de la notion de conjugaison que nous connaissons
pour les nombres complexes et que nous avons vu avec les quaternions en 3.1.4. En effet, nous l’illustrons
au travers de la déﬁnition de la norme.
4.1.5.2
Norme
La norme de A ∈Gn est déﬁnie par le produit scalaire de A par rapport à sa réversion :
|A| = A · eA =
q
⟨A eA⟩0
(4.13)
Donc pour un multivecteur A de G2 la norme est donnée par :
|A| =
q
A2
0 + A2
1 + A2
2 + A2
3 + A2
12
(4.14)
Nous voyons donc ici qu’il existe une correspondance entre la réversion d’un multivecteur et la
conjugaison complexe ou quaternionique qui permettent également de déﬁnir la norme pour ces deux
autres algèbres. En effet si z ∈C alors |z|2 = zz et si q ∈H alors |q|2 = qq.
4.1.5.3
Inverse
Le produit géométrique est inversible, c’est à dire que pour tout multi-vecteur X de Gn, il existe un
unique multi-vecteur X−1 de Gn tel que XX−1 = 1, avec 1 le scalaire unité de Gn. Certains éléments de
Gn appelés verseurs sont inversibles facilement, il s’agit de ceux pouvant s’exprimer comme un produit
de 1-vecteurs. Cependant tout multivecteur de Gn ne s’exprimera pas avec un tel produit. Par exemple la
somme d’un scalaire et d’un vecteur est un multivecteur mais n’est pas exprimable sous forme de produit
de vecteurs. Grâce à la réversion on peut calculer l’inverse d’un verseur de Gn :
X−1 =
e
X
X e
X
(4.15)
Pour illustrer, si on prend u un 1-vecteur de G3 alors ueu est un scalaire :
ueu = (u1e1 + u2e2 + u3e3)2 = u2
1 + u2
2 + u2
3
(4.16)
on obtient donc u−1 le 1-vecteur de G3 inverse de u par :
u−1 =
eu
u2
1 + u2
2 + u2
3
=
u
u2
1 + u2
2 + u2
3
=
u
|u|2
(4.17)

4.1. Algèbres Géométriques
83
4.1.5.4
Dualité
La dualité déﬁnit une notion d’espace orthogonal : pour un sous-espace F d’un espace vectoriel E,
il existe un sous-espace F⊥de E qui est orthogonal à F vériﬁant la relation suivante : F ⊕F⊥= E.
On déﬁnit, avec In = e123···n le pseudoscalaire, le dual A∗d’un multi-vecteur simple A ∈Gn qui lui
est donc orthogonal par :
A∗= A⌋eIn = −AIn
(4.18)
Le dual d’un 1-vecteur u = u1e1 + u2e2 + u3e3 de G3 est donc :
u∗= u⌋g
e123
= −ue123 = −(u1e1 + u2e2 + u3e3)e123
= −u1e23 −u2e31 −u3e12
(4.19)
Un autre exemple : le dual d’un bivecteur formé par deux 1-vecteurs a et b dans G3 est le 1-vecteur
B∗produit mixte de a × b (règle d’orthogonalité des trois doigts de la main droite) (cf. ﬁgure 4.2).
(a ∧b)∗= a × b
(4.20)
FIG. 4.2 – le 1-vecteur B∗est le dual du bivecteur B = a ∧b dans G3.
4.1.5.5
Propriétés remarquables pour des 1-vecteurs
Par la suite, nous verrons que nous avons choisi de coder les informations couleur sur des 1-vecteurs
de l’algèbre G3. Nous désirons donc mettre ici en évidence des propriétés sur les produits de 1-vecteurs.
Pour deux 1-vecteurs de Gn nous avons la relation suivante : ab = a⌋b + a ∧b. Le produit interne a⌋b
(resp. externe a ∧b) est donc la partie symétrique (resp. antisymétrique) du produit géometrique ab et
peut s’écrire :
a ∧b =1
2(ab −ba)
a⌋b =1
2(ab + ba)
(4.21)
Nous ajoutons ici quelques propriétés qui facilitent souvent les calculs effectués avec des 1-vecteurs
dans Gn.
Soit a un 1-vecteur de Gn, on a alors :
– ea = a ;
– |a| =
p
⟨aea⟩0 =
√
a2 ;
– aea = aa = a2 = |a|2 ;
– a−1 =
ea
aea =
a
aa =
a
|a|2 ;
– aa−1 = a a
|a|2 = |a|2
|a|2 = 1.

84
CHAP 4 - MODÉLISATION DES COULEURS PAR LES ALGÈBRES GÉOMÉTRIQUES
4.1.6
Transformations géométriques
Comme leur nom le suggère, les algèbres géométriques permettent de déﬁnir des transformations
géométriques en utilisant le formalisme des notations algèbriques. La ﬁgure 4.3 indique des exemples de
transformations du plan déﬁnies à partir de 1-vecteurs dans l’algèbre G2 ou G3.
FIG. 4.3 – On déﬁnit les transformations géométriques de base à partir de deux 1-vecteurs v1 et v2 de G2
ou G3 : vt est la translation du vecteur v1 par v2 ; v∥est la projection de v1 sur v2 ; v⊥est la réjection de
v1 par rapport à v2 et vr est la réﬂection de v1 par rapport à v2
4.1.6.1
Translation
Soient v1, v2 et vt des 1-vecteurs de G2 ou G3, la translation vt de v1 par v2 est donnée par leur
somme :
vt = v1 + v2
(4.22)
4.1.6.2
Projection
Soient v1, v2 et v∥des 1-vecteurs de G2 ou G3, la projection v∥(ou bien vv2
∥) de v1 sur v2 est donnée
par :
v∥= (v1⌋v2)v−1
2
(4.23)
4.1.6.3
Réjection
Soient v1, v2 et v⊥des 1-vecteurs de G2 ou G3, la réjection v⊥(ou bien vv2
⊥) de v1 par rapport à v2
est donnée par :
v⊥= (v1 ∧v2)v−1
2
(4.24)
4.1.6.4
Réﬂexion
Soient v1, v2 et vr des 1-vecteurs de G2 ou G3, la réﬂexion vr (ou bien vv2
r ) de v1 par rapport à v2 est
donnée par :
vr = (v1⌋v2)v−1
2
−(v1 ∧v2)v−1
2
= v2v1v−1
2
(4.25)

4.1. Algèbres Géométriques
85
4.1.7
Notation exponentielle et rotation
Il est possible d’utiliser la notation exponentielle avec des bivecteurs. L’introduction du concept
d’exponentielle est issue du fait que l’ensemble des bivecteurs ajouté aux scalaires représente une sous-
algèbre isomorphe à l’algèbre des quaternions elle même isomorphe à celle des complexes. Cette notation
comprend donc une partie scalaire et une partie bi-vectorielle (J étant un bivecteur unitaire).
eJθ = cos θ
|{z}
scalaire
+ sin θJ
| {z }
bivecteur
(4.26)
La notation exponentielle est donc généralisée et nous permet par exemple de représenter les rota-
tions.
L’opération de rotation est souvent exprimée au moyen d’un axe et d’un angle. Cependant on peut
aussi voir la rotation comme une composition de deux réﬂexions d’axe. On ne peut d’ailleurs exprimer les
rotations que par ce moyen lorsque l’on travaillle dans le plan par exemple. Dans la ﬁgure 4.4 on illustre
cette composition de réﬂexions avec le 1-vecteur m′′ qui est le résultat de la réﬂexion du 1-vecteur
m′ d’axe ∆2 lui-même résultat de la réﬂexion du 1-vecteur m d’axe ∆1. Le 1-vecteur m′′ représente
ainsi le résultat de la rotation du 1-vecteur m d’angle θ dans le plan porté par le bivecteur unitaire
J =
d1∧d2
|d1∧d2| = d1∧d2
sin( θ
2 ). On peut aussi dire que m′′ est le résultat de la rotation d’axe ∆et d’angle θ. L’axe
∆porté par le 1-vecteur unitaire d est orthogonal au bivecteur unitaire J, formé par les deux axes de
réﬂexion ∆1 et ∆2, portés par les 1-vecteurs d1 et d2 respectivement. On exprimera donc la rotation sur
le plan porté par le bivecteur J et d’angle θ de la manière suivante (l’angle \
∆1∆2 étant de θ
2) :
m′′ = mrot = d2d1md−1
1 d−1
2
= e−J θ
2 meJ θ
2
(4.27)
FIG. 4.4 – Rotations : m′ est le résultat de la réﬂexion d’axe ∆1 ; m′′ est le résultat de la réﬂexion d’axe
∆2 ; m” est aussi le résultat de la rotation d’angle θ (deux fois l’angle entre les axes ∆1 et ∆2) de m
autour de l’axe ∆mais aussi autour du bivecteur normalisé J =
d1∧d2
|d1∧d2|

86
CHAP 4 - MODÉLISATION DES COULEURS PAR LES ALGÈBRES GÉOMÉTRIQUES
4.1.8
Comparaison de deux 1-vecteurs par le produit géométrique
Soient deux 1-vecteurs a et b de G2 ou G3, nous voulons les comparer en utilisant des outils empruntés
de l’algèbre géométrique. Comme nous l’avons vu, le produit géométrique contient les produits interne
et externe entre les deux vecteurs a et b, en effet ab = a⌋b + a ∧b. Les transformations de base de la
partie précédente sont décrites en utilisant ces deux produits, nous pourrons donc probablement comparer
efﬁcacement les deux vecteurs en utilisant le produit géométrique.
Pour cela, nous observons tout d’abord les propriétés suivantes :
– Si a ∥b alors a ∧b = 0 donc ab = a⌋b.
– Si a ⊥b alors a.b = a⌋b = 0 donc ab = a ∧b.
En général, l’angle entre a et b n’est ni nul ni droit, il sera noté α. Développons maintenant le produit
géométrique de a par b :
ab = a⌋b + a ∧b
= (a⌋b)b−1b + (a ∧b)b−1b
= [(a⌋b)b−1]b + [(a ∧b)b−1]b
(4.28)
Des relations (4.23) et (4.24) on a donc ab = ab
∥b + ab
⊥b.
On a donc ab
∥b = a⌋b une partie scalaire et ab
⊥b = a ∧b une partie bivectorielle. Nous proposons
donc d’exprimer ab par l’intermédiaire d’une notation exponentielle comprenant l’angle α entre les deux
vecteurs a et b.
Comme on utilise le produit géométrique sur des 1-vecteurs, le produit interne est équivalent au
produit scalaire. On utilise donc la géométrie vectorielle aﬁn d’exprimer la partie scalaire. On a donc :
a⌋b = a.b = |a||b| cos α
(4.29)
Il nous faut maintenant exprimer la partie bivectorielle en fonction de l’angle α. Pour cela nous
exprimons la norme du bivecteur a ∧b :
|a ∧b| = |ab
⊥b|
= |ab
⊥||b|( car ab
⊥et b sont orthogonaux)
= |a| sin α|b|
(4.30)
On remarquera que la norme du bivecteur est égale à la norme déﬁnie en géométrie vectorielle du
produit vectoriel de deux vecteurs.
On a donc :
|a ∧b|
|a ∧b|a ∧b = |a||b| sin α a ∧b
|a ∧b|
(4.31)
Si on ajoute (4.29) et (4.31) et que l’on pose J =
a∧b
|a∧b|, avec |J| = 1, on retrouve le produit
géométrique ab sous forme exponentielle :
ab = a⌋b + a ∧b
= cos α|a||b| + |a||b| sin αJ
= |a||b|(cos α + sin αJ)
= |a||b| expαJ
(4.32)
Comme J est le bivecteur unitaire formé par le produit externe de a par b, il représente une portion
du plan dans lequel les deux 1-vecteurs sont présents. Nous venons donc de montrer qu’il est possible de
comparer deux 1-vecteurs simplement en calculant leur produit géométrique. Notre approche a montré
que ce produit géométrique s’exprime alors sous forme exponentielle et met en valeur l’angle entre ces
deux 1-vecteurs dans le plan formé par eux. On utilisera cette relation lors du traitement des images
couleur.

4.1. Algèbres Géométriques
87
On remarque également que le produit ab permet de décrire la moitié de l’opération de rotation
d’angle 2α sur le plan porté par J. Ainsi pour effectuer une rotation sur le 1-vecteur m de 2α sur le plan
porté par J on effectuera l’opération suivante : abm(ba)−1.
4.1.9
Quaternions et algèbres géométriques
L’algèbre des quaternions H est isomorphe à l’algèbre R0,2 de l’espace vectoriel R2 muni de la forme
quadratique
Q(x1, x2) = −x2
1 −x2
2
(4.33)
En effet, soit (e1, e2) une base orthogonale de R2 telle que Q(e1) = Q(e2) = e2
1 = e2
2 = −1, on
réalise un isomorphisme entre R0,2 et H en envoyant e1 sur i, e2 sur j et e1e2 sur k (et évidemment 1 = e0
sur 1). Par ailleurs l’algèbre H s’identiﬁe également à la sous-algèbre de G3 constituée des éléments pairs
de cette dernière. Un élément de G3 est dit pair s’il est combinaison linéaire de scalaires et de bivecteurs.
L’identiﬁcation évoquée est donnée par
1 7−→e0, i 7−→e2 ∧e3, j 7−→e1 ∧e3, k 7−→e1 ∧e2
(4.34)
Mentionnons enﬁn le fait important suivant : le groupe des quaternions unitaires S est isomorphe au
groupe Spin(3) des spineurs de l’algèbre G3. Formellement Spin(3) est déﬁni comme le groupe des
éléments pairs x de G3 de norme 1 vériﬁant la condition suivante :
∀v ∈R3, xvx−1 ∈R3
(4.35)
Il s’avère (puisqu’on est en dimension 3) que cette dernière condition est automatiquement satisfaite,
d’où l’afﬁrmation précédente. Le groupe Spin(3) est intimement lié au groupe SO(3) des transforma-
tions linéaires de R3 de déterminant 1 qui préservent la forme quadratique euclidienne. Plus précisément,
l’application
ϕ : Spin(3) −→SO(3)
déﬁnie par
x 7−→(v 7−→xvx−1)
(4.36)
est un morphisme de groupes surjectif qui est 2 :1 autrement dit, l’ensemble ϕ−1({ϕ(x)}) est constitué
des deux éléments x et −x (cf. ﬁgure 4.5).
FIG. 4.5 – Tout élément x ∈Spin(3) à une image ϕ(x) dans SO(3). De plus, ϕ(x) possède également
un autre antécédent à savoir −x.
Nous allons maintenant étudier comment nous pouvons utiliser ce formalisme pour l’analyse d’images
couleur. Mais tout d’abord nous faisons un bref rappel des premiers travaux à notre connaissance liant
traitement d’image et algèbre géométrique.

88
CHAP 4 - MODÉLISATION DES COULEURS PAR LES ALGÈBRES GÉOMÉTRIQUES
4.2
Approche fréquentielle par algèbres géométriques pour les images en
niveaux de gris
Dans son mémoire de thèse, Felsberg [30] généralise les travaux sur les quaternions de Bülow [8]
sur l’étude des signaux 2D appliqués aux images en niveaux de gris. Pour cela il redéﬁnit tout d’abord
le signal analytique qui s’applique aux signaux 1D et ensuite le signal monogétique, généralisation du
signal analytique aux signaux 2D, en utilisant les formalismes des algèbres géométriques G2 et G3.
Pour un signal 1D la transformée de Fourier déﬁnie par Felsberg est la suivante :
F(u) = F1{f}(u) =
Z ∞
−∞
exp−e122πxu f(x)dx
(4.37)
Avec x = xe1 et u = ue1.
Comme e2
12 = −1 , cette transformée de Fourier est isomorphe à une transformée de Fourier com-
plexe, cependant il faut faire attention car le produit géométrique n’est pas commutatif, donc l’expo-
nentielle doit être conservée sur la gauche. La transformée de Fourier inverse est obtenue en changeant
uniquement le signe dans l’exponentielle. Comme cette transformée de Fourier est isomorphe à la trans-
formée de Fourier complexe, elle permet de mettre en évidence les symétries hermitiennes. Ainsi on
a :
F p(u) = F(u) + F(−u)
2
=
Z ∞
x=−∞
f(x) cos(2πx)dx
F i(u) = −e12(F(u) −F(−u))
2
= −
Z ∞
x=−∞
f(x) sin(2πx)dx
(4.38)
On obtient donc F = Fp + e12Fi avec Fp la partie paire et Fi la partie impaire de la fonction F ce
qui traduit que cette transformée de Fourier est directement liée à l’analyse complexe. En effet il sufﬁt
de remplacer e12 par i pour retrouver cette analyse.
Felsberg considère les signaux 2D comme des surfaces dans des espaces en 3 dimensions, en effet il
considère de tels signaux avec l’écriture suivante :
f(x) = f(xe1 + ye2) = f(x, y)e3
(4.39)
A partir de cette écriture, il déﬁnit pour un signal 2D la transformée de Fourier comme suit :
F2{f}(u) =
Z ∞
y=−∞
Z ∞
x=−∞
f(x) exp−e1232πx.u dxdy
(4.40)
Cette déﬁnition résulte sur une transformée de Fourier qui ressemble plus à la transformée de Fourier
complexe qu’à la transformée de Fourier quaternionique car le noyau comprend le pseudoscalaire qui
commute e123 par déﬁnition avec tous les éléments de l’algèbre. D’ailleurs cette transformée de Fourier
ainsi déﬁnie est en effet isomorphe à la transformée de Fourier complexe.
Selon Felsberg, cette transformée de Fourier peut se séparer en parties paires et impaires :
F p(u) = F(u) + F(−u)
2
=
Z ∞
x=−∞
Z ∞
y=−∞
f(x) cos(2πx.u)dxdy
F i(u) = (F(u) −F(−u))∗
2
= −
Z ∞
x=−∞
Z ∞
y=−∞
f(x) sin(2πx.u)dxdy
(4.41)
Et il suit que F = Fp + Fie123 avec Fp la partie paire et Fi la partie impaire de la fonction F.
Felsberg fait alors remarquer que la déﬁnition des fonctions paires et impaires est le principe fonda-
mental car le reste de l’analyse qui en résulte en dépend. En effet, tandis que la déﬁnition de symétrie
est unique dans le cas 1D, il y a au moins deux façons de déﬁnir des symétries en 2D. Ainsi on peut
déﬁnir une symétrie sur les lignes, mais il est également possible de déﬁnir une symétrie sur les points.
La transformée de Fourier quaternionique déﬁnie par Bülow utilise le principe de la symétrie par lignes

4.3. Approche fréquentielle par algèbres géométriques pour les images couleur
89
car les structures 2D sont analysées plus en détail sur les directions associées aux variations suivant l’axe
horizontal et l’axe vertical. Dans son approche Felsberg déﬁnit quand à lui une analyse des structures 2D
en se basant sur des symétries centrales, autrement dit, des symétries sur des points.
Nous allons maintenant proposer et étudier différentes approches utilisant les algèbres géométriques
pour analyser les images couleur.
4.3
Approche fréquentielle par algèbres géométriques pour les images
couleur
4.3.1
G2 et Images Couleur
Il est possible d’utiliser G2 pour coder l’information couleur d’une image numérique. Par exemple
si on code l’information d’une image couleur par une fonction f à deux variables (x, y) ∈Z2 alors au
point de coordonnées (x, y) la fonction f est égale à : f(x, y) = r(x, y)e0 + v(x, y)e1 + b(x, y)e2 où les
fonctions r, v et b correspondent à chacune des composantes rouge, verte et bleue de l’image.
Nous faisons remarquer au lecteur que le choix de cet encodage de l’information couleur sur l’algèbre
G2, interdit l’utilisation des transformations géométriques couleur que nous déﬁnirons plus tard sur les
vecteurs couleur 3D grâce à l’algèbre géométrique G3. En effet, ces opérations, comme les projections,
les rotations, les réjections ainsi que les translations ne sont déﬁnies dans les algèbres géométriques
que pour des multivecteurs simples, c’est à dire s’exprimant sur un grade unique de l’algèbre. Le choix
effectué ici code l’information rouge sur le grade 0 et les informations verte et bleue sur le grade 1 de
l’algèbre et empêche donc l’utilisation de telles transformations. L’utilisation de G2 n’est donc ici faite
que pour proposer de caractériser des propriétés fréquentielles obtenues par transformée de Fourier. Pour
cela nous proposons de suivre le travail de Brackx et al. [6, 7].
4.3.1.1
Transformée de Fourier Cliffordienne utilisant G2
On parle ici de transformée de Fourier Cliffordienne mais il serait équivalent de parler de transformée
de Fourier par algèbres géométriques.
Deﬁnition
On déﬁnit la Transformée de Fourier Cliffordienne Continue 2D (TFCC2D) sur des vecteurs
de Rn en se basant sur [6, 7] par1 :
F(u) =
Z
R2
exp(2π(u∧x)) f(x)dV (x)
(4.42)
avec u la composante fréquentielle et x la composante spatiale.
Si on choisit de travailler en 2D on choisira les vecteurs u = (u, v) et x = (x, y). L’exponentielle
du produit externe 2D s’exprime par expu∧x = cos(uy −vx) + sin(uy −vx)e12 et est constituée d’une
partie scalaire et d’une partie bivectorielle, on dit alors qu’il est parabivectoriel.
L’équation devient alors :
F(u, v) = FH+[f](u, v) =
Z
R
Z
R
exp(2π(uy−vx)e12) f(x, y)dxdy
(4.43)
On remarque dans cette déﬁnition, contrairement à toutes les déﬁnitions de transformée de Fourier
vues précédemment, que le noyau de la transformée vaut exp2π(u∧x) = exp2π(uy−vx)e12 et s’interprète
différemment. En effet, les transformées que nous utilisions auparavant étaient basées sur le produit
scalaire exp2π(ux+vy)e12 = exp2π(u.x)e12 et non sur le produit extérieur comme ici. La différence est
qu’ici le noyau de la transformée s’exprime au moyen d’une valeur appartenant à l’algèbre géométrique.
L’analyse d’une image devant s’effectuer dans le plan, on utilise le produit extérieur des dimensions
fréquentielle u et spatiale x. On obtient un bivecteur qui représente une portion du plan d’analyse. C’est
1On rappelle qu’une lettre minuscule de police grasse sert à représenter des 1-vecteurs de l’algèbre

90
CHAP 4 - MODÉLISATION DES COULEURS PAR LES ALGÈBRES GÉOMÉTRIQUES
ce bivecteur qui est associé au noyau exponentiel de la transformée de Fourier Cliffordienne et donc
l’analyse sera associée à la notion de plan déﬁni par les 1-vecteurs participant à la construction de ce
bivecteur.
Maintenant si l’on pose le problème des images numériques, la transformée a besoin d’être discré-
tisée. On considère donc une matrice de dimension M × N et un pas d’échantillonage de 1 dans le
domaine spatial.
On aura donc :
– x = m avec m = 0 . . . M −1
– y = n avec n = 0 . . . N −1
– u =
o
M avec o = 0 . . . M −1
– v = p
N avec p = 0 . . . N −1
On obtient alors la transformée de Fourier Cliffordienne discrète (TFCD) comme suit :
F[o, p] = FH+[f][o, p] =
1
√
MN
M−1
X
m=0
N−1
X
n=0
exp(2π( on
M −pm
N )e12) f[m, n]
(4.44)
La transformée inverse est donnée par :
f[m, n] = FH−[f][m, n] =
1
√
MN
M−1
X
o=0
N−1
X
p=0
exp(−2π( on
M −pm
N )e12) F[o, p]
(4.45)
Puisque nous avons la propriété suivante : expae12exp−ae12 = exp0 = 1 pour tout a ∈R, la
transformée donc est inversible sans condition. On remarquera également que cette transformation est
calculable au moyen de transformées de Fourier rapides (cf. annexe A.1).
4.3.1.2
Déﬁnition numérique de l’espace spectral
En appliquant la déﬁnition de la transformée de Fourier Cliffordienne précédente nous souhaitons
savoir si nous pouvons effectuer une analyse de la couleur. Pour cela nous étudions la caractérisation
numérique du spectre correspondant.
Condition d’initialisation
A partir de la formulation de la transformée de Fourier G2 (cf. équation
4.45), nous pouvons déduire les conditions nécessaires pour initialiser le spectre obtenu par la trans-
formée de Fourier G2 inverse aﬁn d’obtenir une image couleur déﬁnie sur la partie scalaire et les deux
parties vectorielles. Ce calcul (cf. annexe A.2) est équivalent aux précédents que nous avions effectués
avec le formalisme des quaternions (cf. section 3.5.1.2).
Nous obtenons donc les conditions générales de symétries du spectre pour pouvoir reconstruire le
signal d’une image couleur par notre transformée de Fourier inverse dans G2 avec ∀(o, p) ∈([−M
2 +
1; M
2 ], [−N
2 + 1; N
2 ]) :
F1 et F2 quelconques
F0[k, l] = F0[−k, −l]
F12[k, l] = −F12[−k, −l]
(4.46)
Il apparaît donc que la partie réelle du spectre est paire alors que la partie bivectorielle est impaire.
Le calcul montre cependant que la partie vectorielle (en e1 et e2) ne présente pas de symétrie particulière.
Inﬂuence d’un Dirac
De la même façon que pour les quaternions, section 3.5.2.3, nous proposons
d’analyser les atomes élémentaires par l’initialisation d’un Dirac (une constante), en respectant les condi-
tions d’initialisation données dans l’équation (4.46), sur le spectre d’une image couleur. Le détail des
calculs est donné à l’annexe A.3.

4.3. Approche fréquentielle par algèbres géométriques pour les images couleur
91
– On initialise la composante scalaire avec F0[k0, l0] = F0[−k0, −l0], la variation obtenue dans le
domaine spatial est paire et décrite par :
f[m, n] = 2F0[o0, p0] cos

2π
o0n
M −p0m
N

(4.47)
– On initialise la composante bivectorielle avec deux Dirac : F12[k0, l0] = −F12[−k0, −l0]. On
obtient une variation impaire dans le domaine spatial :
f[m, n] = −2F12[o0, p0] sin

2π
o0n
M −p0m
N

(4.48)
Dans ces deux cas on obtiendra une variation décrite uniquement sur e0 la composante scalaire
associée dans notre cas à la composante rouge.
– Initialisation sur une composante vectorielle
Il n’existe pas de condition de symétrie sur la partie vectorielle du spectre de notre transformée.
Quelle est donc l’inﬂuence d’une initialisation sur l’une ou l’autre de ces deux composantes ?
– on initialise la première partie vectorielle avec un dirac aux coordonnées (o0, p0) :
f[m, n] =
h
F1[o0, p0] cos

2π
o0n
M −p0m
N
i
e1
+
h
−F1[o0, p0] sin

2π
o0n
M −p0m
N
i
e2
(4.49)
– on initialise la deuxième composante vectorielle avec un dirac aux coordonnées (o0, p0) :
f[m, n] =
h
F2[o0, p0] sin

2π
o0n
M −p0m
N
i
e1
+
h
F2[o0, p0] cos

2π
o0n
M −p0m
N
i
e2
(4.50)
Alors que l’initialisation sur la première composante vectorielle du spectre induit une variation spa-
tiale paire sur la première composante et une variation impaire sur la seconde, l’initialisation fréquentielle
sur la seconde composante vectorielle induit une variation spatiale impaire sur la première composante
et une variation paire sur la seconde. Les informations sont donc mélangées sur les parties vectorielles
du spectre puisqu’on exprime f1 en fonction de F1 et F2 et que la même chose est vraie f2. Bien sûr,
cela s’explique entre autre par le fait que l’on ne force pas de symétrie sur le spectre pour ces deux
composantes donc le mélange de celles-ci ne s’annule pas dans le domaine spatial.
On remarque donc que le spectre n’agit pas de manière équivalente pour chacune des composantes
couleur. Tout d’abord les parties scalaires et bivectorielles sont uniquement réservées à la description
des variations de la composante rouge et ensuite les parties vectorielles décrivent les variations pour les
composantes verte et bleue. De plus, on peut séparer les variations paires de la composante rouge sur la
partie scalaire du spectre tandis que les variations impaires seront décrites par la partie bivectorielle du
spectre. Par contre, du fait qu’il n’existe pas de symétrie sur la partie vectorielle du spectre, les variations
paires de la composante verte seront mélangées avec les variations impaires de la composante bleue sur
la première partie vectorielle du spectre alors que ce sera l’inverse sur la seconde partie vectorielle. Ceci
conﬁrme les réserves émises concernant le mélange des parties scalaire et vectorielle. Il ne nous semble
donc pas pertinent d’associer la couleur à l’analyse spectrale fournie par cette transformée de Fourier car
les informations de couleur ne se retrouvent pas séparées sur des composantes indépendantes du spectre.
4.3.1.3
Filtrage fréquentiel
Nous allons cependant étudier les possibilités offertes par cette transformée en termes de ﬁltrage aﬁn
d’afﬁrmer ou d’inﬁrmer les conclusions que nous avons obtenu sur le plan théorique.
Equivalence produit de convolution spatial, produit fréquentiel ?
Le produit de convolution pour
G2 est déﬁni de la manière suivante [6] :

92
CHAP 4 - MODÉLISATION DES COULEURS PAR LES ALGÈBRES GÉOMÉTRIQUES
f ∗g(x) =
Z
R2 f(x −x’)g(x’)dV (x’)
(4.51)
Il est indiqué dans [6, 7] que l’équivalence directe entre produit de convolution spatial et produit
fréquentiel n’est pas vériﬁée. Cependant il existe une relation plus complexe basée sur la séparation entre
partie vectorielle ⃗f(x, y) = f1(x, y)e1+f2(x, y)e2 et parabivectorielle (partie scalaire plus bivectorielle)
f p(x, y) = f0(x, y)e0 + f12(x, y)e12 d’un élément de G2 :
FH+[f ∗g][u, v] = FH+[f p ∗g][u, v] + FH+[⃗f ∗g][u, v]
(4.52)
avec
FH+[f p ∗g][u, v] = FH+[f p][u, v]FH+[g][u, v]
(4.53)
et
FH+[⃗f ∗g][u, v] = FH+[⃗f][u, v]FH−[g][u, v]
(4.54)
Comme la fonction f vaut f p + ⃗f le théorème de convolution comporte deux termes :
FH+[f ∗g][u, v] = FH+[f p][u, v]FH+[g][u, v] + FH+[⃗f][u, v]FH−[g][u, v]
(4.55)
On comprendra alors que le produit de convolution spatial est équivalent au produit fréquentiel uni-
quement pour la composante rouge qui dans notre cas est analysée par la partie para-bivectorielle. Au
contraire pour les informations spectrales associées aux deux autres composantes couleurs qui sont mé-
langées cette équivalence est perdue. Comme nous le constatons, il existe bien une relation qui associe
la transformée de Fourier au produit de convolution. Cependant il n’apparaît pas aisé de l’interpréter
(comme par exemple en termes de gain fréquentiel de ﬁltre). Les auteurs du papier [6, 7] remarquent
aussi cette relation d’équivalence mais ne fournissent pas non plus d’éléments d’interprétation.
Application : Multiplication du spectre par une gaussienne
Nous avons voulu ici illustrer l’inﬂuence
de la multiplication du spectre par une fonction réelle et évaluer le résultat après transformée de Fourier
inverse. La ﬁgure 4.6 illustre le résultat de la multiplication par une fonction gaussienne du spectre de
l’image couleur d’origine. L’image résultat est ensuite obtenue par transformation de Fourier inverse du
spectre modiﬁé suivant :
f[m, n] = FH−(F[o, p]G[o, p])
(4.56)
Une gaussienne 2D centrée en (m0, n0) avec α l’amplitude et σ l’écart type est la fonction réelle
suivante :
g[m, n] = αe−(m−m0)2+(n−n0)2
2σ2
(4.57)
Le résultat obtenu à la ﬁgure 4.6c montre qu’en multipliant le spectre par une gaussienne qui sélec-
tionne les basses fréquences, on obtient une image ﬁltrée dont les contours on été fortement atténués.
La gaussienne a été appliquée de manière indépendante sur chacune des composantes du spectre. Ce-
pendant, l’image obtenue après transformée de Fourier inverse n’est pas un produit de convolution de
l’image d’origine par une gaussienne, car :
FH−(F[o, p]G[o, p]) = FH−(⃗F[o, p]G[o, p]) + FH−(F p[o, p]G[o, p])
= FH−(⃗F[o, p]G[o, p]) + FH−(f p ∗g)[m, n]
̸= FH−(⃗f ∗g)[m, n] + FH−(f p ∗g)[m, n]
(4.58)

4.3. Approche fréquentielle par algèbres géométriques pour les images couleur
93
(a)
(b)
(c)
FIG. 4.6 – Première ligne : (a) image originale, (b) gaussienne 2D (les coordonnées sont centrées au
milieu de l’image) ; Deuxième ligne : (c) image ﬁltrée
4.3.1.4
Conclusion
L’hypothèse de l’utilisation de l’algèbre géométrique G2 pour les images couleur était que cette al-
gèbre était adaptée à la déﬁnition d’une analyse spectrale des images couleur par une transformée de
Fourier Cliffordienne et pourquoi pas au formalisme de description des structures en deux dimensions
comme déﬁnies par l’équipe de Kiel (Sommer, Büllow et Felsberg). Cependant de part l’encodage des
informations couleur sur des entités complètement différentes de l’algèbre par nature (utilisation des par-
ties scalaire et vectorielle), il n’est pas possible de déﬁnir des opérations géométriques manipulant les
couleurs au sein de l’espace spatial. Nous avons alors cherché à caractériser numériquement le spectre
cliffordien en décrivant ses symétries relatives à la déﬁnition du codage spatial d’une image. En utilisant
la transformée de Fourier que nous avons déﬁni, il est apparu que la partie scalaire doit être paire, la
partie bivectorielle impaire pour retomber dans le domaine de déﬁnition d’une image après transformée
inverse. De plus, il n’existe pas de symétrie sur la partie vectorielle. En interprétant le contenu fréquen-
tiel du spectre, on constate que la partie scalaire de l’image est décrite avec ses variations paires sur la
partie scalaire du spectre et ses variations impaires sur la partie bivectorielle du spectre. Les informa-
tions correspondant aux deux autres composantes couleur sont mélangées au sein de la partie vectorielle
du spectre (il n’y a pas de symétrie sur cette partie fréquentielle). Nous avons donc la conclusion lo-
gique que la structure numérique du spectre n’attache pas la même importance à toutes les composantes
couleur car elles n’y sont pas analysées de la même façon. Pour toutes ces raisons, nous pensons que
l’interprétation fréquentielle couleur des images en utilisant cette transformée de Fourier dans G2 n’est
pas satisfaisante. Il est alors peut-être possible de déﬁnir une analyse spectrale des images couleur avec
ce formalisme mais à mon avis ce ne pourra pas être fait avec une seule TF. Il faudra donc certainement
séparer les canaux couleur à analyser et donc déﬁnir par là, plusieurs TF pour analyser l’image complète.
Cette approche n’est pas dans le cadre de notre étude car elle ne prendrait pas en compte l’information
couleur dans sa globalité, même si elle rajouterait des précisions en terme d’analyse de structures 2D, de
la même façon que la TF en niveaux de gris de Bülow.
Nous allons maintenant étudier l’algèbre géométrique G3 qui présente beaucoup plus d’avantages
que G2 dans la manipulation ainsi que l’analyse des couleurs.

94
CHAP 4 - MODÉLISATION DES COULEURS PAR LES ALGÈBRES GÉOMÉTRIQUES
4.3.2
G3 et images couleur
4.3.2.1
Les quaternions sous algèbre de G3
La section 4.1.9 nous a montré que les quaternions pouvaient être vus comme une sous-algèbre paire
de G3. Ceci revient à dire que lors de notre étude des quaternions appliqués aux images couleur nous
avions codé l’information colorimétrique sur les trois parties bivectorielles d’un multivecteur de G3. Une
transformation de Fourier utilisant les bivecteurs de G3 est donc construite en généralisant celle déﬁnie
avec les quaternions (cf. équation 3.25) par l’identiﬁcation donnée dans la sous-section 4.1.9. Cependant
nous avons déjà analysé une telle transformation. Dans cette partie, nous allons déﬁnir une nouvelle
transformée de Fourier appliquée aux images couleur utilisant l’algèbre géométrique G3. La manière
dont sera encodée la couleur préservera la possibilité d’effectuer des transformations géométriques sur les
vecteurs couleur. En effet nous proposons qu’une couleur soit considérée comme un 1-vecteur de G3. On
codera donc l’image par une fonction de Z2 →G3 avec f[m, n] = f1[m, n]e1 +f2[m, n]e2 +f3[m, n]e3
pour une image RVB.
Avec f1, f2 et f3 trois fonctions représentant les composantes couleurs nécessaires pour coder l’in-
formation par exemple rouge, vert et bleu dans un espace RV B (cf. ﬁgure 4.7).
FIG. 4.7 – Réprésentation de l’espace couleur RV B avec G3 ; le 1-vecteur r = e1 représente un rouge
pur ; v = e2 représente le vert ; b = e3 représente le bleu ; on déﬁnit µ = r+v+b
√
3
le vecteur représentant
les niveaux de gris et ν = (r ∧µ)µ−1 la réjection de r par rapport à µ.
4.3.2.2
Déﬁnition d’une « transformation de Fourier Cliffordienne couleur »
Dans une image de dimension M × N, on déﬁnira la « transformation de Fourier Cliffordienne
couleur » dans G3 discrète (TFCG3D) par :
Pour o = 0, ..., M −1 et p = 0, ..., N −1
F[o, p] =
1
√
MN
M−1
X
m=0
N−1
X
n=0
f[m, n] exp−2πe123( om
M + pn
N )
(4.59)
o et p étant les coordonnées dans le domaine fréquentiel tandis que m et n sont les coordonnées dans
le domaine spatial.
On observe que le noyau de la transformée est différent de celui de la déﬁnition donnée dans [6,
7], en effet ici, on revient à la déﬁnition classique contenant une somme et non une différence sur les
coordonnées dans les exponentielles. On utilisera ici le fait que le pseudoscalaire e123 commute avec
tous les éléments de la base de G3 pour distribuer l’information spectrale sur les différentes composantes
comme nous le verrons. Nous n’utilisons donc pas une stratégie de distribution de l’information suivant
les axes horizontaux et verticaux comme l’équipe de Kiel.

4.3. Approche fréquentielle par algèbres géométriques pour les images couleur
95
En revanche le produit de G3 n’est pas commutatif, il est donc possible de déﬁnir d’autres transfor-
mations de Fourier de la même façon qu’avec les quaternions : les transformées de Fourier discrètes à
droite, à gauche et à deux côtés.
Comme pour la plupart des transformées de Fourier hypercomplexes [31], [27], [55] et [24], il est
possible d’effectuer la transformation de Fourier Cliffordienne couleur déﬁnie précédemment en utilisant
des transformations de Fourier complexes rapides classiques. Ceci permet des temps de calculs améliorés
de manière à pouvoir effectuer cette transformation sur des images numériques de façon plus aisée. La
décomposition est détaillée dans l’annexe B.1.
Dans [47], il est déﬁni une transformée de Fourier continue Cliffordienne équivalente à notre trans-
formée de Fourier Cliffordienne discrète couleur utilisant G3. Cette transformée de Fourier est étudiée
en détails et il apparaît que les propriétés basiques des transformées de Fourier complexes sont conser-
vées. Comme l’élément de l’algèbre géométrique du noyau est e123 et que dans G3 c’est un élément qui
commute avec tous les autres, la transformée de Fourier ainsi déﬁnie conserve :
– la linéarité : si f(x) = αf1(x) + βf2(x) alors F{f}(u) = αF{f1}(u) + βF{f2}(u) ;
– retard : si fd(x) = f(x −a) alors F{fd}(u) = e−e123u.xF{f}(u) ;
– facteur d’échelle : si a ∈R+ et fa(x) = f(ax) alors F{fa}(u) =
1
a3 F{f}(u
a) ;
– shift : si u0 ∈R3 et f0(x) = f(x)ee123u0.x alors F{f0}(u) = F{f}(u-u0) ;
– dérivée : F{▽f}(x) = e123uF{f}(u) ;
– théorème de convolution : F{f1 ∗f2}(x) = F{f1}(u)F{f2}(u).
Ces propriétés théoriques très intéressantes ont été développées de manière totalement indépendantes
de nos travaux.
Calcul général numérique
Tout comme pour les quaternions, nous développons la partie cartésienne
de l’expression de la transformée de Fourier déﬁnie par l’équation (4.59). Le calcul en détail est fourni
dans l’annexe B.2.
On découpe donc l’information couleur du pixel f de coordonnées m et n en trois composantes,
rouge r[m, n] = f1[m, n], verte v[m, n] = f2[m, n] et bleue b[m, n] = f3[m, n].
F[o, p] =
1
√
MN
M
2
X
m=−M
2 +1
N
2
X
n=−N
2 +1
[f1[m, n]e1 + f2[m, n]e2 + f3[m, n]e3] cos
h
2π
om
M + pn
N
i
+ [−f1[m, n]e23 −f2[m, n]e31 −f3[m, n]e12] sin
h
2π
om
M + pn
N
i
(4.60)
On remarque que le spectre ne contient pas d’information sur ses parties scalaires et trivectorielles.
Par contre l’information de couleur est séparée sur la partie vectorielle pour les variations paires et
la partie bivectorielle pour les variations impaires. On voit aussi que chacune des variations impaires
décrites dans la partie bivectorielle est associée à la composante duale de la partie vectorielle. Autrement
dit e23 est associé à f1, e31 est associé à f2 et e12 est associé à f3. Chaque composante couleur est
donc traitée de la même façon dans le spectre ce qui est déjà complétement différent de ce que nous
avions constaté avec la transformée de Fourier Cliffordienne dans G2. On peut dire que cette transformée
de Fourier Cliffordienne qui utilise la partie pseudoscalaire dans le noyau de l’exponentielle est donc
équivalente à une transformée de Fourier marginale qui consiste à appliquer une transformée de Fourier
complexe sur chaque composante couleur.

96
CHAP 4 - MODÉLISATION DES COULEURS PAR LES ALGÈBRES GÉOMÉTRIQUES
Transformée de Fourier inverse
Il est également possible de développer l’expression de la transfor-
mée de Fourier inverse (cf. annexe B.3) :
f[m, n] =
1
√
MN
M
2
X
o=−M
2 +1
N
2
X
p=−N
2 +1
h
F0[o, p] cos
h
2π
om
M + pn
N
i
−F123[o, p] sin
h
2π
om
M + pn
N
ii
e0
+
h
F1[o, p] cos
h
2π
om
M + pn
N
i
−F23[o, p] sin
h
2π
om
M + pn
N
ii
e1
+
h
F2[o, p] cos
h
2π
om
M + pn
N
i
−F31[o, p] sin
h
2π
om
M + pn
N
ii
e2
+
h
F3[o, p] cos
h
2π
om
M + pn
N
i
−F12[o, p] sin
h
2π
om
M + pn
N
ii
e3
+
h
F23[o, p] cos
h
2π
om
M + pn
N
i
+ F1[o, p] sin
h
2π
om
M + pn
N
ii
e23
+
h
F31[o, p] cos
h
2π
om
M + pn
N
i
+ F2[o, p] sin
h
2π
om
M + pn
N
ii
e31
+
h
F12[o, p] cos
h
2π
om
M + pn
N
i
+ F3[o, p] sin
h
2π
om
M + pn
N
ii
e12
+
h
F123[o, p] cos
h
2π
om
M + pn
N
i
+ F0[o, p] sin
h
2π
om
M + pn
N
ii
e123
(4.61)
Ce calcul va nous servir à déﬁnir les propriétés de symétrie du spectre obtenu par la transformée de
Fourier Cliffordienne d’une image numérique couleur.
Déﬁnition numérique de l’espace de Fourier « Cliffordien »
– Conditions d’initialisation du spectre :
Encore une fois le calcul est le même que celui utilisé avec les quaternions, donc pour pouvoir
reconstruire le signal d’une image couleur par notre transformée de Fourier inverse il faudra res-
pecter les conditions générales de symétrie du spectre qui suivent avec ∀o ∈[−M
2 + 1; M
2 + 1] et
p ∈[−N
2 + 1; N
2 + 1]2 :
F0[o, p] = 0
F1[o, p] = F1[−o, −p]
F2[o, p] = F2[−o, −p]
F3[o, p] = F3[−o, −p]
F23[o, p] = −F23[−o, −p]
F31[o, p] = −F31[−o, −p]
F12[o, p] = −F12[−o, −p]
F123[o, p] = 0
(4.62)
De nouveau, nous cherchons à décrire les fonctions analysantes à partir du protocole déjà expliqué
(cf. annexe B.5).
– Initialisation sur une composante vectorielle :
L’initialisation est effectuée avec F1[o0, p0] = F1[−o0, −p0], on obtient la variation spatiale sui-
vante :
f[m, n] = 2F1[o0, p0] cos
h
2π
o0m
M
+ p0n
N
i
e1
(4.63)
Le même type de variation est obtenu en initialisant le spectre sur la deuxième ou la troisième
composante vectorielle.
– Initialisation sur une composante bi-vectorielle :
L’initialisation est effectuée avec F23[o0, p0] = −F23[−o0, −p0], on obtient la variation spatiale
suivante :

4.3. Approche fréquentielle par algèbres géométriques pour les images couleur
97
f[m, n] = −2F23[o0, p0] sin
h
2π
o0m
M
+ p0n
N
i
e1
(4.64)
On obtient le même résultat avec la deuxième ou troisième composante bi-vectorielle.
On remarquera ici que les informations fréquentielles sont séparées. En effet, les composantes
vectorielles du spectre correspondent aux variations paires du domaine spatial pour chaque canal
séparément. De plus, les variations impaires du signal sont elles aussi récupérées par notre trans-
formée de Fourier et également indépendamment sur chaque composante bivectorielle du spectre.
Illustration dans l’espace couleur RVB
– Différentes initialisations :
Lorsqu’on initialise un point fréquentiel sur une ou plusieures parties imaginaires du spectre (cf.
ﬁgure 4.8), en utilisant la transformée de Fourier Cliffordienne couleur inverse, nous obtenons
comme décrit dans la partie précédente, des oscillations de couleurs. La couleur dominante de ces
oscillations correspond à l’axe ou aux axes concernés par l’initialisation si celle-ci est faite sur
une composante vectorielle. On voit que la variation est décrite pour les sous-ﬁgures a, b et d par
la couleur rouge lorsque qu’on initialise le spectre avec F1, verte avec F2 et magenta somme du
rouge et du bleu avec F1 et F3. La sous-ﬁgure c présente une variation de couleur bleue car le
spectre est initialisé par F12 qui est le dual de l’axe vectoriel F3 représentant le bleu. On constate
aussi le décalage de phase entre cette troisème sous-ﬁgure et les autres. En effet, la variation est
impaire lorsqu’on l’initialise le spectre sur une composante bivectorielle alors qu’elle est paire si
on l’initialise avec une composante vectorielle.
(a) F1(2, 2) = F1(−2, −2) = K
(b) F2(2, 2) = F2(−2, −2) = K
(c) F12(2, 2) = −F12(−2, −2) = K
(d)
F1(2, 2) = F1(−2, −2) = K
F3(2, 2) = F3(−2, −2) = K
FIG. 4.8 – Initialisation du spectre sur différentes composantes
– Variations géométriques :

98
CHAP 4 - MODÉLISATION DES COULEURS PAR LES ALGÈBRES GÉOMÉTRIQUES
Nous pouvons régler aussi l’orientation des variations de couleur suivant les coordonnées des
points affectés en amplitude dans le domaine fréquentiel. Cette orientation suivra un axe perpen-
diculaire à la droite reliant les deux points affectés par l’initialisation d’amplitude fréquentielle et
passant par l’origine. On se place dans un repère d’interprétation où l’origine est située au centre
de l’image.
Nous choisissons par exemple pour la ﬁgure suivante (cf. ﬁgure 4.9) d’illustrer différentes orienta-
tions spatiales en fonction des points du plan fréquentiel initialisés en amplitude (oscillations dans
le jaune).
F1(2, 2) = F1(−2, −2) = K
F2(2, 2) = F2(−2, −2) = K
F1(2, −2) = F1(−2, 2) = K
F2(2, −2) = F2(−2, 2) = K
FIG. 4.9 – Variations Géométriques
4.3.2.3
Filtrage fréquentiel couleur avec G3
Comme précédemment, nous pouvons nous servir de l’analyse spectrale de notre transformée de
Fourier aﬁn d’effectuer un schéma de ﬁltrage fréquentiel. Celui-ci est obtenu par fenêtrage dans le do-
maine fréquentiel d’une image. Ensuite nous effectuons une transformation de Fourier Cliffordienne
inverse pour obtenir l’image spatiale ﬁltrée. Les coefﬁcients du ﬁltre sont choisis aﬁn de sélectionner les
fréquences voulues. Les résultats obtenus sont illustrés par la ﬁgure 4.10.
Nous venons donc de voir qu’il est possible d’utiliser une transformation de Fourier Cliffordienne
déﬁnie dans G3 pour analyser l’information fréquentielle des images couleur. Nous proposons mainte-
nant d’utiliser ce même formalisme aﬁn de déﬁnir des opérations de manipulation des couleurs dans le
domaine spatial.
4.4
Approche spatiale par algèbres géométriques pour les images couleur
Comme dans la partie déﬁnissant la transformée de Fourier Cliffordienne précédente, nous choi-
sissons d’encoder l’information couleur associée à l’espace RV B sur les trois parties vectorielles d’un
multivecteur de G3. Nous proposons tout d’abord d’exprimer ces composantes RV B, grâce à l’utilisation
des transformations géométriques de G3, en termes de composantes perceptuelles, c’est à dire en teinte,
saturation et clarté.
4.4.1
Exprimer les couleurs RV B dans un espace Teinte Saturation Intensité
4.4.1.1
Teinte, saturation et intensité en fonction d’un 1-vecteur m
De la même manière qu’il est possible d’exprimer un quaternion donné en RVB (Rouge Vert Bleu)
sous forme de Teinte, Saturation, Intensité (cf. section 3.2.3), les transformations géométriques nous
permettent d’exprimer un pixel couleur m donné dans l’espace RVB avec l’algèbre G3 également sous

4.4. Approche spatiale par algèbres géométriques pour les images couleur
99
image originale
Passe-Bas 8
Passe-Haut 8
Passe-Bas 16
Passe-Bas 32
Passe-Haut 32
FIG. 4.10 – Lenna et son résultat après application de différents ﬁltres fréquentiels
cette forme (cf. ﬁgure 4.11). On obtient donc une généralisation de cette écriture quaternionique exprimée
dans [35] avec le formalisme G3.
FIG. 4.11 – On peut donner les équivalents de teinte T, saturation S et intensité I pour n’importe quel
1-vecteur m exprimé dans l’espace couleur RVB. Ici µ représente l’axe des niveaux de gris et ν est la
réjection par rapport à µ du vecteur représentant le rouge pur.
Soient µ le 1-vecteur portant l’axe des niveaux de gris, r celui portant le vecteur couleur rouge pur,
et m un 1-vecteur couleur quelconque.
– L’intensité est la norme de la projection du 1-vecteur couleur RV B m sur l’axe des niveaux de
gris µ, elle s’exprime par :

100
CHAP 4 - MODÉLISATION DES COULEURS PAR LES ALGÈBRES GÉOMÉTRIQUES
I = |(m⌋µ)µ−1|
(4.65)
– La saturation est la distance du vecteur couleur RV B m par rapport à l’axe des niveaux de gris,
c’est donc la norme de la réjection du vecteur couleur par rapport à cet axe :
S = |(m ∧µ)µ−1|
(4.66)
– La teinte est l’angle entre un 1-vecteur de référence que l’on notera ν (réjection du 1-vecteur r par
rapport à µ par exemple) et la réjection du 1-vecteur m par rapport à µ (cf. ﬁgure 4.12).
FIG. 4.12 – Pour trouver la teinte T, on se place dans le triangle ABC rectangle en A. On obtient
tan(T) = ∥⃗
AB∥
∥⃗
AC∥.
∥⃗
AB∥est la norme de la projection du vecteur m sur le vecteur (µ ∧ν)∗.
∥⃗
AB∥=
(m ∧(µ ∧ν)∗)(µ ∧ν)∗−1 =
(m ∧(µν)∗)(µν)∗−1
∥⃗
AC∥est la norme de la projection du vecteur m sur le vecteur ν.
∥⃗
AC∥=
(m ∧ν)ν−1
La teinte est donc obtenue par la formule suivante :
T = tan−1
 (m ∧µν∗)(µν∗)−1
|(m ∧ν)ν−1|
!
= ∥⃗
AB∥
∥⃗
AC∥
(4.67)
On a |µ| = |ν| = 1 et µ ⊥ν donc µ ∧ν = µν, (µ ∧ν)∗= (µν)∗et |µν| = |(µν)∗| = 1
4.4.1.2
Le 1-vecteur m exprimé en fonction de la teinte, la saturation et l’intensité
Nous pouvons exprimer la teinte, la saturation et l’intensité d’un vecteur m exprimé dans la base
RVB. Il serait maintenant intéressant de pouvoir effectuer la conversion dans l’autre sens c’est à dire, de
pouvoir exprimer le vecteur m en fonction de sa teinte, sa saturation et son intensité. Les informations
de saturation et d’intensité peuvent être retrouvées facilement en utilisant les mêmes transformations
géométriques que dans la partie précédente. Il nous faut cependant pouvoir exprimer la teinte au moyen
des outils de l’algèbre G3. Cette teinte T est l’angle entre ν (réjection de r par rapport à µ) et la réjection
de m par rapport à µ que nous appelerons m⊥.
Nous disposons des 1-vecteurs suivants : r, m, µ, ν = (r ∧µ)µ−1.

4.4. Approche spatiale par algèbres géométriques pour les images couleur
101
|r| = |µ| = |ν| = 1
m⊥= (m ∧µ)µ−1
T est l’angle entre m⊥et ν, nous pouvons donc le faire apparaître par l’intermédiaire du produit
géométrique entre ces deux 1-vecteurs m⊥ν = |m⊥||ν| exp
m⊥∧ν
|m⊥∧ν| T = |m⊥| exp
m⊥∧ν
|m⊥∧ν| T .
Comme m⊥et ν sont des réjections par rapport à µ, le bivecteur qui leur est associé est orthogonal à
µ et donc colinéaire au dual de µ d’où
m⊥∧ν
|m⊥∧ν| = µ∗.
Nous avons vu que |m⊥| = |(m ∧µ)µ−1| = S, nous obtenons donc m⊥ν = S expµ∗T .
Et par conséquent :
m⊥ν = S expµ∗T
m⊥νν−1 = S expµ∗T ν−1
m⊥= S expµ∗T ν−1
m⊥= S expµ∗T ν
Nous pouvons conclure qu’il est possible d’écrire un vecteur m exprimé dans la base RV B en
fonction de sa teinte, sa saturation et son intensité telle que :
m = m∥+ m⊥
m = Iµ + m⊥
m = Iµ + Seµ∗T ν
(4.68)
Il nous reste à exprimer les composantes rouge, verte et bleue d’un multivecteur m en fonction de
l’équation (4.68).
Pour cela, sachant que m s’exprime par Iµ+Seµ∗T ν, que µ est ici l’axe des niveaux de gris e1+e2+e3
√
3
et que ν est le 1-vecteur unitaire portant la réjection du vecteur rouge e1 par rapport à µ :
ν =
q
2
3e1 −e2
√
6 −e3
√
6.
On développe le calcul :
Iµ = I e1 + e2 + e3
√
3
µ∗= −e23 + e31 + e12
√
3
µ∗ν =
√
2(e2 −e3)
2
Seµ∗T ν = S cos(T)ν + S sin(T)µ∗ν
= S cos(T)
 r
2
3e1 −e2
√
6
−e3
√
6
!
+ S sin(T)
 √
2
2 (e2 −e3)
!
On peut donc exprimer m en fonction de e1, e2 et e3 :
m = Iµ + Seµ∗T ν
=
"
I +
√
2S cos(T)
√
3
#
e1
+
 I
√
3
−S
√
2
cos(T)
√
3
−sin(T)

e2
+
 I
√
3 −S
√
2
cos(T)
√
3
+ sin(T)

e3
(4.69)
Et ainsi, comme chaque composante vectorielle est associée à un canal couleur, on obtient :

102
CHAP 4 - MODÉLISATION DES COULEURS PAR LES ALGÈBRES GÉOMÉTRIQUES

















r = I +
√
2S cos(T)
√
3
v = I
√
3 −S
√
2
cos(T)
√
3
−sin(T)

b = I
√
3
−S
√
2
cos(T)
√
3
+ sin(T)

(4.70)
Ces relations vont nous permettre de modéliser des transformations couleur.
4.4.2
Transformations géométriques couleur
4.4.2.1
Projection
On peut utiliser la projection pour réaliser des transformations couleur sur nos images. Par exemple
en projetant une image originale sur les axes rouge, vert ou bleu on obtient les différents canaux couleur
de l’image comme illustré dans la ﬁgure 4.13. Il est aussi possible comme nous l’illustrons ﬁgure 4.13f
d’obtenir l’image en niveaux de gris en projetant l’image d’origine sur l’axe des intensités ou axe des
niveaux de gris. En prenant δ le 1-vecteur sur lequel sera projeté l’image I, on obtient l’image I′ telle
que :
I′(x, y) = (I(x, y)⌋δ)δ−1
(4.71)
Chaque couleur sera donc projetée sur l’axe δ.
On remarquera qu’il est aussi possible d’effectuer des projections sur des 1-vecteurs particuliers
selon l’application. Ainsi la ﬁgure 4.13d illustre la projection effectuée sur le 1-vecteur e1 + e2. On re-
marque dans le résultat que la projection est cohérente avec la synthèse additive des couleurs. En effet,
en synthèse additive, le jaune résulte de la somme du rouge et du vert. C’est pour cela que sur l’image
résultat le jaune a son maximum d’intensité à l’endroit même ou les cercles rouge et vert s’entrecroi-
saient. Cependant on remarque aussi que comme le jaune est composé de rouge, la zone purement rouge
est aussi détectée lors de la projection. Il en est de même avec la zone verte. Le bleu étant orthogonal
aux couleurs rouge et verte, il n’apparait pas dans cette ﬁgure. Le 1-vecteur sur lequel sera projeté les
couleurs peut donc être décrit avec des poids différents selon les composantes. Ceci est illustré avec la
ﬁgure 4.13e pour laquelle on a appliqué une projection sur le 1-vecteur v = 0.5e2 + 0.2e3. Encore une
fois, là ou les deux composantes e2 et e3 apportent le même niveau maximum dans l’image d’origine,
le résultat correspond exactement à la description du vecteur. On pourra donc se servir de l’opération
de projection sur des images couleur pour faire apparaître les couleurs de l’image antagonistes à celle
utilisée dans l’axe de la projection.
4.4.2.2
Rotations
Il est possible tout comme nous l’avons fait avec les projections d’effectuer des rotations dans l’es-
pace couleur. La ﬁgure 4.14 illustre ce type d’opération avec ici un axe de rotation égal à l’axe des
niveaux de gris et un angle de 2π
3 . Le résultat modiﬁe la teinte originale de l’image comme nous le ver-
rons dans la partie suivante. Cependant il est aussi possible d’utiliser des axes différents pour effectuer
des rotations couleur. Les résultats ne s’exprimeront par contre plus en termes de variation de teinte.
4.4.2.3
Modiﬁcation des caractéristiques colorimétriques
On va pouvoir utiliser l’expression du 1-vecteur couleur m en fonction des paramètres correspondant
de teinte, intensité et saturation pour effectuer des opérations de modiﬁcation de ces trois caractéristiques
couleur. Nous avons pour cela généralisé le formalisme exprimé avec les quaternions dans [35] aux
algèbres géométriques.

4.4. Approche spatiale par algèbres géométriques pour les images couleur
103
(a)
(b)
(c)
(d)
(e)
(f)
FIG. 4.13 – Image originale (a) et sa projection sur les axes rouge e1 (b), vert e2 (c), jaune e1 + e2 (d),
0.5e2 + 0.2e3 (e) et sur l’axe des niveaux de gris e1 + e2 + e3 (f).
Changement de teinte
La teinte des couleurs peut être modiﬁée en utilisant les rotations autour de
l’axe des niveaux de gris. Pour modiﬁer la teinte, on utilisera la rotation du vecteur couleur m autour de
l’axe des niveau de gris µ, ou bien de façon équivalente, autour du bivecteur unitaire µ∗, dual de µ (cf.
équation 4.15).
On pourra dès lors effectuer une modiﬁcation de la teinte en se basant sur ce qui suit :

104
CHAP 4 - MODÉLISATION DES COULEURS PAR LES ALGÈBRES GÉOMÉTRIQUES
(a)
(b)
FIG. 4.14 – Image originale (a) et sa rotation d’un angle de 2π
3 (b).
FIG. 4.15 – Modiﬁcation de la teinte
m′ = e−µ∗θ
2 meµ∗θ
2
m′ = Ie−µ∗θ
2 µeµ∗θ
2 + Se−µ∗θ
2 eµ∗T νeµ∗θ
2
m′ = Iµ + Seµ∗(T+θ)ν
T ′ = T + θ
(4.72)
Ie−µ∗θ
2 µeµ∗θ
2 = Iµ car le vecteur µ est l’axe de la rotation.
La ﬁgure 4.16 illustre un tel changement de teinte. L’image d’origine (a) a été modiﬁée par une
rotation de l’ensemble de ses pixels couleur par une rotation autour de l’axe des niveaux de gris d’un
angle de π
3 . Ainsi le toit rouge se retrouve vert, le seuil vert se retrouve bleu, etc.
Modiﬁcation de la saturation
Pour modiﬁer la saturation il faut effectuer une translation de m d’un
vecteur pondéré par le coefﬁcient β ∈R suivant l’axe des saturations µ, c’est à dire sa réjection par
rapport à µ (cf. ﬁgure 4.17)
On obtient alors :
m′ = Iµ + S′eµ∗T νm′ = m + βeµ∗T ν
m′ = Iµ + (S + β)eµ∗T ν
S′ = S + β
(4.73)

4.4. Approche spatiale par algèbres géométriques pour les images couleur
105
(a)
(b)
FIG. 4.16 – Modiﬁcation de la teinte
FIG. 4.17 – Modiﬁcation de la saturation
La ﬁgure 4.18 illustre un tel changement de saturation. L’image d’origine (a) a été modiﬁée de la
façon décrite en (4.73) pour obtenir l’image (b). L’effet produit par ce type d’opération est le suivant :
– Lorsqu’on retire de la saturation à l’image, comme dans le cas de la ﬁgure 4.18, l’image obtenue
présente des couleurs pâles ou délavées par rapport à l’image d’origine.
– Lorsque l’image obtenue est plus saturée que l’image d’origine, ses couleurs paraissent alors plus
vives.
(a)
(b)
FIG. 4.18 – Modiﬁcation de la saturation
Modiﬁcation de l’intensité
Pour modiﬁer l’intensité d’une couleur, on augmente ou on diminue sa
clarté. Pour cela on effectue une translation de m d’un vecteur pondéré par le coefﬁcient α ∈R suivant
l’axe des intensités µ (cf. ﬁgure 4.19).

106
CHAP 4 - MODÉLISATION DES COULEURS PAR LES ALGÈBRES GÉOMÉTRIQUES
Ainsi on obtient :
m′ = I′µ + Seµ∗T νm′ = m + αµ
m′ = Iµ + Seµ∗T ν + αµ
m′ = (I + α)µ + Seµ∗T ν
I′ = I + α
(4.74)
FIG. 4.19 – Modiﬁcation de l’intensité
Le résultat d’une augmentation de l’intensité, illustré à la ﬁgure 4.20, montre que l’image modi-
ﬁée (b) est plus contrastée, elle paraît également plus chaleureuse. La même image, avec une intensité
diminuée par rapport à l’image d’origine, peut paraître plus triste. En effet, la lumière du soleil agit
fréquemment sur nos sens et on a tendance à se sentir mieux un jour ensoleillé plutôt qu’une journée
de pluie dont l’intensité de lumière est diminuée par les nuages. De plus, l’augmentation de l’intensité
permet
(a)
(b)
FIG. 4.20 – Modiﬁcation de l’intensité
On remarquera qu’il est possible d’effectuer toutes ces transformations couleurs grâce au fait que
l’information couleur est contenue sur la partie vectorielle d’un multivecteur de G3. En effet, les opéra-
tions de projections, translations, réjections, . . . ne sont déﬁnies que pour des multivecteurs simples c’est
à dire des multivecteurs dont l’information n’est pas séparée sur plusieurs grades. Nous utilisons donc
convenablement les multivecteurs simples pour coder l’information de couleur car elle est stockée sur le
grade 1 des multivecteurs de G3. Le fait de coder l’information couleur sur plusieurs grades comme nous
l’avons effectué dans la partie utilisant G2 interdit donc toute déﬁnition de transformation géométrique.
Après avoir vu qu’il était possible de manipuler les couleurs par des transformations géométriques,
nous allons déﬁnir un détecteur de contours couleur qui se base sur ces transformations déﬁnies dans G3.

4.5. Filtrage spatial par algèbre de Clifford
107
4.5
Filtrage spatial par algèbre de Clifford
Il n’existe pour l’instant que très peu d’applications qui associent les algèbres de Clifford aux images
numériques couleur. On peut cependant citer les travaux de Schlemmer et al. [67] qui utilisent la théorie
des champs de vecteurs 2D déﬁnis dans [25] pour créer un gradient de chrominance qu’ils associent
à un gradient d’intensité. Les parties chrominance et intensité utilisées pour créer ces deux gradients
sont déﬁnies par passage de l’espace couleur RV B à l’espace couleur Y UV . Il en résulte alors deux
images qui seront traitées indépendamment. La première image est obtenue avec la seule composante Y ,
elle représente donc une information de clarté. Il est appliqué sur cette première image un détecteur de
contours classique. La deuxième image, comportant l’information de chromaticité, est obtenue à partir
des composantes U et V de l’image. L’originalité de ces travaux tient dans le fait que cette deuxième
image est traduite en termes de champs de vecteurs avec la composante U codée sur la première partie
vectorielle d’un multivecteur de G2 tandis que la partie en V est codée sur sa deuxième partie vectorielle.
Ensuite, la technique du ﬁltrage par motif (pattern matching) est utilisée pour retrouver des contours par
similitude entre l’image UV et des éléments de motifs propres aux champs de vecteurs 2D. Les éléments
de rotation, convergence et divergence, liés par déﬁnition à l’opérateur de dérivation, ont donc servi à
détecter des contours dans le plan UV . On obtient une carte de similitudes entre le ﬂot de données et
le/les motif(s) utilisé(s) pour détecter des contours. Puis, on combine cette carte de similitudes avec le
résultat obtenu dans le traitement de la clarté avec la première image pour aboutir à une détection globale
des contours couleur.
Notre démarche est différente, car nous voulons manipuler une information complète autrement dit
chacune des composantes nécessaires à la déﬁnition d’une couleur. Nous proposons d’adapter les ﬁltres
quaternioniques, vus au chapitre 3, et de les améliorer avec le formalisme de l’algèbre géométrique
G3. En effet, G3 nous permet de modéliser les transformations géométriques sur les vecteurs mais aussi
permet de caractériser de manière géométrique la différence entre deux 1-vecteurs au moyen du produit
géométrique comme nous l’avons vu à la section 4.1.8.
4.5.1
Approche détection de Sangwine
La méthode de ﬁltrage spatial de Sangwine [63] utilisant les quaternions (vu à la section 3.2.4.4)
est directement généralisable en utilisant le formalisme des algèbres géométriques. Il sufﬁt pour cela de
remplacer les quaternions par des vecteurs de G3. Le résultat obtenu est donc un détecteur de contours.
Nous avons cependant simpliﬁé l’équation du schéma de ﬁltrage avec l’algèbre géométrique en rempla-
çant l’opération de multiplication par les deux conjugués, qui prête à confusion, par une opération de
rotation du pixel central du ﬁltre par rapport à l’axe des niveaux de gris et d’un angle de π, ou autrement
dit, une opération de réﬂexion par rapport à l’axe des niveaux de gris.
L’opération de ﬁltrage proposée par Sangwine et généralisée au formalisme de G3 est la suivante :
ffiltrée[m, n] = (h1 ∗f ∗h2)[m, n]
(4.75)
où les ﬁltres h1 et h2 sont une paire de ﬁltres qui permettent d’effectuer la réﬂexion d’axe µgris =
µ = e1+e2+e3
√
3
comme suit :
h1 = 1
6


1
1
1
0
0
0
µ
µ
µ


et
h2 = 1
6


1
1
1
0
0
0
µ−1
µ−1
µ−1


(4.76)
On remarquera que ce ﬁltre est vertical et dirigé pour détecter les contours horizontaux.
Les résultats de ce ﬁltrage sont exactement équivalents à ceux obtenus avec le formalisme des qua-
ternions (cf. ﬁgure 4.21) car on ne fait que réécrire le problème en utilisant un formalisme différent. On
note également des résultats différents suivant le sens d’application du ﬁltre : sens 1 = droite vers gauche,
sens 2 = inverse.

108
CHAP 4 - MODÉLISATION DES COULEURS PAR LES ALGÈBRES GÉOMÉTRIQUES
(a) image originale
(b) ﬁltre horizontal sens 1
(c) ﬁltre horizontal sens 2
(d) zoom sens 1
(e) zoom sens 2
FIG. 4.21 – Le détecteur de contours de Sangwine adapté à G3
4.5.2
Approche par gradient de saturation
Pour améliorer ces résultats, nous avons ensuite proposé un schéma de ﬁltrage qui calculait un gra-
dient par maximum de distance sur la saturation (cf. section 3.2.4.5). Comme nous avons vu, l’inconvé-
nient de cette méthode réside dans le fait que ce gradient n’est calculé que sur une mesure de saturation.
Par exemple lorsque l’information d’un pixel est uniquement de type achromatique, la saturation est nulle
et donc la valeur du gradient associé en ce point sera elle aussi nulle. En conclusion, cette méthode est
incapable de détecter des différences d’intensité (cf. ﬁgure 4.22).
FIG. 4.22 – L’approche par gradient de saturation

4.5. Filtrage spatial par algèbre de Clifford
109
4.5.3
Approche par gradient de saturation et produit géométrique[18]
Pour améliorer notre technique, nous proposons d’utiliser les algèbres géométriques aﬁn d’apporter
une description géométrique des couleurs par rapport à l’axe achromatique des niveaux de gris. Cette
description géométrique est déﬁnie par le produit géométrique suivant : f[m, n]µ.
En effet, comme nous l’avons vu, ce produit géométrique se décompose en une somme de deux
parties comme l’illustre la ﬁgure 4.23.
FIG. 4.23 – Le produit géométrique d’un pixel couleur f[m, n] avec l’axe des niveaux de gris µ se
décompose en une partie scalaire : f[m, n]⌋µ et une partie bivectorielle : f[m, n] ∧µ. Plus le vecteur
couleur f[m, n] est éloigné de l’axe des niveaux de gris, lus la norme du bivecteur f[m, n]∧µ est grande.
– La première partie : f[m, n] ∧µ, est le produit vectoriel du pixel analysé avec l’axe des gris, c’est
le bivecteur représenté par le plan porté par les vecteurs couleur f[m, n] et µ. Lorsque la norme
de cette partie est nulle, le vecteur couleur analysé est colinéaire à µ c’est à dire qu’il est porté par
l’axe des niveaux de gris.
– La deuxième partie : f[m, n]⌋µ, est un scalaire correspondant à la projection du vecteur couleur
f[m, n] sur l’axe µ, autrement dit, son intensité.
Nous décrivons graphiquement le processus de construction de notre gradient couleur à partir de la
ﬁgure 4.24a. Nous pourrons ensuite comparer cette nouvelle technique avec celle basée uniquement sur
la caractéristique de saturation que nous avons déﬁnie juste avant (cf. ﬁgure 4.24b).
Nous proposons la méthode suivante :
– Pour chaque pixel de l’image, nous effectuons le produit géométrique f[m, n]µ.
– Nous séparons dans le résultat les parties scalaire et bivectorielle.
– Nous calculons la norme de la partie bivectorielle. Cette norme nous permet de savoir à quels
endroits de l’image l’information est de type achromatique. Nous voyons très bien dans la ﬁgure
4.25 qu’il y a deux zones où la norme est quasi nulle sinon nulle. Ces deux zones correspondent
aux deux rectangles au centre de l’image. En regardant l’image originale, il est évident que ces
zones sont composées uniquement de pixels en niveaux de gris. Donc quand la norme de la partie
bivectorielle est proche de zéro, nous avons bien des pixels achromatiques.
– L’étape suivante consiste à construire un masque à partir de cette norme. Ce masque est construit
par un seuillage de la norme permettant de séparer les zones de norme très faibles des autres zones
de l’image où les informations de chromaticité prédominent sur l’information d’intensité. Le seuil
est déterminé de façon empirique. Ainsi ce masque permet de conserver uniquement les pixels

110
CHAP 4 - MODÉLISATION DES COULEURS PAR LES ALGÈBRES GÉOMÉTRIQUES
FIG. 4.24 – Image originale et résultat du gradient basé sur la saturation uniquement (inversé pour une
meilleure visibilité).
pour lesquels la norme est proche de zéro, autrement dit, nous considérons que ces pixels portent
l’information achromatique.
FIG. 4.25 – Norme de la partie bivectorielle (inversée pour une meilleure visibilité).
– Nous avons vu que la partie scalaire représentait la projection de l’image sur l’axe µ des niveaux
de gris. On comprend donc que ce scalaire représente l’information d’intensité de l’image. C’est
justement l’information qui nous manque et que nous voulons rajouter à notre gradient. Pour cela
nous effectuons donc un ﬁltrage sur la partie projection par un ensemble de ﬁltres de Prewitt dans
chacune des directions horizontale, verticale et diagonales aﬁn d’obtenir un gradient d’intensité.
Ensuite, on utilise le masque déﬁni juste avant pour ne conserver que l’information achromatique
dont on a besoin. Le résultat de cette étape est illustré par la ﬁgure 4.26.
– La dernière étape consiste à assembler ce gradient d’intensité sur les zones achromatiques de
l’image au gradient de saturation déﬁni précédemment. Pour cela, nous utilisons là encore l’opéra-
tion qui consiste à garder pour chaque pixel la valeur maximum entre ces deux gradients. La ﬁgure
4.27 illustre donc le gradient ﬁnal obtenu par cette méthode. Comparés au gradient précédent de

4.5. Filtrage spatial par algèbre de Clifford
111
FIG. 4.26 – Gradient d’intensité masqué grâce à la norme de la bivectorielle (inversé pour une meilleure
visibilité).
la ﬁgure 4.24b, les contours sont détectés aussi efﬁcacement. Cependant là où l’ancienne méthode
échouait dans la détection des contours achromatiques, le nouvelle technique permet de résoudre
le problème comme nous le voyons par l’apparition de contours à l’intérieur du rectangle du centre
gauche. Notons que s’il n’y a pas de contours apparents dans le carré à droite de l’image qui varie
entre le blanc et le noir de façon verticale, c’est que celle-ci est en effet décrite par des dégradés et
donc qu’il n’y a pas apparition de ruptures franches.
FIG. 4.27 – Gradient ﬁnal (inversé pour une meilleure visibilité).
Pour conclure, nous avons mené une campagne de tests sur différentes images. La ﬁgure 4.28 ré-
sume les résultats en présentant les gradients couleur obtenus par notre méthode sur différentes images
classiques en traitement d’images couleur. On remarque que l’image de synthèse permet de bien mettre
en avant le fait que les contours achromatiques sont maintenant correctement détectés. Les deux images
suivantes contiennent elles aussi des zones achromatiques comme les goutières et les rebords de fenêtre
pour l’image de la maison et les rayures du zèbre. Ces informations achromatiques apparaissent au ni-
veau du gradient couleur ainsi que les autres informations chromatiques qui permettent de détecter des

112
CHAP 4 - MODÉLISATION DES COULEURS PAR LES ALGÈBRES GÉOMÉTRIQUES
contours pour lesquels l’intensité n’a pas d’importance comme c’est le cas pour l’image du babouin par
exemple, qui est constituée de nombreuses textures couleur.
A partir du gradient, nous pouvons construire une carte de contours par un seuillage simple. En effet,
une information de type gradient n’est décrite que sur une composante, il sufﬁt donc de seuiller cette
information en niveaux de gris pour obtenir les contours globaux de l’image. Ici encore, le seuil est
déterminé de manière empirique. Les résultats sont illustrés dans la ﬁgure 4.29. Le gradient couleur de
la maison (a), resp. les parrots (e), est donné en (b), resp. en (f). Les cartes de contours c et g (resp. d et
h) sont obtenues par seuillage de notre gradient ﬁnal (resp. du gradient de saturation). Nous remarquons
que les détails de la fenêtre de la maison apparaissent nettement plus clairement avec la prise en compte
de l’intensité dans (c) que dans (d) où cette information de clarté n’est pas traitée. De même, d’autres
détails se distinguent avec le nouveau modèle comme les dessous de toit et les gouttières. Néanmoins
les contours des ombres sont aussi détectés en (c) et un travail complémentaire pourrait être apporté
par l’étude d’un gradient teinte pondéré par la saturation dans G3. Pour l’image des parrots (g) et (h) la
différence est encore plus visible car l’image contient des parties très achromatiques. Ainsi les contours
sont bien plus précis au niveau des deux becs qui contiennent essentiellement des nuances de noir ou de
blanc. La nouvelle méthode fait apparaître aussi de nombreux détails achromatiques au niveau de la tête
de l’animal de gauche qui étaient complètement absents avec la méthode précédente (œil par exemple).
Nous avons donc proposé une méthode de traitement d’images couleur qui utilise l’algèbre géomé-
trique G3 et dont l’intérêt réside dans la manipulation géométrique des couleurs au moyen d’opérations
algébriques. Le produit géométrique utilisé notamment dans la dernière partie de la construction de notre
gradient permet de comparer de manière géométrique l’ensemble des pixels de l’image. Si dans notre
proposition actuelle la comparaison a été faite par rapport à l’axe des niveaux de gris, il est tout à fait
possible d’envisager une comparaison des pixels avec d’autres vecteurs couleurs pour déﬁnir de nou-
velles opérations réellement couleur. En effet, la partie bivectorielle associée au produit vectoriel de
deux vecteurs couleur apporte de l’information géométrique notamment le plan colorimétrique qui per-
met de passer d’une couleur à l’autre. Ce plan de couleur est aussi associé dans le produit vectoriel à
l’angle qui sépare les deux vecteurs couleurs multipliés.
4.6
Conclusion
Nous avons vu que l’algèbre Géométrique G3 permet de manipuler des entités géométriques telles
que des scalaires, vecteurs ou bibecteurs et cela de manière indépendante. Des règles permettent d’af-
fecter certains objets au moyen d’autres et celles-ci sont régies par les différents produits que l’on peut
rencontrer dans G3 (produits interne, externe, géométrique, mixte).
Nous avions également vu qu’il était possible d’utiliser les quaternions pour pouvoir appliquer des
transformations géométriques sur des vecteurs de l’espace 3-D. Cependant, même si les opérations géo-
métriques de base peuvent être décrites en utilisant le formalisme quaternionique, là où elles nous four-
nissent des résultats en termes de produits de quaternions, les opérations décrites avec les algèbres géo-
métriques nous permettent de faire la distinction entre les différents objets manipulés, notamment la
différence entre vecteurs et bivecteurs qui est complétement absente de la théorie des quaternions.
Il est donc possible d’utiliser le formalisme des algèbres géométriques pour pouvoir coder les infor-
mations de pixels de couleur au moyen de 1-vecteurs. Les algèbres géométriques permettent de déﬁnir
les opérations géométriques de base telles que projections, réjections, réﬂexions, rotations sur et entre
1-vecteurs couleur. Il est par exemple possible d’utiliser les algèbres géométriques pour exprimer un
pixel donné dans un espace RV B selon ses composantes de teinte, saturation et intensité. Ce genre de
manipulation nous a permis ainsi de déﬁnir des stratégies de ﬁltrages spatiaux déﬁnis par convolution de
ﬁltres.
Nous avons aussi proposé une transformation de Fourier Cliffordienne appliquée aux images couleur.
Cette approche présente l’avantage de séparer les informations de chaque composante couleur sur deux
composantes spectrales distinctes sans mélanger le contenu avec d’autres composantes couleur. En effet,
les variations paires et impaires du signal spatial sont séparées pour chaque canal couleur sur les parties

4.6. Conclusion
113
vectorielle et bivectorielle du spectre. Ceci permet d’éviter le mélange des informations comme c’était le
cas avec l’approche quaternionique. De plus, comme le noyau de la transformée de Fourier Cliffordienne
est le pseudoscalaire, cette transformée de Fourier est équivalente à l’application de trois transformées
de Fourier complexes sur chacune des composantes couleur de l’image car e2
123 = −1.

114
CHAP 4 - MODÉLISATION DES COULEURS PAR LES ALGÈBRES GÉOMÉTRIQUES
(a)
(b)
(c)
(d)
(e)
(f)
(g)
(h)
FIG. 4.28 – Exemple de gradient sur des images couleur

4.6. Conclusion
115
(a)
(b)
(c)
(d)
(e)
(f)
(g)
(h)
FIG. 4.29 – Exemples du gradient couleur : images maison (a) et parrots (e) ; résultats des gradients
couleur par notre méthode (b) et (f) (réhaussement de luminosité pour plus de visibilité) ; différence
entre un seuillage effectué sur notre gradient couleur (c) et (g) et celui n’utilisant pas l’information
achromatique (d) et (h).


CHAPITRE 5
CONCLUSION
Dans ce travail, nous nous sommes intéressés à l’apport que l’on peut obtenir par l’utilisation de
formalismes algébriques pour analyser et traiter les images numériques couleur. Dans ce cadre, nous
avons vu qu’il est possible de matérialiser des vecteurs représentant l’information couleur par de simples
éléments de l’algèbre utilisée. La manipulation des vecteurs couleur utilisant par exemple des produits
vectoriels ou encore des produits matriciels souvent lourds à l’usage est simpliﬁée par l’utilisation d’opé-
rations fondamentales simples pour manier les éléments de l’algèbre. Nous avons alors cherché à carac-
tériser des images couleur en utilisant respectivement l’algèbre des nombres complexes, puis celle des
quaternions pour ﬁnir avec l’algèbre géométrique aussi appelée algèbre de Clifford. Reprenons les diffé-
rents éléments de réponse que nous avons proposés.
Dans le chapitre 2, nous avons tout d’abord effectué un rappel sur l’analyse par transformée de Fou-
rier, élément fondamental dans la suite du document. Dans l’objectif d’étudier la possibilité d’utiliser
un espace couleur pour déﬁnir une approche fréquentielle couleur, nous avons dû analyser différents es-
paces couleur. Notre choix s’est porté sur l’espace couleur Y UV . Cet espace a été créé pour le système
standard PAL de télévision et il permet la séparation de l’information d’intensité et de celle de chroma-
ticité des couleurs. L’étape suivante a alors été de caractériser cet espace Y UV aﬁn de savoir comment
se comportent les coefﬁcients des composantes chromatiques U et V en fonction de la composante de
d’intensité Y ainsi que les domaines de variation. Nous avons par exemple conﬁrmé par des expériences
numériques que la clarté Y fait bien partie de la perception de la couleur en montrant que les variations
de couleurs obtenues avec les composantes U et V changeaient suivant les valeurs de la clarté. Ceci nous
renforce dans notre approche nécessairement tridimensionelle de la couleur.
Ensuite, même si l’information contenue dans un nombre complexe ne sufﬁt pour « capter » complè-
tement la couleur, nous avons montré que la déﬁnition d’une transformée de Fourier « chromatique » per-
mettait d’analyser partiellement le comportement des couleurs dans un espace fréquentiel. Cette analyse
nécessite la déﬁnition et la compréhension de la notion de « chemin couleur » proposée initialement
par McCabe et utilisée pour décrire les variations de couleur obtenues sur des images dont le spectre a
reçu une initialisation de type impulsion. Nous avons vu qu’un chemin couleur est déﬁni dans le plan
complexe formé par les composantes U et V et permet d’illustrer une variation couleur dans ce plan.
Il existe de nombreux chemins couleur de base qui traduisent la notion d’opposition de couleur comme
par exemple l’opposition rouge-vert ou encore l’opposition bleu-jaune qui sont deux cas particuliers de
chemins décrits uniquement sur l’un des axes du plan (U, V ). Pour chaque point de l’espace fréquen-
tiel correspond alors un chemin couleur dans le domaine spatial. Une image couleur est donc composée
d’une somme d’une multitude de chemins couleur élémentaires ayant chacun leur correspondant dans
l’espace des fréquences.
117

118
CHAP 5 - CONCLUSION
Pour illustrer cette approche « Fourier chromatique » , nous avons déﬁni une stratégie de ﬁltrage
fréquentiel « chromatique » sur des images couleur. Les résultats applicatifs montrent que la stratégie
de ﬁltrage fréquentiel reste cohérente même si toute l’information couleur n’est pas utilisée avec les
nombres complexes.
De cette conﬁrmation de la nature complètement tridimensionelle de la couleur, nous avons élargi
l’étude à un formalisme comportant plus de dimensions. Le chapitre 3 traite alors de l’opportunité d’uti-
liser les quaternions pour manipuler les images couleur. Les quaternions, contrairement aux nombres
complexes, peuvent décrire complètement une information couleur par exemple sur leurs parties imagi-
naires. On peut alors manipuler un vecteur couleur par de simples opérations comme le produit. Nous
avons ainsi vu qu’il est possible d’effectuer des transformations géométriques sur des vecteurs couleur
au moyen de ce formalisme. Puis nous avons déﬁni un détecteur de contours utilisant ce type de trans-
formation dans une approche spatiale basée sur les travaux de Sangwine. Ce détecteur repose sur une
généralisation du ﬁltrage linéaire à l’aide du formalisme des quaternions. Un ﬁltrage de Prewitt est ef-
fectué sur l’image d’origine en remplaçant les coefﬁcients réels par des coefﬁcients quaternioniques
permettant de caractériser les contours couleur de l’image. Le résultat du ﬁltrage est représenté par des
vecteurs couleur qui permettent de comparer chaque pixel analysé à l’ensemble de ses voisins. Si le vec-
teur résultat est proche de l’axe des niveaux de gris, le pixel analysé se situe sur une zone de couleur
homogène tandis que s’il s’éloigne de cet axe alors c’est qu’il fait partie d’un contour couleur. Nous
avons proposé de calculer la distance de ce vecteur couleur par rapport à l’axe des niveaux de gris, dia-
gonale du cube RV B, pour obtenir un gradient de couleur. La distance calculée correspond en fait à une
mesure de saturation. Nous avons alors mis en évidence que le gradient quaternionique proposé souffre
de ne pas pouvoir détecter les contours achromatiques.
Dans la seconde partie du chapitre 3, nous avons étudié les approches fréquentielles déﬁnies dans la
littérature utilisant les quaternions.
– Tout d’abord l’analyse de Bülow sur les images en niveaux de gris qui permet de caractériser les
structures 2D d’un signal réel grâce aux symétries présentes dans la transformée de Fourier et à la
caractérisation de la généralisation du signal analytique à deux dimensions. Cette généralisation
appelée signal monogénique permet d’introduire des notions de phase et d’amplitude locale pour
les directions horizontales et verticales de manière indépendante.
– Ensuite, nous avons décrit l’analyse des images couleur par Sangwine et Ell. Nous avons vu que
la description fréquentielle dépend de la direction de la transformée de Fourier quaternionique. En
réalité, pour pouvoir analyser le contenu fréquentiel comme le font Sangwine et Ell, il faut utiliser
une transformée de Fourier quaternionique ne donnant pas plus d’importance à une composante
couleur qu’à une autre, autrement dit, dont la direction suit l’axe des niveaux de gris. Cette analyse
alors permet de retrouver l’interprétation du spectre avec les chemins couleur donnée par McCabe
dans le cas complexe.
Cependant nous avons observé, par l’étude numérique de la transformée de Fourier quaternionique,
qu’il était possible d’effectuer des transformées sur des images couleur avec des directions différentes
de l’axe des niveaux de gris bien qu’une interprétation de l’information spectrale obtenue par une telle
direction semble difﬁcile. Nous avons décrit le domaine de Fourier à travers des propriétés de symétrie
propres à la transformée aussi bien dans le spectre que sur les images d’origines. Nous avons enﬁn
étudié les atomes élémentaires associés à cette transformée de Fourier quaternionique en initialisant le
spectre par des impulsions. L’analyse des résultats de ces initialisations spectrales nous a permis de
différencier plusieurs cas de ﬁgures dans lesquels la direction de la transformée de Fourier prend plus ou
moins d’importance. Cette direction d’analyse est importante lorsque le spectre contient uniquement de
l’information sur la partie réelle, les variations spatiales obtenues dépendent en effet à ce moment là de la
direction de la TFQ. Sinon, dès lors que les parties imaginaires du spectre sont non nulles, l’inﬂuence de
la direction de la transformée de Fourier sur l’analyse couleur disparaît. Cette étude est illustrée à travers
une stratégie de ﬁltrage fréquentielle utilisant les quaternions.
Dans le chapitre 4, nous utilisons une généralisation des formalismes permettant de manipuler des
entités géométriques par l’intermédiaire d’écritures algébriques à savoir les algèbres géométriques. Ces

CHAP 5. CONCLUSION
119
algèbres aussi appelées algèbres de Clifford permettent d’ailleurs de généraliser ce type d’approche à
un nombre de dimensions inﬁni. Nous avons vu que les algèbres géométriques G2 et G3 permettent de
manipuler des entités géométriques telles que scalaires, vecteurs, bivecteurs et trivecteurs de manière
indépendante. Des règles permettent d’affecter certains objets au moyen d’autres et celles-ci sont régies
par les différents produits : produits interne, externe, géométrique, mixte.
Il existe peu de travaux sur l’utilisation des algèbres géométriques dans le domaine de l’image. Nous
avons tout d’abord vu comment les algèbres géométriques étaient utilisées par Felsberg pour l’analyse
fréquentielle des images en niveaux de gris. Dans son approche, il utilise les algèbres géométriques pour
analyser les structures locales des signaux 2D réels en séparant l’information contenue dans ces signaux
2D avec des symétries centrales.
Aﬁn de répondre à notre problématique de caractérisation fréquentielle couleur, nous avons ensuite
appliqué les travaux de Brackx et Sommen aux images couleur. Ces travaux reposent sur la déﬁnition
d’une transformée de Fourier dont le noyau est déﬁni par un produit extérieur de l’algèbre G2. Cette
déﬁnition se distingue en ce point de toutes les autres transformées de Fourier que nous avons étudiées.
Malheureusement, du fait de l’algèbre G2 utilisé, nous avons constaté que cette transformée ne convient
pas à une analyse globale des images couleur tout simplement car elle ne donne pas le même poids aux
trois composantes couleurs : alors que les parties paires et impaires de la première composante couleur
sont séparées correctement dans le spectre, celles correspondant aux deuxième et troisième composantes
se retrouvent mélangées en son sein. De plus, le fait d’utiliser l’algèbre G2 ne permet pas de placer les
composantes couleur sur le même grade de l’algèbre. Il n’y a en effet qu’une partie scalaire et une partie
bivectorielle pour deux parties vectorielles. Ceci empêche d’effectuer des opérations géométriques que
l’on pourrait utiliser dans le domaine spatial car ces opérations ne sont déﬁnies que pour des multivec-
teurs simples, autrement dit de même grade.
Nous avons donc utilisé les trois composantes 1-vectorielles de l’algèbre G3 pour placer les trois
composantes couleur sur un multivecteur. En utilisant ce formalisme, nous avons proposé une déﬁnition
d’une transformation de Fourier Cliffordienne appliquée aux images couleurs. L’étude numérique de
cette transformation a mis en évidence qu’elle n’est pas directionnelle comme c’est le cas pour la trans-
formée quaternionique. Les composantes fréquentielles couleur se séparent suivant les parties paires ou
impaires sur les composantes 1-vectorielles et bi-vectorielles du spectre de manière indépendante. On
retrouve donc les parties paires de la première composante couleur sur la partie vectorielle e1 du spectre
tandis que sa partie impaire se situe sur la composante duale c’est à dire la composante bivectorielle
e23. On constate le même phénomène pour les deux autres composantes couleur. Cette transformée de
Fourier Cliffordienne qui utilise le pseudoscalaire dans le noyau est donc isomorphe à une transformée
de Fourier marginale soit une transformée complexe appliquée sur chaque composante couleur.
Enﬁn, nous avons utilisé l’algèbre G3 dans une approche spatiale. Tout d’abord, nous avons montré
qu’il est possible d’utiliser les avantages donnés par l’utilisation des produits de l’algèbre aﬁn de décrire
la géométrie entre deux 1-vecteurs couleur (car les 1-vecteurs sont par nature de même grade). On peut
ainsi exprimer l’angle qui sépare deux 1-vecteurs dans le plan porté par le bivecteur qui leur est associé
(obtenu par leur produit externe). L’algèbre G3 nous a également permis de déﬁnir une nouvelle approche
spatiale de détection de contours en généralisant celle déﬁnie avec les quaternions. Cette approche re-
prend le principe du ﬁltrage couleur basé sur un gradient de saturation auquel nous avons adjoint une
partie permettant de rajouter une discrimination des contours achromatiques. Pour cela, chaque pixel
couleur de l’image est comparé au 1-vecteur représentant l’axe des niveaux de gris par un produit géo-
métrique. Ce produit géométrique se décompose en une somme de deux termes : le produit externe du
pixel avec l’axe des gris et leur produit scalaire. Le produit externe nous permet de savoir à travers sa
norme si le pixel est achromatique. Dans ce cas, il est conservé dans un masque que nous appliquons sur
le résultat du produit scalaire qui correspond exactement à la clarté du pixel. En ﬁltrant cette partie par
un ﬁltre de Prewitt, on obtient un gradient d’intensité qui est fusionné au gradient de saturation lorsque le
pixel est achromatique. Nous obtenons ainsi un gradient efﬁcace pour détecter les contours d’une image
couleur.

120
CHAP 5 - CONCLUSION
Ces travaux doivent être poursuivis par la déﬁnition de nouvelles méthodes spatiales prenant plus en
compte la spéciﬁcité des opérations rendues possibles par l’utilisation des algèbres géométriques ainsi
que des entités manipulées. Par exemple, nous avons vu que deux 1-vecteurs peuvent être comparés par
leur produit géométrique, plutôt que de les comparer entre eux par rapport à l’axe des niveaux de gris.
On comparerait dans ce cas chaque pixel avec ses voisins et lorsque l’angle entre les deux ou même la
norme du bivecteur leur étant associé seraient importants, nous serions en présence d’un contour. De
plus l’angle et le bivecteur présentent de l’information supplémentaire dans le fait que l’angle est celui
qui sépare les deux 1-vecteurs dans le plan orienté qui leur est associé. Il faudrait également étudier
l’opportunité de faire ces comparaisons entre 1-vecteurs couleurs dans d’autres espaces comme les es-
paces antagonistes comme Y CrCb utilisé pour la TVHD par exemple ou encore l’espace L∗a∗b∗qui
est perceptuellement uniforme. Les algèbres géométriques permettent aussi la formulation des notions
d’union et d’intersection d’ensemble. Ces notions pourraient être utilisées également pour comparer des
vecteurs couleur entre eux et donc applicables pour des ﬁltrages d’ordre et en particulier à des opérations
de morphologies mathématiques. On pourrait de même s’en servir pour agréger des vecteurs rassemblant
des caractéristiques semblables dans une approche de segmentation par régions ou dans une démarche
d’indexation par le contenu de bases d’images couleur. Il est également possible de déﬁnir une notion
de corrélation entre vecteurs de l’algèbre ceci pourrait être utilisé pour comparer des images entre elles
en détectant les mouvements ou disparitions de certains objets. On pourrait donc appliquer ceci dans des
séquences vidéos en télésurveillance pour exemple d’application. Il est difﬁcile de conclure sur l’ana-
lyse fréquentielle couleur. Les propriétés mises en évidence n’ont pas montré un potentiel applicatif.
Pour cela, il nous semble nécessaire d’intégrer à l’analyse couleur l’analyse géométriques des images
en deux dimensions. Cela est peut être possible en codant chaque composante couleur sur deux parties
vectorielles qui seraient ensuite analysées par une transformée de Fourier permettant la séparation entre
les informations horizontales et verticales. Enﬁn, comme les algèbres géométriques ne sont pas limitées
à la dimension trois mais généralisables à n’importe quelle dimension, on est loin d’avoir fait le tour
des potentialités de la représentation. Il est possible de s’en servir pour effectuer des traitements sur des
images multispectrales et multicomposantes comme les images satellitaires par exemple.

ANNEXE A
ALGÈBRE GÉOMÉTRIQUE G2
Nous présentons tout d’abord dans cette annexe comment la transformée de Fourier déﬁnie dans le
manuscrit à la section 4.3.1 peut se calculer en utilisant des FFT (cf. section A.1). Ensuite nous détaille-
rons les calculs nécessaires à la détermination des symétries dans le spectre d’images couleur déﬁnies
par cette TFC (cf. section A.2). Enﬁn, nous détaillerons les calculs permettant de connaitre l’inﬂuence
des atomes élémentaires du spectre (cf. section A.3).
A.1
Simpliﬁcation par transformées de Fourier Rapides
Pour pouvoir assurer la simpliﬁcation de la tranformée de Fourier par des transformées de Fourier
complexes, il faut factoriser l’expression de la transformée de Fourier par l’élément de l’algèbre qui élevé
au carré vaut −1. Une telle factorisation permettrait de pouvoir ensuite calculer la transformée de Fourier
Cliffordienne par une somme de transformées de Fourier complexes rapides. L’élément correspondant
par isomorphisme dans l’algèbre G2 au complexe imaginaire i est e12.
f[n, m] =f0[n, m]e0 + f1[n, m]e1 + f2[n, m]e2 + f12[n, m]e12
=f0[n, m]e0 + f12[n, m]e12 + [f1[n, m]e0 −f2[n, m]e12] e1
On calculera F[o, p] de la manière suivante :
F[o, p] =FH+[f][o, p] =
1
√
NM
M−1
X
m=0
N−1
X
n=0
exp(2π( on
M −pm
N )) f[n, m]
=
1
√
NM
M−1
X
m=0
N−1
X
n=0
h
cos

2π
on
M −pm
N

+ sin

2π
on
M −pm
N

e12
i
f[n, m]
≡
1
√
NM
exp(2iπ( on
M −pm
N )) [[f0[n, m] + f12[n, m]i] + [f1[n, m] −f2[n, m]i]]
=
1
√
NM
M−1
X
m=0
N−1
X
n=0
h
cos

2π
on
M −pm
N

+ sin

2π
on
M −pm
N

i
i
[[f0[n, m] + f12[n, m]i] + [f1[n, m] −f2[n, m]i]]
121

122
CHAP A - ALGÈBRE GÉOMÉTRIQUE G2
Il est donc possible de calculer la transformée de Fourier dans G2 au moyen de deux transformées
de Fourier rapides. Le terme d’équivalence n’est ici employé que pour indiquer que les coefﬁcients
seront conservés. Cependant aﬁn de calculer entièrement la transformée de Fourier Cliffordienne il faudra
ﬁnalement remplacer les i par des e12 et multiplier ces coefﬁcients en fonction de la factorisation donnée
ci-dessus.
A.2
Conditions d’initialisation du spectre
En reprenant la formulation de la tranformée de Fourier inverse, nous avons :
f[n, m] =
1
√
MN
M
2
X
o=−M
2 +1
N
2
X
p=−N
2 +1
h
F0[o, p] cos

2π
on
M −pm
N

−F12[o, p] sin

2π
on
M −pm
N
i
+
h
F1[o, p] cos

2π
on
M −pm
N

+ F2[o, p] sin

2π
on
M −pm
N
i
e1
+
h
F2[o, p] cos

2π
on
M −pm
N

−F1[o, p] sin

2π
on
M −pm
N
i
e2
+
h
F12[o, p] cos

2π
on
M −pm
N

+ F0[o, p] sin

2π
on
M −pm
N
i
e12
il faut que f12[n, m] = 0 pour reconstruire une image couleur.
Pour que f12[n, m] = 0 il faut que
f12A[n, m] =
1
√
MN
M
2
X
o=−M
2 +1
N
2
X
p=−N
2 +1
F12[o, p] cos

2π
on
M −pm
N

= 0
pour cela il faut que ∀(o, p) ∈([−N
2 + 1; N
2 ], [−M
2 + 1; M
2 ]), F12[o, p] = −F12[−o, −p]
et
f12B[n, m] =
1
√
MN
M
2
X
o=−M
2 +1
N
2
X
p=−N
2 +1
F0[o, p] sin

2π
on
M −pm
N

= 0
pour cela il faut que ∀(k, l) ∈([−N
2 + 1; N
2 ], [−M
2 + 1; M
2 ]), F0[o, p] = F0[−k, −l].
Nous obtenons donc les conditions générales de symétries du spectre pour pouvoir reconstruire le
signal d’une image couleur par notre transformée de Fourier inverse.
∀(k, l) ∈([−N
2 + 1; N
2 ], [−M
2 + 1; M
2 ])
F0[o, p] = F0[−k, −l]
F12[o, p] = −F12[−k, −l]
A.3
Interprétation de l’inﬂuence d’un Dirac dans le spectre
En initialisant un point dans le domaine fréquentiel par une constante, on veut interpréter le résultat
obtenu dans le domaine spatial après transformée de Fourier inverse.
Il faut respecter les conditions d’initialisation données dans l’équation (4.46).

A.3. Interprétation de l’inﬂuence d’un Dirac dans le spectre
123
A.3.1
Initialisation sur la composante scalaire
On choisit d’insérer deux Dirac respectant la condition F0[k0, l0] = F0[−k0, −l0] sur le spectre,
en considérant le centre de l’image comme origine du repère. Les coefﬁcients de celui-ci restent nuls
ailleurs. On effectue ensuite une transformée inverse.
f[n, m] =

F0[o0, p0] cos

2π
o0n
M −p0m
N

+ F0[−o0, −p0] cos

2π
−o0n
M
−−p0m
N

+

F0[o0, p0] sin

2π
o0n
M −p0m
N

+ F0[−o0, −p0] sin

2π
−o0n
M
−−p0m
N

e12
comme F0[o0, p0] = −F0[−u0, −v0] et ∀x ∈R cos(−x) = cos(x) et sin(−x) = −sin(x)
f[n, m] = 2F0[o0, p0] cos

2π
o0n
M −p0m
N

(A.1)
A.3.2
Initialisation sur la composante bivectorielle
On choisit d’insérer deux Dirac respectant la condition F12[o0, p0] = −F12[−o0, −p0] sur le spectre
nul ailleurs en considérant le centre de l’image comme origine du repère. On effectue ensuite une trans-
formée inverse.
f[n, m] =

−F12(o0, p0) sin

2π
o0n
M −p0m
N

−F12(−o0, −p0) sin

2π
−o0n
M
−−p0m
N

+

F12(o0, p0) cos

2π
o0n
M −p0m
N

+ F12(−o0, −p0) cos

2π
−o0n
M
−−p0m
N

e12
comme F12(o0, p0) = −F12(−o0, −p0) et ∀x ∈R cos(−x) = cos(x) et sin(−x) = −sin(x)
f(n, m) = −2F12(o0, p0) sin

2π
o0n
M −p0m
N

(A.2)
A.3.3
Initialisation sur une composante vectorielle
Il n’existe pas de condition de symétrie sur la partie vectorielle du spectre de notre transformée.
Quelle est donc l’inﬂuence d’une initialisation sur l’une ou l’autre de ces deux composantes ?
– On initialise une constante sur la première partie vectorielle :
f(n, m) =
h
F1(o0, p0) cos

2π
o0n
M −p0m
N
i
e1
+
h
−F1(o0, p0) sin

2π
o0n
M −p0m
N
i
e2
Il en résulte une variation spatiale paire sur la première composante et une variation impaire sur la
seconde.
– Ici c’est la deuxième composante vectorielle du spectre qui est initialisée :
f(n, m) =
h
F2(o0, p0) sin

2π
o0n
M −p0m
N
i
e1
+
h
F2(o0, p0) cos

2π
o0n
M −p0m
N
i
e2

124
CHAP A - ALGÈBRE GÉOMÉTRIQUE G2
Il en résulte une variation spatiale impaire sur la première composante et une variation paire sur la
seconde.
Des informations semblent être mélangées sur les parties vectorielles du spectre.
Q’en est-il des propriétés de symétrie sur la partie vectorielle du spectre ? En effet, même si elles
ne sont pas nécessaires à la reconstruction d’une image couleur par transformée inverse, peut-être des
symétries existent-elles tout de même.
On redonne l’expression du spectre mais cette fois avec l’information basse fréquence centrée au
milieu de l’image.
F[o, p] =FH+[f][o, p] =
1
√
NM
M−1
X
m=0
N−1
X
n=0
exp(2π( on
M −pm
N )) f[n, m]
=
1
√
NM
M−1
X
m=0
N−1
X
n=0
h
cos

2π
on
M −pm
N

+ sin

2π
on
M −pm
N

e12
i
f[n, m]
=
1
√
MN
M
2
X
m=−M
2 +1
N
2
X
n=−N
2 +1
h
f0[n, m] cos

2π
on
M −pm
N

−f12[n, m] sin

2π
on
M −pm
N
i
+
h
f1[n, m] cos

2π
on
M −pm
N

+ f2[n, m] sin

2π
on
M −pm
N
i
e1
+
h
f2[n, m] cos

2π
on
M −pm
N

−f1[n, m] sin

2π
on
M −pm
N
i
e2
+
h
f12[n, m] cos

2π
on
M −pm
N

+ f0[n, m] sin

2π
on
M −pm
N
i
e12
Première partie vectorielle
F1[o, p] =
1
√
MN
M
2
X
m=−M
2 +1
N
2
X
n=−N
2 +1
h
f1[n, m] cos

2π
on
M −pm
N

+ f2[n, m] sin

2π
on
M −pm
N
i
e1
F1[−o, −p] =
1
√
MN
M
2
X
m=−M
2 +1
N
2
X
n=−N
2 +1

f1[n, m] cos

2π
−on
M
−−pm
N

+ f2[n, m] sin

2π
−on
M
−−pm
N

e1
=
1
√
MN
M
2
X
m=−M
2 +1
N
2
X
n=−N
2 +1
h
f1[n, m] cos

2π
on
M −pm
N

−f2[n, m] sin

2π
on
M −pm
N
i
e1
d’où F1[o, p] ̸= F1[−o, −p] et aussi F1[o, p] ̸= −F1[−o, −p]. Il n’existe donc pas de symétries
équivalentes à celles que l’on a l’habitude d’observer sur la première partie vectorielle du spectre. On se
rend compte par le même type de calculs qu’il n’existe pas non plus de symétrie particulière sur les axes
horizontal et vertical dans la première partie vectorielle du spectre. Ceci est aussi le cas de la deuxième
partie vectorielle. En effet on remarquera facilement que les informations contenues dans ces deux parties
sont mélangées : on exprime F1 en fonction de f1etf2 et la même chose est vraie pour exprimer F2.

ANNEXE B
ALGÈBRE GÉOMÉTRIQUE G3
B.1
Simpliﬁcation par transformées de Fourier rapides
Comme pour la plupart des transformées de Fourier hypercomplexes [31], [27], [55] et [24], il est
possible d’effectuer la transformation de Fourier Cliffordienne couleur déﬁnie précédement en utilisant
des transformations de Fourier complexes rapides classiques. Ceci permet des temps de calculs améliorés
de manière à pouvoir effectuer cette transformation sur des images numériques de façon plus aisée. La
décomposition s’effectue de la façon suivante :
F[m, n] = F0[m, n] + F1[m, n]e1 + F2[m, n]e2 + F3[m, n]e3
+ F23[m, n]e23 + F31[m, n]e31 + F12[m, n]e12 + F123[m, n]e123
en utilisant les propriétes du produit cette relation est équivalente à la suivante :
f[m, n] = [f0[m, n] + f123[m, n]e123]1
+ [f1[m, n] + f23[m, n]e123]e1
+ [f2[m, n] + f31[m, n]e123]e2
+ [f3[m, n] + f12[m, n]e123]e3
Nous voyons apparaître ici que la fonction f est isomorphe à l’ensemble C4 donc comme la trans-
formée de Fourier est une application linéaire nous pouvons alors décomposer la transformée de Fourier
couleur suivant les différentes composantes de notre algèbre en quatre transformées de Fourier complexes
en remplaçant l’élément e123 par le complexe imaginaire pur i.
F[o, p] = F{f[m, n]}[o, p]
= [F{f0[m, n] + f123[m, n]e123}[o, p]]1
+ [F{f1[m, n] + f23[m, n]e123}[o, p]]e1
+ [F{f2[m, n] + f31[m, n]e123}[o, p]]e2
+ [F{f3[m, n] + f12[m, n]e123}[o, p]]e3
125

126
CHAP B - ALGÈBRE GÉOMÉTRIQUE G3
B.2
Calcul numérique de la transformée de Fourier
Ici nous allons expliquer comment se fait le calcul numérique de la transformée de Fourier pour une
image couleur. Soit une image i de longueur N et de largeur M, elle sera représentée numériquement
par une matrice de dimension N × M. Chaque pixel de cette image sera codé par un multivecteur dans
lequel sera stockée l’information de couleur suivant le principe suivant :
F[o, p] =
1
√
MN
N−1
X
m=0
M−1
X
n=0
f[m, n] exp−2πe123( om
M + pn
N )
Ici m et n représentent donc les coordonnées du pixel au sein de la matrice. On découpe donc l’in-
formation couleur du pixel f de coordonnées m et n en trois composantes rouge r[m, n] = f1[m, n],
verte v[m, n] = f2[m, n] et bleue b[m, n] = f3[m, n].
F[o, p] =
1
√
MN
M
2
X
m=−M
2 +1
N
2
X
n=−N
2 +1
f[m, n] exp−2πe123( om
M + pn
N )
=
1
√
MN
M
2
X
m= M
2 +1
N
2
X
n=−−N
2 +1
f1[m, n]e1 exp−2πe123( om
M + pn
N )
+ f2[m, n]e2 exp−2πe123( om
M + pn
N ) +f3[m, n]e3 exp−2πe123( om
M + pn
N )
=
1
√
MN
N
2
X
m=−N
2 +1
M
2
X
n=−M
2 +1
f1[m, n]e1
h
cos

−2π
om
M + pn
N

+ sin

−2π
om
M + pn
N

e123
i
+ f2[m, n]e2
h
cos

−2π
om
M + pn
N

+ sin

−2π
om
M + pn
N

e123
i
+ f3[m, n]e3
h
cos

−2π
om
M + pn
N

+ sin

−2π
om
M + pn
N

e123
i
=
1
√
MN
M
2
X
m= M
2 +1
N
2
X
n=−−N
2 +1
[f1[m, n]e1 + f2[m, n]e2 + f3[m, n]e3] cos
h
−2π
om
M + pn
N
i
+ [f1[m, n]e23 + f2[m, n]e31 + f3[m, n]e12] sin
h
−2π
om
M + pn
N
i
=
1
√
MN
M
2
X
m= M
2 +1
N
2
X
n=−−N
2 +1
[f1[m, n]e1 + f2[m, n]e2 + f3[m, n]e3] cos
h
2π
om
M + pn
N
i
+ [−f1[m, n]e23 −f2[m, n]e31 −f3[m, n]e12] sin
h
2π
om
M + pn
N
i
B.3
Calcul numérique de la transformée de Fourier inverse
Il est également possible de développer l’expression de la transformée de Fourier inverse :

B.4. Conditions d’initialisation du spectre
127
f[m, n] =
1
√
MN
M
2
X
o=−M
2 +1
N
2
X
p=−N
2 +1
F[o, p] exp2πe123( om
M + pn
N )
=
1
√
MN
M
2
X
o=−M
2 +1
N
2
X
p=−N
2 +1
F[o, p]
h
cos
h
2π
om
M + pn
N
i
+ sin
h
2π
om
M + pn
N
i
e123
i
=
1
√
MN
M
2
X
o=−M
2 +1
N
2
X
p=−N
2 +1
h
cos
h
2π
om
M + pn
N
i
[F0[o, p] + F1[o, p]e1 + · · · + F123[o, p]e123]
+ sin
h
2π
om
M + pn
N
i
[F123[o, p]e123 + F1[o, p]e23 + F2[o, p]e31 + F3[o, p]e12
−F23[o, p]e1 −F31[o, p]e2 −F12[o, p]e3 −F123[o, p]]]
=
1
√
MN
M
2
X
o=−M
2 +1
N
2
X
p=−N
2 +1
h
F0[o, p] cos
h
2π
om
M + pn
N
i
−F123[o, p] sin
h
2π
om
M + pn
N
ii
+
h
F1[o, p] cos
h
2π
om
M + pn
N
i
−F23[o, p] sin
h
2π
om
M + pn
N
ii
e1
+
h
F2[o, p] cos
h
2π
om
M + pn
N
i
−F31[o, p] sin
h
2π
om
M + pn
N
ii
e2
+
h
F3[o, p] cos
h
2π
om
M + pn
N
i
−F12[o, p] sin
h
2π
om
M + pn
N
ii
e3
+
h
F23[o, p] cos
h
2π
om
M + pn
N
i
+ F1[o, p] sin
h
2π
om
M + pn
N
ii
e23
+
h
F31[o, p] cos
h
2π
om
M + pn
N
i
+ F2[o, p] sin
h
2π
om
M + pn
N
ii
e31
+
h
F12[o, p] cos
h
2π
om
M + pn
N
i
+ F3[o, p] sin
h
2π
om
M + pn
N
ii
e12
+
h
F123[o, p] cos
h
2π
om
M + pn
N
i
+ F0[o, p] sin
h
2π
om
M + pn
N
ii
e123
B.4
Conditions d’initialisation du spectre
En reprenant la formulation de la tranformée de Fourier inverse, nous avons :

128
CHAP B - ALGÈBRE GÉOMÉTRIQUE G3
f[m, n] =
1
√
MN
M
2
X
o=−M
2 +1
N
2
X
p=−N
2 +1
h
F0[o, p] cos
h
2π
om
M + pn
N
i
−F123[o, p] sin
h
2π
om
M + pn
N
ii
+
h
F1[o, p] cos
h
2π
om
M + pn
N
i
−F23[o, p] sin
h
2π
om
M + pn
N
ii
e1
+
h
F2[o, p] cos
h
2π
om
M + pn
N
i
−F31[o, p] sin
h
2π
om
M + pn
N
ii
e2
+
h
F3[o, p] cos
h
2π
om
M + pn
N
i
−F12[o, p] sin
h
2π
om
M + pn
N
ii
e3
+
h
F23[o, p] cos
h
2π
om
M + pn
N
i
+ F1[o, p] sin
h
2π
om
M + pn
N
ii
e23
+
h
F31[o, p] cos
h
2π
om
M + pn
N
i
+ F2[o, p] sin
h
2π
om
M + pn
N
ii
e31
+
h
F12[o, p] cos
h
2π
om
M + pn
N
i
+ F3[o, p] sin
h
2π
om
M + pn
N
ii
e12
+
h
F123[o, p] cos
h
2π
om
M + pn
N
i
+ F0[o, p] sin
h
2π
om
M + pn
N
ii
e123
il faut que f0[m, n] = f23[m, n] = f31[m, n] = f12[m, n] = f123[m, n] = 0.
Pour que f0[m, n] = 0 il faut que
f0A[m, n] =
1
√
MN
M
2
X
o=−M
2 +1
N
2
X
p=−N
2 +1
F0[o, p] cos
h
2π
om
M + pn
N
i
= 0
pour cela il faut que ∀(o, p) ∈[−M
2 + 1; N
2 + 1]2, F0[o, p] = −F0[−o, −p]
et
f0B[m, n] =
1
√
MN
M
2
X
o=−M
2 +1
N
2
X
p=−N
2 +1
−F123[o, p] sin
h
2π
om
M + pn
N
i
= 0
pour cela il faut que ∀(o, p) ∈[−M
2 + 1; N
2 + 1]2, F123[o, p] = F123[−o, −p]
En appliquant le même raisonnement pour annuler les autres composantes de f[o, p] mis à part ses
composantes vectorielles, nous obtenons ∀(o, p) ∈[−M
2 + 1; N
2 + 1]2 :
f23[m, n] = 0 ⇔F23[o, p] = −F23[−o, −p] et F1[o, p] = F1[−o, −p]
f31[m, n] = 0 ⇔F31[o, p] = −F31[−o, −p] et F2[o, p] = F2[−o, −p]
f12[m, n] = 0 ⇔F12[o, p] = −F12[−o, −p] et F3[o, p] = F3[−o, −p]
f123[m, n] = 0 ⇔F123[o, p] = −F123[−o, −p] et F0[o, p] = F0[−o, −p]
Nous obtenons donc les conditions générales de symétries du spectre pour pouvoir reconstruire le
signal d’une image couleur par notre transformée de Fourier inverse.
∀(o, p) ∈[−M
2 + 1; N
2 + 1]2

B.5. Interprétation de l’inﬂuence d’un Dirac dans le spectre
129
F0[o, p] = 0
F1[o, p] = F1[−o, −p]
F2[o, p] = F2[−o, −p]
F3[o, p] = F3[−o, −p]
F23[o, p] = −F23[−o, −p]
F31[o, p] = −F31[−o, −p]
F12[o, p] = −F12[−o, −p]
F123[o, p] = 0
B.5
Interprétation de l’inﬂuence d’un Dirac dans le spectre
Dans l’étude suivante nous essayons de caractériser le contenu de l’information fréquentielle com-
prise dans l’espace fréquentiel. Pour cela, nous étudions comme précédemment l’inﬂuence de l’initiali-
sation d’un Dirac (constante), respecter les conditions d’initialisation données par l’équation (4.62), dans
le domaine fréquentiel sur une image (domaine spatial obtenu après transformée de Fourier inverse).
B.5.1
Initialisation sur une composante vectorielle
On choisit d’insérer deux Diracs respectant la condition F1[o0, p0] = F1[−o0, −p0] sur le spectre nul
ailleurs en considérant le centre de l’image comme origine du repère. On effectue ensuite une transformée
inverse.
f(m, n) =

F1[o0, p0] cos
h
2π
o0m
M
+ p0n
N
i
+ F1[−o0, −p0] cos

2π
−o0m
M
+ −p0n
N

e1
+

F1[o0, p0] sin
h
2π
om
M + pn
N
i
+ F1[−o0, −p0] sin

2π
−o0m
M
+ −p0n
N

e23
comme F1[o0, p0] = F1[−o0, −p0] et ∀m ∈R cos(−m) = cos(m) et sin(−m) = −sin(m)
f(m, n) = 2F1[o0, p0] cos
h
2π
o0m
M
+ p0n
N
i
e1
On en déduit par le même raisonnement que l’on obtient le même type de variation en initialisant le
spectre sur la deuxième ou la troisième composante vectorielle
En initialisant sur la deuxième composante vectorielle (F2[o0, p0] = F2[−o0, −p0]), on obtient une
variation de la forme :
f(m, n) = 2F2[o0, p0] cos
h
2π
o0m
M
+ p0n
N
i
e2
Et enﬁn en initialisant sur la troisième composante vectorielle (F3[o0, p0] = F3[−o0, −p0]), on ob-
tient une variation de la forme :
f(m, n) = 2F3[o0, p0] cos
h
2π
o0m
M
+ p0n
N
i
e3

130
CHAP B - ALGÈBRE GÉOMÉTRIQUE G3
B.5.2
Initialisation sur une composante bi-vectorielle
On choisit d’insérer deux Diracs respectant la condition F23[o0, p0] = −F23[−o0, −p0] sur le spectre
nul ailleurs en considérant le centre de l’image comme origine du repère. On effectue ensuite une trans-
formée inverse.
f(m, n) =

−F23[o0, p0] sin
h
2π
o0m
M
+ p0n
N
i
−F23[−o0, −p0] sin

2π
−o0m
M
+ −p0n
N

e1
+

F23[o0, p0] cos
h
2π
o0m
M
+ p0n
N
i
+ F23[−o0, −p0] cos

2π
−o0m
M
+ −p0n
N

e23
comme F23[o0, p0] = −F23[−o0, −p0] et ∀m ∈R cos(−m) = cos(m) et sin(−m) = −sin(m)
f(m, n) = −2F23[o0, p0] sin
h
2π
o0m
M
+ p0n
N
i
e1
On utilise le même raisonnement pour obtenir l’inﬂuence de l’initialisation du spectre par un couple
de Dirac sur la deuxième composante bi-vectorielle F31[o0, p0] = −F31[−o0, −p0] après transfomée de
Fourier inverse :
f(m, n) = −2F31[o0, p0] sin
h
2π
o0m
M
+ p0n
N
i
e2
De même pour l’initialisation du spectre sur la troisième composante bi-vectorielle F12[o0, p0] =
−F12[−o0, −p0] :
f(m, n) = −2F12[o0, p0] sin
h
2π
o0m
M
+ p0n
N
i
e3

ANNEXE C
TRANSFORMÉE EN ONDELETTE
QUATERNIONIQUE
Nous joignons ici comme indiqué à la section 3.5.3.2 une copie de l’article rédigé au sein de l’équipe
déﬁnissant une première approche d’ondelettes couleur en utilisant la technique des bancs de ﬁltres. J’ai
présenté cet article invité à la conférence « Wavelet Applications in Industrial Processing IV », à Boston,
Massachusetts, USA en octobre 2006.
Quaternionic Wavelet Transform for Colour
Images
Philippe Carré and Patrice Denis
Quaternionic Wavelet Transform (QWT) already exist but it dealt with greyscale images. In this
paper we propose a quaternionic wavelet transform aimed to colour image processing. To encode colour
information in our new transformation, a pixel in the spatial domain is represented by a quaternion as
described by Sangwine. First, we propose to use the discrete quaternionic Fourier transform to study
the spectral information of the colour image. It is well known that the frequency space of a real signal
is a complex hermitian signal, we then studied the digital spectral domain of the quaternionic Fourier
transform in order to analyze symmetry properties. This study gives us one characterization of the colour
Fourier domain. Second we use the quaternion formalism to deﬁne a wavelet transform for colour images.
We propose to generalize the ﬁlter bank construction to quaternionic formalism. Especially, we describe
conditions on quaternionic ﬁlters to obtain a perfect reconstruction. We build a ﬁrst colour quaternionic
ﬁlter bank : the colour Shannon Wavelet. This family of functions are based on a windowing process in
the quaternionic Fourier space.
C.1
Introduction
Nowadays, as multimedia devices and internet are becoming accessible to more and more people,
image processing must take colour information into account because colour processings are needed eve-
rywhere with new technologies. In this idea, several approaches have been proposed to deal with colour
image, one of the oldest is to process any greyscale algorithm on each channel of the colour image to get
the equivalent result. Implementing such programs often creates artefacts so researchers have come to
deal differently with colour image information. A quite recent manner to process colour algorithms is to
131

132
CHAP C - TRANSFORMÉE EN ONDELETTE QUATERNIONIQUE
encode the three channels components on the three imaginary parts of a quaternion as proposed by S.T.
Sangwine and T. Ell in [63, 65, 50]. Quaternion have been used in the frequential domain for both greys-
cale images by Bülow [8] and colour ones by Sangwine et al. [65]. Introduction of quaternionic Fourier
transforms has been made independendly by both of the teams above but in different deﬁnitions. We ﬁrst
review the concepts of quaternions. Then introducing the discrete quaternionic Fourier transform propo-
sed again by Sangwine and Ell as well by Bülow for greyscale image processing, we deﬁne the conditions
on the quaternionic spectrum to enable manipulation into this frequency domain without loosing infor-
mation when going back to the spatial domain. This is the subject of the next section which gives an
interpretation of the inﬂuence of Dirac initialization in the quaternionic Fourier space and follows with
graphical illustrations. The second part introduces a quaternionic ﬁlter bank, a tool that allows to analyze
colour image with the classical discrete wavelet transform algorithm. First we generalize to quaternions
domain the two ﬁlters conditions to obtain a perfect reconstruction. We show that these conditions are si-
milar to the complex case. Second, we propose a simple construction of a colour ﬁlter bank : the Shannon
Quaternionic multiresolution which approximates functions by their restriction to differents frequency
intervals. We illustrate this new "wavelet decomposition" on different colour images.
C.2
Quaternion
C.2.1
Deﬁnition
Deﬁnition 1 (Quaternion) Let H = {a + ib + jc + kd | a, b, c, d ∈R}
with i,j,k deﬁned by ij = −ji = k
and
i2 = j2 = k2 = −1
H is called the Quaternion algebra.
H refers to Hamilton[36] who was ﬁrst to introduce these numbers.
Deﬁnition 2 (Conjugate) For any quaternion q = a+ib+jc+kd q = a−ib−jc−kd is the conjugate
of q.
Deﬁnition 3 (Norm) For any quaternion q ∈H |q| = √qq is the norm of q.
Deﬁnition 4 (Inverse) For any quaternion q ∈H q−1 =
q
|q|2 is the inverse of q.
Note that the multiplication of quaternions is not commutative.
Deﬁnition 5 (Real and Imaginary parts) For any quaternion q = a+ib+jc+kd we sometimes write
- ℜq = a is the real part of q. If ℜq = q then q is called real.
- ℑq = ib + jc + kd is the imaginary part of q. If ℑq = q then q is pur.
Deﬁnition 6 (Pur Quaternions) P = {q ∈H | q = ℑq} is called the set of Pur Quaternions.
Deﬁnition 7 (Unit Quaternions) S = {q ∈H | |q| = 1} is called the set of Unit Quaternions.
Quaternion can be expressed in a scalar S(q) and vector part V (q), q = S(q)+V (q) with S(q) = qr
and V (q) = qii + qjj + qkk. Sangwine and Ell were the ﬁrst to use this vector part of quaternion to
encode colour images. They took the three imaginary parts to code the colour components r, g and b of
an image. An N × M image I is in this way represented by a N × M matrix as follow :
q[n1, n2] = r[n1, n2]i + g[n1, n2]j + b[n1, n2]k
where n1 and n2 are the spatial coordinates of the pixel I.
As quaternion are used analogously to R3 vectors, the classical R3 transformations can be deﬁned
with only additions and multiplications.
In order to introduce the frequency domain, we must deﬁne the exponential function for the quater-
nions.

C.2. Quaternion
133
Deﬁnition 8 The exponential function for quaternions is classicaly deﬁned by exp(q) = P+∞
n=0
qk
k! with q ∈
H.
The Euler formula is valid with µ ∈(S ∩P) a pur unit quaternion : eµφ = cos φ + µ sin φ. A unit
quaternion allows us to represent one axis and one angle.
Property 9 Let (φ, ψ) ∈R2 et (µ, ν) ∈(S ∩P)2.
1. eµφeµψ = eµ(φ+ψ)
2. Important fact : the classical property eµeν = eµ+ν is not generally true for quaternions, and
consequently eµeν ̸= eνeµ
C.2.2
Frequency analysis : the Quaternionic Fourier Transform.
Differents works introduced the quaternionic Fourier Transform [8, 65]. We review directly the Dis-
crete version of the Quaternion Fourier Transform.
Deﬁnition 10 Let N ∈N, s ∈L2([0..N −1], H) and µ ∈P ∩S, then the function deﬁned by
∀f ∈[0..N −1], Fµ(s)[f] = S[f] =
N−1
X
n=0
s[n]e−2πµ fn
N
is called the 1-D Discrete Quaternionic Fourier Transform of s with a direction µ.
We can deﬁned a two dimensional Discrete Quaternionic Fourier Transform. The main works in the
litterature about the quaternionic Fourier transform are associated with the 2-D transform to deﬁne a tool
for greyscale image processing [8, 65, 55].
Deﬁnition 11 Let (N, M) ∈(N)2, s ∈L2([0..N −1] × [0..M −1], H) and (µ, ν) ∈(P ∩S)2, the
function deﬁned by ∀(f1, f2) ∈[0..N −1] × [0..M −1],
F l
µ(s)[f1, f2] =
M−1
X
n1=0
N−1
X
n2=0
e−2πµ( n2f2
N
+ n1f1
M )s[n1, n2]
is called the 2-D Left Discrete Quaternionic Fourier Transform of s with a direction µ.
Since the classical property eµeν = eµ+ν is not generally true for quaternion, others Fourier trans-
form can be deﬁned. For example, Bülow [8] introduces a Quaternionic Fourier Transform for the real
valued 2-D function that permits one the analysis of separable oscilllations :
Deﬁnition 12 Let (N, M) ∈(N)2, s ∈L2([0..N −1] × [0..M −1], H) and (µ, ν) ∈(P ∩S)2, the
function deﬁned by ∀(f1, f2) ∈[0..N −1] × [0..M −1],
F l−r(s)[f1, f2] =
M−1
X
n2=0
N−1
X
n1=0
e−2πµ f2n2
M s[n1, n2]e−2πν f1n1
N
(C.1)
is the Discrete Quaternionic Fourier Transform of s proposed by Bülow et al.
All these transforms are invertible.
As shown by Bülow, the last deﬁnition of the QFT allows us for greyscale image to study all the
symmetry properties with independently in n1 and n2. For example, if we split a real valued 2-D signal
into even and odd parts along the two axis :
s[n1, n2] = see[n1, n2] + seo[n1, n2] + soe[n1, n2] + soo[n1, n2]

134
CHAP C - TRANSFORMÉE EN ONDELETTE QUATERNIONIQUE
where seo denotes the part of s which is even with respect to n1 and odd with respect to n2. The Bülow
Quaternionic Fourier transform of the 2-D signal can be summarized by :
S[f1, f2] = See[f1, f2] + i.Soe[f1, f2] + j.Seo[f1, f2] + k.Soo[f1, f2]
This expression shows that the Bülow QFT recovers separate parity structures in n1 and n2 as it sepa-
rately records four real values. To conclude, as said by Bülow, contrary to the classical complex Fourier
transform where the basis function are intrinsically one dimensional, the basis function of the QFT are
intrinsically 2-D. The work of Bülow is the beginning of all the actual deﬁnitions of quaternionic wavelet
transforms.
In this work, the context is different : we search a tool for the processing of Quaternion-valued 2-D
signal (colour image). Here, the quaternion algebra is not used to extract the 2-D image structures but
to analyze vector-valued signals. It is a direct generalization of the 2-D complex Fourier analysis : the
spatial problem is omited (the different parity structures along the two axis are mixed) but the Fourier
transform is adapted for vector-valued signal.
C.3
Colour quaternion spectrum properties
In order to understand what the Fourier coefﬁcients stand for, we study the digital caracterization of
the DQFT.
As we saw, different works introduced the quaternionic Fourier Transform [8, 65], we propose to use
the left version of the Discrete Quaternion Fourier Transform (DQFT) in µ ∈S ∩P direction analysis :
Q[f1, f2] =
1
√
MN
N−1
X
n1=0
M−1
X
n2=0
exp−2µπ
“ f1n1
N
+ f2n2
M
”
q[n1, n2]
and in order to simplify some analysis, we compute the expression for [f1, f2] ∈([−N
2 + 1..N
2 ], [−M
2
+
1..M
2 ]).
C.3.1
Spectrum analysis
Even if the spatial information of a colour image uses pur quaternions only, applying a DQFT on
an image results in full quaternions (i.e. with scalar part non zero). We ﬁrst discovered that the Fourier
spectrum presents some symetries due to zero scalar spatial part of any colour image. These properties
of the Quaternion spectrum are equivalent to the spectrum of a real signal analyzed by a complex Fourier
transform : the specturm has hermitian properties of symmetry. In this section we ﬁnd the quaternionic
spectrum’s properties leading to a spatial quaternionic domain after an inverse DQFT (IDQFT) where
the scalar part is zero.
C.3.1.1
The real part’s cartesian form
We want to ﬁnd, after IDQFT, a set where scalar part will be zero in order to avoid any loss of
information because the spatial image is coded on a pur quaternion matrix which real part is automatically
set to zero.
Let
Q[f1, f2] = Qr[f1, f2] + Qi[f1, f2]i + Qj[f1, f2]j + Qk[f1, f2]k
be the spectral quaternion at coordinate [f1, f2] ∈([−N
2 + 1..N
2 ], [−M
2
+ 1..M
2 ]) and
q[n1, n2] = qr[n1, n2] + qi[n1, n2]i + qj[n1, n2]j + qk[n1, n2]k
the IDQFT quaternion at [n1, n2] spatial coordinates.
Developping the IDQFT, the cartesian real part form of the spatial domain leads to

C.3. Colour quaternion spectrum properties
135
ℜq = qr[n1, n2] =
1
√
MN
P N
2
f1=−N
2 +1
P M
2
f2=−M
2 +1
h
cos(2π

f1n1
N
+ f2n2
M

)Qr[f1, f2]
−µi sin(2π

f1n1
N
+ f2n2
M

)Qi[f1, f2] −µj sin(2π

f1n1
N
+ f2n2
M

)Qj[f1, f2] −µk sin(2π

f1n1
N
+ f2n2
M

)Qk[f1, f2]
i
with µ = µi.i + µj.j + µk.k ∈S ∩P.
We observe that qr is null when Q has anti-hermitian properties of symmetry :
Qr(−f1, −f2) = −Qr(f1, f2) ; Qi(−f1, −f2) = Qi(f1, f2) ; Qj(−f1, −f2) = Qj(f1, f2) ; Qk(−f1, −f2) = Qk(f1, f2)
We will see in the next section how these properties are important for the interpretation of the qua-
ternionic Fourier transform because any initialization on the spectrum must obey to them if we want to
keep the spatial information safe.
C.3.1.2
How a spectrum Dirac interferes with the spatial domain
When studying the complex spectrum domain, several notions are helpfull as the modulus and the
angle. In this section we give an interpretation of the information contained in the quaternionic spectrum
of colour images. We thus initialize the spectrum with a Dirac and studied the response in the spatial
domain after a IDQFT. But the spectrum must present anti-hermitian properties of symmetry in order to
obtain a spatial image after IQFT without loss of information. There are different cases for initialization
– Initialization on the real component
In this case the initialization must be made with the Qr(S0, T0) = Kr and Qr(−S0, −T0) = −Kr
conditions
q[n1, n2] = 0 + 2Kr sin

2π
S0n1
N
+ T0n2
M

.(µi + µj + µk)
Initializating the real part of the spectrum with the proper conditions leads to assume zero real part
after IDQFT and discover that the three imaginary components associate odd variations for each
corresponding colour component channel ponderated by the analysing direction µ chosen in the
IDQFT.
– Initialization on an imaginary component
In this case the initialization must be made with the Qe(S0, T0) = Qe(−S0, −T0) = Ke (with e =
i or j or k) condition so after IDQFT the spatial image corresponding to e-imaginary component
is represented on its following cartesian form
q[n1, n2] = 0 + 2Ke cos

2π
S0n1
N
+ T0n2
M

.µe
with e = i or j or k according to the initialization.
In these cases, initializating any imaginary part of the spectrum with the proper conditions supplies
the real zero component after inverse transform and shows that there is even variations on the
imaginary components corresponding to the one which has been initialised in the spectrum. We
observe that the analysing direction µ chosen in the IDQFT has no inﬂuence.
C.3.2
Graphical Illustration
C.3.2.1
Initialization on a spectrum’s imaginary part with any µ ∈S ∩P
As we saw in the previous section, to set a pair of constants that follow the necessary conditions
on one imaginary component of the quaternionic spectrum leads to a spatial oscillation on the same
component after processing a IDQFT. For example if the initialization is done on the ﬁrst frequency

136
CHAP C - TRANSFORMÉE EN ONDELETTE QUATERNIONIQUE
component, the spatial oscillation that will arise from the IDQFT will be on the ﬁrst spatial component
coding the image, that is to say the red channel if working in RGB colour space. The initialization can
be done on several components, in that case, the result will affect the same components that would have
been modiﬁed. In our case as the following example are taken from a RGB colour space, multiple ini-
tializations (always under the conditions for correct spatial reconstruction) on the spectrum will produce
spatial oscillation following the rules of the addivive synthesis of the colour. The µ parameter does not
interfere in this case. Some experimentations are done in ﬁgure C.1.
If we initialize the spectrum on each imaginary component with the same couple of constants, the
spatial result after IDQFT on a RGB colour space will be a grey oscillation.
FIG. C.1 – Initialization examples with µ = µGrey. (a) : init with µGrey Qi[f1, f2] = Ki et
Qi[−f1, −f2] = Ki ; (b) : init with µGrey Qj[f1, f2] = Kj, Qk[f1, f2] = Kk, Qj[−f1, −f2] = Kj and
Qk[−f1, −f2] = Kk ; (c) : initialization with µGrey Qi[f1, f2] = Ki, Qj[f1, f2] = Kj, Qk[f1, f2] = Kk,
Qi[−f1, −f2] = Ki, Qj[f1, f2] = Kj and Qk[−f1, −f2] = Kk where µGrey = i+j+k
√
3
the grey vector
which gives the same weight on each component.
C.3.2.2
Initialization on the spectrum’s real part with any µ ∈S ∩P
We saw as well in the calculus part that initialization on the spectrum could be done on the real
component. In that case we can also get different kinds of oscillation after processing a IDQFT assuming
that the conditions proposed before are preserved. To get oscillation on a wanted component, the IQFT
has to been set with th direction µ that corresponds. In other words, if working in RGB colour space for
example, to get red oscillation, the µ parameter must be equal to the corresponding quaternion component
i. Oscillations composed of numerous colours can be found in setting the µ parameter properly, as i+j
√
2
the get yellow variation in the RGB colour space after IDQFT. Some experimentations are done in ﬁgure
C.2.
FIG. C.2 – Initialization examples with µ ̸= µGrey. (a) : init with µRed = i, Qr[f1, f2] = Kr and
Qr[−f1, −f2] = −Kr ; (b) : init with µMagenta = i+k
√
2 , Qr[f1, f2] = Kr and Qr[−f1, −f2] = −Kr

C.4. Quaternionic Filters Bank
137
C.3.2.3
Geometric Variations
As in the complex plan, coordinates of the pixels involved in the quaternionic Fourier space’s initiali-
zation is a really important parameter. Indeed the resulting oscillation by the IDQFT process will have a
geometric orientation linked to this. Supposing that coordinates are given in Z2 with the pixel O(0, 0) in
the center of the image (whereas on the top-left corner as often), the IDQFT will give an oscillation that
follows the orthogonal axis of the line linking the two pixels involved in the initialization and crossing
the origin O. Some experimentations are done in ﬁgure C.3.
FIG. C.3 – Geometric oscillation examples. (a) : init with µY ellow, Qr[−f1, −f2] = Kr and Qr[f1, f2] =
−Kr ; (b) : init with µY ellow, Qr[−f1, 0] = Kr and Qr[f1, 0] = −Kr
This ﬁrst section illustrates the fact that the Quaternionic spectrum includes evidently similar infor-
mation than the 2-D complex spectrum : the frequency coordinates are associated with the geometric
orientation and the level (low or high) of the features. Then, the second part of this article proposes to
split this quaternionic spectrum into different domains in order to separate the different components of
the colour image. For this, we propose to generalize the concept of ﬁlter bank to quaternions.
C.4
Quaternionic Filters Bank
The Fourier transform has some limitations. The more important is the fact that we loose the notion
of chronology in the frequency domain. To acquire a performant strategy of signal analysis, we need a
joint spatial/frequential representation. The discrete wavelet transform and the associated ﬁlter bank is
able to ﬁt to this representation family. The aim of the ﬁlter bank is the study of the behaviour of the
different frequency bands. In order to realize this transform, the algorithm proposes to use some ﬁltering
operations. If we can deﬁne a set of ﬁlters that cut the frequency axis in several segments, we can also
study, from all the ﬁltered signals, the space behaviour of the different frequency bands.
We want to deﬁne a representation that allows to extract the different frequency components of a
signal. This representation must be not redundant : if the signal is represented with N samples, the
wavelet representation must contains N coefﬁcients. Moreover, this representation must be invertible :
a perfect reconstruction of the original signal from the coefﬁcients. Finaly we want to deﬁne a simple
algorithm : all the ﬁlters must be deﬁned from four lowpass and highpass ﬁlters.
A ﬁlter bank is a set of ﬁlters, linked by sampling operators. The downsampling operators are de-
cimators, the upsampling operators are expanders. In a two-channel ﬁlter bank, the analysis/synthesis
ﬁlters are normally lowpass and highpass. We illustrate the ﬁlter banks in ﬁgure C.4. More details about
the classical concept of ﬁlter banks and wavelet is presented, for example, in [71, 46].
The goal of this section is to discover the conditions on the different ﬁlters for perfect reconstruction :
s = s′ with s ∈L2([0..N −1] × [0..N −1], H).
In the literature, three Quaternionic discrete wavelet transforms have been recently proposed :

138
CHAP C - TRANSFORMÉE EN ONDELETTE QUATERNIONIQUE
FIG. C.4 – Two-channel ﬁlter bank
– Bayro [4] has proposed a Quaternionic wavelet transform for greyscale image (s ∈L2([0..N −
1], R)) with the principle of the modulated Gabor ﬁlters in quadrature. The used ﬁlters are deﬁned
as :
h[n1, n2] = gσ[n1, n2]e2iπf1n1e2jπf2n2
with σ the standard deviation of the gaussian window and f1, f2 the frequency coordinates. We
observe that the deﬁnition of this wavelet transform is an extension of the Bülow’s work C.1. This
expression shows that the Bayro wavelet decomposition recovers separate parity local structure
in n1 and n2. From the Gabor quaternionic coefﬁcients, a concept of three phases is introduced
(similar than the phases introduced by Bülow [8]). In the paper, the author proposed to use the
phase concept in order to estimate the optical ﬂow of the analyzed image. Notice that this wavelet
decomposition is tunned for analysis and no discussion is done about reconstruction.
– Chan et al [12, 13] proposed a Quaternionic wavelet transform for greyscale image as a direct
extension of the complex wavelet decomposition proposed by Kingsbury. In 1-D the complex
wavelet transform uses complex wavelet basis functions that form a 1-D Hilbert transform pair
(the spectrum of the complex wavelet function has no energy in the negative frequency region).
The 1-D complex wavelet transform is redundant but the magnitudes of the coefﬁcients are shift
invariant. Chan et al proposed to extend this principle to 2-D. This is done by deﬁning the four
components of the quaternionic wavelet function from the 1-D Hilbert transform of the 2-D real
tensor product wavelet function along and both the horizontal and vertical directions. According to
the authors this quaternionic wavelet transform is approximately a localized Bülow quaternionic
Fourier transform. As for the ﬁrst presented work, the authors proposed to use the phase concept
in order to estimate the optical ﬂow of the analyzed image.
– Olhede et al [52] proposed the hyperanalytical wavelet transform for greyscale image. This work is
similar than Chan transform : the four components of the quaternionic wavelet function are deﬁned
from the 1-D Hilbert transform of a 2-D real wavelet function along and both the horizontal and
vertical directions. This new basis is called Hypercomplexing wavelet. A second family is also
proposed by them from the work of Felsberg et al [30] and is called Monogenic wavelets.
All these works are linked with the work of Bülow and are approximatly equivalent to a localized Bü-
low quaternionic Fourier transform. All these transforms allows us to study all the symmetry properties
independently from the two directions and with a localized transform for greyscale image.
As for the Fourier transform, in this work we want to deﬁne a tool for processing Quaternion valued
2-D signal (colour image), in order to analyze vector valued signals. This problem is not actually studied
in the literature. Moreover, the main part of our presented work is the deﬁnition of the ﬁlter banks and not
the wavelet function, in order to obtain a numerical transform with perfect reconstruction. We propose
now to study in the quaternion domain the three elements of a ﬁlter banks : convolution, downsampling
and upsampling.

C.4. Quaternionic Filters Bank
139
C.4.1
Filtering operation : convolution product
As for the complex case, one way to describe the ﬁltering operation in the quaternions domain is to
see it as a "black box" system, having an input e and an output s. The ﬁltering can be translated by the
convolution product between e, the original signal, and h, the impulse response of the ﬁlter system :
Deﬁnition 13 The function deﬁned by ∀t ∈R, and e, h ∈L2(R, H) s(t) = e⊛h(t) =
R
e(τ).h(t−τ)dτ
is the Quaternionic convolution product between e and h.
In the case of a numerical system, there is the same type of relation. When the input and output
signals are sampled, the impulse response is a sampled signal {h [k]}k∈N. The link between the output
and input is then a discrete convolution :
Deﬁnition 14 (DQCV) Let N ∈N, e, h ∈L2([0..N −1], H) : The function deﬁned by ∀n ∈[0..N −1]
s[n] = e ⊛h[n] =
N−1
X
τ=0
e[|n −τ|N]h[|τ|N]
is the Right Discrete Quaternionic convolution product between e and h.
The notation |p|N indicates that the indexes are calculated modulo N. Since the quaternionic product is
not commutative, others convolution product can be deﬁned.
The convolution theorem of the Fourier transform states that convolution of two signals in the spatial
domain corresponds to their pointwise multiplication in the frequency domain, i.e.
g[n] = s ⊛h[n] ⇐⇒G[f] = S[f].H[f]
Since the quaternionic product is not commutative, this classical property is not generally true for
quaternion.
Let (e, ⃗µ,⃗ν, ⃗µν) be an orthonormal basis of H, we can ﬁrst decompose h as :
h[n] = ha[n] + hb[n].⃗ν
where ha[n] = he[n] + hµ[n].⃗µ and hb[n] = hν[n] + hµν[n].⃗µ with he, hµ, hν and hµν the projection of
h on (e, ⃗µ,⃗ν, ⃗µν).
Property 15 Let h, e ∈L2(0..N −1, H) and s deﬁned by s = h ⊛e such that s ∈L2(0..N −1, H).
then ∀f ∈[0..N −1],
F l
µ(s)[f] = F l
µ(ha)[f]F l
µ(e)[f] + F l
µ(hb)[f]⃗νF l
µ(e)[−f]
In some special conditions, the precedent relation can be simpliﬁed. In the case where e has the even
symmetry relation :
e[n] = e[−n] ⇔E[f] = E[−f]
then we can prove that convolution of two signals in the spatial domain corresponds to their pointwise
multiplication in the frequency domain.
In order to simplify the quaternion ﬁlter design, we can reverse the problem and ask what forms in
the spatial domain correspond to the product operation in the frequency domain. The result is similar :
Property 16 Let h, e ∈L2(0..N −1, H) and s deﬁned by S[f] = H[f].E[f] then ∀n ∈[0..N −1],
s[n] = ha ⊛e[n] + (hb.⃗ν) ⊛e[−n]
All these problems are presented in details in other forms by Pei et al [55].

140
CHAP C - TRANSFORMÉE EN ONDELETTE QUATERNIONIQUE
C.4.2
Deﬁnition of the downsampling
We want to modelise the inﬂuence in the quaternionnic frequency domain of the downsampling in
the spatial domain. A downsampling operation can be deﬁned such that : we keep only half of the signal
(for example the odd-numbered samples are lost). Downsampling is represented by s →↓2 →s′.
Proposition 17 Let N ∈N, s ∈L2([0..N −1], H) µ ∈P ∩S and S[f] = F l
µ(s)[f] then as for the
classical complex case, it means that the downsampling of the signal can be deﬁned in the quaternionic
frequency domain :
s′ = [↓2] s =⇒S′[f] = 1
2

S[f] + S[f + N
2 ]

for f = 0...N
2 −1
with S′ a N
2 periodic sequence.
In order to analyse the downsampling in the frequency domain we split the process ↓2 into two
operations :
Let u be the vector s with its odd-numbered components set to zero :
u[n] =
 s[n] if n even
0 otherwise
u[n] can be deﬁned such that :
u[n] = 1
2 (s[n] + (−1)ns[n])
The second term includes (−1)n so that addition knocks out odd n. Since µ ∈P ∩S we can write
(e−µπ)n = (−1)n and thus
u[n] = 1
2
 s[n] + (e−µπ)ns[n]

In the frequency domain, we have :
U[f]
=
N−1
X
n=0
e−2µπ fn
N .u[n] =
N−1
X
n=0
1
2e−2µπ fn
N  s[n] + (e−µπ)ns[n]

=
1
2
"N−1
X
n=0
e−2µπ fn
N .s[n] +
N−1
X
n=0
e−2µπ fn
N −µπn.s[n]
#
for f = 0...N −1
then
U[f] = 1
2

S[f] + S[f + N
2 ]

for f = 0...N −1
The second step is such that :
s′[n] = u[2n]
because the result only involves even n.
In the frequency domain, we obtain
S′[f]
=
N
2 −1
X
n=0
e−2µπ fn
N/2.u[2n] for f = 0...N
2 −1
with the following variable change n′ = 2n
=
N−1
X
n′=0
e−2µπn′ 2
N ( f
2).u[n′] = U[f] for f = 0...N
2 −1
It means that the downsampling of the signal can be deﬁned in the quaternionic frequency domain :
s′ = [↓2] s =⇒S′[f] = 1
2

S[f] + S[f + N
2 ]

for f = 0...N
2 −1
Since S is N-periodic, we observe that S′ is N
2 -periodic.

C.4. Quaternionic Filters Bank
141
C.4.3
Deﬁnition of the upsampling
During the reconstruction process the ﬁrst step is to bring back full-length vectors. For this, we apply
the upsampling operation. The odd-numbered components are returned as zeros by upsampling. Applied
to a half-length signal, upsampling inserts zeros.
We want to analyse the upsampling in the quaternionic frequency domain. The signal reached by
upsampling have zeros in their odd components :
s′ = [↑2] s =⇒
 s′[2k] = s[k]
s′[2k + 1] = 0
with {s[k]}k=0... N
2 −1
Proposition 18 Let N ∈N, s ∈L2([0..N
2 −1], H) µ ∈P ∩S and S[f] = F l
µ(s)[f] then
s′ = [↑2] s =⇒S′[f] = S[f] for f = 0...N −1
with S a N
2 -periodic sequence.
The quaternionic Fourier transform of s′ is
S′[f] =
N−1
X
n=0
e−2µπ fn
N .s′[n] for f = 0...N −1
If n is even then s′[n] = s[n/2] otherwise s′[n] = 0. The quaternionic fourier transform can thus be
written :
S′[f]
=
N−1
X
n=0 n even
e−2µπ fn
N .s[n/2] we set k = n/2
=
N/2−1
X
k=0
e−2µπ (2f)k
N .s[k] =
N/2−1
X
k=0
e−2µπ fk
N/2.s[k]
=
S[f] for f = 0...N −1
C.4.4
Quaternionic Filter banks with perfect reconstruction
As we said the goal of this section is to discover the conditions for perfect reconstruction : s = s′
with s ∈L2([0..N −1], H).
In this paper, we consider that the ﬁltering operation can be translated by a product :
Deﬁnition 19 Let N ∈N, e ∈L2([0..N −1], H), E = F l
−µ(e) the left Quaternionic Fourier transform
of the orginal signal e of µ direction and H ∈L2([0..N −1], H) H = F l
−µ(h) the frequency answer of
the ﬁlter and µ ∈(P ∩S).
The function deﬁned by ∀f ∈[0..N −1] S[f] = H[f].E[f] is the ﬁltering operation of e by h.
Because the input and ouput have a very simple relation, the spectrum product is more suitable for
the application of quaternionic ﬁlter bank design (it is similar to the complex case).
The conditions are deﬁned directly in the discrete quaternionic Fourier domain : we consider H ∈
L2([0..N −1], H) a N-periodic sequence corresponding to the frequency answer of the low-pass ﬁlter
(with index 0 for the analysis and index 1 for the reconstruction), G ∈L2([0..N −1], H) a N-periodic
sequence corresponding to the frequency answer of the high-pass ﬁlter (with index 0 for the analysis and
index 1 for the reconstruction) and S = F l
−µ(s) a N-periodic sequence corresponding to the left discrete
Quaternionic Fourier transform of the original signal s of µ direction with s ∈L2([0..N −1], H) and
µ ∈(P ∩S).

142
CHAP C - TRANSFORMÉE EN ONDELETTE QUATERNIONIQUE
If we study the lowpass channel of the ﬁgure C.4 :
c1
=
[↓2] (filtering(h0, s))
C1[f]
=
1
2

H0[f]S[f] + H0[f + N
2 ]S[f + N
2 ]

for f = 0...N
2 −1
Now upsample and ﬁltering :
C′
1[f] = 1
2H1[f]

H0[f]S[f] + H0[f + N
2 ]S[f + N
2 ]

for f = 0...N −1
The highpass output is the same formula with ﬁlters H changed to ﬁlters G :
D′
1[f] = 1
2G1[f]

G0[f]S[f] + G0[f + N
2 ]S[f + N
2 ]

for f = 0...N −1
The ﬁlter bank combines the two channel to get s′
S′[f] = 1
2 [G1[f]G0[f] + H1[f]H0[f]] .S[f] + 1
2

G1[f]G0[f + 1
2] + H1[f]H0[f + 1
2]

S[f + 1
2]
We deduce that a 2-channel ﬁlter bank gives perfect reconstruction when :
– No distortion :
G1[f]G0[f] + H1[f]H0[f] = 2 for f = 0...N −1
(C.2)
– Alias cancellation
G1[f]G0[f + N
2 ] + H1[f]H0[f + N
2 ] = 0 for f = 0...N −1
(C.3)
We observe that we obtain same conditions as classical ﬁlter banks but the order of the elements is
important. Since the quaternionic product is not commutative, by using other deﬁnitions for the ﬁltering
operation we can obtain other conditions.
In order to illustrate the Quaternionic wavelet transform for colour image, we propose now a simple
construction : the colour Shannon ﬁlter bank.
C.4.5
An example : the Quaternionic Shannon ﬁlter bank
The Shannon wavelet is constructed from the Shannon multiresolution approximation which approxi-
mates functions by their restriction to low frequency intervals. This multiresolution is associated with this
following low-pass ﬁlter :
H(ξ) =
√
2.1[−1
4 , 1
4 ] for ξ ∈[−1
2, 1
2] with H(ξ) =
X
n
h[n]e−2jπξn
We propose to adapt the Shannon ﬁlter bank to the discrete quaternionic domain. We can add one
condition on the ﬁlters :
– The wavelet coefﬁcients must be pur quaternion (to be a "colour" coefﬁcient).
The signals c1 and d1 of the ﬁgure C.4 must be such that c1, d1 ∈L2([0..N −1], P). The quater-
nionic Fourier transform of c1 and d1 must have antihermitian properties of symmetry.
Moreover we propose to follow the concept of two-channel multirate ﬁllter bank with conjugate
mirror ﬁlters : the reconstruction ﬁlters are the reverse version of the analysis ﬁlters : h1[n] = h0[−n]
and g1[n] = g0[−n]. We know that if h1, g1 are real, then H1[f] = ¯
H0[f] and G1[f] = ¯
G0[f].
In this case, we propose that the two low-pass ﬁlters are deﬁned such that :

C.4. Quaternionic Filters Bank
143
H0[f] = H1[f] =





√
2 for f∈[0, N
4 −1]∪[ 3N
4 +1,N−1]
0 for f ∈[N
4 + 1, 3N
4 −1 ]
In this case G0 et G1 must satisfy :
 G0[f]G1[f] = 0
G0[f + N
2 ]G1[f] = 0
for f ∈[0, N
4 −1] ∪[3N
4 + 1, N −1]
 G0[f]G1[f] = 2
G0[f + N
2 ]G1[f] = 0
for f ∈[N
4 + 1, 3N
4 −1]
We propose this simple solution :
G0[f] = G1[f] =
 0 for f ∈[0, N
4 −1] ∪[3N
4 + 1, N −1]
√
2 for f ∈[N
4 + 1, 3N
4 −1]
It remains the spectral crossover points at f =
N
4 and f =
3N
4
because at these points H0[f +
N
2 ]H1[f] ̸= 0 if H0[N
4 ] = H0[3N
4 ] =
√
2.
We propose the following relations for the spectral crossover points :
H0[N/4] = H0[3N/4] = 1 ; H1 = ¯
H0
G0[N/4] = −1.G0[3N/4] = µ ; G1 = ¯
G0
with µ ∈P ∩S. With these deﬁnitions H0, G0, H1, and G1 satisfy the condition for perfect reconstruc-
tion. Moreover H0 and G0 have hermitian properties of symmetry.
We deﬁned the four ﬁlters required for the wavelet decomposition/reconstruction. But colour images
are two-dimensional and for this, we must have two-dimensional ﬁlters. Their construction can be easy
if we use a separable strategy : products of one-dimensional ﬁlters. For this, we apply the 1D wavelet
transform on each line of the image and we apply the 1D wavelet transform on each column of the
precedent matrix.
To conclude this section about quaternionic ﬁlters, we can make some remarks about the deﬁnition of
the high-pass ﬁlter. We have proposed an empirical procedure to deﬁne G0 but in the classical approach
about perfect reconstruction ﬁlter bank, a more systematic relation is deﬁned[71, 46] :
G0(ξ) = e−2jπξ. ¯
H0(ξ + 1
2)
One can wonder whether this relation is valid for quaternionic ﬁlter banks and whether it permits to
satisfy the conditions C.2 and C.3 (with H1[f] = ¯
H0[f] and G1[f] = ¯
G0[f]) :
G[f] ¯G[f] + H[f] ¯H[f] = 2 for f = 0...N −1
(C.4)
¯G[f]G[f + N
2 ] + ¯H[f]H[f + N
2 ] = 0 for f = 0...N −1
(C.5)
We propose two generalizations :
G[f] = e−2µπ f
N ¯H[f + N
2 ]
(C.6)
G[f] = ¯H[f + N
2 ]e−2µπ f
N
(C.7)
These two relations are not equivalent since the product is not commutative.

144
CHAP C - TRANSFORMÉE EN ONDELETTE QUATERNIONIQUE
– For the generalization C.6 :
G[f] ¯G[f] = e−2µπ f
N ¯H[f+N
2 ].H[f+N
2 ].e2µπ f
N = e−2µπ f
N |H[f+N
2 ]|2.e2µπ f
N =
H[f + N
2 ]

2
The ﬁrst condition (C.4) is satisﬁed if H is such that (a classical condition for orthonormal decom-
position) :
H[f + N
2 ]

2
+ |H[f]|2 = 2
(C.8)
¯G[f]G[f + N
2 ] = H[f + N
2 ]e2µπ f
N .e−2µπ f+0.5N
N
¯H[f] = −H[f + N
2 ] ¯H[f]
The second condition (C.5) is satisﬁed if H is such that H[f + N
2 ] ¯H[f] = ¯H[f]H[f + N
2 ]. It is
the case if H is real.
– For the generalization (C.7) :
G[f] ¯G[f] = ¯H[f + N
2 ]e−2µπ f
N .e2µπ f
N H[f + N
2 ] =
H[f + N
2 ]

2
We obtain the same result as for the relation (C.6).
¯G[f]G[f + N
2 ] = e2µπ f
N .H[f + N
2 ]. ¯H[f]e−2µπ f+0.5N
N
We can not simplﬁfy this expression since the product is not commutative. However, the second
condition (C.5) is always satisﬁed if H is real.
We conclude that if H is real and if it satisﬁes equation (C.8), we can use the relation (C.6) or (C.7)
to deﬁne the high-pass ﬁlter. It is the case for our Shannon low-pass ﬁlter, and thus G can be deﬁned
by G[f] = e−2µπ f
N ¯H[f + N
2 ] for f = 0...N −1. It is the direct extension of the classical Shannon
multiresolution to quaternion domain.
C.4.6
Experimentation
First, in order to illustrate the precedent construction, we propose to show three analysis functions
associated with our ﬁlter bank (ﬁgure C.5). Like the analysis of the frequency domain, we initialised the
"wavelet" domain with a Dirac and studied the response in the spatial domain after an inverse transform.
We observe that the atoms correspond to coloured "classical" wavelet (µ = µgrey).
To illustrate this decomposition, we create a test image from three coloured objects (ﬁgure C.6.a)
and we use a natural image (ﬁgure C.7.a). We observe that the representation contains all the expected
elements : the low-pass part correspond to the coarse approximation of the colour image ; the high-pass
part tend to be sparse : a coefﬁcient is large only if edges are present within the support of the wavelet.
Moreover the colour of the coefﬁcients gives information about the colour of the discontinuities.
C.5
Conclusion
In this paper, we presented the conditions needed to reconstruct properly a colour signal after a µ
directional IDQFT without any loss of information, that is to say the spatial scalar part is zero. We
discussed as well on the inﬂuence of an initialization of the quaternionic spectrum by a Dirac and gave
an interpretation of Fourier coefﬁcient inﬂuence on the spatial domain with both calculus and graphical
illustrations. Then in a second part, we used the previous concepts to propose a new quaternionic ﬁlter
bank deﬁnition. In that way, both discrete spectrum condition for a perfect reconstruction have been
discussed. To apply this new concept, we proposed a simple version of the colour ﬁlter bank. The new
transform is illustrated on two colour images.

C.5. Conclusion
145
FIG. C.5 – Analysis functions associated with the proposed ﬁlter bank
FIG. C.6 – The wavelet decomposition of a simple test image : (a) Original image (b) The wavelet
coefﬁcients (c) the decomposition normalized for each plan
FIG. C.7 – The wavelet decomposition of a natural image : (a) Original image (b) The decomposition
normalized for each plan
This paper must be considered as the beginning of a more complete discution because some impor-
tant questions remains open : the deﬁnition of more regular quaternionic ﬁlters, the using of this new
wavelet coefﬁcients for the analysis of colour image, the extension of the concept of multiresolution to
quaternions ...


ANNEXE D
SPATIAL AND SPECTRAL QUATERNIONIC
APPROACHES FOR COLOUR IMAGES
Nous joignons ici l’article paru dans le journal « Computer Vision and Image Understanding », spe-
cial issue on Color Image Processing, en juillet 2007 et traitant des aspects spatiaux et fréquentiels
développés avec le formalisme des quaternions.
Spatial and spectral Quaternionic approaches
for Colour Images
Patrice Denis, Philippe Carré and Christine Fernandez-Maloigne
University of Poitiers - SIC Laboratory - Bat SP2MI - Bd Marie et Pierre Curie B.P. 30179 -
86962 Futuroscope Chasseneuil Cedex - FRANCE
Hypercomplex or quaternions numbers have been used recently for both greyscale and colour image
processing. Fast, numerous hypercomplex 2D Fourier transforms were presented as a generalization of
the complex 2D Fourier transform to this new hypercomplex space. Thus, the major problem was to put
an interpretation of what information the Fourier coefﬁcients could provide. In this paper, we ﬁrst deﬁne
the conditions on the spectrum coefﬁcients needed to reconstruct a colour image without loss of
information through the inverse quaternionic Fourier transform process. The result is used to interpret
the quaternionic spectrum coefﬁcients of this speciﬁc colour Fourier transform. Secondly, with this
apprehension of the quaternion numbers and the corresponding colour spectrum space, we deﬁne spatial
and frequential strategies to ﬁlter colour images.
quaternions ; quaternionic Fourier transform ; colour image processing ; ﬁlter ; symmetry conditions
Nowadays, as multimedia devices and internet are becoming accessible to more and more people,
image processing must take colour information into account because colour processing is needed eve-
rywhere for new technologies. Several approaches have been submitted to deal with colour images, one
of the oldest is to process each channel of the colour image separately. Implementing such programs
often creates colour shifts and artefacts, so different approaches should be used to produce visually plea-
sing colour images. A quite recent approach is to encode the three channel components on the three
imaginary parts of a quaternion as proposed by S.T. Sangwine and T. Ell in [63, 50, 49]. Quaternions
have been used for both greyscale images by Bülow [8] and colour ones by Sangwine et al. [63]. An
147

148
CHAP D - SPATIAL AND SPECTRAL QUATERNIONIC APPROACHES FOR COLOUR
IMAGES
introduction of quaternionic Fourier transforms has been made independently by both the teams above
but in different deﬁnitions. In this paper, we study the Quaternionic Fourier spectrum in order to deﬁne
precisely the properties of this new colour representation. In this way, we want to explain the colour
information contained in the new domain that is to say how the different real and imaginary parts of
the spectral quaternionic domain interact with the pure quaternion component chosen to encode colours
in spatial domain. The other fundamental studied topic in the paper is the ﬁltering aspect. Indeed, we
review spatial colour ﬁlter approaches, introduce a new spatial gradient approach using quaternions, and
validate a new quaternionic spectral colour ﬁlter.
The ﬁrst section of this paper reminds what the quaternions are and how to use them to process colour
information. Then we study how quaternions can be used to make R3 transformations such as projections,
rotations, etc. As an example, these transformations are used to switch from RGB to HSV colour spaces.
The second section introduces the discrete quaternionic Fourier transform proposed by Sangwine and
by Bülow, and we deﬁne the conditions on the quaternionic spectrum to enable manipulations into this
frequency domain without loosing information when going back to the spatial domain. This is also the
subject of the second section which gives a new interpretation of the inﬂuence of Dirac initialization
on the quaternionic Fourier space. The third section starts by surveying existing colour image ﬁltering
approaches based on quaternions. Then, we use the R3 transformations deﬁned in the ﬁrst section and
the analysis of the quaternionic frequency domain in the second section to propose the deﬁnitions of a
new quaternionic vector gradient and a frequency quaternionic ﬁlter. Finally, the appendix gives more
details with formulas and graphics to help understand the information included in the quaternionic colour
spectrum.
D.1
Quaternions
D.1.1
Concept
A quaternion q ∈H (H refers to Hamilton[36] who was ﬁrst to discover these numbers) is a genera-
lization of a complex number and is deﬁned as q = qr + qii + qjj + qkk where :
– qr, qi, qj and qk are real numbers.
– i, j and k are three new imaginary numbers, asserting :
i2 = j2 = k2 = −1
ij = −ji = k
jk = −kj = i and ki = −ik = j
With q = qr + qii + qjj + qkk any quaternion :
– q = qr −qii −qjj −qkk is q’s conjugate.
– q’s modulus or norm is
q
q2r + q2
i + q2
j + q2
k = √qq noted |q|.
– if q ̸= 0, then q−1 =
q
|q|2 is q’s inverse.
– ℜ(q) = qr is q’s real part. If ℜ(q) = q, then q is real.
– ℑ(q) = ib + jc + kd is q’s imaginary part. If ℑ(q) = q, then q is pure.
– P = {q ∈H | q = ℑ(q)} is the Pure Quaternion set.
– S = {q ∈H | |q| = 1} is the Unitary Quaternion set.
Note that the quaternion product is anti-commutative.
Quaternions can be expressed using scalar part S(q) and vector part V (q), q = S(q) + V (q) with
S(q) = qr and V (q) = qii + qjj + qkk. Sangwine and Ell [63, 50, 49, 65, 66, 27] were the ﬁrst to use
this vector part of quaternions to encode colour images. They took the three imaginary parts to code the r
(red), g (green) and b (blue) colour components of an image. A colour image I with the spatial resolution
of N × M pixels is in this way represented by an N × M matrix as follow :
q(s, t) = r(s, t)i + g(s, t)j + b(s, t)k
where s = 1, 2, ..., N and t = 1, 2, ..., M are the spatial coordinates of the pixel q.

D.1. Quaternions
149
D.1.2
R3 Transformations with Quaternions
As pure quaternions are used analogously to describe R3 vectors, the classical R3 transformations
such as translations, reﬂections, projections, rejections and rotations can be deﬁned with only addi-
tions and multiplications as explained by Sangwine in [66] (cf. ﬁgure D.1). With two pure quaternions
(q1, q2) ∈P2, the translation vector is supported by the quaternion qtrans = q1 + q2. If q ∈P and
µ ∈S ∩P then qrefl = −µqµ is the q’s reﬂection vector with µ axis. If q ∈P and µ ∈S ∩P then
qproj = 1
2(q −µqµ) is the q’s projection vector on µ axis. If q ∈P and µ ∈S∩P then qrej = 1
2(q +µqµ)
is the q’s orthogonal projection vector on µ axis’s orthogonal plane or the q’s rejection of the µ axis. And
eventually if q ∈P, φ ∈R and µ ∈S ∩P then qrot = eµ φ
2 qe−µ φ
2 is the q’s rotation vector around µ axis
with φ angle.
FIG. D.1 – Geometric Transformations in R3 with Quaternion : q denotes the original vector, µ
denotes the axis vector, qrefl is the q’s reﬂection vector with µ axis, qrej is the q’s rejection of the µ axis
and qproj is q’s projection vector on µ axis.
For each colour pixel described in RGB colour space using a quaternion vector q ∈P, HSV (hue, sa-
turation, value) colour space coordinates can be found using operations on quaternions. We consider that
the value component of the HSV vector represents the norm of the colour’s orthogonal projection vector
(q.µgrey)µgrey on the grey axis µgrey (this axis can be deﬁned such that µgrey = i+j+k
√
3 ). Saturation and
hue are represented on the plane orthogonal to the grey axis which crosses (q.µgrey)µgrey. The satura-
tion is the distance between the colour vector q and the grey axis µgrey, and hue is the angle between the
colour vector q and a colour vector ν taken anywhere on the plane orthogonal to µgrey and which sets
the zero hue reference angle. This reference hue value is often taken to represent the red colour vector,
so we decided arbitrarily to associate the red colour vector to the ν vector and gave it a zero hue value
(cf. ﬁgure D.2). Hue is the angle between this reference colour vector and the colour vector q.
For a colour vector q, the corresponding H, V, and S components can be obtained using the grey-axis
µ = µgrey ∈S∩P and the reference colour vector ν ∈S∩P with the following elementary quaternionic
operations [35]





H=tan−1 |q−µνqνµ|
|q−νqν|
S=|1
2(q + µqµ)|
V =|1
2(q −µqµ)|
(D.1)
which will be used later in this paper to deﬁne a new gradient operator.

150
CHAP D - SPATIAL AND SPECTRAL QUATERNIONIC APPROACHES FOR COLOUR
IMAGES
FIG. D.2 – Hue, Saturation and Value given with reference µGrey and H(ν) = 0
D.2
Discrete Quaternion Fourier Transform
D.2.1
Deﬁnition
Different works introduced the quaternionic Fourier Transform, [8, 65]. The Discrete Quaternion
Fourier Transform (DQFT) in µ = µii + µjj + µkk ∈S ∩P direction analysis allows us to give the
frequency equivalence of a N × M spatial colour image in a matrix deﬁned by
Q(S, T) =
1
√
MN
N
2
X
s=−N
2 +1
M
2
X
t=−M
2 +1
exp−2µπ( Ss
N + T t
M ) q(s, t)
(D.2)
Here, the term Q(S, T) represents the frequency coordinates and q(s, t) = r(s, t)i+g(s, t)j+b(s, t)k
is a pure quaternion used to represent the three different colour channels of the pixel at the coordinates
(s, t) of the colour image. Since the quaternion product is not commutative, DQFT can have different
forms [55]. Note that in this paper we will follow the DQFT deﬁnition given in (D.2).
The inverse DQFT (IDQFT) to the transform presented in (D.2) is given by
q(s, t) =
1
√
MN
P N
2
S=−N
2 +1
P M
2
T=−M
2 +1 exp2πµ( Ss
N + T t
M ) Q(S, T)
It is proved [55, 31] that DQFT or its inverse (IDQFT) for a square matrix of dimension 2n × 2n
could be simpliﬁed by processing two fast complex Fourier transforms.
D.2.2
Colour quaternion spectrum properties
In order to understand what the Fourier coefﬁcients stand for, we studied the digital characterization
of the DQFT. We ﬁrst discovered that the colour Fourier spectrum exhibits some symmetries due to zero
scalar spatial part of any colour image. This observation follows the well-known fact that the spectrum
of a real signal by a complex Fourier transform (CFT) has hermitian properties of symmetry.
Even if the spatial information of a colour image is using pure quaternions only, applying a DQFT
on an image results in full quaternions (i.e. with nonzero scalar part). We wanted to ﬁnd, after IDQFT,

D.2. Discrete Quaternion Fourier Transform
151
a space where scalar part is zero in order to avoid any loss of information as the spatial colour image is
coded on a pure quaternions matrix.
Let
Q(S, T) = Qr(S, T) + Qi(S, T)i + Qj(S, T)j + Qk(S, T)k
be the spectral quaternion at coordinates (S, T) ∈([−N
2 + 1..N
2 ], [−M
2
+ 1..M
2 ]).
In addition, let
q(s, t) = qi(s, t)i + qj(s, t)j + qk(s, t)k
denote the IDQFT quaternion of (s, t) spatial coordinates.
Developping this,with µ = µii + µjj + µkk, the cartesian real part form of the spatial domain leads
to
qr(s, t) =
1
√
MN
P P 
cos(2π
  Ss
N + Tt
M

)Qr(S, T)
−µi sin(2π
 Ss
N + Tt
M

)Qi(S, T) −µj sin(2π
  Ss
N + Tt
M

)Qj(S, T)
−µk sin(2π
  Ss
N + Tt
M

)Qk(S, T)

(D.3)
where qr(s, t) is null when
Qr(−S, −T)
= −Qr(S, T) ; Qi(−S, −T)
= Qi(S, T)
Qj(−S, −T)
= Qj(S, T) ; Qk(−S, −T)
= Qk(S, T)
As it can be seen from the symmetries contained in the Fourier spectrum, the real part must be odd
and all the imaginary parts must be even. This is a direct extension of the antihermitian property of the
complex Fourier transform of imaginary signal. Any transform in the quaternionic colour spectrum must
obey to these rules to keep spatial information safe.
D.2.3
Digital study of the colour spectrum
In this section, we try to give an interpretation of the information contained in the quaternionic
spectrum of colour images. To do this, we propose to initialize the discrete spectrum with a constant
which will represent a Dirac (an inﬁnetely short pulse) and study the response in the spatial domain after
IDQFT. Note that the details of the calculus are presented in appendix.
Initialization could be done in two different ways :
– On the real part of the spectrum, this leads to odd oscillations on the spatial domain linked to the
µ direction parameter of the Fourier transform. Complex colours are obtained in the RGB colour
space after modifying µ and normalizing it in order to obtain a pure unit quaternion.
If Qr(S0, T0) = Kr; Qr(−S0, −T0) = −Kr then
q(s, t) = 2Kr(µi sin
 2π
  S0s
N + T0t
M

+ µj sin
 2π
  S0s
N + T0t
M

+ µk sin
 2π
  S0s
N + T0t
M

– On an imaginary part of the spectrum, this results to even oscillations on the spatial domain inde-
pendently from the µ parameter of the Fourier transform. A proper initialization on the different
imaginary components with respect to the additive colour synthesis theory allows to reach com-
plex colours. For example to get yellow oscillations the red and green components (i and j) should
be initialised (with e=i,j or k).
If Qe(S0, T0) = Qe(−S0, −T0) = Ke then qe(s, t) = 2Keµe cos
 2π
 S0s
N + T0t
M

D.2.4
Quaternionic Graphical Spectrum Illustration
ﬁgure D.3 illustrates the different possible initializations on the quaternionic spectrum. A pair of
constants has been set on the quaternionic spectrum following the properties for spatial reconstruction,
then IDQFT has been performed to make the following subﬁgures (for more graphical illustrations report
to section D.5.2 in the appendix).

152
CHAP D - SPATIAL AND SPECTRAL QUATERNIONIC APPROACHES FOR COLOUR
IMAGES
– Initializing a pair of constants on any imaginary component with any direction µ leads to a spatial
oscillation on the same component (Figure D.3(a)).
– Initializing a pair of constants on the real component leads to a spatial oscillation following the
same imaginary component(s) as those included in the direction µ (Figure D.3(b)).
– The coordinates (S0, T0) and (−S0, −T0) of the two initialization points in the Fourier domain
affect the orientation and the frequency of the oscillations in the spatial domain as it does so for
greyscale image in complex Fourier domain. Orientation of the oscillations can be changed as
shown in Figure D.3(c).
(a)
(b)
(c)
FIG. D.3 – Spectrum Initialization examples : (a) µGrey = i+j+k
√
3
and Qi(2, 2) = Qi(−2, −2) =
Ki ; (b) µMagenta = i+k
√
2 and Qr(2, 2) = −Qr(−2, −2) = Kr ; (c) µY ellow = i+j
√
2 and Qr(0, 2) =
−Qr(0, −2) = Kr
The following focuses on the use of quaternions in ﬁltering which is one of the most frequently used
low level image processing operations. We ﬁrst review spatial colour image approaches and get a new
spatial colour ﬁlter. Then starting from the interpretation of the quaternionic Fourier space that we made
in this previous section, we introduce a quaternionic spectrum ﬁlter.
D.3
Quaternionic ﬁltering
In this section, we focus on the colour ﬁltering aspect and study discontinuity detection which is
a fundamental issue of colour image processing such as edge detection and image analysis. A number
of approaches can be used to detect the edges and ﬁne details in colour images. The following brieﬂy
surveys well-known approaches.
D.3.1
Spatial ﬁltering
D.3.1.1
Marginal methods
Marginal methods, adopted directly from greyscale image processing, process each channel of the
colour image separately (ﬁgure D.4a). Thus, they are computationally simple and easy to implement.
On the other hand, due to the omission of the essential spectral information during processing, many
marginal methods have insufﬁcient performance [45, 43]. As presented in [44, 45], edges can be detected
in a component-wise manner or by applying the processing solution to the luminance signal. However,
neither approach can detect the discontinuities in colour information.
D.3.1.2
Vectorial methods
To avoid the drawbacks of marginal solutions, vectorial methods, such as those based on robust
order statistics [43, 56], process colour pixels as vectors (ﬁgure D.4b). In the design proposed by Di
Zenzo [21], edges are detected using colour vectorial gradients. The vectorial methods usually have better
performance compared to marginal solutions, however, the performance improvements are obtained at
expense of the increased computational complexity.

D.3. Quaternionic ﬁltering
153
(a)
(b)
FIG. D.4 – (a)Marginal and (b) Vectorial methods
D.3.1.3
Perceptual methods
Perceptuals methods [32, 39, 72, 57] are based on the human visual system (HVS) characteristics.
For example, in [11], Carron used a marginal gradient method but based on a weight factor : the hue
coefﬁcient of each pixel, more relevant than saturation or intensity to split colours. In a second approach,
when the hue information is not enough to detect edges, the gradient is given using intensity and/or
saturation. The contribution in this approach relies on the fact that if the difference between two colours
is detected with a high saturation, the colours seem farther than if they have smaller saturation (i.e. nearer
from the grey axis) but the same hues. ﬁgure D.5 shows that the two green vectors q1 and q2, near the
grey axis, seem to have a smaller hue difference than the two red vectors q3 and q4, far from the grey axis.
This is not true but there is a difference : q1 and q2 have a smaller saturation (distance from the grey axis)
than q3 and q4. The perceptual methods because using the HVS characteristics give better results than
the marginal and vectorial ones. Moreover the chromatic information of pixels is used to avoid artefacts
and a major advantage is the integration of colour shadows. Nevertheless, by working in proper colour
spaces and using thresholds for instance for hue relevance, algorithms complexity is raised.
FIG. D.5 – The distance between q1 and q2 (green vectors) seems to be smaller than between q3 and q4
(red vectors) but the hue difference is the same : d
q1q2 = d
q3q4
D.3.1.4
Sangwine’s quaternionic approach
Sangwine proposed the convolution on a quaternionic colour image can be deﬁned by [63, 50, 65] :
qfiltered(s, t) =
n1
X
τ1=−n1
m1
X
τ2=−m1
hl(τ1, τ2)q((s −τ1)(t −τ2))hr(τ1, τ2)
(D.4)
where hl and hr are the two conjugate ﬁlters of dimension N1 × M1 where N1 = 2n1 + 1 ∈N and
M1 = 2m1 + 1 ∈N.

154
CHAP D - SPATIAL AND SPECTRAL QUATERNIONIC APPROACHES FOR COLOUR
IMAGES
From this deﬁnition of the convolution product, Sangwine proposed a colour edge detector in [62].
In this method, the two ﬁlters h1 and h2 are conjugated in order to fullﬁll a rotation operation of every
pixel around the greyscale axis by an angle of π and compare it to its neighbours (cf. ﬁgure D.6).
qfilt(s, t) = l ⋆q ⋆r(s, t)
(D.5)
FIG. D.6 – Sangwine’s Edge Detector Scheme : µ is the grey axis ; µq1µ (resp. µq3µ) is the rotated
vector of q1 (resp. q3) around µ with an angle of π ; the comparison vector between q1 and q2 (resp.
between q3 and q4) is given by q2 + µq1µ (resp. q4 + µq3µ) ; q4 + µq3µ is near from the grey axis so the
colour seems grey but q2 + µq1µ is far from the grey axis so Sangwine’s ﬁlter has detect an edge as this
vector is more coloured.
The ﬁlter composed by a pair of quaternion conjugated ﬁlters is deﬁned as follows
l = 1
6


1
1
1
0
0
0
Q
Q
Q


and
r = 1
6


1
1
1
0
0
0
Q
Q
Q


(D.6)
where Q = eµ π
2 and µ = µGrey = i+j+k
√
3
the greyscale axis.
The ﬁltered image (cf. ﬁgure D.6) is a greyscale image almost everywhere, because in homogeneous
regions the vector sum of one pixel to its neighbours rotated by π around the grey axis has a low saturation
(cf. q4 + µq3µ for instance). However, pixels in colour opposition (like q1 and q2 for example) represent
a colour edge. Therefore, they present a vector sum far from the grey axis. Edges are thus coloured due
to this high distance.
Although this detector has a good performance, it often produces false colours, for example, when
the vector sum is out of the colour space domain. ﬁgure D.7 shows that the edge of the hat is not detected
by the same colour in c or d where the horizontal ﬁltering convolution is applied rightwise or leftwise.
D.3.1.5
A new gradient detector
Starting with the result of Sangwine ﬁlter, we get for each pixel q1 and q3 a vector of itself rotated by
π around the greyscale axis and compared to its neighbours q2 and q4. We saw that the more the colour
vector of a pixel is far from its neighbours (colour edge), the more the vector sum in Sangwine’s ﬁlter
is far from the grey axis. Our approach also gives us a colour gradient. We propose to determine the
distance qdist of Sangwine’s comparison colour vector sum qsum = q2 + µq1µ or qsum = q4 + µq3µ
from the grey axis µ (cf. ﬁgure D.8). This distance can be calculated with quaternionic operations (refer
to section D.1.2) and is the norm of the rejection of the vector of the grey axis. This distance is deﬁned
from a colour vector to the grey axis and we work in the RGB colour space. Thus, equation (D.1) implies
that this is the saturation of the colour vector sum given by Sangwine’s ﬁlter.

D.3. Quaternionic ﬁltering
155
(a)
(b)
(c)
(d)
FIG. D.7 – Sangwine edge detector result : (a) original image ; (b) Sangwine’s ﬁlter applied from left to
right horizontally ; (c) zoom on the hat edge of the (b) picture ; (d) same zoom but with the ﬁlter applied
from right to left. Thus applying the ﬁlter leftwise in one same direction (horizontal, vertical or diagonal)
leads to different results than applying it rightwise.
qdist = 1
2(qsum + µqsumµ)
(D.7)
FIG. D.8 – Proposed quaternionic edge detector : µ is the grey axis ; µq1µ (resp. µq3µ) is the rotated
vector of q1 (resp. q3) around µ with an angle of π ; our comparison vector between q1 and q2 (resp.
between q3 and q4) is given by the distance qdist =
1
2(qsum + µqsumµ) of Sangwine’s vector sum
qsum = q2 + µq1µ (resp. qsum = q4 + µq3µ) from the grey axis (orange arrows) ; An edge is detected
by a high distance from the grey axis like the orange arrow between µ and q2 + µq1µ.

156
CHAP D - SPATIAL AND SPECTRAL QUATERNIONIC APPROACHES FOR COLOUR
IMAGES
ﬁgure D.9 shows that the two distances S1 and S2 are equal. Sangwine’s ﬁlter gives two different
colour vectors q1 + µq2µ and q2 + µq1µ for the same two original colours q1 and q2 comparison. Note
that our new method is thus independent from the path (leftwise or rightwise) applied to convolute the
ﬁlter with the image whereas Sangwine’s is not.
FIG. D.9 – Difference between Sangwine and our edge detector : µ is the grey axis ; µq1µ (resp. µq2µ)
is the rotated vector of q1 (resp. q2) around µ with an angle of π ; the same colours q1 and q2 can give
two different colour vectors qsum = q2 + µq1µ and qsum = q1 + µq2µ by the Sangwine’s method. Note
that our approach leads to the same distance because S1 = S2.
This saturation ﬁlter is applied to the horizontal, vertical and both diagonal directions. The maximum
of these values of saturation at each pixel of the image is then selected to make the ﬁnal colour gradient
ﬁlter by maximum distance. Note that this quaternionic ﬁltering operation is linear but the total process
is not linear as the "maximum" operator interferes.
ﬁgure D.10 shows the results of our experiment where in each row there are ﬁrst the original image,
then the colour gradient and log colour gradient (in order to amplify the edges detected by the colour
gradient) and ﬁnally the edge map images. This last image is a thresholding on the colour gradient image.
The results show that the method detect colour edges quite properly for example with the house image
where walls, roof and sky are well separated. The same observation can be done with the well detec-
ted separation between Lenna’s shoulder and chin. Process our method on images such as the mandrill
separates correctly the homogeneous and textures areas. Even if there is still an edge detected between
the roof and the top right side of the chimney, we can say that our approach handles shadows quite well.
However,because our method uses a comparison of saturation only, the differences of luminance between
colours is not detected, see for instance the details of the window’s house.
D.3.1.6
Edge detection performance
ﬁgure D.11 shows the edge maps obtained using the different methods. The marginal (ﬁgure D.11b)
and Di Zenzo (ﬁgure D.11c) approaches seem to be more sensitive to noise. The edges obtained by
our approach (ﬁgure D.11f and g) are much thicker and closed. Remember that the ﬁrst Carron method
(ﬁgure D.11d) is based on a measure of the hue to weight the marginal gradient ; the second method uses
as well the saturation and the luminance measures to weight the gradient when hue is not enough relevant.
These methods give closed contours and are not sensitive to noise as the marginal and Di Zenzo ones.
Regarding Carron2 approach (ﬁgure D.11e), our method cannot distinguish as efﬁciently shadows to real

D.3. Quaternionic ﬁltering
157
(a)
(b)
(c)
(d)
(e)
(f)
(g)
(h)
(i)
(j)
(k)
(l)
FIG. D.10 – From left to right, original images, colour gradient, log colour gradient and edge map from
our new spatial method
contours because our method is based on the saturation only. But this result depends on the thresholding
done on the colour gradient. Indeed the shadows contours can be erased from our edge map but at the
price of thinner edges everywhere else (see ﬁgure D.10d for example).
To improve our algorithm and take shadows into account we need to check if the saturation measure
is self-sufﬁcient. Indeed, two different colours can have the same saturation. It is the case for instance
with q1 and q2 on one hand and q3 and q4 on the other hand as we saw in ﬁgure D.5. Even so, q1 and q2 are
different colours as well as q3 and q4, fortunately they can be disjoined by their difference of luminance
and/or hue. Implementing these luminance and chromaticity measures (as the Carron2 method does)
when saturation is not enough relevant should enhance the performance of our approach.
Even with this lack of improvement, our edge detector is quite efﬁcient with an implementation
using quaternion formalism and the results are given without performing any change of colour space so
imprecisions due to these digital manipulations of colours are avoided. Moreover, it should be noted that
our edge detector is based on a vectorial approach and does not need any additional deﬁnition to sort
colours. Our distance is a saturation one that does not give more importance for a speciﬁed colour than
for another one, speaking at the same saturation level. Finally, our method is more similar to a perceptual
one than those based on RGB colour space as it uses geometric concepts from HSV colour space for
example.

158
CHAP D - SPATIAL AND SPECTRAL QUATERNIONIC APPROACHES FOR COLOUR
IMAGES
D.3.1.7
Computational complexity
To compare the computational complexity of the proposed approach and the traditional marginal
colour gradient operator, the quaternionic operations have to be expressed in terms of the traditional real
operations such as multiplications and additions. Let multq (resp. multr) stand for quaternionic (resp.
real) multiplication, addq (resp. addr) quaternionic (resp. real) addition :
– addq = 4 addr
– multq = 4 ∗4 multr + 4*3 addr
We apply Sangwine algorithm and then we calculate the distance of the colour sum vector results
from the grey axis. Note that the calculations will be performed for a N × N image.
– Sangwine algorithm :
Remember that for each pixel we apply two convolutions by a 3 × 3 window, one with the quater-
nion Q and one with Q (cf. equations (D.5) and (D.6)).
nSang = N 2(2 ∗(6multq + 5addq))
In fact, since each convolution implies three zero coefﬁcients, only 6 quaternionic multiplications
and 5 quaternionic additions are needed.
– Distance calculation :
For each pixel again we calculate the saturation distance as seen in equation (D.7).
nDist = N 2(addq + 2multq)
Then as we process the Sangwine ﬁlter on horizontal, vertical and both diagonal directions :
nTotal
= 4 ∗(nSang + nDist)
= 4 ∗(N 2(2 ∗(6 multq + 5 addq)) + N 2(addq + 2 multq))
= N 2(832 multr + 768 addr)
For a classical marginal gradient, the same kind of Prewitt ﬁlter is needed, but we only apply it
one time on each colour component. We then apply it on the same four directions and the number of
operations needed is about N 2(28multr + 20addr).
We can see that our method is using much more operations than the classical one so the computation
time is increased (linearly and not exponentially). However, it should be noted that the complexity is not
changed as both methods are in O(N 2) and the results obtained using the proposed approach are better
than the ones obtained using a marginal method.
D.3.2
Frequency ﬁltering
Our approach is built on the same idea used to ﬁlter greyscale images : DQFT is performed on a
colour image leading to its the frequential information. We then apply a mask on this Fourier information
by setting its either low or high frequency coefﬁcients to zero. Eventually, the result is processed through
IDQFT to give the ﬁltered image.
We use the quaternion formalism to encode colour images but we need to stay aware on the fact
that the quaternionic product is not commutative. Indeed, the well known theorem which states that
a convolution product in spatial domain is equal to the product in the Fourier space is not true with
quaternions [55].
By deﬁnition, the formulation of our Fourier ﬁltering approach is given by
qF ilt = IDQFT{H.Q}
(D.8)

D.3. Quaternionic ﬁltering
159
(a)
(b)
(c)
(d)
(e)
(f)
(g)
FIG. D.11 – Different spatial gradients on the "house" image : (a) "House" original image ; (b) Mar-
ginal approach ; (c) Di Zenzo approach ; (d) First Carron approach ; (e) Second Carron approach ; (f) our
method ; (g) our method with logarithmic approach.
with Q = DQFT(q) denotes the quaternionic Fourier transform of the original image and H the fre-
quency behavior of the ﬁlter.
To compare the frequential ﬁltering to the spatial one, we focus on the high-pass ﬁltering
H(S, T) = 1 for (|S| > a, |T| > b) and 0 otherwise, with a, b ∈R

160
CHAP D - SPATIAL AND SPECTRAL QUATERNIONIC APPROACHES FOR COLOUR
IMAGES
Indeed we notice through the quaternionic spectrum study that there is a likeness of organisation as in
the classical complex spectrum. As a consequence, high frequency selection will give weight to ruptures
and thus contours.
ﬁgure D.12 shows that frequency ﬁltering preserves the original colours and the high frequency
content is really isolated from the rest of the image. In fact, the contours of the top and bottom boxes
appear green and white in ﬁgure D.12g and the circle and quadrilateral are red and blue in ﬁgure D.12h
as in the original image (ﬁgure D.12e). These remarks are also valid on the contours made on the Lenna
image as we can see the details of her hat in ﬁgure D.12c and mouth in ﬁgure D.12d. We see that
information on edges is vectorial as it appears in colours. A scaling process between 0 and 255 has
been made after IDQFT using the min and max of each component. As the method uses the windowing
concept to ﬁlter the image in the frequency domain, we can observe that there are some oscillations on
edges detected in the high-pass ﬁltered pictures. This windowing process in the quaternionic spectral
domain leads to equivalent artefacts than those produced if it was done on a greyscale image spectrum :
the Fourier transform of the rectangle function is the sinc (sine cardinal) function. However, even if this
statement is not true anymore with the formalism of quaternions (from the anti-commutativity of the
product), we observe that it still remains the same kind of border effects. Note that the colour artefacts
are just the conjugate colours of the edges in the RGB colour domain as we see in ﬁgure D.12h where
the red (resp. blue) colour of the circle (resp. quadrilateral) is oscillating with green (resp. yellow).
ﬁgure D.13 shows that this spectrum strategy is at least good enough to detect colour edges properly.
A edge map is made by thresholding the absolute values of the ﬁltered images. This method seems
however more sensitive to small details than the one presented on the spatial ﬁltering section but it may
give more details than the spatial approach with not saturated colours. Indeed we can see in ﬁgure D.13c
that the gutters and drainpipes of the roof are well detected by the frequential method. They are not
detected by the spatial one because they are quite white (white has a zero saturation level). Furthermore,
this approach can ﬁlter both in low-pass and high-pass bands and it can be generalized to band-pass by
selecting the proper windowing scheme in the spectrum domain.
Notice that the experiments show only results with the µ parameter of the DQFT and IDQFT equal
to µgrey. Finally taking the interpretation of the quaternionic spectrum of the ﬁrst section we may be able
to make spectrum ﬁlters which can extract only one component or any combinaison of them.
Speaking about performances, it takes two classical complex fast Fourier transforms to perform a
DQFT or IDQFT. To process both DQFT and IDQFT is so equivalent to a complexity in O(N 2ln(N 2)).
The windowing process is a product term by term between the spectrum and a 2D rectangle function.
This process has a complexity in O(N 2). The all method uses the two previous algorithms leading the
total complexity of the process in O(N 2 + N 2ln(N 2)) = O(N 2ln(N 2)). This is a bit slower than the
spatial method.
D.4
Conclusion
In this paper, we analysed the properties of the quaternionic Fourier spectrum. This contributed ﬁrst,
to reconstruct after IDQFT and without any loss of information a quaternionic spatial colour image
composed of three imaginary components only. Secondly, this gave us an interpretation of quaternionic
Fourier coefﬁcients inﬂuence on the spatial domain with both calculus and graphical illustrations. When
initializing the real part of the spectrum with a pair of constants respecting proper symmetries, the cor-
responding spatial domain presents odd oscillations dependent on the µ parameter of the transformation.
However, spectrum pairs of Dirac initialization made on imaginary component inﬂuences the spatial do-
main with even oscillations independently from the µ parameter. As in the complex Fourier analysis, the
quaternionic spectrum can be used to detect spatial orientations. Then in a second part, we applied the
previous digital concepts to propose a new quaternionic colour vectorial gradient. This gave enthusiastic
results as its takes advantages of both vectorial and perceptual approaches of spatial ﬁltering for a RGB
colour space approach. In addition, we used the interpretation of the spectrum to create frequency qua-
ternionic ﬁlters that gave similar results than complex frequency ﬁlters on greyscale images. In that way,

D.4. Conclusion
161
(a)
(b)
(c)
(d)
(e)
(f)
(g)
(h)
FIG. D.12 – Quaternionic high-pass ﬁltering results : (a) Lenna original image ; (b) highpass ﬁlter
applied on (a) ; (c) details of the hat ; (d) details of the face ; (e) hand-made colour image ; (f) high-pass
ﬁlter applied on (e) ; (g) details of the green and white boxes edges ; (h) details of the red circle and blue
quadrilateral edges. Frequency ﬁltering preserves the original colours.
both spatial and spectrum approaches have been discussed to get a wider vision on ﬁltering with quater-
nions. Perspectives are ﬁrst to enhance the spatial vectorial ﬁlter in order to take the saturation reluctance
into account, thus achieving higher efﬁciency by giving more power to intensity and hue values when
needed. The frequential approach can as well be improved ﬁrst by using a smoother function than the
rectangle one to process the spectrum ﬁltering and soften the border effects leading to colour artefacts.
Secondly, we can select in the Fourier domain the wanted components as described by the spectrum
interpretation of the ﬁrst section. Finally, as quaternions do not seem to give information to compare
colour components between themselves but more independent component analysis, geometric algebra
which manipulates vectors but also multivectors may represent a useful tool to achieve new results.

162
CHAP D - SPATIAL AND SPECTRAL QUATERNIONIC APPROACHES FOR COLOUR
IMAGES
(a)
(b)
(c)
(d)
(e)
(f)
(g)
(h)
(i)
FIG. D.13 – Comparison between high-pass and spatial ﬁltering : (a) Lenna original image ; (b) high-
pass ﬁltering’s edge map ; (c) spatial gradient’s edge map ; (d) mandrill original image ; (e) highpass
ﬁltering’s edge map ; (f) spatial gradient’s edge map ; (g) house original image ; (h) highpass ﬁltering’s
edge map ; (i) spatial gradient’s edge map.
D.5
Appendix
D.5.1
Digital study of the colour spectrum
This section shows more details on how, an initialization made in the quaternionic spectrum, in-
ﬂuences the spatial domain after IDQFT.
A problem relies on the fact that the spectrum must present the previous symmetry conditions (refer
to section D.2.2), and thus the pixel at coordinates (−S0, −T0) must be initialized with amplitude that
respects the conditions. Eventually there are two points initialized in the spectrum in order to ﬁnd a
spatial image after IQFT without any loss of information. There are different cases for initialization, as
reported in the following.
– Initialization on the real component

D.5. Appendix
163
In this case, the initialization requires the Qr(S0, T0) = Kr and Qr(−S0, −T0) = −Kr condi-
tions. After IDQFT the spatial image is represented on its imaginary components as follows :
qr(s, t) =
0
qi(s, t) =
2Krµi sin
 2π
  S0s
N + T0t
M

qj(s, t) =
2Krµj sin
 2π
  S0s
N + T0t
M

qk(s, t) =
2Krµk sin
 2π
  S0s
N + T0t
M

Initialize the real component of the spectrum leads, after IQFT process, to odd variations (for the
sinus is an odd function). These variations are described by the imaginary component(s) used to
set the analysing direction µ = µii + µjj + µkk. As for a classical frequency representation, we
observe that the frequency coordinates (S0, T0) are associated with the direction and the repetition
density of the analyzed pattern.
– Initialization on an imaginary component
In this case the initialization requires Qe(S0, T0) = Qe(−S0, −T0) = Ke (with e = i, j or k)
conditions. After IDQFT the spatial image corresponding to e-imaginary component is represented
on its following cartesian form
qe(s, t) =
2Ke cos
 2π
  S0s
N + T0t
M

q′
e(s, t) = 0 with e′ ̸= e
Initialize an (several) imaginary component(s) of the spectrum leads, after IQFT process, to even
oscillations (for the cosinus is a even function) described on the same imaginary component(s).
We observe that the analysing direction µ chosen in the IDQFT has no inﬂuence.
D.5.2
Quaternionic Graphical Spectrum Illustration
D.5.2.1
Initialization on a spectrum’s imaginary part with any µ ∈S ∩P
As we saw in the previous section, to set a pair of constants that follows the necessary conditions on
one imaginary component of the quaternionic spectrum leads to a spatial oscillation on the same com-
ponent after processing IDQFT (cf. ﬁgure D.14). For example if the initialization is done on the ﬁrst
frequency component, the spatial oscillations that arise from IDQFT are on the ﬁrst spatial component
coding the image, that is to say the red channel if working in RGB colour space. The initialization can
be done on several components, in that case, the result affects the same components that have been mo-
diﬁed. In our case as the following examples are taken from a RGB colour space, multiple initializations
(always under the conditions for correct spatial reconstruction) on the spectrum produce spatial oscilla-
tions following the rules of the addivive synthesis of colours. So if we initialize the spectrum on each
imaginary component with the same couple of constants, the spatial result after IDQFT on a RGB colour
space is grey oscillations. The µ parameter does not interfere in this case.
D.5.2.2
Initialization on the spectrum’s real part with any µ ∈S ∩P but µ ̸= µGrey
It was shown in Section D.2.3 that the initialization on the spectrum could be done on the real
component. In that case, we can also get different kinds of oscillations after IDQFT was performed,
thus showing that the conditions enunciated before are preserved. Oscillations after IQFT process are on
the same imaginary components involved in the initialization of the pure unit quaternion direction µ. In
other words, working in RGB colour space implies that, to get red oscillations, the µ parameter must
be equal to i (cf. ﬁgure D.15). Oscillations composed of numerous colours can be achieved in setting
the µ parameter properly, for instance µ = i+j
√
2 leads to yellow variations in the RGB colour space after
IDQFT.

164
CHAP D - SPATIAL AND SPECTRAL QUATERNIONIC APPROACHES FOR COLOUR
IMAGES
(a)
(b)
(c)
(d)
(e)
(f)
(g)
FIG. D.14 – Initialization examples with µ = µGrey = i+j+k
√
3
: (a) Qi(2, 2) = Qi(−2, −2) = Ki ; (b)
Qj(2, 2) = Qj(−2, −2) = Kj ; (c) Qk(2, 2) = Qk(−2, −2) = Kk ; (d) Qi(2, 2) = Qi(−2, −2) = Ki
and Qi(2, 2) = Qi(−2, −2) = Ki ; (e) Qj(2, 2) = Qj(−2, −2) = Kj and Qj(2, 2) = Qj(−2, −2) =
Kj ; (f) Qk(2, 2)Qk(−2, −2) = Kk and Qk(2, 2) = Qk(−2, −2) = Kk ; (g) Qi(2, 2) = Qi(−2, −2) =
Ki, Qj(2, 2) = Qj(−2, −2) = Kj and Qk(2, 2) = Qk(−2, −2) = Kk.
(a)
(b)
(c)
FIG. D.15 – Initialization examples with µ ̸= µGrey and Qr(2, 2) = −Qr(−2, −2) = Kr (a) µGrey =
i+j+k
√
3
; (b) µRed = i ; (c) µMagenta = i+k
√
2 .
D.5.2.3
Geometric Variations
In the complex plane, coordinates of the spectrum coefﬁcients involved in the quaternionic Fourier
space’s initialization are really important parameters. Indeed, the resulting oscillations by IDQFT process

D.5. Appendix
165
have a geometric orientation linked to this. Supposing that coordinates are given in Z2 with the pixel
O(0, 0) in the image centre (whereas on the top-left corner as often), the initialization of the spectrum
at coordinates (S0, T0) and (−S0, −T0) results, through IDQFT process, in a 2D oscillation (sinus and
cosinus) following the axis made by this two pixels.
In ﬁgure D.16, numerous geometric oscillations are shown by modifying the coordinates of the pixels
pair implicated by the initialization but with the same way to set the spectrum components.
(a)
(b)
(c)
(d)
FIG. D.16 – Geometric oscillation examples initialization with µY ellow =
i+j
√
2 (a) Qr(2, 2) =
−Qr(−2, −2) = Kr ; (b) Qr(4, −4) = −Qr(−4, 4) = Kr ; (c) Qr(0, 2) = −Qr(0, −2) = Kr ;
(d) Qr(2, 0) = −Qr(−2, 0) = Kr.


PUBLICATIONS PERSONNELLES
Revue internationale
– P. Denis, P. Carré and C. Fernandez-Maloigne, Spatial and spectral Quaternionic approaches for
Colour Images, in Computer Vision and Image Understanding, Issues 1-2, Special issue on color
image processing, vol.107, pp.74–87, July 2007.
Conférences internationales avec comité de lecture
– P. Denis, P. Carré, Colour Gradient using Geometric Algebra, EUSIPCO2007, 15th European
Signal Processing Conference, Pozna´n, Poland - September 2007.
– P. Carré, P. Denis, Quaternionic Wavelet Transform for Colour Images, Wavelet Applications in
Industrial Processing IV, SPIE Optics East Symposium, Boston, October 2006.
Conférence nationale avec comité de lecture
– P. Denis, P. Carré, Méthode de détection de contours utilisant l’Algèbre Géométrique G3, GRETSI2007,
21ème Colloque GRETSI sur le Traitement du Signal et des Images. Troyes, France - Septembre
2007.
167


BIBLIOGRAPHIE
[1] Robert ARGAND :
Essai sur une manière de représenter des quantités imaginaires dans les
constructions géométriques. Gauthier Villars, Paris, deuxième édition, 1874.
[2] Patrick BAS, Nicolas LE BIHAN et Jean-Marc CHASSERY : Color watermarking using quaternion
fourier tranform. In IEEE International conference on Acoustics Speech and Signal Processing
(ICASSP), volume 3, pages 521–524, 2003.
[3] Patrick BAS, Nicolas LE BIHAN et Jean-Marc CHASSERY : Utilisation de la transformée de fourier
quaternionique en tatouage d’images couleur. In Colloque GRETSI, Paris,France, Septembre 2003.
[4] Eduardo BAYRO-CORROCHANO : Multiresolution image analysis using the quaternion wavelet
transform. Numerical Algorithms, 39:35–55, 2005.
[5] Ronald BRACEWELL : The Fourier transform and its applications. McGraw Hill, March 1986.
[6] Fred BRACKX, Nele DE SCHEPPER et Frank SOMMEN : The clifford-fourier transform.
The
Journal of Fourier Analysis and Applications, 11,6:669–681, December 2005.
[7] Fred BRACKX, Nele DE SCHEPPER et Frank SOMMEN : The two-dimensional clifford-fourier
transform. Journal of Mathematical Imaging and Vision, 26,1-2:5–18, 2006.
[8] Thomas BÜLOW : Hypercomplex Spectral Sinal Representations for the processing and Analysis
of Images. Thèse de doctorat, Christian Albrechts University of Kiel, August 1999.
[9] Thomas BÜLOW et Sommer GERALD : Multi-dimensional signal processing using an algebraically
extended signal representation. In J.J. Koenderink (Eds.) G. SOMMER, éditeur : Proc. Int. Worshop
on Algebraic Frames for the Perception-Action Cycle, volume 1315, pages 148–163, Kiel,LNCS,
1997. Springer-Verlag.
[10] Philippe CARRÉ et Patrice DENIS : Quaternionic wavelet transform for colour images. In Wave-
let Applications in Industrial Processing IV, volume 6383, Boston, Massachusetts, USA, October
2006.
[11] Thierry CARRON : Segmentation d’images couleur dans la base Teinte-Luminance-Saturation :
approche numérique et symbolique. Thèse de doctorat, Université de Savoie, dec 1995.
[12] Wai L. CHAN, Hyeokho CHOI et Richard G. BARANIUK : Directional hypercomplex wavelets for
multidimensionak signal analysis and processing. In Intl Conf. on Image Processing. IEEE, May
2004.
[13] Wai L. CHAN, Hyeokho CHOI et Richard G. BARANIUK : Coherent image processing using qua-
ternion wavelet. Rapport technique, Rice University, 2005.
[14] Sylvain CHARNEAU : Algèbre géométrique et lancer de rayons. Mémoire de D.E.A., Université de
Poitiers, Juin 2004.
[15] CIE : Compte rendu de la huitième session. Rapport technique, Cambridge University Press,
Cambridge, 1931.
[16] Jean-Pierre COCQUEREZ et Sylvie PHILIPP : Analyse d’image : ﬁltrage et segmentation, pages
21–22. Masson, Septembre 1995. ISBN=978-2-225-84923-7.
169

170
Bibliographie
[17] Patrice DENIS : Fourier et images couleur. Mémoire de D.E.A., Université de Poitiers, Juin 2004.
[18] Patrice DENIS et Philippe CARRÉ : Colour gradient using geometric algebra. In EUSIPCO2007,
15th European Signal Processing Conference, Pozna´n, Poland, September 2007.
[19] Patrice DENIS et Philippe CARRÉ : Méthode de détection de contour couleur utilisant l’algèbre
géométrique g3. In GRETSI07, 21ème Colloque GRETSI sur le Traitement du Signal et des Images,
Troyes, France, Septembre 2007.
[20] Patrice DENIS, Philippe CARRÉ et Christine FERNANDEZ-MALOIGNE : Spatial and spectral qua-
ternionic approaches for colour images. Computer Vision and Image Understanding, 107:74–87,
July 2007.
[21] Silvano DI ZENZO : A note on the gradient of multi-image. Computer Vision, Graphics, and Image
Processing, 33:116–125, 1986.
[22] Leo DORST et Stephen MANN : Geometric algebra :a computational framework for geometrical
applications (part i :algebra). Computer Graphics and Applications, IEEE, 22,3:24–31, May/June
2002.
[23] Julia EBLING et Gerik SCHEUERMANN : Clifford convolution and pattern matching on vector
ﬁelds. In IEEE Visualization, pages 193–200, 2003.
[24] Julia EBLING et Gerik SCHEUERMANN : Clifford fourier transform on vector ﬁelds. IEEE Tran-
sactions on Visualization and Computer Graphics, 11,4:469–479, July/August 2005.
[25] Julia EBLING et Gerik SCHEUERMANN : Template matching on vector ﬁelds using clifford al-
gebra. In International Conference on the Applications of Computer Science and Mathematics in
Architekture and Civil Engineering (IKM 2006), 2006.
[26] Todd A. ELL : Hypercomplex spectral transformation. Thèse de doctorat, University of Minnesota,
1992.
[27] Todd A. ELL et Stephen John SANGWINE : Decomposition of 2d hypercomplex fourier transforms
into pairs of fourier transforms. In Proc. EUSIPCO, pages 151–154, 2000.
[28] Todd A. ELL et Stephen John SANGWINE : Hypercomplex wiener-kintchine theorem with appli-
cation to color image correlation. In IEEE International Conference on Image Processing (ICIP),
volume 2, pages 792–795, 2000.
[29] Todd A. ELL et Stephen John SANGWINE : Hypercomplex fourier transform of color images. IEEE
Transactions on Signal Processing, 16,1:22–35, January 2007.
[30] Michael FELSBERG : Low-Level Image Processing with the Structure Multivector. Thèse de doc-
torat, Christian Albrechts University of Kiel, March 2002.
[31] Michael FELSBERG et Gerald SOMMER : Optimized fast algorithms for the quaternionic fourier
transform. 8th Int. Conference on Computer Analysis of Images and Patterns, 1689:209–216, 1999.
[32] Christine FERNANDEZ MALOIGNE, Mohamed Chaker LARABI, Benjamin BRINGIER et Richard
NOËL :
Spatial-temporal characteristics of the visual brain and their effects on colour quality
evaluation. In AIC International Conference, Granada, Spain, May 2005.
[33] Joseph FOURIER : Théorie analytique de la chaleur. Firmin Didot Père et Fils, Paris, réédition
(1988) jacques gabay édition, 1822. ISBN 2-87647-046-2.
[34] Dennis GABOR : Theory of communication. J. IEE (London), 93,3:429–457, November 1946.
[35] Philippe-Henri GOSSELIN : Quaternions et images couleur. Mémoire de D.E.A., Université de
Poitiers, 2002.
[36] William Rowan HAMILTON : Elements of Quaternions. Longman London U.K., 1866.
[37] David HESTENES : New Foundations for Classical Mechanics. Kluwer Academic Publishers, 2
édition, 1986.

Bibliographie
171
[38] David HESTENES et Garret SOBCZYK : Clifford Algebra to Geometric Calculus : A Uniﬁed Lan-
guage for Mathematics and Physics. Reidel, Dordrecht, 1984.
[39] D.H. KELLY : Spatiotemporal variation of chromatic and achromatic contrast thresholds. Journal
of the Optical Society of America, 73, 6:742–750, June 1983.
[40] Joan LASENBY, Anthony N. LASENBY et Chris J. L. DORAN : A uniﬁed mathematical language
for physics and engineering in the 21st century. Philosophical Transactions of the Royal Society A,
358:21–39, 2000.
[41] Nicolas LE BIHAN et Jérôme MARS : New 2d complex and hypercomplex seismic attributes. In
71st Conference of the Society of Exploration Geophysicists (SEG), San Antonio, USA, September
2001.
[42] Nicolas LE BIHAN et Stephen John SANGWINE : Quaternion principal component analysis of color
images. In IEEE International Conference on Image Processing (ICIP), pages 809–812, 2003.
[43] Rastislav LUKAC et Konstantinos N. PLATANIOTIS : A taxonomy of color image ﬁltering and
enhancement solutions. Advances in Imaging and Electron Physics, 140:187–264, 2006.
[44] Rastislav LUKAC, Konstantinos N. PLATANIOTIS, Anastasios N. VENETSANOPOULOS, Robert
BIEDA et Smolka BOGDAN : Color edge detection techniques. Signaltheorie und Signalverar-
beitung, Akustik und Sprachakustik, Informationstechnik, 29:21–4, 2003.
[45] Rastislav LUKAC, Bogdan SMOLKA, Karl MARTIN, Konstantinos N. PLATANIOTIS et Anasta-
sios N. VENETSANOPOULOS : Vector ﬁltering for color imaging. IEEE Signal Processing Maga-
zine, 22-1:74–86, January 2005. Special Issue on Color Image Processing.
[46] Stéphane MALLAT : A Wavelet Tour of Signal Processing. Academic Press, 1998.
[47] Bahri MAWARDI et Eckhard MS HITZER : Clifford fourier transformation and uncertainty prin-
ciple for the clifford geometric algebra cl3,0. Advances in Applied Clifford Algebras, 16,1:41–61,
February 2006.
[48] Andrew MCCABE, Terry CAELLI, Geoff WEST et Adam REEVES : Encoding and processing
spatio-chromatic image information using complex fourier transform methods.
Rapport tech-
nique 4, School of Computing, Curting University of Technology, Australia, 1997.
[49] C.E. MOXEY, Stephen John SANGWINE et Todd A. ELL : Vector correlation of colour images.
In First European Conference on Colour in Graphics, Imaging and Vision (CGIV 2002), pages
343–347, July 2002.
[50] C.E. MOXEY, Stephen John SANGWINE et Todd A. ELL : Hypercomplex correlation techniques
for vector images. IEEE Transactions on Signal Processing, 51:1941–1953, July 2003.
[51] Yuichi OHTA, Takeo KANADE et Toshiyuki SAKAI : Color information for region segmentation.
Computer Graphics and Image Processing, 13(3):222 – 241, July 1980.
[52] Soﬁa OLHEDE et Georgios METIKAS : The hyperanalytical wavelet transform. Rapport technique
TR-06-02, Imperial College London, May 2006.
[53] Soo-Chang PEI, Ja-Han CHANG et Jian-Jiun DING : Commutative reduced biquaternions and their
fourier transform for signal and image processing applications. IEEE Trans. Signal Processing,
52,7:2012–2031, November 2004.
[54] Soo-Chang PEI et Ching-Min CHENG : Novel block truncation coding of image sequences for
limited-color display. In ICIAP ’97 : Proceedings of the 9th International Conference on Image
Analysis and Processing-Volume II, pages 164–171, London, UK, 1997. Springer-Verlag.
[55] Soo-Chang PEI, Jian-Jiun DING et Ja-Han CHANG : Efﬁcient implementation of quaternion fourier
transform, convolution, and correlation by 2-d complex fft. IEEE Trans. Signal Processing, 49:
2783–2797, November 2001.
[56] Konstantinos N. PLATANIOTIS et Anastasios N. VENETSANOPOULOS : Color Image Processing
and Applications. Springer Verlag, 2000.

172
Bibliographie
[57] Allen B. POIRSON et Brian A. WANDELL : Pattern-color separable pathways predict sensitivity to
simple colored patterns. Vision Research, 36, 4:515–526, 1996.
[58] Mikhaïl POSTNIKOV : Leçons de géométrie : Groupes et algèbres de Lie. Editions MIR, Moscou,
1982.
[59] S. A. REDFIELD et Q. Q. HUYNH : Hypercomplex fourier transforms applied to detection for side-
scan sonar. In IEEE International conference on oceanic Engineering (OCEANS), volume 4, pages
2219–2224, Biloxi, October 2002.
[60] Stephen John SANGWINE : Fourier transforms of colour images using quaternion, or hypercomplex,
numbers. Electronics Letters, 32, 21:1979–1980, October 1996.
[61] Stephen John SANGWINE : The discrete quaternion fourier transform. In Proceedings of the 6th
International Conference on Image processing and its applications, volume 2, 14-17, pages 790–
793, July 1997.
[62] Stephen John SANGWINE : Colour image edge detector based on quaternion convolution. Electro-
nics Letters, 34, 10:969–971, May 1998.
[63] Stephen John SANGWINE : Colour in image processing. Electronics and Communication Enginee-
ring Journal, 12,5:211–219, October 2000.
[64] Stephen John SANGWINE et Todd A. ELL : Hypercomplex auto- and cross-correlation of color
images. In IEEE International Conference on Image Processing (ICIP), volume 4, pages 319–322,
1999.
[65] Stephen John SANGWINE et Todd A. ELL : Hypercomplex fourier transforms of colour images. In
Proceedings ICIP, pages 137–140, 2001.
[66] Stephen John SANGWINE et Todd A. ELL : Mathematical approaches to linear vector ﬁltering of
colour images. In First European Conference on Colour in Graphics, Imaging and Vision (CGIV
2002), July 2002.
[67] Michael SCHLEMMER, Hans HAGEN, Ingrid HOTZ et Bernd HAMANN : Clifford pattern matching
for color image edge detection. Visualization of Large and Unstructured Data Sets, GI-Edition
Lecture Notes in Informatics (LNI), 4, 2006.
[68] Lilong SHI et Brian FUNT : Quaternion color texture segmentation. Computer Vision and Image
Understanding, 107:88–96, July 2007.
[69] Alain TRÉMEAU : Contribution des modèles de la perception visuelle à l’analyse d’images couleur.
Thèse de doctorat, Université Jean Monnet de Saint-Étienne, Octobre 1993.
[70] Alain TRÉMEAU, Christine FERNANDEZ-MALOIGNE et Pierre BONTON : Image numérique cou-
leur. De l’acquisition au traitement. Dunod, Janvier 2004.
[71] Martin VETTERLI et Jelena KOVA ˘CEVI ´C : Wavelets and Subband Coding. Prentice Hall PTR, New
Jersey, 1995.
[72] Brian A. WANDELL : Color appearance : The effects of illumination and spatial pattern. Procee-
dings of the National Academy of Sciences of the United States of America (Proc. Natl. Acad. Sci.
U. S. A.), 90, 21:9778–9784, 1993.


Quaternions et Algèbres Géométriques, de nouveaux outils pour les
images numériques couleur
Résumé Les travaux de cette thèse s’inscrivent dans le contexte du traitement et de l’analyse des images
couleur. Les premiers travaux pour traiter ces images consistaient à appliquer des traitements déjà existant
en niveaux de gris marginalement sur les trois composantes constituant la couleur et le plus généralement
dans l’espace RV B. Ces traitements ont été peu à peu améliorés notamment par l’utilisation d’espaces
couleur d’avantage liés à la perception humaine mais aussi par des approches vectorielles. Dans ce tra-
vail de thèse nous nous plaçons dans la continuité de ces travaux et nous proposons une modélisation
mathématique de la dimension vectorielle dans le but de manipuler les couleurs de manière globale.
Trois formalismes sont présentés pour représenter la couleur : les complexes, les quaternions et les al-
gèbres géométriques. Dans ce cadre, il est proposé de déﬁnir de nouveaux outils d’analyse couleur avec
notamment une caractérisation numérique fréquentielle de chacun de ces modèles. Une étude approfon-
die de leurs utilisations permet de faire ressortir leurs propriétés ainsi que leurs principaux avantages et
inconvénients à savoir : impossibilité des complexes à représenter les vecteurs couleurs qui par nature
s’expriment en trois dimensions minimum contrairement aux quaternions et aux algèbres géométriques ;
distinction entre objets manipulés (vecteurs couleur) et opérations effectuées sur ces objets (projections,
rotations,. . . ) pour les algèbres géométriques contrairement aux quaternions . . . Enﬁn nous avons mon-
tré que la transformée de Fourier quaternionique analyse la couleur avec une direction indiquée par un
vecteur couleur, tandis que la transformée de Fourier déﬁnie au moyen de l’algèbre G3, plus générique,
répartit l’information couleur sur des composantes fréquentielles indépendantes. L’utilisation de modèles
algébriques pour représenter l’information couleur permet la déﬁnition et le développement d’un ﬁltre
spatial de détection de contours tenant compte de la dispersion dans l’espace couleur.
Quaternions and Geometric Algebras, new tools for digital colour images
Abstract
The main subject of this PhD thesis is colour image processing. The ﬁrst methods dealing
with these images consisted in applying existing greyscale processing alorithms on each of the three
colour components. Colour processing has improved using perceptual colour spaces but also by consi-
dering colours as vectors. In this work, we follow the idea of colour modelization and we propose to
encode their vectorial information into mathematical models in order to manipulate them globally and
geometrically. Three formalisms are presented to cope with colour : complex numbers, quaternions and
geometric algebras (also called Clifford algebras). New colour tools are proposed to analyse the digital
spectrum embedded in each of these formalisms and the deﬁnition of Fourier transforms. We give the
main advantages and drawbacks of each model, namely : impossibility for the complex numbers to re-
present whole colour vectors that needs at least three components to be described properly ; distinction
between objects and operations on objects (projections, rotations, . . . ) with geometric algebras whereas it
is not possible with quaternions. We then showed that the quaternionic Fourier transform analyse colours
with a direction whereas the Clifford G3 Fourier transform has not got any direction to analyse the colour
so it treats every colour channel independently. Eventually one of the main applications is the deﬁnition
of a spatial colour edge detector ﬁlter using these formalisms.
Discipline : traitement du signal et des images.
Mots clés : Analyse d’images, espace numérique couleur, quaternions, algèbres géométriques, transfor-
mations de Fourier, ﬁltrage spatial et fréquentiel.
Patrice Denis - Laboratoire Signal Image Communication
Bât. SP2MI - Téléport 2, Bd Marie et Pierre Curie - BP 30179 - 86962 Futuroscope Cedex

