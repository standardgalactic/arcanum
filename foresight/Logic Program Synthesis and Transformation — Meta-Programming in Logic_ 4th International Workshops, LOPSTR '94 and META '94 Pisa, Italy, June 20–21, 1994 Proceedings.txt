Lecture Notes in Computer Science 
Edited by G. Goos, J. Hartmanis and J. van Leeuwen 
883 
Advisory Board: W. Brauer 
D. Gries 
J. Stoer 

Laurent Fribourg Franco Turini (Eds.) 
Logic Program Synthesis 
and Transformation- 
Meta-Programming 
in Logic 
4th International Workshops 
LOPSTR '94 and META '94 
Pisa, Italy, June 20-21, 1994 
Proceedings 
Springer-Verlag 
Berlin Heidelberg NewYork 
London Paris Tokyo 
Hong Kong Barcelona 
Budapest 

series Editors 
Gerhard Goos 
Universit~it Karlsruhe 
Vincenz-Priessnitz-StraBe 3, D-76128 Karlsruhe, Germany 
Juris Hartmanis 
Department of Computer Science, Cornell University 
4130 Upson Hall, Ithaka, NY 14853, USA 
Jan van Leeuwen 
Department of Computer Science, Utrecht University 
Padualaan 14, 3584 CH Utrecht, The Netherlands 
Volume Editors 
Laurent Fribourg 
LIENS-CNRS 
45 rue d'Ulm, F-75005 Paris, France 
Franco Turini 
Dipartimento di Informatica, Universit~ di Pisa 
Corso Italia, 40, 1-56125 Pisa, italy 
CR Subject Classification (1991): E4.1, E3.2-3, 1.2.2, 1.2.4, D.3.1, D.3.4 
ISBN 3-540-58792-6 Springer-Verlag Berlin Heidelberg New York 
CIP data applied for 
This work is subject to copyright. All rights are reserved, whether the whole or part 
of the material is concerned, specifically the rights of translation, reprinting, re-use 
of illustrations, recitation, broadcasting, reproduction on microfilms or in any other 
way, and storage in data banks. Duplication of this publication or parts thereof is 
permitted only under the provisions of the German Copyright Law of September 9, 
1965, in its current version, and permission for use must always be obtained from 
Springer-Verlag. Violations are liable for prosecution under the German Copyright 
Law. 
9 Springer-Verlag Berlin Heidelberg 1994 
Printed in Germany 
Typesetting: Camera-ready by author 
SPIN: 10479332 
45/3140-543210 - Printed on acid-free paper 

Preface 
This volume contains the proceedings of the LOPSTR'94 and META'94 
workshops, which were held in Pisa on June 20-21, 1994. The two workshops 
took place in parallel and were attended by 69 persons coming from 16 coun- 
tries. 
LOPSTR'94 is the Fourth International Workshop on Logic Program Syn- 
thesis and Transformation. Previous workshops had taken place in Manchester 
(1991, 1992) and in Louvain-la-Neuve (1993). This year, 19 submitted papers 
were selected for presentation in Pisa, among which 15 were accepted for inclu- 
sion in these proceedings, after some revisions had been made by the authors. 
The main topics addressed by the papers are: unfolding/folding, partial deduc- 
tion, proofs as programs, inductive logic programming, automated program ver- 
ification, specification and programming methodologies. 
META'94 is the Fourth International Workshop on Metaprogramming in 
Logic. Previous workshops had taken place in Bristol (1988), in Leuven (1990), 
and in Uppsala (1992). This year, 21 papers were submitted and 11 were ac- 
cepted for presentation in Pisa and inclusion in the proceedings. The main top- 
ics addressed by the papers are: language extensions in support of Meta-logic, 
semantics of Meta-logic, implementation of Meta-logic features, performance of 
Meta-logic, and applications of Meta-logic to non-monotonic reasoning, program 
control, and programming in the large, 
In addition to LOPSTR-META regular contributions, two invited speakers 
gave very insightful and appreciated talks in Pisa: Giorgio Levi on "Abstract 
debugging of logic programs" (included in this book) and Burton Dreben on 
"Herbrand's contributions to logic " 
We would like to thank all the members of the Program Committees as well 
as the referees for their thorough job of reviewing. 
We also express our gratitude to all the members of the local organizing 
committee for their help in organizing these successful events. 
We gratefully acknowledge the financial support of the Compulog Network 
of Excellence. 
September 1994 
Laurent Fribourg, Franco Turini 

vI 
Organizing Committee: 
Antonio Brogi, Paolo Mancarella, Dino Pedreschi, Franco Turini (U. Pisa) 
Program Committee of LOPSTR: 
Dmitri Boulanger (K.U. Leuven) 
Gerard Ferrand (U. Orleans) 
Pierre Flener (Bilkent U., Ankara) 
Laurent Fribourg (LIENS-CNRS, Paris)(Chair) 
Jean-Marie Jacquet (U. Namur) 
Maurizio Proietti (IASLCNR, Roma) 
Franco Turini (U. Pisa) 
Geraint Wiggins (U. Edinburgh) 
Reviewers for LOPSTR: 
Michel Bidoit 
Paolo Ciancarini 
Ilyas ~i~ekli 
Koen De Bosschere 
Pierre Deransart 
Danny De Schreye 
Philippe Devienne 
Yves Deville 
Alexander Dikovsky 
Maurizio Gabrielli 
Program Committee of META: 
Tadashi Kanamori 
Baudouin Le Charlier 
Christophe Lecoutre 
Vincent Lombart 
Anne Mulkers 
Guy Alain Narboni 
Chet Murthy 
Anne Parrain 
Sophie Renault 
Christel Vrain 
L. Aiello (Rome, Italy) 
K. Bowen (Syracuse, USA) 
Y. Jiang (London, UK) 
G. Lanzarone (Milan, Italy) 
L.M. Pereira (Lisbon, Portugal) 
A. Porto (Lisbon, Portugal) 
L. Sterling (Cleveland, USA) 
F. Turini (Pisa, Italy) (Chairman) 
J. Barklund (Uppsala, Sweden) 
D. De Schreye (Leuven, Belgium) 
J. Komorowski (Trondheim, Norway) 
A. Martelli (Turin, Italy) 
A. Pettorossi (Rome, Italy) 
T. Sato (Tsukuba, Japan) 
S.A. Tarnlund (Uppsala, Sweden) 

Table of Contents 
LOPSTR 
Logic Frameworks for Logic Programs 
D.A. Basin (Max-Planck.Institut fiir Informatik, Saarbriicken, Germany) 
An Extended Transformation System for CLP Programs 
N. Bensaou, L Guessarian (LITP- Universitd Paris 6, France) 
Using Call/Exit Analysis for Logic Program Transformation 
D. Boulanger, M. Bruynooghe (Katholieke Universiteit Leuven, Belgium) 
A Transformation System for Definite Programs Based on 
Termination Analysis 
J. Cook, J.P. Gallagher (University of Bristol, United Kingdom) 
On the Use of Inductive Reasoning in Program Synthesis: 
Prejudice and Prospects 
P. Flener (Bilkent University, Ankara, Turkey) 
L. Popel(nsk~ (Masaryk University, Brno, Czech Republic) 
Transforming Specifications of Observable Behaviour into Programs 
D. Gilbert (City University, London, United Kingdom) 
C. Hogger (Imperial College, London, United Kingdom) 
J. Zlatu3ka (Masaryk University, Brno, Czech Republic) 
On Specification Frameworks and Deductive Synthesis 
of Logic Programs 
K.-K. Lau (University o] Manchester, United Kingdom) 
M. Ornaghi (Universith degli Studi di Milano, Italy) 
Partial Evaluation of the "Real Thing" 
M. Leuschel (Katholieke Universiteit Leuven, Belgium) 
Schema-Based Top-Down Design of Logic Programs 
Using Abstract Data Types 
E. Marakakis, J.P. Gallagher (University of Bristol, United Kingdom) 
Generalizing Extended Execution for Normal Programs 
S. Renault (INRIA-Rocquencourt, Le Chesnay, France) 
Partial Deduction of Disjunctive Logic Programs: 
A Declarative Approach 
C. Sakama (ASTEM Research Institute of Kyoto, Japan) 
H. Seki (Nagoya Institute of Technology, Japan) 
17 
36 
51 
69 
88 
104 
122 
138 
154 
170 

viii 
Avoiding Non-Termination when Learning Logical Programs: 
A Case Study with FOIL and FOCL 
183 
G. Semeraro, F. Esposito, D. Malerba (Universitd degli Studi di Bari, Italy) 
C. Brunk, M. Pazzani (University of California, Irvine, U.S.A.) 
Propagation of Inter-Argument Dependencies in 
Tuple-Distributive Type Inference Systems 
C. Solnon, M. Rueher (I3S, UNSA/CNRS, Sophia Antipolis, France) 
199 
Logic Programming and Logic Grammars 
with First-Order Continuations 
P. Tarau (Universitd de Moncton, Canada) 
V. Dahl (Simon Fraser University, Burnaby, Canada) 
215 
Improving the Whelk System: A Type-Theoretic Reconstruction 
G. A. Wiggins (University of Edinburgh, United Kingdom) 
231 
META 
A Model of Costs and Benefits of Meta-Level Computation 
F. van Harmelen (University of Amsterdam, The Netherlands) 
A Basis for a Multilevel Metalogic Programming Language 
J. Barklund, K. Boberg (Uppsala University, Sweden) 
P. DeU'Acqua (Universitd degli Studi di Milano, Italy) 
Logic Programs with Tests 
M. Mircheva (Bulgarian Academy of Sciences, Sofia, Bulgaria) 
An Architecture with Multiple Meta-levels for the Development 
of Correct Programs 
B. Dunin-Kgplicz (University of Warsaw, Poland) 
More on Unfold/Fold Transformations of Normal Programs: 
Preservation of Fitting's Semantics 
A. Bossi, S. Etalle (Universitd di Padova, Italy) 
Formal Semantics of Temporal Epistemic Reflection 
W. van der Hoek, J.-J. Meyer, (Utrecht University and 
Free University Amsterdam, The Netherlands) 
J. Treur (Free University Amsterdam, The Netherlands) 
248 
262 
276 
293 
311 
332 

Jâ€¢ 
Temporal Semantics of Meta-Level Architectures 
for Dynamic Control of Reasoning 
J. Treur (Free University Amsterdam, The Netherlands) 
GSdel as a Meta-Language for Composing Logic Programs 
A. Brogi, S. Contiero (Universitd di Pisa, Italy) 
A Module System for Meta-Programming 
P.M. Hill (University of Leeds, United Kingdom) 
Building Proofs in Context 
G. Attardi, M. Simi (Universith di Pisa, Italy) 
Introspective Metatheoretic Reasoning 
F. Giunchiglia, A. Cimatti (IRST, Trento, Italy) 
Abstract Debugging of Logic Programs 
M. Comini, G.Levi (Universith di Pisa, Italy) 
G. Vitiello (Universith di Salerno, Italy) 
353 
377 
395 
410 
425 
440 
Author Index 
451 

Logic Frameworks for Logic Programs* 
David A. Basin 
Max-Planck-Institut f'dr Informatik 
Saarbrllcken, Germany 
Email:basin~ mpi-sb.mpg.de 
Abstract. We show how logical frameworks can provide a basis for logic 
program synthesis. With them, we may use first-order logic as a foundation 
to formalize and derive rules that constitute program development calculi. 
Derived rules may be in turn applied to synthesize logic programs using 
higher-order resolution during proof that programs meet their specifications. 
We illustrate this using Paulson's Isabelle system to derive and use a simple 
synthesis calculus based on equivalence preserving transformations. 
1 Introduction 
Background 
In 1969 Dana Scott developed his Logic for Computable Functions and with it a 
model of functional program computation. Motivated by this model, Robin Milner 
developed the theorem prover LCF whose logic PP)~ used Scott's theory to rea- 
son about program correctness. The LCF project [13] established a paradigm of 
formalizing a programming logic on a machine and using it to formalize different 
theories of functional programs (e.g., strict and lazy evaluation) and their correct- 
ness; although the programming logic was simple, within it complex theories could 
be developed and applied to functional program verification. 
This paradigm can be characterized as formal development from foundations. 
Type theory and higher-order logic have been also used in this role. A recent example 
is the work of Paulson with ZF set theory. Although this theory appears primitive, 
Paulson used it to develop a theory of functions using progressively more powerful 
derived rules [24]. 
Most work in formalized program development starts at a higher level; founda- 
tions are part of an informal and usually unstated recta-theory. Consider, for exam- 
ple, transformation rules like Burstall and Darlington's well known fold-unfold rules 
[7]. Their rules are applied to manipulate formulas and derive new onesl afterwards 
* This research was funded by the German Ministry for Research and Technology (BMFT) 
under grant ITS 9102. The responsibility for the contents lies with the author. I thanks 
Tobias Nipkow and Larry Paulson for advice on Isabelle. I also thank Alan Bundy, Ina 
Kraan, Scan Matthews, and members of the Edinburgh Mathematical Reasoning Group 
for helpful discussions and collaboration on related work. 

some collection of the derived formulas defines the new program. The relationship 
of the new formulas to the old ones, and indeed which constitute the new program is 
part of their informal (not machine formalized) metatheory. So is the correctness of 
their rules (see [18, 8]). In logic programming the situation is similar; for example, 
[30, 29] and others have analyzed conditions required for fold-unfold style transfor- 
mations to preserve equivalence of logic programs and indeed what "equivalence" 
means. 
Development from Foundations in Logic Programming 
We propose that, analogous to LCF, we may begin with a programming logic and 
derive within it a program development calculus. Derived rules can be applied to 
statements about program correctness formalized in the logic and thereby verify or 
synthesize logic programs. Logic programming is a particularly appropriate domain 
to formalize such development because under the declarative interpretation of logic 
programs as formulas, programs are formalizable within a fragment of first-order 
logic and are therefore amenable to manipulation in proof systems that contain this 
fragment. Indeed, there have been many investigations of using first-order logic to 
specify and derive correct logic programs [9, 10, 11, 17, 19]. But this work, like that 
of Burstall and Darlington, starts with the calculus rather than the foundations. For 
example in [17] formulas are manipulated using various simplification rules and at 
the end a collection of the resulting formulas constitutes the program. The validity 
of the rules and the relationship of the final set of formulas (which comprise the 
program) to the specification is again part of the informal meta-theory. 
Our main contribution is to demonstrate that without significant extra work 
much of the informal metatheory can be formalized; we can build calculi from 
foundations and carry out proofs where our notion of correctness is more explicit. 
However, to do this, a problem must be overcome: first-order logic is too weak to 
directly formalize and derive proof rules. Consider for example, trying to state that 
in first-order logic we may replace any formula Vx.A by -,3z.~A. We might wish 
to formulate this as Vx.A -4 -~3x.-~A. While this is provable for any instance A, 
such a generalized statement cannot be made in first-order logic itself; some kind 
of second-order quantification is required. 2 In particular, to formalize proof rules 
of a logic, one must express rules that (in the terminology of [15]) are schematic 
and hypothetical. The former means that rules may contain variables ranging over 
formula. The latter means that one may represent logical consequence; in the above 
example consequence has been essentially internalized by implication in the object 
language. 
Rather than moving to a more powerful logic like higher-order logic, we show 
that one can formalize program development using weak logics embedded in logical 
frameworks such as Paulson's Isabelle system [25] or Pfenning's ELF [28]. In our 
2 First-order logic is too weak, but it is possible to formalize powerful enough first-order 
theories to express such rules by axiomatizing syntax, e.g., [32, 3, 23]. However, such 
approaches require some kind of reflection facility to establish a link between the for- 
realized meta-theory and the desired theory where such rules are used. See [4] for a 
further discussion of this. Moreover, under such an approach unification cannot be used 
to identify program verification and synthesis. 

work, a programming logic (also called the object logic) is encoded in the logic of the 
logical framework (the meta-logic). For example, the meta-logic of Isabelle, which 
we use, is fragment of higher-order logic containing implication (to formalize hypo- 
thetical rules) and universal quantification (to formalize schematic rules). Within 
this meta-logic we formalize a theory of relevant data-types like lists and use this 
to specify our notion of program correctness and derive rules for building correct 
programs. Moreover, Isabelle manipulates rules using higher-order unification and 
we use this to build programs during proof where meta-variables are incrementally 
instantiated with logic programs. 
We illustrate this development paradigm by working through a particular exam- 
ple in detail. Within an Isabelle theory of first-order logic we formulate and derive 
a calculus for reasoning about equivalences between specifications and representa- 
tions of logic programs in first-order logic. The derived calculus can be seen as a 
formal development of a logic for program development proposed in Wiggins (see 
Section 3.4). After derivation, we apply these rules using higher-order unification 
to verify that logic programs meet their specifications; the logic programs are given 
by meta-variables and each unification step during proof incrementally instantiates 
them. 
Our experience indicates that this development is quite manageable. Isabelle 
comes with well-developed tactic support for rewriting and simplification. As a re- 
sult, our derivation of rules was mostly trivial and involved no more than typing 
them in and invoking the appropriate first-order simplification tactics. Moreover, 
proof construction with these rules was partially automated by the use of Isabelle's 
standard normalization and simplification procedures. We illustrate this by devel- 
oping a program for list subset. 
2 
Background 
to Isabelle 
What follows is a brief overview of Isabelle [25, 26, 27] as is necessary for what fol- 
lows. Isabelle is an interactive theorem prover developed by Larry Paulson. It is a 
logical framework: its logic serves as a meta-logic in which object logics (e.g., first- 
order logic, set theory, etc.) are encoded. Proofs are interactively constructed by 
applying proof rules using higher-order resolution. Proof construction may be auto- 
mated using tactics which are ML programs in the tradition of LCF that construct 
proofs. 
Isabelle provides a fine basis for our work. Since it is a logical framework, we may 
encode in it the appropriate object logic, first-order logic (although we indicate in 
Section 5 other possible choices). Isabelle's metalogic is based on the implicational 
fragment of higher-order logic where implication is represented by "--=>" and univer- 
sal quantification by "! !"; hence we can formalize and derive proof rules which are 
both hypothetical and schematic. Rules, primitive and derived, may be applied with 
higher-order unification during higher-order resolution; unification permits meta- 
variables to occur both in rules and proofs. We use this to build logic programs by 
theorem proving where the program is originally left unspecified as a higher-order 
meta-variable and is filled in incrementally during the resolution steps; the use of 
resolution is similar to the use of "middle out reasoning" to build logic programs as 
demonstrated in [20, 21, 6, 33]. 

Isabelle manipulates objects of the form a [IF1; .... ; Fall ~-~> F. A proof proceeds 
by applying rules to such formulas which result in zero or more subgoals, possibly 
with different assumptions. When there are no subgoals, the proof is complete. 
Although Isabelle proof rules are formalized natural deduction style, the above 
implication can be read as an intuitionistic sequent where the Fi are the hypotheses. 
Isabelle has resolution tactics which apply rules in a way the maintains this illusion 
of working with sequents. 
3 
Encoding A Simple Equivalence Calculus 
We give a simple calculus for reasoning about equivalence between logic programs 
and their specifications. Although simple, it illustrates the flavor of calculus and 
program development we propose. 
3.1 
Base Logic 
We base our work on standard theories that come with the Isabelle distribution. 
We begin by selecting a theory of constructive first-order predicate calculus and 
augment this with a theory of lists to allow program development over this data- 
type (See IFOL and List in [27]). The list theory, for example, extends Isabelle's 
first-order logic with constants for the empty list "[]', cons ".", and standard axioms 
like structural induction over lists. In addition, we have extended this theory with 
two constants called gfl, (well-formed program) and per with the property that 
wfp(P) * Per(P) -- P for all formulas P; their role will be clarified later. 
The choice of lists was arbitrary; to develop programs over numbers, trees, etc. 
we would employ axiomatizations of these other data-types. Moreover, the choice of 
a constructive logic was also arbitrary. Classical logic suffices too as the proof rules 
we derive are clearly valid after addition of the law of excluded middle. This point 
is worth emphasizing: higher-order unification, not any feature of constructivity, is 
responsible for building programs from proofs in our setting. 
In this theory, we reason about the equivalence between programs and speci- 
fications. "Equivalence" needs clarification since even for logic programs without 
impure features there are rival notions of equivalence. The differences though (see 
[22, 5]) are not so relevant in illustrating our suggested methodology (they mani- 
fest themselves through different formalized theories). The notion of equivalence we 
use is equivalence between the specification and a logic program represented as a 
pure logic program in the above theory. Pure logic programs themselves are equiv- 
alences between a universally quantified atom and a formula in a restricted subset 
of first-order logic (see [6] for details); they are similar to the logic descriptions of 
[12]. 
For example, the following is a pure logic program for list membership, where 
a.. is CONS. 4 
8 We shall use zyl0owriter font to display concrete Isabelle syntax. 
4 Unfortunately, "." is overloaded and also is used in the syntax of quantifiers; e.g., Vx Y.$ 
which abbreviates Vx.Vy.r 

Vx y.p(x, y) ~ (x = 0 A False) V (Svo Vl.X = VO.Vl A (y ---- V 0 V p(Vl, y))) 
(l) 
Such programs can be translated to Horn clauses or run directly in a language like 
Gbdel [16]. 
3.2 
Problem Specification 
As our notion of correctness is equivalence between programs and specifications, 
our proofs begin with formulas of the form V-2.(spec(~) ++ E(-2)). The variables 
in 9 represent parameters to both the specification spec and the logic program E; 
we do not distinguish input from output, spec is a first-order specification and E 
is either a concrete (particular) pure logic program or a schematic (meta) variable 
standing in for such a program. If E is a concrete formula then a proof of this 
equivalence constitutes a verification proof as we are showing that E is equivalent to 
its specification. If E is a second-order meta-variable then a proof of this equivalence 
that instantiates E serves as a synthesis proof as it builds a program that meets 
the spec. If spec is already executable we might consider such a proof to be a 
transformation proof. 
An example we develop in this report is synthesizing a program that given two 
lists l and m is true when l is a subset of m. This example has been proposed by 
others, e.g., [17, 33]. Slipping into Isabelle syntax we specify it as 
ALL 1 m. (ALL z. In(z,l) --> In(z,m)) <-> ?E(l,m). 
Note that ALL, --> and <-> represent first-order universal quantification, implication, 
and equivalence, and are declared in the definition of first-order logic. The "?" 
symbol indicates metavariables in Isabelle. Note that rE is a function of the input 
lists 1 and m but z is only part of the specification. Higher-order unification, which 
we use to build an instance for ?g will ensure that it is only a function of 1 and =. 
3.3 
Rules 
We give natural deduction rules where the conclusion explains how to construct ?~ 
from proofs of the subgoals. These rules form a simple calculus for reasoning about 
equivalences and can be seen as a reconstruction of those of the Whelk system (see 
Section 3.4). Of course, since A <-> A is valid, the synthesis specification for subset 
can be immediately proven by instantiating ?r with the specification on the left hand 
side of the equivalence. While this would lead to a valid proof, it is uninteresting as 
the specification does not suggest an algorithm for computing the subset relation. 
To make our calculus interesting, we propose rules that manipulate equivalences 
with restricted right-hand sides where the right hand side can be directly executed. 
Specifically, we propose rules that admit as programs (on the right hand sides of 
equivalences) formulas like the body of the membership predicate given above, but 
exclude formula like ALL z. In(z,1) --> rn(z,m). To do this we define inductively the 
set of such admissible formulas. They are built from a collection of (computable) 
base-relations and operators for combining these that lead to computable algorithms 
provided their arguments are computable. In particular, our base relations are the 
relations True, False, equality and inequality. Our operators will be the proposi- 
tional connectives and existential quantification restricted to a use like that in the 

membership example, i.e., of the form 3vovl.x = vo.vl A P where P is admissible. 
This limited use of existential quantification is necessary for constructing recursive 
programs in our setting; it can be trivially compiled out in the translation to Horn 
clauses. 
Note that to be strictly true to our "foundations" paradigm, we would specify 
the syntax of such well-formed logic programs in our theory (which we could do 
by recursively defining a unary well-formedness predicate that captures the above 
restrictions). However, to simplify matters we capture it by only deriving rules for 
manipulating these equivalences where the right-hand sides meet these restrictions. 
To ensure that only these rules are used to prove equivalences we will resort to a 
simple trick. Namely, we wrap all the right hand sides of equivalences in our rule, 
and in the starting specification with the constructor ~fp. E.g., our starting goal for 
the subset proof would really be 
ALL I m. (ALL z. In(z,l) --> In(z,m)) <-> Wfp(?E(l,m))). 
As w~p was defined to be the identity (i.e., w~p(P) equals P) it does not effect the 
validity of any of the rules. It does, however, affect their applicability. That is, after 
rule derivation we remove the definition of w~lD from our theory so the only way 
we can prove the above is by using rules that manipulate equivalences whose right 
hand side is also labeled by ~p. In particular, we won't be able to prove 
ALL l m. (ALL z. In(z,l) --> In(z,m)) <-> Wfp(ALL z. In(z,l) --> In(z,m)). 
Basic Rules Figure 1 contains a collection of typical derived rules about equiva- 
lences. Many of the rules serve simply to copy structure from the specification to 
the program. These are trivially derivable, for example 
A ~ Wfp(ExtA) 
B ~ Wfp(ExtB) 
A A B 44 Wfp(ExtA A ExtB) 
Translating this into Isabelle we have 
[I A <-i~ I/~p(ExtA); B 4-> W~p(ExtB) I] ==> A ,lt B <-> Wfp(Exta J: ExtB). 
This rule is derivable (recall that w2p(P) = P) in one step with Isabelle's simplifica- 
tion tactic for intuitionistic logic, so it is a valid rule. The rule allows us essentially 
to decompose synthesizing logic programs for a Conjunction into synthesizing pro- 
grams for the individual parts. Note that this rule is initially postulated with free 
variables like A and v.xtA which are treated as constants during proof of the rule; 
this prevents their premature instant;at;on, which would lead to a proof of some- 
thing more specialized. When the proof is completed, these variables are replaced 
by metavariables, so the rule may be later applied using unification. 
There are two subtleties in the calculus we propose: parameter variables and 
induction rules. These are explained below. 

ghllI: [[ 
!!x. h(x) <-> Wfp(Ext) l] ==> (ALL x.h(x)) <-> Wfp(Ext) 
gAndl: [] A <-> Wfp(ExtA); B <-> Wfp(ExtB) [] ==> A 9 B <-> Wfp(Exth 9 ExtB) 
gOrI: [l A <-> Wfp(ExtA); B <-> Wfp(ExtB) [] ==> A I B <-> Wfp(ExtA t ExtB) 
gImpI: [] A <-> Wfp(Extl); B <-> Wfp(ExtB) m] ==> (A --> B) <-> (Wfp(ExtA --> ExtB)) 
gTrue: [Z AI] ==> A <-> Wfp(True) 
gFalse: [I "A]] ==> A <-> Wfp(False) 
RAllE: [l ALL x.A(x) <-> Wfp(Ext(x)) ]] ==> A(x) <-> Wfp(Ext(x)) 
gOrE: [I A ==> (C <-> Wfp(ExtA)); B ==> (C <-> Wfp(ExtB)); A i B ]] ==> 
C <-> Wfp(ExtA [ ExtB) 
EqInstamce: 
A = B <-> Wfp(A = B) 
Fig. 1. Examples of Basic Rules 
Predicate Parameters Recall that problems are equivalences between specifica- 
tions and higher-order meta-variables applied to parameters, e.g., 1 and m in the 
subset specification. We would like our derived rules to be applicable independent of 
the number of parameters involved. Fortunately, these do not need to be mentioned 
in the rules themselves (with one exception noted shortly) as Isabelle's higher-order 
unification properly propagates these parameters to subgoals. This is explained be- 
low. 
Isabelle automatically lifts rules during higher-order resolution (see [25, 26]); this 
is a sound way of dynamically matching types of meta-variables during unification 
by applying them to new universally quantified parameters when necessary. This 
idea is best explained by an example. Consider applying the above conjunction rule 
to the following (made-up) goal. 
ALL i m. ((ALL z. In(z,l)) 9 (Exists z. "In(z,m))) <-> Wfp(?E(l,m))) 
In our theory, we begin proving goals by "setting up a context" where initial univer- 
sally quantified variables become eigenvariables. 5 Applying V-I (V-intro of first-order 
logic) twice yields the following. 
!! 1 m. ((ILL z. In(z,l)) 9 (Exists z. -In(z,m))) <-> Wfp(?E(l,m))) 
Now if we try to apply the above derived rule for conjunction, Isabelle will auto- 
matically lift this rule to 
!! 1 m. [I ?h(l,m) <-> Extract(YExth(l,m)); ?B(l,m) <-> Extract(?ExtB(l,m)) [] ==> 
?A(l,m) 9 7B(l,m) <-> Extract(?ExtA(l,m) 9 ?ExtB(l,m)), 
which now resolves with ?A(l,m) = ALL z. InCz,l), ?B(l,m) = Exists z. "In(z,m), and 
the program is instantiated with ?E(1,m) -- ?ExtA(1,m) 9 ?ExtB(1,m). As the proof pro- 
ceeds ?ExtA and .*ExtB are further instantiated. 
s By eigenvariables, we mean variables universally quantified outermost in the context. 
Recall universal quantification is the operator "!!" in Isabelle's meta-logic. See [26] for 
more details. 

Recurslve Definitions Our calculus so far is trivial; it copies structure from spec- 
ifications into programs. One nontrivial way of transforming specifications is to ad- 
mit proofs about equivalence by induction over the recursively defined data-types. 
But this introduces a problem of how predicates recursively call themselves. 
We solve this by proving theorems in a context and proof by induction can extend 
this context with new predicate definitions. 6 In particular, the context will contain 
not only axioms for defined function symbols (e.g., like In in the subset example) 
but it also contains a meta-variable ("wrapped" by Def) that is instantiated during 
induction with new predicate definitions. 
Back to the subset example; our starting goM actually includes a context which 
defines the axioms for In and includes a variable .'11 which expands to a definition 
or series of definitions. These will be called from the program that instantiates ?E. 
[[ ALL x. "In(x,[]); 
ALL x h t. 
In(x,h.t) 
<-> x = h [ In(x,t) 
[] 
==> Def(711) --> (ALL 1 m. (ALL z. In(z,l) --> In(z,m)) <-> Wfp(TE(l,m))) 
The wrapper Def (recall this, like w~p is the identity) also serves to restrict unification; 
in particular, only the induction rule which creates a schematic pure logic program 
can instantiate Def(?a). 
Definitions are set up during induction. Consider the following rule correspond- 
ing to structural induction over lists. This rule builds a schematic program P(x,y) 
contained in the first assumption. The second and third assumption correspond to 
the base case and step case of a proof by induction showing that this definition is 
equivalent to the specification formula a(x,y). This rule is derived in our theory by 
list induction. 
[] Def(ALL x y. P(x,y) 
<-> (x = [] Jt EA(y)) I (EX vO vl. 
x = vO.vl Jt EB(vO,vl,y))); 
ALL y. A([J,y) <-> Wfp(EA(y)); 
!'m. ALL y. A(m,y) <-> Wfp(P(m,y)) ==> ALL h y. A(h.,,,y) 
<-> Wfp(EB(h,m,y)) [J 
==> h(x,y) 
<-> Wfp(P(=,y)) 
As in [2] we have written a tactic that applies induction rules. Resolution with 
this rule yields three subgoals (corresponding to the three assumptions above) but 
the first is discharged by unifying against a De~(?H) in the context which sets up a 
recursive definition. This is precisely the role that Def(?11) serves. Actually, to allow 
for multiple recursive definitions, the induction tactic first duplicates the DefCrH) 7 
before resolving with the induction rule. Also, it thins out (weakens) the instantiated 
definition in the two remaining subgoals. 
There is an additional subtlety in the induction rule which concerns parameter 
arguments. Other rules did not take additional parameters but this is the exception; 
P takes two arguments even though the induction is on only one of them. This is 
s The ability to postulate new predicate definitions can, of course, lead to inconsistency. 
We lack space here for details, but it is not hard to prove under our approach that 
defined predicates are defined by well-founded recursion and may be consistently added 
as assumptions. 
7 Def(?H) equals 711 and if we have an hypothesis 711 then we can instantiate it with 7111 l 
?H2. rnstantiation is performed by unification with Jr-elimination and results in the new 
assumptions ?H1 and 71t2 which are rewrapped with Def. This "engineering with logic" 
is accomplished by resolving with a derived rule that performs these manipulations. 

necessary as the rule must establish (in the first assumption) a definition for a 
predicate with a fixed number of universally quantified parameters and the number 
of these cannot be predicted at the time of the induction. Our solution to this 
problem is ad hoc; we derive in Isabelle a separate induction rule for each number 
of arguments needed in practice (two are needed for the predicates synthesized in 
the subset example). Less ad hoc, but more complex, solutions are also possible. 
3.4 
Relationship to Other Calculi 
The derived calculus, although very simple, is motivated by and is similar to the 
Whelk Calculus developed by Wiggins in [33]. There Whelk is presented as a new 
kind of logic where specifications are manipulated in a special kind of "tagged" 
formal system. A tagged formula A is of the form [A~F(~}or Both formulas and 
sequents are tagged and the tag subscript represents part of a pure logic program. 
The Whelk logic manipulates these tags so that the tagged (subscripted) program 
should satisfy two properties. First, the tagged program should be logically equiv- 
alent to formula it tags in the appropriate first-order theory. To achieve this the 
proof rules state how to build programs for a given goal from programs correspond- 
ing to the subgoals. Second, the tagged program should be decidable, which means 
as a program it terminates in all-ground mode. One other feature of Whelk is that a 
proof may begin with a subformula of the starting goal labeled by a special operator 
O. At the end of the proof the Whelk system extracts the tagged program labeling 
this goal; hence Whelk may be used to synthesize logic programs. 
The rules I give can be seen as a reinterpretation of the rules of Whelk where 
tagged formulas are formulated directly as equivalences between specifications and 
program schemas (for full details see [1]); hence, seen in this light, the Whelk rules 
constitute a simple calculus for manipulating equivalences. For example, the Whelk 
rule for reasoning about conjunctions is 
O A.I.~I" I- O A]]p(c.)~r ~lr' P- O B~p(~)~r 
and can be straightforwardly translated into the rule RAndI given in Section 3.3 (r 
and r play the role of ExtA and EztB and P and its parameters E are omitted.) 
Our derivation of many of these rules provides a formal verification that they are 
correctness preserving with respect to the above mentioned equivalence criteria. In 
[1] we describe the translation and derivation of the Whelk rules in considerable 
detail. Interestingly, not all of the Whelk rules given could be derived; the reinter- 
pretation led to rules which were not derivable (counter models could be given) and 
hence helped uncover mistakes in the original Whelk calculus. This confirms that 
just as it is useful to have machine checked proofs of program correctness, it is also 
important to certify calculi formally. 
4 
Program 
Development 
We now illustrate how the derived rules can be applied to program synthesis. Our 
example is synthesizing the subset predicate (over lists). We choose this as it is a 
standard example from the literature. In particular, our proof is almost identical to 
one given in [33]. 

/0 
Our proof requires 15 steps and is given in Figure 2 with comments. Here we 
replay Isabelle's response to these proof step% i.e., the instantiated top-level goal 
an~ subgoals generated after each step. The output is taken directly from an Isabelle 
session except, to save space, we have combined a couple of steps, "pretty printed" 
formulas, and abbreviated variable names. 
val [inbase,instep] = goal thy 
" 
[] ALL x. "In(x,[]); \ 
\ 
ALL x h t. In(x,h.t) <-> x = h I In(x,t) ~] \ 
\ ==> Def(?H) --> (ALL 1 m. (ALL z. In(z,l) --> In(z,m)) <-> Wfp(?E(l,m)))"; 
(* After performing forall introductions, perform induction *) 
by SetUpContext; 
by (IndTac WListInduct2 
[("x","l"),("y","m")] 1); 
(* Base Case *) 
br ~IiiI I; 
br RTrus 1; 
by (cut.fast_tat [inbase] I); 
(* Step Case *) 
by(SIMP_TAC (list_ss addre,s [instep,AndImp,AllEnd,A11EqImp]) I); 
br RAndI 1; 
(* Prove 2nd case ,ith induction hypothesis! *) 
by (etar a11E 2 THEI assllme_tac 2); 
(* First Case --- De an induction on y to synthesize member(h,y) *) 
by (IndTac WListInduct2 
[("x","y"),("y","h")] i); 
br RFalse I; 
(* Induction Base Case *) 
by(SIMP.TAC (list_ss addrews [inbase]) 1); 
by(SIHP.TAC (list_ss address [instep]) I); 
(* Induction Step Case *) 
br ROrI 1; 
5r EqInstance 1; 
by (etac allE 1 THEN assume_tat I); 
(* Apply induction hypothesis *) 
Fig. 2. Isabene Proof Sc~pt for Subset Proof 
The proof begins by giving Isabelle the subset specification. Isabelle prints back 
the goal to be proved (at the top) and the subgoals necessary to establish it. As the 
proof proceeds, the theorem we are proving becomes specialized as ?H is incremen- 
tally instantiated with a program. We have also given the names inbase and instep 
to the context assumptions that define the membership predicate In. 
Def(TH) --> (ALL 1 m. (ALL z. In(z, i) --> In(z, m)) <-> Wfp(TE(I, m))) 
I. Def(TH) --> (ALL 1 m. (ALL z. In(z, i) --> In(z, m)) <-> Wfp(TE(l, m))) 
val inbase = "ALL x. " In(x, [])" 
val instep = *'ALL x h t. In(x, h . t) <-> x = h I In(x, t)" 
The first proof step, invoked by the tactic SetUpContext, moves the definition 
variable ?H into the assumption context and, as discussed in the previous section, 
promotes universally quantified variables to eigenvariables so our rules may be used 
via lifting. 

11 
Def(?lt) --> CALL 1 m. (ALL z. In(z, 
1) --> InCz, m)) <-> Wfp(?E(l, m))) 
1. 
!!l m. Def(?H) ==> CALL z. In(z, 
1) --> In(z, m)) <-> Wfp(?E(1, m)) 
Next, we invoke our induction tactic that applies the derived list induction rule, 
specifying induction on 1. The execution of the tactic instantiates our schematic 
definition *H with the first schematic definition ?P and a placeholder ?q for further 
instantiation. Note too that ?E has been instantiated to this schematic program ?P. 
Def((ALL x y. ?P(x, y) <-> x = [] ~ 7EAIO(y) I 
(EX vO vl. 
x = vO . vl 
t ?EBII(vO, vl, 
y))) 
?Q) --> 
(ALL im. (ALL z. In(z, i) --> In(z, m)) <-> Wfp(?P(l, m))) 
i. !:i m y. Def(?q) ==> (ALL z. InCz, []) --> InCz, y)) <-> Wfp(?EAlOCy)) 
2. !!i mmah 
y. 
[I DefC?q); ALL y. (ALL z. InCz, ma) --> InCz, y)) <-> Wfp(?PCma, y)) I] ==> 
(ALL z. InCz, h . ma) --> InCz, y)) <-> Wfp(?EBllCh, ma, y)) 
We now prove the first case, which is the base-case (and omit printing the step 
case in the next two steps -- Isabelle maintains a goal stazk). First we apply aAllI 
which promotes the V-quantified variable z to an eigenvariable. The new subgoal 
becomes (as this step does not instantiate the theorem we are proving, we omit 
redisplaying it) the following. 
I. !!i m y z. Def(TQ) ==> (In(z, []) --> In(z, y)) <-> Wfp(?EAlOCy)) 
Next we apply RTrue which states if ?F410(y) is True, the above is provable provided 
InCz, []) --> InCz, y) is provable. This reduces the goal to one of ordinary logic 
(without wfp) as it instantiates the base case with the proposition True. 
Def((ALL x y. 7P(x, y) <-> x = [] & True [ 
(EX vO vl. x = vO . vl & ?EBII(vO, vl, y))) & 
Tq) --> 
(ALL I m. (ALL z. In(z, I) --> In(z, m)) <-> Wfp(?P(l, m))) 
I. !!I m y z. DefCTQ) ==> InCz, []) --> InCz, y) 
Finally we complete this step by applying Isabelle's predicate-calculus simpli- 
fication routines augmented with base case of the definition for In. Isabelle leaves 
us with the following step case (which is now the top goal on the stack and hence 
numbered 1). 
1. 
!!lmmah 
y. 
l'l Def(?O); ALL y. (ALL z. In(z, ma) --> In(z, y)) <-> Wfp(TP(ma, y)) 1] ==> 
CALL z. InCz, h . ma) --> In(z, y)) <-> WfpCTEB11(h, ma, y)) 
We now normalize this goal by applying the tactic 
SIMP_TAC Clist_ss addrews [instep,AndImp,AllAnd,AllEqImp]) I 
This calls Isabelle's simplification tactic which applies basic simplifications for the 
theory of lists, list_,,, augmented with the recursive case of the definition for In 
and the following lemmas AndImp, AllAnd and AllEqImp. 
(A I B --> C) <-> CA --> C) ~ CB --> C) 
ALL v. A(v) ,It B(v)) <-> (ALL v.A(v)) & (ALL v.B(v)) 
CALL v. v = , --> A(v)) <-> A(w) 

12 
Each of these had been previously (automatically!) proven with Isabelle's predicate 
calculus simplifier. This normalization step simplifies our subgoal to the following. 
I. !!1 m ma h y. 
[1Def(?Q); 
ALL y. (ALL z. In(z, ma) --> In(z, y)) <-> Wfp(?P(ma, y)) 1] ==> 
In(~, y) 9 (ALL v. In(v, ma) --> In(v, y)) <-> Wfp(?EBII(h, ma, y)) 
We decompose the conjunction with RAndl, which yields two subgoals. 
Dof((ALL x y. ?P(x, y) <-> x = [] t True [ 
(EX vO yr. x = vO . vl & ?EA21(v1, vO, y) ~ ?EB22(vl, vO, y))) 
7Q) --> 
(ALL 1 m. (ALL z. In(z, 
1) --> In(z, 
m)) <-> Wfp(?P(I, m))) 
1. !!1 m ma h y. 
[[ Def(TQ); ALL y. (ALL z. In(z, ma) --> In(z, y)) <-> Wfp(?P(ma, y)) I] ==> 
In(h, y) <-> Wfp(TEA21(ma, h, y)) 
2.'!!1 m ma h y. 
[[ Def(TQ); ALL y. (ALL z. In(z, ma) --> In(z, y)) <-> Wfp(?P(ma, y)) [] ==> 
(ALL v. In(v, ma) --> In(v, y)) <-> Wfp(?EB22(ma, h, y)) 
We immediately solve the second subgoal by resolving with the induction hy- 
pothesis. I.e., after V-E we unify the conclusion with the induction hypothesis using 
Isabelle's assumption tactic. This instantiates the program we are building by re- 
placing ?ES22 with a recursive call to ?P as follows. 
Def((ALL x y. ?P(x, y) <-> x = [] & True l 
(EX vO vl. 
x = vO . vl & ?EA21(vl, vO, y) & ?P(vt, 
y))) 
& ?Q) --> 
(ALL 1 m. (ALL z. In(z, 
1) --> In(z, m)) <-> Wfp(?P(1, m))) 
Returning to the first goal (to build a program for TEA21), we perform another 
induction; the base case is proved as in the first induction except rather than intro- 
ducing True with RTrue we introduce False with RFalse and solve the remaining goal 
by simplification. This leaves us with the step case. 
Def((ALL x y. 7PCx, y) <-> x = [] & True l 
(EX vO vl. 
x ffi vO . vl & ?Pa(vO, y) ~ ?P(vl, y))) & 
(ALL x y. ?Pa(y, x) <-> x = [] 9 False 
[ 
(EX vO vl. 
x = vO . vl 9 ?EB32(vO, vl, y))) & 
?Q27) --> 
(ALL i m. (ALL z. In(z, 
i) --> In(z, m)) <-> Wfp(?P(l, m))) 
I. 
!!I m ma h y mb ha ya. 
[I ALL y. (ALL z. In(z, ma) --> In(z, 
y)) <-> ~fp(?P(aa, 
y)); 
Def(TQ27); ALL y. In(y, mb) <-> Wfp(YPa(y, mb)) ]] ==> 
In(ya, 
ha . mb) <-> Wfp(?EB32(ha, mb, ya)) 
As before, we normalize this subgoal with Isabelle's standard simplifier. 
1. 
!!1 m ma h y mb ha ya. 
[[ ALL y. (ALL z. In(z, ma) --> In(z, 
y)) <-> Wfp(?P(ma, y)); 
Def(TQ27); ALL y. In(y, mb) <-> Wfp(TPa(y, mb)) l] ~=> 
ya = ha [ In(ya, mb) <-> Wfp(TEB32(ha, mb, ya)) 
Applying aorIunifies ?eBS2(vO, vl, y) with ?EA40(vt, vO, y) [ ?EB41(vl,vO, y) and 
yields a subgoal for each disjunct. 

13 
I. !!i mmah 
y mb ha ya. 
[[ ALL y. (ALL z. In(z, ma) --> In(z, y)) <-> Wfp(?P(ma, y)); 
Def(?Q27); ALL y. In(y, mb) <-> Wfp(?Pa(y, mb)) I] ==> 
ya = ha <-> Wfp(?EA40(mb, ha, ya)) 
2. !!i m ma h y mb ha ya. 
[l ALL y. (ALL z. In(z, ,,a) --> Ixt(z, y)) <-> Wfp(?F(ma, y)); 
Dsf(?Q27); ALL y. In(y, mb) <-> Wfp(?Pa(y, mb)) [] ==> 
In(ya, rob) <-> Wfp(?EB41(mb, ha, ya)) 
In the first we apply EqInstaz*ce which instantiates ?EA40(vl, vO, y) with y = vo. 
This completes the first goal leaving only the following. 
Def((ALL x y. ?P(x, y) <-> x = [] ~ True I 
(EX vO vl. 
x = vO . vl ~ ?Pa(vO, y) 9 ?P(vl, y))) 9 
(ALL x y. ?Pa(y, x) <-> x = [] 9 False 
(EX vO vl. 
x = vO . vl & (y ffi vO [ ?EB41(vl, vO, y)))) 
I. 
?q27) --> 
(ALL I m. (ALL z. In(z, I) --> In(z, m)) <-> Wfp(?P(l, m))) 
I. !!i m ma h y mb ha ya. 
[] ALL y. (ALL z. In(z, ma) --> In(z, y)) <-> Wfp(?P(ma, y)); 
Def(?Q27); ALL y. In(y, mb) <-> Wfp(?Pa(y, mb)) [] ==> 
In(ya, rob) <-> Wfp(?EB41(mb, ha, ya)) 
We complete the proof by resolving with the induction hypothesis. Isabelle prints 
back the following proven formula with no remaining subgoals. 
[I ALL x. " ?In(x, [3); 
ALL x h t. ?In(x, h . t) <-> x = h [ 7In(x, t) I] ==> 
Def((ALL x y. ?P(x, y) <-> x = [] *' True I 
(EX vO vl. x = vO . vl *' ?Pa(y, vO) 9 ?P(vl, y))) 9 
(ALL x y. ?Pa(x, y) <-> x = [] 9 False [ 
(EX vO vl. x = vO . vl & (y = vO [ ?Pa(vl, y)))) & 
?q) --> 
(ALL 1 m. (ALL z. ?In(z, i) --> ?In(z, m)) <-> Wfp(?P(l, m))) 
Note that the context remains open (?q) as we might have needed to derive ad- 
ditional predicates. Also observe that Isabelle never forced us to give the predicates 
built (?P and ?l'a) concrete names; these were picked automatically during resolution 
when variables were renamed apart by the system. 
The constructed program can be simplified and translated into a GSdel program 
similar to the one in [33]. Alternatively it can be directly translated into the following 
Prolog program. 
p([],Y), 
pa([],Y) 
:- false. 
p([VO]V1],Y) 
:- pa(Y,VO), p(V1,Y), 
pa([VO[V1],VO). 
pa([VO[V1],Y) 
:- pa(V1,Y). 
5 
Conclusion, 
Comparisons, 
and Future 
Work 
The ideas presented here have applicability, of course, outside logic programming 
and Isabelle can be used to derive other calculi for verification and synthesis. [2, 4] 
describes other applications of this methodology. But logic programming seems an 
especially apt domain for such development due to the close relationship between 
the specification and programming language. 

]4 
Other authors have argued that first-order logic is the proper foundation for 
reasoning about and transforming logic programs (e.g., [11, 9]). But there are ben- 
efits to using even richer logics to manipulate first-order, and possibly higher-order, 
specifications. For example, in this paper we used a recursion schema corresponding 
to structural induction over lists. But synthesizing logic programs with more com- 
plicated kinds of recursion (e.g., quick sort) requires general well-founded induction. 
But providing a theory where the user can provide his own well-founded relations 
necessitates formalizing well-foundedness which in turn requires quantifying over 
sets or predicates and, outside of set-theory, this is generally second-order. We are 
currently exploring synthesis based on well-founded induction in higher-order logic. 
Another research direction is exploring other notions of equivalence. Our calculus 
has employed a very simple notion based on provability in a theory with induction 
principles over recursive data-types. There are other notions of equivalence and ways 
of proving equivalence that could be formalized of course. Of particular interest is 
exploring schematic calculi like that proposed by Waldau [31]. Waldau presents a 
calculus for proving the correctness of transformation schemata using intuitionis- 
tic first-order logic. In particular he showed how one can prove the correctness of 
fold-unfold transformations and schemata like those which replace recursion by tail 
recursion. The spirit of this work is similar to our own: transformation schemata 
should be proven correct using formal proofs. It would be interesting to carry out 
the kinds of derivations he suggests in Isabelle and use Isabelle's unification to apply 
his transformation schemata. 
We conclude with a brief comparison of related approaches to program synthesis 
based on unification. This idea can be traced back to [14] who proposed the use of 
res61ution not only for checking answers to queries, but also for synthesizing pro- 
grams and the use of second-order matching by Huet and Lang to apply schematic 
transformations. Work in unification based program synthesis that is closest in spirit 
to what we described here is the work of [20, 21], which used higher-order (pattern) 
unification to synthesize logic programs in a "middle-out" fashion. Indeed, syn- 
thesis with higher-order resolution in Isabelle is very similar as in our work, the 
meta-variable standing in for a program is a second-order pattern and it is only 
unified against second-order patterns during proofi [20, 21] emphasizes, however, 
the automation of such proofs via rippling while we concentrate more on the use 
of logical frameworks to give formal guarantees to the programming logic itselfl Of 
course, these approaches are compatible and can be combined. 
References 
1. David Basin. Isawhelk: Whelk interpreted in lsabelle. Abstract accepted at the llth 
International Conference on Logic Programming (ICLP94). Full version available via 
anonymous ftp to mpi-sb.mpg.de in pub/papers/conferences/Basin-ICLP94.dvi.Z. 
2. David Basin, Alan Bundy, Ina Kraan, and Sean Matthews. A framework for program 
development based on schematic proof. In 7th International Workshop on Software 
Specification and Design, Los Angeles, December 1993. IEEE Computer Society Press. 
3. David Basin and Robert Constable. Metalogical frameworks. In GSrard Huet and Gor- 
don Plotkin, editors, Logical Environments, pages 1-29. Cambridge Urdversity Press, 
1993. 

15 
4. David Basin and Sean Matthews. A conservative extension of first order logic and its 
appfications to theorem proving. In 13th Conference of the Foundations of Software 
Technology and Theoretical Computer Science, pages 151-160, December 1993. 
5. A. Bundy. Tutorial notes; reasoning about logic programs. In G. Comyn, N.E. Fuchs, 
and M.J. Ratcfiffe, editors, Logic programming in action, pages 252-277. Springer 
Verlag, 1992. 
6. A. Bundy, A. Smaill, and G. A. Wiggins. The synthesis of logic programs from induc- 
tive proofs. In J. Lloyd, editor, Computational Logic, pages 135-149. Springer-Verlag, 
1990. Esprit Basic Research Series. Also available from Edinburgh as DAI Re search 
Paper 501. 
7. R.M. Burstall and J. Darlington. A transformation system for developing recursive 
programs. Journal of the Association for Computing Machinery, 24(1):44-67, 1977. 
8. Wei Ngan Chin. 
Automatic Methods for Program Transformation. 
Ph.D. thesis, 
Imperial College Department of Computer Science, March 1990. 
9. K.L. Clark and S-A. T~irnlund. 
A first order theory of data and programs. 
In 
B. Gilchrist, editor, Information Processing, pages 939-944. IFIP, 1977. 
10. K.L. Clark. Predicate logic as a computational formalism. Technical Report TOC 
79/59, Imperial College, 1979. 
11. K.L. Clark and S. Sickel. Predicate Logic: a calculus for deriving programs. 
In 
R. Reddy, editor, Proceedings of IJCAI-77, pages 419-420. IJCAI, 1977. 
12. Pierre Flener and Yves Deville. Towards stepwise, schema-guided synthesis of logic 
programs. In T. Clement and K.-K. Lau, editors, Logic Program Synthesis and Trans- 
formation, pages 46-64. Springer-Verlag, 1991. 
13. Michael J. Gordon, Robin Milner, and Christopher P. Wadsworth. Edinburgh LCF: A 
Mechanized Logic of Computation, volume 78 of Lecture Notes in Computer Science. 
Springer-Verlag, 1979. 
14. Cordell Green. Application of theorem proving to problem solving. In Proceedings of 
the IJCAI-69, pages 219-239, 1969. 
15. Robert Harper, Furio HonseU, and Gordon Plotkin. A framework for defining logics. 
Journal of the Association for Computing Machinery, 40(1):143-184, January 1993. 
16. P. Hill and J. Lloyd. The GSdel Report. Technical Report TR-91-02, Department of 
Computer Science, University of Bristol, March 1991. Revised in September 1991. 
17. C.J. Hogger. Derivation of logic programs. JACM, 28(2):372-392, April 1981. 
18. L..Kott. About a transformation system: A theoretical study. In Proceedings of the 
3rd International Symposium on Programming, pages 232-247, Paris, 1978. 
19. Robert A. Kowalsld. Predicate logic as a programming language. In IFIP-74. North- 
Holland, 1974. 
20. Inn Kraan, David Basin, and Alan Bundy. Logic program synthesis via proof planning. 
In Proceedings of LoPSTr-9~. Springer Verlag, 1992. 
21. Inn Kraan, David Basin, and Alan Bundy. Middle-out reasoning for logic program 
synthesis. In lOth International Conference on Logic Programming (ICLP93), pages 
441-455, Budapest Hungary, 1993. 
22. M.J. Maher. Equivalences of logic programs. In J. Minker, editor, Foundations of 
Deductive Databases and Logic Programming. Morgan Kaufmann, 1987. 
23. Sean Matthews, Alan Smaill, and David Basin. Experience with FSo as a framework 
theory. In GErard Huet and Gordon Plotkin, editors, Logical Environments, pages 
61-82. Cambridge University Press, 1993. 
24. Lawrence C. Paulson. Set theory for verification: I. From foundations to functions. 
Journal of Automated Reasoning. In press; draft available as Report 271, University 
of Cambridge Computer Laboratory. 
25. Lawrence C. Paulson. The foundation of a generic theorem prover. Journal of Auto- 
mated Reasoning, 5:363-397, 1989. 

16 
26. Lawrence C. Paulson. Introduction to Isabelle. Technical Report 280, Cambridge 
University Computer Laboratory, Cambridge, January 1993. 
27. Lawrence C. Paulson. Isabelle's object-logics. Technical Report 286, Cambridge Uni- 
versity Computer Laboratory, Cambridge, February 1993. 
28. Frank Pfenning. Logic programming in the LF logical framework. In Logical Frame- 
works, pages 149 - 181. Cambridge University Press, 1991. 
29. Taisnke Sato. Equivalence-preserving first-order unfold/fold transformation systems. 
Theoretical Computer Science, 105:57-84, 1992. 
30. H. Tamaki and T. Sato. Unfold/fold transformations of logic programs. In Proceedings 
of 2nd ICLP, 1984. 
31. Mattias Waldau. 
Formal validation of transformation schemata. 
In T. Clement 
and K.-K. Lau, editors, Logic Program Synthesis and Transformation, pages 97-110. 
Springer-Verlag, 1991. 
32. Richard W. Weyhrauch. 
Prolegomena to a theory of formal reasoning. Artificial 
Intelligence, 13:133-170, 1980. 
33. Geraint A. Wiggins. Synthesis and transformation of logic programs in the Whelk 
proof development system. In K. R. Apt, editor, Proceedings o] JICSLP-92, 1992. 

AN EXTENDED 
TRANSFORMATION 
SYSTEM FOR CLP PROGRAMS 
N. Bensaou - I. Guessarian 
LITP - Universit~ Paris 6 - email: ig@litp.ibp.fr, bensaou@litp.ibp.fr 
Abstract. We extend the Tamaki-Sato transformation system for logic 
programs into a transformation system for constraint logic programs in- 
cluding fold, unfold, replacement, thinning and fattening, and constraint 
simplifications; we give a direct proof of its correctness. 
1 
INTRODUCTION 
Logic programming has been extended to constraint logic programming to inte- 
grate the resolution of numerical, boolean or set-theoretical constraints together 
with symbolic evaluation methods. Program transformations have been intro- 
duced to improve efficiency of programs; the usual strategy is to first write a 
simple, but may be non efficient program, which can easily be proved correct, 
and to then improve its efficiency by applying to it program transformations 
which preserve correctness. For logic programs, a well-known such system is the 
one introduced by Tamaki-Sato [24], following a methodology first defined by 
Burstall-Darlington [6]; this system has then been improved and generalized in 
e.g. [1, 12, 20]. Other transformation systems have been proposed in different 
frameworks and properties of these transformations, e.g. the associativity of the 
unfolding rule, have been proved in [8]. 
From an operationM viewpoint, it was recently proved in [2] that unfolding 
preserves universal termination and cannot introduce infinite derivations, both 
when it is applied alone or in a "restricted" Tamaki-Sato transformation sequence, 
while in [3] it was proved that the Tamaki-Sato system preserves the acyclity of 
the initial program. 
In the framework of Prolog, transformations preserving the solutions of pro- 
grams together with their computation times are given [21], while in [23] syntac- 
tical conditions have been defined to ensure that the transformations preserve the 
sequence of answer substitutions semantics for Prolog. In [22], an abstract strat- 
egy for automatic transformation of logic programs has been presented. In [14] 
transformation methods involving partial evaluations and designed for a program- 
query pair are studied. In [20] a transformation system for CLP programs with a 
stronger form of correctness is proposed, and finally, a fold/unfold transformation 
system for CLP programs has recently been introduced in [7]. 
Semantics of logic programs and constraint logic programs have been studied 
in [10, 13, 18]. Finally, a survey of the state of the art about constraint logic 
programs can be found in [15]. 
A sequence of program transformations is correct if the final program is equiv- 
alent to the original one, namely the two programs have the same semantics, cf. 
Section 4.1. Usually, we will be given a basic program P, together with new pred- 
icates defined in terms of the predicates of P, and the goal of the program trans- 
formations will be to find direct definitions, more efficiently computable, of these 
new predicates. We will then say that a constraint logic program (CLP program 
in short) has been successfully transformed when the sequence of transforma- 
tions ends with a final program which is equivalent to the original one (and is of 

]8 
course hopefully simpler or better). We here extend the Tamaki-Sato fold/unfold 
program transformations [24] and the transformations proposed in [1], to CLP 
programs. 
In [5] we presented a fold/unfold transformation system for CLP programs and 
proved its correctness with respect to a denotational and an operational semantics. 
The main contributions of the present paper are the following 
1) we improve the fold transformation by making it more general, 
2) we define new transformation rules for CLP programs, namely replacement, 
deletion and addition of redundant clauses and atoms, constraint simplifications, 
and give the conditions under which these transformations are correct. 
The paper is organized as follows: in Section 2, we recall the basic definitions 
about CLP programs and we define the semantics of our programs; we define 
the transformation rules in Section 3, and we finally prove the correctness of the 
proposed transformation system with respect to the defined semantics in Section 
4; technical proofs are given in the appendix. The present paper considerably 
improves [5] where only a fold/unfold transformation was considered, with the 
more restrictive fold of [24]. 
2 
CLP PROGRAMS AND THEIR SEMANTICS 
2.1 
CLP programs 
A CLP program is a set of definite clauses, of the following form: 
p0(t~) , 
pl(t~),...,p,(t:): cl(u~),...,c,n(u~) 
(1) 
where for 0 < i < n, Pi is a predicate symbol, for j = 1, ..., m, cj is a constraint, 
and for k = 1,...,m, i = O,...,n, ~,uk are vectors of terms, n and m can be 
equal to 0. 
In the sequel, clauses will be written in the following form: 
p0(t~) ~ 
pl(t~) : dl,...,p,(t:): 
d, 
(2) 
where for k = 1,...,n, i = 0,...,n, ~ are terms, and dk are constraints. Both 
forms 1 and 2 are equivalent (cf. [5]). 
2.2 
Semantics 
Our semantics is based on the C-models [10, 5]. Along similar lines, a very general 
and elegant semantics has been recently introduced for CLP programs in [13]: it 
uses cylindric algebras as interpretations for CLP programs. We however will 
use here a less general but simpler and more intuitive semantics, based on a 
generalization of the well-known Herbrand interpretations. 
We will consider a language CLP(X), where X is an appropriate constraint 
domain; the semantic interpretation of the domain X is a structure R; R has 
underlying domains, in which variables are assigned values and on which pred- 
icates and functions operate; R will be fixed throughout and will be implicitly 
understood in the sequel. 
The languages CLP(X) have been given both operational semantics, com- 
puted by SLD refutation, and fixpoint semantics, based on immediate consequence 
operators Tp; these semantics have been proved equivalent [15, 11, 5]. We will use 
a fixpoint semantics to prove the correctness of our transformations. We only 
define here the notions of constrained atoms, solvable constraints, and Herbrand 
basis characterizing the semantics. 

19 
Definition 2.1 9 solvable constraint: A constraint c is said to be R-solvable (in 
short solvable), if and only if there exists a valuation O: Vat(c) ~-~ Dn such that 
R ~ O(c). 0 is called a solution of c. 
0 is called a solution of c restricted to the set X, and we write R ~x O(c) if 
and only if there exists a solution O' such that R ~ O'(c) and O[x = O. 
9 preorder on constraints: cl is said to be stronger than c2 if and only if any 
solution of Cl is also a solution of c2; this is denoted by cl ~ 
c2. The induced 
equivalence on constraints is denoted by Cl r162 c2 and is called logical equivalence. 
Let Vat(c1) C_ X U Y and Vat(c2) C X U Y; cl is said to be X-stronger than 
c2 if and only ifVO, R ~x 0(cl) ~ 
R ~x O(c~), this is denoted by ct ~x 
c2. 
~x 
extends ~x 
of[9]. 
9 constrained atom: A constrained atom is a pair p(X) : c where c is a con- 
slraint and p an atom. Two constrained atoms p()~) : c and p(X') : c' are called 
variants [10] iff they are identical up to variable renamings. "to be variants" is 
an equivalence relation denoted by ~-.. A constrained atom p(X) : c is said to be 
solvable if and only if c is solvable. 
Intuitively, a solvable constrained atom represents all possible instanciations of 
p with a valuation 0:A" ~-+ DR which is a solution of c. The "Herbrand Basis" 
.4 will be the set of equivalence classes of constrained atoms modulo ~; the 
equivalence class of p(X) ! c will also be denoted by p(X): c. 
Definition 2.2 clause and atom instance 
A constrained clause (p) A ~ 
A1 : cl,..., A,~ : cn is an instance of a con- 
strained clause (p') B , 
B1 : el,..., B,~ : en if there exists a substitution 0 such 
that: 
O(B) = A , and for i = 1,...,n, 
O(Bi) = Ai , ci ~ 
O(ei) 
(3) 
i.e. the atoms of (p) are (possibly non ground) instanciations of the atoms of (p') 
and the constraints occurring in (p) are stronger than (or equal to) the instanci- 
ations of the corresponding constraints of (p'), namely any solution of ci is also 
a solution of O(ei); thus the application of(p') is valid. 
Similarly, a constrained atom A : c is an instance of a constrained atom B : e 
if there exists a substitution 0 such that: O(B) = A and c is stronger than (or 
equal to) O(e). 
Definition 2.3 * preorder: let.4 be the set of ~ equivalence classes of constrained 
atoms of program P. A preorder E_ is defined on .4 by: (p(.X) : cl) E (p(X) : 
c2) if and only if cl is stronger than c2 9 The induced equivalence on the set of 
constrained atoms is denoted by _~ . 
9 basis: The basis B is the factor set of.,4 by the equivalence relation =_. A 
subset I of 13 is said to be upwards closed if whenever A ~ : c ~ E I, and A : c is an 
instance of A ~ : c' then A : c E I. 
9 interpretation: an interpretation is an upwards closed subset of 13. A con- 
strained atom A : c is true in interpretation I if and only if A : c E I. A con- 
strained clause (p~) B ( 
Bx : el,...,Bn 
: en is true in interpretation I if and 
only if for each instance (see Definition 2.2) (p) A ~ 
Aa : el,..., An: c~ of (p~) 
such that Ai : ci E I for i = 1,...,n 
, (A : Cl A...A 
cn) EI. 
Note that: 1) if p()~') : c' is a variant of p()~) : c, then it is also an instance of 
p()~) : c; if (p(A') : cl) _ (p()~) : c2), then p()~) : cl is an instance ofp()~) : c2. 

20 
2) if I is upwards closed and A : d E I, then I contains all constrained 
atoms A : c _E A : d with constraints c stronger than d, since they are instances 
of A : d (see Definition 2.2). It will be fundamental in our semantics that the 
interpretations be upwards closed. 
The above defined interpretations enable us to give a declarative fixpoint se- 
mantics based on an immediate consequence operator Tp [5]. We will only illus- 
trate this semantics by an example here. 
Example 2.4 Let P be defined on 7] by 
A(z,y) ~ 
A(x,z):z>x,l<y<5 
(4) 
A(x, x) , 
x < 0 
(5) 
A(x,x) ~ 
x >_ 100 
(6) 
A(1, 1), 
(7) 
the semantics of P is defined as follows. 
M(P) ={A(1, 1), A(1, 2), A(1, 3), A(1,4), A(1, 5)} t3 {A(x, x) : x < 0} 
U {A(x,x): x > 100}(3 {A(2, y):l<y< 
5} td {A(3, y):l<y< 
5} 
t./{A(4, y): 1 _< y < 5} U {A(5, y): 1 _< y <_ 5} 
t3 {A(x,y) : x <_ O,l <_ y <_ 5}U {A(x,y) : x >_ lOO, l < y_ 5} 
M(P) contains closed and non closed atoms; for each non closed atom, M(P) also 
contains all instances of that atom: e.g. the atoms A(x, x) : x > 100 A x < 200, 
A(x, x): x >__ 100 A x _< 1000, ..., A(x, x): d(x), with d(x) a constraint stronger 
than x > 100 all are instances of A(x,x) 
: x > 100 E M(P), hence belong to 
M(P). 
[] 
Definition 2.5 1) A conjunction of constrained atoms Aa : Cl A "'" /k An : c,~ is 
said to be satisfiable by P, I if there exists a (not necessarily ground) substitution 
0 such that O(Ai : ci) E Tp(I) for i = 1,...,n 
, and we will write: 
P, It- O(A1 :clA"'AAn:cn) 
Similarly, P t- A1 : cl A 9 9 9 A An : c~ if and only if for every interpretation I, 
I t- P implies I ~- A1 : cl A 9 9 9 A A,~ : c~. 
2) Let P be a constrained logic program. A conjunction of constrained atoms 
A1 : clA...AA~: : ck is said to be equivalent to a conjunction B1 : elA.. "ABm :em 
if for every interpretation I and every substitution O, P, I F O(A1 : clA" 9 .AAk : ck) 
if and only if P, I t- O(B1 : el A... A B,~ : era). 
The notation is: P I~- [A1 : cl A...AAk : ck r 
B~ : e~ A...A B,~ : em] 
Example 2.6 Condition 2) will allow us to move constraints around since for 
any P, P [~- [A1 : cl A ... A Ak : ck r 
A1 : el A ... A Ak : ek], as soon as 
Cl A 9 9 A ck r 
el A 9 9 A ek. See Sections 3.4, 3.10. 
[9 

2] 
3 
THE TRANSFORMATION RULES 
The transformation process consists in applying an arbitrary number of times 
the transformation rules which are: definition, and unfolding as in the Tamaki- 
Sato system [24], folding defined as in Gardner-Sheperdson [12], together with 
replacement, thinning, fattening and pruning. The basic difference between the 
Tamaki-Sato system and the systems of [6, 12, 20] is in folding, which is quite 
special in the Tamaki-Sato system. As folding should preserve total correctness, 
it can never be arbitrary, but must obey some restrictions. Unfolding is always 
totally correct (cf. Corollary 4.7) but arbitrary folding is well known to be only 
partially correct in the absence of constraints, and it is not even partially correct 
for constraint logic programs (cf. Example 3.4). The folding of [12] is however 
both simpler and more general than the one in [24], this is the reason why we 
adopted it. 
Definition clauses introduce new predicates, and the program transformation 
will find a simpler form, e.g. a synthetic form, or a direct recursion, for these 
new predicates; this will decrease the number of recursive calls, hence increase 
program efficiency. 
In the rest of this section, we will define the syntax of the transformation rules. 
Their correctness with respect to the semantics given formally in Section 2.2 will 
be shown in Section 4. 
3.1 
Definition rule 
Introduce a clause of the form 
(6) 
p(xl,x2,...,x,) 
( 
A1 : cl,...,Am : c,~ 
where p is a new predicate name not appearing in P, xl, x2,..., x~ are pairwise 
distinct variables, A1, As,..., Am are predicates appearing in the initial program 
P, cl, c2,..., cm are (possibly empty) constraints. 
The clause (6) is added to P, so that P' = P U {~). This implies that, for each 
given new predicate p, there can be at most one definition clause with head p. 
Example 3.1 Let P be the following program, defining the length of a list and 
the matching of two lists: 
tong(D, X), 
: X = 0 
(8) 
tong([NW],X), 
tong(Y,X'): X = X' + 1 
(9) 
match(D, ]12) ' 
(10) 
match([N1 ]]/1], [N2]Y2])' 
match(Y~, Y2), NI = N2 
(11) 
Let the predicate mtlg define the matching of two lists, such that the length of 
the first list is shorter than the length of the second list; mtlg is defined by: 
mtlg(Y1, ]1"2, X1, X2) , 
match(Y1, Y2), long(Y1, X1): X1 < X2, 
long(Y2, X=) : X1 < X2 
(12) 

22 
3.2 
Unfolding rule 
Let (p) be a clause in the program P. 
(p) 
A, 
A1 : cx,...,Aq : cq,...,An : cn 
Let (rrk), for k = 1,..., m, be allthe clauses in P whose head can be unified with 
Aq: 
(~) 
T~ , 
T~l : c'~,...,T,~ : c~ 
The unfolding of (p) by these m clauses at the constraint atom (Aq : Q) is 
obtained by unifying A a with each of the Tk's. 
Let the substitution #~ (k = 1,...,m) be an m.g.u, of A a and Tk, hence: 
Izk(Aa) =/zk(Tk) and substitute for/~k(Aq : Ca) 
' 
... Tkj: 
]Ak(Tkl : C 1 /k Ca, 
, 
c~ /k Ca) , 
for k = 1,..., m. Let now clauses (l-k) be defined by, for k = 1 .... , m: 
(rk) 
#~(A), 
#k(A1 :Cl,...,Aq-1 :Ca-l,Tkl :(Ctl/kcq),.. . , 
Tkj : (c~ A ca),Aq+l : ca+x,..., An: cn) 
clause (p) is replaced by the set of clauses (rk), for m > k > 1,and P' = (P - 
{p}) u {~1,..., ~}. 
Note that after an unfolding, the constraints can fail to be distributed properly 
(i.e. constraints involving a variable X should be affected to atoms involving the 
variable X, of. [5]) among the atoms in the body of the unfolded rule, but this 
does not affect the correctness of our transformation. 
Example 3.2 (3.1 continued) Unfolding clause 12 at its first atom results in two 
new clauses 
a) unfolding with clause 10 we obtain: 
mtlg(~, y~, xx , 12), 
long(D, Xl) :Xx < X2, 
long(Y2, X~) : X1 < X2 
(13) 
b) unfolding with clause 11 we obtain: 
mtlg([N1 IY1], [N2 IY2], X1, X2) , 
match(Y1, Y2), N1 = N2, 
long([Yl IY1], X1): X1 < X2, long([N2 [Y2], X2): X1 < X2 
(14) 
Unfolding 13 at its first predicate once and simplifying we obtain: 
r~tZg(D, Y~, xx, x~) , 
tong(Y~, x~) : o = xl < x~ 
(15) 
unfolding 14 twice we obtain: 
mtlg([Ul [Y1], [N2]Y2], X1, X2)( 
Nx = N2, match(Y1, Y2), 
to.g(Yx, xl): (xx = x~ + 1, x~ < x~), 
long(Y2, X~): (X2 = X~ + 1, X~ < X~) 
(16) 
Finally clause 12 is replaced by clause 15 and clause 16. 

23 
3.3 
Folding rule 
Let (p) and (6) be clauses in the program P: 
(p) 
A ~ 
A1 : c1,..., Aq : Cq, Aq+l : Cq+l,..., Aq+r : Cq+r,..., An : Cn 
l 
Br : 
l 
(6) 
B r 
B1 :cl,..., 
c r 
and # a substitution such that the following conditions hold: 
1. Vj = 1,..., r, Aq+ i = #(Bj) 
and moreover (cf. Definition 2.1) 
Vj = 1,...,r 
(eq+j ~ 
p(c~.)) 
(17) 
2. (6) is the only clause in P whose head unifies with #(S). 
3. # substitutes distinct variables for the internal variables of (6), and these vari- 
ables do not occur in the head predicate A of (p), nor in the {A1 : cl,..., Aq : 
cq} O {Aq+~+l : eq+r+l,...,An : cn}, nor in #(B) : eq+l A...Acq+~. 
Recall that a variable Y is said to be internal to a clause (6) if Y occurs only in 
the body of (6) and Y does not occur in its head. 
The folding of (p) by (6) at the subset {Aq+l : Cq+l,..., Aq+~ : Cq+~} is the 
clause (v) which will replace (p): 
(r) 
A~ 
A1 : cl,...,Aq: eq,p(B): Cq+l A...A eq+~, 
Aq+r+l 
: CqWr+l, 9 9 9 An 
: en 
(p) is called the folded rule and (6) is called the folder. Note that conditions 1., 
2. and 3. are needed in order to insure the correctness of the transformation (see 
[5, 12]). 
Finally e' = (P-{p})u 
{r}, and P' is equivalent to P. The folding considered 
here is the inverse of the unfolding rule as in [12]; it is more general than the folding 
of [24, 5], and its correctness proof is much easier. 
Example 3.3 (3.2 continued) Folding 16 by 12 gives: 
(7") mtlg([N1 []I1], [N21Y2], X1, X2) 
~ 
N1 = N2, 
mtlg(Y1, Y2, X~, X~) (.X1 = X I + 1, X2 = X~ + 1, X~ < X~) 
Example 3.4 This example shows that arbitrary folding not taking into proper 
account the constraints is not even partially correct. Let P 
(p) 4x, v), 
(6) p(X,V), 
(cr) p(X,Y), 
Folding (p) by (6) gives PI: 
(~) ~(x,r), 
(6) p(X,Y), 
(or) p(X,Y), 
q(X, Z) , q(Z,Y) : Y > 0 
q(X,Z) , q(Z,Y) : Y > 100 
r(X,Y) :Y > 0 
p(X, Y): v > 0 
q(X,Z), q(Z,Y): Y > 100 
r(X,Y) :Y > 0 
which is no longer equivalent to P, and is not even partially correct since according 
to P, s is defined as soon as q(X, Z), q(Z, Y) and Y > 0, while according to P1, 
s is defined as soon as q(X, Z) , q(Z, Y) and Y > 100 or r(X, Y) and Y > 0. 

24 
3.4 
Substitution rule 
Let P be a logic program and (p) a clause in P: 
(p) 
A( 
Al:cl,...,A~:ck,...,An:ca 
such that the following equivalence holds (cf. Definition 2.5, 3.): 
P IF-A~ : c~ A ... A Ak : ck <:~ B1 : el A ... A Bm: era. 
Using this equivalence we can replace the conjunction A1 : Cl A -.. A Ak : ck by 
the conjunction B1 : el A .-. A Bm: em and we will obtain the clause 
(p') 
A( 
B1 :el,...,Bm:e,~,Ak+l:ek+l,...,An:cn 
and the program P' : (P - {p}) U {p'} will be equivalent ~to P. 
The substitution rule seems quite restrictive, it is however useful in optimizing 
the number of transformation steps, and also for proving the correctness of folding 
and of moving constraints around. 
3.5 
Replacement rule 
Let P be a logic program and (p) a clause in P: 
(p) 
A ~- A1 : ci,...,Ak : ck,...,An : cn 
assume that the following conditons 1) and 2) hold (cf. Definition 2.5): 
1) P F- O(A1 : Cl A...A Ak : ck) implies P-(p) 
F- O'(B1 : el A...A Brn : era)for 
some 0' such that 0 and 0 ~ agree on all the variables of A, Ak+l : Ck+l,...,An : Cn, 
and 0(cl A... A ck) ~ 
0'(el A... A era), 
2) P e 0(B1 : el 
: 
implies P- (p) e O'(A1 : el A...AA, 
: ck) for 
some 0' such that 0 and 0' agree on all the variables of A, Ak+l : Ck+l,..., An : cn, 
and 0(el A...A era) ~ 
0'(cl A...Ack). 
Using these conditions we can replace the conjunction A1 : Cl A ... A Ak : ck 
by the conjunction B1 : el A ..- A Bm : e,~, we will obtain the clause 
(p') 
A, 
B1 :el,...,Bm :e,~,Ak+l :ck+l,...,An :Cn 
and the program P' = (P - {p}) O {p'} will be equivalent to P. 
This corresponds to the notions of sub-molecule, rule-subsumption and re- 
placement of [20]: there is however a difference with the replacement rule of [20], 
namely: our notion of replacement which is taken from [12], where it is called per- 
missible goal replacement, is more liberal (Maher's rule requires that none of the 
predicates of A1, 9 9 Ak, B1, 9 9 B,~ depend on the predicate of A, hence implies 
an implicit stratification of the program). There are cases when our replacement 
rule applies and not Maher's (cf. Example 3.5). Thinning and fattening can be 
viewed as particular cases of this rule [24, 1]. 
Example 3.5 Let P be the program 
p(X,X) 
( 
q(Y) , p(X,Y) 
: Y > 100 
p(X,Y), 
r(Y): Y > 100 
q(r), 
r(Y): Y > 100 
Then, according to our rule 
P ~ [(q(Y), p(X,Y): Y > 100) r 
(q(Y): Y > 100)] 
Hence the first rule can be simplified into p(X, X) ( 
q(Y) : Y > 100. Maher's 
replacement rule cannot be applied here because the predicate p occurs in the 
replaced conjunction. 

25 
3.6 
Elimination of redundant atoms: thinning 
This transformation enables us to suppress some useless constrained atoms in 
clause bodies (cf. thinning of [1]). Let (p) be the clause: 
(p) 
A *--- A1 : cl,...,Ai-1 
: ci-l,Ai : ci,Ai+l : ci+l,...,An : cn 
If there exists in P a clause (r) such that, for instance, 
(~) 
B( 
A~ : c~,...,A~_l: c~_ 1 
and a substitution 0 verifying: 
Ai=O(B) , 
and for j= 1,...,i-i, 
for j = l,...,i-1, 
c~ = 0(cl) ^... ^ O(e;_l) 
Aj = 0(Ai), 
c~ ~ 
0(el), 
(18) 
(19) 
this implies that Ai : ci ( 
A1 : c1,..., Ai-1 : ci-1 is an instance of (~). Let the 
internal variables of (~r) be those variables which occur in the body of (~r) and do 
not occur in the head of (r). If 
1. 0 substitutes distinct variables for the internal variables of (~r), and these vari- 
ables do not occur in the head predicate A of(p), nor in the {A1 : cl,..., Ai-1 : 
ci-1} U {Ai+l : Ci+l,...,An : Cn}. 
Then we can substitute for clause (p) the clause (p'): 
(p') 
A, 
At : Cl,...,Ai-1 
: Ci-l,Ai+l : ci+l,...,An : c, 
henceforth P' = (P - {p}) U {p'} and P' is equivalent to P. 
Thinning can be viewed as a particular case of replacement: 
Example 3.6 Let (p) be clause 20 and (Tr) be clause 21 in the following program 
P: 
r(X), 
q(x):x> 
p(x), 
q(X):X> 
p(x) ~- s(X) 
The atom p(X) can be deleted from 
program P': 
?/:- 
p' : pX 
pX 
Maher's replacement rule could also 
100, p(X): X > 100, t(X) 
(20) 
100 
(21) 
(22) 
the first clause 20. We obtain the equivalent 
qIXI:X>IO0, 
t(X) 
--qX 
:X> 
100 
sX 
have been applied here. 
Example 3.7 This example shows the necessity for condition 19, i.e. the con- 
junction of constraints of the clause r must be equivalent to the constraint of the 
redundant atom, namely ci: 
r(X) ~-- q(X): X > 100, p(X): X > O, t(X) 
p(X) ~-- q(X): X > 200 
p(X) ~-- s(X) 
q(x) ~- 
In this case, we cannot suppress p(X) from the first clause. 

26 
Example 3.8 This counter example shows the need for condition 1. concerning 
internal variables of the clause (~'): 
r(x), 
q(y): x > 100, ,(x): x > 100 
p(x) , 
q(y) 
q(X) , 
Deleting p(X) : X > 100 from the first clause would result in the program: 
r(X) , 
q(Y): X > 100 
,(X) , 
q(r) 
q(x) 
which is different from the original program and equivalent to 
r(X), 
q(Y):X > 100, p(Z) 
p(X) , 
q(Y) 
q(X) , 
Remark 3.9 If the applicability conditions of fold are satisfied, i.e. if Or) is a 
definition clause, then a better simplification will be achieved by first folding (p) 
by Or), then merging the two remaining atoms in the body of the folded clause 
into a single atom; i.e. the folded clause being: 
A( 
Ai: ci, 0(B): e(cl A.../x c~), Ai+l: Ci+l,..., A,~: c,~ 
with Ai = O(B) , and ci = O(cl) A . . . A O(c~), the simplified clause is 
A, 
Ai : ci~Ai+l : Ci+l,...,An 
: c,. 
In an application strategy of these rules, we will consider that in such a case 
folding has precedence over redundance elimination. 
3.7 
Introduction of a redundant atom in a clause body: fattening 
It is the inverse of the previous operation (cf. [1]). Let (p) 
A ~-- A1 : Cl,...,Ai : 
ci,Ai+l 
: Ci+l,...,An : cn assume there exists in P a clause (Tr) B ~ 
B1 : 
el,..., 
Bi : ei and a substitution 0 such that: 
Aj 
= 
O( Bj ) for j = l, . . . , i 
cj ~ 
O(ej) for j = 1,...,i 
and Aj:I ..... i cj --~ c = Aj=I ..... ~ O(ej ), then we can substitute (p') for (p): 
(p') 
A, 
Al : cl,...,A,~ 
: cn,O(B) : c 
P' = (P - {p}) U (p'} is equivalent to P. 
For instance, in Example 3.6, P can be obtained by fattening from PL 

27 
3.8 
Suppressing useless (redundant) 
clauses: generalized pruning 
A program can be simplified by suppressing its useless clauses, namely clauses 
which are subsumed by other clauses (cf. generalized pruning of [1]). 
Let P be a program containing a clause (p). The clause (p) is said to be 
redundant if the set of atoms that it can produce is contained in the set of atoms 
produced by P - {p). Such a clause cannot add any atom to the model of the 
program. A sufficient applicability condition is to check whether all the atoms 
produced by clause (p) are already in Tp_{p} T w. 
Namely, letting P be a program containing clauses: 
(p) 
A ~-- A1 : cl,...,An : c, 
and 
(r) 
B ~ 
B1 : el,...,Bm :em with m < n 
and such that there exists a substitution 0 verifying: A = 0(B), A~ = 0(B~), and 
ci ~ 
O(ei), for i -- 1,..., m, i.e.: (p) contains as a subset in its body an instance 
of (r), then (p) is a redundant clause and can be deleted, and P' = P - {p} is 
equivalent to P. 
Example 3.10 Let P be the program: 
(p) 
y) 
r(y) :x = y+ 1, z = y- 1,y-- 5; 
q(x):x=y+ 
l,z=y-l,x>O 
q(x) : x = y+ 1, z = y- 
1 
(23) 
(24) 
We can also simplify a program by deleting clauses which can never be applied 
because they contain an inconsistance in their body or are inconsistant with the 
rest of the program. Let (p) 
A *-- A1 : Cl,..., An : Cn be a clause of P. If the 
conjunction of constrained atoms in the body of (p) is unsatisfiable, the clause 
(p) can then be deleted, and P~ = P - {p} is equivalent to P. 
3.9 
Suppression of clauses which can never be used 
y) 
q(x) 
r(U) 
Clause 23 contains an instance of clause 24, hence can be deleted. 
Remark 3.11 A particular case of this simplification takes place when rn = n. 
Then clause (p) is redundant, and it is an instance of clause (r) (cf. Definition 
2.2). Hence every clause which is an instance of another clause can be deleted. 
Example 3.12 Let P be the program: 
p(X) , 
X = V 
p(X) ( 
X ~- a 
(25) 
Clause (25) is redundant and can be deleted. P is equivalent to P~: 
p(x) , 
x = Y 

28 
3.10 
Constraint simplifications 
Equivalent constraints : 
We can replace a clause by another clause whose constraints are equivalent to 
the constraints of the first clause. 
Let (p) be the clause: (p) A ( 
A1 : cl,'",An 
: cn and assume that 
Ai=I ..... nci ~ 
Ai=I ..... nei. Then we can replace (p) by (pl) 
(p') 
A, 
Al : el,...,An 
: en 
It is a particular case of the substitution rule since clearly 
PIP (AI: el,-", Zk: ck) ~ 
(B1 : el,..., Bin: e,~) 
is satisfied with k = m = n, and, for i = 1,..., m, Ai = Bi; the set of constrained 
atoms Ak+l : Ck+l,...,An : cn in (p) is empty. 
Hence P' = (P - {p}) U {p'} is equivalent to P. 
A particular case of the previous simplification is when for i = 1,..., m, ci r 
ei and ei is a simplified form of ci. 
Eliminating intermediate variables in constraints : 
An intermediate variable in a clause, is a variable occurring in the body but 
not the head of the clause. Such variables can be deleted if they occur only in the 
constraints and not in the atoms of the body of the rule, we will say in such a 
case that the intermediate variable is a local variable. However, we will no longer 
have correctness, i.e. the simplified program can possibly have more solutions than 
the original program, so we can only hope for a notion of weak correctness. The 
notion of weak satisfaction of constraints (cf. [9]), see Definition 2.1, enables us 
to express solvability of constraints while deleting intermediate local variables. 
Let X U Y be the variables of the clause, X being the set of variables occurring 
either in the head or in the atoms of the body, hereafter called global variables, 
and Y the set of variables occurring only in constraints called intermediate local 
variables; 0 is said to satisfy the constraint c on the global variables X if and only 
if there exists a solution 0' of c on (X U Y) such that 01x = 0. We can simplify 
the original constraint by deleting the constraints on local intermediate variables 
and will obtain as simplified constraint the projection of the original constraint 
on the global variables. 
Proposition 3.13 Let P contain clause (p) 
A ( 
A1 : Cl,...,An 
: Cn. Let 
i where 
' = CilX for i = 1,. 
n. Let P' - 
(p') 
A , .... 
A1 : c~,...,An 
: cn 
c i 
.., 
- 
(P - {p}) U {p'}. Then M(P) C M(P'). 
However this result is not very interesting, in that it does not even imply 
partial correctness; henceforth, in order to obtain correctness, we must take a 
weaker semantics and assume the stronger hypotheses which are given below. If 
in addition the following holds (cf. Definition 2.1) 
! 
ci =::~x ci for i = 1,..., n 
' 
~ clause (p') will be weakly equivalent 
then, since c i = cqx implies that ci ~ 
ci, 
to clause (p) and P'= (P - {p}) U {p'} will be weakly equivalent to P. 
Example 3.14 (p) Q(u, v) ~-- T(u): v = u + 3, x > u, y = u + v. 
The constraints are {v = u + 3, x > u, y = u + v}; since e.g. on the reals or 
the integers {v = u + 3} ::::::~u,v {v = u + 3, x > u, y = u + v}, x and y are local 
intermediate variables which can be deleted; take for instance {x = u + 1} and 
the constraint {x > u} will be satisfied. We can substitute for (p) the clause (p~): 
(p') 
Q(u, v) , 
T(u):v=u+3. 

29 
4 
CORRECTNESS OF THE TRANSFORMATION SYSTEM 
The program transformation consists in applying to a program P together with 
a set of definitions D, the transformation rules. The result is another program 
Tr(P). If a transformation preserves program equivalence with respect to a given 
semantics Sam, i.e. Sem(Tr(P)) = Sem(P U D) then the transformation is said 
to be totally correct. It is said to be partially correct if Sem(Tr(P)) C Sem(P U 
D). The system proposed by Burstall and Darlington [6] preserves only partial 
correctness of programs. The system of Tamaki-Sato was proved totally correct 
with respect to the least Herbrand model semantics [24] and with respect to the 
computed answer substitution semantics [16]. In [1], this system was also proved 
correct with respect to the S-semantics of [10]. 
All the rules of the system proposed in the previous section except for the 
elimination of intermediate variables, are correct with respect to a fixpoint se- 
mantics inspired from the usual semantics of [15] and [17], from the C-semantics 
of [10], and based on a notion of model in a Herbrand Universe with variables. 
Our proof method is inspired by the proof of Tamaki and Sato [24] but is much 
simpler. 
4.1 
Correctness of the transformation system 
Proposition 4.1 If P is transformed into P' via one unfold transformation, then 
M(P) = M(P'). 
Proposition 4.1 is proved in [5]. See also Lemma 6.4 of [20]. 
Proposition 4.1 showed that unfold transformations preserve total correctness. 
Conversely, the following lamina shows that the fold transformation can be viewed 
as the inverse of the unfold transformation, hence is also correct. 
Lamina 4.2 If P is transformed into P' via a fold transformation, then, P' can 
be transformed into P via an unfold transformation followed by a substitution rule. 
Correctness of the fold transformation then follows from the correctness of unfold 
and substitution (Propositions 4.1 and 4.4). 
Proposition 4.3 If P is transformed into pi by applying a fold transformation 
rule, then M(P) = i(P'). 
Proposition 4.4 If P results in P' by applying the substitution rule, then M(P) = 
M(P'). 
Proposition 4.5 1) If P results in P' by applying the replacement rule, then 
(i) if only condition 1) of the replacement rule is satisfied, then M(P) C 
M(P'); 
(it) if only condition 2) of the replacement rule is satisfied, then M(P') C 
M(P), i.e. the replacement rule with only condition 2) is partially correct. 
2) If P results in P' by applying the replacement rule, with both conditions 1) 
and 2) satisfied, then M(P) = M(P ~) and P' is equivalent to P. 
Proposition 4.6 If P results in P' by applying thinning (suppressing a redundant 
atom), fattening (adding a redundant atom), or generalized pruning, then M(P) = 
M(P'). 

30 
Corollary 4.7 If P is transformed into P~ via a transformationS, with ~ among 
unfold, replacement, thinning, fattening or generalized pruning, then M(P) = 
M(P'). 
Corollary 4.7, even though it may seem trivial, gives a very useful tool for checking 
the correctness of potential transformation rules. 
Corollary 4.8 Let T~' be a transformation rule, let P~ = Td~(P) be the result 
of applying transformation Tr to P, then Tr is correct if and only if M(P) =- 
M(Ti(P')), where Ti(P') is a suitable transformation of P' = Ti(P), chosen among 
unfold, replacement, thinning, fattening or generalized pruning. 
Proof: Since 7~ is correct, M(P') = M(7~(P')); 7U is correct if and only if M(P) =- 
M(P'), and this is equivalent to M(P) = M(T~(P')). 
[] 
4.2 
Weak correctness of the elimination of intermediate variables in 
constraints 
We define a weaker semantics of a program P by taking into account the solvability 
of constraints. 
Definition 4.9 Let X be the global variables of P and Y its intermediate local 
variables and let I C 13 be an interpretation; the immediate consequence operator 
Tp, s is defined as follows A : c is an immediate consequence of P, I if and only 
if there exists an instance (cf. Definition 2.2} (p) A ( 
A1 : ci,..., An : c~ of a 
clausc(p')B( 
B1:el,...,B~:e~ofP, 
thereexistAi:diEIfori=l,...,n, 
such that ci ~x 
di for i = 1,..., n, and c .'. '.'x cl A. 9 9 A c, is solvable. Let 
Ms(P) be defined as the least fixpoint of Tp,s Ms(P) = lfv(Tp, s) = Tp, s T w. 
Proposition 4.10 Assume that 
(p) 
A *--- A1 : cl,...,Am 
: c, 
(p') 
A ~-- AI : cI1,...,A~ : % 
If P is tranformed in P' = ( P-{p} )U{p'} by deleting some intermediate local vari- 
ables in (p), and moreover c~ ~x 
cl for i= 1,...,n, then Ms(P) = Ms(P'). 
5 
CONCLUSION 
We gave in this paper a transformation system for CLP programs and proved 
its correctness. This system is an extension of the Tamaki-Sato system to CLP 
programs; it includes fold, unfold, replacement, thinning and fattening, pruning 
and constraint simplifications; its correctness proof, which is based on the Tp 
operator, is simpler than the Tamaki-Sato proof; this simplicity stems from the 
naturalness of the Te operator. Our formalism is a very natural extension of the 
Logic Programming methods to the CLP case, and it immediately gives back the 
results known in Logic Programming when the constraints are empty. 
A general transformation system for CLP programs with a more restrictive and 
more syntactic fold has been studied in [20], and a fold/unfold transformation 
system for CLP programs with again a more restrictive fold has been recently 
introduced by [7]: this last system was proven correct with respect to the f2- 
semantics, which has the liability of being very strong (few programs will be 
equivalent, e.g. programs P and P~ of Example 3.12 are not equivalent with respect 
to the I2-semantics) but the asset of being modular. 

31 
We prove for all transformations except constraint simplifications the strongest 
form of correctness from which one can deduce simply other equivalences with re- 
spect to weaker semantics; we thus conserve the advantage of proposing a simple 
and practical tool for automatic transformation systems. For constrMnt simplifica- 
tion however, we can only prove a weaker form of correctness taking into account 
the solvability of constraints. 
Acknowledgments: We thank the referees and A. Na'it Abdallah for insightful 
comments. 
References 
1. A.Bossi; N.Cocco. Basic transformation operations which preserve answer substitu- 
tions of logic programs, Journal of logic programming, Vol. 16, 1993, 47-87. 
2. A.Bossi; N.Cocco. Preserving universal termination through unfold/fold, Proceed- 
ings ALP'9~, to appear. 
3. A.Bossi; S.Etalle. Transforming Acyclic Programs, ACM Transactions on Program- 
ming Languages and Systems, to appear 1994. 
4. A. Bossi; N. Cocco; S. Dulli. A method for specializing logic programs, ACM Trans. 
on programming langages and systems, Vol.12, 2, April 1990, 253-302. 
5. N. Bensaou; I. Guessarian. Transforming constraint logic programs, 11 th Syrup. on 
Theoretical Aspects of Computer Science, LNCS 775, 1994, 33-46. 
6. R.M. Burstall; J. Darlington. A transformation system for deriving recursive pro- 
grams, J. ACM, Vol. 24, 1, 1977, 44-67. 
7. S. Etalle; M. Gabrielli. Modular transformations of CLP programs. Proc. GULP- 
PRODE 1994, to appear. 
8. F. Denis; J.P. Delahaye. Unfolding, procedural and fixpoint semantics of logic pro- 
grams, Proc. STACS'1991, LNCS 480, 1991, 511-522. 
9. S.V. Denneheuvel; K.L. Kwast. Weak equivalence for constraint sets, IJCAI, 1991, 
851-856. 
10. M. Falaschi; G. Levi; M. Martelli; C. Palamidessi. 
Declarative Modeling of the 
Operational Behavior of Logic Languages, Theoretical Computer Science 69 , 1989, 
289-318. 
11. M Gabbrielli ; G. Levi. Modeling answer constraints in Constraint Logic Programs, 
Proc. eight int. conf. on Logic Programming, eds. Koichi &= Furukawa, 1991, 238-252. 
12. P.A. Gardner; J.C. Sheperdson. 
Unfold/fold transformations of logic programs, 
Computational logic, essays in honor of Alan Robinson, MIT Press, London, 1991, 
565-583. 
13. R. Giacobazzi; S.K. Debray; G. Levi. A generalized semantics for constraint logic 
programs, Proc. Int. Conf. on Fifth Gen. Computer Systems, Tokyo, 1992, 581-591. 
14. T.J. Hickey; D.A. Smith. Toward the partial evaluation of CLP languages, Proc. 
PEPM'91, ACM-SIGPLAN Notices Vol. 26, 9, 1991, 43-51. 
15. J. Jaffar; M.J. Maher. Constraint logic programming: a survey, to appear in J. 
Logic Programming. 
16. T.Kawamura; T.Kanamori. Presrvation of stronger equivalence in unfold/fold logic 
program transformation, Proc. lntern. Conf. on FGCS, Tokyo (1988), 413-421. 
17. P. Kanellakis; G. Kuper; P. Revesz. Constraint Query Languages, Tech. report, 
Department of Computer Science, Brown university, November 1990. 
18. G. Levi. Models, unfolding rules and fixpoint semantics, Proc. of the fifth interna- 
tional conf. on Logic programming, 1988, 1649-1665. 
19. M.]. Maher. Correctness of a logic program transformation system, IBM Research 
Report RC 13496, T.J. Watson Research center, 1987. 
20. M.J. Maher. A transformation system for deductive database modules with perfect 
model semantics, Theoretical Computer Science 110, 1993, 377-403. 
21. A. Parrain; P. Devienne; P. Lebegue. Techniques de transformations de programmes 
g~n~raux et validation de meta-interpr~teurs, BIGRE 1991. 
22. M. Proietti; A. Pettorossi. An abstract strategy for transforming logic programs, 
Fundamenta Informaticae, Vol. 18, 1993, 267-286. 
23. M. Proietti; A. Pettorossi. Semantics preserving transformation rules for Prolog, 
Proc. PEPM'91, ACM-SIGPLAN Notices Vol. 26, 9, 1991, 274-284. 

32 
24. H. Tamald; T. Sato. Unfold/Fold transformation of logic programs, Proc. 2nd logic 
programming conference, Uppsala, Sweden, 1984. 
6 
APPENDIX: 
TECHNICAL 
PROOFS 
Definition 6.1 Immediate consequence operator Tp - Let P be a CLP program and 
I C 13 be an interpretation; a constrained atom A : c is an immediate consequence of P, I 
if and only if there exists an instance (cf. Definition 2.2) (p) A ~-- A1 : cl,..., A, : cn 
of a clause (p~) B ~-- B1 : el .... ,B, : e, of P such that Ai : ci E I for i = 1,...,n, 
and c = cl A ... A en. Let Tp(I) denote the set of immediate consequences of P,I, and 
7~p(z) = {A: 
c I A: c is an instance ofA' : c' e Tp(I)} 
denote the upwards closure o] 
the set of immediate consequences o] P, I. 
Proof of Proposition 3.13 Recall that (p) 
A ~-- A~ : cl,...,A,~ : cn (p') 
A 
! 
I 
A~ : c~,..., An : c~ and P' = P - {p} U {p'}. Note that c i = cilx implies that ci ~ 
c~, 
hence (p) is an instance of (p'). 
By induction on k we check that T~(r 
C T~,(r 
for all k E IN. 
It is clear for k = 0. Assume it holds for k, i.e. Ik = T~(0) C_ T~,(0) = ]~, and let 
A': c' E Tp 
TM (0): we check that A': c' E Tp k+1(0). 
a) IRA': c' is obtained by instanciating a clause in P - {p}, then A': c' E Tp,(I~). 
b) If A': c' is obtained by an instance 0' of (p), then 30'(A~ : cl),... ,O'(An: c,~) EIk 
such that 8'(A: c) = A' : c' E Tp(Ik). Hence O'(Aj : cj) E Ik C I~, for j = 1 ..... n. 
But O'(Aj: cj), for j ---- 1 .... , n, is an instance of o'(mj: c'j), hence by 6.1, rule (p') 
can be appfied and O'(A : c) E Tp,(I~). 
[] 
Proof of Proposition 4.1 See [5]. 
[-1 
Proof of Lemma 4.2 Recall that 
(p) 
A~----A~ :cl,...,Aq 
:cq, AqÂ§ :Cq+l,...,Aq+~ :Cq+~,Aq+~+l :cq+~+l,...,An :c~ 
t 
! 
(~) 
B *--- 
B1 : cl ..... B~ : c~ 
(r) 
A ~ 
A1 : el,..., Aq : Cq, It(B) : Cq+l A... A Cq+~, Aq+r+l : Cq+r+l ..... A~ : c~ 
and P~ = (P - {p}) U {r}. We will show that P can be retrieved from P~ by unfolding 
and substitution; the correctness of folding will follow from the correctness of unfolding 
and substitution. 
Let us try to unfold (7-) at the atom #(B) in P~. Indeed, since (~f) is the only clause 
in P whose head is unifiable with #(B) and since the heads of the clauses in P~ are the 
same as the heads of the clauses in P, (~) is also the only clause in P~ whose head is 
unifiable with #(B), and (r) can only be unfolded by (8). Assuming B = B(X1,..., X~), 
0 defined by O(Xi) = /z(X~) for i = 1,..., n is clearly a most general unifier of B and 
It(B). Because of the condition 2. of folding, ( It substitutes distinct variables for the 
internal variables of (8), and these variables do not occur in (r)), 0 can be extended to 
all the variables of (r) U (8) by letting 
y.(y), 
if y is an internal variable of 
0(y) 
l y. 
if y is a variable of (7-). 
Hence, letting c = Cq+~ A ... A eq+~ and unfolding (r) at It(B) : c with most general 
unifier 0 results in (pl) 
(p') 
O(A ~-- A~: cl,...,&: 
c~, B~ : c A c~ .... , B,: c ^ c',, 
Aq+~+l : cq+~+l, 9 9 9 An : c,~) 
! 
(p') 
A~--- 
Aa :ca,...,Aq:cq,#(Ba):cAIt(c~),...,it(B,):cA#(c',), 
Aq+r+l : Cq+r+l ~ 9 9 9 ~ A~ : c.) 
(p') 
A~---- 
Al:cl,...,Aq:cq, 
Aq+l:cAit(c~) .... ,Aq+~:cAIt(c'~), 
Aq+r+l : Cq+r+l, 
. 9 9 ~ An : Cn) 

33 
since by the condition 1. of the folding rule (see imphcation 17), for j = 1,..., r, cq+j ==~ 
#(c'j), we also have c ===~ #(c~) for j = 1,:.., r and (p') can be replaced by 
(p") A+---A1 :Cl,...,Aq :cq, Aq+l :c,...,Aq+r :c, Aq+r+l : Cq+r+l,...,An :Cn 
it is now immediate by the substitution rule that (p") can be replaced by (p) (cf. Section 
3.10). 
[] 
Proof of Proposition 4.4 Let P, (p) and (p') be such that 
(p) 
A ~---- Al : cl,...,Ak 
: ck,...,A,~ : c,~ 
P 
H- [A, : Cl A... A Ak: ck r 
Ba : ea A.-- A Bin: em] 
(26) 
(p') 
A ~---- Bl : ea,...,B,n : e,n,Ak+l : ck+l ..... An:cn 
and let P' = P - {p} O {p'}. P' is equivalent to P, i.e. M(P) = M(P'). 
Let I, = T~(0) and T~,(0) = I': we prove by induction on n that I~ = I" for all n. 
The base case is clear. Let us check the inductive step: assume In = I" and let 
O(A' : c') E T~(I,) = I,+a; 
- 
if O(A' : c') is obtained by applying a rule in P - {p}, the inductive step is clear; 
- if O(A' : c') is obtained by applying the rule (p), then 8(A1 : ca A.-.AAk : ck) 9 In = 
Tp(In-'a); by 26, (cf. Definition 2.5), O(Ba : el A...ABm 
: era) 9 In and by the induction 
hypothesis 0(8a : el A 9 .. A Bin: era) 9 I', hence O(A' : c') 9 Tp, (Fn) = I~+a' 
. 
[] 
Proof of Proposition 4.5 2) clearly follows from 1) (i) and (ii). So, let us prove 1). 
Let P, (p) and (p') be such that 
(p) 
A *-- Aa : ca,...,A~ : ck ..... An : c,~ 
(p') 
A ~---- Ba :el .... ,Bm:em, Ak+l :Ck+l,...,A~ :cn 
and let P' = P- 
{p} U {p'}. 
Let us first prove 1) (i); assume that condition 1) of the replacement rule, which we 
recall below, is satisfied. 
1) P ~- /?(A1 : cl A... A A~ : ck) implies P- 
(p) F- O'(Ba : el A--- A B,~ : era) for 
some 0' such that 0 and/?' agree on all the variables of A, Ak+I : ck+a,... ,An : c,,, and 
/?(cl ^... ^ ck) ~/?'(~1 ^... ^ ~), 
Let us then show that M(P) C M(P'). Let In = T~(I~) and T~,,(0) = I": we prove by 
induction on n that 
for all n there exists m such that In C I" 
(27) 
The base case is clear. Let us check the inductive step: assume It C I~ and let /?(A' : 
c') 9 Tp(I~) = I,+l; 
- 
if/?(A' : c') is obtained by applying a rule in P - {p}, the inductive step is clear; 
- 
if/?(A': c') =/?(A: c') is obtained by applying the rule (p), then 
O(A1 : Cl ^... A A~ : c~) 9 I~ = Tp(I,-l) 
(28) 
and 
O(Ak+I : ckq-1 A... ^ A,~: cn) 9 II = Tp(I,-a) 
(29) 
with c' = ca A--. A ck ^ Ck+a A... ^ c,; 29 together with the induction hypothesis implies 
that O(Ak+l : c~+aA...AA, : c,~) 9 I~; 28 implies that P ~-/?(A1 : ca^...Aak : ck), hence 
by condition 1) P - (p) b- O'(B1 : el ^-.. ^Bm : era), hence there exists a j' such that 
/?'(Ba : el A... A Bin: era) 9 TJi_(p)(O) C Ij,. Let j" = sup(j,j'), then /?'(B1 : el ^-" A 
Bin: era) 9 I~,,, and/?'(Ak+l : Ck+l A'''AAn 
: cn) = /?(Ak+a : ck+IA"-AA, : cn) 9 I;,,, 
hence, applying rule (p') we obtain/?'(d: Cl A.. "AemACk+a h'" .^On) 9 Tp, (I;,,) = I;,,+a ; 
as 0'(el A... A em A ck+l A... ^ Cn) = /?'(el A... A era) A O(ck+a ^... A cn) and since 
/?(ca ^... ^ ck) ~/?'(el 
^... ^ era) and O'(A) =/?(A), O(A : e') = O(A : ca A ... A ck A 

34 
Ck+l A''" A Cn) is an instance of O'(A : el A... A em A ck+l h..- A Cn), hence O'(A : c') is 
in I~,,+1. 
To prove 1) (ii), we assume that the condition 2) of the replacement rule, is satisfied, 
namely 
2) P ~- O(B1 : el A... A B,~ : era) implies P - (p) ~- O'(A, : cl A ... A Ak : ck) for 
some 0' such that 0 and 0' agree on all the variables of A, Ak+l : ck+l,... ,An : c,~, and 
0(el ^... 
^ era) ~ 
e'(cl ^... 
^ c~). 
Mutatis mutandis, a proof similar to the previous one will show that 
for all n there exists m such that I~ C Im 
(30) 
Whence it will follow that M(P') C M(P). 
[] 
Proof of Proposition 
4.6 1) Correctness of thinning 
Let 
(p) 
A ~---- A1 : cl,...,Ai-1 
: ci-l,Ai : c~,Ai+l :c,+l,...,A,,:c,, 
(r) 
B ~ 
At : c~,...,A~_ 1 : c~_~ 
(p') 
A *---- AI : cl,...,Ai-1 
: c~-l,A~+l : c~+1,...,An : cn 
be as in Section 3.6, with a substitution 0 such that 
AI=O(B), 
and forj=l,...,i-1 
, 
A s =O(A'j), 
for j = 1 .... , i -- 1 , 
cj ===>/~(c)), 
(31) 
c, = O(e~) ^... ^ O(e:_l) 
(32) 
(i) M(P) C M(P') since (p') subsumes (p), i.e. whenever (p) applies, (p') also applies 
and gives the same consequence; 
(ii) moreover, since condition 2) of the replacement rule is satisfied by taking 
B1 : el,...,Bm 
:em = A1 : Cl,...,Ai-1 
: ci-1 
A1 : cl, 9 Ak : ck = A1 : cl,. 9 Ai-1 : ci-1, Ai : ci 
M(P') C M(P) (cf. Proposition 4.5 1) (ii)). 
2) Correctness of fattening 
Let (p) 
A , 
A1 : cl,...,Ai 
: ci,Ai+l : c/+l .... ,An : cn and (r) 
B ~ 
B1 : 
el,...,Bi 
: e/ be in P, and 0 be a substitution such that: C ~ 
A1 : cl,...,A~ : ci is 
an instance of (r), with O(B) = C and moreover Aj=l ..... /cj ~ 
e = Aj=l ..... iO(eJ), 
cj ~ 
0(e,) for ~ = ~ ..... i. Let (0'): 
(p') 
A ~-- Al : cl,...,A~ 
: c,,C : c 
and P' = P - {p} U {p'}. Apply now the thinning transformation to P' and (p'); (p') 
contains in its body an instance C , 
- A1 : cl,...,Ai 
: ci of (rr), the applicability 
conditions for the thinning transformation are satisfied, and applying this transformation 
we obtain P" = P'- 
{p'} U {p"}. Moreover, it is immediate to check that (p") = (p), 
hence P" = P and M(P) = M(P") = M(P') by the correctness of thinning, and P' is 
equivalent to P. 
3) Correctness of pruning 
Let (p) 
A ~ 
A1 : cl,...,mn 
: c,~ and (r) 
B ~-- B1 : el,...,Bm 
: e,~ with 
m <_ n and such that there exists a substitution 0 verifying: A = O(B), Ai = t?(B~), 
ci ==:r 8(ei), for i = 1,...,m. 
Let P' = P - {p}, then Tp ~ w = Tp, ~ w. 
1) Clearly, Tp, T w c Tp T w since the set of clauses of P' is contained in P. 
2) Tp T w c Tp, T w. By induction on n we check that T~(0) C T~,(0) for all n E IN. 
It is clear for n = 0. Assume it holds for n, i.e. In = T~(O) C T~,,(O) = I~, and let 
A': c' e T~+l(r 
we check that A' : c' e Tp+l(O). 

35 
a) If A': c' is obtained by instanciating a clause in P - (p}, then A': c' E Tp, (I,~) C_ 
Tp, (I"). 
b) If A': c' is obtained by an instance 0' of (p), then 38'(A, : cx),... ,#'(A,~ : c,~) E 
In such that O'(A : c) = A' : c' C Tp(1,). Hence e'(Aj : c~) E In _c I', for 
j = 1 ..... m,..., n. There exists a substitution 0 such that A = 0(B) A~ = 0(B~) 
ci =:~ O(ei), for i = 1 .... ,m. Hence O'(8(Bj) : O(ej)) E l'n, for j = 1,...,m. 
By 
clause (z') we obtain 0'(0(B): Aj=, ...... 0(e j)) E TF,(I'). Since all interpretations 
are upwards-closed and c = Aj=, ...... cj ==~ Aj=, ...... 0(ej), we have O'(A: c) E 
T~, (r). 
o 
Proof of Proposition 
4.10 Let P contain clause (p) 
A ~-- A1 : cx,..., A,~ : c~. We 
' 
' where 
'=ciix 
for 
can substitute for (p) the clause p' (p') 
A ~ 
A1 : cl ..... A,~ : cn, 
c~ 
i = 1 ..... n. Let P' = (P- 
{p}) O {p'}. 
Assume that the local intermediate variables have been renamed so that the local 
variables occurring in the ci's for i -- 1,..., n are pairwise distinct. 
a) Ms(P) 
C Ms(P') can be proved as in Proposition 3.13 above: i.e. c~ = cilx 
t 
implies that ci ==~ ci, hence (p) is an instance of (p'). 
b) Let us check conversely that Ms(P') C Ms(P). 
Let Is,k = T~,s(O) and I), k = T~,,s(fJ ). By induction on k we prove that 1~, k C ls,k, 
Vk EIN. 
This is clear for k = 0; assume it holds for k and check that I's,k+l C Is, k+,. Let 
A' : c ~ E l's,k+, then 
1. If A' : c' is obtained by a clause of P' - {p'}, then A' : c' E ls,~+1. 
2. If A' : c' is obtained by an instance of clause (p') then 38' instance of (p') such 
c') = A' 
d' 
' 
' 
' 
that O'(A: Aj=a ...... 3 
: 
9 Is,k+ 1 and O (Aj=I ...... c 3) r 
c' is solvable; 
whence 0'(Ai): O'(d'j) 9 I's,k with O'(c'j) ==*x O'(d'j) and O'(c'j) is solvable for j = 
1,..., n. By the induction hypothesis, we deduce that O'(Aj) : O'(d'j) 9 1s,k, hence 
also O'(Aj) 
"'( '" 
' 
= 
: u cj) 9 Is,k since O'(c'j) ==~x O'(d'j). Since cj ==~x c3 for j 
1 ..... n, 
O'(c~) solvable implies that Oj(c3) solvable for some Oj such that Oil x = 0'. 
Since the local variables occurring in the ci's for i = 1,..., n are pairwise distinct, 
# can be well-defined by 
f O'(y) = O(y) 
if y 9 X is a global variable 
u(y) = \ 0j(y) 
if y is a variable local to constraint c~ 
and It is such that for j = 1,...,n, 
It(c~) = Oj(cj), It(Ar 
= O'(Ai) = Oj(Aj), 
It(A) = O'(A) = A', (It(Aj) : It(cj)) ----- (O'(Aj) : Oj(cj)) 9 Is,k and It(cj) solvable. 
We can thus apply rule (p) and #(A : Aj=a ...... cj) = A' : d 9 ls, k+,. Hence also, 
I 
by the definition of Is,k+x, since c' is solvable, and c' = Aj=I,...,~ cj r 
d = 
I 
]~j=l ...... c~ (because on the one hand c~ is an instance of ci, and on the other hand 
c; :==~x cj), A' : c' = It(A): c' 9 Is,k+,. 
[] 

Using Call/Exit Analysis 
for Logic Program Transformation 
Dmitri Boulanger* 
Maurice Bruynooghe** 
Department of Computer Science, Katholieke Universiteit Leuven 
Celestijnenlaan 200 A, B-3001, Heverlee, Belgium 
email: {dmitri, maurice}Ocs.kuleuven.ac.be 
Abstract. A technique for transformation of definite logic programs is 
presented. A first phase performs an analysis of the extended call/exit 
patterns of the source program. It is shown that a particular form of 
correct abstract call/exit patterns can be used as a guide to control the 
transformation itself and can help to generate the target program having 
desired properties. The technique provides a framework which, combined 
with problem specific information concerning the source program, can 
lead to nontrivial transformations. 
1 
Introduction 
The most popular approaches for definite logic program transformations are 
based on unfold/fold and goal replacement operations applied to the clauses of 
a source program. The unfold/fold transformations have been introduced in [5] 
and later were applied to logic programming in [25, 15, 24]. The recent paper 
[13] s revisits the framework developed by Tamaki and Sato. 
In this paper we are developing another approach to logic program trans- 
formation. Namely, we consider transformations which are performed into two 
phases: a first phase performs a complete static data flow analysis to derive a 
transformation guide of the source program, the second phase follows the guide to 
transform the source logic program (here we follow some basic ideas of [14, 12]). 
In [1, 2] we have introduced a rather general and powerful approach to derive 
unfold/fold transformations of definite logic programs by abstract interpreta- 
tion. The unfold/fold transformations, which can be obtained in this way, have 
been shown to be more general than those of Tamaki and Sato. Indeed, as it 
was pointed out in [18, 13], SLD-like tree analysis can produce transformations 
which cannot always be expressed in terms of unfold/fold transformations as 
described in [25, 15, 24]. 
* Supported by the K.U.Leuven. Permanent address: Keldysh Institute for Applied 
Mathematics, Russian Academy of Science, Miusskaya sq., 4, 125047 Moscow, Russia. 
** Supported by the Belgian National Fund for Scientific Research. 
3 The examples presented in this paper show that the approach of Tamaki and Sato 
is not sufficiently sound. 

37 
The paper aims at introducing a logic program transformation framework, 
which is capable of performing complex transformations by applying unfold/fold 
and goal replacement transformations which are specialised by problem specific 
information which are specialised. It is clear, that a toolkit having such a rich set 
of elementary operations has to be controlled by high level specifications, which 
are to be sufficiently expressive to describe the target of the transformation of the 
source program. In this respect the central idea of our approach is to specify the 
behaviour of the target program in the form of its possible call/exit patterns. The 
source program can have a lot of different sets of call/exit patterns (by choosing 
different computation rules), so it is possible to choose the most suitable ones and 
to obtain by transformation the program, having the specified cM1/exit patterns, 
i.e. to fix by transformation the desired behaviour of the program. 
The paper is organised as follows: after some preliminaries in section 3 we 
introduce a special variant of SLD resolution, which is used as basis for our 
approach. Afterwards we present a technique to represent call/exit patterns and 
use them as a guide during execution of the definite logic program. The results of 
the execution are used to transform the program. The new program reflects the 
specified call/exit structure. In section 4 we give an extensive example, which 
shows an advanced technique usable for deriving non trivial transformations. 
2 
Preliminaries 
In what follows the standard terminology and the basic knowledge of the theory 
of logic programming, as can be found in [20], is assumed. We will use the 
standard notions of SLD derivation and refutation, unification and idempotent 
substitution. The properties of unification and substitutions presented in [9, 19] 
are used indirectly throughout the paper. 
The capital letters B,Q and R denote conjunctions of atoms. In the sequel 
they are considered as collections and are called blocks. The letters A and H 
denote atoms. Where convenient, we write E(X) to denote a syntactical object 
E (block, atom, goal or other expression over the set of terms) with variables 
X. By var(E) we denote the set of variables, occurring in the syntactical object 
E (so 
-- 
The greek letters O, a, ~a and r will be used to denote idempotent sub- 
stitutions. Given a substitution 0, 0 I~=r(E) will denote the restriction of the 
substitution 0 to the variables occurring in E. Given an expression E over the 
set of terms, ES, the instance of E by 8, is defined as usual. 
The greek letter X is used to denote set of constraints or equations. The 
most general unifier of a solvable set of constraints is an idempotent substitu- 
tion a which we denote by solv(x). Given the well known correspondence be- 
tween solved form and idempotent substitutions [19], we sometimes write eq(a) 
to denote the solved form corresponding to a substitution or. With X a set of 
constraints, by Xa we mean xUeq(a). An empty set of constraints 0 corresponds 
to the identity substitution {}. We consider a definite logic program P to be a 
set of definite clauses {cl,..., c,~) equipped with an initial goal Go. The succes- 

38 
sive goals in a SLD derivation for the initial goal wrt P will be denoted by Gi, 
i = 0, 1,..., n. In the context of this paper we will always deal with programs 
having exactly the same initial goal Go =4-- e, where the predicate symbol e 
never appears in the bodies of the clauses {cl,..., c,~}. The predicate eis used 
to declare the "entry points" of a program. Moreover, given two logic programs 
P1 and P2, the intersection of the corresponding languages includes all function 
symbols but only one predicate symbol, namely e. It is clear, that all these re- 
strictions cannot influence the generality of the presentation. Finally, we have a 
simple notion of equivalence of programs: two programs P1 and P2 are equivalent 
iff they are logically equivalent wrt the common language (an extensive discus- 
sion of the topic can be found in [21]). This notion of logic program equivalence 
is the most appropriate one for a wide class of applications. 
3 
Using Extended 
Call/Exit 
Patterns 
for Controlling 
Logic Program 
Transformation 
In this section we present an algorithm for logic program transformation based 
upon call/exit analysis of an SLD-like tree of the source program P. So firstly 
we describe a special variant of SLD-resolution to be used as the main engine 
for the call/exit analysis. 
3.1 
Extended OLD Resolution 
Extended OLD resolution was introduced by us in [1, 2] and deviates from the 
standard SLD resolution only by imposing certain restrictions on the computa- 
tion rule. Namely, the SLD derivation 
Go cx e I GI,..., c,, of, Ga 
is an EOLD derivation for the initial goal Go wrt a definite logic program P 
provided that any goal Gi in the derivation is represented as an ordered sequences 
< B1, B2, ...B~ >, m > 0 of conjunctions of atoms (blocks) and the computation 
rule always selects an atom from the first block. Given a goal G represented as an 
ordered sequence of blocks, HGII will denote the collection of all atoms occurring 
in G (In OLD resolution [26, 16] blocks have only one atom). 
The following definition gives a more precise description of an EOLD resolu- 
tion step. 
Definition 1. EOLD Resolve~t 
Let G~ be a goal represented as < B1, B2,..., Bm >, m ~ 1, A the atom selected 
from B1, Ci+l a standardised apart input clause from P, Oi+l the mgu of A and 
the head of the clause c~+1. Then G~+I is derived from Gi and ci+l using mgu 
0i+1 via the EOLD computation rule if G~+I is obtained by applying the following 
two steps: 

39 
- 
construct the auxiliary goal G' =< B~, B2,..., Bm >, where B~ -- B1 with 
A replaced by the possibly empty body of ci+l 
- 
if B~ is empty, then Gi+l ---< B2,..., Bm> 0~+1; else partition the first 
block B~ of G' into a number of non empty parts (blocks) B~I , 
B' 
9 " ", 
Ik' 
k > I, and let Gi+ 1 :< B~I,.. 
I 
", 
_ 
.,Blk,B2,.. 
Brn > 0i+1 blocks 
[] 
In what follows the definition of a subrefutation in an EOLD derivation will 
play an important role. 
Definition 2. EOLD Subrefutation 
An EOLD subderivation of the form Gi c,+1 0~+1 Gi+l,..., c" 0~, G,, is an EOLD 
subrefutation for the first block B1 of the goal Gi =< B1, B2,..., Bk >, /e > 1 if 
either G,, =<> and k = 1 (i.e. the subderivation is a refutation for B1) or there 
exists a substitution o "4, such that II < B~, ...B~ > all : IIG,~I[ and there is no 
goal Gj, i ~ j < n having this property in the subderivation. The substitution 
0i+10i+2 ... 0,~ is called an answer substitution of the subrefutation. 
[] 
Notice that EOLD resolution is sound and complete because soundness and 
completeness of SLD resolution is independent from the computation rule [20]. 
Any expression identical, up to variable renaming, with the first block B 
of the goal G is said to be an eztended call of the goal (it will be denoted by 
call(G)). The corresponding ezten, ded answer (it will be denoted by snaky(G)) 
is any expression identical, up to variable renaming, with BS, where 8 is the 
answer substitution of some refutation of block B. Extended call/exit patterns 
of EOLD trees describe important properties of programs. So below we present 
a technique for safely approximating the complete set of call/exit patterns. 
3.2 
A Safe Approximation of Call/Exit Patterns 
Consider a complete (and, thus, possibly infinite) EOLD tree for a logic program 
P. The complete Call/Exit cover of the tree is the set of all call/exlt pairs of the 
form [K ~ Ansi(K)], where the key K is an extended call and the set Ansi(K) 
is the set of all corresponding extended answers. In general the complete CE- 
cover is infinite. So we need a finite abstraction which is a safe approximation. 
A finite correct abstract CE-cover for an EOLD tree can be defined as follows. 
Suppose there is some equivalence relation over the set of all blocks such that 
the set of distinct equivalence classes is finite. Then the set of keys occurring in 
the complete CE-cover can be represented by a finite set {K~, K~',..., K~'} of 
equivalence classes. Let Answ ~ (K ~) be the finite set of equivalence classes of 
blocks occurring in a set 
LJ Ans (g). 
KEK 
~ 
4 In the context of EOLD resolution the substitution a is exactly the s u b s t i t u t i o n  
0i+1 ... 0,~. Below we will use the modified EOLD resolution, where this property is 
not always the case. 

40 
Then the complete abstract CE-cover is a finite set of abstract call/exit pairs 
{[K~ :=~ Answ~(g~)] l i = 1,...,n}. 
Let G be a goal occurring in an COLD tree. Given a complete abstract CE-cover, 
the extended call call(G) is said to be covered by the key g ~ iff call(G) 6 K ~. 
Similarly, the extended answer answ(G) is said to be covered iff the correspond- 
ing extended call call(G) is covered by the key K ~ and answ(G) belongs to 
some equivalence class occurring in the set Answ ~ (K ~). 
The complete abstract cover requires all call/exit pairs to be covered. In the 
sequel we will need a more flexible description of program properties: we will 
allow that not all call/exit pairs are covered. This will be used to control the 
transformation of the source program P (see below). Consider the following more 
flexible description of call/exit patterns. 
Definition 3. Safe Abstract Call~Celt Cover 
Given an EOLD tree, a safe abstract CE-cover of the tree is a subset of the 
complete abstract finite CE-cover such that the number of not covered extended 
calls and answers occurring in the COLD tree is finite. 
O 
In what follows we will always assume that the COLD tree and the corre- 
sponding safe abstract CE-cover satisfy the following conditions: 6 
- 
Every equivalence class can be represented by a block of atoms. All elements 
of an equivalence class are instances of its corresponding block. Thus we will 
not distinguish between equivalence classes and their corresponding blocks. 
- The block size of an EOLD tree is bounded by some constant. 
The conditions above ensure that any COLD tree has a (safe) abstract finite 
CE-cover. For example, a trivial CE-cover can be obtained using only recursive 
predicate symbols of the program P with distinct variables as arguments to 
construct the blocks of the equivalence classes. 
Ezample 1. The empty set is a safe abstract CE-cover for any EOLD tree, which 
can be constructed for any logic program P having a finite extended minimal 
model EMMp (see [10]) provided that the block size is bounded. Also the set 
{[q(X) =~ EMMp(q)] I q E P} 
is always a safe (possibly infinite) CE-cover for any program P, where q E P are 
the predicates of P and EMMp(q) C EMMp are the elements of the extended 
minimal model of P having a predicate symbol q. Moreover it is complete CE- 
cover. 
On the other hand, the empty set is not a safe cover of any OLD tree, which 
can be constructed for the program 
e(X) ~-- even(s(X)). 
even(O). 
even( s( s( X) ) ) ~-- even(X). 
These conditions are not strictly necessary. We use them to :simplify the presentation. 

41 
with the standard goal ~ e(X), because the number of not covered answers 
is infinite. Notice, that the number of not covered calls is finite. The abstract 
CE-cover 
{[even(X) ~ {even(Y)}}} 
is safe for any OLD tree, which can be constructed for the above program. 
1:3 
A safe abstract CE-cover can be used to control EOLD resolution and to 
construct a tree having a special shape. 
3.3 
Modified EOLD Resolution 
Our framework uses a special variant of EOLD resolution. In order to introduce 
it we need some auxiliary definitions. Firstly, we will use eztended goals, which 
are sequences of blocks and ezit markers. An exit marker is a block which is 
syntactically different from any block of atoms and has the form AG (a, X), where 
G is a goal in the current EOLD derivation, a is a substitution and X is a set of 
constraints. The goal G is the goal, where the exit marker has been inserted. The 
initial goal always has the form Go =< r AGo({}, r >. Given a substitution 9, 
we will assume that 
x)0 : 
x u eq(0)). 
Secondly, we will use two special operations: a key factorisation and an exit 
marker elimination. The former inserts an exit marker, while the latter deletes it. 
Key factorisation is a transformation of a goal G =< B1, B2,..., Bn >, where 
B1 is a block of atoms. If there exists a standardised apart key K = K(W) 
in the CE-cover, i.e. var(K) = W, W n vat(G) = 0, and a substitution or, 
dam(a) : W such that B1 : Ka (i.e. the block B1 is covered by the key g), 
then the key factorisation replaces the goal G by < K, An(a, 0), B~,.-., Bn >. It 
is important to notice that after key factorisation the first block of the goal has 
"fresh" variables, which differ from the variables in the other blocks of atoms. 
The ezit marker elimination is applicable to a non singleton goal if the goal 
has at least two exit markers and if its first element is an exit marker. Let 
G :</kol(Crl,X1),B1,...,Bm,/ka2(a2,Xa),... >, rn ~ 0 
be a goal, where Aa2(a2, X~) is the second exit marker in the goal. There exists 
always at least one exit maker because any goal contains the exit marker of 
the initial goal, i.e. any goal has the form < ..., AGo({},X) >. Suppose that 
0 = solv(xl) ~ fail and G1 =< K(W),AGI(crl,r 
> with dora(a) = W 
(cf. key factorisation above). Then the safety of the CE-cover ensures (see def. 
4 below, which describes the structure of a derivation), that there exist a key 
g = K(W) and a corresponding answer ga,,~,,~ with dom(a~n,~) = W such 
that KO is an instance of Ka~,,~, i.e. 
ro : (r,,o,,,,~ho , and soZv(eq(,~o,,,,~)U eq(~,)) = solv(Xl) 
Then the exit marker elimination creates the new goal G' : ezit(G), 
G' --< B1,..., Bin,/kG~(GZ, X2 tJ eq(~))... > ~b, 

42 
where ~ -- solv(eq(~rl)U eq(tT~,~,~,)). The substitution ~ is exactly the part of the 
answer which is "prescribed" by the CE-cover to instantiate the remaining part 
of the goal. Therefore, ~ is applied to the whole goal, while the not allowed part 
is added to the constraints of the next exit marker. In this way ~ is isolated 
(but not lost!) in the next exit marker. This explains why it is always necessary 
to have at least one exit marker - it accumulates the parts of the answers which 
have to be delayed. 
The extensions above allow to modify standard EOLD resolution as follows. 
Let us denote by resolve~oLD (G, c) the goal, which can be derived from the 
goal G and input clause c E P by applying a standard EOLD resolution step 
(cf. def. 1). 
Definition4. 
(Modified) EOLD* Resolve~tt 
Given a CE-cover and an extended goal G =< BI, B2,--', B= >, the (modified) 
EOLD* resolution step 
Gi oi+~ G,+I ' Gi4-1 : resolve~OLD(Gi, ci-l-1) 
consists of o~e of the following operations: 
1. If B1 is a block of atoms (not an exit marker), derive the intermediate goai 
G' = resolveEoLD (Gi, el+l) 
and construct the corresponding substitution 6i+1 and: 
I 
! 
.. 
If the goal G' has the form < BI, B2, 
- >, where B~ is a block of atoms 
such that the key factorisation on B~ is applicable, 
then Gi+l =< K,/Xa~+i(a , 0), B~,... > 
else (the key factorisation is not applicable) G~+I = G'. 
2. If the goal G has the form < ZXa(~,X),... > (the first block is an exit 
marker) do: 
if the exit marker elimination is applicable on Aa(o', X) 
then Gi+l = ezit(Gi), 81+l = tr 
else (exit marker elimination is not applicable) the goal is non-extendable 
[] 
In the sequel we will assume that all failed branches of the modified EOLD* 
tree are dropped. A branch of the tree is considered to be a failed branch iff it 
contains a non extendable goal G such that it is either a failed goal in standard 
sense (cf. def. 1) or the set of all constraints occurring in G is not solvable. Then 
definition 4 above ensures the following simple properties of the modified EOLD* 
trees: 
- 
A goal G is a non extendable goal iff it is a success goal of the form G =< 
~a0({}, X) >, sotv(x) # fail. 

43 
- The definition of subrefutation (cf. def. 2) and the notions of extended calls 
and answers, which have been introduced above in the context of standard 
EOLD resolution (cf. section 3.1), are also applicable to the goals of the 
modified EOLD* trees (including the goals having an exit marker as a first 
element), but the answer substitutions have another meaning (see prop. 5 
and 6 below). 
- Each covered extended call occurring in the tree occurs as a key in the CE- 
cover 
Consider a standard EOLD tree and the corresponding modified EOLD* tree 
constructed wrt some safe finite abstract CE-cover. The relation between them 
is given in the following proposition: 
Proposltlon5. 
The BOLD* tree constr~cted using some safe finite abstrac~ 
CE-cover contains a derivation 
Go o, G1, . . . , -~ G, 
having the final success #oal G, of the form < AGo((}, X) >, cr = solv(x) ~ fail 
(i.e. the refutation of the initial goal) iff the standard BOLD tree contains a 
refutation 
I 
t 
Go o l G'I,..., 
o.% G~, n > m 
such that G~n =<> and solv( eq( 01) U . . . U eq( On ) U X) = solv( x ) = 81... 8~m . Q 
The following proposition describes the most important feature of EOLD* 
resolution. 
Proposltlon6. 
Given an EOLD* tree constructed usin 9 some safe finite ab- 
stract CE-cover, any eztended call of an eztendable goal occurring in the tree 
has a finite number of corresponding eztended answers, while the length of the 
corresponding subrefutation and their total number can be unbounded. 
0 
The propositions 5 and 6 are very important for the transformation algorithm 
introduced below. 
3.4 
Transformation Algorithm 
Given an EOLD* tree constructed wrt some safe abstract CE-cover, the algo- 
rithm for generating a new logic program H is the following: 
1. Introducing New Predicate Symbols: for each key K different from e in the 
CE-cover generate a fresh predicate symbol 7r/n, where n is the number of 
distinct variables occurring in the key K e. The predicate symbol 9 is also 
included in the set of predicate symbols of the program H. In this way each 
covered extended call in the EOLD* tree is associated with a new predicate 
symbol of//. 
6 In [3] we give powerful conditions, which allow for dropping some arguments of the 
new predicates. 

44 
2. Sy~zthesisilzg New Program Clauses: for each subrefutation of the first block 
of a goal G having the form 
G 01)GI~..., 0.)G, 
where G =< K,/\G(~r, $),--- > and G,~ --< /\u(cr, X),... > (i.e. the key 
factorisation has been successful for the goal G), construct a new clause of 
the program//of the form 
(~0(X0) ~- ~,,(y-~,),..., ~,~(Y,~) )soZv(~) 
where: 
- vr0 is a new predicate symbol associated with the block of atoms B0 
(covered extended call of G) and Xo = var(Bo) 
- 
G~ r G, j = 1,..., m are all goals occurring in the subrefutation B0 of 
the form 
G~, =< B~, Aa,~ (~ij, X~j ), " " , Aa(. . .) . . . >, 
such that the exit marker/ku(a~#, Xii) is exactly the second element in 
the goal (the latter means that we consider only the top level covered 
extended calls occurring in the subrefutation of B0) 
- 7ri# is the predicate associated with the covered extended call of Gij 
(which corresponds to the block of atoms B~) and Y,~ = var(B~j), 
j = 1,...,m 
- E = [J~ eq(Oi~), where 8i~ is the substitution labelling the EOLD* step 
Gib-i Oi~ Gib 
and the goals Gi~ ~ G, k = 1,..., 1 are all the goals in the subrefutation 
of B0 having the form 
Gi, =< Bs~, Aa(,~,Xi,),---> 
or 
G~ =< B~,, Aa,, (~,, X~,),'", At(...)... > 
where Bsi~ is a (possibly empty) sequence of blocks of atoms (here we 
consider all top level calls occurring in the subrefutation of B0) 
For the clauses which are synthesised from the refutations of the initial goal 
Go =< r 
({}, 0) > the predicate r is used to construct the clause head. 
Notice that Xo, Yij, j = 1,..., m are disjoint sets of variables. 
3. The Final Program: consider the set of all clauses, which can be obtained 
following the algorithm above. If clauses which are renaming of each other 
are considered identical, then the set of clauses is finite. Moreover, the new 
program H is logically equivalent to the source program P wrt the common 
language, which consists of only one predicate symbol c and all function 
symbols. 

45 
To be convinced that the algorithm always generates a finite program, it is 
sufficient to notice the following: 
- All goals of the form G =< K, Ao(--')'" 
> have exactly the same (up 
to the variable renaming) set of subrefutations for the first block, because 
the key factorisation always creates the first block with fresh variables, and 
thus the set of subrefutations is independent from the particular goal in the 
tree. In other words, the influence of the other blocks on the goal is isolated 
(delayed) in the exit marker in the form of a set of constraints. This means, 
that the final program has a finite number of predicate definitions (one for 
each key in the CE-cover and one for e). 
- 
The number of clauses in each definition is finite. Suppose that there is 
a definition having an infinite number of clauses. This implies, that the 
extended call, which corresponds to the predicate symbol of the definition, 
has an infinite number of extended answers. This contradicts proposition 6. 
For the same reason the number of atoms in the bodies of the clauses is also 
bounded. 
The equivalence of the source program P and the program H can be derived 
by using proposition 5 and by showing that any EOLD* refutation of P, which is 
constructed wrt a chosen safe finite CE-cover, can be simulated by some OLD* 
refutation (EOLD* with singleton blocks!) of ii7, which is constructed wrt the 
trivial CE-cover (constructed from the new predicates having distinct variables 
as arguments) and vice versa. 
Let us provide some important remarks concerning the applicability of the 
logic program transformation framework, which has been introduced above. The 
presentation above was given under assumption that there exists an EOLD tree 
having a safe CE-cover. Finding the EOLD tree and the CE-cover is intended to 
be solved separately during a first phase. In the next section we will give several 
remarks concerning this problem. 
It should be clear from the discussion above, that we really need to con- 
struct only some upper portion of the EOLD* tree. Namely, all keys occurring 
in the CE-cover and some portion of the corresponding subrefutations have to 
be discovered in the tree s . This problem is also addressed in the next section. 
The presentation itself of the transformation algorithm was given in a form, 
which was as simple as possible (the price of the simplicity is that the algorithm 
uses too many intermediate variables, which are not always necessary). For the 
same reason a tabulation mechanism [26]) was not included too. Here we were 
mainly interested in the careful investigation of the class of logic program trans- 
formations (see sections 4 and 5 below), which can be derived in our framework. 
So we have omitted technical details related to an efficient implementation of the 
7 This means, that the algorithm is capable to derive FOLD transformations. 
s Using the specially constructed CE-cover we significantly extend the "upper por- 
tion" algorithms of [22, 23]. For example, in this way we avoid Et, reka-steps when 
generating complex folding transformations (see also [1, 2]). 

46 
algorithm (a variant of the algorithm, which is rather efficient from an implemen- 
tation point of view, but has a more narrow class of derivable transformations 
can be found in [1, 2]). 
Finally, notice, the great importance of the particular structure of the chosen 
safe abstract CE-cover. It can be used to control the structure of the new pro- 
gram: the keys specify the granularity of the definitions of ]I, while the answers 
can be used to control the internal structure of the definitions and the structure 
of the clauses of//. By allowing some extended calls and answers not to be 
covered (cf. example 1), we can specify what should be factored out by partial 
evaluation: all procedure calls not corresponding to the keys in the CE-cover 
are partially evaluated (cf. [18]). Thus, the particular form of the equivalence 
relation over the set of blocks is crucial. It seems that, by choosing non trivial 
equivalence relations, one can obtain rather complex and deep transformations 9. 
4 
Deriving Logic Programs Using Call/Exit Patterns of 
the Source Program 
As could be seen from above the EOLD* interpretation and subsequent transfor- 
mation algorithm are strictly controlled by the safe abstract OE-cover of some 
EOLD tree. So the first problem is to prove the existence of the desired EOLD 
tree and to find a safe approximation of its call/exit patterns: This problem is 
well known and several frameworks based on abstract top-down computation 
equipped with the tabulation mechanism have been suggested [26, 16, 7]. It was 
shown, that abstract tabled computations can be done correctly for a very wide 
class of abstract domains [16, 7]. These algorithms allow to construct complete 
finite abstract CE-covers of some OLD tree using some equivalence relation over 
the set of atoms. Definition 1 has been elaborated keeping in mind the appli- 
cability of these algorithms to the extended call/exit patterns, which are used 
in our framework. Thus, we can assume, that we are given some equivalence 
relation 7~ and the corresponding complete abstract OE-cover gs162 
Notice, 
that gs 
can imply a particular blocking strategy of some EOLD tree, i.e. the 
rule for partitioning atoms of the current goal into blocks (el. def. 1). 
Below we provide an example of a program transformation, which uses a more 
general form of 7~ than was described in section 3.1. This example is intended to 
demonstrate the capabilities of the framework and the usefulness of nontrivial 
equivalence relations over the set of atoms. 
Consider the logic program P given in example 1. The abstract OE-cover 
{[even(s(X)) =~ {even(s(s(O))), < even(s(,(Y))), r â€¢ 0 >}]) 
is rLota safe abstract CE-cover for P, because the not covered call even(X) 
has an infinite number of exit patterns. Some modification of the framework 
presented in section 3 allows to derive a finite new program. The OLD* tree 
In [3] we use an equivalence relation over the set of blocks, which considers two blocks 
to be equivalent if they are equivalent goals wrt the source program P. 

47 
contains the following simple derivation 
9 Go =< e(X),no({),0)> 
9 G1 =< e~en(s(W1)),A~({wi .- x), ~),no({}, ~)> 
o~ = {wl ,-- .(w2)) 
9 G2 --< even(VC'2),nz((wz ~ x), {wz = 6(w2))),no({), (w1 = a(w2)))> 
i 
os = {w2 +- o) 
9 G3 ---Az({wz .-- x), {wz = ~(o),w2 = o}), Ao ({}, {wz = ,(o),w2 _-- o}))> 
o4 = {wz ~- X) 
9 G4 =no({), {wz = ,(o), w2 = o, x = ,(o)})> 
which produces the clauses: 
- the clause e(X) ,--- ~z(X), which was obtained from the subrefutation of 
call(Go) by 
(dx) 
 1(w1) ),oZv(eq(01) U eq(0,)) 
- the clause ~rl(s(0)), which was obtained from the subrefutation of call(Gi) 
by 
( z(W1) ),oZv(eq(02) u eq(03)) 
The subrcfutations for call(Gi) of the form Gz 0~ G2 0% Gs 
,..., where 
05 = {w2 +-- ~(a(w3))) and 
G~ =< even(W3),Az({wz ,- x), {wi = m(a(,(ws))),w2 = a(,(w3)))), A 0 ({), {.-.))> 
will produce an infinite number of clauses ~'z(s(s(s(0)))), ~'z (s(s(s(s(s(O)))))),..., 
if the algorithm from section 3.4 is used. 
Thus we have to control the uncovered exit patterns of the call even(X) 
"manually". We can apply apply some "massaging" on Gs such that we avoid 
the the infinite number of distinct subrefutations for even(W3). It can be done 
as follows. The substitution 0s is the first one, which creates an "incomplete" 
but already not allowed answer for call(Gz). Thus 0s has to be made more flat. 
In general it is a complex operation, which is not always possible (because we 
should preserve correctness of all refutations in the tree), but in this particular 
case the following reconstruction is correct: 0~ = {w2 ~- ~(w4)} and 
G~ :< even(s(W4),nz({wz ,-- x), .{wz = ,(,(w4)),w2 = J(w4)}), n0 ({}, {...})>, 
Now key factorisation on G~ is applicable! One obtains: G~' = 
< even(s(Wh),ns({w5 ,-- w4}, 0),Al({w1 4-- x}, {wl = s(s(w4)), W2 = s(w4)}), 
n0 ({), {..-))>. 
The reconstruction above is ensured by the available abstract CE-cover. In- 
deed, the variable T473 occurs in only one atom of the goal Gs and it can possibly 
be instantiated by resolving even(W3). On the other hand, the CE-cover en- 
sures, that the new introduced variable W4 occurring in G~ can be instantiated 
only by s(U) when resolving even(s(W4)) in G~ and thus, the variable W2 will 
have the same value as in the original derivation, provided that all constraints in 
G~ are modified accordingly. This reconstruction can be considered as applying 
a special equivalence relation over the set of atoms, which can be defined wrt 
the source program P. On the other hand, this reconstruction is something more 

48 
powerful than the well known goal replacement (see [13, 17, 3]). In [2] it is shown 
how the formal proof of the equivalence above can be obtained. 
, 
01 G~ I 06 
The reconstructed subrefutations of the form G1 02 G2 
~, 
Gs-.-, 
where call(Gs) : even(W6) and ee = {ws ,-- ,(ws)), will produce only one clause 
7rl(s(s(W4))) e-- 7q(W4) by 
 
l(ws) 
u eq(O;) U {W5 = W4)), 
i.e. the following new program is generated 
n = 
.l(x), 
.l(s(0)), 
.l(s(.(x))) 
.l(x)}. 
Notice, that it was sufficient to consider only some upper portion of the 
tree. In general, if a covered call has s answers in the CE-cover, then only s 
derivations, which are passing it should be considered (this can be implemented 
by applying the corresponding tabulation mechanism). In the case of OLD* 
resolution by allowing to consider several answers we extend the algorithms 
of [11, 12], where only one answer can be considered. In complex applications 
similar to meta-programs specialisation multiple answers can help to increase 
the granularity of residual programs. By using OLD* resolution with CE-covers 
having only singleton sets of answers, our algorithm reduces to that [12]. On 
the other hand in the example above the specification of the pair of answers 
was important and was used in another way (otherwise the goal reconstruction 
would not be possible). 
The new program H is the odd numbers program. This kind of transforma- 
tions cannot be produced using the frameworks of [11, 12, 17, 22, 23] (in our case 
it has been possible due to incorporating of special information about the source 
program). This example shows that our approach can be used in a problem spe- 
cific way by introducing specialised equivalence relations. We expect that very 
interesting transformations can be obtained by using equivalence relations over 
blocks Of unbounded size (the number of equivalence classes should be finite). 
In this way folding of an infinite number of atoms can be derived (the recent 
paper [4] gives an example). Equivalence relations of the latter kind can produce 
transformations similar to [6, 8]. Extensive examples of standard "finite" fold- 
ing transformations, which can be obtained by applying a weaker version of the 
presented algorithm are given in [1, 2]. 
5 
Conclusion 
and Related 
Work 
Our framework allows to consider the source logic program as a "runnable" 
specification, which should be used to derive a "real" program, which satisfies 
some requirements. Indeed, one can perform the following step: 
1. Choose the most suitable abstract domain for the program at hand. The 
domain should satisfy the necessary conditions for the correct application 
of an abstract tabulation mechanism (see for example [16, 7]). This step is 

49 
not formal and should take into account all available information about the 
program and its application (sometimes it can be provided by the users of 
the program). 
2. In terms of the abstract domain specify the desired call/exit patterns of the 
target program. The following items can be specified: 
- What should be factored out by partial evaluation 
- The macro structure of the program, i.e. the number of the definitions 
and their granularity 
- The internal structure of the clauses 
Prove by applying an abstract tabulation technique, that the specified 
call/exit patterns imply the existence of an EOLD tree. 
3. Apply the algorithms described in sections 3.3 and 3.4. 
The basic ideas of.the approach allow to integrate in one toolkit lots of 
existing transformation techniques for definite logic programs [18, 13, 11, 12, 
22, 23] combined with high level concepts to specify the properties of the target 
program and possibilities to incorporate problem specific information. It seems, 
that the development of a general form for the requirements on the equivalence 
relations over the set of blocks is a promising direction of research. 
References 
1. Boulanger,D., Bruynooghe,M., Deriving Transformations of Logic Programs us- 
ing Abstract Interpretation, Logic Program Synthesis and Transformation (LOP- 
STR'92), eds. K.K.Lau and T.Clement, Workshops in Computing, Springer Verlag, 
1993, 99-117. 
2. Boulanger,D., Bruynooghe,M., Deriving Fold~Unfold Transformations of Logic 
Programs Using Eztended OLDT-based Abstract Interpretation, J. Symbolic Com- 
putation, 1993, Vol.15, 495-521. 
3. Boulanger,D., Bruynooghe,M., Using Abstract Interpretation for Goal Replace- 
ment, Logic Program Synthesis and Transformation LOPSTIt'93, Workshops in 
Computing, Springer-Verlag, 1993. 
4. Boulanger,D., De Schreye,D., Compiling Control Revisited: A New Approach based 
upon Abstract Interpretation, Proc. ll-th Int. Conf. Logic Programming, 1994, 
699-713. 
5. Burstal],R., Darlington,J., A Transformation System for Developing Recursive 
Programs, JACM, Jan.1977, Vol.24, No.l, 44-67. 
6. Bruynooghe,M., De Schreye,D., Krekels,B., Compiling Control, J. Logic Program- 
ming, 1989, Vol.6, Nos.2-3, 135-162. 
7. Codognet,P., File, G., Computations, Abstraction~ and Constraints in Logic Pro- 
grams, Proc. 4 th Int. Conf. on Programming Languages, Oakland, USA, April 
1992. 
8. De Schreye,D., Martens,B, Sablon,G., Bruynooghe,M., Compiling Bottom-Up 
and Mired Derivations into Top-Down Ezecutable Logic Programs, J. Automated 
Reasoning, 1991, 337-358. 
9. Eder,E., Properties of Substitutions and Unifications, J. Symbolic Computation, 
1985, Vol.1, No.l, 31-46. 

50 
10. Palaschi,M., Levi, G., Martelli,M., Palamidessi, C., Declarative Modelling of the 
Operational Behaviour of Logic Languages, Theoretical Computer Science, 1989, 
Vol.69, No.3, 289-318. 
11. Gallagher,J., Bruynooghe,M., Some Low Level Transformations of Logic Pro- 
grams, Proc. 2 '~d Workshop in Meta-Programming in Logic, Leuven, 1990, 229- 
244. 
12. Ga]lagher,J., Bruynooghe,M., The Derivation of an Algorithm for Program Spe- 
cialisation, New Generation Computing, 1991, Vol.9, 305-333. 
13. Gardner, P., Shepherdson, J., Unfold/Fold Transfo~rnations of Logic Programs, 
Computational Logic, Essays in Honour of Alan Robinson, eds. J.L.Lassez and 
G.Plotldn, MIT Press, 1991, 565-583. 
14. GMlagher, J., Codish M., Shapiro E., Specialisation of Prolog and FCP Programs 
Using Abstract Interpretation, New Generation Computing, 1988, Vol.6, Nos.2-3, 
159-186. 
15. 
Kawamura, T., Kanamori, T., 
Preservation of Stronger Equivalence in Un- 
fold/Fold Logic Program Transformation, 
Proc. 4 eh Int. Conf. on FGCS, 
Tokyo,1988. 
16. Kanamori, T., Kawamura, T., Abstract Interpretation Based on OLDT Resolution, 
J. Logic Programming, 1993, Vol.15, Nos.l-2, 1-30 . 
17. Kawamura, T., Derivation of Efficient Logic Programs by Synthesising New Pred- 
icates, Proc. 1991 Int. Symp. on Logic Programming, San Diego, 1991, 611-825. 
18. Lloyd,L, Shepherdson,J., Partial Evaluation in Logic Programming, J. Logic 
Programming, 1991, Vol.ll, Nos.3-4, 217-242. 
19. Lassez, J.-L., Maher, M., Mariott, K., 
Unification Revisited, Foundations of 
Deductive Databases and Logic Programming, ed. J.Minker, Morgan-Kaufmann, 
1988, 587-625. 
20. Lloyd,L, Foundations of Logic Programming, Springer-Verlag, Berlin, 1987. 
21. Maher,M., Equivalences of logic Programs, Foundations of Deductive Databases 
and Logic Programming, ed. J.Minker, Morgan-Kaufmann, 1988, 627-858. 
22. Proietti,M., Pettorossi,A., Construction of Efficient Logic Programs by Loop Ab- 
sorption and Generalisation, Proc. 2 nd Workshop in Meta-Programming in Logic, 
Leuven, 1990, 57-81. 
23. Proietti,M., Pettorossi,A., Unfolding- Definition- Folding, In this Order, For 
Avoiding Unnecessary Variables in Logic Programs, Proc. 3 "d Int. Syrup. on Pro- 
gramming Languages Implementation and Logic Programming, Aug. 1991, LNCS 
No.528, Springer-Verlag, 1991, 347-358. 
24. Seld,H., Unfold/Fold Transformation of stratified programs, J. Theoretical Com- 
puter Science, 1991, Vol.86, 107-139. 
25. Tamaki,H., Sato,T., Unfold/Fold Transformation of Logic Programs, Proc. 2 '~d 
International Conference on Logic Programming, Uppsala, 1984, 127-138. 
26. Tamald,H., Sato,T., OLD Resolution with Tabulation, Proc. 3 ~d Int. Conf. on 
Logic Programming, London, July 1986, 84-98. 

A Transformation System for Definite 
Programs Based on Termination Analysis 
3. Cook and J.P. Gallagher* 
Department of Computer Science, University of Bristol, Bristol BS8 1TR, U.K. 
Abstract. We present a goal replacement rule whose main applicability 
condition is based on termination properties of the resulting transformed 
program. The goal replacement rule together with a multi-step unfold- 
ing rule forms a. powerfld and elegant transformation system for definite 
programs. It also sheds new light on the relationship between folding 
and goal replacement, and between different folding rules. Our explicit 
termination condition contrasts with other transformation systems in 
the literature, which contain conditions on folding and goal replacement, 
often rather complex, in order to avoid "introducing a loop" into a pro- 
gram. We prove that the goal replacement rule preserves the success set 
of a definite progranl. We define an extended version of goal repla.cement 
tha.t also preserves the finite f~dlure set.. A powerful folding rule can be 
constructed as a special case of goal replacement, allowing folding with 
recursive rules, with no distinction between old a.nd new predicates. A 
proof that Seki's transformation system preserves recurrence, an impor- 
tant termination property, is outlined. 
1 
Introduction 
In this paper we define a goal replacement rule (for definite programs) based on 
termination analysis. Under the conditions of the rule, a replacement can only 
be made if the resulting program terminates for all ground calls to the head of 
the transformed clause. We show that. application of this rule to a program will 
preserve its success set. The finite fa.ilure set can also be preserved by adding a 
similar termination condition on the program being transformed. We also give a 
definition of a more genera.1 unfolding rule which is based on a partial evaluation 
rule discussed in [LSgl] and [(;S.~l]. 
On reviewing the literature regarding folding and goal replacement, it was ap- 
parent that the underlying issue (when considering the correctness of such rules) 
was the termination of the resulting program. This was particularly evident in 
[Sek891 and [BCE921. 
In the first of these papers, Seki, discussing the unfold/fold transformations 
of Tamaki and Sato [TS84], noted that a goal may not terminate in a program 
resulting from a Tamaki-Sato folding rule, even though it finitely failed in the 
original program. To combat this, Seki proposed a refornmlated folding rule. 
* Correspondence to jpg@compsci.bristol.ac.uk 

52 
Under the conditions of [BCE92], a goal replacement can be made provided that 
'a loop is not introduced' into the progrmn. This is clearly a reference to some 
termination properties of the transformed program. 
It should be noted that the originM unfold/fold transformations for fimctional 
programs [BD77] preserves only partial correctness. Total correctness, that is, 
termination, has to be established separately. 2 In logic programming, starting 
with the work of Tamaki and Sato [TS84], the tradition has been to devise 
conditions on unfolding and folding that implicitly guarantee total correctness 
results. Recently, conditions on goal replacement requiring 'reversibility' of goal 
replacement have been proposed by Proietti and Pettorossi [PP93], stressing the 
preservation of partial and total correctness as separate concerns. This work is 
in the same spirit as ours though the approach differs. Our goal replacement is 
not reversible, but still preserves total correctness (in the sense of the program's 
success set). 
The link between transforn-mtion rules and termination analysis provided us 
with the motivation for the system we present. The main difference of approach 
between our work and the works just cited (and a.lso [GS91], [Mah871, [Sek891 
and others) is t.hat in our goal replacement rule termination of the transformed 
program is a condition of application of the rule, and we leave open the means 
by which t, ernaination is checked. Air.hough the problem of checking goal re- 
placement conditions is thereby shifted to checking termination properties, the 
advantage gained is that the link between folding and goal replacement is clari- 
fied. More flexible folding rules can be invented, as we show below. Also, research 
on termination analysis can be brought to bear on the problem. 
We note that Boulanger and Bruynooghe [BB93] also developed an approach 
to goal replacement that is based on generation of replacement lemmata during 
an abstract interpretation of the program. This approach also seems capable 
of performing fold-like operations that are less restrictive than usual, allowing 
folding with recursive rules, for instance, s 
There are two alternative strategies for implementing our transformation 
rules. One possibility is to use termination analysis techniques, to check ter- 
mination of a transformed program directly. Secondly, special cases of the goal 
replacement can be derived, in which syntactic conditions ensuring termination 
are checked. This suggest a reconstruction of 'fold' transformations. In general 
the first approach seem the more promising, since it seems very difficult to find 
syntactic conditions that guarantee usefill termination properties (such as ac- 
ceptability [AP90]). 
Section 2 contains a review of logic program transformation systems. In Sec- 
tion 3 we introduce our transfonna.tion rules and prove the correctness results. 
In Section 4 termination analysis is reviewed. An example of our system is given 
in Section 5. We show that our replacement rule allows 'foldings' to be based on 
2 We are grateful to A. Pettowssi for this pertinent colmnent 
* We have been informed that folding using reeursive rules was also considered in 
unpublished technical reports by Ta.maki and Sato (1986), and by Kanamori and 
Fujita (1986). 

53 
equivalences that depend on recursive definitions of predicates. This is not al- 
lowed in other unfold/fold transformation systems. An informM proof that Seki's 
transformation system preserves recurrence can be found in Section 6. Finally, 
Section 7 is a short concluding section and some thoughts on future research 
directions. 
The terminology used throughout this paper is consistent with that of [Llo87]. 
2 
Background 
2.1 
Unfold/Fold 
of Definite Programs 
In [TS84] the notion of a transformation sequence for definite programs was 
introduced. 
Definition l. An initial program, P0, is a definite program satisfying the fol- 
lowing conditions: 
- P0 is divided into two sets of clauses, P, ..... and fold. The predicates defined in 
Pnew are called new predicates, l.hose defined in Pold are called old predicates. 
- Predicates defined in P,~ ..... do not appear in Pold nor in the body of any 
clause in P,C~,,,. 
The clauses defining new predicates a.re considered as new definitions; we note 
that they cannot be recursive. 
Definition 2. Let. P0 be an initial program, and Pi+l a program obtained from 
Pi by applying either unfolding or folding for i > 0. The sequence of programs 
Pc),..., Pn is called a t.ransfornJa.tion sequence sta.rting fl'om P0. 
We do not repeat the definition of the unfoht and fold rules from [TS84] 
here, but note that folding depends on the distinction between old and new 
predicates in the initial program. In a folding tra.nsfornm.tion applied in Pi in a 
transformation sequence, the clause used for folding is one of the clauses defining 
a new predica.te. Thus folding in [TS84], and other systems derived from it, is 
not defined as a t.ransformation on a. program, but rather ~s a transformation 
on a sequence of programs. 
Denoting the least I]erbra.nd model of a program P by M[P], the main result 
of [TS84] is the following. 
Proposition3. Let Po,..., Pn be: a transformation sequence starting from Po 
which uses Tamal~:i-5'~o m@,lding and folding. Then M[Po] = M[P,]. 
Although the unfolding and folding rules of [TS84] preserve the suec.ess set of 
a program, they do not preserve its finite fa.ilure set. Sonre queries that finitely 
failed in an origina.l program may not terminate after the transformation has 
been applied. [Sek89] proposes a. modified folding rule based on the notion of 
an inherited atom. (Although Seki's transformations are defined for normal pro- 
grams, we restrict our attention to definit.e programs here). 

54 
The fold-unfold system using Seki's fold rule preserves the finite failure set 
of a program as well as its minimal model. Let FF[P] denote the finite failure 
set of P, 
Proposition4. 
Let Po .... , P,~ be a tram@~rmation sequence starting from Po 
wh.ich, uses unfolding as in [TS84], and th.e fohling rule in [Sck89]. Th, en FF[Po] - 
FF[P,,]. 
A property of Seki's transforrnation system will be considered in Section 6. For 
the rest of the paper we refer to the success set SS[P] rather than M[P] for a 
program P, for symmetry with FF[P]. 
Transfornaation rules (for normal programs) are also considered by Gardner 
and Shepherdson in [GSgl]. The unfolding rule (restricted to definite programs) 
is the same as that of [TS84]. The unfolding rule is used in conjunction with a 
reversible folding rule, sirnilar to that of [Mah87], in which the folding clause is 
taken from the current program rather than fi'om the initial program. Folding 
can be reversed by unfolding using these rules, and thus the correctness of folding 
follows from the correctness of unfolding. This elegant framework is independent 
of any transformation sequence. However, as a consequence of this, the frame- 
work appears to be less usefill for pra.ctical purposes than the transformation 
system proposed in [TS84], in which the equivalences on which-the foldings are 
based come from a set of cla.uses in the fixed initia.l program, and so are not 
altered during a trarlsforlnation sequence. 
By proving that their folding rule is the inverse of unfolding, Gardner and 
Shepherdson are able to show that their system preserves procedural equivalence 
based on SLDNF-resolution. For definite programs, therefore, both the minimal 
model and the finite failure set. are preserved. 
2.2 
Goal Replacement 
The goal replacement operation was defined in [TS84] to increase the power of 
the unfold/fold transformation system. In general, the rule is the replacement of 
a clause in P of the form 
C : A +- At .... , At,, Ak+l .... , A,. 
by the clause 
C' : A ~ B1 ..... B,~,Ak+I ..... A, 
to form the program P' = P - {C} U {C'}, where A1,...,A~: and B1,...,Bm 
are in some sense equivalent in P and P'. (We consider replacing only some left 
conjunct of the body, without loss of generality). 
Tamaki and Sato claimed that their goal replacement rule preserved the least 
Herbrand model of P. tlowever, [GS91] gives a counter-example to this claim and 
defined a goal replacement rule with stronger applicability conditions. Gardner 
and Shepherdson show tha.t the least tterbrand model is preserved by their goat 
replacement transformation. 

55 
One motivation of our work is to provide a goal replacement rnle so that 
folding is a special case, and more flexible folding rules can be derived. 
This was also one of the aims of Bossi el al. [BCE92]. A replacement operation 
(for normal programs) is defined in [BCE92]. Applicability conditions are given 
in order to ensure the correctness of the operation with respect to Fitting's 
semantics for normal programs. These semantics are based on Kleene's three- 
valued logic, the truth values being true, false, and undefined. 
The conditions for goal replacement there are based on the rather complex 
notions of 'semantic delay' and 'dependency degree'. It is explained in [BCE92] 
that the applicability conditions are to ensure that there is 'no room for introduc- 
ing a loop'. When the program P is transforlned to P~, under the applicability 
conditions: 
- the dependency degree is an indication of how big a loop would be. 
- the semantic dela.y is a.n indication of the space in which the loop would be 
introduced. 
The transformation rules in [BCE92], though complex, provided us with the 
inspiration to search for more general conditions for goal replacement by inves- 
tigating the problem of termina.tion, since avoiding the 'introduction of a loop' 
seems to be the main int, uition behind the work outlined above. 
3 
A Transformation 
System 
Based 
on Termination 
Analysis 
In this section, we apply some of the ideas from the survey in Section 2 to 
develop a new transformation system. The main idea is that a goal replacement 
operation should depend on the notion of termination. Furthermore, we claim 
that this approach sheds light on other transforma.tion systems. 
We present two transformation rules for definite programs and prove that if 
the progra.m P' results from the tra.nsforma.tion of P under these rules then P and 
P~ have the same least Herbrand mode[. The rules are, the unfold rule (Definition 
5) based on partial evaluation, and the goal replacement rule (Definition 8) based 
on termination analysis. We do not consider a rule to introduce new definitions 
since we ma.y consider all such definitions to have been introduced in the initial 
program of a tra.nsformation sequence. 
3.1 
Unfolding 
Definition 5. Let. P be a definite program and C a clause in P of the form 
A~Q 
where Q is a conjunction of atoms (possiMy empty). 
Build an (incomplete) SLD-tree for P U {~-- Q} via. some computation rule. 

56 
Choose goals ~-- G1,.,., ~-- G,, such tha.t every non-failing branch of the 
SLD-tree contains precisely one of them. Let Oi be the computed answer for the 
derivation from ~ Q to ~ 
Gi, (i = 1 .... , r). 
The result of unfolding C on B in P is the definite program P' formed from 
P by replacing C by the set of clauses {C1,..., Cr}, where Ci = AOi *-- Gi. 
Theorem 6. Let the definite lnvgram P' be obtained by applying an unfold trans- 
Iorm.ation to a clause in P. Then SS;[P] = S'S[P'] and FF[P] = FF[Pq. 
The proof is drawn from a special case of partial evaluation which is discussed 
in [LSgl] and [GSgl]. Note that the extension of the usual 'one-step' unfold rule 
to the 'multi-step' rule above is more than just convenience; there are unfoldings 
using Definition 5 that cannot be reproduced by a series of one-step unfoldings, 
since a clause being used for unfolding nlay itself be modified as the result of a 
single unfolding step. 
3.2 
Goal Replacement 
Let Q1 ~v Q2 in P denote a notion of computational equivalence of formulas, 
in the following sense. 
Definition 7. Let Ol aim 02 be conjunctions of atoms a.nd V a set of variables. 
We write Q1 =v Q2 in P if 
- 3or such that P U {~- Q1 } has an SLD-reflltation with computed answer o', 
where crlv = 0 
r 
3p such that P tO {,,--- Q~} has an SLD-reflltation with computed answer p, 
where Ply = 0 
In other words the computed answers for goals +- Q1 and ~ Qu agree on the 
va.riables in V. 
Definition 8. goal replacement 
Let P be a. definite program and C a (non-unit) clause in P of the form 
A~Q1,Q 
where A is a.n atom and Q1,Q conjunctions of at, ores. Let R be a computation 
rule, and let vats(A, Q) denote the set of va.riables occurring in either A or Q. 
Form P' from P by replacing C by the clause 
A +---O2,O 
where both of the following conditions are satisfied: 
- Q1 =--va.rs(A,Q) Q2 in P. 
- For all ground instances A' of A, the SLD-tree for P' tO {+- A'} via R is 
finite. 

57 
Note that the definition refers to t.erminatiol~ (finiteness of a.n SLD-tree) 
via a particular computation rule. One can use whatever computation rule one 
chooses in order to check termination. In practice one is probably interested in 
'standard' computation rules such as the Prolog leftnmst selection rule. The or- 
der of atoms in clause bodies and the computation rule are interdependent. For 
simplicity in the definition we have assumed that goal replacement takes place 
on the left part of the body, but with a fixed computation rule such as Prolog's 
this restriction needs to be relaxed. The definition is also asymmetric, in that 
we check the termination property in P' only. This reflects the directed nature 
of the transformation sequence, and the concern not, to introduce loops during 
transformations. Tile second condition could also be weakened by checking ter- 
mination of derivations starting with the transforlned clause only (rather than 
all derivations of atomic goals unifying with its head). 
The main correctness result for the goal replacement transformation is the 
preservation of the success set (Theorem 10). We shall see later that a symmetric 
version of the goal repla.cement rule, with an extended notion of goal equivalence, 
preserves the finite failure set as well (Theorem 15). 
We start by proving a lemma sta.ting that goals which succeed in P do not 
finitely fail in P'. Note that this lemma does not require the termination condi- 
tion in the goal replacement rule, but simply uses the properties of goal equiv- 
Mence. In a sense this lemma estal)lislles a "partial correctness" result, and the 
termination condition will be used to establish total correctness. 
Lemma9. 
Let the definite program. P' be obtained by applying a goal replace- 
meat transformation to a clavsc in P. Th.cT~. for all definite goals +- B, 
P' o {*-- B} has a .fi,,itely f(~ilcd SLD-tre~. implies *hat P to {~-- B} has no 
SLD-refulalion. 
The proof of this lemma is in tile appendix. 
Theorem10. 
Let the definite program P' be obtained by applying a goal re- 
placement, tra,,.sfovma*io,,, *o a clause: i,,. P. The,,. SS[P] = SST[P']. 
Pro@ The proof is in two stages. We show that: 
1. SS[P'] C SS[P] 
2. SS[P] C SS[P'] 
Stage 1: let A' E SS[P']; show by induction on the length of the shortest 
SLD-refutation of P' tO {~-- A'}, that there is an SLD-refutation of P tO {,-- A'}. 
Let SS k [P'] be the set of atoms A such tha.t P' tO {~-- A} has an SLD-refntation 
of length at most k. 
For the base cruse, suppose A' E 5'5 'I[P']. This means that A' is a ground 
instance of the head of a unit clause D in P'. Goal replacement does not affect 
unit clauses, so D is also in P, Therefore P to {+-- A'} has an SLD-refutation of 
depth 1. 

58 
For the induction step, assume that P tO {~-- A'} has an SLD-reflltation for 
all A E SS ~,[P']. Suppose that A' E SS k+l [P'] and let T' be an SLD-refutation 
of P' tO {~ A'} of length k + 1. Suppose the first clause (variant) used in T' is 
C~:H~S. 
If C'r is not. the result of the goal replacement, then C~ is also in P. Let 
mgu(A ~, H) = p; then P'U {~--- Sp} has an SLD-refutation of length k with 
computed answer or, say. Let, Spa7 be any ground instance of Spot. Then for 
each ground atom A in SpOrT, P' U {*-- A} has an SLD-refutation of length at 
most k and so by the induction hypothesis, PU{~-- A} has an SLD-refiltation. It 
follows that PLJ{~--- SporT} has an SLD-refutation and hence so has PtO{*-- Sp}. 
Therefore P tO {~-- A ~} has an SLD-refutation using C~ on the first step. 
If Cr is the clause produced by goal replacement we have 
C,. : A ~-- O2, Q in P' 
which repla.ced 
C:A 
~-- 01, O ill P 
where A' is unifiabh~ with A with mgu 0. Then P' U {~--- (Q~, Q)O} has an SLD- 
refutation and hence P'tO{~-- Q~O} has an SLD-refilta.tion with computed answer 
o', say, and P' to {~-- QOa} has a. refittation with computed answer ~r, say. 
Using the inductive hypothesis a.pplied to the atoms in any ground instance 
of Q.20r we can show that P tO {~--- @20} a.lso has an SLD-refutation with com- 
puted answer o'. Since Q1 =--v',,r,~(A,Q) @2 in P, and since 0 acts on variables in A, 
P U {~---- QIO} has an SLD-refi~tation with computed answer &, where r agrees 
with & in variables of AO and QO. Also by the inductive hypothesis applied to 
any ground instance of Q0a, cr it follows that P U {*-- Q&~} has a refutation 
with computed answer or. Itence P to {~--- QOd,} has a refiltation with computed 
answer or: Putting the goals together it follows that P U {~--- (Q1, Q)0} has an 
SLD-reflltation. Therefore, P U {+-- A ~} has an SLD-reflltation using clause C 
on the first step. 
Stage 2: let A' E 3',5'[P] and show that A E SS[P']. Proof is by induction on 
the length of an SLD-refutation of P u {+- A'}. 
The base case is similar to the base case in Stage 1. For the inductive step, 
consider an SLD-reflltation of P O {+-- A'} of length k + 1, using C,. on the first 
step. If C~ is not the clause used in goal repla.cement the argument is identical 
to the corresponding step in Stage 1. 
If C,. is the clause used in goal repla.cement, then A' is a ground instance of 
the head of C,., and thus also of the head of the clause that replaces (Jr. By the 
termination condition on goal repla~cement, P' tO {~-- A'} has a finite SLD-tree, 
so it is either a finitely-failed tree, or contains a reflitation. Suppose P'U {+-- A'} 
has a finitely-failed SLD-tree. Then by Lemma 9 P tO {+--- A ~} has no SLD- 
reflltation. But this contradicts the inductive hypothesis. Hence P' W {~-- A'} 
has an SLD-reflltation. cq 
We conjecture that the set of computed answers is also preserved, since goal 
equivalence is based on equivalence of computed answers. 

59 
There is an obvious corollary to q'heorems 6 arm 10, wlfich is the basis for 
reconstructing folding as a specia.l ca.se of goal replacement. 
Corollary 11. Let Pc,,...,Pk be a transformation sequence using unfold and 
goal replacement rules. Lct Q1 =-v Q'2 in Pi for some 0 <_ i < k. Then Q1 =v Q2 
in Pj, O < j < k. 
In particular, if there is a. clause A +-- Q in some Pi, where A has no common 
instance with any other clause hea.d in Pi, then A -=~(A) Q holds in Pi. There- 
fore it holds in subsequent programs in the sequence aim the clause can be used 
for goal replacement ill subsequent programs. In other words, if a clause of form 
H *--- QO, R occurs in some Pj, where j > i. it may he replaced by H ~-- AO, R 
in Pj+I provided that 
1. Variables in w~rs(Q)/w~rs(A) are mapped by 0 into distinct variables not 
occurring in H, AO or R. (This is sutficient to establish the first goal re- 
placement condition t, ha,t QO --w+,rsCH,/+) AO). 
2. Pj+~ U {~--- H') has a finite SLD-tree (via some computation rule) for all 
ground instances H' of H. 
~e 
Tlfis avoids the restrictions on folding present in [TS84], iS k89], [GS91] and so 
on, that folding clauses define "new" predicates and are non-recursive. In Section 
5 there is an exanaple of a. "fold" transforma.tion using a recursive definition, 
which would not be possible with other fold rule based on [TS84]. Our goal 
replacelnent condition Mso avoids the ra, ther conaplex syntactic conditions that 
are typical of folding rules. 
In the literature there are two distiuct flavours of folding. In [TS84] and 
related systems, fohling is dofined on a. transforrnation sequence, a.nd t.he clause 
used for folding might not be in the program to which folding is applied. By 
contrast, [GS91] and [Mah87] give a lnore elegant folding rule in which the 
folding clause comes from the program being transformed. These two folding 
rules are quite different in power. Both of thena can be viewed as special cases 
of our goal replacement rule. 
3.3 
Preserving the Finite Failure Set 
The goal replacement rule does not pr(~serve the finite failure set. Preserving 
finite failure is desirable in some contexts, and so we strengthen the definition of 
goal equivalence in Definition 7, by insisting that the equiwdent goals have the 
same failing behaviour as well as computed answers. 
Definition 12. Let. QI and Q.., be conjunctions of atoms and V a set of variables. 
We write Q1 =v Q2 in P if 
- 3er such that P U {~--- Q1} has an SLD-reflltation with computed answer er, 
where er]v = 0 
<~> 
3p such that P W {+- Q2} has an SLD-refutation with computed answer p, 
where ply = 0, and 

60 
-- for all substitutions 0 acting only on variables in V, 
P U {,-- QIO} has a finitely failed SLD-tree 
r 
P U {~ Q20} has a finitely failed SLD-tree. 
Assume now that the goal replacement transformation (Definition 8) refers to 
equivalence in the sense of Definition 12. We can then prove a stronger version 
of Lemma 9. 
Lemlna 13. Let the definite program P' be obtained by applying a goal replace- 
ment, transformation to a clause in P (using Definition 12 and Definition 8). 
Then for all definite goals ~ B, 
P' U {~--- B} has a finitely fa.iled SLD-l, ree 
:=~ P tO {,-- B} has a finitely failed SLD-lree. 
Proof. (outline) 
The proof is similar in structure to the proof of Lemma 9, and does not use 
the termination condition on goal replacement. The key step is the construction 
of a finitely-failed SLD tree for a computation of form P LI {+-- (~1, R)0} given 
a finitely-failed SLD tree for P U {~-- (Q'e, R)O}, where Q1 =v Q~, 0 acts only 
on V, and R is some conjunction, ca 
Note that the converse of I, ernma 13 does not hold. A goal may fail finitely in 
P but loop in P', as the following example shows. 
Example 1. Let P = {p ~ q(X), q(f(X)) *-r(X)}. Then q(X) ~{x} ,'(X) 
and we can replace r(X) by q(X) in the second clause, since the termination 
condition is satisfied. We obtain P' = {p +- ,t(X), q(f(X)) ~ q(X)}. PU{*-- p} 
has a. finitely failed SLD tree but P' O {~- p} loops. 
As noted above, the goa.l replacement rule is a symnaetric in that termination 
is checked only in the program after transformation. Clearly by virtue of Lemma 
13 a symmetric version preserves the finite failure set as well as the success set. 
Definition l4. (symmetric goal replacement) Let P be transformed to P' by 
goal repla.cement a.s defined in Definition 8 with Definition 12. If P can also be 
obtained from P' by goal replacement, then we say P' is obtained from P by 
symmetric goal replacement. 
Theorem 15. Let P' be obtained from P by symmetric goal replacement, Then 
SS[P] = SS[P'] and FF[P] = FF[P']. 
Proof. Using Theorern 10 and Lemma 13.D 
Corollary 11 holds with respect to the symmetric goal replacement transfor- 
ma.tion and the extended definition of goal equivalence. Thus folding transforma- 
tions that preserve the finite failure set can be constructed as goal replacements. 

61 
4 
Termination of Definite Programs 
We now turn our attention to tim topic of termination analysis, which is needed 
in order to verify the conditions for our goal replacement rule. There. has been 
a great deal of research effort addressing many aspects of termination analysis. 
This research has branched into naa.ny different directions becanse of the variety 
of definitions that exist for termination. The question of what is meant by a 
terminating program depends principally on such matters as the procedural 
semantics employed, the different modes of use of a program, and the fact that 
logic programs can be nondetenninistic. This summary relies to a great extent 
on the survey in [DV92]. 
We may wish to consider either existential or universal termination, the for- 
mer being termination because of finite fa.ilure, or because at least one sohltion is 
found (even though the program couhl lmve entered an infinite computation after 
finding such a solution), the latter being termination of the entire computation 
(all solutions having been found). 
There are two different a.pproa.ches in the resea.rch. The approach taken in, 
for example, [UV88] and [P1ii92] looks t.o the provision of sufficient conditions for 
the termination of a logic program with respect to certain classes of queries that 
can be automatically verified. An alternative approach is taken in such papers 
as [VP86], [Bez89], [AP90] and {DW392], where theoretical frameworks to solve 
questions about termination are offered. 
Both [UV88] and [Plii92] use reasoning with linear predica.te inequalities 
to generate termination proofs. The termina.tion dealt, with in [Plii92] is left.- 
termination (i.e. termination under the left-to-right computation rule) of pure 
Prolog programs with respect to goals with input terms of known mode. 
The concept of a. level mapping is int, roduced by Bezem in [Bez89]. Denoting 
the Herbrand base of a. program P by [~,,: 
Definition 16. A level mapping tot a definite program P is a mapping 
I'l :Up --+ N. 
The necessary decrease in measure for establishing termination through recursive 
clauses is ensured by the restriction of Bezeln'S work to a particular class of 
programs- those which are recurrent. 
Definition17. A definite program P is recurrent if there is a level mapping }.1 
such that for each ground instance A ~-- [3j,..., Bn of a clause in P, we have 
IAI > IB~[ for each i = 1,..., 7~. A program is recurrent if it is recurrent with 
respect to some level mapping. 
Note that, in tile above definition, there is a. decrease in measure between the 
head and body of every clause of the program. The main result of [Bez89] is that 
a logic program is terminating (with respect to ground goals and an arbitrary 
computation rule) if and only if it is recurrent. 
Recurrency with respect to I.} can be used to infer termination of non-ground 
goals whose ground instances have a. maxinmm value with respect to 1.l- 

62 
The ideas of [BezS9] are addressed with respect to termination in the left-to- 
right computation rule by Apt and Pedreschi in [AP90]. Many practical programs 
terminate under the Prolog selection rule (when given the correct class of inputs) 
even though they are not recurrent. As a result, in [AP90] the notion of a recur- 
rent program is replaced by that of an acceptable one. Apt and Pedreschi prove 
that the notions of left-termination and acceptability coincide. 
Some limitations of these approaches, with respect to automating the analysis 
of termination, are discussed by De Schreye et al. in [DVB92]. where extended 
notions of level mappings and recurrency are introduced. They introduce the 
notion of recurrency with respect to a set of atoms .5". The key results in [DVB92] 
are that: P is recurrent with respect to S if and only if it is terminating with 
respect to S, and that P is recurrent if and only if it is recurrent with respect 
to Bp. 
5 
Example 
This section contains an example of a program transformation under our rules 
in which the goal replacement stages cannot be made under the fohling rule of 
[TS84], [Sek89] or [GS91]. This suggests that our systeln could be used to achieve 
more flexible folding rules, using, say, recursive definitions of new predicates. The 
example also illustrates the use of both recurrence and acceptability to establish 
applicability of goal replacements. 
Example 2. Let p0={C1,...,(7q},where 
C1 : append([], x.s, xs). 
C~: append([xlxs], ys, [x[zs]) +--- append(xs, ys, zs). 
C3: leaves(leaf(,v), [x]). 
(:4 : leaves(tree(x, y), zs) +- 
leaves(x, xs), leaves(y, ys), append(xs, ys, zs). 
Unfold C4 on the first atom to obtain p1 : (pO/{c4}) tO {C5, Ce;}, where 
c'~ : lea~es(t~ee(lea~(x'), 
.V), [*'l~s]) ~- leaves(y, zs), 
C.~: leaves(t~ee(t~ee(~,', 
y'), y), ~.~') ~- 
leaves(,', xs'), Zeaves(y', V,'), append(.~,,', ys', z,'), 
mea~es(y, y.,'), appene(zs', V.~, zs). 
Goal Replacement 1 
Replacement of append(xs', ys', zs'), append( zs', ys, zs) by 
append(ys', ys, vs), append(xs', v.s, z.s) in Ct~ to give p2 : 
C1 : append([], xs, xs). 
c~: append([~,~l.~s], >% [.~:l:'q) ~- appe~d(.~,s, ys', z.~). 
C3 : leaves(leaf(a:), [X]). 
(7:5 : leaves(tree(leaf(a:'), y), [*'b~]) ~- leaves(y, zs), 
c'~ : meaves(t~ee(t~ee(.,:', 
.~/), .~j), :s) ~-- 
leaves(;,,", *s'), leaves(y', y,'), leaves(y, V*), 
append(Ys', ys, vs), append(xs', vs, zs). 

63 
Goal Replacement 2 
Goal replace leaves(y', ys'), leaves(y, ys), append(ys', ys, vs) by 
leaves(tree(y', y), vs) in Cv to ohtain pa : 
C1 : append(~, xs, xs). 
C2: append([;/:lxs], ys, [xlzs]) ~-- append(xs, ys, zs). 
lea e- (lea (x), [.q). 
65: leaves(tree(lea:f(x'), y), [xtlzs]) *-- leaves(y, zs), 
c,: 
.r V), zs) 
leaves(.v', ,vs'), leaves(gree(y', y), vs), append(~:s', vs, zs). 
Goal Replacement 3 
Replac  lea e (x', 
:,j), 
appena( s', vs, zs) by 
leaves(tree(x', tree(y', y)), zs) in C's to obtain the final program p4 : 
Cl : append(~, xs, zs). 
C2: append([xlas ], ys, [.~:lzs]) ,-- append(xs, y.s, zs). 
63: leaves(leaf(:r.), Ix]). 
65: leaves(tree(leaf(a,'), y), [:r'l:s]) ~- leaves(y, zs), 
C9: leaves(tree(tree(x', y'), y), zs) -- leaves(tree(.~:', tree(J, 9)), zs). 
We must show that the conditions of goal replacement (Definition 8) are 
satisfied for the three repla.cements steps in this tra.nsformation sequence. The 
recurrence of p4 can easily be shown, which establishes the condition for the 
third goal repla.cement. For the first and second goal replacements, P~ and pa are 
not recurrent, so we need a more refined notion of termination than recurrency. 
The notion of acceptability from [DVB92] is appropria.te for these cases, since 
then we can prove termina.tion for gromld goals via. a left-to-right computation 
rule. In [Coo92] the detailed demonstrat.ions of the acceptability properties are 
given. 
The applicability of the transformations does not actually require the notions 
of recurrence or applicability, which collcern termination of all ground atoms, 
not just instances of the hea.d of the transformed clause. There is clearly scope 
for using still more limited notions of termination (such a.s those in [DV92]) in 
cases where neither applicability nor recurrence can be shown. 
6 
Termination 
Preservation 
It is interesting to examine current logic program transforma,tion systems with 
regard to termination properties, since our work is based on tile premise that 
termination properties a.re an essential ingredient in correct transformation sys- 
tems. In this section we consider termina.tion properties of the Seki transfor- 
mation system [Sek89] (restricted to definite programs). We show that Seki's 
transformation system preserves recurrence. This shows that, given a recurrent 
initial program, a Seki transformation sequence is a special case of our transfor- 
mations, since the Seki folding conditions are sufficient to establish recurrence 
and hence termination of the folded program. 

64 
Recently, Bossi and Etalle [BE94] have proved the stronger result that the 
Tamaki-Sato transformation system preserves another termination property, namely 
acyclicity. Although many typical terminating programs are neither recurrent 
nor acyclic these results are further evidence of the importance of termination 
properties in program transformation. 
6.1 
Preservation 
of Recurrence 
in Seki's System 
We first recall that a transformation sequence is a sequence P0,..-, Pn where 
Po = Pn.ew 0 Potd. Tile predicates in tile heads of clauses in Pne,~ are new predi- 
cates and the other predicates are old predicates. 
The unfolding rule is sta.ndard and we do not repeat it here. The folding rule 
depends on the notion of an inherited atom. We do not give the full definition 
of an inherited atmn here. Intuitively, an atom A in the body of a clause in Pi 
is inherited from P0 if 
- A was in the body of a clause in Prima,,, and 
- for each transforma.tion in the sequence up to Pi, A w~s neither the unfolded 
atom nor one of the folded literals. 
Seki's folding rule can now be defined. 
Definition 18. Let Pi be a. program in a. transfornmtion sequence and C a clause 
in Pi of form A +--- QIO, Q, where A is an atom and Q,, Q conjunctions of atoms. 
Let D be a clause in P,,,w of form B +--- Q1. Then the result of folding C using 
D is 
C' : A +-- BO, Q 
provided that all the following conditions hold. 
- For each variable occurring in Q1 but not in B, 0 substitutes a distinct 
variable not a.ppearing in C ~. 
- D is the only clause in Pn.e,u whose head is unifia.ble with BO. 
- Either the predicate in the head of(..' is an old predicate, or there is no atom 
in QIO which is inherited fi'om P0. 
The resulting program is P/+i = (Pi/{C}) 0 {C'}. 
We first state a lemma. (whose proof is in the appendix), and then the final 
result that recurrence is preserved by Seki's transformations. 
Lelnma 19. Let Po,..., P, be a .g. cl:i transformation sequence and let Po be 
recurrent. Then for all clauses A +-- B1,..., B,,. in Pi: 
(i) If A has an old urcdicatc, none of the: Bj is inherited from Po. 
(i.i) If By has an old predicate and is not inherited from Po, then for all ground 
i,~.stances (A +-- B, ..... 13,,,.)0 we h.a.ve IAOI - IBiO} > 2 for some level ma.p- 
vi,,.cj I.I- 
An outline proof of the lemma is in the appendix. 

65 
Theorem20. 
Suppose Po,,,., P,, is a Seki transformation sequence and Po is 
recurrent. Then Pn is recurrent. 
Proof. (Outline:) Suppose P0 is recurrent by some level mappingl.I ~. Construct 
a level mapping I-1 in the same way ,~s in Lemma 19. The proof is by induction 
on the length of the transformation sequence. The case for P0 is established by 
the construction of I.I. The inductive case for unfolding is a straightforward case 
analysis of the unfolding rule. For the folding case suppose Pi+l is obtained from 
Pi by folding C : A ~-- QxO, Q using the folding clause Co : B ~ Q1 in P,,~o to 
obtain C' : A ~-- BO, Q in Pi+l. By Lemma 19 and using the definition of folding, 
the 'distance' between A and each a.tom in QIO is at least 2 (with respect to 
level mapping I.]). Also, since Co e P,~etv the distance between B and Q1 is at 
least 1. Therefore the 'distance' between the head of C ~ and each atom in its 
body is at least 1. Therefore Pi+I is recurrent with respect to 1.1.[:3 
7 
Conclusion 
The results of this work can be summa.rised as follows: we have introduced a 
goal replacement rule based on terrninatioll analysis. By making the re(pdrement 
that all ground calls to the head of the transformed clause terminate, we have 
shown that the replacement rule preserves the snccess set of a definite program. 
Finite failure is preserved when a symmetric goal replacement rule is used, with 
an extended notion of goal equivalence. We have shown that a transformation 
system based on our rules can perform 'foldings' based on equivalences that 
depend on recursive definitions of predicates in the original program. Tamaki 
and Sato's folding rule and other similar versions do not allow this. Finally 
we have shown that Seki's unfold/fold rules (restricted to definite programs) 
preserve recurrence. 
The identification of terlnination as the key property could be said merely to 
shift the problem of checking goal replacement conditions to that of establishing 
termination properties. In practice this is so, but the advantages of doing this 
are that promising research on termination analysis can be brought to bear, and 
links between folding and goal replacement are clarified and strengthened. 
Two approaches to implementation ca.n be envisaged. Firstly, automated ter- 
mination analysis tools coukl provide direct checking of the goal replacement 
conditions (e.g. checking the transformed program for recurrence or acceptabil- 
ity). Secondly, we could search for some syntactic conditions that guaranteed 
applicability of the replacement rulel as in forms of 'folding' that are special 
cases of our replacement rule. 
Future research possibilities include the following. The repla.cement rule could 
be extended to normal programs. This is obviously dependent on advances in 
the termination analysis of such progra.rns, since finite faihlre is closely bound tip 
with termination analysis. The relat, iorlship between the goal replacement rule 
we have introduced and other existing goal replacernent/folding rules, such as 
[GS91] could be further investiga.ted. The termination properties preserved by 

66 
folding/goal replacement conditions in systems other than Seki's can be investi- 
gated. Application of the goal replacement rule can be extended by using weaker 
notions of termination (such as in [DVB92]). 
Acknowledgemellts 
We thank M. Proietti for pointillg out a serious error in a previous version. 
We also thank A. Pettorossi and the LOPSTR'94 referees for comments and 
corrections. 
References 
[AP90] 
[BB93] 
[BCE92] 
[BD77] 
[BE94] 
[Bez89] 
[Coo92] 
[DV92] 
[DVB92] 
[GS91] 
[Llo87] 
[LS91] 
[Mah87] 
K.R. Apt and D. PedrescM. Studies in Pure Prolog: Termination. In J.W. 
Lloyd, editor, Proceedings of th.e Esprit symposium on computational logic, 
pages 150-176, 199(11. 
D. Boulanger a.nd M. Bruynooghe. Using abstract interpretation for goal re- 
pla.cement. In Y. Deville, editor, Logic Program Synth.esis and Tranformation 
(LOPSTR'93), Louvain-la.-Neuve, 1993. 
A. Bossi, N. C',occo, and S. Etalle. Transforming Normal Programs by Re- 
placement. In Third Worl,:shop on Metaprogrammin9 in Logic, Uppsala, 1992. 
META92. 
R.M. Burstall and J. Darlil,gton. 
A transformation system for developing 
recursive progranls. Journal o.[ the A CM, 24:44-67, 1977. 
A. Bossi and S. Etalle. Tra.nsforming Acyclic Programs. ACM Tran.sactions 
on lPr~orammin 9 La~guages and Systems, (to appear); also a.vailable a.s CWI 
Technical Report CS-R9369 December 1993, CWI, Alnsterdam, 1994. 
M. Bezem. C, hara.cterising Termination of Logic Programs with Level Map- 
pings. In E.L. Lusk and R.A. Overbeek, editors, Proceedings NA CLP89, pages 
69-80, 1989. 
J. Cook. A transfornlation systeln for definite logic programs ba.sed on terlni- 
nation analysis. Master's thesis, School of Mathematics, University of Bristol, 
1992. 
D. De Schreye and K. \;erschaetse. Termination of Logic Programs:Tutorial 
Notes. In Third Workshop on Metap'lvgramming in Logic, Uppsala, 1992. 
META92. 
D. De Schreye, K. Verscha.etse, and M. Bruynooghe. 
A Framework for 
Ana.lysing the Termina.tion of Definite Logic Programs with respect to call 
pa.tterns. 
In ICOT, editor, Proceedings of th, e International Conference on 
F~fth. Generation Computer Systems, 1992. 
P.A. Ga.rdner a.nd J.C,. Shepherdson. 
Unfold/fold transformations of logic 
progra.ms. In J.L La.ssez a.nd G. Plotkin, editors, Computational Logic: Essays 
in Honour of Alan Robinson. MIT Press, 1991. 
9 
LW. Lloyd. 
Foundations o.f Logic Programming, 2nd Edition. 
Springer- 
Verlag, 1987. 
J.W. Lloyd and J.C. Shepherdson. Pa.rtial Ewfluation in Logic Programming. 
Journal of Logic Programming, 11(3 ,t,; 4):217-242, 1991. 
M..]. Maher. Correctness of a Logic Program Transformation System. Re- 
search Report RC13496, IBM, T..]. Watson Research Center, 1987. 

[Plim] 
[PP93] 
[Sek891 
[TS84] 
[uvss] 
[VP86] 
67 
L. Pliimer. Automa.tic Termination Proofs for Prolog Programs Opera.ting on 
Nonground Terms. In Proceedings ILPS'91,San Diego, pages 503=517. MIT 
Press, 1992. 
M. Proietti and A. Pettorossi. Synthesis of programs from unfold/fold proofs. 
In Y. Deville, editor, Logic Program Synthesis and Tranformation (LOP- 
STR'93), Louvain-la-Neuve, 1993. 
H. Seki. Unfold/Fokl Transformation of Stratified Programs. In G. Levi and 
M. Martelli, editors, Sixth (..:o1~]erence on Logic Programming,Lisboa,Portu9al. 
The MIT Press, 1989. 
H. Tamaki and T. Sato. Unfold/Fohl Tra.nsformation of Logic Programs. In 
Proceedings o.[ the Second interuational Logic Programming Conference, pages 
127-138, Uppsala, 1984. 
J.D. Ulhnan and A. Van Gelder. Efficient tests for top-down termination of 
logical rules. Journal of the A CM, 35(2), pages 345-373, 1988. 
T. Vasak and .I. Potter. C'hara.cterisation of Terminating Logic Programs. In 
Proceedings 1986 Symposiuln o1~ Logic Programming, Salt Lake City, pages 
14(I-147, 1986. 
Appendix: 
Proofs 
of Leml-na 9 and 
Lelnma 
19 
Lemma 9: Let the definite program pt be obtained by applying a goal replace- 
meat transformation to a clause in P. The, for all definite goals *--- B, 
- P' t3 {+--- /3} has a. finitely failed SLD-tree implies that P u {~-- B} has no 
SLD-refiltation. 
Proof. Proof is by induction on the depth of the smallest finitely failed SLD-tree 
for P~ U {*- B}. Let B = B1,..., B,,.. 
For the base case, suppose tha.t PJ U {*-- B} has a finitely-fa.iled SLD-tree 
of depth 0. This means that some atom Bj (1 < j < m) fails to unify with the 
head of any clause ill P'. Goal reph~.cemerJt, has no effect, on clause heads, so Bj 
also fails to unify with the head of any clause in P. Ilence P U {~--- B} has no 
SLD-refutation. 
For the induction step, assmm ~, that, t, he property holds for goals G such that 
P' U {G) has a finitely-failed SLD-tree of deptla at most. k, and that P' U {+-- B} 
has a finitely-failed SLD-tree F ~ of deptla k + 1. Let ~-- B have n immediate 
successor nodes, ~ $1, 9 ~ S,., in F r and let, D1,..., D,~ be the corresponding 
clauses used. Each .--- S'i (i = 1... n) is at the root, of a finitely failed SLD-tree 
of depth at, most k. By the induction hypothesis P W {~ S~} (for i = 1... n) h~ 
no SLD-reflltation. 
If none of the clauses D1,..., D,. is the clause produced by the goal replace- 
meat,, then clearly P U {~ B} has no SLD-refllt, a.tion, since otherwise at least 
one P u {~-- Si} would have a refiltation, violating the induction hypothesis. 
If Di, say, is the clause produced by tile goal replacement, then we have 

68 
Di : +I -- Q'2, Q in P' 
which replaced 
C: A ~ Q1,Q in P 
where for some j (1 _< j _< m) Bj is unifiable with A with mgu 0. Assume 
without loss of generality that j = 1. 
Then Si = (Q2, Q, B..,,..., Bm)O and P to {+- Si} has no SLD-reflltation, by 
the induction hypothesis. Consider the computation of P tO {+- Si}. There are 
two cases to consider. 
(1) Suppose P tO {+-- Q.,O} succeeds with computed answer u. Then P tO {+--- 
(O, B2 .... , Bm)Oo'} has no SLD-refiltation. By the definition of goal replace- 
ment, Qt =wrs(a,Q) Q2 in P. The mgu 0 acts on the variables of A so P tO {*--- 
Q10} succeeds with computed answer & where c~ and & agree on variables in AO 
and QO. It follows that P tO {,--- (Q, B2,,.., B,,,)0&} has no SLD-reflltation, and 
therefore P tO {+-- (Q1, Q, B.2, . . ., B,,,.)O} has no SLD-refutation. 
(2) Suppose P tO { +- @9} llas no SLD-refutation. Again, since Q1 --w~(A,O) 
Q2 in P and 0 acts on the va.riables of A, it. follows that P tO {+-- QIO} has no 
SLD-refutation. Therefore PU {+-- (Q~, Q, B.,, . . . , B,,,)O} has no SLD-refutation. 
It now follows that PU{+--- B} has no SLD-refutation, since otherwise at least 
one of the goals +- S, .... , +--- &-l, +- &+ l,..., 
+'- s 
or +--- ( Q,, Q, B2 .... , Bm)O 
would have an SLD-refutation, violating the induction hypothesis.rq 
Lemma 19: Let Po,..., t~ be a Seki transformatioll sequence and let P0 be 
recurrent. Then for a.ll clauses A *--B1,..., B,,~ in Pi: 
(i) If A has an old predicate, none of the Bj is inherited from P0. 
(ii) If Bj has a.n old predicate and is not inherited from Po, then for all ground in- 
stances (A ~-- B1,..., B,,~)O we have IAOI- IBiO} _> 2 for some level mapping 
I,I. 
Proof. (Outline): Suppose t~ is recurrent by level mapping [.['- Construct a level 
mapping I.I as follows: 
IAa" I = 2 * [Aa'[' if A has an old predicate and Aa, is a ground atom. 
[A~ l = max{IAlo'l,..., lAg, I} + 1 if (A ~-- A1 .... , Av)o' is a ground instance 
of a clause in P, ....... 
Note that (i) holds trivially fl:om the definition of inherited a.tom. We prove 
(ii) by induction on the length of the transformation sequence. Tile base case 
(that is, for P0) is established by the construction of the level mapping I,I- The 
inductive case is a. straighl;forwa.rd case analysis using tile defnitions of unfold 
and fold.n 

On the Use of Inductive Reasoning in Program Synthesis: 
Prejudice and Prospects 
Pierre Flener 
Department of Computer Engineering 
and Information Science 
Faculty of Engineering 
Bilkent University 
TR-06533 Bilkent, Ankara, Turkey 
pf@bilkent.edu.tr 
Lubo~ Popellnsk~, 
Department of Computing Science 
Faculty of Informatics 
Masaryk University 
Bure~ova 20 
CZ-60200 Bmo, Czech Republic 
popel@fi.muni.cz 
Abstract - In this position paper, we give a critical analysis of the deductive and inductive 
approaches to program synthesis, and of the current research in these fields. From the 
shortcomings of these approaches and works, we identify future research directions for these 
fields, as well as a need for cooperation and cross-fertilization between them. 
1 Introduction 
Many Software Engineering tasks--such as algorithm design, algorithm transforma- 
tion, algorithm implementation into programs, and program transformation--are usual- 
ly perceived as requiring sound reasoning--such as deduction--in order to achieve 
useful results. We believe that this perception is based on some faulty assumptions, and 
that there is a place for not-guaranteed-sound reasoning--such as induction, abduction, 
and analogy--in these tasks. 
In this position paper, we analyze this case within the research of the Logic Program- 
ming community, and more specifically within logic program synthesis research. More- 
over, we concentrate on the use of inductive inference as a complement to sound 
reasoning. This paper is then organized as follows. In Section 2, we take a critical look 
at the use of deductive reasoning in synthesis, so as to identify the shortcomings of that 
approach. In Section 3, we do the same thing with the use of inductive reasoning in syn- 
thesis. This allows us, in Section 4, to plead for a cooperation and cross-fertilization be- 
tween the two approaches. In Section 5, we conclude this apology of the use of not- 
guaranteed-sound reasoning in Software Engineering. 
2 
On the Use of Deductive Reasoning in Program Synthesis 
The Software Engineering tasks of algorithm design, algorithm transformation, algo- 
rithm implementation into programs, and program transformation are often believed to 
be the exclusive realm of sound reasoning, such as deduction. Note that the last two 
tasks are often merged into the first two, provided the focus is on some form of pure 
logic programs. However, it is clearly advantageous to separate algorithms from pro- 
grams, that is to distinguish between the declarative aspects (such as logical correct- 
ness) and the procedural aspects (such as control, operational correctness, and 
efficiency) of software. This distinction is often blurred by the promises of Logic Pro- 
gramming, promises that have however not been fulfilled by languages such as Prolog. 
It is but a recent trend to dissociate algorithms and programs in Logic Programming 

70 
[16] [24] [32] [56] [86]. This corresponds to recasting Kowalski's equation "Algorithm 
= Logic + Control" [55] as "Program = Algorithm + Control". Since there is no consen- 
sus yet on these issues, and in order to keep our terminology simple, the word "algo- 
rithm" stands in the sequel for "algorithm or program", hence encompassing all 
viewpoints. 
In the Logic Programming community, this trend of deduction-based approaches is 
clearly dominant in the proceedings of dedicated workshops such as the LOPSTR series 
(LOgic Program Synthesis and TRansformation, where "synthesis" stands for some 
form of (semi-)automated algorithm design) [19] [25] [57] [this volume], and of dedi- 
cated sessions at most Logic Programming conferences (ICLP [50], SLP, META .... ). 
Let's focus our attention now on the most challenging of the four tasks enumerated 
above, namely algorithm design, and, more precisely, on algorithm synthesis. It should 
be noted that the line between synthesis and transformation is a very subjective one, and 
that the synthesizers of some researchers would be transformers for other researchers. 
For the sake of this paper, we assume the following purely syntactic criterion for distin- 
guishing between synthesis and transformation: if the input and output languages of a 
tool are the same, then it is a transformer, otherwise it is a synthesizer. Usually, synthe- 
sis amounts to the translation from a rich, high-level input language (the specification 
language) into a less rich, lower-level language (the algorithm language). It is in this 
sense that we consider synthesis more challenging than transformation. Our restriction 
of the focus on algorithm synthesis can now be motivated as follows: synthesis gener- 
ates the objects that can be transformed, so synthesis could just as well generate the 
transformed version right away. In this sense, it suffices to discuss synthesis here. 
The rest of this section is now organized as follows. Section 2.1 briefly relates the var- 
ious approaches to using deductive reasoning in synthesis. This allows us, in 
Section 2.2, to enumerate the problems of such deduction-based synthesis. Finally, 
Section 2.3 contains a partial conclusion. 
2.1 Approaches to Deduction-based Program Synthesis 
In Logic Programming, synthesis is usually the process of (semi-)automatically trans- 
lating a specification (usually in a language quite close to full first-order logic plus 
equality) into a logic algorithm (usually in a language that is a proper subset of the spec- 
ification language). Such a first-order axiomatization is often just assumed to be a faith- 
ful formalization of the intentions 1, though the synthesis process may provide feedback 
to the specification elaboration process [60]. From such a formal specification, a natu- 
ral thing to do is to proceed with sound reasoning, so as to obtain an algorithm that is 
logically correct with respect to the specification. Research from this mind-set can be 
divided into two main categories [27] [31]: 
9 Deductive Synthesis (also known as Transformational Synthesis): meaning-preserv- 
ing transformations are applied to the specification, until an algorithm is obtained. 
Sample works are those of Clark [18], Hogger [48], B ibel et a l. [6], Sato and Tamaki 
[73] [74], Lau and Prestwich [62], Kraan etal. [56], and so on. The theoretical foun- 
dations to deductive synthesis are being laid out by Lau and Ornaghi [58]-[61]. 
1. Let's ignore here the problem that the intentions tend to be unknown or to change over time. 

71 
9 Constructive Synthesis (also known as Proofs-as-Programs Synthesis): an algorithm 
is extracted from a (sufficiently) constructive proof of the satisfiability of the spec- 
ification. Sample works are those of T/irnlund et al. [29] [46], Takayama [83], 
Bundy et al. [16], Wiggins [86], Fribourg [35], and so on. 
These two categories are not as clear-cut as one might think, as some synthesis mecha- 
nisms can be successfully classified in the two of them [56]. The two approaches are 
probably only facets of the same technique. 
A third category, namely Schema-guided Synthesis, should be added: an algorithm is 
obtained by successively instantiating the place-holders of some algorithm schema, us- 
ing the specification, the algorithm synthesized so far, and the integrity constraints of 
the chosen schema. This usually involves a lot of deductive inference sub-tasks, hence 
the justification for viewing this as deduction-based synthesis. Curiously, this category 
seems almost absent from the Logic Programming world, although spectacular results 
are being obtained with this approach in Functional Programming by D.R. Smith [78] 
[79]. The work of Fuchs [40] and Kraan [56] is definitely schema-based, but their logic 
program schemas are not finegrained enough to more effectively guide the synthesis. 
2.2 The Problems with Deduction-based Program Synthesis 
Now, what are the problems with deduction-based synthesis, and the current approaches 
to it? We see basically two problems. 
The first problem is related to the current synthesis approaches. A lot of wonderful 
theoretical effort is being directed at building theories of algorithms that may underlie 
synthesis. Almost any algorithm can be synthesized using these approaches. Another 
crux is that although these approaches show the derivability of many algorithms (which 
is in itself a very positive result), the search spaces are exponentially large, making 
these synthesizers impossible to use in automatic mode. So interactive usage is recom- 
mended. But a close look at such syntheses shows that one almost needs to know the 
final algorithm if any serious speedup is to be expected, which is not what one would 
expect to have to do with a synthesizer. What is needed now is also a theory of algorithm 
design in order to allow efficient traversal of these huge search spaces. The investiga- 
tions on proof planning [17] and lemma generation [36] are first steps into that direc- 
tion. But we believe that even more can be done, maybe along the lines of the schema- 
guided synthesis paradigm mentioned above. Indeed, one of the conclusions of the early 
efforts at automatic programming was that algorithm design knowledge and domain 
knowledge are essential if synthesis wants to scale up to realistic tasks [42]. Curiously, 
few people in the Logic Programming community seem to pay heed to that recommen- 
dation by Green and Barstow. 
The second problem with deduction-based synthesis is related to the formality of the 
specifications. Where do the formal specifications come from? If deduction-based syn- 
thesizers guarantee total correctness of the resulting algorithms with respect to their 
specifications, what guarantee do we have that these specifications correctly capture our 
intentions? These questions are often either dismissed as irrelevant or considered as in- 
tractable issues that are left for future research. But what use are these synthesizers if 
we don't even know whether they solve our problems or not? 

72 
Before continuing, we must define the concept of specification, as there is little con- 
sensus on such a definition. For the purpose of this paper, a specification is a description 
of what a program does, and of how to use that program. Such specifications are totally 
declarative in that they don't express how the program actually works, and they thus 
don't bias the programmer in her/his task. Specifications have been alternately required 
to be not (necessarily) executable [47], (preferably) executable [37] [38], and so on. 
So what are the problems with formal specifications? As seen above, there is no way 
to construct formal specifications so that we have a formal proof that they capture our 
intentions. So an informal proof is needed somewhere (at worst by testing a prototype, 
although testing never amounts to proving), as the purpose of Software Engineering is 
after all to obtain programs that implement our informal intentions. Writing formal 
specifications just shifts the obligation of performing an informal proof from the pro- 
gram vs. specification verification to the specification vs. intentions verification, but it 
doesn't rid us of that obligation. So specifications could just as well be informal, to pre- 
vent a delaying of an informal proof that has to be done anyway. 
So we are actually hoping for somebody to write a new paper stating that specifica- 
tions ought to be informal! Informal specifications should not be mixed up with natural 
language specifications: they are just specifications written in a non-formal language 
(without a predefined syntax and semantics). So natural language statements augmented 
with ad hoc notations, or statements in a subset of natural language with a "clear" se- 
mantics, would constitute an informal specification [63]. 
Another indicator why specifications ought to be informal can be obtained by observ- 
ing the history of program synthesis research [72]: the first assemblers and compilers 
were seen as automatic programmers, as they relieved the programmers from many of 
the burdens of binary programming. Some programmers felt like they were only writing 
some form of specifications, and that the compilers took care of the rest. But after a 
while, the new "specification languages" were perceived as programming languages! 
The same story is happening over and over again with each new programming para- 
digm. One of the latest examples is Prolog: initially perceived by many as a specifica- 
tion language (and still being perceived as such by some people), the consensus now 
seems that it is a programming language. So how come that one-time specification lan- 
guages are sooner or later perceived as programming languages, or that there never is a 
consensus about the difference between formal specifications and programs? The for- 
mal specifications of some people are indeed often very close to what other people 
would call programs. Moreover, formal specifications are often as difficult to elaborate 
and to maintain as the corresponding programs. 
Some researchers don't require formal specifications to be totally declarative, but only 
as declarative as possible. Indeed, if a specification language allows the procedural ex- 
pression of knowledge, practice shows that specifiers will use these features. But what 
does it mean for a formal specification to be declarative? As writing recursive state- 
ments seems to reflect a very procedural way of thinking 2, a possible criterion for 
declarativeness could be the absence of explicit recursion in the specification itself as 
well as in the transitive closure of the union of the specifications of the predicate-sym- 
bols used in that specification. But such recursion-free specifications are (possibly?) im- 
2. However, recursive statements can be understood declaratively: the meaning is "... and so on". 

73 
possible to write, as sooner or later one gets down to such fundamental concepts as 
integer-addition or list-concatenation, which don't have non-recursive finite-length de- 
scriptions that completely capture them. So if the most evident symptom of 
"procedurality", namely recursion, seems impossible to avoid in formal specifications, 
this would imply that declarative formal specifications don't exist. And since specifica- 
tions ought to be declarative, this would in turn imply that formal specifications cannot 
be written. 
In our opinion, the solution to all these problems with formality is that formal speci- 
fications and programs are intrinsically the same thing! The inevitable intertwining be- 
tween the formal specification elaboration process and the algorithm design process has 
already been pointed out by Swartout and Balzer [82]. 
As algorithm synthesis research aims at raising the level of language in which we can 
interact with the computer, synthesizers and compilers perform intrinsically the same 
process. In other words, the "real" programming is being done during the formalization 
process while going from an informal specification to a formal specification/program 
(which is then submitted to a synthesizer/compiler). In Logic Programming, there is lit- 
tle research about this formalization process, a laudable exception being Deville's work 
on hand-constructing logic algorithms from informal specifications [24], a process for 
which some mechanization opportunities have been pointed out [26]. 
Note that we are not saying that formal specifications are useless: of course it is im- 
portant to be able to check whether a formal specification is internally consistent, and 
to generate prototypes from executable specifications, because this allows early error 
detection and hence significant cost-cutting. At any given time, formal specifications, 
even if written in a programming language, will have different purposes (validation, 
prototyping, contracts .... ) and attributes (readability, efficiency .... ) than programs 
[39]. We here just say that formal/executable specifications are already programs, 
though not in a conventional sense. But conventions change in time, and the specifica- 
tions of today may well be perceived tomorrow as programs. To understand this, it helps 
to define programming from a process-theoretic viewpoint (that is, as an activity of 
carefully crafting, debugging, and maintaining a formal text) rather than from a prod- 
uct-theoretic viewpoint (programming yields a formal text). 
2.3 Partial Conclusion about Deduction-based Program Synthesis 
Let's summarize in a very synoptic way the situation about deduction-based synthesis: 
9 Deduction-based synthesis translates a formal specification (with assumed-to-be- 
complete information about the intentions) into an algorithm. 
9 Deduction-based synthesis research, in Logic Programming, should incorporate 
(more) explicit algorithm design knowledge, such as algorithm schemas. 
9 The deduction-based synthesis approach suffers from the following problems: 
- where do the formal specifications come from? 
- it's impossible to have a formal guarantee that a formal specification correctly 
captures the intentions; 
- formal specifications are often as difficult to write as programs; 
- there is even no consensus on the difference between formal specifications and 
programs; in fact, the expression "formal specification" is a contradiction in 

74 
terms, and formal specifications and programs are intrinsically the same thing; so 
synthesis and compilation also are intrinsically the same process. 
Let's now move on to the use of inductive reasoning in algorithm synthesis. 
3 On the Use of Inductive Reasoning in Program Synthesis 
Human beings often understand a new concept after just seeing a few positive (and neg- 
ative) examples thereof. Machine Learning is the branch of Artificial Intelligence that 
explores the mechanization of concept learning (from examples). Important sub- 
branches are Empirical Learning (from a lot of examples, hut only a little background 
knowledge) and Analytical Learning (from a few examples, but a lot of background 
knowledge), the latter being also known as Explanation-Based Learning (EBL) or Ex- 
planation-Based Generalization (EBG) [85]. Machine Learning was long cast in the 
framework of propositional logic, but since the early 1980s, the results are being up- 
graded to first-order logic. These efforts are nowadays collectively referred to as ILP 
(Inductive Logic Programming, a term coined by Muggleton [65]), because concept de- 
scriptions are there written as logic programs. ILP is somehow a cross-fertilization be- 
tween Logic Programming and Machine Learning, and between Empirical Learning 
and Analytical Learning, and is divided into Empirical ILP (heuristic-based learning of 
a single concept from many examples) and Interactive ILP (algorithmic and oracle- 
based learning of many concepts from a few examples). The base cycle of every learner 
is that it reads in examples from a teacher and periodically turns out hypotheses (con- 
jectures at concept descriptions). 
An important distinction needs to be made here. Algorithm synthesis from examples 
is but a niche (albeit a significant one) of ILP. Indeed, algorithm synthesis in general is 
only useful if the algorithm actually performs some "computations", via some looping 
mechanism such as recursion or iteration. Straight-line code is always very close to its 
full specification, and its synthesis is thus a mere rewriting process. So, in particular, 
algorithm synthesis from examples is only useful if the algorithm actually performs 
some "computations". But recursive algorithms are only a subclass of all possible con- 
cept descriptions, so algorithm synthesis from examples effectively is a niche of ILP. In 
the following, by "algorithms" we mean recursive concept descriptions, and by "iden- 
tification procedures" we mean non-recursive concept descriptions. Other differences 
between ILP in general and induction-based algorithm synthesis in particular are sum- 
marized in Table 1 [31]. 
The central column of Table 1 shows the spectrum of situations covered by ILP re- 
search, but it doesn't mean to imply that all learners do cover, or should cover, this full 
spectrum. The right-hand column however shows the most realistic situation for induc- 
tion-based algorithm synthesis, that is a situation that should be covered by every syn- 
thesizer. Let's have a look now at these two columns. 
In ILP, the agent who provides the examples can be either a human being or some au- 
tomated device (such as a robot, a satellite, a catheter .... ). It is possible for this agent 
not to know the intended concept, which means that it may give examples that are not 
consistent with the intended concept, or that it may give wrong answers to queries from 
the learner. Examples can be given in any amounts: Empirical ILP systems expect nu- 
merous examples, while Interactive ILP systems expect only a few examples, and often 

75 
Inductive Logic 
Programming 
Induction-based 
Algorithm Synthesis 
Class of hypotheses 
any concept descriptions 
algorithms 
Specifying agent 
human or machine 
human 
Intended concept 
sometimes unknown 
always known 
Consistency of examples 
any attitude 
assumed consistent 
# examples 
any 
a few 
# predicates in examples 
at least 1 
exactly 1 
Rules of inductive infer, 
selective & constructive 
necessarily constructive 
Correctness of hyp.s 
any attitude 
total correct, is crucial 
Existence of hyp. schemas 
hardly any 
yes, many 
# correct hypotheses 
usually only a few 
always many 
Table 1: 
Induction-based Algorithm Synthesis as a Niche of Inductive Logic Programming 
construct their own examples so as to submit them to the teacher. Examples may in- 
volve more than one predicate-symboh the instance "Tweety" of the concept "canary" 
could yield the example: 
mouth(tweety,beak) 
A legs(tweety, 2) A skin(tweety,feather) 
A 
utterance(tweety,sings) 
A color(tweety,yellow) , 
which involves many predicate-symbols, but not a canary~1 predicate-symbol, The 
used rules of inductive inference can be either selective (only the predicate-symbols of 
the premise may appear in the conclusion) or constructive (the conclusion "invents" 
new predicate-symbols). Selective rules are often sufficient to learn concepts, such as 
"canary", from multi-predicate examples. There are many learning situations where an 
approximately correct concept description is sufficient, whereas in other situations a to- 
tally correct description is hoped for. For general concept descriptions, there are hardly 
any useful schemas (template concept descriptions): indeed, such schemas tend to spell 
out the entire search space, and thus don't decrease its size. For general concepts, there 
are usually only a few correct hypotheses: for instance, there is probably only one cor- 
rect definition of the "canary" concept, in any given context. 
But in induction-based algorithm synthesis, the most realistic setting is where the 
specifier is a human being who knows the intended concept and who is assumed to pro- 
vide only examples that are consistent with that intended concept. 3 "Knowing a con- 
cept" means that one can act as a decision procedure for answering membership queries 
3. There are of course other settings for induction-based synthesis, such as the intelligent system 
that re-programs itself in the face of new problems [11]. We think that in such cases a general 
Machine Learning approach is more adequate as the system can't know in advance whether the 
new concept has an algorithm or an identification procedure. 

76 
for that concept [2], but it doesn't necessarily imply the ability to actually write that de- 
cision procedure. 4 Such a specifier cannot be expected to be willing to give more than 
just a few examples. Examples only involve one predicate-symbol, namely the one for 
which an algorithm is to be synthesized: for instance, an example of a sorting algorithm 
could be sort([2,1,3],[1,2,3]). The used rules of inductive inference thus necessarily in- 
clude constructive rules, as algorithms usually use other algorithms than just them- 
selves. Total correctness of the synthesized algorithm with respect to the intended 
concept is crucial in induction-based synthesis. Algorithms are highly structured, com- 
plex entities that are usually designed according to some strategy, such as divide-and- 
conquer, generate-and-test, global search [79]: algorithm synthesis can thus be effec- 
tively guided by an algorithm schema that reflects some design strategy. The existence 
of many such schemas, and the existence of many choice-points within these strategies 
entail the existence of many correct algorithms for a given "computational" concept. 
For instance, sorting can be implemented by Insertion-sort, Merge-sort, Quicksort algo- 
rithms, and many more. 
So there is a dream of actually synthesizing algorithms from specifications by exam- 
pies. Since many intentions are covered by an infinity of examples, finite specifications 
by examples cannot faithfully formalize such intentions, and the synthesizer needs to 
extrapolate the full intentions from the examples. This is necessarily done by not-guar- 
anteed-sound reasoning, such as induction, abduction, or analogy. 
The rest of this section is now organized as follows. Section 3.1 briefly relates the var- 
ious approaches to using inductive reasoning in synthesis. This allows us, in 
Section 3.2, to enumerate the problems of such induction-based synthesis. In 
Section 3.3, we tackle the most commonly encountered prejudice about induction- 
based synthesis. Finally, Section 3.4 contains a partial conclusion. 
3.1 Approaches to Induction-based Program Synthesis 
In the early 1970s, some researchers investigated how to synthesize algorithms from 
traces of sample executions thereof. However, traces are very procedural specifications, 
and constructing a trace means knowing the algorithm, which rather defeats the purpose 
of synthesis. Sample work is related in [7] and, more recently, [52]. Regarding induc- 
tion-based synthesis from examples, there are basically two approaches [31] [27]: 
9 Trace-based Synthesis: positive examples are frst "explained" by means of traces 
(that fit some predefined algorithm schema), and an algorithm is then obtained by 
generalizing these traces, using the above-mentioned techniques of induction-based 
synthesis from traces. Sample works are those of Biermann et al. [8] [ 12], Summers 
[81], and so on, and they are surveyed by D.R. Smith [77]. This research was a pre- 
cursor to the EBL/EBG research of Machine Learning. 
9 Model-based Synthesis: a logic program is "debugged" with respect to positive and 
negative examples until its least Herbrand model coincides with the intentions. This 
is the ILP approach. Sample works are those of E.Y. Shapiro [76], and many others 
are compiled by Muggleton [66] and surveyed in [67]. 
4. It would be interesting to examine specifiers (oracles) that are capable of answering other kinds 
of queries (subset, superset .... [2]) and to investigate other meanings of the phrase "knowing 
a concept". 

77 
Historically speaking, the two approaches barely overlap in time: trace-based synthesis 
research took place in the mid and late 1970s, whereas model-based synthesis research 
is ongoing ever since the early 1980s. Indeed, in the late 1970s, trace-based synthesis 
research hit a wall and partly declared defeat considering that the techniques found 
didn't seem to scale up to realistic problems. But then, E.Y. Shapiro [76] and others pub- 
lished their first experiments with model-based approaches, and model-based synthesis 
took over, not only for induction-based algorithm synthesis, but for inductive concept 
learning in general. 
"Linguistically" speaking, the two approaches also barely overlap: trace-based syn- 
thesis was pursued by the Functional Programming community, whereas model-based 
learning is being investigated by the Logic Programming community. Revivals of trace- 
based synthesis in the Logic Programming community have been suggested by Flener 
[31] [32] and Hagiya [45]. 
3.2 The Problems with Induction-based Program Synthesis 
Now, what are the problems with induction-based synthesis, and the current approaches 
to it? We see basically two problems. 
The first problem is related to the current synthesis approaches: there seems to be little 
dedicated induction-based synthesis research any more in the Logic Programming com- 
munity, as most research seems directed at model-based learning in general. However, 
as conveyed by Table 1, induction-based synthesis is a sufficiently restricted sub-area 
of induction-based learning to justify very dedicated techniques. It is illusory to hope 
that very general learning techniques carry over without major efficiency problems to 
particular tasks such as induction-based synthesis: since synthesis is akin to compilation 
(see Section 2.2), this illusion amounts to looking for a universal programming lan- 
guage. The phrase ILP is ambiguous in that it can be understood in two different ways: 
ILP could mean "writing Logic Programs using Inductive reasoning" (I-LP), or it could 
mean "Programming (in the traditional sense of the word) in Logic using Inductive rea- 
soning" (I-L-P). The bulk of ILP research accepts the first interpretation. 
Some good ideas of trace-based synthesis (such as schema-guidance) haven't re- 
ceived much attention by model-based learning research. Indeed, as seen above, for 
general concepts there are hardly any schemas that wouldn't spell out the entire search 
space. Of course, one can use application-specific schemas, but then the question arises 
as to the acquisition of these schemas. Now, for the particular task of model-based syn- 
thesis, there is room for schemas [80] [84]: algorithm schemas significantly reduce the 
search space, they bring "discipline" into an otherwise possibly anarchic debugging 
process, and they convey part of the algorithm design knowledge called for by Green 
and Barstow [42]. The other entries of Table 1 provide an agenda for future, dedicated 
research in model-based synthesis. 
Also, there is a fundamental difference between a teacher/learner relationship and a 
specifier/synthesizer relationship. A teacher usually is expected to know how to com- 
pute/identify the concept s/he is teaching to the learner, whereas a specifier usually only 
knows what the concept is about, the determination of how to compute it being precisely 
the task of the synthesizer. So a teacher can guide a learner who is "on the wrong track", 
but a specifier usually can't. A teacher can, right before the learning session, set the 

78 
learner "on the right track" by providing carefully chosen examples and/or background 
knowledge, but a specifier often can't. For instance, most ILP systems can learn the 
Quicksort algorithm from examples of sort~2 plus logic procedures for partition~3 and 
append~3 as background knowledge. But this amounts to a "specification of quick- 
sort~2", which is a valid objective for a teacher, but not for a specifier: one specifies 
sort~2, a problem, not quicksort/2, a solution! We really wonder about the efficiency of 
ILP-style learners in a true specifier/synthesizer setting, where a lot of relevant and ir- 
relevant background knowledge is provided. A solution to the ensuing inefficiency 
would be structured background knowledge, such as classifying the partition~3 proce- 
dure as a useful instance of the induction-parameter-decomposition placeholder in a di- 
vide-and-conquer algorithm schema. 
The second problem with induction-based synthesis is that examples alone are too 
weak a specification approach. Incompleteness results are indeed abundant [3] [10] [41] 
[51] [68] [69]. It is true that in Machine Learning in general, examples are often all one 
can hope for. But, as conveyed by Table 1, in synthesis, we usually have the setting of 
a human specifier who knows the intended relation. So s/he probably knows quite a bit 
more about that relation, but can't express it by examples alone. For instance, it is un- 
realistic that somebody would want a sorting program and not know the reason why 
[2,1 ] is sorted into [ 1,2] rather than into [2,1 ]. The reason of course is that 1 < 2, but the 
problem here is that the <_/2 predicate-symbol cannot appear in the examples. 
More generally, the problem is about the lack of provision of domain knowledge to 
the synthesizer (another recommendation by Green and Barstow [42]), and has been 
perceived a while ago. Various proposed solutions are type declarations for the param- 
eters [76], type assertions about the intended relation [28], properties of the intended re- 
lation [31] [32], integrity constraints about a set of intended relations [20] [21], and bias 
(all knowledge potentially useful for narrowing the search space [71]), as generally 
used in ILP. Note that special care needs to be taken not to require complete knowledge 
about the intentions in the assertions/properties/constraints/bias, because otherwise a 
deduction-based synthesizer would be more appropriate. This is a problem with some 
of the proposed solutions [23]. Of course, if someone wants to give complete knowl- 
edge about the intentions, then the synthesizer should be able to handle it. 
Some other often mentioned "problems" with induction-based synthesis are, in our 
opinion, no problems at all, and we discuss them in the next sub-section. 
3.3 Induction-based Program Synthesis: Prejudice and Reality 
When faced with research about synthesizing algorithms from examples, some deduc- 
tion-based synthesis researchers react somewhere in between the paternalistic smile of 
a father at his child who just completed her/his first Lego house and aggressive attacks 
about the uselessness of such research. Let's have a look at the most frequently encoun- 
tered prejudices, and debunk them in the face of reality. 
Prejudice: Induction-based synthesis researchers think that they will provide the solu- 
tion to synthesis. 
Reality: Induction-based synthesis researchers are fully aware of the limitations of their 
research. They view it as just the provision of components and tools for software engi- 
neering 
environments. 
In 
the 
synthesizer-as-a-workbench-of-powerful-mini- 

79 
synthesizers approach advocated by A.W. Biermann [9] and schema-guided synthesis 
researchers such as D.R. Smith [78] [79], there is a place for induction-based synthesiz- 
ers, because certain classes of algorithms can be reliably synthesized with little effort 
from a few examples. As an illustration, the first author estimates that about 50% of the 
code of his induction-based SYNAPSE synthesizer [31] falls into such categories of al- 
gorithms (divide-and-conquer algorithms in this case), and could thus have been written 
by SYNAPSE itself. 
Prejudice: Induction-based synthesis can at most pretend to aim at programming-in the- 
small. So it is useless as such algorithms are trivial and can often be written faster than 
the specifications by examples. 
Reality: Even though deduction-based synthesis can effectively hope to scale up to pro- 
gramming-in-the-medium (though probably not to programming-in-the-large?), this 
doesn't mean that strictly less powerful approaches are not useful. One should not for- 
get that synthesis aims at helping all sorts of programmers, not only the skilled ones. 
Moreover, synthesis aims at the design of any algorithms, not only the complex ones. 
Finally, synthesis aims at raising the level of language in which the programmer can 
communicate with the computer, and thinking in terms of examples seems to us of a 
higher level than thinking in terms of recursion. During the implementation of his 
SYNAPSE system, the first author felt many times that he would rather use SYNAPSE (if 
only it existed already !) than work out himself the recursive calls and other more low- 
level details. In ILP research on algorithm synthesis, a lot of denotation is now being 
paid to minimizing the number of examples, and the first results are promising [1] [5] 
[43] [70]. 
Prejudice: Induction-based synthesis research is useless because it offers no guarantee 
that the synthesized algorithms are correct with respect to our intentions. 
Reality: In both the deduction-based and the induction-based synthesis approaches, it 
takes specification debugging and maintenance to achieve correctness with respect to 
the intentions. In the two approaches, completeness of the algorithm with respect to the 
specification is guaranteed, but only in the deduction-based approach does partial cor- 
rectness with respect to the specification make sense. The problem does not lie in the 
use of not-guaranteed-sound vs. sound reasoning, but in the fact that synthesis starts 
from formal specifications. Whereas with example-based specifications one knows that 
the specification is but a fragmentary description of the intentions, such is usually not 
the case with axiomatic specifications, where one only knows that there is a problem 
when something goes wrong during the synthesis or during the execution of an imple- 
mentation of the synthesized algorithm. The line of reasoning for the prejudice above 
could thus also be used to claim that deduction-based synthesis research is useless be- 
cause it also doesn't offer a guarantee that the synthesized algorithms are correct with 
respect to our intentions, this because we have no guarantee that our formal specifica- 
tions are correct with respect to our intentions. 
There certainly are other prejudices, but let's leave it at these for now. 

80 
3.4 Partial Conclusion about Induction-based Program Synthesis 
Let's summarize in a very synoptic way the situation about induction-based synthesis: 
9 Induction-based synthesis generalizes a formal specification (with known-to-be- 
fragmentary information about the intentions) into an algorithm. 
9 Induction-based synthesis research, in Logic Programming, is a niche of ILP, but its 
specifics are not being catered for. The results are usually inefficiency and inade- 
quateness. For instance, synthesizers should incorporate (more) explicit algorithm 
design knowledge, such as algorithm schemas. 
9 The induction-based synthesis approach suffers from the problem that examples 
alone are too weak a specification approach: additional domain and problem knowl- 
edge must be provided. 
9 There is a place for the induction-based synthesis approach. 
This finishes our discussion of the deduction-based and induction-based approaches to 
algorithm synthesis. Let's now plead for a cooperation and cross-fertilization between 
the two approaches, and actually also with abduction- and analogy-based approaches. 
4 Towards a Cooperation and Cross-Fertilization between 
Deduction-based Synthesis and Other Approaches to Synthesis 
From the beginning, ILP has sought cross-fertilization with other fields, be it by defini- 
tion (ILP is an attempt at cross-fertilizing Machine Learning and Logic Programming) 
or by "charter" (ILP aims at the cross-fertilization of Empirical Machine Learning and 
Analytical Machine Learning). Other opportunities for cross-fertilization have been 
discovered and added to the ILP "charter". Some successful attempts have been with: 
9 Data~Knowledge-Base Updating: cross-fertilization resulted in that learning can 
now be done from (clausal) integrity constraints, a generalization of examples, and 
that non-unit clauses can now be asserted [20] - [22]. The extended field is known 
as Belief Updating or Theory Revision. The discovery of data dependencies in rela- 
tional and deductive databases has also been examined [30] [53] [75]. 
9 Theorem Proving: a procedure may be constructed by an analysis of a failed proof 
of a formal specification of its predicate-symbol [34] [49] [64]. However, in some 
cases, an inductive theorem prover is not able to process a formula and thus fails to 
finish a proof. Induction-based learning methods are then used for inventing new 
predicates and a new formula is built. It is shown that even in the case where the new 
formula is not equivalent to the original one, the prover is able to make the next step 
and to finish the proof [33]. 
9 Logic Program Transformation: cross-fertilization with Analytical Learning 
(EBL/EBG) resulted in Explanation-Based Program Transformation (EBPT) [14], 
where sample concrete transformations guide the overall abstract transformation 
process. 
So the question now arises as to whether cooperation and cross-fertilization are possible 
with (other) branches of deduction-based Software Engineering? Some attempts at 
solving Software Engineering tasks with induction-based techniques have been made, 
such as logic program synthesis and debugging [5] [23] [28] [43] [76], test case gener- 
ation [4], and program verification [13], but there was no sign of actual cross-fertiliza- 
tion. So what is the potential of such cooperation and cross-fertilization? 

81 
One of the major problems we pointed out with the deduction-based synthesis para- 
digm is due to the formality of the needed specifications: where do the formal specifi- 
cations (logical axiomatizations, that is) come from? Following Muggleton's summary 
of the importance of inductive reasoning in scientific discovery [65], the popular answer 
is that axioms, representing generalized beliefs, can be constructed from particular 
facts, which are in turn derived from the senses. Turing is reported to have believed that 
the problems due to Grdel's incompleteness theorem could be overcome by learning 
from examples. So a possible cooperation would be mixed-inference specification ac- 
quisition followed by deduction-based synthesis/transformation. Deduction-based syn- 
thesis can provide feedback to the specification elaboration process [60], but this 
doesn't assist in the initial formalization process and only detects inconsistencies within 
the specification, but not inconsistencies with respect to the intentions. 
Another opportunity for cooperation lies in the synthesizer-as-a-workbench-of-pow- 
erful-mini-synthesizers approach advocated by A.W. Biermann [9] and schema-guided 
synthesis researchers such as D.R. Smith [78] [79]: such a workbench should include 
induction-based synthesizers that are known to reliably converge very quickly to cor- 
rect algorithms from just a few examples. This would be handy synthesis tools, and we 
believe they would be used very often. Similarly for tools based on other kinds of infer- 
ence. 
A little-explored avenue for cross-fertilization is the use of deductive reasoning within 
induction-based synthesis, and vice-versa. Indeed, synthesis (especially if schema- 
guided) can often be broken down into very different sub-tasks (such as instantiating 
some place-holder of an algorithm schema). So it is likely that some sub-tasks are easier 
to solve by deductive reasoning, whereas others are more amenable to other kinds of 
reasoning. 
For instance, the SYNAPSE system [31] [32] is schema-guided, starts from specifica- 
tions by examples and some strong form of axioms (called properties), and features de- 
ductive and inductive reasoning, according to whichever is preferable for each place- 
holder of a divide-and-conquer schema. The given properties are used in a constructive 
way: formulas are extracted from an explanation of the failure of a deductive proof that 
the current algorithm satisfies the properties, and these formulas are then added to that 
algorithm. This is a different approach from the usage of assertions [28] or integrity 
constraints [21], which are used in a destructive way (to reject parts of the current hy- 
pothesis) and without any actual deductive reasoning. 
This technique is related to abduction [54], which plays an important role when the 
incorporation of incoming information to an existing theory is impossible or inconve- 
nient: for example in deductive databases and knowledge bases, where adding a new 
piece of knowledge may cause an inconsistency [15] [44], or in a fault diagnosis, where 
we are interested in a cause of failure rather than in the failure itself. By abduction, we 
look for an explanation of the new knowledge, consistent with the existing theory, and 
then add it to the theory. 
Abductive reasoning is non-monotonic, as many explanations may exist for a given 
piece of knowledge. Another evidence for non-monotonicity is that explanations of two 
different pieces of incoming knowledge may contradict each other. 

82 
In the field of algorithm synthesis, De Raedt [20] pointed out that Shapiro's MIS [76] 
actually also performs abduction: in the context of multiple predicate learning, abduced 
facts are not added to the theory, but rather used as the starting point for a synthesis 
phase. In [20], an abductive technique for the inductive learner CLINT is described, 
making it capable of learning multiple predicates. The use of abduction in interactive 
algorithm synthesis from examples is also explored in [70]. 
We believe that deductive/abductive inference from, and constructive usage of, ora- 
cle-answers and extensions of example-based specificatiohs will play an important role 
in induction-based synthesis (and learning). Conversely, we also believe that deduction- 
based synthesis will greatly benefit from the inclusion of other kinds of reasoning. 
5 Conclusion 
In this essay, we have given a critical analysis of the deduction-based and induction- 
based approaches to algorithm synthesis, and of the current research in these fields with- 
in the Logic Programming community. We have identified some future research direc- 
tions for these approaches, as well as a clear need for cooperation and cross-fertilization 
between them. 
The two approaches and their associated current research efforts have their shortcom- 
ings, and, upon close inspection, they even share the most fundamental shortcomings: 
9 the two current efforts suffer from the fact that (more) algorithm design knowledge 
(such as algorithm schemas) ought to be injected into the synthesizers; 
9 the two approaches suffer from the fact that there is no formal guarantee that the 
synthesized algorithms correctly cover our intentions; so in the two approaches an 
informal proof of correctness is needed somewhere (usually via specification debug- 
ging and maintenance). 
We hope to have convinced initially suspicious readers that the intuitive argument of the 
superiority of the deduction-based approach is based on some faulty and prejudiced as- 
sumptions. 
Acknowledgments 
The first author gratefully acknowledges stimulating discussions with Baudouin Le 
Charlier (University of Namur, Belgium), Yves Deville (Catholic University of 
Louvain, Belgium), and Norbert Fuchs (University of Ztirich, Switzerland). Thanks of 
the second author are due to his supervisor Olga St~pgnkovgt (Czech Technical Uni- 
versity, Prague, Czech Republic) and to Pavel Brazdil (University of Porto, Portugal) 
for useful discussions and suggestions. The first author also benefitted from the feed- 
back of the students of his Automatic Program Synthesis course at Bilkent University. 
References 
ICLP = International Conference on Logic Programming 
ILP = International Workshop on Inductive Logic Programming 
LOPSTR = International Workshop on LOgic Program Synthesis and TRansformation 
LPAR = International Conference Logic Programming and Automated Reasoning 
SLP = Symposium on Logic Programming 

83 
[1] David W. Aha, Strphane Lapointe, Charles X. Ling, and Stan Matwin. Inverting 
implication with small training sets. In E Bergadano and L. De Raedt (editors), 
Proceedings of the 1994 European Conference on Machine Learning, pages 31- 
48. LNCS 784, Springer-Verlag, 1994. 
[2] Dana Angluin. Queries and concept learning. Machine Learning 2(4):319-342, 
April 1988. 
[3] Dana Angluin and Carl H. Smith. Inductive inference: Theory and methods. Com- 
puting Surveys 15(3):237-269, September 1983. 
[4] Francesco Bergadano et al. Inductive test case generation. In Proceedings of 
ILP'93, pages 11-24. 
[5] Francesco Bergadano and Daniele Gunetti. Inductive synthesis of logic programs 
and inductive logic programming. In [25], pages 45-56. 
[6] Wolfgang Bibel. Syntax-directed, semantics-supported program synthesis. Artifi- 
cial Intelligence 14(3):243-261, October 1980. 
[7] Alan W. Biermann. On the inference of Turing machines from sample computa- 
tions. Artificial Intelligence 3(3):181-198, Fall 1972. 
[8] Alan W. Biermann. The inference of regular LISP programs from examples. IEEE 
Transactions on Systems, Man, and Cybernetics 8(8):585-600, 1978. 
[9] Alan W. Biermann. Dealing with search. In Alan W. Biermann, Grrard Guiho, and 
Yves Kodratoff (editors). Automatic Program Construction Techniques, pages 
375-392. Macmillan, 1984. 
[10] Alan W. Biermann. Fundamental mechanisms in machine learning and inductive 
inference. In W. Bibel and Ph. Jorrand (editors), Fundamentals of Artificial Intel- 
ligence, pages 133-169. LNCS 232, Springer-Verlag, 1986. 
[11] Alan W. Biermann. Automatic programming. In S. C. Shapiro (editor), Encyclo- 
pedia of Artificial Intelligence, pages 59-83. John Wiley, 1992. Second, extended 
edition. 
[12] Alan W. Biermann and Douglas R. Smith. A production rule mechanism for gen- 
erating LISP code. IEEE Transactions on Systems, Man, and Cybernetics 
9(5):260-276, May 1979. 
[13] Ivan Bratko and Marko Grobelnik. Inductive learning applied to program con- 
struction and verification. In Proceedings oflLP'93, pages 279-292. 
[14] Maurice Bruynooghe and Danny De Schreye. Some thoughts on the role of exam- 
ples in program transformation and its relevance for explanation-based learning. 
In K. P. Jantke (editor), Proceedings of the 1989 International Workshop on Ana- 
logical and Inductive Inference, pages 60-77. LNCS 397, Springer-Verlag, 1989. 
[15] Franqois Bry. Intensional updates: Abduction via deduction. In D. H. D. Warren 
and P. Szeredi (editors), Proceedings oflCLP'90, pages 561-578. The MIT Press, 
1990. 
[16] Alan Bundy, Alan Smaill, and Geraint Wiggins. The synthesis of logic programs 
from inductive proofs. In J. W. Lloyd (editor), Proceedings of the ESPRITSympo- 
sium on Computational Logic, pages 135-149. Springer-Verlag, 1990. 
[17] Alan Bundy, Andrew Stevens, Frank van Harmelen, Andrew Ireland, and Alan 
Smaill. Rippling: A heuristic for guiding inductive proofs. Artificial Intelligence 
62(2): 185-253, 1993. 

84 
[ 18] Keith L. Clark. The synthesis and verification of logic programs. Technical Report 
DOC-81/36, Imperial College, London (UK), September 1981. 
[19] Tim Clement and Kung-Kiu Lau (editors), Proceedings of LOPSTR'91. Work- 
shops in Computing Series, Springer-Vedag, 1992. 
[20] Luc De Raedt. Interactive Theory Revision: An Inductive Logic Programming Ap- 
proach. Academic Press, 1992. 
[21] Luc De Raedt and Maurice Bruynooghe. Belief updating from integrity con- 
straints and queries. Artificial Intelligence 53(2-3):291-307, February 1992. 
[22] Luc De Raedt and Maurice Bruynooghe. A theory of clausal discovery. In Pro- 
ceedings of lLP'93, pages 25--40. 
[23] Nachum Dershowitz and Yuh-Jeng Lee. Logical debugging. Journal of Symbolic 
Computation 15(5-6):745-773, May/June 1993. Early version, entitled "Deduc- 
tive debugging", in Proceedings of SLP'87, pages 298-306. 
[24] Yves Deville. Logic Programming: Systematic Program Development. Interna- 
tional Series in Logic Programming, Addison Wesley, 1990. 
[25] Yves Deville (editor), Proceedings of LOPSTR'93. Workshops in Computing Se- 
ties, Springer-Verlag, 1994. 
[26] Yves Deville and Jean Burnay. Generalization and program schemata: A step to- 
wards computer-aided construction of logic programs. In E. L. Lusk and R. A. 
Overbeek (editors), Proceedings of the North American Conference on Logic Pro- 
gramming' 89, pages 409-425. The MIT Press. 
[27] Yves Deville and Kung-Kiu Lau. Logic program synthesis: A survey. Journal of 
Logic Programming, Special Issue on 10 Years of Logic Programming, 1994. 
[28] Wlodek Drabent, Simin Nadjm-Tehrani, and Jan Maluszynski. Algorithmic de- 
bugging with assertions. In H. Abramson and M. H. Rogers (editors), Meta-Pro- 
gramming in Logic Programming: Proceedings of META'88, pages 501-521. The 
MIT Press. 
[29] Agneta Eriksson and Anna-Lena Johansson. Computer-based synthesis of logic 
programs. In M. Dezani-Ciancaglini and U. Montanari (editors), Proceedings of 
an International Symposium on Programming, pages 105-115. LNCS 137, 
Springer-Verlag, 1982. 
[30] Peter Flach. Predicate invention in inductive data engineering. In Proceedings of 
the 1993 European Conference on Machine Learning, pages 83-94. LNAI 667, 
Springer-Verlag, 1993. 
[31] Pierre Flener. Logic Algorithm Synthesis from Examples and Properties. Ph.D. 
Thesis, Universit6 Catholique de Louvain, Louvain-la-Neuve (Belgium), June 
1993. 
[32] Pierre Flener and Yves Deville. Logic program synthesis from incomplete speci- 
fications. Journal of Symbolic Computation 15(5-6):775-805, May/June 1993. 
[33] Marta Fra~ovfi. Fundamentals of a new method for inductive theorem proving: 
CM-----construction of atomic formulae. In Proceedings of the 1988 European 
Conference on Artificial Intelligence. 
[34] Marta Fra~v~ and Yves Kodratoff. Predicate synthesis from formal specifica- 
tions or using mathematical induction for finding the preconditions of theorems. 
Technical Report 646, LRI, Universit6 Paris-Sud, 1991. 

85 
[35] Laurent Fribourg. Extracting logic programs from proofs that use extended Prolog 
execution and induction. In D. H. D. Warren and P. Szeredi (editors), Proceedings 
oflCLP'90, pages 685-699. The MIT Press, 1990. Updated and revised version 
in [50], pages 39-66. 
[36] Laurent Fribourg. Automatic generation of simplification lemmas for inductive 
proofs. In V. Saraswat and K. Ueda (editors), Proceedings ofSLP'91, pages 103- 
116. The MIT Press, 1991. 
[37] Norbert E. Fuchs. Hoare logic, executable specifications, and logic programs. 
Structured Programming 13:129-135, 1992. 
[38] Norbert E. Fuchs. Specifications are (preferably) executable. Software Engineer- 
ing Journal 7:323-334, September 1992. 
[39] Norbert E. Fuchs. Private communicationsl March-June 1994. 
[40] Norbert E. Fuchs and Markus P. J. Fromherz. Schema-based transformations of 
logic programs. In [19], pages 111-125. 
[41] E. Mark Gold. Language identification in the limit. Information and Control 
10(5):447--474, 1967. 
[42] Cordell Green and David R. Barstow. On program synthesis knowledge. Artificial 
Intelligence 10(3):241-270, November 1978. 
[43] Marko Grobelnik. Induction of Prolog programs with Markus. In [25], pages 57- 
63. 
[44] A. Guessoum and John W. Lloyd. Updating knowledge bases. New Generation 
Computing 8:71-88, 1990. 
[45] Masami Hagiya. Programming by example and proving by example using higher- 
order unification. In M. E. Stickel (editor), Proceedings of the 1990 Conference on 
Automated Deduction, pages 588-602. LNCS 449, Springer-Verlag, 1990. 
[46] ~,ke Hansson. A Formal Development of Programs. Ph.D. Thesis, University of 
Stockholm (Sweden), 1980. 
[47] I.J. Hayes and C.B. Jones. Specifications are not (necessarily) executable. Soft- 
ware Engineering Journal 4(6):330--338, November 1989. 
[48] Christopher J. Hogger. Derivation of logic programs. Journal of the ACM 
28(2):372-392, April 1981. 
[49] Andrew Ireland. The use of planning critics in mechanizing inductive proofs. In 
A. Voronkov (editor), Proceedings of LPAR'92, pages 178-189. LNCS 624, 
Springer-Verlag, 1992. 
[50] Jean-Marie Jacquet (editor). Constructing Logic Programs. John Wiley, 1993. 
[51] Klaus P. Jantke. Algorithmic learning from incomplete information: Principles 
and problems. In J. Dassow and J. Kelemen (editors), Machines, Languages, and 
Complexity, pages 188-207. LNCS 381, Springer-Verlag, 1989. 
[52] Alfpio M. Jorge and Pavel Brazdil. Learning by refining algorithm sketches. Pro- 
ceedings of ECAI'94. 1994. 
[53] Jyrki Kivinen and Heikki Mannila. Approximate dependency inference from rela- 
tions. In Proceedings of the 1992 International Conference on Database Theory. 
[54] Andonakis C. Kakas, Robert A. Kowalski, and E Toni. Abductive logic program- 
ming. Journal of Logic and Computation 2:719-770, 1992. 
[55] Robert A. Kowalski. Logic for Problem Solving. North Holland, 1979. 

86 
[56] Ina Kraan, David Basin, and Alan Bundy. Middle-out reasoning for logic program 
synthesis. In D.S. Warren (editor), Proceedings oflCLP'93, pages 441-455. The 
MIT Press, 1993. 
[57] Kung-Kiu Lau and Tim Clement (editors), Proceedings of LOPSTR'92. Work- 
shops in Computing Series, Springer-Verlag, 1993. 
[58] Kung-Kiu Lau and Mario Ornaghi. An incompleteness result for deductive syn- 
thesis of logic programs. In D.S. Warren (editor), Proceedings oflCLP'93, pages 
456-477. The MIT Press, 1993. 
[59] Kung-Kiu Lau and Mario Ornaghi. A formal view of specification, deductive syn- 
thesis and transformation of logic programs. In [25], pages 10-31. 
[60] Kung-Kiu Lau and Mario Ornaghi. On specification frameworks and deductive 
synthesis of logic programs. In this volume. 
[61] Kung-Kiu Lau, Mario Ornaghi, and Sten-/kke T~nlund. The halting problem for 
deductive synthesis of logic programs. In P. van Hentenryck (editor), Proceedings 
oflCLP'94, pages 665-683. The MIT Press, 1994. 
[62] Kung-Kiu Lau and S. D. Prestwich. Top-down synthesis of recursive logic proce- 
dures from first-order logic specifications. In D. H. D. Warren and P. Szeredi (ed- 
itors), Proceedings oflCLP'90, pages 667-684. The MIT Press, 1990. 
[63] Baudouin Le Charlier. R#flexions sur le probl~me de la correction des 
programmes. Ph.D. Thesis (in French), Facult6s Universitaires Notre-Dame de la 
Paix, Namur (Belgium), 1985. 
[64] Raul Monroy, Alan Bundy, and Andrew Ireland. Proof plans for the correction of 
false conjectures. In E Pfenning (editor), Proceedings ofLPAR'94. LNCS, Spring- 
er-Verlag, 1994. 
[65] Stephen Muggleton. Inductive logic programming. New Generation Computing 
8(4):295-317, 1991. 
[66] Stephen Muggleton (editor). Inductive Logic Programming. Volume APIC-38, 
Academic Press, 1992. 
[67] Stephen Muggleton and Luc De Raedt. Inductive logic programming: Theory and 
methods. Journal of Logic Programming, Special Issue on 10 Years of Logic Pro- 
gramming, 1994. 
[68] Leonard Pitt and Leslie G. Valiant. Computational limits on learning from exam- 
pies. Journal of the ACM 35(4):965-984, October 1988. 
[69] Gordon D. Plotkin. A note on inductive generalization. In B. Meltzer and D. 
Michie (editors). Machine Intelligence 5:153-163, 1970. Edinburgh University 
Press, Edinburgh (UK). 
[70] Lubo~ Popelinsk2~, Pierre Flener, and Olga St~p~inkov~i. ILP and automatic 
programming: Towards three approaches. Submitted to ILP'94, Bonn (Germany). 
[71] Proceedings of the International Workshop on Machine Learning'92 Workshop on 
Biases in Inductive Learning. Aberdeen (Scotland, UK), 1992. 
[72] Charles Rich and Richard C. Waters. Automatic programming: Myths and pros- 
pects. IEEE Computer 21(8):40-51, August 1988. 
[73] Taisuke Sato and Hisao Tamaki. Transformational logic program synthesis. In 
Proceedings of the International Conference on Fifth-Generation Computer Sys- 
tems, pages 195-201, 1984. 

87 
[74] Taisuke Sato and Hisao Tamaki. First-order compiler: A deterministic logic pro- 
gram synthesis algorithm. Journal of Symbolic Computation 8(6):605-627, 1989. 
[75] Iztok Savnik and Peter Flach. Bottom-up induction of functional dependencies 
from relations. In Proceedings of the AAA/'93 Workshop on Knowledge Discovery 
in Databases. 
[76] Ehud Y. Shapiro. Algorithmic Program Debugging. Ph.D. Thesis, Yale University, 
New Haven (CT, USA), 1982. Published under the same title by The MIT Press, 
1983. 
[77] Douglas R. Smith. The synthesis of LISP programs from examples: A survey. In 
Alan W. Biermann, G6rard Guiho, and Yves Kodratoff (editors). Automatic Pro- 
gram Construction Techniques, pages 307-324. Macmillan, 1984. 
[78] Douglas R. Smith. Top-down synthesis of divide-and-conquer algorithms. Artifi- 
cial Intelligence 27(1):43-96, 1985. 
[79] Douglas R. Smith. KIDS: A semiautomatic program development system. IEEE 
Transactions on Software Engineering 16(9): 1024-1043, September 1990. 
[80] Leon S. Sterling and Marc Kirschenbaum. Applying techniques to skeletons. In 
[50], pages 127-140. 
[81] Phillip D. Summers. A methodology for LISP program construction from exam- 
pies. Journal of the ACM 24(1): 161-175, January 1977. 
[82] William R. Swartout and Robert Balzer. On the inevitable intertwining of specifi- 
cation and implementation. Communications of the ACM 25:438--440, 1982. 
[83] Yukihide Takayama. Writing programs as QJ proof and compiling into Prolog pro- 
grams. In Proceedings of SLP' 87, pages 278-287. 
[84] Nancy L. Tinkham. Induction of Schemata for Program Synthesis. Ph.D. Thesis, 
Duke University, Durham (NC, USA), 1990. 
[85] Axel van Lamsweerde. Learning machine learning. In A. Thayse (editor), From 
Natural Language Processing to Logic for Expert Systems, pages 263-356. John 
Wiley, 1991. 
[86] Geraint Wiggins. Synthesis and transformation of logic programs in the Whelk 
proof development system. In K. Apt (editor), Proceedings of the Joint Interna- 
tional Conference and Symposium on Logic Programming'92, pages 351-365. 
The MIT Press, 1992. 

Transforming Specifications of Observable 
Behaviour into Programs 
David Gilbert 1, Christopher Hogger ~, Ji~i Zlatuw 3 
1 City University, Northampton Square, London ECIV 0HB, U.K. 
drg~cs.city.ac.uk 
2 Imperial College, 180 Queens Gate, London SW7 2BZ, U.K. 
cjh~doc.ic.ac.uk 
3 Masaryk University, Bure~ova 20, 602 00 Brno, Czech Republic 
zlatuska@informatics.muni.cz 
A methodology for deriving programs from specifications of observable 
behaviour is described. The class of processes to which this methodology 
is applicable includes those whose state changes are fully definable by la- 
belled transition systems, for example communicating processes without 
internal state changes. A logic program representation of such labelled 
transition systems is proposed, interpreters based on path searching tech- 
niques are defined, and the use of partial evaluation techniques to derive 
the executable programs is described. 
1 
Motivations 
Our methodology provides a means for deriving executable programs from speci- 
fications of the observable behaviour of a restricted class of systems. The systems 
which are tractable by this methodology are those whose observations are dis- 
crete fine-grained steps which progressively construct data objects, expressed as 
terms in our approach. We give the characterisation of these systems by the 
use of a language based on labelled transition systems, and identify a class of 
interpreters derived from rewriting and path searching algorithms on the graphs 
induced by the labelled transition systems. Furthermore, we are able to derive 
programs by partially evaluating such interpreters with respect to the rules in 
the language of the labelled transition systems. We also provide a formalism 
which permits the transformation of the labelled transition systems into the 
target programs within the framework of computational logic. 
The class of computations in which we are interested contains those whose 
result is incrementally constructed, whilst at the same time the partial results 
are being output as observations which are accessible to the environment of the 
computing agent. For some of these computations it is natural also to specify such 
processes in terms of their observable behaviour. We believe this may be closer 
to the user's understanding of the system to be programmed, when the external 
behaviour of the system and the sequence in which the result is produced (i.e. a 
trace history) is an essential part of the activity of the process. For the sake of 
simplicity, we assume that the observation of the external behaviour is tightly 

89 
linked to the internal computation steps of such a system, i.e. each step of the 
computation strictly extends the resulting data structure which it constructs. 
Our method regards observations of the progress of a computation as ex- 
trinsic specifications which can be represented as directed acyclic graphs. Each 
computation that the system can perform is represented by a path through the 
graph, which in turn can be described in first order logic. Logic programs can 
be derived from these first order logic descriptions by standard transformations. 
We view the long-term objective of our method to be the construction of 
reactive concurrent systems. As a first step towards this objective we present 
a working framework for sequential systems. From a more abstract point of 
view, we can understand the procedure for constructing programs from graphs 
representing observable behaviour as a compiler of a graph-based production 
language. A particular strategy for the generation of computations from such 
a graph can be linked to the particular strategy for the search of the tree rep- 
resenting the trace history of the execution of the corresponding program. In 
general, the method as presented in this paper makes no assumptions about the 
sequential or concurrent behaviour of the programs which have been generated; 
such behaviour is a result of the execution mechanism for these programs. 
2 
Summary 
of the Approach 
The outline of our approach can be given as follows: first, give a specification of 
all the possible sequences of the observable behaviour of the system to be con- 
structed. This is done by determining the elementary transitions between the 
states of the program which produce the observables, and taking these transi- 
tions as a definition of a labelled transition system which can generate all the 
possible state changes. Since we assume that every change of state of a program 
is immediately reflected in production of an observable (i.e. an output visible to 
the external observer), we identify internal states with their associated observa- 
tions. 
Second, take a general interpreter of the resulting labelled transition system 
expressed in a suitable language. This interpreter is a path searching algorithm 
which explores the graph of transitions generated by the system. The structure 
of observations, labelled transitions, and the path searching procedure can all 
be formalised in the language of first-order Horn clause logic. Labels of the 
initial transformation system are identified with suitable variables, and partial 
objects built as a result of partial execution of the program. These objects can 
be identified with terms containing variables in places at which the structure 
will be later extended during further program execution. Within the language of 
logic, generation of a particular observable corresponds to substituting the term 
representing this observable for the free variable at the location where the new 
observable occurs. Hence the term which is being constructed during a program 
run corresponds to a tree of a particular history of observable state transitions, 
represented as a term. 

90 
When specifying path-searching procedures working over the state space of a 
particular labelled transition system represented in logic, substitution plays the 
the r61e of the basic operation performed. Each transition of the initial labelled 
transition system thus corresponds to an atomic substitution, and sequences 
of transitions correspond to compositions of atomic substitutions of this kind. 
Based on this, the path-searching procedure works over compositions of substi- 
tutions. Therefore the resulting program defined by such a system amounts to a 
generator of substitutions. These substitutions in turn correspond to changes of 
program observables, i.e. to program state transitions. The substitution genera- 
tor therefore works as an interpreter working over the labelled transition system. 
Finally, generate a program which implements the labelled transition system 
by partially interpreting the path searching algorithm applied to the set of tran- 
sition rules. We employ a partial evaluator for logic programs for this and hence 
use logic programming for all three steps. 
The scheme outlined above depends on the feasibility of realising each of the 
steps involved so that the goal of generating the program from the specification 
can in fact be achieved. In this paper we describe a particular formal framework 
which permits this goal to be accomplished. We start with a simple definition 
of a labelled transition system defined as a system for synchronously rewriting 
several labels during one transition step. The intuitive meaning of this definition 
is that several processing agents can act synchronously within the computational 
environment. We then embed these systems into clauses defining transitions of 
the system. From this point on, all of the construction is performed in a logic 
programming language, Prolog in our test implementation, starting from data 
structures, path-searching algorithms and generation of state-change histories 
i.e. terms generated by subsequent applications of substitutions corresponding to 
observable changes. The partial interpretation needed is therefore just a general 
logic programming partial interpreter (Mixtus [21] in our case). 
Within each of the steps we discuss the data structures involved and the sim- 
plifications which can be employed. Note that because of the meta-programming 
features of our approach which is based on a path-searching interpreter, we need 
to specify substitutions as operations at the meta-level, rather than to rely on 
substitutions performed by the underlying engine of the logic programming lan- 
guage used for implementation. If the method is to be practically usable, the 
implementation of the manipulation of substitutions has to be substantially sim- 
plified in order that the generation of the final programs by partial evaluation 
terminates. Special discussion is therefore devoted to using the general proper- 
ties of the substitutions which can possibly occur during the process of path 
generation, and to designing a modified definition of substitution suitable for 
this step. 
3 
Specifying Observable Changes 
We use a labelled transition system (LTS) to describe possible changes of ob- 
servables in the system. Such a system is given by a set of transition rules of the 

9] 
form 
(xl,...,xn) ~ (tl,...,tn) 
where n _> 1 
Note that we permit more than one label on the left-hand side of the transition, 
enabling us to describe systems where more than one observables may change 
concurrently, xl,..., xn are the labels, or identifiers representing observables, 
and tl,...,tn 
are general expressions built over the labels and other atoms. 
These latter denote the resulting configuration after observable change, and may 
include the observable identifiers again as a proper subpart of any of them. The 
expressions on the right-hand side correspond to fragments of the trees (terms) 
of trace histories associated with observable data generation. 
An example of a labelled transition rule which describes the generation of a 
list is 
(x) ~ (a.x) 
We may extend this to the description of a system which counts the number of 
items in a list: 
(x, y) ~ (a.x, succ(y)) 
The informal motivation is to consider the labels as states, and to take each 
transition rule as a definition of a state change, possibly acting synchronously 
over several processes (if n > 1). The expressions on the right-hand side per- 
mit the definition of both the observable output and the resulting change of the 
state, including termination or splitting into several processes. One can think 
of the expressions generated by systems of this kind as snapshots of trace his- 
tories of processes which are represented by labels. Transitions can be applied 
to any of those labels in order to expand the structure representing the current 
partial trace-history. Observables produced by the system correspond to func- 
tots (atoms) occurring in the expressions generated by the LTS. (In the logic 
programming representation, these will be functors of the language.) 
The descriptive power of the formalism is most easily understood by consid- 
ering the class of processes which can be determined by a LTS as a language 
generated by a grammar derived from it. On an abstract level, any LTS cor- 
responds to a grammar whose nonterminal symbols represent the labels of the 
LTS, and whose terminal symbols correspond to data structures. Thus the non- 
terminals actually correspond to states of a computation (sequential or parallel) 
represented by expanding the starting state. Even in the sequential case, the 
resulting pattern is different from just recursive descent due to the treatment of 
all the non-terminals produced in an expansion step as a partial process output. 
This reflects our interest in focussing primarily on generating/specifying traces 
of computations as sequences of process outputs, not just the resulting (data) 
structure given by the words generated by the grammar. 
If the transitions of the LTS transitions only have one label expanded at 
each step the resulting grammar is at most a context free grammar, with all the 
inherent limitations of CFGs, which for example cannot represent the concurrent 
update of more than one label. The treatment of the class of systems which we 
consider within our framework contains transition rules which can concurrently 

92 
transform several labels at the same time, permitting us to describe concurrent 
systems, and leads to a sub-class of context grammars which is strictly larger 
than CFGs. 
4 
Target Program Structure 
The processes specified by this class of LTS can be represented in various ways, 
depending on the actual programming paradigm selected. In our approach, rep- 
resentation as a logic program is chosen, because of the declarative nature of this 
paradigm. This permits us to develop a framework for program synthesis which 
is independent of the particular implementation of the processes it defines, either 
sequential or concurrent. When the resulting logic programs are coupled with 
a corresponding evaluation strategy, this is effectively equivalent to a program 
in a procedural programming language, yet the particular level of abstraction 
permits a more succinct representation of the problem. 
The observables of a logic program are the logical variables in the initial goal 
associated with it. Unification is the finest level of granularity which is useful to 
observe, and thus unification steps are taken to be the atomic events which are 
observable. Communication in a logic programming system occurs via bindings 
made to shared variables, and our assumption is that an observer can detect the 
incremental bindings made to the variables in the initial goal (i.e. to external 
variables). The observations made are posets of binding sets; we can represent 
these posets as directed acyclic graphs, due to the write-once nature of the logic 
variable. The bottom element of such a set represents the initial unbound state 
of the observable variables. Each path through the graph from the minimum 
vertex to a maximum vertex comprises the observations of one computation and 
the union of the sets associated with all such paths comprises the instantiation 
set of the observational variable(s). 
An example is the instantiation set of the following directed graph for the 
variable x. Nodes are labelled with the term to which z is bound, and an arc 
from node A to node B is labelled with the substitution which when applied to 
the term at A results in the term at B. 
f(~,,~) 
~l~I//'/ "~m} 
f(",z) CK~,/t' '1~}/,)' f(,,'~) 
f(y, z) 
{~lf(~, z)} 
X 
Fig. 1. 

93 
{x/f(y, z), x/f(tl, z), x/f(tl, t2)} U {x/f(y, z), x/f(y, t2), x/f(tl, t2)]'k.J 
= 
z), 
Given the choice of logic variables as observables, the actual data items pro- 
duced by a running program are represented by the functors of the language 
of terms. Therefore changes of a process state are manifested by assignment of 
data to the tuple of logic variables representing the process. The particular syn- 
tactic structure is just a consequence of our use of logic terms to represent data 
structures. During the transformation of terms into prefix/postfix notation, the 
non-variable symbols in them correspond straightforwardly to terminal symbols 
of the grammar associated with the original LTS. The use of logic variables per- 
mits the representation of trace histories as simple variable bindings, with no 
additional formalism being needed. 
An example of an LTS is the pair of transition rules: 
(x) ~ 
(a.x) 
(x) ~ (nil) 
These rules represent an LTS which describes the behaviour of a process which 
binds a variable to list and whose trace history is itself a list of the binding states 
of that variable. 
There is a regular grammar corresponding to this system, 
X --* aX 
X --+ e 
characterizing the set of process behaviour as the corresponding regular set of 
sequences of data items a of arbitrary length. 
The logic-variable representation uses just one type, X, for the variables of 
the LTS. The tuples on the right-hand sides of the production rules can be 
represented by terms a(z), where z is a variable of the type X and a a unary 
function symbol, and by a nullary functor symbol nil, respectively. 
5 
Logic Program 
Representation 
When specifying a logic program, we choose to identify the observables by logic 
variables. As far as these correspond to distinct labels of the LTS, or distinct 
non-terminals of the grammar, there is a need to ensure that the correspondence 
of every variable with its associated label is preserved. Without such correspon- 
dence substitutions may be applied to incorrect variables. This correspondence 
can be achieved by partitioning the sets of labels and identifiers using tags. On 
the level of specification, we choose to work in a multi-sorted logic, where types 
can be used to perform this tagging function. Each variable is therefore asso- 
ciated with a unique fixed type. All the usual properties of logic programs are 
preserved within this, and the only change to the underlying machinery required 

94 
is that of modifying unification so that it fails whenever an attempt to bind a 
variable of certain type to a term of different type is made. 
Thus, for example, in the rule 
y) 
succ(y)) 
we consider that x and y are of different types. 
The type scheme resulting from the use of labels of the LTS as types of 
the system permits simple static type checking, for example that of G5del [11]. 
Note that with static type checking it is sufficient to verify type constraints at 
the level of the source program code, and so at run-time it is possible to use 
type-less logic programming language, such as Prolog, and hence not to refer to 
types. In our case this corresponds to the need to ensure proper type constraints 
when writing the interpreter, as proposed by Hill and Lloyd [10], but the actual 
programs generated by partial evaluation are ordinary type-less logic programs. 
The idea of using typed terms is just a syntactic means for avoiding the 
use of dynamic predicate-based type checking. The untyped predicate logic is 
expressible enough to define all that is needed for this, but requires the use of 
a more complex clause structure for the representation of the transition rules. 
Specifically we need to introduce predicates for dynamic type checking into each 
of the clauses of the interpreter. The framework of typed terms seems more 
natural in our context for two reasons. Firstly because of the example of the 
successful use of types in logic programming which has been set by GSdel, and 
secondly because the use of types simplifies the representation of transition rules 
as clauses by effectively moving the type-checking predicates out of such clauses 
into the code of a general-purpose interpreter. 
For the representation of the LTS, the left-hand side of a rule becomes a 
tuple of logic variables, and the right-hand side is represented by a tuple of 
terms containing new versions of the variables, all of the variables being typed 
by the appropriate LTS label types. The version of the above example would be 
(z, y) ~ (a.z', succ(y')) 
where x and z ~ are of the same type, and so are y and y~. 
In order to implement the above process in Prolog, we choose a representa- 
tion of variables in which each variable carries its source observable id as a type 
associated with it. This observable id tag controls the possible Variable occur- 
rences which may or may not match with the variables resulting from a labelled 
transition rule. Obviously, when using a typed logic programming language such 
as GSdel, the representation could be made simpler. 
Observable changes can now be described by the successive instantiation of 
variables, a characteristic feature being the possibility of binding variable to a 
term containing yet more variables. Non-linear structures can be generated in 
such a way, with several new observables being generated as a result, for example 
the generation of tree structures. 
Instantiations of variables are carried out by substitutions, defined as mor- 
phisms on terms, fully described by their result on variables. In the case of finite 

95 
substitutions (which only change a finite number of variables), the usual notation 
e = 
describes a mapping defined as 
ti 
if t = xi for xi/ti E O; 
tO = 
t 
if t is a variable, not occurring as t/u E 0 for any u; 
f(tlO,...,tnlg) 
fort---f(tl,...,tn),n>0. 
Substitutions define state-changing operations on the processes, and the 
program-generating process developed later in this paper is based on building a 
meta interpreter which combines substitutions in a suitable way. 
The process of observables transformation leads to the composition of substi- 
tutions defined as function compositions. On finite substitutions this this gives 
the following standard definition: 
Oa = [zltalx/t e 0 and x # ta] O [yls e a and for every t, ylt â€¢ 0] 
Note that the second operand of the union allows us to eliminate those changes 
to variables defined by a which are ineffective because of a previous elimination 
of suitable variable occurences by/7. We will employ this fact in the following 
section to simplify our working definition of composition. 
At this point, the LTS can be transformed into substitutions: for each rule 
>-> (tl,..., t,) 
generate a set of substitutions of the form 
[xxlt'~,..., xnl t'] 
with identifiers expressed as logic variables. Moreover, within each pair xi/t~, t~ 
is formed from ti by renaming all variables into fresh ones. As noted above, we as- 
sume the existence of typed variables, and hence the framework of a multi-sorted 
language. When actually implementing this operation in a language lacking strict 
type discipline (such as Prolog), some extra care must be taken in the actual 
code to ensure that the types of the variables are preserved when renaming them. 
Now the program specification part can be viewed as the set of rules de- 
scribing the accumulation of substitutions: input substitution is composed with 
the observable-changing substitution in order that the resulting substitution is 
a new configuration of the system. 
6 
Instantiation Steps 
Our method describes computations as ones which progressively instantiate vari- 
ables to terms. We represent terms explicitly by substitution sets, and describe 
the instantiation of a term t to a more specialised form t ~ by the relation 
compose(x, y, z) where 

96 
x is the substitution set associated with t 
z is the substitution set associated with t' 
y is the substitution set whose composition with x results in z. 
For example, consider the following set of possible instances of a variable x 
{x, f(y, z), /(t~, z), f(y, t2), f(tl, t2)} 
which corresponds to the set of atomic substitutions illustrated by Figure 1 
above. From this poset we may extract, by closure over the arcs, one of the 
possible binding histories, e.g. 
[x/.f(y, z)]..[z//(h, z)]..[x//(h, t2)] 
which we illustrate in Figure 2 below 
f(h, t2) 
.f(t~, z) % 
T, 
Fig. 2. 
f(y,z) 
{~/f(y,~)} 
We can then associate the following compositions with the binding history: 
compose([x//(y, z)], [~/ti], [x//(tl, z), y/td), 
compose([x/.f(t~, ~), y/t~], [z/t~], [x/.f(h, t~), y/t~, ~/t~]) 
We will need to add some restrictions to the standard definition of substitu- 
tion in order to refine our technique. The first is linked to our basic assumptions 
about the class of systems we are interested in. The acyclicity of the underlying 
LTS reflects the intuition that during the process of computation there is always 
some visible non-empty output after each step. In terms of bindings, this means 
that there is a progression in the binding sequence which prohibits simple re- 
naming occurring as local instantiation steps. This permits the elimination of 
useless compositions such as compose([x/y], [y/z], [x/z, y/z]) and hence prohibits 
the inclusion of x/y where x and y are variables in the substitution set at the 
second argument of compose/3 
Our top-level definition is 
compose(A, B, C) ~ progress(A, B, C), full-compose(A, B, C) 
where full-compose~3 is the relation corresponding exactly to the general 
mathematical definition of substitution composition without any additional re- 
strictions. 
Here progress(A, B, C) means that C is not a variant of A, i.e. B must be 
some non-trivial binding corresponding to an observable state change. 

97 
The above-outlined model is too general and contains excessive checks on the 
substitutions which result from composition. The checks for idempotent substi- 
tution pairs and for the elimination of variables from the standard definition 
of substitution make the partial evaluation of the target program unnecessarily 
complicated. Pragmatically we found the definition to be too general, and the 
partial evaluation did not terminate under Mixtus. The picture can be simplified 
by the consideration of the constraints result from the source LTS structure and 
the way substitutions are generated from it. 
First, variables on the right-hand side of substitution pairs can be renamed, 
so that zi ~ ti for any zJtd. Also, for any zd/td E ~ there is no yduj E ~ such 
that zd E uj for any substitution pair ~, ~r, which can possibly be considered 
a result from composing substitution 8 with substitution ~, resulting from LTS. 
This is because variables in uj have been generated as fresh, not yet occurring 
elsewhere. As a result, the idempotency check can be omitted from the definition 
of composition. 
Second, in substitutions 8 and ~, for any zd/td E 0 there is no yj/uj E 
such that xd = Yd. Again, this is a result of state-changing substitution being 
generated from LTS rules. Consequently, the elimination check can be omitted 
as well. 
The resulting definition of substitution needed for describing observable 
changes therefore reads as follows: 
This allows us to simplify the partial-evaluation phase significantly (see Sec- 
tion 9), and to provide for a manageable program generator out of the source 
LTS. 
7 
Constraining Instantiation Steps 
The definition of composition as given above is too general for our purposes and 
does not constrain instantiation to any particular discrete steps. The concept of 
expanding the underlying LTS-related grammar corresponds to performing com- 
putations using the LTS-based specification which leads to the identification of 
computational steps with the expansion of non-terminals, i.e. variable instantia- 
tion. Such an instantiation is limited to terms of the structure which correspond 
to the left-hand sides of transformation rules, i.e. such an instantiation step typ- 
ically replaces variables either by constants or by trees of a restricted depth. 
Hence we are only interested in systems which instantiate terms in such a mini- 
mal manner, and thus introduce the notion of a (non-null) atomic substitution 
set Y whose application to a substitution set X by compose(X,Y,Z) satisfies the 
following constraints: 
- There is at least one non-ground ti of vi/~i E X which is further instantiated 
by vj/tj E Y (where tj is not a variable). 
- 
vj/tj is minimal in some sense to the particular application 

98 
We can define atomic/1 which is part of the meta-interpreter by: 
atomic(Y) ~--Its(P ~ Q), transform(P ~-* Q, Y) 
where Its/l is the object level program and transform/2 performs the transfor- 
mation operation from the LTS into substitutions referred to in Section 5. For 
example, we may take for lists the pair of transition rules represented by Its/l: 
Its((=) ~ (a.x)) 
Its((x) 
(nit)) 
which are transformed to [x/a.x ~] and [x/nil] respectively. 
We now can give a definition of a new predicate inst(X,Z) which relates a 
substitution set X, about a term T, to a substitution set Z, about the immediate 
successor T' of T, as determined by some applicable substitution set Y: 
inst(X,Z) ~-- atomic(Y), compose(X,Y,Z) 
8 
Node Traversal of Instantiation 
Graphs 
The inst/2 predicate allows us to describe only one individual step, or edge, 
in the instantiation graph which represents the graph of transitions, whereas we 
ultimately intend to describe the graph as a whole. More specifically, having pro- 
vided a definition or program for 'inst' in respect of some particular application, 
we want to incorporate it within some encompassing program which traverses 
the DAG determined by 'inst'. The classic path traversal method, for example 
as shown by Kowalski [13] relates nodes (in this case substitution sets) to their 
subsequent states. Consider any node N already generated; after one or more 
atomic steps, various paths will have been developed to some further node N. 
We can define the following path-finding programs by the transitive closure of 
inst/2: 
Program A1 
path(N, F)~-inst(N, F) 
path(N, F) *--inst(N, N'), path(N', F) 
inst(N, F) *- compose(N, Y, F), atomic(Y) 
Program A2 
path(N, F)*--inst(N, F) 
path(N, F) ~-inst(N', F), path(N, N') 
inst(N, F) *-- compose(N, Y, F), atomic(Y) 
Which program is used is determined by the input-output mode with which 
path/2 is queried; the entire graph can be traversed by inputting N as the bottom 
node and using pathl to seek all reachable nodes F, or vice-versa. 
We can now follow the method of Gilbert and Hogger [8] which derived path 
exploration programs which computed only the di~erences between nodes. In 
the context in which compose/3 appears, constrained together with atomic/l, it 
cannot be used in any way which would not satisfy the following conditions, as 
defined by Brough and Hogger [4]: 

99 
(1) (VN VY B F)(compose(N,Y,F)) 
Some result F be defined for any Y applied to any N. 
(2) (3I VY VF)(compose(I,Y,F) ~ Y=F) 
compose to have at least one left-identity I. 
(3) (VN VY VY' VF) ((compose(N,Y',F) ~-~ Y'=Y) ~-- compose(N,Y,F)) 
(VN VY V F V F') ((compose(N,Y,F') *-* F'=F) ~- compose(N,Y,F)) 
compose to be functional in two of its modes. 
(4) (VN VN' VY VY' VY" VF) ((compose(N,V,F) ~ compose(N',Y',F)) 
~-- (compose(Y",V',Y) A compose(N,Y",N'))) 
compose to be associative, 
This new path exploration relation path/1 is defined by 
Program B1 
path(Y) ~- atomic(Y) 
path(Y) *- compose(Y', Y', Y), atomic(Y') , path(Y') 
Program B2 
path(Y) *- atomic(Y) 
path(Y) *-- compose(Y', Y', Y), atomic(Y') , path(Y') 
We should note that all the four path searching programs above act as inter- 
preters for programs defined by the Its/1 relation. 
9 
Program 
Derivation 
by Partial 
Evaluation 
Programs A1, A2, B1 and B2 can be used as general templates to describe a 
class of programs which incrementally instantiate observable variables during 
the course of their execution; specific instances of programs are determined by 
the definition of atomic/i, determined by Its/1. We have coded the relations for 
compose/3, atomic/1 and both path/1 and path/2 in SICStus Prolog in order 
to explore the possibilities of transforming the generic path programs into spe- 
cialised forms for given LTS's. A design decision was taken early on to distinguish 
between meta-level and object-level variables in the Prolog code by using the 
ground term representation, in order to preserve the semantics of the definitions. 
We then use partial evaluation in order to produce a program which in- 
corporates the path searching interpreter and our compose/3 relation with a 
specific labelled transition system as defined by Its/1. Partial evaluation of logic 
programs is an optimisation technique which has been described in logic pro- 
gramming terms by Lloyd and Shepherdson [15] as follows: "Given a program 
P and a goal G, partial evaluation produces a new program P' which is P 'spe- 
cialised' to the goal G. The intention is that G should have the same (correct 
and computed) answers w.r.t. P and P', and that G should run more efficiently 
for P' than for P". Both folding and unfolding are techniques used in partial 
evaluation: 

100 
- logical folding is the replacement of a goal that is an instance of the body of 
a clause by the corresponding instance of the head of the clause; 
- logical unfolding of the goal Xi in the clause 
H~ X1,..., Xi-1, Xi, Xi+l,..., X, 
where Xi is defined by X~--- B1,..., Bm is defined by the following transfor- 
mation: 
{(H~ Xl, ..., Xi-1, B1,..., Bin, Xi+l,..., X,OO I mgu(X, Xi)A 0 # false} 
Although partial evaluation can be done by hand, we have used Mixtus [21], 
the excellent partial evaluator for Prolog developed by Dan Sahlin, and have 
obtained good initial results. 
The choice of Prolog permits the simplification of the relationship between 
the data structures used, the meta-interpreter of the substitution-changing re- 
lation, and the resulting synthesized code. This is because the same language 
is used to represent the observables, the program in the LTS language and the 
interpreter based on graph searching. The methodology itself is nonetheless ap- 
plicable to any implementation language, but the amount of code actually needed 
may be significantly greater. 
In the case of an implementation in logic programming, the method natu- 
rally does not provide any universal mechanism for synthesizing arbitrary logic 
programs. By the nature of the initial assumptions chosen, only programs whose 
state changes result in bindings to variables in an initial query are expressible 
by this method. On the general level of process description this corresponds to 
systems whose change of state is always visible to the outside environment, e.g. 
via observable communication between processes. 
10 
Comparison 
with other work 
The algebraic structure of atomic formulae, including the lattice properties of 
the instantiation order relation, were described independently in the early sev- 
enties by Reynolds [18] and Plotkin [16]. Both authors were also interested in 
mechanical theorem proving. Reynolds showed in his paper that the refutation 
of "transformational systems" (sets of clauses containing only unit clauses and 
clauses with one positive and one negative literal) was in effect path searching, 
but that there was no decision procedure for such systems. Plotkin discussed the 
use of induction to find least generalizations of clauses or literals and showed 
that there is an algorithm to find the least generalization of any pair of literals 
or terms. It is interesting to note that in his paper Plotkin considered the possi- 
bilities of automated induction; the path searching algorithms described in our 
work relate to induction, but it is not our goal to try to enhance the specification 
by generalisation. 
Belia and Occhiuto [2] have developed an explicit calculus of substitutions 
which extends Reynold's gci [18] and combines Robinson's unification [19] and 
term instances. Their work aims to avoid the drawback of the gap between 
the theory and current implementations of logic programming languages repre- 
sented by the use of metalevel structures, like substitutions, and mechanisms, 

101 
like mgu and instantiation, to deal with the substitution rule. Their calculus of 
c-expressions permits structures to be dealt with explicitly at the object level 
which would otherwise typically be hidden at the metalevel. They put the substi- 
tution rule as an additional operator, mgi, of the language of terms, and provide 
c-expressions as programs. We prefer to work initially at the metalevel, and to 
take a classical approach based on interpretation [13, Chapter 12] and partial 
evaluation (see for example [15, 3]). C-expressions which use integers as tuple 
indexes do not exploit the tree structure of terms; Belia and Occhiuto are inves- 
tigating a different calculus using paths instead of integers, which may be closer 
to our approach. 
The language of Associons [17] was developed by Martin Rem as a program 
notation without variables; the motivation was to develop a language model 
which employed more concurrency than traditional languages based on assign- 
ment. An associon is a tuple of names defining a relation between entities repre- 
sented by these names. The state of a computation can be changed by a forward 
chaining process based on the "closure statement", which creates new associons 
that represent new relations deduced from the already existing ones. The lan- 
guage of associons is essentially deterministic and is based on sets. In fact the 
language does have logical variables and also universal quantifiers over closure 
statements. These statements are effectively normal program clauses (i.e. they 
can contain negated conditions) [14], and also contain guards. Our programs 
are expressed as definite program clauses, without negated conditions, and in 
contrast to Rem's language our approach is based on the backward-chaining 
principle of logic programming and permits the expression of all-solutions non- 
determinism since our language does not contain guards. A similarity between 
our approach and that of Rem is that both formalisms permit the construction 
of programs which are inherently concurrent. 
Ban~tre and Le M~tayer have developed the Gamma language [1] which also 
permits the construction of programs which are inherently parallel in their op- 
eration. A Gamma program is essentially a multiset transformer operating on 
all the data at once; it 'reacts' on multisets of data by replacing a subset whose 
elements satisfy a given property by the result of the application of a function 
on that subset. Gamma is an intermediate language between specifications in 
first order logic and traditional programming languages; programs in Gamma 
describe the logic of an algorithm and are transformed into executable programs 
by expressing lower-level choice such as data representation and execution or- 
der. Central to the Gamma language is non-determinism, expressed as the choice 
between several subsets which are candidates for reaction, and the locality prin- 
ciple, which permits independent and simultaneous reactions on disjoint subsets. 
The multiset is seen as a representation of the state of a system in Gamma; al- 
though our approach is based on sets rather than multisets, there is a similarity 
in that the set of bindings is regarded as the state of the system. There is no 
recursive data structure definition in Gamma, and data has to be represented 
as flat multisets of items; for example trees are represented by nodes and leaves 
associated with parenthood information. We preserve the tree structure of terms 

102 
due to our use of term substitution, but do employ types to indicate the posi- 
tion of subterms within a term. In both Gamma and our formalism this means 
that all components of a data structure are directly accessible, independently of 
their position in the structure. However, in contrast with Gamma, our technique 
does not have direct equivalents to the operations of data expansion and data 
reduction. 
The work of Gilbert and Hogger [8, 9] described the instantiation of a given 
term X by a given substitution Y to give a new term Z by a relation subst(X,Y,Z) 
where any substitution Y was constructed by applying a tupling <> to some 
set {Y1,...,Yn} of simpler substitutions. Y was represented by means of a 
substitution-tree, and a special symbol A used exclusively to describe variables. 
A major drawback of this method is that it was only applicable systems which 
generated lists, since the non-inclusion of S-trees in the Herbrand universe re- 
quired the transformation of the subst/3 relation into one which does operate 
over Herbrand terms, but which is not associative. 
Our work is closely related to the area of partial evaluation, in particular as 
applied to logic programs. Work in this field has been carried out by Lloyd et 
al. [15, 3] amongst others, who have given a strong theoretical foundation for 
partial evaluation in logic programming, and Dan Sahlin, who has constructed 
a robust partial evaluator for Prolog [20, 21]. Partial evaluation for concurrent 
logic languages has been explored by ~jita et al. [6] for GHC programs, and by 
Huntbach [12] for Parlog programs. 
Furthermore, our method based on a graph traversal template can be re- 
garded as an interpreter for graph-based computations, and in this sense is re- 
lated to the work by Gallier et al. [7] on graph-based interpreters for general 
Horn clauses. 
11 
Conclusions 
The work reported in this paper reconstructs the method of Gilbert and Hogger 
for deriving logic programs from the expected observations of program behaviour. 
We replace their concept of substitution trees (S-trees) by binding sets, and show 
that a more general method can be developed based on substitution mappings as 
the basis for the theory. We have formulated path exploration programs which act 
as generalised program schemata for certain classes of systems, and have derived 
specialised instances of these programs by partial evaluation of the schemata and 
specifications of program behaviour given in terms of labelled transition systems. 
The partial evaluation stage has been successfully mechanised using Mixtus [21], 
a partial evaluator for Prolog. 
Acknowledgements 
This work was partially supported by PECO Fellowship grants CT931675 (David 
Gilbert) and CT926844 (Jiii Zlatu~ka) provided by the European Community 
under the scheme for Scientific and Technical Cooperation with Central and 
Eastern Europe. 

103 
References 
1. J-P. Ban~tre and D. Le M6tayer. Programming by Multiset Transformation. Com- 
munications of the ACM, 36(1):98-111, 1993. 
2. M. Belia and M. E. Occhiuto. C-expressions: a variable-free calculus for equational 
logic programming. Theoretical Computer Science, 107:209-252, 1993. 
3. K. Benkerimi and J. W. Lloyd. A partial evaluation procedure for logic programs. 
In Debray and Hermenegildo [5], pages 343-358. 
4. D. R. Brough and C. J. Hogger. Compiling associativity into logic programs. The 
Journal of Logic Programming, 4(4):345-360, December 1987. 
5. S. Debray and M. Hermenegildo, editors. Proceedings of the 1990 North American 
Conference on Logic Programming, Austin, 1990. ALP, MIT Press. 
6. H. Pujita, A. Okumura, and K. Furukawa. Partial evaluation of GHC programs 
based on the UR-set with constraints. In R. A. Kowalski and K. A. Bowen, ed- 
itors, Proceedings of the Fifth International Conference and Symposium on Logic 
Programming, pages 924-941, Seatle, 1988. ALP, IEEE, The MIT Press. 
7. J. H. Gallier and S. Raatz. Hornlog: A graph-based interpreter for general Horn 
clauses. The Journal of Logic Programming, 4(2):119-156, June 1987. 
8. D. R. Gilbert and C. J. Hogger. Logic for representing and implementing knowl- 
edge about system beliaviour. In V Maf~, O Stfip~nkov~, and R Trappl, editors, 
Proceedings o/ the International Summer School on Advanced Topics in Artificial 
Intelligence, pages 42-49, Prague, Jul 1992. Springer Verlag Lecture Notes in Ar- 
tificial Intelligence No. 617. 
9. D. R. Gilbert and C. J. Hogger. Deriving logic programs from observations. In 
Jean-Marie Jacquet, editor, Constructing Logic Programs. John Wiley, 1993. 
10. P. M. Hill and J. W. Lloyd. Analysis of Meta-programs. Technical Report CS- 
88-08, Department of Computer Science, University of Bristol, Bristol, UK, June 
1988. 
11. P. M. Hill and J. W. Lloyd. The G&delprogramming language. MIT Press, 1993. 
12. M. Huntbach. Meta-interpreters and partial evaluation in parlog. Formal Aspects 
of Computing, 1(2):193-211, 1989. 
13. R. A. Kowalski. Logic ]or problem solving. North Holland, 1979. 
14. J.W. Lloyd. Foundations of Logic Programming. Spinger-Verlag, Berlin, second 
edition, 1987. 
15. J. W. Lloyd and J. C. Sheperdson. Partial evaluation in logic programming. The 
Journal of Logic Programming, 11(3 & 4):217-242, October/November 1991. 
16. G. D. Plotkin. A note on inductive generalization. In B. Meltzer and D. Mitchie, 
editors, Machine Intelligence, pages 153-165, 1970. 
17. M. Rem. Associons: A Program Notation with Tuples instead of Variables. ACM 
Transactions on Programming Languages and Systems, 3(3):251-262, Jul 1981. 
18. J. C. Reynolds. Transformational systems and the algebraic structure of atomic 
formulas. In B. Meltzer and D. Mitchie, editors, Machine Intelligence, pages 135- 
151, 1970. 
19. J.A. Robinson. 
A machine-orientated logic based on the resolution principle. 
Journal of the ACM, 12(1):23 - 49, Jan 1965. 
20. D. Sahlin. The mixtus approach to automatic partial evaluation of full Prolog. In 
Debray and Hermenegildo [5], pages 377-398. 
21. D. Sahlin. An Automatic Partial Evaluator for Full Prolog. PhD thesis, Swedish 
Institute of Computer Science, Mar 1991. 

On Specification Frameworks and Deductive 
Synthesis of Logic Programs* 
Kung-Kiu Lau 1 and Mario Ornaghi 2 
1 Department of Computer Science, University of Manchester 
Oxford Road, Manchester M13 9PL, United Kingdom 
kung-kiu~cs.man.ac.uk 
2 Dipartimento di Scienze dell'Informazione 
Universita' degli studi di Milano 
Via Comelico 39/41, Milano, Italy 
ornaghi@imiucca.csi, unimi.it 
1 
Introduction 
Logic program synthesis methods can be roughly divided into those that use 
a formal specification and a formal synthesis process, and those that use an 
informal specification and an informal synthesis technique. A taxonomy and a 
survey of logic program synthesis methods can be found in [5]. 
In formal methods for logic program synthesis, the issue of what specification 
language is best has never loomed large, because first-order logic is the obvious 
candidate and hence the natural choice. This, in our view, has resulted in an 
over-simplistic view of logic program specifications. 
In our own area of deductive synthesis of logic programs, for example, a 
specification is often just an if-and-only-if first-order definition, or a set of such 
definitions. Such a simplistic approach to specification has, in our experience, 
two major drawbacks: 
9 It cannot capture the entire body of knowledge needed for and used in the 
synthesis process. 
For example, our formalisation of deductive synthesis of logic programs in 
[9] reveals that the synthesis process has to make use of background knowl- 
edge not captured by the if-and-only-if definition of the specified relation. 
Such knowledge includes relevant theories, e.g. of data types, with induction 
schema, etc. 
* It does not provide an adequate means to specify properties other than 
correctness. 
For example, in [10], we show that if we want to synthesise steadfast pro- 
grams, i.e. programs that are modular in the sense that they define program 
units that remain correct (and hence unchanged) when integrated into larger 
* The first author was partially supported by the EC HCM project on Logic Program 
Synthesis and Transformation, contract no. 93/414. The second author was partially 
supported by MURST. 

105 
programs, then we need to use axiomatisations which allow us to reason 
about program modularity and composition. 
In our work [9, 10], therefore, we have used specification frameworks to pro- 
vide the background for deductive synthesis of logic programs. In this paper, we 
take a closer look at such frameworks. We shall explain what they are, and how 
they can be used to specify properties such as correctness and modularity (and 
hence reusability). 
Moreover, we shall show that there is a close two-way relationship between 
specification frameworks and deductive synthesis. In particular, a deductive syn- 
thesis process can provide a useful feedback mechanism which can not only check 
for desirable properties in the specification framework, but also improve the 
framework (with regard to such properties) using the result of the synthesis. 
In our approach to modularity, we borrow many of the basic ideas developed 
in the algebraic approach. (e.g. [6, 7, 14]). We shall briefly contrast the two 
approaches in Section 2.3. 
2 
Specification Frameworks 
and Specifications 
In this section, we give an informal introduction to specification frameworks, 
and show why and how we distinguish between them and specifications. We also 
briefly explain the background and motivation for our approach. 
2.1 
Specification Frameworks 
We take the view that program synthesis should take place in a general frame- 
work within which we can (a) specify, and (b) synthesise programs, for many 
different computational problems in that framework. The idea is that for (a) 
a framework should be sufficiently expressive, and for (b) it should act as a 
repository that contains all the knowledge that is needed for reasoning about 
the problem domain of interest. 
The following are two examples of specification frameworks: 
Example 1. A well-known example is Peano Arithmetic, which we will denote by 
7~A. Its language contains identity '=', successor 's', sum '+' and product '-'. In 
P.4 every natural number n is represented by a numeral n. 3 Every computable 
function f(x) can be expressed by a formula F(x, z),such that for every pair 
of natural numbers m and n, m = f(n) iff F(m,n), where m and n are the 
numerals corresponding to m and n respectively, is provable in 7).,4. Thus, in 
PA we can specify any computable function by a formula; and therefore 7).4 is 
sufficiently expressive. 
Example 2. Another example is the following framework EZST for lists. We as- 
sume that the framework P.A has already been defined. It contains the language 
3' Numerals are 0, s(0), s(s(O)) .... 

106 
and the axioms of Peano Arithmetic and is enriched by the most useful prim- 
itive recursive functions and predicates. We use (i.e. we "import") P.A in the 
following framework specifying lists, to introduce the function leE(L) (meaning 
the length of L) and the relation elemi(L, i, e) (meaning the element e occurs at 
position i in L). Here, the specification of lists leaves undefined the list elements 
(namely the domain of the sort Elem) and the ordering < on them, and thus 
Elem and < act as parameters. We have a many-sorted language with (polymor- 
phic) identity '='. The 'statement' Import PA incorporates the signature and 
the axioms of T'.A, while the subsequent 'statements' add new sort, function and 
relation symbols to the signature, and introduce new axioms. 
Framework s 
Import 7).4; 
SORTS: 
Elem,List; 
FUNCTIONS: nil : ---* List; 
[ : (Elem, List) -~ List; 
leE : List --* Nat; 
RELATIONS: 
< 
: (Elem, Elem); 
elemi : (List, Nat, Elem) 
AXIOMS: 
Va : Elem, B : List.-~nil = a[B 
Va~,a2 : Elem, B1,B2 : List. (aliBi = a21B2 --* as = a2 A B1 = B~) 
Ve : Elem, L : List. (elemi(L, O, e) ~ 3B :List. L = elB ) 
Ve : Elem, L : List,i : Nat. 
(elemi(L, s(i), e) ,--* 2a : Elem, B: List. (L = a[B A elemi(B, i, e))) 
H(nil) A Vx : Elem, J : List. (H(J) ~ H(x[J)) --* VL : List. H(L) 
End s 
The last axiom is the first-order induction schema on lists, where H is any (first- 
order) formula of the language of lists. 
Natural numbers are not needed to specify list. However, the presence of 
elemi yields a more expressive language, which allows us to define in an easy 
and natural way many different relations on lists, as we will see later. 
Thus we define a specification framework as a consistent first-order theory with 
a many-sorted signature, and with identity. We allow full first-order language 
for the sake of expressiveness. We will denote frameworks by Y, G,... 
2.2 
Specifications 
A framework is thus a general theory, wherein many different computational 
problems can be specified in a clear, declarative manner. To specify a problem 
declaratively, we explicitly define the relation to be computed. We also list the 
goals to be solved by the synthesised program(s). 
Definition 1, A specification in a framework Y with language s 
consists of: 

107 
9 a definition axiom Dr: 
Y (r(x) ~ R(x)) 
where r is a new predicate symbol and R is a formula in s 
9 a set G of goals of the form 3r(t0), 3r(tl),... 
The link between specifications and programs is stated by the following defini- 
tion. 
Definition 2. Let (Dr, G) be a specification within a framework Y. A program 
P is totally correct in a model M of Y wrt (Dr, G) if, for every goal 3r(tk) E G: 
- 
if 3r(tk) is true in M, then there is at least a computed answer substitution 4 
for P t2 {.- r(tk)}; 
- 
if a is a computed answer substitution for P U {~ r(tk)}, then r(tk)a is true 
in M. 
We define correctness in a model, since we will consider both closed frameworks, 
which single out one intended model, and open frameworks, which characterise 
a class of models. 
Example 3. In the framework s 
of Example 2, we can specify many problems 
on lists. Firstly, we can specify many new relations on lists, using definition 
axioms. For example, the new relation symbols 
9 sub(A, B), meaning A is a sub-list of B, i.e. every element of A is an element 
of B; 
9 equiv(A,B), meaning A and B are equivalent, i.e. they contain the same 
elements; and 
9 ord(L), meaning L is ordered, 
can be introduced by the definition axioms Dsub, Deq~,iv and Dord: 
Dsub 
: VA, B : List. (sub(A, B) 
Ve : Elem. (3i : Nat.elemi(A,i,e) ~ 3i : Nat. elemi(B,i,e))) 
D~quiv : VA, B : List. (equiv(A, B) ~ sub(A, B) A sub(B, A)) 
Dord 
: VL : List.(ord(L) 
Vi : Nat, el, e2 : Elem. (elemi(L, i, el) ^ elemi(L, s(i), e2) --* el <_ e2)) 
Each relation symbol so defined, together with the corresponding definition ax- 
iota, can be added to the framework, thus enriching our language. 
We can now specify, for example, the sorting problem by (Dsort, Gsort ), with: 
D~ort : VL, S : List. (sort(L, S) ~ equiv(L, S) A ord(S)) 
G~o~t = {3S : List. sort(l, $) [l is ground} 
The relations ord and sort depend on the ordering 4_: List â€¢ List; hence this spec- 
ification specifies a class of sorting programs, depending on the interpretations 
of <: List â€¢ List. 
4 As defined in [11]. 

108 
2.3 
Background and Motivation 
Various axiomatisations of data and programs can be found in the literature. 
For logic programming, Clark and T/~rnlund [4] formulated a first-order theory 
of programs and data. Other examples of first-order theories of general interest 
to Computer Science are presented in [12]. 
However, a systematic use of axiomatisations to specify data and programs 
has been studied mainly in the field of algebraic specifications of abstract data 
types (ADT's). We refer in particular to the so-called initial algebra approach, 
which has been popularised by many authors (e.g. [8, 6, 7, 14]). In our approach, 
we incorporate many of their basic ideas (and their terminology): in particular, 
modularity (and parametric modules, like E~S~r), and intended-model seman- 
tics. 
However, there are some major and fundamental differences. In this section, 
we briefly outline them and thus contrast our approach with that of initial alge- 
bra. 
We are concerned with program synthesis, and we have a different point of 
view on what a specification should be, for the purpose of synthesis. We distin- 
guish between specification frameworks and specifications, and we do not impose 
any restrictions on the form of the axioms. In contrast, the initial algebra ap- 
proach only allows restricted classes of axioms. Consequently, we cannot exploit 
the strengths of the initial algebra approach, namely that: 
(a) Equational theory admits an initial model [8], unique up to isomorphism, 
and this result can be easily extended to Horn axioms (as in EQLOG[6]). 
(b) There is a correspondence between truth in the initial model and provability 
for positive formulas. This property provides a kind of goal-solving complete- 
ness: a positive existential formula 3xA(x) (where A contains only A, V) is 
true in the initial model iff there is an instance ACt ) provable in the theory. 
However, as soon as we introduce negation, for example, we get into the following 
problems: 
(a') The existence of an initial model is lost, s and there are no general and 
effective criteria to isolate those theories which do admit an initial model. 
(b') Even if a theory .T" has an initial model I, a negated atomic formula may 
be true in I, but not provable; this destroys the goal-solving completeness 
property. 
Both these points are critical in our approach: (a') because we do not want 
particular restrictions on the form of the axioms, and (b') because in a definition 
axiom Vx(r(x) ~ R(x)), R(x) is any formula (using negation we may loose goal- 
solving completeness wrt the goals 3r(t)). 
Therefore we need some effective criterion for the existence of the intended 
model. If we use isoinitial semantics instead of initial semantics, we get such a 
criterion 
5 As is well-known in logic programming, the completion of a normal program may be 
inconsistent, or it may have many incomparable models. 

109 
Isoinitial semantics was introduced in [1], as a semantic characterisation of 
the computable ADT's. In this semantics, the intended model of a theory 9 r is 
the isoinitial model (when it exists), i.e. a model J of .T such that for every 
other model M of .T, there is a unique isomorphic embedding of J in M. 
In other words, whereas initial semantics uses homomorphisms, isoinitial se- 
mantics uses isomorphic embeddings, which preserve relations and their nega- 
tions. As a consequence, isoinitial models turn out to be always recursive, whilst 
this property is not guaranteed, in general, for initial models. An extensive com- 
parison of the two kinds of semantics can be found in [1]. 
We will make use of the following criterion for the existence of isoinitial 
models. 
Definition 3. We say that a model M of a theory .T is reachable if every element 
of the domain of M is represented by some closed term of the language of ~'. 
We say that ~" is atomically complete if, for every closed atomic formula A, 
either .T l- A, or 9 c b- -~A. 
Theorem 4. If a theory .T has at least one reachable model, then .T admits an 
isoinitial model if and only if it is atomically complete. 
This theorem gives atomic completeness as the key condition for the exsitence 
of isoinitial models. In our work, we will show that program synthesis can be 
used to test for atomic completeness, by the provability of the completion of 
synthesised programs. 
3 
Closed and Open Specification Frameworks 
We will distinguish between closed and open frameworks. Informally speaking, 
an open framework leaves open the possibility of different interpretations of the 
symbols of its language, corresponding to different intended models, while a 
closed framework has a unique intended model, determining a unique interpre- 
tation. 
For example, PA is a closed framework, since the meaning of 's', '+', '.', 
'=' is completely defined and the intended model is the standard structure of 
natural numbers. In contrast, s 
is an open framework, since the meaning of 
Elem and < : (Elem, Elem) is left open. Indeed, no axiom is given to characterise 
the domain of the sort Elem or the ordering _< on the elements. 
In an open framework, we can distinguish between two kinds of symbols: 
9 defining symbols, namely symbols whose interpretation is left open; 
9 defined symbols, namely symbols whose meaning is defined by the axioms of 
the framework, possibly in terms of the defining symbols. 
In Example 2, Elem and <_ are defining symbols, while all the other symbols of 
the language are defined symbols. 
We will write 5 c : dx,...,d,~ ~ Pl,...,Pm to indicate that .T" is an open 
framework with dependency dl,...,d,~ ~ Pl,... ,p,~, i.e. in 9 r, dl,..., d,~ are 

110 
defined symbols and Pl,... ,P,~ are defining symbols. Thus Y : dl,...,d,~ r 
denotes a closed framework, i.e. all the symbols are defined by the axioms of the 
framework. 
Thus defining symbols act as parameters, and our idea of an open framework 
is similar to a parametric (algebraic) ADT's. However, unlike the algebraic ap- 
proach, we use the full first-order language, and therefore we need criteria for 
discriminating between 'good' and 'bad' frameworks, as we will now discuss. 
The two key attributes of a good specification framework are consistency and 
adequacy. Consistency has the usual meaning of not containing contradictions, 
whereas adequacy is related to the dependency of the framework. 
Intuitively speaking, a framework is adequate wrt a given set of dependencies, 
if whenever we completely specify the defining symbols, we obtain a complete 
specification of the defined symbols without adding any new axioms for them. 
This notion of adequacy wrt a dependency is the first point that we will develop 
for open frameworks. 
3.1 
Operations on Frameworks 
Since the effort of writing adequate and consistent frameworks, as well as synthe- 
sising correct programs in such frameworks, may be considerably high, reusabil- 
ity of both specifications and programs is a very important issue: once we have 
produced a meaningful, consistent and adequate specification framework and 
correct and good software for it, we should be able to use them in a wide fam- 
ily of problems. Moreover, we should be able to accumulate and increase our 
knowledge of the more interesting problem domains, and to enlarge the class 
of reusable programs, leading to increasingly more complete and useful frame- 
works. An object-oriented approach, like the one developed in algebraic ADT's, 
would be very useful in this respect. 
So, the second point of our study is the introduction of methods suitable 
for object-oriented specification and synthesis. We will consider the following 
operations: 
* Expansion. Given an adequate and consistent open framework 9 ~ : dl,..., dn 
r 
Pl,...,pm, we can expand .7:, by adding a new (defined) relation sym- 
bol r by means of a definition axiom D~, into a new framework 9 v t3 Dr : 
r, dl,...,dn 
~ Pl,...,Pm. 
Since definition axioms give rise to conservative extensions, the expansion 
operation preserves consistency, but it may not preserve adequacy. 
9 Consolidation. An adequate open framework 9 c : dl,...,dn "r Pl,...,pm 
can be consolidated in any closed framework G : Pl, .. 9 ,Pro,..- r 
to obtain 
the closed framework ~'t.J ~ : dl,..., dn, Pl,.. 9 Pro, .. 9 r 
Such an operation 
thus enriches G by the defined symbols of Y. We shall call )rtJ ~ an instance 
of 9 v (or, more precisely, an instantiation of 5 r by G). 6 
This operation preserves adequacy, but it may not preserve consistency. 
6 Rather than the more clumsy alternative of 'a consolidation of 9 v in G'. 

111 
Therefore it is necessary to find conditions under which adequacy is preserved 
by expansions, and consistency by consolidations. For the latter, it is possible to 
find some sufficient conditions, but we will not discuss them here. 
More interestingly, logic program synthesis is strictly related to the above 
operations. Firstly, it can be used to expand frameworks while preserving ad- 
equacy, as we will show in Section 6. Secondly, in an open framework jr, it is 
possible to synthesise open programs, which can be reused in every instantiation 
of jr, as we will explain in Section 6.3. 
4 
Closed Frameworks 
Definition 5. A closed framework ~" with language Ly is an axiomatisation 
(i.e. a set of axioms ~ C s 
which satisfies the following properties: 
- Reachability. There is at least one model of jr reachable by a subset of the 
constant and function symbols of L j:, called the construction symbols. The 
ground terms containing only construction symbols will be called construc- 
tions. 
- Freeness. jr proves the freeness axioms [13] for the construction symbols. 
- Atomic completeness, jr is atomically complete. 
Thus, by Theorem 4, a closed framework is a theory admitting an isoinitial 
model. The existence of a set of construction symbols satisfying the freeness 
axioms is not strictly necessary (teachability sufficies). It is required here, since 
we deal with synthesis of logic programs and use Clark's equality theory 7 [3] for 
construction symbols. Of course, in logic programs only construction symbols 
can be used for constant and function symbols. 
Example 4. As we have already seen, 79A is a closed framework. The construc- 
tion symbols in PA are '0' and 's', and the constructions are the numerals 
0, s(0), s(s(0)),... Note that sum '+' and product '.' are not construction sym- 
bols, so they need not be considered in freeness axioms. Finally, 79A is atomically 
complete. Indeed the closed atomic formulas of 79,4 are of the form tl = t2, where 
tl,t2 are closed terms, and, as is well-known, 79,4 ~- tl = t2 (if tl and t2 denote 
the same natural number), or 79.4 ~- -~tl = t2 (if they denote different numbers). 
All the isoinitial models of a framework are isomorphic. For every closed 
framework jr, using the constructor symbols, we can build a particular recursive, 
isoinitial model I, that we will call the canonical model, in the following way: 
- 
For every sort S, the domain of S is the set of constructions of sort S. 
- 
A function symbol f is interpreted in I as the function fl defined thus: for 
every tuple a of constructions (of the appropriate sorts), the value of fi(a) 
is the construction b such that jr F f(a) = b. 
r Containing freeness axioms. 

112 
- Every relation symbol r is interpreted in I as the relation rl such that, for 
every tuple a of constructions, a belongs to rt iff 9 r F r(a). In particular, '=' 
is the identity of constructions. 
Example 5. In the canonical model of ~o.A, the domain (of its unique sort) is 
the set of numerals {0, s(0), s(s(O)),...}, '+' is the sum of numerals, e.g.P.A F 
s(0) + s(0) = s(s(0)); '.' is the product of numerals, e.g.P.A ~- s(0). s(0) = s(0); 
and '=' is the identity of numerals (79A F sn(O) = sin(O) iff n = m). 
Let .T be a closed framework and I its canonical model. By atomic com- 
pleteness, for every relation symbol r and every tuple a of constructions, r(a) 
is true in I iff it is true in every model M of .T, and -,r(a) is true in I iff it is 
true in every model M of ~'. Therefore the canonical model is representative of 
any other model wrt the closed atomic and negated atomic formulas. That is, it 
yields the intended semantics of the function and relation symbols axiomatised 
by the framework. 
4.1 
Adequate Expansions of Closed Frameworks 
As shown by the examples of the previous sections, definition axioms play a 
central r61e in our approach. In closed frameworks they are adequate when they 
completely characterise the defined relations, according to the following defini- 
tion: 
Definition 6. Let J~ be a closed framework and Dr 
Vz(r(z) 
R(z) ) 
be a definition axiom. We say that Dr completely defines r in r iff .T U Dr 
satisfies the atomic completeness property. 
If Dr completely defines r in 9 r, then 5 c U Dr is in turn a closed framework. 
It is thus an adequate expansion of .~" by a new relation r, in the following sense: 
- Let I be the canonical model of 5 c, and Ir that of f U Dr. Then L is an 
expansion of I by r. 
- The interpretation of the new symbol r in the expansion Ir is the following: 
for every tuple t of constructions (of the appropriate sorts), t belongs to r~,, 
iff r U Dr t- r(t). 
We recall that in an expansion of a model (see [2]) by new symbols, the 
interpretation of the old ones remains unchanged. Thus an adequate expansion 
.T u Dr preserves the semantics of the symbols already present in L~-. 
This nice property holds only for completely defined relations, however. If 
Dr does not completely define a relation, then 9 c U Dr is no longer a closed 
framework and a canonical model no longer exists. This means that, in general, 
we have to possibly reconsider the correctness of programs that have already been 
synthesised. Thus it is important to recognise the axioms Dr which completely 
define new relations. 

113 
5 
Open 
Frameworks 
From a general point of view, an open framework is a consistent set ~ of first- 
order axioms, for which we fix a dependency dl,. 9 9 d,~ r Px, 9 9 9 pro. We require 
that the dependency satisfies the following properties: 
(i) For every defined sort symbol S, identity '=' on S is a defined symbol. 
Moreover, there is (in the language of the framework) a non-empty set of 
constant and function symbols of sort S such that the corresponding freeness 
axioms are provable in ~'; these are the construction symbols of S. 
(ii) For every defining sort symbol D, identity '=' on D is a defining symbol. 
Moreover, the language of the framework does not contain constant and 
function symbols of sort D. 
As in the previous section, the closed terms built by construction symbols 
are called constructions. Note that, by (ii), if D is any defining sort symbol, then 
the set of constructions of sort D is empty. 
Example 6. The framework s 
has the dependency: 
Nat, List, 0, nil, s, +,., ], len, elemi ~ Elem, <_ 
We have the identities = : (Nat, Nat), = : (List, List), = : ( Elem, Elem ); where 
the first two are defined symbols, whilst the third is a defining symbol. 
The construction symbols of List are the constant nil :---* List and the 
function I : (Elem, List) ---* List, and the only construction of sort List is nil. 
Note that the only ground term of sort List is nil, since the other ground terms 
depend on the ground terms of the defining sort Elem, and therefore will be 
known only in particular instances of the framework. 
The construction symbols of the sort Nat are '0' and 's' and the constructions 
of sort Nat are the numerals. 
The defining sort Elem has no construction symbols and no constructors. 
Let ~" : dl,..., dm r Pl,..., P~ be an open framework. If n = 0 (i.e. no defin- 
ing symbol is given), then 9 r is adequate iff it is a closed framework. Otherwise 
adequacy is defined as follows. 
Definition 7. ~': dl,...,dm r Pl,...,Pn is adequate wrt dl,...,dm ~ Pl,..., 
Pn iff, for every closed framework ~ : Pl,... ,P,~, ql,..., qh r 
.T" (3 ~ is a closed 
framework such that its canonical model I* is an expansion of the canonical 
model I of G by the new symbols dl,..., din. 
Let ~ : Pl,... ,p,~,ql,-.. ,qh r 
be any closed framework that is consistent 
with .~ : dl,... ,d,~ ~ pl,... ,p,~; according to Section 3.1, we will say .,z'U ~ is 
an instance of ~" (or an instantiation of f by ~). Adequacy means that every 
(consistent) instantiation of.~" by G gives rise to an expansion of G by the symbols 
defined by ~, while preserving the semantics of the old symbols of G. 

114 
5.1 
Adequate Expansions of Open Frameworks 
Using adequate open frameworks we have the following advantage: all the work 
which can be done directly in the open framework is done once and for all, 
i.e. it can be reused in all the instances of the framework. In particular, this 
holds for reusable programs (see Section 6.3) that can be synthesised in such 
frameworks. This explains why it is interesting to investigate the possibility of 
performing synthesis in open frameworks. We will show that synthesis of reusable 
open programs is possible for relations introduced by adequate definition axioms, 
defined as follows. 
Definition 8. A definition axiom D~ is adequate in an open framework .T : 
dl,..., dm r pl,..., Pn iff, for every instance f U G, Dr completely defines r in 
~-Ug. 
Axioms adequate in an open framework have the following nice property: 
they give rise to adequate expansions of the instances of the framework. More 
precisely, they add to every instance of the framework a new relation r, while 
preserving the semantics of the old symbols. Thus, if Dr is an adequate definition 
axiom, we say that 5 c U D~ is an adequate expansion of .T by r. 
Note that in adequate expansions, the definition r depends only on the in- 
terpretation of the defining symbols in the various instances. Therefore the de- 
pendency of an expansion .T U Dr is : r, dl,. 9 dm r Pl .... , pn. 
Finally, it will be convenient to relate adequacy of frameworks and of their 
expansions (by adequate definition axioms) to restricted classes of instances. 
Let F be a class of closed frameworks which can be used to instantiate an open 
framework .T. To define adequacy wrt T', it is sufficient to consider in Definition 
7 and Definition 8 only the instantiations by closed frameworks ~ C F. 
6 
Deductive 
Synthesis and Specification Frameworks 
In this section, first we briefly describe deductive synthesis of logic programs in a 
specification framework. Then we show how synthesis can be used to determine 
the adequacy of any expansion of a closed or open framework. For an adequate 
open framework, we also introduce the notion of open, reusable programs. 
6.1 
Deductive Synthesis of Logic Programs 
First, as in [10], for a program P, we define: 
9 free(P) to be the freeness axioms for the constant and function symbols of 
P. 
9 Comp + (P) = free(P)U Ax(P), where Ax(P) is the/f-part of Corap(P), the 
completion of P [3]. 

115 
9 Comp-(P, r) is the only-if-part of the completed definition of a predicate r 
in P: 
V(r(x) ~ E1 V--- V E~) 
For convenience, we shall also write Comp-(P, rl,..., rn) for multiple pred- 
icate symbols. 
Now, let .~ be a general (open) framework and consider a specification con- 
sisting of a definition axiom Do 
v (r(x) ~ R(x)) 
and a set G of goals. 
A deductive synthesis process (for this specification) generates a sequence of 
programs/='1 C P2 C_ ... C_ Pa C_ ---, where, for every Pj, there is a corresponding 
set Dj of definition axioms, introducing the new predicate symbols of P# . 
We assume that the synthesis process ensures that at each step: 
(i) 5rUDj t- Comp+(Pj); 
(ii) Pj terminates , i.e. it either finitely fails or its SLD-tree has at least one 
success node, for every goal in G. 
(i) ensures partial correctness. However, (i) and (ii) together do not ensure total 
correctness. In Sections 6.2 and 6.3, we will define the notion of total correctness 
in closed and open frameworks precisely. In the meantime, we state a criterion 
for halting synthesis with a totally correct program, which we presented in [10]. 
Definition 9. For a program P, let rl,..., rk be the relation symbols occurring 
in the head of at least one clause of P, and ql, .. -,qm be the ones occurring 
only in the bodies. Following our terminology for frameworks (without causing 
confusion), we say that P has the dependency rl,... ,rk ~ ql .... ,qm, and we 
write P : ra,..., ra r 
ql, ..., q,~. We call rl,.. 9 rk the defined predicates and 
ql , . 9 9 qm the defining predicates of p.s 
In every synthesis step j, we consider the relation symbols introduced by Dj 
as defined symbols of ~" U Dj. Moreover, we require that the dependency of Pj 
agrees with that of 5 ~ U Dj wrt the defined symbols, namely that the defined 
predicates of P3 are defined symbols of )c U Dj. A criterion for halting synthesis 
is then the following: 
A Criterion for Halting Synthesis. 
Let Pj : rl,..., rk ~ ql,..., qm be the program synthesised in the cur- 
rent step j. 
(i) If, for a defined predicate rh, jc U Dj F- Comp-(Pj,rh), 
then stop 
searching for clauses with head rh. 
(ii) If (i) holds for every defined predicate of Pj, and all the defining 
predicates ql, ..., qm are defining symbols in 9 r, then halt synthesis. 
s A defined predicate may occur both in the head and (re.cursively) in the body of a 
clause, whereas a defining one may occur only in the body. 

116 
As we mentioned in Section 3.1, an adequate (open) framework .7" : dl,..., d,~ 
e= Pl,...,Pro completely characterises the defined symbols dl,..., d,~ in terms 
of the possible interpretations for the defining symbols Pl,...,Pro. Correspond- 
ingly, a correct open program P should be a program computing some defined 
relation symbols of the framework, depending on the interpretation of other 
defining relation symbols. When (i) holds, the completed definition of rh has 
been proved in the framework. Roughly speaking, this implies that we have al- 
ready synthesised all the clauses to compute rh, depending on the interpretation 
of the other relation symbols occurring in their bodies. 
When (ii) holds, the open program Pj contains all the clauses to compute 
all its defined relations, depending only on the interpretation of the defining 
symbols of the framework. This implies reusability: for every model M of the 
framework, it is sufficient to add to Pj the clauses that correctly compute the 
defining relations in M, to obtain a complete program that is totally correct in 
M. 
On the other hand, if such a Pj can be synthesised, then, as we will see in 
Section 6.3, the framework is adequate, i.e. synthesis can be used to analyse 
the adequacy of specification frameworks, and thus we have a useful feedback 
mechanism between specification and synthesis. 
Synthesis in closed frameworks is a limiting case, where we halt synthesis 
only with programs with dependency rx,... ,rk r 
since there are no defining 
symbols in the framework. We will prove that in this case we obtain (closed) 
programs which are totally correct (in the usual sense) in the intended model of 
the framework. Thus in a closed framework, program synthesis can be used both 
to find correct programs and to study adequate expansions, as we now show 
more formally. 
6.2 
Synthesis and Closed Frameworks 
Let (Dr, G) be a specification in a closed framework ~" with canonical model I. 
We are interested in adequate specifications, namely specifications giving rise to 
adequate expansions. In an adequate specification, Dr completely defines r in 9 c, 
and J't.J D~ is a closed framework with a canonical model I~. Thus the following 
definition is sensible: 
Definition 10. For a given specification (Dr, G) and a given framework ~c, a 
program P is totally correct in the expansion E U Dr iff it is totally correct in 
the canonical model It. 
For the synthesis of totally correct programs, we can prove the following theo- 
rems. 
We say that a program P ground tervninates if, for every relation symbol r of 
P, and every ground goal r(t), the SLD-tree for P U {~-- r(t)} contains at least 
one success node or is finitely failed. 9 The following theorem holds (see [10]): 
9 We assume a fair computation rule. 

117 
Theorem 11. Let (Do, G) be a specification in a closed framework jz, where ro 
is the relation defined by Do. In a synthesis process, if a ground terminating 
program Pj : to,...rk ~ can be synthesised such that ~ ~- Comp-(P, r0, ...rk), 
then we have: 
(i) J: U Dj is an adequate expansion of jz by the symbols introduced in Dj; 
(ii) Pj is totally correct in the canonical model of Jr U Dj wrt the set of ground 
goals. 
This theorem is useful in a synthesis process where we do not know whether 
the specification (Do, G) we start from is adequate or not. In such a case, we can 
use synthesis both to obtain a program answering the goals in G and to prove 
the adequacy of the specification. For every step j, we prove Comp + (Pj) and the 
termination of Pj, both for the goals in G and for all the ground goals rh(t). 1~ 
We halt the synthesis process when we obtain a program Pj : ro,...,rk r 
such 
that ,~ U Dj ~- Comp-(Pj, ro,..., rk). If this process halts successfully, then we 
obtain an adequate expansion of our framework (by the relation symbols defined 
in Dj) and a totally correct program. 
However, it may happen that during this process, we reach the following 
situation of uncertainty: the current Pj is such that 
neither ~uDj ~--~Comp-(Pj,ro,...,rk) nor ~'UDj }-- Comp-(Pj,ro .... ,rk). 
The following theorem 11 allows us to handle such a situation. In the theorem, 
'Pj is totally correct in 9 v U Dj wrt ground goals' means that, for every relation 
symbol ri of Pj and every ground atom ri(t), ri(t) is true in the canonical model 
of ~ U Dj iff the SLD-tree for P t.) {~- ri(t)} contains at least one success node. 
Theorem 12. Let Pj : to, .. 9 ra ~ be the current program, and let Dj be def- 
inition axioms that completely define r0,... ,rk in .~. If Pj is totally correct in 
jr U Dj wrt ground goals, then Comp- (Pj, ro, ..., rk) is consistent with jz U D j, 
and can be added to it whilst preserving the canonical model. 
According to this theorem, in case we reach the above situation of uncertainty, 
then we study the definition axioms Dj. If we can prove (in some way) that Dj 
completely define the corresponding relations, then by Theorem 12 we can add 
Comp-(Pj,ro,... ,ra) as a new axiom, and we obtain both a totally correct 
program and an adequate expansion. Note that in this case we also have an 
improvement of the framework, since we add a stronger axiom. 
On the other hand, if we discover that some definition axiom in Dj does 
not completely define the corresponding relation, we have to reconsider both the 
synthesis process and the framework. Indeed, it may be that in some synthesis 
step we made a bad 'choice', or that our framework is too weak to define the 
relations we want to compute. 
lo Ground termination is needed to apply Theorem 11. 
11 We omit the proof here for brevity. 

118 
6.3 
Synthesis and Open Frameworks 
To treat the correctness (i.e. the reusability) of an open program in an open 
framework, it is useful to compare the various Herbrand models of the program 
with the canonical models of the various instances of the framework. To this 
end, we introduce the following definitions. 
Let M be a model for a language LM and let C be a set of constant and 
function symbols. 
We say that M is C-generable if it is reachable by C, and the freeness axioms 
of the function and constant symbols of C are satisfied in M. The closed terms 
built from C are the constructions. 
Let M be a C-generable model with language LM and let r be a relation 
symbol of LM. The positive diagram of r in M is defined by: 
diag + ( M, r) = { r( t ) l t are constructions and M ~ r(t)} 
For many relations, diag+(M, rl,..., rk) is defined in the obvious way. 
Now we can compare the positive diagrams with the Herbrand models of 
programs, and we introduce and define steadfastness (as in [10]) as follows: 
Definition 13. Let A4 be a class of models, and assume that, for every model 
M E M, there is a set CM of construction symbols of LM such that M is CM- 
generable. We say that 
* M is a steadfast model of a program P : rl,..., rk ~ ql,..., qm iff the 
constant and function symbols of P belong to CM, and diag + (M, rl,..., rk, 
ql,. 9 9 qm) is the minimum Herbrand model of Comp + (P)U diag + (M, ql,..., 
qm); 
* P is steadfast in M of models iff every M C M is a steadfast model of P. 
Steadfast programs are reusable in the following sense. 
Property 14. Let the program P : rl,..., rk ~ ql,..., qm be steadfast in a class 
.M of models, and let M be any model belonging to M. For every program QM 
totally correct wrt ql,..., qm in M, if PUQ M terminates, then PU Q M is totally 
correct in M wrt rl,. .. , rk, ql,. .. , q,~. 
Thus steadfastness of P works as a kind of 'parametric correctness' in a class 
of models, where P assumes in each model M the appropriate behaviour that 
depends on QM. 
Now we introduce the notion of steadfastness in a class of instances of a 
framework (as defined in the previous subsection), as follows. 
Let .T be an open framework that is adequate wrt a class F of closed frame- 
works. Thus, for every ~ G T', the instance .T U ~ is a closed framework with a 
canonical model Iy:ug. Let ZF be the class of canonical models Iy:ug such that 
E F: we say that a program P is steadfast in the class of F-instances of ~ iff 
it is steadfast in Zr. 
Synthesis can be used to inform on the adequacy of expansions of open frame- 
works by new relation symbols, as stated by following theorem. 

119 
Theorem 15. Let ~ : dl,. .. ,dn ~ Pl,. .. ,Pro be an open framework, and con- 
sider a class F of closed frameworks. Let Pj : ro,... ,rk ~ qli... ,qh be a syn- 
thesised program, and assume that all the defining predicates of Pj are defining 
symbols of .1:. If 
(i) f U Dj P Comp-(Pj,rl .... ,rk); and 
(ii) for every ~ e F, there exists at least one program Q : ql,... ,qm,. .. ~, such 
}- Comp-(Q, ql,...,qm) and Pj U Q terminates at least for the ground 
goals in rl,..., r~; 
then 
(i) Pj is steadfast in the class of F-instances of .~; and 
(ii) the definition axioms Dj are adequate in that class. 
The proof is very simple. It follows from the fact that P LJ Q 1- Comp- (Pj u 
Q, rl, ..., rk, ql,..., q,,~), and from Theorem 11. More general facts about stead- 
fast programs could be proved (see [10]), but they are not directly applicable to 
the methodology outlined here. 
By Theorem 15, if we halt synthesis according to the criterion given in Sec- 
tion 6.1, then we obtain programs which are steadfast (and hence reusable) 
in the class of instances where a terminating Pj U Q, satisfying the hypothe- 
ses of the theorem, exists. This class may be a subclass of the class of all the 
instances. However, the theorem makes sense, since it applies to the class of 
instantiations by any framework ~ that can be obtained by our methodology 
and that (hence) contains a synthesised program Q : ql,...,qm,... ~, such 
6 ~- Comp-(Q, ql,... ,qm). 
To obtain reusable programs P in this sense, a crucial point is the possibility 
of stating the termination of P tO Q, for the various possible Q's, once and for all 
in the open framework. That is, we have to state termination of P U Q without 
knowing Q, but only knowing some possible properties which can be expressed 
by the axioms of the open framework. 
An example of parametric termination is given by the following program 
P:p~q: 
p(X,O,O) 
p(X, s(y), w) 
p(x, Y, z), q(Z, x, w) 
where the set of goals is G = {3Z.p(m, n, Z) I m, n are numerals}. To obtain 
parametric termination, it is sufficient that the programs Q : q,... r 
used in 
the instantiations do not contain the predicate p. This requirement is sensible 
in our general approach, where p is to be computed by the reusable program 
P : p r q, and not by Q : q,... ~=. 
Another example is given by parametric sorting programs on lists P : sort r 
Many other examples can be given, coming from everyday programming practice. 
We intend to study in future general techniques to state parametric termination 
in relevant classes. 

120 
7 
Conclusion 
In this paper, we have described specification frameworks and their relationship 
with deductive synthesis of logic programs. We have shown that such frame- 
works are necessary to formalise not only the background knowledge needed for 
synthesis, but also notions related to reusable programs and their synthesis. 
Hitherto, research in logic program synthesis has made use of closed specifi- 
cation frameworks in which all relation symbols are completely defined. However, 
such frameworks cannot capture the notion of reusable or steadfast programs. 
To do so, it is necessary to use open frameworks in which the meaning of some 
relation symbols is open, i.e. it can vary depending on a chosen model of the 
framework. Open frameworks thus provide a suitable backdrop to the synthesis 
of steadfast programs, and are therefore vital for an object-oriented approach to 
specification and synthesis. We have described such an approach, similar to the 
one developed in algebraic ADT's, for progam synthesis using the full first-order 
language and isoinitial semantics. 
The relationship between synthesis and specification frameworks is very much 
a two-way affair. As well as reasoning 'forwards' from a specification (in a frame- 
work) via synthesis to the specified program, we can use the result of synthesis 
to inform on and improve the specification framework if necessary, i.e. we can 
reason 'backwards' from the program via synthesis to the specification frame- 
work. 
Synthesis in a closed framework can tell us if the initial specification com- 
pletely defines the specified relation. It can also enhance the framework by adding 
stronger axioms to it that correspond to the synthesised program. 
Similarly, synthesis in an open framework can be used to determine if the 
initial specification is adequate, i.e. if it defines an adequate expansion of the 
framework. 
In summary, the results presented and discussed in this paper should provide 
important foundations for our future work on object-oriented deductive synthesis 
of logic programs. 
Acknowledgements 
We are very grateful to the referees for their valuable comments and constructive 
suggestions which have enabled us to vastly improve this paper. 
References 
1. A. Bertoni, G. Mauri and P. Miglioli. On the power of model theory in specifying 
abstract data types and in capturing their recursiveness. Fundamenta Informaticae 
VI(2):127-170, 1983. 
2. C.C. Chang and H.J. Keisler. Model Theory. North-Holland, 1973. 
3. K.L. Clark. Negation as failure. In H. GaJlaire and J. Minker, editors, Logic and 
Data Bases, pages 293-322. Plenum Press, 1978. 

121 
4. K.L. Clark and S.-/~. T~rnlund. A first order theory of data and programs. Proc. 
1FIP 77, pages 939-944. North-Holland, 1977. 
5. Y. Deville and K.K. Lau. Logic program synthesis. To appear in J. Logic Pro- 
gramming, special issue on "Ten Years of Logic Programming", 1994. 
6. J.A. Goguen and J. Meseguer. EQLOG: Equality, types,and generic modules for 
logic programming. In D. DeGroot and G. Lindstrom, editors, Logic Programming: 
Functions, Relations, and Equations, pages 295-363. Prentice-Hall, 1986. 
7. J.A. Goguen and J. Meseguer. Unifying functional, object-oriented and relational 
programming with logical semantics. In B. Shriver and P. Wegner, editors, Re- 
search Directions in Object-Oriented Programming, pages 417-477. MIT Press, 
1987. 
8. J.A. Goguen, J.W. Thatcher and E. Wagner. An initial algebra approach to spec- 
ification, correctness and implementation. In R. Yeh, editor, Gurrent Trends in 
Programming Methodology, 1V, pages 80-149. Prentice-Hall, 1978. 
9. K.K. Lau and M. Ornaghi. An incompleteness result for deductive synthesis of 
logic programs. In D.S. Warren, editor, Proc. 10 th Int. Conf. on Logic Program- 
ming, pages 456-477, MIT Press, 1993. 
10. K.K. Lau, M. Ornaghi, and S.-A. T/irnlund. The halting problem for deductive 
synthesis of logic programs. In P. Van Hentenryck, editor, Proc. 11 th lnt. Conf. 
on Logic Programming, pages 665-683. MIT Press, 1994. 
11. J.W. Lloyd. Foundations of Logic Programming. Springer-Verlag, 2nd edition, 
1987. 
12. Z. Manna and R. Waldinger. The Deductive Foundations of Computer Program- 
ming. Addisoia-Wesley, 1993. 
13. J.C. Shepherdson. Negation in Logic Programming. in J. Minker, editor, Founda- 
tions of Deductive Databases and Logic Programming, pages 19-88. Morgan Kauf- 
mann, 1988. 
14. M. Wirsing. Algebraic specification. In J. Van Leeuwen, editor, Handbook of The- 
oretical Computer Science, pages 675-788. Elsevier, 1990. 

Partial Evaluation of the "Real Thing" 
Michael Leuschel 
K.U. Leuven, Department of Computer Science 
Celestijnenlaan 200A, B-3001 Heverlee, Belgium 
e-mail: michael@cs.kuleuven.ac.be 
Abstract. In this paper we present a partial evaluation scheme for a 
"real life" subset of Prolog. This subset contains first-order built-in's, 
simple side-effects and the operational predicate if-then-else. We outline 
a denotational semantics for this subset of Prolog and show how partial 
deduction can be extended to specialise programs of this kind. We point 
out some of the problems not occurring in partial deduction and show 
how they can be solved in our setting. Finally we provide some results 
based on an implementation of the above. 
1 
Introduction 
Partial evaluation has been established as an important research topic, espe- 
cially in the functional and logic programming communities. The topic has been 
introduced to logic programming in [10] and has later been called partial deduc- 
tion when applied to pure logic programs. A sound theoretical basis of partial 
deduction is given in [12]. 
Although a lot of papers address partial deduction there are few approaches 
addressing partial evaluation of "real life" programs written for instance in some 
"real life" subset of Prolog. Even fewer papers discuss the theoretical implications 
of making the move from partial deduction to partial evaluation. This is what we 
propose to examine in this paper. First though we have to choose an adequate 
subset of Prolog. We have chosen a subset encompassing: 
1. first-order 1 built-in's, like var/1, nonvar/1 and =../2, 
2. simple side-effects, like print/l, 
3. the operational if-then-else construct. 
Our choice tries to strike a balance between practical usability, complexity of the 
semantics and the potential for effective (self-applicable) partial evaluation. The 
most important decision was the inclusion of the if-then-else. As we will see in 
Sect. 3 the first-order built-in's and the side-effects do not add much complexity 
to the semantics. In later sections we will also see that the if-then-else lends itself 
quite nicely to partial evaluation and is much easier to cope with than the "full 
blown" cut. Using the if-then-else instead of the cut was already advocated in 
[14] and performed in [21]. 
1 As opposed to "second order" built-in's which are predicates manipulating clauses 
and goals, like call/1 or asserr 

123 
In this paper we first formally define the subset of Prolog in Sect. 2 and give 
it a semantics in Sect. 3. In the sections 4 through 8 we adapt partial deduction 
such that it can cope with this subset of Prolog and study some of the added 
complications. Notably we will show that freeness and sharing information, al- 
though completely uninteresting in partial deduction, can be vital to produce 
efficient specialised programs. In Sect. 9 we extend the partial evaluation tech- 
nique such that a Knuth-Morris-Pratt like search algorithm can be obtained by 
specialising a "dumb" search algorithm for a given pattern. We conclude with a 
discussion of related work and summarise our results. 
2 
Definition 
of RLP 
The syntax of "Real-life Logic Programming" or simply RLP is based on the 
syntax of definite logic programs with the following extensions and modifications. 
The concept of term remains the same. The set of predicates P is partitioned 
into the set of "normal" predicates Pcl defined through clauses and the set of 
built-in predicates Phi. A normal atom (respectively a built-in atom) is an atom 
which is constructed using a predicate symbol E Pcz (respectively E Phi). 
A literal is either an atom or it is an expression of the form (If --* Then; Else) 
where If, Then, Else are lists of literals. We will denote by Goal8 the set of all lists 
of literals. We will represent a list of n literals by (Lt,..., L,~). Sometimes we 
will also use the notation *-- Lt,..., L,~. 
A clause is an expression of the form Head *-- Body where Head is a normal 
atom and Body is a list of literals. 
We can see from the above that RLP does not incorporate the negation nor 
the cut, but uses an if-then-else construct instead. This construct will behave 
just like the Prolog version of the if-then-else which contains a local cut and is 
usually written as (If -> Then ; Else). Most uses of the cut can be mapped 
to if-then-else constructs and the if-then-else can also be used to implement the 
not 2. The following informal Prolog clauses can be used to define the if-then-else: 
(If->Then;Else) 
:- If, !,Then. 
(If->Then;Else) :- Else. 
Thus the behaviour of the if-then-else is as follows: 
1. If the test-part succeeds then a local cut is executed and the then-part is 
entered. 
2. If the test-part fails finitely then the else-part is entered. 
3. If the test-part "loops" (i.e. fails infinitely) then the whole construct loops. 
3 
Semantics 
of RLP 
We will now outline a semantics for RLP. This semantics should be preserved 
by any reasonable partial evaluation procedure for RLP. 
Both the unsound and the sound version (using a groundness check for soundness). 

124 
The inclusion of the if-then-else into RLP has important consequences on the 
semantic level. As we have already pointed out the if-then-else contains a local 
cut. It is thus sensitive to the sequence of computed answers of the test-part. 
An implication being that the computation rule and the search rule have to be 
fixed in order to give a clear meaning to the if-then-else. From now on we will 
presuppose the Prolog left-to-right computation rule and the lexical search rule. 
The two programs hereafter illustrate the above point: 
Program PI 
Program P~ 
~(x),--(v(x)--.r(x)iy~a) 
a(x).--(v(x)~r(x);f~iO 
p(a).-- 
!V(~),-- 
p(~).-- 
p(a)~ 
,(~).-- 
,(~),-- 
Using the Prolog computation and search rules, the query ~ q(X) will fail for 
program P1 whereas it will succeed for P2. All we have done is change the order of 
the computed answers for the predicate p/1. This implies that a partial evaluator 
which handles the if-then-else has to preserve the sequence of computed answers 
of all goals prone to be used inside an if-then-else test-part. This for instance is 
not guaranteed by the partial deduction framework in [12] which only preserves 
the computed answers but not their sequence. 
As noted in Sect. 2 the if-then-else is also sensitive to non-terminating be- 
haviour of the test-part. It is thus vital that our semantics also captures this 
aspect of RLP programs. 
Finally a semantics for RLP has to take into account that the computed 
answers of built-in's cannot always be specified logically (vat/1 for instance) and 
that built-in's can generate side-effects which have no impact on the computed 
answers (print/i for example). 
We fulfilled all the above requirements by adapting the denotational seman- 
tics of pure Prolog as defined in [2] and [17]. In these papers the semantics semv 
of a pure Prolog program P is a mapping from goals to (possibly infinite) se- 
quences of computed answers. These sequences can be terminated by a least 
element _1_ which captures divergence (non-termination producing no computed 
answer). 
Our semantics is based upon the view that computed answers and side-effects 
are events which can be observed by a person executing a RLP program. In that 
sense we will be characterising the observable behaviour of RLP programs. 
Definltlonl. The side-effect domain SD is a (possibly infinite) set equipped 
with an equivalence relation --. The elements of SD are called side-effects. 
In the remaining of this paper we suppose that the side-effect domain SD is the 
set of built-in atoms and that the equivalence relation is syntactical identity. 
For instance the side-effect that "occurs" when print(a) gets executed will be 
simply represented by the built-in atom print(a). Our approach however makes 
no assumptions on SD and it can thus be replaced by a finer structure if required. 
Definition2. An e~ent is either a substitution representing a computed answer 
or a side-effect E SD. We will denote by Ever~t the set of all events. 

125 
Definltion3. Two events el, e2 are equivalent with respect to a given goal G, 
denoted by el-=-G e2, if either 
1. both el and e2 are side-effects and el - e2 or 
2. both el : 81 and e2 : 82 are substitutions and G81 and G82 are variants, s 
Definltion4. An event sequence is an element of one of the following sets 
1. Event*: the set of finite sequences of events 
2. Event* â€¢ {_L}: the set of finite sequences of events terminated with 3_ 
3. EventW: the set of infinite sequences of events 
We define the notation EventSeq = Event* U Event* â€¢ {3_} U Event ~. Fur- 
thermore two event sequences will be equivalent w.r.t, a given goal G (---G) iff 
they have the same length and the corresponding elements of the sequences are 
equivalent w.r.t G. 
Definltion5. 
An ES-sema~tics sam for a set of goals G C_ Goals is a mapping 
G -, EventSeq. If G = Goals then sam will be called complete. An oracle is an 
ES-semantics for G : {(A) I A is a built-in atom }. 
The concept of oracle as it is presented here, has nothing to do with the 
concept as presented in [1] where an oracle is used to abstract away from the 
sequential depth-first strategy of Prolog. We use an oracle to provide us with 
the meaning of the built-in's. Starting in the next section we will try to develop 
a partial evaluation procedure which preserves the semantics of a given RLP 
program independently of the actual oracle used to model the built-in's. 
It is important to note that in Def. 5 the value returned by an oracle de- 
pends only on the actual call. In particular it does not depend on the program 
from which the built-in got called nor from any run-time environment. This 
makes our approach unsuitable to model built-in's which are not first order (like 
assert/1 or call/l). But note that unrestricted use of built-in's like assert/1 
or retract/l, 
makes effective partial evaluation almost impossible. 4 Further- 
more if the oracle's responses depended on something else it would be impossible 
to do semantics preserving program transformation without intricate assump- 
tions on how the oracle's responses vary when the program or some run-time 
environment varies. 
Unfortunately due to space restrictions we cannot elaborate on the exact 
details of our denotational ES-semantics and its fixpoint construction. Let us just 
state that the equivalence notion - for event sequences induces an equivalence 
on ES-semantics and we thus obtain an equivalence relation between programs. 
All further details will be made available in an upcoming technical report. 
3 This definition avoids a mistake of [1T] which uses equivalence up to a renaming 
substitution (for which, contrary to what is stated in [17], {Y/X1} and {Y/X~} are 
not equivalent). 
4 On page 48 of [19] it is stated that "It is a question open to future research whether 
it is feasible to execute assert/1 and retract/1 by a partial evaluator." 

126 
The following table might help in giving the reader an intuition of our ES- 
semantics. Note that, when abstracting away from the side-effects, all the pro- 
grams have the same least Herbrand model Mp = {q(a)}. 
RLP Program P 
q(a)~ 
q( a ) ~- pri,,t( ~ ) 
q(X) ~- ~(X) 
q(a) ~- 
q(a) ~- 
~(X) .-- q(X) 
ES-Semantics setup(*-- q(X)) 
W 
(â€¢ 
(IX/a}, {X/a}, {X/a},...) 
4 
LDR 
Trees 
In the previous section we have sketched a semantics for RLP. In this section 
we elaborate on some of the problems when trying to preserve this semantics 
while performing partial evaluation. It should be clear that "standard" unfolding 
preserves the ES-semantics of a program as long as it uses the Prolog left-to-right 
computation rule 5 and it doesn't evaluate any non-loglcal predicates. 
This of course summons the question of what we should do if the left-most 
literal is non-logical (or if it is logical but further unfolding it would lead us into 
an infinite loop). The easiest solution would be to just stop unfolding the goal 
completely. However the loss in specialisation is unacceptable. For instance in 
the framework of [12] the links (through variable sharing) between the remaining 
literals of the goal would be lost because the literals will be (even in the best 
possible case) partially evaluated separately. Worse, all specialisation w.r.t, the 
remaining literals would be lost if we use a method that constructs just one big 
SLD tree, as is the case with the partial evaluator developed by the author in 
[11]. To illustrate the problem let us take a look at the following simple program 
Ps and try to specialise it for the query ~ q(X): 
Program Ps 
q(f(Y))~-vrint(Y),r(Y),s(Y) 
r(a),- 
r(b).- r(~)~ 
Ils(a)~--- 
s(b)*--s(d)*-- 
After the first unfolding step we obtain the goal ~-- print(Y), r(Y), s(Y). If 
we stop unfolding and generate partial evaluations for the uncovered goals r(Y) 
and s(Y) we get the unmodified and unspecialised program Pa back. 
On the other hand if we do not follow the Prolog left-to-right rule and unfold 
the goals to the right of print(Y) we obtain the specialised program P4 which 
has a different ES-semantics. 
s This is imperative even for purely logical programs. Take for instance the program 
"p(x, Y) ~-- q(X), q(u 
q(a) ~-- 
q(b) ~---'. If we unfold without following the left- 
to-right computation rule we change the order of solutions and the ES-semantics. In 
some cases this might change the (existential) left-termination behaviour. 

127 
Program P4 
q(f(a)) *-- print(a) 
q(f(b)) *-- print(b) 
For instance we have that semp~ (*-- q(f(X))) = (print(X), {X/a}, {X/b}) while 
setup, (~- q(f(X))) = (print(a), {X/a}, print(b), {X/b}). The problem is caused 
by the backpropagation of substitutions onto the print atom. s 
So we are faced with a dilemma: on the one hand we cannot select the left- 
most literal print(Y) but on the other hand we cannot select r(Y) or s(Y) either 
because the substitutions will backpropagate onto print(Y) changing the ES- 
semantics. The solution is however quite simple and just requires a minor exten- 
sion of LD ~ trees: in addition to resolution steps we allow residualisation steps 
in the LD tree. These residualisation steps are not labelled with substitutions 
but with the selected literal which is thereby removed from the goal and hidden 
from vicious backpropagations. This extension allows us to follow the Prolog 
left-to-right computation rule without having to sacrifice neither specialisation 
nor correctness. This leads to the following definition of LDR trees. 
Definition6. A complete LDR tree for a program P is a tree whose nodes 
consist of goals such that the children for each goal ~-- L1,. 9 L~ are: 
1. either obtained by performing a resolution step with selected literal L1. In 
this case the children are ordered according to the lexical ordering of the 
clauses used in the resolution step and the arcs are labelled with the substi- 
tutions of the resolution step. 
2. or the goal has just one child which is obtained by performing a residualisa- 
tion step on selected literal L1. In this case the arc is labelled with L1. 
For a (partial) LDR tree we also allow any node .to have no children at all (this 
corresponds to stopping unfolding). In this case there will be no selected literal. 
Figure 1 depicts an LDR tree and shows how the introduction of the residu- 
Misation step solves the above dilemma. The generation of residual code from an 
LDR tree will be addressed in the next section. Note that the selected literal of a 
residualisation step is not necessarily a built-in. For instance it can be necessary 
to residualise a purely logical predicate to avoid infinite unfolding (see Sect. 6). 
5 
Generating 
Code 
from 
LDR 
trees 
It should be quite obvious by looking at Fig. 1 that resultants are no longer 
sufficient for code generation. In fact we have to avoid the backpropagation of 
the bindings {Y/a} and {Y/b} onto the Frint(Y) atom while ensuring that the 
e The problem of backpropagation seems to have been overlooked in [61, thereby yield- 
ing a simple (non-pure) self-applicable partial evaluator whose semantics is however 
modified by self-applicatlon. Also note that under some circumstances backpropaga- 
tion of single bindings can be allowed, see [191 and [16]. 
7 SLD using the Prolog left-to-right computation rule and the lexical search rule. 

128 
p.i,~qY), .(Y), .(r) 
pri~t(Y) 
~'(r), ,(Y) 
,..,AN.o, 
,(~) 
,(b___J) 
,(o) 
11 
r-1 
n 
Fig. 1. LDlt tree for program P3 
print(Y) atom gets executed only once. The only way to do this in the RLP 
framework is to generate a new predicate for the goal ~ r(Y), s(Y). The code 
for this new predicate can then be generated by taking resultants as there are 
no more residualisation steps in its subtree. Using that code generation strategy 
we get the following specialised version of Ps: 
Program Ps 
q(f(Y)) ~-- print(Y), newly(Y) 
.~p(~) ~- 
newp(b) ~-- 
To formalise this process we first need the following notations: 
Definition 7. Let r be a LDR tree. Then root(r) denotes the root of the tree. 
Also 7. ~ , r' holds iff r' is a subtree of r accessible via a branch whose sequence 
of labels is a. 
We define children(7.) = {C a, r') 17. (a), 7-'}. We also define vats(r) to be the 
variables occurring in the arcs and leaves (but not the inner nodes) of 7-. 
In the following definition we present a way to remove a residualisation step 
from LDR trees. The basic idea is to split an LDR tree at a given residualisation 
step into two LDR trees which will be linked through the introduction of a new 
predicate. Figure 2 serves as an illustration of this definition. 
Definltlon8. Let S be a set of LDR trees. If we can find an LDR tree r E S 
such that 
1. r 
~, r' R, r" where R is a residualised literal 
2. root(7.') =*--- R, G1,..., G~ and roo~(r") =*--- G1,..., Gk 
then (S\{7.}) U {7-1, 7.a} 6 rspli$(S) where 
1. rl is obtained from r by replacing the subtree r' by a tree consisting of the 
single node *-- R, newp(Args) 
2. children(r2) - {(r r")} and roog(r~) : newp(Args) 

129 
3. ~wp is a new unused predicate 
4. A,.gs = 
n va, s(r"). 
Note that in a sense we add a clause of the form r~ewp(Args) *-- G1,..., Gk to 
the program to be specialised (and use it for folding). 
root(~) =.- o 
/J,,, 
,:i\ 
,'oor 
=*- R, Oz,..., O~, 
~'oot('r") =*-- G1, ..., if'J, 
root(q') 
ne~p( Av g s ) 
/1,, 
Â§ 
1' 
R, ~e~op( Ar g s ) 
Fig. 2. Illustrating Def. 8 of rsplit 
Using the above definitions we can now formalise a way to generate code 
for an LDR tree r. We will denote by rsplit*(r) the set Si obtained by the 
algorithm below. Note that rsplit* (r) is independent of the order in which the 
residualisation steps are removed. 
Algorithm 1: Code Generation 
i = o, So = ~} 
while rsplit(S~) #- 4' do 
Si+l : some element S' G rsplit(Si) 
increment i 
od 
take resultants for the set of partial LD trees S~ 
Although the above technique always produces correct code it can generate 
superfluous predicates: if a newly generated predicate newp has less than two 
defining clauses its introduction was not necessary. We present a post-processing 
scheme which remedies this (in practice this will be incorporated into rsplit). 
Definltlon9. Let 0 -- {Xz/T1...,X,~/T,~} 
be a substitution and let eq be a 
binary predicate defined by the following single clause: "eq(X, X) 4--". 
Then we define eqcode(O) = eq([X1,..., X,~], [T1,..., T,~]). In practice we will 
write eqcode(8) as X1 : TI.,., X,~ = T,~ and eqcode(qb) as true. 
Using the above definition we define the post-processing as follows: 
1. Transform all clauses "Head ~-- L1,..., Li-1, newp(Args)" where newp is a 
new predicate defined by the single clause "newp(ArgsO) +- Body" into the 
following clause (and then remove newp from the program): 
"Head *- L1, . . . , Li-1, eqcode(8), Body". 

130 
2. Transform all clauses "Head r 
L1, . . . , Li-1, newp( Args)" where newp has 
no defining clause into "Head 4-- L1,..., Li-1, fail". 
Note that, by definition of rsplit, a newly generated predicate newp can only 
occur in the last position of a residual clause. Point 2 becomes interesting if we 
allow "safe" left-propagation of failure (see for instance [161 and [19]). 
In [7] it is stated that "only the leftmost choice-point in a goal should be 
unfolded". Doing otherwise can be harmful for efficiency, for instance it can lead 
to the situation where an expensive goal has to be re-solved in the specialised 
program. This is certainly true for partial deduction. But in our case there is no 
backpropagation of bindings and the introduction of the new predicates not only 
guarantees that side-effects don't multiply but also that no expensive goal has 
to be re-solved. So in our framework unfolding (deterministic or not) is never 
harmful with respect to this problem. 
6 
Useless 
Bindings 
In this section we will point at a particular problem which occurs when we want 
to preserve the ES-semantics during partial evaluation. This problem will be 
linked to "useless bindings" which are informally defined by the following: 
A useless binding inside a partial SLD tree (respectively LDR tree) is a 
binding which can be removed without changing the semantics (under 
consideration) of the resulting residual program. 
Let us first show why useless bindings are no problem for partial deduction. 
When performing partial deduction according to [12] the specialised program 
is obtained by taking resultants of a partial SLD-tree. The combination of the 
mgu's, required to reach a leaf, is thus backpropagated on the top-level goal 
and any useless binding in the combination of mgu's automatically disappears. 
Suppose for instance that starting from the goal 4-- p(X, Y) we reach the leaf 
~-- q(Z) via the combination of mgu's 0 = {X/h(Z),W/h(Z),Y/a,V/b}. The 
resultant will be p(h(Z), a) ~-- q(Z) and all the useless bindings in bold have 
disappeared. In other words backpropagation on the top-level goal ensures that 
useless bindings have not even an effect on the syn$az of the residual program. 
When we want to preserve the ES-semantics and backpropagation is forbid- 
den these useless bindings can become a big problem. This is even the case for 
purely logical programs. We will use the following programs to illustrate this. 
'Program P6 
Program P7 
p(x, z_, a) .- 
Kx, x, a) .-- 
v(x, Y, b) ~- v(X, z, w), q(z, W) v(x, Y, b) ~- p(X, z, w), q(z, w) 
q(b, b) ~- 
q(b, b) ~- 
q(a, a) ~- 
~q(a, a) ~- 
In Fig. 3 we show an LDR tree for the programs Ps and P7 in which p(X, Z, W) 
has been residualised to avoid infinite unfolding. In this LDR tree the problematic 

131 
v(X, Y, v) 
~ 
ak 
D 
v(X, N, W), ~(Z, W) 
~ 
iD(X, Z, W) 
q(z,w) 
[] 
[] 
Fig. 3. LDR tree for Programs Ps and/)7 
substitutions {Z/a, W/a} and {Z/b, W/b} occur. In contrast to partial deduction 
these substitutions cannot be backpropagated onto the top-level goal. s Using the 
code generation strategy of algorithm 1 in Sect. 5 they will have an effect on the 
residual code. However for program P~ the bindings Z/a and Z/b inside these 
substitutions are useless, i.e. removing them will yield a more efficient residual 
program with the same ES-semantics. The following table shows the generated 
residual programs with and without the bindings. 
Specialised Ps with Z / a, Z lb 
Speciallsed 
Po without Z / a, Z lb 
v(x, z, 4) .-- 
v(x, z, a) .-- 
v(X, Y, b) +-- v(X, Z, W), newp(Z_, W) p(X, Y, b) ~-- p(X, Z, W), newp(W) 
This is just one simple example but our experiments have shown that bad 
code can be generated when no additional measures are taken. A way to solve 
this problem is to improve the calculation of the arguments Args for the new 
predicates in Def. 8. For example in Fig. 3 we can detect for P8 that the variable 
Z will always be free after a successful call to p(X, Z, W) and that the variable 
g cannot possibly share with a variable of the top-most goal p(g, Y, V). Thus Z 
can be removed from Arts because no value will ever be transmitted via g to 
the subtree for q(Z, W) and the bindings of the subtree which affect Z are of no 
consequence. By removing g from Args the bindings g/a and Z/b no longer have 
an effect on the residual code. 9 
s Backpropagating {z/a, w/a} and {z/b, w/b} by applying them on the top-level goal 
and all residualisation steps would generate a program which diverges after the first 
answer for ~(x, Y, Z). 
The interested reader might have noticed that for program Ps in Fig. 3 the entire 
goal q(z, w) can be replaced by trae without changing the semantics. To do this 
safely however we have to calculate a safe approximation of the possible computed 
answers for the goal p(x, z, w). This could be: {{w/b}, {w/a}} allowing us to con- 
dude that one of the branches of q(z,w) wRl succeed with the empty computed 
answer substitution and the other one will fail. Formalising and implementing this 
technique is still a matter of ongoing research. 

132 
Generalising the above we see that we can remove from Args all those vari- 
ables which are guaranteed to be free and guaranteed not to share with any 
variable of the root of the LDR tree. In order to detect this we have imple- 
mented an abstract interpretation scheme which calculates for each node i the 
following sets of variables: 
1. Freei, which are variables guaranteed to be free at that node 
2. Share~, which are potentially sharing with the variables of the root 
We can remove a variable V from the set Args of Def. 8 if V E Freeroot(~.,) 
and V ~ Share~oot(,,) where root(r") is the node of the LDR tree following the 
residualisation step. For example for Fig. 3 we have the following: 
Goal of node i 
Freei 
!Sharei 
Valid for 
+-- v(X, Y, V) 
~b 
{X, Y, V} 
P,, P, 
~ -  v(x, z, w), q(z,w) {z, w} 
{x} 
P~, P, 
+-+_ a(z, w) 
{z} 
~ 
P~ 
q(z,w) 
r 
{z} 
P, 
Thus for program Pe we can remove the variable Z from the arguments Args 
because Z E Free~oot(~,) and Z ~ Share~oot(~,,) while for program P~. we cannot 
(where root(T") is the node with goal +- q(Z, W)). 
In our implementation we also calculate for each root of an LDR tree (ex- 
cept possibly for the query goal) a set of "unused" argument variables. As we 
perform renaming and argument filtering (see [8], [3]) these unused variables 
can be removed from the residual code. More importantly this may diminish the 
number of variables sharing with the topmost goal and may allow us to generate 
much better code. A further improvement lies in generating multiple versions 
of a predicate call according to varying freeness information of the arguments. 
In our implementation we have accomplished this by integrating the freeness 
and sharing analysis into the partial evaluation process and using more refined 
notions of "instance" and "variant". Our system might thus generate two ver- 
sions for a given goal ,--- p(X): one version where X is guaranteed to be free and 
one where it is not. Under some circumstances this can substantially improve 
the quality of the generated code (especially when useless if-then-else constructs 
come into play, see Sect. 8). 
We go even further and let the user of our system specify freeness for his 
top-level goal. In that case the set Freei for the top-level goal +-- p(X, Y, V) in 
the above table would no longer be r but some user specified set. Note that now 
we are no longer performing partial evaluation in the usual sense. The specialised 
program will not be correct for all instances of the top-level goal, but only for 
those instances respecting the freeness information provided by the user. 
From this section we can draw the conclusion that, as soon as we want 
to preserve the sequence of computed answers or the existential termination 
behaviour of programs (w.r.t. a given static computation rule), partial evaluation 
should be combined with additional analysis (i.e. abstract interpretation) to give 
good results. 

133 
7 
Unfolding the If-then-else 
Until now we have not touched the specialisation of the if-then-else predicate. 
Using the method presented so far we could perform a residualisation step on a 
selected if-then-else construct. However this technique performs no specialisation 
whatsoever inside the if-then-else. To remedy this problem we adapt residual- 
isation such that, in addition to removing a selected if-then-else from a goal, 
it specialises the construct. The technique is based on partially evaluating the 
test-part and then based on this generating specialised then- and else-parts. 
Suppose that the construct (if ~ Then; Else) is selected by a residua]isation 
step. First we partially evaluate If yielding an LDR tree r. We now calculate 
S : rsplit* (r) to remove all residualisation steps. We can now take the tree 
r/ E S which has the goal If as root and obtain its sequence of branches 8. 
The sequence/~ is useful because it provides us with substitutions which can be 
applied to the then-part. The process of generating the specialised if-then-else 
construct using/~ is detailed in algorithm 2 below and we obtain the label of the 
residualisation step by calling code(/~/, Then, Else). We also have to add S\{r'} 
to the global set of LDR trees determining our partial evaluation. 
Algorithm 2: code(/~, Then, Else) 
if [3 is empty then 
Partially evaluate Else yielding LDR tree rt 
Add r~' to the global set of LDR trees where 
root(r~) = nelvpz(var(Else)) and ehildren(r~)= {(~b, rl)} 
else 
Let ~ = (bt,..., bk) and let 0 be the composition of substitutions of bl 
PartiMly evaluate Then0 yielding LDR tree 
Add r~ to the global set of LDR trees where 
root(r~) = ne~up2(var(Then)) and ehildren(r~) = {(~b, ~)} 
Let G be the leaf goal of bt and let R = code((b~,..., bh), Then, Else) 
neturn ((eqeode(O), G)--+ netup2(var(Then)) ; R) 
This technique generates a cascade of if-then-else's and an example is given 
in the next section. Note that to "unfold" the if-then-else we did not have to 
resort to other non-pure predicates. So in a sense RLP is closed under unfolding. 
This unfolding resembles constructive negation (see e.g. [4]) when the if-then- 
else is used to represent the r~ot/1. The definition based on if-then-else seems 
however much simpler from a practical viewpoint. Also note that our technique 
is as rather aggressive with respect to specialisation (it can be made even more 
aggressive by pushing code to the right of an if-then-else inside its then- and 
else-branches). For instance it specialises more than [9] but there is a risk of 
code-explosion. The results are however quite similar to the ones obtained by 
Mixtus in [18] which first transforms the if-then-else using a special form of cut 
and disjunctions. A similar approach is used in [16] which transforms the if-then- 
else using "ancestral cuts" and disjunctions. The problems discussed in the next 
section should also be relevant to these approaches. 

134 
8 
Useless 
If-then-else 
Constructs 
The problem of useless bindings discussed in Sect. 6 is also present for the new 
predicates newpl and newp2 introduced in algorithm 2 and can be solved in 
a similar way. The problem tackled in this section usually occurs as soon as 
predicates with output arguments are present inside the test-part of an if-then- 
else. For example the variable Y in the following simple program Ps is used as 
an output argument to arc. 
Program Ps 
arcs_leave(X) ~ one_arc(X, Z) 
one_arc(X, Y) *-- (arc(X, Y) -* true; fail) 
arc(a, b) ~ 
arc(b, a) *- arc(a, e) *-- 
Without freeness information we can only come up with the following spe- 
cialisation for the goal *- arcs_leave(a): 
arcs_leave(a) ~- ((Z = b) ~ true; ((z = c) -~ true;/ail)) 
Our experiments showed that such useless if-then-else constructs can become 
very frequent for programs with output arguments. Again through the use of 
freeness information, we can remedy this problem. For instance, knowing that g 
is guaranteed to be free and and hence that Z = b will always succeed exactly once 
at run2time, we can come up with the following specialisation for arcs_leave(a): 
arcs_leave(a) 
Note that it is not sufficient to just detect existential variables in residual 
clauses because output arguments can still be present in the residual program. 
Again a freeness and sharing analysis is needed to solve the problem. In our 
implementation we have used the same analysis which was used to solve the 
problem of useless bindings in Sect. 6. Using this information we can refine algo- 
rithm 2 by improving the calculation of arguments to newpl and newp2 and by 
detecting when a test-branch (bl in Algorithm 2) is guaranteed to succeed ex- 
actly once. When this is the case we do not have to create a residual if-then-else 
construct (a conjunction suffices) and we can drop the else-part. 
9 
Results 
All the ideas of the previous sections have been incorporated into a running sys- 
tem (based on [11]) whose results were very satisfactory. The removal of useless 
bindings and useless if-then-else constructs turned out to be vital for a lot of 
non-toy examples, especially for self-application. The system also performs well 
on the benchmarks used in [18], We also performed tests with a regular expres- 
sion parser taken from [13] yielding similar results, i.e. we obtain a deterministic 
automaton. 
We now take a look at the famous match example. We will see that our 
treatment of the if-then-else is not yet optimal in the sense that we need one 
further optimisation to get a Knuth-Morris-Pratt (KMP) like search algorithm 
out of match. 

135 
Program P~ 
ma~ch(Pat, T) ~ ma~chl(Pat, T, Pat, T) 
ma~ch(~, Is, P, T) *-- 
match([AlPs], [BITs], P, [X[T]) 
(A = B -* matchl(Ps, Ts, P, IX T]) ; matchl(P, T, P, T)) 
We do not obtain a KMP algorithm using the unfolding method presented 
so far because we do not use the information that the test has failed in the else- 
branch. This problem can been solved in several ways. For instance in [5],[20] 
constraints similar to A r B are propagated. The SP system presented in [7] 
derives a KMP algorithm by left-propagation of bindings and the execution 
of ground not's. In this case the non-ground negative literals play the role of 
the constraints and the left-propagation of bindings takes care of testing the 
constraints. The partial evaluators Mixtus (see [18]) and Paddy (see [15]) are 
also able to derive KMP algorithms in what seems to be a quite similar way. 
The question is how do we achieve KMP without left-propagation of bindings 
nor the explicit introduction of constraints. The solution is quite simple and con- 
sists in checking whether there are any apparent incompatibilities between the 
else-part and the fact that the test-part has to fail in order to reach the else-part. 
Pormalising this we can transform constructs of the form (If ~ Th ; (Et, P, E~)) 
where the success of P implies the success of If and where If is purely logical 
into the simplified construct (If --* Wh ; (Et, fail)). For instance we can trans- 
form (X : V --+ p(X); (X = a, Y = a, q(Z))) into (X : V ---* p(X); fail). 1~ This 
simple transformation is sufficient to obtain a KMP-like string marcher out of 
Pg. Program P10 below was obtained by partially evaluating P9 for the query 
+-- ma$ch([a,a, b],X). The above technique can be quite powerful because it 
does not require that bindings are actually left-propagated on Et and because it 
can extract information out of non-ground not's (when implemented using the 
if-then-else). Also freeness and sharing information can again be important to 
obtain good results (to detect success of If). 
Program Pro 
.~a~ch__l(W) .- .~atchl__2(T) 
ma~chl__2([H[W]) ~-- ( H = a --+ matchl__3(W]) ; matchl__2(T) ) 
matchl__3([HIT]) *-- ( H = a --* matchl_4(W]) ; matchl__2(T) ) 
.~atchl__4([HIW]) ~- (â€¢ = b -* ~r~e ; (H = a -. ma~chl__4(W]) ; ma~c~l__2(W))) 
10 
Discussion 
and Conclusion 
The aspect of trying to preserve the sequence of computed answers (and side- 
effects) has been dealt with in some of the approaches based on the unfold/fold 
transformations of [22]. For instance [19] talks about the dangers of left-propa- 
gation of bindings and solves this by transforming the bindings into explicit code 
based on the =/2 predicate and by introducing disjunctions. But as stated in [7] 
t0 Which can be further simplified (using another simple optimisation based on the fact 
that a substitution will succeed at most once) into "X = Y,p(X)". 

136 
such an approach can have a harmful effect by removing indexing information. 
The method used in [16] relies on the introduction of new predicates in a similar 
way to ours. 11 However the problems of useless bindings or useless if-then-else 
constructs are not dealt with in these papers and the semantics that is used 
stays rather informal and is not denotational. 
To our knowledge the preservation of the sequence of computed answers has 
not been dealt with in the framework of [12] and the concept of a residualisation 
step is new. Two other partial evaluators handle a significant subset of Prolog. 
One is Logimix coming from the functional world, described in [13]. The other 
one is described in [6] but, as noted earlier, does not always preserve the sequence 
of answers. The primary concern of these papers was self-application and the 
problems of useless bindings or useless if-then-else constructs are not dealt with. 
In this paper we have introduced the ES-semantics for a non-trivial subset 
of Prolog. We have shown how, through the use of LDR trees, the ES-semantics 
can be preserved by partial evaluation. An important conclusion of this paper 
is that using just partial evaluation based on unfold/fold transformations can 
yield surprisingly bad results, leaving a lot of useless assignments, arguments or 
if-then-else constructs in the residual program. We have shown how freeness and 
sharing information, which are of no interest in partial deduction, can be used 
to solve this problem. Finally our results confirm that the if-then-else is very 
well suited for partial evaluation and can be used to obtain a KMP like string 
marcher by partially evaluating the simple "match" algorithm. 
Acknowledgements 
The author is supported by GOA "Non-standard applications of abstract in- 
terpretation." I would like to thank Danny De Schreye and Bern Martens for 
proof-reading an earlier version of this paper. I also would like to thank them for 
the stimulating discussions and for their encouragement. I also thank anonymous 
referees for their helpful remarks and for pointing out related work. 
References 
1. R. Barbuti, M. Codish, R. Giacobazzi, and M. Maher. Oracle semantics for Pro- 
log. In H. Kirchner and G. Levi, editors, Proceeding8 of the Third International 
Conference on Algebraic and Logic Programming, Lecture Notes in Computer Sci- 
ence 632, pages 100-114. Springer Verlag, 1992. 
2. M. Baudinet. Proving termination of Prolog programs: A semantic approach. The 
Journal of Logic Programming, 14(1 & 2):1-29, 1992. 
3. K. Benkerimi and P. M. Hill. Supporting transformations for the partial evaluation 
of ]ogic programs. Journal of Logic and Computation, 3(5):469-486, October 1993. 
4. D. Chan and M. Wallace. A treatment of negation during partial evaluation. In 
H. Abramson and M. Rogers, editors, Meta-Programming in Logic Programming, 
Proceedings of the Meta88 Workshop, June 1988, pages 299-318. MIT Press, 1989. 
tl There is however a small mistake w.r.t, the arguments for new predicates. 

137 
5. H. Fujita. An algorithm for partial evaluation with constraints. Technical Memo- 
randum TM-0367, ICOT, 1987. 
6. H. Fujita and K. Furukawa. A self-applicable partial evaluator and its use in in- 
cremental compilation. New Generation Computing, 6(2 & 3):91-118, 1988. 
7. J. Gsllagher. 
Tutorial on specialisation of logic programs. 
In Proceedings of 
PEPM'93, the ACM Sigplan Symposium on Partial Evaluation and Semantics- 
Based Program Manipulation, pages 88-98. ACM Press, 1993. 
8. J. Gallagher and M. Bruynooghe. Some low-level transformations for logic pro- 
grams. In M. Bruynooghe, editor, Proceedings of MetagO Workshop on Meta Pro- 
gramming in Logic, pages 229-244, Leuven, Belgium, 1990. 
9. C. A. Gurr. A Self-Applicable Partial Eraluator for the Logic Programming Lan- 
guage GJdel. PhD thesis, Department of Computer Science, University of Bristol, 
January 1994. 
10. J. Komorowksi. A Specification of an Abstract Prolog Machine and its Application 
to Partial Evaluation. PhD thesis, Link6ping University, Sweden, 1981. Link6ping 
Studies in Science and Technology Dissertations 69. 
11. M. Leuschel. Self-applicable partial evaluation in Prolog. Master's thesis, K.U. 
Leuven, 1993. 
12. J. W. Lloyd and J. C. Shepherdson. Partial evaluation in logic programming. The 
Journal of Logic Programming, 11:217-242, 1991. 
13. T. Mogensen and A. Bondorf. Logimix: A self-applicable partial evaluator for Pro- 
log. In K.-K. Lau and T. Clement, editors, Logic Program Synthesis and Trans- 
formation. Proceedings of LOPSTR'9~, pages 214-227. Springer-Verlag, 1992. 
14. R. O'Keefe. On the treatment of cuts in Prolog source-level tools. In Proceedings 
of the Symposium on Logic Programming, pages 68-72. IEEE, 1985. 
15. S. D. Prestwich. The PADDY partial deduction system. Technical Report ECRC- 
92-6, ECRC, Munich, Germany, 1992. 
16. S. D. Prestwich. An unfold rule for full Prolog. In K.-K. Lau and T. Clement, 
editors, Logic Program Synthesis and Transformation. Proceedings of LOPSTR'9~, 
Workshops in Computing, University of Manchester, 1992. Springer-Verlag. 
17. M. Proietti and A. Pettorossi. Semantics preserving transformation rules for Pro- 
log. In Proceedings of the ACM Symposium on Partial Evaluation and Semantics 
based Program Manipulation, PEPM'91, Sigplan Notices, Vol. 26, N. 9, pages 274- 
284, Yale University, New Haven, U.S.A., 1991. 
18. D. Sahlin. An Automatic Partial Evaluator for Full Prolog. PhD thesis, Swedish 
Institute of Computer Science, Mar. 1991. 
19. D. Sahlin. Mixtus: An automatic partial evaluator for full Prolog. Ne~v Generation 
Computing, 12(1):7-51, 1993. 
20. D. A. Smith. Partial evaluation of pattern matching in constraint logic program- 
ming languages. In N. D. Jones and P. Hudak, editors, ACM Symposium on Partial 
Evaluation and Semantics-Based Program Manipulation, pages 62-71. ACM Press 
Sigplan Notices 26(9), 1991. 
21. A. Takeuchi and K. Furukawa. Partial evaluation of Prolog programs and its ap- 
plication to meta programming. In H.-J. Kugler, editor, Information Processing 
86, pages 415-420, 1986. 
22. H. Tamaki and T. Sato. Unfold/fold transformations of logic programs. In S.- 
~. T~rnlund, editor, Proceedings of the Second International Conference on Logic 
Programming, pages 127-138, Uppsala, Sweden, 1984. 

Schema-Based Top-Down Design of Logic 
Programs Using Abstract Data Types 
E. Marakakis and J.P. Gallagher 
Department of Computer Science, University of Bristol 
Queen's Building, University Walk, Bristol BS8 1TR, U.K. 
e-mail: manolis~compsci.bristol.ac.uk, john~compsci.bristol.ac.uk 
Abstract. This paper presents a set of schemata that support stepwise 
top-down design of logic programs using abstract data types (ADTs). 
There are thus three main components to this approach: top-down de- 
sign, program schemata and ADTs, all of which are already well es- 
tablished notions. Our aim is to combine these ideas in a framework, 
amenable to support by design tools and allowing the use of existing 
logic program transformation techniques to optimise the final programs. 
1 
Introduction and Motivation 
This paper presents a set of schemata that support stepwise top-down design 
of logic programs using abstract data types (ADTs). There are thus three main 
components to this approach: top-down design, program schemata and ADTs, 
all of which are already well-established notions. Our aim is to combine these 
ideas in a framework, amenable to support by design tools and allowing the use of 
existing logic program transformation techniques to optimise the final programs. 
The choice of the set of available schemata and ADTs is very important, and is 
based on a thorough survey in the literature of the use of these techniques in 
logic program construction. 
The main aims of this paper are 
- to justify the approach, 
- to show a small set of schemata and ADTs with which we are currently 
working, 
- to discuss future directions of this work. 
The main components of our approach are now discussed. 
1.1 
Top-Down Design 
Top-down design is a process of successive refinement of a design. At each stage 
in the process there is a number of "undefined" parts of the design. A refinement 
step replaces some undefined part by a more detailed construct, which itself may 
contain further undefined subparts as well as constructs from some executable 
target language L. The process is finished when the design is entirely in L. 

139 
The main justification of top-down design is that it gives a goal-oriented 
structure to the design process, and suggests a "compositional" style of program 
in which each refinement step can be independently justified or proved correct. 
Apart from this very little is implied by the phrase "top-down design". The 
actual refinement steps may take many forms. 
Our belief is that, if tools to support top-down design are to be practical, 
refinement steps should correspond to the set of basic constructs in the tar- 
get language L. That is, each refinement step should introduce one language 
construct. For example, if L is a Pascal-like language we could insist that each 
refinement would introduce only one while, repeat, if-then-else or statement 
composition construct. The target language L therefore plays a very important 
role in top-down design since each design decision has to be expressed by a single 
construct. The constructs available in L should be sufficiently high-level to be 
regarded as part of the design rather than implementation. 
In our approach each refinement step introduces either one instance of a 
program schema or an ADT operation. In a loose sense, therefore, the choice of 
schemata and ADTs defines a "design language" whose basic constructs consist 
of the set of schemata and the set of ADT operations. 
The separation of schemata from ADTs is an important aspect of our ap- 
proach since each schema is independent of any particular types. Design decisions 
therefore need not confuse control with data. This is unlike most schemata in 
the logic programming literature, which are associated with specific types (such 
as lists and trees). 
1.2 
Program Design Schemata 
A program design schema for a language M, or simply schema for M, is an 
expression that represents a set of programs in M having a common form. Each 
such program is called an instance of the schema. For logic programs, schemata 
are defined in Section 4. A schema can be identified with the set of its instances. 
Schemata are abstractions of program structure, analogous to abstractions of 
data by ADTs. 
Our problem is to define a relatively small set of schemata, each member 
of which captures a useful form of program. Schemata should contain enough 
structure to be useful in the design process, but be independent of specific data 
types. This choice is quite difficult. At one extreme, a single schema could be 
used to construct all programs [24]. On the other hand the literature contains a 
large number of possible schemata (variously called schemata, cliches, skeletons, 
and other things). Too many schemata would be confusing and choosing among 
them would inevitably obscure the design process. Our current set, shown in 
this paper, consists of five schemata. Although we do not regard this as final by 
any means, it is important to stress that we do not envisage a growing library 
of schemata. 
Another requirement on our choice of schemata is that they should have both 
a clear declarative and a procedural reading. Instantiations of schemata should 
be executable, but have a clear logical structure. 

140 
1.3 
Abstract Data Types (ADTs) 
The concept of type is used to classify objects with distinct characteristics. In 
programming, a type or data type is a class of data objects or values, such as 
integers, reals, sets, graphs, cartesian products, and so on. A number of opera- 
tions is associated with each type which are applied to the values of the type. 
Abstract data types give a representation-independent specification of a data 
type. That is, the operations of the data type are defined in terms of axioms 
that any representation of the type should satisfy. 
We also need to introduce the notion of a parameterised ADT. This is an 
ADT whose components may be of some other unspecified type. For instance 
a sequence may consist of integers, sets, other sequences, and so on. Thus we 
could define a type sequence(r) where r is a type variable indicating the type 
of elements of the sequence. 
In our design approach, abstraction is applied to both the algorithm and 
the data in a problem. In this way the design is separated from any particular 
representation of the problem. The use of data abstractions is common, but the 
use of algorithm abstractions is rarer. Yet we maintain that the experienced 
program designer makes much use of algorithm abstractions or forms. 
The result of the top-down design is an executable design or prototype. To 
summarise our approach, we might replace the well-known equation [23] 
Algorithms + Data Structures = Programs 
by 
Schemata + ADTs = Executable Designs 
As a next step in this approach program transformation techniques can be ap- 
plied to the executable design. These could have the effect of removing the design 
layer by intertwining it with implementation, or of introducing other standard 
optimisations. The intention of this step is to improve the performance of the 
final program. 
2 
Related 
Work 
2.1 
Program Abstractions 
Approaches for constructing logic programs based on some kind of abstraction 
have been followed by many researchers [2], [5], [6], [9], [12], [19], [22]. Their 
difference apart from technical details is on how they have conceived and used 
the concept of abstraction. These approaches are classified and discussed based 
on the kind of abstraction that they use. 

141 
Program Skeletons and Cliches. Skeletons are the primary control flow of 
programs [12], [19], [21]. They are used as the starting point for program de- 
velopment. Techniques are standard Prolog programming practices, e.g. passing 
back results from computations. Logic programs are constructed by successively 
enhancing skeletons by applying techniques to them. 
Cliches in [2] are defined as commonly occurring program forms that can be 
reused. Formally cliches are defined to be second-order sentences. The construc- 
tion process involves instantiation of a clich~ with argument values supplied from 
the programmer. 
Abstraction in these approaches is based on control flow similarities between 
logic programs. These tend to be constructed from commonly occurring program 
idioms such as processing all elements of a list, and in fact these skeletons tend 
to be closely related to certain data structures. Experience seems to be the main 
requirement needed to select such schemata. 
Program Schemata. In [9] and [22] a schema is formally defined to be the 
most specific generalisation [18] of a class of programs. The program construc- 
tion process in [221 is seen as searching a well-founded ordering of schemata up 
to certain depth guided by a set of positive and negative examples. Schema in- 
stantiation is not discussed in [9]. Schemata for list processing only are shown. 
Schema classification is based on syntactic similarities. 
This approach depends very much on the set of programs that are used for 
finding the most specific generalisation. This kind of abstraction may result in 
program schemata with very little structure in them to support the design pro- 
cess. The schemata that can be constructed by that approach are as many as 
there are programs, that is, infinite. Only small programs have been constructed 
by this approach. Verification is not discussed in [9] while in [22] program correct- 
ness is proved with respect to a set of positive and negative instances that have 
to be covered and not covered respectively by the predicate under construction. 
Logic Description Schemata. A method for constructing logic programs based 
on structural induction and the generalization paradigm is proposed in [5], [6]. A 
logic description (LD) is a formula in typeless first-order logic. Two kinds of gen- 
eralisations are used for the construction of LDs, structural and computational 
generalisation. Structural induction is the basis of the construction method. The 
constructed LD is in turn transformed into a logic program. Logic description 
skeletons are produced automatically from logic description schemata. Undefined 
predicates in logic description skeletons are defined either automatically using 
object knowledge or interactively by the user. It is shown that logic descriptions 
are correct by construction. A logic description schema, i.e. Divide-and-Conquer, 
is used in [8] to guide the synthesis of logic programs from specifications which 
consist of examples and properties. 
The structural and computational generalisations in [6] correspond to ADTs 
and to design schemata respectively, from the point of view that both are ab- 
stractions over the data and the procedural aspects of a program but they are 

142 
different kinds of abstractions. The construction of LD and therefore the whole 
method is data representation dependent. The Divide-and-Conquer schema in 
[8] is hardwired in the synthesis mechanism while in our approach the schemata 
are input to the system. Specifications based on examples have the advantage 
of simplicity but on the other hand the selection of appropriate examples is not 
always simple. The synthesis of programs which require multiple applications of 
the Divide-and-Conquer schema are not discussed in [8]. Construction of small 
programs is demonstrated in [6] and [8]. The construction of large programs does 
not seem to be a straightforward task. The use of typeless logic is one reason for 
their limitation. 
2.2 
Types 
The extension of Prolog programs with mode and type declarations is suggested 
in [3] in order to enhance their readability and obtain more reliable programs. 
Types are used to detect errors in cases like mistyping arguments or misplaced 
arguments. Ghdel [11] is a strongly typed logic programming language. Its type 
system is based on many sorted-logic with parametric polymorphism. A poly- 
morphic type checking system for Prolog is proposed in [17]. The type system 
in [17] is extended with subtype relations in [7] in order to improve its software 
engineering properies. 
Types in [7], [11] and [17] as in our approach are treated as terms over a spe- 
cial alphabet disjoint from the program's alphabet. Unification and type substi- 
tution are over the extended set of type symbols which are treated as ordinary 
terms. Types in our approach are both inferred during program development 
and for type checking of calls to ADT predicates. The type systems in [7], [11], 
[17] perform type Checking in constructed programs. ~'hey use type declarations 
to check if the programs are type correct. 
2.3 
Modes 
Modes in [3] are used to validate the flow of data through a clause. The problem of 
automatically inferring modes for predicates in Prolog programs is studied in [4] 
for optimization purposes. Modes in [16] are used to optimize Prolog programs. 
The mode analysis in the literature [4], [16] is mainly used for optimization 
purposes, 
In our approach intended" modes are declared for the schemata, the ADT 
operations and the initial predicate specification. During the design, modes are 
inferred and can be checked for compatibility with the intended modes. 
3 
Data Types and Modes 
3.1 
Data Types 
The data types that we consider in this approach are polymorphic types. The 
type variable 7" ranges over types. The alphabet of variables V, function symbols 

143 
F and predicate symbols P of the underlying logic language has been extended 
by the type variables V ~ and the type constructors F ~ such that V t3 V r = {} 
and F t3 F ~ = {}. The theoretical basis of the types in this approach is many 
sorted logic with parametric polymorphism [10], [11]. 
A data type term may consist of type variables, basic types and type construc- 
tors. The syntax of data types in BNF production rules is the following 
Type ::= r l 
BI 
C(Type,..,Type) 
r stands for type variables~ B stands for the basic types, or constructors 
of arity O. C(Type, .., Type) stands for constructors of arity > 1. Type terms 
are defined similarly to first-order terms. That is, type variables correspond to 
individual variables, basic types correspond to constants and type constructors 
to functions. A variable typing [10], [11], is defined to be a set of the form 
{X1/rl, .., Xn/rn} where Xi (1 < i < n) are distinct variables and r~ are types. 
Each schema individual variable has been assigned a type variable. 
3.2 
Abstract Data Types 
Unfortunately, programming languages do not have facilities for direct modelling 
of all real world problems. The problem of expressing in a programming language 
a situation of the real world can be split in two subproblems: 
1. Construct a model of the real world situation. 
2. Implement that model using the facilities of a programming language. 
The relationships of the real world objects are complex and their modelling 
requires a powerful language. Mathematics seems to be the most appropriate. 
Once the modelling has been completed, it can be implemented using the facili- 
ties of a programming language. An abstract data type or data type specification 
is a representation-independent specification of data types. Each data type is 
associated with a set of operations which are defined in terms of axioms that 
any representation of the type should satisfy. A mathematical model of a real 
world problem can be constructed by using abstract data types. They provide a 
valuable way to express real world entities and to organize their relationships. 
We have implemented several abstract data types such as sets, ordered sets, 
stacks, graphs, cartesian product etc. The operations have been implemented as 
predicates. 
3.3 
Modes 
The mode of a predicate in a logic program indicates how its arguments will be 
instantiated when that predicate is called. The mode of arguments of a predicate 
can be seen in two possible states, that is before the call and after the success of 
the predicate. The mode of an argument in these two states is called call-mode 

144 
and success-mode respectively. Call modes are meaningful in a logic program 
only when the control strategy has been specified. The program schemata in this 
approach have been constructed with the left-to-right depth-first computation 
rule of Prolog in mind. The modes i and d are used. They stand for "input" 
and "don't know" respectively, i identifies the arguments which are expected 
to be ground. These terms are characterized as "input". An argument with any 
instantiation can be assigned mode d. Each schema individual variable has been 
assigned an "intended" mode of use. Modes in this approach are used to guide 
the application of schemata to undefined predicates and in the refinement of 
undefined predicates by ADT operations or equality. 
Given a partial design and a moded initial goal, a mode inference procedure 
computes call and success modes as far as possible. These inferred modes are 
used to check the modes of calls to ADT predicates for compatibility with the 
intended modes. Our mode inference procedure is an abstract interpretation 
similar in many respects to other mode inferrence procedures such that in [4]. It 
is beyond the scope of this paper to describe it in detail. 
4 
Program 
Design Schemata 
Algorithm design techniques are important in constructing programs [1], [13]. 
It has been observed that different problems are solved by using the same algo- 
rithm. If we take a collection of solution programs for such problems and factor 
out the differences relating to the problem representation, we obtain the algo- 
rithm common to all of them. We call such a problem-independent algorithm 
a program design schema, or schema. Such design schemata contain a fixed set 
of subparts or subgoals, that have different realisations/instantiations for each 
problem that they are applied to. 
4.1 
The Design Schema Language 
In this section we consider a small set of program design schemata that we find 
useful for constructing logic programs. Their classification is based on the design 
strategy that each schema represents. 
The schemata are formally defined as expressions in a meta-language of first- 
order logic. The meaning of the symbols of the meta-language is the following. 
- the capital letters X, Y, Z, W, U, V, T, S are schema individual variables. 
They range over object-language variables or tuples of such variables. 
- Other capitalized words are predicate variables. They range over predicate 
symbols. 
- The meta-language logical symbols A, -~ and *-- have their usual meaning. 
For each schema individual variable its type and mode are shown as well. 
For example, (X r, i) stands for the schema individual variable X whose type is 
r and mode i. In the following, rl, r2, ra stand for type variables. 

145 
4.2 
Five Design Schemata 
We consider schemata named as follows, and discuss each in turn. 
1. Incremental 
2. Subgoal 
3. Divide-and-conquer 
4. Case 
5. Backtracking 
The predicate variables are given names that indicate their intended meaning. 
Incremental. The Incremental schema processes one by one each piece of the 
input data and composes the results for each one to construct the solution. The 
schema is as follows. 
Incr((X n , i), (yr2, d)) +-- 
Terminating((X 
n , i)) A 
Initial-result((X 
r' , i), (yr~, d)) 
Incr((X n , i), (y,2., d)) 
-,Terminating((X 
n , i)) A 
Elem-by-elem( ( X n , â€¢ 
( V TM , d), ( W n , d)) A 
Incr((W rl , i), (Z ~', d)) A 
Non-initial_resuit( ( X n , i), ( V r3 , i), ( Z r2, i), (y~2, d)) 
Subgoal. The Subgoal schema reduces the problem into a sequence of two sub- 
problems. The solutions of the simpler problems are composed into a solution of 
the original problem. This is, an AND reduction. Note that V could be empty 
as well. The schema is as follows. 
SubGoal((X n , i), (Y", d)) ~-- 
SubGoall((X n , i), (V r~, d), (yr~, d)) 
SubGoal2((X n , i), (V r" , i), (yr~, d)) 
Divide-and-conquer. The Divide-and-conquer schema decomposes the prob- 
lem in two subproblems. The solution of the problem is constructed by composing 
the solutions of the subproblems together. The schema is of the following form. 
DivConq((X 
n , i), (yr2, d)) ,-- 
Terminating( ( X n , i)) A Initial_result( ( X r` , i), (yr, , d)) 
DivConq( ( X n , i), (Y", r 
+-- 
-~Terminating((X 
n , i)) A 
Decompos"ion( ( X r' , i), (W r' , d), ( Z n , d)) A 
DivConq((W',, i), (Ur',d)) A OivConq((Z n , i), (Vr',d)) A 
Cornposition( (U r' , i), (V r2 , i), (yr2 , d)) 

146 
Case. The Case schema reduces the problem in two independent subproblems. 
Each subproblem corresponds to a different case of the original problem. This 
is, an OR reduction. The schema is as follows. 
Case((X 
r, , i), (yr,, d)) 
Casel((X", :t), (Y", d)) 
Case((X r' , i), (yr,, d)) 
c~,e2((x',, ~), (Y',, a)) 
Backtracking. The Backtracking schema does an organized exhaustive search 
in the solution space. Solutions are constructed in a stepwise fashion. Note that 
the solution returned may be composed from the complete search path. The 
schema is as follows. 
Backtr( ( X" , s 
(yr., d)) ~-- 
Initiai_search_node((X r' , i), (W "'aek(r~), d), (Ur% d)) A 
Backtrl((Xr', i), (W ''ack(') , i), (U "2, :i.), (yr,, d)) 
Backtrl((X n , i), (W ~''ack(r'), i), (U r2, i), (yr,, d)) ~.- 
Solution_cornplete( ( W"~k('. ), i ), ( U'~, i ) ) A 
Solution_assignment((U ~ , i), (Y'~, d) 
Backtri((X r' , i), (W "t~'k('3), i), (U r2, i), (Y'~, d)) ,-- 
-~Solution-complete((W "''ek('), i), (U r2 , i)) A 
rorward-move((X rl , i), (W "taek(rs), i), (U r2, i), 
(z''~ 
d), (v',, d)) ^ 
Backtrl((X "1 , i), (Z '`"`kO'), .i), (Vr,, i), (Y~", d)) 
Backtrl ( ( X" , i ), ( W ,'"r 
i ), ( U':, i), (Y~'~, d)) ,,-- 
-~Solution_complete((W "`a'~(rD, i), (U "~, i)) A 
~rorward..rnove( ( X r' , i), (W "taek(r'), i ), ( U r2 , i ), 
(Z `taet(r'), d), (V r,, d)) A 
Backtracking( (W "'a~(r'), i), (U r2, i), 
(T"~ 
d), (a ~, d)) ^ 
Backtr l ( ( X T' , i ), (T ''a~k(r~), i), ( S r" , i ), (Y", d)) 
5 
Schema Instantiation 
A program design schema is instantiated with respect to an undefined predicate. 
Let p(X1,.., Xn) be an undefined predicate with variable typing 
= {X,l~, ...,x,H,}. 
In the following, mode(X) stands for the mode of argument X. Let 
7 = (Y,, .., Y,,): rnode(r~) = i, r~ e {X,, .., X,} 

147 
m 
D = (Zl, ..,Z.~): ,'.ode(Z~) = d, Zj ~ {XI, .., X.} 
{Ys, .., Ynl} O {Zl,.., Zn2} = {X1,.., An}. The variables in the tuples 7 and 
respectively have the same order that they have in p(Xx,.., Xn). 
Tupling is an operation that is applied on the undefined predicate p/n as 
follows: 
tupling(p( X1, .., X,) ) = p( I, D) 
Let {Cx, .., Cr} be a variant of schema s 
Each clause Ci (1 < i < r) has the 
form Hi ~ Bi, where Hi is an atom and Bi is a conjunction of literals. 
A schema substitution gti for clause Ci of ,U with respect to p(X1, ..,X,) is 
defined as the composition of the following substitutions. 
~i = OioAi 
where 
- Oi = mgu(p(I, D), Hi). That is, Oi is a substitution of schema predicate 
variables and individual variables that occur in Hi, 
- Ai is a substitution of the schema predicate variables in Bi that do not occur 
in Hi. 
Schema predicate variables are substituted by fresh predicate symbols that have 
not been used before. The instance f of ~ which defines p(I, D) is defined to 
be 
f= 
1c,~1, .., c,~} = {#1, ..., c;} 
Let A be an atom and 12 a variable typing of A. A12 denotes the application 
of variable typing 12 on the atom A. Similarly let C be a clause and ~ a variable 
typing of C. CE denotes the application of variable typing ~" on the clause C. 
Let ~i be the variable typing of clause Ci in schema ,U. Let 
r = mgu(p(I, D) 12, Hi ~,) 
Then the derived variable typing for C~ (1 < i < r) is defined to be 
rl~ = { Xl,,r 
: Xl,, ~ 12 u zi } 
Any variable X in C~ of f with variable typing of the form (rl,.., rk) is 
replaced by the tuple of variables (Xx,..,Xk). The variable typing Hi of C~ 
is extended by such variable typings, i.e. {X1/7"1, ..,Xk/vk}. The new variable 
typing//i for Ci consists from the union of Hi and such variable typings. 
detupling(A) where A is an atom is defined to be detupling(A) = p(X~, .., X,) 
where {X1,.., Xr} = vars(A) and X1,.., X, have the same order as in A. 
A detupling operation on clause C of the form H *--- L1, .., La is defined to be 
detupling(H *-- L1,.., Lt) = detupling(tt) ~-- detupling(L1),..,detupling(Li) 
detupling(Li) = -- detupling(Ai), (1 < i < 1) 

148 
where Ai is the atom of Li. 
The instance/of schema 27 that defines the predicate p(X1,.., Xn) is defined 
to be 
9 
! 
. 
# 
I---- {detuphng(C1),..,detupllng(Cr) } 
Example: 
Suppose that the Incremental schema 27 is applied to the undefined predicate 
p(Xl, X2, X3). The variable typing of p(Xl, X2, X3) is f2 = {Xl/set(str), X2/r, 
X3/orderedSet(str)} where r is a type variable, and the "intended" modes of its 
arguments are mode(X1) = i, mode(X2) = i, mode(X3) = d. 
tupling(p(X1, X2, X3) --" p((X1,X2), (X3)) = p(7,'D) 
Assuming that a renamed substitution for Incremental schema is 
{ c~,62 } = 
{ 
Incr(Xrl,Y r2) 
Terminating(X r' ) A Initial_result(X r' , yr2) 
incr(Xrl, yT~) 
-~Terminating(X r' ) ^ Eiem_by_elem(X ~' , Vr3, W r') ^ 
Incr(Wr,, Z~) ^ Non_initial_resuit(xr~, V~, Z~, y~2) } 
where, vl, r2, ra are the types corresponding to each schema individual variable9 
The variable typing for C1 is ~-1 = {X/rl, Y/r2}. The variable typing for C2 is 
F.2 = {x/~, y/~2, v/~3, w/~l, z/~} 
The schema substitution ~i = Oi o Ai i ~-- {1,2} with respect to p(I,D) is 
the following 
f 
O1 = 02 = mgu(p(I,D), Incr(X,Y)) - { Incr/p, X/(X1,X2), Y/(X3) } 
A 1 = { Terminating/q1, Initial-result/q2 } 
A2 = { Terminating/q1, Elem_by_elem/q3, Non-initial_result/q4 } 
= {clolzxl, c~o2a2} = {c'1, c'2} 
= {p((Xl,X2), (xa)) .- 
ql((Xl,X2)) ^ 
q2((Xl,X2), (X3)) 
p((Xl,X2), (X3)) *-- 
-~ ql((Xl,X2)) A 
q3((Xl,X2), V, W) A 
p(W, z) ^ 
q4((x1,x2), v, z, (x3)) } 
Let ~ 
and ~ be two type substitutions such that 

149 
~I = mgu((p(I,D) ~), (Incr(X,Y) ~'1)) = 
{ rl/(set(str),r), r2/(orderedSet(str)) } 
~[ = ~ 
= mgu((p(I,D) ~), (Incr(X,Y) ~2)) = 
{ n/(set(str),r), r2/(orderedSet(str)) } 
The variable typings of the clauses {C1 O1A1, C202A2} are the following 
//1 = {*a~I} u {&~I} 
//1 = { Xl/set(str), X2/r, X3/orderedSet(str), 
X/(set(str),r), Y/(orderedSet(str))} 
II2 = { Xl/set(str), X2/r, X3/orderedSet(str), 
X/(set(str),r), Y/(orderedSet(str)), 
V/r3, W/(set(str),r), Z/(orderedSet(str))} 
9 
I 
. 
I 
= { detuphng(C1), detuphng(C2) } = 
= {p(Xl, X2, X3) ~-- 
ql(X1, X2) A 
q2(Xl, X2, X3), 
p(Xl, X2, X3) ~- 
"- ql(X1, X2) A 
q3(Xl, X2, V, Wl, W2) A 
p(Wl, W2, Zl) A 
q4(Xl, X2, V, Zl, X3) } 
I7; = mu {} 
1/'2 =//2u {Wl/set(str), W2/r, Zl/orderedSet(str)} 
6 
Refinement 
by ADT 
or Equality 
Predicates 
The definition of an undefined predicate p(X1, ..X,) in terms of an ADT or 
equality predicate will create a new clause of either form 
p(X,, ..X,) ~- R(Y,,.., Ym) m < 
p(x1, ..x,) ~- ~R(YI,.., Ym) m < n 
where R is an ADT operation predicate symbol or the equality symbol and 
{I"1, ..Ym} C_ {X1, ..Xn}. The variables in the clause are typed according to the 
declared types of ADTs. 
The call-success modes generated by the mode inference procedure are used 
to validate the call modes of R(YI,.., Ym). That is, the call mode of R(Y1,.., Y,~) 
is subsumed by its intended mode. 

150 
7 
The Design Process 
Initially, the programmer gives a specification of the predicate that he wants 
to construct. That specification consists of the data type and the mode of each 
argument. Goals are expected to have ground the arguments with mode i, argu- 
ments with mode d can be either ground or nonground or partially ground. The 
initial refinement is applied to that predicate. The next refinements are applied 
to undefined subgoals of the clauses created. Each refinement step involves either 
of the following actions. 
- The application of a design schema. 
- The definition of the predicate being refined in terms of an ADT or equality 
predicate or its negation. 
The construction process is a successive top-down application of refinements 
until the complete construction of an executable design of the system. A design 
is considered to be complete when all of its predicates are defined. 
The above discussion is illustrated by applying an example with.five refine- 
ments. That is, three applications of design schemata and two predicate defini- 
tions in terms of ADT predicates. The effect of the application of each schema 
will be shown, not the instantiation details of the schema. 
1. Predicate specification: p((I,i,set(~-)), (D,d,orderedSet(r))) 
2. Refinement 1 applied on p/2: Incremental schema. 
p(I, D) :- 
ql(i), 
q2(I, D). 
p(I, D) :- 
not ql(I), 
q3(I, X, aI), 
p(RI, liD), 
q4(I, X, RD, D). 
3. Refinement 2 applied on q2/2: Subgoal schema. 
q2(I, D) "- 
tl(I, Y, D), 
t2(I, Y, D). 
4. Refinement 3 applied on q3/3: Subgoal schema. 
q3(I, x, RI) "- 
ra(I, X, RI), 
r2(I, X, RI). 
5. Refinement 4 applied on rl/3: Abstract data type operation get_e/era/2. 
rl(I, X, RI) :-get_elem(I, X). 
6. Refinement 5 applied on r2/3: Abstract data type operation delete/3 
r2(I, X, RI) :-delete(I, X, RI). 

7.1 
Examples 
151 
Insertion sort. insert_sort(S1, S2) is true if $2 is the set S1 with its elements 
sorted. 
Predicate specification: insert.sort((Sl,i,set(r)), (S2,d,orderedSet(r))) 
Refinements. 
Schema: Incremental 
insert_sort(S1, $2) :- 
terminating(S1), 
construct_initial_result(St, $2). 
insert_sort(St, $2) "- 
\+ terminating(S1), 
get_elem_incr(S1, Elem, RestS1), 
insert_sort(RestSl, RestS2), 
construct_non_initial_result(St, Elem, RestS2, $2). 
terminating(el) :- empty_set(S1). 
construct_initial_result(Sl, $2) :- empty_ordSet(S2). 
Schema: Subgoal 
get_elem_incr(S1, Elem, RestS1) :- 
get_element(Sl, Elem, RestSl), 
delete_element(Sl, Elem, ResiSt). 
construct_non_initial_result(Sl, Elem, RestS2, $2) :- 
set_elem_ordSet(Elem, RestS2, $2). 
get_element(Sl, Elem, ReetSl) :- get_elem(Sl, Elem). 
delete_element(S1, Elem, RestSl) :- delete(Elem, SI, RestSl). 
Abstract Data Type Operations. 
ADT operations for ,nordered sets 
- 
empty_set(S) 
-delete(X, Sl, S2) 
- 
get_elem(S, Elem) 
ADT operations for ordered sets 
- 
empty_ordSet (S) 
- 
set_elem_ordSet(X, $1, S2) 

152 
8 
Conclusions and Further Work 
Five novel features in the development of logic programs are introduced by 
this appoach. First, the problem domain representation, i.e. the abstract data 
types, are separated from the structural or control part of the algorithm, i.e. 
the program schemata. Second, the set of program schemata consists of only 
five schemata, making them manageable by humans. Third, the application of 
a program schema to an undefined predicate is directed by modes. Fourth, the 
constructed program designs are type correct. Fifth, static analysis is performed 
dynamically during program construction. 
So far, we find this small set of schemata surprisingly expressive. Larger ex- 
amples of constructed programs, e.g. depth-first traversal of a graph, can be 
found in [15]. Related work in functional programming languages has been fol- 
lowed in [20]. One strategy, i.e. divide and conquer, is used in [20] for automat- 
ically constructing programs from formal specifications. 
A set of support tools for program development using these ideas is under 
development. The question of heuristics for selecting the appropriate schema or 
ADT operation at each refinement step is also a subject that requires study. 
The transformation of the executable design into a more efficient program 
will also be investigated. The fact that executable logic programs are produced 
means that state of the art transformation methods can be brought to bear. 
Techniques such as partial evaluation have already been applied to removing the 
overhead of ADTs [14]. Other deeper transformations include those based on 
unfold/fold and coroutining between goals. 
Our approach produces type-correct designs, and the role of ADTs is impor- 
tant for this. On the question of verification in general, we have not assumed 
the presence of a full formal specification of the problem (that is, a detailed 
formalisation of the input/output relation of the program). We have considered 
only questions of algorithm design and have assumed that some aspects of spec- 
ification are subsumed in the design process. However, higher level specification 
languages that can be mapped to the schemata could be investigated. 
References 
1. A. Aho, J. Hopcroft and J. Ullman, Data Structures and Algorithms, Addison- 
Wesley, 1983. 
2. D. Barker-Plummet, 
Clichd Programming in Proiog, Proceedings of the Second 
Workshop on Meta-programming in Logic, (ed. M. Bruynooghe); April 1990, Bel- 
gium, pp.247-256. 
3. M. Bruynooghe, Adding Redundancy to Obtain More Reliable and More Readable 
Prolog Programs, Proceedings of the First International Logic Programming Con- 
ference, Sept. 1982, Marseille, France, pp.129-133. 
4. S. Debray, D. Warren, Automatic Mode Inference ]or Prolog Programs, Proceedings 
of the Symposium on Logic Programming, Salt Lake City, Utah, Sept. 1986, pp.78- 
88. 

153 
5. Y. Deville, J. Burnay, Generalization and Program Schemata: A Step Towards 
Computer-Aided Construction of Logic Programs, Proc. of the North American Con- 
ference on Logic Programming, 1989, (eds. E. Lusk and R. Overbeek); pp.409-425, 
vol.I,. 
6. Y. Deville, Logic Programming: Systematic Program Development, Addison-Wesley, 
1990. 
7. R. Dietrich, F. Hagl, A Polymorphic Type System with Subtypes]or Prolog, ESOP'88 
Proceedings of the 2nd European Symposium on Programming, Nancy, France 1988, 
Lecture Notes in Camp. Sc. no 300, pp.79-93. 
8. Pierre Flener, Yves Deville, Towards Stepwise, Schema-Guided Synthesis of Logic 
Programs, Proceedings of International Workshop on Logic Program Synthesis and 
Transformation, LOPSTR'91, Manchester, U.K., 1991, pp.46-64. 
9. T. Gegg-Harrison, Basic Pralog Schemata, Technical Report, CS-1989-20, Dept. of 
Computer Science, Duke University, Durham, North Carolina, Sept. 1989. 
10. P. Hill, and R. Topor, A Semantics ]or Typed Logic Programs, Chapter 1 in Types 
in Logic Programming edited by F. Pfenning, The MIT Press, 1992. 
11. P. Hill, J. Lloyd, The GJdel Programming Language, The MIT Press, 1994. 
12. A. Lakhotia, A Workbench for Developing Logic Programs by Stepwise Enhance- 
ment, PhD thesis, Case Western Reverse University, Department of Computer En- 
gineering and Science, Aug. 1989. 
13. J. Kingston, Algorithms and Data Structures, Design, Correctness, Analysis, 
Addison-Wesley, 1990. 
14. J. Komorowski, Towards a Programming Methodology Founded on Partial De- 
duction, Proc. of the European Conference on Artificial Intelligence, Stockholm, 
Sweden, August 1990. 
15. E. Marakskis, J.P. Gallagher, Schema-Based Top-Down Design of Logic Programs 
Using Abstract Data Types, Technical Report, CSTR-94-02, University of Bristol, 
Department of Computer Science. 
16. C. Mellish, Some Global Optimizations ]or a Prolog Compiler, Journal of Logic 
Programming, 1, 1985, pp.43-66. 
17. A. Mycroft, R. O'Keefe, A Polymorphic System ]or Prolog, Artificial Intelligence, 
23, 1984, pp. 295-307. 
18. G. Plotkin, A Note on Inductive Generalization, Machine Intelligence, 5, 1970, 
pp.153-163. 
19. D. Robertson, A Simple Prolog Techniques Editor]or Novice Users, Proceedings of 
the 3 ra Annual Conference on Logic Programming, Edinburgh, April 1991, pp.78-85. 
20. D. Smith, Top-Down Synthesis o] Divide-and-Conquer Algorithms, Artificial Intel- 
ligence, vol. 27, 1985, pp.43-96. 
21. L. Sterling, M. Kirschenbanm, Applying Techniques to Skeletons, Chapter 6 in 
Constructing Logic Programs edited by Jean-Marie Jacquet, Wiley, 1993. 
22. N. Tinkham, Induction o] Schemata ]or Program Synthesis, PhD thesis, Depart- 
ment of Computer Science, Duke University, 1990. 
23. N. Wirth, Algorithms 4- Data Structures = Programs, Prentice-Hall, 1976. 
24. T. Yokomori, Logic Program Forms, New Generation Computing, No.4, 1986, 
pp.305-319. 

Generalizing Extended Execution 
for Normal Programs 
Sophie Renault 
INRIA-Rocquencourt 
BP 105, 78153 Le Chesnay, France 
Sophie.Renault @inria.fr 
Abstract 
We present a set of inference rules aimed at proving declarative (logical) 
properties of normal programs. Proofs are goal directed and are performed by 
means of replacement, simplification and rewriting. This work can be seen as a 
generalization of Extended Execution [16] which is in turn an extension of the 
prolog interpreter. We show the soundness of our generalization and discuss its 
completeness. Two extensive examples are given. We conclude on the relevance 
of our approach within the general framework of verification. 
1 
Introduction 
Checking the correctness of a logic program w.r.t, a specification has been consid- 
ered from various angles, each of them suggesting its own criteria for an adequate 
semantics and an appropriate definition of correctness and specification. 1 
In this paper our approach of correctness is to prove that a formula ~, ex- 
pected to express a desirable property of a program P, is a logical consequence of 
its completion [5]. P is a normal program (definite clauses with possibly negative 
literals in their bodies). ~ is any (closed) first-order formula and may be seen as 
a partial specification for P. A successful proof is a sequence of goals from 9 to 
true. Our framework is named EEG (Extended Execution Generalized) since it 
is a generalization of the one proposed by Kanamori et al. in [16, 15] for definite 
programs, namely Extended Execution (EE). 
EE is based on an extension of the Prolog interpreter for more general 
queries named S-formulas that mainly consist of implicative formulas of the 
form V~(A --* 3~B), where 5 and ~ denote two sequences of variables and A 
and B denote conjunctions of atoms whose variables are in ~ and 9 or ~ re- 
spectively. EE is complete for the class of S-formulas [15]. Notice that they are 
closed formulas (no free variable). Therefore EE is aimed at proving and not at 
computing answers, at the contrary of SLDNF. A derivation step in EE involves 
unfolding or simplification over literals occurring in the goal. 
In EEa the class of S-formulas is extended to any first-order (closed) formula. 2 
The main novelty is the acceptance of queries such as 3x-~p(x) for which we need 
1 [9] and [7] provide a deep survey and a comparison between several proposals. 
In general, a normal clause is not an S-formula. 

155 
to refer explicitly to the definitions of the completion and therefore to handle 
the equality relation. The unfolding is now performed by using the it definitions 
of the predicates. 
The paper is organized as follows: In section 2 we introduce some notation 
and recall some basic definitions. In section 3 we informally describe EEG and 
give an intuition of the use of its rules by an example. Sections 4, 5 and 6 are 
devoted to a formal description of each rule. In section 7 we show the soundness 
of EEa, while its completeness is studied in section 8. Section 9 provides two ex- 
tensive examples. Finally, section 10 is devoted to a discussion and a comparison 
with related works. 
2 
Preliminaries 
For the notations, we choose the following conventions. We will use lower case 
letters possibly indiced and primed to denote individual objects: x, y for vari- 
ables, t, u for terms, p, q, r for predicate symbols, a, b, of for function symbols, a, 
0 for substitutions. Upper case letters will be preferred for collection of objects: 
P for programs, G, F, W, D, Q, E, L for first-order formulas. These symbols may 
also be overlined in order to denote a sequence: ~ denotes a sequence of distinct 
variables, t a sequence of terms (not necessarily distinct), t = ~ will stand for 
A~=l(ti = ui) when t = (tl,..,,tn) and ~ = (ul,...,un). 
~.~ will denote the 
concatenation of 9 and y. vats(F) will denote the sequence of free variables 
occurring in a term or a formula F. 
A replacement of one (resp. every) occurrence of F1 by F.2 in G will be 
denoted by G[FI +- F2] (resp. G(FI +- F2)). A replacement of every occurrence 
of a variable x in G by a term t will be denoted by G(x ~-- t). 
An atom has the form p(t). A//term is an atom (positive//terM) or a negated 
atom --,p(~) (negative literal). 
A normal clause has the form p(~) ~-- W where W is a conjunction of liter- 
als. When W is a conjunction of atoms then the clause is a definite clause. A 
normM program (resp. detinite program) P is a finite set of normal (resp. def- 
inite) clauses, l%om now on the qualifier 'normal' will be omitted, unless some 
confusion arises. 
The polarity of a subformula is defined as usual: A subformula F has a 
positive polarity (resp. negative polarity) in G (or F is a positive subformula 
(resp. negative subformula) of G) when F appears in G within an even number 
of negation (explicitly, or implicitly in the left-hand-side of an implication). 
The scope of a quantifier Vx (resp. 3x) in a formula VxF (resp. 3xF) is F. 
A substitution a is a function from variables to terms with a finite domain. 
Its domain will be denoted dora(a), a(xl) will denote the image of zl by a. 
Let {xl,...,x,,} be the domain of a, then the range of a is the set of terms 
{a(xl),..., aCx,)}. 
P* will denote Clark's completion [5] of a program. It consists of the set of 
the it definitions of every relation occurring in P and the CET (Clark's Equality 

156 
Theory). 3 If ~ 
(p(~) ~ defp(~)) is the iff definition of a predicate p then the 
completed definition of atom p(~) is the formula defp(~) in which ~ replaces 5. 
3 
General 
description 
of EEG 
3.1 
Normal goals 
The formula ~ to be proved is assumed to be initially a normal goal G: 
Definition 1 normal goal. A normal goal G is a closed formula (no free vari- 
able) that can be generated by the following grammar: 
G::=QIE 
Q ::=QAQ I V~EIL 
E::-EvE 
I 3yQIL 
L ::-p(~) I "~P(u) I t-- u I t ~t u I true I false 
where t ~t u stands for -~t = u. Moreover we assume that a variable occurs 
exactly once in a quantification. 
Example1. Vx (3yl p(x, yl) V 3y2 q(x, yz)) is a normal goal. It is not the case 
of the equivalent formula Vx (3y p(x, y) V 3y q(x, y)) in which 3y occurs twice. 
Vx (p(x, y) V qy q(x, y)) is not a normal goal since it is not a closed formula (the 
first occurrence of y is free). 
The following lemmas are immediate from definition 1. 
Lemma 2. Every closed first-order formula is equivalent to a normal goal. This 
normal goal is not unique. 
Proof: It can be easily verified by firstly converting the formula into an equiv- 
alent prenex normal form. The non uniqueness is illustrated by the two logi- 
cally equivalent normal goals Vx(3y (p(x) A q(y)) V r(x)) and Vx (p(x) V r(x)) A 
w'( y q(y) v r(=')). 
Lemma 3. A variable in a normal goal occurs only in the scope of its quantifi- 
cation. 
Lemma 4. F is a negative subformula of a normal goal G iff it is a negated 
atom p(~). 
3 See [26] for a deep survey on the CET and the results related to its completeness 
and decidability. 

157 
3.2 
Derivation 
and derivation step 
EEG consists mainly of the Rephcement and the Simplitication rules. A suc- 
cessful proof in EEG is a sequence of derivation steps that derives a normal goal 
G into true. A derivation step replaces a normal goal Gi by a new one Gi+l. 
Gi+l is produced from Gi by an application of the Replacement or the Simpli- 
fication rule and a normalization process. More precisely, an application of one 
of the two rules yields an intermediary formula which is immediatdy subject to 
normalization. Gi+l is the normalized form of the intermediary formula. 
3.3 
An example 
The following program {r(a). r(b) ~ r(b). r(b) ~ q(a). q(a) ~ q(a).} was first 
given in [1]. Its completion P* consists of the two axioms: 
w 
(r(=) ~ 
= = a V (~ = b ^ r(b)) V (= = b ^ q(a))) 
Vx (q(x)~ 
x=a 
A q(a)) 
Let G0 be Bx(r(x) A -~q(x)). Then we have P* ~ Go. Actually, it is easy to 
see that P* ~ r(a) and P* ~ -~q(b). Then, in any (two-valued) model of P*, 
q(a) is always true or false. If it is true so must be r(b) and then r(b) A -~q(b) 
is true. If it is false then r(a) A -~q(a) is true. Finally, either (r(a) ^ -~q(a)) or 
(r(b) ^ -~q(b)) is true in any model of P*. 
Nevertheless, there is no successful SLDNF-derivation for the goal r(x) A 
-~q(x). 4 EEG for its part, provides a proof for G0. s It is summarized in the 
following proof tree: 
Go: ~= (,(~) A-q(=)) 
q--- 
Replacement of r(z) and normalization 
I 
-.q(a)Vr(b)Vq(a) ^ -~q(a)Vr(b)V'.q(b) ^ "~q(a)V'.q(b)Vq(a) ^ -.q(a)V-.q(b)V-.q(b) 
~0 
G20 
G30 
G40 
The replacement of r(x) by its completed definition yields the formula 3x((x = 
aV (x = bAr(b))V (x = bAq(a)))A-~q(x)). It is transformed during normalization 
by distributivity of connectors and elimination of equalities. The conjunction of 
Glo, G20, Gao and G40 is the result of the normalization. The proof is now di- 
vided into four subproofs. Gio and G30 can be derived into true by applying a 
simplification between "~q(a) and q(a). G20 and G40 can be derived into true by 
a replacement of q(b) (its completed definition is equivalent to false). 
4 That is why this example is used in [1] to illustrate the incompleteness of SLDNF 
even in the case of a definite program and a non floundering goal. 
The inability of SLDNF to provide a successful derivation for (r(z) A -~q(z)) comes 
from its attempt to instantiate z. This problem is avoided by EEa since it is not 
aimed at computing answer substitutions to queries (they all axe closed formulas). 

158 
Remark: Although P is a definite program, this proof cannot be performed by 
EE. The query 3x (r(x) A -~q(x)) is not an S-formula. 
The following three sections aim at a formal description of the rules involved 
in EEa. 
4 
The Replacement 
rule 
Definition 5 the Replacement rule. Let G be a normal goal and p(~) an 
atom in G. An application of the Replacement rule to G and p(~) yields: 
F] 
where F is the completed definition of p(~). The variables of F that do not occur 
in p(~) must be introduced in G as new fresh variables. 
Remark: The replacement of p(~) can be seen as an unfolding using the iff 
definition of predicate p. This point of view is adopted by Sato in [24]. 
Lemma 6 Correctness of the Replacement rule. If G2 is a formula pro- 
duced by an application of the Replacement rule to a normal goal G1, then 
P* ~ G1 ~ G2. 
Proof: The proof is obvious since this rule merely replaces an atom by its com- 
pleted definition which is by construction of P* an equivalent formula. 
5 
The Simplification 
rule 
We need first the definition of a deciding substitution for a normal goal. Intu- 
itively, this notion is comparable to the 3-introduction rule in natural deduction: 
if Gi+l is the result of applying to Gi a deciding substitution a = {x ~ t}, then 
Gi can be restored from Gi+l by an 3-introduction of variable x for term t. Some 
conditions on the variables involved in a must be stated. 
5.1 
Deciding substitution 
Definition 7 deciding substitution. Let G be a normal goal. A substitution 
a is a deciding substitution for G if the following holds: 
1. every variable in dora(a) is existentially quantified in G, 
2. for every variable x in dam(a) and every variable y in a(x), then y is uni- 
versally quantified in G and 3x is in the scope of Vy. 
Definition 8 deciding substitution instance. Let G be a normal goal and 
a be a deciding substitution for G. Then the instance of G by ~ is obtained by 
replacing every occurrence of xi in dam(a) by a(xi) and by removing all the 
quantifiers 3xl. It is denoted Ga. 
Note that the empty substitution is a (trivial) deciding substitution. 

159 
Example P. cr = {Yl ~ x ; Y2 ~-- f(x, x)) is a deciding substitution for G = 
Vx Syl.y2 (p(x, yl) A q(x, y2)) and Gq is Vx (p(x,x) A q(x,f(x,x))). 
= {x ~-- y} is not a deciding substitution for G ~ = 3xVy p(x, y) since y lies in 
the scope of 3x. 
Lemmag. If G~ is a deciding substitution instance for G then P* ~ G if 
P* ~ G~. 
Proof: It follows from the validity of the q-introduction rule in natural de- 
duction. Stronger conditions on the variables involved in the substitution are 
required here in order to preserve, after instantiation, the property of bindings 
stated by the definition of a normal goal. 
Lemma 10. A deciding substitution instance of a normal goal is a normal goal. 
Proof." Got is G in which some variables have been replaced by terms and some 
irrelevant quantifiers have been removed. By definition ~ ensures that every vari- 
able in the range of ~ will appear in Gcr in the scope of its quantification. Notice 
that in example 2, Gcr is a normal goal with an empty sequence of existential 
variables. Such normal goals will be splitted during the normalization process 
(see the renaming rules in section 6.1). 
5.2 
The simplification rule 
Definition 11 the Simplification rule. Let G be a normal goal. Let P(~I) 
and -~P(U2) be respectively a positive and a negative literal s in G such that 
p(~l) and p(~2) are both unifiable to p(~) 
by a deciding substitution a for 
G. Then an application of the Simplification rule to G, p(~l) and P(~2) with ~r 
yields two new goals G1 and G2, where G1 and G2 are obtained by replacing in 
G~r every occurrence of p(~) by true and false respectively, i.e.: 
al: 
true) 
G2 : (C~)(p(Ct) 4-- false) 
Lemma 12. Let G be a normal goal and L be a literal in G. Then it exists in 
G a subformula F such that F contains all the occurrences of L in G and such 
that every variable in L is free in F. 
Proof: Let xx,..., x,~ be the n variables occurring in L. By lemma 3, for every 
quantifier Qi, where Qi stands for 3xi or Vxl with i E [1..n], it exists a subformula 
QiFi such that Fi contains all the occurrences of xi in G, and consequently, all 
the occurrences of p(~). It follows that for all i and j (i # j), either Qi occurs in 
Fj or Q~ occurs in Fi. Hence, it exists a k (k E [1..n]) and a subformula QkFk 
such that Fk contains all the occurrences of L and no occurrence of a Qi (for 
i E [1..n]), i.e. such that every variable in L is free in Fk. Finally F is Fk. 
We give here a simple formulation of the rule in the case where only two literals are 
selected. 

160 
Lemma 13. Let (Ga)(p(~) ~- true) and (Ga)Cp(~) ~-- false) be the two formu- 
las produced by an application of the Simplification rule to a normal goal G. Let 
F be a subformula of Ga such that F contains all the occurrences of p(~) and 
such that every variable of p(~) is free in F. Then: 
P* 
G [F ,- 
v F)] if P* 
G,,[F ,- FCp( ) ,-- true)], and 
P* ~ GafF ~ (p(~) V F)] if P* ~ GafF ~- F(p(~) *-- false)] 
Proof: Firstly, the existence of F is ensured by lemma 12. We prove the first 
part of the lemma. By hypothesis P* ~ GafF ~ F(p(~) ~ true)]. F is equiva- 
lent to a conjunctive prenex form ~) (AiDi) where Di are disjunctions of literals 
and Q) is a vector of quantifiers. Hence GafF ~ f(p(~) *-- true)] is equivalent 
to 
Gaff ~ 
Q (^i Di)(p(~) ~ true)], i.e. to Gaff ~-- Q (^i(Di (p(~) ~-- true)))] 
The validity of this last formula implies the validity of GafF +- Q (--p(~) v 
(^i (Di(p(~) ~-- true))))] (because F is a positive subformula of Ga by lemma 4) 
which is equivalent (by de Morgan's laws) to: 
--t 
GafF ~-- O 
Ai (-~p(~) V Di(p(~) +-- true))] 
(i) 
For all i, 
1. ifp(~) is a positive literal of Di then -~p(~) VDi(p(~) ~-- true) and --p(~) YDi 
are both equivalent to true. 
2. otherwise, ifp(~) is a negated atom in Di then --p(~) Y Di(p(~) ~-- true) is 
also equivalent to -~p(~) V Di. 
3. otherwise -,p(~) V Di(p(~) ~-- true) is trivially equivalent to --p(~) v Di. 
Since the property holds for all i it follows from (1) the formula GafF e-- Q ^~ 
(--p(~) y Di)] which is equivalent by de Morgan's laws to 
Gaff ~ q (--p(~) V (^i Di))] 
(2) 
Finally, because no variable in p(~) occurs in Q, it follows from (2) the formula 
Gaff ~-- (-~p(~) V Q (^i Di))], i.e. GafF ~-- (-,p(~) V F)l Hence, from the 
hypothesis we have inferred P* ~ GafF ~-- (--p(W) V F)]. 
Lemma 14 Correctness of the Simplification rule. If G1 and G2 are two 
formulas produced by an application of the Simplification rule to a normal goal 
G, then P* ~ G if P* ~ ax and P* ~ G2. 
Proof: Let G1 and G2 be Ga(p(~) e-- true) and Ga(p(~) ~ false) respectively. 
By hypothesis, P* ~ G1 and P* ~ G2. Let F be a subformula in Ga defined 
as in lemma 12. Then by lemma 13, and because G1 and G2 are equivalent to 
GafF ~ F(p(~) ~ true)] and GafF ~ F(p(~) ~ false)] respectively, we get 
P* ~ Gaff ~-- F V --p(~)] and P* ~ Gaff ~-- F V p(~)]. It follows from these 
two statements that P* ~ Gaff ~-- (F Vp(~))^ (F V-~p(~))]. Finally, because 
(F Vp(~)) A (F V --p(~)) is equivalent to F, we get P* ~ Ga. Hence P* ~ C 
(by lemma 9). 

161 
6 
The normalization 
rules 
The normalization process involves the rewrite, the equality-decomposition and 
the equality-elimination rules which apply to the subterms of a formula. Rules 
are given in their general form, i.e. we assume that F~ may also be empty. An 
empty conjunction and an empty disjunction are the boolean constants true and 
false respectively. 
6.1 
The rewrite rules 
We omit here the rules for boolean simplification, for distributivity of negation 
over ^ and V and for elimination of irrelevant quantification. The well-known de 
Morgan's laws are applied in a particular context to ensure the termination of 
the normalization. 
de Morgan's laws 
FI V (GI ^ G2) V F2 
, (FI V GI V F2) ^ (FIv G2 V F2) 
37 (FI ^ (al v G2) a F2) ~ 
37 (F~ a GI ^ F2) v 3~ (F~ ^ G2 ^ F2) 
where ~ is a proper renaming of the variables 9 in FI, G2 and F2. 
renaming 
W(F~ ^ F2) 
, V-~F~ ^ VyF2 
3~(FI v F2) 
,3~F~ v 3~F2 
where ~ is a proper renaming of the non empty 9 in F2. 
(V-widening) and (3-widening) 
if y N (vats(F1) U vats(F2)) = r 
F1 VV~ G y F2) ---* V~ (F1 Y G v F2) 
FI ^ 3y G ^ F2 ---, ~y ( F~ ^ G ^ F2) 
Lemma15 Correctness of the rewrite rules. If G.2 is a formula obtained 
from G1 by any sequence of applications of the rewrite rules, then ~ G1 *-* G2. 
Proof: The whole rewrite rules preserve, in every model, the equivalence be- 
tween formulas. They correspond to well-known theorems of predicate logic [27]. 
6.2 
The equality-decomposition rule 
It is aimed at transforming an equality among two terms u and v into an equiv- 
alent conjunction of the form Ai(xi ---- tl) where ti is a term and xl is a variable 
not occurring in ti. This can be done by using the Solved Form Algorithm given 
in [19]. 
An application of the equality-decomposition rule to a formula G consists of: 
1. a selection in G of an equality u ----- v (resp. a disequality u ~ v) 
2. an application of the Solved form algorithm to {u = v} 
3. a replacement in G of the equality u = v (resp. the disequality u ~ v) by: 
- false (resp. true) when failure has been returned. 
- Ai(xi = ti) (resp. Vi(x~ ~ ti)) otherwise. 

162 
Lemma 16 Correctness of the equality-decomposition 
rule. If G2 is a for- 
mula produced by any sequence of applications of the equality-decomposition rule 
to G1, then CET ~ G1 *'* G~. 
Proof." The correctness (and termination) of the Solved form algorithm is proved 
in [19] (Theorem 3.1). It follows that an application of the equality-decomposition 
rule merely replaces in G an equality by an equivalent formula in CET. 
6.3 
The equality-elimination rules 
They are aimed at removing in simple cases an occurrence of the equality symbol. 
V~ (F1 v x' # t v F2) ~ 
W~ ((Fx V F2)(x' ~ t)) 
3~ (F1 ^ x' = t ^ F2) ----* 3~ ((Fx ^ F2)(x' ~ t)) 
where x' occurs in 9 and not in t. 
In particular, in the case of definite programs and S-formulas, an application 
of the above rules after a replacement will remove all the equality symbols, such 
that the resulting formula coincides with the one that would have been produced 
by the rules of EE (see section 8). 
They are also useful since they can lead to further normalization steps or 
make practical the application of the Simplification rule. 
Lemma 17 Correctness of the equality-elimination rule. If G2 is a for- 
mula produced by any sequence of applications of the equality-elimlnation rules 
to Gx, then CET ~ Gi *-* G2. 
Proof." See [27]. 
7 
Soundness 
of EEG 
Lemma 18 Conservation of the normal form of goals. Let F be a formula 
produced by an application of the Replacement or the Simplification rule to a 
normal goal G1. Then an exhaustive application of the rewrite rules, the equality 
decomposition and elimination rules enables the derivation of F into an equiv- 
alent stable formula G2 to which none of the rules is applicable, and G2 is a 
normal goal. 
Corollary 19. A derivation step preserves the normal form of a goal. 
Proof." We describe the form of the intermediary formula F. Following the cases: 
- F is obtained from G1 by a Simplification with a deciding substitution a. Gla 
is a normal goal by lemma 10. F is a conjunction of F1 and F2 respectively 
produced by replacing in Gla some atoms by true and by false. Hence, F1 
and F2 are also normal goals. 

163 
- F is obtained from G1 by a Replacement. Then F is G1 in which an atom 
p(~) is replaced by a formula of the form 3~(t = g^ W) where ~ = vars(t) u 
vats(W) is a sequence of fresh variables and W is a conjunction of literals. 
Hence F is also a closed formula in which every variable occurs in the scope 
of its quantification. 
* if p(~) occurs positively in G1 in a disjunction, then F is also a normal 
goal: this case is immediate when considering the grammar of the defi- 
nition 1. If y is empty then the first de Morgan's law (cf. subsection 6.1) 
is applicable and it yields another normal goal (or a conjunction of two 
normal goals). 
* if p(~) occurs positively in G1 in a conjunction then the 3-widening rule 
(cf. subsection 6.1) turns F into a normal goal. 
9 if p(~) occurs negatively in G1 in a conjunction then F is turned into a 
normal goal by distributivity of -1 (the rule for negation are not described 
in subsection 6.1). If y is empty then the second de Morgan's law is also 
applicable. The two rules can be applied in any order and yield a normal 
goal. 
* if p(~) occurs negatively in Gt in a disjunction, then F is turned into a 
normal goal G2 by distributivity of -, and the V-widening rule if ~ is not 
empty. 
Finally it is easy to verify that the normalization process always terminates 
(notice that when a conjunction of goals is produced at the higher level, the 
two goals are considered separately in two subproofs, i.e. the second de Mor- 
gan's law is not applicable to this conjunction) and that the whole rewrite rules, 
the equality-decomposition rule and the equality-elimination rules preserve the 
form of normal goals and do not violate the property of variables binding. The 
equivalence between F and G2 is ensured by lemmas 15, 16 and 17. 
Remark: The conservation of the uniqueness of variable bindings is crucial re- 
garding the validity of an EEG proof. Actually a simplification on Vxp(x) v 
Vx-~p(x) would be possible and would derive true. It is not the case for the 
normal goal Vxp(x) Y Vy-~p(y). 
Theorem 20 Soundness of EEG. Let G be a normal goal. If there exists a 
finite sequence of derivation steps that derives G into true then G is a logical 
consequence o[ P*, i.e. P* ~ G. 
Proof." The proof follows from the lemmas 6, 9, 14, 15, 16, 17 and 18, which 
ensure us that when Gi+l is obtained from Gi in one derivation step, i.e. by an 
application of the Replacement or the Simplification rule and of the normaliza- 
tion process (which involves the rewrite rules, the equality-decomposition rule 
and the equality-elimination rules) then, if P* ~ Gi+l then P* ~ Gi. 

164 
8 
A partial 
completeness 
result 
for EEG 
Indeed in our generalization work, we have to be sure that we do not lose any 
power in comparison with EE. This is the aim of this paragraph. We recall a 
definition for the class of S-formulas. 
Definition 21 (S-]ormula). An S-formula is any dosed first-order formula which 
can be written into the following normal goal: 
W (F~ v ... v F~_~ v3y~ F~ v... v 3y~ F=) 
where Fj is a conjunction of literals (resp. atoms) when j E [1..i- 1] (resp. 
j 9 [i..n]). 
Theorem 22. Let P be a definite program and G be a normal goal in the class of 
S-formulas. Then if G is a logical consequence of P*, EEG provides a successful 
derivation for G. 
Proof.- This result is obtained for the rules of EE and the proof is given in 
[15]. Hence it amounts for us to verify that every derivation in EE can also be 
achieved by EEG. We just give here the idea of the proof which actually does 
not present any difficulty but would require the description of each rule of EE. 
Let us just describe the case where the dci rule (unfolding) is applied. Let p(~) 
be the selected atom in a goal G : V-~ (F1 V 3~ (F2 A p(~) A F3) V F4), with p 
defined in P by the clauses {p(tl) ~-- Wi}i and let Yi be the variables occurring 
in ti or Wi. Let p(t~) ~-- Wk be the selected clause for the dci and a be the 
corresponding deciding substitution. Then G leads to G' : (G[p(~) *- Wk])~ i.e. 
to w (F1 v 3~.y~ (F2 ^Wk n F3), v F4), i.e. to V-~ (F1 v 3~.Yk (F2 ^Wk ^F3 ^~ = 
uk) V F4) 9 In EEG, a replacement of the same atom p(~) produces, after nor- 
realization, C" : W (F~ v F' V ~.y~ (F~ ^ Wk ^ F3 ^ ~ = ~k) v F" v F4) for 
some F' and F" possibly empty. Finally every successful derivation for G' in EE 
clearly also holds for G'. 
The verification for an application of the rule nfi follows the same arguments: 
this time the two goals G ~ and G" are exactly the same. 
The verification for an application of the simplification rule is immediate since 
our definition of this rule is the same than the definition given for EE. It amounts 
to verify that the difference between the two definitions of a deciding substitu- 
tion is not relevant when the substitution is involved in a simplification, i.e. that 
every deciding substitution used in a simplification in EE is also a deciding sub- 
stitution following our definition 7. This holds because a simplification requires 
the selection of at least one negative literal which by definition of an S-formula 
cannot contain any occurrence of a variable quantified by 3x. Hence no new 
variable can be introduced in a goal by a simplification. 
Finally we verify that the rules aimed at normalizing the goals in the two frame- 
works coincide. 
Remark: We must point out that the symbol of implication is allowed in EE 
in the syntax of goals and an advantage is that the formulas are kept in a form 

165 
which emphasizes an intuition of their meaning. This is not the case at present 
time in EEG because at right stage it simplifies the formulation of the rules and 
their proofs. However it must be considered as a possible improvement of our 
technique. 
9 
Examples 
9.1 
First example 
We borrow from [8] the following program, where the relation of list inclusion is 
defined by means of the negation of non inclusion. 
ninclud(Ix, /2) *-- elem(e, tl) A -~elem(e, 12) 
We prove the formula Vl~1213 (includ(l~,12) ^ includ(12,13) ---} includ(lx,13)) 
aimed at expressing the transitivity of the list inclusion. Notice that the proof 
is performed with no use of a definition for elem. 
A possible proof is summarized by the tree below where each node is labelled 
by a goal. When G yields a conjunction of n goals G~ then the node for G has n 
sons, each of them is labelled by some G~. Moreover the normalization process 
is implicitly applied at each derivation step (in the first four derivation steps it 
produces no effect). When a simplification is applied, a is the associated deciding 
substitution. 
Vtll213(-.ina~(ll, 12) v ~i.a~(12, t3) v incl~d(ll, 13) ) 
I replacement 
u 
12) V -~includ(12,13) V includ(ll, lz)) 
replacement 
u 
12) V ninclud(12, 13) V includ(l~ , lz) ) 
replacement 
Vill2lz(ninclud(ll, 12) V ninelud(12, 13) V -~ninelud(ll , lz) ) 
replacement 
Vlxl2t~Oe(elem(e, l~) ^ -~elem(e, l~)) V ni,~d~(l~, l~) V ~,~incl~(l~, t~)) 
replacement 
u 
l~) ^ -,elem(e, 12)) V ninclud(12,13) v -~elem(e', h) v elera(e', 13)) 
Vl21ze'('~elem(e', 12) V ninelud(12, {,3) V elern(e', lz)) 
true 
o" = {e ~ e'} 
replacement 
Vl,lne'(-,elem(e', l~) V 3e(elem(e, 12) ^ -,elem(e, 13)) V elem(e', l~)) 
Vl3e'(-,elem(e', l~)V ele..m(e', l~)) 
true 
a = {e ~ e'} 
true 
true 
a -- {} 

166 
9.2 
Second example 
Let P be the following program: 
int(o) .- 
even(O) .-- 
o~(,(x)) .-- evenCx) 
~nt(~(x)) .-- ~nt(x) 
even(~(x)) .-- -~even(x) 
and G be the formula Vx (int(x) -* even(x) v odd(x)) which expresses a partial 
specification of integers. Then G can be easily derived into true by replacements 
and a simplification. 
Now let us suggest an interesting perspective of complementarity with our 
technique and the proof method introduced by Deransart and Ferrand in [8] 
which is aimed at proving properties of atoms in the well-founded model [14]. 
For instance to prove that every ground atom int(~) in the denotation verifies the 
property to be always an even or an odd number, we can prove the validity (see 
[8]) of the (partial) spedfication S ~'~t = even(x) V odd(x). Following [8] a speci- 
fication is valid if assuming that the property holds for the body of a (ground) 
clause, it holds also for the head. This amounts to prove that the following two 
statements hold (notice the similarity with computational induction): 
even(0) V odd(0) 
Vx (even(x) V odd(x) -~ even(s(x)) V odd(8(x))) 
A possibility to prove that these formulas are valid and therefore to complete 
the proof of the validity of S i'~t is to use EEG. EEG ensures us of the validity of 
these formulas in every model of the completion and therefore in the well-founded 
model (which is total since P is locally stratified [14]). 
10 
Discussion and related works 
Our approach of proving properties of a program P is addressed with respect to 
Clark's completion semantics which is the standard approach for a declarative 
meaning of negation in logic programming. However it is well-known that the 
completion is not always consistent and therefore the problem of the complete- 
ness of a procedural counterpart for this semantics must be studied for special 
classes of programs [6]. 
An alternative is to move into Klenee's three-valued logic [11, 17]. It provides 
a weaker semantics (every two-valued model is a three-valued one) which ensures 
the consistency of the (three-valued) completion and which allows to extend the 
completeness result of SLDNF resolution to a wider class of programs [18]. Many 
recent works propose solutions to overcome the limitations of SLDNF due to the 
floundering problem [21] which is a major obstacle to its completeness. 7 Most 
of these works are strongly related to the completion even if the completion is 
not used explicitly in the proof procedure [4, 2, 25]. In [10] another view based 
on failed (SLDFA)-trees is preferred. All these techniques are proved sound and 
complete w.r.t, the three-valued completion. 
It is not the unique one. As it is shown in section 3.3 the problem with excluded 
middle remains. 

167 
Regarding mechanical verification of programs, the choice of a three-valued 
semantics, because of its weakness is not in our opinion a relevant approach. For 
example none of the properties proved in the examples of section 9 are three- 
valued consequences of the completion. It is also the case for the goal of the 
example in section 3.3. s 
The crucial distinction of our framework compared to the above mentioned 
ones lies in the existence of the Simplification rule (which relates to the excluding 
middle) and which is very useful in practice. That is why, regarding practical 
matters in mechanical verification, we believe it is better to deal with a two- 
valued semantics. 
Nevertheless even in a two-valued setting, it is a fact that a semantics based 
on the completion may be too restrictive since it is a strong requirement to be 
true in every model of the completion. A possible approach would be to consider 
some special classes of models of P* expected to fit better the intended meaning 
of P. 
In [10], Drabent defines SLSFA-resolution, an adaptation of SLDFA for the 
well-founded semantics [14]. 9 He proves the completeness of SLSFA for atomic 
queries which is naturally extended to normal queries. However the properties 
considered in section 9 are not normal goals and the techniques of [10] do not 
apply. 
In [20], Lever addresses the problem of proving properties of (locally strati- 
fied) logic programs by means of SLS-resolution which is the procedural counter- 
part of the Perfect Model Semantics (Przymusinski [22]). However his method 
is limited because of the floundering problem, i.e. SLS-trees under consideration 
must be unfloundered. As a consequence the property of example 9.1 cannot be 
handled by his techniques since the construction of an SLS-tree from the denial 
r includ(lx, 12) A includ(ll,12) A -~includ(ll, 13) leads to the floundering denial 
r 
-minclud(ll, 12) ^ -~ninclud(lx, 12) ^ -~includ(ll, 13). It is still the case when 
we use an extension of SLS-resolution, as is proposed by Przymusinski in [23], 
namely SLSC-resolution (SLS-resolution with Constructive negation), despite of 
a refinement in the definition of floundering. For its part, the example of sec- 
tion 3.3 can neither be handled since it is not an implicative property acceptable 
in his framework. Notice that it is always the case when we use an extension of 
SLS-resolution, as is proposed by Przymusinski in [23], namely SLSC-resolution 
s This can be verified by iterating Fitting's operator #p. Kunen in [18] shows the 
result that for any sentence it is equivalent to be true in every three-valued model 
of the completion and to be true in #~, T "~ for a finite n. In example 9.2 the expected 
property Vx (int(x) ~ even(x)x/odd(x)) is true at stage w+l only (more precisely it 
is the negation of this formula that turns to false at this stage and the least fixpoint 
of #p is obtained at stage w+2). It is still undefined in 4fp ]~ and consequently it is 
not a three-valued consequence of the completion. In the example of section 3.3 the 
query that is proved is not even in the least fixpoint of ~e. 
9 The well-founded semantics is a three-valued semantics but the class of programs 
possessing a total (two-valued) model properly includes the classes of stratified and 
locally stratitled programs. 

168 
(SLS-resolution with Constructive negation), despite of a refinement in the def- 
inition of floundering. 
11 
Conclusion 
We have presented a method aimed at proving logical consequences of the com- 
pletion of normal programs. This is a significant extension of the framework 
introduced by Kanamori and Seki [16] for definite programs. It is essentially 
based on an unfolding rule with the iff definitions of the completion and a sim- 
plification rule which operates over opposite literals in a goal. 
Through some examples, this resulting enriched framework has been shown 
to be an interesting contribution in program verification. Its first prototyping is 
currently under improvement. It must be seen as a tool for the stepwise checking 
of correctness. More generally, it provides a better understanding of a program 
and its semantics. It can be naturally applied to the field of program equivalence. 
Section 9.2 gives some perspective of incorporating induction rules in EEa. Its 
application to the field of program synthesis has already been investigated for 
definite programs in [12, 13, 3]. 
12 
Acknowledgments 
I would like to thank Mikhail Boulyonkov and anonymous referees for helpful 
comments. I am grateful to Pierre Deransart, Gerard Ferrand and Laurent Fri- 
bourg for valuable discussions and axivices. 
References 
1. K. Apt. Introduction to Logic Programming. In J. Van Leeuven, editor, Handbook 
of Theoretical Computer Science. North Holland, 1990. 
2. A. Bottoni and G.Levi. Computing in the Completion. In Atti dell Ottavo Con- 
vegno sulla Prograrnmazione Logica (Gulp), pages 375-389. Mediterranean Press, 
1993. 
3. A. Bouverot. Comparaison entre la transformation et l'extraction de programmes 
logiqucs. PhD thesis, Universit$ Paris VII, 1991. 
4. P. Bruscoli, F. Levi, G. Levi, and M. C. Meo. Intensional Negation in Constraint 
Logic Programs. 
In Atti dell Ottavo Convegno sulla Programrnazione Logica 
(Gulp}, pages 359-373. Mediterranean Press, 1993. 
5. K. L. Clark. Negation as Failure. In H. Gallaire and J. Minker, editors, Logic and 
Databases, pages 293-322. Plenum Press, New York, 1978. 
6. A. Cortesi and G. Fil~. Graph Properties for Normal Programs. Theoretical Com- 
puter Science, 107:277-303, 1993. 
7. P. Dermasart. Proof Methods of Declarative Properties of Definite Programs. The- 
oretical Computer Science, 118:99-166, 1993. 
8. P. Deransart and G. Ferrand. Proof Method of Partial Correctness and Weak 
Completeness for Normal Logic Programs. Journal of Logic Pragramming, 17:265- 
278, 1993. 

169 
9. Y. Deville. A Correctness Definition for Logic Programming. Technical Report 
RP 88/8, Namur University, 1988. 
10. W. Drabent. What is Failure? An Approach to Constructive Negation. Tech- 
nical Report LITH-IDA-R-91-23, Linkoping University, 1993. to appeax in Acta 
Informatica. 
11. M. Fitting. A Kripke-Kleene Semantics for Logic Programs. Journal of Logic 
Programming, 2:295-312, 1985. 
12. L. Fribourg. Extracting Logic Programs from Proofs that Use Extended Prolog 
Execution and Induction. In Proceedings of the Seventh Int. Conference on Logic 
Programming, Jerusalem, pages 685-699, 1990. 
13. L. Fribourg. Generating Simplification Lemmas using Extended Prolog Execution 
and Proof-Extraction. In Proceedings of the Int. Logic Programming Symposium, 
San Diego, 1991. 
14. A. Van Gelder, K. A. Ross, and J. S. Schlipf. The well-founded semantics for 
general logic programs. Journal of the ACM, 38(3):620-650, 1991. 
15. T. Kanamori. Soundness and Completeness of Extended Execution for Proving 
Properties of Prolog Programs. Technical Report TR-175, ICOT, 1986. 
16. T. Kanamori and H. Seki. Verification of Logic Programs Using an Extension of 
Execution. In Proceedings of the Third International Conference on Logic Pro- 
gramming, London, pages 475-489, 1986. 
17. K. Kunen. Negation in Logic Programming. Journal of Logic Programming, 4:289- 
308, 1987. 
18. K. Kunen. Signed Data Dependencies in Logic Programs. Journal of Logic Pro- 
gramming, 7:231-245, 1989. 
19. J. L. Lassez, M. J. Maher, and K. G. Marriott. Unification Revisited. In J. Minker, 
editor, Foundations of Deductive Databases and Logic Programming, pages 587- 
625. Morgan Kaufmann, Los Alto, Ca., 1988. 
20. J. M. Lever. Proving Program Properties by means of SLS-resolution. In Proceed- 
ings of the Eight Int. Conference on Logic Programming, Paris, pages 614-628, 
1991. 
21. J. Lloyd. Foundations of Logic Programming. Springer-Verlag, Berlin, 1987. 
22. T. C. Przymusinski. Perfect Model Semantics. In R. Kowalski and K. Bowen 
editors, editors, Proceedings of the Fifth Int. Logic Programming Symposium, pages 
1081-1096. Association for Logic Programing, 1988. 
23. T. C. Przymusinski. On Constructive Negation in Logic Programming. Technical 
report, University of Texas at El Paso, 1990. 
24. T. Sato. Equivalence-preserving first order unfold/fold transformation systems. 
Theoretical Computer Science, 105:57-84, 1992. 
25. T. Sato and F. Motoyoshi. A Complete Top-down Interpreter for First Order 
Programs. In Proceedings of the Int. Logic Programming Symposium, San Diego, 
pages 35-53. MIT Press, 1991. 
26. J. C. Shepherdson. Language and Equality Theory in Logic Programming. Tech- 
nical Report PM-88-08, University of Bristol, 1988. 
27. D. van Dales. Logic and Structure. Springer Verlag, Berlin, second edition, 1987. 

Partial Deduction of Disjunctive Logic 
Programs: A Declarative Approach 
Chiaki Sakama 1 and Hirohisa Seki 2 
1 ASTEM Research Institute of Kyoto 
17 Chudoji Minami-machi, Shimogyo, Kyoto 600 Japan 
sakama@astem, or. jp 
2 Department of Artificial Intelligence and Computer Science 
Nagoya Institute of Technology, Gokiso, Showa-ku, Nagoya 466 Japan 
seki@ics .nitech. ac. jp 
Abstract. This paper presents a partial deduction method for disjunc- 
tive logic programs. We first show that standard partial deduction in 
logic programming is not applicable as it is in the context of disjunctive 
logic programs. Then we introduce a new partial deduction technique for 
disjunctive logic programs, and show that it preserves the minimal model 
semantics of positive disjunctive programs, and the stable model seman- 
tics of normal disjunctive programs. Goal-oriented partial deduction is 
also presented for query optimization. 
1 
Introduction 
Partial deduction or partial evaluation is known as one of the optimization tech- 
niques in logic programming. Given a logic program, partial deduction derives 
a more specific program through performing deduction on a part of the pro- 
gram, while preserving the meaning of the original program. Such a specialized 
program is usually more efficient than the original program when executed. 
Partial deduction in logic programming was firstly introduced by Komorowski 
[Kom81] and has been developed by several researchers from various viewpoints 
(for an introduction and bibliographies, see [Uom92] and [SZ88], for example). 
From semantic points of view, Lloyd and Shepherdson [LS91] formalized partial 
evaluation for normal logic programs and showed its correctness with respect 
to Clark's program completion semantics. On the other hand, Tamaki and Sato 
[TS84] showed that partial deduction preserves the least Herbrand model se- 
mantics of definite logic programs in the context of unfold/fold transformation. 
The result is extended by Seki to the perfect model semantics for stratified logic 
programs [Seki91], and the well-founded semantics for normal logic programs 
[Seki93]. 
Recent studies of logic programming extended its framework to include indef- 
inite information in a program. Disjunctive logic programs are such extensions 

171 
of logic programming, which possibly include disjunctive clauses in programs. A 
disjunctive logic program enables us to reason with indefinite information in a 
program, and its growing importance in logic programming and artificial intelli- 
gence is recognized these days. Disjunctive logic programs increase expressiveness 
of logic programming on the one hand, but their computation is generally ex- 
pensive on the other hand. Then optimizations of disjunctive logic programs are 
important issues for practical usage, however, there have been few studies on the 
subject. 
In this paper, we develop partial deduction techniques for disjunctive logic 
programs. We first show that standard partial deduction is not useful in the 
presence of disjunctive information in a program, and introduce new partial 
deduction for disjunctive logic programs. We prove that the proposed partial 
deduction method preserves the minimal model semantics of positive disjunc- 
tive programs, and the disjunctive stable model semantics of normal disjunctive 
programs. 
The rest of this paper is organized as follows. In Section 2, we introduce nota- 
tions of disjunctive logic programs. In Section 3, we present new partial deduction 
for positive disjunctive programs and show its correctness with respect to the 
minimal model semantics. Section 4 extends the result to normal disjunctive pro- 
grams containing negation as failure, and shows that proposed partial deduction 
also works well for the disjunctive stable model semantics. Section 5 discusses 
some connections between normal partial deduction and the proposed one. In 
Section 6, partial deduction techniques are applied to goal-oriented partial de- 
duction for query optimization. Section 7 summarizes the paper and addresses 
future work. 
2 
Disjunctive 
Logic Programs 
A normal disjunctive program is a finite set of clauses of the form: 
At V...V At ~-- B~ A...ABmAnot Bm+~ A...Anot B~ 
(l_>O,n_>m_>O) (1) 
where Ai's and Bj's are atoms and not denotes the negation.as-failure operator. 
The left-hand side of the clause (1) is called the head, while the right-hand 
side of the clause is called the body. The clause (1) is called disjunctive (resp. 
normal ) if I > 1 (resp. I = 1). Else if I = 0 and n r 0, it is called an integrity 
constraint. A normal disjunctive program containing no not is called a positive 
disjunctive program, while a program containing no disjunctive clause is called 
a normal logic program. A normal logic program containing no not is called a 
Horn logic program, and a Horn logic program without integrity constraints is 
called a definite logic program. 

172 
In this paper, when we write A V s ~ F, ~ denotes a disjunction (possibly 
false) in the head, and F denotes a conjunction (possibly true) in the body. 3 
In logic programming, a program is semantically identified with its ground 
program, which is the set of all ground clauses from the program. Then we 
consider ground programs throughout this paper. We also assume without loss 
of generality that a disjunction in the head of a ground clause is already factored, 
that is, each atom in the disjunctive head of a clause is different. 
An interpretation of a program is a subset of the Herbrand base of the pro- 
gram. For a positive disjunctive program P, an interpretation I is called a mini- 
mal model of P if there is no smaller interpretation J satisfying the program. A 
program is consistent if it has a minimal model, otherwise a program is incon- 
sistent. The minimal model semantics [Min82] of a positive disjunctive program 
P is defined as the set of all minimal models of P (denoted by ~4A4p). 
For a normal disjunctive program P, an interpretation I is called a stable 
model of P if I coincides with a minimal model of the positive disjunctive pro- 
gram pI obtained from P as follows: 
pZ = {A1 V ... V At ~- B1 A... A Bm I there is a ground clause of the form (1) 
from P such that {B,~+I,...,B,} AI = 0 }. 
A normal disjunctive program has no, one, or multiple stable models in general. 
A program which has no stable model is called incoherent. 
The disjunctive stable model semantics [Prz91] of a normal disjunctive pro- 
gram P is defined as the set of all stable models of P (denoted by STp). The 
disjunctive stable model semantics coincides with Gelfond and Lifschitz's stable 
model semantics [GL88] in normal logic programs. 
3 
Partial 
Deduction 
of Positive 
Disjunctive 
Programs 
Partial deduction in logic programming is usually defined as unfolding of clauses 
in a program. 4 For a Horn logic program P, partial deduction is formally pre- 
sented as follows. 
Given a Horn clause C from P: 
C: H~---AAF, 
3 When we write a clause as A V Z ~-- F, it does not necessarily mean that A should 
be the leftmost atom in the head of the clause. That is, any two clauses are identified 
modulo the permutation of disjuncts/conjuncts in their heads/bodies. 
4 Partial deduction is also called partial evaluation. However, we prefer to use the term 
partial deduction since partial evaluation often includes non-deductive procedures. 

173 
suppose that C1,..., Ck are all of the clauses in P such that each of which has 
the atom A in its head: 
Ci: A~-Fi 
(l<i<k). 
Then normal partial deduction of P (with respect to C on A) is defined as 
the program 7r~Vc;A}(P) (called a residual program) such that 
rl~C;A}(P) = (P \ {C}) U {C~,...,C~} 
where each C[ is defined as 
C~: H~"-FAI"i. 
When we simply say normal partial deduction of P (written teN(P)), it means 
normal partial deduction of P with respect to any clause on any atom. 
Example 3.1 Let P be the program: 
P={a~---b, 
b.---c, 
b~---a, c~--}. 
Then normal partial deduction of P with respect to a ~-- b on b becomes 
7r~a.._b;b}(P ) ={ a~--c, 
a~--a, 
b~c, 
b*---a, c~}. 
[] 
In the context of unfold/fold transformation of logic programs, Tamaki and 
Sato [TS84] showed that normal partial deduction preserves the least Herbrand 
model semantics of definite logic programs. 
Lemma 3.1 ([TS84]) Let P be a definite logic program and MR be its least 
Herbrand model. Then, for any residual program 7rg(P) of P, Mp = MTrN(p). 
[] 
The result also holds for Horn logic programs, that is, programs containing 
integrity constraints. 
Theorem 3.2 Let P be a Horn logic program and 7rN(P) be any residual pro- 
gram of P. Then MR = MrrN(p). 
Proof: 
By identifying each integrity constraint ~-- G with false ~ G, Mp 
contains false iff M~N(p) contains false. In this case, both programs are incon- 
sistent. Then the result follows from Lemma 3.1. 
[] 

174 
Thus, in what follows we do not take special care for the treatment of in- 
tegrity constraints, that is, they are identified with normal clauses during partial 
deduction as presented above. 
Now we consider partial deduction in disjunctive logic programs. If we con- 
sider to extend normal partial deduction to a program possibly containing dis- 
junctive clauses, however, normal partial deduction does not preserve the mini- 
mal models of the program in general. 
Example 3.2 Let P be the program: 
P={aVb*---, 
a(---d, 
c~---a} 
where A//A4p = {{a, e}, {b}}. On the other hand, 
where A/IA/I~ 
(p) = {{a}, {b}}. 
[] 
The problem is that normal partial deduction of logic programs is defined 
as unfolding between normal clauses. In the above example, however, there is 
the disjunctive clause a V b ~-- containing the atom a in its head, so unfolding 
between c ~- a and a V b ~- would be needed~ 
Then our first task is to extend the normal partial deduction method to the 
one which supplies unfolding for disjunctive clauses. 
Definition 3.1 Let P be a positive disjunctive program and C be a clause in 
P of the form: 
C: S ~--- A A r. 
(2) 
Suppose that C1,..., Ck are all of the clauses in P such that each of which 
includes the atom A in its head: 
Ci : A V Si ~ Fi (l<i<k). 
(3) 
Then disjunctive partial deduction of P (with respect to C on A) is defined 
as the program 7r~C;A}(P ) (called a residual program) such that 
7rl~C;A}(p) = (/9 \ {C}) U {C[,... ,C~} 
where each C~ is defined as 
C~: SV ~Ui ~-- F A Fi, 
(4) 
in which S V Si is factored, t:] 

175 
Disjunctive partial deduction is a natural extension of normal partial deduc- 
tion. In fact, the clause (4) is a resolvent of the clauses (2) and (3). In Horn logic 
programs, disjunctive partial deduction coincides with normM partial deduction. 
Now we show that disjunctive partial deduction preserves the minimal model 
semantics of positive disjunctive programs. We first present a preliminary lemma. 
Lemma 3.3 Let P be a positive disjunctive program and M be its minimal 
model. Then an atom A is in M iff there is a clause C : A V ,U *-- F in P such 
that M \ {A} ~ F and M \ {A} ~= 27. 
Proof: (=r Suppose that for some atom A in M, there is no clause C in P such 
that M \ {A} ~ F and M \ {A} ~= 27. Then, for each clause C, M \ {A} ~= F 
or M \ {A} ~ 27, and hence it holds that M \ {A} ~ F implies M \ {A} ~ S. 
In this case, since M \ {A} satisfies each clause C, it becomes a model of P, 
which contradicts the assumption that M is a minimal model. Hence the result 
follows. 
(r 
Assume that A is not in M. Then M \ {A} = M, and for a clause C in 
P, M ~ F and M ~: 27 imply A E M, contradiction, t3 
Theorem 3.4 Let P be a positive disjunctive program and reD(p) be any resid- 
ual program of P. Then J~J~p = J~./~TrD(p). 
Proof: (C) Let M be a minimal model of P. Since the clause (4) is a resolvent 
of the clauses (2) and (3) in P, M also satisfies each clause (4) in reD(p). Then 
M is a model of reD(P). Assume that there is a minimal model N of reD(P) such 
that N C M. Since N is not a model of P, N does not satisfy the clause (2). 
Then N ~ F, N ~ A, and N ~= ~. As a minimal model N of reD(p) implies A, 
it follows from Lemma 3.3 that there is a clause C of the form (3) or (4) in red (p) 
such that C contains A in its head. (i) Suppose first that C is of the form (3). 
Then g ~ A implies N \ {A} ~ Fi and N \ {A} ~: ~i (by Lemma 3.3). Here 
N \ {A} ~ Fi implies W ~ Fi. Besides, the disjunctive head A V Ei is assumed 
to be already factored, then 27i does not include A. Thus N \ {A} ~ 27i also 
implies N ~ 274. In this case, however, N does not satisfy the clause (4). This 
contradicts the assumption that N is a model of reD(p). (ii) Next suppose that 
C is of the form (4) such that ,U = A V ,U'. Then N ~ A implies N ~ 27, which 
contradicts the fact N ~: 27. Hence, M is also a minimal model of reD(p). 
(__D) Let M be a minimal model of reD(p). If M is not a model of P, U does 
not satisfy the clause (2). In this case, M ~ ,U, M ~ A, and M ~ F. Since a 
minimal model M of reD(p) implies A, it follows from Lemma 3.3 that there is 
a clause C of the form (3) or (4) in reD(p) such that C contains A in its head. 
When C is of the form (3), M ~ A implies M ~ F~ and M ~: S~ (by Lemma 3.3 
and the discussion presented above). Thus M does not satisfy the corresponding 
clause (4), which contradicts the assumption that M is a model of red (p). Else 

176 
when C is of the form (4) such that 22 = A V 2J', M ~ A implies M ~ ,U, which 
contradicts the fact M ~: 22. Hence M is a model of P. Next assume that there 
is a minimal model N of P such that N C M. By (_C), N is also a minimal 
model of ~rD(P), but this is impossible since M is a minimal model of rD(P). 
[] 
Corollary 3.5 Let P be a positive disjunctive program. Then P is inconsistent 
iff ~rD(P) is inconsistent. 
[] 
Example 3.3 (cont. from Example 3.2) Given the program P, its disjunctive 
partial deduction "ff~c*--a;a}(P) becomes 
and A/lAd~o 
.(P) = {{a, c}, {b}} which is exactly the same as A~tAz[p. 
o 
{c~aia) 
4 
Partial Deduction of Normal Disjunctive Programs 
In this section, we extend disjunctive partial deduction to normal disjunctive 
programs. 
The definition of disjunctive partial deduction of normal disjunctive programs 
is the same as Definition 3.1, except that in this case each clause possibly contains 
negation as failure. 
Example 4.1 Let P be the normal disjunctive program: 
P=(aVb*---notc, 
a*--d, c*---a}. 
Then disjunctive partial deduction of P with respect to c ~ a on a becomes 
~r~._a;a}(P)={aVb~--notc , a*---d, e*---d, bVc*-notc}. [] 
As shown in the above example, disjunctive partial deduction is not affected 
by the presence of negation as failure in a program. Thus we can directly apply 
previously defined disjunctive partial deduction to normal disjunctive programs 
and the following result holds. 
Theorem 4.1 Let P be a normal disjunctive program. Then $'/'p --': ~.~VrD(p). 
Proof" 
Let M be a stable model of P. Then M is a minimal model of pM. 
Since pM is a positive disjunctive program, by Theorem 3.4, M is also a minimal 
model of ~r D (pM). Now let us consider the clauses: 
E~AAF^notr' 
(,) 

177 
and 
AV~i~FiAnotF~ 
(l<i<k) 
(t) 
in P, where not F ~ is the conjunction of negation-as-failure formulas in the body. 
(i) If M ~: U and M ~ F[ for some i (1 < i < k), the clauses: 
and 
Z~--AAF 
(*') 
A V,Ui *- Fi 
(t') 
are in pM. From these clauses, disjunctive partial deduction generates the clauses: 
s v s~ ~- r A r~ 
( ~') 
in rcD(pM). On the other hand, from (*) and (t) in P, there are the clauses: 
S V Si ~-- F A Fi A no~ rl A not F[ 
( ~ ) 
in ~D(p), which become (t') in ~rD(P) M. 
(ii) Else ifM ~ F' or M ~ F[ for anyi 
(1 < i < k), the clauses (.) or 
(t) is respectively eliminated in pM. Then the clauses (:~1) are not included in 
~rD(pM). In this case, each clause ($) in ~D(p) is also eliminated in ~D(p)M. 
Thus, there is a one-to-one correspondence between the clauses in ~.D(pM) 
and the clauses in ~D(p)U, hence 7rD(P M) ---. ~rD(P) u. Therefore M is also a 
minimal model of ~rD(p) M, and a stable model of ~rD(p). 
The converse is also shown in the same manner. 
[:] 
Corollary 4.2 Let P be a normal disjunctive program. Then P is incoherent 
iff rc o (P) is incoherent. 
E] 
The above theorem also implies that in normal logic programs, normal partial 
deduction preserves Gelfond and Lifschitz's stable model semantics. 
Corollary 4.3 Let P be a normal logic program. Then 8Tp - S'I-rN(p). [] 
The above result is also presented in [Seki90]. 
5 
Connections between Normal and Disjunctive Partial 
Deduction 
In this section, we consider connections between normal and disjunctive partial 
deduction. We first give a sufficient condition such that normal partial deduction 
preserves the meaning of disjunctive logic programs. 

178 
Theorem 5.1 Let P be a normal disjunctive program and C be a clause of the 
form E ~- A A F from P. If A does not appear in the head of any disjunctive 
clause in P, then S2/-p - ST,~c;A}(p). That is, normal partial deduction of P 
with respect to C on A preserves the disjunctive stable model semantics. 
Proof: 
In this case, disjunctive partial deduction coincides with normal one, 
hence the result follows from Theorem 4.1. 
[] 
Next we present a method to compute disjunctive partial deduction in terms 
of normal partial deduction. 
Definition 5.1 Let P be a normal disjunctive program. The nip-transformation 
transforms P into the normal logic program y(P) which is obtained from P by 
replacing each disjunctive clause: 
C: A1V...VAz~--F 
(5) 
with l normal clauses: 
C~- : Ai ~-- F A A 7 A... A A-~_ 1 A Ahl A... A A T 
(1 < i < 1). 
(6) 
where each A~- is a new atom introduced for each Aj. 
In particular, C = C/-- if I _< 1. 
[] 
Now we show that disjunctive partial deduction of a normal disjunctive pro- 
gram P with respect to a clause C is obtained through normal partial deduction 
of r/(P) with respect to each C[. In the following, the function t/-1 is the re- 
verse transformation which shifts each atom Af appearing in the body of each 
clause in a program to the atom Ai in the head of the clause. Also Z- means 
A 7 A... A A[ where 22 = A1 V ...VAt. 
Theorem 5.2 Let P be a normal disjunctive program. Then rrgC;A}(P ) = 
~l-l(rd(CF;A}O/(P))) where 7r~c 7;A](r/(P)) means normal partial deduction of 
r/(P) with respect to each normal clause C/- on A. 
Proofi Corresponding to the clauses (2) and (3) in P, there are the clauses: 
A'~AAFAZ'- 
(where Z=ZVA')(.) 
and 
A*--FiAZ~- 
(1 <i<k) 
in ~I(P), respectively. Then the clauses: 
A I *- FAFi AZ I- A~[- 
(t) 
(5) 
are obtained from (.) and (t) by normal partial deduction in rl(P ). In this 
case, by the reverse transformation q-l, each clause of the form (5) becomes a 
disjunctive clause of the form (4). Hence, ~r}Uc;A} (P) = y-10r{Vc~_ ;A}(y(P))). [] 

179 
Example 5.1 Let P be the program: 
P={aVb*--, 
a~--b, 
b*---a}. 
Then, 
D 
~r{a,__b;b}(P)={aVb~---, 
a*--, 
a~a, 
b~--a}. 
On the other hand, the nip-transformation of P becomes 
and 
~(P)={a~---b-, 
b~--a-, 
a*-b, 
b~---a}, 
7r~_b;b}(TI(P)) = {a~b-, 
b~--a-, 
a~--a-, 
a~--a, 
b~-a}. 
Thus, 
~-l(~r~a._b;b}(~(P)) 
) -~ { a V b ~-, 
a ~---, a ~ a, 
b ~-- a }. 
Therefore, ~r~a,_b;b}(P ) = rl-l(~rI~a_b;b}(rl(P))). 
D 
The above theorem presents that disjunctive partial deduction ~r~C;A}(P ) 
is obtained by the transformation sequence: P --* y(P) --+ 7r~CV;A}(~(P)) --+ 
~/-l(~r~C:-;A} (~(P)))" That is, together with the n/p-transformation, normal par- 
tial deduction can also be used for normal disjunctive programs. 
6 
Goal-Oriented 
Partial 
Deduction 
In this section, we present goal-oriented partial deduction in disjunctive logic 
programs. Goal-oriented partial deduction specializes a program with respect to 
a given goal, which is useful to optimize programs for query-answering. Lloyd 
and Shepherdson [LS91] discuss a framework of goal-oriented partial evaluation 
for normal logic programs and provide conditions to assure its correctness with 
respect to Clark's completion semantics and SLDNF proof procedures. In our 
framework, goal-oriented partial deduction is presented as follows. 
Let us consider a query of the form: 
Q : Q(x) ~-- B1 A... A B,~ A not B,~+I A ... A notBn 
(7) 
where Q(x) is a new atom not appearing elsewhere in a program and x represents 
variables appearing in the body of the clause. 
Then, given a normal disjunctive program P, partial deduction of P with 
respect to Q is defined as ~'~O;Bi}(Po) where Bi is any atom occurring positively 
in the body of Q and PO is the program P U {Q}. When a query contains 
variables, we consider partial deduction with respect to its ground instances. 

180 
An answer to a query is defined as a ground substitution c, for variables in 
Q(x). When Q contains no variable, a is the empty substitution. 
A query Q is true in P under the disjunctive stable model semantics if for 
every stable model I of PQ there is an answer cr such that Q(x)cr is included in 
I. Else if for some stable model I of PQ there is an answer cr such that Q(x)cr is 
included in I, the query is possibly true. Otherwise, if there is no such answer, 
the query is false. By Theorem 4.1, the following results hold. 
Theorem 6.1 Let P be a normal disjunctive program and Q be a query. Then, 
under the disjunctive stable model semantics, 
(i) Q is true in P iff Q is true in 7r~Q;Bi}(PQ). 
(ii) Q is possibly true in P iff Q is possibly true in r~Q;B,}(PQ). 
(iii) Q is false in P iff Q is false in 7r~Q;B,}(PQ). 
[3 
Example 6.1 Let P be the program: 
{ p(a) V p(b) ~ }, 
in which the query Q: q(x) ~ p(x) is true. Then, 
r~Q;p(~:)}(PQ) = { q(a)Vp(b) ~---, q(b)Vp(a) *-, 
q(a)Vq(b) ~----, p(a)Vp(b) ~-- } 
and Q is also true in 7r~)Q;p(z)} (PQ) under the disjunctive stable model semantics. 
o 
Note that in the above example, we assume that the ground queries 
q(a) *--- p(a) and q(b) ~ p(b) are unfolded consecutively in the program. That is, 
D 
D 
(P U { q(a) ~- p(a), q(b) ~ p(b) })). In 
7r~gQ;p(=)} (PQ) means 7r{o;p(b)} (Tr{Q;p(a)} 
this case, the order of unfolding does not affect the result of partial deduction 
since each partial deduction preserves the stable models of the program PQ. 
7 
Summary 
This paper presented a method of partial deduction for disjunctive logic pro- 
grams. We first showed that normal partial deduction is not applicable to dis- 
junctive logic programs in its present form. Then we introduced disjunctive par- 
tial deduction for disjunctive logic programs, which is a natural extension of 
normal partial deduction for normal logic programs. Disjunctive partial deduc- 
tion was shown to preserve the minimal model semantics of positive disjunctive 
programs, and the disjunctive stable model semantics of normal disjunctive pro- 
grams. We also showed a method of translating disjunctive partial deduction into 
normal partial deduction, and presented an application to goal-oriented partial 
deduction for query optimization. 

181 
The partial deduction technique presented in this paper is also directly appli- 
cable to disjunctive logic programs possibly containing classical negation [GL91]. 
Moreover, since positive disjunctive programs are identified with first-order the- 
ories, disjunctive partial deduction has potential application to first-order theo- 
rem provers. Recently, Brass and Dix [BD94] independently developed a partial 
deduction technique for disjunctive logic programs which is equivalent to ours. 
They discuss several abstract properties of disjunctive logic programs and con- 
clude partial deduction as one of the fundamental properties that logic program- 
ming semantics should satisfy. 
In this paper, we have mainly concerned with declarative aspects of partial 
deduction and considered propositional programs as a first step. Then our next 
step is to apply the partial deduction method to programs containing variables 
and investigate the procedural aspect of disjunctive partial deduction. 
References 
[BD94] Brass, S. and Dix, J., A Disjunctive Semantics Based on Unfolding and Bottom- 
up Evaluation, Proc. 13th World Computer Congress'94, IFIP, GI-Workshop W2, 
Disjunctive Logic Programming and Disjunctive Databases, 1994. 
[GL88] Gelfond, M. and Lifschitz, V., The Stable Model Semantics for Logic Program- 
ming, Proc. Joint Int. Conf. and Syrup. on Logic Programming, 1070-1080, 1988. 
[GL91] Gelfond, M. and Lifschitz, V., Classical Negation in Logic Programs and Dis- 
junctive Databases, New Generation Computing 9, 365-385, 1991. 
[KomS1] Komorowski, J., A Specification of an Abstract Prolog Machine and its Ap- 
plication to Partial Evaluation, Technical Report LSST 69, LinkSping Univ., 1981. 
[Kom92] Komorowski, J., An Introduction to Partial Deduction, Proc. 3rd lnt. Work- 
shop on Meta-programming in Logic, Lecture Notes in Computer Science 649, 
Springer-Verlag, 49-69, 1992. 
[LS91] Lloyd, J. W. and Shepherdson, J. C., Partial Evaluation in Logic Programming, 
J. Logic Programming 11,217-242, 1991. 
[Min82] Minker, J., On Indefinite Data Bases and the Closed World Assumption, Proc. 
6th Int. Conf. on Automated Deduction, Lecture Notes in Computer Science 138, 
Springer-Verlag, 292-308, 1982. 
[Prz91] Przymusinski, T. C., Stable Semantics for Disjunctive Programs, New Gener- 
ation Computing 9, 401-424, 1991. 
[Seki90] Seki, H., A Comparative Study of the Well-Founded and the Stable Model 
Semantics: Transformation's Viewpoint, Proc. Workshop on Logic Programming and 
Nonmonotonic Logic, Association for Logic Programming and Mathematics Sciences 
Institute, Cornell University, 115-123, 1990. 
[Seki91] Seki, H., Unfold/Fold Transformation of Stratified Programs, Theoretical 
Computer Science 86, 107-139, 1991. 
[Seki93] Seki, H., Unfold/Fold Transformation of General Logic Programs for the Well- 
Founded Semantics, J. Logic Programming 16, 5-23, 1993. 

182 
[SZ88] Sestoft, P. and Zamulin, A. V., Annotated Bibliography on Partial Evaluation 
and Mixed Computation, New Generation Computing 6, 309-354, 1988. 
[TS84] Tamaki, H. and Sato, T., Unfold/Fold transformation of Logic Programs, Proc. 
2nd Int. Conf. on Logic Programming, 127-138, 1984. 

Avoiding Non-Termination when 
Learning Logic Programs: 
A Case Study with FOIL and FOCL 
Giovanni Semeraro 1, Floriana Esposito 1 and Donato Malerba 1 
Clifford Brunk 2 and Michael Pazzani 2 
z Dipartimento di Informatica, 
Universits degli Studi di Bari 
Via Orabona 4, 70126 Bari, ITALY 
{semeraro, esposito, malerbad}~vm.csata.it 
2 Department of Information and Computer Science, 
University of California, Irvine 
Irvine, CA 92717 USA 
{brunk, pazzani} ~ics.uci.edu 
Abstract. Many systems that learn logic programs from examples adopt 
8-subsumption as model of generalization and refer to Plotkin's frame- 
work in order to define their search space. However, they seldom take 
into account the fact that the lattice defined by Plotkin is a set of 
equivalence classes rather than simple clauses. This may lead to non- 
terminating learning processes, since the search gets stuck within an 
equivalence class, which contains an infinite number of clauses. 
In the paper, we present a task that cannot be solved by two well-known 
systems that learn logic programs, FOIL and FOCL. The failure is ex- 
plained on the ground of the previous consideration about the search 
space. This task can be solved by adopting a weaker, but more mecha- 
nizable and manageable, model of generalization, called 8-subsumption 
under object identity (8ol-subsumption). Such a solution has been im- 
plemented in a new version of FOCL, called FOCL-OI. 
1 
Introduction 
Recently, a new research area, called Inductive Logic Programming (ILP) [21], 
was born. It lies between logic programming and learning from examples, and 
aims at inductively learning logic programs from examples. ILP is characterized 
by a formal approach to the problem of inductive generalization. 
The first formal method developed for inductive generalization is due to Plotkin 
[25]. Most of the work in the area of ILP refers to Plotkin's framework in order 
to define the space in which the search for concept descriptions is performed. 
Unfortunately, only in few eases it is realized that Plotkin's l~ttice is a set of 
equivalence classes rather than single clauses. 
Ilelff [12] proposed a logical framework for inductive generalization that aims 
at reducing the size of the search space by restricting the representation lan- 
guage to function-free (but not constant-free) clausal logic. The two constraints 

184 
adopted by Helft, namely the difference links and the linkedness of the Horn 
clauses, allow his algorithm to infer better generalizations from a practical point 
of view. Helft's framework, together with Plotkin's, is now commonly recognized 
as one of the two main frameworks for ILP [1] [14]. 
More recently, Quinlan [26] has developed a system, called FOIL (First Order 
Inductive Learner), that learns definite Horn clauses from data expressed as rela- 
tions. FOIL proved effective and efficient on several learning tasks. Nevertheless, 
Quinlan himself recognizes that "it is not difficult to construct tasks on which 
the current version of FOIL will fail". He ascribes these failures to the greedy 
search performed by FOIL. FOCL (First Order Combined Learner) [24] is an 
extension of FOIL in several aspects. The main extension allows FOCL to de- 
fine and exploit background knowledge in the inductive learning process. Both 
FOIL and FOCL are widely acknowledged as an advance in the area of learning 
from examples [35] and some authors recently provided FOIL with a theoretical 
foundation by casting it in Plotkin's framework [1]. 
In this paper, we point out that both FOIL and FOCL may fall into a non- 
termination problem when they cope with toy world problems taken from the 
machine learning literature. The same problems occur on real world tasks [18] 
[30]. Furthermore, we provide an interpretation of the behaviour of these sys- 
tems based on a pure analytical approach to the problem of learning logical 
programs. In Section 2 the model of generalization of 8-subsumption under ob- 
ject identity, called Ooi-subsumption, is formally defined and compared to 
O-subsumption. Section 3 presents a brief overview of FOIL and FOCL and 
describes the representation language used by these two systems. Negative ex- 
perimental results concerning FOIL and FOCL are shown in Section 4. Moreover, 
we provide an explanation for these negative results. This explanation straight- 
forwardly suggests a way for overcoming the detected conceptual problem. The 
general theoretically-founded solution is proposed in Section 5. In the same sec- 
tion, we present FOCL-OI, a new learning system based on FOCL, that replaces 
the model of generalization based on 0-subsumption with that based on 001- 
subsumption. FOCL-OI has been empirically evaluated on those learning tasks 
that could not be solved by FOIL and FOCL and proved successful in avoiding 
the problem of non-terminating learning processes, 
2 
O-subsumption 
and Ooi-subsumption 
Subsequently, we refer to [17] for what concerns the basic definitions of sub- 
stitution, positive and negative literal, clause, definite clause, program clause 
and Horn clause. In particular, we denote a substitution (or variable binding) 
~r with {xl *-'- tl,x2 *--- t~,...,xn *--" tn}, where the terms tl,t2,...,tn replace 
the variables Xl,X2,...,xn, respectively. Furthermore, dora(or) denotes the set 
{xl, x2,..., xn}. Given a first order expression r vars(r is the set of the vari- 
ables occurring in r We will consider a clause as the set of its literals. Henceforth, 
we denote with C the set of the clauses of the language and with 7-/the subset 
of Horn clauses. The term logic theory (or simply theory) is used as a synonym 
of logic program, i.e. a set of program clauses. 

185 
2.1 
0-subsumption 
Definitionl (0-subsumption). Let C, D be two Horn clauses. We say that 
D O-subsumes C if and only if (iff) there exists a substitution cr such that 
DaCC. 
Without loss of generality, we always assume that dom(~r) C vats(D). 
8-subsumption is a strictly weaker order relation than implication for first-order 
logic [12] [22] [25]. Here, we use the same order relation in [25], defined in terms 
of 0-subsumption, on the set 7"/of the Horn clauses. 
Definition2 (Generality under 0-subsumption). Let C, D be two Horn 
clauses. We say that D is more general than or equal to C - or that C is more 
specific than or equal to D - and we write C _< D iff D 8-subsumes C, i.e. 
C<Diff3c~ 
: D~rC_C 
Differently from Plotkin, we write C < D to indicate that D is more general 
than C. When the condition above holds, we say that D is a generalization of C 
and C is a specialization of D. We write C < D when C _< D and not(D < C) 
and we say that D is more general than C ( D is a proper generalization of C) or 
C is more specific than D (C is a proper specialization of D). We write C ~-, D 
when C < D and D < C and we say that C is equivalent to D. 
0-subsumption induces a quasi.ordering upon the set of Horn clauses, that 
is, < is reflexive and transitive, but not antisymmetric. Here, ,-~ denotes the 
equivalence relation induced by <. Notice that it does not coincide with set 
equality. Indeed, two equivalent clauses under --~ can be not only alphabetic 
variants, but even have a different number of literals, as for {P(x), P(f(y))} and 
{P(f(z))}. Thus, as Plotkin [25] pointed out, there is a reduced member of any 
equivalence class under -,, and this member is unique to within an alphabetic 
variant. 
Definition3 (Reduced clause). A clause C is reduced if it is not equivalent 
to any proper subset of itself. Formally, C is reduced iff D C C, D ,,~ C implies 
that C = D. 
Plotkin [25] reports an algorithm that returns a reduced clause D, given any 
clause C. The literals in C \ D are called redundant. 
Example 1. Consider the following clause 
C = {bicycle(X),-,wheel(X, Y), ~wheel(X, Z)} 
It is easy to see that C is not reduced. Indeed, the two literals -,wheel(X, Y), 
-,wheel(X, Z) can be unified through the substitution o" = {Z ,--- Y} and the 
resulting factor [11] 
C' = Ca = {bicycle(X),-~wheel(X, Y)} 

186 
is logically equivalent to C and represents the reduced member of an equivalence 
class of Horn clauses. 
Henceforth, we will always work on the quotient set 7"//,-, and, when conve- 
nient, we will denote with the name of a clause the equivalence class it belongs 
to. Indeed, the definition of < straightforwardly extends to equivalence classes 
under < as follows: 
Given two clauses C and D, let [C]~ and [D]~ denote the corresponding equiv- 
alence classes under .v. We say that [C]~ < [D]~ if] C <_ D. 
In [30], it is proved that (:H/-~ , <) is a complete lattice and contains ascending 
and descending chains of infinite length. 
An immediate consequence of the existence of infinite both ascending and de- 
scending chains is that the search space of any inductive system based on O- 
subsumption is inherently infinite, when further language restrictions are not 
considered. Even more so, both specific-to-general and general-to-specific search 
strategies may go through an infinite path. This consideration points out the 
relevance of a proper definition both of the goal of the search - for instance, least 
general generalization vs. most general generalization - and of the language biases 
which, together with the adopted model of generalization, may reduce/increase 
the size of the search space, hopefully without reducing its scope (or at least 
reducing the scope only on meaningless clauses). 
2.2 
001-subsumption 
We consider two distinct language biases, namely linkedness and object identity. 
The former constrains the kind of Horn clauses allowed, the latter limits the kind 
of substitutions considered. Subsequently, we formally define linkedness [12] and 
object identity. 
Definition4 (Linkedness). A Horn clause is linked if all of its literals are 
linked. A literal is linked if at least one of its arguments is linked. An argument 
of a literal is linked if either the literal is the head of the clause or another 
argument in the same literal is linked. 
Linkedness is a restriction on the arguments of a clause that generally pre- 
vents a learning system from introducing meaningless literals in the body of the 
learned clause. Therefore, similar restrictions (sometimes exactly the same re- 
striction) are adopted by many researchers and can be found in [17] with the 
name of connected formulas, in [33] with the name of association chains, as well 
as in [3] [5] [19]. 
Henceforth, /2 will denote the set of the linked Horn clauses. Obviously, s 
C 
~ c Cl~. 
Dei]nition5 (Object Identity). Variables with different names denote dis- 
tinct objects (or units). 

187 
Object identity is a restriction on the kind of substitutions allowed. More pre- 
cisely, substitutions are necessarily injective functions under such an assumption. 
This means that only one-to-one variable bindings are allowed, instead of many- 
to-one variable bindings. Formally, object identity corresponds to an equality 
I 
! 
! 
theory with an axiom schema of the form f(tl,t2,...,tn) â€¢ g(tl,t2,...,tm ) 
whenever f r g, where tk and t~, k = 1,2 .... , denote the terms of the language. 
The same axiom has been used by Clark [4], under the name of inequality ax- 
iom, and by Reiter [28] under the name of unique name axiom. For instance, the 
clause arch(X, Y, Z) ~-- on-top(X, Y), left-of(Y, Z) is equivalent to arch(X, Y, 
Z) ~ on-top(X, Y), left-of(Y, Z), [X r Y], [X ~ Z], [Y r Z], when object iden- 
tity holds. The object identity assumption corresponds to introduce constraints 
in form of difference links of the type [X r Y] into the Horn clause repre- 
sentation of inductively learned rules. Semantically, object identity assumption 
corresponds to consider only discriminant interpretations. These interpretations 
have the property that each consistent set of formulas has a discriminant model 
[2]. 
Definition 6 (0ol-subsumption). Let C, D be two Horn clauses. We say that 
D Ool-subsumes C (D O-subsumes C under object identity ) iff there exists a 
substitution a such that Dc~ C C and c~ is injective. 
Definition 7 (Generality under Ool-Subsumption). Let C, D be two Horn 
clauses. We say that D is more general than or equal to C under object identity 
and we write C _<oI D iff D 0oi-subsumes C, that is, 
C<_oIDiff3cr 
: DaC_Candcrisinjective 
Similarly to Definition 2, we can define the concepts of (proper) general- 
ization/speeialization and equivalence under object identity. The corresponding 
symbols will be endowed with the subscript OI. 
Proposition 8. Let C, D be two Horn clauses, then C <ol D ~ C < D, while 
the opposite is not true in general. 
Therefore, Ooi-subsumption is a model of generalization weaker than 0- 
subsumption. 
Ezample 2. Consider again the clause of Example 1: 
C = (bicycle(X), -,wheel(X, Y), ~wheel(X, Z)} 
It is easy to see that, under object identity, C cannot be further reduced. In- 
deed, the two clauses C and C' = {bicycle(X),-~wheel(X, Y)} define two distinct 
equivalence classes under ~Ol. 

188 
2.3 
The algebraic structure of the search space 
An analysis of the algebraic properties of the ordering relation defined by 8- 
subsumption led Plotkin to state that the partially ordered set (C/--,, <) forms 
a lattice: 
(C/~,Vc,Ac) 
where the lattice operations are defined as follows (C1 and C2 are assumed to 
be variable disjoint) : 
[c,]~ vc 
= [lgg(c1, c2)]~ 
[c1]~ ^c [c2)]~ = IV, u c21~ 
By lgg(C1, C~), we denote the least general generalization of the clauses C1 and 
C2 under 0-subsumption, that is: 
Definition9 (Least general generalization under O-subsumption). A 
least general generalization (lgg) under 0-subsumption of two clauses is a gener- 
alization which is more specific than or equal to any other such generalization. 
Formally, given C1, C2 E C, C is a lgg of {C1, C2} iff: 
1. Ci < C,i= 1,2 
2. V D such that Ci < D, i = I,2 : C < D 
lgg(Ci,C2) -- {C]C~ < C,i = 1,2 and V D such that Ci _< D, i = 1,2 : C_< 
D} 
Least general generalizations are extremely important in the area of inductive 
learning, since they are the only generalizations that are guaranteed to be correct, 
whenever correct generalizations exist [13]. Definition 9 can be straightforwardly 
restricted to the subset 7~ of ttorn clauses. The lgg of any set of clauses is unique 
under ,-,, i.e. [lgg(C1, C2) I-- 1, where I SI denotes the cardinality of the set S. 
This property does not hold when the lgg is computed under 8o~-subsumption. 
Indeed, under object identity assumption, the set of the Horn clauses is no 
longer a lattice, but it is simply a quasi-ordered set. As a conseguence, (7//~, ~) 
is a lattice, while (7//-~, <_Ol) is a partially ordered set. Partially ordered search 
spaces that are not lattices are finitary as to the problem of finding a lgg of two or 
more clauses, that is, there exists a set of lgg's of any pair of elements in ?-//~, and 
this set is at most finite (since the only generalization'operators are the dropping 
of a literal and, if needed, the turning of constants into variables), while lattices 
are unitary by definition (there exists a unique reduced lgg). The loss of the 
requirement of uniqueness and the possibility to have a set of incomparable lgg's 
is regarded as a desirable property by some authors [23]. As a consequence, when 
the generalization model of a learning algorithm is ~ox-subsumption, Definition 
9 should be modified as follows: 

189 
Definition 10 (Lgg under Oox-subsumption). A least general generalization 
under Oot-subsumption of two clauses is a generalization which is not more gen- 
eral than any other such generalization, that is, it is either more specific than or 
not comparable to any other such generalization. 
Formally, given C1,C2 6 C, C is a lgg of { C1,C2} iff: 
1. C/_<oIC, i=1,2 
2. V D such that Ci _<01D, i=1,2: not(D _<01C) 
lgg(C1,C2) = {C I Ci <or C, i = 1,2 and V D such that Ci _<ol D, i = 
1,2 : not(D <oI C)} 
Of course, the same results apply to Horn clause logic, in particular to 
(7//,,% _<oi). The space (~//,~, -<ol) has another desirable property for the prob- 
lem of generalization. In this space, there exist only finite strictly ascending 
chains, since the set of all generalizations of a clause C corresponds to the power 
set of C, i.e. the set of all subsets of the literals of C. Thus, each proper gener- 
alization of C has a number of !iterals less than the number of literals of C [32]. 
In formulae: 
Let C be a clause and GENoI(C) the set of all the generalizations of C under 
object identity. It holds that: 
GENoz (C) = {D 6 "H/.~[ D C C} = 2 c 
As a consequence, the cardinality of Iggoz(Cl, C2) in (7-(/.~,_<o1) is upper 
bounded by the following condition: 
[ lggot (Ct, 6'2) [ _< [ GENo, (C1) 91GENol (C2) [ _< 2 n, 
where n = min{I C1 I, ] C2 1} and I A ] denotes the number of literals in the 
clause A. 
On the contrary, when many-to-one variable bindings are allowed, as under 0- 
subsumption, there exist infinite strictly ascending chains in the lattice of the 
Horn clauses, as previously stated. 
Given two clauses C1 and C2, it holds that: lgg(C1,C2) -< D, for each D 
in lggo1(C1, C2). Thus, the lgg's generated by assuming 0oi-subsumption as 
model of generalization may be -overly general w.r.t, the corresponding unique 
0-subsumption-based lgg, 
Overgeneralization can be dealt with by exploiting the proper refinement oper- 
ator. A consistency-preserving refinement operator that copes with the problem 
of finding a most general specialization (rags) in the generalization model defined 
by Ool-subsumption can be found in [6] [8]. 
All the results above extend straightforwardly to the proper subset of the linked 
Horn clauses. 
As shown by Buntine [3], surprisingly generalization and specialization hierar- 
chies possess very different properties. In the following, by size of the search space 
we mean the number of equivalence classes in a specialization/generMization hi- 
erarchy. Given a partially ordered set (S[--,, _<) and a clause C 6 S/-,~, by scope 

190 
of the search in a generalization hierarchy we mean the set of the generalizations 
of C, that is: 
GEN(C) = {D e S/'.~ I C < D} 
while by scope of the search in a specialization hierarchy we mean the set of the 
specializations of C, that is: 
SPEC(C) = {D E S/"~ I D < C} 
Linkedness reduces the size of both specialization and generalization hierarchies, 
as wellas the scope of the search. Conversely, object identity increases the size 
of the hypothesis space, as Example 2 shows, but it reduces the scope of the 
search. 
3 
FOIL and FOCL 
At the high level, both FOIL and FOCL adopt a separate-and-conquer search 
strategy. The separate stage of the algorithm is basically a loop that checks for 
the completeness of the current logical theory and, if this check fails, begins the 
search for a new consistent clause, while the conquer stage performs a general- 
to-specific hill-climbing search to construct the body of the new clause. The 
evaluation function used in the latter search is the information theoretic heuris- 
tic called information gain. Therefore, the search space for the separate stage is 
2 s 
i.e. the space of logic theories. The conquer stage searches for a consistent 
clause in the only specialization hierarchy of (s 
<) rooted into the linked 
Horn clause whose head contains the predicate to be learned and whose body 
is empty, i.e. P(X) ~--, where P is the predicate that denotes the concept to be 
learned. 
In FOIL, each k-ary predicate is associated with a relation consisting of the set 
of k-tuples of constants that satisfy that predicate. Such predicates are called 
extensional or operational. The relation associated to the predicate that we want 
to learn is called target relation. Each relation, including the target relation, 
defines both positive and negative instances of the predicate. Negative instances 
of a predicate can be defined either explicitly or according to the closed-world 
assumption (CWA) of Prolog. In this last case, negative instances consist of all 
constant k-tuples other than those considered positive and they are generated 
by temporarily making a domain closure assumption (DCA) [17]. A peculiarity 
of FOCL is that it is possible to define and use intensional or non-operational 
predicates, besides extensional ones. A predicate is defined intensionally when it 
appears in the head of an inference rule expressed as a Horn clause. 
Given a k-ary predicate P, FOIL and FOCL learn a predicate definition or rule 
for P, that is, a set of definite Horn clauses in which P(X1, X2,..., Xk) is the 
literal in the head. Each clause of this rule should be satisfied only by positive 
tuples (consistency), while all clauses together should cover all positive instances 
of P(X~, X2,..., Xk) (completeness). Each literal in the body of a clause takes 

191 
one of the four forms Xj = Xk,.\'j r Xk, Q(V1, t~,..., t~),--,Q(V1, V2,..., It), 
where the Xi's are variables already introduced by previous literals (old vari- 
ables) in the body, the Vi's can be both old and new variables, and Q is the 
same predicate associated with a relation. Therefore, FOIL and FOCL learn 
function-free Horn clauses, since terms other than variables cannot occur as ar- 
guments of a literal. 
Finally, we observe that the hill-climbing search strategy, used by FOIL and 
FOCL while building a single clause, suffers from the horizon effect: A literal 
that proves to be desirable or even essential from a global perspective (the whole 
clause) may appear relatively unpromising at a local level (a partially developed 
clause) and so may be left out. In order to avoid this problem, FOIL intro- 
duces determinate literals [27], while FOCL exploits some user-defined relalional 
clichds [31] that suggest potentially useful combinations of literals to be tested 
while generating a clause of a predicate definition. 
4 
Experiments with FOIL and FOCL 
This section presents some experimental results obtained by running FOIL and 
FOCL on a classical task from the machine learning literature. Such results point 
out that both FOIL and FOCL may give rise to non-terminating learning pro- 
cesses. 
The objects in Figure la are the training examples supplied to FOIL and FOCL 
in order to learn the nature of an arch much like the arch which Winston de- 
scribes [34]. The set A = {At, A2} includes examples of arches and the set N = 
{N1, N2, N3 } contains examples of objects that are not arches. The predicates 
used to describe the objects are reported in Figure lb. 
Both FOIL and FOCL generate no clause, that is, they are not able to find a 
definition for the concept arch from the given training set. 
The problem with FOIL is that it adopts a stopping criterion for the conquer 
A| 
~'~ 
Predicate 
Meaning 
] 
arch(X) 
X is an arch 
~. 
cont(X, Y) 
X contains Y 
on(X. Y) 
X is on Y 
wuch(X, Y) 
X touches Y 
P" 
I I 
P~ 
l or-hor(X) 
X is horizontally oriented 
or-vet(X) 
X is vr 
oriented 
~' ~ 
or-not-appl(X) X has no orientation 
sh-rect(X) 
X has a rectangular shape 
sh.tri(X) 
X has a triangular shape 
(a) 
(b) 
Fig. 1. (a) Training set for the problem arch. (b) Description language for the problem 
arch. 

192 
stage that is based on Rissanen's Minimum Description Length (MDL) principle 
[29]. According to this criterion, an inconsistent clause is not extended further if 
the bits required to encode the new clause, obtained by adding the literal with 
the maximum information gain, exceed the bits needed to indicate the covered 
tuples. The elimination of this stopping criterion makes FOIL converge to the 
following clause: 
arch(A):- cont(A,B), or-ver(S), on(C,S), sh-rect(S), 
touch(C,D), sh-rect(D), B <> D 
which is complete and consistent. 
Conversely, FOCL fails because no literal has a positive information gain, and 
this suggests the use of relational cliches. Indeed, in a second running, we intro- 
duced the relational clich~ CONT, by which FOCL is said to test the pairs of 
literals cont(X, Y), Q(V1, V2,..., Vt), rather than to limit the search by testing 
separately the literals of the kind cont(X, Y) and Q(V1, V2,..., V~). 
Even in this case, FOCL is not able to generate a complete and consistent concept 
definition and, moreover, the learning process does not converge, that is, FOCL's 
search does not terminate. An analysis of the ongoing running of FOCL provides 
a simple explanation of this behaviour. A snapshot of the state of FOCL's search 
at a time t is the following: 
C1 arch(?0) : - cont(?0, ?1), or-not-appl(?l) 
C2 arch(?0) : - cont(?0, ?1), or-ver(?l), on(?2, ?1), sh-rect(?l), 
cont(?0, ?3), sh-rect(?3), 
cont(?0, ?4), sh-rect(?4),... 
The first clause is consistent and covers only the positive example A2. The second 
clause is generated by FOCL in the attempt to achieve completeness. Actually, 
this clause is a partial one, but it is enough to give us an insight of what is 
going on: FOCL's conquer stage searches in the wrong specialization hierarchy. 
It performs its search in the lattice (L, <) of all the linked Horn clauses rather 
than in the lattice (L/..~, <_) of all the equivalence classes having a linked Horn 
clause as a reduced member. 
Indeed, it is easy to see that the second clause in the rule for arch is logically 
equivalent to the clause: 
C3 arch(?0) : - cont(?0, ?1), or-ver(?l), on(?2, ?1), sh-rect(?l) 
FOCL does not implement an algorithm for testing the equivalence of the newly 
generated hypothesis with respect to 'the previous one. As a consequence, the 
search continues by generating and testing hypotheses that belong to the same 
equivalence class as the previously generated hypothesis, so remaining inside the 
same node of the specialization hierarchy and with no means of escape. In other 
words, the conquer stage in FOCL defines incorrectly its termination condition, 
9 therefore there is no guarantee of termination. In fact, the pair of literals conl(?O, 
?n), sh-rect(?n) turns out to have the maximum information gain at each step 

193 
of the search for a new literal to add. Moreover, setting one of FOCL's built-in 
functions, namely the eql built-in function that allows the system to test also 
the literals eql(X, Y) and their negations (alphabetic variants of X = Y and 
X ~ Y, respectively), has no effect on the results, since these literals have a low 
information gain. 
It is interesting to observe that Quinlan [26] reports a result obtained by FOIL on 
the task of learning the concept of an arch. Indeed, FOIL is released with some 
data files. The file containing the input data for the arch problem is winston.d. 
If we compare the experiment performed by Quinlan to the similar experiment 
presented above, we can easily observe that Quinlan's formulation of the arch 
problem makes the learning process easier. In fact, FOIL learns the predicate 
arch(A, B, C) instead of arch(A). This is apparently a slight difference, but 
as a matter of fact this representation biases the learning system towards the 
generation of concept definitions whose clauses are both domain-reslricted and 
range-reslricted [5]. Our formulation of the arch problem is more similar to that 
in [16] and requires that the learning system be able to determine autonomously 
the number of components (and their characteristics) that are sufficient to dis- 
criminate the positive instances of the target concept from the negative ones. 
The conclusion that FOCL searches in the lattice (/:, <) rather than in (Z:/.-., <) 
applies to FOIL, as well. An empirical proof of this is given in [9]. Furthermore, 
learning tasks from real-world domains, concerning the field of document un- 
derstanding [7] [18] [30], showed the same problem of non-termination, as that 
presented above. This points out that the conceptual deficiency of FOIL and 
FOCL's conquer stage may become manifested in real world learning tasks, in 
addition to laboratory-sized ones. 
5 
FOCL-OI 
In this section, we consider the negative results of FOIL and FOCL and propose a 
theoretical solution that prevents these systems from going through the troubles 
shown in Section 4. Moreover, a practical solution is proposed and implemented 
in a new version of FOCL, called FOCL-OI. 
The theoretical solution is to change the search space of the conquer stage of 
FOIL and FOCL from (/:, <) to (/:/-~, <). Practically speaking, this means to 
provide the conquer stage of the high level separate-and-conquer strategy with 
a procedure that performs a O-subsumption equivalence test. This procedure 
should check if the current clause is equivalent (under .-~) to the clatise obtained 
by adding the literal (or a combination of literals, if cliches are used) with the 
highest information gain. In the general case, this is an NP-complete problem, 
since it involves a test for 0-subsumption, which is NP-complete [10]. In the 
particular case of FOIL and FOCL, the current clause C is a proper subset of 
the clause D, obtained by adding the literal with the maximum information 
gain, since the conquer stage performs a general-to-specific search. Thus, the 
procedure needs to check only if D 8-subsumes C. In formulae, C C D and we 
want to know if C ~ D. But C C D implies that D < C, thus it is enough to 

194 
check whether C < D. 
However, let us observe that, for the conquer stage of FOIL and FOCL, the 
following proposition holds: 
Proposition 11. Let C and D be two definite Horn clauses: 
C reduced and C C D and vats(C) = vats(D) ::~ [C]~ r [D]~ 
Proof. Let us suppose that C and D are two definite Horn Clauses s.t.: 
C is reduced, C C D, cars(C) = cars(D) (i.e., D does not introduce new vari- 
ables) and [C]~ -- [D]~. Let n be the size of C, i.e. ] C [= n. By hypothesis, 
C C D, thus we can suppose C = {L1,L2,...,Ln} and D = {L1,L2,...,Ln, 
Ln+l,...,Ln+m},m < 1. 
We prove the proposition by induction on m. 
m=l. 
Ad absurdum. 
D = C U {Ln+l}, where Ln+l is necessarily a literal in the body of D. Further- 
more, 
vats(C) = cars(D) ::r vars({Ln+l}) c_C. vats(C) 
(1) 
By definition, [C]~ = [D]~ means C < D and D < C. 
C < D ~ 
3 ~r : Dcr C_ C =ee (CU {L,+I})~ C C =~ Ccr C_ C and {L,+I}~C_ C. 
Let us consider Cr 
We know that 
C~ C C 
(2) 
Cc~ C C ==r C < Cg and, obviously, it holds also C~r < C (since C~ = C~ :r 
Cc _C Ccr), thus 
Cg "~ C 
(3) 
Now, either Cc~ C C or C~r = C holds. 
If C~ C C holds, then Cc~ r C. But (2) and (3) and C~r r C imply that C is 
not reduced, which contradicts the first hypothesis. 
If C~ = C holds, then it suffices to consider ~r = {}. But, then {L~+l}c' C C 
is equivalent to say that {L~+I} _C C by (1), which contradicts the hypothesis 
that C C D. 
As a consequence, it holds [C]~ r [D]~ 
m>l. 
Let D' = CU{Ln+I, Ln+~,..., Ln+m-1}, then D = D'U{Ln+m} and vats(D) = 
vars(D') U vars({nn+,~}). Moreover, by hypothesis, cars(C) = vats(D), then 
vats(C) = vars(D')U vars({Ln+m}) ~ vars(D') C cars(C). 
Thus, vars({n~+m}) C_ vats(C). 
It follows that: 
vats(C) = vats(D) = vars( D') U vars( { Ln+m } ) = vars( D'). 
Now, C is reduced, C C D', and vats(C) = vars(D'). In the trivial case C = D', 
the proof is reduced to the basic case for m = 1 shown above. In the case C C D ~, 
we can state that [C]~ r [D']~, from the inductive hypothesis. We want to prove 

195 
that: [C]~ = [D]~ ~ [C]~ = [D']~, which contradicts the inductive hypothesis. 
Let us suppose [C]~ = [D]~, then, by definition, C < D and D < C. 
C < D ~ B a : Da C C => (D' U{L,,+m})a C C ::~ D'~ C C =~ C <_ D' (4) 
But 
D = CU {Ln+I,L,+2,...,Ln+,~-I} U {Ln+m} 
= D' U {Ln+m} =:~ C C D' ~ D' < C 
(5) 
(6) 
(4) and (5) imply that [C]~ = [D']~. 
[] 
In other words, it is necessary to perform a 0-subsumption equivalence test if 
and only if the new clause D introduces new variables. Therefore, since in FOIL 
and FOCL we have D = C U {Ln+l}, where Ln+I is the literal with maximum 
information gain, and C and D are linked, it is sufficient to search for a uni- 
fication between Ln+l and one of the n literals in C, This search has a linear 
complexity in the size of the clause. Indeed, it can be proved that there exists no 
ascending chain of infinite length {Ci}i>o such that Ci < Ci+l and Ci C Ci+l. 
The trivial case in which Ln+l E C can be easily ruled out by preventing the 
search from adding a literal that already exists in the body of the currently gen- 
erated clause. As a consequence, the computational complexity of the procedure 
that performs a O-subsumption equivalence test can be reduced to O(n), where n 
is the size of the current clause C. Indeed, from the literature about unification 
[16], it is known that the best unification algorithms between terms have a linear 
complexity in time. 
For the sake of completeness, we have to observe that a literal which appears to 
be redundant in a partially developed clause (local redundancy) may no longer 
be such when further literals are added to the clause. There are two possible 
solutions to this short-sightedness of the search. A simple one consists in testing 
pairs (triples, foursomes, ...) of literals, when there is no single literal that helps 
to jump to a different equivalence class, while the other solution consists in test- 
ing pairs of literals {L,+I, Ln+2} as soon as L,+x turns out to be redundant. 
The equivalence test is no longer necessary when we change the underlying model 
of generalization from 0-subsumption to 8oi-subsumption, which causes a change 
of FOCL's search space from (s <) to (f, <ol). Indeed, it is easy to see that 
Proposition 11 holds even under object identity. Moreover, the introduction of a 
new variable always causes a change of the equivalence class under object iden- 
tity. Thus, we can conclude that searching into (s <oz) is equivalent to search- 
ing into (/:/,~, <ol). In order to avoid non-termination problems, we changed 
the underlying model of generalization of FOCL from 8-subsumption to 001- 
subsumption. This new version of FOCL, called FOCL-OI, implements object 
identity in a modular way. Indeed, the end-user/teacher can choose the type(s) 
of variables for which object identity is assumed. 
Below, the complete and consistent concept definition produced by FOCL-OI 
with the same input data - training set and system parameters - as those used 

196 
in the experiment described in Section 4 is reported. 
(74 arch(?0) : - cont(?0, ?1), or-not-appl(?l) 
Cs arch(?0) : - cont(?0, ?1), or-ver(?l), on(?2, ?1), not(?l - ?2) 
sh-rect(?l), cont(?0, ?3), not(?l = 73), 
not(?2 -- ?3), sh-rect(?3) 
In this case, however, the typing information has been properly changed in order 
to assume object identity for the variables that represent a part of an arch. 
The object identity assumption allows FOCL to prevent the problem of non- 
termination of the search, when learning a complete and consistent rule for the 
concept of an arch. 
6 
Conclusions 
and future 
work 
All learning systems need to clarify the adopted model of generalization and the 
space in which they perform the search for concept definitions. Formal methods 
and techniques can be useful to detect potential sources of problems and con- 
ceptual shortcomings of the existing empirical learning systems and to suggest 
the suitable counteractions in order to improve their performance. 
This paper constitutes an attempt to apply this analytical approach to two 
well-known learning systems, FOIL and FOCL. Plotkin's logical framework to 
inductive generalization [25] proved useful both to point out some lacks that 
affect the search strategy of these systems and to suggest straightforwardly the 
adequate correction. This correction has been implemented in a new version of 
FOCL, called FOCL-OI, and proved effective to overcome non-termination prob- 
lems. Future work will concern the implementation of a new version of FOCL in 
which, at first, the 0Ol-SUbsumption generalization model is fully adopted (for 
any type of variables) and then, the system autonomously learns the equality lit- 
erals in the form [Xi = Xj], if necessary. Theoretically, this new learning strategy 
should prove more effective and efficient than that in which 0-subsumption and 
difference links [Xi # Xj] have to be learned, since OoI-subsumption is more 
manageable than 0-subsumption, while learning the equality literals would hap- 
pen rarely, according to a when-needed strategy. 
Finally, this analytic approach to concept learning allows us to identify the limits 
of commonly accepted theories and methodologies for inductive learning and to 
critically revise and reformulate them on the ground of the cited logical frame- 
works. For instance, we can now state that, under object identity, adding a literal 
to a clause is always a specializing rule (unless the added literal already exists 
in the clause), while, by dropping such assumption, this is no longer true. More 
precisely, it is true if and only if the new clause is not equivalent to the pre- 
vious one. In a similar manner, the dropping condition generalization rule [20], 
holds under 0os-subsumption, but it is no longer a generalization rule under 
0-subsumption if the new clause belongs to the same equivalence class as the 

197 
previous one. The immediate consequence of this observation is that the gener- 
alization rules in [20] should be reformulated (indeed, Michalski uses implication 
as generalization model and the same observation applies also to implication) or, 
alternatively, it should be stated clearly that they hold under 0ol-subsumption. 
References 
1. Bell, S., and Weber, S., On the close logical relationship between FOIL and the 
frameworks of HeIR and Plotkin, Proceedings of The Third Int'l Workshop on 
Inductive Logic Programming ILP'93, Bled, Slovenia, 1-10, 1993. 
2. Bossu, G., and Siegel, P., Saturation, Nonmonotonic Reasoning and the Closed- 
World Assumption, Artificial Intelligence, 25, 13-63, 1985. 
3. Buntine, W., Generalized Subsumption and Its Applications to Induction and Re- 
dundancy, Artificial Intelligence, 36, 149-176, 1988. 
4. Clark, K.L., Negation as failure, in Logic and Databases, H. Gallaire and J. Minker 
(Eds.), 293-321, Plenum Press, New York, 1978. 
5. De Raedt, L., Interactive Theory Revision, Academic Press, San Diego, CA, 1992. 
6. Esposito, F., Malerba, D., and Semeraro, G., Specialization in Incremental Learn- 
ing: The Negation Operator, Proceed. of the AAAI-93 Spring Symp. Series on 
"Training Issues in Incremental Learning", Stanford, CA, 1993. 
7. Esposito, F., Malerba, D., Semeraro, G., and Pazzani, M., A Machine Learning 
Approach To Document Understanding, Proceed. of the 2nd Int'l Workshop on 
Multistrategy Learning MSL-93, Harpers Ferry, West Virginia, 276-292, 1993. 
8. Esposito, F., Malerba, D., and Semeraro, G., Negation as a Specializing Operator, 
in Advances in Artificial Intelligence - Proceedings of the Third Congress of the 
Italian Association for Artificial Intelligence AI*IA 93, Lecture Notes in Artificial 
Intelligence 728, P. Torasso (Ed.), Springer-Verlag, Turin, Italy, 166-177, 1993. 
9. Esposito, F., Malerba, D., Semeraro, G., Brunk, C. and Pazzani, M., Traps and 
Pitfalls when Learning Logical Definitions, Proceedings of the 8th International 
Symposium on Methodologies for Intelligent Systems, Charlotte, North Carolina, 
1994 (to appear) 
10. Garey, M.R., and Johnson, D.S., Computers and Intractability, Freeman, San Fran- 
cisco, CA, 1979. 
11. Genesereth, M.R., and Nilsson, N.J., Logical Foundations of Artificial Intelligence, 
Morgan Kaufmann, Palo Alto, CA, 1987. 
12. HelR, N., Inductive Generalization: A Logical Framework, in Progress in Machine 
Learning - Proceedings of EWSL 87, I. Bratko & N. Lavrac (Eds.), Sigma Press, 
Bled, Yugoslavia, 149-157, 1987. 
13. Idestam-Almquist, P., Generalization under Implication by Recursive Anti- 
unification, Proceedings of the Tenth International Conference on Machine Learn- 
ing, Amherst, MA, 151-158, 1993. 
14. Kietz, J.U., A Comparative Study Of Structural Most Specific Generalizations 
Used In Machine Learning, in Logical Approaches to Machine Learning - Workshop 
Notes: 10th ECAI, Vienna, Austria, 1992. 
15. Knight, K., Unification: A Multidisciplinary Survey, ACM Computing Surveys, 
Vol.21, No.l, 1989. 
16. Larson, J.B., Inductive Inference in the Variable Valued Predicate Logic System 
VL21: Methodology and Computer Implementation, Ph.D. dissertation, Dept. of 
Computer Science, University of Illinois, Urbana, Illinois, May 1977. 

198 
17. Lloyd, J.W., Foundations of Logic Programming, Second Edition, Springer-Verlag, 
New York, 1987. 
18. Malerba, D., Document Understanding: A Machine Learning Approach, Technical 
Report, Esprit Project 5203 INTREPID,. March 1993. 
19. Manago, M., and Kodratoff, Y., Model-Driven Learning of Disjunctive Concepts, 
in Progress in Machine Learning - Proceedings of EWSL 87, I. Bratko & N. Lavrac 
(Eds.), Sigma Press, Bled, Yugoslavia, 183-198, 1987. 
20. Michalski, R.S., A Theory and Methodology of Inductive Learning, Artificial In- 
telligence, 20, 111-161, 1983. 
21. Muggleton, S., Inductive Logic Programming, New Generation Computing, 8(4), 
295-318, 1991. 
22. Niblett, T., A study of generalization in Logic Programs, Proceedings of the Third 
European Working Session on Learning, Pitman, London, 131-138, 1988. 
23. Nienhuys-Cheng, S.H., van der Laag, P.R.J., van der Torre, L.W.N., Constructing 
refinement operators by decomposing logical implication, in Advances in Artificial 
Intelligence - Proceedings of the Third Congress of the Italian Association for 
Artificial Intelligence AI*IA 93, Lecture Notes in Artificial Intelligence 728, P. 
Torasso (Ed.), Springer-Verlag, Turin, Italy, 178-189, 1993. 
24. Pazzani, M., and Kibler, D., The utility of knowledge in inductive learning, Machine 
Learning 9, 1, 57-94, 1992. 
25. Plotkin, G.D., A Note on Inductive Generalization, in Machine Intelligence 5, B. 
Meltzer and D. Michie (Eds.), 153-163, Edinburgh University Press, 1970. 
26. Quinlan, J. R., Learning Logical Definitions from Relations, Machine Learning 5, 
3, 239-266, 1990. 
27. Quinlan, J. R., Determinate Literals in Inductive Logic Programming, Proceed- 
ings of the llth International Joint. Conference on Artificial Intelligence, Sydney, 
Australia, 746-750, 1991. 
28. Reiter, R., Equality and domain closure in first order databases, Journal of ACM, 
27, 235-249, 1980. 
29. Rissanen, J., A universal prior for integers and estimation by minimum description 
length, Annals of Statistics, 11, 1,416-431, 1983. 
30. Semeraro, G., Brunk, C.A., and Pazzani M.J., Traps and Pitfalls when Learning 
Logical Theories: A Case Study with FOIL and FOCL, Technical Report 93-33, 
Department of Information and Computer Science, University of California, Irvine, 
California, July 26, 1993. 
31. Silverstein, G., and Pazzani, M., Relational cliches: constraining constructive in- 
duction during relational learning, Proceedings of the Eighth International Work- 
shop on Machine Learning, Evanston, Illinois, 203-207, 1991. 
32. VanLehn, K., Efficient Specialization of Relational Concepts, Machine Learning 4, 
1, 99-106, 1989. 
33. Vere, S.A., Multilevel Counterfactuals for Generalizations of Relational Concepts 
and Productions, Artificial Intelligence, 14, t39-164, 1980. 
34. Winston, P.H., Learning Structural Descriptions from Examples, Ph.D. disserta- 
tion, Department of Electrical Engineering, Massachussetts Institute of Technology, 
Cambridge, MA, January 1970. 
35. Wirth, R., and O'Rorke, P., Constraints on Predicate Invention, Proceedings of the 
Eighth International Workshop on Machine Learning, Evanston, Illinois, 457-461, 
1991. 

Propagation of Inter-argument Dependencies in 
"Tuple-distributive" Type Inference Systems 
Christine SOLNON, Michel RUEHEI~ 
I3S, UNSA / CNRS, Route des Colles, B.P. 145, 
06903 Sophia Antipolis Cedex, FRANCE 
e-mail: {solnon,mr } @mimosa.unice.fr 
Abstract. Many type inference systems for Prolog programs are based 
on the tuple-distributive closure abstraction which ignores inter-argument 
dependencies. Thus, dependencies specified by head-only shared vari- 
ables cannot be handled, and the inferred types are often very inac- 
curate. In this paper, we define an unfolding process which propagates 
such inter-argument dependencies: each call to a predicate that contains 
head-only shared variables is replaced by its definition. Hence, depen- 
dencies are actually propagated and the accuracy of the inferred types is 
improved. This unfolding process is repeated until a fix-point is reached 
in the computation of the type system. Termination is ensured by an 
abstraction function which limits the depth of recursive structures. 
1 
Motivations 
Prolog is an untyped language. This provides the programmer with flexibility for 
rapid prototyping, but does not facilitate the debugging, optimization and reuse 
of programs. Hence, different type inference systems have been proposed for 
statically approximating the denotation of Prolog programs. Many of these type 
inference systems are based on the tuple-distributive closure abstraction which 
ignores inter-argument dependencies. For example, [YS87] proposed to define 
types with respect to a fix-point of the abstract immediate consequence operator 
T~. This operator just ignores inter-argument dependencies by computing the 
distributive closure of tuples (i.e., terms and atoms). [Mis84] proposed to infer 
set constraints from a Prolog program in order to approximate its denotation, 
and [HJ92b] showed that a model of these set constraints corresponds to a fix- 
point of the abstract operator T~. [Hei92b] also proposed a type inference system 
based on set constraints like the one of [Mis84]. This type system only ignores 
inter-variable dependencies rather than all inter-argument dependencies and the 
computed types are a bit more accurate. Tuple-distributive types can also be 
computed by using regular unary logic (RUL) programs [FSVY91, GdW94]. 
However, in all these works inter-variable dependencies are ignored. As a 
consequence, types inferred from programs containing head-only shared vari- 
ables are often very inaccurate. A head-only shared variable is a variable which 
occurs more than once in the head of a clause but does not occur in its body. 
Such variables can be seen as type parameters that are universally quantified on 

200 
the Herbrand universe. Hence, we shall say that a predicate is parametric if it 
contains head-only shared variables in its definition. Parametric predicates ex- 
press dependencies (i.e., unification constraints between different occurrences of 
head-only shared variables) that are ignored by tuple-distributive type systems. 
Consider for example the following program PI: 
eq(X,X). 
p(Y) :- eq(Y,1). 
The predicate eq is parametric and the variable X expresses a dependency rela- 
tion between the two arguments of eq/2. The denotation 1 of Pi is 
Ifp(Tp1) : { eq(t,t) / tE Up1 } U { p(1) } 
However, tuple-distributive type inference systems ignore this dependency and 
the computed approximation for P1 is 
{ eq(s,t) 
/ tEUp1 and sEUp1 } U { p(t) / tEUp1 } 
Hence, the type associated with the argument of the predicate p is the Herbrand 
universe and does not bring any significant information 2. 
In order to propagate inter-argument dependencies, we propose to unfold the 
program to be typed with respect to its parametric predicates, i.e., each call to a 
parametric predicate q is replaced by the definition of q. Let us consider again 
the previous program Pl: the predicate p depends on eq which is parametric. 
Thus, we unfold p with respect to eq, and we obtain the new program PI': 
eq(X,X). 
p(1). 
These two programs have a same denotational semantics, but P1 ~ does not con- 
tain any call to parametric predicates, and the dependency constraint specified 
by eel between Y and 1 has been propagated. 
The major problem of this approach remains in the termination of the unfold- 
ing process: in the case of recursive parametric predicates, each unfolding step 
may introduce some new clauses that have to be unfolded again. Hence, we pro- 
pose to perform the unfolding process until the associated type system becomes 
stable, and we introduce an abstraction function to ensure the stabilization of 
the type system. 
The rest of the paper is organized as follows. In section 2, we define the tuple 
distributive closure operator c~ and we present the type inference system which 
1 We note UP1 the Herbrand universe of P1. On this very short program, UPa only 
contains the value 1, but if P1 is part of a program with functional terms, then the 
Herbrand universe is infinite. 
In a more general way, a shared variable in a clause expresses a dependency relation 
that is ignored by the abstraction and that impfies a loss of accuracy. For example, 
if the predicate integer defines a set Int of integers, then the type of the predicate 
"eq_int(X,X) :- integer(X)." is { eq_int(s,t) / sEInt and tEInt }, and the 
type associated with the predicate "p_int(X) :- eq_int(X,1)." is the set Int. 

201 
is used to illustrate our approach. In section 3, we define the unfolding process 
that propagates inter-argument dependencies specified by parametric predicates. 
In section 4, we show that the new inferred types actually approximate the 
denotation of the program. In section 5, we define an abstraction function which 
ensures the termination of the unfolding process. In section 6, we illustrate our 
approach on two examples. Section 7 discusses related works. 
2 
Definitions 
We shall use the following notations, possibly subscripted: 
- f and p respectively denote functional and predicate symbols. 
- t denotes a term. A term is either a constant c, a variable X or a functional 
term f(Q,..., t,~). 
- 
A denotes a logic atom and D a set 3 of atoms. OA denotes the instance of A 
obtained by the substitution 0. (A ~-- D) denotes a Horn clause. 
- P denotes a set of clauses, i.e., a Prolog program. Up and Bp respectively 
denote the Herbrand universe and base of P. Tp is the usual immediate 
consequence operator. Ifp(Tp) is the least fix-point of Tp and corresponds 
to the denotation of P. 
2.1 
Definition of Positions 
Positions are used to refer to sets of terms within sets of atoms, and correspond 
to types. A position, noted r, is either the empty position <> or a sequence like 
p(i) . fl(il) . f2(i2).... 9 fn(in) 
(n > O) 
where 1 < i < arity(p) and Yj E 1..n, 1 <_ ij <_ arity(fj). Intuitively, a position 
7r allows one to refer to a sub-term t in an atom A: in the tree that represents 
A, 7r denotes the path between the root of A and the root of t. We note pos(A) 
the set of all the paths between the root of A and all the nodes and leaves of A. 
If 7r is a position of A, we note AI~ the sub-term of A at position 7r. 
Let us consider, for instance, the atom A = p(cl, f(c2)). This atom defines 
the positions pos(A) = {p(1),p(2),p(2).f(1)}. The sub-term of A at position 
p(1), noted Alp0) is c~, the sub-term of A at position p(2), noted Alp(2), is f(c2) 
and the sub-term of A at position p(2).f(1), noted Alp(2) 10), is c~. 
More formally, the set of positions of an atom or a term is: 
vos(p(tl,..., t,)) = 
/ 
pos(t,)} 
pos(/(tl,..., t,)) = {<>} U Ui"___l{f(i).rr / r e pos(ti)} 
pos(t) = {<>} if t is a variable X or an atomic constant c 
We define the sub-terms of a term or an atom as follows: 
3 As we are only concerned with fix-point semantics, we assume without loss of gen-. 
erality that the body of a clause is a set (rather than a multi-set) of atoms. 

202 
p(tl .... ,tn)lv(i).~ = tilt ifi 6 1..n 
p(ti,...,t,~)b,,(i).,~ = _1_ if pep' 
or i â€¢ 1..n 
f(ti,..., tn)b'(i).~ = tfl,~ if i E 1..n 
f(tt,..., t,)M,(1).~ = _1_ if f r f' or i ~ 1..n 
tl< > = t 
By extension, the set of the sub-terms at position r in a set D of atoms is 
DI. = {AI~ / A E D and 7r E pos(A)} 
2.2 
Definition of the tuple-distributive closure operator 
The tuple-distributive closure operator, noted o~, approximates a set S of tuples 
by ignoring dependencies between arguments of tuples as follows: 
o~(S) ={e / c E S} O {f(ti, ..., t=) / Vi E 1..n, ti E a(SM(i)) } 
For example, co({/(1, 2), f(3, 4)}) - {f(1, 2), f(1, 4), f(3, 2), f(3, 4)}. 
The abstract operator T g is defined by the composition of a with the imme- 
diate consequence operator Tp, i.e., Tfi = c~oTp. The least fix-point of Tfi, noted 
lfp(T~), approximates the denotation of the program by ignoring inter-argument 
dependencies. This set is an interesting basis for defining types [YS87]. 
2.3 
The type inference system 
We have defined in [SP~94] a type inference system that is more particularly 
suited to analyse uncomplete Prolog programs. This type inference system ig- 
nores inter-argument dependencies and we shall use it to illustrate our approach. 
This system is based on the inference of a collection of equations that describes 
set relationships that hold between terms of the program. A set equation looks 
like < 7r = E > where the position rr denotes a type, and E is a set expression: 
z ::= c I T I â€¢ ( ~ I I(E1 x ... â€¢ Er) I E1 u Z2 I E1 n E2 I El~ 
Inference of set equations. Let be P = Uin_i{Ai *--- Di} a Prolog program, and 
pos(P) = U~=~ pos({Ai} U Di) the set of positions defined by P. The collection 
of set equations inferred from P is type(P): 
tupe(P) = (< ~ = L] e~p(~, i) > / ~ e pos(P) } 
i=l 
where ezp(Tr, i) is the set expression associated with the position 7r in the i th 
clause (Ai *--- Di) of P. It is computed by using the following rules: 
(1) - exp(r, i) = c 
if Ailx =- c 
(2)- exp(r,i) = f(~r.f(1) x ... x 7r.f(r)) if A~ I, = f(tl .... ,tr) 
(3) - ezp(Tr, i) = T 
if Ail~r _.-': X and VTr' E pos(Di), X q~ Dill, 
(4) - ezp(Tr, i) = rl n... I-1 rrr if Ail~ = X and {Tri,..., 7rr} = {r' / X E Dill,} ~ 0 
(5) - ezp(r, i) = ezp(Trl, i)l~ 2 
if Ail~ = 2 and 3,'r 1 / r = 7rl.r2 and Ailr~ = X 
(6) - ezp(rr, i) = I 
if Ail~ = .L and Vrl / r = rl.r2, Ailxt r X 

203 
Rules (1) to (4) respectively define the set expression associated with an atomic 
constant, a functional term, a head-only variable and a head and body variable. 
Rule (5) states that if there exists a prefix ri of 7r such that the subterm at 
position 7ri in Ai is a variable, then the set expression associated with 7r is 
a projection onto the set expression associated with ~'l. For example, the set 
expression associated with p(1).f(1) in the clause p(X) :- q(X) is q(1)lf(1 ). 
Finally rule (6) associates _1_ with a position which is not defined in the head 
atom of the clause. 
Solution of a system of equations. An interpretation Z of a system of equations 
type(P) is a mapping from the set of positions pos(P) to the set of subsets of 
the Herbrand universe Up. I is extended to set expressions as follows: 
/(T) = Up 
Z(.L) = 
Z(c) = {e} 
Z(I(E1 x ... x Er)) = {/(tl,..., tr) / t~ ~ Z(Ei)} 
Z(E, u E~) = ~(Z(E~) u Z(E2)) 
Z(Ei [7 E2) : Z(E1) n Z(E2) 
Z(E~) : Z(E) I. 
A solution of a type system type(P) is an interpretation Z such that Z(Tr) = Z(E) 
for all equation < a- = E > of type(P). The least solution Z of a type system 
type(P) corresponds 4 to the least fix-point of T g, i.e., for each position ~" of 
pos( P), Z(r = lfp(T~)l~. 
One can remark that U is distributive with respect to x (i.e., Z(E1 U E2) = 
a(Z(E1) U2"(E2))). Thus, the least solution of a type system exactly corresponds 
to lfp(T~). This property facilitates some proofs, in particular for characterizing 
the meaning of an unfolded program. However, one could define U as a non- 
distributive operator with respect to x (i.e., Z(E1 U E2) = Z(E1) U Z(E2)). In 
this case, the least solution of a type system is a subset of lfp(T~), and the 
unfolding process can be applied in a same way. 
The least solution of a type system can be "computed", i.e., set constraints 
can be transformed in an explicit form which is a regular tree description of the 
least model [H J90, Hei92a] 
Ezample. Let us consider the program P described in Fig. 1. 
s(a,b). 
s(b,c). 
s(a,d). 
s*(X,X). 
s*(X,Z) :- s(X,Y), s*(Y,Z). 
t(X) :- s*(b,X). 
Fig. 1. Program P 
4 This property only holds for "non-redundant" programs [HJ92a]: a program P is 
non-redundant if for each clause (A ,-- D), there exists a substitution 0 such that 
9D C /]p(T~). 

204 
The set of equations inferred from this program is: 
type(P) : { s(1) : a U b, 
s(2) : b U c U d, 
The least model of these equations is Z: 
Z(s(1)) 
: { a, b } 
Z(s(2)) : { b, c, d } 
s*(1) : 
T 
U s(1), 
s*(2) : 
T 
U s*(2), 
t(1) 
: 
s*(2) 
} 
I(s*(i)) 
= up 
Z(s*(2)) = up 
I(t(1)) 
= up 
Comparison of sel expressions. This type inference system has been designed in 
order to analyse uncomplete Prolog programs. The goal is to extract informations 
from the definition of some predicates and independently from the definition of 
some other predicates that are (not yet) defined or that are not relevant. Hence, 
we have defined a system that deduces subtyping relationships from set equations- 
without resolving them. These relationships do not depend on the interpretation 
of the undefined predicates [SR94]. For example, from the predicate "p(X) "- 
q(X), r(X) .", and independently from the definition of the predicates q and r, 
we infer that p(1) is a subtype of both q(1) and r(1). 
3 
Definition of the unfolding 
process 
The type inference system described in the previous section ignores all inter- 
argument dependencies. In particular, dependencies expressed by head-only sha- 
red variables are ignored. As a consequence, predicates defined with respect to 
parametric predicates are not accurately approximated at all by this type in- 
ference system. For example, on the program of Fig. 1 the dependency between 
s*(1) and s*(2) is lost and the type associated with t(1) is the Herbrand 
universe whereas the denotation of t is {t(b), 1;(c)}. Conversely, one should 
remark that the types associated with parametric predicates are often very rele- 
vant. For instance, in the program of Fig. 1, any term of the Herbrand universe 
can be instance of the first and the second argument of the predicate s*. Thus 
the computed types s*(1) and s*(2) exactly correspond to the denotation of 
s*. Actually, the problem is not to approximate parametric predicates but to 
approximate predicates defined with respect to parametric predicates. 
Thus, we propose to propagate inter-argument dependencies due to head- 
only shared variables before inferring types. We note P the Prolog program to 
be typed, and we consider the partition P = Q u R so that Q (resp. R) is the 
set of clauses of P that define parametric (resp. non parametric) predicates. 
We define unfold(R), the unfolding of R with respect to Q, as follows 
unfold(R) = {(A ~-- D) E R / all atoms of D correspond to predicates of R} 
LJ {(OA ~-- O(DR 0 D' 1 U...U D')) / 
(A ~ D) 9 R and D = DR U {A1,...,Am} 
and Vi 9 1..n, 3(A~ ~-- D~) 9 Q and 
= mgu(A1, dl) o...o mgu(A,,, A')) 

205 
where DR U {A1,...,An} is the partition of D such that each atom of DR is 
instance of a predicate of R and each Ai is instance of a predicate of Q. 
We note R, the program resulting of n unfolding steps of R with respect to Q: 
R0 = R and Rn -: unfold(R,,_t) (n > O) 
We note R~ the set of clauses of Rn that do not depend on Q: 
R" = {(A ~-- D) E R~ / all atoms of D correspond to predicates of R} 
Definition. To propagate inter-argument dependencies specified by parametric 
predicates, the idea is to unfold R with respect to Q until the type system 
associated with R~n becomes stable. Hence, the type system associated with R is 
tupe(R') 
if fo~ aU positive k, type( n" ) = ~ype( R',+~). 
The equality between two systems of equations type(R~) and type(R~+k) is 
a syntactical one. It is established with respect to the idempotence, associativity 
and commutativity of U and fq. 
Example. Let us consider again the program P of Fig. 1. The predicate s* is 
parametric. We note Q the set of clauses defining s* and R the set of clauses 
defining s and t. The successive unfolding steps of R with respect to Q are: 
R~ = { s(a,b)., 
s(b,c)., 
s(a,d)., 
t(b). 
} 
R1 : R~ U { t(Z) :- s(b,Y), s*(Y,Z). } 
R~ = R~ U { t(Y) 
:- s(b,Y). 
} 
R2 = R~ D { t(Z) :- s(b,Y), s(Y,Y1), s*(YI,Z).} 
R~ = R~ u { t(Y) 
R3 : R~U { t(z) 
:- s(b,Y1), s(YI,Y). } 
:- s(b,Y), s(Y,YI), s(YI,Y2), s*(Y2,Z).} 
and the successive inferred set equations for t (1) are 
type(n~) 
= { t(1) = b } O .. 
type(R~) = { t(1) = b U s(2) } U ... 
typo(R~) = { t(1) = b Ll s(2) U s(2) } U ... 
= type(R~) = type(R'~) (n>2) 
Thus, the final type system associated with R is type(R~), and the least model 
2: associated with t(1) is/:(t(1)) = {b, c, d}. This should be compared with 
the type system type(P) which associates the Herbrand universe to t(1). 
4 
Semantics 
of type(R',~) 
The termination of the unfolding process is studied in section 5. In this sec- 
tion, we suppose that there exists an n such that for all positive k, type(R~) = 
type(R'+k ). The least solution of type(R~) corresponds to the set lfp(T~, ). In 

206 
this section, we define this set by means of the initial program P. In particular, 
we show that lfp(T~, ) actually approximates the denotation of P. As the un- 
folding process does not modify Q, we only focus on the semantics of the types 
of the predicates of R. We shall note BR the subset of the Herbrand base Be 
corresponding to the predicates of R, and we shall note lfp(Te) f3 BR the subset 
of the denotation of P corresponding to the predicates of R. 
Theorem 1. The inferred types approximate the denotation of P, i.e., 
Vk > O, lfp(T~, ) = lfp(T~,+k) ~ 
lfp(T~, ) D lfp(Tp) N BB 
Proof. see appendix A. 
Definition of Sp and Sp.. To define the semantics of the inferred set lfp(T~,) 
with respect to the initial program P, we introduce a new immediate consequence- 
operator Sp which only computes the tuple distributive closure for the non 
parametric predicates of P (i.e., on R): 
Se(1) = T~(I) U ~(Ta(I)) 
In a same way, we define the immediate consequence operator Sp, associated 
with the i th unfolding step of R with respect to Q: 
Sp,(I) = TO(I) U a(TR,(I)) 
We note Ifp(Sp) and lfp(Sp,) the least fix-points associated with Sp and Sp~. 
Theorem 2. lfp(Sp) better approximates the denotation of P than lfp(T~), i.e., 
lfp(Tv) c lfp(Sp) c Ifp(T?,) 
proof. One can easily check that VI C_ Be, Tp(I) C_ Sp(I) C TF,(I ). 
Theorem 3. The unfolding process preserves the least fix-point of Sp, i.e., 
lfp(Se) = lfp(Se,) Vi > 0 
Proof. see appendix B. 
Theorem 4. The inferred set lfp(T~; ) is a subset of the least fix-point of Sp: 
Vk >O, lfp(T~, )= Ifp(T~,+k) =r lfp(T~, ) C lfp(Se) 
Proof. By definition, Sp(I) = Sp.(I) = Tq(1)Ua(Tn.(1)) and R'~ _C R,~. Thus, 
a(Tn, (1)) C_ a(Tn.(I)) C_ Sp(I) and therefore, lfp(T~, ) C_ lfp(Sp). 

207 
Ezarnple: On the program P of Fig. 1, we compute the following sets: 
I/p(Tp) -- { s(a,b), s(a,d), s(b,c), 
t(b), t(c), 
s*(a,b), s*(b,c), s*(a,d), s*(a,c) } U 
s*(X,X) / X6Up } 
Ifp(Sp) 
= { s(a,b), s(a,c), s(a,d), s(b,b), s(b,c), s(b,d), 
t(b), t(c), t(d), 
s*(a,b), s*(a,c), s*(a,d), s*(b,b), s*(b,c), s*(b,d) } U 
{ s.(X,X) / xeue } 
ljfp (T~,) = { s(a,b), s(a,c), s(a,d), s(b,b), s(b,c), s(b,d) } U 
{ t(x) / xevp ) u 
{ s,(x,Y) / xeue, YEUp } 
The set lfp(T~) corresponds to the least solution of type(P). Considering this 
set, the type of t (1) is the whole Herbrand universe. However, after performing 
the unfolding process, the least solution of type(R') is bounded by lfp(Sp). In 
this new set, the type of t (1) is {b, c, d}, which much better approximates the 
denotation of t than does the corresponding type in lfp(T~). 
5 
Stabilization 
of the unfolding 
process 
The unfolding process defined in section 3 terminates if there exists a step n 
so that type(R~) is equal to type(R~+k) for all positive k. In this section, we 
study the conditions of such a stabilization. In a first time, we show that the 
type system cannot become stable if the unfolding process introduces terms of 
increasing depth. Then we define an abstraction function .4 which limits the 
depth of types and ensures a stabilization. 
5.1 
Definition of recursive positions 
The unfolding process is increasing, i.e., for all positive i, R~ C_ R~+ 1. Hence, 
one will finitely reach a fix-point if the number of different type systems that 
can be inferred from the successive unfolded programs R~, R~,..., R~ is finite, 
i.e., if the number of different constants, functors and positions generated by the 
unfolding process is finite. However, an infinite number of different positions can 
be generated by unfolding. Let us consider for example the following program 
P=QUR: 
O: mb(X,cons(X,L)). 
mb(X,cons(Y,L)) 
:- mb(X,L). 
R: p(Z) :- mb(a,Z). 
The predicate mb defines a recursive structure (i.e., cons/2), and the depth of 
the argument of the predicate p increases at each unfolding step: 

208 
R~ : { p(cons(a,L)). 
} 
R~ : R~ U { p(cons(Xl,cons(a,L))). 
} 
R~ = R~U 
{ p(cons(X2, cons(Xl,cons(a,L)))). 
} 
Hence, each unfolding step introduces two new positionsS: 
pos(R~) = { p(i), p(1).cons(1), p(1).cons(2) }, 
pos(R~) = pos(R~_t)[ {p(1).{cons(2)} i-l.cons(1), p(1).{cons(2)} i} 
and the type system never becomes stable, i.e., type(R~) # type(/~+1) for all i. In 
this example, the recursive call occurs on the second argument of the functional 
term cons. Hence, we shall say that cons(2) is a recursive position. 
In a general way, the number of positions can become infinite by unfolding 
if Q contains a recursive predicate (or mutually recursive predicates) which in- 
finitely introduces terms of increasing depth9 The sub-position corresponding to 
growing parts of terms is called a recursive position. 
Static identification of recursive positions9 Some recursive positions can be iden- 
tified by comparing positions of variables that both occur in the head and in the 
recursive call of a clause. For example, let us consider the predicate rev: 
rev(nil,L,L). 
rev(f(X,f(Y,L)),Res,Acc) 
:- rev(L,Res,g(X,Acc)). 
This predicate uses an accumulator g to reverse the elements at even positions in 
a list f (e.g., rev(f(4,f(3,f(2,f(1,nil)))),nil,g(2,g(4,nil))) 
is a logical 
consequence of this program). The variable L occurs in the head atom at position 
rev(1).f(2).f(2) and in the body at position rev(2). By comparing these 
two positions, we identify the recursive position f(2).f(2). In a same way, 
the variable Ace occurs at position rev(3) in the head atom and at position 
rev(3) .g(2) in the body and g(2) is a recursive position. In a more general 
way, we can identify the recursive positions defined by a recursive parametric 
predicate p if p does not depend on some other recursive parametric predicates. 
Otherwise, recursive positions have to be dynamically identified. 
Dynamic identification of recursive positions. Recursive positions can be iden- 
tified during the unfolding process by comparing new positions introduced by 
unfolding with existing ones. The growing part in a new position may be a recur- 
sive position. Hence, a superset of recursive positions can be identified at each 
unfolding step n as follows: 
rec - pos = 
/ 
e pos(R;) and 
r pos(n _ ) and 
pos(R;_l)) 
i=1 
rec-pos is a superset of the recursive positions as a position may grow at one 
step and then becomes stable. To improve the accuracy, this set can be defined 
by considering sub-positions that have been repeated k times rather than once. 
s Notation: {Tr}" = ~.{:r}"-' if n > 1, {Tr} 1 = 7r. 

209 
5.2 
Definition of the .A abstraction 
If there is no recursive position, the number of positions is finite by unfolding, 
and therefore the unfolding process terminates. Otherwise, the unfolding pro- 
cess introduces an infinite number of different positions and no fix-point will be 
reached. We now define an abstraction function ,4 which ensures the termination 
in this case. For example, let us consider again the program P = Q u R: 
q: mb(X,cons(X,L)). 
R: p(Z) :-mb(a,Z), 
mb(X,cons(Y,L)) :- mb(X,L). 
The unfolding process introduces a recursive position cons (2) and therefore an 
infinite number of different positions 
p(1).cons(1), p(1).cons(2).cons(1) .... , p(1).{cons(2)}~.cons(l) .... 
These different positions all correspond to the single notion of "member of the list 
Z". Hence, to limit the number of positions generated by the unfolding process, 
the idea is to approximate all these different positions by the single abstract 
position p(1), cons(1). This abstract position is defined by the union of all set 
expressions associated with all concrete positions p ( l ) {. cons (2) }i. cons (I). 
Abstract positions. Each concrete position 7r is approximated by the abstract 
position A(Tr) which is obtained by "removing" from 7r the recursive positions: 
.4(<>) 
= <>, 
,A(Tr I .?r2) : 
.A(7r2) if 71" 1 is a recursive position 
A(f(i).Tr) = f(i).A(Tr) if no recursive position 7ri is prefix of f(i)Jr 
With each abstract position rr, we associate the set C(a') of concrete positions: 
C(Tr) = {7c' E pos(P) / A(7c') = 7r} 
Abstract set expressions. 
A(T) = T 
x(â€¢ 
= â€¢ 
A(e) = c 
.4 is extended to set expressions as follows: 
.A(f(Ei x... x E,)) = f(.A(E1) x... x .A(E,)) 
A(E1 U E2) = A(E1) U A(E~) 
A(Ei n E2) = A(Ei) n A(E~) 
A(Ej,) = A(E)p4(~) 
Abstract type systems. The abstract type system type.a(P) that describes all 
abstract positions associated with a program P = U~=i(Ai *--- Di) is: 
type.4(P) = {< ~- = 
U 
U~= i A(ezp(r',i)) > / 7c E A(pos(P))} 
~'ec(Tr) 
Definition. The type system associated with R is type.a(R~)) such that for all 
positive k, type.4(R~) = $ype.~(R~+k). 

210 
Theorem 5. The abstract type system is a correct approximation of the concrete 
one, i.e., ifZ and ZA respectively are the least solutions of type(P) and type.4(P), 
then for each concrete position 7r of pos(P), E(Tr) _C 27~(A(Tr)). 
Proof. In typeA(P), A(Tr) is defined by the union of all abstract expression 
.A(E) such that E is the set expression associated with a concrete position 
r' E C(A(Tr)) ~ {rr}. Then, one can easily check by induction that for any 
set expression E, we have Z(E) C E(A(E)). 
Theorem 6. The unfolding process terminates, i.e., there exists n such that for 
all positive k, typea ( R~ ) = type,4( R~+k). 
Proof. The set of different positions that can be generated by the unfolding pro- 
cess is limited by the A abstraction. Therefore, the number of different abstract 
type systems associated with the successive unfolding steps is finite. 
6 
Examples 
We illustrate in this section the relevance of the inferred types on two rather 
small but representative programs. 
Example 1: let be the program 
R: p(X) :- q(L1), s(L2), append(L1,L2,L3), member(X,L3). 
q(cons(a,cons(b,nil))). 
s(cons(c,cons(d,cons(e,nil)))). 
Q: append(nil,L,L). 
append(cons(X,L1),L2,cons(X,L3)) :- append(L1,L2,L3). 
member(X,cons(Z,L)). 
member(X,cons(Y,L)) :- member(X,L). 
q defines the recursive position cons(2). The abstract type system becomes 
stable at the second unfolding step and is: 
p(I) = s(i).cons(1) U q(1).c0ns(1) 
q(1) = cons(q(1).cons(1)â€¢ 
U nil 
s(1) = cons(s(1).cons(1)â€¢ 
U nil 
q(1).cons(1) = a u b 
s(1).cons(1) = c U d U e 
After resolution of the equations, the type of the argument of p is 27(p(1)) = 
{a, b, c, d, e}. However, before unfolding, the type associated with p(1) was 
the herbrand universe (as it was defined with respect to member(l)). 

211 
Example 2: Let be the program: 
R: p(LI,L2) :- rev(Ll,nil,L2). 
Q: rev(nil,L,L). 
rev(f(X,f(Y,L)),Acc,Res) :- rev(L,g(X,Acc),Res). 
Q defines the recursive positions f (2). f (2) and g(2) (see section 5.1). The type 
system becomes stable at the third unfolding step and is: 
p(1) -- nil U f(p(t).f(1) â€¢ p(1).f(2) ) 
p(1).f(1) = T 
p(1).f(2) 
= f(p(1).f(2).f(1) 
â€¢ p(1) ) 
p(1).f(2).f(1) 
= T 
p(2) = nil U g(p(2).g(1) â€¢ p(2) ) 
p(2).g(1) = T 
The least model of this type system is I: 
~(p(1)) 
= { nil, f(Up,f(Up,t)) / t~Z(p(1)) 
} 
I(p(2)) = { nil, g(Up,t) / te/:(p(2)) } 
Before unfolding, the type associated with p(2) was the herbrand universe (as 
it was defined with respect to the type of the third argument of rev). 
7 
Related works 
Different solutions have been proposed to extend tuple-distributive type infer- 
ence systems so that they can take into account parametric polymorphism. For 
example, [Zob87] proposed to parameterize the types by "type variables", and 
[PR89] proposed to use "conditional types" to express and propagate dependency 
constraints. However, the resulting types do not allow an intuitive understand- 
ing of the underlying structure and they are not easy to handle. Moreover, the 
comparison of parametric types is still an open problem [DZ92]. Our approach 
is rather opposite to this one: instead of modifying the type system so that it 
can handle inter-argument dependencies, we propose to propagate dependencies 
before inferring types. 
A comparable approach to ours has been proposed in [HJ92a]. The idea is 
to unfold abstract semantic equations inferred from Prolog programs until a fix- 
point is reached. To obtain a terminating algorithm, this process is curtailed 
by introducing an abstraction. This algorithm is generic as it can be used by 
an inference system based on any abstract interpretation (top-down or bottom- 
up) using set constraints. However, the abstraction function which ensures the 
termination has to be defined by the programmer. This abstraction function is 
quite easy to define if one wants to deduce "simple" informations like modes. 
However, if one wants to infer precise types, the definition of this abstraction 
requires to know rather precisely what kind of structures are manipulated by 
the program, and this is just the goal of type inference. 
Gallagher and de Wall [GdW94] defined a bottom up algorithm to compute 
a regular approximation of a logic program. The idea is to combine a tuple dis- 
tributive closure abstraction (which ignores inter-argument dependencies) with 

212 
a shortening operator which ensures the termination and the efficiency of the 
computation. In order to improve the precision of the approximation, top-down 
computation is simulated through query-answer transformations. This kind of 
"magic set" style transformations improves the accuracy of the approximation 
by restricting the calls that can occur with respect to a particular goal and it 
takes into account some inter-argument dependencies. 
Some other type inference systems are based on abstract interpretation of 
top-down operational semantics of Prolog (e.g., [Bru91, KK93, HCC93]). The 
abstraction is introduced both to ensure the termination and to improve the 
efficiency of the computation, and it highly depends on the kind of information to 
be inferred. In these approaches, argument dependencies can easily be captured 
by the operational resolution, eventhough they are often ignored for efficiency 
reasons. The inferred informations are not formally characterized and depend 
on the choices made in the abstract domain. These approaches usually aim at 
extracting run time informations (e.g., modes, variable sharing) for a given set 
of goals in order to design an effective compiler. 
8 
Discussion 
We have defined an unfolding process which propagates inter-argument depen- 
dencies specified by shared head-only variables, and thus improves the accuracy 
of a type inference system based on the a abstraction. In order to ensure the 
termination of this process, we have introduced another abstraction function A 
which approximates different concrete types by a single abstract one. These dif- 
ferent concrete types correspond to successive arguments of recursive predicates 
and they are semantically very closed (e.g., the different elements of a binary 
list). Hence, the abstract type system is a relevant approximation of the concrete 
one. 
Actually, the two abstractions a and A are rather complementary in their 
effects: the a abstraction is used to limit the breadth of types (e.g., a({ f(a,b), 
:f(a,d), :f(c,d) }) is { f({a,c},{b,d}) }), while theA abstraction is intro- 
duced to limit the depth of types (e.g.,.A({ f(a,f(b,f(c,nil))) 
}) is X = { 
nil, f({a,b,c},X) }). We argue that these two abstraction functions are both 
necessary for an accurate and e]ficient approximation. 
The A abstraction can be compared with the widening operator used in some 
type inference systems based on abstract interpretation of top-down execution of 
logic programs (e.g., [HCC93]) or with the shortening operator used in [GdW94], 
Actually, these operators are introduced to ensure the termination of a fix-point 
computation, and they limit the depth of abstract structures in a similar way 
than does the ,4 abstraction. 
Acknowledgements: Many thanks to Patrice Boizumault for carefully reading a 
first version of this paper and to Andreas Podelski for numerous and enriching 
discussions on this work. 

213 
References 
[HCC93] 
[HeigZa] 
[Hei92b] 
[H J90] 
[HJ92a] 
[HJ92b] 
[KK93] 
[Mis84] 
[PR.89] 
[SR94] 
[TS84] 
[YS87] 
[Zob871 
[Bru91] 
M. Bruynooghe. A practical framework for the abstract interpretation of 
logic programs. Journal of Logic Programming, 10:91-124, 1991. 
[DZ92] 
P.W. Dart and J. Zobel. A regular type language for logic programs. In 
Frank Pfenning, editor, Types in Logic Programming, pages 157-187, 1992. 
[FSVY91] T. Fruhwirth, E. Shapiro, M.Y. Vardi, and E. Yardeni. Logic programs as 
types for logic programs. In IEEE-LICS, pages 300-309, 1991. 
[GdW94] J.P. Gallagher and D.A. de Waal. Fast and precise regular approximations 
for logic programs. In ICLP, 1994. 
P. Van Hentenrick, A. Cortes, and B. Le Charher. Type analysis of prolog 
using type graphs. Technical report, 1993. 
N. Heintze. Practical aspects of set based analysis. In Joint Int. Conf. 8J 
Syrup. on Logic Programming, 1992. 
N. Heintze. Set based program analysis. Phd thesis, School of Computer 
Science - Carnegie Mellon University, 1992. 
N. Heintze and J. Jaffar. A decision procedure for a class of set constraints. 
In IEEE-LICS'90, pages 42-51, 1990. 
N. Heintze and J. Jaffar. An engine for logic program analysis. In 1EEE- 
LICS, 1992. 
N. Heintze and J. Jaffar. Semantic types for logic programs. In Frank Pfen- 
ning, editor, Types in Logic Programming, pages 141-151, 1992. 
T. Kanamori and T. Kawamura. Abstract interpretation based on OLDT 
resolution. Journal of Logic Programming, 15:1-30, 1993. 
P. Mishra. 
Towards a theory of types in Prolog. In International Logic 
Programming Symposium, Atlantic City, pages 289-298, 1984. 
C. Pyo and U.S. Reddy. Inference of polymorphic types for logic programs. 
In Logic Programming North American Conference, pages 1115-1132, 1989. 
C. Solnon and M. Rueher. Deduction of inheritance hierarchies from Prolog 
programs via set constraints. Research report, 1994. 
H. Tamaki and T. Sato. Unfold/fold transformation of logic programs. In 
2nd ICLP, pages 127-138, 1984. 
E. Yardeni and E. Shapiro. A type system for logic programs. In E. Shapiro, 
editor, Concurrent Prolog- Collected papers - Vol. 2, pages 211-244. MIT 
Press Series in Logic Programming, 1987. 
J. Zobel. Derivation of polymorphic types for Prolog programs. In 4th ICLP, 
pages 817-838, 1987. 
A 
Proof of theorem 
1 
Let us show by induction on i that: Vi, (Tp T i) n Bn C lfp(T~, ) 
9 Tp T 0 N BR _C/]p(T~,) as any clause (A *--) of R is also a clause of R'. 
9 Let us suppose that (Tp 1" i) f3 Bn C/]p(T~,) and let us show that 
A e (Te T i + 1) n BR =~ A e @(T~;): 
A E (Tp I i+l) 
f3Bn imphes that there exists a clause (A i *-- Dj) of R and a 
substitution 0 such that OAt = A and ODj C_ Tp T i. Let be D i = Dcj O Da3 the 
partition of Dj such that ODQa C_ BQ and ODai C BR. 
- IfDQi = 0 then (Aa ,- Dj) E R'. AsODj C_ Tp T inBn C_ lfp(T~,), A q lfp(T~,). 

214 
- Otherwise, OD~3 C Tp ~ i implies that there exists an SLD-derivation, from 8D~j 
to D', that only uses clauses of Q and such that D' C (Tp T i) n Ba. 
As the unfolding process corresponds to a breadth first search, there exists an 
unfolding step s such that (I?Aj *--- D' t3 8Daj) is an instance of a clause of R'~. 
 9  
9 Otherwise, as the type system is stable at step n, lfp(T~;) = lfp(T~, ). 
In both cases, D' t3 8DR~ C (Tp ~ i) ~ Bn C. Ifp(T~, ), and therefore A 9 lfp(T~,,, ). 
B 
Proof 
of theorem 
2 
* Let us prove by induction on j that: Vj > O, Sp, "f j C_ lfp(SPi+ 1 ) 
- 
Sp, T 0 C l]p(Sp~+,) as any clause (A *--) of Ri also belongs to unfold( R~ ). 
- 
Let us suppose that Sp, ~ j C lfp(Sp~+,) and let us show that 
Sp, ~ j + 1 C lfp(Sp~+, ), i.e., that Tq(Sp, ~ j) U oz(TR,(Sp~ ~ j)) C lfp(Sp,+~). 
TQ(Sp, T J) C lfp(Sp,+,) as unfolding does not modify clauses of Q. 
Thus, let us first show that A E Tn, (Sp~ T J) ~ A E lfp(Sp~+~ ): 
9 A E Tn,(SP~ T J) implies that there exists a clause (A' ~ D') of Ri and a 
substitution 8 such that 0A' = A and/?D' C Sp~ T J- Let be D' = D 0 U D~ 
the partition of D' such that/~D~ C BQ and 8D~ C Bn. 
9 If D~ = 0 then (d' ~-- D') E unfold(R,), and thus d 9 Ifp(Sp,+ 1 ) 
9 Otherwise, let be D 0 = {d~,..., d~}. As 8D~ g Sp, ]" j, there exists for each 
k in 1..n, a claus e (Ak ~ Dk) of Q and a substitution 8k such that 8kAk = 8A~ 
and 8kDk C_ Spi 1" j. Thus, the clause (SA' ~-- 8D~othDi t3... O 8kDk) is an 
instance of a clause of unfold(Ri) and A belongs to lfp(Sp,+~). 
Hence, TR, (Sp~ T J) C lfp(Sp,+, ) f3 Bn. Then, as lfp(Sp,+~ ) N BR is closed with 
respect to ~ and a preserves inclusion relations, a(TR, (Sp~ T J)) c Ifp(Sp,+~)NBR. 
Thus, TQ(Sp, T J) U a(TR,(Sp, T J)) = Sp, T J + 1 C_ lfp(Sv~+,) 
9 Let us prove by induction on j that: Vj > 0, Sp,+~ T J C lfp(Sp,) 
- Let us show that Sp,+, t 0 = T~(I~) t3a(T~,+~(O)) C lfp(Sp~): 
- T~(~) c_ S~, t 0 ___ ~Ip(S~,) 
- T~,+, (0) C Ifp(Tp) n Bn as unfolding preserves the denotation [TS84]. Thus, 
c~(T~,+~ (0)) C a(lfp(Tv) f3 BR) C lfp(Se,). 
- 
Let us suppose that Sp,+~ ~ j C lfp(Sp,) and let us show that 
Sp~+, ~ j + 1 C lfp(Sp,), i.e., that TQ(Sp,+~ ~ j)t_J a(Tg,+,(Sp,+, T J)) c lfp(Sp,). 
TQ(SPi+~ T J) ~ lfp(Spi) as unfolding does not modify clauses of Q. 
Thus, let us first show that A 9 T~,+~(Sp~+~ "f j) ~ A 9 lfp(Sp,): 
9 A 9 T~,+, (Sp,+~ ~ j) implies that there exists a clause (A' ,--- D') of unfold(Ri) 
and a substitution 8 such that 8A' = A and tgD' C_ Sp.+~ ~ j. 
9 If (A' ~ D') is also a clause of R~, then A belongs to lfp(Sp,). 
Otherwise, (A' ~-- D') has been generated by unfolding a clause of Ri with 
respect to Q, i.e., there exists a clause (A" ~ D~ U {A~' .... , A"}) of R, and 
for each k in 1..n, there exists a clause (A~ ,-- D[) of Q and a substitution 
8' = mgu( A T, A ~ ) o... o mgu( A~, A~ ) such that O' A " = A' and D' = 8'(D~ U 
D~ tJ... U O~). As t~D' C Sp~+I "[ j C lfp(Sp,), for each k in 1..n, 8 o 8'D~ C 
lfp(Sp, ), and therefore, 0 o O'A'~ C_ lfp(Se, ). Thus, A belongs to lfp(Sp, ). 
Hence, Ta,+t(Sp,+~ ~ j) C lfp(Sp,)nBa and a(T~,+t(Sp,+, T J)) c_ lfp(Sp,)~BR. 
Therefore, TQ(Sp,+, ~ j) Uo~(Ta,+,(Sp,+~ T J)) = Sp,+~ T J + 1 C lfp(Sp~) 

Logic Programming and Logic Grammars with 
First-order Continuations 
Paul Tarau 1 and Veronica Dahl ~ 
1 Universit~ de Moncton 
D~partement d'Informatique 
Moncton, N.B. Canada E1A 3E9, 
t arau@info.umoncton.ca 
Logic Programming Group 
Department of Computing Sciences 
Simon Fraser University 
Burnaby, B.C. Canada V5A 1S6 
veronica@cs.sfu.ca 
Abstract. Continuation passing binarization and specialization of the 
WAM to binary logic programs have been proven practical implementa- 
tion techniques in the BinProlog system. In this paper we investigate the 
additional benefits of having first order continuations at source level. We 
devise a convenient way to manipulate them by introducing multiple- 
headed clauses which give direct access to continuations at source-level. 
We discuss the connections with various logic grammars, give examples 
of typical problem solving tasks and show how looking at the future of 
computation can improve expressiveness and describe complex control 
mechanisms without leaving the framework of binary definite programs. 
Keywords: continuation passing binary logic programs, logic grammars, 
program transformation based compilation, continuations as first order 
objects, logic programming with continuations. 
1 
Introduction 
From its very inception, logic programming has cross-fertilized with computa- 
tional linguistics in very productive ways. Indeed, logic programming itself grew 
from the automatic deduction needs of a question-answering system in French [7]. 
Over the years we have seen other interesting instances of this close-relatedness. 
The idea of continuations, developed in the field of denotational semantics [22] 
and functional programming [27, 26] has found its way into programming appli- 
cations, and has in particular been useful recently in logic programming. 
In this article we continue this tradition by adapting to logic programming 
with continuations some of the techniques that were developed in logic gram- 
mars for computational linguistic applications. In particular, logic grammars 
have been augmented by allowing extra symbols and meta-symbols in the left 
hand sides of rules [6, 17, 9]. Such extensions allow for straightforward expres- 
sions of contextual information, in terms of which many interesting linguistic 
phenomena have been described. We show that such techniques can be effi- 
ciently transfered to continuation passing binary programs, that their addition 

216 
motivates an interesting style of programming for applications other than lin- 
guistic ones, and that introducing continuations in logic grammars with multiple 
left-hand-side symbols motivates in turn novel styles of bottom-up and mixed 
parsing, while increasing efficiency. 
2 
Motivation 
Several attempts to enhance the expressiveness of logic programming have been 
made over the years. These efforts range from simply providing handy notational 
variants, as in DCGs, to implementing sophisticated new frameworks, such as 
HiLog [5, 29]. 
In AProlog for instance [14, 15] there is a nice facility, that of scoping of 
clauses, which is provided by the 2Prolog incarnation of the intuitionistic rule 
for implication introduction: 
~ ; P F F ::~ C 
Example 1 For instance, in the AProlog program 3: 
insert X Xs Ys "- 
paste X => ins Xs Ys. 
ins Ys [XlYs] 
:- paste X. 
ins [YIYs] [YlZs]:- ins Ys Zs. 
used to nondeterministically insert an element in a list, the unit clause paste X 
is available only within the scope of the derivation for ins. 
With respect to the corresponding Prolog program we are working with a 
simpler formulation in which the element to be inserted does not have to perco- 
late as dead weight throughout each step of the computation, only to be used in 
the very last step. We instead clearly isolate it in a global-value manner, within a 
unit clause which will only be consulted when needed, and which will disappear 
afterwards. 
Now, let us imagine we are given the ability to write part of a proof state 
context, i.e., to indicate in a rule's left-hand side not only the predicate which 
should match a goal atom to be replaced by the rule's body, but also which 
other goal atom(s) should surround the targeted one in order for the rule to be 
applicable. 
Example 2 Given this, we could write a program for insert which strikingly 
resembles the AProlog program given above: 
3 where for instance insert X Xs Ys means insert (X,Xs,Ys) in curried notation 

217 
insert(X,Xs,Ys):-ins(Xs,Ys),paste(X). 
ins (Ys, [XJ Ys] ),past e (X). 
ins([YIYs], [YIZs]) :-ins(Ys,Zs). 
Note that the element to be inserted is not passed to the recursive clause of 
the predicate ins/2 (which becomes therefore simpler), while the unit clause of 
the predicate ins/2 will communicate directly with insert/3 which will directly 
'paste' the appropriate argument in the continuation. 
In this formulation, the element to be inserted is first given as right-hand side 
context of the simpler predicate ins/2, and this predicate's first clause consults 
the context paste(X) only when it is time to place it within the output list, i.e. 
when the fact ins (Ys, [XlYs] ),paste(X) is reached. 
Thus for this example, we can obtMn the expressive power of ~Prolog without 
having to resort to an entirely new framework. As we shall see in the next sec- 
tions, we can simply use any Prolog system combined with a simple transformer 
to binary programs [24]. 
3 
Multiple Head Clauses in Continuation 
Passing Binary 
Programs 
We will start by reviewing the program transformation that allows compilation 
of logic programs towards a simplified WAM specialized for the execution of 
binary logic programs. We refer the reader to [24] for the original definition of 
this transformation. 
3.1 
The binarization transformation 
Binary clauses have only one atom in the body (except for some inline 'builtin' 
operations like arithmetics) and therefore they need no 'return' after a call. A 
transformation introduced in [24] allows to faithfully represent logic programs 
with operationally equivalent binary programs. 
To keep things simple we will describe our transformations in the case of 
definite programs. First, we need to modify the well-known description of SLD- 
resolution (see [11]) to be closer to Prolog's operational semantics. We will follow 
here the notations of [25]. 
Let us define the composition operator ~ that combines clauses by unfolding 
the leftmost body-goal of the first argument. 
Definition 1 Let A0:-A1,A2 ..... l,~ and B0:-B1 ..... Bm be two clauses (sup- 
pose n > 0, m > 0). We define 
(Ao:-A1,A2 ..... An) 9 (Bo:-BI ..... Bin) = (A0:-B1,... ,BIn,A2 ..... An)8 
with 8 = mgu(A1,Bo). I/the atoms It1 and Bo do not unify, the result of the compo- 
sition is denoted as _L. Furthermore, as usual, we consider A0:-true,A2 ..... An 

218 
to be equivalent to A0:-A2 ..... 
Am, and for any clause C, _L 9 C = C G l 
= 
_L. We assume that at leasl one operand has been renamed to a variant with 
fresh variables. 
Let us call this Prolog-like inference rule LF-SLD resolution (LF for 'left- 
first'). Remark that by working on the program P' obtained from P by replacing 
each clause with the set of clauses obtained by all possible permutations of atoms 
occurring in the clause's body every SLD-derivation on P can be mapped to an 
LF-SLD derivation on P'. 
Before defining the binarization transformation, we describe two auxiliary 
transformations. 
The first transformation converts facts into rules by giving them the atom 
true as body. E.g., the fact p is transformed into the rule p :- true. 
The second transformation, inspired by [28], eliminates the metavariables by 
wrapping them in a call/1 goal. E.g., the rule and(X,Y) :-X, Y is transformed 
into and(X,Y) 
:- call(X), call(Y) . 
The transformation of [24] (binarizalion) adds continuations as extra argu- 
ments of atoms in a way that preserves also first argument indexing. 
Definition 2 Let P be a definite program and Cont a new variable. Let T and 
E = p(T1,...,T,) be two expressions. 4 We denote by r 
the expression 
p(T1, ..., Tn, T). Slatting with the clause 
(C) 
A: -B1,B2,...,B~. 
we construct the clause 
(c,) 
r 
toni): -r 
r 
..., 
Gout))). 
The set P' of all clauses C ' obtained from the clauses of P is called the binariza- 
lion of P. 
Example 3 The following example shows the result of this transformation on 
the well-known 'naive reverse' program: 
app([],Ys,Ys,Cont):-true(Cont). 
app([AIXs],Ys,[ALZs],Cont):-app(Xs,Ys,Zs,Cont). 
nrev([],[],Cont):-true(Cont). 
nrev([XlXs],Zs,Cont):-nrev(Xs,Ys,app(Ys,[X],Zs,Cont)). 
These transformations preserve a strong operational equivalence with the origi- 
nal program with respect to the LF-SLD resolution rule which is reified in the 
syntactical structure of the resulting program. 
Theorem 1 ([25]) Each resolution step of an LF-SLD derivation on a definite 
program P can be mapped to an SLD-resolution step of the binarized program P'. 
Lel G be an atomic goal and G' = %b(G, true). Then, computed answers obtained 
querying P with G are the same as those obtained by querying P' with G'. 
4 Atom or term. 

219 
Notice that the equivalence between the binary version and the original pro- 
gram can also be explained in terms of fold/unfold transformations as suggested 
by [18]. 
Clearly, continuations become explicit in the binary version of the program. 
We will devise a technique to access and manipulate them in an intuitive way, 
by modifying BinProlog's binarization preprocessor. 
3.2 
Modifying the binarization preprocessor for multi-head clauses 
The main difficulty comes from the fact that trying to directly access the continu- 
ation from 'inside the continuation' creates a cyclic term. We have overcome this 
in the past by copying the continuation in BinProlog's blackboard (a permanent 
data area) but this operation was very expensive. 
The basic idea of the approach in this paper is inspired by 'pushback lists' 
originally present in [6] and other techniques used in logic grammars to simulate 
movement of constituents [9]. We will allow a multiple head notation as in: 
a,b,c:-d,e. 
intended to give, via binarization: 
a(b(c(A))) 
:- d(e(A)) 
This suggests the following: 
Definition 3 A multiheaded definite clause is a clause of the form: 
A1,A2,...,Am :-B1,B2,...,B~. 
A multiheaded definite program is a set of multiheaded definite clauses. 
Logically speaking, ','/2 in 
A1, A2, ..., Am : -B1, B2, ..., Bn 
is interpreted as conjunction on both sides. 
The reader familiar with grammar theory will notice (as suggested by [13]) 
that generalizing from definite to multi-headed definite programs is similar to 
going from context-free grammars to context-dependent grammars. 
The binarization of the head will be extended in a way similar to that of the 
binarization of the right side of a clause. 
Definition 4 Let P be a multiheaded definite program and Cont a new variable. 
"Starting with the multiheaded clause 
(C) 
A1,A2...,Am :-B1,B2, ...,Bn. 
we construct ~he clause 
(C') 
r 
r 
..., r 
Cont))): -r 
r 
..., r 
Coat))). 

220 
Note that after this transformation the binarized head will be able to match 
the initial segment of the current implicit goal stack of BinProlog embedded in 
the continuation, i.e. to look into the immediate future of the computation. 
Somewhat more difficult is to implement 'meta-variables' in the left side. In 
the case of a goal like: 
a, Next : -writ e (Next), nl, b (Next). 
we need a more complex binary form: 
a(A) :- strip_cont(A,B,C,write(B,nl(b(B,C)))). 
where strip_cont (GoalAndCont, Goal, Cont) is needed to undo the binariza- 
tion and give the illusion of getting the goal Next at source level by unification 
with a metavariable on the left side of the clause a/1. 
Notice that the semantics of the continuation manipulation predicate strip_cont/3 
is essentially first order, as we can think of strip_coat simply as being defined 
by a set of clauses like: 
, 
. 
~
 
o
.
.
 
strip_cont (f (X 1 ..... Xn, C), f (Xl ..... Xn), C). 
.
.
 
,
.
.
.
.
.
 
for every functor f occuring in the program. 
The full code of the preprocessor that handles multiples-headed clauses is 
given in Appendix A. 
4 
Programming with Continuations in Multiple-headed 
clauses 
The first question that comes to mind is how well our transformation technique 
performs compared with handwritten programs. 
Example 4 The following program is a continuation based version of nrev/2. 
app (Xs, Ys, Zs) : -app args (Xs, Zs) ,past e (Ys). 
app_args ( [], [X] ) ,paste(X). 
app_args ( [A [ Xs], [A [ Zs] ) :-app_args (Xs, Zs). 
nrev([],[]). 
nrsv([XIXs],R):- 
nrevl(Xs,R), 
paste(X). 
nrevl(Xs,R):- 
nrev(Xs,T), 
app_args(T,R). 

221 
which shows no loss in speed compared to the original program (530 KLIPS with 
BinProlog 2.20 on a Sparcsiation 10-40). 
One of Miller's motivating examples for intuitionistic implication in s 
~ 
[14], is the reverse predicate with intuitionistic implication. 
Example 5 By using our multi-headed clauses we can write a such a reverse 
predicate as follows: 
reverse(Xs,Ys):-rev(Xs,[]),result(Ys). 
rev([],Ys), result(Ys). 
rev([XlXs],Ys):-rev(Xs,[XlYs]). 
which gives after binarization: 
reverse(Xs,Ys,Cont):-rev(Xs,[],result(Ys,Cont)). 
rev([] ,Ys, result(Ys,Cont)) :- true(Cont). 
r ev ( [X I Xs], Ys, Cont) : -r ev (Xs, [X I Ys], Cont). 
with a suitable definition for true/1 as: 
true (C) :-C. 
and with a clause like 
reverse (Xs ,Ys) : -reverse (Xs ,Ys ,true). 
Notice that such definitions are 'virtual' (i.e. supplied by generic WAM-level 
operations) in BinProlog, for space and efficiency reasons [23]. 
By replacing true (C) : -C an appropriate set of clauses where C=p(Xl ..... Xn) 
for every head of clause p/n occurring in the program, we obtain a definite binary 
program which accurately describes the operational semantics of the original 
multi-headed program. 
Although the existence of such a translation is expected (as binary definite 
programs are Taring-equivalent) its simple syntactic nature rehabilitates the idea 
of using a translation semantics as an 'internal' means to describe the semantics 
of multi-headed logic programs, despite the fact that it fixes an implementation 
as the meaning of a programming construct. 
The availability of such a programming style in the Horn subset of Prolog 
is also of practical importance as classical Prolog is still about 5-10 times faster 
than, for instance, the fastest known AProlog implementation [4]. 
Example 6 The following program implements a map predicate with a Hilog- 
style (see [5]) syntax: 
5 which is, by the way, a motivating example also for Andreofi and Pareschi's Linear 
Objects, [2] 

222 
cmap (F), i( [] ) ,o( [] ). 
cmap (F), i( [X ] Xs] ), o( [Y] Ys] ) : -G=.. [F, X, Y] ,G, cmap (F), i(Xs), o (Ys). 
inclO(X,Y):-Y is X+lO. 
test : -r 
(inc 10) ,i( [1,2,3,4,5,6] 
), o (Xs), writ e (Xs) ,nl. 
Some interesting optimization opportunities by program transformation can 
be obtained by using multiple-headed clauses, as can be seen in the following 
example of elimination of existential variables (this technique has been pioneered 
by Proietti and Pettorossi, in a fold/unfold based framework, [19]). 
Example 7 Given the program: 
r(X,Y):-p(X,N),q(N,Y). 
p(a,l), 
q(1,10). 
p(b,2), 
q(2,11). 
we can rewrite it as: 
r(X,Y):-p(X),result(Y). 
p(a) :-q(1). 
p(b) :- q(2). 
q(1), result (10). 
q(2), result(ll). 
which avoid passing unnecessary information by directly unifying the 2 occur- 
rences of result (_). 
Example 8 Multi-headed clauses can be used 1o ensure direct communication 
with the leafs of a tree (represented simply as a Prolog term). 
front ier (T, X) : -leaf_var (Y), result (X). 
leaf var(X), result(X):- var(X). 
leaf_var(T) 
:- compound(T), T=..LIXs], 
member(X,Xs), leaf_var(X). 
where ?-frontier(X) returns non-deterministically all the variables in a term 
seen as a (finite) tree. 
The example also shows that the technique scales easily to arbitrary recursive 
data-types, and to programs in practice beyond the domain of definite programs. 
As it can be seen from the previous examples, the advantage of our tech- 
nique is that the programmer can follow an intuitive, grammar-like semantics 
when dealing with continuations and that 'predictability' of the fact that the 
continuation will be at the right place at the right time is straightforward. 
The next section will show some special cases where full access to continua- 
tions is more convenient. 

223 
5 
Multiple headed clauses vs. full-blown continuations 
BinProlog 2.20 supports direct manipulation of binary clauses denoted 
Head : :- Body. 
They give full power to the knowledgeable programmer on the future of the 
computation. Note that such a facility is not available in conventional WAM- 
based systems where continuations are not first-order objects. 
Example 9 We can use them to write programs like: 
member_cont (X, Cont) : : - 
strip_ cont (Cont, X, Ne~Cont, true (Ne~Cont) ). 
member_cont (X, Cont) : : - 
strip_cont (Cont, _, NewCont ,member_cont (X, NewCont) ). 
test(X):-member_cont(X),a,b,c. 
A query like 
?-test(X). 
willreturnX=a; X=b; X=c; X:whateverfollowsfrom the calling point o frost(X). 
catch(Goal,Hame,Cont)::- 
ival(catch_throw,Name,Cont,call(Goal,Cont)). 
thro~(Name,_) : :- 
ival ( cat ch_throw, Name, Cont, nonvar (Cont, Cont ) ). 
where lval(K1 ,K2,Val) is a BinProlog primitive which unifies Val with a back- 
trackable global logical variable accessed by hashing on two (constant or variable) 
keys gl ,g2. 
Example 10 This allows for instance to avoid execution of the infinite loop 
from inside the predicate b/1. 
loop:-loop. 
c(X):-b(X),loop. 
b(hello):-throw(here). 
b(bye). 
go :-catch(c (X) ,here) ,write (X) .nl. 
Notice that due to our translation semantics this program still has a first 
order reading and that BinProlog's lval/3 is not essential as it can be emulated 
by an extra argument passed to all predicates. 
Although implementation of catch and throw requires full-blown continua- 
tions, we can see that at user level, the multi-headed clause notation is enough. 

224 
6 
Continuation 
Grammars 
By allowing us to see the right context of a given grammar symbol, continuations 
can make logic grammars both more efficient and simpler, as well as provide 
several sophisticated capabilities within a simple framework. We next discuss 
some of these capabilities. 
6.1 
Parsing strategy versatility 
Changing parsing strategies is usually deemed to require a different parser, We 
now discuss how we can effect these changes with no more apparatus than con- 
tinuation grammars. 
Take for instance the noun phrase "Peter, Paul and Mary". We can first use 
a tokenizer which transforms it into the sequence 
Example 11 (noun('Peter'), comma, notm('Paul'), 
and, noun('Mary')) 
and then use this sequence to define the rule for list-of-names in the following 
continuation grammar: 
names 
--> noun('Peter'), comma, noun('Paul'), and, noun('Mary'). 
noun(X), comma--> IX,',']. 
noun(X), and, noun(Last) --> [X,'and',Last]. 
This is an interesting way in which to implement bottom-up parsing of recursive 
structures, since no recursive rules are needed, yet the parser will work on lists of 
names of any length. It is moreover quite efficient, there being no backtracking. 
It can also be used in a mixed strategy, for instance we could add the rules: 
verb_phrase --> verb. 
verb --> [sing]. 
and postulate the existence of a verb phrase following the list of nouns, which 
would then be parsed top-down. The modified rules follow, in which we add a 
marker to record that we have just parsed a noun phrase, and then we look for 
a verb phrase that follows it. 
noun(X), comma --> [X,',']. 
noun(X), and, noun(Last) --> [X,'axtd',Last], parsed_noun_phrase. 
parsed_noun_phrase --> verb_phrase. 
DCGs allow further left-hand side symbols provided they are terminal ones (it 
has been shown that rules with non-leading non-terminal left hand side sym- 
bols can be replaced by a set of equivalent, conforming rules [6]). However, 
because their implementation is based on synthesizing those extra symbols into 

225 
the strings being manipulated, lookahead is simulated by creating the expecta- 
tion of finding a given symbol in the future, rather than by actually finding it 
right away. 
With continuations we can implement a more restricted but more efficient 
version of multiple-left-hand-side symbol-accepting DCGs, which we shall call 
continuation grammars. It is more restricted in the sense that the context that 
an initial left-hand side symbol is allowed to look at is strictly its right-hand 
side sisters, rather than any descendants of them, but by using this immediate 
context right away the amount of backtracking is reduced for many interesting 
kinds of problems. 
Example 12 For comparison with the length of code, here is a non-continuation 
based DCG formulation of the "list of names" example which allows for multiple 
left-hand side symbols 6 
names--> start, start(C), name, end(C), nms, end. 
nms--> 
[]. 
rims --> start(C), name, end(C), nms. 
The next two rules are for terminalizing symbols that appear in later rules as 
non-leading left-hand-side symbols. 
end--> [end]. 
start(C)--> 
[start(C)]. 
start, 
[end] --> [] 
start, 
[start(C)] 
--> []. 
end(and), end--> [,]. 
end(comma), start(and) --> [and]. 
end(comma), start(comma) --> [,]. 
Other possible applications are to procedures to read a word or a sentence, 
which typically make explicit use of a lookahead character or word, to restrictive 
relative clauses, whose end could be detected by looking ahead for the comma 
that ends them, etc. 
6.2 
Relating of long-distance constituents 
One important application in computational linguistics is that of describing 
movement of constituents. For instance, a common linguistic analysis would 
state that the object noun phrase in "Jack built the house" moves to the front 
through relativization, as in "the house that Jack built", and leaves a trace be- 
hind in the phrase structure representing the sentence. For describing movement, 
6 This is a simplified version of the corresponding code fragment in [8]. 

226 
we introduce the possibility of writing one meta-variable in the left hand side of 
continuation grammar rules. Then our example can be handled through a rule 
such as the following: 
relative_pronoun, X, trace --> [that], X. 
This rule accounts, for instance, for "the house that jack built", "the house 
that the Prime Minister built", "the house that the man with the yellow hat 
who adopted curious George built", and so on. A simple grammar containing a 
similar rule follows, the reader might try it to derive: "The elephant that Jill 
photographed smiles": 
Example 13 sentence --> noun_phrase,verb_phrase. 
noun_phrase --> proper_name. 
noun_phrase --> det, noun, relative. 
noun_phrase --> trace. 
verb_phrase --> verb, noun_phrase. 
verb_phrase --> verb. 
relative --> []. 
relative --> relative_marker, sentence, 
relative_marker, X, trace --> relative_pronoun, X. 
det--> [the]. 
noun --> [elephant]. 
relative_pronoun --> [that]. 
proper_name --> ['Jill']. 
verb --> [photographed]. 
verb --> [smiles]. 
What is noteworthy about this example is that it shows how to use plain Pro- 
log plus binarization to achieve the same expressive power which used to require 
more sophisticated grammar formalisms, such as Extraposition or Discontinuous 
Grammars [17, 9]. 
6.3 
Computation viewed as parsing 
Continuation Grammars are useful not only for linguistic or intrinsically gram- 
matical examples, but can also serve to simplify the description of many problems 
which can be formulated in terms of a grammar. 

227 
Example 14 For instance, we can sort a list of numbers by viewing it as an 
input string to a grammar, which Obtains successive intermediate strings in a 
parallel-like fashion until two successively obtained strings are the same: 
sort(Input):- 
s(V,V,Input,[]), 
remember(Input). 
s(H,[Y,X]Z])--> [X,Y], {X>Y}, !, s(H,Z). 
s(H,[XlZ]) --> [X], s(H,Z). 
s(NewString,[]), {remember(OldString)} --> 
{decide(OldString,NewString)}. 
decide(Result,Result),output(Result). 
decide(OldString,NewString):- sort(NewString). 
par_sort(Input,Result):-sort(Input),output(Result). 
The first clause initializes a difference-list as empty (both the head and tail 
are represented by a variable V); adds the two extra arguments (input string 
and output string) that are typically needed by the Prolog translation of the 
grammar rules; and pastes a reminder of the last string obtained (initially, the 
input string). 
The first grammar rule consumes the next two numbers from the input string 
if they are unordered, and calls s recursively, keeping track of their ordered 
version in the difference list represented by the two first arguments of s. 
If the next two numbers to be consumed are not ordered, or if there is only 
one number left, the second grammar rule consumes one number, and keeps track 
of it in the difference list as it recursively calls s. 
The third grammar rule finds no more numbers to consume, so it consults 
the last strin~ remembered in order to decide whether to print the result (if the 
new string is no different than the last one) or to start another iteration of the 
algorithm on the list last obtained. 
The last clause returns the answer directly from the continuation. For in- 
stance, on the input string L=[8,4,5,3] with the goal par_sort(L,R), we suc- 
cessively obtain: [4,8,3,fi], [4,3,8,5] and finally 1%=[3,4,5,8]. 
The above example is a variation of the odd-even-transposition parallel al- 
gorithm for sorting numbers [1]. A grammatical version of this algorithm has 
been developed in terms of parametric L-systems [20], an extension of L-systems 
which operates on parametric words and which can be viewed as a model of par- 
allel computation. It is interesting to note that by using continuation grammars 
we need no special formalisms to obtain the kind of parallel computation that 
is provided by more elaborate formalisms such as parametric L-systems. 
7 
Conclusion 
We have proposed the use of continuation-passing binarization both for extend- 
ing logic programs to allow multiple heads, and for a fresh view of those logic 

228 
grammars which allow multiple left-hand-side symbols. In both of these areas, 
the use of continuations has invited interesting new programming (grammar) 
composition techniques which we have provided examples for. 
Other logic programming proposals involve multiple heads, e.g. disjunctive 
logic programming [12, 21] or contextual logic programming [16, 10]. However, 
in these approaches the notion of alternative conclusions is paramount, whereas 
in our approach we instead stress the notion of contiguity that computational 
linguistics work has inspired. A formal characterization of this stress with respect 
to logic grammars has been given in [3]. 
The technique has been included as a standard feature of the BinProlog 2.20 
distribution available by ftp from clement.info.umoncton.ca. 
Acknowledgment 
This research was supported by NSERC Operating grant 31-611024, and by an 
NSERC Infrastructure and Equipment grant given to the Logic and Functional 
Programming Laboratory at SFU, in whose facilities this work was developed. 
We are also grateful to the Centre for Systems Science, LCCR and the Depart- 
ment of Computing Sciences at Simon Fraser University for the use of their 
facilities. Paul Tarau thanks also for support from the Canadian National Sci- 
ence and Engineering Research Council (Operating grant OGP0107411)and a 
grant from the FESR of the Universit6 de Moncton. 
References 
1. S. Akl. The design and analysis of parallel algorithms. Prentice Hall, Englewood 
Cliffs, 1989. 
2. J.-M. Andreoli and R. Pareschi. Linear objects: Logical processes with built-in in- 
heritance. In D. Warren and P. Szeredi, editors, 7th Int. Conf. Logic Programming, 
Jerusalem, Israel, 1990. MIT Press. 
3. J. Andrews, V. Dahl, and F. Popowich. A Relevance Logic Characterization of 
Static Discontinuity Grammars. Technical report, CSS/LCCR TR 91-12, Simon 
Fraser University, 1991. 
4. P. Brisset. Compilation de AProlog. Th~se, Universit~ de Rennes I, 1992. 
5. W. Chen and D. S. Warren. Compilation of predicate abstractions in higher-order 
logic programming. In :1. MaluszyIiski and M. Wirsing, editors, Proceedings of the 
3rd Int. Symposium on Programming Language Implementation and Logic Pro- 
gramming, PLILP91, Passau, Germany, number 528 in Lecture Notes in Computer 
Science, pages 287-298. Springer Verlag, Aug. 1991. 
6. A. Colmerauer. Metamorphosis Grammars, volume 63, pages 133-189. Springer- 
Verlag, 1978. 
7. A. Colmerauer, H. Kanoui, R. Pasero, and P. Roussel. Un systeme de communi- 
cation homme-machine en francais. Technical report, Groupe d'Intelligence Arti- 
ficielle, Universite d'Aix-Marseille II, Marseille, 1973. 
8. V. Dahl. Translating spanish into logic through logic. American Journal of Com- 
putational Linguistics, 13:149-164, 1981. 

229 
9. V. Dahl. 
Discontinuous grammars. 
Computational Intelligence, 5(4):161-179, 
1989. 
10. J.-M. Jacquet and L. Monteiro. Comparative semantics for a parallel contextual 
logic programming language. In S. Debray and M. Hermenegildo, editors, Pro- 
ceedings of the 1990 North American Conference on Logic Programming, pages 
195-214, Cambridge, Massachusetts London, England, 1990. MIT Press. 
11. J. W. Lloyd. Foundations of Logic Programming. Springer-Verlag, 1987. 
12. J. Lobo, J. Minker, and A. Rajasekar. Extending the semantics of logic programs 
to disjunctive logic programs. In G. Levi and M. Martelli, editors, Proceedings of 
the Sixth International Conference on Logic Programming, pages 255-267, Cam- 
bridge, Massachusetts London, England, 1989. MIT Press. 
13. J. Maluszyliski. 
On the relationship between context-dependent grammars and 
multi-headed clauses., June 1994. Personal Communication. 
14. D. Miller. A logic programming language with lambda-abstraction, function vari- 
ables, and simple unification. J. Logic and Computation, 1(4):497-536, 1991. 
15. D.A. Miller. 
Lexical scoping as universal quantification. 
In G. Levi and 
M. Martelli, editors, Proceedings of the Sixth International Conference on Logic 
Programming, pages 268-283, Cambridge, Massachusetts London, England, 1989. 
MIT Press. 
16. L. Monteiro and A. Porto. 
Contextual logic programming. 
In G. Levi and 
M. Martelli, editors, Proceedings of the Sixth International Conference on Logic 
Programming, pages 284-299, Cambridge, Massachusetts London, England, 1989. 
MIT Press. 
17. F. Pereira. Extraposition grammars. American Journal for Computational Lin- 
guistics, 7:243-256, 1981. 
18. M. Proietti. On the definition of binarization in terms of fold/unfold., June 1994. 
Personal Communication. 
19. M. Proietti and A. Pettorossi. Unfolding-definition-folding, in this order, for avoid- 
ing unnecessarY variables in logic programs. In J. Maluszyfiski and M. Wirsing, 
editors, Proceedings of the 3rd Int. Symposium on Programming Language Imple- 
mentation and Logic Programming, PLILP91, Passau, Germany, number 528 in 
Lecture Notes in Computer Science, pages 347-358. Springer Verlag, Aug. 1991. 
20. P. Prusinkiewicz and J. Hanan. L-systems: from formalism to programming lan- 
guages. Springer-Verlag, 1992. 
21. D. W. Reed, D. W. Loveland, and B. T. Smith. An alternative characterization of 
disjunctive logic programs. In V. Saraswat and K. Ueda, editors, Logic Program- 
ming Proceedings of the 1991 International Symposium, pages 54-70, Cambridge, 
Massachusetts London, England, 1991. MIT Press. 
22. J. Stoy. Denotational Semantics: the Scott-Strachey Approach to Programming 
Language Theory. Cambridge, MA. The MIT Press, 1977. 
23. P. Tarau. Program Transformations and WAM-support for the Compilation of 
Definite Metaprograms. In A. Voronkov, editor, Logic Programming, RCLP Pro- 
ceedings, number 592 in Lecture Notes in Artificial Intelligence, pages 462-473, 
Berlin, Heidelberg, 1992. Springer-Verlag. 
24. P. Tarau and M. Boyer. 
Elementary Logic Programs. 
In P. Deransart and 
J. Maluszyfiski, editors, Proceedings of Programming Language Implementation 
and Logic Programming, number 456 in Lecture Notes in Computer Science, pages 
159-173. Springer, Aug. 1990. 
25. P. Tarau and K. De Bosschere. Memoing with Abstract Answers' and Delphi Lem- 
mas. In Y. Deville, editor, Logic Program Synthesis and Transformation, Springer- 
Verlag, Workshops in Computing, Louvain-la-Neuve, July 1993. 

230 
26. P. Wadler. Monads and composable continuations. Lisp and Symbolic Computa- 
tion, pages 1-17, 1993. 
27. M. Wand. Continuation-based program transformation strategies. Journal of the 
Association for Computing Machinery, 27(1):164-180, 1980. 
28. D. H. D. Warren. 
Higher-order extensions to Prolog - are they needed? 
In 
D. Michie, J. Hayes, and Y. H. Pao, editors, Machine Intelligence 10. Ellis Hor- 
wood, 1981. 
29. D. S. Warren. The XOLDT System. Technical report, SUNY Stony Brook, elec- 
tronic document: ftp sbcs.sunysb.edu, 1992. 
Appendix A 
converts a multiple-head clause to its binary equivalent 
def_to mbin((H:-B),M):-!,def_to mbinO(H,B,M). 
def_to mbin(H,M):-def_to mbinO(H,true,M). 
def_to_mbinO((H,Upper),B,(HC:-BC)) ;- nonvar(H),!, 
termcat(H,ContH,HC), 
add_uppercont(B,Upper,ContH,BC). 
def_to_mbinO(H,B,(HC:-BC)) :- !, 
termcat(H,Cont,HC), 
add_cont(B,Cont,BC). 
add_upper_cont(B,Upper,ContH,BC):-nonvar(Upper),!, 
add cont(Upper,ContU,ContH), 
add_cont(B,ContU,BC). 
add_upper_cont(B,Upper,ContH,BC):- 
add_cont((strip_cont(ContH,Upper,ContU),B),ContU,BC). 
adds a continuation to a term 
add_cont((true,Gs),C,GC):-!,add_cont(Gs,C,GC). 
add_cont((fail,_),C,fail(C)):-!. 
add_conZ((G,Gsl),C,GC):-!, 
add_cont(Gsl,C,Gs2), 
termcat(G,Gs2,GC). 
add cont(G,C,GC):-termcat(G,C,GC). 
strip_cont(TC,T,C):-TC=..LC,append(L,[C],LC),!,T=..L. 
The predicate termcat(Term,Cont,TermAndCont) is a BinProlog builtin which 
works as if defined by the following clause: 
t e rmc at (T, C, TC) : -T=.. LT, append (LT, [C], LTC), !, TC=.. LTC. 

Improving the Whetk System: 
a type-theoretic reconstruction 
Geraint A. Wiggins 
Department of Artificial Intelligence 
University of Edinburgh 
80 South Bridge, Edinburgh EH1 1HN 
Scotland 
geraint~ai, ed. ac. uk 
Abstract. I present a reformulation of the Wlletk system [Wiggins 92b], 
as a higher-order type theory. The theory is based on that of [Martin- 
LSf 79], adapted to facilitate the extraction of logic programs from proof 
objects. A notion of normalization is used to ensure that the extrac- 
ted program is executable by standard logic-programming methods. The 
extension admits specifications over types and programs, and so allows 
modularity and the construction of program combinators. In doing so, it 
demonstrates that logic program synthesis techniques have potential for 
solving "industrial-strength" problems. 
1 
Introduction 
In this paper, I present a reconstruction of the VVhetk proof development and 
program construction system which was explMned in [Wiggins et al 91, Wiggins 
92a, Wiggins 92b]. The reconstruction uses a higher order logic which admits 
quantification over types, and, following the style of Martin-LSf Type Theory 
[Martin-LSf 79], views sentences in the logic as types. Proofs of such sentences 
are then thought of as members of the types. The addition of the higher order 
features means we can now synthesise meta-programs and program modules. 
Making such a gain means that the system is more complicated than before, 
because type membership is undecidable. However, much of the extra proof 
obligation entailed may be dealt with automatically, and good heuristics exist 
for those parts which are not straightforward. The correctness argument for the 
new system is greatly simplified over the original YVb.etk, because it can be given 
largely by reference to Martin-LSf's existing theory. 
The paper is structured as follows. In section 2, I remind the reader of the 
modus operandi of the original Whelk system, and illustrate the disadvantages 
which led to the reconstruction explained here; in section 3 I explain the shift 
from the first order logic to the type theory and outline the changes necessary. In 
section 4, I give those inference figures of the reconstructed system necessary for 
an example. Correctness is shown by reference to Martin-LSf original calculus, 
but there is not space to cover it in depth here. Section 5 shows the synthesis of 
the subset/2 predicate for comparison with the original system [Wiggins 92b]. 
Finally, because of space constraints, I merely sketch the normalization process 
for generating the runnable programs in section 6. 

232 
2 
Background 
The Wb.etk system is an attempt to bring ideas used in the domain of type theory 
and functional program synthesis to bear on the synthesis and/or transforma- 
tion of logic programs. We wish to give the specification of a program in terms 
only of the logical relation between its arguments; the construction of a suitable 
algorithm is then to be left to a process of proof that the specification can be 
realised. The notion on which this is based is the proofs-as-programs paradigm 
of [Constable 82], in which a constructive proof of an existentially quantified 
conjecture is encoded as an extract term, a function, expressed as a ~-term, em- 
bodying an algorithm which implements the input/output relation specified in 
the conjecture. The proofs-as-programs idea has been adapted [Bundy et al 90b] 
to synthesise logic programs. This is achieved by viewing logic programs as func- 
tions on to the Boolean type. The synthesised relations are then Boolean-valued 
functions (expressed as logic programs, called in the all-ground mode). 
In [Wiggins et al 91, Wiggins 92b], the original version of the logic system de- 
signed for this purpose is explained. While the system does its job effectively, and 
is in use for teaching and research at various institutions, the background theory 
is not as tidy as it might be. In particular, the means of specifying what con- 
stitutes a synthesis conjecture leads us to convoluted correctness proofs, which 
are less than elegant. Further, the original system is restricted to first order 
specifications, with no meta-language. Therefore, it is not possible to synthesise 
program modules, or to specify meta-programs, simply because quantification 
over mathematical structures other than the natural numbers and parametric 
lists is not allowed. (In fact, it is not clear that the modularity issue is as import- 
ant in the context of program synthesis as elsewhere; however, the fact remains 
that the expressive power of modularity is desirable.) 
In YVketk, the fact that we wish to synthesise a program is expressed by 
means of a decidability operator, ~, which is applied to the specification of the 
desired program. By proving constructively that a specification is decidable, we 
synthesise the decision procedure - in the form of a logic program -- for that 
specification. In earlier versions of the system [Wiggins 92b], a was defined by 
reference to the existence of the extracted program, and not via sequent calculus 
rules, like the other logical connectives. Therefore, it behaved rather like a macro, 
defined at the meta-level with respect to the sequent calculus. This approach 
was taken because it allowed certain restrictions to be placed on the form of the 
programs derived from YVh.etk proofs, so that no program components would be 
generated by parts of the proof concerned purely with verification of correctness. 
In particular, the meta-flavour of the a definition allowed certain restrictions 
on the applicability of inference rules to be hidden in a way which seems, in 
retrospect, undesirable. In the reconstruction explained here, these meta-level 
definitions and restrictions have been abandoned in favour of logical elegance, 
their respective effects being reproduced by a more conventional sequent calculus 
definition and application of a simple heuristic during proof construction. 
In the following sections of this paper, I will discuss the use of the reconstruc- 
ted calculus, which I will call WTT, for program manipulation, with reference 
to the existing example from [Wiggins 92b], showing how the program can be 

233 
modularised by type. The Wb.e~k conjecture, which clearly has types built in, is 
as follows: 
I--Vk:l.~st(~).Vl.:t~st(]N).~ (Vx:~.x e k ~ x e t) 
where E is the usual list membership; it specifies the list inclusion relation. Proof 
of this synthesis conjecture is fairly straightforward, and will be outlined again 
in section 5. The extracted program, expressed as a logical equivalence, may be 
automatically converted the GSdel code, as shown in [Wiggins 92b]. 
The new higher-order calculus presented here is also designed for describing 
and manipulating logic programs. However, because of the first order nature of 
logic programs themselves, it is clear that programs parameterised by module 
or type will not be expressible as such, in a strictly first-order way. In what 
follows, therefore, I assume that the parameters of the modules I synthesise 
will be instantiated within WTT, and the resulting GSdel program extracted 
subsequently, rather than the converse. 
3 
Reconstruction 
There are two main aspects to the type-theoretic reconstruction of ~Vlxctk. First, 
the decidability operator, a, on which the construction of logic programs rests, 
has been integrated into the sequent calculus as an operator in its own right, 
rather than as a set of operators related to the standard ones, as is the case in 
Whetk. This results in a considerable reduction in the number of rules (roughly 
half), which necessarily makes things less complicated. 
The second change is the raising of the calculus to higher order. This is car- 
ried out by following the rules of Martin-LSf's Type Theory [Martin-L6f 79], and 
adapting and extending them where necessary. This approach has the advantage 
that correctness can be argued in terms of the original system. The introduction 
of higher-order structures raises the possibility that functional terms and vari- 
ables might appear in the extracted programs, and we will need to be careful 
that this does not prove to be the case - the programs would not then be logic 
programs. This point is the main motivation for the building of a new calculus, 
from the bottom up, as it were, rather than simply implementing the WTT logic 
on top of an existing type theory. In the latter of these options, it is not clear 
how (or indeed if) we could guarantee the first order structures we need. 
4 
VVh.etk Type 
Theory 
4.1 
Introduction 
In order to specify our type theory, we must specify what is the syntactic form of 
each type, and what is the syntactic form of objects of each type. In general, there 
will be two forms of objects: the non-canonical and canonical forms - i.e. forms 
which may be further evaluated and forms which may not. The calculus must 
also supply a means of computation to enable the derivation of canonical forms 
from non-canonical ones. It will be clear from the expression of the evaluation 

234 
strategy below, which follows Martin-L6f's description closely, that the theory is 
extensional - that is to say, equality of functions is expressed in terms of equality 
of corresponding inputs and outputs. 
Like Martin-L6f's type theory, WTT admits four kinds of "judgement" - a 
judgement being essentially what we can prove is true (i.e., the logical sentence 
to the right of the sequent symbol). The four kinds of judgement I will use here 
relate to the formation of types and the objects which inhabit them. In each case, 
entities themselves, and equality between entities is covered. 
Judgement 
Form 
A is a type 
A tlgpe 
A and B are equal types 
A = B 
a is an object of type A 
a E A 
a and b are equal objects of type A a = b E A 
4.2 
Preamble 
(First order) VVhe[k uses distinct languages for expression of its specification 
(Z;s) and of its programs (s 
A mapping connects the two, and allows us 
to say what the syn~hesised program means in terms of the specification - for 
more details, see [Wiggins 92b]. In WTT, a similar arrangement pertains: loosely, 
types correspond with s 
and objects with/:p-formulae, and type mem- 
bership replaces the interpretation. However, there is a significant difference: in 
9VTT, we have a type of types, known as a universe, so it is possible to view 
a type as an object also. For the purposes of the examples here, however, these 
higher-order complications are irrelevant. (Incidentally, there is a hierarchy of 
universes, each containing the one "below" it, which avoids Russell's Paradox, 
while still giving all the types we need.) 
The type language admits the familiar connectives (though for reasons of 
limited space I have given only those necessary for the example): A (and), V 
(or), --* (implies), V (for all). Contradiction is denoted by {} (the empty type), 
and negation by implication, so the negation of A is A --* {}. We also have 
identity within a type, =,, (NB, this is not the same as the object equality 
judgement) and the decidability operator, 3. The quantifiers are typed in the 
usual way, : denoting type membership. The operators of the object language are 
the constructors of the members of the types. They are best given in terms of the 
types they construct and destruct. To facilitate comparison, these constructions 
are given in the style of [Martin-L6f 79]. 
Type 
Vx:A.B 
A~B 
AAB 
AVB 
OA 
a~Ab 
{} 
A ttst 
Canonical Form 
Non-canonical Form 
t]x:A.b 
x:A~b 
aVlb 
~;u(a), 7~L(b) 
A 
c=d 
Ib]A 
cM 
n (b) 
d, r 
A a,e) 
raise 
p(â€¢ 
p(â€¢ 
ttst)= LtstC(x, d, â€¢ 
x~, v, e). 

235 
The non-canonical forms operate as follows: 
1. If c has canonical form Hx:A.b and a E A then c(a) is b[a/â€¢ 
2. If c has canonical form x:A H b and a E A then c{a} is b. 
3. If c has canonical form a lq b then s 
is a and ~^(c) is b. 
4. If c has canonical form s 
then 79v(X,~)(c, d, e) is d[a/x]; if c has canon- 
ical form n (b) then Dv(x,y)(c, d, e) is e[b/y] 
5. If b has canonical form s 
then 790 (x,~)(b, c, d) is c[a/x]; if b has ca- 
nonical form ~0(a) then 7)0 (x,~)(b, c, d) is d[a/~]. 
6. a -A b expresses the identity relation between a and b, and is syntactically 
distinct from the equality judgement a = b E A. If c has canonical form 
A 
p = q then J(c, d) is d[q/p]. 
7. {} is uninhabited; it has no constructors. 
8. Ifx is []A then kistC(x,d, xo,xl ,v,e) is d; 
if x is [x0 [xl] then L~stC(x, d, x0,xl ,v, e) is e[p(xl )/v]. 
The appearance of the non-canonical forms in synthesised programs corresponds 
with the application of elimination rules in the proof. Similarly, the application 
of introduction rules in the proof corresponds with the appearance of object 
constructors in the program. This will become obvious on inspection of the 
example inference figures, below. 
The sequent symbol is written I-. Non-empty formulm are represented by up- 
per case Roman letters (A,B,C,D); variables by lower case (x,y,z); types by lower 
case Greek letters (I:); and sequences of formulm by upper case. Hypothesis man- 
agement is implicit, so the order of the hypotheses is insignificant; unchanging 
hypotheses are not shown in the figures below. As the calculus is constructive, 
there is only one formula on the right of b, so no management is needed there. 
Because this is a sequent calculus, the introduction and elimination rules of nat- 
ural deduction correspond with operations on the right and left of the sequent 
symbol, respectively. 
The construction proving each formula is associated with it by E, which may 
be thought of as type membership. Thus, a proof/program may be viewed as 
inhabiting the type which is its specification. Note that program constructions 
in the inference figures, in particular those associated with hypotheses, may 
contain uninstantiated (meta-)variables; the construction process may be seen 
as a process of instantiation. Some cases (e.g. proofs of implications not in the 
scope of a) will lead to finished constructions containing uninstantiated variables. 
These constructions may be thought of as program transformers: they take an 
"input", by unification, and return a new structure related to that input in a 
way described by the conjecture whose proof produced the transformer. These 
ideas will be explored elsewhere. 
In order to verify or synthesise a WTT program, we prove a conjecture of 
the general form 
A ~ r e Va~.O S(~) 
where A is an initial theory providing the definitions and axioms necessary for the 
proof; S is the specification of the program; ~-.'~ is a vector of typed arguments; 
and ~b is the (synthesised) program, which includes an initial goal. The difference 

236 
between verification and synthesis is the instantiation level of the object r - if it 
is fully ground, we are verifying, if it is a pure variable we are synthesising, and 
correspondingly for any case in between. This is essentially the same as VVb.etk. 
However, given the improved uniformity of the reconstruction, we can now say 
precisely what an object/program means for any type membership judgement 
which is part of a proof. If we have a complete proof of the conjecture 
so that qb is ground, then we know that 0 explicitly encodes a proof of O. The 
computation rules of the calculus allow us to manipulate this proof- instan- 
tiating arguments, for example - in a way which models the execution of the 
program in a higher-order functional programming language. This is relevant to 
logic programs because, when executed in the all-ground mode, they are equi- 
valent to boolean functions. We can therefore read a subset of the proof objects 
produced by the system - that subset whose member are members of 0 types - 
as logic programs. 
4.3 
General Rules 
Reflexivity 
Symmetry 
Transitivity 
FaEA 
b At~pe 
ha=aEA 
hA=A 
ha=bEA 
FB=A 
bb=aEA 
FA=B 
~-a=bEA 
F-b=cEA 
PA=B 
~-B-=C 
~-a----cEA 
~-A=C 
Equality of Types 
FaEA 
FA=B 
Fa=bEA 
bA=B 
baEB 
ba=bEB 
Substitution 
F-aEA 
x:AbB[a/x]tgpe 
~-aEA 
x:AI-b[a/â€¢ 
E B[a/x] 
h B t~pe 
FbEB 
Axiom 
a = c e A 
x:h 
~ B[a/x] = D[c/x] 
} - B = D  
~- a -- c E A x:A l- b[a/x] -- d[c/x] E B[a/x] 
bb=dEB 
a : A ~ - a E A  

4.4 
Dependent Function Type 
Formation 
~- A tt3pe x:A ~- B t~pe 
b Vx:A.B t~pe 
Construction 
x:AbbEB 
b- (Idx:A.b) E (Vx:A.B) 
Selection 
237 
t-A=C 
x:At-B =D 
b- (Vx:A.B) = (Vx:C.D) 
x:Abb=cEB 
(U~:A.b) = (U~:A.r ~ (W:A.B) 
t-teB 
b:B[t/x] ~ g E G 
c:(Vx:A.B) t- g[c(t)/b] E G 
t-cE(Vx:A.B) 
t-tEB 
b:B[t/x]b-gEG 
Evaluation 
haEA 
x:AFbEB 
~- o[c(t)/bl ~ G 
((M,~:a.b)(n)) = b[~/â€¢ 
~ B[~/~] 
4.5 
Function Type 
Formation 
~-At0pe 
t-Bt~pe 
t- A--,B tope 
Construction 
a:AFbEB 
(â€¢ 
~. b) ~ (A-*B) 
Selection 
ba:A 
b:Bb-g EG 
c:(A-*B) h g[c{a}/b] E G 
Evaluation 
~-aEA 
bbEB 
~- ((x:A ~ b){a}) = b E B 
t- c E (Vx:A.B) 
((U~:A.c)(~)) = c e (W:A.B) 
hA=C 
I-B=D 
I- (A~B) = (C~D) 
x:AI-b=dEB 
F c E (A--*B) 
bctEA 
b:BFgEG 
~- o[cM/b] ~ c 
t- b ~ (â€¢ 
~ B) 

238 
4.6 
Product Type 
Formation 
~-Atype 
}-Btype 
~- AAB type 
Construction 
}-aEA 
FbEB 
I-alqb EAAB 
Selection 
a:A,b:B b O E G 
c:(a ^ B) ~ g[~,b/c^(c),Ze^(c)] e c 
Evaluation 
I-aVIb E AAB 
t- s 
= a E A 
4.7 
Disjoint Union Type 
Formation 
t-Atype 
t-Btype 
F- A V B type 
Construction 
baEA 
t- s 
e h V B 
I-bEB 
I-- ~.v(b) ~ A V B 
Selection 
â€¢ 
b- d:G 
y:B b- e:G 
c:(avB) ~ Vv(â€¢162 
a, e) e c 
Evaluation 
hA=C 
B=D 
I- (AAB) = (CAD) 
ba=cEA 
Fb=dEB 
I-(ctMb) = (cr-1 d) E (AAB) 
F- c:(A A B) 
a:A,b:B F0 E G 
0[a,b/C^(c),~^(0] ~ C 
F-aMbEAAB 
b T~^(aMb) =b E B 
FA=C 
F-B=D 
F (AV B) = (CV D) 
ha:cEA 
C4a ) : C4c) ~ (AV B) 
Fb=dEB 
Ze~(b) = 7e~(d) ~ (h v B) 
bcE(AVB) â€¢ 
y:BFeEG 
~-Vv(x,y)(c,d,e)e G 
t-aEA 
x:AI-dEC 
y:BFeEC 
Vv(~,y)(c~(n), a, e) = a[./â€¢ 
~ c 
I-aEA 
x:AI--dEC 
y:BI--eEC 
F 79v(X,y)(~v(b), d, e) = e[b/y] E C 

239 
4.8 
Decision Type 
Formation 
b A t~pe 
b a A t~pe 
Construction 
ba9 
t- &(a) 9 0 A 
~- ~0(a) 9 a h 
Selection 
x:AF-d9 
a:Oa ~ v~ (,,,y)(a,,1, ~) 9 G 
Evaluation 
FA=B 
(o a) = (o B) 
ha=bEA 
~- co(a) = Ca(b) 9 ~ a 
a = b 9 (a--, {}) 
Fa9 
x:Al-d9 
"t3:(A--*{})l-e9 
1-790 (X, 12)(a, d, e) 9 G 
Fa9 
x:AFd9 
o:(A~{})Fe9 
I- (7)~ (â€¢ 
d, e)) = d[a/â€¢ 
9 C 
I-a9 
â€¢149 
~:(A-~{})I-e9 
~- (79o (â€¢ 
a, ~)) = e[a/~] 9 c 
F-b:A 
F-A=C 
F-a=c:A 
F-b=d:A 
4.9 
Identity Relation 
Formation 
F-Atgpe 
F-a:A 
I- a =A b t!~pe 
Construction 
I-a=b9 
b-(c=A d)9 
Selection 
e 9 C[b/a] 
c:(a -A b) ~- Z(c, e) 9 C 
Evaluation 
ba=b9 
(a -A b) = (c --c d) 
ha=b9 
(c ~ a) = (c ~ a) 9 (a -A b) 
~- c 9 (a =A b) 
~- e 9 C[a/b] 
z(c, e) 9 c 
F- e 9 C[a/b] 
A 
J(a 
b,e)=eeC 

4.10 
Void Type 
Formation 
{} t~pe 
Selection 
4.11 
Parametric Lists 
Formation 
~- At~pe 
I- A Kst t~pe 
Construction 
h A t~pe 
I.-- []a :A tist 
Fa:A 
I- b E A 1,ist 
I-- [alb]A ~ Ahst 
Selection 
F- a: G[[]~/x] 
240 
t- {} = {} 
a:{} I- fatse ~ G 
I- A tgpe 
t- (A ttst) = (A tist) 
~- A t~pe 
k []A -- []A ~ A tist 
~-a=cEA 
bb = d E Atist 
[alb]A = [cld]A e Atist 
â€¢ : A, â€¢ 
: h tist,y : C[â€¢215 ~ e e G[[â€¢ 
Iâ€¢ ])/â€¢ 
â€¢ 
Ust b- (p(â€¢215 
Ust) ---- UstC(x, d,â€¢ 
,v, e)) E G 
I-- â€¢ e A tist 
~- d: G[[IA/â€¢ 
â€¢ : A,â€¢ 
A fist, ~: G[â€¢215 k e e G[[â€¢ 
Iâ€¢ 
F" (p(â€¢215 
list) = tistC(x, d,xo,xl ,v, e)) e G 
EvaJuation 
h d E G[[]A/â€¢ 
â€¢215 
:A t~st,~:G[â€¢215 k e E G[[xo Ixl]/x] 
x:A [~st b- (p(x);p(x:A [~st) = â€¢stC([]A,d,xo,xl ,v,e) = d) E G 
k d ~ G[[]a/x] 
â€¢ 
xl :A ttst,~:G[â€¢ 
~- e ~ G[[xo Ixl]/x] 
x:h tist ~ (p(x);p(x:A List) = ListC([zo Iz,],d, xo,Xl ,v, e)) = 
e[zo, zl ,p(â€¢215 
â€¢ ,v] ~ G 

241 
4.12 
Universes 
Formation 
Un tope 
Construction (similarly for all types except Urn) 
I-'A:U~ 
x:AF B:U,~ 
F (Vx:A.B) :Ur~ 
Selection 
t- A type 
I- A:U~ 
b- A:U~ 
k A:U~+I 
5 
Example: 
subset/2 
I'- A ~U,~ 
x:A I-- B = D:U,, 
I- (Vx:A.B) = (Vx:C.D):U~ 
FA=B 
I- A = B:U~ 
FA=B:Un 
b A = B:Ur~+I 
For this example, I use the conjecture which specifies the subset/2 predicate 
using lists as a representation for sets - that is, the predicate which succeeds 
when all the members of the list given as its first argument are members of 
that given as its second. The specification is parameterised by base type (i.e., 
by the type of the list elements), and, necessarily, by a decision procedure for 
equality for that type. In the event that such a decision procedure is not supplied, 
the proof process will not yield a logic program. I assume a background theory 
defining the Ex (typed member/2), as follows: 
U'r:Uo. l-ld: (Va:'r.Vb :7.0 (a -~ b)). 
Ux:x. ~ :~ [ist.(m(~); 
m(y:x t/.st) = 
tistC(y, 
zeo(v:{} ~ fal.se), 
U0,1.31 ,V, 
~0 (VO ,P, )(d(~)(x)(y o), ~(~(Po)), ~(v)))) 
Vx:Uo.Vd:(Va:~.Vb :x.O (Q -~ b)). 
Vx:x.vy :7 ttst.0 (x ~ ~) 
(1) 
This definition is the statement that a program implementing member inhabits 
the appropriate type. It is worth mentioning at this stage that a user of WTT 
will not normally have to deal with such complex constructions. Instead, we also 
have two logical equivalences (i.e., type equalities): 
v~:uo.vx:~.(x ~ [1~) = {} 
(2) 
w:uo.vx:~r.vyo:x.Vyo:T ti.st.(x ~ [yolu,]) = (x -~ uo vx e~ u~) 
(a) 

242 
It is, however, necessary to show that the type defined using Ev is inhabited - 
so we must construct the object; in fact, this turns out to be done via a simple 
proof. 
Returning to the example conjecture, we start with 
F V~:U0.Vd: (Va:~.Vb :~.0 (a =~ b)). 
Vâ€¢ 
U.st.V~ :'~ ttst.~ (Vz:~r.z ET x--oz e~ y) 
(4) 
The proof proceeds by primitive induction on lists, first on x and then on y. Note 
that the proof is presented in refinement style, with the rules applied "back- 
wards", and that I have omitted unchanging hypotheses unless they are used in 
the current proof step. Further, since we begin with a completely uninstantiated 
proof object, I have omitted it and the E symbol from the sequents - otherwise 
the sequents would be completely illegible. 
The first move is to introduce the universally quantified type parameters, 
and the quantifier of x in 4. This yields the conjecture 
9 : U0, d: (Va :~.Vb :~.0 (a -~ b)), 
â€¢ 
ttst F V~ :~ ttst.~ (Vz:~.z e~ x--.z e~ ~) (5) 
and the program 
t:]'c: U0. t:]d: ( ga:~. Hb :-r.8 (ct --~ b)). gx:'r tist.r 
where qb5 is a meta-variable which will be instantiated during the rest of the 
proof. Note the difference from the original WheLk here: the Us were previously 
represented by a predicate definition head and arguments. Also, we have two 
(syntactically detectable) higher-order arguments, whose presence indicates that 
what we are synthesising here is not a logic program, but a logic-program-valued 
function - i.e., a module. These, then, are the first two significant differences 
between this presentation of the example and that of [Wiggins 92b]. 
Next, we apply tist selection to x. This gives us two subconjectures: 
k Vy :~ t~st,a (Vz:~.z 6~ []~ -*z 6~ ~) 
(6) 
xo :T, xl :~ fist, 
v: (V~ :~.z e~ â€¢ -*z e~ y) U Vy :T ttst2 (Vz:~.z e~ [x0 Ixl]--.*s e~ ~) 
(7) 
and the following synthesised program, where 46 and ~b7 are the program con- 
structions corresponding with (6) and (7), respectively: 
H~:U0. tJd:( tJ a:x. tJb :~.0 (a -~ b)). 
Ux:z tist.(p(x);p(x:x tist) = tistC(x,Xb~,x0,xl ,v,*7)) 
Here is another difference between Whel.k and WTT: the choice between [] and 
non-[] lists is built into the language as a type-selector, so no explicit disjunction 
appears here. 
To prove the base case, (6), observe that the expression within the scope of 
is true, because the antecedent of the implication is always false. We can now use 
the new decision type rules to introduce the ~ and then show that the resulting 

243 
statment is indeed true. We introduce ~ and then use the first 3 construction, 
to yield the following conjecture: 
~:z List F Vz:z.z E.~ []~z 
E.~ t3 
(s) 
and the program 
t~-~:tlo, tJd:( tJ a:'r tJb:z.~ (a -, b)). 
tJx:, tist.(p(x);p(x:z List) = tistC(x,Z;a( tJy:z tist.*s),xo,xl ,v,*7)) 
where kbs is the program corresponding with (8) as before. It is the fa0 operator, 
appearing in the [] part of the 
tistC selector which tells us that, when we 
reach this point in execution, we have succeeded; the argument of ListC is just 
verification proof (maybe with some embedded identity relations, which can be 
extracted easily). 
Proof of the remaining conjecture, (8), is trivial (from the definitions of E, 
in 2) and is omitted here for lack of space. When it is finished, we have the 
following program. 
H'[:U0. lid:( U a:'[. Nb:'r 
(a -~ b)). 
~x:1: List.(p(x); 
p(x:~ List) = 
tistC(x, 
s 
tJ~ :~ List. ~z:T tist.v:(z E~ []'c ~ false)), 
x0,x, 
The step case of the induction on x, (7) is harder. First, we use the definition 
(3) of E~ rule to unfold the leffmost occurrence in the conclusion. This gives 
t- V~ :~ List.0 (Vz:-c.(z =. x0 v z e~)~z e~ ~) 
(9) 
Note here that I am using the type equality rules to perform and prove correct 
these rewrites, and not the evaluation rules. As such, the rewrites are effectively 
under equivalence, and the program does not change. 
Now, we introduce the universal quantifier of ~ and rewrite under logical 
equivalence, again proving correctness by reference to type equality, to get: 
:~ List b 0 (Vz:~.(z m, X0 --'Z r y) A Vz:*.(z r x] -*z e ~)) 
As with VVb.etk, the rewriting can be performed automatically, via the rippling 
paradigm of [Bundy et al 90a, Bundy et al 90c]. Again, this step does not change 
the structure of the synthesised program. 
One more logical rewrite gives us 

244 
again, not contributing to the program structure. The next step, however, A 
construction, does contribute. Its sub-sequents are: 
b 0 (Vz:T.z ----. x0 --*z 6 ~) 
(10) 
F 0 (Vz:7.z 6T xl --*z 6 ~) 
(11) 
and the program is: 
u~:u0, tJd:( ua:~. Ub:7.~ (a --~ b)). 
dx:7 ti.st.(p(x); 
p(x:7 ttst)= 
ttstC(x, 
s 
tit3:7 fist. Uz:7 ttst.v:(z 6~ []7 ~ false)), 
XO~Xl ,V, 
*,o n,11)) 
We show (10) by first simplifying its conclusion: 
F 0 (no ~.~ y) 
and then applying induction on y. This can now be demonstrated by appeal to 
the definition of 6~, whose inhabitant proof object instantiates the program. 
The program now looks like this: 
tJ'c: tl0. tJd:( Hct:~. Ub:7.0 (a --~ b)). 
[3x:'[ [.i.st.(p (x); 
p(x:T ti.st) = 
ttstC(x, 
s 
U~ :7 ttst. tJz:7 ti.st.v: (z e~ []7 ~ fatse)), 
Xo~Xl ~Y, 
M(7)(x0)(z) n ,,,)) 
where .A/f is the proof object of definition (1). 
Finally, we appeal to the induction hypothesis of x (called v) to fill in the 
uninstantiated ~bl 1 and complete the program. 
U~:Uo. Ud:( Ua:z. tJb:,.a (a -~ b)). 
Ux :-~ [i.st.(p(x); 
p(x:. t~st) = 
tistC(x, 
s 
lJ~ :~ tist. Uz:* tist.v: (z e~ []z ~ fatse)), 
XO,Xl ,Y~ 
(M(x0))(z) n v)) 

245 
6 
Normalization 
We now have our WTT module for parameterised subset. However, (12) is 
clearly a higher-order structure, since it has two arguments which are types, "~ 
and d. It also has embedded non-canonical forms, such as the application of M 
to its arguments. Before we can convert this program into one runnable directly 
as a "normal" logic program, we must evaluate and instantiate these structures, 
respectively. Evaluation of M, as far as the instantiation of its variables may be 
performed immediately, in the obvious way, as licensed by the V type evaluation 
rules. To instantiate ~ and d, we need another type. I will use iN here, although I 
have omitted its proof rules for reasons of restricted space. All we need to know 
is that iN E Ll0, and that the type Va E iN.Vb E iN.0 (a ------IN b) is inhabited, 
thus: 
I:la E 1~./:lb E iN.e(a); 
e(a:iN) = r,rr 
f(b); 
f(b :iN) = iNe(b, 
c (o -- o), 
bo,w, 
7~(U: (0 ---- s(O) ~ fatse)), 
XO,V, 
o(b); 
0(b:iN) = iNC(b, 
na( : 
o 
bo,w, 
v(bo)) 
k Va:~.Vb:iN.0 (a =~ b) 
Again, it is worth emphasising that the production of such an algorithm is a 
straightforward, and in this case trivially automated, prooL This version of the 
equality predicate works by counting down the natural numbers; a better version 
would use a decision procedure built in as a basic type, which would yield a more 
efficient program. 
Given this definition, the evaluation rules of the calculus may be used to 
reduce the original modular specification to the following: 
Vx:iN List.V~ :1~ tist.O (Vz:~.z E~--*z E~ ~) 
Such an evaluation results in parallel evaluation of the proof object, so the proof 
object we end up with is convertible into the subset relation for lists of naturals 
as required. 

246 
7 
Conclusion 
In this paper I have discussed how a higher-order extension of the VVh.etk system 
can help us synthesise modular programs. The example has shown that the 
system works for programs which are parameterised both in type and in sub- 
module. I have sketched the outline of an example proof, and shown that it is 
essentially the same as that for the same example in the YVlxetk system, though 
the modularity of WTT makes things slightly easier, in that it is not necessary to 
re-synthesised the member predicate - we can simply plug in an existing definition 
as a module. 
The consequences of all this are significant. It has been shown elsewhere 
that logic program synthesis techniques work well for compiling ngive or non- 
executable specifications into comparatively efficient programs. The question has 
always been: "what about scaling up?". The modularity of the WTT system is 
one answer to this important question. 
8 
Acknowledgements 
This work has been supported by ESPRIT basic research project #6810, "Com- 
pulog II". I am very grateful to my colleagues in the DREAM group at Edinburgh, 
in particular Alan Smaill, and in the Compulog project for their advice and sup- 
port. I also thank Frank Pfenning, Andrei Voronkov and David Basin for their 
comments on the original version of YVhetk. 
References 
[Bundy et al 90a] 
[Bundy et al 90b] 
[Bundy et al 90c] 
[Constable 82] 
[Martin-Lhf 79] 
A. Bundy, A. Smaill, and J. Hesketh. Turning eureka steps into cal- 
culations in automatic program synthesis. In S.L.H. Clarke, editor, 
Proceedings of UK IT 90, pages 221-6, 1990. Also available from 
Edinburgh as DAI Research Paper 448. 
A. Bundy, A. Smaill, and G. A. Wiggins. 
The synthesis of logic 
programs from inductive proofs. In J. Lloyd, editor, Computational 
Logic, pages 135-149. Springer-Verlag, 1990. Esprit Basic Research 
Series. Also available from Edinburgh as DAI Research Paper 501. 
A. Bundy, F. van Harmelen, A. Smaill, and A. Ireland. Extensions 
to the rippling-out tactic for guiding inductive proofs. In M.E. 
Stickel, editor, lOth International Conference on Automated Deduc- 
tion, pages 132-146. Springer-Verlag, 1990. Lecture Notes in Ar- 
tificial Intelligence No. 449. Also available from Edinburgh as DAI 
Research Paper 459. 
R.L. Constable. Programs as proofs. Technical Report TR 82-532, 
Dept. of Computer Science, Cornel1 University, November 1982. 
Per Martin-Lhf. Constructive mathematics and computer program- 
ming. In 6th International Congress for Logic, Methodology and 
Philosophy of Science, pages 153-175, Hanover, August 1979. Pub- 
lished by North Holland, Amsterdam. 1982. 

247 
[Wiggins 92a] 
[Wiggins 92b] 
[Wiggins et al 91] 
G. A. Wiggins. Negation and control in automatically generated 
logic programs. In A. Pettorossi, editor, Proceedings of META-92. 
Springer Verlag, Heidelberg, 1992. LNCS Vol. 649. 
G. A. Wiggins. Synthesis and transformation of logic programs in 
the Whelk proof development system. In K. R. Apt, editor, Proceed- 
ings of JICSLP-92, pages 351-368. M.I.T. Press, Cambridge, MA, 
1992. 
G. A. Wiggins, A. Bundy, I. Kraan, and J. Hesketh. Synthesis and 
transformation of logic programs through constructive, inductive 
proof. In K-K. Lau and T. Clement, editors, Proceedings of LoPSTr- 
91, pages 27-45. Springer Verlag, 1991. Workshops in Computing 
Series. 

A model of costs and benefits 
of meta-level computation 
Frank van Harmelen 
SWI 
University of Amsterdam 
frankh@swi.psy, uva.nl 
Abstract. It is well known that meta-computation can be used to guide 
other computations (at the object-level), and thereby reduce the costs of 
these computations. However, the question arises to what extent the cost 
of meta-computation offsetts the gains made by object-level savings. In 
this paper we discuss a set of equations that model this trade-off between 
object-savings and meta-costs. The model shows that there are a number 
of important limitations on the usefulness of meta-computation, and we 
investigate the parameters that determine these limitations. 
1 
Introduction 
One of the most often stated aims of meta-programming is search-control: a meta- 
program is used to guide the computation at the object-level. Often, this takes 
the form of a meta-program choosing among multiple applicable object-level 
computations. A large body of literature exists on this type of meta-programs, in 
areas like knowledge-representation, (logic-)programming and theorem proving. 
Although many other types of meta-programs are both possible and useful, 
this paper will only consider meta-programs that are used to guide the com- 
putation at the object-level. This type of meta-program gives rise to a trade- 
off situation, in which costs should be compared with benefits. The benefit of 
recta-computation is that it leads to a better choice among object-computations, 
and therefore to savings at the object-level, since useless or expensive object- 
computations can be avoided (see e.g. [1] for results in the area of theorem 
proving). On the other hand, meta-computations themselves often have a con- 
siderable cost, and this cost might offset any savings that are obtained by that 
very same computation. 
This trade-off (between savings made by meta-level choices and the costs of 
having to make these choices) has been recognised in the literature: [5], [2] and 
[4, chapter 7] report on experimental results on measuring the size of the meta- 
level overhead, and the large literature on partial evaluation tries t.o reduce the 
size of this overhead. 
The goal of this paper is to investigate a theoretical model of the costs and 
benefits of meta-computation. After setting out the formal assumptions that 
underlie this work (Sect. 2), we present in Sect. 3 a quantitative model developed 
by [6]. In the context of this model, we postulate some reasonable properties of 

249 
meta-computations (Sect. 4), and illustrate the model with some examples (Sect. 
5). In Sect. 6 we extend and generalise the basic model from Sect. 3. 
2 
Assumptions 
We will assume that there are two independent methods for solving a particular 
object-level problem, and we will call these methods x and yl. We also assume 
that each of these methods has a certain expected cost, which we will denote by 
c= and %. Furthermore, we assume that z and y are heuristic methods, i.e. they 
are not guaranteed to solve the object-problem. Instead, we will assume that 
each method has a specific chance of solving the given object-problem, which we 
will write as Px and py. 
The goal of the meta-computation is to choose among the two object-methods 
x and y in order to solve a given problem in such a way that the overall cost of the 
object-computation is minimised. Because in general x and y are not guaranteed 
to solve the problem (p= and Pv might be smaller than 1), the meta-computation 
must not choose between either x or y, but it must choose the ideal ordering 
of z and y: first try x, and if it fails, then try y, or vice versa. We will write 
c,;y to denote the expected cost of first executing x followed by y if x fails, and 
similarly for Cy;,. 
The meta-computation that determines this choice will again have a cer- 
tain cost, which we will write as cm. Again, we will assume that this meta- 
computation is heuristic, i.e. it will make the correct choice of how to order x 
and y only with a certain chance, which we will write as pro. 
We assume that without meta-level computation, the system will try to use 
the two methods in a random order to solve the object-problem. The goal of the 
model will be to compute the savings (or losses, i.e. negative savings) that are 
obtained by using meta-computation to choose the ordering of x and y instead 
of making a random choice 2. These expected savings will be denoted by s. 
All of this notation (plus some additional notation used in later sections) is 
summarised in Table 1. 
3 
The 
Savings 
Function 
In this section, we will derive the expression for the expected savings obtained 
by making a correct meta-level choice concerning the optimal order in which to 
execute two object-level methods. 
Given the assumptions about x, y, c=, %, p= and py, the expected cost of 
executing x before y, c=;y is: 
cx;~ = c= + (1 -p=)% 
(1) 
1 In Sect. 6, we will show how the model can be extended to deal with an arbitrary 
number of methods. 
2 In Sect. 6 we will show how the model can be adjusted to accommodate the more 
realistic assumption that the system will execute the methods in some fixed order if 
no meta-computation is done. 

250 
Table 1. summary of notation 
meaning 
x,y 
C~Cy 
Cx;y 
Px,Py 
Cm 
Pm 
Is 
object-methods 
expected cost of object-methods 
expected cost of first executing x then y 
chance that object-method will solve problem 
cost of meta-computation 
chance that meta-computation makes the correct choice 
expected savings made by meta-computation 
Z~ 
difference in expected costs between the two object scenarios 
utility of method x 
namely the expected cost of executing z plus the expected cost of executing 
y, but reduced by the chance that y is not executing because z has succeeded 
in solving the problem. An analogous expression holds for cy;~:. Notice that (1) 
reduces to simply the expected cost of c. when z is a complete method (i.e when 
p~ = 1). 
The decision to try x before y should be made when 
e.;y < 
(2) 
or equivalently, using (1): 
< p lc . 
(3) 
The quantity r 
= p~:/cz can be seen as a measure of the utility of method z. 
The utility of a method x increases with its success rate p. and decreases with 
its expected costs c.. The above inequality (3) says that the method with the 
highest utility should be tried first. 
However, the values for success rates and expected costs of x and y (and 
therefore the values of r 
and r 
will not in general be available to the 
system, and will have to be computed at the cost of some meta-level effort, 
cm. Once the meta-level has estimated r 
and r 
the optimal ordering of 
the two methods can be determined. We can now derive the expteced savings s 
made by executing the methods in this optimal order as follows: we assume that 
without any meta-level effort, the system chooses a random ordering of z and y. 
The expected savings are then the cost of executing a randomly chosen ordering 
minus the cost of executing the methods in the optimal ordering, increased with 
the cost of finding the optimal ordering: 
savings = cost-of-random-ordering -- 
(cost-of-chosen-ordering + meta-level-cost) 
and the expected cost of executing the methods in a random order is: 
c~:;~ + cy;~: 
2 
(4) 

251 
If the system spends cm on meta-level effort and then chooses x before y as the 
optimal ordering, the expected execution cost would be: 
c=;y + cm. 
(5) 
The expected savings would then he the difference between these two formulae: 
Cy;re -- Cx;y 
cm. 
(6) 
2 
This would be the expected savings if the system preferred x over y on the basis 
of its estimates of 4(x) and r 
In general, we cannot expect that the meta- 
level will always succeed in computing the true values of r 
and r 
We can 
adjust our model to the assumption that the meta-level prefers x over y (i.e. it 
claims r 
> r 
but that this decision is only correct with a probability pro. 
In this case, the expected execution costs would be 
pmc~;u + (1 - pm)cu;= + cm. 
(7) 
If we subtract this from the costs of executing a random ordering, and simplify 
the result, we get: 
(2pm - 1)(Cy;~ - c=;y) 
- 
cm 
(s) 
2 
These are the expected savings when the meta-level prefers x over y. An analo- 
gous expression holds for the reverse case. We can combine these two expressions 
to obtain the following expression for the expected savings s made by a meta- 
computation: 
s 
(2pro - 1)/4 
- 
= 
2 
cm 
(Pm 
em 
(9) 
where A is notation for Ic=;y -cy;= [ = IP~c= -p~c~ 1. The intuitive interpretation 
of A is that it represents the difference in costs between the optimal and the 
non-optimal object-scenario's (executing first x and then, if necessary, y, or 
vice versa). This concludes the derivation of the savings function (which closely 
followed [6]). 
An alternative derivation for s is as follows: the expected gains made by 
making the correct choice between x; y or y; ~ are Ic~;~ - c~;~ I = A. If the chance 
of a correct meta-decision is only pro, the maximal expected gains are reduced 
to p,~A. The savings made by a random choice would already have been -}A, 
reducing the expected savings made through meta-computation to p,~A - gA.I 
The costs of the meta-computation must also be subtracted from this, yielding 
a total of: 
s= p.~A- 89 
= (p.~-- 89 
(10) 
From this value for the savings function s we can already draw some con- 
clusions. The form s = (Pro - 89 
cm shows that even an ideal meta-level 
computation (with perfect results, Pm= 1 and no costs, c,~ = 0), can at best 
only save half the difference in expected object-costs (s = 89 
This is already 
a severe limit on what meta-level computations can gain. 

252 
1 
This maximal savings of ~A also puts an upper limit on the maximum 
amount of meta-effort that we should invest: because the expected savings can 
1 
never amount to more than ~A, it will certainly never be useful to make C,n larger 
than this same amount. Thus, any potential losses by spurious meta-computation 
could be limited given an estimate of A. 
Furthermore, we see that s is monotonically increasing with A, and this 
makes sense: the larger the difference in expected costs between the differ- 
ent object-computations, the larger the expected savings to be made by meta- 
computation. In the boundary case, when A = 0 and the ordering of object- 
computations is irrelevant, the expteced savings will be negative (since in that 
case, s = -c,~), and meta-computations will lead to a loss in overall efficiency. 
Finally, we see that when Pm= 89 i.e. when the meta-level decision does not 
improve over a random choice, meta-computation will again only lead to a loss 
in overall efficiency ( s = -cm), as expected. 
4 
Properties 
of Meta-computations 
In realistic situations, the value of p,~, the probability of making a correct choice 
between methods, will be dependent on the amount of meta-level effort spent, 
i.e. Pm= f(em). Placing this in (9) above, we get: 
= 
- 
89 
- 
(11) 
Obviously, we want to maximise s as a function of Cm. Exactly what shape s(cm) 
will have will depend on how the accuracy of the meta-computation (i.e. Pro) 
depends on the meta-level effort spent by the system, i.e. the shape of f(cm). 
The following are reasonable assumptions to make about f(cm): 
Monotonicity: We expect of a meta-level that the quality of its results does not 
decrease with increased effort, making f(cm) non-decreasing: 
df (cm) > 0. 
(12) 
dcrr t 
Lowerbound: With no meta-level effort, i.e. cm = 0, we assume Pm = 89 (because 
of the random ordering of z and y): 
f(0) = 89 
(13) 
Upperbound: Since f(cm) is a probability, we certainly expect 0 < f(cm) < 1. 
Together with (12) and (13) this gives: 
1 < f(cm) < 1. 
(14) 
2 
-- 
This upperbound on f(cm) immediately makes clear that any meta-level com- 
putation is eventually doomed to lead to losses: 
lim s(cm)=-c<) 
(15) 
since the positive term in (9) is limited to 89 the negative term -Cm will 
eventually dominate. 

253 
Diminishing returns: Finally, although this is not strictly necessary, we can ex- 
pect some effect of diminishing returns, giving a smaller increase in Pm for every 
further increase in cm: 
d2 f 
d(cm)2 (cm) < O. 
(16) 
5 
Examples 
For illustrational purposes, it is interesting to look at a number of example 
functions for f(cm) which have the above properties, and to see what the actual 
shape of the savings curve s(cm) would be for these functions. The first two 
examples are taken from [6]. 
Pm 
1 
1/2 
s 
f 
((A - 2)/2) - ln(A/2) 
C m 
a 
Fig. 1. example of diminishing returns in p.~ 
/n(A/2) 
b 
Example 1: Figure la shows the case for 
Pm= f(cm) -" 1 - 1_-c~ 
(17) 
The only significance of this function is that it obeys conditions (12)-(16), but 
otherwise it is arbitrary. It serves to illustrate the case where a relatively small 
amount of meta-level effort results in substantially improved performance, while 
there are diminishing returns for subsequent effort. Its convergence to Pm= 1 for 
cm ---* <x~ is arbitrary, and does not influence the qualitative shape of the savings 
curve for s(cm) shown in Fig. lb. In this figure, we can see that at a certain 
point, the expected savings achieved by meta-computation reach a maximum, 
and any further meta-level effort will only reduce the overall savings. With even 
more effort spent on meta-computation, the system will eventually behave worse 
than without any meta-level effort at all. 
It is instructive to notice that at the point of maximal expected savings, the 
value of pm is 1 - ~ (simply substitute ln(A/2) in (17)). This shows that for 
large A, it pays to spend effort trying to get pm close to 1, whereas for smaller A, 

254 
a small value of Pm is all that we can afford to compute. The costs of computing 
any better approximation of Pm will then not be paid back by the corresponding 
savings in object-computations. 
Ptn 
1/2- 
s 
,5/2 - c- 
cm 
. 
\ 
cm 
c 
a 
Fig. 2. example of maximised Pm 
Example 2: Similarly, Fig. 2a shows an example where increased meta-level effort 
initially improves the reliability of the choice among object-methods, but after 
some point (Cm = c) the decision is made with maximum reliability (in this case 
perfect reliability, Pm= 1), and any further meta-level effort does not contribute 
to a more effective control decision. The function used in this figure (shown as 
a solid line) is: 
{ 89 
+ 89 if c~ _< c 
Pm=f(Cm)= 
1 
ifcm >c 
(lS) 
Again, the only crucial properties of this example for f(cm) are conditions (12)- 
(16),. Other properties, such as the slope of f(cm) on [0, c], or the fact that 
f(cm) = 1 on [c, oo) are irrelevant to the qualitative shape of the saving curve 
shown as the solid line in Fig. 2b, where again the expected savings reach a 
maximum at some point, beyond which further meta-level effort will only degrade 
the performance of the system. 
Example 3: Whereas the previous examples showed meta-computations which 
improved the behaviour of the control decision gradually (in accordance with 
(16)), a final example shows what happens if meta-level reliability improves 
suddenly after some initial effort. 
Figure 3a shows the case of a meta-level which needs some initial effort to 
compute a good choice between object-computations, but whose quality does 
not improve after having made its decision: 
I1 if cm < c 
(19) 
Pm= f(cm) 
1 if c.-~ > c 

Pm 
C 
Cm 
255 
am 
Fig. 3. example of suddenly increasing pm 
The corresponding savings curve is shown in Fig. 3b. The interesting property 
of this curve is that the expected savings are initially negative (0 _< cm < 
c), and only become positive after a required minimum amount of effort. This 
is an important difference with the previous two examples: there, insufficient 
meta-effort might lead to non-maximal savings, but would never lead to actual 
losses, whereas the meta-computation of this third example does indeed yield 
losses at insufficient meta-effort. This third example shares with the previous 
two examples the property that too much meta-effort leads to reduced gains, 
and eventually to losses over no meta-computation at all. 
6 
Extensions 
The simple model above can extended in a number of ways. 
6.1 
Complete Methods 
The first extension is not really an extension, but rather a special case: our 
current model deals with heuristic methods which would have to be tried in 
sequence and we therefore have to take into account the expected costs of exe- 
cuting the second method in those cases where the first method failed. We might 
also consider choosing between complete object-methods, which always succeed. 
The choice is then not between executing first x and then y or vice versa, but 
between executing either x or y. The model deals with this situation as a simple 
special case. We simply take p~ = p~ = 1. Then A reduces to Ic= - Cyl, i.e. the 
difference between the expected costs of executing ciiher x or y as expected . 
6.2 
Harder Meta-level Problems 
We call one meta-level problem harder than another if for the same amount of 
recta-level effort cm, the system achieves a lower value of pm (i.e. the choice 

256 
between the applicable methods is made less reliably). 
In the case of the definition for f(cm) used in example 2, harder meta-level 
problems are represented by an increasing value of c, and are indicated by the 
family of dashed lines in Fig. 2a. The corresponding behaviour of the saving 
function s(c,~) is shown by the dashed lines in Fig. 2b. We see that when the 
meta-level problem gets harder, the optimum meta-level effort is found for a 
larger value of cm, and the corresponding savings are reduced. 
This behaviour illustrates a phenomenon often observed in developing meta- 
level systems, namely that the usefulness of meta-level inference cannot be il- 
lustrated adequately on very simple toy problems. For those problems, c will be 
very small, and any significant amount of meta-level effort is likely to be larger 
than c, and will thus overshoot the point of maximum expected savings. 
Sa,(Cm) 
Cm 
Fig. 4. savings for harder meta-problems 
A similar set of curves can be drawn for the example used in Fig. 1. If we 
take 
I -c./~ 
(20) 
pm=/(Cr.) = 1 - ~e 
le-C~ 
then increasing values of a > 1 will 
(instead of Pm= f(Cm) = 1 -- ~ 
j, 
represent harder meta-level problems. Again, the maxima for s(cm) for different 
values of a lie at increasing values of cm, and the corresponding savings are 
reduced. An example of this behaviour is shown in Fig. 4 which displays different 
curves s(cm) for values a = 1, 189 2, 3, 5. 
The same phenomenon occurs in example 3, where again, increasing values 
of c represent harder meta-level problems, which again lead to lower maximum 
expected savings, obtained at higher values of cm. An interesting additional effect 
is shown in this example: harder meta-level problems not only lead to reduced 
maximum expected savings, but the savings function is also positive on a smaller 
interval, making the balance for meta-computation even more delicate. 

257 
6.3 
Number of Methods 
Rather than modelling just two methods x and y, we can adjust the model to 
choose between n methods (a suggestion also made by [6]). Expression (1) can be 
generalised from 2 to n methods, so that the expected cost of executing methods 
zl,...,xn in that order is: 
n 
4--1 
c~,;...;~, =c~, + ~.[,(H(1-p=j))c~:, 
i=2 j=l 
(21) 
(i.e. the total cost is the sum of the cost of each method multiplied with the 
chance that all earlier methods failed). The optimal order for executing the 
methods would of course be some order xil;... ;xi, such that for all j, 1 < j 
n - 1: r 
>_ r 
Before we can derive the savings function for this generalised case, we must 
introduce some notation. The methods xl,..., xn can be executed in n! different 
orders, and we shall denote each such sequence by some crj, 1 < j < n!. Then 
coj is the expected cost associated with executing such a sequence (written as 
cxk;...;=~ in (21)). Furthermore, let us assume that r 
is the optimal order (i.e. 
it satisfies r 
> r 
whenever xk occurs earlier in or1 than xt). With this 
notation, we can derive the savings function analogously to the case n = 2 in 
Sect. 3. The expected cost of executing the methods xl,...,xn in a random 
order (i.e. the generalised version of (4)) is: 
n! 
~-'~j = 1 Caj 
n! 
(22) 
Equation (7), the expected cost of executing the optimal method (or1), chosen 
by the meta-level with probability Pro, now becomes: 
n~ 
pmc~ 1 + (1 -pro) ~j=2c'j 
~.: ~ 
+ ~m 
(231 
namely: the cost of ~r 1 times the probability that ~rl was chosen, plus the chance 
that any of the other methods was chosen times the average cost of one of the 
other methods, plus the cost of making the meta-level choice. 
As before, the expected savings of a meta-computation is the difference be- 
tween these two formula. Subtracting (23) from (22) gives, after simplification: 
where 
8 = (p~ - 1)~ 
_ c~ 
(24) 
A 
= 
n!- 1 - 
c~,. 
(25) 
Equation (25) shows us that the proper interpretation of A is the difference 
between the cost of the correct choice and the average cost of an incorrect choice. 

258 
In the case n = 2, this reduces to the difference in expected costs between the 
two possible sequences, ca 2 - co 1, written as Cy;~ - Cy;= in Sect. 3. 
From the generalised savings function shown in (24), we see that the max- 
imal expected savings are (1 - 
1 A 
~) 
. If we assume that A stays more or less 
constant with increasing n (since there is no reason why the average cost of a set 
of methods must increase or decrease for larger sets), we can conclude that for in- 
creasing n, the maximal expected savings will increase and will rapidly approach 
A (within 1% for n -:- 5). This gives a slightly rosier perspective on the maximal 
expected savings to be made by meta-computation than originally derived in 
Sect. 3, where the expected savings were limited to 89 namely (1 - ~)A for 
r$~2. 
6.4 
Initial Ordering of Methods 
The model assumed that with no recta-level effort, the system would make an 
arbitrary choice for the order in which it executed its object-methods x and y. 
A more realistic assumption would be that the system would apply x and y in 
some fixed order, say first x and then y, on the basis of some a priori knowledge 
that the system's designer has about r 
and r 
Suppose that with no meta- 
effort, the system chooses z before y, and that this choice is indeed the right one 
with a chance P0. In other words, the value f(0), the quality of the meta-level 
decision at no recta-effort, is no longer 89 as specified in (13), but is now P0. 
1 
Presumably, ~ < P0 _< 1, since the fixed ordering programmed into the system 
will be better than a random ordering. Because (13) has changed to 
f(0) = P0 
(26) 
Formula (14) must also change, into 
Po <_ f(cm) _< 1. 
(27) 
To derive the new value of the savings function, we follow the derivation of (10) 
above. In this derivation, we subtracted the savings made by a random choice 
(89 
This term must now be replaced by the expected savings made by an 
informed initial choice, which are p0 A. This leads to the following new savings 
function: 
S(Cm) = f(crn)A 
-- po A -- cm = (f(cm) 
-- po) A -- em 
(28) 
Notice that this reduces to (9) for the case P0 = 89 (the random choice case). 
Because of the new boundary condition (26), this again implies s(0) = 0, as 
before. Furthermore, if P0 - 1 is (and the initial ordering is already perfect), 
then (27)implies f(cm) = 1, and the savings function reduces to s(cm) = -Cm, 
and any meta-computation only leads to losses, as expected. 
Finally, the value of (28) is always smaller than the value of (9), because p0 > 
1 For the same reason, the maximum expected savings that can be obtained 
2" 
1 
by a recta-computation are reduced from ~A to (1 - po)A. This is just what 
one would expect, since without meta, effort, the system performs better than 
it did before, and as a result, the potential savings that can be made by the 
recta-computation are smaller. 

259 
6.5 
Cost Dependent 
on Success or Failure 
The assumption above was that a method, say z, had some associated expected 
cost c~, which was independent of whether the method succeeded or failed. This 
assumption can be lifted by introducing two costs, namely c~, the expected cost 
of x if it succeeds, and c{, the expected cost of z if it fails. The expected cost of 
executing method z is then: 
c ~ 
(1 - p=)c{ 
C~: =- p~: ='-F 
(29) 
namely the cost of x succeeding times the probability that it will succeed plus 
the cost of x failing, times the probability that it will fail. We can then uniformly 
substitute this new expression for any c~ in the above, and similarly for y. If we 
do this in (11, representing the expected cost of executing first method z and 
then method y, the resulting expression can be rewritten to the following: 
C3 
x- 
]\ 
X 
$ 
-- 
c ;y 
+(1 
+py% + (1 
(301 
which is exactly what we expect, namely the cost of z succeeding times the 
probability that x succeeds plus the sum of z failing and executing y times 
the probability that z fails. Notice that this equation reduces to (1 / when the 
distinction between success and failure costs is irrelevant (i.e. when c~ = c{). 
If we substitute (29) into the definition of the utility r 
we obtain: 
i 
(31) 
r 
c s 
(i 
c "e= el+ 
c{ 
From this we can see that the utility of ~c decreases if either failure costs or 
success costs increase, or when the success chance decreases. This is again as 
expected, and similar to the old value of r 
S 
Furthermore, we see that when p~ > 89 then an increase or decrease in c~ 
has a larger effect on r 
than an equal increase or decrease in c{. Thus, for 
a method which often succeeds, r 
is dominated by the success costs, and 
similarly the utility for mostly failing methods is dominated by the failure costs. 
More surprisingly, (31) also shows that for methods with very low failure 
costs c{, the utility r 
becomes simply inversely proportional to the success 
costs, and independent of the success rate. This is surprising because in the case 
of two methods with zero failure cost (thus: c{ = %I = 0), but different success 
rates (say p~ > py) we would expect z to be preferred over y, but (31) fails to 
capture this. 
A final, and perhaps somewhat counterintuitive implication from (31) would 
be the following. Suppose that method x fails by running into an infinite loop 
(e.g. because of a loop in the search space). If we model this by c~ = c~, this 
immediately means r 
/ = 0, implying that z is always to be selected as the 
last method. The counterintuitive aspect of this is that this conclusion is again 
independent of the success chance. 

260 
7 
Discussion 
The problem of choosing the correct amount of meta-effort in order to optimise 
the total savings is very similar to the problems tackled in classical decision 
theory (e.g. [7]). A number of the effects that we have observed in the models 
above are also well known in decision theory. In particular, the fact that the 
1 
(in the case n 
2) is known as the base-rate 
maximal savings are limited to ~A 
= 
effect: the gains of an informed decision are limited if a random choice already 
performs well (when the "base-rate" is already high), as in the case of n = 2. The 
reduction of the base-rate and the corresponding increase in maximal savings for 
increasing n (to (1 - ~,)A) is also a known effect. 
The law of diminishing returns (in our case modelled by assumption (16)) is 
also familiar from decision theory. Decision theory also gives us an explanation 
of the counterintuitive results at the end of the previous section for the case 
of zero or infinite failure costs. In decision theory this is called the boundary 
effect: if one of the dimensions in a multi-dimensional decision problem becomes 
0 or oe, then the model is no longer valid because this single dimension will 
entirely dominate all the other dimensions. In such cases, we should move to a 
new model, rather than simply substitute 0 or e~ in the old model. 
An interesting application of our theoretical model can possibly be found 
in the area of explanation-based learning. A well-known problem in that area 
is the so-called utility problem [3]: learning more control knowledge does not 
always lead to more efficient problem-solving behaviour, and learning too much 
may actually adversely affect efficiency. At first sight, it would seem that this 
effect could be explained by a model similar to ours. Further research is required 
to shed lighton this issue. 
Finally, a remark is in order on the usefulness of our model. One might object 
that the above results are not very useful since in practice it will be very hard, 
if not impossible, to obtain the actual values for the costs and probabilities 
involved in a particular system. The main value of our model is therefore a 
different one: rather than using it to compute numerical values in a concrete 
system, it teaches us general lessons about the qualitative behaviour of a whole 
class of meta-systems in general, lessons which are sometimes surprising and 
perhaps not obvious at first sight. 
8 
Conclusions 
We can summarise the main conclusions from this model as follows: 
- The model shows that a trade-off does indeed exist between the costs of 
meta-computation and the savings obtained by it. This results in a situation 
where savings are maximised at a certain amount of meta-effort. Both more 
and less meta-effort will lead to non-maximal savings. 
- Meta-computation may also lead to a loss in efficiency (when compared to 
doing only object-computation). This will always happen if the meta-effort 

261 
becomes greater than a certain maximum (too much meta-effort), but might 
also happen in certain cases if meta-effort is less than a certain minimum (not 
enough meta-effort). The loss of overall efficiency at high amounts of meta- 
effort explains the phenomenon that the usefulness of meta-computation is 
often hard to illustrate on the basis of small examples. 
- An important quantity in the analysis of meta-computation is the difference 
in the costs of alternative object-computations (A in the above). The savings 
to be made by a meta-computation are proportional to A, and the maximum 
savings (and consequently an upperbound for the amount of meta-effort) are 
A, and even less than that in the case of an informed initial ordering. 
The overall conclusion from all of this is that meta-computations are not an 
unqualified blessing, and that the savings to be made from such computations 
are often less than expected, and only occur within a narrowly defined interval of 
meta-effort. Before one decides to use meta-computation as a means to control 
object-computation, a careful analysis Of crucial quantities like A, r and f(cm) 
is required. 
Acknowledgement: I am grateful to Annette ten Teije for her detailed comments 
and suggestions. She also provided the derivation for the case n > 2. 
References 
1. J. Hesketh A. Bundy, F. van Harmelen and A. SmaiU. Experiments with proof plans 
for induction. Journal of Automated Reasoning, 7:303-324, 1991. Earlier version 
available from Edinburgh as DAI Research Paper No 413. 
2. H. Lowe. Empirical evaluation of meta-level interpreters. Master's thesis, Depart- 
ment of Artificial Intelligence, University of Edinburgh, 1988. (M.Sc. Thesis). 
3. S. Minton. Quantitative results concerning the utility of explanation-based learning. 
Artificial Intelligence, 42:363-392, 1990. 
4. R. A. OKeefe. The Graft of Prolo9. MIT Press, Massachussetts, 1990. 
5. S. Owen. The development of explicit interpreters and transformers to control rea- 
soning about protein topology. Technical Memo HPL-ISC-TM-88-015, Hewlett- 
Packard Laboratories Bristol Research Centre, Bristol, U.K., 1988. 
6. J.S. Rosenschein and V. Singh. The utility of meta-level effort. Report HPP-83-20, 
Stanford Heuristic Programming Project, March 1983. 
7. D. yon Winterfeldt and Ward Edwards. Decision Analysis and Behavioral Research. 
Cambridge University Press, 1986. 

A Basis for a Multilevel 
Metalogic Programming Language 
Jonas Barklund, Katrin Boberg and Pierangelo Dell'Acqua* 
Uppsala University 
Computing Science Dept., Box 311, S-751 05 Uppsala, Sweden 
F~mail: jonas@csd.uu, se, katrin~csd.uu, se or pier@csd.uu, se 
Abstract. We are developing a multilevel metalogic programming lan- 
guage that we call Alloy. It is based on first-order predicate calculus 
extended with metalogical constructs. An Alloy program consists of a 
collection of theories, all in the same language, and a representation 
relation over these theories. The whole language is self-representable, 
including names for expressions with variables. A significant difference, 
as compared with many previous approaches, is that an arbitrary num- 
ber of metalevels can be employed and that the object-meta relationship 
between theories need not be circular. 
The language is primarily intended for representation of knowledge and 
metaknowledge and is currently being used in research on hierarchical 
representation of legal knowledge. We believe that the language allows 
sophisticated expression and efficient automatic deduction of interesting 
sets of beliefs of agents. 
This paper aims to give a preliminary and largely informal definition of 
the core of the language, a simple but incomplete and inefficient proof 
system for the language and a sketch of an alternative, more efficient, 
proof system. The latter is intended to be used as a procedural semantics 
for the language. It is being implemented by an extension of an abstract 
machine for Prolog. 
1 Introduction 
We are interested in the representation of complex formalized knowledge, e.g., 
- knowledge containing metaknowledge, e.g., knowledge about how some part 
of the knowledge should be interpreted or applied; 
- knowledge that is too voluminous to organize as a single, one-level collection; 
or 
- knowledge that involves beliefs about other knowledge bases or agents. 
Our hypothesis is that such knowledge can favourably be structured in a collec- 
tion of theories, where some theories contain theorems about some of the other 
theories. This hypothesis is supported by previous research conducted by, e.g., 
* P. Dell'Acqua has been financially supported by both Uppsala Univ. and Univ. degli 
Studi di Milano. 

263 
Bowen [6], Eshghi [19], Aiello, Nardi & Schaerf [1], Costantini & Lanzarone [16], 
Kim fs Kowalski [21], and Brogi & Turini [i1L 
In order to test our hypothesis we are developing a metalogic programming 
language, Alloy, suited for expressing knowledge of the kind just described. A 
brief description of the language was recently given by Barklund & Hamfelt [5]. 
The purpose of this paper is to summarize the language and its properties in 
further detail. 
The language can be characterized as a Horn clause language with resolution 
[25] that is extended with a representation of the linguistic elements and of its 
demonstrability. The novel ideas, as we see it, are the following. 
- The language has multiple theories; inferences of demonstrability for a cer- 
tain theory may be made in another theory that represents it. 
- The proof systems allows deductions at different metalevels to occur and 
interact in an intuitively appealing way. 
- One proof system allows a correct and efficient interleaving of computations 
at different metalevels, also in the presence of names of expressions with 
variables. 
The language has been influenced by Prolog [15], Reflective Prolog [18] and 
unnamed languages proposed by Kowalski [22, 23]. The intended procedural se- 
mantics is an extension of that proposed by Barklund, Costantini, Dell'Acqua 
and Lanzarone [4]. The procedural semantics will be realized through translation 
to sequences of instructions for an abstract machine, currently under develop- 
ment. 
As stated above, we primarily intend this language to be used in applications 
involving metareasoning and representation of metaknowledge, and secondarily 
in tools for manipulating programs (such as compilers and program transform- 
ers). This intention has influenced the development of the language by making 
us focus on representation of demonstrability. So far the language has been used 
for representing legal knowledge [5] and for a solution (not yet published) to the 
'Three Wise Men' puzzle, a well-known benchmark problem for metareasoning 
formalisms [1, 21]. 
Even though we intend Alloy to become a language with a well-defined con- 
crete syntax we prefer to use an abstract syntax in this report. This is partly 
because we find it too early to decide on a definitive syntax and partly because 
tile requirements on the concrete syntax of a programming language make it less 
convenient for a concise presentation of the language and its properties. 
Lack of space prevents us from presenting a background of metaprogram- 
ming in logic. We therefore trust the reader to have some prior knowledge of 
metaprogramming and of computational logic. 
2 
Language 
Elements 
An Alloy program constitutes a definition of a collection of theories, which are 
here sets of program clauses, closed under inference rules that will be presented 

264 
in Sect. 5. Such a definition contains theory-tagged program clauses and repre- 
sentation statements, the latter identifying the metatheories for every theory. 
The language is common for all theories and we describe it in this section. 
We let terms, definite program clauses and definite goal clauses be as usual 
[24] (but in what follows we will simply write "program clause" or "goal Clause" 
for a definite clause).2 We will refer to expressions composed from atomic sen- 
tences (or "atoms") by conjunction and implication operators as sentences. 
We will employ the standard convention that every free variable in a program 
clause is implicitly universally quantified. (We make this note here because below 
there will be nested encodings of tagged program clauses; this rule disambiguates 
such clauses.) 
A theory term is simply a term but one that is assumed to denote a theory. 
We introduce this name only to make the presentation of the syntax and the 
inference systems easier to follow, because theory terms will formally be treated 
just as the other terms. 
A tagged atomic sentence (or "tagged atom") is an expression 7- }- a, where 
r is a theory term and a is an atomic sentence. 
A tagged program clause is an expression r P to, where r is a theory term and 
tr is a program clause. It states that ~; is a theorem of the theory denoted by r 
(from here on we will simply write "the theory r"). Throughout this paper, the 
symbol '~-' denotes provability using the inference rules of Sect. 5. 
A tagged goal clause is like a goal clause except that it contains tagged atoms 
instead of ordinary atoms. The tagged goal clauses includes the empty tagged 
goal clause with no atoms and is true in every interpretation. 
A representation statement is an expression 7"M ~'ro- It states that the theory 
TM contains a representation of the theory To. We also say that the theory rM 
is a metatheory for 7-0. In order to explain what this means, we first have to 
explain representation. 
For every expression r of the language, there is an encoding of the expression 
denoted by a ground expression r-r that is also in the language. The encodings 
of terms and clauses are denoted by terms. The encodings of tagged clauses and 
representation statements are denoted by sentences. 3 We will not say here ex- 
actly what the representations are; we can view them here as abstract datatypes. 
However, we expect that application of substitutions and the unification opera- 
tion is extended to handle encodings. Moreover, in this presentation we will also 
assume that the sentences representing tagged clauses and representation state- 
ments are atomic, so expressions rr 0 ~- ~ and r'TMI>TO-I can appear in any place 
where an atomic sentence can appear. It might help the reader, when comparing 
our work with that of others, to assume that r'ro F ~'~ is an atomic sentence 
Demo(r'To 7, rtr 
We will discuss these issues in more detail in connection with 
the proof systems. 
We can now explain the meaning of a representation statement TM t> 7- 0 . It 
states that 7-0 F ~ is true if and only if rM }- fro F ~7 is true. Therefore, if we 
We will use an alphabet where function and predicate symbols begin with uppercase 
letters while variable symbols begin with lowercase letters. 
3 Employing sentences as encodings is clearly a nonstandard device, but note that they 
are used only to represent the metalogical part of the language. 

265 
have proved To }- ~ and rM ~ rO then we may infer rM }- rvo F" ~'~. Similarly, 
from TM J- r'To }- K~ ~ and "rM E> 7- 0 we are entitled to deduce ro 1- ~. 
Representation statements define a representation relation between theories. 
We may want to restrict this relation in order to provide more efficient proof 
procedures. Some possible restrictions are: 
- Existence of a (irreflexive) partial order on theories (i.e., no cycles). 
- 
A finite number of theories. 
- That no theory have more than one metatheory. 
- 
No infinite chains .-. T3 ~ ~'2 ~ ~'1. 
Some of these restrictions will prevent a theory from being its own metatheory. 
Such a restriction seems to simplify implementation but yields a weaker language 
without direct self reference. In many situations this is highly desirable, and 
certain reasonable forms of self-reference can instead be programmed at the 
metalevel. However, we have not yet investigated the full consequences of the 
various restrictions. 
3 
Encodings, 
Substitutions, 
Equality 
and Unification 
As stated above, rr 
is some expression that denotes an encoding of r We allow 
the writing of "parameterized" encodings, containing metavariables where there 
would otherwise have been terms, function symbols or predicate symbols. By 
"metavariables" we mean variables having a scope which is the program clause 
in which the current encoding appears as a term; the dot signifies a "hole" in 
the encoding, where such a variable can appear. The metavariables are thus not 
themselves part of the encoded expression, but encodings of expressions of the 
appropriate kind may be substituted for them, yielding proper encodings. (We 
refrain here from discussing what results from substituting other expressions for 
the metavariables.) 
For example, rF(A,v) 7 is the encoding of the (nonground) term F(A,v), 
while rF(A, ~)l, r~(A, v)l, rk(y, ~)n and rzbn are parameterized encodings. Sub- 
stituting an encoding of a function symbol for x and encodings of terms for y, z 
and w yields proper encodings. (The last expression, r~bT, is equivalent to w.) 
~rthermore, rT(A) t- P(F(v),B) "~ properly encodes the tagged program 
clause T(A) }- P(F(v), B) while rT(~) ~- ~j(F(v), ~)'~ is parameterized with the 
metavariables x, y and z. Of these, encodings of terms must eventually be substi- 
tuted for x and z, while an encoding of a predicate symbol must be substituted 
for y. (In both examples, v is the only variable known to be universally quanti- 
fied over the program clause. However, in the second example, instantiating z to 
an encoding of a nonground term might reveal further variables with the scope 
of the program clause. 4) 
4 If this appears to give ambiguous scoping, let us point out that this is what happens 
when encodings of program clauses are developed through unification. When all 
"dotted variables" have been instantiated to proper encodings, then the encoding 
of the program clause is complete and its local variables can be unambiguously 
identified. 

266 
The equality theory of our language is "Herbrand equality", as defined by 
Clark [14], extended with three axioms for encodings: 
rto(tl,... , tk ) -I = r uO(Ul , . . . , Ut) ~ -+ 
k=lA 
rt0"l = ruo~ A rtln = rUlT A ... A rtk~ = rut7 
r T 1 ~ ~1 "l = rT 2 b ~2 ''I --')" 
rT"l-I = rT2-1A 
r/~l"l ~ r'/~2"1 
rT"l, 1 I> 7"1,2 n = r7"2,1 l> "/'2,2 n --~ 
rTl,l -I -~- rT2,1-1A 
rT1,2-1 ~ I-T2,2-I 
r~m = t. 
Together these statements ensure compositionality of encodings. For example, 
we have that x = rtn ~ rF(~)n = rF(t)~. 
Moreover, for any pair of distinct symbols al and as, there is an axiom 
ral 7 ~ ra2 n, stating uniqueness of encodings. 
The unification algorithm must be extended accordingly. We only give two 
examples here of what it should produce when given (partially instantiated) 
encodings. 
- Unification of the names rT(k) b fl(F(A), v) "1 and rT(u) b Q(~, ~b) ~ succeeds 
with the substitution that replaces x with ru~, y with rQ1, z with rF(A)n, 
and w with rv~ as most general unifier. 
- The names rF(A, u) "~ and rF(A, v) n do not unify because that would imply 
rub = rye, which is false. 
4 
Examples 
Before explaining the proof system of the language we shall look at two examples 
that show some of its abilities. 
The following program (from a similar Reflective Prolog program [18]) con- 
tains three theories denoted by the symbols M, O1 and 05, where M is intended 
to be a metatheory of O1 and Oz. 
M k ro 2 b ~(~, b)'~ +-- rO I b ~(h, ~)n 
(1) 
M b r02 b k(b, d) "~ ~- Symmetric(x) A r01 k ~(4, ~)7 
(2) 
M k Syrametric(rAs_good_as l) 
(3) 
01 b As_good_as(p, Gold) +- Honest(p) 
(4) 
01 k" Honest(Mary) 
(5) 
M ~, O1 
(6) 
M ~ 02 
(7) 

267 
The statement As_good_as(Mary, Gold) is a theorem of both Ox and 02 but in 
addition also As_9ood_as(Gold , Mary) is a theorem of 02. It could be derived as 
follows. Resolving clause 4 with unit clause 5 yields 
As_good_as(Mary, Gold) 
in O1. As M is a metatheory of O1 (according to 6) we obtain 
rO 1 F As_good_as(Mary, Gold) 7 
(8) 
as a theorem of M. The sentences Symmetric(x) and v01 F k(d, ~)7 of clause 2 
can be resolved with unit clauses 3 and 8, respectively, yielding 
tO2 ~- As_good_as(Gold, Mary) ~ 
as a consequence. Because M is a metatheory also of 02 (7) we obtain 
As_good_as(Gold, Mary) 
as a theorem of 02. 
Without clause 6 we would not have had M as a metatheory of Ox. Then 
there would have been no correspondence between having a theorem r in O1 
and a theorem tO1 ~- r 
in M, and vice versa (similarly for clause 7 and the 
relationship between M and 02). 
It should be obvious that in the theory 02 the predicate symbol As_9ood_as 
denotes a relation that is the symmetric closure of the relation denoted by 
As_good_as in the theory O1. (The same would be true also of any other predicate 
symbol lr for which Symmetric(fir ~) is a theorem in M.) 
Alloy is expressive enough, however, that much more sophisticated relation- 
ships between theories can be expressed. For example, the following program 
makes theory 02 'inherit' (not necessarily unit) clauses from O1 and obtains a 
symmetric relation that depends also on information in theory 02. 
M F v02 I- ~(h, b) +-- ~ +- tO1 F ~(a, b) +-- ~n 
(9) 
M t- tO2 b e(b, 5) e- ~ ~- Symmetric(x) A tO1 t- ~(~, b) +- ~ 
(10) 
M P Symmetric(rAs_good-as n) 
(11) 
Ox I- As_good_as(p, Gold) ~- Honest(p) 
(12) 
02 I- Honest(Mary) 
(13) 
M ~, 01 
(14) 
M ~ Oo_ 
(15) 
The statements As_good_as(Mary, Gold) and As_good_as(Gold, Mary) are theo- 
rems of O2 also for this program, even though none of them is a theorem of O1. 
The second of these could now be derived as follows. The clause 
As_good_as(p, Gold) +-- Honest(p), 
where p is universally quantified, is apparently a theorem of 01; M is a meta- 
theory of 01 (14) so 
tO1 b As_good_as(p, Gold) +-- Honest(p) ~ 
(16) 

268 
is a theorem of M. The sentences Symmetric(x) and rO 1 b ~(~, b) ~- ~ of 
clause 10 can be resolved with unit clauses 11 and 16, respectively, yielding 
tO2 ~- As_good_as(Gold,p) ~- Honest(p) ~ 
as a theorem of M. As M is a metatheory also of 02 (15) we obtain 
As_good_as(Gold,p) t- Honest(p) 
(17) 
as a theorem of 02. Resolving clauses 17 and 13 finally yields the theorem 
As_good_as(Gold, Mary) in 02. 
This expressivity is similar to that obtained by Brogi, Mancarella, Pedreschi 
and Turini [9] when applying their work on composition operators for theories 
[8] to modules. In their work, a module can be constructed extensionally or 
intensionally, corresponding to the subgoals rO 1 F ~(~, b)~ and cO1 F ~(i~, b) +-- 
~'~ of clauses 2 and 10, respectively, that inspect either the extension or the 
intension of the theory O1. In other aspects their work is quite different from 
ours, e.g., in that they construct an algebra for theories, where a theory, in 
practice, can be treated much as a powerful kind of data structure. We, on the 
other hand, write executable specifications for theories. The approaches are thus 
complementary. 
As a third example, showing some use of encoding nonground expressions, 
consider the following program. (The last clause contains the encoding of a 
nonground program clauses Irresistible(f) ~- Female(f) and Likes(y,z) t- 
Irresistible ( z ). ) 
Beliefs(Mary) F 
Charming(x) +- r Beliefs(i~) F Likes(h, Mary) 7 A Name(x, n) 
(18) 
Beliefs(Mary) ~- 
r Beliefs(h) ~- Irresistible(f) ~ Female(f) ~ 
+-- Male(m) A Name(m, n) 
(19) 
Beliefs(Mary) F e Beliefs(k) F Female(Mary) n 
(20) 
Beliefs(Mary) b Male(John) 
(21) 
Beliefs(Mary) k V Beliefs(k) b Likes(y,z) ~ Irresistible(z) n 
(22) 
The clauses can be seen as stating that Mary has the following five basic beliefs: 
anyone who she believes is thinking they like her, she finds charming (clause 18); 
all men think all women are irresistible (clause 19); everyone think that Mary is 
a woman (clause 20); John is a man (clause 21); everyone think that if they are 
irresistible then everyone likes them (clause 22). We have assumed the existence 
of a predicate Name above, intending that an atomic sentence Name(t, vtq), can 
be proved for any ground term t, in any theory. 
From this program we can prove that Mary finds John charming (actually 
that she finds anyone charming who she believes is a man); the query can be 
expressed as a tagged goal clause 
~- Beliefs(Mary) F Charming(John). 
(23) 

269 
From clauses 19 and 21 (when solving the Name atom) we obtain 
Beliefs(Mary) F r-Beliefs(John) F Irresistible(f) ~ Female(f) ~, 
i.e., that Mary believes that John thinks all women are irresistible. By resolving 
this clause with clause 20 we obtain 
Beliefs(Mary) F r Beliefs ( John ) ~- Irresistible(Mary) q, 
i.e., that Mary believes that John thinks she is irresistible. By resolving this 
clause with clause 22 we obtain 
Beliefs(Mary) b r'Beliefs(John) F Likes(y, Mary) "~, 
i.e., that Mary believes that John thinks that everyone likes her (the variable y 
in the unit clause Likes(y, Mary) is universally quantified in that unit clause). 
Note that this resolution step involved substitution of variables at two levels: 
r'John'l for x and Mary for z. Resolving the clause so obtained with clause 18 
and solving the Name atom produces a tagged program clause 
Beliefs(Mary) F Charming(John) 
that can be resolved with the tagged goal clause 23 yielding an empty tagged 
goal clause, so the original goal clause is entailed by the program. 
5 
A Proof System 
This proof system is intended to give the reader an understanding of what can 
be proved from an Alloy program; it is not intended to be efficient. (See the next 
section for a short description of a more complicated but efficient proof system.) 
The following inference rule is a generalized Horn clause resolution rule that 
is capable of "indirect" reasoning. A theory vl contains a theorem that a theory 
r2 contains a theorem that a theory T3 contains a theorem, and so on. Finally, 
there is a theorem that a theory Vk contains two procedure clauses A ~-- C and 
H ~ B, where H can be unified with a selected atom tC (we designate the 
rest of the conjunction by ~C). Using the rule we may infer that 7"1 contains a 
theorem, etc., that Tk contains a theorem that is the resolvent of A r 
C and 
H +-- B on 1"C. 
T1 t- r~'2 t- -.- rTk b A ~ C 7''" ~ 
T1 F rv 2 F ...r~- k F H +-- B ~-.. ~ 
T1 F r- 
7 
0 = mgu(H, ~fC) 
T: F ...r~'k F (A ~ B A $C)O "~... 
As special cases of this rule we obtain a single-level resolution rule 
rFA~C 
rFH+--B 
8 = mgu(H, tC) 
v b (A +- B A J~C)8 
and a two-level resolution rule 
7-1F rr2 F A ~ C "~ vl b r'7-2 ~- H ~_ B "~ 8 = mgu(H, ?C) 
rl t- r-r2 F (A +-- B ^ ~C)O ~ 

270 
For example, when the theories represent the beliefs of agents, this rule allows 
an agent to reason that he believes another agent believes in some statement 
P, because he believes that the second agent believes in the statements Q and 
P+-Q. 
The following rule is a generalized meta-to-object linking rule [7, 28]. 
r 
7 
T1 ~- T2 ~-'''rTk b r-7-Ml>7-O 77"'" 
r- 
r- 
7 
T1 ~- T2 ~- ''" Tk ~-1-7-M ~- r-TO ~- g 777''" 
r" 
7 
T1 I- T2 I- ..-rT k I- r-TO I- tc 77.-- 
To understand the rule, it may help to first look at some of its special cases. The 
first is a direct linking rule 
7"M ~' 7"0 7"M f- rT"o I- t~ 7 
7"o P ~ 
stating: if T M is a metatheory for 7-0 and contains as a theorem that ~ is a 
theorem of 7"o, then we may infer that ~ is indeed a theorem of 7"o. 
Another special case is an indirect linking rule 
7"[ ~- VTM ~> 7"0 7 
7"1 ~- VT-M ~- rTO ~- E77 
7"I ~- r-TO ~- I'~7 
If a theory I has a theorem that theory M is a metatheory for theory O and 
another theorem that M has a theorem that theory O contains ~, then theory 
I infers that theory O contains ~. 
The generalized rule not only allows transfer of information from a meta- 
theory an object theory, but also permits reasoning that is conditional to a 
hypothesis that such a relationship exists. 
There is also a corresponding generalized object-to-meta linking rule 
r 
7 
7"I ~- 7"2 ~- "''rTk ~- rTM~T077''" 
r 
r- 
7 
7-1 l- 7-2 l- ... 
Tk I- r T" 0 I- ~ 77" "" 
F 
r- 
7 
T 1 ~- T2 ~- "'" Tk ~- rTM ~- ['TO ]- I~, 777"'" 
with corresponding special cases. One might get the impression that the two link- 
ing rules together with a single-level resolution rule could replace the generalized 
resolution rule. For example, to get 
~'x ~" rr~ ~- (A e- B A $C)0 n 
from 
rlFr-r2bA+--C 7 
and 
rx~-r7-2f-H+'-B 7 
(where 0 is a mgu of H and 1"C) one would infer 7-2 F A e- C and T2 ~" H e- B 
using the meta-to-object linking rule, resolve these clauses (obtaining 7-~ ~- (A +- 
B A $C)0) and finally apply the object-to-recta linking rule. This is correct only 
if T1 ~ v2, while the generalized inference rule can always be applied. Expressed 
in the domain of agents: One may reason about how other agents would reason, 

271 
without actually asking them to hypothesize the premisses and tell us their 
conclusions. Expressed from an implementation point of view: We can simulate 
a computational device instead of actually invoking it. 
We should mention that an implementation of this proof system is likely to be 
incomplete (with respect to a so fax unstated, intended semantics) because it may 
encounter proofs that require applications of the meta-to-object linking rule but 
where the encoding contains uninstantiated metavaxiables. The inference rule is 
then not applicable, unless an arbitrary instantiation is made. For completeness 
an interpreter would have to try all possible instantiations, a hopeless task. The 
proof system outlined in the next session is not only more efficient but its linking 
rules employ constraints on names, rather than mere translation, allowing them 
to be applied to paxti.ally instantiated encodings. 
6 
Outline 
of a More 
Efficient Proof 
System 
As a full description would become too long for this paper, we only outline here 
the efficient proof system for Alloy on which an implementation is being based. 
First we should analyse what 'efficient' should mean in this context. 
SLD-resolution is goal-directed in the following two ways: 
1. Every SLD-resolution step in a successful resolution proof is necessary in the 
sense that it resolves away some atom of the goal. 
2. Unification will immediately stop the exploration of a resolution series, if the 
selected atom cannot unify with the chosen clause. 
Of course, a nondeterministic choice of clauses may lead to unsuccessfully ter- 
minated resolution series before a proof is found, or even to nontermination, but 
that is a separate problem. Moreover: 
3. In an SLD-resolution series, the resolvents are always goal clauses. Therefore 
the set of program clauses (i.e., the left side of clauses sequents) remains 
constant while a proof is being sought. 
This property is exploited in the efficient implementation of Prolog-like lan- 
guages, as it allows compilation of the program clauses to efficient machine code. 
Note that the inference rules in the proof system of the previous section created a 
new program clause. Operationally that would correspond to an addition to the 
program, preventing or complicating compilation of program clauses. (Even if we 
were to replace the generalized resolution rule with a generalized SLD-resolution 
rule, there axe no obvious direct replacements of the linking rules.) 
Just like RSLD-resolution [18], our proof procedure combines reflection in- 
ferences with SLD-resolution steps in order to retain the three properties above. 
This ensures that if an object level deduction invokes a metalevel deduction, or 
vice versa, then it is because the result is needed. Moreover, unification (which 
is extended to a form of constraint satisfaction) will terminate unsuccessful mul- 
tilevel proofs as soon as possible. Finally, the program remains constant during 
execution. 

272 
Extending unification to constraint satisfaction over the domain of names is 
an elegant and implementation-wise straightforward way to get correct linking 
between levels. We employ the scheme that was proposed recently by Baxklund, 
Costarttini, Dell'Acqua and Lanzarone for a somewhat more restricted language 
[3, 4] (see also Christiansen [13]). 
First, unification and SLD-resolution is re-expressed in terms of equations 
instead of substitutions. Each resolution step sets up an equation system that 
either can be transformed to a solved form, corresponding to a most general 
unifier, or can be shown to have no solution. 
Next, the language of the equations to be solved by unification is extended 
with the operators 'up' and 'down' (for computing the name of an expression and 
computing what an expression names, respectively). It is no longer certain that 
an equation system can be transformed to a solved form or failed, because an 'up' 
or 'down' operator may be applied to an insufficiently instantiated expression. 
Therefore, it is necessary to retain some unsolved equations between resolution 
steps. We can think of these equations as unsolved constraints. 
The scheme above only computes names of ground expressions. A further 
complication when implementing the present language is that the 'up' and 'down' 
operators must have an additional parameter indicating a scope, so encodings 
of variable symbols occurring in the encoding of some program clause can be 
associated consistently with variables. The added complication is the price to 
be paid for this richer language. We should add that these "scopes" seem to 
be quite efficiently implementable (cf. the dictionaries of Barklund [2] and the 
substitutions of Sato [26]). 
7 
Related 
Work 
In constructing this language we have tried to remain closer to work on reflection 
and encodings in mathematical logic [27] than most other approaches. 
The language was obviously inspired by Reflective Prolog [18], differing from 
it in mainly three aspects: 
- Alloy has names for variables, so nonground expressions can be represented 
directly. This should make the language suitable for writing program ma- 
nipulating tools, such as partial evaluators, at least for the language itself. 
Moreover, knowledge that is naturally represented by quantified formulas 
can be more directly represented. We have not yet begun to exploit this 
capability. 
- The multiple theories allows a more elaborate structure of metaknowledge 
to be expressed directly (in Reflective Prolog there is a single amalgamated 
theory) and it seems possible to trade some expressivity for ease of imple- 
mentation by preventing theories from being their own metatheories. On the 
other hand, in principle it should not be too difficult to write in Reflective 
Prolog an interpreter for a language with this kind of theory structure. How- 
ever, incorporation of this fundamental construct explicitly in the language 
seems justified on grounds of efficiency and convenience. (The interesting 
multiple theory extension proposed for Reflective Prolog [17] was intended 

273 
for modelling communicating agents, by describing how theories exchange 
information, and is therefore quite different from the extension described 
here.) 
- The view of what is actually reflected between metalevels is conceptually 
quite different in the two languages, although the views coincide when only 
ground expressions are transferred. 
There are also other formalisms where a comparison should be useful: 
- 
Our language is also related to languages proposed by Kowalski [22, 23] in 
the use of multiple theories. Our language is indeed an attempt to concretize 
these ideas. 
- 
Brogi, Mancarella, Pedreschi & Turini [8, 9, 10] have investigated a collection 
of operators for composing theories. The "meta-interpretive" definitions of 
the operators can be expressed directly in Alloy. Although theories in Alloy 
are not to be thought of as data structures, the language allows theories 
to be denoted by arbitrary ground expressions. Alloy could accomodate a 
programming style where many theories (denoted by compound expressions) 
are defined, although extensional representations of the theories need not be 
computed. The operators by Brogi et al. could serve as a useful basis for 
defining more specific operators. 
- The encodings in this language are more abstract than the structural names 
of Barklund [2], Costantini and Lanzarone [18] and of Cervesato & Rossi [12], 
but less abstract than those of Hill & Lloyd [20]: We do not commit to a 
particular ground representation but there is a syntax for the representations. 
- The truth predicate proposed by Sato [26] is related to Alloy in that it too 
allows encodings of nonground expressions and reflection. However, there 
are also important differences, the most important being that the theory 
structure of Alloy can be used to prevent a theory from introspecting its 
own theorems. Sato shows how paradoxes can easily be expressed using his 
definition of the truth predicate; the programs can still be given semantics 
in three-valued logic. Alloy, as presented here, is a Horn clause language. It 
might be possible to incorporate some of Sato's ideas into Alloy, in order to 
extend the language to general clauses. 
- 
Alloy has interesting similarities with provability logics and we are presently 
investigating what results from this area are applicable, and if this language 
and its inference systems bring any novel ideas to that area. 
Acknowledgments 
We are indebted to Stefania Costantini, Gaetano Lanzarone, Andreas Hamfelt 
and Robert A. Kowalski for valuable discussions. Their ideas have significantly 
influenced this work. The referees provided many useful comments and sugges- 
tions that have improved the paper. 
The research reported herein was supported financially by the Swedish Na- 
tional Board for Technical and Industrial Development (NUTEK) under contract 
No. 92-10452 (ESPRIT BRP 6810: Computational Logic 2). 

274 
References 
1. Aiello, L. C., Nardi, D. and Schaerf, M., Reasoning about Knowledge and Igno- 
rance, in: H. Tanaka and K. Furukawa (eds.), Proc. Intl. Conf. on Fifth Generation 
Comp. Sys. 1988, Ohmsha, Tokyo, 1988. 
2. Barklund, J., What is a Meta-Variable in Prolog?, in: H. Abramson and M. H. 
Rogers (eds.), Meta-Programming in Logic Programming, MIT Press, Cambridge, 
Mass., 1989. 
3. Barklund, J., Costantini, S., Dell'Acqua, P. and Lanzarone, G.A., 
Reflection 
through Constraint Satisfaction, in: P. Van Hentenryck (ed.), Logic Programming: 
Proc. 11th Intl. Conf., MIT Press, Cambridge, Mass., 1994. 
4. Barklund, J., Costantini, S., Dell'Acqua, P. and Lanzarone, G. A., SLD-Resolu'tion 
with Reflection, to appear in Proc. ILPS'94, 1994. 
5. Barklund, J. and Hamfelt, A., Hierarchical Representation of Legal Knowledge 
with Metaprogramming in Logic, J. Logic Programming, 18:55-80 (1994). 
6. Bowen, K.A., Meta-Level Programming and Knowledge Representation, New 
Generation Computing, 3:359-383 (1985). 
7. Bowen, K. A. and Kowalski, R. A., Amalgamating Language and Metalanguage 
in Logic Programming, in: K. L. Clark and S.-/~. T~irnlund (eds.), Logic Program- 
ming, Academic Press, London, 1982. 
8. Brogi, A., Mancarella, P., Pedreschi, D. and Turini, F., Composition Operators 
for Logic Theories, in: J. W. Lloyd (ed.), Computational Logic, Springer-Verlag, 
Berlin, 1990. 
9. Brogi, A., Mancarella, P., Pedreschi, D. and Turini, F., Meta for Modularising 
Logic Programming, in: A. Pettorossi (ed.), Meta-Programming in Logic, LNCS 
649, Springer-Verlag, Berlin, 1992. 
10. Brogi, A., Program Construction in Computational Logic, Ph.D. Thesis, Diparti- 
mento di Informatica, Universit~ di Pisa, 1993. 
11. Brogi, A. and Turini, F., Metalogic for Knowledge Representation, in: J. A. Allen, 
R. Fikes and E. Sandewall (eds.), Principles of Knowledge Representation and Rea- 
soning: Proc. 2nd Intl. Conf., Morgan Kanfmann, Los Altos, Calif., 1991. 
12. Cervesato, I. and Rossi, G.F., 
Logic Meta-Programming Facilities in 'LOG, 
in: A. Pettorossi (ed.), Meta-Programming in Logic, LNCS 649, Springer-Verlag, 
Berlin, 1992. 
13. Christiansen, H., Efficient and Complete Demo Predicates for Definite Clause Lan- 
guages, in: P. Van Hentenryck (ed.), Logic Programming: Proc. 11th Intl. Conf., 
MIT Press, Cambridge, Mass., 1994. 
14. Clark, K. L., Negation as Failure, in: H. Gallalre and J. Minker (eds.), Logic and 
Data Bases, Plenum Press, New York, 1978. 
15. Colmerauer, A., Kanoui, H., Pasero, R. and Roussel, P., Un Syst6me de Commu- 
nication Homme-Machine en Fran~ais, Technical report, Groupe de Recherche en 
Intelligence Artificielle, Univ. d'Aix-Marseille, Luminy, 1972. 
16. Costantini, S. and Lanzarone, G. A., Analogical Reasoning in Reflective Prolog, 
in: A. A. Martino (ed.), Pre-Proc. 3rd Intl. Conf. on Logica Informatica Diritto, 
Istituto per la documentazione giuridica, Florence, 1989. 
17. Costantini, S., Dell'Acqua, P. and Lanzarone, G. A., Reflective Agents in Meta- 
logic Programming, in: A. Pettorossi (ed.), Meta-Programming in Logic, LNCS 
649, Springer-Verlag, Berlin, 1992. 
18. Costantini, S. and Lanzarone, G. A., A Metalogic Programming Language, in: 
G. Levi and M. Martelli (eds.), Proc. 6th Intl. Conf. on Logic Programming, MIT 
Press, Cambridge, Mass., 1989. 

275 
19. Eshghi, K., Meta-Language in Logic Programming, Ph.D. Thesis, Dept. of Com- 
puting, Imperial College, London, 1986. 
20. Hill, P. M. and Lloyd, J.W., The G6del Programming Language, MIT Press, 
Cambridge, Mass., 1994. 
21. Kim, J.S. and Kowalski, R.A., 
An Application of Amalgamated Logic to 
Multi-Agent Belief, in: M. Bruynooghe (ed.), Proc. Second Workshop on Meta- 
Programming in Logic, Dept. of Comp. Sci., Katholieke Univ. Leuven, 1990. 
22. Kowalski, R.A., Meta Matters, invited presentation at Second Workshop on 
Meta-Programming in Logic, 1990. 
23. Kowalski, R. A., Problems and promises of Computational Logic, in: J. W. Lloyd 
(ed.), Computational Logic, Springer-Verlag, Berlin, 1990. 
24. Lloyd, J.W., 
Foundations of Logic Programming, Second Edition, 
Springer- 
Verlag, Berlin, 1987. 
25. Robinson, J. A., A Machine-oriented Logic Based on the Resolution Principle, J. 
ACM, 12:23-41 (1965). 
26. Sato, T., Meta-Programming through a Truth Predicate, in: K. Apt (ed.), Proc. 
Joint Intl. Conf. Syrup. on Logic Programming 1992, MIT Press, Cambridge, Mass., 
1992. 
27. Smorynski, C., The Incompleteness Theorems, in: J. Barwise (ed.), Handbook of 
Mathematical Logic, North-Holland, Amsterdam, 1977. 
28. Weyhrauch, R. W., Prolegomena to a Theory of Mechanized Formal Reasoning, 
Artit~cial Intelligence, 13:133-70 (1980). 

Logic Programs with Tests * 
Marion Mircheva 
Institute of Mathematics â€¢ Computer Science 
Bulgarian Academy of Sciences 
"Acad. G.Bonchev" str. bl. 8, Sofia 1113 , Bulgaria 
E-mail: marion@bgeaxn.bitnet 
Abstract. We extend logic programming to deal with logic programs 
that include new truth functional connectives called tests. Stable Model 
Semantics and Three Valued Stable Model Semantics are extended to 
give meaning to programs with tests. 
We consider three possible applications of such programs. It is shown 
how to define a particular semantics in terms of another one with the 
help of an appropriate transformation of normal programs into programs 
with tests. Our approach can be applied for resolving inconsistency in 
logic programs with explicit negation. Programs with tests can serve as 
a promising tool for eliminating or encoding integrity constraints within 
particular background semantics. 
1 
Introduction 
In this paper we propose a general framework for extending two valued and three 
valued stable model semantics to programs with new truth functional connectives 
called tests. We consider at least three possible applications of logic programs 
with such metatools. 
For some well known semantics we present a method to calculate a particular 
semantics (set of models) of a program in terms of some other semantics of 
the program obtained from the initial one after a suitable transformation. The 
resulting program however includes a new test connective. For example the stable 
models of the program 
a~-~b 
b~-- ~a 
M1 = {a, ,-~ b} and M2 = {b, ~ a} coincide with the three valued stable 
models of the following program 
a *-- ~ b, ,,~ t(a) 
b 
Ha, ~t(b) 
* This paper has been developped during my visit at the Institute for Logic, Complex- 
ity and Deductionsystems, University of Karlsruhe, Germany. It was supported by 
the European Economic Community within the framework of the Community's Ac- 
tion for Cooperation in Science and Technology with Central and Eastern European 
Countries under the contract number CIPA3510CT924716. 

277 
The modal 2 operator t(a) has the meaning: 
if a = u then t(a) = true, otherwise t(a) = false. 
This test operator distinguishes undefined value from the Boolean ones. 
Obviously its meaning can be given by the truth table: 
0 
0 
1 
Along this line we present answer sets [4] via stable models [3], stable models 
via three valued stable models and three valued stable models for extended 
programs [11] via three valued stable models for normal programs. In fact the 
last evidence presents elimination of integrity constraints with the help of a 
program with a test. 
The next applieation concerns extended logic programs, that are programs 
with default (,-~) and explicit (-~) negations. We propose a method for resolving 
inconsistency caused by the interaction between default and explicit negations 
within three valued stable semantics. We present an alternative extension of three 
valued stable models to programs with explicit negation that gives meaning to 
every logic program. Our models can be calculated within three valued stable 
semantics over logic programs with a special test connective. 
Within our framework, any background semantics could be easily adapted 
to deal with programs augmented with integrity constraints presented as denials 
*-- a~,...,a,~. This can be done either by withdrawing the models that brake 
up the constraints or by revising the models in a satisfactory way. The revision 
strategy has to be encoded in the meaning of the test connectives that has to be 
used (witness section 5). 
The paper is organized as follows. Section 2 involves the syntax of our frame- 
work. In Section3 we formally describe our extension of two valued stable models 
to programs with tests and present a case study example. Section 4 extends Sta- 
ble3 of Przymusinski to include programs with tests and presents two case study 
examples. Section 5 describes a new extension of three valued stable models to 
programs with explicit negation. An appropriate transformation into a class of 
programs with guard connective is considered here. Section 6 discusses related 
papers and gives some conclusive remarks. 
2 
General Framework: Normal Logic 
Programs with Test Formulae 
In this section we extend the propositional logic programming to deal with 
programs that include some new truth functional connectives, called test operators. 
2 We use the term "modal" according to Polish logical tradition: each connective that 
transforms multi valued domain into Boolean one is called modal. 

278 
Some of them have modal flavor as they transform all possible values into 
Boolean ones. Their meaning is defined with correspondent truth tables. 
A normal logic program is a set of formulae of the form 
c ~-- al~ .. 9 ,am, ~ bl, " 9 ,~ bn 
where n > 0, m > 0 3 and all c, a~ and bj are atoms. The sign -~ stands for 
default negation. A clause containing variables is treated as standing for the set 
of all ground instances of that clauses. 
We extend ordinary language of logic programs to include a new truth func- 
tional connective t(xl,..., 
x,) where xl,..., x,~ are atoms or literals (if the lan- 
guage includes classical negation). The next are examples of test operators: 
1. test(a, b) = true if a = true and b = true otherwise t(a, b) =/alse. For a two 
valued domain this is classical conjunction or in terms of logic programming 
that is the meaning of an integrity 
constraint of the form ~-- a, b. So, 
test(a, b) =- true (equivalently test(a, b) = false) if and only if ~-- a, b is 
satisfied. 
2. test(a) = true if a = undefined otherwise test(a) = false. This is a test that 
will be used in a three valued domain for separating the Boolean models 
from the others. 
3. If a = true then test(a,b) 
= b otherwise test(a,b) 
= false. This is again 
a three valued connective and in the sequel we call it strong guard. 4 Note 
that restricted to a two valued domain this operator is equivalent to the test 
connective from 1. 
For the aim of simplicity we restrict our general presentation to binary test 
connectives. 
Definition 
2.1. A program with test is a set of clauses such that some 
rules may have default negated test formulae in addition to the other premises. 
Consequently it might contains rules with test: 
c ~-- cl,'", 
Cm, "~ cm+l,'", 
"~ c,~, "~ test(a, b) 
3 If n -- m = 0 we mean the rule c ~- and when m -- 0 or n = 0 we mean c ~--.-~ 
bl, 9 9 .., bn or c *-- al,'- ", a,~ correspondingly. 
4 A similar connective has been used by Fitting [2] in connection with logic pro- 
gramming languages based on billatices. Fitting considers the usefulness of guard 
connective "P guards Q" (P:Q) with the meaning: 
if P = true then P : Q = Q otherwise P : Q -- undefined. 
Our strong guard is also close to what Fitting refers as Lisp conjunction or con- 
junction of Prolog as actually implemented, with its left-right, top-down evaluation. 
Obviously, our strong guard is also an asymmetric connective. However all Fitting's 
connectives are regular in Kleene's sense (that is k-monotone), while the strong guard 
is not regular in that sense. 

279 
3 
Two Valued 
Stable 
Model 
Semantics 
for 
Programs 
with 
Test 
We slightly modify Stable Model Semantics introduced by Gelfond and Lifschitz 
[3] to deal with programs with a test formulae. In fact we prolong stable seman- 
tics to programs with test connective. This is done according to the meaning of 
a particular test operator. 
Definition 3.1 (It interpretation). Given a program t-II with test, let I 
be an ordinary 2-valued interpretation of t-II (set of atoms). It is obtained 
from I by adding test (a, b) to I for any test formula test(a, b) 9 Lang(t-H) if 
test(a, b) =true for the current value of a and b in I. 
It extends an ordinary interpretation I in a natural way to interpretations 
over the language with test and this extension conforms with the semantics for 
a test connective. 
For the presentation below let us assume t-II be a logic program with test. 
The clauses of such programs are allowed to have in addition to ordinary premises 
only default negated test sentences. 
Definition 3.2 (t-H/It program). By t-H/It transformation we mean a pro- 
gram obtained from t:II by performing the following two operations that concern 
each default negated atom or default negated test in the bodies of the program 
rules. 
1. Remove from t-II all rules containing -~X, if X E It; 
2. Remove from all remaining rules their default premises ,-~ X. 
The only difference compared to the original GL modulo transformation is 
the new concern with default negated tests. The resulting program t-H/It is pos- 
itive by definition and it has a unique least 2-valued model. 
Definition 3.3. An interpretation I is called a Stable model if least model 
(t-H/It) = I. Stable semantics for a program t-II with test is determined by the 
set of all stable models of t-II. 
There is no syntactical difference between stable models for programs with 
tests and ordinary programs. In both cases any stable model is a set of atoms. 
Moreover t-interpretations play only an auxiliary role during the calculations. 
3.1 
Case Study Example: Answer Sets via Stable Models 
Answer Set Semantics (AS) [4] extends Stable Models [3] to programs that in- 
clude both explicit (-~) and default (,~) negations. 
An extended logic program is a set of formulae of the form 
lO ~--ll,"',Im,~Sl,'",~sn 

280 
where n >_ 0, m > 0 5 and all li and sj are literals. The sign -~ stands for a 
classical (explicit) negation and ,,, stands for a default negation. A literal is a 
formula of the form a or -~a, where a is an atom. By default literal we mean ,,~ l 
where l is a literal. 
Recall the definition of answer sets, which is in two parts. 
Let/-/be any set of ground clauses not containing ~, and let Lit be the set 
of all ground literals in the language of H. The answer set of//, denoted by 
a(//), is the smallest subset S of Lit such that 
1. for any clause lo *-- ll,...,lm E H, ifll,...,l,~ E S then 10 E S, and 
2. if S contains a pair of complementary literals, then S = Lit. 
Now let // be any extended logic program which doesn't contain variables. 
For any subset S of Lit, let//s 
be the set of clauses without ,,~ obtained 
1. by deleting every clause containing a condition ,,, l, with 1 E S and 
2. by deleting in the remaining clauses every condition ,-~ 1. 
S is an answer set of// 
if and only if S is the answer set of/-/s, i.e. if 
s = a(ars). 
According to Answer Set Semantics extended logic programs are divided into 
three disjoint classes: 
1. H is as-consistent if it has a consistent 6 answer set. 
2. H is as-contradictory if it has an inconsistent answer set (namely only one 
answer set Lit). 
3. //is as-incoherent if it has no answer set. 
It is a well known fact that contradictions (in as-contradictory programs) are 
"stable" in the sense that they do not depend on the contribution of default 
negation. In as-contradictory programs, contradictions can not be removed even 
if either any clause is added to the program or any clause with ,-~ is removed 
from the program. 
For the aim of presenting answer sets in terms of stable models we need to 
separate the class of as-contradictory programs. 
Definition 3.1.1. (Legal Programs). A program//is 
legal if the set C(/-/) 
is consistent where C(H) is the smallest set such that: 
If l0 *-- ll,'..,lm E H and ll,...,lm E C(H) then l0 E C(//). 
Intuitively legal programs have consistent monotonic part. For instance the 
program 
s If n = m = 0 we mean the rule l0 ~-- and when ra = 0 or n = 0 we mean l0 ~--'~ 
sl,-", "~ s,~ or l0 ~-- ll,..., lm correspondingly. 
6 A set of literals is consistent if it does not contain both a and -~a for some atom a. 

281 
ma 
r 
ar 
is not legal and it is not in the scope of our interests. 
Statement 
3.1.1. A program/-/is not legal if and only if/-/is as-contradictory. 
Consequently legal programs are as-incoherent or as-consistent. 
Notations: 
- For an arbitrary set of clauses R we denote Head(R) = {l I l *-- ... 9 R}. 
- //~ denotes the renamed version of//, that is the next transformation is 
applied to every literal occurring in/7. 
l ~= ~a, 
ifl -- a for some atom a 
L a ~, if I ---- -~a for some atom a 
Extended logic programs could be considered as a particular case of normal 
logic programs together with a set of integrity constraints of the form ~-- a, a TM for 
any atom a. Thus instead of answer sets of a given extended program/7 we can 
calculate the stable models of its renamed version in which the correspondent 
constraints are properly encoded. 
Definition 3.1.2. 
- (A-test) For any two atoms let A(a, b) be a new formula with the following 
meaning: 
A(a, b) = true if a = true and b = true, otherwise t(a, b) = false. 
This is the first test connective from the examples of tests in section 2. 
- (A-//) For any extended program // let A-// be a program with A-test 
obtained from // by adding a default negated formula .,~ A(a,-~a) to the 
premises of each rule with a head a and -~a. 
Theorem 
3.1.1. 
For any extended legal program// 
Answer Sets(//) -- Answer Sets(A-//) ---- Stable ModelsT(A-//) ~ 
Proo]: Follows from the fact that answer sets of // and A-// are always 
consistent. 
Example. 
//1: 
a*-~b 
b~ 
,~a 
~a 
r 
The program/-I1 has one answer set M - 
{-~a, b}. Then Mt -- {-~a, b}, so 
~A(a,-~a), ,-~ A(b,-~b), ,-~ a are true and ,-~ b is false in Mt (def 3.1). It is easy to 
calculate (def 3.2, def 3.1.2.): 
7 We mean stable models after reversing the renamed literals. 

282 
A-H1 : a ~-- ,,, b, ,-, A(a, ~a) 
b ~- ~a, ~^(b,-,b) 
-,a ,- ~A(a,-,a) 
A-H1/Mt : b *- 
"~a 
Then M is also a stable model of A-H1 because the least model(A-Hi~Mr) = 
M (def.3.3). 
4 
Three 
Valued 
Stable 
Model 
Semantics 
for 
Programs 
with 
Test 
In this section we extend Three-valued Stable Semantics (Stable3) in style of 
Przymusinski [12,15] to programs with test formulae. For a normal logic program 
the F-least s stable3 model determines the so called Well Founded Semantics, 
originally introduced by Van Gelder at al. [15]. 
We use the standard notion of the three-valued (partial) interpretation I = 
TU --~ F where T is the set of true atoms and F is the set of false atoms. The 
rest are undefined. 
Definition 4.1 (It interpretation). Given a program t-H with test, let I be 
an ordinary 3-valued interpretation of t-H (a set of true and false atoms). It is 
obtained from I in the following way: 
- add test(a, b) to I for any test formula test(a, b) E Lang(t-H) if test(a, b) =true 
for the current value of a and b in I; 
- evaluate test(a, b) as undefined if test(a, b) =undefined for the current value 
of a and b in I; 
- add ,~test(a, b) otherwise. 
It extends an ordinary interpretation I in a natural way to interpretations 
over the language with a test and this extension conforms with the semantics 
for the test connective. 
For the presentation below let us assume t-H be a logic program with test. 
Remind that the clauses of such programs might have in addition to ordinary 
premises only default negated test sentences. 
Definition 4.2 (t-H/It program). By t-H/It transformation we mean a pro- 
gram obtained from t-/-/by performing the following three operations that con- 
cern each default negated atom or default negated test in the bodies of the pro- 
gram rules. 
1. Remove from t-/-/all rules containing ,-,X, if X E It; 
2. Remove from all remaining rules their default premises ~X, if ,,,X C It; 
3. Replace all the remaining default premises by proposition u. 
s F stands for Fitting ordering, though Fitting call it k(nowledge)-ordering. 

283 
The only difference compared to the original modulo transformation [def. 
6.23,14] concerns the inclusion of default negated test formulae. The resulting 
program Pi/I~ is by definition non-negative and it has a unique least 3-valued 
model. 
Definition 4.3. An interpretation I is called a Stable3 model if least model 
(t-l/lit) = I. Stable3 semantics for a program t-II with test is determined by 
the set of all Stable3 models of t-i/. 
Similarly to the case with two valued stable models, there is no syntactical 
difference between Stable3 models for programs with tests and ordinary pro- 
grams. In both cases any Stable3 model is a set of atoms and default atoms. 
However not every program with test possesses Stable3 models (witness t-i/3 
bellow). 
4.1 
Case Study Example: Stable Models via Stable3 Models 
We aim to define two valued stable models of a normal program H in terms 
of 3-valued stable models of a correspondent program with test t-H. The test 
operator must distinguish exact values from undefinedness. 
Definition 4.1.1. 
- (test for u). For any atom a let t(a) be the following three valued connective: 
if a = u then t(a) = true, otherwise t(a) = false. 
This test operator distinguishes undefined values from the Boolean ones. 
Obviously its meaning can be given by the truth table: 
llO 
1 
[ 
u 
1 
0 
0 0 
1 
- For any normal program//, t-l/denotes the program with test for u obtained 
from//by adding a default negated formula ,,~ t(a) to the premises of each 
rule in/7 with a head a (for every head a). 
Theorem 4.1.1. 
For any normal program 17 let t-// be a program with test for u obtained 
from//by adding a default negated formula ,,~t(a) to the premises of each rule 
in//with a head a. Then 
Stable Models(//) = Stable3 Models(t-//) 
Proof: Follows from the observation that in every Stable3 model of t-H the 
set of undefined atoms is empty. 
Examples. 
//2 :a ~---,,~b 
b*--,,~a 

284 
The program/72 has two stable models, M1 = {a, ,,~ b} and M2 = {b,--~ a}. 
It is easy to check that M1 and M2 are the only three valued stable models of 
t-H2. 
t-//2 : a r 
~b, ,.~t(a) 
b ~-- ,,~ a, ,,~ t(b) 
Consider the program//3: 
H3 : a ~-- ,,,a 
Then the correspondent program (def.4.1.1) t-H3 is as follows: 
t-Ha : a ~- ,~a, ,.~t(a) 
Neither/I3 possesses any stable models nor t-IIa admits Stable3 models. 
4.2 
Case Study Example: Stable3 Models for Extended Programs 
via Stable3 Models for Normal Programs 
As we have already mentioned Przymusinski extended Stable3 semantics to pro- 
grams with explicit negation [11]. This was done in a very simple way. Przy- 
musinski takes all Stable3 models of the renamed program H" and throws out 
all "inconsistent" models, i.e. those which contain both l and l" for some atom 
l. Thus the program 
1-14 :-,a ~--,,~b 
a4--- 
hasn't any Stable3 models. 
In the sequel we use Stable3 to denote three-valued stable models for normal 
and extended programs, as well as for programs with test (section 3) when the 
context makes the background language clear. 
We can easily notice that Stable3 semantics for an extended logic program is 
in fact Stable3 semantics for the normal program/--/" with A-test (see def.3.1.2. 
for A-test). 
l alb[A(a,b)l"~A(a,b)[ 
1 1 
1 
0 
1 u 
0 
1 
Statement 4.2.1. Let H be an extended program and let H" be its renamed 
version. Let A-//" be a program with A-test obtained from H" by adding a 
default negated formula ,,-A(a, a ~) to the premises of each rule with head a and 
a ". Then 
Stable3(~~) = Stable3(A-H') 
Example. For the program//4 above, the correspondent program A-//~ is 
as follows: 
A-//; : a TM ~-- ,~b,,,~A(a,a-') 
a ~-- ,,*A(a, a ~) 
The program A-//; doesn't have any Stable3 models. 

285 
5 
Resolving 
Inconsistency 
in Extended 
Logic Programs 
As we already pointed out Stable3 semantics for an extended logic program is 
in fact Stable3 semantics for the normal program/i7 with A-test. 
For the aim of a better representation of incomplete knowledge, hypothetical 
reasoning, abduction and other forms of non-monotonic reasoning, classical (ex- 
plicit) negation (-~) has been proposed to be used in logic programs along with 
negation as failure (,-,) [4,5,6,8]. Though default negation has a clear procedural 
meaning its application is limited in the sense that ,,, a does not refer to the 
presence of knowledge asserting the falsehood of the atom a but only to the lack 
of evidence about its truth. In this section we propose an alternative extension 
of Stable3 semantics to deal with explicit negation. We define models for ev- 
ery legal (see def.3.1.1.) extended program. If an extended program//possesses 
Stable3 models of Przymusinski, then our models form a superset of Stable3. 
In the sequel we show that our semantics for extended logic programs is in fact 
three valued stable semantics over normal logic programs with a new connective 
called strong guard. Thus in this section we aim to illustrate another application 
of test connectives for resolving inconsistency within three valued stable model 
semantics. 
There are at least two awkward questions related to the inconsistency of 
extended logic programs that Stable3 Semantics is faced with: 
- 
First, Stable3 semantics does not distinguish between inconsistency arising 
as a result of a mutual relationship between Closed World Assumption and 
explicit negation (witness II4) and inconsistency created by the monotonic 
part of the program. 
- There are two different notions of falsehood in extended programs and no 
satisfactory semantics for explicit negation besides the constraint that a and 
-~a create an unwilling situation. 
We aim to resolve partly both questions. We propose an alternative extension 
of Stable3 (for normal programs) to programs with explicit negation, evaluating 
the explicit negation as Kleene's three valued negation. For normal programs 
our semantics coincide with Stable3. For a rather general case (Statement 5.1.2) 
our semantics coincide with Przymusinski's semantics. 
The appearance of the two kinds of negations make the use of the notion 
false ambiguous. As usual we refer to not a as default negation, that is a is false- 
by-default in/7 if not a is provable from 1I. We define the meaning of explicit 
negation as Kleene's three valued negation i.e. there is a logical falsehood beside 
false-by-default. So -~a (a) is logically false (simply false) if and only if a (-~a) is 
true and -~a (a) is unknown whenever neither a nor ~a is true (provable). 
We give a meaning to each legM program by resolving inconsistency caused 
by the interaction between default and explicit negations. For instance in the 
program//4, the rule -~a ~-,,~ b is considered less trustful then the nonnegative 
rule a ~. Each rule that depends on default negation is considered as context 
dependent. Though -~a has an explanation ,-~ b in II4 the meaning of -~a depends 
on the value of a in the current context. Since a has more trustful explanation 

286 
then -~a, then a has to be accepted as true and -~a has to be revised to undefined. 
The intuitive meaning of -~a *--,,, b turns out to be: ~a is true if b is false and a 
is not true, but if a turns out to be true along with ,~ b then a must be revised 
to undefined. This holds for all rules that depend on default assumptions. Thus 
we propose {a,--~ b} to become a model for //1. All of these lead to the next 
definition. 
Definition 
5.1 (Split Program). Let // be a logic program. // could be 
uniquely split into two disjoint parts, 17 = T U H where T is the minimal set 
inductively defined as follows: 
- if I ~--E//, then l ~--E T; 
- if/~ 
ll,...,l,~ E TI and li E Head(T) for each i, then l ~-- 11, "" .,Ira E T. 
The couple (T, H) is called split program. 
Definition 5.1 holds for extended logic programs as well as for normal pro- 
grams. To every program/7 we associate the corresponding splitting (T, H). The 
set T forms the monotonic part of the program and the set H stands for the 
defeasible part of the program. H also could be treated as a set of hypotheses 
in the context of//. In this setting hypotheses are not predominant as it is usu- 
ally considered in hypothetical reasoning frameworks [10] and sometimes in logic 
programming frameworks [6]. In our case each program determines by itself the 
set of defeasible clauses. 
Statement 
5.1. A program /I = T U H is legal if T is consistent (T is 
considered as a set of inference rules). 
5.1 
Three Valued Stable Semantics for Split Programs: 
s-Stable3 
In this section we formally define our intended models for extended logic pro- 
grams. We supply with definite meaning every legal program. For normal pro- 
grams our semantics coincides with Stable3 models. 
We resolve the inconsistency caused by the interaction between default and 
explicit negation. Consider a split program//--- T U H. If a contradiction arises 
between rules with heads l and -~l, the rules from T override the rules from H. 
If both clauses have equal priority, that is l and -~l come from H, then multiple 
models are adopted - one in which 1 is true and -~l is undefined and the other 
in which -~l is true and l is undefined. For example the program 
II5 : ~a *-- ~b 
a~--~c 
has two s-Stable3 models: {a, --~ b, ~ c} and {-~a, ,,~ b, ,,~ c}. 
Definition 
5.1.1. Let I C Lit(//) be an interpretation and//= 
T U H be a 
split (legal extended) program. By///sI we mean the program obtained from// 
after performing the following five operations that concern each default literal 
in the bodies of the program rules. 

287 
1. Remove from/-/all rules containing condition --~ l, if I E I; 
2. Remove from//all rules with a head l if l and -~l belong to I; 
3. Remove from all rules in/-/their default premises -~l, if ,,,1 E I; 
4. Add the proposition u to the premises of all clauses in H with a head l, if 1 
does not belong to T t3 F and --I E T; 
5. Replace all the remaining default premises by proposition u. 
We changed the original modulo transformation///I definition by adding 
extra conditions (2) and (4). Item (2) rejects all inconsistent models, item (4) 
ensures the revision to logical falsehood for those literals l which counterpart -,l 
is true. 
The resulting program///'I is by definition non-negative and it has a unique 
least three-valued model. 
Definition 5.1.2. A 3-valued interpretation I of the language of//is called 
an s-Stable3 model if I = least model (H/'I). Three-valued s-Stable semantics 
is determined by the set of all s-Stable3 models of//. 
Remark. In fact the points 1,2,3,5 from def.5.1.1 together with def.5.1.2 
are equivalent to Stable3 semantics of Przymusinski. Provision 4 supplies with 
models those programs that do not have Przymusinski's semantics. For instance 
the program//4 = T U H 
H : -,a *-- ,,~b 
T: 
a~ 
has an s-Stable3 model M = {a, ,-~b} because M is indeed the least model of 
//dS M. 
//4/SM : -a ~ ,,~b, u 
a~-..- 
Statement 5.1.1. S-Stable3 models are always consistent (it directly follows 
from the provision 2, def.5.1.1). 
Statement 5.1.2. Let H be an extended legal program. If all Stable3 models 
of its renamed version H TM are "consistent" then Stable3 models of//coincide 
with s-Stable3 models of _1-/. 
Statement 5.1.3. Every extended legal program has at least one s-Stable3 
model. (Follows from the observation that the number of s-Stable3 models of H 
is no less that the number of the Stable3 models of/-/~.) 
Theorem 5.1.1. 
Let//= 
T t3 H be a legal extended logic program. If M is a Stable3 model 
of H then M is also an s-Stable3 model of//. 
Proof. Assume M is a Stable3 model of//, that is M=least model(//~M). 
Then the only difference between II/M and H/~M concerns some rules I ~-- ... 
from II/M for which neither l nor ~ l belong to M and --I is true in M. These 
rules are replaced with I ~ ..., u in H/SM. However these rules don't contribute 
to the model M as l is also undefined in M. Therefore M=least model(llpM). 
# 

288 
5.2 
Stable3 Semantics for Programs with Strong Guard Coincides 
with s-Stable3 
We need to extend our syntax to include a new truth functional connective 
- strong guard - in order to express our intended meaning of logic programs in 
terms of Stable3 semantics. Given a program H we find a correspondent program 
H g such that 
s-Stable3(H) = Stable3(Hg). 
H g is a program with strong guard. 
Definition 5.2.1 (Strong Guard). We extend the propositional language 
with a new binary truth functional connective (a; b) (a and bl are literals) and 
read it "a guards b". It has the following meaning: 
if a = true then (a; b) = b otherwise ,~ Ca; b) = true. 
This definition shows when a guard formula is true (provable) with respect to 
some semantics and when it is false-by-default. Now the rule for default negation 
over literals is again Closed World Assumption, but a guard formula (a; b) is 
false-by-default if a is not true. In that sense the guard connective performs a 
metacalculation. 
We adopt the notation Ca; b) to distinguish from Fitting's guard (:) [2]. 
Now definition 2.1 adapted to a strong guard connective looks like: A program 
with strong guard is an extended program in which some rules may have default 
guard sentences in addition to the other premises. Thus it might contain rules 
with guard: 
1 +-- ll,.. ",Im, "~ lm+l,'" ",~ l,~,,,,(a;b) 
Following the content of section 3, Stable3 semantics can easily be prolong 
to programs with strong guards. This is done in according to the meaning of the 
test operator -- in this case a strong guard connective. 
We've already given some hints about how to transform a program H to a 
program H g with strong guard such that 
s-Stable3(H) = Stable3(Hg). 
Definition 5.2.2 (The Transformation). 
Let H = T U H be a legal 
extended logic program. Then H g -- T O H g where 
g 9 = {l *---.-.,~(-/;l)ll *--... e g and-~l E Lit(H)} U 
{l *---... [l *-- .. 9 e g and -~l ~ Lit(H)}. 
In fact this transformation changes only the set H in H, as we add auxiliary 
premises to the clauses in H. That is why the transformation preserves the legal 
property, i.e. if H is a legal program then H g is also a legal program and T U H 9 
is indeed its splitting. 
Recall the program//5 = T U H, that has two s-Stable3 models: {a, ,~ b, ,,, c} 
and {--a, -,~ b, ,,~ c}. 

289 
//5 : T =O 
H: 
a 
~-,~b 
Its transformed version H i 
: T = O 
H: 
a 
~-- ,~b,,,~(-~a;a) 
-~a r 
,,~ c, ,,~ (a; -~a) 
has two Stable3 models (for a program with guard): 
{a, ,,~b, ~c} and {-~a, ,,~b, ~c}, that are identical to s-Stable3 models of//5. 
The following theorem shows that the transformation preserves the meaning 
of the original program. 
Theorem 5.2.1. 
Let//be 
a legal program and//9 be the program obtained after the trans- 
formation. Then 
1) s-Stable3(//) = Stable3(/-/9) 
2) Stable3((//9) ~) = Stable3(//g) 
Proof. 1) We show more generally that for any 3-valued consistent interpre- 
tation I of T/ 
///'I 
The only difference between///'I and IIg/I 9 concerns those rules from H with 
heads I for which the correspondent rules from H 9 contain a default guard 
not(~l;l), i.e. l ~-- ... E H and I ~-- ...,not(~l;l) 
E H 9. The nontrivial sub- 
cases concern the provision when -~l is true in I and 1 is undefined in I, otherwise 
lI/SI =//9/I 9 directly follows from def.5.1.1, and def.4.2. For such I and -~l by 
provision 4, def.5.1.1, we get l ~-- .-.,u E II/'I. As -~l is true in I 9 we get 
not (-~l; l) = not I = u. Therefore l ~-- ..., u e II9/I 9. 
2) follows from the fact that Stable3 models of (//9)- are always consistent 
(after reversing the renaming).# 
5.3 
Elimination of Integrity Constraints 
Extended logic programs could be considered as a particular case of normal logic 
programs together with a set of integrity constraints of the form *-- a, b where b is 
the renamed version of -~a. In this setting the framework proposed in this section 
can serve as a method for elimination of integrity constraints. For example let 
us consider a theory that contains the program//and 
the constraints *-- a, b: 
Fl : a ~-- ,,~c 
b~--,,~d 
This theory has two expected models Mz = {a, ~ c, ~- d} and M2 = {b, 
c, ,~ d}. These models are exactly the Stable3 models of a program TI9 with 
strong guard: 
//9 : a ~-- ,,~ c, ,-, (b; a) 
b ~- --~ d, ,,~ (a; b) 
Indeed we can easily check that 

least model( Hg /M1) = M1 
least model(IIg /M2) = M2 
290 
because the correspondent modulo programs are as follows: 
IIg/M1 : a ~- 
b~--u 
IIg /M2 : b ~- 
a~---u 
Consider the more general case of integrity constraints like r al," "., a,~. It 
is read as "al,..', an are not allowed to be true together". To eliminate these 
constraints within Stable3 semantics we need n guard connectives: 
(al,..., ai-1, ai+l,""', a,~; ai), i = 1,..., n with the following meaning: 
if al, 9 9 9 a~-l, ai+l, 9 ", an are true, then (al, 9 9 ai-1, a~+l, 9 .., an; ai) = 
ai otherwise ~- (al,'.., ai_l, ai+l,-.., an; ai) = true 
Then the meaning of a program//= 
T U H with a constraint *-- a~,..., a,~ is 
equivalent to Stable3 semantics of the program T/9 obtained from//by 
adding 
the guard formula ,-~ (al,'", ai-1, a~+l,..., a,~; ai) to the premises of each rule 
from H with a head ai. 
6 
Discussion 
Our framework was originally motivated by the goal of providing an extension 
of 3-valued stable semantics that makes the use of explicit negation harmless 
(section 5). Later we found out that programs with some other metatools like 
test operators could help for a better understanding the mutual relationships 
between different semantics as well as to increase the expressive power of logic 
programs. 
The idea to use a transformation between programs (over one and the same 
language) was widely explored in different contexts. Besides the other advantages 
this idea is useful as the transformation usually facilitates implementation. Thus 
for s-Stable3 models for programs with guard logic programming methods for 
three valued stable models [13,16] can be applied over the transformed pro- 
grams. A transformation that can eliminate certain restricted forms of integrity 
constraints from definite clause databases is proposed in the work of Asirelli et 
al [1]. In [7] a particular case of elimination of constraints in some restricted 
program databases has been independently considered. 
Kowalski and Sadri [6] proposed a technique for a contradiction removal 
within the context of default reasoning based on answer set semantics. They allow 
an explicit representation of exceptions, that are rules with heads of the form 
-~x, in addition to the original program. They restrict the syntax of the original 
program, so that explicit negation does not appear in the heads of ordinary 
clauses. They give a semantics for rules and exceptions in a way that exceptions 
have higher priority then rules. We also use a priority assignment of some rules 

291 
over the others but in a completely different setting - split programs. To encode 
the priority relation and to resolve inconsistency we propose a transformation 
that helps to calculate the intended meaning within Stable3 semantics. Kowalski 
and Sardi use a transformation that calculates their intended meaning in terms of 
answer sets. For that aim they propose a cancellation technique that is different 
from ours. We need a new connective in the language as we deal with a three 
valued domain. Our models are not deductively closed in a sense that it is possible 
to have a *--,,, b in a program, b false-by-default and a not true. This holds also 
for the models of Logic Programs with Exceptions of Kowalski and Sardi and for 
some semantics for inconsistent databases [8]. 
A recent work by Pereira, at al. [9] independently concerns how to present 
knowledge for default reasoning by using extended logic programs. They pro- 
pose to resolve inconsistency within three valued semantics by retracting some 
negation as failure formulae from the rules of a program. That way they re- 
strict the Closed World Assumption assigning value undefined instead of false 
to some of the default negated premises. This is done by a rather complicated 
procedure based on tracing all possible sets of admissible hypotheses (default 
literals). We on the contrary don't restrict CWA but propose a transformation 
that helps calculate our models within programming methods for 3-valued stable 
semantics. 
References 
1. Asirelli, P., De Santis, M. and M.Martelli. Integrity constraints in logic databases. 
J. Logic Programming, vol 2, number 3, 221-233, 1985. 
2. Fitting, M. Kleene's three valued logics and their children. August, 1993. 
Manuscript. 
3. Gelfond, M and V.Lifschitz. The stable model semantics for logic programming.In 
R.A.Kowalski and K.A.Bowen, editors, 5th ICLP, 1070- 1080. MIT Press, 1988. 
4. Gelfond, M and V.Lifschitz. Logic programs with classical negation.In Warren and 
Szeredi, editors, 7th ICLP, 579-597, MIT Press, 1990. 
5. Kowalski, R. A. and F.Sadri. Logic Programs with exceptions. In Warren and 
Szeredi, editors, 7th ICLP, 588-613. MIT Press, 1990. 
6. Inoue, K. Extended Logic programs with default assumptions. Proceeding of 8th 
ICLP, 491-504. MIT Press, 1991. 
7. Mircheva, M. Declarative semantics for inconsistent database programs. In D. 
Pearce and H. Wansing, editors, Proc. of JELIA '92, LNCS 663, 252- 263, Springer- 
Verlag, 1992. 
8. Pearce P. and G. Wagner. Logic Programming with strong negation. In P. 
Schroeder-Heister, editors, Proceedings of the International Workshop on Exten- 
sion of Logic Programming, pages 311-326, Tubingen, Dec. 1989. Lecture Notes in 
Artificial Intelligence, Springer-Verlag. 
9. Pereira, L. M., Aparicio, J.N. and J.J.Alferes. Contradiction removal within well 
founded semantics. In A. Nerode, W. Marek and V.S.Subrahmanian, editors, Pro- 
ceedings of the First International Workshop on Logic Programming and Non- 
monotonic Reasoning, pages 105-119, MIT Press, Cambridge, MA, 1991. 

292 
10. Poole, D. A logical framework for default reasoning. Artificial Intelligence 36, 27- 
47, 1988. 
11. Przymusinski, T. Extended stable semantics for normal and disjunctive pro- 
grams.In Waren and Szeredi, editors, 7th ICLP, pages 459-477. MIT Press, 1990. 
12. Przymusinski, T. Well founded semantics coincides with three valued stable models. 
Fundamenta Informaticae 13, pages 445-463, 1990. 
13. Przymusinski, T. and David S. Warren. Well founded semantics: theory and im- 
plementation Technical report, Dep. of Computer Science, University of California 
at Riverside and SUNY at Stony Brook, March,1992. 
14. Przymusinska, H. and T. Przymusinski. Semantic issues in deductive databases 
and logic programs. In Formal Techniqies in Artificial Intelligence. A Sourcebook. 
R.B.Banerji (editor), Elsevier Science Publishers B.V. (North-Holland),1990. 
15. Van Gelder, A., Ross, K.A. and J.S.Schlipf. The well founded semantics for general 
logic programs. Journal of ACM, pages 221-230, 1990. 
16. Warren, D. The XWAM: A machine that integrate prolog and inductive database 
query evaluation. Technical report #25, SUNY at Stony Brook, 1989. 

An Architecture with Multiple Meta-Levels for 
the Development of Correct Programs 
1 
Barbara 
Dunin-Kgplicz 
Institute of Informatics 
University of Warsaw 
02-097 Warszawa, Banacha 2 
Poland 
e-maih keplicz@mimuw.edu.pl 
Abstract 
In this paper we design a multi-meta-level compositional archi- 
tecture for correct programs development. In this architecture an 
object level, describing an application domain, together with a recta- 
level, representing the semantics of a programming language, and a 
meta-meta-level, reflecting the adopted methodology, provide a spe- 
cification of a generic system supporting the user in the process of 
correct programs construction. The ideas reported in this paper are 
illustrated in a prototype version of the system, designed for Dij- 
kstra's guarded command programming language. 
Keywords: multi-level compositional architecture, formal program develop- 
ment, specification and verification, programming in logic. 
1 
Introduction 
Most software systems designed to help the user in a program derivation are so 
large that they need the support of a rigorous methodology. A precise specifi- 
cation of methodological assumptions enables one to describe a correct program 
development process in formal terms. Our goal in this paper is to design an ar- 
chitecture which gives rise to a system which is parametric w.r.t, methodology, 
programming language and application domain. Distinguishing and separate 
treatment of these three aspects of program construction is the key point of the 
reusability of the system. 
1Thls work has been partially supported by grants: KBN 2 1199 9101 (Polish Research 
Commltee), CRIT-1 (CEC). 

294 
The expressive power needed to cover various methodological approaches seems 
to be hard to realize without research in this field; different methodological fra- 
meworks need different tools to formalize them. However it is generally accepted 
that the most conceptually natural programming style is top-down program de- 
velopment. For this reason our general framework will be characterized through 
the two main principles, namely: 
* the step-wise refinement technique. 
* verifying the correctness of the program during its development. 
The above methodological perspective can be expressed via an adequate para- 
metrization of various aspects of the program construction. 
The first, very intuitive, principle is the realization of an analytic design scheme 
characterized in [9] (p.139): 
The analytic design consists of a systematic application of the 
following reasoning: 
1. Given a problem P, is it possible to express its solution in a rea- 
sonably concise fashion using primitive notions of the linguistic 
level at which we want to program? If yes - write the program, 
if not - invent notions P1,...,Pn, such that 
(a) each of the notions P1,...,Pn is well specified, 
(b) using the notions according to their specification it is po- 
ssible to write a satisfactory program for problem P. 
2. Consider each of the notions P1,...,Pn in turn as a new problem 
and repeat the reasoning. 
This process continues until all invented, intermediary notions 
are implemented in terms of primitive notions. 
Applying this scheme we can show that a program may be constructed by 
creating a sequence of refinements. Each "notion" may be treated as a well- 
specified module: let the symbolic module Hi correspond to the notion of Pi (for 
i = 1,..., n). In subsequent steps, solving the problem amounts to consecutive 
development of particular symbolic modules. During the refinement of the pro- 
gram, on any level its correctness may be formally verified. In other words, the 
notion of symbolic module enables one the on-line verification of the program 
correctness. 

295 
Definition 
Let II be a partially developed program with the symbolic modules IIa,...,IIn. 
We say that II is conditionally correct iff the correct development of the modules 
II1,...,IIn guarantees the correctness of the completely developed program, rn 
Our approach realizes the following mathematical view of programming ([3], 
p.5): 
"The development of a proof of correctness and the construction 
of a correct program that satisfies its specification can proceed hand 
in hand. A program can literally be derived from its specification." 
While constructing programs, the user's activity can be viewed as a systematic 
development of symbolic modules. Our goal is to help the user in those phases 
of program derivation which can be realized automatically. On the one hand, 
the system is planned to support, but not to substitute, the user in the program 
construction. On the other hand, the system can be treated as a tool enfor- 
cing a good, systematic programming style, which is essential especially for an 
inexperienced programmer. 
Another point we want to implement is the capability to use a possibly broad 
class of programming languages. For this purpose we plan to embed the seman- 
tics of a programming language in a formal theory. This high-level construction 
is applicable to imperative programming languages with axiomatically defined 
semantics. 
The last premise underlying our system concerns the application domain. The 
domain knowledge embodies the conceptualization of a domain for a particular 
application in a form of a domain theory. This knowledge is considered as system 
neutral, i.e. represented in a form that is independent of its use. 
The paper is organized as follows. Section 2 characterises a structure of the 
presented multi-meta-level compositional architecture. Section 3 is an overview 
of the generic system: a description of three reasoning levels, a communication 
between them and an inference cycle in the system are discussed. Section 4 
illustrates the presented ideas in action; it contains a prototypical version of 
the system designed for Dijkstra's guarded command programming language. 
Finally, conclusions and further perspectives are discussed in section 5. 

2 
296 
Why 
a Multi-Level 
Architecture? 
2.1 
Motivation 
Distinguishing three reasoning levels: a theory describing an application domain, 
a theory representing the semantics of a programming language and a theory 
reflecting the adopted methodology leads naturally to designing a system in 
terms of a multi-level compositional architecture ([8]). Each of the reasoning 
levels, namely: 
(i) object -- application domain; 
(ii) meta -- semantics of a programming language; 
(iii) meta-meta-- adopted methodology 
is substantially different with respect to: 
9 goals; 
9 knowledge; 
9 reasoning capabilities. 
One of the goals of this paper is to argue that designing two meta-levels in this 
architecture is really well motivated in the field of program construction. 
The step-wise program refinement requires a certain mechanism of a task decom- 
position; to be more specific, a precise goal definition on particular reasoning 
levels. In effect, the essential property of our system is that each reasoning level 
establishes a goal to be achieved at the lower level. In other words the behaviour 
of the system can be specified in a goal directed manner. 
2.2 
The User's Role 
A translation from specification to implementation cannot be realized automa- 
tically but what is possible is the automatic support in some phases of program 
derivation. In practice this amounts to the formal verification of particular steps 
of the program construction. To achieve this goal the user interacts with meta- 
meta-level realizing methodology. At this place he takes strategic decisions both 
about the shape of the program and, in the case of failure of its construction, 
about where to start its reconstruction. We will discuss these questions in more 
detail in subsection 3.3. 

3 
297 
Overview 
of the Generic 
System 
3.1 
Domain: Object Level 
Before starting the program development, the user has to precisely specify what 
problem is to be solved and to identify any constraints on the input data. This 
starting specification will then guide the process of program development. 
The specification of the program II has to be defined in terms of an applica- 
tion domain of the program. In order to carry out the necessary manipulations 
of specifications, domain knowledge can he viewed as a declarative theory of 
the application domain, formalized as the object theory To. Theorems to be 
proved in the theory To, let say 71, 9 -., 7k, are established on meta-level descri- 
bing semantics. A communication between object and recta-level is assured by 
reflection rules defined in subsection 3.5. 
The way of describing theory To is irrelevant from our point of view -- it may 
be any adequate formal theory with a derivability relation. The only important 
point is the ability of drawing conclusions based on this theory. 
3.2 
Semantics: Meta-Level 
The assumption about axiomatic semantics allows us to use Hoare's notation. 
Since we are interested in total correctenss of the program, the triple {Q}I{R} 
indicates that the execution of a statement I, which begins in any state satisfy- 
ing the predicate Q (called precondition), is guaranteed to terminate in a state 
satisfying the predicate R (called postcondition). 
In our framework the statement I may be : 
At the beginning of program construction -- the symbolic module denoting 
the whole program to be developed. In this case predicates Q and R are 
the precondition and postcondition for the entire program. 
During the development process -- a sequence of programming language 
statements and/or symbolic modules. 
When the development is completed -- the sequence of programming lan- 
guage statements. 
The axiomatic semantics of the programming language can be naturally formu- 
lated as aformal meta-theory: proof rules describing the meaning of particular 

298 
programming language commands are represented as meta rules in the theory 
TM1. 
The language of TM1 contains two predicate symbols THR and SP. 
9 THR(Q) denotes that Q is a theorem of the object theory To. 
9 SP(Q, I, R) denotes that {Q}I{R} holds; here Q and R are logical formu- 
las referred to as precondition and postcondition, respectively and I is a 
command of the programming language or the name of symbolic module. 
We adopt the convention that formulas of the object theory To and commands 
of the programming language will be treated as terms of the theory TM1. To 
this end we assume a naming function; for convenience, in our presentation we 
will use the symbols themselves as their names. 
The system starts the program construction from the symbolic module cor- 
responding to the program II in order to develop systematically all symbolic 
modules occurring in it. Let II1,..., lln are symbolic modules in the partially 
developed program 1I. Then II is conditionally correct and the description of 
the current state of the process of program construction is reflected in the list: 
[SP(~I, II1,131),. 9 SP(an, IIn, fin)]. The verification of the correctness of the 
development of the symbolic module Hi amounts to the proof of the theorem 
[SP(ai, Hi, fli)]. 
On the basis of the theory TM1 and control information transferred from the 
meta-meta-level (control-choice(Q,I,R)), pointing out a selected symbolic mo- 
dule (Q), an instruction meant to implement it (I) and the current list of theo- 
rems (R), the meta-level is able to generate new list of theorems to be proved: 
! 
I 
[THR('h),..., THR(7~), SP(a~, 1-I 1, ill),..., SP(a~, II~,/)~m)] 
(k > 0, m _ 0). 
Theorems 71,..., 7k, pointed out in the part THR(71),..., THR(Tk), are trans- 
ferred to the object theory To -- as goals -- in order to be proved there. 
Depending on the adopted method of formalizing the meta-theory TM1 (and of 
course inference procedure, e.g. programming in logic and resolution, production 
rules and chaining, etc.) the recta-level reasoning may be realized in various 
ways. 
A communication between meta-meta and meta level is assured by reflection 
rules defined in subsection 3.4. 

299 
3.3 
Methodology: Meta-Meta-Level 
Formalizing a possibly general methodology of correct program construction is 
an important research question. Still a lot needs to be done to support the user 
in this process. While designing the system we are abstracting from a general 
solution of this problem. The underlying strategy behind our approach is to limit 
attention to the necessary design decisions. Assuming a stepwise development 
of programs, the crucial modelling decisions concern: 
9 Introducing a concept of symbolic module in order to implement a step- 
wise refinement technique. 
9 Assuming a certain strategy for symbolic module choice at any moment of 
the program development. 
9 Assuming a certain strategy for selecting a program construction to im- 
plement a given symbolic module. 
All these modelling assumptions will be then translated into control primitives. 
Although the formulation of the knowledge sufficient to take all necessary deci- 
sions is a promising line of research, we recall that the final choices are always 
made by the user. Assuming a very strict interaction with the programmer, we 
will be satisfied with a precise specification of input and output of the meta- 
meta-level, treating the methodology as a kind of a black box. In other words, 
the adopted methodology amounts to a highest-level goal selection. The user, as 
the one responsible for taking decisions, is obliged to point out: 
9 the symbolic module at hand. 
9 the program construction implementing the selected symbolic module. 
9 the new highest level goal statement. 
Thus, the language of the meta-meta-level contains three predicate symbols 
selected-goal, selected-instruction, new-goal-statement. 
9 selected-goal(Q) denotes that Q is the symbolic module under considera- 
tion. 
9 selected-instruction(l) denotes that I is the program construction imple- 
menting the selected symbolic module. 
9 new-goal-statement(R) denotes that R is the new goal statement (to be 
considered at the meta-level). 

300 
The problem of establishing a new-goal-statement is more complicated. If the 
program derivation goes on without any disturbance, the resulting current-goal- 
statement may become, if the user did not change his/her mind in the meantime, 
the next new-goal-statement in the following reasoning cycle. 
Otherwise, when the reasoning cycle fails, i.e. some facts underlying the program 
costruction turn out not to be true -- certain theorems in the object theory To 
remain unproved, the further program derivation should be revised. In order 
to establish another next-goal-statement on the meta-meta-level, classical back- 
tracking techniques (under the user's control) may be applied. In general, the 
question where to start the program reconstruction may be answered in many 
ways, reflecting not only user's taste but also various methodological approaches. 
So, in future meta-meta-level may be viewed as a sophisticated reasoning level 
using specialized knowledge, strategies, heuristics, etc. 
3.4 
Generic Communication Between Meta- and Meta-Meta-Level 
The meta-meta-level (M2) communicates with meta-level (M1) via the downward 
reflection 2 rule. 
(DR,2) 
selected-goal(Q} 
selected.instruction(l) 
new.goal-statement(R} 
control-choice(Q,1, R) 
(DR2) transfers control information for meta reasoning. 
The next rule assures communication in the opposite direction: between meta- 
level (M1) and meta-meta-level (M2). The upward reflection 2 rule is defined as 
follows: 
meta.goal-statemcnt(M) 
(UR2) 
Current-goal-statemeni(M) 
(UR2) transfer s current-goal statement for meta-meta-reasoning. 
3.5 
Generic Communication Between Meta- and Object Level 
The meta-level (M1) communicates with object level (0) via the downward re- 
flection 1 rule: 

301 
meta-goal-statement 
(DR1) 
([THR(71),..., THR(7~), SP(al, II1, ill),..., SP(am, IIm, tirol) 
object-goal-statement(J71,..., 7k]) 
(DR1) transfers objeet-goal-statement([71,...,Tk]) for object reasoning. 
The upward reflection 1 rule assures communication in the opposite direction: 
between object level (O) and meta-level (M1). 
Toe Q 
(UR1) 
TM1 F THt~(Q) 
(UR1) transfers information about realized object-goal statements for meta 
reasoning. 
3.6 
Global Description of the Reasoning Pattern of the System 
During an inference cycle the system tries to develop one symbolic module. This 
process is realized in eight separate phases, namely: 
(A) Reasoning on meta-meta-level: GOAL SELECTION. 
(B) Downward reflection from meta-meta-level into meta-level: (DR2). 
(C) Reasoning on meta-level: ESTABLISHING a raeta-goal-statement. 
(O) Downward reflection from meta-level to object level: (DR1). 
(E) Reasoning on object level: VERIFYING an object-goal-statement. 
(F) Upward reflection from object level to meta-level: (UR1). 
(G) Reasoning on meta-level: ESTABLISHING a new meta-goal-staternent. 
(H) Upward reflection from meta-level to meta-meta-level: (UR2). 
The inference cycle in our architecture is constructed in such a way that the 
reasoning on the object level is realized as soon as possible. Another acceptable 
strategy is to postpone proving theorems in the object theory, treating it as 
the last phase of the program development: the constructed program is then 
considered as totally correct under the condition that all the object level theorems 
generated during the program derivation are provable. In this context our design 
decision is well motivated. Proving theorems in the object theory To implies 
verification of facts underlying the program construction. If these facts turn out 

302 
not to be true, program derivation based on them should be blocked as soon as 
possible. 
The choice of the strategy of program construction may be viewed in future as 
another parameter of the system. Obviously, different strategies imply different 
imference cycles in this kind of architecture. 
4 
Prototype 
System 
for Dijkstra's 
Guarded 
Command 
Programming 
Language 
We illustrated our multi-meta-level framework by designing the prototype system 
for Dijkstra's guarded command programming language ([2]), providing a very 
simply and concise notation for expressing algorithms. Since there is only room 
for very brief presentation of the language, for details please consult [6], [4]. 
4.1 
Dijkstra's Programming Language 
4.1.1 
The Notion of the Weakest Precondition 
To characterize the semantics of his language, Dijkstra introduced the predicate 
wp(S, R) (a weakest precondition) for representation of the weakest precondition 
of a command S with respect to a postcondition R. The wp(S, R) characterizes 
the set of all initial states such that if S starts in any one of them it will terminate 
with R true. We can write Q ~ wp(S, R) to express that Q implies the weakest 
precondition for S establishing R. A program S is said totally correct with 
respect to the precondition Q and postcondition R if the relation Q ~ wp(S, R) 
holds. 
For the purpose of readability, we briefly introduced Dijkstra's programming 
language. 
4.1.2 
List of commands 
1. The skip command. Execution of this command does not change state of 
any variable. 
wp(skip, A) = A. 

303 
2. The abort command. This command aborts the program execution: 
wp(abort, A) = False. 
3. The multiple assignment command. 
wp(xl,...,Xn :=el,...,en, 
A)-- A[xl,...,xn ~--el,...,en]. 
The variables Xl,..., X n should be all distinct. 
4. The sequential composition. This command is equivalent to the sequential 
execution two commands, in a given order: 
wp(I1; h, A) = tvp(I1, ~P(h, A)). 
5. The selection command. This command consists of a set of guarded com- 
mands and it is executed as follows. A guard which is true is selected, then 
the command bound to it is executed. If no guard is true, the program 
execution is aborted. 
if 
B1 ---+ I1 
B2~h 
O 
Bn 41. 
fi 
When more than one guard is true, then the selection of a guarded com- 
mand is nondeterrninistic. 
6. The iteration command. This command also consists of guarded com- 
mands: as long as there are guards which are true, one of them is selected 
and the command bound to it is executed. When no guard is true the 
iteration terminates. 
do 
B1-+I1 
B2 -~ Is 
D 
B. ~In 
do 
The evaluation of the predicate wp for selection and iteration from a definition 
may be sometimes very difficult or even impossible, because of the inconstruc- 
tire character of this definition (for the iteration). To overcome this problem, 
Dijkstra formulated two theorems for iteration and selection. 

304 
Theorem 1 Suppose a predicate A satisfies 
(1) 
A ~ (B1 V...VB.). 
(2) 
(A A Bi) =~ wp(Ii,B), for 1 < i < n. 
Then (and only then) 
A :~ wp(IF, B).O 
Theorem 2 Suppose a predicate A satisfies 
(1) 
(A A Bi) :2z wp(Ii,A), for 1 < i < n. 
Suppose further that an integer function t satisfies the following, where tl is a 
fresh identifier 
(2) 
(a A (B1 V...V B,)) ==~ (t > 0). 
(3) 
(A A Bi) ::~ wp((tl := t; Ii),t < tl), for 1 < i < n. 
Then 
A ~ wp(DO, A A --(B1 V... V B.)).[::] 
Because the notion of the weakest precondition for other commands can be 
immediately transformed into Hoare's notation, the characterization of the se- 
mantics of Dijkstra's language may be formulated in terms of preconditions and 
postconditions. This notation will be applied in formalizing the meta-theory 
rw p . 
4.2 
The Object Theory T[I 
Domain knowledge is formalized by a declarative theory of the application do- 
main: the object theory Tn with derivability relation. 
4.3 
The Meta-Theory Twp 
Proof rules describing the meaning of particular Dijkstra's commands will be 
now represented as meta rules of the theory Twp (theory of wp). The theory 
Twp will be formalized as a Horn clause program ([1]). 

305 
In this theory (meta-rules for) compound statements, e.g. the sequential com- 
position, the selection command and the iteration command are logically related 
by meta-rules to the specification of simpler constructions and to theorems in 
the object theory Tn. 
Three simple commands: the multiple assignment, abort and skip are related to 
the construction of theorems in the object theory Tri. 
Meta~ 
Twp 
(1) SP(Q, xl,...,xn :=el,...,en, R)~ THR(Q~ Rel ..... e.). 
(2) SP(Q, skip, R) ~ THR(Q ~ R). 
(3) SP(Q, abort, R) *-- THR(False). 
(4) SP(Q, /1;/2, R) ~-- SP(Q, I1, S), SP(S, I2, R). 
(5) SP(Q, if B1 ~III...IB, ~Infi, R) 
THR(B1V .. . V Bn), 
SP(Q A B1, 11, R), 
SP(Q A Bn, In, R). 
(6) SP(Q, IINIT; do B1 --* I10"" DBn ---* In od, R) ~-- 
THR(P ^ -~(B1 V . .. V B,) ~ R), 
THR(P A (Sl V .. . V Bn) ~ t > 0), 
SP(Q, IINIT, P), 
SP(P A B1, I1, P), 
SP(P A Bn, In, P), 
SP(P A B1 Atl = t, I1, t < tl), 
SP(P A Bn At1 = t, In, t < tl). 
4.4 
Communication Between Meta-Theory and Object Theory 
The meta-theory Twp and the object theory Tn constitute the two basic levels 
of reasoning in the system. Because the recta-theory is formalized in a logic 

306 
programming language, we formulate the downward reflection 1 rule (between 
meta and object level) in terms of goal statements. 
(DR.l) 
*'- THR(71),..., THR(Tk), SP(oq, 111, fl,),..., SP(am, IIm, tim) 
71,- .. ,Tk 
The meta-goal-statement 
THR(71),..., THR(Tk), SP(al, HI, ill), 9 9 SP(am, IIm, tim) 
is transformed into object-goal-statement 
+-- 71,...,7k. 
Let us also recall the generic upward reflection 1 rule. 
TnP Q 
(uR1) Twp 
THR(Q) 
THR(Q) is a theorem of the meta-theory Twp, provided that Q is a the- 
orem of the object theory Tn. 
4.5 
Methodology 
The methodology adopted in the prototype is based on a program development 
method designed in [2], [7] and [3]. Our framework can be characterized through 
the following principles that underlie the process of program development: 
9 Using the concept of symbolic module. 
9 Assuming that the user is responsible for the selection of the symbolic 
module to be developed at any moment of the program construction. 
9 Assuming that the user points out a programming construct implementing 
the selected symbolic module (and delivers all the necessary information). 
4.6 
Goal Flow in the System 
Goal: To derive program II from the specification {a)II{fl). 
The system starts from the symbolic module corresponding to the program II in 
order to develop systematically all symbolic modules occurring in the program. 
(Step-wise refinement). 

307 
The initial goal-statement is of the form: 
new-goal-statement([ SP( a, II,/31). 
(A) GOAL SELECTION 
Let us assume that the new-goal-statement is of the form 
new-goal-statement( [ S P( a l , Ih , /3~ ), . . . , SP ( ,, , II, , /3, ) ] ) 
(n > 0). 
If n=0 the system finishes its work: the developed program is totally cor- 
rect. 
Otherwise, the user chooses any module Hi from (HI,..., Hn} and gives 
its partial development, i.e. points out the command (with all necessary 
information, e.g. invariant, bound function and a set of guarded commands 
in the case of an iterative command). In effect, the meta-meta-level, re- 
flecting the adopted methodology, delivers the following information: 
selected-instruction(I) 
selected-goal(Hi) 
new-goal-statement([SP(a,, II1,/31),..-, SP(ai, IIi, fli), . . . , 
sp(~., n.,/3.)]) 
(o < i < n). 
(B) (DR2) 
The system applies the downward reflection 2 rule in order to transfer the 
following control information for the meta-level reasoning: 
control-choice(Hi, [SP(al, HI,/31),..., SP(an, Hn, flu)], I) (0 < i _< n). 
(c) RESOLUTION in the META-THEORY Twp 
Based on the information obtained from the meta-meta-level, the resolu- 
tion rule is applied to the selected literal of the form SP(ai, Hi, fli) and a 
clause of the theory Twp corresponding to the selected instruction I. The 
new meta-goal statement is constructed: 
! 
! 
+- THR(71),..., THR(Tk), SP(~, II' 1, ill),..., SP(am, IIm, fl'~) 
(k > O, m >_ O). 
(D) (DR1) 
The system applies the downward reflection 1 rule. The new object-goal 
statement is of the form: 
~- 71,..., 7k 
(k > 0). 
(E) THEOREM PROVING in the OBJECT THEORY Tn 
The system transfers control to the object theory Tn in order to attempt to 
prove the theorems 71, 9 9 7k. Let us assume that the following theorems 
are proved: 
71,...,7, 
(0 < I < k). 

308 
(F) (UR1) 
The system applies the upward reflection 1 rule to transfer information 
about proved theorems into the meta-level: 
THR(Ti),..., THR(TI) 
(0 < 1 < k). 
(G) RESOLUTION in the META-THEORY Twp 
The resolution rule is applied to the current meta-goal-statement and to 
all the literals of the form THR(Ti) 
The new meta-goal statement is constructed: 
+-- THR(7~ ), . . . , THR(7~ ), SP(~'I, II'l, fl~), . . . , SP(a~, II'm, tim) 
(0 < j < k,m >_ 0). 
(H) (Ua2) 
The system applies the upward reflection 2 rule. The new meta-goal- 
statement is transferred into the meta-meta-level as the: 
current-goal-statement([ THR(7~), . . . , THR(7~ ), 
SP(~'~, II~, fl~),..., SP(a'm, H', tim)]) 
(0 < j < k, m ~ 0). 
(A1) GOAL SELECTION 
If j=0 (all the object theorems are proved) the current-goal-statement may 
become the next new-goal-statement. The resulting program is conditio- 
nally correct. 
Otherwise, the program construction was based on a false assumption, 
so further derivation should be revised. This requires establishing a next 
new-goal-statement on the meta-meta-level. To realize this point classical 
backtracking techniques may be applied. 
When the new-goal-statement is established, the system transfers control 
to point (A). 
Presented inference cycle for the prototype system gives reasons for a formulation 
of the following theorem. 
Theorem 3 Let II be a program in Dijkstra's quarded command programming 
language completely developed from the specification {c~}II{fl}, during some 
inference cycles of the prototype system. Then the program H is totally correct. 
[3 
5 
Conclusions 
The idea of supporting the programer in those phases of program derivation 
which can be realized automatically, deserve further study. In this context, the 

309 
investigation in sound development methodologies is the most urgent research 
subject. Possible approaches to program development should be charactedized in 
terms of the necessary design decisions. In order to take adequate choices at any 
moment of the program construction a highly specialized knowledge (together 
with reasoning capabilities) has to be precisely formulated. 
Treating methodology as a reasoning level responsible for the highest-level goal 
selection, a classical problem of choosing the next goal statement, especially in 
the case of failure, arises. From technical viewpoint, the well known techniques 
of backtracking can be applied here. But let us stress the need of taking decisions 
at this point as well. 
After posing all these methodological questions, answering them in a possible 
flexible way and planning an adequate interaction with the programmer, metho- 
dology can be treated as a full rights reasoning level. Distinguishing methodo- 
logy as the meta-meta-level in multi-level compositional architecture for correct 
program derivation suggests a transparent description of this, rather complex, 
process. The approach reported in this paper illustrates the need of having two 
meta-levels in order to resolve more complicated problems. 
Another line of research is increasing of the expressive power of the system. 
The methodology may be extended by adopting different program construction 
techniques, not only restricted to stepwise-refinement. A very natural exten- 
tion seems to be a combination of top-down program development (using the 
concept of symbolic module) and/or composing program from already existing 
components (modules). 
The ideas underlying the general-purpose system for program derivation are 
based on our experiences with CAProDel -- a system supporting the user in 
creating programs in Dijkstra's quarded command programming language. This 
system was implemented at Institute of Informatics of Warsaw University (for 
details please consult [5]). A multi meta-levels generic system meant for carrying 
out experiments in program development is currently under implementation. In 
this case the methodology for complex reasoning task and the modelling language 
for compositional architecture -- DESIRE -- is applied. 
6 
Acknowledgements 
I would like to thank Witold Lukaszewicz for the fruitful discussion motivating 
this work. 

310 
References 
[1] K. Apt. Logic programming. In J. van Leeuven, editor, Handbook of Theo- 
retical Computer Science. Elsevier Science Publishers, 1990. 
[2] E. W. Dijkstra. A Discipline of Programming. Prentice Hall, Englewood 
Cliffs, 1976. 
[3] G. Dromey. Program Derivation. The Development of Program from Speci- 
fications. Addison Wesley, Reading, Mass., 1989. 
[4] B. Dunin-Kr 
Formal reconstruction of correct programs development 
process. Technical report, Institute of Informatics, Warsaw University, 1994. 
[5] B. Dunin-Kr 
J. Jabtonowski, W. Lukaszewiez, and E. Madalifiska- 
Bugaj. CAProDeI: A system for computer aided program development. 
To appear in Proceeding of the Sixth International Conference on Software 
Engineering and Knowledge Engineering, SEKE'94, Jurmala, Latvia, 1994. 
[6] B. Dunin-K~plicz, J. Jablonowski, W. Lukaszewicz, and E. Madalifiska- 
Bugaj. Developing programs from specifications: Design of a system. In 
Proceedings of the Third International Conference on Information Systems 
Developers Workbench, pages 145-168, Gdafisk, 1992. 
[7] D. Gries. The Science of Programming. Springer, Berlin, 1981. 
[8] A. Langevelde, A. Philipsen, and J. Treur. Formal specification of compo- 
sitional architecture. In Proecedings of ECAI 92, pages 272-276, Vienna, 
1992. 
[9] W. M. Turski. Computer Programming Methodology. Heyden, London, 1978. 

More on Unfold/Fold 
Transformations of Normal 
Programs: Preservation of Fitting~s Semantics. * 
Annalisa Bossi 1 and Sandro Etalle 1,2 
1 Dipartimento di Matematica Pura ed Applicata 
Universitk di Padova 
Via Belzoni 7, 35131 Padova, Italy 
CWI 
P.O. Box 4079, 1009 AB Amsterdam, The Netherlands 
emaJ]: bosai~zenone .math.unipd. it, etalle@cwi .nl 
Abstract. The unfold/fold transformation system defined by Tamaki and 
Sato was meant for definite programs. It transforms a program into an equiv- 
alent one in the sense of both the least tterbrand model semantics and the 
Computed Answer Substitution semantics. Seki extended the method to nor- 
mal programs and specialized it in order to preserve also the finite failure set. 
The resulting system is correct wrt nearly all the declarative semantics for 
normal programs. An exception is Fitting's model semantics. In this paper we 
consider a slight variation of Saki's method and we study its correctness wrt 
Fitting's semantics. We define an applicability condition for the fold opera- 
tion and we show that it ensures the preservation of the considered semantics 
through the transformation. 
1 
Introduction 
The unfold/fold transformation rules were introduced by Burstall and Darlington 
[8] for transforming clear, simple functional programs into equivalent, more efficient 
ones. The rules were early adapted to the field of logic programs both for program 
synthesis [10, 13] and for program specialization and optimization [2, 16]. Soon later, 
Tamaki and Sato [26] proposed an elegant framework for the transformation of logic 
programs based on unfold/fold rules. 
The major requirement of a transformation system is its correctness: it should 
transform a program into an equivalent one. Tamaki and Sato's system was originally 
designed for definite programs and in this context a natural equivalence on programs 
is the one induced by the least Herbrand model semantics. In [26] it was shown that 
the system preserves such a semantics. Afterward, the system was proven to be 
correct wrt many other semantics: the computed answer substitution semantics [14], 
the Perfect model semantics [24], the Well-Founded semantics [25] and the Stable 
model semantics [23, 4]. 
In [24], Seki modified the method by restricting its applicability conditions. The 
system so defined enjoys all the semantic properties of Tamaki-Sato's, moreover, 
* This work has been partially supported by "Progetto Finalizzato Sistemi Informatici e 
Calcolo Parallelo" of CNR under grant n. 89.00026.69 

312 
it preserves the finite failure set of the original program [22] and it is correct wrt 
Kunen's semantics [21]. 
However, neither Tamaki-Sato's, nor Seki's system preserve the Fitting model 
semantics. 
In this paper we consider a transformation schema which is similar yet slightly 
more restrictive to the one introduced by Seki [24] for normal programs. We study 
the effect of the transformation on the Fitting's semantics [11] and we individuate 
a sufficient condition for its preservation. 
The difference between the method we propose and the one of Seki consists in the 
fact that here the operations have to be performed in a precise order. We believe that 
this order corresponds to the "natural" order in which the operations are usually 
carried out within a transformation sequence, and therefore that the restriction we 
impose is actually rather mild. 
The structure of the paper is the following. In Section 2 we recall the definition of 
Fitting's operator. In Section 3 the transformation schema is defined and exemplified, 
and the applicability conditions for the fold operation are presented and discussed. 
Finally, in Section 4, we prove the correctness of the unfold/fold transformation wrt 
Fitting's semantics. 
2 
Preliminaries 
We assume that the reader is familiar with the basic concepts of logic programming; 
throughout the paper we use the standard terminology of [17] and [1]. We consider 
normal programs, that is finite collections of normal rules, A ~-- L1,..., Lm. where A 
is an atom and L1,..., Lm are ]iterals. Bp denotes the Herbrand base and Ground(P} 
the set of ground instances of clauses of a program P. We say that a clause is definite 
if the body contains only positive literals (atoms); a definite program is then a 
program consisting only of definite clauses. Symbols with a -.~ on top denote tuples 
of objects, for instance s denotes a tuple of variables zl,..., x,~, and s = ~ stands 
for xl = Yl A...Axn = Yn. We also adopt the usual logic programming notation that 
uses "," instead of A, hence a conjunction of literals Lj A ... A Ln will be denoted 
by L1,...,L,~ or by L. 
Three valued semantics for normal programs. In this paper we refer to the 
usual Clark's completion definition, Comp(P), [9] which consists of the completed 
definition of each predicate together with CET, Clark's Equality Theory, which is 
needed in order to interpret "=" correctly. It is well-known that, when considering 
normal programs, the two valued completion Comp(P) of a program P might be 
inconsistent an consequently have no model; moreover, when Comp(P) is consistent, 
it usually has more models, none of which can be considered the least (hence the 
preferred) one. Following [11], we avoid this problem by switching to a three-valued 
logic, where the truth tables of the connective are the ones given by Kleene [15]. 
When working with 3-valued logic, the same definition of completion app/ies, with 
the only difference that the connective ~ is replaced with r 
Lucasiewicz's oper- 
ator of "having the same truth value". In this context, we have that a three valued 

313 
(or pa~ial) interpretation, is a mapping from the ground atoms of the language/: 
into the set {true, false, undefined}. 
Definitionl. 
Let s be a language. A three valued (or parlial) /:-interprelalion, I, 
is a mapping from the ground atoms of/: into the set {true, false, undefined}. 
1:3 
A partial interpretation I is represented by an ordered couple, (T, F), of disjoint 
sets of ground atoms. The atoms in T (resp. F) are considered to be lrue (resp. false) 
in I. T is the positive part of I and is denoted by I+; equivalently F is denoted by 
I-. Atoms which do not appear in either set are considered to be undefined. 
If I and J are two partial /:-interpretations, then I N J is the three valued /:- 
interpretation given by (I + N J+, I- A J-), I U J is the three valued/:-interpretation 
given by (I + t3 J+, I- U J-) and we say that I C J iffI = IN J, that is, iffI + C J+ 
and I- _C J-. The set of all/:-interpretations is then a complete lattice. In the se- 
quel we refer to a fixed but unspecified language/~ that we assume contains all the 
functions symbols and the predicate symbols of the programs that we consider, con- 
sequently we will omit the Z: prefix and speak of "interpretations" rather than of 
"/:-interpretations". 
We now give a definition of Fitting's operator [11]. We denote by Vat(E) the 
set of all the variables in an expression E and we write 3y BO as a shorthand for 
(3y B)~, that is, unless explicitly stated, the quantification applies always before the 
substitution. 
Definition2. Let P be a normal program, and I a three valued interpretation. 
9 p(I) is the three valued interpretation defined as follows: 
- A ground atom A is lrue in ~p(I) 
iff there exists a clause c : 
B,--L. in P whose head unifies with A, O = 
mgu(A,B), and 3~0 is true in I, where tb is the set of local variables of c, 
Co = Var(Z)\Var(B). 
- A ground atom A is false in~p(I) 
ifffor all clauses c : B~-L in P for which there exists 0 = mgu(A,B) we 
have that 3~ L6 is false in I, where ~ is the set of local variables of c, ~ = 
Var(L)\Var(B). 
0 
Recall that a Herbrand model is a model whose universe is given by the set of 
/:-terms. 
~p is a monotonic operator, that is I C_ J implies q~p(I) C ~Sp(J), and charac- 
terizes the three valued semantics of Comp(P), in fact Fitting, in [11] shows that 
the three-valued Herbrand models of Comp(P) are exactly the fixpoints of ~/ie; it 
follows that any program has a least (wrt. C) three-valued Herbrand model, which 
coincides with the least fixpoint of ~p. This model is usually referred to as Fitting's 
model. 
Definition3. Let P be a program, Fitting's model of P, Fit(P), is the least three 
valued Herbrand model of Comp(P). 
o 

314 
We adopt the standard notation: ~0 is the interpretation that maps every ground 
atom into the value undefined, ~?pa+l = ~p(~a), ~ 
= Ut<a~pT/6, when c~ is a limit 
ordinal. From the monotonicity of ep follows that its Kleene's sequence is mono- 
tonically increasing and it converges to its least fixpoint. Hence there always exists 
an ordinal c~ such that lfp(~p) = eTp~. Since ~p is monotone but not continuous, c~ 
could be greater than w. 
Theorem4 [11]. Le~ P be a program, then, for some ordinal c~, 
- Fit(P) = r 
[] 
3 
Unfold/fold 
transformations 
3.1 
Introduction 
Unfold and fold are basic transformation rules but their definition may differ de- 
pending on the considered semantics. 
Unfolding is the fundamental operation for partial evaluation [18] and consists 
in applying a resolution step to the considered atom in all possible ways. Usually, it 
is applied only to positive literals (an exception is [3]). 
Folding is the inverse of unfolding when one single unfolding is possible. Syntac- 
tically, it consists in substituting a literal L for an equivalent conjunction of literals 
K in the body of a clause c. This operation is used to simplify unfolded clauses and 
to detect implicit recursive definitions. In order to preserve the declarative semantics 
of logic programs, its application must be restricted by some, semantic dependent, 
conditions. Therefore, the various proposals mainly differ in the choice of such con- 
ditions. They can be either a constraint on how to sequentialize the operations while 
transforming the program [26, 24], or they can be expressed only in terms of (seman- 
tic) properties of the program, independently from its transformation history [5, 19]. 
For normal programs different definitions for folding in a particular transformation 
sequence are given in [24, 23, 12]. 
3.2 
A four step transformation schema 
In this section we introduce the unfold/fold transformation schema. All definitions 
are given modulo reordering of the bodies of the clauses and standardization apart 
is always assumed. 
First we define the unfolding operation, which is basic to all the transformation 
systems. 
Definition5 Unfold. Let cl : A *--- L, H. be a clause of a normal program P, where 
H is an atom. Let {H1 ~--/?1,.-., H,~ *--/),~} be the set of clauses of P whose heads 
unify with H, by mgu's {01,..., 0.}. 
- 
unfolding an a*om H in cl consists of substituting cl with {cl~ .... , cl'n} , where, 
for each i, cl~ = (A ~-- 7~, f~i)~i. 
unfold (P, cl, H) de2 P\{cl} O {cll,..., cl~}. 
[] 
Let P be a normal program. A four step transformation schema starting in the 
program P consists of the following steps: 

315 
Step 1. Introduction 
of new definitions. We add to the program P the set of 
clauses Ddef --" {ci : Hi *'-/~i}, where the predicate symbol of each Hi is new, that 
is, it does not occur in P. On the other hand, we require that the predicate symbols 
found in each /3i are defined in P, and therefore are not new. The result of this 
operation is then 
- P1 = P UDdef 
I-1 
Example 1 
P={ 
(rain-max, part 1). Let P be the following program 
min([X], X). 
m~n([XlXs], Y) ~ m~n(Xs, Z), in/(X, Z, Y). 
m,~([X], X). 
max([XlXs], Y) ~ max(Xs, Z), sup(X, Z, Y). 
in/(x, Y, x) 
,-- x < y. 
inf(X, Y, Y) 
*--- -(X < Y). 
sup(X, Y, Y) 
~-- X < Y. 
sup(X, Y, X) 
~ ~(X <_ Y). 
cl : med(Xs, Med) 
~-- min(Xs, Min), 
max(Xs, Max), 
Med is (Min + Max)~2. 
here med(Xs, Med) reports in Med the average between the minimum and the 
maximum of the values in the list Xs. 
We may notice that the definition of med(Xs, Med) traverses the list Xs twice. 
This is obviously a source of inefficiency. In order to fix this problem via an un- 
fold/fold transformation, we first have to introduce a new predicate minmax. Let us 
then add to program P the following new definition: 
Ddef = {c~: minmax(Xs, Min, Max) *--- min(Xs, Min), max(Xs, Max). ) 
H 
Step 2. Unfolding in Ddef. We transform Ddef into Dunf by unfolding some of its 
clauses. The clauses of P are therefore used as unfolding clauses. This process can 
be iterated several times and usually ends when all the clauses that we want to fold 
have been obtained; the result of this operation is 
- P2=PUDunr 
[] 
Example 1 (rain-max, part 2). We can now unfold the atom rnin(Xs, Min) in the 
body of c2, the result is 
c3: rninrnax([X], X, Max) 
,-- max(IX], Max). 
c4 : minrnaz([X]Xs], Min, Max) ~-- rnin(Xs, Y), 
inf(X, Y, Min), 
max([X ]X s], M az ). 
In the bodies of both clauses we can then unfold predicate max. Each clause gener- 
ates two clauses. 

316 
min. ax([x], x, x). 
cs: minmax([X], X, Max) 
~ max([ ], Z), sup(Z, X, Max). 
cr : minmax([X], Min, X) 
~ rain([ ], Y), inf(X, Y, Min). 
c8: minmax([XlXs], Min, Max) 4--- min(Xs, Y), 
inf(X, }I, Min), 
max(Xs, Z), 
sup(X, Z, Max). 
Clauses c6 and c7 can then be eliminated by unfolding respectively the atoms 
max([ ], Z) and rain([ ], Y). Dunf consists then of the following clauses. 
min ax([X], x, x). 
cs: minmaz([X[Xs], Min, Max) ,-- min(Xs, Y), 
inf(X, Y, Min), 
max(Xs, Z), 
sup(X, Z, Max). 
Still, rninmax traverses the list Xs twice; but now we can apply a recursive folding 
operation. 
D 
Step 3. Recursive folding. Let c{ : Hi ~-- [~i be one of the clauses of Ddef, which 
was introduced in Slep 1, and cl : A ~--/3', S. be (a renaming of) a clause in Dunf. 
If there exists a substitution 0, Dora(O) = Var(cl) such that 
(a) 
h 0; 
(b) 0 does not bind the local variables ofci, that is for any x, y E Var(Bi)\Var(fIi) 
the following three conditions hold 
- xO is a variable; 
- 
x0 does not appear in A, S, HiO; 
- if z -~ y then zO # yO; 
(c) cl is the only clause of Ddef whose head unifies with HiO; 
(d) all the literals of B' are the result of a previous unfolding. 
then we can fold HiO in cl, obtaining cl I : A ~--HiO, S. This operation can be 
performed on several conjunctions simultaneously, even on the same clause. The 
result is that Dunf is transformed into Dfold and hence 
- 
P3 
= PU Drola 
[:] 
Example 1 (rain-raax, par~ 3). We can now fold min(Xs, Y), max(Xs, Z) in the 
body of cs. The resulting program Dfold consists of the following clauses 
c5: minmax([X], X, X). 
c9: minmax([X[Xs], Min, Max) ~-- minraax(Xs, Y, Z), 
inf(X, Y, Min), 
sup(X, Z, Max). 
minmax(Xs, Min, Max) has now a recursive definition and needs to traverse the 
list Xs only once. In order to let the definition of rned enjoy of this improvement, 
we need to propagale predicate rninmax inside its body. 
o 

317 
Step 4. Propagation folding. Technically, the difference between this step and 
the previous one is that now the folded clause comes form the original program P. 
This allows us to drop condition (d) of the folding operation. 
Let cl : Hi *--/)i be one of the clauses of Daef, which was introduced in S~ep I, 
and cl : A *-- IV, S. be (a renaming of) a clause in the original program P. If there 
exists a substitution 9, Dorn(O) = Yar(ci) such that the conditions (a), (b) and (c) 
defined above are satisfied, then we can fold Hi0 in cl, obtaining cl I : A *--- Hi6, S. 
Also this operation can be performed on several conjunctions simultaneously, even 
on the same clause. The result is that P is transformed into Pfold and therefore 
- P4 = Pfo|d U Dfold 
Ezample 1 (min-maz, part 4). We can now fold min(Xs, Y),max(Xs, Z) in the 
body of cl, in the original program P. The resulting program is 
Pfola = P\{cl} U {c10: med(Xs) ~-- rninmaz(Xs, Min, Mar.), 
Med is (Min + Max)/2. 
} 
And then the final program is P4 = Pfold I../ Dfold = 
= { c~: .~inma=([x], x, x). 
c9: minmaz([XlXs], Min, Max) ~-- 
clo : med(Xs) 
*-- 
+ definitions for predicates min, rnaz, 
minmax( X s, Y, Z ), 
inf(X, Y, Min), 
sup(X, Z, Max). 
minrnaz( X s, M in, Max), 
Med is (Min + Maz)/2. 
inf and sup.} 
Notice also that predicates rain and max are no longer used by the program, rn 
3.3 
Semantic considerations 
The schema (that is, the method we propose) is similar but more restrictive than the 
transformation sequence with modified folding 3 proposed by Seki [24]. The (only) 
limitation consists in the fact that the schema requires the operations to be per- 
formed in fixed order: for instance it does not allow a propagation folding to take 
place before a recursive folding. We believe that in practice this is not a bothering 
restriction, as it corresponds to the "natural" procedure that is followed in the pro- 
cess of transforming a program. In fact, in all the papers we cite, all the examples 
that can be reduced to a transformation sequence as in [24], can also be reduced to 
the given transformation schema. 
Since the schema can be seen as a particular case of the transformation sequence, 
it enjoys all its properties, among them, it preserves the following semantics of the 
initial program: the success set [26], the computed answer substitution set [14], the 
s here we are adopting Seld's notation, and we call modified folding the one presented 
in [22, 24], which preserves the finite failure set, as opposed to the one introduced by 
Tamaki and Sato in [26], which does not. 

318 
finite failure set [24], the Perfect model semantics for stratified programs [24], the 
Well-Founded semantics [25], the Stable model semantics [23, 4]. 
However, as it is, the schema suffers of the same problems of the sequence, i.e., 
Fitting's Models is not preserved. This is shown by the following example. 
Example 2. Let P1 = P UDdef, where P and Ddef are the following programs 
D~or = { p 
,-- q(X). 
} 
P 
= { q(s(X)) ~ 
q(x),t(O). 
t(o). 
} 
As we fix a language s that contains the constant 0 and the function s/l, we have 
that 3X q(X) is false in Fit(P1), consequently, p is also false in Fit(P~). Now let us 
unfold q(X) in the body of the clause in Ddef; the resulting program is the following. 
P2 = P U Dunf, where 
Dunf = { P 
+'-- q(Y),t(O). ) 
P 
= { q(s(x)) ~ 
q(X),t(o). 
t(o). 
} 
We can now fold q(Y) in the body of the clause of Dunf, the resulting program is 
P3 = P U Dfold, where 
Ofold = { P 
e- p,t(O). 
} 
P 
= { q(s(X)) ~ q(X),t(O). 
t(o). 
} 
Now we have that p is undefined in the Fitting model of P3. 
[:3 
So, in order for the transformation to preserve Fitting's model of the original 
program, we need some further applicability conditions. Therefore the following. 
Theorem 6 Correctness. Let P1,..., P4 be a sequence of programs obtained ap- 
plying the transformation schema to program P. Let also Ddef --~ {Hi ~ Bi } be the 
set of clauses introduced in Step 1, and, for each i, 5)i be the set of local variables of 
ci: 5Ji = Var(Bi)\Var(Hi). If each cl in Da~f satisfies the following condition: 
A each lime that 3~i BiO is false in some r 
then there exists a non-limit ordinal 
c~ < 13 such that 3Col BiO is false in ~ 
Then Fit(P1) = Fit(P2) = Fit(P3) = Fit(P,). 
Proof. The proof is given in the subsequent Section 4. 
o 
On condition A. Condition A is in general undecidable, it is therefore important 
to provide some other decidable sufficient conditions. For this, in the rest of this 
Section, we adopt the following notation: 
" Dder = {cl : Hi *"/Ts'} is the set of clauses introduced in Step 1, 
and, for each i, 

319 
- wi = Var(Bi)\Var(Hi) is the set of local variables of ci. 
First, it is easy to check that if ci has no local variables, then it satisfies A. 
Proposition 7. If wl = O then ei satisfies A. 
Proof. It follows at once from the definition of Fitting's operator. 
O 
This condition, though simple, is met by most of the examples found in the 
literature; if we are allowed an informal "statistics", of all the papers cited in our 
bibliography, seven contain practical examples in clausal form which can be assim- 
ilated to our method ([6, 14, 20, 22, 24, 25, 26]), and of them, only two contain 
examples where the "introduced" clause contains local variables ([14, 20]). Our Ex- 
ample 1 satisfies the condition as well. 
Nevertheless Proposition 7 can easily be improved. First let us consider the fol- 
lowing Example 4. 
Example 3. Let P1 = P U Ddef, where P and Dder are the following programs 
Ddef = { c0 : br(X, Y) 
+--- reach(X, Z), reach(Y, Z). } 
P 
= { 
reach(X,Y) *-- arc(X,Y). 
reach(X, Y) ,--- arc(X, Z), reach(Z, Y). 
} U DB 
Where DB is any set of ground unit clauses defining predicate arc. reach(X, Y) holds 
iff there exists a path starting from node X and ending in node Y, while br(X, Y) 
holds iff there exists a node Z which is reachable both from node X and node Y. [] 
In this Example the definition of predicate br can be specialized and made re- 
cursive via an unfold/fold transformation. Despite the fact that clause co contains 
the local variable Z, it is easy to see that A is satisfied. This is due to the fact that 
P is actually a DATALOG (function-free) program. 
We now show that if (a part of) the original program P is function-free (or 
recursion-free) then A is always satisfied. 
Let us first introduce the following notation. Let p, q be predicates, we say that 
p refers to q in program P if there is a clause of P with p in its head and q in its 
body= The depends on relation is the reflexive and transitive closure of refers to. 
Let L be a conjunction of literals, by PIL we denote the set of clauses of P that 
define the predicates which the predicates in/] depend on. We say that a program is 
recursion-free if there is no chain Pl,..-,Pk of predicate symbols such that pi refers 
to pi+x and Pk = Pl. With an abuse of notation, we Mso call a program function-free 
if the only terms occurring in it are either ground or variables. 
We can now state the following. 
Proposition8. 
For each index i, and each w E ffJi, let us denote by L~ the subset 
of Bi formed by those literals where w occurs. If for every Lw, one of the following 
two conditions holds: 
4 The example is actually a rhodification of Example 2.1.1 in [22] 

320 
(a) P1 ]s is recursion-free, or 
(b) PilL. is function-free; 
then each ci satisfies A. 
Proof, First we need the following Observation. 
Observation 9 Let Q be a function-free or a recursion-free program, then for some 
integer k, Fit(Q) = r 
Proof. Straightforward 
[] 
Now fix an index i, and let Col = wl,..., win, and let hT/be the subset of Bi consisting 
of those literals that do not contain any of the variables in ~i. It is immediate that, 
for any ordinal a, and for any substitution 0 
r 
iff r 
... ASwmL,o~OA)VIO 
(1) 
Now suppose that, for some ordinal or, and substitution O, 3Col [3i0 is false in ~. 
By (1), either (O ~-40 is false in etp~, or 0/) there exists an i such that ?wi ;~0 is 
false in ~; 
we treat the two cases separately. 
(i), 1OO is false in ~Ie~, then, by the definition of ~p~, there exists a non-limit 
ordinal/3 < (~ such that )O0 is false in ~TP and, by (1), 3~5i/)i0 is false in ~b Tp 
-- 
PI ' 
PI " 
(ii), 3wi Lw,O is false in ~rp:, since P11L., is function or recursion-free, by Obser- 
vation 9 there exists an integer k such that 3wi Lw~0 is false in ~pk; again, by (1), 
3tbi Bid is false in ~irpk. 
So, in any case, there exists a non-limit ordinal ~3 _< o~ such that 3ffJi BiO is false 
in ~T~ Since this holds for any index i, the thesis follows. 
13 
PI" 
Checking A "a posteriori". We now show that condition A holds in P0 iff it 
holds in any program of the unfold part of the transformation sequence. This gives 
us the opportunity of providing further sufficient conditions. 
First let us restate A as follows: 
A': For each substitution 0 and non-limit ordinal/3, if Hi/? is false in ~T~+I then 
Pl 
' 
HiO is false in #T~ 
Pa as well. 
Now, let P~ be a program which is obtained from P1 by applying some unfolding 
transformation. It is easy to see 5 that Hi satisfies A ~ in P1 iff Hi satisfies A' in P~. 
So the advantage of A' over A is that it can be checked a posteriori at any time 
during the unfolding part of the transformation. So Proposition 8 can be restated 
as follows. 
Proposition 10. Let P[ be a program obtained from P1 by (repeatedly) applying the 
unfolding operation. Let D~der be the subset of P' corresponding to Ddef in P. If for 
each clause c of D~def, and for every variable y, local to the body of c 
5 This is a direct consequence of Lemma 11, which is given in the next Section 

321 
! 
~ 
- P~ [L, is recursion-free or function.free, 
where L~ denotes the subset of the body of c consisting of those literals where y 
occurs; 
then each ci satisfies A in P1. 
Proof. It is a straightforward generalization of the proof of Proposition 8. 
[:3 
4 
Correctness 
of the transformation 
The aim of this section is to prove the correctness of the transformation schema wrt 
Fitting's semantics, Theorem 6. 
4.1 
Correctness of the unfold operation 
First we consider the unfold operation. To prove its correctness we need the following 
technical Lemma. 
Lemmall. 
Let pi be the program obtained by unfolding an atom in a clause of 
program P. Then for each integer i and limit ordinal fl, 
Ti _ r 
- 
c_ 
and 
c 
, 
_ 
~12i[d~T~ 
9 ~(~'/) C ~Ti {~T#~ and 
~ 
(~T#~ C ~p ,~p ). 
_ 
~t-p~ \~p~ 
] 
~P~ 
k~P 
~ 1 -- 
Proof. The proof is given in [7]. 
t3 
This brings us to a preliminary conclusion. 
Corollary 12 Correctness of the unfold operation. Let P~ be the result of un- 
folding an atom of a clause in P. Then 
- Fit(P) = Fit(P') 
[] 
It should be mentioned that, because of the particular structure of the transfor- 
mation sequence, here we never use self-unfoldings (that is, unfoldings in which the 
same clause is both the unfolded clause and one of the unfolding ones). Consequently 
the correctness of Step 2 follows also from a result of Gardner and Shepherdson [12, 
Theorem 4.1] which states that if the program pt is obtained from P by unfold- 
ing (but not self-unfolding), then Comp(P) and Comp(P') are logically equivalent 
theories 6 . 
The following is a second, technical result on the consequences of an unfolding 
operation which will be needed in the sequel. 
Lemma13. 
Let P be a normal program, cl : A *-- f<. be a definite, clause of P. 
Suppose also that cl is the only clause of P whose head unifies with AO. If P' is 
the program obtained by unfolding at least once all the atoms in [<, then, for each 
non-limit ordinal c~ 
e In [12] this result is stated for the usual two-valued program's completion. By looking at 
the proof it is straightforward to check that it holds also for the three-valued case 

322 
- ifAO is true (resp. false) in ~,+1 then AO is true (resp. false) in 0~? 
Proof. Let us first give a simplified proof by considering the case when/-f consists 
of two atoms H, J and we perform a single unfolding on them; we will later consider 
the general case. 
Let {H1 +--/~1.,..., H, ~/},~.} be the set of clauses of P whose head unify with 
H via mgu's r 
r 
and let {J1 '-'- C1.,.-., Jm '-- C,,~} be the set of clauses of 
P whose head unify with J. Unfolding H in cl and then J in the resulting clauses, 
will lead to the following program: 
P' = P\{cl) U (d,,j : (A *-- [3,, (~j.)0i,j)} 
Where Oi,j = mgu(Jr 
Jj). Here some of the clauses dij may be missing due to the 
fact that Jr 
and Jj may not unify, but this is of no relevance in the proof. 
Note that the clauses did are the only clauses of P~ whose head could possibly 
unify with A. 
Let â€¢ = Vat(H, J)\Var(A) be the set of variables local to the body. We have to 
consider two cases. 
a) AO is lrue in ai?o+l 
~p 
. By the definition of JR, (3~ H, J)O is lrue in CTp~. There 
has to be an extension a of 0, Dora(a) = Dora(O) U f/ = Vat(A, H, J) such that 
(H, J)a is true in ~. 
Let Hi ~/31 and Jj +--Cj be the clauses used to prove, 
respectively, Ha and Ja. Hence there exists a r such that Oi,jV[Dom(o) = a, Ha = 
-_ 
~Ta-i 
HiOi,jr, Ja 
JjOi,jr, and (Bi,Cj)Oi,jr is irue in ~Tp~-l. By Lemma 11, ~s, 
C_ 
]'a--I 
n~Ta- 1 
p, 
, hence (B{, Cj)O{,jr is irue in ~-p, 
. It follows that AOi,j r = Aa = AO is irue 
ta 
in 45p,. 
b) AO is false in 4~Tp a+l. By the definition of 4~p, (3~ H, J)O is false in ~/iTpa. Hence 
for all extensions a of 0, such that Dora(a) = Dorn(O) t3 ~l = Vat(A, H, J), we have 
that (H, J)a is false in ~Ie~. 
Hence for all such a's, and for all i,j and r such that Oi,jr[Dom(a) = a, H~ = 
~ 
~ 
fsTa_ 1 
Hi Oi,j r, Ja = Jj Oi,jr, we have that (Bi, Cj)Oi,j 7" is false in ~e 
. By Lemma 11, 
Ta-1 
__ di'fa-1 
(Bi,Cj)Oi,jT is 
OTpa,1. Since the clauses di, j are the 
p 
C .-p, 
, hence 
false in 
only ones that define A in P', we have that AOi,j 7" = Ao- = AO is false in O~a,. 
Now to complete the proof, we have to observe two facts: 
- First, that if we perform some further unfoldings on the resulting clauses, then 
we can only "speed up" the process of finding the truth value of A. In fact, by the 
same kind of reasoning used above, if AO is true in ~sTpa,, and P" is obtained from p, 
by unfolding some atoms in the bodies of the clauses did, then, for some fl < a, AO 
is true in oTpO. 
- Second, that if cl contains just one atom, or more than two atoms, then the 
exact same reasoning applies. 
12 
4.2 
The replacement operation 
In order to prove the correctness of the unfold/fold transformation schema we will 
use (a simplified version of) the results in [6, 7] on the simultaneous replacement 
operation. 

323 
The replacement operation has been introduced by Tamaki and Sato in.[26] 
for definite programs. Syntactically it consists in substituting a conjunction, C, of 
literals with another one,/), in the body of a clause. 
Similarl_y, simultaneous replacement consists in substituting a set of conjunctions 
of literals {61 .... , C~ ), with another corresponding set of conjunctions {/91,..., b. ) 
in the bodies of the clauses of program P; here each Ci represents a subset of the 
body of a clause of P and we assume that if i r j then Ci and Cj do not overlap, 
that is, they are either found in different clauses or they represent disjoint subsets 
of the same clause. 
Note that the fact that each C~ may occur in the body of only one clause of P is 
not restrictive, as even if i r j, Ci and Cj may actually represent identical literals. 
We now give a simplified version of the applicability conditions introduced in [6, 7] 
in order to ensure the preservation of the semantics through the transformation. Such 
conditions depend on the semantics we associate to the program. Our first require- 
ment is the semantic equivalence of the replacing and the replaced conjunctions of 
literals. 
Definition 14 Equivalence of formulas. Let E, F be first order formulas and P 
be a normal program. 
- F is equivalent to E wrt Fit(P), F ...p E, if for each ground substitution 0 
EO is true (resp. false) in Fit(P) iff FO is. 
rn 
Note that F mR E iff Fit(P) ~ V(F r 
E). 
Example 4. Let P be the program in Example 1. We have that 
med(Xs, Med) ~p 3X, Y min(Xs, X) A max(Xs, Y) A Meg = (X + Y)/2 
[3 
With many respects, and with some caution, two equivalent (conjunctions of) 
literals can be used interchangeably; for example, if q is a new predicate we want to 
give a definition to, and we know that A ..~p B then defining q by introducing the 
new clause q ,--- A is, from Fitting's semantics viewpoint, equivalent to doing it by 
introducing q ~- B. 
Notice that the formula in Example 4 we had to specify X and Y as existentially 
quantified variables. When we want to replace the conjunction C with D, in the 
clause cl the first requirement of those applicability conditions is the equivalence of 
35 ~' and B~ D, where $ is a set of "local variables", that is, variables which appear 
in C and/or /), but which do not occur anywhere else in the clause that we are 
transforming. The equivalence is required as it would make no sense to replace 
with something which has a different meaning. Unfortunately this is not enough, in 
fact we need the equivalence to hold also after the transformation. The equivalence 
can be destroyed when D depends on cl, in which case the operation may introduce 
an infinite loop. 
In order to prove that no fatal loops are introduced, we make use of a further 
concept. Here we say that the (closed) formula G is defined in the interpretation I, 
if the truth value of G in I is not undefined. 

324 
Definitionl5 not-slower. Let P be a normal program, E and F be first order 
formulas. Suppose that F up E. We say that 
- 
F is not-slower that E if for each ordinal tr and each ground substitution ~: 
Ta 
if EO is defined in ~p , then FO is defined in r 
as well. 
0 
So F is not-slower that E if, for each 8, computing the truth value of FO never 
requires more iterations that computing the one of EO. In a way we could then say 
that the definition of F is at least as efficient as the one of E. 
The following Theorem shows that if the replacing conjunctions are equivalent 
to and not-Mower than the replaced ones, then the replacement operation is correct. 
Theorem 16. Let P~ be a program obtained by simultaneously replacing the con- 
junctions {C1 .... ,Ca} with {D1,...,/gr,} in the bodies o/the clauses of P. I/for 
each Ci, there ezists a (possibly empty) set of variables xi such that the following 
three conditions hold: 
(a) [locality of the variables in ki]. @, is a subset of the variables local to Ci and 
Di, that is, ~ C_ Var(~)U Var(b~) and the variables in ~i don't occur in 
{/)1 ..... [91-1, [9i+1 .... , Dn} nor anywhere else in the clause where Ci is found. 
(b) [equivalence of the replacing and replaced parts]. 3~i Di Np 3~i Ci 
(c) [the Di's are not-slower than the Ci's]. 3@i Di is not-slower than 3~i Ci. 
then Fit(P) = Fit(P'). 
Proof. This is a particular case of Corollary 3.16 in [7]. 
A property we will need in the sequel is the following. 
Proposition 17. Suppose that A *--C, E is a clause of P and that P~ is obtained 
from P by replacing C with D in such a way that lhe conditions of Theorem 16 are 
satisfied (so that Fit(P) = Fit(P')). Then 
- 
Each time that AO is true (resp. false) in r 
then AO is true (resp. false) in 
Proof. This is a consequence of the fact that the replacing conjunction is not- 
slower than the replaced one. The formal proof is omitted here, it can be inferred 
by analyzing the proof of Theorem 3.15 in [7] 
O 
Before we provide the proof of the correctness of the four step schema, we need 
to establish some further preliminary results. The first one states that the converse 
of A holds in any case. 
Proposition l8. Each time that 3ff~BO is true in some qSIZ then there exists a 
Pl t 
non-limit ordinal a < [3 such that 3ff~ BO is true in ~Tp:. 
Proof. It follows at once from the definition of Fitting's operator. 
[] 
The following important transitive property holds: 

325 
Propositionl9. 
Let P and P' be normal programs , E and F be first order formulas; 
- If E ,..p F and Fit(P) = Fit(P'), then E ,~,, F. 
D 
Now we can provide the details of the proof. 
4.3 
Correctness of the four step schema 
We now prove the correctness of the four step schema. For the sake of simplicity 
we restrict ourselves to the case in which Step 1 introduces only one clause. The 
extension to the general case is straightforward. 
Let P1,...P4 be the sequence of programs obtained via the four step schema: 
P1 is the initial program, i.e. the one that contains Ddef. P2, Pa and P4, are the 
programs obtained by applying steps Step 2 through Step 4. In order to show that 
the Fitting's models of programs P1 .... P4 coincide, we proceed as follows: 
By the correctness of the unfolding operation, Corollary 12 we have that Fit(P1) = 
Fit(P2). 
We perform some further unfolding on some atoms of P2, obtaining a new pro- 
gram that we will call P2u, again by Corollary 12 we have that Fit(P2) = Fit(P2~); 
then we produce a "parallel sequence" of programs Psu, P4u by applying the simulta- 
neous replacement operation, miming, to some extent, the original transformation. 
By applying Theorem 16 we will show that Fit(P2~) = Fit(Psi) = Fit(P4~). 
Finally we show that programs P~u and P4u are obtainable respectively from P3 
and P4 by appropriately applying the unfold operation, and hence, by Corollary 12, 
that Fit(Ps) = Fit(Psi) and that Fit(P4) = Fit(P4,). This will end the proof. Fig.1 
illustrates both the original transformation and its parallel sequence. 
Initial program. Let us establish some notation: P1... P4 are the programs ob- 
tained by applying the four step schema to program P, and co : H *-- B. is the 
(only) clause added to program P in Step 1. We also denote by tb the set of the local 
variables of ci, z5 = Var(B)\Yar(H). For the moment, let us make the following 
restriction: 
- till the end of 4.3, we assume that/3 doesn't contain negative literals. 
Later, in subsection 4.4, we will prove the general case. 
A simple consequence of the fact that co is the only clause defining the predicate 
symbol of H is the following. 
Observation 20 
- H ~p~ 
3(v [~; 
[] 
P2 and P2~- P2 is obtained by unf(~lding some of the atoms in/~, so/)2 = P tA {Ai ,-- 
Ui, Ni}, where the atoms in Ni are those that have not been unfolded during Step 1 
(N stands for Not unfolded, while U for Unfolded), so/V/is equal to a subset of an 
instance of/3 and each Ai is an instance of H. We obtain P2u from P2 by further 

326 
unfolding all the atoms in each ~'~. We denote by {eij : (Ai ~-~7i)Tij,/)ij} 
the 
J 
. 
i 
set of clauses of P2u obtained from clause cl by unfolding the atoms in Ni. By the 
correctness of the unfolding operation, Corollary 12, we have that 
Fit(P,) = Fit(Pz) = Fit(P2u) 
(2) 
Pt = P U Ddef 
where Ddef = {co : H ~-- B} 
P2 = P U Dunf 
where Dunf = {ci : Ai ,-- (Ji, Ni} 
9 
P2u = PU DunJ. 
c' 
(A, 
O,)'ri,j, b,, A 
where Du,~l. = { i,j : 
~-- 
P3 = P U Dfold 
~ 
where Dfold = {c~ : Ai ~-- U[, Ni} 
9 ' 
' 
P3u = PUDlold* 
e' 
(Ai ~- -' 
9 
where Dlozd. = { i,j : 
U~)7iz, 1)i,j ) 
P4 -7- Pfold U Dfold 
where Dfold = { c~ : Ai *-- U~ , Ni } 
9 P4~ = Pfotd U Dlota.. 
where D.toZd,. -- {c~j: (Ai ~-U/t)Tij, D;j) 
Fig. 1. Diagram of the transformation (left) together with the "parallel sequence" 
(right). 
Moreover, the following properties hold: 
Observation 21 
- H is not-slower than ]ffJ B in P2,. 
Proof. From Observation 20 we have that H "~el 3t5/3. The first statement follows 
then from (2) and Proposition 19. For the second, fix 0 and let fl be the least ordinal 
such that 3~/~0 is true (or false) in ~t~. The clauses defining the atoms in /~ 
are the same in P1, P2 and P2~, so S~/~ is true (resp. false) in ~ta 
pa as well. From 

327 
condition A and Proposition 18 we have that /3 is a non-limit ordinal. Hence, by 
the definition of r H0 is true (resp. false) in ~T#+I and, by Lemma 13 H9 is true 
(resp. false) in ~T~. 
n 
P3 and Psi" Ps~ is obtained from P~ as follows. 
Suppose that in Step 2 we performed a recursive folding on the clause cl : 
Ai ,--/30./~/', Ni of P~, obtaining c~ : Ai +--- HO, Ri, Ni in Ps. In the diagram we de- 
note by U[ the conjunction of liter Ms resulting from the application of the recursive 
folding on the conjunction Ui (so Ui = BO, R~ and b'/' = Ha,/~i). 
On P~u we then perform the following. In each of the clauses ci,j we transform 
UiTi,j into U~Ti,j by replacing conjunctions of literals of the form BOTi,j with HOTi,j 
wherever needed; we call the resulting clauses c~j. It is easy to see that if we unfold 
all the atoms in Ni in the body of clause c~ in Ps, then the resulting clauses are 
exactly the c~j in Psu; this is best shown by the diagram. Hence P3u is obtainable 
from P3 by appropriately applying the unfolding operation. From Corollary 12 it 
follows that 
Fit(P3) = rit(P3u) 
(3) 
Now we show that Fit(P2u) = Fit(Psi). First we need the following. 
Proposition22. Let Q be a program, A, B be atoms and ~ be a set of variables, 
such thai A .-.Q 3~I B. Suppose also that 0 is a renaming over ~ and thai for each 
variable z that occurs in A or B, but not in ~1, Var(zrl) N Var(~p?) = O. Then 
- A~ ~Q 3(9rl) B, 
Proof. Straightforward. 
O 
Since 7ij results from unfolding the atoms in Ni, we have that Dom(Tij) f~ Var(ci) 
C Var(Ni). Hence, by the conditions on 0 in Step 2, Dorn(Ti,j ) N~0 = 0 and 
(vOTi,j = ~0; so 07i,j is a renaming over ~, and the variables in (oO"[i,j do not occur 
anywhere else in cij. From Observation 21 and Proposition 22 we have that 
-- H OTi,J "~P2. 3(wOTi,j ) ff~O~'i,j ; 
-- HO"[i,j is not-slower than 3(wO~[i,j) BO'Ti,j in P~u. 
Since we obtained Pzu from P2u by simultaneously replacing conjunctions (of the 
form) [~07i,j with HOTi,j , by Theorem 16 
Fit(P2u) = Fit(Psu). 
(4) 
Moreover, the following properties hold: 
Observation g3 
- 
H 
~'~u 
3~ B; 
- 
H is not-slower than 3ff~ B in P3u. 
Proof. The first statement follows from Observation 21, (4) and Proposition 19. For 
the second first note that going from P~ to P3, we have affected only clauses that 
define the predicate new, moreover no other predicates definition depends on these 
clauses, in particular the atoms in /3 are independent from them, hence, since H is 
not-slower than 3~/3 in P2~, the statement follows from Proposition 17. 
o 

328 
/'4 and P4u. P4 is obtained from Ps by transforming some of the clauses of P of 
the form A ,---/30, s into A *--- HO, E. 
Now we want to obtain P4u from P3u in such a way that P4u is obtainable also 
from P4 by unfolding the atoms in the conjunctions Ni. 
Let d : A *---BO, E be one of the clauses of P3 that are transformed in Step 1. 
First note that d belongs both to P3 and P3~, in fact d was already present it the 
original program P, and never modified. We can then apply the same operations 
to the clauses of P3u. Observe that for the conditions on 0 given in Step 1, and by 
Observation 23 we have that 
Observalion 24 
- 
HO "m. 
3(~o) [~o 
- HO is not-slower than 3(COO) [30 in P3u 
[] 
Second, notice that in case that d was used as unfolding clause for going from P2 
to P2", then some instances of/30 were propagated into P3u. Using the notation of 
the diagram, this is the case when some/7/(in P2) is of the form #,~i where A and 
A' are unifiable atoms, then one of the/)ij (in P2u) is of the form Did = (B, ff'i)O'. 
" 
= HO ~, Fi, that has HO ~ instead 
However, if we unfold Ni in s 
what we get is Di, j 
of/30 ~. By the same argument used for 07i,j in 4.3, we have that 
Observation 25 
- 
HO' "Pa. B(~O') /30' 
- HO' is not-slower than 3(CvO') BO' in P3~ 
So in order to obtain P4u from P3u we have then to do two things: First, replace 
/30, with the corresponding HO in all the clauses d that are transformed in Step 4. 
-i 
Second, replace/30' with HO' in the/)i,j so that P4u contains Dij instead of Dij. 
This tantamounts to the application of a simultaneous replacement. 
From Observations 24 and 25, and Theorem 16 we have that 
Fit(P3u) = Fit(P4,) 
(5) 
Moreover P4u is obtainable from *~ by unfolding all the atoms in the conjunctions 
N/ in the clauses where they occur. Hence 
Fit(P4) = Fit(P4u). 
(6) 
So far, because of (1), (2), (3), (4) and (5), we have the following 
Propositlon26. If condition A holds and [~ does not contain negative literals, then 
- Fit(P1) = Fit(P2) = Fit(Ps) = Fit(P4) 
[] 

329 
4.4 
The general case 
We can finally prove Theorem 6. Let us state it again. 
Theorem 6. Let P1,..., P4 be a sequence of programs obtained applying the trans- 
formation schema to program P, Let also Ddef= {Hi ~-- [31} be the set of clauses 
introduced in Step 1, and, for each i, ff~i be the set of local variables of el: ~)i -= 
Var([3i)\Var(Hi). If each ci in Ddef satisfies the following condition: 
A each time that 3(vi BiO is false in some r 
then there exists a non-limit ordinal 
Pt t 
a <_ 13 such that 3ff)i [~iO is false in r 
Then Fit(P1) = Fit(P~) = Fit(Pz) = Fit(P4). 
Proof. We consider here the simplified case in which Step 1 introduces only one 
clause which in turn contains only one negative literal in the body, i.e. Ddef = 
{co : H ~-- -,l(~),/~'}. The generalization to the case of multiple clauses and multiple 
negative literals is straightforward and omitted here. Notice that if co contained no 
negative literals, then the result would following directly from Proposition 26. 
We now perform a double transformation on PI: first, we enlarge it with the 
following new definition: d : notl(~l) ~-,l(~); then, we replace each instance -~l(t) 
of l(~) that occurs in the body of a clause with the corresponding instance notl(~ 
of notl(~t). This replacement operation clearly preserves Fitting's model of the pro- 
grams, in fact it can be undone by unfolding. Let us call P~ the program so obtained. 
We have that 
Fit(P1) = Fit(P~)[Be, 
(7) 
Where Fit(P~)lBp, denotes the restriction of Fit(P~) to the atoms in the Herbrand 
base of P1. 
Now P~ contains, instead of clause e0, the following: C'o = H *-- notl(O), [~'. which 
is a definite clause. 
Now notice that, since the unfold operation is defined only for positive literals, 
then -~l(~)) is never unfolded in the transformation P1...P4. It follows that, by 
performing the same operations used for going from Px to P4, we can obtain another 
"parallel sequence" P~... P~ that starts with program P~. By the same arguments 
used to prove (7), we have that, for i E [1... 4], 
Fit(P,) = rlt(P')lBp, 
(8) 
Moreover, by Proposition 26, 
Fit(P~) = Fit(P~) = Fit(P~) = Fit(P~) 
(9) 
From (8) and (9) the thesis follows. 
[] 

330 
References 
1. K. R. Apt. Introduction to Logic Programming. In J. van Leeuwen, editor, Handbook 
of Theoretical Computer Science, volume B: Formal Models and Semantics. Elsevier, 
Amsterdam and The MIT Press, Cambridge, 1990. 
2. L. Aiello, G. Attardi, and G. Prini. Towards a more declarative programming style. 
In E. J. Neuhold, editor, Proceedings of the IFIP Conference on Formal Description of 
Programming Concepts, pages 121-137. North-Holland, 1978. 
3. C. Aravidan and P. M. Dung. Partial deduction of logic programs w.r.t, well-founded 
semantics. In H. Kirchner G. Levi, editor, Proceedings o/the Third International Con- 
]erence on Algebraic and Logic Programming, pages 384-402. Springer-Verlag, 1992. 
4. C. Aravidan and P. M. Dung. On the correctness of Unfold/Fold transformation of 
normal and extended logic programs. Technical report, Division of Computer Science, 
Asian Institute of Technology, Bangkok, ThaMand, April 1993. 
5. A. Bossi and N. Cocco. Basic Transformation Operations which preserve Computed 
Answer Substitutions of Logic Programs. Journal o/Logic Programming, 16(1/2):47- 
87, 1993. 
6. A. Bossi, N. Cocco, and S. Etalle. Transforming Normal Programs by Replacement. In 
A. Pettorossi, editor, Meta Programming in Logic - Proceedings META '9~, volume 649 
of Lecture Notes in Computer Science, pages 265-279. Springer-Verlag, Berlin, 1992. 
7. A. Bossi, N. Cocco, and S. Etalle. 
Simultaneous replacement in normal programs. 
Technical Report CS-R9357, CWI, Centre for Mathematics and Computer Science, 
Amsterdam~ The Netherlands, August 1993. Available via anonymous ftp at ftp.cwi.nl, 
or via xmosaic at http://www.cwi.nl/cwi/publications/index.html. 
8. R.M. Burstall and J. Darlington. A transformation system for developing recursive 
programs. Journal of the ACM, 24(1):44-67, January 1977. 
9. K. L. Clark. Negation as failure rule. In H. Gallaire and G. Minker, editors, Logic and 
Data Bases, pages 293-322. Plenum Press, 1978. 
10. K.L. Clark and S. Sickel. Predicate logic: a calculus for deriving programs. In Proceed- 
ings of IJCAI'77, pages 419-120, 1977. 
11. M. Fitting. A Kripke-Kleene semantics for Logic Programs. Journal of Logic Program- 
ming, 2(4):295-312, 1985. 
12. P.A. Gardner and J.C. Shepherdson. Unfold/fold transformations of logic programs. 
In J-L Lassez and editor G. Plotkin, editors, Computational Logic: Essays in Honor o/ 
Alan Robinson. 1991. 
13. C.J. Hogger. Derivation of logic programs. Journal of the ACM, 28(2):372-392, April 
1981. 
14. T. Kawamura and T. Kanamori. Preservation of Stronger Equivalence in Unfold/Fold 
Logic Programming Transformation. Theoretical Computer Science, 75(1/2):139-156, 
1990. 
15. S.C. Kleene. Introduction to Metamathematics. 
D. van Nostrand, Princeton, New 
Jersey, 1952. 
16. H.J. Komorowski. Partial evaluation as a means for inferencing data structures in 
an applicative language: A theory and implementation in the case of Prolog. In Ninth 
A CM Symposium on Principles of Programming Languages, Albuquerque, New Mexico, 
pages 255-267~ 1982. 
17. J. W. Lloyd. Foundations of Logic Programming. Springer-Verlag, Berlin, 1987. Sec- 
ond edition. 
18. J. W. Lloyd and J. C. Shepherdson. Partial Evaluation in Logic Programming. Journal 
of Logic Programming, 11:217-242, 1991. 

331 
19. M.J. Maher. Correctness of a logic program transformation system. IBM Research 
Report RC13496, T.J. Watson Research Center, 1987. 
20. M. Proietti and A. Pettorossi. Unfolding, definition, folding, in this order for avoid- 
ing unnecessary variables in logic programs. In Maluszynski and M. Wirsing, editors, 
PLILP 91, Passau, Germany (Lecture Notes in Computer Science, Vol.5~8), pages 
347-358. Springer-Verlag, 1991. 
21. T. Sato. Equivalence-preserving first-order unfold/fold transformation system. Theo- 
retical Computer Science, 105(1):57-84, 1992. 
22. H. Seki. Unfold/fold transformation of stratified programs. In G. Levi and M. Martelli, 
editors, 6th International Conference on Logic Programming, pages 554-568. The MIT 
Press, 1989. 
23. H. Seki. A comparative study of the Well-Founded and Stable model semantics: Trans- 
formation's viewpoint. In D. Pedreschi W. Marek, A. Nerode and V.S. Subrahmanian, 
editors, Workshop on Logic Programming and Non-Monotonic Logic, Austin, Texas, 
October 1990, pages 115-123, 1990. 
24. H. Seki. Unfold/fold transformation of stratified programs. Theoretical Computer Sci- 
ence, 86(1):107-139, 1991. 
25. H. Seki. Unfold/fold transformation of general logic programs for the Well-Founded 
semantics. Journal o] Logic Programming, 16(1/2):5-23, 1993. 
26. H. Tamaki and T. Sato. Unfold/Fold Transformations of Logic Programs. In Sten- 
Ake T~rnlund, editor, Proc. Second Int'l Conf. on Logic Programming, pages 127-139, 
1984. 

Formal Semantics of 
Temporal Epistemic Reflection + 
Wiebe van der Hoek a,b 
John-Jules Meyer a,b 
Jan Treur b 
a Utrecht University, Department of Computer Science 
P.O. Box 80.089, 3508 TB Utrecht, The Netherlands. 
Email: { wiebe,jj }@cs.ruu.nl 
b Free University Amsterdam, Department of Mathematic s and Computer Science 
De Boelelaan 1081a, 1081 HV Amsterdam, The Netherlands. 
Email: treur@cs.vu.nl. 
Abstract 
In this paper we show how a formal semantics can be given to reasoning processes in 
meta-level architectures that reason about (object level) knowledge states and 
changes of them. Especially the attention is focused on the upward and downward 
reflections in these architectures. Temporalized epistemic logic is used to specify 
meta-level reasoning processes and the outcomes of these. 
1 Introduction 
Meta-level architectures often are used either to model dynamic control of the object 
level inferences, or to extend the inference relation of the object level. In [Tre92] we 
introduced formal semantics for meta-level architectures of the first kind based on 
temporal models. It may be considered quite natural that for such a dynamic type of 
reasoning system the temporal element of the reasoning should be made explicit in the 
formal sem~mtics. For the use of meta-level architectures to extend the object level 
inference relation the situation looks different. In principle one may work out formal 
semantics in terms of (the logic behind) this extended, non-classical inference relation; 
e.g., as in the literature for nonmonotonic logics. However, much discussion is 
possible about this case. Some papers argue that also in the case of a non,monotonic 
logic the semantics have to make the inherent temporal element explicit; approaches 
are described in, e.g., [Gab82], [ET93]. In the current paper we adopt this line. 
In principle a downward reflection that extends the inference relation of the object 
level theory disturbs the (classical) object level semantics: facts (assumptions) are 
added that ,are not logically entailed by the available object level knowledge. Adding a 
tempor,'d dimension (in the spirit of [FG92]) enables one to obtain formal semantics 
+ This work is partially supported by ESPRIT III Basic Research Action 6156 (DRUMS II). 

333 
of downward reflection in a dynamic sense: as a transition from the current object level 
theory to a next one (where the reflected assumption has been added). 
In [MH93a] a metaphor of a meta-level architecture was exploited to define a 
nonmonotonic logic, called Epistemic Default Logic. It was shown how upward 
reflection can be formalized by a nonmonotonic entailment relation based on epistemic 
states (according to [HM84]), and the meta-level reasoning process by a (monotonic) 
epistemic logic. Compared to a meta-level architecture, what was still missing was a 
formalization of the step where the conclusions of the meta-level actually were used to 
change the object level, i.e., where formulas q~ are added to the object level knowledge, 
in order to be able to reason further with them at the object level. This should be 
achieved by the downward reflection step. In the current paper we introduce a 
formalization of this downward reflection step in the reasoning pattern as well. We 
formalize the semantics of the architecture by means of entailment on the basis of 
temporalized Kripke models. Thus, a formalization is obtained of the reasoning pattern 
as a whole, consisting of a process of generating possible default assumptions by 
meta-level reasoning and actually assuming them by downward reflection (a similar 
pattern as generated by the so-called BMS-architecture introduced in [1q91]). 
The temporal epistemic meta-level architecture described here is a powerful tool to 
reason with dynamic assumptions: it enables one to introduce and retract additional 
assumptions during the reasoning, on the basis of explicit epistemic information on 
the current knowledge state and meta-knowledge to determine adequate additional 
assumptions. This covers a whole class of reasoning patterns of meta-level 
architectures; we call them temporal epistemic meta-level architectures (TEMA). In 
such an architecture upward reflection is restricted to the transfer to the meta-level of 
epistemic information: information about what currently is known and what is not 
known at the object level, and downward reflection is restricted to introducing 
additional information (assumptions) to the object level, based on the conclusions 
derived at the meta-level. In this architecture a number of interesting reasoning 
patterns can be formalized in temporal semantics in a quite intuitive and transparent 
manner. In [Tre90], [Tre91] various applications of the architecture are shown, 
including: hypothetical reasoning, the method of indirect proof, reasoning about 
knowledge, reasoning about actions integrated with executing them. 
The formalization of downward reflection was inspired by [Tre92], where it is 
pointed out how temporal models can provide an adequate semantics of meta-level 
architectures for dynamic control, and [ET93] where similar ideas have been worked 
out to obtain a linear time temporal semantics for default logic. The general idea is 
that conclusions derived at the meta-level essentially are statements about the state of 
the object level reasoning at the next moment of time. Thus, downward reflection is a 
shift of time in a (reasoning) process that is described by temporal logic. 
To get the idea we will use the following informal description of an example 
reasoning pattern, involving diagnostics (of a car that cannot start) by elimination of 
hypotheses (for a more extensive description, see [Tre90]). Later on (in Section 7.3) 
we will come back to this example to show how it can be formalized by our approach. 
Suppose at the object level we have the following (causal) knowledge about a car: 

334 
9 
if the battery is empty 
then the lights cannot burn 
9 
if the battery is empty, or the sparking-plugs are tuned up badly 
then the car does not start 
9 
the car does not start 
At the meta-level we control a diagnostic reasoning process to find out whether it can 
be excluded that an empty battery is the cause of the problems (the only hypothesis 
that we fully consider in this example). To this end we have the following (simplified) 
meta-knowledge that enables to propose hypotheses for elimination, and to reject them 
if indeed they turn out to fail: 
9 
if it is known that the car does not start 
and it is not known whether the hypothesis "the battery is empty" holds 
then "the battery is empty" is an adequate hypothesis to focus on 
9 
if it is known that the car does not start 
and it is known that the hypothesis "the battery is empty" does not hold 
and it is not known whether the hypothesis 
"the sparking-plugs are tuned up badly" holds 
then "the sparking-plugs are tuned up badly" is an adequate hypothesis to focus on 
* 
if we have focused on a hypothesis X 
and assuming X we have derived that the observable Y should be the case 
and it has been observed that Y is not the case, 
then our hypothesis X should be rejected 
9 
it has been observed that the lights can burn 
Using these two knowledge bases in a temporal epistemic meta-level architecture we 
can perform the following dynamic reasoning pattern: 
1. 
2. 
3. 
4. 
5. 
6. 
7. 
8. 
9. 
Draw all conclusions that are possible at the object-level 
Reflect upwards that at the object level it is not known whether the battery is empty 
Draw the conclusion at the meta-level that 'battery is empty' is an adequate 
hypothesis to focus on 
Reflect this hypothesis downward: introduce it at the object level as additional 
information (assumption) 
Draw the conclusion at the object level that the lights cannot burn 
Reflect upwards the information that at the object level it has been found that the 
lights cannot burn 
Use the observation at the recta-level that the lights can burn, and notice the 
contradictory situation 
At the recta-level draw the conclusion that the focus hypothesis 'battery is empty' 
should be rejected 
Reflect downwards that 'battery is empty' is considered to be not true. 
This example shows some of the possibilities of temporal epistemic reflections. 
Notice especially the manner in which we treat epistemic states and additional 

335 
information in a dynamic manner. This implies that during the reasoning the (states 
of) object level and meta-level both change in (reasoning) time; temporal logic is 
exploited to describe these changes in a logical manner. 
Our approach provides a formalization of upward reflection by a nonmonotonic 
entailment relation based on epistemic states and downward reflection by an entailment 
relation based on temporal models. As in the literature reflections usually either are 
kept rather restricted (and static), or are described in a procedural or syntactic manner 
(e.g., by means of gene.ralized inference rules; see [GTG93]), the novelty of our 
approach is that it introduces a semantic formalization for reflections involving 
epistemic and temporal aspects. 
In this paper in Section 2 the basic notions of epistemic logic are presented. In 
Section 3 we do the same for temporal logic and the notion of temporalization of a 
logic system. In Section 4 we show how upward reflection can be formalized based on 
epistemic states. In Section 5 we introduce the logic used to formalize the meta-level 
reasoning: S5P*. In Section 6 we define a labelled branching time temporal 
formalization of downward reflection. In Section 7 we show how the overall 
formalization can be obtained from its parts and how it works for the running example 
reasoning pattern. In Section 8 we draw some conclusions. In this version, proofs are 
omitted; they can be found in the full paper [HMT94b]. 
2 
Basic notions and properties of Epistemic Logic 
2.1 Epistemic Logic 
2.1. DEFINITION (epistemic formulas). Let P be a set of propositional constants 
(atoms); P = {Pk [ k ~ I}, where I is either a finite or countably infinite set. The set 
FORM of epistemic formulas (p, t~ .... is the smallest set containing P, closed under 
the classical propositional connectives and the epistemic operator K, where K(p means 
that (p is known. An objective formula is a formula without any occurrences of the 
modal operator K. For F c FORM, we denote by Prop(F) the set of objective 
formulas in F. 
2.2. DEFINITION (S5-Kripke models). An S5-model is a structure M = (M, rt) where 
M is a non-empty set, ~ is a truth assignment function of type M --~ (P --~ {~, f}) 
such that for all ml, m 2 ~ M: n(ml) = re(m2) ~ m I = m 2. The class of S5-models 
is denoted by Mod(S5). 
The set of states in an S5-model represents a collection of alternative states that are 
considered (equally) possible on the basis of (lack of) knowledge. We shall use S5- 
models as representations of the knowledge of agents. 
2.3 REMARK For any m ~ M, the function 7t(m): p ~ rffm)(p) is a valuation. Since 
we have that in an S5-model it holds that n(ml) = 7t(m2) r 
m I = m2, we may identify 
states m with their valuations ~(m), and write m - re(m) for m ~ M. So, without 
loss of generality, we may consider S5-models of the form M = (M, r 0 with M c W. 

336 
2.4. DEFINITION (submodels and union of S5-models). We define a subset relation on 
S5-models by: M 1 c M 2 iff M 1 c_ M 2. Moreover, if MI= (M1, Trl) and 
M 2 = (M2, rr2) are two S5-models, their union is defined as: M 1 u M 2 = (M, 7r), 
where M = M 1 u M 2 and 7t(m) = hi(m) if m ~ M i, i = 1, 2. 
2.5. DEFINITION (interpretation of epistemic formulas). Given M = (M, n), we define 
the relation (M, m) ~ tp by induction on the structure of the epistemic formula tp: 
(M, m) ~ p 
r 
n(m)(p) = t for p ~ P 
(M, m) ~ ~p A V 
r 
(M, m) ~ 9 and (M, m) ~ ~g 
(M, m) ~ ~cp 
r 
(M, m) ~ ~p 
(M, m) ~ Kcp 
r 
(M, m') ~ cp for all m' ~ M 
2.6. DEFINITION (validity). 
i 
tp is valid in M = (M, re), denoted M ~ tp, if for all m ~ M: (M, m) ~ cp. 
ii 
tp is valid, notation Mod(S5) ~ tp, if M ~ tp for all S5-models M. 
Validity w.r,t. S5-models can be axiomatized by the system S5: 
2.7. DEFINITION (system $5). The logic $5 consists of the following: 
Axioms: 
(AI) 
All propositional tautologies 
(A2) 
(Ktp A K(tp ---) ~)) --) K~ 
Knowledge is closed under logical consequence. 
(A3) Kcp --) tp 
Known facts are true. 
(A4) 
Ktp ---) KKtp 
An agent knows that he knows something. 
(A5) 
--d(tp ---) K---d(cp 
An agent knows that he does not know something. 
Derivation rules: 
(R1) 
~- tp, ~- ~ --~ ~ ~ F- ~ 
Modus Ponens 
(R2) 
F- cp ~ ~- K~p 
Necessitation 
That tp is a theorem derived by the system S5 is denoted by $5 ~- tp. 
2.8. THEOREM (Soundness and completeness of S5). $5 ~- tp r 
Mod(S5) ~ tp 
2.2 Epistemic States and Stable Sets 
In this paper we simply define an epistemic state as an S5-model: 
2.9. DEFINITION. An epistemic state is an S5-model M = (M, 7t). The set M is the 
set of epistemic alternatives allowed by the epistemic state M. 
2.10. DEFINITION. let M be an $5 model. Then K(M) is the set of facts known in 
M: K(M) = {tp [M ~ Kq)}. We call K(M) the theory of M or knowledge in M. 
We mention here that the knowledge in M are exactly the validities in M (Cf. 
[MH94]), i.e. we have K(M) = {~ ]M ~ K~p} = {tp [M ~ q~}. 

337 
2.11. LEMMA. For any $5 models M 1 and I~2: 
i 
If M1 c M2 then Prop(K(IVI2) ) c_ Prop(K(M1) ). 
ii 
If the set of atoms P is finite, then also 
Prop(K(M2) ) c Prop(K(M1)) ~ M1 c M2. 
2.12. PROPOSITION (Moore [Moo85]). 
i 
The theory ~ = K(M) of an epistemic state M is a so-called stable set, i.e., 
satisfies the following properties: 
(St 1) 
all instances of propositional tautologies are elements of E; 
(St 2) 
if tp ~ E and tp -4 ~ ~ E then ~ ~ E; 
(St3) 
tp e Ec~Ktp ~ Z 
(St 4) 
tp ~ E r 
-4(q~ ~ E 
(St 5) 
E is propositionally consistent. 
ii 
Every stable set E of epistemic formulas determines an S5-Kripke model M E 
for which it holds that E = K(ME). Moreover, if P is a finite set, then M E is 
the unique S5-Kripke model with this property. 
2.13. PROPOSITION. A stable set is uniquely determined by its objective formulas. 
3 Basic notions and properties of Temporal Logic 
We start (following [FG92]) by defining the temporalized models associated to any 
class of models and apply it to the classes of models as previously discussed. In 
contrast to the reference as mentioned we use labelled flows of time. We use one fixed 
set L of labels, viz. L = 2 I, the powerset of some index set I. However, in most 
definitions we do not use this fact, but only refer to (elements x of) L. 
3.1 Flows of time 
3.1. DEFINITION (discrete labelled flow of time). 
Suppose L is a set of labels. A (discrete) labelled flow of time (or lft), labelled by L 
is a pair T = (T, (<x)z ~ L) consisting of a non-empty set T of time points and a 
collection of binary relations <z on T. Here for s, t in T and z in L the expression 
s <x t denotes that t is a (immediate) successor of s with respect to an arc labelled by 
"~. Sometimes it is convenient to leave the indices out of consideration and use just 
the binary relation s < t denoting that s <x t for some x (for some label "c they are 
connected). Thus we have that < = ux <x. We also use the (non-reflexive) transitive 
closure ~ of this binary relation: ~ = <+. 
We will make additional assumptions on the flow of time; for instance that it 
describes a discrete tree structure, with one root and where time branches in the 
direction of the future. 
3.2. DEFINITION (labelled time tree) 
An lft T = (T, (<x)x e L) is called a labelled time tree (ltt) if the following conditions 
are satisfied (recall that < = ux <x): 
i 
the graph (T,<) is a directed rooted tree. 

338 
ii 
Successor existence: Time points have at least one <-successor. 
iii Label-deterministic: For every label x there is at most one x-successor. 
3.3. DEFINITION (branch and path) 
a A branch in an lft T is an lfl B = (T', (<'x)x ~ L) with (i) T' c T, (ii) s <'x t 
s <x t, (iii) every s e T' has at most one <'-successor t ~ T', (iv) for all s, t ~ T': 
s <z t ~ s <"c t, and (v) every element of T that is in between elements of T' is 
itself in T': for all s' ~ T', t e T, u' ~ T' : s' ,, t ,, u' ~ t e T'. 
b 
A branch in an ltt T = (T,(<x)x e L) is maximal if contains the root r of T. 
c Apath is a finite sequence of successors: so, 9 ..... s n such that: si < Si+l for all 0 
< i < n-1. We call so the starting point and s n the end point of the path. 
3.4. PROPOSITION Any branch of an lft T is an ltt. 
3.5. DEFINITION (time stamps). Given an ltt (T, (<x)x ~ L). A mapping ['l : T ~ lq is 
called a time stamp mapping if for the root r it holds that Irl = 0, and for all time 
points s, t it holds s < t ~ 
[tl = Isl + 1. 
3.2 Temporal models 
We first define our temporal formulas: 
3.6. DEFINITION (temporal formulas). 
Given a logic L, temporal formulas over (the language of) L are defined as follows: 
i 
if tO is a formula of L then CtO is a temporal formula (also called a temporal atom) 
ii 
if tO and ~ are temporal formulas, then so are: 
~tO, to A ~, to ---) q~, X3,xto, X3to, Xv,zto, XVtO, F3tO, FVtO, G3tO, GVto. 
Note how the C-operator acts as a kind of 'separator' between the basic language for L 
and the actual temporal formulas: from the temporal language point of view, formulas 
of the form CtO may be conceived as a kind of 'atoms'; in the truth-definition, 
occurrences of the C enforce a 'shift' in the evaluation of formulas, taking us from a 
temporal model M to some of it snapshots M__t, which are in their turn models for L: 
3.7. DEFINITION (temporal models) 
a 
Let MOD be a class of models, and T = (T, (<z)~ e L) a labelled flow of time. A 
temporal MOD-model over T is a mapping M: T ---> MOD. For t ~ T we 
sometimes denote I~(t) (the snapshot at time point t) by M..M_ t. 
b 
If we apply a) to the classes of models ModSet(PC) or Mod(SS) we call these 
temporalized models temporal valuation-set-models (abbreviated temporal V- 
models) and temporal S5-models over T, respectively. Similarly for the class of 
S5P*-models that will be introduced in Section 5. 
c 
Given an lft T, the temporal formulas are interpreted on MOD-models as follows: 
i 
Conjunction and implication are defined as usual; moreover 
]~ s ~ ~to iff not ~ 
s ~ tO; 
ii The temporal operators are interpreted as follows: 

339 
1) Cq~ means that in the current state tp is true, i.e. 
~d[, s ~ Ctp iff~d[s ~ tp 
2) X3,xt p means that tp is true in some x-successor state i.e., 
M.~ s ~ X3,xt p iff there exists a time point t with s <x t such that M__, t ~ cp 
3) X3tP means that there is a x with some x-successor in which 9 is true. 
s ~ X3t p iff there exists a time point t with s < t such that ~ 
t ~ tp 
4) Xv,ztp, meaning that cp is true in all x-successor states, i.e., 
M, s ~ Xv,xt p iff for all time points t with s <x t it holds ~ 
t ~ tp 
5) XVtp means that tp is true in all immediate successors: 
s ~ XV9 iff for all time points t with s < t it holds ~ 
t ~ tp 
6) F3c p means that tp is true in some future state, i.e., 
~_, s ~ F3t p iff there exists a time point t with s << t such that M__, t ~ tp 
7) FvtP, means that for all future paths there is a time point where tp is true: 
s ~ FVt p iff for all branches ~. starting in s there is a t in B__with I~ t ~ tp 
8) G3t p means that tp is true along some future path, i.e., 
s ~ G3t p iff there exists a branch B starting in s, 
with ~ 
t ~ tp for all t in B. 
9) GvtP, means that tp is true all future states i.e. 
s ~ GVt p iff for all time points t with s ,~ t it holds M__, t ~ tp. 
4 Formalizing Upward Reflection Using Epistemic States 
In order to let the meta-level manipulate the information that is (explicitly or 
implicitly) encoded at the object-level, somehow it has to be reflected upward what is 
known at the object-level, and what is not. The former, i.e. to reflect upward what is 
known, is straightforward: if an objective formula tp is true at the object-level, we 
simply reflect this as Kip being true. More interestingly, we also want to reflect 
upward those facts that are (currently) not known at the object level. Moreover, we 
somehow want to implement the idea that the facts that are true at the object level is 
all that is known at the current time point. 
The converse relation of c on Kripke models (Cf. Definition 2.4), will play an 
important role in the sequel. M 1 _D M 2 means that the model M2, viewed as a 
representation of the knowledge of an agent, involves a refinement of the knowledge 
associated with model M 1. This has to be understood as follows: in the model M 2 
less (or the same) states are considered possible by the agent as compared by the model 
I~ 1. So, in the former case the agent has less doubts about the true nature of the 
world. It will turn out that our definitions below will work in such a way that this 
means that with respect to model M 2 the agent has at least the knowledge associated 
with model MI, and possibly more. So in a transition of M 1 to M 2 we may say that 
knowledge is gained by the agent. Thus the relation 'D' acts as an knowledge ordering 
on the set of S5-models. 
We already noted in Section 2, that the set of states in an S5-model represents the 
states that are considered possible on the basis of (lack of) knowledge). We also 
mentioned, that the validities of such a model exactly determine what was called an 

340 
epistemic state. On the basis of such epistemic states, Halpern & Moses define an 
entailment relation ~" with which one can infer what is known, and, more 
importantly, what is unknown in such epistemic states. 
4.1. DEFINITION. Given a set M c_ W, we define the associated S5-model ~(M), 
given by O(M) = (M, ~) with n: M x P ~ {t, f} such that n: (m, p) ~ m(p). 
4.2. DEFINITION. Given some objective formula to, we define Mto as the set of 
valuations satisfying to, i.e., M~7 {m e W I m ~ to}. We denote the epistemic state 
O(Mcp ) associated with Mtp by vatp. 
4.3. PROPOSITION. Mtp = (J {M I M ~ to} = O {M I M ~ Kto}. 
Thus, in order to get Mtp, we can consider all S5-models of to and take their union to 
obtain one 'big' S5-model. We denote the mapping to 
Mcp by B: B(to) = M~0. 
4.4. DEFINITION (Nonmonotonic epistemic entailment). 
For to ~ Prop(FORM), and HI ~ FORM: to ~" ~ r uj ~ K(Mq0 ). 
Informally, this means that ~ is entailed by to, if qJ is contained in the theory 
(knowledge) of the "largest S5-model" Mtp of to. Halpern & Moses showed in [HM84] 
that this "largest model" need not always be a model of to itself if we allow to to 
contain epistemic operators. However, in our case where we only use objective 
formulas to, Mcp is always the largest model for t 0. Moreover, Halpern & Moses have 
shown that in this case the theory K(M~p) of this largest model is a stable set that 
contains to and such that for all stable sets E containing to it holds that Prop(K(M~0)) 
_ 
Prop(E), thus K(Mq~) is the proposltlonally least stable set that contains to. So 
~" can also be viewed as a preferential entailment relation in the sense of Shoham 
[Sho88], where, in our paper, the preferred models of to are the largest ones, viz. M~p, 
where the least objective knowledge is available. 
We denote the mapping to ~ K(Mq~) by K: ~:(to) = K(M0, ), the stable set associated 
with knowing only to. Alternatively viewed, ~c(to) is the ~-'-closure of to. Note that 
since ~c(to) = K(M~p) is a stable set, it is also propositionally closed. We now give a 
few examples to show how the entailment ~" works: Let p and q be two distinct 
primitive propositions. Then: 
p ~' K(p v q) 
p ~-" Kp ^ --dfq 
p ^ q ~" K(p /,, q) ,,, Kp ^ Kq 
pvqFK(pvq) 
p ~ -dCq 
p ~ --df-~q 
p ~ --dC(p ^ q) 
p v q ~ -arfp ^ -4r 
Obviously, the entailment relation ~'- is nonmonotonic; for instance, we have 
p ~-- ---d~q, while not p ^ q ~" ~Kq; it even holds that p ^ q ~" Kq. 

341 
5 The Meta-level: The Epistemic Preference Logic SSP* 
The "upward reflection" entailment relation ~ enables us to derive information about 
what is known and what is not known. In this section we show how we can use this 
information to perform meta-level reasoning. To this end we extend our language with 
operators that indicate that something is a possible assumption to be introduced at the 
object level and thus has a different epistemic status than a certain fact. In this way the 
proverbial "make an assumption" is not made directly in the logic, but a somewhat 
more cautious approach is taken. The "assuming" itself is part of the downward 
reflection, to be discussed in Section 6. 
Let I be a finite set of indexes. The logic SSP (introduced in [MH91] and 
developed further in [MH92, MH93a,b]) is an extension of the epistemic logic S5 by 
means of special modal operators Pi denoting possible assumption (w.r.t. situation or 
frame of mind i), for i e I, and also generalisations Px, for "c c_ I. Informally, Piq~ is 
read as "tp is a possible assumption (within frame of reference i)". As we shall see 
below, a frame of reference (or mind) refers to a preferred subset of the whole set S of 
epistemic alternatives. This operator is very close to the PA-operator of [TT91] and 
the D-operator of [Doh91]. The generalisation P'dP is then read as a possible 
assumption with respect to the (intersection of the) frames of reference occurring in "c. 
Also, we have an operator K to denote what is known and an operator B to describe 
what is true (believed) under the hypothesis (under focus). 
The logic S5P* is an extension of S5P by allowing an arbitrary set A of 
additional symbols that denote primitive meta-level propositions; for the moment, one 
may think of them as a way to express that certain propositions have been observed, 
or that a given hypothesis is 'in focus'. From a logical point of view, such assertions 
are just atoms, whose truth is governed by some 'meta truth assignment function'. It 
may well be, that upon closer examination, there are some logical laws steering the 
truth of such atoms, but in this stage we will not investigate the inner structure of the 
given meta-level propositions. 
Formally, S5P*-formulas are interpreted on Kripke-structures (called S5P*- 
models) of the form 
M = (U, M, x, {Mili e I}, MV), 
where: 
- U is a collection of states (universe), and M c U is non-empty (the current focus). 
- rt: U x P --~ {L f} is a truth assignment to the primitive propositions per world 
- M i c M (i e I) are sets ('frames') of preferred worlds 
-MV: 
A--~ {t, f} is a valuation for the additional primitive meta-levei 
propositions. 
When writing MI c M2 we mean that the set of states of I~ 1 is a subset of those of 
M 2. Again we identify states s and their truth assignments n(s). We let Mod(SSP*) 
denote the collection of Kripke-structures of the above form. Given an S5P*-model M 
= (U, M, 7t, {Mi ] i e I}, MV), we call the S5-model M M = (M, ltIM ) the focused 
S5-reduct of l~ and M U = (U, r~lU ) the universal or general SS-reduct of M. 

342 
5.1. DEFINITION (interpretation of S5P*-formulas). 
Given a model M = (U, M, n, {M i [ i ~ I}, MV), we give the following truth 
definition. Let g) be a formula, ~ a A and m 9 U. The cases in which g) 9 P, 
g) = (g)l ^ g)2) or g) = ~ 
are dealt with as in Definition 2.5, for the other cases are as 
follows: 
(M, m) ~ Kg) iff for all m' 9 U, (M, m') ~ g); 
(M, m) ~ Bg) iff for all m' 9 M, (M, m') ~ g); 
(M, m) ~ Pig) iff for all m' 9 Mi, (M, m') g g); 
(M, m) ~ Pxg) ifffor all m' 9 Mx, (M, m') g g), where Mx = (-)ie xMi and x G I. 
(M, m) ~ ~ iff MV(o 0 = t, for c~ in A. 
We see that the clauses state that Pig) is true if g) is a possible assumption w.r.t. 
subframe Mi, whereas the latter says that Pzg) is true if g) is a possible assumption 
w.r.t, the intersection of the subframes Mi, i 9 x. This intersection is denoted by M x. 
We assume that, for z = 0, M~ = ~ie ~Mi = M. So in this special case we get that 
the Px modality coincides with the belief operator B. Validity and satisfiability is 
defined analogously as before. 
It is possible to axiomatize (the theory of) SSP* by adjusting the axiom system 
SSP of [MH93b]; we will not go into full details here but give some main 
principles: 
5.2. DEFINITION (system SSP*). In the following, i ranges over I, and "~ over 
subsets of I. Moreover, O, [] 1 and 0 2 are variables over {K, B, Pi, Pz I i 9 I, x c_ I}. 
031) 
All propositional tautologies; 
032) 
(og) ^ o(g) -~ v)) --4 or; 
033) 
og)-~ong); 
(t?,4) 
-~o g) -~ [] ~o g); 
035) 
Kg) -4 g); 
036) 
Kg) --) ore; 
03v) 
mD 1_1_ --4 (D 102(I) +--> 02(I)); 
038) 
Pig) ~ P{i}g) 
039) 
Pzg) --) Pz'g) 
(1310) 
P~g) (---) Bg) 
0311) 
---,Bâ€¢ 
~c'g' 
(R1) 
(R2) 
Modus Ponens 
Necessitation for K: F- g) ~ ~- Kg). 

343 
We call the resulting system S5P*. In the sequel we will write F ~-S5P* q) or 
q) ~ ThssP,(1-" ) to indicate that q) is an S5P*-consequence of F. We mean this in the 
more liberal sense: it is possible to derive q) from the assertions in F by means of the 
axioms and rules of the system S5P*, including the necessitation rule. (So, in effect 
we consider the assertions in F as additional axioms: F ~- S5P* q) iff ~ S5P*uF q), cf. 
[MH93b]) 
5.3. THEOREM F ~- S5P* q) r 
(for all M ~ Mod(S5P*): M ~ F ~ I~ ~ q)) 
PROOF. Combine the arguments given in [MH92, MH93b]. 
6 A Temporal Formalization of Downward Reflection 
In the previous sections it has been described how the upward reflection can be 
formalized by a (nonmonotonic) inference based on epistemic states, and the meta- 
level process by a (monotonic) epistemic logic. In the current section we will 
introduce a formalization of the downward reflection step in the reasoning pattern. The 
meta-level reasoning can be viewed as the part of the reasoning pattern where it is 
determined what the possibilities are for additional assumptions to be made, based on 
which information is available at the object level and which is not. The outcome at 
the meta-level concerns conclusions of the form Pq), where q) is an object-level 
formula. What is missing still is the step where the assumptions are actually made, 
i.e., where such formulas q) are added to the object level knowledge, in order to be able 
to reason further with them at the object level. This is what should be achieved by the 
downward reflection step. Thus the reasoning pattern as a whole consists of a process 
of generating possible assumptions and actually assuming them. 
By these downward reflections at the object level a hypothetical world description 
is created (as a refinement or revision of the previous one). This means that in 
principle not all knowledge available at the object level can be derived already from the 
object level theory OT: downward reflection creates an essential modification of the 
object level theory. Therefore it is excluded to model downward reflection according to 
reflection rules as sometimes can be found in the literature, e.g., "If at the meta-level 
it is provable that Provable(q)) then at the object level q) is provable" (Cf. [Wey80]): 
MT ~- Provable(q)) 
OT~- q) 
A reflection rule like this can only be used in a correct manner if the meta-theory 
about provability gives a sincere axiomatization of the object level proof system, and 
in that case by downward reflection nothing can be added to the object level that was 
not already derivable from the object level theory. Since we essentially extend or 
modify the object level theory, such an approach cannot serve our purposes here. 
In fact, a line of reasoning at the object level is modelled by inferences from 
subsequently chosen theories instead of inferences from one fixed theory. In principle a 
downward reflection realizes a shift or transition from one theory to another. In 
[GTG93] such a shift between theories is formalized by using an explicit parameter 
referring to the specific theory (called 'context' in their terms) that is concerned, and 

344 
by specifying relations between theories. In their case downward reflection rules 
('bridge rules' in their terms) may have the form: 
or, in their notation 
MT ~ Provable(OT', tp) 
OT'~ 
< Th(",p", "o'r'"), Ma" > 
< 9, OT'> 
Here, the second element of the pair denotes the context in which the formula that is 
the first element holds. At the meta-level, knowledge is available to derive 
conclusions about provability relations concerning a variety of object level theories 
OT. So, if at the object level from a (current) theory OT some conclusions have been 
derived, and these conclusions have been transformed to the meta-level, then the meta- 
level may derive conclusions about provability from another object level theory OT'. 
Subsequently one can continue the object level reasoning from this new object level 
theory OT'. The shift from OT to OT' is introduced by use of the above reflection 
rule. 
In the approach as adopted here we give a temporal interpretation to these shifts 
between theories. This can be accomplished by formalizing downward reflection by 
temporal logic (as in [Tre92]). In a simplified case, where no branching is taken into 
account, the temporal axiom (CPtp--~ Xtp) can be used to formalize downward 
reflection, for every objective formula tp. 
In the general case we want to take into account branching and the role to be 
played by an index x in Pz% We will use this index z to label branches in the set of 
time points. By combining S5P* with the temporal logic obtained in this manner we 
obtain a formalization of the whole reasoning pattern. 
During the reasoning process we modify the information we have at the object 
level, and accordingly change the focus set M of possible worlds. We can formulate 
this property as follows: 
6.1. DEFINITION. A temporal S5P*-model obeys downward reflection if the 
following holds for any s and z : 
the cluster M.~ in ~ 
is non-empty r 
there is a t with s <'c t and for all such t the 
focus set of states M of I~t equals M.c 
Now we are ready to zoom in into the models we like to consider here, the temporal 
epistemic meta-level architecture (TEMA-) models. 
6.2. DEFINITION (TEMA- models) 
A TEMA-model IV][ is a temporal S5P*-model over an lft T such that: 
i 
T is a labelled time tree; 
ii 
For every time point s, there is exactly one t with s <~ t; 
iii 
beg obeys downward reflection. 
iv 
M is conservative: if s < t then (~ks)U D (Mt)U 

345 
Notice that conservatism refers to the universe U. Sometimes also M is shrinking 
during the reasoning process: in case of an accumulation of assumptions that are never 
retracted (e.g., see [HMT93]), but in general M may vary arbitrarily within U. 
6.3. THEOREM. 
TEMA-models have the following validities: 
TO 
All the operators of {Xv,x, XV, FV, GV} satisfy the K-axiom (C too) and 
T1 
T2 
T3 
T4 
T5 
T6 
T7 
T8 
T9 
T10 
Tll 
T12 
T13 
generalisation; 
~S5P* q~ :=~ ~ TEMA Cq~ 
--O(Vs 
X3,~ ~ Xv,~ 
Xv ,xcp ~ ---~3,~cp 
Xvt p ~-~ --~3-~p 
Xv~ <--> A~ceVV,~ 
X3~ <--> VzciX3,x~ 
(introduction of C) 
(successor existence) 
(label-deterministic) 
(duality) 
(duality) 
(< is union of <~) 
(dual of T6) 
C(---~z_I_ A Pxtp) ~ X3,xCKcp, if q~ is objective (allowing downward reflection) 
GVq~ ~ Xvt p 
(< c_ ~) 
GVC p ---> XvGv~ p 
(since ~ is transitive closure of <) 
GV(t p --~ XVCP) --~ (Xvr p --~ GvtP) 
(induction) 
(Ctp --~ XvCq~ ) A (CKtp --> XvCK~p), if cp is objective 
(conservativity) 
CK~p --> GvCKtp 
(from conservativity and induction) 
6.4. REMARK. The Theorem above says that the formulas T1 - T13 are at least sound; 
yet we have not been concerned by designing a complete logic for TEMA-models. 
7 
Overall Formalization 
In this section we will show how the different parts of the reasoning pattern as 
described in previous sections can be combined. 
7.1 EMA-theories 
and EMA-entailment 
In the language of S5P* we can express meta-knowledge. By combining the formal 
apparatus of S5P* with Halpern & Moses' nonmonotonic epistemic entailment we 
obtain a framework in which we can perform static epistemic reasoning: reasoning 
about the current epistemic state without reflecting the conclusions downwards. We 
call this framework Epistemic Meta-level Architecture (EMA). 
7.1. DEFINITION (EMA-theory). An EMA-theory | is a pair (W, A), where W is a 
finite, consistent set of objective (i.e. non-modal) formulas describing facts about the 
world, and A is a finite set of S5P*-formulas. The sets W and A are to be considered 
as sets of axioms; we may apply necessitation to them. 

346 
7.2. DEFINITION (EMA-entailment). Given an EMA-theory O = (W, A), we define the 
nonmonotonic inference relation ~"O as follows. Let W* be the conjunction of the 
formulas in W, and let q0 be an objective formula. Then we define the EMA- 
entailment relation ~0 w.r.t. O as follows: qo ~"O ~ r 
â€¢(tpAW*) U A ~-S5P* ~" 
7.3. EXAMPLE (Hypothesis elimination). 
We come back to our example in the introduction. Let the EMA-theory O = (W, A) be 
defined by 
W = {e --) ~b} 
A = {K~s ---) ((K~e A ---J<~e) ---) Ple), 
initially_~s, initially_z ---~Kz}, 
where e means "empty battery" and b "lights can burn". Moreover, we have used 
primitive meta-level propositions "initially_z" to indicate that the information 
"z" is present initially, that is, before the reasoning process starts. Now we have the 
following: 
W* ~" ---~e A ~K~e 
and 
A u {---d(e A --4(-~e} HS5P. Pie 
Therefore ~'O Pie 
In [HMT94a] we show how this temporal framework also covers default reasoning. 
Also, we think our framework of temporalizing S5P* can easily be adapted to give 
an account of counterfactual reasoning (as treated in [MH93c]) too. 
7.2 TEMA-models and TEMA-entailment 
7.4. DEFINITION Let O = (W, A) be an EMA-theory. Then we define a TEMA-model 
of | as a TEMA-model M__ O such that: 
i 
(basis: the root) MOr is an S5P*-model such that 
(a) the universal S5-reduct of MOr is the S5-model MW., 
(b) MOt satisfies the meta-knowledge, i.e., MOr ~ A. 
ii 
(induction step) Suppose that we are given an S5P*-model at snapshot MOs . 
Then we have that for a(n S5P*-) model MOt with s <z t, it holds that: 
(a) (MOt)U is the S5-model I~ x as it appeared as a cluster in MOs, and 
(b) MOt satisfies the meta-knowledge again, i.e., MO t ~ A. 
In general, there are multiple TEMA-models of an EMA-theory O. Note that clause 
ii(a) reflects the downward reflection operation with respect to the P.c-assumptions. 
Even in less trivial reasoning processes we may be interested in some kind of 
final outcome (a conclusion set). In our case the universe U always shrinks, but not 
always the focus set M does so. We can view U as a core of derived facts that after all 
survives during the reasoning pattern; this is reflected in the following definition: 
7.5. DEFINITION (limit model). 
Suppose IM is a conservative temporal V-model. The intersection of the models IM(s) 
for all s in a given branch B = (T, (<'~)x e L) of the lft T is called the limit model of 
the branch, denoted limB M. The set of limit models for all branches is called the set 

347 
of limit models of M. These definitions straightforwardly extend to temporal $5- and 
S5P-models, by identifying M with its set of states, U. 
We might formulate definitions of entailment of objective formulae related to any 
model, or any model based on the standard tree. But it may well happen that there are 
branches in such models, for instance labelled by the empty set only, that contain no 
additional information as compared to the background knowledge. It is not always 
realistic to base entailment on such informationally poor branches in a model. Thus 
we def'me: 
7.6. DEFINITION (informationally maximal) 
We define for branches ~-1 and ~-2 with the same set of time stamps of a TEMA- 
model M that ~2 is informationally larger than B1, denoted B 1 < B2, if for all i ~ Iq 
and s, t with Isl = Itl = i it holds ~2(s) c Bl(t). 
We call ~1 informationally maximal if it is itself the only branch of M that is 
informationally larger. 
7.7. DEFINITION (regular model) 
A TEMA-model M__ is called regular if all branches are informationally maximal. The 
submodel based on all time points t included in at least one informationally maximal 
branch is called the regular core of M..M_, denoted by reg(]~). 
7.8. DEFINITION 
i 
for k e N we define M(k) = Ut e reg(~ff), It] = k M(t) 
ii 
M~ = C"~k e N M(k). 
7.9. THEOREM (From [HMT94a]). Let M be a TEMA-model. Then: 
i 
For k < k' we have M.._(k') c M__(k) 
ii 
M ~ = t~ ~ branch of reg(~) lim~. 1~.. 
Since (regular) TEMA models describe a reasoning process over time, it seems natural 
to have notions of entailment that exploit the conservativity of such models, 
expressing the monotonic growth of knowledge of objective formulas. The latter 
restriction is important, since it may be the case that initially an atom p is not 
known, yielding ~Kp and hence K~Kp, while at some later point p has been learnt, 
giving ---Js163 
expressing that some knowledge (i.e., knowledge about ignorance!) 
has been lost. So, in the sequel we will be interested in formulas of the form CKcp, 
where tp is an objective formula. We will call such formulas currently known 
objective formulas (cko's) and use o~ and 13 as variables over them. 
In the literature on non-monotonic reasoning, one usually distinguishes so called 
sceptical (true in all obtained models) and credulous (true in some of them) notions of 
entailment. Due to the fact that we have an (infinite) branching time structure, we 
have a great variety of combining these notions, although for the formulas that we are 
interested in, the current objective formulas, various of such notions do collapse. This 
observation is made explicit in the following theorem. 

348 
7.10. THEOREM Let ~ and ~ be cko-formulas. Then, on TEMA models, we have the 
following equivalences: 
i 
G3o~ -- o~ 
iii 
GVo~ =- XV~ 
ii 
ct - (o~ ^ GV~) 
iv 
F3or - F3(Gvor ^ ~) 
7.11. DEFINITION (sceptical entailment) Let M be a TEMA-model with root r and 
an cko-formula. We define the sceptical entailment relation by: 
I~ ~seep ~ 
iff 
~br ~ FVoc 
Due to our remark that we made before definition 7.6, it makes most sense to use this 
notion of sceptical entailment for (sub) models of type reg(l~). 
7.12. PROPOSITION Let M be a TEMA-model with root r and cta cko-formula. 
The following are equivalent: 
i 
reg(M..M_) ~scep 
ii 
limb m..M_ ~ ~ for every maximal branch B of the regular core of M__. 
For our definition of credulous entailment we can be less restrictive; we do not need to 
bother about informationally maximal branches. Especially, too little information in 
one branch can always be overcome by another, informationally larger branch. 
7.13. DEFINITION (credulous entailment) Let M be a TEMA-model and c~ a cko- 
formula. We define: I~ ~cred 0~ iff M__.,r ~ F3oc 
7.14. PROPOSITION 
Let I~ be a TEMA-model and cx a cko-formula. The following are equivalent: 
i 
I~ ~cred O~ 
ii 
limb M___ ~ ct for some maximal branch B 
We finally can give the definitions of sceptical and credulous entailment. 
7.15. DEFINITION (entailment from an EMA-theory) 
Let @ = ( W, A) be an EMA-theory and q~ an objective formula. 
O ~scep q) 
iff 
for all models I~ of O it holds reg(]~) ~scep q) 
19 ~cred q0 
iff 
for all models M of 19 it holds I~ ~cred q) 
7.16. PROPOSITION 
Let O = ( W, A) be an EMA-theory and q) an objective formula. Then it holds 
-- 
~scep q) =~ 0 ~cred q) 
0 

349 
7.3 The example reasoning pattern 
We return to our running example and show how it obtains its natural semantics. To 
cover the whole reasoning pattern, we take W = {(e v p) --~ -,s, e ~ ~b} and A as: 
A = {K~s ~ ((---d(e A ---d(~e) --~ Ple), 
if --a is knowt~ 
and we do not know whether -,e holds, we may choose e as an hypothesis 
(K~s A K~e) --~ ((--d(p ^ ---d~p) ~ 
P2P), 
we investigate p if we know -~s and ~e 
observed_b, 
initially_~s, 
initially z -~Kz, 
possible hyp_e, possible_hyp_p, 
(possible_hyp_z 
A Pi z) -~ X3, i focus_z, 
z e {e, p}, i e {I, 2} 
(focus_z A observed_w A B~w) ~ bad_hyp_z, 
z e {e, p}, w 6 {b} 
(bad-hyp_z A fOCUSZ) -~ OvK~z 
z ~ {e, p}} 
We denote worlds by 4-tuples (w, x, y, z) ~ {0,1} 4, to be interpreted as the truth- 
values of the tuple (b, e, p, s). We construct a model that is linear. 
* Initial snapshot 
We obtain the initial model M(0) = (U(0),M(0),rr(0),MI(0), M2(0), MV(0)). The 
universe U(0) is based on all models of W; we take M(0) = U(0). Furthermore, we 
have seen in Example 7.3, how we can derive P1 e from (W, A), defining the cluster 
MI(0). In this model M2 (0) = 0, (Cf. our remarks at the end of this section); MV(0) 
is to be understood as the minimal valuation on the atoms of A so that A is satisfied; 
g~ o) 
observed b 
}ossible hyp_e 
}ossible hyp_p 
(o,o,o,o) 
0,o,o,o) 
(11) 
did 
(0,0,1,0) 
(1,0,1,0) 
9 
0 
(o,l,o,o) 
(0,1,1,o) 
o 
did 
M~ }) 
M(O) 
U (0) 
* Next snapshot 
Using T8, C(~PIâ€¢ 
A Pie) e-~ X3 ICKe, we obtain a downward reflection into the 
next model M(1) = <U(1),M(I),rr~I),MI(1), M2(I), MV(1)), where MV(1) is like 

350 
MV(0), but under MV(1), now also focus_e is true. Moreover, U(1) = U(0), and the 
new cluster M(1) equals the old MI(0): 
observed b 
possible_hyp_e 
possible_hyp__p 
focus e 
(0,0,0,0) 
(1,0,0,0) 
(0,0,1,0) 
(1,0,1,0) 
91' 
Q 
(0,1,0,0) 
(0,1,1,0) ! 
U (1) 
* Further snapshots 
Now, the cluster M(1) is the one which is in the current focus: at its object-level 
theory we can derive that ~b, since in M(1) we have M(1) ~ B~b. We use the meta- 
knowledge (f0cus_z 
/x observed_w ^ B~w) ~ bad_hyp_z with e for z and b 
for w. Using A again this yields GvK~e, so that for all ~..~_(2) with ~(1) < M__(2) it 
holds that M(2) ~ ~e; semantically this amounts to saying that the universe U(2) of 
all future models I~.._(2) is at most the set U(1) \ M(I), and one may proceed and 
investigate the hypothesis of bad plugs (p) for the failure of the non-starting car. 
Some remarks are in order here. Firstly, we have only analyzed some intended model 
for the theory O = (W, A); a model that carries the assumption that the theory (W, A) 
is all that we know; this justified for example that we took M2 (1) to be empty. 
Secondly, since the atoms in A are rather application-dependent, we decided to add all 
assumptions about them to A; however, for classes of applications, one might 
consider to add some of those properties as axioms to S5P*. Finally, in this particular 
example we did not exploit the fact that we have a branching time model; one may 
change the example in such a way that the two possible hypotheses p and e are so to 
speak investigated simultaneously. In our example there may be specific reasons to 
investigate one hypothesis before the other: because one of them (i.e., e) is more easy 
to refute, for example; this preference is also explicitly modelled in A. 
8 
Conclusions 
In [MH93a,b] an Epistemic Default Logic (EDL) was introduced inspired by the 
notion of meta-level architecture that also was the basis for the BMS-approach 
introduced in [TT91]. In EDL drawing a default conclusion has no other semantics 
than that of adding a modal formula to the meta-level. No downward reflection takes 
place to be able to reason with the default conclusions at the object level (by means of 
which assumptions actually can be made). In [TT91] downward reflection to actually 

351 
make assumptions takes place, but no logical formalization was given: it was defined 
only in a procedural manner. 
In principle a downward reflection that enlarges the object level theory disturbs the 
object level semantics: facts are added that are not logically entailed by the available 
object level knowledge. Adding a temporal dimension (in the spirit of [FG92]) enables 
one to obtain formal semantics of downward reflection in a dynamic sense: as a 
transition from the current object level theory to a next one (where the reflected 
assumption has been added). This view, also underlying the work presented in [ET93] 
and [Tre92], turns out to be very fruitful. A number of notions can be formalized in 
temporal semantics in a quite intuitive and transparent manner. 
The temporal epistemic meta-level architecture described here is a powerful tool to 
reason with dynamic assumptions: it enables one to introduce and retract additional 
assumptions during the reasoning, on the basis of explicit meta-knowledge. In 
[Tre90], [Tre91] various applications of this architecture are shown. In the current 
paper we formalized the semantics of a temporal epistemic meta-level architecture by 
means of entailment on the basis of temporalized Kripke models. 
Acknowledgements 
Discussions about the subject with Joeri Engelfriet have played a stimulating role for 
the development of the material presented here. 
REFERENCES 
[Doh91] 
P. Doherty, NM3 - A Three-Valued Cumulative Non-Monotonic Formalism, in: 
Logics in A1, (J. van Eijck, ed.), LNCS 478, Springer, Berlin, 1991, pp. 196-211. 
[ET93] 
J. Engelfriet, J. Treur, A Temporal Model Theory for Default Logic, in: M. 
Clarke, R. Kruse, S. Moral (eds.), Proc. ECSQARU '93, Springer Verlag, 1993, pp. 91- 
96. 
[FG92] 
M. Finger, D. Gabbay, Adding a temporal dimension to a logic system, Journal 
of Logic, Language and Computation 1 (1992), pp. 203-233. 
[Gab82] 
D.M. Gabbay, Intuitionistic basis for non-monotonic logic, In: G. Goos, J. 
Hartmanis (eds.), 
6th Conference on Automated Deduction, LNCS 138, Springer 
Verlag, 1982, pp.260-273 
[GTG93] 
E. Giunchiglia, P. Traverso, F. Giunchiglia, Multi-Context Systems as a 
Specification Framework for Complex Reasoning Systems, in: J. Treur, Th. Wetter 
(eds.), Formal Specification of Complex Reasoning Systems, Ellis Horwood, 1993, 
pp. 45-72 
[HM84] 
J.Y. Halpern & Y.O. Moses, Towards a Theory of Knowledge and Ignorance, 
Proc. Workshop on Non-Monotonic Reasoning, 1984, pp. 125-143. 
[HMT94a] W. van der Hoek, J.-J. Ch. Meyer & J. Treur, Temporalizing Epistemic Default 
Logic. Techn. Report, Free University Amsterdam, 1994 
[HMT94b] W. van der Hoek, J.-J. Ch. Meyer & J. Treur, Formal Semantics of Temporal 
Epistemic Reflection. Techn. Report, Free University Amsterdam, 1994. 
[MH91] 
J.-J.Ch. Meyer & W. van der Hoek, Non-Monotonic Reasoning by Monotonic 
Means, in: J. van Eijck (ed.), Logics in AI (Proc. JELIA '90), LNCS 478, Springer, 
1991, pp. 399-411. 
[MH92] 
J.-J.Ch. Meyer & W. van der Hoek, A Modal Logic for Nonmonotonic 
Reasoning, in: W. van der Hoek, J.-J. Ch. Meyer, Y.H. Tan & C. Witteveen (eds.), 
Non-Monotonic Reasoning and Partial Semantics, Ellis Horwood, Chichester, 1992, 
pp. 37-77. 

352 
[MH93a] 
J.-J. Ch. Meyer & W. van der Hoek, An Epistemic Logic for Defeasible 
Reasoning using a Meta-Level Architecture Metaphor. Techn. Report IR-329, Free 
University, Amsterdam, 1993. 
[MH93b] J.-J. Ch. Meyer & W. van der Hoek, A Default Logic Based on Epistemic States. 
in: M. Clarke, R. Kruse, S. Moral (eds.), Proc. ECSQARU '93, Springer Verlag, 1993, 
pp. 265-273. Full version to appear in Fundamenta Informatica. 
[MH93c] J.-J. Ch. Meyer & W. van der Hoek, Counterfactual reasoning by (means of) 
defaults in: Annals of Mathematics and Artificial Intelligence 9 (III-IV), (1993), pp. 
345-360. 
[MH94] 
J.-J. Ch. Meyer & W. van der Hoek, Epistemic Logic for AI and Computer 
Science, forthcoming. 
[Moo85] 
R.C. Moore, Semantical Considerations on Nonmonotonic Logic, Artificial 
Intelligence 25, 1985, pp. 75-94. 
[Sho88] 
Y. Shoham, Reasoning about Change, MIT Press, Cambridge, 1988. 
[qT91] 
Y.-H. Tan & J. Treur, A Bi-Modular Approach to Non-Monotonic Reasoning, 
in: Proc. WOCFAI'91 (M. DeGlas & D. Gabbay, eds.), Paris, 1991, pp. 461-475. 
[Tre90] 
J. Treur, Modelling nonclassical reasoning patterns by interacting reasoning 
modules, Report IR-236, Free University Amsterdam, 1990. 
[Tregl] 
J. Treur, Interaction types and chemistry of generic task models, in: B. Gaines, 
M. Linster (eds), Proc. EKAW'91, GMD Studien 211, 1992, Bonn. 
[Tre92] 
J. Treur, Towards dynamic and temporal semantics of meta-level architectures, 
Report 1R-321, Free University Amsterdam, 1992. Also: Proc. META'94, 1994 (this 
volume). 
[Wey80] 
R.W. Weyhrauch, Prolegomena to a Theory of Mechanized Formal Reasoning, 
Artificial Intelligence J. 13 (1980), pp. 133-170. 

Temporal Semantics of Meta-Level Architectures 
for Dynamic Control of Reasoning+ 
Jan Treur 
Free University Amsterdam, Department of Mathematics and Computer Science 
De Boelelaan 1081a, 1081 HV Amsterdam, The Netherlands 
Email: treur@cs.vu.nl 
Abstract 
Meta-level architectures for dynamic control of reasoning processes are quite 
powerful. In the literature many applications in reasoning systems modelling 
complex tasks are described, usually in a procedural manner. In this paper we 
present a declarative framework based on temporal (partial) logic that enables one 
to describe the dynamics of reasoning behaviour by temporal models. Using these 
models the semantics of the behaviour of the whole (meta-level) reasoning system 
can be described by a set of (intended) temporal models. 
1 
Introduction 
In the literature on meta-level architectures and reflection two separate streams can be 
distinguished: a logical stream (e.g., [3], [9], [25] ) and a procedural stream (e.g., [5], 
[6] ). Unfortunately there is a serious gap between the two streams. In the logical 
stream one restricts oneself often to static reflections; i.e., of facts the truth of which 
does not change during the reasoning: e.g., provable(A) (with A an object-level 
formula). In the procedural stream usually facts are reflected the truth of which changes 
during the whole reasoning pattern; e.g. control statements like currentgoal(A), 
with A ,an object-level formula, that are sometimes true and sometimes false during 
the reasoning. If applications to dynamic control of complex reasoning tasks are 
concerned these dynamic reflections are much more powerful (for applications see, 
e.g.: [6], [5], or [4], [8], [18], [19], [21], [23]). However, a logical basis for this is 
still lacking. The current paper provides a logical foundation (based on temporal logic) 
of meta-level architectures for dynamic control. Our logical framework enables one to 
study these dynamic meta-level architectures by logical means. It can be viewed as a 
contribution to bridge the gap between the logical stream and the procedural stream. 
A meta-level architecture consists of two interacting components that reason at 
different levels: the object-level component and the meta-level component. The 
interactions between the components are: upward reflection (information transfer from 
object-level component to meta-level component) and downward reflection 
+ This work is partially supported by ESPRIT III Basic Research Action 6156 (DRUMS II). 

354 
(information transfer from meta-level component to object-level component). In a 
meta-level architecture each of the reasoning processes in one of the components can 
be assigned its own local semantics (local in view of the whole system) that can be 
formally described according to well-known approaches to static (declarative) and 
dynamic (procedural) semantics (for instance as known from logic programming). In 
this local semantics a static view (the contents; declarative) and a dynamic view (the 
control; procedural) can be distinguished, and these views can be treated (to a certain 
extent) as orthogonal (e.g., see [15]). 
The crucial point of a meta-level architecture for dynamic control is that the 
semantics of the meta-level component relates in some manner to (the control of) the 
reasoning process of the object-level component. To obtain an overall semantics for 
the whole system, the crux is to formally describe the precise semantic connection 
between the two components. The semantic connection is used in a bidirectional 
manner. Firstly, meta-level reasoning is about (or refers to) process aspects of the 
reasoning of the object-level component and uses information about that (via upward 
reflection). Secondly, the results of its reasoning may affect the control of this object- 
level reasoning process by changing its control settings (downward reflection). 
Therefore meta-level architectures enable one to represent control knowledge in the 
system in an explicit declarative manner. 
A formal semantic connection between the two components should relate some 
(formal) description of procedural (inference process control) aspects of the object-level 
component to the formal declarative description of the meta-level component. 
Therefore for the overall semantics of this type of reasoning system a global 
distinction between a static view and a dynamic view essentially cannot be made (as an 
extension of the distinction that can be made within each of the components). The 
views are not orthogonal in this case: to a certain extent they are defined in terms of 
each other. In particular, it is impossible to provide independent declarative semantics 
for such systems without taking into account the dynamics (of the object-level 
component). For the overall architecture a formal semantical description is needed that 
systematically integrates both views. The lack of such overall semantics for complex 
reasoning systems (with meta-level reasoning capabilities) was one of the major open 
problems that were identified during the ECAI'92 workshop on Formal Specification 
Methods for Complex Reasoning Systems (see [24] ). 
In this paper we develop a formal framework where partial models are used to 
explicitly represent (current) information states (see also [12]). This enables us to 
represent inference processes within each of the components as transitions between 
partial models, and a trace of a reasoning process as a partial temporal model. First, in 
Section 2 some basic notions from Temporal Partial Logic are introduced. Next, in 
Section 3 we give a formalization of a static view and a dynamic view on the object- 
level reasoning component. In Section 4 a temporal interpretation of meta-level 
reasoning is introduced and in Section 5 formal semantics for reasoning patterns of 
meta-level architectures for dynamic control are presented based on partial temporal 
models that formalize the overall reasoning traces. Finally, in Section 6 an example is 
presented. In the full report, under an additional finiteness condition a temporal theory 
is constructed that in some sense is an axiomatisation of the meta-level architecture: 
its minimal models are just the overall reasoning traces. 

355 
2 Basic notions of Temporal Partial Logic 
In this section we will introduce the formal notions of partial logic and temporal 
partial logic that are needed later on. 
Definition 
2.1 
(signature 
and propositional 
formula) 
a) A signature F, is an ordered sequence of (propositional) atom names, or a sequence 
of sort, constant, function and predicate symbols in (many-sorted) predicate logic. By 
I;1 c_ Y., 2 we denote that I;1 is a subsignature of Y-,-z. The disjoint union of two 
signatures I;1 and Y.~ is denoted by I; 1 ~ I:'z. A mapping of signatures Ix : :El ---> I;'z 
is a mapping from the set of symbols of I;1 into the set of symbols of E2 such that 
sorts are mapped to sorts, constants to constants, predicates to predicates, functions to 
functions, and the arities and argument-sort relations are respected. 
b) The set At(Z) is the set of (ground) atoms based on I;. By a (ground) formula of 
signature I; we mean a proposition built from (ground) atoms using the connectives 
^, -->, ~ We will call these formulae propositional formulae, in contrast to the 
temporal formulae introduced later on. Below we will assume all formulas ground 
(closed and without quantifier@ For a finite set F of formulae, con(F) denotes the 
conjunction of the elements of F; in case F 
is the empty set then by definition 
con(F) is true. 
By Lit(Z) we denote the set of ground literals of signature I:. 
As discussed in [12], partial models can be used to represent information states in a 
reasoning system; therefore we define: 
Definition 
2.2 
(partial models as information 
states) 
a) An information state or partial model M for the signature E is an assignment of 
a truth value from {0, 1, u} to each of the atoms of I;, i.e. M: At(i;) ~ 
{0, 1, u}. 
An atom a is true in M if 1 is assigned to it, and false if 0 is assigned; else it is 
called undefined or unknown.A literal L is called true in M, denoted by M ~ + L 
(resp. false in M, denoted by M ~- L) we mean 
M(L) = 1 (resp. M(L) = 0) if L 
is an atom and 
M(a) = 0 (resp. M(a) = 1) if L = ~ a 
with a e At(i:). By 
Lit(M) we denote the set ofliterals which are true in M. 
We call a partial model M complete if no M(a) equals u for any a e At(I;). 
b) The set of all information states for I; is denoted by IS(I;). If I:1 c_ Y.~ then 
this induces an embedding of IS(I;1) into IS(i;-z); we will identify IS(I: 0 with its 
image under this embedding: IS0"a) c_ IS(Z2). Furthermore, IS(I;1 9 Y-,z) can (and 
will) be identified with the Cartesian product IS(I;1) x IS(I;2). 
c) We call N a refinement of M, denoted by M _< N, if for all atoms a e At(I:) it 
holds: M(a) _< N(a) where the partial order on truth values is defined by 
u _<0, u < 1, u < u, 0 < 0, 1 _< 1. 
d) If K is a set of formulae of signature Z, a complete model M of signature I; 
is called a model of K if all formulae of K are true in M. An information state is 
consistent with K if it can be refined to a complete model that is a model of K. By 
ISK(Z) we denote the set of all information states for I; that are consistent with K. 

356 
e) If M 
is a partial model for the signature I; and S ~ Ate), then by MIS we 
denote the restriction or reduct of M to S, defined by 
MlS(a) 
= 
M(a) 
if a ~ S 
u 
otherwise (i.e., if a e At(~)\S) 
If S = At(Y.') for some subsignature ~.' of ]~, then we denote M]S by MI~'.'. 
Notice that for partial models M, N for 9 it holds M -< N if and only if M ~Â§ L 
N ~ + L for all literals L e Lit(Y.). We base the interpretation of propositional 
formulae on the Strong Kleene truth tables for the logical connectives (see also 
Definition 2.6 below); more details and possibilities of partial semantics can be found 
in [2], [13]. 
Definition 2.3 
(labeled flow of time) 
Let L be a set of labels. 
a) A (discrete) labeled flow of time, labeled by L is a pair '11' = (T, (<i)i ~ L) 
consisting of a nonempty set T of time points and a collection of binary relations <l 
on T. Here for s, t in T 
and i ~ L 
the expression s <i t denotes that t is a 
(immediate) successor of s with respect to an arc labeled by i. Sometimes we use 
just the binary relation s < t denoting that s <it for some i (for some label i 
they are connected). Thus < is defined as u i % We will assume that this relation < 
is irreflexive, antisymmetric and antitransitive. 
We also use the (irreflexive) transitive closure ~ of this binary relation, defined as <+. 
b) We call T linear if ~ is a linear ordering and rooted with root r if r is a 
(unique) least element: for all 
t it holds r = t or r ~ t. We say T 
satisfies 
successor existence if every time point has at least one successor: for all s ~ T there 
existsa t~ Tsuchthat 
s<t. 
Definition 2.4 
(partial temporal model) 
Let I: be a signature. 
a) A labeled (linear time) partial temporal model of signature Y. with labeled flow 
of time T is a mapping 
M: T --~ IS(Y-) 
For any fixed time point t the partial model M(t) is also denoted by Mr; the model 
M can also be denoted by (MOt e T. If a is an atom, and t is a time point in T, and 
Mr(a) = 1, then we say in this model 
M at time point t the atom a is true. 
Similarly we say that at time point t the atom a is false, respectively unknown, if 
Mr(a) = 0, respectively Mt(a ) = u. 
b) The refinement relation <_ between partial temporal models is defined as: M _< N 
if M and N have the same flow of time and for all time points t and atoms a it 
holds Mt(a ) < Nt(a ). 
c) M is called conservative if for alls, t~T 
with s<t 
it holds Ms -<Mt. 

357 
~ 
o 
b 
II 
M 
t 
time pointa 
Fig 1 Example of a partial temporal model 
From now on we will assume that all used labeled flows of time are linear, rooted and 
satisfy successor existence. This is equivalent to 
T being order-isomorphic to the 
natural numbers 1~'. Therefore in the rest of the paper we will use I~ as our flow of 
time. 
We introduce three temporal operators, 
X, P and C, referring to the next 
information state, past information states and the current information state, 
respectively. Intuitively, the temporal formula 
Xa is true at time t means that 
viewed from time point t, the formula a is true in the next information state. We 
use labeled next operators to be able to distinguish different types of steps. The 
temporal formula Pa 
is true at time 
t 
means that a 
is true in some past 
information state. Furthermore we will need an operator that expresses the fact that 
currently a is true (in the current information state); this will be the operator C. 
Definition 2.5 makes this formal. Notice that sometimes we will denote the 
application of the temporal operators like F(a); if no confusion is expected, for 
shortness we write Fa. We will not need nested operators in this paper, although it 
would certainly be possible to use them. 
Definition 2.5 
Let a propositional 
a time point t e Iq 
a) 
(M, t) I= + 
(M, t) ~- 
b) 
(M, 
(M, 
(M, 
(M, 
c) 
(semantics of the temporal 
operators) 
formula a, a labeled partial temporal model M, a label i E L and 
be given. Then: 
X|a 
~:~ 
3s~H 
[t <is & (M,s) I=+ a] 
Xla 
r 
(M, t) I~ + Xla 
t) ~+ Ca 
r 
(M, t) ~=+ a 
t) I=-Cct 
r 
(M, t) ~+ Cet 
t)~+Pa 
r 
3s~t~ 
[s~t 
& (M,s) ~+a] 
t) I=- Pa 
r 
(M, t) I~ + Pa 
Now we can make new formulae using conjunctions, negations and implications of 
these temporal operators. From now on the word (temporal) formula will be used to 
denote a formula possibly containing any of the new operators, unless stated 

358 
otherwise. As we do not need nesting of temporal operators, for convenience we will 
only consider non-nested formulae. 
Definition 2.6 
(temporal formulae and their interpretation) 
Let Z be a signature, let M be a labeled partial temporal model for ~;, and t r I~l a 
time point. 
a) A temporal atom of signature Z is a formula Oct where O is one of the 
temporal operators in Definition 2.5 and cta propositional formula of signature 1;. 
A temporal formula of signature Z is a formula built from temporal atoms of 
signature X, using the logical connectives --1, ^, -->. 
b) Any propositional atom p e At(E) is interpreted according to: 
(M, t)~+p 
r 
M(t, p) = 1 
(M, t) ~-p 
r 
M(t, p) = 0 
For the interpretation of a temporal atom, see Definition 2.5. 
c) For any two temporal or propositional formulae tO and u 
(i) 
(M, t) ~+ tO ^ W 
r 
(M, t) I =+ r 
and 
(M, t) I=- tO ^ W 
r 
(M, 0 ~- tO 
or 
(ii) 
(M, 0 I= + tO ---> ~ 
r 
(M, t) L-tO 
or 
(M, t) ~- to ~ 
~ 
r 
(M, t) ~ + to 
and 
(iii) 
(M, t) I= + --, tO 
r 
(M, t) ~- tO 
(M, t) I=- ~ tO 
r 
(M, t) I= + tO 
(M, 0 ~+ u 
(M, 0 I=-~ 
(M, t) ~+~ 
(M, t) I=-~ 
d) For any temporal or propositional formula tO: 
(M, t) ~ Â§ tO 
r 
(M, t) ~ + tO 
does not hold 
(M, t) I#" tO 
r 
(M, 0 I=- tO 
does not hold 
(M, t) ~u tO 
r 
(M, 0~ +tO 
and 
(M,t)~-tO 
e) For a partial model M and a set of formulae K, by M ~ + K we mean M ~ + tO for 
all tO e K. By M ~+ tO we mean (M, t) ~+ tO for all t E I~1 and by M is a temporal 
model ofK, denoted M~+K, 
we mean MV+t0 for all tO~ K, where K isaset 
of temporal or propositional formulae. A model M of K is called a minimal model 
of K if for any model M' of K with M'_< M it holds M'= M. 
The temporal approach provides declarative semantics for systems that behave 
dynamically, essentially since time has been put into the domain of consideration in 
an explicit manner: one reasons both on world states and the time points on which 
they occur. This means that non-conservative changes in truth values of a statement b 
referring to a changing world state are accounted for by considering the statement in 
fact as two (or more) statements: one (t, b) referring to one time point t, and another 
one 
(s, b) referring to another time point 
s. The truth values of these two 
statements do not change; e.g., it will always remain true that at time point t the 
statement b holds. ThUs a dynamic system is described in a declarative manner. Its 
set of intended models can be constructed in the temporal sense described above. One 
specific behaviour of the system corresponds to one of these temporal models. We will 
work out this general idea for the case of a meta-level architecture. More details on 
temporal logic can be found in [1], [10]. 

359 
3 
Static and dynamic view on the object-level reasoning 
In this section we use the notion of a partial model to formalize the information state 
of the object-level reasoning component at a certain moment. A transition of one 
information state to another one can be formally described by a mapping between the 
partial models specifying the information states. In a reasoning process such a 
transition is induced by a reasoning step where a knowledge unit K (e.g., a set of 
rules or a single rule) is used to derive some additional conclusions. The dynamic 
interpretation of such a knowledge unit K can be defined as the mapping in the set 
of all relevant partial models induced by K. 
Note that information states are defined in terms of literals. This implies that in 
principle only literal conclusions count in inferences. Therefore we can take advantage 
of the fact that inference relations, restricted to literal conclusions, that are sound with 
respect to the classical Tarski semantics are also sound with respect to the partial 
Strong Kleene semantics (and vice versa), as has been established in [17] (cf. Theorem 
2.3, p. 464). In the sequel by I- we will denote any sound inference relation that is 
not necessarily complete (e.g, one of: natural deduction, chaining, full resolution, 
SLD- resolution, unit resolution, etc.). 
3.1 
The static view on the object-level reasoning 
In this subsection we define the underlying language, logical theory and inference 
relation of the object-level component. Moreover we define the notions of deductive 
and semantic closure. 
Definition 3.1 
(static view on the object-level component) 
The static view on the object-level reasoning component is a tuple 
(go, OT, ~- ) 
with 
xo 
OT 
a signature, called the object-signature 
a set of propositional ground formulae expressed in terms of 
the object-signature 
a classical inference relation (assumed sound but not 
necessarily complete) 
Notice that a literal formula is true in a partial model M if and only if according to 
the classical semantics the formula is true in every complete refinement of M. 
Definition 3.2 
(deductive and semantic closure) 
Let K be a set of propositional formulae of signature Y. and ~" a (sound) inference 
relation or (semantic) entailment relation. 
l 
a) For M 9 ISK(~) we define the partial model ClKr"(M) by 
ClKP(M) ~+ L r 
KU Lit(M) 
F L 

360 
for any literal L. This model is called the closure of M under K (with respect to 
~). We call M closed under K 
(with respect to ~) if 
M -- clI~ ~"(M) , or, 
equivalently, if 
M~+L 
r 
KuLit(M) 
~ L 
b) If ~, is an inference relation I-- we denote elKS'(M) by dCK~-(M) and call it 
the deductive closure of M under K (with respect to I-). We call M deductively 
closed under K if 
KuLit(M) I-- Lr162 M~ +L 
i.e., if it is its own deductive closure under K. 
c) For the classical semantic consequence relation I= (based on complete models) we 
denote elKS'(M) by SCK(M) and call it the semantic closure of M. We call M 
semantically closed under K if 
KuLit(M) 
~ L 
r 
M~+L 
i.e., if it is its own semantic closure under K. 
Definition 3.3 
(conservation, monotonicity, idempotency) 
Let K be a set of propositional formulae of signature Y.. 
We call the mapping r : ISK(Y-) --~ ISK(Y-): 
(i) conservative 
if 
M _< a(M) 
for all M ~ ISK(~) 
(ii) monotonic 
if 
~(M) <_ ~(N) 
for all M, N e ISK(~) 
with M _< N 
(iii) idempotent 
if 
(x(ct(M)) = r 
for all M e ISK(I;) 
Proposition 
3.4 
Let K be a set of propositional formulae of signature ~ and ~, 
a (sound) inference 
relation or the semantic consequence relation, 
/ 
Then the mapping 
ClKt~: ISK(E) ---> ISK(E) 
is conservative, monotonic and 
idempotent. 
Moreover, for any 
M e ISK(E) 
and any model 
N of K 
that is a complete 
/ 
refinement of M it holds CIK~'(M) _< N. In particular this holds for the semantic 
closure mapping. 
3.2 
Object level reasoning traces and controlled inference functions 
In Subsection 3.1 we have assumed that the deduction is exhaustive with respect to the 
specific set K; this is not a realistic assumption. In practice often only some of the 
inferences that are possible are applied, depending on additional control information. 
However, the full deductive closure always gives an upper bound: if control is 
involved leading to non-exhaustive reasoning, the actual outcome is a model M' with 
M < M' _< dCKt-(M) < SCK(M) 

361 
In this paper we will assume that controlled inference is deterministic, depending on an 
assignment of values to some set of control parameters. In that case controlled 
inference can be described as follows. 
Definition 3.5 
(controlled inference function) 
Suppose K is a set of formulae of signature Z and ~ 
is a (sound) inference 
relation or the (semantic) entailment relation. The mapping a: ISK(y~) --* ISK('s is 
called a controlled inference function for K based on ~ 
if it is conservative and 
monotonic and for all M ~ ISK(~) it holds 
/ 
w(M) < cl K~'(M). 
Notice that we do not require that a controlled inference function is idempotent. If 
reasoning is not exhaustive idempotency is often lost. Controlled inference functions 
can be viewed as functions aK ~ where instead of a general entailment relation ~" a 
variant is used that is parameterized by certain control information N. Two examples 
of control parameters and the corresponding inference functions are: 
- information about which atoms are the goals for the reasoning 
In this case the control information N expresses that the conclusions should be 
restricted to what already is available and the set of atoms G; i.e., 
aKN(M)(a) = 
M(a) 
if M(a) ~ u 
ClK~(M)lG(a) 
otherwise 
information about the selection of elements of the knowledge base to be used 
Here the control information N expresses that only formulae of a subset K' of the 
theory K can be used in the reasoning, i.e., 
~KN(M) = r 
< C]KF(M) 
Notice that these examples of control apply not only to the case of an inference 
relation but also to the semantic consequence relation. In this sense control can be 
defined in a semantic (inference relation independent) manner. 
In a meta-level architecture the control information N is determined by the meta- 
level reasoning. What is needed to formalize a meta-level architecture is a 
formalization of this control information on the right level of abstraction; i.e., in such 
a manner that it can be subject of a (meta-level) inference process. We will come back 
to this point in Section 4. 
Definition 3.6 
(object.reasoning trace) 
Let (go, OT, I- ) be a static view on the object-level reasoning component, where 
l- 
is a sound inference relation. A partial temporal model 
(Mt) t G N is called an 
(object-reasoning) trace for (Y.o, OT, I- ) if for all s, t ~ N with s < t it holds 
Ms<- Mt <_ dCoT~-(Ms). 

362 
Theorem 3.7 
(approximation of an intended model: soundness) 
Let ( Y-,o, OT, I- ) be a static view on the object-level reasoning component and N 
a model of OT (the intended model). 
a) If (MOt ~ N is a trace for (I;o, OT, I- ) with root r and M r _< N then for all 
t E N it holds M t < N, i.e.: 
Mr< 
...<Mt_<... <N 
b) Let for any t e I~1 a controlled inference function ~ 9 ISorCs 
~ ISor(7-,o) for 
OT be given. 
Then for any starting point M 0 e ISxCs a trace (MOt G 1~1 for ( Y-'o, OT, I- ) can be 
defined by: 
Mt+ 1 = Ott(Mt) 
for all t ~ I~l 
Given the formal framework as set up here, the proof of this theorem is not difficult. 
The above results show a direct connection between the semantics on the basis of 
partial models (as used here) and the classical Tarski semantics. In our terms this 
connection can be stated as follows. Reasoning of the object-level component is 
always on one specific, intended (complete) model that is a (Tarski) model of the 
knowledge base. An information state is a partial description of this intended model: a 
partial model with the intended model as one of its complete refinements. During 
reasoning this partial description is (step-wise) refined, but (in sound reasoning 
processes) always remains within the intended model. In our model reasoning can be 
viewed as constructing a partial model, approximating the intended complete model 
better and better by refinement steps: This even holds if additional observations are 
allowed, based on the intended model (this point is left out of the current paper). Since 
at any moment in time the intended complete model is not known, in principle we 
have to take into account all complete refinements of the current information state that 
are models of the knowledge base. Thus the approach discussed here relates static 
semantics and dynamic semantics to each other in one formal framework. 
3.3 
Control information and dynamic view on object-level reasoning 
In this section we will introduce a formalization of control aspects of the object-level 
reasoning. The intended model of the object-level component is (a formal 
representation of) a specific world situation. As the meta-level component reasons 
about the reasoning process of the object-level component, the intended model of this 
is a formal description of (relevant aspects of) the inference process of the object-level 
component. Considered from the viewpoint of the meta-level component, the object- 
level component can be considered as some exotic world situation with as a crucial 
characteristic that it is dynamic: each time the meta-level component starts a new 
reasoning session, its associated world situation may have changed. Note that we 
assume that object-level and meta-level reasoning processes are alternating: during the 
meta-level reasoning the object-level component is not reasoning, so changes of the 
object-level state occur only between the reasoning sessions of the meta-level 
component. 

363 
This observation leads us to introduce a control signature that defines at an 
abstract level a number of descriptors that can be used to characterize the control and 
process states of the object-level reasoning: a lexicon in terms of which all relevant 
control information can be expressed. A truth assignment to the ground atoms of such 
a meta-signature is called a control-information state. Such a control-information state 
can serve as a (partial) model for the meta-level component. The question of what are 
the semantics of the meta-level component is equivalent to the question of what is 
described by the control-information state related to an object-level component. We 
illustrate this idea by some examples (for a more specific example, see Section 6): 
- 
the fact that the object-level statement h is (currently) considered a goal for the 
reasoning process; e.g., expressed by the (ground) control-atom goal(h) where 
h is the name of an atom in the object-level language; 
- a selection or priority of object-level knowledge elements to be used; e.g., 
expressed by the (ground) control-atom rule_priority(r), where r is the name 
of a rule in the object-level knowledge base, or goalpriority(h, 0.9), with 
h as above; 
the degree of exhaustiveness 
of the reasoning; e.g., expressed by 
exhaustiveness(any), meaning that it is enough to determine only one of the 
current goals (the one with highest possible priority). 
A control-information state formalizes at a high level of abstraction the parameter 
N in a controlled inference function as introduced earlier in Section 3. We assume that 
the control-information state specifies all information relevant to the control of the 
(future) reasoning behaviour; i.e., the object-information state and the control- 
information state together determine in a deterministic manner the behaviour of the 
object-level reasoning component during its next activation. Of course it depends on 
the specific inference procedure that is used which control aspects can be influenced and 
which aspects cannot. 
In principle for execution we would expect that all atoms of the control signature 
have a truth value assigned to it (i.e. the control-information state is a complete 
model). However, we allow partial control-information states as well. 
Definition 
3.8 
(dynamic 
view on the object-level 
component) 
A dynamic view related to the static view (Zo, OT, I- ) on an object-level 
component 
is a tuple (~:c, ktoT k, X~OT ~- ) with Y'c a signature called control 
signature and ktoT ~-, ~OT ~- mappings 
~tOT k- 
'DOT ~- 
: IS(Y.o) â€¢ IS(gc) ~ 
IS(F,o) 
: IS(go) x IS(ge) ~ 
IS(ge) 
We call ~tOT ~- the (controlled) inference function for the object-level, and ~OT ~- the 
process state update function. For any N r IS(Y.r the mapping 
P~or s : IS(Y~o) -~ IS(~o) 
is defined by 
~OT N : M 1--r I~OT~(M, N) 

364 
We assume that for any N r IS(~) this IXOT N is a controlled inference function, 
i.e., it is conservative and monotonic and satisfies 
IXoTN(M) <_ dcoTv-(M) for all M ~ IS(So). 
When no confusion is expected, we will leave out the subscript and superscript of 
IXOT ~" and ~OT ~" and write shortly tx and ~. 
In a control signature sometimes reference will be made to (names of) elements of 
the language based on the object-level signature. On the other hand, also control-atoms 
are possible that do not refer to specific object-level language elements (e.g., 
exhaustiveness). We do not prescribe in a generic manner if and how reference is made 
to object-level language elements. In examples this will always be determined in a 
more specific manner. 
The process state update function expresses what the process brings about with 
respect to the process state descriptors. Examples: an object-atom was unknown, but 
becomes known during the reasoning; an object-atom that was a goal has failed to be 
found. 
The functions ~t and x~ for partial control-information states can be defined from 
the values of the functions for complete control-information states as follows: 
~(M, N) 
D(M, N) 
= 
gci {IX(M, N') I N < N' & N' complete } 
= 
gci {~(M, N') I N < N' & N' complete } 
where the greatest common information state 
gci(S) of a set S of information 
states is defined by 
gci(S)(a) 
= 
1 
if for all M e S it holds M(a) = 1 
0 
if for all M E S it holds M(a) = 0 
o 
otherwise 
A (combined) information state 
is a pair (M, N) where M 
is an object- 
information state and N a control-information state. A (combined) trace is a sequence 
of (combined) information states. An object-level execution step on the basis of a 
combined information state ( Mr, Nt) provides the successor information state 
defined by: 
( Mt+l, Nt+l ) = ( IX(Mt, Nt), x)(it, Nt) ) 
A combined reasoning trace can be obtained by alternating object-level execution 
steps and interaction steps between the two levels to obtain new control-information 
states N. We will work this out in more detail in Subsection 4.2. 

365 
4 Temporal interpretation of the meta-level reasoning 
Locally, at each of the two reasoning levels, the system behaves conservative and 
monotonic, but the whole cycle implies non-conservative changes of information 
states: the actions induced by the upward and downward reflections are not 
conservative. To describe this we can label the information states with an explicit time 
parameter (e.g., expressed by natural numbers). The non-conservatism can be covered 
by our declarative formal model, assuming each new (object-meta) cycle is labeled 
with the next (successor) time label. This approach implies that the meta-level 
reasoning component has semantics that relates states of the object-level reasoning 
component at time t to states of this component at time t + 1. In this manner, 
statements like 
"if the atom a is unknown, then the atom b is proposed as a goal" 
after downward reflection can be interpreted in a temporal manner: 
"if at time t the atom a is unknown 
then at time t + l the atom b is a goal " 
(in the object-level reasoning component) 
(for the object-level reasoning process) 
Assuming that the meta-level's proposals are always accepted (this assumption is 
sometimes called causal connection), downward reflection is just a shift in time, 
replacing the goals at the object-level by new goals (the ones proposed by the meta- 
level). This can be expressed as follows 
known(a) 
--~ 
proposed_goal(b) 
(meta-knowledge) 
C(proposed_goai(b)) 
--~ 
X(goal(b)) 
(downward reflection) 
where C means "holds in the current state" and X "holds in the next state". 
Within the meta-information involved in the meta-reasoning we distinguish two 
special types: a) information on relevant aspects of the current (control-)state of the 
object-level reasoning process (possibly also including facts inherited from the past), 
and b) information on proposals for control parameters that are meant to guide the 
object-level reasoning process in the near future. Therefore we assume that in the 
meta-signature a copy of the control signature of the object-level component is 
included as a subsignature that refers to the current state. Moreover, we assume that a 
second copy of this control signature is included referring to the proposed truth values 
for the next state of the object-level reasoning process. For example, if goal(h) is 
an atom of the control signature, then there are copies 
current_goal(h) 
and 
proposed_goal(h) in the set of atoms for the meta-signature. A syntactic function 
transforming a meta-atom into a current variant and a proposed variant of it can simply 
be defined by two (injective) mappings c and p of predicates, leaving the arguments 
the same e.g., 
c(goal) 
-- current_goal, p(goal) -- proposed_goal. 

366 
We assume that the reasoning of the meta-level itself has no sophisticated control: 
for simplicity we assume that it concerns taking deductive closures with respect to the 
inference relation used at the meta-level. Under this assumption a dynamic view on the 
meta-level component is completely determined by a static view. 
Definition 4.1 (static and dynamic view on the meta-level 
component) 
a) The signature 7-,m is called a meta-signature related to Y'c if there are two 
injective mappings c : s "-~ 7_~ and p : s ~ s 
In this case the subsignatures 
c(Y.c) and P(Y-c) are denoted by Y-an c and 7-anP; they are referring to the current 
state control-information of the object-level and the proposed state control-information 
for the object-level. 
b) The static view on the meta-level component is a tuple 
(Zm, MT, I-m ) 
with 
,V_.m 
MT 
a signature, called the meta-signature related to s 
a set of propositional ground formulae expressed in terms of 
the meta-signature 
I- m 
a classical inference relation (assumed sound but not necessarily complete) 
c) The inference function of the meta-level I, tMT~-m (or shortly lz*) 
~tMTF'm: ISMT(~-~n c) --~ ISMT(~_~n ) 
is defined by the exhaustive inference function based on I- , i.e., by the transition 
function 
~tMTF-m : N I"> dCMTF-m(N) 
This function It* defines the dynamic view on the meta-level component, related to 
the static view 
(Zm, MT, I- m ). 
Note that we essentially use propositional logic to describe the meta-language; if 
needed a propositional signature can be defined based on the set of all ground atoms 
expressible in a given (many-sorted) predicate logic signature. In fact it does not matter 
how language elements at the meta-level are denoted, but how their semantics is 
defined (in terms of the controlled inference function). 
5 Temporal models of overall reasoning patterns 
After having introduced the required concepts in the previous sections, in this section 
it will turn out to be easy to compose them to semantics for the dynamics of a meta- 
level architecture. The information states of the meta-level component of the reasoning 
system will have a direct impact on the control-information state of the object- 
component, and vice versa. These connections will be defined formally in this section. 
Notice that in our approach the object-level component and the meta-level component 
do not reason at the same time, but are alternating. 

367 
N O 
M o 
1) 
tt 
'lq 1' 
tt* 
~ t 
Iq 1 
M 1 
'1~'* 
~ down 
N 2 
1) 
Fig 2 Transitions of information states in a meta-level architecture 
In fact the following four types of actions take place (see Fig. 2). For a formal 
description, see Definitions 5.1 and 5.2 below. 
- object-level reasoning 
The reasoning of the object-level component can be described by the functions It 
and ~ as defined in Definition 3.8. 
- upward reflection 
Information from the control-information state of the object-level component is 
transformed (by a transformation function tX, p defined in Definition 5.1 below) 
to the next information state of the meta-level component. This will provide 
input information for the subsequent reasoning of the meta-level component (see 
Definition 4.1). 
- meta-level reasoning 
The reasoning of the meta-level component can be described by the inference 
function It* as defined in Definition 4.1. 

368 
- downward reflection 
Information from the of the meta-level component is transformed (by the mapping 
adown; see Definition 5.1 below) to the next control-information state to be used 
in the control of the object-level component. This will affect the reasoning 
behaviour during the subsequent object-level reasoning. 
Definition 5.1 
(meta-level architecture for dynamic control) 
a) A meta-level architecture for dynamic control is described by a tuple 
MLC = {{~.o, OT, k-o ); {~.o~ 
); {~'m, MT, ~-m) ;{c,p)) 
where 
(Zo, OT, I-o ) 
are a static and a dynamic view on the object-level component, 
(gin, MT, ["m ) 
is a static view on the meta-level component, where X m is related to the control 
signature Zc by the injective functions c : Yc ~ gm and p : Zc ~ 
Y-,m and l- m is 
an inference relation. Moreover, MT is a meta-knowledge base satisfying 
ISMT(~m c) = IS(~qn c) 
i.e., no information state in IS(gm c) is inconsistent with MT. 
Based on MLC we can define the function Ix* according to Definition 4.1. 
b) Let MLC be as in a). The upward reflection function is the mapping 
~up: IS(gc) "-~ IS(gm) 
defined for N ~ IS(Zc) and b ~ At(gm) by 
~up(N)(b) 
= 
N(a) 
if b = c(a) for some a ~ At(Xc) 
u 
otherwise 
The (left) inverse upward reflection function ~ is the mapping 
~: IS(T-~a)---) lS(Xe) 
defined for N ~ IS(Y.m) and a ~ At(Zc) by 
[~(N)(a) 
= 
N(c(a)) 
The downward reflection function is the mapping 
~down: IS(Xm) "~ IS(Y'c) 
defined for N r IS(Y_~) and a ~ At(Zc) by 
~down (N)(a) = 
1 
0 
The time shift function is the mapping 
o: IS(Y.m)~ IS(Y-m) 
defined by 
O(N)(b) 
= 
N(p(a)) 
U 
if 
N(p(a)) 
= 1 
otherwise 
if b = c(a) for some a ~ At(Zc) 
and N(P(a)) ~ u 
if b = c(a) for some a e At(Zc) 
and N(P(a)) = u 
otherwise 
Reasoning activities are modifying object-information states in a conservative manner 
(making refinements). Notice, however, that execution of upward and downward 

369 
reflection may induce non-conservative changes. Notice that we force the new control 
state resulting from downward reflection to be two-valued. This is to avoid 
nondeterministic phenomena and to allow that the meta-level only provides the 
relevant (partial) information on control. In the rest of the paper MLC will denote a 
tuple as defined in Definition 5.1. 
The following relations hold for the functions defined above: 
l]aup = id, 0~down = [~a, ff = IXepO~low n. 
Definition 
5.2 
(overall 
semantics 
based 
on traces) 
a) An overall trace for the meta-level architecture MLC is a labeled linear partial 
temporal model 
(Mt ~ NOt 9 1~ 
(also denoted by M 9 N) over 
IS(7., o ~ 7_~n ) 
with set of labels L = {re, sh} (re 
for a reasoning step, sh for a time shift step) satisfying the following conditions for 
all s, tE 
I~l: 
(i) If S<ret 
Mt 
= 
It(Ms, 13(Ns)) 
N t 
= 
It*(aup(~(Ms, ~(Ns)))) 
(it) 
IfS<sht 
Mt 
= 
Ms 
N t 
= 
It*(a(Ns)) 
b) The (intended) semantics of the meta-level architecture MLC is the set of traces 
as defined in a), denoted by Traces(MLC). 
c) A trace is called alternating if for all r, s, t ~ H and i, j e L with r <l s <j t it 
holds i ~ j. 
Although usually we are most interested in alternating traces, there may be cases were 
we are interested in other traces as well: e.g. if we allow multiple activations of the 
object-level without intervenience of the meta-level. 
Temporal models can be defined using our framework by traces of information 
states. These traces are constructed during reasoning. At each moment of time only a 
partial (in time) fragment of such a trace-model has been constructed. The set of 
completed traces can be viewed as the set of intended overall models of the meta-level 
architecture. The meta-level architecture as a whole approximates an intended model in 
a conservative manner by subsequently adding elements to the trace according to time 
steps. This view will be made more precise in the following theorem. 
Theorem 
5.3 
(approximation 
of a trace) 
Let MLC be a meta-level architecture for dynamic control. 
a) The set of alternating traces of MLC is parameterizcd by the initial states, together 
with the label (from {re, sh}) of the initial transition. 
b) Let M ~ N be a trace for MLC. Define for any time point t 
M(t)s(a) 
= 
Ms(a) 
if s ~ t or 
s = t 
u 
otherwise 

370 
N(t)s(a) 
= 
Ns(a ) 
if s ~ t or 
s = t 
u 
otherwise 
Then for all time points t it holds 
M(o) ~ N(o) < ... _< M(t)~ N(t) _< M(t+l)~ NO+l) < ...< M~N 
Notice that in this section we do not (yet) add temporal elements to the languages 
of the reasoning components themselves, but we attribute temporal semantics to the 
whole system by interpreting the object reasoning process and the downward reflection 
in a temporal manner. This means that within each of the components (locally) we 
retain our original (non-temporal) semantics. The temporal semantics only serves as a 
foundation for the composition principle to define an overall semantics composed from 
the local semantics of each of the components at the two levels. 
6 An example reasoning pattern 
To illustrate the concepts introduced here we will give a trace of a meta-level 
architecture for reasoning with dynamic hypotheses that are used as goals. The meta- 
level reasoning performs hypothesis selection whereas the object-level reasoning 
performs testing of hypotheses by trying to derive them from observation information 
(in a goal-directed manner). Control is needed to direct the object-level reasoning to the 
goal that is to be posed: the selected hypothesis. The meta-level contains declarative 
knowledge on which hypothesis to select under which circumstance (state of the 
object-level reasoning process). The downward reflection transforms this information 
about the selected hypothesis to control-information in the form of a goal set for the 
object-level reasoning; this enables the system to effectuate control. The upward 
reflection provides the information for the meta-level component on the current state 
of what is already known and what is not yet known in the object-level reasoning 
process. The knowledge in this example system is not realistic, but it enables one to 
get an impression of the reasoning pattern. 
A. Static view on the object-level reasoning component 
Object-signature (propositional): 
~'o = ( Sl, s2, s3, hl, h2 ) 
Object theory (knowledge base of the object-level component) OT: 
s 2 
^ 
s 3 
--~ 
h 1 
s 3 
^ 
s I 
--~ 
h 2 
~S 3 
--~ --ah I 
Inference relation: bch (chaining) 

371 
B. Dynamic view on the object-level reasoning component 
This reasoning component is used in a goal-directed fashion with chaining as inference 
relation. We will not involve the possibility to acquire additional information from the 
outside of the system. 
Control-signature : 
( true s 1, false s 1, 
true s 2, 
false_s2~ 
true s 3, 
known_hp 
known_h2, 
goal_hi, goal_h 2) 
false_s 3, 
Inference function: 
The dependency of the inference function Ix on the control-information state is 
concentrated in information expressed by goal-statements goal_h i (meaning that h l 
is a goal for the object-level reasoning process). As a formal definition we can take 
Ix(M, N)(a) = 
dcowF-ch(M)(a) 
if 
a = h i and N(goal_h i) = I 
M(a) 
otherwise 
Process state update function 
The process state update function ~ is defined as follows: 
The statement known_h i gets truth value 1 in the control-information state if 
in the object-information state h i has truth value 1 or 0; it gets truth value 
0 otherwise (i.e., if h i has truth value u in the object-information state). 
The statement true_s i has truth value 1 in the control-information state if in 
the object-information state 
s i has truth value 1; it gets truth value 0 
otherwise (i.e., if s i has truth value u or 0 in the object-information state). 
The statement false_s i has truth value 1 in the control-information state if in 
the object-information state 
s i has truth value 0; it gets truth value 0 
otherwise (i.e., if s i has truth value u or 1 in the object-information state). 
- The other truth values remain unchanged. 
C. Meta-level 
reasoning component 
The meta-signature 
is taken as the disjoint union of two copies of the control 
signature above: c_at (currently at), and p_at (proposed at), where at is an atom 
of the control signature. 
Knowledge base of the meta-level component (Ml'): 
c_true_s 2 
^ 
~ 
c known_h I --~ 
p_goal_h l 
c_false_s 3 ^ 
-1 c_known 
h 2 --~ 
p_goal_h 2 
The meta-level wil use chaining as its inference relation. 
The inference function Ix* is the deductive closure function under MT. 

372 
Trace of an example session 
In Fig. 3 a session with initial state (sp s2, s 3 ): (1, 1, 0 ) is described. Here 
for convenience partial models are denoted by the list of atomic statements and 
negations of atomic statements that are true. For the (combined) information states 
(named 
Pl) of the object-level component both the object-information states and the 
control-information states are depicted (separated by a colon ;). For the meta-level 
component only the object-information states are depicted (named ti). For shortness 
only some relevant (literal) facts are written in the information states. 
object-level component 
meta-level component 
PO : [Sl, s2, "9s3l; [ ~ kn~ 
1, "~ known_h 2 ] 
Pl : [Sl, s2, -'s3]; [ trues2, ~known_h 1, ~ known_h 2 ] 
to: [ c_trues 2, -~c_known h 1, -~ c_known_h 2 ] 
tl: [ ctrue_s 2, ~ c_known_h 1, ~c_known_h2, p_goal_h I ] 
P2 : [Sl' s2' "~s3 ]; [ true--s2, ~ kn~ 
"~ kn~ 
g~ 
] 
P3 : [ Sl' s2' -~s3' ~hl ]; [ trues2' false-s3, kn~ 
~ kn~ 
] 
t2: [ c_true_s 2, c_falses 3, c_known_hl, ~c known_h2] 
t3: [ c_trues 2, c_faise_s 3, c_known_h 1, -,c_known_h2, p_goal_h 2 ] 
P4 : [ Sl' s2' TM S3~ ~ hi ]; [ true-s2, false-s3, kn~ 
-" kn~ 
g~ 
] 
P5 : [ Sl' s2' -~ s3' -1 hi, h2 ]; [ truesl' true-s2, falses3, kn~ 
kn~ 
] 
Fig 3 Trace of an example session 
This example shows that it does not matter how language elements at the meta- 
level are denoted, but how their semantics is defined. Using a propositional language 
at the meta-level is possible, but the more concise syntactical notation of predicate 
logic has practical advantages. Therefore, often a predicate logic language is used at the 
meta-level. For the semantics of the whole reasoning pattern this makes no essential 
difference. 

373 
7 
Conclusions 
The semantic framework as discussed provides integration of static and dynamic 
aspects in two different forms. On the one hand we connect the partial semantics as 
used to describe information states to the standard Tarski semantics: a partial model 
corresponds to the set of all of its complete refinements. On the other hand the 
integration between static and dynamic aspects takes place by introducing the notion of 
an explicit (declarative) control-information state in the object-level component. 
Our logical framework has been partly inspired by Weyhrauch's view on the role 
of partial models (or simulation structures) in meta-level architectures ([25], [9]). What 
is different in our case is that the partial models may be dynamic. Furthermore, 
similarities can be found to the approach called dynamic interpretation of natural 
language (e.g., see [7], [10], [11]). In this approach the dynamic interpretation of a 
sentence in natural language is defined as an operator that transforms the current 
information state into a new one where the content of the sentence is included. 
With respect to dynamics the type of meta-level architecture covered here is less 
restricted than sometimes studied in logical approaches, where meta-level predicates are 
meant to express only static properties of the object-level, e.g., provability, et cetera. 
We believe that the semantic model as discussed here can help to bridge the gap 
between the (more restricted) logic-based approaches and (less restricted) procedural 
approaches to meta-level architectures. 
It is not difficult to use our framework to model meta-level reasoning that looks 
ahead more than one step. One can transfer a part of the information at the meta-level 
over the time shift and thus connect the reasoning in different activations of the meta- 
level. The results presented here can also be extended easily to the case of higher meta- 
levels where also the control of the meta-level is guided in a dynamic manner (in this 
case a refinement of the time scale can be made). 
Our logical framework has been implemented and applied in a number of practical 
applications, often in projects in cooperation with companies (e.g., [4], [8] ), and has 
also been used to model an approach to defeasible reasoning with explicit control (see 
[18], [19] ). The type of meta-level architecture as discussed can be designed and 
formally specified using our formal specification framework DESIRE (framework for 
DEsign and Specification of Interacting REasoning modules; see [14]). In DESIRE 
various types of reasoning components are covered; e.g., goals can be used to guide 
the reasoning, and various measures of exhaustiveness can be used (for a more 
extensive survey, see [14]). By means of DESIRE complex reasoning systems can be 
designed and specified according to what we call a compositional architecture: an 
architecture composed from a number of formally specified reasoning components 
using formal and standard composition principles (see [14]). 
In our current practical applications (using DESIRE) of the framework as 
described the control-information states are two-valued, i.e., no u's occur as truth 
values. In other words: at each moment all state descriptors defined by the control 
signature have a determined truth value. On the one hand this corresponds to the 
intuition that, since the meta-level reasoning is about the states of the object-level 
reasoning process, input information about this can be acquired from the system itself: 
there is essentially no incompleteness of incoming information. On the other hand the 

374 
two-valuedness of the control-information states is related to the fact that we require 
that the control of the object-level reasoning is completely determined by the truth 
values of the control-atoms, and vice versa. Therefore, if we require complete 
deterministic specification of the behaviour of the reasoning system, all control-atoms 
should have determined truth values (and vice versa). If we would allow non- 
deterministic control (e.g., by only specifying some, but not all aspects of the 
control), the control-information states may be viewed as essentially three-valued. 
Since for the notion of a compositional architecture and the framework DESIRE, 
an essential use is made of the notion of a meta-level architecture, the (formal) 
semantics of the static and dynamic semantics of DESIRE depend on these semantics 
of meta-level architectures. In literature not much work is reported on such 
foundations. As this paper contributes an approach to the semantics of meta-level 
architectures, this can be used to work out a semantics for DESIRE. This work is 
planned in the near future. 
Acknowledgements 
Guszti Eiben, Joeri Engelfriet and Pieter van Langen have read and commented upon 
earlier drafts of this paper. This, and the reviewers comments have led to a number of 
improvements in the text. 
References 
1. 
2. 
3. 
J.F.A.K. van Benthem, The logic of time: a model-theoretic investigation into the 
varieties of temporal ontology and temporal discource, Reidel, Dordrecht, 1983. 
S. Blarney, Partial Logic, in: D. Gabbay and F. Guenthner (eds.), Handbook of 
Philosophical Logic, Vol. III, 1-70, Reidel, Dordrecht, 1986. 
K. Bowen and R. Kowalski, Amalgamating language and meta-language in logic 
programming. In: K. Clark, S. Tarnlund (eds.), Logic programming. Academic Press, 
1982. 
4. 
5. 
6. 
H.A. Brumsen, J.H.M. Pannekeet and J. Treur, A compositional knowledge-based 
architecture modelling process aspects of design tasks, Proc. 12th Int. Conf. on AI, 
Expert systems and Natural Language, Avignon'92 (Vol. 1), 1992, pp. 283-294. 
W.J. Clancey and C. Bock, Representing control knowledge as abstract tasks and 
metarules, in: Bolc, Coombs (eds.), Expert System Applications, 1988. 
R. Davis, Metarules: reasoning about control, Artificial Intelligence 15 (1980), pp. 
179-222. 
7. 
T. Fernando, Transition systems and dynamic semantics, Proc. JELIA'92 Workshop on 
Logic and AI, Berlin, 1992. 

375 
8. 
P.A. Geelen and W. Kowalczyk, A knowledge-based system for the routing of 
international blank payment orders, Proc. 12th Int. Conf. on AI, Expert systems and 
Natural Language, Avignon-92 (Vol. 2), 1992, pp. 669-677. 
9. 
E, Giunchiglia, P. Traverso and F. Giunchiglia, Multi-context Systems as a 
Specification framework for Complex Reasoning Systems, In: [24], 1993, pp. 45-72. 
10. R. Goldblatt, Logics of Time and Computation. CSLI Lecture Notes, Vol. 7. 1987, 
Center for the Study of Language and Information. 
11. J.A.W. Kamp, A theory of truth and semantic representation, In: Formal methods in 
the study of language. Mathematical Centre Tracts 135, Amsterdam, 1981. 
12. P.H.G. van Langen and J. Treur, Representing world situations and information states 
by many-sorted partial models, Report PE8904, University of Amsterdam, Department 
of Mathematics and Computer Science, 1989. 
13. T. Langholm, Partiality, Truth and Persistance, CSLI Lecture Notes No. 15, Stanford 
University, Stanford, 1988. 
14. I.A. van Langevelde, A.W. Philipsen, J. Treur, Formal specification of compositional 
architectures, In: B. Neumann (ed.), Proc. 10th European Conference on Artificial 
Intelligence, ECAI'92, Wiley and Sons, 1992, pp. 272-276. 
15. J.W. Lloyd, Foundations of logic programming, Springer Verlag, 1984. 
16. P. Maes, D. Nardi (eds), Meta-level architectures and reflection, Elsevier Science 
Publishers, 1988. 
1 7. Y.H. Tan and J. Treur, A bi-modular approach to nonmonotonic reasoning, In: De Glas, 
M., Gabbay, D. (eds.), Proc. World Congress on Fundamentals of Artificial 
Intelligence, WOCFAr91, 1991, pp. 461-476. 
18. Y.H. Tan and J. Treur, Constructive default logic and the control of defeasible 
reasoning, In: B. Neumann (ed.), Proc. 10th European Conference on Artificial 
Intelligence, ECAI'92, Wiley and Sons, 1992, pp. 299-303. 
19. Y.H. Tan and J. Treur, Constructive default logic in a meta-level architecture, in: A 
Yonezawa, B.C. Smith (eds.), Proc. International Workshop on new Models in 
Software Architecture (IMSA) 1992, Reflection and Meta-level Architectures, 1992, 
pp. 184-189. 
20. J. Treur, Completeness and definability in diagnostic expert systems, Proc. European 
Conference on Artificial Intelligence, ECAI'88, Miinchen, 1988, pp. 619-624. 
21. J. Treur, On the use of reflection principles in modelling complex reasoning, 
International Journal of Intelligent Systems 6 (1991), pp. 277-294. 
22. J. Treur, Declarative functionality descriptions of interactive reasoning modules, In: 
H. Boley, M.M. Richter (eds.), Processing Declarative Knowledge, Proc. of the 
International Workshop PDK'91, Lecture Notes in Artificial Intelligence, vol. 567, 
Springer Verlag, 1991, pp. 221-236. 
23. J. Treur, P. Veerkamp, Explicit representat!on of design process knowledge, in: J.S. 
Gero (ed.), Artificial Intelligence in Design '92, Proc. AID'92, Kluwer Academic 
Publishers, 1992, pp. 677-696. 

376 
24. J. Treur and Th. Wetter (eds.), Formal Specification of Complex Reasonirig Systems, 
Ellis Horwood, 1993, pp 282. 
25. R.W. Weyhrauch, Prolegomena to a theory of mechanized formal reasoning, Artificial 
Intelligence 13 (1980), pp. 133-170. 

G6del as a Meta-Language 
for Composing Logic Programs 
Antonio Brogi and Simone Contiero 
Dipartimento di Informatica, Universitg di Pisa 
Corso Italia 40, 56125 Pisa - Italy 
Abstract. Increasing attention is being paid to GSdel, a new declara- 
tive programming language aimed at diminishing the gap between the- 
ory and practice of programming with logic. An intriguing question is 
whether or not existing logic programs can be suitably re-used in GSdel. 
We investigate the possibility of employing GSdel as a meta-language 
for re-using and composing existing definite programs. Two alternative 
implementations of 9 set of mete-level operations for composing defi- 
nite programs are presented. The first implementation consists of an 
extended vanilla meta-interpreter using the non-ground representation 
of object level programs. The second implementation exploits the meta- 
programming facilities offered by GSdd, which support the construction 
of meta-interpreters using the ground representation of object level pro- 
grams. 
1 
Introduction 
The idea of programming with logic [15] found its first realisation in the Prolog lan- 
guage, which has been widely considered as the logic programming language for the 
last twenty years. The development of logic programming, however, has shown the de- 
ficiencies of Prolog as a declarative language and the consequent gap between theory 
and practice of programming with logic [2]. Several efforts have been devoted to design 
new programming languages aimed at being the declarative successors of Prolog (e.g., 
[9, 22]). The GSdel language [14] is starting to emerge as a new declarative general- 
purpose programming language in the family of logic programming languages. GSdel 
is a strongly typed language, has a module system and places considerable emphasis 
on meta-programming. These features of G5dcl, in particular the emphasis on meta. 
programming, suggest the intriguing question whether or not existing logic programs 
can be suitably re-used in G5del. 
The ultimate objective of this work is to investigate the adequacy of GSdel as a meta- 
language for re-using and composing existing definite programs. In this perspective, we 
consider a simple extension of logic programming which consists of introducing a set 
of meta-level operations for composing definite programs. These operations, originally 
presented in [4, 19], form an algebra of logic programs with interesting properties for 
reasoning about programs and program compositions. From a programming perspec- 
tive, the operations enhance the expressive power of logic programming by supporting 
a wealth of programming techniques, ranging from software engineering to ~rtificial 
intelligence applications [5, 6, 7]. In this paper the implementation in GSdel of such a 
set of program composition operations is discussed. 

378 
Meta-level operations over object level programs can be naturally implemented by 
means of meta-programming techniques. More precisely, as shown in [4, 6], several 
composition operations over logic programs can be implemented by extending the well 
known vanilla meta-interpreter [24]. The actual realisation of extended vanilla meta- 
interpreters in GSdel presents various implementation choices that lead to different 
solutions. One of these choices is the representation of object level constructs, which 
is one of the crucial issues in meta-programming. In logic programming, object level 
expressions are usually represented by terms at the meta-level, and the critical issue 
is how to represent object level variables at the meta-level. Two basic alternative rep- 
resentations of object level variables are employed, as ground terms and as variables 
(or, more generally, non-ground terms). The first is called ground representation mad 
the second non-ground representation [13]. The ground representation is very versatile 
and adequate for many applications of meta-programming, such as program transfor- 
mation and compiler writing. Though the non-ground representation is less versatile, 
it has been widely adopted in the practice of meta-programming with logic, e.g. for the 
construction of several expert systems [24]. Indeed, in the absence of suitable support 
for managing the complexity of meta-programming with the ground representation, 
programmers have been attracted by the simplicity and et~ciency of the non-ground 
representation, which are due to the fact that the non-ground representation directly 
exploits the basic unification mechanism of the meta-language. A thorough discussion 
of the two representations can be found for instance in [8, 13, 16, 17, 20, 23]. 
Two alternative implementations in G6del of program composition operations are pre- 
sented here. Both implementations are based on an extended vanilla meta-interpreter, 
and they differ in the choice of the representation of object level programs. 
The first implementation adopts the non-ground representation of object level pro- 
grams. This choice offers a simple and concise way of extending the vanilla meta- 
interpreter to deal with program composition operations. The implementation is equip- 
ped with suitable support for the non-ground representation, which is not directly sup- 
ported by the G6del system. This support frees the user from the need of explicitly 
providing the non-ground representation of object programs. 
The second implementation adopts the ground representation of object level pro- 
grams, for which GSdel provides considerable support. The GSdel approach to meta- 
programming is strongly based on abstract data types. For instance, the system module 
Programs offers a large number of operations on an abstract data type that is the type 
of terms representing object level programs. The abstract data type view supports a 
declarative high-level style of meta-programming as the user has to be concerned nei- 
ther with the internal representktion of the data type nor with the implementation 
of the associated operations. The ground representation offered by GSdd, however, 
relies on a naming policy that does contrast with the naming policy employed in the 
context of logic program composition. We show how this problem can be tackled by 
suitably extending GSdel's support for generating the ground representation of object 
programs. 
The two implementations are then compared in order to highlight the merits of the 
alternative representations and, most important, the adequacy of GSdel as a meta- 
language for composing logic programs. The analysis of the implementations also out- 
lines some possible extensions of GSdel which may improve the flexibility of the lan- 
guage. 

379 
The plan of the paper follows. A suite of meta-level operations for composing logic pro- 
grams is introduced in Section 2. Two alternative implementations of these operations 
in GSdel are described in Sections 3 and 4. Finally in Section 5 some conclusions are 
drawn. 
2 
Program Composition Operations 
This section is devoted to briefly introduce a set of composition operations that form 
an algebra of logic programs, originally defined in [4, 19]. 
Four basic operations for composing definite logic programs are introduced: Union (de- 
noted by U), intersection (n), encapsulation (*), and import (4).The operations are 
defined in a semantics-driven style, following the intuition that if the meaning of a pro- 
gram P is denoted by the corresponding immediate consequence operator T(P) then 
such a meaning is a homomorphism for several interesting operations on programs. 
Notice that the standard least tterbrand model semantics of logic programming is not 
appropriate to model compositions of programs in that it does not enjoy the com- 
positionality requirement. In fact, the least Herbrand model of a program cannot be 
obtained, in general, from the least Herbrand models of its clauses. Each program P is 
therefore denoted by the corresponding T(P). 
Recall that, for a logic program P, the immediate consequence operator T(P) is a 
continuous mapping over Herbrand interpretations defined as follows [25]. For any 
Herbrand interpretation I: 
A e T(P)(I) ~ 
(3/~: A *-- B e ground(P) A [3C_I) 
where B is a (possibly empty) conjunction of atoms and ground(F) denotes the ground 
version of program P. The powers of T(P) are defined as nsual [1]: 
T O (P)(I) = I 
T "+1 (P)(I) = T(P) (T"(P)(I)) 
T~(R)(I) = U T"(P)(I). 
The semantics of program compositions can be given in a compositional way by ex- 
tending the definition of T with respect to the first argument. For any Herbrand inter- 
pretation I: 
T(P U Q)(I) = T(P)(I) U T(Q)(I) 
T(P N Q)(I) = T(P)(I) n T(Q)(I) 
T(P')(I) = T~(P)(0) 
T(P ~ Q)(I) = T(P) (I u T~(Q)(O)) 
The above definition generalises the notion of immediate consequence operator from 
programs to compositions of programs. The operations of union and intersection of 
programs directly relate to their set-theoretic equivalent. For any interpretation I, the 
set of immediate consequences of the union (resp. intersection) of two programs is 
the set-theoretic union (resp. intersection) of the sets of immediate consequences of 

380 
the separate programs. For any interpretation I, the formulae that may be derived in 
an encapsulated program P* are all the formulae that may be derived from P in an 
arbitrary (finite) number of steps. Finally, for any interpretation I, the set of immediate 
consequences of the import of two programs P 4 Q is the set of formulae that may be 
derived in the importing program P in a single deduction step from I and from the set 
of formulae that may be derived in the imported program Q in an arbitrary (finite) 
number of steps. 
The operations U, N, 9 and ,~ satisfy a number of algebraic properties such as associa- 
tivity, commutativity and distributivity. The resulting algebra [4] extends the algebra 
presented in [19] and provides a formal basis for proving properties of program com- 
positions. For instance, syntactically different program compositions may be compared 
and simplified by means of the properties of program composition operations. 
Program composition operations can be equivalently defined by characterising the op- 
erational behaviour of program compositions. Such a characterisation can be expressed 
by directly extending the standard notation of SLD refutation [1, 18, 25] to deal with 
program expressions. The standard SLD refutation relation may be defined by means 
of inference rules of the form 
Premise 
Conclusion 
asserting that Conclusion holds whenever Premise holds. We write P l- G if there 
exists a refutation for a goal G in a program P. 
P F Empty 
(1) 
PFGa A Pt-G~ 
e ~- (a~, G~) 
(2) 
PF(A*--G) A PFG 
P I- A 
(3) 
Rule (1) states that the empty goM, denoted by Empty, is solved in any program 
P. Rule (2) deals with conjunctive goals. It states that a conjunction (G1, G2) is solved 
in a program P if Ga is solved in P and G2 is solved in P. Finally, rule (3) deals with 
atomic goal reduction. To solve an atomic goal A, choose a clause from program P and 
recursively solve the body of the clause in P. Notice that, for the sake of simplicity, 
substitutions are omitted in that we are interested here in characterising only the 
(ground) success set of a program. 
Program clauses are represented by means of the following rule: 
P is a plain program A A *-- G E ground(P) 
P ~ (A ,-- G) 
(4) 
The derivation relation F can be generalised to the case of program compositions in 
a simple way. Namely, each composition operation is modelled by adding new inference 
rnles to rules (1)--(4). 

381 
P ~ (a ~- G) 
P U O F (A ~-- G) 
(5) 
Q ~ (A ~- G) 
e U Q t- (A ,--- G) 
(6) 
PI-(A~--G1) A QF(A*--G2) 
e n Q ~ (A ~- G1, G~) 
(7) 
P~-A 
P* I- (A 4--- Empty) 
(8) 
PF(A*--G1,G2) ^ QI-Gz 
P ~ Q ~- (A *-- al) 
(9) 
Rules (5) and (6) state that a clause A ,-- G belongs to the program expression 
P U Q if it belongs either to P or to Q. Rule (7) states that a clause A *-- G belongs 
to P n Q if there is a clause A 4-- GI in P and a clause A ~ G~ in Q such that 
G = (G1, G2). Rule (8) states that the program expression P* contains a unit clause 
A ~-- Empty for each atom A that is provable in P. Finally, rule (9) deals with the 
import operation. It states that the clauses in P ,a Q are obtained from the clauses in 
P by dropping the calls to Q, provided that they are provable in Q. 
The extended derivation relation t- defined by rules (1)--(9) characterises the oper- 
ational behaviour of arbitrary composition of programs. It is worth noting that the 
operational and the T(P)-based definitions are equivalent. As shown in [4], for any 
program expression P: 
AeT~(P)(0) 
r 
PFA. 
The use of the composition operations tO, N, * and <t for programming finds natural 
application in several domains, ranging over expert systems, hypothetical and hierar- 
chical reasoning, knowledge assimilation and modularisation. The description of such 
applications is outside the scope of this paper and is reported in [4, 5, 6, 7]. 
3 
Non-Ground Representation of Object Programs 
We now present a first implementation in G5del of the set of program composition oper- 
ations introduced in the previous Section. The implementation consists of an extended 
vanilla meta-interpreter using the non-ground representation of object level programs. 
The definition of the vanilla meta-interpreter in GSdel is illustrated in Subsection 
3.1. The extended meta-interpreter is presented in Subsection 3.2, and the associated 
support for the non-ground representation of object definite programs is described in 
Subsection 3.3. 
3.1 
Vanilla Meta-Interpreter 
The standard vanilla meta-interpreter [24] using the non-ground representation of ob- 
ject programs can be written in G6del as illustrated in Chapter 10 of [14]. We consider 
here a more general form of the vanilla meta-interpreter, where the Solve predicate 

382 
has an extra argument to explicitly denote the name of the object program to be in- 
terpreted. The module Vanilla below contains the definition of this more general form 
of the vanilla meta-interpreter in GSdel. 
MODULE 
IMPORT 
PREDICATE 
DELAY 
Vanilla. 
Object_Program. 
Solve : Program_Name *OFormula. 
Solve(x,y) 
UNTIL GROUND(x) ~ NONVAR(y). 
Solve(x, Empty). 
Solve(x, y And z) <- Solve(x, y) & Solve(x, z). 
Solve(x, y) <- Statement(x, y If z) & Solve(x, z). 
According to GSdel's syntax, the PREDICATE declaration declares Solve to be a binary 
predicate whose first argument has type Program_Name and whose second argument 
has type 0Formula. The type Program.Name is used for the type of meta-level terms 
representing the name (viz. a constant) of the object level program. The type 0Formula 
is used for the type of meta-level terms representing object level formulae. The con- 
nectives & and <- are represented by the functions And and If, respectively. The DELAY 
declaration is a control declaration stating that calls to Solve will delay until first ar- 
gument (i.e. the program name) is ground and the second argument is not a variable. 
Statements in the object program to be interpreted are represented in the imported 
module 0bject_Program using the predicate Statement and the constant Empty. 
The module 0bject_Program (imported by Vanilla) contains the meta-level represen- 
tation of the program to be interpreted. For instance, consider the program consisting 
of the module M below, which defines the relations Arc and Path over a graph. 
MODULE 
M. 
BASE 
Node. 
CONSTANT 
Bristol, London, Pisa : Node. 
PREDICATE Arc, Path : Node * Node. 
Path(x, y) <- Arc(x, y). 
Path(x, y) <- Arc(x, z) & Path(z, y). 
Arc(Bristol, London). 
Arc(London, Pisa). 
The meta-level representation of M is reported below. Object level symbols are repre- 
sented by themselves, including object level variables which are represented by meta- 
level variables. 
EXPORT 
BASE 
CONSTANT 
FUNCTION 
Object_Program. 
Program_Name, 0Formula, Node. 
Empty :OFormula; 
M : Program_Name; 
Bristol, London, Pisa : Node. 
And : xFy(110) : 0Formula *OFormula -> OFormula; 
If : xFy(lO0) : 0Formula *OFormula -> 0Formula; 

383 
Arc, Path : Node * Node -> 0Formula. 
PREDICATE 
Statement : Program_Name * 0Formula. 
LOCAL 
0bject_Program. 
Statement(N, Path(x,y) If Arc(x,y)). 
Statement(g, Path(x,y) If Arc(x,z) And Path(z,y)). 
Statement(g, Arc(Bristol,London) If Empty). 
Statement(g, Arc(Londen,Pisa) If Empty). 
According to GSdel's syntax, the module Object_Program consists of an EXPORT and 
a LOCAL part. The EXPORT part contains the declarations of types, constants, func- 
tions and predicates that are exported by the module. The BASE declaration declares 
the types used in the object program (viz. Node), as well as the types ProgramJame 
and OFormula, which are also used in the importing module Vanilla. The CONSTANT 
declaration declares the constant Empty, the name of the object program to be inter- 
preted, and the constants occurring in the object program. The FUNCTION declaration 
declares the function symbols used in both modules (If, And), as well as the object 
level predicates (e.g. Arc), which are represented by functions at the meta-level. Notice 
that the module conditions of G6del require that types, constants and functions used 
in both modules (such as OFormula, Empty and If) must be declared in the imported 
module 0b jeer_Program. Finally, the LOCAL part of module Object_Program contains 
the clauses defining the predicate Statement, which is used to represent the object 
program to be interpreted by the vanilla meta-interpreter. 
It is worth making a couple of remarks here. First, the lack of parametric modules in 
G6dd does not allow a flexible use of the Solve meta-interpreter since the name of the 
module containing the object program to be interpreted must be fixed in the module 
Vanilla. The availability of parametric modules would increase the flexibility of G5del 
and, in particular, the possibility of parameterising a module w.r.t, the modules to be 
imported would allow a more flexible use of the meta-interpreter. Second, G~dd does 
not provide any special support for meta-programming with the non-ground represen- 
tation. This means that, though it is easy to write a vanilla meta-interpreter in GSdel, 
the non-ground representation of the object programs must be given explicitl~; 
by the 
programmer [14]. 
3.2 
Extended Vanilla Meta-Interpreter 
The Solve meta-interpreter can be extended in a simple and concise way in order to 
implement meta-level operations for composing logic programs. Following [4, 6], each 
program composition operation is represented at the meta-level by a function symbol: 
U by Union, I"1 by Intersection, 9 by Encapsulate, and ~ by Import. The idea is 
to use the first argument of Solve for representing arbitrary compositions of object 
programs, such as P Union Q, rather than just a single object program. The meaning 
of each function symbol denoting a program composition operation can be defined by 
extending the definition of the vanilla meta-interpreter. Intuitively, this corresponds to 
turning the inference rules given in Section 2 into meta-level axioms. 
The following module Extended_Vanilla contains the definition of the Solve meta- 
interpreter suitably extended to deal with programs composition operations. 

384 
EXPORT 
IMPORT 
PREDICATE 
DELAY 
Extended_Vanilla. 
Object_Programs. 
Solve : Program_Expression * OFormula. 
Solve(x,y) 
UNTIL GROUND(x) & NONVAR(y). 
LOCAL 
Extended_Vanilla. 
PREDICATE 
Clause : Program_Expression * OFormula. 
Solve(x, Empty). 
Solve(x, y And z) <- 
Solve(x, y) 
Solve(x, z). 
Solve(x, y) <- 
Clause(x, y If z) & 
Solve(x, z). 
Clause(x Union y, z If w) <- 
Clause(x, z If w). 
Clause(x Union y, z If w) <- 
Clause(y, z If v). 
Clause(x Intersection y, z If (wl And ~2)) <- 
Clause(x, z If wl) & 
Clause(y, z If w2). 
Clause(Encapsulate(x), y If Empty) <- 
Solve(x, y). 
Clause(x Import y, w If z) <- 
Clause(x, , If u) & 
Partition(u, z, v) & 
Solve(y, v). 
Clause(x, y If z) <- 
Statement(x, y If z). 
The EXPORT part contains the declaration of the predicate Solve, whose first argument 
now has type Program.Expression. This is the type of a meta-level term representing a 
program expression, that is a term constructed via the functions Union, Intersection, 
Encapsulation and Import starting from a set of program names. 
The definition of Solve in the LOCAL part of Extended..Vanilla extends the definition 
of Solve given in the module Vanilla. The only differences axe the type of the first 
argument (which is now Program_Expression) and the substitution of the predicate 
Statement with a new predicate Clause. The latter is introduced for the meta-level 
representation of compositions of object programs. Intuitively speaking, the definition 
of Clause extends the definition of Statement by induction on the structure of program 
expressions. For instance, the definition of Clause in the case of Union states that a 
clause z <- w belongs to the meta-level representation of a program composition x 
U y if it belongs either to the meta-level representation of x or to the meta-level 
representation of y. The definition of Clause for Intersection states that a clause z 
<- (u k v) belongs to the meta-level representation of the composition x N y if zl 
<- wl belongs to the meta-level representation of x, z2 <- w2 belongs to the meta- 
level representation of y, z! and z2 unify via a mgu tg, and z = (zl)#, and (u ~ v) 
= (wl ~ w2)#. Notice that the adoption of the non-ground representation of object 

385 
programs allows this statement to exploit the basic unification mechanism. The meta, 
level representation of an encapsulated program expression Encapsulate (x) consists of 
assertions of the form Clause (Encapsulate (x), y If Empty) for each y provable in x. 
The Import operation is defined as follows. The statements in a composition x Import 
y are obtained from the statements of x by possibly dropping part of their body if 
this is provable in the imported y and possibly instantiating the remaining part of the 
body. Finally the last definition of Clause resorts to the predicate Statement (used to 
represent the single object programs to be composed), which is defined in the imported 
module 0bject_Programs. 
Basic modularity principles suggest that the Solve vanilla meta-interpreter and the 
representation of the object programs should be arranged into separate modules. Such 
a separation makes it easier to use the meta-interpreter with different collections of 
object programs. The structuring of the module Extended_Vanilla partly supports 
such a possibility in the sense that the meta-interpreter and the representation of the 
object programs are arranged into two separate modules: 
Extended_Vanilla 
I 
Obj ect_Programs 
Notice that such a separation requires the employment of two predicates (Clause and 
Statement) for the meta-level representation of object program compositions. This is 
due to the module conditions of G6del that do not allow to spread the definition of a 
predicate over different modules. 
We also implemented a more modular solution that establishes a one-to-one correspon- 
dence between object level programs and G6del modules containing their meta-level 
representation, as illustrated by the following figure: 
Extended~anilla 
Object2rograms 
/ 
I 
\ 
Object~rogram_l 
... 
Object_Program_N 
Language 
Roughly speaking, each object program P_i is represented by means of a predicate 
Statement_i defined in a G6del module 0bject_Programi In this second implementa- 
tion, 0bject_Programs simply plays the role of a bridge between the extended vanilla 
meta-interpreter and the representation of the object programs, and contains a clause 
Statement(x, y If z) <- Statement_i(x, y If z). 
for each imported module 0bject_Program_i. Finally, types and symbols used in both 
modules are declared in the module Language at the bottom of the hierarchy, as re- 
quired by GSdd's module conditions. 

386 
3.3 
Support for the Non-Ground 
Representation 
As we pointed out, G6del provides considerable support for meta-programming with the 
ground representation, while it does not provide any special support for the non-ground 
representation. This means that, though it is easy to write a vanilla meta-interpreter in 
G6del, the non-ground representation of the object programs must be given explicitlyby 
the programmer. When using G6del as a meta-language for composing object definite 
programs, the problem is how to automatically generate a G6del module containing 
the non-ground representation of a (collection of) given object definite program(s). 
In order to free programmers from the need of explicitly providing the non-ground 
representation of their object definite programs, we developed suitable support for the 
generation of such a representation. The main issue to be faced is concerned with types, 
since G6del is a strongly typed language while definite programs do not contain any 
type declaration. One solution might be to try to infer as much type information as 
possible from the object program, by resorting to program analysis techniques (e.g. 
[3]). Rather than trying to infer (incomplete) type information from untyped logic 
programs, we simply employed a single type 0Term to represent any object level term. 
The module Non_Ground_I0 supports the generation of the non-ground representation 
of a (collection of) object definite program(s) to be imported by the Extended_Vanilla 
module. Notice that we actually implemented two variants of the support correspond- 
ing to the two module structures for the extended vanilla presented in the previous 
Subsection. Since these supports have a similar structure we shall discuss only the 
support for the first solution. 
EXPORT 
IMPORT 
PREDICATE 
DELAY 
Non_Ground_IO. 
FlocksIO. 
Represent : List(String) * String. 
Represent(x,y) UNTIL GROUND(x) & GROUND(y). 
Non_Ground_.I0 imports FlocksI0, containing the abstract data type Flock that has 
revealed to be very convenient for the parsing of the files containing the object logic 
programs. The predicate Represent can be used to generate the non-ground represen- 
tation of a collection of object definite programs. The first argument of Represent is a 
list of strings that denotes the names of the files containing the definite programs to be 
represented at the meta-level. The second argument of Represent is a string denoting 
the name of the G6del module in which the non-ground representation of the object 
programs will be written. Notice that if the object level programs are intended to be 
interpreted by the vanilla meta-program of module Extended_Vanilla then the second 
argument of Represent is necessarily the string "0b jeer_Programs", since G6del does 
not provide parametric modules at the moment. The possibility of specifying the name 
of the target G6del module is however offered by the support also in the perspective 
of the availability of parametric modules in the near future [12]. 
To illustrate the use of the support, suppose that the user wants to query program 
expressions obtained by composing a collection of given object definite programs. First, 
the non-ground representation of the object programs is generated by means of the 
module Non_Ground_I0 that creates the G6del module 0b jeer_Programs. 
[Non_Ground_ IO] <- Represent ( ["P", "O", "R"], "Obj ect_Programs" ). 

387 
Then, the user loads the module Extended_Vanilla (which imports 0bject_Programs) 
and queries it by means of meta-level goals such as 
[Extended_Vanilla] <- Solve(P Union (q Import R), G(x)). 
4 
Ground Representation of Object Programs 
We now present a second implementation of the set of program composition operations 
introduced in Section 2. This second implementation exploits the meta-programming 
facilities offered by GSdel for the ground representation of object level programs. As in 
the previous Section, the vanilla meta-interpreter is illustrated first. Then we show the 
extended meta-interpreter and the associated support for the generation of the ground 
representation of object logic programs. 
4.1 
Vanilla Meta-Interpreter 
G~lel provides considerable support for meta-programming with the ground repre- 
sentation, in which object level expressions are represented by ground terms at the 
meta-level. For instance, the vanilla meta-interpreter discussed in Subsection 3.1 (too- 
dule Vanilla) can be written in G5del using the ground representation of object level 
programs [10], as illustrated in the module Ground_Vanilla below. 
EXPORT 
Ground_Vanilla. 
IMPORT 
Programs. 
PREDICATE Demo 
: Program* Formula * TermSubst. 
LOCAL 
Ground_Vanilla. 
Demo(program, goal, answer) <- 
StandardiseFormula(goal, O, vat_index, new_goal)& 
EmptyTermSubst(empty_subst) & 
Solve(program, new_goal, var_index, _, empty_subst, subst) & 
RestrictSubstToFormula(new_goal, subst, answer). 
PREDICATE 
Solve : Program * Formula * Integer * Integer * TermSubst * TermSubst. 
Solve(program, goal, v, v, subst, subst) <- 
EmptyFormula(goal). 
Solve(program, goal, v_in, v_out, subst_in, subst_out) <- 
And(left. right, goal) 
Solve(program, left, v_in. new_v, subst_in, new_subst) E 
Solve(program, right, new_v, v_out, new_subst, subst_out). 
Solve(program, goal. v_in, v_out, sub_in, sub_out) <- 
Atom(goal) 
MyStatementMatchAtom(program, goal, stment) 
Resolve(goal, stment, v_in, ne,_v, sub_in, new_sub, new_goal) & 
Solve(program, new_~oal, new_v, v_out, new_sub, sub_out). 
The module Ground-Vanillaimports the system module Programs, wh~h contMns a 
variety of predicates for handing the ground representation of G6del programs. The 

388 
PREDICATE declaration declares Demo to be a ternary predicate with arguments of type 
Program, Formula and TermSubst, which represent the ground representation of a pro- 
gram, of a formula and of a term substitution, respectively. 
The LOCAL part of Ground_Vanilla contains the definition of the predicate Demo. The 
Demo predicate first calls the predicates StandardiseFormula and EmptyTermSubst to 
initialise the variables in the object goal and to get the representation of the empty sub- 
stitution. Damo then calls Solve that performs the interpretation of the object program 
and returns the representation of the computed substitution. Finally such a substitu- 
tion is restricted to the initial object goal. 
The definition of Solve closely resembles the definition of Solve with the non-ground 
representation of object programs (module Vanilla in Subsection 3.1). To illustrate 
the reading of this meta-interpreter, let us focus on the last statement in the definition 
of Solve, namely the case of atomic goal reduction. Given an atomic goal, the predicate 
MyStatementMatchatom selects a statement in the program whose predicate (proposi- 
tion) in the head is the same as the predicate (proposition) in the goal. The predicate 
Resolve performs the clause reduction step: Given a goal, a selected statement and a 
substitution returns the new goal and a new substitution obtained by composing the 
initial one with the substitution computed during the reduction step. 
One of the annoying aspects of meta-programming with the ground representation 
is that unification and substitutions must be handled explicitly. G~del offers several 
system modules, such as Programs, which provide a large set of operations for working 
with the ground representation. It is worth noting that the abstract data type view of 
modules hides most of the complexity of these operations and supports a declarative 
style of meta-programming. 
4.2 
Extended 
Vanilla Meta-Interpreter 
We now extend the vanilla meta-interpreter using the ground representation in order 
to implement meta-level operations for composing definite programs. The idea is to 
follow the same approach presented in Section 3. As in the non-ground case, program 
composition operations are represented by function symbols whose meaning is defined 
by meta-level axioms. The key difference is that in the ground case object programs are 
represented by ground terms rather than referred to by constant names as in the non- 
ground case. The ground representation of a single object program can be generated 
by means of the system predicate Programeompile, which given the name of a program 
returns the term containing its ground representation. 
There is, however, a main problem to face when extending the ground vanilla meta- 
interpreter with the ground representation to deal with program expressions. Indeed 
GSdel meta-programming facilities strictly rely on the internal ground representation 
of Gfidel object programs, which coherently mirrors the naming policy of the language. 
Each symbol is internally represented by a flat name that is a quadruple containing 
name, category and arity of the symbol, as well as the name of the module in which 
the symbol is declared. Therefore symbols with same name, category and arity that 
are declared in different modules are distinguished. This does contrast with the naming 
policy adopted in the logic program composition setting, where a predicate definition 
may be spread over different modules (e.g. see [4, 6, 21]). 

389 
A first solution to this obstacle is to exploit the meta-programming support offered 
by GSdel to generate the ground representation of object programs, and to recta- 
program the unification mechanism of flat names in order to identify symbols with 
same name, category and arlty declared in different modules. The implementation of 
this solution presented two major drawbacks. First, it is necessary to introduce an extra 
representation of substitutions and therefore to construct from scratch a corresponding 
support. Second, the introduction of a further interpretation layer for handling the 
unification mechanism heavily affects the performance of the system. 
An alternative approach consists of extending the support for the generation of the 
ground representation of object programs in order to avoid the undesired distinction 
among fiat names. This way, the extended vanilla meta-interpreter is let free from the 
problem of fiat names, which is completely solved during the pre-processing phase. 
Before presenting the extended support for this second solution (Subsection 4.3), let 
us show the corresponding extended vanilla meta-interpreter. 
EXPORT 
IMPORT 
PREDICATE 
Extended_Ground_Vanilla. 
Program_Expressions. 
Demo: Program_Expression * Formula * TermSubst. 
LOCAL 
Extended_Ground_Vanilla. 
Demo(pexp, goal, answer) <- 
StandardiseFormula(goal, 0, var_index, new_goal) & 
EmptyTermSubst(empty_subst) & 
Solve(pexp, new_goal, var_index, _, empty_subst, subst) 
RestrictSubstToFormula(new_goal, subst, answer). 
PREDICATE Solve : 
Program_Expression * Formula * Integer * Integer * TermSubst * TermSubst. 
o * .  
Solve(pexp, goal, v_in, v_out, sub_in, sub_out) <- 
Atom(goal) 
MyStatementsMatchAtom(pexp, goal, v_in, vl, stment) & 
Resolve(goal, stment, vl, new_v, sub_in, new_sub, new_goal) & 
Solve(pexp, new.goal, new_v, v_out, new_sub, sub_out). 
PREDICATE MyStatementsMatchAtom 
: 
Program_Expression * Formula * Integer * Integer * Formula. 
MyStatementsMatchAtom(p Union q, goal, v_in, v_out, statement) <- 
MyStatementsMatchAtom(p, goal, v_in, v_out, statement). 
MyStatementsMatchAtom(p Union q, goal, v_in, v_out, statement) <- 
MyStatementsMatchAtom(q, goal, v_in, v_out, statement). 
.
.
.
 
MyStatementsMatchAtom(Enc(p), goal, v_in, v_out, statement) <- 
EmptyTermSubst(empty_subst) & 
Solve(p, goal, v_in, v_out, empty_subst, subst_out) 
BuildStatement(goal, subst_out, statement). 
MyStatementsMatchAtom(Prog(_,p), goal, v, vl, statement) <- 

390 
MyStatementMatchAtom(p, goal, statementl) & 
StandardiseFormula(statementl,v,vl,statement). 
Extended_Ground_Vanilla imports the module Program_Expressions, which contains 
the declaration of the type Program_Expression with the associated function symbols. 
The only change in the definition of the Demo predicate is the type of its first argu- 
ment. The definition of Solve extends the definition of Solve given in the module 
Ground_Vanilla much in the same way as in the non-ground case of Section 3. Intu- 
itively, the predicate MyStatementsMatchAtom extends MyStatementHatchAtom in the 
same way as Clause extends Statement in the vanilla meta-interpreter of Subsection 
3.2. It is worth noting that in this extendcd ground meta-interpreter subsltutions must 
be explicitly handled. For instance, in the case of an encapsulated program expression 
Eric (p), the representation of the empty substitution as well as of the answer computed 
by Solve must be explicitly handled in order to build a statement belonging to the 
ground representation of Eric(p). 
4.3 
Support 
for the Ground 
Representation 
In order to employ the module Ex~nded_fround.Vanilla for querying an arbitrary 
composition of object logic programs, the meta-interpreter must be provided with the 
ground representation of such a program expression. We h~ve therefore equipped the 
module Extended_flrouad_Vanilla with a suitable support capable of generating the 
ground representation of a composition of object definite programs. 
Given a program expression E over definite logic programs, the support generates the 
GSdel term denoting the ground representation of E. Such a term is obtained by com- 
posing the ground representations of the single object programs forming the program 
expression. The ground representation of a definite program P is obtained by first trans- 
forming P into an equivalent GcSdel program Pc, and then applying Progra~Compile 
to PG. According to Subsection 3.3, each logic program is transformed into an untyped 
GSdel module by employing a unique type Void. 
The support is in charge of solving the problem of flat names, so that symbols with 
same name, category and arity, though occurring in different programs, are identi- 
fied in their ground representation. This is done by assigning the same name to all 
the modules and by arranging them into separate directories. The structure of this 
support is more complex than the non-ground one, since it must combine GSdel mod- 
ules and utilities, and Unix commands. Notice, however, that the complexity of the 
ground support is transparent to the user, which only has to invoke a Unix shell called 
ProgramsCompile. Indeed, in order to compile a collection of object programs, the user 
simply calls ProgramsCompile with the names (of the files containing) the object pro- 
grams. For instance, the compilation of the object programs P, Q and R is obtained by 
invoking: 
csh ProgramsCompile P Q R 
Finally, in order to allow the user to query the extended vanilla meta-interpreter, we 
developed a user interface module Test_Ground_Vanilla reported below. The predicate 
Go allows the user to specify both the program expression and the goal of the intended 
query as strings. First the ground representation of the program expression is built 
via the predicate StringToProgramExpression. Then the string identifying the goal is 

391 
converted into a formula w.r.t, the name of any of the object programs (which have 
been given the same name M during the pre-processing phase). Finally, the answer 
possibly computed by Demo is converted back from the internal GSdel representation 
of substitutions into a string. 
MODULE 
IMPORT 
PREDICATE 
Test_Ground_Vanilla. 
Extended_Ground_Vanilla, Program_ExpressionsIO, Answers. 
Go : String * String * String. 
Go(pe_string, goal_string, answer_string) <- 
StringToProgramExpression(pe_string, program_expression) & 
ProgramInProgramExpression(program_expression, program) & 
StringToProgramFormula(program, "M", goal_string, 
[goal]) 
Demo(program_expression, goal, answer) & 
RestrictSubstToFormula(goal, answer, computed_answer) & 
AnswerString(program, "M", computed_answer, answer_string). 
5 
Discussion 
The ultimate objective of our work was to investigate the adequacy of GSdel as a meta- 
language for re-using and composing existing definite programs. First of all, we would 
like to draw from our own experience a few considerations on GSdel as a programming 
language. G6del offers 9 number of features to which logic programmers may not be 
used to. For instance G6del is a strongly typed language that forces programmers to 
assign a type to each symbol in a program (except for variables). After feeling initially 
reluctant to employ types, we found that G6del's type discipline greatly assists the 
correct development of programs. The module system is another feature of GSdel that, 
along with the associated abstract data type view, is essential for the incremental and 
disciplined development of software. Moreover some GSdel system modules, such as 
Units and Flocks, have revealed to be very convenient for analysing and handling 
terms and programs. 
Another relevant feature of GSdel is the emphasis placed on meta-programming. GSdel 
provides ample support for meta-programming with the ground representation. Sev- 
eral system modules offer operations for generating and handling the representation of 
programs. We found GSdel's abstract data type view of modules particularly power- 
ful in the case of meta-programming. Indeed, system modules such as Programs and 
Syntax support a declarative style of meta-programming by hiding the complexity of 
the ground representation. In this respect, however, it is worth mentioning that one of 
the deficiencies of the the current implementation of G6del is the tracer. For instance 
terms with types used in the ground representation, such as Formula, are not visible 
to the user. As a consequence the tracer is often of little help when analysing the 
behaviour of meta-programs. 
We developed two alternative implementations in GSdel of a suite of meta-level op- 
erations for composing definite programs. The two implementations are based on an 
extended vanilla meta-interpreter and they differ each other for the chosen representa- 
tion of object level programs. The first implementation, described in Section 3, employs 
the non-ground representation of object programs and is quite simple and efficient. 

392 
The second implementation described in Section 4 heavily exploits GSdel's support 
for meta-programming. The choice of addressing the naming problem during the pre- 
processing phase notably simplifies the structure of the extended meta-interpreter with 
the ground representation, which closely resembles its non-ground correspondent. 
Even though the non-ground implementation offers much better performances than the 
ground one, the latter is definitely more promising than the former. Indeed the ground 
implementation can greatly benefit from the application of tools that are currently un- 
der development for GSdel and that rely on the ground representation. For instance, a 
partial evaluator called SAGE for GSdel programs is currently under experimentation 
[10, 11]. The extended vanilla meta-interpreter using the ground representation was 
designed according to the requirements of SAGE. We expect that the partial evalu- 
ation of the recta-interpreter will sensibly reduce the efficiency gap between the two 
implementations. Another advantage of the implementation with the ground represen- 
tation is its extensibility to deal with composition of object GSdel programs. Actually 
the presented implementation of program composition operations already deals with 
the composition of object GSdel programs in that definite programs are translated into 
corresponding GSdel programs. Such programs, however, do not contain control decla- 
rations or type information. An interesting research direction is to investigate how to 
extend the implementation of program composition operations to deal with arbitrary 
GSdel programs. This may allow to push the program composition approach to extend 
the GSdel language itself. 
Finally, we would like to mention some other possible extensions and improvements 
that might be encorporated in G6del. The availability of parametric modules [12], for 
instance, would notably increase the flexibility of the language. In the case of the non- 
ground implementation described in Section 3, it would allow the parameterisation of 
the extended vanilla recta-interpreter w.r.t, the object programs, thus enhancing its ac- 
tual usability. Even more importantly, the possibility of parameterising the language of 
a Gbdel module would allow to overcome one of the most severe limits of the language. 
Namely, GSdel recta-programming support does not allow to meta-program extensions 
of the language itself. This is due to the fact that the ProgramCompile operation gen- 
erating the ground representation of a program requires the latter to be a (pure) GSdel 
program. A more flexible form of ProgramCompile could also offer the possibility of 
specifying different names for the program to be compiled and for the file containing 
it. 
Acknowledgements 
We would like to thank J.W. Lloyd for the many suggestions and encouragement. 
Thanks also to A. Bowers, D. Pedreschi and to the referees for their valuable com- 
ments. This work was partly supported by Esprit BRA 6810 Compulog ~ and by 
Progetto Finalizzato Sistemi Informatici e Calcolo Parallelo of C.N.R. under grant 
n. 92.01864.PF69. 
References 
I. K. R. Apt. Logic programming. In J. van Leeuwen, editor, ttandbook of Theoretical 
Computer Science, pages 493-574. Elsevier, 1990. Vol. B. 

393 
2. K. R. Apt. Declarative programming in Prolog. In D. Miller, editor, Proc. Inter. 
national Symposium on Logic Programming, pages 11-35. MIT Press, 1993. 
3. R. Barbuti and R. Giacobazzi. A bottom-up polymorphic type inference in logic 
programming. Science of Computer Programming, 19(3):281-313, 1992. 
4. A. Brogi. Program Construction in Computational Logic. PhD thesis, University 
of Pisa, March 1993. 
5. A. Brogi, P. Mancarella, D. Pedreschi, and F. Turini. Hierarchies through Basic 
Metalevel Operators. In M. Bruynooghe, editor, Proceedings of the Second Work- 
shop on Meta-programming in Logic, pages 381-396, 1990. 
6. A. Brogi, P. Mancarella, D. Pedreschi, and F. Turini. Modular Logic Program- 
ming. A CM Transactions on Programming Languages and Systems, 16(3), 1994. 
7. A. Brogi and F. Tarini. Metalogic for Knowledge Representation. In J.A. Allen, 
R. Fikes, and E. Sandewall, editors, Principles of Knowledge Representation and 
Reasoning: Proceedings of the Second International Conference, pages 100-106. 
Morgan Kaufmann, 1990. 
8. A. Brogi and F. Turini. Semantics of meta-logic in an algebra of programs. In 
S. Abramski, editor, Proceedings Ninth Annual IEEE Symposium on Logic in Com- 
puter Science. IEEE Society Press, 1994. 
9. K.L Clark, F.G. McCabe, and S. Gregory. IC-Prolog language features. In K.L. 
Clark and S.A. Tarnlund, editors, Logic Programming, pages 253-266. Academic 
Press, 1982. 
10. C.A. Gurr. A guide to specialising Gfdel programs with the partial evaluator sage. 
Technical report, University of Edinburgh, 1994. 
11. C.A. Gurr. A self-applicable partial evaluator for the logic programming language 
Gddel. PhD thesis, University of Bristol, 1994. 
12. P.M. Hill. A parameterised module system for constructing typed logic programs. 
In R. Bajcsy, editor, Proceedings IJCAl'93, pages 874-880. Morgan Kaufmann, 
1993. 
13. P.M. Hill and J.W. Lloyd. Analysis of metaprograms. In H.D. Abramson and 
M.H. Rogers, editors , Metaprogramming in Logic Programming, pages 23-52. The 
MIT Press, 1989. 
14. P.M. Hill and J.W. Lloyd. The GSdel Programming Language. The MIT Press, 
1994. 
15. R.A. Kowalski. Predicate logic as a programming language. In 1FIP 74, pages 
569-574, 1974. 
16. R.A. Kowalski. Problems and Promises of Computational Logic. In J.W. Lloyd, 
editor, Computational Logic, Symposium Proceedings, pages 1-36. Springer-Verlag, 
1990. 
17. G. Levi and D. Ramundo. A Formalization of Metaprogramming for Real. In 
D.S. Warren, editor, Proceedings Tenth International Conference on Logic Pro- 
gramming, pages 354-373. The MIT Press, 1993. 
18. J.W. Lloyd. Foundations of logic programming. Springer-Verlag, second edition, 
1987. 
19. P. Mancarella and D. Pedreschi. An algebra of logic programs. In R. A. Kowalski 
and K. A. Bowen, editors, Proceedings Fifth International Conference on Logic 
Programming, pages 1006-1023. The MIT Press, 1988. 
20. B. Martens and D. De Schreye. Why untyped non-ground meta-programming is 
not (much of) a problem. Technical Report CW159, Departement Computer- 
wetenschappen, K.U.Leuven, Belgium, December 1992. Revised November 1993, 
Abridged version to appear in The Journal of Logic Programming. 

394 
21. L. Monteiro and A. Porto. 
Contextual logic programming. 
In G. Levi and 
M. Maxtelli, editors, Proceedings Sixth International Conference on Logic Program- 
ming, pages 284-302. The MIT Press, 1989. 
22. L. NaJsh. 
Negation and quantifiers in NU-Prolog. In E. Shapiro, editor, Pro- 
ceedings Third International Conference on Logic Programming, pages 624-634. 
Springer-Verlag, 1987. 
23. D. De Schreye and B. Martens. A Sensible Least tterbrand Semantics for Untyped 
Vanilla Meta-Programming and its Extension to a Limited Form of Amalgamation. 
In A. Pettorossi, editor, Proceedings of the Third Workshop on Meta-programming 
in Logic, pages 127-141, 1992. 
24. L. Sterling and E. Shapiro. The Art of Prolog. The MIT Press, 1986. 
25. M. H. van Emden and R. A. Kowalski. 
The semantics of predicate logic as a 
programming language. Journal of the ACM, 23(4):733-742, 1976. 

A Module System for Meta-Programming 
P.M. Hill* 
School of Computer Studies, University of Leeds, Leeds LS2 9JT 
hill@scs.leeds.ac.uk 
Abstract. The need for modules in the development of large programs 
is well known while meta-programming is widely regarded as a simple 
yet powerful methodology for knowledge representation and reasoning. 
Thus if we wish to reason about large knowledge bases, it is desirable that 
meta-programs should be designed to reason about modular programs. 
This paper describes a module system which allows the modules to be 
parametrised over the language symbols exported by the module and 
shows that this provides a natural environment for meta-programming 
where both the meta and object programs enjoy the same parametrised 
module system. 
1 
Introduction 
A meta-program, regardless of the nature of the programming language, is a 
program whose data denotes another (object) program. The object program 
does not necessarily have to be written in the same programming language as 
the meta-program although this is often the case and most theoretical work 
on meta-programming in logic programming (as in this paper) makes this as- 
sumption. There are many applications for meta-programming: compilers, in- 
terpreters, program analysers, program transformers, and so on. Furthermore, 
because a logic program is often used in artificial intelligence and defines some 
knowledge, a meta-program is often viewed as a meta-reasoner for reasoning 
about this knowledge. Meta-programming for logic was first studied by Bowen 
and Kowalski [2] and continues to be an important area of research. Barklund [1] 
has recently written an overview of this area together with a survey of the liter- 
ature. In [6], Hill and Gallagher have contributed an in-depth survey of the area 
focusing on those aspects of meta-programming particularly relevant to logic 
programming. 
The key to the semantics of a meta-program with respect to an object pro- 
gram is the way the object program is represented in the meta-program. Such 
a representation is often called a naming relation. Both the syntax and the 
semantics of this relation has to be defined. Normally, the naming relation is 
given for each symbol of the object language. Then simple rules of construction 
can be used to define the representation of the constructed terms and formulas. 
However, there are two basic representations for the object variables: either as 
* This work is supported by SERC Grant GR/H/79862 

396 
ground terms or as variables (or, more generally, non-ground terms). The first 
is called the ground representation and the second, the non-ground representa- 
tion. Clearly, the ground representation is the most versatile since the object 
expressions may then be regarded as an arbitrary string of characters. The main 
factor in favour of the non-ground representation is the fact that the semantics 
of the object program can easily be represented in the meta-program [8]. The 
meta-programming in this paper is presented using the non-ground represen- 
tation although the underlying ideas are also applicable to meta-programming 
using a ground representation. 
Logic programming has been used extensively for representing and reasoning 
about knowledge bases. For large knowledge bases, we require a means of seg- 
menting the program so that small component parts of the knowledge base can 
be developed. These can then be used to build larger components, and so on, 
until the program is completed. These components are called modules. Modules 
have been researched from a number of points of view including software en- 
gineering, object-oriented programming, and theory construction. The module 
system discussed in this paper is designed with the software engineering appli- 
cation in mind, in particular with regard to the use of modules for program 
construction. There are a number of requirements for such a module system. 
1. There must be a means of combining modules. This is normally achieved by 
allowing one module to import another. 
2. Part of a module should be protected from unintended use by other modules; 
This is called encapsulation. Usually a module is divided into two parts. One 
part defines a language that can be used by an importing module. The other 
part extends this language with symbols only required locally. 
3. It should be possible to develop a module independently of other modules 
that it does not import. Thus the import relation is normally restricted to 
defining a partial order on the modules in a program. The order of compila- 
tion of the modules must then respect this ordering. 
4. A module should be usable in as many contexts as possible. A module pro- 
viding an abstract data type such as a stack or a definition of an abstract 
relation such as transitivity needs to be re-usable and not tied to a specific 
application. 
The programming language GSdel [9] has a simple module system that sup- 
ports importation, encapsulation, and separate compilation as well as allowing 
for modules defining abstract data types. The GSdel module system does not 
support re-usable modules defining abstract relations such as transitivity. This 
means that many generic relations have to be redefined in each module in which 
they are used. Many meta-programs such as interpreters are generic so that a 
meta-programming module will have to be modified for each object program 
it is to reason about. Moreover, when the object program is also modular, the 
problem is more acute. In order to realise the first three criteria of importa- 
tion, encapsulation, and separate compilation, GSdel has a number of module 
conditions (see Section 3). These force a modular logic program to be repre- 
sented in the meta-program as a single module. Thus, the encapsulation and 

397 
separate compilation of the object module are lost in the representation. In [7], 
we described a parametrised module system that extended the GSdel module 
system and provided better facilities for defining abstract relations. In this pa- 
per, we focus on the application of this system for meta-programming using the 
non-ground representation. 2 
Important issues for meta-programming in logic programming are amalga- 
mation and self-applicability. For these concepts, it is necessary to assume that 
there is one system for writing both the object program and the meta-program. If 
the meta-program can be applied to a representation of itself, then it is said to be 
self-applicable. If the language of the meta-program is an extension of the object 
language and each statement in the object program is a logical consequence of 
the meta-program, then we say that the meta-program and object program are 
amalgamated. For both self-application and amalgamation, the meta-program 
and object program must be written in the same (logic) programming language 
and hence be constructed by means of the same module system. Thus it is desir- 
able that a programming language be able to represent its own module system. 
We will show in this paper, that the parametrised module system described here 
(and defined more formally in [7]) satisfies this requirement. 
Since the ideas in this paper are based on the GSdel programming language, 
we give below a simple GSdel program for readers not familiar with the language. 
This program defines a family and the relations between them 3. Further exam- 
ples illustrating the ideas of this paper will be modified forms of this program. 
MODULE 
BASE 
CONSTANT 
TheJonesFamilyTree. 
Person. 
Mary,Pat,Sid,Tim: Person. 
PREDICATE Mother,Father: Person * Person. 
Father(Sid,Pat). 
Father(Tim,Mary). 
Mother(Pat,Mary). 
PREDICATE Par: Person * Person. 
Par(x,y) <- Mother(x,y) \/ Father(x,y). 
PREDICATE Anc: Person * Person. 
Anc(x,y) 
<- Par(x,z) 
~ Anc(z,y). 
Anc(x,y) 
<- Par(x,y). 
2 The language GSdel does not provide any support for the non-ground represen- 
tation for meta-programming. However, this does not prevent this style of meta- 
programming in GSdel. For example, the meta-program Vanilla in [9, pages 145- 
147] illustrates an interpreter using this representation. 
Par, Rels, Anc are short for Parent, Relations, Ancestor, respectively. 

398 
In the above program, there are a number of declarations and statements. The 
statements are formulas inthe language defined by the language declarations. 
These declarations begin with a key word that indicates the category 4 and arity 
of the symbol being declared. The type in a constant declaration or on the right 
of the -> in a function declaration is the range type of the declaration. Constant 
and function declarations define the top-level constructors of their range types. 
Thus Person is declared to be a base type; the constant declaration for Mary, 
Pat, etc., defines Person. Mother and Father are declared to be predicates with 
arguments of type Person. Every symbol used in a program (other than the 
logical symbols and variables) must be declared in the program. The module 
system in GSdel will be explained later in Section 3. 
The paper is organised as follows. In the next section, we present a non- 
ground representation and illustrate it using the above example with a sim- 
ple meta-interpreter. The GSdel module system and its extension to include 
parametrised modules is given in Section 3. We combine these ideas in Section 4 
and show how a modular program can be represented and interpreted by a 
meta-interpreter using the same module system. The final section highlights the 
basic advantages of the parametrised module system for meta-programming and 
discusses the relation of this work with other relevant published work. 
2 
The 
Non-Ground 
Representation 
The non-ground representation requires the variables in the object program to be 
represented by non-ground terms in the meta-program. This paper assumes, as 
in Prolog, that object variables are represented as variables in the meta-program. 
The representation for the non-logical symbols is summarised as follows. 
Object Symbols 
Meta Symbols 
Constant 
Constant 
Function of arity n 
Function of arity n 
Proposition 
Constant 
Predicate of arity n 
Function of arity n 
It is often assumed that distinct symbols (including the variables) in the 
object language are represented by symbols in the meta-language distinct from 
the object language symbols. For example, Tim and Pat in TheJonesFamilyTree 
can be represented by constants, say 0Tim and 0Pat. The predicates such as 
Father and Mother in TheJonesFarailyTree can be similarly represented by 
functions, say 0Father and 0Mother of the same arity. However, the name of 
the object symbol can also be used as the name of the symbol that represents 
it. This trivial naming relation, which is the one adopted in Prolog, does not 
in itself cause any amalgamation of the object and meta-languages and may 
be regarded as just a syntactic convenience for the programmer. Note however 
4 The categories are: type constructor, function, or predicate. A base, constant, or 
proposition is regarded as a constructor, function, or predicate, respectively, of ar- 
ity 0. 

399 
that, in the case of the constants, and functions, a symbol can represent itself, 
thereby facilitating the strong amalgamation of the meta and object levels and 
many levels of meta-reasoning. 
We can construct terms that represent terms and atoms of the object lan- 
guage in the obvious way. However, to represent formulas, a representation of 
the logical connectives is required. Our representation is as follows. 
Object Symbols 
Meta Symbols 
Binary connective 
Function of arity 2 
Unary connective 
Function of arity 1 
Continuing the above representation, suppose the connectives ~, \/, and " are 
represented by functions AND/2, 0R/2, and NOT/1, respectively. Then the formula 
Par(x,z) ~ Anc(z,y) will be represented by the term Par(x,z) AND Anc(z,y) 
and Mother(x,y) \/ Father(x,y) by Mother(x,y) OR Father(x,y) . 
We assume here that a logic program 5 is a set of clauses of the form h <- b or h 
where h is an atom, called the head, and b is any formula constructed using atoms 
and the connectives ~, \/, and ", cMled the body. It is clearly necessary, that if 
the meta-program is to reason about the object program there must be a way of 
identifying which formulas represent the statements. In Prolog, each statement 
in the program is represented as a fact (that is, a statement with the empty 
body). This has the advantage that the variables in the fact are automaticMty 
standardised apart each time the fact is used. We adopt this representation here. 
In particular, we assume that the language of the meta-program contains the 
distinguished predicate Clause/2 6 and each clause in the object program of the 
form 
h<-b. 
is represented as a fact 
Clause(h,b). 
and each atomic clause 
h. 
is represented as a fact 
Clause (h, Empty). 
Hence, with this representation, the object program is represented in the meta- 
program by the definition of Clause/2. The representation of the family database 
and its use by the well known 'vanilla' interpreter (see [13]) is given below. 
Before continuing with the discussion of the representation of modules, we 
examine (informally) the semantics of this program. An issue that has had much 
attention is whether the facts defining Clause accurately represent the object 
program. The problem is a consequence of the fact that, in Prolog, the language 
is not explicitly defined but assumed to be determined by the symbols used in 
the program and goal. Thus, the variables in the object program range over the 
terms in the language of the object program while the variables in the definition 
s See [10] for the underlying theoretical basis of logic programming assumed in this 
paper. 
e We use the predicate name Clause/2 although statements such as h <- bV c are not 
clauses. Such a statement is equivalent to two clauses h <- b and h <- c. 

4OO 
of Clause range not only over the terms representing terms in the object pro- 
gram but also over the terms representing the formulas of the object program. 
MODULE 
BASE 
CONSTANT 
FUNCTION 
Vanilla. 
ObjectForm. 
Empty : ObjectForm. 
AND : xFy(110) : ObjectForm * ObjectForm -> ObjectForm; 
OR : xFy(llO) : ObjectForm * ObjectForm -> ObjectForm; 
NOT : Fy(120) : ObjectForm -> ObjectForm. 
PREDICATE Solve : ObjectForm. 
Solve(Empty). 
Solve(x AND y) <- Solve(x) ~ Solve(y). 
Solve(x OR y) <- Solve(x) \/ Solve(y). 
Solve(NOT x) <- " Solve(x). 
Solve(x) <- Clause(x, y) & Solve(y). 
BASE 
CONSTANT 
FUNCTION 
FUNCTION 
Person. 
Mary,Pat,Sid,Tim : Person. 
Mother, Father : Person * Person -> ObjectForm. 
Par, Anc : Person * Person -> ObjectForm. 
PREDICATE Clause: ObjectForm * ObjectForm. 
Clause(Father(Sid,Pat), Empty). 
Clause(Father(Tim,Mary), Empty). 
Clause(Mother(Pat,Mary, Empty)). 
Clause(Par(x,y), Mother(x,y) OR Father(x,y)). 
Clause(Anc(x,y), Par(x,y)). 
Clause(Anc(x,y), Par(x,z) AND Anc(z,y)). 
Thus, in the family database example, the terms in the object language are 
the constants Mary, Pat, Sid, Tim, while in an untyped meta-program contain- 
ing a representation of just the clauses in this program, the terms would not 
only include these constants but also Father (Tim,Mary), Mother(Mary,Tim), 
Father (Tim, Mother (Mary, Tim) ) and so on. Thus in the statement 
Anc(x,y) <- Par(x,z) 8t Anc(z,y). 
in the object program, x and y are universally quantified in the domain of people, 
while in the fact 
Clause(Anc(x,y), Par(x,z) And Anc(z,y)). 
in the (untyped) meta-program, x and y are universally quantified in a domain 
that contains a denotation of all terms and formulas of the object program. 

401 
There is a simple solution, that is, assume that the intended interpretation of 
the meta-program is typed. The types distinguish between the terms that rep- 
resent terms in the object program and terms that represent the formulas. This 
approach has been developed by Hill and Lloyd in [8] 7 . An alternative solution is 
to assume an untyped interpretation but restrict the object program so that the 
semantics of this representation is preserved. This approach has been explored 
by De Schreye and Martens in [11] using the concept of language independence. 
(Informally, a program is language independent when the Herbrand model is not 
affected by the addition of new constant and function symbols.) 
It can be seen that the problem is avoided in the examples here by assuming 
that, as in GSdel, the programming language is typed, so that all the symbols 
and their types are explicitly declared. 
3 
Modules 
In this section, the GSdel module system is explained by means of an exam- 
ple. (We provide here an informal description of the GSdel module system. A 
complete definition is given in [9].) In the program below, the family database 
program in Section 1 is divided into two modules, one specific to the particular 
family where the mother and father relations are defined, and the other defining 
the parent and ancestor relations. 
Each module is in two parts called export and local. A part begins with 
a module declaration stating whether it is the export or local part and the 
name of the module s . The export part contains language declarations for sym- 
bols that can be used in this module and also in other modules that import 
it. Thus the type Person can be used in either part of TheJonesRels as well 
as in TheJonesFamily. Symbols declared in the local part of a module are only 
available for use within this part. Hence, since TheJonesRels declares Par in the 
local part, Par cannot be used outside this module. Statements are only allowed 
in the local part of a module. These define the predicates declared in either part 
of the module. TheJonesRels also has a module declaration that begins with 
the key word IMPORT. This makes all the symbols declared in the export part of 
TheJonesFamily available for use in TheJonesRels. Note that to avoid unnec- 
essary overloading, a symbol name (for a given arity and category) must have 
at most one declaration in a module. 
7 Note that this does not mean that the program has to be explicitly typed, just that 
the intended interpretation is typed so that all the clauses in the program and goals 
for the program respect the intended typing. With simple many-sorted typing as 
required for meta-programming, no type checking in the execution of a correctly 
typed goal and program is needed. 
s The Module declaration, as used in the example in Section 1, indicates it is the local 
part and that there is no export part to this module. 

402 
EXPORT 
TheJonesFamily. 
BASE 
Person. 
CONSTANT Nary,Pat,Sid,Tim: Person. 
PREDICATE Mother,Father: Person * Person. 
LOCAL 
TheJonesFamily. 
Father(Sid,Pat). 
Father(Tim,Mary). 
Mother(Pat,Mary). 
EXPORT 
TheJonesRels. 
IMPORT 
TheJonesFamily. 
PREDICATE Anc: Person * Person. 
LOCAL 
TheJonesRels. 
PREDICATE Par: Person * Person. 
Par(x,y) <- Nother(x,y) \/ Father(x,y). 
Anc(x,y) <- Par(x,z) ~ Anc(z,y). 
Anc(x,y) <- Par(x,y). 
A G6del program for a module m (called the main module) is the smallest set 
of modules that includes m and is closed wrt the modules named in the import 
declarations. The program must satisfy the following three conditions. 
1 The module names can be partially ordered so that if m' occurs in an import 
declaration in a module named m then m' < m. 
2 Every symbol appearing in (the export part of) a module, must be declared 
in or imported into (the export part of) the module. 
3 Each constructor or predicate with a non-empty definition in a module must 
be declared in that module. 
These conditions enable independent compilation and protect procedures defined 
in one module from being modified by another. The set of modules 
{TheJonesFamily, TheJonesRels} form a GSdel program. 
The Vanilla module in Section 2 includes the representation of the object 
program. It is clearly desirable to split this module into two modules, one con- 
taining the vanilla interpreter and the other the family database. The interpreter 
part should be generic and hence, independent of the object programs that it can 
interpret. However, the three GSdel module conditions make this impossible. In 
particular, the declarations for Obj ectForm, Empty, AND, OR, and NOT have to be 
included in the module containing the representation of the object program. Fur- 
thermore, if the third module condition was deleted so that the representation 

403 
of the object program was in a separate module, then the interpreter module 
would have to import this representation by means of an import declaration, 
and so be specialised for the particular object program. 
We now describe a parametrised module system. This is a straightforward 
extension of the GSdel module system. We explain the system using the same 
family database as before. 
EXPORT 
TheJones. 
IMPORT 
Rels(Jones,Ma,Pa). 
BASE 
Jones. 
PREDICATE Ma,Pa: Jones * Jones. 
CONSTANT 
Mary,Pat,Sid,Tim: Jones. 
LOCAL 
TheJones. 
Father(Sid,Pat). 
Father(Tim,Mary). 
Mother(Pat,Mary). 
EXPORT 
Rels(Person,Mother,Father). 
BASE 
Person. 
PREDICATE Mother,Father: Person * Person. 
PREDICATE Anc: Person * Person. 
LOCAL 
Rels(Person,Mother,Pather). 
IMPORT 
Trans(Person, Par). 
PREDICATE Par: Person * Person. 
Par(x,y) <- Mother(x,y) \/ Father(x,y). 
Anc(x,y) <- Tr(x,y). 
EXPORT 
Trans(Point,Connect). 
BASE 
Point. 
PREDICATE Connect: Point * Point. 
PREDICATE Tr: Point * Point. 
LOCAL 
Trans(Point, 
Connect). 
Tr(x,y) <- Connect(x,y). 
Tr(x,y) <- Connect(x,z) ~ Tr(z,y). 
In this example, there are three declared modules, identified by TheJones, Rels, 

404 
and Trans. The The Jones module, which is not parametrised, is the main mod- 
ule which imports an instance of the Eels module. This is parametrised with 
respect to the base Person and predicates Mother and Father. Note that it 
is the The Jones module that imports the Eels module which defines the rela- 
tions Par and tnc whereas, in the previous example based on the GSdel module 
system, the importation was in the opposite direction. The module name that 
follows the key words EXPORT and LOCAL consists of an identifier with 0 or more 
symbols as arguments. The set of declarations for these symbols (which must 
be in the export part of the module) is called the signature of the module. For 
example, Eels (Person, Mother, Father) is a module name with identifier Eels 
and signature 
BASE 
Person. 
PREDICATE Mother,Father: Person * Person. 
Symbols that are declared in a module but are not in the signature are said to be 
completely specified by the module. For example, the base Jones is completely 
specified in The Jones. 
The written module is the initial module. Instances of these modules can be 
obtained by substituting new symbols for symbols occurring in the module name. 
In the example program, the following instance of the initial Trans module is 
imported into Eels (Person, Mother, Father) 
EXPORT 
Trans(Person,Par). 
BASE 
Person. 
PREDICATE Par: Person * Person. 
PREDICATE Tr: Person 
* Person. 
LOCAL 
Trans(Person,Par). 
Tr(x,y) <- Par(x,y). 
Tr(x,y) <- Par(x,z) & Wr(z,y). 
The substituted symbols used to obtain the instance module must be distinct 
from symbols that were completely specified by its initial module. For example, 
the module name Trans (Person,Tr) is not a legal module name for importa- 
tion since Tr is completely specified in Trans(Person,Connect). Therefore, if 
a symbol is completely specified in a module, it will be completely specified in 
every module that is an instance of it. In the example, as the predicate Tr is 
completely specified by Trans (Point,Connect), it is also completely specified 
by Trans(Person,Par). This rule ensures that the definitions of constructors 
and predicates that are completely specified cannot be modified by modules 
that import them. 

405 
We define a modular program in a similar way to the definition of a GSdel 
program above. InformMly, it the smallest set of initial modules with a distin- 
guished module called the main module and closed with respect to the identifiers 
in the import declarations. It must satisfy similar module conditions to those 
given for the GSdel module system. 
1' The identifiers in the module names can be partially ordered so that if I' 
is an identifier in an import declaration in a module with identifier I then 
I' <I. 
2* Every symbol name appearing in (the export part of) a module m, must 
either be declared in (the export part of) m or be completely specified by 
the export part of a module that is imported into (the export part of) m. 
3* Each constructor or predicate name declared in or imported into a module 
and completely specified by an imported module n may only have a non- 
empty definition in n or in imported modules that are also imported into n. 
A modular program for the The Jones consists of the following set of modules 
{The Jones, Rels (Person, Mother, Father), Trans (Point, Connect ) } 
The semantics of a modular program are given by renaming the symbols in 
the different instances of the generic modules to ensure that overloaded names 
are standardised apart and then combining the renamed modules to form a 
program consisting of a single flattened module. The semantics of the modular 
program are then the semantics of the combined module. DetMls of the flattening 
procedure for this parametrised module system can be found in [7]. 
4 
The Representation of Modules 
We now present the Vanilla interpreter using parametrised modules. 
EXPORT 
Vanilla(ObjectForm,Clause). 
BASE 
ObjectForm. 
PREDICATE Clause : 0bjectForm * ObjectForm. 
IMPORT 
Representation(ObjectForm). 
PREDICATE Solve : ObjectForm. 
LOCAL 
Vanilla(ObjectForm,Clause). 
Solve(Empty). 
Solve(x AND y) <- Solve(x) ~ Solve(y). 
Solve(x OR y) <- Solve(x) 
\/ Solve(y). 
Solve(NOT x) <- " Solve(x). 
Solve(x) <- Clause(x, y) ~ Solve(y). 
The interpreter assumes a particular representation of the object program which 
is first defined in another module called Representation(Formula) and then 
imported into the Vanilla module. 

406 
EXPORT 
BASE 
CONSTANT 
FUNCTION 
Representation(Formula). 
Formula. 
Empty : Formula. 
AND : xFy(ll0) : Formula * Formula -> Formula; 
OR : xFy(llO) 
: Formula * Formula -> Formula; 
NOT : Fy(120) : Formula -> Formula. 
The Vanilla interpreter can be used for any program provided it uses the rep- 
resentation declared in Representation(Formula) 
module. Each module of the 
object program can now be represented as a single module in the meta-program. 
The following is such a representation of the The Jones program 
{TheJones, Rels(Person,Mother,Father),Trans(Point,Connect)}. 
EXPORT 
BASE 
PREDICATE 
Z 
IMPORT 
IMPORT 
BASE 
FUNCTION 
CONSTANT 
0TheJones(ObjectForm,Clause). 
ObjectForm. 
Clause: ObjectForm * ObjectForm. 
Representation(ObjectForm). 
ORels(Jones,Ma,Pa,ObjectForm,Clause). 
Jones. 
Ma,Pa: Jones * Jones -> ObjectForm. 
Mary,Pat,Sid,Tim: Jones. 
LOCAL 
OTheJones(0bjectForm,Clause). 
Clause(Father(Sid,Pat), Empty). 
Clause(Father(Tim,Mary), Empty). 
Clause(Mother(Pat,Mary), Empty). 
EXPORT 
BASE 
FUNCTION 
BASE 
PREDICATE 
Z 
IMPORT 
FUNCTION 
ORels(Person,Mother,Father,ObjectForm,Clause). 
Person. 
Mother,Father: Person * Person -> ObjectForm. 
0bjectForm. 
Clause: ObjectForm * ObjectForm. 
Representation(ObjectForm). 
Anc: Person * Person -> ObjectForm. 

407 
LOCAL 
ORels(Person,Nother,Father,ObjectForm,Clause). 
IMPORT 
OTrans(Person, Par,0bjectForm,Clause). 
FUNCTION Par: Person * Person -> ObjectForm. 
Clause(Par(x,y), Mother(x~y) OR Father(x,y)). 
Clause(Anc(x,y), Tr(x,y)). 
EXPORT 
BASE 
FUNCTION 
BASE 
PREDICATE 
IMPORT 
FUNCTION 
OTrans(Point,Connect,0bjectForm,Clause). 
Point. 
Connect: Point * Point -> 0bjectForm. 
0bjectForm. 
Clause: ObjectForm * ObjectForm. 
Representation(0bjectForm). 
Tr: Point * Point -> ObjectForm. 
LOCAL 
OTrans(Point,Connect,0bjectForm,Clause). 
Clause(Tr(x,y), Connect(x,y)). 
Clause(Tr(x,y), Connect(x,z) AND Tr(z,y)). 
Note that this representation maintains the module structure of the underlying 
object program. We have added two arguments 0bjectForm and Clause to each 
module name in the object program. Language declarations for ObjectForm 
and Clause and an import declaration for the Representation(0bjectForm) 
module have been added to each module. Note also, that because Clause occurs 
in the signature of each of these modules, the definition of Clause consists of the 
union of the sets of facts in these modules that contain the predicate Clause. 
This representation transformation, illustrated in the above example, is defined 
for an object module independent of its use in an object program. Thus the 
representation of a modular program consisting of a set of modules { M1,. 9 M~ } 
is the set of modules {M~,..., M'}, where M" represents M~, for i E {1,..., n}. 
This representation is also independent of any particular meta-program. To 
use Vanilla for this representation of the object program, another module is 
required that imports both the representation of the main module of the object 
program and the Vanilla module. Such a module is given below. 
EXPORT 
InterpretTheJones. 
IMPORT 
Vanilla(ObjectForm, Clause). 
IMPORT 
OTheJones(ObjectForm, Clause). 
BASE 
ObjectForm. 
PREDICATE Clause: ObjectForm * ObjectForm. 
# 
A goal for the program with main module InterpretTheJones is 
<- Solve(Anc(Sid, x)). 

408 
5 
Discussion 
The parametrised module system described here is ideal for meta-programming 
for at least two reasons. First, good software engineering practice requires mod- 
ules to be independent program components. This means that the meta-program 
should be a generic module, independent of any specific object program that it 
has to manipulate. The second concerns the need to improve the efficiency of 
meta-programs. By including the object program in the meta-program, meta- 
programming predicates defining the semantics of the object program can be im- 
plemented directly using the object program. In this form of meta-programming, 
the programming languages used for the object and meta-programs have to be 
the same so that a representation must be defined for modular programs. By 
preserving the module structure of the object program in its representation, 
it is straightforward to keep the locality of symbol names, thereby preventing 
accidental interference between overloaded symbol names. 
We have assumed that the module system is a fundamental requirement for a 
programming language and will therefore be provided as one of the main features 
of the language. Meta-programming techniques have also been used to provide 
a module system on top of a logic programming language that has no built-in 
module system. However, a built-in module system has many advantages. One 
of these is that it can support separate compilation for the individual modules. 
Moreover, at run-time, only the flattened form of the program need actually be 
executed while, with the meta-programming method, there is the overhead of 
the extra level of interpretation. One disadvantage of the parametrised modules 
is that separate compilation of the modules appears to be more difficult. Work 
on the implementation of parametrised modules is required to determine the 
best way to resolve this problem. 
The meta-programming approach was first proposed in [2]. Here it was shown 
how, by representing programs as terms, predicates defining the inference pro- 
cedure can interpret the programs in a constrained way, thereby limiting par- 
ticular reasoning strategies to different parts of the object program. This idea 
has been further developed in a number of papers by Brogi, Mancarella, Pe- 
dreschi, Turini and Contiero. In particular, the papers [3] and [4] consider the 
combining of modules and meta-programming from a perspective opposite to 
that considered in this paper. They show how using a simple extension of inter- 
preters for logic programs (using both non-ground and ground representations), 
operators for combining export and local parts of modules as well as importing 
one module into another module can be defined. Our module system does have 
certain advantages over the one proposed in these papers. In particular, there 
is no apparent way in which the definition of a predicate exported by a mod- 
ule can be protected from alteration by an importing module. In a programming 
language such as GSdel, such lack of protection would inhibit efficient implemen- 
tation of the numeric modules and cause unpredictable results in the presence 
of negation in the bodies of statements. Further work needs to be done to see 
if the parametrised module system described here can be implemented using 
techniques similar to those described in these papers. 

409 
We have based our approach in this paper on the module and type sys- 
tems of the programming language GSdel. The language 'LOG was developed 
by Cervesato and Rossi [5] with similar aims as GSdel, at least as far as providing 
declarative facilities for meta-programming. Each expression has basically two 
representations. One as a constant naming the expression and the other as com- 
posite object representing the structure of the expression. A particular feature of 
this language is the ability to define parts of object programs as inner programs 
for a meta-program. This provides a limited means of defining and interpreting 
programs as modules. 
References 
1. J. Barklund. Metaprogramming in logic. Technical Report UPMAIL Technical 
Report 80, Department of Computer Science, University of Uppsala, Sweden, 1994. 
to be published in Encyclopedia of Computer Science and Technology, A. Kent and 
J.G. Williams (eds.), Marcell Dekker, New York, 1994/5. 
2. K.A. Bowen and R.A. Kowalski. Amalgamating language and metalanguage in 
logic programming. In K.L. Clark and S.-A. T~irulund, editors, Logic Programming, 
pages 153-172. Academic Press, 1982. 
3. A. Brogi and S. Contiero. GSdel as a meta-language for composing logic programs. 
In F. Turini, editor, Meta-Programming in Logic, Proceedings of the ~th Interna- 
tional Workshop, Pisa, Italy. Springer-Verlag, 1994. 
4. A. Brogi, P. Mancarella, D. Pedreschi, and F. Turini. Meta for modularising logic 
programming. 
In A. Pettorossi, editor, Proceedings of the Third Workshop on 
Meta-programming in Logic, pages 105-119. Springer-Verlag, 1992. 
5. I. Cervesato and G. F. Rossi. 
Logic meta-programming facilities in 'LOG. In 
A. Petterossi, editor, Proceedings of the Third Workshop on Meta-programming in 
Logic, pages 148-161. Springer-Verlag, 1992. 
6. P. M. Hill and J. Gallagher. Meta-programming in logic programming. Technical 
Report 94.22, School of Computer Studies, University of Leeds, 1994. To be pub- 
lished in Handbook of Logic in Artificial Intelligence and Logic Programming, Vol. 
5, Oxford Science Publications, Oxford University Press. 
7. P.M. Hill. A parameterised module system for constructing typed logic programs. 
In R. Bajcsy, editor, Proceedings of 13th International Joint Conference on Artifi- 
cial Intelligence, Chamb6ry, France, pages 874-880. Morgan-Kaufmann, 1993. 
8. P.M. Hill and J.W. Lloyd. Analysis of meta-programs. In H.D. Abramson and 
M.H. Rogers, editors, Meta-Programming in Logic Programming, pages 23-52. MIT 
Press, 1989. Proceedings of the Meta88 Workshop, June 1988. 
9. P.M. Hill and J.W. Lloyd. The G~del Programming Language. MIT Press, 1994. 
10. J.W. Lloyd. Foundations of Logic Programming. Springer-Verlag, 2nd edn., 1987. 
11. B. Martens and D. De Schreye. A perfect Herbrand semantics for untyped vmxilla 
meta-programming. In K. Apt, editor, Proceedings of the Joint International Con- 
ference on Logic Programming, Washington, USA, pages 511-525, 1992. 
12. B. Martens and D. De Schreye. Why untyped non-ground meta-programming is 
not (much of) a problem. Technical Report CW 159, Department of Computer 
Science, Katholieke Universiteit Leuven, 1992. 
13. L. Sterling and E. Shapiro. The Art of Prolog. MIT Press, 1986. 

Building Proofs in Context 
Giuseppe Attardi and Maria Simi * 
Dipartimento di Informatica 
UniversitY. di Pisa 
Corso Italia 40 
1-56125 Pisa, Italy 
net: {attardi, simi}Qdi.unipi.it 
Abstract. When reasoning with implicitly defined contexts or theories, a general notion of proof in 
context is more appropriate than classical uses of reflection rules. Proofs in a multicontext framework 
can still be carried out by switching to a context, reasoning within it, and exporting the result. Context 
switching however does not correspond to reflection or reification but involves changing the level of 
nesting of theory within another theory. We introduce a generalised rule for proof in context and a 
convenient notation to express nesting of contexts, which allows us to carry out reasoning in and across 
contexts in a safe and natural way. 
1 Introduction 
A general notion of relativised truth can be useful for reasoning in and about different theories in a formal 
setting. For example to reason about the reasoning of different agents, to model temporal evolution of 
knowledge, to split a large knowledge base into manageable chunks or microtheories that can be related to 
each other by means of transfer rules or lifting axioms. 
There are several approaches to the formalization of a notion of relativised truth: by means of a predicate 
expressing "provability" like for example PR(T, P) in [22] and demo(T, P) in [7], or with a notion of truth 
in context like for example ist(c,p) in [11, 14, 15, 8] and pC in ]20], or with a notion of entailment from a set 
of assumptions like in(P, vp) [3, 21, 5 I. 
Most of these are syntactic approaches where theories are modeled as collections of reified statements or 
statement names in First Order Predicate Calculus. The object theory is extended with a meta-theory 
consisting of statements about statements. The relation between genera] validity and truth relativised to 
a subtheory is usually expressed by means of a pair of reflection/reification rules. These are classically 
formulated as follows [13, 22]: 
TFP 
( Reificationl ) 
pr"~- demo(T, P) 
pr b demo(T, P) 
TFP 
(Reflection1) 
which say that if formula P is derivable from the set of statements T, then demo(T,P) is derivable in the 
recta-theory from theory pr and vice versa, where pr is a theory containing a suitable axiomatisation of the 
demo predicate. 
Unfortunately carrying out proofs dealing with multiple theories is not simple. When reasoning about rea- 
soning, one often needs to carry out some proof steps within a different theory from the current one and 
then to lift the conclusions back into the original theory. The deductive rules required to carry out these 
steps involve either reflection principles or some other notion of proof in context. 
Standard formulations of the reflection rules assume explicit knowledge of the theory one reasons about. In 
many interesting application however it is not possible to explicitly state once for all the assumptions of a 
theory; this is often the case for theories representing agents and is always the case for infinite theories, for 
theories which refer to each other or reflective theories, as those required for expressing common knowledge. 
* This work has been done while the authors were visiting the International Computer Science Institute, Berkeley 
CA. 

411 
Moreover dynamic extension of theories, provided by lifting axioms, requires the ability to define theor{es 
implicitly. 
In this paper we discuss different approaches to contextual reasoning according to whether implicit and mu- 
tually referential theories are allowed. We will argue that implicit contexts are necessary for most significant 
applications. When reasoning with implicit contexts however, reflection rules are not the right way to tranfer 
facts from one context to another. 
Context switching in a natural deduction proof is better seen as nesting or unnesting of contexts justified 
by suitable rules for proof in context. A notation is introduced to write more readable proofs where context 
switching is interpreted according to this semantics. 
The three approaches discussed in the paper use three slightly different notations for relativised truth, whose 
correspondence is shown below: 
demo(T, P) Kowalski 
ist(T, P) 
McCarthy 
in(P, T) 
Attardi and Simi 
2 
Approaches 
to proofs 
in context 
2.1 
Explicit vs. implicit theories 
When reasoning with contexts or theories, an important distinction is whether we are dealing with explicit 
theories or with theories which axe only implicitly defined. 
In the first case we assume that a theory can be explicitly and completely characterised by a finite set of 
statements representing the relevant assumptions of the theory. If names are used for theories they should 
be considered as linguistic shortcuts for the set of statements. This is an adequate model in many practical 
situations; for example one can reason about a subset of an agent's beliefs as if it was complete, without 
having to know all of them. 
In many interesting applications theories cannot be defined explicitly as a finite set of statements and the 
ability to characterize theories implicitly is required. The language must then allow for constants, or more 
in general terms, denoting theories or contexts. 
For example, one may want to characterize theories by means of assertions, like McCarthy's lifting rules 
[McCarthy 93}, stating that whenever a formula satisfying some condition holds in a theory vpl then a related 
formula holds in another theory vp2. As a special case, subsumption between theories can be expressed as 
follows in our notation: 
Vx . in( x, vpt ) =~ in( x, vp2 ) 
Incidentally, the.possibility of quantification over statements inside the in predicate, not provided by modal 
logics, appears essential here; hence our preference for a syntactic treatment of in, our notion of relativised 
truth. 
Another example could be the evolution of state of affairs, as in: 
inffClear(A) A Clear(B)', sit1) =~ in('On(A, B)', sit(puton(A, B), sih)) 
This allows for compact statements of problems and leaves to the logic machinery the burden of incrementally 
specifying theories when the rules for their construction are known. 
Implicit theories are also required for expressing self referential statements. Here are a few examples, where 
we use in to express bell@ 
John believes that he has a false belief 
in('Jx . in(x, vp( John) ) A False(x)', vp( gohn) ) 
Agent a believes that whatever he and agent b believe is true, while b does not believe so 
in('Vx . in(x, vp(a)) V in(x, vp(b)) ~ True(x)', vp(a)) 
in('~Vx . in(x, vp(a) ) V in(x, vp(b ) ) :~ True(x)', vp(b) ) 

412 
Agent a and agent b have common knowledge (or belief) that A 
in('A', cg) 
(C/C-l) 
Vx . in(x, eK) :=> in(x, vp(a)) A in(x, vp(b)) 
( CK-2) 
Vx. in(x, CK) ::~ in(in(x, vp(a)) A in(x, vp(b)), CK) 
(CK-3) 
Note that for common knowledge it is not enough that both agents know A but it is also required that 
they know that they know A, that they know that they know that they know A,... and so on. Such infinite 
nesting calls for a recursive definition like CK-3. 
The approach of implicit contexts is carried to its extreme consequences in the proposal of McCarthy, where 
contexts are primitive objects denoted by symbols in the language, and are never explicitly characterised. 
2.2 
Reflective vs. layered theories 
Syntactic approaches to provability differ in the degree of connection between object-theory and meta-theory, 
ranging from a semantic connection of completely separate theories as in [12], to the reflection principles 
of FOL [22] between two still distinct theories, to user defined bridge rule connecting theories with distinct 
languages, to the proposal of a single amalgamated theory encompassing object and meta-level [7] or, more 
in general, reflective theories. 
Nevertheless, a satisfactory first order theory of relativised truth is not easy to develop since one must face 
delicate issues of semantics and must avoid the pitfalls of paradoxes arising from self referential statements, 
which trickle in by diagonalization [Montague 63]. 
A simple way out of paradoxes is to keep the object language separate from the metalanguage [18, 22] and 
when nested beliefs are involved, to build a hierarchy of languages, each one being a meta-language for the 
previous [12]. Self reference is not allowed and the construction of paradoxical statements is blocked. 
However this forbids also non paradoxical self referential statements like those mentioned in the previous 
section. This lack of expressiveness may be considered a major drawback [19] since self referential statements 
about truth, beliefs or knowledge arise naturally in common sense reasoning. The complex machinery required 
by the layered approach also does not seem convenient for implementation within reasoning programs nor 
natural as a formalisation of common sense. 
When self or mutually referential theories are allowed, they must be accounted for in the semantics of the 
logic. One way to do so is to use non well founded sets [1] as denotation for theories and rely on Baxwise 
solution lemma to ensure that solutions to the recursive equations exist. 
A different approach is the one pursued in the theory of viewpoints [5], where viewpoints denote recursive 
set of statements and the interpretation of in statements is done in a layer by layer fashion so as to properly 
account for paradoxical self referential statements. 
In a reflective framework reflection rules are to be carefully formulated to avoid falling into an inconsistent 
theory because of the results of [17] 2. A possibility is to be conservative and use reflection rules, such 
as the ones in [7], which do not add any new theorem with respect to the amalgamated theory without 
reflection rules. But useful non conservative formulations, still preserving consistency, axe possible, as the 
one we propose for the theory of viewpoints. 
2.3 
Reflection rules vs. nesting/unnesting 
When reasoning with multiple theories one needs rules for context switching, i.e. for moving from one theory 
to another, performing some deduction there and then transfering elsewhere some of the derived consequences. 
For theories which 'are specially related by being one the meta-theory for the other, reflection and reification 
may be used for this purpose. 
All standard formulations of the reflection rule postulate that only theorems can be object of reflection, in 
fact the premise of the rule is something like 
pr F derno(T,P) 
where pr is just an axiomatization of provability. In other words, demo(T, P) cannot be just asserted as part 
of the statement of the problem or assumed during a hypothetical line of reasoning. 
2 Note that this could happen even in a layered framework if the layering collapses due to strong bridge rules 

413 
When dealing with implicit theories, the following is a very useful pattern of reasoning. One could assert or 
assume: 
demo(T, P) 
and given that P F Q, one would like to conclude that 
demo(T, Q) 
Standard reflection would not be applicable for such kind of reasoning since an asserted or assumed demo 
statement is not a logical theorem. It is possible to strengthen reflection to make it applicable in such cases, 
as proposed for instance in [10] or [6], provided the conclusion still depends on the assumptions made to 
derive the antecedent. 
Reification should be restricted accordingly to prevent unsound consequences. For example the antecedent 
T F Q of reification should not be the consequence of an assumption or something which is just stated but 
rather must correspond to a real ability to prove. Differently one could use reification to conclude demo(T, S) 
in any theory from the fact that S is true (or is asserted to be derivable) in theory T. These restrictions 
would again prevent the application of reification for concluding demo(T, Q), 
For a sligthly different reason we believe that reification is also used improperly in the solution to the three 
wise men puzzle presented in [13] in the framework of the amalgamated logic of Bowen and Kowalski [7]. 
The pattern of reasoning used there corresponds to constructing a new object level theory consisting of those 
statements P such as 
demo(T, P) 
holds. This theory should not be confused with T, since it is rather an image of T from the perspective of 
the current reasoner; let us call it T'. Once the conclusion Q is reached in T' reification is used, improperly, 
to conclude demo(T, Q). 
These considerations suggest that another kind of context switching is more appropriate when reasoning 
with implicit contexts which are dynamically nested during deduction: this kind of contextual reasoning can 
be made explicit, by representing somehow the structure of nesting. 
For example, in their formalization of contexts [8] Buva~ and Mason propose rules for context switching 
which correspond to this idea, and introduce indexes made of sequences of context names to represent nested 
contexts. The rule they present is bidirectional and reads as follows: 
~-~ iSt(kl, r 
(cs) 
The index k represents a sequence of contexts and the rule expresses that a statement about the truth of r 
in a series of nested contexts k can be turned into the fact r holding in the series of contexts k 9 kl. Keeping 
track of the level of nesting is crucial for the correctness of the rule. 
Following this idea we will formally justify our notion proof in context, introduce a notation for nest- 
ing/unnesting of contexts and present a solution to the three wise men which does not make use of reflection 
rules, but still exploits a very general mechanism for context switching. 
3 
Proof theory 
In order to discuss the problems and subtle issues hinted in the previous sections, we introduce a formal 
deductive system for proofs in contexts developed in connection with the theory of viewpoints [5]. 
The theory of viewpoints is a reflective first order theory with explicit or implicit viewpoints (viewpoint 
constants and functions). A complete semantic account of viewpoints is presented in I5]. 
Viewpoints are sets of reified statements and the expression in('P', vp) means that a statement P is contex- 
tually entailed by the set of assumptions represented by vp. 

414 
More precisely, given a term tl denoting a statement and a viewpoint expression t2 denoting a set of state- 
ments, in(t1, t2) is true at a model 2r 
the statement denoted by tl is true in any model of the statement 
denoted by t2 which is "coherent" with 2el in the interpretation of viewpoint constants and functions. 
The proof theory for viewpoints can be conveniently presented in the style of natural deduction. 
3.1 
Inference rules for classical natural deduction 
As customary, the notation F F P indicates the pending assumptions in rules where some of the assumptions 
are discharged, like in the cases of implication introduction and negation introduction. When the pending 
assumptions are.the same in the antecedent and consequent of a rule they are omitted. 
The rules for natural deduction are quite standard. For example: 
P'Q 
(^;) 
PAQ 
(^E) 
PAQ 
P,Q 
are the rules for conjunction introduction and elimination, respectively, and 
Fu{P}I-Q 
(o I) 
P'P=~-----~Q (~ E) 
FI-(P~Q) 
Q 
are the rules for implication introduction and elimination. The full set of classical rules used is presented in 
the appendix. 
3.2 
Metalevel axioms and inference rules 
The behaviour of in is characterised by the following axioms and inference rules, which allow classical rea- 
soning to be performed inside any viewpoint. 
The first axiom asserts that all the statements which constitute a viewpoint hold in the viewpoint itself, 
while the second establishes a principle which could be called positive introspection, if we chose an epistemic 
interpretation for in. The third axiom states monotonicity of viewpoints. 
i,('P', { .... 'P',...}) 
in(IP ', vp) =~ in('in (~P ', vp)', vp) 
in(IP', vp) =r in('P', vp u {'Q'}) 
(Axiom1) 
(Axiom2) 
(Axiom3) 
in ('P', vp), in('Q', vp) 
in('P A Q',vp) 
(Meta A I) 
in ('P ^ Q', vp) 
in('P',vp),in('Q', vp) 
(Meta A E) 
in('Q',vpu {'p'}) 
in('P =~ Q',vp) 
( Meta ::~ 1) 
in('P', vp), in(~P =r Q', vp) 
in('Q',vp) 
(Meta ~ E) 
The full set of meta-inference rules is presented in the appendix. 
Moreover we have a meta-inference rule for each classical natural deduction inference rule. For example: 

415 
3.3 
Reflection rules 
The following are the reflection and reification rules for the theory of viewpoints: they are more powerful 
than those of [7], but still safe from paradoxes as discussed in [4]. 
vpl F in(IP',vp2) 
vpl U vp~ b P 
(Reflection) 
vpFc P 
F in('P',vp) 
( Rcification) 
The notation Fc stands for "classically derivable" or "derivable without using the reflection rules". 
We have argued elsewhere for the usefulness of the strong version of reflection [4], [5]. As a consequence we 
have: 
Theorem 1. in(IP ', {'Q'}) =~ (Q =v P) 
Reiflcation is a derived inference rule; in fact any proof at the object level can be completely mirrored at the 
metalevel using the meta-level inference rules. In fact also the stronger 
vp f-c P 
i]] 
~-e in('P',vp) 
holds. 
This can be proved by induction on the length of the proof, with the base case being provided by Axioml, 
or derived as a consequence of theorem 3 below. 
3.4 
Proof in context 
Proof in context is a powerful mechanism for reasoning across multiple contexts. In this section we present 
the results which provide the formal justification for this technique. 
First we note that logical theorems can be used in proofs within any context, and then that classical deduc- 
tions can be carried out within any viewpoint. 
The first result is a consequence of reification and Axioml: 
Theorem 2. in('P',vp), for any logical theorem P and viewpoint vp. 
FFcP 
Theorem 3 Proof in context. 
in('P, vp) Fc in('P', vp) 
where the/" is a finite set of sentences and the consequent should be read as the conjunction o] the formulae 
in 1". 
Proof. The proof is by induction on the length of the derivation and by showing that each step can be 
mirrored at the metalevel using the corresponding recta-inference rule. The only interesting case is the one 
for implication introduction. Suppose that this rule was used in the last step of the derivation to prove 
Q ~ R. We have by induction hypothesis: 
r u {Q} ~c n 
in('P A Q',vp) I-c in('R',vp) 
Therefore: 
in ('F j, vp) 
(premise) 
in('Q', vp u {'Q'} ) 
(Axiom1) 
in('F A Q', vp u {'Q'}) 
(Ueta ^ 1) 
in('R', vp u {'Q'} ) 
(induction) 
in('Q ~ R',vp) 
(Ueta =r 1) 

416 
The following inference rules can be established from theorem 3: 
in('P', vp), P I- c Q 
(Proof in context) 
i.('Q', vv) 
which generalises to: 
{x [in(x, vp) } t- C P 
( Generalised proof in context) 
in('P', vp) 
The antecedent of the rule corresponds to the condition that in order to exploit a proof carried out in another 
context one must know at least that the premises of the proof are in that context. 
Notice that the consequent of theorem 3 is again a classical derivation, therefore the theorem can be applied 
repeatedly, to carry out a proof at any level of nesting within viewpoints. Therefore, if P I-c Q then: 
in('P',vpl) I"c in('Q',vpl) 
in ('in('P', vpl )', vp2) I-c in ('in ('Q', vpl )', vp2 ) 
Similarly the rules of proof in context can be extended to deal with arbitrary level of nesting. 
3.5 
Entering and leaving contexts 
Another useful mechanism to build proofs in context is the ability to switch contexts and perform natural 
deduction proofs within viewpoints. The safest way to interpret context switching in the framework of natural 
deduction proofs with pending assumptions and implicit contexts is simply to go one level deeper or shallower 
in nesting, or in other words unnesting and nesting. 
This means for instance that in order to prove a statement of the form 
in (ip,, vpl ) 
one may pretend to move inside vpl, and perform a proof using available facts of the form in('...', vpl). If 
the formula P is itself of the form in('Q', vp2) one will have to go one level deeper to prove Q by using this 
time just facts of the form in('in('...', vp2)', vpl ). 
Later we will provide safe rules for importing and exporting facts in a context. 
4 
A proof method 
and notation 
Our proofs will become more readable and intuitive with the aid of a graphical notation, which emphasises 
the boundaries and nesting of contexts. The notation we introduce is an extension of the box notation 
introduced by Kalish and Montague [16]. 
4.1 
Rules for classical natural deduction 
We show here some examples of proof schemas for classical natural deduction. 
The following schema corresponds to the rule of =~ I and should be read as: "if assuming P you succeed in 
proving Q, then you have proved P =~ Q". 
P 
(assam.) 
P~Q 
Similarly, the schema corresponding to the inference rule of -~ I is the following: 

417 
P 
(~ss~,,n.) 
-~p 
The box notation is useful to visualise the scope of the assumptions made during a natural deduction proof. 
In performing a proof within a box one can use facts proved or assumed in the same box or in enclosing 
boxes. Facts cannot be exported from within a box to an enclosing or unrelated box. 
4.2 
Rules for proofs in context 
For proofs in context we introduce a different kind of box, with a double border, to suggest boundaries which 
are more difficult to traverse. The double box represents a viewpoint, i.e. a theory, whose assumptions, if 
known, are listed in the heading of the box. If the assumptions are not known the name of the viewpoint 
is shown. The only two rules for bringing facts in and out of a double box are the rules corresponding to 
unnesting and nesting. 
Importing a fact in a viewpoint: 
in ('P', vp) 
(unnesting) 
Exporting a fact from a viewpoint: 
vp 
(nesting) 
m('P', vp) 
The only way to import a fact P in a double box vp is to have a statement in('P',vp) in the environment 
immediately outside the box. Symmetrically you can obtain in('P~,vp) in the environment immediately 
outside a double box vp if P appears in a line immediately inside the double box (not inside a further single 
or double box within the double box). Note that to import a fact in nested double boxes an appropriate 
number of crossing double lines must be justified. 
According to Axiornl, the assumptions of a viewpoint, if known, can also be used inside the viewpoint: 
i 
('P~ ..... ,p-} 
P1, . . . , P,~ 
and, in the case of explicit viewpoints, in can be introduced as follows: 
II 
{'P{ .... , P,~} 
P 
in ('P', {'P{ ..... 'P~' }) 
Theorem 3 justifies the possibility of carrying on regular natural deduction proofs within a double box. For 
example the following deduction schema is valid: 

418 
vp 
P 
(assure.) 
~P 
in('~P', vp) 
This is just a combination of the schemas introduced above for classical negation introduction and nesting. 
Notice that opening a single box within a double box to make an assumption corresponds to adding the 
assumption to those of the viewpoint in the box. In practice, it should be considered as an alternative 
notation for: 
vpU {'P'} 
in ('-,P', vp) 
This schema provides us a mean to carry out proofs by contradiction, which naturally occur in the solution 
of the three wise men puzzle. 
5 
Examples 
To illustrate the method just described we will use two examples taken from the recent literature where 
proofs are composed of subproofs in different contexts. 
The first example was used by John McCarthy [15] to illustrate the power of "lifting axioms", which allow 
extrapolating facts from one theory to another and transforming them at the same time into a different 
format. Even though no formal proof theory was provided, the example was meant to suggest the kind of 
proofs one would like to be able to perform. In this case, things are complicated by the fact that the proof is 
carried out in a natural deduction setting, so there are pending assumption when switching from one context 
to another. 
The second one is a solution to the classical three wise men puzzle, which as been tackled in so many 
different ways in the knowledge representation literature. In [6] we discussed for example the approach taken 
by Kowaiski and Kim [13] where a rule of reification is used, we believe improperly, to lift a conclusion 
reached in a common knowledge theory wiseo to the theory of the third wise man. Our solution is meant to 
show that a natural representation of the kind of knowledge and reasoning involved in the puzzle requires the 
ability to express common knowledge through recnrsive definition (hence implicit contexts) and a mechanism 
for nesting and unnesting. 
5.1 
Lifting rules and natural deduction 
In performing proofs involving multiple theories, one would like to be able to move easily from one theory 
to another, reason within a theory with traditional means, for instance by natural deduction, and then to 
carry outside some of the consequences obtained. 
One must be careful however, not to leave behind in an innermost context essential assumptions and not to 
extrapolate to an unrelated context. 
The example presented in [15] is useful to illustrate these issues. 

419 
A fixed theory, called AboveTheory, is used to represent the basic facts about the blocks world which do not 
depend on situations. One would like to make these facts and their consequences available, in the appropriate 
form, in another theory c where situations are accounted for. The correspondence between these theories is 
established by axioms written in viewpoint c. 
An outer context, co, is also needed for lifting facts deduced in AboveTheory to c. Using our notation, the 
statement of the problem can be expressed as in Figure 1. 
To simplify the notation, we have dropped the quotation marks used to represent meta-level statements. 
co 
(1) Vp in(p, AboveTheory ) =~ in(in(p, AboveTheory), c) 
AboveTheory 
(2) Vx, y on(x,y) ~ above(x,y) 
(3) Vx, y, z above(x, y) A above(y, z) ~ above(x, z) 
(4) vx, y, s on(=, y, s) ~, in(~n(x, y), c(s)) 
(5) Vx, y, S above(x, y, s) ~, in(above(x, y), c(s)) 
(6) Vp, s in(p, AboveTheory) =~ in(p, c(s)) 
Figure 1. Statement of the lifting problem 
The lifting axiom (1) was missing in the sketch of proof presented by McCarthy [15] but it is necessary in 
order to lift 
in(Vx, y on(x, y) =~ above(x, y ), AboveTheory ) 
from co to c where it can be exploited by axiom (6). Without this additional assumption step (10) below 
could not be accounted for by any sound rule, producing a case of improper lifting. 
The full proof appears in Figure 2. 
5.2 
The three wise men 
The statement of this well known puzzle is the following [13]. 
A king, wishing to determine which of his three wise men is the wisest, puts a white spot on each of 
their forheads, and tells them that at least one of the spots is white. The king arranges the wise men 
in a circle so that they can see and hear each other (but cannot see their own spots) and asks each 
wise man in turn what is the colour of his spot. The first two say that they don't know, and the third 
says that his spot is white. 
Several solutions to the three wise men puzzle have appeared in the literature, some of which quite reasonable. 
Our aim here is to illustrate the adequacy of a general method for reasoning about nested beliefs by presenting 
a solution which is both a sound and, we believe, intuitive. In this spirit we will limit ourselves to the core 
aspects of the puzzle, without dealing with the derivation of negative knowledge or the evolution of time as 
for example in [2, 9]. 
In our solution common knowledge is grouped in a single theory and lifting axioms are provided for each 
agent to access it. The advantages are a more compact statement of the problem which does not rely on "ad 
hoc" initialization of theories. 
A common approach to the representation of nested beliefs is to introduce explicitly a number of different 
theories according to the different views that an agent has of other agents. In the three wise men puzzle we 

420 
co 
(7) in(on(A, B, So), c) 
(assumption) 
C 
(8) on(A, B, So) 
(9) in(on(A, B), c(So)) 
(10) in(Vx, y on(x, y) =~ above(x, y), AboveTheory) 
(11) in(Vx, y on(x,y) ~ above(x,y),c(So)) 
c(So) 
(unnesting, 7) 
(8 and 4) 
(2, nesting, 1, unnesting) 
(proof in context, 6 and 10) 
(12) on(A, B) 
(13) Vx,y on(x,y) ~ above(x,y) 
(14) above(A, B) 
(15) in(above(A, B), C(So)) 
(16) in(above(A, B), c(So)) ~ above(A, B, So) 
(17) above(A, B, So) 
(18) in(above(A, B, So), c) 
(unnesting, 9) 
(unnesting, 11) 
(proof in context, 12 and 13) 
(nesting, 14) 
(instance of 5) 
(proof in context, 15 and 16) 
Figure 2. Proof of the lifting problem 
would have the theory that wises has about wise2, the theory that wises has about the theory that wise2 
has about wise1, ... and so on [12]. The construction of tower of theories, each one being "meta" for the one 
below, is what justifies the use of reflection and reification principles to transfer information between them 
(for a recent solution along these lines see for example [9]). 
It seems to us quite unnatural to be forced to conceive from the beginning an appropriate number of theories 
according to the number of agents and the nesting level of the reasoning which is required: in this simple 
puzzle, which requires a nesting level of three, one should theoretically conceive of 27 different theories (even 
without considering the evolution of time). 
On the fly construction of theories on the other hand requires some additional mechanism such as dealing 
with sequences of contexts as in [8]. 
Our solution is not radically different but, we believe, more natural. The nesting of viewpoints implicitly 
takes care of the different perspectives. 
Finally our solution does not rely on axioms like confidence [2, 13] or wiseness [3] which are used in other 
solutions to make a wise man believe any conclusion of another wise man that he is aware of. 
The following viewpoints are used. 
wisev viewpoint of the first wise man 
wise2: viewpoint of the second wise man 
wises: viewpoint of the third wise man 
CK: 
viewpoint including the common knowledge. 
The predicate whitel means the color of the spot of wise man i is white. The common knowledge viewpoint 
is shown in Figure 3. 
Two axioms, external to the CK and wise men viewpoints are needed for the wise men to obtain the common 
knowledge. 
(1) Vx in(x, CK) 
in(x, wise1) A in(x, wise2) A in(x, wise3) 
(2) Vx in(x, CK) 
in(in(x, wise1) A in(x, wise2) A in(x, wise3), CK) 

421 
CK 
(3) white1 v white2 v whites 
(4) white1 ~ in(white1, wise2) ^ in(whitel, wises) 
(4') -~whitel =~ in(~whitel, wise~) A in(~whitel, wise3) 
(5) whites =~ in(white2, wise1) A in(whites, wise3) 
(5') -~white2 =~ in(-~white2, wise1) A in(~white2, wises) 
(6) whites =~ in(whites, wise1) A in(whites, wise2) 
(6') ~white3 ~ in('~white3, wisel) A in('~white3, wise2) 
(7) ~in (white1, wise1 ) 
(8) ~in(white2, wise2) 
Figure 3. Statement of the problem in the three wise men puzzle 
(at least one spot is white) 
(wise2 and wises see wisel's spot) 
(wise1 and wise3 see wise2's spot) 
(wise1 and wise2 see wises's spot) 
(asserted by first man) 
(asserted by second man) 
Axioms (1) and (2) provide a proper account of common knowledge, allowing to derive the commonly known 
facts in any viewpoint, no matter how nested. In particular axiom (2) is used to achieve the appropriate 
level of nesting in CK, axiom (1) to lift from the CK viewpoint to any other viewpoint. The details of the 
derivation of common knowledge are omitted from the proof. 
We can formally account, as shown in Figure 4, for the reasoning of the third wise man after the first and 
second one have spoken. The third wise man is in fact able to prove that his spot is white. 
wise3 
(9) -~whitea 
(10) ~white3 ~ in(-~whitea, wise2) 
(11) in(-~whites, wise2) 
wise2 
12) -~whitea 
(13) ~white2 
(14) ~white2 A ~white3 
(15) ~white2 ::~ in(~white2, wisel) 
(16) "~white3 :~ in('~whites, wisel ) 
(17) in(-~white2 A -~white3, wise1) 
(18) in(white1 V whites V white3,wisel) 
wisel 
(19) ~white2 A ~whitea 
(20) whitel V white2 V whites 
(21) white1 
(unnesting, 17) 
(unnesting, 18) 
(19, 20) 
(22) in(white1, wisel) 
(23) ~in(whitel , wise1) 
24) white2 
(25) in(white2' wise2) 
(26) ~in(white2, wise2) 
(assumption) 
(6, 1) 
(9, 10) 
(unnesting, 11) 
(assumption) 
(12, 13) 
(5, 2, I) 
(6, 2, 1) 
(14, 15, 16) 
(3, 2, i) 
(nesting 21) 
(7, 2, 1) 
(-~ I, 22, 23) 
(nesting) 
(8, 1) 
(27) whites 
(28) in(white3, wises) 
Figure 4. Proof of the three wise men puzzle 
(-~ ], 25, 26) 
(nesting, 27) 

422 
6 
Conclusions 
We have discussed several approaches to the realization of formal systems for contextual reasoning. Important 
issues in this respect are whether explicit or implicit theories are allowed and whether theories are stratified 
or one unique reflexive theory is allowed. 
We described a set of inference rules for proof in context based on the theory of viewpoints and a notation 
for their application which expands on the box notation introduced by Kalish and Montague for natural 
deduction. 
We suggested that when dealing with partially specified theories or contexts a generalised notion of proof in 
context is more appropriate than reflection rules and gave an account of what "entering" and "leaving" a 
context should be in the setting of natural deduction proofs. 
Acknowledgments 
We wish to thank the International Computer Science Institute in Berkeley, for pro- 
viding the support and the right atmosphere to get this work done and Sa~a Buva~ for interesting and useful 
discussions whic.h helped us to better understand McCarthy's notion of context. 
References 
1. P. Aczel (1988). Non.well-founded sets, CSLI lecture notes, 12, Center for the Study of Language and Information, 
Stanford, California. 
2. L. C. Aiello, d. Nardi, M. Schaerf (1988). Reasoning about Knowledge and Ignorance, in International Conference 
of 5th generation Computer System, pages 618-627, Tokyo. 
3. G. Attardi and M. Simi (1984). MetManguage and reasoning across viewpoints, in ECA184: Advances in Artificial 
Intelligence, T. O'Shea (ed.), Elsevier Science Publishers, Amsterdam. 
4. G. Attardi and M. Simi (1991). Reflections about reflection, in Allen, 3. A., Fikes, R., and Sandewall, E. (eds.) 
Principles of Knowledge Representation and Reasoning: Proceedings of the Second International Conference. 
Morgan Kaufmann, San Mateo, California. 
5. G. Attardi and M. Simi (1993). A formalisation of viewpoints, TR-93-062, International Computer Science Insti- 
tute, Berkeley. 
6. G. Attardi and M. Simi (1994). Proofs in context, in Doyle, J. and Torasso, P. (eds.) Principles of Knowledge Rep- 
resentation and Reasoning: Proceedings of the Fourth Inter'national Conference. Morgan Kaufmann, San Mateo~ 
California. 
7. K.A. Bowen and R.A. Kowalski (1982). Amalgamating language and metalanguage in logic programming, in 
Logic Programming, K. Clark and S. Tarnlund (eds.), Academic Press, 153-172. 
8. S. Buva~ and I.A. Mason (1993). Propositional Logic in Context, Prec. of the Eleventh AAA1 Conference, Wash- 
ington DC, 412-419. 
9. A. Cimatti and L. Serafini (1994). Multi Agent Reasoning with Belief Contexts: the Approach and a Case Study", 
proceedings of ECAI-94, Workshop on Agent Theories, Architectures, and Languages. 
10. F. Giunchiglia, L. Seraflni, Multilanguage hierarchical logics (or: how we can do without modal logics), Artificial 
Intelligence, 65:29-70, 1994. 
11. R.V. Guha (1991). Contexts: a formalization and some applications, MCC Tech. Rep. ACT-CYC-42391. 
12. K. Konolige (1982). A first order formalization of knowledge and action for a multiagent planning system, Machine 
Intelligence 10. 
13. R. Kowalski and Kim 3.S. (1991). A metalogic programming approach to multi-agent knowledge and belief, in 
Vladimir Lifschitz (ed.), Artificial Intelligence and the Mathematical Theory of Computation: Papers in Honor 
of John McCarthy, Academic Press, 1991, Academic Press, 231-246. 
14. J. McCarthy, Generality in Artificial Intelligence, Communications of the ACM, 80(12), 1987, 1030-1035. 
15. J. McCarthy (1993). Notes on Formalizing Context, Proceedings of the Thirteenth International Joint Conference 
on Artificial Intelligence, Chambery. 
16. D. Kalish and R. Montague (1964). Logic: techniques of formal reasoning, New York, Harcourt, Brace & World. 
17. R.. Montague (1963). Syntactical treatment of modalities, with corollaries on reflexion principles and finite ax- 
iomatizability, Aeta Philosoph. Fennica, 16, 153-167. 
18. R. C. Moore (1977). Reasoning about knowledge and action, Prec. of 1JCA177, Cambridge, MA, 223-227. 
19. D. Perlis (1985). Languages with self-reference I: foundations, Artificial Intelligence, 25:301-322. 
20. Y. Shoham (1991). Varieties of contexts, in Vladimir Lifschitz (ed.), Artificial Intelligence and the Mathematical 
Theory of Computation: Papers in Honor of John McCarthy, Academic Press, 393-407. 
21. M. Simi (1991). Viewpoints subsume belief, truth and situations, in Trends in Artificial Intelligence, Prec. of 2nd 
Congress of the ltalian Association for Artificial lnteUigenee, Ardizzone, Gaglio, Sorbello (Eds), Lecture Notes 
in Artificial Intelligence 549, Springer Verlag, 38-47. 
22. K.W. Weyhrauch (1980). Prolegomena to a theory of mechanized formM reasoning, Artificial Intelligence, 
13(1,2):133-170. 

423 
A 
APPENDIX 
A.1 
Inference rules for classical natural deduction 
P,Q 
PAQ 
PAQ 
P,Q 
(^ 1) 
(A ~-~ 
FU{P}FQ 
_r F (p ~ Q) 
P,P~Q 
Q 
P 
PVQ, QvP 
(o I) 
(~ 
(v ~) 
P v Q,P ~ R,Q ~ R 
R 
Pr 
~P 
(v E) 
(-,-O 
-~p 
P 
(-~E) 
Ply~x] 
where y is a new variable 
Vy.P 
(v I) 
where the notation P[t/x] stands for P with all the free occurrences of variable x substituted by t. 
"ix, P 
P[t/x] 
Pit~x] 
3x . P 
3x . P 
P[ylx] 
where t does not contain variables occurring in P 
(v E) 
(3 1) 
where y is a new variable 
(3 z) 
A.2 
Metalevel axioms and inference rules 
m('p',{ .... 'P',...}) 
(Axiom1) 
in('P', vp) ~ in('i,('P', vv)', vp) 
(A~2) 
in('P', vv), i,('Q', vp) 
in(~P A Q',vp) 
in('P A Q',vp) 
in('/:", vp), i.('Q', vp) 
in('Q',vp U {'P'}) 
in(*P =~ Q',vp) 
( Meta ^ 1) 
(Meta A 
( meta =~ 1) 

424 
in('P',vp),in('P ~ O',vp) 
i.('Q', vp) 
in('P', vp) 
in('P v Q', vp), in('Q y P', vp) 
in(T v Q', vp), in('P =~ n', vp), in('Q ~ n', vp) 
in('R',vp) 
in('P', vp), in('P ~ Q ^ ",Q', vp) 
9 in ("~PI, vp) 
in('-'.~P', vp) 
in ('P', vp) 
in ('P[y/=]', ~p) 
in('u 
P', vp) 
in('Vx . PI,vp) 
i.( ,P[t / =],, ~p ) 
i.('t.[t / z]', ~p ) 
in('3x . P', vp) 
in('~x. P', vp) 
in('P[y/x]', vp) 
( Meta =r E) 
(Meta V 1) 
( Meta V E) 
( Meta -~ 1) 
( Meta - E) 
(Meta V I) 
( Meta V E) 
(Meta 3 1) 
(Meta 3 E) 

Introspective Metatheoretic Reasoning* 
Fausto Giunchiglia 1,2 Alessandro Cimatti 1 
1 IRST, 38050 Povo, Trento, Italy 
2 University of Trento, Via Inama 5, 38100, Trento, Italy 
Abstract. This paper describes a reasoning system, called GETFOL, able 
to introspect (the code implementing) its own deductive machinery, to 
reason deductively about it in a declarative metatheory and to produce 
new executable code which can then be pushed back into the underly- 
ing implementation. In this paper we discuss the general architecture of 
GETFOL and the problems related to its implementation. 
1 
The 
Goal 
The work partially described in this paper tackles the problem of investigat- 
ing criteria and techniques for the development of real introspective/reflective 
systems. We describe a system, called GETFOL 3 [Giu92], able to introspect its 
own code, to reason deductively about it in a declarative metatheory and, as 
a result, to produce new executable code which can then be pushed back into 
the underlying implementation. The behaviour of this system is schematized in 
three steps (see figure 1). We call Lifting the first step, projecting computation 
into deduction. With lifting, the source code of the system is processed, and 
a formal metatheory describing it is automatically generated. Then, during the 
Reasoning step, the theorem proving capabilities of the system are used to reason 
about the lifted theory. This allows to deduce theorems which can be interpreted 
as specifications of new system functionalities. We call Flattening the last step, 
dual of lifting, projecting deduction into computation. By flattening, new pieces 
of executable code are automatically generated from statements proved with 
the reasoning step, and added to the system code. In this way the system may 
be extended, adding new inference procedures, and modified, substituting old 
versions of inference procedures with new, possibly optimized, ones. 
Figure 2 shows the conceptual dependencies among the entities involved in 
the process of figure 1. The starting point is the object theory OT. We give a 
computational account of OT, i.e. we mechanize it, by writing code. By devising 
MT, we give a declarative characterization of OT. The lifting and flattening pro- 
cedures act as a bridge between the code implementing OT and its metatheory 
MT. We call the process described in figure 1, introspective metatheoretic rea- 
soning (IMR). Introspective because the system is able to formalize and reason 
* This work has been done at IRST as part of the MAIA project. 
3 GETFOL is a reimplementation/extension of the F0L system [WeyS0, GW91]. GETFOL 
has, with minor variations, all the functionalities of Ft}L plus extensions, some of 
which described here, to allow for metatheoretic theorem proving. 

426 
METATHEORY 
r 
.
.
.
.
.
.
 
- 
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
 
Lifted 
] 
Aut~ 
Reas~ 
I Inference 
" 
Axioms[ 
(2) 
[Theorems 
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
 
! 
Basic 
(1 2 3) 
[ Derived & 
Inference 
l~[ Optimized 
Procedures 
System Modification 
Rules 
SYSTEM CODE 
Fig. 1. The tiâ€¢ng-reasoning-flattening cycle. 
about (parts of) its own code. Metatheoretic because we require that MT be a 
metatheory of the theory OT mechanized by the system code. Notice that rea- 
soning in a formal metatheory gives the right perspective for describing inference 
mechanisms. In general one would like to prove that a new inference procedure 
is derived from, admissible or consistent with the already existing ones. This 
is the kind of results that metatheoretic reasoning provides (see for instance 
[BMS1, GS88, Pau89]). However MT is different from any other metatheory de- 
fined in the past. Not only does it describe the object level logic, but it also takes 
into account the computations implementing it. Its theorems can be interpreted 
in terms of both the object level logic and its mechanization. To point out this 
fact, we say that MT is a metatheory of a mechanized object theory. 
Some observations. The work closest in spirit to ours is Smith's [Smi83]. In 
Smith's reflective 3-Lisp, the flow of computation can be inspected by reifying 
the status of the interpreter in explicit data structures, and modified by suitably 
updating these data structures. In both his and our approaches, what Smith calls 
an embedded account of the system, i.e. a (partial) description of the system in 
the system itself, can be automatically generated and the system's behaviour 
can be modified. The basic difference is in the way the system is modified. In 
3-Lisp these changes can not be deelaratively reasoned about but only performed 
procedurally by computation. 
On the other hand, our architecture is based on a sharp distinction between 
computation and deduction. There are many reasons underlying this choice. Epis- 
temologically, we believe that deduction and computation are two fundamentally 
different phenomena. Technically, using logic gives a semantics which allows us 
to make and prove correctness statements. Implementationally, we can use and 
integrate different techniques for solving the different aspects of the problem. 
For instance theorem proving techniques can be used for the automation of the 
reasoning step, while techniques for the synthesis, optimization and verification 

427 
MT = Metatheo~(O T)_ .... 
~''Code= 
LMIFTechINaniGzltCiold(ell 
M) T~~_~ 
FLATTENING: MT -> Code 
Fig. 2. The conceptual schema of the system 
of the correctness of programs can be used for the implementation of the lifting 
and flattening processes. Furthermore, from a cognitive science viewpoint, formal 
deduction seems more suited than computation for the modeling of reasoning 
(but see [JL83]). 
Though distinguished, computation and deduction are related. This is a well 
known fact in the mathematical logic literature. It is in fact possible to express 
deduction in terms of computation (e.g. in the A-calculus) and viceversa deduc- 
tion (e.g. in Peano arithmetics) may represent computation. A formal definition 
of the lifting and flattening processes, together with a proof of their complete- 
ness and correctness, could be seen as a re-statement of some of the results in 
the mathematical logic literature. However, these similarities are more superfi- 
cial than it might look at a first sight. The results in the mathematical logic 
literature allow us to connect in a general way (to the extent that it is possible) 
deduction with computation in idealized programming languages (e.g. functional 
languages). In our work we have connected deduction in a formal metatheory 
(see section 2), particularly suited for representing search strategies [GT92], and 
the code of a real running system, GETFOL, with more than one MB of source 
code. Establishing this connection has required facing a lot of problems which 
are irrelevant from the point of view of mathematical logic and which are due 
to the fact that we are dealing with a real system. These problems and our pro- 
posed solutions are informally (and partially) described in the following of this 
paper. Thus, in section 2 we describe the structure of the metatheory MT, and 
various ways of reasoning about and extending inference mechanisms. In section 
3 we discuss the problem of writing code which can be lifted. In section 4 we 
focus on the problems related to lifting and flattening the code of a real system, 
showing how MT can be automatically generated. Finally, in section 5 we draw 
some conclusions. 

428 
2 
MT: a metatheory of a mechanized object theory 
] AAB 
] A(Y) 
I Vx'A(x) 
I 
--X- ^E 
Vx.A(x-----Z v1 
A(t-----F- VE 
Fig. 3. Some inference rules 
The metatheory MT described in this section is a minor extension of the metathe- 
ory defined and formally studied in [GT91, GT92, GT94]. In this section we 
summarize the ideas described in those papers to the extent that it is needed for 
the goals of this paper. 
We suppose that OT uses a first order classical sequent logic. By sequent we 
mean a pair (F, A), where A is a formula and F a set of formulas. The inference 
rules are a sequent presentation of Prawitz' natural deduction calculus [Pra65]. 
They allow introduction and elimination in the post-sequent A. Some of the rules 
are shown in figure 3. They are one of the two conjunction elimination rules, and 
the rules for introduction and elimination of the universal quantifier. MT con- 
tains all the "standard" information about OT. That is, its language must have 
names for all the objects of OT (constants, variables, sequents, ...). It must have 
axioms that say, for instance, that z is a variable (i.e. Var("x"), where "x" is 
the name of z), that a sequent s is a conjunction (i.e. Conj("s")) and so on. 
This construction is routinary and it is not reported here. More interestingly, 
each (piece of code implementing an) inference rule of OT is represented in MT 
by a function symbol. The (subroutines implementing the) inference rules listed 
above are represented in MT by the function symbols alli, alle and ande. Their 
behaviour is described by the axioms of figure 4. T represents provability for 
(the mechanization of) sequents..Aa~d~ states that, if (the subroutine for) and 
elimination is applied to any (data structure representing a) provable sequent 
z whose formula is a conjunction, the (data structure representing the) result 
ande(z) is also a provable sequent. The other axioms have a similar interpreta- 
tion. The predicates Vat, Term and Forall represent the (code computing the) 
properties of being an individual variable, a term and a sequent with a univer- 
sally quantified formula. NoFree represents the (code computing the) restriction 
on the generalized variable in the rule of forall introduction. 
(.A~na~) : Vx.(T(x) A Conj(x) D T(ande(x))) 
z))) 
(Aaui) Yx y z.(T(x) A Vat(y) A Var(z) A goFree(z, x) D T(alli(x, y, 
(AaU,) Vx y.(T(x) A Term(y) ^ Forall(x) D T(alle(x, y))) 
Fig. 4. Axiomatization of primitive inference rules 
The axioms in figure 4 allow only for reasoning about correct proofs, i.e. com- 
positions of applicable inference steps. However, while trying to prove a theorem, 
rarely the user (or the system itself) has a detailed proof schema in mind, and 
inference rules may be tried without knowing whether they are applicable or not. 
In the code of G~.TFOL possible failures are taken into account by suitable sub- 
routines, called tactics. Tactics call the basic inference rules when applicability 

429 
conditions are satisfied, otherwise return a particular data structure representing 
failure. In order to implement the cycle of figure 1, tactics, and therefore failure, 
must be represented in MT. Failure is represented by the individual constant 
fail9 The basic concept of being a failure is expressed by the predicate Fail 
defined as 
Vz.Fail(x) ~ x = fail 
The axiom 
(A~ott/aiz) : Vx.",(Fail(x) A T(z)) 
states that T and Fail are disjoint9 Being a proof step (either successful or 
failing) is expressed by the predicate Tac, defined by the axiom 
(.ATac) : Vx.Tac(z) ~ (Fail(x) V T(z)) 
However, this is not enough. The metalevel representation of a tactic must have 
a structural similarity (very close to a one-to-one mapping) with the tactic itself. 
This makes the lifting, theorem proving and flattening of new tactics easier and 
more natural to understand and to perform. Tactics are basically programs and, 
as such, make extensive use of conditional constructs (and their derivatives). 
We have therefore extended the first order language with conditional term con- 
structors (i.e. trmif wff then term else term), whose meaning is given by the 
inference rules for elimination and introduction of figure 5 (the elimination rule 
for A is not listed, being very similar to that for -~A). The resulting theory 
is a conservative extension of first order logic9 Figure 6 shows how the tactics 
implementing the inference rules of figure 3 are represented in MT. 
tzl 
E-A  
[ 
B(tl) 
B('t2) 
trmifI 
~A 
B(trmif A then tl else t~) 
IB(trmifA~hen~ 
else t2) 
B(t2) 
trmifE~ I 
Fig. 5. Rules for conditional terms 
(r 
: Vx.andetac(x) = trmif T(x) A Conj(x) 
then ande(x) 
else fail 
(Ao,.,oo) : w y z.anitac(~,y, ~) = trmlf T(~) ^ Vat(y) ^ Yar(~) ^ goFree(z,~) 
then alli(x, y, z) 
else fail 
(A~t,,t~c) : Vx y.alletac(x, y) = trmif T(x) A Term(y) ^ Forall(x) 
then alle(x, y) 
else fail 
Fig. 6. Definition of primitive tactics 
Notice that tactics implement the total version of inference rules by returning 
an explicit failure. Failures are used for this particular purpose. Therefore, it 

430 
may not be the case that inference rules return a failure when the applicability 
conditions are not satisfied. This fact is formalized in MT by 
(r 
: Vx y z.~alli(x, y, z) = fail 
and allows to keep reasoning about correct inference and general inference com- 
pletely separated. 
Vx y.alleandeallitac(x, y) = trmif T(x) A Forall(x) A Var(y)A 
Conj(alle(x, y)) A NoFree(y, ande(alle(x, y))) 
then alli( ande(alle( x, y) ), y, y) 
else fail 
Fig. 7. The definition of alleandeallitac 
The ultimate goal of reasoning in MT about an inference procedure is to 
prove the corresponding admissibility statement, and then to flatten it down as 
system code. For inference rules, such statements have the form of axioms of 
figure 4, i.e. 
Vx.Applicability(x__) D T(rule(x__) ) 
The admissibility statements for the corresponding tactics have the form 
Vx.Tac(ruletac(x_) ) 
In MT the admissibility statements for an inference rule and for the correspond- 
ing tactic can be derived from each other. 
In MT and extensions of MT it is possible to synthesize/optimize tactics. 
In the following we will try to give the flavour of how this can be done via 
two examples. As an example of possible reasoning in MT, let us consider the 
class of finite compositions of inference rules. Arbitrary compositions of func- 
tion symbols can be proved to satisfy Tac in MT. Consider the rule which is 
a composition of a forall elimination, a conjunction elimination and finally a 
forall introduction. From the admissibility statement for allitac, we can prove in 
MT Vx y.Tac(allitac(andetac(alletac(x, y)), y, y))), stating that the composition is 
a correct inference rule. From the point of view of the logic provably equal terms 
are completely indistinguishable. However, the composition of tactics as above 
generates very redundant and inefficient code. An equivalent term defining the 
very same inference steps and corresponding to more optimized code, can be 
deduced by composing the axioms of figure 4: 
Vx y.T(x) A Forall(x) A Vat(y) A Conj(alle(x, y)) A NoFree(y, ande(alle(x, y))) D 
T(alli(ande(alle(x, y) ), y, y) ) 
The corresponding tactic is defined as: 
Vx y.alleandeallitac(x, y) = trmif T(x) A Forall(x) A Var(y)A 
Conj(alle(x, y)) A NoFree(y, ande(alle(x, y))) 
then alli(ande(aUe(x, y) ), y, y) 
else fail 

431 
alleandeallitac is optimized with respect to the composition of primitive 
tactics, as the applicability is expressed in a simplified way. For instance, the 
theoremhood tests performed by andetac and allitac are eliminated as they are 
implied by the other applicability conditions. Notice that this framework allows 
for incremental reasoning about inference procedures: first a basic version of 
inference rule can be considered, (e.g. by composing tactics) and then it can be 
more and more optimized by deducing further properties. 
then let (vat . get-free(x)) 
in trmif Vat(vat) 
then uniclosetac(allitac(x, vat, vat)) 
else x 
else fail 
Fig. 8. Definition of uniclosetac 
In (extensions of) MT it is also possible to reason about admissible inference 
procedures, i.e. rules which do not enlarge the provability relation of OT, but 
which can not be expressed as a finite composition of primitive inference steps. 
Being able to reason about this kind of inference rules gives the system the 
capability of extending itself with non trivial functionalities: typical examples are 
a tautology decider or a normalization procedure. (Our treatment of admissible 
rules is similar to Boyer and Moore's work on metafunctions IBM81].) As a 
simple example, consider the inference rule performing the universal closure of 
an arbitrary sequent. This rule succeeds provided that none of the free variables 
of the formula occurs free in the dependencies. This rule can be represented 
in MT by the function symbol uniclosetac, defined by the formula of figure 8. 
The definition exploits another conservative extension of first order language, the 
environment term constructor, i.e. let (var. term) in term (which can be defined 
similarly to what done for conditional terms). The corresponding admissibility 
statement is the formula Vx.Tac(uniclosetac(x)). Its proof requires reasoning by 
induction with the axiom schema of figure 9. The intuition underlying the proof 
is to perform an induction on the structure of well formed formulas (wiTs). At 
every step the selected free variable is proved to be quantified by the application 
of allitac. 
.A,,,a : Vx y.(W f f(x) A W f f(y) D (~(x)A q~(y) D ~(mkor(x,y)))) A ...A 
Vx y.(Var(x) A Wff(y) D (~(y) D ~(mkforall(x,y)))) A... D 
Vx.(Wff(x) D ~(x)) 
Fig. 9. The structural induction axiom schema for wffs 
3 
Writing 
liftable code 
The goal is to produce code which, once lifted, will generate MT (see fig- 
ure 2). However, this is not a trivial consequence of the fact that the code im- 

432 
(DEFLAM alliprf (X Y Z) 
(IF (AND (THEOREM X) (VAR u (VAR Z) (NOFREE Z X)) 
(proof-add-theorem (alli X Y Z)) 
(print-error-message))) 
Fig. 10. Unliftable code for forall introduction 
plements the deductive machinery of OT. Writing liftable code is not a simple 
operation of implementation. It is not enough to satisfy the usual software en- 
gineering requirements (e.g. bug-free, understandable). The code must preserve 
a form of structural similarity with the entity being represented, in this case 
OT. Every data structure, every step of computation, the system structure and 
the abstraction levels are determined in terms of the concepts that are intended 
to be relevant. To emphasize this point we say that we do representation the- 
ory using programs as representational tools. We call this way of writing code, 
mechanization, and distinguish it from simple implementation. 
Consider the code implementing the simple inference rule of forall introduc- 
tion, shown in figure 10 (the programming language is ltGKM [GC89], a SCHEME- 
like language with first order semantics, used as the implementation language of 
GETFOL). THEOREM evaluates to TRUE if the argument is (a data structure repre- 
senting) a provable sequent, VAR evaluates to true if the argument is a variable, 
alli builds a sequent and proof-add-theorem adds it to the proof. Its reading 
is very natural: if the inference rule is applicable then build the (data structure 
representing) the resulting sequent and store it in the current proof, otherwise 
report an error message. Everyone would agree that this is well written code. 
But the correspondence with the description in MT of VI, is only partially pre- 
served. For instance, whilst allitac in MT is a function from sequents to sequents, 
alliprf has a side effect on the system (either adds a sequent to the proof or 
prints an error message) and does not return a value. 
The work on mechanizing GETFOL has required different rewritings of the 
code, during which we have devised a general schema for the development of 
liftable code (see figure 11). We call state the information stored in the system. 
The state is of different kinds, and is justified by different reasons. For instance, 
the axioms of the object theory are stored because of their logical relevance. A 
counter for the automatic generation of different names for skolem functions is 
stored for user interface purposes. In decision procedures, global variables are 
used to avoid explicit argument passing and optimize performances. We call 
logical state (LS) the part of the state containing logical information, physical 
state (PS) the remaining state. This distinction separates the information which 
is relevant for lifting (i.e. LS) from the one which must be suitably "hidden" 
by identifying in the code a liftable abstraction level. The system code is then 
separated in operations which are functional on the state, the computation ma- 
chinery (CM), and operations which change the state, the update machinery 
(UM). Notice that this classification is completely general and independent of 

433 
Ls 
UM 
CM 
Fig. 11. The structure of the system code. 
the application. 
The implementation of forall introduction according to this schema is given 
in figure 12. allitac 
and alli are CM primitives, allitac implements the 
forall introduction tactic, while alli implements VI assuming that the argu- 
ments satisfy the applicability conditions, allâ€¢ and allitac are functions over 
a fixed state, as their execution does not add a theorem to the current proof 
nor does it print an error message, proof-add-theorem is the UM primitive 
"hiding" part of LS, i.e. the current proof, to which it adds the given theorem. 
print-error-message "hides" part of the physical state, i.e. the output chan- 
nel, on which it prints an error message. These operations are called by the UM 
primitive alliprf, according to the result of allitac. Compare the two imple- 
mentations of VI in figure 10 and in figure 12. The computations described in 
the two cases are very similar, undistinguishable from many points of view. How- 
ever, the abstraction levels in the "mechanized" solution are sharply identified, 
the functions are separated from the actions on the state. Even more important, 
notice the correspondence between the subroutines alli and allitac with the 
axiomatization in MT of the rule of forall introduction (figure 6). 
4 
Lifting and flattening 
code 
As already pointed out in section 1, the relation between computation and 
deduction has been widely studied in mathematical logic. In computer science, 
programming languages are given formal account to allow formal reasoning for 
program synthesis, optimization and verification. Independently of the features 
of the language being described, i.e. functional IBM79] or imperative [MW87a, 
MW87b], all these approaches are based on a uniform mapping. In most cases, 
the computing subroutines are immersed into the logic with a mapping which 
is basically one-to-one. Our approach takes a different perspective. Lifting and 

434 
;;; UPDATE MACHINERY 
(DEFLAM alliprf (X Y Z) 
(maybe-proof-add-theorem (allitac X Y Z))) 
(DEFLAM maybe-proof-add-theorem (X) 
(IF (FAIL? X) 
(print-error-message X) ;;; UPDATE THE PHYSICAL STATE 
(proof-add-theorem X))) ;;; UPDATE THE LOGICAL STATE 
;;; COMPUTATION MACHINERY 
(DEFLAM allitac (X Y Z) 
(IF (AND (THEOREM X) (VAR Y) (VAR Z) (NOFREE Z X)) 
(alli X Y Z) 
fail)) 
Fig. 12. Liftable code for forall introduction 
flattening are not uniform: different parts of the code are treated in different 
ways. 
In this paper, for lack of space, we do not consider flattening. We rely on 
the intuition that the flattening step of the schema in figure 1 is the inverse of 
the lifting. Given a definitional axiom, it generates the corresponding one-to-one 
CM definition. For instance, flattening the definition of uniclose given in figure 8 
gives the CM function uniclosetac (figure 13). Statements about the system 
state, once proved in MT, are flattened onto UM primitives. For instance, the 
admissibility statement Vx.Tac(uniclosetac(x)) is flattened in the UM primitive 
unicloseprf. 
Lifting is defined according to the classification of the code discussed in pre- 
vious section. Basically, for each of LS, CM and UM there is a corresponding 
lifting procedure generating an appropriate subset of axioms of MT. In this paper 
we do not consider lifting of LS. The intuition is that LS contains information 
related to the objects of OT (e.g. the language, the axioms), and lifting LS gives 
their metatheoretic description, e.g. the formula Var("x") for the (data structure 
implementing the) variable x of OT. We focus here only on the harder cases of 
lifting CM and lifting UM. 
4.1 
Lifting CM 
The code in CM is a collection of functions defined using the functional subpart 
of HGKM. Therefore lifting CM can exploit the usual techniques for reasoning 
about functional programs: function definitions are immersed via a one-to-one 
mapping into the logic of MT and become definitional axioms. For instance, 
lifting the function definition of allitac (figure 12) gives the axiom -4aUitac 
(figure 6). 

435 
(DEFLAMunicloseprf (x) 
(maybe-proof-add-theorem (tmiclosetac x))) 
(DEFLAMuniclosetac (seq) 
(IF (NOT (THEOREM seq)) fail 
(LET ((v (get-free seq))) 
(IF (VAR v) 
(uniclosetac (allitac seq v v)) 
v))))) 
Fig. 13. Flattening uniclose 
In principle, it would be possible to lift all the function definitions of the sys- 
tem going down to the basic primitives, e.g. CAR, CDR, C0I~S. This is for instance 
what Boyer and Moore do; higher levels of functional abstraction are added 
incrementally during the theorem proving activity IBM79]. Their "bottom-up" 
approach is motivated by the fact that their goal is to prove the termination and 
the correctness (with respect to a certain specification) of user defined functions. 
However, we are interested in developing systems which reason selectively about 
portions of their underlying implementation code. The idea is to keep MT as 
partial as possible still maintaining all the needed information. This in order to 
make the process of self-extension focused and feasible in practice. Therefore, we 
take a slightly different approach. First of all, we want reasoning to be local: for 
instance, we do not want to consider the system deciders when reasoning about 
inference rules. Furthermore, reasoning should be at the right level of abstrac- 
tion. For instance, in order to reason about tactics, we are not interested in the 
internal structure of inference rules, and we take a11i to be a primitive object, 
i.e. as if it were a black box. We call abstract machine the collection of all and 
only the primitive objects involved in our reasoning (e.g. a11i). Notice that the 
choice of what code we lift, and at which level of abstraction we describe it, 
strongly depends on the goals: for instance, taking inference rules as primitive 
objects is particularly suited for synthesizing new tactics. 
The hard problem in lifting CM is to lift the suitable formalization for the 
abstract machine. Indeed, this can not be described with the one-to-one lifting 
of its subroutine definitions: this would imply reasoning at a different (lower) 
level of abstraction. The properties of an abstract machine must be lifted with- 
out analyzing its internal structure. General criteria for axiomatizing abstract 
machines have been defined. A first issue is the characterization in MT of par- 
tial functions (e.g. a11â€¢ 
A partial function is associated with a total version 
(e.g. allitac) which returns the special data structure fail when the value is 
not defined. In order to avoid confusion, partial functions never return fail. 
This general property has been exploited to define a lifting mechanism return- 
ing the corresponding axiom: in the case of a11â€¢ and allitac, the resulting 
axiom is .A~m~ofa~l (see page 6). A second issue is the lifting of code imple- 

436 
I--1 
Deciders (not lifted) 
Lower abstraction level (not lifted) 
Abstract Machine 
Tactics Definitions (one-to-one lifting) 
Fig. 14. Lifting the structure of CM 
menting inductively defined data structures. Consider the code in figure 15. It 
is a (simplified) version of the implementation of wffs. In this code it is possible 
to identify constructors (mkor), recognizers (DIS J) and selectors (lfor, rtor). 
Starting from such considerations, we can lift the axioms defining the mutual 
relations of constructors and selectors, e.g. 
.A Jormkor : Vx y.t/or(mko,'(x, y)) = 
The concrete implementation of this code is not shown, as lifting is independent 
of it. The recursively defined predicate WFF "glues together" the various objects 
into an inductively defined data type. From each of its clauses, we can lift the 
type information for constructors, e.g. 
.Atypemkyoratt : Vx y.Var(x) A W ff(y) D W ff(mkforall(x, y)) 
In the case of inductively defined data, it is also possible to lift a principle of 
structural induction. For WFF the result is the axiom Ai~d used in the admissi- 
bility proof of uniclose (see figure 9). 
4.2 
Lifting UM 
Lifting the theory of inference is somehow analogous to lifting the theory of wffs. 
Indeed, the set of provable sequents of OT can be seen analogously to wffs, i.e. an 
inductively defined set, whose constructors are the inference rules. (One minor 
difference is that for wffs we only consider the partial functions, (e.g. the compu- 
tation of lfor may return a random value or even raise an exception if the argu- 
ment is not a DIS J); in the case of inference we consider both (partial) inference 
rules and the corresponding total versions with fail. Under this interpretation, 
axiom Aande is the dual of the typing axiom Atype,~k/oratt.) A possible solution 
could be therefore to lift Atypr 
from CM, as clone for wffs, given a recur- 
sive definition of the provability predicate (dual of WFF). To do this, however, we 
would also need the recognizers for different inference steps (dual of UNIQUANT). 
The problem is that theoremhood is actually a property which is not decidable, 

437 
(DEFLAM 
(DEFLAM 
(DEFLAM 
(DEFLAM 
(DEFLAM 
(DEFLAM 
(DEFLAM 
(DEFLAM 
mkor (wffl wff2) ...) 
ifor (wff) ...) 
rtor (wff) ...) 
DISJ (wff) ...) 
mkforall (var wff) ...) 
bvarof (wff) ...) 
matrix (wff) ...) 
UNIQUANT (wff) ...) 
DEFLAM WFF (wff) 
(IF (DISJ wff) (AND (WFF (lfor wff)) (WFF (rtor wff))) 
.
,
.
 
(IF (UNIQUANT wff) (AND (WFF (matrix wff)) (VAR (bvarof wff))) 
.
.
.
 
FALSE))) 
Fig. 15. The code implementing the data type WFF 
and we would like to avoid using not recursive recognizers. One (partial) solution 
could be to axiomatize proofhood, rather than theoremhood. This is somehow 
similar to the (type-theoretical/algebraic) approach of [BC91, CAB+86]. In this 
approach inference rules, rather than being functions on sequents, are functions 
on whole proofs. One problem is that, potentially, objects have to be reeomputed 
from scratch any time they are introduced in the system. This is acceptable for 
wffs, whose data structures are indeed generated at parsing time. For sequents, 
though, building the corresponding proof may become a very hard task. 
Lifting UM is based on a different idea. In GETFOL, the state is used to 
save partial computations: this allows us to reuse objects which have already 
been computed. Sequents, once proved, are asserted as theorems in the part of 
LS implementing the current proof (by proof-add-theorem). Verifying theo- 
remhood (cfr. THEOREM in figure 12) amounts to searching in LS. Therefore the 
current proof in LS can be seen as an approximation of the non-recursive set 
of all the provable sequents. Lifting UM is based on the idea that, if an UM 
primitive adds the result of a computation to the state approximating a certain 
set, then the result also belongs to the set, i.e. the approximation is sound. In 
the particular case of inference, alliprf adds the result of allitac to the state 
approximating the set of (successful and failing) inference steps (this state is hid- 
den by maybe-proof-add-theorem). Being Tac the description in MT of this 
set involved, by lifting alliprf we get the admissibility statement for allitac, 
i.e. Vx y z.Tac(allitac(x, y, z)). As shown in section 2, for our purposes this is 
equivalent to the axiom .Aazu. Following this approach, it is possible to lift from 
the UM all the necessary axioms. In particular, to lift the induction principle 
A... ^ 
n 
n 

438 
it is sufficient to notice that the ruletaci are the only inference rules in the 
system. 
5 
Conclusions 
In this paper we have presented the architecture and the issues related to the 
development of an introspective metatheoretic reasoning system, able to lift its 
own code into a declarative metatheory, reason about it and flatten down the 
resulting theorems into new system code. The theoretical foundations of this 
work (e.g. the formal definition of lifting and flattening, the proof of their full 
symmetry and correctness) are discussed in the companion paper [GC92]. 
References 
[BC91] 
IBM79] 
[BM81] 
[CAB+86] 
[GC89] 
[GC92] 
[Giu92] 
[GS88] 
[GT91] 
[GT92] 
[GT94] 
D. Basin and R. Constable. Metalogical Frameworks. In Proceedings of the 
Second Workshop on Logical Frameworks, Edinburgh, Scotland, 1991. To 
Appear as a chapter in a Cambridge University Press book. 
R.S. Boyer and J.S. Moore. A Computational Logic. Academic Press, 1979. 
ACM monograph series. 
R.S. Boyer and J.S. Moore. Metafunctions: proving them correct and using 
them efficiently as new proof procedures. In R.S. Boyer and J.S. Moore, edi- 
tors, The correctness problem in computer science, pages 103-184. Academic 
Press, 1981. 
R.L. Constable, S.F. Allen, H.M. Bromley, et al. Implementing Mathemat- 
ics with the NuPRL Proof Development System. Prentice Hall, 1986. 
F. Giunchiglia and A. Cimatti. HGKM Manual - a revised version. Technical 
Report 8906-22, IRST, Trento, Italy, 1989. 
F. Giunchiglia and A. Cimatti. Introspective Metatheoretic Theorem Prov- 
ing. Technical Report 9211-22, IRST, Trento, Italy, 1992. Upgraded and 
extended version forthcoming. 
F. Giunchiglia. The GETFOL Manual - GETFOL version 1. Technical Report 
92-0010, DIST - University of Genova, Genoa, Italy, 1992. 
F. Giunchiglia and A. Smaill. 
Reflection in constructive and non- 
constructive automated reasoning. In H. Abramson and M. H. Rogers, ed- 
itors, Proc. of META-88, Workshop on Metaprogramming in Logic, pages 
123-145. MIT Press, 1988. Also IRST-Technical Report 8902-04 and DAI 
Research Paper 375, University of Edinburgh. 
F. Giunchiglia and P. Traverso. Reflective reasoning with and between a 
declarative metatheory and the implementation code. In Proc. of the 12th 
International Joint Conference on Artificial Intelligence, pages 111-117, 
Sydney, 1991. Also IRST-Technical Report 9012-03, IRST, Trento, Italy. 
F. Giunchiglia and P. Traverso. A Metatheory of a Mechanized Object The- 
ory. Technical Report 9211-24, IRST, Trento, Italy, 1992. Submitted for 
publication to: Journal of Artificial Intelligence. 
F. Giunchiglia and P. Traverso. Program Tactics and Logic Tactics. In Pro- 
ceedings 5th Intnl. Conference on Logic Programming and Automated Rea- 
soning (LPAR'94), Kiev, Ukraine, July 16-21, 1994. Also IRST-Technical 

439 
[GW91] 
[JL83] 
[MW87a] 
[MW87b] 
[Pau89] 
[Pra65] 
[Smi83] 
[Wey80] 
Report 9301-01, IRST, Trento, Italy. Presented at the Third International 
Symposium on Artificial Intelligence and Mathematics, Fort Lauderdale, 
Florida, January 1994. 
F. Giunchiglia and R.W. Weyhrauch. FOL User Manual - F0L version 2. 
Manual 9109-08, IRST, Trento, Italy, 1991. Also DIST Technical Report 
91-0006, DIST, University of Genova. 
P. N. Johnson-Laird. Mental Models. Cambridge University Press, 1983. 
Z. Manna and R. Waldinger. The Deductive Synthesis of Imperative LISP 
Programs. In Sixth National Conference on Artificial Intelligence. AAAI, 
1987. 
Z. Manna and R. Waldinger. How to clear a block: A Theory of PlanS. Tech- 
nical Report STAN-CS-87-1141, Department of Computer Science, Stanford 
University, 1987. 
L. Paulson. 
The Foundation of a Generic Theorem Prover. 
Journal of 
Automated Reasoning, 5:363-396, 1989. 
D. Prawitz. Natural Deduction - A proof theoretical study. Almquist and 
Wiksell, Stockholm, 1965. 
B.C. Smith. Reflection and Semantics in LISP. In Proc. 11th ACM POPL, 
pages 23-35, 1983. 
R.W. Weyhrauch. Prolegomena to a Theory of Mechanized Formal Reason- 
ing. Artificial Intelligence, 13(1):133-176, 1980. 

Abstract Debugging of Logic Programs 
Marco Comini 1, Giorgio Levi 1 and Giuliana Vitiello 2 
1 Dipartimento di Informatica, Universitg di Pisa, Corso Italia 40, 56125 Pisa, Italy 
2 Dipaxtimento di Informatica ed Appllcazioni, Universitg di Salerno, Baronissi 
(Salerno), Italy 
1 
Introduction 
Abstract debugging of logic programs is a novel combination of three known 
techniques, i.e. algorithmic (declarative) debugging [25, 15, 22], the s-semantics 
approach to the definition of program denotations modeling various observable 
behaviors [13, 14, 16, 4, 3], and abstract interpretation [10, 11, 12]. A similar 
approach was developed in [5] for imperative languages. 
The debugging problem can formally be defined as follows. Let P be a pro- 
gram, [P]~ be the behavior of P w.r.t, the observable property a, and I~ be 
the specification of the intended behavior of P w.r.t.a. The debugging con- 
sists of comparing [P]a and Ia and determining the "errors" and the program 
components which are sources of errors, when [P]~ ~ Ia. 
The above formulation is parametric w.r.t, the observable ~, which is con- 
sidered in the specification Ia and in the actual behavior [P]a. 
Declarative debugging is concerned with model-theoretic properties rather 
than with the operational behavior. The specification is therefore the intended 
declarative semantics of the program, which is the least Herbrand model in 
[25, 22], and the set of atomic logical consequences in [15]. 
Abstract debugging is a generalization of declarative debugging, where we 
consider operational properties. An observable is any property which can be 
extracted from a goal computation, i.e. observables are abstractions of SLD- 
trees. Examples of useful observables are computed answers, finite failures and 
call patterns (i.e. procedure calls selected in an SLD-derivation). Other examples 
come from program analysis, e.g. depth(O-answers (i.e. answers containing terms 
whose depth is <_ l), types, modes and ground dependencies. As we will discuss 
later, the relation among the observables can naturally be understood in terms 
of abstract interpretation. A similar approach to the semantics of logic programs 
can be found in [18]. 
Here are some motivations for abstract debugging. 
- The most natural abstract debugging for positive logic programs is debug- 
ging w.r.t, computed answers, which leads to a more precise analysis, since 
declarative debugging is related to correct answers only. 
- Debugging w.r.t, finite failures allows us to verify another relevant behavior, 
which has also a logical interpretation. 
- Less abstract observables, such as call patterns, can be useful to verify the 
control and data flow between different procedures, as we usually do in in- 
teractive debugging. For example, the intended behavior that we specify 

441 
might be a set of assertions of the form "the execution of the procedure call 
p(tl,...,t,) leads to the procedure call q(sl,..., sin)". 
- 
Debugging w.r.t, depth(/)-answers makes debugging w.r.t.computed answers 
effective, since both 2:a and [P]a are finite. 
- 
Debugging w.r.t, types, modes and ground dependencies allows us to verify 
partial program properties. For example, if2Ya specifies the intended program 
behavior w.r.t, types, abstract debugging boils down to type checking. 
In declarative debugging, the specification is usually assumed to he given 
by means of an oracle. This approach is feasible even in abstract debugging. 
However, since our method can handle abstractions, we can easily come out 
with finite observable behaviors and specify them in an extensional way. 
Our theory of abstract debugging is built on an algebraic semantic framework 
for positive logic programs [8], based on the formalization of observables as 
abstractions. A complete description of the framework is outside the scope of 
this paper. In Section 2 we summarize the main properties of the framework. In 
Section 3 we state the debugging problem in the general case, where we have 
to compare the behaviors for all the possible goals. However, there exists an 
important class of observables with strong semantic properties, which allows us 
to consider the behaviors for most general atomic goals only. These observables 
are called s-observables and are discussed in Section 4. The debugging problem 
and the diagnosis algorithms for s-observables are considered in Section 5. Both 
correctness and completeness can be verified by diagnosis algorithms, which 
only need to consider the behavior for finitely many goals. We also show that 
the existing declarative debugging methods can be reconstructed as instances 
of abstract debugging w.r.t, s-observables. Finally section 6 discusses a weaker 
class of observables (/-observables), which are meant to model the abstraction 
involved in program analysis and we show that only the completeness diagnosis 
algorithm is applicable. 
2 
Observables 
Following [81, we consider Constraint Logic Programs (CLP) [211 with the PRO- 
LOG (leftmost) selection rule. We assume the reader to be familiar with the 
notions of SLD-resolution and SLD-tree (see [23, 1]). 
We represent, for notational convenience, SLD-trees as sets of nodes. Let 7" 
be an SLD-tree rooted at the goal G. A node in 7" is a 4-tuple (G,c,b, k), where 
c D b is the goal associated to the node (c is the accumulated constraint and b is 
a conjunction of atoms), and k is the sequence of (renamed apart) clauses used 
in the derivation of c D b from G. 
We define a partial order _< on nodes. (G, c, b, k) < (G, c', b', k') if and only 
if k' = k :: k" for some k" A set of nodes A is well formed if p E A =~ Vp' _< 
p,# ~A. 
An SLD-tree is represented as a well formed set of nodes. 7~ is the domain 
of all the well formed sets of nodes (modulo variance), partially ordered by set 
inclusion. We can now define the behavior [P] of a program P as the set of all 
the nodes of SLD-trees of G, for any goal G. 

442 
Observables are abstractions of SLD-trees. More precisely, an observable is a 
function c~ from 7~ to an abstract domain :D, which preserves the partial orders. 
is an abstraction function according to abstract interpretation, i.e. there exists a 
function 7 (concretization) from ~D to 7~, such that (a, 7) is a Galois connection. 
The abstract behavior [PL w.r.t, the observable a is simply defined as ~([el). 
a induces an observational equivalence =a on programs. Namely Pl =a P2 iff 
[PtL = [P2L, i.e. if Pt and P2 cannot be distinguished by looking at their 
abstract behaviors. Observational equivalences can be used to define a partial 
order < on observables. Namely ~' < ~ (a is stronger than a') if Pl =a P2 
implies Pl =a, P~. 
Let ~r E 7~ be a well formed set of nodes. The following functions are examples 
of observables. 
- 
(computed answer constraints) 
~(,,) = { CG, c) I (a, e, true, k) e ,, ). 
- 
(correct answer constraints) 
r 
= { (a, c) I (a, c', true, k) ~ ~, c < c' }. 
- 
(solutions of answer constraints) 
q~(~r) = { (G, tg) [ (G, c, true, k) E ~, d is a solution of c }. 
- (answers with depth) 
X(~) = { (G, c, n) [ C G, c, true, k) E ~, n is the length of k }. 
- (/-answers with depth) 
z(~) = { (a, c,.) I (a, c, true, k) ~ ~, 
n is the length of k, 
n<l}. 
- (depth(0-answers) 
~(~) = { C G, c) I (G, c, true, k) E ~, the depth of all terms in c is < l }. 
- 
(call patterns) 
~(~) = { Ca, c, a) I Ca, c, (a, ~), k) ~ ~ }. 
- (finite failures) 
0(~r) = { G I the set of nodes in cr containing G as first element is 
finite, non-empty and does not contain nodes of the 
form (9, c, true, k) }. 
- (ground dependencies in answer constraints) 
The ground dependencies among the variables occurring in the goal are rep- 
resented as propositional formulas (see the domain Prop [9]). We assume the 

443 
answer constraints to be equalities of the form X = t. Abstract constraints 
are given by the function v defined as follows: 
A 
= 
A 
u(X'-t)=X, 
'AXis't'Xi6 
Vars(t). 
The observable is then 
,~(#) = { (G, ,,(c)) I (G, c, true, k) 6 a }. 
3 
Abstract 
debugging 
Let P be a program, a be an observable and 2:a be the specification of the 
intended behavior of P w.r.t.a. The following definitions are straightforward 
extensions of the definitions given in the case of declarative debugging [25, 15, 
221. 
- P is partially correct w.r.t. 2:~, if [P]~ C Za. 
- P is complete w.r.t. Ia, ifZ~ C_ [P]~. 
- P is totally correct w.r.t. Z~, if [PL = I~. 
Incorrectness and incompleteness symptoms are elements (of the abstract 
domain :D) on which the specification and the program disagree. According to 
the above definitions, in order to detect the symptoms we need to consider 
the abstract behaviors for all the goals. However there exists a large class of 
observables (s-observables), for which we can consider only the behaviors for 
most general atomic goals. As we will show in Section 5, abstract debugging can 
be reformulated in much simpler terms for s-observables. 
4 
s-observables 
s-observables are observables for which we can define a denotation, which gener- 
alizes the properties of the s-semantics [3]. The program denotation is defined by 
collecting the behaviors for most general atomic goals, i.e. goals of the form p()() 
consisting of the application of a predicate symbol to a tuple of distinct variables. 
This property holds for our basic observable, i.e. SLD-trees. We will discuss the 
properties in the case of SLD-trees first and then move to the abstractions. 
The SLD-trees denotation O(P) of a program P is the set of all the nodes of 
SLD-trees of most general atomic goals. SLD-trees have the following properties, 
first proved in [16, 17] and later formalized in algebraic terms [8]: 
- AND-compositionality, i.e. the SLD-tree of any (conjunctive) goal can be 
determined from O(P). 
- Correctness and full abstraction of the denotation O(P), i.e. 
[P I = [P I 
o(P0 
= o(P2). 

444 
- Equivalent bottom-up construction of the denotation, i.e.O(P) can be ob- 
tained as least fixpoint of the operator Tp defined in the following. Let I be 
an element of T~. 
TP(O = { 
(q(J?), c, l,, ks) [ 
1. k is the (renamed apart) clause of P 
q(t-) :- c~ [] ql(t~),..., qm(tm), a=+l,..., a,, 
2. (qj( 
),cj,true, 
1 <_1 < m, 
are renamed apart elements of I, 
3. c = ::l(2:t'A ck A Xl=t'l A c1A... A X=:t'= A r 
4. b=b=,am+l, ...,a,, 
5. ks = [k] :: kSl ::... 
:: ks= }. 
The top-down and bottom-up denotations corresponding to an observable a can 
be defined as follows. 
- 
Oa(P) = a(O(P)), 
- Tp, a = a o Tp o 7 (where 7 is the concretization function). 
It is worth noting that in the top-down construction we abstract the SLD- 
trees of most general atomic goals, while, in the bottom-up one, we perform the 
abstraction at each fixpoint approximation step. 
Oa(P) and Tp,~ are meaningful only for observables which satisfy suitable 
conditions formally stated in [8]. Informally, an s-observable is an abstraction a 
of SLD-trees, for which we have a lifting (to more general goals) property and 
which is AND-compositional. Moreover, a must be compatible with the bottom- 
up operator Te, namely Tp, a o a = a o Tp. 
s-observables have the same properties of SLD-trees, namely AND-compo- 
sitionality, correctness (and full abstraction) of the denotation and equivalent 
bottom-up denotation. 
Examples of s-observables are (computed and correct) answer constraints, 
solutions of answer constraints, answers with depth, /-answers with depth and 
call patterns. Some of the specialized bottom-up operators Tp, a = a o Tp o 7 are 
the CLP versions of existing "immediate consequences operators". In particular, 
- Tp,r is the ground operator defined in [26] (and Or 
is the least Herbrand 
model). 
- Tp,r is the non-ground operator first defined in [6] (and Or 
is the least 
term model). 
- Tp, e is the s-semantics operator defined in [13]. 
- Tp,, is the call patterns operator defined in [16]. 
We show two of the operators that will be later used in the examples. 

445 
- 
(computed answer constraints) 
Tp,~(I) -- { 
(q()(), c) I 
1. there exists a (renamed apart) clause of P 
q(~ :- ck [] ql(t-1),..., q,(t~), 
2.(qj(Xj),cj), 1 <_ j <_ n, 
are renamed apart elements of I, 
3.c = 3(YC= Ack ^Y(1= 1 ^el ^...AYr 
}. 
- 
(/-answers with depth) 
Tp, s(1) -- { 
(q(.~), c, m) l 
I. there exists a (renamed apart) clause of P 
q(t) :- c~ [] ql(t~),..., qn(t-,), 
2 
cj, 
l<j<., 
are renamed apart elements of I, 
3.c = 3()C:t'A ck A ~'l:tl A Cl A... A 2,--t',~ A on)X, 
4.m = ml +..-+m, 
+ 1, m_< l}. 
depth(/)-answers and ground dependencies are not s-observables, since the 
denotations do not contain enough information to get a precise reconstruction 
of the behavior of conjunctive goals. However they belong to a weaker class of 
observables (i-observables), for which we still have reasonable semantic proper- 
ties (see Section 6). Note that, if we want an s-observable which gives a finite 
approximation of computed answers, depth(/)-answers cannot be chosen and we 
have to resort to/-answers with depth. 
Finite failures are not even/-observables. For all the observables a in this 
class, we have to consider a stronger s-observable ~ (a < ~). The corresponding 
denotation O~(P) is correct and AND-compositional w.r.t, a, yet it is not fully 
abstract [8]. In the case of abstract debugging, we are forced to specify the 
behavior w.r.t. ~. 
5 
Abstract 
debugging 
w.r.t, s-observables 
Let P be a program and a be an s-observable. Since a is an s-observable, we 
know that the actual and the intended behaviors of P for all the goals can 
be uniquely determined from the behaviors for most general goals. Hence the 
following definitions correspond to the definitions of Section 3. Let 2:a be the 
specification of the intended behavior of P for most general atomic goals w.r.t. 
{T. 
- P is partially correct w.r.t. Za, if On(P) C Za. 
- 
P is complete w.r.t. 2:a, if2:a C_ Oa(P). 
- 
P 
is totally correct w.r.t. 
2:~, 
if O~(P) - Za. 
It is worth noting that we can reconstruct the usual definitions of declarative 
debugging within our more general framework, thus showing that the use of 
declarative specifications can also be motivated by operational arguments (i.e. 
they are denotations for AND-compositional observables). In particular, 

446 
- 
the observable qb (solutions of answer constraints) gives us the declarative 
debugging based on the least Herbrand model [25, 22]; 
- 
the observable r (correct answer constraints) gives us the declarative debug- 
ging based on the atomic logical consequences [15]. 
If P is not totally correct, we are left with the problem of determining the 
errors, which are based, following [25, 15, 22], on the symptoms. Namely, 
- 
an incorrectness symptom is an element in Oa(P) -Za, 
- 
an incompleteness symptom is an element in 27~ - Oa(P). 
Note that our incompleteness symptoms are different from the insufficiency 
symptoms used in [25, 15, 22]. As we will show in the following, our definitions 
lead to a symmetric diagnosis for incorrectness and incompleteness. 
It is straightforward to realize that an element may sometimes be an (in- 
correctness or incompleteness) symptom, just because of another symptom. The 
diagnosis determines the "basic" symptoms, and, in the case of incorrectness, the 
relevant clause in the program. This is captured by the definitions of incorrect 
clause and uncovered element. 
Definition 1. A clause c fi P is incorrect on the element a if 
An element a is uncovered if 
o" 6 Z,~, o" r Oa(P), o" â€¢ Tp, a(7.,,). 
Note that T{,},a is the operator associated to the program {c}, consisting 
of the clause c only. Note also that Oa(P) and 17~ play a symmetric role in the 
diagnosis of incorrect clauses and uncovered elements. The following Theorem is 
a justification of the diagnosis method. 
Theorem2. Let P be a program, a be an s-observable and Za be the specification 
of the intended behavior of P for most general atomic goals w.r.t, a. 
Then P is totally correct w.r.t.I.a, if and only if there are no incorrect clauses 
and uncovered elements according to Definition 1. 
The diagnosis algorithm for incorrect clauses consists of the following steps: 
1. generation of an element a 60a(P); 
2. if ~ r Za and exists a clause c in P such that cr 6 T{e},a(Za), then c is 
labeled as incorrect. 
The generation of the elements in Oa(P) is performed according to the defi- 
nition of the denotation. In the top-down case, the algorithm starts with a most 
general atomic goal and, as soon as an element in the denotation is generated, 
step 2 is applied. The existence of an equivalent bottom-up denotation allows 
us to define bottom-up diagnosis algorithms. Step 2 is now applied whenever a 
new element is generated in the iterative construction of the fixpoint. 
The diagnosis algorithm for uncovered elements is driven by the elements in 
For each a 6 Za 

447 
1. select the most general atomic goal G in a; 
2. compute the set of elements ,U derived from G (top-down); 
3. if a ~ ,U and a ~ Tp,~(7.a) then a is an uncovered element. 
Note that, both in the specification and in the denotation built by the debugging 
algorithms, we are concerned with the behaviors of most general atomic goals. 
Hence there are finitely many goals, i.e. one for each predicate symbol in P. If the 
abstraction a guarantees that for each most general atomic goal we have finitely 
many observations, then the specification is finite and our diagnosis is effective. 
In such a case, as already mentioned, Za can be specified in an extensional way 
and there is no need for the oracle. One example of such an abstraction is the 
observable E (/-answers with depth), that we will consider in the example below. 
Ezample 1. The following program P is a "wrong" version of append, that we 
want to debug w.r.t, the observable ~ (/-answers with depth, l = 2). 
Cl) app(x,Y, z):- Y = [],z = xo. 
C2) app(X, Y, Z) :-- X ---- [XllX2], Z ---- [Xl [Z2] [] app(X2, Y, Z2) 
The specification of the intended behavior of P is 
Zs = {(app(X, Y, Z), (X = [1, Y = Z), 1), 
(app(X, Y, Z), (X = [Xl], Z -- [XllY]) , 2) }, 
while the actual behavior is 
OF.(P) - {(app(X, Y, Z), (Y = [], X = Z), 1), 
(app(X, Y, Z), (Y = [], X -- [XIlX2], X = Z), 2) }. 
All the elements in Ox(P) are incorrectness symptoms, while all the elements 
in 27x are incompleteness symptoms. In order to detect incorrect clauses and 
uncovered elements, we have to apply the bottom-up operator Tp, x to 27~.: 
T{c,},x(2;x) = {(app(X, Y, Z), (Y = [1, X = Z), 1) } 
T{c,},x (:/.~) = {(app(X, Y, Z), (X = [XI], Z = [XIIY]) , 2) }. 
The diagnosis detects that c, is an incorrect clause on (app(X, Y, Z), (Y = 
[],X = Z), 1) and that {app(X,Y,Z),(X = [],Y = Z), 1) is an uncovered 
element. 
Even when the diagnosis is effective, our algorithms are forced to compute 
On(P). This amounts to a fixpoint computation or to the construction of the 
SLD-trees for all the most general atomic goals. 
6 
Abstract 
debugging 
w.r.t./-observables 
/-observables are meant to model the abstraction involved in abstract inter- 
pretation. According to the approach in [7, 19, 20], the abstraction process is 
performed by defining a semi-morphism p from the concrete constraint system 

448 
to a suitable abstract constraint system. This abstraction has to be combined 
with the usual abstraction of SLD-trees to generate an /-observable. Namely, 
an/-observable %, = a o pv is the composition of an s-observable a with the 
function pa, obtained by extending to nodes the constraint semimorphism p. 
Note that in general a t is not an s-observable. 
We follow the so-called "generalized semantics" approach of [19, 20], which 
is a kind of abstract compilation, where the program P is transformed into 
an abstract program p(P), obtained by applying p to the concrete constraints 
in P. Once we have the abstract program p(P), we get the usual (equivalent) 
top-down and bottom-up denotations O,~(p(P)) and T~,(p),a T w, since a is an 
s-observable. 
The abstract compilation introduces an approximation which is safe in the 
sense of abstract interpretation, i.e. 
where O~,~ = ao(O(P)) is the abstraction according to a t of the concrete de- 
notation O(P). 
In abstract debugging, 2:a, is a specification of the intended behavior Oa~. 
Hence we cannot get any information about partial correctness from abstract 
compilation, since in general the following relation holds (for a complete pro- 
gram): 
On the other hand, the definitions given in Section 5 related to completeness 
(and the corresponding diagnosis algorithm for detecting uncovered elements) 
are applicable to the case of/-observables as well, as shown by the following 
example, where we detect uncovered elements w.r.t, a specification related to 
ground dependencies. 
Example 2. We consider the program P of example 1. The overall/-observable 
~v is the composition of the computed answer constraints s-observable and of 
the abstraction on the constraint system u of Section 2, which gives the ground 
dependencies. 
The abstract program g(P) is 
Cl) app(X, Y, Z) :-- Y A (X *--* Z) 1:3. 
c2) app(X, Y, Z) :-- (X ~-* (Xl A X2)) A (Z *-* (Xl A Z2)) El app(X2, Y, Z2) 
The specification of the intended behavior of P is 
Z&. = {(app(X, Y, Z), X A (Y *--* Z)), (app(X, Y, Z), Z ~-* (X A Y)) }, 
while the actual behavior of the abstract program is 
Oe(u(P)) - {(app(X, Y, Z), Y A (X ~ Z)) }. 
All the elements in 2"~. are incompleteness symptoms. In order to detect uncov- 
ered elements, we have to apply the bottom-up operator Tu(p),~ to 27~.. 
T~,(p),~(Z~,.) - { (app(X, Y, Z), Y A (X ~ Z)), 
(app(X, Y, z), z 
(x ^ z)) } 

449 
The diagnosis detects that (app(X, Y, Z), X A (Y ~ Z)) is an uncovered ele- 
ment. Note that sometimes disjunctive constraints in Prop are replaced by their 
greatest lower bound. This solution, if applied to Zr 
and to Or 
would 
introduce a further approximation, which, in this example, would not allow the 
detection of the uncovered element any longer. 
7 
Conclusions 
Our debugging method applies to positive logic programs, under the leftmost 
selection rule. All our results can easily be extended to local selection rules [27]. 
A more interesting extension is related to the overall PROLOG computa- 
tion rule, including the depth-first search based on the clause ordering. Abstract 
debugging can be based on a PROLOG version of the semantic framework in 
[8], which was recently defined in [24]. The framework generalizes the comput- 
ed answer semantics for PROLOG given in [2] and introduces a new abstract 
compilation method, where each constraint is abstracted by a pair of abstract 
constraints (upper and lower approximations). 
Abstract debugging can be viewed as yet another program verification method, 
where we are concerned with partial correctness properties and the specification 
is extensional. An interesting problem is that of better understanding the re- 
lation among the various techniques for proving program properties, namely 
debugging, verification and abstract interpretation. 
References 
1. K. R. Apt. Introduction to Logic Programming. In J. van Leeuwen, editor, Hand- 
book of Theoretical Computer Science, volume B: Formal Models and Semantics, 
pages 495-574. Elsevier, Amsterdam and The MIT Press, Cambridge, 1990. 
2. A. Bossi, M. Bugliesi, and M. Fabris. Fixpoint semantics for PROLOG. In D. S. 
Warren, editor, Proc. Tenth Int'l Conf. on Logic Programming, pages 374-389. The 
MIT Press, Cambridge, Mass., 1993. 
3. A. Bossi, M. Gabbrielli, G. Levi, and M. Martelli. The s-semantics approach: The- 
ory and applications. Journal of Logic Programming, 19-20:149-197, 1994. 
4. A. Bossi, M. Gabbrielli, G. Levi, and M. C. Meo. A Compositional Semantics for 
Logic Programs. Theoretical Computer Science, 122(1-2):3-47, 1994. 
5. F. Bourdoncle. 
Abstract debugging of higher-order imperative languages. 
In 
PLDI'93, pages 46-55, 1993. 
6. K. L. Clark. Predicate logic as a computational formalism. Res. Report DOC 
79[59, Imperial College, Dept. of Computing, London, 1979. 
7. P. Codognet and G. Fil~. Computations, Abstractions and Constraints. In Proc. 
Fourth IEEE lnt'l Conference on Computer Languages. IEEE Press, 1992. 
8. M. Comini and G. Levi. An algebraic theory of observables. In M. Bruynooghe, 
editor, Proc. 1994 lnt'l Symposium on Logic Programming. The MIT Press, Cam- 
bridge, Mass., 1994. To appear. 
9. A. Cortesi, G. Fil~, and W. Winsborough. Prop revisited: Propositional Formula 
as Abstract Domain for Groundness Analysis. In Proc. Sixth IEEE Syrup. on Logic 
In Computer Science, pages 322-327. IEEE Computer Society Press, 1991. 

450 
10. P. Cousot and R. Cousot. Abstract Interpretation: A Unified Lattice Model for 
Static Analysis of Programs by Construction or Approximation of Fixpoints. In 
Proc. Fourth A CM Syrup. Principles of Programming Languages, pages 238-252, 
1977. 
11. P. Cousot and R. Cousot. Systematic Design of Program Analysis Frameworks. 
In Proc. Sixth A CM Syrup. Principles of Programming Languages, pages 269-282, 
1979. 
12. P. Cousot and R. Cousot. Abstract Interpretation and Applications to Logic Pro- 
grams. Journal of Logic Programming, 13(2 & 3):103-179, 1992. 
13. M. Falaschi, G. Levi, M. Martelli, and C. Palamidessi. Declarative Modeling of 
the Operational Behavior of Logic Languages. 
Theoretical Computer Science, 
69(3):289-318, 1989. 
14. M. Falaschi, G. Levi, M. Martelli, and C. Palamidessi. A Model-Theoretic Re- 
construction of the Operational Semantics of Logic Programs. Information and 
Computation, 102(1):86-113, 1993. 
15. G. Ferrand. 
Error Diagnosis in Logic Programming, an Adaptation of E. Y. 
Shapiro's Method. Journal of Logic Programming, 4:177-198, 1987. 
16. M. Gabbrielli, G. Levi, and M. C. Meo. Observational Equivalences for Logic Pro- 
grams. In K. Apt, editor, Proc. Joint Int'l Conf. and Symposium on Logic Pro- 
gramming, pages 131-145. The MIT Press, Cambridge, Mass., 1992. Extended 
version to appear in Information and Computation. 
17. M. Gabbrielli, G. Levi, and M. C. Meo. A resultants semantics for PROLOG. 
Technical report, Dipartimento di Informatica, Universit~ di Pisa, 1994. 
18. R. Giacobazzi. On the Collecting Semantics of Logic Programs. In F. S. de Boer 
and M. Gabbrielli, editors, Verification and Analysis of Logic Languages, Prac. of 
the Post-Conference ICLP Workshop, pages 159-174, 1994. 
19. R. Giacobazzi, S. K. Debray, and G. Levi. A Generalized Semantics for Constraint 
Logi c Programs. In Proceedings of the International Conference on Fifth Genera- 
tion Computer Systems 199~, pages 581-591, 1992. 
20. R. Giacobazzi, G. Levi, and S. K. Debray. Joining Abstract and Concrete Compu- 
tations in Constraint Logic Programming. In M. Nivat, C. Rattray, T. Rus, and 
G. Scollo, editors, Algebraic Methodology and Software Technology (AMAST'93), 
Proceedings of the Third International Conference on Algebraic Methodology and 
Software Technology, Workshops in Computing, pages 111-127. Springer-Veflag, 
Berlin, 1993. 
21. J. Jaffar and J. L. Lassez. Constraint Logic Programming. In Prec. Fourteenth 
Annual ACM Syrup. on Principles of Programming Languages, pages 111-119. 
ACM, 1987. 
22. J. W. Lloyd. Declarative error diagnosis. New Generation Computing, 5(2):133- 
154, 1987. 
23. J. W. Lloyd. Foundations of Logic Programming. Springer-Verlag, Berlin, 1987. 
Second edition. 
24. D. Micciancio. Interpretazione astratta di programmi logici con il controllo di 
PROLOG. Master's thesis, Dipartimento di Informatica, Universit~ di Pisa, 1994. 
in italian. 
25. E. Y. Shapiro. Algorithmic program debugging. In Proc. Ninth Annual ACM 
Syrup. on Principles of Programming Languages, pages 412-531. ACM Press, 1982. 
26. M. H. van Emden and R. A. Kowalski. The semantics of predicate logic as a 
programming language. Journal of the ACM, 23(4):733-742, 1976. 
27. L. Vieille. Recursive query processing: the power of logic. Theoretical Computer 
Science, 69:1-53, 1989. 

Authors 
Index: 
Attardi, G. 410 
Barklund, J. 262 
Basin, D.A 1 
Bensaou, N. 17 
Boberg, K. 262 
Bossi, A. 311 
Boulanger, D. 36 
Brogi, A. 377 
Brunk, C. 183 
Bruynooghe, M. 36 
Cimatti, A. 425 
Comini, M. 440 
Contiero, S. 377 
Cook, J. 51 
DaM, V. 215 
DeU'Acqua, P. 262 
Dunin-K~plicz, B. 293 
Esposito, F. 183 
Etalle, S. 311 
Flener, P. 69 
Gallagher, J.P. 49, 138 
Gilbert, D. 88 
Giunchiglia, F. 425 
Guessarian, I. 17 
Hill, P.M. 395 
Hogger, C. 88 
Lau, K.-K. 104 
Leuschel, M. 122 
Levi, G. 440 
Malerba, D. 183 
Maral~kis, E. 138 
Meyer, J.-J. 332 
Mircheva, M. 276 
Ornaghi, M. 104 
Pazzani, M. 183 
Popellnsk~, L. 69 
Renault, S. 154 
Rueher, M. 199 
Sakama, C. 170 
Seki, H. 170 
Semeraro, G. 183 
Simi, M. 410 
Solnon, C. 199 
Tarau, P. 215 
Treur, J. 332, 353 
van Harmelen, F. 248 
van der Hoek, W. 332 
Vitiello, G. 440 
Wiggins, G.A. 231 
Zlatu~ka, J. 88 

Lecture Notes in Computer Science 
For information about Vols. 1-808 
please contact your bookseller or Springer-Verlag 
Vol. 809: R. Anderson (Ed.), Fast Software Encryption. 
Proceedings, 1993. IX, 223 pages. 1994. 
Vol. 810: G. Lakemeyer, B. Nebel (Eds.), Foundations of 
Knowledge Representation and Reasoning. VIII, 355 pages. 
1994. (Subseries LNAI). 
Vol. 811 : G. Wijers, S. Brinkkemper, T. Wasserman (Eds.), 
Advanced Information Systems Engineering. Proceedings, 
1994. XI, 420 pages. 1994. 
Vol. 812: J. Karhum~iki, H. Maurer, G. Rozenberg (Eds.), 
Results and Trends in Theoretical Computer Science. Pro- 
ceedings, 1994. X, 445 pages. 1994. 
Vol. 813: A. Nerode, Yu. N. Matiyasevich (Eds.), Logical 
Foundations of Computer Science. Proceedings, 1994. IX, 
392 pages. 1994. 
Vol. 814: A. Bundy (Ed.), Automated Deduetion--CADE- 
12. Proceedings, 1994. XVI, 848 pages. 1994. (Subseries 
LNAI). 
Vol. 815: R. Valette (Ed.), Application and Theory of Petri 
Nets 1994. Proceedings. IX, 587 pages. 1994. 
Vol. 816: J. Heering, K. Meinke, B. MOiler, T. Nipkow 
(Eds.), Higher-Order Algebra, Logic, and Term Rewriting. 
Proceedings, 1993. VII, 344 pages. 1994. 
Vol. 817: C. Halatsis, D. Maritsas, G. Philokyprou, 
S. Theodoridis (Eds.), PARLE '94. Parallel Architectures 
and Languages Europe. Proceedings, 1994. XV, 837 pages. 
1994. 
Vol. 818: D. L. Dill (Ed.), Computer Aided Verification. 
Proceedings, 1994. IX, 480 pages. 1994. 
Vol. 819: W. Litwin, T. Risch (Eds.), Applications of 
Databases. Proceedings, 1994. XII, 471 pages. 1994. 
Vol. 820: S. Abiteboul, E. Shamir (Eds.), Automata, Lan- 
guages and Programming. Proceedings, 1994. XIII, 644 
pages. 1994. 
Vol. 821: M. Tokoro, R. Pareschi (Eds.), Object-Oriented 
Programming. Proceedings, 1994. XI, 535 pages. 1994. 
Vol. 822: F. Pfenning (Ed.), Logic Programming and Au- 
tomated Reasoning. Proceedings, 1994. X, 345 pages. 1994. 
(Subseries LNAI). 
Vol. 823: R. A. Elmasri, V. Kouramajian, B. Thalheim 
(Eds.), Entity-Relationship Approach -- ER '93. Proceed- 
ings, 1993. X, 531 pages. 1994. 
Vol. 824: E. M. Schmidt, S. Skyum (Eds.), Algorithm 
Theory - SWAT '94. Proceedings. IX, 383 pages. 1994. 
Vol. 825: J. L. Mundy, A. Zisserman, D. Forsyth (Eds.), 
Applications of Invariance in Computer Vision. Proceed- 
ings, 1993. IX, 510 pages. 1994. 
Vol. 826: D. S. Bowers (Ed.), Directions in Databases. 
Proceedings, 1994. X, 234 pages. 1994. 
Vol. 827: D. M. Gabbay, H. J. Ohlbach (Eds.), Temporal 
Logic. Proceedings, 1994. XI, 546 pages. 1994. (Subseries 
LNAI). 
Vol. 828: L. C. Paulson, Isabelle. XVII, 321 pages. 1994. 
Vol. 829: A. Chmora, S. B. Wicker (Eds.), Error Control, 
Cryptology, and Speech Compression. Proceedings, 1993. 
VIII, 121 pages. 1994. 
Vol. 830: C. Castelfranchi, E. Werner (Eds.), Artificial 
Social Systems. Proceedings, 1992. XVIII, 337 pages. 1994. 
(Subseries LNAI). 
Vol. 831: V. Bouchitt6, M. Morvan (Eds.), Orders, Algo- 
rithms, and Applications. Proceedings, 1994. IX, 204 pages. 
1994. 
Vol. 832: E. BOrger, Y. Gurevich, K. Meinke (Eds.), Com- 
puter Science Logic. Proceedings, 1993. VIII, 336 pages. 
1994. 
Vol. 833: D. Driankov, P. W. Eklund, A. Ralescu (Eds.), 
Fuzzy Logic and Fuzzy Control. Proceedings, 1991. XII, 
157 pages. 1994. (Subseries LNAI). 
Vol. 834: D.-Z. Du, X.-S. Zhang (Eds.), Algorithms and 
Computation. Proceedings, 1994. XIII, 687 pages. 1994. 
Vol. 835: W. M. Tepfenhart, J. P. Dick, J. F. Sowa (Eds.), 
Conceptual Structures: Current Practices. Proceedings, 
1994. VIII, 331 pages. 1994. (Subseries LNAI). 
Vol. 836: B. Jonsson, J. Parrow (Eds.), CONCUR '94: 
Concurrency Theory. Proceedings, 1994. IX, 529 pages. 
1994. 
Vol. 837: S. Wess, K.-D. Althoff, M. M. Richter (Eds.), 
Topics in Case-Based Reasoning. Proceedings, 1993. IX, 
471 pages. 1994. (Subseries LNAI). 
Vol. 838: C. MacNish, D. Pearce, L. Moniz Pereira (Eds.), 
Logics in Artificial Intelligence. Proceedings, 1994. IX, 
413 pages. 1994. (Subseries LNAI). 
Vol. 839: Y. G. Desmedt (Ed.), Advances in Cryptology - 
CRYPTO '94. Proceedings, 1994. XII, 439 pages. 1994. 
Vol. 840: G. Reinelt, The Traveling Salesman. VIII, 223 
pages. 1994. 
Vol. 841: I. Prlvara, B. Rovan, P. Ru~i~ka (Eds.), Math- 
ematical Foundations of Computer Science 1994. Proceed- 
ings, 1994. X, 628 pages. 1994. 
Vol. 842: T. Kloks, Treewidth. IX, 209 pages. 1994. 
Vol. 843: A. Szepietowski, Turing Machines with 
Sublogarithmic Space. VIII, 115 pages. 1994. 
Vol. 844: M. Hermenegildo, J. Penjam (Eds.), Program- 
ming Language Implementation and Logic Programming. 
Proceedings, 1994. XII, 469 pages. 1994. 
Vol. 845: J.-P. Jouannaud (Ed.), Constraints in Computa- 
tional Logics. Proceedings, 1994. VIII, 367 pages. 1994. 

Vol. 846: D. Shepherd, G. Blair, G. Coulson, N. Davies, 
F. Garcia (Eds.), Network and Operating System Support 
for Digital Audio and Video. Proceedings, 1993. VIII, 
269 pages. 1994. 
Vol. 847: A. L. Ralescu (Ed.) Fuzzy Logic in Artificial 
Intelligence. Proceedings, 1993. VII, 128 pages. 1994. 
(Subseries LNAI). 
Vol. 848: A. R. Krommer, C. W. Ueberhuber, Numerical 
Integration on Advanced Computer Systems. XIII, 341 
pages. 1994. 
Vol. 849: R. W. Hartenstein, M. Z. Servlt (Eds.), Field- 
Programmable Logic. Proceedings, 1994. XI, 434 pages. 
1994. 
Vol. 850: G. Levi, M. Rodriguez-Artalejo (Eds.), Alge- 
braic and Logic Programming. Proceedings, 1994. VIII, 
304 pages. 1994. 
Vol. 851: H.-J. Kugler, A. Mullery, N. Niebert (Eds.), To- 
wards a Pan-European Telecommunication Service Infra- 
structure. Proceedings, 1994. XIII, 582 pages. 1994. 
Vol. 852: K. Echtle, D. Hammer, D. Powell (Eds.), De- 
pendable Computing - EDCC- 1. Proceedings, 1994. XVII, 
618 pages. 1994. 
Vol. 853: K. Bolding, L. Snyder (Eds.), Parallel Computer 
Routing and Communication. Proceedings, 1994. IX, 317 
pages. 1994. 
Vol. 854: B. Buchberger, J. Volkert (Eds.), Parallel Process- 
ing: CONPAR 94 - VAPP VI. Proceedings, 1994. XVI, 
893 pages. 1994. 
Vol. 855: J. van Leeuwen (Ed.), Algorithms - ESA '94. 
Proceedings, 1994. X, 510 pages. 1994. 
Vol. 856: D. Karagiannis (Ed.), Database and Expert Sys- 
tems Applications. Proceedings, 1994. XVII, 807 pages. 
1994. 
Vol. 857: G. Tel, P. Vit~nyi (Eds.), Distributed Algorithms. 
Proceedings, 1994. X, 370 pages. 1994. 
Vol. 858: E. Bertino, S. Urban (Eds.), Object-Oriented 
Methodologies and Systems. Proceedings, 1994. X, 386 
pages. 1994. 
Vol. 859: T. F. Melham, J. Camilleri (Eds.), Higher Order 
Logic Theorem Proving and Its Applications. Proceedings, 
1994. IX, 470 pages. 1994. 
Vol. 860: W. L, Zagler, G. Busby, R. R. Wagner (Eds.), 
Computers for Handicapped Persons. Proceedings, 1994. 
XX, 625 pages. 1994. 
Vol: 861: B. Nebel, L. Dreschler-Fischer (Eds.), KI-94: 
Advances in Artificial Intelligence. Proceedings, 1994. IX, 
401 pages. 1994. (Subseries LNAI). 
Vol. 862: R. C. Carrasco, J. Oncina (Eds.), Grammatical 
Inference and Applications. Proceedings, 1994. VIII, 290 
pages. 1994. (Subseries LNAI). 
Vol. 863: H. Langmaack, W.-P. de Roever, J. Vytopil 
(Eds.), Formal Techniques in Real-Time and Fault-Toler- 
ant Systems. Proceedings, 1994. XIV, 787 pages. 1994. 
Vol. 864: B. Le Charlier (Ed.), Static Analysis. Proceed- 
ings, 1994. XII, 465 pages. 1994. 
Vol. 865: T. C. Fogarty (Ed.), Evolutionary Computing. 
Proceedings, 1994. XII, 332 pages. 1994. 
Vol. 866: Y. Davidor, H.-P. Schwefel, R. M~inner (Eds.), 
Parallel Problem Solving from Nature - PPSN III. Proceed- 
ings, 1994; XV, 642 pages. 1994. 
Vol 867: L. Steels, G. Schreiber, W. Van de Velde (Eds.), 
A Future for Knowledge Acquisition. Proceedings, 1994. 
XII, 414 pages. 1994. (Subseries LNAI). 
Vol. 868: R. Steinmetz (Ed.), Multimedia: Advanced 
Teleservices 
and 
High-Speed 
Communication 
Architectures. Proceedings, 1994. IX, 451 pages. 1994. 
Vol. 869: Z. W. Ras', Zemankova (Eds.), Methodologies 
for Intelligent Systems. Proceedings, 1994. X, 613 pages. 
1994. (Subseries LNAI). 
Vol. 870: J. S. Greenfield, Distributed Programming Para- 
digms with Cryptography Applications. XI, 182 pages. 
1994. 
Vol. 871: I. P. Lee, G. G. Grinstein (Eds.), Database Issues 
for Data Visualization. Proceedings, 1993. XIV, 229 pages. 
1994. 
Vol. 872: S Arikawa, K. P. Jantke (Eds.), Algorithmic 
Learning Theory. Proceedings, 1994. XIV, 575 pages. 1994. 
Vol. 873: M. Naftalin, T. Denvir, M. Bertran (Eds.), FME 
'94: Industrial Benefit of Formal Methods. Proceedings, 
1994. XI, 723 pages. 1994. 
Vol. 874: A. Borning (Ed.), Principles and Practice of Con- 
straint Programming. Proceedings, 1994. IX, 361 pages. 
1994. 
Vol. 875: D. Gollmann (Ed.), Computer Security - 
ESORICS 94. Proceedings, 1994. XI, 469 pages. 1994. 
Vol. 876: B. Blumenthal, J. Gornostaev, C. Unger (Eds.), 
Human-Computer Interaction. Proceedings, 1994. IX, 239 
pages. 1994. 
Vol. 877: L. M. Adleman, M.-D. Huang (Eds.), Algorith- 
mic Number Theory. Proceedings, 1994. IX, 323 pages. 
1994. 
Vol. 878: T. Ishida; Parallel, Distributed and Multiagent 
Production Systems. XVII, 166 pages. 1994. (Subseries 
LNAI). 
Vol. 879: J. Dongarra, J. Wa~niewski (Eds.), Parallel Sci- 
entific Computing. Proceedings, 1994. XI, 566 pages. 1994. 
Vol. 880: P. S. Thiagarajan (Ed.), Foundations of Software 
Technology and Theoretical Computer Science. Proceed- 
ings, 1994. XI, 451 pages. 1994. 
Vol. 881: P. Loucopoulos (Ed.), Entity-Relationship Ap- 
proach- ER'94. Proceedings, 1994. XIII, 579 pages. 1994. 
Vol. 882: D. Hutchison, A. Danthine, H. Leopold, G. 
Coulson (Eds.), Multimedia Transport and Teleservices. 
Proceedings, 1994. XI, 380 pages. 1994. 
Vol. 883: L. Fribourg, F. Turini (Eds.), Logic Program 
Synthesis and Transformation - Meta-Programming in 
Logic. Proceedings, 1994. IX, 451 pages. 1994. 
Vol. 884: J. Nievergelt, T. Rots, H.-J. Schek, P. Widmayer 
(Eds.), IGIS '94: Geographic Information Systems. Pro- 
ceedings, 1994. VIII, 292 pages. 19944. 
Vol. 885: R. C. Veltkamp, Closed Objects Boundaries from 
Scattered Points. VIII, 144 pages. 1994. 
Vol. 886: M. M. Veloso, Planning and Learning by Ana- 
logical Reasoning. XIII, 181 pages. 1994. (Subseries 
LNAI). 
Vol. 887: M. Toussaint (Ed.), Ada in Europe. Proceedings, 
1994. XII, 521 pages. 1994. 

