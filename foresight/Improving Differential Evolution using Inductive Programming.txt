Improving Diﬀerential Evolution
using Inductive Programming
Master’s Thesis in Applied Computer Science
Marius Geitle
May 15, 2017
Halden, Norway
www.hiof.no


Abstract
Diﬀerential Evolution (DE) has emerged as one of the most powerful and versatile global
numerical optimizers for non-diﬀerentiable, multimodal problems. The popularity of DE
has led to extensive work on improving the algorithm, and signiﬁcant advances are in-
creasingly more diﬃcult to achieve.
Most researchers seek to improve DE by studying the algorithm using formal analysis,
or manual exploration to ﬁnd improvements. However, many improvements might not
be found using these approaches. In this thesis, we use another evolutionary algorithm,
the inductive programming system Automatic Design of Algorithms Through Evolution
(ADATE), to empirically search for these improvements by systematically testing millions
of synthesized modiﬁcations.
However, even the rigorous requirements for competitions among state-of-the-art al-
gorithms leave considerable statistical uncertainty on many problems. This presents a
signiﬁcant challenge in how modiﬁcations can be evaluated quickly enough. Additionally,
the algorithms are too large to improve all-at-once, thereby raising the question of which
parts to improve. These questions were explored in three experiments.
The ﬁrst experiment attempts to improve the mutation operator in the canonical DE
algorithm, by quickly evaluating modiﬁcations, at the cost of high statistical uncertainty.
While the resulting mutation operator performed worse, when tested using a larger number
of generations, it provided valuable knowledge for the next experiments.
The next experiment signiﬁcantly enhanced the statistical certainty when trying to
improve the pool of strategies in Competitive Diﬀerential Evolution, a variant that uses a
pool of competing strategies to produce mutated individuals. The improved pool achieved
a signiﬁcant performance increase when tested on the CEC 2014 benchmark problems.
This led to the third experiment, which resulted in the improvement of the state-
of-the-art LSHADE-EpSin algorithm.
This DE variant uses an ensemble of sinusoidal
functions to generate the scaling parameter F in the current-to-pbest mutation operator.
ADATE improved both the mutation operator and the ensemble simultaneously, and found
an improved ensemble consisting of a single sine wave that achieves statistically better
performance on CEC 2014 problems with 30 dimensions.
Finally, this thesis proposes a specialized version of DE to train Spiking Neural Net-
works (SNNs). These networks have numerous advantages over traditional artiﬁcial neural
networks, but no good training methods currently in exists. While no experiment was con-
ducted, the proposed algorithm outlines several modiﬁcations that utilize SNNs-speciﬁc
methods, in a manner that might make the search handle the high number of parameters.
Keywords:
Diﬀerential Evolution, ADATE, Inductive Programming, SHADE, SHADE-
EPSin.
i


Acknowledgments
I would like to thank my supervisor Jan Roland Olsson. I appreciate all the contributions
he has made to make my Master thesis experience stimulating and productive. His enthu-
siasm was contagious and helped motivate me even through poor results. He helped me
see that failed experiments can sometimes provide more knowledge than successful ones,
and that every failure is an opportunity to learn and improve.
I would also like to thank my mother and father who has supported me in all my
pursuits.
Marius Geitle, 15.05.2017
iii


Contents
Abstract
i
Acknowledgments
iii
Contents
vi
List of Figures
ix
List of Tables
xii
Listings
xiii
List of Abbreviations
xv
1
Introduction
1
1.1
Motivation
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1.2
Research questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2
1.3
Method
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2
1.4
Structure of this thesis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2
2
Optimization
5
2.1
Derivative-based optimization . . . . . . . . . . . . . . . . . . . . . . . . . .
5
2.2
Derivative-free optimization . . . . . . . . . . . . . . . . . . . . . . . . . . .
6
2.3
Evaluating optimization algorithms . . . . . . . . . . . . . . . . . . . . . . .
8
3
Diﬀerential evolution
10
3.1
Initialization
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
10
3.2
Mutation
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
11
3.3
Crossover . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
13
3.4
Selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
15
3.5
Parameter control
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
15
3.6
Memetic variants . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
16
3.7
Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
17
4
Inductive programming
18
4.1
Types of inductive programming
. . . . . . . . . . . . . . . . . . . . . . . .
18
4.2
Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
20
4.3
ADATE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
20
v

vi
CONTENTS
5
Improving Diﬀerential Evolution
26
5.1
Experiment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
26
5.2
Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
32
5.3
Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
38
6
Improving Competitive Diﬀerential Evolution
39
6.1
Competitive diﬀerential evolution . . . . . . . . . . . . . . . . . . . . . . . .
39
6.2
Experiment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
40
6.3
Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
48
6.4
Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
52
7
Improving LSHADE-EpSin Diﬀerential Evolution
53
7.1
LSHADE-EpSin . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
53
7.2
Experiment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
57
7.3
Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
60
7.4
Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
62
8
Specializing Diﬀerential Evolution for training Spiking Neural Networks 65
8.1
Spiking neural networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
65
8.2
Proposed algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
73
8.3
Conclusion
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
75
9
Further work
77
9.1
Standard diﬀerential evolution
. . . . . . . . . . . . . . . . . . . . . . . . .
77
9.2
Competitive diﬀerential evolution . . . . . . . . . . . . . . . . . . . . . . . .
77
9.3
LSHADE-EpSin . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
78
9.4
Optimizing for specialized use-cases . . . . . . . . . . . . . . . . . . . . . . .
78
10 Conclusions
79
Bibliography
81
A Optimization benchmark problems
90
A.1 Test function collections . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
90
A.2 Properties . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
90
A.3 Basis functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
93
A.4 Compound functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 159

List of Figures
3.1
Illustration by Salomon [30] on the importance of crossover in non-separable
functions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
13
3.2
Example of the binomial crossover operation. . . . . . . . . . . . . . . . . .
14
3.3
Example of the exponential crossover operation. . . . . . . . . . . . . . . . .
14
4.1
Example of the CASE-DIST atomic transformation.
. . . . . . . . . . . . .
23
4.2
Example of the ABSTR atomic transformation. . . . . . . . . . . . . . . . .
23
5.1
Plots of two functions used for grading synthesized programs when improv-
ing DE.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
29
5.2
The sum of the medians of all 30-dimensional functions plotted against total
function evaluations used with the best performing conﬁguration for that
number of function evaluations. . . . . . . . . . . . . . . . . . . . . . . . . .
38
6.1
Some functions forming one niche group when creating a representative
problem set. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
43
6.2
Percentage of successful usages of each strategy . . . . . . . . . . . . . . . .
50
7.1
The population size calculated by Equation (7.12) with Nmax = 540, Nmin =
4 and fesmax = 300000. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
56
7.2
Plots of the means of F, CR, and for each generation for the improved and
original algorithm. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
63
8.1
Structure of a typical neuron. . . . . . . . . . . . . . . . . . . . . . . . . . .
66
8.2
Illustration of the Current-to-pbest-synaptic mutation operator . . . . . . .
74
A.1 Ackley’s function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
93
A.2 Adjiman’s Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
94
A.3 Alpine Function No.01 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
95
A.4 Alpine Function No.02 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
96
A.5 Bent cigar Function
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
98
A.6 Bird Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
99
A.7 Brown Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101
A.8 Bukin’s Function No.06
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 102
A.9 Cosine Mixture Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103
A.10 Cross-In Tray Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104
A.11 Crowned Cross Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105
A.12 Davis’ Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106
vii

viii
LIST OF FIGURES
A.13 Deﬂected Corrugated Spring Function . . . . . . . . . . . . . . . . . . . . . 107
A.14 Discuss function
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108
A.15 Downhill Step Function
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109
A.16 Drop-Wave Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 110
A.17 Egg Crate Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111
A.18 Egg-Holder Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112
A.19 Giunta’s Function
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113
A.20 Griewank function
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114
A.21 HappyCat function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115
A.22 HGBat function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116
A.23 High Conditioned Elliptic Function . . . . . . . . . . . . . . . . . . . . . . . 117
A.24 Hosaki’s Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118
A.25 Katsuura Function function . . . . . . . . . . . . . . . . . . . . . . . . . . . 119
A.26 Leon’s Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120
A.27 L (or F2) Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121
A.28 Lunacek’s bi-Rastrigin Function . . . . . . . . . . . . . . . . . . . . . . . . . 122
A.29 Mishra’s Function No.03 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123
A.30 Modiﬁed Schaﬀer’s Function No.01 . . . . . . . . . . . . . . . . . . . . . . . 124
A.31 Modiﬁed Schwefel function . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125
A.32 Pathological Function
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126
A.33 Peaks function
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128
A.34 Powell sum function
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 129
A.35 Price’s Function No.02 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130
A.36 Qing function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131
A.37 Quintic Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 132
A.38 Rastrigin function
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133
A.39 Rosenbrocks Function
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 134
A.40 Salomon’s Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 135
A.41 Egg Crate Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 136
A.42 Schaﬀer’s F6
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 137
A.43 Schwefel function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 138
A.44 Schwefel F2.21 Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 139
A.45 Schwefel F2.26 Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 140
A.46 Shubert Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141
A.47 Shubert 3 Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 142
A.48 Shubert 4 Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 143
A.49 Six-Hump Camel-Back Function
. . . . . . . . . . . . . . . . . . . . . . . . 144
A.50 Sphere function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 145
A.51 Step Function No.02 function . . . . . . . . . . . . . . . . . . . . . . . . . . 146
A.52 Styblinski-Tang . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147
A.53 Tsoulos’ Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 148
A.54 Ursem Function No.03 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149
A.55 Ursem-Waves Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 150
A.56 Venter Sobiezcczanski-Sobieski function
. . . . . . . . . . . . . . . . . . . . 151
A.57 W / Wavy Function
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 152
A.58 Weierstrass function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153
A.59 Whitley Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 154

LIST OF FIGURES
ix
A.60 Xin-She Yang’s Function No.01 . . . . . . . . . . . . . . . . . . . . . . . . . 155
A.61 Xin-She Yang’s Function No.02 . . . . . . . . . . . . . . . . . . . . . . . . . 156
A.62 Xin-She Yang’s Function No.03 . . . . . . . . . . . . . . . . . . . . . . . . . 157
A.63 Xin-She Yang’s Function No.06 . . . . . . . . . . . . . . . . . . . . . . . . . 158
A.64 Expanded Griewanks plus Rosenbrocks Function . . . . . . . . . . . . . . . 159
A.65 Expanded Scaﬀers F6 function
. . . . . . . . . . . . . . . . . . . . . . . . . 160


List of Tables
4.1
Criteria for each evaluation functions. The functions are evaluated such
that smaller of each criteria is better. Nc is number of correct problems,
Nw is number of incorrect, G is the user deﬁned grade, S is the syntactic
complexity and T is the time complexity.
. . . . . . . . . . . . . . . . . . .
22
5.1
Problems in the training set used by ADATE. The deﬁnition for each func-
tion is available in Appendix A. . . . . . . . . . . . . . . . . . . . . . . . . .
30
5.2
Problems used for validation in ADATE when improving DE. The deﬁnition
for each function is available in Appendix A.
. . . . . . . . . . . . . . . . .
31
5.3
Best performing parameters across all CEC 2014 benchmark functions on
10 dimensions, as measured by the sum of the medians.
The parame-
ters were found by testing Np ∈{20, 40, 45, 50, 55, 60, 80, 100, 150}, Cr ∈
{0.1, 0.5, 0.9}, and F ∈{0.5, 0.8}.
. . . . . . . . . . . . . . . . . . . . . . .
33
5.4
Best performing parameters across all CEC 2014 benchmark functions on
30 dimensions, as measured by the sum of the medians.
The parame-
ters were found by testing Np ∈{20, 40, 45, 50, 55, 60, 80, 100, 150}, Cr ∈
{0.1, 0.5, 0.9}, and F ∈{0.5, 0.8}.
. . . . . . . . . . . . . . . . . . . . . . .
33
5.5
Performance of mutation operators on CEC 2014 benchmark functions 1
to 15 with 10 dimensions using the parameters performing best across all
CEC 2014 functions as measured by the sum of all medians. . . . . . . . . .
34
5.6
Performance of mutation operators on CEC 2014 benchmark functions 16
to 30 with 10 dimensions using the parameters performing best across all
CEC 2014 functions as measured by the sum of all medians. . . . . . . . . .
35
5.7
Performance of mutation operators on CEC 2014 benchmark functions 1
to 15 with 30 dimensions using the parameters performing best across all
CEC 2014 functions as measured by the sum of all medians. . . . . . . . . .
36
5.8
Performance of mutation operators on CEC 2014 benchmark functions 16
to 30 with 30 dimensions using the parameters performing best across all
CEC 2014 functions as measured by the sum of all medians. . . . . . . . . .
37
6.1
Pool of strategies in b3e3pbest with values for problems of 30-dimensions[20]. 40
6.2
Problems used for the training ﬁtness function when improving competitive
DE in ADATE, the deﬁnition of each function is available in Appendix A. .
43
6.3
Problems used for the validation ﬁtness when improving competitive DE in
ADATE, the deﬁnition of each function is available in Appendix A. . . . . .
44
6.5
Problems used for the ﬁtness function when improving competitive DE in
ADATE, the deﬁnition of each function is available in Appendix A. . . . . .
45
xi

xii
LIST OF TABLES
6.7
Problems used for the ﬁtness function when improving competitive DE in
ADATE, the deﬁnition of each function is available in Appendix A. . . . . .
46
6.9
Comparison of the ADATE improved pool against the original b3e3pbest
algorithm using the Wilcoxon Rank-sum test with α = 0.05. . . . . . . . . .
50
6.10 Pool of strategies improved by ADATE on CEC problems with 10 dimen-
sions using a population size of 100 individuals. . . . . . . . . . . . . . . . .
51
6.11 Pool of strategies improved by ADATE on CEC problems with 30 dimen-
sions using a population size of 100 individuals. . . . . . . . . . . . . . . . .
51
6.12 Pool of strategies improved by ADATE on CEC problems with 50 dimen-
sions using a population size of 100 individuals. . . . . . . . . . . . . . . . .
52
7.1
Parameters used in the LSHADE-EpSin algorithm. . . . . . . . . . . . . . .
55
7.2
Problems used for training in ADATE when improving LSHADE-EpSin. . .
60
7.3
Comparison of the ADATE improved LSHADE-EpSin algorithm against
the original using the Wilcoxon Rank-sum test with α = 0.05. . . . . . . . .
61
7.4
Improved LSHADE-EpSin tested on CEC 2014 problems with 10 dimensions. 61
7.5
Improved LSHADE-EpSin tested on CEC 2014 problems with 30 dimensions. 62
7.6
Improved LSHADE-EpSin tested on CEC 2014 problems with 50 dimensions. 63
7.7
Comparison of improved LSHADE-EpSin and improved Competitive Dif-
ferential Evolution (CDE) against the original algorithms. The values are
the mean and standard deviation when the algorithms are tested 51 times
on the CEC 2014 functions with 30 dimensions.
. . . . . . . . . . . . . . .
64
8.1
Comparison of supervised learning algorithms for spiking neural networks. .
71
A.1 Base optimization functions - part 1
. . . . . . . . . . . . . . . . . . . . . .
91
A.2 Base optimization functions - part 2
. . . . . . . . . . . . . . . . . . . . . .
92
A.3 Compound optimization functions
. . . . . . . . . . . . . . . . . . . . . . .
92

Listings
5.1
Original formulation of mutation in DE to be improved by ADATE. For
readability, the rconst wrapper round real numbers are removed.
. . . . . .
27
5.2
Datatype for population with variance . . . . . . . . . . . . . . . . . . . . .
28
6.1
Function to be improved by ADATE, containing heuristics for building mu-
tating an individual in CDE.
. . . . . . . . . . . . . . . . . . . . . . . . . .
41
6.2
Function containing the entire strategies pool which has been improved by
ADATE. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
48
7.1
Function to be improved by ADATE, containing heuristics mutating an
individual in LSHADE-EpSin. . . . . . . . . . . . . . . . . . . . . . . . . . .
57
7.2
The improved heuristics for mutating an individual in LSHADE-EpSin.
. .
60
xiii


List of Abbreviations
ADATE Automatic Design of Algorithms Through Evolution.
ANN Artiﬁcial Neural Networks.
BCM Bienenstock-Cooper-Munro.
BPSL Biologically Plausible Supervised Learning.
CDE Competitive Diﬀerential Evolution.
CEC IEEE Congress on Evolutionary Computation.
DE Diﬀerential Evolution.
EC Evolutionary Computation.
GA Genetic Algorithms.
GP Genetic Programming.
I&F Leaky Integrate and Fire.
IP Inductive Programming.
LSM Liquid State Machines.
LSTM Long Short-Term Memory.
LTD Long-Term Depression.
LTP Long-Term Potentiation.
ODE Ordinary Diﬀerential Equation.
PSO Particle Swarm Optimization.
RNN Recurrent Neural Network.
SNN Spiking Neural Network.
SRM Spike Response Model.
STDP Spike-Timing-Dependent-Plasticity.
xv


Chapter 1
Introduction
1.1
Motivation
Problems requiring ﬁnding the optimal parameters of some non-diﬀerentiable processes
arise in many disciplines such as scientiﬁc, engineering, and ﬁnancial computations. When
these problems also become high dimensional, non-convex, and multimodal, solving them
becomes a signiﬁcant challenge. The need for eﬃcient methods has given rise to exten-
sive literature covering both theoretical analysis and practical methods for solving these
problems.
The importance of non-diﬀerentiable optimization has led to many diﬀerent methods
being developed over the years such as Tabu search[1], Simulated annealing[2], and vari-
ous Evolutionary Computation (EC) algorithms like the Artiﬁcial bee colony algorithm[3],
Particle swarm optimization[4], Genetic algorithms[5] and Evolution strategies[6]. Among
these, Diﬀerential Evolution (DE), introduced by Storn and Price [7] in 1995, has shown
itself to be one of the most powerful and versatile numerical optimizers. DE has been
successfully used on a large number of practical problems spanning many ﬁelds, includ-
ing space trajectory optimization[8], ocean glider path planning [9], and optimizing fossil
fuel burning power plants [10]. In addition to this, variants have been among the best-
performing algorithms in most CEC competitions1. The popularity of the algorithm makes
improving it a very competitive endeavor with many new variations published every year
and signiﬁcant improvements are becoming increasingly harder to achieve.
This thesis investigate whether a related ﬁeld, Inductive Programming (IP), can in-
troduce new methods for improving DE and its variants. IP is a ﬁeld dealing with the
problem of automatically designing algorithms to solve problems using only an incomplete
description. A state-of-the-art IP system is Automatic Design of Algorithms Through Evo-
lution (ADATE)[11]–[13]. ADATE has been shown to be excellent at improving heuristics
for tasks such as solving Boolean satisﬁability problems, classifying edges in images and
improving graph based image segmentation [14]–[16].
Spiking Neural Networks (SNNs) are the third generation of neural networks. Unlike
in traditional Artiﬁcial Neural Networks (ANN), the neurons in an SNN communicate
using binary events called spikes, which are produced when the membrane potential of
a neuron reaches a threshold. These networks have several beneﬁts such as being much
more power eﬃcient when implemented in hardware[17], and have been shown to have
the same computational power using fewer gates [18]. While theoretically interesting, is
1For details, see: http://www.ntu.edu.sg/home/epnsugan/index_files/cec-benchmarking.htm
1

2
Chapter 1. Introduction
has few applications in engineering contexts, apart from some limited use of Liquid State
Machines (LSM)[19]. The lack of applications is due to there currently not existing any
good training methods, but DE algorithms could likely be used to train SNNs, especially
if specialized for these types of networks.
1.2
Research questions
This thesis aims at contributing to the understanding of how IP systems could be used to
automatically improve the performance of DE based optimization algorithms. Moreover,
we would also like to contribute to the understanding of how specialized versions of DE
could be created for training of SNNs.
This leads us to deﬁning the following research questions:
RQ1: How can improvements be evaluated quickly enough for ADATE to test millions of
programs while maintaining a suﬃciently high statistical certainty?
RQ2: Which parts of the algorithms should be improved? Many of the algorithms have
multiple parts, all of which could yield signiﬁcant improvements, but the algorithms
are too large for ADATE to improve all-at-once.
RQ3: How can versions of DE, specialized for training SNNs be created?
RQ1 is especially challenging as there is even high signiﬁcant statistical uncertainty
on many problems when following the rigorous submission requirements for competitions
among state-of-the-art optimization algorithms.
1.3
Method
For the experiments aiming to improve variations of DE, the method consists of the fol-
lowing steps:
• Implement the DE variant in Standard ML, and validate that the algorithm is cor-
rectly implemented by comparing against either published results or published im-
plementations if available.
• Identify which part or parts of the algorithm the ADATE system should try to
improve and represent the problem for ADATE.
• Validate the improved algorithm found by ADATE using additional testing problems.
For understanding how IP systems might be used to create specialized versions of DE
for SNNs, an in-depth literature review was used in combination with knowledge from
experiments to propose an algorithm that could be used to train SNNs.
1.4
Structure of this thesis
This section brieﬂy summarizes the contents of each of the remaining chapters in this
thesis. The ﬁrst three chapters are devoted to discussing background literature on opti-
mization, the DE algorithm, and the ﬁeld of IP. The next three discuss three experiments

1.4. Structure of this thesis
3
for improving three variations of DE using ADATE. The next then discusses SNNs, and
how to create specialized versions of DE. The second to last chapter proposes some future
work, and the last chapter concludes this thesis.
Chapter 2 formulates the optimization problem and discusses both derivative and derivative-
free optimization. The chapter also reviews some of the most important methods
for non-diﬀerentiable optimization. Lastly, the chapter covers how optimization al-
gorithms might be evaluated by discussing problem sets and the Wilcoxon rank-sum
test.
Chapter 3 provides an extensive description of the DE algorithm and reviews some of
the work that has been done on using the algorithm to solve practical problems
and understand how the basic steps of mutation, crossover, and selection aﬀect the
search. It also reviews some techniques for parameter-control and Memetic variations
of DE.
Chapter 4 introduces the concept of inductive programming and discusses the diﬀer-
ences between analytical and search based IP systems. It also provides an in-depth
description of ADATE.
Chapter 5 discusses an experiment where we tried to improve the mutation operator
DE/rand/1 in the original DE algorithm. The evaluation followed a quantity over
quality approach with the focus on evaluating improvements quickly at the cost of
low statistical certainty. While the improved algorithm ended up adapting to the
low number of generations used during testing candidate programs, the experiment
provided valuable knowledge for future experiments.
Chapter 6 reports on an experiment that signiﬁcantly enhanced the statistical certainty
of the evaluation used in ADATE at the cost of requiring much more computation
time to evaluate each improvement. This resulted in the successful improvement of
the pool of mutation strategies in b3e3pbest, a version of DE developed by Bujok,
Tvrdk, and Polakova [20]. The variant adapts to the function being optimized by
probabilistically selecting a mutation strategy such that the most successful are
used most often. However, an analysis of the performance of the programs reveal
signiﬁcant problems in the mechanism used to select the most successful strategy,
which likely prevents the algorithm from achieving better results than the best DE
variants.
Chapter 7 reports on the third experiment in which we further improved the statistical
certainty of the performance evaluation in ADATE by increasing the number of
problems used for training and increasing the repetitions of each problem.
This
led to the successful improvement of the mutation heuristics in the state-of-the-art
DE variant LSHADE-EpSin developed by Awad, Ali, Suganthan, et al. [21]. The
improved heuristics achieved statistically signiﬁcant improved performance on CEC
2014 problems of 30 dimensions with a much smaller algorithm.
Chapter 8 provides an in-depth discussion on SNN and discuss how to create versions
of DE specialized for training SNNs.
Chapter 9 proposes further work based on all three experiments, and discuss other meth-
ods for creating specialized versions of DE.

4
Chapter 1. Introduction
Chapter 10 concludes this thesis, summarizes the main contributions of the work and
outline possible directions for future research.
The thesis ends with an appendix containing the deﬁnitions for the synthetic bench-
mark functions used as part of training and validation sets.

Chapter 2
Optimization
Optimization is the process of ﬁnding optimal parameters with respect to some objective
or objectives. In this thesis, only the problems consisting of real parameters with a single
real objective function are considered. That is, problems that can be stated as follows:
Given an objective function:
f : B ⊆RD −→R
(2.1)
with B being a D-dimensional hyperbox formed by the bounds:
xmin = (xmin,1, xmin,2, · · · , xmin,D)
(2.2)
xmax = (xmin,1, xmax,2, · · · , xmax,D),
(2.3)
ﬁnd an element x0 such that f(x0) ≤f(x) for all x ∈B.
This deﬁnition limits the optimization problems to minimization. This is intentional
as the conversion between minimization and maximization is, in most cases, trivial. Most
techniques used to solve optimization problems like this can be classiﬁed as being either
derivative based or derivative free.
2.1
Derivative-based optimization
Derivative-based optimization uses information about the gradient during optimization to
quickly converge to a locally optimal solution. While it is possible to use the gradient
directly for some simple functions to ﬁnd the true minimum by solving for f′(x) = 0, most
problems require using the gradient iteratively to ﬁnd the minimum.
The simplest of these is the gradient descent method:
x(t+1) = x(t) −γ · f′(x(t))
(2.4)
with γ being a parameter controlling the step size and the gradient is deﬁned as
f′(x) = ∇f(x) =


∂f(x)
∂x1
∂f(x)
∂x2...
∂f(x)
∂xD


.
(2.5)
5

6
Chapter 2. Optimization
The importance of the gradient descent method has led to the development of many
variations that solve or mitigate some of the practical problems with steepest descent. But
all these variations require the objective function to be diﬀerentiable.
2.2
Derivative-free optimization
It is in many situations not possible to diﬀerentiate the objective function. For example,
if the objective function is a computer program with branching, calculating the symbolic
derivative might be impossible or prohibitively diﬃcult.
Without the derivative, the algorithms have to search through the search landscape
using only information obtained by generating and testing a, sometimes large, number of
points. The simplest of these is brute force search which tests every point in a grid covering
the search space. This method is simple to implement. But the computation time quickly
becomes prohibitively large as the step sizes in the grid are reduced to achieve higher
accuracy. Random walk is another simple method which works by starting with a single
point and adding a random value sampled from a Gaussian distribution to each dimension.
This improves slightly on brute force search but still suﬀers from the diﬃculty of ﬁnding
the optimal solution, even for unimodal problems.
Many solutions have been proposed for derivative-free optimization over the years. We
brieﬂy discuss some of the most important in the following sections.
2.2.1
Simulated annealing
Simulated annealing is an optimization method based on the technique of heating and
cooling a metal to increase the size of its crystals[2]. When the metal is hot, it is easier to
change the structure of the metal because the crystals are freer to move around. As the
metal cools, the crystals become increasingly constricted in their movement.
Drawing inspiration from this process, Simulated annealing maintains two pieces of
information: the temperature and the state, usually a candidate solution. The algorithm
then iteratively perturbs and replaces the candidate solution with better solutions as they
are discovered. The size of the perturbation is determined by the temperature which starts
high and is gradually lowered for each iteration.
2.2.2
Tabu search
Tabu search is a single individual, local search algorithm developed by Glover [1]. The
algorithm moves the individual to the best solution in the neighborhood. Moves to worse
solutions are allowed, stopping only when a criterion is satisﬁed.
The search as described above might result in inﬁnite loops; these are prevented by
storing previous solutions for some time in a data structure called a Tabu list. By not
allowing moves to any candidate in the list, the algorithm is free to explore the search
space in a greedy manner.
2.2.3
Evolutionary computation
Inspired by the biological process of evolution, evolutionary computation algorithms start
with a population of candidate solutions which are iteratively evolved towards better

2.2. Derivative-free optimization
7
solutions by using some or all of the fundamental mechanisms, namely, mutation, crossover,
and selection.
Artiﬁcial bee colony algorithm
The Artiﬁcial bee colony algorithm is an optimization algorithm inspired by the foraging
behavior of bees as proposed by Karaboga [3]. The algorithm starts with a population of
food sources, represented by randomly initialized candidate solutions.
The algorithm consists of three phases, each of which governs the process of the three
types of bees, namely, employed bees, onlooker bees and scout bees.
Employed bees are assigned a food source and explore the neighborhood of that food
source in search of better food sources.
Onlooker bees then get probabilistically assigned food sources weighted according to
how good each food source is after the employed bees ﬁnish.
Scout bees explore the search space randomly in search of new and better food sources.
The best food sources are then saved and the process repeated until a termination criterion
is satisﬁed.
Particle swarm optimization
Particle Swarm Optimization (PSO), ﬁrst proposed by Eberhart and Kennedy [4] is an
optimization algorithm inspired by how animals like birds, and ﬁsh are capable of solving
complicated problems without central control.
The algorithm uses a set of candidate solutions called particles which together are
known as a swarm. At each iteration t, the position of the particle i are updated according
to:
x(t+1)
i
= v(t+1)
i
+ x(t+1)
i
(2.6)
The velocity v(t+1)
i
is calculated according to:
v(t+1)
i
= v(t)
i
+ c1(p(t)
i
−x(t)
i )R(t)
1 + c2(g(t) −x(t)
i )R(t)
2
(2.7)
Here momentum is maintained by basing the new value on the previous velocity v(t)
i . The
parameter c1 controls how much the trajectory of the particle is aﬀected by the best point
p(t)
i , found so far by the particle, and c2 controls how much the trajectory is aﬀected by
g(t), the best point found by any particle. R1 and R2 are two diagonal matrices with
random numbers drawn from a uniform distribution between 0 and 1.
By repeating the application of Equation (2.6) and Equation (2.7), incrementing t and
updating the best known points at each iteration, the population of particles will converge
to a local optimum over time.
The standard algorithm here has multiple problems. The amounts of identiﬁed prob-
lems and solutions are vast, and a complete review would be prohibitively large, but a
recent review of the most practically relevant issues and their solutions can be found in
[22].

8
Chapter 2. Optimization
Genetic algorithms
Genetic Algorithms (GA), proposed by Holland [5], solve optimization problems by a
process inspired by natural selection. The basic outline of the algorithm is as follows:
Algorithm 1 General structure of a genetic algorithm
Initialize population with random candidate solutions
while Termination criteria not met do
Select parents.
Recombine pair of parents.
Mutate the resulting oﬀspring.
Evaluate new candidates.
Select next generation.
end while
The individuals are encoded using binary encoding. That is, each individual is rep-
resented by a string of 0’s and 1’s. This representation is practical for problems which
lends themselves to a binary representation, but makes solving problems with real values
diﬃcult.
Evolution strategies
Evolution strategies is an evolutionary algorithm similar to genetic algorithms but designed
to solve real-valued problems[6]. Here the individuals are represented using two pieces of
information. The real-valued vector representing the candidate solution, and a vector of
parameters which determine how the individual is mutated. The parameters are evolved
alongside the solution as a form of adaptation.
2.3
Evaluating optimization algorithms
Most publications of optimization algorithms use a self-deﬁned set of synthetic functions
with their own constraints on the number of function evaluations, search domain range
and initialization. This practice often makes it impossible to compare diﬀerent algorithms
using the published results.
A solution comes from IEEE Congress on Evolutionary Computation (CEC) which has
designed several predeﬁned sets of benchmark problems with strict rules for how results
are to be reported to make the results directly comparable as part of competitions. For
single-objective, real-valued optimization, CEC covered four diﬀerent classes as part of the
2016 competition1:
Single parameter-operator set based case Optimization of problems with a single
objective and real-valued parameters. The optimizer is allowed to perform a large
number of function evaluations using a single conﬁguration across all problems. This
set is referred to as CEC 2014 in the remainder of this thesis [23].
Learning-based case Similar to CEC 2014, but the researcher is allowed to adjust the
parameter for each problem to ﬁnd the optimal solution.
1Detailed descriptions can be found at:
http://www.ntu.edu.sg/home/EPNSugan/index_files/
CEC2016/CEC2016.htm

2.3. Evaluating optimization algorithms
9
Multi-solution niching case The algorithm has to ﬁnd as many as possible of the op-
tima of a given ﬁtness landscape, not just a single global optimum.
Computationally expensive case Similar to CEC 2014, but with a much smaller bud-
get of allowed function evaluations.
2.3.1
CEC 2014 problems
The CEC 2014 set consists of 30 unique minimization problems all deﬁned for D = 10,
D = 30, D = 50 and D = 100 dimensions. In this project, the CEC 2014 problems with
10 and 30 dimensions were used to evaluate all improved algorithms. When computation
time permitted, problems with 50 dimensions were also used.
The requirements include reporting the best, worst, median, mean and standard devi-
ation for all functions. The optimizers must start from a population randomly initialized
from a uniform distribution using a time-dependent seed and repeated 51 times.
The
optimizer is allowed to evaluate the ﬁtness function a maximum of 10000·D times[23], the
search space is limited to [−100, 100]D. The problem is considered solved when an error
value smaller than 10−8 is achieved. At which point the search can be terminated. All
values smaller than 10−8 should be treated as zero.
To make the problems unique and slightly more challenging, CEC 2014 has used three
randomization strategies:
shift All functions are shifted by a shift provided in precomputed data ﬁles for each
function. The shift has been computed by randomly sampling from [−80, 80].
rotation Some functions are rotated using a precomputed rotation matrix. The exact
algorithm used to compute the rotation matrices is poorly documented.
permutation The components of all functions have been randomly permuted.
2.3.2
Wilcoxon rank-sum test
A statistical test is needed to preform statistically sound comparisons between optimiza-
tion algorithms, but the results are rarely normally distributed. Thereby making paramet-
ric methods such as the two-sample t-test unsuitable. Instead, the Wilcoxon rank-sum test
is therefore used, as it does not have the assumption of normality on the observations[24].
This test uses the ordering of the observations within two samples to determine whether
there are statistically signiﬁcant diﬀerences between the two samples.

Chapter 3
Diﬀerential evolution
DE is similar to classical evolutionary algorithms in which a population of candidate
solutions, initialized to a uniform sampling of the instance space, are gradually improved
by repeatedly modifying the candidates and selecting the next generation. However, unlike
other evolutionary algorithms such as Evolution Strategies, mutation is accomplished by
using the scaled diﬀerence between members of the population[6]. This has the eﬀect of
adapting the step size to the ﬁtness landscape over time.
DE consists of four phases: initialization, mutation, crossover, and selection. The last
three of these are repeated until a termination condition such as the maximum number of
generations is met.
Algorithm 2 The standard diﬀerential evolution algorithm.
P (1) ←{x(1)
i
, x(1)
i
, . . . , x(1)
Np}
▷see section 3.1 for details.
t ←1
while Termination criteria not met do
for i ←1, Np do
v(t)
i
←mutate(x(t)
i )
▷see section 3.2 for details.
u(t)
i
←crossover(x(t)
i , v(t)
i )
▷see section 3.3 for details.
if f(u(t)
i ) ≤f(x(t)
i ) then
Insert u(t)
i
into P (t+1)
else
Insert x(t)
i
into P (t+1)
end if
end for
t ←t + 1
end while
3.1
Initialization
DE starts by initializing a population of Np, D-dimensional real-valued vectors. Individ-
uals in the population are denoted by
x(t)
i
=

x(t)
i,1, x(t)
i,1, · · · , x(t)
i,d

,
(3.1)
10

3.2. Mutation
11
with t = 1, 2, · · · , tmax being the generation number.
The initial population should be initialized to cover as much as possible of the search
space constrained by the minimum and maximum bounds xmin = (xmin,1, xmin,2, · · · , xmin,D)
and xmax = (xmax,1, xmax,2, · · · , xmax,D). The j’th component may then be initialized as:
x(1)
i,j = xmin,j + randi,j(0, 1)(xmax,j −xmin,j)
(3.2)
with randi,j(0, 1) being a uniformly random value between 0 and 1.
3.2
Mutation
The next step is to generate a donor vector v(t)
i
for each member of the population using
mutation.
In all operators, R1, R2, R3, R4, and R5 are mutually exclusive, random
integers, drawn from the range [1, Np], and all being diﬀerent from the base index i. x(t)
best
is the individual with the best ﬁtness value for that generation. F is a scaling factor
typically in the range [0.1, 2.0].
3.2.1
DE/rand/1
Proposed in the original 1996 paper by Storn [25] and perhaps the most used mutation
operator. The DE/rand/1 operator creates a donor vector by adding the scaled diﬀerence
between two random individuals to a third randomly selected individual:
v(t)
i
= x(t)
R1 + F

x(t)
R2 −x(t)
R3

(3.3)
3.2.2
DE/best/1
The DE/best/1[25], also proposed in the original publication adds the scaled diﬀerence
between two random individuals to the best individual in the population:
v(t)
i
= x(t)
best + F

x(t)
R1 −x(t)
R2

(3.4)
3.2.3
DE/current-to-best/1
This mutation, also named DE/target-to-best/1 [26] and part of the original publication
[25], is usually used with the only crossover being the arithmetic operation on the current
individual x(t)
i :
v(t)
i
= x(t)
i
+ F

x(t)
best −x(t)
i

+ F

x(t)
R1 −x(t)
R2

(3.5)
This mutation operator is known to easily get stuck in local optima, especially on
high dimensional problems[27]. However, a more robust, less greedy variant is used as
part of the SHADE-EPsin algorithm discussed in chapter 7. That version is commonly
used in combination with the binomial crossover in most state of the art DE variants.
However, that version is not included in this list as, it requires larger modiﬁcations to the
DE algorithm to include an external archive.

12
Chapter 3. Diﬀerential evolution
3.2.4
DE/rand/2
DE/rand/2 stabilizes the search by including the diﬀerence between another pair of indi-
viduals[25]:
v(t)
i
= x(t)
Ri
1 + F

x(t)
R2 −x(t)
R3

+ F

x(t)
R4 −x(t)
R5

(3.6)
3.2.5
DE/best/2
Similar to DE/rand/2, but uses the best individual as the base[25]:
v(t)
i
= x(t)
best + F

x(t)
R1 −x(t)
R2

+ F

x(t)
R3 −x(t)
R4

(3.7)
3.2.6
DE/Randrl/1
Designed to speed up convergence when using DE/rand/1, but reduce the problems of
getting stuck in local optima which are common with DE/best/1. DE/Randrl/1 use the
tournament best as the base individual[28]:
v(t)
i
= x(t)
tb + F (t)
i

x(t)
p2 −x(t)
p3

,
(3.8)
where x(t)
tb is the tournament best among three randomly chosen individuals, with x(t)
p2 and
x(t)
p3 being the remaining two individuals. F (t)
i
is chosen randomly from F (t)
i
∈[−1, −0.4]∪
[0.4, 1].
3.2.7
Trigonometric mutation
Fan and Lampinen [29] proposed to use triangulation to more quickly ﬁnd the optimal
solution by forming the donor vector according to:
v(t)
i
=



y(t)
i
if rand(t)
i (0, 1) ≤Γ
x(t)
R1 + F

x(t)
R2 −x(t)
R3

otherwise
(3.9)
With
y(t)
i
= x(t)
R1 + x(t)
R2 + x(t)
R3
3
+ (p2 −p1)

x(t)
R1 −x(t)
R2

+
(p3 −p2)

x(t)
R2 −x(t)
R3

+ (p1 −p3)

x(t)
R3 −x(t)
R1

(3.10)
p′ =
f(x(t)
R1)
 +
f(x(t)
R2)
 +
f(x(t)
R3)

(3.11)
p1 =
f(x(t)
R1)
 /p′
(3.12)
p2 =
f(x(t)
R2)
 /p′
(3.13)
p3 =
f(x(t)
R3)
 /p′
(3.14)
where f(x) is the function to be optimized, and Γ ∈[0, 1] is the rate which trigonometric
mutation should be used, DE/rand/1 is used with a probability of 1 −Γ.

3.3. Crossover
13
3.3
Crossover
Trial vectors are created by recombining the target vector x(t)
i
and the donor v(t)
i
using
a crossover operator. How many components get taken from the donor is controlled by
the crossover rate parameter: CR. A good choice of CR is especially important when
optimizing non-separable functions[30]. In this thesis, separable functions are functions
which are additively separable such that they be expressed as:
f(x1, x2, . . . , xD) =
D
X
j=1
fj(xj)
(3.15)
Additively Separable functions are special because they can be optimized one variable at
a time. As a result, the problems do not get harder as the dimensionality increases.
(a)
Improvement
interval
on
a
quadratic function.
(b) Improvement interval on a rotated
quadratic function.
Figure 3.1: Illustration by Salomon [30] on the importance of crossover in non-separable functions.
The importance of the crossover rate on separable functions was illustrated by Salomon
[30] using ﬁgure 3.1a. On this non-rotated function, there is a large improvement interval
which in turn means there is a high probability of improvement when moving along any
of the dimensions in the right direction. However, when looking at the same quadratic
function in ﬁgure 3.1b, turned non-separable by rotation, the improvement intervals have
shrunk. Thus reducing the probability of an improvement when moving along only one of
the dimensions. The path in ﬁgure 3.1b also illustrates another problem. The number of
steps required has increased to a point where the optimum might never be reached.
These observations mean that using a small CR value might work well on separable
functions, but will reduce progression of the search on non-separable functions.
Another important work on understanding the crossover rate comes from Zaharie [31],
[32] who recognized that the variance before and after mutation and crossover follow the
relation:
E(V ar(U(t)) = c · V ar(P (t)),
(3.16)
with
c = 2F 2p −2p
Np
+ p2
Np
+ 1
(3.17)
with p being the probability a component is mutated. This observation can be used to
determine the behavior of the search. By adjusting CR and F values using c as a guide,
the variance of the population can be controlled. Speciﬁcally, using c = 1.07 will stimulate

14
Chapter 3. Diﬀerential evolution
an 7% increase in the population variance. Kukkonen found empirically that a value in
[1, 1.5] performs seemed to perform best [33], [34].
3.3.1
Binomial crossover
The binomial crossover produces a trial vector by selecting a component from the donor
vector whenever a randomly generated value drawn from a uniform distribution is below
the crossover rate CR. Additionally, a component k is randomly chosen per iteration to
always come from a donor vector as follows:
u(t)
i,j =



v(t)
i,j
if i = k or randi,j(0, 1) ≤CR.
x(t)
i,j
otherwise.
(3.18)
An example of this is illustrated in ﬁgure 3.2.
Figure
3.2:
Example
of
the
binomial
crossover operation.
Figure 3.3:
Example of the exponential
crossover operation.
3.3.2
Exponential crossover
Exponential crossover tries to exploit relationships between adjacent components. It works
by choosing a random starting component and selecting the next L consecutive components
in a circular manner from the donor vector. The number of components L is calculated
as follows:
Algorithm 3 Exponential crossover
L ←0
repeat
L ←0
until rand(0, 1) > CR or L > D
An example of this is illustrated in ﬁgure 3.3.
Compared to binomial crossover, the signiﬁcance of the CR value in the exponential
crossover is harder to understand. The work of Zaharie [32] eases this by showing that
the probability p of a component being chosen from the donor vector follows the relation:
CRD −DpCR + Dp −1 = 0
(3.19)

3.4. Selection
15
3.4
Selection
Selecting the survivors to form the next generation is accomplished by pairwise tournament
selection:
xi(t+1) =



ui
if f

u(t)
i

≤f

x(t)
i

,
xi(t+1)
otherwise,
(3.20)
where f(·) is the objective function to be optimized.
3.5
Parameter control
Parameters have a large impact on the search performance and are known to be problem
dependent[35]. They might also need to be changed during the search, either following a
ﬁxed predeﬁned plan or adapted during the search.
3.5.1
Population size
In DE, the population size is most often kept constant during the entire optimization. An
exception to this is the L-SHADE algorithm proposed by Tanabe and Fukunaga [36]. L-
SHADE reduce the population size linearly in terms of the consumed function evaluations.
This technique is described in detail in section 7.1.3.
In the ﬁeld of evolutionary algorithms at large, population size is recognized as one of
the most important parameters to control with extensive work on:
• Theoretical studies[37]–[41].
• Adapting the population size to changing circumstances during the run[42], [43].
• Controlling the population size using a predeﬁned plan or searching for optimal
population sizes[44], [45].
A comprehensive review is available in [46].
3.5.2
Scaling factor and Crossover rate
In DE, the scaling factor F and crossover rate CR are usually adapted using the same
techniques for both parameters, only diﬀering in biases and the sampling distributions.
SaDE, developed by Qin and Suganthan [47], was one of the early attempts at making
an adaptive version of DE. The algorithm records successful CR values for ﬁve generations;
the mean of which is then used for the next ﬁve generations to produce CR values by
sampling from a normal distribution.
In 2009, Zhang and Sanderson [48] proposed the JADE algorithm which provides
improved adaptation mechanics for both CR and F. Instead of maintaining a record of
successful values like those used in SaDE, JADE maintains two variables: µF and µCR.
These are updated at the end of the generation, using values which were successful in the
current generation. µF and µCR can be prevented from changing too quickly by adjusting
a parameter.

16
Chapter 3. Diﬀerential evolution
3.5.3
Adaption of mutation operators
The optimal mutation operator depends on the function being optimized. This can be seen
in Tables 5.5 to 5.8, where the performance of the mutation operators diﬀers signiﬁcantly
between the functions. There have been several attempts dynamically switching between
diﬀerent mutation operators during evolution, this section describes some of these.
SaDE switches adaptively between the two strategies “DE/rand/1/bin” and “DE/best/2/bin”
by recording how successful each strategy is during a learning period.
The strategies
are then selected probabilistically by weighting the strategies using the recorded success
counts.
A similar algorithm, Competitive Diﬀerential Evolution (CDE), developed by Tvrdk
[49]. Switches between a pool of strategies, each of which include the scaling factor and
crossover rate in addition to the mutation operator. Each strategy is associated with a
counter which counts how many times the strategy has been successful. These counts
are then used as weights when probabilistically selecting a strategy.
The counts reset
whenever the probability of selecting any of the strategies becomes too low. The pool of
strategies in CDE has been improved in chapter 6.
While both the two preceding algorithms use counts to select a good strategy prob-
abilistically, Mallipeddi, Suganthan, Pan, et al. [50] used a diﬀerent approach.
They
maintain a dynamic pool of strategies where at the end of each generation, the strategies
which have produced individuals that are selected for the new generation are inserted into
the pool.
3.6
Memetic variants
Memetic algorithms hybridize evolutionary algorithms by including local improvement
heuristics into the default population-based evolutionary algorithms.
This section de-
scribes some of these approaches applied to DE. Including local search heuristics in DE
is relatively common, with many diﬀerent proposals on how this can be accomplished. In
most cases, the local search heuristics is only used after a certain number of generations
have passed, or with probabilistic triggering.
Local improvement based
Local improvement based local search tries to improve some or all of the individuals in the
population by using some common technique like hill-climbing, or random perturbations.
One such method proposed by Wang, Qian, and Hu [51] uses chaos theory to produce
random perturbation of the best 20% individuals after each generation. A similar approach
was adopted by Jia, Zheng, and Khan [52], but only applied it on the best individual at
each generation.
A proposal by Poikolainen and Neri [53] is to perform a step along each axis on a subset
of the individuals in the population, replacing the individual each time an improvement
has been found.
Crossover based
Crossover local search based approaches exploit the recombination to produce children in
the neighborhood around the individuals in the population.

3.7. Applications
17
Ali, Pant, and Nagar [54] propose two crossover based local search methods.
The
ﬁrst involves repeatedly applying the trigonometric mutation operator discussed in sec-
tion 3.2.7 until no further improvement could be found. The second method uses quadratic
interpolation to calculate the new individuals. A recent proposal by Peng and Wu [55]
uses Taguchi local search to produce new individuals.
Ensemble based
The LSHADE-EpSin algorithm. which is improved in chapter 7, uses a Gaussian random
walk on an independent, randomly initialized population to produce new individuals. The
best performing individuals found by the local search replace random individuals in the
DE population.
3.7
Applications
DE and its variations have been successfully used to solve a vast amount of practical
problems. This section lists some of these, for a more extensive review, see [56].
3.7.1
Economic Dispatch problem
DE has been used extensively to ensure optimal power delivery while reducing fuel cost
and emission of pollutants in fossil burning power plants while dealing varying power
demands. The most common approach is to formulate mathematical models with the goal
of incorporating all essential and relevant constraints. A recent, extensive review of this
ﬁeld is available in [10].
3.7.2
Ocean glider path planning
An ocean glider is an autonomous underwater vehicle that propels itself forward by chang-
ing its buoyancy. For the glider to reach the target, it must react to changes in ocean
currents and the dynamics of the vessel using a power eﬃcient algorithm. Zamuda and
Sosa [9] proposed to use DE to plan a three-dimensional path with the ﬁtness being the
distance to the target obtained by running a simulation.
3.7.3
Space trajectory optimization
Vasile, Minisci, and Locatelli [8] propose a modiﬁed version of DE for multi-objective
optimization to solve space trajectory planning problems. They use two main models of
space trajectories, one with deep space maneuvers, and one without.

Chapter 4
Inductive programming
IP is the ﬁeld concerned with automatically designing algorithms from incomplete, often
ambiguous speciﬁcations of the problem. Such as training data consisting of an input and
expected output.
When compared to common machine learning methods, IP has several advantages.
Since the hypothesis language used by inductive programming systems is often a functional
or logic-based language. The language can be either domain speciﬁc or a Turing complete,
general programming language. The complexity of the learned hypothesis can more easily
be assessed. Being able to search for the simplest hypothesis which explains the provided
examples means the amount of training data required is reduced.
Additionally, while
a learned hypothesis encoded in most machine learning models like neural networks is
diﬃcult or practically impossible to comprehend. The hypothesis’ learned by inductive
programming can more easily be analyzed and understood.
Understanding the hypothesis provides more options when validating the results. Ma-
chine learning techniques are often limited to using statistical methods to prove the ac-
curacy and generalizability of a hypothesis1. When validating hypothesis’ learned by IP,
there is an additional option of inspecting the code, and sometimes parts of the hypothesis
can be isolated and analyzed separately.
4.1
Types of inductive programming
Contemporary approaches can be classiﬁed into being either search based, analytical or a
combination of the two.
4.1.1
Analytical approaches
Analytical approaches try to synthesize programs using training examples and domain
speciﬁc background knowledge. These approaches are typically limited to solving problems
which can be formulated as:
q∗= q ∈Q : Correct(q)
(4.1)
with Q being the set of valid programs and Correct : Q −→B being a predicate on the
validity of the program q.
1With the exception of some methods like decision tree learning which provides interpretable trees.
18

4.1. Types of inductive programming
19
Development of analytical approaches started in the 1970s with the work on systems
like THESYS[57] which constructs recursive LISP programs from examples. These were
improved in the 1990s with work mostly focused on inductive logic programming which
uses logic languages as the hypothesis language. Some of the major work was done on
systems like Golem [58], Progol [59], [60], and Dialogs [61]. The state-of-the-art analytical
IP system is IGOR2, an improvement of the earlier IGOR system[62]–[64].
4.1.2
Search based approaches
Search-based approaches work by generating programs using some heuristic and evaluating
them by testing how well they perform according to some measurements. These can usually
be stated as a variant of the optimization problem:
Given a set of valid programs Q:
min(pe1(q), pe2(q), . . . , pek(q))
(4.2)
with q ∈Q and pei being program evaluation functions used to balance multiple criteria
such as program size, running time, and results from evaluation of training problems.
This process is typically more ﬂexible than analytical induction because the solvable
problems are not limited to being expressed by input/output examples, but also include
problems where programs have to be evaluated as part of larger simulations. This ﬂexibility
does however come at the cost of being vastly more computationally expensive.
The diﬀerence between optimization based approaches is largely in how the search
space is navigated. The following sections describe some of the most prominent methods.
MagicHaskeller
MagicHaskeller developed by Katayama [65] is one of the most known enumerative IP
systems[66].
It is capable of synthesizing short, pure functional Haskell functions by
exhaustively searching all possible programs, starting with short programs, and gradually
increasing the length.
Additionally, it has been explored using analytical synthesis to
produce more promising programs based on techniques introduced in IGOR 2[65].
More recently, they have investigated whether the algorithm could be improved by
collecting usage data for commonly used expressions from many synthesizes to bias the
search towards more common constructs[67].
Genetic programming
Evolutionary computation has a long history with IP, and one such approach is Genetic
Programming (GP) [68]. GP is similar to GA, but with the individuals represented by
trees or some functional programming language of varying size. Like GA, evolution uses
repeated applications the mechanisms: reproduction, selection, mutation, and recombina-
tion to evolve a population of programs towards better programs.
However, one of the most studied topics is the problem of GP producing bloated
programs, with expressions growing indeﬁnitely in size[69].
ADATE
The system used in this thesis, ADATE is an evolution inspired, local search algorithm.
The system manages to naturally combine the beneﬁts of evolutionary search, with a high

20
Chapter 4. Inductive programming
bias towards smaller programs. A detailed description of ADATE is given in Section 4.3.
4.2
Applications
This section describes similar work where IP systems have been used to improve or design
heuristics for algorithms.
4.2.1
Bent Function Synthesis
Hrbacek and Dvorak [70] won bronze medal in the 2014 Humies Awards2 by using Cartesian
Genetic Programming to synthesize bent functions. Bent functions are functions that are
naturally hard to approximate and are therefore desirable in the ﬁeld of cryptography.
4.2.2
Improving image analysis algorithms
There are multiple attempts at using both GP and ADATE to improve image segmentation
algorithms. The most similar to the work in this thesis, is the work by Magnusson and
Olsson [71]–[73] who used ADATE to improve the Canny edge detector algorithm.
4.2.3
Improving search heuristics
Both GP and ADATE have been used extensively to improve search algorithms. Many of
these use GP to improve the heuristics used in varying forms of the knapsack problem[74]–
[76] or scheduling problem [77]. More related work try to improve the local search heuristics
for solving Boolean Satisﬁability Problems[14], [78], [79].
4.3
ADATE
ADATE is an IP algorithm developed by Olsson [11] based on iterative deepening local
search with evolution inspired heuristics. It is capable of generating functional programs
with multiple, mutually recursive, auxiliary helper functions. The search algorithm evolves
a kingdom of programs by systematically generating and testing a large amount of pro-
grams. The overall search process is outlined in Algorithm 4.
The search starts by initializing the kingdom K and inserting the initial program. The
outer loop representing generations, iteratively deepends the Wtot variable, which controls
how many children are to be produced for each parent program using the branching
factor α. The smallest program which has not been expanded in the current generation is
then selected for expansion, with the children inserted into the kingdom. This process is
repeated until there are no more programs in the kingdom which has not been expanded
in the current generation.
The program chosen for expansion is expanded for each of the forms discussed in
Section 4.3.2, with the goal of producing Wtot/Nforms children for each form using itera-
tive deepening of the Cost_limit variable using the branching factor β. The Cost_limit
variable limits the size of each transformation, in eﬀect deﬁning the neighborhood of a pro-
gram. The iterative deepening of Cost_limit is stopped when it reaches 20 · Wtot/Nforms
2For details see: http://www.human-competitive.org/awards

4.3. ADATE
21
Algorithm 4 The overall ADATE search.
i ←0
K ←empty kingdom
Insert( K, initial program )
repeat
Wtot = 100 · αi
while K contains programs not expanded with Wtot do
q ←smallest program in K, not expanded with Wtot.
for n ←1, Nforms do
c ←0
Cost_limit ←100
j ←0
while Cost_limit < 20·Wtot
Nforms ∧c <
Wtot
Nforms do
Children ←Expand( p, n, Wtot −c, Cost_limit )
▷see Section 4.3.2
c ←c + |Children|
Insert( K, Children )
j ←j + 1
Cost_limit ←100 · βj
end while
end for
end while
i ←i + 1
until terminated by user
but can also end early when all programs have been expanded to produce Wtot/Nforms
programs for each form.
This algorithm, when combined with the kingdom structure described in the next
section allows ADATE to greedily search with a bias towards smaller programs while
avoiding bloated programs and getting stuck in local optima.
4.3.1
The kingdom
The kingdom structure is the core of ADATE and has to balance many diﬀerent require-
ments to maintain diversity. The solution is a kingdom structure inspired by Linnean
Taxonomy. The kingdom consists of nine populations, one for each of the three evaluation
functions: pe1, pe2 and pe3 where programs are compared by lexical ordering using the
criteria in Table 4.1. Each of these is evaluated using three diﬀerent syntactic complexity
measures. The populations are in turn organized into a grid with rows for spans of syn-
tactic complexities and columns for spans of time complexities. Each cell in the grid is
called a family and consists of a base individual and three classes. The classes are used
to prevent ADATE from getting stuck in local optima due to missing links between the
program and the initial program. In this thesis, only one column for time complexity is
used.
When a program is considered inserted into the kingdom, it is, in turn, attempted
inserted into all populations. A program is admitted to a family when it is better than
all smaller programs. The program replaces the base individual in the family if it is not
worse, and is smaller or has lower time complexity. If the program is unable to replace the

22
Chapter 4. Inductive programming
Table 4.1: Criteria for each evaluation functions. The functions are evaluated such that smaller of
each criteria is better. Nc is number of correct problems, Nw is number of incorrect, G is the user
deﬁned grade, S is the syntactic complexity and T is the time complexity.
Evaluation function
Criteria
1
2
3
4
5
pe1
−Nc
G
Nw
S
T
pe2
−Nc
G
Nw
T
S
pe3
Nw
−Nc
G
S
T
peREQ
−Nc
G
Nw
base individual, the program is attempted inserted into one of the classes in the family.
The program is rejected from the family if it is unable to enter any of the classes.
4.3.2
Expanding a program
ADATE attempts to create W programs using the process outlined in Algorithm 5.
Fewer programs might be created if there are no possible transformation with the cur-
rent Cost_limit, or if some the programs fail according to some criteria not accounted for
during synthesis.
Algorithm 5 Expand program q to produce W children using form n with Cost_limit
procedure Expand( q, n, W, Cost_limit )
R ←∅
for i ←1, W do
c ←SynthesizeChild( q, n, Cost_limit )
if c ̸= null ∧IsValid( c ) then
R ←R ∪{c}
end if
end for
return R
end procedure
Atomic transformations
Programs are transformed using one or more compound transformations which consist of
one or more of the following atomic transformations:
R: Replacement transformation replaces an expression with a synthesized expression.
This is the only transformation which can change the semantics of the program.
REQ: This transformation replaces an expression with another that have been shown em-
pirically to not reduce the performance of the program according to peREQ deﬁned in
Table 4.1. This is used in compound transformations to reach a larger neighborhood
of programs.
CASE-DIST: Moves a case expression either out of, or into a function call. An example
is shown in Figure 4.1.
ABSTR: Abstracts an expression into a nested function with a maximum arity of 2. An
example of this is shown in Figure 4.2.
EMB: Changes either the argument, or return type of a nested function.

4.3. ADATE
23
fun
f
x =
case x =>
true => g ( 1 )
|
f a l s e => g ( 2 )
(a) Before
fun
f
x =
g ( case x =>
true => 1
|
f a l s e => 2 )
(b) After
Figure 4.1: Example of the CASE-DIST atomic transformation.
fun
f
x =
1+2+3
(a) Before
fun
f
x =
let
g (V1, V2) => V1 + V2
in
g (
1 , 2 ) + 3
end
(b) After
Figure 4.2: Example of the ABSTR atomic transformation.
Compound transformations
Except for the ﬁrst atomic transformation, the transformations have to be chosen according
to the following coupling rules:
• REQ ⇒R
• REQ ⇒ABSTR
• ABSTR ⇒R
• ABSTR ⇒REQ
• ABSTR ⇒REQ ⇒REQ
• ABSTR ⇒EMB
• CASE-DIST ⇒ABSTR
• CASE-DIST ⇒R
• EMB ⇒R
Combining these rules in all possible ways result in Nforms = 22 forms such as: REQ ⇒
ABSTR ⇒REQ ⇒R.
4.3.3
Speciﬁcation
The speciﬁcation contains information about the problem to be solved by ADATE. It
provides information about how a synthesized program is to be evaluated and which
programs can be synthesized.
A speciﬁcation is a text ﬁle consisting of two parts separated by a line containing only
the text %%. The code above this line is written in ADATE-ML, a language which is
described in Section 4.3.4. This part contains the deﬁnition of the f-function, supporting
user deﬁned data types and helper functions that are to be made available within f. The
part below %% is code written in Standard ML, which contain everything else.

24
Chapter 4. Inductive programming
Grading programs
The grade is a user-deﬁned measure of how well a program solves the problem. Grading is
done by using two sets of problems: Training and Validation. When testing a program, all
problems in these sets are passed the main function. In this thesis, this function implements
a variation of the DE algorithm. The parts of this algorithm which are to be improved
by ADATE is isolated into a function called f. This will be described more in the next
section. The result from main is passed to a function output_eval_fun which evaluates the
result to determine whether it should mark the problem as correctly solved and calculates
the grade. The grade is used to provide a nuanced measure of how well the problem was
solved.
In this project, the result is marked as not correct if it throws an exception at any
point while being tested.
This will often happen with invalid f-functions, which have
invalid raise statements. In addition, exceptions are also thrown to quit the testing of
programs which returns other types of bad results. Examples include real values outside
the accepted range. The grade for the problems where this occur are set to the value 1014,
which is much larger than any valid grade and would cause the program to be discarded
by ADATE.
The f-function
The f-function encapsulate the parts of an algorithm which is to be improved by ADATE
written in the ADATE-ML language which is described in Section 4.3.4. In addition to
only using the functionality provided by ADATE-ML, the function also must take only
a single argument. Passing multiple arguments can be done using user-deﬁned algebraic
data types. The code must also be side-eﬀect free, which preclude modifying arrays or
other mutable data structures in helper functions.
In this project, it was necessary to improve several parts of the algorithms simultane-
ously. This was solved by using a user-deﬁned data type for the argument with constructors
for each of the parts to be improved.
Controlling program synthesis
ADATE provides several methods for controlling which programs can be synthesized to re-
duce the size of the search space. The two methods used in this project are max_syntactic_complexity
which is used to prevent ADATE from producing too large programs, and Funs_to_use
which is a list of functions ADATE is allowed to use in synthesized programs.
The number of allowed functions is typically kept as small as possible to limit the
branching necessary to search through improvements. The exact content of the list is
problem speciﬁc. For problems dealing with real numbers, it is practical to include basic
arithmetic operators like addition and division.
4.3.4
ADATE-ML
ADATE-ML is a stripped-down version of Standard ML with many of the redundant
features removed. This simple language makes the ADATE-ML compiler much smaller
and quicker than compilers for most other languages.

4.3. ADATE
25
The set of features left in the language is designed to match with the features used by
ADATE during program synthesis. Having to handle multiple ways of achieving the same
task, such as declaring a variable, would cause an unnecessarily large search space.
Some notable removed features are: if expressions, selectors, boolean operators, vari-
able deceleration using let-statements, and pattern matching in function decelerations as
these can all be achieved using case expressions. Similarly, polymorphic types are also
removed. Let statements is allowed, but can only contain a single function declaration.
The built-in library only contains basic data types like bool, real, and array, in addition
to basic operations on these types.
The features allowed within the f-function is even more scarce. All code within the f-
function has to be purely functional which prevents using mutable operations like updates
on arrays if that changes the behavior of the program. Additionally, real numbers have to
be deﬁned within f using the rconst constructor, but this is omitted in the code listings in
this project as it has no practical eﬀect outside the ADATE search.

Chapter 5
Improving Diﬀerential Evolution
The standard DE has been implemented in many machine learning and numerical opti-
mization libraries such as SciPy1 and LabView2. Since the mutation operator is conﬁg-
urable in these tools, signiﬁcant improvements could quickly be adopted and used by a
larger group of people.
This chapter aims to understand how synthesized versions of DE can be evaluated in
ADATE and which parts should be improved by attempting to enhance the DE/rand/1
mutation operator in the standard DE algorithm.
Two experiments are used. The ﬁrst requires ADATE to ﬁnd an improved mutation
operator using knowledge about the best individual in the population and a few randomly
selected individuals. Following a preliminary evaluation, a second experiment based on
the same framework but with the population variance made available for ADATE was
designed.
This chapter is organized as follows: Section 5.1 provides details on the experiment,
Section 5.2 reports on and compares the performance of the improved mutation operator
with other mutation operators, and Section 5.3 provides a summary of this chapter.
5.1
Experiment
Improving an algorithm using ADATE requires a starting individual that is to be improved,
and a method for comparing the performance of synthesized programs.
Here, this is
provided by isolating the code responsible for generating a trial vector v(t)
i
into an isolated
f-function, as described in Section 5.1.2, and evaluating the performance of a program, as
outlined in Section 5.1.4.
5.1.1
Which part to improve?
The standard DE algorithm has three primary candidates for improvement, speciﬁcally,
the crossover, the selection, and the mutation operator.
As discussed in Section 3.3, the crossover has a large eﬀect on the search and is of
particular importance when optimizing non-separable functions. However, the heuristics
1https://docs.scipy.org/doc/scipy-0.18.1/reference/generated/scipy.optimize.
differential_evolution.html
2http://zone.ni.com/reference/en-XX/help/371361H-01/gmath/global_optimization/
26

5.1. Experiment
27
are encoded in the structure and enumeration of lists, making incremental reﬁnements
diﬃcult.
The selection has been unchanged from the original publication by Storn and Price [7],
to state-of-the-art variants of DE, making it less likely that improvements could signiﬁ-
cantly enhance the performance. Additionally, any improvement would also require larger
structural changes to the code.
The mutation operator has been among the most studied parts of the algorithm with
numerous variations published over the years as discussed in Section 3.2. Additionally, the
number of transformations needed to change one into another would mostly, if ADATE
were provided all the required background knowledge about the population, be just a
matter of changing some variables or adding some terms to a linear equation. All this
makes mutation the best step to improve using ADATE.
The question then becomes which mutation operator to improve.
Except for the
Trigonometric mutation operator [29], all mutation operators discussed in Section 3.2
have a similar structure. The DE/rand/1 operator is chosen because it is likely to be
the most popular. The performance of the operator has also been extensively evaluated,
which provides a measure the implementation can be compared with to ensure correct
implementation[80].
5.1.2
The f-function
The DE/rand/1 operator is described by Equation (3.3), repeated here for convenience:
v(t)
i
= x(t)
R1 + F

x(t)
R2 −x(t)
R3

.
Here v(t)
i
is the mutated donor vector for individual i at time t, and F is a scaling factor
controlling the step size.
The vectors x(t)
R1, x(t)
R2 and x(t)
R3 are three randomly chosen
individuals from the population.
To create the f-function, DE/rand/1 is implemented in ADATE-ML as shown in List-
ing 5.1 with a scaling factor F = 0.28, a value found by using a simple grid search on the
training problems.
Listing 5.1: Original formulation of mutation in DE to be improved by ADATE. For readability,
the rconst wrapper round real numbers are removed.
1
datatype
r e a l _ l i s t = r n i l
|
rcons
of
r e a l
∗
r e a l _ l i s t
2
datatype
r e a l _ l i s t _ l i s t = r l n i l
|
r l c o n s
of
r e a l _ l i s t
∗
r e a l _ l i s t _ l i s t
3
4
fun
f (
Population ,
Best ,
Z1 ,
Z2 ) =
5
let
6
fun build ( Columns ) =
7
case Columns of
8
r l n i l => r n i l
9
|
r l c o n s ( Col ,
RestColumns ) =>
10
rcons (
11
case Col of
12
r n i l => raise NA1
13
|
rcons ( X1,
X1Rest ) =>
14
case X1Rest of
15
r n i l => raise NA2
16
|
rcons ( X2,
X2Rest ) =>
17
case X2Rest of

28
Chapter 5. Improving Diﬀerential Evolution
18
r n i l => raise NA3
19
|
rcons ( X3,
X3Rest ) =>
20
X1 + 0.28 ∗( X2 −X3 )
21
,
build
RestColumns )
22
in
23
build (
Population
)
24
end
The Population argument is of type real_list_list which stores each column as a real_list.
The best individual is stored in the variable Best of type real_list. Z1 and Z2 are random,
real values drawn from a uniform distribution between 0 and 1.
All X values are normalized to the range -0.5 to 0.5 before f is called using the formula:
φ(x) = (x −xmin) ./ (xmax −xmin) −0.5.
(5.1)
Here, ./ denote element-wise division.
Normalization prevents overﬁtting to the search space of the problems used by ADATE.
It can also have a beneﬁcial eﬀect on the ADATE search, because constants introduced as
part of program synthesis are randomly drawn from a distribution that produces constants
from the same range more frequently. Additionally, this range makes it easier to introduce
nonlinearity, using the tanh operator. The normalization itself does not signiﬁcantly aﬀect
the performance of the algorithm.
The return vector from the f-function is similarly
denormalized before used further.
The implementation was veriﬁed by testing it on the CEC 2013 benchmark prob-
lems[81], and comparing the performance against the results published by Qin and Li
[80].
Variance information
For the second experiment, the type of Population was changed to
Listing 5.2: Datatype for population with variance
1
datatype population = popnil
|
popcons of
(
r e a l
∗
r e a l _ l i s t
) ∗population
Here the standard deviation of the column is returned in the ﬁrst argument of popcons,
while the list of all values from the column and the remaining parts of the population is
in the second.
Additionally, the argument Z2 to the f-function was changed to be drawn from a normal
distribution with σ = 1 centered around µ = 0 to make it easier for ADATE to ﬁnd useful
distributions of random numbers.
5.1.3
Allowed functions
The list of allowed functions for this experiment is primarily motivated by what would be
necessary for ADATE to transform any of the mutation operators discussed in Section 3.2
into any of the others, if provided with the necessary information about the population.
The transformation between most of the operators can be accomplished using only +,
−, and ∗on real numbers. To create the Trigonometric operator, ADATE would also need
to use / and compare two real numbers using the < operator. To allow ADATE to create
interesting non-linear calculations, the tanh operator is also included.
To be able to change the structure of the algorithm, ADATE must also be allowed to
use constructors for the algebraic types used within f.

5.1. Experiment
29
5.1.4
Grading synthesized programs
Three options have been considered for grading the synthesized programs produced by
ADATE, namely, designing problems based on practical machine learning models, land-
scape generators and synthetic benchmark functions designed to test optimization algo-
rithms.
Designing problems based on practical machine learning models is attractive because a
large number of problems could be created, and many models such as feedforward neural
networks can be evaluated quickly. However, it would be prohibitively time-consuming
and diﬃcult to ensure that the ﬁtness landscapes are representative of most problems
encountered for general optimization tasks.
Gallagher and Yuan [82] have proposed a landscape generator based on Gaussian mix-
ture models capable of generating an unlimited number of optimization problems of varying
complexity. However, it is unlikely to produce an equal amount of all types of landscapes,
and complicated problems become computationally expensive to calculate compared to
the other options.
Because of the limitations above, synthetic functions designed to test optimization
problems were used to grade synthesized programs.
While only a limited quantity of
these problems exist, they were designed to study optimization, and as a result, it exists
problems for most of the important types of ﬁtness landscapes.
The functions were selected such that the original DE algorithm were unable to solve
the problems within the constraints on the number of generations and parameter conﬁg-
uration. However, it could solve some of the simpler problems with a larger number of
generations, or by using parameters optimized for each problem.
Training
Five problems, listed in Table 5.1, were used for the training set. These were selected to
represent several types of search landscapes and include both the simple Sphere function
(see Figure 5.1a) and the diﬃcult Schwefel function (see Figure 5.1b).
These problems are all of 20 dimensions and optimized using a population size of 20
individuals.
(a) Sphere function
(b) Schwefel function
Figure 5.1: Plots of two functions used for grading synthesized programs when improving DE.

30
Chapter 5. Improving Diﬀerential Evolution
Table 5.1: Problems in the training set used by ADATE. The deﬁnition for each function is available
in Appendix A.
f
Name
tmax
xi ∈
f1
Ackleys Function
200
[−32, 32]
f41
Rastrigin function
200
[−32, 32]
f53
Sphere function
150
[−10, 10]
f22
Griewank
150
[−32, 32]
f46
Schwefel
250
[−500, 500]
Validation
The best performing programs found by ADATE on the training set were validated using
a signiﬁcantly more extensive set of problems. The 45 problems used for validation are
listed in Table 5.2. These include problems of dimensionality 40, 30 and 2 with population
sizes ranging from 30 to 75.
Randomization
Most of the problems have a global minimum at x = 0, something which ADATE would
quickly exploit. Additionally, many of the problems are symmetric around the minimum.
To prevent overﬁtting to functions with these properties, the functions are shifted by a
random amount.
The random shift vector for each problem was calculated as follows:
sj = xmin,j + randj(0, 1)(xmax,j −xmin,j)
(5.2)
The function was then shifted by:
x′′
j = min(max(xj + sj, xmin,j), xmax,j)
(5.3)
To further prevent overﬁtting to the seeds, each program is evaluated using 11 diﬀerent
seeds, each calculating a unique shift. The ﬁnal grade becomes the median of the tries on
each problem.
Ensuring problem equality
All problems used in the speciﬁcation should contribute equally to the grade. However,
a simple summation of the optimization results would cause a subset of the problems to
dominate, because many of the problems have diﬀerent global optima and ranges. This
was solved by measuring how much the performance on the problem has improved.
First, the median of the best ﬁtness values found by the original DE using 11 diﬀerent
seeds, designated here for problem p as ˜fdefault,p, is calculated prior to running ADATE.
The grade for a program is then calculated as the ratio of the achieved error to the median
of the error reached by the original algorithm as follows:
grade =
X
p
tanh
 
fbest,p
˜fdefault,p
!
(5.4)
Here fbest,p is the ﬁtness of the best individual in the population when the search is
terminated. The tanh operator limits how much each problem can impact the grade.

5.1. Experiment
31
Table 5.2: Problems used for validation in ADATE when improving DE. The deﬁnition for each
function is available in Appendix A.
f
Name
Dim
tmax
Np
xi ∈
f1
Ackleys Function
40
400
30
[−32, 32]
f6
Bent cigar
40
500
30
[−100, 100]
f16
Discus Function
40
500
30
[−100, 100]
f22
Griewank
40
400
50
[−32, 32]
f23
HappyCat Function
40
500
30
[−100, 100]
f24
HGBat Function
40
500
30
[−100, 100]
f25
High Conditioned Elliptic
40
500
30
[−100, 100]
f27
Katsuura Function
40
250
30
[−100, 100]
f33
Modiﬁed Schwefel function
40
500
30
[−100, 100]
f37
Powell sum
40
70
30
[−1, 1]
f39
Qing’s Function
40
500
30
[−500, 500]
f41
Rastrigin function
40
400
50
[−32, 32]
f46
Schwefel
40
600
75
[−500, 500]
f47
Schwefel F2.21
40
500
30
[−500, 500]
f53
Sphere function
40
400
30
[−32, 32]
f53
Sphere function
40
500
75
[−10, 10]
f54
Step Function No.02
40
500
30
[−100, 100]
f61
Weierstrass
40
500
30
[−100, 100]
f62
Whitley
40
500
30
[−10.24, 10.24]
f64
Xin-She Yangs Function No.02
40
500
30
[−2π, 2π]
f67
Expanded Griewanks, Rosenbrocks
40
500
30
[−100, 100]
f68
Expanded Scaﬀers F6 Function
40
500
30
[−100, 100]
f1
Ackleys Function
30
500
50
[−32, 32]
f6
Bent cigar
30
500
30
[−100, 100]
f16
Discus Function
30
500
30
[−100, 100]
f22
Griewank
30
500
50
[−32, 32]
f23
HappyCat Function
30
500
30
[−100, 100]
f24
HGBat Function
30
500
30
[−100, 100]
f25
High Conditioned Elliptic
30
500
30
[−100, 100]
f27
Katsuura Function
30
200
20
[−100, 100]
f33
Modiﬁed Schwefel function
30
500
30
[−100, 100]
f37
Powell sum
30
70
30
[−1, 1]
f39
Qing’s Function
30
500
30
[−500, 500]
f41
Rastrigin function
30
500
50
[−32, 32]
f46
Schwefel
30
600
75
[−500, 500]
f47
Schwefel F2.21
30
500
30
[−500, 500]
f53
Sphere function
30
500
50
[−32, 32]
f53
Sphere function
30
500
75
[−10, 10]
f54
Step Function No.02
30
500
30
[−100, 100]
f61
Weierstrass
30
500
20
[−100, 100]
f62
Whitley
30
500
30
[−10.24, 10.24]
f64
Xin-She Yangs Function No.02
30
500
30
[−2π, 2π]
f67
Exp. Griewanks, Rosenbrocks
30
500
30
[−100, 100]
f68
Expanded Scaﬀers F6 Function
30
500
30
[−100, 100]
f10
Bukin’s Function No.06
2
500
30
x1 ∈[−15, −5]
x2 ∈[−3, 3]

32
Chapter 5. Improving Diﬀerential Evolution
5.2
Results
5.2.1
Improved mutation operator
The ﬁrst improved mutation operator found by ADATE, referred to here as DE/ADATE1
can be expressed as:
v(t)
i,j = F

x(t)
R2,i,j −x(t)
R3,i,j

+



x(t)
R3,i,j
if x(t)
R1,i,j < 0.050668748
x(t)
R2,i,j
Otherwise
(5.5)
with F being the diﬀerence between two random numbers drawn from a uniform distribu-
tion between 0 and 1.
Except for adding a condition that switches the base individual if x(t)
R1,i,j < 0.050668748,
the mutation operator is similar to the original. The condition can act as a primitive
measure of the population variance for problems with an optima suﬃciently far from
xj = 0.050668748, because the condition will gradually stabilize to either x(t)
R2,i,j or x(t)
R3,i,j
when the individuals become localized to either side of 0.050668748.
Switching the base individual has the eﬀect of introducing some limited independence
between the components early in the search. The other signiﬁcant modiﬁcation of the
original is replacing the constant F value used in DE/Rand/1 with the diﬀerence between
two uniform random numbers, which results in a triangular distribution centered around
0.
5.2.2
Improved mutation operator with variance
The second improved mutation operator, based on the experiment with the component
standard deviation available, results in the following operator referred to here as DE/A-
DATE2:
v(t)
i,j = x(t)
R2,i,j + tanh

tanh

tanh

randi,j(0, 1) −0.28 −σ(t)
j
 
x(t)
R2,i,j −x(t)
R1,i,j

. (5.6)
Here σ(t)
j
is the standard deviation for component j across all individuals in the population
at time t.
5.2.3
Analysis and performance
The generalizing performance of the algorithm was tested on the CEC 2014 dataset us-
ing 10 and 30 dimensions, and compared against the mutation operators described in
Section 3.2. To achieve optimal performance, the parameters for each mutation operator
were tuned, using the sum of the medians for each function resulting from 51 trials on each
function. The optimal parameters for each mutation operator for problems of dimensions
10 and 30, are listed in Tables 5.3 and 5.4, respectively. The performance of each mutation
operator on all functions is listed in Tables 5.5 to 5.8.
The performance of the mutation operators found by ADATE is worse than most of
the other mutation operators on the majority of the functions. The reason for this can
be seen in Figure 5.2. While the improved mutation operators achieve better results for a
few functions, on most, they quickly start performing worse than the original DE/rand/1
as the available number of function evaluations is increased. This is because the improved
mutation operator has specialized to the low number of generations used in the training
and validation problems.

5.2. Results
33
Table 5.3:
Best performing parameters across all CEC 2014 benchmark functions on 10 di-
mensions, as measured by the sum of the medians.
The parameters were found by testing
Np ∈{20, 40, 45, 50, 55, 60, 80, 100, 150}, Cr ∈{0.1, 0.5, 0.9}, and F ∈{0.5, 0.8}.
Mutation operator
Np
Cr
F
DE/Rand/1
60
0.9
0.8
DE/Best/1
55
0.9
0.8
DE/current-to-best/1
100
0.5
0.5
DE/Rand/2
50
0.9
0.5
DE/Best/2
20
0.9
0.8
DE/Randrl
80
0.9
NA
DE/ADATE1
80
0.5
NA
DE/ADATE2
55
0.5
NA
Table 5.4:
Best performing parameters across all CEC 2014 benchmark functions on 30 di-
mensions, as measured by the sum of the medians.
The parameters were found by testing
Np ∈{20, 40, 45, 50, 55, 60, 80, 100, 150}, Cr ∈{0.1, 0.5, 0.9}, and F ∈{0.5, 0.8}.
Mutation operator
Np
Cr
F
DE/Rand/1
80
0.9
0.5
DE/Best/1
100
0.9
0.5
DE/current-to-best/1
20
0.9
0.8
DE/Rand/2
20
0.9
0.5
DE/Best/2
20
0.9
0.5
DE/Randrl
40
0.9
NA
DE/ADATE1
50
0.9
NA
DE/ADATE2
45
0.9
NA

34
Chapter 5. Improving Diﬀerential Evolution
Table 5.5: Performance of mutation operators on CEC 2014 benchmark functions 1 to 15 with 10 dimensions using the parameters performing best
across all CEC 2014 functions as measured by the sum of all medians.
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
DE/Rand/1
Best
2.77e−3
1.04e−7
1.42e−12
1.47e−8
2.01e1
2.92e−3
8.14e−2
1.81
2.74
1.56e1
8.17e1
1.04e−1
4.63e−2
1.01e−1
8.53e−1
Worst
7.44e−2
8.26e−6
1.01e−10
3.48e1
2.03e1
6.78
6.34e−1
2.78e1
4.33e1
1.58e2
1.04e3
8.56e−1
3.58e−1
2.52e−1
3.77
Median
1.32e−2
5.91e−7
1.27e−11
4.34
2.02e1
9.14e−1
4.60e−1
1.94e1
3.23e1
5.41e1
2.40e2
2.32e−1
2.52e−1
1.88e−1
2.68
Mean
1.69e−2
9.23e−7
1.85e−11
1.37e1
2.02e1
1.29
4.31e−1
1.75e1
2.84e1
6.31e1
2.79e2
2.68e−1
2.36e−1
1.83e−1
2.53
STD
1.31e−2
1.23e−6
1.85e−11
1.65e1
5.30e−2
1.24
1.67e−1
7.01
1.04e1
3.23e1
2.01e2
1.32e−1
6.76e−2
3.53e−2
6.91e−1
DE/Best/1
Best
1.21e−3
3.23e−8
5.12e−13
7.49e−9
2.00e1
4.16e−3
3.81e−2
1.39
1.01
2.76e1
7.97e1
9.15e−2
3.88e−2
9.22e−2
4.78e−1
Worst
2.65e−2
1.20e−6
2.43e−11
3.48e1
2.04e1
4.17
6.18e−1
2.89e1
3.97e1
1.35e2
1.21e3
6.94e−1
3.23e−1
2.66e−1
3.62
Median
8.05e−3
1.71e−7
3.47e−12
4.34
2.02e1
9.07e−1
4.51e−1
1.60e1
2.71e1
6.13e1
2.91e2
2.31e−1
2.29e−1
1.91e−1
2.50
Mean
9.39e−3
2.60e−7
5.27e−12
1.37e1
2.02e1
1.20
3.89e−1
1.53e1
2.32e1
6.31e1
3.50e2
2.51e−1
2.06e−1
1.85e−1
2.41
STD
6.13e−3
2.32e−7
5.19e−12
1.65e1
8.15e−2
1.12
1.84e−1
6.63
1.15e1
2.67e1
2.69e2
1.37e−1
7.34e−2
4.39e−2
8.15e−1
DE/current-to-best/1
Best
9.35
0.00
0.00
8.18e−3
1.02e−4
0.00
2.98e−11
0.00
5.87
9.67e−2
1.86e2
3.63e−1
6.41e−2
6.57e−2
9.13e−1
Worst
1.12e3
0.00
0.00
3.48e1
2.03e1
2.79
1.71e−1
9.95e−1
1.43e1
2.19e2
9.70e2
8.96e−1
1.75e−1
2.93e−1
2.03
Median
5.41e1
0.00
0.00
3.48e1
2.02e1
0.00
3.97e−2
0.00
9.89
3.04e1
6.78e2
6.38e−1
1.21e−1
1.36e−1
1.45
Mean
1.15e2
0.00
0.00
3.04e1
1.90e1
3.09e−1
4.64e−2
3.90e−2
9.90
5.35e1
6.68e2
6.22e−1
1.20e−1
1.41e−1
1.49
STD
1.85e2
0.00
0.00
1.12e1
4.07
5.74e−1
3.74e−2
1.95e−1
2.09
5.25e1
1.71e2
1.35e−1
2.71e−2
5.39e−2
2.61e−1
DE/rand/2
Best
2.75
2.25
2.52e−1
2.88e−1
1.82e−1
5.85e−2
5.39e−1
3.29e2
1.22e2
1.36e2
1.00e2
1.97
3.57e2
1.32e2
4.62e2
Worst
3.52
1.14e2
4.39
1.31
1.10
5.05
1.97e1
3.29e2
1.45e2
2.01e2
1.00e2
4.00e2
4.78e2
2.23e2
5.01e2
Median
3.18
3.10e1
1.89
7.68e−1
6.82e−1
4.35e−1
3.29
3.29e2
1.38e2
2.01e2
1.00e2
3.34
3.69e2
2.22e2
4.63e2
Mean
3.15
4.18e1
1.98
7.72e−1
6.47e−1
5.57e−1
6.58
3.29e2
1.37e2
1.87e2
1.00e2
1.70e2
3.77e2
2.20e2
4.65e2
STD
1.77e−1
3.05e1
9.59e−1
2.52e−1
1.86e−1
7.01e−1
6.35
5.74e−14
4.41
2.54e1
3.15e−2
1.76e2
2.42e1
1.27e1
8.03
DE/best/2
Best
3.61e−1
4.89e−4
2.22e−9
4.80e−6
2.01e1
3.36e−1
4.83e−1
1.93e1
2.76e1
1.19e2
9.57e1
8.41e−2
1.83e−1
9.74e−2
2.03
Worst
7.43e4
1.05e−1
3.54e−6
3.48e1
2.05e1
9.07
8.18e−1
3.99e1
5.47e1
6.59e2
1.44e3
1.11
4.82e−1
3.07e−1
5.10
Median
2.45
1.27e−2
1.89e−7
4.34
2.02e1
3.54
6.77e−1
3.24e1
4.22e1
3.15e2
5.67e2
2.34e−1
3.53e−1
2.33e−1
3.77
Mean
1.46e3
2.05e−2
4.46e−7
1.13e1
2.02e1
4.06
6.83e−1
3.16e1
4.15e1
3.40e2
7.19e2
3.42e−1
3.43e−1
2.32e−1
3.70
STD
1.04e4
2.25e−2
6.69e−7
1.53e1
9.53e−2
2.20
7.68e−2
4.66
6.48
1.30e2
4.35e2
2.44e−1
7.40e−2
4.45e−2
6.88e−1
DE/Randrl
Best
0.00
0.00
0.00
0.00
2.00e1
0.00
2.46e−2
9.83e−5
5.97
4.37e−1
4.02e1
5.53e−3
1.12e−1
6.44e−2
1.32
Worst
1.42e−14
0.00
0.00
3.48e1
2.04e1
3.44
5.06e−1
2.38e1
3.88e1
1.35e2
1.15e3
3.67e−1
2.23e−1
2.15e−1
3.06
Median
0.00
0.00
0.00
3.48e1
2.02e1
8.95e−1
3.41e−1
1.76e1
2.71e1
4.90e1
2.05e2
1.38e−1
1.58e−1
1.37e−1
2.32
Mean
1.67e−15
0.00
0.00
2.43e1
2.02e1
1.12
2.69e−1
1.74e1
2.56e1
5.16e1
3.50e2
1.47e−1
1.62e−1
1.40e−1
2.28
STD
4.62e−15
0.00
0.00
1.57e1
8.43e−2
9.78e−1
1.71e−1
3.97
6.71
2.17e1
3.27e2
8.82e−2
2.85e−2
3.04e−2
3.71e−1
DE/ADATE1
Best
9.64e2
1.28e−2
2.86
1.49e−1
2.01e1
0.00
0.00
0.00
0.00
3.54
2.97e2
3.72e−1
6.91e−2
1.42e−1
9.97e−1
Worst
2.01e6
7.40e3
1.26e3
3.48e1
2.03e1
8.95e−1
3.69e−2
9.95e−1
1.68e1
6.41e1
1.08e3
8.95e−1
2.12e−1
3.71e−1
1.79
Median
2.22e4
4.18e2
1.22e2
3.48e1
2.02e1
0.00
1.14e−13
0.00
1.08e1
3.54e1
7.40e2
6.73e−1
1.32e−1
2.70e−1
1.46
Mean
1.02e5
1.19e3
1.99e2
3.33e1
2.02e1
1.75e−2
6.06e−3
1.17e−1
1.05e1
3.31e1
7.24e2
6.70e−1
1.29e−1
2.70e−1
1.43
STD
2.99e5
1.64e3
2.46e2
6.80
5.50e−2
1.25e−1
9.16e−3
3.24e−1
3.48
1.35e1
1.45e2
1.17e−1
3.11e−2
6.52e−2
1.90e−1
DE/ADATE2
Best
1.33e3
1.42
4.42
9.90e−2
1.80e1
0.00
0.00
0.00
9.95e−1
3.48
8.26
3.96e−1
7.52e−2
1.18e−1
1.04
Worst
4.66e5
7.12e3
3.04e3
3.48e1
2.03e1
2.89e−2
3.45e−2
2.98
1.39e1
1.55e2
8.80e2
1.00
1.86e−1
3.62e−1
2.20
Median
1.98e4
5.02e2
9.35e1
3.48e1
2.02e1
0.00
1.03e−2
9.95e−1
6.03
2.38e1
5.37e2
6.96e−1
1.26e−1
2.12e−1
1.52
Mean
6.96e4
1.12e3
3.00e2
2.73e1
2.01e1
1.18e−3
1.06e−2
7.41e−1
6.44
2.73e1
4.92e2
6.86e−1
1.26e−1
2.20e−1
1.53
STD
1.10e5
1.45e3
4.92e2
1.43e1
4.17e−1
5.67e−3
8.30e−3
7.92e−1
3.62
2.24e1
1.85e2
1.30e−1
2.77e−2
6.06e−2
2.17e−1

5.2. Results
35
Table 5.6: Performance of mutation operators on CEC 2014 benchmark functions 16 to 30 with 10 dimensions using the parameters performing best
across all CEC 2014 functions as measured by the sum of all medians.
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
DE/Rand/1
Best
9.84e−1
2.11e−1
6.63e−2
1.93e−1
6.75e−2
5.36e−2
1.11e−1
3.29e2
1.09e2
1.31e2
1.00e2
1.98
3.69e2
2.22e2
4.62e2
Worst
3.45
9.46e1
3.44
1.55
1.84
8.50e−1
2.33e1
3.29e2
1.48e2
2.01e2
1.00e2
4.00e2
4.97e2
2.27e2
5.13e2
Median
3.01
4.88
7.68e−1
8.70e−1
8.11e−1
3.78e−1
4.71
3.29e2
1.34e2
2.01e2
1.00e2
4.08
3.79e2
2.23e2
4.63e2
Mean
2.79
8.71
9.21e−1
8.77e−1
7.87e−1
3.77e−1
8.04
3.29e2
1.30e2
1.92e2
1.00e2
1.49e2
3.82e2
2.23e2
4.69e2
STD
6.06e−1
1.39e1
7.39e−1
3.38e−1
3.08e−1
2.18e−1
8.92
5.74e−14
1.15e1
2.19e1
4.47e−2
1.85e2
2.14e1
8.18e−1
1.26e1
DE/Best/1
Best
7.17e−1
3.18e−1
4.58e−2
9.63e−2
1.28e−2
3.25e−2
9.55e−2
3.29e2
1.07e2
1.42e2
1.00e2
1.40
3.57e2
1.01e2
4.63e2
Worst
3.54
4.29e1
7.21
1.62
1.07
1.68e1
2.32e1
3.29e2
1.46e2
2.01e2
1.00e2
4.00e2
4.11e2
2.27e2
5.01e2
Median
2.83
5.00
5.16e−1
7.75e−1
7.20e−1
3.40e−1
3.71
3.29e2
1.27e2
2.01e2
1.00e2
4.01
3.79e2
2.23e2
4.63e2
Mean
2.61
7.05
1.03
7.89e−1
6.37e−1
8.28e−1
8.04
3.29e2
1.27e2
1.99e2
1.00e2
1.50e2
3.79e2
2.19e2
4.67e2
STD
6.10e−1
8.69
1.16
3.12e−1
2.62e−1
2.49
9.16
5.74e−14
1.15e1
9.07
6.38e−2
1.68e2
1.14e1
2.11e1
9.94
DE/current-to-best/1
Best
1.53
1.09e1
2.63e−1
8.37e−3
2.02e−3
1.09e−1
3.95e−2
3.29e2
1.01e2
1.06e2
1.00e2
1.15
3.57e2
2.08e2
4.60e2
Worst
2.77
3.62e2
2.71e1
2.50
9.16
1.25e2
3.71e1
3.29e2
1.22e2
2.01e2
1.00e2
4.00e2
4.98e2
1.96e6
8.29e2
Median
2.13
7.76e1
2.14
9.99e−1
4.40e−1
7.32e−1
2.04e1
3.29e2
1.14e2
1.36e2
1.00e2
2.97
4.56e2
2.27e2
4.91e2
Mean
2.15
1.11e2
3.49
8.28e−1
7.91e−1
1.81e1
1.57e1
3.29e2
1.14e2
1.53e2
1.00e2
1.76e2
4.29e2
3.87e4
5.30e2
STD
2.57e−1
7.83e1
4.44
6.09e−1
1.42
3.44e1
9.40
5.74e−14
4.20
3.61e1
2.49e−2
1.94e2
5.34e1
2.75e5
8.20e1
DE/rand/2
Best
7.90e−12
0.00
0.00
0.00
2.01e1
2.75e−6
3.48e−1
1.47e1
1.85e1
1.57e2
1.93e2
1.34e−1
9.51e−2
9.46e−2
1.69
Worst
1.21e−9
0.00
0.00
3.48e1
2.04e1
5.12
6.82e−1
2.85e1
4.09e1
6.69e2
1.47e3
1.32
2.86e−1
2.40e−1
3.18
Median
6.81e−11
0.00
0.00
0.00
2.02e1
8.95e−1
5.25e−1
2.17e1
3.18e1
3.45e2
7.96e2
9.59e−1
1.94e−1
1.62e−1
2.55
Mean
1.36e−10
0.00
0.00
1.10e1
2.02e1
1.21
5.09e−1
2.20e1
3.01e1
3.48e2
8.60e2
9.07e−1
1.92e−1
1.62e−1
2.49
STD
1.94e−10
0.00
0.00
1.56e1
9.16e−2
1.18
7.53e−2
3.23
4.61
1.09e2
3.97e2
2.71e−1
3.98e−2
3.06e−2
4.07e−1
DE/best/2
Best
3.08
1.48e1
4.75
6.93e−1
1.17
7.55e−1
1.10
3.29e2
1.26e2
1.54e2
1.00e2
3.60
3.57e2
2.11e2
4.60e2
Worst
3.71
2.68e2
1.37e1
2.61
8.31
3.54e6
3.84e1
3.29e2
1.62e2
2.02e2
1.00e2
4.46e2
5.16e2
2.05e6
5.92e2
Median
3.37
9.38e1
8.42
1.72
4.42
4.23
2.35e1
3.29e2
1.48e2
2.01e2
1.00e2
3.04e2
3.87e2
2.24e2
4.74e2
Mean
3.38
9.72e1
8.75
1.73
4.40
9.29e4
2.09e1
3.29e2
1.47e2
2.00e2
1.00e2
1.95e2
4.03e2
1.45e5
4.83e2
STD
1.78e−1
6.58e1
2.34
3.34e−1
1.78
5.20e5
1.09e1
5.74e−14
8.50
7.58
4.93e−2
1.87e2
3.83e1
4.56e5
2.47e1
DE/Randrl
Best
1.01
2.27e−13
1.62e−3
1.97e−2
4.13e−5
3.72e−5
8.04e−5
3.29e2
1.09e2
1.12e2
1.00e2
1.15
3.69e2
2.22e2
4.62e2
Worst
3.35
1.20e2
1.34
1.19
6.94e−1
1.12
6.31
3.29e2
1.41e2
2.01e2
1.00e2
4.00e2
3.89e2
3.32e2
4.99e2
Median
2.98
1.41
2.44e−1
5.61e−1
1.78e−2
3.45e−1
3.13e−1
3.29e2
1.32e2
2.01e2
1.00e2
2.54
3.75e2
2.22e2
4.62e2
Mean
2.94
1.04e1
4.10e−1
5.57e−1
1.20e−1
4.52e−1
4.11e−1
3.29e2
1.31e2
1.95e2
1.00e2
1.70e2
3.75e2
2.24e2
4.64e2
STD
3.75e−1
1.91e1
4.28e−1
2.51e−1
1.91e−1
3.29e−1
9.25e−1
5.74e−14
6.66
1.99e1
2.38e−2
1.89e2
5.75
1.55e1
7.27
DE/ADATE1
Best
1.01
6.05e2
3.39e2
1.50e−2
5.24e−1
9.27
2.23e−2
3.29e2
1.01e2
1.30e2
1.00e2
1.00e2
3.69e2
4.52e2
4.90e2
Worst
2.76
8.79e4
1.50e4
1.20
1.37e4
1.98e4
1.22e2
3.29e2
1.25e2
2.01e2
1.00e2
4.01e2
4.93e2
9.99e2
1.05e3
Median
1.83
6.13e3
5.72e3
1.37e−1
1.04e3
1.31e3
4.50e−1
3.29e2
1.15e2
1.91e2
1.00e2
3.09e2
3.78e2
6.62e2
5.40e2
Mean
1.86
1.43e4
6.17e3
3.10e−1
2.35e3
2.91e3
2.81
3.29e2
1.15e2
1.86e2
1.00e2
2.99e2
3.82e2
6.62e2
5.61e2
STD
3.47e−1
2.00e4
3.68e3
3.43e−1
2.85e3
4.07e3
1.70e1
4.13e−9
4.28
1.83e1
2.78e−2
4.65e1
2.52e1
1.16e2
8.29e1
DE/ADATE2
Best
7.40e−1
4.25e2
1.31e1
2.94e−2
2.66
4.38
1.03e−2
3.29e2
1.02e2
1.26e2
1.00e2
1.43e2
3.69e2
3.48e2
5.09e2
Worst
2.66
8.10e4
1.63e4
1.45
8.23e3
1.84e4
1.19e2
3.29e2
1.22e2
2.02e2
1.00e2
3.34e2
5.36e2
1.34e3
1.15e3
Median
1.77
4.97e3
5.73e3
1.43e−1
7.43e2
1.48e3
4.40e−1
3.29e2
1.13e2
1.98e2
1.00e2
3.09e2
3.78e2
5.71e2
6.02e2
Mean
1.73
8.56e3
6.70e3
3.37e−1
1.61e3
3.24e3
5.01
3.29e2
1.13e2
1.84e2
1.00e2
3.04e2
3.94e2
5.88e2
6.47e2
STD
4.99e−1
1.22e4
4.19e3
3.89e−1
2.20e3
4.02e3
1.72e1
5.74e−14
5.33
2.23e1
2.22e−2
3.12e1
4.15e1
1.78e2
1.45e2

36
Chapter 5. Improving Diﬀerential Evolution
Table 5.7: Performance of mutation operators on CEC 2014 benchmark functions 1 to 15 with 30 dimensions using the parameters performing best
across all CEC 2014 functions as measured by the sum of all medians.
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
DE/Rand/1
Best
6.76e3
0.00
0.00
9.21e−2
2.04e1
0.00
0.00
1.37e1
1.55e2
7.16e2
5.73e3
1.16
2.36e−1
2.19e−1
1.34e1
Worst
2.71e5
2.84e−14
5.68e−14
6.34e1
2.10e1
1.12e1
9.86e−3
1.64e2
1.98e2
4.31e3
7.20e3
3.04
4.45e−1
6.98e−1
1.68e1
Median
6.19e4
0.00
0.00
5.38e−1
2.09e1
3.46
0.00
7.10e1
1.78e2
2.11e3
6.74e3
2.41
3.22e−1
2.88e−1
1.50e1
Mean
7.93e4
1.11e−15
1.00e−14
7.92
2.09e1
3.76
3.38e−4
7.08e1
1.77e2
2.19e3
6.64e3
2.38
3.32e−1
3.09e−1
1.51e1
STD
5.51e4
5.57e−15
2.19e−14
2.05e1
8.96e−2
2.69
1.71e−3
3.05e1
1.02e1
8.56e2
3.82e2
3.17e−1
4.68e−2
9.48e−2
8.93e−1
DE/Best/1
Best
3.36e3
0.00
0.00
3.49e−2
2.08e1
1.80e−4
0.00
8.66e1
1.56e2
2.19e3
6.23e3
1.60
2.65e−1
2.03e−1
1.33e1
Worst
2.22e5
2.84e−14
5.68e−14
6.34e1
2.10e1
1.60e1
1.14e−13
1.79e2
1.99e2
5.36e3
7.36e3
3.05
4.84e−1
3.39e−1
1.85e1
Median
5.10e4
0.00
0.00
3.55e−1
2.09e1
5.06
0.00
1.39e2
1.81e2
4.29e3
6.76e3
2.31
3.72e−1
2.81e−1
1.58e1
Mean
6.47e4
6.13e−15
3.34e−15
2.84
2.09e1
5.36
2.23e−15
1.38e2
1.79e2
4.23e3
6.77e3
2.35
3.77e−1
2.80e−1
1.57e1
STD
5.28e4
1.18e−14
1.35e−14
1.24e1
5.46e−2
3.24
1.59e−14
1.95e1
9.89
6.96e2
2.53e2
3.19e−1
4.61e−2
3.22e−2
8.86e−1
DE/current-to-best/1
Best
1.72e2
2.84e−14
2.54e−11
3.65e−5
2.06e1
8.38
2.27e−13
2.89e1
3.38e1
9.39e2
1.89e3
1.57
2.97e−1
2.12e−1
4.40
Worst
1.35e6
2.72e−10
9.75e−2
1.62e2
2.11e1
2.35e1
2.48e−1
1.25e2
1.74e2
5.81e3
7.30e3
2.93
9.49e−1
1.15
3.94e2
Median
1.50e4
1.42e−13
3.26e−6
4.08
2.09e1
1.61e1
1.97e−2
6.50e1
8.56e1
2.14e3
3.58e3
2.46
4.72e−1
3.37e−1
1.17e1
Mean
1.26e5
1.33e−11
2.28e−3
2.78e1
2.09e1
1.63e1
3.35e−2
6.86e1
9.30e1
2.38e3
4.42e3
2.41
5.00e−1
5.27e−1
2.20e1
STD
2.94e5
4.31e−11
1.37e−2
3.61e1
7.73e−2
3.19
4.22e−2
2.06e1
3.16e1
9.85e2
1.96e3
3.23e−1
1.39e−1
2.83e−1
5.40e1
DE/rand/2
Best
1.07e4
2.84e−14
4.06e−4
2.23e−6
2.04e1
2.09
1.14e−13
1.30e2
1.44e2
3.35e3
1.38e3
1.58
2.30e−1
2.32e−1
1.23e1
Worst
2.38e5
1.62e−12
2.39e2
7.77e1
2.10e1
2.27e1
4.18e−2
1.87e2
2.04e2
6.31e3
7.37e3
2.96
4.94e−1
7.24e−1
1.94e1
Median
3.24e4
2.84e−14
2.61
3.82e−1
2.09e1
5.98
3.41e−13
1.57e2
1.85e2
4.87e3
6.81e3
2.47
3.48e−1
3.02e−1
1.53e1
Mean
5.17e4
1.02e−13
2.10e1
5.92
2.09e1
6.98
5.84e−3
1.57e2
1.82e2
4.76e3
6.50e3
2.45
3.51e−1
3.20e−1
1.54e1
STD
4.81e4
2.35e−13
4.63e1
1.85e1
1.11e−1
4.51
9.20e−3
1.31e1
1.36e1
6.42e2
9.76e2
3.10e−1
5.97e−2
9.72e−2
1.34
DE/best/2
Best
1.64e4
2.84e−14
2.44e−4
5.36e−3
2.05e1
8.24e−3
0.00
1.32e2
1.54e2
3.31e3
1.32e3
1.44
1.74e−1
2.36e−1
1.27e1
Worst
3.98e5
2.85e3
8.39e2
7.67e1
2.10e1
1.71e1
9.81e−2
1.85e2
2.00e2
5.97e3
7.29e3
3.16
4.91e−1
7.69e−1
1.77e1
Median
9.61e4
8.53e−13
1.19e1
5.93e−1
2.09e1
6.39
2.27e−13
1.59e2
1.83e2
4.80e3
6.72e3
2.50
3.22e−1
3.14e−1
1.56e1
Mean
1.35e5
7.46e1
7.62e1
1.00e1
2.09e1
7.33
6.85e−3
1.59e2
1.82e2
4.81e3
6.48e3
2.45
3.29e−1
3.47e−1
1.56e1
STD
1.05e5
4.02e2
1.51e2
2.34e1
9.82e−2
4.22
1.51e−2
1.27e1
1.07e1
6.05e2
1.01e3
3.33e−1
5.78e−2
1.23e−1
1.12
DE/Randrl
Best
3.36e3
0.00
5.68e−14
1.34e−4
2.04e1
2.54
0.00
9.95
1.49e1
4.69e2
1.29e3
1.82e−1
1.73e−1
2.11e−1
2.02
Worst
7.16e4
5.68e−14
7.62e−12
6.50e1
2.10e1
1.40e1
3.69e−2
3.78e1
1.89e2
2.09e3
7.20e3
2.73
3.94e−1
7.60e−1
1.64e1
Median
1.77e4
2.84e−14
1.14e−13
9.39e−2
2.08e1
7.03
1.14e−13
2.29e1
2.79e1
9.52e2
3.23e3
1.47
2.82e−1
3.01e−1
1.41e1
Mean
2.22e4
2.79e−14
7.35e−13
7.66
2.08e1
6.98
3.72e−3
2.30e1
4.19e1
1.04e3
4.06e3
1.45
2.85e−1
3.48e−1
1.17e1
STD
1.74e4
1.20e−14
1.68e−12
2.07e1
1.38e−1
2.61
7.61e−3
6.52
4.33e1
3.77e2
1.89e3
8.21e−1
4.83e−2
1.38e−1
4.76
DE/ADATE1
Best
9.33e4
2.15e1
2.64e2
3.46e−2
2.08e1
4.76e−1
1.14e−13
5.97
5.97
1.60e1
5.25e3
1.72
1.14e−1
2.15e−1
1.03e1
Worst
1.08e6
3.18e4
3.38e4
1.36e2
2.10e1
5.50
3.68e−2
2.60e1
1.54e2
3.82e2
6.98e3
3.03
3.00e−1
5.36e−1
1.56e1
Median
3.96e5
1.17e4
7.17e3
2.15
2.09e1
2.62
2.27e−13
1.09e1
1.15e2
1.37e2
6.48e3
2.42
2.15e−1
3.10e−1
1.32e1
Mean
4.30e5
1.30e4
9.32e3
2.92e1
2.09e1
2.70
3.33e−3
1.19e1
8.80e1
1.38e2
6.46e3
2.40
2.12e−1
3.09e−1
1.33e1
STD
2.29e5
9.06e3
8.49e3
4.32e1
4.79e−2
1.31
7.64e−3
4.41
5.68e1
1.08e2
3.21e2
3.21e−1
3.54e−2
5.20e−2
1.05
DE/ADATE2
Best
7.31e4
2.20e3
5.99e2
7.78e−4
2.08e1
4.43
1.14e−13
9.95
1.39e1
3.64
5.90e2
1.71
1.59e−1
1.60e−1
2.00
Worst
7.77e5
2.47e4
2.67e4
1.32e2
2.10e1
1.17e1
4.41e−2
3.78e1
3.78e1
4.85e2
6.86e3
2.91
3.27e−1
3.32e−1
1.70e1
Median
2.34e5
1.03e4
5.75e3
2.33
2.10e1
7.94
3.41e−13
2.29e1
2.39e1
2.44e2
5.89e3
2.53
2.54e−1
2.35e−1
8.46
Mean
2.81e5
1.01e4
7.23e3
2.69e1
2.09e1
8.05
6.89e−3
2.36e1
2.50e1
2.15e2
4.73e3
2.45
2.49e−1
2.42e−1
8.73
STD
1.62e5
4.76e3
5.78e3
3.42e1
4.94e−2
1.71
1.30e−2
6.93
5.97
1.22e2
2.25e3
2.71e−1
3.58e−2
4.38e−2
4.76

5.2. Results
37
Table 5.8: Performance of mutation operators on CEC 2014 benchmark functions 16 to 30 with 30 dimensions using the parameters performing best
across all CEC 2014 functions as measured by the sum of all medians.
16
17
18
19
20
21
22
23
24
25
26
26
28
29
30
DE/Rand/1
Best
1.18e1
2.08e2
6.27
3.06
6.43
2.97
2.23e1
3.15e2
2.00e2
2.03e2
1.00e2
3.00e2
7.13e2
6.68e2
5.06e2
Worst
1.29e1
1.84e3
6.08e1
6.93
3.87e1
9.42e2
3.96e2
3.15e2
2.30e2
2.04e2
1.00e2
5.03e2
9.57e2
1.20e7
5.10e3
Median
1.26e1
1.32e3
5.14e1
4.74
1.03e1
4.52e2
4.49e1
3.15e2
2.24e2
2.03e2
1.00e2
3.37e2
8.25e2
7.28e2
1.12e3
Mean
1.25e1
1.24e3
4.88e1
4.93
1.40e1
3.95e2
8.12e1
3.15e2
2.23e2
2.03e2
1.00e2
3.50e2
8.33e2
6.26e5
1.65e3
STD
2.42e−1
4.00e2
1.12e1
7.71e−1
8.57
2.97e2
8.21e1
1.72e−13
6.10
2.07e−1
5.09e−2
5.96e1
3.97e1
2.54e6
1.10e3
DE/Best/1
Best
1.22e1
8.32e2
3.98e1
4.11
2.75e1
2.22e2
2.51e1
3.15e2
2.00e2
2.03e2
1.00e2
3.00e2
7.73e2
3.31e2
4.49e2
Worst
1.30e1
1.90e3
6.59e1
6.72
4.46e1
9.38e2
1.99e2
3.15e2
2.30e2
2.03e2
1.00e2
5.94e2
8.95e2
8.65e6
3.96e3
Median
1.27e1
1.53e3
5.41e1
4.91
3.74e1
7.06e2
4.52e1
3.15e2
2.22e2
2.03e2
1.00e2
3.51e2
8.22e2
7.15e2
1.10e3
Mean
1.27e1
1.51e3
5.43e1
4.96
3.69e1
6.85e2
6.47e1
3.15e2
2.17e2
2.03e2
1.00e2
3.47e2
8.24e2
1.70e5
1.38e3
STD
1.69e−1
1.85e2
5.22
5.30e−1
4.20
1.70e2
4.99e1
1.72e−13
1.02e1
9.32e−2
4.31e−2
5.51e1
2.28e1
1.21e6
8.17e2
DE/current-to-best/1
Best
1.10e1
8.82e2
6.16e1
5.13
4.00e1
5.43e2
2.21e1
3.15e2
2.26e2
2.03e2
1.00e2
4.01e2
9.12e2
3.97e2
1.29e3
Worst
1.25e1
1.63e4
2.52e4
6.77e1
6.17e3
3.48e4
9.49e2
3.17e2
2.61e2
2.18e2
3.63e2
1.06e3
2.37e3
2.05e7
2.63e4
Median
1.17e1
1.93e3
1.96e2
1.03e1
2.31e2
9.90e2
2.92e2
3.15e2
2.48e2
2.05e2
1.01e2
8.49e2
1.37e3
9.51e2
3.35e3
Mean
1.18e1
2.66e3
1.02e3
1.44e1
8.31e2
2.22e3
3.28e2
3.15e2
2.48e2
2.07e2
1.33e2
8.33e2
1.39e3
4.13e6
4.36e3
STD
3.64e−1
2.83e3
3.73e3
1.54e1
1.46e3
5.66e3
2.21e2
3.51e−1
6.48
3.53
6.66e1
1.61e2
3.48e2
5.96e6
4.20e3
DE/rand/2
Best
1.16e1
9.62e2
5.80
3.53
1.20e1
2.61e2
2.44e1
3.15e2
2.22e2
2.03e2
1.00e2
3.06e2
7.38e2
3.98e2
7.90e2
Worst
1.30e1
1.50e5
5.62e2
7.87e1
5.36e3
2.75e4
5.66e2
3.15e2
2.51e2
2.08e2
3.11e2
7.29e2
1.86e3
1.62e7
8.06e4
Median
1.25e1
8.44e3
9.82e1
6.45
1.27e2
2.26e3
1.51e2
3.15e2
2.28e2
2.04e2
1.00e2
4.66e2
9.38e2
1.19e3
3.46e3
Mean
1.24e1
1.49e4
1.35e2
7.98
4.95e2
4.41e3
1.89e2
3.15e2
2.31e2
2.04e2
1.05e2
4.83e2
1.00e3
3.78e6
5.47e3
STD
3.35e−1
2.52e4
1.23e2
1.02e1
9.46e2
5.80e3
1.69e2
1.72e−13
7.27
1.10
2.94e1
1.01e2
2.07e2
5.13e6
1.18e4
DE/best/2
Best
1.14e1
1.93e3
5.55e1
4.26
1.70e1
2.71e1
2.47e1
3.15e2
2.22e2
2.03e2
1.00e2
3.00e2
7.40e2
7.46e2
5.40e2
Worst
1.31e1
1.31e5
9.73e3
9.25
7.80e3
9.01e4
6.61e2
3.15e2
2.42e2
2.07e2
2.94e2
9.60e2
2.16e3
2.31e7
4.53e4
Median
1.26e1
8.94e3
9.25e1
5.89
2.52e2
2.12e3
7.19e1
3.15e2
2.27e2
2.03e2
1.00e2
4.40e2
9.14e2
1.28e3
2.93e3
Mean
1.25e1
1.75e4
3.23e2
6.16
7.34e2
5.81e3
1.53e2
3.15e2
2.30e2
2.04e2
1.04e2
4.64e2
1.01e3
2.54e6
4.23e3
STD
3.41e−1
2.26e4
1.35e3
1.28
1.33e3
1.29e4
1.64e2
1.72e−13
5.92
8.17e−1
2.72e1
1.04e2
2.72e2
4.83e6
6.31e3
DE/Randrl
Best
1.11e1
1.88e2
4.48
2.23
4.55
9.41
2.23e1
3.15e2
2.23e2
2.03e2
1.00e2
3.70e2
8.10e2
4.78e2
6.28e2
Worst
1.30e1
2.74e4
2.21e2
7.01
1.57e2
7.54e2
6.38e2
3.15e2
2.43e2
2.07e2
3.22e2
7.16e2
1.45e3
1.52e7
4.57e4
Median
1.22e1
9.62e2
2.13e1
4.52
1.10e1
2.65e2
1.97e2
3.15e2
2.37e2
2.03e2
1.00e2
4.49e2
8.91e2
8.01e2
2.67e3
Mean
1.22e1
2.37e3
3.29e1
4.47
1.59e1
2.83e2
2.46e2
3.15e2
2.34e2
2.04e2
1.13e2
4.70e2
9.32e2
2.47e6
3.78e3
STD
3.70e−1
4.52e3
3.66e1
1.14
2.23e1
2.12e2
1.61e2
1.72e−13
6.66
9.10e−1
5.09e1
7.84e1
1.25e2
4.50e6
6.25e3
DE/ADATE1
Best
9.30
1.92e4
8.18
3.18
5.43e2
9.55e3
2.24e1
3.15e2
2.24e2
2.03e2
1.00e2
3.17e2
7.74e2
1.06e3
1.80e3
Worst
1.18e1
6.33e5
2.98e3
7.05e1
1.11e4
5.50e5
4.69e2
3.15e2
2.44e2
2.13e2
2.00e2
5.17e2
9.38e2
2.93e3
5.36e3
Median
1.10e1
1.85e5
3.78e2
5.75
3.70e3
1.11e5
6.84e1
3.15e2
2.39e2
2.07e2
1.00e2
4.03e2
8.71e2
1.53e3
3.89e3
Mean
1.09e1
2.13e5
7.51e2
7.07
4.24e3
1.66e5
1.27e2
3.15e2
2.37e2
2.07e2
1.02e2
4.04e2
8.73e2
1.74e3
3.75e3
STD
5.59e−1
1.37e5
8.38e2
9.12
2.54e3
1.25e5
1.15e2
1.99e−7
5.80
2.38
1.40e1
4.51e1
3.32e1
5.94e2
8.94e2
DE/ADATE2
Best
9.40
1.48e4
3.78e1
3.95
8.12e2
3.36e3
2.71e1
3.15e2
2.24e2
2.06e2
1.00e2
3.95e2
7.99e2
9.76e2
1.60e3
Worst
1.17e1
2.31e5
3.54e3
6.31e1
1.43e4
2.95e5
6.38e2
3.15e2
2.42e2
2.18e2
2.00e2
6.54e2
9.82e2
8.40e6
4.42e3
Median
1.04e1
1.18e5
3.01e2
6.07
3.94e3
1.08e5
1.60e2
3.15e2
2.26e2
2.11e2
1.59e2
5.27e2
8.71e2
1.42e3
3.18e3
Mean
1.04e1
1.24e5
5.71e2
7.61
4.40e3
1.26e5
2.19e2
3.15e2
2.27e2
2.11e2
1.55e2
5.30e2
8.72e2
1.66e5
3.17e3
STD
4.79e−1
5.38e4
7.37e2
8.09
2.69e3
7.33e4
1.16e2
1.72e−13
4.11
2.03
4.49e1
5.21e1
3.46e1
1.18e6
6.04e2

38
Chapter 5. Improving Diﬀerential Evolution
0.01
0.1
1
100,000
10,000,000
1,000,000,000
DE/ADATE1
DE/ADATE2
DE/Rand/1
Figure 5.2: The sum of the medians of all 30-dimensional functions plotted against total function
evaluations used with the best performing conﬁguration for that number of function evaluations.
5.3
Conclusions
This chapter reported on an experiment that tried to improve the original DE algorithm
using ADATE. After considering both the selection and crossover steps. The mutation
operator DE/rand/1 was chosen to be improved because even small modiﬁcations to the
mutation can have a signiﬁcant impact on the search performance. In addition to the
DE/rand/1 being both simple, and its performance having been extensively studied.
The chapter also discussed how synthesized programs should be graded, with three
options explored, namely, optimizing general machine learning models, landscape gener-
ators, and synthetic optimization functions. The latter of which was chosen because of
quick evaluation time and it being easier to represent most types of problems.
While the experiment did not succeed at creating an improved mutation operator as
it became worse than the starting point when the number of generations was increased
for testing. It shows that ADATE is capable of modifying the mutation operator to ﬁnd
improvements on the training and validation problems.
Although the specialization was unintentional in this case, this could be used to create
specialized versions of DE to solve niche problems.

Chapter 6
Improving Competitive
Diﬀerential Evolution
The goal of this chapter is to increase our understanding of how synthesized modiﬁcations
to DE should be evaluated in ADATE by trying to improve the pool of competing strategies
in the CDE variation of DE. The variant of CDE used in the experiment is based on the
recent b3e3pbest pool of mutation strategies[20].
The experiment improves on the methodology developed to improve the standard DE
algorithm in the previous chapter but signiﬁcantly enhances the training and validation
sets by adding more base functions, adding rotation and permutation of components, and
increasing the number of generations for each problem.
This chapter is organized as follows: Section 6.1 describes the CDE algorithm and the
b3e3pbest pool of mutation strategies, Section 6.2 describes the experiment, Section 6.3
reports the results of the experiment, and Section 6.4 concludes this chapter.
6.1
Competitive diﬀerential evolution
CDE is an adaptive variation of DE originally published by Tvrdk [49] in 2006 based on the
competitive mechanics introduced in 2002[83]. The search adapt to the ﬁtness landscape
by using a set of H competing strategies to generate new trial vectors. A strategy is
randomly selected for each individual in each generation, with more successful strategies
being more likely to be chosen.
A strategy h is selected with a probability qh calculated as:
qh =
nh
PH
j=1 nj
.
(6.1)
Here, nj is the number of times strategy h has produced trial vectors that have been
accepted into the population. nh is initialized to a constant value, usually equal to 2,
which can be adjusted to control how quickly qh changes in response to successful uses of
strategies at the beginning of the search or after a reset. To prevent strategies from being
dominated by others, all nh are reset to their initial value whenever qh decreases below a
limit δ =
1
5h for any h.
Multiple improved pools of strategies have been suggested [20], [84]–[87]. Variations
have also been used to solve constraint satisﬁability problems [88]. The pool used in this
article is b3e3pbest, which consists of the strategies listed in Table 6.1.
39

40
Chapter 6. Improving Competitive Diﬀerential Evolution
Table 6.1: Pool of strategies in b3e3pbest with values for problems of 30-dimensions[20].
Mutation operator
Crossover operator
F
CR
DE/current-to-pbest/1
None
0.5
NA
DE/randrl/1
Binomial crossover
0.8
0.0
DE/randrl/1
Binomial crossover
0.8
0.5
DE/randrl/1
Binomial crossover
0.8
1.0
DE/randrl/1
Exponential crossover
0.8
0.8815
DE/randrl/1
Exponential crossover
0.8
0.9488
DE/randrl/1
Exponential crossover
0.8
0.9801
6.1.1
Current-to-pbest/1
The DE/current-to-pbest/1 improves on the DE/current-to-best/1 mutation to reduce
the problem of getting stuck in local optima as discussed in Section 3.2.3. The solution
is to select the guiding individual probabilistically from the 100p% best individuals in the
population:
v(t)
i
= x(t)
i
+ F

x(t)
pbest −x(t)
i

+ F

x(t)
R1 −x(t)
R2

(6.2)
where x(t)
pbest is selected from the 100p% best individuals. x(t)
R1 is selected form the popu-
lation P such that P(R1 ̸= i), and x(t)
R2 selected from the union of the population and the
archive A: P ∪A(R2 ̸= R1 ̸= i).
The parameter p controls how quickly the search should converge to the optimal so-
lution. A large p leads to the search exploring more the of search space, while a small p
causes the population to converge quickly. In this experiment p = 0.05.
6.1.2
Archive
The external archive maintains the diversity in the population by storing individuals that
were replaced by the pairwise competition between the trial vector and the population
individual.
When an individual is discarded from the population, it is inserted into the archive.
The archive is maintained at a maximum size of N(t)
A = a · N(t)
P , a being the archive rate,
by randomly dropping individuals when the size is exceeded.
6.2
Experiment
The experimental methodology used to improve CDE was based on the experiment dis-
cussed in Chapter 5, enhanced to make overﬁtting less likely.
Unlike the previous experiment, in which the values were normalized prior to calling
the f-function and the result denormalized. This experiment has for performance reasons,
changed the algorithm to optimize based on only the range [−0.5, 0.5] with the values
denormalized when calculating the ﬁtness using φ−1, the inverse of Equation (5.1).
6.2.1
The f-function
The f-function was designed to make ADATE able to ﬁnd an optimal pool of mutation
strategies. The starting individual is the pool b3e3pbest [20]. For brevity, some of the less

6.2. Experiment
41
relevant code in the following listing has been replaced with comments.
Listing 6.1: Function to be improved by ADATE, containing heuristics for building mutating an
individual in CDE.
1
fun
f ( Argument
:
fArgument )
:
fResult =
2
case Argument of
3
t o t a l S t r a t e g i e s => s t r a t e g i e s R e s u l t (
nseven
)
4
|
buildDonorVector (
5
Num, Rdim ,
Current ,
Xpbest ,
Var ,
6
Col ,
Colfitness ,
Jadexr1 ,
Jadexr2 ,
Z1 ,
Z2 ) => (
7
Unpack the
f i t n e s s
values F1 , F2 , and F3 from
C o l f i t n e s s =>
8
Unpack the
f i r s t
column
values X1, X2, X3 from Col =>
9
let
10
fun randlr (
Scaling
) =
11
case F1 < F2 of
12
true =>
13
( case F1 < F3 of
14
true => X1 + Scaling ∗( X2−X3 )
15
|
f a l s e => X3 + Scaling ∗( X1−X2 )
)
16
|
f a l s e =>
17
( case F2 < F3 of
18
true => X2 + Scaling ∗( X1−X3 )
19
|
f a l s e => X3 + Scaling ∗( X1−X2 )
)
20
in
21
donorVectorResult (
22
case Num of
23
nzero => (
Current + 0.5
∗( Xpbest −Current
) +
24
0.5
∗(
Jadexr1 −Jadexr2
) ,
noCrossover
)
25
|
none => (
randlr
0.8 ,
binaryCrossover
0.0
)
26
|
ntwo => (
randlr
0.8 ,
binaryCrossover
0.5
)
27
|
nthree => (
randlr
0.8 ,
binaryCrossover
1.0
)
28
|
nfour => (
randlr
0.8 ,
exponentialCrossover
0.8815
)
29
|
n f i v e => (
randlr
0.8 ,
exponentialCrossover
0.9488
)
30
|
nsix => (
randlr
0.8 ,
exponentialCrossover
0.9801
)
31
|
nseven => raise NA8 )
32
end )
The pool representation allows ADATE to change the number of strategies by altering
the number returned when f is called with totalStrategies . The maximum is seven strategies
as limited by the number of numbers deﬁned in the numbers data type:
1
datatype numbers = nzero
|
none
|
ntwo
|
nthree
|
nfour
|
n f i v e
|
2
nsix
|
nseven
A strategy in the pool consists of two parts, namely, a method for calculating the new
donor value and a type of crossover. The donor value is returned in the ﬁrst value in
donorVectorResult, the type of crossover and CR value in the second. The parameters of the
buildDonorVector argument are:
Num: The id of a strategy selected probabilistically with a probability calculated by
Equation (6.1).
Rdim: The number of dimensions of the problem. Included so ADATE can ﬁnd general
improvements involving the dimensionality of the problem.
The value has been
converted to a real number for simpler use in calculations.
Current: The component value of the current individual, deﬁned as xij in the rest of the
thesis.

42
Chapter 6. Improving Competitive Diﬀerential Evolution
Xpbest: The component value of a randomly chosen individual from the 100p% best
individuals.
Var: The standard deviation of the component, calculated based on the entire population.
Col: The component values of the population represented as a real_list. The individu-
als are shuﬄed to replicate the random individual selection used for the mutation
operators.
Colﬁtness The ﬁtness values of the population represented as a real_list. The values are
ordered in the same order as Col.
Jadexr1: The component value of a random individual chosen from the population, but
not equal to Current.
Jadexr2: The component value of a random individual chosen from the population or
the archive, but not equal to either the current individual or the individual which
was selected for Jadexr1.
Z1: A random number between 0 and 1 chosen from a uniform distribution.
Z2: A random number sampled from a normal distribution with µ = 0.5 and σ = 1.
The crossover types available can be one of noCrossover, binaryCrossover or exponentialCrossover
. The latter two taking the CR value as an argument.
The algorithm has been tested against the results published by Bujok, Tvrdk, and
Polakova [20] to ensure similar performance.
6.2.2
Grading synthesized programs
The number of generations and problems have been increased from the previous chapter
to prevent the problem of overﬁtting from reoccurring. To further reduce the risk, all
problems have also been randomly rotated, and the components permuted.
Creating representative problem sets
Most synthetic benchmark functions are created to study how optimization algorithms
behave in speciﬁc situations. This has led to most of the functions having very diﬀerent
characteristics, with the majority of these being simple unimodal functions. All of the
remaining interesting problems that were discovered as part of this thesis work, in addition
to a few simple ones, are described in Appendix A.
The low quantity of multi-modal problems makes creating representative sets of func-
tions diﬃcult. To solve this, the sets of functions, excluding the functions used in CEC
2014, were recursively divided into groups: First into two groups based on whether the
functions were multimodal.
The multimodal functions were then subdivided based on
whether they were designed for narrow niche cases. One example is the group formed by
the problems f63, f64, and f66, shown in Figure 6.1, all of which have the global optimum
located inside a small, diﬃcult to ﬁnd region. The remaining problems were then tested
using all of the mutation operators deﬁned in Section 3.2 and grouped based on the relative
performance of each operator.
The division left some groups underrepresented, causing an unbalanced problem set.
This was solved by including some of the functions initially excluded because they were
used as base functions in CEC 2014.
The problems used by ADATE and the testing
afterward are not identical due to the diﬀerent rotation and shift applied to the functions.
Nevertheless, there could still be some characteristics that the improvements could exploit

6.2. Experiment
43
(a) Xin-She Yang’s Function
No.01
(b) Xin-She Yang’s Function
No.02, this is optimized after
conversion to minimization.
(c) Xin-She Yang’s Function
No.06
Figure 6.1: Some functions forming one niche group when creating a representative problem set.
unfairly. However, any such overﬁtting is easily detectable as improved performance on
those functions, at the cost of degraded performance on others.
Training
The ﬁve problems used for training, all based on the same functions as in Chapter 5 are
listed in Table 6.2, all evaluated using a population size of 50 individuals. The number of
generations for the Sphere problem was left low because the shape of the function remains
constant regardless of how far the search has progressed.
Table 6.2: Problems used for the training ﬁtness function when improving competitive DE in
ADATE, the deﬁnition of each function is available in Appendix A.
f
Name
D
tmax
xi ∈
Shifted
Rotated
f1
Ackley’s Function
20
500
[−32, 32]
Yes
Yes
f41
Rastrigin Function
20
200
[−32, 32]
Yes
Yes
f53
Sphere Function
20
50
[−32, 32]
Yes
Yes
f22
Griewank Function
20
350
[−32, 32]
Yes
Yes
f46
Schwefel Function
20
350
[−500, 500]
Yes
Yes
Validation
The entire list of problems is listed in Tables 6.3, 6.5 and 6.7.

44
Chapter 6. Improving Competitive Diﬀerential Evolution
Table 6.3: Problems used for the validation ﬁtness when improving competitive DE in ADATE,
the deﬁnition of each function is available in Appendix A.
f
Name
D
Np
xi ∈
Shifted
Rotated
f1
Ackley’s Function
40
100
[−32, 32]
Yes
Yes
f41
Rastrigin Function
40
80
[−32, 32]
Yes
Yes
f53
Sphere Function
40
40
[−32, 32]
Yes
Yes
f22
Griewank Function
40
60
[−32, 32]
Yes
Yes
f46
Schwefel Function
40
75
[−500, 500]
Yes
Yes
f37
Powell sum
40
40
[−1, 1]
Yes
Yes
f39
Qing’s Function
40
40
[−100, 100]
Yes
Yes
f54
Step Function No.02
40
40
[−100, 100]
Yes
Yes
f64
Xin-She
Yang’s
Function
No.02
40
100
[−10, 10]
Yes
No
f6
Bent Cigar
40
30
[−100, 100]
Yes
Yes
f61
Weierstrass
40
80
[−100, 100]
Yes
Yes
f33
Modiﬁed Schwefel function
40
30
[−100, 100]
Yes
Yes
f62
Whitley
40
40
[−10.24, 10.24]
Yes
Yes
f47
Schwefel F2.21
40
50
[−500, 500]
Yes
Yes
f48
Schwefel F2.26
40
70
[−500, 500]
Yes
Yes
f3
Alpine Function No.01
40
40
[−10, 10]
Yes
Yes
f4
Alpine Function No.02
40
40
[0, 10]
No
No
f9
Brown Function
40
40
[−1, 4]
Yes
Yes
f11
Cosine Mixture
40
100
[−1, 1]
Yes
Yes
f34
Pathological Function
40
40
[−100, 100]
Yes
No
f40
Quintic Function
40
40
[−10, 10]
Yes
Yes
f43
Salomon’s Function
40
40
[−40, 40]
Yes
Yes
f55
Styblinski-Tang
40
40
[−5, 5]
Yes
Yes
f60
W / Wavy Function
40
40
[−π, π]
Yes
Yes
f49
Shubert Function
40
40
[−10, 10]
Yes
No
f50
Shubert 3 Function
40
40
[−10, 10]
Yes
No
f51
Shubert 4 Function
40
40
[−10, 10]
Yes
No
f15
Deﬂected Corrugated Spring
Function
40
50
[−0, 10]
Yes
Yes
f20
Egg-Holder Function
40
50
[−512, 512]
Yes
Yes
f29
L (or F2) Function
40
50
[−0, 1]
No
No
f30
Lunacek’s bi-Rastrigin Func-
tion
40
40
[−32, 32]
Yes
Yes
f63
Xin-She
Yang’s
Function
No.01
40
60
[−20, 20]
Yes
No
f65
Xin-She
Yang’s
Function
No.03
40
30
[−2π, 2π]
Yes
Yes
f66
Xin-She
Yang’s
Function
No.06
40
100
[−10, 10]
Yes
No
f59
Venter
and
Sobiezcczanski-
Sobieski’s Function
40
30
[−50, 10]
Yes
No
f1
Ackley’s Function
30
60
[−32, 32]
Yes
Yes
f41
Rastrigin Function
30
50
[−32, 32]
Yes
Yes
f53
Sphere Function
30
20
[−32, 32]
Yes
Yes
f22
Griewank Function
30
70
[−32, 32]
Yes
Yes
f46
Schwefel Function
30
75
[−500, 500]
Yes
Yes
f37
Powell sum
30
30
[−1, 1]
Yes
Yes

6.2. Experiment
45
Table 6.5: Problems used for the ﬁtness function when improving competitive DE in ADATE, the
deﬁnition of each function is available in Appendix A.
f
Name
D
Np
xi ∈
Shifted
Rotated
f39
Qing’s Function
30
20
[−100, 100]
Yes
Yes
f54
Step Function No.02
30
20
[−100, 100]
Yes
Yes
f64
Xin-She
Yang’s
Function
No.02
30
70
[−10, 10]
Yes
No
f6
Bent Cigar
30
20
[−100, 100]
Yes
Yes
f61
Weierstrass
30
60
[−100, 100]
Yes
Yes
f33
Modiﬁed Schwefel function
30
30
[−100, 100]
Yes
Yes
f62
Whitley
30
30
[−10.24, 10.24]
Yes
Yes
f47
Schwefel F2.21
30
20
[−500, 500]
Yes
Yes
f48
Schwefel F2.26
30
30
[−500, 500]
Yes
Yes
f3
Alpine Function No.01
30
50
[−10, 10]
Yes
Yes
f4
Alpine Function No.02
30
30
[0, 10]
No
No
f9
Brown Function
30
20
[−1, 4]
Yes
Yes
f11
Cosine Mixture
30
30
[−1, 1]
Yes
Yes
f34
Pathological Function
30
50
[−100, 100]
Yes
No
f40
Quintic Function
30
30
[−10, 10]
Yes
Yes
f43
Salomon’s Function
30
30
[−40, 40]
Yes
Yes
f55
Styblinski-Tang
30
30
[−5, 5]
Yes
Yes
f60
W / Wavy Function
30
30
[−π, π]
Yes
Yes
f49
Shubert Function
30
40
[−10, 10]
Yes
No
f50
Shubert 3 Function
30
50
[−10, 10]
Yes
No
f51
Shubert 4 Function
30
50
[−10, 10]
Yes
No
f15
Deﬂected
Corrugated
Spring Function
30
30
[−0, 10]
Yes
Yes
f20
Egg-Holder Function
30
40
[−512, 512]
Yes
Yes
f29
L (or F2) Function
30
30
[−0, 1]
No
No
f30
Lunacek’s
bi-Rastrigin
Function
30
30
[−32, 32]
Yes
Yes
f63
Xin-She
Yang’s
Function
No.01
30
60
[−20, 20]
Yes
No
f65
Xin-She
Yang’s
Function
No.03
30
40
[−2π, 2π]
Yes
Yes
f66
Xin-She
Yang’s
Function
No.06
30
40
[−10, 10]
Yes
No
f59
Venter and Sobiezcczanski-
Sobieski’s Function
30
40
[−50, 10]
Yes
No
f8
Brad
3
25
−0.25 ≤x1 ≤0.25
0.01 ≤x2, x3 ≤2.5
No
No
f35
Paviani
10
40
[−2.001, 9.999]
No
No
f5
ANNs XOR Function
9
25
[−1, 1]
No
No
f69
Stacked
Bird,
Egg-crate,
Leon, Sawtoothxy
8
30
−2π ≤x1, x2 ≤2π
−5 ≤x3, x4 ≤5
−1.2 ≤x5, x6 ≤1.2
−20 ≤x7, x8 ≤20
No
No

46
Chapter 6. Improving Competitive Diﬀerential Evolution
Table 6.7: Problems used for the ﬁtness function when improving competitive DE in ADATE, the
deﬁnition of each function is available in Appendix A.
f
Name
D
Np
xi ∈
Shifted
Rotated
f70
Stacked
Adjiman,
Cross
in Tray,
Crowned Cross,
Schaﬀer F6
8
30
−5 ≤x1, x2 ≤5
−15 ≤x3, x4 ≤15
−10 ≤x5, x6 ≤10
−100 ≤x7, x8 ≤100
No
No
f71
Stacked
Davis,
Downhill
step, Drop-wave, Siz-Hump
Camel-back
8
30
−100 ≤x1, x2 ≤100
−10 ≤x3, x4 ≤10
−5.1 ≤x5, x6 ≤5.1
−5 ≤x7, x8 ≤5
No
No
f72
Stacked
Giunta,
Hosaki,
Mishra F3, Ursem F3
8
30
−1 ≤x1, x2 ≤1
−10 ≤x3, x4 ≤10
−5 ≤x5, x6 ≤5
−2.0 ≤x7 ≤2.0
−1.5 ≤x8 ≤1.5
No
No
f10
Bukin’s Function No.06
2
25
−15 ≤x1 ≤−5
−3.0 ≤x2 ≤3.0
Yes
Yes
f58
Ursem-Waves Function
2
25
−0.9 ≤x1 ≤−1.2
−1.2 ≤x2 ≤1.2
Yes
Yes
f7
Bird Function
2
30
[−2π, 2π]
Yes
Yes
f19
Egg Crate Function
2
20
[−5, 5]
Yes
Yes
f44
Sawtoothxy Function
2
20
[−20, 20]
Yes
Yes
f18
Drop-wave Function
2
20
[−5.12, 5.12]
Yes
Yes
f14
Davis’ Function
2
30
[−100, 100]
Yes
Yes
f28
Leon’s Function
2
20
[−1.2, 1.2]
Yes
Yes
f17
Downhill Step Function
2
30
[−10, 10]
Yes
No
f45
Schaﬀer’s F6
2
30
[−100, 100]
Yes
No
f21
Giunta’s Function
2
20
[−1, 1]
Yes
Yes
f26
Hosaki’s Function
2
30
[0, 5]
Yes
Yes
f31
Mishra’s Function No.03
2
30
[−10, 10]
Yes
Yes
f57
Ursem Function No.03
2
30
−2.0 ≤x1 ≤−2.0
−1.5 ≤x2 ≤1.5
Yes
Yes
f2
Adjiman’s Function
2
30
[−5, 5]
Yes
Yes
f12
Cross-In-Tray Function
2
30
[−15, 15]
Yes
No
f13
Crowned Cross Function
2
30
[−10, 10]
Yes
No
f52
Six-Hump
Camel-Back
Function
2
30
[−5, 5]
Yes
No
f52
Six-Hump
Camel-Back
Function
2
30
[−5, 5]
No
Yes
f32
Modiﬁed Schaﬀer’s Func-
tion No.01
2
30
[−100, 100]
Yes
No
f36
Peaks function
2
30
[−4, 4]
Yes
Yes
f38
Price’s Function No.02
2
30
[−10, 10]
Yes
Yes
f56
Tsoulo’s Function
2
30
[−1, 1]
Yes
Yes

6.2. Experiment
47
Randomization
The following randomization strategies are used:
Permutation The components are randomly permuted on all problems. This is to pre-
vent the improvements from overﬁtting to dependencies between adjacent compo-
nents, as these are unlikely to be a common occurrence in practical problems.
Shift Like the previous experiment, a random shift s is used but here it is drawn from a
uniform distribution with the range [−0.5, 0.5].
Rotation The ﬁtness landscapes are randomly rotated. The procedure to generate ran-
dom rotation matrices are described in the rest of this section.
For problems with rotation, a random rotation matrix M is calculated using a proce-
dure intended to be the same as used to generate the rotation matrices provided for the
CEC 2014 problems[23]. However, there might be some diﬀerences because the procedure
they use is poorly documented.
Eii = c

ui−min(u)
max(u)−min(u)

(6.3)
P = GramScmidt(A)
(6.4)
Q = GramScmidt(B)
(6.5)
M = PEQ
(6.6)
First Equation (6.3) builds a diagonal matrix of size D × D with c being the condition
number and u being a random vector where each component ui is drawn from a uniform
distribution between 0 and 1.
Then Equations (6.4) and (6.5) builds the two orthogonal matrices P and Q by applying
Gram-Schmidt decomposition on A and B.
A and B are two random matrices with
elements drawn from a normal distribution.
This can cause the global optima to move outside the search bounds. To reduce the
likelihood of this occurring, both the shift vector and rotation matrix is regenerated if any
of the components in Ms is outside the bounds.
The ﬁtness function used by CDE is evaluated as:
f′ = f(min(max(φ−1(M(x −s)), xmin), xmax))
(6.7)
with x being a candidate solution. For problems without rotation, M is equal to the
identity, while for functions without shift s is equal 0.
Ensuring problem equality
The method used in Chapter 5 to ensure problem equality will not work with the set of
problems used in this project, due to several of the problems having negative optima. This
is solved by adding together the sum of the approximate cumulative densities evaluated
at the achieved ﬁtness values. The distribution is assumed to be normal, with the mean
and standard deviation calculated based on 11 independent runs of the original algorithm
prior to running ADATE.

48
Chapter 6. Improving Competitive Diﬀerential Evolution
Preventing overﬁtting
The short evaluation time required for ADATE make ensuring statistically accurate val-
idation diﬃcult. This problem was reduced by evaluating all problems twice using two
independent tests. Each with three maximum number of generations:
tmax = m · D
Np
for m ∈{2000, 3000, 4000}
(6.8)
The three increments of the number of function evaluations are intended promote solving
the problem quickly and to reduce the total evaluation time.
The ﬁnal grade for a program then becomes:
grade =
X
i
X
tmax
2
X
k=1
Fi(pi,k(tmax))
(6.9)
Here, Fi(·) is the approximate cumulative density function for problem i, and pi,k(·) is the
ﬁtness achieved when testing problem i at try k.
6.3
Results
The improved pool of strategies found by ADATE not only achieves better results but is
also signiﬁcantly smaller than the original. The new pool uses just four strategies, down
from the original seven. The entire function encapsulating the improved pool is shown in
Listing 6.2.
Listing 6.2: Function containing the entire strategies pool which has been improved by ADATE.
1
fun
f
Argument =
2
case Argument of
3
t o t a l S t r a t e g i e s => s t r a t e g i e s R e s u l t (
nfour
)
4
|
buildDonorVector ( Num, Rdim ,
Current ,
Xpbest ,
Var ,
5
Col ,
Colfitness ,
Jadexr1 ,
Jadexr2 ,
Z1 ,
Z2 ) => (
6
Unpack the
f i r s t
f i t n e s s e s
F1 , and F2 from
C o l f i t n e s s =>
7
Unpack the
f i r s t
column
values X1, X2, X3 from Col =>
8
let
9
fun g
Scaling =
10
case F1 < F2 of
11
f a l s e =>
12
X2 + Scaling
∗tanh (
(
( X1 −X3 ) /
Scaling
) ∗Z1 )
13
|
true =>
14
X3 + tanh (
Scaling
) ∗
Scaling
∗(
Jadexr1 −Jadexr2
)
15
in
16
donorVectorResult (
17
case Num of
18
nzero => (
19
Current + tanh (
tanh ( Var )
) ∗(
Current −Current
) +
20
tanh ( X3 ) ∗tanh (
tanh (
Jadexr1 −Z1 )
) ,
21
binaryCrossover F2 )
22
|
none => ( g
0.8 ,
binaryCrossover (
tanh (
tanh
0.0
)
)
)
23
|
ntwo => ( g (
tanh (
tanh
0.8
)
) ,
binaryCrossover
0.5
)
24
|
nthree => ( g
0.8 ,
binaryCrossover
1.0
)
25
|
nfour => raise NA_42649
26
|
n f i v e => raise NA_4264A
27
|
nsix => raise NA_4264B

6.3. Results
49
28
|
nseven => raise NA8
29
)
30
end
Due to limited available computation resources, ADATE was halted after having used
only a small amount of the time required to ﬁnd an optimal solution. This is clear from
the code, which includes superﬂuous operations that could be eliminated entirely, such as:
tanh(tanh(V ar)) ∗(Current −Current).
Terms like this would be removed if ADATE was given enough time and discovered no
better programs in the meantime.
6.3.1
Analysis of strategy 1
The ﬁrst strategy consists of binary crossover with CR = F2, F2 being the ﬁtness value of
a random individual not equal to X3. The binary crossover implementation would result
in a single component being taken from the donor for any CR ≤0 and all components
taken from the donor for any CR ≥1. The majority of problems used to grade synthesized
programs have an optimal value on or around 0. On these problems, this causes a gradual
reduction in the number of components taken from the donor as the value gets closer to
the optima. On the remaining problems either all or none of the components gets taken.
The mutation, here simpliﬁed using algebraic rules:
v(t)
i
= x(t)
i
+ tanh

x(t)
R1

∗tanh

tanh

x(t)
j2 −rand(0, 1)

(6.10)
with v(t)
i
being the current individual, x(t)
R1 being a random individual from the population,
and x(t)
j2 , a random individual from either the population or the archive, not equal to the
current individual. The rand(0, 1) function produces a random number between 0 and 1
drawn from a uniform distribution.
This mutation is essentially a random walk. The lack of guidance by known good
solutions and the step sizes not being scaled to more than a single individual, prevents
this from being a good strategy. This assertion is backed up by the success rate of 0.2%
as discussed in Section 6.3.3.
6.3.2
Analysis of strategies 2-4
Strategies 2-4 have unchanged crossover rates, but the helper function used to build the
donor have changed dramatically:
v(t)
i
=







x(t)
R2 + F tanh
 
x(t)
R1−x(t)
R3
F
· rand(0, 1)
!
if f

x(t)
R1

< f

x(t)
R2

,
x(t)
R3 + (tanh F) · F ·

x(t)
j1 −x(t)
j2

otherwise.
.
(6.11)
Here x(t)
j1 is a random individual from the population, not equal to the current individual.
The condition f

x(t)
R1

< f

x(t)
R2

will be true with an approximate likelihood 50% for
most of the search due to x(t)
R1 and x(t)
R2 being randomly chosen individuals from the
population.

50
Chapter 6. Improving Competitive Diﬀerential Evolution
6.3.3
Overall pool behavior
Analyzing the behavior of the original entire pool of strategies reveal a problem causing
the competition within the original pool to be dysfunctional, with only two strategies
dominating the search as shown in Figure 6.2a. This has become worse in the improved
pool found by ADATE, with only a single strategy dominating the search, as shown in
Figure 6.2b.
1
2
3
4
5
6
7
0
20
40
44.4
33.27
1.9 4.9 7.4 4.3 3.7
% of successfull
(a) Original
1
2
3
4
0
50
0.2
81.1
8.7
10
% of successfull
(b) Improved
Figure 6.2: Percentage of successful usages of each strategy
The problem lies in how CDE measures the successfulness of a given strategy. The
success is measured by how often a strategy produces a trial vector that is successfully
accepted into the population. That is f

v(t)
i

≤f

x(t)
i

. This does not consider how
much each strategy contributes to advancing the search. Fewer applications of strategies
that mutate multiple components can sometimes advance the search much further than
several applications which only mutate a single component. Additionally, as discussed
in Section 3.3, higher crossover rates are needed for eﬃcient navigation of non-separable
problems. The high success rate of the current-to-pbest mutation which mutates all com-
ponents in the original pool is explained by being good on simple landscapes.
6.3.4
Performance
The improved pool achieves better overall performance on CEC 2014 benchmark problems.
As shown in Table 6.9, the improvements become larger as the number of dimensions
increase. Tables 6.10 to 6.12 list the performance of the improved pool of strategies on
all CEC 2014 problems. However, when compared to other algorithms in Table 7.7, the
improved performance does not reach state-of-the-art levels.
Table 6.9: Comparison of the ADATE improved pool against the original b3e3pbest algorithm
using the Wilcoxon Rank-sum test with α = 0.05.
Vs. b3e3pbest
D = 10
D = 30
D = 50
ADATE Improvement
+ (win)
- (lose)
= (equal)
11
10
9
19
3
8
22
5
3

6.3. Results
51
Table 6.10: Pool of strategies improved by ADATE on CEC problems with 10 dimensions using a
population size of 100 individuals.
Func
Best
Worst
Median
Mean
Std
F1
5.4696E-05
2.2654E-03
3.5649E-04
4.8450E-04
4.4884E-04
F2
0.0000E+00
0.0000E+00
0.0000E+00
0.0000E+00
0.0000E+00
F3
0.0000E+00
0.0000E+00
0.0000E+00
0.0000E+00
0.0000E+00
F4
0.0000E+00
3.4780E+01
4.3354E+00
1.1847E+01
1.5751E+01
F5
9.3596E+00
2.0094E+01
2.0063E+01
1.9061E+01
2.8613E+00
F6
0.0000E+00
1.4040E-02
5.3758E-05
6.2355E-04
2.1537E-03
F7
0.0000E+00
3.3026E-02
9.5955E-03
1.1793E-02
9.8811E-03
F8
0.0000E+00
0.0000E+00
0.0000E+00
0.0000E+00
0.0000E+00
F9
2.9306E+00
7.6370E+00
5.2078E+00
5.0403E+00
1.1907E+00
F10
0.0000E+00
6.2454E-02
0.0000E+00
1.2246E-03
8.7454E-03
F11
5.2976E+01
4.5079E+02
2.2517E+02
2.3051E+02
9.7292E+01
F12
1.4912E-01
4.8205E-01
3.4187E-01
3.4109E-01
6.4149E-02
F13
1.7522E-02
1.8850E-01
1.1001E-01
1.0897E-01
3.6759E-02
F14
4.9414E-02
2.1458E-01
1.0528E-01
1.0874E-01
3.7128E-02
F15
5.1233E-01
1.1954E+00
9.0702E-01
8.8359E-01
1.4935E-01
F16
1.2421E+00
2.5521E+00
2.0773E+00
2.0599E+00
2.6026E-01
F17
8.2666E+00
5.7592E+01
2.8522E+01
2.9204E+01
1.1307E+01
F18
6.0205E-01
4.2049E+00
2.1041E+00
2.1802E+00
8.0480E-01
F19
1.3947E-01
5.7271E-01
3.2118E-01
3.3254E-01
1.0803E-01
F20
2.2045E-01
1.4308E+00
5.7551E-01
6.3176E-01
2.4470E-01
F21
4.7850E-01
7.2632E+00
1.2290E+00
1.7237E+00
1.3773E+00
F22
7.9396E-02
2.1552E+00
2.3381E-01
3.2955E-01
3.3120E-01
F23
3.2946E+02
3.2946E+02
3.2946E+02
3.2946E+02
5.7409E-14
F24
1.0660E+02
1.1709E+02
1.1225E+02
1.1226E+02
2.5002E+00
F25
1.0637E+02
2.0113E+02
1.1929E+02
1.2464E+02
2.1849E+01
F26
1.0003E+02
1.0021E+02
1.0012E+02
1.0011E+02
4.1151E-02
F27
1.0262E+00
4.0013E+02
2.4165E+00
6.2691E+01
1.4217E+02
F28
3.5683E+02
4.6960E+02
3.6885E+02
3.6905E+02
2.5302E+01
F29
2.2172E+02
2.2402E+02
2.2321E+02
2.2279E+02
7.4268E-01
F30
4.6262E+02
5.0234E+02
4.6336E+02
4.6436E+02
5.4876E+00
Table 6.11: Pool of strategies improved by ADATE on CEC problems with 30 dimensions using a
population size of 100 individuals.
Func
Best
Worst
Median
Mean
Std
F1
5.0317E+02
7.2613E+04
8.5433E+03
1.4410E+04
1.4771E+04
F2
0.0000E+00
0.0000E+00
0.0000E+00
0.0000E+00
0.0000E+00
F3
0.0000E+00
0.0000E+00
0.0000E+00
0.0000E+00
0.0000E+00
F4
2.1684E-04
6.3401E+01
8.9741E-02
5.1102E+00
1.7175E+01
F5
2.0072E+01
2.0327E+01
2.0179E+01
2.0188E+01
6.4490E-02
F6
1.1291E-01
9.8681E+00
4.5187E+00
4.3890E+00
2.3607E+00
F7
0.0000E+00
0.0000E+00
0.0000E+00
0.0000E+00
0.0000E+00
F8
0.0000E+00
0.0000E+00
0.0000E+00
0.0000E+00
0.0000E+00
F9
2.2884E+01
5.1738E+01
3.5819E+01
3.7031E+01
6.8352E+00
F10
0.0000E+00
2.0819E-02
0.0000E+00
3.6740E-03
8.0157E-03
F11
9.4417E+02
2.3223E+03
1.5183E+03
1.5670E+03
2.9717E+02
F12
4.0787E-02
4.0791E-01
1.1748E-01
1.3748E-01
8.2653E-02
F13
1.1468E-01
3.9443E-01
2.8567E-01
2.8633E-01
5.4848E-02
F14
1.5117E-01
3.2053E-01
2.3124E-01
2.3373E-01
3.3940E-02
F15
1.8028E+00
5.0029E+00
3.0754E+00
3.1926E+00
7.3421E-01
F16
7.9047E+00
1.0116E+01
9.1998E+00
9.1417E+00
5.2749E-01
F17
1.4195E+02
1.1486E+03
5.1228E+02
5.6325E+02
2.2624E+02
F18
5.3315E+00
2.8751E+01
1.4937E+01
1.5526E+01
5.4755E+00
F19
2.4983E+00
5.6160E+00
3.8421E+00
3.9857E+00
7.0479E-01
F20
6.1416E+00
2.0652E+01
1.2167E+01
1.2426E+01
3.4082E+00
F21
1.9035E+01
4.9231E+02
2.2288E+02
2.2046E+02
1.3281E+02
F22
1.7649E+01
2.9045E+02
7.0048E+01
1.0269E+02
7.6626E+01
F23
3.1524E+02
3.1524E+02
3.1524E+02
3.1524E+02
1.7223E-13
F24
2.0000E+02
2.0000E+02
2.0000E+02
2.0000E+02
3.7114E-04
F25
2.0252E+02
2.0309E+02
2.0264E+02
2.0267E+02
1.2577E-01
F26
1.0011E+02
1.0043E+02
1.0026E+02
1.0026E+02
6.4711E-02
F27
3.0082E+02
4.2139E+02
4.0048E+02
3.9210E+02
2.7760E+01
F28
6.9284E+02
8.7483E+02
8.1692E+02
8.1720E+02
2.9518E+01
F29
7.1459E+02
7.1971E+02
7.1495E+02
7.1559E+02
1.4515E+00
F30
4.5879E+02
1.9827E+03
1.0465E+03
1.0107E+03
2.7610E+02

52
Chapter 6. Improving Competitive Diﬀerential Evolution
Table 6.12: Pool of strategies improved by ADATE on CEC problems with 50 dimensions using a
population size of 100 individuals.
Func
Best
Worst
Median
Mean
Std
F1
1.1112E+05
6.7324E+05
3.5718E+05
3.6326E+05
1.3658E+05
F2
9.3242E-05
9.0213E+01
1.2428E-01
5.4416E+00
1.4213E+01
F3
0.0000E+00
1.2485E-08
0.0000E+00
2.4480E-10
1.7482E-09
F4
1.5047E+01
9.8397E+01
8.1331E+01
6.5334E+01
3.6063E+01
F5
2.0035E+01
2.0471E+01
2.0250E+01
2.0260E+01
1.0638E-01
F6
5.1413E+00
1.8720E+01
1.1437E+01
1.1723E+01
2.9645E+00
F7
0.0000E+00
0.0000E+00
0.0000E+00
0.0000E+00
0.0000E+00
F8
0.0000E+00
0.0000E+00
0.0000E+00
0.0000E+00
0.0000E+00
F9
6.0692E+01
1.1939E+02
8.9546E+01
9.1420E+01
1.3484E+01
F10
0.0000E+00
3.7475E-02
0.0000E+00
6.8582E-03
8.7669E-03
F11
1.8534E+03
4.5201E+03
3.5626E+03
3.5947E+03
5.1575E+02
F12
5.0120E-02
2.6643E-01
9.6178E-02
1.0405E-01
4.0576E-02
F13
2.6101E-01
5.1516E-01
3.8596E-01
3.8232E-01
4.5233E-02
F14
2.1350E-01
4.2842E-01
2.6560E-01
2.7166E-01
3.8296E-02
F15
4.2369E+00
9.5943E+00
6.2551E+00
6.5050E+00
1.1505E+00
F16
1.4721E+01
1.7862E+01
1.6937E+01
1.6823E+01
6.3577E-01
F17
1.8206E+03
5.5795E+04
7.5755E+03
9.1466E+03
8.2865E+03
F18
1.4741E+01
3.4406E+02
4.5328E+01
6.1804E+01
5.7996E+01
F19
6.8867E+00
1.3223E+01
1.0191E+01
1.0175E+01
1.2561E+00
F20
1.2698E+01
7.2005E+01
3.4216E+01
3.6165E+01
1.1400E+01
F21
3.5506E+02
3.5222E+03
9.6156E+02
1.0467E+03
5.0374E+02
F22
1.8522E+02
9.1722E+02
5.2482E+02
5.4229E+02
1.7010E+02
F23
3.4400E+02
3.4400E+02
3.4400E+02
3.4400E+02
1.1482E-13
F24
2.5300E+02
2.6713E+02
2.5629E+02
2.5802E+02
4.1979E+00
F25
2.0492E+02
2.0815E+02
2.0563E+02
2.0581E+02
6.7366E-01
F26
1.0024E+02
1.0057E+02
1.0035E+02
1.0036E+02
5.9304E-02
F27
4.0371E+02
8.2578E+02
6.2915E+02
6.3480E+02
8.9349E+01
F28
1.0705E+03
1.2782E+03
1.1859E+03
1.1833E+03
5.0225E+01
F29
7.9634E+02
1.0283E+03
8.1163E+02
8.3581E+02
5.0445E+01
F30
7.8389E+03
8.7959E+03
8.0282E+03
8.1115E+03
2.3933E+02
6.4
Conclusions
This chapter built on experiences from Chapter 5, and attempted to improve the pool of
mutation strategies in CDE, using the b3e3pbest pool as an initial individual.
To prevent overﬁtting, the programs were evaluated using a larger set of validation
problems and ensured the problem sets represented most types of function landscapes,
while minimizing overlap with the test problems by recursively grouping the problems.
The problem sets were also diversiﬁed by creating a diﬀerent rotation and permutation
for each repetition of a base problem.
Because many of the new problems have ranges that can return both negative and
positive values, a new method for ensuring problem equality, by using the approximate
cumulative density function of the original performance, was introduced.
The improved pool outperformed the original pool, but falls short of achieving state-of-
the-art performance on the CEC 2014 set of benchmark functions. A potential reason for
this could be a problem with the mechanics governing the competition among strategies.
By not considering strategies that contribute considerably to the search as competitive
against strategies with a low success rate but higher overall contribution is prevented from
being competitive.

Chapter 7
Improving LSHADE-EpSin
Diﬀerential Evolution
This chapter builds on the knowledge gained in the previous two chapters to improve the
mutation operator and scale factor calculation heuristics in the state-of-the-art LSHADE-
EpSin optimization algorithm[89].
The experiment further enhances the statistical certainty of the evaluations of syn-
thesized programs by increasing the allowed number of ﬁtness function evaluations, and
the number of repetitions each program is tested on the problems. While these changes
increase the total computation time required for each program, some of this is oﬀset by
reducing the dimensionality of the problems.
The chapter is structured as follows: Section 7.1 describes the LSHADE-EpSin algo-
rithm, Section 7.2 describes the experiment, Section 7.3 discusses the results, and Sec-
tion 7.4 concludes this chapter.
7.1
LSHADE-EpSin
LSHADE-EpSin is a variation of DE proposed by Awad, Ali, Suganthan, et al. [21] which
won the CEC 2016 competition. The LSHADE-EpSin algorithm uses two sinusoidal func-
tions to calculate the scaling factor F for the ﬁrst half of the search and producing new
individuals by performing an independent random walk search towards the end. Addi-
tionally, it includes adaptation mechanics introduced in [89], and Linear population size
reduction from [36].
This section describes the LSHADE-EpSin algorithm as implemented in this project.
There are diﬀerences between the published description of the algorithm and their imple-
mentation. Here, the description follows the implementation as submitted to CEC 2016.
The overall algorithm is outlined in Algorithm 6, with new functionality described in the
following subsections. The parameter values are listed in Table 7.1.
7.1.1
First half of search: Sinusoidal ensemble
In the ﬁrst half of the search, as determined by the number of function evaluations, fes <
fesmax
2
, at the start of the generation, the scaling factor F (t)
i
is calculated by randomly
using one of two sinusoidal functions. The ﬁrst is a decreasing, non-adaptive function
53

54
Chapter 7. Improving LSHADE-EpSin Diﬀerential Evolution
Algorithm 6 The LSHADE-EpSin algorithm.
P (1) ←{x(1)
i
, x(1)
i
, . . . , x(1)
Np}
▷see Section 3.1 for details.
t ←1
fes ←Np
Initialize memories M(t)
CR, M(t)
F
and M(t)
freq to 0.5.
▷see Section 7.1.2 for details.
while Termination criteria not met do
SCR ←∅, SF ←∅, Sfreq ←∅
progression ←
fes
fexmax
for i ←1, Np do
r = rand(1, H)
if progression < 0.5 then
if rand(0, 1) < 0.5 then
Calculate F (t)
i
using Equation (7.1).
else
freq(t)
i
←randc(M(t)
freq,r, 0.1)
Calculate F (t)
i
using Equation (7.2).
end if
else
F (t)
i
= randc(M(t)
F,r, 0.1)
end if
if M(t)
CR,r =⊥then
CR(t)
i
= 0
else
CR(t)
i
= randn(M(t)
CR,r, 0.1)
end if
v(t)
i
←mutate(x(t)
i )
▷see Section 6.1.1 for details.
u(t)
i
←binaryCrossover(x(t)
i , v(t)
i )
▷see Section 3.3 for details.
fes ←fes + 1
if f(u(t)
i ) < f(x(t)
i ) then
Insert u(t)
i
into P (t+1)
else
Insert x(t)
i
into P (t+1)
end if
end for
Reduce population size
▷See Section 7.1.3 for details
Update MCR,r, MF,r, and Mfreq,r.
▷see Section 7.1.2 for details
if Np < 20 for the ﬁrst time then
Execute local search as described in Section 7.1.3
end if
t ←t + 1
end while

7.1. LSHADE-EpSin
55
Parameter
Value
freq
0.5
H
5
Np,min
4
Np,max = Np,init
18 · D
NL
10
p ( In Section 6.1.1 )
0.11
a
1.14
Table 7.1: Parameters used in the LSHADE-EpSin algorithm.
deﬁned as:
F (t)
i
= 1
2

sin(2π · freq · t1 + π)tmax −t1
tmax
+ 1

.
(7.1)
Here freq is the frequency of the function.
The second function is an adaptive, increasing function deﬁned as:
F (t)
i
= 1
2

sin(2π · freq(t)
i
· t1) t1
tmax
+ 1

.
(7.2)
Here freq(t)
i
is calculated as described in Section 7.1.2.
7.1.2
Adaptation
The adaptation uses three historical memories MCR, Mfreq and MF , all initially set to
contain H entries of 0.5. For the ﬁrst half of the search, the frequency and crossover rates
are randomly sampled:
freq(t)
i
= randc(M(t)
freq,r, 0.1)
(7.3)
CR(t)
i
=



0
if M(t)
CR,r = ⊥
randn(M(t)
CR,r, 0.1)
otherwise
(7.4)
with r ∈[1, H] being a randomly selected integer, and randc(x, γ) is the Cauchy distribu-
tion with location x and γ scale. The value ⊥is a terminal value, which will remain in
the memory slot for the rest of the search. This value forces the algorithm to only mutate
one component at a time when accessing that particular memory slot.
In the last part of the search, instead of calculating the scaling factor F (t)
i
using the
sinusoidal ensemble, it is calculated using Cauchy distribution:
F (t)
i
= randc(M(t)
F,r, 0.1)
(7.5)
For each generation, successful values of freq(t)
i , CR(t)
i
and F (t)
i
are recorded in Sfreq,
SCR and SF respectively. For the ﬁrst half of the search, all three values are recorded,
while updating Sfreq becomes redundant for the second half.
At the end of the generation, the contents of MCR and MF are updated as follows:
M(t)
CR,k,t+1 =







meanWL(SCR)
if SCR ̸= ∅∧max(SCR) ̸= 0
⊥
if SCR ̸= ∅
MCR,k,t
otherwise
(7.6)

56
Chapter 7. Improving LSHADE-EpSin Diﬀerential Evolution
M(t)
F,k,t+1 =
(
meanWL(SF )
if SF ̸= ∅
MF,k,t
otherwise
(7.7)
Mfreq,k,t+1 =
(
meanWL(Sfreq)
if Sfreq ̸= ∅
Mfreq,k,t
otherwise
(7.8)
with k being an integer initially set to 1, and incremented for each generation. If k > H,
k is to 1. The function meanWL is the weighted Lehmer mean deﬁned as:
meanWL(S) =
P|S|
l=1 wl · S2
l
P|S|
l=1 wl · Sl
(7.9)
wl =
∆fl
P|S|
j=1 ∆fj
(7.10)
∆fl =
f(u(t)
l
−x(t)
l )

(7.11)
7.1.3
Population size reduction
The population size is gradually reduced using the techniques introduced by Tanabe and
Fukunaga [36]. At each generation, a new population size is calculated using the linear
equation:
N(t+1)
P
= round
NP,min −NP,max
fesmax

· fes(t) + NP,init

.
(7.12)
Here, NP,max and NP,min are the maximum and minimum population sizes, NP,init is the
initial population size, and fesmax is the maximum allowed function evaluations. When
N(t+1)
P
< N(t)
P , the N(t)
P −N(t+1)
P
worst individuals are dropped from the population. The
archive is simultaneously resized to maintain a maximum size of NA = a·Nt+1 by randomly
dropping surplus individuals.
0
1,000
2,000
3,000
0
200
400
Generations
Population size
Figure 7.1: The population size calculated by Equation (7.12) with Nmax = 540, Nmin = 4 and
fesmax = 300000.
Equation (7.12) causes the population size to be reduced following an exponential
decay curve as shown in Figure 7.1.

7.2. Experiment
57
Local search
When the population size is reduced to 20 individuals, LSHADE-EpSin uses a local search
to introduce new individuals. The local search starts with a population of NL individuals
initialized randomly using the same procedure as initializing DE. For 250 generations, the
following random walks are performed to produce the next generation yi:
yi,j = randn(xbest,j, σ) + (randn(0, 1) · xbest,j −randn(0, 1) · xi,j),
(7.13)
σ =

log(t)
t
(xi,j −xbest,j)
 .
(7.14)
Here, xbest,j is the j’th component of the best individual in the local search population.
When the local search ﬁnishes, 10 random individuals in the population are replaced
with individuals from the local search population if they are better.
7.2
Experiment
This experiment builds on the previous chapter. Therefore, only diﬀerences between the
previous and this experiment are discussed to reduce redundancy.
7.2.1
The f-function
The parts of the code to be improved by ADATE were extracted into an f-function, deﬁned
to include almost all contributions of the LSHADE-EpSin algorithm. The only novelty
proposed by Awad, Ali, Suganthan, et al. [21], that was not included is the local search
algorithm.
Listing 7.1: Function to be improved by ADATE, containing heuristics mutating an individual in
LSHADE-EpSin.
1
fun
f ( Argument
:
fArgument )
:
fResult =
2
case Argument of
3
buildDonorVector ( FValueArg ,
Current ,
Xpbest ,
Col ,
4
Colfitness ,
Jadexr1 ,
Jadexr2 ,
Z1 ) => (
5
donorVectorResult (
Current + FValueArg ∗
6
( Xpbest −Current + Jadexr1 −Jadexr2
)
)
)
7
|
fValueArg ( UsedFes , Mem1, Mem2, G, Gmax,
Z3 ,
Z4 ) => (
8
case
r e a l L e s s ( UsedFes ,
tor (
rconst (
0 ,
0.1 ,
0.5
)
)
)
of
9
true => (
10
case (
11
case
r e a l L e s s ( Z3 ,
tor (
rconst (
0 ,
0.1 ,
0.5
)
)
)
of
12
true =>
13
tor (
rconst (
0 ,
0.1 ,
0.5
)
) ∗(
14
sin (
15
tor (
rconst (
0 ,
0.1 ,
3.14159265359
)
) ∗G +
16
tor (
rconst (
0 ,
0.1 ,
3.14159265359
)
)
) ∗
17
(
( Gmax −G ) / Gmax ) + tor (
rconst (
0 ,
0.1 ,
1.0
)
)
)
18
|
f a l s e =>
19
tor (
rconst (
0 ,
0.1 ,
0.5
)
) ∗(
20
sin (
6.28318530718 ∗Mem1 ∗G ) ∗
21
( G / Gmax ) + tor (
rconst (
0 ,
0.1 ,
1.0
)
)
)
)
22
of FValue => fValueResult ( memory( Mem1 ) , memory( FValue ) , FValue )
)
23
|
f a l s e =>
24
fValueResult ( noMemory , memory( Mem2 ) , Mem2 )
)

58
Chapter 7. Improving LSHADE-EpSin Diﬀerential Evolution
The f-function consists of two parts. The current-to-pbest mutation operator, which
calculate a component in the donor vector when f is called with an argument of type
buildDonorVector, and the second which is triggered when f called with fValueArg, that en-
capsulate the logic for calculating F for the entire search.
The buildDonorVector argument consists of the following parameters:
FValueArg is a value calculated in the second part of f.
Z1 is a random number sampled from a normal distribution with µ = 0.5 and σ = 1.
The remaining parameters Current, Xpbest, Jadexr1, Jadexr2 have identical descriptions as
those in Section 6.2.1.
The second part is designed to give ADATE great ﬂexibility to change the way F is
calculated, and to also change, to some degree, when information is recorded into the
memory. The parameters of fValueArg are:
UsedFes encapsulate the information used to switch between the sinusoidal ensemble and
direct calculation of F. However, to reduce the problem of ADATE overﬁtting to
the number of function evaluations present in the training and validation problems.
UsedFes is calculated as the ratio:
UsedFes =
fes
fesmax
(7.15)
Mem1 contains randc(Mmem1, 0.1).
Mem2 contains randc(Mmem2, 0.1).
G is equal to t.
Gmax is the total number of generations in the current search.
Z3 is a random number drawn from a uniform distribution between 0 and 1.
Z4 is a random number sampled from a normal distribution with µ = 0.5 and σ = 1.
The return value is of type fValueResult, which allows ADATE to pass the F value as
the last parameter. The ﬁrst two control which information is entered into the success
sets for a generation when a trial vector is accepted into the population.
Note on G and Gmax
The arguments G and Gmax are left unnormalized. This has the undesirable consequence
of making it harder for ADATE to use these values because the range is far outside the
range of values introduced as part of program synthesis. Additionally, the information
they contain has a substantial overlap with UsedFes.
In this attempt at improving LSHADE-EpSin, the algorithm had to be reproduced
exactly. While removing these arguments is desirable, several diﬃculties are preventing
the removal without altering the algorithm:
• The halfway point in the search, as deﬁned by the number of consumed function
evaluations and by the number of generations, does not occur at the same point.

7.2. Experiment
59
• The maximum number of generations can change depending on the start and end
population sizes and the function evaluation budget. This makes it diﬃcult to ﬁnd
a replacement for the frequency that is invariant in terms of these parameters.
Future work should, however, aim to remove both of these arguments at the cost of a
less accurate reproduction.
7.2.2
Grading synthesized programs
The set of problems used to grade synthesized programs was altered to produce more
statistically signiﬁcant results.
The dimensionality of many of the problems has been
reduced, with the saved computation time being used to increase the number of repetitions
of each problem while keeping the total evaluation time unchanged. For this experiment,
additional computer resources have been made available; these resources have been used
to further increase the number of seeds each problem is tested on.
The grade is the sum of all the cumulative densities when testing the problems using
one or more maximum number of function evaluations:
grade =
X
i
X
fesmax
r
X
Fi(pi(fesmax)).
(7.16)
Here, r is the number of times each problem is repeated, Fi(·) is the cumulative density
function for problem i, while pi(·) tests the problem with an allowed budget of function
evaluations fesmax.
Training
For training, candidate programs are evaluated using the 20 problems listed in Table 7.2
using fesmax = 9000 · D function evaluations.
Validation
The entire list of problems used for validation are similar to the once used when improving
CDE which is listed in Tables 6.3, 6.5 and 6.7. The diﬀerences are:
• Problems based on f6 are removed.
• Problems with 40 dimensions are reduced to 25 dimensions.
• Problems with 30 dimensions reduced to 15 dimensions.
The computation time saved by reducing the dimensionality of the problems are used
to repeat the problems eight times for each of:
fesmax ∈{6000 · D, 8000 · D, 10000 · D}
(7.17)
to increase the statistical signiﬁcance of the results.
Rejecting poor programs
When the f-function returns a memory( Mem ) with Mem < 0.3, the program is immediately
rejected. This is because LSHADE-EpSin requires the freq and F values to be resampled
when less than 0. Recording values less than −0.3 could therefore cause the resampling
to occur prohibitively often, with the worst case being an inﬁnite loop.

60
Chapter 7. Improving LSHADE-EpSin Diﬀerential Evolution
Table 7.2: Problems used for training in ADATE when improving LSHADE-EpSin.
f
Name
xi ∈
Shifted
Rotated
f1
Ackley’s Function
[−32, 32]
Yes
Yes
f41
Rastrigin Function
[−32, 32]
Yes
Yes
f53
Sphere Function
[−32, 32]
Yes
Yes
f22
Griewank Function
[−32, 32]
Yes
Yes
f46
Schwefel Function
[−500, 500]
Yes
Yes
f37
Powell sum
[−1, 1]
Yes
Yes
f39
Qing’s Function
[−100, 100]
Yes
Yes
f54
Step Function No.02
[−100, 100]
Yes
Yes
f64
Xin-She Yang’s Function No.02
[−10, 10]
Yes
No
f61
Weierstrass
[−100, 100]
Yes
Yes
f33
Modiﬁed Schwefel function
[−100, 100]
Yes
Yes
f62
Whitley
[−10.24, 10.24]
Yes
Yes
f47
Schwefel F2.21
[−500, 500]
Yes
Yes
f48
Schwefel F2.26
[−500, 500]
Yes
Yes
f3
Alpine Function No.01
[−10, 10]
Yes
Yes
f4
Alpine Function No.02
[0, 10]
No
No
f9
Brown Function
[−1, 4]
Yes
Yes
f11
Cosine Mixture
[−1, 1]
Yes
Yes
f34
Pathological Function
[−100, 100]
Yes
No
f40
Quintic Function
[−10, 10]
Yes
Yes
7.3
Results
In the improvement found by ADATE is shown in the following listing.
Listing 7.2: The improved heuristics for mutating an individual in LSHADE-EpSin.
1
fun
f
Argument =
2
case Argument of
3
buildDonorVector (
4
FValueArg ,
Current ,
Xpbest ,
Jadexr1 ,
Jadexr2 ,
Z1 ) =>
5
donorVectorResult (
6
Current + FValueArg ∗( Xpbest −Current + Jadexr1 −Jadexr2
)
7
|
fValueArg ( UsedFes , Mem1, Mem2, G, Gmax,
Z3 ,
Z4 ) =>
8
case
9
r e a l L e s s ( UsedFes ,
tanh (
tanh (
0.5
)
)
)
of
10
f a l s e => fValueResult ( memory( UsedFes ) , memory( Mem2 ) , Mem2 )
11
|
true =>
12
fValueResult ( memory( Mem1 ) , memory( Z3 ) ,
13
0.5
∗(
sin ( Gmax ∗UsedFes ∗UsedFes ) ∗( Mem1 / G ) + 1.0
)
14
)
15
)
7.3.1
Performance
When testing the algorithm on the CEC 2014 benchmark, it is undecidable whether the
algorithm is better on problems of 10 and 50 dimensions. However, the algorithm performs
statistically better when tested using the Wilcoxon rank sum test with α = 0.05 based
on 51 independent trials on problems with 30 dimensions as shown in Table 7.3. The
performance of the algorithm on CEC 2014 benchmark problems is shown in Tables 7.4
to 7.6.
The performance is compared against several other algorithms on CEC 2014

7.3. Results
61
problems with 30 dimensions in Table 7.7.
Table 7.3: Comparison of the ADATE improved LSHADE-EpSin algorithm against the original
using the Wilcoxon Rank-sum test with α = 0.05.
Vs. SHADE-EPsin
D = 10
D = 30
D = 50
ADATE Improvement
+ (win)
- (lose)
= (equal)
1
1
28
2
0
28
1
1
28
Table 7.4: Improved LSHADE-EpSin tested on CEC 2014 problems with 10 dimensions.
Func
Best
Worst
Median
Mean
Std
F1
0.0000E+00
0.0000E+00
0.0000E+00
0.0000E+00
0.0000E+00
F2
0.0000E+00
0.0000E+00
0.0000E+00
0.0000E+00
0.0000E+00
F3
0.0000E+00
0.0000E+00
0.0000E+00
0.0000E+00
0.0000E+00
F4
0.0000E+00
3.4780E+01
3.4780E+01
3.2734E+01
8.2650E+00
F5
3.3427E-02
2.0016E+01
1.9950E+01
1.1539E+01
9.2096E+00
F6
0.0000E+00
0.0000E+00
0.0000E+00
0.0000E+00
0.0000E+00
F7
0.0000E+00
1.7241E-02
0.0000E+00
3.3858E-04
2.4142E-03
F8
0.0000E+00
0.0000E+00
0.0000E+00
0.0000E+00
0.0000E+00
F9
1.5938E-03
2.9871E+00
1.9906E+00
1.7390E+00
6.5443E-01
F10
0.0000E+00
6.2454E-02
0.0000E+00
4.8984E-03
1.6958E-02
F11
3.5908E+00
1.2945E+02
1.7137E+01
2.7137E+01
3.1238E+01
F12
3.7850E-02
1.1647E-01
7.1112E-02
7.1771E-02
1.9624E-02
F13
1.5134E-02
7.2289E-02
4.5394E-02
4.7651E-02
1.1497E-02
F14
3.0313E-02
2.1606E-01
7.2055E-02
8.3259E-02
4.4479E-02
F15
2.5579E-01
5.9523E-01
4.0268E-01
3.9892E-01
6.5969E-02
F16
2.8986E-01
1.6706E+00
9.1551E-01
9.5962E-01
3.1770E-01
F17
0.0000E+00
1.5745E+02
1.1381E+01
2.9910E+01
4.5017E+01
F18
4.3855E-03
4.9996E-01
1.8705E-01
2.0181E-01
1.7340E-01
F19
7.0618E-04
1.0093E+00
4.9035E-02
1.7852E-01
3.1600E-01
F20
6.8061E-05
6.0600E-01
1.4414E-01
2.6193E-01
2.1770E-01
F21
2.5895E-04
1.7568E+01
3.9467E-01
1.7892E+00
4.5529E+00
F22
3.5258E-02
2.0150E+01
8.0447E-02
5.2551E-01
2.8054E+00
F23
2.0000E+02
2.0000E+02
2.0000E+02
2.0000E+02
0.0000E+00
F24
1.0000E+02
1.0941E+02
1.0705E+02
1.0633E+02
2.5740E+00
F25
1.0001E+02
2.0000E+02
1.2255E+02
1.3594E+02
3.5210E+01
F26
1.0001E+02
1.0007E+02
1.0005E+02
1.0005E+02
1.5450E-02
F27
4.1513E-01
2.0000E+02
1.1452E+00
4.0101E+01
7.9755E+01
F28
2.0000E+02
2.0000E+02
2.0000E+02
2.0000E+02
0.0000E+00
F29
1.6104E+02
2.0000E+02
2.0000E+02
1.9924E+02
5.4561E+00
F30
2.0000E+02
5.0608E+02
2.0000E+02
2.4870E+02
1.0655E+02
7.3.2
Analysis
The sinusoidal ensemble has been replaced with a single, modiﬁed sine wave that is only
used in the ﬁrst 43.1% of the search. Additionally, the value of Mem2 has been changed
to be set to a uniform random value for the ﬁrst half of the search which gets used in the
last half of the search.
Written in terms of the mathematical notation used in most of the thesis, the sine
wave becomes:
F (t)
i
= 1
2

sin

tmax
 
fes(t)
fesmax
!2
· Mem1(t)
i
tmax
+ 1


(7.18)
Recognizing that M(t)
1,r ∈[0, 1], the contribution of the sine wave becomes negligible, re-
sulting in F (t)
i
≈0.5.
The F5 problem is particularly interesting as neither the improved or original LSHADE-
EpSin algorithm are capable of solving the problem. Looking at Figures 7.2a and 7.2b,
both the improved and original algorithm produce F-values with a mean of ¯F ≈0.5.
However, the enhancement starts to produce larger F-values earlier than the original.

62
Chapter 7. Improving LSHADE-EpSin Diﬀerential Evolution
Table 7.5: Improved LSHADE-EpSin tested on CEC 2014 problems with 30 dimensions.
Func
Best
Worst
Median
Mean
Std
F1
0.0000E+00
0.0000E+00
0.0000E+00
0.0000E+00
0.0000E+00
F2
0.0000E+00
0.0000E+00
0.0000E+00
0.0000E+00
0.0000E+00
F3
0.0000E+00
0.0000E+00
0.0000E+00
0.0000E+00
0.0000E+00
F4
0.0000E+00
0.0000E+00
0.0000E+00
0.0000E+00
0.0000E+00
F5
2.0000E+01
2.0161E+01
2.0113E+01
2.0111E+01
2.4071E-02
F6
0.0000E+00
0.0000E+00
0.0000E+00
0.0000E+00
0.0000E+00
F7
0.0000E+00
0.0000E+00
0.0000E+00
0.0000E+00
0.0000E+00
F8
0.0000E+00
0.0000E+00
0.0000E+00
0.0000E+00
0.0000E+00
F9
7.1375E+00
1.9268E+01
1.4047E+01
1.3254E+01
2.4461E+00
F10
0.0000E+00
2.0819E-02
0.0000E+00
2.8575E-03
7.2355E-03
F11
5.1441E+02
1.5304E+03
1.1593E+03
1.1391E+03
1.9046E+02
F12
1.1662E-01
2.2506E-01
1.5904E-01
1.5959E-01
2.1099E-02
F13
1.1040E-01
1.6147E-01
1.3535E-01
1.3716E-01
1.3763E-02
F14
1.2196E-01
2.5218E-01
1.9491E-01
1.9639E-01
2.6400E-02
F15
1.8199E+00
2.8275E+00
2.3092E+00
2.3092E+00
2.3164E-01
F16
7.2095E+00
9.0607E+00
8.2675E+00
8.2198E+00
3.7834E-01
F17
2.0246E+01
4.2683E+02
1.6840E+02
1.6897E+02
9.6394E+01
F18
1.4426E+00
1.4406E+01
5.4072E+00
5.9756E+00
2.6348E+00
F19
9.0399E-01
4.5579E+00
2.7921E+00
2.8425E+00
7.7167E-01
F20
7.5101E-01
5.0629E+00
1.8125E+00
2.1794E+00
1.1657E+00
F21
1.9220E+00
2.5679E+02
4.3427E+01
8.0823E+01
7.4664E+01
F22
9.2745E+00
1.4406E+02
2.4693E+01
5.3963E+01
5.0682E+01
F23
2.0000E+02
2.0000E+02
2.0000E+02
2.0000E+02
0.0000E+00
F24
2.0000E+02
2.0000E+02
2.0000E+02
2.0000E+02
0.0000E+00
F25
2.0000E+02
2.0000E+02
2.0000E+02
2.0000E+02
0.0000E+00
F26
1.0009E+02
1.0017E+02
1.0013E+02
1.0013E+02
1.7020E-02
F27
2.0000E+02
3.0000E+02
2.0000E+02
2.0392E+02
1.9604E+01
F28
2.0000E+02
2.0000E+02
2.0000E+02
2.0000E+02
0.0000E+00
F29
2.0000E+02
2.0000E+02
2.0000E+02
2.0000E+02
0.0000E+00
F30
2.0000E+02
2.0000E+02
2.0000E+02
2.0000E+02
0.0000E+00
The plots also reveal a potential reason for both algorithms being unable to solve this
problem. The CR value drops to 0, early in the search. LSHADE-EpSin locks the memory
slot value to ⊥for the remainder of the search when the only CR value that produced
an individual that was successfully admitted to the population, is CR = 0. Locking this
early might limit how much the search can explore the search space.
7.4
Conclusions
In this chapter, we improved the mutation operator and scaling factor calculation for the
state of the art LSHADE-EpSin algorithm using ADATE. The improvement results in a
statistically signiﬁcant performance gain on problems with 30 dimensions, but there is no
clear winner on problems with either 10 or 50 dimensions. In the improved algorithm,
most of the sinusoidal ensemble has been removed, and the ensemble is used in a shorter
period at the start of the search. Upon analyzing the improvement, it was also discovered
that there was a potential problem with the base LSHADE-EpSin algorithm that could
limit its performance by preventing the mutation of multiple components for most of the
search.

7.4. Conclusions
63
Table 7.6: Improved LSHADE-EpSin tested on CEC 2014 problems with 50 dimensions.
Func
Best
Worst
Median
Mean
Std
F1
0.0000E+00
9.6799E-01
4.9655E-07
2.0916E-02
1.3546E-01
F2
0.0000E+00
0.0000E+00
0.0000E+00
0.0000E+00
0.0000E+00
F3
0.0000E+00
0.0000E+00
0.0000E+00
0.0000E+00
0.0000E+00
F4
2.0140E-01
9.8397E+01
5.9480E+00
4.8551E+01
4.8059E+01
F5
2.0170E+01
2.0310E+01
2.0260E+01
2.0257E+01
2.8293E-02
F6
7.0600E-06
3.8942E-03
3.7207E-04
6.9790E-04
8.6616E-04
F7
0.0000E+00
0.0000E+00
0.0000E+00
0.0000E+00
0.0000E+00
F8
0.0000E+00
8.4812E-08
0.0000E+00
2.1479E-09
1.2304E-08
F9
1.4184E+01
3.8396E+01
2.8759E+01
2.6720E+01
6.8397E+00
F10
3.5576E-03
1.0466E-01
4.3865E-02
5.0707E-02
2.5202E-02
F11
2.0648E+03
3.8193E+03
3.1482E+03
3.1375E+03
3.3743E+02
F12
1.6326E-01
2.6375E-01
2.0800E-01
2.0912E-01
2.5792E-02
F13
1.6483E-01
2.4341E-01
2.0247E-01
2.0386E-01
1.9419E-02
F14
1.5753E-01
2.5489E-01
1.9745E-01
2.0166E-01
2.2025E-02
F15
4.4209E+00
6.4147E+00
5.2438E+00
5.2860E+00
4.8745E-01
F16
1.5452E+01
1.7363E+01
1.6614E+01
1.6539E+01
4.5610E-01
F17
7.1674E+01
9.2081E+02
3.6121E+02
4.0135E+02
1.8502E+02
F18
7.2045E+00
3.5022E+01
1.7275E+01
1.7824E+01
6.3183E+00
F19
6.2804E+00
1.1088E+01
9.9849E+00
9.6713E+00
1.2034E+00
F20
2.4676E+00
1.2438E+01
6.1333E+00
6.5289E+00
2.1145E+00
F21
1.3623E+02
6.1989E+02
3.6324E+02
3.3213E+02
1.0375E+02
F22
2.7048E+01
2.7101E+02
6.2018E+01
1.0332E+02
7.0862E+01
F23
2.0000E+02
2.0000E+02
2.0000E+02
2.0000E+02
0.0000E+00
F24
2.0000E+02
2.0000E+02
2.0000E+02
2.0000E+02
0.0000E+00
F25
2.0000E+02
2.0000E+02
2.0000E+02
2.0000E+02
0.0000E+00
F26
1.0015E+02
1.0025E+02
1.0019E+02
1.0019E+02
1.8512E-02
F27
2.0000E+02
3.4725E+02
2.0000E+02
2.0485E+02
2.4693E+01
F28
2.0000E+02
2.0000E+02
2.0000E+02
2.0000E+02
0.0000E+00
F29
2.0000E+02
2.0000E+02
2.0000E+02
2.0000E+02
0.0000E+00
F30
2.0000E+02
2.0000E+02
2.0000E+02
2.0000E+02
0.0000E+00
0
500
1,000
1,500
2,000
2,500
0
0.5
1
Generations
F5 mean
F5 successful mean
F5 CR mean
F5 CR successful mean
(a) The mean of all and the only the successful F and CR plotted for each generation in the
improved LSHADE-EpSin algorithm.
0
500
1,000
1,500
2,000
2,500
0
0.5
1
Generations
F5 mean
F5 successful mean
F5 CR mean
F5 CR successful mean
(b) The mean of all and the only the successful F and CR plotted for each generation in the original
LSHADE-EpSin algorithm.
Figure 7.2: Plots of the means of F, CR, and for each generation for the improved and original
algorithm.

64
Chapter 7. Improving LSHADE-EpSin Diﬀerential Evolution
Table 7.7: Comparison of improved LSHADE-EpSin and improved CDE against the original algo-
rithms. The values are the mean and standard deviation when the algorithms are tested 51 times
on the CEC 2014 functions with 30 dimensions.
Func
Improved
LSHADE-EpSin
Improved CDE
LSHADE-EpSin
b3e3pbest
F1
0.0000E+00
( 0.0000E+00 )
1.4410E+04
( 1.4771E+04 )
0.0000E+00
( 0.0000E+00 )
9.4315E+03
( 5.9990E+03 )
F2
0.0000E+00
( 0.0000E+00 )
0.0000E+00
( 0.0000E+00 )
0.0000E+00
( 0.0000E+00 )
0.0000E+00
( 0.0000E+00 )
F3
0.0000E+00
( 0.0000E+00 )
0.0000E+00
( 0.0000E+00 )
0.0000E+00
( 0.0000E+00 )
0.0000E+00
( 0.0000E+00 )
F4
0.0000E+00
( 0.0000E+00 )
5.1102E+00
( 1.7175E+01 )
1.5583E-08
( 9.1000E-08 )
1.2432E+00
( 8.8779E+00 )
F5
2.0111E+01
( 2.4071E-02 )
2.0188E+01
( 6.4490E-02 )
2.0119E+01
( 2.0934E-02 )
2.0320E+01
( 2.8623E-02 )
F6
0.0000E+00
( 0.0000E+00 )
4.3890E+00
( 2.3607E+00 )
2.7688E-07
( 1.9773E-06 )
1.4052E+01
( 2.3233E+00 )
F7
0.0000E+00
( 0.0000E+00 )
0.0000E+00
( 0.0000E+00 )
0.0000E+00
( 0.0000E+00 )
2.9474E-03
( 4.8538E-03 )
F8
0.0000E+00
( 0.0000E+00 )
0.0000E+00
( 0.0000E+00 )
0.0000E+00
( 0.0000E+00 )
0.0000E+00
( 0.0000E+00 )
F9
1.3254E+01
( 2.4461E+00 )
3.7031E+01
( 6.8352E+00 )
1.3369E+01
( 2.0754E+00 )
4.6986E+01
( 7.1214E+00 )
F10
2.8575E-03
( 7.2355E-03 )
3.6740E-03
( 8.0157E-03 )
2.0411E-03
( 6.2526E-03 )
4.0822E-04
( 2.9153E-03 )
F11
1.1391E+03
( 1.9046E+02 )
1.5670E+03
( 2.9717E+02 )
1.1829E+03
( 1.6755E+02 )
2.4720E+03
( 2.4943E+02 )
F12
1.5959E-01
( 2.1099E-02 )
1.3748E-01
( 8.2653E-02 )
1.5979E-01
( 2.2386E-02 )
4.4352E-01
( 5.2421E-02 )
F13
1.3716E-01
( 1.3763E-02 )
2.8633E-01
( 5.4848E-02 )
1.3421E-01
( 1.8166E-02 )
2.8380E-01
( 4.7173E-02 )
F14
1.9639E-01
( 2.6400E-02 )
2.3373E-01
( 3.3940E-02 )
1.9783E-01
( 2.2480E-02 )
2.4253E-01
( 4.1479E-02 )
F15
2.3092E+00
( 2.3164E-01 )
3.1926E+00
( 7.3421E-01 )
2.2957E+00
( 3.2137E-01 )
5.6874E+00
( 5.5490E-01 )
F16
8.2198E+00
( 3.7834E-01 )
9.1417E+00
( 5.2749E-01 )
8.1764E+00
( 4.7404E-01 )
9.9306E+00
( 3.2950E-01 )
F17
1.6897E+02
( 9.6394E+01 )
5.6325E+02
( 2.2624E+02 )
1.4111E+02
( 8.4712E+01 )
1.1022E+03
( 4.7227E+02 )
F18
5.9756E+00
( 2.6348E+00 )
1.5526E+01
( 5.4755E+00 )
6.3116E+00
( 2.7455E+00 )
6.0158E+01
( 4.3118E+01 )
F19
2.8425E+00
( 7.7167E-01 )
3.9857E+00
( 7.0479E-01 )
2.7111E+00
( 6.1065E-01 )
4.9758E+00
( 1.0238E+00 )
F20
2.1794E+00
( 1.1657E+00 )
1.2426E+01
( 3.4082E+00 )
2.3591E+00
( 1.0403E+00 )
1.5227E+01
( 5.0255E+00 )
F21
8.0823E+01
( 7.4664E+01 )
2.2046E+02
( 1.3281E+02 )
8.8999E+01
( 7.2279E+01 )
2.1494E+02
( 1.1635E+02 )
F22
5.3963E+01
( 5.0682E+01 )
1.0269E+02
( 7.6626E+01 )
5.5032E+01
( 5.0009E+01 )
1.3378E+02
( 6.0558E+01 )
F23
2.0000E+02
( 0.0000E+00 )
3.1524E+02
( 1.7223E-13 )
2.0000E+02
( 0.0000E+00 )
3.1524E+02
( 1.7223E-13 )
F24
2.0000E+02
( 0.0000E+00 )
2.0000E+02
( 3.7114E-04 )
2.0000E+02
( 5.8812E-10 )
2.2726E+02
( 4.6729E+00 )
F25
2.0000E+02
( 0.0000E+00 )
2.0267E+02
( 1.2577E-01 )
2.0000E+02
( 0.0000E+00 )
2.0405E+02
( 1.1379E+00 )
F26
1.0013E+02
( 1.7020E-02 )
1.0026E+02
( 6.4711E-02 )
1.0013E+02
( 1.6101E-02 )
1.0028E+02
( 4.9230E-02 )
F27*
2.0392E+02
( 1.9604E+01 )
3.9210E+02
( 2.7760E+01 )
2.0000E+02
( 1.4003E-10 )
3.7227E+02
( 4.9793E+01 )
F28
2.0000E+02
( 0.0000E+00 )
8.1720E+02
( 2.9518E+01 )
2.0000E+02
( 0.0000E+00 )
8.2827E+02
( 4.8915E+01 )
F29
2.0000E+02
( 0.0000E+00 )
7.1559E+02
( 1.4515E+00 )
2.0000E+02
( 0.0000E+00 )
7.5534E+02
( 3.8937E+01 )
F30
2.0000E+02
( 0.0000E+00 )
1.0107E+03
( 2.7610E+02 )
2.0000E+02
( 0.0000E+00 )
1.6088E+03
( 7.5520E+02 )
* The result for the improved LSHADE-EpSin algorithm is due to a single bad initialization.

Chapter 8
Specializing Diﬀerential Evolution
for training Spiking Neural
Networks
This chapter aims to contribute to to understand how specialized versions of DE might
be created for training SNNs.
The structure of the chapter is as follows: Section 8.1 provides an in-depth descrip-
tion of SNN by discussing neuron models, synaptic plasticity, existing supervised learning
methods, and LSMs. Section 8.2 proposes a specialized DE version to train SNNs. Lastly,
Section 8.3 summarizes the chapter.
8.1
Spiking neural networks
SNNs are the third generation of neural networks. The neurons in an SNN communicate
using a sequence of binary events called spikes, which are produced when the membrane
potential of a neuron reaches a threshold.
These networks can be much more power
eﬃcient when implemented in hardware[17], and have been shown to possess the same
computational power as traditional ANN using fewer gates [18]. While theoretically inter-
esting, there are few applications in engineering contexts, apart from some limited use of
LSM[19].
The lack of applications are because there currently does not exist any good training
methods for SNNs, but DE algorithms could probably be successfully used to train SNNs,
especially if specialized for these types of networks.
SNN are inspired by biological neural networks. A biological neuron, illustrated in
ﬁgure 8.1, consists of (for our purposes) three parts.
The dendrites collect incoming
signals from other neurons, the soma which perform processing on these inputs and the
axon serves as the output from of the neuron.
The signals neurons use to transfer information consist of a sequence of action poten-
tials or spikes called spike trains. The neurons ensure that spikes are well separated, and
it is for most neurons impossible to trigger another spike within the refractory period of
the neuron. Neurons which cause an action potential is called the presynaptic neuron,
while the receiving neuron is called the postsynaptic neuron.
65

66
Chapter 8. Specializing Diﬀerential Evolution for training Spiking Neural Networks
Figure 8.1: Structure of a typical neuron.
8.1.1
Neurons
There have been developed mathematical models which describe how biological neurons
work which either reproduces some or all observed behaviors.
The seminal paper by
Izhikevich [90] describes 20 of the features observed in biological spiking neurons.
The most well-known neuron model is the Hodgkin-Huxley model which resulted from
the study of a giant squid axon [91]. This model is however too complicated to be analyzed
in analytically or computationally eﬃcient enough to be used in large-scale simulations.
As a result, there have been developed many simpler models which replicate one or more of
the properties[90], [92]–[94]. Nevertheless, there are many additional details in biological
neurons which are accounted for in the Hodgkin-Huxley model, but it is unknown whether
these contribute to computation in the brain.
This section discusses some of the most popular point neuron models.
Leaky integrate and ﬁre
The Leaky Integrate and Fire (I&F) is perhaps the most widely used spiking neuron
model [95]. This simple model is attractive due to easy implementation in software with
relatively eﬃcient simulation, and because it is relatively easy to analyze the networks
mathematically. The neuron can be modeled as a leaky integrator of the input current
I(t):
τm
du
dt = −v + RI(t),
(8.1)
where v(t) represents the membrane potential at time t, τm is the membrane time constant
and R is the resistance. The shape of spikes is not described explicitly by the model.
Instead, when the membrane potential reaches the threshold vth, it is reset to a lower
value vr, and the leaky integration process starts again.
While I&F is widely used, it lacks many of the biological properties that have been
observed and which are modeled in more sophisticated models like the Hodgkin-Huxley
model [91]. The most obvious being the lack of an absolute refractory period in which the
neuron will not ﬁre again. Additionally, it does not show adaptation, which is the observed
phenomenon in which the ﬁring frequency slows down when the neuron is exposed to
a constant stimulus. Additionally, in biological neurons, the shape of the postsynaptic

8.1. Spiking neural networks
67
potential depends not only on the membrane potential but also on the internal state of
the neuron. For example, a spike that arrived shortly after the neuron has ﬁred will cause
a diﬀerent response due to some of the ion channels still being open.
The Izhikcvhich neuron
The Izhikcvhich neuron [90] is a model capable of exhibiting many of the features observed
in biological neurons. While at the same time having a much lower computational com-
plexity than the Hodgkin-Huxley model [91]. It is however not biologically plausible. The
neuron can be described by the following two Ordinary Diﬀerential Equations (ODEs):
˙v = 0.04v2 + 5v + 140 −u −I,
(8.2)
˙u = a(b · v −u),
(8.3)
if v = 30mV then v = c, u = u + d.
(8.4)
The model consists of two state variables, v, and u. v is the membrane potential, and u
being the neuron recovery variable. The spiking condition is v = 30mV , the neuron ﬁres
whenever this condition is met before going back to the reset state.
The remaining variables a, b, c and d are parameters of the Izhikcvhich model. The
parameter a describes the speed of recovery, smaller values equal slower recovery, and
b describe how sensitive the recovery variable u is to sub-threshold ﬂuctuations in the
membrane potential v. When b is large, u and v are more tightly coupled, which can
result in sub-threshold oscillations and low-threshold spiking dynamics. The parameter c
is the value to which the membrane potential v is set to after a spike. Lastly, d aﬀects the
value which the recovery variable u is set to after a spike.
Resonate and ﬁre
A resonate and ﬁre neuron [96] is similar to an I&F with the internal state of the neuron
being complex and can be described as:
z′ = I + (b + iw)z
(8.5)
if Im x == athresh, then z ←z0(z)
(8.6)
with b, w, and athresh being parameters and z0(z), a function describing activity-dependent
activity after the spike.
FitzHugh-Nagumo
The FitzHugh-Nagumo model [92] is a simpliﬁcation of the Hodkin-Huxley model which
models the voltage v and sodium activation, and combining the potassium activation and
sodium inactivation as the recovery variable w. This can be expressed as:
ϵ˙v = F(v) −w + I,
(8.7)
˙w = v −γw,
(8.8)
with I being the injected current and
F(v) = v(1 −v)(v + a),
(8.9)
a, γ and ϵ being constants with ϵ ≪1.

68
Chapter 8. Specializing Diﬀerential Evolution for training Spiking Neural Networks
Morris-Lecar
The Morris-Lecar model [93] is similar to the HodgkinHuxley but is based on the calcium
instead of sodium currents provided through the two ionic conductances. The neuron can
be modeled by the following diﬀerential equations:
C ˙u = I −g1
ˆ
m0(u)(u −V1) −g2w(u −V2) −gL(u −VL),
(8.10)
˙w = −
1
τ(u) [w −w0(u)] .
(8.11)
The ﬁrst describe the dynamics for the membrane potential u, while the second describe
the recovery variable w. The voltage dependency can be approximated by:
m0(u) = 1
2

1 + tanh
u −u1
u2

(8.12)
w0(u) = 1
2

1 + tanh
u −u3
u4

(8.13)
(8.14)
with parameters u1, . . . , u4. The time constant can be approximated by:
τ(u) =
τw
cosh

u−u3
2u4
,
(8.15)
with τw being a parameter.
Hindmarsh-Rose
The Hindmarsh-Rose model is a modiﬁcation of the FitzHugh-Nagumo model which can
be described by the following equations[97]:
˙x = y −f(x) −z + I,
(8.16)
˙y = g(x) −y,
(8.17)
˙z = ϵ(s(x −x0) −z),
(8.18)
with I being the input current and:
f(x) = ax3 −vx2,
(8.19)
g(x) = c −dx2.
(8.20)
The ϵ and s being constants which controls how the neuron behaves.
8.1.2
Spike response model
The most common approach to describing neuronal dynamics in an I&F network is using
diﬀerential equations. However, an alternative approach is to parameterize the variables
of the model as functions of time called ﬁlters. The membrane potential for neuron j can
then be described by:
Vj(t) =
X
i∈Γj
X
k
wk
ijϵ(t −tout
i
−dk
ij).
(8.21)

8.1. Spiking neural networks
69
ϵ(t) is the post-synaptic potentials, Γj is the set of all pre-synaptic neurons of neuron j.
wk
ij is the strength of the synaptic terminal k between neurons i and j. tout
i
is the ﬁring
time of neuron i and dk
ij is the delay of the synaptic terminal. It is assumed that:
ϵ(t) =
1
τ exp

1 −1
τ

(8.22)
with τ being a time constant.
8.1.3
Synaptic plasticity
A remarkable property of the mammalian brain is its ability to modify the neural cir-
cuity and thereby changing how future computation is accomplished. One of the most
important mechanisms for this is synaptic plasticity which is believed to be of fundamen-
tal importance in the formation of memories in the brain. There have therefore been an
enormous amount of work trying to discover the underlying mechanisms of the various
types of synaptic plasticity. This section will brieﬂy describe some of the most important
concepts. A more thorough review is given in [98].
Rate based models
Rate based synaptic plasticity models assume the magnitude of changes in synaptic strength
is determined by the frequency of post- and presynaptic ﬁring measured over some time
interval.
Plain Hebbian learning rule
is the rule which most directly describes the funda-
mentally important postulate of Hebb [99] which is often paraphrased as ”Cells that ﬁre
together, wire together”[100]. This can be expressed plainly in a rate based model as
follows[100]:
τw ˙w = vu
(8.23)
with u being the presynaptic ﬁring rate, v being the postsynaptic ﬁring rate, τw being a
timing constant.
In practice this rule is problematic because the connection strength is only able to
increase, and never decrease. This would cause the weights to increase until an optional
upper bound is reached. At which point the weights will start to saturate.
Anti-Hebbian learning
is a rule ﬁrst proposed by Barlow, Barlow, and Fddik [101],
which can be stated similarly as Hebbian learning, but with a negative learning rate. This
has the eﬀect of making diﬀerent outputs less correlated. While this is believed to be a
primary principle for Purkinje cells in the cerebellum, it is unclear how general this is as
Purkinje cells are inhibitory[100].
Synaptic Normalization
is global constraints imposed on the synaptic strengths to
prevent the postsynaptic neuron from becoming too active[100]. One common constraint
is to require the sum of all synaptic weights to equal a constant value.

70
Chapter 8. Specializing Diﬀerential Evolution for training Spiking Neural Networks
Oja’s rule
is a modiﬁcation to the plain interpretation of Hebb’s postulate to address
the stability issues which occurs due to pure potentiating [102]. The rule is equivalent
to extracting the principal component of the presynaptic input when used with a single
neuron. The rule can be expressed as:
∆wi = α(xiy −y2wi)
(8.24)
with wi being the synaptic strength from neuron i, α the learning rate, xi is the presynaptic
input and y the output of the postsynaptic neuron.
When compared to the plain interpretation of Hebb’s postulate, the rule is similar,
except for in including the −y2wi term which regulates the potentiating by reducing the
potentiating when the strength or output becomes large.
Bienenstock-Cooper-Munro (BCM) rule
is a synaptic update rule which uses a
sliding threshold for determining the sign of the update Bienenstock, Cooper, and Munro
[103].
τw ˙w = vu(v −θv)
(8.25)
with u being the presynaptic ﬁring rate, v being the postsynaptic ﬁring rate, τw being a
timing constant, u with the threshold θv given by:
τθ ˙θv = v2 −θv.
(8.26)
here τθ is a timing constant.
Izhikevich and Desai [104] has shown that a pair-based Spike-Timing-Dependent-
Plasticity (STDP) which operates on the nearest spike principle, can replicate BCM be-
havior when the spike arrival times are distributed according to the Poisson distribution.
Furthermore, Pﬁster and Gerstner [105] showed that triplet-based STDP could also repli-
cate the behavior of BCM when the pre- and postsynaptic spike times follows a Poisson
distribution.
Spike-Timing-Dependent-Plasticity
STDP is a partial explanation for Long-Term Potentiation (LTP) and Long-Term De-
pression (LTD) in biological neural networks. In STDP, if a spike arrives shortly before
the neuron ﬁres, then that particular input is strengthened. However, if the spike arrives
shortly after, then that input is weakened. Thus reducing the chance of it participating
in future action potentials.
Pair-based STDP
The classical description of STDP is the pair-based rule which can
be stated as follows:
∆w =



∆w+ = A+ exp

−∆t
τ+

if ∆t > 0
∆w−= −A−exp

∆t
τ−

if ∆t ≤0,
(8.27)
where ∆t = tpost −tpre is the time diﬀerence between two pre- and postsynaptic spikes.
This will result in a potentiation of the weights if a postsynaptic spike arrives in a speciﬁc
time window τ+ after the occurrence of a presynaptic spike. Similarly, a depression will
occur if a presynaptic spike arrives in the time window τ−. The amount of depression and
potentiation depends on the amplitude parameters A+ and A−.

8.1. Spiking neural networks
71
Triplet-based STDP
Triplet-based STDP was developed by Pﬁster and Gerstner [105]
to address the problem that pair-based STDP cannot account for an observed dependence
on the frequency of spike pairs.
∆w =



∆w+ = exp

−∆t1
τ+
 
A+
2 + A+
3 exp

−∆t2
τy

if ∆t = tpost
∆w−= −exp

−∆t1
τ−
 
A−
2 + A−
3 exp

−∆t3
τx

if ∆t = tpre,
(8.28)
where A+
2 , A−
2 , A+
3 , and A−
3 are amplitude constants, ∆t1 = tpost −tpre, ∆t2 = tpost(n) −
tpost(n−1) −ϵ and ∆t3 = tpre(n) −tpre(n−1) −ϵ are time diﬀerence between the pre- and
postsynaptic spikes. ϵ is typically a small constant which ensures that weight updates are
applied at the correct time. Lastly, τ+, τ−, τx, τy are time constants.
Potentiation can occur when a post-synaptic spike is generated as a result of a two-
step process. First a potentiation proportional to A+
2 for the current post-synaptic spike,
and a potentiation proportional A+
3 for the interaction between the current and previous
post-synaptic spike.
8.1.4
Supervised learning
There have been developed many supervised training algorithms for SNN, but none which
works on all network architectures or without placing extensive restrictions on the neural
code.
Algorithm
Type
Architecture
SpikeProp [106]
Backpropagation
Multilayer
Optimal Hebbain learning [107]
Hebbian
Conditional
ReSuMe [108]
ReSuMe
Single layer, multi-
layer[109]
BPSL [110]
ReSuMe
Single layer
Reward modulated STDP [111]
Hebbian
Multi-layer
Table 8.1: Comparison of supervised learning algorithms for spiking neural networks.
SpikeProp
Developed by Bohte, Kok, and La Poutre [106], SpikeProp is gradient descent algorithm
which to learn a set of desired ﬁring times td
j at the postsynaptic neurons j ∈J for a set
of input patterns Sin(t). The algorithm is derived from the Spike Response Model (SRM)
and required that all neurons are only allowed to ﬁre one; subsequent spikes are to be
ignored.
For SpikeProp, it is necessary for neurons to be initialized such that all neurons ﬁre at
least once for all patterns, to be able to calculate the gradient for the weights to that neu-
ron. This makes it diﬃcult to ﬁnd good problem-independent weight initializations[112].
There has been developed an extension to SpikeProp by Booij and Nguyen [113] that
allow input and hidden neurons to ﬁre more than once.
Optimal Hebbian learning
Optimal Hebbian learning is a probabilistic approach that ﬁnds a likelihood which is a
smooth function of the parameters by examining the pre- and postsynaptic ﬁring times

72
Chapter 8. Specializing Diﬀerential Evolution for training Spiking Neural Networks
[107]. This allows for the use of gradient descent based approaches to optimize the synaptic
strengths.
ReSuMe
The ReSuMe learning rule uses a combination of Hebbian learning and gradient descent
developed by Ponulak [108]. The rule is given by the equation:
˙
wik(t) =
h
Sd(t) −So(t)
i 
a
Z ∞
0
W(s)sin(t −s)ds

,
(8.29)
where Sd(t), Sin(t) and So(t) are the desired, pre- and postsynaptic spike trains respec-
tively. The constant a represents the non-Hebbian contribution to the weight changes.
W(s) is the learning window of a time delay s:
W(s) =
(
+A+ · exp(−s/τ+)
if s ≥0,
−A−· exp(s/τ)
ifs < 0,
(8.30)
with amplitudes A+, A−≥o and time constants τ+, τ−> 0.
The algorithm as given by Ponulak [108] can only be applied to networks without
any hidden layers or as done in the original article, to learn readout neurons of an LSM.
It has however, been shown experimentally that ReSuMe is unable to learn non-linear
computations without hidden layers[109].
Sporea and Grüning [109] recently proposed a modiﬁcation to ReSuMe which allows
training of multilayer feedforward networks by making downstream neurons subject to
multiplicative scaling. This modiﬁcation could be used in conjunction with unrolling the
network to train Recurrent Neural Network (RNN)s.
Biologically Plausible Supervised Learning (BPSL)
BPSL is a recent supervised learning algorithm by Taherkhani, Belatreche, Li, et al. [110],
developed using recent insights into biological synaptic plasticity.
While they do not
demonstrate any higher accuracy of the learning result, the learning speed is much higher
than with similar algorithms like ReSuMe. They report being able to train with ReSuMe
in 3.5 seconds and 1 second for BPSL.
Reward-modulated synaptic plasticity
Reward-modulated synaptic plasticity is a proposal by Izhikevich [111] to solve the problem
of how the ﬁring pattern of neurons can be controlled far from the neuron exhibiting the
wanted behavior. This can be accomplished by introducing some enzyme essential for
plasticity of which there are several candidates, expressed here as the eligibility trace c:
˙c = c
τc
+ STDP(τ) · δ(t −tpre).
(8.31)
The change of synaptic strength can then be controlled by c and an extracellular dopamine
level d:
˙w = cd.
(8.32)
τc controls how fast c converges to 0.

8.2. Proposed algorithm
73
8.1.5
Liquid state machines
LSM [114] is reservoir computing approach developed to elucidate the computational prin-
cipals from biological neural microcircuits. LSMs use biologically plausible spiking neurons
and builds the reservoir using biologically plausible topological constraints such as distant
neurons being less likely to be connected. However, the biological plausibility of LSMs is
challenged by the observation that it is not robust against damage in the network, such
as missing or malfunctioning neurons[115].
Readout
There are two methods for solving practical problems with LSMs. The ﬁrst is to use the
state of the reservoir together with a general machine learning technique which then solves
the problem. However, a more biologically plausible approach has been to use readout
neurons that receive the spike trains of neurons in the reservoir.
This was proposed
already from the beginning [114]. Newer approaches improve on this by including Hebbian
learning[123].
Learning
The reservoir as described by Maass, Natschläger, and Markram [114] is typically un-
trained.
However, Hebbian learning implemented as Spike-timing-dependent plasticity
has been shown to increase separation for speech data[19]. The authors were, however,
uncertain about whether it would be more eﬃcient to create a better liquid initially by
adjusting the parameters. More recent attempts have found that this results in a signif-
icant increase in performance for complicated time series [124]. Similar approaches have
been shown to work well with time-encoding based readout from the reservoir[125].
8.2
Proposed algorithm
There have been some limited attempts at using evolutionary methods to train SNNs.
Some notable previous attempts include Pavlidis, Tasoulis, Plagianakos, et al. [126] which
used a parallel version of the standard DE algorithm, and the work by Vazquez [127] which
attempted to use the cuckoo search algorithm to train sets of individual spiking neurons
to solve classiﬁcation problems.
However, all of these approaches attempt to train simple, feedforward network struc-
tures that do not utilize the computation potential of SNN. To fully utilize these networks,
the networks would need to be recurrent, that is, the synapses would need to form cy-
cles. The only practically useful recurrent SNN architectures are LSM. While these have
been shown to produce signiﬁcantly better results when paired with unsupervised learning
methods, the limitations of unsupervised learning will likely prevent them from becom-
ing competitive against the state-of-the-art traditional ANNs, such as Long Short-Term
Memory (LSTM)[128], [129].
The diﬃculty with training practically interesting SNNs architectures using black-
box optimizers, is that the number of parameters quickly becomes greater than what the
algorithms can eﬃciently handle. This thesis therefore proposes a specialized version of
DE that utilizes synaptic plasticity and selection based on neuronal activity to make the
search more eﬃcient.
The proposed algorithm is based on a simpliﬁed version of the

74
Chapter 8. Specializing Diﬀerential Evolution for training Spiking Neural Networks
improved LSHADE-EpSin algorithm resulting from the experiment in Chapter 7. The
proposed algorithm is outlined in Algorithm 7.
8.2.1
Synaptic plasticity
Synaptic plasticity can function as a local search. However, synaptic plasticity would have
to be used in a controlled manner, since training every individual using synaptic plasticity
could cause the population to lose diversity and get stuck in local optima. Additionally,
using synaptic plasticity would eﬀectively require the computation time equaling one extra
evaluation, two if the performance of the resulting network was needed; one to simulate
the network with plasticity, and one to test afterwards.
The diﬀerent types of synaptic plasticity discussed in Section 8.1.3 exhibit diﬀerent
behaviors, but the Triplet-Based STDP [105] has been shown to be more general than
BCM[130].
The solution proposed here is to associate every individual x(t)
i
with a synaptic in-
dividual s(t)
i
that has been trained using synaptic plasticity. The synaptic individual is
initialized such that x(1)
i
= s(1)
i
. The algorithm can then choose probabilistically, or based
on the search progression, or a combination of the two, to update the synaptic individ-
ual by running a simulation. This approach does not require the ﬁtness of the synaptic
individual, and would, therefore, not need more time than approximately one additional
ﬁtness evaluation whenever the synaptic individual is updated.
Synaptic plasticity might only be useful toward the end of the search. To simplify the
logic of this, the algorithm keeps x(t)
i
= s(t)
i
until the ﬁrst time the synaptic individual i
is updated.
8.2.2
Current-to-pbest-synaptic mutation operator
This section propose including the synaptic individual into a new mutation operator called
Current-to-pbest-synaptic, based on the current-to-pbest mutation operator described in
Section 6.1.1, as follows:
v(t)
i
= x(t)
i
+ F

x(t)
pbest −x(t)
i

+ F

s(1)
i
−x(t)
i

+ F

x(t)
R1 −x(t)
R2

(8.33)
The mutation guides the search toward values found by training the network using
synaptic plasticity. The operator is illustrated in Figure 8.2.
x(t)
i
x(t)
pbest
s(1)
i
x(t)
R1
x(t)
R2
Figure 8.2: Illustration of the Current-to-pbest-synaptic mutation operator

8.3. Conclusion
75
8.2.3
Neuronal activity selection
The selection of individuals for the population might need to be modiﬁed for an eﬃcient
search, especially early in the search. Many weight conﬁgurations would result in either
too few, or no neurons ﬁring, and these individuals might provide too poor performance
to properly guide the search.
A potential solution to this is to have a secondary condition to determine when an
individual is better based on the neuronal activity as follows:
xi(t+1) =







ui
if f

u(t)
i

< f

x(t)
i

,
ui
else if f

u(t)
i

= f

x(t)
i

∧a

u(t)
i

> a

x(t)
i

,
xi(t+1)
otherwise.
(8.34)
Here, a(·) determines how many neurons ﬁred.
8.2.4
Using the algorithm
The algorithm here can be used to train most types of SNNs, the only requirement being
that enough networks can be evaluated within a reasonable time-frame, and that the
performance of the network can be measured as a single real number. Tuning LSMs is
therefore tempting, as these have been shown to achieve better performance when some
training of the reservoir has taken place[124].
8.3
Conclusion
This chapter discussed SNN and proposed a new, specialized version of DE for train-
ing these networks. The new algorithm introduces the concept of a synaptic individual,
which stores the parameters of a network that has been trained using synaptic plasticity.
These parameters are used to guide the search through the new Current-to-pbest-synaptic
mutation operator.
While it is impossible to know how well this new algorithm performs without being
used in practice to train SNNs, it provides novel ideas that could work by itself, or be
built on in future work.

76
Chapter 8. Specializing Diﬀerential Evolution for training Spiking Neural Networks
Algorithm 7 The Synaptic LSHADE algorithm
P (1) ←{x(1)
i
, x(1)
i
, . . . , x(1)
Np}
▷see Section 3.1 for details.
Y (1) ←{x(1)
i
, x(1)
i
, . . . , x(1)
Np}
▷Y (t) is the synaptic individuals at generation t
Y (1)
updated,i ←0 for all i
t ←1
fes ←Np
Initialize memories M(t)
CR, M(t)
F
and M(t)
freq to 0.5.
▷see Section 7.1.2 for details.
while Termination criteria not met do
SCR ←∅, SF ←∅, Sfreq ←∅
progression ←
fes
fexmax
for i ←1, Np do
r = rand(1, H) 1
if progression < tanh(tanh(0.5)) then
F (t)
i
= 0.5
▷Simpliﬁed version of the improvement found in Chapter 7
else
F (t)
i
= randc(M(t)
F,r, 0.1)
end if
if M(t)
CR,r =⊥then
CR(t)
i
= 0
else
CR(t)
i
= randn(M(t)
CR,r, 0.1)
end if
v(t)
i
←mutate(x(t)
i )
▷see Equation (8.33) for details
u(t)
i
←binaryCrossover(x(t)
i , v(t)
i )
▷see Section 3.3 for details.
fes ←fes + 1
if progression > 0.75 ∧rand(0, 1) < 0.5 ∧(fesmax −fes) ≥1 then
s(t)
i
←network trained using synaptic plasticity
fes ←fes + 1
end if
if f(u(t)
i ) < f(x(t)
i ) then
Insert u(t)
i
into P (t+1)
Insert x(t)
i
into archive
▷See Section 6.1.2 for details
else
if f(u(t)
i ) = f(x(t)
i ) ∧a(u(t)
i ) > a(x(t)
i ) then
Insert u(t)
i
into P (t+1)
Insert x(t)
i
into archive
▷See Section 6.1.2 for details
else
Insert x(t)
i
into P (t+1)
end if
end if
end for
Reduce population size
▷See Section 7.1.3 for details
Update MCR,r, MF,r, and Mfreq,r.
▷see Section 7.1.2 for details
if Np < 20 for the ﬁrst time then
Execute local search as described in Section 7.1.3
end if
t ←t + 1
end while

Chapter 9
Further work
There is much further work that could be done to increase the chance of ﬁnding larger
improvements. This section discusses some of it.
9.1
Standard diﬀerential evolution
It is likely improving the standard Diﬀerential Evolution algorithm using ADATE would
succeed if using the improved grading of candidate programs used when improving CDE or
LSHADE-EpSin. The main reason this was not done as part of this project is the diﬃculty
of justifying using a large amount of computation resources on an algorithm that is unlikely
to produce state-of-the-art results. However, due to being available in commercial and
academic software packages, several of which have a conﬁgurable mutation operator. A
signiﬁcantly better mutation could potentially be adopted, and used by a larger community
of users earlier than state-of-the-art variants.
9.2
Competitive diﬀerential evolution
The problem discovered with CDE was the faulty mechanics governing the competition
among strategies, and the priority should be ﬁxing it.
The likely best option is to change the way nh is updated to take into account how
large improvement each success has resulted in by updating nh using the normalized
improvement:
n(t+1)
h
= n(t)
h +
∆h
PH
h=1 ∆h
(9.1)
with ∆h being the sum of all improvements in the current generation for strategy h:
∆h =
X
i∈Dh
f

x(t)
i

−f

u(t)
i
 .
(9.2)
Here Dh is the set of all the indexes for individuals improved by strategy h.
This solution could however be aﬀected by another problem with the competition
mechanics, speciﬁcally that the adaptation slows down after several updates accumulate
in n(t+1)
h
. Potentially to the point where it becomes unable to react to changes in the
landscape. This can be solved using the a method similar to the adaptation mechanics for
77

78
Chapter 9. Further work
F and CR in JADE[48], speciﬁcally, introducing a control parameter c into Equation (9.1):
n(t+1)
h
= (1 −c)n(t)
h + c
 
∆h
PH
h=1 ∆h
!
(9.3)
Using this update rule, the c could be changed to control how quickly nh would be allowed
to change.
The way method used to include the crossover rate in the strategies is rather coarse
compared to other adaptation methods such as in SHADE. Using a version of CDE which
includes these better methods would be preferable. One such version was entered into the
CEC 2016 competition, and with the above modiﬁcations together with further improve-
ment by ADATE, could be highly competitive[131].
9.3
LSHADE-EpSin
Due to the entire sinusoidal ensemble being shown to be unnecessary, including other parts
of the algorithm into f would be the next step. Some candidates are:
• The weighted Lehmer mean represented in a way which would allow ADATE to
produce independent heuristics for the crossover rate and scaling factor F.
• The Cauchy distribution and normal distribution used to sample the scaling factors
and crossover rate respectively.
In practical contexts, it is often beneﬁcial if the optimum is found quickly. In the grad-
ing used in this thesis, this is only weekly accounted for by using three steps of increasing
ﬁtness evaluation budgets. However, this could be made used as a larger requirement
for candidate programs by incorporating how many function evaluations were used to the
grade or adding by another grade which ADATE could use simultaneously.
9.4
Optimizing for specialized use-cases
Specialized versions like the one discussed in Chapter 8 could be created for other niche
problems. However, it would be interesting to investigate the use of ADATE to auto-
matically design such versions. The specialization to the low number of generations in
Chapter 5 shows ADATE is capable.
The Ocean glider path planning problem mentioned in Section 3.7.2 required a power
eﬃcient algorithm. While the DE algorithm is inherently power eﬃcient, the eﬃciency
is dependent on the number of ﬁtness function evaluations necessary to reach a good
enough solution. As shown in Chapter 5, the mutation operator has a large eﬀect on the
performance of the algorithm and how quickly it converges. While the intention in that
project was to use DE with a larger number of evaluations later, the observations can be
used to motivate experiments targeting niche problems.

Chapter 10
Conclusions
This thesis had three goals. First (RQ1), to understand how synthesized modiﬁcations
to Diﬀerential Evolution might be evaluated quickly enough for ADATE. Second (RQ2),
to determine which parts of the Diﬀerential Evolution algorithm might be improved, and
third (RQ3), to understand how specialized versions of Diﬀerential Evolution for training
Spiking Neural Networks might be created.
Three experiments, discussed in Chapters 5 to 7, were used to answer RQ1. In all three
experiments, the candidate programs were evaluated using synthetic benchmark functions,
as these can be evaluated much more quickly than landscape generators[82]. Additionally,
synthetic benchmark functions are often designed to study optimization on problems with
special characteristics. As such, the landscapes are often better deﬁned than machine
learning models, making it easier to create representative problem sets.
To ensure all problems contributed equally to the grade, Chapter 5 proposed an ap-
proach based on the ratio of the achieved ﬁtness on a problem to the median of the ﬁtness
achieved by the original algorithm. This was changed in Chapter 6 to a method based on
the approximate cumulative density function to accommodate problems that include both
negative and positive ﬁtness values.
The maximum number of allowed function evaluation was increased for each of the
three experiments.
The ﬁrst experiment prioritized evaluating a high number of can-
didate programs by using a low number of training and validation problems, all with
relatively few generations. Because of overﬁtting to the low number of generations, the
number of generations was increased signiﬁcantly for the second experiment. Additionally,
the number of problems was increased to further enhance the statistical certainty of the
evaluation. This resulted in the successful improvement of the pool of strategies in the
Competitive Diﬀerential Evolution algorithm.
In the third, and last experiment, the statistical certainty of evaluations was further im-
proved by using an even higher number of allowed function evaluations. This experiment
succeeded in improving the mutation heuristics in the state-of-the-art LSHADE-EpSin
algorithm resulting in an algorithm that is both smaller and achieves better results on
problems with 30 dimensions. It is possible that larger improvements could be found if
ADATE had been able to test more programs. This could be achieved by either using fewer
repetitions of each problem or using more computing time for the experiment. Neverthe-
less, this shows the evaluation both provides enough guidance, and enables the evaluation
of candidate programs quickly enough, for the ADATE search.
To answer RQ2, Chapter 5 included a discussion of which parts to improve. That
79

80
Chapter 10. Conclusions
discussion resulted in the parts selected for improvement were related to the mutation
heuristics for all three experiments. Improving the mutation had several beneﬁts; namely,
since the implementation of all mutation operators has a similar overall algorithmic struc-
ture, the number of transformations that would be necessary to transform one into an-
other, provided all the required background knowledge was made available, is minimal.
Additionally, the mutation is at the core of the algorithm, with diﬀerent mutation oper-
ators changing the performance of the search dramatically, as evidenced by the results
in Tables 5.5 to 5.8. This means that even simple modiﬁcations could yield signiﬁcant
improvement of the algorithms.
The successful improvement of both the Competitive Diﬀerential Evolution and LSHADE-
EpSin supports the conclusion that this was a good choice. However, there are other parts
of the algorithms that might also yield improvements, especially concerning the adaptation
mechanics in LSHADE-EpSin.
Creating specialized variations of Diﬀerential Evolution for training spiking neural
networks to answer RQ3, was limited to theoretical discussions.
The major problem
preventing the use of Diﬀerential Evolution to train spiking neural networks is the diﬃculty
of optimizing such a high-dimensionality problem using black-box methods.
However,
specialized algorithms can use knowledge about the model being optimized to guide the
search more eﬀectively. This was used to motivate the proposal of a specialized version of
Diﬀerential Evolution in Chapter 8 that incorporates synaptic plasticity into the search,
and a new mechanism for selecting the new generation that uses the neuronal activity as
a secondary measure.
While it is impossible to know how well this algorithm will perform in real-life without
it being tested on practical problems, it does show how training methods and information
speciﬁc to spiking neural networks can be included in the mutation and selection mechanics
of Diﬀerential Evolution in a manner that might make the search more eﬃcient. Although
this is not the ﬁrst attempt at creating a specialized version of Diﬀerential Evolution, it
is the ﬁrst version intended to train spiking neural networks of which we are aware.

Bibliography
[1]
F. Glover, “Tabu searchpart i,” ORSA Journal on computing, vol. 1, no. 3, pp. 190–
206, 1989.
[2]
S. Kirkpatrick, C. D. Gelatt, M. P. Vecchi, et al., “Optimization by simulated
annealing,” Science, vol. 220, no. 4598, pp. 671–680, 1983.
[3]
D. Karaboga, “An idea based on honey bee swarm for numerical optimization,”
Technical report-tr06, Erciyes university, engineering faculty, computer engineering
department, Tech. Rep., 2005.
[4]
R. Eberhart and J. Kennedy, “A new optimizer using particle swarm theory,” in
Micro Machine and Human Science, 1995. MHS’95., Proceedings of the Sixth In-
ternational Symposium on, IEEE, 1995, pp. 39–43.
[5]
J. H. Holland, Adaptation in natural and artiﬁcial systems: An introductory analysis
with applications to biology, control, and artiﬁcial intelligence. MIT press, 1992.
[6]
H.-G. Beyer and H.-P. Schwefel, “Evolution strategies–a comprehensive introduc-
tion,” Natural computing, vol. 1, no. 1, pp. 3–52, 2002.
[7]
R. Storn and K. Price, Diﬀerential evolution-a simple and eﬃcient adaptive scheme
for global optimization over continuous spaces. ICSI Berkeley, 1995, vol. 3.
[8]
M. Vasile, E. Minisci, and M. Locatelli, “An inﬂationary diﬀerential evolution al-
gorithm for space trajectory optimization,” IEEE Transactions on Evolutionary
Computation, vol. 15, no. 2, pp. 267–281, 2011.
[9]
A. Zamuda and J. D. H. Sosa, “Diﬀerential evolution and underwater glider path
planning applied to the short-term opportunistic sampling of dynamic mesoscale
ocean structures,” Applied Soft Computing, vol. 24, pp. 95–108, 2014.
[10]
L. Jebaraj, C. Venkatesan, I. Soubache, and C. C. A. Rajan, “Application of dif-
ferential evolution algorithm in static and dynamic economic or emission dispatch
problem: A review,” Renewable and Sustainable Energy Reviews, 2017.
[11]
R. Olsson, “Inductive functional programming using incremental program transfor-
mation; and, execution of logic programs by iterative-deepening a* sld-tree search,”
PhD thesis, University of Oslo, Department of Informatics, 1994.
[12]
——, “Inductive functional programming using incremental program transforma-
tion,” Artiﬁcial intelligence, vol. 74, no. 1, pp. 55–81, 1995.
[13]
J. R. Olsson, “How to invent functions,” in Genetic Programming, Springer, 1999,
pp. 232–243.
[14]
A. Løkketangen and R. Olsson, “Generating meta-heuristic optimization code using
adate,” Journal of Heuristics, vol. 16, no. 6, pp. 911–930, 2010.
81

82
BIBLIOGRAPHY
[15]
K. Larsen, L. V. Magnusson, and R. Olsson, “Edge pixel classiﬁcation using auto-
matic programming.,” in NIK, 2014.
[16]
H. Vu and R. Olsson, “Automatic improvement of graph based image segmenta-
tion,” Advances in Visual Computing, pp. 578–587, 2012.
[17]
P. A. Merolla, J. V. Arthur, R. Alvarez-Icaza, A. S. Cassidy, J. Sawada, F. Akopyan,
B. L. Jackson, N. Imam, C. Guo, Y. Nakamura, et al., “A million spiking-neuron
integrated circuit with a scalable communication network and interface,” Science,
vol. 345, no. 6197, pp. 668–673, 2014.
[18]
W. Maass, “Networks of spiking neurons: The third generation of neural network
models,” Neural networks, vol. 10, no. 9, pp. 1659–1671, 1997.
[19]
D. Norton and D. A. Ventura, “Preparing more eﬀective liquid state machines using
hebbian learning,” 2006.
[20]
P. Bujok, J. Tvrdk, and R. Polakova, “Diﬀerential evolution with rotation-invariant
mutation and competing-strategies adaptation,” in Evolutionary Computation (CEC),
2014 IEEE Congress on, IEEE, 2014, pp. 2253–2258.
[21]
N. H. Awad, M. Z. Ali, P. N. Suganthan, and R. G. Reynolds, “An ensemble sinu-
soidal parameter adaptation incorporated with l-shade for solving cec2014 bench-
mark problems,” in Evolutionary Computation (CEC), 2016 IEEE Congress on,
IEEE, 2016, pp. 2958–2965.
[22]
F. Marini and B. Walczak, “Particle swarm optimization (pso). a tutorial,” Chemo-
metrics and Intelligent Laboratory Systems, vol. 149, pp. 153–165, 2015.
[23]
J. Liang, B. Qu, and P. Suganthan, “Problem deﬁnitions and evaluation criteria
for the cec 2014 special session and competition on single objective real-parameter
numerical optimization,” Computational Intelligence Laboratory, Zhengzhou Uni-
versity, Zhengzhou China and Technical Report, Nanyang Technological University,
Singapore, 2013.
[24]
T. P. Hettmansperger and J. W. McKean, Robust nonparametric statistical meth-
ods. CRC Press, 2010.
[25]
R. Storn, “On the usage of diﬀerential evolution for function optimization,” in Fuzzy
Information Processing Society, 1996. NAFIPS., 1996 Biennial Conference of the
North American, IEEE, 1996, pp. 519–523.
[26]
K. Price, R. M. Storn, and J. A. Lampinen, Diﬀerential evolution: A practical
approach to global optimization. Springer Science & Business Media, 2006.
[27]
E. Mezura-Montes, J. Velázquez-Reyes, and C. A. Coello Coello, “A comparative
study of diﬀerential evolution variants for global optimization,” in Proceedings of
the 8th annual conference on Genetic and evolutionary computation, ACM, 2006,
pp. 485–492.
[28]
P. Kaelo and M. Ali, “A numerical study of some modiﬁed diﬀerential evolution
algorithms,” European journal of operational research, vol. 169, no. 3, pp. 1176–
1184, 2006.
[29]
H.-Y. Fan and J. Lampinen, “A trigonometric mutation operation to diﬀerential
evolution,” Journal of global optimization, vol. 27, no. 1, pp. 105–129, 2003.

BIBLIOGRAPHY
83
[30]
R. Salomon, “Re-evaluating genetic algorithm performance under coordinate rota-
tion of benchmark functions. a survey of some theoretical and practical aspects of
genetic algorithms,” BioSystems, vol. 39, no. 3, pp. 263–278, 1996.
[31]
D. Zaharie, “Critical values for the control parameters of diﬀerential evolution
algorithms,” in Proceedings of MENDEL, vol. 2, 2002, p. 6267.
[32]
——, “A comparative analysis of crossover variants in diﬀerential evolution,” Pro-
ceedings of IMCSIT, vol. 2007, pp. 171–181, 2007.
[33]
S. Kukkonen and J. Lampinen, “An empirical study of control parameters for the
third version of generalized diﬀerential evolution (gde3),” in Evolutionary Compu-
tation, 2006. CEC 2006. IEEE Congress on, IEEE, 2006, pp. 2002–2009.
[34]
S. Kukkonen et al., “Generalized diﬀerential evolution for global multi-objective
optimization with constraints,” Acta Universitatis Lappeenrantaensis, 2012.
[35]
S. Das and P. N. Suganthan, “Diﬀerential evolution: A survey of the state-of-the-
art,” IEEE transactions on evolutionary computation, vol. 15, no. 1, pp. 4–31, 2011.
[36]
R. Tanabe and A. S. Fukunaga, “Improving the search performance of shade using
linear population size reduction,” in Evolutionary Computation (CEC), 2014 IEEE
Congress on, IEEE, 2014, pp. 1658–1665.
[37]
G. Harik, E. Cantú-Paz, D. E. Goldberg, and B. L. Miller, “The gambler’s ruin
problem, genetic algorithms, and the sizing of populations,” Evolutionary Compu-
tation, vol. 7, no. 3, pp. 231–253, 1999.
[38]
C. R. Reeves, “Using genetic algorithms with small populations.,” in ICGA, vol. 590,
1993, p. 92.
[39]
D. E. Goldberg, K. Sastry, and T. Latoza, “On the supply of building blocks,” in
Proceedings of the 3rd Annual Conference on Genetic and Evolutionary Computa-
tion, Morgan Kaufmann Publishers Inc., 2001, pp. 336–342.
[40]
D. E. Goldberg, K. Deb, and J. H. Clark, “Genetic algorithms, noise, and the sizing
of populations,” Urbana, vol. 51, p. 61 801, 1991.
[41]
F. G. Lobo, “Idealized dynamic population sizing for uniformly scaled problems,”
in Proceedings of the 13th annual conference on Genetic and evolutionary compu-
tation, ACM, 2011, pp. 917–924.
[42]
V. K. Koumousis and C. P. Katsaras, “A saw-tooth genetic algorithm combining
the eﬀects of variable population size and reinitialization to enhance performance,”
IEEE Transactions on Evolutionary Computation, vol. 10, no. 1, pp. 19–28, 2006.
[43]
T. Hu, S. Harding, and W. Banzhaf, “Variable population size and evolution accel-
eration: A case study with a parallel evolutionary algorithm,” Genetic Programming
and Evolvable Machines, vol. 11, no. 2, pp. 205–225, 2010.
[44]
G. R. Harik and F. G. Lobo, “A parameter-less genetic algorithm,” in Proceedings
of the 1st Annual Conference on Genetic and Evolutionary Computation-Volume
1, Morgan Kaufmann Publishers Inc., 1999, pp. 258–265.
[45]
J. C. Costa, R. Tavares, and A. Rosa, “An experimental study on dynamic ran-
dom variation of population size,” in Systems, Man, and Cybernetics, 1999. IEEE
SMC’99 Conference Proceedings. 1999 IEEE International Conference on, IEEE,
vol. 1, 1999, pp. 607–612.

84
BIBLIOGRAPHY
[46]
F. G. Lobo and C. F. Lima, “Adaptive population sizing schemes in genetic algo-
rithms,” in Parameter Setting in Evolutionary Algorithms, Springer, 2007, pp. 185–
204.
[47]
A. K. Qin and P. N. Suganthan, “Self-adaptive diﬀerential evolution algorithm
for numerical optimization,” in Evolutionary Computation, 2005. The 2005 IEEE
Congress on, IEEE, vol. 2, 2005, pp. 1785–1791.
[48]
J. Zhang and A. C. Sanderson, “Jade: Adaptive diﬀerential evolution with optional
external archive,” IEEE Transactions on evolutionary computation, vol. 13, no. 5,
pp. 945–958, 2009.
[49]
J. Tvrdk, “Competitive diﬀerential evolution,” in MENDEL, 2006, pp. 7–12.
[50]
R. Mallipeddi, P. N. Suganthan, Q.-K. Pan, and M. F. Tasgetiren, “Diﬀerential
evolution algorithm with ensemble of parameters and mutation strategies,” Applied
Soft Computing, vol. 11, no. 2, pp. 1679–1696, 2011.
[51]
P.-c. Wang, X. Qian, and X.-h. Hu, “A novel diﬀerential evolution algorithm based
on chaos local search,” in Information Engineering and Computer Science, 2009.
ICIECS 2009. International Conference on, IEEE, 2009, pp. 1–4.
[52]
D. Jia, G. Zheng, and M. K. Khan, “An eﬀective memetic diﬀerential evolution
algorithm based on chaotic local search,” Information Sciences, vol. 181, no. 15,
pp. 3175–3187, 2011.
[53]
I. Poikolainen and F. Neri, “Diﬀerential evolution with concurrent ﬁtness based
local search,” in Evolutionary Computation (CEC), 2013 IEEE Congress on, IEEE,
2013, pp. 384–391.
[54]
M. Ali, M. Pant, and A. Nagar, “Two local search strategies for diﬀerential evolu-
tion,” in Bio-Inspired Computing: Theories and Applications (BIC-TA), 2010 IEEE
Fifth International Conference on, IEEE, 2010, pp. 1429–1435.
[55]
H. Peng and Z. Wu, “Heterozygous diﬀerential evolution with taguchi local search,”
Soft Computing, vol. 19, no. 11, pp. 3273–3291, 2015.
[56]
S. Das, S. S. Mullick, and P. N. Suganthan, “Recent advances in diﬀerential evolution–
an updated survey,” Swarm and Evolutionary Computation, vol. 27, pp. 1–30, 2016.
[57]
P. D. Summers, “A methodology for lisp program construction from examples,”
Journal of the ACM (JACM), vol. 24, no. 1, pp. 161–175, 1977.
[58]
S. Muggleton and C. Feng, “Eﬃcient Induction of Logic Programs,” in Algorithmic
Learning Theory, 1990, pp. 368–381.
[59]
S. Muggleton and L. De Raedt, “Inductive logic programming: Theory and meth-
ods,” The Journal of Logic Programming, vol. 19, pp. 629–679, 1994.
[60]
S. Muggleton, “Inverse entailment and progol,” New Generation Computing, vol.
13, pp. 245–286, 3&4 1995. doi: 10.1007/BF03037227.
[61]
P. Flener, “Inductive logic program synthesis with dialogs,” in International Con-
ference on Inductive Logic Programming, Springer, 1996, pp. 175–198.
[62]
M. Hofmann, E. Kitzelmann, and U. Schmid, “A unifying framework for analysis
and evaluation of inductive programming systems,” in Proceedings of the Second
Conference on Artiﬁcial General Intelligence, Citeseer, 2009, pp. 55–60.

BIBLIOGRAPHY
85
[63]
U. Schmid and E. Kitzelmann, “Inductive rule learning on the knowledge level,”
Cognitive Systems Research, vol. 12, no. 3, pp. 237–248, 2011.
[64]
E. Kitzelmann, U. Schmid, M. Mühlpfordt, and F. Wysotzki, “Inductive synthesis of
functional programs,” in Artiﬁcial intelligence, automated reasoning, and symbolic
computation, Springer, 2002, pp. 26–37.
[65]
S. Katayama, “Magichaskeller: System demonstration,” in Proceedings of AAIP
2011 4th International Workshop on Approaches and Applications of Inductive Pro-
gramming, 2011, p. 63.
[66]
——, “Recent improvements of magichaskeller,” in International Workshop on Ap-
proaches and Applications of Inductive Programming, Springer, 2009, pp. 174–193.
[67]
——, “Towards human-level inductive functional programming,” in International
Conference on Artiﬁcial General Intelligence, Springer, 2015, pp. 111–120.
[68]
J. R. Koza, Genetic programming: On the programming of computers by means of
natural selection. MIT press, 1992, vol. 1.
[69]
R. Poli, W. B. Langdon, N. F. McPhee, and J. R. Koza, A ﬁeld guide to genetic
programming. Lulu. com, 2008.
[70]
R. Hrbacek and V. Dvorak, “Bent function synthesis by means of cartesian ge-
netic programming,” in International Conference on Parallel Problem Solving from
Nature, Springer, 2014, pp. 414–423.
[71]
L. V. Magnusson and R. Olsson, “Improving the canny edge detector using au-
tomatic programming: Improving the ﬁlter,” in Image, Vision and Computing
(ICIVC), International Conference on, IEEE, 2016, pp. 36–40.
[72]
——, “Improving the canny edge detector using automatic programming: Improv-
ing hysteresis thresholding,” Norsk Informatikkonferanse (NIK), 2016.
[73]
——, “Improving the canny edge detector using automatic programming: Improv-
ing non-max suppression,” in Proceedings of the 2016 on Genetic and Evolutionary
Computation Conference, ACM, 2016, pp. 461–468.
[74]
E. K. Burke, M. Hyde, G. Kendall, and J. Woodward, “A genetic programming
hyper-heuristic approach for evolving 2-d strip packing heuristics,” IEEE Transac-
tions on Evolutionary Computation, vol. 14, no. 6, pp. 942–958, 2010.
[75]
E. Burke, M. Hyde, and G. Kendall, “Evolving bin packing heuristics with genetic
programming,” Parallel Problem Solving from Nature-PPSN IX, pp. 860–869, 2006.
[76]
S. Allen, E. K. Burke, M. Hyde, and G. Kendall, “Evolving reusable 3d packing
heuristics with genetic programming,” in Proceedings of the 11th Annual conference
on Genetic and evolutionary computation, ACM, 2009, pp. 931–938.
[77]
D. Jakobovi and K. Marasovi, “Evolving priority scheduling heuristics with genetic
programming,” Applied Soft Computing, vol. 12, no. 9, pp. 2781–2789, 2012.
[78]
A. S. Fukunaga, “Evolving local search heuristics for sat using genetic program-
ming,” in Genetic and Evolutionary Computation Conference, Springer, 2004, pp. 483–
494.
[79]
M. Bader-El-Den and R. Poli, “Generating sat local-search heuristics using a gp
hyper-heuristic framework,” in International Conference on Artiﬁcial Evolution
(Evolution Artiﬁcielle), Springer, 2007, pp. 37–49.

86
BIBLIOGRAPHY
[80]
A. K. Qin and X. Li, “Diﬀerential evolution on the cec-2013 single-objective con-
tinuous optimization testbed,” in Evolutionary Computation (CEC), 2013 IEEE
Congress on, IEEE, 2013, pp. 1099–1106.
[81]
J. Liang, B. Qu, P. Suganthan, and A. G. Hernández-Daz, “Problem deﬁnitions and
evaluation criteria for the cec 2013 special session on real-parameter optimization,”
Computational Intelligence Laboratory, Zhengzhou University, Zhengzhou, China
and Nanyang Technological University, Singapore, Technical Report, vol. 201212,
2013.
[82]
M. Gallagher and B. Yuan, “A general-purpose tunable landscape generator,” IEEE
transactions on evolutionary computation, vol. 10, no. 5, pp. 590–603, 2006.
[83]
J. Tvrdk, L. Misik, and I. Krivy, “Competing heuristics in evolutionary algorithms,”
Intell. Technol. Theory Applicat, pp. 159–165, 2002.
[84]
J. Tvrdk, “Diﬀerential evolution with competitive setting of control parameters,”
Task Quarterly, vol. 11, no. 1-2, pp. 169–179, 2007.
[85]
——, “Adaptation in diﬀerential evolution: A numerical comparison,” Applied Soft
Computing, vol. 9, no. 3, pp. 1149–1155, 2009.
[86]
J. Tvrdk and R. Poláková, “Competitive diﬀerential evolution applied to cec 2013
problems,” in Evolutionary Computation (CEC), 2013 IEEE Congress on, IEEE,
2013, pp. 1651–1657.
[87]
R. Poláková, J. Tvrdk, and P. Bujok, “Controlled restart in diﬀerential evolution
applied to cec2014 benchmark functions,” in Evolutionary Computation (CEC),
2014 IEEE Congress on, IEEE, 2014, pp. 2230–2236.
[88]
J. Tvrdk and R. Poláková, “Competitive diﬀerential evolution for constrained prob-
lems,” in Evolutionary Computation (CEC), 2010 IEEE Congress on, IEEE, 2010,
pp. 1–8.
[89]
R. Tanabe and A. Fukunaga, “Success-history based parameter adaptation for dif-
ferential evolution,” in 2013 IEEE Congress on Evolutionary Computation, Jun.
2013, pp. 71–78. doi: 10.1109/CEC.2013.6557555.
[90]
E. M. Izhikevich, “Which model to use for cortical spiking neurons?” IEEE trans-
actions on neural networks, vol. 15, no. 5, pp. 1063–1070, 2004.
[91]
A. L. Hodgkin and A. F. Huxley, “A quantitative description of membrane cur-
rent and its application to conduction and excitation in nerve,” The Journal of
physiology, vol. 117, no. 4, p. 500, 1952.
[92]
R. FitzHugh, “Impulses and physiological states in theoretical models of nerve
membrane,” Biophysical journal, vol. 1, no. 6, p. 445, 1961.
[93]
C. Morris and H. Lecar, “Voltage oscillations in the barnacle giant muscle ﬁber.,”
Biophysical journal, vol. 35, no. 1, p. 193, 1981.
[94]
B. J. Grzyb, E. Chinellato, G. M. Wojcik, and W. A. Kaminski, “Which model
to use for the liquid state machine?” In 2009 International Joint Conference on
Neural Networks, IEEE, 2009, pp. 1018–1024.
[95]
W. Gerstner and W. M. Kistler, Spiking neuron models: Single neurons, popula-
tions, plasticity. Cambridge university press, 2002.

BIBLIOGRAPHY
87
[96]
E. M. Izhikevich, “Resonate-and-ﬁre neurons,” Neural networks, vol. 14, no. 6,
pp. 883–894, 2001.
[97]
J. Hindmarsh and R. Rose, “A model of neuronal bursting using three coupled
ﬁrst order diﬀerential equations,” Proceedings of the Royal Society of London B:
Biological Sciences, vol. 221, no. 1222, pp. 87–102, 1984.
[98]
A. Citri and R. C. Malenka, “Synaptic plasticity: Multiple forms, functions, and
mechanisms,” Neuropsychopharmacology, vol. 33, no. 1, pp. 18–41, 2008.
[99]
D. O. Hebb, The organization of behavior: A neuropsychological approach. John
Wiley & Sons, 1949.
[100]
P. Dayan and L. F. Abbott, Theoretical neuroscience: Computational and mathe-
matical modeling of neural systems, 1st. The MIT Press, Dec. 2001, isbn: 9780262041997.
[Online]. Available: http://amazon.com/o/ASIN/0262041995/.
[101]
C. H. Barlow, H. Barlow, and P. Fddik, “Adaptation and decorrelation,” 1989.
[102]
E. Oja, “Simpliﬁed neuron model as a principal component analyzer,” Journal of
mathematical biology, vol. 15, no. 3, pp. 267–273, 1982.
[103]
E. L. Bienenstock, L. N. Cooper, and P. W. Munro, “Theory for the development
of neuron selectivity: Orientation speciﬁcity and binocular interaction in visual
cortex,” The Journal of Neuroscience, vol. 2, no. 1, pp. 32–48, 1982.
[104]
E. M. Izhikevich and N. S. Desai, “Relating stdp to bcm,” Neural computation, vol.
15, no. 7, pp. 1511–1523, 2003.
[105]
J.-P. Pﬁster and W. Gerstner, “Triplets of spikes in a model of spike timing-
dependent plasticity,” The Journal of neuroscience, vol. 26, no. 38, pp. 9673–9682,
2006.
[106]
S. M. Bohte, J. N. Kok, and H. La Poutre, “Error-backpropagation in temporally
encoded networks of spiking neurons,” Neurocomputing, vol. 48, no. 1, pp. 17–37,
2002.
[107]
J.-P. Pﬁster, D. Barber, and W. Gerstner, “Optimal hebbian learning: A proba-
bilistic point of view,” in Artiﬁcial Neural Networks and Neural Information Pro-
cessingICANN/ICONIP 2003, Springer, 2003, pp. 92–98.
[108]
F. Ponulak, “Resume-new supervised learning method for spiking neural networks,”
Institute of Control and Information Engineering, Poznan University of Technol-
ogy.(Available online at: Http://d1. cie. put. poznan. pl/˜ fp/research. html), 2005.
[109]
I. Sporea and A. Grüning, “Supervised learning in multilayer spiking neural net-
works,” Neural computation, vol. 25, no. 2, pp. 473–509, 2013.
[110]
A. Taherkhani, A. Belatreche, Y. Li, and L. P. Maguire, “A new biologically plau-
sible supervised learning method for spiking neurons.,” in ESANN, 2014.
[111]
E. M. Izhikevich, “Solving the distal reward problem through linkage of stdp and
dopamine signaling,” Cerebral cortex, vol. 17, no. 10, pp. 2443–2452, 2007.
[112]
B. Schrauwen and J. Van Campenhout, “Extending spikeprop,” in Neural Networks,
2004. Proceedings. 2004 IEEE International Joint Conference on, IEEE, vol. 1,
2004.

88
BIBLIOGRAPHY
[113]
O. Booij and H. tat Nguyen, “A gradient descent rule for spiking neurons emitting
multiple spikes,” Information Processing Letters, vol. 95, no. 6, pp. 552–558, 2005.
[114]
W. Maass, T. Natschläger, and H. Markram, “Real-time computing without stable
states: A new framework for neural computation based on perturbations,” Neural
computation, vol. 14, no. 11, pp. 2531–2560, 2002.
[115]
H. Hazan and L. M. Manevitz, “Topological constraints and robustness in liquid
state machines,” Expert Systems with Applications, vol. 39, no. 2, pp. 1597–1606,
2012.
[116]
M. LukoEviIus and H. Jaeger, “Reservoir computing approaches to recurrent neural
network training,” Computer Science Review, vol. 3, no. 3, pp. 127–149, 2009.
[117]
E. Goodman and D. A. Ventura, “Spatiotemporal pattern recognition via liquid
state machines,” 2006.
[118]
D. Norton and D. Ventura, “Improving liquid state machines through iterative
reﬁnement of the reservoir,” Neurocomputing, vol. 73, no. 16, pp. 2893–2904, 2010.
[119]
E. Hourdakis and P. Trahanias, “Improving the classiﬁcation performance of liquid
state machines based on the separation property,” in Engineering Applications of
Neural Networks, Springer, 2011, pp. 52–62.
[120]
G. M. Wojcik and M. Wany, “Bray-curtis metrics as measure of liquid state machine
separation ability in function of connections density,” Procedia Computer Science,
vol. 51, pp. 2979–2983, 2015.
[121]
J. Chrol-Cannon and Y. Jin, “On the correlation between reservoir metrics and
performance for time series classiﬁcation under the inﬂuence of synaptic plasticity,”
PloS one, vol. 9, no. 7, e101792, 2014.
[122]
K. P. Dockendorf, I. Park, P. He, J. C. Prìncipe, and T. B. DeMarse, “Liquid state
machines and cultured cortical networks: The separation property,” Biosystems,
vol. 95, no. 2, pp. 90–97, 2009.
[123]
Y. Zhang, P. Li, Y. Jin, and Y. Choe, “A digital liquid state machine with biologi-
cally inspired learning and its application to speech recognition,” IEEE transactions
on neural networks and learning systems, vol. 26, no. 11, pp. 2635–2649, 2015.
[124]
J. Chrol-Cannon and Y. Jin, “Learning structure of sensory inputs with synaptic
plasticity leads to interference,” Frontiers in computational neuroscience, vol. 9,
2015.
[125]
H. Paugam-Moisy, R. Martinez, and S. Bengio, “Delay learning and polychroniza-
tion for reservoir computing,” Neurocomputing, vol. 71, no. 7, pp. 1143–1158, 2008.
[126]
N. Pavlidis, O. Tasoulis, V. P. Plagianakos, G. Nikiforidis, and M. Vrahatis, “Spik-
ing neural network training using evolutionary algorithms,” in Neural Networks,
2005. IJCNN’05. Proceedings. 2005 IEEE International Joint Conference on, IEEE,
vol. 4, 2005, pp. 2190–2194.
[127]
R. A. Vazquez, “Training spiking neural models using cuckoo search algorithm,” in
Evolutionary Computation (CEC), 2011 IEEE Congress on, IEEE, 2011, pp. 679–
686.
[128]
K. Greﬀ, R. K. Srivastava, J. Koutnik, B. R. Steunebrink, and J. Schmidhuber,
“Lstm: A search space odyssey,” ArXiv preprint arXiv:1503.04069, 2015.

BIBLIOGRAPHY
89
[129]
S. Hochreiter and J. Schmidhuber, “Long short-term memory,” Neural computation,
vol. 9, no. 8, pp. 1735–1780, 1997.
[130]
J. Gjorgjieva, C. Clopath, J. Audet, and J.-P. Pﬁster, “A triplet spike-timing–
dependent plasticity model generalizes the bienenstock–cooper–munro rule to higher-
order spatiotemporal correlations,” Proceedings of the National Academy of Sci-
ences, vol. 108, no. 48, pp. 19 383–19 388, 2011.
[131]
R. Poláková, J. Tvrdk, and P. Bujok, “Evaluating the performance of l-shade with
competing strategies on cec2014 single parameter-operator test suite,” in Evolu-
tionary Computation (CEC), 2016 IEEE Congress on, IEEE, 2016, pp. 1181–1187.
[132]
. G. Rou, C. Rdoi, A. Florescu, P. Guglielmi, and M. Pastorelli, “The analysis of the
solutions for harmonic elimination pwm bipolar waveform with a specialized diﬀer-
ential evolution algorithm,” in Optimization of Electrical and Electronic Equipment
(OPTIM), 2012 13th International Conference on, IEEE, 2012, pp. 814–821.
[133]
M. Jamil and X.-S. Yang, “A literature survey of benchmark functions for global
optimisation problems,” International Journal of Mathematical Modelling and Nu-
merical Optimisation, vol. 4, no. 2, pp. 150–194, 2013.

Appendix A
Optimization benchmark problems
This appendix describes the optimization benchmark functions used as part of this project.
Table A.1 and A.2 list all basis functions, while some have been combined to form com-
pound functions which is listed in table A.3.
A.1
Test function collections
Several good test function collections have been used to compile this document.
The
resources are listed in order of importance.
• M. Jamil and X.-S. Yang, “A literature survey of benchmark functions for global
optimisation problems,” International Journal of Mathematical Modelling and Nu-
merical Optimisation, vol. 4, no. 2, pp. 150–194, 2013
• http://al-roomi.org/benchmarks/unconstrained
• http://infinity77.net/global_optimization/test_functions.html
• J. Liang, B. Qu, and P. Suganthan, “Problem deﬁnitions and evaluation criteria
for the cec 2014 special session and competition on single objective real-parameter
numerical optimization,” Computational Intelligence Laboratory, Zhengzhou Uni-
versity, Zhengzhou China and Technical Report, Nanyang Technological University,
Singapore, 2013
• J. Liang, B. Qu, P. Suganthan, et al., “Problem deﬁnitions and evaluation criteria
for the cec 2013 special session on real-parameter optimization,” Computational In-
telligence Laboratory, Zhengzhou University, Zhengzhou, China and Nanyang Tech-
nological University, Singapore, Technical Report, vol. 201212, 2013
A.2
Properties
Separability Functions where each variable can be optimized independently of the other
variables.
Modality Multimodal functions have several peaks and can have multiple local optima
which can cause the optimizer to get stuck in a local optima.
90

A.2. Properties
91
Function name
Dimensions
f1
Ackley’s Function
n
f2
Adjiman’s Function
2
f3
Alpine Function No.01
n
f4
Alpine Function No.02
n
f5
ANNs XOR Function
9
f6
Bent cigar
n
f7
Bird Function
2
f8
Brad Function
3
f9
Brown Function
n
f10
Bukin’s Function No.06
2
f11
Cosine Mixture Function
n
f12
Cross-In Tray Function
2
f13
Crowned Cross Function
2
f14
Davis’ Function
2
f15
Deﬂected Corrugated Spring Function
n
f16
Discus Function
n
f17
Downhill Step Function
2
f18
Drop-Wave Function
2
f19
Egg Crate Function
2
f20
Egg-Holder Function
n
f21
Giunta’s Function
n
f22
Griewank
n
f23
HappyCat Function
n
f24
HGBat Function
n
f25
High Conditioned Elliptic Function
n
f26
Hosaki’s Function
2
f27
Katsuura Function
n
f28
Leon’s Function
2
f29
L (or F2) Function
n
f30
Lunacek’s bi-Rastrigin Function
n
f31
Mishra’s Function No.03
2
f32
Modiﬁed Schaﬀer’s Function No.01
2
f33
Modiﬁed Schwefel function
n
f34
Pathological Function
n
f35
Paviani
10
f36
Peaks function
2
f37
Powell sum
n
f38
Price’s Function No.02
2
f39
Qing’s Function
n
f40
Quintic Function
n
f41
Rastrigin function
n
f42
Rosenbrocks Function
n
f43
Salomon’s Function
n
f44
Sawtoothxy Function
2
Table A.1: Base optimization functions - part 1

92
Chapter A. Optimization benchmark problems
Function name
Dimensions
f45
Schaﬀer’s F6
2
f46
Schwefel
n
f47
Schwefel F2.21
n
f48
Schwefel F2.26
n
f49
Shubert Function
n
f50
Shubert 3 Function
n
f51
Shubert 4 Function
n
f52
Six-Hump Camel-Back Function
2
f53
Sphere function
n
f54
Step Function No.02
n
f55
Styblinski-Tang
n
f56
Tsoulos’ Function
2
f57
Ursem Function No.03
2
f58
Ursem-Waves Function
2
f59
Venter and Sobiezcczanski-Sobieski’s Function
2
f60
W / Wavy Function
n
f61
Weierstrass
n
f62
Whitley
n
f63
Xin-She Yang’s Function No.01
n
f64
Xin-She Yang’s Function No.02
n
f65
Xin-She Yang’s Function No.03
n
f66
Xin-She Yang’s Function No.06
n
Table A.2: Base optimization functions - part 2
Function name
Dim
Composed of
f67
Expanded Griewanks plus Rosenbrocks Function
n
f22, f42
f68
Expanded Scaﬀers F6 Function
n
f45
f69
Stacked Bird, Egg-crate, Leon, Sawtoothxy
8
f7, f19, f28, f44
f70
Stacked Adjiman, Cross in Tray, Crowned cross,
Schaﬀer F6
8
f2, f12, f13, f45
f71
Stacked Davis, Downhill step, Drop-wave, Six-Hump
Camel-back
8
f14, f17, f18, f52
f72
Stacked Giunta, Hosaki, Mishra F3, Ursem F3
8
f21, f26, f31, f57
Table A.3: Compound optimization functions

A.3. Basis functions
93
A.3
Basis functions
A.3.1
Ackley’s Function
(a) Plot
(b) Contours
Figure A.1: Ackley’s function
f1(x) = −20 exp

−0.2
v
u
u
t 1
n
n
X
i=1
x2
i

−exp
 
1
n
n
X
i=1
cos(2πxi)
!
+ 20 + e
(A.1)
Bounds
−32 ≤xi ≤32
Optima
f1,min(x∗) = 0
x∗
i = 0
Properties
• n-dimensional
• Multimodal
• Non-separable
Resources
• https://www.sfu.ca/~ssurjano/ackley.html
• http://infinity77.net/global_optimization/test_functions_nd_A.html

94
Chapter A. Optimization benchmark problems
A.3.2
Adjiman’s Function
(a) Plot
(b) Contours
Figure A.2: Adjiman’s Function
f2(x) = cos(x1) sin(x2) −
x1
x2
2 + 1
(A.2)
Bounds
−5 ≤xi ≤5
Optima
f2,min(x∗) = −xmax
1
x∗
i = (xmax
1
, 0) = (5, 0)
Properties
• 2-dimensional
• Non-Separable
• Multimodal
Resources
• http://al-roomi.org/benchmarks/unconstrained/2-dimensions/113-adjiman-s-function
• http://infinity77.net/global_optimization/test_functions_nd_A.html

A.3. Basis functions
95
A.3.3
Alpine Function No.01
(a) Plot
(b) Contours
Figure A.3: Alpine Function No.01
f3(x) =
N
X
i=1
|xi sin (xi) + 0.1xi|
(A.3)
Bounds
−10 ≤xi ≤10
Optima
f3,min(x∗) = 0
x∗
i = 0
Properties
• Separable
• Multimodal
Resources
• http://al-roomi.org/benchmarks/unconstrained/n-dimensions/162-alpine-function-no-1
• http://infinity77.net/global_optimization/test_functions_nd_A.html

96
Chapter A. Optimization benchmark problems
A.3.4
Alpine Function No.02
(a) Plot
(b) Contours
Figure A.4: Alpine Function No.02
f4(x) =
n
Y
i=1
sin (xi) · √xi
(A.4)
Bounds
0 ≤xi ≤10
Optima
f4,min(x∗) = 2.8081311800070053291N
x∗
i = 7.9170526982459462172
Properties
• Separable
• Multimodal
Resources
• http://al-roomi.org/benchmarks/unconstrained/n-dimensions/163-alpine-function-no-2
• http://infinity77.net/global_optimization/test_functions_nd_A.html

A.3. Basis functions
97
A.3.5
ANNs XOR Function
f5(x) = g1(x) + g2(x) + g3(x) + g4(x)
(A.5)
where:
g1(x) =
(
1 + e
h
−
x7
1+e−(x1+x2+x5) −
x8
1+e−(x3+x4+x6) −x9
i)−2
g2(x) =
(
1 + e
h
−
x7
1+e−x5 −
x8
1+e−x6 −x9
i)−2
g3(x) =





1 −
1
1 + e
h
−
x7
1+e−(x1+x5) −
x8
1+e−(x3+x6) −x9
i





2
g4(x) =





1 −
1
1 + e
h
−
x7
1+e−(x2+x5) −
x8
1+e−(x4+x6) −x9
i





2
Bounds
−1 ≤xi ≤1
Optima
f5,min(x∗) ≈0.959759
x∗
i ≈(0.99999, 0.99993, −0.89414, 0.99994, 0.55932, 0.99994, 0.99994, −0.99963, −0.08272)
Properties
• 9-dimensional
• Multimodal
• Non-Separable
Resources
• http://al-roomi.org/benchmarks/unconstrained/9-dimensions/145-anns-xor-function

98
Chapter A. Optimization benchmark problems
A.3.6
Bent cigar
(a) Plot
(b) Contours
Figure A.5: Bent cigar Function
f6(x) = x2
1 + 106
n
X
i=2
x2
i
(A.6)
Bounds
−100 ≤xi ≤100
Optima
f6,min(x∗) = 0
x∗
i = 0
Properties
• n-dimensional
• Unimodal
Resources
• http://al-roomi.org/benchmarks/unconstrained/n-dimensions/164-bent-cigar-function

A.3. Basis functions
99
A.3.7
Bird Function
(a) Plot
(b) Contours
Figure A.6: Bird Function
f7(x) = (x1 −x2)2 + sin (x1) · e[1−cos(x2)]2 + cos (x2) · e[1−sin(x1)]2
(A.7)
Bounds
−2π ≤xi ≤2π
Optima
f7,min(x∗) = −106.7645367198034
x∗≈(4.701055751981055, 3.152946019601391) ,
(−1.582142172055011, −3.130246799635430)
Properties
• 2-dimensional
• Non-Separable
• Multimodal
Resources
• http://infinity77.net/global_optimization/test_functions_nd_B.html

100
Chapter A. Optimization benchmark problems
A.3.8
Brad Function
f8(x) =
15
X
i=1
yi −x1 −ui
vix2 + wix3
2
(A.8)
with
ui = i
vi = 16 −i
wi = min(ui, vi)
y = [0.14, 0.18, 0.22, 0.25, 0.29, 0.32, 0.35, 0.39, 0.37, 0.58, 0.73, 0.96, 1.34, 2.10, 4.39]T
Bounds
−0.25 ≤x1 ≤0.25
0.01 ≤x2, x3 ≤2.5
Optima
f8,min(X∗) = 0.00821487
x∗= (0.0824, 1.133, 2.3437)
Properties
• 3-dimensional
• Non-Separable
• Multimodal

A.3. Basis functions
101
A.3.9
Brown Function
(a) Plot
(b) Contours
Figure A.7: Brown Function
f9(x) =
n−1
X
i=1

x2
i


x2
i+1 + 1

+

x2
i+1


x2
i + 1

(A.9)
Bounds
−1 ≤xi ≤4
Optima
f9,min(x∗) = 0
x∗
i = 0
Properties
• n-dimensional
• Non-Separable
• Unimodal
Resources
• http://al-roomi.org/benchmarks/unconstrained/n-dimensions/241-brown-s-function

102
Chapter A. Optimization benchmark problems
A.3.10
Bukin’s Function No.06
(a) Plot
(b) Contours
Figure A.8: Bukin’s Function No.06
f10(x) = 100
qx2 −0.01x2
1
 + 0.01 |x1 + 10|
(A.10)
Bounds
−15 ≤x1 ≤−5, −3 ≤x2 ≤3
Optima
f10,min(x∗) = 0
x∗
i = (−10, 1)
Properties
• 2-dimensional
• Non-Separable
• Multimodal
Resources
• http://al-roomi.org/benchmarks/unconstrained/2-dimensions/52-bukin-s-function-no-6

A.3. Basis functions
103
A.3.11
Cosine Mixture Function
(a) Plot
(b) Contours
Figure A.9: Cosine Mixture Function
f11(x) = 0.1
n
X
i=1
cos (5πxi) −
n
X
i=1
x2
i
(A.11)
Bounds
−1 ≤xi ≤1
Optima
f11,max(x∗) = 0.1 for n = 1 , f11,max(x∗) = 0.2 for n = 2 etc...
x∗
i = 0
Properties
• n-dimensional
• Separable
• Multimodal
Resources
• http://infinity77.net/global_optimization/test_functions_nd_C.html
• http://al-roomi.org/benchmarks/unconstrained/n-dimensions/166-cosine-mixture-function

104
Chapter A. Optimization benchmark problems
A.3.12
Cross-In Tray Function
(a) Plot
(b) Contours
Figure A.10: Cross-In Tray Function
f12(x) = −0.0001





sin (x1) sin (x2) e
100−
p
x2
1+x2
2
π


+ 1




0.1
(A.12)
Bounds
−15 ≤xi ≤15
Optima
f12,min(x∗) = −2.062611870822739
x∗
i = ±1.349406608602084
Properties
• 2-dimensional
• Non-Separable
• Multimodal
Resources
• http://infinity77.net/global_optimization/test_functions_nd_C.html
• http://al-roomi.org/benchmarks/unconstrained/2-dimensions/44-cross-in-tray-functio

A.3. Basis functions
105
A.3.13
Crowned Cross Function
(a) Plot
(b) Contours
Figure A.11: Crowned Cross Function
f13(x) = 0.0001





sin (x1) sin (x2) e
100−
p
x2
1+x2
2
π


+ 1




0.1
(A.13)
Bounds
−10 ≤xi ≤10
Optima
f13,min(x∗) = 0.0001
x∗
i = 0
Properties
• 2-dimensional
• Non-Separable
• Multimodal
Resources
• http://al-roomi.org/benchmarks/unconstrained/2-dimensions/46-crowned-cross-function

106
Chapter A. Optimization benchmark problems
A.3.14
Davis’ Function
(a) Plot
(b) Contours
Figure A.12: Davis’ Function
f14(x) =

x2
1 + x2
2
0.25 
sin2

50

3x2
1 + x2
2
0.1
+ 1

(A.14)
Bounds
−100 ≤xi ≤100
Optima
fmin(x∗) = 0
x∗
i = 0
Properties
• 2-dimensional
• Multimodal
Resources
• http://al-roomi.org/benchmarks/unconstrained/2-dimensions/47-davis-function

A.3. Basis functions
107
A.3.15
Deﬂected Corrugated Spring Function
(a) Plot
(b) Contours
Figure A.13: Deﬂected Corrugated Spring Function
f15(x) = 0.1 ×
n
X
i=1
(xi −α)2 −cos

k ×
v
u
u
t
n
X
i=1
(xi −α)2


(A.15)
with
a = k = 5
Bounds
0 ≤xi ≤2α
Optima
f15,min(x∗) = −1
x∗
i = α
Properties
• n-dimensional
• Multimodal
Resources
• http://al-roomi.org/benchmarks/unconstrained/n-dimensions/238-deflected-corrugated-spri
• http://infinity77.net/global_optimization/test_functions_nd_D.html

108
Chapter A. Optimization benchmark problems
A.3.16
Discus Function
(a) Plot
(b) Contours
Figure A.14: Discuss function
f16(x) = 106x2
1 +
n
X
i=1
x2
i
(A.16)
Bounds
−100 ≤xi ≤100
Optima
f16,min(x∗) = 0
x∗
i = 0
Properties
• n-dimensional
• Separable
• Unimodal

A.3. Basis functions
109
A.3.17
Downhill Step Function
(a) Plot
(b) Contours
Figure A.15: Downhill Step Function
f17(x) =
j
10 ×

10 −e−x2
1−3x2
2
k
10
(A.17)
Bounds
−10 ≤xi ≤10
Optima
f17,min(x∗) = 9
x∗
i = (0, 0)
Properties
• 2-dimensional
• Separable
• Unimodal
Resources
• http://al-roomi.org/benchmarks/unconstrained/2-dimensions/114-downhill-step-function

110
Chapter A. Optimization benchmark problems
A.3.18
Drop-Wave Function
(a) Plot
(b) Contours
Figure A.16: Drop-Wave Function
f18(x) = −
1 + cos

12
q
x2
1 + x2
2

1
2
 x2
1 + x2
2
 + 2
(A.18)
Bounds
−5.12 ≤xi ≤5.12
Optima
f18,min(x∗) = −1
x∗
i = 0
Properties
• 2-dimensional
• Non-separable
• Multimodal
Resources
• https://www.sfu.ca/~ssurjano/drop.html
• http://al-roomi.org/benchmarks/unconstrained/2-dimensions/54-drop-wave-function
• http://infinity77.net/global_optimization/test_functions_nd_D.html

A.3. Basis functions
111
A.3.19
Egg Crate Function
(a) Plot
(b) Contours
Figure A.17: Egg Crate Function
f19(x) = x2
1 + x2
2 + 25
h
sin2 (x1) + sin2 (x2)
i
(A.19)
Bounds
−5 ≤xi ≤5
Optima
f19,min(x∗) = 0
x∗
i = 0
Properties
• 2-dimensional
• Separable
Resources
• http://benchmarkfcns.xyz/benchmarkfcns/eggcratefcn.html
• http://al-roomi.org/benchmarks/unconstrained/2-dimensions/122-egg-crate-function
• http://infinity77.net/global_optimization/test_functions_nd_E.html

112
Chapter A. Optimization benchmark problems
A.3.20
Egg-Holder Function
(a) Plot
(b) Contours
Figure A.18: Egg-Holder Function
f20(x) =
n−1
X
i=1

−xi sin
q
|xi −xi+1 −47|

−(xi+1 + 47) sin
q
|0.5xi + xi+1 + 47|

(A.20)
Bounds
512 ≤xi ≤512
Optima
f20,min(x∗) = −959.640662720850742 for n = 2
x∗= (512, 404.231805123817)
Properties
• n-dimensional
• Non-Separable
• Multimodal
Resources
• https://www.sfu.ca/~ssurjano/egg.html
• http://al-roomi.org/benchmarks/unconstrained/n-dimensions/187-egg-holder-function
• http://infinity77.net/global_optimization/test_functions_nd_E.html

A.3. Basis functions
113
A.3.21
Giunta’s Function
(a) Plot
(b) Contours
Figure A.19: Giunta’s Function
f21(x) = 0.6 +
n
X
i=1

sin2

1 −16
15xi

−1
50 sin

4 −64
15xi

−sin

1 −16
15xi

(A.21)
Bounds
−1 ≤xi ≤1
Optima
f21,min(x∗) = 0.06447042053690566
x∗= (0.4673200277395354, 0.4673200169591304)
Properties
• N-dimensional
• Separable
• Multimodal
Resources
• http://al-roomi.org/benchmarks/unconstrained/2-dimensions/154-giunta-s-function
• http://infinity77.net/global_optimization/test_functions_nd_G.html

114
Chapter A. Optimization benchmark problems
A.3.22
Griewank
(a) Plot
(b) Contours
Figure A.20: Griewank function
f22(x) =
1
4000
n
X
i=1
x2
i −
n
Y
i=1
cos
 xi
√
i

+ 1
(A.22)
Bounds
−600 ≤xi ≤600
Optima
f22,min(x∗) = 0
x∗
i = 0
Properties
• n-dimensional
• Non-Separable
• Multimodal
Resources
• http://infinity77.net/global_optimization/test_functions_nd_G.html
• https://www.sfu.ca/~ssurjano/griewank.html
• http://mathworld.wolfram.com/GriewankFunction.html

A.3. Basis functions
115
A.3.23
HappyCat Function
(a) Plot
(b) Contours
Figure A.21: HappyCat function
f23(x) =

n
X
i=1
x2
i −N

1/4
+
 0.5 Pn
i=1 x2
i + Pn
i=1 xi

N
+ 0.5
(A.23)
Bounds
−100 ≤xi ≤100
Optima
Unknown
Properties
• n-dimensional
• Non-separable
• Multimodal
Resources
• J. Liang, B. Qu, and P. Suganthan, “Problem deﬁnitions and evaluation criteria
for the cec 2014 special session and competition on single objective real-parameter
numerical optimization,” Computational Intelligence Laboratory, Zhengzhou Uni-
versity, Zhengzhou China and Technical Report, Nanyang Technological University,
Singapore, 2013

116
Chapter A. Optimization benchmark problems
A.3.24
HGBat Function
(a) Plot
(b) Contours
Figure A.22: HGBat function
f24(x) =

 n
X
i=1
x2
i
!2
−
 n
X
i=1
xi
!2
1/4
+
 0.5 Pn
i=1 x2
i + Pn
i=1 xi

N
+ 0.5
(A.24)
Bounds
−100 ≤xi ≤100
Optima
Unknown
Properties
• n-dimensional
• Non-separable
• Multimodal
Resources
• J. Liang, B. Qu, and P. Suganthan, “Problem deﬁnitions and evaluation criteria
for the cec 2014 special session and competition on single objective real-parameter
numerical optimization,” Computational Intelligence Laboratory, Zhengzhou Uni-
versity, Zhengzhou China and Technical Report, Nanyang Technological University,
Singapore, 2013

A.3. Basis functions
117
A.3.25
High Conditioned Elliptic Function
(a) Plot
(b) Contours
Figure A.23: High Conditioned Elliptic Function
f25(x) =
n
X
i=1
(106)
i−1
N−1 x2
i
(A.25)
Bounds
−100 ≤xi ≤100
Optima
Unknown
Properties
• n-dimensional
• Separable
• Unimodal
Resources
• J. Liang, B. Qu, and P. Suganthan, “Problem deﬁnitions and evaluation criteria
for the cec 2014 special session and competition on single objective real-parameter
numerical optimization,” Computational Intelligence Laboratory, Zhengzhou Uni-
versity, Zhengzhou China and Technical Report, Nanyang Technological University,
Singapore, 2013

118
Chapter A. Optimization benchmark problems
A.3.26
Hosaki’s Function
(a) Plot
(b) Contours
Figure A.24: Hosaki’s Function
f26(x) =

1 −8x1 + 7x2
1 −7
3x3
1 + 1
4x4
1

x2
2e−x2
(A.26)
Bounds
0 ≤xi ≤10
Optima
f26,min(x∗) = −2.345811576101292
x∗= (4, 2)
Properties
• 2-dimensional
• Non-Separable
• Multimodal
Resources
• http://al-roomi.org/benchmarks/unconstrained/2-dimensions/58-hosaki-s-function
• http://infinity77.net/global_optimization/test_functions_nd_H.html

A.3. Basis functions
119
A.3.27
Katsuura Function
(a) Plot
(b) Contours
Figure A.25: Katsuura Function function
f27(x) = 10
n2
n
Y
i=1
(1 + i
32
X
j=1
2jxi −round(2jxi)

2j
)
10
n1.2 −10
n2
(A.27)
Bounds
−100 ≤xi ≤100
Optima
f27,min(x∗) = 0
x∗
i = 0
Properties
• n-dimensional
• Non-Separable
• Multimodal
Resources
• J. Liang, B. Qu, and P. Suganthan, “Problem deﬁnitions and evaluation criteria
for the cec 2014 special session and competition on single objective real-parameter
numerical optimization,” Computational Intelligence Laboratory, Zhengzhou Uni-
versity, Zhengzhou China and Technical Report, Nanyang Technological University,
Singapore, 2013

120
Chapter A. Optimization benchmark problems
A.3.28
Leon’s Function
(a) Plot
(b) Contours
Figure A.26: Leon’s Function
f28(x) = 100

x2 −x3
1
2 + (1 −x1)2
(A.28)
Bounds
−1.2 ≤xi ≤1.2
Optima
f28,min(x∗) = 0
x∗= (1, 1)
Properties
• 2-dimensional
• Non-Separable
• Unimodal
Resources
• http://al-roomi.org/benchmarks/unconstrained/2-dimensions/125-leon-s-function

A.3. Basis functions
121
A.3.29
L (or F2) Function
(a) Plot
(b) Contours
Figure A.27: L (or F2) Function
f29(x) = −
n
Y
i=1
sink (l1πxi + l2) · e
−l3
xi −l4
l5
2
(A.29)
With:
k = 6, l1 = 5.1, l2 = 0.5, l3 = 4 ln(2), l4 = 0.066832364099628, l5 = 0.64
Bounds
0 ≤xi ≤1
Optima
f29,min(x∗) = −1
x∗
i = l4
Properties
• n-dimensional
• Non-seperable
• Multimodal
Resources
• http://al-roomi.org/benchmarks/unconstrained/n-dimensions/276-l-or-f2-function

122
Chapter A. Optimization benchmark problems
A.3.30
Lunacek’s bi-Rastrigin Function
(a) Plot
(b) Contours
Figure A.28: Lunacek’s bi-Rastrigin Function
f30(x) = min
"
n
X
i=1
(xi −µ1)2 , d · n + s ·
n
X
i=1
(xi −µ2)2
#
+ 10
n
X
i=1
(
1 −cos [2π (xi −µ1)]
)
(A.30)
µ1 = 2.5
µ2 = −
s
µ2
1 −d
s
d ∈1, 2, 3, 4 standardized with d = 1
s ∈[0.2, 1.4] standardized with s = 1 −
1
2√2 + 20 −8.2
Bounds
−5.12 ≤xi ≤5.12
Optima
For N = 1, 2:
f30,min(x∗) = 0
x∗
i = µ1
Properties
• n-dimensional
• Multimodal
Resources
• http://al-roomi.org/benchmarks/unconstrained/n-dimensions/229-lunacek-s-bi-rastrig

A.3. Basis functions
123
A.3.31
Mishra’s Function No.03
(a) Plot
(b) Contours
Figure A.29: Mishra’s Function No.03
f32(x) =
cos
qx2
1 + x2


0.5
+ x1 + x2
100
(A.31)
Bounds
−10 ≤xi ≤10
Optima
f31,min(x∗) = −0.184651333342989
x∗= (−8.466613775046579, −9.998521308999999)
Properties
• 2-dimensional
• Non-Separable
• Multimodal
Resources
• http://al-roomi.org/benchmarks/unconstrained/2-dimensions/138-mishra-s-function-no-3

124
Chapter A. Optimization benchmark problems
A.3.32
Modiﬁed Schaﬀer’s Function No.01
(a) Plot
(b) Contours
Figure A.30: Modiﬁed Schaﬀer’s Function No.01
f32(x) = 0.5 +
sin2  x2
1 + x2
2
 −0.5
1 + 0.001
 x2
1 + x2
2
2
(A.32)
Bounds
−100 ≤xi ≤100
Optima
f32,min(x∗) = 0
x∗
i = 0
Properties
• 2-dimensional
• Multimodal
Resources
• http://al-roomi.org/benchmarks/unconstrained/2-dimensions/96-modified-schaffer-s-f

A.3. Basis functions
125
A.3.33
Modiﬁed Schwefel function
(a) Plot
(b) Contours
Figure A.31: Modiﬁed Schwefel function
f33(x) = 418.9829n −
n
X
i=1
g(zi),
(A.33)
zi = xi + 4.209687462275036e + 002
g(zi) =







zi sin(|zi|1/2)
if |zi| ≤500
(500 −mod(zi, 500)) sin(
p
|500 −mod(zi, 500)|) −(zi−500)2
10000n
if zi > 500
(mod(|zi| , 500) −500) sin(
p
|mod(|zi| , 500) −500|) −(zi+500)2
10000n
if zi < −500
Bounds
−100 ≤xi ≤100
Optima
f33,min(x∗) = 0
x∗
i = 0
Properties
• n-dimensional
• Multimodal

126
Chapter A. Optimization benchmark problems
A.3.34
Pathological Function
(a) Plot
(b) Contours
Figure A.32: Pathological Function
f34(x) =
n−1
X
i=1

0.5 +
sin2 q
100x2
i + x2
i+1

−0.5
1 + 0.001

x2
i −2xixi+1 + x2
i+1
2


(A.34)
Bounds
−100 ≤xi ≤100
Optima
f34,min(x∗) = 0
x∗
i = 0
Properties
• n-dimensional
• Non-Separable
• Multimodal
Resources
• http://al-roomi.org/benchmarks/unconstrained/n-dimensions/239-pathological-functio

A.3. Basis functions
127
A.3.35
Paviani
f35(x) =
10
X
i=1
h
log2(10 −xi) + log2(xi −2)
i
−
 10
Y
i=1
x10
i
!0.2
(A.35)
Bounds
2.001 ≤xi ≤9.999
Optima
f35,min(x∗) = −45.7784684040686
x∗
i = 9.350266
Properties
• 10-dimensional
• Non-Separable
• Multimodal
Resources
• http://infinity77.net/global_optimization/test_functions_nd_P.html

128
Chapter A. Optimization benchmark problems
A.3.36
Peaks function
(a) Plot
(b) Contours
Figure A.33: Peaks function
f36(x) = g1(x) −g2(x) −g3(x)
(A.36)
where:
g1(x) = 3 (1 −x1)2 e
h
−x2
1 −(x2 + 1)2i
g2(x) = 10
x1
5 −x3
1 −x5
2

e

−x2
1 −x2
2

g3(x) = 1
3e
h
−(x1 + 1)2 −x2
2
i
Bounds
−4 ≤xi ≤4
Optima
f36,min(x∗) = −6.551133332622496
x∗≈(0.228279999979237, −1.625531071954464)
Properties
• 2-dimensional
• Non-separable
• Multimodal
Resources
• http://al-roomi.org/benchmarks/unconstrained/2-dimensions/63-peaks-function

A.3. Basis functions
129
A.3.37
Powell sum
(a) Plot
(b) Contours
Figure A.34: Powell sum function
f37(x) =
n
X
i=1
|xi|i+1
(A.37)
Bounds
−1 ≤xi ≤1
Optima
f37,min(x∗) = 0
x∗
i = 0
Properties
• n-dimensional
• Separable
• Unimodal
Resources
• http://benchmarkfcns.xyz/benchmarkfcns/powellsumfcn.html

130
Chapter A. Optimization benchmark problems
A.3.38
Price’s Function No.02
(a) Plot
(b) Contours
Figure A.35: Price’s Function No.02
f38(x) = 1 + sin2 (x1) + sin2 (x2) −0.1e
 −x2
1−x2
2

(A.38)
Bounds
−10 ≤xi ≤10
Optima
f38,min(x∗) = 0.9
x∗
i = 0
Properties
• 2-dimensional
• Non-Separable
• Multimodal
Resources
• http://al-roomi.org/benchmarks/unconstrained/2-dimensions/158-price-s-function-no-

A.3. Basis functions
131
A.3.39
Qing’s Function
(a) Plot
(b) Contours
Figure A.36: Qing function
f39(x) =
n
X
i=1

x2
i −i
2
(A.39)
Bounds
−500 ≤xi ≤500
Optima
f39,min(x∗) = 0
x∗
i = ±
√
i
Properties
• n-dimensional
• Separable
• Multimodal
Resources
• http://al-roomi.org/benchmarks/unconstrained/n-dimensions/185-qing-s-function

132
Chapter A. Optimization benchmark problems
A.3.40
Quintic Function
(a) Plot
(b) Contours
Figure A.37: Quintic Function
f40(x) =
n
X
i=1
x5
i −3x4
i + 4x3
i + 2x2
i −10xi −4

(A.40)
Bounds
−10 ≤xi ≤10
Optima
f40,min(X∗) = 0
x∗= (−1, 2)
Properties
• n-dimensional
• Separable
• Multimodal
Resources
• http://al-roomi.org/benchmarks/unconstrained/n-dimensions/240-quintic-function

A.3. Basis functions
133
A.3.41
Rastrigin function
(a) Plot
(b) Contours
Figure A.38: Rastrigin function
f41(x) = 10n +
n
X
i=1
(x2
i −10cos(2πxi))
(A.41)
Bounds
−5.12 ≤xi ≤5.12
Optima
f41,min(x∗) = 0
x∗
i = 0
Properties
• n-dimensional
• Non-separable
• Multimodal
Resources
• https://en.wikipedia.org/wiki/Rastrigin_function
• https://www.sfu.ca/~ssurjano/rastr.html

134
Chapter A. Optimization benchmark problems
A.3.42
Rosenbrocks Function
(a) Plot
(b) Contours
Figure A.39: Rosenbrocks Function
f42(x) =
n−1
X
i=1
(100(x2
i −xi+1)2 + (1 −xi)2)
(A.42)
Bounds
−30 ≤xi ≤30
Optima
f42,min(x∗) = 0
x∗
i = 1
Properties
• n-dimensional
• Non-Separable
• Unimodal
Resources
• https://en.wikipedia.org/wiki/Rosenbrock_function
• https://www.sfu.ca/~ssurjano/rosen.html

A.3. Basis functions
135
A.3.43
Salomon’s Function
(a) Plot
(b) Contours
Figure A.40: Salomon’s Function
f43(x) = 1 −cos (2π ∥x∥) + 0.1 ∥x∥
(A.43)
with
∥x∥=
v
u
u
t
n
X
i=1
x2
i
Bounds
−100 ≤xi ≤100
Optima
f43,min(x∗) = 0
x∗
i = 0
Properties
• n-dimensional
• Non-Separable
• Multimodal
Resources
• http://al-roomi.org/benchmarks/unconstrained/n-dimensions/184-salomon-s-function

136
Chapter A. Optimization benchmark problems
A.3.44
Sawtoothxy Function
(a) Plot
(b) Contours
Figure A.41: Egg Crate Function
f44(x) = g(r) · h(t)
(A.44)
g(r) =

sin(r) −sin(2r)
2
+ sin(3r)
3
−sin(4r)
4
+ 4
  
r2
r + 1
!
h(t) = 1
2 cos

2t −1
2

+ cos(t) + 2
r =
q
x2
1 + x2
2
t = atan2 (x2, x1)
Bounds
−20 ≤xi ≤20
Optima
f44,min(x∗) = 0
x∗
i = 0
Properties
• 2-dimensional
• Non-Separable
• Multimodal
Resources
• http://al-roomi.org/benchmarks/unconstrained/2-dimensions/66-sawtoothxy-function

A.3. Basis functions
137
A.3.45
Schaﬀer’s F6
(a) Plot
(b) Contours
Figure A.42: Schaﬀer’s F6
f45(x) = 0.5 +
sin2(
q
x2
1 + x2
2) −0.5
[1 + 0.001 · (x2
1 + x2
2)]2
(A.45)
Bounds
−100 ≤xi ≤100
Optima
f45,min(x∗) = 0
x∗= (0, 0)
Properties
• 2-dimensional
• Non-Seperable
• Multimodal
Resources
• http://www.cs.unm.edu/~neal.holts/dga/benchmarkFunction/schafferf6.html

138
Chapter A. Optimization benchmark problems
A.3.46
Schwefel
(a) Plot
(b) Contours
Figure A.43: Schwefel function
f46(x) =
n
X
i=1
(−xisin(
q
|xi|)) + α · n
(A.46)
α = 418.982887
Bounds
−512 ≤xi ≤512
Optima
f46,min(x∗) = 0
x∗
i = 420.968746
Properties
• n-dimensional
• Separable
• Multimodal
Resources
• https://www.sfu.ca/~ssurjano/schwef.html

A.3. Basis functions
139
A.3.47
Schwefel F2.21
(a) Plot
(b) Contours
Figure A.44: Schwefel F2.21 Function
f47(x) = max
i
{|xi|, 1 ≤i ≤n}
(A.47)
Bounds
−100 ≤xi ≤100
Optima
f47min(x∗) = 0
x∗
i = 0
Properties
• n-dimensional
• Separable
• Unimodal
Resources
• http://al-roomi.org/benchmarks/unconstrained/n-dimensions/189-schwefel-s-function-no-2-

140
Chapter A. Optimization benchmark problems
A.3.48
Schwefel F2.26
(a) Plot
(b) Contours
Figure A.45: Schwefel F2.26 Function
f48(x) = −1
n
n
X
i=1
xi sin
q
|xi|
(A.48)
Bounds
−500 ≤xi ≤500
Optima
f48,min(x∗) = −418.983
x∗
i = ±[π(0.6 + k)]2
Properties
• n-dimensional
• Separable
• Multimodal
Resources
• http://al-roomi.org/benchmarks/unconstrained/n-dimensions/176-generalized-schwefel

A.3. Basis functions
141
A.3.49
Shubert Function
(a) Plot
(b) Contours
Figure A.46: Shubert Function
f49(x) =
n
Y
i=1


5
X
j=1
cos((j + 1)xi + j)


(A.49)
Bounds
−10 ≤xi ≤10
Optima
fmin(x∗) = −186.7309
Properties
• n-dimensional
• Separable
• Multimodal
Resources
• https://www.sfu.ca/~ssurjano/shubert.html
• http://infinity77.net/global_optimization/test_functions_nd_S.html

142
Chapter A. Optimization benchmark problems
A.3.50
Shubert 3 Function
(a) Plot
(b) Contours
Figure A.47: Shubert 3 Function
f50(x) =
n
X
i=1
5
X
j=1
j sin((j + 1)xi + j)
(A.50)
Bounds
−10 ≤xi ≤10
Optima
f50,min(x∗) = −29.6733337
Multiple solutions.
Properties
• n-dimensional
• Separable
• Multimodal
Resources
• http://infinity77.net/global_optimization/test_functions_nd_S.html

A.3. Basis functions
143
A.3.51
Shubert 4 Function
(a) Plot
(b) Contours
Figure A.48: Shubert 4 Function
f51(x) =
n
X
i=1
5
X
j=1
j cos((j + 1)xi + j)
(A.51)
Bounds
−10 ≤xi ≤10
Optima
fmin(x∗) = −25.740858
Multiple solutions.
Properties
• n-dimensional
• Separable
• Multimodal
Resources
• http://infinity77.net/global_optimization/test_functions_nd_S.html

144
Chapter A. Optimization benchmark problems
A.3.52
Six-Hump Camel-Back Function
(a) Plot
(b) Contours
Figure A.49: Six-Hump Camel-Back Function
f52(x) = 4x2
1 −2.1x4
1 + 1
3x6
1 + x1x2 −4x2
2 + 4x4
2
(A.52)
Bounds
−5 ≤xi ≤5
Optima
f52,min(x∗) = −1.031628453489877
x∗≈(±0.08984201368301331, ±0.7126564032704135)
Properties
• 2-dimensional
• Multimodal
Resources
• http://infinity77.net/global_optimization/test_functions_nd_S.html
• https://www.sfu.ca/~ssurjano/camel6.html

A.3. Basis functions
145
A.3.53
Sphere function
(a) Plot
(b) Contours
Figure A.50: Sphere function
f53(x) =
n
X
i=1
x2
i
(A.53)
Bounds
−100 ≤xi ≤100
Optima
f53,min(x∗) = 0
x∗
i = 0
Properties
• n-dimensional
• Separable
• Unimodal

146
Chapter A. Optimization benchmark problems
A.3.54
Step Function No.02
(a) Plot
(b) Contours
Figure A.51: Step Function No.02 function
f(x) =
n
X
i=1
(⌊|xi + 0.5|⌋)2
(A.54)
Bounds
−100 ≤xi ≤100
Optima
f54,min(x∗) = 0
−0.5 ≤x∗
i < 0.5
Properties
• n-dimensional
• Separable
• Unimodal
Resources
• http://al-roomi.org/benchmarks/unconstrained/n-dimensions/193-step-function-no-2

A.3. Basis functions
147
A.3.55
Styblinski-Tang
(a) Plot
(b) Contours
Figure A.52: Styblinski-Tang
f55(x) =
n
X
i=1

x4
i −16x2
i + 5xi

(A.55)
Bounds
−5 ≤xi ≤5
Optima
f55,min(x∗) = −39.16616570377142n
x∗
i = −2.903534018185960
Properties
• n-dimensional
• Non-Separable
• Multimodal
Resources
• https://www.sfu.ca/~ssurjano/stybtang.html

148
Chapter A. Optimization benchmark problems
A.3.56
Tsoulos’ Function
(a) Plot
(b) Contours
Figure A.53: Tsoulos’ Function
f56(x) = x2
1 + x2
2 −cos (18x1) −cos (18x2)
(A.56)
Bounds
−1 ≤xi ≤1
Optima
f56,min(x∗) = −2
x∗= (0, 0)
Properties
• 2-dimensional
• Multimodal
Resources
• http://al-roomi.org/benchmarks/unconstrained/2-dimensions/106-tsoulos-function

A.3. Basis functions
149
A.3.57
Ursem Function No.03
(a) Plot
(b) Contours
Figure A.54: Ursem Function No.03
f57(x) = −3 −|x1|
2
.2 −|x2|
2
. sin (2.2πx1 + 0.5π) −2 −|x1|
2
.2 −|x2|
2
. sin

0.5πx2
2 + 0.5π

(A.57)
Bounds
−2 ≤x1 ≤2
−1.5 ≤x2 ≤1.5
Optima
f57,min(x∗) = −2.5
x∗
i = 0
Properties
• 2-dimensional
• Non-separable
Resources
• http://al-roomi.org/benchmarks/unconstrained/2-dimensions/130-ursem-function-no-3

150
Chapter A. Optimization benchmark problems
A.3.58
Ursem-Waves Function
(a) Plot
(b) Contours
Figure A.55: Ursem-Waves Function
f58(x) = −(0.3x1)3 +

x2
2 −4.5x2
2

x1x2 + 4.7 cos
h
3x1 −x2
2 (2 + x1)
i
sin (2.5πx1) (A.58)
Bounds
−0.9 ≤x1 ≤1.2, −1.2 ≤x2 ≤1.2
Optima
f58,min(x∗) = −7.306998731324462
x∗= (−0.605689494589848, −1.177561933039789)
Properties
• 2-dimensional
• Non-separable
Resources
• http://infinity77.net/global_optimization/test_functions_nd_U.html
• http://al-roomi.org/benchmarks/unconstrained/2-dimensions/132-ursem-wave-function

A.3. Basis functions
151
A.3.59
Venter and Sobiezcczanski-Sobieski’s Function
(a) Plot
(b) Contours
Figure A.56: Venter Sobiezcczanski-Sobieski function
f59(x) =
n
X
i=1
"
x2
i −100 cos2 (xi) −100 cos
 
x2
i
30
! #
+ 1400
(A.59)
Bounds
−50 ≤xi ≤10
Optima
f59,min(x∗) = 1000
x∗
i = 0
Properties
• 2-dimensional
• Separable
Resources
• http://al-roomi.org/benchmarks/unconstrained/2-dimensions/108-venter-and-sobiezcczanski
• http://infinity77.net/global_optimization/test_functions_nd_V.html

152
Chapter A. Optimization benchmark problems
A.3.60
W / Wavy Function
(a) Plot
(b) Contours
Figure A.57: W / Wavy Function
f60(x) = 1
n
n
X
i=1
1 −cos (kxi) e−1
2 x2
i
(A.60)
k = 10
Bounds
−π ≤xi ≤π
Optima
f60,min(x∗) = 0
x∗
i = 0
Properties
• n-dimensional
• Separable
• Multimodal
Resources
• http://al-roomi.org/benchmarks/unconstrained/n-dimensions/280-w-wavy-function
• http://infinity77.net/global_optimization/test_functions_nd_W.html

A.3. Basis functions
153
A.3.61
Weierstrass
(a) Plot
(b) Contours
Figure A.58: Weierstrass function
f61(x) =
n
X
i=1


kmax
X
k=0
h
ak cos(2πbk(xi + 0.5))
i
−n
kmax
X
k=0
h
ak cos(2πbk · 0.5)
i


(A.61)
Bounds
−0.5 ≤xi ≤0.5
Optima
f61,min(x∗) = 0
x∗
i = 0
Properties
• n-dimensional
• Separable
• Multimodal
Resources
• http://infinity77.net/global_optimization/test_functions_nd_W.html

154
Chapter A. Optimization benchmark problems
A.3.62
Whitley
(a) Plot
(b) Contours
Figure A.59: Whitley Function
f62(x) =
n
X
i=1
n
X
j=1



100
 x2
i −xj
2 + (1 −xj)22
4000
−cos

100

x2
i −xj
2 + (1 −xj)2 + 1



(A.62)
Bounds
−10.24 ≤xi ≤10.24
Optima
f62,min(x∗) = 0
x∗
i = 1
Properties
• n-dimensional
• Non-Separable
• Multimodal
Resources
• http://infinity77.net/global_optimization/test_functions_nd_W.html
• http://www.cs.unm.edu/~neal.holts/dga/benchmarkFunction/whitley.html

A.3. Basis functions
155
A.3.63
Xin-She Yang’s Function No.01
(a) Plot
(b) Contours
Figure A.60: Xin-She Yang’s Function No.01
f63(x) =

e−Pn
i=1
  xi
β
2m
−2e−Pn
i=1(xi−c)2
·
n
Y
i=1
cos2 (xi)
(A.63)
c can be any value, usually c = 0 or c = π
m = 5
β = 15
Bounds
−20 ≤xi ≤20
Optima
f63,min(x∗) = −1
x∗
i = c
Properties
• n-dimensional
• Non-separable
Resources
• http://al-roomi.org/benchmarks/unconstrained/n-dimensions/262-xin-she-yang-s-function-n

156
Chapter A. Optimization benchmark problems
A.3.64
Xin-She Yang’s Function No.02
(a) Plot
(b) Contours
Figure A.61: Xin-She Yang’s Function No.02
f64(x) =
 n
X
i=1
|xi|
!
· e
−
n
X
i=1
x2
i
(A.64)
Bounds
−10 ≤xi ≤10
Optima
For n = 1:
f64,max(x∗) = 0.428881942480354
x∗= ±0.707106781903310
For n = 2:
f64,max(x∗) =
1
√
e1 = 0.606530659712633
x∗
i = ±1
2
Properties
• n-dimensional
Resources
• http://al-roomi.org/benchmarks/unconstrained/n-dimensions/264-xin-she-yang-s-funct

A.3. Basis functions
157
A.3.65
Xin-She Yang’s Function No.03
(a) Plot
(b) Contours
Figure A.62: Xin-She Yang’s Function No.03
f65(x) =
 n
X
i=1
|xi|
!
· e−Pn
i=1 sin x2
i

(A.65)
Bounds
−2π ≤xi ≤2π
Optima
f65,min(x∗) = 0
x∗
i = 0
Properties
• n-dimensional
Resources
• http://al-roomi.org/benchmarks/unconstrained/n-dimensions/263-xin-she-yang-s-function-n

158
Chapter A. Optimization benchmark problems
A.3.66
Xin-She Yang’s Function No.06
(a) Plot
(b) Contours
Figure A.63: Xin-She Yang’s Function No.06
f66(x) =
(" n
X
i=1
sin2 (xi)
#
−e−Pn
i=1 x2
i
)
· e
−
n
X
i=1
sin2
q
|xi|

(A.66)
Bounds
−10 ≤xi ≤10
Optima
f66,min(x∗) = −1
x∗
i = 0
Properties
• n-dimensional
• Non-separable
Resources
• http://al-roomi.org/benchmarks/unconstrained/n-dimensions/268-xin-she-yang-s-funct

A.4. Compound functions
159
A.4
Compound functions
A.4.1
Expanded Griewanks plus Rosenbrocks Function
(a) Plot
(b) Contours
Figure A.64: Expanded Griewanks plus Rosenbrocks Function
f67(x) = f22(f42(x1, x2)) + f22(f42(x2, x3)) + · · · + f22(f42(xn−1, xn)) + f22(f42(xn, x1))
(A.67)
Bounds
−100 ≤xi ≤100
Optima
f67,min(x∗) = 0
x∗
i = 0
Properties
• n-dimensional
• Non-Separable
• Multimodal

160
Chapter A. Optimization benchmark problems
A.4.2
Expanded Scaﬀers F6 Function
(a) Plot
(b) Contours
Figure A.65: Expanded Scaﬀers F6 function
f68(x) = f45(x1, x2) + f45(x2, x3) + · · · + f45(xn−1, xn) + f45(xn, x1)
(A.68)
Bounds
−100 ≤xi ≤100
Optima
f68,min(x∗) = 0
x∗= (0, 0)
Properties
• n-dimensional
• Non-Seperable
• Multimodal

A.4. Compound functions
161
A.4.3
Stacked Bird, Egg-crate, Leon, Sawtoothxy
f69(x) = f7(x1, x2) + f19(x3, x4) + f28(x5, x6) + f44(x7, x8)
(A.69)
Bounds
−2π ≤x1, x2 ≤2π
−5 ≤x3, x4 ≤5
−1.2 ≤x5, x6 ≤1.2
−20 ≤x7, x8 ≤20
Optima
f69,min(x∗) = −106.7645367198034
x∗= (4.701055751981055, 3.152946019601391, 0, 0, 1, 1, 0, 0) ,
x∗= (−1.582142172055011, −3.130246799635430, 0, 0, 1, 1, 0, 0)
Properties
• n-dimensional
• Non-Seperable
• Multimodal

162
Chapter A. Optimization benchmark problems
A.4.4
Stacked Adjiman, Cross in Tray, Crowned cross, Schaﬀer F6
f70(x) = f2(x1, x2) + f12(x3, x4) + f13(x5, x6) + f45(x7, x8)
(A.70)
Bounds
−5 ≤x1, x2 ≤5
−15 ≤x3, x4 ≤15
−10 ≤x5, x6 ≤10
−100 ≤x7, x8 ≤100
Optima
f70,min(x∗) = −xmax
1
−2.062611870822739
x∗= (xmax
1
, 0, ±1.349406608602084, ±1.349406608602084, 0, 0, 0, 0)
Properties
• n-dimensional
• Non-Seperable
• Multimodal
A.4.5
Stacked Davis, Downhill step, Drop-wave, Six-Hump Camel-back
f71(x) = f14(x1, x2) + f17(x3, x4) + f18(x5, x6) + f52(x7, x8)
(A.71)
Bounds
−100 ≤x1, x2 ≤100
−10 ≤xi ≤10
−5.12 ≤xi ≤5.12
−5 ≤xi ≤5
Optima
f71,min(x∗) = 6.968371547
x∗= (0, 0, 0, 0, 0, 0, ±0.08984201368301331, ±0.7126564032704135)
Properties
• n-dimensional
• Non-Seperable
• Multimodal

A.4. Compound functions
163
A.4.6
Stacked Giunta, Hosaki, Mishra F3, Ursem F3
f72(x) = f21(x1, x2) + f26(x3, x4) + f31(x5, x6) + f57(x7, x8)
(A.72)
Bounds
−1 ≤x1, x2 ≤1
0 ≤x3, x4 ≤10
−10 ≤x5, x6 ≤10
−2 ≤x7 ≤2
−1.5 ≤x8 ≤1.5
Optima
f72,min(x∗) = −4.965992489
x∗= (0.4673200277395354, 0.4673200169591304, 4, 2,
−8.466613775046579, −9.998521308999999, 0, 0)
Properties
• n-dimensional
• Non-Seperable
• Multimodal




