Mark Joshi
Proof 
Patterns

Proof Patterns

Mark Joshi
Proof Patterns
123

Mark Joshi
Centre for Actuarial Studies
University of Melbourne
Melbourne, VIC
Australia
ISBN 978-3-319-16249-2
ISBN 978-3-319-16250-8
(eBook)
DOI 10.1007/978-3-319-16250-8
Library of Congress Control Number: 2015932521
Mathematics Subject Classiﬁcation: 00–01, 97D50
Springer Cham Heidelberg New York Dordrecht London
© Springer International Publishing Switzerland 2015
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part
of the material is concerned, speciﬁcally the rights of translation, reprinting, reuse of illustrations,
recitation, broadcasting, reproduction on microﬁlms or in any other physical way, and transmission
or information storage and retrieval, electronic adaptation, computer software, or by similar or
dissimilar methodology now known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this
publication does not imply, even in the absence of a speciﬁc statement, that such names are exempt
from the relevant protective laws and regulations and therefore free for general use.
The publisher, the authors and the editors are safe to assume that the advice and information in this
book are believed to be true and accurate at the date of publication. Neither the publisher nor the
authors or the editors give a warranty, express or implied, with respect to the material contained
herein or for any errors or omissions that may have been made.
Printed on acid-free paper
Springer International Publishing AG Switzerland is part of Springer Science+Business Media
(www.springer.com)

Preface
Patterns have become a common theme in many ﬁelds of academic study. In
programming, in particular, the book “Design Patterns” has become highly inﬂu-
ential and it is now customary to discuss programs in terms of the patterns used.
The programmers generally attribute the idea of a design pattern to architecture. The
fundamental idea is that each ﬁeld has a collection of ways of breaking down
problems into component pieces. Understanding these methodologies explicitly
then leads to greater comprehension, facilitates learning and simpliﬁes problem
solving. Rather than attempting a problem cold, one ﬁrst sees whether known
patterns work. Even if they all fail, understanding why they fail deﬁnes the
problem.
In this book, my objective is to identify and teach many of the common patterns
that arise in pure mathematics. I call these “Proof Patterns”. The main originality in
the presentation is that examples are focussed about each pattern and drawn from
different areas. This differs from the usual style of teaching pure mathematics where
a topic is chosen and dissected; patterns are then drawn in as needed, and they are
often not explicitly mentioned. After studying enough topics the learner picks up a
variety of patterns, and the difﬁculty of studying a new area is often determined by
the degree of unfamiliarity with its patterns.
This book is intended to do a variety of things. On one level, my objective is to
teach the basic patterns. On another, it is intended as a taster for pure mathematics.
The reader will gain a little knowledge on a variety of topics and hopefully learn a
little about what pure mathematics is. On a third level, the intention of the book is to
make a case for the explicit recognition of patterns when teaching pure mathe-
matics. On a fourth level, it is simply an enjoyable romp through topics I love.
One powerful tool of pure mathematics which I intentionally avoid is that of
abstraction. I believe that patterns and concepts are best learnt via the study of
concrete objects wherever possible. Whilst one must go abstract eventually to
obtain the full power and generality of results, a proof or pattern that has already
been understood in a concrete setting is much easier to comprehend and apply.
v

A side effect of this avoidance is that the patterns are not formally deﬁned since
such deﬁnitions would require a great deal of abstraction.
The target reader of this book will already be familiar with the concept of proof
but need not know much more. So whilst I assume very few results from pure
mathematics, the reader who does not know what a proof is will struggle. There are
several excellent texts such as Eccles, Velleman and Houston for such readers to
study before reading here. In particular, I regard this book as a second book on
proof, and my hope is that the reader will ﬁnd that the approach here eases their
study of many areas of pure mathematics.
I try to build up everything from the ground up as much as possible. I therefore
try to avoid the “pull a big theorem out of the hat” style of mathematics presen-
tation. The emphasis is much more on how to prove results rather than on trying to
impress with theorems whose proofs are far beyond the book’s scope. I do occa-
sionally use concepts from analysis before these are formally deﬁned such as a
convergent sequence. Hopefully, the reader who has not studied analysis will be
able to work with their intuitive notions of these objects.
Inevitably, as with many introductory books on proof, many examples are drawn
from combinatorics and elementary number theory. This reﬂects the fact that these
areas require fewer prerequisites than most and so patterns can be discussed in
simple settings. However, I also draw on a variety of areas including group theory,
linear algebra, computer science, analysis, topology, Euclidean geometry, and set
theory to emphasize patterns’ universality.
There is little if any originality in the mathematical results in this book: the
objective was to provide a different presentation rather than new results. We look at
the “Four-Colour problem” at various points. Our treatment is very much inspired
by Robin Wilson’s excellent book “Four colours sufﬁce” and I recommend it to any
reader whose interest has been piqued. A book with some similarities to this one but
requiring a little more knowledge from the reader is “Proofs from the BOOK” by
Aigner and Ziegler. The emphasis there is more on beauty in proof than on patterns
and it is a good follow on for the reader who wants more. However, I do hope that
any reader of this book will develop some appreciation for the beauty of
mathematics.
Many of the patterns in this book have not been named before although they are
in widespread use. I have therefore invented their names. I hope that these new
names will prove popular. I apologise to those who dislike them.
For the reader who has forgotten or never knew mathematical terminology,
I have included a glossary in Appendix A. This also includes deﬁnitions of the
standard sets of numbers. For clarity, let me say right here that in this book 0 is a
natural number. This is the way I was taught as an undergraduate and it is too ﬁrmly
embedded in my psyche for me to use any other deﬁnition. The term counting
numbers denoted N1 will be used for the natural numbers excluding zero.
This book is ultimately an expression of my philosophy of how to approach the
teaching of mathematics. My views have been shaped by interactions with
vi
Preface

innumerable former teachers, students and colleagues and I thank them all.
I particularly thank Alan Beardon and Navin Ranasinghe for their detailed com-
ments on a former version of the text. I also thank some anonymous referees for
their constructive comments.
Melbourne, 2014
Mark Joshi
Preface
vii

Contents
1
Induction and Complete Induction . . . . . . . . . . . . . . . . . . . . . . .
1
1.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1.2
Examples of Induction . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2
1.3
Why Does Induction Hold? . . . . . . . . . . . . . . . . . . . . . . . .
3
1.4
Induction and Binomials . . . . . . . . . . . . . . . . . . . . . . . . . .
4
1.5
Triangulating Polygons . . . . . . . . . . . . . . . . . . . . . . . . . . .
7
1.6
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
8
2
Double Counting. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
11
2.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
11
2.2
Summing Numbers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
11
2.3
Vandermonde’s Identity . . . . . . . . . . . . . . . . . . . . . . . . . . .
13
2.4
Fermat’s Little Theorem. . . . . . . . . . . . . . . . . . . . . . . . . . .
14
2.5
Icosahedra . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
15
2.6
Pythagoras’s Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . .
16
2.7
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
17
3
The Pigeonhole Principle. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
19
3.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
19
3.2
Rationals and Decimals . . . . . . . . . . . . . . . . . . . . . . . . . . .
19
3.3
Lossless Compression . . . . . . . . . . . . . . . . . . . . . . . . . . . .
21
3.4
More Irrationality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
22
3.5
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
23
4
Divisions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
25
4.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
25
4.2
Division and Well-Ordering . . . . . . . . . . . . . . . . . . . . . . . .
25
4.3
Algorithms and Highest Common Factors . . . . . . . . . . . . . .
26
4.4
Lowest Terms. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
28
ix

4.5
Euclid’s Lemma . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
29
4.6
The Uniqueness of Prime Decompositions . . . . . . . . . . . . . .
30
4.7
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
31
5
Contrapositive and Contradiction . . . . . . . . . . . . . . . . . . . . . . . .
33
5.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
33
5.2
An Irrational Example . . . . . . . . . . . . . . . . . . . . . . . . . . . .
34
5.3
The Infinitude of Primes . . . . . . . . . . . . . . . . . . . . . . . . . .
36
5.4
More Irrationalities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
37
5.5
The Irrationality of e . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
38
5.6
Which to Prefer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
40
5.7
Contrapositives and Converses . . . . . . . . . . . . . . . . . . . . . .
40
5.8
The Law of the Excluded Middle . . . . . . . . . . . . . . . . . . . .
40
5.9
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
41
6
Intersection-Enclosure and Generation. . . . . . . . . . . . . . . . . . . . .
43
6.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
43
6.2
Examples of Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . .
43
6.3
Advanced Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
44
6.4
The Pattern. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
45
6.5
Generation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
46
6.6
Fields and Square Roots. . . . . . . . . . . . . . . . . . . . . . . . . . .
48
6.7
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
51
7
Difference of Invariants. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
53
7.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
53
7.2
Dominoes and Triminoes . . . . . . . . . . . . . . . . . . . . . . . . . .
53
7.3
Dimension . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
54
7.4
Cardinality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
58
7.5
Order. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
61
7.6
Divisibility . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
63
7.7
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
64
8
Linear Dependence, Fields and Transcendence. . . . . . . . . . . . . . .
65
8.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
65
8.2
Linear Dependence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
66
8.3
Linear Dependence and Algebraic Numbers . . . . . . . . . . . . .
69
8.4
Square Roots and Algebraic Numbers . . . . . . . . . . . . . . . . .
70
8.5
Transcendental Numbers . . . . . . . . . . . . . . . . . . . . . . . . . .
71
8.6
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
71
x
Contents

9
Formal Equivalence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
73
9.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
73
9.2
Ruler and Compass Constructions . . . . . . . . . . . . . . . . . . . .
73
9.3
Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
80
9.4
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
80
10
Equivalence Extension . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
81
10.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
81
10.2
Constructing the Integers . . . . . . . . . . . . . . . . . . . . . . . . . .
81
10.3
Constructing the Rationals . . . . . . . . . . . . . . . . . . . . . . . . .
85
10.4
The Inadequacy of the Rationals . . . . . . . . . . . . . . . . . . . . .
88
10.5
Constructing the Reals . . . . . . . . . . . . . . . . . . . . . . . . . . . .
90
10.6
Convergence of Monotone Sequences . . . . . . . . . . . . . . . . .
93
10.7
Existence of Square Roots . . . . . . . . . . . . . . . . . . . . . . . . .
94
10.8
Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
94
10.9
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
95
11
Proof by Classiﬁcation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
97
11.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
97
11.2
Co-prime Square . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
97
11.3
Classifying Pythagorean Triples . . . . . . . . . . . . . . . . . . . . .
98
11.4
The Non-existence of Pythagorean Fourth Powers . . . . . . . . .
101
11.5
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
103
12
Speciﬁc-generality. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
105
12.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
105
12.2
Reducing the Fermat Theorem . . . . . . . . . . . . . . . . . . . . . .
105
12.3
The Four-Colour Theorem . . . . . . . . . . . . . . . . . . . . . . . . .
106
12.4
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
108
13
Diagonal Tricks and Cardinality . . . . . . . . . . . . . . . . . . . . . . . . .
109
13.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
109
13.2
Definitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
109
13.3
Infinite Sets of the Same Size. . . . . . . . . . . . . . . . . . . . . . .
110
13.4
Diagonals. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
112
13.5
Transcendentals. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
115
13.6
Proving the Schröder–Bernstein Theorem. . . . . . . . . . . . . . .
116
13.7
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
118
14
Connectedness and the Jordan Curve Theorem . . . . . . . . . . . . . .
119
14.1
Definitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
119
14.2
Components . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
120
14.3
The Jordan Closed-Curve Theorem . . . . . . . . . . . . . . . . . . .
122
14.4
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
125
Contents
xi

15
The Euler Characteristic and the Classiﬁcation
of Regular Polyhedra . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
127
15.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
127
15.2
The Euler Characteristic and Surgery. . . . . . . . . . . . . . . . . .
127
15.3
Transforming the Problem . . . . . . . . . . . . . . . . . . . . . . . . .
129
15.4
The Result for Networks in the Plane . . . . . . . . . . . . . . . . .
130
15.5
Counterexamples. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
133
15.6
Classifying Regular Polyhedra . . . . . . . . . . . . . . . . . . . . . .
135
15.7
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
136
16
Discharging . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
137
16.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
137
16.2
The Euler Characteristic via Discharging . . . . . . . . . . . . . . .
137
16.3
Maps and Double Counting . . . . . . . . . . . . . . . . . . . . . . . .
138
16.4
Inevitable Configurations . . . . . . . . . . . . . . . . . . . . . . . . . .
141
16.5
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
141
17
The Matching Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
143
17.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
143
17.2
Formulating the Problem . . . . . . . . . . . . . . . . . . . . . . . . . .
143
17.3
The Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
144
17.4
Uniqueness. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
144
17.5
Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
145
17.6
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
145
18
Games . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
147
18.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
147
18.2
Defining a Game. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
147
18.3
Termination . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
148
18.4
Optimal Strategy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
149
18.5
Second Player Never Wins . . . . . . . . . . . . . . . . . . . . . . . . .
149
18.6
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
150
19
Analytical Patterns . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
151
19.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
151
19.2
The Triangle Inequality . . . . . . . . . . . . . . . . . . . . . . . . . . .
152
19.3
The Definition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
152
19.4
Basic Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
154
19.5
Series . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
159
19.6
Continuity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
162
19.7
Theorems About Continuous Functions . . . . . . . . . . . . . . . .
165
19.8
The Fundamental Theorem of Algebra. . . . . . . . . . . . . . . . .
168
19.9
Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
171
19.10
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
171
xii
Contents

20
Counterexamples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
173
20.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
173
20.2
Matrix Algebra . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
173
20.3
Smooth Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
175
20.4
Sequences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
177
20.5
Ordinary Differential Equations. . . . . . . . . . . . . . . . . . . . . .
178
20.6
Characterisation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
179
20.7
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
180
Appendix A: Glossary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
181
Appendix B: Equivalence Relations . . . . . . . . . . . . . . . . . . . . . . . . . .
183
References. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
185
Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
187
Contents
xiii

Chapter 1
Induction and Complete Induction
1.1 Introduction
Two basic proof tools are the principle of induction and the related principle of
complete induction. Each of these relies on certain properties of the natural numbers
which we now explore.
The idea of induction is simple. We wish to prove that a set of statements, P(n),
hold for all n ∈N greater than or equal to some natural number k. We ﬁrst check it
for P(k), and then we show that if it holds for one value of n then it also holds for
the next one. In other words, we have to prove
• P(k);
• P(n) =⇒P(n + 1), ∀n ⩾k.
It then follows that it holds for all values of n starting with k. Why? It holds for k so
putting n = k, it holds for k + 1. Putting n = k + 1, it holds for k + 2. Repeating,
it holds for k + 3, k + 4, k + 5, . . . . We discuss how to show that P(n) really does
hold for n ⩾k in Sect.1.3.
Complete induction is a closely related tool. The difference is that we are allowed
to use P(l) for k ⩽l ⩽n when proving P(n + 1) rather than just P(n). This can
be advantageous—for certain types of results, it is the truth of P(l) for some much
smaller l that is useful rather than that of P(n). It holds for similar reasons to ordinary
induction and we will discuss the proofs that they hold together.
© Springer International Publishing Switzerland 2015
M. Joshi, Proof Patterns, DOI 10.1007/978-3-319-16250-8_1
1

2
1
Induction and Complete Induction
1.2 Examples of Induction
Induction often come in useful when establishing formulas for sums. Let f (n) be
the sum of the ﬁrst n natural numbers. We want to prove
f (n) = n(n + 1)
2
.
In this case, P(n) is the statement that the formula is correct for f (n).
We certainly have f (1) = 1 so P(1) is true. We now assume that P(n) is true
and try to establish that P(n + 1) is true. In this context P(n) is sometimes called
the inductive hypothesis. We have
f (n + 1) = f (n) + n + 1,
by deﬁnition. We now substitute the formula which we assumed to be true for n, to
obtain
f (n + 1) = n(n + 1)
2
+ (n + 1) = n(n + 1) + 2(n + 1)
2
.
Simplifying,
f (n + 1) = (n + 2)(n + 1)
2
.
We have shown that P(n) implies P(n+1) and the results holds for all n by induction.
Whilst proof by induction is often easy and in a case like this it will generally
work if the result is true, it has the disadvantage that you have to already know the
formula! It is therefore more a way of proving formulas rather than of ﬁnding them.
It can therefore come in useful when a result has been guessed in some non-rigorous
fashion and still has to be proven.
We now give a classic example of applying the principle of complete induction.
We show that any natural number bigger than one can be written as a product of
prime numbers. In this case, P(n) is the statement that n can be written as a product
of product of primes.
We start with P(2). It certainly holds since 2 is prime. We now assume the
inductive hypothesis that P(2), P(3), . . . , P(n) are true. Consider n + 1. Either
it is prime in which case we are done, or it is composite. In the latter case, we can
write
n + 1 = ab
with 2 ⩽a, b ⩽(n + 1)/2 ⩽n. We have assumed that P(a) and P(b) hold so we
can write
a = p1 p2 . . . pα,
b = q1q2 . . . qβ

1.2 Examples of Induction
3
for some primes p j and q j and α, β ∈N. So
n + 1 = p1 p2 . . . pαq1q2 . . . qβ
and P(n + 1) holds. It follows from complete induction, that all natural numbers
bigger than 1 can be written as a product of primes. Note that this proof used complete
induction in a non-trivial way; it is not at all clear how we could prove the result
using only ordinary induction.
More generally, note that whilst we have established that every natural number
bigger than 1 is a product of primes, we have not shown that the representation is
unique. Indeed without some extra restrictions, it is not:
2 × 2 × 3 = 12 = 2 × 3 × 2.
This non-uniqueness can be circumvented by requiring the primes to be in ascending
order, and the representation is then unique. Note the general technique here: impose
additional structure to remove non-uniqueness. However, one still has to prove that
this amount of extra structure is enough to gain uniqueness. We will prove that it is
sufﬁcient in Sect.4.6.
1.3 Why Does Induction Hold?
How can we prove that induction works? One solution is to use the well-ordering of
the natural numbers: every non-empty subset of the natural numbers has a smallest
element. The idea is essentially that there cannot be a least element that the statement
does not hold for, so the set of such elements must be empty.
More formally, the argument is let E be the set of n for n > k for which P(n) is
false. If E is non-empty then it has a least element l and we know l > k. So l −1 ̸∈E
so P(l −1) holds. By the inductive hypothesis, P(l) holds. So l is both in E and not
in E. We have a contradiction. So E has no least element and must be empty.
We can prove the principle of complete induction in a similar fashion. In fact,
we can deduce it from the principle of induction directly. Let Q(n) be the statement
that P(l) holds for k ⩽l ⩽n. We then have that Q(k) holds, and that Q(n) implies
Q(n + 1) so it follows by induction that Q(n) holds for all n ⩾k. Since Q(n)
certainly implies P(n), we also have that P(n) holds and we are done.
These arguments are correct; however, we have proven the principle of induction
by assuming the well ordering of the natural numbers. How can we prove that well
ordering holds? (Un)fortunately, proofs really come down to the fact that the principle
of induction holds! We have to take one of the two as an axiom and use it to deduce the
other. Ultimately, mathematicians deﬁne their formal systems and axioms in such a
way as to capture their intuitive notions of what they are trying to model. In this case,
the axioms capture the notion that all natural numbers can be reached by starting at
0 and repeatedly adding one.

4
1
Induction and Complete Induction
1.4 Induction and Binomials
The binomial coefﬁcient
n
k

expresses the number of ways that k objects can be
selected from n objects with n ⩾k. We do not care about the order of the objects
selected. We have
n
k

=
n!
(n −k)! k!.
Why? The number of ways we can select the ﬁrst object is n. The second is then
n −1 since one is gone, and n −2 for the one after, and so on. (See if you can write
out a formal proof of this using induction.) So we can select k objects in
n(n −1) . . . (n −k + 1) =
n!
(n −k)!
different ways. However, this is an ordered selection. We do not care about the
ordering so we can divide again by the number of different orderings of k objects
and we get
n!
(n −k)! k!,
as desired. Note that an immediate consequence of our interpretation of this fraction
is that it represents a whole number! We always have that
k! | n(n −1) . . . (n −k + 1)
which is not obvious. For the reader not familiar with |, we say that for a, b ∈Z
a | b
if there exists m ∈Z such that
ma = b.
In other words, b/a is an integer.
Note that here, we have shown a relationship between two numbers by interpreting
a formula in a certain way. Sometimes this can yield non-obvious properties:
proof by observation.
We take 0! = 1. This can be regarded as a deﬁnition, however, it makes sense in
that k! expresses the number of ways you can order k objects. If we have no objects
then there is only one way to order them so we should have 0! = 1. We have
n
0

= 1 =
n
n

;

1.4 Induction and Binomials
5
we also have
n
1

= n =

n
n −1

.
An obvious symmetry exists
n
k

=

n
n −k

.
We can also show Pascal’s identity
n
k

+

n
k −1

=
n + 1
k

,
for 1 ⩽k ⩽n. This can be proven either via algebraic manipulation or by
interpretation. We use the latter approach. We want to show that the number of sub-
sets with k elements taken from {1, 2, . . . , n +1} is the left-hand-side of the identity.
We show that any such subset corresponds to either a subset with k elements of
1, 2, . . . , n or one with k −1 elements. If our subset, E, with k elements contains the
element n +1 then discarding n +1 gives a subset of {1, . . . , n} with k −1 elements.
Clearly all such subsets can be obtained this way. If E does not contain n + 1 then
it is a subset of {1, 2, . . . , n} with k elements, and again we can get all such subsets
in this way. We have constructed a correspondence and the identity follows.
With Pascal’s identity in hand, we can now prove something using induction.
Theorem 1.1 The binomial theorem. If n is a natural number, and x, y are real
numbers then
(x + y)n =
n

k=0
n
k

xk yn−k.
Proof If n = 0, both sides are equal to 1. Now suppose the result holds for n. We
write
(x + y)n+1 = (x + y)(x + y)n = x(x + y)n + y(x + y)n.
Using the inductive hypothesis,
(x + y)n+1 =
n

k=0
n
k
 
xk+1yn−k + xk yn−k+1
.
We need to gather terms with the same powers of x and y together,
n
k

xk+1yn−k =
 n
l −1

xl yn+1−l

6
1
Induction and Complete Induction
where l = k + 1. So, letting
 n
−1

= 0,
(x + y)n+1 =
n

l=0
n
l

+
 n
l −1

xl yn−l+1 +
n
n

xn+1.
Invoking Pascal’s identity and the fact that
n
n

= 1 =
n+1
n+1

, we have
(x + y)n+1 =
n+1

l=0
n + 1
l

xl yn+1−l,
as required and the result follows by induction.
□
Induction is not essential for the proof of the binomial theorem. Another approach
is to think about how the coefﬁcient of xk yn−k arises when we work out the expansion
of (x + y)n. It occurs from picking the x of (x + y) in k places out of n possible
ones. It can therefore arise
n
k

different times and we get the binomial theorem.
With the binomial theorem proven, we can make various proofs by observation.
First,
2n =
n

k=0
n
k

.
(1.4.1)
To prove this, just put x = y = 1 in the binomial theorem. Once we interpret this
result, it is actually clear for other reasons. We are adding the number of ways of
choosing k elements from n for each k. We are therefore counting the number of
subsets of {1, 2, . . . , n}. Each number is either in a given subset or not, so each
number gives us two possibilities. There are n numbers so there are 2n subsets and
we have (1.4.1). Our alternate proof is a proof by double counting; we counted a
collection of objects in two different ways to establish a formula.
Another immediate consequence of the binomial theorem is
n

k=0
n
k

(−1)k = 0.
(1.4.2)
Just set x = −1 and y = 1. We can rewrite this as
k⩽n/2

k=0
 n
2k

=
k<n/2

k=0

n
2k + 1

.
(1.4.3)
The number of different ways of choosing a subset with an even number of elements
equals the number of ways of choosing a subset with an odd number. This is clear
when n is odd; taking the complement provides a natural bijection between the two
classes of subsets. It is not so obvious when n is even.

1.5 Triangulating Polygons
7
1.5 Triangulating Polygons
We now look at an application of complete induction to a quite different area. We
prove that every polygon in the plane can be triangulated. In fact, we prove a stronger
result, we show that it can be done without adding any extra vertices. Before pro-
ceeding to the proof, we discuss what a triangulation is. A polygon is a closed loop in
the plane consisting of a sequence of straight line segments which starts and ﬁnishes
at the same point. The loop does not self intersect anywhere. To triangulate means
to divide the polygon into triangles which only intersect along common sides. We
give a couple of examples in Fig.1.1. We prove
Theorem 1.2 If P is a polygon in the plane, it is possible to write P as a union
of triangles whose vertices are subsets of those of P and which only intersect in
common sides or vertices.
Proof A polygon has at least 3 vertices. If it has 3 exactly then it is a triangle and
the result is trivial. We now assume that any polygon with 3 ⩽k < n sides can be
triangulated. Let P be a polygon with n sides. It must have a vertex, V , where the
interior angle between its two edges is less than 180 ◦. To see this observe that if
the change in direction of the edge at a vertex is x degrees then the interior angle is
180 −x degrees. Since all the changes of direction must add up to 360 ◦, at least one
must have x > 0 and so that angle must be less than 180.
Now consider the two vertices next to V . Call them A and B. We draw a line
between them. See Fig.1.2. If this line’s interior does not intersect P then ABC
deﬁnes a triangle that we can cut off P. The remaining part of P can be triangulated
by the inductive hypothesis and so P is triangulable.
If the line AB’s interior does intersect P, then we slide its endpoints along towards
V . We do the sliding in such a way that they both reach V at the same time. Since
Fig. 1.1 Examples of triangulations of polygons

8
1
Induction and Complete Induction
Fig. 1.2 A proof of the triangulation of a polygon
there are only a ﬁnite number of vertices in P, there will be a last time at which the
line crosses a vertex. Call a vertex crossed at this last time D. (There could be more
than one but this is not important.) The line from A to D will now not intersect P
and it divides P into two smaller polygons. These can both be triangulated by the
inductive hypothesis. The result now follows by complete induction.
□
1.6 Problems
Exercise 1.1 Develop an expression for the sum of the ﬁrst n odd numbers and prove
that it holds using induction.

1.6 Problems
9
Exercise 1.2 Prove that for n ⩾1,
n

j=1
1
√j ⩾√n.
Exercise 1.3 A chess-style board is of size 2n × 2n and has a single square deleted.
A trimino is three squares joined together so as to have an angle; it is like a domino
with a square stuck to the side. Show that for any n, the board can be covered by
non-overlapping triminoes.
Exercise 1.4 Prove that
n

j=1
j2 = n(n + 1)(2n + 1)
6
.
Exercise 1.5 Prove that
n

j=1
2 j−1 = 2n −1.
Exercise 1.6 Prove that if x > −1 then
(1 + x)n ⩾1 + nx,
for n ∈N.
Exercise 1.7 Prove that every number bigger than 11 is a positive integer combina-
tion of 4 and 5. That is if k ∈N, k ⩾12, there exists a, b ∈N such that
k = 4a + 5b.
Exercise 1.8 A polynomial is reducible if it can be written as a product of polyno-
mials which are not constant. If it is not reducible, it is said to be irreducible. Prove
that every non-constant polynomial is a product of irreducible polynomials.
Exercise 1.9 Show that if n ∈N, n4 −n2 is a multiple of 12.
Exercise 1.10 A statement, P(k) is deﬁned for all k ∈Z. We know that P(l) is true.
We also know that for all n ∈Z
P(n) =⇒P(n + 1),
P(n) =⇒P(n −1).
Prove that P(n) holds for all n ∈Z.

Chapter 2
Double Counting
2.1 Introduction
Often mathematicians want to develop formulas for sums of terms. As we have seen,
induction is one way to establish the truth of such formulas. However, induction
relies on foreknowledge of the formula which has to be derived or guessed in some
other way ﬁrst. Induction also does not assist with recall. An alternate way to ﬁnd and
derive many counting formulas is double counting. With this technique, we divide
up a collection of objects in two different ways. The results of the two different
divisions must agree and this can yield a formula for the more complicated one.
Such approaches have the advantage that the technique for ﬁnding the formula is
often more memorable than the formula itself.
2.2 Summing Numbers
We wish to ﬁnd the sum of the ﬁrst N numbers. Call this xN. So
xN =
N

j=1
j.
We can regard the sum as a triangle with 1 stone in the ﬁrst row, two stones in
the second, three in the third and so on. See Fig.2.1. Now if we make a copy of the
triangle and rotate it through 180◦, we get N stones in the ﬁrst row, N −1 in the
second, N −2 in the third and so on. Joining the two triangles together, we have N
rows of N + 1 stones. The total number of stones is N(N + 1). So
X N = 1
2 N(N + 1).
© Springer International Publishing Switzerland 2015
M. Joshi, Proof Patterns, DOI 10.1007/978-3-319-16250-8_2
11

12
2
Double Counting
Fig. 2.1 Stones arranged in
rows with one more stone in
each row together with the
same stones rotated
We could also give this proof algebraically. Before proceeding to the algebra, we
look at a special case. If we have 5 stones, then
X5 = 1 + 2 + 3 + 4 + 5,
X5 = 5 + 4 + 3 + 2 + 1,
2X5 = (1 + 5) + (2 + 4) + (3 + 3) + (4 + 2) + (5 + 1).
Now the algebra, if we reverse the order of the sum, we get
xN =
N

j=1
(N + 1 −j).
Adding the two expressions for xN together,
2xN =
N

j=1
(N + 1) = N(N + 1),
and the result follows.
A similar argument can be used for the sum of the ﬁrst N odd numbers
yN =
N

j=1
(2 j −1).
Either by rotating the triangle or by reversing the order of the sum, we have
yN =
N

j=1
(2N + 1 −2 j).

2.2 Summing Numbers
13
So
2yN =
N

j=1
2N.
We conclude that
yN = N 2.
As well as being the sum of the ﬁrst N odd numbers, N 2 is also the sum of the ﬁrst
N numbers plus the ﬁrst N −1 numbers. One way to see this is take an N × N grid of
stones and see how many stones lie on each upwards sloping diagonal. For the ﬁrst
N diagonals, the jth diagonal has j stones. These contribute the sum of the ﬁrst N
numbers.After N,thelengthofthediagonalsgoesdownbyoneeachtime.Thesecond
set therefore contribute the sum of the ﬁrst N −1 numbers and the result follows.
2.3 Vandermonde’s Identity
Suppose we have m + n jewels of varying sizes. There are m rubies and n sapphires.
How many different ways can we select r jewels to be placed on a bracelet? Clearly,
the answer is
m + n
r

.
Note that since the jewels are all of different sizes, two different selections of r jewels
are essentially different. However, if we ﬁrst think in terms of using k rubies and
r −k sapphires, we see that the answer is also
r

k=0
m
k

n
r −k

.
(We take the binomial coefﬁcient to be zero when the inputs are out of their natural
range. For example, if r > m, there are zero ways to choose r rubies.) In conclusion,
we have Vandermonde’s identity:
m + n
r

=
r

k=0
m
k

n
r −k

.

14
2
Double Counting
2.4 Fermat’s Little Theorem
Fermat’s little theorem states
Theorem 2.1 If a is a positive integer and p is prime then p divides a p −a.
An elementary proof can be made using double counting.
Proof Consider strings of letters of length p. The letters are from the ﬁrst a letters
in the alphabet. (If a > 26, we add extra letters to the alphabet.) How many such
strings are there? Order matters, so we have a choices in each slot and there are p
slots, so we get a p different strings.
Now consider the operation on these strings of chopping off an element at the end
and reinserting it at the front. Call this T 1. We deﬁne T j to be the result of applying
T 1 j times. Clearly, T p is the identity map. We give some examples when p = 3
and a = 2.
T 1(AAA) = AAA,
T 1(AB A) = AAB,
T 2(AB A) = B AA.
Two strings, x and y, are said to be in the same orbit if there exists j such that
T j x = y.
Note that then
T p−j y = x.
Also note that if x and y are in the same orbit, and y and z are in the same orbit then
x and z are too. So being in the same orbit is an equivalence relation. (See Appendix
B for further discussion of equivalence relations.) This implies that every string is in
exactly one orbit.
If a string is all one letter, e.g. “AAA”, then it is the only string in its orbit. There
are a such strings and so a orbits of size 1.
Now suppose a string x has more than one letter in it. Consider the strings
x, T x, T 2x, . . . , T p−1x.
These will all be in the same orbit and everything in x’s orbit is of this form. If we
keep going we just get the same strings over again since T px = x. There are at most
p elements in these orbits then. We show that when p is prime there are exactly p
elements. If there were less than p then for some k < p, we would have
T kx = x.

2.4 Fermat’s Little Theorem
15
This means that cutting off the last k elements and sticking them at the front does
not change the string. We also have
x = T kx = T 2kx = T 3kx = T 4kx = . . .
This implies that x is made of p/k copies of the ﬁrst k elements. However, p is
prime so its only divisor are 1 and p. If k = 1 then we have a string of elements the
same which is the case we already discussed. If k = p then we are just saying that
T px = x which is always true.
So we have two sorts of orbits, those with p elements and those with 1 element.
We showed that there are a of the second sort. Let there be m of the ﬁrst sort. Since
there are a p strings in total, we have
a p = mp + a,
So
pm = a p −a.
This says precisely that p divides a p −a.
□
This proof is due to Golomb (1956).
2.5 Icosahedra
An icosahedron is a polyhedron with 20 faces. When working with three-dimensional
solids, we can divide their surfaces into vertices, edges and faces. A vertex is a
corner, a face is a ﬂat two-dimensional side and an edge is the line deﬁning the side
of two faces.
A regular icosahedron is a Platonic solid. Every face is a triangle and the same
number of faces meet at each vertex. How many edges does an icosahedron have?
Call this number E. We know that there are 20 faces and that each face is a triangle.
Deﬁne an edge-face pair to be a face together with one of the sides of the face which
is, of course, an edge of the icosahedron. There are 60 such pairs since each face
has 3 sides.
Each edge of the icosahedron lies in precisely two sides. The number of edge-face
pairs is therefore double the number of edges. That is
2E = 60
and so E = 30.

16
2
Double Counting
2.6 Pythagoras’s Theorem
The reader will already be familiar with the theorem that for a right-angled triangle,
the square of the hypotenuse is equal to the sum of the squares of the other two sides.
So if the sides are a, b and c, with c the longest side, we have
c2 = a2 + b2.
We can use an extension of the double counting pattern to prove this theorem. Instead
of using equal numbers of objects, we use equal areas. We take the triangle and ﬁx a
square with side length c to its side of that length. We then ﬁx a copy of the triangle
to each of the square’s other sides. See Fig.2.2. At each vertex of the square, we get
3 angles, each of which is one of the angles of the triangle so these add up to 180◦
and make a straight line. We now have two squares: the big one has side a + b and
the small one c. The former’s area is
(a + b)2 = a2 + 2ab + b2.
We can also regard the big square as the small one plus 4 copies of the triangle and
so it has area
c2 + 4 × 0.5ab = c2 + 2ab.
Fig. 2.2 Four right-angled
triangles with sides a, b, c,
placed on a square of side c

2.6 Pythagoras’s Theorem
17
Equating these two, we get
a2 + b2 = c2,
as required. Our proof is complete.
2.7 Problems
Exercise 2.1 Let a and b be integers. Develop a formula for
n

j=1
a + jb.
Exercise 2.2 How many vertices does an icosahedron have?
Exercise 2.3 If p is a prime and not 2, and a is an integer, show that 2 divides into
a p −a. (Try to construct a bijection on the set of size p orbits which pairs them.)
Exercise 2.4 Suppose we have three sorts of jewels and apply the arguments for
Vandermonde’s identity, what formula do we ﬁnd?

Chapter 3
The Pigeonhole Principle
3.1 Introduction
A pigeonhole is another name for a mailbox. If we have more pieces of mail than
pigeonholes, someone’s pigeonhole gets two pieces of mail. That is the pigeonhole
principle. Whilst easy to state and rather obvious, it is very useful. It is closely related
to the concept of cardinality which generalizes the concept of the number of elements
of ﬁnite sets.
More formally, let A and B be sets such that the cardinality of A is greater than
that of B. (i.e. A has more elements than B.) Suppose a function f maps from A to
B then f is not injective that is there exists x, y ∈A such that
f (x) = f (y).
In this chapter, we look at a variety of applications from some quite different areas.
3.2 Rationals and Decimals
The reader will be familiar with the fact that some rational numbers are not easy to
represent with decimals. In particular, their expansions repeat. For example,
1
3 = 0.3333333 . . .
and
1
9 = 0.111111 . . .
© Springer International Publishing Switzerland 2015
M. Joshi, Proof Patterns, DOI 10.1007/978-3-319-16250-8_3
19

20
3
The Pigeonhole Principle
More interestingly,
1
7 = 0.142857142857142857142857 . . .
which repeats every 6 places.
Two obvious questions arise:
• If a decimal expansion repeats, will it always represent a rational number?
• If a number is rational, will its expansion always be ﬁnite or repeating?
The ﬁrst of these is easy. Suppose the expansion of x repeats every k places after some
point in the expansion. Then y = 10kx −x is zero after that point in the expansion.
So we can make y into an integer simply by multiplying it by some power of 10. We
then have for some l, m ∈N
10l(10k −1)x = m.
Equivalently,
x =
m
10l(10k −1),
so x is rational.
For the second question, we analyze the algorithm that produces the terms in the
decimal expansion. We have q = m/n, with m and n natural numbers. We take
q > 0, since the result will follow for negative q simply by putting a minus sign in
front.
If we proceed using the arithmetic algorithms we learnt in school, then eventually,
we get to a point in the decimal expansion computation where we take a number r0
and write
r0 = a0n + b0,
with 0 ⩽b0 ⩽n −1. (See Chap.4 for more discussion of the division algorithm.)
The number a0 is the term in the decimal expansion and b0 is the remainder we use
for the next term. We then put r1 = 10b0, and set
r1 = a1n + b1,
with 0 ⩽b1 ⩽n −1. If we get a zero remainder the expansion terminates and we
have a ﬁnitely long decimal. Otherwise, we keep going, setting r j = 10b j−1, and
r j = a jn + b j.
If for some j, k with j < k, b j = bk then the expansion starting at place k is the
same as the one starting at place j. This is because the algorithm translated from j
to k has the same inputs and the same operations.

3.2 Rationals and Decimals
21
However, if we consider the values
b0, b1, . . . , bn−1,
there are n of these. If any is zero, the expansion terminates. If none is zero then they
take values from 1 to n −1. The pigeonhole principle then guarantees that two of
them are equal. So for some j, k with j < k ⩽n −1,
b j = bk,
and the decimal repeats with period k−j. Note that the maximum period of repetition
is, in fact, n −1.
A consequence of our results is that we can characterize irrational numbers as
those that have inﬁnite non-repeating expansions. Note also that if a number has a
ﬁnite or repeating expansion for one number base then it will have one of the two
for all number bases.
3.3 Lossless Compression
I once saw an advertisement for a compression program that claimed to reduce the
size of any ﬁle by at least 20%. This did not seem very believable so I asked a
colleague if this was really possible. His response was that he doubted that it could
compress the same ﬁle twice!
We can use the pigeonhole principle to prove that an algorithm that losslessly
compressesanyﬁleisimpossible.Bylosslesscompression,wemeanthatitispossible
to recover the original ﬁle purely from the data in the new ﬁle. For compression, the
new ﬁle has to be smaller than the old ﬁle. A ﬁle in a modern digital computer is no
more and no less than a sequence of 1 and 0s. The amount of memory used is the
length of the sequences.
A compression algorithm maps the sequences of length m to a sequence of length
n with m > n. There are 2m sequences of length m and 2n sequences of length n. If
we ﬁll out any sequences of length less than n using zeros to be of length m −1, then
a lossless compression algorithm would give an injection from those of length m to
those of length m −1. However, a map from the sequences of length m to those of
length m −1 cannot be injective by the pigeonhole principle. In other words, it must
be the case that two ﬁles get mapped to the same target ﬁle, and the decompression
algorithm will not be able to say which is which. Lossless compression cannot occur.
However, most people use lossless compression programs all the time. So what
is going on? In practice, most ﬁles, that have not already been compressed, have
some structure that the compression program can work with. For example, a musical
recording will display quite different characteristics from a text ﬁle or an image ﬁle.
By recognizing this internal structure, the compression program can exploit it and

22
3
The Pigeonhole Principle
compress the data. In particular, different compression formats are tuned to different
sorts of ﬁles. We use MP3 ﬁles to store our music but not for our images.
3.4 More Irrationality
Let x > 0 be an irrational number. Consider the set
Sx = {frac(nx) for n ∈Z}.
Here frac(y) is the fractional part of y, that is the part obtained after discarding the
whole number part: the bit after the decimal point if you prefer. More formally, it
is the result after subtracting the largest integer less than or equal to y so frac(y) is
always in the range [0, 1). We use the pigeonhole principle to show that Sx contains
a number arbitrarily close to zero: we show that if δ > 0, then there exists z ∈Sx
such that
0 < z < δ.
All elements of Sx are positive, since if there was a zero the number x would be
rational. So Sx ⊂(0, 1). Now suppose we pick n such that nδ > 1. If we consider
the intervals ( j/n, ( j + 1)/n] for j = 0, . . . , n −1, there are n such intervals. This
means that if we take the ﬁrst n + 1 points in Sx, at least two must lie in one of these
intervals by the pigeonhole principle. We therefore have values l and m with m > l,
such that
| frac(lx) −frac(mx)| < 1/n < δ.
In other words, there exist integers a, b and j such that
lx ∈(a + j/n, a + ( j + 1)/n), mx ∈(b + j/n, b + ( j + 1)/n).
Now consider (m −l)x = mx −lx. This number is certainly positive and it is clearly
in the interval
(b −a −1/n, b −a + 1/n).
If it is bigger then b −a, its fractional part is less than 1/n and we are done.
Otherwise, consider (l −m)x. This will lie in the range
(a −b, a −b + 1/n),
and taking its fractional part we are done. The crucial part of this argument was that
the pigeonhole principle implied that eventually the sequence of numbers frac(nx)
had to bunch together.

3.5 Problems
23
3.5 Problems
Exercise 3.1 Show that if a lossless compression algorithm exists for any ﬁle, then
it is possible to represent any ﬁle by a single bit of information.
Exercise 3.2 Show that there are two residents of London with the same number of
hairs on their heads.
Exercise 3.3 Suppose N people are at a party. Some have met before and some have
not. Show that there are two people who have met the same number of other people
before.
Exercise 3.4 Suppose we take a set of 101 different integers between 1 and 200.
Show that there is a pair such that one divides the other.
Exercise 3.5 Represent the following decimals as ratios of integers.
• 0.1212121212 . . . ,
• 0.123123123123123 . . . ,
• 0.456456456 . . . .

Chapter 4
Divisions
4.1 Introduction
In this chapter, we explore some basic results about division. These allow us to
illustrate some proof techniques. The ﬁrst result we want to prove is sometimes
called the Division Lemma—it says that we can always write the answer as a whole
number plus a remainder just as we did in primary school! To prove a result, we
ﬁrst have to formulate it correctly. Once that is done, we will see how it follows
from more basic properties of natural numbers and, in particular, the well-ordering
principle.
Our second task is to show that if two numbers, m and n, have highest common
factor h then there exist integers a and b such that
am + bn = h.
We will show this via algorithmic construction. That is we construct an algorithm
whose output is the numbers a, b and h and we prove that it always terminates.
4.2 Division and Well-Ordering
We have a natural number m and we want to divide it by another integer n. If we
work solely with whole numbers, then if we proceed as we did when ﬁrst learning
arithmetic, we write
m = nq + r
with q,r natural numbers, and 0 ⩽r < n.
The Division Lemma states that such a decomposition is always possible. The
standard way to prove it is to deduce it from the well-ordering of the natural numbers.
© Springer International Publishing Switzerland 2015
M. Joshi, Proof Patterns, DOI 10.1007/978-3-319-16250-8_4
25

26
4
Divisions
We previously mentioned well ordering in the context of induction in an informal
manner, now we give a formal deﬁnition.
Deﬁnition 4.1 A set E with an ordering < is said to be well-ordered if every non-
empty subset, F, of E has a smallest element. In other words, there exists f ∈F,
such that for all g ∈F, we have f ⩽g.
The standard ordering of the natural numbers is a well-ordering. We will take this
for granted for now.
How does well-ordering help us? Let
F = {m −nq | q ∈Z, m −nq ⩾0}.
Note that if x ∈F and x ⩾n then x −n ∈F also. So any element bigger than n −1
is not the smallest element of F. The set F is non-empty since it contains m, so by
the well-ordering principle it has a smallest element. Let r be the smallest element
of F. It must be smaller than n, since any element greater than or equal to n is not
the smallest.
We therefore have
m = nq + r
with 0 ⩽r < n, as required.
4.3 Algorithms and Highest Common Factors
The highest common factor of two natural numbers, m and n, is the largest natural
number, h, which divides into both of them with no remainders. This deﬁnition
presupposes that such a number exists! It is, however, easy to show that there is such
a number. First, the set of factors is non-empty since it contains 1. Second, any factor
of a number is less than or equal to it. So the largest element is less than or equal to
min(m, n). We therefore have a ﬁnite set of common factors and its largest element
is the highest common factors. (Note the implicit use of well-ordering here—we are
using that a ﬁnite non-empty subset of the integers has a largest element. How would
you prove this?)
Our proof of the existence of the highest common factor is not very constructive—
it does not tell us how ﬁnd it. Indeed, the implicit method is to test every number
from 1 to min(m, n) and see if it divides both m and n. Once this is done, take the
largest such number. Whilst that algorithm would work, it is not very efﬁcient. How
could we improve it? One simple improvement is simply to count downwards and
stop as soon as a common divisor is reached. This is still not very efﬁcient, however.
Fortunately, there is a much better method known as the Euclidean algorithm. We
will write (m, n) for the highest common factor from now on to simplify notation. It
relies on the observation that if
m = qn + r

4.3 Algorithms and Highest Common Factors
27
with m, n, q,r all counting numbers then
(m, n) = (n,r).
To see this, note that we can also write
r = m −qn.
If x divides a and b then it also divides a + b and a −b. Setting a = qn and b = r,
any factor of r and n is a factor of m. With a = m and b = qn, any factor of n and
m is also a factor of r. Since the set of common factors of m and n is the same as the
set of common factors of n and r, the two pairs must have the same highest common
factor.
There is an obvious choice for r and q: the results of the Division lemma. This
will make r as small as possible. If r is zero, then we have
m = qn
which means that the highest common factor is n. Otherwise, we can repeat, and
n = q1r + r1,
with r1 < r. We have
(m, n) = (n,r) = (r,r1).
Letting r0 = r, we can now keep going and obtain a sequence of remainders r j. We
terminate when we obtain a zero remainder. As argued above, we have
(m, n) = (r j,r j+1)
for all j with r j+1 > 0.
Once we hit a point with zero remainder, the algorithm terminates. We need to
show that it does. However, we always have
r j+1 < r j,
so it must terminate in at most n steps.
We do an example with m = 57 and n = 51.
57 = 1 × 51 + 6,
51 = 8 × 6 + 3,
6 = 2 × 3 + 0.
The highest common factor is 3.

28
4
Divisions
A consequence of the Euclidean algorithm is that we can always express a highest
common factor as an integer combination of the two original numbers:
Theorem 4.1 If m and n are counting numbers then there exist integers a and b
such that
(m, n) = am + bn.
In our last example,
3 = 51 −8 × 6 = 51 −8 × (57 −51) = 9 × 51 −8 × 57.
We simply work our way backwards through the algorithm.
We can formally prove this theorem using complete induction. We assume n ⩽m
without loss of generality since they can always be switched. First note that if n is
the highest common factor then the result holds
n = 1 × n + 0 × m.
Otherwise, let r j be the remainder after j + 1 steps. For convenience, let r−1 = n.
The ﬁrst remainder r0 is certainly an integer combination since
r0 = m −qn.
Now assume the result holds for rl for l ⩽j. We have
r j−1 = q jr j + r j+1,
and so
r j+1 = r j−1 −q jr j
Substituting the linear combinations for r j−1 and r j, we have a linear combination
for r j+1 and the result follows.
Our proof proceeded by using an algorithm that constructed the numbers a and b.
We also proved that the algorithm does terminate. This is an example of algorithmic
construction.
4.4 Lowest Terms
The reader will have reduced fractions to lowest terms many times at school. What
does that mean mathematically and how can we show that it is always possible?

4.4 Lowest Terms
29
Theorem 4.2 Suppose p and q are counting numbers then there exists counting
numbers p1 and q1 such that
(p1, q1) = 1, and p
q = p1
q1
.
Proof Let m = (p, q). We can then set p1 = p/m and q1 = q/m. Clearly,
p
q = mp1
mq1
= p1
q1
.
Let k = (p1, q1) we have that km divides p and q. Since m is their highest common
factor, k must be 1 and we are done.
□
4.5 Euclid’s Lemma
We can now use the result of the last section to prove a result about factors which is
sometimes called Euclid’s Lemma.
Lemma 4.1 Suppose k, m, and n are counting numbers such that (k, m) = 1 and k
is a factor of mn, then k is a factor of n.
Proof We have that there exists integers a and b such that
am + bk = 1.
So
amn + bkn = n.
We have that mn is a multiple of k so amn is. So
amn = αk,
for some α. Clearly, bkn is nb times k. So
n = (α + bn)k
and k is a factor of n.
□
A nice consequence of this lemma is
Corollary 4.1 Let m and n be positive natural numbers. If p is a prime or 1, and
p|mn then p divides at least one of m and n.

30
4
Divisions
Proof If p is 1 it divides anything, so assume that p is prime. If p divides m then we
are done. Otherwise, the highest common factor of m and p is 1, since the highest
common factor must divide into p and its only factors are p and 1. Euclid’s lemma
then states that p divides n and we are done.
□
Note that many authors state this lemma with the hypothesis that p is prime rather
than that p is prime or 1. The more general version is certainly true and it will be
convenient later when we are trying to prove that a certain number is 1 to allow its
possibility here.
4.6 The Uniqueness of Prime Decompositions
We know from Sect.1.2 that every natural number bigger than one can be written as
a product of positive integer powers of prime numbers. So given m, there exists p j
prime and α j ∈N, α j > 0, such that
m = pα1
1 pα2
2 . . . pαk
k .
Rearranging if necessary, we can assume that pi < pi+1 for all i. We want to show
that this representation is unique. Suppose we also have primes q j and powers β j
with the same properties. We need to show that
q j = p j
for all j and α j = β j.
If p and q are prime numbers they are either equal or coprime. We have that
for each l
ql|pα1
1 pα2
2 . . . pαk
k .
From Corollary 4.1, we have that ql divides at least one of
pα1
1
and pα2
2 . . . pαk
k .
Repeating the argument, we see that for some r,
ql|pαr
r .
If αl > 1, we can argue in the same way that ql divides pr or pαr−1
r
. Repeating,
we have
ql|pr
so pr = ql.

4.6 The Uniqueness of Prime Decompositions
31
Since the problem is symmetric in the ps and qs, for every pr there exists an l
such that pr = ql. In other words, we have the same sets of primes.
It remains to show that the powers are the same. We need to show that if
pα1
1 pα2
2 . . . pαk
k
= pβ1
1 pβ2
2 . . . pβk
k ,
with p j prime and αl, βl positive natural numbers then αl = βl for all l.
For each point where αl ⩾βl, we divide both sides by pβl
l . For any remaining
values of l, we divide both sides by pαl
l . We then have primes to the power αl −βl
on the left hand side and primes to the power βl −αl on the right hand side. The sets
of primes on each side with non-zero powers are disjoint.
If we repeat the argument above where we showed that the primes on each side
must be the same, we realize that all the powers must be zero. In others αl = βl for
all l and we are done.
4.7 Problems
Exercise 4.1 Find the highest common factors of the following number pairs.
• 1236 and 369.
• 144 and 900.
• 99 and 36.
Exercise 4.2 Show that the highest common factor of n and n + 1 is 1.
Exercise 4.3 Show that the highest common factor of n and n2 + 1 is 1.
Exercise 4.4 What are the possible highest common factors of n and n2+k if k < n?

Chapter 5
Contrapositive and Contradiction
5.1 Introduction
Two very common proof tools are proof by contrapositive and proof by contradiction.
Whilst these are related, they are distinct notions and it is useful to distinguish
between them. They are both really principles of logic rather than of mathematics.
In what follows let P, Q and R be mathematical statements that may be true or
false. We write ¬P for “not P” and so on. We write P&Q for the statement that
both P and Q hold. Proof by contrapositive states that the following two statements
are logically equivalent:
P =⇒Q;
¬Q =⇒¬P.
If we can prove one of them, then the other holds. If we can disprove one, then the
other is false.
Proof by contradiction involves a third statement, R. It states that if there is a
statement R such that
P&¬Q =⇒R, and
P&¬Q =⇒¬R
then
P =⇒Q.
© Springer International Publishing Switzerland 2015
M. Joshi, Proof Patterns, DOI 10.1007/978-3-319-16250-8_5
33

34
5
Contrapositive and Contradiction
5.2 An Irrational Example
Many proofs by contrapositive are phrased as proofs by contradiction. The objective
is to prove
P =⇒Q
and they are structured as follows:
(1) assume P is true;
(2) assume ¬Q is true;
(3) show that ¬Q implies ¬P;
(4) deduce that ¬P is true;
(5) since we have that both P and ¬P are true, we have shown assuming ¬Q is true
leads to a contradiction so Q is true;
(6) that is we have shown P =⇒Q.
First, note that in this proof by contradiction the third statement, R, is actually P.
Second, the crucial part of this proof structure is line 3. This may or may not use the
truth of P which was assumed at step 1. If it does not then we can short-circuit the
argument and replace it with
(1) show that ¬Q implies ¬P;
(2) invoke the equivalence of contrapositives and deduce that P =⇒Q.
The second structure is a proof by contrapositive rather than contradiction and it is
much simpler when it applies.
A standard well-known example of proof by contradiction is the irrationality of
the square root of 2. The argument goes as follows.
• Suppose
√
2 is rational then there exists m, n positive natural numbers such that
2 = m2/n2 where m and n have no common factors.
• We can write m2 = 2n2.
• So m2 is even. The number m is even or odd. The square of an odd number is odd
so m is not odd.
• So m is even and m = 2k for some integer k.
• 2n2 = 4k2 so n2 = 2k2.
• So n2 is even and by the same argument as above, n is even.
• So 2 is a common factor of m and n, but they were said to have no common factors
so we have a contradiction.
• Our initial assumption must be false and
√
2 is not rational.
Some points to note, if we phrase our statements correctly, we do not need
√
2 to
exist as a real number for this proof; the statement that lead to a contradiction was
2 = (m/n)2
not that
√
2 = m/n. The difference being that the latter statement requires us to
work in a bigger number system where
√
2 makes sense. Second, we used the fact

5.2 An Irrational Example
35
that any rational number can be expressed as a ratio of two integers that have no
common factors which we proved as Theorem 4.2.
Beforeconsideringcontrapositives,itisworththinkingaboutwhatwehaveproven
and to what extent the result is generalizable. Our main result is that
x2 = 2,
has no rational solutions. A natural question to ask is “what is special about 2?” Of
course, many things are special about 2. It is even, it is prime, and it appears twice in
this equation. The crucial argument in the proof was that if 2 divided the square of a
number, m, then 2 also divides m. So we can expect the same result to hold for the
square root of any number k that has this property. Prime numbers have this property,
see Sect.4.5:
p|m2 =⇒p|m,
(5.2.1)
so it will follow that the square root of any prime is also irrational once we have
proven (5.2.1). We do this below.
Perfect squares trivially have rational square roots. However, there are many num-
bers that are neither prime nor are perfect squares. The smallest such number is 6,
another one is 12. If we use a calculator to compute their square roots, these show
no obvious patterns and so might be irrational. My computer gives
√
6 = 2.44948974278318 and
√
12 = 3.46410161513775.
Remember that computer numbers are always approximations; this does not mean
that there are not more digits. We certainly have
12 | 36
but 12 does not divide into 6. So our proof does not generalize to 12. Of course, that
does not mean that
√
12 is not irrational, merely that we need a different method
of proof.
What if we proceed via contrapositive? Our new statement is: if q is rational and
not an integer then q2 is not an integer. If we can we prove this, then we have shown
that all non-perfect squares have irrational square roots. Even more generally, we
could consider the analogous statement for kth powers: for k ⩾2, if q is rational and
not an integer then qk is not an integer. Once this is proven, we will have that all kth
roots are integers or irrational.
Now for the proof: if q is rational and not an integer then q can be written as m/n
with m and n coprime and n > 1 using Theorem 4.2. Note that that if n = 1, q is an
integer which we assumed was not the case so n ̸= 1. Now consider
qk = mk
nk .

36
5
Contrapositive and Contradiction
This will be an integer if and only if nk divides into mk. We show that it cannot. We
show that no natural number bigger than 1 divides both nk and mk. This will follow
if we show no prime number divides both numbers, since any natural number greater
than 1 is prime or composite, and any composite number will have a prime factor
(see below). Let p be a number that is either 1 or a prime such that
p|mk and p|nk.
We need a lemma:
Lemma 5.1 Let l be a positive integer. If a number, p, that is 1 or prime divides lk
for k ⩾2 then p|l.
Given this lemma, we have that p divides m and n, but m and n have highest
common factor 1 so p must be 1. So qk is not an integer and every root of an integer
that is not an integer is irrational.
We still have to prove our lemma.
Proof We use Corollary 4.1. If p is 1 there is nothing to prove, so assume that p
is prime. We use induction. If k = 2, then this is just Corollary 4.1. For general k
assume the result is known for k and suppose p|lk+1 then writing
lk+1 = lkl,
we have by the same Corollary that either p|l or p|lk. In the ﬁrst case, we are done,
and in the second, the result follows immediately from the inductive hypothesis and
we are done.
□
Although the irrationality of the square root is a standard example of the power
of proof by contradiction, we have seen that is perfectly possible to prove it by
contrapositive. We have also proven a much more general result: any kth root of a
positive integer that is not an integer is irrational.
5.3 The Inﬁnitude of Primes
There are an inﬁnite number of primes. Before proceeding to the proof. We ﬁrst
establish a lemma.
Lemma 5.2 Every integer, y, bigger than 1 has a prime factor.
Proof If y is prime, we are done. Otherwise, y = k1l1 with k1,l1 > 1. Note that
k1 ⩽y/2. Either k1 is prime and we are done, or k1 = k2l2, with k2,l2 > 1. We
now have
k2 ⩽k1/2 ⩽k1/4.

5.3 The Inﬁnitude of Primes
37
Either k2 is prime or we can construct k2 = k3l3 and so on. Since 2y ⩾y, this process
must halt by step y and we are done.
One could also prove this result using complete induction—in fact, it follows
directly from the results of Sect.1.2.
□
How can we prove the inﬁnitude of primes?
First, we use proof by contradiction.
Proof Suppose there are a ﬁnite number, N, of primes. Then we can label them,
p1, p2, . . . , pN to make a list. If we now let
x = p1 p2 p3 . . . pN + 1,
then x is either prime or composite. It cannot be prime since it is not on the list. We
also have that x divided by p j has remainder 1 for each j so it is not a product of
the primes on our list either. However, by our lemma x has a prime factor p, but p
is not on our list. We have a contradiction: assuming the list was ﬁnite and complete
led to the existence of a prime not on the list. So our initial assumption that a ﬁnite
list could be complete was false, and there are an inﬁnite number of times.
□
However, we do not really need proof by contradiction.
Proof We show that any ﬁnite list of primes is not complete, and so the number of
primes must be inﬁnite. Let p1, p2, . . . , pN be a list of primes. Let
x = p1 p2 p3 . . . pN + 1.
From our lemma, x has a prime factor, p. Each p j does not divide x, since the
remainder is 1. So p j ̸= p for all j. We have constructed a prime not on the list, and
so the list is not complete, as claimed. The number of primes is therefore inﬁnite. □
The two arguments are very similar. What is the difference? In the ﬁrst, we assume
that the list of ALL primes is ﬁnite and show that that generates a contradiction. In
the second, we show that any given ﬁnite list of primes is not complete. This proves
that the number of primes is greater than N for all N and so that it is inﬁnite.
5.4 More Irrationalities
Suppose x is irrational and q is rational. What can we say about y = x + q? If y is
rational, then we have for some integers, k,l, m, n,
k
l = x + m
n .

38
5
Contrapositive and Contradiction
It follows that
x = k
l −m
n = kn −lm
ln
.
The right hand side is a rational number so this contradicts the irrationality of x.
Invoking proof by contradiction, we conclude that y is not rational.
Alternatively, we could employ proof by contrapositive. Our contrapositive is
Proposition 5.1 If q1 and q2 are rational and for some x ∈R, we have
q1 = q2 + x,
then x is rational.
Proof We have
x = q1 −q2 = k
l −m
n = kn −lm
ln
for integers k,l, m and n. So x is rational.
□
If x is irrational and q2 is rational, we therefore must have that by contrapositive
that q1 is irrational and we are done.
5.5 The Irrationality of e
Recall that the number e is deﬁned by
e =
∞

n=0
1
n!.
When studying e it will be convenient to use some results about geometric series.
The main result we will use is
Proposition 5.2 If |x| < 1, then
∞

j=0
x j exists and equals (1 −x)−1.
With this fact handy, we ﬁrst look at why the sum for e makes sense. Let
xk =
k

n=0
1
n!.

5.5 The Irrationality of e
39
The sequence xk is increasing since each additional term is positive. Any bounded
increasing sequence converges (see Chap.10). So we need to show that the terms xk
are bounded. We use that for n > 1,
1
n! ⩽
1
2
n−1
.
To see this just replace each number bigger than 2 in the deﬁnition of n! with 2. So
xk ⩽2 +
k

n=2
1
2
n−1
.
So xk < 4 for all k by our result on geometric series. We have a bounded increasing
sequence and convergence follows. We have given an example of proof of conver-
gence by domination. To prove that a series of positive terms converges, we ﬁnd
another convergent positive series of which each individual term is bigger.
We have shown that the number e makes sense. We still need to show that it is
irrational. We show that for any natural numberq, the number qe is not an integer. Any
rational number can be turned into a integer simply by multiplying by its denominator
so this is enough. If qe is an integer, then so is q!e. So it is enough to show that q!e
is not an integer for any q ∈N.
We can write
q!e =
q

k=0
q!
k! +
∞

k=q+1
q!
k! .
If k ⩽q,
q!
k! = (k + 1)(k + 2) . . . (q −1)q,
and this is an integer. We will show that the remaining term is between zero and 1
which proves that q!e is not an integer. For k > q,
q!
k! =
1
q + 1
1
q + 2 . . . 1
k ⩽

1
q + 1
k−q
.
Using the sum of a geometric series with x = 1/(q + 1), we now observe
∞

m=1

1
q + 1
m
= 1
q
which is less than 1. This shows that the tail of the expansion of q!e is less than 1.
Since it is between zero and one, it is not a whole number. It follows that q!e is not
a whole number and so that e is not rational.

40
5
Contrapositive and Contradiction
5.6 Which to Prefer
Some mathematicians love proof by contradiction. Some hate it. I generally ﬁnd
that I can rephrase proofs by contradiction to be proofs by contrapositive, and I
generally ﬁnd such rephrasings cleaner. However, it is often easier to ﬁnd the proof by
contradiction in the ﬁrst place. Ultimately, mathematicians greatly prefer any proof to
no proof! However, it is generally worthwhile to see whether a proof can be rephrased
if for no other reason than that the process of rephrasing yields extra insights.
The main reason I prefer proofs by contrapositive is that everything within the
proof is true under the contrapositive assumptions. With proof by contradiction, your
objective is to show that everything after the assumptions is false! This means that
with proof by contrapositive, I get to know many additional things I do not get with
proof by contradiction.
5.7 Contrapositives and Converses
I wish to emphasize that the contrapositive is not the converse. The contrapositive of
P =⇒Q
is
¬Q =⇒¬P.
The converse is
Q =⇒P
which has contrapositive
¬P =⇒¬Q.
Whilst statements are logically equivalent to their contrapositives, converses are a
differentmatter.Astatementcanbefalseanditsconversetrueandviceversa.Suppose
n is a number bigger than 2. The statement n is prime implies that n is odd is true.
However, if n is odd it does not have to be prime.
5.8 The Law of the Excluded Middle
Another basic technique from logic is the law of the excluded middle. It states that
given a statement P, either P is true or not P is true. No other possibility can occur.
We give a brief example of its application. We want to prove that there exist irrational

5.8 The Law of the Excluded Middle
41
numbers p and q such that
pq
is rational. Consider
√
2
√
2√
2
=
√
2
2 = 2.
This number is certainly rational. Let P be the statement that
√
2
√
2
is irrational. Either P is true and so setting
p =
√
2
√
2, q =
√
2,
we have our example. Or P is false and we have that
√
2
√
2
is rational, and we are done. We have proven the existence of a pair (p, q) both
irrational such that pq is irrational. However, we have not found such a pair! Our
proof is silent on which of the two possibilities holds. The law of the excluded middle,
like proof by contradiction, is not constructive.
5.9 Problems
Exercise 5.1 Use proof by contradiction to show that
√
12 is irrational.
Exercise 5.2 What are the contrapositives of the following statements?
• Every differentiable function is continuous.
• Every inﬁnite set can be placed in a bijection with the rationals.
• Every prime number is odd.
• Every odd number is prime.
What are their converses? Which are true?

Chapter 6
Intersection-Enclosure and Generation
6.1 Introduction
In many areas of mathematics, we study subsets with speciﬁc properties. For an
arbitrary subset, we then want to ﬁnd its smallest superset with the requisite proper-
ties. The ﬁrst question to answer is “does such a smallest set exist?” Thus we have
a set A contained in some larger set E. We have a property P and we want to ﬁnd a
set B such that
A ⊆B ⊆E
which has the property P, and which is contained in all subsets of E which both con-
tain A and have the property P. One solution to this problem is to use the intersection-
enclosure pattern.
6.2 Examples of Problems
A non-empty subset, B, of R is said to be an additive subgroup if the difference of
any two elements of B is also in B. In symbols
x, y ∈B
=⇒
x −y ∈B.
Note that 0 = x −x ∈B. It follows that −x is also in B. A quick consequence is
that x + y is in B if x and y are in B, as well as x −y.
Our problem is to show that for any set A there is a smallest additive subgroup
containing it.
A trivial example is “what is the smallest additive sub-group containing 1?” The
answer is the integers! Try to convince yourself that is indeed the case. A slightly
harder example is to let A be {
√
2}. We then end up with the integers scaled by
√
2.
© Springer International Publishing Switzerland 2015
M. Joshi, Proof Patterns, DOI 10.1007/978-3-319-16250-8_6
43

44
6
Intersection-Enclosure and Generation
A non-empty subset, B, of Rn is said to be a vector sub-space if the sum of any
two elements of B is also in B, and any scalar multiple of an element of B is also
in B. In symbols
x, y ∈B
=⇒
x + y ∈B,
x ∈B, λ ∈R
=⇒
λx ∈B.
The problem is therefore to show that there is a smallest subspace containing any
set A.
We give some examples of sub-spaces. Consider any vector x. The set
Bx = {λx | λ ∈R}
is a vector sub-space and is, in fact, the smallest one containing x. Another simple
example is to consider all the vectors whose ﬁrst coordinate vanishes. Adding two
such vectors will result in a vector with zero ﬁrst coordinate, and multiplying by a
scalar will not change the ﬁrst coordinate’s zeroness.
Obviously, there is nothing special about the ﬁrst coordinate, and we could obtain
a subspace by choosing any one of the coordinates and requiring it to be zero. More
generally, we could make a ﬁxed subset of coordinates zero.
A subset B of R is said to be closed if the limit of every convergent sequence in
B is also in B. Thus
xn ∈B ∀n, xn →x ∈R
=⇒x ∈B.
For example, the set [0, ∞) is closed since the limit of a sequence of non-negative
points is also non-negative. However, the set B = (0, ∞) is not. If we take xn = 1/n
then xn converges to zero which is not in B.
The integers are also a closed subset of R since a sequence of integers only
converges if it is eventually constant, and the limit is then this ﬁnal constant.
A subset, B, of Rn is said to be convex if the straight line between any two of its
points is also contained in it. So
x, y ∈B, λ ∈(0, 1)
=⇒λx + (1 −λ)y ∈B.
6.3 Advanced Example
In probability theory, the concept of a sigma algebra is important. We have a set 
and a collection of subsets of  typically called F. This collection is called a sigma
algebra if
•  ∈F,
• C ∈F implies Cc ∈F,

6.3 Advanced Example
45
• C, D ∈F implies C ∪D ∈F,
• if Cn is a sequence of sets in F then
∞

n=1
Cn ∈F.
The same problem arises of ﬁnding the smallest sigma algebra which contains a
given collection of subsets.
6.4 The Pattern
In all the examples above, there is an important additional feature. If we take an inter-
section of subsets with a given property then the intersection also has the property.
This intersection can be over an inﬁnite collection of subsets and the property is
still retained.
For example, if Eα is an additive sub-group of R for all α ∈I for some index
set I, then
E =

α∈I
Eα = {x | x ∈Eα, ∀α},
is also an additive sub-group. To see this, if x, y ∈E then x, y ∈Eα for all α ∈I
so x −y ∈Eα. Since this is true for all α, we have
x −y ∈E
and E is indeed an additive subgroup.
The pattern is therefore to consider the set of subsets with the given property which
contain a given set A and take their intersection. We need that the encompassing set
E has the property to ensure that the intersection is over a non-empty collection. We
thus let
B = {x | x ∈C ∀C such that A ⊆C and the property holds for C}.
First, B contains A since A is a subset of all the sets C which we intersect. Second,
since the property is preserved by intersections and it holds for each set C, it also
holds for their intersection, that is B.
We have thus constructed a set B containing A for which the property holds. We
now need to show that it is the smallest such set. However, if we take an arbitrary
set, C, with the property then it would have been part of the intersection. So B is
its intersection with some other sets and by the deﬁnition of intersection must be
contained in it.
In conclusion, B is the smallest set containing A for which the property holds.
This construction works provided the property holds for the encompassing set E and
is preserved by arbitrary intersections.

46
6
Intersection-Enclosure and Generation
An intersection of vector subspaces is also a vector subspace, and the smallest
one containing A is said to be generated by A or sometimes its linear span.
Closedness is preserved by intersections and the smallest closed set containing
A ⊆R is called its closure and generally written ¯A.
The smallest convex set containing A ⊆Rn exists by the same argument, and is
called the convex hull.
6.5 Generation
The set B produced from A by the enclosure-intersection pattern we have discussed
is often said to have been generated by A. There is often an alternative way to ﬁnd
B which is more intuitive. However, proving that it works is sometimes harder. In
this section, we explore this alternative.
Instead of considering intersections, suppose instead that we keep on adding in
the elements that stop the property from holding. First, we look at additive subgroups
of R. We analyze the subset {1} using generation. Let
A0 = {1}.
It is not an additive subgroup because it does not contain 1 −1 = 0. So we add in
zero. We therefore let
A1 = {0, 1}.
We are now missing −1. So we let
A2 = {−1, 0, 1}.
But we now need −2 and 2 and so on.
We can therefore let
A j+1 = A j ∪{x −y | x, y ∈A j},
for j = 1, 2, 3, . . . . The problem is that the process may not terminate. If it does
then we have for some k
Ak = Ak+1
and this means that Ak is an additive subgroup. It is the smallest one containing A
since any additive subgroup is required to be invariant under the operations used to
generate Ak.
However, it is clear that for our example the process does not terminate. To see
this, ﬁrst observe that A j has a ﬁnite number of elements for all j. It must therefore
have a largest element, z. Clearly, z + 1 is in A j+1 −A j.

6.5 Generation
47
A solution is at hand, however. We simply take the union, let
A∞=

k
Ak.
The set A∞contains A trivially. It is contained in the smallest additive subgroup, B,
containing A since B must contain Ak for all k.
It remains to check that A∞is indeed an additive subgroup. If x, y ∈A∞then
x ∈Al for some l and y ∈Am for some m. We then have
x, y ∈Amax(l,m).
So
x −y ∈Amax(l,m)+1.
This shows that x −y ∈A∞and we are done.
This argument worked because the deﬁnition of an additive sub-group is essen-
tially ﬁnite. We only look at the difference of two elements and require that to be
in the same set. This allowed us to specialize down to a point before inﬁnity. If our
property was deﬁned in terms of a larger ﬁnite number of elements then the argument
would still work. However, if an inﬁnite number of elements were involved then it
might not.
What could we do if A∞did not have the invariance property required? One
solution is simply to start over again using A∞in place of A0. Thus we get a sequence
of sets A∞, j and we can deﬁne
A∞,∞=

k
A∞,k.
If the property still does not hold, then there is nothing to stop us repeating as many
times as we want. Indeed, we can do so inﬁnitely often and then take the union of all
the generated sets again. Hopefully, that will be enough but if not, we can keep going.
More generally, we can imagine an operation on our set that involves an uncount-
able number of its elements and this will be even harder. (We discuss the notion of
uncountability in Chap.13.) To give a general proof that this process of using bigger
and bigger unions will eventually terminate is actually very hard. So whilst genera-
tion is in many ways more intuitive than intersection-enclosure, it can be harder to
work with.
The reader may be curious to see an example where generation terminates before
inﬁnity, that is an example where A j = A j+1 ̸= A0 for some j. Let
A0 = {2 j | j ∈Z} ∪{1}.

48
6
Intersection-Enclosure and Generation
So A0 is all even integers together with 1. We clearly do not have an additive subgroup
and A1 is the set of all integers, Z. However, Z certainly is an additive subgroup and
the process terminates.
6.6 Fields and Square Roots
The real numbers have various properties including closure under addition and
multiplication, the existence of additive inverses and for non-zero elements the exis-
tence of multiplicative inverses. In equation terms,
x, y ∈R =⇒x + y, xy ∈R,
x ∈R =⇒∃y, x + y = 0,
x ∈R −{0} =⇒∃y, xy = 1.
An extra property that R has, but Q does not, is that non-negative numbers have
square roots. So
x ∈R =⇒∃y, y2 = |x|.
We can therefore write √|x| for elements of R. For elements of Q we can write √|x|
but we are not guaranteed that the result is in Q.
The question then arises of ﬁnding the smallest subset of R closed under addition,
subtraction, multiplication and division which contains Q and is also closed under
the taking of square-roots of positive numbers. This is called ﬁnding the smallest
sub-ﬁeld with the square-root property.
First, does such a smallest sub-ﬁeld exist? Yes. This is a direct application of
intersection-enclosure. The set R contains Q and is invariant under these operations.
Since these properties are all deﬁned in a ﬁnite way, it is trivial to check that any
intersections of such sets is also invariant so intersection-enclosure does apply.
The existence of a smallest sub-ﬁeld does not imply that the smallest sub-ﬁeld
is not R. In fact, there are smaller sub-ﬁelds but we have to prove they exist. Now
suppose we apply generation. Let F0 = Q. We let F j be the set of points of the form
p + q√r for p, q,r ∈F j−1
with r > 0. Note that it would be equivalent to use p + q√|r|, since r ∈F j implies
that −r ∈F j. We then let
F =

j
F j.
The ﬁniteness of the conditions guarantees that F is indeed a square-root closed
sub-ﬁeld.

6.6 Fields and Square Roots
49
In fact, each set F j is a sub-ﬁeld. For example, if x ∈F j then
x = p + q√r, with p, q,r ∈F j−1,
and
x−1 =
1
p + q√r = p −q√r
p2 + q2r
which is clearly in F j. The other operations are easily checked. However, for
square-roots there is no reason to think that F j is closed. But if x ∈F, then for
some j, x ∈F j so √|x| ∈F j+1 ⊂F, so F is invariant under square roots. Similarly,
since every F j is closed under the other operations so is F.
The question remains of whether F = R. We prove that it is not by showing that
a well-known number, the cube-root of 2, is not in F. We show
Theorem 6.1 If the equation
x3 −m = 0
with m a rational has a solution in F then it has a solution in Q.
Proof Let x1 be a root in F then x1 ∈F j for some j. If j = 0, we are done. Otherwise,
let
x1 = p + q√r
with p, q,r ∈F j−1. We will show that there must be a solution in F j−1. We have
0 = (p + q√r)3 −m = p3 + 3p2q√r + 3pq2r + q3r3/2 −m,
or grouping
0 = (p + q√r)3 −m = (p3 + 3pq2r −m) + (3p2q + q3r)√r.
Let
α = p3 + 3pq2r −m, β = 3p2q + q3r.
If β is non-zero then
√r = −α/β
which shows that p + q√r ∈F j−1. Otherwise,
α = β = 0.
In this case,
(p −q√r)3 −m = α −β√r = 0.

50
6
Intersection-Enclosure and Generation
So x2 = p −q√r is also a root. We have found two real roots of our equation unless
q√r = 0. If it does, then our original root was in F j−1 and we are done.1
We will now show that there if there are two real roots then there is a third and
that it is in F j−1. We use the fact that a cubic real polynomial that has two real zeros
has three real zeros. We prove this below. Call the roots x j, we can write
x3 −m = (x −x1)(x −x2)(x −x3) = x3 −(x1 + x2 + x3)x2 + γx + δ
for some real numbers γ and δ. We must have that the coefﬁcient of x2 is zero since
it is zero in x3 −m, so
x3 = −x1 −x2 = −p −q√r −p + q√r = −2p.
Since p was in F j−1, we have a root in F j−1.
Repeating, we have a root in F0 = Q as claimed.
□
Now consider the case where m is not a perfect cube such as when m = 2. We
know from Sect.5.2 that the cube root is not rational, so there cannot be a root in F.
We thus have lots of examples of real numbers that are not in F.
We used a lemma without proof.
Lemma 6.1 If a cubic polynomial with real coefﬁcients has 2 real roots then it has
3 real roots.
There are multiple ways to prove this. First, we proceed in an elementary way.
Proof To see this divide the cubic polynomial, p(x), by (x −x1)(x −x2). We can
then write
p(x) = (ax + b)(x −x1)(x −x2) + cx + d,
for some real numbers a, b, c, d. Putting x = xi for i = 1, 2 yields
cxi + d = 0.
Since this is true for two distinct values of i, we must have c = d = 0. We then have
that
x3 = −a/b
is a root. So we have a third real root.
□
1 In fact, x3 −m only has one real root and an alternate route to proving this theorem is to show
that.

6.6 Fields and Square Roots
51
One alternate proof uses the fundamental theorem of algebra which we prove in
Chap.19. This implies that every cubic polynomial has three complex roots. It is
then a question of showing that the third root is real. If the roots are z j we know that
z1, z2 are real. We also know that
z1 + z2 + z3 = −a2,
where a2 is the coefﬁcient of x2 which we have assumed to be real. So z3 = −a2 −
z1 −z2 is also real. Alternatively, it is easy to show that the complex conjugate of
any complex zero of a real polynomial is also a zero. If z3 is not real, its complex
conjugate would yield a fourth root which is impossible so z3 is real.
6.7 Problems
Exercise 6.1 Check that the intersection-enclosure pattern does indeed apply to each
of the examples of Sect.6.2.
Exercise 6.2 Given 3 points in the plane, what is their convex hull? Distinguish
according to whether the 3 points are collinear.
Exercise 6.3 Given a subset of the plane, how many steps are required for the gen-
eration algorithm for convexity to terminate?
Exercise 6.4 A subset of R is said to be binarily division invariant if dividing
any element by 2 results in an element of the subset. Check that intersection-
enclosure applies. Also analyze generation for this property and show that it ter-
minates with A∞.
Exercise 6.5 A subset of R is said to be binarily division invariant and zero-happy
if dividing any element by 2 results in an element of the subset, it is closed, and, in
addition, if it contains zero then it also contains 2. Check that intersection-enclosure
applies. Also analyze generation for this property and show that it does not always
terminate with A∞.
Exercise 6.6 A subset of R is said to be open if its complement is closed. Will there
be a smallest open subset containing [0, 1]?
Exercise 6.7 Show that if a p is a polynomial with real coefﬁcients and p(z) = 0
then p(¯z) is also zero. Use this fact in conjunction with the fundamental theorem of
algebra to show that every real polynomial of odd order has a real zero.

Chapter 7
Difference of Invariants
7.1 Introduction
One of the main themes in modern mathematics is the classiﬁcation of types of
objects. Given two objects of a given type, are they in some sense equivalent? Can
we ﬁnd a simple way to tell? One common to approach is to associate numbers to
the objects in such a way that equivalent objects have the same numbers.
If two objects have distinct numbers then they are truly different. The related
problem of ﬁnding a set of numbers that truly characterises a class of objects is
generallymuchharder.Indeed,thecharacterisingpropertiesmaynotevenbenumbers
but instead some simpler other class of objects.
7.2 Dominoes and Triminoes
We start with a simple example. Consider a chess-board from which two opposite
corners have been removed. We have a set of dominoes. Each domino is the precise
size of two squares of the chess-board. Is it possible to completely cover the board
with dominoes in such a way that there is no overlap or protruding pieces? What
about the same problem using triminoes? A trimino covers 3 squares of the board,
and it may be straight or angular.
An alternate way of phrasing this problem is “is it possible to build a board
of this shape by sticking dominoes (or triminoes) together?” We can generalize
further by allowing the sticking of dominoes to the edge before they are laid on top.
Indeed, we could view laying on top as cutting off a domino shape. The problem
then becomes “what board shapes can be transformed into which other shapes?” Our
original problem is now “can the board minus opposite corners be transformed to
the empty board?”
Infact, thetriminoes problemis easier thanthedominoes one. Thereare62 squares
left on the board. A trimino covers 3 squares. The remainder when we divide 62 by 3
© Springer International Publishing Switzerland 2015
M. Joshi, Proof Patterns, DOI 10.1007/978-3-319-16250-8_7
53

54
7
Difference of Invariants
is 2. Adding or subtracting a trimino will not change this number. We will therefore
never get to zero. It is not possible to cover the board with triminoes and we are done.
In this case, our invariant is the remainder on dividing the number of squares by 3.
The board and the empty board have different invariants so we cannot go from one
to the other. We have used difference of invariants to establish the impossibility.
Now suppose we remove the other two corners. The number of remaining squares
is now 60. The remainder on dividing by 3 is 0 so they have the same invariant. It
may therefore be possible to cover with triminoes. Or it may not! The difference of
invariants only establishes impossibility. If the invariant is the same, it does not tell
us much.
What about dominoes? The board has 62 squares which is a multiple of 2 so
working with the remainder on division by two is not going to help. We therefore
have to look for another invariant. A domino will always cover one black square
and one white. We therefore use the number of black squares minus the number of
white squares as our invariant. For a chess-board with all its corners, this invariant
is zero. If we subtract two opposite black corners, we get −2, and for two opposite
white corners, we get 2. The empty board clearly has zero. Subtracting a domino
shape or adding one will not affect this invariant. We can therefore never get to zero.
No matter how small we get, we will always be left with two more squares of one
colour than the other. Note that in this case, if we subtract two adjacent corners, the
invariant is zero, and it is, in fact, rather easy to cover the board with dominoes.
We have seen in a rather simple setting that the use of an invariant can establish
that it is impossible to go from one object to another. The crucial point was that we
found a number that did not change under each operation. This number was different
for the two original objects and so we could not go from one to the other.
7.3 Dimension
All mathematicians and most users of mathematics learn linear algebra at some
point in their career. A key invariant in linear algebra is dimension. In this section,
we explore this concept and look at how to use it to establish that linear sub-spaces
are different in a linear sense.
We shall say that a subset, E, of Rn is a vector sub-space if it is closed under
addition and scalar multiplication. So
x, y ∈E
=⇒x + y ∈E,
x ∈E, λ ∈R
=⇒λx ∈E.
In Sect.6.4 a proof that every subset, A, of Rn is contained in a smallest sub-space,
E, was given. The subset A is then said to generate E. In fact, the set E is given by
all ﬁnite linear combinations of elements of A. So if
A = {a1, a2, . . . , ad}

7.3 Dimension
55
then every element of E can be written as
e =
d

j=1
λ ja j
for some real numbers λ j. To see that this holds, ﬁrst observe that the set of all such
vectors is a vector sub-space that contains A. So by the intersection-enclosure pattern
it contains E. Second, any sub-space that contains A must contain all such sums by
deﬁnition so E must contain them.
We shall say that a map,
T : U →V,
between sub-spaces U and V is a linear map, if
T (λx + μy) = λT x + μT y,
(7.3.1)
for all x, y ∈U and λ, μ ∈R. If there exists a linear map S : V →U such that
ST is the identity map on U and T S is the identity on V then we say that U and V
are linearly equivalent. Note that since T has a two-sided inverse, it is necessarily
a bijection.
We shall say that a vector sub-space, V , is of dimension d if the smallest set that
generates it is of size d. If a vector sub-space is of dimension d, then there are vectors
v1, v2, . . . , vd in V such that every element v of d can be written in the form
v =
d

j=1
λ jv j.
(7.3.2)
Such a minimal set of elements {vk} is called a basis.
The representation is unique: if we have
d

j=1
μ jv j = v =
d

j=1
λ jv j,
and λk ̸= μk for some k, then
vk =
1
μk −λk

j̸=k
(λ j −μ j)v j.
We can then use this equation to substitute for vk and thus eliminate vk from the right
hand side of (7.3.2), and thus express every element v using d −1 elements which
contracts the minimality of d.

56
7
Difference of Invariants
Consider R3. Let Ui be the sub-space of elements which may be non-zero only
in coordinate i. So U1 consists of vectors of the form
⎛
⎝
x
0
0
⎞
⎠.
Let Vi be elements that are zero in coordinate i. So V1 is the set of vectors of the form
⎛
⎝
0
y
z
⎞
⎠.
The sub-spaces Ui are clearly of dimension 1. They can be generated by the vector
with 1 in the appropriate slot, and they can clearly not be generated by 0 vectors!
The sub-spaces Vi are of dimension 2. Clearly, V1 can be generated by
⎛
⎝
0
1
0
⎞
⎠,
⎛
⎝
0
0
1
⎞
⎠.
We need to show that it cannot be generated by a single vector. If we take a ﬁxed vector
⎛
⎝
0
x
y
⎞
⎠,
and y is zero then it clearly does not generate and we get U2. If y is non-zero then
we get vectors
⎛
⎝
0
λx
λy
⎞
⎠,
with λ an arbitrary element of R. If we divide the second coordinate by the third
then we get the same value, x/y, for every non-zero λ. This is clearly not the case
for general elements of V1 since it contains
⎛
⎝
0
1
1
⎞
⎠,
⎛
⎝
0
0
1
⎞
⎠.
So V1 cannot be generated by a single element and has dimension 2.
Note that the only difference between the deﬁnitions of V1, V2 and V3 is the
labeling of the entries. We can permute the entries to make each one into either of
the others. We can therefore say that by rearrangement, the same result follows for
V2 and V3.

7.3 Dimension
57
We have seen that the sub-spaces Ui are of dimension 1 and the dimension of the
sub-spaces Vj is 2. We now use this fact to show that they are not linearly equivalent.
We do so by showing that if two sub-spaces are linearly equivalent then they are of
the same dimension.
So suppose U and V are linearly equivalent. If U is of dimension d then there
exists a basis
v1, v2, . . . , vd.
We also have a map T : U →V with inverse S. We show that
T v1, T v2, . . . , T vd
generates V . If w ∈V then w = T (Sw). Now, by the deﬁnition of a basis, there
exists scalars λ j such that
Sw =
d

j=1
λ jv j
and so
w = T (Sw),
(7.3.3)
= T
⎛
⎝
d

j=1
λ jv j
⎞
⎠,
(7.3.4)
=
d

j=1
λ jT v j,
(7.3.5)
where the ﬁnal equality comes from the deﬁnition of a linear map. This shows that
the vectors {T v j} generate V . The dimension of V is therefore at most d.
We also want to show that it is at least d. However, the same argument with U
and V switched shows that the dimension of U is less than or equal to the dimension
of V . We are done. Note that the last part of this argument was really another proof
pattern. If two quantities are deﬁned in identical manner and they have a symmetrical
relationship, then if we can prove that one is less than or equal to the other, it
follows that they are equal. The proof is simply to repeat the proof with the quantities
switched. As a general rule, symmetry plus inequality implies equality.
It now immediately follows that the sub-spaces U j are not linearly equivalent to
the subspaces Vj since they are of different dimensions.

58
7
Difference of Invariants
The case of linear subspaces is a rarity in that dimension is, in fact, enough to
classify them. Two linear subspaces are linearly equivalent if and only if they have
the same dimension. To see this, suppose U and V are of dimension d with bases
u1, u2, . . . , ud and v1, v2, . . . , vd,
respectively.
Every element, u, of U can be written uniquely as
u =
d

j=1
λ ju j
as discussed above. We deﬁne
T u =
d

j=1
λ jv j,
and similarly if
v =
d

j=1
μ jv j,
we set
Sv =
d

j=1
μ ju j.
It is immediate that ST and TS are both the identity map. Of course, we also need to
show that T and S are linear. However, that is an easy exercise which we leave to
the reader.
7.4 Cardinality
When we say two sets X and Y that have some structure are equivalent then we
generally have a bijection between them. Both this bijection and its inverse are
required to preserve the structure. In the sub-space example above, the requirement
was linearity. In topology, they are required to be continuous.
A consequence is that whatever the extra structure required, there must exist a
bijection between X and Y. Recall that a bijection is a map
f : X →Y

7.4 Cardinality
59
such that every element y of Y is in the range of f , and precisely one element of X
maps to it. So
∀y ∈Y, ∃x ∈X such that f (x) = y,
∀x1, x2 ∈X, f (x1) = f (x2) =⇒x1 = x2.
Note that a bijection, f , automatically has an inverse g: we simply deﬁne g(y) to be
the unique element x such that f (x) = y. We can regard a bijection as a relabeling.
We are simply giving the name f (x) to the element x of X. In consequence, X and
Y have the same number of elements.
In fact, for inﬁnite sets, the existence of a bijection between two sets is typically
taken as the deﬁnition of being the same size. They are then said to be of equal
cardinality. A set is said to be ﬁnite if for some n it can be placed in a bijection with
{0, 1, 2, . . . , n −1}
and it is then said to have n elements. Note that all we are really doing is labeling
the elements
x0, x1, x2, . . . , xn−1,
and so this is the same as our usual concept of a set having n elements. A set is
inﬁnite if it is not ﬁnite.
How can we use cardinality to prove that objects are not equivalent? We use
commutative groups as an example. A commutative group is a set X with an operation
+ with certain properties. There exists a special element, 0X, and elements x, y, z
in X, we have
x + y = y + x, commutativity,
(7.4.1)
(x + y) + z = x + (y + z), associativity,
(7.4.2)
x + 0X = x, identity element,
(7.4.3)
∀x, ∃y, x + y = 0X, inverse element.
(7.4.4)
The ﬁrst two properties say that + is commutative and associative. The special
element 0X called the identity element which is commonly just called zero. Every
element, x, has a negative, −x, that sums with it to zero. This negative is unique. If
x + y1 = 0X = x + y2
then
y1 = y1 + (x + y2) = (y1 + x) + y2 = y2.
It is also possible to study groups that are not commutative. In that case, we generally
write xy or x ∗y rather than x + y. We will not study non-commutative groups here
to retain simplicity.

60
7
Difference of Invariants
Three simple examples of inﬁnite commutative groups are Z, Q and R. However,
there also ﬁnite examples. One standard example is the set of integers modulo k,
denoted Zk. The underlying set is
{0, 1, 2, . . . , k −1}
which has k elements. We deﬁne x + y in the usual way if x + y is less than k.
If it is not then we subtract k from it. This is sometimes called addition modulo k.
The value 0 is clearly the identity and the inverse of x is k −x. Commutativity and
associativity easily follow from the same properties of integers.
Given two commutative groups, we can easily construct another one by taking
their Cartesian product and making addition act in each coordinate. If the groups are
X and Y, we deﬁne
X × Y = {(x, y) : x ∈X, y ∈Y},
with the operation
(x1, y1) + (x2, y2) = (x1 + x2, y1 + y2).
The element (0X, 0Y ) is the identity.
Two commutative groups X and Y are said to be isomorphic if there exists a
bijection, f , which preserves + so
f (x + y) = f (x) + f (y).
Note that for any x ∈X,
f (x) = f (x + 0X) = f (x) + f (0X),
so f (0X) = 0Y . Similarly,
0Y = f (0X) = f (x + (−x)) = f (x) + f (−x)
for any x ∈X. So
f (−x) = −f (x).
Since f is a bijection, it has an inverse f −1. It turns out that f −1 is also an
isomorphism. To see this,
f ( f −1(x) + f −1(y)) = f ( f −1(x) + f −1(y)),
= f ( f −1(x)) + f ( f −1(y)),
= x + y.

7.4 Cardinality
61
So on applying f −1 to both sides
f −1(x) + f −1(y) = f −1(x + y).
In this particular case, f preserving the structure “+” and being a bijection was
enough to make f −1 also preserve “+”. The fact that a bijection preserves a given
property implies its inverse also does so is quite a common phenomenon. However,
it is by no means universal. For example, consider the function
f (x) = x3
as a map from R to R. The function f deﬁnes an inﬁnitely differentiable bijection.
Its inverse, g, is taking the cube root which is not differentiable at the origin. So for
any differentiable function h, we have that
h ◦f
is differentiable. However, we need not have that h◦g is differentiable and in general,
it will not be. The simplest example of failure is given by taking h(y) = y.
The solution generally adopted in such circumstances is simply to make a
deﬁnition that the inverse must preserve the requisite property too! However, as
we have seen, that is not necessary for commutative groups.
A great deal of effort has gone into classifying groups under isomorphism. How
does cardinality help? Clearly, Zk has k elements so it is not isomorphic to Zr for
any r not equal to k, nor is it isomorphic to Z, Q or R since they are not ﬁnite.
In fact, one can prove that R has bigger cardinality than Z and Q and so cannot
be isomorphic to either of them. See Sect.13.4.
7.5 Order
We saw that cardinality is enough to show that Zk and Zr are not isomorphic for
r ̸= k. Now consider Zk × Zr and Zkr. Both of these groups have kr elements
so cardinality is not going to help. If they are not isomorphic we need a different
invariant.
Given an element x of a commutative group, we can deﬁne lx to be the result of
summing l copies of x together. Using associativity, it does not matter how we do
this addition:
lx = (l −1)x + x = x + (l −1)x.
We can then deﬁne the order of an element, x, to be the smallest positive natural
number, m, such that
mx = 0.

62
7
Difference of Invariants
If there is no such m, then x is said to be of inﬁnite order. For integers, rationals,
and reals all non-zero elements are of inﬁnite order so the concept is not very useful.
However,forﬁnitegroups,thesituationisratherdifferent.Inparticular,everyelement
of a ﬁnite group has order at most equal to the group’s cardinality. To see this suppose
the group, X, has cardinality k, and x ∈X. Consider the set of elements
Xx,k = {x, 2x, 3x, . . . , (k + 1)x}.
We know
Xx,k ⊆X
and the cardinality of X is k. Two elements of Xx,k must therefore be the same.
(Pigeonhole principle!) We therefore have for some s, t, with 1 ⩽s < t ⩽k + 1
sx = tx,
which implies
(t −s)x = 0.
The value m = t −s is at least 1 and at most k. We conclude that the order of x is at
most k.
How does order help? If f : X →Y is an isomorphism, then we must have
f (0X) = 0Y
and
f (mx) = m f (x).
The same holds for the inverse of f . It follows that x and f (x) have the same order.
The set of orders of group elements must therefore be the same. If we can show two
groups have different sets of orders then they are not isomorphic. Note the general
point here, f is a bijection, both f and f −1 commute with +, so the two groups
X and Y are the same except for the names of the elements. This means that any
property deﬁned in terms of “+” but not speciﬁc labels of the entries will be the same
for both groups.
Consider Zk × Zr and Zrk. The order of 1 in Zrk is rk simply by our deﬁnition
of addition. What about Zk × Zr? Some obvious elements are
(1, 0), (0, 1), (1, 1).
The ﬁrst of these has order k and the second order r. The third will have order equal
to the smallest m with k|m and r|m that is the least common multiple of k and r.
This will equal kr if and only if k and r are co-prime.

7.5 Order
63
We show that all elements of Zk × Zr have order less than or equal to this least
common multiple, m.
m(x, y) = (mx, my) = (m.1.x, m.1.y) = (0.x, 0.y) = (0, 0).
We know m.1 = 0 in both Zk and Zr since r and k both divide m.
We have shown that the highest order of any element of Zk × Zr is the least
common multiple of k and r, it is therefore not isomorphic to any group that has
an element of order kr unless k and r are co-prime. Order has given us a way to
distinguish commutative groups.
In fact, if two commutative groups X and Y have the same number of elements,
m, and they both have an element of order m then they will be isomorphic. Let the
two such elements be x and y. We deﬁne
f (lx) = ly
for l = 0, 1, . . . , m −1. Since x is of order m, the left-hand side ranges over all
elements of X. (If two elements are the same, x is not of order m.) For the same
reason, the right hand side ranges over all elements of Y and we have a bijection.
Note
f (lx + rx) = f ((l + r)x) = (l + r)y = l f (x) + r f (x),
provided l + r ⩽m −1. If l + r > m then
f (lx + rx) = f ((l + r −m)x) = (l + r −m)y = ly + ry = l f (x) + r f (x).
So f is indeed an isomorphism.
7.6 Divisibility
How can we show that Z and Q are not isomorphic? Both sets are inﬁnite and it
is possible to construct bijections between them so cardinality is not going to help.
All non-zero elements are of inﬁnite order so that will not help either. However, the
fundamental difference is that elements of Q can be divided as many times as we
like.
We can deﬁne the divisibility order of a non-zero element, x, of a commutative
group X to be the largest positive integer m such that there exists y with
my = x.

64
7
Difference of Invariants
If there is no largest value, we say that x has inﬁnite divisibility order. For any q ∈Q,
we can write
q = m q
m
for any positive integer m so all non-zero elements of Q have inﬁnite order.
What about Z? If z ∈Z, and z > 0, we can write
z = z1.
For z < 0, we have
z = (−z)(−1).
The order of a non-zero integer, z, is therefore |z|. Clearly, we cannot have a higher
order since 1 is the smallest element and multiplying by a bigger number will yield
too big an answer.
If two groups X and Y are isomorphic with isomorphism f then x and f (x) must
have the same divisibility order for all x in X. This is clearly not the case for Z and
Q since all orders in Q are inﬁnite and all ones in Z are ﬁnite. We have shown that Z
and Q are not isomorphic by establishing that they have different sets of divisibility
orders.
7.7 Problems
Exercise 7.1 What sizes of board m × n, can be covered by 2 × 2 squares?
Exercise 7.2 Deﬁne multiplication on Zk by taking xy and then taking its remainder
on division by k. For what values of x and k does there exists a number y such that
xy = 1?
Exercise 7.3 Let n be a positive integer. Let f (n) denote the sum of its digits. Show
that the remainder on division by 9 is invariant under passing from n to f (n). Use this
to show that if we keep summing up the digits of n until we get a number less than
10 then n is divisible by 9 if and only if this last number is 9. Repeat and reformulate
this result for 3. More generally, does this approach work for any other numbers?
What if we change our number base?

Chapter 8
Linear Dependence, Fields
and Transcendence
8.1 Introduction
A key idea in linear algebra and many other areas of mathematics is that of dimension.
The way in which dimension is deﬁned varies according to context. In linear algebra
it is is the number of vectors required to generate the entire space. We touched on
this idea in Sect.7.3. There we used it to show that linear maps could not be bijective
between certain subsets of Euclidean space.
In this chapter, we explore a different application. We want to show that the set
of algebraic numbers forms a ﬁeld. A complex number, x, is said to be algebraic if
there exists a non-zero polynomial p with rational coefﬁcients such that p(x) = 0.
Equivalently, one can require the coefﬁcients to be integers. These two deﬁnitions are
equivalentbecauseonecanmultiplyallthecoefﬁcientsofarationalpolynomialbythe
product of their denominators. Every rational number is algebraic. For q ∈Q solves
x −q = 0.
Numbers that are not algebraic are said to be transcendental.
To show that the algebraic numbers form a ﬁeld we have to show that if p(x) = 0
and q(y) = 0 for some rational polynomials p and q, then there are rational poly-
nomials r and s such that
r(x + y) = 0, and s(xy) = 0.
We also need a rational polynomial, t, such that
t(−x) = 0,
and if y ̸= 0, we need another one, u, such that
u(y−1) = 0.
© Springer International Publishing Switzerland 2015
M. Joshi, Proof Patterns, DOI 10.1007/978-3-319-16250-8_8
65

66
8
Linear Dependence, Fields and Transcendence
In fact, the last two are the easiest. If
p(x) =
N

j=0
c j x j,
for some c j, then setting
d j = (−1) jc j,
and taking these as the coefﬁcients we have our polynomial, t, since
t(−x) = p(x) = 0.
For y−1, we have
M

j=0
e j y j = 0
for some e j ∈Q with eM ̸= 0. So multiplying by y−M
M

j=0
e j y j−M = 0
Putting r = M −j, we can rewrite this as
M

r=0
eM−r(y−1)r = 0
and we have that y−1 is algebraic.
The other two cases are harder. Rather than trying to construct the appropriate
polynomial explicitly, we proceed by using linear dependence.
8.2 Linear Dependence
We shall say that a subset, E, of C is linearly dependent over Q if there exists
e1, . . . , en ∈E and q1, . . . , qn ∈Q not all zero such that
n

i=1
eiqi = 0.

8.2 Linear Dependence
67
In words, we can take a rational amount of each e j and sum to get zero. Note that
this implies that for some j
e j = −

i̸= j
(qi/q j)ei.
In other words, at least one of the e j can be written as a rational linear combination
of the others.
If E is not linearly dependent, we shall say that it is linearly independent. We
shall say that E spans a set V ⊂C if any element of V can be written as a linear
combination of elements of E with rational coefﬁcients. So
v ∈V =⇒∃q j ∈Q, such that v =
n

j=1
q je j.
The crucial result we need is that if a subset F of V has more elements than a ﬁnite
spanning subset E then F is linearly dependent.
We ﬁrst shrink E to ensure that is linearly independent. If it is already linearly
independent there is nothing to be done, otherwise some element, ek, of E is a rational
linear combination of other elements of E:
ek =

j̸=k
λ je j.
Now if v ∈V then for some {q j}, we have
v =
n

j=1
q je j =

j̸=k
q je j + qk

j̸=k
λ je j
So we can discard ek from E and still have a spanning set. We keep doing this until E
is linearly independent and spanning. A linearly independent spanning set is called a
basis. Note that if F had more elements than E before the discards, it certainly does
afterwards so it is enough to consider the case that E is linearly independent.
We now suppose that E has n elements and is both linear independent and span-
ning. Consider F. Call its elements { f j}. It has at least n + 1 elements. If the ﬁrst n
elements are linearly dependent then so is F and we are done. It is therefore enough
to consider the case that they are linearly independent. We will show that in this case
they span V . This will be enough since fn+1 ∈V and so is in the set spanned by
V which is equivalent to saying that it is a linear combination of the other elements.
This says that F is linearly dependent.
Wewanttoprovethattheﬁrstn elementsof F spaniftheyarelinearlyindependent.
In fact, we will show that any subset of V that is linearly independent and has n
elements is spanning. This is key to the concept of dimension in a linear context: all
ﬁnite linearly independent spanning sets have the same number of elements. We can

68
8
Linear Dependence, Fields and Transcendence
therefore say that the dimension of their span is equal to their size, and this deﬁnition
makes sense since it is choice independent.
We proceed by induction. We will use permutations of {1, . . . , n}. A permutation
is a bijection on a set and can be simply thought of as a rearrangement of the numbers.
Our inductive hypothesis is that there exists a permutation, σ, of {1, 2, . . . , n} such
that if Ek is given by
Ek = { f1, . . . fk, eσ(k+1), . . . , eσ(n)}
then Ek spans V . In other words, if we pick the right subset of E with n −k elements
then it together with the ﬁrst k elements of F spans. If k = 0, the hypothesis is just
that E spans which is certainly true. Now suppose the hypothesis holds for k and
we want to prove it for k + 1. We have fk+1 ∈V , so it is in the span of Ek and we
can write
fk+1 =

j⩽k
α j f j +

j⩾k+1
β jeσ( j).
with α j, β j ∈Q. The set F is linearly independent so fk+1 is not in the linear span
of f j with j < k. This means that we must have β j ̸= 0, for some j > k. We
can relabel the elements of E so that βk+1 ̸= 0. The rearrangement is equivalent to
changing the permutation but that is within our inductive hypothesis and causes no
problems. We use this new ordering to deﬁne Ek+1 as the ﬁrst k + 1 elements of
F followed by the remaining elements of E post this permutation. Since βk+1 ̸= 0,
we have
eσ(k+1) =
1
βk+1
⎛
⎝fk+1 −

j⩽k
α j f j −

j>k+1
β jeσ( j)
⎞
⎠.
To express any element, v, of V using Ek+1, we ﬁrst write it as a linear combination
of elements of Ek. We then substitute for eσ(k+1) using this expression. We have
written it as a linear combination of elements of Ek+1. We have proven the inductive
hypothesis for k + 1. It follows that the result holds when k = n, and the ﬁrst n
elements of F span.
The result we have just proven is sometimes called the Steinitz exchange lemma.
It holds in much more general contexts than the one we have done here, but the proof
is essentially the same.
Having proven that the ﬁrst n elements of F span, it follows that fn+1 is a rational
linear multiple of them. We conclude that F is linearly dependent as required.

8.3 Linear Dependence and Algebraic Numbers
69
8.3 Linear Dependence and Algebraic Numbers
We now show that the sum of two algebraic numbers is algebraic. First, observe that
the statement that x + y is algebraic is equivalent to the statement that there exists n
such that the set
{(x + y) j, j = 0, . . . , n}
is linearly dependent over Q. For both statements say that there exist rational numbers
γ j not all zero, such that
n

j=0
γ j(x + y) j = 0.
Consider the set, V , of numbers spanned by numbers of the form
{xr ys, r, s ∈N}.
Whilst this set at ﬁrst appears to be high dimensional, it is not so when x and y are
algebraic. If they are algebraic, then there exists m, n such that
xn =
n−1

j=0
q j x j
with q j rational, and
ym =
m−1

j=0
r j y j
with r j rational. Using these expressions, we can therefore write
xnym =
n−1

j=0
q j x j
m−1

k=0
rk yk
as a linear combination of lower powers and so it is in the span of
Em,n = {xr ys, r, s ∈N,r < n, y < m}.
In fact, we can write xl for any l ⩾n as a rational linear combination of x j, j < n
by repeated substitution, and we can do similarly for y. This means that the set Em,n
spans V .
All we have to do now is show that (x + y)l ∈V for all l. As we showed above,
since V is spanned by a set with mn elements, it cannot have a linearly independent
subset with mn + 1 elements and it will follow that x + y is algebraic. We have from

70
8
Linear Dependence, Fields and Transcendence
the binomial theorem that
(x + y)l =
l
i=0
l
i

xl−i yi,
so it is indeed in V and we are done.
For xy, it is even easier: we have
(xy)l = xl yl ∈V.
So we must have that
{1, xy, (xy)2, . . . , (xy)mn}
is linearly dependent, and we are done.
8.4 Square Roots and Algebraic Numbers
In Sect.6.6, we saw the existence of a sub-ﬁeld, F, of R and therefore C which is
closed under taking the square root of positive elements. We also saw that it was a
proper subset of R that is there are real numbers that are not in F. A natural question
is how does F relate to the set of algebraic numbers? In fact, it is a proper subset.
First, we have previously shown that 21/3 is not in F but it certainly solves
x3 −2 = 0
and so is algebraic. We conclude that the two sets do not coincide. Now observe that
if x > 0 is algebraic so is √x for if
p(x) = 0,
then
p((√x)2) = 0.
It therefore gives a zero of the polynomial q deﬁned by
q(y) = p(y2).
The set of real algebraic numbers is therefore a sub-ﬁeld of R which is closed under
the taking of positive square roots and it contains Q. If we deﬁne F by intersection-
enclosure,wehavethatthesetofalgebraicnumbersisoneofthesetsthatisintersected
and so it must contain F. In other words, F is a proper subset of the algebraic numbers
as claimed.

8.4 Square Roots and Algebraic Numbers
71
Alternatively, we can use generation to show that F j is a subset of the algebraic
numbers for all j. To see this observe that every operation used to generate F j from
F j−1 does not cause us to leave the set of algebraic numbers.
8.5 Transcendental Numbers
We have shown that a lot of numbers are algebraic. Are all numbers algebraic? No.
In fact, in a certain sense most numbers are not. We will prove this in Chap.13. A
simple example is a number in which we take an inﬁnite decimal expansion and we
insert vastly increasing numbers of zeros between successive 1s. We let
w =
∞

i=0
10−i!
This is called Liouville’s constant. It was the ﬁrst number that was proven to be
transcendental. We sketch why this is true, a full proof is a little beyond our scope.
Suppose we wish to show that w does not satisfy a polynomial of degree N. Its biggest
coefﬁcient will be less in magnitude than some power of 10 say 10K . Consider the
terms w0, w1, . . . , wN. Once we go far enough into the right tail of the expansion,
the powers of the entries will be too far apart from each other to cancel and so we
cannot get zero.
8.6 Problems
Exercise 8.1 Show that if y ∈C is algebraic and xk = y then x is also algebraic.
Exercise 8.2 Showthatif y istranscendentalthen yk istranscendentalforall counting
numbers k. Show also that y1/k is transcendental.
Exercise 8.3 Show that the smallest sub-ﬁeld of R which is closed under the taking
of the powers 1/2, 1/3, 1/5 is contained in the set of algebraic numbers.

Chapter 9
Formal Equivalence
9.1 Introduction
One of the most powerful tools in mathematics is to show that two seemingly
unconnected classes of objects are in some sense equivalent. In other words, there is
a map between the classes that is bijective and maps the essential operations of one
class to those of the other. The more different the two classes are, the more powerful
the technique is. A rather difﬁcult to prove statement for one class may translate into
a simple one for the other and vice versa. Sometimes we even have a map from a
class to itself that transforms operations on the class.
Here we call this technique formal equivalence. We explore one example in depth,
the equivalence of ruler and compass constructions with properties of sub-ﬁelds of
R. As a consequence, we show the impossibility of duplicating the cube.
9.2 Ruler and Compass Constructions
The ancient Greek mathematicians spent a great deal of effort on studying ruler and
compass constructions. Here the objective is to construct a given angle or length
using only a straight edge and a pair of drawing compasses. Note that “ruler” does
not mean we can measure lengths. However, if we have two points a distance x apart
then we can set the compasses to that size by ﬁtting them to the two points. We can
then draw a circle of radius x about any other point we have constructed. This also
allows to measure the distance along a straight line from a given point on it.
In the original deﬁnition of a ruler and compass construction in Euclid’s Elements,
it was not possible to lift the compass off the paper without collapsing it. So one could
draw a circle centred at a given point that passed through another given point but one
could not copy a length from one place to another. However, the second Proposition
in the Elements shows how to copy a length using a ruler and collapsible compass so
allowing the use of a non-collapsing compass does not change the set of constructible
© Springer International Publishing Switzerland 2015
M. Joshi, Proof Patterns, DOI 10.1007/978-3-319-16250-8_9
73

74
9
Formal Equivalence
points. For a beautiful presentation of the ﬁrst six volumes of Euclid’s Elements, see
the 2010 Taschen edition which is a colour reprint of an 1847 edition that replaced
names of lines with colours.
We generally assume that we are given two points a unit distance apart. We may
also be given some other lengths to take functions of. We can always draw a straight
line through any two points we have constructed and extend any straight line. A
typical problem is given a number x, ﬁnd a given function of it. For example, the
ancient Greeks could construct the square root of two but not its cube root. Natural
questions which arise are
• can every number be constructed?
• how can we prove that certain numbers cannot be constructed?
Before proceeding to these we look at how to perform some basic constructions.
We ﬁrst look at the construction of perpendiculars and parallels. To construct a
perpendicular to a given line through a point A, ﬁrst mark off the two points that are
a distance 1 from A and call them B and C. We can do this by drawing a unit circle
centred at A and taking the points of intersection. Doing the same thing at B and C,
we get a further two points D and E which are at distance 2 from A. We now draw
a circle centred at B which passes through E and a second one centred at C that
passes through D. These two circles intersect in two points. Call one of these points
of intersection F. The line through A and F is perpendicular to the original line.
See Fig.9.1. We can repeat the construction to get a line perpendicular to AF that
Fig. 9.1 How to construct a perpendicular to a given line using ruler and compass

9.2 Ruler and Compass Constructions
75
passes through F. This second line is parallel to the original line through A since it
is perpendicular to its perpendicular.
Whilst the last construction will construct a parallel line, often we want something
better: we want a parallel line that goes through a given point. Suppose the line goes
through points P and Q and we want a parallel line through a point A. Draw a circle
centred at P through A. It will intersect with the line PQ twice. Take the point closer
to A and call it S. Now draw two more circles of the same radius as the ﬁrst centred
at A and S. These two circles will intersect in two points: P and a new point R. The
points APSR deﬁne a rhombus since all of its sides are the same length. The sides
of a rhombus are parallel so the line through A and R is parallel to our original line
which goes through P and S. See Fig.9.2.
If we have a length x and a length y, the ﬁrst thing we might do is add them to get
a length of x + y. Suppose we have a straight-line through a point A. We measure
out the distance x from A along the line using our compass to get a point B. We then
measure out the distance y from B to get a point C. The distance from A to C is now
x + y. See Fig.9.3.
Once we can add, the next question is how to subtract. We perform a similar
construction. We measure x from A to get B. See Fig.9.4. We then measure y back
towards A to get C. Provided x > y, the distance from A to C will be x −y. We
started with a unit length and we can add and subtract. We can now construct all the
natural numbers by repeated addition.
Fig. 9.2 How to construct a parallel line through a given point
Fig. 9.3 How to add two numbers using ruler and compass

76
9
Formal Equivalence
Fig. 9.4 How to take the difference of two numbers using ruler and compass
What other numbers can be constructed? The next obvious question is can we
multiply and divide? The product and quotient of two lengths x and y can be con-
structed using similar triangles. We start with the lengths 1, x and y. First, we draw
two intersecting straight lines. Call the intersection point A. On one of them mark
off the distance 1 from A to a point B. We then mark off a further y from B to a
point D. On the second line, mark off a distance x to a point C. We now draw a line
from B to C. To ﬁnish, we draw a line parallel to the line BC through D. Note that
this requires the construction of a parallel line that we did above. Denote by E its
intersection with the line through AC. See Fig.9.5. We claim that the distance from
C to E is xy. To see this observe that the triangles ABC and ACE are similar since
they have the same angles: they have the angle at A in common, and the other two
angles arise from intersections of the same line with parallel lines so they must be
the same. This means that we must have
|AB|
|AD| = |AC|
|AE|.
This says
1
1 + y =
x
x + |CE|.
Solving for |C E|, we ﬁnd that it is equal to xy.
Fig. 9.5 How to construct
the length xy from x and y

9.2 Ruler and Compass Constructions
77
A related construction does division. We proceed as for multiplication but use
different lengths. The length of AB is y, that of BD is 1 and that of AC is x. We have
this time that
y
1 + y =
x
x + |CE|
from similarity. Solving yields that |CE| = x/y. See Fig.9.6.
We start off with 1. We can add. We can divide. This means that we can construct
any rational length. We can say that the set of positive rationals is constructible. Since
we can multiply, we can also construct any rational multiple of a given number. Are
there any other constructible numbers? Yes. For example, we can construct
√
2. Take
a line and point on it. Construct a perpendicular through that point. See Fig.9.7. Now
measure a unit distance from the intersection point on both lines. It is immediate from
Pythagoras’s theorem that the distance between them is
√
2.
We can now construct the square root of any integer. We see how to construct
√x + 1 given √x. Mark the distance √x along the perpendicular and 1 on the
Fig. 9.6 How to construct
the length x/y from x and y
Fig. 9.7 How to construct
√
2 using ruler and compass

78
9
Formal Equivalence
horizontal. The resulting right-angled triangle has hypotenuse of size √x + 1 by
Pythagoras’s theorem. It follows by induction that the square root of any positive
integer is constructible. Since the ratio of any two constructible numbers is con-
structible, so is the square root of any positive rational.
What about the square roots of square roots and their square roots as well? We
now show that if a is constructible then so is √a. Assume that we have the length
a > 1 and a unit length. We draw a and then 1 along a straight line with the point
R in between. We take the midpoint of this line and call it P. We now draw a semi-
circle with centre P of radius (a + 1)/2. See Fig.9.8. We also draw the vertical
perpendicular to P R through R and denote its intersection with the semi-circle with
Q. The length PQ is (a + 1)/2 since Q is on a circle centred at P of that radius. The
length PR is
t = a + 1
2
−1 = a −1
2
.
If s is the length QR, we know by Pythagoras’s theorem that
s2 + t2 =
a + 1
2
2
.
Hence,
s =
a + 1
2
2
−
a −1
2
2
= √a.
There remains the square roots of positive numbers less than 1, however, these
follow since
√a =
1

1
a
and 0 < a < 1 if and only if 1/a > 1.
Fig. 9.8 How to construct
√a using ruler and compass

9.2 Ruler and Compass Constructions
79
We have shown that the class of constructible numbers is closed under the
operations of addition, subtraction, multiplication, division and square root taking.
It also contains the positive integers. In fact, these properties characterize the class:
it is the smallest subset of R that has these properties. How can we show this? The
key is in observing how new lengths are constructed. We start with a unit length. We
can pick a coordinate system so that its end points are (0, 0) and (1, 0). Every time
we draw a line or make a circle, we have to use existing points. We can use them in
three ways.
• We draw a line through two points.
• We measure the distance between two points for the radius of a circle.
• We use a point as the centre of a circle.
Once we have lines and circles, we use them by taking intersections. Again we have
three possibilities.
• We intersect two lines and they have at most one point of intersection.
• A line and a circle intersect in zero, one or two points.
• Two circles also intersect in zero, one or two points.
Line equations are of the form
ax + by + c = 0
with a, b, c constants, and (x, y) varying over the line. Circles can be written
(x −α)2 + (y −β)2 = γ2,
with α, β, γ constants, and (x, y) varying over the circle.
Our equations of deﬁnition are quadratic or linear. When we solve for the solution
set of two of them, we are either solving a linear equation, in which case we can
get the solution from the equation’s coefﬁcients, purely using addition, subtraction,
multiplication, and division, or we are solving a quadratic in which case we also
have to use square roots. Crucially, these ﬁve operations are sufﬁcient. Every solution
point constructed must have coordinates arising from their repeated application. Any
length is computable via the Pythagorean theorem which again only uses these.
We have shown that the set of constructible lengths, L, is equal to the positive
elements of the smallest subset of R which contains the rationals, and is closed under
the four basic arithmetic operations and taking square roots. We have replaced the
problem of ruler and compass constructions with studying the closure of subsets
of R under certain operations. This is an example of equivalence. A problem is
replaced with one involving an apparently different class of object. In fact, we studied
this equivalent problem in Sect.6.6. There we showed that certain numbers are not
generated by these operations. In particular, we showed that if m ∈Z is not a perfect
cube then m1/3 ̸∈L.
We can now solve the ancient Greek problem of duplicating the cube. Given a
cube of side length x, is it possible to construct a cube with volume 2x3? This is

80
9
Formal Equivalence
equivalent to the question of constructing a cube with side length 21/3x which can
be done if and only if we can construct the length 21/3. We have shown that this is
impossible and we are done.
Note that our proof shows that the construction is impossible if we are restricted
to using straight edge and compass. We have said nothing regarding the possibility if
other instruments are allowed. The impossibility of other ancient Greek problems has
been shown in similar fashion. In particular, the trisection of an angle is impossible as
is the construction of “squaring the circle”. For this last, the problem is to construct
a square with the same area as the unit circle. One therefore needs to be able a
construct the length √π. This is constructible if and only if π is. However, π is
transcendental which means that it is not a solution to any polynomial equation
with integer coefﬁcients. We showed in Chap.8 that no constructible numbers are
transcendental, and so π is not constructible. However, the proof of π’s transcendence
is a little too hard for this book.
9.3 Further Reading
Benjamin Bold’s excellent book “Famous Problems of Geometry and How to Solve
Them” is a very nice place to read more about the topics covered here.
9.4 Problems
Exercise 9.1 Using a ruler and compass construction, duplicate the square.
Exercise 9.2 Show directly that if a, b,r are rationals with r > 0, then a + b√r
satisﬁes a polynomial with rational coefﬁcients.

Chapter 10
Equivalence Extension
10.1 Introduction
It is often the case that a class of objects with which we are working is lacking in some
regard. For example, subtraction cannot be deﬁned on the set of positive integers in a
natural way. The solution is, of course, to allow negative numbers. Similarly, divisors
do not always exist so we introduce fractions that is rationals to create them. Square
roots of positive rationals are generally not rationals, so we introduce the reals. The
square roots of negative reals do not exist in the reals either, so complex numbers
are introduced.
Whilst we have a clear intuitive notion of integers and rationals, it is nevertheless
an issue in mathematics how to construct them from simpler sets. Passing from the
rationals to the reals is not even intuitively clear and they are many ways to do so. In
this chapter, we study a common construction we call equivalence-extension which
can be used to embed sets lacking a property into larger sets that possess it.
We review the concept of an equivalence relation in Appendix B, and here we
look at how we can use them to construct sets.
10.2 Constructing the Integers
Suppose we have already constructed the natural numbers
N = {0, 1, 2, 3, . . . },
and we have a natural notion of addition, +, on them. We now want to construct a
bigger set on which every subtraction sum has an answer. For example, the problem
ﬁnd x such that
x + 2 = 1
has no solution in N.
© Springer International Publishing Switzerland 2015
M. Joshi, Proof Patterns, DOI 10.1007/978-3-319-16250-8_10
81

82
10
Equivalence Extension
Equivalence extension is one way to proceed. We ﬁrst consider the set of all
possible subtraction sums. This will just be the Cartesian product N × N since we
are trying to subtract one number from another. Thus a pair (y, z) represents the
sum y–z.
Even when sums have no answers in N, we can often identify cases where they
should have the same answer! For example, 2–3 and 4–5 should give the same result.
We now deﬁne an equivalence relation on the set of sums so that they are equivalent
if and only if they should have the same answers.
We want to say
(y1, z1) ∼(y2, z2)
if and only if
y1 −z1 = y2 −z2.
However, we cannot do so because the sums may not have solutions in N and we
cannot use Z, since that is what we are trying to construct! We therefore say
(y1, z1) ∼(y2, z2) ⇐⇒y1 + z2 = y2 + z1.
This is well-deﬁned since addition is properly deﬁned on N. We need to check that
∼is an equivalence relation.
First, (y, z) ∼(y, z) for any y and z since
y + z = y + z.
So it is reﬂexive. For symmetry, we clearly have
y1 + z2 = y2 + z1 ⇐⇒y2 + z1 = y1 + z2,
and so
(y1, z1) ∼(y2, z2) =⇒(y2, z2) ∼(y1, z1).
For transitivity, if (y1, z1) ∼(y2, z2) and (y2, z2) ∼(y3, z3), then y1 + z2 = y2 + z1
and thus
z2 = (y2 + z1) −y1
and this subtraction is well deﬁned since it has an answer in N. Similarly,
z2 = (y2 + z3) −y3.
We therefore have
(y2 + z1) −y1 = (y2 + z3) −y3.

10.2 Constructing the Integers
83
Adding y1 + y3 to both sides yields
y2 + z1 + y3 = y2 + z3 + y1,
and so
z1 + y3 = z3 + y1.
This says
(y1, z1) ∼(y3, z3),
and ∼is indeed transitive.
We have deﬁned an equivalence relation on N×N and this induces a partition via
its equivalence classes. What do the partition sets look like? The difference of the
two elements is always the same, so we have upwards diagonally sloping lines. For
example,
[(0, 0)] = {(0, 0), (1, 1), (2, 2), (3, 3), . . . },
[(1, 0)] = {(1, 0), (2, 1), (3, 2), (4, 3), . . . },
and
[(0, 1)] = {(0, 1), (1, 2), (2, 3), (3, 4), . . . }.
Every equivalence class will have precisely one element that contains a 0. This will
be (n, 0) for n > 0, (0, 0) or (0, m) with m > 0. We therefore effectively have two
copies of N joined together at 0. This is precisely what we want! The original positive
natural numbers, zero, and our new numbers: the negatives of the counting numbers.
We still need to do a few things:
• deﬁne + on the new set;
• show that + extends the old +;
• show that every subtraction sum now has an answer.
We deﬁne
[(y1, z1)] + [(y2, z2)] = [(y1 + y2, z1 + z2)].
We have to be slightly careful; given an equivalence class it can be represented in
more than one way, we have to make sure that our deﬁnition does not depend on
the representation. This is a common issue in pure mathematics: we need to make
sure that our deﬁnitions are well-deﬁned when there is an arbitrary choice in a
representation.
Thus we need to show that if
(y1, z1) ∼( ˜y1, ˜z1), (y2, z2) ∼( ˜y2, ˜z2),
then
(y1 + y2, z1 + z2) ∼( ˜y1 + ˜y2, ˜z1 + ˜z2).

84
10
Equivalence Extension
We have
y1 + ˜z1 = ˜y1 + z1,
y2 + ˜z2 = ˜y2 + z2.
Now
˜y1 + ˜y2 + z1 + z2 = ( ˜y1 + z1) + ( ˜y2 + z2),
= (y1 + ˜z1) + (y2 + ˜z2),
= y1 + y2 + ˜z1 + ˜z2.
So the equivalence class of the sum is independent of the representation as required.
An alternate approach here would be to deﬁne + in terms of distinguished ele-
ments. Each equivalence class has a unique member in which at least one entry is
zero so we can deﬁne it in terms of that member. Thus we could deﬁne
[(x, 0)] + [(y, 0)] = [(x + y, 0)],
[(x, 0)] + [(0, y)] = [(x, y)],
[(0, x)] + [(0, y)] = [(0, x + y)].
We then have no troubles with the operation being well-deﬁned. However, we would
have to analyze special cases when studying the properties of operations which would
be annoying. One solution is show that the two deﬁnitions agree, and then one simply
uses whichever is convenient for a given proof thereafter.
The commutativity and associativity of “+” follow immediately from our original
deﬁnition.
We call the set of equivalence classes Z. We deﬁne an injection
i : N →Z,
i(n) = [(n, 0)].
This is clearly one-one since m −0 = n −0 if and only if m = n. It preserves
“+” since
i(m + n) = [(m + n, 0)] = [(m, 0)] + [(n, 0)] = i(m) + i(n).
This means that we can identify N with its image under this map whilst retaining the
same additive structure.
It remains to check that all subtractions now have an answer! Note
[(n, 0)] + [(0, n)] = [(n, n)] = [(0, 0)].

10.2 Constructing the Integers
85
Since every element can be written with a zero in one of its two slots, this shows that
every element, x, has a negative which we denote −x. For any x, y we can therefore
always solve the equation
x + p = y
for an element p of Z. We simply set
p = y + (−x).
We have used equivalence-extension to construct a set containing the natural num-
bers which is closed under subtraction, and corresponds to our intuitive notion of
the integers.
10.3 Constructing the Rationals
The integers are great for addition, subtraction and multiplication, but not so good for
division. We can, however, again apply the equivalence-extension pattern to create
the rationals. Thus we consider the set of all division sums and identify sums that
should have the same answer.
A division sum is a number to be divided and a non-zero number to divide by.
This means that the set we need to partition is Z × (Z −{0}) rather than Z × Z. Our
equivalence relation is
(p1, q1) ∼(p2, q2) ⇐⇒p1q2 = p2q1,
since the relation we want to express is p1/q1 = p2/q2.
We need to check that ∼is indeed an equivalence relation. Reﬂexivity and sym-
metry are obvious. We prove transitivity in a very similar way as for the integers. If
(p1, q1) ∼(p2, q2) and (p2, q2) ∼(p3, q3),
then
q2 = (p2q3)/p3 and q2 = (p2q1)/p1.
So
(p2q3)/p3 = (p2q1)/p1.
This implies
p1 p2q3 = p3 p2q1.
If p2 ̸= 0 then p1q3 = p3q1 and (p1, q1) ∼(p3, q3). If p2 = 0, then p1 = p3 = 0
from the deﬁnition of ∼, and again (p1, q1) ∼(p3, q3).

86
10
Equivalence Extension
We have that ∼is an equivalence relation. We call its set of equivalence classes
the set of rational numbers, Q. What do the equivalence classes look like? Since the
ratio of the two entries is always the same, if we plot the classes on Z × Z, each one
will lie in a straight line through the origin.
It will sometimes be convenient to choose a special representative of each class.
We can take this to be our usual concept of “simplest terms.” If we multiply p and
q by −1, we do not change [(p, q)] so we can assume that q > 0. Also, if a number
u divides both p and q, [(p, q)] will equal [(p/u, q/u)]. This means that we can
assume that p and q are coprime. Any other representative ( ˜p, ˜q) will then have
˜p = vp, ˜q = vq
for some q.
We now need to deﬁne addition and multiplication on Q. We deﬁne
[(p1, q1)] ∗[(p2, q2)] = [(p1 p2, q1q2)]
which corresponds to our intuitive notion of multiplying fractions. We need to test
that “*” is well deﬁned. In other words, we must show that
(p1, q1) ∼( ˜p1, ˜q1), (p2, q2) ∼( ˜p2, ˜q2)
=⇒(p1 p2, q1q2) ∼( ˜p1 ˜p2, ˜q1 ˜q2).
However, given the left-hand-side equivalences, we have
p1 p2 ˜q1 ˜q2 = (p1 ˜q1)(p2 ˜q2) = ( ˜p1q1)( ˜p2q2) = ˜p1 ˜p2q1q2,
and the result is clear.
What about addition? We work with our intuitive notion. We deﬁne
[(p1, q)] + [(p2, q)] = [(p1 + p2, q)].
We need to check
• that there is always a q such that both elements of Q can be represented in the
form [(s, q)],
• and that the choice of q does not affect the answer.
For the ﬁrst, suppose we have x = [(p1, q1)] and y = [(p2, q2)] then we can
represent via
x = [(p1q2, q1q2)], y = [(p1q1, q1q2)],
and it is clear that the representation exists.
To see that the choice of q does not matter, we show all choices agree with
one particular choice, q′, which is easy to work with. Given x = (p1, q1) and
y = (p2, q2), we assume, as above that pi is coprime to qi and that qi > 0 for
i = 1, 2. We take q′ to be the least common multiple of q1 and q2. For any other

10.3 Constructing the Rationals
87
q, we must have q′|q, since both q1 and q2 divide into q. We can therefore write
q = rq′ for some r.
We then have to show the representation using rq′ in the second slot, i.e. as
denominator, agrees with that using q′. We have
x = [(s1, q′)], y = [(s2, q′)],
for some s1, s2 ∈Z. This yields
x + y = [(s1 + s2, q′)].
Our alternative representation is
[(rs1,rq′)] + [(rs2,rq′)] = [(rs1 + rs2,rq′)] = [(r(s1 + s2),rq′)].
However,
(s1 + s2, q′) ∼(r(s1 + s2),rq′),
and we are done.
Note the general technique here, if we wish to prove equality of all elements of
some set, we do not prove that any two arbitrary elements agree. Instead, we ﬁx a
particular element with nice properties and show that all other elements agree with it.
We have now constructed Q with addition and multiplication. There is a clear
identity element:
[(1, 1)] = [(p, p)]
for any non-zero p. Every non-zero element has a multiplicative inverse, we just take
[(p, q)]−1 = [(q, p)].
So any division sum involving a non-zero divisor can be solved exactly.
We also have an additive identity
[(0, 1)] = [(0, q)]
for any non-zero q. Every element has a negative:
−[(p, q)] = [(−p, q)].
We have constructed the rationals.
One important property of the rationals that we have not yet discussed is its
ordering. We deﬁne
[(p1, q)] ≤[(p2, q)] ⇐⇒p1 ≤p2

88
10
Equivalence Extension
when q > 0. Multiplying p1, p2 and q by a positive constant will not affect the
inequality so the ordering is well-deﬁned. There are many more things one could
check about the rationals such as associativity, commutativity, the distributive law,
and that the operations + and ∗interact with ≤in the way one might expect. We will
not carry out the checks here but we encourage the reader to do them!
Our initial objective was to extend the integers so that all division sums have an
answer. To complete this objective, we need to embed the integers into the rationals.
We use the map
i : Z →Q
deﬁned by
i(z) = [(z, 1)].
In more usual language:
z = z
1.
The map i is one-one and it is easy to see that
i(x + y) = i(x) + i(y),
so we have indeed extended Z.
10.4 The Inadequacy of the Rationals
We have seen how to construct the rationals and that they have many desirable
properties. However, they still are lacking in certain regards. First, as we saw in
Sect.5.2, many natural equations lack solutions in Q. For example, for any k > 1,
the equation
xk = 2,
has no rational solutions.
Second, many sequences that we might expect to converge do not. This is closely
related to our ﬁrst problem. For example, suppose we take a sequence yk =
mk
10k
where mk is chosen to be the biggest integer such that
y2
k ≤2.
The irrationality of root two guarantees that y2
k < 2 for all k. Since we deﬁned mk
to be maximal, we must have
ml+1 ≥10ml

10.4 The Inadequacy of the Rationals
89
and
yl+1 ≥yl
for all l. We also have yl < 2 for all l. The sequence (yl) is therefore increasing and
bounded.
It does not converge, however; the sequence (yl) represents the decimal expansion
of
√
2 to k decimal places. If it is to converge to anything it must be
√
2 which we
know is not rational. Of course, we need to prove that the sequence does not converge
to a rational.
Suppose it does converge to l then l2 ≤2 since y2
k ≤2 for all k. If l is rational
then l2 ̸= 2, so l < 2. Now
l + 10−j →l
as j →+∞. So
(l + 10−j)2 →l2 < 2.
This means that if we take j sufﬁciently large,
(l + 10−j)2 < 2.
If we now take the decimal expansion of l to j places, and call it ˜l, we can only have
decreased it, so
(˜l + 10−j)2 ≤(l + 10−j)2 < 2.
We see that y j has not been properly deﬁned since we can increase it whilst not
taking its square above 2. We have proven by contradiction that yk does not converge
to a rational.
That increasing bounded sequences do not converge is therefore another defect of
the rationals. A closely-related defect is the failure of the least upper bound property
or supremum property. This states that any subset that is bounded above should have
a smallest upper bound. For example, the sets
{x ∈Q | x < 2}, and {x ∈Q | x ≤2},
both have the least upper bound of 2. However, the set
E2 = {x ∈Q | x2 < 2} = {x ∈Q | x2 ≤2}
has no least upper bound. The natural candidate for such a least upper bound is
√
2
which, as we know, is not in Q. We still need to prove that no rational upper bound
is the least one, however. However, we can argue similarly to above. If b is a rational
and b2 < 2 then by taking b j = b + 10−j for j sufﬁciently large, we obtain a value
b j with b2
j < 2 and b j > b so b is not an upper bound.

90
10
Equivalence Extension
If b is a rational upper bound, it follows that b2 > 2 and b is positive. Let
c j = b−10−j. We then have that c j < b for all j and for j sufﬁciently large c2
j > 2.
So c j is a positive rational number with c2
j > 2 and c j < b. The number c j will also
be an upper bound, since squaring is an increasing operation. We thus have that b
is not the least upper bound. Since b was an arbitrary upper bound, there is no least
upper bound in the set of rationals.
10.5 Constructing the Reals
If we want to have least upper bounds, square roots and convergence of bounded
increasing sequences then we need to construct a bigger set. This set is generally
called the real numbers. We can proceed again by extension–equivalence.
Our base set is the set of bounded above subsets of rationals which we denote
BQ. Thus each element of BQ is a set of rational numbers which is bounded above.
Some examples of elements are the sets
{x ∈Q | x < 0},
{1},
{x ∈Q | x ≤0},
{x ∈Q | x ≤10},
{x ∈Q | x2 < 2}.
We want to identify subsets which should have the same least upper bound. The main
problem is that they may not have a rational least upper bound and we are trying to
construct the reals so using the real least upper bound is not allowed. However, if
two subsets have the same least upper bound then they have the same set of upper
bounds in the rationals and that is a statement that makes sense within the rationals.
We therefore say E ∼F if and only if E and F have the same set of rational
upper bounds. This is trivially an equivalence relation on BQ. We denote the set
of equivalence classes by R. It will be convenient in what follows to have a unique
representative of each equivalence class. We can then work with these without any
worries regarding dependence on the choice of representative. For such an approach
to work, the choice must be natural (or canonical) rather than arbitrary. Here we
will show that each class has an element which contains all the others and we will
use that.
There is an easy way to get a biggest element of an equivalence class of sets: just
take the union of all of them. So given an equivalence class [X] with X a bounded
above subset of Q, we deﬁne
UX =

Z∼X
Z.

10.5 Constructing the Reals
91
In other words, we take all the members of Q which are in some member of the
equivalence class. Note that X ⊆UX. Of course, we need to check that UX ∈BQ
and that UX ∼X. The second of these implies the ﬁrst in any case.
Suppose y is an upper bound for X. It is then an upper bound for all Z in [X] since
they have the same upper bounds. It is therefore greater than all elements of UX that
is it is an upper bound for UX. So the set of upper bounds for X is contained in the
set of upper bounds for UX. Since X ⊆UX, any upper bound for UX is also one
for X, and we have that the two sets of upper bounds are the same, and so UX ∼X
as required.
In addition, it follows from transitivity that if X ∼X1, then
UX = UX1
since the unions are taken across the same sets, and so UX depends only on [X] rather
than X. We can therefore write U[X].
What special properties does U[X] have? It is a bounded-above set of rationals
and if q ∈U[X] then r ∈U[X] for all r ∈Q with r < q. To see this, for such an r
consider the set
Vr = U[X] ∪{r}.
We claim that Vr ∼U[X]. First Vr is bigger than U[X] so any upper bound for Vr
is also an upper bound for U[X]. Any upper bound for U[X] is greater than q which
is greater than r so it is also an upper bound for Vr and we have Vr ∼U[X]. Since
U[X] ∼Vr and the deﬁnition of UX requires that the union be taken over all sets
which relate to UX, we must have that r is in U[X].
The set UX has an additional property: its complement in Q has no smallest
element. We ﬁrst show that that every element of the complement is an upper bound.
Let x ∈Q−U[X]. If it is not an upper bound then there must be an element q ∈U[X]
with q > x. But the argument above shows that then x ∈U[X] and we have a
contradiction.
The question is therefore whether the least upper bound if it exists must be in
UX. The answer is yes, because the single element set containing it would have the
same upper bounds as UX and so by the deﬁnition of UX, we have {x} ∼UX and
so {x} ⊂UX.
Deﬁnition 10.1 A bounded-above subset of rationals, V , with the properties that
if q ∈V, then (−∞, q) ⊂V , and such that Q −V has no smallest element is
called a cut.
We have seen that every equivalence class can be represented by a cut.
Infact,thereisaone-correspondencebetweenthecutsandtheequivalenceclasses;
if two cuts are distinct then they are in different equivalence classes. To see this,
suppose V1 and V2 are distinct cuts. Without loss of generality, suppose there exists
q1 ∈V1−V2, (swap indices otherwise). We must then have q1 > r for allr in V2 since
otherwise the deﬁnition of a cut would imply q ∈V1. It follows that q1 ∈Q−V2 and

92
10
Equivalence Extension
it is not the smallest element of Q−V2 from the deﬁnition of a cut. We therefore have
an interval of rationals, (q2, q1), in V1−V2. The sets V1 and V2 therefore have distinct
sets of upper bounds since (q1 + q2)/2 is an upper bound for V2 and not for V1.
The upshot of all this is that we can work with cuts to deﬁne the real numbers,
and in fact this is often taken as a starting point. It is known as the Dedekind cut
construction of the reals. However, by starting with equivalence classes, we have
seen that there is a natural motivation for the construction in terms of providing the
least upper bound property.
Let 2Q denote the set of all subsets of the rationals which is sometimes called its
power set. Every cut is an element of this power set. We can embed the rationals in
the set of cuts by taking the map
i :Q →2Q,
i :q →(−∞, q].
This is clearly injective and the image sets are certainly cuts. For the construction to
be useful, this map must not be onto. In other words, there needs to be cuts that are
not of this form. An easy example is the one studied above, take X to be the negative
rationals together with q ∈Q such that q2 < 2.
There is a natural ordering on the space of cuts. We simply say A ≤B if and only
if A ⊆B. We want to show that we now get the least upper bound property. Suppose
we have a collection of cuts
{Xα}
with α ranging over some index set I. We can let
X =

α∈I
Xα,
that is we take the union of all the cuts. Clearly, if y ∈X, and q < y for some
rational q, then y ∈Xα for some α. Since Xα is a cut, q ∈Xα, and q ∈X. So X
has the cut property of being closed downwards.
Now suppose the collection of cuts is bounded above in the sense that there is a
cut Y such that
Xα ⊆Y
for all α. Since Y is a cut there is a rational u such that all elements of Y are less
than u. It follows that all elements of Xα and thus X are also bounded above by u.
We also need Q −X to have no smallest element. However, this may not hold.
For example, if we set
Zn = (−∞, −1/n] ⊂Q,
then, Z, the union over n is the set of negative rationals. Its complement has a clear
smallest element: 0. However, there is an easy cure for both this case and in general.
We take the cut, D, which represents the equivalence class containing the union.

10.5 Constructing the Reals
93
Since the representative cut is bigger than all elements of the equivalence class, it is
certainly at least as big as the union and therefore of all of its elements, Xα.
It remains to show that D is the least upper bound. That is we need to show that
there is no cut, C, such that for all α
Xα ⊆C ⊂D,
with the second inequality strict. Suppose C is a cut containing Xα for all α. First
note that C must contain X by the deﬁnition of a union. Either, it is in the same
equivalence class as X, in which case it is D since we have shown that there is one
cut per class, or it is not. If it is not then it has a different set of upper bounds than
X. Since it is bigger than X this means that there is an upper bound for X that is not
an upper bound for C. Since X and D have the same upper bounds, D has an upper
bound that C does not: D is smaller than C and we are done.
We have established that the set of cuts has the least upper bound property and
we have constructed the real numbers.
We still need to establish that the reals have the properties that we would expect
them to have. For example, we need to show that we can extend addition and multi-
plication to them in a natural way, and that the extensions interact with the ordering
in a natural fashion. We do not carry out the extension here but it is not particularly
hard. Once the reals have been constructed we simply use them as numbers and do
not think about cuts anymore. We also regard the rationals as a subset of the reals.
10.6 Convergence of Monotone Sequences
The reals were introduced to cure the defect that bounded above sets of rationals
did not have least upper bounds. We also saw that the rationals had a second related
defect, namely that increasing bounded sequences sometimes fail to converge. We
will see in this section that the reals do not have that defect. Let xn be an increasing
sequence in R and suppose xn ≤u for all n.
Let l be the least upper bound of the set {xn}. Such an l exists since {xn} is bounded
above by u and we have proven that there is always a real least upper bound. In fact,
l is the limit of the sequence xn. To see this note that if
y < l,
then y being less than the least upper bound is not an upper bound. So there exists
N such that X N > y. Since xn is increasing we have
xn ≥y, for all n ≥N.

94
10
Equivalence Extension
Thus given any ϵ > 0, set y = l −ϵ/2 and we have
l −ϵ < xn ≤l for all n ≥N.
This is the deﬁnition of a limit and xn →l. See Chap.19.
10.7 Existence of Square Roots
We now look at the problem of the existence of square roots for positive real numbers.
Suppose x > 0 is real. Let
Ex = {y ∈R : y2 ≤x}.
This set is non-empty since it contains 0 and is bounded above since all elements are
less than the maximum of x and 1.
Let l be the least upper bound of Ex. This will be the square root of x. How do
we prove this? If l2 > x then consider
ln = l −1
n .
The sequence ln converges to l and l2
n →l2 > x. For n sufﬁciently large we have
l2
n > x
and ln < l. This means that ln is an upper bound for Ex so l is not the least upper
bound. We have a contradiction. We conclude
l2 ≤x.
If l2 < x, we can proceed similarly. Let mn = l + 1/n, then for n sufﬁciently
large m2
n < x and so mn ∈Ex and l is not an upper bound. We conclude that l2 = x
as required.
10.8 Further Reading
Two nice books which are good introductions to the embedding of mathematics in
set theory are Halmos’s “Naive set theory” and Enderton’s “Elements of set theory.”
Both of these books treat the subject matter of this matter in greater depth as well as
introducing the axiomatic approach to set theory.

10.9 Problems
95
10.9 Problems
Exercise 10.1 Prove that if k is a positive integer and x is a positive real number
then x has a kth root in the real numbers.
Exercise 10.2 Prove that every subset of reals that is bounded below has a greatest
lower bound.
Exercise 10.3 Construct the positive rationals directly from the natural numbers,
and then construct the negative rationals from them. Establish a bijection between
the rationals constructed this way and the rationals constructed the original way.
Ensure that the bijection is the identity on the natural numbers and that it commutes
with multiplication and division.
Exercise 10.4 Give examples of subsets of the reals that do not have greatest lower
bounds.
Exercise 10.5 Show that a monotone decreasing sequence of real numbers is
bounded below if and only if it is convergent.

Chapter 11
Proof by Classiﬁcation
11.1 Introduction
One of the major strands of modern pure mathematics is classiﬁcation. A category
of objects is deﬁned and the objective is then to make a list of all its members. Whilst
mathematicians tend to regard such an activity as worthwhile in its own right and as
an essential part of understanding the objects, it is natural for a non-mathematician to
askwhatisthepoint?Oneansweristhatoncealltheobjectswithasetofpropertiesare
classiﬁed, it becomes very easy to prove theorems about them. Rather than working
with the deﬁnition, one simply works down the list.
Similarly, if one wants to know whether an object with a collection of properties
exists, one can consult classiﬁcation lists and see whether any of the known objects
has them. If the list is complete, then failure to ﬁnd is proof of non-existence.
In this chapter, we look at some simple examples of this powerful technique. We
develop the classiﬁcation of all Pythagorean triples that is positive integer solutions to
Pythagoras’s equation and use it to show non-existence of positive integer solutions
to the equation
x4 + y4 = z2.
11.2 Co-prime Square
As a ﬁrst application of proof by classiﬁcation, we look at the problem of showing
that if a and b are co-prime and ab is a perfect square then a and b are also perfect
squares. We use a classiﬁcation that we have already developed: the uniqueness of
prime decompositions. If m = ab is a perfect square then m = k2 with k an integer.
We can write uniquely
k = pα1
1 pα2
2 . . . pαn
n
© Springer International Publishing Switzerland 2015
M. Joshi, Proof Patterns, DOI 10.1007/978-3-319-16250-8_11
97

98
11
Proof by Classiﬁcation
for a sequence of ascending primes p j and positive integers α j. We can therefore
write
ab = k2 = p2α1
1
p2α2
2
. . . p2αn
n
.
Each of a and b has its own prime decomposition. However, since prime decompo-
sitions are unique, we can write
a = p2α1−β1
1
p2α2−β2
2
. . . p2αn−βn
n
,
(11.2.1)
b = pβ1
1 pβ2
2 . . . pβn
n
(11.2.2)
for some non-negative integers β j with 0 ⩽β j ⩽2α j. We have not yet used the
fact that a and b are co-prime. Note that if 0 < β j < 2α j then p j divides both a
and b and so they are not co-prime. So we have for all j that β j = 0 or β j = 2α j.
In other words, the power of the prime p j in the decompositions is either zero or
2α j. Since every prime has an even power, this immediately implies that both of a
and b are perfect squares. We are done.
To summarize,
Proposition 11.1 If a and b are co-prime positive integers and ab is a perfect square
then so is each of a and b.
Whilst our proof of this result was not particularly elegant, the use of the classiﬁcation
in terms of primes meant that it was easy and straightforward.
11.3 Classifying Pythagorean Triples
Recall that the theorem of Pythagoras states that if a right-angled triangle has sides
a, b and c, and c is the side opposite the right-angle then
a2 + b2 = c2.
If we allow a, b and c to be real numbers then we choose any values of a and b and
get a corresponding value for c by taking

a2 + b2.
There is therefore an inﬁnite number of solutions and they are easy to list. However, if
we restrict ourselves to positive integer solutions, the classiﬁcation problem becomes
much more interesting. Such solutions certainly do exist:
32 + 42 = 52;
52 + 122 = 132.

11.3 Classifying Pythagorean Triples
99
Also, if we have one solution we can construct an inﬁnite number simply by
multiplying all three numbers by positive integers, that is for any k ∈N,
a2 + b2 = c2 =⇒(ka)2 + (kb)2 = (kc)2.
The ﬁrst piece of our classiﬁcation is therefore to restrict our attention to cases where
a, b and c have no common divisor knowing that once we have found all such triples,
we can easily generate the rest.
In fact, we can do better.
Lemma 11.1 If a2 + b2 = c2 and a, b and c are positive integers with no common
divisors then they are pairwise co-prime.
Proof Suppose p is a prime or 1 and divides a and b. Clearly, p divides a2 and b2
so p divides a2 + b2. Thus p divides a, b and c so p is 1. We have shown that a and
b are co-prime.
The cases where p divides c and one of a and b follow similarly.
□
Since the numbers are pairwise co-prime, at most one is even. We show that if a and
b are odd then c is not a perfect square. This will imply that exactly one of a and b
is even and that c is odd.
If a = 2k + 1 and b = 2l + 1 then
a2 + b2 = 4k2 + 4k + 1 + 4l2 + 4l + 1 = 4(k2 + l2) + 4(k + l) + 2.
The square of an odd number is odd so a2 + b2 is not the square of an odd number.
However, the square of any even number is divisible by 4 and a2 + b2 is clearly not
a multiple of 4, so it is not a perfect square.
We therefore have that one of a and b is even and that c is odd. Relabelling a and
b if necessary, we can say that a is odd and that b is even. We can now write
b2 = c2 −a2 = (c −a)(c + a).
All of b, c −a and c + a are even, so we can write the integer equation
b
2
2
= c −a
2
c + a
2
.
We next want to show that x = c−a
2
and y = c+a
2
are co-prime. If p divides both
of them then it divides x + y and y −x, that is it divides c and a. Since c and a are
co-prime, p must be 1. So x and y are co-prime as claimed.
Applying Proposition 11.1, we have that x and y are perfect squares. We can write
x = u2 and y = v2. Note that u and v are co-prime and that u < v. We also have
b
2
2
= u2v2.

100
11
Proof by Classiﬁcation
Taking square roots, b = 2uv. Gathering, we have shown that there exist co-prime
positive integers u and v with u < v such that
a = v2 −u2,
(11.3.1)
b = 2uv,
(11.3.2)
c = u2 + v2.
(11.3.3)
Note that since a and c are odd, u and v must have the extra property that one is even
and the other is odd. Our classiﬁcation is almost complete. We still need to show:
• Different pairs (u, v) with these properties lead to different triples (a, b, c).
• That any triple (a, b, c) developed from these formulas, yields a Pythagorean triple
with co-prime entries. (That is we need to check the reverse implication.)
The ﬁrst is easy to check. We can recover v from a and c, via
v =

(a + c)/2
and u from
u =

(c −a)/2.
Since u and v can be found from the values of a and c, it must be that if you change
u or v then the triple (a, b, c) must change too.
For the second, we really have to check two things: that you get a Pythagorean
triple and that its entries are co-prime. We compute
(v2 −u2)2 + (2uv)2 = v4 −2u2v2 + u4 + 4u2v2 = v4 + 2u2v2 + u4,
and this equals c2. So we do indeed have a Pythagorean triple. Now let p be a 1 or a
prime that divides a and c. Since one of u and v is even and the other odd, we have
that c is odd so p cannot be 2. We have that p divides
v2 −u2 and u2 + v2
so p divides 2u2 and 2v2. Since p is not 2, it therefore divides u2 and v2. As p is a
prime or 1, it therefore divides u and v. Since we assumed that u and v are co-prime,
p must be 1. We have that a and c are co-prime, as needed. Note that this is sufﬁcient,
since any divisor of all three of a, b and c must certainly divide a and c.
Our classiﬁcation is complete:
Theorem 11.1 There is a bijection between the set of Pythagorean triples and
positive integer triples (k, u, v) with u and v co-prime, u + v odd and u < v
given by
(k, u, v) →(k(v2 −u2), 2kuv, k(u2 + v2)).

11.3 Classifying Pythagorean Triples
101
This means that any time we want to prove a result about Pythagorean triples, we
can prove it about triples of this form instead.
Now that we have the list, what are the actual triples? Here are a few:
(1, 1, 2) →(3, 4, 5);
(1, 1, 4) →(15, 8, 17);
(1, 2, 3) →(5, 12, 13);
(2, 1, 2) →(6, 8, 10).
Note that when we take k = 1 and u = 1, we have that c−a = 2, so we immediately
see that there are inﬁnitely many Pythagorean triples which have two side lengths
differing by two.
11.4 The Non-existence of Pythagorean Fourth Powers
Having classiﬁed all positive integer solutions of the equation a2 + b2 = c2, what
about
a4 + b4 = c4?
This is, of course, a special case of Fermat’s Last Theorem and it has long been
known to have no solutions. We can prove it as an application of the classiﬁcation of
Pythagorean triples. We use some other standard techniques.
First, we actually prove that
X4 + Y 4 = Z2
has no positive integer solutions, putting X = a, Y = b, and Z = c2 then proves the
desired result. Proving the stronger result turns out to be easier. This is not unusual
with induction-style proofs in that the stronger inductive hypothesis makes it easier
to establish results.
Second, we use the technique of inﬁnite descent which was invented by Fermat
to solve this problem. This is essentially the contrapositive of complete induction.
We show that if a solution exists then there must be another smaller solution. This
shows that if there is no solution with X +Y + Z < k, then there cannot be one with
X + Y + Z = k. Applying complete induction, there is no solution for any k and we
are done.
As before, we ﬁrst reduce to the case where X and Y are co-prime. If X = px,
Y = py then
X4 + Y 4 = p4(x4 + y4).

102
11
Proof by Classiﬁcation
So p4|Z2 which implies that we can write
Z = p2z
and we have
x4 + y4 = z2.
So we need only consider the case that X and Y are co-prime. At least one is therefore
odd and we assume that Y is.
Using the classiﬁcation of Pythagorean triples, with a = X2, b = Y 2 and c = Z,
there exists u and v co-prime with u < v and u + v odd such that
X2 = 2uv,
Y 2 = v2 −u2,
Z = v2 + u2.
We have
Y 2 + u2 = v2.
Since u and v are co-prime, we have another co-prime Pythagorean triple and since
Y is odd, it follows that u is even and v is odd. Applying the classiﬁcation again,
there exist co-prime a and b with a < b, and a + b odd such that
u = 2ab,
Y = a2 −b2,
v = a2 + b2.
So
X2 = 2uv = 4ab(a2 + b2).
Hence
 X
2
2
= ab(a2 + b2).
We have that a and b are co-prime. It follows that ab and a2 + b2 are co-prime. To
see this, suppose p is 1 or prime and divides both. Since p|ab, it must divide a or b.
It also must divide
a2 + b2 + 2ab = (a + b)2,
and therefore a + b. It therefore divides both a and b so it must be 1.

11.4 The Non-existence of Pythagorean Fourth Powers
103
Using Proposition 11.1, we have that both of ab and a2 + b2 are perfect squares.
Since a and b are also co-prime, the same proposition shows that they are also perfect
squares. Writing a = α2, b = β2, a2 + b2 = γ2, we have
α4 + β4 = a2 + b2 = γ2.
So we have another solution and its method of construction ensures that it is smaller
than the ﬁrst one. Our result follows by inﬁnite descent and we are done.
11.5 Problems
Exercise 11.1 Find all Pythagorean triples with one side equal to 12.
Exercise 11.2 Suppose a, b, c, k are positive integers and
ck = ab,
with a, b co-prime. Does it follow that a and b are the kth powers of positive integers?
Exercise 11.3 Suppose we want to ﬁnd all rational Pythagorean triples, that is right-
angled triangles with all sides rational. Can we classify these?
Exercise 11.4 Consider the map from Pythagorean triples to the length of the longest
side as a natural number. Is this map surjective? Is it injective? What about for the
other two sides?
Exercise 11.5 Suppose we allow triangles to have negative side lengths. What
differences does it make to the classiﬁcation of Pythagorean triples?
Exercise 11.6 How many Pythagorean triples have two sides differing by 1?

Chapter 12
Speciﬁc-generality
12.1 Introduction
When attempting to tackle a problem, a mathematician will often break it down
into cases. Some cases will be easier than others to tackle. Often the process is
simply random: after making additional hypotheses the result becomes easy and so
the problem is broken into the case where they hold, and the case where they do not.
This approach is called case analysis.
In this chapter, we look at a related technique that is in many ways more powerful
which we call speciﬁc generality. With this approach we divide the problem into two
cases A and B, and we show that if the result holds in case A then it also holds in
case B. Equivalently, if it does not hold in case B then it does not in case A. The
approach does not require nor imply the truth of the result in either case; instead, it
says that we only need to study case A. Once that case has been dealt with in either a
positive or negative sense we are done. The speciﬁc case A implies the general case
of A and B.
We look at two applications of speciﬁc-generality in this chapter. The ﬁrst is that
we show that it is sufﬁcient to prove Fermat’s Last Theorem for prime exponents,
and for the second we look at how to reduce the four-colour problem to a subset of
maps.
12.2 Reducing the Fermat Theorem
Fermat’s Last Theorem, proven by Andrew Wiles with assistance from Richard
Taylor in 1994, states there are no positive integer solutions to the equation
xn + yn = zn
© Springer International Publishing Switzerland 2015
M. Joshi, Proof Patterns, DOI 10.1007/978-3-319-16250-8_12
105

106
12
Speciﬁc-generality
when n > 2. We saw in Sect.11.3 that it is certainly not true when n = 2 and indeed
we classiﬁed all the possible solutions. We also saw in Sect.11.4 that when n = 4 it
does hold.
We now show that if we can prove the theorem for all n prime bigger than 2 then
it holds for all n > 2. We ﬁrst show that any number bigger than 2 has either a prime
factor bigger than 2 or is divisible by 4. Let n > 2. If it is prime, we are done. If not
it is composite. It therefore has some prime factors. Either these are all 2 in which
case it is a power of 2 and so must be divisible by 4, or one is not 2, in which case
it has a prime factor which is not 2 and again we are done.
If we have a solution
xn + yn = zn,
we can write n = ql with q either a prime bigger than 2 or equal to 4. We now have
xql + yql = zql.
Let X = xl, Y = yl, Z = zl, and then
Xq + Y q = Zq.
We have shown that if there is a solution for some n > 2, then there is also a solution
for n either a prime bigger than 2 or 4. We have already shown that there are no
solutions when n = 4. We conclude that q must be prime.
We have established that if the result holds for n prime then it holds in general.
Note, however, that we have not established the prime case and so whilst we have
reduced the remaining workload, we have not proven that it holds for any case other
than 4.
12.3 The Four-Colour Theorem
The Four-Colour theorem states that if we have a map which divides the plane into
countries, or regions, and we wish to colour it in such a way that no countries with
a common border are the same colour, then we only need four colours of paint. A
country is a connected subset of the plane with a nice boundary. This result has a
long history and was eventually proven in 1976 by Kenneth Appel and Wolfgang
Haken. Their proof was rather contentious, however, in that it involved breaking the
problem down into a large number of special cases and then checking each one using
a computer. A computer-free proof has not yet been found.
A feature of the theorem is that regions are only considered to be adjoining if
they have a common edge and not if they only have a common vertex. In fact, it is
easy to see that the result is false if any two regions with a common vertex have to
be coloured differently: take a pie and divide it into N pieces; all the pieces have
the centre of the pie as a vertex and they would all have to be different colours. So

12.3 The Four-Colour Theorem
107
not only is the Four-Colour theorem false if we require all countries with a common
vertex to be differently coloured, but so is the N-colour theorem for all N.
How can we apply speciﬁc-generality to the four-colour problem? A general map
can have any number of countries meeting at a vertex but we shall show that it is
sufﬁcient to consider the case where a maximum of three countries do so. Such a
map is said to be cubic.
Suppose we have proven the result for maps with only 3 countries meeting at each
vertex, and suppose we have a general map, M, which does not have this property.
We take each vertex of M and blow it up slightly, and make the interior of the bubble
a new country. See Fig.12.1. This map, M′, has the property that if two countries
share a common edge in M then their deformations in M′ also do. In addition, each
vertex of M′ belongs to at most 3 countries. We therefore colour M′ and shrink the
introduced bubbles to get a colouring of M. Since the shrinking does not introduce
any new adjacencies, the colouring of M is valid if that of M′ is. In other words, if
M′ can be coloured with N colours so can M.
We have shown that if all maps with at most 3 countries meeting at each vertex can
be coloured with 4 colours then so can all maps. As usual with speciﬁc generality,
we have not actually shown that the result is true in any case, however.
We can further apply speciﬁc-generality to the Four-Colour problem to reduce
to the case where all countries have at least 4 sides. To see this suppose all maps
containing countries with at least 4 sides are colourable. We deduce the general case
by induction. A map with less than 5 countries is certainly 4 colourable. Suppose
all maps with n countries are colourable. Take a map with n + 1 countries. If it has
no countries with less than 4 sides, it is colourable by our general hypothesis. If it
has countries with two or three sides, then take one such country and merge it with
a neighbour. The resulting map has n countries so it is colourable. Colour it. The
country that was merged has at most 3 neighbours so we can simply give it a colour
different from them and we have coloured the map with n +1 countries. Our general
result follows by induction.
Fig. 12.1 A pie with six pieces: before and after the central vertex is made into an extra country

108
12
Speciﬁc-generality
12.4 Problems
Exercise 12.1 Suppose we can prove that every map in which all countries have
at least k sides can be coloured with k colours. Show that every map can then be
coloured with k colours.
Exercise 12.2 Show that if there are no solutions to the Fermat equation with x, y, z
pairwise co-prime then there are no solutions in general.

Chapter 13
Diagonal Tricks and Cardinality
13.1 Introduction
For non-mathematicians, the concept of inﬁnity is rather nebulous and generally just
refers to any number that is not ﬁnite. For mathematicians, there are numerous types
of inﬁnities depending on the nature of the object being studied. For example, we may
wish to study how many elements are in sets and then we are studying cardinality.
Alternatively, we may want a concept of a limit for divergent sequences—we often
say that a sequence or series tends to inﬁnity, but what does that mean? Finite numbers
are often used to order objects as well to count them, we may wish to extend these
concepts of ordering to sets that are not ﬁnite. Such numbers are called ordinals. The
fact that the sets of ordinals and cardinals are the same for ﬁnite numbers does not
imply that the concepts will be the same in the inﬁnite case, and, in fact, they are
different.
In this chapter, we will examine sizes of inﬁnity from the point of view of cardi-
nality. In particular, we will see that there are an inﬁnite number of different sizes
of inﬁnity. We will also see that there are in a certain sense of the word more real
numbers than rationals but the same number of rationals and integers.
13.2 Deﬁnitions
First, we deﬁne when two sets are the same size.
Deﬁnition 13.1 Two sets A and B have the same cardinality if there exists a bijection
between them.
For ﬁnite sets, this corresponds to the notion that a set has n elements if and only if
its elements can be labeled with the numbers 1 to n. Sometimes, it is convenient to
label them 0, 1, 2, . . . , n −1.
We can also say that a set has fewer elements than another one.
© Springer International Publishing Switzerland 2015
M. Joshi, Proof Patterns, DOI 10.1007/978-3-319-16250-8_13
109

110
13
Diagonal Tricks and Cardinality
Deﬁnition 13.2 A set A is of smaller cardinality than a set B if there exists an
injective map from A to B but there does not exist a bijection between A and B.
For this deﬁnition, to be useful, we need to show
Theorem 13.1 (Schröder–Bernstein theorem) If there exists an injective map from
A to B, and one from B to A, then there exists a bijection between A and B.
13.3 Inﬁnite Sets of the Same Size
Many inﬁnite sets are the same size. Quite unlike ﬁnite sets, we can ﬁnd inﬁnite
sets which are the same size as some of their subsets. In fact, a set having the same
cardinality as a proper subset is sometimes taken as a deﬁnition of its non ﬁniteness.
For example, consider the set of even natural numbers, E. In fact, E and N have the
same cardinality. Let
f : N →E,
be deﬁned by f (n) = 2n. This function is a bijection and so they have the same
cardinality.
Similarly, the function g(n) = n2 shows that there are the same number of perfect
squares as natural numbers. In fact, any inﬁnite subset, S, of N will have the same
cardinality as it. To see this observe that it is naturally ordered since the natural
numbers are. So we deﬁne a map, h, from N to S as follows. Let h(0) be the smallest
element of S. Let h(1) be the smallest element of S −{h(0)}. We keep going and
let h(n) be the smallest element of S −{h(0), h(1), . . . , h(n −1)}. The map h is
certainly injective since each number mapped to is bigger than the previous one.
After n steps, we will have covered all numbers in S that are less than n, so h is onto.
So any inﬁnite subset of N is the same size as N. In particular, there is the same
amount of prime numbers as natural numbers. This is despite the fact that they get
further and further apart along the number line.
Note also that we can always add a ﬁnite number of elements to a countable set
and still have a countable set. To see this, suppose we want to add X = {x1, . . . , xn}
to the natural numbers. Let f ( j) = x j+1 for j < n and let f ( j) = j −n for j ≥n.
We then have a bijection from N to X ∪N.
What about larger sets? Now consider N × N. This is the set of ordered pairs
(m, n) with m, n both natural numbers. Is this any bigger? The answer is no. We can
construct a bijection from N to it by enumerating along the diagonals. So
f (0) = (0, 0),
f (1) = (1, 0),
f (2) = (0, 1),
and
f (3) = (2, 0),
f (4) = (1, 1),
f (5) = (0, 2).

13.3 Inﬁnite Sets of the Same Size
111
Every pair lies in some diagonal, and we go down these one by one. This means that
every pair is in the image of f and we have a bijection. For future use, denote its
inverse by g. Note that this result shows not just that N × N is countable but also that
the Cartesian product of any two countable sets is countable. We simply label their
elements via their bijection with N and the result is immediate.
We can use this result to establish the cardinality of Q. We work with the non-
negative rationals, Q+. We have the natural injection
i : N →Q+,
which is simply mapping each natural number to itself. We also have a simple map,
j : Q+ →N × N,
which is to map a rational q to its numerator, m, and denominator, n, in lowest terms.
So
j(m/n) = (m, n).
The map g ◦j is then an injection from Q+ to N. We thus have injections both ways
when considering Q+ and N. It follows from the Schröder–Bernstein theorem that
they are of the same cardinality.
We also have that any countable union of countable sets is countable. Suppose E j
is countable for j = 0, 1, 2, . . . . We can assume E j is non-empty since if it is empty
then it has no effect on the union. We then have a bijection f j from E j to either N
or a subset of it. We can deﬁne
f :

E j →N × N,
by
f (x) = ( j, f j(x)) for x ∈E j.
If x is in more than one E j, use the smallest value of j for which x ∈E j. This
yields an injection from  E j to N × N and so an injection to N since N × N is
countable. If  E j is ﬁnite our result is trivial. If for some j, E j is inﬁnite, then
we have a bijection from it to N whose inverse yields an injection from N to  E j.
Otherwise, in the case that all the sets are ﬁnite, we can construct an injection from
N by simply enumerating all the elements of each set one by one, and skipping over
any already in the image. It then follows from the Schröder–Bernstein theorem that
since we have an injection each way that there is a bijection between  E j and N.
So  E j is countable.

112
13
Diagonal Tricks and Cardinality
13.4 Diagonals
After the above examples, the reader might be forgiven for thinking that all inﬁnite
sets are the same size. How can we prove that there are more real numbers than
natural numbers? We show that any countable list of reals is incomplete by using
a pattern sometimes called the diagonal trick. We employ decimal representations.
So each real number on the list is written ﬁrst as a decimal. In order to ensure that
representations are unique, we make the convention that decimals cannot end in an
inﬁnite string of recurring 9s. So if we have a number
1.99999999999999999999999999999999 . . .
we write
2.00000000000000000000000000000000 . . .
instead.
The reader may not be familiar with the fact that a number ending in an inﬁnite
string of 9s can be represented by a ﬁnite string instead. We digress a little to discuss
this fact. The key here is to realize that a decimal expansion is really just an inﬁnite
sum
∞

j=0
a j10m−j
where m ∈Z determines the magnitude of the number, and a j are the digits lying
in the range 0 to 9 with a0 ̸= 0. We will study inﬁnite sums in Chap.19. The sum
is increasing and bounded by 10m+1 so it certainly converges. Suppose a number,
x, has an expansion ending in an inﬁnite string of 9’s consider the last digit that is
not 9 and suppose this is in place k (We assume that there is at least one non 9, the
reader can deal with the case of all 9s.). Deﬁne a new expansion bi = ai for i < k
and bk = ak +1. We take zero thereafter. Intuitively, we have rounded up the trailing
9s. The implied real number, y, has a ﬁnite decimal representation.
Now consider y −x. The terms before k agree so after canceling we have essen-
tially that y −x equals
z = 1 −0.999999 . . .
times some integer power of 10. Now z must be smaller than 1 −0.9 = 0.1 and
1 −0.99 = 0.01. So take a ﬁnite number of 9s, r, and consider that
z < 1 −
r

i=1
9 × 10−i = 10−r−1.
Since this is true for any r, z must be zero.

13.4 Diagonals
113
Back to studying the cardinality of R, it is easier to work with the interval (0, 1)
which is certainly has fewer elements than R. Let f : N →(0, 1) be any map. We
show that f is not surjective. We do this by constructing a number not in the image
of f . We do this by making the number disagree in the nth decimal place with f (n).
So let xn be the digit in the n decimal place of f (n). Let
yn = (xn + 2)
mod 10.
The notation mod means take the remainder on division by 10. In this case, it means
that if the answer is 10 take 0, if it is eleven take 1.
Now let
y =
∞

n=1
yn10−n.
The number y has yn in the nth decimal place unless {yn} ends in an inﬁnite string
of 9s in which case y is all zeros after some point. The nth decimal digit therefore
differs from xn since either xn is 2 different from yn, or xn is 7 in which case it is
still different from 0.
So y and f (n) are different in the nth decimal place. This implies that
y ̸= f (n).
So f is not surjective as claimed.
Why is this technique called the diagonal trick? If we write the numbers in vertical
list, we are creating a new number from the digits on the diagonal. For example, if
we have for the ﬁrst 9 numbers
0.693458302,
0.780695725,
0.132661746,
0.723736632,
0.746140245,
0.969628025,
0.948094516,
0.949140569,
0.477748785,
then the diagonal digits are
6, 8, 2, 7, 4, 8, 5, 6, 5.

114
13
Diagonal Tricks and Cardinality
The value of y is then
0.804960787 . . .
We have shown that no bijections from N to R exist. The set R is said to be
uncountable. Note that injections from N to (0, 1) certainly exist, however. We can
set
g(n) =
1
n + 1
to get such an injection.
How can we construct even bigger sets? The standard way to do it is to take the
set of all subsets. Thus if X is a set, let 2X denote the set of its subsets. Note that each
element of 2X is a subset of X rather than an element of X. Thus if X = {1, 2, 3}
then
2X = {∅, {1}, {2}, {3}, {2, 3}, {1, 3}, {1, 2}, {1, 2, 3}}.
In this case, 2X has 8 = 23 elements. One of these elements is the empty set itself.
In general, if a ﬁnite subset has n elements then its set of all subsets has 2n
elements. Hence the notation. To see this observe that we can identify a subset of
{1, 2, . . . , n} with a binary number. We put 1 in slot j if j is in the subset and 0
otherwise. We thus get a bijection from the set of subsets to the set of n digit binary
numbers that is the set of numbers from 0 to 2n −1. So the set of subsets has 2n
elements.
For inﬁnite sets, of course, life is rather more complicated. However, we can use
a variant of the diagonal trick to show that 2X is bigger than X. Let
f : X →2X.
We need to show that it is not surjective. We need to ﬁnd a subset that is not in the
image of f . Let
A = {x | x ̸∈f (x)}.
We now show that the set A cannot be in the image of f . Suppose for some y,
A = f (y). Either y ∈A, or y ̸∈A. We show that both of these are impossible. If
y ∈A, then by the deﬁnition of A we have y ̸∈f (y) but f (y) is A so y ̸∈A and
we have a contradiction. Now for the other case, if y ̸∈A then y ̸∈f (y) so y ∈A.
Again, we have a contradiction.
There are no surjections from X to 2X. However, there are certainly injections.
We simply deﬁne
f (x) = {x}.
So 2X has a bigger cardinality than X.
Starting with N, we can repeat many times. Let X0 = N. Let X j = 2X j−1. In
each case, X j has bigger cardinality than X j−1. The cardinality of X j is called ℵj.
The Hebrew letter ℵis pronounced aleph.

13.4 Diagonals
115
We now have an inﬁnite number of sizes of inﬁnity! In fact, we have ℵ0 different
sizes. The next natural question is “are there any more?” The answer is “yes”. If we
take a set Y which is the union of all these sets (the fact that we can do this is a little
deep for this book) it has more elements than X j for every j and gives us a new
order of inﬁnity. We can then start taking 2Y and so on. This sort of process will go
on forever. There are an awful lot of sizes of inﬁnity.
How big are the reals? We have seen that their cardinality is not ℵ0. In fact, it
is ℵ1. There are a number of ways to see this. One is simply to observe that every
subset of the natural numbers can be viewed as a binary number between zero and
one. We do this by putting 1 in the jth place after the point if j is in the subset and
zero otherwise. We thus get a bijection from 2N to (0, 1]. The sets R and (0, 1) have
the same cardinality. For example, the map
x 
→−1 + 1
x
deﬁnes a bijection from (0, 1) to (0, ∞). The map
y 
→log y
deﬁnes a bijection from (0, ∞) to R. So (0, 1) and R have the same cardinality.
How do we show that (0, 1) and (0, 1] have the same cardinality? We deﬁne
f : (0, 1) →(0, 1]
to be the identity on the irrationals. For the rationals, the intersection of (0, 1) with
Q is countable so, as we saw above, there is a bijection to its union with {1}. We use
this bijection to deﬁne f on the rationals and we are done.
13.5 Transcendentals
We can use countability to prove the existence of transcendental numbers. We will
prove that the set of algebraic numbers is countable. So, in fact, almost all real and
complex numbers are transcendental. First, we show that the set of polynomials
with rational coefﬁcients is countable. Such a polynomial is just a ﬁnite sequence
of rational numbers. The question therefore is equivalent to showing that the set of
ﬁnite sequences of elements of a countable set is countable.
The set of polynomials of a given degree, d, is simply the set of rational sequences
of length d. In other words, it is the set
Qd = Q × Q × Q . . . Q

116
13
Diagonal Tricks and Cardinality
with d terms. We showed above that the Cartesian product of any two countable sets
is countable. It then follows by induction that Q, Q2, . . . , Qd are countable since Q
is. The set of rational polynomials of degree d is therefore countable. A countable
union of countable sets is rational so it follows that the set of all rational polynomials
is countable.
A rational polynomial only has a ﬁnite number of zeros. If we take the zeros of
each rational polynomial, and take their union, then we are taking a countable union
of ﬁnite sets and so have a countable set. We have shown that the set of algebraic
numbers is countable.
Since the union of two countable sets is countable, and the set of complex numbers
is uncountable, the complement of the algebraic numbers must be uncountable. We
have shown that the set of transcendental numbers is uncountable, and, in fact, that
there are inﬁnitely more transcendental numbers than algebraic ones.
13.6 Proving the Schröder–Bernstein Theorem
We have two sets X and Y and we are given injections
f : X →Y and g : Y →X.
Our objective is to stitch f and g together to get a bijection from X to Y. First, note
that f and g deﬁne bijections to their images, and so have well-deﬁned inverses on
their images.
f −1 : Im f →X and g−1 : Im g →Y.
Our new bijection, h, will have to be a mixture of f and g−1 since these are the only
two maps from parts of X to Y that we have. It is a question of how to divide up X
so that all points in Y are mapped onto and there is no overlap in the images.
Since f maps no element of X to points in Y −Im f, we will need to use g−1 to get
those points. So we will have to deﬁne h to equal g−1 on g(Y −Im f ). More generally,
we will partition X according to how the points behave under the mappings.
What sort of points in X are there? We have already seen one special subset:
points that map under g−1 to points outside the image of f . We can think about how
points map under repeated application of g ◦f . Consider a point x, we repeatedly
apply g ◦f to it to get new points of X. If we take (g ◦f )l(x) for l = 1, 2, . . . , ∞,
we get a sequence of points. This sequence will form a loop or go on forever. We
can say that points are related if you can get from one to another using g ◦f . More
formally, we deﬁne an equivalence relation on X that two points x1 and x2 relate if
and only if there exists k ∈N such that
x1 = (g ◦f )k(x2) or x2 = (g ◦f )k(x1).
This is easily checked to be an equivalence relation.

13.6 Proving the Schröder–Bernstein Theorem
117
We now have a partition of x. Each partition set will be an inﬁnite sequence or
a loop. The inﬁnite sequences come in three varieties. To see this, ﬁrst say that a
sequence is generated by x0 if all its elements can be written in the form
(g ◦f )l(x0).
We can thus distinguish between sequences that are generated and so have a starting
point, and those that go on forever in both directions. Note that if a sequence does
not have a starting point then given any point, x, in it, there exists a point x2 such
that
x = (g ◦f )m(x2)
for some m. Repeating this argument, one can go back as far as one wants.
If a sequence does have a starting point, x0, then we know that
x0 ̸= (g ◦f )(x)
for all x in X. This can happen in two ways either
x0 ̸= g(y)
for all y in Y, or, x0 is in the image of g and we have
g−1(x0) ̸= f (x)
for all x ∈X.
We thus have a partition of X into four sets. Each point is in one of the following
(1) a loop,
(2) a doubly inﬁnite sequence,
(3) a sequence that starts outside the image of g,
(4) a sequence that starts in the image of g.
The great thing about this partition is that applying g ◦f preserves each of the four
subsets. We now deﬁne h to be f in cases 1, 2, and 3, and g−1 in case 4. Note that
all of case 4 will be in the image of g since the image of g ◦f is smaller than that
of g.
We still have to show that h is a bijection. First, we show that h is surjective. given
y ∈Y. Consider g(y). If this in case 4, then
h(g(y)) = g−1(g(y)) = y
and we are done. If not, we are in one of the three other cases and
g(y) = (g ◦f )(x)

118
13
Diagonal Tricks and Cardinality
for some x in case 1, 2 or 3. Since g is injective, y = f (x) and since we are not in
case 4, y = h(x). We have shown that h is surjective.
It only remains to show that h is injective. Since f and g−1 are injective where
deﬁned, we have to show that h does not use the two functions to map different points
to the same point. That is we must show that we cannot have x4 in case 4 and x in
case i for some i < 4, such that
f (x) = g−1(x4).
If this were to hold, then we would have
x4 = (g ◦f )(x).
So x4 and x would have to be in the same part of the partition by the deﬁnition of
our equivalence relation, and therefore could not be in different cases, and so we are
done.
13.7 Problems
Exercise 13.1 Suppose X and Y are the natural numbers. We deﬁne f to be multi-
plication by two from X to Y. We deﬁne g to be multiplication by three. What is the
bijection h constructed by the Schröder–Bernstein theorem? What if both maps are
multiplication by 2?
Exercise 13.2 Show that every real number can be represented by a decimal that
goes on forever.
Exercise 13.3 A submarine starts at integer point n. It travels with integer speed k.
So after turn m, its location is n + mk. A ship which does not know n and k drops a
depth charge once a turn on an integer. Show that it is possible to design an algorithm
so that the submarine is always hit eventually. What if the speeds are rational? What
if they are real?
Exercise 13.4 Consider the set of real-valued functions on the reals. What is the
cardinality of this set?
Exercise 13.5 Let X be an inﬁnite set show that X ∪N has the same cardinality as
X.

Chapter 14
Connectedness and the Jordan Curve
Theorem
14.1 Deﬁnitions
An important idea in topology is that of connectedness. There are many ways to deﬁne
it. Here we use a simple deﬁnition that agrees with more complex ones for open1
subsets of R2. We will use it later in the book to prove that the Euler characteristic
is the same for all convex polyhedra.
Deﬁnition 14.1 We shall say a subset E of Rn is polygonally connected if given
any two points p, q, of E there exists a path consisting of a union of straight line
segments contained in E that joins p to q.
So if we can draw a straight line path with only a ﬁnite number of direction
changes between any two points of E then E is connected. We will call such a path a
polygonal path and call the points of direction change vertices. Generally, even if a
set is not connected, it can be written as a union of connected subsets. For example,
let S be the unit circle in the plane, R2. The complement of S is not connected. Since
a point inside the unit circle cannot be joined to one outside without crossing S.
However,
R2 −S = {||x|| < 1} ∪{||x|| > 1},
and both of these sets are connected.
How can we prove that sets are connected other than by checking the deﬁnition?
Typically, we build them up from simpler connected sets. First, we can show
Theorem 14.1 Any convex set is connected.
Proof If C is convex then any two points of C are joined by the straight line segment
between them. This deﬁnes a polygonal path between them and we are done.
□
1 A subset U is open if every point in U is surrounded by points in U. More formally, if x ∈U
there exists δ > 0 such that Nδ(x) = {y : |y −x| < δ} ⊆U.
© Springer International Publishing Switzerland 2015
M. Joshi, Proof Patterns, DOI 10.1007/978-3-319-16250-8_14
119

120
14
Connectedness and the Jordan Curve Theorem
More interestingly, if we take two sets that are connected and have non-empty
intersection then their union is connected.
Theorem 14.2 If A and B are connected subsets of Rn and A ∩B is non-empty
then A ∪B is connected.
Proof Let p, q ∈A ∪B. Let r ∈A ∩B. Then there exists a path γ1 from p to r
and a path γ2 from r to q. Join these two together to get a path from p to q. Any
two points of A ∪B are thus joinable by a polygonal path so it is connected as
claimed.
□
Now suppose we have the plane with a big square subtracted. How can we show
this set is connected? Suppose the square is centred at the origin and has sides of
length 2R. So let
ER = {(x, y) | |x| > R or |y| > R}.
We can write E as a union of four sets
{x < −R}, {y < −R}, {x > R}, {y > R}.
Each of these four sets is connected since they are all convex. Each one has a non-
empty intersection with the preceding and succeeding sets. So add them one at a time
to the union, and we see that E is connected.
For a more complex example, suppose C is convex and bounded. We show that
R2 −C is connected. We need to deﬁne bounded. We take it to mean that C lies
within some square centred at the origin. So there exists R such that for all points
(x, y) ∈C, |x| < R and |y| < R. Since we know that ER is connected, all we need
to do is to construct a straight line from any point in R2 −C to ER. This straight line
can then be used along with a polygonal path in ER to join the point to any point in
ER.
Let p ∈R2 −C. If p is in ER we are done. If not, consider the horizontal line
through p. This gives two possible lines from p to ER according to whether we go
left or right. We claim that one of these must not intersect C. For if they both do then
there is a point q on the left segment in C and a point r on the right segment also in
C. But then the convexity of C would then imply that p is in C too, so this cannot
happen. We therefore take the line segment from p to ER which does not intersect
C and we are done.
14.2 Components
As mentioned above, it is always possible to divide a set into connected components.
The main result is

14.2 Components
121
Theorem 14.3 Suppose E ⊂Rn then there exists a collection of subsets {Eα} whose
union is E such that each Eα is connected and the subsets {Eα} are pairwise disjoint.
Any connected subset of E is contained in Eα for some α.
The term pairwise disjoint means that if α1 ̸= α2 then
Eα1 ∩Eα2 = ∅.
Before proceeding to the proof, note that the theorem does not say anything about
the cardinality of the number of components. In particular, it does not say that there
is only a ﬁnite number. We will prove the result using equivalence relations.
Let E ⊂Rn. For p, q ∈E, let p ∼q if there exists a polygonal path in E from
p to q. Clearly, p ∼p by taking the path to be a single point. If p ∼q, then there
is a path from p to q. Reversing the path to go from q to p yields q ∼p. If p ∼q
and q ∼r then take the path from p to q and join it to the one from q to r to get a
path from p to r. So p ∼r.
Let {Eα} be the equivalence classes deﬁned by ∼. They are connected trivially
by our deﬁnition. Since they are equivalence classes, they form a partition and so
they are pairwise disjoint. If a subset, C, of E is connected and p ∈C is in Eα, then
all points of C can be joined to p by a polygonal path. This means that they are in
the equivalence class of p so C in contained in Eα as claimed. We have proven the
theorem.
Ausefulalternativewaytolookatcomponentsisintermsofinteger-valuedcontin-
uous functions. This almost sounds like a contradiction since continuous functions
never jump, and the only way to get from one integer to the next is by a jump.
However, when working with disconnected sets the concept is not trivial.
Deﬁnition 14.2 Let E ⊂Rn. We shall say that f
: E →Z is polygonally
continuous if it is constant on any straight line segment contained in E.
For example, suppose E has n components called E1, E2, . . . , En. We let f take
value j on E j. The function f is then polygonally continuous since if any two points
can be joined by a straight line segment they are in the same component and so take
the same value.
In fact, a set E is connected if and only if every polygonally-continuous integer-
valued function is constant. To see this, suppose p and q are such that p ∼q and g
is continuous. We have a polygonal path from p to q and along each segment in the
path g is constant so it must be constant on the entire path. The value at p and q is
therefore the same. Hence, g is constant on each component of E.
If E is connected then there is only one component and the function is constant.
If E is not connected then there are at least 2 components. Let g take the value 0 on
the ﬁrst component and 1 elsewhere. The function g is continuous and so there is a
non-constant integer-valued polygonally continuous function.

122
14
Connectedness and the Jordan Curve Theorem
Fig. 14.1 The number of crossings of the curve by a ray starting at A is always even
14.3 The Jordan Closed-Curve Theorem
Take a closed loop in the plane with no self intersections. Thus we have a path, P, that
meanders around and returns to its starting point without touching itself in between.
Such a path is said to be closed. Consider the set R2 −P, how many components
does it have? The Jordan closed-curve theorem says that the answer is always 2.
Whilst the result is obvious, that does not mean it is easy to prove. Here we look at
how to prove it for polygonal paths. The proof for general continuous paths is hard
and far beyond our scope.
There are really two parts to the proof. First, we show that there are at least two
components and then we show that there at most two components.
Lemma 14.1 Let P be a closed polygonal path without self intersections, then
R2 −P has at least two components.
Proof We construct an integer-valued polygonally continuous function that takes
two values. Given a point p in R2 −P, take a ray l from p. A ray is an inﬁnite half
straight-line. Think of a laser beam emanating from p in some direction and going
off to inﬁnity. The ray l may intersect P. Its intersection will be a union of points
and straight line segments. Let x be one of these points or line segments. We call x
a crossing of P if the part of P before and after x lie on different sides of l. Call the
total number of crossings c(p,l).

14.3 The Jordan Closed-Curve Theorem
123
Fig. 14.2 The number of crossings of the curve by a ray starting at B is always odd
There is no reason to think that c(p,l) will the same for all rays starting at l. In
fact, it is easy to construct examples where it is not. A ray in some direction may miss
P altogether whilst in the opposite direction it may hit P. However, if we slowly
rotate l, we see that it only changes when l hits a vertex of P and it then stays the
same or goes up or down by 2. So c(p,l) varies with l, but whether it is odd or even
does not. We therefore deﬁne c(p) to be the remainder of c(p,l) on division by 2.
See Figs.14.1 and 14.2.
Now if two points p, q, are connected by a straight line in R2 −P then we can
extend that line into a ray from p that goes through q. Since there are no points in
P on the part of the ray from p to q, we see that c(p) and c(q) are the same. So c is
indeed an integer-valued polygonally continuous function.
We still need to show that c is not constant. Take a point r in P and a short line
segment through r that crosses P and does not meet P anywhere else. Let p and q

124
14
Connectedness and the Jordan Curve Theorem
Fig. 14.3 The sets NE and
QE
be the two endpoints of it. Let l be the ray from p through q and let lq the part of
that ray after q. We clearly have
c(p,l) = c(q,lq) + 1.
So
c(p) ̸= c(q).
□
Lemma 14.2 Let P be a closed polygonal path without self intersections, then
R2 −P has at most two components.
Proof Before proceeding to the main part of the proof, we note some facts about
vertices and edges. First, if a vertex is not part of an edge then since the edge is a
closed set, we can ﬁnd ϵ > 0 such that all points in the edge are more than ϵ away
from the vertex.
Second, given two disjoint edges the point of closest approach will be a vertex of
one of the two edges. To see this, observe that either the two edges are parallel or
they are not. If they are, then it is possible to slide two points along them without
changing distance until one is a vertex. So the vertex is as close as anything to the
other edge. If they are not parallel then one can slide along in the direction in which
they get closer together until one is a vertex. So the pair of closest points must have
one as a vertex.

14.3 The Jordan Closed-Curve Theorem
125
Now pick δ so that every vertex is at least 2δ away from every edge of which it is
not a member. We can do this since there are only a ﬁnite number of vertices. Then
every edge is at least 2δ away from every edge it does not intersect by the arguments
above.
Given an edge E, let NE be the points less than δ away from E, and let QE be the
points in NE that are not in the polygonal path. See Fig.14.3. The set NE will be a
rectangle with a semi-circle added on top and bottom. The radius of both semi-circles
will be δ and the rectangle will have short side 2δ and long side equal to the length
of E. Subtracting P takes a middle vertical line out of the centre of the rectangle.
It also takes a radial straight line (like a spoke) out of each of the two semi-circles.
These clearly divide QE into two connected sets. These two sets will have different
parity functions according to the component function, c, we deﬁned when proving
that there are at least 2 components. The sets NE will only intersect when the edges
they surround intersect due to the fashion in which we picked δ.
If we now consider the set of all points, Pδ, within δ of P then it will be a union
of the sets QE. Taking a particular edge E, each of the two components of QE will
intersect with the component of the same parity for each neighbouring edge, and
so its union with it is connected. Going round the polygon, we see that Pδ has two
connected components.
Now consider an arbitrary point p ∈R2 −P. We will show that it can be straight-
line connected in R2 −P to one of these two components. Take a ray starting at p.
Rotate it until it hits P. It must hit Pδ before P, since all points less than δ from P
are in Pδ. So we have a straight line from p to one of the two components of Pδ and
we are done.
□
14.4 Problems
Exercise 14.1 Show that a subset of Rn has k components if and only there exists
an integer-valued continuous function that takes k different values.
Exercise 14.2 Show that if a point, p, can be joined to a connected set, U, by a
polygonal path then p and all points of U are in the same component.
Exercise 14.3 Will a ﬁnite intersection of connected sets be connected?
Exercise 14.4 Suppose we have a collection of connected sets U j such that for all
j > 1, there is some k < j, such that
U j ∩Uk ̸= ∅,
does this guarantee that 
j
U j is connected?
Exercise 14.5 Suppose we take the real line and subtract k distinct points, how many
components will there be? Prove it.

Chapter 15
The Euler Characteristic
and the Classiﬁcation of Regular
Polyhedra
15.1 Introduction
It has long been known that there are only ﬁve regular polyhedra. These are the
tetrahedron, the cube, the octahedron, the dodecahedron and the icosahedron. How
can we deﬁne a regular polyhedron and how can we prove this list is complete? The
usual deﬁnition is that every face must have the same number of edges, and the same
number of faces must meet at every vertex.
The key to most proofs of this classiﬁcation is the Euler characteristic. This tells
us how to compute the number of edges, E, given the number of faces, F, and the
number of vertices, V.
For all the regular polyhedra, we get
V −E + F = 2.
See Table15.1, the quantity V −E + F is called the Euler characteristic. It takes the
value 2 for many more polyhedra than just the regular ones. In this chapter, we will
explore when it takes the value 2, how to prove it takes the value 2 and then how to
use this fact to classify the regular polyhedra. We will use various proof patterns en
route.
When mathematicians discuss polyhedra they generally mean the surface of a
solid polyhedron. We will use the term both for the surface and the solid object in
this chapter.
15.2 The Euler Characteristic and Surgery
The ﬁrst thing to note about the Euler characteristic is that it is very robust. We can
do all sorts of things to a polyhedron without changing its characteristic. As a ﬁrst
operation, consider drawing a line from a vertex to another non-adjacent vertex on
© Springer International Publishing Switzerland 2015
M. Joshi, Proof Patterns, DOI 10.1007/978-3-319-16250-8_15
127

128
15
The Euler Characteristic and the Classiﬁcation of Regular Polyhedra
Table 15.1 The Euler characteristic for regular polyhedra
Shape
V
E
F
V −E + F
Tetrahedron
4
6
4
2
Cube
8
12
6
2
Octahedron
6
12
8
2
Dodecahedron
20
30
12
2
Icosahedron
12
30
20
2
Fig. 15.1 A cube before and after chopping off a corner
the same face. Call this line an extra edge. We have divided the face into 2 pieces so
we also have an extra face. The number of vertices has not changed. So V −E +F has
not changed either. In conclusion, dividing a face in two by drawing a line between
two non-adjacent vertices does not change the Euler characteristic.
Now suppose we chop off a corner. We have a vertex where k edges meet and
we replace it by a small face. See Fig.15.1. The new face will have k sides because
there are k edges coming in. It will also have k vertices since a face must have the
same number of sides and vertices. For the polyhedron, we have increased the faces
by one, the edges by k and the number of vertices by k −1. So V −E + F changes
by
k −1 −k + 1 = 0.
Chopping off a corner does not change the Euler characteristic.
Wecanalsodeformpolyhedra:ifwemoveavertexandstretchtheedgesemanating
from it correspondingly, then the number of vertices, edges and faces does not change
and so neither does the Euler characteristic.
We can also glue polyhedra together. Suppose we have two polyhedra P1 and P2
with Euler characteristics χ1 and χ2. Let the number of vertices, edges and faces
in Pj be Vj, E j, Fj. Suppose we can ﬁnd a face in P1 which is identical to one in
P2. We now glue those two faces together to get a new polyhedron. What is the new
Euler characteristic? Suppose the joined-together faces have k edges and k vertices.
The number of vertices in the new polyhedron will be
V1 + V2 −k.

15.2 The Euler Characteristic and Surgery
129
The number of edges will be
E1 + E2 −k,
and the number of faces will be
F1 + F2 −2,
since the two glued-together faces have disappeared. The Euler characteristic of P
is therefore
χ = χ1 + χ2 −2.
So gluing on a shape with Euler characteristic 2 does not change the Euler charac-
teristic.
With all these operations, we can now construct a lot of polyhedra with Euler
characteristic 2. Equally, we have shown that if a polyhedron does not have Euler
characteristic 2 then it cannot be constructed from regular polyhedra using these
operations using difference of invariants.
Two obvious questions arise:
• How can we prove that a large class of polyhedra have Euler characteristic 2?
• Are there polyhedra that do not have Euler characteristic 2?
We will answer both of these in this chapter.
15.3 Transforming the Problem
We will prove that convex polyhedra have Euler characteristic 2. Recall that a subset,
A, of Rn is convex if given any points in it, the line between them also lies in A. We
ﬁrst change the problem to a statement about networks in the plane.
It is easier to prove statements when every face is a triangle. We saw in Sect.1.5
that every polygon can be triangulated by drawing straight lines between vertices. We
saw above that this operation does not change the Euler characteristic. It is therefore
enough to prove the result in the case that all faces are triangles. This is an example
of speciﬁc generality.
We next transform into a statement about lines inscribed on a sphere. Take a large
sphere which contains the polyhedron. Take a point, p, inside the polyhedron. We
deﬁne a map from the surface of the polyhedron to the sphere. Let q be a point in
the surface. Let θp(q) be the point on the sphere where the straight line starting at p
which passes through q hits the sphere.
Thestraightlineforeachpointq willbedifferentbecausethepolyhedronisconvex
and so each point q will get mapped to a different point of the sphere. Equally if
we take a point, r, on the sphere, then the line through it and p must intersect the
surface of the polyhedron somewhere and this point will be mapped to r, so we have
a bijection. We thus have mapped all the edges and vertices onto the sphere, and they

130
15
The Euler Characteristic and the Classiﬁcation of Regular Polyhedra
Fig. 15.2 Stereographic projection for a circle to a line
then now surround areas of the sphere which we can regard as faces. The network on
the sphere and the polyhedron will have the same Euler characteristic. We therefore
now only need consider the case of sphere with a network of lines and vertices drawn
on it. Note the crucial property that two lines can only intersect in a vertex. If we
started with a polyhedron with triangular faces then each face on the sphere will also
have 3 sides and 3 vertices.
It is easier to work with networks in the plane than on a sphere so we can transform
the problem further. We rotate and translate the sphere so that the south pole is at the
origin in three-dimensional space, and so that the north pole is in the interior of some
face. Having done so, we can now use stereographic projection to map the sphere to
the plane. We deﬁne a map, φ, from the sphere minus the north pole to the plane, for
a point p in the sphere, we take the straight line from the north pole to p and extend
it until it hits the plane, that is the set with x3 = 0. We map p to that point, q. See
Fig.15.2.
Every face other than the one containing the north pole maps to a triangular-
shaped region in the plane. The sides of these may be curved, however. The north
pole containing region maps to all the plane outside a large triangle which contains all
the other triangles. If we do not regard the exterior region as a face, then our problem
has transformed to proving that for a network of lines and vertices surrounding
triangles, the value of V −E + F must be 1.
15.4 The Result for Networks in the Plane
In this section, we prove that if we have a network of triangles in the plane then we
have V −E + F = 1. We assume that the triangles can only intersect along common
edges or a single vertex. We regard the network as the union of vertices, edges and
faces contained in it. We also assume that the network is polygonally connected.
Note that a path between two points in different triangles can pass ﬁrst to the edge
of one triangle, then along edges and vertices, and then to the ﬁnal point. So it is the
only ﬁrst and last part of the path that involve triangle interiors. The result cannot

15.4 The Result for Networks in the Plane
131
be true without this hypothesis of connectedness: n disjoint triangles will have Euler
characteristic n. Our ﬁnal assumption is that the area outside the network is also
connected. This will certainly be the case for the network resulting from polyhedra
according to our projection.
We proceed by induction. Our inductive hypothesis is that ALL such networks
containing n triangles have Euler characteristic 1. When n = 1, we only have 1
triangle and the result is clear.
Given a general such network with n + 1 triangles, we need to reduce to the n
case and then apply the inductive hypothesis. We will remove a triangle on the edge
of the network. There are a number of ways a triangle can be on the edge. It will not
share 3 edges since it is on the edge, and it must share at least one vertex since the
network is connected. Note also that if an edge is shared so is its endpoints. So the
intersection set could be
(1) zero edges and one vertex;
(2) zero edges and two vertices;
(3) zero edges and three vertices;
(4) one edge and two vertices;
(5) one edge and three vertices;
(6) two edges and three vertices.
See Fig.15.3 for the cases 1, 4 and 6. In case 1, we delete the triangle. We remove 3
edges, 2 vertices and 1 face. The Euler characteristic does not change. The network’s
complement is also clearly still connected. For the network’s connectedness, see that
if the path between two points in the remaining network had passed through this
triangle then it must have crossed the not-deleted vertex twice: on the way into the
triangle and the way out. So we simply remove the part of the path in between and
we still have a path between the two points.
In case 4, we delete the triangle by removing the vertex and two edges that are
not in the network. We have removed 2 edges, 1 vertex and 1 face so the Euler
Fig. 15.3 The three cases of
triangles that can be easily
removed

132
15
The Euler Characteristic and the Classiﬁcation of Regular Polyhedra
Fig. 15.4 The three cases of triangles that cannot be easily removed
characteristic is again invariant. We clearly have not changed the connectedness of
the network’s complement. For the connectedness of the network, we replace any
part of a path inside the triangle with a path along the edge, and so it is still connected.
In case 6, the sole edge of the triangle that is not in the intersection with the rest of
the network is removed. Its deletion removes the face of the triangle and the edge itself
so we decrease F and E by one and the Euler characteristic is unchanged. The edge
is on the boundary of the network so we are adding the interior of the triangle and the
edge to the complement. The network’s complement therefore remains connected.
We move any path through the triangle to run along the two edges left and the network
is still connected.
We are left with cases 2, 3 and 5. See Fig.15.4. These cases are different in that a
path through the triangle cannot be easily deformed to not pass through it—we can
expect that deleting such a triangle does indeed disconnect the network. Our solution
is therefore to ﬁnd a triangle that is in one of the other cases. So pick a triangle on the
boundary, if it is in another case, we are done. If it is in case 2, 3 or 5, it must be next
to another triangle on the boundary. Look at that triangle. If it is not in case 2, 3 or 5,
we delete it. If it is, observe that there must be a third triangle on the boundary next
to it. Again if this is not in case 2, 3 or 5, delete otherwise continue. We keep going
until we ﬁnd a deletable triangle. We need to show that the process stops. Since there
are only a ﬁnite number of triangles, it can only stop if we return to a case 2, 3 or 5
triangle already considered or we ﬁnd one not in case 2, 3 or 5.
We need to show that the ﬁrst does not occur. Suppose it does. We then have a
loop of triangles on the boundary. These triangles are all on the boundary so they will
always have an edge on the boundary and we can trace all these edges to get a closed
polygonal loop. See Fig.15.5. There will be points on both sides of this loop which
are not in the network since all the triangles are in case 2, 3 or 5. We now have to
invoke a big theorem: the Jordan closed-curve theorem from Chap.14. It tells us that

15.4 The Result for Networks in the Plane
133
Fig. 15.5 A bad
conﬁguration in which the
triangles form a loop
the two sides of the loop are not connected to each other. The loop of case 2, 3 and
5 triangles has made the complement of the network disconnected. This contradicts
our inductive hypothesis so such loops do not occur and we are done.
Note that we have used induction here and we have worked down rather than up.
An alternate approach might have been to start with one triangle and then stick more
on. The main trickiness would then lie in showing that you got every possible network
eventually. We also made the proof easier by assuming the inductive hypotheses for
all possible connected networks with connected complement and one less triangle
rather than trying to just assume it for the one network that was relevant.
The appearance of the Jordan closed-curve theorem is important in that it is at
this point that we make use of the fact that the polyhedron is topologically a sphere.
If our proof did not use it or something similar, we would be suspicious of it.
15.5 Counterexamples
An obvious question now arises, do all polyhedra have Euler characteristic 2?
That partially depends on the deﬁnition of a polyhedron! We construct some three-
dimensional shapes where it takes a different value. Suppose we take 5 cubes and
glue them together in a U pattern. See Fig.15.6. So we take one, glue a second one
to its bottom, glue 2 more to its side and then glue a further one to the last one’s top.
We know that this U shape has Euler characteristic 2 since it was made by gluing
cubes together, and we showed above that this does not change the value. However,

134
15
The Euler Characteristic and the Classiﬁcation of Regular Polyhedra
Fig. 15.6 Five cubes glued together in a “U” shape viewed from above
if we take two of these U shapes and glue them together on the faces at the tops of
the U shapes then we are gluing two faces at once and we get a ring-shape.
What is theEuler characteristic?Wehaveeliminated2faces, 4edges and4vertices
for each of the gluings, so we get
χ = χ1 + χ2 + 2 × (−4 −(−4) −2) = 2 + 2 + 2 × (−2) = 0.
The ring, or doughnut-shape, has Euler characteristic zero. The surface of this shape
is generally called a torus. We have shown that Euler characteristics do vary. Note
that there is a qualitative difference in this shape from the convex polyhedra: if we
take a loop on a torus that goes round the ring, it is not possible to shrink it to a point
without breaking it or leaving the torus. In a sphere, we can always just push the
entire loop to the north pole so it is quite different.
We can repeatedly glue on more and more U shapes, joining both the ends each
time. Each time we reduce the Euler characteristic by 2 and get an essentially different
shape. The number of holes is called the genus g and we have
χ = 2 −2g.
For closed surfaces in three-dimensional Euclidean space, it can be shown that given
an appropriate notion of deformation, two surfaces can be deformed into each other
if and only if they have the same g or χ.

15.6 Classifying Regular Polyhedra
135
15.6 Classifying Regular Polyhedra
We have listed ﬁve regular polyhedra and it has long been known that this list is
complete but how we can prove it? A polyhedron has V vertices, E edges, F faces,
and since it is regular, suppose every face is a polygon with p sides and q faces meet
at each vertex. What relations can we deduce? We must have
V −E + F = 2,
pF = 2E,
qV = 2E.
The middle equation is because every face has p edges and each edge is in two faces.
The last is because q edges meet at each vertex and each edge has two vertices. We
have three equations and all the solutions must be integers. We can eliminate V and
F from the ﬁrst equation, to get
2E
q −E + 2E
p = 2,
or
1
p + 1
q = 1
2 + 1
E .
The number of edges must be positive so we have
1
p + 1
q > 1
2.
Now p and q are positive integers. A polygon must have 3 sides and in a polyhedron
at least 3 sides must meet at a vertex so they are both at least 3. Since
1/p ≤1/3
we have
1/q > 1/6.
This means that q is 3, 4 or 5. The same argument shows that p is 3, 4 or 5. We now
have nine pairs, checking them, we see that the only possibilities for the pair (p, q)
are the ﬁve cases
(3, 3), (3, 4), (3, 5), (4, 3), (5, 3).
These yield the ﬁve polyhedra we listed initially and we are done.

136
15
The Euler Characteristic and the Classiﬁcation of Regular Polyhedra
15.7 Problems
Exercise 15.1 Suppose we make two W shapes out of cubes and join the three top
bits together what happens?
Exercise 15.2 If we attempt to apply our proof that the Euler characteristic is 2 to
a ring shape, where does it fail?
Exercise 15.3 Suppose we take a square in the plane and cut it into small triangles,
what is the Euler characteristic? Suppose we stick opposite sides together, what is
the new Euler characteristic? What if we twist one pair of sides before gluing?
Exercise 15.4 Suppose we take a regular polyhedron and form a new one by making
each vertex the centre of one of the old faces and joining vertices from neighbouring
faces with edges. What happens for each of the 5 regular polyhedra?

Chapter 16
Discharging
16.1 Introduction
In this chapter, we use the notion of discharging to prove more results about polyhedra
and maps. First, we give an alternative more recent proof that the Euler characteristic
is always 2 for a convex polyhedron, and then we look at how to combine discharging
and double counting to prove that only certain face combinations are possible for
any polyhedron.
In order to discharge a polyhedron, one ﬁrst has to charge it. The notion is similar
to that of electric charge. We put one unit of charge on every face and vertex, and
minus one units on every edge. The Euler characteristic is then the total charge on
the polyhedron.
16.2 The Euler Characteristic via Discharging
We present a proof due to William Thurston that the Euler characteristic of certain
polyhedra is 2. We suppose that the network deﬁned by the edges can be inscribed
on a sphere without changing the number of faces, edges and vertices and their
intersections. We saw that this was possible for convex polyhedra in the last chapter.
We also saw previously that we can make all faces triangular without affecting the
Euler characteristic so assume also that this has been done.
First, we rotate the sphere and deform the network so that one vertex is at the north
pole and another is at the south pole. We also deform the network so that no edge
is horizontal: we make sure that no two vertices have the same latitude. Now charge
the network as discussed above. We push charge eastwards. We make the charge on
each edge go on to the face to its east. Since no edge is horizontal the eastwards
face is well deﬁned. If a vertex is between two edges both going on the same face
its charge goes to that face as well. For other than the two poles, since every vertex
© Springer International Publishing Switzerland 2015
M. Joshi, Proof Patterns, DOI 10.1007/978-3-319-16250-8_16
137

138
16
Discharging
is surrounded by triangles which have it as a vertex, this will be true for exactly one
of those triangles.
Each face therefore gains the charge from either one edge and so has net charge
zero, or gains the charge from two edges and one vertex and again has zero net
charge. At the end, the only charge remaining is that on the north and south poles
and we have 2. The charge-moving procedure has not changed the net charge so the
Euler characteristic must have been 2 initially and we are done.
16.3 Maps and Double Counting
We saw in Chap.12 that the Four-Colour theorem in general is implied by the special
case that three countries meet at every vertex. Such a map is sometimes said to
be cubic. Counting the area outside the map as a single extra country, we can use
stereographic projection to change a map into a polyhedron. What can we say about
cubic polyhedra? We can count up the edges, faces and vertices in terms of how
many sides each face has. Thus let Nk be the number of faces with k sides. We then
have
F =

k
Nk.
For edges, we get
2E =

k
kNk,
since each edge is two sides, and if a face has k sides that is the same as saying it has
k edges. For vertices, since the map is cubic, each vertex is in 3 faces. So
3V =

k
kNk.
We know
V −E + F = 2.
We conclude

k
(1 −k/2 + k/3)Nk = 2.
equivalently,

k
(6 −k)Nk = 12.
This immediately says that for some k < 6, Nk > 0: there must be at least one side
with less than 6 sides.

16.3 Maps and Double Counting
139
Fig. 16.1 A cubic map containing a pentagon marked “A”
In fact, the result does quite a bit better. Each face has at least 3 sides so we must
have 4 faces with less than 6 sides. If each face has at least 4 sides, then we must
have at least 6 faces with 4 or 5 sides. If there are no faces with less than 5 sides then
we must have 12 faces with 5 sides. A dodecahedron has 12 faces with 5 sides and
3 faces meet at each vertex so this is as good as you can get.
We can now easily prove the Six-Colour theorem.
Theorem 16.1 Any map of the plane can be coloured with 6 colours so that no two
territories with a common edge have the same colour.
Proof It is enough to consider the cubic case. We proceed by complete induction.
If there are less than 7 countries, the result is clear. Suppose every map with n or
fewer countries can be done. If our map has n + 1 countries, ﬁnd a country with
5 or fewer sides. See Fig.16.1. Merge this country with one of its neighbours. The
new map has n countries so it can be six-coloured. Now restore the country that was
merged. See Fig.16.2. It only has 5 or fewer neighbours, so assign it a colour that
none of its neighbours have and we have a colouring. Unfortunately, this argument

140
16
Discharging
Fig. 16.2 A cubic map in which the pentagon marked “A” has been merged with an adjacent
hexagon
has a ﬂaw. We have implicitly assumed that the two countries merged do not have
more than one side in common. If the two sides in common are adjacent then they
are not really separate sides and we do not have a problem. If they are not adjacent
then post merging the new country is a ring shape and so we have a map interior to it
and one exterior. By considering the ring and its exterior as a single country, we can
colour the interior and the ring with 6 colours. Rearrange the colours so that the ring
is yellow. Now do the same for the exterior and the ring. Since both colourings make
the ring yellow, we can merge the two and have a colouring of the map including the
ring. We can reinsert the pentagon, as before and give it the one colour that does not
neighbour it.
The result follows by complete induction.
□
Of course, we would really like to prove the Four-Colour theorem not the Six-
Colour one. This is much harder but the basic approach is the same, show that certain
conﬁgurations of territories are inevitable and that they can be handled.

16.4 Inevitable Conﬁgurations
141
16.4 Inevitable Conﬁgurations
In the last section, we saw that for a cubic map, there will always be a face with less
than 6 sides. We can actually do better. We can prove that there must always be a
face with less than 5 sides or a face with 5 sides adjacent to a face with 5 or 6 sides.
The proof uses discharging.
Suppose every face has at least 5 sides. To each face with k sides, assign a charge
of 6 −k. We know

k
(6 −k)Nk = 12.
The only faces with positive charge have 5 sides. Suppose each one only has neigh-
bours with seven or more faces. Take the positive charge and share it equally among
the neighbours. We show that the neighbours will continue to have negative charge.
If a face has 2k edges then it has charge 6 −2k before the discharging. It can have at
most k pentagon neighbours if no two are adjacent, so it can gain at most k/5 charge.
So its ﬁnal charge is at most
6 −2k + k/5
which is less than zero for k > 3. If it has 2k + 1 faces it can again have at most k
pentagon neighbours so its ﬁnal charge is at most
6 −2k −1 + k/5 = 5 −14
5k,
which is again less than zero for k > 3. We thus have that all faces have zero or
negative charge. This is impossible if the charges add up to 12. We conclude that
some pentagonal face has a neighbour with ﬁve or six sides.
16.5 Problems
Exercise 16.1 What happens if we attempt to apply Thurston’s discharging proof
to a torus? (i.e. the surface of a doughnut.)
Exercise 16.2 Is it possible to have a polyhedron whose faces are all pentagons or
hexagons? How many pentagons must such a polyhedron have? Suppose we merge
two adjacent faces what happens?

Chapter 17
The Matching Problem
17.1 Introduction
The Principal of Silly College has decided that his students are spending too much
time dating and not enough time studying. He decides that the easiest way to solve
the problem is to pair off the students as couples in such a way that everyone is happy
enough to make the pairings stable. He therefore summons the college mathemati-
cians, Jack and Jill, and asks them to devise an algorithm for pairing the students.
17.2 Formulating the Problem
First, the problem has to be given a mathematical formulation. Jack and Jill arrive at
the following formulation.
• There are N male and N female students.
• Each student is required to provide a list of the students of the opposite sex in
order of desirability with most desirable ﬁrst.
• A pairing is stable if there does not exist a male and female who prefer each other
to their assigned partners.
Note that this deﬁnition of stability does not require anyone to have their ideal mate,
nor does it have a concept of optimality; there may be other pairings that make more
students happy in some sense.
Once a deﬁnition has been formulated, three obvious questions are generally asked
by mathematicians:
(1) does a stable pairing always exist?
(2) are stable pairings unique?
(3) how can we ﬁnd a stable pairing?
We now see how to answer all of these using an algorithmic construction.
© Springer International Publishing Switzerland 2015
M. Joshi, Proof Patterns, DOI 10.1007/978-3-319-16250-8_17
143

144
17
The Matching Problem
17.3 The Algorithm
Jack comes back the next day with an algorithm.
(1) Every male student who is not paired, proposes to the highest ranked female on
his list who has not yet said no to him.
(2) Each female who has multiple offers takes the one she ranks highest. She does
this even if she has already accepted an offer from someone who is lower on her
list. If her new offers are worse than her previously accepted offer she ignores
them.
(3) This process is repeated until everyone is paired.
For this algorithm to be useful, we have to show that it always terminates and that
the resulting pairing is indeed stable. This algorithm is called the Gale–Shapley
algorithm.
To see that the algorithm always terminates, observe that once a female is engaged
she is always engaged (but possibly to someone else,) and that once she has had one
proposal this is always the case. Observe also that every female will always get at
least one proposal since each male will work down his list until he is paired, and as
long as there is a surplus female there is also a surplus male.
We now show that the resulting pairing is stable. Consider a male A and a female
B who are not paired to each other. We must show either that A prefers his current
partner to B, or that B prefers hers to A. If A does not prefer his current partner to
B, then he will have asked B before his current partner. She must have turned him
down for someone else she preferred or he would be paired with her. Given that she
only changes partners when she gets a better offer, she therefore prefers her current
partner to A. So the pairing is indeed stable.
17.4 Uniqueness
The question of uniqueness remains. Immediately, after Jack presents his solution,
Jill derides it as sexist since men get to do all the proposing. She therefore switches
the role of males and females. Since the problem formulation does not change when
we switch them, her algorithm is equally valid. We now have two different algorithms
that produce stable matchings.
The existence of two different algorithms alone does not imply non-uniqueness.
They could always end up at the same solution. Indeed, this is often the case in
computer science where the objective of ﬁnding new algorithms is to reach the same
solution faster rather than to ﬁnd a different one. However, if we present input data
that causes the two algorithms to lead to different outcomes then we do indeed have
non-uniqueness. Call the male students A, B and C and the female students X, Y
and Z.

17.4 Uniqueness
145
Suppose the lists are as follows:
• A : XY Z.
• B : Y Z X.
• C : Z XY.
Then it does not matter what the female lists are for Jack’s algorithm. Each male gets
his ﬁrst choice and we are done. A gets X, B gets Y and C gets Z. Now suppose the
female lists are
• X : C B A.
• Y : B AC.
• Z : AC B.
and we use Jill’s algorithm, then X gets C, Y gets B and Z gets A. Since both
pairings came from algorithms guaranteed to produced stable results, we now have
two distinct stable pairings. We have demonstrated non-uniqueness.
We have shown the existence and non-uniqueness of stable pairings by algorithmic
construction. In designing these algorithms, we have not put in any form of optimality
criterion. All we have looked for is stability. One pairing may be better than another
in that it leads to greater happiness but we have not built that consideration into our
algorithms.
17.5 Further Reading
For more discussion of the matching problem and related questions, see Gura and
Maschler’s “Insights into game theory.”
17.6 Problems
Exercise 17.1 The room-mate problem is to pair new students of the same sex into
rooms. A pairing is stable if no two students prefer each other to their room-mate.
Does the algorithm presented here apply?
Exercise 17.2 We can rate a matching of all students by summing all the ranks of
each member of a pair for his/her partner. Show that there is a stable pairing which
minimizes this rating amongst stable pairings. Will it be unique? Design an algorithm
to ﬁnd it.

Chapter 18
Games
18.1 Introduction
In this chapter, we look brieﬂy at game theory. In particular, we look at how one
might use mathematics to answer questions such as is it ever advantageous to play
second in a game? In answering that question, we see an example of a non-trivial
application of proof by contradiction.
What is game theory? It is the study of how to ﬁnd optimal strategies for playing
games. It is often applied to situations well outside board games such as negotiations
and evolution. Here we will stick to “classic games” in which there are two players,
they play alternately, there is no luck and at all times both players know the complete
state of the game. Examples of such games are chess, draughts, go, othello, abalone,
Nim, and noughts and crosses.
We look at the following questions
• must there exist an optimal strategy?
• must games always end?
• are there games where we can be sure that going second is bad?
18.2 Deﬁning a Game
There are many ways to deﬁne a classical game. Here we deﬁne it using a state-space
and relations that specify which moves are legal. Thus we can deﬁne a game-state
to be a ﬁnite sequence of integers or real numbers. Note that our objective here is to
prove theorems, not to develop efﬁcient computer algorithms so our data structures
are ones that would be unlikely to be used by a software engineer. For traditional
games, integers will sufﬁce. For example, the state of chess board can be described
as a sequence of 64 integers each one denoting what piece is in that square and a
zero denoting an empty square. A “go board” is 192-squared lattice points each one
containing 0 for nothing, 1 for a black piece and 2 for a white piece.
© Springer International Publishing Switzerland 2015
M. Joshi, Proof Patterns, DOI 10.1007/978-3-319-16250-8_18
147

148
18
Games
In noughts and crosses, also known as tic-tac-toe, the players take turns to write
down their symbol, a cross or a nought, into empty squares until all squares are ﬁlled
or the victory condition of 3 in a row is achieved. More generally, we could consider
an n-dimensional board of k squares in each direction with a victory condition of
achieving l in a row. We will call this (n, k,l) noughts and crosses.
Both chess and go have a rules subtlety designed to prevent inﬁnite loops. In
chess if the same position occurs 3 times in the same game, a draw can be claimed.
In go, it is illegal to return the board to a state that has been previously achieved.
Thus the state of the game is not just the state of the board but also all previously
achieved board-states. We can easily encapsulate this mathematically by deﬁning the
game state to be the vector of all board states so far achieved in the game. We will
also generally want an extra state variable to specify termination and who won, for
example white wins, black wins, draw, game not over yet.
The game Nim has a very simple state-space. In this game, two players take turns
to remove 1–3 matches from a pile of them. The person who takes the last match
wins. The state space is simply a natural number representing the number of matches
left in the pile.
We can deﬁne the game rules to be a relation, R, between game states. Thus the
legal moves from a position x are simply the positions y such that x Ry.
Having deﬁned games mathematically, we can now start trying to prove theorems.
18.3 Termination
We show that chess, go and (n, k,l) noughts and crosses must terminate. Noughts
and crosses is the easiest. The board has kn squares and every turn one is ﬁlled in.
After kn turns the board is full, and the game is over so noughts and crosses certainly
ends.
Now chess, we can prove termination by using the three-repetition rule. Each
player has 6 different sorts of pieces, and a square must contain one of these or be
empty so there are at most 6413 legal positions. Eventually, one of these must be
attained 3 times so the game must end. Our upper bound on the numbers of moves is
rather crude, and chess generally has other ways to ensure termination in a reasonable
amount of time. However, our approach is sufﬁcient to prove that the game ends.
In go, similarly, we have 3261 possible board states. So eventually the no-repetition
rule will ensure that neither player has a legal move and they will both have to pass
and the game is over.
In Nim, we can use a simpler argument, if there are n matches and each player
always takes at least one, the game will be over in at most n turns.

18.4 Optimal Strategy
149
18.4 Optimal Strategy
We can ask the question of who will win if both players play optimally. For example,
in Nim there is a well-known strategy. If there are 4k + l matches left with k an
integer and l between 1 and 3 inclusive, take l matches. If l = 0 and it is your turn,
then you have lost, so take 1 and hope your opponent does not play optimally. This
strategy works because after your turn there is always a multiple of 4 matches left.
The number of matches goes down by 4 every two turns and so eventually hits zero
with you having taken the last match.
The game Nim is said to be “ﬁrst player wins” if you start with a non-multiple of
four matches, and “second player wins” otherwise. We would like to classify other
games as “ﬁrst player wins”, “second player wins” or “draw”. Before doing so we
really need to show that every classical game does indeed have an optimal strategy.
We can proceed by backwards induction. There are a ﬁnite number of ﬁnished
game board states. In each of these, the victor or draw is known. We label them
accordingly. We next consider positions where all moves put you into an already
labeled position, or the player moving can achieve a position labeled with their own
victory. We label all these positions to be the best outcome they can achieve so if
they can get a victory then the player moving wins; if not and they can achieve a
draw then “draw”; otherwise label with other player wins.
Once this is done. We repeat until all positions have been labeled. Note that each
time we label a position, more positions will have all possible moves labeled. To see
who wins we look at the initial position and we are done.
We really ought to show that the process will always terminate in the sense that we
will not reach a point where no positions can be labeled. However, if we know that
the game must terminate after N moves, then at the kth stage we must have labeled
all games that have taken N −k moves. So we will ﬁnish labeling when k = N at
the latest.
Our optimal strategy is now just to play the state that has the same label as the
current board state. If there are multiple such states then choose any one. This would
then indicate that there is more than one optimal strategy.
Our argument has shown that an optimal strategy exists and shown how to con-
struct it. Unfortunately, for reasonably complex games it is not feasible to program
in that the amount of computational power required would be immense. Indeed,
it is only recently that computer programs that play go reasonably have been
implemented, and they are still a long way from defeating human professionals.
18.5 Second Player Never Wins
In some games, one can prove that optimal play will not make the second player win.
The essential feature of such games is that there is never a disadvantage to playing.
This is not the case for chess where a special word “zugzwang” is used to denote

150
18
Games
a position where the optimal move would be no move if that were legal. It is also
clearly not the case in Nim where second player does win if there are 4 sticks left.
In noughts and crosses, however, it is always preferable to play. The reason being
that having an extra piece on the board in no way restricts you or makes your position
worse. We can use proof by contradiction to prove that there is not a strategy to make
the second player always win. Suppose such a strategy existed. The ﬁrst player would
make a random ﬁrst move, and then would be in the position of the second player
with an extra piece on the board. From then on, he would follow the second player’s
optimal strategy. If the strategy was to play at a point already occupied by his extra
piece then we just plays an extra piece anywhere on the board. Since this strategy
makes the second player win, it must also make the ﬁrst player win since the extra
piece can cause no harm. We have a contradiction: if second player always wins then
ﬁrst player always wins. We conclude that with optimal play either ﬁrst player wins
or there is a draw.
18.6 Problems
Exercise 18.1 Suppose Nim is played with 2 stacks and each player can only take
from one of them each turn. Analyze this game.
Exercise 18.2 Suppose we play a version of Nim on a clock face. We start with the
hour hand at 12 the ﬁrst player to get it to 6 wins. Each turn a player can move the
hour hand 1–3 integer hours. What happens? What if we add in the rule that the clock
cannot show the same time twice? What if we delete any time that has been visited
so moving the remaining times closer together. What if we allow a 24-h clock?
Exercise 18.3 Suppose the ability to “pass” in chess is added. If both players “pass”
then the game is drawn. Can we then prove that there is not an optimal strategy
making the second player always win?
Exercise 18.4 There are n lions in a cage. A piece of meat is thrown in. Suppose
• The lions are hungry.
• A lion that eats the meat falls asleep.
• An asleep lion is meat to the other lions.
• Each lion and the meat is closest to exactly one other lion.
• The lions are ultra-intelligent.
• The lions prefer to stay alive.
What happens?

Chapter 19
Analytical Patterns
19.1 Introduction
When calculus is made rigorous, it is renamed analysis. It is one of the major branches
of modern pure mathematics. Analysis is essentially the study of limits. One of the big
achievements of 19th century mathematics was to give deﬁnite meaning to statements
such as
xk →x, as
k →∞,
and to derivatives. The reader who has done no analysis may ﬁnd this chapter a little
tough, however, we try to present the basics in a slightly non-standard way that we
hope will be useful to both total beginners and novices.
Thekeytomakingsenseoflimitslayinadeﬁnitionthatappearsslightlybackwards
to the untrained eye. Before we proceed to it, we must deﬁne a sequence.
Deﬁnition 19.1 An Rn−valued sequence is a map from N1 to Rn.
Thus we associate an element of Rn to every counting number, k. In analysis, we are
generally only concerned with what happens for k large. The truth of most statements
about limits will not change if the ﬁrst one million values of the sequence are changed.
We can regard C as R2 so all our statements are equally valid for complex-valued
sequences.
In this chapter, we will look at the deﬁnition of limits and study some of the basic
patterns used to show that they do and do not exist. We can do no more than touch
on the basic concepts and ideas in a short chapter, however.
© Springer International Publishing Switzerland 2015
M. Joshi, Proof Patterns, DOI 10.1007/978-3-319-16250-8_19
151

152
19
Analytical Patterns
19.2 The Triangle Inequality
A fundamental tool in analysis is the triangle inequality. This states that for two
vectors x, y ∈Rn,
||x + y|| ⩽||x|| + ||y||.
The same result holds for R and C, if we replace || with |. It is often useful in a
backwards way.
||v + w|| ⩾||v|| −||w||.
To see this let x = v + w, y = −w.
19.3 The Deﬁnition
The modern deﬁnition of a limit of a sequence is as follows. We shall say that xk →x
as k →∞, if given any ϵ > 0, there exists N such that for all k ⩾N,
||xk −x|| < ϵ.
In other words, xk tends to x if and only if you can pick any positive distance, wait
long enough, and then eventually all points in the sequence are within that distance
of x.
Sometimes N is written as Nϵ to emphasize the fact that the value N will vary
with the choice of ϵ. The deﬁnition does not say anything about the rate at which xk
gets close to x. It may be very fast or very slow.
The great feature of the deﬁnition is that it only involves ﬁnite quantities even
though it is a statement about what happens as k gets very large and in some sense
close to inﬁnity. It is this feature that allowed the rigorization of calculus.
We now look at some examples. Let
xk = 1
k .
Intuitively, we would expect xk →0. How do we show this with our deﬁnition?
Given ϵ > 0, let
Nϵ = 1 + 1
ϵ .
We then have that if k ⩾Nϵ, then k > 1/ϵ which immediately implies
0 < 1
k < ϵ.
So the limit is zero as we would expect.

19.3 The Deﬁnition
153
Having made the deﬁnition, we need to check that it is a good one. Our intuitive
notion of limit suggests that a sequence should not have more than one limit. We
prove that this is true with our deﬁnition.
Proposition 19.1 Let (xk) be a sequence in Rn. Suppose xk →x, and xk →y then
x = y.
Proof We show that x = y by proving that they are within ϵ of each other for every
ϵ > 0. The only way this can happen is if they are equal. This is a common pattern
in analysis. We call it arbitrary closeness.
Let ϵ > 0. Let ϵ′ = ϵ/2, then there exists integers Nϵ′, Mϵ′ such that
k > Nϵ′ =⇒||xk −x|| < ϵ′,
l > Mϵ′ =⇒||xl −y|| < ϵ′.
Let r = 1 + max(Nϵ′, Mϵ′). We then have
||x −y|| = ||x −xr + xr −y|| ⩽||x −xr|| + ||xr −y|| < 2ϵ′ = ϵ.
So x = y as claimed.
□
Do all sequences have a limit? No! A simple example is
xk = (−1)k.
This alternates between −1 and 1 and so converges to neither. A more violent example
is
yk = k(−1)k.
With our deﬁnition, we do not have a concept of converging to inﬁnity. So a simple
sequence that does not converge is
zk = k.
However, one could make a different deﬁnition that encompasses the notion of con-
verging to inﬁnity and then it might converge. We do not explore that option here.
One simple property of limits is that they preserve weak inequalities.
Proposition 19.2 Let xk be a sequence in R. Suppose xk →x, and xk ⩾y for all
k then x ⩾y. Similarly for ⩽.
Proof We show that if z < y then xk does not converge to y. Let ϵ = y −z. Then
|xk −z| = xk −z = (xk −y) + (y −z) ⩾y −z = ϵ.
So there does not exist N such that for k > N, |xk −z| < ϵ.
□

154
19
Analytical Patterns
Strict inequalities are not preserved, however. We have
1
k > 0, ∀k and lim
k→∞
1
k = 0.
19.4 Basic Results
It is fairly rare that the deﬁnition is used directly. Instead, results about convergence
are used to imply that sequences converge from the fact that other sequences do. In
our proof of the uniqueness of limits, we used a common technique which is that if
we can show that convergence occurs within some multiple of ϵ that is enough. In
fact, we can prove something better: the poly-epsilon pattern.
Proposition 19.3 Suppose p is a non-zero polynomial with p(0) = 0, and all non-
constant coefﬁcients positive, (xk) is a sequence in Rn, x ∈Rk, z > 0 and for all
ϵ > 0, there exists Nϵ such that k > Nϵ, implies
||xk −x|| ⩽p(ϵz),
then
xk →x.
As a special case, taking z = 1, and p(y) = 2y, we see that it is enough to show
that there exists Nϵ such that for k > Nϵ
||xk −x|| ⩽2ϵ.
Proof Suppose we are given ϵ > 0. We know that given f > 0, we have for k > N f ,
||xk −x|| ⩽
d

j=1
c j f jz
where the polynomial is of degree d and
p(y) =
d

j=1
c j y j.
There is no constant term since p(0) = 0. Our objective is to pick e so that k > Ne
implies ||xk −x|| < ϵ. Let C = max(c j). We can write

19.4 Basic Results
155
||xk −x|| ⩽C
d

j=1
f jz.
It is sufﬁcient to consider the case where ϵ < 1, since if we can show that the result
holds with ϵ = 0.5, then the same value of N will do for all ϵ > 0.5. We therefore
also take f < 1, the value of f jz is biggest when j = 1, since raising any number
between zero and one to a positive integer power makes it smaller. We therefore have
||xk −x|| ⩽Cd f z.
Now
Cd f z < ϵ
if and only if
f z <
ϵ
Cd .
This holds if and only if
f <
 ϵ
Cd
1/z
.
We therefore set
f = 1
2
 ϵ
Cd
1/z
,
and we have that for k > N f
||xk −x|| < ϵ.
We have proven convergence.
□
With this result proven, we can prove some basic results.
Proposition 19.4 Let xk →x and let yk →y, then
xk + yk →x + y.
Proof Let ϵ > 0, then there exists M, N such that
||xk −x|| < ϵ for
k > M,
and
||yk −y|| < ϵ for
k > N.

156
19
Analytical Patterns
Let L = max(M, N). We then have for k > L,
||xk + yk −(x + y)|| = ||(xk −x) + (yk −y)|| ⩽||xk −x|| + ||yk −y|| < 2ϵ.
Our result is now immediate by poly-epsilon.
□
Proposition 19.5 Let xk →x and let λ ∈R, then
λxk →λx.
Proof Let ϵ > 0, then there exists M such that
||xk −x|| < ϵ for
k > M.
We have
||λxk −λx|| = ||λ(xk −x)|| = |λ|||xk −x|| ⩽|λ|ϵ.
Our result is now immediate by poly-epsilon.
□
A slightly more complicated fact is that products of sequences converge to the
product of the limits.
Proposition 19.6 If xk →x, yk →y, in R or C then
xk yk →xy.
Proof Note that a sequence zk converges to z if and only if zk −z converges to zero.
We show that it is enough to consider the case where x = y = 0. To this observe
xk yk −xy = (xk −x)(yk −y) + xyk + xk y −2xy.
The sum of the two middle terms converges to 2xy by our results above, so the sum
of all four terms will converge to zero if and only if
(xk −x)(yk −y)
converges to zero. Given ϵ > 0, we have that there exists M, N such that for k >
M, k > N, ||xk −x|| < ϵ, and ||yk −y|| < ϵ. So for k > L = max(M, N),
||(xk −x)(yk −y)|| = ||xk −x||||yk −y|| < ϵ2.
The convergence follows by poly-epsilon.
□

19.4 Basic Results
157
Having established that sequences behave well under addition and multiplication,
the obvious next question is what about subtraction and division? In fact, our existing
results already cover subtraction. We have showed that if xk →x then −xk →−x
by setting λ = −1 in the result above. So if yk →y, we have adding together that
xk −yk →x −y.
This leaves division. We ﬁrst prove a result about reciprocals.
Proposition 19.7 If xk →x in R or C and xk ̸= 0 for all k and x ̸= 0, then
1
xk
→1
x .
Proof First note,

1
xk
−1
x
 =

x −xk
xxk
 .
Dealing with the top is easy, the bottom is more subtle. We need to show that it is
not too small so that its reciprocal is not too big. Taking ϵ = |x|/2, we know that
there exists N such that for k > N,
|xk −x| < |x|
2 .
This implies
|xk| > |x|
2 .
We thus have for k > N,

1
xk
−1
x
 < |x −xk|
2
|x|2 .
So given ϵ > 0, we pick Mϵ so that Mϵ ⩾N, and k > Mϵ implies
|xn −x| < ϵ.
So for k > Mϵ,

1
xk
−1
x
 <
2
|x|2 ϵ.
The result now follows by poly-epsilon.
□

158
19
Analytical Patterns
Combining this result with our results on products, we have
Proposition 19.8 If xk →x in R or C and xk ̸= 0 for all k and x ̸= 0, then if
yn →y, we have
yk
xk
→y
x .
We can now establish the convergence of various sequences. For example, if A
and B are complex numbers
A
k →A × 0 = 0,
so
1 + A
k →1
and then
k + A
k + B = 1 + A/k
1 + B/k →1.
Often when proving convergence, we use sandwiching or domination. The idea
here is that if we have three sequences with one in between the other two, then the
limiting behaviour of the middle must be between that of the other two.
Proposition 19.9 Suppose xk, yk, zk are real-valued sequences with
xk ⩽yk ⩽zk
for all k. If xk and zk converge to α then so does yk.
Proof Let ϵ > 0, there exist Nϵ such that for k > Nϵ,
|xk −α| < ϵ.
So
−α −ϵ < xk ⩽yk.
Similarly, there exists Mϵ such that for k > Mϵ,
α + ϵ > zk ⩾yk.
So for k > max(Lϵ, Mϵ),
−α −ϵ < yk < α + ϵ,
which is equivalent to
|yk −α| < ϵ.
We are done.
□

19.4 Basic Results
159
For example, if β > 1, we immediately have
0 < 1
kβ ⩽1
k
so
1
kβ →0,
as k →∞.
When working with sequences in Rn, it is sometimes more convenient to look at
each coordinate. We can prove
Proposition 19.10 The sequence xk in Rn converges to y ∈Rn if and only if every
coordinate x j,k of xk converges to the j coordinate of y.
Proof Let y = (y1, . . . , yn). First, observe that
|x j,k −y j| ⩽||xk −y||
so the forward direction is immediate.
Now suppose x j,k →y j for each j. Given ϵ > 0, we can ﬁnd N j,ϵ for each j
such that for k > N j,ϵ,
|x j,k −y j| < ϵ.
Setting Nϵ = max
j
N j,ϵ, this holds for j ≥Nϵ.
Now
||xk −y|| =




n

j=1
|x j,k −y j|2
⩽
	
nϵ2,
= √nϵ.
Our result follows by poly-epsilon.
□
19.5 Series
Series are closely related to sequences but are often more interesting. With a series,
it is the convergence of the partial sums that interests us not the sequence itself.

160
19
Analytical Patterns
Deﬁnition 19.2 Let xk be a real- or complex-valued sequence. Let
sk =
k

i=1
xi.
The series 
 xk is said to converge to s if and only if sk converges to s. We call sk
the sequence of partial sums of xi.
An important result when proving convergence of series is that a bounded increas-
ing sequence of real numbers converges. We discussed this result in Chap.10. Here
we shall take it as an axiom.
This allows us to prove that series converge via domination.
Proposition 19.11 Suppose 
 xk converges, and 0 ⩽yk ⩽xk for all k then 
 yk
converges.
Proof Since the terms are non-negative, both sequences of partial sums are increas-
ing. We have that
k
i=1
xi is increasing and convergent to some limit, x. This implies
k

i=1
yi ⩽
k

i=1
xi ⩽x
for all k. The sequence of partial sums of yi is therefore increasing and bounded.
The series converges.
□
For example, does 
 kα converge? Before examining individual cases, we show
that there exists α0 such that for α < α0 it converges and for α > α0 it does not.
We have if α < β, k > 1
kα < kβ.
So by domination, if 
 kβ exists so does 
 kα. Contrapositively, if 
 kα does
not converge, neither does 
 kβ. Once we have found a value for which convergence
occurs, all lower values give convergence. We can let α0 be the supremum of the set
of values for which convergence occurs.
If α = 0, 
 kα = 
 1 and divergence is clear. If we take α = −2, we have for
k > 1,
1
i2 <
1
i(i −1) =
1
i −1 −1
i .
This means that
k

i=1
i−2 ⩽1 +
k

i=2

1
i −1 −1
i

= 1 + 1 −1
k < 2.

19.5 Series
161
So by domination
k

i=1
i−2,
converges and
k
i=1
iβ converges for all β < −2.
The changeover point is therefore between 0 and −2. We now look at −1. In this
case, we have divergence. We will show that
s2k ⩾1 + k
2
which shows that the partial sums are unbounded and so convergence cannot occur.
Observe that we can write
s1 = 1,
s2 = 1 + 1
2,
s4 = 1 + 1
2 + 1
3 + 1
4 > 1 + 1
2 + 2
4 = 1 + 2
2,
s8 = s4 + 1
5 + 1
6 + 1
7 + 1
8 > s4 + 4
8 > 1 + 2
2 + 1
2.
So we have shown the result for k = 1, 2, 3, 4. For the general case, we use induction,
assume it is true for S2k, we then have
s2k+1 = s2k +
2k+1

l=2k+1
1
l > s2k + (2k+1 −2k)2−(k+1).
The second term simpliﬁes to 1/2. So using the inductive hypothesis,
s2k+1 > 1 + k
2 + 1
2 = 1 + k + 1
2
as required and we are done.
The series 1/k is sometimes called the harmonic series. We have seen that it
diverges, however, the divergence is very slow. Our proof only shows that the sum
of the ﬁrst 220 terms is at least 11, and 220 is bigger than a million. It is an important
example of a series in which the individual terms go to zero but the partial sums of
the series go to inﬁnity.

162
19
Analytical Patterns
We have not addressed the convergence of kα for α ∈(−2, −1). In fact, these all
converge. The standard way to proceed is to observe that
kα ⩽xα
for x ∈(k −1, k]. It then follows that
m

k=2
kα <
m

1
xαdx =
1
1 + α

m1+α −1

.
Showing that the integral is bounded is easy and the result follows. However, to do
this properly would require us to develop a rigorous theory of integration which is
beyond our scope.
We have seen that the terms of a series converging to zero does not imply that the
series converges. However, the converse is true.
Proposition 19.12 If 
 xk exists then xk →0.
Proof If the sum converges to x then given ϵ > 0, there exists N such that for n > N
|sn −x| < ϵ.
Now
|sn+1 −sn| ⩽|sn+1 −x| + |x −sn| < 2ϵ.
But xn+1 = sn+1 −sn. So for k > N + 1,
|xk| < 2ϵ,
and we are done.
□
This result is more often used in the contrapositive: if xk does not converge to
zero then 
 xk does not exist.
19.6 Continuity
Functions are a very general concept in mathematics. In some ways, they are too
general to say much. A natural restriction is to require a function to be continuous.
Deﬁnition 19.3 Let I ⊂Rn. A function, x, from I to Rm is continuous if for every
sequence xk such that xk ∈I for all k and xk →x ∈I, we have
f (xk) →f (x).

19.6 Continuity
163
In other words, we deﬁne continuity to mean that you can take the function through
limits:
lim
k→∞f (xk) = f ( lim
k→∞xk).
We have only considered real functions here but we can identify C with R2 so the
deﬁnition and results work equally well for complex numbers. Note that the deﬁnition
requires that f can be passed through the limit for every convergent sequence not
just one of them.
What are some continuous functions? The identity function
f (z) = z,
is trivially continuous from our deﬁnition. We showed above that the limits of two
convergent sequences is the product of the limits, applying this to the product of a
sequence with itself, we have that
f (z) = z2
is also continuous.
More generally, we can show
Proposition 19.13 Suppose f, g are real (or complex-valued) continuous functions
on I and λ ∈R (or C) then the following functions are continuous
• f + g,
• λ f,
• f g,
and if g ̸= 0 everywhere and takes values in R (or C) then so is f/g.
Proof If xn →x, then we have
f (xn) →f (x) and g(xn) →g(x),
by the deﬁnition of continuity. Our results on limits then says
f (xn) + g(xn) →f (x) + g(x).
This shows that f + g is continuous. The proofs for λ f and f g are essentially the
same. For f/g we have that g(xn) ̸= 0 and g(x) ̸= 0 so the result on quotients also
goes over.
□
We can now build up some continuous functions. If p is a polynomial then it
is continuous on both R and C. To see this, ﬁrst we have by induction that zk is
continuous for all k ∈N. We also that ckzk is continuous for any constant ck.
Summing a ﬁnite number of such terms yields all polynomials so all polynomials

164
19
Analytical Patterns
are continuous. If a polynomial, q, has no zeros in the set I then we also have that
p/q is also continuous on I for any polynomial p.
There are plenty of continuous functions which are not polynomials. For example,
let
f (x) = x1/2
as a function from [0, ∞) to R. To show that it is continuous, we need to show that
xk →x =⇒x1/2
k
→x1/2.
We use case analysis: either x = 0 or x > 0. If x = 0, we have to show that
xk →0 =⇒x1/2
k
→0.
Now given ϵ > 0, there exists N such that k > N implies
|xk| < ϵ.
and, so
|x1/2
k
| < ϵ1/2.
The result follows by poly-epsilon. If x > 0, then we have some N such that for
k > N,
|xk −x| < |x|
2
and so
|xk| = |xk −x + x| > 1
2|x|.
This implies
|xk|1/2 > 1
2|x|1/2.
We then have
|x1/2
k
−x1/2| =


x1/2
k
−x1/2 x1/2
k
+ x1/2
x1/2
k
+ x1/2
 =
|xk −x|
|x1/2
k
+ x1/2|
< |xk −x|
2
|x|1/2 .
Using poly-epsilon, the result is now clear.

19.6 Continuity
165
More generally, if we take the composition of two continuous functions, we get
a continuous function. We simply pass each continuous function through the limit.
This implies that f (z) = |z| is a continuous function from C to R simply by taking
the composition of
g(x + iy) = x2 + y2
and the square root function.
19.7 Theorems About Continuous Functions
The main reason to place a restriction on a class of objects is to make them have nice
features. So what does continuity buy us? Our ﬁrst result is that continuous functions
have the property that they never jump in value. If a real-valued continuous function,
f, on the reals takes the values y0 at x0 and the value y1 at x1, then all values
between y0 and y1 are taken on [x0, x1]. This is sometimes called the Intermediate
Value Property.
More formally, we want to show
Theorem 19.1 Suppose f : [x0, x1] →R is continuous and f (x0) < y < f (x1)
then there exists x ∈(x0, x1) such that f (x) = y.
Proof We construct a convergent sequence whose limit is the required point x. In
fact, we construct two sequences. Let a0 = x0 and let b0 = y0. Now consider
c0 = 0.5(a0 + b0). If f (c0) = y we are done. If f (c0) < y, let a1 = c0, b1 = b0.
Otherwise, let a1 = a0, b1 = c0.
We now have the same situation as before with the endpoints [a1, b1]. And
b1 −a1 = 0.5(b0 −a0). We now simply repeat and stop if for j f (c j) = y. If
this never happens we have sequences (a j) and (b j) such that
b j −a j = 2−j(b0 −a0),
f (a j) < y < f (b j).
The sequence a j is increasing and bounded above by b0 so it converges to some point
x. Now
f (x) = f (lim
j a j) = lim
j
f (a j) ⩽y
since f (a j) ⩽y for all j. Now b j will also converge to x since
|b j −x| = b j −x < b j −a j = 2−n|b0 −a0|.

166
19
Analytical Patterns
So
f (x) = f (lim
j b j) = lim
j
f (b j) ⩾y,
since f (b j) > y for all j. We have proven
f (x) = y
and we are done.
□
Note that the crucial feature of f in this proof was that we could pass limits
through it which was precisely our deﬁnition of continuity.
A second important property of continuous functions is that they always have a
maximum and a minimum on closed and bounded intervals. Note that is not true
without all three of these hypotheses, for example, consider
f (x) = 1/x
on the set (0, 1). The image set is (1, ∞). At no point is a minimum value attained
and the maximum is inﬁnity. Our theorem is
Theorem 19.2 Let f : [a, b] →R be continuous then there exist x, y ∈[a, b] such
that
f (x) ⩽f (s) ⩽f (y)
for all s ∈[a, b].
Proof We can deduce the result for the minimum from that for the maximum by
considering the function −f, so it is enough to consider the maximum. We again use
a two-sequence argument. Let a0 = a, b0 = b. Now let
c0 = 0.5(a0 + b0).
We shall say that f is at least as big on [a0, c0] as on [c0, b0] if for all x ∈[c0, b0],
there is a point x′ in [a0, c0] such that
f (x) ⩽f (x′).
If this is the case we let a1 = c0, b1 = b0, otherwise we let a1 = a0, b1 = c0. In the
second case, there is a point x′ ∈[a1, b1] such that
f (x′) > f (x)

19.7 Theorems About Continuous Functions
167
for all x ∈[a0, c0]. The crucial fact is now that for each s ∈[a0, b0], there exists a
point t ∈[a1, b1] where
f (s) ⩽f (t).
If a maximum exists it must therefore be in [a1, b1].
We can now repeat. We get intervals [a j, b j] and these retain the property that for
each point in [a0, b0] there is some point in [a j, b j] where f is at least as big.
As for the intermediate value theorem, the sequences a j and b j converge to the
same point x. It is at this point where the maximum occurs. We still have to prove
this, however.
We know that for each s ∈[a, b] and j ∈N1, there exists a point s j ∈[a j, b j]
with f (s) ⩽f (s j) by our construction of the intervals [a j, b j]. This sequence s j
will also converge to x by the “sandwich theorem.” We have
f (s) ⩽f (s j)
for all j. We have
f (x) = lim f (s j) ⩾f (s).
So x is indeed a maximum for f on [a, b] as claimed.
□
Note that we did not show that the maximum is unique, and, in general, it will not
be. For example, if the function f is constant every point in [a, b] is a maximum.
An analogue of this result holds true for continuous functions on Rn. The crucial
feature of the set I above is that it is closed and bounded.
Theorem 19.3 Let E ⊂Rn be a product of intervals I j = [α j, β j] and let
f : E →R be continuous, then f has a maximum and a minimum in E.
Proof We can do the same proof as for the one-dimensional case. We simply divide
each I j into two equal sub-intervals. This divides E into 2n pieces. Given any two
pieces, one of them must have the property that f is bigger on it in the same sense as
the proof for the one dimensional case. So repeatedly comparing the 2n pieces, we
ﬁnd one which has that property compared to all the others. We now simply repeat
the exercise on that piece and get a sequences of sets Ek with Ek ⊂Ek−1 and Ek
is a product of intervals, [α j,k, β j,k], with the length of the kth coordinate interval
being 2−k(β j −α j). For every point in E, there is a point in Ek where f is at least
as big by construction.
By the same arguments as for the one-dimensional case, there exists x j such that
lim
k α j,k = x j = lim
j,k β j,k.

168
19
Analytical Patterns
The points x = (x1, x2, . . . , xn) is the limit of the sequences
(α1,k, α2,k, . . . , αn,k)
and it is the maximum for the same reasons as before.
□
Whilst we have proven the result for cuboids, the product of intervals structure
is certainly not necessary. For example, if we take any ﬁnite union of sets for which
it holds, then it will still hold; simply ﬁnd the maximum on each, and then take the
maximum on that small set of points. One can also prove the result for balls of the
form, ||x|| ⩽R, by a similar argument that is just more ﬁddly since the endpoints
are curved.
19.8 The Fundamental Theorem of Algebra
As aculminatingtheoreminthis book, weconsider theproof of thetheoremthat every
complex polynomial has a complex root: this is sometimes called the fundamental
theorem of algebra. We adapt a proof from “Proofs from the BOOK.” We ﬁrst show
a lemma sometimes called d’Alembert’s Lemma or d’Argand’s inequality.
Lemma 19.1 Suppose p is a complex polynomial. Suppose z0 is not a zero of p,
then for any ϵ > 0, there exists a point z such that
|z −z0| < ϵ and |p(z)| < |p(z0)|.
Proof Any point within ϵ of z0, can be written as
z0 + w
with |w| < ϵ. Let p be of degree d. Since p is a polynomial, we can consider the
polynomial
q(w) = p(z0 + w) −p(z0)
as a polynomial in w with z0 ﬁxed. Clearly, q(0) = 0 that is 0 is a root of q. We can
therefore write
q(w) = wq1(w)
with q1 a polynomial of one lower degree. Either q1(0) ̸= 0, or we can write
q1(w) = wq2(w). Repeating, we obtain
q(w) = wkqk,

19.8 The Fundamental Theorem of Algebra
169
where qk is of degree d −k and qk(0) ̸= 0. Note that this process must stop when
k = d, if not before, or p is identically zero.
We thus have that we can write
p(w + z0) = p(z0) + wkqk(w),
with qk(0) ̸= 0.
The idea of the ﬁnal part of the proof is to ﬁnd a direction which makes wkqk(w)
point in the opposite direction to p(z0). That is we make it a positive real multiple
of the negative of p(z0). This will be sufﬁcient since it will add to p(z0) to give a
smaller number provided its magnitude is smaller. Sufﬁciently close to w = 0, this
will be true as we have a factor of wk.
Since we can write
p(z0) = Reiθ
with R and θ real, a complex number z will be a real multiple of −p(z0) if it is of
the form
z = Sei(θ+π)
with S real.
We can write
qk(0) = Peiφ
with P, φ real and P > 0.
As a warm-up, we ﬁrst do the special case that qk is constant. We want to ﬁnd γ
such that if w = eiγ, then
(eiγ)keiφ = ei(θ+π).
We thus need
kγ + φ = θ + π
up to a multiple of 2π. We simply set
γ = 1
k (θ + π −φ),
and the qk constant case is done.
In general, of course, qk will not be constant. However, we can write
qk(w) = qk(0) + wr(w)
for a polynomial r of lower degree. We will make the term wr(w) too small to affect
our results. In particular, we know that r is continuous so |r| is bounded by some
value M on the set we are interested in. We therefore have that |wr(w)| is less than
M|w|. Take γ as in the constant case, and let w = Seiγ with S real. We then have

170
19
Analytical Patterns
p(z0 + w) = Reiθ + Sk Peikγ+iφ + wk+1r(w).
By our choice of γ we now have
p(z0 + w) = (R −PSk)eiθ + wk+1r(w).
So for S small the ﬁrst term is certainly of smaller modulus than p(z0). For the
second term, we can bound it by
MSk+1.
So
|p(z0 + w)| < |R −PSk| + MSk+1
by the triangle inequality. This equals
R −PSk + MSk+1
for S small. Since Sk+1 goes to zero faster than Sk, for S sufﬁciently small, this is
less than R = |p(z0)|, and we are done.
□
The lemma is important in that it shows that if p(z0) is non-zero then z0 is not
a local minimum of |p(z)| and therefore it is not a global minimum either. In other
words, a polynomial p has to be zero at a global minimum of |p|. So to prove that a
zero exists all we have to do is show that a global minimum of |p| exists. However,
this is easy. We can write
p(z) =
d

i=0
cizi
for some complex numbers ci with cd ̸= 0. So
cdzd = p(z) −
d−1

i=0
cizi
and
|cd||z|d ⩽|p(z)| +

d−1

i=0
cizi
 ,
⩽|p(z)| +
d−1

i=0
|ci||z|i.

19.8 The Fundamental Theorem of Algebra
171
This implies that
|p(z)| ⩾|cd||z|d −
d−1

i=0
|ci||z|i.
The highest power |z|d will dominate on the right side for |z| large. So as |z| goes
to inﬁnity, the right hand side will go to inﬁnity. Hence so will |p(z)|. In particular,
we can ﬁnd R such that everywhere on the circle |z| = R, |p(z)| > |p(0)|. Since p
is continuous on the set |z| ⩽R, then, as we saw above, it has a minimum in it. The
minimum is not on the boundary since everywhere on the boundary |p(z)| is bigger
than |p(0)|. At this minimum, z0, we must have p(z0) = 0, since otherwise it would
not be a minimum by the lemma. We are done.
19.9 Further Reading
Analysis is a huge ﬁeld and there are myriads of books. My favourite introductory
book is Byrant’s “Yet Another Introduction to Analysis.” This book is anything
but yet another one on the topic! The author works hard to motivate everything he
does and to keep everything clear and elementary. He keeps the topic rigorous but
also concrete. As a follow-up, I recommend Binmore’s “Mathematical Analysis: A
Straightforward Approach” which again has an emphasis on simplicity and clarity.
19.10 Problems
Exercise 19.1 Prove or disprove that the following sequences converge. If they
converge, identify the limit.
• xk = k,
• xk = 1 −1
k .
• xk = 1+k
2+k2 .
• xk = √k + 1 −
√
k.
Exercise 19.2 Suppose f : R2 →R, is continuous on the set
E = {1 ⩽|(x, y)| ⩽2},
show that f has a maximum and minimum on E. Find an example where these occur
on the boundary.

172
19
Analytical Patterns
Exercise 19.3 A function is said to have the intermediate value property on R if
f : R →R, and if a < b, f (a) < x < f (b) implies that there exists c ∈(a, b)
with f (c) = b. Let a function g have value 0 at 0 and value
g(x) = sin
 1
x

for x ̸= 0. Does g have the intermediate value property? Is g continuous?
Exercise 19.4 Does each of the following series converge? Prove or disprove.
• xk =
1
1+k .
• xk =
1
1+k2 .
• xk =
1
1+k3 .

Chapter 20
Counterexamples
20.1 Introduction
Developing new mathematics is as much about disproving conjectures as it is about
proving theorems. The standard way to disprove a conjecture is to construct an
example satisfying the proposed hypotheses but not the conclusion. Such an example
is called a counterexample. The process of mathematics is then that the conjecture’s
hypotheses are modiﬁed to outlaw the counterexamples and then the mathematicians
again try to prove or disprove. If the counterexample is in the spirit of the conjecture,
they may well conclude that the direction is wrong and interest moves on to other
topics. Alternatively, someone may well feel that there still is a positive result to be
found, and it is simply a question of working out the correct hypotheses to rule out
unnatural examples.
The big difference between proving theorems and constructing counterexamples
is speciﬁcity. A counterexample is just a single solitary example that rules out a
conjecture being true. This contrasts with proving a theorem where we are trying to
prove many cases at once.
Knowing a good collection of examples and counterexamples is an important part
of being a mathematician. Any ideas can be quickly tested against this collection
and modiﬁed appropriately or dropped. In this chapter, we present some elementary
examples that show that more hypotheses than one might guess are necessary to
prove some basic results.
20.2 Matrix Algebra
Matrices are an important part of linear algebra and provide a good example of a
collection of objects which have some of the properties of real numbers but not all
of them. Recall that if we have two by two matrices then
© Springer International Publishing Switzerland 2015
M. Joshi, Proof Patterns, DOI 10.1007/978-3-319-16250-8_20
173

174
20
Counterexamples
a11 a12
a21 a22

·
b11 b12
b21 b22

=
a11b11 + a12b21 a11b12 + a12b22
a21b11 + a22b21 a21b12 + a22b22

.
One can easily conjecture that matrix multiplication has the same properties as
multiplication of real numbers. We will construct some counterexamples to show
that some of them do not hold.
To see that matrix multiplication is not commutative, in general, it is enough to
construct one counterexample. So we have
Conjecture 20.1 If A and B are square matrices then AB = B A.
Disproof by counterexample
1 1
1 1
 0 1
0 0

=
0 1
0 1

;
0 1
0 0
 1 1
1 1

=
1 1
0 0

.
In this case, we see that the product of the two matrices depends on order and
thus matrix multiplication does not commute in general. Note that it is still possible
for a given pair of matrices A and B that AB = B A holds.
Now consider the question of the existence of inverses. To invert a matrix, A, we
need to ﬁnd a matrix B such that
AB = I
where I is the identity matrix:
I =
1 0
0 1

.
Conjecture 20.2 If A is a square matrix then there exist a matrix, B, such that
AB = I.
Disproof by counterexample
Let
A =
1 0
0 0

.
We multiply by a general matrix
1 0
0 0
 a b
c d

=
a b
0 0

.
Whatever values we take for a, b, c and d, we do not obtain I. We conclude that A
is not invertible. Note that in order to show that the particular example worked in

20.2 Matrix Algebra
175
this case, we did need to consider all possible inverses to show that none of them
worked.
In ordinary arithmetic, the square of a non-zero number is never zero. What about
matrices?
Conjecture 20.3 If A is a non-zero square matrix then A2 ̸= 0.
Disproof by counterexample
0 1
0 0
2
=
0 0
0 0

.
20.3 Smooth Functions
In this section, we present some counterexamples which show that some natural
conjectures about smooth functions are, in fact, false.
Conjecture 20.4 Suppose f : R →R is inﬁnitely differentiable and deﬁnes a
bijection and so has an inverse g. We conjecture that g must also be inﬁnitely
differentiable.
Disproof by counterexample
Let f be the function with
f (x) = x3.
The inverse function is then given by
g(x) = x1/3.
The function is not differentiable at x = 0 and for x ̸= 0, we have
g(x) = 1
3x−2/3
which blows up at 0.
Conjecture 20.5 Suppose f : R →R is inﬁnitely differentiable and deﬁnes a
bijection. We conjecture that we must have for all x that f ′(x) ̸= 0.
Disproof by counterexample
Again, let f be the function with
f (x) = x3.
We have f ′(0) = 0.

176
20
Counterexamples
An important property of continuous functions is the intermediate value property.
This says that if a function takes the value f (a) at a and the value f (b) at b then it
takes all the values in between in the interval (a, b). More formally, it says that if
a < b and f (a) < y < f (b) or f (a) > y > f (b) then there exists c ∈(a, b) such
that
f (c) = y.
It is a theorem that continuous functions have this property (Theorem 19.1). Indeed,
one might take the property as a deﬁnition of continuity rather than the standard one.
So the question becomes “Is every function that has the intermediate value property
continuous?”
Conjecture 20.6 Let f : R →R have the intermediate value property for every
interval [a, b] ⊂R, then f is continuous.
Disproof by counterexample
Let
f (x) = sin(1/x)
for x ̸= 0 and 0 at x = 0. The function f is a composition of two continuous
functions away from 0 and so is continuous except at 0.
However, it has very odd behaviour at zero. In particular, if we take a sequence
xn such that xn tends to zero, a continuous function should have
f (xn) →f (0) = 0.
However, if we let
xn =
π
2 + 2πn
−1
,
we have f (xn) = 1. We can construct similar sequences converging to any value in
[−1, 1].
However, f does have the intermediate value property. To see this, ﬁrst observe
that if 0 is not in an interval [a, b] we are studying a continuous function so all its
properties hold, so we need only consider the case 0 ∈[a, b]. We take b > 0 for
simplicity. However, a very similar argument works for intervals [a, 0]. The function
sin takes all values between −1 and 1 on any interval
[2π j, 2π( j + 1)]
for 0 ̸= j ∈N and never takes any value outside [−1, 1]. This means that f takes
these values on any interval
[1/(2π( j + 1), 1/(2π j)].

20.3 Smooth Functions
177
For j sufﬁciently large, this will be within [a, b] and so there must be a point in
the interval for each value between −1 and 1 which is sufﬁcient given that f (a) and
f (b) must also be in that range.
20.4 Sequences
Much of analysis is dominated by questions involving interchanges of limiting
operations. In other words, if we have two parameters does the order of taking them
to limits matter? The simplest context in which to study these questions is sequences.
A two-dimensional sequence is a map from N × N to R. If we ﬁx either coordinate,
we get an ordinary sequence.
Conjecture 20.7 Suppose we have a two-dimensional sequence xm,n such that for
all m, n,
lim
m→∞xm,n and lim
n→∞xm,n
exist. Suppose also that
lim
n→∞lim
m→∞xm,n and
lim
m→∞lim
n→∞xm,n
exist. We conjecture that the last two limits are equal.
Disproof by counterexample
Let
xm,n =
m
m + n
for m, n > 0. We then have
lim
m→∞xm,n = lim
m→∞
m
m + n = lim
m→∞
1
1 + n/m = 1,
but
lim
n→∞xm,n = lim
n→∞
m
m + n = 0.
So the iterated limits are 1 and 0 and do not agree.
A related example regards the limits of integrals. Can we always take a limit
through an integral?
Conjecture 20.8 Suppose fn : [0, 1] →R is continuous for each n, and suppose
for all x ∈[0, 1], fn(x) →f (x) with f continuous. We conjecture that
lim
n→∞
1

0
fn(x)dx =
1

0
f (x)dx.

178
20
Counterexamples
Note that we have not said what sort of integral this is, e.g. Lebesgue or Riemann.
However, for a continuous function on a ﬁnite interval all reasonable integrals give
the same answer.
Disproof by counterexample
Let
fn(x) =
⎧
⎪⎨
⎪⎩
n2x for x ∈[0, 1/n],
n2(2/n −x) for x ∈(1/n, 2/n],
0 for x > 2/n.
(20.4.1)
A direct computation yields that
1

0
fn(x)dx = 1
for every n. However, for any given x the value of fn(x) is eventually zero as n goes
to inﬁnity. So the limit function is 0 everywhere and has 0 integral.
20.5 Ordinary Differential Equations
It is normal in the study of ordinary differential equations to talk of “the solution”
as if a solution always exists and is unique. We will see in this section that this is not
always the case.
Conjecture 20.9 Suppose that f : R →R is a continuous function, then there is a
unique function y from R+ to R such that y(0) = 0 and
dy
dx = f (y).
Disproof by counterexample
Let
f (z) = 3z2/3.
An easy solution is simply y(x) = 0 for all x. However, there is also another solution.
We let
y(x) = x3.
We then certainly have that y(0) = 0 and that
dy
dx = 3x2 = f (y).

20.5 Ordinary Differential Equations
179
This example shows that we need extra hypotheses to get a positive result
regarding uniqueness. In fact, there is a standard additional condition which does
lead to uniqueness. Generally, f is assumed to be assumed Lipschitz continuous that
is there exists a constant C such that for all s and t
| f (s) −f (t)| ⩽C|s −t|.
We do not present the proof here since we are focusing on counterexamples.
20.6 Characterisation
It is worth mentioning that counterexamples are not the only way to show that
statements are not universally valid. An alternate approach is show that the desired
property is equivalent to some simpler property. For example, if we take two by two
matrices, we can use the determinant to characterise invertibility.
First, if the determinant is non-zero, there is a simple formula for the inverse.
Let
A =
a b
c d

.
The determinant of A is deﬁned by
det(A) = ad −bc.
It follows from direct computation that if det(A) is non-zero then
A−1 =
1
det A
 d −b
−c a

is both a left and right inverse that is
A−1A = AA−1 = I.
So we have that if det(A) is non-zero then A is invertible.
The next question is can a matrix with zero determinant be invertible? We show
that it cannot. Let A and B be two by two matrices, then
det(AB) = det(A) det(B).
This can be checked by direct computation. It is also true that
det(I) = 1.

180
20
Counterexamples
So if
AB = I
then
det(A) det(B) = 1.
So det(A) is non-zero.
We have shown that a matrix is invertible if and only if its determinant is non-
zero. We therefore immediately see that there are many non-invertible matrices. For
example, if a ̸= 0 and we set
d = bc/a,
for any b and c.
Although we have only studied two by two matrices in this section, similar
results hold for general square matrices. It is simply a question of obtaining the
right deﬁnition for a determinant.
20.7 Problems
Exercise 20.1 Find matrices A and B which are distinct and AB = B A ̸= 0.
Exercise 20.2 Find a matrix with all entries non-zero which is not invertible.
Exercise 20.3 Do there exist square matrices, A, with A2 = 0 and all entries non-
zero?
Exercise 20.4 If A is a square matrix and there exists B such that AB = I, must
there exist C such that
C A = I,
and if C does exist, must we have C = B?
Exercise 20.5 Which of the following functions are Lipschitz continuous?
• f (x) = x2/3.
• f (x) = x.
Exercise 20.6 Suppose f : (0, 1) →R is continuous. Must there be a global
maximum in (0, 1)? i.e. does there always exist x such f (y) ⩽f (x) for all y ∈
(0, 1)?

Appendix A
Glossary
Inthisappendix,wedeﬁnesomecommontermsandestablishnotationforthereader’s
convenience.
First, we deﬁne our number systems.
• The integers, Z, are {. . . , −3, −2, −1, 0, 1, 2, 3, . . . }.
• The natural numbers, N, are {0, 1, 2, 3, . . . }. They include zero. They are the
non-negative integers.
• The counting numbers, N1, are {1, 2, 3, . . . }. They do not include zero. They are
also known as the positive integers.
• The real numbers will be denoted R.
• The complex numbers will be denoted C.
Next, we deﬁne terminologies for mappings.
• The domain of a mapping from X to Y is X. The set Y is sometimes called the
codomain.
• An injection is a map, f, between sets X and Y such that
x1 ̸= x2 =⇒f (x1) ̸= f (x2).
Equivalently,
f (x1) = f (x2) =⇒x1 = x2.
The mapping f is said to be injective or one-one.
• The range of a mapping from X to Y is the set
{ f (x), x ∈X}.
• A surjection is a map f between sets X and Y such that the range of X is Y. Such
a map is said to be surjective or onto.
© Springer International Publishing Switzerland 2015
M. Joshi, Proof Patterns, DOI 10.1007/978-3-319-16250-8
181

182
Appendix A: Glossary
We now deﬁne some terminology for sequences.
• A sequence is a mapping from N1 to a set Y. The set Y is generally R or
C. The mapping is generally written as (x j) or x1, x2, x3, . . . rather than as
f (1), f (2), f (3), . . .
• A sequence, (x j), is bounded if there exists some K ∈R such that
|x j| ≤K
for all j.
• A sequence, (x j), is increasing if for all j
x j ≤x j+1.
• A series is a sequence of partial sums of a sequence. Thus if (x j) is a sequence,
we have the series (Sn) deﬁned by
Sn =
n

j=1
x j.

Appendix B
Equivalence Relations
In this appendix we recall the basics of equivalence relations. First, recall that a
relation on a set X is a subset, R, of X × X. We say that x relates to y if
(x, y) ∈R.
We shall write this as
x ∼y.
Such a relation is said to be reﬂexive if every element relates to itself so
x ∼x, ∀x ∈X.
It is symmetric if
x ∼y =⇒y ∼x.
In others words, (x, y) ∈R implies that (y, x) ∈R. It is transitive if
x ∼y, y ∼z =⇒x ∼z.
Given an element x of X we deﬁne the equivalence class of x written as [x] to be the
subset of X given by
{y ∈x | x ∼y}.
An important property of equivalence classes is that
[x] = [y] ⇐⇒x ∼y.
First, we show that x ∼y implies [x] = [y]. If z ∈[x] then x ∼z so z ∼x
and x ∼y, which implies z ∼y by transitivity. We have y ∼z by symmetry, and
© Springer International Publishing Switzerland 2015
M. Joshi, Proof Patterns, DOI 10.1007/978-3-319-16250-8
183

184
Appendix B: Equivalence Relations
we have shown z ∈[y]. This means that [x] ⊆[y]. However, swapping x and y
everywhere also demonstrates [y] ⊆[x], and so by symmetry
[x] = [y].
For the opposite direction, if [x] = [y], then y ∈[x] since y ∈[y] by reﬂexivity.
Saying y ∈[x] is by deﬁnition x ∼y and we are done.
Equivalence relations are important because they induce partitions of X. A par-
tition of X is a decomposition into smaller sets X j such that every element of X is
in precisely one subset X j. So
X =

X j,
and for j ̸= k
X j ∩Xk = ∅.
We do not make any particular requirement on how many sets X j there are.
Our main result is
Theorem B.1 If R is an equivalence relation on X then the equivalence classes
induced by R deﬁne a partition of X.
Proof First, we have assumed that R is reﬂexive so every x is in some equivalence
class, and the union of all the classes is indeed X. Second, we need to show that if
two equivalence classes have non-empty intersection then they are equal. If
z ∈[x] ∩[y]
then
x ∼z, y ∼z.
By symmetry, z ∼y. By transitivity, it then follows that x ∼y. We showed above
that this implies
[x] = [y]
and we are done.
⊓⊔
Alternatively, given a partition, X j, we can deﬁne a relation by
x ∼y ⇐⇒∃k, x, y ∈Xk.
That is x relates to y if and only if they are in the same subset when the set is
partitioned.

References
1. Aigner M, Ziegler GM (2012) Proofs from the book, 4th edn. Springer, Berlin
2. Binmore K (1983) Mathematical analysis: a straight-forward approach, 2nd edn. Cambridge
University Press, Cambridge
3. Bryant V (1990) Yet another introduction to analysis. Cambridge University Press, Cambridge
4. Bold B (1982) Famous problems of geometry and how to solve them. Dover, New York
5. Eccles PJ (1997) An introduction to mathematical reasoning. Cambridge University Press,
Cambridge
6. Enderton HB (1977) Elements of set theory. Academic Press, New York
7. Oeschslin W (2010) Elements of Euclid by Byrne. Taschen, Koln
8. Golomb SW (1956) A combinatorial proof of Fermat’s “Little” theorem. Am Math Monthly
63(10):718. http://www.jstor.org/stable/2309563
9. Houston K (2009) How to think like a mathematician: a companion to undergraduate mathe-
matics. Cambridge University Press, Cambridge
10. Gura E-Y, Maschler MB (2008) Insights into game theory. Cambridge University Press, Cam-
bridge
11. Halmos PR (2014) Naive set theory, 2nd edn. Springer, New York
12. Velleman DJ (2006) How to prove it: a structured approach, 2nd edn. Cambridge University
Press, Cambridge
13. Wilson R (2002) Four colours sufﬁce: how the map problem was solved. Allen Lane Science,
London
© Springer International Publishing Switzerland 2015
M. Joshi, Proof Patterns, DOI 10.1007/978-3-319-16250-8
185

Index
A
Abalone, 147
Addition modulo k, 60
Additive subgroup, 43
Aleph, 114
Algebraic number, 65, 70, 116
Algorithm, 21, 28
Algorithmic construction, 25, 28, 143
Analysis, 151
Appel
Kenneth, 106
Arbitrary closeness, 153
Associative, 59, 60
Associativity, 84
B
Backwards strategy, 149
Base, 21
Basis, 55, 67
Bijection, 55, 58, 60, 68, 109
Binary number, 114
Binomial coefﬁcient, 4
Binomial theorem, 5
Bold
Benjamin, 80
Bounded, 120, 182
C
Calculus, 151
Canonical, 90
Cardinality, 58, 59, 61, 109, 121
Cartesian product, 60, 82
Case analysis, 105, 164
Characterisation, 179
Chess, 147, 149
Chess-board, 53
Classic game, 147
Classiﬁcation
proof by, 97
Closed, 44, 122
Closure, 46
Codomain, 181
Commutative, 59, 60, 84
Commutative group, 59, 60
Complete induction, 1, 28, 101
proof of, 3
Complex number, 65, 81, 115, 116
Component, 120, 121
Composite number, 2
Composition of continuous functions, 165
Connected, 106, 119, 130
Continuous, 58
Continuous function, 162, 165, 167
Contradiction
proof by, 33–41, 147
Contrapositive, 101, 162
proof by, 33–41
Convergence by domination, 39
Convergent sequence, 163
Converse, 40
Convex, 44, 120, 129
Convex hull, 46
Convex polyhedron, 129
Convex set
connectedness of, 119
Countable, 115
Counterexample, 133, 173
Counting number, vi
Crossing, 122
Cube, 127
Cube root, 50, 79
Cube root of two, 49, 74
© Springer International Publishing Switzerland 2015
M. Joshi, Proof Patterns, DOI 10.1007/978-3-319-16250-8
187

188
Index
Cubic map, 107, 138, 141
Cut, 91
D
D’Alembert’s lemma, 168
D’Argand’s inequality, 168
Decimal expansion, 71
Decimal number, 19, 112
Dedekind cut, 92
Determinant, 179
Diagonal trick, 112, 113
Difference of invariants, 53, 129
Dimension, 54, 65, 67, 68
Discharging, 137, 141
Disconnected, 133
Divergence, 161
Divergent sequence, 109
Divisibility, 63
Division
ruler and compass construction, 77
Division Lemma, 25
Dodecahedron, 127, 139
Domain, 181
Domination, 158, 160
Domino, 9, 53
Double counting, 6, 11, 138
Doughnut, 134, 141
Duplicating the cube, 73, 79
E
e
irrationality of, 38
Edge, 15, 106, 127, 131, 137
Equal areas, 16
Equivalence class, 84, 121
Equivalence relation, 14, 81, 121, 183
Equivalence-extension, 81
Euclid’s Elements, 73
Euclid’s Lemma, 29
Euclidean algorithm, 26
Euclidean space, 134
Euler characteristic, 119, 127, 133, 137
F
Face, 15, 127, 137, 141
Fermat equation, 108
Fermat’s Last theorem, 101, 105
Fermat’s little theorem, 14
Field, 48, 65
Finite, 59
Formal equivalence, vi
Four colours sufﬁce, vi
Four-Colour problem, vi
Four-Colour theorem, 106, 138, 140
Fundamental theorem of algebra, 51, 168
G
Gale–Shapley algorithm, 144
Game, 148
Game theory, 147
Generated, 46
Generation, 71
Genus, 134
Gluing, 133
Gluing of polyhedra, 128
Go, 147
Golomb, Solomon, 15
Greek, 73
Groups
classiﬁcation of, 61
H
Haken
Wolfgang, 106
Harmonic series, 161
Hexagon, 141
Highest common factor, 26
Hypotenuse, 16
I
Icosahedron, 15, 127
Identity, 60
Identity element, 59
Increasing, 182
Induction, 1, 26, 68, 101, 131, 133, 149
proof of, 3
Inductive hypothesis, 2, 131, 133
Inevitable conﬁgurations, 141
Inﬁnite, 59, 110
Inﬁnite descent, 101
Inﬁnite set, 112
Inﬁnity, 109
Injection, 110, 114, 181
Injective, 181
Integer numbers
cardinality of, 109
Integers
construction of, 81
Integer-valued continuous function, 121
Intermediate value property, 165, 176
Intermediate value theorem, 167
Intersection, 120

Index
189
Intersection-enclosure, 43, 70
Inverse, 59
Invertible matrix, 179
Irrational number, 21, 22, 34
sum with rational, 37
Irreducible, 9
Isomorphic, 60
Isomorphism, 62
J
Jordan closed-curve theorem, 119, 122, 132
L
Lattice, 147
Law of the excluded middle, 40
Least upper bound, 89, 92
existence of, 93
Lebesgue integral, 178
Limit, 109, 163
deﬁnition of, 152
Linear algebra, 54, 65
Linear dependence, 65
Linear map, 55
Linear span, 46
Linearity, 58
Linearly dependent, 66
Linearly equivalent, 55
Linearly independent, 67
Lion, 150
Liouville’s constant, 71
Loop, 7, 132, 134
Lossless compression, 21
M
Map, 106, 107, 137, 138
Matching problem, 143
Mate, 143
Maximum, 166
Minimum, 166
Monotone sequences
convergence of, 93
Multiplication
ruler and compass construction, 77
N
Natural, 90
Natural numbers, 81
Negative numbers, 85
Network, 130, 137
Nim, 147, 150
North pole, 137
Noughts and crosses, 147, 150
O
Octahedron, 127
One-one, 181
Onto, 181
Open, 51
Optimal strategy, 149
Optimality, 143
Orbit, 14
Order, 61
Ordinal, 109
P
Pairing, 143
Pairwise disjoint, 121
Parallel
construction of, 74
Pascal’s identity, 5
Pentagon, 141
Permutation, 68
Perpendicular
construction of, 74
Pigeonhole principle, 19–23, 62
Platonic solid, 15
Poly-epsilon pattern, 154, 164
Polygon, 7, 135
Polygonal path, 119, 122, 124
Polygonally connected, 130
Polygonally continuous, 121
Polyhedron, 133, 137
convex, 119
Polynomial, 65, 70, 163, 168
Power set, 92, 114
Prime decomposition
proof of, 2
uniqueness of, 30, 97
Prime factor, 36
Prime number, 2, 14, 35
cardinality of, 110
non-ﬁniteness of, 36
Proof by observation, 4
Proof patterns, v
Proofs from the BOOK, 168
Pythagoras’s equation, 97
Pythagoras’s theorem, 16, 77, 98
Pythagorean triple, 97
R
Rational number, 19

190
Index
Rational numbers
cardinality of, 109, 111
construction of, 85, 86
inadequacy of, 88
Rational polynomial, 116
Ray, 122
Real numbers, 81
cardinality of, 109
construction of, 90
Rearrangement, 56
Reducible, 9
Reﬂexive, 183
Regular polyhedron, 127, 135
Relation, 148, 183
Riemann integral, 178
Ring, 134, 136
Room-mate problem, 145
Roots
irrationality of, 35
Root two, 74
construction of, 77
irrationality of, 34
Ruler, 73
Ruler and compass construction, 73
S
Sandwich theorem, 167
Sandwiching, 158
Schröder–Bernstein theorem, 110, 116
Second player never wins, 149
Self intersection, 122
Sequence, 151, 177, 182
two-dimensional, 177
Series, 159, 182
Set of all subsets, 92
Sigma algebra, 44
Six-Colour theorem, 139
South pole, 137
Span, 67
Spanning set, 67
Speciﬁc generality, 105
Sphere, 133, 134, 137
Square root, 48, 70, 165
existence of, 94
Squares
cardinality of, 110
Squaring the circle, 80
Stable, 143
Stable pairing, 143
Steinitz exchange lemma, 68
Stereographic projection, 130
Sub-ﬁeld, 48
Supremum, 89
Surface, 134
Surgery, 127
Surjection, 181
Surjective, 181
Symmetric, 183
T
Taylor
Richard, 105
Termination, 148
Tetrahedron, 127
Thurston
William, 137
Tic-tac-toe, 148
Topology, 58, 119, 133
Torus, 134, 141
Transcendental number, 65, 71, 80, 115, 116
Transitive, 183
Triangle, 15, 131
Triangle inequality, 152
Triangulation
of polygons, 7
Trimino, 9, 53
Trisection of an angle, 80
U
Uncountable, 114
Union, 120
Uniqueness, 144
V
Vandermonde’s identity, 13
Vector sub-space, 44, 54
Vertex, 15, 106, 119, 127, 131, 137
W
Well ordering, 26
of natural numbers, 26
of the natural numbers, 3
Well-ordering principle, 25
Wiles
Andrew, 105
Z
Zugzwang, 149

