Alessandro Antonucci · Laurence Cholvy
Odile Papini (Eds.)
 123
LNAI 10369
14th European Conference, ECSQARU 2017
Lugano, Switzerland, July 10–14, 2017
Proceedings
Symbolic and Quantitative
Approaches to Reasoning
with Uncertainty

Lecture Notes in Artiﬁcial Intelligence
10369
Subseries of Lecture Notes in Computer Science
LNAI Series Editors
Randy Goebel
University of Alberta, Edmonton, Canada
Yuzuru Tanaka
Hokkaido University, Sapporo, Japan
Wolfgang Wahlster
DFKI and Saarland University, Saarbrücken, Germany
LNAI Founding Series Editor
Joerg Siekmann
DFKI and Saarland University, Saarbrücken, Germany

More information about this series at http://www.springer.com/series/1244

Alessandro Antonucci
• Laurence Cholvy
Odile Papini (Eds.)
Symbolic and Quantitative
Approaches to Reasoning
with Uncertainty
14th European Conference, ECSQARU 2017
Lugano, Switzerland, July 10–14, 2017
Proceedings
123

Editors
Alessandro Antonucci
IDSIA
Lugano
Switzerland
Laurence Cholvy
ONERA
Toulouse
France
Odile Papini
Aix-Marseille University
Marseille
France
ISSN 0302-9743
ISSN 1611-3349
(electronic)
Lecture Notes in Artiﬁcial Intelligence
ISBN 978-3-319-61580-6
ISBN 978-3-319-61581-3
(eBook)
DOI 10.1007/978-3-319-61581-3
Library of Congress Control Number: 2017943848
LNCS Sublibrary: SL7 – Artiﬁcial Intelligence
© Springer International Publishing AG 2017
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part of the
material is concerned, speciﬁcally the rights of translation, reprinting, reuse of illustrations, recitation,
broadcasting, reproduction on microﬁlms or in any other physical way, and transmission or information
storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar methodology now
known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication
does not imply, even in the absence of a speciﬁc statement, that such names are exempt from the relevant
protective laws and regulations and therefore free for general use.
The publisher, the authors and the editors are safe to assume that the advice and information in this book are
believed to be true and accurate at the date of publication. Neither the publisher nor the authors or the editors
give a warranty, express or implied, with respect to the material contained herein or for any errors or
omissions that may have been made. The publisher remains neutral with regard to jurisdictional claims in
published maps and institutional afﬁliations.
Printed on acid-free paper
This Springer imprint is published by Springer Nature
The registered company is Springer International Publishing AG
The registered company address is: Gewerbestrasse 11, 6330 Cham, Switzerland

Preface
The biennal ECSQARU conference is a major forum for advances in the theory and
practice of reasoning under uncertainty. Contributions are provided by researchers in
advancing the state of the art and practitioners using uncertainty techniques in appli-
cations. The scope of the conference includes, but is not limited to, fundamental and
representation issues, reasoning, and decision-making in both qualitative and quanti-
tative paradigms.
Previous ECSQARU conferences were held in Compiègne (2015), Utrecht (2013),
Belfast (2011), Verona (2009), Hammamet (2007), Barcelona (2005), Aalborg (2003),
Toulouse (2001), London (1999), Bonn (1997), Fribourg (1995), Granada (1993), and
Marseille (1991).
The 14th European Conference on Symbolic and Quantitative Approaches to
Reasoning with Uncertainty (ECSQARU 2017) was held in Lugano, Switzerland,
during July 10–14, 2017. The event was co-located with the 10th International Sym-
posium on Imprecise Probability: Theories and Applications (ISIPTA 2017).
A young researcher award granted by Springer for excellent research in the area of
symbolic and quantitative approaches to reasoning with uncertainty was assigned to
Nico Potyka.
The papers in this volume were selected from 63 submissions, after a strict
single-blind review process by the members of the Program Committee. In addition, the
volume contains the abstracts of ﬁve invited talks by outstanding researchers in the
ﬁeld: Leila Amgoud, Alessio Benavoli, Jim Berger, Didier Dubois, and Eyke
Hüllermeier.
We would like to thank all the members of the Program Committee and the addi-
tional reviewers for their timely and valuable reviews. We also thank the members
of the Organizing Committee for their work and contribution to the success of the
conference.
We gratefully acknowledge operational support from IDSIA (Istituto Dalle Molle di
Studi sull’Intelligenza Artiﬁciale), USI (Università della Svizzera Italiana), and SUPSI
(Scuola Universitaria Professionale della Svizzera Italiana) as well as ﬁnancial support
from ONERA.
July 2017
Alessandro Antonucci
Laurence Cholvy
Odile Papini

Organization
Executive Committee
Conference Chairs
Alessandro Antonucci
IDSIA, Switzerland
Laurence Cholvy
ONERA, France
Odile Papini
Aix-Marseille University, France
Organizing Committee
Alessandro Antonucci
IDSIA, Switzerland
Giorgio Corani
IDSIA, Switzerland
Program Committee
Leila Amgoud
IRIT, France
Nahla Ben Amor
LARODEC, Tunisia
Salem Benferhat
CRIL, France
Concha Bielza
Technical University of Madrid, Spain
Isabelle Bloch
ENST, France
Claudette Cayrol
IRIT, France
Giulianella Coletti
University of Perugia, Italy
Giorgio Corani
IDSIA, Switzerland
Inés Couso
University of Oviedo, Spain
Fabio G. Cozman
University of São Paulo, Brazil
Fabio Cuzzolin
Oxford Brookes University, UK
Luis De Campos
University of Granada, Spain
Thierry Denœux
UTC, France
Sébastien Destercke
UTC, France
Didier Dubois
IRIT, France
Florence Dupin
de Saint-Cyr
IRIT, France
Zied Elouedi
LARODEC, Tunisia
Patricia Everaere
University of Lille 1, France
Alessandro Facchini
IDSIA, Switzerland
Hélène Fargier
IRIT, France
Laurent Garcia
University of Angers, France
Laura Giordano
University of Eastern Piedmont, Italy
Lluis Godo
CSIC-IIIA, Spain
Anthony Hunter
University College London, UK
Katsumi Inoue
National Institute of Informatics, Japan
Souhila Kaci
LIRMM, France

Gabriele Kern-Isberner
TU Dortmund University, Germany
Sébastien Konieczny
CRIL, France
Jérôme Lang
LAMSADE, France
Florence Le Ber
ENGEES, France
Philippe Leray
University of Nantes, France
Churn-Jung Liau
Academia Sinica, Taiwan
Weiru Liu
Queen’s University Belfast, UK
Peter Lucas
Radboud University Nijmegen, The Netherlands
Francesca Mangili
IDSIA, Switzerland
Pierre Marquis
University of Artois, France
Maria Vanina Martinez
UNS, Argentina
Andrés Masegosa
NTNU, Norway
David Mercier
University of Artois, France
Enrique Miranda
University of Oviedo, Spain
Serafín Moral
University of Granada, Spain
Farid Nouioua
LSIS, France
Jose M. Peña
Linköping University, Sweden
Davide Petturiti
University of Perugia, Italy
Henri Prade
IRIT, France
Silja Renooij
Utrecht University, The Netherlands
Karim Tabia
CRIL, France
Choh Man Teng
IHMC, USA
Matthias Troffaes
Durham University, UK
Barbara Vantaggi
Sapienza University of Rome, Italy
Linda Van der Gaag
Utrecht University, The Netherlands
Leon van der Torre
University of Luxembourg, Luxembourg
Jiří Vomlel
UTIA, Czech Republic
Renata Wassermann
University of São Paulo, Brazil
Éric Würbel
LSIS, France
Additional Reviewers
Jérôme Delobelle
CRIL, France
Eduardo Fermé
University of Madeira, Portugal
Marcelo Finger
University of São Paulo, Brazil
Tommaso Flaminio
University of Insubria, Italy
Diogo Patrão
A.C. Camargo Cancer Center, Brazil
Martin Plajner
UTIA, Czech Republic
Ahmed Samet
IRISA, France
Nicolas Schwind
AIST, Japan
Gerardo. I. Simari
UNS, Argentina
Che-Ping Su
University of Melbourne, Australia
Sara Ugolini
University of Siena, Italy
Srdjan Vesic
CRIL, France
Chunlai Zhou
Renmin University of China, China
VIII
Organization

Sponsoring Institutions
Organization
IX

Invited Talks

Evaluation Methods of Arguments:
Current Trends and Challenges
Leila Amgoud
IRIT – CNRS, Toulouse, France
Argumentation is a reasoning process based on the justiﬁcation of conclusions by
arguments. Due to its explanatory power, it has become a hot topic in Artiﬁcial
Intelligence. It is used for making decisions under uncertainty, learning rules, modeling
different types of dialogs, and more importantly for reasoning about inconsistent
information. Hence, an argument’s conclusion may have different natures: a statement
that is true or false, an action to do, a goal to pursue, etc. Furthermore, it has generally
an intrinsic strength, which may represent different issues (the certainty degree of its
reason, the importance of the value it promotes if any, the reliability of its source, …).
Whatever its intrinsic strength (strong or weak), an argument may be weakened by
other arguments (called attackers), and may be strengthened by others (called sup-
porters). The overall acceptability of arguments needs then to be evaluated. Several
evaluation methods, called semantics, were proposed for that purpose. In this talk, we
show that they can be partitioned into three classes (extension semantics, gradual
semantics, ranking semantics), which answer respectively to following questions:
1. What are the coalitions of arguments?
2. What is the overall strength of an argument?
3. How arguments can be rank-ordered from the most to the least acceptable ones?
We analyze the three classes against a set of rationality principles, and show that
extension semantics are fundamentally different from the two other classes. This means
that in concrete applications, they lead to different results. Namely, in case of reasoning
with inconsistent information, extension semantics follow the same line of research as
well-known syntactic approaches for handling inconsistency, while the two other
classes lead to novel and powerful ranking logics. We argue that there is no universal
evaluation method. The choice of a suitable method depends on the application at hand.
Finally, we point out some challenges ahead.

Bayes + Hilbert = Quantum Mechanics
Alessio Benavoli
IDSIA, Lugano, Switzerland
Quantum mechanics (QM) is based on four main axioms, which were derived after a
long process of trial and error. The motivations for the axioms are not always clear and
even to experts the basic axioms of QM often appear counter-intuitive. In a recent
paper, we have shown that:
– It
is
possible
to
derive
quantum
mechanics
from
a
single
principle
of
self-consistency or, in other words, that QM laws of Nature are logically consistent;
– QM is just the Bayesian theory generalised to the complex Hilbert space.
In particular, we have considered the problem of gambling on a quantum experiment
and enforced rational behaviour by a few rules. These rules yield, in the classical case,
the Bayesian theory of probability via duality theorems. In our quantum setting, they
yield the Bayesian theory generalised to the space of Hermitian matrices. This very
theory is QM: in fact, we have derived all its four postulates from the generalised
Bayesian theory. This implies that QM is self-consistent. It also leads us to reinterpret
the main operations in quantum mechanics as probability rules: Bayes’ rule (mea-
surement), marginalisation (partial tracing), independence (tensor product). To say it
with a slogan, we have obtained that quantum mechanics is the Bayesian theory in the
complex numbers.

Encounters with Imprecise Probabilities
Jim Berger
Duke University, Durham, USA
Although I have not formally done research in imprecise probability over the last
twenty years, imprecise probability was central to much of my research in other areas.
This talk will review some of these encounters with imprecise probability, taking
examples from four areas:
– Using probabilities of a “higher type” (I.J. Good’s phrase), with an application to
genome-wide association studies.
– Robust Bayesian bounds, with an application to conversion of p-values to odds.
– Importance (and non-importance) of dependencies in imprecise probabilities.
– Imprecise probabilities arising from model bias, with examples from both statistical
and physical modeling.

Symbolic and Quantitative Representations
of Uncertainty: An Overview
Didier Dubois
IRIT, CNRS and University of Toulouse, Toulouse, France
The distinction between aleatory and epistemic uncertainty is more and more
acknowledged to-date, and the idea that they should not be handled in the same way
becomes more and more accepted. Aleatory uncertainty refers to a summarized
description of natural phenomena by means of frequencies of occurrence, which jus-
tiﬁes a numerical approach based on probability theory. In contrast, epistemic uncer-
tainty stems from a lack of information, and describes the state of knowledge of an
agent. It seems to be basically qualitative, and is captured by sets of possible worlds of
states of nature, one of which is the actual one. In other words, beliefs induced by
aleatory uncertainty are naturally quantitative, while this is less obvious for beliefs
stemming from epistemic uncertainty for which there are various approaches ranging
from qualitative ones like three-valued logics and modal logics to quantitative ones like
subjective probabilities. The qualitative approaches can be reﬁned by considering
degrees of beliefs on ﬁnite value scales or yet by means of conﬁdence relations.
Moreover aleatory and epistemic uncertainty may come together, and leads to the use
of upper and lower probabilities.
In this talk, we review the various approaches to the representations of uncertainty,
by showing similarities between quantitative and qualitative approaches. We give a
general deﬁnition of an epistemic state or an information item, as deﬁning a set of
possible values, a set of plausible ones, a plausibility ordering on events. Moreover,
epistemic states must be compared in terms of informativeness.
The basic mathematical tool for representing uncertainty is the monotonic
set-function, called capacity of fuzzy measure. In the quantitative case, the most general
model is based on convex probability sets, that is, capacities that stand for lower
probabilities. In the qualitative case, the simplest non-Boolean approach is based on
possibility and necessity measures. It is shown that possibility theory plays in the
qualitative setting a role similar to the one of probability theory in the quantitative
setting. Just as a numerical capacity can, under some conditions, encode a family of
probability distributions, a qualitative capacity always encodes a family of possibility
distributions. For decision purposes, Sugeno integral is similar to Choquet integral.
Logical reasoning under incomplete information can be achieved by means of a
simpliﬁed version of epistemic logic whose semantics is in terms of possibility theory,
in contrast with probabilistic reasoning. It can be extended to reasoning with degrees of
beliefs using generalised possibilistic logic. Various ways of deﬁning logics of
uncertainty are outlined, absolute, comparative, or fuzzy.

Finally we discuss the issue of uncertainty due to conﬂicting items of information.
In the numerical setting this is naturally captured by the theory of evidence, that
essentially models unreliable testimonies and their fusion. A general approach to the
fusion of information items is outlined, proposing merging axioms that apply to
quantitative and qualitative items of information. Finally, we show that using Boolean
valued capacities, we can faithfully represent conﬂicting information coming from
several sources. In this setting, necessity functions represent incomplete information
while possibility measures represent precise but conﬂicting pieces of information.
This talk owes much to works performed with M. Banerjee, D. Ciucci, L. Godo,
W. Liu and J. Ma, H. Prade, A. Rico, S. Schockaert, among others.
References
1. Banerjee, M., Dubois, D.: A simple logic for reasoning about incomplete knowledge. Int.
J. Approx. Reason. 55, 639–653 (2014)
2. Ciucci, D., Dubois, D.: A two-tiered propositional framework for handling multisource
inconsistent information these proceedings (2017)
3. Dubois, D.: Representation, propagation, and decision issues in risk analysis under incom-
plete probabilistic information. Risk Anal. 30, 361–368 (2010)
4. Dubois, D., Godo, L., Prade, H.: Weighted logics for artiﬁcial intelligence - an introductory
discussion. Int. J. Approx. Reason. 55(9), 1819–1829 (2014)
5. Dubois, D., Liu, W., Ma, J., Prade, H.: The basic principles of uncertain information fusion.
An organised review of merging rules in different representation frameworks. Inf. Fusion 32,
12–39 (2016)
6. Dubois, D., Prade, H., Rico, A.: Representing qualitative capacities as families of possibility
measures. Int. J. Approx. Reason. 58, 3–24 (2015)
7. Dubois, D., Prade, H., Schockaert, S.: Reasoning about uncertainty and explicit ignorance in
generalized possibilistic logic. In: Proceedings of the ECAI 2014, pp. 261–266 (2014)
8. Ferson, S., Ginzburg, L.R.: Different methods are needed to propagate ignorance and
variability. Reliab. Eng. Syst. Saf. 54, 133–144 (1996)
9. Flage, R., Dubois, D., Aven, T.: Combined analysis of unique and repetitive events in
quantitative risk assessment. Int. J. Approx. Reason. 70, 68–78 (2016)
10. Grabisch, M.: Set functions, Games and Capacities in Decision-Making. Springer (2016)
11. Walley, P., Fine, T.: Varieties of modal: classiﬁcatory and comparative probabilities. Syn-
these 41, 321–374 (1979)
Symbolic and Quantitative Representations of Uncertainty: An Overview
XVII

Learning from Imprecise Data
Eyke Hüllermeier
Paderborn University, Paderborn, Germany
This talk addresses the problem of learning from imprecise data. Although it has been
studied in statistics and various other ﬁelds for quite a while, this problem received
renewed interest in the realm of machine learning more recently. In particular, the
framework of superset learning will be discussed, a generalization of standard super-
vised learning in which training instances are labeled with a superset of the actual
outcomes. Thus, superset learning can be seen as a speciﬁc type of weakly supervised
learning, in which training examples are imprecise or ambiguous. We introduce a
generic approach to superset learning, which is motivated by the idea of performing
model identiﬁcation and “data disambiguation” simultaneously. This idea is realized by
means of a generalized risk minimization approach, using an extended loss function
that compares precise predictions with set-valued observations. Building on this
approach, we furthermore elaborate on the idea of “data imprecisiation”: By deliber-
ately turning precise training data into imprecise data, it becomes possible to modulate
the inﬂuence of individual examples on the process of model induction. In other words,
data imprecisiation offers an alternative way of instance weighting. Interestingly,
several existing machine learning methods, such as support vector regression or
semi-supervised support vector classiﬁcation, are recovered as special cases of this
approach. Besides, promising new methods can be derived in a natural way, and
examples of such methods will be shown for problems such as classiﬁcation, regres-
sion, and label ranking.

Contents
Analogical Reasoning
Analogical Inequalities. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3
Henri Prade and Gilles Richard
Boolean Analogical Proportions - Axiomatics and Algorithmic
Complexity Issues. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
10
Henri Prade and Gilles Richard
Argumentation
Evaluation of Arguments in Weighted Bipolar Graphs . . . . . . . . . . . . . . . . .
25
Leila Amgoud and Jonathan Ben-Naim
Debate-Based Learning Game for Constructing Mathematical Proofs . . . . . . .
36
Nadira Boudjani, Abdelkader Gouaich, and Souhila Kaci
Updating Probabilistic Epistemic States in Persuasion Dialogues . . . . . . . . . .
46
Anthony Hunter and Nico Potyka
From Structured to Abstract Argumentation: Assumption-Based
Acceptance via AF Reasoning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
57
Tuomo Lehtonen, Johannes P. Wallner, and Matti Järvisalo
On Relating Abstract and Structured Probabilistic Argumentation:
A Case Study . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
69
Henry Prakken
Bayesian Networks
Structure-Based Categorisation of Bayesian Network Parameters. . . . . . . . . .
83
Janneke H. Bolt and Silja Renooij
The Descriptive Complexity of Bayesian Network Specifications . . . . . . . . .
93
Fabio G. Cozman and Denis D. Mauá
Exploiting Stability for Compact Representation of Independency Models . . .
104
Linda C. van der Gaag and Stavros Lopatatzidis
Parameter Learning Algorithms for Continuous Model Improvement
Using Operational Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
115
Anders L. Madsen, Nicolaj Søndberg Jeppesen, Frank Jensen,
Mohamed S. Sayed, Ulrich Moser, Luis Neto, Joao Reis, and Niels Lohse

Monotonicity in Bayesian Networks for Computerized Adaptive Testing . . . .
125
Martin Plajner and Jiří Vomlel
Expert Opinion Extraction from a Biomedical Database . . . . . . . . . . . . . . . .
135
Ahmed Samet, Thomas Guyet, Benjamin Negrevergne, Tien-Tuan Dao,
Tuan Nha Hoang, and Marie Christine Ho Ba Tho
Solving Trajectory Optimization Problems by Influence Diagrams. . . . . . . . .
146
Jiří Vomlel and Václav Kratochvíl
Belief Functions
Iterative Aggregation of Crowdsourced Tasks Within the Belief
Function Theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
159
Lina Abassi and Imen Boukhris
A Clustering Approach for Collaborative Filtering Under the Belief
Function Framework . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
169
Raoua Abdelkhalek, Imen Boukhris, and Zied Elouedi
A Generic Framework to Include Belief Functions in Preference
Handling for Multi-criteria Decision . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
179
Sébastien Destercke
A Recourse Approach for the Capacitated Vehicle Routing Problem
with Evidential Demands . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
190
Nathalie Helal, Frédéric Pichon, Daniel Porumbel, David Mercier,
and Éric Lefèvre
Evidential k-NN for Link Prediction . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
201
Sabrine Mallek, Imen Boukhris, Zied Elouedi, and Eric Lefevre
Ensemble Enhanced Evidential k-NN Classifier Through
Random Subspaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
212
Asma Trabelsi, Zied Elouedi, and Eric Lefevre
Conditionals
Comparison of Inference Relations Defined over Different Sets
of Ranking Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
225
Christoph Beierle and Steven Kutsch
A Transformation System for Unique Minimal Normal Forms
of Conditional Knowledge Bases . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
236
Christoph Beierle, Christian Eichhorn, and Gabriele Kern-Isberner
On Boolean Algebras of Conditionals and Their Logical Counterpart . . . . . .
246
Tommaso Flaminio, Lluis Godo, and Hykel Hosni
XX
Contents

A Semantics for Conditionals with Default Negation . . . . . . . . . . . . . . . . . .
257
Marco Wilhelm, Christian Eichhorn, Richard Niland,
and Gabriele Kern-Isberner
Credal Sets, Credal Networks
Incoherence Correction and Decision Making Based on Generalized
Credal Sets. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
271
Andrey G. Bronevich and Igor N. Rozenberg
Reliable Knowledge-Based Adaptive Tests by Credal Networks . . . . . . . . . .
282
Francesca Mangili, Claudio Bonesana, and Alessandro Antonucci
Decision Theory, Decision Making and Reasoning Under Uncertainty
Algorithms for Multi-criteria Optimization in Possibilistic Decision Trees . . .
295
Nahla Ben Amor, Fatma Essghaier, and Hélène Fargier
Efficient Policies for Stationary Possibilistic Markov Decision Processes . . . .
306
Nahla Ben Amor, Zeineb EL khalfi, Hélène Fargier, and Régis Sabaddin
An Angel-Daemon Approach to Assess the Uncertainty in the Power
of a Collectivity to Act . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
318
Giulia Fragnito, Joaquim Gabarro, and Maria Serna
Decision Theory Meets Linear Optimization Beyond Computation . . . . . . . .
329
Christoph Jansen, Thomas Augustin, and Georg Schollmeyer
Axiomatization of an Importance Index for Generalized Additive
Independence Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
340
Mustapha Ridaoui, Michel Grabisch, and Christophe Labreuche
Fuzzy Sets, Fuzzy Logic
Probability Measures in GödelD Logic . . . . . . . . . . . . . . . . . . . . . . . . . . . .
353
Stefano Aguzzoli, Matteo Bianchi, Brunella Gerla, and Diego Valota
Fuzzy Weighted Attribute Combinations Based Similarity Measures . . . . . . .
364
Giulianella Coletti, Davide Petturiti, and Barbara Vantaggi
Online Fuzzy Temporal Operators for Complex System Monitoring . . . . . . .
375
Jean-Philippe Poli, Laurence Boudet, Bruno Espinosa,
and Laurence Cornez
Contents
XXI

Logics
Complexity of Model Checking for Cardinality-Based Belief
Revision Operators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
387
Nadia Creignou, Raïda Ktari, and Odile Papini
A Two-Tiered Propositional Framework for Handling Multisource
Inconsistent Information. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
398
Davide Ciucci and Didier Dubois
Reasoning in Description Logics with Typicalities and Probabilities
of Exceptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
409
Gian Luca Pozzato
Orthopairs
Measuring Uncertainty in Orthopairs . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
423
Andrea Campagner and Davide Ciucci
Possibilistic Networks
Possibilistic MDL: A New Possibilistic Likelihood Based Score
Function for Imprecise Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
435
Maroua Haddad, Philippe Leray, and Nahla Ben Amor
Probabilistic Logics, Probabilistic Reasoning
The Complexity of Inferences and Explanations in Probabilistic
Logic Programming. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
449
Fabio G. Cozman and Denis D. Mauá
Count Queries in Probabilistic Spatio-Temporal Knowledge Bases
with Capacity Constraints. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
459
John Grant, Cristian Molinaro, and Francesco Parisi
RankPL: A Qualitative Probabilistic Programming Language . . . . . . . . . . . .
470
Tjitze Rienstra
Generalized Probabilistic Modus Ponens . . . . . . . . . . . . . . . . . . . . . . . . . .
480
Giuseppe Sanfilippo, Niki Pfeifer, and Angelo Gilio
A First-Order Logic for Reasoning About Higher-Order Upper
and Lower Probabilities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
491
Nenad Savić, Dragan Doder, and Zoran Ognjanović
Author Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
501
XXII
Contents

Analogical Reasoning

Analogical Inequalities
Henri Prade1,2(B) and Gilles Richard1
1 IRIT, Toulouse University, Toulouse, France
{prade,richard}@irit.fr
2 QCIS, University of Technology, Sydney, Australia
Abstract. Analogical proportions, i.e., statements of the form a is to
b as c is to d, state that the way a and b possibly diﬀer is the same
as c and d diﬀer. Thus, it expresses an equality (between diﬀerences).
However expressing inequalities may be also of interest for stating, for
instance, that the diﬀerence between a and b is smaller than the one
between c and d. The logical modeling of analogical proportions, both in
the Boolean case and in the multiple-valued case, has been developed in
the last past years. This short paper provides a preliminary investigation
of the logical modeling of so-called “analogical inequalities”, which are
introduced here, in relation with analogical proportions.
1
Introduction
Comparative thinking plays a key role in our assessment of reality. This has been
recognized for a long time. Making comparison is closely related to similarity
judgment [14] and analogy making [4]. Analogical proportions, i.e., statements
of the form a is to b as c is to d provides a well-known way for expressing a
comparative judgment between the two pairs (a, b) and (c, d) by suggesting that
the comparison between the elements of each pair yields the same kind of result
in terms of dissimilarity [12].
The interest of analogical proportions has been recently pointed out in clas-
siﬁcation in machine learning [1,2,8] and in visual multiple-class categorization
tasks for handling pieces of knowledge about semantic relationships between
classes. More precisely in this latter case, analogical proportions are used for
expressing analogies between pairs of concrete objects in the same semantic
universe and with similar abstraction level, and then this gives birth to con-
straints that serve regularization purposes [5]. Interestingly enough, constraints
of the same kind but issued from pieces of knowledge stating relative comparisons
between quadruplets of images, feature by feature, have been recently experi-
enced with success [6,7]. These relative comparisons are inequalities between dif-
ferences inside pairs rather than equalities. Moreover these comparisons involv-
ing quadruplets have been shown to be more useful in categorization tasks than
comparisons involving only triplets, or pairs, of images.
Besides, it has been also recently noticed that similar relations in terms of
comparison of pairs were also present in multiple criteria analysis for expressing,
for instance, that the “diﬀerence” between two evaluation vectors on a criterion
c
⃝Springer International Publishing AG 2017
A. Antonucci et al. (Eds.): ECSQARU 2017, LNAI 10369, pp. 3–9, 2017.
DOI: 10.1007/978-3-319-61581-3 1

4
H. Prade and G. Richard
is smaller than (i.e., does not compensate) the “diﬀerence” between the vectors
on the rest of the criteria [10].
This recent emergence of the interest for inequality constraints between pairs
of items motivates this ﬁrst formal study of “analogical inequalities”, in relation
with the Boolean and the multiple-valued modeling of analogical proportions.
The paper ﬁrst restates the necessary background on these proportions, before
extending it in order to represent “analogical inequalities”, both in the Boolean
and in the multiple-valued settings.
2
Background on Analogical Proportions
We start with a reminder on analogical proportions, ﬁrst in the case of binary
attributes.
2.1
Boolean Case
Let us assume that four items a, b, c, d are represented by sets of binary features
belonging to a universe U (i.e., an item is then viewed as the set of the binary
features in U that it satisﬁes). Then, the dissimilarity between a and b can be
appreciated in terms of a ∩b and/or a ∩b, where a denotes the complement
of a in U, while the similarity is estimated by means of a ∩b and/or of a ∩b.
Then, an analogical proportion between subsets is formally deﬁned by the two
conditions [9]:
a ∩b = c ∩d and a ∩b = c ∩d
(1)
This expresses that “a diﬀers from b as c diﬀers from d” and that “b diﬀers from
a as d diﬀers from c”. It can be viewed as the expression of a co-variation.
Analogical proportion has an easy counterpart in Boolean logic, where it is
denoted by a : b :: c : d, a, b, c, d being now Boolean variables (supposed to
refer to the value of the same attribute for 4 diﬀerent items). In this logical
setting, “equality” translates into “equivalence” (≡), a into the negation of a (i.e.,
¬a), and ∩is changed into a conjunction (∧), and we get the logical condition
expressing that 4 Boolean variables make an analogical proportion [9]:
a : b::c : d = (a ∧¬b ≡c ∧¬d) ∧(¬a ∧b ≡¬c ∧d)
(2)
An analogical proportion is then a Boolean formula. The expression a :
b::c : d takes the truth value “1” only for the 6 following patterns for abcd:
1111, 0000, 1100, 0011, 1010, 0101. For the 10 other patterns of its truth table, it
is false (i.e., equal to 0).
A worth noticing property, beyond reﬂexivity (a : b::a : b), symmetry (if
a : b::c : d then c : d::a : b), and central permutation (if a : b::c : d then a : c::b : d)
is the fact that the analogical proportion remains true for the negation of the
Boolean variables [11]. It expresses that the result does not depend on a positive
or a negative encoding of the features:
if a : b::c : d then ¬a : ¬b::¬c : ¬d
(code independency).
(3)

Analogical Inequalities
5
2.2
Multiple-Valued Case
Attributes or features are not necessarily Boolean, and a graded extension of
analogical expression is needed. We assume that attributes are now valued in
[0, 1] (possibly after renormalization). The extension is obtained by replacing (i)
the central ∧in (2) by min, (ii) the two ≡symbols by min(s →L t, t →L s) =
1−| s −t |, where s →L t = min(1, 1 −s + t) is Lukasiewicz implication, (iii)
the four expressions of the form s∧¬t by the bounded diﬀerence max(0, s−t) =
1 −(s →L t), which is associated to Lukasiewicz implication, using 1 −(·) as
negation. The resulting expression [3] is then
a : b ::Lc : d =
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
1−| (a −b) −(c −d) |,
if a ≥b and c ≥d, or a ≤b and c ≤d
1 −max(|a −b|,|c −d|),
if a ≤b and c≥d, or a ≥b and c ≤d
(4)
It coincides with a : b::c : d on {0, 1}. As can be seen, this expression is equal
to 1 if and only if (a−b) = (c−d), while a : b ::Lc : d = 0 if and only if (i) a−b = 1
and c ≤d, or if (ii) b −a = 1 and d ≤c, or if (iii) a ≤b and c −d = 1, or if iv)
b ≤a and d −c = 1. Thus, a : b ::Lc : d = 0 when the change inside one of the
pairs (a, b) or (c, d) is maximal, while the other pair shows either no change or a
change in the opposite direction. It can be also checked that code independency
continue to hold under the form a : b ::Lc : d = 1 −a : 1 −b ::L1 −c : 1 −d.
Note that the algebraic diﬀerence between a and b equated with the diﬀerence
between c and d, namely a −b = c −d, provides a constraint that is satisﬁed by
the 6 patterns making true the analogical proportion a : b::c : d in the Boolean
case, and by none of the 10 others. However, a−b may not belong to {0, 1} when
a, b ∈{0, 1}. While | a −b |∈{0, 1}, the constraint | a −b |=| c −d | validates
8 patterns including 0110 and 1001. When considering the graded case, a −b is
not close in [0, 1]; moreover, the modeling of the analogical proportion by the
constraint a −b = c −d does not provide a graded evaluation of how far we are
from satisfying it.
3
Inequalities
In the following, we propose a logical modeling for expressions of the form “a
is to b at least as much as c to d”, ﬁrst in the Boolean case, and then in the
multiple-valued case. We denote this expression by a : b << c : d.
3.1
Boolean Case
Starting from the Boolean expression (2) of the analogical proportion, we replace
the two symbols ≡expressing sameness by two material implications →for
modeling the fact that the result of the comparison of c and d is larger or equal
to the result of the comparison of a and b. Namely, we obtain
a : b << c : d = ((a ∧¬b) →(c ∧¬d)) ∧((¬a ∧b) →(¬c ∧d))
(5)

6
H. Prade and G. Richard
It can be checked from this deﬁnition that the following expected properties
hold:
– a : b << a : b
– a : b :: c : d →a : b << c : d
– a : b :: c : d ≡((a : b << c : d) ∧(c : d << a : b))
– (a : b << c : d) ≡(¬a : ¬b << ¬c : ¬d)
Namely, a : b << c : d is weaker than a : b :: c : d, while a : b :: c : d holds if and
only if both a : b << c : d and c : d << a : b hold; moreover, code independency is
preserved.
The truth table of a : b << c : d is given in Table 1. As can be seen a : b << c : d
holds true for the 6 patterns that makes analogical proportion true, plus the
4 patterns 0001, 0010, 1110, 1101. These latter patterns correspond to the 4
situations where a ≡b and c ̸≡d. In these 4 situations a and b are indeed
strictly closer than c and d, and these are the only cases in {0, 1}. Since the 4
situations where a ≡b and c ≡d are among the patterns making true a : b :: c : d,
we have
a : b << c : d ≡(a : b :: c : d) ∨(a ≡b)
(6)
It is also worth noticing that the central permutation property of analogical
proportion now fails since 0010 and 1101 are true while 0100 and 1011 are false.
This may be unexpected at ﬁrst glance since the arithmetic proportion inequality,
a −b ≤c −d, still satisﬁes central permutation in the numerical case; however
it is made possible since a −b ∈{−1, 0, 1} and indeed 0 < 1 ⇔−1 < 0.
Table 1. Boolean valuations for a : b << c : d
a b c d a : b << c : d a b c d a : b << c : d
0 0 0 0 1
1 0 0 0 0
0 0 0 1 1
1 0 0 1 0
0 0 1 0 1
1 0 1 0 1
0 0 1 1 1
1 0 1 1 0
0 1 0 0 0
1 1 0 0 1
0 1 0 1 1
1 1 0 1 1
0 1 1 0 0
1 1 1 0 1
0 1 1 1 0
1 1 1 1 1
Note that the quaternary relation a : b << c : d induces a ternary relation
(just as a continuous analogical proportion of the form a : b :: b : c is a particular
case of analogical proportion [13]). It can be seen that a : b << b : c is true only
for the four patterns 0000, 0001, 1110 and 1111, and false for the four other
patterns. It expresses that the diﬀerence between b and c is greater or equal to
the one between a and b.

Analogical Inequalities
7
3.2
Graded Case
The expression (5) can be extended to the multiple valued case, still keeping
min for extending the central ∧, 1−| s −t | for the ≡symbols, and the four
expressions of the form s ∧¬t as the bounded diﬀerence max(0, s −t). The
resulting expression is then
a : b <<L c : d =
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
min(1, 1 −((b −a) −(d −c))
if a ≤b and c ≤d
min(1, 1 −((a −b) −(c −d))
if a ≥b and c ≥d
1 −(b −a)
if a ≤b and c ≥d
1 −(a −b)
if a ≥b and c ≤d
(7)
Thus a : b <<L c : d can be read “c is more diﬀerent from d than a is from b”.
It can be checked that the following expected properties still hold
– a : b <<L c : d = a : b << c : d when a, b, c, d ∈{0, 1};
– a : b <<L a : b = 1;
– a : b ::Lc : d ≤a : b <<L c : d;
– a : b ::Lc : d = min((a : b <<L c : d), (c : d <<L a : b));
– (a : b <<L c : d) = ((1 −a) : (1 −b) <<L (1 −c) : (1 −d)).
In particular, a : b <<L c : d = 1 if and only if
– a = b, or
– | b −a | ≤| d −c | if a ≤b and c ≤d, or if b ≤a and d ≤c.
Moreover a : b <<L c : d = 0 if and only if
– | b −a |= 1 and | d −c |= 0, or
– b −a = 1 and c ≥d, or
– a −b = 1 and c ≤d.
It is worth noticing that a : b <<L c : d does not exactly amount at comparing
absolute value distances, as in the constraint | a −b |≤| c −d |. Indeed it can
be checked that we may have a : b <<L c : d = 0, while | a −b |≤| c −d | holds
(taking a = d = 0 and b = c = 1). Moreover a : b <<L c : d provides a graded
estimate of the extent to which the numerical constraint a−b ≤c−d is satisﬁed.
Continuous analogical inequalities deﬁne the following graded comparative
ternary relation:
a : b <<L b : c =
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
min(1, 1 + (a + c) −2b)
if a ≤b ≤c
min(1, 1 + 2b −(a + c))
if a ≥b ≥c
1 −(b −a)
if a ≤b and b ≥c
1 −(a −b)
if a ≥b and b ≤c
(8)
Note that a : b <<L b : c = 1 if and only if a = b, or if b ≤(a + c)/2 (resp.
b ≥(a + c)/2) if a ≤b ≤c (resp. a ≥b ≥c), i.e., if and only if b is closer (in
the broad sense) to a than to c. It means that the diﬀerence between b and c is

8
H. Prade and G. Richard
greater or equal to the one between a and b and the diﬀerences are oriented in
the same way (when non zero).
Lastly, all the deﬁnitions considered in this paper apply to a single attribute.
Just as in the case of the analogical proportion, the deﬁnitions straightforwardly
extend to multiple attribute descriptions by applying them in a component-
wise manner, attribute per attribute. If necessary, a global evaluation may be
obtained by taking the average of the estimates obtained for each considered
attribute.
4
Conclusion
The paper has provided a preliminary investigation of the idea of analogical
inequality as a relaxation of the notion of analogical proportion, both in the
Boolean case and in the multiple-valued case. It appears that this proper exten-
sion does not just amount at comparing diﬀerences (or distances) between the
elements of two pairs, but, as in the case of the analogical proportion, it also
takes into account the orientation of the variations when going from a to b, and
from c to d. Moreover, it also provides a graded estimate of the extent to which
“c is more diﬀerent from d than a is from b”. This enables us to turn such a
statement into a soft constraint, where the threshold corresponding to the min-
imal amount to which the constraint should hold might be a matter of learning
in practice.
References
1. Bayoudh, S., Miclet, L., Delhay, A.: Learning by analogy: a classiﬁcation rule for
binary and nominal data. In: Proceedings of 20th International Joint Conference
on Artiﬁcal Intelligence (IJCAI 2007), Hyderabad, India, pp. 678–683 (2007)
2. Bounhas, M., Prade, H., Richard, G.: Analogical classiﬁcation. A new way to deal
with examples. In: Proceedings of ECAI 2014, pp. 135–140 (2014)
3. Dubois, D., Prade, H., Richard, G.: Multiple-valued extensions of analogical pro-
portions. Fuzzy Sets Syst. 292, 193–202 (2016)
4. Gentner, D., Holyoak, K.J., Kokinov, B.N. (eds.): The Analogical Mind: Perspec-
tives from Cognitive Science. MIT Press, Cambridge (2001)
5. Hwang, S.J., Grauman, K., Sha, F.: Analogy-preserving semantic embedding for
visual object categorization. In: Proceedings of International 30th Conference on
Machine Learning (ICML), Atlanta, pp. 639–647 & JMLR: W&CP, 28 (1) 222–230
(2013)
6. Law, M.T., Thome, N., Cord, M.: Quadruplet-wise image similarity learning. In:
Proceedings of IEEE International Conference on Computer Vision (ICCV) (2013)
7. Law, M.T., Thome, N., Cord, M.: Learning a distance metric from relative com-
parisons between quadruplets of images. Int. J. Comput. Vis. 121(1), 65–94 (2017)
8. Miclet, L., Bayoudh, S., Delhay, A.: Analogical dissimilarity: deﬁnition, algorithms
and two experiments in machine learning. J. Artif. Intell. Res. (JAIR) 32, 793–824
(2008)

Analogical Inequalities
9
9. Miclet, L., Prade, H.: Handling analogical proportions in classical logic and
fuzzy logics settings. In: Sossai, C., Chemello, G. (eds.) ECSQARU 2009.
LNCS (LNAI), vol. 5590, pp. 638–650. Springer, Heidelberg (2009). doi:10.1007/
978-3-642-02906-6 55
10. Pirlot, M., Prade, H., Richard, G.: Completing preferences by means of analogical
proportions. In: Torra, V., Narukawa, Y., Navarro-Arribas, G., Ya˜nez, C. (eds.)
MDAI 2016. LNCS (LNAI), vol. 9880, pp. 135–147. Springer, Cham (2016). doi:10.
1007/978-3-319-45656-0 12
11. Prade, H., Richard, G.: From analogical proportion to logical proportions. Logica
Universalis 7(4), 441–505 (2013)
12. Prade, H., Richard, G.: From the structures of opposition between similarity and
dissimilarity indicators to logical proportions. A general representation setting for
capturing homogeneity and heterogeneity. In: Dodig-Crnkovic, G., Giovagnoli, R.
(eds.) Representation and Reality in Humans, Animals and Machines. Springer
(2017)
13. Schockaert, S., Prade, H.: Completing rule bases using analogical proportions. In:
Prade, H., Richard, G. (eds.) Computational Approaches to Analogical Reasoning
- Current Trends, pp. 195–215. Springer, Heidelberg (2014)
14. Tversky, A.: Features of similarity. Psychol. Rev. 84, 327–352 (1977)

Boolean Analogical Proportions - Axiomatics
and Algorithmic Complexity Issues
Henri Prade1,2(B) and Gilles Richard1
1 IRIT, Toulouse University, Toulouse, France
{prade,richard}@irit.fr
2 QCIS, University of Technology, Sydney, Australia
Abstract. Analogical proportions, i.e., statements of the form a is to b as
c is to d, are supposed to obey 3 axioms expressing reﬂexivity, symmetry,
and stability under central permutation. These axioms are not enough to
determine a single Boolean model, if a minimality condition is not added.
After an algebraic discussion of this minimal model and of related expres-
sions, another justiﬁcation of this model is given in terms of Kolmogorov
complexity. It is shown that the 6 Boolean patterns that make an analogi-
cal proportion true have a minimal complexity with respect to an expres-
sion reﬂecting the intended meaning of the proportion.
1
Introduction
Despite the fact that conclusions obtained by analogical reasoning do no guaran-
tee to be valid from a classical logic viewpoint, this kind of reasoning is consid-
ered as a valuable and often creative way to solve real life problems. Analogical
proportions, i.e., relations between four items of the form a is to b as c is to
d, constitute a key notion formalizing analogical inference and relying on the
following principle: if such proportions hold on a noticeable subset of known fea-
tures used for describing the four items, the proportion may still hold on other
features as well, which may help guessing the unknown values of d on these other
features from their values on a, b, and c [11,19]. It is only quite recently that a
logical modeling of these proportions has been proposed [12,13], following sev-
eral attempts at formalizing them in other settings [7,10]. This logical modeling
makes clear that the analogical proportion holds if and only if a diﬀers from b
as c diﬀers from to d and vice-versa.
The paper investigates two new justiﬁcations of the Boolean expression of
an analogical proportion. First, starting from the core axioms supposed to be
satisﬁed by an analogical proportion, and agreed by everybody for a long time,
this paper exhibits the Boolean models compatible with these axioms. There are
several ones, but the smallest model is the standard Boolean expression of an
analogical proportion previously proposed. This smallest model is characterized
by six possible Boolean patterns (among sixteen candidates). In the second part
of the paper, we try to evaluate their cognitive signiﬁcance in terms of algorithmic
complexity (i.e. Kolmogorov complexity) and show that they are also minimal
c
⃝Springer International Publishing AG 2017
A. Antonucci et al. (Eds.): ECSQARU 2017, LNAI 10369, pp. 10–21, 2017.
DOI: 10.1007/978-3-319-61581-3 2

Boolean Analogical Proportions
11
among all Boolean patterns with respect to an algorithmic complexity-based def-
inition of analogy. Indeed algorithmic complexity measures a kind of universal
information content of a Boolean string. Despite its inherent uncomputability,
there exist powerful tool for computing good approximations. Kolmogorov com-
plexity has been proved to be of great value in diverse applications: for example,
in distance measures [1] and classiﬁcation methods, plagiarism detection, net-
work intrusion detection [5], and in numerous other applications [9].
The paper is organized as follows. In Sect. 2, we provide a background on
the deﬁnition of an analogical proportion and its basic properties in a Boolean
setting. In Sect. 3, we start from the characteristic axioms of analogical propor-
tions, and we investigate the diﬀerent compatible Boolean models. In Sect. 4, we
brieﬂy review the main deﬁnition and theorems of Kolmogorov complexity. As
we have the main tools, we are in a position to give a Kolmogorov complexity-
based deﬁnition of analogy in Sect. 5. Section 6 is devoted to a set of experiments
that empirically validate our deﬁnition. Finally, we conclude in Sect. 7.
2
Background on Boolean Analogical Proportion
At the time of Aristotle, the idea of analogical proportion originated from
the notion of numerical proportion. In that respect the arithmetic proportion
between 4 integers a, b, c, d, which holds if a −b = c −d, is a good prototype
of the idea of analogical proportion, since we can read it as “a diﬀers from b as
c diﬀers from d”, which perfectly ﬁts with “a is to b as c is to d”, denoted by
a : b :: c : d. When considering Boolean interpretation where a, b, c, d ∈{0, 1}, it
is tempting to carry on with the same deﬁnition as {0, 1} ⊂R, with the inevitable
drawback that diﬀerence is not an internal operator in B = {0, 1}. Nevertheless,
if we draw the truth table (16 lines) corresponding to this deﬁnition, we get
Table 1 highlighting that only 6 among 16 lines are valid proportions.
Table 1. Boolean valuations for a : b :: c : d
a b c d a : b :: c : d a b c d a : b :: c : d
0 0 0 0 1
1 0 0 0 0
0 0 0 1 0
1 0 0 1 0
0 0 1 0 0
1 0 1 0 1
0 0 1 1 1
1 0 1 1 0
0 1 0 0 0
1 1 0 0 1
0 1 0 1 1
1 1 0 1 0
0 1 1 0 0
1 1 1 0 0
0 1 1 1 0
1 1 1 1 1
Boolean Deﬁnition. Looking for a purely logical deﬁnition of a : b :: c : d,
we need to make use of the comparative indicators [14,15] that are naturally
associated with a pair of variable (a, b):

12
H. Prade and G. Richard
– a∧b and ¬a∧¬b: they are positive similarity and negative similarity indicators
respectively; a ∧b (resp. ¬a ∧¬b) is true iﬀonly both a and b are true (resp.
false);
– a ∧¬b and ¬a ∧b: they are dissimilarity indicators ; a ∧¬b (resp. ¬a ∧b) is
true iﬀonly a (resp. b) is true and b (resp. a) is false.
Then analogical proportion is deﬁned by the two logically equivalent expres-
sions [13]:
a : b :: c : d = (a ∧¬b ≡c ∧¬d) ∧(¬a ∧b ≡¬c ∧d)
(1)
a : b :: c : d = ((a ∧d) ≡(b ∧c)) ∧((¬a ∧¬d) ≡(¬b ∧¬c))
(2)
Expression (1) reads “a diﬀers from b as c diﬀers from d and b diﬀers from a as d
diﬀers from c”. This deﬁnition is equivalent to the previous one (it yields Table 1)
with the advantage of being an internal deﬁnition inside B. Expression (2) may
be viewed as the logical counterpart of the well-known property of arithmetical
proportions a −b = c −d ⇔a + d = b + c. “a is to b as c is to d” can now
be read “what a and d have in common, b and c have it also (both positively
and negatively)”, which, however, is a less straightforward reading of the idea
of analogy than the one associated with (1). As can be checked on Table 1,
analogical proportions are independent with respect to the positive or negative
encoding of properties: (a : b :: c : d) ≡(¬a : ¬b :: ¬c : ¬d).
For representing objects one generally needs vectors of Boolean values, rather
than single Boolean values, each component being the value of a binary attribute.
The previous deﬁnition directly extends to Boolean vectors in Bn of the form
−→a = (a1, · · · , an) as follows: −→a : −→b :: −→c : −→d iﬀ∀i ∈[1, n], ai : bi :: ci : di.
Equation and Creativity. The equation a : b :: c : x has a unique solution
x = c ≡(a ≡b) provided that (a ≡b) ∨(a ≡c) holds. Indeed neither 0 : 1 :: 1 : 0
nor 1 : 0 :: 0 : 1 holds true. This process can be extended componenwise to
vectors. In that case, for instance, the following equation 010 : 100 : 011 : x has
for unique solution the vector (1, 0, 1) which is not among the 3 previous vectors
(0, 1, 0), (1, 0, 0), (0, 1, 1). Then analogical proportions for vectors are creative (an
informal quality usually associated with the idea of analogy) as they may involve
4 distinct vectors.
A Previous View of Analogical Proportion. In [6], S. Klein suggests that
an analogical proportion would hold as soon as a, b, c are completed by d taken as
d = c ≡(a ≡b). This amounts to deﬁne it as AK(a, b, c, d) ≜(a ≡b) ≡(c ≡d).
Then 0 : 1 :: 1 : 0 and 1 : 0 :: 0 : 1 become valid analogical proportions and
leads to the model denoted Kl in the following section. The validity of such
patterns may be advocated on the basis of a functional view of analogy where
a : f(a) :: b : f(b) sounds indeed valid, taking the negation in B for f. But, this is
debatable since AK(a, b, c, d) ⇔AK(b, a, c, d) (which does not ﬁt with intuition).
It turns out that a : b :: c : d ⇒AK(a, b, c, d).
Lower Approximations of Analogical Proportion. While AK(a, b, c, d) is
an upper approximation of a : b :: c : d true for 8 patterns, one may look for

Boolean Analogical Proportions
13
lower approximations that are true for 4 patterns only (taking into account code
independency). There are 3 such approximations, given below, followed by the
patterns they validate1:
(a ≡b) ∧(c ≡d)
1 1 1 1
0 0 0 0
1 1 0 0
0 0 1 1
; (a ≡c) ∧(b ≡d)
1 1 1 1
0 0 0 0
1 0 1 0
0 1 0 1
; (a ̸≡d) ∧(b ̸≡c)
1 1 0 0
0 0 1 1
1 0 1 0
0 1 0 1
.
Note that only the last one remains creative.
The question addressed now is “Could an axiomatic view of analogical propor-
tions oﬀer a kind of intrinsic justiﬁcation that only the 6 patterns obeying (1)–(2)
are acceptable?”
3
Analogy and Its Lattice of Boolean Models
Analogy, viewed as a quaternary relation R, is supposed to obey 3 axioms
(e.g., [7,10]):
1. ∀a, b, R(a, b, a, b) (reﬂexivity);
2. ∀a, b, c, d, R(a, b, c, d) →R(c, d, a, b) (symmetry);
3. ∀a, b, c, d, R(a, b, c, d) →R(a, c, b, d) (central permutation).
These axioms are clearly inspired by numerical proportions. From them, some
basic properties can be deduced by proper applications of symmetry and central
permutation:
– ∀a, b, R(a, a, b, b) (identity);
– ∀a, b, c, d, R(a, b, c, d) →R(b, a, d, c) (inside pair reversing);
– ∀a, b, c, d, R(a, b, c, d) →R(d, b, c, a)(extreme permutation).
In fact, another (less standard) axiom expected from a natural analogy is:
∀a, b, R(a, a, b, x) =⇒x = b (unicity)
All these properties ﬁt with our intuition of what may be an analogical propor-
tion. In this paper, we focus on B = {0, 1} as interpretation domain. In that case,
R should be interpreted as a subset of B4: removing the emptyset leaves 216 −1
candidate models. It is straightforward to get a basic model. By applying reﬂex-
ivity, we see that 0101, 1010 should belong to the relation and 0000, 1111 as well
since we may have a = b, and central permutation then leads to add 0011 and
1100. Thus, we get the model Ω0 = {0000, 1111, 0101, 1010, 0011, 1100}, which is
1 There are 3 companion approximations that involve the two additional patterns of
AK:
(a ≡d)∧(b ≡c)
1 1 1 1
0 0 0 0
1 0 0 1
0 1 1 0
; (a ̸≡b)∧(c ̸≡d)
1 0 0 1
0 1 1 0
1 0 1 0
0 1 0 1
; (a ̸≡c)∧(b ̸≡d)
1 1 0 0
0 0 1 1
1 0 0 1
0 1 1 0
.

14
H. Prade and G. Richard
stable under symmetry. Ω0 is the smallest model for analogical proportion over
B2. However, one may ask about other models, and we can show the following:
Property 1. There are exactly 8 models of analogy (satisfying the 3 ﬁrst
axioms) over B. There are exactly 2 models of analogy (satisfying the 3 ﬁrst
axioms plus unicity).
Proof. Any model should include Ω0. Let us note that a bigger model should
necessarily have an even cardinality due to the following facts:
– To be bigger than Ω0, it should contain a string s containing both 0 and 1.
– Thanks to symmetry or central permutation axioms, it should contain the
symmetric cdab of s = abcd and the central permutation acbd of s: necessarily,
one of these 2 strings is diﬀerent from s (otherwise, we get a = b = c = d).
So we have to look for models of cardinality 8, 10, 12, 14 and 16. Obviously B4
of cardinality 16 is a model, the biggest one. Due to the axioms, we have to add
to Ω0 subsets of B4 that are stable w.r.t. symmetry and central permutation.
We have exactly:
– one subset with 2 elements: S2 = {1001, 0110}
– two subsets with 4 elements: (i) S3 = {1110, 1101, 1011, 0111}; (ii) S4 =
{0001, 0010, 0100, 1000}.
Since every model has to be built by adding to Ω0 one of the previous subsets,
we get the following models for analogy in B:
(1) 1 model with 6 elements: Ω0 (the smallest one)
(2) 1 model with 8 elements: Kl = Ω0∪S2={0000, 1111, 0101, 1010, 0011, 1100,
0110, 1001}
As previously explained, this model is due to Klein [6].
(3) 2 model with 10 elements:
– M3 = Ω0∪S3={0000, 1111, 0101, 1010, 0011, 1100, 1110, 1101, 1011, 0111},
– M4 = Ω0∪S4={0000, 1111, 0101, 1010, 0011, 1100, 0001, 0010, 0100, 1000}
(4) 2 models with 12 elements:
– M5 = M3 ∪S2={0000, 1111, 0101, 1010, 0011, 1100, 1110, 1101, 1011,
0111, 0110, 1001},
– M6 = M4 ∪S2={0000, 1111, 0101, 1010, 0011, 1100, 0001, 0010, 0100,
1000, 0110, 1001},
(5) 1 model with 14 elements:
– M7 = M3 ∪S4 = M4 ∪S3 = Ω0 ∪S3 ∪S4 =
{0000, 1111, 0101, 1010, 0011, 1100, 1110, 1101, 1011, 0111, 0100, 1000,
0110, 1001},
(6) 1 model with exactly 16 elements: Ω = Ω0 ∪S2 ∪S3 ∪S4 = B.
Finally Ω0 and Kl satisfy unicity but M3 (containing 1100 and 1101) and
M4 (containing 0000 and 0001) do not satisfy. This achieves the proof.
□
2 Note that lower approximations of analogical proportions miss at least one axiom.

Boolean Analogical Proportions
15
The set of models is a lattice with bottom element Ω0 and top element B, see
Fig. 1. As can be seen, 8 models ﬁt with the axioms in the Boolean case, including
the 6-patterns model Ω0 and the 8-patterns model Kl due to Klein. However,
it is natural to privilege the smallest model, the minimal one that just accounts
for the axioms and nothing more.
Ω = B(16 elements)
M7(14 elements)
M6(12 elements)
M5(12 elements)
M3(10 elements)
M4(10 elements)
Ω0 = {0000, 1111, 0101, 1010, 0011, 1100}(6 elements)
Kl(8 elements)
Fig. 1. The lattice of Boolean models of analogy
We now investigate if another justiﬁcation in favor of the minimal model Ω0
can be obtained by minimizing an expression reﬂecting the information content
of an analogical proportion in terms of Kolmogorov complexity. We now review
the fundamentals of Kolmogorov complexity theory, also known as Algorithmic
Complexity Theory.
4
Kolmogorov Complexity: A Brief Review
Kolmogorov complexity is not a new concept and the theory has been designed
many years ago: see for instance [9] for an in depth study. This theory has not
to be confused with Shannon information theory [16] despite the fact that they
share some links.
The Starting Point. We need the help of a universal Turing machine
denoted U. Then p denotes a program running on U. Two situations can hap-
pen: (i) either p does not stop for the input x, or (ii) p stops for the input x and
outputs a ﬁnite string y. In that case, we write U(p, x) = y. The Kolmogorov
complexity [9] of y w.r.t. x is then deﬁned as:
KU(y/x) = min{|p|, U(p, x) = y}.
KU(y/x) is the size of the shortest program able to reconstruct y with the help
of x. The Kolmogorov complexity [9] of y is just obtained with the empty string ϵ:
KU(y) = min{|p|, U(p, ϵ) = y}.

16
H. Prade and G. Richard
Given a string s, KU(s) is an integer which, in some sense, is a measure of
the information content of s: instead of sending s to somebody, we can send p
from which s can be recovered as soon as this somebody has the machine U.
KU enjoys a lot of properties among which a kind of universality: this complex-
ity is independent of the underlying Turing machine as we have the invariance
theorem [9]:
Theorem 1. If U1 and U2 are two universal Turing machines, there exists a
constant cU1U2 such that for all string s: |KU1(s) −KU2(s)| < cU1U2, where
KU1(s) and KU2(s) denote the algorithmic complexity of s w.r.t. U1 and U2
respectively.
This theorem guarantees that complexity values may only diverge by a constant
c (e.g. the length of a compiler or a translation program) and for huge complexity
strings, we can denote K without specifying the Turing machine U. It can also
be shown that [9]:
Theorem 2. ∀x, y, K(xy) = K(x) + K(y/x) + O(1).
Unfortunately K has been proved as a non-computable function [9]. But in
fact, K or an upper bound of K can be estimated in diverse ways that we
investigate now.
Complexity Estimation. The ﬁrst well known option available to estimate
K is via lossless compression algorithm. For instance bzip approximates better
than gzip, and the PAQ family is still better than bzip2. Due to the invariance
theorem, when the size of s is huge, using compression will provide a relatively
stable approximation as the constant c in the theorem can be considered as
negligible. It is obviously not the case when the size of s becomes small. When
s is short, compression is not a valid option. On another side, the constant c
can prevent for providing stable approximations of K(s). Luckily, the works of
[3,4,17] give means of providing sensible values for the complexity of short strings
(i.e. less than 10bits). This job has been done by the Algorithmic Nature Group
(https://algorithmicnature.org/). They have developed a tool OACC (http://
www.complexitycalculator.com/) allowing to estimate the complexity of short
strings. The authors derived their approach from a theorem from Levin [4,8]
establishing the exact connection between m(s) and K(s), where m(s) is a semi-
measure known as the Universal Distribution deﬁned as follows [18]: m(s) =
Σp:U(p,ϵ)=s2−|p|.
Theorem 3. There exists a constant c depending only of the underlying Turing
machine such that: ∀s, | −log2(m(s)) −K(s)| < c.
Rewriting the formula as K(s) = −log2(m(s)) + O(1), shows that estimating
K could also be done via estimating m(s). Estimating m(s) becomes realistic
when s is short as we have to estimate the probability for s to be the output
of a short program. Considering simple Turing machines as described in [17],
over a Boolean alphabet {0, 1} and a ﬁnite number n of states {1,. . . ,n} plus a

Boolean Analogical Proportions
17
special Halt state denoted 0, there are exactly (4n + 2)2n such Turing machines.
Using clever optimizations [17], running these machines for n = 4 and n = 5
becomes realistic and provides an estimation of m(s) and ultimately of K(s). In
the following, we denote K′(s) this OACC estimation of K(s).
Short Chains Complexity Estimation. Some properties are expected
from a complexity calculator machinery to be in accordance with a cognitive
process:
1. There is no way to distinguish strings of length 1 and it is absolutely clear
that K(0) = K(1) should hold whatever the considered universal Turing
machine.
2. An important point is to be able to distinguish the 4 strings of length 2:
00, 11, 10, 01 and we expect the following properties: K(00) = K(11) <
K(01) = K(10);
3. In terms of n bits strings, we expect 0 . . . 0 and 1 . . . 1 to be the simplest ones
and to have the same complexity.
Observing the tables in [4], it appears that the properties above are satisﬁed,
namely:
– Whatever the number of states of a 2-symbols Turing machine, K′(0) =
K′(1).
– Whatever the number of states of a 2-symbols Turing machine, K′(00) =
K′(11) = a, K′(01) = K′(10) = b and a < b.
– Whatever the number of states of a 2-symbols Turing machine, and for strings
of length less than or equal to 10 (short strings) K′(0 . . . 0) = K′(1 . . . 1) = a
and a is the minimum value among the set of values.
Then the estimation of K via K′ coming from the OACC estimator is a
suitable candidate for our purpose. But before going further, we have ﬁrst to
check that OACC validate the above conditions. As we can check by examining
Table 2 and column 4 of the ﬁnal table in Sect. 6, these basic cognitive evidences
are conﬁrmed with the OACC tool. So we can start from OACC to check the
properties required to validate the analogical hypothesis that we propose in the
next section.
Table 2. Complexity of 1 bit and 2 bits chains with OACC
x
K(x)
0 3.5473880692782100
1 3.5473880692782100
x1x2
K(x1x2)
00
5.4141012345247104 = a
01
5.4141040197301500 = b
10
5.4141040197301500 = b
11
5.4141012345247104 = a

18
H. Prade and G. Richard
5
An Algorithmic Complexity View of Analogical
Proportions
As described in our introduction, several attempts have been done to formalize
analogy or analogical reasoning with mitigate success. In this paper, as it has
been the case in the works of [2], we adopt a machine learning viewpoint. Our
aim is to integrate analogical reasoning in the global landscape of predicting
values from observable examples.
When stated in a machine learning perspective, the problem of analogical
inference is as follows: for a given x3, predict x4 such that the target pair (x3, x4)
is in the same relation that another given source pair (x1, x2) considered as an
example. The pair (x3, x4) is the target pair which is partially known. In the
case of classiﬁcation where the 2nd element in a pair is the label, it amounts to
predict the label of x3 having only one classiﬁed example (x1, x2) at hand.
A functional view amounts to considering a hidden function f such that
x2 = f(x1) and we have to guess x4 = f(x3). This functional view is the one
developed in [2]: the problem of analogical inference strictly ﬁts with a regres-
sion problem but with only one example. Ruling out any statistical models, this
approach needs a brand new formalization that the authors extract from algo-
rithmic complexity theory. Instead of trying to ﬁnd regularities among a large
set of observations (statistical approach), they consider the very meaning of each
of the 3 observables x1, x2 = f(x1) and x3. We start from this philosophy, but
we depart from it as below:
– We focus on the Boolean case where the 3 objects under consideration are
Boolean vectors. So we do not have to care about the change between the
source domain representation and the target domain representation: these 2
domains are identical. The cost of this representation change is null in terms
of algorithmic complexity.
– To be in line with the machine learning minimal assumption that there exists
some unknown probability distribution P from which the data are drawn,
we do not consider that x2 is a (hidden) function of x1. We just have a
probability of observing x2 having already observed x1 which is more general
than associating a ﬁxed x2 with every given x1. It could be the case that for
another x′
2 we still have x1 : x′
2 :: x3 : x4.
As a consequence, we start from the following intuitions:
1. For x1 : x2 :: x3 : x4 to be accepted as a valid analogy, it is clear that the way
we go from x1 to x2 should not be very diﬀerent from the way we go from x3 to
x4 (but it has not to be a functional link). We suggest to measure this expected
proximity with the diﬀerence |K(x2/x1) −K(x4/x3)|. Considering K(x2/x1)
as the diﬃculty to build x2 from x1, the previous expression |K(x2/x1) −
K(x4/x3)|, when small, tells us that it is not more diﬃcult to build x4 from
x3 than to build x2 from x1, and vice versa. This is what we call the atomic
view of analogy. But this is obviously not enough.

Boolean Analogical Proportions
19
2. In fact, the previous formula does not tell anything about the link between
the pair (x1, x2) and the pair (x3, x4). For x1 : x2 :: x3 : x4 to be accepted as
a valid analogy, the diﬃculty to apprehend the string x1x2 from the string
x3x4 should be close to the diﬃculty to apprehend x3x4 from x1x2. We sug-
gest to measure this expected proximity with the diﬀerence |K(x1x2/x3x4)−
K(x3x4/x1x2)|. This diﬀerence is obviously symmetric and is linked to the
symmetry of an analogy.
3. Above all, the global picture has to be “simple” i.e. telling that x1 : x2 :: x3 :
x4 is a valid analogy should not be too disturbing, at least from a cognitive
viewpoint. This means that the occurrence of the string x1x2x3x4 in this
order should be highly plausible. We suggest to measure this plausibility with
K(x1x2x3x4) which is the size of the shortest program producing the binary
string x1x2x3x4 from a universal Turing machine.
Following the ideas of [2], we use the sum as aggregator operator and denote
k(x1x2x3x4) the following formula measuring, in some sense, the quality of an
analogy:
|K(x2/x1) −K(x4/x3)| + |K(x1x2/x3x4) −K(x3x/x1x2)| + K(x1x2x3x4)
This leads us to postulate that the “best” x4 we are looking for to build
a valid analogy x1 : x2 :: x3 : x4 is the one minimizing this expression. So, we
have: x4 = argminuk(x1x2x3u). Let us see if we can, at least from an empirical
viewpoint, validate this model.
6
Validation in the Boolean Setting
As we are not in a position to prove something at this stage, let us just investigate
now the empirical evidence for our formula. One point to start with is to check
if this formula holds in the very basic Boolean case. Considering x1, x2, x3, x4
as Boolean values, we have to check how the 6 cases of valid analogical propor-
tions actually behave w.r.t. the formula k(x1x2x3x4). Thus, we have to estimate
formula k(x1x2x3x4) for every x1x2x3x4 ∈B4. The point is that our strings are
very short: only 4 bits. So, as explained in Sect. 4, we have to rely on OACC
instead of a compression estimation.
The Less Complex Analogical Chains. On top of that, we have to consider,
not only pure Kolmogorov complexity K but also complexity w.r.t. a given string
as in K(x3x4/x1x2). Generally, it is quite clear that K(xy) ≤K(x) + K(y/x):
roughly speaking, we can build a program whose output is xy by concatenating
a program whose output is x to a program taking x as input and providing y
as output. It is more diﬃcult to get a more precise bound. Thanks to Theorem
2: K(xy) = K(x) + K(y/x) + O(1), which shows that we can approximate
K(y/x) with K(xy)−K(x). As we now have all the tools needed to approximate
formula k, it remains to use OACC to compute the estimation. The following
table reports the results of this computation:

20
H. Prade and G. Richard
As can be seen for the 6 patterns of the model Ω0 of analogical proportion,
the unique solution of equation a : b :: c : x always corresponds to a string
abcx that minimizes expression k wrt the other option abcx (where x = ¬x),
e.g. k(1111) < k(1110). Besides 0101 is simpler than 0110 despite the fact that
in the second case there is also an underlying function such that x2 = f(x1)
and x4 = f(x3): the negation. Note that 0110 and 1001 exhibit the highest
complexity as estimated by OACC. It eliminates Kl. As there is no known
convergence result regarding K and that we cannot estimate the constant in the
formula K(s) = −log2(m(s))+O(1), these experiences should only be considered
as adding a bit of credibility to the smallest model.
7
Conclusion
We have given a complete description of the Boolean models of analogy. To
choose the most relevant one among the possible 8 models beyond the mini-
mality argument, we have proposed a complexity-based deﬁnition for Boolean
analogical proportion. Using a set of calculations with OACC, the tool devel-
oped by the Algorithmic Nature Group (https://algorithmicnature.org/), we
have checked that the truth table of the Boolean analogy ﬁts with the fact
that the corresponding combinations minimize the given complexity formula. It
remains to consider the formula in a more general setting than the Boolean one.
This would in particular allow to establish a link between transfer learning and
Kolmogorov complexity. Another point would be of interest: to be able to solve
the minimization problem associated to the formula. Doing so would be to solve
the analogical equation a : b :: c : x. This might be the basis of a constructive
process.

Boolean Analogical Proportions
21
References
1. Bennett, C.H., G´acs, P., Li, M., Vit´anyi, P., Zurek, W.H.: Information distance
(2010). CoRR abs/1006.3520
2. Cornu´ejols, A.: Analogy as minimization of description length. In: Nakhaeizadeh, G.,
Taylor, C. (eds.) Machine Learning and Statistics: The Interface, pp. 321–336. Wiley,
Chichester (1996)
3. Delahaye, J.P., Zenil, H.: On the Kolmogorov-Chaitin complexity for short
sequences (2007). CoRR abs/0704.1043
4. Delahaye, J.P., Zenil, H.: Numerical evaluation of algorithmic complexity for short
strings: a glance into the innermost structure of randomness. Appl. Math. Comput.
219(1), 63–77 (2012)
5. Goel, S., Bush, S.F.: Kolmogorov complexity estimates for detection of viruses in
biologically inspired security systems: a comparison with traditional approaches.
Complexity 9(2), 54–73 (2003)
6. Klein, S.: Whorf transforms and a computer model for propositional/appositional
reasoning. In: Proceedings of the Applied Mathematics colloquium, University of
Bielefeld, West Germany (1977)
7. Lepage, Y.: Analogy and formal languages. Electr. Notes Theor. Comp. Sci. 53,
180–191 (2002). Moss, L.S., Oehrle, R.T. (eds.) Proceedings of the Joint Meeting of
the 6th Conference on Formal Grammar and the 7th Conference on Mathematics
of Language
8. Levin, L.: Laws of information conservation (non-growth) and aspects of the foun-
dation of probability theory. Probl. Inf. Transm. 10, 206–210 (1974)
9. Li, M., Vitanyi, P.: An Introduction to Kolmogorov Complexity and Its Applica-
tions, 3rd edn. Springer, New York (2008)
10. Miclet, L., Delhay, A.: Relation d’analogie et distance sur un alphabet d´eﬁni par
des traits. Technical Report 1632, IRISA, July 2004
11. Miclet, L., Delhay, A.: Analogical dissimilarity: deﬁnition, algorithms and ﬁrst
experiments in machine learning. Technical Report RR-5694, INRIA, July 2005
12. Miclet, L., Prade, H.: Logical deﬁnition of analogical proportion and its fuzzy exten-
sions. In: Annual Meeting of the North American Fuzzy Information Processing
Society (NAFIPS), New-York, pp. 1–6. IEEE (2008)
13. Miclet, L., Prade, H.: Handling analogical proportions in classical logic and
fuzzy logics settings. In: Sossai, C., Chemello, G. (eds.) ECSQARU 2009.
LNCS (LNAI), vol. 5590, pp. 638–650. Springer, Heidelberg (2009). doi:10.1007/
978-3-642-02906-6 55
14. Prade, H., Richard, G.: From analogical proportion to logical proportions. Logica
Universalis 7(4), 441–505 (2013)
15. Prade, H., Richard, G.: Homogenous and heterogeneous logical proportions.
IfCoLog J. Logics Appl. 1(1), 1–51 (2014)
16. Shannon, C.E.: A mathematical theory of communication. Bell Syst. Tech. J. 27(3),
379–423 (1948)
17. Soler-Toscano, F., Zenil, H., Delahaye, J.P., Gauvrit, N.: Correspondence and
independence of numerical evaluations of algorithmic information measures. Com-
putability 2, 125–140 (2013)
18. Solomonoﬀ, R.J.: A formal theory of inductive inference. Part i and ii. Inf. Control
7(1), 1–22 and 224–254 (1964)
19. Stroppa, N., Yvon, F.: Du quatri`eme de proportion comme principe inductif: une
proposition et son application `a l’apprentissage de la morphologie. Traitement
Automatique des Langues 47(2), 1–27 (2006)

Argumentation

Evaluation of Arguments
in Weighted Bipolar Graphs
Leila Amgoud(B) and Jonathan Ben-Naim
IRIT – CNRS, 118, route de Narbonne, 31062 Toulouse, France
{amgoud,bennaim}@irit.fr
Abstract. The paper tackled the issue of arguments evaluation in
weighted bipolar argumentation graphs (i.e., graphs whose arguments
have basic strengths, and may be both supported and attacked). We
introduce axioms that an evaluation method (or semantics) could sat-
isfy. Such axioms are very useful for judging and comparing semantics.
We then analyze existing semantics on the basis of our axioms, and ﬁnally
propose a new semantics for the class of acyclic graphs.
1
Introduction
Argumentation is a form of common-sense reasoning consisting of the justiﬁ-
cation of claims by arguments. The latter have generally basic strengths, and
may be attacked and/or supported by other arguments, leading to the so-called
bipolar argumentation graphs (BAGs). Several methods, called semantics, were
proposed in the literature for the evaluation of arguments in such settings. They
can be partitioned into two main families: extension semantics [1–5], and gradual
semantics [6–8]. The former extend Dung’s semantics [9] for accounting for sup-
ports, and look for acceptable sets of arguments (called extensions). The latter
focus on the evaluation of individual arguments.
This paper extends our previous works on axiomatic foundations of seman-
tics for unipolar graphs (support graphs [10] and attack graphs [11]). It deﬁnes
axioms (i.e. properties) that a semantics should satisfy in a bipolar setting.
Such axioms are very useful for judging and understanding the underpinnings
of semantics, and also for comparing semantics of the same family, and those of
diﬀerent families. Some of the proposed axioms are simple combinations of those
proposed in [10,11]. Others are new and show how support and attack should be
aggregated. The second contribution of the paper consists of analyzing existing
semantics against the axioms. The main conclusion is that extension seman-
tics do not harness the potential of support relation. Indeed, when the attack
relation is empty, the existing semantics declare all (supported, non-supported)
arguments of a graph as equally accepted. Gradual semantics take into account
supporters in this particular case, however they violate some key axioms. The
third contribution of the paper is the deﬁnition of a novel gradual semantics for
the sub-class of acyclic bipolar graphs. We show that it satisﬁes all the proposed
axioms. Furthermore, it avoids the big jump problem that impedes the relevance
of existing gradual semantics for practical applications, like dialogue.
c
⃝Springer International Publishing AG 2017
A. Antonucci et al. (Eds.): ECSQARU 2017, LNAI 10369, pp. 25–35, 2017.
DOI: 10.1007/978-3-319-61581-3 3

26
L. Amgoud and J. Ben-Naim
The paper is structured as follows: Sect. 2 introduces basic notions, Sect. 3
presents our list of axioms as well as some properties, Sect. 4 analyses existing
semantics, and Sect. 5 introduces our new semantics and discusses its properties.
2
Main Concepts
This section introduces the main concepts of the paper. Let us begin with weight-
ings:
Deﬁnition 1 (Weighting). A weighting on a set X is a function from X to
[0, 1].
Next, we introduce weighted bipolar argumentation graphs (BAGs).
Deﬁnition 2 (BAG). A BAG is a quadruple A = ⟨A, w, R, S⟩, where A is a
ﬁnite set of arguments, w a weighting on A, R ⊆A × A, and S ⊆A × A.
Given two arguments a and b, aRb (resp. aSb) means a attacks (resp. sup-
ports) b, and w(a) is the intrinsic strength of a. The latter may be the certainty
degree of the argument’s premises, trustworthiness of the argument’s source, . . ..
We turn to the core concept of the paper. A semantics is a function trans-
forming any weighted bipolar argumentation graph into a weighting on the set
of arguments. The weight of an argument given by a semantics represents its
overall strength or acceptability degree. It is obtained from the aggregation of
its intrinsic strength and the overall strengths of its attackers and supporters.
Arguments that get value 1 are extremely strong whilst those that get value 0
are worthless.
Deﬁnition 3 (Semantics). A semantics is a function S transforming any BAG
A = ⟨A, w, R, S⟩into a weighting f on A. Let a ∈A, we denote by DegS
A(a) the
acceptability degree of a, i.e., DegS
A(a) = f(a).
Let us recall the notion of isomorphism between graphs.
Deﬁnition 4 (Isomorphism). Let A = ⟨A, w, R, S⟩and A′ = ⟨A′, w′, R′, S′⟩
be two BAGs. An isomorphism from A to A′ is a bijective function f from A to
A′ such that: (i) ∀a ∈A, w(a) = w′(f(a)), (ii) ∀a, b ∈A, aRb iﬀf(a)R′f(b),
(iii) ∀a, b ∈A, aSb iﬀf(a)S′f(b).
Notations: Let A = ⟨A, w, R, S⟩be a BAG and a ∈A. We denote by AttA(a)
the set of all attackers of a in A (i.e., AttA(a) = {b ∈A | bRa}), and by
sAttA(a) the set of all signiﬁcant attackers of a, i.e., attackers x of a such that
DegS
A(x) ̸= 0. Similarly, we denote by SuppA(a) the set of all supporters of a
(i.e., SuppA(a) = {b ∈A | bSa}) and by sSuppA(a) the signiﬁcant supporters of
a, i.e., supporters x such that DegS
A(x) ̸= 0.
Let A′ = ⟨A′, w′, R′, S′⟩be another BAG such that A ∩A′ = ∅. We denote
by A ⊕A′ the BAG ⟨A′′, w′′, R′′, S′′⟩such that A′′ = A ∪A′, R′′ = R ∪R′,
S′′ = S ∪S′, and ∀x ∈A′′, the following holds: w′′(x) = w(x), if x ∈A;
w′′(x) = w′(x), if x ∈A′.

Evaluation of Arguments in Weighted Bipolar Graphs
27
3
Axioms for Acceptability Semantics
In what follows, we propose axioms that shed light on foundational principles
behind semantics. In other words, properties that help us to better understand
the underpinnings of semantics, and that facilitate their comparisons. The ﬁrst
nine axioms are simple combinations of axioms proposed for graphs with only
one type of interactions (support in [10], attack in [11]). The three last axioms
are new and show how the overall strengths of supporters and attackers of an
argument should be aggregated.
The ﬁrst very basic axiom, Anonymity, states that the degree of an argument
is independent of its identity. It combines the two Anonymity axioms from [10,11].
Axiom 1 (Anonymity). A semantics S satisﬁes anonymity iﬀ, for any two
BAGs A = ⟨A, w, R, S⟩and A′ = ⟨A′, w′, R′, S′⟩, for any isomorphism f from
A to A′, the following property holds: ∀a ∈A, DegS
A(a) = DegS
A′(f(a)).
Bi-variate independence axiom states the following: the acceptability degree
of an argument a should be independent of any argument b that is not connected
to it (i.e., there is no path from b to a, ignoring the direction of the edges). This
axiom combines the two independence axioms from [10,11].
Axiom 2 (Bi-variate Independence). A semantics S satisﬁes bi-variate
independence iﬀ, for any two BAGs A = ⟨A, w, R, S⟩and A′ = ⟨A′, w′, R′, S′⟩
such that A ∩A′ = ∅, the following property holds: ∀a ∈A, DegS
A(a) =
DegS
A⊕A′(a).
Bi-variate directionality axiom combines Non-Dilution from [10] and Cir-
cumscription from [11]. It states that the overall strength of an argument should
depend only on its incoming arrows, and thus not on the arguments it itself
attacks or supports.
Axiom 3 (Bi-variate Directionality).
A semantics S satisﬁes bi-variate
directionality iﬀ, for any two BAGs A = ⟨A, w, R, S⟩, A′ = ⟨A′, w′, R′, S′⟩
such that A = A′, R ⊆R′, and S ⊆S′, the following holds: for all a, b, x ∈A,
if R′ ∪S′ = R ∪S ∪{(a, b)} and there is no path from b to x, then DegS
A(x) =
DegS
A′(x). Note that a path can mix attack and support relations, but the edges
must always be directed from b to x.
Bi-variate Equivalence axiom ensures that the overall strength of an argu-
ment depends only on the overall strengths of its direct attackers and supporters.
It combines the two equivalence axioms from [10,11].
Axiom 4 (Bi-variate Equivalence).
A semantics S satisﬁes bi-variate
equivalence iﬀ, for any BAG A = ⟨A, w, R, S⟩, for all a, b ∈A, if:
– w(a) = w(b),
– there exists a bijective function f from AttA(a) to AttA(b) such that ∀x ∈
AttA(a), DegS
A(x) = DegS
A(f(x)), and

28
L. Amgoud and J. Ben-Naim
– there exists a bijective function f ′ from SuppA(a) to SuppA(b) such that ∀x ∈
SuppA(a), DegS
A(x) = DegS
A(f(x)),
then DegS
A(a) = DegS
A(b).
Stability axiom combines Minimality [10] and Maximality [11] axioms. It
says the following: if an argument is neither attacked nor supported, its overall
strength should be equal to its intrinsic strength.
Axiom 5 (Stability). A semantics S satisﬁes stability iﬀ, for any BAG A =
⟨A, w, R, S⟩, for any argument a ∈A, if AttA(a) = SuppA(a) = ∅, then
DegS
A(a) = w(a).
Neutrality axiom generalizes Dummy axiom [10] and Neutrality one from
[11]. It states that worthless attackers or supporters have no eﬀect.
Axiom 6 (Neutrality).
A semantics S satisﬁes neutrality iﬀ, for any BAG
A = ⟨A, w, R, S⟩, ∀a, b, x ∈A, if:
– w(a) = w(b),
– AttA(a) ⊆AttA(b),
– SuppA(a) ⊆SuppA(b),
– AttA(b) ∪SuppA(b) = AttA(a) ∪SuppA(a) ∪{x}, and DegS
A(x) = 0,
then DegS
A(a) = DegS
A(b).
Bi-variate Monotony states the following: if an argument a is equally or less
attacked than an argument b, and equally or more supported than b, then a
should be equally strong or stronger than b. This axiom generalizes 4 axioms
from the literature (Monotony and Counting [10] for supports, and the same
axioms from [11] for attacks).
Axiom 7 (Bi-variate
Monotony).
A semantics S satisﬁes
bi-variate
monotony iﬀ, for any BAG A = ⟨A, w, R, S⟩, for all a, b ∈A such that:
– w(a) = w(b) > 0,
– AttA(a) ⊆AttA(b),
– SuppA(b) ⊆SuppA(a),
the following holds:
– DegS
A(a) ≥DegS
A(b),
(Monotony)
– if (DegS
A(a) > 0 or DegS
A(b) < 1) and (sAttA(a) ⊂sAttA(b), or sSuppA(b) ⊂
sSuppA(a)), then DegS
A(a) > DegS
A(b).
(Strict Monotony)
The next axiom combines the Reinforcement axioms of [10,11]. It states that
any argument becomes stronger if the quality of its attackers is reduced and the
quality of its supporters is increased.
Axiom 8 (Bi-variate Reinforcement).
A semantics S satisﬁes bi-variate
reinforcement iﬀ, for any BAG A = ⟨A, w, R, S⟩, for all C, C′ ⊆A, for all
a, b ∈A, for all x, x′, y, y′ ∈A\(C ∪C′) such that

Evaluation of Arguments in Weighted Bipolar Graphs
29
– w(a) = w(b) > 0,
– DegS
A(x) ≤DegS
A(y),
– DegS
A(x′) ≥DegS
A(y′),
– AttA(a) = C ∪{x},
– AttA(b) = C ∪{y},
– SuppA(a) = C′ ∪{x′},
– SuppA(b) = C′ ∪{y′},
the following holds:
– DegS
A(a) ≥DegS
A(b),
(Reinforcement)
– if (DegS
A(a) > 0 or DegS
A(b) < 1) and (DegS
A(x) < DegS
A(y), or DegS
A(x′) >
DegS
A(y′)), then DegS
A(a) > DegS
A(b).
(Strict Reinforcement)
Our next axiom combines Imperfection axiom from [10] with Resilience axiom
from [11]. Imperfection states that an argument whose basic strength is less than
1 cannot be fully rehabilitated by supports. In other words, it cannot get an
acceptability degree 1 due to supports. This axiom prevents irrational behaviors,
like fully accepting fallacious arguments that are supported. Below, the argument
A remains fallacious even if it is supported by B.
A: Tweety needs fuel, since it ﬂies like planes.
B: Indeed, Tweety ﬂies. It is a bird.
Resilience in [11] states that an argument whose basic strength is positive
cannot be completely destroyed by attacks. Assume that B is attacked by the
argument C below. Despite the attack, the argument B is still reasonable.
C: Tweety does not ﬂy since it is a penguin
Axiom 9 (Resilience). A semantics S satisﬁes resilience iﬀ, for any BAG
A = ⟨A, w, R, S⟩, for all a ∈A, if 0 < w(a) < 1, then 0 < Deg(a) < 1.
The next three axioms are new and answer the same question: how the overall
strengths of attackers and supporters of an argument are aggregated? To answer
this question, it is important to specify which of the two types of interactions is
more important. In this paper, we consider both relations as equally important.
Hence, Franklin axiom states that an attacker and a supporter of equal strength
should counter-balance each other. Thus, neither attacks nor supports will have
impact on the argument.
Axiom 10 (Franklin). A semantics S satisﬁes franklin iﬀ, for any BAG A =
⟨A, w, R, S⟩, for all a, b, x, y ∈A, if
– w(b) = w(a),
– DegS
A(x) = DegS
A(y)
– AttA(a) = AttA(b) ∪{x},
– SuppA(a) = SuppA(b) ∪{y},
then DegS
A(a) = DegS
A(b).

30
L. Amgoud and J. Ben-Naim
We show that attacks and supports of equal strengths eliminate each others.
Proposition 1. Let S be a semantics that satisﬁes Bi-variate Independence, Bi-
variate Directionality, Stability and Franklin. For any BAG A = ⟨A, w, R, S⟩,
for all a ∈A, if there exists a bijective function f from AttA(a) to SuppA(a)
such that ∀x ∈Att(a), DegS
A(x) = DegS
A(f(x)), then DegS
A(a) = w(a).
Weakening states that if attackers overcome supporters, the argument should
loose weight. The idea is that supports are not suﬃcient for counter-balancing
attacks. Please note that this does not means that supports will not have an
impact on the overall strength of an argument. They may mitigate the global
loss due to attacks.
Axiom 11 (Weakening). A semantics S satisﬁes weakening iﬀ, for any BAG
A = ⟨A, w, R, S⟩, for all a ∈A, if w(a) > 0 and there exists an injective
function f from SuppA(a) to AttA(a) such that:
– ∀x ∈SuppA(a), Deg(x) ≤Deg(f(x)); and
– sAttA(a)\{f(x) | x ∈SuppA(a)} ̸= ∅or ∃x ∈SuppA(a) s.t Deg(x) <
Deg(f(x)),
then Deg(a) < w(a).
Strengthening states that if supporters overcome attackers, the argument
should gain weight. Indeed, attacks are not suﬃcient for counter-balancing sup-
ports, however, they may mitigate the global gain due to supports.
Axiom 12 (Strengthening). A semantics S satisﬁes strengthening iﬀ, for
any BAG A = ⟨A, w, R, S⟩, for all a ∈A, if w(a) < 1 and there exists an
injective function f from AttA(a) to SuppA(a) such that:
– ∀x ∈AttA(a), Deg(x) ≤Deg(f(x)); and
– sSuppA(a)\{f(x) | x ∈AttA(a)} ̸= ∅or ∃x ∈AttA(a) s.t. Deg(x) <
Deg(f(x)),
then Deg(a) > w(a).
It is worth mentioning that weakening and strengthening generalize their
corresponding axioms in [10,11]. Indeed, when the support relation is empty,
bipolar version of weakening coincides with weakening axiom in [11]. However, it
handles additional cases when supports exist. Similarly, when the attack relation
is empty, the axiom coincides with strengthening axiom in [10].
Almost all axioms are independent, i.e., they do not follow from others. A
notable exception is Bivariate Monotony which follows from ﬁve axioms.
Proposition 2. If a semantics satisﬁes Bi-variate Independence, Bi-variate
Directionality, Stability, Neutrality and Bi-variate Reinforcement, then it sat-
isﬁes Bivariate Monotony.
All axioms are compatible, i.e., they can be satisﬁed all together by a
semantics.
Proposition 3. All the axioms are compatible.

Evaluation of Arguments in Weighted Bipolar Graphs
31
4
Formal Analysis of Existing Semantics
There are several proposals in the literature for the evaluation of arguments
in bipolar argumentation graphs. They can be partitioned into two families:
extension semantics [1–5] and gradual semantics [6–8].
Extension semantics extend Dung’s semantics [9] for accounting for supports
between arguments. They take as input an argumentation graph ⟨A, w, R, S⟩
whose arguments have all the same basic strength, and return sets of argu-
ments, called extensions. From the extensions, a three-valued qualitative degree
is assigned to every argument. Indeed, an argument is accepted if it belongs to
all extensions, undecided (or credulously accepted) if it belongs to some but not
all extensions, and rejected if it does not belong to any extension. When the
support relation is empty, the semantics proposed in [1–5] coincide with Dung’s
ones. Thus, they violate the axioms that are violated by Dung’s semantics (see
[11] for a detailed analysis of Dung’s semantics). For instance, stable semantics
violates Independence, Equivalence, Stability, Resilience, and strict monotony.
When the attack relation is empty, the approaches from [1,2,4] return a sin-
gle extension, which contains all the arguments of the BAG at hand. Thus, all
arguments are equally accepted. This shows that the support relation does not
play any role, and a supported argument is as acceptable as a non-supported
one. To say it diﬀerently, these approaches violate strengthening axiom which
captures the role of supports. The approaches developed in [3,5] return a single
extension when the attack relation is empty. This extension coincides with the
set of arguments when there are no cycles in the BAG. Thus, they also vio-
late strengthening and the support relation may not be fully exploited in the
evaluation of arguments.
The second family of gradual semantics was introduced for the ﬁrst time in [6].
In their paper, the authors presented some properties that such semantics should
satisfy (like a particular case of strengthening). However, they did not deﬁne
concrete semantics. To the best of our knowledge, the ﬁrst gradual semantics
is QuAD, introduced in [7], for evaluating arguments in acyclic graphs. This
semantics assigns a numerical value to every argument on the basis of its intrinsic
strength, and the overall strengths of its attackers and supporters. It evaluates
separately the supporters and the attackers before aggregating them. Due to
lack of space, we do not provide the formal deﬁnitions.
Proposition 4. QuAD satisﬁes Anonymity, Bi-variate Independence, Bi-
variate Directionality, Bi-variate Equivalence, Stability, Neutrality, Monotony,
Reinforcement.
QuAD violates Strict Monotony, Strict Reinforcement, Resilience, Franklin,
Weakening, and Strengthening.
As a consequence of violating Weakening and Strengthening, QuAD may
behave irrationally. Consider a BAG where A = {a, b1, b2, b3}, w(b1) = w(b2) =
0.8, w(b3) = 0.9, R = {(b2, a), (b3, a)}, and S = {(b1, a)}. Thus, a has an
attacker and a supporter of equal strengths, and an additional attacker b3. Note

32
L. Amgoud and J. Ben-Naim
that if w(a) = 0.2, then DegS
A(a) = 0.422 meaning that the single supporter
is privileged to the two attackers. However, if w(a) = 0.7, DegS
A(a) = 0.477
meaning that attacks are privileged to support. More generally, we can show
that if w(a) ≥0.5, then DegS
A(a) < w(a), else DegS
A(a) > w(a). Hence, choosing
which of support and attack should take precedence depends on the intrinsic
strength of an argument.
QuAD was recently extended to DF-QuAD in [8]. The new semantics focuses
also on acyclic graphs. Unlike QuAD, it uses the same function for aggregating
supporters and attackers separately. It satisﬁes Franklin axiom, thus it treats
equally attacks and supports. It violates Strengthening and Weakening in pres-
ence of attackers/supporters of degree 1. However, the semantics avoids the
irrational behavior of QuAD.
Proposition 5. DF-QuAD satisﬁes Anonymity, Bi-variate Independence, Bi-
variate Directionality, Bi-variate Equivalence, Stability, Neutrality, Monotony,
Reinforcement, and Franklin. DF-QuAD violates Strict Monotony, Strict Rein-
forcement, Resilience, Weakening, and Strengthening.
Both semantics (QuAD and DF-QuAD) suﬀer from a big jump problem.
Let us illustrate the problem with the BAG depicted in Fig. 1. Note that the
argument i has a very low basic strength (w(i) = 0.1). This argument is sup-
ported by the very strong argument j. According to QuAD and DF-QuAD,
DegS
A(i) = 0.991. Thus, the value of i makes a big jump from 0.1 to 0.991. The
argument i became even stronger than its supporter j. There are two issues with
such jump: First, the gain is enormous and not reasonable. Assume that i is the
argument “Tweety needs fuel, since it ﬂies like planes”. It is hard to accept i
even when supported. The supporter may increase slightly the strength of the
argument but does not correct the wrong premises of the argument. Second,
such jump impedes the discrimination between diﬀerent cases where w(i) > 0.1
since whatever the value of w(i), the overall strength is almost 1.
5
Euler-Based Graded Semantics
As shown in the previous sections, no existing semantics satisﬁes all our 12
axioms together. The goal of the present section is to handle this issue. More
precisely, we construct a new semantics satisfying all axioms, but at the cost of a
certain degree of coverage. Indeed, we only consider a subclass of BAGs: acyclic
non-maximal BAGs.
Deﬁnition 5 (BAG properties).
A BAG A = ⟨A, w, R, S⟩is acyclic iﬀ
the following holds: for any non-empty ﬁnite sequence a = ⟨a1, a2, . . . , an⟩of
elements of A, if ∀i ∈{1, 2, . . . , n−1}, ⟨ai, ai+1⟩∈R∪S, then ⟨an, a1⟩̸∈R∪S.
Next, A is non-maximal iﬀ∀a ∈A, w(a) < 1.
Without loss of generality, the basic strengths of arguments are less than
1. Note that few arguments are intrinsically perfect. The probability of false

Evaluation of Arguments in Weighted Bipolar Graphs
33
information, exceptions, etc., is rarely 0. In contrast, the loss of cyclic BAGs is
important. But, we consider that the class of all acyclic non-maximal BAGs is
expressive enough to deserve attention.
Deﬁnition 6 (Restricted semantics). A restricted semantics is a function S
transforming any acyclic non-maximal BAG A = ⟨A, w, R, S⟩into a weighting
on A.
All notations and axioms for semantics are straightforwardly adapted to
restricted semantics. Before presenting our semantics, we need to introduce a
relation between arguments based on the longest paths to reach them (mixing
support and attack arrows).
Deﬁnition 7 (Well-founded relation). Let A = ⟨A, w, R, S⟩be an acyclic
BAG and a ∈A. A path to a in A is a non-empty ﬁnite sequence a =
⟨a1, a2, . . . , an⟩of elements of A such that an = a and ∀i ∈{1, 2, . . . , n −1},
⟨ai, ai+1⟩∈R ∪S. We denote by Rel(A) the well-founded binary relation ≺
on A such that ∀x, y ∈A, x ≺y iﬀmax{n | there exists a path to x of length
n} < max{n | there exists a path to y of length n}. Since A is acyclic, those
maximum lengths are well-deﬁned, so is Rel(A).
We are ready to deﬁne the Euler-based restricted semantics. The general
idea is to take into account supporters and attackers in an exponent E of e (the
Euler’s number). More precisely, the stronger or more-numerous the support-
ers, the greater and more-likely-positive that exponent. Obviously, the inverse
is true with the attackers. Then, the overall strength of an argument a is natu-
rally deﬁned as w(a)eE. Finally, we need certain tweakings (including a double
polarity reversal) to make our function a restricted semantics in the ﬁrst place,
and to have it satisfy all our axioms. More formally:
Deﬁnition 8 (Euler-based
restricted
semantics).
We denote by Ebs
the restricted semantics such that for any acyclic non-maximal BAG A =
⟨A, w, R, S⟩, Ebs(A) is the weighting f on A recursively deﬁned with Rel(A)
as follows: ∀a ∈A,
f(a) = 1 −1 −w(a)2
1 + w(a)eE
where
E =

x∈Supp(a)
f(x) −

x∈Att(a)
f(x).
As an immediate corollary, we have:
Corollary 1. Let A = ⟨A, w, R, S⟩be an acyclic non-maximal BAG and a ∈A. The
following holds:
DegEbs
A (a) = 1 −1 −w(a)2
1 + w(a)eE
where
E =

x∈Supp(a)
DegEbs
A (x) −

x∈Att(a)
DegEbs
A (x).
Below is an example where most axioms are exempliﬁed. Every circle contains
[argument name]:[intrinsic strength] and below [overall strength].

34
L. Amgoud and J. Ben-Naim
d:0.22
0.22
a:0.60
0.60
g:0.00
0.00
e:0.40
0.40
b:0.60
0.54
i:0.10
0.22
j:0.99
0.99
h:0.99
0.99
f:0.40
0.27
c:0.60
0.53
Fig. 1. Example of BAG
Example 1. The axiom neutrality can be checked with g and e, stability with
e.g. d, bivariate monotony with a and b, bivariate reinforcement with b and c,
Imperfection with i, Franklin with a, weakening with e.g. b, and strengthening
with i.
Theorem 1. Ebs satisﬁes all our 12 axioms.
Note that being supported by an extremely strong argument does not cause
a weak argument to become extremely strong as well, which shows that Ebs does
not suﬀer from the big jump problem. Note that DegEbs
A (i) = 0.22 and thus the
jump is not big. Note also that by satisfying Weakening and Strengthening, the
semantics avoids the irrational behavior of QuAD.
6
Conclusion
The paper presented for the ﬁrst time axioms that serve as guidelines for deﬁn-
ing acceptability semantics in weighted bipolar settings. It also analyzed existing
semantics with regard to the axioms. The results revealed that extension-based
semantics like [1–5] fail to satisfy key properties. Furthermore, the role of sup-
port relation is a bit ambiguous since in case the attack relation of a BAG
is empty, the argumentation graph has a single extension containing all the
arguments. This means that supported and non-supported arguments are all
equally acceptable. Gradual semantics deﬁned in [7,8] satisfy more but not all
the axioms. We proposed a novel semantics which satisﬁes all the 12 axioms.
However, this semantics deals only with acyclic graphs. An urgent future work
would be to prove whether the sequence of values it returns converges in case of
arbitrary graphs. We also plan to investigate additional properties where attacks
and supports do not have the same importance.
Acknowledgments. This work was supported by ANR-13-BS02-0004 and ANR-11-
LABX-0040-CIMI.

Evaluation of Arguments in Weighted Bipolar Graphs
35
References
1. Cayrol, C., Lagasquie-Schiex, M.C.: On the acceptability of arguments in bipolar
argumentation frameworks. In: Godo, L. (ed.) ECSQARU 2005. LNCS, vol. 3571,
pp. 378–389. Springer, Heidelberg (2005). doi:10.1007/11518655 33
2. Oren, N., Norman, T.: Semantics for evidence-based argumentation. In: Proceed-
ings of COMMA, pp. 276–284 (2008)
3. Brewka, G., Woltran, S.: Abstract dialectical frameworks. In: Proceedings of KR
(2010)
4. Boella, G., Gabbay, D.M., van der Torre, L., Villata, S.: Support in abstract argu-
mentation. In: Proceedings of COMMA, pp. 111–122 (2010)
5. Nouioua, F., Risch, V.: Bipolar argumentation frameworks with specialized sup-
ports. In: International Conference on Tools with Artiﬁcial Intelligence, ICTAI
2010, pp. 215–218 (2010)
6. Cayrol, C., Lagasquie-Schiex, M.C.: Gradual valuation for bipolar argumentation
frameworks. In: Godo, L. (ed.) ECSQARU 2005. LNCS, vol. 3571, pp. 366–377.
Springer, Heidelberg (2005). doi:10.1007/11518655 32
7. Baroni, P., Romano, M., Toni, F., Aurisicchio, M., Bertanza, G.: Automatic eval-
uation of design alternatives with quantitative argumentation. Argum. Comput.
6(1), 24–49 (2015)
8. Rago, A., Toni, F., Aurisicchio, M., Baroni, P.: Discontinuity-free decision support
with quantitative argumentation debates. In: Proceedings of KR, pp. 63–73 (2016)
9. Dung, P.M.: On the acceptability of arguments and its fundamental role in non-
monotonic reasoning, logic programming and n-person games. Artif. Intell. 77,
321–357 (1995)
10. Amgoud, L., Ben-Naim, J.: Evaluation of arguments from support relations: axioms
and semantics. In: Proceedings of IJCAI, pp. 900–906 (2016)
11. Amgoud, L., Ben-Naim, J.: Axiomatic foundations of acceptability semantics. In:
Proceedings of KR, pp. 2–11 (2016)

Debate-Based Learning Game for Constructing
Mathematical Proofs
Nadira Boudjani, Abdelkader Gouaich, and Souhila Kaci(B)
LIRMM, Montpellier, France
{boudjani,gouaich,kaci}@lirmm.fr
Abstract. Debate is a valuable and eﬀective method of learning. It is
an interactive process in which learners cooperate by exchanging argu-
ments and counter-arguments to solve a common question. We propose a
debate-based learning game for mathematics classroom to teach how to
structure and build mathematical proofs. Dung’s argumentation frame-
work and its extensions are used as a means to extract acceptable argu-
ments that form the proof. Moreover this allows instructors to provide
continuous feedbacks to learners without information overload.
1
Introduction
Debate has been used as a learning method since antiquity notably by sophists
such as Protagoras, Plato and Socrates. From that time, the principles of this
method remained unchanged: a group of learners explore a common question
by exchanging opinions, ideas in the form of arguments and counter-arguments.
Such debates are based on a collaborative and progressive learning process. What
has changed however are technologies that nowadays enable autonomous and
ubiquitous learning.
The literature of educational science witnesses numerous examples of debate-
based learning [14,20]. Furthermore, the use of debate in several areas such as
medicine, natural sciences and humanities has been experimentally demonstrated
as an eﬀective learning tool [3,8]. In the ﬁelds of mathematics, [15] proposes a
description of Lakatos’s method by a dialogue game for collaborative mathe-
matics. In short, we can synthesize main advantages of debate-based learning
as follows: (i) it allows a group of heterogeneous learners with diﬀerent back-
grounds to collectively solve a common problem by using their own skills [1],
(ii) it improves critical thinking skills, reasoning and communication within a
group since each learner has to justify and defend her point of view and con-
structively criticize others [3,6], (iii) it increases motivation and involvement of
learners by improving self-esteem and promoting social interaction [13], (iv) it
makes explicit reasoning processes that led to conclusions. This provides instruc-
tors with information to identify misunderstandings and take actions to correct
them.
The context. We are interested in this paper in learning how to structure and
build mathematical proofs. Mathematical skills are increasingly becoming a cen-
tral criterion in skills evaluation as they are an important selection criterion for
c
⃝Springer International Publishing AG 2017
A. Antonucci et al. (Eds.): ECSQARU 2017, LNAI 10369, pp. 36–45, 2017.
DOI: 10.1007/978-3-319-61581-3 4

Debate-Based Learning Game for Constructing Mathematical Proofs
37
academic and professional applications. Therefore shortcomings in mathematics
may be highly detrimental to students in both academic and professional oppor-
tunities. In the context of mathematical didactics several works have shown
advantages of using debate in classes [5]. The object of the debate can be either
to build a mathematical proof or to falsify a claim using sound mathematical
deductions.
The problem and contribution. Despite the beneﬁts witnessed in debates-
based classes, we can mention some limitations of current approaches. The ﬁrst
limitation concerns learner’s motivation and involvement. Although it has been
demonstrated that learners show a high motivation in debate-based courses [8],
it has also been acknowledged that this is inﬂuenced by instructor’s animation
abilities and the fact that these courses are formal and mandatory. In order
to promote an autonomous and ubiquitous learning beyond institutional envi-
ronment, we propose a gamiﬁcation approach that considers the debate as a
genuine game with its intrinsic motivation levers. The second limitation con-
cerns assessment of debate outcomes and its eﬀect on instructors’ workload. In
fact, assessment is fundamental in order to provide learners with continuous
feedbacks. This task is often performed manually by the instructor who has to
understand, evaluate and provide feedbacks based on the state of the debate.
However, debate data are often overloaded by details of intermediate and erro-
neous stages of reasoning. While these stages are important to understand how
learners have come to ﬁnal conclusions, they do overload instructors with unnec-
essary details during assessment phases. As the basic ingredients in debates are
arguments and counter-arguments, we use formal argumentation framework as
a means to extract ﬁnal conclusions from a debate before its assessment by
instructors.
The remainder of this paper is structured as follows. In Sect. 2 we provide
necessary background on argumentation. In Sect. 3 we introduce our system for
debate-based learning through argumentation and games. In Sect. 4 we illustrate
our system with an example on a group of learners. Lastly we conclude.
2
Background on Formal Argumentation Frameworks
Artiﬁcial intelligence witnesses a large amount of contributions in argumentation
theory. In particular Dung’s argumentation framework is a pioneer work in the
topic [4].
Deﬁnition 1 (Dung’s Framework). An argumentation framework (AF) is a
tuple ⟨A, Def⟩, where A is a ﬁnite set of arguments and Def ⊆A×A is a binary
defeat1 relation. Given A, B ∈A, A Def B stands for “A defeats B”.
The outcome of Dung’s AF is sets of arguments, called extensions, that are
robust against defeats [4]. We say that T ⊆A defends A if ∀B ∈A s.t. B Def
A, ∃C ∈T such that C Def B. We say that T ⊆A is conﬂict-free if ∄A, B ∈T
1 Called attack in [4].

38
N. Boudjani et al.
such that A Def B. A subset T ⊆A of arguments is an admissible extension iﬀit
is conﬂict-free and it defends all elements in T . Diﬀerent acceptability semantics
have been proposed. In particular T ⊆A is a complete extension of ⟨A, Def⟩
iﬀit is admissible and contains all arguments it defends. T is a grounded exten-
sion ⟨A, Def⟩iﬀit is minimal (for set inclusion) complete extension. For other
semantics, see [4].
Several authors have considered a new kind of interaction called the support
relation [2,11,12]. An abstract bipolar argumentation framework is an extension
of Dung’s framework such that both defeat and support relations are considered.
Deﬁnition 2 (Bipolar argumentation framework). An abstract bipolar
argumentation framework (BAF) is a tuple ⟨A, Def, Supp⟩, where ⟨A, Def⟩is
Dung’s AF and Supp ⊆A × A is a binary support relation. For A, B ∈A, A
Supp B means “A supports B”.
Defeat and support relations are combined to compute new defeat relations
and recover Dung’s framework from which acceptable extensions are computed
[2,11,12].
In this paper we are interested in deductive reasoning, i.e. a conclusion is
derived from a set of premises.
Deﬁnition 3 (Argument).
Let Γ be a set of formulas constructed from a
given language L. An argument over Γ is a pair A = ⟨Δ, α⟩s.t. (i) Δ ⊆Γ, (ii)
Δ ̸⊢∗⊥, (iii) Δ ⊢∗α and, (iv) for all Δ′ ⊂Δ, Δ′ ̸⊢∗α, where ⊢∗is the inference
symbol.
We say that ⟨Δ, α⟩undercuts ⟨Δ′, α′⟩iﬀfor some φ ∈Δ′, α and φ are con-
tradictory w.r.t. the language at hand. ⟨Δ, α⟩rebuts ⟨Δ′, α′⟩iﬀα and α′ are
contradictory. Then, ⟨Δ, α⟩defeats ⟨Δ′, α′⟩iﬀ⟨Δ, α⟩rebuts/undercuts ⟨Δ′, α′⟩.
3
A Debate-Based Learning Game
Our system builds on learners who exchange arguments for some purpose. The
Oracle represents the instructor of the game. She opens the discussion by pro-
viding a ﬁrst argument of the form ⟨P, C⟩, where P is a set of premises and C
is a conclusion. Then learners are engaged in a debate in which they exchange
arguments to construct a proof for C given P. A set of relations is provided by
the Oracle to connect arguments. A learner may add an argument/relation or
pass her turn. The discussion is closed when decided by the learners or stopped
by the Oracle. The output of the debate is a debate graph which is composed of
arguments and relations constructed during the debate. The graph is submitted
to the Oracle for evaluation. We ﬁrst discuss and give our design choices. Then
we propose a game-based modeling of our learning system.

Debate-Based Learning Game for Constructing Mathematical Proofs
39
3.1
Design Choices
Diﬀerent factors need to be considered for the game. Before we present our
game-based modeling of the learning system let us expose these factors:
• Argumentation mechanisms: Three mechanisms have been distinguished to
model the exchange of arguments between agents [17]: In a Direct mechanism
every agent may propose a set of arguments at once. Then the process termi-
nates. This mechanism is not appropriate in our setting because a learning
process needs to be progressive. In a synchronous mechanism every agent
may propose any set of arguments at the same time. The process is repeated
until no agent wants to make more arguments. In a dialectical mechanism an
order is assumed over agents to provide their arguments. Four variants (rigid,
non rigid) × (single, multiple) can be obtained. A mechanism is rigid when an
agent who passed her turn will no longer be allowed to propose arguments.
The mechanism is not rigid if the agent is not discarded in such a situation.
Also an agent may propose a single argument or multiple arguments when she
takes her turn. As the purpose of the game is that all learners progressively
collaborate to construct a proof we use a dialectical, non rigid and single
argument mechanism.
• Construction of the arguments & their validity: Arguments may be provided
by the Oracle or constructed by learners. In the second case, the Oracle
provides a set of propositions upon which arguments will be constructed.
We choose the second option. Now whatever arguments are constructed or
provided we need to check their validity which refers to the satisfaction of
conditions (i)–(iv) in Deﬁnition 3. Condition (i) will always be satisﬁed as
arguments will be constructed from a set of propositions provided by the
Oracle. An argument that does not satisfy condition (ii) should be removed.
An argument that does not satisfy condition (iv) should be modiﬁed to make
its set of premises minimal. Let us now consider condition (iii). For exam-
ple the argument ⟨{p}, q⟩is not valid w.r.t. (iii) because q does not logically
follow from p. This argument should be removed. On the other hand, the
argument ⟨{(2−ϵ)(n+2) < 2n+1}, 2−ϵ < 2n+1
n+2 ⟩will be considered as valid
although 2 −ϵ < 2n+1
n+2 does not logically follow from (2 −ϵ)(n + 2) < 2n + 1
because the set of premises of the argument is not complete. In fact we need
an additional constraint, namely n+2 > 0. Such an argument can however be
accepted in a debate. Then learners have to cooperate in order to defeat the
argument or defend it by completing its set of premises. This is coherent with
a debate-based learning process in which arguments can be both collabora-
tively and progressively constructed. We distinguish between two ways to deal
with an argument that should be removed (e.g. ⟨{p}, q⟩or condition (ii) not
satisﬁed) or modiﬁed (condition (iv)). First notice that learners in the same
group cooperate in order to solve a problem. Therefore they may be allowed
to have a chat box by which they can discuss in order to convince a learner
that her argument is not valid and should be removed/modiﬁed. We expect
a cooperation from all learners. If not then the non valid argument will be

40
N. Boudjani et al.
refused by the Oracle (when the latter evaluates the debate graph at the end
of the debate) which leads to the failure of the group to construct a correct
proof. Another way to control the validity of an argument is to delegate this
task to the Oracle in which case an argument is added to the debate graph
only when it is valid. A penalty on the score of the group is applied each time
a learner proposes a non valid argument. We choose the ﬁrst option.
If constructed arguments do not comply with Deﬁnition 3 and not
repaired/removed by learners then the group will fail to construct a correct
proof.
• Relations between arguments and their validity:
– Defeat relation: This relation is syntactically deﬁned and should be in
the background of learners. In contrast to existing works [16,17] in which
the defeat relation is automatically stated by the system as soon as an
agent proposes an argument we do believe that this relation should be
stated by the learners themselves. This is a part of the learning process.
Two ways to control the validity of a defeat relation are possible. Either
we authorize defeats on defeats which can be captured by hierarchical
argumentation frameworks [10], or the Oracle accepts a defeat relation in
the debate graph only when it is valid. We choose the second option in
our game.
– Support relation: we do not control the support relation because the objec-
tive of the game is to construct a proof which is built using the support
relation. So it is up to learners to discuss/agree on a given support relation
without the intervention of the Oracle.
• Termination of the game: The game terminates when the group stops or the
Oracle decides so. We choose the ﬁrst option in our game. The debate graph
is submitted to the Oracle for evaluation.
• Score function: A score which is a penalty degree is given to a group of learners
when its debate graph is evaluated by the Oracle. We deﬁne a penalty degree
as the number of irrelevant arguments present in the debate graph plus the
number of non valid defeat relations refused by the Oracle during the debate.
3.2
Game-Based Modeling of the Learning System
Our game aims at creating a debate environment for learners so that they can
exchange arguments to prove the Oracle’s claim. Learners need to be maintained
engaged in a game. For this purpose we use social levers of motivation: we divide
learners into groups that will be made in competition. The Oracle initiates the
debate by setting the question under the form of an argument. The group that
wins the game is the one that manages to build a debate graph accepted by
the Oracle with a minimal penalty. To construct such a graph, learners have to
use their domain knowledge to build arguments and correctly set relationships
between arguments. This section formalizes the game by describing states of the
game and actions which are transitions among states.

Debate-Based Learning Game for Constructing Mathematical Proofs
41
3.2.1
State of the Game
To construct arguments we use a universe of discourse based on a given L-
language. We assume that this language is at least equipped with a conjunction
operator. Given a set of arguments A and a set of relation labels L, a state
of a debate is a sequence of relations indexed by natural numbers and labels:
S : L × N →2A×A. S(l, k)l∈L, k∈N represents the content of the relation l at the
kth step. S denotes the set of all states.
3.2.2
Actions of the Game
Adding a relation. This action adds a new relationship between two (new or
existing) arguments. This action takes as input the label of the relation and two
arguments.
Deﬁnition 4. Given a relation label l ∈L and a couple of arguments (A, B), the
add action is a transition between states such that ∀S, S′ ∈S, S
add(l,A,B)
−→
S′ iﬀ
∃k ∈N, ∀r ∈L,
⎧
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎩
∀m > k, S′(r, m) = S(r, m) = ∅
∀n < k, S(r, n) = S′(r, n)
S(r, k) = ∅
S′(r, k) = S(r, k −1) for r ̸= l
S′(l, k) = S(l, k −1) ∪{(A, B)}
The add action makes a transition from S to S′ if and only if the follow-
ing conditions hold: (i) the game states contain only a ﬁnite number of known
relation graphs. In other words, there exists an integer k for which all relation
graphs of subsequent steps are empty, (ii) S and S′ are equal until kth step. This
means that S′ copies S until the kth step, (iii) game state S does not contain
any information about the relation l at step k, (iv) ﬁnally, game state S′ at kth
step is equal to the graph of l at the (k −1)th step to which the couple (A, B)
is added.
Removing a relation. A player can remove a relation between arguments from
the debate graph. This action takes as input the label of the relation and the
couple to be removed. Speciﬁcation of the remove action is similar to that of the
add action, except that S′ at kth step contains previous graph of l from which
the pair (A, B) has been removed. That is S′(l, k) = S(l, k −1)\{(A, B)}.
Append action. The goal of this action is to make an argument’s premises and
conclusion more speciﬁc. It is an auxiliary action that is built as a composition
of a remove and add actions. Before we deﬁne this action, let us introduce a
connector (∧) between arguments. Given A = ⟨P1, C1⟩and B = ⟨P2, C2⟩, the
notation A ∧B is an abbreviation for ⟨P1 ∪P2, C1 ∧C2⟩2.
Deﬁnition 5. The append relation between states S and S′ is deﬁned as:
∀S, S′ ∈S, S
append(l,A,B,C)
−→
S′ iﬀ∃S′′, S
remove(l,A,B)
−→
S′′ add(l,A∧C,B)
−→
S′.
2 Notice that P1 ∪P2 may be inconsistent but remind that the validity of arguments
is decided by learners.

42
N. Boudjani et al.
Submit action. This action ends the game and submits the ﬁnal debate state
to the Oracle for evaluation.
4
Example: Mathematical Proof
Let Q: “Prove that ∀ϵ > 0∃N ∈N such that (n ≥N ⇒2 −ϵ < 2n+1
n+2 < 2 + ϵ)”
to be proved. We have the Oracle and 6 learners (players): l1, l2, l3, l4, l5, l6.
The Oracle provides a ﬁrst argument A0 corresponding to Q. We have A0 =
⟨{ϵ > 0, ∃N ∈N, n ≥N}, 2 −ϵ < 2n+1
n+2 < 2 + ϵ)⟩. The Oracle also provides a set
of labels L = {defeat, support} and a set of propositions P:
{n ∈N,
2n+1
n+2 < 2, 2 −ϵ < 2n+1
n+2 ,
2n+1
n+2 < 2 + ϵ,
¬( 2n+1
n+2 < 2),
n ≥N,
ϵ > 0,
N > 3
ϵ −2,
n > 3
ϵ −2,
ϵ = −1,
n = 1,
¬(2 −ϵ < 2n+1
n+2 ), n = −3,
¬(N = [ 3
ϵ −2] + 1)
¬(n = −3), ¬(ϵ = −1), ∃N ∈N,
(2 −ϵ)(n + 2) < 2n + 1}.
The aim of the game is to demonstrate Q. Let Group1 and Group2 be two
groups of learners: G1 = {l1, l2, l3} and G2 = {l4, l5, l6}. Each group has to
demonstrate the proof individually. Not only the groups have to argue to con-
struct the proof but they also have to do that as fast as possible and with minimal
penalty degree. Due to space limitation, we illustrate the game on Group1 only.
Initially, the debate graph contains only A0. The discussion is dialectical: a ran-
dom order is deﬁned over the set of learners. Let l1, l2, l3 be this order. Table 1
illustrates ﬁrst states of the game.
Table 1. First game states during the game.
# state
Player
Argument
Action
State
0
∅
A0
∅
S0 = ∅
1
l1
A1
add(′support′, A1, A0)
S1(′support′, 1) = {(A1, A0)}
2
l2
A2
add(′defeat′, A2, A1)
S2(′support′, 2) = {(A1, A0)}
S2(′defeat′, 2) = {(A2, A1)}
3
l3
A3
append(′support′, A1, A0, A3)
S3(′support′, 3) = {(A1 ∧A3, A0)}
S3(′defeat′, 3) = {(A2, A1)}
4
l1
∅
add(′defeat′, A3, A1) (not valid)
S4(′support′, 4) = {(A1 ∧A3, A0)}
S4(′defeat′, 4) = {(A2, A1)}
. . .
. . .
. . .
. . .
. . .
The complete debate graph is given in Fig. 1, where
A1: ⟨{ϵ > 0, ∃N ∈N, n ≥N}, 2 −ϵ < 2n+1
n+2 ⟩
A2: ⟨{ϵ = −1, n = 1, }, ¬(2 −ϵ < 2n+1
n+2 )⟩
A3: ⟨{ϵ > 0, ∃N ∈N, n ≥N}, 2n+1
n+2
< 2 + ϵ⟩
A4: ⟨{ϵ > 0, 2n+1
n+2
< 2}, 2n+1
n+2
< 2 + ϵ⟩
A5: ⟨{ϵ > 0}, ϵ > 0⟩
A6: ⟨{n ∈N}, 2n+1
n+2
< 2⟩
A7: ⟨{n ∈N}, n ∈N⟩
A8: ⟨{n ∈N, (2 −ϵ)(n + 2) < 2n + 1}, 2 −ϵ < 2n+1
n+2 ⟩
A9: ⟨{ϵ > 0, n > 3
ϵ −2}, (2 −ϵ)(n + 2) < 2n + 1⟩A10: ⟨{n ≥N, N > 3
ϵ −2}, n > 3
ϵ −2⟩
A11: ⟨{N > 3
ϵ −2}, N > 3
ϵ −2⟩
A12: ⟨{n ≥N}, n ≥N⟩
A13: ⟨{n = −3}, ¬( 2n+1
n+2
< 2)⟩
A14: ⟨{n ∈N}, ¬(n = −3)⟩
A15: ⟨{n ∈N, ϵ > 0}, 2n+1
n+2
< 2 + ϵ⟩
A16: ⟨{ϵ > 0}, ¬(ϵ = −1)⟩

Debate-Based Learning Game for Constructing Mathematical Proofs
43
Fig. 1. Debate graph during the game.
In this example learners may add a symmetric defeat between ⟨{ϵ > 0}, ϵ > 0⟩
and ⟨{ϵ = −1}, ϵ = −1⟩. In this case learners need to discuss in a chat box and
convince the learner who added the defeat relation from the latter to the former
to remove her defeat because ϵ > 0 appears in the premises of A0 so it is a
fact that overrides ϵ = −1. We do not make any explicit distinction between
propositions because distinguishing facts and giving them priority should be
done by the learners. This is a part of the learning process. Assuming that the
game ends when the learners agree to submit the debate graph to the Ora-
cle. Thus Group1 submits the graph of the statefinal using the action submit.
Then the Oracle evaluates the debate graph by computing acceptable argu-
ments. To this aim, she computes the argumentation framework corresponding
to the debate graph in order to compute acceptable extensions. The debate
graph is composed of nodes representing arguments and two types of rela-
tions, namely defeat and support relations. Therefore bipolar AF is suitable. We
have BAF = ⟨A, Def, Supp⟩, where A = {A0, A1, A1 ∧A3, A2, A3, A4, A5, A6,
A5 ∧A6, A7, A8, A9, A7 ∧A9, A10, A5 ∧A10, A11 ∧A12, A13, A14, A15, A16},
Def = {(A2, A1), (A16, A2), (A13, A6), (A14, A13)} and Supp = {(A1 ∧A3, A0),
(A8, A1), (A9 ∧A7, A8), (A10 ∧A5, A9), (A11 ∧A12, A10), (A15, A3), (A4, A15),

44
N. Boudjani et al.
(A5 ∧A6, A4), (A7, A6), (A5, A16), (A7, A14)}3. In this example “A Supp B” is
interpreted as “the acceptance of A is necessary for the acceptance of B” [2,11].
As we previously indicated a bipolar argumentation framework can be trans-
lated into Dung’s argumentation framework by combining defeat and support
relations. As we are looking for the proof of a given question, we need to com-
pute the set of arguments that all learners agree on. To this aim the grounded
extension is suitable as it is the set of arguments that are not defeated and those
that are defeated but defended by acceptable arguments. Note that if the debate
graph contains several valid proofs then all corresponding arguments will appear
in the grounded extension. Given the grounded extension, the path of a proof
can be retrieved from the debate graph thanks to the support relations. With-
out entering in the details of computation, the grounded extension associated
to the above BAF is {A0, A1, A3, A1 ∧A3, A4, A5, A6, A5 ∧A6, A7, A8, A9, A7 ∧
A9, A10, A5 ∧A10, A11 ∧A12, A14, A15, A16}.
The Oracle evaluates the grounded extension. Then she informs the group
if it won/failed the game and returns a penalty degree (if any). The win-
ing group is the one that correctly constructed the proof with lowest penalty
degree. The Oracle also returns irrelevant arguments to winners and wrong argu-
ments/relationships to losers. In our example the group won the game with a
penalty degree 3 due to a non valid defeat (A3 Def A1) and two irrelevant argu-
ments (A14 and A16).
5
Conclusion and Ongoing Work
The present paper uses argumentation framework in the context of mathematical
proofs. It oﬀers a conceptual formal debate-based learning system whose advan-
tages are twofold: (i) it oﬀers a formal method to analyze and ﬁlter (generally
huge amount of) information exchanged during the debate and computes valu-
able information (i.e., acceptable arguments) that serves to evaluate the debate,
(ii) it also provides a game-modeling of the argumentation debate as a means
to keep learners motivated.
Several works present argumentation as an abstract dialectical game [9,18].
However there are few genuine games based on the theoretical frameworks devel-
oped in AI. We can mention [19] which presents a simple graph of abstract argu-
ments and players must select arguments in the graph to win the debate accord-
ing to Dung’s semantics [4]. The authors of [17] use structured argumentation
framework in order to construct a syntactical path for the support relation. Our
work does rely on both syntactical and semantical paths in the support relation
in order to ﬁt the mathematical domain. We do also give a greater importance
to the output of the argumentation framework which serves to extract valuable
information from the debate (which corresponds to the proof).
As perspective we intend to experimentally validate our learning system to
assess both its learning value for learners and its acceptance by instructors. At
3 A11 and A12 need not to be considered separately. In fact A11 ∧A12 is needed and
suﬃcient.

Debate-Based Learning Game for Constructing Mathematical Proofs
45
the conceptual level we intend to consider preferences among learners in the
argumentation framework [7]. In fact more experts learners need to be favored
against less expert ones.
References
1. Amir, Y., Sharan, S., Ben-Ari, R., Desegregation, S.: Cross-Cultural Perspectives.
Psychology Press, New York (1984)
2. Cayrol, C., Lagasquie-Schiex, M.C.: Bipolarity in argumentation graphs: Towards
a better understanding. IJAR 54(7), 876–899 (2013)
3. Davidson, N.: Enhancing Thinking through Cooperative Learning. Teachers Col-
lege Press, New York (1992)
4. Dung, P.M.: On the acceptability of arguments and its fundamental role in non-
monotonic reasoning, logic programming and n-person games. Artif. Intell. 77,
321–357 (1995)
5. Durand-Guerrier, V., Boero, P., Douek, N., Epp, S., Tanguay, D.: Argumentation
and proof in the mathematics classroom. In: Hanna, G., de Villiers, M. (eds.) Proof
and Proving in Mathematics Education, pp. 349–367. Springer, Dordrecht (2012)
6. Johnson, D.W., Johnson, R.T.: Learning Together and Alone: Cooperative, Com-
petitive, and Individualistic Learning. Allyn and Bacon, Boston (1999)
7. Kaci, S., van der Torre, L.: Preference-based argumentation: arguments supporting
multiple values. IJAR 48, 730–751 (2008)
8. Kennedy, R.R.: The power of in-class debates. Act. Learn. High Educ. 10(3), 225–
236 (2009)
9. Maudet, N., Moore, D.: Dialogue games as dialogue models for interacting with,
and via, computers. Informal Logic 21(3), 219–243 (2001)
10. Modgil, S.: Hierarchical argumentation. In: Fisher, M., Hoek, W., Konev, B.,
Lisitsa, A. (eds.) JELIA 2006. LNCS (LNAI), vol. 4160, pp. 319–332. Springer,
Heidelberg (2006). doi:10.1007/11853886 27
11. Nouioua, F., Risch, V.: Bipolar argumentation frameworks with specialized sup-
ports. In: ICTAI 2010, pp. 215–218 (2010)
12. Oren, N., Norman, T.J.: Semantics for evidence-based argumentation. In: COMMA
2008, pp. 276–284 (2008)
13. Oros, A.L.: Let’s debate: active learning encourages student participation and crit-
ical thinking. J. Polit. Sci. Educ. 3(3), 293–311 (2007)
14. Park, C., Kier, C., Jugdev, K.: Debate as a teaching strategy in online education:
a case study. Can. J. Learn. Technol. 37(3), 17–20 (2011)
15. Pease, A., Budzynska, K., Lawrence, J., Reed, C.: Lakatos games for mathematical
argument. In: COMMA 2014, pp. 59–66 (2014)
16. Rahwan, I., Larson, K.: Argumentation and game theory. In: Simari, G., Rahwan,
I. (eds.) Argumentation in Artiﬁcial Intelligence, pp. 321–339. Springer, New York
(2009)
17. Thimm, M., Garc´ıa, A.J.: Classiﬁcation and strategical issues of argumentation
games on structured argumentation frameworks. In: AAMAS 2010, pp. 1247–1254
(2010)
18. Weigand, E.: Argumentation: the mixed game. Argumentation 20(1), 59–87 (2006)
19. Yuan, T., Svansson, V., Moore, D., Grierson, A.: A computer game for abstract
argumentation. In: CMNA (IJCAI 2007 Workshop), pp. 62–68 (2007)
20. Zempl´en, G.: History of Science and Argumentation in Science Education, pp.
129–140. SensePublishers, Rotterdam (2010)

Updating Probabilistic Epistemic States
in Persuasion Dialogues
Anthony Hunter1(B) and Nico Potyka2
1 Department of Computer Science, University College London, London, UK
anthony.hunter@ucl.ac.uk
2 Institute of Cognitive Science, University of Osnabr¨uck, Osnabr¨uck, Germany
Abstract. In persuasion dialogues, the ability of the persuader to model
the persuadee allows the persuader to make better choices of move. The
epistemic approach to probabilistic argumentation is a promising way of
modelling the persuadee’s belief in arguments, and proposals have been
made for update methods that specify how these beliefs can be updated
at each step of the dialogue. However, there is a need to better under-
stand these proposals, and moreover, to gain insights into the space of
possible update functions. So in this paper, we present a general frame-
work for update functions in which we consider existing and novel update
functions.
1
Introduction
The aim of persuasion is for the persuader to change the mind of the persuadee,
and the provision of good arguments, and possibly counterarguments, is of cen-
tral importance for this. Some recent developments in the ﬁeld of computational
persuasion have focused on the need to model the beliefs of the persuadee in
order for the persuader to better select arguments to present to the persuadee.
For instance, if the persuader wants to persuade the persuadee to give up smok-
ing, and the persuader knows that the persuadee believes that if he gives up
smoking, he will put on weight, then the persuader could start the dialogue by
providing a counterargument to this, for example by saying that there is a local
football team for ex-smokers who are looking for new players.
One approach to modelling the persuadee is to harness the epistemic app-
roach to probabilistic argumentation [11]. In this, an argument graph (as deﬁned
by Dung [4]) is used to represent the arguments and attacks between them, and
a probability distribution over the subsets of arguments is used to represent
the uncertainty over which arguments are believed. The belief in an individual
argument is then the sum of the belief in the subsets that contain this argument.
When a persuader starts a dialogue with a persuadee, the persuader iden-
tiﬁes an appropriate probability distribution to represent what s/he thinks the
persuadee believes. Then during the dialogue, the moves are made by the partic-
ipants according to some protocol. After each move, the belief is updated using
an update function (see Fig. 1). Some initial proposals for update functions have
c
⃝Springer International Publishing AG 2017
A. Antonucci et al. (Eds.): ECSQARU 2017, LNAI 10369, pp. 46–56, 2017.
DOI: 10.1007/978-3-319-61581-3 5

Updating Probabilistic Epistemic States in Persuasion Dialogues
47
m1
m2
mi
mn
P0
P1
P2
Pi
Pn
Fig. 1. Schematic representation of a dialogue D = [m1, . . . , mn] and user models Pi.
Each user model Pi is obtained from Pi−1 and move mi using an update method.
been made (e.g. [10]) which seem intuitive and well-behaved, but there is a lack
of a general understanding of what an update function is, of what the space of
options are, and of how alternatives could be deﬁned. The aim of this paper is
to address these questions by proposing some basic properties for update func-
tions, and then proposing a framework for update measures in which we show
how existing and some useful novel update functions are situated.
2
Basics
We consider a ﬁnite argument graph G with arguments Args and attacks Attacks.
For A ∈Args, we let A−= {B ∈Args | (B, A) ∈Attacks}. Form denotes the
set of propositional formulas over Args. That is, Form is the smallest set that
contains Args and is closed under application of the usual logical connectives like
¬ and ∧. An interpretation of Form is a subset X ⊆Args. X satisﬁes an atomic
formula A ∈Args iﬀA ∈X and we write X |= A in this case. The satisfaction
relation is extended to complex formulas in the usual way. For instance, X |= F1∧
F2 iﬀX |= F1 and X |= F2. A probability distribution over Args is a function
P : 2Args →[0, 1] such that 
X⊆Args P(X) = 1. We let P denote the set of
all probability distributions over Args. When speaking of topological properties
of subsets of P, we regard probability distributions as probability vectors and
consider the usual topology on Rn. Note that we can do so because 2Args is ﬁnite
(because Args is ﬁnite). For F ∈Form, we let P(F) = P({X ⊆Args | X |= F}).
A complete conjunction over a subset X ⊆Args is a conjunction of the form

A∈X LA, where either LA = A or LA = ¬A. Let Conj(X) denote the set of
all complete conjunctions over X. In the following, we will make use of the fact
that there is a 1-1 relationship between Conj(Args) and the interpretations 2Args.
More strictly speaking, a complete conjunction 
A∈Args LA corresponds to the
interpretation {A ∈Args | LA = A} that contains all arguments that appear
positive in the conjunction. Conversely, an interpretation X ⊆Args corresponds
to the complete conjunction 
A∈X A ∧
A∈Args\X ¬A.
Intuitively, a probability distribution over Args represents the epistemic state
of an agent. Given an argument graph G, we want to impose certain constraints
on probability distributions. We can consider some of the following rationality
postulates for the epistemic state represented by P [11].
– RAT: P is rational iﬀfor all (A, B) ∈Attacks, P(A) > 0.5 implies P(B) ≤
0.5.

48
A. Hunter and N. Potyka
– COH: P is coherent iﬀfor all (A, B) ∈Attacks, P(A) ≤1 −P(B).
– SFOU: P is semi-founded iﬀA−= ∅implies P(A) ≥0.5.
– FOU: P is founded iﬀA−= ∅implies P(A) = 1.
– SOPT: P is semi-optimistic iﬀA−̸= ∅implies P(A) ≥1 −
B∈A−P(B).
– OPT: P is optimistic iﬀP(A) ≥1 −
B∈A−P(B).
For a subset R ⊆{RAT, COH, SFOU, FOU, SOPT, OPT, JUS} of rationality
postulates, we write P |= R iﬀP satisﬁes all constraints in R and for a subset
T ⊆P, we write T |= R iﬀP |= R for all P ∈T.
3
Properties of Update Functions
We can model the change of an agent’s epistemic state in a dialogue by an
update function [10]. Our goal here is to investigate the space of possible update
functions systematically. Formally, we regard an update function as a function
U : P × Form →2P that takes a probability distribution and a formula and
maps them to a set of probability distributions U(P, F) that satisfy F in some
way. In the following, we list several properties that might be interesting in this
context. We start with a list of general properties.
– Uniqueness: |U(P, F)| ≤1.
– Completeness: If F ̸≡⊥then |U(P, F)| ≥1.
– Tautology: U(P, ⊤) = {P}.
– Contradiction: U(P, ⊥) = ∅.
– Representation Invariance: If F ≡G then U(P, F) = U(P, G).
– Idempotence: If U(P, F) = {P ∗} then U(P ∗, F) = {P ∗}.
– Order Invariance: U(U(P, F1), F2) = U(U(P, F2), F1).
Uniqueness says that the solution of the update is always unique. Complete-
ness says that a solution always exists when the new information is consistent.
Tautology says that updating with a tautology should not change the epistemic
state because we do not add any new information. Since our generated epistemic
state should be consistent, Contradiction demands that updating with a contra-
dictory formula should yield the empty set. Representation invariance says that
semantically equivalent formulas should result in the same update. Idempotence
says that if the update yields a unique solution, then updating again with the
same information should not change the result. Order invariance says that the
order in which we update does not aﬀect the result.
Next,
we
consider
some
semantical
properties.
To
begin
with,
we
might want that updates take the structure of the argument graph into
account. Therefore, we consider the following property for subsets R
⊆
{RAT, COH, SFOU, FOU, SOPT, OPT} of rationality postulates:
– R-Consistency: If P |= R then U(P, F) |= R.
In addition, the probability distributions in U(P, F) should satisfy F in some
way. We consider the following satisfaction conditions.

Updating Probabilistic Epistemic States in Persuasion Dialogues
49
– STRICT: P satisﬁes F strictly iﬀP(F) = 1.
– ϵ-WEAK: P satisﬁes F ϵ-weakly iﬀP(F) ≥0.5 + ϵ for ϵ ∈(0, 0.5).
Remark 1. Note that strict satisfaction implies ϵ-weak satisfaction for all ϵ ∈
(0, 0.5).
For a satisfaction condition S ∈{STRICT, ϵ-WEAK} and a formula F ∈Form,
we write P |=S F iﬀP satisﬁes F with respect to S and for a subset T ⊆P, we
write T |=S F iﬀP |=S F for all P ∈T. Analogous to rationality postulates, we
consider the following property for S ∈{STRICT, ϵ-WEAK}:
– S-Consistency: U(P, F) |=S F.
For a set of rationality postulates R and a satisfaction condition S, we deﬁne
the set of R-S-models of F ∈Form by
ModR,S(F) = {P ∈P | P |= R, P |=S F}
We call F R-S-consistent if ModR,S(F) ̸= ∅and R-S-inconsistent otherwise.
If F is R-S-inconsistent, the condition of S-consistency becomes ∅|=S F and is
trivially true. The following example illustrates an R-S-inconsistency.
Example 1. Consider an argument graph over A, B with Attacks = {(A, B)}.
Let R = {RAT, FOU}. Then FOU implies P(A) = 1 for all P ∈ModR,S(⊤)
and therefore RAT implies P(B) ≤0.5. Hence, ModR,ϵ-W EAK(B) = ∅for all
ϵ > 0.
Finally, we might want to update the epistemic state such that we minimally
change the prior state. To this end, we can consider diﬀerent change functions
over P. The ﬁrst class of change measures that we consider measure the diﬀerence
in probability mass that is assigned to interpretations.
– Manhattan Distance: d1(P, P ∗) = 
X⊆Args |P(X) −P ∗(X)|.
– Least Squares Distance: d2(P, P ∗) = 
X⊆Args(P(X) −P ∗(X))2.
– Maximum Distance: d∞(P, P ∗) = maxX⊆Args |P(X) −P ∗(X)|.
– KL-divergence: dKL(P ∗, P) = 
X⊆Args P ∗(X) · log P ∗(X)
P (X) .
Note that the KL-divergence is not a metric. In particular, it is asymmetric and
we use the prior distribution P as the second argument. If we have P ∗(X) >
0 = P(X) for some X ⊆Args, we let dKL(P ∗, P) = ∞as usual.
When updating our belief with respect to a set of literals Φ, we might be
interested only in the change with respect to atoms not appearing in Φ. The
following two distance measures capture this intuition. Here, X ⊆Args denotes
a set of arguments that is supposed to be updated.
– Atomic Distance: dX
At(P, P ∗) = 
B∈Args\X |P(B) −P ∗(B)|.
– Joint Distance: dX
Jo(P, P ∗) = 
C∈Conj(Args\X) |P(C) −P ∗(C)|.

50
A. Hunter and N. Potyka
Table 1. Illustration of diﬀerent change measures.
A B P0
P1
P2
P3
P4
d
d1
d2
d∞dKL d{A}
At
d{A}
Jo
0
0
0.3 0.4 0.5 0.5 0.3 d(P0, P1) 0.3 0.03 0.1
0.16 0.1
0.1
0
1
0.3 0.2 0.2 0.4 0.3 d(P0, P2) 0.4 0.06 0.2
0.09 0.1
0.2
1
0
0.3 0.2 0.2 0.1 0.2 d(P0, P3) 0.6 0.1
0.2
∞
0
0
1
1
0.1 0.1 0.1 0
0.2 d(P0, P4) 0.2 0.02 0.1
0.05 0.01
0.2
Both measures can be zero even though the distributions are unequal. This
happens, when they have equal marginal probabilities on Args\X for the
atomic distance measure and when they have equal marginal probabilities on
Conj(Args\X) for the joint distance measure. Hence, they are not metrics. How-
ever, they are pseudometrics as we explain in the full version1. We illustrate the
diﬀerent change measures in Fig. 1.
We consider the following minimality properties for each change measure d,
set of rationality postulates R and satisfaction condition S:
– R-S-d-minimality: If P ∗∈U(P, F), then P ∗minimizes the distance to P
over ModR,S(F).
R-S-d-minimality demands that we update in such a way that we minimize
the distance to the prior distribution among all probability distributions that
satisfy the argument graph and the new information with respect to the chosen
semantics (Table 1).
4
Reﬁnement-Based Update Functions
In [10], several update functions have been proposed that are deﬁned by means
of the following reﬁnement function. They are restricted in the sense that they
are deﬁned only for literals.
Deﬁnition 1. Let L ∈Formulae(G) be a literal, let P be a probability distrib-
ution, and let λ ∈[0, 1]. The reﬁnement function Hλ : P × {A, ¬A | A ∈
Args} →P is deﬁned by Hλ(P, L) = P ∗as follows where X ⊆Args
P ∗(X) =

P(X) + λ · P(hL(X))
if X |= L
(1 −λ) · P(X)
if X |= ¬L,
where hL(X) = X\{A} if L = A and hL(X) = X ∪{A} if L = ¬A for some
A ∈Args.
1 Full version is at http://www0.cs.ucl.ac.uk/staﬀ/a.hunter/papers/updatefunctionfull
.pdf.

Updating Probabilistic Epistemic States in Persuasion Dialogues
51
Table 2. Illustration of reﬁnement-based updates for a graph with C attacks B and
B attacks A. Note, by deﬁnition, H1(P, A) = Una(P, A) and H1(P, B) = Una(P, B).
A B C P
H0.75(P, A) H1(P, A) Una(P, B) Utr(P, B) Utr(P, A) Ust(P, B) Ust(P, A)
0 0 0 0.2 0.05
0
0
0
0
0
0.2
0 1 0 0.5 0.125
0
0.7
1
0
0.7
0.5
0 0 1 0
0
0
0
0
0
0
0
0 1 1 0.1 0.025
0
0.1
0
0
0.3
0.1
1 0 0 0
0.15
0.2
0
0
0.7
0
0
1 1 0 0
0.375
0.5
0
0
0
0
0
1 0 1 0.1 0.1
0.1
0
0
0.3
0
0.1
1 1 1 0.1 0.175
0.2
0.2
0
0
0
0.1
If we think of interpretations as bit vectors (b1, . . . , bn) where bi is the truth
state of the i-th argument, redistribution with respect to Ai can be explained
as follows: for each bit vector (b1, . . . , bn), if bi = 1, then move a fraction λ of
the probability mass of (b1, . . . , bi−1, 0, bi+1, . . . , bn) to (b1, . . . , bn). We illustrate
this in Table 2.
Let us note that reﬁnement functions are actually commutative in the sense
that Hλ2(Hλ1(P, L1), L2) = Hλ1(Hλ2(P, L2), L1), see [10], Proposition 8. Since
the order in which we add literals is not important, reﬁnement functions can
also be applied to sets of literals Φ recursively, where we let Hλ(P, ∅) = P and
Hλ(P, Φ ∪{L}) = Hλ(Hλ(P, L), Φ). As the following lemma explains, for λ = 1,
updating with multiple literals comes down to shifting probability mass to the
interpretations that satisfy the conjunction of these literals.
Lemma 1. Let X = {A1, . . . , Ak} ⊆Args and for i = 1, . . . , k, let Li ∈
{Ai, ¬Ai}. Let P be a probability distribution and let H1(P, {L1, . . . , Lk}) = P ∗.
Then for all C ∈Conj(X) and D ∈Conj(Args\X),
P ∗(C ∧D) =

P(C ∧D) + 
C′∈Conj(X)\{C} P(C′ ∧D)
if C = k
i=1 Li
0
else.
We will now analyze some reﬁnement-based update functions from [10] by means
of the properties introduced in the previous section. Since the reﬁnement-based
update functions are only deﬁned for atoms or literals, Tautology, Contradiction
and Representation Invariance are not interesting here. However, it is reasonable
to consider Idempotence and Order Invariance restricted to literals.
The naive update function shifts the probability mass from an interpretation
X that violates L to the corresponding interpretation that is obtained from X
by ﬂipping the truth state of the argument in L.
Deﬁnition 2 ([10]). The naive update function Una : P × {A, ¬A | A ∈
Args} →P is deﬁned by Una(P, L) = H1(P, L).

52
A. Hunter and N. Potyka
Una satisﬁes the following properties.
Proposition 1. Una satisﬁes Uniqueness, Completeness, Idempotence, Order
Invariance and STRICT-Satisfaction.
The naive update function is intended to model persuadees who believe any
arguments that are posited in a dialogue. The function does not take the struc-
ture of the argument graph into account, and therefore can generally violate all
rationality postulates that we introduced over argument graphs. However, given
an update literal over the argument A, the naive update is guaranteed to be
minimal with respect to d{A}
Jo
- in fact, the change with respect to d{A}
Jo
is 0 as
we show in the full version of this paper.
The next two update functions maintain consistency with the argument graph
by also considering arguments that are connected to the argument whose state
we update. They are restricted to atomic arguments, however.
The trusting update reﬁnes the naive update by also shifting the probability
mass from all interpretations that satisfy the attackers and attackees of the
update argument.
Deﬁnition 3 ([10]). The trusting update function Utr : P × Args →P is
deﬁned by Utr(P, A) = H1(P, Φ), where Φ = {A} ∪{¬C | (A, C) ∈Attacks(G) or
(C, A) ∈Attacks(G)}.
Utr satisﬁes the following properties.
Proposition 2. Utr satisﬁes Uniqueness, Completeness, Idempotence, Order
Invariance, STRICT-Satisfaction and R-Satisfaction for all R ⊆{RAT, COH}.
Utr can violate the remaining R-Satisfaction properties, but it does guarantee
that the joint distance to the prior distribution is 0. However, the joint distance
is now not only deﬁned with respect to the update argument, but also with all
of its attackers and attackees as we show in the full version.
The strict update function conditionally updates the probability of an argu-
ment to 1. In order to maintain consistency with the argument graph, the update
is only performed if no attackers of the argument are believed in the current
epistemic state. If the update is performed, the belief in attacked arguments will
additionally be set to 0.
Deﬁnition 4 ([10]). The strict update function is a function Ust : P ×
Args →P. For A ∈Args, let Φ = {A} ∪{¬C | (A, C) ∈Attacks} and let
the constraint C(P) be true iﬀfor all (B, A) ∈Attacks, P(B) ≤0.5. Then
Ust(P, A) = P ∗where
P ∗=

H1(P, Φ)
if C(P)
P
else
Ust satisﬁes the following properties.

Updating Probabilistic Epistemic States in Persuasion Dialogues
53
Proposition 3. Ust satisﬁes Uniqueness, Completeness, Idempotence and R-
Satisfaction for all R ⊆{RAT, COH, SFOU, FOU}.
Ust does not satisfy Order Invariance, but it satisﬁes all semantical constraints
except R-OPT and R-SOPT. Ust again guarantees joint distance 0, this time
with respect to the update argument and all of its attackees. We refer again to
the full version of this paper for more details and proofs.
In [10], H0.75 is considered as an alternative to H1 in the above deﬁnition, and
this is used to model skeptical agents who do not entirely believe an argument
when updating.
5
R-S-d Update Functions
We now consider another class of update functions. Whereas reﬁnement-based
update functions are based on the idea of shifting probability mass in a speciﬁc
way, we will now consider a more declarative approach using tools from numerical
optimization. R-S-d Update Functions are deﬁned by minimizing some notion of
distance subject to semantical constraints.
Deﬁnition 5. Let
R
⊆
{RAT, COH, SFOU, FOU, SOPT, OPT},
S
∈
{STRICT, ϵ-WEAK} and d ∈{d1, d2, d∞, dX
At, dX
Jo}. An R-S-d Update Func-
tion UR,S,d : P × Form →2P is deﬁned by
UR,S,d(P, F) = arg
min
P ′∈ModR,S(F ) d(P, P ′).
Let us ﬁrst note that most R-S-d update functions have some nice analytical
properties (Table 3).
Lemma 2. For each R ⊆{COH, SFOU, FOU, SOPT, OPT} (we left out
RAT), S ∈{STRICT, ϵ-WEAK} and d ∈{d1, d2, d∞, dm, dKL, dX
At, dX
Jo}, com-
puting UR,S,d(P, F) corresponds to a convex combination problem. In partic-
ular, the set UR,S,d(P, F) will be non-empty, convex and compact whenever
ModR,S(F) ̸= ∅.
If R includes RAT, UR,S,d(P, F) will be non-empty and compact whenever
ModR,S(F) ̸= ∅.
We have the following general guarantees for R-S-d update functions.
Proposition 4. For all R ⊆{RAT, COH, SFOU, FOU, SOPT, OPT}, S ∈
{STRICT, ϵ-WEAK} and
d
∈
{d1, d2, d∞, dm, dX
At, dX
Jo}, UR,S,d
satisﬁes
Completeness (if the update argument is R-S-consistent), R-consistency, S-
consistency and R-S-d-minimality.
If we exclude RAT from R and d ∈{d2, dKL}, UR,S,d also satisﬁes Unique-
ness, Tautology, Contradiction, Representation Invariance and Idempotence.
We can give some stronger guarantees for some special cases, see the full paper
for a detailed analysis.
Order Invariance can be violated for many combinations of semantical con-
straints and change measures. We give a simple example for the Euclidean dis-
tance without semantical constraints on the argument graph.

54
A. Hunter and N. Potyka
Table 3. Illustration of R-S-d updates with R1 = {COH}, R2 = {COH, SOPT},
S = STRICT and d = d2.
A B C P
UR1,S,d(P, A) UR1,S,d(P, B) UR2,S,d(P, A) UR2,S,d(P, ⊤)
0
0
0
0.2 0
0
0
0.17
0
1
0
0.5 0
1
0
0.49
0
0
1
0
0
0
0
0
0
1
1
0.1 0
0
0
0.07
1
0
0
0
0.45
0
0
0.02
1
1
0
0
0
0
0
0.5
1
0
1
0.1 0.55
0
1
0.09
1
1
1
0.1 0
0
0
0.12
Example 2. Consider an argument graph over A, B, let R = ∅, S = STRICT
and d = d2. Let P be deﬁned by P({B}) = 0.5, P({A, B}) = 0.5. Then
P1 = UR,S,d(UR,S,d(P, A), B) is given by P1({B}) = 0.125, P1({A, B}) = 0.875,
whereas P2 = UR,S,d(UR,S,d(P, B), A) is given by P2({A}) = 0.25, P2({A, B}) =
0.75.
What can we say about the relationship between reﬁnement-based update
functions and R-S-d update functions? We ﬁrst note that R-S-d-update functions
generalize the naive update function in the following sense.
Proposition 5. Consider an arbitrary set of semantical constraints R
⊆
{RAT, COH, SFOU, FOU, SOPT, OPT}, a probability distribution P
∈P
and let L ∈{A, ¬A} be a literal for some A ∈Args. If there is a P ∗∈
ModR,ST RICT (L) such that d{A}
Jo (P, P ∗) = 0 then UR,ST RICT,d{A}
Jo (P, L) =
{Una(P, L)}.
Remark 2. Note that if there is no P ∗
∈
ModR,ST RICT (L) such that
d{A}
Jo (P, P ∗) = 0, then applying the Naive update function will violate some
semantical constraint in R (because the probability distribution resulting from
the naive update will have distance 0). Hence, UR,ST RICT,d{A}
Jo
agrees with Una
whenever Una is consistent with R. Otherwise, UR,ST RICT,d{A}
Jo
will select prob-
ability distributions that are consistent with R and minimize the joint distance.
In particular, the Naive update function can be thought of as a special case of
the following R-S-d-update function.
Corollary 1. U∅,ST RICT,d{A}
Jo (P, L) = {Una(P, L)}.
The trusting method can similarly be generalized by an R-S-d-update function.

Updating Probabilistic Epistemic States in Persuasion Dialogues
55
Proposition 6. Consider an arbitrary set of semantical constraints R
⊆
{RAT, COH, SFOU, FOU, SOPT, OPT}, a probability distribution P
∈P
and let L ∈{A, ¬A} be a literal for some A ∈Args. Let X′ = {C |
(A, C) ∈Attacks(G) or (C, A) ∈Attacks(G)} and X = {A} ∪X′. If there is
a P ∗∈ModR,ST RICT (L) such that dX
Jo(P, P ∗) = 0 then UR,ST RICT,dX
Jo(P, L ∧

C∈X′ ¬C) = {Utr(P, L)}.
Corollary 2. U∅,ST RICT,dX
Jo(P, L ∧
C∈X′ ¬C) = {Utr(P, L)}.
We could get a similar result for the strict update using the joint distance over
the update argument and its attackees. This would require a case diﬀerentiation
analogous to the case diﬀerentiation that is used for the strict update.
6
Conclusions and Future Work
Most proposals for dialogical argumentation focus on protocols (e.g., [2,5,14,15])
with strategies being under-developed. See [18] for a review of strategies in multi-
agent argumentation. There are proposals for modelling the likelihood of the
moves that an opposing agent might make (e.g. [6,7,16,17]). Note, however,
that none of the above proposals consider the beliefs of the opposing agent. In
[1], a planning system is used by the persuader to optimize choice of arguments
based on belief in premises. However, there is no consideration of how the beliefs
are updated during the dialogue.
The epistemic approach to probabilistic argumentation oﬀers a formal frame-
work for modelling a persuadee’s beliefs in arguments. There are methods for
updating beliefs during a dialogue [10], for eﬃcient representation and reason-
ing with the pesuadee model [8], and for harnessing decision-theoretic decision
rules for optimizing the choice of arguments based on the persuadee model [9].
Therefore, the framework for update functions presented in this paper clariﬁes
and extends the space of update functions that we can harness in persuasion
dialogues.
There are several interesting directions for future work. First, we can investi-
gate diﬀerent ways to deal with the problem of non-unique solutions. We might
focus on some best solution or represent epistemic states by sets of probability
distributions rather than by a single one. Second, we can deal with inconsistencies
like in Example 1 in diﬀerent ways. We might consider priorities over diﬀerent
semantical constraints [12] or select solutions that violate the constraints in a
minimal way [3,13]. Third, we can try to include more expressive argumentation
frameworks by introducing numerical constraints for other relations than attack
relations.
Acknowledgements. This research was partly funded by EPSRC grant EP/
N008294/1 for the Framework for Computational Persuasion project.

56
A. Hunter and N. Potyka
References
1. Black, E., Coles, A., Bernardini, S.: Automated planning of simple persuasion
dialogues. In: Bulling, N., Torre, L., Villata, S., Jamroga, W., Vasconcelos, W.
(eds.) CLIMA 2014. LNCS (LNAI), vol. 8624, pp. 87–104. Springer, Cham (2014).
doi:10.1007/978-3-319-09764-0 6
2. Caminada, M., Podlaszewski, M.: Grounded semantics as persuasion dialogue. In:
Proceedings of the International Conference on Computational Models of Argu-
ment (COMMA), pp. 478–485 (2012)
3. Daniel, L.: Paraconsistent probabilistic reasoning. Ph.D. thesis, L’´Ecole Nationale
Sup´erieure des Mines de Paris (2009)
4. Dung, P.: On the acceptability of arguments and its fundamental role in non-
monotonic reasoning, logic programming, and n-person games. Artif. Intell. 77,
321–357 (1995)
5. Fan, X., Toni, F.: Assumption-based argumentation dialogues. In: Proceedings of
IJCAI 2011, pp. 198–203 (2011)
6. Hadjinikolis, C., Siantos, Y., Modgil, S., Black, E., McBurney, P.: Opponent mod-
elling in persuasion dialogues. In: Proceedings of IJCAI 2013, pp. 164–170 (2013)
7. Hadoux, E., Beynier, A., Maudet, N., Weng, P., Hunter, A.: Optimization of prob-
abilistic argumentation with Markov decision models. In: Proceedings of IJCAI
2015, pp. 2004–2010 (2015)
8. Hadoux, E., Hunter, A.: Computationally viable handling of beliefs in arguments
for persuasion. In: Proceedings of ICTAI 2016, pp. 319–326. IEEE Press (2016)
9. Hadoux, E., Hunter, A.: Strategic sequences of arguments for persuasion using
decision trees. In: Proceedings of AAAI 2017, pp. 1128–1134. AAAI Press (2017)
10. Hunter, A.: Modelling the persuadee in asymmetric argumentation dialogues for
persuasion. In: Proceedings of IJCAI 2015, pp. 3055–3061 (2015)
11. Hunter, A., Thimm, M.: On partial information and contradictions in probabilistic
abstract argumentation. In: Principles of Knowledge Representation and Reasoning
(KR 2016), pp. 53–62 (2016)
12. Potyka, N.: Reasoning over linear probabilistic knowledge bases with priorities. In:
Beierle, C., Dekhtyar, A. (eds.) SUM 2015. LNCS (LNAI), vol. 9310, pp. 121–136.
Springer, Cham (2015). doi:10.1007/978-3-319-23540-0 9
13. Potyka, N., Thimm, M.: Probabilistic reasoning with inconsistent beliefs using
inconsistency measures. In: Proceedings of IJCAI 2015, pp. 3156–3163 (2015)
14. Prakken, H.: Coherence and ﬂexibility in dialogue games for argumentation. J.
Logic Comput. 15(6), 1009–1040 (2005)
15. Prakken, H.: Formal sytems for persuasion dialogue. Knowl. Eng. Rev. 21(2), 163–
188 (2006)
16. Rienstra, T., Thimm, M., Oren, N.: Opponent models with uncertainty for strategic
argumentation. In: Proceedings of IJCAI 2013, pp. 332–338 (2013)
17. Rosenfeld, A., Kraus, S.: Providing arguments in discussions on the basis of the
prediction of human argumentative behavior. ACM Trans. Interact. Intell. Syst. 6,
30:1–30:33 (2016)
18. Thimm, M.: Strategic argumentation in multi-agent systems. Kunstliche Intelligenz
28, 159–168 (2014)

From Structured to Abstract Argumentation:
Assumption-Based Acceptance
via AF Reasoning
Tuomo Lehtonen1, Johannes P. Wallner2(B), and Matti J¨arvisalo1
1 HIIT, Department of Computer Science, University of Helsinki, Helsinki, Finland
2 Institute of Information Systems, TU Wien, Vienna, Austria
wallner@dbai.tuwien.ac.at
Abstract. We study the applicability of abstract argumentation (AF)
reasoners in eﬃciently answering acceptability queries over assumption-
based argumentation (ABA) frameworks, one of the prevalent forms of
structured argumentation. We provide a reﬁned algorithm for translating
ABA frameworks to AFs allowing the use of AF reasoning to answer
ABA acceptability queries, covering credulous and skeptical acceptance
problems over ABAs in a seamless way under several argumentation
semantics. We empirically show that the approach is complementary with
a state-of-the-art ABA reasoning system.
1
Introduction
Argumentation is today a vibrant area of modern AI research, providing for-
malisms for representing and reasoning about conﬂicting arguments, aiming at
conﬂict resolution through detecting sets of non-conﬂicting arguments which
together counter—or defend themselves against—all counterarguments.
Several argumentation formalisms have been proposed, with diﬀerent desir-
able properties. Perhaps the simplest formalism for argumentation are abstract
argumentation frameworks (AFs) [11]. AFs allow for representing conﬂicts—or
attacks—between arguments as directed graphs, where nodes represent abstract
arguments, and edges represent attacks. Several reasoning system implementa-
tions for AF reasoning exists today [5,6,17,18,24,25], especially for central AF
reasoning problems such as credulous and skeptical acceptance of arguments
under various AF semantics.
Another central formalism is structured argumentation [1–3,22,26] in which,
in contrast to abstract argumentation, the internal structure of arguments
is made explicit through derivations from more basic structures. One well-
known approach to structured argumentation is assumption-based argumenta-
tion (ABA) [3,13,29]. In ABA arguments are represented compactly as graph-
based derivations [7] from a given rule-based deductive system over sentences,
Work funded by Academy of Finland, grants 251170 COIN, 276412, and 284591;
Research Funds of the University of Helsinki; and the Austrian Science Fund (FWF):
I2854 and P30168.
c
⃝Springer International Publishing AG 2017
A. Antonucci et al. (Eds.): ECSQARU 2017, LNAI 10369, pp. 57–68, 2017.
DOI: 10.1007/978-3-319-61581-3 6

58
T. Lehtonen et al.
starting from assumptions. A central approach to reasoning about acceptabil-
ity of arguments over ABAs are so-called dispute derivations [7,12,14,20,21,28],
implemented in various ABA reasoning systems [7–9,14,19–21,28]. The aba-
graph system [7] supporting credulous reasoning over ABAs under the admissible
and grounded semantics represents the current state of the art.
While systems for reasoning over AFs and ABAs have been developed, the
applicability of state-of-the-art abstract argumentation reasoners for reasoning
about assumption-based argumentation frameworks has received little atten-
tion. To bridge this gap, we study the applicability of state-of-the-art abstract
argumentation reasoners in eﬃciently answering acceptability queries over ABA
frameworks. While theoretical work on mapping ABAs to AFs exists [4,14],
here we concretely implement an approach to reasoning about acceptance of
sentences in assumption-based argumentation via translating ABA frameworks
into abstract argumentation frameworks, and thereafter using AF reasoning to
decide acceptance of sentences. While it would be desirable to exactly compute
a small, yet suﬃcient, set of AF arguments for a given ABA, we show that
restricting argument construction to only those arguments satisfying a minimal-
ity condition in their supports, which we call relevant arguments, is computa-
tionally very demanding: we prove that counting the number of such relevant
arguments is #P-complete. To overcome this obstacle, we propose an algorithm
for overapproximating the set of relevant arguments for a given ABA framework.
We implement the reasoning part by answer set programming (ASP) encodings
speciﬁcally suited for the types of AFs the translation gives rise to. We show
that a prototype implementation of the approach is complementary in terms of
performance with the state-of-the-art abagraph system for credulous acceptance
in ABA. Our approach is generic in that it covers both credulous and skep-
tical acceptance problems under several central argumentation semantics over
ABAs in a seamless way. Proofs of the main theorems are available in the paper
supplement online at https://cs.helsinki.ﬁ/group/coreo/ecsqaru17.
2
Preliminaries
Assumption-Based
Argumentation.
We
recall
deﬁnitions
related
to
assumption-based argumentation (ABA) [3,29], following [10]. We assume a
deductive system (L, R) with L a formal language, i.e., a countable set of sen-
tences, and R a set of inference rules over L with a rule r ∈R having the form
a0 ←a1, . . . , an with ai ∈L. We denote the head of rule r by head(r) = {a0}
and the (possibly empty) body of r by body(r) = {a1, . . . , an}. A sentence a ∈L
is derivable from a set X ⊆L via rules R, denoted by X ⊢R a, if there is a
sequence of rules (r1, . . . , rn) s.t. head(rn) = a and for each rule ri it holds that
ri ∈R and each sentence in the body of ri is derived from rules earlier in the
sequence or in X, i.e., body(ri) ⊆X ∪
j<i head(rj). The deductive closure for
X w.r.t. rules R is given by ThR(X) = {a | X ⊢R a}.
An ABA framework is a tuple (L, R, A, ) with (L, R) a deductive system,
a set of assumptions A ⊆L, and a function
(contrary function) mapping

From Structured to Abstract Argumentation: Assumption-Based Acceptance
59
assumptions A to sentences L. We focus on ﬂat ABA frameworks where assump-
tions cannot be derived. Let D = (L, R, A, ) be an ABA framework. A set of
assumptions Δ ⊆A attacks an assumption b ∈A in the ABA framework D if
the contrary of b is derivable from Δ in D, i.e., b ∈ThR(Δ). Further, Δ attacks
a set of assumptions Δ′ ⊆A in the ABA framework D if an assumption in Δ′
is attacked by Δ, i.e., ThR(Δ) ∩{a|a ∈Δ′} ̸= ∅.
Deﬁnition 1. Let D = (L, R, A, ) be an ABA framework. Further, let Δ ⊆A
be a set of assumptions that does not attack itself in D. Set Δ is
– admissible in D if each set of assumptions Δ′ that attacks Δ is attacked by
Δ;
– preferred in D if Δ is admissible and there is no admissible set of assumptions
Δ′ in D with Δ ⊂Δ′; and
– stable in D if each a ∈A\Δ is attacked by Δ.
We use the term σ-assumption-set to refer to an assumption set under a speciﬁc
semantics σ ∈{adm, stb, prf }.1 Let D = (L, R, A, ) be an ABA framework and
σ a semantics. A sentence s ∈L is credulously accepted in D under semantics
σ if there is a σ-assumption-set Δ s.t. s ∈ThR(Δ); and skeptically accepted in
D under semantics σ if it holds that s ∈ThR(Δ) for all σ-assumption-sets Δ.
ABA
AF
semantics cred
skept
cred
skept
admissible NP-c
P-c
NP-c trivial
stable
NP-c coNP-c NP-c coNP-c
preferred NP-c Πp
2 -c NP-c Πp
2 -c
Fig. 1. Complexity of reasoning.
Complexity of reasoning of (ﬂat) ABA
frameworks [10] is shown in Fig. 1.
Example 1. An ABA framework is shown in
Fig. 2 (left) with L = {a, b, c, d, e, f, g, h, i},
as well as the admissible, stable, and pre-
ferred assumption sets. Sentences g and
h
are
credulously
accepted
under
σ
∈
{adm, prf , stb}, since they can be derived from {a} and {c}. Further, i is skep-
tically accepted under σ, since i is derivable from ∅.
Abstract Argumentation Frameworks. An abstract argumentation frame-
work (AF) [11] is a pair F = (A, R), where A is a ﬁnite non-empty set of
arguments and R ⊆A × A is the attack relation. The pair (a, b) ∈R indicates
that a attacks b. A set S ⊆A attacks an argument b (in F) if there is an a ∈S
rules R
contr. ass. sets σ
d ←a
g ←e a = h
∅
adm
e ←a, b d ←g b = e
{a}
adm, prf , stb
f ←c
h ←f c = d
{c}
adm
e ←d
i ←
{b, c} adm, prf , stb
({a, d, e, g}, {a})
({c, f, h}, {c})
({b}, {b})
({i}, ∅)
Fig. 2. Example ABA with A = {a, b, c} (left) and the corresponding AF (right).
1 We call, for reasons of uniformity and brevity, admissible sets a semantics; this is
not meant to prescribe a particular logical stance to the frameworks.

60
T. Lehtonen et al.
s.t. (a, b) ∈R. An argument a ∈A is defended (in F) by a set S ⊆A if, for each
b ∈A such that (b, a) ∈R, it holds that S attacks b.
AF semantics are deﬁned through functions σ which assign to each AF F =
(A, R) a set σ(F) ⊆2A of extensions. We consider for σ the functions adm, stb,
and prf .
Deﬁnition 2. Let F = (A, R) be an AF. A set S ⊆A is conﬂict-free (in F) if
there are no a, b ∈S such that (a, b) ∈R. We denote the collection of conﬂict-free
sets of F by cf (F). For a conﬂict-free set S ∈cf (F) it holds that
– S ∈adm(F) iﬀeach a ∈S is defended by S;
– S ∈prf (F) iﬀS ∈adm(F) and ∄S′ ∈adm(F) with S ⊂S′; and
– S ∈stb(F) iﬀeach a ∈A\S is attacked by S.
We use “σ-extension” to denote an extension under a semantics σ. Let F =
(A, R) be an AF. An argument a ∈A is credulously accepted in F under σ if
there is an E ∈σ(F) s.t. a ∈E. An argument a is skeptically accepted in F
under σ if a is contained in every E ∈σ(F). For complexity of AF reasoning [15]
see Fig. 1.
3
From ABA to AF
The focus of this work is on studying the applicability of abstract argumentation
reasoning tools for reasoning about acceptance of sentences in assumption-based
argumentation frameworks. Given an ABA and a credulous/skeptical query as a
sentence in the ABA, our approach to answer the query consists of the following
two steps.
1. Translate the ABA framework into an AF in a way that the ABA query can
be answered by applying AF reasoning principles on the resulting AF.
2. Adjust an AF reasoning system to answer the ABA query on the AF from
step 1.
In this section we adapt translations of ABA frameworks [4,14] to AFs to suit
our goal of computational feasibility. The idea of the approach is to view subsets
of the assumptions, and sentences derived from these sets, as abstract arguments.
The assumptions of such an argument are called support of the argument. A key
point for this translation, to ensure correctness, is to construct arguments so
that all assumption sets are suﬃciently covered, not missing crucial parts of
the ABA framework. Sentences contained in an argument in a σ-extension of
the resulting AF will be derivable in a σ-assumption-set of the original ABA
framework and vice versa, thereby aligning the corresponding reasoning tasks of
ABA frameworks and AFs.
In order to make step 2 computationally feasible, care needs to be taken in
order to ensure that the AF resulting from step 1 does not become restrictively
large (in terms of the number of arguments) in order to enable reasoning on
the AF. To this end, we consider constructing only those arguments, which we

From Structured to Abstract Argumentation: Assumption-Based Acceptance
61
call relevant arguments, whose support is minimal, in the sense that there is
a sentence derivable from the support, but the sentence is not derivable from
any proper subset of the support. However, we will show that the complexity
of computing (exactly) the set of relevant arguments is restrictive for practical
purposes. Motivated by both the computational hardness result and the need
for restriction of the number of arguments, we then, in the subsequent sections,
propose an algorithm for over-approximating the set of relevant arguments of a
given ABA, and detail an approach to step 2 via answer set programming.
Key to the translation of ABA frameworks to AFs are the arguments for the
AF, which are viewed as pairs of a set of assumptions and sentences derived
from the set of assumptions. With the aim of focusing on relevant arguments,
we generalize and adapt the concept of support-minimality [7, Deﬁnition 4.11].
In [7] support-minimality is deﬁned for arguments with a single claim (derivation
for a single sentence).
Deﬁnition 3. Let D = (L, R, A, ) be an ABA framework. We deﬁne the set
of sets of assumptions minsupp(D) by Δ ∈minsupp(D) iﬀ
Δ′⊂Δ ThR(Δ′) ⊂
ThR(Δ).
In words, a set of assumptions Δ is a minimal support if there is a sentence
derivable from Δ via R but not from any proper subset Δ′ ⊂Δ. Relevant
arguments are deﬁned as pairs of a set of sentences and a minimal support.
Deﬁnition 4. Let D = (L, R, A, ) be an ABA framework, L ⊆L, and Δ ⊆A.
A pair (L, Δ) is a relevant argument (for D) if the following two conditions hold:
(i) Δ ∈minsupp(D); and (ii) L = ThR(Δ)\(
Δ′⊂Δ ThR(Δ′)).
In words, a pair (L, Δ) is a relevant argument for a given ABA if Δ is in
minsupp(D) (ﬁrst item), and L contains those sentences that are derivable from
Δ but not any proper subset of Δ (second item).
Example 2. Consider the ABA framework from Example 1. The sets in
minsupp(D) are {a}, {b}, {c}, and ∅. The admissible assumption set {b, c}
is not in minsupp(D) since all sentences derivable from {b, c} are derivable
from {b} or {c}. For each set in minsupp(D) there is a relevant argument,
e.g., ({a, d, e, g}, {a}) is a relevant argument for the ABA framework and all
sentences in {a, d, e, g} can be derived from a, and all sentences derivable from
{a} but not ∅are contained in the ﬁrst component.
Deﬁnition 5. Let D = (L, R, A, ) be an ABA framework. An AF F = (A, R)
corresponds to the ABA D if the following two conditions hold. (i) A is the set of
relevant arguments for D; and (ii) R = {((L, Δ), (L′, Δ′))|L∩{x | x ∈Δ′} ̸= ∅}.
Brieﬂy put, a corresponding AF for a given ABA framework contains the
relevant argument for each set of assumptions in minsupp(D), i.e., |A| =
|minsupp(D)|, and attacks based on the supports and the derived sentences.
In Fig. 2, the corresponding AF (right) for the ABA framework (left) is shown.
In the following formal result, that follows the spirit of [14, Theorem 2.2] and

62
T. Lehtonen et al.
[4, Theorem 6], we show that we have a correspondence between the ABA
framework and the corresponding AF in terms of the semantics, which allows
for utilization of AF reasoners on the AF to answer ABA queries. We deﬁne
sentences(E) = 
(L,Δ)∈E L.
Theorem 1. Let D = (L, R, A, ) be an ABA framework, Δ ⊆A, and σ ∈
{adm, stb, prf }. For an AF F = (A, R) that corresponds to D, and E ⊆A, it
holds that
– if Δ is a σ-assumption-set of D, then E = {(L, Δ′) ∈A | Δ′ ⊆Δ} is a
σ-extension of F, and ThR(Δ) = sentences(E);
– if E is a σ-extension of F, then Δ = 
(L,Δ′)∈E Δ′ is a σ-assumption-set of
D, and ThR(Δ) ⊇sentences(E) for σ = adm, and ThR(Δ) = sentences(E)
for σ ∈{stb, prf }.
Based on this formal correspondence, we can answer credulous (skeptical)
acceptability queries in an ABA framework as speciﬁed in the next corollary.
Corollary 1. Let D = (L, R, A, ) be an ABA framework, l ∈L, σ =
{adm, stb, prf }, σ′ = {stb, prf }, and AF F = (A, R) the corresponding AF for
D. It holds that
– l is credulously accepted under σ in D iﬀthere is a credulously accepted argu-
ment (L,Δ) under σ in F with l ∈L;
– l is skeptically accepted under σ′ in D iﬀfor each σ′-extension E of F it holds
that l ∈sentences(E).
Skeptical acceptance under admissible semantics for ABA frameworks is
polynomial-time decidable (Table 1), while our focus here is on the NP-hard
acceptance problems. Omitting a relevant argument in a corresponding AF can
directly lead to incorrect results w.r.t. acceptance queries of the original ABA
framework. For instance, considering the corresponding AF shown in Example 2,
removal of any of the relevant arguments of this AF would lead to missing sen-
tences in the AF which are credulously accepted under, e.g., admissible semantics
in the original ABA framework.
4
Computing Relevant Arguments
The authors of [7] conjecture that computing minimal supports may be com-
putationally costly. We provide a formal result backing up this conjecture: we
show that counting the number of minimal supports for a given ABA frame-
work is intractable, in fact #P-complete under subtractive reductions [16] often
used for showing hardness for counting complexity classes. (The prototypical
#P-complete problem is that of counting satisfying assignments of a Boolean
formula.)
Theorem 2. For a given ABA framework, counting the number of minimal
supports is #P-complete under subtractive reductions.

From Structured to Abstract Argumentation: Assumption-Based Acceptance
63
To overcome this obstacle, we give an algorithm that overapproximates the
set of relevant arguments. The algorithm traverses the rules backwards towards
the assumptions. The underlying data structure operated on is a directed graph
with vertices being both heads and bodies of rules in the ABA. There is a directed
edge from a body to a head if there is a corresponding rule, and from a head
to a body if the former is contained in the latter. We ﬁlter out non-derivable
sentences. If the rules are acyclic, we can straightforwardly backward chain from
the sinks to create all needed arguments. For the general (i.e. possibly cyclic)
case, the presented algorithm also takes all heads of rules that are in non-trivial
strongly connected components (SCCs), i.e., non-singleton SCCs, denoted by
SCC(D), as starting points. We store (partial) arguments with a set of sets of
sentences, Arg(X) = {S1, . . . , Sn} for a head or body X, indicating that X is
derivable from any S1, . . . , Sn.
Algorithm 1. Argument Construc-
tion
Require: ABA D = (L, R, A, )
1: Compute SCC(D)
//non-trivial
SCCs
2: S = sinks(G) ∪( SCC(D) ∩L)
3: while S ̸= ∅
4:
remove s from S
5:
process-head(s, ∅)
6:
mark s visited
The main Algorithm 1 computes non-
trivial SCCs, stores starting points in S,
and recurses in the while loop (call by ref-
erence) with a picked sentence and the
current derivation path P (for detect-
ing cyclic derivations; initialized with ∅).
After processing, the sentence is marked,
indicating that all derivations have been
exhausted. Algorithm 2, process-head,
marks the head s if not in a non-trivial
SCC and adds s to the derivation path P. In case s is an assumption (or ⊤
for sentences derived from ∅), we add a new argument {s} for s. Otherwise call
process-body(B, P) for each non-visited body B from which s can be derived,
excluding P. Afterwards, we extend arguments for the bodies and add these
arguments to Arg(s).
Algorithm 3 takes care of bodies. We mark B if it is not a non-trivial SCC
or when each element in the body is either marked or not in non-trivial SCC.
To avoid cyclic derivations we check if an element in the body is contained in
path P. If not, after adding body B to P, we call process-head for each non-
visited element. We collect all possible ways of deriving body B by taking all
minimal combinations of arguments from which to directly derive each s ∈B
(subderivations). Arguments with the same support are then merged (there
is at most one argument per set of assumptions) by calling merge-by-sup.
Each constructed argument contains only sentences derivable from its set of
assumptions. For each Δ ∈minsupp(D) an argument with Δ as its assumptions
is constructed. Our algorithm approximates the set of relevant arguments in two
senses. First, arguments with minimal support might contain more derived sen-
tences, i.e., sentences also derivable from subsets of their support. Secondly, we
might compute arguments with assumption sets not in minsupp(D). Correctness
of the overall approach is not aﬀected by either approximation as long as the
attacks are as speciﬁed in Deﬁnition 5.

64
T. Lehtonen et al.
Algorithm 2. process-head(s, P)
1: if s /∈ SCC(D) then mark s visited
2: P = P ∪{s}
3: if s ∈A ∪{⊤} then
4:
Arg(s) = Arg(s) ∪{{s}}
5: else
6:
for each B ∈{body(r)|head(r) = s}
7:
if B not visited then
8:
process-body(B, P)
9:
Arg(B) = {A ∪{s}|A ∈Arg(B)}
10:
Arg(s) = Arg(s) ∪Arg(B)
11: P = P\{s}
Algorithm 3. process-body(B, P)
1: if B /∈ SCC(D) then mark B vis-
ited
2: if each s′ ∈B is marked or not in SCC
then mark B visited
3: if B ∩P ̸= ∅then return
4: P = P ∪{B}
5: for each s′ ∈B
6:
if s′ not visited then
7:
process-head(s′, P)
8: Arg(B) = subderivations(B)
9: merge-by-supp(Arg(B))
10: P = P\{B}
Special Cases. ABA acceptance can, in cases, be decided during the AF trans-
lation. Assume an ABA D = (L, R, A, ) and a sentence l ∈L. For admissi-
ble and preferred semantics it holds that if l ∈ThR(∅), then l is both credu-
lously and skeptically accepted; and if l /∈ThR(A) or each (L, Δ) with l ∈L is
self-attacking, then l is neither credulously nor skeptically accepted. For stable
semantics, it holds that if l ∈ThR(∅), then l is skeptically accepted, and credu-
lously accepted iﬀD has a stable assumption set. If l ̸∈ThR(A) or each (L, Δ)
with l ∈L is self-attacking, then l is not credulously accepted, and skeptically
accepted iﬀD has no stable assumption set. In our approach, existence of stable
assumption sets can be checked with an AF reasoner.
5
Reasoning About ABA Acceptance on AFs
For reasoning over the AFs (step 2) obtained from our ABA-to-AF translation
(step 1) we encode the ABA acceptance problem over the AF obtained via
step 1 using answer set programming (ASP). Interchangeably, one could apply
essentially any of the e.g. SAT-based AF reasoning systems via similar minor
modiﬁcations. We focus here on encodings for admissible and stable semantics;
other central argumentation semantics can be encoded with relatively minor
changes. Our encodings are similar to ones used in the ASP-based AF reasoning
system ASPARTIX [18], except for one seemingly minor but essential diﬀerence:
we represent the AF attack relation via its complement, using the predicate
natt/2 (not attack) which is true for a pair (a, b) of nodes iﬀa does not attack
b. This complement representation is vital as the edge relations of the AFs
obtained via step 1 are typically very dense. This is in stark contrast to typical
AF reasoning benchmark instances with relatively sparse attack relations [27].

From Structured to Abstract Argumentation: Assumption-Based Acceptance
65
Our encoding of the admissible semantics is
in(X) :- not out(X), arg(X).
:- in(X), in(Y ), not natt(X, Y ).
out(X) :- not in(X), arg(X).
defeated(X) :- in(Y ), not natt(Y, X), arg(X).
out(X) :- arg(X), not natt(X, X).
:- in(X), arg(Y ), not natt(Y, X), not defeated(Y ).
Further minor changes to the original ASPARTIX encoding are that we
include the rule on the lower left, and collapsed two rules to what is now
here the last rule. For stable semantics, we simply replace the last rule by
:- out(X), not defeated(X).
Implementing credulous ABA queries under NP-complete semantics such
as admissible, preferred, and stable on the AF side is achieved by checking if there
is an extension which includes an argument that contains the queried sentence
during argument construction. This is implemented with the ASP constraint :-
not in(a1), ..., not in(an). for arguments ai that contain queried sentence l, i.e.,
ai = (L, Δ) with l ∈L.
Implementing skeptical ABA queries for coNP-complete semantics such as
stable is achieved by checking if there is a counterexample to the query, i.e.,
whether there is an extension of the AF that does not include any arguments
containing the queried sentence. This is implemented by constraint :- in(ai). for
each argument ai that contains the queried sentence, pruning the search space
by partial instantiation. An alternative approach to skeptical acceptance would
be to enumerate all AF extensions, and check whether each of them includes
some argument that contains the queried sentence.
6
Experiments
For a ﬁrst evaluation of the two-step approach to answering ABA queries via
AF reasoning, we implemented a prototype translation (step 1) in Java 8. We
compare our approach to the recently published state-of-the-art graph-based
ABA reasoning system abagraph (http://www.doc.ic.ac.uk/∼rac101/proarg/
abagraph.html) implemented in Prolog, using SICStus Prolog 4.3.3. We used
the “default” search strategy of abagraph. The experiments were run on 2.83-
GHz Intel Xeon E5440 quad-core machines with 32-GB RAM under Linux using
a 600-second timeout and a 16-GB memory limit per instance. As the running
times of our approach, we report the combined time of the translation and the
ASP solver Clingo 4.5.4 [23].
As benchmarks we use the 680 ABA frameworks provided by the authors
of abagraph [7]. A benchmark instance consists of an ABA graph and a query
on whether a given sentence in the ABA framework is credulously accepted
under a speciﬁc semantics (recall that abagraph supports only credulous queries
under admissible and grounded semantics). For each ABA framework, we used
10 queries per ABA. After ﬁltering out 90 duplicate queries and trivial instances
wrt the special cases outlined for admissible semantics in the previous section,

66
T. Lehtonen et al.
we obtained 1466 ﬁnal benchmark instances. The benchmarks are explicitly cat-
egorized wrt whether the rules of a framework give rise to cyclic dependencies,
i.e., whether a framework is cyclic (804) or acyclic (662).
A comparison of abagraph and our approach is shown in Fig. 3 (left). Here we
consider the credulous task of enumerating all admissible assumption sets con-
taining the given query. The same task was used to evaluate abagraph in [7] and
shown to outperform earlier state of the art. For enumeration in our approach,
we used the built-in enumeration mode of Clingo. Figure 3 (left) shows that our
approach and that of the dedicated abagraph approach are complementary in
that there are instances on which each of the approaches is clearly better than the
other. Figure 3 (right) corroborates this observation. The relative performance
is essentially on-par on cyclic instances, while our approach is somewhat better
on acyclic instances. To illustrate the generality of our approach, we also exper-
imented on skeptical acceptance of sentences under stable semantics (a task not
supported by abagraph). Our approach solved 6228 of the 6710 instances. The
per-instance runtime was < 10 s on over 6000 instances. A majority of runtime
was used in the AF translation on every instance, AF translation taking over
80% of the total runtime on approximately 95% of the solved instances. The
ASP solving part was very eﬃcient, ﬁnishing within 65 s on each instance.
 1
 10
 100
 1
 10
 100
AF translator + ASP solver runtime (s)
abagraph runtime (s)
acyclic
cyclic
x
Timeouts
Uniquely solved
abagraph
us abagraph
us
acyclic
93
56
20
57
cyclic
394 402
86
78
Fig. 3. Left: running time comparison of abagraph and our approach on credulous
reasoning under admissible semantics. Right: numbers of timeouts and uniquely solved
instances.
7
Conclusions
We studied an approach to reasoning about acceptance in assumption-based
argumentation via translating ABA frameworks into argumentation frameworks.
We considered relevant ABA arguments as a sought after small yet suﬃcient set
for reasoning about acceptance of ABA sentences on AFs. However, we showed
that counting the number of relevant arguments is #P-complete, and hence pro-
posed an algorithm for overapproximating the set of relevant arguments in order

From Structured to Abstract Argumentation: Assumption-Based Acceptance
67
to translate ABAs to AFs, and ASP encodings speciﬁcally suited for the types
of AFs obtained through the translation. Our prototype implementation yields
complementary performance wrt the state-of-the-art dedicated ABA reasoning
system abagraph. As a further beneﬁt, our approach also allows for deciding
skeptical acceptance in ABA, not supported by abagraph.
References
1. Besnard, P., Garc´ıa, A.J., Hunter, A., Modgil, S., Prakken, H., Simari, G.R., Toni,
F.: Introduction to structured argumentation. Argum. Comput. 5(1), 1–4 (2014)
2. Besnard, P., Hunter, A.: Elements of Argumentation. The MIT Press, Cambridge
(2008)
3. Bondarenko,
A.,
Dung,
P.M.,
Kowalski,
R.A.,
Toni,
F.:
An
abstract,
argumentation-theoretic approach to default reasoning. Artif. Intell. 93, 63–101
(1997)
4. Caminada, M., S´a, S., Alcˆantara, J., Dvoˇr´ak, W.: On the diﬀerence between
assumption-based argumentation and abstract argumentation. In: Proceedings of
BNAIC, pp. 25–32 (2013)
5. Cerutti, F., Dunne, P.E., Giacomin, M., Vallati, M.: Computing preferred exten-
sions in abstract argumentation: a SAT-based approach. In: Black, E., Modgil, S.,
Oren, N. (eds.) TAFA 2013. LNCS, vol. 8306, pp. 176–193. Springer, Heidelberg
(2014). doi:10.1007/978-3-642-54373-9 12
6. Cerutti, F., Giacomin, M., Vallati, M.: ArgSemSAT: solving argumentation prob-
lems using SAT. In: Proceedings of COMMA. FAIA, vol. 266, pp. 455–456. IOS
Press (2014)
7. Craven, R., Toni, F.: Argument graphs and assumption-based argumentation.
Artif. Intell. 233, 1–59 (2016)
8. Craven, R., Toni, F., Cadar, C., Hadad, A., Williams, M.: Eﬃcient argumentation
for medical decision-making. In: Proceedings of KR, pp. 598–602 (2012)
9. Craven, R., Toni, F., Williams, M.: Graph-based dispute derivations in assumption-
based argumentation. In: Black, E., Modgil, S., Oren, N. (eds.) TAFA 2013.
LNCS (LNAI), vol. 8306, pp. 46–62. Springer, Heidelberg (2014). doi:10.1007/
978-3-642-54373-9 4
10. Dimopoulos, Y., Nebel, B., Toni, F.: On the computational complexity of
assumption-based argumentation for default reasoning. Artif. Intell. 141(1/2), 57–
78 (2002)
11. Dung, P.M.: On the acceptability of arguments and its fundamental role in non-
monotonic reasoning, logic programming and n-person games. Artif. Intell. 77(2),
321–358 (1995)
12. Dung, P.M., Kowalski, R.A., Toni, F.: Dialectic proof procedures for assumption-
based, admissible argumentation. Artif. Intell. 170(2), 114–159 (2006)
13. Dung, P.M., Kowalski, R.A., Toni, F.: Assumption-based argumentation. In: Rah-
wan, I., Simari, G.R. (eds.) Argumentation in Artiﬁcial Intelligence, pp. 25–44
(2009)
14. Dung, P.M., Mancarella, P., Toni, F.: Computing ideal sceptical argumentation.
Artif. Intell. 171(10–15), 642–674 (2007)
15. Dunne, P.E., Wooldridge, M.: Complexity of abstract argumentation. In: Rahwan,
I., Simari, G.R. (eds.) Argumentation in Artiﬁcial Intelligence, pp. 85–104 (2009)

68
T. Lehtonen et al.
16. Durand, A., Hermann, M., Kolaitis, P.G.: Subtractive reductions and complete
problems for counting complexity classes. Theor. Comput. Sci. 340(3), 496–513
(2005)
17. Dvoˇr´ak, W., J¨arvisalo, M., Wallner, J.P., Woltran, S.: Complexity-sensitive deci-
sion procedures for abstract argumentation. Artif. Intell. 206, 53–78 (2014)
18. Egly, U., Gaggl, S.A., Woltran, S.: Answer-set programming encodings for argu-
mentation frameworks. Argum. Comput. 1(2), 147–177 (2010)
19. Gaertner, D., Toni, F.: CaSAPI: a system for credulous and sceptical argumenta-
tion. In: Proceedings of NMR, pp. 80–95 (2007)
20. Gaertner, D., Toni, F.: Computing arguments and attacks in assumption-based
argumentation. IEEE Intell. Syst. 22(6), 24–33 (2007)
21. Gaertner, D., Toni, F.: Hybrid argumentation and its properties. In: Proceedings
of COMMA. FAIA, vol. 172, pp. 183–195. IOS Press (2008)
22. Garc´ıa, A.J., Simari, G.R.: Defeasible logic programming: an argumentative app-
roach. TPLP 4(1–2), 95–138 (2004)
23. Gebser, M., Kaufmann, B., Kaminski, R., Ostrowski, M., Schaub, T., Schneider,
M.T.: Potassco: the potsdam answer set solving collection. AI Comm. 24(2), 107–
124 (2011)
24. Nofal, S., Atkinson, K., Dunne, P.E.: Algorithms for decision problems in argument
systems under preferred semantics. Artif. Intell. 207, 23–51 (2014)
25. Nofal, S., Atkinson, K., Dunne, P.E.: Looking-ahead in backtracking algorithms
for abstract argumentation. Int. J. Approx. Reasoning 78, 265–282 (2016)
26. Prakken, H.: An abstract framework for argumentation with structured arguments.
Argum. Comput. 1(2), 93–124 (2010)
27. Thimm, M., Villata, S., Cerutti, F., Oren, N., Strass, H., Vallati, M.: Summary
report of the ﬁrst international competition on computational models of argumen-
tation. AI Mag. 37(1), 102 (2016)
28. Toni, F.: A generalised framework for dispute derivations in assumption-based
argumentation. Artif. Intell. 195, 1–43 (2013)
29. Toni, F.: A tutorial on assumption-based argumentation. Argum. Comput. 5(1),
89–117 (2014)

On Relating Abstract and Structured
Probabilistic Argumentation: A Case Study
Henry Prakken1,2(B)
1 Department of Information and Computing Sciences,
Utrecht University, Utrecht, The Netherlands
h.prakken@uu.nl
2 Faculty of Law, University of Groningen, Groningen, The Netherlands
Abstract. This paper investigates the relations between Timmer et al.’s
proposal for explaining Bayesian networks with structured argumenta-
tion and abstract models of probabilistic argumentation. First some chal-
lenges are identiﬁed for incorporating probabilistic notions of argument
strength in structured models of argumentation. Then it is investigated
to what extent Timmer et al’s approach meets these challenges and satis-
ﬁes semantics and rationality conditions for probabilistic argumentation
frameworks proposed in the literature. The results are used to draw con-
clusions about the strengths and limitations of both approaches.
1
Introduction and Motivation
There is a recent increase in interest in models of probabilistic argumentation.
In argumentation theory, Hahn and others have advocated a probabilistic inter-
pretation of argument schemes (e.g. [3]). A limitation of this work is that it does
not deal with several crucial features of argumentation-based inference, such as
attacks and combinations of arguments. Recent AI research on abstract models
of probabilistic argumentation, e.g. [6,7], addresses the ﬁrst limitation. However,
since it says nothing about the structure of arguments and the nature of attack,
the proposed models have so far been hard to interpret. For example, it is not
easy to understand what the probability of an argument means, since in proba-
bility theory probabilities are assigned to the truth of statements or to outcomes
of events, and an argument is in general neither a statement nor an event. What
is required here is a precise account in terms of the structure of arguments and
the nature of attack. The present paper aims to oﬀer such an account.
In the literature two diﬀerent uses of probability theory in argumentation can
be seen, depending on whether the uncertainty is in or about the arguments. In
the ﬁrst use, probabilities are intrinsic to an argument in that they are used for
capturing the strength of an argument given uncertainty concerning the truth of
its premises or the reliability of its inferences. An example is default reasoning
with probabilistic generalisations, as in The large majority of Belgian people
speak French, Mathieu is Belgian, therefore (presumably) Mathieu speaks French.
Clearly, if all premises of an argument are certain and it only makes deductive
c
⃝Springer International Publishing AG 2017
A. Antonucci et al. (Eds.): ECSQARU 2017, LNAI 10369, pp. 69–79, 2017.
DOI: 10.1007/978-3-319-61581-3 7

70
H. Prakken
inferences, the argument should be given maximum probabilistic strength. [4]
calls this use of probability the epistemic approach.
A second, extrinsic use of probability in argumentation (by [4] called the con-
stellations approach) is for expressing uncertainty about whether arguments are
accepted as existing by some arguing agent. [5] gives the example of a dialogue
participant who utters an enthymeme and where the listener can imagine two
reasonable premises that the speaker had in mind: the listener can then assign
probabilities to these options, which translate into probabilities on which argu-
ment the speaker meant to construct. This uncertainty has nothing to do with
the intrinsic strengths of the two candidate completed arguments: one might be
stronger than the other while yet the other is more likely the argument that the
speaker had in mind. Note that in this approach even deductive arguments from
certain premises can have less than maximal strength.
This paper focuses on the ﬁrst use of probability theory, unlike most recent
work on probabilistic abstract argumentation, which instead focuses on the sec-
ond use (cf. the overview in [6]). An exception is [4], who formally distinguishes
and develops both approaches, followed-up in e.g. [6]. For its epistemic approach
[4] instantiates probabilistic argumentation frameworks with classical argumen-
tation and deﬁnes the strength of an argument as the probability of the con-
junction of all its premises. However, while for classical argumentation (where
all arguments are deductive) this makes sense, this is not the case for accounts
where arguments make defeasible inferences from certain premises (as in the
above example of default reasoning, where it is both certain that the large major-
ity of Belgian people speaks French and that Mathieu is Belgian but where the
conclusion does not deductively follow from them): here all arguments should
according to [4] be given strength 1, which is clearly undesirable.
Accordingly, the problem studied in this paper is how to instantiate abstract
probabilistic frameworks with an account of intrinsic probabilistic strength of
structured arguments, where the premises of all arguments are certain but their
inferences can be defeasible. The problem will be studied in the context of a sim-
ple instantiation of the ASPIC+ framework [8]. In particular, [10]’s recent pro-
posal will be studied to explain forensic Bayesian networks in terms of ASPIC+-
style structured argumentation frameworks (SAFs) with probabilistic argument
strengths. Since SAFs are an instance of [1]’s abstract argumentation frame-
works (AFs), Timmer’s probabilistic SAFs are a suitable candidate for being
related to abstract probabilistic frameworks.
This paper is organised as follows. Section 2 presents the formal preliminaries.
Section 3 gives a conceptual analysis of the problem of deﬁning probabilistic
strengths of structured arguments. Section 4 summarises [10]’s structured model
of probabilistic argumentation. Section 5 then formally investigates its relation
with abstract probabilistic argumentation frameworks, while Sect. 6 draws some
general conclusions on the relation between abstract and structured models of
probabilistic argumentation.

On Relating Abstract and Structured Probabilistic Argumentation
71
2
Formal Preliminaries
An abstract argumentation framework (AF) is a pair ⟨A, attack⟩, where A is a
set arguments and attack ⊆A × A is a binary relation. The theory of AFs
addresses how sets of arguments (called extensions) can be identiﬁed which are
internally coherent and defend themselves against attack. A key notion here is
that of an argument being acceptable with respect to, or defended by a set of
arguments: A ∈A is defended by S ⊆A if for all B ∈A: if B attacks A, then
some C ∈S attacks B. Then relative to a given AF various types of extensions
can be deﬁned.
– E is admissible if E is conﬂict-free and defends all its members;
– E is a preferred extension if E is a ⊆-maximal admissible set;
– E is a stable extension if E is admissible and attacks all arguments outside
it;
– E ⊆A is the grounded extension if E is the least ﬁxpoint of operator F,
where F(S) returns all arguments defended by S.
Various proposals for extending abstract argumentation frameworks with prob-
abilities exist. Here we focus on one of the simplest proposals, the one of [7]
as adapted by [4]. A probabilistic argumentation framework (PrAF) is a triple
⟨A, attack, Pr⟩where ⟨A, attack⟩is an abstract argumentation framework and
Pr : A →[0, 1]. Further notions concerning PrAFs will be discussed in Sect. 5
below.
ASPIC+ [8] is a general framework for structured argumentation. It
abstracts from the logical language L except that it assumes a binary contrari-
ness relation deﬁned over L. In the present paper L will be a language of propo-
sitional or predicate-logic atoms. Arguments are constructed from a knowledge
base expressed in L by chaining inference rules deﬁned over L into graphs (which
are trees if no premise is used more than once). For present purposes only certain
(non-attackable) premises and defeasible (attackable) inference rules are needed.
All this reduces to the following deﬁnitions:
Deﬁnition 1 (Argumentation System). An argumentation system (AS) is
a tuple AS = (L,¯, R) where:
– L is a logical language consisting of propositional or predicate-logic atoms
– ¯: L →Pow(L) is a contrariness function over L
– R is a set of (defeasible) inference rules of the form φ1, . . . , φn ⇒φ (where
φ, φi are meta-variables ranging over wﬀin L).
Deﬁnition 2 (Knowledge Bases and Arguments). An argument A on the
basis of a knowledge base K ⊆L in an argumentation system AS is:
1. ϕ if ϕ ∈K with: Prem(A) = {ϕ}; Conc(A) = ϕ; Sub(A) = {ϕ};
2. A1, . . . An
⇒
ψ if A1, . . . , An are arguments such that Conc(A1), . . . ,
Conc(An) ⇒ψ ∈R with: Prem(A) = Prem(A1)∪. . .∪Prem(An), Conc(A) = ψ,
Sub(A) = Sub(A1) ∪. . . ∪Sub(An) ∪{A};

72
H. Prakken
An argument A is said to attack an argument B iﬀA rebuts B, where A rebuts
B (on B′) iﬀConc(A) = ϕ for some B′ ∈Sub(B) of the form B′′
1 , . . . , B′′
n ⇒ϕ.
The ASPIC+ counterpart of an abstract argumentation framework is a
structured argumentation framework.
Deﬁnition 3 (Structured Argumentation Frameworks). Let AT be an
argumentation theory (AS, K). A structured argumentation framework ( SAF)
deﬁned by AT, is a triple ⟨A, C, ⪯⟩where A is the set of all ﬁnite arguments con-
structed from K in AS, ⪯is an ordering on A, and (X, Y ) ∈C iﬀX attacks Y .
A relation of defeat is then deﬁned as follows (A ≺B is deﬁned as usual as
A ⪯B and B ̸⪯A). A defeats B iﬀA rebuts B on B′ and A ⊀B′. Abstract
argumentation frameworks are then generated from SAFs by letting the attacks
from an AF be the defeats from a SAF.
Deﬁnition 4 (Argumentation Frameworks).
An abstract argumentation
framework (AF) corresponding to a SAF = ⟨A, C, ⪯⟩(where C is ASPIC+’s
attack relation) is a pair (A, attack) such that attack is the defeat relation on A
determined by SAF.
3
Probabilistic Argument Strength: A Conceptual
Analysis
We can now make the problem studied in this paper even more speciﬁc. The
problem is: in the context of the just-described simple instantiation of ASPIC+,
how can a probabilistic notion of argument strength be deﬁned such that for two
arguments A and B we have that A ⪯B just in case strength(A) ≤strength(B)?
In other words: how can probabilistic argument strength be used to resolve
attacks into defeats?
A ﬁrst challenge here is that a higher internal strength does not necessar-
ily make an argument dialectically stronger. Suppose 90% of the birds can ﬂy,
and 80% of penguins cannot ﬂy. Should the argument Tweety can ﬂy since it
is a penguin so it is a bird be stronger than the argument Tweety cannot ﬂy
since it is a penguin? Of course not, since probability theory requires that all
evidence is taken into account, and since penguins are a special kind of bird, we
should (defeasibly) conclude that Tweety cannot ﬂy. More formally, if we have
Pr(q|p) = x and Pr(q|p∧r) = y and both p and r are given, then we should base
our inference on Pr(q|p ∧r) = y. For this reason, probability-based comparisons
between arguments should, either explicitly or implicitly, involve a kind of speci-
ﬁcity principle. For example, [2] do so in their notion of speciﬁcity defeat for
probabilistic assumption-based argumentation. More generally this shows that
the probabilistic strength of an argument cannot be calculated independent of
its attackers.
This issue arises in a diﬀerent way in case of attacks between arguments that
do not have a speciﬁcity relation. Consider the following well-known example

On Relating Abstract and Structured Probabilistic Argumentation
73
from nonmonotonic logic: Quakers are usually paciﬁsts, Republicans are usu-
ally not paciﬁsts, Nixon was a quaker and a republican. It is wrong to compare
Pr(P|Q) with Pr(¬P|R). What counts is Pr(P|Q∧R) and in general the latter
probability is independent of the former probabilities (although in special cases
this may be diﬀerent).
A third challenge arises from the step-by-step nature of arguments. Consider
I see smoke, my observations are usually correct, therefore (presumably) there
is smoke. Where there is smoke, there usually is ﬁre, therefore (presumably)
there is ﬁre. Can a recursive deﬁnition of argument strength be given where
the strength of the entire argument depends on the strength of its subargument
for there is smoke and the strength of its ﬁnal step? This is not a trivial prob-
lem, since Pr(ﬁre|seesmoke) does in general not follow from Pr(ﬁre|smoke) and
Pr(smoke|seesmoke).
4
Explaining Bayesian Networks with Argumentation
In this section we summarise [10]’s method for explaining (forensic) Bayesian
networks with argumentation. A Bayesian network is a graphical representation
of a joint probability distribution. Formally, it is a pair (G, Pr) where G is a
directed acyclic graph (V, E), with a ﬁnite set of variables V connected by edges
E from V×V, and Pr is a probability function which speciﬁes for every variable
Vi the probability distribution Pr(Vi|parents(Vi)) of its outcomes conditioned on
its parents parents(Vi) in the graph. [10] assume that all variables are boolean.
[10] ﬁrst set the language L of the ASPIC+ argumentation system to the
set of all V = v expressions where V ∈V and v is a possible value of V . Then
ϕ ∈ψ iﬀϕ and ψ assign diﬀerent values to the same variable. [10] then derive
an ASPIC+ SAF from a BN plus a set of instantiated variables (the evidence)
in terms of an intermediate structure called a support graph, which for a given
variable of interest from V captures the potential reasoning paths through the
BN. Entering evidence in a BN prunes all branches of the support graph that
do not end in evidence. Arguments can be constructed from the support graph
by making its non-premise nodes either true or false.
The basic idea is illustrated with Figs. 1 and 2, displaying an example from
[10]. The variable of interest in the BN is whether the suspect committed the
Crime. Evidence for this can be a DNA match between the suspect’s DNA and
DNA found at the crime scene. Such a DNA match may also be explained by
the existence of a Twin brother. The existence of a Motive makes the crime
more likely. Evidence for a motive may be given in a psychological report
(Psych report). After the evidence Psych report = True and DNA match = True
is entered into the BN, the chain in the support graph from Twin to Crime is
pruned away. The arguments generated from this are all inference trees corre-
sponding to the pruned graph or a subgraph with all non-evidence nodes instan-
tiated in any possible way (i.e., with either True or False). Figure 2 displays the
arguments when Psych report and Crime are both true. Formally (with contrari-
ness for convenience encoded with negation, even though ¬ is strictly speaking
not part of L) both these pieces of evidence are arguments and moreover:

74
H. Prakken
Fig. 1. A Bayesian network (below) and a support graph (above).
A1 = Psych report ⇒Motive
A2 = A1, DNA match ⇒Crime
But, for instance, the following arguments can also be constructed:
B1 = Psych report ⇒¬ Motive
B2 = B1, DNA match ⇒¬ Crime
C = A1, DNA match ⇒¬ Crime
Suppose that now Twin also becomes available as evidence. At ﬁrst sight, one
might expect that this gives rise to rebuttal of A2 of the form Twin ⇒¬ Crime.
However, this is not how the method works. Instead, it captures all variables
relevant to a conclusion in a single argument concerning that conclusion. So, A2,
B2 and C are modiﬁed to:
A′
2 = A1, DNA match, Twin ⇒Crime
B′
2 = B1, DNA match, Twin ⇒¬ Crime
C′ = A1, DNA match, Twin ⇒¬ Crime
So for every constructable argument there is a rebuttal with the same ‘skele-
ton’ but with some truth values of non-premises ﬂipped, and there are no other
(direct) rebuttals.
Space limitations prevent listing the formal deﬁnitions of the support graph
and the induced SAF. Essentially, the knowledge base consists of the evidence
while the set of defeasible rules corresponds to links in the support graph. For
present purposes all that is relevant is that the following deﬁnition of argument
strength, when used to resolve attacks into defeats, gives the induced SAF a
number of ‘good’ properties, which means that [10]’s way to deﬁne probabilistic
structured argumentation as an instantiation of Dung-style AFs makes sense
(with some simpliﬁed notation compared to [10]):
strength(A) = Pr(Conc(A)|K)
(where K is the knowledge base of the AT induced by the BN-with-evidence).
Thus the strength of an argument A equals the posterior probability of Conc(A)
in the BN-with-evidence inducing the SAF. This deﬁnition implies that the
strengths of two directly rebutting arguments always adds up to 1, since
Pr(Q|P) = 1 −Pr(¬Q|P).

On Relating Abstract and Structured Probabilistic Argumentation
75
Fig. 2. Deriving arguments from the pruned support graph after entering evidence.
Figure 2 displays the strengths of the non-premise arguments in the ﬁgure,
based on the probability tables in [10]. The strength of B1 is 1 −strength(A1) =
11% and the strength of B2 and C is 1 −strength(A2) = 5%. In fact, to obtain
the results listed below, for arguments for the variable of interest the deﬁn-
ition of strength can be reduced to the equivalent deﬁnition strength(A) =
Pr(Conc(A)|Prem(A)). However, for subarguments the inclusion of all of K is
needed. For the reasons why see [10]. It should be noted that a strength of 1 of
a non-premise argument does not mean that it should be modelled as applying
strict rules, since Pr(P|Q) = 1 does not imply Pr(P|Q ∧R) = 1. So even a
non-premise argument of strength 1 is defeasible.
The ‘good’ properties (as proven by or easily following from [10]) are as
follows.
1. The grounded extension equals the set of undefeated arguments.
2. The grounded extension satisﬁes subargument closure, direct and indirect
consistency and (trivially) strict closure. For the deﬁnitions of these properties
see [8].
3. If A is in the grounded extension, then A is the strongest argument for
Conc(A).
4. If A is in the grounded extension, then strength(A) > 0.5.
Interestingly, an argument can be stronger than some of its subarguments, An
example is Fig. 2, where argument A2 for Crime is stronger than its subargu-
ment A2 for motive. This can happen since by combining arguments A1 and
DNA match, argument A2 aggregates the support given to its conclusion by
two pieces of evidence. This reﬂects a general feature of probabilistic reasoning,
namely, that the combination of pieces of evidence that each have weak probative
force can have strong probative force.
Let us see how [10]’s approach deals with the challenges discussed in Sect. 3.
The ﬁrst two challenges are dealt with since, ﬁrstly, all arguments contain all
variables from the BN that are relevant for their conclusions and, secondly,
argument strength is deﬁned relative to all (relevant) evidence. While this is

76
H. Prakken
good, it also has an obvious limitation, namely, that two arguments with the
same premises and conclusion but diﬀerent internal structure have the same
strength. Thus the third challenge is not fully met. On the other hand, it is
still partially met since two such arguments can have subarguments of diﬀerent
strengths, and this can be reported to those to which the BN is explained.
Another possible limitation is that in [10] the reasons pro and con a conclusion
are not, as usual in argumentation, distributed over conﬂicting arguments but
are all contained in a single argument for or against the conclusion, which is
not according to the conceptual idea underlying argumentation-based inference.
Nevertheless, for the purpose of explaining forensic Bayesian networks to judges,
prosecutors and defence lawyers this may be perfectly adequate.
5
Relating the Abstract and Structured Accounts
We now investigate whether the work of [10] can be seen as an instantiation of
epistemically interpreted probabilistic abstract frameworks in the sense of [4].
The ﬁrst step is obvious, namely, equating the probability of an argument in a
PrAF with the argument’s strength according to [10]. However, the next step,
instantiating the attack relation of PrAFs, is less obvious: should it be instanti-
ated with ASPIC+’s C relation of attack or with its defeat relation? Let us ﬁrst
assume that the probability of an argument is to be used to resolve attacks: can
this be modelled at the abstract level or should this be modelled while taking the
structure of arguments into account? [8] provide reasons for the latter approach,
since the former approach cannot distinguish between direct and indirect attack
relations and therefore runs the risk of applying the wrong probabilities to an
attack. Consider an argument A3 = A1, A2 ⇒ϕ and an argument B rebutting
A3 on A1. [8] show that with a last-link ordering in terms of rule priorities it
may be that A1 ≺B while B ≺A3. Then resolving the attacks at the abstract
level by saying that an argument A attacks (i.e., ASPIC+-defeats) an argument
B iﬀA rebuts B and A ⊀B results in a grounded/preferred/stable/complete
extension {A2, A3, B}, which is not closed under the subargument relation. This
problem arises since the rebuttal of B on A3 is incorrectly resolved with B ≺A3
(so B does not attack A3 in the AF) while it should be resolved with A1 ≺B
(so B does attack A3 in the AF), resulting in a grounded extension {A2, B}. As
shown by [8], the same problem can make conclusion sets of extensions violate
consistency. Since, as noted above, in [10]’s approach an argument can also be
stronger than some of its subarguments, all these problems also arise if the Pr
function is used at the abstract level of PrAFs to resolve attacks. This is an
important lesson that can be learned from the present analysis.
In [4], which instantiates PrAFs with classical argumentation, the argument
probabilities are not used in deﬁning the attack relation between arguments,
so (in terms of ASPIC+), [4] instantiates the attack relation of PrAFs with
ASPIC+’s C relation. Yet his approach does not necessarily suﬀer from the just-
sketched problems, since [4] does not use the Pr functions to resolve the attacks
in PrAFs. Instead, he deﬁnes the following notions. The epistemic extension

On Relating Abstract and Structured Probabilistic Argumentation
77
of a PrAF is {A ∈A|Pr(A) > 0.5}. A probability function is rational iﬀfor
every pair of arguments A and B such that A attacks B, if Pr(A) > 0.5 then
Pr(B) ≤0.5. A PrAF is called rational if its Pr is rational. [4] then proves that
for every rational PrAF its epistemic extension is conﬂict-free with respect to
the attack relation.
Yet the notion of an epistemic extension combined with the rationality con-
straint on Pr is not a good abstraction of [10]’s approach. To start with, the
grounded extension in [10]’s approach does not always equal the epistemic exten-
sion. Consider a support graph E −→H1 −→H2 and consider the arguments
(E ⇒H1) ⇒H2 and (E ⇒¬H1) ⇒H2. Both have the same strength. Suppose
their strength exceeds 0.5. Then they cannot be both in the grounded extension,
since they have rebutting subarguments. Yet both are in the epistemic extension.
This can happen since in [10]’s approach an argument can be stronger than some
of its subarguments.
Next, [10]’s probability function is not guaranteed to be rational. Consider
the same support graph, the above arguments and their respective subargu-
ments E ⇒H1 and E ⇒H2, and suppose strength((E ⇒H1) ⇒H2) = 0.6 and
strength((E1 ⇒H1)) = 0.4 and strength((E1 ⇒¬H1)) = 0.6. The argument
for ¬H1 indirectly attacks the argument for H2 but both have strength > 0.5.
This can happen since the attack is indirect. In PrAFs the distinction between
direct and indirect attack cannot be modelled. However, if the rationality con-
straint is conﬁned to direct attacks, then it holds, since the strengths of two
directly rebutting arguments always add up to 1. This is a ﬁrst indication of the
importance of taking the structure of arguments into account.
Further indications follow from an analysis of the other “rationality condi-
tions” on PrAFs proposed in [6]. (Below for any A ∈A, A−= {B|B attacks A}).
COH Pr is coherent if for every A, B ∈A, if A attacks B then Pr(A) ≤
1 −Pr(B).
INV Pr is involutary if for every A, B ∈A, if A attacks B then Pr(A) =
1 −Pr(B).
SFOU Pr is semi-founded if Pr(A) ≥0.5 for every unattacked A ∈A.
FOU Pr is founded if Pr(A) = 1 for every A ∈A with A−= ∅.
SOPT Pr is semi-optimistic if Pr(A) ≥1 −ΣB∈A−Pr(B) whenever A−̸= ∅.
OPT Pr is optimistic if Pr(A) ≥1 −ΣB∈A−Pr(B) for every A ∈A.
We now investigate whether these properties hold for [10]’s approach, for
both the ASPIC+ C relation and its defeat relation. In doing so, we will use
the support graph E −→H1 −→H2 and the various arguments it generates
with evidence E, assuming that both Pr(H1|K) > 0.5 and Pr(H2|K) > 0.5.
(For space limitations we omit a proof that a BN that generates such a support
graph, arguments and strengths exists).
COH in general neither holds for C nor for defeat, since these relations can
be indirect. For example, argument (E ⇒H1) ⇒H2 rebuts (E ⇒¬H1) ⇒
H2 on E ⇒¬H1 but both arguments have strength > 0.5 (even though the
latter’s subargument for ¬H1 has strength < 0.5). However, COH does hold

78
H. Prakken
when restricted to direct C or defeat relations, since for every pair of direct
rebuttals their strengths add up to 1. All these observations also hold for INV.
SFOU holds in general for both C and defeat. For C, note that the only non-
rebutted arguments are elements of K, which by deﬁnition have strength 1. For
defeat, if B unsuccessfully directly rebuts A, then strength(B) < strength(A) so
since these strengths add up to 1, strength(A) > 0.5. Note further that every
non-premise argument has at least one rebuttal, so every non-defeated argument
has strength > 0.5.
FOU holds in general for C but not for defeat. For C FOU holds for the same
reason as why SFOU holds. Our above example provides a counterexample for
defeat if the strength of the argument for H2 does not equal 1. This is also a
counterexample for FOU restricted to direct defeats.
SOPT neither holds for C nor for defeat, and neither for the direct nor for
the indirect relations. In our example, (E ⇒H1) ⇒H2 has two direct rebuttals,
namely, (E ⇒H1) ⇒¬H2 and (E ⇒¬H1) ⇒H2. If the strength of the
argument for H2 is higher than 0.5 but below 0.75, then the strengths of its two
rebuttals add up to above 0.5. This is also a counterexample to OPT.
The negative results do not indicate ﬂaws of [10]’s approach, since they are
due to two of its features which both are reasonable for probabilistic argumen-
tation: the distinction between direct and indirect attack and the fact that an
argument can be stronger than some of its subarguments. It can therefore be
concluded that [6]’s set of rationality conditions cannot be seen as minimum
conditions for the well-behavedness of PrAFs.
6
Conclusion
In this paper we have investigated to what extent [10]’s probabilistic version of
ASPIC+, proposed for explaining Bayesian networks, satisﬁes semantics and
rationality conditions for probabilistic argumentation frameworks proposed in
the literature. Some results were positive but other results were negative. The
negative results do not seem to point at ﬂaws of [10]’s approach but instead at
limitations of current abstract models of probabilistic argumentation, in partic-
ular their failure to distinguish between direct and indirect relations of attack
and defeat. One conclusion is that to make this distinction in a proper way,
the structure of arguments and the nature of attack and defeat must be made
explicit. Another conclusion is that not all rationality conditions for probabilistic
models of argumentation proposed in the literature can be regarded as minimum
requirements for the well-behavedness of these models.
This paper has also identiﬁed several challenges for attempts to use prob-
abilistic argument strength for resolving attacks into defeats. These challenges
arise from the diﬀerence between the global nature of Bayesian probabilistic rea-
soning (where all evidence has to be taken into account) and the local nature
of argumentation (where particular conﬂicting arguments are compared). [10]
found a way to meet these challenges but with some limitations. While [10]’s
approach may suﬃce for its intended application of explaining forensic Bayesian

On Relating Abstract and Structured Probabilistic Argumentation
79
networks, future research should study whether more general solutions are pos-
sible without these limitations.
Some related work was already discussed throughout this paper. In addi-
tion, [2] propose an extension of [1]’s abstract frameworks with probability and
then extend assumption-based argumentation with the means to label literals
in rules with probabilities. The abstract approach models more than what is of
present concern, namely, some aspects of multi-agent argumentation, while the
abstract and assumption-based parts are not formally related. In future research
it would be interesting to investigate [2]’s probabilistic version of assumption-
based argumentation in the same way as we did for [10]’s probabilistic version
of ASPIC+.
In this paper we studied the use of probability for two things: for resolving
attacks into defeats within ASPIC+ and for identifying epistemic extensions in
the sense of [4]. In future research it would be interesting to investigate the use
of probability to deﬁne graded notions of argument acceptability, as in e.g. [9].
We conjecture that here, too, it is important to take the structure of arguments
and the nature of attack into account.
References
1. Dung, P.M.: On the acceptability of arguments and its fundamental role in non-
monotonic reasoning, logic programming, and n-person games. Artif. Intell. 77,
321–357 (1995)
2. Dung, P.M., Thang, P.M.: Towards (probabilistic) argumentation for jury-based
dispute resolution. In: Baroni, P., Cerutti, F., Giacomin, M., Simari, G.R. (eds.)
Computational Models of Argument. Proceedings of COMMA 2010, pp. 171–182.
IOS Press, Amsterdam (2010)
3. Hahn, U., Hornikx, J.: A normative framework for argument quality: argumenta-
tion schemes with a Bayesian foundation. Synthese 193, 1833–1873 (2016)
4. Hunter, A.: A probabilistic approach to modelling uncertain logical arguments. Int.
J. Approx. Reason. 54, 47–81 (2013)
5. Hunter, A.: Probabilistic qualiﬁcation of attack in abstract argumentation. Int. J.
Approx. Reason. 55, 607–638 (2014)
6. Hunter, A., Thimm, M.: On partial information and contradictions in probabilistic
abstract argumentation. In: Principles of Knowledge Representation and Reason-
ing: Proceedings of the Fifteenth International Conference (KR-16), pp. 53–62.
AAAI Press (2016)
7. Li, H., Oren, N., Norman, T.: Probabilistic argumentation frameworks. In: Pro-
ceedings First Workshop on the Theory and Applications of Formal Argument, pp.
1–16 (2011)
8. Modgil, S., Prakken, H.: A general account of argumentation with preferences.
Artif. Intell. 195, 361–397 (2013)
9. Thimm, M.: A probabilistic semantics for abstract argumentation. In: Proceedings
of the 20th European Conference on Artiﬁcial Intelligence (ECAI 2012), pp. 750–
755 (2012)
10. Timmer, S., Meyer, J.-J.C., Prakken, H., Renooij, S., Verheij, B.: A two-phase
method for extracting explanatory arguments from Bayesian networks. Int. J.
Approx. Reason. 80, 475–494 (2017)

Bayesian Networks

Structure-Based Categorisation of Bayesian
Network Parameters
Janneke H. Bolt(B) and Silja Renooij
Department of Information and Computing Sciences, Utrecht University,
P.O. Box 80.089, 3508 TB Utrecht, The Netherlands
{j.h.bolt,s.renooij}@uu.nl
Abstract. Bayesian networks typically require thousands of probability
para-meters for their speciﬁcation, many of which are bound to be inac-
curate. Know-ledge of the direction of change in an output probability
of a network occasioned by changes in one or more of its parameters, i.e.
the qualitative eﬀect of parameter changes, has been shown to be useful
both for parameter tuning and in pre-processing for inference in credal
networks. In this paper we identify classes of parameter for which the
qualitative eﬀect on a given output of interest can be identiﬁed based
upon graphical considerations.
1
Introduction
A Bayesian network deﬁnes a unique joint probability distribution over a set of
discrete random variables [8]. It combines an acyclic directed graph, representing
the independencies among the variables, with a quantiﬁcation of local discrete
distributions. The individual probabilities of these local distributions are called
the parameters of the network. A Bayesian network can be used to infer any
probability from the represented distribution.
The eﬀect of possible parameter inaccuracies on the output probabilities of a
network can be studied with a sensitivity analysis. An output can be described as
a fraction of two functions that are linear in any network parameter; the coeﬃ-
cients of the functions are determined by the non-varied parameters [6]. Depend-
ing on the coeﬃcients, such so-called sensitivity functions are either monotone
increasing or monotone decreasing functions in each parameter. Interestingly, as
we showed in previous research, for some outputs and parameters, the sensitiv-
ity function is even always increasing (or decreasing) regardless of the speciﬁc
values of the other network parameters [1]. That is, regardless of the speciﬁc
quantiﬁcation of a network, the coeﬃcients of the sensitivity function for a cer-
tain parameter can be such that the gradient is always positive (or always neg-
ative). In such a case, the qualitative eﬀect of a parameter change on an output
probability can be predicted from properties of the network structure, without
considering the values of the other network parameters.
Knowledge of the qualitative eﬀect of parameter changes can be exploited
for diﬀerent purposes. Examples of applications can be found in pre-processing
for inference in credal networks [1] and in multi-parameter tuning of Bayesian
networks [2].
c
⃝Springer International Publishing AG 2017
A. Antonucci et al. (Eds.): ECSQARU 2017, LNAI 10369, pp. 83–92, 2017.
DOI: 10.1007/978-3-319-61581-3 8

84
J.H. Bolt and S. Renooij
In this paper we present a complete categorisation of a network’s parameters
with respect to their qualitative eﬀect on some output, where we assume that
the network is pruned before hand to a sub-network that is computationally
relevant to the output. The paper extends the work in [1] in which only a partial
categorisation of the network parameters was given. Compared to our previous
results, the present results also enable a meaningful categorisation for a wider
range of parameters.
2
Preliminaries
2.1
Bayesian Networks and Notation
A Bayesian network B = (G, Pr) represents a joint probability distribution
Pr over a set of random variables W as a factorisation of conditional distrib-
utions [5]. The independences underlying this factorisation are read from the
directed acyclic graph G by means of the well-known d-separation criterion. In
this paper we use upper case W to denote a single random variable, writing
lowercase w ∈W to indicate a value of W. For binary-valued W, we use w and
w to denote its two possible value assignments. Boldfaced capitals are used to
indicate sets of variables or sets of value assignments, the distinction will be
clear from the context; boldface lower cases are used to indicate a joint value
assignment to a set of variables.
Two value assignments are said to be compatible, denoted by ∼, if they agree
on the values of the shared variables; otherwise they are said to be incompatible,
denoted by ≁. We use Wpa(V ) = W ∩pa(V ) to indicate the subset of W that is
among the parents of V , and Wpa(V ) = W\Wpa(V ) to indicate its complement in
W; descendants of V are captured by de(V ). To conclude, ⟨T, U|V⟩d, T, U, V ⊆
W, denotes that all variables in T are d-separated from all variables in U given
the variables in V, where we assume that ⟨T, ∅|V⟩d = True.
A Bayesian network speciﬁes for each variable W ∈W exactly one local
distribution Pr(W |π) over the values of W per value assignment π to its parents
pa(W) in G, such that
Pr(w) =

W ∈W
Pr(w|π)

wπ∼w
where the notation |prop is used to indicate the properties the arguments in
the preceding formula adhere to. The individual probabilities in the local dis-
tributions are termed the network’s parameters. A Bayesian network allows for
computing any probability over its variables W. A typical query is Pr(h|f),
involving two disjoint subsets of W, often referred to as hypothesis variables
(H) and evidence variables (F); W can also include variables not involved in
the output query of interest.
An example Bayesian network is shown in Fig. 1. For output Pr(ghk|def) we
identify hypothesis variables H = {G, H, K} (double circles), evidence variables
F = {D, E, F} (shaded), and remaining variables {R, S}. In addition to the
graph, conditional probability tables (CPTs) need to be speciﬁed for each node.

Structure-Based Categorisation of Bayesian Network Parameters
85
Fig. 1. An example Bayesian
network (with just two of its
CPTs).
Fig. 2. The example network from Fig. 1 after
query dependent preprocessing given the output
probability Pr(ghk|def).
2.2
Query Dependent Pre-processing
Prior to computing the result of a query, the Bayesian network can be pre-
processed by removing parts of its speciﬁcation that are easily identiﬁed as being
irrelevant to the computations. Sets of nodes that can be removed based upon
graphical considerations only are nodes d-separated from H given F, irrelevant
evidence nodes (eﬀects blocked by other evidence), and barren nodes, that is,
nodes in W\(H∪F) which are leafs or have only barren descendants; the remain-
ing nodes coincide with the so-called parameter sensitivity set [3,7]. In addition,
evidence absorption can be applied, where the outgoing arcs of variables with evi-
dence are removed and the CPTs of the former children are reduced by removing
the parameters that are incompatible with the observed value(s) of their former
parent(s) [4]. After evidence absorption, all variables with evidence correspond
to leafs in the graph and the CPT parameters of their former children will all
be compatible with the evidence.
From here on we consider Bayesian networks that are reduced to what we
call its query-dependent backbone Bq, using the above-mentioned pre-processing
options1. Bq, tailored to the original query Pr(h|f), is assumed to be a Bayesian
network over variables V ⊆W from which the now equivalent query Pr(h|e) is
computed for evidence variables E ⊆F; the remaining variables V\(H ∪E) will
be denoted by R.
The backbone given output Pr(ghk|def) in our example network from Fig. 1
is depicted in Fig. 2. After evidence absorption, the arc from F to K and the
last two rows of K’s CPT are removed. The node S is removed since it is barren,
and D is removed, since it is d-seperated from the variables in H given F. In
the backbone network we have the hypothesis variables H = {G, H, K}, the
evidence variables E = {E, F} and the remaining variable R = {R}.
1 Note that the parameters of the local distributions that are in B but not in Bq do
not aﬀect the output of interest in any way.

86
J.H. Bolt and S. Renooij
2.3
Relating Queries to Parameters
It is well-known that an output of a Bayesian network relates to a network
parameter x as a fraction of two functions linear in that parameter:
Pr(h|e)(x) = Pr(he)(x)
Pr(e)(x) = τ1 · x + τ2
κ1 · x + κ2
where the constants τ1, τ2, κ1 and κ2 are composed of network parameters inde-
pendent of x [3]. The above function can be generalised to multiple parameters [6]
and is typically exploited in the context of sensitivity analysis, to determine how
a change in one or more parameters aﬀects Pr(h|e). We note that upon varying
a parameter x of a distribution, the other parameters of the same distribution
have to be co-varied to let the distribution sum to 1. If the distribution is associ-
ated with a binary variable, the co-varying parameter equals 1−x. If a variable is
multi-valued, however, diﬀerent co-variation schemes are possible [9]. Sensitivity
functions are monotonic functions in each parameter, and are either increasing or
decreasing functions in such a parameter. Here we consider increasing (decreas-
ing) in a non-strict sense, that is, increasing (decreasing) includes non-decreasing
(non-increasing).
3
Categorisation of Parameters in a Backbone
Network Bq
We will discuss the parameters of the variables in R, H and E of a backbone
network and categorise these parameters according to their qualitative eﬀect on
Pr(h|e) as summarised in Table 1. In the proofs of our propositions we repeatedly
use the deﬁnition of conditional probability and the factorisation deﬁned by Bq:
Pr(h|e) = Pr(he)
Pr(e)
in which for the numerator Pr(he) we ﬁnd
Pr(he) =

r∈R
Pr(rhe) =

r∈R

V ∗∈V
Pr(v∗|π∗)

v∗π∗∼rhe
(1)
and for the denominator Pr(e) we ﬁnd that
Pr(e) =

r∈R,h∗∈H
Pr(rh∗e) =

r∈R,h∗∈H

V ∗∈V
Pr(v∗|π∗)

v∗π∗∼rh∗e
(2)
Parameters which are not present in Eqs. (1) and (2) cannot aﬀect the output
directly and are categorised as ‘∗’. The eﬀect of all other parameters is investi-
gated by studying properties of their sensitivity functions Pr(h|e)(x). Parame-
ters that are guaranteed to give a monotone increasing sensitivity function are
classiﬁed as ‘+’; parameters that are guaranteed to give monotone decreasing

Structure-Based Categorisation of Bayesian Network Parameters
87
Table 1. Categorisation of parameters x = Pr(v|π) of a Bayesian network Bq with
respect to the output probability Pr(h|e).
V ∈R cat ‘?’
V ∈H E ∩de(V ) = ∅v ∼h, π ∼h
cat ‘+’
v ≁h or π ≁h cat ‘∗’
E ∩de(V ) ̸= ∅non-binary V
cat ‘?’
binary V
π ≁h cat ‘?’
π ∼h ¬⟨Hpa(V ), Rpa(V ) |E ∪Hpa(V ) ∪V ⟩d cat ‘?’
⟨Hpa(V ), Rpa(V ) |E ∪Hpa(V ) ∪V ⟩d
v ∼h cat ‘+’
v ≁h cat ‘−’
V ∈E v ≁e
cat ‘∗’
v ∼e
π ≁h
cat ‘−’
π ∼h
¬⟨Hpa(V ), Rpa(V ) |E ∪Hpa(V )⟩d cat ‘?’
⟨Hpa(V ), Rpa(V ) |E ∪Hpa(V )⟩d
cat ‘+’
sensitivity functions as ‘−’. Parameters for which the sign of the derivative of
the sensitivity function depends on the actual quantiﬁcation of the network will
be categorised as ‘?’. Note that sensitivity functions for parameters of category
‘∗’ are not necessarily constant: variation of such a parameter may result in
co-variation of a parameter from the same local distribution which is present
in Eqs. (1) or (2). As such, parameters of category ‘∗’ may be indirectly aﬀect-
ing output Pr(h|e), yet for the computation of Pr(h|e) it suﬃces to know the
values of parameters in the categories ‘+’, ‘−’ and ‘?’. In the relation between
parameter changes and output changes these latter parameters are pivotal.
For the backbone network of our example in Fig. 2, the categories of its
parameters are indicated in the CPTs.
4
Categorisation of the Parameters of Variables in R
and H
4.1
Parameters of Variables in R
For a variable R ∈R the qualitative eﬀect of a change in one of its parameters
x cannot be predicted without additional information: the sensitivity function
Pr(h|e)(x) can be either monotone increasing or decreasing. Therefore, these
parameters are categorised as ‘?’.
Proof of the above claim, and of all further propositions concerning para-
meters in the category ‘?’, is omitted due to space restrictions. All these proofs
are based on demonstrating that additional knowledge—for example the speciﬁc
network quantiﬁcation—is required to determine whether the one-way sensitivity
function is increasing or decreasing.
4.2
Parameters of Variables in H Without Descendants in E
The propositions in this section concern parameters x = Pr(v|π) of nodes V ∈
H without descendants in E. The parameters of such a node which are fully

88
J.H. Bolt and S. Renooij
compatible with h have a monotone increasing sensitivity function Pr(h|e)(x)
and therefore are classiﬁed as ‘+’. The parameters not fully compatible with h
are not used in the computation of Pr(h|e) and therefore are classiﬁed ‘∗’.
Proposition 1. Consider a query-dependent backbone Bayesian network Bq
with probability of interest Pr(h|e). Let x = Pr(v|π) be a parameter of a vari-
able V ∈H such that de(V ) ∩E = ∅. If both v ∼h and π ∼h, then Pr(h|e)(x)
is a monotone increasing function.
Proof. Let rπ denote the conﬁguration of Rpa(V ) compatible with π. In addi-
tion, let h = vhπhπ, where hπ and hπ are assignments, compatible with h, to
Hpa(V ) and Hpa(V ), respectively. First consider the general form of Pr(he) given
by Eq. (1). We observe that under the given conditions we can write:
Pr(he)(x) = x·Pr(hπ |vhπerπ) · Pr(vhπerπ)
Pr(v|π)
+

r+∈Rpa(V )
Pr(vhπhπer+)

r+̸=rπ
where Pr(vhπerπ)/ Pr(v|π) represents a sum of products of parameters no
longer including Pr(v|π). This expression thus is of the form x · τ1 · τ2 + τ3,
for non-negative constants τ1, τ2, τ3.
For Pr(e), as given in Eq. (2), we observe that since V has no descendants
in E, this node in fact is barren with respect to Pr(e). As a result, none of
V ’s parameters are relevant to the computation and Pr(e)(x) therefore equals a
constant κ1 > 0.
The sensitivity function for parameter x thus is of the form Pr(h|e)(x) =
(x·τ1 ·τ2 + τ3)/κ1 with τ1, τ2, τ3 ≥0 and κ1 > 0. The ﬁrst derivative of this
function equals (τ1·τ2)/κ1, which is always non-negative.
□
Proposition 2. Let Bq and Pr(h|e) be as before. Let Pr(v|π) be a parameter
of a variable V ∈H such that de(V ) ∩E = ∅. If v ≁h or π ≁h, then Pr(v|π)
is not used in the computation of Pr(h|e).
Proof. We again consider Pr(he) as given by Eq. (1) and observe that a parameter
Pr(v|π) with v ≁h or π ≁h is not included in this expression. Moreover, as
argued in the proof of Proposition 1, no parameter of V is used in computing Pr(e)
from Eq. (2). Pr(v|π) is therefore not used in the computation of Pr(h|e).
□
4.3
Parameters of Variables in H with Descendants in E
For a parameter of a non-binary variable V ∈H with at least one descendant
in E, we cannot predict without additional knowledge whether the sensitivity
function Pr(h|e)(x) is monotone increasing or monotone decreasing. These para-
meters therefore are classiﬁed as ‘?’. The same observation applies to a parameter
of a binary variable V ∈H with descendants in E for which π ≁h or for which
Hpa(V ) and Rpa(V ) are not d-separated given Hpa(V ), V itself and the evidence.

Structure-Based Categorisation of Bayesian Network Parameters
89
If V ∈H is binary, π ∼h and Hpa(V ) and Rpa(V ) are d-separated given
Hpa(V ), V itself and the evidence, then we do have suﬃcient knowledge to deter-
mine the qualitative eﬀect of varying parameter x = Pr(v|π) of V . If v ∼h then
Pr(h|e)(x) is monotone increasing, and the parameter is classiﬁed as ‘+’. If
v ≁h then Pr(h|e)(x) is monotone decreasing, and the parameter is classi-
ﬁed as ‘−’ These observations are captured by Proposition 3. This proposition
extends Proposition 2 in [1] by replacing the condition that Rpa(V ) = ∅by the
less strict d-separation condition mentioned above.
Proposition 3. Let Bq and Pr(h|e) be as before. Let Pr(v|π) with π ∼h be a
parameter of a binary variable V ∈H and let ⟨Hpa(V ), Rpa(V )|E∪Hpa(V ) ∪V ⟩d.
If v ∼h then Pr(h|e)(x) is a monotone increasing function; if v ≁h then
Pr(h|e)(x) is a monotone decreasing function.
Proof. First consider the case where v ∼h. Under the given conditions we
have from the proof of Proposition 1 that Pr(he) takes on the form Pr(he)(x) =
x·τ1·τ2 + τ3, for constants τ1, τ2, τ3 ≥0.
For Pr(e) and binary V we note that Eq. (2) can be written as
Pr(e)(x) = x· Pr(vhπrπe)
Pr(v|π)
+ (1 −x)· Pr(vhπrπe)
Pr(v|π)
+

r+∈Rpa(V )
Pr(vhπr+e)

r+̸=rπ
+

r+∈Rpa(V )
Pr(vhπr+e)

r+̸=rπ +

h+∈Hpa(V )
Pr(h+e)

h+̸=hπ
which takes on the following form: Pr(e)(x) = x·τ2 + (1 −x)·κ2 + κ1 + κ3 + κ4,
with constants κi ≥0, i = 1, . . . , 4.
The sign of the derivative of the sensitivity function is determined by the
numerator τ1·τ2·(κ1 +κ2 +κ3 +κ4)−τ3·(τ2 −κ2) of Pr(h|e)′(x). We observe that
given ⟨Hpa(V ), Rpa(V )|E∪Hpa(V )∪V ⟩d we ﬁnd that τ1·κ1 = τ3 which guarantees
the derivative to be non-negative. This implies that, for v ∼h, Pr(h|e)(x) is a
monotone increasing function.
Now consider the case where v ≁h. Since V is binary, this implies that
v ∼h. The proof for this case follows by replacing, in the above formulas, every
occurrence of v by v and, hence, every x with 1 −x. As a result we ﬁnd that in
this case Pr(h|e)(x) is a monotone decreasing function.
□
5
Categorisation of the Parameters of the Variables in E
5.1
Parameters Pr(v|π) of a Variable V ∈E with v ≁e
Recall that after evidence absorption all parameters with π ≁e are removed
from the network. For a parameter Pr(v|π) of a variable in V ∈E, however, we
may still ﬁnd that v ≁e; these parameters are in category ‘∗’.

90
J.H. Bolt and S. Renooij
Proposition 4. Let Bq and Pr(h|e) be as before. Let Pr(v|π) be a parameter
of a variable V ∈E. If v ≁e, then Pr(v|π) is not used in the computation of
Pr(h|e).
Proof. This proposition is equivalent to Proposition 3 in [1], but stated for Bq
rather than for B.
□
5.2
Parameters Pr(v|π) of a Variable V ∈E with v ∼e and π ≁h
We now consider the parameters Pr(v|π) of V ∈E, with v ∼e and π ≁h.
The one-way sensitivity functions of such parameters are monotone decreasing.
These parameters therefore are categorised as ‘−’.
Proposition 5. Let Bq and Pr(h|e) be as before. Let x = Pr(v|π) be a para-
meter of V ∈E such that v ∼e. If π ≁h, then Pr(h|e)(x) is a monotone
decreasing function.
Proof. This proposition is equivalent to Proposition 1 in [1], but stated for Bq
rather than for B.
□
5.3
Parameters Pr(v|π) of a Variable V ∈E with v ∼e and π ∼h
We now consider parameters Pr(v|π) of V ∈E with v ∼e and π ∼h. The
one-way sensitivity functions of such parameters are monotone increasing under
the condition that Hpa(V ) is d-separated from Rpa(V ) given Hpa(V ) and the
evidence. Under this condition, these parameters therefore can be categorised
as ‘+’. This proposition extends Proposition 1 in [1] by replacing the condition
that Rpa(V ) = ∅by the less strict d-separation condition mentioned above.
Proposition 6. Let Bq and Pr(h|e) be as before. Let x = Pr(v|π) with v ∼e
and π ∼h be a parameter of V ∈E and let ⟨Hpa(V ), Rpa(V )|Hpa(V )∪E⟩d. Then
Pr(h|e)(x) is a monotone increasing function.
Proof. For Pr(he) we observe that Eq. (1) can be written as the expression
in the proof of Proposition 1, but with v included in e rather than in h. We
therefore have that Pr(he)(x) = x·τ1·τ2 + τ3 for constants τ1, τ2, τ3 ≥0.
For Pr(e), given by Eq. (2), we observe that we can write
Pr(e)(x) = x·Pr(hπrπe)
Pr(v|π) +

r+∈Rpa(V )
Pr(hπer+)

r+̸=rπ+

h+∈Hpa(V )
Pr(h+e)

h+̸=hπ
which is of the form x·τ2 + κ1 + κ2, for constants κ1, κ2 ≥0.
We now ﬁnd that the numerator of the ﬁrst derivative of the sensitivity func-
tion equals τ1·τ2·(κ1+κ2)−τ2·τ3. We observe that given ⟨Hpa(V ), Rpa(V )|Hpa(V )∪
E⟩d we ﬁnd that τ1·κ1 = τ3 which guarantees the derivative to be non-negative.
This implies that Pr(h|e)(x) is a monotone increasing function.
□

Structure-Based Categorisation of Bayesian Network Parameters
91
In case the above mentioned d-separation property does not hold, we need
additional information to predict whether the sensitivity function Pr(h|e)(x) of
a parameter x of a variable V ∈E with v ∼e and π ∼h is monotone increasing
or monotone decreasing, without additional knowledge. If the property does not
hold, therefore, these parameters are in category ‘?’.
6
Discussion
In this paper we presented fundamental results concerning the qualitative eﬀect
of parameter changes on the output probabilities of a Bayesian network. Based
on the graph structure and the query at hand, we categorised all network para-
meters into one of four categories: parameters not included in the computa-
tion of the output, parameters with guaranteed monotone increasing sensitivity
functions, parameters with guaranteed monotone decreasing sensitivity func-
tions, and parameters of which the qualitative eﬀect cannot be predicted with-
out additional information. Previously we demonstrated that knowledge of the
qualitative eﬀects can be exploited in inference in credal networks [1] and in
multiple-parameter tuning of Bayesian networks [2]. In our previous research
only a partial categorisation of the parameters was given. Our present paper
allocates a wider range of parameters into one of the meaningful categories ‘+’,
‘−’ and ‘∗’. For future research we would like to further study properties of the
additional information required to predict the qualitative eﬀect of the parameters
in category ‘?’.
Acknowledgements. This research was supported by the Netherlands Organisation
for Scientiﬁc Research (NWO).
References
1. Bolt, J.H., De Bock, J., Renooij, S.: Exploiting Bayesian network sensitivity func-
tions for inference in credal networks. In: Proceedings of the 22nd European Con-
ference on Artiﬁcial Intelligence, vol. 285, pp. 646–654 (2016)
2. Bolt, J.H., van der Gaag, L.C.: Balanced sensitivity functions for tuning multi-
dimensional Bayesian network classiﬁers. Int. J. Approx. Reason. 80c, 361–376
(2017)
3. Coup´e, V.M.H., van der Gaag, L.C.: Properties of sensitivity analysis of Bayesian
belief networks. Ann. Math. Artif. Intell. 36(4), 323–356 (2002)
4. van der Gaag, L.C.: On evidence absorption for belief networks. Int. J. Approx.
Reason. 15(3), 265–286 (1996)
5. Jensen, F.V., Nielsen, T.D.: Bayesian Networks and Decision Graphs, 2nd edn.
Springer, New York (2007)
6. Kjærulﬀ, U., van der Gaag, L.C.: Making sensitivity analysis computationally eﬃ-
cient. In: Boutilier, C., Goldszmidt, M. (eds.) Proceedings of the Sixteenth Con-
ference on Uncertainty in Artiﬁcial Intelligence, pp. 317–325. Morgan Kaufmann
Publishers, San Francisco (2000)

92
J.H. Bolt and S. Renooij
7. Meekes, M., Renooij, S., Gaag, L.C.: Relevance of evidence in Bayesian networks. In:
Destercke, S., Denoeux, T. (eds.) ECSQARU 2015. LNCS, vol. 9161, pp. 366–375.
Springer, Cham (2015). doi:10.1007/978-3-319-20807-7 33
8. Pearl, J.: Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Infer-
ence. Morgan Kaufmann Publishers, Palo Alto (1988)
9. Renooij, S.: Co-variation for sensitivity analysis in Bayesian networks: properties,
consequences and alternatives. Int. J. Approx. Reason. 55, 1022–1042 (2014)

The Descriptive Complexity of Bayesian
Network Speciﬁcations
Fabio G. Cozman1(B) and Denis D. Mau´a2
1 Escola Polit´ecnica, Universidade de S˜ao Paulo, S˜ao Paulo, Brazil
fgcozman@usp.br
2 Instituto de Matem´atica e Estat´ıstica, Universidade de S˜ao Paulo,
S˜ao Paulo, Brazil
Abstract. We adapt the theory of descriptive complexity to Bayesian
networks, by investigating how expressive can be speciﬁcations based on
predicates and quantiﬁers. We show that Bayesian network speciﬁcations
that employ ﬁrst-order quantiﬁcation capture the complexity class PP;
that is, any phenomenon that can be simulated with a polynomial time
probabilistic Turing machine can be also modeled by such a network. We
also show that, by allowing quantiﬁcation over predicates, the resulting
Bayesian network speciﬁcations capture the complexity class PPNP, a
result that does not seem to have equivalent in the literature.
1
Introduction
One can ﬁnd a variety of “relational” Bayesian networks in the literature, where
constructs from ﬁrst-order logic are used to represent whole populations and
repetitive patterns [7,15,16]. Such networks may be speciﬁed by diagrams or by
text; typically they are viewed as templates that can be grounded into ﬁnite
propositional Bayesian networks whenever needed.
It is only natural to ask what is the expressivity of Bayesian network speciﬁ-
cations based on predicates and quantiﬁers. That is, what can and what cannot
be modeled by these speciﬁcations, and at what computational costs. To address
these questions, we are inspired by the well-known theory of descriptive complex-
ity for logical languages [4,9]. It does not seem that the descriptive complexity
of Bayesian networks has been investigated in previous work, and to do so we
adapt existing insights and results. Because the topic is novel, most of this paper
consists of building a framework in which to operate.
In fact, one should expect “relational” Bayesian network speciﬁcations to
exhibit properties that cannot be matched by propositional networks — much
as ﬁrst-order logic goes beyond propositional logic. This sort of phenomenon has
been already noted in connection with lifted inference algorithms [10,18], but
has not been characterized in terms of descriptive complexity.
We deﬁne precisely what we mean by “Bayesian network speciﬁcations” in
Sect. 2, and present some necessary background in Sect. 3. We then move to our
main results in Sects. 4 and 5.
c
⃝Springer International Publishing AG 2017
A. Antonucci et al. (Eds.): ECSQARU 2017, LNAI 10369, pp. 93–103, 2017.
DOI: 10.1007/978-3-319-61581-3 9

94
F.G. Cozman and D.D. Mau´a
We show that Bayesian network speciﬁcations that employ ﬁrst-order quan-
tiﬁcation capture the complexity class PP. That is, a language is in PP if and
only if its strings encode valid inferences in a Bayesian network speciﬁed with
predicates and ﬁrst-order quantiﬁers. Note that this is a much stronger statement
than PP-completeness. And then we look at speciﬁcations that allow quantiﬁ-
cation over predicates, and show that such “second-order” Bayesian networks
capture the complexity class PPNP. It does not seem that previous results on
descriptive theory have reached this latter complexity class.
Intuitively, these results can be interpreted as follows: suppose we have a
(physical, social, economic) phenomenon that can be simulated by a probabilis-
tic Turing machine in polynomial time: given an input, the machine will run for
a number of steps that is polynomial in the length of the input, and the machine
will stop with the same YES-NO answer as produced by the phenomenon. Our
results show that the phenomenon can be modeled by a Bayesian network speci-
ﬁcation based on predicates and ﬁrst-order quantiﬁcation in the sense that, given
the input as evidence, an inference with the network will produce the same result
as the phenomenon. But what happens if the phenomenon is so complex that it
requires even more computation to be simulated? For instance, what happens if
the phenomenon requires a polynomial time probabilistic Turing machine with
another nondeterministic Turing machine as oracle? This phenomenon cannot be
modeled by a “relational” Bayesian network speciﬁcation, unless widely accepted
assumptions about complexity classes collapse. However, our results show that
this phenomenon can be modeled by a Bayesian network speciﬁcation that allows
quantiﬁcation over predicates.
We further discuss the intellectual signiﬁcance of these results in the con-
cluding Sect. 6.
2
Specifying Bayesian Networks with Logical Constructs
In the Introduction we loosely mentioned “relational” Bayesian networks. To
make any progress, we must precisely deﬁne what is here allowed in specifying
Bayesian networks. Our strategy, described in this section, is to adopt a proposal
by Poole [14] to mix probabilistic assessments and logical equivalences [2].
2.1
Preliminaries
First, to recap: a Bayesian network is a pair consisting of a directed acyclic
graph G whose nodes are random variables, and a joint probability distribution
P over the variables in the graph, so that G and P satisfy the Markov condition
(a random variable is independent of its nondescendants given its parents). The
Markov condition induces a factorization of probabilities [11].
In this paper every random variable is binary with values 0 and 1, respectively
signifying false and true.
We only consider textual speciﬁcations, mostly relying on formulas of
function-free ﬁrst-order logic with equality (denoted by FFFO). That is, most

The Descriptive Complexity of Bayesian Network Speciﬁcations
95
formulas we contemplate are well-formed formulas of ﬁrst-order logic with equal-
ity but without functions, containing predicates from a ﬁnite relational vocabu-
lary, negation (¬), conjunction (∧), disjunction (∨), implication (⇒), equivalence
(⇔), existential quatiﬁcation (∃) and universal quantiﬁcation (∀). Later we dis-
cuss second-order quantiﬁcation over predicates.
First-order theories are interpreted as usual [5], using domains, that are just
sets, and interpretations that associate predicates with relations, and constants
with elements; that is, an interpretation is a truth assignment for every grounding
of every predicate. A pair domain/interpretation is a structure. We only deal with
ﬁnite domains in this paper.
Throughout the paper it will be convenient to view each grounded predicate
r(
→a), for a ﬁxed vocabulary/domain, as a random variable over interpretations
(note: an overline arrow denotes a tuple). That is, given a domain D, we under-
stand r(
→a) as a function over all possible interpretations of the vocabulary, so
that r(
→a)(I) yields 1 if r(
→a) is true in interpretation I, and 0 otherwise.
For instance, say we have two unary predicates r and s, and we are given a
domain D = {a, b}. Then we have groundings {r(a), r(b), s(a), s(b)}, and there
are 24 possible interpretations. Each interpretation assigns true or false to r(a),
and similarly to every grounding. So r(a) can be viewed as a random variable
over the possible interpretations.
2.2
Relational Bayesian Network Speciﬁcations
A relational Bayesian network speciﬁcation, abbreviated relBN, is a directed
acyclic graph where each node is a predicate (from a ﬁnite relational vocabulary),
and where
1. each root node r is associated with a probabilistic assessment
P

r(
→x ) = 1

= α,
(1)
2. while each non-root node s is associated with a formula (called the deﬁnition
of s)
s(
→x ) ⇔φ(
→x ),
(2)
where φ(
→x ) is a formula in FFFO with free variables
→x .
Given a domain, a relBN can be grounded into a unique Bayesian network:
1. by producing every grounding of the predicates;
2. by associating with each grounding r(
→a) of a root predicate the grounded
assessment P

r(
→a) = 1

= α;
3. by associating with each grounding s(
→a) of a non-root predicate the grounded
deﬁnition s(
→a) ⇔φ(
→a), and by replacing univeral/existential quantiﬁcation
by conjunction/disjunction over the domain;

96
F.G. Cozman and D.D. Mau´a
4. ﬁnally, by drawing a graph where each node is a grounded predicate and
where there is an edge into each grounded non-root predicate s(
→a) from each
grounding of a predicate that appears in the grounded deﬁnition of s(
→a).
Consider, as an example, the following model of asymmetric friendship, where
an individual is always a friend of herself, and where two individuals are friends
if they are both fans (of a writer, say) or if there is some “other” reason for it:
P(fan(x )) = 0.2,
P

other(x , y)

= 0.1,
P

friends(x , y)

⇔(x = y) ∨(fan(x ) ∧fan(y)) ∨other(x , y),
(3)
Suppose we have domain D = {a, b, c}. Figure 1 depicts the Bayesian network
generated by D and Expression (3).
Fig. 1. The Bayesian network generated by Expression (3) and domain D = {a, b, c}.
For a given relBN τ and a domain D, denote by B(τ, D) the Bayesian
network obtained by grouning τ with respect to D. The set of all relational
Bayesian network speciﬁcations is denoted by B(FFFO).
3
A Bit of Descriptive Complexity
We employ several concepts from ﬁnite model theory [4,8,12] and complexity
theory [13]. We consider input strings in the alphabet {0, 1}; that is, a string is
a sequence of 0s and 1s. A language is a set of strings; a complexity class is a set
of languages. A language is decided by a Turing machine if the machine accepts
each string in the language, and rejects each string not in the language. The
complexity class NP contains each language that can be decided by a nonde-
terministic Turing machine with a polynomial time bound. If a Turing machine
is such that, whenever its transition function maps to a non-singleton set, the
transition is selected with uniform probability within that set, then the Turing
machine is a probabilistic Turing machine. The complexity class PP is the set
of languages that are decided by a probabilistic Turing machine in polynomial
time, with an error probability strictly less than 1/2 for all input strings. This

The Descriptive Complexity of Bayesian Network Speciﬁcations
97
complexity class can be equivalently deﬁned as follows: a language is in PP if
and only if there is a polynomial nondeterministic Turing machine such that a
string is in the language if and only if more than half of the computation paths
of the machine end in the accepting state when the string is the input.
If a formula φ(
→x ) has free logical variables
→x , then structure A is a model of
φ(
→a) iﬀφ(
→x ) is true in structure A when the logical variables
→x are replaced by
elements
→a of the domain.
A formula φ in existential function-free second-order logic (denoted by ESO)
is a formula of the form ∃r1 . . . ∃rmφ′, where φ′ is a sentence of FFFO contain-
ing predicates r1, . . . , rm. Such a sentence allows existential quantiﬁcation over
the predicates themselves. Note that again we have equality in the language
(that is, the built-in predicate = is always available). Here a structure A is a
pair domain/interpretation, but the interpretation does not touch predicates
that are existentially quantiﬁed (that is, if φ contains predicates r1, . . . , rm and
s1, . . . , sM, but r1, . . . , rm are all existentially quantiﬁed, then a model for φ
contains an intepretation for s1, . . . , sM).
As an example, consider the following formula of ESO [8]:
∃partition : ∀x : ∀y :

edge(x , y) ⇒(partition(x ) ⇔¬partition(y))

.
(4)
Here a domain can be viewed as a set of nodes, and an interpretation can be
viewed as a set of edges; the formula is satisﬁed if and only if it is possible to
partition the vertices into two subsets such that if a node is in one subset, it is
not in the other (that is, the graph is bipartite).
There is an isomorphism between structures A1 and A2 when there is a
bijective mapping g between the domains such that if r(a1, . . . , ak) is true in A1,
then r(g(a1), . . . , g(ak)) is true in A2, and moreover if r(a1, . . . , ak) is true in A2,
then r(g−1(a1), . . . , g−1(ak)) is true in A1 (where g−1 denotes the inverse of g).
A set of structures is isomorphism-closed if whenever a structure is in the set,
all structures that are isomorphic to it are also in the set.
We assume that every structure is given as a string, encoded as follows for a
ﬁxed vocabulary (encoding from Ref. [12, Sect. 6.1]). First, if the domain contains
elements a1, . . . , an, then the string begins with n symbols 0 followed by 1. The
vocabulary is ﬁxed, so we take some order for the predicates, r1, . . . , rm. We
then append, in this order, the encoding of the interpretation of each predicate.
Focus on predicate ri of arity k. To encode it with respect to a domain, we need
to order the elements of the domain, say a1 < a2 < · · · < an. This total ordering
is assumed for now to be always available; it will be important later to check
that the ordering itself can be deﬁned. In any case, with a total ordering we
can enumerate lexicographically all k-tuples over the domain. Now suppose
→a j
is the jth tuple in this enumeration; then the jthe bit of the encoding of ri is 1
if r(
→a j) is true in the given interpretation, and 0 otherwise. Thus the encoding
is a string containing n + 1 + m
i=1 narity(ri) symbols (either 0 or 1).
We can now state the celebrated theorem by Fagin on descriptive complexity:

98
F.G. Cozman and D.D. Mau´a
Theorem 1. Let S be an isomorphism-closed set of ﬁnite structures of some
non-empty ﬁnite vocabulary. Then S is in NP if and only if S is the class of
ﬁnite models of a sentence in ESO.
The signiﬁcance of Fagin’s theorem is that it oﬀers a deﬁnition of NP that is
not tied to any computational model; rather, it is tied to the expressivity of the
language that is used to specify problems. The surprising part of Fagin’s theorem
is that every language in NP can be exactly encoded by an ESO sentence.
4
B(FFFO) Captures PP
Given a relBN and a domain, an evidence piece E is a partial interpretation;
that is, an evidence piece assigns a truth value to some groundings of predicates.
We encode a pair domain-evidence (D, E) with the same strategy used in
the previous section to encode a structure; however, we must take into account
the fact that a particular grounding of a predicate can be either assigned true
or false or be left without assignment. So we use a pair of symbols in {0, 1} to
encode each grounding; we assume that 00 means false and 11 means true, while
say 01 means lack of assignment.
Say there is an isomorphism between pairs (D1, E1) and (D2, E2) when there
is a bijective mapping g between the domains such that if r(a1, . . . , ak) is true in
E1, then r(g(a1), . . . , g(ak)) is true in E2, and moreover if r(a1, . . . , ak) is true
in E2, then r(g−1(a1), . . . , g−1(ak)) is true in E1 (where again g−1 denotes the
inverse of g). A set of pairs domain-evidence is isomorphism-closed if whenever
a pair is in the set, all pairs that are isomorphic to it are also in the set.
Suppose a set of pairs domain-evidence is given with respect to a ﬁxed vocab-
ulary σ. Once encoded, these pairs form a language L that can for instance
belong to NP or to PP. One can imagine building a relational Bayesian network
speciﬁcation τ on an extended vocabulary consisting of σ plus some additional
predicates, so as to decide this language L of domain-evidence pairs. For a given
input pair (D, E), the Bayesian network speciﬁcation and the domain lead to a
Bayesian network B(τ, D); this network can be used to compute the probability
of some groundings, and that probabiility in turn can be used to accept/reject
the input. This is the sort of strategy we pursue.
The point is that we must determine some prescription by which, given a
Bayesian network and an evidence piece, one can generate an actual decision
so as to accept/reject the input pair domain/evidence. We adopt the following
strategy. Assume that in the extended vocabulary of τ there are two sets of dis-
tinguished auxiliary predicates A1, . . . , Am′ and B1, . . . , Bm′′ that are not in σ.
We can use the Bayesian network B(τ, D) to compute the probability P(A|B, E)
where A and B are interpretations of A1, . . . , Am′ and B1, . . . , Bm′′ respectively.
And then we might accept/reject the input on the basis of P(A|B, E). However,
we cannot specify particular intepretations A and B as the related predicates
are not in the vocabulary σ. Thus the sensible strategy is to ﬁx attention to
some selected, ﬁxed, pair of intepretations for these predicates; we simply take
the interpretations that assign true to every grounding.

The Descriptive Complexity of Bayesian Network Speciﬁcations
99
In short: use the Bayesian network B(τ, D) to determine whether or not
P(A|B, E) > 1/2, where A assigns true to every grounding of A1, . . . , Am′, and
B assigns true to every grounding of B1, . . . , Bm′′. If this inequality is satisﬁed,
the input pair is accepted; if not, the input pair is rejected.
We refer to A1, . . . , Am′ as the conditioned predicates, and to B1, . . . , Bm′′ as
the conditioning predicates.
Here is the main result:
Theorem 2. Let S be an isomorphism-closed set of pairs domain-evidence of
some non-empty ﬁnite vocabulary, where all domains are ﬁnite. Then S is in PP
if and only if S is the class of domain-evidence pairs that are accepted by a ﬁxed
relBN with ﬁxed conditioned and conditioning predicates.
Proof. First, if S is a class of domain-query pairs that are accepted by a ﬁxed
relBN, they can be decided by a polynomial time probability Turing machine.
To see that, note that we can build a nondeterministic Turing machine that
guesses the truth value of all groundings that do not appear in the query (that
is, not in A ∪B ∪E), and then veriﬁes whether the resulting complete interpre-
tation is a model of the relBN. Recall that model checking of a ﬁxed ﬁrst-order
sentence is in P [12].
To prove the other direction, we adapt the proof of Fagin’s theorem as
described by Gr¨adel [8], along the same lines as the proof of Theorem 1 by
Saluja et al. [17]. So, suppose that L is a language decided by some probabilis-
tic Turing machine. Equivalently, there is a nondeterministic Turing machine
that determines whether the majority of its computation paths accept an input,
and accepts/rejects the input accordingly. By the mentioned proof of Fagin’s
theorem, there is a ﬁrst-order sentence φ′ with vocabulary consisting of the
vocabulary of the input plus additional auxiliary predicates, such that each inter-
pretation of this joint vocabulary is a model of the sentence if it is encodes a
computation path of the Turing machine, as long as there is an available addi-
tional predicate that is guaranteed to be a linear order on the domain. Due to
the lack of space, details of the construction are omitted; suﬃce to say that the
same predicates Xq (one per state), Yσ (one per symbol), and Z, employed by
Gr¨adel, are to be used here, with the same associated deﬁnitions. Denote by A
the zero arity predicate with associated deﬁnition A ⇔φ′ ∧φE, where φE is
satisﬁed when an accepting state is reached. Suppose a linear order is indeed
available; then by creating a relBN where all groundings are associated with
probability 1/2, and where a non-root node is associated with the sentence in the
proof of Fagin’s theorem, we have that the probability of the query is larger than
1/2 iﬀthe majority of computation paths accept. The challenge is to encode a
linear order. To do so, introduce a new predicate < and the ﬁrst-order sentence
φ′′ that forces < to be a total order, and a zero arity predicate B that is associ-
ated with deﬁnition B ⇔φ′ ∧φ′′. Now an input domain-pair (D, E) is accepted
by the majority of computation paths in the Turing machine if and only if we
have P(A|B, E) > 1/2. Note that there are actually n! linear orders that sat-
isfy B, but for each one of these linear orders we have the same assignments

100
F.G. Cozman and D.D. Mau´a
for all other predicates, hence the ratio between accepting computations and all
computations is as desired.
□
We might picture this as follows. There is always a Turing machine TM and
a corresponding triplet (τ, A, B) such that for any pair (D, E), we have
(D, E) as input to TM with output given by P(TM accepts (D, E)) > 1/2,
if and only if
(D, E) as “input” to (τ, A, B) with “output” given by Pτ,D(A|B, E) > 1/2,
where Pτ,D(A|B, E) denotes probability with respect to B(τ, D). (Of course, there
is no even need to be restricted to zero-arity predicates A and B, as Theorem 2
allows for sets of predicates.)
Note that the same result could be proved if every evidence piece was taken
to be a complete interpretation for the vocabulary σ. In that case we could
directly speak of structures as inputs, and then the result would more closely
mirror Fagin’s theorem. However it is very appropriate, and entirely in line with
practical use, to take the inputs to a Bayesian network as the groundings of a
partially observed interpretation. Hence we have preferred to present our main
result as stated in Theorem 2.
5
Moving to Second-Order
Suppose we have a phenomenon whose simulation requires computational powers
that go beyond a polynomial time probabilistic Turing machine. There are in fact
description languages whose inferences require exponential time probabilistic
Turing machines [2,3], but we need not go to such extremes. We might for
instance have a phenomenon that requires a polynomial time probabilistic Turing
machine to use as oracle a polynomial time nondeterministic Turing machine.
That is, we might have a phenomenon with requirements within PPNP, a level
above PP in the polynomial counting hierarchy [19]. Given current beliefs about
complexity classes, Theorem 2 shows that such a phenomenon cannot be modeled
with a relBN. Can we ﬁnd a “reasonable” speciﬁcation language that allows
one to model such a phenomenon?
Indeed we can, by putting together Fagin’s theorem and Theorem 2. Consider
a speciﬁcation language as follows: we have a directed acyclic graph where nodes
are predicates, and where as before root and non-root nodes are respectively
associated with assessments P(r(
→x ) = 1) = α and deﬁnitions s(
→x ) ⇔φ(
→x ), but
the latter are now enlarged so that φ is a formula in ESO. A directed graph
associated with such assessments and formulas is referred to as a existential
second-order Bayesian network speciﬁcation, abbreviated esoBN.
For instance, consider the model of friendship presented in Expression (3),
and suppose we add a variable that indicates whether the graph of friends can
be partitioned, using Expression (4) as follows:
partitioned ⇔∃partition : ∀x :∀y :

edge(x , y)⇒(partition(x )⇔¬partition(y))

.

The Descriptive Complexity of Bayesian Network Speciﬁcations
101
The presence of probabilities and second-order quantiﬁcation gives us the
desired modeling power:
Theorem 3. Let S be an isomorphism-closed set of pairs domain-evidence of
some non-empty ﬁnite vocabulary, where all domains are ﬁnite. Then S is in
PPNP if and only if S is the class of domain-evidence pairs that are accepted by
a ﬁxed esoBN with ﬁxed conditioned and conditioning predicates.
Proof. To prove that a class of domain-query pairs that are accepted by a ﬁxed
esoBN can be decided within PPNP, put together the argument in the ﬁrst
paragraph of the proof of Theorem 2 and the fact that an ESO sentence can be
evaluated within NP by Theorem 1.
To prove the other direction, the corresponding part of the proof of
Theorem 2 must be enlarged. We introduce again the same predicates Xq, Yσ
and Z for the base machine, together with the whole machinery in Gr¨adel’s
proof of Fagin’s theorem [8], and we also introduce predicates Xo
q , Y o
σ , Zo for
the oracle machine (the superscript o refers to the “oracle”). Additionally, in the
proof of Theorem 2 it is necessary to introduce logical variables that “mark the
steps” of the Turing machine (these steps are ordered by the introduced linear
order). Here we need two sets of such logical variables and associated machin-
ery; one set “marks the steps” of the base machine, while the other “marks the
steps” of the oracle machine. And of course a linear order must also be built
as in the proof of Theorem 2. Again, due to lack of space the details of the
construction are omitted. And again, an input domain-query is accepted by the
majority of computation paths in the (base) Turing machine if and only if we
have P(A|B, E) > 1/2, where A, B and E are as in the proof of Theorem 2. □
6
Conclusion: A Finite Model Theory of Bayesian
Networks?
We have introduced a theory of descriptive complexity for Bayesian networks, a
topic that does not seem to have received due attention so far. Our results can
be extended in a variety of directions, for instance to various ﬁxpoint logics that
are the basis of logic programming [4,12]. To summarize, we have shown that
relational Bayesian network speciﬁcations capture PP, and we have indicated
how we can go beyond PP in our modeling tools. Speciﬁcally, we added existential
second-order quantiﬁcation to capture the complexity class PPNP.
These results can be better appreciated by taking a broader perspective. For
several decades now, there has been signiﬁcant study of models that arise from
combinations of probability and logic [1,6]. However, by dealing with domains
of arbitrary cardinality, and with logics that include too many constructs (for
instance, functions) and that exclude valuable techniques (for instance, the
modularity introduced by independence relations), these previous investigations
arrive at results that are often too weak — for instance, almost always obtaining
undecidability or very high computational complexity. By focusing on modular
tools such as Bayesian networks, and by focusing on ﬁnite domains, we are able

102
F.G. Cozman and D.D. Mau´a
to obtain much sharper results, nailing down speciﬁc complexity classes such as
PP and PPNP. In fact, the purpose here is to initiate a “ﬁnite model theory of
Bayesian network speciﬁcations” that can pin down the expressivity and com-
plexity of Bayesian networks, not only when they are propositional objects, but
particularly when they are speciﬁed using logical constructs.
Our results are also interesting from a point of view centered on complexity
theory. There has been little work on capturing counting/probabilistic classes;
the most signiﬁcant previous results capture #P using counting [17]. We oﬀer
a more concrete modeling language that captures PP, and we move into the
counting hierarchy, up to PPNP — we are not aware of any similar result in the
literature. Our results show that classes in the counting hierarchy can be tied to
the expressivity of modeling tools, not to any particular computational model
(much as Fagin’s theorem does for NP).
Acknowledgements. The ﬁrst author is partially supported by CNPq, grant
308433/2014-9. This paper was partially funded by FAPESP grant #2015/21880-4
(project Proverbs).
References
1. Abadi, M., Halpern, J.Y.: Decidability and expressiveness for ﬁrst-order logics of
probability. Inf. Comput. 112(1), 1–36 (1994)
2. Cozman, F.G., Mau´a, D.D.: Bayesian networks speciﬁed using propositional and
relational constructs: Combined, data, and domain complexity. In: AAAI Confer-
ence on Artiﬁcial Intelligence (2015)
3. Cozman, F.G., Polastro, R.B.: Complexity analysis and variational inference for
interpretation-based probabilistic description logics. In: Conference on Uncertainty
in Artiﬁcial Intelligence, pp. 117–125 (2009)
4. Ebbinghaus, H.-D., Flum, J.: Finite Model Theory. Springer, Heidelberg (1995)
5. Enderton,
H.B.:
A
Mathematical
Introduction
to
Logic.
Academic
Press,
Cambridge (1972)
6. Gaifman, H.: Concerning measures on ﬁrst-order calculi. Isr. J. Math. 2, 1–18
(1964)
7. Getoor, L., Taskar, B.: Introduction to Statistical Relational Learning. MIT Press,
Cambridge (2007)
8. Gr¨adel, E.: Finite model theory and descriptive complexity. In: Gr¨adel, E. (ed.)
Finite Model Theory and its Applications, pp. 125–229. Springer, Heidelberg (2007)
9. Gr¨adel, E.E., Kolaitis, P.G., Libkin, L., Marx, M., Spencer, J., Vardi, M.Y.,
Venema, Y., Weinstein, S.: Finite Model Theory and its Applications. Springer,
Heidelberg (2007)
10. Jaeger, M.: Lower complexity bounds for lifted inference. Theor. Pract. Logic Pro-
gram. 15(2), 246–264 (2014)
11. Koller, D., Friedman, N., Models, P.G.: Probabilistic Graphical Models: Principles
and Techniques. MIT Press, Cambridge (2009)
12. Libkin, L.: Elements of Finite Model Theory. Springer, Heidelberg (2004)
13. Papadimitriou, C.H.: Computational Complexity. Addison-Wesley, Boston (1994)

The Descriptive Complexity of Bayesian Network Speciﬁcations
103
14. Poole, D.: Probabilistic programming languages: independent choices and deter-
ministic systems. In: Dechter, R., Geﬀner, H., Halpern, J.Y. (eds.) Heuristics, Prob-
ability and Causality - A Tribute to Judea Pearl, pp. 253–269. College Publications,
London (2010)
15. De Raedt, L.: Logical and Relational Learning. Springer, Heidelberg (2008)
16. De Raedt, L., Frasconi, P., Kersting, K., Muggleton, S.: Probabilistic Inductive
Logic Programming. Springer, Heidelberg (2010)
17. Saluja, S., Subrahmanyam, K.V.: Descriptive complexity of #P functions. J. Com-
put. Syst. Sci. 50, 493–505 (1995)
18. Van den Broeck, G.: On the completeness of ﬁrst-order knowledge compilation
for lifted probabilistic inference. In: Neural Processing Information Systems, pp.
1386–1394 (2011)
19. Wagner, K.W.: The complexity of combinatorial problems with succinct input
representation. Acta Informatica 23, 325–356 (1986)

Exploiting Stability for Compact Representation
of Independency Models
Linda C. van der Gaag1(B) and Stavros Lopatatzidis2
1 Department of Information and Computing Sciences, Utrecht University,
Princetonplein 5, 3584 CC Utrecht, The Netherlands
L.C.vanderGaag@uu.nl
2 SYSTeMS Research Group, Ghent University,
Technologiepark-Zwijnaarde 914, 9052 Zwijnaarde, Belgium
stavros.lopatatzidis@ugent.be
Abstract. The notion of stability in semi-graphoid independency
models was introduced to describe the dynamics of (probabilistic) inde-
pendency upon inference. We revisit the notion in view of establishing
compact representations of semi-graphoid models in general. Algorithms
for this purpose typically build upon dedicated operators for construct-
ing new independency statements from a starting set of statements. In
this paper, we formulate a generalised strong-contraction operator to
supplement existing operators, and prove its soundness. We then embed
the operator in a state-of-the-art algorithm and illustrate that the thus
enhanced algorithm may establish more compact model representations.
1
Introduction
Pearl and his co-researchers were among the ﬁrst to formalise qualitative prop-
erties of (probabilistic) independency in an axiomatic system [6]. Known as the
semi-graphoid axioms, the axioms from this system are often looked upon as
derivation rules for generating new independencies from a starting set of inde-
pendency statements; any set of independencies that is closed under ﬁnite appli-
cation of these rules is called a semi-graphoid independency model. Semi-graphoid
models have been well studied from various diﬀerent perspectives. Researchers
have addressed the axiomatic system itself, focusing on the question whether the
notion of independency relative to the class of discrete probability distributions
allows a ﬁnite axiomatisation [7]. Also, the implication problem for semi-graphoid
models has received attention, that is, the problem of verifying whether a new
independency statement logically follows from a given set of statements by appli-
cation of the semi-graphoid rules [4]. The problem on which we shall focus in
this paper is the representation problem, that is, the problem of ﬁnding a small
set of independency statements which fully describes a given model [1,2,8].
From a practical point of view, probabilistic independency models are the key
to dealing with the computational complexity of problem-solving tasks involv-
ing uncertainty. Given their importance, diﬀerent classes of independency model
c
⃝Springer International Publishing AG 2017
A. Antonucci et al. (Eds.): ECSQARU 2017, LNAI 10369, pp. 104–114, 2017.
DOI: 10.1007/978-3-319-61581-3 10

Exploiting Stability for Compact Representation of Independency Models
105
have been studied, among which are the graphoid models describing indepen-
dency relative to the class of strictly positive probability distributions, and stable
independency models. This latter class of models derives its importance from its
role in describing the dynamics of (probabilistic) independency upon inference.
Any independency model is a complete description of all independencies among
the variables concerned and thereby provides for all possible contexts of given
information. At any time in an iterative problem-solving process, however, only
some of the independencies from the model apply: these are the independen-
cies that pertain to the current context of information. As inference progresses,
learning new information causes the set of relevant independency statements to
change dynamically. Stability of an independency now means that the indepen-
dency remains to hold as the context of given information grows.
Several researchers have studied the representation of semi-graphoid models
in general and developed algorithms for ﬁnding compact representations [1,2,8].
These algorithms construct such a representation in an iterative fashion by apply-
ing dedicated operators to a set of given independency statements. De Waal and
Van der Gaag were the ﬁrst to exploit the notion of stability for studying model
representations [9]. They formulated an algorithm in which the stable and unsta-
ble parts of an independency model are addressed separately; upon doing so, they
exploited the strong-union axiom of stable independency. Niepert et al. [5] have
since then formulated a second axiom for stable independency, called the strong-
contraction axiom. In this paper, we design a new operator to accommodate appli-
cation of this axiom for deriving new statements and embed this operator in the
existing algorithm for ﬁnding compact representations of semi-graphoid models in
general. We will illustrate, by means of a small example, that the thus enhanced
algorithm may establish more compact representations.
The paper is organised as follows. Section 2 revisits semi-graphoid models
and introduces our notations. Section 3 addresses stable independency models
and their representation; more speciﬁcally, it deﬁnes our new operator for stable
independency. Section 4 embeds the operator in the state-of-the-art algorithm for
computing compact model representations. The paper ends with our concluding
observations in Sect. 5.
2
Independency Models Revisited
We brieﬂy review semi-graphoid independency models and their representation
[6,8]. To this end, we consider a ﬁnite, non-empty set V of discrete random
variables. A triplet over V is a statement of the form ⟨A, B | C⟩, where A, B, C ⊆
V are pairwise disjoint subsets with A, B ̸= ∅; we use X = A ∪B ∪C to denote
the set of all variables involved in the triplet. A triplet ⟨A, B | C⟩is taken to
state that the sets of variables A and B are independent given the conditioning
set C; relative to a discrete joint probability distribution Pr over V , the triplet
thus states that Pr(A, B | C) = Pr(A | C)·Pr(B | C) for all values combinations
of A, B, C. The set of all triplets over V is denoted by V (3).
A set of triplets constitutes a semi-graphoid independency model if it satisﬁes
the four properties stated in the following deﬁnition.

106
L.C. van der Gaag and S. Lopatatzidis
Deﬁnition 1. A semi-graphoid independency model is a subset of triplets J ⊆
V (3) which satisﬁes the following properties:
G1: if ⟨A, B | C⟩∈J, then ⟨B, A | C⟩∈J (Symmetry)
G2: if ⟨A, B | C⟩∈J, then ⟨A, B′ | C⟩∈J for any non-empty subset B′ ⊆B
(Decomposition)
G3: if ⟨A, B1 ∪B2 | C⟩∈J with B1 ∩B2 = ∅, then ⟨A, B1 | C ∪B2⟩∈J (Weak
Union)
G4: if ⟨A, B | C ∪D⟩∈J and ⟨A, C | D⟩∈J, then ⟨A, B ∪C | D⟩∈J (Con-
traction)
The four properties stated above have been proven logically independent and
taken to constitute an axiomatic system for the qualitative notion of indepen-
dency [6]. The system is sound relative to the class of discrete probability distrib-
utions, yet not complete; in fact, it has been shown that the probabilistic notion
of independency does not allow a ﬁnite axiomatisation [7]. The four properties
of independency are often viewed as derivation rules for generating possibly new
triplets from a given triplet set. Given a set J ⊆V (3) and a designated triplet
θ ∈V (3), we write J ⊢∗θ if the triplet θ can be derived from J by ﬁnite appli-
cation of the semi-graphoid rules G1–G4. The closure of the starting set J then
is the semi-graphoid independency model composed of J and all triplets θ that
can be derived from J, that is, all triplets θ such that J ⊢∗θ.
Semi-graphoid models typically being exponentially large in size, Studen´y
proposed a more compact representation than mere enumeration of their element
triplets [8]. The idea of this representation is to explicitly capture only a subset
of triplets from a semi-graphoid model, called a basis, and let all other triplets be
deﬁned implicitly through the derivation rules. Underlying this representation
was the notion of dominance [8], which was later enhanced by Baioletti et al. to
the notion of g-inclusion [1].
Deﬁnition 2. Let J ⊆V (3) be a semi-graphoid independency model, and let
θi = ⟨Ai, Bi | Ci⟩, with Xi = Ai ∪Bi ∪Ci, i = 1, 2, be triplets in J. Then, θ1 is
g-included in θ2, denoted as θ1 ⊑θ2, if the following two conditions hold:
– C2 ⊆C1 ⊆X2; and,
– A1 ⊆A2 and B1 ⊆B2, or B1 ⊆A2 and A1 ⊆B2.
A triplet θ ∈J is g-maximal in J if it is not g-included in any triplet τ ∈J with
τ ̸= θ, θT .
The conditions for g-inclusion capture all possible ways in which the triplet θ1
may be derived from θ2 by means of the derivation rules G1–G3. Since g-included
triplets can be derived from other ones, they need not be represented explicitly
in a basis.
For application of the contraction rule G4 to pairs of triplets, Studen´y for-
mulated a dedicated operator, called the gc-operator, which constructs from two
triplets θ1, θ2, triplets θ′
1, θ′
2 by application of the rules G1–G3, to which the con-
traction rule can be applied to yield a possibly new triplet θ [8]. This operator
is deﬁned as follows.

Exploiting Stability for Compact Representation of Independency Models
107
Deﬁnition 3. For all triplets θi = ⟨Ai, Bi | Ci⟩∈V (3) with Xi = Ai∪Bi∪Ci, i =
1, 2, such that
– A1 ∩A2 ̸= ∅;
– C1 ⊆X2 and C2 ⊆X1; and
– (B2\C1) ∪(B1 ∩X2) ̸= ∅,
the gc-operator is deﬁned through:
gc(θ1, θ2) = ⟨A1 ∩A2, (B2\C1) ∪(B1 ∩X2) | C1 ∪(A1 ∩C2)⟩
For all pairs of triplets θ1, θ2 for which the conditions stated above do not all
hold, gc(θ1, θ2) is undeﬁned.
Building upon the gc-operator, Baioletti et al. [1] formulated a generalised con-
traction rule which constructs from a pair of triplets θ1, θ2, a set of possibly new
triplets by applying the gc-operator to θ1, θ2 and the transposes θT
i
obtained
from θi, i = 1, 2, by a single application of the symmetry rule G1. Their rule
was later extended by Lopatatzidis and Van der Gaag [2] to the rule stated in
the following lemma.
Lemma 1. Let J ⊆V (3) be a semi-graphoid independency model. Then, J sat-
isﬁes the following property:
G4+: if θ1, θ2 ∈J, then GC(θ1, θ2) ∪GC(θ2, θ1) ⊆J
where
GC(θi, θj)
=
{gc(θi, θj), gc(θi, θT
j ), gc(θT
i , θj), gc(θT
i , θT
j )}
for
all
θi, θj ∈J.
We note that for any two triplets θ1, θ2, eight potentially new triplets may result
from application of the G4+ rule; for a proof of the lemma, we refer to [2].
For establishing compact representations of semi-graphoid models in general,
an algorithm is available which builds on the G4+ derivation rule. The algorithm
constructs a basis, from a given starting set of triplets, for the independency
model deﬁned by this set [1,2,8]. To this end, the algorithm initialises the basis
by the starting set and iteratively adapts the current basis until it no longer
changes. In each iteration, the G4+ rule is applied to any pair of triplets from
the current basis and the results are added. After removing all g-included triplets
from the resulting set, the next iteration is started.
3
Stable Independency Models
Of the family of semi-graphoid independency models, the subfamily of stable
models is of special interest for studying the dynamics of independency upon
inference. Informally, two sets of variables are stably independent given a spe-
ciﬁc conditioning set of variables, if they are independent given this set and
remain to be so as this set grows [9]. We review the notion of stable triplet in an
independency model.

108
L.C. van der Gaag and S. Lopatatzidis
Deﬁnition 4. Let J ⊆V (3) be a semi-graphoid independency model and let
θ = ⟨A, B | C⟩∈J. Then,
– θ is stable in J if ⟨A, B | C′⟩∈J for all sets C′ with C ⊆C′ ⊆V \(A ∪B)
and is called saturated in J if C = V \(A ∪B);
– θ is unstable in J if it is not stable in J.
The set of all stable triplets in J is called the stable part of J, and is denoted
with JS; the set of all unstable triplets in J constitutes its unstable part, denoted
by JU.
The stable part of a semi-graphoid independency model satisﬁes the four semi-
graphoid properties from Deﬁnition 1, and hence constitutes a semi-graphoid
model by itself [9]; in fact, there exist semi-graphoid models composed of a stable
part only, which have also been termed ascending [3]. The unstable part of an
independency model not necessarily obeys the decomposition, weak union and
contraction properties, and therefore need not constitute an independency model
in general. In this section, we focus on stable models, that is, on independency
models with an empty unstable part; in Sect. 4, we return to models which involve
a non-empty unstable part as well.
A stable independency model has a highly regular structure, which is
described by two properties in addition to the four semi-graphoid properties.
Lemma 2. Let J ⊆V (3) be a stable model. Then, J satisﬁes the following
properties:
S5: if ⟨A, B | C⟩∈J, then ⟨A, B | C ∪D⟩∈J for all sets D ⊆V \(A ∪B ∪C)
(Strong Union)
S6: if ⟨A, B | C ∪D⟩, ⟨A, B | C ∪E⟩, ⟨D, E | C⟩∈J, then ⟨A, B | C⟩∈J
(Strong Contraction)
The strong-union property follows directly from the deﬁnition of stable indepen-
dency [6,9]. The strong-contraction property was formulated by Niepert et al.
who proved that the properties G1–G4 and S5–S6 constitute a sound and com-
plete axiomatisation of stable independency relative to the class of discrete prob-
ability distributions [5]. The properties S5–S6 now are taken as derivation rules,
for stable independencies only.
In the previous section we addressed the representation of semi-graphoid
models in general, and reviewed the notion of g-inclusion which underlies repre-
sentation by a basis. De Waal and Van der Gaag [9] observed that stable models
can be represented more concisely, since by including a stable triplet ⟨A, B | C⟩
in a basis, all triplets ⟨A, B | C′⟩with C ⊆C′ ⊆V \(A ∪B) can be derived by
means of the S5 rule and hence be left implicit. To further explore this observa-
tion, we deﬁne the notion of stable g-inclusion.
Deﬁnition 5. Let J
⊆
V (3)
be a stable independency model, and let
θi = ⟨Ai, Bi | Ci⟩, i = 1, 2, be triplets in J. Then, θ1 is stably g-included in
θ2, denoted θ1 ⊑S θ2, if the following two conditions hold:

Exploiting Stability for Compact Representation of Independency Models
109
– C2 ⊆C1; and,
– A1 ⊆A2 and B1 ⊆B2, or B1 ⊆A2 and A1 ⊆B2.
A triplet θ ∈J is stably g-maximal in J if it is not stably g-included in any
triplet τ ∈J with τ ̸= θ, θT .
Like the general notion of g-inclusion, stable g-inclusion pertains to a single
triplet and the triplets that can be derived from it by means of the rules G1–G3.
The diﬀerence is in the condition C1 ⊆X2: while the context X2 is required for
g-inclusion in general, this restriction is no longer necessary for stable triplets,
since any triplet with a conditioning part expanding beyond X2 is still included
in the model under study through the S5 derivation rule. The notion of stable
g-inclusion thus covers application not just of the rules G1–G3, but of the strong-
union rule as well. For application of the contraction rule to stable independen-
cies, De Waal and Van der Gaag introduced a dedicated operator, analogous
to the gc-operator. This gcS-operator constructs from two stable triplets θ1, θ2,
stably g-included triplets θ′
1, θ′
2 by means of the G1–G3 and S5 rules, to which
the contraction rule can be applied to give a possibly new triplet. It is deﬁned
as follows.
Deﬁnition 6. For all triplets θi = ⟨Ai, Bi | Ci⟩∈V (3), i = 1, 2, such that
– A1 ∩A2 ̸= ∅; and
– (B2\C1) ∪(B1\B2) ̸= ∅,
the gcS-operator is deﬁned through:
gcS(θ1, θ2) = ⟨A1 ∩A2, (B2\C1) ∪(B1\B2)) | C1 ∪(C2\B1)⟩
For all pairs of triplets θ1, θ2 for which the conditions stated above do not all
hold, gcS(θ1, θ2) is undeﬁned.
Building upon the gcS-operator, we now formulate a generalised contraction rule
for stable models, similar to the G4+ rule for semi-graphoid models in general.
Lemma 3. Let J ⊆V (3) be a stable model. Then, J satisﬁes the following
property:
G4S: if θ1, θ2 ∈J, then GC S(θ1, θ2) ∪GCS(θ2, θ1) ⊆J
with GC S(θi, θj) = {gcS(θi, θj), gcS(θi, θT
j ), gcS(θT
i , θj), gcS(θT
i , θT
j )} for all
θi, θj ∈J.
We note that for any two triplets θ1, θ2, eight new ones may result from ap-
plying the G4S rule. Proof of the lemma follows directly from properties of the
gcS-operator [9].
The gcS-operator takes the strong-union rule into consideration in addition
to the derivation rules G1–G3, for constructing triplets to which the contraction
rule can be applied. The generalised contraction rule G4S thus accommodates the

110
L.C. van der Gaag and S. Lopatatzidis
rules G1–G4 and S5. It does not yet cover the strong-contraction rule, however.
For accommodating this rule, we introduce a new operator, denoted as gscS.
This operator constructs, from three triplets θ1, θ2, θ3, stably g-included triplets
θ′
1, θ′
2, θ′
3 by application of G1–G3 and S5, to which the strong-contraction rule
can be applied. It is deﬁned as follows.
Deﬁnition 7. For all triplets θi = ⟨Ai, Bi | Ci⟩∈V (3), i = 1, 2, 3, such that
– A1 ∩A2 ̸= ∅and B1 ∩B2 ̸= ∅;
– ∅̸= C1\(B2 ∪C2) ⊆A3 and ∅̸= C2\(B1 ∪C1) ⊆B3; and
– C3 ⊆(C1 ∩C2) ∪(B1 ∩C2) ∪(B2 ∩C1),
the gscS-operator is deﬁned through:
gscS(θ1, θ2, θ3) = ⟨A1 ∩A2, B1 ∩B2 | (C1 ∩C2) ∪(B1 ∩C2) ∪(B2 ∩C1)⟩
For all triplets θ1, θ2, θ3 ∈J for which the conditions stated above do not all
hold, gscS(θ1, θ2, θ3) is undeﬁned.
We show that any stable model is closed under application of the gscS-operator.
Lemma 4. Let J ⊆V (3) be a stable independency model. For all triplets θi ∈J,
i = 1, 2, 3, if gscS(θ1, θ2, θ3) is deﬁned, then gscS(θ1, θ2, θ3) ∈J.
Proof. We let θi = ⟨Ai, Bi | Ci⟩, i = 1, 2, 3, and assume that gscS(θ1, θ2, θ3) is
deﬁned. From the three triplets, we construct, by application of the symmetry,
decomposition, and weak- and strong-union rules, the following stably g-included
triplets:
θ′
1 = ⟨A1 ∩A2, B1 ∩B2 | C1 ∪(B1 ∩C2)⟩= ⟨A′
1, B′
1 | C′
1⟩
θ′
2 = ⟨A1 ∩A2, B1 ∩B2 | C2 ∪(B2 ∩C1)⟩= ⟨A′
2, B′
2 | C′
2⟩
θ′
3 = ⟨C1\(B2 ∪C2), C2\(B1 ∪C1) | (C1 ∩C2) ∪(B1 ∩C2) ∪(B2 ∩C1)⟩=
= ⟨A′
3, B′
3 | C′
3⟩
For the intersection of the two sets C′
1 and C′
2, we observe that C′
1 ∩C′
2 =
(C1∩C2)∪(B1∩C2)∪(B2∩C1) = C′
3. We further have that A′
3 = C1\(B2∪C2) ⊆
C1 ∪(B1 ∩C2) = C′
1; with A′
3 ∪C′
3 = C′
1, we thus ﬁnd that C′
1\(B′
2 ∪C′
2) ⊆A′
3.
Similarly, C′
2\(B′
1 ∪C′
1) ⊆B′
3. Since its conditions are all met, the strong-
contraction rule can be applied to θ′
1, θ′
2, θ′
3 to yield the following triplet:
θ = ⟨A1 ∩A2, B1 ∩B2 | (C1 ∩C2) ∪(B1 ∩C2) ∪(B2 ∩C1)⟩= gscS(θ1, θ2, θ3)
Since only sound rules for stable independency were applied in the derivation,
we conclude that θ ∈J, and hence that gscS(θ1, θ2, θ3) ∈J.
⊓⊔
Analogous to the property that the gcS-operator can be used for constructing
a basis for any stable model [9], we now prove a related property for our gscS-
operator.

Exploiting Stability for Compact Representation of Independency Models
111
Lemma 5. Let D ⊆V (3) be a set of stable triplets such that for all θi ∈D,
i = 1, 2, 3, the following property holds:
if gscS(θ1, θ2, θ3) is deﬁned, then there is a θ ∈D such that gscS(θ1, θ2, θ3) ⊑S θ
Then, the set J = {θ′ | there is a θ ∈D such that θ′ ⊑S θ} is closed under the
derivation rules G1–G3, S5 and S6.
Proof. From its deﬁnition, it is immediate that the set J is closed under the
rules G1–G3 and S5. We now show that the set is also closed under the strong-
contraction rule S6. To this end, we consider three triplets τi = ⟨ai, bi | ci⟩,
i = 1, 2, 3, in J and suppose that the strong-contraction rule can be applied
directly to these triplets, to give τ = ⟨a, b | c⟩. By deﬁnition, there are triplets
θi = ⟨Ai, Bi | Ci⟩, i = 1, 2, 3, in D with τi ⊑S θi, such that θ = gscS(θ1, θ2, θ3)
is well deﬁned. To show that τ ⊑S θ, we have to show that a ⊆A, b ⊆B
and C ⊆c. From τi ⊑S θi, we have that ai ⊆Ai, i = 1, 2. Since the strong-
contraction rule can be applied directly to τi, i = 1, 2, 3, we have that a1 = a2,
from which it is readily seen that a1 ∩a2 ⊆A1 ∩A2 and, hence, that a ⊆A;
similarly, b ⊆B. From τj ⊑S θj we further have that Cj ⊆cj, j = 1, 2, from
which it follows that C1∩C2 ⊆c1∩c2. From the conditions for application of the
gscS-operator to θ1, θ2, θ3, we have that C2\(B1 ∪C1) ⊆B3, from which we ﬁnd
that (B1 ∩C2)∩B3 = ∅. Since b3 ⊆B3, it follows that (B1 ∩C2)∩b3 = ∅. From
b3 = c2\c1 ̸= ∅, we thus ﬁnd that B1 ∩C2 ⊆c1 ∩c2; similarly, B2 ∩C1 ⊆c1 ∩c2.
We conclude that
C = (C1 ∩C2) ∪(B1 ∩C2) ∪(B2 ∩C1) ⊆c1 ∩c2 = c
which proves the property stated in the lemma.
⊓⊔
Building upon the gscS-operator, we now formulate a generalised strong-
contraction rule S6S for stable independency, similar to the G4+ and G4S rules.
Lemma 6. Let J ⊆V (3) be a stable model. Then, J satisﬁes the following
property:
S6S: if θ1, θ2, θ3 ∈J, then GSCS(θ1, θ2, θ3) ⊆J
where GSCS(θ1, θ2, θ3) = 
(i,j,k) = π(1,2,3) GSC S(θi, θj, θk), with π taking a per-
mutation of its arguments and GSC S(θi, θj, θk) = {gscS(θx, θy, θz) | θx ∈
{θi, θT
i }, θy ∈{θj, θT
j }, θz ∈{θk, θT
k }} for all triplets θi, θj, θk.
We note that for any three triplets θ1, θ2, θ3, in essence as many as 48 potentially
new triplets may result from application of the S6S derivation rule.
4
Exploiting Stability for Basis Computation
From Studen´y’s original idea, a series of algorithms have originated for com-
puting compact representations of semi-graphoid models [1,2,8]. As reviewed in

112
L.C. van der Gaag and S. Lopatatzidis
Sect. 2, these algorithms iteratively construct, from a starting triplet set, a basis
for the model deﬁned by this set; to this end, the algorithms apply in each itera-
tion the G4+ rule to any pair of triplets from the current basis. De Waal and Van
der Gaag introduced the notion of stability into this algorithmic framework [9],
by using both the G4+ and G4S derivation rules and keeping track of the stable
and unstable parts of a model separately.
We now extend the existing algorithmic framework by incorporating the
strong-contraction rule for stable independency. To this end, we consider a set
D of stable triplets for which the following hold, for all θi ∈D, i = 1, 2, 3:
– if gcS(θ1, θ2) is deﬁned, then there is a θ ∈D such that gcS(θ1, θ2) ⊑S θ; and
– if
gscS(θ1, θ2, θ3)
is
deﬁned,
then
there
is
a
θ
∈
D
such
that
gscS(θ1, θ2, θ3) ⊑S θ.
From the properties proved for the gcS-operator [9] and our Lemmas 4 and 5,
we ﬁnd that the set J = {θ′ | there is a θ ∈D such that θ′ ⊑S θ} is a stable
independency model. From this ﬁnding, we conclude that for incorporating the
strong-contraction rule, it suﬃces to establish the closure of the stable part of
a model under both the gcS- and gscS-operators. Figure 1 outlines the thus
enhanced algorithm for basis construction.
The enhanced algorithm has the same outline as the algorithm by De Waal
and Van der Gaag, yet includes recent advances [1,2] and embeds our new results.
The algorithm takes a pair (JS, JU) of stable and unstable starting sets, and
Fig. 1. Our enhanced algorithm for computing a basis by exploiting stability.

Exploiting Stability for Compact Representation of Independency Models
113
updates these iteratively. Line 7 of the algorithm pertains to the stable part of
the model under consideration and constructs a basis for this part by means of
the G4S and S6S rules; Line 8 constructs new triplets for the model’s unstable
part. Lines 9–11 address the interaction between the two parts of the model;
for further details of the computation steps involved, we refer to [9]. Line 12
constructs a new pair (JS, JU) for the next iteration, by removing all included
triplets and identifying implicit stable ones. We note that Fig. 1 presents just an
outline of the algorithm and upon implementation should be further optimised.
To study the eﬀects of our new results on computed representations, we
constructed, in Python, prototype implementations of the algorithm by De Waal
and Van der Gaag and of our enhanced algorithm. With both algorithms, we
implemented two simple rules for identifying implicit stable independencies. The
ﬁrst rule moves any saturated triplets from the unstable part JU to the stable
part JS. Secondly, if triplets ⟨A, B | C ∪{Vi}⟩for all Vi ∈V \(A ∪B ∪C) can
be derived from JS ∪JU, and at most one of these triplets is unstable, then the
stable triplet ⟨A, B | C⟩is added to JS.
With the two algorithms alike, we ran some preliminary experiments, for
diﬀerent starting sets. The following simple example illustrates that our new
algorithm may return a smaller basis than the algorithm by De Waal and Van
der Gaag.
Example 1. We take the set of variables V = {1, . . . , 5} and use concatenation of
elements as a shorthand for subsets of V . Table 1 states the stable and unstable
starting sets, and summarises the results from the two algorithms. Our new
algorithm constructs a smaller stable part as a result of a single application of
the gscS-operator, yielding the stable triplet ⟨3, 4 | ∅⟩. As the algorithm ﬁnds
this triplet during the ﬁrst iteration, it maintains smaller intermediate bases
throughout the subsequent iterations.
□
Our enhanced algorithm is not guaranteed to always yield a smaller basis
than existing algorithms. Since the strong-contraction rule aims at construct-
ing triplets with the smallest possible conditioning contexts, some triplets may
thereby become uncovered and have to be added explicitly to the basis under
construction. Even when a reduction in size is achieved for the representation
Table 1. An example starting set and the triplet sets of the bases returned by the two
algorithms.
Starting sets
Existing algorithm
New algorithm
Unstable
Stable
Unstable
Stable
Unstable
Stable
⟨1, 5 | 2⟩
⟨2, 5 | 3⟩
⟨1, 25 | ∅⟩⟨3, 4 | 1⟩
⟨1, 25 | ∅⟩⟨4, 3 | ∅⟩
⟨12, 5 | ∅⟩⟨2, 5 | 4⟩
⟨5, 12 | ∅⟩⟨3, 4 | 2⟩
⟨5, 12 | ∅⟩⟨2, 15 | ∅⟩
⟨1, 2 | ∅⟩
⟨2, 15 | ∅⟩
⟨3, 4 | 1⟩
⟨3, 4 | 2⟩

114
L.C. van der Gaag and S. Lopatatzidis
of a model’s stable part, therefore, may the enhanced algorithm return a larger
overall basis than existing algorithms.
5
Conclusions
Revisiting semi-graphoid independency models, we addressed the potential of
exploiting the notion of stability for constructing compact representations. We
formulated a new derivation rule to accommodate the strong-contraction prop-
erty for stable independencies and embedded this rule into an existing algorith-
mic framework. We illustrated the potential of the new rule by means of a simple
example. In the near future, we will perform more extensive experimentation to
investigate the interaction between the stable and unstable parts of the interme-
diate bases computed for a semi-graphoid independency model. We will further
address the question whether also other parts of such a model can be identiﬁed
and exploited for the construction of compact representations.
References
1. Baioletti, M., Busanello, G., Vantaggi, B.: Conditional independence structure and
its closure: inferential rules and algorithms. Int. J. Approx. Reason. 50, 1097–1114
(2009)
2. Lopatatzidis, S., van der Gaag, L.C.: Concise representations and construction algo-
rithms for semi-graphoid independency models. Int. J. Approx. Reason. 80, 377–392
(2015)
3. Mat´uˇs, F.: Ascending and descending conditional independence relations. In: Pro-
ceedings of the Eleventh Prague Conference on Information Theory, Statistical Deci-
sion Functions and Random Processes: B, pp. 189–200 (1992)
4. Niepert, M., Van Gucht, D., Gyssens, M.: A lattice-theoretic approach. In: Parr,
R., van der Gaag, L.C. (eds.) Proceedings of the Twenty-Fourth Conference on
Uncertainty in Artiﬁcial Intelligence, pp. 435–443. AUAI Press, Arlington (2008)
5. Niepert, M., Van Gucht, D., Gyssens, M.: Logical and algorithmic properties of
stable conditional independence. Int. J. Approx. Reason. 51, 531–543 (2010)
6. Pearl, J.: Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Infer-
ence. Morgan Kaufmann, Palo Alto (1988)
7. Studen´y, M.: Conditional independence relations have no ﬁnite complete character-
ization. In: Kub´ık, S., V´ısek, J.´A. (eds.) Information Theory, Statistical Decision
Functions and Random Processes, pp. 377–396. Kluwer, Amsterdam (1992)
8. Studen´y, M.: Complexity of structural models. In: Proceedings of the Joint Session of
the 6th Prague Conference on Asymptotic Statistics and the 13th Prague Conference
on Information Theory, Statistical Decision Functions and Random Processes, vol.
2, pp. 521–528 (1998)
9. de Waal, P., van der Gaag, L.C.: Stable independence and complexity of representa-
tion. In: Chickering, M., Halpern, J. (eds.) Proceedings of the Twentieth Conference
on Uncertainty in Artiﬁcial Intelligence, pp. 112–119. AUAI Press, Arlington (2004)

Parameter Learning Algorithms for Continuous
Model Improvement Using Operational Data
Anders L. Madsen1,2(B), Nicolaj Søndberg Jeppesen1, Frank Jensen1,
Mohamed S. Sayed3, Ulrich Moser4, Luis Neto5, Joao Reis5, and Niels Lohse3
1 HUGIN EXPERT A/S, Aalborg, Denmark
anders@hugin.com
2 Department of Computer Science, Aalborg University, Aalborg, Denmark
3 Loughborough University, Loughborough, UK
4 IEF-Werner GmbH, Furtwangen, Germany
5 Instituto de Sistemas e. Robotica Associacao, Porto, Portugal
Abstract. In this paper, we consider the application of object-oriented
Bayesian networks to failure diagnostics in manufacturing systems and
continuous model improvement based on operational data. The analysis
is based on an object-oriented Bayesian network developed for failure
diagnostics of a one-dimensional pick-and-place industrial robot devel-
oped by IEF-Werner GmbH. We consider four learning algorithms (batch
Expectation-Maximization (EM), incremental EM, Online EM and frac-
tional updating) for parameter updating in the object-oriented Bayesian
network using a real operational dataset. Also, we evaluate the perfor-
mance of the considered algorithms on a dataset generated from the
model to determine which algorithm is best suited for recovering the
underlying generating distribution. The object-oriented Bayesian net-
work has been integrated into both the control software of the robot as
well as into a software architecture that supports diagnostic and prog-
nostic capabilities of devices in manufacturing systems. We evaluate the
time performance of the architecture to determine the feasibility of on-
line learning from operational data using each of the four algorithms.
Keywords: Bayesian networks · Parameter update · Practical applica-
tion
1
Introduction
The need for diagnostic and health monitoring capabilities in manufacturing
systems is becoming increasingly important as manufacturing organisations
continuously aim to reduce system downtime and unpredicted disturbances to
production. We have found that Bayesian networks (BNs) [3,6,17] and their
extension Object-Oriented Bayesian Networks (OOBNs) [8,13] are well-suited to
capture and represent uncertainty in root-cause analysis using both component-
level models and wider system-level models integrating component-level models.
The crucial need for diagnostic and health monitoring capabilities is accompa-
nied with the availability of increasing amounts of sensory data and decreasing
c
⃝Springer International Publishing AG 2017
A. Antonucci et al. (Eds.): ECSQARU 2017, LNAI 10369, pp. 115–124, 2017.
DOI: 10.1007/978-3-319-61581-3 11

116
A.L. Madsen et al.
costs of computation on the shop-ﬂoor level have opened new opportunities for
component suppliers and system integrators to provide more competitive func-
tionalities that go beyond traditional control and process monitoring capabilities.
In this paper, we consider the challenge of parameter learning for contin-
uous model improvement using operational data. In particular, we investigate
the use of four diﬀerent approaches to improve the diagnostic performance of
an OOBN using operational data. The four algorithms are the batch EM algo-
rithm, incremental EM, Online EM and fractional updating. The investigation is
performed using an OOBN for root-cause analysis of a pick-and-place industrial
robot developed by IEF-Werner GmbH1 (the Linear Axis shown in the center
of Fig. 3). An initial OOBN for root-cause analysis has been developed based on
expert knowledge [11]. The OOBN has been integrated into the control software
of the component and is being deployed in a production line where eﬃcient and
eﬀective root-cause analysis is required in case of failure. In order to improve the
diagnostic performance of the OOBN diﬀerent methods for continuous model
update based on operational data are being investigated. This paper reports on
the results of these investigations.
Inspired by the work of [18], a number of approaches are considered. Notice
that our work diﬀers from the work of [18] in three important ways: (1) we
are considering parameter learning in OOBNs, (2) the objective is to improve
diagnostic performance (not classiﬁcation), and (3) while [18] compares three
algorithms, we investigate four algorithms. We consider the EM algorithm [9]
for parameter learning from a batch of data (referred to as batch EM). Using
batch EM, the idea is to collect data in batches and learn parameters oﬀ-line,
for instance, during maintenance hours as suggested by [18]. We use batch EM
as a reference. Adaptive causal probabilistic networks and fractional updating
are described in [16] who cites [21] while adaptive probabilistic networks are
described in [1,19]. A similar gradient descent approach is described in [5]. [10]
describes how the approach of [16] referred to as sequential learning has been
implemented in the HUGIN tool. The online EM algorithm [2] is a stochastic
gradient method that is faster than other gradient methods such as [19] which
involves a diﬃcult task of determining the step size between iterations.
2
Preliminaries and Notation
A BN N = (X, G, P) consists of a directed, acyclic graph G specifying depen-
dence and independence relations over a set of variables X and a set of
conditional probability distributions (CPDs) P encoding the strengths of the
dependence relations eﬀectively combining elements of probability and graph
theory. A BN is a representation of a joint probability distribution P(X) =
P(X1, . . . , Xn) = 
Xi∈X P(Xi|πXi) where πX are the parents of X in G. The
CPD P(X|πX) consists of one probability distribution over the states of X for
each conﬁguration of πX. We only consider discrete variables.
1 http://www.ief-werner.de.

Parameter Learning Algorithms for Continuous Model Improvement
117
An OOBN is a BN augmented with network classes, class instances and an
associated notion of interface and private variables [6,8,13]. A class instance is
the instantiation of a network class representing a sub-network within another
network class. The variables X(C) of network class C are divided into disjoint
subsets of input I, output O and hidden H variables such that X(C) = I∪O∪H
where the interface variables I ∪O are used to link nested class instances, see
Fig. 1. Inference in an OOBN is performed by creating a run-time instance of
the model and doing inference in this model. A run-time instance of an OOBN
is created by expanding it into a corresponding ﬂat BN.
The Hellinger distance DH(P, Q) used to compare two probability distribu-
tions P and Q is deﬁned as DH(P, Q) =

i(√pi −√qi)2 [18] who cites [7]. It
is similar to the Kullback-Leibler divergence, but deﬁned for zero probabilities.
To compare the results of parameter learning using two diﬀerent algorithms on
the same OOBN, the distance is computed as a sum of DH(Pi, Qi) for Xi ∈X.
This is similar to the approach taken by [18,22]. For each parent conﬁgura-
tion π of each X in each network class C, DH(P1(X|π), P2(X|π)) is computed
where P1 and P2 are CPDs produced by the two learning algorithms. The val-
ues DH(P1(X|π), P2(X|π)) are summed across parent conﬁgurations, variables
and classes (ignoring bounded input nodes). In the weighted Hellinger distance
Dw
H(P1(X|π), P2(X|π)), DH(P1(X|π), P2(X|π)) is weighted by P(π) in the ref-
erence model.
Fig. 1. The top level class of the Linear Axis Model.
3
The Linear Axis OOBN Model
The Linear Axis as a self-sustainable handling system that is designed to be a
high performance machine with a demand to work 24 h/day seven days a week.
Therefore, there is little or no time for maintenance and repair. This means that
there is a need for system condition monitoring to prevent failures and for system
failure diagnosis. The Linear Axis diagnosis model considered here is used for
root-cause analysis under the assumption that a problem is observed and the ﬁve
most likely root causes should be identiﬁed. Figure 1 shows the structure of the

118
A.L. Madsen et al.
top-level class of the Linear Axis OOBN. In the ﬁgure, blue nodes denote possible
root causes, orange nodes denote problem deﬁning nodes, and green nodes denote
possible observations such as sensor readings and operator feedback. The model
has 35 variables, 27 failure states, 555 CPD entries, maximum CPD size of 128
and ﬁve class instances (two instances of the LimitSwitch class). The Linear Axis
OOBN has been quantiﬁed using subject matter expert knowledge. We refer to
this model as the knowledge driven model and its development is described in
more detail in [11].
The diagnostic performance of the knowledge driven model has been assessed
following the approach of [11]. The basic idea, is to iterate through the root
causes where each root causes is instantiated to a failure state and all other root
causes are instantiated to non-failure. For each such conﬁguration, values for the
observations are generated. The values for the observations are propagated in
the model and the probabilities of the root causes recorded. This demonstrates
how well the observations can distinguish the root causes.
Fig. 2. The SelComp internal architecture concept.
4
The SelSus Architecture
The aim of the SelSus System Architecture is to provide an environment for
highly eﬀective, self-healing production resources and systems to maximize their
performance over longer life times through highly targeted and timely repair,
renovation and upgrading [20]. The architecture deﬁnes three levels of abstrac-
tion for its constituents: (1) Component Level, which relates directly to machines
or its sub-components and is composed of smart sensory capabilities, methods
for self-diagnostics and predictive maintenance. (2) Station Level, at this level
the developments are constituted by previous capabilities plus human machine
interfaces and tools to support the design and maintenance of the factory station.
(3) Factory Level, previous levels capabilities are combined to create a semantic
driven maintenance scheduling for large production factory plants.

Parameter Learning Algorithms for Continuous Model Improvement
119
The Linear Axis typically integrates a production cell, performing operations
in collaboration with other machines (e.g., robotic arms and welding tools). To
make operational and sensory data available to the SelSus System, the SelComp
(SelSus Component) concept was designed. The SelComp (Fig. 2), is a self-aware
entity that makes available to the SelSus system its internal state conditions,
providing this way operational and structural knowledge. A SelComp also pro-
vides built-in models for state estimation based on sensor data which enables
pro-active and predictive maintenance. These components have the ability to
collect data from sensors that are mounted physically in the same device or
in a near location and fuse this data to extend its models capabilities. The
Linear Axis OOBN has been encapsulated in the Machine SelComp for the
Linear Axis [12,20], see Fig. 3, as it represents a ﬁeld device, machine or its sub-
components. The goal is to provide diagnostic capabilities at component-level
supporting system-level diagnostics. A Sensor SelComp [14,15], on the other
hand, is designed to provide essentially smart sensor data to the SelSus sys-
tem and more often to Machine SelComps. The Sensor SelComp component has
plug&play capabilities in terms of physical sensors, data models and algorithms.
The Linear Axis OOBN can also be abstracted as a service to provide outputs
to and subscribe to inputs from the SelSus System and other SelComps.
Fig. 3. The SelSus system architecture.
5
Parameter Learning Algorithms
Let N = (X, G, P) be a BN with parameters Θ = (θijk) such that θijk = P(Xi =
k | πXi = j) for each i, j, k. The task of parameter learning is to estimate the
values of the parameters Θ given a dataset of cases D = {c1, . . . , cN}. The cases
of D are assumed independent and identically distributed (i.i.d.) with values
missing at random or completely at random [4]. The generating probability dis-
tribution is assumed to be stationary. We ﬁrst present the parameter learning

120
A.L. Madsen et al.
algorithms for standard BNs followed by a description of how they are applied
to OOBNs.
The EM algorithm [4,9] is well-suited for calculating maximum likelihood
and maximum a posteriori (MAP) estimates in the case of missing data. The
algorithm iterates the E-Step and M-Step until convergence. Given an initial
value of the parameters Θ, the E-step computes the current expected suﬃcient
statistics while the subsequent M-step maximizes the log-likelihood function l(Θ|
D) = N
i=1 log P(ci | Θ). The E-step of the EM algorithm computes expected
suﬃcient statistics for each family fa(Xi) and parent conﬁguration πij of each Xi
under Θ as n(Y ) = EΘ{n(Y ) | D}, where n(·) is counts for either πij or Xi =
k, πij. The M-step computes new estimates of θ∗
ijk from the expected counts
under θijk and a virtual count θijkαij speciﬁed beforehand (MAP estimate):
θ∗
ijk = n(Xi = k, πij) + θijkαij
n(πij) + αij
,
(1)
where αij is the equivalent sample size (ESS) speciﬁed for πij.
The principle idea of the incremental EM algorithm, e.g. [18], is to divide
the data D into disjoint subsets D1, . . . , Dm and iteratively apply EM on Di.
The estimates θijk and αij produced by one iteration of EM are used as virtual
counts in the next iteration of EM. If D is complete, then incremental EM and
batch EM produce the same result. Incremental EM is less space demanding
than EM as it only needs to hold Di in memory at step i.
Online EM [2], which can be considered a gradient ascent algorithm, performs
a parameter update after propagating each case c. It is a stochastic approxima-
tion algorithm that computes the updated parameter θ∗
ijk as:
θ∗
ijk = (1 −γ)mijk + γP(xijk|c),
(2)
where mijk is the normalized suﬃcient statistics computed as mijk = αij ∗
p(xik|πij)/ 
j αij and p(xijk|c) is computed by propagating case c. Notice that
even for πij with P(πij) = 0 there is a fading of (1 −γ). The learning rate
γ = (1 + n)−ρ controls the weighting of new cases where n is the iteration
number. [2] suggests to use ρ = 0.6 while [18] recommends ρ = 0.501.
The fractional updating algorithm, see e.g., [16] who cites [21], also performs
a parameter update after propagating each case c. In fractional updating the
parameter θijk is adjusted after propagating each case c as follows:
θ∗
ijk = αijk + P(xijk|c)
αij + P(πij|c) .
(3)
Fading of past cases is controlled by a fading factor λ speciﬁed for each πij
and a gradual fading is obtained by taking P(πij) into consideration. To improve
performance, fractional updating is only performed for πij when P(πij) > 0 (an
update would leave θ∗
ijk and αij unchanged when P(πij) = 0)), see [10].
Both fractional updating and Online EM perform no update when αij = 0.
Also, fractional updating and Online EM are the least space demanding algo-
rithms as they only need to hold the latest case in memory.

Parameter Learning Algorithms for Continuous Model Improvement
121
In the general case of OOBNs, we compute the average expected counts for
the run-time instances of the node and increase the experience counts by the
number of run-time instances. This applies to all four algorithms.
6
Empirical Evaluation
The empirical evaluation is organised into three diﬀerent tests (1) we consider
updating the parameters of the knowledge driven model where all distributions
are made uniform using a dataset of 250, 000 cases with 5% missing values gen-
erated completely at random from the knowledge driven model, (2) we consider
updating the parameters of the knowledge driven model using an real operational
dataset, and (3) we consider the time performance of updating the parameters
in the knowledge driven model in a real setting. The evaluations are performed
using diﬀerent values of the parameters of the learning algorithms.
Figure 4 shows the results (1) where a random sample generated from the
knowledge driven model is used to learn the parameters in the model with uni-
form distributions. Figure 4(left) shows the weighted Hellinger distance while
(right) shows the time usage of each algorithm.
0
5
10
15
20
25
30
0
50000
100000
150000
200000
250000
Hellinger Distance
Number of cases
Batch EM
+
+
+
+
+
+
+
+
+
+
+
+
Incremental EM
×
×
×
×
×
×
×
×
×
×
×
×
Online EM, ρ = 0.99
∗
∗
∗
∗
∗
∗
∗
∗
∗
∗
∗
∗
Online EM, ρ = 0.6
□
□
□
□
□
□
□
□
□
□
□
□
Online EM, ρ = 0.501
■
■
■
■
■
■
■
■
■
■
■
■
Fractional Update
◦
◦
◦
◦
◦
◦
◦
◦
◦
◦
◦
◦
0
50000
100000
150000
200000
250000
300000
350000
400000
0
50000
100000
150000
200000
250000
Time (ms)
Number of cases
Batch EM
+
+
+
+
+
+
+
+
+
+
+
+
Incremental EM
×
×
×
×
×
×
×
×
×
×
×
×
Online EM, ρ = 0.99
∗
∗
∗
∗
∗
∗
∗
∗
∗
∗
∗
∗
Online EM, ρ = 0.6
□
□
□
□
□
□
□
□
□
□
□
□
Online EM, ρ = 0.501
■
■
■
■
■
■
■
■
■
■
■
■
Fractional Update
◦
◦
◦
◦
◦
◦
◦
◦
◦
◦
◦
◦
Fig. 4. Hellinger distance (left) and accumulated time is ms (right).
In the test, the values ρ ∈{0.501, 0.6, 0.99}, n0 = 1, 
j αij = 1 for all i
and λ = 1 are used. The value for N = 0 is the distance is between the uniform
distribution and the knowledge driven model. The distances are quickly reduced
in all cases and after a certain point no or little improvement is observed. Dw
H
reduces the impact of large diﬀerences in distributions for πij with αij ≪1.
In (2) the operational dataset contains two sequences of 13, 429 cases in total
with six observed sensor readings represented in the model, i.e., there is 83%
missing values due to the hidden variables alone. It contains both failure and
non-failure cases. Table 1 shows the diagnostic performance of the ﬁve models
considered where μrank refers to the average rank of the true root cause, i.e., the
value 1 means perfect performance and 27 worst possible performance. In the
test, the values ρ = 0.99, 
j αij = 13, 429 for all i and n0 = 13, 429 are used.

122
A.L. Madsen et al.
Table 1. The diagnostic performance of the ﬁve models considered.
Algorithm
Top-1 Top-5 µrank
Knowledge driven model
8
17
4.6
Batch EM
10
17
5.1
Online EM
9
17
4.5
Fractional update
10
21
3.4
For all algorithms, there is an increase in the number of true root causes
identiﬁed as the cause with highest probability. For Top-5 there is a signiﬁcant
improvement using fractional updating. The value μrank is not improved for
batch EM. This is due to three true root causes obtaining a signiﬁcantly worse
rank after learning (e.g., rank 2 before compared to rank 16 after learning).
Next (3), we report on a performance analysis of two levels of integration of
the OOBN model into the SelSus architecture using Online EM and fractional
updating for parameter learning. The ﬁrst and most tight level of integration
has been achieved by integrating the model directly into the component control
software where data is read from ﬁle. The second conﬁguration is to deploy a
BBN web service holding the model, a data server holding the data and the
control software inside the SelSus Cloud. The control software retrieves data
from the cloud and requests propagation of and learning from each case in the
data retrieved. We consider retrieving diﬀerent amounts of data in each request.
Table 2. Average time cost of handling one case across the integration levels.
Algorithm
Conﬁguration
Cases/Request
Total time (ms)
Average time (ms)
Online EM
Direct integration
1
1,730
0.067
SelSus Cloud
1000
11,367
0.44
SelSus Cloud
100
44,867
1.74
SelSus Cloud
10
496,199
19.29
Fractional
Direct integration
1,533
0.067
updating
SelSus Cloud
1000
10,553
0.41
SelSus Cloud
100
42,111
1.64
SelSus Cloud
10
478,612
18.60
Table 2 shows the total and average time cost for each conﬁguration. The
analysis is performed using an operational data set of 25, 726 cases collected
randomly. Here the focus is only on runtime and not the learning. As expected,
there is a signiﬁcant diﬀerence between direct integration and using a cloud
service wrt. runtime. This means that the learning must be designed taking the
data frequency into consideration.

Parameter Learning Algorithms for Continuous Model Improvement
123
7
Discussion
We have described the use of batch EM, incremental EM, Online EM and frac-
tional updating on OOBNs for continuous model improvement using operational
data. The objective was to improve the diagnostic performance of an OOBN for
root-cause analysis by adjusting the model parameters using data.
The experimental results show that parameter learning for continuous model
improvement using operation data is both feasible and will lead to better diag-
nostic performance. The Online EM algorithm is sensitive to the value of the ρ
parameter and our results indicate that a value close to 1 is preferred. This is
contrary to the [18] who suggests ρ = 0.501 and [2] who suggests ρ ∈[0.6; 0.9]
and uses ρ = 0.6. The ρ-value controls the learning rate γ and higher γ-values
(and lower ρ-values) means more emphasis on new cases (i.e., faster learning).
The results of the ﬁrst experiment demonstrate that all four approaches
quickly produce a model that has a low Dw
H relative to the knowledge driven
models. There is no method that produce a signiﬁcantly better result that the
other algorithms. This is using a data set with 5% missing values. The running
time of incremental EM with large batches and batch EM makes them infeasible
in practice for this application.
For the Linear Axis OOBN with ||X|| = 35 only six are observed in the
operational data. This data set has not been augmented with information on
presence or absence of root causes nor any operator feedback. The data only
includes sensor readings. Despite this fact, the algorithms all improve the diag-
nostic performance of the model compared to the initial knowledge driven model.
It is expected that enriching the operational data with information on absence
or presence of root causes will improve the learning. This will reduce the bias
of the data as much more non-failure than failure data must be expected. Frac-
tional update enables the speciﬁcation of diﬀerent αij for diﬀerent CPDs and
parent conﬁgurations in this way controlling the impact of the expert assessed
parameters whereas Online EM uses normalised suﬃcient statistics and uses ρ
to control the learning rate.
When learning the parameters from operational data using a knowledge
driven model as the starting point, a decision on the relative balance of the
data and the expert elicited values must be made. In the experiments, we have
deﬁned an ESS equal to the size of the operational data. This decision is impor-
tant when the data stream is, in principle, inﬁnite in a real operational setting.
In any case, it is important that the parameters are stable at least until suﬃcient
data has been processed, which is dependent on the model complexity.
Acknowledgments. This work is part of the project “Health Monitoring and Life-
Long Capability Management for SELf-SUStaining Manufacturing Systems (SelSus)”
which is funded by the Commission of the European Communities under the 7th
Framework Programme, Grant agreement no: 609382. We would like to thank Andres
Masegosa for discussions on the Online EM algorithm and the reviewers for their
insightful comments, which have helped to improve the paper.

124
A.L. Madsen et al.
References
1. Binder, J., Koller, D., Russell, S., Kanazawa, K.: Adaptive probabilistic networks
with hidden variables. Mach. Learn. 29(2), 213–244 (1997)
2. Cappe, O., Moulines, E.: Online EM algorithm for latent data models. J. Roy. Stat.
Soc. Ser. B (Stat. Method.) 71(3), 593–613 (2009)
3. Cowell, R.G., Dawid, A.P., Lauritzen, S.L., Spiegelhalter, D.J.: Probabilistic Net-
works and Expert Systems. Springer, New York (1999)
4. Dempster, A.P., Laird, N.M., Rubin, D.B.: Maximum likelihood from incomplete
data via the EM algorithm. J. Roy. Stat. Soc. Ser. B 39(1), 1–38 (1977)
5. Jensen, F.V.: Gradient descent training of Bayesian networks. In: Proceedings of
the ECSQARU, pp. 190–200 (1999)
6. Kjærulﬀ, U.B., Madsen, A.L.: Bayesian Networks and Inﬂuence Diagrams. A Guide
to Construction and Analysis, 2nd edn. Springer, New York (2013)
7. Kokolakis, G., Nanopoulos, P.: Bayesian multivariate micro-aggregation under the
Hellingers distance criterion. Res. Oﬃc. Stat. 4(1), 117–126 (2001)
8. Koller, D., Pfeﬀer, A.: Object-oriented bayesian networks. In: Proceedings of the
UAI, pp. 302–313 (1997)
9. Lauritzen, S.L.: The EM algorithm for graphical association models with missing
data. Comput. Stat. Anal. 19, 191–201 (1995)
10. Madsen, A.L., Lang, M., Kjærulﬀ, U.B., Jensen, F.: The Hugin tool for learning
Bayesian networks. In: Proceedings of the ECSQARU, pp. 594–605 (2003)
11. Madsen, A.L., Søndberg-Jeppesen, N., Lohse, N., Sayed, M.: A methodology for
developing local smart diagnostic models using expert knowledge. In: IEEE INDIN,
pp. 1682–1687 (2015)
12. Madsen, A.L., Søndberg-Jeppesen, N., Sayed, M.S., Peschl, M., Lohse, N.: Apply-
ing object-oriented Bayesian networks for smart diagnosis and health monitoring
at both component and factory level. Accepted for IEA/AIE 2017 (2017)
13. Neil, M., Fenton, N., Nielsen, L.M.: Building large-scale Bayesian networks. Knowl.
Eng. Rev. 15(3), 257–284 (2000)
14. Neto, L., Reis, J., Guimaraes, D., Concalves, G.: Sensor cloud: smartcompo-
nent framework for reconﬁgurable diagnostics in intelligent manufacturing envi-
ronments. In: IEEE INDIN, pp. 1706–1711 (2015)
15. Neto, L., Reis, J., Silva, R., Concalves, G.: Sensor SelComp, a smart component
for the industrial sensor cloud of the future. In: IEEE ICIT, pp. 1256–1261 (2017)
16. Olesen, K.G., Lauritzen, S.L., Jensen, F.V.: aHUGIN: a system creating adaptive
causal probabilistic networks. In: Proceedings of the UAI, pp. 223–229 (1992)
17. Pearl, J.: Probabilistic Reasoning in Intelligent Systems: Networks of Plausible
Inference. Morgan Kaufmann Publishers, San Mateo (1988)
18. Ratnapinda, P., Druzdzel, M.J.: Learning discrete Bayesian network parameters
from continuous data streams: what is the best strategy. J. Appl. Logic 13, 628–
642 (2015)
19. Russell, S., Binder, J., Koller, D., Kanazawa, K.: Local learning in probabilistic
networks with hidden variables. In: Proceedings of IJCAI, pp. 1146–1152 (1995)
20. Sayed, M.S., Lohse, N., Søndberg-Jeppesen, N., Madsen, A.L.: SelSus: towards
a reference architecture for diagnostics and predictive maintenance using smart
manufacturing devices. In: IEEE INDIN, p. 6 (2015)
21. Titterington, D.M.: Updating a diagnostic system using unconﬁrmed cases. Appl.
Stat. 25, 238–247 (1976)
22. Zagorecki, A., Voortman, M., Druzdzel, M.J.: Decomposing local probability dis-
tributions in bayesian networks for improved inference and parameter learning. In:
Proceedings of the FLAIRS, pp. 860–865 (2006)

Monotonicity in Bayesian Networks
for Computerized Adaptive Testing
Martin Plajner1,2(B) and Jiˇr´ı Vomlel2
1 Faculty of Nuclear Sciences and Physical Engineering, Czech Technical University,
Prague, Trojanova 13, 120 00 Prague, Czech Republic
2 Institute of Information Theory and Automation, Czech Academy of Sciences,
Pod Vod´arenskou vˇeˇz´ı 4, 182 08 Prague 8, Czech Republic
{plajner,vomlel}@utia.cas.cz
http://staff.utia.cas.cz/plajner/
http://www.utia.cas.cz/vomlel/
Abstract. Artiﬁcial intelligence is present in many modern computer
science applications. The question of eﬀectively learning parameters of
such models even with small data samples is still very active. It turns
out that restricting conditional probabilities of a probabilistic model by
monotonicity conditions might be useful in certain situations. Moreover,
in some cases, the modeled reality requires these conditions to hold. In this
article we focus on monotonicity conditions in Bayesian Network mod-
els. We present an algorithm for learning model parameters, which sat-
isfy monotonicity conditions, based on gradient descent optimization. We
test the proposed method on two data sets. One set is synthetic and the
other is formed by real data collected for computerized adaptive testing.
We compare obtained results with the isotonic regression EM method
by Masegosa et al. which also learns BN model parameters satisfying
monotonicity. A comparison is performed also with the standard unre-
stricted EM algorithm for BN learning. Obtained experimental results
in our experiments clearly justify monotonicity restrictions. As a conse-
quence of monotonicity requirements, resulting models better ﬁt data.
Keywords: Computerized adaptive testing · Monotonicity · Isotonic
regression EM · Gradient method · Parameters learning
1
Introduction
In our previous research Plajner and Vomlel (2015) we focused on Computer-
ized Adaptive Testing (CAT) (Almond and Mislevy 1999; van der Linden and
Glas 2000). We used artiﬁcial student models to select questions during the
course of testing. We have shown that it is useful to include monotonicity con-
ditions while learning parameters of these models (Plajner and Vomlel 2016b).
This work was supported by the Czech Science Foundation (project No. 16-12010S)
and by the Grant Agency of the Czech Technical University in Prague, grant No.
SGS17/198/OHK4/3T/14.
c
⃝Springer International Publishing AG 2017
A. Antonucci et al. (Eds.): ECSQARU 2017, LNAI 10369, pp. 125–134, 2017.
DOI: 10.1007/978-3-319-61581-3 12

126
M. Plajner and J. Vomlel
Monotonicity conditions incorporate qualitative inﬂuences into a model. These
inﬂuences restrict conditional probabilities in a speciﬁc way to avoid unwanted
behavior. Some models we use for CAT include monotonicity naturally, but in
this article we focus on a speciﬁc family of models, Bayesian Networks, which do
not. Monotonicity in Bayesian Networks is discussed in literature for a long time.
It is addressed, for example, by Wellman (1990), Druzdzel and Henrion (1993)
and more recently by, e.g., Restiﬁcar and Dietterich (2013), Masegosa et al.
(2016). Monotonicity restrictions are often motivated by reasonable demands
from model users. In our case of CAT it means we want to make sure that stu-
dents having certain skills will have a higher probability of answering questions
depending on these skills correctly. Moreover, assuming monotonicity we can
learn better models, especially when the data sample is small. In our work we
have so far used monotonicity attained by logistic regression models of CPTs.
This has proven useful but it is restrictive since it requires a prescribed CPT
structure.
In this article we extends our results in the domain of Bayesian Networks. We
present a gradient descent optimum search method for learning parameters of
CPTs respecting monotonicity conditions. First, we establish our notation and
monotonicity conditions in Sect. 2. Our method is derived in Sect. 3. We have
implemented the method and performed tests. For testing we used two diﬀerent
data sets. First, we used a synthetic data set generated from a monotonic model
(CPTs satisfying monotonicity) and second, we used real data set collected ear-
lier. Experiments were performed on these data sets also with the isotonic regres-
sion EM (irem) method described by Masegosa et al. (2016) and the ordinary
EM learning without monotonicity restrictions. In Sect. 4 of this paper we take
a closer look at the experimental setup and present results of described tests.
The last section brings an overview and a discussion of the obtained results.
2
BN Models and Monotonicity
2.1
Notation
In this article we use Bayesian Networks. Details about BNs can be found in,
for example, Pearl (1988), Nielsen and Jensen (2007). We restrict ourselves to
the following BN structure. Networks have two levels. In compliance with our
previous articles, variables in the parent’s level are addressed as skill variables
S. The children level contains questions-answers variables X. Example network
structures, which we also used for experiments, are shown in Figs. 1 and 2.
– We will use symbol X to denote the multivariable (X1, . . . , Xn) taking states
x = (x1, . . . , xn). The total number of question variables is n, the set of all
indexes of question variables is N = {1, . . . , n}. Question variables are binary
and they are observable.
– We will use symbol S to denote the multivariable (S1, . . . , Sm) taking states
s = (s1, . . . , sm). The set of all indexes of skill variables is M = {1, . . . , m}.

Monotonicity in Bayesian Networks for Computerized Adaptive Testing
127
Fig. 1. Artiﬁcial model
Fig. 2. CAT model network
Skill variables have variable number of states1, the total number of states of a
variable Sj is mj and individual states are sj,k, k ∈{1, . . . , mj}. The variable
Si = Spa(i) stands for a multivariable same as S but containing only parent
variables of the question Xi. Indexes of these variables are M i ⊆M. The
set of all possible state conﬁgurations of Si is V al(Si). Skill variables are all
unobservable.
CPT parameters for a question variable Xi for all i ∈N, si ∈V al(Si) are
θi,si = P(Xi = 0|Si = si), θi = (θi,si)si∈V al(Si).
We will also use θi,s = θi,si with the whole parent set S, where variables from
S\Si do not aﬀect the value. Probabilities of a correct answer to a question Xi
given state conﬁguration si is P(X = 1|Si = si) = 1 −θi,si (binary questions).
Parameters of parent variables for j ∈M are
ρj,sj = P(Sj = sj), ρj = (P(Sj = sj′)) , j′ ∈{1, . . . , mj}.
Parameter vector ρj is constrained by a condition mj
sj=1 ρj,sj = 1. To remove
this condition we reparametrize this vector to
ρj,sj =
exp(μj,sj)
mi
s′
j=1 exp(μj,s′
j).
1 In our experiments we use parents with 3 states, but the following theory applies to
any number of states.

128
M. Plajner and J. Vomlel
The whole vector of parameters is then
θ = (θ1, . . . , θn, ρ1, . . . , ρm) , or μ = (θ1, . . . , θn, μ1, . . . , μm) ,
where the meaning of μj is the same as ρj but in this case vectors contain
reparametrized variables. The transition from μ to θ is simply done with the
reparametrization above and will be used without further notice. The total num-
ber of elements in the vector μ and θ is
lμ = lθ =

i∈N

j∈M i
mj +

l∈M
ml.
2.2
Monotonicity
The concept of monotonicity in BNs has been discussed in literature since the last
decade of the previous millennium (Wellman 1990; Druzdzel and Henrion 1993).
Later its beneﬁts for BN parameter learning were addressed, for example, by
van der Gaag et al. (2004), Altendorf et al. (2005). This topic is still active, e.g.,
Feelders and van der Gaag (2005), Restiﬁcar and Dietterich (2013), Masegosa
et al. (2016).
We will consider only variables with states from N0 with their natural order-
ing, i.e., the ordering of states of skill variable’s Sj for j ∈M, is
sj,1 ≺. . . ≺sj,mj.
For questions we use natural ordering of its states (0 ≺1).
A variable Sj has monotone, resp. antitone, eﬀect on its child if for all k, l ∈
{1, . . . , mj}:
sj,k ⪯sj,l ⇒P(Xi = 1|Sj = sj,k, s) ≤P(Xi = 1|Sj = sj,l, s),
resp.
sj,k ⪯sj,l ⇒P(Xi = 1|Sj = sj,k, s) > P(Xi = 1|Sj = sj,l, s).
where s is the conﬁguration of other remaining parents of question i without
Sj. For each question Xi, i ∈M we denote by Si,+ the set of parents with a
monotone eﬀect and by Si,−the set of parents with an antitone eﬀect.
Next, we create a partial ordering ⪯i on all state conﬁgurations of parents
Si of the i-th question, where for all si, ri ∈V al(Si):
si ⪯i ri ⇔

si
j ⪯ri
j, j ∈Si,+
and

ri
j ⪯si
j, j ∈Si,−
.
The monotonicity condition then requires that the question probability of
correct answer is higher for a higher order parent conﬁguration, i.e., for all
si, ri ∈V al(Si):
si ⪯i ri ⇒P(Xi = 1|Si = si) ≤P(Xi = 1|Si = ri),
si ⪯i ri ⇒P(Xi = 0|Si = si) ≥P(Xi = 0|Si = ri) ⇔θi,si ≥θi,ri.
In our experimental part we consider only isotone eﬀect of parents on their
children. The diﬀerence with antitone eﬀects is only in the partial ordering.

Monotonicity in Bayesian Networks for Computerized Adaptive Testing
129
3
Parameter Gradient Search with Monotonicity
To learn parameter vector μ we develop a method based on the gradient descent
optimization. We follow the work of Altendorf et al. (2005) where they use a
gradient descent method with exterior penalties to learn parameters. The main
diﬀerence is that we consider models with hidden variables.
We denote by D the set of indexes of observations vectors. One vector
xk, k ∈D corresponds to one student and an observation of i-th variable Xi
is xk
i . The number of occurrences of the k-th conﬁguration vector in the data
sample is dk.
We use the model structure as described in Sect. 2, i.e., unobserved parent
variables and observed binary children variables. With sets Ik
0 and Ik
1 of indexes
of incorrectly and correctly answered questions, we create following products
based on observations in the k-th vector:
pk
0(μ, s, k) =

i∈Ik
0
θi,s,
pk
1(μ, s, k) =

i∈Ik
1
(1 −θi,s),
pµ(μ, s) =
m

j=1
exp(μj,sj).
We work with the log likelihood:
LL(μ) =

k∈D
dk · log
⎛
⎝

s∈V al(S)
m

j=1
exp(μj,sj)
mj
s′
j=1 exp(μj,s′
j) · pk
0(μ, s, k) · pk
1(μ, s, k)
⎞
⎠
=

k∈D
dk · log


s∈V al(S)
pµ(μ, s) · pk
0(μ, s, k) · pk
1(μ, s, k)

−N ·
m

j=1
log
mj

s′
j=1
exp(μj,s′
j).
The partial derivatives of LL(μ) with respect to θi,si for i ∈N, si ∈V al(Si)
are
δLL(μ)
δθi,si
=

k∈D
dk · (−2xk
i + 1) · pµ(μ, si) · pk
0(μ, si, k) · pk
1(μ, si, k)
θi,si · 
s∈V al(S) pµ(μ, s) · pk
0(μ, s, k) · pk
1(μ, s, k).
and with respect to μi,l for i ∈M, l ∈{1, . . . , mi} are
δLL(μ)
δμi,l
=

k∈D
dk ·
si=l
s∈V al(S) pµ(μ, s) · pk
0(μ, s, k) · pk
1(μ, s, k)

s∈V al(S) pµ(μ, s) · pk
0(μ, s, k) · pk
1(μ, s, k)
−N ·
exp(μi,l)
mi
l′=1 exp(μk,l′).
3.1
Monotonicity Restriction
To ensure monotonicity we use a penalty function
p(θi,si, θi,ri) = exp(c · (θi,ri −θi,si))

130
M. Plajner and J. Vomlel
for the log likelihood:
LL′(μ, c) = LL(μ) −

i∈N

si⪯iri
p(θi,si, θi,ri),
where c is a constant determining the strength of the condition. Theoretically,
this condition does not ensure monotonicity but, practically, selecting high values
of c results in monotonic estimates. If the monotonicity is not violated, i.e.
θi,ri < θi,si then the penalty value is close to zero. Otherwise, the penalty is
raising exponentially fast with respect to θi,ri −θi,si. In our experiments we
have used the value of c = 40 but any value higher than 20 provided almost
identical results.
Partial derivatives with respect to μi,l remain unchanged. Partial derivatives
with respect to θi,si are:
δLL′(μ, c)
δθi,si
= δLL(μ)
δθi,si
+ c

si⪯iri
p(θi,si, θi,ri) −c

ri⪯isi
p(θi,ri, θi,si)
Using the penalized log likelihood, LL′(μ, c), and its gradient
∇(LL(μ, c)) =
δLL′(μ, c)
δθi,si
, δLL(μ)
δμj,l

,
for i ∈N, si ∈V al(Si), j ∈M, l ∈{1, . . . , mj}, we can apply the standard gra-
dient method optimization to solve the problem. In order to ensure probability
values of θi, i ∈N it is necessary to use a bounded optimization method.
4
Experiments
For testing we use two diﬀerent Bayesian Network models. The ﬁrst one is an
artiﬁcial model and we use simulated data. The second model is one of the
models we used for computerized adaptive testing and we work with real data (for
details please refer to Plajner and Vomlel (2016a)). In both cases we learn model
parameters from data. Parameters are learned with our gradient method, isotonic
regression EM2 and the standard unrestricted EM algorithm. The learned model
quality is measured by the log likelihood of the whole data sample including the
training subset. This is done in order to provide results comparable between
diﬀerent training set sizes.
2 We have implemented the irem algorithm based on the article (Masegosa et al. 2016).
We extended the method to work with parents with more states than 2 (the article
considers only binary variables). Questions (children) remain binary which makes
the extension easy.

Monotonicity in Bayesian Networks for Computerized Adaptive Testing
131
4.1
Artiﬁcial Model
The ﬁrst model is displayed in Fig. 1. This model was created to provide sim-
ulated data for testing. The structure of the model is similar to models we use
in CAT modeling with two levels of variables. Parents S1 and S2 have 3 possi-
ble states and children X1, . . . , X5 are binary. We have instantiated the model
with random parameters vector θ∗satisfying monotonicity conditions. We drew
a random sample of 100 000 cases from the model.
For parameters learning we use random subsets of size k of 10, 20, 50, 100,
1 000, 10 000, 50 000, and 100 000-(full data set) cases. For each size (except
the last one) we use 10 diﬀerent sets. Next, we prepared 15 initial parameter
conﬁgurations for the ﬁxed Bayesian Network structure (Fig. 1). These networks
have starting parameters θi generated at random, but in such a way, that they
satisfy monotonicity conditions. The assumption of monotonicity is part of our
domain expert knowledge. Therefore we can use it to speed up the process and
avoid local optima. Parameters of parent variables are uniform and initial vectors
are the same for each method. In our experiment we learn network parameters
for each initial parameter setup for each set in a particular set size (giving a
total of 150 learned networks for one set size). The learned parameter vectors
are θi,j for j-th subset of data.
The average log likelihood for the whole data sample
LLA =
10
j=1
15
i=1 LL(θi,j)
150
is shown in Fig. 3 for each set size. In case of this model we are also able to
measure the distance of learned parameters from the generating parameters in
addition to the log likelihood. First we calculate an average error for each learned
model:
ei,j = |θ∗−θi,j|
lθ
,
k − training sample size
−LLA(k)
3e+6
4e+6
5e+6
6e+6
1e+1
2e+1
5e+1
1e+2
1e+3
1e+4
5e+4
1e+5
Model
grad
irem
em
Fig. 3. Negative log likelihood for the whole sample and diﬀerent training set sizes for
the artiﬁcial model.

132
M. Plajner and J. Vomlel
0.00
0.05
0.10
0.15
0.20
0.25
k − training sample size
e(k)
1e+1
2e+1
5e+1
1e+2
1e+3
1e+4
5e+4
1e+5
Model
grad
irem
em
Fig. 4. Mean diﬀerence of parameters of learned and generating networks for diﬀerent
set sizes for the artiﬁcial model.
7000
8000
9000
k − training sample size
−LLA(k)
1/10
2/10
3/10
4/10
Model
grad
irem
em
Fig. 5. Negative log likelihood for the whole sample and diﬀerent training set sizes for
the CAT model.
where || is L1 norm. Next we average over all results in one set size:
e =
10
j=1
15
i=1 ei,j
150
.
Resulting values of e are displayed in Fig. 4 for each set size.
4.2
CAT Model
The second model is the model we used for CAT (Plajner and Vomlel 2016b).
Its structure is displayed in Fig. 2. Parent variables S1, . . . , S7 have 3 states and
each one of them represents a particular student skill. Children nodes Xi are vari-
ables representing questions which are binary. Data associated with this model
were collected from paper tests of mathematical skills of high school students.

Monotonicity in Bayesian Networks for Computerized Adaptive Testing
133
In total the data sample has 281 cases. For more detailed overview of tests refer
to Plajner and Vomlel (2016a). For learning we use random subsets of size of
1/10, 2/10, 3/10, and 4/10 of the whole sample. Similarly to the previous model,
we drew 10 random sets for each size and initiated models by 15 diﬀerent initial
random monotonic starting parameters θi.
After learning we compute log likelihoods of the whole data set and we create
averages for each set size LLA(k) as with the previous model. Resulting values
are in Fig. 5. In this case we cannot compare learned parameters because the
real parameters with real are unknown.
5
Conclusions
In this article we have presented a gradient based method for learning parameters
of Bayesian Network under monotonicity restrictions. The method was described
and then tested on two data sets. In Figs. 3 and 5 it is clearly visible that this
method achieves the best results from three tested methods (especially for small
training samples). The irem method has problems with small training samples
and the log likehood in those cases is low. This is a consequence of the fact that it
moves to monotonic solution from a poor EM estimate and in these cases ensur-
ing monotonicity implies log likelihood degradation. We can also observe that
for the training sets larger than 1000 data vectors the EM algorithm stabilizes
in its parameter estimations. It means that at about k = 1000 the EM algorithm
found the best model it can and increasing training size does not improve the
result. Nevertheless, as we can observe in Fig. 4 parameters of learned networks
are always closer to the generating parameters while considering monotonicity
for both the irem and the gradient methods than for the standard EM.
These results verify usefulness of monotonicity for learning Bayesian Net-
works. A possible extension is to enlarge the theory of gradient based method
to work with more general network structures.
References
Almond, R.G., Mislevy, R.J.: Graphical models and computerized adaptive testing.
Appl. Psychol. Meas. 23(3), 223–237 (1999)
Altendorf, E.E., Restiﬁcar, A.C., Dietterich, T.G.: Learning from sparse data by
exploiting monotonicity constraints. In: Proceedings of the Twenty-First Conference
on Uncertainty in Artiﬁcial Intelligence (UAI 2005) (2005)
Druzdzel, J., Henrion, M.: Eﬃcient reasoning in qualitative probabilistic networks.
In: Proceedings of the Eleventh National Conference on Artiﬁcial Intelligence, pp.
548–553. AAAI Press (1993)
Feelders, A.J., van der Gaag, L.: Learning Bayesian network parameters with prior
knowledge about context-speciﬁc qualitative inﬂuences. In: Proceedings of the
Twenty-First Conference on Uncertainty in Artiﬁcial Intelligence (UAI 2005) (2005)
Masegosa, A.R., Feelders, A.J., van der Gaag, L.: Learning from incomplete data in
Bayesian networks with qualitative inﬂuences. Int. J. Approx. Reason. 69, 18–34
(2016)

134
M. Plajner and J. Vomlel
Nielsen, T.D., Jensen, F.V.: Bayesian Networks and Decision Graphs. Information Sci-
ence and Statistics. Springer, New York (2007)
Pearl, J.: Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Infer-
ence. Morgan Kaufmann Publishers Inc., San Francisco (1988)
Plajner, M., Vomlel, J.: Bayesian network models for adaptive testing. In: Proceedings
of the Twelfth UAI Bayesian Modeling Applications Workshop, pp. 24–33. CEUR-
WS.org, Amsterdam (2015)
Plajner, M., Vomlel, J.: Probabilistic models for computerized adaptive testing: exper-
iments. Technical report, arXiv:1601.07929 (2016a)
Plajner, M., Vomlel, J.: Student skill models in adaptive testing. In: Proceedings of the
Eighth International Conference on Probabilistic Graphical Models, pp. 403–414.
JMLR.org (2016b)
Restiﬁcar, A.C., Dietterich, T.G.: Exploiting monotonicity via logistic regression in
Bayesian network learning. Technical report, Oregon State University, Corvallis, OR
(2013)
van der Gaag, L., Bodlaender, H.L., Feelders, A.J.: Monotonicity in Bayesian networks.
In: 20th Conference on Uncertainty in Artiﬁcial Intelligence (UAI 2004), pp. 569–576
(2004)
van der Linden, W.J., Glas, C.A.W.: Computerized Adaptive Testing: Theory and
Practice, vol. 13. Kluwer Academic Publishers, Dordrecht (2000)
Wellman, M.P.: Fundamental concepts of qualitative probabilistic networks. Artif.
Intell. 44(3), 257–303 (1990)

Expert Opinion Extraction
from a Biomedical Database
Ahmed Samet1(B), Thomas Guyet1, Benjamin Negrevergne3, Tien-Tuan Dao2,
Tuan Nha Hoang2, and Marie Christine Ho Ba Tho2
1 Universit´e Rennes 1/IRISA-UMR6074, Rennes, France
{ahmed.samet,thomas.guyet}@irisa.fr
2 Sorbonne University, Universit´e de technologie de Compi`egne CNRS,
UMR 7338 Biomechanics and Bioengineering, Compi`egne, France
{tien-tuan.dao,tuannha.hoang,mariechristinehoba.tho}@utc.fr
3 LAMSADE, Universit´e Paris-Dauphine, Paris, France
benjamin.negrevergne@dauphine.fr
Abstract. In this paper, we tackle the problem of extracting frequent
opinions from uncertain databases. We introduce the foundation of an
opinion mining approach with the deﬁnition of pattern and support mea-
sure. The support measure is derived from the commitment deﬁnition. A
new algorithm called OpMiner that extracts the set of frequent opinions
modelled as a mass functions is detailed. Finally, we apply our approach
on a real-world biomedical database that stores opinions of experts to
evaluate the reliability level of biomedical data. Performance analysis
showed a better quality patterns for our proposed model in comparison
with literature-based methods.
Keywords: Uncertain database · Data mining · Opinion · OpMiner
1
Introduction
Data uncertainty has challenged nearly all types of data mining tasks, creating
a need for uncertain data mining. Uncertainty is inherent in data from many
diﬀerent domains, including social networks and cheminformatics [1]. The prob-
lem of pattern mining, or ﬁnding frequent patterns in data, has been extensively
studied in deterministic databases [2] since its introduction by Aggrawal et al.
[3] as well as in the ﬁeld of uncertain databases [4]. The uncertain databases have
brought more ﬂexibility in data representation [5]. For instance, mass function
of evidence theory are comparable to expert’s opinion since it details answer to
a question over a set of response elements. It also allows to model someone’s
degree of belief regarding an asked question. Therefore databases storing mass
functions (commonly called evidential databases), are seen as a data support for
expert opinions and imperfect data.
What classical approaches have in common is that they extract answers.
They extract answer elements (fragment of the expert answer) as long they are
c
⃝Springer International Publishing AG 2017
A. Antonucci et al. (Eds.): ECSQARU 2017, LNAI 10369, pp. 135–145, 2017.
DOI: 10.1007/978-3-319-61581-3 13

136
A. Samet et al.
redundant in the database. Therefore, the extracted information is limited and
does not describe what experts have expressed. To illustrate this point, let us
consider the example of several practitioners that have been asked to give their
opinion regarding new treatments for a disease. We intend to extract knowledge
from a set of experts’ opinions asked about their evaluations of these treatments.
Each practitioner gives his opinion regarding the eﬃciency of a treatment j
among a set of evaluation possibilities {Goodj, Averagej, Badj}.
Table 1. Example of uncertain database.
Practitioner Treatment 1
Treatment 2
P1
Bad0.3
1
Average0.7
1
Good1
2
P2
{Average1 ∪Bad1}1 Good0.5
2
Average0.5
2
The ﬁrst practitioner hesitates between bad and average evaluation with a
higher conﬁdence to average. The second practitioner can not decide whether
the treatment is average or bad. A classical pattern mining approach as [6]
would extract answers as pattern. For instance, for a threshold of 0.7,
{Treatment1 = Average1} is a frequent pattern1. Looking at Table 1, the pat-
tern {Treatment1 = Average1} is a fraction of the opinion expressed by the
practitioner P1 and therefore the extracted information is not complete. Unfor-
tunately, this type of output is generated by uncertain mining approaches [7–9].
An opinion pattern would be Treatment1 = Bad0.3 Average0.7 and is consid-
ered as frequent since it does not contradict with the opinion of P2. In this work,
we intend to shake this notion of answer pattern of uncertain databases and we
aim to evaluate a pattern as a whole opinion.
Methodologically, we build the foundation of an opinion mining approach. We
develop our mining approach on evidential databases. Evidential databases oﬀer
more knowledge representation with its simple formalism [10]. They bring more
ﬂexibility thanks to mass functions. In fact, it is possible to model all level of
uncertainty from absolute certainty to total ignorance. From applicative point of
view, we experiment our OpMiner algorithm on a real-world biomedical expert
database. The results show the quality of retrieved patterns comparatively to
classical ones. In addition, our algorithm shows interesting performances.
2
Preliminaries
The evidence theory or Dempster-Shafer theory [11,12] proposes a robust for-
malism for modeling uncertainty. The evidence theory is based on several funda-
mentals such as the Basic Belief Assignment (BBA). A BBA m is the mapping
from elements of the power set 2Θ onto [0, 1]:
1 A pattern is called frequent if its computed support (i.e. frequency in the database)
is higher than or equal to a ﬁxed threshold set by an expert.

Expert Opinion Extraction from a Biomedical Database
137
m : 2Θ −→[0, 1]
where Θ is the frame of discernment. It is the set of possible answers for a
addressed problem and is composed of N exhaustive and exclusive hypotheses:
Θ = {H1, H2, ..., HN}.
A BBA m is constrained by:

A⊆Θ m(A) = 1
m(∅) = 0
.
(1)
Each subset X of 2Θ fulﬁlling m(X) > 0 is called focal element. Constrain-
ing m(∅) = 0 is the normalized form of a BBA and this corresponds to a
closed-world assumption, while allowing m(∅) > 0 corresponds to an open world
assumption [13].
Dubois and Prade [14] have made three proposals to order BBAs. Let m1
and m2 be two BBA’s on Θ. The statement that m1 is at least as committed as
m2 is denoted m1 ⊑m2. Three types of ordering have been proposed:
– pl-ordering (plausibility ordering) if Pl1(A) ≤Pl2(A) for all A ⊆Θ, we write
m1 ⊑pl m2,
– q-ordering (communality ordering) if q1(A) ≤q2(A) for all A ⊆Θ, we write
m1 ⊑q m2,
– s-ordering (specialization ordering) if m1 is a specialization of m2, we write
m1 ⊑s m2,
In this paper, we develop our approach using the plausibility based commitment.
The plausibility function Pl(.) is deﬁned as follows:
Pl(A) =

B∩A̸=∅
m(B).
(2)
Among all belief functions on Θ, the least committed belief function is the vac-
uous belief function (i.e. m(Θ) = 1).
Finally, it is possible to store imperfect data modelled as BBAs into a data-
base. This kind of database is commonly called evidential database. Formally,
an evidential database is a triplet EDB = (AEDB, O, REDB). AEDB is a set
of attributes and O is a set of d transactions (i.e., rows). Each column Aj
(1 ≤j ≤n) has a domain Θj of discrete values. REDB expresses the relationship
between the ith transaction (i.e., row Ti) and the jth column (i.e., attribute Aj)
by a normalized BBA mij : 2Θj →[0, 1].
Example 1. We intend to extract knowledge from a set of experts’ opinions asked
about their evaluations of several treatment eﬃciencies for a disease. Each prac-
titioner gives his opinion regarding a treatment j from a set of evaluation pos-
sibilities Θj = {Goodj, Averagej, Badj} (see Table 2).

138
A. Samet et al.
3
Extraction Opinion Patterns over Evidential Databases
In the following subsection, we study the plausibility based commitment relation
between two BBAs in the evidence theory.
Table 2. Example of evidential database
Practitioner Treatment 1
Treatment 2
P1
m11(Good1) = 0.7 m12(Good2) = 0.4
m11(Θ1) = 0.3
m12(Average2) = 0.2
m12(Θ2) = 0.4
P2
m21(Good1) = 0.6 m22(Good2) = 0.3
m21(Θ1) = 0.4
m22(Θ2) = 0.7
3.1
Plausibility Based Commitment Measure
Let us consider two BBAs m1 and m2 such as m1 ⊑pl m2. We intend to develop
a measure to estimate the commitment level of m2 wrt m1.
Deﬁnition 1. Given the plausibility functions Pl1 and Pl2 of two BBAs m1
and m2, the plausibility PL12(.) expresses the diﬀerence between two plausibility
functions and is computed as follows:
PL12(A) = Pl1(A) −Pl2(A).
(3)
Deﬁnition 2. Assuming two BBAs m1 and m2. Assuming that C(·, ·) is a com-
mitment measure between two BBAs. It is computed as follows,
C : 2Θ × 2Θ →[0, 1]
(m2, m1) →
⎧
⎨
⎩
1 −||PL21|| = 1 −
 
A⊆Θ
PL21(A)2 if m1 ⊑pl m2
0
Otherwise
(4)
Property 1. Assuming two BBAs m1 and m2 such as m2 ⊑pl m1, Eq. 4 veriﬁes
the following properties:
– C(m2, m1) ≥0 (separation axiom);
– C(m2, m1) = 1 ⇔m1 = m2 (identity of indiscernible);
– C(m2, m1) = C(m1, m2) (symmetry);
– C(m2, m3) ≤C(m2, m1) + C(m1, m3) (triangle inequality).

Expert Opinion Extraction from a Biomedical Database
139
3.2
Mining Opinions over Evidential Databases
In an evidential database, an item corresponds to a BBA. An itemset (so called
pattern) corresponds to a conjunction of several BBAs having diﬀerent domains
X = {mij ∈MΘ}. We recall that i is the transaction id and j is the attribute
id. MΘ denotes the set of all BBAs in EDB.
Let us consider an evidential database EDB and the itemset X made of a set
of BBAs. The frequency of appearance of an item x = mi′j in a transaction Ti
can be computed as follows:
SupTi : MΘj
i
→[0, 1]
x →C(x, mij) where mij ∈MΘj
i .
(5)
MΘj
i
is the set of BBAs in the row Ti of the attribute j. As illustrated above,
the SupTi is a measure that computes whether x is in the row Ti. Even if the
BBA is not in the studied row, we analyse if there is a BBA that generalizes it.
Then, the support of an itemset X over the transaction Ti is computed as
SupTi(X) =
	
x∈X
SupTi(x).
(6)
Therefore, the support of mij over the database is computed as,
SupEDB(X) = 1
d
d

i=1
SupTi(X).
(7)
Property 2. Assuming an itemset X, the measure of support fulﬁls the anti-
monotony property, i.e.,
SupEDB(X) ≤SupEDB(X ∪mij).
(8)
Proof. Assuming an evidential database EDB, let us consider two evidential
itemsets X and X ∪mij. We aim at proving this relation SupEDB(X) ≤
SupEDB(X ∪mij):
SupTi(X ∪mij) =

mi′j′∈X∪mij
SupTi(mi′j′)
SupTi(X ∪mij) =

mi′j′∈X
SupTi(mi′j′) × SupTi(mij)
SupTi(X ∪mij) ≤SupTi(X)
since
SupTi(mij) ∈[0, 1]
then
SupEDB(X ∪mij) ≤SupEDB(X).
Example 2. Assuming
the
evidential
database
given
in
Example
1.
For
a
minsup
=
0.7,
the
pattern
{m11, m12}
have
a
support
of
C(m11,m11)×C(m12,m12)+C(m11,m21)×C(m12,m22)
2
= 0.765 and is then considered as
frequent. Semantically, having a relatively good opinion on treatment 1 (i.e. m11)
and hesitant one regarding the treatment 2 (i.e. m12) is redundant over 76.5% of

140
A. Samet et al.
asked practitioners. Moreover, comparatively to patterns of an evidential data
mining algorithm, our output is more informative. In fact, a classical algorithm
would provide the frequent pattern {Good1, Good2} which contain less details
than {m11, m12}.
In this section, we develop a new level-wise algorithm to mine opinions over
evidential databases. OpMiner, shown in Algorithm 1 generates all BBAs of
size one by favouring the most speciﬁc ones. Formally, for all mij, mi′j ∈MΘ,
we retain mij as long as mij ⊑pl mi′j. Thus, function candidate gen reduces
the set of frequent patterns to the set of the more speciﬁc ones. The other less
speciﬁc BBAs are used to compute the support as described in Eq. 7. In addition,
this selection aims at reducing time computing since candidate generation and
support computing depends on the set of items (i.e. pattern with a single BBA).
The patterns that have a support lower than the minsup are pruned in line 5.
The process stops until no candidate is left.
4
Experiments: Data Reliability Assessment Using
Biomedical Expert Opinion
The investigation of the eﬀects of muscles morphology and mechanics on motion,
and the risks of injury, has been at the core of many studies, sometimes with
conﬂicting results. Often diﬀerent measurement methods have been used, mak-
ing comparison of the results and drawing sound conclusions impossible [15].
In this section, we aim at studying the opinion of several experts on col-
lected measurement data. To do so, we collected data by a systematic review
process of 20 data sources (papers) from reliable search engines (PubMed and
ScienceDirect). Data is described over 7 parameters regarding muscle mor-
phology, mechanics and motion analysis. Four main questions were asked to
experts about measuring technique (Q1), experimental protocol (Q2), number
of samples (Q3) and range of values (Q4). An expert opinion database was
built from an international panel of 20 contacted experts with diﬀerent exper-
tise (medical imaging, motion analysis). Five evaluation degrees were possible
{V ery high, High, Moderate, Low, V ery low}. Each given degree was associated
to a conﬁdence value. In this study, as a ﬁrst goal, we aim at ﬁnding frequent
opinions in the database. Frequent opinions show correlation between opinions.
The second goal is to evaluate the reliability of sources. To do so, the algorithm
selects from the frequent set of patterns those that express a positive opinion
regarding the same source.
Table 3 shows a small set of recorded answers from experts. For instance,
row 1 details the opinions of expert 1 regarding the source S1 (data measures
retrieved from a source). The expert expresses his opinion over 4 questions. The
column Confi shows the conﬁdence of the expert regarding his given opinion for
the question Qi.
The evidential database is constructed by using the evaluation of the experts
and their conﬁdences. First, the evaluation of the expert is used to model a

Expert Opinion Extraction from a Biomedical Database
141
Algorithm 1. OpMiner algorithm
Require: EDB, minsup, EDBpl, maxlen
Ensure: EIFF
1: EIFF, Items ←∅, size ←1
2: Items ←candidate gen(EDB, EIFF, Items)
3: While (candidate ̸= ∅and size ≤maxlen)
4: for all pat ∈candidate do
5:
if Support(pat, minsup, EDBpl, Size EDB)≥minsup then
6:
EIFF ←EIFF ∪pat
7: size ←size + 1
8: candidate ←candidate gen(EDB, EIFF, Items)
9: End While
10: function Support(pat, minsup, EDBpl,d)
11:
Sup ←0
12:
for i=1 to d do
13:
for all plij ∈Mi do
14:
pl ←mtopl(pat)\\ computes the plausibility out of a BBA
15:
if plij ≥pl then
16:
SupT rans ←SupT rans × 1 −||plij −pl||
17:
Sup ←Sup + SupT rans
18:
return SupI
d
19: function candidate gen(EDB, EIFF, Items)
20:
if size(Items) = 0 then
21:
for all BBA ∈EDB do
22:
while Items ̸= ∅and BBA ̸⊑pl it do
23:
if Items = ∅then
24:
Add(BBA, Item)
25:
else
26:
Replace(BBA, it, Item)
27:
return Items
28:
else
29:
for all BBA ∈EIFF do
30:
for all it ∈Items do
31:
if !same attribute(it, BBA) then
32:
Cand ←Cand ∪{BBA ∪it}
33:
return Cand
certain BBA2. Then, the conﬁdence is used to integrate uncertainty into the
BBA. To do so, the conﬁdence is used as reliability measure and part of the
mass initially given to the evaluation is then transferred to the ignorance mass.
Formally, the discounting of a mass function m can be written as follows

mα(B) = (1 −α) × m(B)
∀B ⊆Θ
mα(Θ) = (1 −α) × m(Θ) + α.
(9)
2 A BBA is called a certain BBA when it has one focal element, which is a singleton.
It is representative of perfect knowledge and the absolute certainty.

142
A. Samet et al.
Table 3. Sample of the expert opinion data.
Expert
S1
Q1 Conf1 Q2 Conf2 Q3 Conf3 Q4 Conf4
1
Hig
Hig Hig
Hig Mo
Hig Hig
Mo
2
Hig
Ver Mo
Ver Hig
Ver Mo
Ver
3
Hig
Hig Hig
Hig Hig
Hig Hig
Hig
4
Hig
Hig Mo
Hig Hig
Hig Mo
Hig
5
Lo
Ver Lo
Ver Mo
Ver Mo
Ver
6
Mo
Mo Mo
Mo Lo
Hig Lo
Hig
7
Mo
Ver Mo
Ver Hig
Ver Mo
Ver
8
Mo
Ver Lo
Hig Hig
Ver Lo
Ver
9
Mo
Ver Mo
Hig Hig
Ver Mo
Hig
10
Mo
Hig Mo
Hig Mo
Hig Mo
Hig
11
Ver
Ver Ver
Ver Ver
Ver Ver
Ver
Very high Very high
conﬁdence
High
High con-
ﬁdence
Moderate Moderate
conﬁdence
Low
Low conﬁ-
dence
Very low
Very
low
conﬁdence
α is the reliability factor and is in the set {0.8, 0.6, 0.4, 0.2, 0}. The higher α is
the more mass is transferred to m(Θ).
In the following, we compare a classical evidential pattern mining approaches
such as EDMA [16] and U-Apriori [6] with the output of OpMiner. To do so, we
compare these three algorithms in terms of number of extracted patterns and
computational time. Figure 1 illustrates the number of extracted patterns with
regards to the threshold minsup. It is evident that the pattern mining approach
EDMA ﬁnds the highest number of patterns for all ﬁxed minsup comparatively
to probabilistic approach approach and OpMiner. In fact, EDMA computes fre-
quent patterns from a set of 28 × 25 items (i.e. sum of the size of all superset
of attributes). Therefore, EDMA extracts more patterns than the probabilis-
tic U-Apriori that mines from a set of 28 × 5 items (i.e. sum of the size of all
frames of discernment). OpMiner is has a diﬀerent approach since an item is a
BBA and therefore the number of items is the number of BBAs in the database
(i.e., 28 × 11). In addition, this number is reduced by selecting, at ﬁrst, only the
more committed BBAs. As a result OpMiner is more eﬃcient than the two other
approaches since it generates less candidates (see Fig. 2). OpMiner not only gen-
erates less frequent patterns but more informative ones since it regroups several
information in a single item. Even if in our application, all treated BBAs are
simple3, OpMiner works perfectly on normal BBAs4.
In order to test the quality of the patterns, we oppose the best pattern of
EDMA relatively to the ﬁrst four attributes shown in Table 4 to the best one
provided by OpMiner. In fact, it is possible to select from the set of frequent pat-
terns those having items of the four attributes. These patterns show the answer
(opinion for OpMiner) that the majority of the experts have expressed. These
patterns are representative of the quality of source S1 measures. As it is show in
3 A BBA is said to be simple if it has at most two focal sets and, if it has two, Θ is
one of those.
4 A BBA is said to be normal if ∅is not a focal set.

Expert Opinion Extraction from a Biomedical Database
143
0.15
0.3
0.5
101
103
105
minsup
# Frequent patterns
OpMiner
U-Apriori [6]
EDMA [16]
Fig. 1. Number of retrieved frequent
patterns from the database.
0.15
0.3
0.5
10−2
101
104
minsup
Time (s)
OpMiner
U-Apriori [6]
EDMA [16]
Fig. 2. Number of retrieved valid asso-
ciation rules from the database.
Table 4, the construction of both patterns is not the same. EDMA’s pattern is
constructed from focal elements in contrary of OpMiner that contains BBAs. In
addition, the interpretation of both patterns is diﬀerent. EDMA’s pattern shows
a hesitation between high and moderate as an answer trend. Therefore, from
this point, making an evaluation of source S1 is not straightforward. OpMiner
pattern has a diﬀerent meaning. It gives for each asked question the most shared
opinion (i.e. BBA). It means that, for question 1, 2 and 4 the answer is moderate
with high or very high conﬁdence. For question 4, the trend is a high evaluation
with a very high conﬁdence. As a result, with an overall moderate evaluation of
its measure, it is possible to conclude that source S1 is moderately reliable.
Table 4. EDMA’s pattern vs. OpMiner’s pattern
EDMA S1 best pattern
OpMiner S1 best pattern
Pattern
{Q1 = Hig or Mod, Q2 = Hig or Mod,
Q3 = Hig or Mod, Q4 = Hig or Mod}
{m1(Mo1) = 1,

m2(Mo2) = 0.8
m2(Θ2) = 0.2
m3(Hig3) = 1,

m4(Mo4) = 0.8
m4(Θ4) = 0.2
}
5
Conclusion
In this paper, we introduced a new approach for mining opinion patterns from
uncertain database. The uncertainty and the imprecision of the data are mod-
elled with the evidence theory. The extraction is based on new anti-monotonic
measures of support derived from the commitment relation. A mining algorithm
OpMiner is then applied to retrieve frequent opinions patterns a from the data-
base. The results on a real-world database shows more informative extracted

144
A. Samet et al.
patterns than literature-based approaches. In future work, we will be interested
in reﬁning the inclusion and support measure using the specialization matrix
of Smets [17]. Furthermore, the performance of OpMiner algorithm could be
improved by adding speciﬁc heuristics such as the decremental pruning [7].
Acknowledgements. This work is a part of the PEPS project funded by the French
national agency for medicines and health products safety (ANSM), and of the SePaDec
project funded by Region Bretagne.
References
1. Samet, A., Dao, T.T.: Mining over a reliable evidential database: application on
amphiphilic chemical database. In: Proceeding of 14th International Conference on
Machine Learning and Applications, Miami, Florida, pp. 1257–1262 (2015)
2. Aggarwal, C.C., Han, J. (eds.): Frequent Pattern Mining. Springer, Cham (2014)
3. Agrawal, R., Srikant, R.: Fast algorithm for mining association rules. In: Proceed-
ings of International Conference on Very Large DataBases, VLDB, Santiago de
Chile, Chile, pp. 487–499 (1994)
4. Aggarwal, C.C., Li, Y., Wang, J., Wang, J.: Frequent pattern mining with uncer-
tain data. In: Proceedings of the 15th ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining, Paris, France, pp. 29–38 (2009)
5. Bell, D.A., Guan, J., Lee, S.K.: Generalized union and project operations for pool-
ing uncertain and imprecise information. Data Knowl. Eng. 18(2), 89–117 (1996)
6. Chui, C.K., Kao, B., Hung, E.: Mining frequent itemsets from uncertain data.
In: Proceedings of the 11th Paciﬁc-Asia Conference on Advances in Knowledge
Discovery and Data Mining, Nanjing, China, pp. 47–58 (2007)
7. Aggarwal, C.C.: Managing and Mining Uncertain Data, vol. 3. Springer, New York
(2010)
8. Hewawasam, K.R., Premaratne, K., Shyu, M.L.: Rule mining and classiﬁcation in
a situation assessment application: a belief-theoretic approach for handling data
imperfections. IEEE Trans. Syst. Man Cybern. Part B 37(6), 1446–1459 (2007)
9. Chen, Y., Weng, C.: Mining association rules from imprecise ordinal data. Fuzzy
Set Syst. 159(4), 460–474 (2008)
10. Bach Tobji, M.A., Ben Yaghlane, B., Mellouli, K.: Incremental maintenance of
frequent itemsets in evidential databases. In: Proceedings of the 10th European
Conference on Symbolic and Quantitative Approaches to Reasoning with Uncer-
tainty, Verona, Italy, pp. 457–468 (2009)
11. Dempster, A.: Upper and lower probabilities induced by multivalued mapping.
AMS 38, 325–339 (1967)
12. Shafer, G.: A Mathematical Theory of Evidence. Princeton University Press,
Princeton (1976)
13. Smets, P., Kennes, R.: The transferable belief model. Artif. Intell. 66(2), 191–234
(1994)
14. Dubois, D., Prade, H.: The principle of minimum speciﬁcity as a basis for eviden-
tial reasoning. In: International Conference on Information Processing and Man-
agement of Uncertainty in Knowledge-Based Systems, Paris, France, pp. 75–84
(1986)

Expert Opinion Extraction from a Biomedical Database
145
15. Hoang, T.N., Dao, T.T., Ho Ba Tho, M.C.: Clustering of children with cerebral
palsy with prior biomechanical knowledge fused from multiple data sources. In:
Proceedings of 5th International Symposium Integrated Uncertainty in Knowledge
Modelling and Decision Making, Da Nang, Vietnam, pp. 359–370 (2016)
16. Samet, A., Lef`evre, E., Yahia, S.B.: Evidential data mining: precise support and
conﬁdence. J. Intell. Inf. Syst. 47(1), 135–163 (2016)
17. Smets, P.: The application of the matrix calculus to belief functions. Int. J. Approx-
imate Reasoning 31(1–2), 1–30 (2002)

Solving Trajectory Optimization Problems
by Inﬂuence Diagrams
Jiˇr´ı Vomlel1,2(B) and V´aclav Kratochv´ıl1,2
1 Institute of Information Theory and Automation, Czech Academy of Sciences,
Pod Vod´arenskou Vˇeˇz´ı 4, 182 08 Prague 8, Czechia
vomlel@utia.cas.cz
2 Faculty of Management, University of Economics,
Prague Jaroˇsovsk´a 1117/II, 377 01 Jindˇrich˚uv Hradec, Czechia
Abstract. Inﬂuence diagrams are decision-theoretic extensions of Bayes-
ian networks. In this paper we show how inﬂuence diagrams can be used
to solve trajectory optimization problems. These problems are tradition-
ally solved by methods of optimal control theory but inﬂuence diagrams
oﬀer an alternative that brings beneﬁts over the traditional approaches.
We describe how a trajectory optimization problem can be represented as
an inﬂuence diagram. We illustrate our approach on two well-known trajec-
tory optimization problems – the Brachistochrone Problem and the God-
dard Problem. We present results of numerical experiments on these two
problems, compare inﬂuence diagrams with optimal control methods, and
discuss the beneﬁts of inﬂuence diagrams.
Keywords: Inﬂuence diagrams · Probabilistic graphical models ·
Optimal control theory · Brachistochrone problem · Goddard problem
1
Introduction
Inﬂuence diagrams (IDs) were originally proposed by Howard and Matheson
(1981). They extend Bayesian network models (Pearl 1988) by utility and deci-
sion nodes. They can be used to solve optimal decision problems. For a detailed
introduction to inﬂuence diagrams, see, for example, Jensen (2001). In the regu-
lar inﬂuence diagrams proposed in 80’s it was required that (a) a total ordering
of decision nodes that speciﬁes the order in which the decisions are made must
be speciﬁed and (b) the total utility is the sum of utility values of all utility
nodes in the inﬂuence diagram. In this paper we will see that both requirements
are naturally satisﬁed for many trajectory optimization problems.
IDs have been applied to diverse decision problems. Kratochv´ıl and Vomlel
(2016) applied IDs to the speed proﬁle optimization problem. The experiments
performed on a real problem – the speed control of a Formula 1 race car – revealed
that IDs can provide a good solution of the problem very quickly and that this
This work was supported by the Czech Science Foundation through projects
16-12010S (V. Kratochv´ıl) and 17-08182S (J. Vomlel).
c
⃝Springer International Publishing AG 2017
A. Antonucci et al. (Eds.): ECSQARU 2017, LNAI 10369, pp. 146–155, 2017.
DOI: 10.1007/978-3-319-61581-3 14

Solving Trajectory Optimization Problems by Inﬂuence Diagrams
147
solution can be used as an initial solution for the methods of the optimal control
theory, which signiﬁcantly improves the convergence of these methods.
In this paper we will generalize the approach presented in (Kratochv´ıl and
Vomlel 2016). In Sect. 2 we will describe how IDs can be used to solve trajectory
optimization problems. We consider not only problems where the goal is to ﬁnd
the trajectory but also problems where we want to optimize certain criteria (e.g.,
the total time, the fuel consumption) for a given trajectory. We use the suggested
approach to solve two well-known optimal control problems: the Brachistochrone
problem in Sect. 3 and the Goddard problem in Sect. 4. We conclude the paper
by a discussion in Sect. 5.
2
Inﬂuence Diagrams for Trajectory Optimization
In this section we will describe how one can use IDs to solve a trajectory opti-
mization problem. Next we describe general guidelines for the construction of an
ID for the trajectory optimization. We will illustrate this construction on two
problems in the next sections.
1. Specify the state variables, the control variables, and the utility function.
2. Describe the system dynamics using a system of ordinary diﬀerential equa-
tions (ODEs). Often, the system dynamics is described with respect to time.
In the trajectory optimization it is often more convenient or even necessary
to rewrite the ODEs with respect to the trajectory.
3. Discretize the trajectory to short segments.
4. Find the analytical formula for the state transitions as a function of previous
values of the state and control variables for one segment. If the analytical
solution is not available use approximations by an appropriate method –
candidates are, for example, the Euler method, a Runge-Kutta method, or
an implicit method as the Gauss-Legendre method.
5. If necessary, discretize the state and control variables.
6. If states are discretized and the state transitions lead to states that are
not in the set of state values then use the stochastic approximation of the
state transition by a mixture of two nearest states whose probability is
proportional to their closeness to the computed state value, so that the
expected value (conditioned on previous state and control values) is equal
to the computed state value, see (Kratochv´ıl and Vomlel 2016, Sect. 5.2).
7. Construct the ID with state variables as chance nodes, the control variables
as decision nodes, and a utility node for each segment.
8. Specify the state transitions using conditional probability tables (CPTs).
9. Find and store the optimal policy for each state and control conﬁguration
and for each segment of the trajectory by solving the ID.
10. During the application in a real control problem the optimal policy for the
actual observed values of state variables at each point of the trajectory
is used. In practice, the controlled object often deviates from the optimal
solution. The reason can be a measuring and control imprecision, a bias,
unexpected interventions, etc. Therefore, it is very useful to have the optimal
policy stored for all conﬁgurations of the parents of all decision nodes.

148
J. Vomlel and V. Kratochv´ıl
The additive utility requirement means that the utility function decomposes
additively along the segments of the trajectory. Such utility functions are com-
mon in practice. This condition is satisﬁed, for example, by total time or by the
total fuel consumption. The requirement of the total ordering of the decisions is
also natural for trajectory optimization problems. The decisions at coordinates
closer to the origin are taken before those more distant ones. Another natural
total ordering is the ordering by time elapsed from the beginning.
3
Brachistochrone Problem
Formulated by Johan Bernoulli in 1696, the Brachistochrone Problem is: given
two points ﬁnd a curve connecting them such that a mass point moving along
the curve under the gravity reaches the second point in minimum time. We will
consider this problem as an optimal control problem (Bertsekas 2000, Example
3.4.2). The state variable is the vertical coordinate y and it is a function of the
horizontal coordinate x. The variable u controls the derivative of y:
dy(x)
dx
= u(x).
(1)
It is assumed that the initial speed at the origin is zero. Speed v is deﬁned by the
law of energy conservation – kinetic energy equals to the change of gravitational
potential energy, which results in
v =

−2 · g · y.
(2)
For an inﬁnitesimal segment of length dx with an inﬁnitesimal change dy of
the vertical position y we can write for the speed, which is the derivative of the
position s with respect to time t:
v = ds
dt
=
dy
dt
2
+
dx
dt
2
=
⎛
⎝

1 +
dy
dx
2
⎞
⎠dx
dt .
(3)
By substituting (1) and (2) to (3) we get
dt = ds
v
=

1
√−2 · g · y ·

1 + u2

dx
df=
q (y, u) dx.
(4)
The solution of the Brachistochrone problem is a function y = f(x) that mini-
mizes the total time T necessary to get from the point (0, 0) to the point (a, b),
where a > 0 and b < 0.
3.1
Inﬂuence Diagram for the Brachistochrone Problem
Next, we will illustrate how an ID can be used to ﬁnd an arbitrary precise solution
of the problem. We will discretize the problem and use the following symbols:

Solving Trajectory Optimization Problems by Inﬂuence Diagrams
149
the number of discrete intervals n, the distance discretization step Δx = a
n, the
index of the interval i = 0, 1, . . . , n, x-coordinate xi = i · Δx, y-coordinate yi,
the speed vi, and time to get from xi−1 to xi denoted as ti. The control value
ui deﬁnes the vertical shift: yi+1 = yi + ui. In each segment we will assume that
the path is a line segment1, i.e. for x ∈[xi, xi+1] and for y ∈[yi, yi+1] it holds
y = ui
Δx · x + yi.
(5)
By substituting (5) to (4) and solving the deﬁnite integral

 xi+1
xi
q (y, u) dx =

 xi+1
xi
q
 ui
Δx · x + yi, ui

dx
(6)
we get the formula for the time spent at the segment [xi, xi+1]:
ti+1 =
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
Δx
√−2 · g · yi
if ui = 0
−
2
g ·
(Δx)2 + u2
i
ui

· (√−yi −√−ui −yi)
otherwise.
(7)
The goal is to ﬁnd a control strategy u = (u0, . . . , un−1), ui ∈R, i =
0, 1 . . . , n −1 so that we get from the initial point (x0, y0) to the terminal point
(xn, yn) minimizing the total timen
i=1 ti and satisfying the state constraints
yi ≤y0 for i = 1, . . . , n.
Yi
Yi+1
ti+1
Ui
Ui+1
Fig. 1. One segment of the ID for the Brachistochrone Problem
1 This is an approximation only, but the smaller distance discretization step the smaller
the approximation error.

150
J. Vomlel and V. Kratochv´ıl
0
2
4
6
8
10
−5
−4
−3
−2
−1
0
x
y
Fig. 2. Comparison of the optimal solution with the ID solution.
The structure of a segment of the ID for the discrete version of the Brachis-
tochrone Problem is presented in Fig. 1. The state transition CPT is determin-
istic and deﬁned as:
P(Yi+1 = yi+1|Ui = ui, Yi = yi) =

1
if yi+1 = yi + ui
0
otherwise.
(8)
The utility function for node ti+1 is deﬁned by formula (7).
3.2
Experimental Results
The solution of the Brachistochrone Problem is known – it is a part of a cycloid,
which can be speciﬁed by two functions of a parameter ϕ ∈[0, M], M ≤2π:
x = K
2 (ϕ + sin ϕ) + L, y = −K
2 (1 −cos ϕ) .
(9)
K, L, M are speciﬁed so that the cycloid goes through the points (0, 0) and (a, b).
In Fig. 2 we compare the optimal trajectory (full red line) with the solution
found by the ID (circles connected by lines) for Δx = 0.25, Δy = 0.1 and
(a, b) = (10, −5). We can see that the solution found by the ID approximates
well the optimal solution. The diﬀerence between the optimal trajectory and the
ID solution can be reduced by decreasing the lengths of the discretization steps
Δx and Δy. More details about the experiments and the R code used for the
experiments can be found in our research report (Vomlel 2017).
4
Goddard Problem
Formulated by Robert H. Goddard, see (Goddard 1919), the problem is to estab-
lish the optimal thrust proﬁle for a rocket ascending vertically from the Earth’s
surface to achieve a given altitude with a given speed and pay load and with the
minimum fuel expenditure. The aerodynamic drag and the gravitation vary with

Solving Trajectory Optimization Problems by Inﬂuence Diagrams
151
the altitude. We assume a bounded thrust. The problem has become a bench-
mark in the optimal control theory due to a characteristic singular arc behavior
in connection with a relatively simple model structure.
In this paper we consider the normalized Goddard Problem. For the deriva-
tion of the normalized version and more details about the approximation meth-
ods see our research report (Vomlel and Kratochv´ıl 2017). We specify the God-
dard Problem as an optimal control problem. The movement of the rocket is
described by ordinary diﬀerential equations (ODEs). We describe the system
dynamics with respect to the altitude h measured as the distance from the
Earth’s center. The rocket’s mass m is composed from the pay load and the fuel,
the latter is burnt during the rocket ascent. The speed is denoted by v.
The control variable u controls the engine thrust, which is the derivative of
the rocket’s mass m with respect to time t multiplied by the jet speed c, i.e.,
u = c · dm
dt
=
c · dm
dh · dh
dt
=
dm
dh · c · v.
(10)
The derivatives of mass m and speed v with respect to h are deﬁned using
functions of g and f as it follows:
dm
dh = g(u, v)
df=
u
c · v
(11)
dv
dh = f(h, m, u, v)
df= −
u
m · v −v · s · cD
2 · m
· ρ0 · exp (β · (1 −h)) −
1
v · h2 ,
(12)
where s is the cross-section area of the rocket, cD is the drag constant, ρ0 is the
density of the air at the Earth’s surface, and β is a dimensionless constant.
We will use model parameter values presented in (Tsiotras and Kelley 1991)
and (Seywald and Cliﬀ1992). The aerodynamic data and the rocket’s parameters
originate from (Zlatskiy and Kiforenko 1983) and correspond roughly to the
Soviet SA-2 surface-to-air missile, NATO code-named Guideline. The control
will be restricted to u ∈[−3.5, 0]. It is assumed that the rocket is initially at rest
at the surface of the Earth and that its fuel mass is 40% of the rocket total mass.
The nondimensionalized values of these constants and the initial and terminal
values are:
β = 500, s · ρ0 = 12400, cD = 0.05, c = 0.5,
h0 = 1, hT = 1.01, m0 = 1, mT ≥0.6 · m0 = 0.6, v0 = 0.
4.1
The Inﬂuence Diagram for the Goddard Problem
In each segment i of the ID there are (a) two state variables – a speed variable
Vi and a mass variable Mi, (b) one decision variable Ui controlling the thrust of
the rocket engine, (c) one utility node fi representing the fuel consumption in
the segment. The structure of one segment of the ID for the discrete version of
the Goddard Problem is presented in Fig. 3.
We discretize the trajectory to segments of length Δh with a constant control.
In each segment a solution of the system of two ODEs (11) and (12) is found by an

152
J. Vomlel and V. Kratochv´ıl
Ui
fi+1
Ui+1
Mi
Mi+1
Vi
Vi+1
Fig. 3. One segment of the ID for the Goddard Problem
ODE approximation method. The solution provides values of the mass m(h+Δh)
and speed v(h+Δh) at the end of the segment. ODE approximation methods can
be used, e.g. the Euler, Runge–Kutta, and Gauss–Legendre methods. See (Vomlel
and Kratochv´ıl 2017) for a derivation of these methods for the Goddard Problem.
The computed mass and speed values will not lay in the discrete set of values of
these variables. Therefore we will approximate the state transformations by non-
deterministic CPTs P(Vi+1|Ui, Vi, Mi) and P(Mi+1|Ui, Vi, Mi) as it is described
in (Kratochv´ıl and Vomlel 2016, Sect. 5.2).
4.2
Experimental Results
In Fig. 4 we compare the control, speed, and mass proﬁles of the optimal solution
found by Bocop2 (Team Commands, Inria Saclay 2016) with solutions found by
IDs with diﬀerent discretizations and diﬀerent approximation methods. It is
known (Miele 1963) that the optimal solution consists of three sub-arcs: (a) a
maximum-thrust sub-arc, (b) a variable-thrust sub-arc, and (c) a coasting sub-
arc, i.e., a sub-arc with the zero thrust.
For the solutions found by IDs we use the following name schema v.u.m.M.h
composed from the parameters used in the experiments:
– v ... the number of states of the speed variables,
2 Bocop package implements a local optimization method. The optimal control prob-
lem is approximated by a nonlinear programming (NLP) problem using a time dis-
cretization. The NLP problem is solved by Ipopt, using sparse exact derivatives
computed by ADOL-C.

Solving Trajectory Optimization Problems by Inﬂuence Diagrams
153
1.000
1.002
1.004
1.006
1.008
1.010
0.0
0.2
0.4
0.6
0.8
1.0
Distance to the Earth's center [in multiples of Earth's radius]
Thrust control
Bocop optimal
120.20.60.E.5e−05
120.20.60.G.5e−05
120.20.60.RK.5e−05
1.000
1.002
1.004
1.006
1.008
1.010
0.00
0.02
0.04
0.06
0.08
0.10
Distance to the Earth's center [in multiples of Earth's radius]
Rocket speed
Bocop optimal
120.20.60.E.5e−05
120.20.60.G.5e−05
120.20.60.RK.5e−05
1.000
1.002
1.004
1.006
1.008
1.010
0.6
0.7
0.8
0.9
1.0
Distance to the Earth's center [in multiples of Earth's radius]
Rocket mass
Bocop optimal
120.20.60.E.5e−05
120.20.60.G.5e−05
120.20.60.RK.5e−05
Fig. 4. Comparisons of the optimal solution with ID solutions.
– u ... the number of states of the control variables,
– m ... the number of states of the mass variables,
– M ... the discretization method for solving ODEs (E is the Euler method, G
the Gauss–Legendre method, and RK the Runge–Kutta RK4 method), and
– h ... the length of the trajectory segment.

154
J. Vomlel and V. Kratochv´ıl
By looking at Fig. 4 we can conclude that the Euler method best approxi-
mates the optimal control and it suﬀers from smaller oscillations of the control
than other methods. The control strategy found by Runge-Kutta and the Gauss-
Legendre methods have larger oscillations. However, the speed and the mass
proﬁles are similar for all methods and they are close to the optimal proﬁles
found by BOCOP3.
The quality of the solution is inﬂuenced by the number of states of speed,
control, and mass variables. We had to ﬁnd a proper balance between these
parameters to avoid large oscillations. This issue deserves a further study to
allow the application of IDs to problems where no optimal solution is known.
5
Conclusions and Future Work
We have described how IDs can be used to solve trajectory optimization prob-
lems. We applied the suggested approach to two trajectory optimization prob-
lems. The ID solution methods were tailored for these problems and can be con-
sidered a special case of dynamic programming (Bellman 1957). The numerical
experiments reveal that the solutions found by IDs approximates well the optimal
solution and the quality of the approximation improves with ﬁner discretizations.
It is important that IDs work well also in problems where the optimal strategy
is more complex than a simple bang-bang strategy4.
The trajectory optimization problems are traditionally solved by methods of
the optimal control theory but IDs oﬀer an alternative that can bring several
beneﬁts over the traditional approaches. IDs can incorporate uncertainty about
the state transitions into the model. For each decision node in an ID the optimal
decision is computed for all conﬁgurations of its parents. This is very handy in the
situations where the controlled objects deviates for some reason from the optimal
trajectory. The new optimal trajectory is thus available without any delay. In
noisy environments or in environments with interactions with other objects the
imposed deviations from the optimal trajectory can be quite common.
For many control problems it would be natural to use continuous IDs. Unfor-
tunately, exact ID solution methods are available only for special cases that
cannot be used in the problems studied in this paper. We leave a deeper study
of applications of continuous IDs to trajectory optimization for future research.
3 The initial mass of the rocket is the same for all methods but in the third plot of
Fig. 4 we can see that the terminal mass slightly diﬀers. The lowest fuel consumption
is observed in case of RK method but we should conclude from that the RK method
is optimal but rather that it has the largest approximation error.
4 A bang-bang strategy is a strategy that consists of extreme values only, e.g. it consists
of the full thrust and the zero thrust phases only. Bang-bang strategies are optimal
solutions of a wide class of optimal control problems.

Solving Trajectory Optimization Problems by Inﬂuence Diagrams
155
References
Bellman, R.: Dynamic Programming. Princeton University Press, Princeton (1957)
Bertsekas, D.P.: Dynamic Programming and Optimal Control, 2nd edn. Athena Scien-
tiﬁc, Belmont (2000)
Goddard, R.H.: A method for reaching extreme altitudes, volume 71(2). Smithsonian
Miscellaneous Collections (1919)
Howard, R.A., Matheson, J.E.: Inﬂuence diagrams. In: Howard, R.A., Matheson, J.E.
(eds.) Readings on the Principles and Applications of Decision Analysis, vol. II, pp.
721–762. Strategic Decisions Group (1981)
Jensen, F.: Bayesian Networks and Decision Graphs. Springer, New York (2001)
Kratochv´ıl, V., Vomlel, J.: Inﬂuence diagrams for speed proﬁle optimization. Int. J.
Approximate Reasoning. (2016, in press). http://dx.doi.org/10.1016/j.ijar.2016.11.
018
Miele, A.: A survey of the problem of optimizing ﬂight paths of aircraft and missiles.
In: Bellman, R. (ed.) Mathematical Optimization Techniques, pp. 3–32. University
of California Press (1963)
Pearl, J.: Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Infer-
ence. Morgan Kaufmann series in representation and reasoning. Morgan Kaufmann,
Burlington (1988)
Seywald, H., Cliﬀ, E.M.: Goddard problem in presence of a dynamic pressure limit. J.
Guidance Control Dyn. 16(4), 776–781 (1992)
Team Commands, Inria Saclay: BOCOP: an open source toolbox for optimal control
(2016). http://bocop.org
Tsiotras, P., Kelley, H.J.: Drag-law eﬀects in the goddard problem. Automatica 27(3),
481–490 (1991)
Vomlel, J.: Solving the Brachistochrone Problem by an inﬂuence diagram. Technical
report 1702.02032 (2017). http://arxiv.org/abs/1702.02032
Vomlel, J., Kratochv´ıl, V.: Solving the Goddard Problem by an inﬂuence diagram.
Technical report 1703.06321 (2017). http://arxiv.org/abs/1703.06321
Zlatskiy, V.T., Kiforenko, B.N.: Computation of optimal trajectories with singular-
control sections. Vychislitel’naia i Prikladnaia Matematika 49, 101–108 (1983)

Belief Functions

Iterative Aggregation of Crowdsourced Tasks
Within the Belief Function Theory
Lina Abassi(B) and Imen Boukhris
LARODEC, Institut Sup´erieur de Gestion de Tunis,
Universit´e de Tunis, Tunis, Tunisia
lina.abassi@gmail.com, imen.boukhris@hotmail.com
Abstract. With the growing of crowdsourcing services, gathering train-
ing data for supervised machine learning has become cheaper and faster
than engaging experts. However, the quality of the crowd-generated
labels remains an open issue. This is basically due to the wide rang-
ing expertise levels of the participants in the labeling process. In this
paper, we present an iterative approach of label aggregation based on
the belief function theory that simultanously estimates labels, the relia-
bility of participants and diﬃculty of each task. Our empirical evaluation
demonstrate the eﬃciency of our method as it gives better quality labels.
Keywords: Aggregation · Crowd · Expectation-Maximization · Belief
function theory · Expertise
1
Introduction
Recently, crowdsourcing has attracted an increasing interest as an eﬀective and
fast way for collecting training data for supervised machine learning methods. It
emerged from the need to label a big amount of data at a low cost. Crowdsourcing
systems such as the Amazon Mechanical Turk (AMT) provide a platform where
requesters post tasks to be executed by human workers in exchange of few cents.
Nevertheless, these advantages come at a cost of a lower results quality. In fact,
workers are not always reliable and mistakes can occur even with ones who make
real eﬀorts.
As a result, several strategies arised in order to handle the label quality
problem, among them, redundancy [11] which consists in assigning a task to more
than one worker and then aggregating the results. In fact, the main objective
of label aggregation is to ﬁnd the unknown ground truth of a set of tasks. This
objective is hardly reachable since workers are of diﬀerent levels of expertise
leading to high uncertainty in answers, likewise for tasks which diﬃculty can
strongly inﬂuence how worker’s expertise is determined.
In this paper, we provide a new solution to aggregate imperfect labels pro-
duced by multiple workers under the belief function theory (BFT). The BFT
[1,2] is known to be a rich framework that deals eﬀectively with imperfect infor-
mation in addition of providing tools to both integrate sources conﬁdence and
c
⃝Springer International Publishing AG 2017
A. Antonucci et al. (Eds.): ECSQARU 2017, LNAI 10369, pp. 159–168, 2017.
DOI: 10.1007/978-3-319-61581-3 15

160
L. Abassi and I. Boukhris
combine information induced from them. The proposed method generates the
true label, the worker reliability and the task’s diﬃculty simultanously. These
latter are all unknown a priori.
The remainder of the paper is structured as follows: We ﬁrst give an overview
the related work in Sect. 2 then we present the belief function theory fundamen-
tals in Sect. 3. Section 4 introduces our proposed approach. We ﬁnally discuss
experimental results in Sect. 5 and conclude with a summary and future work in
Sect. 6.
2
Related Work
It has been shown that gathering multiple labels even if they are noisy [8] and
then aggregate them according to the simplest manner such as majority decision
(MD) is a better way than just having one label. Yet, a lot of work has attempted
to improve even more the aggregation results since (MD) assumes that all work-
ers have the same expertise. In [17], a benchmark is proposed comparing diﬀerent
methods and classifying them into non iterative and iterative approaches. The
ﬁrst class includes methods that beneﬁt from some a priori ground truth also
called gold data. The Expert Label Injected Crowd Estimation (ELICE) [10]
uses gold data to estimate parameters such as worker’s expertise and question
diﬃculty to then integrate them in the aggregation process. As for the Honeypot
(HP) [5], the gold data is used to ﬁlter workers that could not correctly label
them and after that labels are aggregated according to (MD). In a previous work
[15], the Belief Label Aggregation (BLA) estimates worker’s expertise assuming
that (MD) is the ground truth and then aggregates labels using BFT tools.
The second class of approaches covers EM-based methods that operate when
no ground truth is available. The Expectation-Maximization (EM) algorithm
used in the Dawid and Skene method (DS) [9] is an iterative technique that
consists of two phases: The E step, and the M step. In the E step, answers
are estimated given workers’ error-rates. In the M step, the workers’ expertise
are re-estimated since the missing labels are known from the E step. Many
methods resort to the EM algorithm such as the Supervised Learning from Mul-
tiple Experts (SLME) [7] that can be used only for binary labels and repre-
sents the worker’s expertise by the sensitivity and speciﬁcity measures. Also
the Generative model of Labels, Abilities and Diﬃculties (GLAD) [13] gener-
ates aside worker’s expertise, another parameter which is the question diﬃculty.
In [8], a bayesian approach is employed to estimate the error-rates and ﬁnal
labels. Another recent work, [16] suggests an EM-based method computing the
aggregated label and worker’s expertise and proposes to distinguish a positive
expertise on positive labels and a negative expertise on negative labels and to
incorporate them to the label aggregation step.
In this paper, we propose a model inspired by the EM method that itera-
tively estimates labels, worker’s expertise and task diﬃculty. Unlike most related
works, it beneﬁts from the BFT power to cope with uncertainty generalizing the
probabilistic and possibilistic frameworks and distinguishing between equiprob-
ability and total ignorance. To improve quality results when aggregating labels,

Iterative Aggregation of Crowdsourced Tasks Within the Belief Function
161
our idea is to adapt this theory to one of the most used optimization method
namely the EM algorithm.
3
Belief Function Theory: Fundamentals
The theory of belief function [1,2] is among the most used theories for repre-
senting and reasoning with uncertainty. It is considered as a ﬂexible and rich
framework for dealing with imperfect information. Several interpretations have
emerged including the Transferable Belief Model (TBM) [12].
3.1
Representation of Information
Suppose that Ω is a ﬁnite set of elementary, non empty and mutually exclusive
events applied to a given problem, we call it the frame of discernment. All pos-
sible values that each subset of Ω can take is the power set of Ω denoted by 2Ω
deﬁned as 2Ω = { E : E ⊆Ω}.
The impact of a piece of evidence on the whole subsets of Ω is represented
by the basic belief assignement (bba). A bba is a function mΩ : 2Ω →[0, 1] that
satisﬁes: 
E⊆Ω mΩ(E) = 1.
Each subset E of Ω having a strictly positive mass mΩ(E) > 0 is referred as
the focal element of the bba.
In order to express particular situations related to uncertainty, Shafer [1]
proposed some special bbas:
• Vacuous bba deﬁned by: m(Ω) = 1 and m(E) = 0 for E ̸= Ω. It represents
the total ignorance.
• Categorical bba has a unique focal element E.
• Certain bba is a categorical bbas except that its focal element is a singleton.
• Simple support function is a bba with at most one focal element other
than Ω.
3.2
Discounting Information
It is possible to quantify the reliability of a source inducing degrees of support.
Thus, when dealing with bba, degrees of reliability of its source has to be taken
into account. Discounting [1] consists in weighting bba by a discount rate
α ∈
[0, 1] with (1 −α) is the reliability of the source. The discounted mass function
is given by:

mα(E) = (1 −α) · m(E),
∀E ⊂Ω,
mα(Ω) = (1 −α) · m(Ω) + α.
(1)
• A source is fully reliable if α = 0 accordingly mα(E) = m(E)
• A source is fully unreliable if α = 1 leading to a vacuous bba: mα(Ω) = 1

162
L. Abassi and I. Boukhris
3.3
Combination of Information
There is a great number of combination rules proposed in the framework of
belief function. They are intended to fuse a set of bbas into only one bba in
order to simplify decision making. In what follows we present those related to
our work. Let s1 and s2 be two distinct and cognitively independent reliable
sources providing two diﬀerent bbas m1 and m2 deﬁned on the same frame of
discernment Ω.
(1) Conjunctive rule of combination
This rule is introduced by Smets [6], a mass can be allocated to the empty
set interpreted as the non exhaustivity of the frame of discernment. Therefore,
the conjunctive rule of combination noted by ∩⃝and deﬁned as:
m1 ∩⃝m2(E) =

F ∩G=E
m1(F)m2(G)
(2)
(2) Dempster’s rule of combination
The rule was proposed by Dempster [2] but unlike the conjunctive rule, it
generates a normalized bba (i.e. m(∅) = 0), denoted by ⊕and deﬁned as:
m1 ⊕m2(G) =
⎧
⎨
⎩
m1 ∩⃝m2(G)
1 −m1 ∩⃝m2(∅)
if E ̸= ∅, ∀G ⊆Ω
0
otherwise.
(3)
(3) The Combination with Adapted Conﬂict
The Combination With Adapted Conﬁct (CWAC) rule [4] denoted by ↔
⃝is
an adaptive weighting between the conjunctive and Dempster’s rules. It actually
behaves as the ﬁrst rule if bbas are contradictory and as the second in the opposite
case. It is deﬁned as follows:
m ↔
⃝(E) = ( ↔
⃝mi)(E) = Dm ∩⃝(E) + (1 −D)m⊕(E)
(4)
with D = max [d(mi,mj)] is the maximum distance between mi and mj. This
distance is the Jousselme distance [3], a measure of dissimilarity between bbas
that ensures the adaptation between the two combination rules. It is deﬁned as
follows:
d(m1, m2) =

1
2(m1 −m2)td(m1 −m2),
(5)
where d is the Jaccard index deﬁned by:
d(E, F) =

0
if E = F = ∅,
|E∩F |
|E∪F |
∀E, F ∈2Ω.
(6)

Iterative Aggregation of Crowdsourced Tasks Within the Belief Function
163
3.4
Decision Process
To make a decision, Smets [12] proposes to convert beliefs to a probability func-
tion called the pignistic probability, denoted BetP. The pignistic transformation
is presented as follows:
BetP(ωi) =

E⊆Ω
|E ∩ωi|
|E|
·
m(E)
(1 −m(∅))
∀ωi ∈Ω
(7)
4
I-BLA: Iterative Belief Label Aggregation
In this section, we describe our approach the Iterative Belief Label Aggregation.
It simultaneously infers worker’s expertise, task diﬃculty and aggregated labels.
The calculation of aggregated labels and parameters will go through a sequence
of EM iterations till convergence. It leads to the improvement of the estima-
tion since labels and the parameters are mutually boosted at each iteration.
Therefore, the aggregated label and parameters jointly depend on each other.
A set of X labelers gives answers on Y tasks. A labeler j receives a task i
and contributes a label lij ∈{0, 1, −1}. The (−1) label means that the worker
skipped the task. Li is the ﬁnal aggregated label belonging to (0, 1) for simplicity.
Each worker’s expertise is modelled by (1 −αj) with αj ∈[0, 1] is his error-rate
whereas a task diﬃculty is denoted by βi ∈[0, 1].
Algorithm 1. I-BLA Algorithm
Input: All labels lij for i ∈[1, Y] and j ∈[1, X]
Output: Estimation of αj, βi and the ﬁnal aggregated label Li
1: Pre-processing: Labels representation by bbas
2: Initialize worker’s expertise with αj = 0 (considering all workers are equally reli-
able)
3: repeat
4:
E step: Compute the aggregated labels Li for all tasks taking into account αj
5:
M step: Compute all αj and all βi
6: until convergence
7: return αj, βi and Li for each worker and each task
We describe the Iterative Belief Label Aggregation in Algorithm 1. It is
inspired by the EM algorithm and induces jointly the worker’s expertise, the task
diﬃculty and the ﬁnal aggregated label. These parameters are mutually boosted.
First, We initialize αj to 0 assuming that all workers have equal expertise (like
the majority decision method). Then, as a pre-processing step, bbas are gener-
ated for all labels. The algorithm iterates two steps until it reaches convergence:
E step computes the aggregated labels integrating the workers’ expertise and

164
L. Abassi and I. Boukhris
tasks diﬃculty, and the M step updates both the workers’ expertise as measures
of the aggreement between workers labels and aggregated label as well as the
tasks diﬃculty according to the conﬂict degree induced when aggregating labels.
We detail these three steps in-depth in what follows:
4.1
Pre-processing
This pre-processing step consists in a bba generation where all labels are trans-
formed into mass functions under the belief function theory. As a result, each
label is changed into a bba mΩ
ij with Ω = {ω1, . . . , ωn}. In our case, we are dealing
with binary labelling therfore Ω = {0, 1}.
In this work, three cases are possible:
– If lij = 1 then mij({1}) = 1,
– If lij = 0 then mij({0}) = 1,
– If lij = −1 then mij(Ω) = 1 reﬂecting label ignorance.
4.2
E Step: Label Estimation
The Expectation (E) step consists in estimating all tasks true labels depending
on two parameters namely worker’s expertise and task diﬃculty. First, generated
bbas are discounted by each worker’s expertise (1−αj) (with αj is the error-rate)
with the discounting operation (Eq. 1) depending on task diﬃculty (βi):
⎧
⎪
⎨
⎪
⎩
if βi = 1 and αj > 0.8 then αj = 1,
if βi = 0 and αj < 0.2 then αj = 0,
else αj = αj.
(8)
The ﬁrst case takes away the worker’s label (with a bba transformed into a
vacuous bba) since that he has a low expertise (αj > 0.8) and the task is hard
(βi = 1) so we assume that he is most likely to give a wrong answer.
The second case reinforces the worker’s label (keeping his initial certain bba)
seen that he has a high expertise (αj < 0.2) and the task is easy (βi = 0) so we
assume that he is most likely to give a correct answer.
For the other cases, bbas are discounted and hence transformed into simple
support functions.
We note that the error-rate (αj) threshold values are ﬁxed under the assump-
tion that workers with more than 80% of bad answers are considered unskilled
or even spammers, and those with less than 20% of bad answers must be experts
or futur experts.
After the discounting step, all bbas are aggregated applying the combination
with adapted conﬂict (CWAC) rule 4 in order to get one bba such as ↔
⃝mi =
mα
i1 ↔
⃝mα
i2 ↔
⃝...mα
ij. This rule generates a conﬂict degree which is the mass on
the empty set of the aggregated bba denoted by ci ∈[0, 1].
When the number of mass functions are high, using the conjuctive rule leads
to a conﬂict hitting very high values due to its absorbing power. So unlike the

Iterative Aggregation of Crowdsourced Tasks Within the Belief Function
165
conjunctive rule, the CWAC induces a reasonable conﬂict degree that actually
reﬂects how much the bbas are contradictory.
As a ﬁnal step, decision about the possible label is made through the one
that has the higher pignistic probability (BetP) (Eq. 7).
Example 1. Supposing that the aggregating results for a task is the following bba:
mi(∅) = 0.25, mi({0}) = 0.75
We obtain the following pignistic probability:
BetP({0}) = 1 ·(0.75/(1 −0.25)) = 1,
BetP({1}) = 0
As a result, the decision is Li = 0.
4.3
M Step: Parameters Estimation (α, β)
During the Maximization (M) step, the worker’s expertise and task diﬃculty are
estimated depending on the generated labels in the E step. In fact, the worker’s
expertise is induced from the comparison of the worker labels and the generated
labels by calculating the error-rate αj in [0, 1] as follows:
αj = Number of incorrect labels
Number of labeled tasks
(9)
As for the second parameter, namely the task diﬃculty β in {0, 1}, it is
induced from the conﬂict degree ci. Indeed, according to [4] when ci is above 0.8
then bbas are heteregenous and thus conﬂictual. Therefore, we conclude that:
– If ci > 0.8 then the task i is considered hard (βi = 1) as answers are very
contradictory,
– Else the task i is considered easy (βi = 0).
5
Experimentation
Datasets.
Experiments are conducted on three real datasets namely the
duchenne dataset [13], the event temporal ordering (Temp) dataset [14] and
the recognizing textual entailement (RTE) dataset [14] covering various tasks of
diﬀerent diﬃculty, collected employing diﬀerent numbers of workers. In Table 1,
we present a description of these datasets.
Table 1. Datasets details
Dataset
Workers Task Labels Proportion of labels(̸= (−1))
Duchenne
17
159
1221
0.45
Temp
76
462
4620
0.13
RTE
164
800
8000
0.06

166
L. Abassi and I. Boukhris
5.1
Results Evaluation
In this section we validate our proposed method (I-BLA) by comparing it to a non-
iterative and iterative baseline methods namely Majority Decision (MD) and the
Dawid-Skene (DS) and the Belief Label Aggregation (BLA) which is also based
on the belief function theory to aggregate labels.
The comparison is done considering accuracy which measures the proportions
of correctly estimated labels.
Results of our (I-BLA), (MD), (DS) and (BLA) methods as functions of the
number of workers are shown in Figs. 1, 2 and 3.
Fig. 1. Accuracies as function of workers’
number for Duchenne
Fig. 2. Accuracies as function of workers’
number for Temp
Fig. 3. Accuracies as function of workers’ number for RTE
According to the plots, the accuracy of all techniques increases with the
increase of the number of workers. In general, the iterative methods (I-BLA) and
(DS) are the best performers when the number of workers is high. This is due

Iterative Aggregation of Crowdsourced Tasks Within the Belief Function
167
to the fact that workers’ labels are together justiﬁed through iterations. Yet, (I-
BLA) is taking the lead and overpassing the (DS) and non-iterative techniques.
Indeed, in Fig. 2, the leading method (I-BLA) accuracy goes from 72% when
employing 5 labelers up to 97% at 75 labelers gaining about 2% performance
over (DS) method.
In Table 2, the average accuracies of these ﬁgures are reported. For the three
datasets, our method accomplish the best performance according to accuracy
overpassing state-of-art methods. It records at best an improvement over 20%
compared to (MD) and over 17% compared to (BLA) for the duchenne dataset.
Moreover, it achieves at least an average of 2% compared to the (DS) method
for all datasets.
Table 2. Accuracy of (MD), (BLA), (DS) and (I-BLA) for diﬀerent datasets
Dataset
(MD)
(BLA) (DS)
(I-BLA)
Duchenne 63%
66%
81%
83,4%
RTE
79%
81,3%
85,2% 88%
Temp
80,9% 82%
88%
90,1%
6
Conclusion and Future Works
In this paper, we proposed a new approach (I-BLA) for the aggregation of crowd-
sourced labels within the belief function theory. This approach is based on EM
concept that iteratively computes the aggregated labels, worker’s expertise and
task diﬃculty all depending on each other. We demonstrated the eﬃciency of
our method through extensive experimentation on three datasets.
References
1. Shafer, G.: A Mathematical Theory of Evidence, vol. 1. Princeton University Press,
Princeton (1976)
2. Dempster, A.P.: Upper and lower probabilities induced by a multivalued mapping.
Ann. Math. Stat. 38, 325–339 (1967)
3. Jousselme, A.-L., Grenier, D., Boss´e, ´E.: A new distance between two bodies of
evidence. Inf. Fusion 2, 91–101 (2001)
4. Lef`evre, E., Elouedi, Z.: How to preserve the conﬁct as an alarm in the combination
of belief functions? Decis. Support Syst. 56, 326–333 (2013)
5. Lee, K., Caverlee, J., Webb, S.: The social honeypot project: protecting online
communities from spammers. In: International World Wide Web Conference, pp.
1139–1140 (2010)
6. Smets, P.: The combination of evidence in the transferable belief model. IEEE
Trans. Pattern Anal. Mach. Intell. 12(5), 447–458 (1990)

168
L. Abassi and I. Boukhris
7. Raykar, V.C., Yu, S., Zhao, L.H., Jerebko, A., Florin, C., Valadez, G.H., Bogoni, L.,
Moy, L.: Supervised learning from multiple experts: whom to trust when everyone
lies a bit. In: Proceedings of the 26th Annual International Conference on Machine
Learning, pp. 889–896 (2009)
8. Raykar, V.C., Yu, S., Zhao, L.H., Valadez, G.H., Florin, C., Bogoni, L., Moy, L.:
Learning from crowds. J. Mach. Learn. Res. 11, 1297–1322 (2010)
9. Dawid, A.P., Skene, A.M.: Maximum likelihood estimation of observer error-rates
using the EM algorithm. Appl. Stat. 28, 20–28 (2010)
10. Khattak, F.K., Salleb, A.: Quality control of crowd labeling through expert evalu-
ation. In: The Neural Information Processing Systems 2nd Workshop on Compu-
tational Social Science and the Wisdom of Crowds, pp. 27–29 (2011)
11. Sheng, V.S., Provost, F., Ipeirotis, P.G.: Get another label? improving data quality
and data mining using multiple, noisy labelers. In: Proceedings of the 14th ACM
SIGKDD International Conference on Knowledge Discovery and Data Mining, pp.
614–622 (2008)
12. Smets, P., Mamdani, A., Dubois, D., Prade, H.: Non Standard Logics for Auto-
mated Reasoning, pp. 253–286. Academic Press, London (1988)
13. Whitehill, J., Wu, T., Bergsma, J., Movellan, J.R., Ruvolo, P.L.: Whose vote should
count more: optimal integration of labels from labelers of unknown expertise. In:
Neural Information Processing Systems, pp. 2035–2043 (2009)
14. Snow, R., et al.: Cheap and fast but is it good? Evaluation non-expert annotations
for natural language tasks. In: The Conference on Empirical Methods in Natural
Languages Processing, pp. 254–263 (2008)
15. Abassi, L., Boukhris, I.: Crowd label aggregation under a belief function frame-
work. In: Lehner, F., Fteimi, N. (eds.) KSEM 2016. LNCS, vol. 9983, pp. 185–196.
Springer, Cham (2016). doi:10.1007/978-3-319-47650-6 15
16. Georgescu, M., Zhu, X.: Aggregation of crowdsourced labels based on worker his-
tory. In: Proceedings of the 4th International Conference on Web Intelligence,
Mining and Semantics, pp. 1–11 (2014)
17. Quoc Viet Hung, N., Tam, N.T., Tran, L.N., Aberer, K.: An evaluation of aggre-
gation techniques in crowdsourcing. In: Lin, X., Manolopoulos, Y., Srivastava, D.,
Huang, G. (eds.) WISE 2013. LNCS, vol. 8181, pp. 1–15. Springer, Heidelberg
(2013). doi:10.1007/978-3-642-41154-0 1

A Clustering Approach for Collaborative
Filtering Under the Belief Function Framework
Raoua Abdelkhalek(B), Imen Boukhris, and Zied Elouedi
LARODEC, Institut Sup´erieur de Gestion de Tunis,
Universit´e de Tunis, Tunis, Tunisia
abdelkhalek raoua@live.fr, imen.boukhris@hotmail.com, zied.elouedi@gmx.fr
Abstract. Collaborative Filtering (CF) is one of the most successful
approaches in Recommender Systems (RS). It exploits the ratings of
similar users or similar items in order to predict the users’ preferences.
To do so, clustering CF approaches have been proposed to group items
or users into diﬀerent clusters. However, most of the existing approaches
do not consider the impact of uncertainty involved during the clusters
assignments. To tackle this issue, we propose in this paper a clustering
approach for CF under the belief function theory. In our approach, we
involve the Evidential C-Means to group the most similar items into
diﬀerent clusters and the predictions are then performed. Our approach
tends to take into account the diﬀerent memberships of the items clusters
while maintaining a good scalability and recommendation performance.
A comparative evaluation on a real world data set shows that the pro-
posed method outperforms the previous evidential collaborative ﬁltering.
Keywords: Collaborative ﬁltering · Belief function theory · Clustering ·
Evidential C-Means
1
Introduction
During the last few years, Recommender Systems (RS) [1] have attracted con-
siderable attention from several research communities and have reached a high
level of popularity. The diversity of the information sources and the variety of
domain applications gave birth to various recommendation approaches. Accord-
ing to the literature, CF is considered to be the most popular and the widely
used approach in this area [1–3]. In order to provide recommendations, CF tends
to predict the users’ preferences based on the users or the items sharing sim-
ilar ratings. To do so, this latter exploits the user-item matrix and computes
the similarities between users (user-based [4]) or items (item-based [5]) in the
system. Based on the computed similarities, the prediction process is then per-
formed. CF has achieved widespread success in both academia and industry [2].
Despite its simplicity and eﬃciency, CF approach exhibits some limitations such
as the scalability problems [6]. Actually, CF needs to search the whole user-
item space in order to compute similarities. This computation increases with
the number of items and users leading to poor scalability performance. To over-
come the problem mentioned above, several recommendation approaches have
c
⃝Springer International Publishing AG 2017
A. Antonucci et al. (Eds.): ECSQARU 2017, LNAI 10369, pp. 169–178, 2017.
DOI: 10.1007/978-3-319-61581-3 16

170
R. Abdelkhalek et al.
been proposed using diﬀerent model-based techniques such as Bayesian network
[7], Singular Value Decomposition (SVD) [8] and clustering techniques [6,9,10].
The common point of these approaches is to forecast pre-trained models using
an item-user matrix. For instance, in clustering CF approaches, items can be
assigned to clusters based on their historical ratings and recommendations are
performed accordingly. However, an item may potentially belong to more than
only one cluster. This concept is referred to as soft clustering. This imprecision
may impact the relationship between the items and therefore the ﬁnal prediction.
Indeed, we show in a previous work [11] the relevance of handling uncertainty
in CF throughout the prediction process. In this paper, we treat uncertainty
involved in the clustering CF approaches where we consider the cluster mem-
bership of each item to be uncertain. To this end, we opt for the belief function
theory (BFT) [12–14] which oﬀers a rich representation about all situations rang-
ing from complete knowledge to complete ignorance. Several clustering methods
have been proposed under this theory. For example, the belief K-modes (BKM)
has been proposed by [15] to deal with uncertainty in the attribute values. On
the other hand, the Evidential C-Means (ECM) [16] has been conceived to han-
dle uncertainty for objects’ assignment. Since we are in particular interested in
assessing the uncertainty in items cluster membership, we involve the Eviden-
tial C-Means method which is based on the concept of credal partition. Taking
advantage of the BFT in particular the ECM technique, we propose an evidential
clustering CF. The new approach allows us to assign the items to soft clusters
whilst handling challenges imposed from the CF framework.
This paper is organized as follows: Sect. 2 recalls the basic concepts of the
belief function theory and the Evidential C-Means. Section 3 presents brieﬂy
some related works on clustering CF as well as CF under the belief function
framework. Our proposed recommendation approach is presented in Sect. 4.
Section 5 exposes the experimental results conducted on a real world data set.
Finally, the paper is concluded and some future works are depicted in Sect. 6.
2
Clustering in a Belief Function Framework
The BFT [12–14] represents a ﬂexible and rich framework for reasoning under
uncertainty. In this section, we provide an overview about its basic concepts and
we recall the Evidential C-Means [16] as a clustering method under an uncertain
framework.
2.1
Belief Function Theory
In the BFT, a problem domain is represented by the frame of discernment Θ. The
belief committed to each element of Θ is expressed by a basic belief assignment
(bba) which is a mapping function m : 2Θ →[0, 1] such that: 
A⊆Θ
m(A) = 1
Each mass m(A) quantiﬁes the degree of belief exactly assigned to the event
A of Θ. The subsets A of Θ such as m(A) > 0 are called focal elements.

A Clustering Approach for CF Under the Belief Function Framework
171
To make decisions, beliefs can be represented by pignistic probabilities
deﬁned as:
BetP(A) =

B⊆Θ
|A ∩B|
|B|
m(B)
(1 −m(∅)) for all A ∈Θ
(1)
2.2
Evidential C-Means
The Evidential C-Means (ECM) [16] is a clustering technique based on the con-
cept of credal partition. Given an object i, this method determines the mass mij
representing partial knowledge regarding the cluster membership to any subset
Aj of Θ = {ω1, ω2, . . . , ωn} where n is the number of clusters. Every partition is
represented by a center vk ∈Rp where p is the dimension of data. Each subset
Aj of Θ is represented by the barycenter vj of the centers vk associated to the
clusters composing Aj. The barycenter is computed as follows:
vj = 1
cj
c

k=1
skjvk
(2)
where cj = |Aj| denotes the cardinal of Aj and skj is deﬁned as follows:
skj =

1
if ωk ∈Aj
0
otherwise
(3)
The distance between an object i and any subset Aj of Θ is deﬁned by:
dij = ||xi −vj||
(4)
Finally, the credal partition is determined by minimizing the following objective
function:
JECM =
n

i=1

{j/Aj̸=∅,Aj⊆Θ}
cα
j mβ
ijd2
ij +
n

i=1
δ2mβ
i∅
(5)
α, β and δ are the input parameters such that α ≥0 is a weighting exponent
for cardinality. β > 1 is a weighting exponent controlling the hardness of the
partition and δ represents the distance between all instances and the empty set.
More details about parameters and credal partition process can be found in [16].
3
Related Work on Collaborative Filtering
CF has shown a great applicability in a wide variety of domains [2]. The key idea
is that if two users rated some items similarly or had similar behaviors in the past
then, they would rate or act on other items similarly. CF approaches are divided
into two categories namely, memory-based and model-based. Memory-based CF
approaches exploit the whole user-item matrix to ﬁnd similar users or items and
generate recommendations accordingly. In contrast, model-based algorithms rely

172
R. Abdelkhalek et al.
on the ratings matrix to infer a model which is then applied for predictions. The
model building process can be performed using diﬀerent methods. For exam-
ple, Bayesian networks have been used in [7] for CF process. Clustering CF
approaches that are based on a cluster model to reduce the time complexity
have also been proposed [6,9,10,17]. In [6,17], authors have proposed a cluster-
ing approach for CF that classiﬁes the users in diﬀerent groups and neighborhood
has been selected for each cluster. In [9], the users have been clustered from the
views of both rating patterns and social trust relationships. Similarly, a CF app-
roach has been implemented in [10] based on user’s preferences clustering. All
the clustering techniques mentioned above focus on user-based CF. In our work,
we consider only item-based CF where items are clustered into groups rather
than users. It is obvious that developing RSs that can quickly produce high
quality recommendations have become more and more required in this area [6].
On the other hand, considering uncertainty during the recommendation process
can be argued to be another important challenge in real-world problems [18]. The
belief function theory [12–14] is among the most widely used ones for dealing
with uncertainty. Recent studies have investigated the beneﬁts of the adoption of
such theory in RSs area. In fact, authors in [19] have represented the user’s pref-
erences through the BFT tools and integrate context information for predicting
all unprovided ratings. Another approach developed in [20] relies on this theory
to represent both user’s preferences and community preferences extracted from
social networks. The authors in [11] have proposed an evidential item-based CF
where they considered the similar items as diﬀerent pieces of evidence. They
computed the similarities between the target item and the whole items in the
system and the ﬁnal prediction was an aggregation of the ratings corresponding
to the similar items. However, a lot of heavy computations are needed in this
case. This problem is referred to as the scalability problem which we tackle in
our proposed recommendation approach.
4
Evidential Clustering Approach for CF
In this section, we represent our evidential CF method based on items clustering.
Figure 1 gives the overall ﬂow of the proposed recommendation approach.
Fig. 1. A new clustering CF approach under the belief function theory

A Clustering Approach for CF Under the Belief Function Framework
173
4.1
Items Clustering
Clustering is a crucial step in our approach since the predictions are then per-
formed accordingly. The heart of this approach is to use the eﬃcient soft clus-
tering method, ECM [16] in order to provide a credal partition of the items.
Hence, we allocate, for each item in the ratings matrix a mass of belief not only
to single clusters, but also to any subsets of the frame of discernment Θ. Before
performing the clustering process, we exploit the rating matrix and we randomly
initialize the cluster centers commonly referred to as prototypes. Then, we com-
pute the Euclidean distance between the items and the non empty subsets of
Θ. We obtain the ﬁnal credal partition when the objective function (Eq. 5) is
minimized.
Example 1. Let us consider the user-item matrix illustrated in Table 1.
Table 1. User-item matrix
Movie1 Movie2 Movie3 Movie4 Movie5
User1 3
?
4
1
2
User2 4
4
2
?
?
User3 3
2
4
3
2
User4 ?
1
5
2
3
User5 5
2
0
2
5
Suppose that the number of clusters c = 3, the clustering process consists of
providing a credal partition for the 5 movies. In other words, each movie in
the system may belong to not only singleton clusters but also to disjunctions of
clusters as represented in Table 2.
Table 2. The credal partition corresponding to the ﬁve movies
Movies ∅
{C1}
{C2}
{C1, C2} {C3}
{C1, C3} {C2, C3} Θ
Movie1 0.0025 0.9682 0.009
0.0078
0.0046 0.0043
0.0018
0.0017
Movie2 0.0468 0.2946 0.2715 0.1106
0.1135 0.0731
0.0516
0.0382
Movie3 0.0005 0.0010 0.0018 0.0004
0.9934 0.0009
0.0017
0.0004
Movie4 0.0062 0.0212 0.8856 0.0174
0.0247 0.0107
0.0246
0.0097
Movie5 0.0366 0.1484 0.4931 0.0909
0.0947 0.0479
0.0556
0.0327
4.2
Clusters Selection
In order to make a ﬁnal decision about the cluster of the current item, we
compute the pignistic probability BetPi(Ck) (Eq. 1) induced by each bba. These

174
R. Abdelkhalek et al.
values are interpreted as the degree of membership of the item i to cluster k.
Finally, a hard partition can be easily obtained by assigning each object to the
cluster with the highest pignistic probability.
Example 2. Based on the credal partition derived in the ﬁrst step, the bba′s
can be transformed into pignistic probablities in order to select the corresponding
cluster having the highest value as shown in Table 3.
Table 3. The pignistic probabilities corresponding to the ﬁve movies
Movies C1
C2
C3
Selected cluster
Movie1 0.9773 0.0144 0.0083 C1
Movie2 0.4188 0.3833 0.1979 C1
Movie3 0.0017 0.0029 0.9953 C3
Movie4 0.0387 0.9155 0.0458 C2
Movie5 0.2374 0.5992 0.1633 C2
4.3
Ratings Prediction
The selected clusters are used to obtain knowledge about the items that should
be considered in the rating prediction. In order to perform the prediction task,
only the items belonging to the same cluster as the target item are extracted. The
predicted rating consists of the average of the ratings corresponding to the same
clusters members. Given a target item, the prediction is performed as follows:
Ru,i =

j∈Ci(u) Ruj
|Ci(u)|
(6)
where Ci(u) is the set of items belonging to the cluster of the target item i and
that have been rated by the user u. Ruj is the rating given by user u to item j.
|Ci(u)| is the number of items in cluster Ci which have been rated by user u.
Example 3. For instance, to predict the rating R1,2 given by User1 to Movie2,
we simply average the ratings of the items belonging to the same cluster and that
have been rated by User1. In our case, only Movie1 ∈C1. Then R1,2 = 3
1 = 3.
5
Experimental Evaluation
In order to evaluate our proposal, we test our approach using a real world
data set which is widely used in CF and publicly available on the MovieLens1
website. It contains 100.000 ratings collected from 943 users in 1682 movies.
1 http://movielens.org.

A Clustering Approach for CF Under the Belief Function Framework
175
We conducted our experiments by following the experimental protocol suggested
by [7]. The movies rated by the 943 users are ranked according to the number
of the ratings given by the users. Rating matrix do not have enough data for
accurate predictions, which is known as sparsity. The experimentation strategy
consists on increasing progressively the number of the missing rates leading to
diﬀerent sparsity degrees. Hence, we obtain 10 diﬀerent subsets containing a
speciﬁc number of ratings provided by the 943 users for 20 diﬀerent movies. For
each subset, we randomly extract 20% of the available ratings as a testing data
and the remaining 80% were considered as a training data.
5.1
Evaluation Metrics
We assume that involving an evidential clustering approach for CF may lead to
a better performance over the predicted ratings as well the consuming time.
Prediction and Recommendation
In order to assess the prediction accuracy and to evaluate the quality of rec-
ommendations provided to the active user, we opt for two evaluation metrics
commonly used in CF: the Mean Absolute Error (MAE) which belongs in this
case to [0, 4] and the precision belonging to [0, 1] deﬁned by:
MAE =

u,i | Ru,i −Ru,i|
|| Ru,i||
(7)
Precision =
IR
IR + UR
(8)
where Ru,i is the real rating for the user u on the item i and Ru,i is the predicted
value. ∥Ru,i∥is the total number of the predicted ratings over all the users. IR
indicates that an interesting item has been correctly recommended while UR
indicates that an uninteresting item has been incorrectly recommended. The
lower the MAE values are, the more accurate the predictions are. Otherwise, the
highest values of the precision indicate a better recommendation quality.
Scalability
We also investigated the performance of our approach in terms of scalablity. We
recall that the purpose of scalability refers to the ability of a method to be run
quickly by handling the evolution regarding the number of items and users.
5.2
Experimental Results
We performed various experiments over the 10 selected subsets by varying each
time the number of clusters c. We used c = 2, c = 3, c = 4 and c = 5. For
each subset, the results corresponding to the diﬀerent number of clusters used
in the experiments are then averaged. In other words, we compute the MAE
and the precision measure for each value of c and we note the overall results.
For all our experiments, we used α = 2, β = 2 and δ2 = 10 as invoked in [16].

176
R. Abdelkhalek et al.
Unlike the evidential item-based CF (Evidential IB-CF) [11], the proposed evi-
dential clustering item-based CF (Evidential Clustering IB-CF) relies on items
clusters rather than the user-item matrix. Hence, we compare the two CF meth-
ods proposed under the BFT in order to evaluate the performance of our app-
roach. Table 4 recapitulates the results of each evidential IB-CF considering dif-
ferent sparsity degrees.
Table 4. Comparison results in terms of MAE and precision
Evaluation metrics
Subsets
Sparsity degrees
Evidential IB-CF
Evidential clustering IB-CF
MAE
Subset1
53%
0.751
0.749
Precision
0.79
0.792
MAE
Subset2
56.83%
0.84
0.8
Precision
0.76
0.74
MAE
Subset3
59.8%
0.761
0.747
Precision
0.77
0.785
MAE
Subset4
62.7%
0.763
0.793
Precision
0.763
0.782
MAE
Subset5
68.72%
0.831
0.845
Precision
0.735
0.752
MAE
Subset6
72.5%
0.851
0.8
Precision
0.735
0.813
MAE
Subset7
75%
0.744
0.733
Precision
0.78
0.805
MAE
Subset8
80.8%
0.718
0.762
Precision
0.778
0.755
MAE
Subset9
87.4%
0.840
0.873
Precision
0.707
0.73
MAE
Subset10
95.9%
0.991
0.83
Precision
0.513
0.55
Overall MAE
0.809
0.793
Overall Precision
0,733
0.75
The proposed approach allows an improvement over the standard evidential
item-based CF approach [11] by acquiring, in average the lowest error rates over
the 10 subsets (0.793 compared to 0.809) as well as the highest overall precision
(0.75 compared to 0.733). While the clustering CF proposed in [6] improves the
scalability with a worse prediction quality compared to the traditional one, our
evidential clustering CF outperforms the standard evidential CF in both cases.
Scalability Performance
We perform the scalability of our approach by varying the sparsity degree. We
compare the results to the standard evidential CF as depicted in Fig. 2.
According to Fig. 2, the elapsed time corresponding to the clustering CF
approach is substantially lower than the basic evidential CF. These results are

A Clustering Approach for CF Under the Belief Function Framework
177
Fig. 2. Elapsed time of evidential clustering CF vs. evidential CF
explained by the fact that standard CF methods need to search the closest neigh-
bors to the target item in the whole item space, which leads to huge computing
amount.
6
Conclusion
In this paper, we have proposed a new clustering CF approach based on the
Evidential C-Means method. Compared to a recent CF method under the belief
function theory, elapsed time has been signiﬁcantly improved, along with better
prediction and recommendation performance. As future work, we intend to rely
on the diﬀerent bba′s corresponding to the diﬀerent clusters rather than the most
signiﬁcant one.
References
1. Bobadilla, J., Ortega, F., Hernando, A., Guti´errez, A.: Recommender systems sur-
vey. Knowl.-Based Syst. 46, 109–132 (2013)
2. Park, Y., Park, S., Jung, W., Lee, S.G.: Reversed CF: A fast collaborative ﬁltering
algorithm using a k-nearest neighbor graph. Expert Syst. Appl. 42(8), 4022–4028
(2015)
3. Su, X., Khoshgoftaar, T.M.: A survey of collaborative ﬁltering techniques. Adv.
Artif. Intell. 2009, 1–19 (2009)
4. Zhao, Z.D., Shang, M.S.: User-based collaborative-ﬁltering recommendation algo-
rithms on hadoop. In: Third International Conference on Knowledge Discovery and
Data Mining, pp. 478–481. IEEE, Phuket (2010)
5. Sarwar, B., Karypis, G., Konstan, J., Riedl, J.: Item-based collaborative ﬁltering
recommendation algorithms. In: International Conference on World Wide Web, pp.
285–295. ACM, Hong Kong (2001)

178
R. Abdelkhalek et al.
6. Sarwar, B.M., Karypis, G., Konstan, J., Riedl, J.: Recommender systems for large-
scale e-commerce: scalable neighborhood formation using clustering. In: Interna-
tional Conference on Computer and Information Technology. IEEE, Dhaka (2002)
7. Su, X., Khoshgoftaar, T.M.: Collaborative ﬁltering for multi-class data using
bayesian networks. Int. J. Artif. Intell. Tools 17(01), 71–85 (2008)
8. Symeonidis, P.: Matrix and tensor decomposition in recommender systems. In:
ACM Conference on Recommender Systems, pp. 429–430. ACM, Boston (2016)
9. Guo, G., Zhang, J., Yorke-Smith, N.: Leveraging multiviews of trust and similarity
to enhance clustering-based recommender systems. Knowl.-Based Syst. 74, 14–27
(2015)
10. Zhang, J., Lin, Y., Lin, M., Liu, J.: An eﬀective collaborative ﬁltering algorithm
based on user preference clustering. Appl. Intell. 45(2), 230–240 (2016)
11. Abdelkhalek, R., Boukhris, I., Elouedi, Z.: Evidential item-based collaborative ﬁl-
tering. In: Lehner, F., Fteimi, N. (eds.) KSEM 2016. LNCS, vol. 9983, pp. 628–639.
Springer, Cham (2016). doi:10.1007/978-3-319-47650-6 49
12. Dempster, A.P.: A generalization of bayesian inference. J. Roy. Stat. Soc. Series B
(Methodological) 30, 205–247 (1968)
13. Shafer, G.: A Mathematical Theory of Evidence, vol. 1. Princeton University Press,
Princeton (1976)
14. Smets, P.: The transferable belief model for quantiﬁed belief representation. In:
Smets, P. (ed.) Handbook of Defeasible Reasoning and Uncertainty Management
Systems, vol. 1, pp. 267–301. Springer, Dordrecht (1998)
15. Hariz, S., Elouedi, Z., Mellouli, K.: Clustering approach using belief function the-
ory. In: Euzenat, J., Domingue, J. (eds.) AIMSA 2006. LNCS, vol. 4183, pp. 162–
171. Springer, Heidelberg (2006). doi:10.1007/11861461 18
16. Masson, M.H., Denoeux, T.: ECM: An evidential version of the fuzzy c-means
algorithm. Pattern Recogn. 41(4), 1384–1397 (2008)
17. Xue, G.R., Lin, C., Yang, Q., Xi, W., Zeng, H.J., Yu, Y., Chen, Z.: Scalable col-
laborative ﬁltering using cluster-based smoothing. In: International ACM SIGIR
Conference on Research and Development in Information Retrieval, pp. 114–121.
ACM, Salvador (2005)
18. Nguyen, V.-D., Huynh, V.-N.: A community-based collaborative ﬁltering system
dealing with sparsity problem and data imperfections. In: Pham, D.-N., Park, S.-B.
(eds.) PRICAI 2014. LNCS, vol. 8862, pp. 884–890. Springer, Cham (2014). doi:10.
1007/978-3-319-13560-1 74
19. Nguyen, V.-D., Huynh, V.-N.: A reliably weighted collaborative ﬁltering system.
In: Destercke, S., Denoeux, T. (eds.) ECSQARU 2015. LNCS, vol. 9161, pp. 429–
439. Springer, Cham (2015). doi:10.1007/978-3-319-20807-7 39
20. Nguyen, V.-D., Huynh, V.-N.: Integrating with social network to enhance recom-
mender system based-on dempster-shafer theory. In: Nguyen, H.T.T., Snasel, V.
(eds.) CSoNet 2016. LNCS, vol. 9795, pp. 170–181. Springer, Cham (2016). doi:10.
1007/978-3-319-42345-6 15

A Generic Framework to Include Belief
Functions in Preference Handling
for Multi-criteria Decision
S´ebastien Destercke(B)
Sorbonne Universit´e, UMR CNRS 7253 Heudiasyc,
Universit´e de Technologie de Compi`egne CS 60319, 60203 Compi`egne Cedex, France
sebastien.destercke@hds.utc.fr
Abstract. Modelling the preferences of a decision maker about multi-
criteria alternatives usually starts by collecting preference information,
then used to ﬁt a model issued from a set of hypothesis (weighted average,
CP-net). This can lead to inconsistencies, due to inaccurate information
provided by the decision maker or to a poor choice of hypothesis set.
We propose to quantify and resolve such inconsistencies, by allowing the
decision maker to express her/his certainty about the provided preferen-
tial information in the form of belief functions.
1
Introduction
Preference modelling and multi-criteria decision analysis (MCDA) are increas-
ingly used in our everyday lives. Generally speaking, their goal is to help decision
makers (DM) to model their preferences about multi-variate alternatives, to then
formulate recommendations about unseen alternatives. Such recommendations
can take various shapes, but three common problems can be diﬀerentiated [1]:
– the choice problem, where a (set of) best alternative is recommended to
the DM;
– the ranking problem, where a ranking of alternatives is presented to the
DM;
– the sorting problem, where each alternative is assigned to a sorted class.
In this paper, we will be interested in the two ﬁrst problems, which are closely
related since the choice problem roughly consists in presenting only those ele-
ments that would be ranked highest in the ranking problem.
One common task, in preference modelling as well as in MCDA, is to col-
lect or elicit preferences of decision makers (DM). This elicitation process can
take various forms, that may diﬀer accordingly to the chosen model (Choquet
Integral [6], CP-net [4],. . . ). Anyway, in all cases, each piece of collected infor-
mation then helps to better identify the preference model of the DM. A problem
is then to ensure that the information provided by the DM are consistent with
the chosen model. Ways to handle this problem is to identify model parame-
ters minimising some error term [6], or to consider a probabilistic model [11].
c
⃝Springer International Publishing AG 2017
A. Antonucci et al. (Eds.): ECSQARU 2017, LNAI 10369, pp. 179–189, 2017.
DOI: 10.1007/978-3-319-61581-3 17

180
S. Destercke
Such methods solve inconsistent assessments in principled ways, but most do not
consider the initial information to be uncertain. Another problem within prefer-
ence modelling problems is to choose an adequate family of models, expressive
enough to capture the DM preferences, but suﬃciently simple to be identiﬁed
with a reasonable amount of information. While some works compare the expres-
siveness of diﬀerent model families, few investigate how to choose a family among
a set of possible ones.
In this paper, we propose to model uncertainty in preference information
through belief functions, arguing that they can bring interesting answers to both
issues (i.e., inconsistency handling and model choice). Indeed, belief functions
are adequate models to model uncertainty about non-statistical quantities (in
our case the preferences of a DM), and a lot of work have been devoted about
how to combine such information and handle the resulting inconsistency. It is not
the ﬁrst work that tries to combine belief functions with MCDA and preference
modelling, however existing works on these issues can be split into two main
categories:
– those starting from a speciﬁc MCDA model and proposing an adaptation to
embed belief functions within it [2];
– those starting from belief functions deﬁned on the criteria and proposing
preference models based on belief functions and evidence theory, possibly but
not necessarily inspired from existing MCDA techniques [3].
The approach investigated and proposed in this paper diﬀers from those in two
ways:
– no a priori assumption is made about the kind of model used, as we do not
start from an existing method to propose a corresponding extension. This
means that the proposal can be applied to various methods;
– when selecting a particular model, we can retrieve the precise version of the
model as a particular instance of our approach, meaning that we are consistent
with it.
Section 2 describes our framework. We will use weighted average as a sim-
ple illustrative example, yet the described method applies in principle to any
given set of models. Needed notions of evidence theory are introduced gradually.
Section 3 then discusses how the framework of belief functions can be instru-
mental to deal with the problems we mentioned in this introduction: handling
inconsistent assessments of the DM, and choosing a rich enough family of models.
2
The Basic Scheme
We assume that we want to describe preferences over alternatives X issued from
a multivariate space X = ×C
i=1X i of C criteria X i. For instance, X may be the
space of hotels, applicants . . . and a given criteria X i may be the price, age, . . . In
the examples, we also assume that Xi is within [0, 10], yet the presented scheme

A Generic Framework to Include Belief Functions
181
can be applied to criteria ranked on ordinal scales, or even on symbolic methods
such as CP-net [4].
We will denote by PX the set of partial orders deﬁned over X. Recall that
a strict partial order P is a binary relation over X 2 that satisﬁes Irreﬂexivity
(not P(x, x) for any x ∈X), Transitivity (P(x, y) and P(y, z) implies P(x, z)
for any (x, y, z) ∈X 3) and Asymmetry (either P(x, y) or P(y, x), but not both)
and where P(x, y) can be read “x is preferred to y”, also denoted x ≻P y. When
P concerns only a ﬁnite set A = {a1, . . . , an} ⊆X of alternatives, convenient
ways to represent it are by its associated directed acyclic graph GP = (V, E)
with V = A and (ai, aj) ∈E iﬀ(ai, aj) ∈P, and by its incidence matrix whose
elements denoted Pij will be such that Pij = 1 iﬀ(ai, aj) ∈P. Given a partial
order P and a subset A, we will denote by MaxP the set of its maximal elements,
i.e., MaxP = {a ∈A :̸ ∃a′ ∈A s.t. a′ ≻P a}.
2.1
Elementary Information Item
Our approach is based on the following assumptions:
– the decision-maker (DM) provides items of preferential information Ii
together with some certainty degree αi ∈[0, 1] (αi = 1 corresponds to a cer-
tain information). Ii can take various forms: comparison between alternatives
of X (“I prefer menu A to menu B”) or between criteria, direct information
about the model, . . .
– given a selected space H of possible models, each item Ii is translated into
constraints inducing a subset Hi of possible models consistent with this infor-
mation.
– Each model h ∈H maps subsets of X to a partial order P ∈PX . A subset
H ⊆H maps subsets of X to the partial order H(A) = ∩h∈Hh(A) with
A ⊆X.
We model this information as a simple support mass function mi over H
deﬁned as
mi(Hi) = αi,
mi(H) = 1 −αi.
(1)
Mass functions are the basic building block of evidence theory. A mass function
over space H is a non-negative mapping from subsets of H (possibly including
the empty-set) to the unit interval summing up to one. That is, m : ℘(H) →[0, 1]
with  m(E) = 1 and ℘(H) the power set of H. The mass m(∅) is interpreted
here as the amount of conﬂict in the information. A subset H ⊆H such that
m(H) > 0 is often called a focal set, and we will denote by F = {H ⊆H :
m(H) > 0} the collection of focal sets of m.
Example 1. Consider three criteria X 1, X 2, X 3 that are averages of student notes
in Physics, Math, French (we will use P, M, F). X is then the set of students.
We also assume that the chosen hypothesis space H are weighted averages: a
model h ∈H is then speciﬁed by a positive vector (w1, w2, w3) where  wi = 1.
A student ai is evaluated by ai = w1P + w2M + w3F, and an alternative ai is
better than aj if ai > aj.

182
S. Destercke
Any subset of models can be summarized by a subset of the space H =
{(w1, w2) : w1+w2 ≤1}, since the last weight can be inferred from the two ﬁrsts.
For instance, let us assume that the information item I is (0, 8, 5) ≻(8, 4, 5),
meaning that
0w1 + 8w2 + 5w3 > 8w1 + 4w2 + 5w3 →w2 > 2w1
The resulting subspace H of models is then pictured in Fig. 1. The decision
maker can then provide some assessment of how certain she/he is about this
information by providing a value α. For instance, if the DM is certain to choose
a student with grades (0, 8, 5) over one with grades (8, 4, 5), then α should be
close to 1. Yet if the DM is quite uncertain about this choice, then α should be
closer to 0.
2.2
Combining Elements of Information
In practice, the DM will deliver multiple items of information, that should be
combined. If m1 and m2 are two mass functions over the space H, then their
conjunctive combination in evidence theory is deﬁned as the mass
m1∩2(H) =

Hi∈Fi,H1∩H2=H
m1(H1)m2(H2),
(2)
which is applicable if we consider that the provided information items are dis-
tinct, a reasonable simplifying assumption in a preference learning setting where
the DM usually does not answer a question by consciously thinking about the
ones she/he already answered. If we have n masses m1, . . . , mn to combine, cor-
responding to n information items I1, . . . , In, we can iteratively apply Eq. (2),
as it is commutative and associative. If each mi has two focal elements (Hi and
H), then the number of focal elements of the combined mass double after each
application of (2). This of course limits the number n we can consider, yet in
frameworks where individual decision makers are asked about their preferences,
this number is often small.
It may happen that the given preferential information items conﬂict, pro-
ducing a non-null mass m(∅) > 0, meaning that no models in H satisﬁes all
preferential information items. In evidence theory, two main ways to deal with
this situation exist:
0
w1
1
w2
1
H
Fig. 1. Information item subset

A Generic Framework to Include Belief Functions
183
W1 Ignoring the fact that some conﬂicting information exists and normalise m
into m′. There are many ways to do so [10], but the most commonly used
consists in considering m′ such that for any H ∈F \ ∅we have m′(H) =
m(H)/1−m(∅).
W2 Use the value of m(∅) as a trigger to resolve the conﬂicting situation rather
than just relocating it. A typical solution is then to use alternative combi-
nation rules [8].
We discuss in Sect. 3 how m(∅) can be used in our context to select the relevant
information or to select alternative hypothesis spaces.
Example 2. Consider again the setting of Example 1, The ﬁrst information deliv-
ered, H1 = {(w1, w2) ∈H : w2 ≥2w1} is that (0, 8, 5) ≻(8, 4, 5) with a mild
certainty, say α1 = 0.6. The second item of information provided by the DM is
that for her/him, sciences are more important than language, which we interpret
as the inequality
w1 + w2 ≥w3 →w1 + w2 ≥0.5
obtained from the fact that  wi = 1. The DM is pretty sure about it, resulting
in α2 = 0.9 and H2 = {(w1, w2) ∈H : w2 + w1 ≥0.5}. The mass resulting from
the application of (2) to m1, m2 is then
m(H1) = 0.06, m(H2) = 0.36, m(H1 ∩H2) = 0.54, m(H) = 0.04.
2.3
Inferences: Choice and Ranking
When having a ﬁnite set A = {a1, . . . , an} of alternatives and a mass with k focal
elements H1, . . . , Hk, two tasks in MCDA are to provide a recommendation to
the DM, in the form of one alternative a∗or a subset A∗, and to provide a
(partial) ranking of the alternatives in A. We suggest some means to achieve
both tasks.
Choice. When a partial order P is given over A, a natural recommendation is
to provide the set A∗= MaxP of maximal items derived from P. Providing a
choice in an evidential framework, based on the mass m, then requires to extend
this notion. Assuming that the best representation of the DM preferences we
could have is a partial order P ∗, a simple way to do so is to measure the so-
called belief and plausibility measures that a given subset A ⊆A is a subset of
the set of maximal elements, considering that the subset MaxPi derived from
the focal element Hi represents a superset of A∗. These two values are easy to
compute, as under these assumptions we have
Pl(A ⊆A∗) =

A⊆MaxPi
m(Hi),
(3)
Bel(A ⊆A∗) =

A=2
MaxPi \∅
m(Hi) =

0 if |A| > 1,

MaxPi={a} m(Hi) if A = {a}.
(4)

184
S. Destercke
The particular form of Bel is due to the fact that we have no information about
which subset have to be necessarily contained in the set of maximal elements of
the unknown partial order P ∗. Some noteworthy properties of Eqs. (3)–(4) are
the following:
– for an alternative a ∈A, Pl({a}) = 1 iﬀ{a} is a maximal element of all
possible partial orders (in particular, m(∅) = 0).
– given A ⊆B ⊆A, we can have Pl(A ⊆A∗) ≥Pl(B ⊆A∗), meaning that it
is sensible to look for the most plausible set of maximal elements, that may
not be A.
Example 3. Consider the four alternatives A = {a1, a2, a3, a4} presented in
Table 1. We then consider the mass of four focal elements given in Example 2
with the renaming:
H1 = H1, H2 = H2, H3 = H1 ∩H2, H4 = H
From these, we can for example deduce that P1 = {(a1, a4), (a2, a3)} using simple
linear programming. That (a1, a4) ∈P1 comes from the fact that the diﬀerence
between a1 and a4 evaluation is always positive in H1, that is
min
(w1,w2,w3)∈H1(4w1 + 3w2 + 9w3) −(7w1 + w2 + 7w3) > 0.
Similarly, we have P3 = {(a1, a4), (a2, a1), (a2, a3), (a3, a4), (a2, a4)} and P2 =
P4 = {}, from which follows MaxP1 = {a1, a2}, MaxP3 = {a2}, MaxP2 =
MaxP4 = A. Interestingly, this shows us that while information I2 leading to
H2 does not provide suﬃcient information to recommend any student in A,
combined with I1, it does improve our recommendation, as |MaxP3| = 1.
Table 1. A set of alternatives
P M F
a1 4 3 9
a2 5 9 6
P M F
a3 8 7 3
a4 7 1 7
Table 2 gives the plausibilities and belief resulting from Eqs. (3)–(4) for sub-
sets of one or two elements. Clearly, {a2} is the most plausible answer, as well as
the most credible, and hence should be chosen as the predicted set of maximal
elements.
Table 2. Plausibilities and belief on sets of one and two alternatives
{a1} {a2} {a3} {a4} {a1, a2} {a1, a3} {a1, a4} {a2, a3} {a2, a4} {a3, a4}
Pl
0.46
1
0.4
0.4
0.46
0.4
0.4
0.4
0.4
0.4
Bel 0
0.54
0
0
0
0
0
0
0
0

A Generic Framework to Include Belief Functions
185
Ranking. The second task we consider is to provide a (possibly partial) ranking
of the alternatives. Since each (non-empty) focal element can be associated to
a partial order over A, this problem is close to the one of aggregating partial
orders [9]. Focusing on pairwise information, we can compute the plausibilities
and belief that one alternative ai is preferred to another aj, as follows:
Pl(ai ≻aj) =

Pk,Pk,ji̸=0
m(Hk),
Bel(ai ≻aj) =

Pk,Pk,ij=1
m(Hk),
(5)
where Pk,ij is the (i, j) value of the incidence matrix of Pk. In practice, Pl
comes down to sum all partial orders that have a linear extension with ai ≻
aj, and Bel the partial orders whose all linear extensions have ai ≻aj. The
result of this procedure can be seen as an interval-valued matrix R with Ri,j =
[Bel(ai ≻aj), Pl(ai ≻aj)]. It can also be noted that, if m(∅) = 0, we do
have Pl(ai ≻aj) = 1 −Bel(aj ≻ai). From this matrix, we then have many
choices to build a predictive ranking: we can either use previous results about
belief functions [7], or classical aggregation rules of pairwise scores to predict
rankings [5]. For instance, a classical way is to compute, for each alternative ai,
the interval-valued score [si, si] = 
aj̸=ai[Bel(ai ≻aj), Pl(ai ≻aj)] and then to
consider the resulting partial order. This last approach is connected to optimizing
the Spearman footrule, and has the advantage of being straightforward to apply.
Example 4. The matrix R and the scores [si, si] resulting from Example 3 is
⎛
⎜
⎜
⎝
a1
a2
a3
a4
a1
0
[0, 0.46]
[0, 1]
[0.6, 1]
a2
[0.54, 1]
0
[0.6, 1]
[0.54, 1]
a3
[0, 1]
[0, 0.4]
0
[0.54, 1]
a4
[0, 0.4]
[0, 0.46]
[0, 0.46]
0
⎞
⎟
⎟
⎠

=
⎛
⎜
⎜
⎝
[si, si]
[0.6, 2.46]
[1.68, 3]
[0.54, 2.4]
[0, 1.32]
⎞
⎟
⎟
⎠
from which we get the ﬁnal partial order P ∗= {(a2, a4)}.
Note that, in practice, it could be tempting to ﬁrst compute the set of max-
imal elements and to combine them, rather than combining the models then
computing a plausible set of maximal elements, as the ﬁrst solution is less con-
strained. However, this can only be done when a speciﬁc set A of interest is
known.
3
Inconsistency as a Useful Information
So far, we have largely ignored the problem of dealing with inconsistent infor-
mation, avoiding the issue of having a strictly positive m(∅). As mentioned in
Sect. 2.2, this issue can be solved through the use of alternative combination
rules, yet in the setting of preference learning, other treatments that we discuss
in this section appear at least as equally interesting. These are, respectively,
treatments selecting models of adequate complexity and selecting the “best”
subset of consistent information. To illustrate our purpose, consider the follow-
ing addition to the previous examples.

186
S. Destercke
Example 5. Consider that in addition to previously provided information in
Example 2, the DM now aﬃrms us (with great certainty, α3 = 0.9) that the
overall contribution of mathematics (X2) should count for at least four tenth
of the evaluation but not more than eight tenth. In practice, if H is the set of
weighted means, this can be translated into H3 = {(w1, w2) : 8/10 ≥w2 ≥4/10}.
Figure 2 shows the situation, from which we get that H1, H2 and H3 do not
intersect, with m(∅) = 0.6 · 0.9 · 0.9 = 0.486, a number high enough to trigger
some warning.
0
w1
1
w2
1
H1
H2
H3
Fig. 2. Inconsistent information items
3.1
Model Selection
m(∅) can be high because the hypothesis space H is not complex enough to
properly model a user preference. By considering more complex space H′, we
may decrease the value m(∅), as if H ⊆H′, we will have that for any information
Ii, the corresponding sets of models will be such that Hi ⊆H′
i (as all models
from H satisfying the constraints of Ii will also be in H′), hence we may have
Hi ∩Hj = ∅but H′
i ∩H′
j ̸= ∅.
Example 6. Consider again Example 5, where H′ is the set of all 2-additive
Choquet integrals. A 2-additive Choquet integral can be deﬁned by a set of
weights wi and wij, i ̸= j where wi and wij are the weights of groups of criteria
{X i} and {X i, X j}. The evaluation of alternatives for a 2-additive Choquet
integral then simply reads
ai =

j
wjxj +

j<k
wkj min(xj, xk).
For the evaluation function to respect the Pareto ordering, these weights must
satisfy the following constraints
wi ≥0 for all i,
wij + wi + wj ≥max(wi, wj) for all pairs i, j,
(6)

i
wi +

ij
wij = 1.

A Generic Framework to Include Belief Functions
187
Also, the contribution φi of a criterion i can be computed through the Shapley
value
φi = wi + 1/2

j̸=i
wij.
In the case of Example 5, this means that H corresponds to the set of vectors
(wi, wij) that satisfy the constraints given by Eq. (6). In this case, the infor-
mation items H1, H2 provided in Example 1 and H3 in Example 5 induce the
following constraints:
H1 = {w ∈H′ : 4w2 + w23 ≥8w1 + 4w12 + 5w13}
H2 = {w ∈H′ : φ1 + φ2 ≥φ3} = {w ∈H′ : w1 + w2 + w12 ≥w13}
H3 = {w ∈H′ : 4/10 ≤φ2 ≤8/10} = {w ∈H′ : 4/10 ≤w2 + 1/2w12 + 1/2w13 ≤8/10}
These constraints are not inconsistent, as for example the solution where
w1 = 0.2, w2 = 0.4, w23 = 0.4 are the only non-null values is within H1, H2
and H3. Among other things, this means that combining m1, m2, m3 within the
hypothesis space H′ leads to m(∅) = 0.
When considering a discrete nested sequence H1 ⊆. . . ⊆HK of hypothesis
spaces, then a simple procedure to select a model is to iteratively increase its
complexity is summarised in Algorithm 1, where Hi
j is the set of possible hypoth-
esis induced by information Ij in space Hj. It should be noted that the mass
given to the empty set is guaranteed to decrease as the hypothesis spaces are
nested. One could apply the same procedures to non-nested hypothesis spaces
H1, . . . , HK (e.g., considering lexicographic orderings and weighted averages),
yet in this case there would be no guaranteed relations between the conﬂicting
mass induced by each hypothesis spaces.
Algorithm 1. Algorithm to select preference model
Input: Spaces H1 ⊆. . . ⊆HK, Information I1, . . . , IF , threshold τ, i = 1
Output: Selected hypothesis space H∗
repeat
foreach j ∈{0, . . . , m} do Evaluate Hi
j;
Combine mi
1, . . . , mi
F into mi ;
i ←i + 1
until mi(∅) ≤τ or i = K + 1;
3.2
Information Selection
If we assume that H is suﬃciently rich to describe the DM preferences, then m(∅)
results from the fact that the DM has provided some erroneous information. It
then makes sense to discard those information items that are the most uncer-
tain and introduce inconsistency in the result. In a short word, given a subset

188
S. Destercke
S ⊆{1, . . . , n}, if we denote by mS the mass obtained by combining the masses
{mi : i ∈S}, then we can try to ﬁnd the subset S such that mS(∅) = 0 and
Cer(S) = 
i̸∈S αi is minimal with this property.
An easy but sub-optimal way to implement this strategy is to consider ﬁrst
the set S0 = {1, . . . , n}, and then to consider iteratively subsets by removing
the set of sources having the lowest cumulated weight so far. In Example 5,
this would come to consider ﬁrst S1 = {2, 3} (with Cer(S1) = 0.6), then either
S2 = {1, 3} or S2 = {1, 2} (with Cer(S1) = 0.9). From Fig. 2, we can see that
for S = {2, 3}, we already have mS(∅) = 0, thus not needing to go any further.
When n is small enough (often the case if MCDA), then such a naive search may
remain aﬀordable. Improving upon it then depends on the nature of the space
H. It seems also fair to assume that the DM makes his/her best to be consistent,
and therefore the number of information items to remove from S0 = {1, . . . , n}
should be small in general.
One can also combine the two previously described approach, i.e., to ﬁrst
increase the model complexity if the conﬂict is important at ﬁrst, and then
to discard the most conﬂicting and uncertain information. There is a balance
between the two: increasing complexity keeps all the gathered information but
may lead to over-ﬁtting and to computational problems, while letting go of some
information reduces the computational burden, but also delivers more conserv-
ative conclusions.
4
Conclusion
In this paper, we have described a generic way to handle uncertain preference
information within the belief function framework. In contrast with previous
works, our proposal is not tailored to a speciﬁc method but can handle a great
variety of preference models. It is also consistent with the considered prefer-
ence model, in the sense that if enough fully reliable information is provided, we
retrieve a precise preference model.
Our proposal is very general, and maybe more or less diﬃcult to apply
depending on the choice of H. In the future, it would be interesting to study
speciﬁc preference models and to propose eﬃcient algorithmic procedures to per-
form the diﬀerent calculi proposed in this paper. For instance, how do the com-
putations look like where we consider numerical models? Indeed, all procedures
described in this paper can be applied to numerical as well as to non-numerical
models, but numerical models may oﬀer speciﬁc computational advantages.
References
1. Benabbou, N., Perny, P., Viappiani, P.: Incremental elicitation of choquet capac-
ities for multicriteria decision making. In: Proceedings of the Twenty-First Euro-
pean Conference on Artiﬁcial Intelligence, pp. 87–92. IOS Press (2014)
2. Beynon, M.J.: Understanding local ignorance and non-speciﬁcity within the
DS/AHP method of multi-criteria decision making. Eur. J. Oper. Res. 163(2),
403–417 (2005)

A Generic Framework to Include Belief Functions
189
3. Boujelben, M.A., De Smet, Y., Frikha, A., Chabchoub, H.: A ranking model in
uncertain, imprecise and multi-experts contexts: the application of evidence theory.
Int. J. Approximate Reasoning 52(8), 1171–1194 (2011)
4. Boutilier, C., Brafman, R.I., Domshlak, C., Hoos, H.H., Poole, D.: CP-nets: a tool
for representing and reasoning with conditional ceteris paribus preference state-
ments. J. Artif. Intell. Res. (JAIR) 21, 135–191 (2004)
5. Destercke, S.: A pairwise label ranking method with imprecise scores and partial
predictions. In: Machine Learning and Knowledge Discovery in Databases - Euro-
pean Conference, ECML PKDD 2013, Prague, Czech Republic, 23–27 September,
Proceedings, Part II, pp. 112–127 (2013)
6. Grabisch, M., Kojadinovic, I., Meyer, P.: A review of methods for capacity iden-
tiﬁcation in Choquet integral based multi-attribute utility theory: applications of
the Kappalab R package. Eur. J. Oper. Res. 186(2), 766–785 (2008)
7. Masson, M., Destercke, S., Denoeux, T.: Modelling and predicting partial orders
from pairwise belief functions. Soft Comput. 20(3), 939–950 (2016)
8. Pichon, F., Destercke, S., Burger, T.: A consistency-speciﬁcity trade-oﬀto select
source behavior in information fusion. IEEE Trans. Cybern. 45(4), 598–609 (2015)
9. Rademaker, M., De Baets, B.: A threshold for majority in the context of aggre-
gating partial order relations. In: 2010 IEEE International Conference on Fuzzy
Systems (FUZZ), pp. 1–4. IEEE (2010)
10. Smets, P.: Analyzing the combination of conﬂicting belief functions. Inf. Fusion 8,
387–412 (2006)
11. Viappiani, P., Boutilier, C.: Optimal bayesian recommendation sets and myopically
optimal choice query sets. In: Advances in Neural Information Processing Systems,
pp. 2352–2360 (2010)

A Recourse Approach for the Capacitated
Vehicle Routing Problem with Evidential
Demands
Nathalie Helal1(B), Fr´ed´eric Pichon1, Daniel Porumbel2, David Mercier1,
and ´Eric Lef`evre1
1 Univ. Artois, EA 3926, Laboratoire de G´enie Informatique et d’Automatique de
l’Artois (LGI2A), 62400 B´ethune, France
nathalie helal@ens.univ-artois.fr,
{frederic.pichon,david.mercier,eric.lefevre}@univ-artois.fr
2 Conservatoire National des Arts et M´etiers, EA 4629, Cedric, 75003 Paris, France
daniel.porumbel@cnam.fr
Abstract. The capacitated vehicle routing problem with stochastic
demands can be modelled using either the chance-constrained approach
or the recourse approach. In previous works, we extended the former
approach to address the case where uncertainty on customer demands
is represented by belief functions, that is where customers have so-
called evidential demands. In this paper, we propose an extension of
the recourse approach for this latter case. We also provide a technique
that makes computations tractable for realistic situations. The feasibil-
ity of our approach is then shown by solving instances of this diﬃcult
problem using a metaheuristic algorithm.
Keywords: Vehicle routing problem · Stochastic Programming with
Recourse · Belief function
1
Introduction
In the Capacitated Vehicle Routing Problem (CVRP), one aims at ﬁnding a set
of routes of minimum cost, such that a ﬂeet of vehicles initially located at a
depot, collect goods from a set of customers with deterministic collect demands,
while respecting the capacity restrictions of the vehicles. The CVRP with Sto-
chastic Demands (CVRPSD) [14] is a modiﬁed version of this problem, where
customers have stochastic demands such that, in general, the vehicle capacity
limit has a non zero probability of being violated on any route. It is a sto-
chastic integer linear program, which can be modelled by two main approaches:
Chance Constrained Programming (CCP) and Stochastic Programming with
Recourse (SPR) [1]. Modelling the CVRPSD via CCP consists in having con-
straints specifying that vehicle capacity limit on any route must not be violated
with a high probability. While an SPR model for the CVRPSD allows so-called
recourse actions to be performed along a route, such as returning to the depot
c
⃝Springer International Publishing AG 2017
A. Antonucci et al. (Eds.): ECSQARU 2017, LNAI 10369, pp. 190–200, 2017.
DOI: 10.1007/978-3-319-61581-3 18

A Recourse Approach for the Capacitated Vehicle Routing Problem
191
to unload, in order to bring to feasibility a violated capacity limit. The cost of
these actions is considered directly in the problem objective [14]. Speciﬁcally,
the total expected travel cost is subject to minimisation, this cost covering the
classical travel cost, i.e., the cost of travel if no recourse action is performed, as
well as the expected cost of the recourse actions. SPR models of the CVRPSD
have a wider range of applications than CCP models, but they are generally
more involved.
Recently [7], another variant of the CVRP was considered: the CVRP with
Evidential Demands (CVRPED), where evidential means that uncertainty on
customer demands is represented by belief functions [11]. Belief function theory is
an alternative framework to probability theory for modelling uncertainty, and it
can naturally account for uncertainty on customer demands in various situations,
such as when pieces of information on customer demands are partially reliable.
In [7], the CVRPED was modelled using an extension of the CCP approach used
for CVRPSD, and subsequently solved using a metaheuristic, which is a classical
means to tackle the CVRP, because it is NP-hard. In this paper, the CVRPED is
modelled using an extension of the other main approach to modelling stochastic
programs, that is by extending the SPR approach used for the CVRPSD, and
then it is also solved using a metaheuristic algorithm.
Note that, to the best of our knowledge, this is the ﬁrst time that an integer
linear program involving uncertainty represented by belief functions is tackled
using such a modelling approach. Indeed, besides [7], other works [8,9,12] han-
dled optimisation problems involving uncertainty represented by belief functions
in the case of continuous linear programs, which are usually much less diﬃcult to
solve than their discrete counterparts. In particular, Masri and Ben Abdelaziz [8]
extended both CCP and SPR to model linear programs involving belief functions
(so-called belief linear programs).
This paper is organised as follows. Necessary background on SPR modelling
of CVRPSD and on belief function theory is recalled in Sect. 2. An extension of
the recourse approach for the CVRPED is presented in Sect. 3. Experiments on
CVRPED instances solved using a simulated annealing metaheuristic adapted
from [6], are reported in Sect. 4. Section 5 concludes the paper.
2
Background
2.1
CVRPSD Modeled by SPR
In the CVRP, a ﬂeet of m identical vehicles with a given capacity limit Q, initially
located at a depot, must collect1 goods from n customers, with 0 < di ≤Q the
indivisible deterministic collect demand of client i, i = 1, . . . , n. The objective
is to ﬁnd a set of m routes with minimum cost to serve all the customers such
that (i) total customers demands on any route must not exceed Q; (ii) each
route starts and ends at the depot; and (iii) each customer is serviced only
once; we refer to [2] for a formal description of these constraints. Let Rk be the
1 The problem can also presented in terms of delivery, rather than collection, of goods.

192
N. Helal et al.
route associated to vehicle k and ci,j be the cost of traveling from customer i to
customer j. The objective is thus to
min
m

k=1
C(Rk),
where
C(Rk) =
n

i=0
n

j=0
ci,jwi,j,k,
(1)
with wi,j,k a binary variable that equals 1 if vehicle k travels from i to j and
serves them, and 0 if it does not.
In the CVRPSD, each client demand di, i = 1, . . . , n, becomes a random
variable, such that P(di ≤Q) = 1. As a consequence, a vehicle might not
be able to load all of the actual customer demands on any given route having
more than one customer. The SPR approach deals with this issue by permitting
recourse actions, such as allowing vehicles to return to the depot to unload when
they are full. These actions lead to extra costs for routes, which we call penalty
costs, and it is generally possible to compute the expected penalty cost of a
route induced by the stochastic demands. A general expression for SPR models
of CVRPSD is then the following. The objective is to ﬁnd a set of routes that
min
m

k=1
Ce(Rk),
where Ce(Rk) is the expected cost of Rk deﬁned by
Ce(Rk) = C(Rk) + Cp(Rk),
with C(Rk) the cost deﬁned by (1) representing the cost of traveling along Rk if
no recourse action is performed, and Cp(Rk) the expected penalty cost on Rk –
Cp(Rk) may be deﬁned in many diﬀerent ways depending on the recourse policy
used (see, e.g., [4,5]).
2.2
Belief Function Theory
Let us recall the concepts of belief function theory needed in this study. Let x be
a variable taking its values in a domain X. In this theory, uncertain knowledge
about x may be represented by a Mass Function (MF) deﬁned as a mapping
mX : 2X →[0, 1] such that mX (∅) = 0 and 
A⊆X mX(A) = 1. The quantity
mX(A), for some A ⊆X, represents the probability of knowing only that x ∈A.
Subsets A ⊆X such that mX(A) > 0 are called focal sets. A MF whose focal
sets are singletons, i.e., mX(A) > 0 iﬀ|A| = 1, corresponds to a probability
mass function and is called a Bayesian MF. Furthermore, a variable x whose
true value is known in the form of a MF will be called an evidential variable.

A Recourse Approach for the Capacitated Vehicle Routing Problem
193
Finally, given a MF mX and a function h : X →R+, it is possible to compute
its upper expected value E∗(h, mX) deﬁned as [3]
E∗(h, mX) =

A⊆X
mX(A) max
x∈A h(x).
3
Recourse Approach for the CVRPED
In this section, a recourse approach is proposed for the case where uncertainty
on customer demands in the CVRP is represented by belief functions.
3.1
Formalisation
Assume customer demands di, i = 1, . . . , n, are no longer deterministic or ran-
dom, but evidential, i.e., the actual demand of customer i is known with some
uncertainty represented by a MF. In such case, one obtains a new problem called
CVRPED. As shown in [7], this problem can be addressed via a constrained pro-
gramming approach. However, similarly to what has been done for the case of
belief linear programs [8], this problem may be also addressed using an exten-
sion of the other main approach to modelling stochastic programs, that is by
extending the recourse approach of CVRPSD to CVRPED.
Speciﬁcally, we propose to extend the recourse approach, for the following
policy and assumptions studied for the stochastic case in [4,5]. Each actual
customer demand cannot exceed the vehicle capacity. In addition, when a vehicle
arrives at a customer on its planned route, it is loaded with the actual customer
demand up to its remaining capacity. If this remaining capacity is suﬃcient to
pick-up the entire customer demand, then the vehicle continues its planned route.
However, if it is not suﬃcient, i.e., there is a failure, then the vehicle returns to
the depot, is emptied, goes back to the client to pick-up the remaining customer
demand and continues its originally planned route.
Consider a given route R containing N customers and, without lack of gener-
ality, that the i-th customer on R is customer i. According to the above setting,
a failure cannot occur at the ﬁrst customer on R. However, it can occur at any
other customer on R, and there may even be failure at multiple customers on R
(at worst, if the actual demand of each customer is equal to the capacity of the
vehicle, failure occurs at each customer except the ﬁrst one).
Formally, let us introduce a binary variable ri that equals 1 if failure occurs
at the i-th customer on R and 0 otherwise (by problem deﬁnition r1 = 0). Then,
the possible failure situations that may occur along R may be represented by
the vectors (r2, r3, . . . , rN) ∈{0, 1}N−1. To simplify the exposition, we deﬁne
the set Ω = {ω1, . . . ω2N−1} representing the possible failure situations along R,
with failure situation (r2, r3, . . . , rN) being in one-to-one correspondence with
ωj where j = 1 + N
i=2 ri × 2i−2. For instance, when R contains only N = 3
customers, we have Ω = {ω1, ω2, ω3, ω4}, where ωj, j = 1, . . . , 4, mean that
the vehicle needs to perform a round trip to the depot, respectively, “never”,

194
N. Helal et al.
“when it reaches the second customer”, “when it reaches the third customer”,
and “when it reaches both the second and third customers”.
Furthermore, let g : Ω →R+ be a function representing the cost of each
failure situation ω ∈Ω. Since the penalty cost upon failure on customer i is 2c0,i
(a failure implies a return trip to the depot), the cost associated to failure ωj is
g(ωj) =
N

i=2
ri2c0,i,
using the one-to-one correspondence ωj ↔(r2, r3, . . . , rN).
Let mΩ be a MF representing uncertainty towards the actual failure situation
occurring on R – as will be shown in the next section, evidential demands may
induce such a MF.
Then, adopting a similar pessimistic attitude as in the recourse approach to
belief linear programming [8], the upper expected penalty cost C∗p(R) of route R
may be obtained as C∗p(R) = E∗(g, mΩ). Accordingly, the upper expected cost
C∗e(R) of route R may be deﬁned as
C∗e(R) = C(R) + C∗p(R),
with C(R) the cost (1) of travelling along route R when no failure occurs.
The CVRPED under the above recourse policy, may then be modelled as the
problem of ﬁnding a set of m routes optimising the following objective function
min
m

k=1
C∗e(Rk).
(2)
Since C∗e(R) is the upper, i.e., worst, expected cost of a route, we note that
optimising (2) has some similarities with the protection against the worst case
popular in robust optimisation [13].
The evaluation of the objective function (2) requires the computation for
each route, of the MF mΩ representing uncertainty on the actual failure situation
occurring on the route. This is detailed in the next section.
3.2
Uncertainty on Recourses
We assume customer demands to be positive integers. Hence, evidential demands
are deﬁned on the ﬁnite set Θ = {1, . . . , Q}.
Consider again a route R containing N customers. In addition, let us ﬁrst
assume that MF mΘ
i representing the evidential demand of the i-th client, i =
1, . . . , N, on R is such that ∃θi ∈Θ, mΘ
i ({θi}) = 1, i.e., client demands are
known without any uncertainty. Then, it is clear that the above recourse policy
amounts to the following deﬁnition for the binary failure variables ri:
ri =

1, if qi−1 + θi > Q,
0, otherwise,
∀i ∈{2, . . . , N}
(3)

A Recourse Approach for the Capacitated Vehicle Routing Problem
195
where qj, j = 1, . . . , N, denotes the load in the vehicle after serving the j-th
customer such that qj = θ1 for j = 1 and, for j = 2, . . . , N,
qj =
qj−1 + θj −Q, if qj−1 + θj > Q,
qj−1 + θj,
otherwise.
In other words, when it is known that the demand of the i-th customer is θi, i =
1, . . . , N, then it can be deduced that the failure situation ωj ↔(r2, r3, . . . , rN),
with ri deﬁned by (3), occurs. This can be encoded by a function f : ΘN →Ω,
s.t. f (θ1, . . . , θN) = ωj, with ωj the failure situation induced by demands θi. For
example, suppose we have N = 3 customers on route R, with respective demands
θ1 = 3, θ2 = 3 and θ3 = 5, and the vehicle capacity limit is Q = 5. In such case,
failure situation ω4 ↔(r2 = 1, r3 = 1) occurs, hence f (θ1, θ2, θ3) = ω4.
Assume now that MF mΘ
i , i = 1, . . . , N, on R is such that mΘ
i (Ai) = 1, with
Ai ⊆Θ, i.e., client demands are known imprecisely. In such case, it can only be
inferred that the failure situation on R belongs to the subset B ⊆Ω deﬁned as
(using a common abuse of notation for the image of a set)
B = f (A1, . . . , AN) =

(θ1,...,θN)∈A1×···×AN
f (θ1, . . . , θN) .
(4)
More generally, assume that MF mΘ
i , i = 1, . . . , N, have arbitrary numbers
of focal sets and that the joint probability of knowing only that demands of
customers i = 1, . . . , N, belong, respectively, to Ai ⊆Θ, i = 1, . . . , N, is equal to
N
i=1 mΘ
i (Ai) (this latter equality is not necessary in our approach, but it sim-
pliﬁes the exposition and corresponds to the case considered in our experiments
in Sect. 4). Then, uncertainty on the actual failure situation on R is represented
by a MF mΩ deﬁned as
mΩ(B) =

f(A1,...,AN)=B
N

i=1
mΘ
i (Ai).
(5)
Computing mΩ deﬁned by (5) involves evaluating f (A1, . . . , AN) for all
possible combinations of focal sets of MF mΘ
i , i = 1, . . . , N. Evaluating
f (A1, . . . , AN) for some Ai, i = 1, . . . , N, implies |A1| × · · · × |AN| (and thus at
worst QN) times the evaluation of function f at some point (θ1, . . . , θN) ∈ΘN.
Hence, computing Eq. (5) is generally intractable. Nonetheless, in the particular
and realistic case where the focal sets of MF mΘ
i , i = 1, . . . , N, are all inter-
vals of positive integers (which will be the case in our experiments in Sect. 4),
it becomes possible to compute f (A1, . . . , AN), and thus Eq. (5), with a much
more manageable complexity. This is detailed in the next section.
We remark that if evidential demands of all customers are Bayesian, then we
are actually dealing with a CVRPSD. In addition, mΩ is in this case Bayesian
on any given route R. Hence, the upper expected penalty cost C∗p(R) reduces to
the classical (probabilistic) expected value of cost function g with respect to the
probability mass function mΩ, and thus our recourse modelling of the CVRPED
clearly degenerates into the recourse modelling of the aforementioned CVRPSD.

196
N. Helal et al.
Finally, we showed in [7] that the constrained programming modelling of
CVRPED can be converted, in a particular case, into an equivalent CVRPSD
modelled via constrained programming, by transforming each evidential demand
represented by MF mi into a stochastic demand represented by probability mass
function pi such that pi(A) = mi(A), ∀A ⊆Θ, with A the greatest value in A.
It can be shown that under the recourse approach, this latter transformation
cannot be used in general to convert a CVRPED into an equivalent CVRPSD.
3.3
Interval Demands
Let us consider a route R with N customers, such that the demand of customer
i, i = 1, . . . , N, is known in the form of an interval of positive integers, which we
denote by [[Ai; Ai]], where Ai ≥1 and Ai ≤Q. In this case, as explained above,
the failure situation on R belongs to f

[[A1; A1]], . . . , [[AN; AN]]
	
⊆Ω. Hereafter,
we provide a method to eﬃciently compute f

[[A1; A1]], . . . , [[AN; AN]]
	
.
In a nutshell, this method consists in generating a rooted binary tree, which
represents synthetically yet exhaustively what can possibly happen on R in terms
of failure situations.
More precisely, this tree is based on the following remark. Suppose a vehicle
traveling along R and all that is known about its load when it arrives at the i-th
customer on R is that its load belongs to an interval [[q; q]]. Let us denote by qi
its load after visiting the i-th customer. Then, there are three exclusive cases:
1. either q + Ai ≤Q, hence there will surely be no failure at that customer and
all that is known is that qi ∈[[q; q]] + [[Ai; Ai]];
2. or q + Ai > Q, hence there will surely be a failure at that customer and all
that is known is that qi ∈[[q; q]] + [[Ai; Ai]] −Q;
3. or q + Ai ≤Q < q + Ai, hence it is not sure whether there will be or not a
failure at that customer. However, we can be sure that if there is no failure
at that customer, i.e., the sum of the actual vehicle load and of the actual
customer demand is lower or equal to Q, then it means that qi ∈[[q + Ai; Q]];
and if there is a failure at that customer, then it means that qi ∈[[1; q+Ai−Q]].
By applying the above reasoning repeatedly, starting from the ﬁrst customer
and ending at the last customer, whilst accounting for and keeping track of all
possibilities and their associated failures (or absence thereof) along the way, one
obtains a binary tree. The tree levels are associated to the customers according
to their order on R. The nodes at a level i represent the diﬀerent possibilities in
terms of imprecise knowledge about the vehicle load after the i-th customer, and
they also store whether these imprecise pieces of knowledge about the load were
obtained following a failure or an absence of failure at the i-th customer. The
pseudo code of the complete tree induction procedure is provided in Algorithm 1,
which is illustrated by Example 1.
Example 1. Let us illustrate Algorithm 1 on a route R where Q = 10 and con-
taining 3 customers, with [[4; 8]], [[5; 7]] and [[7; 9]] the imprecise demands of the

A Recourse Approach for the Capacitated Vehicle Routing Problem
197
Algorithm 1. Induction of Recourse Tree (RT)
Input: interval load [[q; q]], Boolean failure variable r, next customer number i
Output: ﬁnal tree T ree
1: create a root node containing interval load [[q; q]] and Boolean failure r
2: if i = N + 1 then
3:
return T ree = {root node}
4: else if q + Ai ≤Q then
5:
T reeL = RT ([[q; q]] + [[Ai; Ai]], 0, i + 1)
6:
attach T reeL as left branch of T ree
7: else if q + Ai > Q then
8:
T reeR = RT ([[q; q]] + [[Ai; Ai]] −Q, 1, i + 1)
9:
attach T reeR as right branch of T ree
10: else
11:
T reeL = RT ([[q + Ai; Q]], 0, i + 1)
12:
attach T reeL as left branch of T ree
13:
T reeR = RT ([[1; q + Ai −Q]], 1, i + 1)
14:
attach T reeR as right branch of T ree
15: end if
ﬁrst, second and third customers, respectively. Since the demand of the ﬁrst
customer is [[4; 8]], and there is no failure by deﬁnition at the ﬁrst customer,
and the customer following the ﬁrst customer is the second customer, the tree
is obtained with RT([[4; 8]], 0, 2) and is shown in Fig. 1.
Fig. 1. Recourse tree constructed for Example 1
For a given branch of the tree, by concatenating in a vector the Boolean
failure variable ri at level i, i = 2, . . . , N, we obtain the failure situation ωj ↔
(r2, r3, . . . , rN). Hence, all the branches of the tree yield the subset B ⊆Ω. For
instance, the rightmost branch of the tree in Fig. 1 yields the failure situation
(r2 = 1, r3 = 1) ↔ω4, the leftmost branch yields (r2 = 0, r3 = 1) ↔ω3 and the
remaining branch yields (r2 = 1, r3 = 0) ↔ω2. The tree in this example yields
thus the set B = {ω2, ω3, ω4}.
Proposition 1. The set B built using the tree generated by Algorithm 1 veriﬁes
B = f

[[A1; A1]], . . . , [[AN; AN]]
	
.
Worst-case complexity to obtain set B is O(2N−1) on a route R with N
clients, which is the maximum number of leaf nodes in the tree.

198
N. Helal et al.
4
Experiments
We used the CVRPED instances described in [7] and deriving from those of
Augerat set A for the CVRP [10]. These CVRPED instances are obtained as
follows. A customer deterministic demand ddet in the Augerat instances is trans-
formed into an evidential demand with associated MF mΘ deﬁned by
mΘ({ddet}) = α,
mΘ([[⌊ddet −γ · ddet⌋; ⌈ddet + γ · ddet⌉]]) = 1 −α,
(6)
where α ∈(0, 1) and γ ∈[0, 1]. This transformation corresponds to assuming
that the deterministic demand of each customer has been provided by a source,
which is reliable with probability α and approximately (at ±γ ∗100%) reliable
with probability 1 −α. In addition, we assumed that these latter sources have
independent probabilities of reliability.
Proposition 2. For any α, the upper expected cost of an optimal set of routes
for a CVRPED instance generated from a CVRP instance through transforma-
tion (6) and modelled via the recourse approach, is non decreasing in γ.
Proposition 2 basically shows that the more a decision maker is uncertain
(cautious) with respect to actual customer demands, i.e., the greater γ is, the
greater will be the (upper expected) cost of the optimal solution to his associated
optimisation problem. Proposition 2 also yields a lower bound on the cost of the
Table 1. Results of the simulated annealing algorithm for the CVRPED instances
Instance
Best cost Penalty
cost
Avg cost Stand. dev. Avg runtime Best cost γ = 0
A-n32-k5
843,06 0.03%
874,18
9,19
1837s
839,18
A-n33-k5
705,69 0.37%
724,11
8,39
2241s
697,12
A-n33-k6
773,55 0.75%
793,07
10,42
2271s
758,36
A-n34-k5
820,37 1.40%
837,04
9,19
2975s
812,16
A-n36-k5
884,51 0.34%
914,85
13,84
2715s
869,10
A-n37-k5
722,57 0%
753,51
12,86
2634s
720,85
A-n37-k6
1044,27 3.06%
1071,27
12,74
3111s
995,07
A-n38-k5
781,69 8.36%
816,67
18,44
4525s
748,64
A-n39-k5
890,88 1.57%
935,58
19
5068s
885,04
A-n39-k6
896,60 0.34%
916,91
16.11
3196s
884,09
A-n44-k6
1051,21 2.46%
1104,58
24,88
3922s
1019,07
A-n45-k6
1091,72 6.01%
1129,21
18,98
5444s
1006,90
A-n45-k7
1296,37 0.94%
1348,57
23,02
3237s
1246,14
A-n46-k7
1060,47 0.05%
1087,16
16
2865s
1045,93
A-n48-k7
1241,33 0.11%
1274,24
20,97
3119s
1227,79

A Recourse Approach for the Capacitated Vehicle Routing Problem
199
optimal solution to any CVPRED instance built using (6): it is obtained by
solving to optimality under the recourse approach the corresponding Augerat
set A instance, since such instance corresponds to setting γ = 0 in (6).
In order to solve CVRPED instances under the recourse approach, we
adapted a simulated annealing metaheuristic algorithm originally introduced
for CVRP in [6]. However, we do not describe this adaptation here due to space
limitation.
In our experiments, parameters α and γ of the CVRPED instances were set
arbitrarily to 0.8 and 0.1, respectively. Each instance was solved 30 times and
the best, average and standard deviation of costs are reported in Table 1. In
addition, the contribution of the expected penalty costs to the overall costs of
the best solutions is provided as percentages: as can be seen, it varies between
0% to 8%. Finally, the last column of Table 1 provides the best costs obtained
with our metaheuristic when solving CVRPED instances with γ = 0 - these costs
may be seen as an approximation of the lower bounds on the costs of the optimal
solutions of the CVPRED instances generated through transformation (6).
5
Conclusions
Belief function theory was used to represent uncertainty on customer demands
in the capacitated vehicle routing problem. We handled this problem by extend-
ing the recourse modelling approach of stochastic programming. In addition,
we provided a technique that makes computations tractable in realistic cases.
Instances of such cases were then solved using a simulated annealing algorithm.
Future works include studying more elaborate recourse policies and improving
the solving algorithm.
References
1. Birge, J.R., Louveaux, F.: Introduction to Stochastic Programming. Springer, New
York (1997)
2. Bodin, L.D., Golden, B.L., Assad, A.A., Ball, M.O.: Routing and scheduling of
vehicles and crews: the state of the art. Comput. Oper. Res. 10(2), 63–212 (1983)
3. Denoeux, T.: Analysis of evidence-theoretic decision rules for pattern classiﬁcation.
Pattern Recogn. 30(7), 1095–1107 (1997)
4. Dror, M., Laporte, G., Trudeau, P.: Vehicle routing with stochastic demands: prop-
erties and solution frameworks. Transport. Sci. 23(3), 166–176 (1989)
5. Gauvin, C., Desaulniers, G., Gendreau, M.: A branch-cut-and-price algorithm for
vehicule routing problem with stochastic demands. Comput. Oper. Res. 50, 141–
153 (2014)
6. Harmanani, H., Azar, D., Helal, N., Keirouz, W.: A simulated annealing algorithm
for the capacitated vehicle routing problem. In: 26th International Conference on
Computers and Their Applications, New Orleans, USA (2011)
7. Helal, N., Pichon, F., Porumbel, D., Mercier, D., Lef`evre, ´E.: The capacitated
vehicle routing problem with evidential demands: a belief-constrained program-
ming approach. In: Vejnarov´a, J., Kratochv´ıl, V. (eds.) BELIEF 2016. LNCS, vol.
9861, pp. 212–221. Springer, Cham (2016). doi:10.1007/978-3-319-45559-4 22

200
N. Helal et al.
8. Masri, H., Ben Abdelaziz, F.: Belief linear programming. Int. J. Approx. Reason.
51, 973–983 (2010)
9. Mourelatos, Z.P., Zhou, J.: A design optimization method using evidence theory.
J. Mech. Design 128, 901–908 (2006)
10. Vehicle Routing Data sets. http://www.coin-or.org/SYMPHONY/branchandcut/
VRP/data/index.htm. Accessed 20 Mar 2016
11. Shafer, G.: A Mathematical Theory of Evidence. Princeton University Press,
Princeton (1976)
12. Srivastava, R.K., Deb, K., Tulshyan, R.: An evolutionary algorithm based approach
to design optimization using evidence theory. J. Mech. Design 135(8), 081003-12
(2013)
13. Sungur, I., Ord´onez, F., Dessouky, M.: A robust optimization approach for the
capacitated vehicle routing problem with demand uncertainty. IIE Trans. 40, 509–
523 (2008)
14. Stewart Jr., W.R., Golden, B.L.: Stochastic vehicle routing: a comprehensive app-
roach. Eur. J. Oper. Res. 14(4), 371–385 (1983)

Evidential k-NN for Link Prediction
Sabrine Mallek1,2(B), Imen Boukhris1, Zied Elouedi1, and Eric Lefevre2
1 LARODEC, Institut Sup´erieur de Gestion de Tunis,
Universit´e de Tunis, Tunis, Tunisia
sabrinemallek@yahoo.fr, imen.boukhris@hotmail.com, zied.elouedi@gmx.fr
2 Univ. Artois, EA 3926, Laboratoire de G´enie Informatique et d’Automatique
de l’Artois (LGI2A), 62400 B´ethune, France
eric.lefevre@univ-artois.fr
Abstract. Social networks play a major role in today’s society, they
have shaped the unfolding of social relationships. To analyze networks
dynamics, link prediction i.e., predicting potential new links between
actors, is concerned with inspecting networks topology evolution over
time. A key issue to be addressed is the imperfection of real world social
network data which are usually missing, noisy, or partially observed.
This uncertainty is perfectly handled under the general framework of the
belief function theory. Here, link prediction is addressed from a super-
vised learning perspective by extending the evidential k-nearest neigh-
bors approach. Each nearest neighbor represents a source of information
concerning new links existence. Overall evidence is pooled via the belief
function theory fusion scheme. Experiments are conducted on real social
network data where performance is evaluated along with a compara-
tive study. Experiment results conﬁrm the eﬀectiveness of the proposed
framework, especially when handling skewness in data.
Keywords: Link prediction · Social network · Belief function theory ·
Information fusion · Evidential k-nearest neighbor · Supervised learning
1
Introduction
Link prediction (LP) is an important task in social network analysis and graph
mining that plays a major role in the understanding of network evolution. It is
a powerful tool with a wide variety of applications such as prediction of protein-
protein interactions in bioinformatics [3], construction of recommendation sys-
tems for e-commerce [11], detection of criminals or terrorist cells for security
applications [24] or users aid to form new connections in social networks [15]. The
main goal is to accurately predict the existence of new links between unlinked
entities given a state of the network.
Supervised machine learning techniques have been intensively applied to
LP. Many classiﬁcation models successfully addressed link prediction [4,9] (for
details, see [10]). Indeed, LP can be easily transformed into a two-class classiﬁ-
cation problem. Given a social network graph G(V, E) where V is the set nodes
c
⃝Springer International Publishing AG 2017
A. Antonucci et al. (Eds.): ECSQARU 2017, LNAI 10369, pp. 201–211, 2017.
DOI: 10.1007/978-3-319-61581-3 19

202
S. Mallek et al.
and E is the set of edges, one can partition the graph into two states by con-
sidering the edges that occurred at the time interval [t0, t1] as the training set
and those belonging to the time interval [t1, t2] as the test set. To this end, LP
is reformulated into a binary classiﬁcation problem by assigning class labels to
all pairs of nodes such that:
class(u, v|G) =

1
if uv ∈E
0
if uv /∈E
The most straightforward perception for LP is that similar nodes are likely to
connect. That is, the challenge is how to evaluate this similarity accurately. From
this point of view, we propose, in this paper, a framework that extends the k
nearest neighbor (k-NN) classiﬁcation approach to LP. We draw on the assump-
tion that query links that are similar to links present in the network are likely to
exist. Yet, the challenge is to evaluate the degree of support regarding the class
membership of the new links. Actually, information given by the nearest neigh-
bors cannot be considered completely trustworthy as a result of uncertainty and
imperfection in the data. As pointed out in [2], real-world networks especially,
the large scale ones, are characterized by shifting degrees of uncertainty. Besides,
data from real world applications are inherently uncertain, they are frequently
incomplete, noisy and sensitive to observation errors. In order to overcome data
imperfection issues, k-NN extensions under uncertainty theories have been pro-
posed. For example, fuzzy k-NN algorithm [14] is an extension of k-NN based on
fuzzy set theory [30]. It applies a fuzzy editing that alters the membership of each
training sample according to its k nearest neighbors. However, it does not allow
to model and deal with imprecise or incomplete information eﬀectively. Another
example would be the evidential k-NN (EKNN) [7] based on the belief function
theory (BFT) [6,25], a formal framework for reasoning under uncertainty that
permits to manage and model imprecise information accurately.
Obviously, dealing with uncertainty is relatively correlated to the deﬁnition
of fusion. It is important to determine the properties of objects and the relations
among multiple ones. Yet, one has to quantify the uncertainty regarding cer-
tain characteristics of an object and the likelihood with which we can say that
some elements are related. The BFT allows to carry out such fusion procedures.
Furthermore, it enables to pool evidence while being cautious to the sources’
reliability. The usage of the BFT to handle uncertainty in networks has been
strongly recommended in the literature [5,13,29]. In that regard, we extend, in
this paper, evidential k-NN proposed by [7] under the belief function framework
[6,25] to address link prediction. The proposed framework combines topological
properties and the intuition of the nearest neighbors approach. The similarity is
evaluated using structural metrics as features. Each nearest neighbor is consid-
ered as a distinct item of evidence supporting the class membership of the query
link. Finally, the overall evidence given by the k-nearest neighbors is fused using
the belief function theory combination tools.
This paper is organized as follows: in the next two sections, we recall related
work on link prediction and a brief background on the belief function theory.

Evidential k-NN for Link Prediction
203
In Sect. 4, our proposals for LP based on supervised learning under the belief
function theory framework are presented. In Sect. 5, we report the conducted
experiments to test the novel framework. Lastly, conclusions and possible future
work are drawn in Sect. 6.
2
Related Work on Link Prediction
According to [17], LP approaches can be roughly classiﬁed into three groups:
probabilistic models, maximum likelihood algorithms and similarity based meth-
ods [10]. The probabilistic models estimate the likelihood of links existence by
building a joint probability distribution representing the graph and applying
inference techniques. They are generally based on Markov Networks or Bayesian
Networks [8]. On the other hand, maximum likelihood approaches concentrate
on a given structure across the network (i.e. hierarchical structure, community
structure, etc.) and try to ﬁt the most likely structure through maximum likeli-
hood algorithms. Finally, similarity-based algorithms compute similarity scores
between the nodes based on some topological properties of the graph. These
scores can be easily employed under a supervised learning. They are generic as
they do not depend on the network domain and do not require an overall model.
Additionally, each similarity score is independent from the others which allows to
compute several ones separately and at the same time. They are the simplest of
LP algorithms in terms of computational cost. Actually, LP applies to networks
which are continuously evolving in size. In many cases, maximum likelihood and
probabilistic models cannot even be checked due the large structure of the net-
works. On that point, similarity-based methods are more convenient since they
do not only perform to large graphs but their performance is also impressive.
We presented, in previous works [18–21], LP approaches inspired from similarity-
based methods. However, the latter works are applicable to uncertain social net-
works i.e., edges are attached by uncertainty degrees regarding their existence.
They operate merely using the BFT tools. Our proposed framework, in this
paper, tackles LP under supervised learning. Furthermore, it applies to social
networks without encapsulated uncertainty in their structure.
The similarity-based methods use topological information of the networks.
This information is usually grouped into two types: local and global information.
The ﬁrst group of methods computes scores according to node-neighborhoods.
An example would be the common neighbors of two nodes [23]. The intuition
is that the more two nodes u and v share many common neighbors the more
likely they tend to connect. This makes sense in many real world networks such
as friendship networks, as two persons who have many mutual friends are very
likely to become friends. In contrast, global information methods employ prox-
imity in the network where two nodes are likely to connect if they are close in the
network in distance terms. An example of such algorithms would be the shortest
path between two nodes. Yet, these algorithms have higher computational com-
plexity since they require all the topological information which is frequently not
completely available. In this paper, we consider the node neighborhood based
metrics as they are simple and not costly in computational terms.

204
S. Mallek et al.
For a node u, let τ(u) be the set if its neighbors in the network, called ﬁrst
level neighbors or direct neighbors. The second level neighbors of u, denoted
τ(u)2, are the nodes connected to the direct neighbors of u. We recall here the
most popular local similarity scores that proved their eﬃciency in many works
from literature [15,23,31]:
– Common Neighbors (CN) [23] computes the common neighbors between a
pair of nodes (u, v).
– Jaccard Coeﬃcient (JC) [12] measures the ratio of the common neighbors of
u and v and all their neighbors.
– Adamic Adar measure (AA) [1] weights all common neighbors of the pair
(u, v) and penalizes the ones with high degrees.
– Resource Allocation (RA) [31] is inspired from the resource allocation process
of networks. For an unlinked pair of nodes (u, v), each common neighbor plays
the role of a transmitter of a single resource unit. As such, the similarity
between u and v is the amount of resource v collected from u.
– Preferential Attachment (PA) [23] assumes that the probability that a new
edge relate to u is proportional to |τ(u)|. Thus, the score of uv is correlated
to the number of neighbors of u and v.
Equations of the presented metrics are given in Table 1.
Table 1. Structural similarity measures based on local topological information between
the pair of nodes (u, v) where τ(u) and τ(v) are respectively their sets of neighbors in
the graph.
Common Neighbors (CN)
|τ(u) ∩τ(v)|
Adamic Adar (AA)

z∈(τ(u)∩τ(v))
1
log|τ(z)|
Jaccard Coeﬃcient (JC)
|τ(u)∩τ(v)|
|τ(u)∪τ(v)|
Resource Allocation (RA)

z∈(τ(u)∩τ(v))
1
|τ(z)|
Preferential Attachment (PA) |τ(u)| · |τ(v)|
In this paper, local topological metrics are combined with EKNN to evalu-
ate similarities for LP. A feature set is constructed using structural metrics to
determine the nearest neighbors according to a distance measure. The assets of
the belief function theory for information fusion are subsequently exploited to
pool the information gathered from the nearest neighbors. We present, in the
next section, some fundamental basic concepts of the BFT.
3
Background on the Belief Function Theory
In the belief function theory [6,25], a problem is represented by a frame of dis-
cernment Ω = {ω1, ω2, . . . , ωn}, an exhaustive and ﬁnite set of mutually exclusive

Evidential k-NN for Link Prediction
205
events. A basic belief assignment (bba), denoted by m, represents the knowledge
committed to the elements of 2Ω given a source of information. It is a mapping
function m : 2Ω →[0, 1], such that:

A⊆Ω
m(A) = 1
(1)
An element A is called a focal element of the bba m if m(A) > 0. The belief
committed to Ω represents the degree of ignorance. A state of total ignorance is
deﬁned by m(Ω) = 1. When the bba has at most one focal element A diﬀerent
from Ω, it said to be a simple support function (ssf) and has the following
form [26]:

m(A)
= 1 −ω
m(Ω)
= ω
(2)
for some A ⊂Ω and ω ∈[0, 1].
Combining two basic assignments induced from two distinct sources of infor-
mation over the same frame of discernment into one may be ensured using the
conjunctive rule of combination denoted by ∩⃝. It is deﬁned as [27]:
m1 ∩⃝m2(A) =

B,C⊆Ω:B∩C=A
m1(B) · m2(C)
(3)
The combination rule permits to aggregate evidence by meaningfully out-
lining a corpus of data and making it simpler. Furthermore, it allows to fuse
information induced from single and multiple sources.
4
Evidential k-nearest Neighbors for Link Prediction
The goal is to predict the existence of new links in a network graph G(V, E) where
V is the set of nodes and E is the set of edges. The set of classes is Ω = {E, ¬E},
where E points up the existence of a link in G and ¬E its absence. The class of
each link in E is assumed to be known with certainty. The available information
consists in a training set T = {(e1, ω1), . . . , (e|E|, ω|E|)} of single labeled links,
where ei ∈E, i ∈{0, . . . , |E|} and its corresponding class label is ωi ∈Ω.
Let e be a new link to be classiﬁed, where e may connect the pair of nodes
(u, v). Let L1 be the set of links shared with the direct (1st level) neighbors
of u and v in G, where |L1| = |τ(u)| + |τ(v)|. Additionally, let L2 be the set
of links unshared with the 2nd level neighbors of u and v in G, where |L2| =
|τ(u)2| + |τ(v)2|. The set L incorporates L1 and L2.
It is obvious that the class of the links in the set L1 is E. In contrast, the class
of the links in L2 is ¬E since it includes the links that are not shared between u
and v and their respective 2nd level neighbors. As follows, the nearest neighbors
of each unseen link are uncovered thought-out the neighborhood of its end points.
Accordingly, instead of comparing each unseen link with all the possible edges in
the network, which is computationally not feasible since there are (|V|×(|V|−1))
2

206
S. Mallek et al.
possible links, it is compared to the neighboring ones. As such, the search space
is reduced. Besides, the intuition of node neighborhood approaches is inherently
employed as they are exactly intended to ﬁnd similar nodes. In this context,
the authors in [28], proposed a framework for LP using k-NN by considering
the local similarity indexes to evaluate the similarity with the neighbors. The
prediction of an edge uv is made by comparing the neighbors of u to v and vice
versa. However, the proposed approach considers the nearest neighbors equally
trustworthy. Besides, only one similarity index is considered in k-NN at a time.
In our proposed framework, the evidential k-NN classiﬁer [7] operates in two
stages. First, it computes the distances between a test link e and its neighborhood
in L and retain the smallest k distances. Subsequently, the evidence given by
the k nearest neighbors is combined to get an overview about the global belief
regarding the existence of e. The steps are detailed in the following.
At ﬁrst, one has to determine the k nearest neighbors. For that, we need to
deﬁne a distance to evaluate the similarity between the edges in the test set and
those in the train set. We propose to use the Euclidean distance d(e, ei) between
the link e and its nearest neighbor ei ∈L by computing the similarities between
their connecting nodes as follows:
d(e, ei) =




n

j=1
(sj
e −sj
ei)2
(4)
where j is the index of a local similarity metric (e.g., CN, AA, JC, RA, PA),
se and sei are respectively its values for e and ei and n is the number of local
similarities considered.
Each link ei in L represents a piece of evidence that increases our belief
about e also belonging to ωi. Yet, this information solely does not provide certain
knowledge about the class of e. This situation is modeled in the BFT by simple
support functions where only some part of the belief is committed to ωi and the
rest is aﬀected to Ω. Therefore, we get the following bba:

mi({ωi}) = αφ(di)
mi(Ω) = 1 −αφ(di).
(5)
where di = d(e, ei), α is a parameter such that 0 < α < 1 and φ is a decreasing
function. The closer e is to ei according to the distance d, the more likely for e
to have same class as ei. In contrast, when e is far from ei, in distance terms,
then ei would provide little information regarding the class of e. On that point,
the function φ must verify φ(0) = 1 and limd→∞φ(d) = 0. Authors in [7] suggest
to use the following decreasing function:
φ(di) = e(−γdβ
i )
(6)
where γ > 0 and β ∈{1, 2, . . . }. β can be arbitrarily ﬁxed to a small value
(1 or 2).
As a result of considering each nearest neighbor in L as an independent source
of evidence regarding the class of the e, we obtain k bba’s that can be combined

Evidential k-NN for Link Prediction
207
using the conjunctive rule of combination. Thus, a global bba m that synthesizes
the belief regarding the existence of e is produced as follows:
m = m1 ∩⃝. . . ∩⃝mk
(7)
Finally, decision about the membership of e to one of the classes in Ω is made
by comparing m({E}) and m({¬E}). If m({E}) > m({¬E}) then e exists, it is
absent otherwise.
5
Experiments
Experiments are conducted on a real social network component of 1 K nodes and
10 K edges of the Facebook dataset from [22]. Since network data with time infor-
mation are not usually available, we must settle for the more drastic technique
by randomly removing a partition of the edges from the network in order to use
them as test set. That is, we remove a random 10% of the edges which we try
to predict the existence along with randomly generated false links of the same
size using the graph as a source composed by the remaining 90%. The results
are obtained by averaging over 10 implementations with independently random
divisions of testing set and training set. In order to reduce the computational
time, a preprocessing phase is ﬁrst conducted in which the local similarity scores
of all the links from the train and test sets are computed. Evaluation is made
according to accuracy which computes the number of correct predictions among
all predictions and the precision which takes the fraction of predicted links that
are relevant.
Required parameters are α, β, γ for the induced bba’s and the number of
nearest neighbors k. As discussed in [7], the parameters α and β do not have a
great inﬂuence on the approach performance. Thus, as in [7], α is ﬁxed to 0.95
and β to 1. We tested values of k ranging from 1 to 15. Tests for the optimization
of the γ parameter allowed us to set it to the value of 0.12. A comparison with
the standard k-NN method (KNN) is carried out, where the class of a link is
predicted according to the majority classes of its k nearest neighbors. The results
are reported in Fig. 1.
Figure 1 reports the results in terms of accuracy for diﬀerent values of k. It can
be seen that both methods have better performances as k increases. Indeed, as we
boost the number of nearest neighbors we get more sources of evidence regarding
the class membership of the links. Yet, as shown in Fig. 1, performance stops
upon reaching a certain threshold. Rather, by increasing excessively the number
of nearest neighbors, we get more distant ones (less similar). Consequently, the
associated mass functions are close to the state of total ignorance. Thus, they
have no impact in the combination and therefore in the prediction. The EKNN
based framework has better classiﬁcation performance than the standard KNN
based LP method. It stands to reason that, EKNN performs better for some
values of k as a results of taking implicitly the relevance of the information
given by the sources into account unlike KNN as it considers all the nearest

208
S. Mallek et al.
Fig. 1. Results according to the values of k
neighbors equally trustworthy. Although, the results are low for small values of
k, it still gives acceptable results i.e., 75% accuracy for k = 3.
In a second stage, we conduct implementations by increasing the number of
negative instances (non existing links) at each time to evaluate the behavior of
our algorithms to class imbalance scenarios. Actually, LP is a very imbalanced
class problem where the number of non existing links is much larger than the
existing ones. The same parameters speciﬁcations are considered except that
k is set to 15. Precision results are presented in Fig. 2 for diﬀerent negative
links number. Measuring precision is very important for evaluating LP since, in
many cases, the main goal is to accurately predict the real existing edges. For
example, in Facebook, it is more important to not miss actual friends and it
does not really matter when unknown friends are recommended. As shown in
Fig. 2, EKNN outperforms KNN for most values. Furthermore, the precision plot
decreases as more non existing edges are predicted. However, the curve does not
fall dramatically but rather slowly reaching 77% for 10 K false edges. These good
performances are also obtained thanks to the advantages of supervised learning
which permits to focus on class boundaries and balance data. As opposed to
unsupervised methods which cannot address this imbalance well because they are
agnostic to class distributions by nature [16]. We conjecture that our framework
is capable of dealing with the class imbalance problem. Furthermore, it allows
us to consider network topology and deal with uncertainty at the same time.

Evidential k-NN for Link Prediction
209
Fig. 2. Precision results for diﬀerent negative links number
6
Conclusion
Local similarity measures naturally operate to detect similar nodes which make
it simple to extend them to k-NN. In this paper, we propose a framework for
link prediction that combines structural local topological properties and the
evidential k-NN approach. Based on the direct and second level neighbors of
two unlinked nodes u and v, local similarity indexes are computed and used as
features to ﬁnd their k-nearest neighbors. These latter are considered as items
of evidence regarding the class membership of the link uv. Global evidence is
pooled using the conjunctive rule of combination from the belief function theory
to get an overall information abut new links existence. Tests on real world social
network data proved the eﬃciency of the proposed framework. It is interesting
to note that the novel framework handles skewness in social network data. It is
capable of combating class imbalance that characterizes the link prediction task.
Furthermore, it shows performance improvement over the baseline algorithm
KNN which does not take into account uncertainty in the analysis.
A straightforward direction for future research is to take supplementary
information into account such as node attributes. Obviously, nodes with sim-
ilar attribute values are likely to share social relationships i.e., two authors who
have the same aﬃliation and the same research ﬁelds. Besides, handling node
attributes brings semantics to social connections. Therefore, it is an important
source of information that may enhance the link prediction task.

210
S. Mallek et al.
References
1. Adamic, L.A., Adar, E.: Friends and neighbors on the web. Soc. Netw. 25(3),
211–230 (2003)
2. Adar, E., R´e, C.: Managing uncertainty in social networks. Data Eng. Bull. 30(2),
23–31 (2007)
3. Airoldi, E.M., Blei, D.M., Fienberg, S.E., Xing, E.P., Jaakkola, T.: Mixed member-
ship stochastic block models for relational data with application to protein-protein
interactions. In: Proceedings of the International Biometrics Society Annual Meet-
ing (2006)
4. Cukierski, W., Hamner, B., Yang, B.: Graph-based features for supervised link
prediction. In: Proceedings of International Joint Conference on Neural Networks,
pp. 1237–1244 (2011)
5. Dahlin, J., Svenson, P.: A method for community detection in uncertain networks.
In: Proceedings of the 2011 European Intelligence and Security Informatics Con-
ference, pp. 155–162 (2011)
6. Dempster, A.P.: Upper and lower probabilities induced by a multivalued mapping.
Ann. Math. Stat. 38, 325–339 (1967)
7. Denoeux, T.: A k-nearest neighbor classiﬁcation rule based on Dempster-Shafer
theory. IEEE Trans. Syst. Man Cybern. 25, 804–813 (1995)
8. Getoor, L., Taskar, B.: Introduction to Statistical Relational Learning. The MIT
Press, Cambridge (2007)
9. Hasan, M.A., Chaoji, V., Salem, S., Zaki, M.J.: Link prediction using supervised
learning. In: Proceedings of the 6th Workshop on Link Analysis, Counter Terrorism
and Security (2006)
10. Hasan, M.A., Zaki, M.J.: A survey of link prediction in social networks. In:
Aggarwal, C.C. (ed.) Social Network Data Analytics, pp. 243–275. Springer,
Newyork (2011)
11. Huang, Z., Li, X., Chen, H.: Link prediction approach to collaborative ﬁltering.
In: Proceedings of the 5th ACMIEEE-CS Joint Conference on Digital Libraries,
JCDL 2005, pp. 141–142. ACM (2005)
12. Jaccard, P.: ´Etude comparative de la distribution ﬂorale dans une portion des Alpes
et des Jura. Bulletin de la Soci´et´e Vaudoise des Sciences Naturelles 37, 547–579
(1901)
13. Johansson, F., Svenson, P.: Constructing and analyzing uncertain social networks
from unstructured textual data. In: ¨Ozyer, T., Erdem, Z., Rokne, J., Khoury, S.
(eds.) Mining Social Networks and Security Informatics. Lecture Notes in Social
Networks, pp. 41–61. Springer, Dordrecht (2014)
14. Keller, J.M., Gray, M.R., Givens, J.A.: A fuzzy k-nearest neighbor algorithm. IEEE
Trans. Syst. Man Cybern. SMC–15(4), 580–585 (1985)
15. Liben-Nowell, D., Kleinberg, J.: The link prediction problem for social networks.
J. Am. Soc. Inf. Sci. Technol. 58(7), 1019–1031 (2007)
16. Lichtenwalter, R.N., Lussier, J.T., Chawla, N.V.: New perspectives and methods
in link prediction. In: Proceedings of the 16th ACM SIGKDD International Con-
ference on Knowledge Discovery and Data Mining, pp. 243–252 (2010)
17. Lu, L., Zhou, T.: Link prediction in complex networks: a survey. Phys. A 390(6),
1150–1170 (2011)
18. Mallek, S., Boukhris, I., Elouedi, Z., Lefevre, E.: Evidential link prediction based on
group information. In: Prasath, R., Vuppala, A.K., Kathirvalavakumar, T. (eds.)
MIKE 2015. LNCS, vol. 9468, pp. 482–492. Springer, Cham (2015). doi:10.1007/
978-3-319-26832-3 45

Evidential k-NN for Link Prediction
211
19. Mallek, S., Boukhris, I., Elouedi, Z., Lefevre, E.: The link prediction problem under
a belief function framework. In: Proceedings of the IEEE 27th International Con-
ference on the Tools with Artiﬁcial Intelligence, pp. 1013–1020 (2015)
20. Mallek, S., Boukhris, I., Elouedi, Z., Lefevre, E.: An evidential method for multi-
relational link prediction in uncertain social networks. In: Proceedings of the 5th
International Symposium on Integrated Uncertainty in Knowledge Modelling and
Decision Making, pp. 280–292 (2016)
21. Mallek, S., Boukhris, I., Elouedi, Z., Lefevre, E.: Evidential missing link prediction
in uncertain social networks. In: Proceedings of the 16th International Conference
on Information Processing and Management of Uncertainty in Knowledge-Based
Systems, pp. 274–285 (2016)
22. McAuley, J.J., Leskovec, J.: Learning to discover social circles in ego networks.
In: Proceedings of the 26th Annual Conference on Neural Information Processing
Systems 2012, pp. 548–556 (2012)
23. Newman, M.E.J.: Clustering and preferential attachment in growing networks.
Phys. Rev. E 64, 025102 (2001)
24. Rhodes, C.J., Jones, P.: Inferring missing links in partially observed social net-
works. JORS 60(10), 1373–1383 (2009)
25. Shafer, G.R.: A Mathematical Theory of Evidence. Princeton University Press,
Princeton (1976)
26. Smets, P.: The canonical decomposition of a weighted belief. In: Proceedings of the
Fourteenth International Joint Conference on Artiﬁcial Intelligence, IJCAI 1995,
vol. 14, pp. 1896–1901 (1995)
27. Smets, P.: Application of the transferable belief model to diagnostic problems. Int.
J. Intell. Syst. 13(2–3), 127–157 (1998)
28. Speegle, G., Bai, Y., Cho, Y.R.: Extending local similarity indexes with knn for link
prediction. In: Proceedings of the 14th International Conference on Computational
Science and Its Applications, ICCSA 2014, pp. 1–7 (2013)
29. Svenson, P.: Social network analysis of uncertain networks. In: Proceedings of the
2nd Sk¨ovde Workshop on Information Fusion Topics (2008)
30. Zadeh, L.: Fuzzy sets. Inf. Control 8(3), 338–353 (1965)
31. Zhou, T., L¨u, L., Zhang, Y.: Predicting missing links via local information. Eur.
Phys. J. B-Condens. Matter Complex Syst. 71(4), 623–630 (2009)

Ensemble Enhanced Evidential k-NN Classiﬁer
Through Random Subspaces
Asma Trabelsi1,2(B), Zied Elouedi1, and Eric Lefevre2
1 Universit´e de Tunis, Institut Sup´erieur de Gestion de Tunis, LARODEC,
Tunis, Tunisia
trabelsyasma@gmail.com, zied.elouedi@gmx.fr
2 Univ. Artois, EA 3926, Laboratoire de G´enie Informatique et d’Automatique de
l’Artois (LGI2A), 62400 B´ethune, France
eric.lefevre@univ-artois.fr
Abstract. The process of combining an ensemble of classiﬁers has been
deemed to be an eﬃcient way for improving the performance of sev-
eral classiﬁcation problems. The Random Subspace Method, that con-
sists of training a set of classiﬁers on diﬀerent subsets of the feature
space, has been shown to be eﬀective in increasing the accuracy of clas-
siﬁers, notably the nearest neighbor one. Since, in several real world
domains, data can also be suﬀered from several aspects of uncertainty,
including incompleteness and inconsistency, an Enhanced Evidential k-
Nearest Neighbor classiﬁer has been recently introduced to deal with the
uncertainty pervading both the attribute values and the classiﬁer outputs
within the belief function framework. Thus, in this paper, we are based
primarily on the Enhanced Evidential k-Nearest Neighbor classiﬁer to
construct an ensemble pattern classiﬁcation system. More precisely, we
adopt the Random Subspace Method in our context to build ensemble
classiﬁers with imperfect data.
Keywords: Classiﬁer ensemble · Random Subspace Method · Enhanced
evidential k-NN · Belief function theory
1
Introduction
The core purpose of an ensemble classiﬁer is to achieve a high accuracy for a
given classiﬁcation problem. The process of building an ensemble learning con-
sists ﬁrstly of generating a set of base/weak classiﬁers from the training data and
then perform actual classiﬁcation by combining the output predictions of base
classiﬁers. To gain a better accuracy, the basic classiﬁers should be diverse and
independent [13]. Several ensemble classiﬁer generation methods allow to achieve
diversity among the base classiﬁers. Bagging [3] and Boosting [18] are widely used
as ensemble methods but some authors have proven that these two techniques
are not guaranteed to produce fully independent individual base classiﬁers [5].
Both theoretical and experimental researches conducted by the machine learn-
ing community have shown that the eﬃcient method for achieving a good diver-
sity consists of training the base classiﬁers on diﬀerent feature subsets [4,24].
c
⃝Springer International Publishing AG 2017
A. Antonucci et al. (Eds.): ECSQARU 2017, LNAI 10369, pp. 212–221, 2017.
DOI: 10.1007/978-3-319-61581-3 20

Ensemble Enhanced Evidential k-NN Classiﬁer Through Random Subspaces
213
This may be explained by the fact that a feature subset-based ensemble can
reduce the correlation among the classiﬁers and also perform faster owing to the
reduced size of input features [4,8,11]. The key problem of this kind of ensemble
learning is how to yield attribute subsets with good predicting power. Several
feature subsets techniques have been introduced till now where some of which
are based on ﬁlter approaches [17], while others are relied on wrapper approaches
[12]. Another more popular and eﬀective tool is the Random Subspace Method
(RSM) also called random subspacing [19] and has satisfactory yielded results
particulary with the standard k-Nearest Neighbor classiﬁer (k-NN) [2]. In this
paper, we have to adapt the random subspace method in the real context of
uncertain data. Precisely, we propose to design a classiﬁer ensemble via random
subspacing on the basis of the Enhanced Evidential k-NN (EEk-NN) classiﬁer,
which is proposed in [23], as a new technique for dealing with uncertain data
represented within the belief function framework. The reminder of this paper is
organized as follows: Sect. 2 is committed to highlighting the fundamental con-
cepts of the belief function theory. In Sect. 3, we present the EEk-NN classiﬁer
that handles evidential databases. Section 4 is dedicated to describing our pro-
posed ensemble classiﬁer through random subspaces. Our experimentation on
several synthetic databases is conducted in Sect. 5. Finally, the conclusion and
our main future work directions are reported in Sect. 6.
2
Belief Function Theory: Background
The belief function theory, also referred to as evidence theory, is widely regarded
as very eﬀective and eﬃcient basis for representing, managing and reasoning
about uncertain knowledge. This section brieﬂy reviews some important concepts
underlying this theory.
2.1
Information Representation
Let Θ = {θ1, θ2, . . . , θN} denote the frame of discernment including a ﬁnite non
empty set of N elementary hypotheses that are assumed to be exhaustive and
mutually exhaustive. The power set of Θ, denoted by 2Θ, is made up of all the
subsets of Θ:
2Θ = {∅, θ1, θ2, . . . , θN, . . . , Θ}
(1)
Expert’s beliefs over the subsets of the frame of discernment Θ are repre-
sented by the so-called basic belief assignment (bba) denoted by m. It is carried
out in the following manner:

A⊆Θ
m(A) = 1
(2)
Each subset A of 2Θ having fulﬁlled m(A) > 0 is called a focal element.

214
A. Trabelsi et al.
2.2
Combination Operators
For certain real world problems, we are clearly confronted with information
issued from several sources. Therefore, a number of combination rules has been
proposed and discussed for some past time. The conjunctive rule, introduced
by Smets within the Transferable Belief Model (TBM) [21], is one of the best
known ones. Given two information sources S1 and S2 with respectively m1 and
m2 as bbas, the conjunctive rule, denoted by ∩⃝, was established as follows:
m1 ∩⃝m2(A) =

B∩C=A
m1(B)m2(C),
∀A ⊆Θ.
(3)
The belief completely associated to the empty set was recognised under the
name of conﬂictual mass. A normalized version of the conjunctive rule has been
proposed by Dempster [6] to retain the basic characteristics of the belief function
theory. Indeed, it allows to manage the conﬂict while redistributing the conﬂict-
ual mass over all focal elements. The Dempster rule is then set as follows:
m1 ⊕m2(A) =
1
1 −K

B∩C=A
m1(B)m2(C),
∀A ⊆Θ
(4)
where the conﬂictual mass K caused by the combination of the two bbas m1
and m2 through the conjunctive rule, is given as follows:
K =

B∩C=∅
m1(B)m2(C)
(5)
2.3
Decision Making
The pignistic probability, denoted by BetP, has been proven to be an eﬀective
and eﬃcient decision-making tool for selecting the most likely hypothesis rela-
tive to a given problem [20]. It consists of transforming beliefs into probability
measures as follows:
BetP(A) =

B∩A=∅
|A ∩B|
|B|
m(B),
∀A ∈Θ
(6)
The hypothesis Hs that has to be chosen is the one with the highest pignistic
probability:
Hs = argmaxABetP(A),
∀A ∈Θ
(7)
2.4
Dissimilarity Between bbas
In the research literature, several measures have been proposed to compute the
degree of dissimilarity between two given bbas [10,16,22]. One of the earliest

Ensemble Enhanced Evidential k-NN Classiﬁer Through Random Subspaces
215
and best-known measures is the Jousselme distance. Formally, the Jousselme
distance, for two given bbas m1 and m2, is deﬁned by:
dist(m1, m2) =

1
2(m1 −m2)T D(m1 −m2)
(8)
where the Jaccard similarity measure D is set to:
D(X, Y ) =
⎧
⎨
⎩
1
if X = Y = ∅
|X ∩Y |
|X ∪Y |
∀X, Y ∈2Θ
(9)
3
Nearest Neighbor Classiﬁers for Uncertain Data
Data uncertainty is regarded as one of the main issues of several real world
applications that can aﬀect experts’ decisions. Two levels of uncertainty can be
distinguished in the literature: the uncertainty that occurs in the attribute val-
ues and the one pervading the class labels. The process of constructing classiﬁers
from totally uncertain data has not received the great attention till now. Drawing
inspiration from the Evidential theoretic k-NN that incorporates classiﬁer out-
puts uncertainties [7,9], we have proposed an EEk-NN classiﬁer for handling not
only the uncertainty associated with the classiﬁer outputs but also that pervad-
ing the data, precisely the attribute values. Suppose we have to solve an M class
classiﬁcation problem. Let us denote by X = {xi = (xi
1, ..., xi
n); Li|i = 1, ..., N}
a collection on N n-dimensional training samples where each one is character-
ized by n uncertain attribute values xi
j (j ∈{1, . . . , n}) represented within the
belief function framework and a class label Li demonstrating its membership to
a speciﬁc class in Θ = {θ1, . . . , θM}. Assume that y = {y1, . . . , yn} be a new
query pattern to be classiﬁed on the basis of the training set X. The major idea
underlying our proposed classiﬁer is to compute the distance dy,i between the
query pattern y and each instance xi ∈X that corresponds to the sum of the
absolute diﬀerences between the attribute values as follows:
dy,i =
n

j=1
dist(xi
j, yj)
(10)
Particulary, we have relied on the Jousselme distance measure dist (see Eq. 8)
for processing the uncertainty that characterizes the attribute values. It must be
emphasised that dy,i can have values comprised within the range of from 0 to
1. A value of dy,i which is too small involves the situation that the instances y
and xi are described by the same class label Li. In contrast, a high value of dy,i
implies the situation of almost complete ignorance with regard to the class label
of y. As a matter of fact, the uncertainty pervading the class label of the query
pattern y can be modeled and represented within the belief function theory.
Assume that the training instances are sorted in ascending order according to

216
A. Trabelsi et al.
their distance from the test instance y, each training instance xi ∈X provides
an item of evidence denoted by m(i)(.|xi) over Θ:
m(i)({θq}|xi) = αΦq(dy,i)
(11)
m(i)(Θ|xi) = 1 −αΦq(dy,i)
m(i)(A|xi) = 0, ∀A ∈2Θ\{Θ, θq}
where the distance function dy,i should be calculated such as in Eq. 8, θq refers
to the class label of xi and α is a parameter satisfying 0 < α < 1. It has been
proven that a value of α equal to 0.95 can lead to satisfactory or better outcomes
[7]. The decreasing function Φq, checking Φq(0) = 1 and limd→∞Φq(d) = 0, will
be given as follows:
Φq(d) = exp(−γqd2),
(12)
where γq displays a positive parameter of class θq. It can be optimized depending
on the training samples. An exact method relied on a gradient search procedure
can be used for small or medium data sets, while using a linearization approach
for large data [25]. The best values of γq, for both exact and approximated
methods, can be estimated by minimizing the mean squared classiﬁcation error
over the whole training set X of size N.
The ﬁnal bba my regarding the class membership of the query pattern y
can be obtained by merging the bbas issued from k nearest neighbors training
instances of y through the Dempster rule of combination. The ﬁnal bba will be
deﬁned as follows:
my = m(1)(.|x1) ⊕m(2)(.|x2) ⊕. . . ⊕m(k)(.|xk)
(13)
The class label concerning the test pattern y, will be made by computing the
pignistic probability BetP of the bba my as shown in Eq. 6. The query pattern
y is then assigned to the class label with the highest pignistic probability.
4
Ensemble Enhanced Evidential k-NN (Ensemble
EEk-NN)
As already mentioned, the concept of diversity is regarded as a vital necessity
for the ultimate success of ensemble classiﬁer systems. Note however, that in
this context, the RSM is a widely used technique addressed to ensure diversity
between individual classiﬁers and has achieved satisfactory results notably for
the ensembles of Evidential theoretic k-NNs [1]. Despite their relevance and suc-
cess, such kind of ensemble systems cannot handle imperfect data, especially the
uncertain ones. Get inspired from [1], in this paper, we propose a new ensemble
system that fully beneﬁts from the advantages of both RSM and EEk-NN. Our
proposed ensemble classiﬁcation system deals mainly with uncertain data where
the uncertainty occurs precisely in the attribute values and is represented within
the belief function framework. The suggested model is generally characterised

Ensemble Enhanced Evidential k-NN Classiﬁer Through Random Subspaces
217
by three main steps. Given a training data X, the ﬁrst level concerns the gener-
ation of T feature subsets with size S from a uniform distribution over X. In the
second level, the output label of each query pattern will be predicted through T
EEk-NN classiﬁers that are trained with the diﬀerent generated feature subsets.
The ﬁnal stage concerns the combination of the predictions yielded by the diﬀer-
ent classiﬁers. Let us remind that the output label of each individual classiﬁer is
expressed in terms of a mass function. The belief function theory has also been
proven to be an eﬃcient way for merging an ensemble of classiﬁers where each
of which produces a belief function for each query instance. Diﬀerent combina-
tion rules have been implemented within this framework and can be categorized
according to the dependency between the merged sources. In this paper, we ulti-
mately opted for the Dempster operator, which is the conventionally used rule
within the belief function theory, for combining diverse classiﬁers.
Two substantial parameters need to be considered for our proposed
framework:
– The number of created classiﬁers: A substantial key element when
designing an ensemble classiﬁers is the number of individual classiﬁers used to
get the ﬁnal decision. There is no doubt that a huge number of classiﬁers may
in the one hand increase the computational complexity and on the other hand
decrease the comprehensibility. Several researches have been done to prede-
ﬁne a reasonable number of classiﬁers. The conclusion conducted following to
the study of [15] shows that ensembles of 25 k-NN classiﬁers are suﬃcient for
reducing the error rate and consequently for improving performance. For that
very reason, in this paper, we set the number of combined EEk-NN classiﬁers
to 25.
– The size of feature subsets S: The choice of the appropriate size of fea-
ture subsets is still being studied. Since a small subspace size can make the
algorithm even faster, the chance to fall into missing informative features or
also missing correlation between several features can ever be strong enough.
To address that challenge, in this paper, we will randomly select the subspace
size, relative to each individual EEk-NN classiﬁer, in the range [n/3; 2n/3],
which means that at least one-third and at most two-thirds of the original
feature set will be used to train each component classiﬁer (i.e. the subspace
size S varies from one classiﬁer to another).
5
Experimentations
This section is devoted to studying the performance improvements of our Ensem-
ble EEk-NN classiﬁer in random subspaces compared with that in full feature
space. Our comparative study will mainly be based on the percentage of correct
classiﬁcation (PCC) criterion. In what follows, we elaborate our experimentation
settings (Sect. 5.1) and our experimentation results (Sect. 5.2).

218
A. Trabelsi et al.
5.1
Experimentation Settings
Since we are dealing speciﬁcally with uncertain knowledge, we have generated
several synthetic databases while injecting a degree of uncertainty P, having
values comprised within the range [0, 1], to some well−known real data sets
obtained from the UCI machine learning repository [14]. Table 1 provides a short
description of the diﬀerent tested databases where #Instances, #Attributes and
#Classes denote, respectively, the number of instances, the number of attributes
and the number of classes. Four uncertainty levels have been considered in this
paper: certain case (P = 0), low uncertainty case (0 < P < 0.4), middle uncer-
tainty case (0.4 ≤P < 0.7) and high uncertainty case (0.7 ≤P ≤1).
Table 1. Description of databases
Databases
#Instances #Attributes #Classes
Voting Records 435
16
2
Heart
267
22
2
Monks
195
23
2
Lymphography
148
18
4
Audiology
226
69
24
Let D be a given database described by N instances xi (i ∈{1, . . . , N}) and
n attributes xi
j (j ∈{1, . . . , n}). Let Θj be the frame of discernment associated
to the attribute j. Suppose that |Θj| is the cardinality of Θj, every attribute
value vi
j,t relative to an instance xi such that vi
j,t ⊆Θj (t ∈{1, . . . , |Θj|}) will
be represented through the belief function framework as follows:
mΘj{xi}(vi
j,t) = 1 −P
(14)
mΘj{xi}(Θj) = P
5.2
Experimentation Results
To assesses our model performance, we have undertaken the 10-fold cross vali-
dation strategy. This technique splits randomly the treated data into ten equal
sized parts where nine part is used as a training set and the remaining as test-
ing sets. A major key issue in our proposed approach is related to the number
of neighbors that may give satisfactory results, in our current experimentation
tests, we evaluate ﬁve values of the nearest neighbors k which respectively cor-
respond to 1, 3, 5, 7 and 9. The PCC results are given from Tables 2, 3, 4, 5
and 6.
According to the results given from Tables 2, 3, 4, 5 and 6, we can deduce
that ensembles of the EEk-NN classiﬁer through random subspacing has led
to interesting results compared to the individual EEk-NN classiﬁers that are

Ensemble Enhanced Evidential k-NN Classiﬁer Through Random Subspaces
219
Table 2. Results for Heart database (%)
k = 1
k = 3
k = 5
k = 7
k = 9
EEk-
NN
Ensemble
EEk-NN
EEk-
NN
Ensemble
EEk–NN
EEk-
NN
Ensemble
EEk-NN
EEk-
NN
Ensemble
EEk–NN
EEk–
NN
Ensemble
EEk–NN
No
61.15
67.30
63.84
70.38
67.30
68.07
70
70.03
71.15
71.23
Low
58.46
68.84
64.23
66.15
66.92
69.23
68.07
68.07
79.03
78.24
Middle 60
69.23
63.07
65.38
66.15
67.69
69.61
67.30
68.07
67.69
High
63.84
68.46
63.07
65.76
66.36
66.53
70.76
71.13
69.61
70.03
Table 3. Results for Vote Records database (%)
k = 1
k = 3
k = 5
k = 7
k = 9
EEk-
NN
Ensemble
EEk-NN
EEk-
NN
Ensemble
EEk–NN
EEk-
NN
Ensemble
EEk-NN
EEk-
NN
Ensemble
EEk–NN
EEk–
NN
Ensemble
EEk–NN
No
92.79
92.05
92.32
92.65
93.02
92.32
93.72
94.01
93.72
92.81
Low
92.09
93.14
93.02
93.65
92.55
93.24
93.25
94.25
93.25
94.78
Middle 91.62
92.79
91.39
92.56
91.39
93.12
91.86
92.94
92.32
94.16
High
84.18
87.20
87.67
88.60
88.60
89.30
89.30
86.97
89.76
91.86
Table 4. Results for Monks database (%)
k = 1
k = 3
k = 5
k = 7
k = 9
EEk-
NN
Ensemble
EEk-NN
EEk-
NN
Ensemble
EEk–NN
EEk-
NN
Ensemble
EEk-NN
EEk-
NN
Ensemble
EEk–NN
EEk–
NN
Ensemble
EEk–NN
No
72
73.13
59.81
60.26
60.54
61.68
70
69.03
79.81
80.45
Low
69.63
71.01
58.18
59.49
63.63
94.16
70.90
70.65
76.54
77.88
Middle 68.9
69.85
63.81
64.23
66.72
68.9
71.09
72.84
70.72
72.13
High
54.90
56.14
53.09
53.68
52.54
52.03
52.72
53.26
54.18
55.36
Table 5. Results for Audiology database (%)
k = 1
k = 3
k = 5
k = 7
k = 9
EEk-
NN
Ensemble
EEk-NN
EEk-
NN
Ensemble
EEk–NN
EEk-
NN
Ensemble
EEk-NN
EEk-
NN
Ensemble
EEk–NN
EEk–
NN
Ensemble
EEk–NN
No
63.18
64.22
60.45
60.67
52.72
53.16
50.45
51.26
44.54
45.22
Low
52.72
52.98
55.45
55.67
53.63
53.87
47.27
47.56
45.9
46.81
Middle 52.72
53.24
48.18
47.84
44.54
44.22
41.13
42.76
40.45
41.68
High
15.45
14.49
23.18
24.01
21.36
22.45
22.27
23.46
18.18
18.96
Table 6. Results for Lymphography database (%)
k = 1
k = 3
k = 5
k = 7
k = 9
EEk-
NN
Ensemble
EEk-NN
EEk-
NN
Ensemble
EEk–NN
EEk-
NN
Ensemble
EEk-NN
EEk-
NN
Ensemble
EEk–NN
EEk–
NN
Ensemble
EEk–NN
No
84.28
84.51
85
85.07
62.42
63.45
85.71
86.25
85
85.42
Low
80
81.12
85.71
86.13
83.57
82.56
86.42
81.17
85.71
86.96
Middle 82.14
82.42
84.28
83.96
86.42
87.22
84.28
85.14
82.14
83.27
High
58.57
58.63
61.42
62.19
59.28
61.02
58.57
59.13
65.71
66.48

220
A. Trabelsi et al.
learnt with the full feature space. In fact, the PCC yielded by an ensemble of
classiﬁers is generally better than that yielded by an individual classiﬁer for
the most of cases. For instance, let us consider k equals 5, the PCC results
yielded by the ensemble system on the Heart database with No, Low, Middle and
High uncertainties are respectively equal to 67.30%, 66.92%, 66.15% and 66.36%.
However, there are equal to 68.07%, 69.23%, 67.69% and 66.53% when using an
individual system. This small diﬀerence may be explained by the existence of
irrelevant and redundant features as a consequence of the random method.
6
Conclusion
In this paper, we have proposed an ensemble EEk-NN classiﬁer through random
subspaces with the aim of increasing the classiﬁcation performance for a given
classiﬁcation problem. For assessing the performance of our proposed approach,
we have carried out a comparative study between the ensemble EEk-NN classiﬁer
in random subspaces and that in full feature space when relied on the PCC
assessment criterion. Although the RSM method can unfortunately increase the
risk that irrelevant and redundant features may be part of the selected subsets,
numerical results have shown that ensemble EEk-NN classiﬁers have contributed
to somewhat more favorable PCC results for the diﬀerent mentioned databases.
To promote better and more eﬀective classiﬁcation performance, in our future
studies and research projects, we look forward to solutions allowing to produce
the best possible feature subsets.
References
1. Altın¸cay, H.: Ensembling evidential k-nearest neighbor classiﬁers through multi-
modal perturbation. Appl. Soft Comput. 7(3), 1072–1083 (2007)
2. Bay, S.D.: Combining nearest neighbor classiﬁers through multiple feature subsets.
In: 15th International Conference on Machine Learning, vol. 98, pp. 37–45 (1998)
3. Breiman, L.: Bagging predictors. Mach. Learn. 24(2), 123–140 (1996)
4. Bryll, R., Gutierrez-Osuna, R., Quek, F.: Attribute bagging: improving accuracy
of classiﬁer ensembles by using random feature subsets. Pattern Recogn. 36(6),
1291–1302 (2003)
5. Cho, S.B., Won, H.-H.: Cancer classiﬁcation using ensemble of neural networks
with multiple signiﬁcant gene subsets. Appl. Intell. 26(3), 243–250 (2007)
6. Dempster, A.P.: Upper and lower probabilities induced by a multivalued mapping.
Ann. Math. Stat. 38, 325–339 (1967)
7. Denoeux, T.: A k-nearest neighbor classiﬁcation rule based on Dempster-Shafer
theory. IEEE Trans. Syst. Man Cybern. 25(5), 804–813 (1995)
8. G¨unter, S., Bunke, H.: Feature selection algorithms for the generation of multiple
classiﬁer systems and their application to handwritten word recognition. Pattern
Recogn. Lett. 25(11), 1323–1336 (2004)
9. Jiao, L., Denœux, T., Pan, Q.: Evidential editing K-nearest neighbor classiﬁer. In:
Destercke, S., Denoeux, T. (eds.) ECSQARU 2015. LNCS, vol. 9161, pp. 461–471.
Springer, Cham (2015). doi:10.1007/978-3-319-20807-7 42

Ensemble Enhanced Evidential k-NN Classiﬁer Through Random Subspaces
221
10. Jousselme, A., Grenier, D., Boss´e, E.: A new distance between two bodies of evi-
dence. Inf. Fusion 2(2), 91–101 (2001)
11. Kim, Y.: Toward a successful crm: variable selection, sampling, and ensemble.
Decis. Support Syst. 41(2), 542–553 (2006)
12. Kohavi, R., John, G.H.: Wrappers for feature subset selection. Artif. Intell.
97(1–2), 273–324 (1997)
13. Kuncheva, L., Skurichina, M., Duin, R.P.: An experimental study on diversity for
bagging and boosting with linear classiﬁers. Inf. Fusion 3(4), 245–258 (2002)
14. Murphy, P., Aha, D.: UCI repository databases (1996). http://www.ics.uci.edu/
mlear
15. Opitz, D., Maclin, R.: Popular ensemble methods: an empirical study. J. Artif.
Intell. Res. 11, 169–198 (1999)
16. Ristic, B., Smets, P.: The TBM global distance measure for the association of
uncertain combat id declarations. Inf. Fusion 7(3), 276–284 (2006)
17. S´anchez-Maro˜no, N., Alonso-Betanzos, A., Tombilla-Sanrom´an, M.: Filter methods
for feature selection – a comparative study. In: Yin, H., Tino, P., Corchado, E.,
Byrne, W., Yao, X. (eds.) IDEAL 2007. LNCS, vol. 4881, pp. 178–187. Springer,
Heidelberg (2007). doi:10.1007/978-3-540-77226-2 19
18. Schapire, R.E.: The boosting approach to machine learning: an overview. In:
Denison, D.D., Hansen, M.H., Holmes, C.C., Mallick, B., Yu, B. (eds.) Nonlin-
ear Estimation and Classiﬁcation. LNS, vol. 171, pp. 149–171. Springer, New York
(2003). doi:10.1007/978-0-387-21579-2 9
19. Skurichina, M., Duin, R.P.: Bagging, boosting and the random subspace method
for linear classiﬁers. Pattern Anal. Appl. 5(2), 121–135 (2002)
20. Smets, P.: Decision making in the TBM: the necessity of the pignistic transforma-
tion. Int. J. Approximate Reasoning 38(2), 133–147 (2005)
21. Smets, P., Kennes, R.: The transferable belief model. Artif. Intell. 66(2), 191–234
(1994)
22. Tessem, B.: Approximations for eﬃcient computation in the theory of evidence.
Artif. Intell. 61(2), 315–329 (1993)
23. Trabelsi, A., Elouedi, Z., Lefevre, E.: A novel k-nn approach for data with uncertain
attribute values. In: 30th International Conference on Industrial, Engineering and
other Applications of Applied Intelligent Systems. Springer (2017, to appear)
24. Tumer, K., Ghosh, J.: Classiﬁer combining: analytical results and implications.
In: Proceedings of the National Conference on Artiﬁcial Intelligence, pp. 126–132
(1996)
25. Zouhal, L.M., Denoeux, T.: An evidence-theoretic k-nn rule with parameter opti-
mization. IEEE Trans. Syst. Man Cybern. Part C (Appl. Rev.) 28(2), 263–271
(1998)

Conditionals

Comparison of Inference Relations Deﬁned
over Diﬀerent Sets of Ranking Functions
Christoph Beierle(B) and Steven Kutsch
Department of Computer Science, University of Hagen, 58084 Hagen, Germany
christoph.beierle@fernuni-hagen.de
Abstract. Skeptical inference in the context of a conditional knowledge
base R can be deﬁned with respect to a set of models of R. For the seman-
tics of ranking functions that assign a degree of surprise to each possible
world, we develop a method for comparing the inference relations induced
by diﬀerent sets of ranking functions. Using this method, we address the
problem of ensuring the correctness of approximating c-inference for R
by constraint satisfaction problems (CSPs) over ﬁnite domains. While
in general, determining a suﬃcient upper bound for these CSPs is an
open problem, for a sequence of simple knowledge bases investigated only
experimentally before, we prove that using the number of conditionals
in R as an upper bound correctly captures skeptical c-inference.
1
Introduction
For a knowledge base R containing conditionals of the form If A then usually B,
various semantics have been proposed, e.g. [4,9]. Here, we will consider the
approach of ranking functions (or Ordinal Conditional Functions (OCF) [10]),
assigning a degree of surprise to each possible world. The models of R are then
OCFs accepting all conditionals in R, and every OCF model of R induces
a nonmonotonic inference relation (e.g. [4,9,10]). For any set O of models of
R, skeptical inference with respect to O takes all elements of O into account.
C-representations are particular ranking functions exibiting desirable infer-
ence properties [7], and c-inference is skeptical inference with respect to all
c-representations of R [1].
The two main objectives of this paper are (1) to develop an approach for
comparing the inference relations with respect to two diﬀerent sets of OCFs O
and O′, and (2) to illustrate how this approach can be used for proving that in
the context of c-representations [7], particular upper bounds in a ﬁnite domain
constraint system are suﬃcient for correctly modeling skeptical c-inference [1]
so that only a subset of all c-representations have to be taken into account.
For checking that the inference relations with respect to O and O′ are iden-
tical, we introduce the notion of merged order compatibility and show that it
suﬃces to check that their inference cores coincide if O and O′ are merged
order compatible. We demonstrate that there are knowledge bases R such that
the set of all ranking modes of R is not merged order compatible, while at the
c
⃝Springer International Publishing AG 2017
A. Antonucci et al. (Eds.): ECSQARU 2017, LNAI 10369, pp. 225–235, 2017.
DOI: 10.1007/978-3-319-61581-3 21

226
C. Beierle and S. Kutsch
same time the set of all c-representations of R is merged order compatible. We
then investigate how this approach can be employed for c-representations [7]
and skeptical c-inference [1]. For the sequence of knowledge bases Rn considered
in [2] that contain only conditional facts of the form (a|⊤) we formally prove
upper bounds that are suﬃcient for skeptical c-inference. This indicates that
the concepts developed here may be helpful for addressing the open problem of
determining upper bounds for general knowledge bases R that are suﬃcient for
modelling skeptical c-inference for R.
2
Background: Conditional Logic and OCFs
Let Σ = {v1, ..., vm} be a propositional alphabet. A literal is the positive (vi) or
negated (vi) form of a propositional variable, ˙vi stands for either vi or vi. From
these we obtain the propositional language L as the set of formulas of Σ closed
under negation ¬, conjunction ∧, and disjunction ∨. For shorter formulas, we
abbreviate conjunction by juxtaposition (i.e., AB stands for A ∧B), and nega-
tion by overlining (i.e., A is equivalent to ¬A). Let ΩΣ denote the set of possible
worlds over L; ΩΣ will be taken here simply as the set of all propositional inter-
pretations over L and can be identiﬁed with the set of all complete conjunctions
over Σ; we will often just write Ω instead of ΩΣ. For ω ∈Ω, ω |= A means
that the propositional formula A ∈L holds in the possible world ω. For any
propositional formula A let ΩA = {ω ∈Ω | ω |= A} be the set of all possible
worlds satisfying A.
A conditional (B|A) with A, B ∈L encodes the defeasible rule “if A then
usually B” and is a trivalent logical entity with the evaluation [5,7]
(B|A)ω =
⎧
⎨
⎩
true
iﬀ
ω |= AB
(veriﬁcation)
false
iﬀ
ω |= AB
(falsiﬁcation)
undeﬁned
iﬀ
ω |= A
(not applicable)
An Ordinal Conditional Function (OCF, ranking function) [10] is a function
κ : Ω →N0 ∪{∞} that assigns to each world ω ∈Ω an implausibility rank κ(ω):
the higher κ(ω), the more surprising ω is. OCFs have to satisfy the normalization
condition that there has to be a world that is maximally plausible, i.e., κ−1(0) ̸=
∅. The rank of a formula A is deﬁned by κ(A) = min{κ(ω) | ω |= A}. An OCF
κ accepts a conditional (B|A), denoted by κ |= (B|A), iﬀthe veriﬁcation of
the conditional is less surprising than its falsiﬁcation, i.e., iﬀκ(AB) < κ(AB).
This can also be understood as a nonmonotonic inference relation between the
premise A and the conclusion B: We say that A κ-entails B, written A |∼κB, iﬀ
κ accepts the conditional (B|A): κ |= (B|A) iﬀκ(AB) < κ(AB) iﬀA |∼κB.
Note that κ-entailment is based on the total preorder on possible worlds
induced by a ranking function κ as A |∼κB iﬀfor all ω′ ∈ΩAB, there is a
ω ∈ΩAB such that κ(ω) < κ(ω′).
The acceptance relation is extended as usual to a set R of conditionals, called
a knowledge base, by deﬁning κ |= R iﬀκ |= (B|A) for all (B|A) ∈R. This is
synonymous to saying that κ is admissible with respect to R [6], or that κ is a

Comparison of Inference Relations Deﬁned
227
ranking model of R; the set of all ranking models of R is denoted by Mod(R).
R is consistent iﬀit has a ranking model.
3
Skeptical Inference and Merged Order Inference
While each OCF κ accepting R induces a nonmonotonic inference relation, also
each set O of such ranking functions induces an inference relation determined
by taking all elements of O into account.
Deﬁnition 1 (skeptical
inference). Let R be a knowledge base, O
⊆
Mod(R), and A, B ∈L. Skeptical Inference over O in the context of R, denoted
by |∼O
R, is deﬁned by A |∼O
RB iﬀA |∼κB for all κ ∈O.
Thus, A |∼O
RB holds if every κ ∈O accepts (B|A). The skeptical inference rela-
tions deﬁned over two diﬀerent sets of OCFs may be identical. Instead of having
to check the acceptance of all possible conditionals (B|A) with respect to both
sets of OCFs, we will investigate conditions under which it suﬃces to check only
so-called base conditionals.
Deﬁnition 2 (base conditional). A base conditional over the signature Σ is
a conditional of the form (ω1|ω1 ∨ω2) with ω1, ω2 ∈ΩΣ and ω1 ̸= ω2.
Note that a base conditional (ω1|ω1 ∨ω2) is accepted by a ranking model κ,
iﬀκ(ω1) < κ(ω2). To characterize the behavior of an inference relation |∼for
these base conditionals, we deﬁne the inference core of an inference relation as
the reduction of |∼from pairs of formulas to pairs of possible worlds.
Deﬁnition 3 (inference core, ⌊|∼⌋). Let |∼be an inference relation. The
inference core of |∼, denoted by ⌊|∼⌋, is the set of all pairs (ω1, ω2) ∈Ω × Ω
with ω1 ̸= ω2, such that ω1 ∨ω2 |∼ω1, i.e., ⌊|∼⌋= {(ω1, ω2) | ω1 ∨ω2 |∼ω1}.
The notion of the inference core is based on an inference relation. The corre-
sponding concept of a merged order is based solely on a set of ranking models:
Deﬁnition 4 (merged order, <O). Let O be a set of OCFs. The merged order
<O is given by <O = {(ω1, ω2) | ω1 ̸= ω2, κ(ω1) < κ(ω2) for all κ ∈O}.
Note that in general <O is a strict weak ordering, i.e. it is irreﬂexive, asym-
metric, and transitive. The inference core of skeptical inference over a set of
OCFs O coincides with the merged order induced by O:
Proposition 1 (inference core and merged order). For any knowledge base
R and any set O ⊆Mod(R) it holds that ⌊|∼O
R⌋= <O.
Proof
<O = {(ω1, ω2) ∈Ω × Ω | ω1 ̸= ω2, κ(ω1) < κ(ω2) for all κ ∈O}
= {(ω1, ω2) ∈Ω × Ω | ω1 ̸= ω2, κ |= (ω1|ω1 ∨ω2) for all κ ∈O}
= {(ω1, ω2) ∈Ω × Ω | ω1 ̸= ω2, ω1 ∨ω2 |∼κω1 for all κ ∈O}
= ⌊|∼O
R⌋
⊓⊔

228
C. Beierle and S. Kutsch
We now deﬁne an inference relation with respect to <O in a similar way to
inference with respect to the total pre-order on worlds induced by an OCF.
Deﬁnition 5 (inference relation induced by merged order, |∼<O
R ). Let
R be a knowledge base, O ⊆Mod(R), and A, B ∈L. Then
A |∼<O
R B
iﬀ
for all ω′ ∈ΩAB there is a ω ∈ΩAB such that ω <O ω′.
Proposition 2. For any two sets of ranking models O and O′ of R it holds that
if <O = <O′ then |∼<O
R
= |∼<O′
R
.
The inference relation induced by the merged order of a set of OCFs O
approximates skeptical inference over O.
Proposition 3. For any knowledge base R and O ⊆Mod(R) it holds that
|∼<O
R
⊆|∼O
R
(1)
Proof.
A |∼<O
R B ⇔∀ω′ ∈ΩAB ∃ω ∈ΩAB : ω <O ω′
⇔∀ω′ ∈ΩAB ∃ω ∈ΩAB ∀κ ∈O : κ(ω) < κ(ω′)
⇒∀κ ∈O : min{κ(ω) | ω |= AB} < min{κ(ω) | ω |= AB}
⇔∀κ ∈O : A |∼κB
⇔A |∼O
RB
⊓⊔
While it is always the case that an inference over the merged order of a set
O is also a skeptical inference over that set, the other direction of (1) does not
hold in general.
Proposition 4. There is a knowledge base R and a set O ⊆Mod(R) with
|∼O
R ⊈|∼<O
R .
(2)
Proof. Consider R = {(a|⊤)} over Σ = {a, b}. Let κ1 and κ2 be deﬁned as:
κ1(ω) =

0
if ω = ab
1
otherwise
κ2(ω) =

0
if ω = ab
1
otherwise
Both κ1 and κ2 accept R, but for O = {κ1, κ2} it holds that <O= ∅. Thus, since
both OCFs accept R it holds that ⊤|∼O
Ra, but since <O is empty, ⊤|≁<O
R a. ⊓⊔
Since (1) holds for all sets of OCF models, but the reverse direction does not
hold in general, we introduce the notion of merged order compatibility, classifying
the sets of OCFs for which the other direction of (1) holds.
Deﬁnition 6 (merged order compatible). Let R be a knowledge base and
O ⊆Mod(R). O is called merged order compatible iﬀ|∼O
R ⊆|∼<O
R .

Comparison of Inference Relations Deﬁned
229
Thus, for merged order comaptible O we immediately get:
Proposition 5. If O ⊆Mod(R) is merged order compatible, then |∼<O
R
= |∼O
R.
Since the merged order of a set of ranking models is equal to the inference
core of the skeptical inference over that set of models, merged order compat-
ibility ensures that equivalence of skeptical inference relations coincides with
equivalence of inference cores.
Proposition 6. For any two merged order compatible sets of ranking models O
and O′ of a knowledge base R it holds that:
⌊|∼O
R⌋= ⌊|∼O′
R ⌋iﬀ
|∼O
R = |∼O′
R
(3)
Proof. The direction from right to left trivially holds since base conditionals are
a subset of all conditionals. For the other direction we have:
⌊|∼O
R⌋= ⌊|∼O′
R ⌋⇒<O = <O′
(Proposition 1)
⇒|∼<O
R
= |∼<O′
R
(Proposition 2)
⇒|∼O
R = |∼O′
R
(Proposition 5)
⊓⊔
Note that according to Proposition 6, merged order compatibility provides a
suﬃcient condition for reducing the question of skeptical inference equivalence
to the equality of the inference cores.
4
C-Inference and Merged Order Compatibility
We will now illustrate merged order compatibility for a special kind of ranking
models. C-Representations are special ranking models of a knowledge base R,
obtained by assigning individual impacts to the conditionals in R. The rank of
a possible world is then deﬁned as the sum of impacts of falsiﬁed conditionals.
Deﬁnition 7 (c-representation [7,8]). A c-representation of a knowledge base
R is a ranking function κ constructed from integer impacts ηi ∈N0 assigned to
each conditional (Bi|Ai) such that κ accepts R and is given by:
κ(ω) =

1⩽i⩽n
ω|=AiBi
ηi
(4)
Every c-representation exibits desirable inference properties, and two c-repre-
sentations induce the same inference relation if they induce the same total pre-
order on worlds. In [1], a modeling of c-representations as solutions of a constraint
satisfaction problem CR(R) is given and shown to be correct and complete with
respect to the set of all c-representations of R. Recently, it has been suggested
to take inferential equivalence of c-representations into account and to sharpen
CR(R) by introducing an upper bound for the impact values ηi.

230
C. Beierle and S. Kutsch
Deﬁnition 8 (CRu(R) [3]). Let R = {(B1|A1), . . . , (Bn|An)} and u ∈N. The
ﬁnite domain constraint satisfaction problem CRu(R) on the constraint variables
{η1, . . . , ηn} ranging over N is given by the conjunction of the constraints, for
all i ∈{1, . . . , n}:
ηi ⩾0
(5)
ηi >
min
ω|=AiBi

j̸=i
ω|=AjBj
ηj −
min
ω|=AiBi

j̸=i
ω|=AjBj
ηj
(6)
ηi ⩽u
(7)
A solution of CRu(R) is an n-tuple (η1, . . . , ηn) of natural numbers, its set of
solutions is denoted by Sol(CRu(R)). For #»η ∈Sol(CRu(R)) and κ as in Eq. (4),
κ is the OCF induced by #»η , denoted by κ #»
η , and the set of all induced OCFs is
denoted by O(CRu(R)) = {κ #»
η | #»η ∈Sol(CRu(R))}. The constraint satisfaction
problem CR(R), given in [1], is obtained by removing the constraints (7) from
CRu(R).
C-inference is skeptical inference over the set of all c-representations.
Deﬁnition 9 (c-inference, |∼c
R [1]). Let R be a knowledge base and let A, B
be formulas. B is a (skeptical) c-inference from A in the context of R, denoted
by A |∼c
RB, iﬀA |∼κB holds for all c-representations κ for R.
We will now illustrate c-representations, c-inference, and how the inference
over the merged order of the set of all c-representations accepting a knowledge
base can coincide with c-inference in the context of that knowledge base.
Example 1 (Rlw). Consider Σlw = {l, w} and Rlw = {r1, r2, r3} with
r1 = (w|l)
“land vehicles are usually not watercrafts”
r2 = (l ∨w|⊤)
“usually, something is a land vehicle or not a watercraft”
r3 = (w|l)
“things that are not land vehicles, are usually watercrafts”
representing some default knowledge about vehicles in a country like Germany.
Using the veriﬁcation and falsiﬁcation behavior of the four possible worlds
reveals that #»η 1, . . . , #»η 5 as given in Table 1 are solutions to CR(Rlw). Further-
more, there are no other solutions of CR(Rlw) inducing an ordering on worlds
that is diﬀerent from every of the orderings induced by κ #»
η 1, . . . , κ #»
η 5; for exam-
ple, the solution #»η 6 = (3, 2, 3) induces the same ordering on worlds as κ #»
η 5 and
thus allows for exactly the same inferences.
Therefore, the merged order for O = {κ #»
η 1, . . . , κ #»
η 5}, given in the lower right
corner of Table 1, coincides with the merged order over all c-representations of
Rlw. Checking all pairs of formulas over Σlw shows that for Rlw there is no
diﬀerence between merged order inference over O and skeptical c-inference.
The following example illustrates an interesting diﬀerence between the set of
all ranking models of a knowledge base and the set of its c-representations and
shows that there are knowledge bases R such that the former set is not merged
order compatible while the latter set is merged order compatible.

Comparison of Inference Relations Deﬁned
231
Table 1. Veriﬁcation (v), falsiﬁcation (f ), impacts (ηi), solution vectors #»η i, induced
OCFs κ #»
η i, and merged order of {κ #»
η 1, . . . , κ #»
η 5} for CR(Rlw) in Example 1.
Example 2. Consider the knowledge base R and Σ
from the proof of
Proposition 4, and let P = Mod(R) and let O be the set of all c-representations
accepting R. For both P and O, a can be inferred skeptically from ⊤in
the context of R, i.e. ⊤
|∼P
R
a and ⊤
|∼O
R
a. The two ranking func-
tions κ1 and κ2 used in the proof of Proposition 4 both accept R and are
thus elements of P. Since there are no two distinct worlds ω and ω′ with
κ1(ω) < κ1(ω′) and κ2(ω) < κ2(ω′), the merged order <P is empty, and
therefore ⊤|≁<P
R
a. On the other hand, for every c-representation κ accept-
ing R it holds that κ(ab) = κ(ab) and κ(ab) = κ(ab) and κ(a˙b) < κ(a˙b). Thus,
<O=

(ab, ab), (ab, ab), (ab, ab), (ab, ab)

and hence ⊤|∼<O
R
a. In fact, the set O
of all c-representations accepting R is merged order compatible, while ⊤|∼P
R a
and ⊤|≁<P
R
a shows that the set P of all ranking models of R is not merged
order compatible.
For studying the exact relationship between CR(R) and CRu(R), the concept
of a suﬃcient CRu(R) was introduced in [3] to capture the idea that only a ﬁnite
number of c-representations is needed for modeling c-inference.
Deﬁnition 10 (suﬃcient).
Let R be a knowledge base and let u ∈N. Then
CRu(R) is called suﬃcient (for skeptical inference) iﬀfor all formulas A, B we
have
A |∼c
RB
iﬀ
A |∼O(CRu(R))
R
B.
If CRu(R) is suﬃcient, we will also call u suﬃcient for R.
In terms of the classical skeptical inference relation over a set of ranking models
given in Deﬁnition 1 this means that CRu(R) is suﬃcient iﬀ
A |∼O(CR(R))
R
B
iﬀ
A |∼O(CRu(R))
R
B.
(8)
For various R and u, we will now use merged order compatibility for proving (8).

232
C. Beierle and S. Kutsch
5
Proving Suﬃcient Upper Bounds
In this section, we continue the investigation from [2] and use the concepts from
the previous section to formally prove an experimental result from [2].
Deﬁnition 11 (Σn, Rn). For n
⩾
1 and Σn
=
{a1, . . . , an}, Rn
=
{(a1|⊤), . . . , (an|⊤)} is called the knowledge base of n conditional facts.
Note that from the constraints in CR(Rn) and CRu(Rn) it follows that for
all impacts in c-representations accepting Rn it holds that ηi ⩾1. In the rest
of this section, we investigate how the concepts of merged order compatibility
and inference cores can be used to prove that for Rn the CSP O(CRn−1(Rn))
is indeed suﬃcient. In [2] this was solely illustrated by means of some examples.
Because the structure of knowledge bases Rn is very simple, the rank of a
world ω over Σn assigned by a c-representation depends on the set of falsiﬁed
atoms in ω in a very predictable way.
Deﬁnition 12 (f(ω), <f). For ω ∈ΩΣn, f(ω) = { i | ω |= ai, i ∈{ 1, . . . , n } }
is the set of indices of the negated literals in ω. The ordering <f on ΩΣn is
deﬁned such that for two worlds ω, ω′ ∈ΩΣn, ω <f ω′ iﬀf (ω) ⫋f (ω′).
As the ordering <O on worlds, also <f induces an inference relation.
Deﬁnition 13 ( |∼<f
Rn). For n > 1 and formulas A, B ∈LΣn
A |∼<f
RnB
iﬀ
for every ω′ ∈ΩAB, there is a ω ∈ΩAB such that ω <f ω′.
The following proposition generalizes a proposition from [2] regarding the rank-
ing of worlds ω and ω′ incomparable in <f.
Proposition 7. Let n > 1, ω′ ∈ΩΣn and ΩV = {ω1, . . . , ωm} ⊆ΩΣn. If
for all i ∈{1, . . . , m}, f (ω′) ̸⊆f (ωi) and f (ωi) ̸⊆f (ω′), then there exists a
c-representation κ accepting Rn such that for all i ∈{1, . . . , m}, κ(ω′) ⩽κ(ωi).
Proof. Let I be I = (	m
i=1 f (ωi)) \ f (ω′). Note that because of the precondition
f (ω′) ̸⊆f (ωi) and f (ωi) ̸⊆f (ω′), it holds that I ̸= ∅. Let #»η = (η1, . . . , ηn) with
ηi =

1
i ̸∈I
n −1
i ∈I
Since for every i ∈f (ω′) the impact vector #»η assigns 1 to the correspond-
ing conditional (ai|⊤) ∈Rn and because we know that ω′ ̸= a1 . . . an, we get
κ #»
η (ω′) = |f (ω′)| ⩽n−1. Because I is not empty, for every i ∈{1, . . . , m}, there
is some k ∈f (ωi) such that ηk = n −1. Thus, we get κ #»
η (ωi) ⩾n −1. Therefore,
it holds that κ #»
η (ω′) ⩽κ #»
η (ωi) for every i ∈{1, . . . , m}.
⊓⊔
We now use Proposition 7 to show that the inference relation |∼<f
Rn deﬁned
over the ordering on worlds <f is equal to the skeptical inference over all c-
representations accepting Rn.

Comparison of Inference Relations Deﬁned
233
Proposition 8. For n > 1 and O = O(CR(Rn)), |∼<f
Rn = |∼O
Rn.
Proof. Let A and B be arbitrary formulas from LΣn. If A |∼<f
RnB then for all
ω′ ∈ΩAB there is a ω ∈ΩAB such that ω <f ω′. Thus f (ω) ⫋f (ω′), and
because κ(ω) for a c-representation κ is deﬁned by the sum of all impacts of
negative literals in ω, it also holds that κ(ω) < κ(ω′) for κ ∈O. Thus A |∼κB
holds for all κ ∈O, implying that |∼<f
Rn ⊆|∼O
Rn.
To show the other direction, we assume that A |≁<f
RnB and show that
A |≁O
RnB. If A |≁<f
RnB, then there is a world ω′ ∈ΩAB, such that for all worlds
ω ∈ΩAB ω ̸<f ω′ holds. If ω′ <f ω, then κ(ω′) ⩽κ(ω) for every c-representation
κ with κ |= Rn and therefore A |≁O
RnB. If ω′ ̸<f ω then for all worlds ω ∈ΩAB
f (ω′) ̸⊆f (ω) and f (ω) ̸⊆f (ω′), and we use Proposition 7 by setting ΩV = ΩAB
and construct a c-representation κ such that κ(ω′) ⩽κ(ω) for all ω ∈ΩAB.
Thus, min

κ(ω) | ω |= AB

⩽min {κ(ω) | ω |= AB}, implying A |≁κB and
therefore A |≁O
RnB.
⊓⊔
Since both <f and <O are orderings of worlds and |∼<f
Rn and |∼<O
Rn are deﬁned
in the same way, it is now straightforward to show that O(CR(Rn)) is merged
order compatible for any Rn.
Proposition 9. For n > 1, O(CR(Rn)) is merged order compatible for Rn.
Proof. To show that O = O(CR(Rn)) is merged order compatible for Rn,
we need to show that |∼O
Rn ⊆|∼<O
Rn. Since we already know |∼O
Rn = |∼<f
Rn
(Proposition 8), due to Proposition 2 it suﬃces to show that <f= <O . If
ω <f ω′, then f (ω) ⫋f (ω′). As was already pointed out in the proof of Proposi-
tion 8, this means that for all c-representations κ we have κ(ω) < κ(ω′) and thus
ω <O ω′. We now have |∼O
Rn = |∼<f
Rn = |∼<O
Rn and O(CR(Rn)) is merged order
compatible.
⊓⊔
Since we do not make use of impacts ηi > n −1, the proofs of Propositions 8
and 9 also work for O = O(CRn−1(Rn)), implying:
Proposition 10. For n>1, O(CRn−1(Rn)) is merged order compatible for Rn.
These results now enable us to prove that n −1 is suﬃcient for Rn, implying
that the inference relation induced by the solutions of CRn−1(Rn) is equal to
the skeptical inference over all c-representations for Rn.
Proposition 11. For n>1, CRn−1(Rn) is suﬃcient for Rn.
Proof. We need to show that |∼O(CRn−1(Rn))
Rn
=
|∼O(CR(Rn))
Rn
. Since both
O(CRn−1(Rn)) and O(CR(Rn)) are merged order compatible, it suﬃces to show
that the inference cores are equal, i.e. ⌊|∼O(CRn−1(Rn))
Rn
⌋= ⌊|∼O(CR(Rn))
Rn
⌋.
It is easy to see that if a pair of possible worlds (ω, ω′) is in ⌊|∼O(CR(Rn))
Rn
⌋,
then it is also in ⌊|∼O(CRn−1(Rn))
Rn
⌋since |∼O(CRn−1(Rn))
Rn
allows for possibly more

234
C. Beierle and S. Kutsch
inferences. To show the other direction, we assume that (ω, ω′) ̸∈⌊|∼O(CR(Rn))
Rn
⌋
and show that (ω, ω′) ̸∈⌊|∼O(CRn−1(Rn))
Rn
⌋.
If (ω, ω′) is not in the inference core of the unbounded skeptical c-inference, it
means that there is a c-representation κ in which κ(ω) ⩾κ(ω′). If f (ω′) ⊆f (ω),
then for #»η = (1, . . . , 1) it holds that κ #»
η (ω) ⩾κ #»
η (ω′). If f (ω) ⊆f (ω′), then there
is no c-representation κ such that κ(ω) ⩾κ(ω′), contradicting the assumption. If
neither f (ω′) ⊆f (ω) nor f (ω) ⊆f (ω′) holds, the precondition of Proposition 7
is met for ω′ and ΩV = {ω}, and we can construct a c-representation κ in
O(CRn−1(Rn)) such that κ(ω) ⩾κ(ω′); hence (ω, ω′) ̸∈⌊|∼O(CRn−1(Rn))
Rn
⌋.
⊓⊔
6
Conclusions and Further Work
We introduced the notion of inference core of a nonmonotonic inference relation
taking only so called base conditionals into account. By showing that a set
of ranking models is merged order compatible, we can reduce the question of
equality of inference relations to equivalence of inference cores. We illustrated
arising diﬀerences between the set of all ranking models of a knowledge base R
and the set of all c-representations of R, and we applied our approach to skeptical
c-inference for proving that for certain knowledge bases a maximal impact of
|R| −1 is suﬃcient to fully capture the behavior of skeptical c-inference.
In our current work, we employ the concepts of inference cores and merged
order compatibility for extending our investigations on suﬃcient upper bounds
for CR(R) to more general kinds of knowledge bases, and for addressing the
open problems of characterizing knowledge bases whose set of c-representations
is merged order compatible or whether this property holds for all knowledge
bases. This goes along with ﬁnding a suitable characterization of merged order
compatible sets of ranking models, and exploring relationships to approaches
employing e.g. possibilistic or probabilistic semantics.
References
1. Beierle, C., Eichhorn, C., Kern-Isberner, G.: Skeptical inference based on C-
representations and its characterization as a constraint satisfaction problem. In:
Gyssens, M., Simari, G. (eds.) FoIKS 2016. LNCS, vol. 9616, pp. 65–82. Springer,
Cham (2016). doi:10.1007/978-3-319-30024-5 4
2. Beierle, C., Kutsch, S.: Regular and suﬃcient bounds of ﬁnite domain constraints
for skeptical c-inference. In: Benferhat, S., Tabia, K., Ali, M. (eds.) Proceedings
of the 30th International Conference on Industrial, Engineering, Other Applica-
tions of Applied Intelligent Systems (IEA/AIE-2017). LNAI, vol. 10350. Springer,
Heidelberg (2017)
3. Beierle, C., Eichhorn, C., Kern-Isberner, G., Kutsch, S.: Properties of skeptical
c-inference for conditional knowledge bases and its realization as a constraint sat-
isfaction problem, (2017, submitted)
4. Benferhat, S., Dubois, D., Prade, H.: Possibilistic and standard probabilistic
semantics of conditional knowledge bases. J. Logic Comput. 9(6), 873–895 (1999)

Comparison of Inference Relations Deﬁned
235
5. de Finetti, B.: La pr´evision, ses lois logiques et ses sources subjectives. Ann. Inst.
H. Poincar´e 7(1), 1–68 (1973). ed. Kyburg, H., Smokler, H.E.: English Translation
in Studies in Subjective Probability, pp. 93–158. Wiley, New York (1974)
6. Goldszmidt, M., Pearl, J.: Qualitative probabilities for default reasoning, belief
revision, and causal modeling. Artif. Intell. 84(1–2), 57–112 (1996)
7. Kern-Isberner, G.: Conditionals in Nonmonotonic Reasoning and Belief Revision.
LNAI, vol. 2087. Springer, Heidelberg (2001)
8. Kern-Isberner, G.: A thorough axiomatization of a principle of conditional preser-
vation in belief revision. Ann. Math. Artif. Intell. 40(1–2), 127–164 (2004)
9. Pearl, J.: System Z: a natural ordering of defaults with tractable applications
to nonmonotonic reasoning. In: Proceedings of the 3rd Conference on Theoreti-
cal Aspects of Reasoning About Knowledge (TARK 1990), pp. 121–135. Morgan
Kaufmann Publisher Inc., San Francisco (1990)
10. Spohn, W.: Ordinal conditional functions: a dynamic theory of epistemic states. In:
Harper, W., Skyrms, B. (eds.) Causation in Decision, Belief Change, and Statistics,
II, pp. 105–134. Kluwer Academic Publishers (1988)

A Transformation System for Unique Minimal
Normal Forms of Conditional Knowledge Bases
Christoph Beierle1(B), Christian Eichhorn2, and Gabriele Kern-Isberner2
1 Department of Computer Science, University of Hagen,
58084 Hagen, Germany
christoph.beierle@fernuni-hagen.de
2 Department of Computer Science, TU Dortmund,
44221 Dortmund, Germany
Abstract. Conditional knowledge bases consisting of sets of condition-
als are used in inductive nonmonotonic reasoning and can represent the
defeasible background knowledge of a reasoning agent. For the compari-
son of the knowledge of diﬀerent agents, as well as of diﬀerent approaches
to nonmonotonic reasoning, it is beneﬁcial if these knowledge bases are
as compact and straightforward as possible. To enable the replacement
of a knowledge base R by a simpler, but equivalent knowledge base R′,
we propose to use the notions of elementwise equivalence or model equiv-
alence for conditional knowledge bases. For elementwise equivalence, we
present a terminating and conﬂuent transformation system on condi-
tional knowledge bases yielding a unique normal form for every R. We
show that an extended version of this transformation system takes model
equivalence into account. For both transformation system, we prove that
the obtained normal forms are minimal with respect to subset inclusion
and the corresponding notion of equivalence.
1
Introduction
Defeasible Conditionals “If A then usually B” and conditional knowledge bases
consisting of ﬁnite sets of such conditionals play a major role in nonmonotonic
reasoning, as they are used to formalize the background knowledge of intelligent
agents. A short, compact and straightforward normal form of these knowledge
bases is desirable, not only to allow us to compare the knowledge of diﬀerent
agents, but also to store this knowledge in a form that is easily understandable
and to compare diﬀerent approaches of nonmonotonic reasoning. Additionally,
the number of conditionals in a knowledge base is an important factor in the com-
putational complexity of approaches that generate an epistemic state inductively
on top of conditional knowledge bases. Thus, knowledge bases which contain no
unnecessary conditionals may lead to signiﬁcantly reduced computational eﬀorts
required when dealing with knowledge bases in these approaches.
This article extends the work presented in the short paper [2] in several
directions and is organized as follows: After brieﬂy recalling the required back-
ground in Sect. 2, we propose to use the notion of elementwise equivalence or
c
⃝Springer International Publishing AG 2017
A. Antonucci et al. (Eds.): ECSQARU 2017, LNAI 10369, pp. 236–245, 2017.
DOI: 10.1007/978-3-319-61581-3 22

A Transformation System for Unique Minimal Normal Forms
237
model equivalence for conditional knowledge bases (Sect. 3) to enable the replace-
ment of a knowledge base R by a simpler, but equivalent knowledge base R′. In
Sect. 4 we present a set of naturally arising transformation rules on conditional
knowledge bases, develop a terminating and conﬂuent transformation system for
elementwise equivalence, yielding a unique normal form for every conditional
knowledge base, and prove that two knowledge bases are elementwise equiva-
lent iﬀthey have the same conditional normal form. In Sect. 5, we show that
an extended version of this transformation system takes model equivalence into
account. We prove that both transformation systems yield normal forms that
are minimal with respect to the corresponding notion of equivalence and subset
inclusion. Section 6 concludes the paper and points out future work.
2
Background: Conditionals and OCFs
Let Σ = {V1, ..., Vm} be a propositional alphabet. A literal is the positive (vi)
or negated (vi) form of a propositional variable Vi. From these we obtain the
propositional language L as the set of formulas of Σ closed under negation
¬, conjunction ∧, and disjunction ∨, as usual; for formulas A, B ∈L, A ⇒B
denotes the material implication and stands for ¬A∨B. For shorter formulas, we
abbreviate conjunction by juxtaposition (i.e., AB stands for A∧B), and negation
by overlining (i.e., A is equivalent to ¬A). Let Ω denote the set of possible worlds
over L; Ω will be taken here simply as the set of all propositional interpretations
over L and can be identiﬁed with the set of all complete conjunctions over Σ.
For ω ∈Ω, ω |= A means that the propositional formula A ∈L holds in the
possible world ω.
A conditional (B|A) with A, B ∈L encodes the defeasible rule “if A then
usually B” and is a trivalent logical entity with the evaluation [4,6]:
[[(B|A)]]ω =
⎧
⎨
⎩
true
iﬀ
ω |= AB
(veriﬁcation)
false
iﬀ
ω |= AB
(falsiﬁcation)
undeﬁned
iﬀ
ω |= A
(not applicable)
A knowledge base R = {(B1|A1), ..., (Bn|An)} is a ﬁnite set of such conditionals.
An Ordinal Conditional Function (OCF, ranking function) [9] is a function
κ : Ω →N0 ∪{∞} that assigns to each world ω ∈Ω an implausibility rank
κ(ω), that is, the higher κ(ω), the more surprising ω is. OCFs have to satisfy
the normalization condition that there has to be a world that is maximally
plausible, i.e., the preimage of 0 cannot be empty, formally κ−1(0) ̸= ∅. The
rank of a formula A is deﬁned by κ(A) = min{κ(ω) | ω |= A}.
An OCF κ accepts a conditional (B|A) (denoted by κ |= (B|A)) iﬀthe
veriﬁcation of the conditional is less surprising than its falsiﬁcation, i.e., iﬀ
κ(AB) < κ(AB). This can also be understood as a nonmonotonic inference
relation between the premise A and the conclusion B: We say that A κ-entails
B (written A |∼κB) if and only if κ accepts the conditional (B|A), formally
κ |= (B|A)
iﬀ
κ(AB) < κ(AB)
iﬀ
A |∼κB.
(1)

238
C. Beierle et al.
The acceptance relation in (1) is extended as usual to a set R of conditionals
by deﬁning κ |= R iﬀκ |= (B|A) for all (B|A) ∈R. This is synonymous to saying
that R is admissible with respect to R [5]. A knowledge base R is consistent iﬀ
there exists an OCF κ such that κ |= R.
Example 1 (Rcar). Let Σ = {C, E, F} be an alphabet where C indicates whether
something is a car (c), or not (c), E indicates whether something is an e-car (e),
or not (e), and F indicates whether something needs fossil fuel (f), or not (f).
Let Rcar = {r1, r2, r3, r4, r5, r6, r7} be a knowledge base using Σ with:
r1 : (f|c)
“Usually cars need fossil fuel.”
r2 : (f|e)
“Usually e-cars do not need fossil fuel.”
r3 : (c|e)
“E-cars usually are cars.”
r4 : (e|ef )
“E-cars that do not need fossil fuel usually are e-cars.”
r5 : (ef|e)
“E-cars usually are e-cars that do not need fossil fuel.”
r6 : (e|⊤)
“Usually things are no e-cars.”
r8 : (cf ∨cf |ce ∨ce)
“Things that are cars and e-cars or cars but not e-cars
are cars that need fossil fuel or are no cars but need fossil fuel.”
This knowledge base is consistent: For instance, a ranking model κ for Rcar is
ω
c e f
c e f
c e f
c e f
c e f
c e f
c e f
c e f
κ(ω)
2
1
0
1
4
2
0
0
with, e.g., κ |= (f|e) because κ(ef) = 1 < 2 = κ(ef) and κ |= (e|⊤) because
κ(e) = 0 < 1 = κ(e).
3
Model Based Equivalences
With the acceptance relation between ranking functions and knowledge bases,
we now can deﬁne the set of ranking models of a knowledge base.
Deﬁnition 1 (ranking models). Let R = {(B1|A1), . . . , (Bn|An)} be a ﬁnite
conditional knowledge base. The set of ranking models of R is the set of OCFs
that are admissible with respect to R, formally Mod (R) = {κ|κ |= R}.
The notion of inconsistency gives us a possibility to determine whether every
ranking model of a knowledge base accepts a given conditional:
Proposition 1 ([5]). Let R = {(B1|A1), . . . , (Bn|An)} be a ﬁnite conditional
knowledge base. A conditional (B|A) with AB ̸≡⊥is accepted by every ranking
model κ ∈Mod (R) if and only if R ∪{(B|A)} is inconsistent.
Deﬁnition 2 (model equivalence). Let R, R′ be knowledge bases. R and R′
are model equivalent, denoted R ≡mod R′, iﬀMod(R) = Mod(R′).
By deﬁnition, the model set of an inconsistent knowledge base is empty,
so all inconsistent knowledge bases are equivalent. We introduce the special
knowledge base ⋄that is inconsistent by deﬁnition; thus ⋄≡mod R for every
R with Mod (R) = ∅; for instance, {(⊥|⊤)} ≡mod ⋄. The idea of elementwise
equivalence is that each piece of knowledge (i.e. conditional) in one knowledge
base directly corresponds to a piece of knowledge in the other knowledge base.

A Transformation System for Unique Minimal Normal Forms
239
Deﬁnition 3 (elementwise equivalence). Let R, R′ be knowledge bases.
– R is an elementwise equivalent sub-knowledge base of R′, denoted by R ≪ee
R′, iﬀfor every conditional (B′|A′) ∈R′ that is not self-fulﬁlling (i.e.
A′ ̸|= B′) there is a conditional (B|A) ∈R such that Mod({(B|A)}) =
Mod({(B′|A′)}).
– R and R′ are strictly elementwise equivalent iﬀR ≪ee R′ and R′ ≪ee R.
– R and R′ are elementwise equivalent, denoted by R ≡ee R′, iﬀeither both
R and R′ are inconsistent, or both R and R′ are consistent and strictly
elementwise equivalent.
Thus, two inconsistent knowledge bases are also elementwise equivalent
according to Deﬁnition 3, e.g. {(B|A), (B|A)} ≡ee {{(B′|A′), (⊥|⊤)}, enabling us
to avoid cumbersome case distinctions when dealing with sets of consistent and
inconsistent knowledge bases. We illustrate model equivalence and elementwise
equivalence with the following excerpts of Example 1:
Example 2. Let R′
car = {r1, r2, r3, r7} and R′′
car = {r1, r2, r3} be knowledge
bases with conditionals from Example 1. Since f ≡ef ∨cf and c ≡ce ∨ce,
for every OCF κ we have κ(cf) = κ ((ce ∨ce) ∧(ef ∨cf)) and likewise κ(cf) =
κ ((ce ∨ce) ∧¬ (ef ∨cf)) and hence κ |= r3 if and only if κ |= r7. There-
fore, for every κ |= R′′
car we also have κ |= R′
car, and vice versa, which gives
us R′
car ≡mod R′′
car. For the same reason we have Mod ({r3}) = Mod ({r7})
(and, trivially, Mod ({ri}) = Mod ({ri}) for all i ∈{1, 2, 3, 7}), which gives us
R′
car ≪ee R′′
car and R′′
car ≪ee R′
car and hence R′
car ≡ee R′′
car. So R′
car and R′′
car
are both model equivalent and also elementwise equivalent.
4
Normal Forms for Elementwise Equivalence
Similar to formulas in propositional logic, it is often advantageous to consider
only conditional knowledge bases that are in a standardized normal form. In
the following, we will develop rules for transforming a knowledge base toward
a normal form. For this, we will use a function Π that assigns to a knowledge
base R an ordered partition Π(R) = (R0, . . . , Rm) such that all conditionals in
Ri, 1 ⩽i ⩽m, are tolerated by the set m
j=i Rj [8]; if no such partition exists,
we extend Π by deﬁning Π(R) = ⋄. Thus, R is consistent iﬀΠ(R) ̸= ⋄[8].
For propositional formulas over a propositional alphabet Σ, there are vari-
ous ways of deﬁning a normal form such that precisely semantically equivalent
formulas are mapped to the same normal form, using e.g. disjunctions of worlds
or selected shortest formulas. In order to abstract from a particular choice, for
the rest of this paper we assume a function ν that maps a propositional formula
A to a unique normal form ν(A) such that A ≡A′ iﬀν(A) = ν(A′).
Using Π and ν, the transformation system T is given in Fig. 1:
(SF) removes a conditional (B|A) if A |= B since such a conditional is self-
fulﬁlling because it can not be falsiﬁed by any world.

240
C. Beierle et al.
Fig. 1. Transformation rules T for conditional knowledge bases
(DP) removes a conditional (B′|A′) which is a duplicate of a conditional (B|A)
under propositional equivalences of A and A′ and of B and B′.
(CE) removes a conditional that is conditionally equivalent to another one.
(PN ) propositionally normalizes antecedent and consequent of a conditional.
(CN ) transforms a conditional (B|A) to its conditional normal form by sharp-
ening its consequent to the conjunction with its antecedent.
(CC) transforms a knowledge base containing both a conditional (B|A) and its
counter conditional (B|A) into the inconsistent knowledge base ⋄.
(SC) transforms a knowledge base containing a conditional that can not be
veriﬁed by any world into the inconsistent knowledge base ⋄.
(IC) transforms an inconsistent knowledge base into ⋄.
We illustrate T transforming the knowledge base in the running example to
a reduced, more compact form.
Example 3 (T (Rcar)). Consider the knowledge base Rcar from Example 1.
(SF) In Rcar, r4 is self-fulﬁlling since ef |= e, hence the application of (SF)
yields R(SF)
car
= Rcar \ {r4}.
(DP) The conditionals r1 and r7 are duplicates since c ≡ce ∨ce and f ≡
(cf ∨cf ). So applying (DP) to Rcar gives us R(DP)
car
= Rcar \ {r7}.
(CE) We have ef ≡eef and ef ≡e ∧(e ∨f ), therefore r2 and r5 are condi-
tionally equivalent; applying (CE) to Rcar yields R(CE)
car
= Rcar \ {r5}.

A Transformation System for Unique Minimal Normal Forms
241
(PN ) The conditional r1 is equivalent to r7 but shorter, so let us assume the
shorter formula as propositional normal form. With ν being a function that
converts a propositional formula to this normal form, applying (PN ) to Rcar
gives us the same results as (DP), that is, R(PN)
car
= Rcar \ {r7}.
(SC) The knowledge base Rcar contains no self-contradictory conditional;
hence, (SC) can not be applied to Rcar.
Applying T exhaustively and in arbitrary sequence to Rcar gives us the knowl-
edge base RT
car = T (Rcar) = {r1, r2, r3, r6}.
Note that T is not a minimal set of transformation rules. For instance, (DP)
is redundant since the eﬀect of removing a conditional (B′|A′) as a duplicate of
(B|A) could also be achieved by applying (PN ) to both conditionals, thereby
mapping them both to the same normalized conditional in the resulting knowl-
edge base. Similarly, (CC) and (SC) are redundant since these cases are also
covered by the more general transformation rule (IC). However, our objective
here is not to present a minimal set of rules, but a set of more or less naturally
arising transformation rules.
Proposition 2. T is terminating.
Proof. The rules (SF), (DP), (CE), and (IC) all remove at least one conditional,
(PN ) and (CN ) can be applied at most once to any conditional, and also (CC),
(SC), and (IC) all remove at least one conditional. Hence, T is terminating. ⊓⊔
Proposition 3 (T correct).
Let T (R) be the knowledge base obtained from
R by exhaustively applying T to R. Then R ≡mod T (R).
Proof. We prove the proposition by showing that each single rule is correct.
– (SF) is correct since (B|A) with A |= B is veriﬁed by every OCF.
– (DP) is correct since A ≡A′, B ≡B′ implies that κ |= (B|A) iﬀκ |= (B′|A′)
for every OCF κ.
– (CE) is correct since AB ≡A′B′, AB ≡AB′ implies that κ |= (B|A) iﬀ
κ |= (B′|A′) for every OCF κ.
– (PN ) is correct since for every OCF κ, we have κ
|=
(B|A) iﬀκ
|=
(ν(B)|ν(A)).
– (CN is correct since for every OCF κ, we have κ |= (B|A) iﬀκ |= (AB|A).
– (CC) is correct since there is no OCF κ accepting both a conditional (B|A)
and its counter conditional (B|A).
– (SC) is correct since there is no OCF κ with κ |= (B|A) if AB ≡⊥.
– (IC) is correct since Π is a consistency test for any knowledge base R.
⊓⊔
While Proposition 3 states that T is correct with respect to model equivalence
of knowledge bases, the following proposition shows that this is also the case with
respect to the stricter notion of elementwise equivalence.
Proposition 4 (T correct w.r.t. elementwise equivalence). Let T (R) be
the knowledge base obtained from R by exhaustively applying T to R. Then
R ≡ee T (R).

242
C. Beierle et al.
Proof. According to the proof of Proposition 3, R is inconsistent iﬀT (R) = ⋄;
thus, if R is inconsistent then R ≡ee T (R). So let R be consistent. Then T (R)
has been obtained from R by a ﬁnite number of applications of (SF), (DP),
(CE), (PN ), and (CN ). For these applications we observe:
– (SF) preserves elementwise equivalence since for self-fulﬁlling conditionals no
counterpart in the other knowledge base is required.
– (DP) and (CE) preserve elementwise equivalence since in both cases, we obvi-
ously have Mod({(B|A)}) = Mod({(B′|A′)}) and thus {(B|A), (B′|A′)} ≡ee
{(B|A)}.
– (DP) and (CN ) preserve elementwise equivalence since Mod({(B|A)}) =
Mod({(ν(B)|ν(A))}) and since Mod({(B|A)}) = Mod({(AB|A)}).
⊓⊔
T is an extended version of the transformation system NF presented in [2]. While
NF is not conﬂuent [1,2,7], the next proposition proves that T is conﬂuent.
Proposition 5. T is conﬂuent.
Proof. Since T is terminating, local conﬂuence of T implies conﬂuence of T ;
local conﬂuence of T in turn can be shown by ensuring that for every critical
pair obtained form superpositioning two left hand sides of rules in T reduces to
the same knowledge base [1,7]:
Any critical pair obtained from (CC), (SC), or (IC) and a rule in T reduces
to ⋄since all rules preserve the consistency status af a knowledge base.
Any critical pair obtained from (SF) with T \{(CC), (SC), (IC)} reduces to
the same knowledge base since a self-fulﬁlling conditional replaced by a trans-
formation rule in {(DP), (CE), (PN ), (CN )} is still self-fulﬁlling. Furthermore,
any critical pair involving (PN ) can obviously be reduced to the same knowledge
base; this observation also holds for (CN ).
Thus, we are left with critical pairs obtained from (DP) and (CE). Consider
R0 = R ∪{(B|A), (B′|A′), (B′′|A′′)}.
If (DP) can be applied to R0 at {(B|A), (B′|A′)} we get R1
=
R ∪
{(B|A), (B′′|A′′)}, and if (CE) can be applied to R0 at {(B′|A′), (B′′|A′′)} we
get R2 = R ∪{(B|A), (B′|A′)}. The used applicability of (DP) to R0 ensures
A ≡A′, B ≡B′; hence (DP) can be applied to R2, yielding R3 = R ∪{(B|A)}.
The used applicability of (CE) to R0 ensures A′B′ ≡A′′B′′, A′B′ ≡A′′B′′;
thus, we also have AB ≡A′′B′′, AB ≡A′′B′′ so that (CE) can be applied to
R1, yielding R ∪{(B|A)} = R3. Hence, T reduces both R1 and R2 to R3. Sim-
ilarly, the other critical pairs obtained from (DP) and (CE) can be shown to be
reducible to the same knowledge base.
⊓⊔
T is not only conﬂuent, but it also yields a knowledge base that is minimal
when taking elementwise equivalence into account.
Proposition 6 (T minimizing w.r.t. elementwise equivalence). For all
knowledge bases R we have T (R) = ⋄iﬀR is inconsistent, and if R is consistent,
then for all knowledge bases R′ it holds that:
R′ ⫋T (R)
implies
R′ ̸≡ee R
(2)

A Transformation System for Unique Minimal Normal Forms
243
Proof. For inconsistent R, the proof follows from Proposition 4, so let R
be consistent and R′ ⫋T (R). Proposition 4 implies R ≡ee T (R); hence,
it suﬃces to show R′
̸≡ee
T (R). If we assume the contrary, R′
≡ee
T (R), then R′ ⫋T (R) implies that there must be two diﬀerent condi-
tionals (B1|A1), (B2|A2) ∈T (R) and a conditional (B|A) ∈R′ such that
Mod({(B1|A1)}) = Mod({(B|A)}) and Mod({(B1|A1)}) = Mod({(B|A)})
and hence Mod({(B1|A1)}) = Mod({(B2|A2)}). This requires A1
≡A2,
A1B1 ≡A2B2, and A1B1 ≡A2B2, implying that (CE) could be applied to
(B1|A1), (B2|A2), a contradiction to our assumptions. Thus, R′ ̸≡ee R.
⊓⊔
Propositions 2–6 ensure that applying T to a knowledge base R always yields
the unique normal form T (R) that is elementwise equivalent to R and minimal
with respect to set inclusion.
Deﬁnition 4 (conditional normal form). A knowledge base R is in condi-
tional normal form iﬀR = T (R).
Thus, for every knowledge base R, its conditional normal form is uniquely
determined. Moreover, T provides a convenient test for the elementwise equiva-
lence of knowledge bases.
Proposition 7 (elementwise equivalence). Two knowledge bases R, R′ are
elementwise equivalent iﬀthe have the same conditional normal form, i.e.:
R ≡ee R′
iﬀ
T (R) = T (R′)
(3)
5
Normal Forms for Model Equivalence
While T is correct with respect to both model equivalence and elementwise
equivalence, it is minimizing for elementwise equivalence (Proposition 4), but it
is not minimizing when taking model equivalence into account.
Example 4 (T not minimizing for model equivalence). We illustrate that T is
not minimizing with respect to model equivalence using the running example
with the knowledge bases Rcar and RT
car. We already illustrated that RT
car can
be obtained from Rcar by exhaustive application of the rules of T in Example 3,
i.e. T (Rcar) = RT
car. But RT
car is not minimal with respect to set inclusion
when taking model equivalence into account: Consider the knowledge base R′
car
= {r1, r2, r3} ⫋RT
car = {r1, r2, r3, r6}. We have R′
car ∪{(e|⊤)} ≡mod ⋄and
thus Proposition 1 gives us κ |= (e|⊤) for all κ |= R′
car. Therefore, since
r6 = (e|⊤), every ranking model of R′
car is also a ranking model of RT
car, thus
R′
car ≡mod RT
car.
This example motivates the following extension of T :
Deﬁnition 5 (T2). T2 is the transformation system T extended by the rule:
(RC) redundant conditional :
R ∪{(B|A)}
R
Π(R ∪{(B|A)}) = ⋄

244
C. Beierle et al.
Since (RC) removes a conditional (B|A) from a knowledge base R∪{(B|A)}
if every model of R accepts (B|A), we immediately have R ∪{(B|A)} ≡mod R.
Together with the properties for T shown above, we get:
Proposition 8 (T2 terminating and correct w.r.t. model equivalence).
T2 is terminating, and for all knowledge bases R, we have R ≡mod T2(R).
In contrast to T , T2 is not conﬂuent as the choice of where the transformation
rule (RC) is applied may inﬂuence the result as illustrated by the following
example.
Example 5 (T2 not conﬂuent). Consider the knowledge base R = {r1, r2, r3, r4}
with r1 = (f|c), r2 = (c|e), r3 = (f|e), and r4 = (f|ce). Let r3 = (f|e) and
r4 = (f|ce). Then Π({r1, r2, r3} ∪{r4}) = ⋄, and hence applying (RC) to R at
r4 yields R1 = {r1, r2, r3}. Furthermore, Π({r1, r2, r4} ∪{r3}) = ⋄, and hence
applying (RC) to R at r3 yields R2 = {r1, r2, r4}. Applying T2 yields
R′
1 = T2(R1) = {(ν(cf)|ν(c)), (ν(ce)|ν(e)), (ν(ef)|ν(e))}
(4)
R′
2 = T2(R2) = {(ν(cf)|ν(c)), (ν(ce)|ν(e)), (ν(cef)|ν(ce))}
(5)
and since R′
1 ̸= R′
2, these two knowledge bases are two diﬀerent normal forms
for R under T2.
On the other hand, T2 is minimizing when taking model equivalence into
account.
Proposition 9 (T2 minimizing w.r.t. model equivalence). For all knowl-
edge bases R we have T2(R) = ⋄iﬀR is inconsistent, and if R is consistent,
then for all knowledge bases R′ it holds that:
R′ ⫋T2(R)
implies
R′ ̸≡mod R
(6)
Proof. As in Proposition 6, we are left to prove the case for a consistent R. So let
R be consistent and R′ ⫋T2(R). Proposition 8 implies R ≡mod T2(R); hence, it
suﬃces to show R′ ̸≡mod T2(R). If we assume the contrary, R′ ≡mod T2(R), then
R′ ⫋T2(R) implies that there must be conditionals (B1|A1), . . . , (Bn|An) ∈
T2(R), n
⩾
1, such that R′ ∪{(B1|A1), . . . , (Bn|An)}
=
T2(R) with
Mod({R′ ∪{(B1|A1), . . . , (Bn|An)}) = Mod({T2(R)}). This implies that (RC)
could be applied to T2(R) at (B1|A1), contradicting our assumptions. Thus,
R′ ̸≡mod R.
⊓⊔
6
Conclusions and Future Work
In this paper we proposed notions of elementwise and model equivalence for con-
ditional knowledge bases, enabling the replacement of a knowledge base R by
an equivalent knowledge base R′. Based on these notions, we presented the ter-
minating and conﬂuent transformation system T that for every knowledge base

A Transformation System for Unique Minimal Normal Forms
245
yields a minimal and unique conditional normal form with respect to element-
wise equivalence, providing a straightforward test for elementwise equivalence of
knowledge bases. We extended this system to the transformation system T2 that
takes model equivalence into account. Both systems yield set-inclusion minimal
knowledge bases with respect to the corresponding notion of equivalence. Note
that we used OCFs as an exemplary model for knowledge bases. Both T and T2
should also apply to probabilistic or possibilistic [3] settings, it remains to show
that the resulting knowledge bases respect the given semantics.
In our ongoing work, we are studying the practical consequences that result
from using normalized knowledge bases instead of their non-normalized versions.
Both transformation systems T and T2 are model preserving, so the normal forms
obtained by these system can be used for all inference relations that take all or
a single model into account. We are currently investigating to which extent this
also applies to inference relations that are deﬁned upon a set of preferred models.
Acknowledgment. This work was supported by DFG-Grant KI1413/5-1 to Gabriele
Kern-Isberner as part of the priority program “New Frameworks of Rationality”
(SPP 1516). Christian Eichhorn is supported by this Grant. We thank the anonymous
reviewers for their valuable hints and comments.
References
1. Baader, F., Nipkow, T.: Term Rewriting and All That. Cambridge University Press,
Cambridge (1998)
2. Beierle, C., Eichhorn, C., Kern-Isberner, G.: On transformations and normal forms
of conditional knowledge bases. In: Benferhat, S., Tabia, K., Ali, M. (eds.) Pro-
ceedings of the 30th International Conference on Industrial, Engineering, Other
Applications of Applied Intelligent Systems (IEA/AIE-2017). LNAI, vol. 10350, pp.
488–494. Springer, Heidelberg (2017)
3. Dubois, D., Prade, H.: Possibility theory and its applications: where do we stand? In:
Kacprzyk, J., Pedrycz, W. (eds.) Springer Handbook of Computational Intelligence,
pp. 31–60. Springer, Heidelberg (2015). doi:10.1007/978-3-662-43505-2 3
4. de Finetti, B.: La pr´evision, ses lois logiques et ses sources subjectives. Ann. Inst.
H. Poincar´e 7(1), 1–68 (1937). English translation in Kyburg, H., Smokler, H.E.
(eds.): Studies in Subjective Probability, pp. 93–158. Wiley, New York (1974)
5. Goldszmidt, M., Pearl, J.: Qualitative probabilities for default reasoning, belief revi-
sion, and causal modeling. Artif. Intell. 84(1–2), 57–112 (1996)
6. Kern-Isberner, G.: Conditionals in Nonmonotonic Reasoning and Belief Revision -
Considering Conditionals as Agents. LNCS, vol. 2087. Springer, Heidelberg (2001)
7. Knuth, D.E., Bendix, P.B.: Simple word problems in universal algebra. In: Leech, J.
(ed.) Computational Problems in Abstract Algebra, pp. 263–297. Pergamon Press
(1970)
8. Pearl, J.: System Z: a natural ordering of defaults with tractable applications to
nonmonotonic reasoning. In: Parikh, R. (ed.) Proceedings of the 3rd Conference
on Theoretical Aspects of Reasoning about Knowledge (TARK 1990), pp. 121–135.
Morgan Kaufmann Publishers Inc., San Francisco (1990)
9. Spohn, W.: The Laws of Belief: Ranking Theory and Its Philosophical Applications.
Oxford University Press, Oxford (2012)

On Boolean Algebras of Conditionals
and Their Logical Counterpart
Tommaso Flaminio1, Lluis Godo2(B), and Hykel Hosni3
1 Dipartimento di Scienze Teoriche e Applicate, Universit`a dell’Insubria,
Via Mazzini 5, 21100 Varese, Italy
tommaso.flaminio@uninsubria.it
2 Artiﬁcial Intelligence Research Institute (IIIA - CSIC),
Campus de la Univ. Aut`onoma de Barcelona s/n, 08193 Bellaterra, Spain
godo@iiia.csic.es
3 Department of Philosophy, University of Milan,
Via Festa del Perdono 7, 20122 Milano, Italy
hykel.hosni@unimi.it
Abstract. This paper sheds a novel light on the longstanding problem
of investigating the logic of conditional events. Building on the frame-
work of Boolean algebras of conditionals previously introduced by the
authors, we make two main new contributions. First, we fully charac-
terise the atomic structure of these algebras of conditionals. Second, we
introduce the logic of Boolean conditionals (LBC) and prove its com-
pleteness with respect to the natural semantics induced by the structural
properties of the atoms in a conditional algebra as described in the ﬁrst
part. In addition we outline the close connection of LBC with preferential
consequence relations, arguably one of the most appreciated systems of
non-monotonic reasoning.
Keywords: Conditionals events · Uncertain reasoning · Boolean alge-
bra of conditionals · Non-monotonic reasoning
1
Introduction
Conditionals play a fundamental role both in qualitative and in quantitative
uncertain reasoning, see e.g. [1,6,7,9,12,14,15]. In the former, conditionals con-
stitute the core focus of non-monotonic reasoning [8,10,11]. In quantitative
uncertain reasoning, conditionals are central both for conditional probability,
and more generally, for conditional uncertainty measures [5].
This paper builds on [4], where a Boolean algebra structure for conditionals
was proposed with the goal of clarifying the relationship between conditional
probabilities and simple probabilities on conditional events. The approach of
considering (measure-free) conditionals as Boolean objects departs from previous
ones in the literature where conditionals are mainly considered as three-valued
objects, proposing diﬀerent deﬁnitions for the operations between conditionals,
see e.g. [2,3,7,9,13]. For a comparison, the reader may consult [4, Sect. 3.1].
c
⃝Springer International Publishing AG 2017
A. Antonucci et al. (Eds.): ECSQARU 2017, LNAI 10369, pp. 246–256, 2017.
DOI: 10.1007/978-3-319-61581-3 23

On Boolean Algebras of Conditionals and Their Logical Counterpart
247
Intuitively, a Boolean algebra of conditional events, a BAC algebra for
short, is an algebra built up over a Boolean algebra of plain events A =
(A, ∧, ∨, ¬, ⊤, ⊥) in which we allow basic conditionals, i.e. syntactic objects of
the form (a | b) with a ∈A and b ∈A′ = A\{⊥}, to be freely combined with the
usual Boolean operations, subject to the following plausible constraints (recall
that in any Boolean algebra A, if a, b ∈A, then a ≤b iﬀa ∧b = a):
– the conditional (⊤| ⊤) will be the top element of the algebra, while (⊥| ⊤)
will be the bottom;
– given b ∈A′, we want the set of conditionals {(a | b) : a ∈A} to be the
domain of a Boolean subalgebra, and in particular when b = ⊤, then we want
this subalgebra to be isomorphic to A;
– in a conditional (a | b) we can equivalently replace the consequent a by a ∧b,
that is, we require the conditionals (a | b) and (a ∧b | b) to be equivalent;
– if a ≤b ≤c then the result of conjunctively combining the conditionals (a | b)
and (b | c) yields the conditional (a | c).
This last condition captures a form of restricted transitivity and is clearly
inspired by the chain rule of conditional probabilities: P(a | b)·P(b | c) = P(a | c)
whenever a ≤b ≤c.
The purpose of this paper is to put BAC algebras on ﬁrm logical footing. To
this end, we make two main new contributions. First, we fully characterise the
atomic structure of BAC algebras, a problem that was left open in [4]. This is
done in Sect. 3. Second, in Sect. 4, we introduce the logic of Boolean conditionals
(LBC) and prove its completeness with respect to the natural semantics induced
by the structural properties of the atoms in a conditional algebra. In Sect. 5 we
conclude with a result to the eﬀect that LBC is indeed a preferential consequence
relation, in the sense of the well-known System P, see e.g. [10,11].
2
Boolean Algebras of Conditionals
Boolean algebras of conditionals, introduced and investigated in [4], are built as
follows. Let A = (A, ∧, ∨, ¬, ⊤, ⊥) be a Boolean algebra and let A′ = A\{⊥}.
The construction starts with considering the Boolean algebra of terms freely
generated by the pairs (a, b) ∈A × A′, that will be denoted
F(A × A′) = (F(A × A′), ∧∗, ∨∗, ¬∗, ⊤∗, ⊥∗).
Notice that all pairs (a, b) ∈A×A′ are such that b > ⊥. This is motivated by the
fact that we are avoiding, in this paper, to consider counterfactual conditionals.
Since we want conditionals to satisfy a number of properties, what we do is
to consider the greatest subalgebra of F(A × A′) where these properties hold.
Technically speaking, we deﬁne it as a quotient algebra by a suitable congruence
relation. Namely, consider the following elements in F(A × A′), where we use
δ(c, c′) to denote the element c ↔∗c′ (of F(A × A′)) for any c, c′ ∈F(A × A′):
(t1) δ((y, y), ⊤∗) for every y ∈A′,

248
T. Flaminio et al.
(t2) δ((x, y) ∧∗(z, y), (x ∧z, y)) for every x, z ∈A and y ∈A′,
(t3) δ(¬∗(x, y), (¬x, y)) for every x ∈A, y ∈A′,
(t4) δ((x ∧y, y), (x, y)) for every x ∈A, y ∈A′,
(t5) δ((x, z), (x, y) ∧∗(y, z)) for every x ∈A and y, z ∈A′ such that x ≤y ≤z.
Let C be the ﬁlter of F(A × A′) generated by the set of all the instances of the
above terms (t1-t5). We hence deﬁne the congruence relation ≡C in the following
way: c ≡C c′ if δ(c, c′) ∈C.
Deﬁnition 1. For every Boolean algebra A, we say that the quotient algebra
C(A) = F(A × A′)/≡C is the Boolean algebra of conditionals of A, the BAC
algebra of A for short.
Since C(A) is a quotient of a free Boolean algebra, it is a Boolean algebra as
well. The elements of C(A) are in fact equivalence classes of elements of F(A×A′).
We will denote the equivalence class of a pair (a, b) ∈A×A′ by (a | b). Therefore,
in C(A) we have basic conditionals of the form (a | b) and compound conditionals,
that is, those elements in C(A) that are algebraic terms deﬁnable in the language
of Boolean algebras, modulo the identiﬁcation induced by C. The operations on
C(A) are denoted as follows, with the obvious interpretation
C(A) = (C(A), ⊓C, ⊔C, ¬C, ⊥C, ⊤C).
In order to simplify our notation we will omit the subscript C whenever this
leads to no ambiguity.
Notice that, the above conditions (t1)–(t5) used to deﬁne the quotient alge-
bras C(A) automatically imply that, in any C(A), the following equations on
conditionals will always hold: (y | y) = ⊤, (x | y)⊓(z | y) = (x∧y | z), ¬(x | y) =
(¬x | y), (x ∧y | y) = (x | y), and (x | y) ⊓(y | z) = (x | z) whenever x ≤y ≤z.
Observe as well, that the basic conditionals of C(A, A′) need not be closed
under meets and joins, though in some particular cases they can be, for instance
as a consequence of (t2) and (t3), ensuring that the conjunction of two basic
conditionals with the same antecedent is a basic conditional, and the negation
of a basic conditional, is basic as well. In any algebra C(A), as in any Boolean
algebra, the induced order relation, also denoted ≤, is deﬁned as (x | y) ≤(z |
k) iﬀ(x | y) ⊓(z | k) = (x | y).
Space constraints do not allow us to delve any further into BAC algebras.
We refer the interested reader to [4] for further details, and limit ourselves to
collect the properties required in this paper in the following proposition.
Proposition 1. In every BAC algebra C(A), for every x, z ∈A and y ∈A′, the
following properties hold:
(e1) (y | y) = (⊤| y) = ⊤and (¬y | y) = (⊥| y) = ⊥.
(e2) (x | y)⊓(z | y) = (x∧z | y), and hence, if x∧z = ⊥then (x | y)⊓(z | y) = ⊥.
(e3) if z ∈A′ and x ≤y ≤z then (x | z) = (x | y) ⊓(y | z).
(e4) (x | y) ⊔(z | y) = (x ∨z | y) and ¬(x | y) = (¬x | y).
(e5) (x ∧y | ⊤) ≤(x | y) ≤(¬y ∨x | ⊤).

On Boolean Algebras of Conditionals and Their Logical Counterpart
249
(e6) (x | ⊤) ⊓(y | x) ≤(y | ⊤).
(e7) (x ∧y | ⊤) ≤(x | y) and (¬x ∧y | ⊤) ≤¬(x | y).
(e8) if z ∈A′ then (x | y) ⊓(x | z) ≤(x | y ∨z).
Interesting readings of some of the above properties are the following. (e1), (e2)
and (e4) force that for any z ∈A′, the set A | z = {(a | z) | a ∈A} is (the
domain of) a Boolean subalgebra of C(A). On the other hand, (e5) shows that
conditionals are stronger than material implications but weaker than conjunc-
tions. Also, from a logical point of view, (e6) states a form of modus ponens
with conditionals. (e7) states that, whenever y unconditionally holds true, a
conditional (x | y) holds true if x unconditionally holds true, while (x | y) holds
false otherwise. Finally, (e8) corresponds to the so-called OR property, typical
in nonmonotonic systems, see Sect. 5.
3
The Atoms of a Finite Algebra of Conditionals
We now move on to the investigation of the atoms of a BAC algebra C(A) for
a ﬁnite A. To this end it is worth remembering that an element α of a Boolean
algebra A is an atom of A iﬀwhen α covers ⊥, that is, ⊥< α and if ⊥≤β ≤α
then either β = ⊥or β = α. Note that every algebra C(A) is ﬁnite whenever A
is. Indeed, if A is ﬁnite, F(A × A′) is ﬁnite as well, since the variety of Boolean
algebras is locally ﬁnite. Thus, C(A) is ﬁnite and hence atomic. In the following,
we write Atom(B) to denote the set of atoms of any Boolean algebra B.
For the characterization theorem, we need some preliminary results. The
following properties are immediate consequences of Proposition 1 (e3). In what
follows A will always denote a ﬁnite Boolean algebra such that |Atom(A)| = n.
Lemma 1. Let x, y, z ∈A. The following properties hold:
1. If x ≤y ≤z, then (x | z) ≤(x | y); in particular (x | ⊤) ≤(x | y).
2. If x ∧z = ⊥and ⊥< x ≤y, then (x | ⊤) ⊓(z | y) = ⊥.
Now we can prove the following interesting results.
Proposition 2. Let i ≤n −1 and deﬁne Seqi(A) to be the set of sequences of
length i of pairwise distinct atoms of A. Then the set
Parti(C(A)) =
{(β1 | ⊤) ⊓(β2 | ¬β1) ⊓. . . ⊓(βi | ¬β1 ∧. . . ∧¬βi−1) | ⟨β1, β2, . . . , βi⟩∈Seqi(A)}
is a partition of C(A), that is,  Parti(C(A)) = ⊤and for any distinct C, D ∈
Parti(C(A)), C ⊓D = ⊥.
Proof. (1) The case i = 1 is easy as Seq1(A) = {⟨α⟩| α ∈Atom(A)}, and it is clear
that 
α(α | ⊤) = (
α α | ⊤) = ⊤.
(2) Suppose the claim is true for i −1, that is,  Parti−1(C(A)) = ⊤. Consider then a
sequence β = ⟨β1, . . . , βi−1⟩
∈Seqi−1 and its corresponding compound conditional
Hβ = (β1 | ⊤) ⊓. . . ⊓(βi−1 | ¬β1 ∧. . . ∧¬βi−2). By hypothesis, we know that

β∈Seqi−1 Hβ =  Parti−1(C(A)) = ⊤.

250
T. Flaminio et al.
Let D(β) = Atom(A) \ {β1, . . . βi−1} be the set of n −i + 1 atoms disjoint from
{β1, . . . βi−1}. Then it is clear that 
β∈D(β)(β | ¬β1 ∧. . . ∧¬βi−1) = ⊤, and thus
Hβ = 
β∈D(β) Hβ ⊓(β | ¬β1 ∧. . . ∧¬βi−1).
Therefore, since we can do this for every sequence β ∈Seqi−1, we ﬁnally get that

β∈Seqi−1
Hβ =

β∈Seqi−1
(

β∈D(β)
Hβ⊓(β | ¬β1∧. . .∧¬βi−1))=

δ∈Seqi
Hδ =

Parti(C(A))
Thus we have proved that  Parti(C(A)) = ⊤.
⊓⊔
Let A be a Boolean algebra with n atoms. We denote by Seq(A) the set of
sequences α = ⟨α1, α2, . . . , αn−1⟩of n−1 pairwise distinct atoms of A. Moreover,
for every such a sequence α ∈Seq(A), let us consider the compound conditional
ωα = (α1 | ⊤) ⊓(α2 | ¬α1) ⊓. . . ⊓(αn−1 | ¬α1 ∧. . . ∧¬αn−2),
or equivalently, ωα = (α1 | ⊤) ⊓(α2 | α2 ∨· · · ∨αn) ⊓. . . ⊓(αn−1 | αn−1 ∨αn).
Theorem 1. The set of the atoms of C(A) is Atom(C(A)) = {ωα : α ∈Seq(A)}.
As a consequence, |Atom(C(A))| = n! and |C(A)| = 2n!.
Proof. We have to prove the following two conditions:
(i) For any ωα ∈Atom(C(A)), ωα > ⊥. First of all, observe that, looking at the
way the set Atom(C(A)) is deﬁned, if ωα = ⊥for some ωα ∈Atom(C(A)) then,
by a symmetry argument it would be the case that every ωβ ∈Atom(C(A))
would also be ⊥. Second, let us show that  Atom(C(A)) = ⊤. Indeed, note
that Atom(C(A)) = Partn−1(C(A)), and thus this directly follows from Propo-
sition 2 when taking i = n −1. Therefore, we conclude that ωα > ⊥for every
ωα ∈Atom(C(A)).
(ii) For any ωα ∈Atom(C(A)), there is no D ∈C(A) such that ⊥< D < ωα. It is
enough to show that, for any element (γ | b) ∈C(A) \ {⊥}, with γ ∈Atom(A), we
have that either ωα ⊓(γ | b) = ⊥or ωα ⊓(γ | b) = ωα itself. Since γ ∈Atom(A),
then γ = αi for some 1 ≤i ≤n. Then we have two cases: either b = αi ∨· · · ∨αn,
and in that case ωα ⊓(γ | b) = ωα, or otherwise b is of the form b = αi ∨αk ∨a, for
some k < i. Then, in the latter case, we have (γ | b) ⊓(αk | αk ∨. . . ∨αn) = (αi |
αi ∨αk ∨a) ⊓(αk | αk ∨. . . ∨αn) ≤(αi | αi ∨αk) ⊓(αk | αk ∨αi) = ⊥, whence
(γ | b) ⊓ωα = ⊥as well.
⊓⊔
Example 1. Let A be the Boolean algebra of 3 atoms {α1, α2, α3} and 8 elements.
Theorem 1 tells us that the atoms of the algebra C(A) are as follows:
Atom(C(A)) = {(αi | ⊤) ⊓(αj | ¬αi) : i, j = 1, 2, 3 and i ̸= j}.
Therefore, the algebra C(A), depicted in Fig. 1, has six atoms {x1, . . . , x6} and
26 = 64 elements. In particular, we have that x1 = (α1 | ⊤) ⊓(α2 | ¬α1),
x2 = (α1 | ⊤)⊓(α3 | ¬α1), x3 = (α2 | ⊤)⊓(α1 | ¬α2), x4 = (α2 | ⊤)⊓(α3 | ¬α2),
x5 = (α3 | ⊤) ⊓(α1 | ¬α3) and x6 = (α3 | ⊤) ⊓(α2 | ¬α3).

On Boolean Algebras of Conditionals and Their Logical Counterpart
251
⊥
x1 x2 x3 x4 x5 x6
y
α1 | ⊤
α2 | ⊤
α3 | ⊤
⊤
Fig. 1. The algebra of conditionals C(A), when |Atom(A)| = 3, the atoms of which are
x1, x2, x3, x4, x5, x6. The element y = (α1 | ¬α3) is x1 ⊔x2 ⊔x5.
Let us consider the conditional y = (α1 | ¬α3). Obviously, y = {xi : xi ≤y}
and, thanks to part (2) of Lemma 1, it is easy to see that, indeed, y = x1⊔x2⊔x5.
As for a further explicative example, notice that x1 ⊔x2 = ((α1 | ⊤) ⊓(α2 |
¬α1)) ⊔((α1 | ⊤) ⊓(α3 | ¬α1)) = (α1 | ⊤) ⊓(α2 ∨α3 | ¬α1) = (α1 | ⊤) ⊓(¬α1 |
¬α1) = (α1 | ⊤). Analogously (α2 | ⊤) = x3 ⊔x4 and (α3 | ⊤) = x5 ⊔x6.
We close this section by characterising the atoms which are below a given
non-trivial basic conditional (i.e. diﬀerent from ⊤).
Lemma 2. Let α = ⟨α1, α2, . . . , αn−1⟩∈Seq(A), and let ωα be its correspond-
ing atom, i.e. ωα = (α1 | ⊤) ⊓(α2 | ¬α1) ⊓(α3 | ¬α1 ∧¬α2) ⊓. . . ⊓(αn−1 |
¬α1 ∧. . . ∧¬αn−2). Further let β ∈Atom(A) and y ∈A such that β < y. Then,
ωα ≤(β | y) iﬀ∃i ≤n −1 such that αi = β and ¬α1 ∧. . . ∧¬αi−1 ≥y.
Proof. If αi = β and ¬α1∧. . .∧¬αi−1 ≥y, then clearly (αi | ¬α1∧. . .∧¬αi−1) ≤(β | y)
and hence ωα ≤(β | y) as well. As for the other direction, we have two possibilities:
(i) There is i ≤n −1 such that αi = β. If i = 1, then since ⊤≥y, the condition
is fulﬁlled. Then assume i > 1 and ωα ⊓(β | y) = ωα, we want to prove that
¬α1 ∧. . . ∧¬αi−1 ≥y. Indeed, we have:
– If α1 ≤y, we would have (α1 | ⊤) ⊓(β | y) ≤(α1 | y) ⊓(αi | y) = ⊥, and hence
ωα ⊓(β | y) = ⊥, contradiction. Therefore α1 ≤¬y.
– If α2 ≤y, since α1 ≤¬y, we would have (α2 | ¬α1) ⊓(β | y) ≤(α2 | y) ⊓(β |
y) = ⊥, and hence ωα ⊓(β | y) = ⊥, contradiction. Therefore, α2 ≤¬y.

252
T. Flaminio et al.
– . . .
– If αi−1 ≤y, since α1 ≤¬y, α2 ≤¬y, . . . , αi−2 ≤¬y, we would have (αi−1 |
¬α1 ∧. . . ∧αi−2) ⊓(β | y) ≤(α2 | y) ⊓(β | y) = ⊥, and hence ωα ⊓(β | y) = ⊥,
contradiction. Therefore, αi−1 ≤¬y.
As consequence, α1 ∨. . . ∨αi−1 ≤¬y or, equivalently, ¬α1 ∧. . . ∧¬αi−1 ≥y.
(ii) β = αn, where αn is the remaining atom not appearing α. In this case, one can
show that ωα ⊓(β | y) = ⊥, and hence ωα ̸≤(β | y). Indeed, if β = αn < y, it
means that y ≥αi ∨αn, with i ≤n −1. Then the atom ωα contains the conjunct
(αi | ¬α1 ∧. . . ¬αi−1) = (αi | αi ∨. . . ∨αn), and we have ωα ⊓(β | y) ≤(αi |
αi ∨. . . ∨αn) ⊓(β | y) ≤(αi | αi ∨αn) ⊓(β | αi ∨αn) = ⊥.
⊓⊔
Proposition 3. Let α = ⟨α1, α2, . . . , αn−1⟩∈Seq(A), and let ωα be its corre-
sponding atom. Then, for any x, y ∈A \ {⊥} such that x ̸≥y.
ωα ≤(x | y) iﬀ∃i ≤n −1 such that: (1) αi ≤x ∧y, and (2) ∀j < i, ¬αj ≥y.
Proof. Since (x | y) ̸= ⊥, we know that At = {β ∈Atom(A) : β ≤x ∧y} ̸= ∅, and
(x | y) = {(β | y) : β ∈At}. Now, ωα ≤(x | y) iﬀthere exists β ∈At such that
ωα ≤(β | y). By Lemma 2, this holds iﬀthere is i ≤n −1 such that αi = β and for all
j < i, ¬αj ≥y.
⊓⊔
4
Towards a Logic for Conditionals
In this section we deﬁne ﬁrst steps towards a logic to reason with conditionals
whose semantics is in accordance with the notion of BAC algebras as described
above. Let L be the classical propositional logic language, built from a ﬁnite set
of propositional variables p1, p2, . . . pm. Based on L, we deﬁne the language CL
of conditionals, in the style of e.g. [8], by the following stipulations:
– Atomic conditional formulas are expressions (ϕ | ψ), where ϕ, ψ ∈L, and
such that ψ ̸⊢⊥. Atomic conditional formulas are in CL.
– Further, if Φ, Ψ ∈CL, then ¬Φ, Φ ∧Ψ, Φ ∨Ψ ∈CL.1
Deﬁnition 2. The Logic of Boolean conditionals (LBC for short) has the fol-
lowing axioms and rules, where ⊢P L denotes classical derivability:
(PL) Axioms and rule of classical propositional logic for CL formulas
(A1) (ψ | ψ)
(A2) ¬(ϕ | ψ) ↔(¬ϕ | ψ)
(A3) (ϕ | ψ) ∧(δ | ψ) ↔(ϕ ∧δ | ψ)
(A4) (ϕ | ψ) ↔(ϕ ∧ψ | ψ)
(A5) (ϕ | ψ) ↔(ϕ | χ) ∧(χ | ψ), if ⊢P L ϕ →χ and ⊢P L χ →ψ
(R1) from ⊢P L ϕ →ψ derive (ϕ | χ) →(ψ | χ)
(R2) from ⊢P L χ ↔ψ derive (ϕ | χ) ↔(ϕ | ψ)
The notion of proof in LBC, ⊢LBC, is deﬁned as usual.
1 We use the same symbols for connectives in L and in CL without danger of confusion.

On Boolean Algebras of Conditionals and Their Logical Counterpart
253
The above axiomatic system is clearly inspired on the key properties of BAC
algebras, and indeed we can prove a tight relation with them. We shall write
L to denote the Lindenbaum-Tarski algebra for the propositional language L.
For Φ, Ψ ∈CL, we write Φ ≡Ψ if ⊢LBC Φ ↔Ψ. (R1) and (R2) ensures that if
⊢P L ϕ ↔ϕ′ and ⊢P L ψ ↔ψ′, then (ϕ | ψ) ≡(ϕ′ | ψ′). The following holds.
Proposition 4. The Lindenbaum-Tarski algebra for the language of condition-
als CL, i.e. the quotient algebra CL/≡, is a BAC algebra, namely CL/≡= C(L).
Semantics and completeness
The guiding idea in deﬁning a semantics for CL is that the evaluations of CL-
formulas should be in one-to-one correspondence with the atoms of the algebra
CL/≡. Recall from Sect. 3 that the atoms of C(A) are of the form
(α1 | ⊤) ⊓(α2 | ¬α1) ⊓(α3 | ¬α1 ∧¬α2) ⊓. . . ⊓(αn−1 | ¬α1 ∧. . . ∧¬αn−2),
where α1, . . . αn−1 are atoms of original algebra A, that is, the αi’s must cor-
respond to maximal elementary conjunctions of literals, or equivalently to eval-
uations of L. In the following let Ω be the set of (classical) interpretations
for the propositional language L, i.e. Ω = {w : V ar →{0, 1}}. Note that
if there are m propositional variables, then |Ω| = 2m. Therefore, the idea is
to deﬁne CL-evaluations as sequences e = (w1, . . . , w2m), of pair-wise distinct
2m interpretations w1, . . . , w2m ∈Ω, and to stipulate that a CL-evaluation e
makes true a conditional (ϕ | ψ) when the ‘atomic’ formula determined by e,
(w1 | ⊤) ∧(w2 | ¬w1) ∧. . . ∧(wn−1 | ¬w1 ∧. . . ∧¬wn−2), is ‘below’ (ϕ | ψ),
where n = 2m and wi denotes the maximal elementary conjunction of L-literals
that are true under wi ∈Ω. Therefore, taking into account Proposition 3, we
propose the following deﬁnition of CL-evaluations.
Deﬁnition 3. A CL-evaluation is a sequence e = (w1, w2, . . . , wn) of n pairwise
distinct w1, . . . , wn ∈Ω. The corresponding truth-evaluation of formulas of CL
is as follows:
– for atomic CL-formulas: e(ϕ | ψ) = 1 if wi |= ϕ for the lowest index i such
that wi |= ψ, and e(ϕ | ψ) = 0 otherwise.
– for compound CL-formulas: e is extended using Boolean truth-functions.
The corresponding notion of consequence is as expected: for any set of CL-
formulas Γ ∪{Φ}, Γ
|=LBC Φ if, for every CL-evaluation e such that e(Ψ)
= 1 for all Ψ ∈Γ, then e(Φ) = 1.
In order to prove completeness for LBC, we need some preliminary results.
For every valuation h of the Lindenbaum algebra CL/≡into the 2-element
Boolean algebra, i.e. for every Boolean homomorphism h : CL/≡→{0, 1}, let ωh
be the unique atom in CL/≡such that h(ωh) = 1. Also, let αh = (α1, . . . , αn−1)
(for αi ∈Atom(L)) be such that ωh = ωαh. Further, for every αi, let wh
i be
the unique evaluation in Ω such that wh
i (αi) = 1. Then, we write Λ(h) =
(wh
1, . . . , wh
n−1).

254
T. Flaminio et al.
Lemma 3. Λ(h) is a CL-evaluation, and for each CL-formula Φ, h(Φ) = 1 iﬀ
Λ(h)(Φ) = 1.
Proof. Let h : CL/≡→{0, 1} be a valuation as above. By construction, it is clear that
Λ(h) is a CL-evaluation. Now we prove, by induction on the structure of the formula Φ,
that Λ(h)(Φ) = 1 iﬀh(Φ) = 1. The interesting case is when Φ is an atomic conditional
(ϕ | ψ) such that (ϕ | ψ) ̸≡⊤. Then, h(Φ) = 1 iﬀωh ≤(ϕ | ψ) iﬀ(by Proposition 3)
there is i ≤n −1 such that wh
i (ϕ) = wh
i (ψ) = 1 and wh
l (ψ) = 0 for all l < i, and thus,
iﬀΛ(h) = (wh
1 , . . . , wh
n−1) is such that a Λ(h)(Φ) = 1.
⊓⊔
Now the soundness and completeness of LBC easily follows from the above.
Theorem 2 (soundness and completeness). LBC is sound and complete
w.r.t. CL-evaluations, i.e. ⊢LBC = |=LBC.
Proof. Soundness is easy. As for completeness, assume that Γ ̸⊢LBC Φ. Thus there
exists a homomorphism h : CL/≡→{0, 1} such that h(γ) = 1 for all γ ∈Γ, and
h(Φ) = 0. Thus, by Lemma 3, Λ(h) is a CL-evaluation such that Λ(h)(γ) = 1 for every
γ ∈Γ and Λ(h)(Φ) = 0, i.e. Γ ̸ |=LBC Φ.
⊓⊔
5
Relation to Non-monotonic Reasoning Models
Conditionals possess an implicit non-monotonic behaviour. Given a conditional
(ϕ | ψ), it does not follow in general that we can freely strengthen its antecedent,
i.e. in general, (ϕ | ψ) ̸⊢LBC (ϕ | ψ ∧χ). For instance, ϕ, ψ, χ can be such that
ϕ ∧ψ ̸ |= ⊥while ϕ ∧ψ ∧χ |= ⊥. Actually, and not very surprisingly, the
logic ⊢LBC satisﬁes the analogues of KLM-properties which characterize the
well-known system P of preferential entailment [10,11].
Lemma 4. ⊢LBC satisﬁes the following properties:
Reﬂexivity: ⊢LBC (ϕ | ϕ)
Left logical equivalence: if |=P L ϕ ↔ψ then (χ | ϕ) ⊢LBC (χ | ψ)
Right weakening: if |=P L ϕ →ψ then (ϕ | χ) ⊢LBC (ψ | χ)
Cut: (ϕ | ψ) ∧(χ | ϕ ∧ψ) ⊢LBC (χ | ψ)
OR: (ϕ | ψ) ∧(ϕ | χ) ⊢LBC (ϕ | ψ ∨χ)
AND: (ϕ | ψ) ∧(δ | ψ) ⊢LBC (ϕ ∧δ | ψ)
Cautious Monotony: (ϕ | ψ) ∧(χ | ψ) ⊢LBC (χ | ϕ ∧ψ).
Proof. Reﬂexivity, Left Logical Equivalence, Right Weakening and AND correspond to
(A1), (R2), (R1), and (A3) of LBC, respectively. The other cases are proved as follows.
Cut: by (A4), (χ | ϕ ∧ψ) ∧(ϕ | ψ) is equivalent to (χ ∧ϕ ∧ψ | ϕ ∧ψ) ∧(ϕ ∧ψ | ψ), and
by (A5), it is equivalent to (χ ∧ϕ ∧ψ | ψ), and by (R1) this clearly implies (χ | ψ).
Cautious Monotony: by (A3), (ϕ | ψ) ∧(χ | ψ) is equivalent to (ϕ ∧χ | ψ), which by
(A 4) is in turn equivalent (ϕ ∧χ ∧ψ | ψ), and by (A5) implies (ϕ ∧χ ∧ψ | ϕ ∧ψ),
which by (A3) it is equivalent to (χ | ϕ ∧ψ).

On Boolean Algebras of Conditionals and Their Logical Counterpart
255
OR: (ϕ | ψ) ∧(ϕ | χ) is equivalent to [(ϕ | ψ) ∧(ϕ | χ) ∧(ψ | ψ ∨χ)] ∨[(ϕ | ψ) ∧(ϕ |
χ) ∧(χ | ψ ∨χ)], and this implies [(ϕ ∧ψ | ψ) ∧(ψ | ψ ∨χ)] ∨[(ϕ ∧χ | χ) ∧(χ | ψ ∨χ)],
that is equivalent to (ϕ ∧ψ | ψ ∨χ) ∨(ϕ ∧χ | ψ ∨χ), which ﬁnally implies (ϕ | ψ ∨χ).⊓⊔
Now, let us ﬁx a set of (atomic) conditional statements K, and let us deﬁne
the consequence relation associated to K: ϕ |∼K ψ if K ⊢LBC (ψ | ϕ). Our last
proposition is easily derived from the previous lemma.
Proposition 5. |∼K is a preferential consequence relation.
It can also be proved, but we omit this owing to space constraints, that Rational
Monotonicity is also satisﬁed by LBC. Though this property is far more con-
troversial than Cautious Monotonicity, it has been argued for in a number of
circumstances.
6
Concluding Remarks
This paper deepens the investigation on Boolean algebras of conditional events
that we began in [4]. Here, we have presented a full description of the atomic
structure of these algebras and, based on this, we have deﬁned a corresponding
logic, LBC, to reason with conditionals. Moreover, we have shown tight connec-
tions of this logic with preferential nonmonotonic consequence relations.
Our previous work [4] was motivated by investigating the relationship of
conditional probabilities on a Boolean algebra A and simple probabilities on the
algebras of conditional events C(A). Our conjecture is that for any conditional
probability on A there is a simple probability on C(A) agreeing on basic condi-
tionals. Based on our new results, a close investigation on probabilities and other
uncertainty measures on BAC algebras is the object of our future research.
Acknowledgments. We are thankful to the anonymous reviewers. Flaminio and Godo
acknowledge partial support by the Spanish FEDER/MINECO project TIN2015-71799-
C2-1-P.
References
1. Adams, E.W.: What is at stake in the controversy over conditionals. In: Kern-
Isberner, G., R¨odder, W., Kulmann, F. (eds.) WCII 2002. LNCS, vol. 3301, pp.
1–11. Springer, Heidelberg (2005). doi:10.1007/11408017 1
2. Calabrese, P.: An algebraic synthesis of the foundations of logic and probability.
Inf. Sci. 42, 187–237 (1987)
3. Dubois, D., Prade, H.: Measure-free conditioning, probability and non-monotonic
reasoning. In: Proceedings of IJCAI 1989, vol. 2, pp. 1110–1114 (1989)
4. Flaminio, T., Godo, L., Hosni, H.: On the algebraic structure of conditional events.
In: Destercke, S., Denoeux, T. (eds.) ECSQARU 2015. LNCS, vol. 9161, pp. 106–116.
Springer, Cham (2015). doi:10.1007/978-3-319-20807-7 10
5. Friedman, N., Halpern, J.Y.: Plausibility measures and default reasoning. J. ACM
48(4), 648–685 (2001)

256
T. Flaminio et al.
6. Gilio, A., Sanﬁlippo, G.: Conditional random quantities and compounds of condi-
tionals. Stud. Logica 102(4), 709–729 (2014)
7. Goodman, I.R., Nguyen, H.T., Walker, E.A.: Conditional Inference and Logic
for Intelligent Systems - A Theory of Measure-free Conditioning. North-Holland,
Amsterdam (1991)
8. Halpern, J.Y.: Deﬁning relative likelihood in partially ordered structures. J. Artif.
Intell. Res. 7, 1–24 (1997)
9. Kern-Isberner, G.: Conditionals in Nonmonotonic Reasoning and Belief Revision.
Lecture Notes in Artiﬁcial Intelligence, vol. 2087. Springer, Heidelberg (2001)
10. Lehmann, D., Magidor, M.: What does a conditional knowledge base entail? Artif.
Intell. 55(1), 1–60 (1992)
11. Makinson, D.: Bridges From Classical to Non-monotonic Logic. College Publica-
tions, London (2005)
12. Makinson, D.: Conditional probability in the light of qualitative belief change. In:
Hosni, H., Montagna, F. (eds.) Probability, Uncertainty and Rationality. Edizioni
della Normale (2010)
13. Milne, P.: Bruno de Finetti and the logic of conditional events. Br. J. Philos. Sci.
48(2), 195–232 (1997)
14. Nguyen, H.T., Walker, E.A.: A history and introduction to the algebra of con-
ditional events and probability logic. IEEE Trans. Syst. Man Cybern. 24(12),
1671–1675 (1994)
15. Schay, G.: An algebra of conditional events. J. Math. Anal. Appl. 24, 334–344
(1968)

A Semantics for Conditionals with Default
Negation
Marco Wilhelm(B), Christian Eichhorn, Richard Niland,
and Gabriele Kern-Isberner
Department of Computer Science, TU Dortmund, Dortmund, Germany
marco.wilhelm@tu-dortmund.de
Abstract. Ranking functions constitute a powerful formalism for non-
monotonic reasoning based on qualitative conditional knowledge. Con-
ditionals are formalized defeasible rules and thus allow one to express
that certain individuals or subclasses of some broader concept behave
diﬀerently. More precisely, in order to model these exceptions by means
of ranking functions, it is necessary to state that they behave contrarily
with respect to the considered property. This paper proposes condition-
als with default negation which instead enable a knowledge engineer to
formalize exceptions without giving more speciﬁc information. This is
useful when a subclass behaves indiﬀerent towards a certain property, or
the knowledge engineer wants to exclude a certain subclass because she
is not aware of its behavior. Based on this novel type of conditionals, we
further present and discuss a nonmonotonic inference formalism.
1
Introduction
Qualitative uncertain reasoning is often based on default rules of the form “if
A holds, then typically B follows”, representing semantically meaningful rela-
tionships between A and B that may serve as guidelines for rational decision
making. Such rules are called conditionals and are formally written as (B|A).
Conditionals are diﬀerent from material implications A ⇒B in that they are
trivalent logical structures [3] that cannot be interpreted truth functionally but
need richer epistemic structures to be evaluated. Ranking functions, also called
ordinal conditional functions [10], provide a most convenient way for evaluat-
ing conditionals by assigning a degree of implausibility to formulas. Therewith,
a conditional (B|A) is accepted by a ranking function iﬀits veriﬁcation A∧B
is more plausible than its falsiﬁcation A∧¬B. Based on this methodology, it
is possible to express and reason about subclasses of individuals that behave
diﬀerently to some broader concept, like the well-known penguins that form an
exceptional subclass of non-ﬂying birds. In order to model these exceptions by
means of ranking functions, it is however necessary to state that they behave
contrarily regarding the considered property. Therefore, this approach fails to
address scenarios in which a subclass behaves indiﬀerently towards a property
of their superclass, as in the following example.
c
⃝Springer International Publishing AG 2017
A. Antonucci et al. (Eds.): ECSQARU 2017, LNAI 10369, pp. 257–267, 2017.
DOI: 10.1007/978-3-319-61581-3 24

258
M. Wilhelm et al.
Example 1. Hybrid electric cars (hybrids) form a subclass of cars with an electric
engine. While one would generally attribute not having an additional gasoline
engine to electric cars, one would not do so for hybrids. More particularly, it is
unbeknownst whether said additional engine is a gasoline engine or, for instance,
diesel-powered.
In this paper, we propose a novel knowledge representation and inference
formalism which is based on conditionals with default negation. Using these
extended conditionals leaves it open whether they apply to certain subclasses,
and thus allows one to model exceptions such as the one in Example 1. Con-
ditionals with default negation are ordinary conditionals enriched with default
negated formulas within their premises that act as disqualiﬁers. Default nega-
tion, also called negation as failure [2], is an attenuated form of negation that
is used to derive not D from the failure to derive D. In our framework, a condi-
tional is blocked when a default negated formula D within its premise is assumed
to hold. As a consequence, the conditional remains unconsidered when drawing
inferences. We show that this approach leads to a novel inference relation that
is convenient for our purpose. Although both conditionals and default negation
are well-known in nonmonotonic reasoning, individually, (see, e.g., [2,4,5,8]), to
our knowledge there is no work published yet which combines both concepts.
The rest of the paper is organized as follows: After preliminary remarks on
conditionals and ranking functions, we give some examples that illustrate the
beneﬁt of expanding conditionals by default negation. Formal deﬁnitions as well
as a discussion of our inference relation based on knowledge bases containing
conditionals with default negation follow afterwards. Finally, we conclude.
2
Preliminaries
Let L = L(Σ) be the set of (propositional) formulas over a ﬁnite set of atoms
Σ built in the usual way using the connectives ∧(conjunction), ∨(disjunction),
and ¬ (negation). To shorten expressions, we write A ∧B as AB, ¬A as A,
A ∨B as A ⇒B, and ⊤instead of A ∨A for A, B ∈L. A literal ˙a is either
the atom a or its negation a. A world ω is a complete conjunction of literals,
i.e., every atom occurs in ω exactly once, either positive or negated. Thus, the
set of all worlds Ω corresponds to the complete set of interpretations of L,
and we say that a world ω is a model of a formula A, written ω |= A, iﬀ
I(A) = true where I is the interpretation associated with ω. A set of formulas
F entails a formula G, written F |= G, iﬀevery model of F is also a model
of G. A conditional (B|A) built upon formulas A, B ∈L is a formalization of
the defeasible rule “if A, then typically B” and leads to the trivalent evaluation
[[(B|A)]]ω = 1 iﬀω |= AB (veriﬁcation), [[(B|A)]]ω = 0 iﬀω |= AB (falsiﬁcation),
and [[(B|A)]]ω = u iﬀω |= A (non-applicability) with respect to some world ω.
A knowledge base R = (FR, BR) consists of a ﬁnite set of formulas FR and
a ﬁnite set of conditionals BR. The set FR represents known facts that are
certain, while conditionals in BR represent beliefs that are plausible. We call

A Semantics for Conditionals with Default Negation
259
Ω(R) = {ω ∈Ω | ∀F ∈FR : ω |= F} the set of possible worlds with respect
to (the facts in) R. Thus, the worlds that contradict at least one fact from FR
are declared as impossible and therefore excluded from Ω(R). The semantics of
knowledge bases is deﬁned via ranking functions. A ranking function, also called
ordinal conditional function [10], is a mapping κ : Ω →N∞
0
with κ−1(0) ̸= ∅,
assigning to every world a degree of implausibility. The higher the rank κ(ω) is,
the more implausible the world ω is believed to be, such that worlds with a rank
of 0 are the most plausible worlds, and those with a rank of ∞are completely
disbelieved. A ranking function κ is called a model of a conditional (B|A), written
κ |= (B|A), iﬀκ(AB) < κ(AB), whereby the rank of a formula A is deﬁned by
κ(A) = min({κ(ω) | ω |= A}). κ is a model of a knowledge base R iﬀκ is a
model of every conditional in BR and κ−1(∞) = Ω \Ω(R). Models of knowledge
bases represent epistemic states. A knowledge base R is called consistent iﬀit
has at least one model. The consistency of R can be characterized by the notion
of tolerance [5]. A conditional (B|A) ∈BR is tolerated by a set of conditionals
P ⊆BR iﬀthere is a possible world ω verifying (B|A) without falsifying any of
the conditionals in P. Therewith, R is consistent iﬀthere is an ordered partition
P(R) = (P0, P1, . . . , Pk) of BR such that each conditional in Pm is tolerated
by k
l=m Pl for 0 ≤m ≤k. When choosing the sets Pi for i = 0, . . . , k to
be maximal with respect to set inclusion (beginning from P0), one obtains a
unique tolerance partition PZ(R). The superscript Z is in reference to the well-
known System Z [9] from which the concept of tolerance partitions arises, and
therefore, we call PZ(R) the Z-partition (of BR and thus) of R. Eventually,
ranking functions yield nonmonotonic inference relations. To this end, let κ be a
model of the consistent knowledge base R, and let A and B be formulas. Then,
B can be inferred from A with respect to κ, written A|∼κ B, iﬀκ |= (B|A).
It is reasonable to assign the same rank to possible worlds with the same
conditional structure [7], i.e., κ(ω) should equal κ(ω′) if ω and ω′ verify, falsify,
and do not apply to the same conditionals in BR, as these possible worlds are
indistinguishable based on their behavior towards R. This indiﬀerence property
is not guaranteed by ranking functions in general, but it is a shared property of
the c-representations [6] and of ranking functions which fulﬁll System Z.
Deﬁnition 1 (c-Representation). A c-representation κc(R) of a consistent
knowledge base R with BR = {(B1|A1), . . . , (Bn|An)} is a ranking function
κc(R)(ω) =

i=1,...,n, ω|=AiBi κ−
i ,
iﬀω ∈Ω(R),
∞,
iﬀω ∈Ω \ Ω(R)
where the κ−
i ∈N0 for i = 1, . . . , n are impact values for falsifying the respective
conditionals, and which have to be chosen such that
κ−
i >
min
ω∈Ω(R)
ω|=AiBi
⎧
⎨
⎩

i̸=j
ω|=AjBj
κ−
j
⎫
⎬
⎭−
min
ω∈Ω(R)
ω|=AiBi
⎧
⎨
⎩

i̸=j
ω|=AjBj
κ−
j
⎫
⎬
⎭,
(1)

260
M. Wilhelm et al.
which guarantees that all c-representations of R are indeed models of R. We
will focus on the unique Z-c-representation κZ
c (R) induced by the Z-partition
PZ(R) which exists for every consistent knowledge base R (cf. [7]). The impact
values of κZ
c (R) are deﬁned as follows (ibid.): For every Pm in P, starting with
P0, and for every (Bi|Ai) ∈Pm,
κ−
i =
min
ω∈Ω(R) with ω|=AiBi and
∀(B|A)∈k
l=m Pl: ω̸|=AB
⎧
⎨
⎩

(Bj|Aj)∈m−1
l=0
Pl
ω|=AjBj
κ−
j
⎫
⎬
⎭+ 1.
(2)
The recursive deﬁnition of the impact values (2) of κZ
c (R) results in signiﬁcantly
lower computational costs in contrast to the general deﬁnition of the impact
values (1). Furthermore, we will see that Z-c-representations are very useful
when reasoning with conditionals with default negation as they coherently induce
the required models of reducts. Before we introduce conditionals with default
negation, we discuss the need for them by means of some illustrating examples.
3
Representing Exceptions with Conditionals
Conditionals in combination with c-representations are convenient to represent
and reason with many kinds of defeasible rules. For example, it is possible to
express that a class of individuals shows a typical property, whereas a certain
subclass behaves contrarily towards this property.
Example 2. We consider the knowledge base R = ({e ⇒c}, {(r|c), (¬r|e)}) sta-
ting that cars with an electric engine are, in particular, cars; cars typically have
a long range; and cars with an electric engine typically do not have a long range.
Commonsense deliberations tell us that from these conditionals we should be
able to infer that cars without an electric engine do have a long range whereas
electricity driven cars do not.
In Example 2, the exceptional behavior of electric driven cars with respect
to a car’s range is modelled by stating that cars with an electric engine behave
contrarily to prototypical cars and thus do not have a long range. However,
in some cases, one might want to treat a subclass as exceptional not because
its members behave contrarily but because they behave indiﬀerently towards a
certain property of the superclass, as for instance in Example 1. Another reason
for treating a subclass as exceptional is the lack of information on whether the
subclass shares a property of its superclass.
Example 3. Typically, cars have a bad carbon footprint. Electric driven cars are
a subclass of cars, and it is reasonable to say that they form an exception as
one might not want to commit to an estimate of the car’s carbon footprint when
that of the original power source is unknown.

A Semantics for Conditionals with Default Negation
261
Altogether, one might want to exclude subclasses from sharing a property
without stating anything about the subclasses except for their exceptionality.
Therefore, it is necessary to extend the previously introduced framework of con-
ditionals and ranking functions. The following example conﬁrms this assessment
by proving that there is no ranking function that can represent the epistemic
state induced by the given assertions.
Example 4. We continue Example 1 and consider the set of atoms Σ = {e, g, h}
that denote whether a car has an electric engine or a gasoline engine, respectively
whether it is a hybrid electric car (hybrid). A ranking function κ which shall
model the assertion that cars with an electric engine are attributed not having
a gasoline engine has to satisfy κ(eg) < κ(e.g.) (⋆). Further, since hybrids are
a subclass of cars with an electric engine, we need κ(ω) = ∞for all worlds ω
that contradict the formula h ⇒e, i.e., κ(egh) = κ(e gh) = ∞(†). In addition,
we want to model that cars with an electric engine are hybrids with a gasoline
engine more likely than non-hybrids without a gasoline engine, such that the
restriction κ(egh) < κ(egh) (‡) is satisﬁed as well. As κ(egh) < κ(e.g.) (∗) is a
consequence from (⋆) and (‡), it inevitably follows that hybrids typically do not
have a gasoline engine, i.e., κ |= (g|h):
κ(gh) ≤κ(egh)
(∗)
< κ(e.g.) ≤κ(egh)
(†)
= κ(gh).
This obviously contradicts the desire for neither treating the presence nor the
abscence of a gasoline engine as an attribute of hybrids.
In the next section, we introduce the concept of conditionals with default
negation which proves to be an extension of the presented framework that is
capable of dealing with all the exceptions discussed in this section.
4
Conditionals with Default Negation
Syntactically, conditionals with default negation are conditionals that addition-
ally contain a default-negated set of disqualiﬁers D within their premise. Such
a term not D is assumed to be true as long as no disqualiﬁer D ∈D is known
to hold. In this paper, we use the notation not D as an abbreviation for the
set of terms not D1, . . . , not Dk, where D = {D1, . . . , Dk}. In analogy to sim-
ilar concepts from answer set programming [4], the semantics of a knowledge
base containing conditionals with default negation is based on reducts of the
knowledge base that are free of default negation. These reducts are built with
respect to a formula S and describe the reasoner’s focus on a concrete situation
she is reasoning about. If one of a conditional’s disqualiﬁers is a consequence
of S, thereby falsifying the default negation not D, the respective conditional is
blocked and not contained in the reduct. As a consequence, the conditional is not
considered when drawing inferences. Due to the concept of default-negation-free
reducts, many concepts from reasoning with ordinary conditionals carry over to
reasoning with conditionals with default negation.

262
M. Wilhelm et al.
For a formal deﬁnition of conditionals with default negation, we recall L to
be a propositional language.
Deﬁnition 2 (Conditional with Default Negation). Let A, B ∈L, and let
D ⊆L be a ﬁnite set of formulas. Then, (B|A, not D) is called a conditional with
default negation. If D is empty, then (B|A, not D) equals a conditional without
default negation, and we write (B|A) instead of (B|A, not ∅).
Conditionals with default negation have the informal meaning “if A, then
typically B, unless any D ∈D holds”. A knowledge base (with default negation)
R = (FR, BR) consists of a ﬁnite set of formulas FR and a ﬁnite set of condi-
tionals with default negation BR. We use the same notation and naming as for
ordinary knowledge bases because knowledge bases without default negation can
easily be expressed as knowledge bases with (empty) default negation.
Deﬁnition 3 (Reduct). The reduct RS = (FR, BS
R) of R by some formula
S ∈L is the knowledge base R with its set of conditionals BR being replaced by
BS
R =

(B|A) | (B|A, not D) ∈BR
and
∀D ∈D : {S} ∪FR ̸|= D

.
Thus, BS
R is obtained from BR by removing all conditionals that have a
disqualiﬁer D ∈D with {S} ∪FR |= D, and subsequently omitting all default
negations in the remaining conditionals. Informally, BS
R represents those ordinary
conditional beliefs that are plausible when S is assumed to be true. Note that
this neither implies that S is believed to be true nor that S is factually true. The
aim behind determining the reduct RS is to be able to reason about the speciﬁc
scenario in which S is true, regardless of its (relative) plausibility, by adapting
the general belief BR to the assumption of S.
Example 5. By using a conditional with default negation, namely (g|e, not {h}),
we are now able to formalize that cars with electric engines typically do not
have gasoline engines unless they are hybrids, such that no estimation about
hybrids having a gasoline engine is made (cf. Example 1). In total, we consider
the knowledge base R = ({h ⇒e}, {(g|e, not {h}), (gh|e(gh ∨gh))}) over the set
of atoms Σ = {e, g, h} with the meanings
– h ⇒e
= hybrids are, in particular, cars with electric engines,
– (g|e, not {h})
= cars with electric engines typically do not have
gasoline engines unless they are hybrids,
– (gh|e(gh ∨gh)) = cars with electric engines are more likely to be hybrids
with a gasoline engine than non-hybrids without.
The only two distinct reducts of R are RS = ({h ⇒e}, {(gh|e(gh ∨gh))}) for S
with S |= h and RS′ = ({h ⇒e}, {(g|e), (gh|e(gh ∨gh))}) for S′ with S′ ̸|= h.
Although there are usually inﬁnitely many formulas to reduce a given knowl-
edge base R by, there are only ﬁnitely many distinct reducts of R as two for-
mulas S1, S2 ∈L may lead to the same reduct, i.e., RS1 = RS2, which holds

A Semantics for Conditionals with Default Negation
263
iﬀBS1
R = BS2
R . More precisely, the number of diﬀerent reducts of R is obviously
restricted by 2n where n = |BR|. Note that this upper bound is not tight.
Before we deﬁne the semantics of knowledge bases with default negation, we
want to explicitly exclude from our investigations a speciﬁc class of conditionals.
A conditional (B|A, not D) is called self-blocking with respect to a knowledge base
R = (FR, BR) iﬀ{A}∪FR |= D for some D ∈D. The formula A in the premise
of a self-blocking conditional can never be satisﬁed in the context of FR without
satisfying any of the conditional’s disqualiﬁers D ∈D, too. This means that the
conditional is a vacuous assertion. Therefore, self-blocking conditionals are not
of a reasoner’s interest and we can disregard them without any loss. We call a
knowledge base that is free of such self-blocking conditionals a self-blocking-free
knowledge base, and consider only this kind of knowledge base in the following.
Now we have covered all necessary prerequisites to deﬁne the concept of
models of knowledge bases with default negation.
Deﬁnition 4 (Model of a Self-blocking-free Knowledge Base). Let R be
a self-blocking-free knowledge base, let R(R) be the set of all reducts of R, and
let K(Ω) be the set of all ranking functions. A mapping η : R(R) →K(Ω) is
called a model of R, written η |= R, iﬀη(RS) |= RS for every RS ∈R(R).
In plain words, η is a model of R iﬀη maps every reduct of R to a ranking
function that models this speciﬁc reduct. Further, a self-blocking-free knowledge
base R is called consistent iﬀit has at least one model. Consistency can be
checked easily following the next proposition.
Proposition 1. A self-blocking-free knowledge base R is consistent iﬀits reduct
R⊤is consistent.
Proof. By deﬁnition R is consistent iﬀit has at least one model, which is the case
iﬀevery reduct of R is consistent. As for every formula S the set BS
R is a subset
of B⊤
R and subsets of consistent knowledge bases (without default negations) are
always consistent, it suﬃces to verify the consistency of the reduct R⊤.
□
Example 6. The knowledge base R from Example 5 is self-blocking-free (since
{e, h ⇒e} ̸|= h) and consistent (as R⊤= ({h ⇒e}, {(g|e), (gh|e(gh ∨gh))})
is consistent). The images of the model η of R with η(R⊤) = κZ
c (R⊤) and
η(Rh) = κZ
c (Rh), i.e., the models of the reducts of R, are shown in Table 1.
Table 1. Z-c-Representations κZ
c (R⊤) of R⊤= ({h ⇒e}, {(g|e), (gh|e(gh ∨gh))}) as
well as κZ
c (Rh) of Rh = ({h ⇒e}, {(gh|e(gh ∨gh))}).
ω
κZ
c (R⊤)(ω) κZ
c (Rh)(ω)
ω
κZ
c (R⊤)(ω) κZ
c (Rh)(ω)
egh 1
0
¯egh ∞
∞
eg¯h 1
0
¯eg¯h 0
0
e¯gh 0
0
¯e¯gh ∞
∞
e¯g¯h 2
1
¯e¯g¯h 0
0

264
M. Wilhelm et al.
Based on the notion of models of knowledge bases with default negation, we
are now able to deﬁne a nonmonotonic inference relation.
Deﬁnition 5 (Nonmonotonic Inference Relation). Let R be a consistent
knowledge base, let η be a model of R, and let A, B ∈L be formulas. Then, B
can be inferred from A with respect to η, written A|≈η B, iﬀA|∼η(RA) B, i.e.,
iﬀη(RA) |= (B|A).
The idea behind the inference A|≈η B is as follows: We assume A to be true
and check if B is more plausible than B in the presence of A. If so, we infer
B from A, and thus, A|≈η B holds. To this end, the assumption that A is true
allows us to evaluate the default negations in R with respect to the trueness of
FR ∪{A}, i.e., we build the reduct RA in which only those conditionals remain
that are not blocked by A verifying one of their disqualiﬁers. Reasoning then
reduces to reasoning with a knowledge base without default negation, namely
the model η(RA) of RA, and common techniques can be used to check whether
B is more plausible than B in the presence of A, i.e., iﬀη(RA) |= (B|A).
Example 7. We recall the model η with η(R⊤) = κZ
c (R⊤) and η(Rh) = κZ
c (Rh)
of the knowledge base R = ({h ⇒e}, {(g|e, not {h}), (gh|e(gh ∨gh))}) from
Example 6. As Re = R⊤and due to κZ
c (R⊤)(eg) = 0 < 1 = κZ
c (R⊤)(e.g.), it
holds that κZ
c (Re) |= (g|e). Hence, we infer that cars with an electric engine
typically do not have a gasoline engine. However, we can neither infer that
hybrids do have a gasoline engine nor that they do not have since there is no
preference either way: κZ
c (Rh)(gh) = 0 = κZ
c (Rh)(gh). Therefore, we can now
obtain the desired inference behavior (cf. Example 4) unlike when reason based
on ordinary knowledge bases.
The inference relation |≈η fulﬁlls a wide range of inference properties, includ-
ing reﬂexivity (REF), and (AND), modus ponens in the consequence (MPC),
right weakening (RW), and left logical equivalence (LLE), as stated in the next
proposition (cf. [8] for a discussion of the inference properties).
Proposition 2. Let R = (FR, BR) be a consistent knowledge base, and let η be
a model of R. Then, A|≈ηA (REF) and
A|≈ηB
and
A |≈η C
imply
A |≈η BC,
(AND)
A|≈ηB ⇒C
and
A |≈η B
imply
A |≈η C,
(MPC)
B |= C
and
A |≈η B
imply
A |≈η C,
(RW)
A ≡B
and
A |≈η C
imply
B |≈η C.
(LLE)
Proof. The proofs are purely technical, so, due to spatial restrictions, we only
present the proof of (LLE): Due to A ≡B, it holds that RA = RB, and A|≈ηC
holds iﬀη(RA) |= (C|A) iﬀη(RB) |= (C|A) iﬀη(RB) |= (C|B) iﬀB|≈ηC.
Hence, (LLE) holds. Other proofs can be furnished in a similar fashion since |≈η
essentially inherits its properties from |∼κ.

A Semantics for Conditionals with Default Negation
265
However, |≈η does not satisfy the entirety System P [1], as the inference prop-
erties cumulative transitivity (CUT), i.e., A|≈ηB and AB|≈ηC imply A|≈ηC, and
cautious monotonicity (CM), i.e., A|≈ηB and A|≈ηC imply AB|≈ηC, do not hold
in general. The non-fulﬁllment of (CUT) and (CM) is an unpleasent property
of nonmonotonic inference relations and thus of |≈η. However, the fulﬁllment
of both (CUT) and (CM) can be guaranteed by weak additional assumptions
(e.g., when claiming RA = RAB). Until now, any two images of a model η of a
consistent knowledge base R, i.e., the models of any two distinct reducts of R,
can be chosen completely independently. The following example shows that this
freedom of choice can lead to undesirable behavior.
Table 2. All c-representations κc(R⊤) of R⊤= {∅, {(s|dr), (s|d), (d|s)}} and κc(Rr)
of Rr = {∅, {(s|dr), (s|d)}}. In the ﬁrst case, the impact values have to be chosen such
that κ−
1 > 0 and κ−
2 + κ−
3 > 0. In the second case, κ−
1
′ > 0 and κ−
2
′ > 0 have to hold.
ω
κc(R⊤)(ω) κc(Rr)(ω)
ω
κc(R⊤)(ω) κc(Rr)(ω)
drs 0
0
¯drs κ−
2 + κ−
3
κ−
2
′
dr¯s κ−
1
κ−
1
′
¯dr¯s 0
0
d¯rs 0
0
¯d¯rs κ−
2 + κ−
3
κ−
2
′
d¯r¯s 0
0
¯d¯r¯s 0
0
Example 8. We consider the set of atoms Σ = {d, r, s} and the knowledge base
R = {∅, {(s|dr), (s|d), (d|s, not {r})} with the meanings
– (s|dr)
= if the housetop is damaged and it rains, then typically
the ﬂoor inside is soaked,
– (s|d)
= if the housetop is not damaged, then typically the ﬂoor
inside is not soaked,
– (d|s, not {r}) = if the ﬂoor inside is soaked, then typically the housetop
is damaged, unless it does not rain.
R has two distinct reducts, depending on whether r is assumed to hold or not.
Table 2 shows the schemata of all possible c-representations κc(R⊤) and κc(Rr)
of these both reducts. A reasoner now is allowed to assign to the possible world
ω = dr¯s diﬀerent ranks of implausibility, namely κ−
1 and κ−
1
′, depending on the
reduct used to establish her epistemic state. However, in both cases the implau-
sibility of ω = dr¯s only depends on the impact value of the ﬁrst conditional
(w|ds) which can be chosen regardless of the absence or presence of the third
conditional, (d|s, not {r}). Thus, the rank of implausibility should be the same
for ω in both cases, i.e., κ−
1 = κ−
1
′ should hold.
Hence, Example 8 advises the reasoner to use a common meta strategy when
determining the models of the diﬀerent reducts of R. An obvious strategy is to
choose the respective Z-c-representations.

266
M. Wilhelm et al.
Deﬁnition 6 (Z-c-Mapping). Let R be a consistent knowledge base. We call
the model η of R with η(RS) = κZ
c (RS) for every reduct RS of R the Z-c-
mapping of R. We denote the Z-c-mapping of R with ηZ
c (R).
The Z-c-mapping ηZ
c (R) of R is unique as Z-c-representations are unique,
and hence, ηZ
c (R) is predetermined by the knowledge base R itself.
Example 9. The Z-c-mapping of R from Example 8 can be obtained from the
c-representation schemata given in Table 2 by instantiating all impact values
κ−
1 , κ−
2 , κ−
3 as well as κ−
1
′, κ−
2
′ with 1. Thus, κ−
1 = κ−
1
′ holds as desired.
Another example of a Z-c-mapping is given in Example 6. It remains an open
question if Z-c-mappings show more inference properties than those presented
in Proposition 2.
5
Conclusion
In this paper, we introduced a novel semantics for conditionals with default nega-
tion that allows for drawing nonmonotonic inferences. Basically, conditionals
with default negation enable a reasoner to formulate conditional rules that typ-
ically hold unless a certain disqualiﬁer applies. If so, the respective conditional
remains unconsidered when drawing inferences from the reasoner’s knowledge
base. In our approach, the validity of the disqualiﬁer is checked with respect
to a conditional query, and thus, the reasoner is able to incorporate assump-
tions into her query and even to draw inferences based on implausible beliefs.
Further, we argued that default negations truly extend the concept of condition-
als as we were able to capture epistemic states by models of knowledge bases
with default negation that cannot be reproduced using ordinary conditionals and
ranking functions. In future work, we want to further investigate the properties
of our proposed inference relation, particularly for speciﬁc subclasses of knowl-
edge bases, formulate complexity results, and extend our approach to reasoning
with probabilistic conditionals with default negation.
Acknowledgments. This research was supported by the DFG research unit FOR
1513 on “Hybrid Reasoning for Intelligent Systems” and the DFG grant KI1413/5-1 to
Prof. Kern-Isberner as part of the priority program “New Frameworks of Rationality”
(SPP 1516).
References
1. Adams, E.W.: The Logic of Conditionals: An Application of Probability to Deduc-
tive Logic. Springer, New York (1975)
2. Clark, K.L.: Negation as Failure. In: Gallaire, H., Minker, J. (eds.) Logic and Data
Bases. Springer, New York (1978)
3. de Finetti, B.: Theory of Probability. Wiley, New York (1974)
4. Gelfond, M.: Answer sets. In: Lifschitz, V., van Hermelen, F., Porter, B. (eds.)
Handbook of Knowledge Representation. Elsevier, San Diego (2008)

A Semantics for Conditionals with Default Negation
267
5. Goldszmidt, M., Pearl, J.: Qualitative probabilities for default reasoning, belief
revision, and causal modeling. Artif. Intell. 84, 57–112 (1996)
6. Kern-Isberner, G.: Conditionals in Nonmonotonic Reasoning and Belief Revision:
Considering Conditionals As Agents. Springer, New York (2001)
7. Kern-Isberner, G.: A thorough axiomatization of a principle of conditional preser-
vation in belief revision. Ann. Math. Artif. Intell. 40, 127–164 (2004)
8. Lehmann, D.J., Magidor, M.: What does a conditional knowledge base entail?
Artif. Intell. 55, 1–60 (1992)
9. Pearl, J.: System Z: A natural ordering of defaults with tractable applications to
default reasoning. In: Proceedings of the 3rd TARK Conference (1990)
10. Spohn, W.: The Laws of Belief: Ranking Theory and Its Philosophical Applications.
Oxford University Press, Oxford (2012)

Credal Sets, Credal Networks

Incoherence Correction and Decision Making
Based on Generalized Credal Sets
Andrey G. Bronevich1,2(B) and Igor N. Rozenberg1,2
1 National Research University Higher School of Economics,
Myasnitskaya 20, 101000 Moscow, Russia
brone@mail.ru, I.Rozenberg@gismps.ru
2 JSC Research, Development and Planning Institute
for Railway Information Technology, Automation and Telecommunication,
Orlikov Per.5, Building 1, 107996 Moscow, Russia
Abstract. While making decisions we meet diﬀerent types of uncer-
tainty. Recently the concept of generalized credal set has been proposed
for modeling conﬂict, imprecision and contradiction in information. This
concept allows us to generalize the theory of imprecise probabilities giv-
ing us possibilities to process information presented by contradictory
(incoherent) lower previsions. In this paper we propose a new way of
introducing generalized credal sets: we show that any contradictory lower
prevision can be represented as a convex sum of non-contradictory and
fully contradictory lower previsions. In this way we can introduce gener-
alized credal sets and apply them to decision problems. Decision making
is based on decision rules in the theory of imprecise probabilities and
the contradiction-imprecision transformation that looks like incoherence
correction.
Keywords: Contradictory (incoherent) lower previsions · Decision mak-
ing · Generalized credal sets · Incoherence correction
1
Introduction
Recently the extension of imprecise probabilities based on generalized credal sets
has been proposed [3,4]. By the classical theory of imprecise probabilities [1,2,
6,8] we can model two types of uncertainty: conﬂict associated with probability
measures and imprecision (non-speciﬁcity) linked with the choice of a probability
measure among possible alternatives. Generalized credal sets allow us also to
model contradiction when the avoiding sure loss condition is not fulﬁlled. Each
upper generalized credal set consists of special plausibility functions, conceived
as lower probabilities, whose bodies of evidence consist of singletons and certain
event. The part consisting of singletons models conﬂict in information and the
part described by a certain event models contradiction.
In our previous research [3,4] we have shown how we can work with contra-
dictory lower and upper previsions based on generalized credal sets, we introduce
c
⃝Springer International Publishing AG 2017
A. Antonucci et al. (Eds.): ECSQARU 2017, LNAI 10369, pp. 271–281, 2017.
DOI: 10.1007/978-3-319-61581-3 25

272
A.G. Bronevich and I.N. Rozenberg
the construction like natural extension in the classical theory of imprecise prob-
abilities, we describe conditions when generalized credal sets generate models
based on usual imprecise probabilities.
In the paper we show how generalized credal sets can be used for correcting
incoherent information and how they can be applied to decision problems.
2
Monotone Measures: Basic Deﬁnitions and Notations
Let X = {x1, ..., xn} be a ﬁnite set of elementary events, and let 2X be the
algebra of all subsets of X. A set function μ : 2X →[0, 1] is called a monotone
measure if μ(∅) = 0, μ(X) = 1 and μ(A) ⩽μ(B) for any A, B ∈2X such that
A ⊆B. A monotone measure μ is
– a probability measure if μ(A ∪B) = μ(A) + μ(B) for any A, B ∈2X such that
A ∩B = ∅;
– a belief function if there is a set function m : 2X →[0, 1] called the basic belief
assignment (bba) with m(∅) = 0 and 
B∈2X m(B) = 1 such that μ(A) =

B⊆A m(B).
In the sequel Mmon denotes the set of all monotone measures on 2X; Mpr
denotes the set of all probability measures on 2X; and Mbel denotes the set of
all belief functions on 2X.
We deﬁne on Mmon the following operations and relations:
– μ = aμ1 + (1 −a)μ2 for μ1, μ2 ∈Mmon and a ∈[0, 1] if μ(A) = aμ1(A) + (1 −
a)μ2(A) for all A ∈2X;
– μ1 ⩽μ2 for μ1, μ2 ∈Mmon if μ1(A) ⩽μ2(A) for all A ∈2X;
– μd is the dual of μ if μd(A) = 1 −μ(Ac) for all A ∈2X, where Ac is the
complement of A.
Let Bel ∈Mbel with bba m, then
– Beld is called a plausibility function;
– a set B ∈2X is called a focal element if m(B) > 0;
– the set of all focal elements is called the body of evidence;
– a belief function is called categorical if its body of evidence contains one focal
element B ∈2X. This set function is denoted by η⟨B⟩and can be computed
as η⟨B⟩(A) =
1, B ⊆A,
0, B ̸⊆A. ;
– Any Bel ∈Mbel with bba m can represented as a convex sum of categorical
belief functions Bel =

B∈2X m(B)η⟨B⟩.
Assume that M is an arbitrary subset of Mmon, then M d = {μd|μ ∈M}. In
such a way M d
bel denotes the set of all plausibility functions on 2X.

Incoherence Correction Based on Generalized Credal Sets
273
3
Credal Sets, Lower and Upper Previsions
In
the
following
any
P
∈
Mpr
can
be
represented
as
a
point
(P({x1}), ..., P({xn})) in Rn. By deﬁnition [1,6], a credal set P is a non-empty
subset of Mpr, which is convex and closed. Convexity of P means that P1, P2 ∈P
and a ∈[0, 1] implies that aP1 + (1 −a)P2 ∈P, and P is closed as a subset of
Rn. A model based on credal sets is one of the most general models of imprecise
probabilities. We can describe credal sets using lower and upper previsions. Let
K be a set of all real-valued functions f : X →R on X. Then any f ∈K can
be viewed as a random variable for a ﬁxed P ∈Mpr and we can compute its
expectation deﬁned by EP (f) = 
x∈X
f(x)P({x}). Let K′ be an arbitrary subset
of K, then any functional E : K′ →R is called a lower prevision if each value
E(f), f ∈K′, is viewed as a lower bound of expectation of the random variable
f. This lower prevision is called non-contradictory (or it avoids sure loss) iﬀit
deﬁnes the credal set
P(E) = {P ∈Mpr|∀f ∈K′ : EP (f) ⩾E(f)}
(1)
Otherwise, when the set P(E) is empty, the lower prevision is called contradictory
(or incoherent). Analogously, upper previsions are deﬁned. Any functional ¯E :
K′ →R is called an upper prevision if its values are viewed as upper bounds
of expectations. It is non-contradictory (or it avoids sure loss) iﬀit deﬁnes the
credal set
P( ¯E) =

P ∈Mpr|∀f ∈K′ : EP (f) ⩽¯E(f)

,
and it incurs sure loss otherwise. Models of uncertainty based on upper and
lower previsions are equivalent. It follows from the fact that every lower prevision
E : K′ →R and the corresponding upper prevision
¯E(f) = −E(−f),
−f ∈K′,
deﬁne the same credal set. The central role in reasoning based on imprecise prob-
abilities plays the natural extension. Let E : K′ →R be an non-contradictory
lower prevision and P(E) be the credal set deﬁned by formula (1), then the
natural extension of E is a functional
E′(f) =
inf
P ∈P(E) EP (f),
f ∈K′.
A lower prevision E is called coherent if E(f) = E′(f) for all f ∈K′. Analo-
gously the natural extension of non-contradictory upper previsions is deﬁned and
coherent upper previsions are introduced. Monotone measures can be considered
as special models of lower and upper previsions. In this case K′ = {1A}A∈2X,
where 1A is the characteristic function of the set A, i.e. μ(A) = E(1A), A ∈2X,
can be viewed as a set function. A monotone measure μ is called a lower prob-
ability if its values give us lower bounds of probabilities. It is non-contradictory
if it deﬁnes the credal set P(μ) = {P ∈Mpr|μ ⩽P}. We can deﬁne analogously

274
A.G. Bronevich and I.N. Rozenberg
the natural extension of non-contradictory lower previsions and the family of
coherent lower probabilities. In the same way we deﬁne upper probabilities that
give us upper bounds of probabilities, the natural extension of non-contradictory
upper probabilities and coherent upper probabilities.
Remark 1. Obviously, min
x∈X f(x) ⩽EP (f) ⩽max
x∈X f(x) for any P ∈Mpr and
f ∈K. Thus, without decreasing generality we can assume that values E(f) of
any lower prevision E : K′ →R should be not larger than max
x∈X f(x), i.e. E(f) ⩽
max
x∈X f(x) for any f ∈K′. Analogously, we will assume that ¯E(f) ⩾min
x∈X f(x) for
any upper prevision ¯E : K′ →R and f ∈K′, This assumption will be used later
without mentioning about it.
4
Generalized Credal Sets for Describing Contradictory
Lower Previsions
Assume that we have estimates ˆp(xi), i = 1, ..., n, of probabilities, but unfor-
tunately n
i=1 ˆp(xi) ̸= 1. What should we do? One can say that the avail-
able information is defective and it is not possible to use it. But if the value
ε = |n
i=1 ˆp(xi) −1| is small, then this conclusion seems to be not useful.
Otherwise we should correct ˆp(xi). Assume that n
i=1 ˆp(xi) < 1, then the
correction can be done by adding to each ˆp(xi) a value αi ⩾0 such that
n
i=1 (ˆp(xi) + αi) = 1. Thus, uncertainty can be modeled by the set of proba-
bility distributions

(p(x1), ..., p(xn)) |p(xi) ⩾ˆp(xi), i = 1, ..., n,
n
i=1 p(xi) = 1

.
Observe that in this case values ˆp(xi) looks like lower bounds of probabili-
ties, but this does not follow from the problem statement. To avoid ambiguity
we should decide whether ˆp(xi) give us lower or upper bounds of probabilities.
Lower probabilities have been intensively investigated in the theory of impre-
cise probabilities and they describe two types of uncertainty: conﬂict associated
with probability measures and non-speciﬁcity linked with the choice of a prob-
ability measure among possible alternatives. If values ˆp(xi) are viewed as upper
probabilities then we say that the available information incurs sure loss or it is
contradictory.
Let us analyze the above model in detail. If ˆp(xi) = 0, i = 1, ..., n, and ˆp(xi)
are viewed as lower bounds of probabilities, then the set

(p(x1), ..., p(xn)) |p(xi) ⩾0, i = 1, ..., n,
n
i=1 p(xi) = 1

contains all possible probability distributions or probability measures on 2X.
Thus, in such a case, values ˆp(xi) = 0, i = 1, ..., n, describe the situation of
complete ignorance. We will describe this situation by a vacuous belief function
η⟨X⟩viewed as lower probability. Analogously, if ˆp(xi) = 0, i = 1, ..., n, are viewed

Incoherence Correction Based on Generalized Credal Sets
275
as upper bounds of probabilities, then we can describe contradiction by the set
of all probability measures Mpr, or by η⟨X⟩viewed as an upper probability. This
situation can be understood as the case of full contradiction.
Although we can describe contradiction and non-speciﬁcity by the set of
probability measures there is a principal diﬀerence between these two types of
uncertainty. Non-speciﬁcity means that we don’t know exactly what kind of
probability model should be chosen among possible alternatives, but contradic-
tion means that we have some deﬁciency in estimating probabilities. The last
problem appears when we try to use simultaneously diﬀerent probabilistic mod-
els for analyzing statistical data or to aggregate pieces of evidence from separate
sources of information.
Let us remind the notion of contradiction from usual logic. Let we have a
set of axioms A1,...,Am, and if we use the set-theoretical model, then any Ai
can be represented as a subset of a ﬁnite set X. Then this system of axioms is
contradictory iﬀA1 ∩... ∩Am = ∅. In logic we can infer from the contradictory
system of axiom that any conclusion is true. This situation can be described by
the contradictory lower probability
ηd
X(A) =
1, A ̸= ∅,
0, A = ∅.
Thus, the case of full contradiction can be described by any lower probability
μ ∈Mmon such that μ(A1) = ... = μ(Am) = 1 and A1 ∩... ∩Am = ∅. In general
the case of full contradiction can be described by the following deﬁnition.
Deﬁnition 1. The information described by a lower prevision E : K′ →R
is fully contradictory iﬀE can not be represented as a convex sum E(f) =
aE(1)(f) + (1 −a)E(2)(f) of a non-contradictory lower prevision E(1) : K′ →R,
and a (contradictory) lower prevision E(2) : K′ →R for some a ∈(0, 1].
Lemma 1. A lower prevision E : K′ →R is fully contradictory iﬀfor any
a ∈(0, 1] the lower prevision E′(f) = 1
a
	
E(f) −(1 −a) max
x∈X f(x)

, f ∈K′, is
contradictory.
Lemma 2. If the set of contradictory previsions on K′ is not empty, then the
lower prevision ˆE(f) = max
x∈X f(x), f ∈K′, is fully contradictory.
Remark 2. It is possible to choose K′ such that every lower prevision is non-
contradictory. In this case ˆE is also a non-contradictory lower prevision. Because
the aim of the paper is to deal with contradictory information, in the next
we will assume that K′ is chosen providing the lower prevision ˆE to be fully
contradictory.
Let E : K′ →R be a lower prevision. Then by Lemma 1 and Lemma 2 (see
also Remark 2) it can be always represented as a convex sum
E(f) = aE(1)(f) + (1 −a)E(2)(f),
(2)

276
A.G. Bronevich and I.N. Rozenberg
where E(1) is a non-contradictory lower prevision and a lower prevision E(2) is
fully contradictory. If a ∈(0, 1], then by Lemma 1 E(2) can be chosen to be equal
to ˆE. If the lower prevision E is fully contradictory, then E(2) = E, a = 0, and
we can take a non-contradictory lower prevision E(1) arbitrarily. We see that the
largest value of a characterizes the amount of contradiction in E. Thus, we can
introduce the following deﬁnition.
Deﬁnition 2. Let E : K′ →R be a lower prevision and let A be the set of all
possible values a ∈[0, 1], for which the representation (2) exists for some non-
contradictory lower prevision E(1) and a fully contradictory lower prevision E(2).
Then the amount of contradiction is deﬁned by Con(E) = 1 −sup{a|a ∈A}.
Obviously, by Deﬁnition 2 Con(E) = 0 iﬀE is a non-contradictory lower previ-
sion, and Con(E) = 1 iﬀE is fully contradictory. Let us introduce new concepts,
which will help us to simplify the computation of Con(E). Consider monotone
measures on 2X of the type
P = a0ηd
⟨X⟩+
n

i=1
aiη⟨{xi}⟩,
(3)
where
n
i=0
ai = 1, ai ⩾0, i = 0, ..., n, and P is viewed as a lower probability.
Such a P can be represented also as P = a0ηd
⟨X⟩+ (1 −a0)P ′, where ηd
⟨X⟩is a
fully contradictory lower probability and P ′ is a probability measure deﬁned by
P ′ =
1
1−a0
n
i=1
aiη⟨{xi}⟩for a0 ̸= 1. We can extend P to the lower prevision on
the set of all functions in K by
EP (f) = a0 max
x∈X f(x) +
n

i=1
aif(xi).
Again EP can be represented as a convex sum of fully contradictory lower pre-
vision ˆE and linear prevision EP ′, i.e. EP (f) = a0 ˆE(f) + (1 −a0)EP ′(f) for all
f ∈K. We will denote by Mcpr the set of all monotone measures deﬁned by (3).
Lemma 3. Let P = a0ηd
⟨X⟩+
n
i=1
aiη⟨{xi}⟩be in Mcpr. Then Con(P) = a0.
We will identify each P ∈Mcpr from (3) with a point (a1, ..., an) in Rn. Let
P1, P2 ∈Mcpr and Pi = (a(i)
1 , ..., a(i)
n ), i = 1, 2, then P1 ⩽P2 iﬀa(1)
k
⩾a(2)
k ,
k = 1, ..., n. Clearly, such P1 and P2 can describe the same information, but P2
is a lower probability with higher contradiction.
Deﬁnition 3. A subset P of Mcpr is called an upper generalized credal set (UG-
credal set) if
(1) P1 ∈P, P2 ∈Mcpr, and P1 ⩽P2 implies P2 ∈P;

Incoherence Correction Based on Generalized Credal Sets
277
(2) P1, P2 ∈P implies aP1 + (1 −a)P2 ∈P for every a ∈[0, 1];
(3) P is a closed set if we consider it as a subset of Rn.
We will describe any lower prevision E : K′ →R by a UG-credal set P deﬁned by
P = {P ∈Mcpr|∀f ∈K′ : E(f) ⩽EP (f)} .
(4)
Remark 3. Obviously, the set deﬁned by (4) is not empty, because it always
contains the measure ηd
⟨X⟩.
Proposition 1. Let E : K′ →R be a lower prevision, and let P be its corre-
sponding UG-credal set deﬁned by (4). Then
Con(E) = inf {Con(P)|P ∈P} .
(5)
5
Decision Making Based on Contradictory
Lower Previsions
Assume that E : K′ →R is a lower prevision and Con(E) = b. If b = 1 then
E is fully contradictory and E does not contain useful information. Therefore,
this case is identical to the case of complete ignorance. Let b < 1, then for any
a ∈(0, 1 −b] the lower prevision E can be represented as E(f) = aE(1)(f) +
(1 −a)E(2)(f), f ∈K′, where E(1) is a non-contradictory and E(2) is a fully
contradictory lower prevision. Obviously, decision making should be based on
information in E(1). Notice also that decreasing parameter a we get information
in E(1) more imprecise. Therefore, it makes a sense taking a = 1 −b. It is also
possible to choose E(2) = ˆE. After this choice the above representation can be
rewritten as E(f) = (1 −b)E(1)(f) + b ˆE(f), f ∈K′.
Assume that a non-contradictory lower prevision E(1) deﬁnes the credal set
P′ =

P ∈Mpr|∀f ∈K′ : E(1)(f) ⩽EP (f)

. Then taking in account that ˆE
describes the case of full contradiction, we can describe E by a credal set P′′
represented as a convex sum of two credal sets in which the ﬁrst is P′ and the
second describes the case of complete ignorance, i.e.
P′′ = {(1 −b)P1 + bP2|P1 ∈P′, P2 ∈Mpr} .
(6)
The following proposition shows how the above set P′′ can be found based
on UG-credal sets.
Proposition 2. Let E : K′ →R be a lower prevision, Con(E) = b, and let P
be its corresponding UG-credal set. Then
P′′ = {P ′ ∈Mpr|∃P ∈P : Con(P) = b, P ′ ⩽P} .
(7)

278
A.G. Bronevich and I.N. Rozenberg
The above transformation E : K′ →R of a contradictory lower prevision to the
non-contradictory information presented by the credal set P′′ can be considered
as incoherence correction in which full contradiction is transformed to complete
ignorance. After this transformation we can use known models of decision making
considered in imprecise probabilities. In our paper we will consider the decision
rule justiﬁed in many works (e.g. [1,8].).
We will identify each decision with a function in K. Assume that available
information is described by a credal set P′′ ⊆Mpr. Then decision f2 ∈K is
at least preferable as decision f1 ∈K (f1 ≼f2) if EP ′(f1) ⩽EP ′(f2) for every
P ′ ∈P′′. This rule can be rewritten as f1 ≼f2 if EP′′(f2 −f1) ⩾0, where
EP′′(f) =
inf
P ∈P′′ EP (f), f ∈K.
Lemma 4. Let we use notations as in formula (6). Then the expression for
EP′′(f) can be transformed to
EP′′(f) = (1 −b)EP′(f) + b min
x∈X f(x),
where EP′(f) = inf
P ∈P′ EP (f).
Let us consider the computational scheme by which this decision rule can be
realized. A function f ∈K is called normalized from above if max
x∈X f(x) = 0.
The following lemma shows how we can normalize functions for a given lower
prevision.
Lemma 5. Let E : K′ →R be a lower prevision. Consider the set K′′ =

¯f = f −max
x∈X f(x)|f ∈K′

of normalized from above functions. Then a lower
prevision E′ : K′′ →R deﬁnes the same UG-credal set as E if E′( ¯f) = E(f) −
max
x∈X f(x) for all f ∈K′.
Clearly the above lemma allows us to assume that functions in K′, on which
a lower prevision E is deﬁned, are normalized from above.
Proposition 3. Let K′ be a ﬁnite subset of normalized functions from above in
K and let E : K′ →R be a lower prevision. Then Con(E) = max{0, b}, where
b is the solution of the following linear programming problem:
b = 1 −
n

i=1
ai →min,
⎧
⎨
⎩
n
i=1
aifk(xi) ⩾E (fk) ,
fk ∈K′,
ai ⩾0,
i = 1, ..., n,

Incoherence Correction Based on Generalized Credal Sets
279
Proposition 4. Let K′ be a ﬁnite subset of normalized functions from above
in K and let E : K′ →R be a lower prevision with Con(E) = b. Then c =
(1 −b)EP′(f) for any f ∈K is the solution of the following linear programming
problem:
c =
n

i=1
aif(xi) →min,
⎧
⎪
⎪
⎨
⎪
⎪
⎩
n
i=1
aifk(xi) ⩾E (fk) ,
fk ∈K′,
n
i=1
ai = 1 −b,
ai ⩾0,
i = 1, ..., n.
Example 1. Let we have two pieces of evidence. The ﬁrst says that the prob-
ability that it will be sunny tomorrow is higher or equal than 0.3. The second
says that the probability of rain is higher or equal than 0.8. We can describe
this information by the states of the world: x1 := sunny, x2 := rain, and
denote X = {x1, x2}. Then we have E

1{x1}

= 0.3, E

1{x2}

= 0.8. For using
our computational scheme functions 1{x1} and 1{x2} should be normalized from
above. Doing it we get functions f1 = 1{x1} −1X and f2 = 1{x2} −1X with
E (f1) = −0.7 and E (f2) = −0.2. Then the amount of contradiction can be
computed by solving the following linear programming problem:
b = 1 −a1 −a2 →min
⎧
⎨
⎩
−a2 ⩾−0.7,
−a1 ⩾−0.2,
a1, a2 ⩾0.
Thus, b = 0.1. Assume that we need to compute c = (1 −b)EP′(f) for some
f ∈K. Then c can be computed by solving the following linear programming
problem:
c = a1f(x1) + a2f(x2) →min,
⎧
⎨
⎩
−a2 ⩾−0.7,
−a1 ⩾−0.2,
a1 + a2 = 0.9, a1, a2 ⩾0.
Thus, c = 0.2f(x1) + 0.7f(x2). In this case by Lemma 4 EP′′(f) = 0.2f(x1) +
0.7f(x2) + 0.1 min
x∈X f(x). Assume, for example, that we have two decisions: g1 :=
go to the park; g2 := go to the theater; deﬁned by g1(x1) = 3, g1(x2) = −1,
g2(x1) = 1, g2(x2) = 1. Then
EP′′(g2 −g1) = 0.2 · (−2) + 0.7 · 2 + 0.1 · (−2) = 0.8 > 0,
i.e. decision g2 is more preferable than decision g1.

280
A.G. Bronevich and I.N. Rozenberg
6
The Comparison with Previous Works
Incoherence correction has been considered in the papers by A. Capotorti and
others (see [5] and references therein), and in the work [7] by E. Quaeghebeur.
The main idea described in [5] is to use distances between incoherent lower pre-
vision and the set of all possible coherent previsions, i.e. the best approximation
is to use the closest coherent lower prevision to the available assessments. Among
possible distances (divergences) are L1- and L2-distances, the logarithmic Breg-
man divergence, the discrepancy measure. In [7] the correction is produced by
the lower envelope of maximal coherent lower previsions, which are lower than
a given incoherent lower prevision.
Let us compare the incoherence correction based on generalized credal sets
and the mentioned above approaches. Assume that μ ∈Mmon is an upper enve-
lope of the set of probability measures P, i.e.
μ(A) = sup
P ∈P
P(A),
A ∈2X,
but it is viewed as a lower probability. Obviously, μ is a contradictory lower
probability if P contains at least two diﬀerent probability measures. If we apply
methods from [5], then we choose some optimal approximation P ∈P of μ. Thus,
using this correction we cannot take in account that information is contradictory
- every two decisions are comparable. If we use the approach considered in [7],
then obviously after correction we get the coherent lower probability
μd(A) = inf
P ∈P P(A),
A ∈2X.
Although sometimes corrections based on our approach and this one give us the
same result (this is fulﬁlled for Example 1), but in some cases they can give us
suﬃciently diﬀerent results, when, for example, we choose P such that μ is a
fully contradictory lower probability and P ̸= Mpr. In this case, by our approach
μ does not give us useful information, but the Quaeghebeur’s approach supposes
that μ contains some useful information that seems to be not correct.
References
1. Augustin, T., Coolen, F.P.A., de Cooman, G., Troﬀaes, M.C.M. (eds.): Introduction
to Imprecise Probabilities. Wiley, New York (2014)
2. Bronevich, A.G., Klir, G.J.: Measures of uncertainty for imprecise probabilities: an
axiomatic approach. Int. J. Approx. Reason. 51, 365–390 (2010)
3. Bronevich, A.G., Rozenberg, I.N.: The generalization of the the conjunctive rule for
aggregating contradictory sources of information based on generalized credal sets.
In: Augustin, T., Doria, S., Miranda, E., Quaeghebeur, E. (eds.) Proceedings of the
9th International Symposium on Imprecise Probability: Theories and Applications,
pp. 67–76. Aracne Editrice, Rome (2015)
4. Bronevich, A.G., Rozenberg, I.N.: The extension of imprecise probabilities based on
generalized credal sets. In: Ferraro, M.B., Giordani, P., Vantaggi, B., Gagolewski,
M., Gil, M.A., Grzegorzewski, P., Hryniewicz, O. (eds.) Advances in Intelligent
Systems and Computing. 456, pp. 87–94. Springer Verlag, Berlin (2017)

Incoherence Correction Based on Generalized Credal Sets
281
5. Brozzi, A., Capotorti, A., Vantaggi, B.: Incoherence correction strategies in statis-
tical matching. Int. J. Approx. Reason. 53, 1124–1136 (2012)
6. Klir, G.J.: Uncertainty and Information: Foundations of Generalized Information
Theory. Wiley-Interscience, Hoboken (2006)
7. Quaeghebeur, E.: Characterizing coherence, correcting incoherence. Int. J. Approx.
Reason. 56(Part B), 208–233 (2015)
8. Walley, P.: Statistical Reasoning with Imprecise Probabilities. Chapman and Hall,
London (1991)

Reliable Knowledge-Based Adaptive Tests
by Credal Networks
Francesca Mangili, Claudio Bonesana, and Alessandro Antonucci(B)
Istituto Dalle Molle di Studi sull’Intelligenza Artiﬁciale, Lugano, Switzerland
{francesca,claudio,alessandro}@idsia.ch
Abstract. An adaptive test is a computer-based testing technique which
adjusts the sequence of questions on the basis of the estimated ability
level of the test taker. We suggest the use of credal networks, a general-
ization of Bayesian networks based on sets of probability mass functions,
to implement adaptive tests exploiting the knowledge of the test devel-
oper instead of training on databases of answers. Compared to Bayesian
networks, these models might oﬀer higher expressiveness and hence a
more reliable modeling of the qualitative expert knowledge. The counter-
part is a less straightforward identiﬁcation of the information-theoretic
measure controlling the question-selection and the test-stopping criteria.
We elaborate on these issues and propose a sound and computationally
feasible procedure. Validation against a Bayesian-network approach on
a benchmark about German language proﬁciency assessments suggests
that credal networks can be reliable in assessing the student level and
eﬀective in reducing the number of questions required to do it.
1
Introduction
The use of communication and information technologies in education is actually
growing. Both online (e.g., MOOCs) and classroom courses are urgently asking
for more ﬂexible and sophisticated e-learning and e-testing tools [1]. AI-based
approaches such as intelligent tutoring systems, adapting the interaction with the
student on the basis of his/her knowledge and/or psychological proﬁle, represent
an important direction to improve the quality of the (e-)learning experience [2].
Bayesian networks (BNs) [3] have been used to model the knowledge driving
such intelligent systems [4]. However, collecting large sets of reliable data in edu-
cational domains may be diﬃcult and time consuming (e.g., a course with few
students, or taught for the ﬁrst time), and the quantiﬁcation should be based
on expert knowledge only. To elicit a Bayesian network, an expert might face
questions like: “which is the probability of a student with a particular knowledge
level giving the right answer to a question?”. Giving sharp probabilities for ques-
tions of this kind can be problematic for an expert, whose knowledge is mostly
qualitative (e.g., “a right answer is very unlikely”). Fuzzy linguistic approaches
represent a viable, non-numerical, way to address these issues [5]. To stick within
the probabilistic framework, verbal-numerical probability scales associated with
sharp values [6] or intervals [7] have been also proposed.
c
⃝Springer International Publishing AG 2017
A. Antonucci et al. (Eds.): ECSQARU 2017, LNAI 10369, pp. 282–291, 2017.
DOI: 10.1007/978-3-319-61581-3 26

Reliable Knowledge-Based Adaptive Tests by Credal Networks
283
In this paper we show how to conjugate an interval-valued probabilistic elic-
itation of expert knowledge with the BN framework. This means to cope with a
credal network (CN) [8], a generalization of BNs based on the imprecise prob-
ability theory [7], where local parameters are deﬁned by set-valued probabili-
ties. This simpliﬁes the elicitation process and oﬀers a more reliable handling of
the related uncertainty. Moving from BNs to CNs implies two main issues: (i)
numerical inferences will be interval-valued too, thus making debatable both the
decision criterion [9] an the information measures [10] to adopt; and (ii) inference
tasks in CNs typically belongs to higher complexity classes than their Bayesian
counterparts [11]. Both these issues are addressed by deﬁning a computation-
ally feasible procedure based on CNs to be used for practical implementation
of intelligent systems solely speciﬁed by expert knowledge. To the best of our
knowledge this is the ﬁrst attempt to perform e-testing with models of this kind.
We focus on the application of CNs to computer adaptive testing (CAT), i.e.,
an approach to e-testing that adjusts the sequence and the number of questions
to the ability level of the test taker. CATs have the potential to make the test
an individualised experience that challenges and does not discourage the test
takers, as most of the questions are near their ability levels. Building upon item
response theory [12], the common background underpinning CATs, graphical
modeling (such as BNs and CNs) oﬀers a powerful language for describing com-
plex multivariate dependencies between skills and rich tasks. Several researchers
have exploited the potential of BNs both in adaptive and non-adaptive educa-
tional assessment [13,14]. These authors focus on applications for which data
are available to learn the model parameters. We regard this point as a serious
limitation, possibly hindering CATs adoption by many teachers and instructors.
We start from a CAT procedure based on BNs that uses entropy as the
information-theoretic measure driving the question selection and the stopping
criteria (Sect. 2). Our goal is to improve this procedure by using CNs to better
describe the pervasive uncertainty characterizing the model. A direct extension
of the Bayesian framework to CNs would require the computation of bounds for
the conditional entropy with respect to the CN speciﬁcation. This corresponds
to a non-linear non-convex optimization task. We therefore propose a number
of simplifying assumptions to overcome this problem at the price of accepting
sub-optimal question selection schemes (Sect. 3). The approach is tested on a
real-world benchmark about German language proﬁciency assessment (Sect. 5).
The results are promising: CAT based on CNs is eﬀective in reducing the num-
ber of questions while maintaining a high accuracy in the evaluation and the
approximations introduced do not compromise the procedure’s eﬀectiveness.
2
Adaptive Testing by Bayesian Networks
Skills modeling. We describe the knowledge level of a student as a collection
of categorical variables, say X := (X1, . . . , Xn), called skills. A joint probability
mass function (PMF) P(X) describes the uncertainty about the actual values
of the skills. A compact speciﬁcation of such multivariate model can be achieved

284
F. Mangili et al.
by a BN [3]. This corresponds to: (i) a directed acyclic graph whose nodes are in
one-to-one correspondence with the variables of X; and (ii), for each Xi ∈X,
a collection of conditional PMFs P(Xi|πXi), one for each value πXi of the joint
variable ΠXi denoting the parents (i.e., the immediate predecessors) of Xi. The
Markov condition for BNs assumes every variable conditionally independent of
its non-descendants non-parents given the parents. Accordingly, the joint PMF
associated with a BN is such that P(x) := n
i=1 P(xi|πXi), for each x, where
the values of xi and πXi are those consistent with x.
Questions modeling. The above joint probabilistic model describes the uncer-
tainty about the skills of a student prior to his/her answers to the questions. To
evaluate the student we formulate a number of questions, described as a collec-
tion of variables Y := (Y1, . . . , Ym). We assume these variables to be Boolean,
with the true value corresponding to the correct answer.1 We call background of
a question the set of skills “required” to answer it. This can be regarded as a
conditional independence statement: given the background skills, the answer to
the question is independent of the other skills and of the other questions. Fol-
lowing the Markov condition, this can be modeled by representing each question
as a leaf node whose parents are the background skills. Such augmented graph
requires the quantiﬁcation, for each Yj ∈Y , of a conditional PMF P(Yj|πYj) for
each value πYj of the background skills ΠYj. This procedure deﬁnes a BN over
the skills and the questions, and hence a joint PMF P(X, Y ).
Non-adaptive testing. Let Y = y denote a student’s answers to the test. In
the above considered framework, the posterior knowledge about the skills is
modeled by the joint PMF P(X|y). By running standard BN updating algo-
rithms, the most probable level ˜xi of skill Xi can be therefore evaluated as
˜xi := arg maxxi P(xi|y), for each Xi ∈X. This reﬂects a non-adaptive, proba-
bilistic approach to student evaluation.
Adaptive testing. To add adaptiveness to the above approach, every question
should be chosen on the basis of the previous answers. As the goal is to gather
information about the student skills, we evaluate the expected information gain
(IG, i.e., the change in information entropy) associated with each possible new
question, and pick the one maximizing this measure. The entropy of a BN over
X can be computed as H(X) := n
i=1 H(Xi|ΠXi) [3], where H(Xi|ΠXi) :=

πXi H(Xi|πXi)P(πXi) is the conditional entropy for X given its parents and
H(Xi|πXi) is the entropy of the conditional PMF P(Xi|πXi).2 Let Y = y denote
the answers to the questions already asked and Y ′ the set from which the next
question should be picked. If the answer to every question Y ′ ∈Y ′ would be
1 Extension to non Boolean answers is trivial as all answers Yi are manifest variables,
and, thus, Yi can be always regarded as a binary variable with the two values denoting
the observed answer yi and its negation [15].
2 To have entropy levels between zero and one, we deﬁne the entropy of the PMF
P(X) as H(X) := −
x P(x) logb P(x), with b number of states of X.

Reliable Knowledge-Based Adaptive Tests by Credal Networks
285
known, and denoted by y′, the question ˜Y ′ ∈Y′ to choose would be the one
leading to the largest IG. Yet, as the decision has to be made before the student’s
answer, conditional entropy should be considered instead, i.e.,
˜Y ′ := arg max
Y ′∈Y ′ [H(X|y) −H(X|Y ′, y)] .
(1)
CATs should also decide when to stop asking questions. Again, entropy can be
used as a measure to decide when the current evaluation is suﬃciently informa-
tive, i.e., we stop the test if the skills entropy given the answers is below some
threshold ˜H. The overall approach is depicted in Fig. 1.
PICK A
QUESTION
QUESTIONS
DATABASE
ASK
QUESTION
COLLECT
ANSWER
STOPPING
RULE?
END TEST
ASSIGN
LEVELS
YES
NO
Fig. 1. CAT procedure
3
Adaptive Testing by Credal Networks
Credal sets and credal networks. A set of PMFs over Xi is called here credal
set (CS) and denoted as K(Xi). We always remove the inner points (i.e., those
corresponding to convex combinations of the others) of a CS. CNs [16] are gen-
eralized BNs whose local PMFs are replaced by CSs. The BN deﬁned in the pre-
vious section over the skills X and the questions Y becomes a CN if we replace
with CSs the skill-to-skill and skill-to-question conditional PMFs. A joint CS
K(X, Y ) is consequently obtained as the collection of all the joint PMFs induced
by BNs whose parameters take their values from the corresponding CSs, i.e.,
K(X, Y ) :=

P(X, Y )

P (x,y):=n
i=1 P (xi|πXi)·m
j=1 P (yj|πYj ),
P (Xi|πXi)∈K(Xi|πXi), P (Yj|πYj )∈K(Yj|πYj )

,
(2)
where the values of xi, πXi, yj, πYj are those consistent with x and y.
Expert knowledge modeling. For a reliable expert knowledge modeling, we use
CSs induced by probability intervals. Qualitative judgments about the probability
of a state are converted in interval constraints such as l ≤P(x) ≤u, with the
interval [l, u] capturing the expert knowledge behind the judgment in a more
reliable way than a sharp assessment. The CS consistent with these constraints
is eventually obtained by standard polyhedral algorithms. Verbal to interval-
numeric scales such as that Table 2 are used. For instance, if for the probability
of the true state of the Boolean variable Y the expert judgment is “very likely”,
the corresponding linear constraint is .2 ≤P(Y = true) ≤.4.

286
F. Mangili et al.
Non-adaptive testing. Given the answers y to the questions Y , we evaluate the
student as in the previous section by updating the marginal probabilities of each
skill. With CNs, these posterior values are set-valued and their characterization
can be provided by lower and upper bounds, say P(Xi|y) and P(Xi|y) for each
Xi ∈X. CN updating algorithms can eventually compute these bounds. The
task displays higher complexity than in the case of BNs (e.g., exact inference in
non-binary singly-connected CNs is NP-hard [11]), but approximate techniques
can be considered when exact inference is unfeasible [17].
To compare the posterior intervals and decide the actual level of the student
we might adopt the (conservative) interval dominance criterion [9], which rejects
a level if its upper probability is smaller than the lower probability of some
other level. Overlaps between intervals might therefore induce a situation of
indecision between two or more levels. This is a so-called credal classiﬁcation
of the student level [18], and it represents the fact that students answers are
somehow contradictory or not informative enough to provide a sharp decision.
Interval dominance can return unnecessarily imprecise results. Maximality is a
more reﬁned criterion that rejects the levels which are less probable than another
level for all the elements of the CS [7]. Maximality can be reduced to multiple
updating tasks on auxiliary binary leaf nodes deﬁned for each pair of states [17].
Adaptive testing. To achieve CAT with CNs using entropy as measure of informa-
tiveness for PMFs, as in the BN approach of Sect. 2, computation of entropies
should be extended to CSs. This topic has been the subject of much discus-
sion [10]. A cautious approach [19] consists in taking the upper entropy H(X),
i.e., the entropy of the most entropic PMF in the convex closure K(X) of
K(X). In our framework, we should, then, look for maximum values of con-
ditional entropies, such as H(Xi|Y ′, y) or H(Xi|ΠXi), as conditional entropies
are required to compute both: (i) the joint (unconditional) entropy H(X) (and
its posterior values); and (ii) the conditional entropies involved in the question
selection in Eq. (1). By deﬁnition a conditional entropy is a convex combination
(whose weights are the elements of a marginal PMF) of convex functions (the
entropies). The objective function might, then, be non-convex, as the weights
are also optimization variables.3
Then, to bypass this non-convex optimization task, we compute (i) by sepa-
rately considering the entropies of each skill Xi ∈X. This is analogous to the
marginal approach commonly considered in multi-label classiﬁcation to mini-
mize Hamming losses [20]. The issue (ii) is more challenging. We consider the
following upper approximation of H(Xi|Y ′, y):
H(Xi|Y ′, y) =
max
P (y′|y)∈{P (y′|y),P (y′|y)}

y′∈{true,false}
H(Xi|y, y′)P(y′|y) ,
(3)
3 E.g., if f(x) and g(x) are convex functions of x, h(x, y) := yf(x) + (1 −y)g(x) is not
convex even for 0 ≤y ≤1.

Reliable Knowledge-Based Adaptive Tests by Credal Networks
287
where the bounds of P(y′|y) are obtained by standard CN updating algorithms.
The problem thus reduces to the computation of upper entropies as
H(Xi|y) :=
sup
P (Xi|y)∈K(Xi|y)
H(Xi|y) ,
(4)
where K(Xi|y) is the posterior CS after conditioning on the observed answers y.
If K(Xi|y) has a ﬁnite number of non-inner points, this is a linearly-constrained
convex optimization whose solution typically corresponds to either the uniform
PMF or a non-inner point on the frontier of K(Xi|y). A numerical solution can
be easily found by a simple iterative approach in the special case of CS speciﬁed
by probability intervals [19]. We have therefore computed the posterior lower
and upper bounds of P(Xi|y), and then maximized the entropy with respect to
those bounds. The procedure induces an outer approximation of K(Xi|y), and
hence the upper approximation of the maximum entropy H(X|y) ≥H(X|y).
Finally, to generalise Eq. (2) to CNs, we deﬁne the information gain provided
by a question Y ′ for its background skill XY ′ as H(XY ′|y) −H(XY ′|Y ′, y) and
select the question ˜Y ′ leading to the maximum information gain, i.e.,
˜Y ′ := arg max
Y ′∈Y ′

H(XY ′|y) −H(XY ′|Y ′, y)
	
.
(5)
For the stopping criterion, as we do not consider the joint entropy over the
skills, we separately require each H(Xi|y) to be smaller than a threshold ˜H. To
be consistent with this choice, we remove from the set of questions to be selected,
those whose background skills already satisfy this condition.
Note that the use of an outer approximation of the upper entropy aﬀects
only the question selection process (eventually making it sub-optimal), whereas
it has no eﬀect on the student evaluation given a set of answers.
4
Application to Language Assessment
Before the academic year begins, the students of the University of Applied Sci-
ences and Arts of Southern Switzerland (SUPSI) are asked to take an online
German language placement test with 95 questions. In years 2015 and 2016, the
answers of 451 students to all the questions have been collected. This benchmark
is used to simulate CATs based on BNs and CNs as described in Sects. 2 and 3.
Model elicitation. Four skills are assessed: W¨ortschatz (X1, vocabulary), Kom-
munikation (X2, communication), H¨oren (X3, listening), and Lesen (X4, read-
ing). For each skill the student is assigned to a knowledge level compliant with
EU guidelines.4 Levels A1, A2, B1, and B2 are considered, and skills are there-
fore modeled as quaternary variables. Teachers associate each question with a
single skill, which is set as the unique background skill of the question. The
4 http://www.coe.int/t/dg4/linguistic/Source/Framework EN.pdf.

288
F. Mangili et al.
number of questions associated with X1/X2/X3/X4 is 26/24/30/15. The cur-
rent evaluation method assigns levels by setting thresholds on the percentage γ
of correct answers on each skill (A1 if γ < 35%, A2 up to 55%, B1 up to 75%).5
We ﬁrst elicit from the teachers the structure of the BN/CN graph over
the skills. The result is a chain, which is augmented by leaf nodes modeling
the questions, each having its background skill as single parent. Overall, a tree-
shaped topology as in Fig. 2 is obtained. This makes exact inference in the BN
fast, while in the CN a variable elimination might be slow (a minute for query
in our setup). A faster approximate CN algorithm is therefore used [17].
X1
X2
X3
X4
Y1
Y2
Y3
Y4
Y5
Y6
Y7
Fig. 2. A directed graph for CAT.
Teachers report their knowledge about the unconditional states of X1 and the
conditional states of Xi given Xi−1, for i = 2, 3, 4, as qualitative judgments (top
of Table 1). To simplify the elicitation, the probabilities P(Xi|Xi−1) are given
the same verbal judgment for all i = 2, 3, 4. A more detailed model could provide
more accurate evaluations but it would be very hard for the domain expert to
elicit it in a reliable way. Also, questions are divided by the teachers in three
groups, corresponding to diﬀerent diﬃculty levels. Questions in the same group
are quantiﬁed in the same way, irrespective of their background skill, giving the
judgments reported in the bottom part of Table 1.
For the CN, those judgements are translated in interval constraints for the
corresponding events on the basis of the verbal-numerical scale in Table 2. Dif-
ferent probability intervals are considered for skills and questions as they refer
to events of diﬀerent type. For instance, when the expert considers “impossible”
for an A1 level student to know the answer to a diﬃcult question, the student is
assigned a probability between .175 and .2 of answering correctly, as the ques-
tions oﬀer only four choices plus the option of giving no answer. Notice that, by
doing so, we are not anymore assuming that all questions in the same diﬃculty
group share exactly the same conditional PMFs (as done by the BN model), as
PMFs of diﬀerent questions can vary independently in the given intervals. This
seems a more sensible assumption than that of the precise model. For the BN,
the PMFs corresponding to the centers of mass of the CSs deﬁning the CN are
used. Numerical inferences in the BN are consequently included in the intervals
computed with the CN.
5 These data as well as the software used for the simulations are freely available at
http://ipg.idsia.ch/software.php?id=138.

Reliable Knowledge-Based Adaptive Tests by Credal Networks
289
Table 1. Expert judgements.
X1
P(X1)
A1 improbable
A2 uncertain
B1 uncertain
B2 improbable
P(Xi|Xi−1) Xi−1 = A1
Xi−1 = A2
Xi−1 = B1
Xi−1 = B2
Xi=A1
ﬁfty-ﬁfty
uncertain
improbable
impossible
Xi=A2
uncertain
ﬁfty-ﬁfty
uncertain
improbable
Xi=B1
improbable
uncertain
ﬁfty-ﬁfty
uncertain
Xi=B2
impossible
improbable
uncertain
ﬁfty-ﬁfty
P(Y = T|X)
X = A1
X = A2
X = B1
X = B2
Easy
uncertain
ﬁfty-ﬁfty
expected
probable
Medium
improbable uncertain
ﬁfty-ﬁfty
expected
Diﬃcult
impossible improbable uncertain
ﬁfty-ﬁfty
Table 2. A verbal-numerical scale for probability-intervals elicitation.
Judgement impossible improbable uncertain ﬁfty-ﬁfty
expected
probable
Skills
1–10%
10–20%
20–40%
30–50%
-
-
Questions
17.5–20%
22.5–25%
30–35%
60–65%
75–80%
95–97.5%
Experimental results. BN and CN methods in their non-adaptive (NA) and
adaptive (AD) versions are considered. Accuracy, i.e., the proportion of stu-
dents to whom the test assigns the same level of the current evaluation method,
describes BN performances. This measure cannot be used for the set-valued out-
puts of CN methods. In this case the u65 measure can provide a comparison
with the accuracy [18]. If L is the set of levels assigned by the CN on a skill
and L its cardinality, a discounted accuracy gives 1/L if L includes the true
level and zero otherwise. The u65 is a concave reinforcement of this score based
on risk-adverse arguments. Its underlying assumption is that acknowledging the
indecision between more levels has larger utility than randomly choosing one of
them (e.g., the teacher could set up further assessments in the undecided cases).
Table 3 shows the NA comparison. In Fig. 3(left), the BN-NA accuracy is sepa-
rately evaluated on the determinate (light bars) and indeterminate (dark bars)
instances, i.e. those for which, respectively, a single level or multiple levels are
returned by the CN model. On average, CN-NA returns single levels in 37.25% of
the cases and, if this is not the case, an average of 2.36 levels (3.22 with interval
dominance) are returned.
In the AD case we also track the average number of asked questions.
Results are in Fig. 3(right). CN-AD (circles) is tested for diﬀerent thresholds
over the entropy (labels of the markers) against a version of BN-AD based on
the joint entropy (triangles). Similar values are obtained by coping with mar-
ginal entropies. We also allow the BN-AD method to return multiple levels by

290
F. Mangili et al.
Table 3. Non-adaptive tests results.
Algorithm
Average X1
X2
X3
X4
BN-NA (acc) 63.09%
67.56% 60.85% 75.84% 48.10%
CN-NA (u65) 65.37%
67.71% 66.67% 70.33% 56.76%
X1
X2
X3
X4
0
.25
.50
.75
1
Skills
acc
determinate
indeterminate
40
50
60
70
80
90
50
55
60
65
.7
.65
.6
.55
.45
.3
0
.7
.65
.6
.55
.45
.3
0
.95
.925
.9
.8
0
Number of questions
acc/u65
BN-AD
BN-AD’
CN-AD
Fig. 3. Non-adaptive (left) and adaptive (right) tests performance.
maximizing the expected u65 utility over any possible set of levels. This variant
is called BN-AD’ and the corresponding u65 measure is reported (squares).
As a comment, CNs seem to identify hard-to-evaluate students as those for
which multiple levels are provided. In fact, the agreement between the BN and
the traditional tests is larger when the CN test is determinate. As a consequence,
the CN u65 measure is, on average, larger than the BN accuracy. A limitation of
the CN test is the large fraction of indeterminate evaluations. One can interpret
this result as a lack of robustness of the BN model, as even small variations
in the model speciﬁcations can result in diﬀerent decisions. Results also show
that, both BN-AD and CN-AD approaches reduce the number of questions asked
without signiﬁcantly aﬀecting the accuracy. BN-AD performances are improved
by the “credal” variant BN-AD’. The results becomes very similar to those of
the CN-AD. Yet, the latter method appears to be a more principled and suitable
approach for a direct modeling of qualitative expert knowledge.
5
Conclusions and Outlooks
A procedure for adaptive testing built solely on expert knowledge has been
proposed based on credal networks. The procedure has been validated on a
real dataset about a German language test. Results are promising, as the credal
approach simpliﬁes the model elicitation, recognizes when a sharp decision about
the student level should not be made (that is, when the traditional and precise
Bayesian evaluations disagree) and achieves an accuracy comparable to that of
an indecisive Bayesian approach maximizing the expected u65 measure. However,
the fraction of instances where CNs issue multiple levels remains rather large,
therefore further research is needed to make CN-based CATs a viable solution
for adaptive testing solely based on expert knowledge.

Reliable Knowledge-Based Adaptive Tests by Credal Networks
291
References
1. Pollard, E., Hillage, J.: Exploring e-learning. Inst. for Empl., Studies Brighton
(2001)
2. Burns H., Luckhardt, C.A., Parlett, J.W., Redﬁeld, C.L.: Intelligent Tutoring Sys-
tems: Evolutions in Design. Psychology Press (2014)
3. Koller, D., Friedman, N., Models, P.G.: Principles and Techniques. MIT Press,
Cambridge (2009)
4. Almond, R.G., Mislevy, R.J., Steinberg, L., Yan, D., Williamson, D.: Bayesian
Networks in Educational Assessment. Springer, New York (2015)
5. Badaracco, M., Mart´ınez, L.: A fuzzy linguistic algorithm for adaptive test in
intelligent tutoring system based on competences. Expert Syst. Appl. 40(8), 3073–
3086 (2013)
6. Renooij, S., Witteman, C.: Talking probabilities: communicating probabilistic
information with words and numbers. Int. J. Approx. Reason. 22(3), 169–194
(1999)
7. Walley, P.: Statistical Reasoning with Imprecise Probabilities. Chapman &
Hall/CRC Monographs on Statistics & Applied Probability. Taylor & Francis
(1991)
8. Piatti, A., Antonucci, A., Zaﬀalon, M.: Building knowledge-based systems by credal
networks: a tutorial. In: Baswell, A.R. (ed.) Advances in Mathematics Research,
vol. 11. Nova Science Publishers, New York (2010)
9. Troﬀaes, M.: Decision making under uncertainty using imprecise probabilities. Int.
J. Approx. Reason. 45(1), 17–29 (2007)
10. Klir, G., Wierman, M.: Uncertainty-Based Information: Elements of Generalized
Information Theory. STUDFUZZ, vol. 15. Springer, Heidelberg (1999)
11. Mau´a, D., de Campos, C., Benavoli, A., Antonucci, A.: Probabilistic inference in
credal networks: new complexity results. J. Artif. Intell. Res. 50, 603–637 (2014)
12. Hambleton, R.K., Swaminathan, H.: Item Response Theory: Principles and Appli-
cations, vol. 7. Springer Science & Business Media, New York (1985)
13. Vomlel, J.: Building adaptive tests using Bayesian networks. Kybernetika 40(3),
333–348 (2004)
14. Plajner, M., Vomlel, J.: Bayesian network models for adaptive testing, arXiv
preprint arXiv:1511.08488
15. Antonucci, A., Piatti, A.: Modeling unreliable observations in bayesian networks
by credal networks. In: Godo, L., Pugliese, A. (eds.) SUM 2009. LNCS (LNAI), vol.
5785, pp. 28–39. Springer, Heidelberg (2009). doi:10.1007/978-3-642-04388-8 4
16. Cozman, F.G.: Credal networks. Artif. Intell. 120, 199–233 (2000)
17. Antonucci, A., de Campos, C., Zaﬀalon, M., Huber, D.: Approximate credal net-
work updating by linear programming with applications to decision making. Int.
J. Approx. Reason. 58, 25–38 (2014)
18. Zaﬀalon, M., Corani, G., Mau´a, D.: Evaluating credal classiﬁers by utility-
discounted predictive accuracy. Int. J. Approx. Reason. 53(8), 1282–1301 (2012)
19. Abellan, J., Moral, S.: Maximum of entropy for credal sets. Int. J. Uncertain. Fuzz.
11(05), 587–597 (2003)
20. Antonucci, A., Corani, G.: The multilabel naive credal classiﬁer. Int. J. Approx.
Reason. 83, 320–336 (2016)

Decision Theory, Decision Making and
Reasoning Under Uncertainty

Algorithms for Multi-criteria Optimization
in Possibilistic Decision Trees
Nahla Ben Amor1, Fatma Essghaier1,2(B), and H´el`ene Fargier2
1 LARODEC, Le Bardo, Tunisia
nahla.benamor@gmx.fr, essghaier.fatma@gmail.com
2 IRIT, Toulouse, France
fargier@irit.fr
Abstract. This paper raises the question of solving multi-criteria
sequential decision problems under uncertainty. It proposes to extend
to possibilistic decision trees the decision rules presented in [1] for non
sequential problems. It present a series of algorithms for this new frame-
work: Dynamic Programming can be used and provide an optimal strat-
egy for rules that satisfy the property of monotonicity. There is no guar-
antee of optimality for those that do not—hence the deﬁnition of ded-
icated algorithms. This paper concludes by an empirical comparison of
the algorithms.
Keywords: Possibility theory · Sequential decision problems · Multi-
criteria decision making · Decision trees
1
Introduction
When information about uncertainty cannot be quantiﬁed in a probabilistic
way, possibilistic decision theory is a natural ﬁeld to consider [2–7]. Qualitative
decision theory is relevant, among other ﬁelds, for applications to planning under
uncertainty, where a suitable strategy (i.e. a set of conditional or unconditional
decisions) is to be found, starting from a qualitative description of the initial
world, of the available decisions, of their (perhaps uncertain) eﬀects and of the
goal to reach (see [8–10]). But up to this point, the evaluation of the strategies
was considered in a simple, mono-criterion context, while it is often the case that
several criteria are involved in the decision [11].
A theoretical framework has been proposed for multi-criteria/multi-agent
(non sequential) decision making under possibilistic uncertainty [1,12]. In the
present paper, we extend it to decision trees and we propose a detailed algorith-
mic study. After a refreshing on the background (Sect. 2), Sect. 3 presents our
algorithms, and is completed, in Sect. 4, by an experimental evaluation.
2
Background
2.1
Multi-criteria Decision Making (MCDM) Under Uncertainty
Following Dubois and Prade’s possibilistic approach of decision making under
qualitative uncertainty, a non-sequential (i.e. one stage) decision can be seen
c
⃝Springer International Publishing AG 2017
A. Antonucci et al. (Eds.): ECSQARU 2017, LNAI 10369, pp. 295–305, 2017.
DOI: 10.1007/978-3-319-61581-3 27

296
N. Ben Amor et al.
as a possibility distribution1 over a ﬁnite set of outcomes, called a (simple)
possibilistic lottery [2]. Such a lottery is denoted L = ⟨λ1/x1, . . . , λn/xn⟩where
λi = πL(xi) is the possibility that decision L leads to outcome xi; this possibility
degree can also be denoted by L[xi]. In this framework, a decision problem is
thus fully speciﬁed by a set of possibilistic lotteries on X and a utility function
u : X →[0, 1]. Under the assumption that the utility scale and the possibility
scale are commensurate and purely ordinal, [2] proposes to evaluate each lottery
by a qualitative, optimistic or pessimistic, global utility:
Optimistic utility: U +(L) = max
xi∈X min(λi, u(xi))
(1)
Pessimistic utility: U −(L) = min
xi∈X max(1 −λi, u(xi))
(2)
U +(L) is a mild version of the maximax criterion: L is good as soon as it is totally
plausible that it gives a good consequence. On the contrary, the pessimistic index,
U −(L) estimates the utility of an act by its worst possible consequence: its value
is high whenever L gives good consequences in every “rather plausible” state.
This setting assumes a ranking of X by a single preference criterion, hence the
use of a single utility function. When several criteria, say a set Cr = {1, . . . , p}
of p criteria, have to be taken into account, u must be replaced by a vector
u = ⟨u1, . . . , up⟩of utility functions uj. If the criteria are not equally important,
each j is equipped with a weight wj ∈[0, 1] reﬂecting its importance.
In the absence of uncertainty, each decision leads to a unique consequence and
the problem is a simple problem of qualitative MCDM aggregation; classically,
such aggregation shall be either conjunctive (i.e. based on a weighted min) or
disjunctive (i.e. based on a weighted max) - see [13] for more details about
weighted min and weighted max aggregations.
In presence of uncertainty, the aggregation can be done ex-ante or ex-post:
– The ex-ante approach consists in computing the (optimistic or pessimistic)
utility relative to each criterion j, and then performs the MCDM aggregation.
– The ex-post approach consists in ﬁrst determining the aggregated utility (con-
junctive or disjunctive) of each possible xi; then the problem can be viewed
as a mono-criterion problem of decision making under uncertainty.
Since the decision maker’s attitude with respect to uncertainty can be either
optimistic or pessimistic and the way of aggregating the criteria either conjunc-
tive or disjunctive, [1,12] propose four ex-ante and four ex-post approaches:
U −min
ante (L) = min
j∈Cr max((1 −wj), min
xi∈X max(uj(xi), (1 −L[xi])))
(3)
U −max
ante (L) = max
j∈Cr min(wj, min
xi∈X max(uj(xi), (1 −L[xi])))
(4)
U + min
ante (L) = min
j∈Cr max((1 −wj), max
xi∈X min(uj(xi), L[xi]))
(5)
1 A possibility distribution π is a mapping from the universe of discourse to a bounded
linearly ordered scale, typically by the unit interval [0, 1].

Algorithms for Multi-criteria Optimization in Possibilistic Decision Trees
297
U + max
ante (L) = max
j∈Cr min(wj, max
xi∈X min(uj(xi), L[xi]))
(6)
U −min
post (L) = min
xi∈X max((1 −L[xi]), min
j∈Cr max(uj(xi), (1 −wj)))
(7)
U −max
post
(L) = min
xi∈X max((1 −L[xi]), max
j∈Cr min(uj(xi), wj))
(8)
U + min
post (L) = max
xi∈X min(L[xi], min
j∈Cr max(uj(xi), (1 −wj)))
(9)
U + max
post
(L) = max
xi∈X min(L[xi], max
j∈Cr min(uj(xi), wj))
(10)
In the notations above, the ﬁrst (resp. second) sign denotes the attitude of
the decision maker w.r.t. uncertainty (resp. the criteria). The U −min
ante
utility for
instance considers that the decision maker is pessimistic and computes the pes-
simistic utility of each criterion. Then the criteria are aggregated on a cautions
basis: the higher is the satisfaction of the least satisﬁed of the important crite-
ria, the better is the lottery. Using the same notations, U −max
post
considers that
a xi is good as soon as one of the important criteria is satisﬁed: a max-based
aggregation of the utilities is done, yielding a unique utility function u() on the
basis of which the pessimistic utility is computed. It should be noticed that the
full pessimistic and full optimistic ex-ante utilities are equivalent to their ex-post
counterparts [12], i.e. U −min
ante
= U −min
post
and U + max
ante
= U + max
post
. But U −max
ante
(resp.
U + min
ante ) may diﬀer from U −max
post
(resp. from U + min
post ).
Example 1. Consider two equally important criteria 1 and 2 (w1 = w2 = 1),
and a lottery L = ⟨1/xa, 1/xb⟩leading to two equi possible consequences xa and
xb such that xa is good for 1 and bad for 2, and xb is bad for 1 and good for
2: u1(xa) = u2(xb) = 1 and u2(xa) = u1(xb) = 0. It is easy to check that
U + min
ante (L) = 0 ̸= U + min
post (L) = 1.
2.2
Possibilistic Decision Trees [14]
Decision trees provide an explicit modeling of sequential problems by represent-
ing, simply, all possible scenarios. A decision tree is a labeled tree DT = (N, E)
where N = D ∪C ∪LN contains three kinds of nodes (see Fig. 1): D is the set of
decision nodes (represented by squares); C is the set of chance nodes (represented
by circles) and LN is the set of leaves.Succ(N) denotes the set of children nodes
of node N. For any Xi ∈D, Succ(Xi) ⊆C i.e. a chance node (an action) must
be chosen at each decision node. For any Ci ∈C, Succ(Ci) ⊆LN ∪D: the set of
outcomes of an action is either a leaf node or a decision node (and then a new
action should be executed).
In the possibilistic context, leaves are labeled by utility degrees in the [0,1]
scale and the uncertainty pertaining to the possible outcomes of each Ci ∈C,
is represented by a conditional possibility distribution πi on Succ(Ci), such that
∀N ∈Succ(Ci), πi(N) = Π(N|path(Ci)) where path(Ci) denotes all the value
assignments of chance and decision nodes on the path from the root to Ci [14].

298
N. Ben Amor et al.
Solving a decision tree amounts at building a complete strategy that selects an
action (a chance node) for each decision node: a strategy is a mapping δ : D →
C ∪{⊥}. δ(Di) = ⊥means that no action has been selected for Di (δ is partial).
Leaf nodes being labeled with utility degrees, the rightmost chance nodes can
be seen as simple possibilistic lotteries. Then, each strategy δ can be viewed as
a connected sub-tree of the decision tree and is identiﬁed with a possibilistic
compound lottery Lδ, i.e. with a possibility distribution over a set of (simple
or compound) lotteries. A compound lottery ⟨λ1/L1, ..., λk/Lk⟩(and thus any
strategy) can then be reduced into an equivalent simple lottery as follows2 [2]:
Reduction(⟨λ1/L1, ..., λk/Lk⟩) = ⟨max
j=1,k(min(λj
1, λj))/u1, ..., max
j=1,k(min(λj
n, λj))/un⟩.
The pessimistic and optimistic utility of a strategy δ can then be computed on
the basis of the reduction of Lδ: the utility of δ is the one of Reduction(Lδ).
3
Multi-criteria Optimization in Possibilistic Trees
Multi-criteria Possibilistic Decision Trees can now be deﬁned: they are classical
possibilistic decision trees, the leaves of which are evaluated according to several
criteria - each leaf N is now labeled by a vector u(N) = ⟨u1(N), . . . , up(N)⟩
rather than by a single utility score (see Fig. 1). A strategy still leads to com-
pound lottery, and can be reduced, thus leading in turn to a simple (but multi-
criteria) lottery. We propose to base the comparison of strategies on the com-
parison, according to the rules O previously presented, of their reductions:
δ1 ⪰O δ2 iﬀUO(δ1) ≥UO(δ2),
where ∀δ, UO(δ) = UO(Reduction(Lδ)) (11)
Example 2. Consider the tree of Fig. 1, involving two criteria that are supposed
to be equally important and the strategy δ(D0) = C1, δ(D1) = C3, δ(D2) = C5.
It holds that Lδ = ⟨1/LC3, 0.9/LC5⟩with LC3 = ⟨0.5/xa, 1/xb⟩, LC5 = ⟨0.2/xa,
1/xb⟩. Because Reduction(Lδ) = ⟨max(0.5, 0.2)/xa, max(1, 0.9)/xb⟩= ⟨0.5/xa,
1/xb⟩, we get U +min
ante (δ) = min(max min(0.5, 0.3), min(1, 0.6), max(min(0.5, 0.8)
min(1, 0.4))) = 0.5.
The deﬁnition proposed by Eq. (11) is quite obvious but raises an algorithmic
challenge: the set of strategies to compare is exponential w.r.t. the size of the tree
which makes the explicit evaluation of the strategies not realistic. The sequel of
the paper aims at providing algorithmic solutions to this diﬃculty.
3.1
Dynamic Programming as a tool for ex-post Utilities
Dynamic Programming [15] is an eﬃcient procedure of strategy optimization. It
proceeds by backward induction, handling the problem from the end (and in our
case, from the leafs): the last decision nodes are considered ﬁrst, and recursively
2 Obviously, the reduction of a simple lottery is the simple lottery itself.

Algorithms for Multi-criteria Optimization in Possibilistic Decision Trees
299
Fig. 1. A multi-criteria possibilistic decision tree
until the root is reached. This algorithm is sound and complete as soon as the
decision rule leads to complete and transitive preferences and satisﬁes the prin-
ciple of weak monotonicity,3 that ensures that each sub strategy of an optimal
strategy is optimal in its sub-tree. Hopefully, each of the ex-post criteria satisfy
transitivity, completeness and weak monotonicity, because collapsing to either a
classical U −or a U + utility, which satisfy these properties [8,14]. The adaptation
of Dynamic Programming to the ex-post rules is detailed in Algorithm 1.
In short, this algorithm aggregates the utility values of each leaf, and then
builds an optimal strategy from the last decision nodes to the root of the tree,
using the principle deﬁned by [9,10] for classical (monocriterion) possibilistic
decision trees.
3.2
Dynamic Programming for ex-ante Utilities?
The ex-ante variant of Dynamic Programming we propose is a little more tricky
(see Algorithm 2). It keeps at each node a vector of p pessimistic (resp. opti-
mistic) utilities, one for each criterion. The computation of the ex-ante util-
ity can then be performed each time a decision is to be made. Recall that
U −min
ante
= U −min
post
and U + max
ante
= U + max
post
. Hence, for these two rules the opti-
mization could also be performed by the ex-post algorithm. The two other rules,
U −max
ante
and U + min
ante , unfortunately do not satisfy the monotonicity principle (see
[1]). Hence, Algorithm 2 may provide a good strategy, but without any guarantee
of optimality - it can be considered as an approximation algorithm in these two
cases. Another approximation algorithm is the ex-post Algorithm described in
the previous Section - even if it is not always the case, it often happens that
U −max
post
= U −max
ante
(resp. U + min
post
= U + min
ante ); if it is the case the solution provided
by the ex-post Algorithm is optimal.
3 Formally, ⪰O is said to be weakly monotonic iﬀwhatever L, L′ and L′′, whatever
(α,β) such that max(α, β) = 1: L ⪰O L′ ⇒⟨α/L, β/L′′⟩⪰O ⟨α/L′, β/L′′⟩.

300
N. Ben Amor et al.
Algorithm 1. DynProgPost: Ex-post Dynamic Programming
Data: A Decision tree T, a node N in of T
Result: The value of the optimal strategy δ - δ is stored as a global variable
begin
if N ∈LN then // Leaf : MCDM aggregation
for i ∈{1, . . . , p} do uN ←(uN ⊕(ui ⊗ωi));
// ⊗= min, ωi = wi, ⊕= max for disjunctive aggregation
// ⊗= max, ωi = 1 −wi, ⊕=
min for conjunctive aggregation ;
if N ∈C then // Chance Node: compute the qualitative utility
foreach Y ∈Succ(N) do uN ←(uN ⊕(λY ) ⊗DynProgPost(Y ));
// ⊗= min, λY = π(Y ), ⊕= max for optimistic utility
// ⊗= max, λY = 1 −π(Y ), ⊕= min for pessimistic utility
if N ∈D then // Decision node: determine the best decision
u∗←0 ;
foreach Y ∈Succ(N) do
uY ←DynProgPost(Y ) ;
if uY ≥u∗then δ(N) ←Y and u∗←uY ;
return u∗;
Algorithm 2. DynProgAnte: Ex-ante Dynamic Programming
Data: A Decision tree T, a node N in of T
Result: The value of the optimal strategy δ - δ is stored as a global variable
begin
if N ∈LN then // Leaf
for i ∈{1, . . . , p} do uN [i] ←ui;
if N ∈C then // Chance Node: compute the utility vectors
// Optimistic utility ⊗= min, λY = π(Y ), ⊕= max, ϵ ←0
// Pessimistic utility ⊗= max, λY = 1 −π(Y ), ⊕= min, ϵ ←1
for i ∈{1, . . . , p} do uN [i] ←ϵ ;
foreach Y ∈Succ(N) do
uY ←DynProgAnte(Y ) ;
for i ∈{1, . . . , p} do uN [i] ←(uN [i] ⊕(λY ⊗uY [i])) ;
if N ∈D then // Decision node
// Disjunctive MCDM: let ⊗= min, ωi = wi, ⊕= max, ϵ ←0
// Conjunctive MCDM: let ⊗= max, ωi = 1 −wi, ⊕=
min, ϵ ←1
u∗←0
foreach Y ∈Succ(N) do
vY ←ϵ ; uY ←DynProgAnte(Y ) ;
for i ∈{1, . . . , p} do vY ←vY ⊕(uY [i] ⊗ωi);
if vY > u∗then δ(N) ←Y and uN ←uY ;
return uN ;

Algorithms for Multi-criteria Optimization in Possibilistic Decision Trees
301
3.3
Optimization of U −max
ante
by Multi Dynamic Programming
The lack of monotonicity of U −max
ante
is not dramatic, even when optimality must
be guaranteed. With U −max
ante
indeed, we look for a strategy that has a good
pessimistic utility U −
j for at least one criterion j. This means that if it is possible
to get for each j a strategy that optimizes U −
j (and this can be done by Dynamic
Programming, since the classical pessimistic utility is monotonic), the one with
the highest value for U −max
ante
is globally optimal. Formally:
Proposition 1. U −max
ante (L) = max
j=1,p min(wj, U −
j (L)) where U −
j (L) is the pes-
simistic utility of L according to the sole criterion j.
Corollary 1. Let Δ∗= {L∗
1, . . . , L∗
p} s.t. ∀L, U −
j (L∗
j) ≥U −
j (L) and L∗∈Δ∗.
If max
j=1,p min(wj, U −
j (L∗)) ≥max
j=1,p min(wj, U −
j (L∗
i ))∀L∗
i ∈Δ∗then U −max
ante (L∗) ≥
U −max
ante (L), ∀L.
Hence, the optimization problem can be solved by a series of p calls to a
classical (monocriterion) pessimistic optimization. This is the principle of the
Multi Dynamic Programming approach detailed by Algorithm 3.
Algorithm 3. MultiDynProg: right optimization of U −max
ante
Data: A tree T
Result: An Optimal strategy δ∗and its value u∗
begin
u∗= 0; // Initialization
for i ∈{1, . . . , p} do
δi = PesDynProg(T, i) // Call to classical possibilistic
Dynamic Prog. [14] - returns an optimal strategy for U −
i ;
ui = max
j=1...p min(wj, U −
j (δi));
if ui > u∗then δ∗←δi; u∗←ui;
return u∗;
3.4
Right Optimization of U + min
ante : A Branch and Bound algorithm
Let us ﬁnally study the U + min
ante
utility. As previously said, it does not satisfy
monotonicity and Dynamic Programming can provide a good strategy, but with-
out any guarantee of optimality. To guarantee optimality, one can proceed by an
implicit enumeration via a Branch and Bound algorithm, as done by [8] for Pos-
sibilistic Choquet integrals and by [16] for Rank Dependent Utility (both in the
mono criterion case). The Branch and Bound procedure (see Algorithm 4) takes
as argument a partial strategy δ and an upper bound of the U + min
ante
value of
its best extension. It returns U ∗, the U + min
ante
value of the best strategy found

302
N. Ben Amor et al.
so far, δ∗. We can initialize δ∗with any strategy, e.g. the one provided by
Algorithms 2 or 1. At each step of the Branch and Bound algorithm, the current
partial strategy, δ, is developed by the choice of an action for some unassigned
decision node. When several decision nodes are candidate, the one with the min-
imal rank (i.e. the former one according to the temporal order) is developed.
The recursive procedure backtracks when either the current strategy is com-
plete (then δ∗and U ∗are updated) or proves to be worse than the current
δ∗in any case. Function UpperBound(D0, δ) provides an upper bound of the
best completion of δ - in practice, it builds, for each criterion j, a strategy δj
that maximizes U +
j
(using [9,10]’s algorithm, which is linear). It then selects,
among these strategies, the one with the highest U + min
ante . It is important to note
that UpperBound(D0, δ) = U + min
ante (δ) when δ is complete. Whenever the value
returned by UpperBound(D0, δ) is lower or equal to U ∗, the value of the best
current strategy, the algorithm backtracks, yielding the choice of another action
for the last considered decision node.
Algorithm 4. B&B algorithm for the optimization of U +,min
ante
Data: A decision tree T, a (partial) strategy δ, an upper Bound U of U +,min
ante
(δ)
Result: U ∗: the U +,min
ante
value of δ∗the best strategy found so far
begin
if δ(D0) = ⊥then Dpend ←{D0};
else Dpend ←{Di ∈D s.t. ∃Dj, δ(Dj) ̸= ⊥and Di ∈Succ(δ(Dj))} ;
if Dpend = ∅then // δ is a complete strategy
δ∗←δ; U ∗←U;
else
Dnext ←arg minDi∈Dpend i ;
foreach Ci ∈Succ(Dnext) do
δ(Dnext) ←Ci;
U ←UpperBound(D0, δ);
if U > U ∗then U ∗←B&B(U, δ) ;
return U ∗;
4
Experiments
Beyond the evaluation of the feasibility of the algorithms proposed, our exper-
iments aim at evaluating to what extent the optimization of the problematic
utilities, U −max
ante
and U + min
ante , can be approximated by Dynamic Programming.
The implementation has been done in Java, on a processor Intel Core i7 2670
QMCPU, 2.2 GHz, 6 GB of RAM. The experiments were performed on complete
binary decision trees. We have considered four sets of problems, the number
of decisions to be made in sequence (denoted seq) varying from 2 to 6, with
an alternation of decision and chance nodes: at each decision level l (i.e. odd

Algorithms for Multi-criteria Optimization in Possibilistic Decision Trees
303
level), the tree contains 2l−1 decision nodes followed by 2l chance nodes.4 In the
present experiment, the number of criteria is set equal to 3. The utility values as
well as the weights degrees are uniformly ﬁred in the set {0, 0.1, 0.2, . . . , 0.9, 1}.
Conditional possibilities are chosen randomly in [0, 1] and normalized. Each of
the four samples of problems contains 1000 randomly generated trees.
Feasibility Analysis and Temporal Performances: Table 1 presents the execution
time of each algorithm. Obviously, for each one, the CPU time increases with the
size of the tree. But it remains aﬀordable even for very big trees (1365 decisions).
We can check that U −max
ante
(resp. U + min
ante ) the approximation performed by ex-
post Dynamic Programming is faster than the one performed by ex-ante Dynamic
Programming, both being faster than the exact algorithm (Multi Dynamic Pro-
gramming and Branch and Bound, respectively).
Table 1. Average CPU time, in milliseconds, of for each algorithms and for each rule,
according the size of the tree (in number of decision nodes)
# decision nodes
5
21
85
341
1365
U −min
post
U −min
ante
Post Dyn. Prog
0.068 0.073 0.076 0.126 0.215
U + max
post
U + max
ante
Post Dyn. Prog
0.071 0.075 0.082 0.128 0.207
U −max
post
Post Dyn. Prog
0.068 0.083 0.090 0.140 0.235
U + min
post
Post Dyn. Prog
0.067 0.075 0.082 0.132 0.211
U −max
ante
Multi Dyn. Prog
0.172 0.203 0.247 0.295 1.068
U −max
ante
Ante Dyn. Prog
0.079 0.096 0.120 0.147 0.254
U + min
ante
Branch & Bound 0.576 1.012 1.252 1.900 5.054
U + min
ante
Ante Dyn. Prog
0.074 0.084 0.093 0.147 0.231
Quality of the Approximation: As previously mentioned the ex-post and the ex-
ante Dynamic Programming algorithms are approximation algorithms for U −max
ante
and U + min
ante . The following experiments estimate the quality of these approxi-
mations. At this extent, we compute for each sample the success rate of the
approximation algorithm considered, i.e. the number of trees for which the value
provided by the approximation algorithm is actually optimal; then for the trees
for which it fails to reach optimality, we report the average closeness value to
UApprox
UExact where UApprox is the utility of the strategy provided by the approxima-
tion algorithm and UExact is the optimal utility - the one of the solution by the
exact algorithm (Branch and Bound for U + min
ante
and Multi Dynamic Program-
ming for U −max
ante ). The results are given in Table 2.
Clearly, Ex-Post Dynamic Programming provides a good approximation for
U + min
ante
- its success rate decreases with the number of nodes but stay higher
4 Hence, for a sequence length seq = 2 (resp. 3, 4, 5, 6), the number of decision nodes
in each tree of the sample is equal to 5 (resp. 21, 85, 341, 1365).

304
N. Ben Amor et al.
Table 2. Quality of approximation of U −max
ante
and U + min
ante
by Dynamic Programming
# decision nodes
5
21
85
341
1365
% of success
U −max
ante
Ante Dyn. Prog
17.3% 19%
22.1% 26.4% 31%
U −max
ante
Post. Dyn. Prog 15.4% 23.6% 30.7% 35.6% 40.4%
U + min
ante
Ante Dyn. Prog
87%
76.8% 68%
62.6% 59.6%
U + min
ante
Post Dyn. Prog
91.7% 90.8% 88.2% 86.7% 76%
Closeness value
U −max
ante
Ante Dyn. Prog
0.522
0.56
0.614
0.962
0.981
U −max
ante
Post Dyn. Prog
0.473
0.529
0.556
0.58
0.62
U + min
ante
Ante Dyn. Prog
0.97
0.95
0.94
0.93
0.91
U + min
ante
Post Dyn. Prog
0.989
0.975
0.946
0.928
0.90
than 70%, and above all it has a very high closeness value (above 0.9); notice
that it is always better than its ex-ante counterpart, in terms of success rate, of
closeness and of CPU time. This is good news since it is polynomial while Branch
and Bound, the exact algorithm, is exponential in the number of nodes. As to
U −max
ante , none of the approximation algorithms is good. However, this is not so
bad news since Multi Dynamic Programming, the exact algorithm is polynomial
and has very aﬀordable CPU time.
5
Conclusion
This paper proposes to extend to possibilistic decision trees the decision rules
presented in [1] for non sequential problems. We show that, for the ex-post deci-
sion rules, as well as for U +max
ante
and U −min
ante , the optimization can be achieved
by Dynamic Programming. For U + min
ante
the optimization can be carried either by
an exact but costly algorithm (Branch & Bound) or by an approximation one,
(ex-post Dynamic Programming). For U −max
ante
we propose an exact algorithm
(Multi Dynamic Programming) that performs better than Dynamic Program-
ming. As future work, we would like to study the handling of several criteria
in more sophisticated qualitative decision models such as possibilistic inﬂuence
diagrams [14] or possibilistic Markov decision models [10].
References
1. Ben Amor, N., Essghaier, F., Fargier, H.: Solving multi-criteria decision problems
under possibilistic uncertainty using optimistic and pessimistic utilities. In: Lau-
rent, A., Strauss, O., Bouchon-Meunier, B., Yager, R.R. (eds.) IPMU 2014. CCIS,
vol. 444, pp. 269–279. Springer, Cham (2014). doi:10.1007/978-3-319-08852-5 28
2. Dubois, D., Prade, H.: Possibility theory as a basis for qualitative decision theory.
In: Proceedings of IJCAI 1995, pp. 1924–1930 (1995)

Algorithms for Multi-criteria Optimization in Possibilistic Decision Trees
305
3. Dubois, D., Godo, L., Prade, H., Zapico, A.: Making decision in a qualitative
setting: from decision under uncertainty to case-based decision. In: Proceedings of
KR, pp. 594–607 (1998)
4. Giang, P.H., Shenoy, P.P.: A qualitative linear utility theory for Spohn’s theory of
epistemic beliefs. In: Proceedings of UAI, pp. 220–229 (2000)
5. Dubois, D., Prade, H., Sabbadin, R.: Decision theoretic foundations of qualitative
possibility theory. EJOR 128, 459–478 (2001)
6. Dubois, D., Fargier, H., Prade, H., Perny, P.: Qualitative decision theory: from
savage’s axioms to nonmonotonic reasoning. JACM 49, 455–495 (2002)
7. Dubois, D., Fargier, H., Perny, P.: Qualitative decision theory with preference
relations and comparative uncertainty: an axiomatic approach. Artif. Intell. 148,
219–260 (2003)
8. Ben Amor, N., Fargier, H.: Possibilistic sequential decision making. Int. J. Approx-
imate Reasoning 55, 1269–1300 (2014)
9. Sabbadin, R., Fargier, H., Lang, J.: Towards qualitative approaches to multi-stage
decision making. Int. J. Approximate Reasoning 19, 441–471 (1998)
10. Sabbadin, R.: Empirical comparison of probabilistic and possibilistic Markov deci-
sion processes algorithms. In: Proceedings of ECAI, pp. 586–590 (2000)
11. Harsanyi, J.: Cardinal welfare, individualistic ethics, and interpersonal comparisons
of utility. J. Polit. Econ. 63, 309–321 (1955)
12. Ben Amor, N., Essghaier, F., Fargier, H.: Egalitarian collective decision making
under qualitative possibilistic uncertainty: principles and characterization. In: Pro-
ceedings of AAAI, pp. 3482–3488 (2015)
13. Dubois, D., Prade, H.: Weighted minimum and maximum operations in fuzzy set
theory. J. Inform. Sci. 39, 205–210 (1986)
14. Garcias, L., Sabbadin, R.: Possibilistic inﬂuence diagrams. In: Proceedings of
ECAI, pp. 372–376 (2006)
15. Bellman, R.: Dynamic Programming. Princeton University Press, New Jersey
(1957)
16. Jeantet, G., Spanjaard, O.: Rank-dependent probability weighting in sequential
decision problems under uncertainty. In: Proceedings of ICAPS, pp. 148–155 (2008)

Eﬃcient Policies for Stationary Possibilistic
Markov Decision Processes
Nahla Ben Amor1(B), Zeineb EL khalﬁ1,2(B), H´el`ene Fargier2(B),
and R´egis Sabaddin3(B)
1 LARODEC, Le Bardo, Tunisie
nahla.benamor@gmx.fr, zeineb.khalfi@gmail.com
2 IRIT, Toulouse, France
fargier@irit.fr
3 INRA-MIAT, Toulouse, France
regis.sabbadin@inra.fr
Abstract. Possibilistic Markov Decision Processes oﬀer a compact and
tractable way to represent and solve problems of sequential decision
under qualitative uncertainty. Even though appealing for its ability to
handle qualitative problems, this model suﬀers from the drowning eﬀect
that is inherent to possibilistic decision theory. The present paper pro-
poses to escape the drowning eﬀect by extending to stationary possibilis-
tic MDPs the lexicographic preference relations deﬁned in [6] for non-
sequential decision problems and provides a value iteration algorithm to
compute policies that are optimal for these new criteria.
Keywords: Markov Decision Process · Possibility theory · Lexico-
graphic comparisons · Possibilistic qualitative utilities
1
Introduction
The classical paradigm for sequential decision making under uncertainty is the
one of expected utility-based Markov Decision Processes (MDP) [2,11], which
assumes that the uncertain eﬀects of actions can be represented by probability
distributions and that utilities are additive. But the EU model is not tailored
to problems where uncertainty and preferences are ordinal in essence. Alter-
natives to the EU-based model have been proposed to handle ordinal pref-
erences/uncertainty. Remaining within the probabilistic, quantitative, frame-
work while considering ordinal preferences has lead to quantile-based approaches
[8,9,15,17,18]) Purely ordinal approaches to sequential decision under uncer-
tainty have also been considered. In particular, possibilistic MDPs [1,4,12,13]
form a purely qualitative decision model with an ordinal evaluation of plau-
sibility and preference. In this model, uncertainty about the consequences of
actions is represented by possibility distributions and utilities are also ordinal.
The decision criteria are either the optimistic qualitative utility or its pessimistic
counterpart [5]. However, it is now well known that possibilistic decision criteria
suﬀer from the drowning eﬀect [6]. Plausible enough bad or good consequences
c
⃝Springer International Publishing AG 2017
A. Antonucci et al. (Eds.): ECSQARU 2017, LNAI 10369, pp. 306–317, 2017.
DOI: 10.1007/978-3-319-61581-3 28

Eﬃcient Policies for Stationary Possibilistic Markov Decision Processes
307
may completely blur the comparison between policies, that would otherwise be
clearly diﬀerentiable. [6] have proposed lexicographic reﬁnements of possibilistic
criteria for the one-step decision case, in order to remediate the drowning eﬀect.
In this paper, we propose an extension of the lexicographic preference relations
to stationary possibilistic MDPs.
The next Section recalls the background about possibilistic MDPs, including
the drowning eﬀect problem. Section 3 studies the lexicographic comparison of
policies in ﬁnite horizon problems and presents a value iteration algorithm for
the computation of lexi-optimal policies. Section 4 extends these results to the
inﬁnite-horizon case. Lastly, Section 5 reports experimental results. Proofs are
omitted, but can be found in1.
2
Possibilistic Markov decision process
2.1
Deﬁnition
A possibilistic Markov Decision Process (P-MDP) [12] is deﬁned by:
– A ﬁnite set S of states.
– A ﬁnite set A of actions, As denotes the set of actions available in state s;
– A possibilistic transition function: each action a ∈As applied in state s ∈S
is assigned a possibility distribution π(.|s, a);
– A utility function μ: μ(s) is the intermediate satisfaction degree obtained in
state s.
The uncertainty about the eﬀect of an action a taken in state s is a possi-
bility distribution π(.|s, a) : S →L, where L is a qualitative ordered scale used
to evaluate both possibilities and utilities (typically, and without loss of gener-
ality, L = [0, 1]): for any s′, π(s′|s, a) measures to what extent s′ is a plausible
consequence of a when executed in s and μ(s′) is the utility of being in state
s′. In the present paper, we consider stationary problems, i.e. problems in which
states, the actions and the transition functions do not depend on the stage of
the problem. Such a possibilistic MDP deﬁnes a graph, where states are repre-
sented by circles and are labelled by utility degrees and actions are represented
by squares. An edge linking an action to a state denotes a possible transition
and is labeled by the possibility of that state given the action is executed.
Example 1. Let us suppose that a “Rich and Unknown” person runs a
startup company. Initially, s/he must choose between Saving money (Sav)
or Advertising (Adv) and may then get Rich (R) or Poor (P) and Famous
(F) or Unknown (U). In the other states, Sav is the only possible action.
Figure 1 shows the stationary P-MDP that captures this problem, formally
described as follows: S = {RU, RF, PU}, ARU = {Adv, Sav}, ARF = {Sav},
AP U = {Sav}, π(PU|RU, Sav) = 0.2, π(RU|RU, Sav) = 1; π(RF|RU, Adv) =
1; π(RF|RF, Sav) = 1, π(RU|RF, Sav) = 1, μ(RU) = 0.5, μ(RF) = 0.7,
μ(PU) = 0.3.

308
N. Ben Amor et al.
Fig. 1. A possibilistic stationary MDP
Solving a stationary MDP consists in ﬁnding a (stationary) policy, i.e. a
function δ : S →As which is optimal with respect to a decision criterion. In the
possibilistic case, as in the probabilistic case, the value of a policy depends on
the utility and on the likelihood of its trajectories. Formally, let Δ be the set of
all policies encoded by a P-MDP. When the horizon is ﬁnite, each δ ∈Δ deﬁnes
a list of scenarios called trajectories. Each trajectory is a sequence of states and
actions τ = (s0, a0, s1, . . . , sE−1, aE−1, sE).
To simplify notations, we will associate the vector vτ
= (μ0,π1,μ1,
π2, . . . , πE−1, μE) to each trajectory τ, where πi+1 =def
π(si+1|si, ai) and
μi =def μ(si).
The possibility and the utility of τ given that δ is applied from s0 are
deﬁned by:
π(τ|s0, δ) = min
i=1..E π(si|si−1, δ(si−1))
and μ(τ) = min
i=0..E μ(si)
(1)
Two criteria, an optimistic and a pessimistic one, can then be used [5,13]:
uopt(δ, s0) = max
τ
min{π(τ|s0, δ), μ(τ)}
(2)
upes(δ, s0) = max
τ
min{1 −π(τ|s0, δ), μ(τ)}
(3)
These criteria can be optimized by choosing, for each state, an action that max-
imizes the following counterparts of the Bellman equations [12]:
uopt(s) = max
a∈As min{μ(s), max
s′∈S min(π(s′|s, a), uopt(s′))}
(4)
upes(s) = max
a∈As min{μ(s), min
s′∈S max(1 −π(s′|s, a), upes(s′))}
(5)
This formulation is more general than the ﬁrst one in the sense that it applies
to both the ﬁnite and the inﬁnite case. It has allowed the deﬁnition of a (possi-
bilistic) value iteration algorithm which converges to an optimal policy in poly-
time O(|S|2 · |A|2 · |L|) [12]. This algorithm proceeds by iterated modiﬁcations
of a possibilistic value function ˜Q(s, a) which evaluates the “utility” (pessimistic
or optimistic) of performing a in s.
1 https://www.irit.fr/publis/ADRIA/PapersFargier/XKRU17MDP.pdf.

Eﬃcient Policies for Stationary Possibilistic Markov Decision Processes
309
2.2
The Drowning Eﬀect
Unfortunately, possibilistic utilities suﬀer from an important drawback called
the drowning eﬀect: plausible enough bad or good consequences may completely
blur the comparison between acts that would otherwise be clearly diﬀerentiated;
as a consequence, an optimal policy δ is not necessarily Pareto eﬃcient - it may
exist a policy δ′ such that upes(δ′
s) = upes(δs) while ∀s, upes(δ′
s) ⪰upes(δs) and
(ii) ∃s, upes(δ′
s) ≻upes(δs) where δs (resp. δ′
s) is the restriction of δ (resp. δ′) to
the subtree rooted in s.
Example 2. The P-MDP of Example 1; it admits two policies δ and δ′: δ(RU) =
Sav; δ(PU) = Stay; δ(RF) = Sav; δ′(RU) = Adv; δ′(PU) = Stay; δ′(RF) =
Sav. For horizon E = 2:
– δ has 3 trajectories: τ1 = (RU, PU, PU) with vτ1 = (0.5 0.2 0.3 1 0.3); τ2 =
(RU, RU, PU) with vτ2 = (0.5 1 0.5 0.2 0.3); τ3 = (RU, RU, RU) with vτ3 =
(0.5 1 0.5 1 0.5).
– δ′ has 2 trajectories: τ4 = (RU, RF, RF) with vτ4 = (0.5 1 0.7 1 0.7); τ5 =
(RU, RF, RU) with vτ5 = (0.5 1 0.7 1 0.5).
Thus Uopt(δ) = Uopt(δ′) = 0.5. However δ′ seems better than δ since it pro-
vides utility 0.5 for sure while δ provides a bad utility (0.3) in some non impos-
sible trajectories (τ1 and τ2). τ3 which is good and totally possible “drowns” τ1
and τ2: δ is considered as good as δ′.
2.3
Lexi-Reﬁnements of Ordinal Aggregations
In ordinal (i.e. min-based and max-based) aggregation a solution to the drowning
eﬀect has been proposed, that is based on leximin and leximax comparisons [10].
It has then been extended to non-sequential decision making under uncertainty
[6] and, in the sequential case, to decision trees [3]. Let us ﬁrst recall the basic
deﬁnition of these two preference relations. For any two vectors t and t′ of length
m built on L:
t ⪰lmin t′ iﬀ∀i, tσ(i) = t′
σ(i) or ∃i∗, ∀i < i∗, tσ(i) = t′
σ(i) and tσ(i∗) > t′
σ(i∗)
(6)
t ⪰lmax t′ iﬀ∀i, tμ(i) = t′
μ(i) or ∃i∗, ∀i < i∗, tμ(i) = t′
μ(i) and tμ(i∗) > t′
μ(i∗)
(7)
where, for any vector v (here, v = t or v = t′), vμ(i) (resp. vσ(i)) is the ith best
(resp. worst) element of v.
[6] have extended these procedures to the comparison of matrices built on
L. Given a complete preorder ⊵on vectors, it is possible to order the lines of
the matrices (say, A and B) according to ⊵and to apply an lmax or an lmin
procedure:
A ⪰lmin(⊵) B ⇔∀j, a(⊵,j) ∼
= b(⊵,j) or ∃i s.t. ∀j > i, a(⊵,j) ∼
= b(⊵,j) and a(⊵,i) ▷b(⊵,i) (8)
A ⪰lmax(⊵) B ⇔∀j, a(⊵,j) ∼
= b(⊵,j) or ∃i s.t.∀j < i, a(⊵,j) ∼
= b(⊵,j)and a(⊵,i) ▷b(⊵,i) (9)
where, for any c ∈(LM)N, c(⊵,i) is the ith largest sub-vector of c according to ⊵.

310
N. Ben Amor et al.
3
Lexicographic-Value Iteration for Finite Horizon
P-MDPs
In (ﬁnite-horizon) possibilistic decision trees, the idea of [3] is to identify a strat-
egy with the matrix of its trajectories, and to compare such matrices with a
⪰lmax(lmin) (resp. ⪰lmin(lmax)) procedure for the optimistic (resp. pessimistic)
case. We propose, in the following, a value iteration algorithm for the computa-
tion of such lexi-optimal policies in the ﬁnite (this Section) and inﬁnite (Sect. 4)
horizon cases.
3.1
Lexicographic Comparisons of Policies
Let E be the horizon of the P-MDP. A trajectory being a sequence of states
and actions, a strategy can be viewed as a matrix where each line corresponds
to a distinct trajectory. In the optimistic case each line corresponds to a vector
vτ = (μ0, π1, μ1, π2, . . . , πE−1, μE) and in the pessimistic case to wτ = (μ0, 1 −
π1, μ1, 1 −π2, . . . , 1 −πE−1, μE).
This allow us to deﬁne the comparison of trajectories and strategies by2:
τ ⪰lmin τ ′ iﬀ(μ0, π1, . . . , πE, μE) ⪰lmin (μ′
0, π′
2, . . . , π′
E, μ′
E)
(10)
τ ⪰lmax τ ′ iﬀ(μ0, 1 −π1, . . . , 1 −πE, μE) ⪰lmax (μ′
0, 1 −π′
1, . . . 1 −π′
E, μ′
E)
(11)
δ ⪰lmax(lmin) δ′ iﬀ∀i, τμ(i) ∼lmin τ ′
μ(i)
or ∃i∗, ∀i < i∗, τμ(i) ∼lmin τ ′
μ(i) and τμ(i∗) ≻lmin τ ′
μ(i∗) (12)
δ ⪰lmin(lmax) δ′ iﬀ∀i, τσ(i) ∼lmax τ ′
σ(i)
or ∃i∗, ∀i < i∗, τσ(i) ∼lmax τ ′
σ(i) and τσ(i∗) ≻lmax τ ′
σ(i∗) (13)
where τμ(i) (resp. τ ′
μ(i)) is the ith best trajectory of δ (resp δ′) according to ⪰lmin
and τσ(i) (resp. τ ′
σ(i)) is the ith worst trajectory of δ (resp δ′) according to ⪰lmax.
It is easy to show that we get eﬃcient reﬁnements of uopt and upes.
Proposition 1. If uopt(δ)
>
uopt(δ′) (resp. upes(δ)
>
upes(δ′)) then
δ ≻lmax(lmin) δ′ (resp. δ ≻lmin(lmax) δ′).
Proposition 2. Relations ⪰lmin(lmax) and ⪰lmax(lmin) are complete, transitive
and satisfy the principle of strict monotonicity3.
2 If a trajectory is shorter than E, neutral elements (0 for the optimistic case and 1
for the pessimistic one) are added at the end. If the policies have diﬀerent numbers
of trajectories, neutral trajectories (vectors) are added to the shortest one.
3 A criterion O satisﬁes the principle of strict monotonicity iﬀ: ∀δ, δ′, δ′′, δ ⪰O δ′ ⇐⇒
δ+δ′′ ⪰O δ′+δ′′. δ+δ′′ contains two disjoint sets of trajectories: the ones of δ and the
ones of δ′′ (and similarly for δ′ +δ′′). Then, adding or removing identical trajectories
to two sets of trajectories does not change their comparison by ⪰lmax(lmin) (resp.
⪰lmin(lmax)) - while it may transform a strict preference into an indiﬀerence if uopt
(resp. upes) were used.

Eﬃcient Policies for Stationary Possibilistic Markov Decision Processes
311
Remark. We deﬁne the complementary MDP, (S, A, π, ¯μ) of a given P-MDP
(S, A, π, μ) where ¯μ(s) = 1 −μ(s), ∀s ∈S. The complementary MDP simply
gives complementary utilities. From the deﬁnitions of ⪰lmax and ⪰lmin, we can
check that:
Proposition 3. τ
⪰lmax
τ ′
⇔
¯τ ′
⪰lmin
¯τ and δ
⪰lmin(lmax)
δ′
⇔
¯δ′ ⪰lmax(lmin) ¯δ.
where ¯τ and ¯δ are obtained by replacing μ with ¯μ in the trajectory/P-MDP.
Therefore, all results which we will prove in the following for ⪰lmax(lmin) also
hold for ⪰lmin(lmax), if we take care to apply them to complementary strategies.
Since considering ⪰lmax(lmin) involves less cumbersome expressions (no 1 −·),
we will give the results for this criterion. Moreover, abusing notations slightly,
we identify trajectories τ (resp. strategies) with their vτ vectors (resp. matrices
of vτ vectors).
3.2
Basic Operations on Matrices of Trajectories
Before going further, we deﬁne some basic operations on matrices (typically, on
U(s) representing trajectories issued from s). For any matrix U = (uij) with n
lines and m columns, [U]l,c denotes the restriction of U to its ﬁrst l lines and
ﬁrst c columns.
Composition, U × (N1, . . . , Na): Let U be a a × b matrix and N1, . . . , Na be
a series of a matrices of dimension ni × c (they all share the same number of
columns). The composition of U with (N1, . . . , Na) denoted U ×(N1, . . . , Na) is a
matrix of dimension ( Σ
1≤i≤ani)×(b+c). For any i ≤a, j ≤nj, the (Σi′<ini′)+j)th
line of U × (N1, . . . , Na) is the concatenation of the ith line of U and the jth line
of Ni. The composition of U ×(N1, . . . , Na) is done in O(n·m) operations, where
n =
Σ
1≤i≤ani and m = b+c. The matrix U(s) is typically the concatenation of the
matrix U = ((π(s′|s, a), μ(s′)), s′ ∈succ(s, a)) with the matrices Ns′ = U(s′).
Ordering Matrices U lmaxlmin: Let U be a n × m matrix, U lmaxlmin is the
matrix obtained by ordering the elements of the lines of U in increasing order
and the lines of U according to lmax (in decreasing order). The complexity of the
operation depends on the sorting algorithm: if we use QuickSort then ordering
the elements within a line is performed in O(m · log(m)), and the inter-ranking
of the lines is done in O(n · log(n) · m) operations. Hence, the overall complexity
in O(n · m · log(n · m)).
Comparison of Ordered Matrices: Given two ordered matrices U lmaxlmin
and V lmaxlmin, we say that U lmaxlmin > V lmaxlmin iﬀ∃i, j such that ∀i′ <
i, ∀j′, U lmaxlmin
i′,j′
= V lmaxlmin
i′,j′
and ∀j′ < j, U lmaxlmin
i,j′
= V lmaxlmin
i,j′
and
U lmaxlmin
i,j
> V lmaxlmin
i,j
. U lmaxlmin ∼V lmaxlmin iﬀthey are identical (com-
parison complexity: O(n · m)).

312
N. Ben Amor et al.
3.3
Lexicographic-Value Iteration
In this section, we propose a value iteration algorithm (Algorithm 1 for the
lmax(lmin) variant; the lmin(lmax) variant is similar) that computes a lexi-
cographic optimal policy in a ﬁnite number of iterations. This algorithm is an
iterative procedure that updates the utility of each state, represented by a ﬁnite
matrix of trajectories, using the utilities of the neighboring states, until a halting
condition is reached. At stage t, the procedure updates the utility of every states
s ∈S as follows:
– For each a ∈As, a matrix Q(s, a) is built which evaluates the “utility” of
performing a in s at stage t: this is done by combining TUs,a (comparison of
the transition matrix Ts,a = π(·|s, a) and the utilities μ(s′) of the states s′ that
may follows s when a is executed) with the matrices U t−1(s′) of trajectories
provided by these s′. The matrix Q(s, a) is then ordered (the operation is
made less complex by the fact that the matrices U t−1(s′) have been ordered
at t −1).
– The lmax(lmin) comparison is performed on the ﬂy to memorize the best
Q(s, a)
– The value of s at t, U t(s), is the one given by the action δt(s) = a which pro-
vides the best Q(s, a). U t and δt are memorized (and U t−1 can be forgotten).
Algorithm 1. Lmax(lmin)-value iteration
Data: A possibilistic MDP and an horizon E
δ∗, the policy built by the algorithm, is a global variable
1 // δ a global variable starts as an empty set
Result: Computes and returns δ∗for MDP
2 begin
3
t ←0;
4
foreach s ∈S do U t(s) ←((μ(s)));
5
foreach s ∈S, a ∈As do TUs,a ←Ts,a × ((μ(s′)), s′ ∈succ(s, a));
6
repeat
7
t ←t + 1;
8
foreach s ∈S do
9
Q∗←((0));
10
foreach a ∈A do
11
Future ←(U t−1(s′), s′ ∈succ(s, a)); // Gather the matrices
provided by the successors of s;
12
Q(s, a) ←(TUs,a × Future)lmaxlmin;
13
if Q∗≤lmaxlmin Q(s, a) then Q∗←Q(s, a); δt(s) ←a ;
14
U t(s) ←Q∗(s, δt(s))
15
until t == E;
16
δ∗(s) ←argmaxaQ(s, a)
17
return δ∗;

Eﬃcient Policies for Stationary Possibilistic Markov Decision Processes
313
Proposition 4. lmax(lmin)-Value iteration provides an optimal solution for
⪰lmaxlmin.
Time and space complexities of this algorithm are nevertheless expensive,
since it eventually memorizes all the trajectories. At each step t its size may be
about bt · (2 · t + 1), where b is the maximal number of possible successors of
an action; the overall complexity of the algorithm is O(|S| · |A| · |E| · bE), which
is problematic. Notice now that, at any stage t and for any state s [U t(s)]1,1
(i.e. the top left value in U t(s)) is precisely equal to uopt(s) at horizon t for
the optimal strategy. We have seen that making the choices on this basis is not
discriminant enough. On the other hand, taking the whole matrix is discriminant,
but exponentially costly. Hence the idea of considering more than one line and
one column, but less than the whole matrix - namely the ﬁrst l lines and c
columns of U t(s)lmaxlmin; hence the deﬁnition of the following preference:
δ ≥lmaxlmin,l,c δ′ iﬀ[δlmaxlmin]l,c ≥[δ′lmaxlmin]l,c
(14)
≥lmaxlmin,1,1
corresponds
to
⪰opt
and
≥lmaxlmin,+∞,+∞
corresponds
to
≥lmaxlmin.
The combinatorial explosion is due to the number of lines (because at ﬁnite
horizon, the number of columns is bounded by 2·E+1), hence we shall bound the
number of considered lines. The following proposition shows that this approach
is sound:
Proposition 5. For any l, c δ ≻opt δ′ ⇒δ ≻lmaxlmin,l,c δ′.
For any l, c, l′ such that l′ > l, δ ≻lmaxlmin,l,c δ′ ⇒δ ≻lmaxlmin,l′,c δ′.
Hence ≻lmaxlmin,l,c reﬁnes uopt and the order over the strategies is reﬁned for
a ﬁxed c when l increases. It tends to ≻lmaxlmin when c = 2.E + 1 and l tends
to bE.
Up to this point, the comparison by ≥lmaxlmin,l,c is made on the basis of the
ﬁrst l lines and c columns of the full matrices of trajectories. This does obviously
not reduce their size. The important following Proposition allows us to make the
l, c reduction of the ordered matrices at each step (after each composition), and
not only at the very end, thus keeping space and time complexities polynomial.
Proposition 6. Let U be a a×b matrix and N1, . . . , Na be a series of a matrices
of dimension ai × c. It holds that:
[(U × (N1, . . . , Na))lmaxlmin]l,c = [(U × ([Nlmaxlmin
1
]l,c, . . . , [Nlmaxlmin
a
]l,c))lmaxlmin)]l,c.
In summary, the idea of our Algorithm, that we call bounded lexicographic-
value iteration (BL-VI) is to compute policies that are close to lexi-optimality,
by keeping a sub matrix of each current value matrix - namely the ﬁrst l lines
and c columns. The algorithm is obtained by replacing line 12 of Algorithm 1,
with:
Line 12′ : Q(s, a) ←[(TUs,a × Future)lmaxlmin]l,c;

314
N. Ben Amor et al.
Proposition 7. Bounded lmax(lmin)-Value iteration provides a solution that is
optimal for ⪰lmaxlmin,l,c and its time complexity is O(|E| · |S| · |A| · (l · c) · b ·
log(l · c · b)).
In summary, this algorithm provides in polytime a strategy that is always as
least as good as the one provided by uopt (according to lmax(lmin)) and tends
to lexi optimality when c = 2 · E + 1 and l tends to bE.
4
Lexicogaphic-Value Iteration for Inﬁnite Horizon
P-MDPs
In the inﬁnite-horizon case, the comparison of matrices of trajectories by
Eqs. (12) or (13) may not be enough to rank-order the policies. The length of
the trajectories may be inﬁnite, and their number inﬁnite as well. This problem
is well known in classical probabilistic MDP where a discount factor is used that
attenuates the inﬂuence of later utility degrees - thus allowing the convergence of
the algorithm [11]. On the contrary, classical P-MDPs do not need any discount
factor and Value Iteration, based on the evaluation for l = c = 1, converges for
inﬁnite horizon P-MDPs [12].
In a sense, this limitation to l = c = 1 plays the role of a discount factor
- which is too drastic; it is nevertheless possible to make the comparison using
≥lmaxlmin,l,c. Let us denote U t(s) the matrix issued from s at horizon t when δ
is executed. It holds that:
Proposition 8. ∀l, c, ∃t such that, forall t′ > t, (U t)lmaxlmin
l,c
(s) = (U t′)lmaxlmin
l,c
(s).
This means that from a given stage t, the value of a strategy is stable if computed
with the bounded lmax(lmin) criterion. This criterion can thus be soundly used
in the inﬁnite-horizon case and bounded value iteration converges. To adapt the
algorithm to the inﬁnite case, we simply need to modify the halting condition
at line 15 by:
Line15′ : until

U tlmaxlmin
l,c
==

U t−1lmaxlmin
l,c
.
Proposition 9. Whatever l, c, Lmax(lmin)-Bounded Value iteration converges
for inﬁnite horizon P-MDPs.
Proposition 10. The overall complexity of Bounded lmax(lmin)-Value iteration
algorithm is O(|L| · |S| · |A| · (l · c) · b · log(l · c · b)).
5
Experiments
We now compare the performance of Bounded lexicographic value iteration (BL-
VI) as an approximation of (unbounded) lexicographic value iteration (UL-VI),
in the Lmax(lmin) variant. The two algorithms have been implemented in Java

Eﬃcient Policies for Stationary Possibilistic Markov Decision Processes
315
0%
10%
20%
30%
40%
50%
60%
70%
80%
90%
100%
(2,2)
(20,20)
(40,40)
(100,100)
(200,200)
Success rate
(l,c)
0,01
0,1
1
10
100
1000
5
10
15
20
25
CPU Ɵme in sec
Horizon of MDPs
Success rate (b)  
Average CU Ɵme in second (a)
UL-VI
BL-VI (40,40)
BL-VI (20,20)
BL-VI (10,10)
BL-VI (2,2)
E=10
E=15
E=20
E=25
E=10
E=15
E=20
E=25
Fig. 2. Bounded lexicographic value iteration VS Unbounded lexicographic value
iteration
and the experiments have been performed on an Intel Core i5 processor com-
puter (1.70 GHz) with 8 GB DDR3L of RAM. We evaluate the performance of
the algorithms by carrying out simulations on randomly generated P-MDPs with
|S| = 25. The number of actions in each state is equal to 4. The output of each
action is a distribution on two states randomly ﬁred (i.e. the branching fac-
tor is equal to 2). The utility values are uniformly randomly ﬁred in the set
L = {0.1, 0.3, 0.5, 0.7, 1}. Conditional possibilities relative to decisions should
be normalized. To this end, one choice is ﬁxed to possibility degree 1 and the
possibility degree of the other one is uniformly ﬁred in L. For each experience,
100 P-MDPs are generated. The two algorithms are compared w.r.t. 2 measures:
(i) CPU time and (ii) Pairwise success rate: Success, the percentage of opti-
mal solutions provided by Bounded value iteration with ﬁxed (l, c) w.r.t. the
lmax(lmin) criterion in its full generality. The higher Success, the more impor-
tant the eﬀectiveness of cutting matrices with BL-VI; the lower this rate, the
more important the drowning eﬀect.
Figure 2 presents the average execution CPU time for the two algorithms.
Obviously, for both UL-VI and BL-VI, the execution time increases with the
horizon. Also, we observe that the CPU time of BL-VI increases according to
the values of (l, c) but it remains aﬀordable, as the maximal CPU time is lower
than 1s for MDPs with 25 states and 4 actions when (l, c) = (40, 40) and E = 25.
Unsurprisingly, we can check that the BL-VI (regardless of the values of (l, c))
is faster than UL-VI especially when the horizon increases: the manipulation of
l, c-matrices is obviously less expensive than the one of full matrices. The saving
increases with the horizon.
As with the success rate, the results are described in Fig. 2. It appears that
BL-VI provides a very good approximation especially when increasing (l, c). It
provides the same optimal solution as the UL-VI in about 90% of cases, with
an (l, c) = (200, 200). Moreover, even when the success rate of BL-VI decreases
(when E increases), the quality of approximation is still good: never less than
70% of optimal actions returned, with E = 25. These experiments conclude in
favor of bounded value iteration: its approximated solutions are comparable in
terms of quality for high (l, c) and increase when (l, c) increase, while it is much
faster than the unbounded version.

316
N. Ben Amor et al.
6
Conclusion
In this paper, we have extended to possibilistic Markov Decision Processes the
lexicographic reﬁnement of possibilistic utilities initially introduced in [6] for
non-sequential problems. It can be shown that our approach is more discriminant
than the reﬁnement of binary possibilistic utility [16] since the latter does not
satisfy strict monotonicity. Our lexicographic reﬁnements criteria allowed us to
propose a Lmax(lmin)-Value Iteration algorithm for stationary P-MDPs with
two variants: (i) an unbounded version that converges in the ﬁnite horizon case,
but is unsuitable for inﬁnite-horizon P-MDPs, since it generates matrices which
size continuously increases with the horizon and (ii) a bounded version which
has polynomial complexity. It bounds the size of the saved matrices and reﬁnes
the possibilistic criteria, whatever the choice of the bounds. The convergence of
this algorithm is shown for both the ﬁnite and the inﬁnite horizon cases, and its
eﬃciency has been observed experimentally even for low bounds.
There are two natural perspectives to this work. First, as far as the inﬁ-
nite horizon case is concerned, other types of lexicographic reﬁnements could
be proposed. One of these options could be to avoid the duplication of the set
of transitions that occur several times in a single trajectory and consider only
those which are observed. A second perspective of this work will be to deﬁne rein-
forcement learning [14] type algorithms for P-MDPs. Such algorithms would use
samplings of the trajectories instead of full dynamic programming or quantile-
based reinforcement learning approaches [7].
References
1. Bauters, K., Liu, W., Godo, L.: Anytime algorithms for solving possibilistic MDPs
and hybrid MDPs. In: Gyssens, M., Simari, G. (eds.) FoIKS 2016. LNCS, vol. 9616,
pp. 24–41. Springer, Cham (2016)
2. Bellman, R.: A Markovian decision process. J. Math. Mech. 6, 679–684 (1957)
3. Ben Amor, N., El Khalﬁ, Z., Fargier, H., Sabbadin, R.: Lexicographic reﬁnements
in possibilistic decision trees. In: Proceedings ECAI 2016, pp. 202–208 (2016)
4. Drougard, N., Teichteil-Konigsbuch, F., Farges, J.L., Dubois, D.: Qualitative pos-
sibilistic mixed-observable MDPs. In: Proceedings UAI 2013, pp. 192–201 (2013)
5. Dubois, D., Prade, H.: Possibility theory as a basis for qualitative decision theory.
In: Proceedings IJCAI 1995, pp. 1925–1930 (1995)
6. Fargier, H., Sabbadin, R.: Qualitative decision under uncertainty: back to expected
utility. Artif. Intell. 164, 245–280 (2005)
7. Gilbert, H., Weng, P.: Quantile reinforcement learning. In: Proceedings JMLR
2016, pp. 1–16 (2016)
8. Gilbert, H., Weng, P., Xu, Y.: Optimizing quantiles in preference-based Markov
decision processes. In: Proceedings AAAI 2017, pp. 3569–3575 (2017)
9. Montes, I., Miranda, E., Montes, S.: Decision making with imprecise probabilities
and utilities by means of statistical preference and stochastic dominance. Eur. J.
Oper. Res. 234(1), 209–220 (2014)
10. Moulin, H.: Axioms of Cooperative Decision Making. Cambridge University Press,
Cambridge (1988)
11. Puterman, M.L.: Markov Decision Processes. Wiley, Hoboken (1994)

Eﬃcient Policies for Stationary Possibilistic Markov Decision Processes
317
12. Sabbadin, R.: Possibilistic Markov decision processes. Eng. Appl. Artif. Intell. 14,
287–300 (2001)
13. Sabbadin, R., Fargier, H.: Towards qualitative approaches to multi-stage decision
making. Int. J. Approximate Reasoning 19, 441–471 (1998)
14. Sutton, R.S., Barto, A.G.: Introduction to Reinforcement Learning. MIT Press,
Cambridge (1998)
15. Sz¨or´enyi, B., Busa-Fekete, R., Weng, P., H¨ullermeier, E.: Qualitative multi-armed
bandits: a quantile-based approach. In: Proceedings ICML 2015, pp. 1660–1668
(2015)
16. Weng, P.: Qualitative decision making under possibilistic uncertainty: toward more
discriminating criteria. In: Proceedings UAI 2005, pp. 615–622 (2005)
17. Weng, P.: Markov decision processes with ordinal rewards: reference point-based
preferences. In: Proceedings ICAPS 2011, pp. 282–289 (2011)
18. Yue, Y., Broder, J., Kleinberg, R., Joachims, T.: The k-armed dueling bandits
problem. J. Comput. Syst. Sci. 78(5), 1538–1556 (2012)

An Angel-Daemon Approach to Assess
the Uncertainty in the Power
of a Collectivity to Act
Giulia Fragnito, Joaquim Gabarro(B), and Maria Serna
ALBCOM CS Department, Universitat Polit`ecnica de Catalunya, Barcelona, Spain
giuliafragnito@yahoo.it, {gabarro,mjserna}@cs.upc.edu
Abstract. We propose the use of the angel-daemon (a/d) framework to
assess the Coleman’s power of a collectivity to act under uncertainty in
weighted voting games. In this framework uncertainty proﬁles describe
the potential changes in the weights of a weighted game and ﬁxes the
spread of the weights’ change. For each uncertainty proﬁle a strategic
a/d game can be considered. This game has two selﬁsh players, the angel
a and the daemon d, a selects its action as to maximize the eﬀect on
the measure under consideration while d acts oppositely. Players a and
d give a balance between the best and the worst. The a/d games asso-
ciated to the Coleman’s power are zero-sum games and therefore the
expected utilities of all the Nash equilibria are the same. In this way we
can asses the Coleman’s power under uncertainty. Besides introducing
the framework for this particular setting we analyse basic properties and
make some computational complexity considerations. We provide several
examples based in the evolution of the voting rules of the EU Council of
Ministers.
Keywords: Weighted voting games · Coleman’s power of a collectivity
to act · Uncertainty proﬁles · Strategic games · Zero-sum games · EU
Council of Ministers
1
Introduction
The distinction between risk and uncertainty has become increasingly important
since [11] discussed it as we have imperfect knowledge of future events in our ever-
changing world. Informally, risk can be measured by probabilities. In contrast,
uncertainty refers to something where we cannot even gather the information
required to ﬁgure out probabilities. However, in practice both are measured
G. Fragnito—Partially supported by a scholarship from Universit`a degli Studi di
Roma “La Sapienza”. J. Gabarro and M. Serna are partially supported by funds
from the Spanish Ministry for Economy and Competitiveness (MINECO) and the
European Union (FEDER funds) under grant COMMAS (ref. TIN2013-46181-C2-
1-R), and also by 2014 SGR 1034 (ALBCOM).
c
⃝Springer International Publishing AG 2017
A. Antonucci et al. (Eds.): ECSQARU 2017, LNAI 10369, pp. 318–328, 2017.
DOI: 10.1007/978-3-319-61581-3 29

An Angel-Daemon Approach to Assess the Uncertainty
319
by historical standard deviation of the variable of interest [2,10]. This paper
proposes an alternative, applying ideas from game theory and computer science.
The study of web applications is a ﬁeld where uncertainty becomes unavoid-
able. The angel-daemon framework [9,18] provides a way to obtain numerical
estimates of uncertainty in the execution of a Web service. In such a setting,
the uncertainty is captured by an uncertainty proﬁle describing a stressed envi-
ronment for the execution of Web, or Cloud, applications. Uncertainty proﬁles
provide a description of the perceived uncertain behaviour with respect to pos-
sible failing services or execution delays. That is, some sites can potentially
misbehave but, a priori, we are uncertain about the speciﬁc sites that will do so.
The model attempts to balance positive and negative aspects. Considering only
positive aspects (minimizing damage) is usually too optimistic. In the opposite
side, being pessimistic (maximizing damage) is also not realistic. When facing an
intermediate situation with pessimistic and optimistic aspects. The framework
considers two agents: the angel (a), dealing with the optimistic side; and the dae-
mon (d), dealing with the pessimistic side. These agents act strategically in an
associated angel-daemon zero-sum game. In this context, uncertain behaviours
are identiﬁed with the Nash equilibria of the angel-daemon game and they are
assessed by the value of the game. It is important to emphasize that the results
in [9] are useful to analyse uncertain stable (or timeless) environments.
Another ﬁeld where uncertainty becomes unavoidable is in the analysis of
weighted voting systems. More speciﬁcally, the study of the power of the players
inside a weighted voting game [17] is a well developed topic started by Lloyd
Shapley in 1953 [16]. Also, the study of the uncertainty in such a weighted voting
systems has been considered under theoretical [7] or practical [12] aspects. Less
studied is the behaviour, as a whole, of a weighted voting game under uncertainty.
In 1971 James Coleman [6] introduced the formal deﬁnition of the power of a
collectivity to act, denoted here as Act. Practical applications appears yet in [6].
More recently, [1] (Table 4), it has been used to analyse the power of the EU
Council of Ministers from 1958 to 2007. Its voting rules continuously change
to adapt to EU enlargements. When considering a new voting criteria, there is
uncertainty on the eﬀects on the decision-making. Thus, a uncertainty assessment
is convenient.
In this paper, we extend the a/d framework to assess uncertainty in Act.
We do that shaping uncertainty proﬁles U to deal with the a priori volatility in
the weights of a voting game. Given an uncertainty proﬁle U, well adapted to
Act, the a/d-game becomes a zero-sum game. Therefore, the value of the game
divided by 2n allows us to assess the Coleman’s power to act under uncertainty,
denoted as Act(U). Our objective is to analyse the viability of the model by ﬁrst
analysing some theoretical properties and secondly, using the simplicity of the
model of weighted voting games, develop a series of scenarios in which we can
test the adequacy of the approach.

320
G. Fragnito et al.
2
Preliminaries
A simple game Γ is given by a tuple (N, W) where N is a set of n players and
W is a monotonic family of subsets of N [19]. In the context of simple games,
the subsets of N are called coalitions. N is the grand coalition and S ∈W
is a winning coalition. Any subset of N which is not a winning coalition is
called a losing coalition. The Coleman’s power of the collectivity to act [6], is
deﬁned as Act(Γ) = #W/2n. This measure of collective power can be seen as
the probability of the yes outcome assuming that all coalitions are equally like.
A weighted voting game [17] is a simple game deﬁned by a tuple Γ =
⟨q; w1, . . . wn⟩, where q is the quota and wi ∈N+ is the weight of player
i, for all 1 ≤i ≤n. The set of players is N
= [n] = {1, . . . , n}. Let
w(S) = 
i∈S wi denote the weight of coalition S. The set of winning coali-
tions is W(Γ) = {S | w(S) ≥q}. Therefore, the set of losing coalitions is
L(Γ) = {S | w(S) < q}. Let us consider the case where the weights of
all the players are equal, Γ = ⟨q; w, . . . , w⟩with n > 1. We denote such a
game as Γ(n, q, w). Observe that, for S ⊆[n] it holds w(S) = w |S| and
W(Γ) = {S | w |S| ≥q}. In the case of equal weights, to catch the straight
majority of the total weight, it is needed to capture a weight strictly greater
than (nw)/2. In such a case we cannot distinguish between the requirement of
having the majority of the players from having the majority of the votes. In fact
any quota between w⌊n
2 ⌋+1 and⌊nw
2 ⌋+1 deﬁnes the same game. We consider two
basic families of weighted voting games. The equal weight majority on n play-
ers in which all the players have the same weight w, denote as Γ(n, q, w) and
the equal weight majority on n players game as Γ(n, w) = Γ(n, w⌊n/2

+ 1, w).
Observe that W(Γ(n, w)) = W(Γ(n, 1)) and Act(Γ(n, w)) = Act(Γ(n, 1)).
In order to study some uncertainty scenarios, we consider the weights of the
diﬀerent states at the Council of Ministers of the EU (now the Council of the EU)
along the time [1]. In 1958 the founding members were Germany (DE), France
(FR), Italy (IT), The Netherlands (NL), Belgium (BE), and Luxembourg (LU)
listed in non-decreasing order of assigned weights. The Council of the EU at 1958
is summarized as ΓEC6 = ⟨12; 4, 4, 4, 2, 2, 1⟩where there are six players, the ﬁrst
one is DE, the second one FR, being the last one LU. We adopt the succinct nota-
tion ΓEC6 = ⟨12; 3:4, 2:2, 1:1⟩where notation 3:4 means “3 times weight 4”. Note
that, the total number of votes is #W([6]) = 17. The quota was deﬁned by a qual-
iﬁed majority rule, QMR, of the 70.6% that is q = 12 ≈17∗(70.6/100) = 12.002.
Along the period 1958 to 2014 the number of states increases from the initial
6 to 9, 10, 12, 15, 25 and 27. The voting system changed to cover the new
arrivals [1]. For instance, in 1973, three new states arrive; United Kingdom (UK),
Denmark (DK) and Ireland (IE) having respectively 10, 3,3 votes. As in Sect. 6
we analyse the changes in Act when the weights of the six founding states are per-
turbed, we split the weights in two parts. The part corresponding to the found-
ing six and the rest, ΓEC9 = ⟨41; 10, 10, 10, 5, 5, 2 | 10, 3, 3⟩= ⟨41; 3:10, 2:5, 1:2 |
1:10, 2:3⟩. Following we give a list of the diﬀerent voting systems taken from [1].

An Angel-Daemon Approach to Assess the Uncertainty
321
ΓEC6 = ⟨12; 3:4, 2:2, 1:1⟩
ΓEC9 = ⟨41; 3:10, 2:5, 1:2 | 1:10, 2:3⟩
ΓEC10 = ⟨45; 3:10, 2:5, 1:2 | 1:10, 1:5, 2:3⟩
ΓEC12 = ⟨54; 3:10, 2:5, 1:2 | 1:10, 1:8, 2:5, 2:3⟩
ΓEC15 = ⟨62; 3:10, 2:5, 1:2 | 1:10, 1:8, 2:5, 2:4, 3:3⟩
ΓEC251 = ⟨88; 3:10, 2:5, 1:2 | 1:10, 2:8, 4:5, 2:4, 8:3, 2:2⟩
ΓEC252 = ⟨232; 3:29, 1:13, 1:12, 1:4 | 1:29, 2:27, 4:12, 2:10, 5:7, 4:4, 1:3⟩
ΓEC27 = ⟨255; 3:29, 1:13, 1:12, 1:4 | 1:29, 2:27, 1:14, 4:12, 3:10, 5:7, 4:4, 1:3⟩
In all those games players 1 to 6 correspond to the six founding members in
the same order as in the 1958 description. The parameters of those games and
the Coleman’s Power are the following.
Γ
ΓEC6
ΓEC9
ΓEC10
ΓEC12
ΓEC15
ΓEC251
ΓEU252
ΓEC27
w([n])
17
58
63
76
87
124
321
345
% of q
70.6
70.7
71.4
71.1
71.3
71
72.3
73.9
#W(Γ) 14
75
140
402
2549
1170000 1204448 2718774
Act(Γ)
0.2187 0.1464 0.1455 0.0981 0.0777 0.0348
0.0358
0.0202
Note that the power to act is quite small and roughly decreases along the
time.
3
Uncertainty Proﬁles and a/d Games
Let us move on to adapt the deﬁnition of uncertainty proﬁles [8,9]. They capture
situations in which we have an approximate idea of the extension and nature
of the perturbation but we are uncertain over the speciﬁc location where it will
impact the system. A uncertainty proﬁle is essentially based on three compo-
nents: the set of players of Γ whose weights may be perturbed; the extent to
which the perturbation can be applied; and the number of the components that
can suﬀer the perturbation. As uncertainty may have both positive and negative
eﬀects, we have angelic and daemonic perturbations. The perturbation values
are real numbers, so they can be either positive or negative.
Deﬁnition 1. A uncertainty proﬁle is a tuple U = ⟨Γ, A, D, δa, δd, ba, bd⟩where
Γ = ⟨q; w1, . . . , wn⟩is a weighted voting game; A, D ⊆[n] are the sets of players
whose weights may be subject to angelic and daemonic perturbations, respec-
tively; δa : A →Z and δd : D →Z represent the strength of the potential
weight’s perturbations; ba, bd ∈N are such that ba ≤#A and bd ≤#D and they
represent the spread of the angelic and daemonic perturbations.

322
G. Fragnito et al.
The exerted perturbation follows joint actions (a, d), for a ⊆A, d ⊆D
with #a = ba and #d = bd. The eﬀects of a joint action is a perturbed game
Γ[a, d] = ⟨q; w′
1, . . . , w′
n⟩deﬁned as
w′
i = wi + xa(i)δa(i) + xd(i)δd(i),
where xa(i) = 1 if i ∈a; 0 otherwise, and xd(i) = 1 if i ∈d; 0 otherwise. To
ensure w′
i ∈N+ we require that |δa(i)|, |δd(i)|, |δa(i) + δd(i)| < wi. We consider
also another way to deﬁne the perturbed game that we call proportional quota
in contraposition to the ﬁxed quota presented before. We deﬁne the perturbed
game as Γp[a, d] = ⟨q′, w′
1, . . . , w′
n⟩where q′ =
q
w([n])w′([n]). Observe that the
proportion quota versus total weight is preserved in Γp[a, d].
We are interested to know how the angelic and daemonic perturbations of
a permissible joint action aﬀect the number of winning coalitions through the
perturbed games.
Example 1. Let U = ⟨ΓEC6, {2, 3}, {2, 3}, δa, δd, 1, 1⟩where: The game is ΓEC6 =
⟨12; 4, 4, 4, 2, 2, 1⟩, A = D = {2, 3} = {FR, IT}. We set the angelic perturbations
so that they increase the number of votes, i.e., δa(2) = δa(3) = 1. By contrary, we
set the daemonic perturbations so that such number is more strictly decreased,
i.e., δd(2) = δd(3) = −2. Players’ perturbed weights vary according to joint
actions and we have four joint actions. The perturbed games in the ﬁxed quota
model are:
ΓEC6[{IT}, {FR}] = ⟨12; 4, 2, 5, 2, 2, 1⟩,
ΓEC6[{FR}, {IT}] = ⟨12; 4, 5, 2, 2, 2, 1⟩,
ΓEC6[{FR}, {FR}] = ⟨12; 4, 3, 4, 2, 2, 1⟩,
ΓEC6[{IT}, {IT}] = ⟨12; 4, 4, 3, 2, 2, 1⟩.
In the proportional quote model the total weight is 16 and q′ = 12
1716.
⊓⊔
Assessing uncertainty in a weighted voting game consists in evaluating the
eﬀects of a uncertainty proﬁle. Such analysis is done by means of an associated
strategic zero-sum a/d-game. Two agents are considered: the angel a, exerting
the angelic perturbations of the uncertainty proﬁle; and the daemon d, exerting
the daemonic perturbations. Precisely, a attempts to maximize Act and d acts
in order to minimize it. As we are interested in the study of Act = #W/2n,
we take as utility of the a/d-game ua = #W. To avoid confusions, we use Γ to
denote the underlying weighted voting game and G to denote zero-sum strategic
a/d-game. For sake of simplicity we provide the deﬁnitions for the ﬁxed quota
model, similar deﬁnitions can be settled for the proportional quota model.
Deﬁnition 2. Given U = ⟨Γ, A, D, δa, δd, ba, bd⟩, the associated angel/daemon
(or a/d) game is G(U) = ⟨{a, d}, Aa, Ad, ua, ud⟩. Game G(U) has two players:
the angel a and the daemon d. The player’s actions are Aa = {a ⊆A | #a = ba}
and Ad = {d ⊆D | #d = bd}. For (a, d) ∈Aa × Ad utilities are ua(a, d) =
#W(Γ[a, d]) and ud(a, d) = −ua(a, d).
Notice that, in an a/d game the set of strategy proﬁles is Aa × Ad. a
and d choices of actions can be done probabilistically. Mixed strategies for

An Angel-Daemon Approach to Assess the Uncertainty
323
a and d are probability distributions α : Aa
→[0, 1] and β
: Ad
→
[0, 1] respectively. A mixed strategy is a tuple (α, β) such that up(α, β) =

(a,d)∈Aa×Ad α(a)up(a, d)β(d) for p ∈{a, d}. Given ua(a, d) = #W(Γ[a, d]) it
makes sense to extend #W to mixed strategies deﬁning #W(α, β) = ua(α, β) =

(a,d)∈Aa×Ad α(a)

#W(Γ[a, d])

β(d).
Let Δa and Δd denote the set of mixed strategies for a and d, respectively.
A pure strategy proﬁle (a, d) is a special case of mixed strategy proﬁle (α, β)
in which α(a) = 1 and β(d) = 1. A mixed strategy proﬁle (α, β) is a Nash
equilibrium if for any α′ ∈Δa it holds ua(α, β) ≥ua(α′, β) and for any β′ ∈Δd
it holds ud(α, β) ≥ud(α, β′). A pure Nash equilibrium, pne, is a Nash equilibrium
(a, d) where a and d are pure strategies.
It is well known that all Nash equilibria of a zero-sum game G have
the same value ν(G) corresponding to the utility of the row player [13].
For an a/d game G(U) we have: ν(G(U)) = maxα∈Δa minβ∈Δd #W(α, β) =
minβ∈Δd maxα∈Δa #W(α, β). Considering a/d games we extend the deﬁnition
of the Coleman’s power to act to uncertainty proﬁles as follows.
Deﬁnition 3. Given Γ
with n players, U
=
⟨Γ, A, D, δa, δd, ba, bd⟩and
ua(a, d) = #W(Γ[a, d]). We deﬁne #W(U) = ν(G(U)) being G(U) the cor-
responding a/d-game. The Coleman’s power to act of U is Act(U) = #W(U)/2n.
When (α, β) is a Nash equilibrium of G(U) the utility of the angel player
veriﬁes ua(α, β) = #W(U) = 
(a,d)∈Aa×Ad α(a)β(d)#W(Γ[a, d]) and therefore,
dividing by 2n we get Act(U) = 
(a,d)∈Aa×Ad α(a)β(d)Act(Γ[a, d]).
Example 2. We continue with U given in Example 1. As A = D = {FR, IT} =
{2, 3} and ba = bd = 1 we have Aa = Ad = {{FR}, {IT}}. Then, for example,
ua({FR}, {FR}) = #W(ΓEC6[{FR}, {FR}] = #W(⟨12; 4, 3, 4, 2, 2, 1⟩). Observe
that a reordering of the weights does not change the number of winning coali-
tions, i.e., #W(⟨12; 4, 3, 4, 2, 2, 1⟩) = #W(⟨12; 2:4, 1:3, 2:2, 1:1⟩). The a/d-game
is described by the following utility matrix for a.
{FR}
{IT}
{FR} #W(⟨12; 2:4, 1:3, 2:2, 1:1⟩) = 11 #W(⟨12; 1:5, 1:4, 3:2, 1:1⟩) = 12
{IT}
#W(⟨12; 1:5, 1:4, 3:2, 1:1⟩) = 12 #W(⟨12; 2:4, 1:3, 2:2, 1:1⟩) = 11
There is only one Nash equilibrium with α(FR) = β(FR) = 1/2 and α(IT) =
β(IT) = 1/2. Then #W(U) = 23/2 and Act(U) = 23/27 ≈0.1796
⊓⊔
4
Majority Games with Equal Weights
We consider the case in which all the players have equal weight, Γ(n, q, w)
or Γ(n, w). We start by perturbing two players with equal and opposite
strengths. The minimal egalitarian proﬁle is deﬁned as ME(n, w, δ, A, D) =
⟨Γ(n, w), A, D, δa, δd, 1, 1⟩, where δa(i) = δ, for i ∈A, and δd(i) = −δ, for i ∈D.

324
G. Fragnito et al.
Lemma 1. Let n > 2, w > 1, 0 < δ < w, and Γ = Γ(n, w). Let A, D ⊆[n]
and U = ME(n, w, δ, A, D). Then, we have #W(Γ[{i}, {j}]) = #W(Γ(w, n)) if
j = i, otherwise #W(Γ[{i}, {j}]) = #W(Γ(n, w)) +

n−2
⌊n/2⌋−1

.
Proof. Observe that, when both a and d select a common player {i}, the two
perturbations cancel and the so obtained game is the initial one. When (a, d) =
({i}, {j}) with i ̸= j the perturbed game is such that w′
i = w + δ, w′
j = w −δ
and the remaining players have weight w. Thus, the set of winning coalitions
under ({i}, {j}), denoted by W(Γ[{i}, {j}]), is given by the disjoint union {S |
#S ≥⌊n/2⌋+ 1} ∪

{i} ∪S | S ⊆N\{i, j}, #S = ⌊n/2⌋−1

. The number of
winning coalitions follows by straightforward combinatorial arguments.
⊓⊔
Example 3. Take n = 3, w = 2 and δ = 1. In such a case w⌊n/2

+ 1 = 3,
Γ(3, 2) = ⟨3; 2, 2, 2⟩and W(Γ(3, 2)) =

{1, 2}, {1, 3}, {2, 3}, {1, 2, 3}

. Under
the uncertainty proﬁle U = ME(n, w, δ, A, D), where A = {1, 2}, D = {1},
the winning coalitions are W(Γ[{1}, {1}]) = W(Γ(3, 2)) and W(Γ[{2}, {1}]) =
W(Γ(3, 2)) ∪

{2}

.
⊓⊔
Theorem 1. Let n > 2, w > 1, 0 < δ < w, and Γ = Γ(n, w). Let A, D ⊆[n]
and U = ME(n, w, δ, A, D). Assume #A > 0, #D > 0. Then, if A = D,
pne(Γ(U)) = ∅, if A ̸= D and A ⊆D, pne(G(U)) = {({i}, {i}) | i ∈A} and
Act(U) = Act(Γ(n, w)), otherwise pne(G(U)) = {({i}, {j}) | i ∈A\D, j ∈D}
and Act(U) = Act(Γ(n, w)) +
1
2n

n−2
⌊n/2⌋−1

.
It is easy to see that all the previous results also hold in the proportional
quota model. We conclude with an example in which the a/d game has no pne
but exactly one ne.
Example 4. Let n > 2 and w > 1. Let Γ = Γ(n, w) and U = ME(n, w, 1,
{1, 2}, {1, 2}), by Theorem 1 we know that G(U) has no PNE. As ba = bd = 1
we have Aa = Ad =

{1}, {2}

and a’s payoﬀmatrix in the a/d game is the
following.
{1}
{2}
{1} #W(Γ(n, w))
#W(Γ(n, w) +
1
2n

n−2
⌊n/2⌋−1

{2} #W(Γ(n, w) +
1
2n

n−2
⌊n/2⌋−1

#W(Γ(n, w))
A straightforward computation shows that the unique (mixed) Nash equilibrium
is ((1/2,1/2),(1/2, 1/2)). Therefore, Act(U) = Act(Γ(n, w)) +
1
2n−1

n−2
⌊n/2⌋−1

. ⊓⊔
5
Computational Complexity Considerations
We refer the reader to [15] for the deﬁnition of complexity classes and to [3–
5] for further computational results in the context of weighted voting games.

An Angel-Daemon Approach to Assess the Uncertainty
325
Observe that the number of losing coalitions in a weighted voting game corre-
sponds to the number of solutions of a 0–1 Knapsack problem [15]. The counting
version of 0–1 Knapsack is known to be a #P-complete problem, therefore com-
puting the number of winning coalitions of a given weighted voting game is
also #P-complete. The hardness result for Knapsack like problems can be be
extended to decisional problems in our context.
Theorem 2. Computing #W(Γ), given Γ, is #P-complete. The following prob-
lems are NP-hard: deciding whether Act(Γ) ̸= Act(Γ ′), given Γ and Γ ′; given U
and a joint action (a, d) ∈Aa ×Ad, deciding if d is a best response to a in G(U);
and given U associated to Γ, deciding whether Act(U) ̸= Act(Γ).
A slight modiﬁcation in those reductions allows us to get similar complexity
limits for the proportional quota model. The preceding results rely on the hard-
ness of 0–1 Knapsack like problems. Although those problems are NP-hard, they
do admit pseudo-polynomial time algorithms. The problems become solvable
in time polynomial in n, provided the weights are polynomial in n. So, we can
compute #W(Γ) in pseudo-polynomial time using Dynamic Programming on an
array of size w([n]) adapting the traditional 0–1 Knapsack algorithm. However,
even when the weights are polynomial in n, the number of strategies in G(U)
can be exponential, in such a case the complexity of computing ν(G(U)) is still
open.
6
A Study Based on the Council of the EU
When we face a uncertainty proﬁle U in which, all the weights are polynomial
in n and where the spread is constant, it is possible to compute eﬃciently a
complete description of G(U). Afterwards we compute ν(G(U)) solving a Linear
Programming problem [14]. We use this approach to assess experimentally prop-
erties of Act in small games. We have computed Act(U) for several uncertainty
proﬁles when the game is taken from the voting systems of the Council of the
EU and uncertainty is limited to the weights of the six founder members. Our
setting and results are summarized in Fig. 1.
For our ﬁrst case study we selected the weights of the funding states in ΓEC6,
ΓEC27 and ΓEC12. The diﬀerences in weights provide the perturbation functions
δ12−27 and δ12−6 given in Fig. 1(a). From the point of view of ΓEC12, a attempts
to move forward the weights to those in ΓEC27 while d wishes to move them
back to ΓEC6. Our aim is to evaluate the monotonicity of the assessment under
severe weight perturbations when a and d can act in the same set of nations in
opposite directions. We assessed uncertainty proﬁles of the form U12(ba, bd) =
⟨ΓEC12, [6], [6], δ12−27, δ12−6, ba, bd⟩, for all possible values of (ba, bd). In Fig. 1(b)
we provide, for each combination of (ba, bd), Act(U12(ba, bd)) in the ﬁxed quota
model (left) and in the proportional quota model (right). As one can expect, the
variability of Act is higher when the quota is ﬁxed. In the ﬁxed quota model,
an increase of power by a (d) results in an increase (decrease) of Act. The quota
is unchanged while some angelic players’ weights are signiﬁcantly increased.

326
G. Fragnito et al.
This phenomena does not appear in the variable quota model as it can be seen,
for example, when ba = 2.
For our second case of study we selected some variations of the previous
uncertainty proﬁles keeping a and d with the same spread. We assessed uncer-
tainty proﬁles of the form U12SD(b) = ⟨ΓEC12, {0, 1, 2}, {3, 4, 5}, δ12−27, δ12−6, b, b⟩
and U12SI(b) = ⟨ΓEC12, {0, 1, 3}, {3, 4, 5}, δ12−27, δ12−6, b, b⟩and their reversed
versions U12SDr(b) and U12SIr(b). With reversed, we mean that δa = δ12−6 and
δd = δ12−27. In such a scenario, a tries to reduce the damage by decreasing Act
as less as possible, d acts in opposite way. The resulting assessment values are
summarized in Fig. 1(c) for the two models. As one can expect, in the reversed
case Act increases. Observe that by reversing the roles of a and d, the perturbed
Fig. 1. Experimental results

An Angel-Daemon Approach to Assess the Uncertainty
327
games are the same but the Nash equilibria are diﬀerent. As we can see in the
tables, the a/d approach provides as expected diﬀerent assessments when the
objectives change.
In
our
third
case
study
we
analyse
the
extent
to
which
a
ﬁxed
uncertainty model with unit perturbations aﬀects the assessment of Actin
the
Council
of
the
EU.
We
assessed
uncertainty
proﬁles
Ux(b)
=
⟨ΓECx, {0, 1, 2}, {3, 4, 5}, δ1, δ−1, b, b⟩. The results are given in Fig. 1(d). Under
such proﬁles the total weights of the players is preserved, thus the ﬁxed and
proportional models are equivalent. As one can expect, under so small pertur-
bations Act slightly increases as the spread increases and does not present big
variations.
7
Conclusions and Open Problems
We have extended the a/d framework to tackle with the uncertainty in Coleman’s
power to act issued from the imprecisions on weights in voting games. We have
provided an extension of the power measure to uncertainty proﬁles. We developed
several properties and examples. Finally, we conducted an experimental study
showing the monotonicity of the Power to act of the Council of the EU under
uncertainty. Act changes proportionally to the strength and the spread of the
perturbation. As expected, such variations are more obvious in the ﬁxed model
than in the proportional one.
We are working towards extending the framework to voting systems in
which ﬂuctuations of weights are due to a-priori uncertainty in the level of
abstention. Other related topics merits to be studied. In [6] two other mea-
sures were considered. For a player i of a weighted voting game Γ. The
power to initiate action, Initiatei(Γ), deﬁned as #{S ∈L(Γ) | S ∪{i} ∈
W(Γ)}/#L(Γ) which gives the likelihood that i turns a loosing coalition
into a winning one. The power to prevent action, Preventi(Γ), given by
#{S
∈W(Γ) | S\{i} ∈L(Γ)})/#W(Γ) which is the fraction of win-
ning coalitions for which i is critical. It remains open how to address indi-
vidual measures like the power to initiate or the power to prevent in an
uncertain environment. This extension could allow a comparison with the
probabilistic approach undertaken in [1]. In the same lines, uncertainty proﬁles
well adapted to the Shapley values, will allow a comparison with probabilistic
approaches like the one given in [7] and to much more practical approaches like
those given in [1,12].
References
1. Antonakakis, N., Badinger, H., Reuter, W.H.: From Rome to Lisbon and beyond:
Member states’power, eﬃciency, and proportionality in the EU Council of Minis-
ters. Working Paper 175, Vienna University of Economics and Business, Depart-
ment of Economics (2014)
2. Arratia, A.: Computational ﬁnance. An introductory course with R. Atlantis Press,
Paris (2014)

328
G. Fragnito et al.
3. Aziz, H.: Algorithmic and complexity aspects of simple coalitional games. Ph.D.
thesis, University of Warwick (2009)
4. Chalkiadakis, G., Elkind, E., Wooldridge, M.: Computational aspects of coopera-
tive game theory. Morgan & Claypool (2011)
5. Chalkiadakis, G., Wooldridge, M.: Weighted voting games. In: Brandt, F.,
Conitzer, V., Endriss, U., Lang, J., Procaccia, A. (eds.) Handbook of Computa-
tional Social Choice, pp. 377–394. Cambridge University Press, New York (2016)
6. Coleman, J.: Control of collectivities and the power of a collectivity to act. In:
Lieberman, B. (ed.) Social choice, pp. 269–300. Gordon and Breach, reedited in
Routledge Revivals, 2011(1971)
7. Fatima, S.S., Wooldridge, M., Jennings, N.R.: An analysis of the Shapley value and
its uncertainty for the voting game. In: Gleizes, M.P., Kaminka, G.A., Now´e, A.,
Ossowski, S., Tuyls, K., Verbeeck, K. (eds.) EUMAS 2005, Belgium, December 7–8,
2005. pp. 480–481. Koninklijke Vlaamse Academie van Belie voor Wetenschappen
en Kunsten (2005)
8. Gabarro, J., Serna, M.: Uncertainty in basic short-term macroeconomic models
with angel-daemon games. Int. J. Data Anal. Tech. Strat. (2017, in press)
9. Gabarro, J., Serna, M., Stewart, A.: Analysing web-orchestrations under stress
using uncertainty proﬁles. Comput. J. 57(11), 1591–1615 (2014)
10. Hull, J.: Risk Management and Financial Institutions, 3rd edn. Pearson, Hoboken
(2012)
11. Knight, F.: Risk, Uncertainty and Proﬁt. Houghton Miﬄin, Boston (1921)
12. Mielcova, E.: The uncertainty in voting power: the case of the Czech parliament
1996–2004. AUCO Czech Econo. Rev. 4(2), 201–221 (2010)
13. von Neumann, J., Morgenstern, O.: Theory of Games and Economic Behavior,
60th Anniversary, Commemorative edn. Princeton University Press, Princeton and
Oxford (1953)
14. Osborne, M.: An Introductions to Game Theory. Oxford University Press, New
York and Oxford (2004)
15. Papadimitriou, C.: Computational Complexity. Addison-Wesley, Reading (1994)
16. Shapley, L.: A value for n-person games. In: Kuhn, H., Tucker, A. (eds.) Contri-
butions to the Theory of Games, vol. II, pp. 307–317. Princeton University Press,
Princeton (1953). Included in Classics in Game Theory
17. Shapley, L.: Simple games: an outline of the descriptive theory. Syst. Res. Behav.
Sci. 7(1), 59–66 (1962)
18. Stewart, A., Gabarro, J., Keenan, A.: Uncertainty in the cloud: an angel-
daemon approach to modelling performance. In: Destercke, S., Denoeux, T. (eds.)
ECSQARU 2015. LNCS (LNAI), vol. 9161, pp. 141–150. Springer, Cham (2015).
doi:10.1007/978-3-319-20807-7 13
19. Taylor,
A.,
Zwicker,
W.:
Simple
Games:
Desirability
Relations,
Trading,
Pseudoweightings. Princeton University Press, Princeton (1999)

Decision Theory Meets Linear Optimization
Beyond Computation
Christoph Jansen(B), Thomas Augustin, and Georg Schollmeyer
Department of Statistics, LMU, Munich, Germany
{christoph.jansen,augustin,georg.schollmeyer}@stat.uni-muenchen.de
Abstract. The paper is concerned with decision making under com-
plex uncertainty. We consider the Hodges and Lehmann-criterion
relying on uncertain classical probabilities and Walley’s maximality
relying on imprecise probabilities. We present linear programming based
approaches for computing optimal acts as well as for determining least
favorable prior distributions in ﬁnite decision settings. Further, we apply
results from duality theory of linear programming in order to provide
theoretical insights into certain characteristics of these optimal solutions.
Particularly, we characterize conditions under which randomization pays
out when deﬁning optimality in terms of the Gamma-Maximin criterion
and investigate how these conditions relate to least favorable priors.
Keywords: Linear programming · Decision making · Least favor-
able prior · Duality · Maximality · Imprecise probabilities · Gamma-
maximin · Hodges & Lehmann
1
Introduction
Many problems arising in modern sciences, e.g. estimation and hypothesis testing
in statistics or modeling an agent’s preferences in economics, can be embedded
in the formal framework of decision theory under uncertainty. However, as the
speciﬁcation of a precise (i.e. classical) probability measure on the space of uncer-
tain states often turns out to be too restrictive from an applicational point of
view, decision theory using imprecise probabilities (for a survey see, e.g., [12])
has become a more and more attractive modeling tool recently. For determining
optimal decisions with respect to the complex decision criteria particularly (but
not exclusively) arising in the context of the theory of imprecise probabilities,
linear programming theory (see, e.g., [15]) often turns out to be well-suited: By
embedding decision problems into this general optimization framework, one can
draw on the whole theoretical toolbox of this well-investigated mathematical
discipline. Particularly, this allows for a computational treatment of complex
decision making problems in standard software (e.g. MATLAB or for statisti-
cians R) and, therefore, helps in order to make the abstract theory applicable for
practitioners. Accordingly, there exists plenty of literature on linear optimization
driven algorithms for facing complex decision problems. Examples include [6,13].
A survey is given in [5].
c
⃝Springer International Publishing AG 2017
A. Antonucci et al. (Eds.): ECSQARU 2017, LNAI 10369, pp. 329–339, 2017.
DOI: 10.1007/978-3-319-61581-3 30

330
C. Jansen et al.
However, quite similar to characterizations of imprecise probabilities and
natural extensions in [17, Chap. 4] and [14], the opportunities of using linear
programming in decision theory are by far not exhausted by producing powerful
algorithms (see [18, p. 402]). Instead, applying basic results on duality from lin-
ear programming theory (such as, e.g., the complementary slackness property,
see, e.g., [15, Sect. 5.5]) can often provide theoretical insights on both the con-
nection between diﬀerent decision criteria and the speciﬁc properties shared by
all optimal solutions with respect to a certain criterion.
The paper is structured as follows: In Sect. 2, we recall the classical model of
ﬁnite decision theory as well as the extended version of the model allowing for
randomized acts. In Sect. 3, we give a linear program for determining optimal
randomized acts with respect to a decision criterion of Hodges and Lehmann
which tries to cope with uncertain prior probabilistic information and investigate
the corresponding dual programming problem. In Sect. 4, we consider the case
of decision making under imprecise probabilistic information. Particularly, we
present an algorithm for checking maximality of pure acts in one single linear
program in Sect. 4.1 and use duality theory for deriving connections between
least favorable prior distributions and the Gamma-Maximin criterion in Sect. 4.2.
Finally, Sect. 5 is preserved for concluding remarks.
2
The Basic Model
Throughout the paper, we consider the standard model of ﬁnite decision theory:
An agent (or decision maker) has to decide which act ai to pick from a ﬁnite set
A = {a1, . . . , an}. However, the utility of the chosen act depends on which state
of nature from a ﬁnite set Θ = {θ1, . . . , θm} corresponds to the true description
of reality. Speciﬁcally, we assume that the utility of every pair (a, θ) ∈A×Θ can
be evaluated by a known real-valued cardinal utility function u : A × Θ →R.
For simplicity, we will often use the notation uij := u(ai, θj), where i = 1, . . . , n
and j = 1, . . . , m. The structure of the basic model and a running example
repeatedly considered throughout the paper are visualized in Table 1. For every
act a ∈A, the utility function u is naturally associated with a random variable
ua : (Θ, 2Θ) →R deﬁned by ua(θ) := u(a, θ) for all θ ∈Θ. Similarly, for
every θ ∈Θ, we can deﬁne a random variable uθ : (A, 2A) →R by setting
uθ(a) := u(a, θ) for all a ∈A.
Depending on the context, we also allow for randomized acts, i.e. classical
probability measures λ on (A, 2A). Choosing λ is then interpreted as leaving
your ﬁnal decision to a random experiment which yields act ai with probability
λ({ai}). We denote the set of randomized acts on (A, 2A) by G(A).
The utility function u on A×Θ is then extended to a utility function G(u) on
G(A) × Θ by assigning each pair (λ, θ) the expectation of the random variable
uθ under the measure λ, i.e. G(u)(λ, θ) := Eλ

uθ
, which corresponds to the
expectation of utility that choosing the randomized act λ will lead to, given θ
is the true description of reality. Every pure act a ∈A then can uniquely be
identiﬁed with the Dirac-measure δa ∈G(A), and we have u(a, θ) = G(u)(δa, θ)

Decision Theory Meets Linear
331
Table 1. Basic model (left) and running example with acts A = {a1, a2, a3}, states
Θ = {θ1, . . . , θ4} (right) and the credal set M :=

π : 0.3 ⩽π({θ2}) + π({θ3}) ⩽0.7

additionally considered in the Sects. 4.1 and 4.2.
u(ai, θj)
θ1
· · ·
θm
a1
u(a1, θ1) · · · u(a1, θm)
...
...
· · ·
...
an
u(an, θ1) · · · u(an, θm)
u(ai, θj) θ1 θ2 θ3 θ4
a1
20 15 10 5
a2
30 10 10 20
a3
20 40 0 20
for all (a, θ) ∈A × Θ. Again, for every λ ∈G(A) ﬁxed, the extended utility
function G(u) is associated with a random variable G(u)λ on (Θ, 2Θ) by setting
G(u)λ(θ) := G(u)(λ, θ) for all θ ∈Θ. Finally, we refer to the triplet (A, Θ, u)
as the (ﬁnite) decision problem and to the triplet (G(A), Θ, G(u)) as the corre-
sponding randomized extension.
Within this framework, our goal is to determine an optimal act (depending
on the context, either randomized or pure). However, any appropriate deﬁnition
of optimality depends on (what we assume about) the mechanism generating the
states of nature. Here, traditional decision theory mainly covers two extremes:
The mechanism follows a known probability measure π on (Θ, 2Θ) or it can be
compared to a game against an omniscient enemy. In this cases optimality is
almost unanimously deﬁned by either maximizing expected utility with respect to
π (also known as Bayes-criterion) or applying the Maximin-criterion (i.e. choos-
ing an act that has maximal utility under the worst possible state of nature).
In contrast, deﬁning optimality of acts becomes less obvious if the prior π
is only partially known (case of imprecise probabilities) or there is uncertainty
about the complete appropriateness of it (case of uncertainty about precise prob-
abilities). The following sections are concerned with these two situations.
3
Handling Uncertain Precise Probabilistic Information:
The Hodges and Lehmann-Criterion
Apart from the border cases of maximizing expected utility with respect to
a precise prior π in the presence of perfect probabilistic information and the
Maximin-criterion in complete absence of probabilistic information, classical
decision theory tries to cope with decision making under uncertain probabilistic
information, too: Anticipating ideas of robust statistics, Hodges and Lehmann
proposed applying the Bayes-criterion only to such acts, whose worst possible
utility does not fall below a certain amount of the Minimax utility (see [4]).
Their idea is to utilize probabilistic information from previous experience while
simultaneously distrusting the complete appropriateness of this information and
restricting analysis to acts that are not too bad under the worst state. They
also give the following alternative representation of their approach that has a

332
C. Jansen et al.
diﬀerent, intuitively more accessible, interpretation1: The decision maker is
allowed to model his degree of trust in the prior by a parameter α ∈[0, 1]. Specif-
ically, if π is a probability measure on (Θ, 2Θ), a randomized act λ∗∈G(A) is
said to be Hodges and Lehmann-optimal w.r.t. π and α (short: Φπ,α-optimal), if
Φπ,α(λ∗) ⩾Φπ,α(λ) for all λ ∈G(A), where
Φπ,α(λ) := (1 −α) · min
θ
G(u)(λ, θ) + α · Eπ

G(u)λ

(1)
Thus, the parameter α in (1) controls how the linear trade-oﬀbetween expecta-
tion maximization w.r.t. π and applying the Maximin-criterion is actually made.
The following Proposition 1 describes an algorithm for determining a randomized
Hodges and Lehmann-optimal act for arbitrary pairs (π, α).2
Proposition 1. Consider the linear programming problem
(1 −α) · (w1 −w2) + α ·
n

i=1
Eπ(uai) · λi −→
max
(w1,w2,λ1,...,λn)
(2)
with constraints (w1, w2, λ1, . . . , λn) ⩾0 and
• n
i=1 λi = 1
• w1 −w2 ⩽n
i=1 uij · λi
for all j = 1, . . . , m.
Then the following holds:
(i) Every optimal solution (w∗
1, w∗
2, λ∗
1, . . . , λ∗
n) to (2) induces a Φπ,α-optimal
randomized act λ∗∈G(A) by setting λ∗({ai}) := λ∗
i .
(ii) There always exists an Φπ,α-optimal randomized act.
□
By computing the dual linear program of the linear program given in
Proposition 1, we receive the following Corollary. It can be interpreted as a
method to construct priors that take the agent’s scepticism about the prior
probability π (expressed by the parameter α) into account.
Corollary 1. Let λ∗∈G(A) denote a Φπ,α-optimal randomized act. Then, there
exists a probability measure μπ,α on (Θ, 2Θ) and a pure act a∗∈A such that
Φπ,α(λ∗) = Eμπ,α[ua∗]
(3)
Proof. The dual of the optimization problem (2) is given by:
z1 −z2 −→
min
(z1,z2,σ1,...,σm)
(4)
with constraints (z1, z2, σ1, . . . , σm) ⩾0 and
1 A further mathematical characterization from the viewpoint of Gamma-Maximinity
for certain imprecise probabilities is given in Footnote 3.
2 The proofs of Propositions 1, 2 and 3 are straightforward and therefore left out.

Decision Theory Meets Linear
333
• m
j=1 σj = 1 −α
• z1 −z2 ≥m
j=1 uij · σj + α · Eπ(uai)
for all i = 1, . . . , n.
Let (z∗
1, z∗
2, σ∗
1, . . . , σ∗
m) denote an optimal solution to (4). Then the constraints
guarantee that assigning μπ,α({θj}) := α · π({θj}) + σ∗
j for all j = 1, . . . , m
induces a probability measure on (Θ, 2Θ) and that for all expectation maximal
acts a∗∈A with respect to μπ,α it holds that z∗
1 −z∗
2 = Eμπ,α[ua∗]. Further, by
duality, we know that z∗
1 −z∗
2 coincides with the optimal value of program (2)
and, therefore, with Φπ,α(λ∗) where λ∗∈G(A) denotes an Hodges and Lehmann-
optimal randomized act. Thus, Φπ,α(λ∗) = Eμπ,α[ua∗], as desired.
□
Running Example (Table 1): Let π denote the prior on (Θ, 2Θ) induced by
(0.2, 0.7, 0.05, 0.05) and let our trust in π be expressed by α = 0.35. Resolving
the linear programming problem from Proposition 1 gives the optimal solution
(8, 0, 0.8, 0, 0.2). Thus, a Φπ,0.35-optimal randomized act λ∗∈G(A) is induced
by (0.8, 0, 0.2). Next, we can use Corollary 1 to compute μπ,0.35. An optimal
solution of problem (4) is given by the vector (11.78, 0, 0, 0, 0.6385, 0.0115), and
thus the measure μτ,0.35 is induced by the vector (0.070, 0.245, 0.656, 0.029).
4
Handling Imprecise Probabilistic Information:
The Gamma-Maximin View
We now turn to decision criteria taking into account the uncertainty in the prior
information in a more direct way: For modeling prior knowledge, instead of one
classical probability, we consider polyhedral sets of probability measures that
are a common tool in diﬀerent theories of imprecise probabilities, like e.g. linear
partial information ([7]), credal sets ([8]), lower previsions ([16]) or interval
probability ([17]) as well as in robust statistics, like e.g. ε-contamination models
(see [3, p. 12]). Particularly, we assume probabilistic information is expressed by
a polyhedrical set M of probability measures on (Θ, 2Θ) of the form
M :=

π| bs ⩽Eπ(fs) ⩽bs ∀s = 1, ..., r
	
(5)
where, for all s = 1, ..., r, we have (bs, bs) ∈R2 such that bs ⩽bs and fs :
Θ →R. Speciﬁcally, the available information is assumed to be describable by
lower and upper bounds for the expected values of a ﬁnite number of random
variables on the space of states. Clearly, if uncertainty is described by a set of
probability measures, deﬁning meaningful criteria for decision making strongly
depend on the agent’s attitude towards ambiguity, i.e. towards the non-stochastic
uncertainty between the measures contained in M. Accordingly, many competing
criteria exist (see [12] for a survey or [2,8,16] for original sources). In the following
sections, we present linear programming based results for a selection of such
criteria, namely Walley’s maximality and the Gamma-Maximin criterion. For
the latter, we also investigate some connections to least favorable priors.

334
C. Jansen et al.
4.1
Checking Maximality of Pure Acts
The idea behind maximality of an act a∗∈A is quite simple: One repeatedly
compares an act a∗pairwise to all other acts and checks whether there exists an
element of the set M with respect to which ua∗dominates the corresponding
other act in expectation. Formally, an act a∗∈A is said to be M-maximal, if
∀a ∈A ∃πa ∈M :
Eπa(ua∗) ⩾Eπa(ua)
(6)
Naturally, the above deﬁnition extends to randomized acts. However, when also
considering randomized acts, the criterion of M-Maximality coincides (see [16,
p. 163]) with another well-investigated criterion known from IP decision theory
contributed to Levi: E-admissibility. For a detailed discussion of connections
between the two criteria see [11]. An algorithm for determining the set of all
randomized E-admissible acts has been introduced in [13]. However, for ﬁnite
A, being M-Maximal is a strictly weaker condition and, therefore, needs to be
checked separately from E-admissibility. Other approaches for doing so have
already been proposed in [6]. Proposition 2 describes an algorithm for checking
M-Maximality of a pure act az ∈A by solving one single linear program.
Proposition 2. Let (A, Θ, u) denote a ﬁnite decision problem and let M be of
the form (5). Further, let az ∈A be any act. Consider the linear program
n

i=1

 m

j=1
γij

−→
max
(γ11,...,γnm)
(7)
with constraints (γ11, . . . , γnm) ⩾0 and
• m
j=1 γij ⩽1
for all i = 1, . . . , n
• bs ⩽m
j=1 fs(θj) · γij ⩽bs
for all s = 1, ..., r, i = 1, . . . , n
• m
j=1(uij −uzj) · γij ⩽0
for all i = 1, . . . , n.
Then az ∈A is M-Maximal iﬀthe optimal outcome of (7) equals n.
□
If (γ∗
11, . . . , γ∗
nm) is an optimal solution to problem (7) yielding an value of n,
we can construct πai ∈M for which act az dominates act ai in expectation by
setting πai({θj}) := γij. The problem possesses n(3 + r) constraints and nm
decision variables. Determining the set of all maximal acts requires to solve n
such linear programs. Compared to this, the algorithm based on pairwise com-
parisons of acts proposed in [6] here translates to solving n2 −n linear programs
with m decision variables, however, with only r + 2 constraints.
Running Example (Table 1): Resolving the linear programming problem
from Proposition 2 for every act a1, a2 and a3 separately gives optimal value 3
for each of them. Thus, all available acts are M-Maximal.

Decision Theory Meets Linear
335
4.2
Gamma-Maximin and Least Favorable Priors
In this section, we ﬁrst present a linear program for identifying a least favorable
prior distribution from the credal set M under consideration. Afterwards, we
investigate the dual of this linear program and, in this way, provide a connection
between pure acts a ∈A that maximize expected utility with respect to a least
favorable prior and randomized acts λ ∈G(A) that are optimal with respect to
the Gamma-Maximin criterion.
Before we proceed, some additional notation is needed: For a credal element
π ∈M, let B(π) denote the maximal expectation with respect to π that an act
from A can yield (that is B(π) = Eπ(ua∗), where a∗∈A maximizes expected
utility with respect to π). The set of all acts a ∈A that maximize expected
utility with respect to π is denoted by Aπ. Further, we call a credal element
π−∈M a least favorable prior (lfp) from M iﬀB(π−) ⩽B(π) holds for all
π ∈M. Speciﬁcally, π−is a lfp, if it yields the minimal best possible expected
utility under all concurring elements on the credal set. Proposition 3 describes
a linear program for determining a lfp from M.
Proposition 3. Let (A, Θ, u) denote a decision problem and let M be of the
form (5). Consider the linear program
w1 −w2 −→
min
(w1,w2,π1,...,πm)
(8)
with constraints (w1, w2, π1, . . . , πm) ⩾0 and
• m
j=1 πj = 1
• bs ⩽m
j=1 fs(θj) · πj ⩽bs
for all s = 1, ..., r
• w1 −w2 ⩾m
j=1 uij · πj for all i = 1, . . . n.
Then the following holds:
(i) Every optimal solution (w∗
1, . . . , π∗
m) to (8) induces a least favorable prior
π−∈M by setting π−({θj}) := π∗
j .
(ii) There always exists a least favorable prior.
□
A lfp can be understood as a kind of “pignistic” probability, representing the
decision problem under complex uncertainty in a way that is speciﬁc to the prob-
lem and the criterion under consideration, but in return gives the exact criterion
value. This contrasts lfps from pignistic probabilities in Smets’ spirit, who argued
that a decision problem under complex uncertainty could be approached by dis-
tinguishing between a credal level, where the uncertain beliefs are to be expressed
with all their ambiguity and scarceness by an imprecise probability (belief func-
tion in Smets’ context), and a decision level, where eventually the imprecise
probability is condensed into a traditional probability on which expected util-
ity theory could be applied (see, e.g., [9,10], as well as, e.g., [1] for geometric
techniques to represent belief functions by a single precise probability).

336
C. Jansen et al.
We now show some connections between least favorable priors and random-
ized Gamma-Maximin acts w.r.t. M (M-Maximin). Recalling its deﬁnition, a
randomized act λ∗∈G(A) is said to be M-Maximin optimal iﬀfor all λ ∈G(A):
EM

G(u)λ∗
⩾EM

G(u)λ

(9)
where EM(X) := minπ∈M Eπ(X) for random variables X : (Θ, 2Θ) →R.3 It
turns out that the linear program from Proposition 3 is dual to the one for
determining a randomized M-Maximin act described in [13, Sect. 3.2]. Together
with complementary slackness (see, e.g., [15, Sect. 5.5]) from linear optimization
theory, this allows to derive connections between lfps and the Gamma-Maximin.
Proposition 4. Let (A, Θ, u) denote a ﬁnite decision problem and let M be of
the form (5). Then the following holds:
(i) If π−is a lfp from M, then for all optimal randomized M-Maximin acts
λ∗∈G(A) we have λ∗({a}) = 0 for all a ∈A\Aπ−.
(ii) Let π−denote a lfp from M and let λ∗∈G(A) denote a randomized M-
Maximin act. Then for all a ∈Aπ−we have
Eπ−
ua

= EM

G(u)λ∗
Proof. The dual programming problem of problem (8) is given by:
z1 −z2 +
r

s=1
(bsxs −bsys) −→
max
(z1,z2,x1,...,xr,y1,...,yr,λ1,...,λn)
(10)
with constraints (z1, z2, x1, . . . , xr, y1, . . . , yr, λ1, . . . , λn) ⩾0 and
• n
i=1 λi = 1
• z1 −z2 + r
s=1 fs(θj)(xs −ys) ≤n
i=1 uij · λi for all j = 1, . . . , m.
The resulting linear program (10) is exactly the one for determining a random-
ized act λ∗∈G(A) which is optimal with respect to the M-Maximin criterion
as proposed and proven in [13, Sect. 3.2]. We now can use standard results on
duality and complementary slackness (see, e.g., [15, Chap. 5]) to proof the propo-
sition:
3 For the special case of an ε-contamination model (a.k.a. linear-vacuous model) of
the form M(π0,ε) := {(1 −ε)π0 + επ : π ∈P(Θ)}, where P(Θ) denotes the set
of all probability measures on (Θ, 2Θ), ε > 0 is a ﬁxed contamination parame-
ter and π0 ∈P(Θ) is the central distribution, Gamma-Maximin is mathematically
closely related to the Hodges and Lehmann-criterion: For ﬁxed X : (Θ, 2Θ) →R
we have EM(π0,ε)(X) = minπ∈P(Θ)((1 −ε)Eπ0(X) + εEπ(X)) = (1 −ε)Eπ0(X) +
ε minπ∈P(Θ) Eπ(X) = (1 −ε)Eπ0(X) + ε minθ∈Θ X(θ). Thus, maximizing the lower
expectation w.r.t. the ε-contamination model is equivalent to maximizing the Hodges
and Lehmann-criterion with trust parameter (1 −ε) and prior π0.

Decision Theory Meets Linear
337
Part (i): Let π−∈M denote a lfp and let az ∈A\Aπ−. Then
(max{B(π−), 0}, −min{B(π−), 0}, π−({θ1}), . . . , π−({θm}))
(11)
deﬁnes an optimal solution to (8) for which it holds that B(π−) > Eπ−(uaz).
Thus, there exists an optimal solution to (8), for which the constraint w1 −w2 ≥
m
j=1 uzj · πj holds strictly and, therefore, the corresponding slack variable is
strictly greater 0. Hence, by complementary slackness, the corresponding vari-
able in the dual problem (10), that is λz, equals 0 for every optimal solution
of problem (10). Finally, note that {λ∗
z : λ∗
z appears in optimal solution} =
{λ∗({az}) : λ∗∈G(A) M-Maximin optimal}, since, as (implicitly) shown in
[13, Sect. 3.2], every M-Maximin optimal λ∗∈G(A) induces an optimal solu-
tion to (10), namely
(z∗
1, z∗
2, x1, . . . , x∗
r, y∗
1, . . . , y∗
r, λ∗({a1}), . . . , λ∗({an}))
(12)
where (z∗
1, z∗
2, x1, . . . , x∗
r, y∗
1, . . . , y∗
r) denotes an optimal solution to a reduced
version of problem (10) with (λ1, . . . , λn) := (λ∗({a1}), . . . , λ∗({an})) ﬁxed.
Part (ii): Let π−∈M denote an lfp and λ∗∈G(A) denote an M-Maximin
act. Use (11) and (12) to construct optimal solutions to (8) and (10). As the opti-
mal value of (8) equals B(π−) and the optimal value of (10) equals EM

G(u)λ∗
,
the result follows by the duality theorem.
□
As an immediate consequence of Proposition 4 (i), we can specify a condition
under which randomization cannot improve utility, if optimality is deﬁned in
terms of the Gamma-Maximin criterion. Speciﬁcally, we have the following corol-
lary.
Corollary 2. If there exists a lfp π−from M such that Aπ−= {az} for some
z ∈{1, . . . , n}, then δaz ∈G(A) is the unique randomized M-Maximin act.
Speciﬁcally, considering randomized acts is unnecessary in such situations.
□
Running Example (Table 1): Algorithm 8 leads to the optimal solution vector
(13, 0, 0, 0, 0.7, 0.3). Thus, a lfp π−from M is induced by (0, 0.7, 0.3, 0). Simple
computation gives Aπ−= {a2}. Hence, according to Corollary 2, a2 is the unique
M-Maximin act (even compared to randomized acts) with utility 13.
5
Summary and Concluding Remarks
We presented linear programming based approaches for determining optimal
randomized acts and investigated what can be learned by dualizing these. Future
research includes the following issues: If M is non-degenerated, i.e. π({θ}) > 0
for all (π, θ) ∈M × Θ, the same holds for every lfp π−. Since every π−induces
an optimal solution to (8), complementary slackness implies that all constraints
of problem (10) are binding for every optimal solution. This gives a system
of linear equations that have to be satisﬁed by every randomized M-Maximin
act. A natural question is: Under which conditions is this system suﬃcient to

338
C. Jansen et al.
identify an optimal act without solving an optimization problem at all? A further
interesting point is that algorithm (7) for checking maximality of an act az takes
into account all other acts ai in one linear program simultaneously. This could
be used to modify the algorithm for ﬁnding maximal acts that are not too far
from being E-admissible in the sense that the involved probabilities πai that
establish maximality of az diﬀer not too much w.r.t. the L1-norm which can be
guaranteed by imposing further linear constraints.
Acknowledgement. The authors would like to thank the three anonymous referees
for their helpful comments and their support.
References
1. Cuzzolin, F.: Two new Bayesian approximations of belief functions based on convex
geometry. IEEE T. Syst. Man. Cy. B 37, 993–1008 (2007)
2. Gilboa, I., Schmeidler, D.: Maxmin expected utility with non-unique prior. J. Math.
Econ. 18, 141–153 (1989)
3. Huber, P.: Robust Statistics. Wiley, New York (1981)
4. Hodges, J., Lehmann, E.: The use of previous experience in reaching statistical
decisions. Ann. Math. Stat. 23, 396–407 (1952)
5. Hable, R., Troﬀaes, M.: Computation. In: Augustin, T., Coolen, F., de Cooman,
G., Troﬀaes, M. (eds.) Introduction to Imprecise Probabilities, pp. 329–337. Wiley,
Chichester (2014)
6. Kikuti, D., Cozman, F., Filho, R.: Sequential decision making with partially
ordered preferences. Artif. Intel. 175, 1346–1365 (2011)
7. Koﬂer, E., Menges, G.: Entscheiden bei unvollst¨andiger Information. Springer,
Berlin (1976)
8. Levi, I.: The Enterprise of Knowledge: An Essay on Knowledge, Credal Probability,
and Chance. MIT Press, Cambridge (1983)
9. Smets, P.: Decision making in the TBM: the necessity of the pignistic transforma-
tion. Int. J. Approx. Reason. 38, 133–147 (2005)
10. Smets, P.: Decision making in a context where uncertainty is represented by belief
functions. In: Srivastava, R., Mock, T. (eds.) Belief Functions in Business Decisions,
pp. 17–61. Physica, Heidelberg (2002)
11. Schervish, M., Seidenfeld, T., Kadane, J., Levi, I.: Extensions of expected utility
theory and some limitations of pairwise comparisons. In: Bernard, J.-M., Seiden-
feld, T., Zaﬀalon, M. (eds.) Proceedings of ISIPTA 2003, pp. 496–510. Carleton
Scientiﬁc, Waterloo (2003)
12. Troﬀaes, M.: Decision making under uncertainty using imprecise probabilities. Int.
J. Approx. Reason. 45, 17–29 (2007)
13. Utkin, L., Augustin, T.: Powerful algorithms for decision making under partial prior
information and general ambiguity attitudes. In: Cozman, F., Nau, R., Seidenfeld,
T. (eds.) Proceedings of ISIPTA 2005, pp. 349–358 (2005)
14. Utkin, L., Kozine, I.: Diﬀerent faces of the natural extension. In: de Cooman, G.,
Fine, T., Seidenfeld, T. (eds.) Proceedings of ISIPTA 2001, pp. 316–323 (2001)
15. Vanderbei, R.: Linear Programming: Foundations and Extensions. Springer,
New York (2014)
16. Walley, P.: Statistical Reasoning with Imprecise Probabilities. Chapman and Hall,
London (1991)

Decision Theory Meets Linear
339
17. Weichselberger, K.: Elementare Grundbegriﬀe einer allgemeineren Wahrschein-
lichkeitsrechnung I: Intervallwahrscheinlichkeit als umfassendes Konzept. Physica,
Heidelberg (2001)
18. Weichselberger, K.: Interval probability on ﬁnite sample spaces. In: Rieder, H. (ed.)
Robust Statistics, Data Analysis, and Computer Intensive Methods, pp. 391–409.
Springer, New York (1996)

Axiomatization of an Importance Index
for Generalized Additive Independence Models
Mustapha Ridaoui1(B), Michel Grabisch1, and Christophe Labreuche2
1 Paris School of Economics, Universit´e Paris I - Panth´eon-Sorbonne, Paris, France
{mustapha.ridaoui,michel.grabisch}@univ-paris1.fr
2 Thales Research and Technology, Palaiseau, France
christophe.labreuche@thalesgroup.com
Abstract. We consider MultiCriteria Decision Analysis models which
are deﬁned over discrete attributes, taking a ﬁnite number of values. We
do not assume that the model is monotonically increasing with respect
to the attributes values. Our aim is to deﬁne an importance index for
such general models, encompassing Generalized-Additive Independence
models as particular cases. They can be seen as being equivalent to k-
ary games (multichoice games). We show that classical solutions like the
Shapley value are not suitable for such models, essentially because of the
eﬃciency axiom which does not make sense in this context. We propose
an importance index which is a kind of average variation of the model
along the attributes. We give an axiomatic characterization of it.
Keywords: MultiCriteria decision analysis · k-ary game · Shapley value
1
Introduction
In MultiCriteria Decision Analysis (MCDA), a central question is to determine
the importance of attributes or criteria. Suppose the preference of a decision
maker has been represented by a numerical model. For interpretation and expla-
nation purpose of the model, a basic requirement is to be able to assess the
importance of each attribute. If this is easy for a number of elementary models
(essentially additive ones), it becomes more challenging with complex models.
For models based on the Choquet integral w.r.t. a capacity or fuzzy measure
(see a survey in [8]), it has been recognized since a long time ago that the Shapley
value [15], a concept borrowed from game theory, is the adequate tool to quantify
the importance of attributes.
Choquet integral-based models belong to the category of decomposable mod-
els, that is, where utility functions are deﬁned on each attribute, and then
are aggregated by some increasing function. In this paper, we depart from
this kind of models and focus on models where there is no such separation
of utilities among the attributes. Typically, the Generalized Additive Indepen-
dence (GAI) model proposed by Fishburn [4,5] is of this type, since of the form
U(x) = 
S∈S uS(xS), where S is a collection of subsets of N, the index set of
c
⃝Springer International Publishing AG 2017
A. Antonucci et al. (Eds.): ECSQARU 2017, LNAI 10369, pp. 340–350, 2017.
DOI: 10.1007/978-3-319-61581-3 31

Axiomatization of an Importance Index
341
all attributes. In this paper, however, we do not take advantage of this peculiar
form, and consider a numerical model without particular properties, except that
the underlying attributes are discrete, and thus take a ﬁnite number of values.
Note that in many applications, especially in the AI ﬁeld, this is the case, in
particular for GAI models [1,2,6].
As far as we know, the question of the deﬁnition of an importance index
for such a general case remains open. As we will explain, discrete models can be
seen as k-ary capacities or more generally k-ary games [9] (also called multichoice
games [11]), and thus it seems natural to take as importance index the various
deﬁnitions of Shapley-like values for multichoice games existing in the literature.
There is however a major drawback inherent to these values: they all satisfy the
eﬃciency axiom, that is, the sum of the importance indices over all attributes is
equal to v(kN), the value of the game when all attributes take the highest value.
If this axiom is natural in a context of cooperative game, where the Shapley
value deﬁnes a rational way to share among the players the total beneﬁt v(kN)
of the game, it has no justiﬁcation in MCDA, especially if the model v is not
monotone increasing.
The approach we propose here is inspired by the calculus of variations: we
deﬁne the importance index of an attribute as the average variation of v (depict-
ing the satisfaction of the decision maker) when the value of attribute i is
increased by one unit. We propose an axiomatic deﬁnition, where the chosen
axioms are close to those of the original Shapley value.
Section 2 recalls the basic concepts. Section 3 informally deﬁnes what is the
aim of our importance index. The axiomatic characterization is presented in
Sect. 4. The new index is then interpreted (Sect. 5).
2
Preliminaries
Throughout the paper, N = {1, . . . , n} is a ﬁnite set which can be thought as
the set of attributes (in MCDA), players (in cooperative game theory), etc.,
depending on the application. In this paper, we will mainly focus on MCDA
applications. Cardinality of sets will be often denoted by corresponding lower
case letters, e.g., n for |N|, s for |S|, etc.
The set of all possible values taken by attribute i ∈N is denoted by Li. As it
is often the case in MCDA, we assume that these sets are ﬁnite, and we represent
them by integer values, i.e., Li = {0, 1, . . . , ki}. Alternatives are thus elements
of the Cartesian product L = ×i∈NLi and take the form x = (x1, x2, . . . , xn)
with xi ∈Li, i = 1, . . . , n. For x, y ∈L, we write x ≤y if xi ≤yi for every
i ∈N. For S ⊆N and x ∈L, xS is the restriction of x to S. L−i is a shorthand
for ×j̸=iLj. For each y−i ∈L−i, and any ℓ∈Li, (y−i, ℓi) denotes the combined
alternative x such that xi = ℓi and xj = yj, ∀j ̸= i. The vector 0N = (0, . . . , 0)
is the null alternative of L, and kN = (k1
1, . . . , kn
n) is the top element of L. 0−i
denotes the element of L−i in which all coordinates are zero. We call vertex of
L any element x ∈L such that xi is either 0 or ki, for each i ∈N. We denote
by Γ(L) = ×i∈N{0, ki} the set of vertices of L. For each x ∈L, we denote by

342
M. Ridaoui et al.
S(x) = {i ∈N | xi > 0} the support of x, and by K(x) = {i ∈N | xi = ki} the
kernel of x. Their cardinalities are respectively denoted by s(x) and k(x). We
call elementary cell of L a unit cell ×i∈N{xi, xi + 1}, for xi ∈Li\ki.
We suppose to have a numerical representation v : L →R of the preference
of the decision maker (DM) over the set of alternatives in L. For the sake of
generality, we do not make any assumption on v, except that v(0N) = 0 (this is
not a restriction, as most of numerical representations are unique up to a positive
aﬃne transformation). In particular, there is no assumption of monotonicity,
that is, we do not assume that x1 ≥x′
1,. . . , xn ≥x′
n implies v(x1, . . . , xn) ≥
v(x′
1, . . . , x′
n). Example 1 below illustrates that it is quite common to observe
this lack of monotonicity.
Example 1. The level of comfort of humans depends on three main attributes:
temperature of the air (X1), humidity of the air (X2) and velocity of the air
(X3). Then v(x1, x2, x3) measures the comfort level. One can readily see that v
is not monotone in its three arguments. For x2 and x3 ﬁxed, v is maximal for
intermediate values of the temperature (typically around 23 ◦C). Similarly, the
value of humidity maximizing v is neither too low nor too high. Finally, for x1
relatively large, some wind is well appreciated, but not too much. Hence for any
i, and supposing the other two attributes being ﬁxed, there exists an optimal
value ℓi ∈Li such that v is increasing in xi below ℓi, and then decreasing in xi
above ℓi.
Although we will not use this speciﬁc form for v in the sequel, we men-
tion as typical example of a model not necessarily satisfying monotonicity the
Generalized Additive Independence (GAI) model, i.e., v is written as v(x) =

S∈S vS(xS), where S is a collection of subsets of N [4,5]. This model has been
widely used in AI [1,2,6].
For convenience, we assume from now on that all attributes have the same
number of elements, i.e., ki = k for every i ∈N (k ∈N). Note that if this
is not the case, k is set to maxi∈N ki, and we duplicate some elements of Li
when ki < k. A fundamental observation is that when k = 1, v is nothing
other than a pseudo-Boolean function v : {0, 1}N →R vanishing on 0N, or
put otherwise via the identity between sets and their characteristic functions, a
(cooperative) game (in characteristic form) μ : 2N →R, with μ(∅) = 0. A game
v is monotone if v(A) ≤v(B) whenever A ⊆B. A monotonic game is called
a capacity [3] or fuzzy measure [16]. For the general case k ≥1, v : L →R is
called a multichoice game or k-ary game [11], and the numbers 0, 1, . . . , k in Li
are seen as the level of activity of the players. By analogy with the classical case
k = 1, a k-ary capacity is a monotone k-ary game, i.e., satisfying v(x) ≤v(y)
whenever x ≤y, for each x, y ∈L [9]. Hence, a k-ary capacity represents a
preference on L which is increasing with the value of the attributes. We denote
by G(L) = {v : L →R, v(0N) = 0} the set of functions deﬁned on L vanishing
on 0N. A function is called single-peaked if it has only one local maximum and
no troughs.

Axiomatization of an Importance Index
343
By analogy with classical games, a unanimity game for k-ary game denoted
ux, for each x ∈L with x ̸= 0N is deﬁned by
ux(y) =

1, if
y ≥x
0, otherwise
Note that the set of unanimity games forms a basis of the vector space of k-ary
games. One advantage of unanimity games is that they are monotone. Hence this
basis is relevant for k-ary capacities. In order to obtain a basis of k-ary games
not necessarily made of monotone functions, we deﬁne for each x ∈L such that
x ̸= 0N, the game δx by
δx(y) =
1, if
y = x
0, otherwise
It is obvious that any k-ary game v can be written as
v =

x∈L
x̸=0N
v(x)δx.
(1)
3
Deﬁnition of an Importance Index: What Do We Aim
at Doing?
We restrict ourselves to the MCDA setting and interpretation in this paper.
When dealing with numerical representations of preference in MCDA, one of the
primary concerns is to give an interpretation of the model in terms of importance
of the attributes. When v is a capacity or a game (k = 1), or with continuous
models extending capacities and games like the Choquet integral, the standard
solution is to take the Shapley value, introduced by Shapley in the context of
cooperative games [15]. A value is a function φ : G(2N) →RN that assigns to
every game μ a payoﬀvector φ(μ). It is interpreted in the MCDA context as the
vector of importance of the attributes. The value introduced by Shapley is one
of the most popular, and is deﬁned by:
φSh
i (μ) =

S⊆N\i
(n −s −1)!s!
n!

μ(S ∪i) −μ(S)

, ∀i ∈N.
(2)
A standard property shared by many values in the literature is eﬃciency:

i∈N φi(μ) = μ(N). This property is very natural in game theory, as μ(N)
is the total beneﬁt obtained from the cooperation of all players in N, and by
eﬃciency the payoﬀvector φ(v) represents a sharing of this total beneﬁt.
If the Shapley value has been widely used in MCDA with great success (see,
e.g., [8]), it must be stressed that it was only in the case of monotonically increas-
ing models, i.e., based on a capacity μ. In such cases, μ(N) is set to 1, the value
of the best possible alternative, and the importance index of an attribute could

344
M. Ridaoui et al.
be seen as a kind of contribution of that attribute to the best possible alterna-
tive. However if the model is not monotone increasing, such an interpretation
fails. Hence, we are facing here a double diﬃculty: to propose a “value” both
valid for k ≥1 and for nonincreasing models. There have been many proposed
values for multichoice games, e.g., Hsiao and Raghavan [11], van den Nouweland
et al. [17], Klijn et al. [12], Peters and Zank [14] and Grabisch and Lange [10],
etc. All of them satisfy the classical eﬃciency axiom.
We wish to capture in our importance index the impact of each attribute
on the overall utility. Let us consider for illustration function δy with k = 2,
n = 3 and y = (2, 1, 1). Attribute 1 is non-decreasing and has a positive impact
on the overall utility. Attribute 2 has neither a positive nor a negative impact
on the overall utility, since δy(x) is going from value 0 (at x2 = 0) to 1 (at
x2 = 1), and then decreasing to value 0 again (at x2 = 2). Hence attribute 2 has
globally neither a positive nor a negative impact. The same holds with attribute
3. Hence, denoting by φ(δy) our importance index for that function, one shall
have φ1(δy) > 0, φ2(δy) = φ3(δy) = 0, so that the sum 
i∈N φi(v) > 0 cannot
be equal to v(2, 2, 2) −v(0, 0, 0) = 0, and hence φ does not satisfy eﬃciency.
Rather, the index φi(v) shall measure the impact of attribute i on v, as the total
variation on v if we increase the value of attribute i of one unit (going from value
xi to xi + 1), when x is varying over the domain.
4
Axiomatization
We deﬁne in this section an importance index according to the ideas explained
above, by using an axiomatic description. Our ﬁrst three axioms are the same as
those used by Shapley when characterizing his value in [15]: linearity, null player
and symmetry. Our approach will follow Weber [18], who introduces the axioms
one by one and at each step gives a characterization. Throughout this section,
we consider a value as a mapping φ : G(L) →R.
We expect our importance index to have an exponential complexity of com-
putation, as for the Shapley value. In order to reduce the complexity bur-
den for some functions v having some particular properties, we assume that
for GAI models, the value can be decomposed over each utility function vS.
Hence φ shall be additive: φi(v + v′) = φi(v) + φi(v′). Moreover, utilities are in
MCDA invariant to positive linear transformations. Hence φi shall be homoge-
neous: φi(αv) = αφi(v) for every α > 0. Lastly the value shall be symmetric:
φi(−v) = −φi(v). The previous three properties yield linearity axiom L.
Linearity Axiom (L): φ is linear on G(L), i.e., ∀v, w ∈G(L), ∀α ∈R,
φi(v + αw) = φ(v) + αφ(w).
Proposition 1. Under axiom (L), for all i ∈N, there exists constants ai
x ∈R,
for all x ∈L, such that ∀v ∈G(L),
φi(v) =

x∈L
ai
xv(x).
(3)

Axiomatization of an Importance Index
345
The proof of this result and the other ones are omitted due to space limitation.
The second axiom that characterizes the Shapley value in [18] is called the
null player axiom. It says that a player i ∈N who brings no contribution (i.e.,
μ(S ∪i) = μ(S), ∀S ⊆N\{i}) should receive a zero payoﬀ. This deﬁnition can
be easily extended to v ∈G(L) and to a MCDA setting.
Deﬁnition 1. A criterion i ∈N is said to be null for v ∈G(L) if
v(x + 1i) = v(x), ∀x ∈L, xi < k.
Remark 1. Let i ∈N be a null criterion for v ∈G(L). we have,
∀x ∈L, v(x−i, xi) = v(x−i, 0i).
If an attribute is null w.r.t. a function v ∈G(L), then this attribute has no
inﬂuence on v, and hence the importance of this attribute shall be zero. We
propose the following axiom.
Null Axiom (N): If a criterion i is null for v ∈G(L), then φi(v) = 0.
Proposition 2. Under axioms (N) and (L), for all i ∈N, there exists bi
x ∈R,
for all x ∈L with xi < k, such that ∀v ∈G(L),
φi(v) =

x∈L
xi<k
bi
x

v(x + 1i) −v(x)

.
(4)
This proposition shows that φi is a linear combination of the added-values on v,
going from value xi to xi + 1, over all x.
The classical symmetry axiom says that the numbering of the attributes has
no inﬂuence on the value. It means that the computation of value should not
depend on the numbering of the attributes.
Let σ be a permutation on N. For all x ∈L, we denote σ(x)σ(i) = xi. For all
v ∈G(L), The function σ ◦v is deﬁned by σ ◦v(σ(x)) = v(x).
Symmetry Axiom (S): For any permutation σ of N,
φσ(i)(σ ◦v) = φi(v), ∀i ∈N.
Proposition 3. Under axioms (N), (L) and (S), ∀v ∈G(L), ∀i ∈N,
φi(v) =

x∈L
xi<k
bxi;n0,...,nk

v(x + 1i) −v(x)

,
where bxi;n0,...,nk ∈R, and nj is the number of components of x−i being equal
to j.

346
M. Ridaoui et al.
This result means that the coeﬃcients in front of the added-values on v, going
from value xi to xi + 1, do not depend on the precise value of x, but only on the
number of terms of x−i taking values 0, 1, . . . , k.
Let us take for example N = {1, 2, 3}, k = 2 and x = (0, 2, 2). We have,
b1
x = b0;0,0,2, b2
x = b2;1,0,1, and b3
x = b2;1,0,1.
The next axiom enables an easier computation of coeﬃcients bi
x while reduc-
ing their number.
Invariance Axiom (I): Let us consider two functions v, w ∈G(L) such
that, for all i ∈N,
v(x + 1i) −v(x) = w(x) −w(x −1i), ∀x ∈L, xi /∈{0, k}
v(x−i, 1i) −v(x−i, 0i) = w(x−i, ki) −w(x−i, ki −1), ∀x−i ∈L−i.
Then φi(v) = φi(w).
Taking two functions v and w for which the diﬀerences v(x + 1i) −v(x)
(measuring the added value of improving x of one unit on attribute i can be
deduced from that of w just by shifting of one unit, then the mean importance
of attribute i shall be the same for v and w. In other words, what is essential
is the absolute value of the diﬀerences v(x + 1i) −v(x) and not the value x at
which it occurs.
Proposition 4. Under axioms (L), (N) and (I), ∀v ∈G(L), ∀i ∈N,
φi(v) =

x−i∈L−i
bi
x−i

v(x−i, ki) −v(x−i, 0i)

.
Axiom (I) implies that we only need to look at the diﬀerence of v between the
extreme value 0 and k. The evaluation on the intermediate elements of Li do
not count.
Proposition 5. Under axioms (L), (N), (I) and (S), ∀v ∈G(L), ∀i ∈N,
φi(v) =

x−i∈L−i
bn(x−i)

v(x−i, ki) −v(x−i, 0i)

,
where n(x−i) = (n0, n1, . . . , nk) with nj the number of components of x−i being
equal to j.
As explained in Sect. 3, we do not require that φ satisﬁes eﬃciency. In the
context of game theory, φSh
i (μ) is the amount of money alloted to player i, so that
relation 
i∈N φSh
i (μ) = μ(N) means that all players share among themselves
the total worth μ(N). We have no such interpretation in MCDA. By contrast, we
interpret φi(v) as an overall added value when increasing the value of attribute i
of one unit – thereby going from any point x to (xi + 1, x−i). Hence 
i∈N φi(v)
can be interpreted as the overall added value when increasing simultaneously

Axiomatization of an Importance Index
347
the value of all attributes of one unit – thereby going from any point x to
x + 1 = (x1 + 1, . . . , xn + 1). For an arbitrary function v, there is a priori no
particular property for the previous sum. We thus consider a very special case of
functions following Example 1. These functions are single peaked. The simplest
version of these functions is the family of functions δy. For those functions,
we immediately see from Proposition 5 that φi(δy) = 0 for every i such that
yi ̸= 0, k, as already mentioned in Sect. 3. Based on this remark, we should only
bother on attributes which are equal to either 0 or k in y. We have therefore
three cases (recall that s(y), k(y) are the cardinalities of the support and kernel
of y):
– k(y) ̸= 0 and s(y) = n. Then y −1 ∈L because no component of y is equal
to 0, and we have δy(y) −δy(y −1) = 1. Note that δy(x + 1) −δy(x) = 0 for
any x ̸= y −1 and x, x + 1 ∈L. Therefore, by the above argument, we have

i∈N φi(δy) = 1.
– k(y) = 0 and s(y) < n. This is the dual situation: y + 1 ∈L because no
component is equal to k, and we have δy(y + 1) −δy(y) = −1. Since δy(x +
1) −δy(x) = 0 for any other possible x, we get 
i∈N φi(δy) = −1.
– k(y) ̸= 0 and s(y) < n. This time there are both components equal to 0
and to k in y. Therefore, neither y + 1 nor y −1 belong to L, and for any
possible x ∈L s.t. x + 1 ∈L, we have δy(x + 1) −δy(x) = 0. Therefore,

i∈N φi(δy) = 0.
To summarize, we shall write

i∈N
φi(δy) =
⎧
⎨
⎩
+1
if
k(y) ̸= and s(y) = n
−1
if
k(y) = 0 and s(y) < n
0
else
This can be written in the following compact form.
Restricted Eﬃciency Axiom (RE): For all x ∈L\{0N},

i∈N
φi(δx) = δx(x−i, ki) −δx(x−j, 0j)
where, i = argmax x and j = argmin x.
Note that the previous formula takes the form of standard eﬃciency

i∈N φSh
i (μ) = μ(N) −μ(∅). The ﬁnal result is the following.
Theorem 1. Under axioms (L), (N), (I), (S) and (RE), for all v ∈G(L)
φi(v) =

x−i∈L−i
(n −s(x−i) −1)!k(x−i)!
(n + k(x−i) −s(x−i))!

v(x−i, ki) −v(x−i, 0i)

, ∀i ∈N.
Our axiomatic characterization has in common with the Shapley value the
satisfaction of axioms (L), (N) and (S). The other axioms (I) and (RE) are
diﬀerent.

348
M. Ridaoui et al.
We note that we have the following relation, for every v ∈G(L)

i∈N
φi(v) =

x∈L
xj<k

v(x + 1) −v(x)

.
The right-hand side of this expression corresponds exactly to the interpretation
provided above saying that 
i∈N φi(v) is the overall impact of going from any
point x to x + 1.
We apply Theorem 1 with the following example.
Example 2. Let x ∈L\{0N} and i ∈N.
• The computation of φi w.r.t. δx gives,
φi(δx−i,0) = −φi(δx−i,k) = (n −s(x−i) −1)!k(x−i)!
(n + k(x−i) −s(x−i))! , and φi(δx−i,xi) = 0, ∀xi /∈{0, k}.
• The computation of φi w.r.t. ux gives,
φi(ux) =

y−i∈L−i
y−i≥x−i
(n −s(x−i) −1)!k(x−i)!
(n + k(x−i) −s(x−i))! .
Let us take for exemple N = {1, 2, 3}, k = 3, and x = (2, 0, 3), we have,
φ1(δx) = 0, φ2(δx) = −1
2, φ3(δx) = 1
2,
φ1(ux) = 3
2, φ2(ux) = 0, φ3(ux) = 9
2.
We note that φi(δx) can be nul when the peak is attained inside the domain
(i = 1), is strictly positive if the peak is attained at the maximal value k (i = 3),
and is strictly negative if the peak is attained at 0 (i = 2). On the other hand,
φi(ux) is always non-negative as the unanimity function is non-decreasing.
5
Interpretation
We propose here an interpretation of φ in continuous spaces, that is, after
extending v to the continuous domain [0, k]N. We consider thus a function
U : [0, k]N →R which extends v: U(x) = v(x) for every x ∈L. The impor-
tance of attribute i can be deﬁned as (see [13, Proposition 5.3.3, p. 141])
Impi(U) =

[0,k]n−1

U(ki, z−i) −U(0i, z−i)

dz−i =

[0,k]n
∂U
∂zi
(z) dz.
In this formula, the local importance of attribute i for function U at point z is
equal to ∂U
∂zi (z). The index Impi(U) appears as the mean of relative amplitude

Axiomatization of an Importance Index
349
of the range of U w.r.t. attribute i, when the remaining variables take uniformly
random values.
The most usual extension of v on [0, k]N is the Choquet integral with respect
to k-ary capacities [7]. Let us compute Impi in this case. We write Impi(U) =

x∈{0,...,k−1}N

[x,x+1]n ∂U
∂zi (z) dz. In [x, x + 1]n, U is equal to v(x) plus the
Choquet integral Cμx w.r.t. capacity μx deﬁned by μx(S) = v((x + 1)S, x−S) −
v(x) for every S ⊆N. By [13],

[0,1]n
∂Cµx
∂zi (z) dz = φSh
i (μx). Hence
Impi(U) =

x∈{0,...,k−1}N
φSh
i (μx).
(5)
We then obtain the following result.
Lemma 1. If U is the Choquet integral w.r.t. k-ary capacity v, then Impi(U) =
φi(v).
Hence the counterpart of φi on continuous domains is the integrated local impor-
tance.
6
Conclusion and Related Works
We have proposed a new importance index for GAI models. It quantiﬁes the
impact of each attribute on the overall utility. According to the linearity, null
criterion, symmetry and invariance properties, φi(v) takes the form of the sum
over x ∈{0, . . . , k −1}N of a value over the restriction of functions v on
×i∈N{xi, xi + 1} (see (5)). In our construction, the value at an elementary cell
×i∈N{xi, xi + 1} corresponds to the usual Shapley value.
We will explore in future work the possibility of the use of other values such
as the Banzhaf value. We will also investigate other indices φi which measure
the impact in absolute value of attribute i. In this case, φi(δy) is not equal to
zero when 0 < yi < k.
References
1. Bacchus, F., Grove, A.: Graphical models for preference and utility. In: Conference
on Uncertainty in Artiﬁcial Intelligence (UAI), Montreal, Canada, pp. 3–10, July
1995
2. Braziunas, D., Boutilier, C.: Minimax regret based elicitation of generalized addi-
tive utilities. In: Proceedings of the Twenty-Third Conference on Uncertainty in
Artiﬁcial Intelligence (UAI-07), Vancouver, pp. 25–32 (2007)
3. Choquet, G.: Theory of capacities. Annales de l’institut Fourier 5, 131–295 (1953)
4. Fishburn, P.: Interdependence and additivity in multivariate, unidimensional
expected utility theory. Int. Econ. Rev. 8, 335–342 (1967)
5. Fishburn, P.: Utility Theory for Decision Making. Wiley, New York (1970)
6. Gonzales, C., Perny, P., Dubus, J.: Decision making with multiple objectives using
GAI networks. Artif. Intell. J. 175(7), 1153–1179 (2000)

350
M. Ridaoui et al.
7. Grabisch, M., Labreuche, C.: Capacities on lattices and k-ary capacities. In:
International Conference of the Euro Society for Fuzzy Logic and Technology
(EUSFLAT), Zittau, Germany, 10–12 September 2003
8. Grabisch, M., Labreuche, C.: A decade of application of the Choquet and Sugeno
integrals in multi-criteria decision aid. Ann. Oper. Res. 175, 247–286 (2010)
9. Grabisch, M., Labreuchem, C.: Capacities on lattices and k-ary capacities. In: 3rd
International Conference of the European Society for Fuzzy Logic and Technology
(EUSFLAT 2003), Zittau, Germany, pp. 304–307, September 2003
10. Grabisch, M., Lange, F.: Games on lattices, multichoice games and the Shapley
value: a new approach. Math. Methods Oper. Res. 65(1), 153–167 (2007)
11. Hsiao, C.R., Raghavan, T.E.S.: Shapley value for multi-choice cooperative games,
I. Discussion paper of the University of Illinois at Chicago, Chicago (1990)
12. Klijn, F., Slikker, M., Zarzuelo, J.: Characterizations of a multi-choice value. Int.
J. Game Theor. 28(4), 521–532 (1999)
13. Marichal, J.-L.: Aggregation operators for multicriteria decision aid. Ph.D. thesis,
University of Li`ege (1998)
14. Peters, H., Zank, H.: The egalitarian solution for multichoice games. Ann. Oper.
Res. 137(1), 399–409 (2005)
15. Shapley, L.: A value for n-person games. In: Kuhn, I.H., Tucker, A. (eds.) Contri-
butions to the Theory of Games, II(28), pp. 307–317. Princeton University Press,
Princeton (1953)
16. Sugeno, M.: Theory of fuzzy integrals and its applications. Ph.D. thesis, Tokyo
Institute of Technology (1974)
17. van den Nouweland, A., Tijs, S., Potters, J., Zarzuelo, J.: Cores and related solu-
tion concepts for multi-choice games. Research Memorandum FEW 478, Tilburg
University, School of Economics and Management (1991)
18. Weber, R.J.: Probabilistic values for games. In: Roth, A.E. (ed.) The Shapley
Value: Essays in Honor of Lloyd S. Shapley, pp. 101–120. Cambridge University
Press, Cambridge (1988)

Fuzzy Sets, Fuzzy Logic

Probability Measures in G¨odelΔ Logic
Stefano Aguzzoli1(B), Matteo Bianchi2, Brunella Gerla2, and Diego Valota1
1 Department of Computer Science, Universit`a degli Studi di Milano,
via Comelico 39/41, 20135 Milan, Italy
{aguzzoli,valota}@di.unimi.it
2 Dipartimento di Scienze Teoriche e Applicate, Universit`a degli Studi dell’Insubria,
via Mazzini 5, 21100 Varese, Italy
{brunella.gerla,matteo.bianchi}@uninsubria.it
Abstract. In this paper we deﬁne and axiomatise ﬁnitely additive
probability measures for events described by formulas in G¨odelΔ (GΔ)
propositional logic. In particular we show that our axioms fully charac-
terise ﬁnitely additive probability measures over the free ﬁnitely generated
algebras in the variety constituting the algebraic semantics of GΔ as inte-
grals of elements of those algebras (represented canonically as algebras of
[0, 1]-valued functions), with respect to Borel probability measures.
Keywords: Probability measures in non-classical logics · G¨odel propo-
sitional logic, G¨odelΔ propositional logic, Free algebras
1
Introduction
Probability theory over non-classical logics has been an increasingly interest-
ing research topic for the last pair of decades. The literature on the subject
amounts to several research articles and monograph chapters. One of the ﬁrst
papers connecting Lukasiewicz logic with probability theory was [11], in which
the notion of state (ﬁnitely additive probability measure) over MV-algebras was
introduced, and from then several directions have been pursued (see [9]). More
recently, in [5,6] the notion of state was studied for G¨odel-Dummett logic G, by
showing also a connection with the defuzziﬁcation process of fuzzy systems, and
in [4] for the logic of Nilpotent Minimum. In all such logics, formulas can be
seen as functions taking values in the real interval [0, 1], hence it is reasonable
to expect that ﬁnitely additive probability measures over formulas behave as
integrals with respect to some measure over [0, 1]. The logic GΔ was introduced
in [7]. It is obtained by expanding the language of G with a unary operator
Δ that increases expressiveness: informally, we can say that Δ allows to make
“fuzzy” statements “crisp”, allowing to express the characteristic functions of
1-sets of fuzzy sets (see Eq. (2)). In this paper we introduce the notion of state
for classes of logically equivalent formulas of GΔ. Indeed we show that classes of
logically equivalent formulas of GΔ can be represented as real valued functions,
and that a deﬁnition of state over logically equivalent formulas can be given in
such a way that it corresponds to integrals of such functions with respect to a
c
⃝Springer International Publishing AG 2017
A. Antonucci et al. (Eds.): ECSQARU 2017, LNAI 10369, pp. 353–363, 2017.
DOI: 10.1007/978-3-319-61581-3 32

354
S. Aguzzoli et al.
measure over [0, 1]. One of the advantages of having Δ is that the functional
representation and the axiomatisation of states can be slightly simpliﬁed, w.r.t.
the one provided in [6] for G.
We further characterise states by combinatorial means, considering the dual
space of GΔ-algebras: such characterisation can be fruitfully adapted to other
logics, and in the last section we shall brieﬂy mention the case of Drastic
Product logic.
2
Algebraic Notions
We assume that the reader is acquainted with many-valued logics in H´ajek’s
sense, and with their algebraic semantics. We refer to [9,10] for any unexplained
notion. We recall that MTL is the logic, on the language {&, ∧, ∨, →, ¬, ⊥, ⊤},
of all left-continuous t-norms and their residua, and that its associated alge-
braic semantics in the sense of Blok and Pigozzi [8] is the variety MTL of
MTL-algebras, that is, prelinear, commutative, bounded, integral, residuated
lattices [9]. In an MTL-algebra A = (A, ∗, ⇒, ⊓, ⊔, ∼, 0, 1) the connectives &, →
, ∧, ∨, ¬, ⊥, ⊤are interpreted, respectively, by ∗, ⇒, ⊓, ⊔, ∼, 0, 1. Totally ordered
MTL-algebras are called MTL-chains. In every chain ⊓= min and ⊔= max.
A logic L is the extension of MTL via a set of axioms {ϕi}i∈I if and only if L
is the subvariety of MTL-algebras satisfying { ¯ϕi = 1}i∈I, where ¯ϕi is obtained
from ϕi by replacing the connectives with the corresponding operations, and
every propositional variable in ϕ with an individual variable.
G¨odel logic G is axiomatised as MTL plus ϕ →(ϕ&ϕ). The variety G of
G-algebras is axiomatised as MTL plus x ⇒(x∗x) = 1 (see [9]). The operations
of a G-chain are deﬁned as follows.
x ∗y = min{x, y}
x ⇒y =

1
if x ≤y,
y
otherwise
∼x =

1
if x = 0,
0
otherwise.
(1)
The logic GΔ [7] is obtained by expanding the language with a new unary con-
nective Δ. The corresponding variety GΔ is axiomatised as follows.
Δ(x) ⊔∼Δ(x) = 1.
(Δ1)
Δ(x ⊔y) ⇒(Δ(x) ⊔Δ(y)) = 1.
(Δ2)
Δ(x) ⇒x = 1.
(Δ3)
Δ(x) ⇒Δ(Δ(x)) = 1.
(Δ4)
Δ(x ⇒y) ⇒(Δ(x) ⇒Δ(y)) = 1.
(Δ5)
For every GΔ-chain, the operation Δ has the following semantics:
Δ(x) =

1
if x = 1,
0
otherwise.
(2)
GΔ is the variety generated by all the GΔ-chains. Moreover, it is singly generated
by the standard GΔ-chain [0, 1]Δ = ([0, 1], ∗, min, max, ⇒, ∼, 0, 1, Δ) where ∗=

Probability Measures in G¨odelΔ Logic
355
min, while ⇒and ∼are deﬁned as in Eq. (1). Since in G and in GΔ the operations
interpreting & and ∧always coincide, from now on we drop the ﬁrst one from
the signature.
Let A be an MTL algebra, then p ⊆A is a ﬁlter of A if for all y ∈A, if there
is x in p such that x ≤y then y ∈p, and x ∗y ∈p for all x, y ∈p. We call proper
the ﬁlters p such that p ̸= A. If A is a GΔ-algebra then a ﬁlter p of A is a ﬁlter
of its G¨odel reduct ¯
A further satisfying x ∈p implies Δx ∈p.
Filters and congruences of A are in bijection. Indeed, xθpy if and only if
(x ⇒y) ⊓(y ⇒x) ∈p, and pθ = {x ∈A | xθ1}. By abuse of notation we write
A/p to denote A/θp.
A ﬁlter p of A is prime if it is proper and for all x, y ∈A, either x ⇒y ∈p
or y ⇒x ∈p. The set Spec(A) of all prime ﬁlters of A ordered by reverse
inclusion is called the prime spectrum of A. The inclusion-maximal elements
of Spec(A) are the maximal ﬁlters of A, and they form the maximal spectrum
Max(A) ⊆Spec(A). For each p ∈Spec(A), A/p is a chain.
Proposition 1 ([2], Lemma 7.2). Every ﬁnite GΔ-algebra A is a direct pro-
duct of chains. That is, A ≃
p∈Max(A) A/p, and Max(A) = Spec(A).
We recall that in any lattice A an element a is join-irreducible if whenever
a = b ∨c, then a = b or a = c. In any ﬁnite lattice every element a is the join of
all join-irreducible elements below a. An element a covers an element b if b < a,
and for every c ∈A, if b ≤c ≤a, then either c = b or c = a.
3
Functional Representation
Two formulas ϕ and ψ over n many distinct variables x1, x2, . . . , xn are logi-
cally equivalent in GΔ iﬀboth ϕ →ψ and ψ →ϕ are GΔ tautologies. As is
well known, the Lindenbaum algebra formed by the set of all classes of logically
equivalent formulas over the set of variables {x1, . . . , xn} equipped with the oper-
ations inherited from the connectives, constitutes a GΔ-algebra, which in turn
is (isomorphic with) the free n-generated GΔ-algebra Fn(GΔ).
Since the algebra [0, 1]Δ singly generates the whole variety GΔ, from uni-
versal algebra we have that Fn(GΔ) is isomorphic with the subalgebra of the
algebra of all functions f : [0, 1]n
Δ →[0, 1]Δ generated by the projection func-
tions xi : (t1, . . . , tn) →ti, for all i ∈{1, 2, . . . , n}. To ﬁx notation, for each
formula ϕ over {x1, . . . , xn} we shall write ϕ for the corresponding element of
Fn(GΔ), considered as a function ϕ: [0, 1]n →[0, 1]. Moreover, we shall denote
each operation of Fn(GΔ) with the same symbol of the connective it interprets.
In this section we shall characterise the functions ϕ belonging to Fn(GΔ).
Let ≈be the binary relation on [0, 1]n deﬁned in the following way: given two
n-tuples u = (u1, · · · , un), v = (v1, · · · , vn) ∈[0, 1]n we set u ≈v if and only if
there is a permutation σ of {1, . . . , n} and a map ≺: {0, . . . , n} →{<, =} such
that (we write ≺i for ≺(i))
0 ≺0 uσ(1) ≺1 · · · ≺n−1 uσ(n) ≺n 1 iﬀ0 ≺0 vσ(1) ≺1 · · · ≺n−1 vσ(n) ≺n 1.
(3)

356
S. Aguzzoli et al.
The relation ≈is an equivalence relation. We denote by [u] the equivalence class
of u. The quotient set [0, 1]n/ ≈is hence a partition of [0, 1]n.
With each class [u], where 0 ≺0 uσ(1) ≺1 · · · ≺n−1 uσ(n) ≺n 1, we associate a
unique ordered partition ρu = Q1 < · · · < Qh (i.e., a partition equipped with a
total order among its blocks) of the set {⊥, x1, . . . , xn, ⊤} in the following way:
– ⊥∈Q1; ⊤∈Qh; h > 1;
– if ≺i is = then xσ(i) and xσ(i+1) belong to the same Qj;
– if ≺i is < and xσ(i) ∈Qj then xσ(i+1) ∈Qj+1.
We call such an ordered partition a G¨odel n-partition. There is a bijection
between G¨odel n-partitions and equivalence classes [u] ∈[0, 1]n/ ≈. If ρ = ρu is
a G¨odel n-partition, we denote by Dρ the associated equivalence class [u]. We
write Ωn for the set of all G¨odel n-partitions.
A n-variate GΔ-function is a function f : [0, 1]n →[0, 1] such that for every
u ∈[0, 1]n (equivalently, for any ρ ∈Ωn) the restriction of f to [u] (equivalently,
to Dρ) is either equal to 0, or to 1, or to a projection function xi.
Theorem 1. The elements of Fn(GΔ) are exactly the n-variate GΔ-functions.
Proof. An easy induction on the complexity of a formula ϕ over {x1, . . . , xn}
proves that ϕ is a GΔ-function.
To prove the other direction we start by deﬁning formulas whose associated
function is the characteristic function of the set [u] for all u ∈[0, 1]n. Let us
deﬁne the following derived connective:
x ◁y = Δ(x →y) ∧¬Δ(y →x).
Note that when interpreted in [0, 1] we have x ◁y = 1 if x < y and x ◁y = 0
otherwise. Let u = (u1, · · · , un) in [0, 1]n with 0 ≺0 uσ(1) ≺1 · · · ≺n−1 uσ(n) ≺n
1. To simplify notation, let us put xσ(0) = ⊥and xσ(n+1) = ⊤. Moreover, let
x ↔y denote (x →y) ∧(y →x). For any ρ = ρu ∈Ωn, consider the formula
χρ =
n

i=0
δi,
where
δi =

Δ(xσ(i) ↔xσ(i+1)) iﬀ≺i is =,
xσ(i) ◁xσ(i+1)
iﬀ≺i is < .
Then it is straightforward to check that χρ(v) = 1 iﬀv ≈u, while χρ(v) = 0
otherwise.
Let now f : [0, 1]n →[0, 1] be a GΔ-function. For each ρ ∈Ωn, let yρ be the
necessarily unique element of {⊥, x1, . . . , xn, ⊤} such that yρ coincides with f
over the whole of Dρ. Consider the formula
ϕ =

ρ∈Ωn
(χρ ∧yρ).

Probability Measures in G¨odelΔ Logic
357
Fix any point u ∈[0, 1]n. Then ϕ(u) coincides with χρ ∧yρ(u) for the unique
ρ ∈Ωn such that u ∈Dρ, since χτ(u) = 0 for all ρ ̸= τ ∈Ωn, while χρ(u) = 1.
Whence, ϕ(u) = yρ(u), that is ϕ(u) = f(u), since u ∈Dρ. We have proved
ϕ = f.
⊓⊔
4
States on Fn(GΔ)
In this section we introduce the notion of state over a ﬁnitely generated free GΔ-
algebra, and prove our main result, stating that integrals of elements of such
algebras with respect to Borel probability measures exactly correspond to our
notion of states.
Deﬁnition 1. A state on Fn(GΔ) is a function s: Fn(GΔ) →[0, 1] such that,
for every f, g ∈Fn(GΔ):
1. s(⊥) = 0, s(⊤) = 1;
2. s(f ∨g) = s(f) + s(g) −s(f ∧g);
3. If f ≤g then s(f) ≤s(g);
4. If f ≤g and s(g) = s(f) then s(Δ(g →f)) = 1.
Note that, as in the case of G¨odel logic [6], the following theorem shows that
Deﬁnition 1 provides an axiomatisation `a la Kolmogorov, where no explicit con-
ditions on the connectives ¬, →and Δ are required, apart from item 4, which
deals with the interaction of order, Δ and →(recall that ¬ϕ is ϕ →⊥).
Theorem 2. The following hold.
1. If s: Fn(GΔ) →[0, 1]n is a state, there exists a Borel probability measure μ
on [0, 1]n such that

[0,1]n f dμ = s(f), for every f ∈Fn(GΔ).
(4)
2. Viceversa, for any Borel probability measure μ on [0, 1]n, the function
s: Fn(GΔ) →[0, 1] deﬁned by (4) is a state.
Proof. We prove (1). Let s be a state, and consider a G¨odel n-partition ρ and
the region Dρ ⊆[0, 1]n. Throughout the proof we ﬁx x0 = 0 and xn+1 = 1.
For any ρ such that s(χρ) ̸= 0, we deﬁne the element zρ ∈[0, 1]n whose i-th
component zi
ρ is equal to
zi
ρ = s(xi ∧χρ)
s(χρ)
.
We claim that zρ ∈Dρ. Indeed consider i, j ∈{0, · · · , n + 1} and suppose ﬁrst
that for every element (t1, . . . , tn) ∈Dρ, ti = tj. Hence xi ∧χρ = xj ∧χρ and
zi
ρ = zj
ρ. On the other hand, if ti < tj for some i, j, then xi ∧χρ < xj ∧χρ and,
by 3. in Deﬁnition 1, s(xi ∧χρ) ≤s(xj ∧χρ). If it were s(xi ∧χρ) = s(xj ∧χρ), by

358
S. Aguzzoli et al.
4. in Deﬁnition 1 it would be the case that s(Δ((xj ∧χρ) →(xi ∧χρ))) = 1. This
is impossible by 1. in Deﬁnition 1, since (xj ∧χρ) = χρ and then Δ((xj ∧χρ) →
(xi ∧χρ)) = ⊥,
hence it must be that s(xi ∧χρ) < s(xj ∧χρ) and zi
ρ < zj
ρ. We can hence
conclude that zρ ∈Dρ.
We are ready to deﬁne the discrete Borel probability measure μ determined
by μ([0, 1]n\{zρ | ρ ∈Ωn}) = 0 and μ({zρ}) = s(χρ) for each ρ ∈Ωn.
If f ∈Fn(GΔ), we have:

[0,1]n f dμ =

ρ∈Ωn

Dρ
f dμ =

ρ∈Ωn
f(zρ)μ({zρ}) =

ρ∈Ωn
f(zρ)s(χρ).
By Theorem 1, f is a GΔ-function. Then on every region Dρ the function f is
equal to either 0 or 1 or a projection function xi. Let ρ(i) ∈{0, 1, · · · , n + 1} be
such that xρ(i) = f ↾Dρ. We hence have

ρ∈Ωn
f(zρ)s(χρ) =

ρ∈Ωn
zρ(i)
ρ
s(χρ) =

ρ∈Ωn
s(xρ(i) ∧χρ)
s(χρ)
s(χρ) =

ρ∈Ωn
s(xρ(i) ∧χρ).
Since, for ρ ̸= σ we have (xρ(i) ∧χρ) ∧(xσ(i) ∧χσ) = ⊥, by 2. in Deﬁnition 1
we have

ρ∈Ωn
s(xρ(i) ∧χρ) = s
⎛
⎝
ρ∈Ωn
(xρ(i) ∧χρ)
⎞
⎠= s(f).
We now prove (2). It is easy to check that the function s(f) =

[0,1]n f dμ
satisﬁes properties 1., 2. and 3. of Deﬁnition 1, so we focus on the last property.
Let f, g ∈Fn(GΔ) with f ≤g and

[0,1]n g dμ =

[0,1]n f dμ.
(5)
Let A = {x ∈[0, 1]n | f(x) = g(x)} and B = [0, 1]n\A = {x ∈[0, 1]n | f(x) <
g(x)}. We have

[0,1]n f dμ =

A
f dμ +

B
f dμ =

A
g dμ +

B
f dμ.
and

[0,1]n g dμ =

A
g dμ +

B
g dμ.
Whence, by (5),

B f dμ =

B g dμ. Since in B we have f < g it must be
μ(B) = 0, hence μ(A) = 1 and, since Δ(g →f)(x) = 1 for every x ∈A,

[0,1]n Δ(g →f) dμ =

A
Δ(g →f) dμ +

B
Δ(g →f) dμ = μ(A) = 1.
⊓⊔

Probability Measures in G¨odelΔ Logic
359
In words, ﬁxing a state on Fn(GΔ) precisely amounts to integrating GΔ-
functions of n variables with respect to an appropriate Borel probability measure
μ on [0, 1]n. The proof of the following corollary is omitted for lack of space.
Corollary 1. The states of Fn(GΔ) are precisely the convex combinations of
ﬁnitely many truth value assignments.
Example 3. For n = 2, the set of all G¨odel partitions Ω2 counts 11 elements.
Consider ρ1 = {0, x, y} < {1}, ρ2 = {0} < {x, y} < {1} and ρ3 = {0} <
{x} < {y} < {1}. Let s be the state on F2(GΔ) given by setting s(χρ1) = 1/3,
s(χρ2) = 1/6, s(χρ3) = 1/2, s(x ∧χρ2) = 1/12, s(x ∧χρ3) = 1/12, s(y ∧χρ3) =
1/6, s(χσ) = 0 for σ ̸∈{ρ1, ρ2, ρ3}; all the other values of s are determined
by the previous ones. Then we have three points zρ1 = (0, 0), zρ2 = (1/2, 1/2)
and zρ3 = (1/6, 1/3) on which we can deﬁne the discrete measure μ by setting
μ({zρ1}) = 1/3, μ({zρ2}) = 1/6 and μ({zρ3}) = 1/2. Consider now the GΔ-
function f that is equal to 1 over Dρ1, it is equal to 0 over Dρ2 and it is equal
to y on Dρ3 (the other values of f are not relevant to our example). Then
s(f) = s(χρ1 ∨(y ∧χρ3)) = s(χρ1) + s(y ∧χρ3) = 1
3 + 1
6 = 1
2
and

[0,1]2 fdμ =
3

i=1
f(zρi)μ({zρi}) = 1 · 1
3 + 0 · 1
6 + 1
3 · 1
2 = 1
2 = s(f).
5
A Dual Equivalence
In this section we recall from [2] a dual equivalence concerning ﬁnite GΔ-algebras
that will be useful for dealing with states with combinatorial tools.
The variety GΔ of GΔ-algebras and their homomorphisms form a category.
We write (GΔ)fin for the full subcategory of GΔ whose objects have ﬁnite car-
dinality. Authors in [2] introduce a dual equivalence between (GΔ)fin and a
suitable combinatorial category by adapting the well-known dual categorical
equivalence between ﬁnite G-algebras and ﬁnite forests (see [3,5] for details). In
this section we brieﬂy recall their results.
Lemma 1 ([2]). Let C and D be GΔ-chains, and let h : C →D be a homomor-
phism. Then h is injective.
Let h: A →
i∈I Ci be a homomorphism of G-algebras, where each Ci is a G-
chain. Then h is called chain-injective if, given each projection πj : 
i∈I Ci →Cj,
the homomorphism πj ◦h: A →Cj is injective.
By Lemma 1 each homomorphism h of GΔ-algebras is a chain-injective homo-
morphism between their G¨odel reducts. These observation allows to prove a dual
equivalence between (GΔ)fin and the combinatorial category we are going to
describe.

360
S. Aguzzoli et al.
Given a poset (P, ≤), a subset C of P is a subchain of P if it is totally
ordered by the restriction of ≤. A subset Q ⊆P is downward-closed if Q = ↓Q,
for ↓Q = {x ∈P | ∃y ∈Q, x ≤y}. Analogously, Q ⊆P is upward-closed if
Q = ↑Q, for ↑Q = {x ∈P | ∃y ∈Q, y ≤x}. Given a poset P which is a disjoint
union C1∪C2∪· · ·∪Cu of chains, we write C(P) for the multiset {C1, C2, . . . , Cu}.
Let MC be the category whose objects are ﬁnite multisets of (nonempty)
ﬁnite chains, and whose morphisms h: C →D, are deﬁned as follows. Display
C as {C1, . . . , Cm} and D as {D1, . . . , Dn}. Then h = {hi}m
i=1, where each hi is
an order preserving surjection hi : Ci ↠Dj for some j ∈{1, 2, . . . , n}.
Theorem 4 ([2]). The categories (GΔ)fin and MC are dually equivalent.
We remark that, for each A ∈(GΔ)fin, the poset Spec( ¯
A), that is, the prime
spectrum of the G-algebra reduct of A, ordered by reverse inclusion, is isomor-
phic with the poset of the join-irreducible elements of A ordered by restriction.
As a matter of fact, each prime ﬁlter p of ¯
A is generated by a join-irreducible
element a as p = {b ∈A | a ≤b}. On the other hand, each join-irreducible
element of A singly generates a prime ﬁlter of ¯
A. Recall also that in general
Max(A) = Spec(A) ̸= Spec( ¯
A), and equality between the two prime spectra
occurs if and only if A is a Boolean algebra. Further, it is clear that the poset
Spec( ¯
A) is the disjoint union of chains, as A is a direct product of chains by
Proposition 1.
The functor implementing one side of the dual equivalence is:
SpecΔ : (GΔ)fin →MC,
deﬁned on objects as SpecΔ(A) = C(Spec( ¯
A)), and on morphisms as follows. If
h : A →B then (SpecΔh) : SpecΔ(B) →SpecΔ(A) is given by (SpecΔh)i(p) =
h−1[p] ∩Ci for each p ∈Spec( ¯B) and each i ∈{1, 2, . . . , m}. The other side of
the dual equivalence is given by the functor
SubΔ : MC →(GΔ)fin,
deﬁned on objects by the following prescriptions. Given {C} ∈MC, deﬁne ΔC =
C and ΔD = ∅for each proper downward-closed subchain D ⊊C. For all
downward-closed subchains D1, D2 ⊆C, deﬁne D1 →D2 = C\↑(D1 \ D2) (that
is, D1 →D2 = C if D1 ⊆D2, and D1 →D2 = D2 otherwise). Further, deﬁne
∼D1 = C if D1 = ∅and ∼D1 = ∅otherwise. Then,
SubΔ(C) = ({D ⊆C | D = ↓D}, ∪, ∩, →, ∼, ∅, C, Δ).
Whence, for any C = {C1, C2, . . . , Cm} ∈MC, we deﬁne
SubΔ(C) =
m

i=1
SubΔ(Ci).
Given a morphism f : C →D in MC, to deﬁne the dual homomorphism
SubΔ(f) : SubΔ(D) →SubΔ(C) in (GΔ)fin, we recall that if C is {C1, . . . , Cm}

Probability Measures in G¨odelΔ Logic
361
and D is {D1, . . . , Dn}, then f = {fi}m
i=1 is composed by order preserving sur-
jections fi : Ci ↠Dj(i) for some j : {1, 2, . . . , m} →{1, 2, . . . , n}. Then, given
E = (E1, . . . , En) ∈SubΔ(D) we deﬁne (SubΔ(f))(E) = (Ci ∩f −1
i
[Ej(i)])m
i=1.
6
A Combinatorial Way to States
In this section we shall use the dual equivalence proved in Sect. 5, to formulate
states over Fn(GΔ) in a purely combinatorial way. The combinatorial notion
corresponding to state is the following deﬁniton of labeling. For every p, q ∈
SpecΔ Fn(GΔ) we write p ⋚q to mean that p and q are comparable, that is
p ≤q or q ≤p, in Spec(Fn(GΔ)). We shall use the same notation f ⋚g to
mean that two join-irreducible elements of Fn(GΔ) are comparable. For any
join-irreducible element g ∈Fn(GΔ), we shall write ⟨g⟩for the prime ﬁlter of
Fn(GΔ) generated by g.
Deﬁnition 2. A labeling l is a function l: SpecΔ Fn(GΔ) →[0, 1], such that
1. 
p∈SpecΔ Fn(GΔ) l(p) = 1;
2. If l(p) = 0 then l(q) = 0 for all q ⋚p.
We will show that labelings and states are in bijection. Moreover, labelings
can be used to compute states (compare with the analogous notion given for G-
algebras in [5]). For each f ∈Fn(GΔ) let J(f) be the set of all join-irreducible
elements g ∈Fn(GΔ) such that g ≤f. Note that f = 
g∈J(f) g. Moreover,
observe that J(Δf) = {g ∈J(Fn(GΔ)) | ∀h ⋚g, h ∈J(f)}.
Theorem 5. Let Sn be the collection of all states s: Fn(GΔ) →[0, 1], and let
Ln be the collection of all labelings l: SpecΔ Fn(GΔ) →[0, 1]. Then, the map
deﬁned for every formula ϕ over the set of variables {x1, . . . , xn} by
(S(l))(ϕ) =

g∈J(ϕ)
l(⟨g⟩)
is a bijective correspondence S : Ln →Sn.
Proof. Notice that for each labeling l ∈Ln the map S(l) clearly satisﬁes Deﬁni-
tion 1 (1), (2), (3). To prove Deﬁnition 1 (4), we observe that if f, g ∈Fn(GΔ) are
such that f ≤g and (S(l))(g) = (S(l))(f), then J(f) ⊆J(g), and l(⟨h⟩) = 0 for
any h ∈J(g)\J(f). Whence, by the deﬁnition of labeling, and the isomorphism
between the posets Spec(Fn(GΔ)) and J(Fn(GΔ)), we have l(⟨k⟩) = 0 for all
k ∈J(Fn(GΔ)) comparable with h. Now, (S(l))(Δ(g →f)) = 
h∈H l(⟨h⟩), for
H = {k ∈J(Fn(GΔ)) | ∀h ⋚k, h ̸∈↑(J(g)\J(f))}. Then (S(l))(Δ(g →f)) =
1−
k∈K l(⟨k⟩) for K = {k ∈J(Fn(GΔ)) | ∃h ⋚k, h ∈↑(J(g)\J(f))}. Whence,

k∈K l(⟨k⟩) = 0, and we conclude that (S(l))(Δ(g →f)) = 1, and S(l) maps
Ln to Sn.

362
S. Aguzzoli et al.
We now prove injectivity of S. If l1 ̸= l2 are two diﬀerent labelings, then there
is a join-irreducible element g such that l1(⟨g⟩) ̸= l2(⟨g⟩) hence (S(l1))(g) ̸=
(S(l2))(g) and S(l1) ̸= S(l2).
To prove surjectivity, we construct the map inverse to S. We deﬁne for every
s ∈Sn the following labeling. For any join-irreducible element g ∈Fn(GΔ) let
h ∈J(g)∪{⊥} be the unique element such that g covers h, whence J(g)\J(h) =
{g}. Then we set (L(s))(⟨g⟩) = s(g) −s(h). It is straightforward to check that
S(L(s)) = s and L(S(l)) = l.
⊓⊔
7
Drastic Product Algebras
Drastic Product algebras constitute the subvariety DP of MTL axiomatised by
x ⊔∼(x ∗x) = 1. Let MC⊤be the non-full subcategory of MC whose morphisms
h: C →D satisfy the following additional constraint: for each i = 1, 2, . . . , m,
if the target Dj of hi is not isomorphic with 1 = {∗}, then h−1
i (max Dj) =
{max Ci}.
Theorem 6 ([1]). MC⊤is dually equivalent to the category DPfin of ﬁnite DP
algebras and their homomorphisms.
The above theorem implies that the category of ﬁnite DP algebras and their
homomorphisms is equivalent to a non-full subcategory of ﬁnite GΔ-algebras
and their homomorphisms. Using this fact, we can adapt the results of Sect. 4
to axiomatise states over DP-algebras. Details will be given elsewhere.
References
1. Aguzzoli, S., Bianchi, M., Valota, D.: A note on drastic product logic. In: Laurent,
A., Strauss, O., Bouchon-Meunier, B., Yager, R.R. (eds.) IPMU 2014. CCIS, vol.
443, pp. 365–374. Springer, Cham (2014). doi:10.1007/978-3-319-08855-6 37
2. Aguzzoli, S., Codara, P.: Recursive formulas to compute coproducts of ﬁnite G¨odel
algebras and related structures. In: 2016 IEEE International Conference on Fuzzy
Systems (FUZZ-IEEE). pp. 201–208 (2016)
3. Aguzzoli, S., D’Antona, O.M., Marra, V.: Computing minimal axiomatizations in
G¨odel propositional logic. J. Log. Comput. 21, 791–812 (2011)
4. Aguzzoli, S., Gerla, B.: Probability measures in the logic of nilpotent minimum.
Stud. Log. 94(2), 151–176 (2010)
5. Aguzzoli, S., Gerla, B., Marra, V.: De Finetti’s no-Dutch-book criterion for G¨odel
logic. Stud. Logica 90, 25–41 (2008)
6. Aguzzoli, S., Gerla, B., Marra, V.: Defuzzifying formulas in G¨odel logic through
ﬁnitely additive measures. In: 2008 IEEE International Conference on Fuzzy Sys-
tems (IEEE World Congress on Computational Intelligence), pp. 1886–1893 (2008)
7. Baaz, M.: Inﬁnite-valued G¨odel logics with 0-1-projections and relativizations. In:
H´ajek, P. (ed.) G¨odel’96: Logical foundations of mathematics, computer science
and physics–Kurt G¨odel’s legacy, Brno, Czech Republic, August 1996, proceedings.
Lecture Notes in Logic, vol. 6, pp. 23–33. Springer-Verlag, Berlin (1996)

Probability Measures in G¨odelΔ Logic
363
8. Blok, W., Pigozzi, D.: Algebraizable logics, Memoirs of The American Mathemat-
ical Society, vol. 77. American Mathematical Society (1989)
9. Cintula, P., H´ajek, P., Noguera, C. (eds.): Handbook of Mathematical Fuzzy Logic,
vol. 1, 2, 3. College Publications, London (2011)
10. H´ajek, P.: Metamathematics of Fuzzy Logic, Trends in Logic, vol. 4. Kluwer
Academic Publishers, Dordrecht (1998)
11. Mundici, D.: Averaging the truth-value in Lukasiewicz logic. Stud. Logica 55(1),
113–127 (1995)

Fuzzy Weighted Attribute Combinations
Based Similarity Measures
Giulianella Coletti1, Davide Petturiti2, and Barbara Vantaggi3(B)
1 Dip. Matematica e Informatica, Universit`a di Perugia, Perugia, Italy
giulianella.coletti@unipg.it
2 Dip. Economia, Universit`a di Perugia, Perugia, Italy
davide.petturiti@unipg.it
3 Dip. S.B.A.I., Universit`a di Roma “La Sapienza”, Rome, Italy
barbara.vantaggi@sbai.uniroma1.it
Abstract. Some similarity measures for fuzzy subsets are introduced:
they are based on fuzzy set-theoretic operations and on a weight capac-
ity expressing the degree of contribution of each group of attributes.
For such measures, the properties of dominance and T-transitivity are
investigated.
Keywords: Fuzzy
subset ·
Capacity ·
Similarity
measure ·
T-
transitivity
1
Introduction
In many contexts, a similarity measure can be (loosely) seen as a mathemat-
ical tool to express quantitatively what is in common between two “objects”.
Similarity measures expressing the degree of similarity of objects are adopted
in many applications such as multi-criteria decision making, economics, ﬁnance,
information retrieval, psychology, automatic classiﬁcation, probability, statistics
and data mining. Almost all the proposed similarity measures present in the
literature take into account (at most) the signiﬁcance value of diﬀerent features
individually, disregarding their mutual inﬂuence. This is true both in the classic
(crisp) ambit, where each attribute can only be present or absent, as well as in
the fuzzy one, where any attribute can be present with a degree α ∈[0, 1].
On the other hand, in many ﬁelds (such as multi-criteria decision making
[1,9,10,14], multi-attribute utility theory [11], cooperative game theory [18],
text mining [16], to cite some) capacities and the Choquet integral are used to
model and evaluate the measure of a speciﬁc concept (such as utility, power,
coalition eﬀort), taking into account the signiﬁcance value of diﬀerent features
and their mutual (positive or negative) interactions. This is due to the fact that
a weight of importance is attached to every subset of features.
Our aim is to propose similarity measures able to consider weights which can
be interpreted as the “importance” of groups of attributes, in measuring simi-
larity. For this, starting from the approach proposed in [2], where only positive
c
⃝Springer International Publishing AG 2017
A. Antonucci et al. (Eds.): ECSQARU 2017, LNAI 10369, pp. 364–374, 2017.
DOI: 10.1007/978-3-319-61581-3 33

Fuzzy Weighted Attribute Combinations Based Similarity Measures
365
interactions are taken into account, we deﬁne similarity measures based on a
weight capacity and the Choquet integral, generalising the index proposed by
Jaccard [12]. For these measures, we limit to a ﬁnite universe of fuzzy attributes,
investigating dominance and T-transitivity properties, where T is a t-norm.
2
Preliminaries
We introduce capacities and brieﬂy recall some well-known notions in fuzzy mea-
sure theory and their related integrals useful in this paper. Let N = {1, . . . , n}
be a ﬁnite index set and denote with ℘(N) its power set. We call signiﬁcance
assessment a function σ : ℘(N) →R satisfying the following conditions:
(S1) σ(∅) = 0;
(S2) 
{i}⊆B⊆A σ(B) ≥0, for every A ∈℘(N) and every i ∈A.
Notice that requirement (S2) imposes, in particular, to assign a non-negative
weight to singletons. The function σ is then used to compute the weight capacity
μ : ℘(N) →[0, +∞) deﬁned for every A ∈℘(N) as:
μ(A) =

B⊆A
σ(B).
By Proposition 2 in [4] it immediately follows that μ is a capacity [5], i.e., it
satisﬁes:
(C1) μ(∅) = 0;
(C2) A ⊆B =⇒μ(A) ≤μ(B), for every A, B ∈℘(N).
In the case the signiﬁcance assessment σ fulﬁls the further normalization
condition 
A∈℘(N) σ(A) = 1, then μ is a normalized capacity, that is μ(N) = 1.
Given a weight capacity μ on ℘(N) and X ∈[0, 1]N, the Choquet integral of
X with respect to μ is deﬁned (see [8]) by
Cμ(X) =
n

i=1
[X(π(i)) −X(π(i −1))] μ({π(i), . . . , π(n)}),
where π is a permutation of N such that X(π(1)) ≤. . . ≤X(π(n)) and
X(π(0)) := 0. In particular, if X ∈{0, 1}N then X can be identiﬁed with a
subset of N (still denoted with X) and so Cμ(X) = μ(X).
In the particular case σ ranges in the set of non-negative real numbers, the
corresponding weight capacity μ is totally monotone, i.e., it satisﬁes, for every
n ≥2, the n-monotonicity condition, for every A1, . . . , An ∈℘(N),
μ
 n

i=1
Ai

≥

∅̸=I⊆{1,...,n}
(−1)|I|+1μ

i∈I
Ai

.
If further σ(A) = 0 for every A ∈℘(N) such that |A| > 1, then the corresponding
weight capacity μ is additive, i.e., for every A, B ∈℘(N) such that A ∩B = ∅,
μ(A ∪B) = μ(A) + μ(B). Weighted means are particular cases of Choquet
integrals for the case μ is additive.

366
G. Coletti et al.
3
Weighted Attribute Combinations Based Similarities
Here we assume that every object is described by a set of attributes indexed
by the ﬁnite set N = {1, . . . , n}, which can be only present or absent: any
object description is thus regarded as a subset of N, which is identiﬁed with its
indicator function, so, we simply denote it as a function X : N →{0, 1}. Denote
with C = {0, 1}N the set of all (crisp) object descriptions.
We start from the similarity measure proposed by Jaccard in [12]
SJ(X, Y ) =
|X ∩Y |
|X \ Y | + |Y \ X| + |X ∩Y | =
|X ∩Y |
|XΔY | + |X ∩Y | = |X ∩Y |
|X ∪Y |, (1)
where |Z| stands for the cardinality of the set Z and all the attributes are
considered equally important (or eﬀective) in the evaluation of the similarity
between two object descriptions.
The equalities in Eq. (1) continue to hold also if the cardinality measure
is replaced by the sum of positive weights (of indicator functions) attached to
each attribute (i.e., by the weighted mean) which quantify their “signiﬁcance”
in evaluating the similarity between two object descriptions.
As already discussed in multi-criteria decision making, taking into account
interactions among attributes can make the model more eﬀective. To reach this
aim, the generalisation of (1) using the weighted mean in place of set cardinality
is not suﬃcient. In fact, in order to consider weights satisfying (S1) and (S2)
for groups of attributes, we need to use a proper non-additive capacity.
Example 1. Let us consider apartments in New York described by the following
crisp attributes indexed by N = {1, 2, 3, 4}:
1: the apartment is located in a skyscraper;
2: the apartment has a terrace;
3: the apartment has a panoramic view;
4: the apartment is equipped with a lift;
and assign the following signiﬁcance assessment σ and the corresponding μ (we
remove braces and commas on subsets of N to save space):
℘(N) 1
2
3
4
12
13
14
23
24
34
123
124 134 234 1234
σ
0.3 0.2 0.3 0.2 0.4 −0.1 −0.1 −0.1 0
0
−0.1 0
0
0
0
μ
0.3 0.2 0.3 0.2 0.9 0.5
0.4
0.4
0.4 0.5 0.9
1
0.6
0.6
1
Let us consider the pairs (X, Y ) and (X′, Y ′) reported below:
Subset 1 2 3 4
X
1 0 1 0
Y
0 0 1 1
X′
1 0 1 1
Y ′
0 1 1 1
Subset 1 2 3 4
X ∩Y 0 0 1 0
X \ Y 1 0 0 0
Y \ X 0 0 0 1
X ∪Y 1 0 1 1
Subset
1 2 3 4
X′ ∩Y ′ 0 0 1 1
X′ \ Y ′ 1 0 0 0
Y ′ \ X′ 0 1 0 0
X ∪Y
1 1 1 1

Fuzzy Weighted Attribute Combinations Based Similarity Measures
367
By using the above μ it follows
μ(X ∩Y )
μ(X \ Y ) + μ(Y \ X) + μ(X ∩Y ) = 3
8 < 1
2 =
μ(X′ ∩Y ′)
μ(X′ \ Y ′) + μ(Y ′ \ X′) + μ(X′ ∩Y ′),
μ(X ∩Y )
μ(XΔY ) + μ(X ∩Y ) = 3
7 > 5
14 =
μ(X′ ∩Y ′)
μ(X′ΔY ′) + μ(X′ ∩Y ′),
μ(X ∩Y )
μ(X ∪Y ) = 1
2 = 1
2 = μ(X′ ∩Y ′)
μ(X′ ∪Y ′).
So, depending on the particular functional form chosen for (1) we reach com-
pletely diﬀerent similarity orderings between the pairs (X, Y ) and (X′, Y ′).
■
Then, the generalization of (1) to fuzzy subsets is not obvious. For that we
refer to the Choquet integral with respect to a non-necessarily additive measure.
A possible choice is to compute a Lp-norm attribute-wise and then apply the
Choquet integral to the vector of diﬀerences. Another possibility, as done in
what follows, is to apply the fuzzy set-theoretic operations attribute-wise and
then apply the Choquet integral.
Choosing the Choquet integral the equalities in Eq. (1) may not hold any-
more: diﬀerent choices of the expression of (1) can even invert the inequality of
a comparative degree of similarity between two pairs of object descriptions, as
shown in Example 1. For crisp sets the generalization through the Choquet inte-
gral leads to diﬀerent similarities if μ is not additive, but each of them satisﬁes the
maximality condition: for every X, Y ∈C it holds S(X, X) = S(Y, Y ) ≥S(X, Y ).
4
Fuzzy Weighted Attribute Combinations Based
Similarities
Now, we assume that every object is described by a set of attributes indexed by
the ﬁnite set N = {1, . . . , n}, and that each one can be present with a diﬀerent
degree of membership: any object description is thus regarded as a fuzzy subset
of N [17]. In order to avoid cumbersome notation, every fuzzy subset X of N
is identiﬁed with its membership function, so, we simply denote it as a function
X : N →[0, 1]. Denote with F = [0, 1]N the set of all possible fuzzy object
descriptions and still with C = {0, 1}N the subset of crisp object descriptions.
We consider a t-norm T together with its dual t-conorm S and the comple-
ment (·)c = 1−(·) to perform fuzzy set-theoretic operations. As usual (see [13]),
we denote the main t-norms and t-conorms, for every x, y ∈[0, 1], as
TM(x, y) = min{x, y},
TP (x, y) = x · y,
TL(x, y) = max{x + y −1, 0},
SM(x, y) = max{x, y},
SP (x, y) = x + y −x · y,
SL(x, y) = min{x + y, 1}.
For every X, Y ∈F, we deﬁne X ∩Y = T(X, Y ), X \ Y = T(X, Y c),
Y \ X = T(Y, Xc), XΔY = S(X \ Y, Y \ X) and X ∪Y = S(X, Y ), where all
operations are intended pointwise on the elements of N.

368
G. Coletti et al.
Diﬀerent deﬁnitions of similarities have been given for fuzzy subsets [3,6,7]
essentially based on the “common” and the “diﬀerent” parts of the compared
fuzzy subsets.
We introduce three classes of similarity measures Sμ
i : F2 →[0, 1], for i =
1, 2, 3, each parametrized by a weight capacity μ or, equivalently, by a signiﬁcance
assessment σ, deﬁned, for every X, Y ∈[0, 1]N, as:
Sμ
1 (X, Y ) =
Cμ(X ∩Y )
Cμ(X \ Y ) + Cμ(Y \ X) + Cμ(X ∩Y ),
(2)
Sμ
2 (X, Y ) =
Cμ(X ∩Y )
Cμ(XΔY ) + Cμ(X ∩Y ),
(3)
Sμ
3 (X, Y ) = Cμ(X ∩Y )
Cμ(X ∪Y ).
(4)
If the denominator (and so the numerator) of Sμ
i vanishes, we set Sμ
i (X, Y ) := 0
even if diﬀerent generalisations could be introduced by considering reﬁnements
of the capacity μ or better by considering conditional capacities (we omit this
discussion due to limit of space).
If μ is additive then the similarity Sμ
3 is a special case of that introduced in
[15] and coincides with the Jaccard similarity when μ is the Laplace measure
(discrete uniform measure). Notice that, under an additive μ, the similarity
measures Sμ
1 , Sμ
2 and Sμ
3 coincide on C2, but are generally diﬀerent on F2 \ C2.
The choice among the diﬀerent similarities could be based on the role played by
the operations between fuzzy sets (so, by the chosen t-norm) and that played by
the weight capacity: in Sμ
1 and Sμ
2 the role of the t-norm is more relevant than
in Sμ
3 .
Even if μ is additive, the maximality condition Sμ
i (X, X) ≥Sμ
i (X, Y ), for
i = 1, 2, may fail. For instance, when (TM, SM) or (TP , SP ) are taken to perform
fuzzy set-theoretic operations, it is suﬃcient to take a crisp set X and a proper
fuzzy set Y . Instead, when (TL, SL) are used, maximality fails by taking a crisp
set X and a proper fuzzy set Y pointwise less or equal than 1
2.
Due to the freedom on the choice of μ (or, equivalently, σ), in general there is
no dominance relation holding between Sμ
1 , Sμ
2 and Sμ
3 , as shown in the following
example.
Example 2. Let N = {1, 2, 3} and take the weight capacities μ1 and μ2 deﬁned
on ℘(N) as:
℘(N) ∅{1}
{2}
{3} {1, 2} {1, 3} {2, 3} N
μ1
0 0.1
0.1
0.1
0.2
0.2
0.2
1
μ2
0 0.25 0.25 0.5
0.5
0.5
0.5
1
Let T and S be any pair of dual t-norm and t-conorm and consider the crisp
subsets of N below

Fuzzy Weighted Attribute Combinations Based Similarity Measures
369
Fuzzy subset 1 2 3
X
0 1 1
Y
1 1 0
If we take the weight capacity μ1 then we get Cμ1(X∩Y ) = 0.1, Cμ1(X\Y ) =
0.1, Cμ1(Y \ X) = 0.1, Cμ1(XΔY ) = 0.2 and Cμ1(X ∪Y ) = 1, so, it holds
Sμ1
3 (X, Y ) = 0.1 < 0.3333 = Sμ1
1 (X, Y ) = Sμ1
2 (X, Y ).
On the other hand, if we take the weight capacity μ2 then we get Cμ2(X ∩
Y ) = 0.25, Cμ2(X \ Y ) = 0.5, Cμ2(Y \ X) = 0.25, Cμ2(XΔY ) = 0.5 and
Cμ2(X ∪Y ) = 1, so, it holds
Sμ2
1 (X, Y ) = Sμ2
3 (X, Y ) = 0.25 < 0.3333 = Sμ2
2 (X, Y ).
■
Restricting Sμ
1 , Sμ
2 and Sμ
3 on C2, if μ is superadditive, i.e., for every A, B ∈
℘(N) with A ∩B = ∅it holds
μ(A ∪B) ≥μ(A) + μ(B),
we have that Sμ
1 (X, Y ) ≥Sμ
2 (X, Y ) ≥Sμ
3 (X, Y ) for every X, Y ∈C. In analogy,
if μ is subadditive, i.e., for every A, B ∈℘(N) with A ∩B = ∅it holds
μ(A ∪B) ≤μ(A) + μ(B),
we have that Sμ
1 (X, Y ) ≤Sμ
2 (X, Y ) ≤Sμ
3 (X, Y ) for every X, Y ∈C.
Nevertheless, regarding Sμ
1 , Sμ
2 and Sμ
3 as functions on the whole F2, super-
additivity or subadditivity of μ do not determine any form of dominance as
shown in the following example.
Example 3. Let N = {1, 2, 3} and take the weight capacities μ1 and μ2 deﬁned
on ℘(N) as:
℘(N) ∅{1} {2} {3} {1, 2} {1, 3} {2, 3} N
μ1
0 0
0
0
0
0
0
1
μ2
0 1
1
1
1
1
1
1
which are easily seen to be, respectively, superadditive and subadditive (actu-
ally, they are totally monotone and totally alternating). This implies that
Sμ1
1 (X, Y ) ≥Sμ1
2 (X, Y ) ≥Sμ1
3 (X, Y ) and Sμ2
1 (X, Y ) ≤Sμ2
2 (X, Y ) ≤Sμ2
3 (X, Y ),
for every X, Y ∈C.
Note that Cμ1(X) =
min
i=1,...,3 X(i) and Cμ2(X) = max
i=1,...,3 X(i), for X ∈F.
Consider the fuzzy subsets of N below

370
G. Coletti et al.
Fuzzy subset 1
2
3
X
0.2 0.4 0.3
Y
0.9 0.7 0.8
If we take T = TM and S = SM, simple computations show that
Sμ1
1 (X, Y ) = 0.2222 < Sμ1
3 (X, Y ) = 0.2857 < Sμ1
2 (X, Y ) = 0.6666,
Sμ2
1 (X, Y ) = 0.2666 < Sμ2
3 (X, Y ) = 0.4444 < Sμ2
2 (X, Y ) = 0.5714.
An analogous situation happens if fuzzy set-theoretic operations are executed
taking T = TL and S = SL, since it holds
Sμ1
3 (X, Y ) = 0.1 < Sμ1
1 (X, Y ) = 0.25 < Sμ1
2 (X, Y ) = 1,
Sμ2
3 (X, Y ) = 0.1 < Sμ2
1 (X, Y ) = 0.125 < Sμ2
2 (X, Y ) = 1.
■
Now, we consider the T ′-transitivity of the similarity measures Sμ
1 , Sμ
2 and Sμ
3 ,
i.e., for every X, Y, Z ∈F,
Sμ
i (X, Z) ≥T ′(Sμ
i (X, Y ), Sμ
i (Y, Z)),
where T ′ is a t-norm possibly diﬀerent from the t-norm T used in the fuzzy
set-theoretic operations. In the relevant literature, diﬀerent authors maintain
that TM-transitivity is a too strong requirement [6,7], then weaker forms of
transitivity must be required (essentially choosing a diﬀerent t-norm).
The following example shows that the above measures are generally not T ′-
transitive, for any t-norm such that TL ≤T ′ ≤TM.
We recall that if a similarity measure is T ′-transitive for some t-norm TL ≤
T ′ ≤TM, then it is T ′′-transitive for any t-norm T ′′ such that TL ≤T ′′ ≤T ′ [7].
Example 4. Let N and μ1 as in Example 3 and take the fuzzy subsets of N
Fuzzy subset 1
2
3
X
0.47 0.87 0.95
Y
0.46 0.99 0.56
Z
0.98 0.23 0.21
Taking T = TM and S = SM to perform fuzzy set-theoretic operations, we
have
Sμ1
1 (X, Z) = 0.75,
Sμ1
1 (X, Y ) = 0.884615,
Sμ1
1 (Y, Z) = 0.875,
Sμ1
2 (X, Z) = 0.913043,
Sμ1
2 (X, Y ) = 0.978723,
Sμ1
2 (Y, Z) = 0.954545,
Sμ1
3 (X, Z) = 0.241379,
Sμ1
3 (X, Y ) = 0.978723,
Sμ1
3 (Y, Z) = 0.375,

Fuzzy Weighted Attribute Combinations Based Similarity Measures
371
so, for i = 1, 2, 3, we have that
Sμ1
i (X, Z) < TL(Sμ1
i (X, Y ), Sμ1
i (Y, Z)) ≤TM(Sμ1
i (X, Y ), Sμ1
i (Y, Z)).
■
Next we prove that if the weight capacity μ is additive, then the similarity
measure Sμ
3 is TL-transitive.
Proposition 1. If the weight capacity μ : ℘(N) →[0, +∞) is additive, then the
similarity measure Sμ
3 is TL-transitive.
Proof. For any X, Y, Z ∈[0, 1]N it is suﬃcient to show that
Sμ
3 (X, Z) + 1 ≥Sμ
3 (X, Y ) + Sμ
3 (Y, Z).
Note that
Sμ
3 (X, Y ) = Cμ(X ∩Y )
Cμ(X ∪Y ) ≤Cμ(X ∩Y ) + c
Cμ(X ∪Y ) + c
for any non-negative constant c, in particular, for c = Cμ(X∪Y ∪Z)−Cμ(X∪Y ).
Analogously,
Sμ
3 (Y, Z) = Cμ(Y ∩Z)
Cμ(Y ∪Z) ≤Cμ(Y ∩Z) + c′
Cμ(Y ∪Z) + c′
for c′ = Cμ(X ∪Y ∪Z) −Cμ(Y ∪Z).
Then,
Sμ
3 (X, Y ) + Sμ
3 (Y, Z) ≤Cμ(X ∩Y ) + c
Cμ(X ∪Y ) + c + Cμ(Y ∩Z) + c′
Cμ(Y ∪Z) + c′
= Cμ(X ∩Y ) + c
Cμ(X ∪Y ∪Z) + Cμ(Y ∩Z) + c′
Cμ(X ∪Y ∪Z)
≤Cμ(X ∩Y \ Z) + Cμ(X ∩Z) + c
Cμ(X ∪Z)
+ Cμ(Y ∩Z) + c′
Cμ(X ∪Z)
= 1 + Sμ
3 (X, Z).
□
5
A Paradigmatic Example
The following example is inspired to the main example in [9].
Example 5. We consider 3 students x, y, z evaluated with respect to 3 subjects:
mathematics (1), physics (2) and literature (3), whose ﬁnal marks are given on
a scale from 0 to 20:
The above evaluation vectors determine three fuzzy subsets of N = {1, 2, 3}
by rescaling the marks to range in [0, 1]:

372
G. Coletti et al.
Student 1
2
3
x
18 16 10
y
10 12 18
z
14 15 15
Fuzzy subset 1
2
3
X
0.9 0.8
0.5
Y
0.5 0.6
0.9
Z
0.7 0.75 0.75
℘(N) ∅{1}
{2}
{3} {1, 2} {1, 3} {2, 3} N
μ
0 0.45 0.45 0.3
0.5
0.9
0.9
1
It is common knowledge that “usually” students good at mathematics are
also good at physics, and vice versa. Thus, to weigh the subjects on which the
students are evaluated we use the capacity μ : ℘(N) →[0, 1] given below:
Notice that the capacity μ is neither superadditive nor subadditive since:
μ({1, 2}) = 0.5 < 0.45 + 0.45 = μ({1}) + μ({2}),
μ({1, 3}) = 0.9 > 0.45 + 0.3 = μ({1}) + μ({3}),
μ({2, 3}) = 0.5 > 0.45 + 0.3 = μ({2}) + μ({3}).
Taking T = TM and S = SM, the values of Sμ
1 , Sμ
2 and Sμ
3 are reported in
Table 1.
Thus, denoting with ≾i the weak order (with asymmetric part ≺i) induced
by the similarity measure Sμ
i on {X, Y, Z}2, for i = 1, 2, 3, we obtain:
(X, Y )
(Y, X) ≺1 (Y, Z)
(Z, Y ) ≺1 (X, Z)
(Z, X) ≺1 (Y, Y ) ≺1 (X, X) ≺1 (Z, Z),
(X, Y )
(Y, X) ≺2 (Y, Z)
(Z, Y ) ≺2 (X, Z)
(Z, X) ≺2 (Y, Y ) ≺2 (Z, Z) ≺2 (X, X),
(X, Y )
(Y, X) ≺3 (X, Z)
(Z, X) ≺3 (Y, Z)
(Z, Y ) ≺3
(X, X)
(Y, Y )
(Z, Z)
.
Table 1. Values of S1, S2 and S3 on {X, Y, Z}2
X
Y
Z
X 0.5538 0.4866 0.5298
Y 0.4866 0.5354 0.5281
Z 0.5298 0.5281 0.5775
X
Y
Z
X 0.7680 0.5266 0.6368
Y 0.5266 0.6974 0.6318
Z 0.6368 0.6318 0.7322
X
Y
Z
X
1
0.6124 0.7591
Y 0.6124
1
0.8034
Z 0.7591 0.8034
1

Fuzzy Weighted Attribute Combinations Based Similarity Measures
373
This shows that, generally, the three similarity measures induce diﬀerent weak
orders, moreover, disregarding reﬂexive pairs, Sμ
1 and Sμ
2 select X and Z as the
most similar, while Sμ
3 selects Y and Z.
■
6
Conclusions
The application of similarity measures whose evaluation is based on the Choquet
integral requires the prior identiﬁcation of a weight capacity μ or, equivalently, a
signiﬁcance assessment σ. The choice of μ or σ deeply impacts on the similarity
orderings induced by the proposed measures. The elicitation of μ or σ by a
ﬁeld expert seems to be the most “natural” procedure, in agreement to what
happens in multi-criteria decision analysis [9]. Nevertheless, in this context a
learning procedure in the line of that in [2] can be envisaged.
Acknowledgment. This work was partially supported by INdAM-GNAMPA through
the Project 2015 U2015/000418 and the Project 2016 U2016/000391 and by the Italian
Ministry of Education, University and Research, under grant 2010FP79LR 003.
References
1. Angilella, S., Greco, S., Lamantia, F., Matarazzo, B.: The application of fuzzy inte-
grals in multicriteria decision making. Eur. J. Oper. Res. 158(3), 734–744 (2004)
2. Baioletti, M., Coletti, G., Petturiti, D.: Weighted attribute combinations based
similarity measures. In: Greco, S., Bouchon-Meunier, B., Coletti, G., Fedrizzi,
M., Matarazzo, B., Yager, R.R. (eds.) IPMU 2012. CCIS, vol. 299, pp. 211–220.
Springer, Heidelberg (2012). doi:10.1007/978-3-642-31718-7 22
3. Bouchon-Meunier, B., Coletti, G., Lesot, M.-J., Rifqi, M.: Towards a conscious
choice of a fuzzy similarity measure: a qualitative point of view. In: H¨ullermeier,
E., Kruse, R., Hoﬀmann, F. (eds.) IPMU 2010. LNCS (LNAI), vol. 6178, pp. 1–10.
Springer, Heidelberg (2010). doi:10.1007/978-3-642-14049-5 1
4. Chateauneuf, A., Jaray, J.Y.: Some characterizations of lower probabilities and
other monotone capacities through the use of m¨obius inversion. Math. Soc. Sci.
17(3), 263–283 (1989)
5. Choquet, G.: Theory of capacities. Ann. Inst. Fourier 5, 131–295 (1953)
6. De Baets, B., Janssens, S., Meyer, H.D.: On the transitivity of a parametric family
of cardinality-based similarity measures. Int. J. Approximate Reasoning 50(1),
104–116 (2009)
7. De Baets, B., Meyer, H.D.: Transitivity-preserving fuzziﬁcation schemes for
cardinality-based similarity measures. Eur. J. Oper. Res. 160(3), 726–740 (2005)
8. Denneberg, D.: Non-Additive Measure and Integral, Series B: Mathematical and
Statistical Methods, vol. 27. Kluwer Academic Publishers, Dordrecht (1994)
9. Grabisch, M.: The application of fuzzy integrals in multicriteria decision making.
Eur. J. Oper. Res. 69(3), 279–298 (1995)
10. Grabisch, M.: Fuzzy integral in multicriteria decision making. Fuzzy Sets Syst.
89(3), 445–456 (1996)
11. Grabisch, M., Kojadinovic, I., Meyer, P.: A review of methods for capacity iden-
tiﬁcation in choquet integral based multi-attribute utility theory: applications of
the kappalab R package. Eur. J. Oper. Res. 186(2), 766–785 (2008)

374
G. Coletti et al.
12. Jaccard, P.: Nouvelles recherches sur la distribution ﬂorale. Bull. Soc. Vaud. Sci.
Nat. 44, 223–270 (1908)
13. Klement, E., Mesiar, R., Pap, E.: Triangualr Norms, vol. 8. Kluwer Academic
Publishers, Dordrecht (2000)
14. Marichal, J.: An axiomatic approach of the discrete choquet integral as a tool to
aggregate interacting criteria. IEEE Trans. Fuzzy Syst. 8(6), 800–807 (2000)
15. Scozzafava, R., Vantaggi, B.: Fuzzy inclusion and similarity through coherent con-
ditional probability. Fuzzy Sets Syst. 160(3), 292–305 (2009)
16. Wilbik, A., Keller, J.M., Alexander, G.: Similarity evaluation of sets of linguistic
summaries. Int. J. Intell. Syst. 27, 226–238 (2012)
17. Zadeh, L.A.: Fuzzy sets. Inf. Control 8, 338–353 (1965)
18. Yu, X., Zhang, Q.: An extension of cooperative fuzzy games. Fuzzy Sets Syst. 161,
1614–1634 (2010)

Online Fuzzy Temporal Operators for Complex
System Monitoring
Jean-Philippe Poli(B), Laurence Boudet, Bruno Espinosa,
and Laurence Cornez
CEA, LIST, Data Analysis and System Intelligence Laboratory,
91191 Gif-sur-Yvette cedex, France
{jean-philippe.poli,laurence.boudet,bruno.espinosa,
laurence.cornez}@cea.fr
Abstract. Online fuzzy expert systems can be used to process data and
event streams, providing a powerful way to handle their uncertainty and
their inaccuracy. Moreover, human experts can decide how to process the
streams with rules close to natural language. However, to extract high
level information from these streams, they need at least to describe the
temporal relations between the data or the events.
In this paper, we propose temporal operators which relies on the
mathematical deﬁnition of some base operators in order to character-
ize trends and drifts in complex systems. Formalizing temporal relations
allows experts to simply describe the behaviors of a system which lead
to a break down or an ineﬀective exploitation. We ﬁnally show an exper-
iment of those operators on wind turbines monitoring.
1
Introduction
Complex systems are now equipped with hundreds of sensors which deliver con-
tinuous signals. Sensors provide either measurements at a dynamic or constant
sampling rate (i.e. data streams, e.g. connected thermometers), either events
whenever they are detected (i.e. event streams, e.g. presence detectors). Such
streams are generally processed, ﬁltered and combined to get higher level infor-
mation. These operations can be applied to predictive maintenance of complex
systems.
Predictive maintenance consists in monitoring an engineering system in order
to detect changes in its exploitation and prevent damages. Having a continuous
report of in-service systems allows an optimal use of it, the avoidance of impor-
tant damages and early-stage failure detection. Moreover, it changes the organi-
zation of maintenance services by replacing scheduled and periodic maintenance
and by minimizing the involvement of operators.
Artiﬁcial intelligence plays an important role in predictive maintenance [4]
and provides system-speciﬁc solutions : signal processing and statistical learn-
ing techniques have been successfully applied to obtain a type of damage or
a type of risk. Predictive maintenance mainly relies on data from process sen-
sors (temperature, pressure, etc.) and test sensors (vibration, acoustic, humidity,
c
⃝Springer International Publishing AG 2017
A. Antonucci et al. (Eds.): ECSQARU 2017, LNAI 10369, pp. 375–384, 2017.
DOI: 10.1007/978-3-319-61581-3 34

376
J.-P. Poli et al.
etc.) [3]. In order to better handle the sensors inaccuracy and the uncertainty in
the assessment of the system’s state, fuzzy logic has been applied to predictive
maintenance [8,12].
Our work consists in developing an online fuzzy expert system which can
take data or event streams as input. The goal is to reinforce the expressivity
of such systems to let experts author their own rules with complex fuzzy rela-
tions. Gathering the knowledge of diﬀerent experts can be a suitable approach
to predictive maintenance, avoiding some diﬃculties of the techniques described
formerly:
– no past data are needed to build the models;
– the decision can be explained through the trace of activated rules.
In the case of predictive maintenance, the rules consist in detecting patterns
in time-series which lead to a damage. Numerous authors [1,2,11] state tempo-
ral relations are a prerequisite to describe such patterns. One can distinguish
diﬀerent approaches. On the one hand, fuzzy temporal relations [2,5,10] can
be used to describe the temporality of events but are not always relevant for
online causal reasoning. On the other hand, some papers suggest to linguisti-
cally describe time-series [6,7] using fuzzy natural logic, speciﬁcally on complete
time-series, i.e. in an oﬄine way.
In this article, we remind 3 base fuzzy temporal relations which are then com-
bined into more complex relations. The compositional paradigm we use allows
to create new intuitive relations because they combined simple operators. The
new operators are the ﬁrst of a series of temporal operators which can be used
to describe time-series. In our work, we make the following assumptions:
– sensors give correct timestamps: there is no uncertainty in the acquisition
timestamps, but we take into account the vagueness in the relations between
the timestamps;
– sensors values are fuzziﬁed to both manipulate linguistic terms and manage
their inaccuracy.
The article is organized as follows: the next section presents the previous
work and the notations. The new temporal operators are described in Sect. 3.
In Sect. 4, we describe their use by an application to wind turbine predictive
maintenance. Finally, Sect. 5 draws the conclusions and perspectives of this work.
2
Previous Work
In our previous work, we introduced a compositional paradigm which consists in
deriving specialized operators from base operators in the temporal domain [9].
In this paper, we take advantage from these operators to build new temporal
ones for online characterization of time-series.
The temporal operators use two concepts to deal with event streams [9]. On
the one hand, expiration is the faculty for a temporal expression to yell that its
value has expired and must be re-evaluated. On the other hand, they are applied

Online Fuzzy Temporal Operators for Complex System Monitoring
377
on a scope. A scope is a fuzzy set deﬁned on a temporal domain, anchored at
the present moment, and whose membership function gives the importance of
a moment in this temporal domain. For instance, Fig. 1.c shows such a scope
representing “the last 10 s”. Both concepts ensure a satisfying computational
cost and allow an online execution.
Let E be a fuzzy expression, eval(E, t) be the value of E at time t. Let S be
a fuzzy scope and µS its membership function. In the remainder of this paper,
we will use the following temporal operators:
– The occurrence operator which indicates if an expression has a degree of
fulﬁllment strictly greater than 0 throughout the scope :
Occ(E, S, tnow) =

t∈supp(S)
eval(E, t) ∧µS(t)
(1)
When its value is strictly greater than 0, it means that at least at one moment
of the scope, the operand expression has been observed. It is a disjunction
over all the moments ti in the scope of conjunctions of the operand value at
time ti and the value of the scope membership function for ti.
– The ratio operator which aggregates the diﬀerent degrees of fulﬁllment of the
operand expression E throughout a scope S:
Ratio(E, S, tnow) =

t∈supp(S) eval(E, t) ∧µS(t)

t∈supp(S) µS(t)
(2)
It aggregates the diﬀerent values of the operand E on the scope S, divided
by the area under the scope membership function. It is related to Zadeh’s
relative count applied on a fuzzy scope.
– The persistence operator which indicates if at each moment of S, the degree
of fulﬁllment of E is strictly greater than 0:
StrictPers(E, S, tnow) = ¬Occ(¬E, S, tnow).
(3)
It equals 0 if there exists a moment ti in the scope S such as eval(E, ti) = 0.
This is why we called it “strict”. To moderate its deﬁnition, we can either
replace the Occ operator by the Ratio inside its deﬁnition, or simply use
Ratio instead of StrictPers.
In the next section, we use these operators to deﬁne new temporal operators
to both characterize trends of time-series and to compare two of them. Adopting
an iterative approach, we ﬁrst deﬁne the following operators and we will add new
ones when are not suﬃcient anymore.
3
Signal Characterization Operators
To illustrate the behavior of the operators, we introduce some examples of input
signals and parameters we will use throughout this section.

378
J.-P. Poli et al.
1.a: Signal of Input1
1.b: Signal of Input2
1.c: Fuzzy scope for the
last 10 seconds
Fig. 1. Examples of two signals and a fuzzy scope
For the sake of comprehension, Fig. 1(a) and (b) show two simple simulated
signals. We will use these signals to illustrate the behavior of the operators and
in the Sect. 4, we will use more realistic signals.
In the remainder of this section, without loss of generality, the operators are
deﬁned upon the Ratio operator. As a consequence of the use of the Ratio oper-
ator, those operators are considered tolerant. Thus, if at some moment the input
signal is changing for a short while, the direct eﬀect of its change is smoothed.
If a more strict behavior is needed, it is possible to replace the Ratio by the
StrictPers operator.
3.1
Growth, Decline and Variation
In predictive maintenance, it is important to be able to characterize drifts of
some sensors, because it can lead to the detection of a damage. The goal here is
to monitor the growth or the decline of an input value with operators such as:
input ⟨adverb⟩decreases/increases throughout S.
where adverb is a fuzzy set which represents, for example, “slowly” or “signiﬁ-
cantly” and S is a fuzzy scope.
To compute a degree of fulﬁllment for such relations, saving all the values in
the scope is not necessary. We chose instead to compute the gradient between
the two last samples and then to characterize its direction with a fuzzy set corre-
sponding to the adverb. The fuzzy set is thus deﬁned on a quarter of the trigono-
metric circle (top-right quadrant for the growth and bottom-right quadrant for
the decline). Figures 2(a) and 3(a) show an example of membership functions for
adverbs “slowly” and “signiﬁcantly” applied respectively to the decline and the
growth operator.
To aggregate the characterizations of the gradient over the scope, we can use
the Ratio. Thus, the Decreases operator can be deﬁned as:
Decreases(I, S, µg, tnow) = Ratio(µg(grad(I, tnow)), S, tnow)
(4)
where I is the real input of the system whose values change, grad is the direction
of the gradient, and µg is the membership function of the adverb fuzzy set.

Online Fuzzy Temporal Operators for Complex System Monitoring
379
-pi/2 -pi/3 -pi/6
0
pi/6 pi/3 pi/2
rad
0
0.2
0.4
0.6
0.8
1
fuzzy value
slowly
significantly
2.a: Examples of “slowly” and “signiﬁ-
cantly” membership functions
2.b: “Input1
signiﬁcantly
decreases
throughout the last 10 seconds”
Fig. 2. Examples of membership functions for the adverbs of the Decreases operator
and result on Input 1
-pi/2 -pi/3 -pi/6
0
pi/6 pi/3 pi/2
rad
0
0.2
0.4
0.6
0.8
1
fuzzy value
slowly
significantly
3.a: Examples of “slowly” and “signiﬁ-
cantly” membership functions
3.b: “Input1
signiﬁcantly
increases
throughout the last 10 seconds”
Fig. 3. Examples of membership functions for the adverbs of the Increases operator
and result on Input 1
The Increases operator only diﬀers from the Decreases operator because of
the deﬁnition domain and the membership function of the adverb fuzzy set.
Figures 2(b) and 3(b) show respectively the result of operators Decreases
and Increases on the ﬁrst input whose signal is shown in Fig. 1a.
In a similar way, it is useful to be able to tell that the value of an input
remains stable over time, with an operator like:
input varies ⟨adverb⟩throughout S
where adverb is a fuzzy set which represents, for instance, “fewly” or “highly”.
The deﬁnition of the V aries operator is based on the variance of its signal over
S and on a fuzzy set which deﬁnes the adverb by characterizing the variance.

380
J.-P. Poli et al.
0
100
200
300
400
500
0
0.2
0.4
0.6
0.8
1
fuzzy value
fewly
moderately
highly
4.a: Examples of “fewly”,
“moderately”
and
“highly”
membership
functions
4.b: “Input1 varies fewly
throughout
the
last
10
seconds”
4.c: “Input1 varies highly
throughout
the
last
10
seconds”
Fig. 4. Examples of membership functions for the adverbs of the V aries operator and
results on Input 1
The V aries operator is deﬁned by:
V aries(I, S, µv, tnow) = Ratio(µv(V ar(I, supp(S))), S, tnow)
(5)
where I is an input of the system whose value changes, V ar is the variance of
the signal I(t) over S and µv is the membership function of the adverb fuzzy set.
Figure 4(b) and (c) show the results of the V aries operator on the ﬁrst input
(see Fig. 1a), using respectively the adverbs “fewly” and “highly” described in
Fig. 4a.
3.2
Comparison
The last family of operators in this article concerns comparison between two
input values throughout a scope; one of them can be a ﬁxed value, for instance
a threshold. For instance, an expert may want to express that the signal of an
input is extremely less than another value:
input1 is ⟨adverb⟩less/greater/close than/to input2 throughout S.
The idea behind these operators is to compare at each time the two values
and to characterize the diﬀerence between them with a fuzzy set (the adverb).
Then, we aggregate the point-to-point comparisons with the Ratio operator.
Thus, we can deﬁne LessThan, GreaterThan, CloseTo as:
LessThan(I1, I2, S, µlt, tnow) = Ratio(µlt(I1(tnow) −I2(tnow)), S, tnow)
(6)
GreaterThan(I1, I2, S, µgt, tnow) = Ratio(µgt(I1(tnow) −I2(tnow)), S, tnow)
(7)
ClosteTo(I1, I2, S, µct, tnow) = Ratio(µct(I1(tnow) −I2(tnow)), S, tnow)
(8)
where µlt, µgt and µct are the membership functions of the adverb fuzzy set
which characterizes the diﬀerence between the two signals I1(t) et I2(t). The
operators diﬀer by the deﬁnition of the adverb fuzzy set.
Figure 5b shows the application of the GreaterThan operator on the input
signals shown in Fig. 1(a) and (b) with the adverb “much”(Fig. 5a).

Online Fuzzy Temporal Operators for Complex System Monitoring
381
0
10
20
30
40
50
0
0.2
0.4
0.6
0.8
1
fuzzy value
much
5.a: Example
of
“much”
membership
function
for
a
comparison
with
GreaterThan
5.b:
“Input1
is
much
greater
than
input2
throughout
the
last
10
seconds”
Fig. 5. Example of membership function for the adverb of the GreaterThan operator
and result on Input 1 and Input 2
4
Application to a Drift Detection
The goal of the presented work is to apply fuzzy expert systems to predictive
maintenance of complex systems. As illustration, we developed a speciﬁc soft-
ware for wind turbines. Figure 6 show some screenshots of our tool. It provides
an overview of the system (Fig. 6a) and can locate with a circle the suspected
default. The tiles on the left indicate the state of each sub-system of the wind
turbine : a green tile indicates it is fully functional while a red tile indicates
a critical state. By clicking on a tile, it is possible to access a more detailed
view (Fig. 6b) with the signals, the output of the fuzzy expert system, and the
rules with their activation which give an explanation of the decision contrarily
to other approaches.
In this paper, we focus on the characterization of one of the sub-systems: the
rotor-side multicellular converter. It occasionally suﬀers from drifts which are
clues that the energy production is not optimal. It consists of serial cells, each
one containing two switches with complementary values. The combination of the
6.a: Screenshot
of
the
system
overview
6.b: Screenshot of the detailed view
Fig. 6. Screenshots of the application for windturbines.

382
J.-P. Poli et al.
values of all the switches in the converter deﬁnes a “mode”. Among the other
variables, the dynamics of the converter is also described by V Ci which is the
ﬂoating voltage of the capacitors Ci of each cell. An instance of a controlled drift
of V Ci is shown in Fig. 7a. According to the mode, the drift can be detected or
not. It results in the computation of the new signal V Ci residuals by subtract-
ing the mean reference value to V Ci according to the mode as deﬁned in [13]
(Fig. 7b). Then, we deﬁned a rule base for detecting such a drift composed of:
– First, rules for deﬁning the nominal values of the system. To compute that, we
wait for a steady state during at least 20 s and we compare the actual values
of the amplitude of V Ci residuals to the values provided by the constructor.
– Then, rules for monitoring a drift and, according to its importance and its
duration, to yield a suitable level of alarm.
Figure 8 show the membership functions used to compare the amplitude of
V C1 residuals (Fig. 7c) to its reference value and diﬀerent expressions computed
to detect the drift. Once the steady state has been observed, the expression
verifying that the amplitude of V Ci residuals is very close to the reference value
(Fig. 8b) is associated with a null alert (Fig. 9a), and the one verifying that it
is much higher than the reference value (Fig. 8c) is associated with a high alert.
The defuzziﬁed value of the alert is shown by a black curve in Fig. 9b. The drift
is applied between 40 and 80 s. It begins to be detected after only 15 s which
is the delay necessary to compute the Ratio operator on the chosen temporal
scope. Then, the alert value gradually rises until it reaches its maximum value
40 s afterward.
Monitoring a system with fuzzy temporal rules enables both to estimate a
continuous value of the output (an alert here) and to know which rules are
activated and led to the results. All the membership functions used as well
as temporal scopes have to be chosen according to the application in order to
characterize a normal or abnormal behavior of each sub-system. They can be
learned when suﬃcient data of sub-systems are available.
7.a: V C1 values
7.b: V C1 residuals
7.c: Amplitude
of
V C1
residuals over 20 seconds
Fig. 7. Input example for ﬂoating voltage of capacitor C1

Online Fuzzy Temporal Operators for Complex System Monitoring
383
-40
-20
0
20
40
0
0.2
0.4
0.6
0.8
1
fuzzy value
very (close to)
slightly (greater than)
much (greater than)
8.a:
Membership
func-
tions
for
comparing
amplitudes of V C1 resid-
uals
to
the
reference
value
8.b:  Amplitude of
V C1
residuals is very close to
reference value during the
last 20 seconds”
8.c:  Amplitude
of
V C1
residuals is much greater
than the reference value
during the last 20 seconds”
Fig. 8. Examples of membership functions for comparing the amplitude of V C1 resid-
uals to the reference value and results of comparison operators
-0.5
0
0.5
1
1.5
0
0.2
0.4
0.6
0.8
1
null
low
high
9.a: Membership functions for
output  alert”
9.b: V C1 signal (left-hand axis) and defuzziﬁed
value of a drift alert between 0 and 1 (right-hand
axis) superimposed
Fig. 9. Example of membership functions for alerting a drift detection and application
of detection rules on V C1 signal
5
Conclusion
In this article, we use a compositional paradigm to build new temporal operators
to characterize the kinetics of input values. From simple and intuitive operators
like the ratio and the persistence, the temporal aspect is easily handled. These
operators can take into account both the temporal uncertainty and the vagueness
of the relation between the values.
With such operators, online fuzzy expert systems can play an important
role in predictive maintenance or health monitoring. Experts can describe their
knowledge about the systems and describe the clues which lead to damage detec-
tion from sensors signals. The decision making process can then be justiﬁed to
the user by tracing activated rules. Moreover, such expert systems are indepen-
dent of the system on which they are applied, contrary to statistical models
which are system-dependent.

384
J.-P. Poli et al.
The perspectives of our work is to formalize more operators which are suitable
for predictive maintenance, like online operators to characterize the seasonality
or the periodicity of time-series.
References
1. Barro, S., Bugar´ın, A., Cari˜nena, P., D´ıaz-Hermida, F., Mucientes, M.: Fuzzy tem-
poral rule-based systems: new challenges. In: Actas del XIV Congreso Espa˜nol
sobre Tecnolog´ıas y L´ogica Fuzzy (ESTYLF), pp. 507–514, Langreo, Spain (2008)
2. Dubois, D., Hadj Ali, A., Prade, H.: Fuzziness and uncertainty in temporal rea-
soning. J. Univ. Comput. Sci. 9(9), 1168–1194 (2003)
3. Hashemian, H.M., Bean, W.C.: State-of-the-art predictive maintenance techniques.
IEEE Trans. Instrum. Measur. 60(10), 3480–3492 (2011)
4. Kobbacy, K.A.H.: Artiﬁcial Intelligence in Maintenance, pp. 209–231. Springer,
London (2008)
5. Manaf, N.A.A., Beikzadeh, M.R.: Crisp-fuzzy representation of Allen’s tempo-
ral logic. In: Proceedings of the 25th Conference on Proceedings of the 25th
IASTED International Multi-Conference: Artiﬁcial Intelligence and Applications,
AIAP 2007, pp. 174–179. ACTA Press, Anaheim (2007)
6. Moyse, G., Lesot, M.J.: Linguistic summaries of locally periodic time series. Fuzzy
Sets Syst. 285, 94–117 (2016). Special Issue on Linguistic Description of Time
Series
7. Nov´ak, V.: Linguistic characterization of time series. Fuzzy Sets Syst. 285, 52–72
(2016). Special Issue on Linguistic Description of Time Series
8. Pereira, R.R., da Silva, V.A.D., Brito, J.N., Nolasco, J.D.: On-line monitoring
induction motors by fuzzy logic: a study for predictive maintenance operators. In:
2016 12th International Conference on Natural Computation, Fuzzy Systems and
Knowledge Discovery (ICNC-FSKD), pp. 1341–1346, August 2016
9. Poli, J.P., Boudet, L., Mercier, D.: Online temporal reasoning for event and data
streams processing. In: FUZZ-IEEE 2016, pp. 2257–2264, July 2016
10. Schockaert, S., De Cock, M., Kerre, E.E.: Fuzzifying Allen’s temporal interval
relations. Trans. Fuzzy Syst. 16(2), 517–533 (2008)
11. Schockaert, S., Cock, M.D., Kerre, E.: Reasoning About Fuzzy Temporal and Spa-
tial Information from the Web. Intelligent Information Systems, vol. 3. World Sci-
entiﬁc, Singapore (2010)
12. da Silva Vicente, S.A., Fujimoto, R.Y., Padovese, L.R.: Rolling bearing fault diag-
nostic system using fuzzy logic. In: 10th IEEE International Conference on Fuzzy
Systems, vol. 2, pp. 816–819, December 2001. vol. 3
13. Toubakh, H., Sayed-Mouchaweh, M.: Hybrid dynamic classiﬁer for drift-like fault
diagnosis in a class of hybrid dynamic systems: application to wind turbine con-
verters. Neurocomputing 171, 1496–1516 (2016)

Logics

Complexity of Model Checking
for Cardinality-Based Belief Revision Operators
Nadia Creignou1(B), Ra¨ıda Ktari2, and Odile Papini1
1 Aix-Marseille Universit´e, CNRS, LIF, LSIS, Marseille, France
{nadia.creignou,odile.papini}@univ-amu.fr
2 University of Sfax, ISIMS, Sfax, Tunisia
raida.ktari@isims.usf.tn
Abstract. This paper deals with the complexity of model checking
for belief base revision. We extend the study initiated by Liberatore
& Schaerf and introduce two new belief base revision operators stem-
ming from consistent subbases maximal with respect to cardinality. We
establish the complexity of the model checking problem for various oper-
ators within the framework of propositional logic as well as in the Horn
fragment.
Keywords: Belief revision · Complexity · Model checking · Maximal
cardinality
1
Introduction
Belief revision is an important issue in artiﬁcial intelligence, which consists in
restoring consistency, keeping new information while modifying as little as pos-
sible the agent’s initial beliefs. These principles have been formalized in terms of
postulates (AGM postulates) [1] and numerous operators have been proposed in
the literature, which are classiﬁed according to two points of view, semantic [12]
and syntactic [2,3,10,11,13,18,21]. While early work mainly aimed at deﬁning
appropriate semantics for revision, some researchers also investigated the compu-
tational complexity of reasoning with the operators introduced in the literature.
First works in this direction [4,7,15,16] dealt with the inference problem. Given
a set of beliefs, new information and a query (propositional formula), the infer-
ence problem consists in deciding whether the query is a logical consequence
of the revised set of beliefs. Liberatore and Schaerf [14] proposed to consider
another problem, model checking. Given a set of beliefs and new information,
it consists in deciding whether an interpretation is a model of the set of revised
beliefs. They advocated that studying the complexity of model checking is very
important since this problem is the most basic computational task in the setting
of model-based knowledge representation and that the succinctness of a knowl-
edge representation formalism is related to the complexity of model checking.
This work has received support from the French Agence Nationale de la Recherche,
ASPIQ project reference ANR-12-BS02-0003.
c
⃝Springer International Publishing AG 2017
A. Antonucci et al. (Eds.): ECSQARU 2017, LNAI 10369, pp. 387–397, 2017.
DOI: 10.1007/978-3-319-61581-3 35

388
N. Creignou et al.
Liberatore and Schaerf focused on syntactic operators based on consistent sub-
bases maximal with respect to set inclusion, in particular Ginsberg’s operator
[10] and Widtio operator [21]. In this paper we focus on two operators that are
similar to Ginsberg’s one and Widtio, but which use set cardinality instead of
set inclusion as maximality criterion. We also generalize these two operators to
stratiﬁed belief bases.
We present all these operators within a uniﬁed framework. We then study the
complexity of the model checking problem for each of them within the proposi-
tional framework, as well as within the Horn fragment. We thus obtain a syn-
thetic view of the impact of diﬀerent strategies and two diﬀerent maximality
criteria (set inclusion and cardinality) on the complexity of the problem, see
Table 1. From a computational complexity perspective, maybe surprisingly, the
complexity of revision operators based on maximal cardinality can be lower than
the complexity of similar revision operators based on set inclusion.
2
Preliminaries
Notations. We assume familiarity with the basics of propositional logic. We
remind that a literal is an atom (positive literal) or the negation of an atom
(negative literal). Let A be a set of atoms, Lit(A) denotes the set of literals over
A. A clause is a disjunction of literals. We say that a formula is in CNF if it is a
conjunction of clauses. A formula is called Horn if it is in CNF and in each clause
at most one literal is positive. A formula is called Krom if it is in CNF and each
clause has at most two literals. It is convenient to identify any truth assignment
with the set of variables that are true in this assignment. It is thus possible to
consider the cardinality of a model of a formula. Let ϕ be a formula, we denote
by Mod(ϕ) the set of models of ϕ. A formula ψ is a logical consequence of ϕ,
denoted by ϕ |= ψ, if Mod(ϕ) ⊆Mod(ψ), and the two formulas are equivalent,
denoted by ϕ ≡ψ, if Mod(ϕ) = Mod(ψ).
Let B be a ﬁnite set of propositional formulas, B = {ϕ1, ϕ2, . . . , ϕn} is iden-
tiﬁed to  B the conjunction of its formulas, ϕ1 ∧ϕ2 ∧. . . ∧ϕn. Given a family
of ﬁnite sets of formulas W = {B1, . . . , Bp}, we use
p
i=1

Bi for
p
i=1

ϕ∈Bi
ϕ.
Complexity Classes. The classes P and NP are the classes of decision problems
solvable in deterministic resp. non deterministic polynomial time. The class coNP
is the class of problems whose complementary is in NP [17]. An oracle for a
complexity class C is an entity capable of solving any problem in the class C,
it is simply a “black box” that is able to decide for any instance of a given
computational problem from C whether it is a positive instance or not. We
write PC (resp. NPC) for the class of decision problems that can be decided
by a deterministic (resp. non-deterministic) Turing machine in polynomial time
using an oracle for the class C. Stockmeyer inductively deﬁned the polynomial
hierarchy, where the ﬁrst level consists of the P, NP and coNP classes [19].
Within this hierarchy we particularly use the classes of the second level, i.e.

Complexity of Model Checking for Cardinality-Based Belief Revision
389
Σ2P = NPNP, Δ2P = PNP. We also use the class Θ2P = PNP[log(n)], introduced
by Wagner in [20], which is a sub-class of Δ2P. The problems of Θ2P are those
of Δ2P that can be solved in polynomial time with only a logarithmic number
of calls to an NP-oracle.
3
Belief Base Revision
A formula-based (syntactic) revision operator, denoted by ∗, is a function that
takes a belief base B and a formula μ representing new information as input
and returns a new belief base B ∗μ. Many formula-based operators stem from
W(B, μ), the set of maximal subbases of B consistent with μ. They then make
use of this set to deﬁne the revised belief base according to a given strategy. The
maximality criterion as well as the strategy can vary.
In the literature maximality was ﬁrst considered in terms of set inclusion,
and thus the following set was considered:
W⊆(B, μ) = {B1 ⊆B |

B1 ̸|= ¬μ and for all B2 s. t. B1 ⊂B2 ⊆B,

B2 |= ¬μ}.
We can then consider two diﬀerent strategies. The ﬁrst one considers that
all maximal subbases are equally plausible. The second one is more drastic and
stems from the intersection of consistent maximal subbases, i.e. it only keeps
beliefs that are not questioned. Thus, we obtain two well-known operators,
namely Ginsberg’s operator, ∗G, [10] and Widtio operator, ∗wid, [21]:
B ∗G μ =

B′∈W⊆(B,µ)

(B′ ∪{μ}) and B ∗wid μ =


B′∈W⊆(B,µ)
(B′ ∪{μ}).
We focus here on maximality deﬁned in terms of cardinality. So, we consider
the set of consistent subbases maximal w.r.t. cardinality:
Wcard(B, µ) = {B1 ⊆B |

B1 ̸|= ¬µ and for all B2 ⊆B s. t. |B1| < |B2|,

B2 |= ¬µ}.
A ﬁrst operator using this criterion was deﬁned in [2] named RSR 1. We
keep this name and suﬃx it by G and W to deﬁne two operators, RSRG [2] and
RSRW, similar respectively to Ginsberg’s and Widtio one:
B ∗RSRG μ =

B′∈Wcard (B,µ)

(B′ ∪{μ}) and B ∗RSRW μ =


B′∈Wcard (B,µ)
B′ ∪{μ}.
1 The notation RSR comes from the expression “Removed Sets Revision”.

390
N. Creignou et al.
Example 1. Consider the belief base B = {a →¬b, b, b →c, c →¬a, b →d, d →
¬a, ¬d →c}, and new information μ = a.
Wcard(B, μ) = {{a →¬b, b →c, c →¬a, b →d, d →¬a};
{a →¬b, b →c, c →¬a, b →d, ¬d →c};
{a →¬b, b →c, b →d, d →¬a, ¬d →c}}
Observe that Wcard(B, μ) ̸= W⊆(B, μ) (since W⊆(B, μ) contains for instance
{b, c →¬a, d →¬a}, which is not cardinality-maximal). On the one hand we get
B ∗RSRG μ ≡(a ∧¬b ∧¬c ∧¬d) ∨(a ∧¬b ∧¬c ∧d) ∨(a ∧¬b ∧c ∧¬d)
≡(a ∧¬b) ∧¬(c ∧d).
On the other hand, since 
B′∈Wcard(B,μ) B′ = {a →¬b, b →c, b →d}, we
have
B ∗RSRW μ ≡a ∧(a →¬b) ∧(b →c) ∧(b →d) ≡a ∧¬b.
The operators RSRG and RSRW may be extended to stratiﬁed belief bases. A
stratiﬁed belief base B = (S1, ..., Sn) is provided by a partition of the belief base
in strata Si (1 ≤i ≤n) representing priorities between formulas. Let X ⊆B
be a set of formulas, we deﬁne trace(X, B) by a tuple of integers as follows:
trace(X, B) = (|X ∩S1|, ..., |X ∩Sn|). The usual lexicographic order over traces,
denoted by ≤lex, provides a new maximality criterion for consistent subbases.
We deﬁne the set of consistent subbases maximal w.r.t. this crite-
rion by Wtrace(B, μ)
=
{B1
⊆
B
|
 B1
̸|=
¬μ and for all B2
⊆
B s. t. trace(B1, B) <lex trace(B2, B),  B2 |= ¬μ}. Observe that all elements
of Wtrace(B, μ) have same trace, denoted by Tracemax(B, μ). The operators
PRSRG [2,3] and PRSRW are thus deﬁned by:
B ∗PRSRG μ =

B′∈Wtrace(B,µ)

(B′ ∪{μ}), B ∗PRSRW μ =


B′∈Wtrace(B,µ)
(B′ ∪{μ}).
Note that all these formula-based operators are sensitive to the syntactic
form of the belief base B. While it is well-known that Ginsberg’s and Widtio
operators satisfy respectively the ﬁrst seven and the ﬁrst six AGM postulates,
it is proven in [2] that RSRG satisﬁes all of them when extended to belief set
revision.
4
Complexity of Model Checking
In this section we study the computational complexity of the following decision
problem according to the considered belief revision operator ∗.
Problem :
Model-Checking(∗)
Instance :
B a belief base, μ a formula, m an interpretation
Question :
m |= B ∗μ ?

Complexity of Model Checking for Cardinality-Based Belief Revision
391
4.1
Complexity Results for the Operators ∗G, ∗RSRG and ∗PRSRG
Complexity of model checking has been studied in [14] by Liberatore and Schaerf
for Ginsberg’s operator. They proved that Model-Checking(∗G) is coNP-com-
plete in the general case, and in P when restricted to Horn formulas. So, for Gins-
berg’s operator restricting instances to Horn formulas makes the model checking
problem tractable. On the one hand we prove that Model-Checking(∗RSRG)
has the same complexity as Model-Checking(∗G). On the other hand we prove
that with this cardinal-maximality criterion, restricting instances to Horn for-
mulas does not make the problem easier.
Theorem 1. Model-Checking(∗RSRG) and Model-Checking(∗PRSRG) are
coNP-complete even if the formulas in the instances are restricted to Horn form.
Proof. Let (B, μ, m), where B is a stratiﬁed belief base, be an instance of
Model-Checking(∗PRSRG). If m is not a model of μ, then m ̸|= B ∗P RSRG μ.
Otherwise, only one subset B′ of B is a candidate to have a maximal trace among
all subsets of B consistent with μ having m as model: B′ = {α ∈B | m |= α}.
Therefore, to show that m ̸|= B ∗P RSRG μ, we only have to prove that B′
is not trace-maximal. For this it is suﬃcient to guess a set B0 ⊆B and an
interpretation m0 such that m0 |= (B0 ∪{μ}) (and thus B0 ∪{μ} is consis-
tent) and trace(B′, B) <lex trace(B0, B). All these veriﬁcations can be done in
polynomial time, thus proving that Model-Checking(∗PRSRG) (and a fortiori
Model-Checking(∗RSRG)) is in coNP.
Let us now prove that Model-Checking(∗RSRG) (and a fortiori Model-
Checking(∗PRSRG)) is coNP-hard even if the formulas are restricted to Horn
form. We use a reduction from the well-known NP-complete problem
Max-Independent-Set (see for example [9]) to the complementary of Model-
Checking(∗RSRG).
Problem :
Max-Independent-Set
Instance :
G = (V, E) an undirected graph, k a positive integer.
Question :
Does there exist in G an independent set of size at least k, i.e.,
V ′ ⊆V with |V ′| ≥k, such that for every two vertices {x, y} ∈
V ′2, {x, y} ̸∈E?
Let G = (V, E) be an undirected graph and k a positive integer. To every
vertex v in G we associate a propositional variable v and let U = {u1, ..., uk−1}
be a set of k −1 fresh variables. We then consider the belief base B, the formula
μ and the interpretation m deﬁned as follows:
– B = {(vi) | vi ∈V } ∪{(uj) | uj ∈U} ∪{(¬vi ∨¬vj) | {vi, vj} ∈E} ∪{(¬vi ∨
¬uj) | vi ∈V, uj ∈U}
– μ = s and m = U ∪{s} where s is a fresh variable that does not occur in B.
Observe that every consistent subbase of B is consistent with μ, moreover
there exists a consistent subbase of B of maximal cardinality, B′, that contains
all binary clauses. Indeed, if some clause (¬vi ∨¬wj) is not in B′, then by

392
N. Creignou et al.
maximality B′ contains both vi and wj. Since all binary clauses are negative,
the set B′ = B ∪{(¬vi ∨¬wj)}\{vi} is consistent, has the same cardinality as B′
and contains one negative clause more. Finally, such a set cannot contain both
a unary clause coming from V and one coming from U.
Suppose that G contains an independent set W with |W| ≥k. The set
B′ = {(vi) | vi ∈W}∪{(¬vi∨¬vj) | {vi, vj} ∈E}∪{(¬vi∨¬uj) | vi ∈V, uj ∈U}
is then consistent (satisﬁed by the interpretation W). Since |W| ≥k, B′ shows
that the set of clauses from B that are satisﬁed by m is not cardinality-maximal,
which proves that m ̸|= B ∗RSRG μ.
Conversely, according to the observations above, if G does not contain any
independent set of size larger than or equal to k, then the set {(uj) | uj ∈
U} ∪{(¬vi ∨¬vj) | {vi, vj} ∈E} ∪{(¬vi ∨¬uj) | vi ∈V, uj ∈U} is cardinality-
maximal. But this set is exactly the set of clauses from B that are satisﬁed by
m, therefore m |= B ∗RSRG μ.
4.2
Complexity Results for the Operators ∗wid, ∗RSRW and ∗PRSRW
Liberatore and Schaerf proved that Model-Checking(∗wid) is Σ2P-complete
[14] in the propositional case. As far as we know this is the only known complexity
result. In particular the complexity of this problem when restricted to Horn
formulas was left open in [14]. We answer this question in proving that the
complexity drops by one level in the polynomial hierarchy if the formulas are
restricted to Horn.
Theorem 2. Model-Checking(∗wid) is NP-complete in the case of Horn for-
mulas.
Proof. Let us ﬁrst prove membership. Let B be a set of Horn formulas, μ a Horn
formula and m an interpretation. In order to prove that m |= B ∗wid μ, one has
to show that for every α ∈B such that m ̸|= α, there exists B′
α ⊆B such that
B′
α ∪{μ} is consistent and B′
α ∪{μ} ∪{α} is inconsistent (such a set B′
α can be
completed until it becomes maximal in terms of set inclusion).
All these consistency checks can be performed in polynomial time since all
considered formulas are Horn. Therefore Model-Checking(∗wid) is in NP.
Hardness is shown by reduction from the problem PQ-Abduction deﬁned
as follows and proven to be NP-complete in [6]:
Problem :
PQ-Abduction
Instance :
a Horn formula ϕ, a set of variables A = {x1, ..., xn} such that
A ⊆V ar(ϕ) and a variable q ∈V ar(ϕ) \ A.
Question :
Does there exist a set E ⊆Lit(A) such that ϕ ∧ E is satisﬁable
and ϕ ∧ E ∧¬q is unsatisﬁable?
Consider an arbitrary instance (ϕ, A, q) of PQ-Abduction. Without loss of
generality suppose that the Horn formula ϕ ∧q is satisﬁable. Let x0 be a fresh
variable and consider B a set of formulas, μ a formula and m an interpretation
deﬁned as follows:

Complexity of Model Checking for Cardinality-Based Belief Revision
393
– B = {(ϕ ∧l) ∨¬x0 | l ∈Lit(A)} ∪{¬q ∧x0},
– μ = x0, and m an interpretation such that m |= ϕ ∧x0 ∧q.
First observe that all formulas occurring in B can be rewritten as equivalent
Horn formulas. Let us now prove that there exists E ⊆Lit(A) such that ϕ∧ E
is consistent and ϕ∧ E ∧¬q is inconsistent if and only if m |= B ∗wid μ, that is
to say, for all α ∈B such that m ̸|= α, there exists B′
α ⊆B such that B′
α ∪{μ}
is consistent, while B′
α ∪{μ} ∪{α} is inconsistent.
First consider E ⊆Lit(A) such that ϕ ∧ E is consistent and ϕ ∧ E ∧¬q
is inconsistent. Let us examine the formulas α in B such that m ̸|= α. There are
two possible cases:
– If α = (¬q ∧x0), then let us consider B′
α = {(ϕ ∧l) ∨¬x0 | l ∈E}. We
have (B′
α ∪{μ}) ≡((ϕ ∧ E) ∨¬x0) ∧x0. On the one hand, this formula
is consistent. On the other hand, (B′
α ∪{μ} ∪{α}) ≡ϕ ∧ E ∧x0 ∧¬q is
inconsistent.
– If α = ((ϕ ∧l) ∨¬x0) for some literal l. If m ̸|= α, then m ̸|= l for m |= ϕ.
Let us then consider B′
α = {(ϕ ∧¬l) ∨¬x0}. On the one hand, since m |= ϕ
and m ̸|= l (and hence m |= ¬l), the only formula from B′
α is satisﬁed by m,
and therefore B′
α ∪{μ} is consistent. On the other hand, B′
α ∪{μ} ∪{α} =
{(ϕ ∧¬l) ∨¬x0} ∪{x0} ∪{(ϕ ∧l) ∨¬x0} is inconsistent.
Thus we have proven that if there exists a set E ⊆Lit(A) such that ϕ ∧ E
is consistent and ϕ ∧ E ∧¬q is inconsistent, then m |= B ∗wid μ.
Conversely, suppose that m |= B ∗wid μ. This means that for every α ∈B
such that m ̸|= α there exists B′
α ⊆B such that B′
α ∪{μ} is consistent and
B′
α ∪{μ} ∪{α} is inconsistent. Let us consider α = ¬q ∧x0 and let us take
E = {l | ((ϕ ∧l) ∨¬x0) ∈B′
α}. On the one hand, observe that ϕ ∧ E ∧
x0 ≡(B′
α ∪{μ}), and therefore ϕ ∧ E is consistent. On the other hand,
ϕ∧ E ∧x0∧¬q ≡(B′
α∪{μ}∪{α}) and therefore ϕ∧ E ∧¬q is inconsistent.
To conclude observe that this reduction is feasible in polynomial time. The
only critical point is to ﬁnd an interpretation m, which is a model of ϕ ∧x0 ∧q.
This can be done in polynomial time since ϕ is a Horn formula. So we have
ﬁnally proven that Model-Checking(∗wid) is NP-complete when restricted to
Horn formulas.
For this strategy, as stated in the following theorem, considering subbases maxi-
mal in terms of cardinality instead of subbases maximal in terms of set inclusion
makes the checking problem slightly easier in the context of full propositional
logic. However, restricting the instances to Horn formulas is of no help.
Theorem 3. Model-Checking(∗RSRW) is Θ2P-complete, and
Model-Checking(∗PRSRW) is in Δ2P and is Θ2P-hard.
Hardness results hold even if the formulas occurring in the instances are further
restricted to Horn and Krom.
Proof. Let us ﬁrst establish membership. We show that Model-Checking
(∗RSRW) is in Θ2P. Let B be a belief base and μ be a formula. Let kmax denote

394
N. Creignou et al.
the maximal cardinality of subsets of B that are consistent with μ. In order to
decide whether m is a model of the revised belief base B ∗RSRW μ, we have to
check that for every α ∈B such that m ̸|= α, there exists a subset Bα of B \{α}
consistent with μ such that |Bα| = kmax.
We proceed by the classical binary search [17] for ﬁnding the optimum, asking
questions like “Does there exist a subset of B consistent with μ of size least at
k?”. This requires a logarithmic number of calls to an NP-oracle. When the
maximal size kmax of all subbases from B that are consistent with μ has thus
been computed, we check if for all α ∈B such that m ̸|= α, there exist a
subset Bα ⊆B\{α} and an interpretation mα such that : mα |= Bα ∪{μ} (and
thus Bα ∪{μ} is consistent) and |Bα| = kmax. This can be done by a single
question to an NP-oracle since there are at most |B| formulas to consider and
they can be dealt with in parallel. In total, we have then a polynomial algorithm
with a logarithmic number of calls to an NP-oracle, thus proving that Model-
Checking(∗RSRW ) is in Θ2P.
For the problem Model-Checking(∗PRSRW), the algorithm is similar. The
only diﬀerence lies in the fact that we have to compute lexicographically maxi-
mal trace. This can be done by computing the maximum of each stratum, one
after the other. This cannot be done for all strata at once, the oracle calls are
adaptative. Therefore the number of calls to an NP-oracle depends linearly on
the number of layers of the stratiﬁed belief base and logarithmically on the total
number of formulas in the belief base. So, the algorithm proves that the problem
is in Δ2P.
We prove that Model-Checking(∗RSRW) is Θ2P-hard by reduction from
the following decision problem:
Problem :
CardMinSat
Instance :
Propositional formula ϕ and an atom xi.
Question :
Is xi true in a cardinality-maximal model of ϕ?
The problem CardMinSat is Θ2P-hard even if we restrict ϕ to Krom and
moreover the clauses consist of positive literals only (see [5]).
Let (ϕ, xi) be an instance of of CardMinSat where ϕ is a conjunction of
disjunctions of two positive literals and X = {x1, . . . , xn} is the set of variables
in ϕ. We deﬁne the following instance of Model-Checking(∗RSRW):
– B = {ϕ ∧yj | j = 1, . . . , n + 1} ∪{(¬xi)} ∪{(¬xj ∨r) | j = 1, . . . , n, j ̸= i}
– μ = ¬r and m = X ∪{y1, . . . yn+1, r} where y1, . . . yn+1, r are fresh variables,
not occurring in ϕ.
This reduction is clearly feasible in polynomial time.
On the one hand observe that m satisﬁes all formulas in B except (¬xi). On
the other hand, the subbases of B that are consistent with μ and have maximal
cardinality necessarily contain {ϕ ∧yj | j = 1, . . . , n + 1}.
Let us prove that ϕ has a cardinality-minimal model containing xi if and
only if there exists B′ ⊆B consistent with μ of maximal cardinality that does
not contain (¬xi), that is to say if and only if m |= B ∗RSRW μ.

Complexity of Model Checking for Cardinality-Based Belief Revision
395
Suppose that ϕ has a cardinality-minimal model m′ that contains xi. Con-
sider B′ = {ϕ ∧yj | j = 1, . . . , n + 1} ∪{(¬xj ∨r) | xj /∈m′}, |B′| = n + 1 + |I′|
where I′ = {j | xj /∈m′}. It is easy to check that B′ is a cardinality-maximal
subbase of B consistent with μ that does not contain (¬xi).
Conversely, suppose that there exists B′ ⊆B consistent with μ of maximal
cardinality that does not contain (¬xi). Such a set B′ is necessarily of the form
B′ = {ϕ∧yj | j = 1, . . . , n+1}∪{(¬xj ∨r) | xj ∈I′} where I′ ⊆{1, . . . , n}\{i}.
It is easy to check that m′ = {xj | j /∈I′} is a cardinality-minimal model of ϕ
that contains xi.
Observe that all formulas in B, as well as the formula μ are Krom formulas.
Therefore, we have proven that Model-Checking(∗RSRW) is Θ2P-hard even
when restricted to Krom formulas. Moreover, each clause in any of these for-
mulas contains at most one negative literal. Hence, in considering the set ˜B
and the formula ˜μ obtained from B and μ by renaming all variables, and the
interpretation ˜m = 1 −m, we obtain a reduction that proves that Model-
Checking(∗RSRW) is Θ2P-hard even when restricted to formulas that are both
Horn and Krom.
Table 1. Complexity results: synthetic summary
Operator Propositional logic
Horn
Ginsberg coNP-complete [14, Theorem 1]
P [14, Theorem 17]
Widtio
Σ2P-complete [14, Theorem 2]
NP-complete, Theorem 2
RSRG
coNP-complete, Theorem 1
coNP-complete, Theorem 1
RSRW
Θ2P-complete, Theorem 3
Θ2P-complete, Theorem 3
PRSRG
coNP-complete, Theorem 1
coNP-complete, Theorem 1
PRSRW
in Δ2P, Θ2P-hard, Theorem 3
in Δ2P, Θ2P-hard, Theorem 3
5
Concluding Discussion
It is well known that belief base revision and non-monotonic inference from
an inconsistent belief base are the two sides of a same coin [8]. In [4] Cayrol,
Lagasquie-Schiex and Schiex present a comparative study of some non-monotonic
syntactic inference relations. Let B be a belief base, < be a total pre-order over
the formulas of the base, and φ be a propositional formula, the inference rela-
tions are synthetically deﬁned by (B, <) |∼p,m φ where p ∈{T, INCL, LEX}
represents the mechanism for selecting consistent subbases, consistent subbases
maximal w.r.t. set inclusion or w.r.t. to lexicographic order respectively and
m ∈{∀, ∃, ARG} represents the inference strategy, universal, existential or argu-
mentative respectively. A comparative study from the complexity perspective is
presented in the full propositional case and in the Horn fragment, however it
focuses on the inference problem and not on the model checking one. Besides,

396
N. Creignou et al.
the strategy stemming from the intersection of maximal consistent subbases is
not dealt with. In this paper, on the one hand, we established the complexity of
the model checking problem for the Widtio operator in the Horn case, answering
to a question left open by Liberatore and Schaerf [14]. On the other hand, we
focused on cardinality-based belief revision operators RSRG and RSRW their
respective generalization to stratiﬁed belief bases. Thus we studied to which
extent the use of cardinality as consistent subbases maximality criterion (instead
of set inclusion) has an impact on the complexity of the model checking problem.
It seems natural to think about the impact of cardinality as maximality criterion
for other belief base revision strategies. This will be addressed in a future work.
References
1. Alchourr´on, C.E., G¨ardenfors, P., Makinson, D.: On the logic of theory change:
partial meet contraction and revision functions. J. Symbolic Logic 50, 510–530
(1985)
2. Benferhat, S., Ben-Naim, J., Papini, O., W¨urbel, E.: An answer set programming
encoding of prioritized removed sets revision: application to GIS. Appl. Intell.
32(1), 60–87 (2010)
3. Benferhat, S., Cayrol, C., Dubois, D., Lang, J., Prade, H.: Inconsistency manage-
ment and prioritized syntax-based entailment. In: Proceedings of IJCAI 1993, pp.
640–645 (1993)
4. Cayrol, C., Lagasquie-Schiex, M., Schiex, T.: Nonmonotonic reasoning: from com-
plexity to algorithms. Ann. Math. Artif. Intell. 22(3–4), 207–236 (1998)
5. Creignou, N., Pichler, R., Woltran, S.: Do hard sat-related reasoning tasks become
easier in the Krom fragment? In: IJCAI (2013)
6. Creignou, N., Zanuttini, B.: A complete classiﬁcation of the complexity of propo-
sitional abduction. SIAM J. Comput. 36, 207–229 (2006)
7. Eiter, T., Gottlob, G.: On the complexity of propositional knowledge base revision,
updates, and counterfactuals. Artif. Intell. 57(2–3), 227–270 (1992)
8. G¨ardenfors, P.: Belief revision and nonmonotonic logic: Two sides of the same coin?
In: Proceedings of ECAI 1990, pp. 768–773 (1990)
9. Garey, M., Johnson, D.: Computers and Intractability: A Guide to the Theory of
NP-Completeness. W.H Freeman, New York (1979)
10. Ginsberg, M.: Counterfactuals. Artif. Intell. 30, 35–79 (1986)
11. Hansson, S.O.: Revision of belief sets and belief bases. In: Dubois, D., Prade, H.
(eds.) Belief Change. Handbook of Defeasible Reasoning and Uncertainty Manage-
ment Systems, pp. 17–75. Kluwer, Netherlands (1998)
12. Katsuno, H., Mendelzon, A.O.: Propositional knowledge base revision and minimal
change. Artif. Intell. 52, 263–294 (1991)
13. Lehmann, D.: Belief revision, revised. In: Proceedings of IJCAI 1995, pp. 1534–
1540 (1995)
14. Liberatore, P., Schaerf, M.: Belief revision and update: complexity of model check-
ing. J. Comput. Syst. Sci. 62(1), 43–72 (2001)
15. Nebel, B.: Belief revision and default reasoning: syntax-based approaches. In: Pro-
ceedings of KR 1991, pp. 417–428 (1991)
16. Nebel, B.: How hard is it to revise a belief base? In: Dubois, D., Prade, H. (eds.)
Belief Change. Handbook of Defeasible Reasoning and Uncertainty Management
Systems, vol. 3, pp. 77–145. Springer, Netherlands (1998)

Complexity of Model Checking for Cardinality-Based Belief Revision
397
17. Papadimitriou, C.H.: Computational Complexity. Addison Wesley, Boston (1994)
18. Papini, O.: A complete revision function in propositional calculus. In: Proceedings
of ECAI 1992, pp. 339–343 (1992)
19. Stockmeyer, L.J.: The polynomial-time hierarchy. Theor. Comput. Sci. 3(1), 1–22
(1976)
20. Wagner, K.: More complicated questions about maxima and minima, and some
closures of NP. Theor. Comput. Sci. 51(1–2), 53–80 (1987)
21. Winslett, M.: Sometimes updates are circumscription. In: Proceedings of IJCAI
1989, pp. 859–863 (1989)

A Two-Tiered Propositional Framework
for Handling Multisource Inconsistent
Information
Davide Ciucci1(B) and Didier Dubois2
1 DISCo - Universit`a di Milano - Bicocca, Milan, Italy
ciucci@disco.unimib.it
2 IRIT - CNRS & Universit´e de Toulouse, Toulouse, France
dubois@irit.fr
Abstract. This paper proposes a conceptually simple but expressive
framework for handling propositional information stemming from several
sources, namely a two-tiered propositional logic augmented with classi-
cal modal axioms (BC-logic), a fragment of the non-normal modal logic
EMN, whose semantics is expressed in terms of two-valued monotonic
set-functions called Boolean capacities. We present a theorem-preserving
translation of Belnap logic in this setting. As special cases, we can recover
previous translations of three-valued logics such as Kleene and Priest
logics. Our translation bridges the gap between Belnap logic, epistemic
logic, and theories of uncertainty like possibility theory or belief func-
tions, and paves the way to a uniﬁed approach to various inconsistency
handling methods.
1
Introduction
A number of works has been published proposing approaches that deal with
inconsistent knowledge bases in such a way as to extract useful information
from them in a non-explosive way [5,18]. Inconsistency is often due to the pres-
ence of multiple sources providing information. Belnap 4-valued logic [4] is one
of the earliest approaches to this problem. It is based on a very natural set-up
where each source tentatively assigns truth-values to elementary propositions.
The sets of truth-values thus collected for these propositions are summarized by
so-called epistemic truth-values referring to whether sources are in conﬂict or not,
informed or not. There are 4 such epistemic truth-values, two of which referring
to ignorance and conﬂict. Truth tables for conjunction, disjunction, and nega-
tion are used to compute the epistemic status of other complex formulas. This
approach underlies both Kleene three-valued logic (when no conﬂict between
sources is observed) and the Priest three-valued logic of paradox [16] (sources
are never ignorant and assign truth-values to all elementary propositions).
Besides, inconsistency and incompleteness are present in uncertainty theo-
ries as well, using monotonic set-functions called capacities with values in the
unit interval, instead of logics. The simplest logical framework for incomplete
c
⃝Springer International Publishing AG 2017
A. Antonucci et al. (Eds.): ECSQARU 2017, LNAI 10369, pp. 398–408, 2017.
DOI: 10.1007/978-3-319-61581-3 36

A Two-Tiered Propositional Framework
399
information is the two-tiered propositional logic MEL [3], that accounts for an all-
or-nothing view of possibility theory [11], and borrows axioms K and D from modal
epistemic logic. Replacing necessity measures by general inclusion-monotonic set-
functions can account for the idea of conﬂicting sources of information. It leads to
adopting a fragment of the non-normal modal logic EMN [7] as a general logical
framework, which can encompass variants of probabilistic and belief function
logics, for instance the logic of risky knowledge [15], where the adjunction rule
is not valid. Here, we show that our two-tiered propositional setting related to
EMN can encode Belnap 4-valued logic, namely that the four truth-values in
Belnap logic are naturally expressed by means of capacities taking values on
{0, 1}. Thus, we construct a bridge between Belnap logic and uncertainty the-
ories. As special cases, we recover our previous translations of Kleene logic for
incomplete information [8] and Priest logic of paradox [9]. Showing the possi-
bility of this translation indicates that our logic has potential to support other
inconsistency handling approaches as well. The paper is organized as follows.
Section 2 presents the propositional logic of Boolean capacities BC and shows
its capability to capture the notion of information coming from several sources.
Section 3 recalls Belnap 4-valued logic from the point of view of its motivation,
its syntactical inference and its semantics. Section 4 contains the main results
pertaining to the translation of Belnap logic into BC. Most proofs are omitted
due to length constraints.
2
The Logic of Boolean Capacities and Multisource
Information Management
In this section, we consider an approach to the handling of pieces of incomplete
and conﬂicting information coming from several sources. We show, following an
intuition already suggested in [1,12] that if we represent each body of information
items supplied by each source by means of a set of possible states of aﬀairs,
the collective information supplied by the sources can be modelled in a lossless
way by a monotonic set function (called a capacity) that takes value on {0, 1}.
These set-functions can serve as natural multisource semantics for a simple ﬂat
non-regular modal logic that captures the four Belnap truth-values as already
suggested in [10]. This logic looks rather uncommitting for handling multiple
source information, while other approaches seem to put additional assumptions.
2.1
Boolean Capacities and Multisource Information
Consider a standard propositional language L with variables V = {a, b, c, . . . }
and connectives ∧, ∨, ¬, for conjunction, disjunction and negation, respectively.
We denote the propositional formulas of L by letters p, q, . . . . Consider a set of
states of aﬀairs Ω which is the set of interpretations of this language.
Deﬁnition 1. A capacity (or fuzzy measure) is a mapping γ : 2Ω →[0, 1] such
that γ(∅) = 0; γ(Ω) = 1; and if A ⊆B then γ(A) ≤γ(B).

400
D. Ciucci and D. Dubois
The value γ(A) can be interpreted as the degree of support of a proposition p
represented by the subset A = [p] of its models. A Boolean capacity (B-capacity,
for short) is a capacity with values in {0, 1}. It can be deﬁned from a usual
capacity and any threshold λ > 0 as β(A) = 1 if γ(A) ≥λ and 0 otherwise.
The useful information in a B-capacity consists of its focal sets. A focal set
E is such that β(E) = 1 and β(E\{w}) = 0, ∀w ∈E. Let Fβ be the set of focal
sets of β. They are minimal sets for inclusion such that β(E) = 1: we can check
that β(A) = 1 if and only if there is a subset E of A in Fβ with β(E) = 1.
Consider n sources providing information in the form of epistemic states
modelled by non-empty sets Ei ⊆Ω: it is only known from source i that the real
state of aﬀairs s should lie in Ei. A capacity β can be built from these pieces of
information then viewed as the set Fβ = {E1, E2, . . . , En} of its focal subsets.
Then β([p]) = 1 really means that there is at least one source i that believes
that p is true (that is p is true in all states of aﬀairs in Ei). Note that this way
of synthetizing information is not destructive: it preserves every initial piece of
information. Given a proposition p, there are four epistemic statuses based on
the information from sources, that can be described by the capacity:
– Support of p: β([p]) = 1 and β([¬p]) = 0. Then p is asserted by at least one
source and negated by no other one.
– Rejection of p: β([¬p]) = 1 and β([p]) = 0. Then p is negated by at least one
source and asserted by no other one.
– Ignorance about p: β([p])= β([¬p])=0. No source supports nor negates p.
– Conﬂict about p: β([p]) = β([¬p]) = 1. Some sources assert p, some negate it.
Important special cases are
– when β is minitive, i.e., β(A ∩B) = min(β(A), β(B)). It is then a necessity
measure and Fβ = {E}. There is only one source and its information is
incomplete, but there is no conﬂict.
– when the focal sets are singletons {ei}. Then β is maxitive, i.e., β(A ∪B) =
max(β(A), β(B)). All sources have complete information, so there are con-
ﬂicts, but no ignorance. Letting E = {e1, e2, . . . , en}, then β(A) = 1 if and
only if A∩E ̸= ∅, formally a possibility measure. But here E is a conjunction
of non-mutually exclusive elements, not a possibility distribution.
2.2
The Logic BC
To provide a logical setting to the above situation, we build a higher level propo-
sitional language L□on top of L, whose formulas are denoted by Greek letters
φ, ψ, . . . , and deﬁned by: if p ∈L then □p ∈L□; if φ, ψ ∈L□then ¬φ ∈L□,
φ ∧ψ ∈L□. Note that the language L is not part of L□, it is embedded in it,
since atomic variables of L□are of the form □p, p ∈L. As usual ♦p stands for
¬□¬p. It deﬁnes a very elementary fragment of a modal logic language [3].
A minimal logic for B-capacities has been proposed using the language L□
[12]. It is a two-tiered propositional logic plus some modal axioms:

A Two-Tiered Propositional Framework
401
1. All axioms of propositional logics for L□-formulas.
2. The modal axioms:
(RM) □p →□q if ⊢p →q in propositional logic.
(N) □p, whenever p is a propositional tautology.
(P) ♦p, whenever p is a propositional tautology.
The only rule is modus ponens: If ψ and ψ →φ then φ. This is a fragment
of the non-regular logic EMN [7]. Note that the two dual modalities □and ♦
play the same role. Namely the above axioms remain valid if we exchange □and
♦. So these modalities are not distinguishable. Semantics is usually expressed in
terms of neighborhood semantics, but it can be equivalently expressed in terms of
B-capacities on the set of interpretations Ω of the language L. We have indicated
elsewhere [10] that the set of subsets A such that β(A) = 1 is a special case of
neighborhood family in the sense of neighborhood semantics [7]. This logic can
thus be called the logic of Boolean Capacities (BC). A BC-model of an atomic
formula □p is a B-capacity β. The satisfaction of BC-formulas is deﬁned as:
– β |= □p, if and only if β([p]) = 1;
– β |= ¬φ, β |= φ ∧ψ in the standard way.
Semantic entailment is deﬁned classically, and syntactic entailment is classical
propositional entailment taking RM, N, P as axioms: Γ ⊢BC φ if and only if
Γ ∪{all instances of RM, N, P} ⊢φ (classically deﬁned). It has been proved
that BC logic is sound and complete wrt B-capacity models [12]. In fact, axiom
RM clearly expresses the monotonicity of capacities, and it is easy to realize that
a classical propositional interpretation of L□that respects the axioms of BC can
be precisely viewed as a B-capacity.
As a B-capacity precisely encodes a set of sources each delivering incomplete
information items in the form of an n-tuple of focal sets (E1, E2, . . . , En), we can
see that β |= □p if and only if ∃i : Ei ⊆[p], so we may write (E1, E2, . . . , En) |= ϕ
in place of β |= ϕ. Denoting by □ip the statement Ei ⊆[p], the formula □p is of
the form □1p∨· · ·∨□np where □i is a standard KD modality in a regular modal
logic. Likewise, ♦p = ¬□¬p = ¬□1¬p ∧· · · ∧¬□n¬p = ♦1p ∧· · · ∧♦np clearly
means that no source is asserting ¬p. The four epistemic statuses of propositions
in L can then be expressed by means of modal formulas in L□as follows [10]:
– Support of p: (E1, E2, . . . , En) |= □p ∧♦p
– Rejection of p: (E1, E2, . . . , En) |= □¬p ∧♦¬p
– Ignorance about p: (E1, E2, . . . , En) |= ♦p ∧♦¬p
– Conﬂict about p: (E1, E2, . . . , En) |= □p ∧□¬p
Note that this framework is very cautious, in the sense that inferences made are
minimal ones one can expect to make from multisource information. If we add
axioms K and D of modal logics, then β is forced to be a necessity measure,
and the conﬂict situation disappears: there is only one source with epistemic
set E driving β. We get the logic MEL [3], a fragment of the logic KD. In case
we restrict to capacities β whose focal sets are singletons, the □modality has
all properties of a KD possibility modality ♦. It is a kind of mirror image of

402
D. Ciucci and D. Dubois
logic MEL where conﬂict is taken into account but there is no ignorance. It can
capture Priest logic of paradox [9]. The aim of this paper is to show that the
general framework of BC-logic can encode Belnap logic as a special case.
3
Belnap 4-Valued Logic
Belnap [4] considers an artiﬁcial information processor, fed from a variety of
sources, and capable of answering queries on propositions of interest. The basic
assumption is that the computer receives information about atomic propositions
in a cumulative way from outside sources, each asserting for each atomic propo-
sition whether it is true, false, or being silent about it. The notion of epistemic
set-up is deﬁned as an assignment, of one of four values denoted by T, F, C, U,
to each atomic proposition a, b, . . .:
1. Assigning T to a means the computer has only been told that a is true (1)
by at least one source, and false (0) by none.
2. Assigning F to a means the computer has only been told that a is false by at
least one source, and true by none.
3. Assigning C to a means the computer has been told at least that a is true by
one source and false by another.
4. Assigning U to a means the computer has been told nothing about a.
Table 1. Belnap disjunction, conjunction and negation
∨F U C T
F F U C T
U U U T T
C C T C T
T T T T T
∧F U C T
F F F F F
U F U F U
C F F C C
T F U C T
a ¬a
F T
U U
C C
T F
If {0, 1} is the set of usual truth values (as assigned by the information sources),
then the set V4 = {T, F, C, U} of epistemic truth values coincides with the
power set of {0, 1}, letting T = {1}, F = {0}. According to the convention
initiated by Dunn [13], U represents the empty set and corresponds to no infor-
mation received, while C = {0, 1} represents the presence of conﬂicting sources,
expressing true and false at the same time. Belnap’s approach relies on two
orderings in V4 = {T, F, C, U}, equipping it with two lattice structures:
– The information ordering, ⊏whose meaning is “less informative than”, such
that U ⊏T ⊏C; U ⊏F ⊏C. This ordering reﬂects the inclusion relation of
the sets ∅, {0}, {1}, and {0, 1}. (V4, ⊏) is the information lattice.
– The truth ordering, <t, representing “more true than” according to which
F <t C <t T and F <t U <t T, each chain reﬂecting the truth-set of Kleene’s
logic. In other words, ignorance and conﬂict play the same role with respect
to F and T according to this ordering. It yields the logical lattice, based on

A Two-Tiered Propositional Framework
403
the truth ordering, and the interval extension of standard connectives ∧, ∨
and ¬ from {0, 1} to 2{0,1}\{∅}. In this lattice, the maximum of U and C is
T and the minimum is F.
The syntax is the one of propositional logic. Connectives of negation, con-
junction and disjunction are deﬁned truth-functionally in Belnap 4-valued logic
(see Table 1). Belnap 4-valued logic has no tautologies, but it has an inference
system. It can be deﬁned only via a set of inference rules, as those that can be
found in [14,17]:
Deﬁnition 2. Let a, b, c ∈V . The inference system of Belnap 4-valued logic is
deﬁned by no axiom and the following set of rules
(R1) : a ∧b
a
(R2) : a ∧b
b
(R3) : a
b
a ∧b
(R4) :
a
a ∨b
(R5) : a ∨b
b ∨a
(R6) : a ∨a
a
(R7) :
a ∨(b ∨c)
(a ∨b) ∨c
(R8) :
a ∨(b ∧c)
(a ∨b) ∧(a ∨c)
(R9) : (a ∨b) ∧(a ∨c)
a ∨(b ∧c)
(R10) :
a ∨c
¬¬a ∨c
(R11) : ¬(a ∨b) ∨c
(¬a ∧¬b) ∨c
(R12) : ¬(a ∧b) ∨c
(¬a ∨¬b) ∨c
(R13) : ¬¬a ∨c
a ∨c
(R14) : (¬a ∧¬b) ∨c
¬(a ∨b) ∨c
(R15) : (¬a ∨¬b) ∨c
¬(a ∧b) ∨c
These rules express that conjunction is idempotent and distributes over disjunc-
tion, disjunction is idempotent, associative and distributes over conjunction.
Negation is involutive and De Morgan Laws are satisﬁed. It makes clear that the
underlying algebra is a De Morgan algebra [17]. Applying these rules, formulas
can be put in normal form as a conjunction of clauses, i.e., p = p1∧. . .∧pn, where
the pi’s are disjunctions of literals lij = a or ¬a where a ∈V . For the semantics,
consider again the four epistemic truth-values forming the set V4 = {F, U, C, T}.
A Belnap valuation is a mapping vb : L →V4. Let Γ ⊆L and p ∈L, then we
deﬁne the consequence relation by means of the truth ordering ≤t as
Γ ⊨B p
iﬀ
∃p1, . . . , pn ∈Γ, ∀vb vb(p1) ∧. . . ∧vb(pn) ≤t vb(p)
Now, let us consider the consequence relations ⊨U, ⊨C obtained by the des-
ignated values {U, T} or {C, T}, respectively deﬁned as:
Γ ⊨U p : ∀vb
if vb(pi) ∈{U, T}, ∀pi ∈Γ, then vb(p) ∈{U, T};
Γ ⊨C p : ∀vb
if vb(pi) ∈{C, T}, ∀pi ∈Γ, then vb(p) ∈{C, T}.
Font [14] proves the following result: Γ ⊨B p iﬀΓ ⊨U p and Γ ⊨C p. More-
over, due to the symmetric role that {U, T} and {C, T} play in Belnap’s logic,
the two relations Γ ⊨U p and Γ ⊨C p are equivalent: Γ ⊨U p iﬀΓ ⊨C p. The
adequacy with the Hilbert-style axiomatization of Belnap logic and the above
semantics is proved by Pynko [17] and Font [14]:

404
D. Ciucci and D. Dubois
Theorem 1. Belnap logic is sound and complete with respect to Belnap seman-
tics, that is Γ ⊢B p iﬀΓ ⊨B p using the 15 rules Ri, i = 1, . . . , 15.
Kleene logic has truth tables obtained from Belnap logic’s by deleting the truth-
value C, and has designated truth-value T. Priest logic is obtained by deleting
the truth-value U, keeping C, T as designated. From a syntactic point of view,
Kleene logic has one more inference rule than Belnap 4-valued logic, e.g., q∧¬q ⊢
p ∨¬p, while Priest logic is Belnap logic plus one axiom (p ∨¬p, see [14,17]).
4
A Translation of Belnap Logic into BC
The above results, joined with the fact that Kleene logic and Priest logic can be
translated into MEL [8,9] strongly suggest that Belnap logic can be expressed in
BC. Formulas in BC can be related to Belnap truth-values T, F, U, C in an obvi-
ous way, provided that we restrict to atomic formulas. Let T be the translation
operation that changes a partial Belnap truth-value assignment vb(a) ∈Θ ⊆V4
to an atomic propositional formula a, into a modal formula, indicating its epis-
temic status w.r.t a set of sources. In agreement with the multisource semantics
of the BC logic, we let T (vb(a) ≥t C) = □a and T (vb(a) ≤t C) = □¬a. Like-
wise T (vb(a) ≥t U) = ♦a, T (vb(a) ≤t U) = ♦¬a. Hence, we get the modal
translation of the four Belnap epistemic values:
T (vb(a) = T) = □a ∧♦a
T (vb(a) = F) = □¬a ∧♦¬a
T (vb(a) = U) = ♦a ∧♦¬a
T (vb(a) = C) = □a ∧□¬a
In Belnap logic, though, sources provide information only on these elementary
propositions, valuations for other propositions being obtained via truth-tables.
The translation of Belnap truth-qualiﬁed formulas will be carried out using the
truth-tables of the logic, which means that in all formulas of L□that can be
reached via the translation, only literals appear in the scope of modalities.
Let us consider the fragment of BC language where we can only put a modal-
ity in front of literals: Lℓ
□= □a|□¬a|¬φ|φ ∧ψ|φ ∨ψ. We can proceed to the
translation of Belnap truth-tables into BC. First consider negation. It is easy to
check that T (vb(¬p) = T) = T (vb(p) = F), T (vb(¬p) = x) = T (vb(p) = x),
T (vb(¬p) ≥t x) = T (vb(p) ≤t x), x ∈{U, C}. On compound formulas built
with conjunction and disjunction, it is clear that T (vb(p ∧q) = T) = T (vb(p) =
T) ∧T (vb(q) = T) but, due to the distributive lattice structure of V4, we have
T (vb(p ∨q) = T) = T (vb(p) = T) ∨T (vb(q) = T) ∨(T (vb(p) = U) ∧T (vb(p) =
C)) ∨(T (vb(p) = C) ∧T (vb(p) = U)).
For elementary formulas ¬a, a ∨b, a ∧b of Belnap logic, we get explicit
translations using the truth-tables of Belnap logic, for instance:
T (vb(¬a) = T) = T (vb(a) = F)
T (vb(¬a) = U) = T (vb(a) = U); T (vb(¬a) = C) = T (vb(a) = C)
T (vb(¬a) ≥t C) = T (vb(a) ≤t C) = □¬a

A Two-Tiered Propositional Framework
405
T (vb(a ∧b) = T) = □a ∧♦a ∧□b ∧♦b
T (vb(a ∨b) = T) = (□a ∧♦a) ∨(□b ∧♦b) ∨(Ca ∧Ub) ∨(Ua ∧Cb)
T (vb(a ∧b) ≥t U) = ♦a ∧♦b;
T (vb(a ∧b) ≥t C) = □a ∧□b
T (vb(a ∨b) ≥t U) = ♦a ∨♦b;
T (vb(a ∨b) ≥t C) = □a ∨□b
where ♦a ∧♦¬a is shortened as Ua and □a ∧□¬a as Ca. Belnap logic has
two designated values: T and C. So, for inference purposes, we use translated
semantic expressions T (vb(p) ≥t C). According to this translation, Belnap logic
reaches the following fragment of BC-language: LB
□= □a|□¬a|φ∧ψ|φ∨ψ without
negation in front of □. Conversely, from the fragment LB
□we can go back to
Belnap logic. Namely any formula in LB
□can be translated into a formula of the
propositional logic language as follows: □a maps to a and □¬a to ¬a; θ(ψ ∧φ)
to θ(ψ) ∧θ(φ) and θ(ψ ∨φ) to θ(ψ) ∨θ(φ). We remark that □a ∨□¬a is not
a tautology in BC, and in general no tautologies can be expressed in the above
fragment. This is coherent with the fact that Belnap logic has no theorems.
Theorem 2. Let φ/ψ be any of the 15 inference rules of Belnap logic. Then,
the following inference rule is valid in BC:
T (vb(φ) ≥t C)
T (vb(ψ) ≥t C)
As a consequence we can mimic syntactic inference of Belnap logic in BC, more
precisely restricting to formulas in LB
□. The restriction of the scope of modalities
to literals also aﬀects the set of B-capacities that can act as a semantic coun-
terpart of the logic. We can check that semantic inference in Belnap logic can
be expressed in the modal setting of BC by restricting the capacities that can
be used as models of LB
□formulas. Namely, consider a Belnap set-up where each
source i provides a set Ti of atoms considered true by this source, a set Fi of atoms
considered false by this source, where Ti∩Fi = ∅. It corresponds to a special kind
of epistemic state with rectangular shape, namely: Ei = [(
a∈Ti a)∧(
b∈Fi ¬b)].
As there are n sources of this kind, we can restrict to B-capacities β with
such rectangular focal sets. In fact, as atoms of LB
□are of the form □ℓwhere
ℓis a literal, and as we cannot put □in front of conjunctions nor disjunctions,
it is enough to use capacities whose focal sets are of the form [a], a ∈∪n
i=1Ti
and [¬b], b ∈∪n
i=1Fi to interpret formulas in LB
□. We call such capacities atomic.
Considering the Belnap valuation vb associated to the information supplied by
n sources, there is a one-to-one correspondence between Belnap valuations and
atomic B-capacities α induced by this information:
Proposition 1. For any B-capacity β, there is a single Belnap valuation vbβ
such that β |= φ if and only if vbβ(θ(φ)) ∈{C, T}.
The idea is to let vbβ(a) = T if β([a]) = 1 and β([¬a]) = 0, vbβ(a) = F if
β([a]) = 0 and β([¬a]) = 1, etc. In the other way around,
Proposition 2. For each Belnap valuation vb, there exists a unique atomic B-
capacity αvb such that vb |= p if and only if αvb |= T (vb(p) ≥t C).

406
D. Ciucci and D. Dubois
Indeed, deﬁne T = {a : vb(a) = T or C}, F = {a : vb(a) = F or C}, and let
α([a]) = 1 if a ∈T, α([¬a]) = 1 if a ∈F. However there are several Belnap
set-ups inducing a given Belnap valuation vb: for instance only two sources are
enough to model the four values [6]. We thus introduce an equivalence relation
on the set of B-capacities, whereby two of them are equivalent if they correspond
to the same Belnap truth assignment: β ∼B β′ if and only if vbβ = vbβ′.
Proposition 3. For any B-capacity β, there exists an atomic B-capacity α such
that β ∼B α.
Indeed, consider β with focal sets E1, . . . En. Let Ti = {a ∈V : Ei ⊆[a]} and
Fi = {b ∈V : Ei ⊆[¬b]}. The focal sets of α are based on such literals and form
the family
Fα = {[a] : a ∈∪n
i=1Ti} ∪{[¬b] : b ∈∪n
i=1Fi}.
From Proposition 3 we can conclude that for any B-capacity β, there exists an
atomic B-capacity α ∼B β such that β |= φ ∈LB
□if and only if α |= φ. We then
can prove that our translation of Belnap logic into BC is consequence-preserving:
Theorem 3. Let Γ be a set (conjunction) of formulas in propositional logic
interpreted in Belnap logic, and p be another such formula. Then Γ ⊢B p if and
only if {T (vb(q) ≥t C) : q ∈Γ} ⊢BC T (vb(q) ≥t C).
Proof. Suppose Γ ⊢B p. Then from Theorem 2, all inference rules of Belnap
logic become valid inferences in BC using the translations of their premises and
conclusions. So the inference can be made in BC. Conversely, by completeness
of BC, suppose ∀β, if β |= T (vb(q) ≥t C), ∀q ∈Γ then β |= T (vb(p) ≥t C).
Using Proposition 3, for all B-capacities β, ∃α ∼B β, where α is atomic, such
that ∀q ∈Γ, α |= T (vb(q) ≥t C) if and only if β |= T (vb(q) ≥t C) and
α |= T (vb(p) ≥t C) if and only if β |= T (vb(p) ≥t C). Then, we have that if
vb(q) ≥t C, ∀q ∈Γ then vb(p) ≥t C for the Belnap valuation vb associated to
α. So Γ |=B p. By completeness of Belnap logic, Γ ⊢B p follows.
⊓⊔
We can recover our previous translations of three-valued Kleene logic and
the logic of paradox into the logic MEL [8,9], from our translation of Belnap
logic into BC, by translating into BC the properties added to Belnap logic to
recover these logics. Namely Kleene logic is obtained by adding the inference
rule q ∧¬q ⊢p ∨¬p to Belnap logic, which comes down to adding inference rule
(KL) :
□q ∧□¬q ⊢□p ∨□¬p to BC. A simpler approach is to add axiom D
(□p →♦p) to BC. To recover Priest logic from Belnap’s, axiom p ∨¬p must be
added, which means adding to BC the (unusual) axiom □p ∨□¬p [9].
5
Conclusion
In this paper, we have pursued our work regarding a class of many-valued logics
dealing with inconsistent or incomplete information processing [8,9]. Just like
Kleene logic and Priest’s logic of paradox in MEL, we can capture Belnap 4-
valued logics in a simple two-tiered propositional logic couched in the language of

A Two-Tiered Propositional Framework
407
modal logic EMN involving only depth-1 formulas. The natural semantics for this
propositional logic is in terms of all-or-nothing set-functions that model Belnap
set-ups and capture both incomplete and inconsistent pieces of information. The
use of set-functions clariﬁes the connection between Belnap 4-valued logic and
uncertainty modeling. The use of set-functions beyond possibility and necessity
measures is in agreement with the fact that propositions in Belnap 4-valued
logics cannot be viewed as S5-like beliefs. The logic BC is cautious enough to be
a general setting for modeling incomplete and inconsistent logical information.
It subsumes Belnap 4-valued logic, doing away with the restriction to literals,
and accounting for generalized Belnap set-ups considered by Avron et al. [2].
It seems that our framework may be used to capture various approaches to
inconsistent and incomplete information handling; for instance, the one based on
maximal consistent subsets could be obtained by considering B-capacities such
that β(A ∩B) = min(β(A), β(B)) if A ∩B ̸= ∅. Moreover it can be extended to
handling degrees of support. This is to be explored in the future.
References
1. Assaghir, Z., Napoli, A., Kaytoue, M., Dubois, D., Prade, H.: Numerical informa-
tion fusion: lattice of answers with supporting arguments. In: Proceedings ICTAI
2011, Boca Raton, FL, USA, pp. 621–628 (2011)
2. Avron, A., Ben-Naim, J., Konikowska, B.: Processing Information from a set of
sources. In: Makinson, D., Malinowski, J., Wansing, H. (eds.) Towards Mathe-
matical Philosophy. Trends in Logic, vol. 28, pp. 165–186. Springer, Netherlands
(2009)
3. Banerjee, M., Dubois, D.: A simple logic for reasoning about incomplete knowledge.
Int. J. Approximate Reasoning 55, 639–653 (2014)
4. Belnap, N.D.: A useful four-valued logic. In: Dunn, J.M., Epstein, G. (eds.) Modern
Uses of Multiple-Valued Logic, pp. 8–37. D. Reidel, Dordrecht (1977)
5. Besnard, P., Hunter, A. (eds.): Reasoning with Actual and Potential Contradic-
tions. The Handbook of Defeasible Reasoning and Uncertain Information, vol. 2.
Kluwer, Dordrecht (1998)
6. Carnielli, W., Lima-Marques, M.: Society semantics for multiple-valued logics. In:
Advances in Contemporary Logic and Computer Science. Contemporary Mathe-
matics, vol. 235, pp. 33–52. American Mathematical Society (1999)
7. Chellas, B.F.: Modal Logic: An Introduction. Cambridge University Press, Cam-
bridge (1980)
8. Ciucci, D., Dubois, D.: A modal theorem-preserving translation of a class of three-
valued logics of incomplete information. J. Appl. Non Classical Logics 23(4), 321–
352 (2013)
9. Ciucci, D., Dubois, D.: From possibility theory to paraconsistency. In: Beziau, J.Y.,
Chakraborty, M., Dutta, S. (eds.) New Directions in Paraconsistent Logic. Springer
Proceedings in Mathematics & Statistics, vol. 152. Springer, New Delhi (2015)
10. Dubois, D.: Reasoning about ignorance and contradiction: many-valued logics ver-
sus epistemic logic. Soft Comput. 16(11), 1817–1831 (2012)
11. Dubois, D., Prade, H.: Possibility theory and its applications: where do we stand?
In: Kacprzyk, J., Pedrycz, W. (eds.) Handbook of Computational Intelligence, pp.
31–60. Springer, Heidelberg (2015)

408
D. Ciucci and D. Dubois
12. Dubois, D., Prade, H., Rico, A.: Representing qualitative capacities as families of
possibility measures. Int. J. Approximate Reasoning 58, 3–24 (2015)
13. Dunn, J.M.: Intuitive semantics for ﬁrst-degree entailment and coupled trees. Phi-
los. Stud. 29, 149–168 (1976)
14. Font, J.M.: Belnap’s four-valued logic and De Morgan lattices. Logic J. IGPL 5(3),
1–29 (1997)
15. Kyburg, H.E., Teng, C.-M.: The logic of risky knowledge, reprised. Int. J. Approx-
imate Reasoning 53(3), 274–285 (2012)
16. Priest, G.: The logic of paradox. J. Philos. Logic 8, 219–241 (1979)
17. Pynko, A.P.: Characterizing Belnap’s logic via De Morgan’s laws. Math. Log. Q.
41, 442–454 (1995)
18. Tanaka, K., Berto, F., Mares, E., Paoli, F. (eds.): Paraconsistency: Logic and
Applications, pp. 1–12. Springer, Heidelberg (2013)

Reasoning in Description Logics
with Typicalities and Probabilities of Exceptions
Gian Luca Pozzato(B)
Dipartimento di Informatica, Universit`a di Torino, Turin, Italy
gianluca.pozzato@unito.it
Abstract. We introduce a nonmonotonic procedure for preferential
Description Logics in order to reason about typicality by taking prob-
abilities of exceptions into account. We consider an extension, called
ALC +TP
R, of the logic of typicality ALC +TR by inclusions of the form
T(C) ⊑p D, whose intuitive meaning is that “typical Cs are Ds with a
probability p”. We consider a notion of extension of an ABox contain-
ing only some typicality assertions, then we equip each extension with
a probability. We then restrict entailment of a query F to those exten-
sions whose probabilities belong to a given and ﬁxed range. We propose
a decision procedure for reasoning in ALC + TP
R and we exploit it to
show that entailment is ExpTime-complete as for the underlying ALC.
1
Introduction
Nonmonotonic extensions of Description Logics (from now on, DLs for short)
have been actively investigated since the early 90s [2–7,16] in order to tackle the
problem of representing prototypical properties of classes and to reason about
defasible inheritance. A simple but powerful nonmonotonic extension of DLs is
proposed in [8]: in this approach “typical” or “normal” properties can be directly
speciﬁed by means of a “typicality” operator T enriching the underlying DL, and
a TBox can contain inclusions of the form T(C) ⊑D to represent that “typical
Cs are also Ds” or “normally, Cs have the property D”. The Description Logic
so obtained is called ALC + TR and, as a diﬀerence with standard DLs, one can
consistently express exceptions and reason about defeasible inheritance as well.
For instance, a knowledge base can consistently express that “normally, referees
do not send-oﬀfootball managers”, whereas “Italian referees usually send-oﬀ
football managers” (since they usually either protest without justiﬁcation or
kick oﬀwater bottles at ﬁeld side when they become angry) as follows:
T(Referee) ⊑¬∃sendoﬀ.FootballManager
T(Referee ⊓Italian) ⊑∃sendoﬀ.FootballManager
G.L. Pozzato—Partially supported by the project “ExceptionOWL”, Universit`a di
Torino and Compagnia di San Paolo, call 2014 “Excellent (young) PI”, project ID:
Torino call2014 L1 111.
c
⃝Springer International Publishing AG 2017
A. Antonucci et al. (Eds.): ECSQARU 2017, LNAI 10369, pp. 409–420, 2017.
DOI: 10.1007/978-3-319-61581-3 37

410
G.L. Pozzato
The semantics of the T operator is characterized by the properties of rational
logic [11], recognized as the core properties of nonmonotonic reasoning. As a con-
sequence, T inherits well-established properties like speciﬁcity: in the example,
if one knows that Daniele is a typical Italian referee, then the logic ALC + TR
allows us to infer that he usually sends-oﬀfootball managers, giving preference
to the most speciﬁc information.
The logic ALC + TR itself is too weak in several application domains.
Indeed, although the operator T is nonmonotonic (T(C) ⊑E does not imply
T(C ⊓D) ⊑E), the logic ALC + TR is monotonic, in the sense that if the
fact F follows from a given knowledge base KB, then F also follows from any
KB’ ⊇KB. As a consequence, unless a KB contains explicit assumptions about
typicality of individuals, there is no way of inferring defeasible properties about
them: in the above example, if KB contains the fact that Mark is a referee,
i.e. Referee(mark) belongs to KB, it is not possible to infer that he does not
send-oﬀmanagers (¬∃sendoﬀ.FootballManager(mark)). This would be possible
only if the KB contained the stronger information that Mark is a typical ref-
eree, i.e. T(Referee)(mark) belongs to (or can be inferred from) KB. In order
to overwhelm this limit and perform useful inferences, in [10] the authors have
introduced a nonmonotonic extension of the logic ALC +TR based on a minimal
model semantics, corresponding to a notion of rational closure as deﬁned in [11]
for propositional logic. Intuitively, the idea is to restrict our consideration to
(canonical) models that maximize typical instances of a concept when consis-
tent with the knowledge base. The resulting logic, call it ALC +TRaCl
R
, supports
typicality assumptions, so that if one knows that Mark is a referee, one can non-
monotonically assume that he is also a typical referee if this is consistent, and
therefore that he does not send-oﬀmanagers. From a semantic point of view, the
logic ALC + TRaCl
R
is based on a preference relation among ALC + TR models
and a notion of minimal entailment restricted to models that are minimal with
respect to such preference relation. However, ALC + TRaCl
R
imposes to consider
all consistent typicality assumptions that are consistent with a given KB. This
seems to be too strong in several application domains, in particular when the
need arises of reasoning about scenarios where exceptional individuals are taken
into account.
In this work we introduce a new Description Logic called ALC + TP
R, which
extends ALC by means of typicality inclusions equipped by probabilities of excep-
tionality of the form T(C) ⊑p D, where p ∈(0, 1). The intuitive meaning is that
“typical Cs are also Ds with a probability p” or “normally, Cs are Ds and the
probability of having exceptional Cs not being Ds is 1 −p”. For instance, we
can have
T(Student) ⊑0.3 SportLover
T(Student) ⊑0.9 SocialNetworkUser
whose intuitive meaning is that being sport lovers and social network users are
both typical properties of students, however the probability of having exceptional
students not loving sport is higher than the one of ﬁnding students not using
social networks, in particular we have the evidence that the probability of not

Reasoning in Description Logics with Typicalities
411
having exceptions is 30% and 90%, respectively. As a diﬀerence with DLs under
the distributed semantics introduced in [13,14], where probabilistic axioms of the
form p :: C ⊑D are used to capture uncertainty in order to represent that Cs
are Ds with probability p, in the logic ALC + TP
R we are able to ascribe typical
properties to concepts and to reason about probabilities of exceptions to those
typicalities. We deﬁne diﬀerent extensions of an ABox containing only some of
the “plausible” typicality assertions: each extension represents a scenario having
a speciﬁc probability. Then, we provide a notion of nonmonotonic entailment
restricted to extensions whose probabilities belong to a given and ﬁxed range,
in order to reason about scenarios that are not necessarily the most probable.
We introduce a decision procedure for checking entailment in ALC + TP
R and
we exploit it in order to show that reasoning in ALC + TP
R with probabilities
of exceptions is ExpTime complete, therefore we retain the same complexity of
the underlying standard ALC.
2
Preferential Description Logics
The logic ALC + TR is obtained by adding to standard ALC the typicality
operator T [8]. The intuitive idea is that T(C) selects the typical instances of
a concept C. We can therefore distinguish between the properties that hold for
all instances of concept C (C ⊑D), and those that only hold for the normal or
typical instances of C (T(C) ⊑D).
The semantics of the T operator can be formulated in terms of rational
models: a model M is any structure ⟨ΔI, <, .I⟩where ΔI is the domain, < is an
irreﬂexive, transitive, well-founded and modular (for all x, y, z in ΔI, if x < y
then either x < z or z < y) relation over ΔI. In this respect, x < y means that
x is “more normal” than y, and that the typical members of a concept C are
the minimal elements of C with respect to this relation. An element x ∈ΔI is
a typical instance of some concept C if x ∈CI and there is no C-element in ΔI
more typical than x. In detail, .I is the extension function that maps each concept
C to CI ⊆ΔI, and each role R to RI ⊆ΔI × ΔI. For concepts of ALC, CI
is deﬁned as usual. For T, we have (T(C))I = Min<(CI). A model M can be
equivalently deﬁned by postulating the existence of a function kM : ΔI 
−→N,
where kM assigns a ﬁnite rank to each domain element: kM and < can be deﬁned
from each other by letting x < y if and only if kM(x) < kM(y).
Given standard deﬁnitions of satisﬁability of a KB in a model, we deﬁne
a notion of entailment in ALC + TR. Given a query F (either an inclusion
C ⊑D or an assertion C(a) or an assertion of the form R(a, b)), we say that
F is entailed from a KB, written KB |=ALC+TR F, if F holds in all ALC + TR
models satisfying KB.
Even if the typicality operator T itself is nonmonotonic (i.e. T(C) ⊑E does
not imply T(C ⊓D) ⊑E), what is inferred from a KB can still be inferred from
any KB’ with KB ⊆KB’, i.e. the logic ALC + TR is monotonic. In order to
perform useful nonmonotonic inferences, in [10] the authors have strengthened
the above semantics by restricting entailment to a class of minimal models. Intu-
itively, the idea is to restrict entailment to models that minimize the untypical

412
G.L. Pozzato
instances of a concept. The resulting logic is called ALC + TRaCl
R
and it corre-
sponds to a notion of rational closure on top of ALC + TR. Such a notion is
a natural extension of the rational closure construction provided in [11] for the
propositional logic.
The nonmonotonic semantics of ALC + TRaCl
R
relies on minimal rational
models that minimize the rank of domain elements. Informally, given two models
of KB, one in which a given domain element x has rank 2 (because for instance
z < y < x), and another in which it has rank 1 (because only y < x), we prefer
the latter, as in this model the element x is assumed to be “more typical” than
in the former.
Query entailment is then restricted to minimal canonical models. The intu-
ition is that a canonical model contains all the individuals that enjoy properties
that are consistent with KB. A model M is a minimal canonical model of KB
if it satisﬁes KB, it is minimal and it is canonical1. A query F is minimally
entailed from a KB, written KB |=ALC+TRaCl
R
F, if it holds in all minimal canon-
ical models of KB. In [10] it is shown that query entailment in ALC + TRaCl
R
is
in ExpTime.
3
Dealing with Probabilities of Exceptions
In this section we deﬁne an alternative semantics that allows us to equip a
typicality inclusion with the probability of not having exceptions for that, and
then to reason about such inclusions. In the resulting Description Logic, called
ALC + TP
R, a typicality inclusion has the form T(C) ⊑p D, and its intuitive
meaning is “normally, Cs are also Ds with probability p” or, in other words,
“typical Cs are also Ds, and the probability of having exceptional Cs not being
Ds is 1−p”. We then deﬁne a nonmonotonic procedure whose aim is to describe
alternative completions of the ABox obtained by assuming typicality assertions
about the individuals explicitly named in the ABox: the basic idea is similar to
the one proposed in [8], where a completion of an ALC+T ABox is proposed in
order to assume that every individual constant of the ABox is a typical element
of the most speciﬁc concept he belongs to, if this is consistent with the knowl-
edge base. An analogous approach is proposed in [12], where diﬀerent extensions
of the ABox are introduced in order to deﬁne plausible but surprising scenar-
ios. Here we propose a similar, algorithmic construction in order to compute
only some assumptions of typicality of individual constants, in order to describe
alternative scenarios having diﬀerent probabilities: diﬀerent extensions/scenarios
are obtained by considering diﬀerent sets of typicality assumptions of the form
T(C)(a), where a occurs in the ABox.
Deﬁnition 1. We consider an alphabet of concept names C, of role names R,
and of individual constants O. Given A ∈C and R ∈R, we deﬁne:
C := A | ⊤| ⊥| ¬C | C ⊓C | C ⊔C | ∀R.C | ∃R.C
1 In Theorem 10 in [10] the authors have shown that for any consistent KB there exists
a ﬁnite minimal canonical model of KB.

Reasoning in Description Logics with Typicalities
413
An ALC + TP
R knowledge base is a pair (T , A). T contains axioms of the form
either (i) C ⊑C or (ii) T(C) ⊑p C, where p ∈R, p ∈(0, 1). A contains
assertions of the form C(a) and R(a, b), where a, b ∈O.
Given an inclusion T(C) ⊑p D, the higher the probability p the more the inclu-
sion is “exceptions-free” or, equivalently, the less is the probability of having
exceptional Cs not being also Ds. In this respect, the probability p is a real
number included in the open interval (0, 1): the probability 1 is not allowed, in
the sense that an inclusion T(C) ⊑1 D (the probability of having exceptional Cs
not being Ds is 0) corresponds to a strict inclusion C ⊑D (all Cs are Ds). Given
another inclusion T(C′) ⊑p′ D′, with p′ < p, we assume that this inclusion is
less “strict” than the other one, i.e. the probability of having exceptional C′s is
higher than the one of having exceptional Cs with respect to properties D′ and
D, respectively. Recalling the example of the Introduction, where KB contains
T(Student) ⊑0.9 SocialNetworkUser and T(Student) ⊑0.3 SportLover, we have
that typical students make use of social networks, and that normally they also
love sport; however, the second inclusion is less probable with respect to the
ﬁrst one: both are properties of a prototypical student, however there are more
exceptions of students not loving sport with respect to those not being active on
social networks.
Before introducing formal deﬁnitions, we provide an example inspired to
Example 1 in [12] in order to give an intuitive idea of what we mean for reasoning
in ALC + TP
R with probabilities of exceptions. We will complete it with part 2
in Example 3.
Example 1 (Reasoning in ALC + TP
R part 1). Let KB = (T , A) where T is as
follows:
AtypicalDepressed ⊑Depressed
T(Depressed) ⊑0.85 ¬∃Symptom.MoodReactivity
T(AtypicalDepressed) ⊑0.6 ∃Symptom.MoodReactivity
T(ProstateCancerPatient) ⊑0.5 ∃Symptom.MoodReactivity
T(ProstateCancerPatient) ⊑0.8 ∃Symptom.Nocturia
(1)
We have that (2) T(Depressed ⊓Spleenless) ⊑¬∃Symptom.MoodReactivity follows2
from KB, and this is a wanted inference, since undergoing spleen removal is
irrelevant with respect to mood reactivity as far as we know. This is a non-
monotonic inference that does no longer follow if it is discovered that typical
depressed people without their spleen are subject to mood reactivity: given
T ′ = T
∪{T(Depressed
⊓Spleenless) ⊑∃Symptom.MoodReactivity}, we
have that the inclusion (2) does no longer follow from KB with T ′ in the logic
ALC + TP
R. As for rational closure, the set of inclusions that are entailed from
a ALC + TP
R KB is closed under the property known as rational monotonicity:
for instance, from KB and the fact that T(Depressed) ⊑¬Elder is not entailed
2 As mentioned, at this point of the presentation we only want to give an intuition
of inferences characterizing ALC + TP
R. Technical details and deﬁnitions will be
provided in Deﬁnition 5.

414
G.L. Pozzato
from KB in ALC + TP
R, it follows that the inclusion T(Depressed ⊓Elder) ⊑
¬∃Symptom.MoodReactivity is entailed in ALC + TP
R.
Concerning ABox reasoning, if A = {Depressed(jim)}, then we can infer that
Jim has not mood swings with a probability of 85%, since T(Depressed(jim)) is
minimally entailed from KB in ALC + TRaCl
R
and the inclusion (1) is equipped
by a probability of 0.85. If we discover that Jim is an atypical depressed, then
ALC + TP
R allows us to retract such inference, whereas the fact that Jim has
mood swings (∃Symptom.MoodReactivity(jim)) is entailed and evaluated having
probability of 60%.
3.1
Extensions of ABox
Given a KB, we deﬁne the ﬁnite set Tip of concepts occurring in the scope of
the typicality operator, i.e. Tip = {C | T(C) ⊑p D ∈KB}. Given an individual
a explicitly named in the ABox, we deﬁne the set of typicality assumptions
T(C)(a) that can be minimally entailed from KB in the nonmonotonic logic
ALC + TRaCl
R
, with C ∈Tip. We then consider an ordered set TipA of pairs
(a, C) of all possible assumptions T(C)(a), for all concepts C ∈Tip and all
individual constants a in the ABox.
Deﬁnition 2 (Assumptions in ALC+TP
R). Given an ALC+TP
R KB=(T , A),
let T ′ be the set of inclusions of T without probabilities, namely T ′ = {T(C) ⊑
D | T(C) ⊑p D ∈T }
∪
{C ⊑D ∈T }. Given a ﬁnite set of concepts
Tip, we deﬁne, for each individual name a occurring in A: Tipa = {C ∈
Tip | (T ′, A) |=ALC+TRaCl
R
T(C)(a)}. We also deﬁne TipA = {(a, C) | C ∈
Tipa and a occurs in A} and we impose an order on its elements: TipA =
[(a1, C1), (a2, C2), . . . , (an, Cn)]. Furthermore, we deﬁne the ordered multiset
PA = [p1, p2, . . . , pn], respecting the order imposed on TipA, where pi =
m

j=1
pij
for all T(Ci) ⊑pi1 D1, T(Ci) ⊑pi2 D2, . . . , T(Ci) ⊑pim Dm in T .
The ordered multiset PA is a tuple of the form [p1, p2, . . . , pn], where pi is the
probability of the assumption T(C)(a), such that (a, C) ∈TipA at position i. pi
is the product of all the probabilities pij of typicality inclusions T(C) ⊑pij D in
the TBox.
Following the basic idea underlying surprising scenarios outlined in [12], we
consider diﬀerent extensions 
Ai of the ABox and we equip them with a probabil-
ity Pi. Starting from PA = [p1, p2, . . . , pn], the ﬁrst step is to build all alternative
tuples where 0 is used in place of some pi to represent that the correspond-
ing typicality assertion T(C)(a) is no longer assumed (Deﬁnition 3). Further-
more, we deﬁne the extension of the ABox corresponding to a string so obtained
(Deﬁnition 4). In this way, the highest probability is assigned to the extension
of the ABox corresponding to PA, where all typicality assumptions are consid-
ered. The probability decreases in the other extensions, where some typicality
assumptions are discarded, thus 0 is used in place of the corresponding pi. The
probability of an extension 
Ai corresponding to a string PAi = [pi1, pi2, . . . , pin]

Reasoning in Description Logics with Typicalities
415
is deﬁned as the product of probabilities pij when pij ̸= 0, i.e. the probability
of the corresponding typicality assumption when this is selected for the exten-
sion, and 1 −pj when pij = 0, i.e. the corresponding typicality assumption is
discarded, that is to say the extension contains an exception to the inclusion.
Deﬁnition 3 (Strings of possible assumptions S). Given a KB = (T , A),
let the set TipA and PA = [p1, p2, . . . , pn] be as in Deﬁnition 2. We deﬁne the
set S of all the strings of possible assumptions with respect to KB as
S = {[s1, s2, . . . , sn] | ∀i = 1, 2, . . . , n either si = pi or si = 0}
Deﬁnition 4 (Extension of ABox). Let KB=(T , A), PA = [p1, p2, . . . , pn]
and TipA = [(a1, C1), (a2, C2), . . . , (an, Cn)] as in Deﬁnition 2. Given a string of
possible assumptions [s1, s2, . . . , sn] ∈S of Deﬁnition 3, we deﬁne the extension

A of A w.r.t. TipA and S as:

A = {T(Ci)(ai) | (ai, Ci) ∈TipA and si ̸= 0}
We also deﬁne the probability of 
A as P 
A =
n
i=1
χi where χi =
si
if si ̸= 0
1 −pi if si = 0
It can be observed that, in ALC + TRaCl
R
, the set of typicality assumptions that
can be inferred from a KB corresponds to the extension of A corresponding to
the string PA (no element is set to 0): all the typicality assertions of individuals
occurring in the ABox, that are consistent with the KB, are assumed. On the
contrary, in ALC+TR, no typicality assumptions can be derived from a KB, and
this corresponds to extending A by the assertions corresponding to the string
[0, 0, . . . , 0], i.e. by the empty set.
Example 2. Given a KB=(T , A), let the only typicality inclusions in T
be
T(C) ⊑0.6 D and T(E) ⊑0.85 F. Let a and b be the only individual con-
stants occurring in A. Suppose also that T(C)(a), T(C)(b), and T(E)(b) are
entailed from KB in ALC + TRaCl
R
. We have that TipA = {(a, C), (b, C), (b, E)}
and PA = [0.6, 0.6, 0.85]. All possible strings, corresponding extensions of A and
probabilities are shown in Table 1.
3.2
Reasoning in ALC + TP
R
We are now ready to provide formal deﬁnitions for nonmonotonic entailment
in the Description Logic ALC + TP
R. Intuitively, given KB and a query F, we
distinguish two cases: (i) if F is an inclusion C ⊑D, then it is entailed from
KB if it is minimally entailed from KB’ in the nonmonotonic ALC + TRaCl
R
,
where KB’ is obtained from KB by removing probabilities of exceptions, i.e. by
replacing each typicality inclusion T(C) ⊑p D with T(C) ⊑D; (ii) if F is an
ABox fact C(a), then it is entailed from KB if it is entailed in the monotonic
ALC + TR from the knowledge bases including the extensions of the ABox of

416
G.L. Pozzato
Table 1. Plausible extensions of the ABox of Example 2.
String
Extension
Probability
[0.6, 0.6, 0.85] 
A1 = {T(C)(a), T(C)(b), T(E)(b)}P
A1 = 0.6 × 0.6 × 0.85 = 0.306
[0, 0, 0.85]

A2 = {T(E)(b)}
P
A2 = (1 −0.6) × (1 −0.6) × 0.85 = 0.136
[0, 0.6, 0]

A3 = {T(C)(b)}
P
A3 = (1 −0.6) × 0.6 × (1 −0.85) = 0.036
[0.6, 0, 0]

A4 = {T(C)(a)}
P
A4 = 0.6 × (1 −0.6) × (1 −0.85) = 0.036
[0, 0.6, 0.85]

A5 = {T(C)(b), T(E)(b)}
P
A5 = (1 −0.6) × 0.6 × 0.85 = 0.204
[0.6, 0, 0.85]

A6 = {T(C)(a), T(E)(b)}
P
A6 = 0.6 × (1 −0.6) × 0.85 = 0.204
[0.6, 0.6, 0]

A7 = {T(C)(a), T(C)(b)}
P
A7 = 0.6 × 0.6 × (1 −0.85) = 0.054
[0, 0, 0]

A8 = ∅
P
A8 = (1 −0.6) × (1 −0.6) × (1 −0.85) = 0.024
P
A1 + P
A2 + · · · + P
A8 = 1
Deﬁnition 4. More in detail, we provide both (i) a notion of entailment restricted
to scenarios whose probabilities belong to a given range and (ii), similarly to
[13], a notion of probability of the entailment of a query C(a), as the sum of the
probabilities of all extensions from which C(a) is so entailed.
Deﬁnition 5 (Entailment in ALC + TP
R). Given a KB=(T , A), given Tip a
set of concepts, and given p, q ∈(0, 1], let E = {
A1, 
A2, . . . , 
Ak} be the set of
extensions of A of Deﬁnition 4 w.r.t. Tip, whose probabilities are s.t. p ≤P1 ≤
q, p ≤P2 ≤q, . . . , p ≤Pk ≤q. Let T ′ = {T(C) ⊑D | T(C) ⊑r D ∈T } ∪{C ⊑
D ∈T }. Given a query F, we say that F is entailed from KB in ALC + TP
R
in range ⟨p, q⟩, written KB |=⟨p,q⟩
ALC+TP
R F: (i) if F is a TBox inclusion either
C ⊑D or T(C) ⊑D, if (T ′, A) |=ALC+TRaCl
R
F; (ii) if F is an ABox fact C(a),
where a ∈O, if (T ′, A ∪
Ai) |=ALC+TR F for all 
Ai ∈E. We also deﬁne the
probability of the query as P(F) =
k
i=1
Pi.
We conclude by describing a decision procedure for reasoning in the logic ALC +
TP
R, in order to check whether a query F is entailed from a given KB as in
Deﬁnition 5. Let KB = (T , A) be an ALC + TP
R knowledge base. Let T ′ be
the set of inclusions of T without probabilities of exceptions: T ′ = {T(C) ⊑
D | T(C) ⊑r D ∈T } ∪{C ⊑D ∈T }, that the procedure will consider in
order to reason in ALC + TR and ALC + TRaCl
R
for checking query entailment
and ﬁnding all plausible typicality assumptions, respectively. Other inputs of the
procedure are the ﬁnite set of concepts Tip, a query F, and two real numbers
p, q ∈(0, 1] describing a range of probabilities. If F is an inclusion C ⊑D (where
C could be T(C′)), we just need to check whether (T ′, A) |=ALC+TRaCl
R
C ⊑D in
ALC +TRaCl
R
. If F is an ABox formula of the form C(a), we exploit Algorithm 1
in order to check whether KB |=⟨p,q⟩
ALC+TP
R F.
We exploit the procedure of Algorithm 1 to show that the problem of entail-
ment in the logic ALC + TP
R is ExpTime complete. This allows us to conclude
that reasoning about typicality and defeasible inheritance with probabilities of

Reasoning in Description Logics with Typicalities
417
Algorithm 1. Entailment in ALC + TP
R: KB |=⟨p,q⟩
ALC+TP
R F
1: procedure Entailment((T , A), T ′, F, Tip, p, q)
2:
TipA ←∅
▷build the set S of possible assumptions
3:
for each C ∈Tip do
4:
for each individual a ∈A do
▷Reasoning in ALC + TRaCl
R
5:
if (T ′, A) |=ALC+TRaCl
R
T(C)(a) then TipA ←TipA ∪{T(C)(a)}
6:
PA ←∅
▷compute the probabilities of Deﬁnition 2 given T and TipA
7:
for each C ∈Tip do
8:
ΠC ←1
9:
for each T(C) ⊑p D ∈T do ΠC ←ΠC × p
10:
PA ←PA ∪ΠC
11:
S ←build strings of possible assumptions as in Deﬁnition 3 given TipA and PA
12:
E ←∅
▷build extensions of A
13:
for each si ∈S do
14:
build the extension 
Ai corresponding to si and compute P 
Ai as in Deﬁnition 4
15:
if p ≤P 
Ai ≤q then E ←E ∪
Ai
▷select extensions with probability in ⟨p, q⟩
16:
for each 
Ai ∈E do
▷query entailment in ALC + TR
17:
if (T ′, A ∪
Ai) ̸|=ALC+TR F then return KB ̸|=⟨p,q⟩
ALC+TP
R
F
18:
return KB |=⟨p,q⟩
ALC+TP
R
F
▷F is entailed in all extensions
exceptions is essentially inexpensive, since reasoning retains the same complex-
ity class of the underlying standard ALC, which is known to be ExpTime-
complete [1].
Theorem 1 (Complexity of entailment). Given a KB in ALC + TP
R, real
numbers p, q ∈(0, 1] and a query F whose size is polynomial in the size of KB,
the problem of checking whether KB |=⟨p,q⟩
ALC+TP
R F is ExpTime-complete.
Proof (sketch). The algorithm checks, for each concept C ∈Tip and for each
individual name a whether T(C)(a) is minimally entailed from KB in the non-
monotonic logic ALC + TRaCl
R
. Let n be the length of the string representing
KB. By deﬁnition, the size of Tip is O(n). For each T(C)(a) (they are O(n2))
the algorithm relies on reasoning in ALC + TRaCl
R
, which is in ExpTime [10].
Building PA can be solved with O(n2) operations. For building the set S of plau-
sible extensions we have to consider all possible strings obtained by assuming
(or not) each typicality assumption T(C)(a), that are O(n2): for each si, we
have two options (si = 0 or si ̸= 0), then 2 × 2 × · · · × 2 diﬀerent strings, thus S
has exponential size in n. Selecting extensions whose probabilities P
Ai are in the
range [p, q] can be solved in ExpTime, then the algorithm relies on reasoning
in monotonic ALC + TR in order to check whether F is entailed in selected
extensions in E, whose size is O(2n): we have O(2n) calls to query entailment in
ALC + TR, which is ExpTime-complete.
2

418
G.L. Pozzato
Example 3 (Reasoning in ALC + TP
R part 2). We continue Example 1 in
the light of deﬁnitions provided above. Suppose that the ABox is A
=
{AtypicalDepressed(john), ProstateCancerPatient(greg)}, we can consider two
typicality assumptions:
(a) T(AtypicalDepressed)(john)
and
(b) T(ProstateCancerPatient)(greg)
then we can distinguish among four diﬀerent extensions: (i) both (a) and (b)
are assumed: in this scenario, whose probability is 0.6 × (0.5 × 0.8) = 0.24, we
can conclude that both John and Greg have mood swings, and that Greg has
nocturia. (ii) we assume (b) but not (a): this scenario has probability (1−0.6)×
(0.5 × 0.8) = 0.16, and we can only conclude ∃Symptom.MoodReactivity(greg)
and ∃Symptom.Nocturia(greg). (iii) we assume (a) and not (b): this scenario,
having a probability 0.6 × (1 −(0.5 × 0.8)) = 0.36, allows us to conclude
∃Symptom.MoodReactivity(john). (iv) Neither (a) nor (b) is added to A: here
the probability is (1 −0.6) × (1 −(0.5 × 0.8)) = 0.24, but we are not able
to conclude anything about John and Greg. The probability that John has
mood swings is deﬁned as the sum of the probabilities of scenarios where such
inference can be performed, namely scenarios (i) and (iii), and it is therefore
0.24 + 0.36 = 0.6. Similarly, the probability that Greg has nocturia and mood
swings is 0.24 + 0.16 = 0.4. Concerning entailment, we have that, in less pre-
dictable scenarios (probability no higher than 20%), Greg has nocturia, i.e. KB
|=⟨0,0.2⟩
ALC+TP
R ∃Symptom.Nocturia(greg).
4
Related Works and Conclusions
Several nonmonotonic extensions of DLs have been proposed in the literature
in order to reason about inheritance with exceptions, essentially based on the
integration of DLs with well established nonmonotonic reasoning mechanisms
[2–7,9]. In none of them, probability of exceptions in concept inclusions is taken
into account.
Probabilistic extensions of DLs, allowing to label inclusions (and facts) with
degrees representing probabilities, have been introduced in [13,14]. In this app-
roach, called DISPONTE, the authors propose the integration of probabilistic
information with DLs based on the distribution semantics for probabilistic logic
programs [15]. The basic idea is to label inclusions of the TBox as well as facts
of the ABox with a real number between 0 and 1, representing their probabili-
ties, assuming that each axiom is independent from each others. The resulting
knowledge base deﬁnes a probability distribution over worlds: roughly speak-
ing, a world is obtained by choosing, for each axiom of the KB, whether it is
considered as true of false. The distribution is further extended to queries and
the probability of the entailment of a query is obtained by marginalizing the
joint distribution of the query and the worlds. There are two main diﬀerences
between the logic ALC + TP
R proposed in this work and probabilistic DLs. On
the one hand, as already mentioned in the Introduction, in the logic ALC + TP
R

Reasoning in Description Logics with Typicalities
419
probabilities are used in order to express diﬀerent degrees of admissibility of
exceptions with respect to such typicality inclusions. Probabilities are then the
basis of diﬀerent scenarios built by assuming – or not – that individuals are typi-
cal instances of a given concept. On the contrary, in DISPONTE probabilities are
used to capture a notion of uncertainty about information of the KB, therefore
an inclusion C ⊑D having a very low probability p has a signiﬁcantly diﬀerent
meaning w.r.t. an inclusion T(C) ⊑p D, representing anyway a typical property:
normally, Cs are Ds, even if with a high probability of having exceptions to such
typical inclusion. On the other hand, in ALC + TP
R probabilities are restricted
to typicality inclusions only. On the contrary, in DISPONTE probabilities can
be associated to concept inclusions as well as to ABox facts. It is worth noticing
that the two approaches could be combined in order to describe a probabilis-
tic extension of DLs with typicalities and probabilities of having exceptions: a
knowledge base can contain axioms labelled by probabilities that can be inter-
preted as “epistemic” ones, i.e. as degrees of our belief in those axioms, as in
[14], as well as typicality inclusions with probabilities about exceptions. In this
respect, an inclusion p :: T(C) ⊑q D represents that we have degree of belief
p in the fact that typical Cs are also Ds with a probability q of not having
exceptions. Such a further extension will be material for future works.
In [12] a nonmonotonic procedure for reasoning about surprising scenarios
in DLs has been proposed. In this approach, the Description Logic ALC + TR
is extended by inclusions of the form T(C) ⊑d D, where d is a degree of expect-
edness. Similarly to ALC + TP
R, a notion of extension of an ABox is introduced
in order to assume typicality assertions about individuals satisfying cardinal-
ity restrictions on concepts, then degrees of expectedness are used in order to
deﬁne a preference relation among extended ABoxes: entailment of queries is
then restricted to ABoxes that are minimal with respect to such preference rela-
tions and that represent surprising scenarios. Also in this case, we have two main
diﬀerences with the approach of the logic ALC+TP
R: ﬁrst, in ALC+Texp
R degrees
of exprectedness are non-negative integers used essentially to deﬁne a – partial –
preference relation among extended ABoxes, whereas they are not used in order
to estimate probabilities of typicality inclusions. Second, cardinality restrictions
play a fundamental role in order to “ﬁlter” extended ABoxes. On the contrary, in
the logic ALC + TP
R, entailment is deﬁned in terms of the probability of a given
scenario and can be used to estimate the probability of a given query. In future
work we aim at extending the logic ALC + TP
R with cardinality restrictions, in
order to investigate the precise relation with the approach proposed in [12].

420
G.L. Pozzato
References
1. Baader, F., Calvanese, D., McGuinness, D., Nardi, D., Patel-Schneider, P.: The
Description Logic Handbook - Theory, Implementation, and Applications, 2nd edn.
Cambridge University Press, Cambridge (2007)
2. Baader, F., Hollunder, B.: Priorities on defaults with prerequisites, and their appli-
cation in treating speciﬁcity in terminological default logic. J. Autom. Reason.
15(1), 41–68 (1995)
3. Bonatti, P.A., Faella, M., Petrova, I., Sauro, L.: A new semantics for overriding in
description logics. Artif. Intell. 222, 1–48 (2015)
4. Bonatti, P.A., Lutz, C., Wolter, F.: The complexity of circumscription in DLs. J.
Artif. Intell. Res. (JAIR) 35, 717–773 (2009)
5. Casini, G., Straccia, U.: Rational closure for defeasible description logics. In:
Janhunen, T., Niemel¨a, I. (eds.) JELIA 2010. LNCS (LNAI), vol. 6341, pp. 77–90.
Springer, Heidelberg (2010). doi:10.1007/978-3-642-15675-5 9
6. Casini, G., Straccia, U.: Defeasible Inheritance-Based Description Logics. J. Artif.
Intell. Res. (JAIR) 48, 415–473 (2013)
7. Donini, F.M., Nardi, D., Rosati, R.: Description logics of minimal knowledge and
negation as failure. ACM Trans. Comput. Logics (ToCL) 3(2), 177–225 (2002)
8. Giordano, L., Gliozzi, V., Olivetti, N., Pozzato, G.L.: ALC+T: a preferential exten-
sion of description logics. Fundamenta Informaticae 96, 341–372 (2009)
9. Giordano, L., Gliozzi, V., Olivetti, N., Pozzato, G.L.: A nonmonotonic description
logic for reasoning about typicality. Artif. Intell. 195, 165–202 (2013)
10. Giordano, L., Gliozzi, V., Olivetti, N., Pozzato, G.L.: Semantic characterization of
rational closure: from propositional logic to description logics. Artif. Intell. 226,
1–33 (2015)
11. Lehmann, D., Magidor, M.: What does a conditional knowledge base entail? Artif.
Intell. 55(1), 1–60 (1992)
12. Pozzato, G.L.: Reasoning about surprising scenarios in description logics of typ-
icality. In: Adorni, G., Cagnoni, S., Gori, M., Maratea, M. (eds.) AI*IA 2016.
LNCS (LNAI), vol. 10037, pp. 418–432. Springer, Cham (2016). doi:10.1007/
978-3-319-49130-1 31
13. Riguzzi, F., Bellodi, E., Lamma, E., Zese, R.: Probabilistic description logics under
the distribution semantics. Semant. Web 6(5), 477–501 (2015)
14. Riguzzi, F., Bellodi, E., Lamma, E., Zese, R.: Reasoning with probabilistic ontolo-
gies. In: Proceedings of IJCAI 2015, Buenos Aires, Argentina, 25–31 July 2015,
pp. 4310–4316 (2015)
15. Sato, T.: A statistical learning method for logic programs with distribution seman-
tics. In: Sterling, L. (ed.) Logic Programming, Proceedings of ICLP, pp. 715–729.
MIT Press (1995)
16. Straccia, U.: Default inheritance reasoning in hybrid kl-one-style logics. In: Pro-
ceedings of IJCAI 1993, pp. 676–681. Morgan Kaufmann (1993)

Orthopairs

Measuring Uncertainty in Orthopairs
Andrea Campagner and Davide Ciucci(B)
DISCo, University of Milano-Bicocca, Milan, Italy
ciucci@disco.unimib.it
Abstract. In many situations information comes in bipolar form.
Orthopairs are a simple tool to represent and study this kind of infor-
mation, where objects are classiﬁed in three diﬀerent classes: positive,
negative and boundary. The scope of this work is to introduce some
uncertainty measures on orthopairs. Two main cases are investigated:
a single orthopair and a collection of orthopairs. Some ideas are taken
from neighbouring disciplines, such as fuzzy sets, intuitionistic fuzzy sets,
rough sets and possibility theory.
1
Introduction
Information often comes in bipolar form; that is, positive evidence versus neg-
ative one [8]. In order to take into account this bipolarity in a generic and
formal way, orthopairs have been introduced and studied [4,5]. An orthopair is
just a pair of sets (A, B) with empty intersection, i.e., A ∩B = ∅. Diﬀerent
meanings can be attached to these two sets, for instance positive and negative
examples, aﬃrmed or negated propositional variables, trust and distrust state-
ments, accepted and rejected objects, etc. They can be found at work in several
situations in knowledge representation (partial knowledge, borderline cases, con-
sensus) and applications (social network analysis, representing partial or vague
knowledge, rough sets, formal concept analysis). Moreover, orthopairs are linked
to other paradigms in uncertainty management, in particular they are in bijec-
tion with three-valued sets and they can be generalized to obtain Atanassov
Intuitionistic Fuzzy Sets (IFS) or possibility distributions.
The two sets A and B usually do not cover the universe, so there is an
intrinsic uncertainty in any orthopair. According to the interpretation given
to the orthopair, also this uncertainty can be interpreted in several ways. In
particular, as a lack of knowledge (we do not have enough evidence to classify
all the objects as positive or negative) or as fuzziness (there exist borderline
cases which do not belong to either A or B). In any case, it is important to
measure this uncertainty and the present work is a preliminary step in this
direction. Since, as already mentioned, orthopairs are linked to other paradigms,
we will take inspiration from the uncertainty measures already existing on those
paradigms and try to cast them on orthopairs. The paper is organized as follows.
In Sect. 2, we give the basic deﬁnitions concerning orthopairs and formalize their
relationship with other paradigms. Then, the uncertainty expressed by a single
orthopair is studied in Sect. 3 where it is shown that the EO measure plays a
c
⃝Springer International Publishing AG 2017
A. Antonucci et al. (Eds.): ECSQARU 2017, LNAI 10369, pp. 423–432, 2017.
DOI: 10.1007/978-3-319-61581-3 38

424
A. Campagner and D. Ciucci
fundamental role. The behaviour of this measure with respect to order relations
and aggregation operators is analysed in Sect. 4. Finally, measures of uncertainty
on a collection of orthopairs on the same universe are given in Sect. 5.
2
Orthopairs: Basic Deﬁnitions
An orthopair on a universe X is a pair of sets (A, B) such that A ∩B = ∅. Since
not necessarily A and B cover the universe, we have to consider also the set
C = X \(A∪B). The sets A, B, C now form a tri-partition of X, thus interesting
connections with three-way decision [17] and the theory of opposition [9] can be
put forward (see [3,5]). Despite this general deﬁnition and the several meanings
that can be attached to A, B [5], we will usually interpret them as positive
and negative, therefore denoted as (P, N). Moreover, the set C will be named
boundary and denoted as Bnd. Let O(X) be the collection of all orthopairs on X.
It is easy to show that O(X) is in bijection with three-valued sets. Indeed, it is
suﬃcient to ﬁx an orthopair o and consider the (bijective) three-valued function
fo : X →V with V = {a, b, c} deﬁned for all x ∈X as: fo(x) = a if x ∈P, b if
x ∈N and c otherwise. In particular, if V = {0, 1
2, 1} we obtain a fuzzy set with
three values. As a ﬁrst use of this bijection, we deﬁne six point-wise orderings,
some of which are total and some partial, as schematized in Table 1.
Table 1. A summary of the pointwise order relations on orthopairs.
Order on V
Order on O(X)
Symbol Type
0 ≤1
2 ≤1
P1 ⊆P2, N2 ⊆N1
≤t
Total
1
2 ≤1 ≤0
N1 ⊆N2, Bnd2 ⊆Bnd1 ≤N
Total
1
2 ≤0 ≤1
P1 ⊆P2, Bnd2 ⊆Bnd1
≤P
Total
1
2 ≤1, 1
2 ≤0 P1 ⊆P2, N1 ⊆N2
≤I
Partial
0 ≤1
2, 0 ≤1
P1 ⊆P2, Bnd1 ⊆Bnd2
≤P B
Partial
1 ≤1
2, 1 ≤0
N1 ⊆N2, Bnd1 ⊆Bnd2 ≤NB
Partial
In particular, ≤t and ≤I are the most used orderings, the ﬁrst one named
truth ordering [1] and linked to the logical truth of a statement, whereas the sec-
ond one is the knowledge ordering [1], accounting for the more complete knowl-
edge given by the greater orthopair. Let us notice that some other non-pointwise
orderings can be deﬁned [5], but are not considered here.
Clearly, the three total order relations deﬁne three lattice structures and
hence three diﬀerent meet and join operations. On orthopairs they read as:
(P1, N1) ⊓t (P2, N2) := (P1 ∩P2, N1 ∪N2)
(P1, N1) ⊔t (P2, N2) := (P1 ∪P2, N1 ∩N2)
(P1, N1) ⊓N (P2, N2) := ((P1 ∩P2) ∪[(P1 ∩N2) ∪(P2 ∩N1)], N1 ∩N2))
(P1, N1) ⊔N (P2, N2) := (P1\N2 ∪P2\N1, N1 ∪N2)

Measuring Uncertainty in Orthopairs
425
(P1, N1) ⊓P (P2, N2) := (P1 ∩P2, (N1 ∩N2) ∪[(N1 ∩P2) ∪(N2 ∩P1)])
(P1, N1) ⊔P (P2, N2) := (P1 ∪P2, N1\P2 ∪N2\P1)
When considered on three values, they correspond to strong Kleene (from ⪯t),
weak Kleene (the min from ⪯P and ⪯N) and Soboci´nski (the max from ⪯N
and ⪯P ) conjunction and disjunction. Moreover, it is of interest to consider also
the meet operation deﬁnable from the knowledge ordering, also known as the
pessimistic combination operator [12], (P1, N1) ⊓I (P2, N2) := (P1 ∩P2, N1 ∩
N2). On the other hand, the join corresponding to ≤I (when deﬁnable) is the
optimistic combination operator [12]: (P1, N1) ⊔I (P2, N2) := (P1 ∪P2, N1 ∪N2).
As a last aggregation operator, let us consider the consensus operation O1 ⊙
O2 := (P1\N2∪P2\N1, N1\P2∪N2\P1) whose aim is to reconcile two orthopairs
(for instance representing two agents’ opinion), by keeping as positive part only
what is not considered negative by the other and dually for the negative part.
Orthopairs can be generalized in several ways [5]. For the scope of the present
work it is useful to recall the links with IFS and possibility theory. As the former
is concerned, it is enough to consider as P, N two fuzzy (instead of crisp) sets.
Indeed, IFSs are pairs of fuzzy sets fP , fN : X →[0, 1] such that for all x ∈X,
fP (x) + fN(x) ≤1. Hence, orthopairs are particular cases of IFSs. With respect
to possibility distributions, orthopairs coincide with the particular class of hyper-
rectangular Boolean possibility distributions on the space {0, 1}n. In detail, given
an orthopair (P, N), the associated possibility distribution is the characteristic
function of the set of models of the formula φ = [
a∈P a ∧
a∈N ¬a]. That is
π(P,N)(ω) :=

1
if ω ⊨[
a∈P a ∧
a∈N ¬a]
0
otherwise
(1)
So, the partial (i.e., there can exists variables a ̸∈{P, N}) truth assignments ω
such that π(P,N)(ω) = 1 are those compatible with the orthopair (P, N). In order
to capture any Boolean possibility distribution π, a set of orthopairs is needed
[6]. Speciﬁcally, given π we can associate a formula in disjunctive normal form
where the disjuncts are mutually exclusive and then associate to each of these
conjuncts an orthopair thus obtaining a set of orthopairs.
3
Uncertainty in a Single Orthopair
Let us consider a single orthopair O = (P, N). Of course, the uncertainty con-
tained in O can depend on the interpretation given to the boundary (fuzziness
vs lack of information) or if we want to measure a particular facet of uncertainty
(for instance, speciﬁcity). In the following, we introduce some measures by look-
ing at what happens in generalized theories, such as fuzzy sets and IFS. We will
see that a central role is played by a simple counting measure:
EO(O) = |Bnd|
|X|
(2)

426
A. Campagner and D. Ciucci
Clearly, EO counts the number of elements in the boundary region, supposing
that they are the elements on which we are uncertain. We notice that EO is a
possible deﬁnition of roughness in rough set theory if P is interpreted as the
lower approximation and N as the exterior region [2].
3.1
Inspired by IFS
Let us consider an orthopair O = (P, N) and denote the characteristic function
of P and N as χP , χN respectively. We consider now O as a crisp version of IFS
and apply some IFS uncertainty measures to O, namely: Entropy, Knowledge
Measure and Non-Speciﬁcity.
Entropy Functions. In [13], Pal et al. deﬁne two types of entropy for IFS, in
order to distinguish between two diﬀerent types of uncertainty coexisting in
IFS: Fuzziness and Lack of knowledge. In order to quantify the ﬁrst type of
uncertainty, the authors introduce a system of axioms which are not meaningful
when restricted to orthopairs since they constrain an entropy function E to be
deﬁned as the constant 0 function. On the other hand, the axioms introduced
by Szmidt and Kacprzyk in [16] can be directly applied to orthopairs:
(Ax1) E(O) = 0 iﬀA ∈2X;
(Ax2) E(O) = 1 iﬀ∀x ∈X, χP (x) = χN(x);
(Ax1) E(O1) ≤E(O2) if ∀x ∈X, χP1(x) ≤χP2(x) and χN1(x) ≥χN2(x) for
χP2(x) ≤χN2(x), vice versa χP1(x) ≥χP2(x) and χN1(x) ≤χN2(x) for
χP2(x) ≥χN2(x);
(Ax4) E(O) = E(Oc)
where (P, N)c = (N, P). In order to quantify the second type of uncertainty the
authors in [13] introduce the following set of axioms:
(Ax5) I(O) = 0 iﬀ∀x ∈X, χP (x) + χN(x) = 1
(Ax6) I(O) = 1 iﬀ∀x ∈X, χP (x) = χN(x) = 0
(Ax7) I(O1) ≥I(O2) if ∀x ∈X, χP1(x) + χN1(x) ≤χP2(x) + χN2(x)
(Ax8) I(O) = I(Oc)
Clearly, on orthopairs the two sets of axioms turn out to be equivalent:
Proposition 1. Let E : O(X) →[0, 1] be a function. Then E satisﬁes axioms
1–4 iﬀit satisﬁes axioms 5–8.
Proof (sketch). Axiom 4 is the same as axiom 8. An orthopair O is a crisp set (i.e.
BndO = ∅) iﬀ∀x, either χP (x) = 1 or χN(x) = 1, therefore axiom 1 and axiom
5 are equivalent. Axioms 2 and axiom 6 are equivalent since χP (x) = χN(x) iﬀ
χP (x) = χN(x) = 0. Finally, it is possible to show that from axioms (Ax5)–(Ax8)
we get (Ax3) and vice-versa, from axioms (Ax1)–(Ax4) we get (Ax7).
It is easy to observe that EO satisﬁes axioms 1–4 (and therefore also axioms
5–8). Furthermore it is the only function, up to constants, to satisfy them. At
ﬁrst, let us recall the following result, adapted to the orthopair case.

Measuring Uncertainty in Orthopairs
427
Lemma 1. [13] Let g : {0, 1} →{0, 1} be a function. Then G : O(X) →[0, 1]
deﬁned as G(O) = k 
x∈U g(χP (x) + χN(x)) satisﬁes 5–8 iﬀg(1) = 0 and
g(0) = 1.
Proposition 2. EO is the only function in the form k 
x∈X g(χPA(x) +
χNA(x)) satisfying axioms 1–4 and 5–8, up to a multiplicative constant.
Proof. First of all, EO is in the form required by Lemma 1. Indeed, k = 1/|X|
and g′(x) = 1 −(χP (x) + χN(x)). Thus, we can rewrite k 
x∈U g(χP (x) +
χN(x)) = k 
x∈P ∪N g(1) + k 
x∈Bnd g(0) = k 
x∈Bnd 1 = k|Bnd|, which,
choosing k = 1/|X|, is exactly the deﬁnition of EO, hence the result.
Several deﬁnitions of entropy satisfying axioms 1–4 or 5–8 have been given. We
consider, in particular, the list of entropies, surveyed by Zhang in [18]. We can
divide them in two groups, the ﬁrst one, clusters all measures that on orthopairs
reduce to EO. They are
– EBB(O) =
1
|X|

x∈X χBndO(x) = EO(O);
– ESK(O) =
1
|X|

x∈X
min(χPO (x),χNO (x))+χBndO (x)
max(χPO (x),χNO (x))+χBndO (x) = EO(O);
– EZL(O) = 1 −
1
|X|

x∈X |χPO(x) −χNO(x)| = EO(O);
– EV S(O)
=
−
1
|X|ln2

x∈X [χPO(x)lnχPO(x) + χNO(x)lnχNO(x) −(1 −
χBndO(x))ln(1 −χBndO(x)) −χBndO(x)ln2] = EO(O);
– EY 1(O) =
1
|X|

x∈X {{sin[ π
4 (1 + χPO(x) −χNO(x))] + sin[ π
4 (1 −χPO(x) +
χNO(x))] −1}
1
√
2−1} = EO(O);
– EY 2(O) =
1
|X|

x∈X {{cos[ π
4 (1 + χPO(x) −χNO(x))] + cos[ π
4 (1 −χPO(x) +
χNO(x))] −1}
1
√
2−1} = EO(O);
– E(O) = 1 −
1
|X|

x∈X[

2(χPO(x) −0.5)2 + 2(χNO(x) −0.5)2 −χBndO(x)];
The second group is made of measures that reduce to the zero constant function:
– EZJ(O) =
1
|X|

x∈X
min(χPO (x),χNO (x))
max(χPO (x),χNO (x)) = 0;
– EZ1(O) = 1 −

2
|X|

x∈X [(χPO(x) −0.5)2 + (χNO(x) −0.5)2] = 0;
– EZ2(O) = 1 −
1
|X|

x∈X [|χPO(x) −0.5| + |χNO(x) −0.5|] = 0;
– EZ3(O) = 1 −
2
|X|

x∈X max(|χPO(x) −0.5|, |χNO(x) −0.5|) = 0;
– EZ4(O) = 1 −

4
|X|

x∈X max(|χPO(x) −0.5|2, |χNO(x) −0.5|2) = 0;
– E2
hc(O) =
1
|X|

x∈X[1 −χPO(x)2 −χNO(x)2 −χBndO(x)2] = 0;
– E1/2
r
(O) =
2
|X|

x∈X ln[χPO(x)1/2 −χNO(x)1/2 −χBndO(x)1/2] = 0;
Knowledge Measure. In [10] Guo deﬁnes axiomatically a knowledge measure K
in order to measure the amount of knowledge in an IFS. This notion of knowl-
edge measure is deeply related to the concept of entropy as deﬁned by axioms
(Ax1)–(Ax4). Indeed, the set of axioms deﬁning it can be directly obtained by
negation of (Ax1)–(Ax4). In particular, Guo deﬁnes the following knowledge
measure: KAIF S(O) = 1 −1
2n

x∈U(1 −|χPO(x) −χNO(x)|)(1 + χBndO(x)) that
on orthopairs gives the negation of EO: KAIF S(O) = 1 −EO(O).

428
A. Campagner and D. Ciucci
Non Speciﬁcity. In [15], Song et al. distinguish another type of uncertainty in an
IFS, namely non-speciﬁcity, and deﬁne a measure of non-speciﬁcity in analogy
with the well-known Hartley measure1. The non-speciﬁcity HIF S(A) of an IFS
A, once restricted to orthopairs, is deﬁned as follows:
HIF S(o) =

log |U|
if P = ∅
log |Po ∪Bndo|
otherwise
3.2
Inspired by Fuzzy Sets
We can harness the bijective correspondence between three-valued sets and
orthopairs in order to translate the measures on fuzzy sets to our context.
Entropy. In [7] De Luca and Termini proposed the well-known non-probabilistic
deﬁnition of entropy for fuzzy sets based on a set of four axioms. It can be easily
shown that, in the case of orthopairs, their axioms are equivalent to axioms
(Ax1)–(Ax4). The authors also propose an entropy measure, inspired by Shannon
entropy:
Ek(O) = k[

x∈X
χPO(x)log(
1
χPO(x)) +

x∈X
(1 −χPO(x))log(
1
1 −χPO(x))].
where O is an orthopair on X. We can prove the following result:
Proposition 3. Restricted to orthopairs EK(O) = EO(O), with k =
1
|X|.
Non Speciﬁcity. In [11], Klir deﬁned a measure of non-speciﬁcity for fuzzy
sets. Considering an orthopair O = (P, N) this measure reads as: HKlir(O) =
1
2log|P ∪Bnd| + 1
2log|P|. Let us remark that when P = ∅, it is not deﬁned
since the term log|P| = log(0) is undeﬁned. We notice that the two measures of
non-speciﬁcity introduced from IFS and fuzzy sets are diﬀerent. We have that:
1. Both have value in the range [0, log |U|];
2. HKlir(o) ≤HIF S(o);
3. HIF S(o) reaches the maximum value log|U|, either when Po ∪Bndo = U, in
this case HKlir(o) = 1
2log|U|+ 1
2log|P|, or when Po = ∅, in this case HKlir(o)
is not deﬁned; HKlir(o) reaches the maximum value whenever Po = U;
4. Both HIF S(o) and HKlir(o) have minimum value 0, when o = ({x}, U \ {x})
with x ∈U.
As a conclusion of this section, we can say that EO is the unique general
measure of uncertainty of a single orthopair. If we want to consider particular
aspects such as non-speciﬁcity (as above) or proportion between positive and
negative (not discussed here) then other measures are possible.
1 We recall that the Hartley measure is deﬁned on crisp sets as: HHartley(X) = log|X|.

Measuring Uncertainty in Orthopairs
429
4
EO Measure and Aggregation Operations
In this section, we want to study how uncertainty, measured by EO, propagates
through the various orderings and aggregation operators deﬁned in Sect. 2.
First of all, let us consider the order relations. We can easily observe the
following monotonic behaviours.
Proposition 4. The measure EO is anti-tonic w.r.t. the orders ≤N, ≤P and
≤I and isotonic w.r.t. the orders ≤NB, ≤P B.
On the other hand EO is non-monotonic w.r.t. the order ≤t, as shown in the
following example.
Example 1. Consider the orthopairs O1 = (∅, U) ≤t O2 = (∅, {1, 2}) ≤t O3 =
({1}, {2}) deﬁned on U = {1, 2, 3}. We have that EO(O1) = 0 ≤EO(O2) = 1
3
but EO(O2) = 1
3 ≥EO(O3) = 0.
Regarding the amount of uncertainty obtained by diﬀerent binary aggregation
operators, the following proposition holds.
Proposition 5. Let O1 = (P1, N1), O2 = (P2, N2) be two orthopairs deﬁned on
universe U. Then, the following properties hold
1. EO(O1 ⊓t O2) = |Bnd1∩P2|+|Bnd2∩P1|+|Bnd1∩Bnd2|
|U|
≤EO(O1) + EO(O2);
2. EO(O1 ⊔t O2) = |Bnd1∩N2|+|Bnd2∩N1|+|Bnd1∩Bnd2|
|U|
≤EO(O1) + EO(O2);
3. EO(O1), EO(O2) ≤EO(O1 ⊓N O2) ≤EO(O1) + EO(O2);
4. EO(O1), EO(O2) ≤EO(O1 ⊓P O2) ≤EO(O1) + EO(O2);
5. EO(O1 ⊔N O2) ≤min(EO(O1), EO(O2));
6. EO(O1 ⊔P O2) ≤min(EO(O1), EO(O2));
7. EO(O1), EO(O2) ≤EO(O1 ⊓I O2) ≤EO(O1) + EO(O2) + |P1∩N2|
|U|
+ |P2∩N1|
|U|
;
8. EO(O1 ⊔I O2) ≤min(EO(O1), EO(O2));
9. EO(O1 ⊙O2) = |P1∩N2|+|P2∩N1|+|Bnd1∩Bnd2|
|U|
.
Thus, we can see that aggregating two orthopairs, in some cases the uncertainty
diminishes, in some cases it augments, and in others the behaviour is unpre-
dictable, according to the changes occurring in the boundary. Namely, in cases
5,6,8 (⊔N, ⊔P , ⊔I) the resulting uncertainty is less than the uncertainty of a
single orthopair, since these operators have the eﬀect to diminish the bound-
ary. In case of 3,4 (⊓N, ⊓P ), it is less than their sum but greater than the
single orthopairs’ one. In case 1, 2 (⊓t, ⊔t), it can be either greater or lesser
than the single orthopairs, depending on their overlapping, but lesser than their
sum. In case 7 (⊓I) the resulting uncertainty is greater than the single ones,
but it can be greater or lesser that their sum, depending if they are in con-
ﬂict or not; indeed, in the case that O1, O2 are not in conﬂict we have that
(EO((P1, N1)⊓I (P2, N2)) ≤EO(O1)+EO(O2)). Finally, the uncertainty of case
9 (⊙) is in general incomparable to both EO(O1) and EO(O2), the reason is that
O1 ⊙O2 puts in the boundary all the elements that put O1 and O2 in conﬂict.

430
A. Campagner and D. Ciucci
5
Uncertainty in a Collection of Orthopairs
In the following section, we will consider contexts (in particular rough sets,
possibility distributions) in which we have a collection of orthopairs instead of
a single one. A generic approach to generalize a measure of uncertainty to a
collection O of orthopairs is to associate a probability distribution PO to the
collection O and then deﬁne the global uncertainty E(O) of the collection as a
weighted sum:
E(O) =

Oi∈O
P(Oi)EO(Oi)
(3)
The exact value of the probability and the interpretation associated to it and to
the entropy clearly depend on the context. In general, if we have no reasons to
assume that an orthopair in the collection is more probable than others, we can
assume PO as the uniform distribution. So, if we have n orthopairs deﬁned on
the same universe U, the associated entropy is E(O) =
1
n|U|
n
i=1 |Bndi|.
5.1
Rough Sets
We suppose that the collection of orthopairs represents the rough sets deﬁn-
able on a universe U based on a partition π. That is, given an approximation
space (U, π), we collect all the lower-exterior approximation pairs (l(A), e(A)) of
subsets A of U, deﬁned in the standard manner [14].
Now, given (U, π), we can, as suggested by Zhu and Wen [19], associate to
any rough approximation R(A) = (l(A), e(A)) induced by π the probability
Pi(R(A)) = ri(A)
2|U| , where ri(A) is deﬁned as the number of subsets of U repre-
sented by R(A), that is ri(A) = |{B ⊆U|R(B) = R(A)}|. We can then deﬁne
the global entropy of the partition π as the weighted sum
E(π) =
m

i=1
Pi(R(A)) · EO(R(A))
(4)
where m is the number of diﬀerent approximation pairs induced by π.
Given the standard ordering π1 ≤π2 between partitions (i.e., π1 ≤π2 iﬀ
∀C ∈π1 ∃D ∈π2 : C ⊆D), we can verify the following result:
Proposition 6. EO is isotonic w.r.t. the standard ordering between partitions,
i.e., π ≤σ →E(π) ≤E(σ).
Thus, in case of exact knowledge, where the partition is made by singletons, we
have that ri(A) = 1 for all A, and the entropy assumes the minimum value.
5.2
Possibility Distribution
We now suppose that the collection of orthopairs represents a possibility distrib-
ution. Indeed, as observed in Sect. 2 we can associate to any Boolean possibility
distribution π a set of orthopairs O∗
π.

Measuring Uncertainty in Orthopairs
431
In order to apply Eq. (3) to this particular case, we can assign to each
orthopair (Pi, Ni) = Oi ∈O∗
π a probability measure P(Oi) =
|πOi|
|πO| where
|πOi| is the number of valuation functions ω : X →[0, 1] such that ω |=
[
x∈Pi x∧
x∈Ni ¬x] and |πO| is the cardinality of the set of valuations of which
πO is the characteristic function. Thus we obtain the global uncertainty of O∗
π as:
E(O∗
π) =

Oi∈O∗
π
P(Oi)EO(Oi) =
1
|X||πO|

Oi∈Oπ
|πOi||Bnd(Oi)|
(5)
More in general given a set of orthopairs O = {O1, ..., On} (not necessar-
ily obtained from a possibility distribution) we can associate to each of these
orthopairs a probability measure P(Oi) = m(Oi)
|πO| where m(Oi) is deﬁned, as sug-
gested in [2], as m(Oi) = 
ω∈πO
χπOi (ω)

Oj ∈O χπOj (ω). We can then deﬁne the global
entropy as
E(O) =

Oi∈O
m(Oi)
|πO| EO(Oi).
(6)
Besides these deﬁnitions based on the weighted sum of Eq. (3), we can give
another deﬁnition based on the non-speciﬁcity of the associated Boolean possi-
bility distribution. At ﬁrst, given a single orthopair O we can associate to it πO
and measure its non-speciﬁcity with the Hartley measure, H(πO) = log2(|πO|) =
log2(2|BndO|) = |BndO|. Once normalized over |X| we get back the counting
measure EO of Eq. (2). Then, if O∗
π is a set of orthopairs representing a Boolean
possibility distribution in disjunctive normal form, we can easily observe that
EO(O∗
π) =
log(
O∈O∗π 2EO(O)∗|X|)
|X|
. In case of a generic set O = {O1, ..., On} of
orthopairs, this measure is an upper bound since the πOi have a non-empty
intersection, that is in general, EO(O) ≤log(n
i=1 2EO(Oi)∗|X|)
|X|
.
6
Conclusions
A preliminary study on uncertainty measures for orthopairs has been put for-
ward. In case of a single orthopair we have seen that a prominent role is played by
the counting measure EO. In case of a collection of orthopairs a generic entropy
can be deﬁned (see Eq. (3)). This measure can then be instantiated in particular
collections and the cases of rough sets and possibility distribution have been
investigated. However, the picture is far from being complete. Particular facets
of uncertainty can be studied, and we have just seen the non-speciﬁcity case on
a single orthopair. The case of conﬂict/agreement among orthopairs is another
one worth consideration, with the possibility to combine them in a consistent
orthopair. Further, we concentrated on the boundary region, another possibility
is to analyze the balance between positive and negative. Finally, in a forthcom-
ing work, we will introduce a generalized notion of partition on the space of
all orthopairs, introduce a mutual information on this partition and use it for
clustering.

432
A. Campagner and D. Ciucci
References
1. Belnap, N.: A useful four-valued logic. In: Dunn, M., Epstein, G. (eds.) Modern
Uses of Multiple Valued Logics, pp. 8–37. D. Reidel (1977)
2. Bianucci, D., Cattaneo, G.: Information entropy and granulation co-entropy of
partitions and coverings: a summary. In: Peters, J.F., Skowron, A., Wolski, M.,
Chakraborty, M.K., Wu, W.-Z. (eds.) Transactions on Rough Sets X. LNCS, vol.
5656, pp. 15–66. Springer, Heidelberg (2009). doi:10.1007/978-3-642-03281-3 2
3. Ciucci, D., Yao, Y.: Special issue on three-way decisions, orthopairs and square of
opposition. Int. J. Approximate Reasoning (2017). http://www.sciencedirect.com/
science/journal/0888613X/vsi/10WGD1MNXV4
4. Ciucci, D.: Orthopairs: a simple and widely used way to model uncertainty. Fun-
dam. Inf. 108(3–4), 287–304 (2011)
5. Ciucci, D.: Orthopairs and granular computing. Granular Comput. 1, 159–170
(2016)
6. Ciucci, D., Dubois, D., Lawry, J.: Borderline vs. unknown: comparing three-valued
representations of imperfect information. Int. J. Approximate Reasoning 55(9),
1866–1889 (2014)
7. De Luca, A., Termini, S.: A deﬁnition of a nonprobabilistic entropy in the setting
of fuzzy sets theory. Inf. Control 20(4), 301–312 (1972)
8. Dubois, D., Prade, H.: An introduction to bipolar representations of information
and preference. Int. J. Intell. Syst. 23(3), 866–877 (2008)
9. Dubois, D., Prade, H.: From Blanch´e’s hexagonal organization of concepts to formal
concept analysis and possibility theory. Log. Univers. 6, 149–169 (2012)
10. Guo, K.: Knowledge measure for Atanassov’s intuitionistic fuzzy sets. IEEE Trans.
Fuzzy Syst. 24(5), 1072–1078 (2016)
11. Klir, G.J.: Generalized information theory: aims, results, and open problems.
Reliab. Eng. Syst. Saf. 85(1–3), 21–38 (2004)
12. Lawry, J., Dubois, D.: A bipolar framework for combining beliefs about vague
propositions. In: Brewka, G., Eiter, T., McIlraith, S.A. (eds.) Principles of Knowl-
edge Representation and Reasoning: Proceedings of the Thirteenth International
Conference, pp. 530–540. AAAI Press (2012)
13. Pal, N., Bustince, H., Pagola, M., Mukherjee, U., Goswami, D., Beliakov, G.:
Uncertainties with Atanassov’s intuitionistic fuzzy sets: fuzziness and lack of knowl-
edge. Inf. Sci. 228, 61–74 (2013)
14. Skowron, A., Jankowski, A., Swiniarski, R.W.: Foundations of rough sets. In:
Kacprzyk, J., Pedrycz, W. (eds.) Springer Handbook of Computational Intelli-
gence, pp. 331–348. Springer, Heidelberg (2015)
15. Song, Y., Wang, X., Yu, X., Zhang, H., Lei, L.: How to measure non-speciﬁcity of
intuitionistic fuzzy sets. J. Int. Fuzzy Syst. 29(5), 2087–2097 (2015)
16. Szmidt, E., Kacprzyk, J.: Entropy for intuitionistic fuzzy sets. Fuzzy Sets Syst.
118(3), 467–477 (2001)
17. Yao, Y.: An outline of a theory of three-way decisions. In: Yao, J.T., Yang, Y.,
Slowi´nski, R., Greco, S., Li, H., Mitra, S., Polkowski, L. (eds.) RSCTC 2012.
LNCS (LNAI), vol. 7413, pp. 1–17. Springer, Heidelberg (2012). doi:10.1007/
978-3-642-32115-3 1
18. Zhang, H.: Entropy for intuitionistic fuzzy sets based on distance and intuitionistic
index. Int. J. Uncertainty Fuzziness Knowl. Based Syst. 21(01), 139–155 (2013)
19. Zhu, P., Wen, Q.: Information-theoretic measures associated with rough set approx-
imations. Inf. Sci. 212, 33–43 (2012)

Possibilistic Networks

Possibilistic MDL: A New Possibilistic
Likelihood Based Score Function
for Imprecise Data
Maroua Haddad1,2(B), Philippe Leray2, and Nahla Ben Amor1
1 LARODEC Laboratory ISG, Universit´e de Tunis, Tunis, Tunisia
nahla.benamor@gmx.fr
2 LINA-UMR CNRS 6241, Universit´e de Nantes, Nantes, France
maroua.haddad@gmail.com, philippe.leray@univ-nantes.fr
Abstract. Recent years have seen a surge of interest in methods for rep-
resenting and reasoning with imprecise data. In this paper, we propose a
new possibilistic likelihood function handling this particular form of data
based on the interpretation of a possibility distribution as a contour func-
tion of a random set. The proposed function can serve as the foundation
for inferring several possibilistic models. In this paper, we apply it to
deﬁne a new scoring function to learn possibilistic network structure.
Experimental study showing the eﬃciency of the proposed score is also
presented.
1
Introduction
In statistics, likelihood functions are generally viewed as adequateness functions
of a probability distribution w.r.t a set of data. They play a key role in model
inference, especially in estimating model parameters given observed data. Most
of research endeavors elaborated in this context are deﬁned in the probabilistic
framework which, for a long time, has been considered as the unique normative
model manipulating uncertain but precise information. Nevertheless, probability
theory, as good as it is, does not remain the best alternative where imprecision
is inherent in the studied domain or where we are faced to incomplete infor-
mation. Thereby, over the last ﬁve decades, a lot of eﬀort has been put into
developing new non-classical uncertainty theories and proposing methods han-
dling such imperfect data. This paper rigorously ﬁts this context by proposing a
new likelihood function in the possibilistic framework [7], one of the non-classical
uncertainty theories that has gained considerable interest in recent years. The
proposed likelihood function handles imprecise data i.e. set-valued data based on
the acknowledged interpretation of a possibility distribution as a contour func-
tion of a random set [17]. Since this form of imperfect data may arise in many
real world applications, the proposed likelihood function could be used to infer
multiple types of possibilistic/random sets models. In this paper, it represents
the key concept of proposing a new scoring function to learn possibilistic network
structure from imprecise data.
c
⃝Springer International Publishing AG 2017
A. Antonucci et al. (Eds.): ECSQARU 2017, LNAI 10369, pp. 435–445, 2017.
DOI: 10.1007/978-3-319-61581-3 39

436
M. Haddad et al.
This paper is organized as follows: Sect. 2 brieﬂy introduces the probabilistic
likelihood function. In Sect. 3, we propose a new possibilistic likelihood function
exploring the link between possibility theory and random sets theory. Section 4
deﬁnes a new likelihood based scoring function. In Sect. 5, experimental study
showing the eﬃciency of the proposed score in the context of structure learning
of possibilistic networks is proposed.
2
Probabilistic Likelihood
The likelihood function is the probability of the joint occurrence of all the given
data for a speciﬁed value of the parameter deﬁned by a probability distribution.
More formally, let us consider a set of data Di = {d(1)
i , d(2)
i , ..., d(l)
i } relative to a
variable Xi deﬁned on Di and let xik be an instance of Xi. Let pi1, pi2, ..., piri
be the parameter values of pi relative to Xi. The most used likelihood function
is the logarithmic-based likelihood (log-likelihood) deﬁned as follows:
LL(pi, Di) =
l

o=1
log(p(d(o)
i ))
(1)
If we name Nik the number of occurrences of each xik in Di i.e. the number
of times xik appears in Di: Nik = |{o s.t. xik = d(o)
i }|, the log-likelihood function
could be re-written as follows:
LL(pi, Di) =
ri

k=1
Nik log(pik)
(2)
where ri = |Di|. Note that this likelihood function has been widely used in
many domains to infer probabilistic models from precise data. Despite the fact
that most of researches of the last decades have proved that imperfection, be it
uncertainty or imprecision, is unavoidable in real world applications and must
be incorporated in information systems, only one attempt [6] has been made
to adapt the probabilistic likelihood function to imperfect data, in particular,
evidential data. This adaptation combines aleatory uncertainty captured by a
parametric statistical model with epistemic uncertainty induced by an imper-
fect observation process and represented by belief functions. A recent work [5]
has shown that this evidential adaptation of likelihood function is limited and
unsound in some situations especially, when used to estimate model parameters.
In what follows, we propose a possibilistic likelihood function which handles a
more common form of imperfect data i.e. imprecise data. This form of imperfec-
tion has gained increasing interest in recent years, in particular, in the context of
learning models from data. Note that in this paper, we do not consider the issue of
imprecision due to a small number of precise observations (see for instance [16]).
3
Possibilistic Likelihood
The main objective of this work is to propose a likelihood function that rep-
resents data as they have been collected, i.e. including imprecision due to the

A New Possibilistic Likelihood Based Score Function for Imprecise Data
437
physical measurement, in the possibilistic framework [7]. The latter is able to
oﬀer a natural and simple formal framework representing imprecise and uncertain
information. In fact, it refers to the study of maxitive and minitive set-functions
and can be interpreted as an approximation of upper and lower frequentist set
probabilities in the presence of imprecise observations. The basic building block
of possibility theory is the notion of possibility distribution π which corresponds
to a mapping from the universe of discourse Di to the unit interval [0, 1]. For any
state xik ∈Di, π(xik) = 1 means that the realization of xik is totally possible.
π(xik) = 0 means that xik is an impossible state. It is generally assumed that
at least one state xik is totally possible and π is then said to be normalized.
The particularity of the possibilistic scale is that it can be interpreted in two
ways: (i) in an ordinal manner which means that possibility degrees reﬂect only
a speciﬁc order between possible values (ii) in a numerical manner which means
that possibility degrees make sense in the ranking scale. Given a possibility dis-
tribution π, we can deﬁne for any subset A ⊆Di two dual measures: possibility
measure Π(A) = max
xik∈A π(xik) and necessity measure N(A) = 1 −Π( ¯A). The
deﬁnition of a possibility distribution could be generalized to a set of variables
V = {X1, X2, ..., Xn} deﬁned on the universe of discourse Ω = D1 × ... × Dn
encoded by π and ω ∈Ω is called interpretation or event.
The formulation of our likelihood function is made in two steps: ﬁrst, we
propose an extension of the probabilistic likelihood function based on random
sets since their deﬁnition supports naturally set-valued data. Then, we propose
its approximation in the possibilistic framework using the interpretation of a
possibility distribution π on Xi as a contour function (CFm→π) of a random
set [17] of Di. A random set of Di is a pair (F, m) where F is the family of
all focal sets i.e. Aik ⊆Di such that m(Aik) > 0. m is called basic probability
assignment or mass function and corresponds to a mapping m : 2|Di| −→[0, 1]
such that 
Aik⊆Di(m(Aik)) = 1 and m(∅) = 0. So, a possibility distribution
could be derived using the following equation:
CFm→π(xik) = π(xik) =

Aik|xik∈Aik
m(Aik)
(3)
The extension of the probabilistic log-likelihood (Eq. 2), named random set like-
lihood, consists in replacing the probability distribution by mass functions. More
formally, let us consider a set of imprecise data Di = {d(1)
i , d(2)
i , ..., d(l)
i } relative
to a variable Xi deﬁned on Di and let Aik be a focal set belonging to Di, i.e.
Aik ⊆Di. We name Nik the number of occurrences of each Aik in Di i.e. the
number of times Aik appears in Di: Nik = |{l s.t. xik = d(l)
i }|. Let mi1, mi2,
..., mirsi be the parameter values of mi relative to Xi, we deﬁne random set
log-likelihood function as follows:
mLL(mi, Di) =
rsi

k=1
Nik log(mik)
(4)

438
M. Haddad et al.
where rsi = 2|Di|. It should be noted that computing the random set log-
likelihood function is computationally expensive. In fact, a random set relative to
a variable Xi is deﬁned on 2|Di| and its cardinality grows exponentially with the
number of values in Di. To alleviate this complexity, we propose to investigate
the link between possibility theory and random sets theory expressed in Eq. 3
and we replace mass functions by possibility distributions. More formally, let us
consider a set of imprecise data Di = {d(1)
i , d(2)
i , ..., d(l)
i } relative to a variable
Xi. We name Nik the number of occurrences of each xik in Di i.e. the number
of times xik appears in Di: Nik = |{l s.t. xik ⊆d(l)
i }|. Let πi1, πi2, ..., πiri be
the parameter values of πi relative to Xi, we express the possibilistic likelihood
function as follows:
πLL(πi, Di) =
ri

k=1
Nik log(πik)
(5)
where ri = |Di|. It is evident that random set likelihood and possibilistic like-
lihood functions are not equivalent. However, possibility distributions obtained
by transforming mass functions, obtained by maximizing random sets likelihood,
using CFm→π leads to the ones obtained by directly maximizing possibilistic like-
lihood in Eq. 5 (for more details about maximizing possibilistic and random set
likelihood functions, see [12]). More formally,
Proposition 1. argmax(πLL(πik, Di)) = CFm→π(argmax(mLL(mik, Di))).
Proof. argmax(πLL(πik, Di)) =
Nik
N
=

Aik|xik∈Ai
NAik
N
= CFm→π(
NAik
N ) =
CFm→π(argmax(mLL(mik, Di))).
4
New Possibilistic-Likelihood-Based Score
πLL could be used in many research ﬁelds such as pattern recognition and
classiﬁcation. We propose here to illustrate it in an ill-explored area of research
that is learning possibilistic network structure. Before detailing its application,
we brieﬂy introduce these models and present existing learning methods.
4.1
Learning Possibilistic Networks from Data
Possibilistic networks [8] represent the possibilistic counterpart of Bayesian net-
works [13] having similarly two components: a graphical component composed of
a DAG which encodes a set of independence relations (i.e. each variable Xi ∈V is
conditionally independent of its non-descendant given its parents) and a numer-
ical component corresponding to the set of conditional possibility distributions
relative to each node Xi ∈V in the context of its parents, denoted by Pa(Xi), i.e.
π(Xi|Pa(Xi)). The two interpretations of the possibilistic scale lead naturally
to two diﬀerent ways to deﬁne possibilistic networks: product-based possibilistic
networks and min-based possibilistic networks. In this paper, we are interested

A New Possibilistic Likelihood Based Score Function for Imprecise Data
439
in product-based possibilistic networks, deﬁned in the numerical interpretation,
using the product-based conditioning expressed by:
π(ω|Φ) =

π(ω)
Π(Φ)
if ω ∈Φ
0
otherwise.
(6)
where Φ ⊆Ω. The joint distribution relative to product-based possibilistic net-
works can be computed via the following product-based chain rule
π(X1, ..., Xn) =

i=1..n
π(Xi | Pa(Xi))
(7)
Contrarily to Bayesian networks, learning possibilistic networks from data
has not been deeply studied. In fact, for the last years, learning Bayesian net-
works has been widely studied and various approaches were proposed to learn
both DAG structure and parameters. More precisely, structure learning algo-
rithms can be classiﬁed into three families: constraint-based approaches, score-
based approaches and hybrid methods. Regarding possibilistic networks, few
attempts address the problem of their learning and existing ones [2,15] are direct
adaptations of Bayesian networks learning methods without any awareness of
speciﬁcities of the possibilistic framework and of advances made concerning pos-
sibilistic networks as models of independence [1]. In fact, Sang¨uesa et al. [15] have
proposed two hybrid methods handling precise data: the ﬁrst one learns trees
and the second one learns the more general structure of DAGs. Borgelt et al. [2]
have adapted two methods initially proposed to learn Bayesian networks: K2 [4]
and maximum weight spanning tree (MWST) [3] to learn possibilistic networks
from imprecise data. These two algorithms are based on local scores to guide the
search in graph candidates. In the current work, we retain two scores, namely,
possibilistic mutual information and possibilistic χ2 measure which are direct
adaptations of probabilistic independence tests mutual information and χ2. In
fact, Borgelt et al. have shown that these adaptations lead to good structures
[2]. Given two variables Xi and Xj in V, then:
– Possibilistic mutual information is expressed by:
dmi(Xi, Xj) = −

xik∈Di
xjl∈Dj
Nik,jl
N
.log2
Nik,jl
min (Nik, Njl)
(8)
– Possibilistic χ2 measure is expressed by:
dχ2(Xi, Xj) =

xik∈Di
xjl∈Dj
(min(Nik, Njl) −Nik,jl)2
min(Nik, Njl)
(9)
Note that these scores are computed in a binary manner which ﬁt well with
MWST that generates trees. For K2 algorithm, a generalization of these scores
to more than two attributes is made as follows: given a variable Xi, all its parents

440
M. Haddad et al.
could be ombined into one pseudo-variable representing the Cartesian product of
their domains. It should be noted that none of these works is theoretically sound
and every proposed score lacks an explanation of its use and its contributions
regarding the others (for more details, see [11]). Moreover, contrarily to the
probabilistic case, none of these scores is based on likelihood and assesses the
adequateness between the learned possibilistic networks and the training dataset.
In what follows, we investigate the use of the possibilistic likelihood expressed
by Eq. 5 to propose a new scoring function based on minimum description length
(MDL) principle [14].
4.2
Possibilistic MDL
MDL principle is based on the following insight: any regularity in a given set of
data can be used to compress the data, i.e. to describe it using fewer symbols
than needed to describe the data literally [9]. More explicitly, the underlying
idea of MDL principle is that the model that best represents a data set is the
one that minimizes the sum of two terms : (i) the coding length of the model and
(ii) the data coding length when this model is used to represent this data. This
principle has been applied to deﬁne the probabilistic scoring function, named
MDL [14], to learn Bayesian networks. MDL establishes an appropriate trade-
oﬀbetween complexity and precision and is based on the following insight: the
model to be selected is the one that is best balanced in terms of simplicity
and ﬁtness of given data. In fact, it includes two terms: likelihood function to
quantify ﬁtness between the graph and the data and complexity computed via
the dimension of the graph. The latter corresponds to the sum over variables Xi
of the number of parameters required to represent p(Xi|Pa(Xi)). So, by analogy
to the probabilistic case, our possibilistic adaptation of MDL, named πMDL,
includes the likelihood function of the possibilistic network given data and its
dimension. We deﬁne these two quantities as follows:
Deﬁnition 1. The dimension of a possibilistic network G denoted by Dim(G)
is the number of parameters required to represent its conditional possibility dis-
tributions and is expressed by:
Dim(G) =
n

i=1
dim(Xi, G)
(10)
where dim(Xi, G) = |Di| ∗
Xj∈P a(Xi) |Dj|.
Deﬁnition 2. Let G be a DAG and {π1, π2, ..., πn} be the parameters relative
to {X1, X2, ..., Xn} to be estimated and Dij = {d(l)
ij } be a dataset relative to a
variable Xi and its parents Pa(Xi) = xj, d(l)
ij ⊆Dij. The number of occurrences
of each xik ∈Di such that such that Pa(Xi) = xj, denoted by Nijk, is the
number of times xijk appears in Dij: Nijk = |{l s.t. xijk ⊆d(l)
ij }|. We express
the possibilistic likelihood by:

A New Possibilistic Likelihood Based Score Function for Imprecise Data
441
πLL(π, G, D) =
n

i=1
qi

j=1
ri

k=1
Nijk log πijk
(11)
where for each Xi, qi = |Pa(Xi)|, ri = |Di|, πijk is the parameter to be estimated
when Xi = xik and Pa(Xi) = xj.
So, we deﬁne πMDL as follows:
πMDL(G|D) = πLL(π, G, D) −Dim(G)
(12)
where the conditional possibility distributions are inferred from data by maxi-
mizing πLL (for more details see [12]) and computed as follows:
ˆπ(X = xik|Pa(Xi) = xj) =
Nijk
ri
k=1 Nijk
(13)
So, MDL could be re-written as follows:
πMDL(G|D) =
n

i=1
qi

j=1
ri

k=1
Nijk log ˆπ(X = xik|Pa(Xi) = xj) −Dim(G)
(14)
4.3
Property Analysis
Most of Bayesian scores proposed in the literature satisfy two criteria: decom-
posability and Markov equivalence. In what follows, we will check if these two
criteria are satisﬁed by πMDL.
Decomposability: A score S is said to be decomposable if it can be described in
terms (generally a sum) of local scores i.e. depending only on a node and all its
parents. πMDL is decomposable as follows:
πMDL(G|D) =
n

i=1
πmdl(Xi|Pa(Xi))
(15)
where πmdl(Xi|Pa(Xi)) = πLL(Xi|Pa(Xi), D) −Dim(Xi, G).
Markov equivalence: A score is said to be Markov equivalent if it assigns the
same value to two equivalent graphs. Two DAGs are equivalent if and only if they
have the same skeleton (the skeleton of a directed graph is the same underlying
undirected graph) and the same v-structures (Xi →Xj ←Xk). Contrarily to
the case of the probabilistic MDL, πMDL does not satisfy Markov equivalence
as shown by the following example:

442
M. Haddad et al.
Table 1. Example of an imprecise dataset
X1
X2
nb of occurrences
x12
x22
3
x12
x21, x22 3
x11, x12 x22
3
x11
x21, x22 1
Example 1. Let us consider the imprecise dataset D in Table 1, the two Markov
equivalent graphs composed of two variables X1 and X2 (G1: X1 →X2 and G2:
X1 ←X2 ).
πMDL(G1|D) = 4 log(0.4) + 9 log(0.9) + log(0.25) + 4 log(1) + 3 log( 1
3) +
9 log(1) −6 = −10.03.
πMDL(G2|D) = 4 log(0.4) + 10 log(1) + log(0.25) + 3 log(0.75) + 4 log(0.4) +
9 log(0.9) −6 = −11.10.
Now, to learn possibilistic network structure, we propose to adapt greedy
search algorithm initially proposed to learn Bayesian network structure using
πMDL. Greedy search algorithm is an iterative method which given an initial
DAG (an empty DAG, randomly generated network or the tree obtained by
MWST algorithm), generates all neighbor structures obtained after performing
one of elementary operation, i.e., adding, deleting or reversing an edge. Then,
it computes obtained neighbors structures scores using πMDL and picks the
operation that leads to the structure having the highest score. This process is
repeated until the already obtained structure has a higher score than DAGs
in the list of neighbors. Note that the decomposability property satisﬁed by our
score πMDL allows us to eﬃciently evaluate the elementary operators performed
by greedy search. In fact, it reduces the number of calculations by locally esti-
mating the change in the score between two neighboring structures, instead of
recalculating entirely to the new structure. Note also that the non satisfaction
of Markov equivalence property deprives to perform greedy search in an eﬃcient
way, i.e., by reducing the search space from DAGs space to CPDAGs (graph
representative of Markov equivalence class) space.
5
Experimental Study
To evaluate πMDL, we use the evaluation strategy proposed for product-based
possibilistic networks learning algorithms [10] described in Fig. 1. More pre-
cisely, we generate 20 possibilistic networks (10 with 10 variables and 10 with
20 variables) to derive 60 synthetic datasets containing 1000 imprecise observa-
tions. We also vary the maximum number of parents between 2 and 4 and the
maximum number of variable domain cardinality between 2 and 51. Using the
1 Used
benchmarks
are
publicly
available
in:
https://sites.google.com/site/
karimtabiasite/mappos.

A New Possibilistic Likelihood Based Score Function for Imprecise Data
443
Fig. 1. Evaluation process of possibilistic networks learning algorithms
generated networks, we apply existing possibilistic learning structure algorithms
which handle imprecise data, i.e. the possibilistic adaptation of k2 (πK2) [2]2,
the Maximum Weight Spanning Tree (πMWST) [2] and our approach which
combines greedy search (πGS) and πMDL. In order to better appreciate the
impact of πMDL, we also propose to test πGS with other scores i.e. sum over
V of the local scores dχ2 and dmi, denoted respectively by 
dχ2 and 
dmi.
Then, we compare the learned and the initial possibilistic networks using the
editing distance [18] which corresponds to the number of operations required to
transform a learned possibilistic network DAG into the initial one (add, reverse
or delete an edge increases the editing distance by 1). Table 2 presents the aver-
age of obtained results. Unsurprisingly, πGS combined with πMDL outperforms
the remaining learning algorithms (i.e. πK2 and πMWST). Indeed, this result
reaﬃrms the quality of greedy search already observed in the probabilistic frame-
work in learning Bayesian networks. Moreover, using πGS with πMDL is better
than combining it with 
dχ2 and 
dmi and this result is in coherence with a
previous work on parameters learning in possibilistic networks [12] using πLL
from which we derive πMDL.
Table 2. Editing distance between initial and learned networks
n
10
20
πGS + πMDL
19.77 +/−1.5 31.55 +/−2.92
πGS + 
dχ2
28.83 +/−2.32
51.66 +/−1.33
πGS + 
dmi
35.66 +/−2.06
49.55 +/−1.41-
πMWST + dχ2
23.44 +/−1.63
47.33 +/−0.88
πMWST + dmi 22.77 +/−1.6
47.55 +/−1.41
π K2 + dχ2
27.44 +/−2.95
42.22 +/−6.87
πK2 + dmi
28.38 +/−4.53
42.77 +/−5.66
2 Since πK2 handles variables in a predeﬁned order, so, we generate 5 orders in each
experiment and we retain the best structure.

444
M. Haddad et al.
6
Conclusion
In this paper, we propose two likelihood functions, namely, random set likelihood
function which represents an extension of the probabilistic one and handles set-
valued data, and possibilistic likelihood function which is an approximation of
the ﬁrst one based on the interpretation of a possibility distribution as a countour
function of a random set. This approximation could be applied to infer diﬀerent
types of possibilistic models. In this study, it represents the basis of deﬁning a
new possibilistic score πMDL to learn possibilistic network structure. Proposed
experimental study shows that πMDL combined with greedy search outperforms
existing learning algorithms. Such results are preliminary and clearly deserve
more investigations but encouraging. A further comparative study on a large
number of benchmarks and problems using other evaluation measures will be
needed to really evaluate the eﬃciency of the proposed score. Moreover, it will
be interesting to evaluate the impact of non-satisfaction of Markov equivalence
property on the learned possibilistic network structure quality.
References
1. Ben Amor, N., Benferhat, S.: Graphoid properties of qualitative possibilistic inde-
pendence relations. Int. J. Uncertainty, Fuzziness Knowl.-Based Syst. 13(01), 59–96
(2005)
2. Borgelt, C., Kruse, R.: Operations and evaluation measures for learning possibilis-
tic graphical models. Artif. Intell. 148(1), 385–418 (2003)
3. Chow, C., Liu, C.: Approximating discrete probability distributions with depen-
dence trees. IEEE Trans. Inf. Theory 14(3), 462–467 (1968)
4. Cooper, G.F., Herskovits, E.: A Bayesian method for the induction of probabilistic
networks from data. Mach. Learn. 9(4), 309–347 (1992)
5. Couso, I., Dubois, D.: Maximum likelihood under incomplete information: toward
a comparison of criteria. In: Ferraro, M.B., Giordani, P., Vantaggi, B., Gagolewski,
M., Gil, M.´A., Grzegorzewski, P., Hryniewicz, O. (eds.) Soft Methods for Data
Science. AISC, vol. 456, pp. 141–148. Springer, Cham (2017). doi:10.1007/
978-3-319-42972-4 18
6. Denoeux, T.: Maximum likelihood estimation from uncertain data in the belief
function framework. IEEE Trans. knowl. data Eng. 25(1), 119–130 (2013)
7. Dubois, D., Prade, H.: Possibility Theory. Springer, Berlin (1988)
8. Fonck, P.: Propagating uncertainty in a directed acyclic graph. In: Proceedings of
the Fourth Information Processing and Management of Uncertainty Conference,
92, 17–20 (1992)
9. Gr¨unwald, P.D.: Theory and applications: advances in minimum description length,
Mdl tutorial (2005)
10. Haddad, M., Leray, P., Amor, N.B.: Evaluating product-based possibilistic
networks learning algorithms. In: Proceedings of Symbolic and Quantitative
Approaches to Reasoning with Uncertainty, pp. 312–321 (2015)
11. Haddad, M., Leray, P., Amor, N.B.: Learning possibilistic networks from data : a
survey. In: 16th World Congress of the International Fuzzy Systems Association
and the 9th Conference of the European Society for Fuzzy Logic and Technology,
pp. 194–201 (2015)

A New Possibilistic Likelihood Based Score Function for Imprecise Data
445
12. Haddad, M., Leray, P., Levray, A., Tabia, K.: Possibilistic networks parameter
learning: Preliminary empirical comparison. In: 8`emes journ´ees francophones de
r´eseaux bay´esiens (JFRB 2016), (2016)
13. Pearl, J.: Probabilistic Reasoning in Intelligent Systems: Networks of Plausible
Inference. Morgan Kaufmann, San Francisco (1988)
14. Rissanen, J.: Modeling by shortest data description. Automatica 14(5), 465–471
(1978)
15. Sang¨uesa, R., Cab´os, J., Cortes, U.: Possibilistic conditional independence: A
similarity-based measure and its application to causal network learning. Int. J.
Approximate Reasoning 18(1), 145–167 (1998)
16. Serrurier, M., Prade, H.: An informational distance for estimating the faithfulness
of a possibility distribution, viewed as a family of probability distributions, with
respect to data. Int. J. Approximate Reasoning 54(7), 919–933 (2013)
17. Shafer, G.: A mathematical Theory of Evidence, vol. 1. Princeton University Press,
Princeton (1976)
18. Shapiro, L.G., Haralick, R.M.: A metric for comparing relational descriptions.
IEEE Trans. Pattern Anal. Mach. Intell. 1(1), 90–94 (1985)

Probabilistic Logics, Probabilistic
Reasoning

The Complexity of Inferences and Explanations
in Probabilistic Logic Programming
Fabio G. Cozman1(B) and Denis D. Mau´a2
1 Escola Polit´ecnica, Universidade de S˜ao Paulo, S˜ao Paulo, Brazil
fgcozman@usp.br
2 Instituto de Matem´atica e Estat´ıstica, Universidade de S˜ao Paulo,
S˜ao Paulo, Brazil
Abstract. A popular family of probabilistic logic programming lan-
guages combines logic programs with independent probabilistic facts.
We study the complexity of marginal inference, most probable explana-
tions, and maximum a posteriori calculations for propositional/relational
probabilistic logic programs that are acyclic/deﬁnite/stratiﬁed/normal/
disjunctive. We show that complexity classes Σk and PPΣk (for various
values of k) and NPPP are all reached by such computations.
1
Introduction
The goal of this paper is to shed light on the computational complexity of infer-
ence for probabilistic logic programs interpreted in the spirit of Sato’s distri-
bution semantics [25]; that is, we have logic programs where some facts are
annotated with probabilities, so as to deﬁne probability distributions over mod-
els. This framework has been shown to be quite useful in modeling practical
problems [15,24].
The distribution deﬁned by a probabilistic logic program can be used to
answer many queries of interest. Two common queries are to compute the prob-
ability of some ground atom given evidence (inference), and to ﬁnd a (partial)
interpretation that maximizes probability while being consistent with evidence
(MPE/MAP).
We present results on the complexity of acyclic, deﬁnite, stratiﬁed, normal
and disjunctive probabilistic logic programs; these results are summarized by
Table 1. While most semantics agree on stratiﬁed programs, there is less con-
sensus on non-stratiﬁed programs. Here we examine two semantics: the credal
semantics, based on stable models, and the well-founded semantics.
We start in Sects. 2 and 3 by reviewing relevant background on probabilistic
logic programs and on complexity theory. Our contributions appear in Sect. 4.
These results are further discussed in the concluding Sect. 5.
2
Background
The results in this paper depend on an understanding of logic and answer set
programming; the topic is dense and cannot be described in detail in the space
c
⃝Springer International Publishing AG 2017
A. Antonucci et al. (Eds.): ECSQARU 2017, LNAI 10369, pp. 449–458, 2017.
DOI: 10.1007/978-3-319-61581-3 40

450
F.G. Cozman and D.D. Mau´a
Table 1. Summary of complexity results presented in this paper (all entries indicate
completeness with respect to many-one reductions). Entries containing known results
have orange background (grey background if printed in black-and-white) [6–8].
Propositional
Bounded arity
Inferential MPE MAP Inferential MPE MAP
Acyclic normal
PP
NP
NPPP
PPNP
ΣP
2
NPPP
Deﬁnite (positive query)
PP
NP
NPPP
PPNP
ΣP
2
NPPP
Stratiﬁed normal
PP
NP
NPPP
PPNP
ΣP
2
NPPP
Normal, credal
PPNP
ΣP
2
NPPP
PPΣP
2
ΣP
3
NPPP
Normal, well-founded
PP
NP
NPPP
PPNP
ΣP
2
NPPP
Disjunctive, credal
PPΣP
2
ΣP
3
NPPP
PPΣP
3
ΣP
4
NPPP
we have here. We just mention the main concepts, and refer the reader to any
in-depth presentation in the literature [9,14].
We have a vocabulary consisting of predicates, constants, and logical variables;
a term is a constant or logical variable, and an atom is a predicate of arity k
associated with k terms; a ground atom is an atom without logical variables. We
often resort to grounding to produce ground atoms. A disjunctive logic program
(dlp) consists of a set of rules written as
A1 ∨· · · ∨Ah : −B1, . . . , Bb′, not Bb′+1, . . . , not Bb.
where each Ai and Bi is an atom. The lefthand side is the head of the rule; the
remainder is its body. A rule without disjunction (i.e., h = 1) and with empty
body, written simply as A1., is a fact. A program without disjunction is a normal
logic program; a normal logic program without negation is a deﬁnite program;
ﬁnally, a program without variables is a propositional program. The dependency
graph of a program is the graph where each atom is a vertex and there are arcs
from atoms in the bodies to atoms in the heads of a same rule; a normal logic
program is acyclic when the dependency graph of its grounding is acyclic. A
normal logic program is (locally) stratiﬁed when the dependency graph of its
grounding has no cycles containing an arc involving a negated literal.
The Herbrand base of a program is the set of all ground atoms built from
constants and predicates in the program. An interpretation is a set of ground
literals mentioning exactly once each atom in the Herbrand base. A model is
an interpretation that satisﬁes every grounding of a rule (a rule is satisﬁed iﬀ
the interpretation contains all of B1, . . . , Bb′, none of Bb′+1, . . . , Bb, and some
of A1, . . . , Ah). A minimal model minimizes the number of non-negated literals.
The most common semantics for dlps is the stable model semantics. Given a
program P and an interpretation I, deﬁne their reduct to be program obtained by
removing from P every rule whose body is not satisﬁed by I. An interpretation
is a stable model if it is a minimal model of its reduct. A normal program may
have zero, one or several stable models. Brave reasoning asks whether there is

The Complexity of Inferences and Explanations
451
a stable model containing a speciﬁc literal (possibly returning one). Cautious
reasoning asks whether a speciﬁc literal appears in all stable models (possibly
listing all).
Here is an example: Several robots can perform, each, one of three operations,
called “red”, “green”, “yellow”. A robot placed in a site also covers adjacent sites,
so there is no need to place same-color robots on adjacent sites. There is a list of
robots and a list of (one-way) connections between sites; the goal is to distribute
the robots and verify whether the sites are connected. This disguised 3-coloring
problem can be encoded as [14]:
color(X, red) ∨color(X, green) ∨color(X, yellow) : −site(X).
clash : −not clash, edge(X, Y ), color(X, C), color(Y, C).
path(X, Y ) : −edge(X, Y ).
path(X, Y ) : −edge(X, Z), path(Z, Y ).
We might have a database of facts, consisting of a list of sites and their connec-
tions, say site(s1), site(s2), . . . , edge(s1, s4), and so on. Each stable model of this
program is a possible placement (a 3-coloring) and a list of paths between sites.
An alternative semantics for normal logic programs is the well-founded
semantics; a model under this semantics might ﬁx only a truth-value for some
of the atoms (leaving the remaining atoms undeﬁned) [30]. One way to deﬁne
the well-founded semantics is as follows [4]. Write LFTP(I) to mean the least
ﬁxpoint of TPI, where TP is a transformation such that: atom A is in TP(I) iﬀ
there is grounded rule with head A with the whole body true in interpretation
I. Then the well-founded semantics of P consists of those atoms A that are in
the least ﬁxpoint of LFTP(LFTP(·)) plus the literals ¬A for those atoms A that
are not in the greatest ﬁxpoint of LFTP(LFTP(·)).
We also need standard concepts from complexity theory: languages (sets of
strings), decision problems (deciding whether input is in language), complex-
ity classes (sets of languages), many-one reductions [22]. We use well-known
complexity classes such as P, NP, PP. We also consider oracle machines and
corresponding complexity classes such as ΠP
i and ΣP
i (the so-called polynomial
hierarchy). We also use Wagner’s polynomial counting hierarchy deﬁned as the
smallest set of classes containing P and, recursively, for any class C in the poly-
nomial counting hierarchy, the classes PPC, NPC, and coNPC [29,31].
3
Probabilistic Logic Programming
In this paper we focus on a particularly simple combination of logic programming
and probabilities [23,25]. A probabilistic disjunctive logic program, abbreviated
pdlp, is a pair ⟨P, PF⟩consisting of a disjunctive logic program P and a set
of probabilistic facts PF. A probabilistic fact is a pair consisting of an atom
A and a probability value α, written as α :: A. [15]. Note that we allow a
probabilistic fact to contain logical variables. As an instance of pdlp, take our
running example on robots and sites: to generate a random graph over a set of
ﬁve sites add the rules: 0.5 :: edge(X, Y )., site(s1)., site(s2)., site(s3)., site(s4).,
site(s5).. If P is a normal logic program, we just write probabilistic logic program,

452
F.G. Cozman and D.D. Mau´a
abbreviated plp. If P is normal and acyclic/deﬁnite/stratiﬁed, we say the plp
is acyclic/deﬁnite/stratiﬁed.
To build the semantics of a pdlp, we ﬁrst take its grounding. From a pdlp
with n ground probabilistic facts, we can generate 2n dlps: for each probabilistic
fact α :: A., either keep fact A. with probability α, or erase A. with probability
1 −α. A total choice is a subset of the set of ground probabilistic facts that is
selected to be kept (other grounded probabilistic facts are discarded). For any
total choice θ we obtain a dlp P∪PF↓θ with probability 
Ai∈θ αi

Ai̸∈θ(1−αi).
The distribution over total choices induces a distribution over dlps.
We ﬁrst deﬁne a semantics proposed by Lukasiewicz [18,19]. A probability
model for a pdlp ⟨P, PF⟩is a probability measure P over interpretations, such
that (i) every interpretation I with P(I) > 0 is a stable model of P ∪PF↓θ
for the total choice θ that agrees with I on the probabilistic facts; and (ii) the
probability of a total choice θ is P(θ) = 
Ai∈θ αi

Ai̸∈θ(1 −αi). The set of all
probability models for a pdlp is the semantics of the program; note that if a
pdlp does not have stable models for some total choice, there is no semantics for
it (the program is inconsistent). Because a set of probability measures is often
called a credal set [2]; we adopt the term credal semantics.
If P is deﬁnite, then P ∪PF↓θ is deﬁnite for any θ, and P ∪PF↓θ has a
unique minimal model that is also its unique stable/well-founded model. Thus
the distribution over total choices induces a single probability model. This is
Sato’s distribution semantics [25]. Similarly, suppose that P is acyclic or strati-
ﬁed; then P ∪PF↓θ is respectively acyclic or stratiﬁed for any θ, and P ∪PF↓θ
has a unique stable model that is also its unique well-founded model [1].
Given a consistent pdlp whose credal semantics is the credal set K, we
may be interested in computing lower conditional probabilities, deﬁned as
P(Q|E) = infP∈K:P(E)>0 P(Q|E) or upper conditional probabilities, deﬁned as
P(Q|E) = supP∈K:P(E)>0 P(Q|E), where Q and E are consistent set of liter-
als. Note that we leave conditional lower/upper probabilities undeﬁned when
P(E) = 0 (that is, when P(E) = 0 for every probability model).
Consider again our running example. Suppose we have a graph over ﬁve sites,
with edges (to save space, e means edge):
0.5 :: e(s4, s5).
e(s1, s3).
e(s1, s4).
e(s2, s1).
e(s2, s4).
e(s3, s5).
e(s4, s3)..
That is, we have an edge e(s4, s5) which appears with probability 0.5. If this edge
is kept, there are 6 stable models; if it is discarded, there are 12 stable models.
If additional facts color(s2, red). and color(s5, green). are given, then there is a
single stable model if edge(s4, s5) is kept, and 2 stable models if it is discarded.
Then, P(color(s4, green)) = 0 and P(color(s4, green)) = 1/2.
A diﬀerent semantics is deﬁned by Hadjichristodoulou and Warren [17] for
normal plps: they allow probabilities directly over well-founded models, thus
allowing probabilities over atoms that are undeﬁned. That is, given a plp
⟨P, PF⟩, associate to each total choice θ the unique well-founded model of
P∪PF↓θ to θ; the unique distribution over total choices induces a unique distri-
bution over well-founded models. To conclude, we note that one can ﬁnd other
semantics in the literature that serve deserve further study [3,5,18,21,26].

The Complexity of Inferences and Explanations
453
4
Complexity Results
We consider three diﬀerent problems in this paper: (marginal) inference, most
probable explanation (MPE), and maximum a posteriori (MAP).
In the following problem deﬁnitions a pdlp ⟨P, PF⟩is always speciﬁed using
rational numbers as probability values, and with a bound on the arity of pred-
icates (so the Herbrand base is always polynomial in the input size). A query
(Q, E) is always a pair of sets of consistent literals (consistent here means that
the set does not contain both a literal and its negation). The set E is called evi-
dence. The symbol M denotes a set of atoms in the Herbrand base of the union
of the program P and all the facts in PF. The symbol γ is always a rational
number in [0, 1].
The inferential complexity of a class of pdlps is the complexity of the fol-
lowing decision problem: with input equal to a pdlp ⟨P, PF⟩, a query (Q, E),
and a number γ, the output is whether or not P(Q|E) > γ; by convention, the
input is rejected if P(E) = 0.
The MPE complexity of a class of pdlps is the complexity of the following
decision problem: with input equal to a pdlp ⟨P, PF⟩, evidence E, and a number
γ, the output is whether or not there is an interpretation I that agrees with E
and satisﬁes P(I) > γ.
The MAP complexity of a class of pdlps is the complexity of the following
decision problem: with input equal to a pdlp ⟨P, PF⟩, a set M, and a number
γ, the output is whether or not there is a consistent set of literals Q mentioning
all atoms in M such that P(Q|E) > γ; by convention, the input is rejected if
P(E) = 0.
The contributions of this paper are summarized by Table 1. Darker entries are
already known [6–8], and some entries on acyclic plps can also be found in work
by Ceylan et al. [5]. All entries in this table indicate completeness with respect
to many-one reductions. In this section we prove these facts through a series of
results.1 In all proofs the argument for membership depends on the complexity of
logical reasoning on logic programs that are obtained by ﬁxing all total choices;
this suﬃces to even make decisions concerning conditional probabilities (using
for instance techniques by Park [10, Theorem 11.5]).
Theorem 1. The MPE complexity of acyclic propositional plps is NP-hard, and
of stratiﬁed propositional plps is in NP. The MPE complexity of acyclic plps is
ΣP
2 -hard, and of stratiﬁed plps is in ΣP
2 .
Proof. Membership for stratiﬁed propositional plps: “guess” a polynomial-sized
interpretation consistent with evidence, and then decide if its probability exceeds
a given threshold in polynomial time (by checking the stable model [12, Table 4]).
Hardness: use acyclic propositional plps to encode Bayesian networks [11].
1 IMPORTANT NOTE: Due to space restrictions; we only present proof sketches;
the reader can ﬁnd the complete proofs at http://sites.poli.usp.br/p/fabio.cozman/
Publications/Article/cozman-maua-ecsqaru2017.pdf.

454
F.G. Cozman and D.D. Mau´a
To prove membership for stratiﬁed plps, note that deciding whether a given
interpretation is a stable model of a stratiﬁed logic program can be reduced
to an instance of cautious reasoning. Hence, we can “guess” an interpretation
consistent with evidence, then decide whether it is a stable model using a PNP
oracle [12, Table 5]. To obtain ΣP
2 -hardness, use an encoding employed by Eiter
et al. [12]. Suppose we have formula φ = ∃X : ¬∃Y : ϕ(X, Y), where ϕ(X, Y) is
a propositional formula in 3CNF with sets X and Y of propositional variables.
Deciding satisﬁability of such formulas is a ΣP
2 -complete problem [27]. Introduce
0.5 :: x. with predicate x for each x in X. A clause c in ϕ contains k ∈{0, . . . , 3}
propositional variables from Y. Introduce a predicate c of arity k, and for each
predicate c introduce a set of rules: For each one of the 2k groundings y′ of the
logical variables Y′ in c, if y′ satisﬁes c (for all assignments of X), introduce a
fact c(y′).; if y′ does not satisfy c (for some assignment of X), introduce 3 −k
rules of the form c(y′) : −[not] x., where not appears in the rule depending
on whether x is preceded by negation or not in the clause c. The formula ϕ is
encoded by the rule cnf : −c1, c2, . . . . (conjunction extends over all clauses).
Then the MPE with evidence {¬cnf} and threshold γ = 0 decides whether φ
is satisﬁable.
□
As deﬁnite programs are stratiﬁed, they are already covered by previous
results. However, it makes sense to assume that any query with respect to such
a program will also be positive in the sense that it only contains non-negated
literals. Even then we have the same complexity as stratiﬁed programs:
Theorem 2. Assume all queries are positive. The inferential complexity of def-
inite propositional plps is PP-complete, and of deﬁnite plps is PPNP-complete.
The MPE complexity of deﬁnite propositional plps is NP-complete, and of deﬁ-
nite plps is ΣP
2 -complete.
Proof. Membership follows from results for stratiﬁed plps [7]. To show hardness
for propositional programs, consider a 3CNF formula ϕ over variables x1, . . . , xn,
and obtain a new monotone formula ˜ϕ by replacing every literal ¬xi by a fresh
variable yi. Now the formula ϕ has M satisfying ssigments iﬀthe formula ˜ϕ ∧
(
i xi ∨yi)∨
i(xi ∧yi) has M +22n −3n satisfying assignments [16, Proposition
4]. The latter formula is monotone (i.e., contains no negated variables), so we
can encode it as a deﬁnite program using probabilistic facts 0.5 :: x. to represent
each logical variable, ci to represent clauses, and cnf to represent the value of
the formula. To decide whether the number of solutions of ϕ exceeds M, verify
whether P(cnf) > (22n −3n +M)/22n. To decide if there is a solution, decide the
MPE with evidence {cnf} and threshold 22n −3n. The same reasoning applies
to deﬁnite plps, by building existential quantiﬁcation over part of the variables
as in the proof of Theorem 1.
□
Non-stratiﬁed programs climb one step up in the polynomial hierarchy:
Theorem 3. Assume the credal semantics for plps. The MPE complexity of
propositional plps is ΣP
2 -complete, and of plps is ΣP
3 -complete.

The Complexity of Inferences and Explanations
455
Proof. Adapt the proof of Theorem 1, as follows. For the propositional case,
membership obtains as cautious reasoning is coNP-complete [12, Table 2], and
ΣP
2 -hardness obtains by encoding a formula φ = ∃X : ∀Y : ϕ(X, Y), where
ϕ(X, Y) is a propositional formula in 3DNF. Encode each x ∈X as before, and
introduce yi and nyi for each yi in Y, together with rules yi : −not nyi. and
nyi : −not yi.. Then encode ϕ by rules dnf := dj (where each dj is a conjunct
of ϕ); the MPE of this program with evidence {dnf} and threshold 0 decides
whether φ is satisﬁable (the “inner” universal quantiﬁer is “produced” by going
over all stable models when doing cautious reasoning). For the arity-bounded
case, membership obtains as cautious reasoning is ΠP
2 -complete [12, Table 5],
and ΣP
3 -hardness obtains by a combination of strategies used in the proof of
Theorem 1 and in the proof for propositional plps. That is, encode a formula
φ = ∃X : ∀Y : ∃Z : ϕ(X, Y, Z), where ϕ is in CNF.
□
Now consider inferential complexity under the credal semantics, for pdlps.
The credal semantics of a pdlp is a credal set that dominates an inﬁnite
monotone Choquet capacity [6]. This result is important because it implies
that P(M) = 
θ∈Θ:Γ (θ)⊆M P(θ) and P(M) = 
θ∈Θ:Γ (θ)∩M̸=∅P(θ), where Θ
is the set of total choices and Γ maps a total choice to the set of resulting sta-
ble models. Also, we have that P(A|B) = P(A ∩B) /(P(A ∩B) + P(Ac ∩B))
whenever P(A ∩B) + P(Ac ∩B) > 0; otherwise, either P(A|B) = 1 when
P(A ∩B) + P(Ac ∩B) = 0 and P(A ∩B) > 0, or P(A|B) is undeﬁned. Similarly,
P(A|B) = P(A ∩B) /(P(A ∩B) + P(Ac ∩B)), when P(A ∩B) + P(Ac ∩B) > 0,
with similar special cases. Using these results we see that computing lower and
upper probabilities can be reduced to going through the total choices and run-
ning brave/cautious inference for each total choice [6].
Theorem 4. Assume the credal semantics for pdlps. The inferential complexity
of propositional pdlps is PPΣP
2 -complete, and of pdlps is PPΣP
3 -complete.
Proof. To prove membership for propositional pdlps, note that once a total
choice is guessed, the cost of checking whether a set of literals holds under
cautious reasoning is in ΠP
2 [12, Table 2]. To obtain PPΣP
2 -hardness, consider a
formula φ(X) = ∀Y : ¬∀Z : ϕ(X, Y, Z), where ϕ(X, Y, Z) is a propositional
formula in 3DNF with conjuncts dj and sets of propositional variables X, Y,
and Z. Deciding whether the number of truth assignments to X that satisfy the
formula is strictly larger than an integer M is a PPΣP
2 -complete problem [31,
Theorem 7]. To emulate counting, introduce a predicate xi for each propositional
variable xi in X, associated with a probabilistic fact 0.5 :: xi.. And to encode
φ(X), we combine the use of stable sets as in the proof of Theorem 3 with an
adapted version of a proof by Eiter and Gottlob [13] on disjunctive programming.
We focus on the latter construction here. Introduce predicates zi and nzi for each
propositional variable zi in Z, and auxiliary predicate w, together with the rules
zi ∨nzi., zi : −w., and nzi : −w. for each zi in Z, plus the rule w : −L1
j, L2
j, L3
j. for
each conjunct dj, where Lr
j is obtained from L, the rth literal of dj, as follows:
(1) if L = zi, then Lr
j = zi; (2) if L = ¬zi, then Lr
j = nzi; (3) if L = xi, then

456
F.G. Cozman and D.D. Mau´a
Lr
j = xi; (4) if L = ¬xi, then Lr
j = not xi; (5) if L = yi, then Lr
j = yi; (6) if
L = ¬yi, then Lr
j = not yi. Finally, introduce nw : −not w.. Now reason as
follows. To decide whether P(nw = true) > γ, we must go through all possible
total choices; each one of them has probability 2−n where n is the length of
X. For each total choice, we must run cautious inference; this is done by going
through all stable models, and verifying whether nw is true in all of them. For
each truth assignment of Y, the program has a stable model where w is true iﬀ
for all truth assignments of Z we have that ϕ holds [13, Theorem 3.2]. Hence
for ﬁxed y, resulting stable models have nw as true iﬀ∀Z : ϕ(x, y, Z) is false
(x is ﬁxed by the selected total choice). Thus if we take γ = M/2−n, we obtain
that P(nw = true) > γ decides whether φ(X) has a number of satisfying truth
assignments of X that is strictly larger than M.
To prove membership for pdlps, note that once a total choice is guessed, the
cost of checking whether a set of literals holds under cautious reasoning is in
ΠP
3 [12, Table 5]. To obtain PPΣP
3 -hardness, we use a combination of strategies
used in the proof of Theorem 1 and in the proof for propositional plps (previous
paragraph) to encode a formula φ(X) = ∀Y : ¬∀Z : ∃V : ϕ(V, X, Y, Z).
□
Theorem 5. Assume the credal semantics for pdlps. The MPE complexity of
propositional pdlps is ΣP
3 -complete, and of pdlps is ΣP
4 -complete.
Proof. Membership and hardness are proved by adapting arguments in the proofs
of Theorems 3 and 4, using the complexity of cautious reasoning [12, Tables 2
and 5], and encodings of DNF and CNF formulas as before.
□
Theorem 6. Assume the well-founded semantics for plps. The MPE complex-
ity of propositional plps is NP-complete, and of plps is ΣP
2 -complete.
Proof. Hardness follows from Theorem 1 (in both cases). Membership: use the
argument in the proof of Theorem 1, employing complexity of logical inference
of propositional case [9] and the bounded-arity case [8] as appropriate.
□
Theorem 7. Assume the credal semantics both for plps and for pdlps. The
MAP complexity of propositional plps is NPPP-hard, and of pdlps is in NPPP.
Proof. Hardness: a propositional plp can encode a Bayesian network with binary
variables, and MAP in such networks is NPPP-complete [11]. To show member-
ship, reason in two steps: one can solve MAP by ﬁrst guessing literals for the
MAP-predicates that are not ﬁxed by evidence, and then running inference in
an PPΣP
3 oracle. That is, the decision problem is in NPPPΣP
3 . Now resort to a
theorem by Toda and Watanabe [28] that shows that, for any k, PPPΣP
k collapses
to PPP, to note that the decision problem of interest is in NPPP.
□
Theorem 8. Assume the credal semantics for plps and positive queries. The
MAP complexity of deﬁnite propositional plps is NPPP-hard, and of plps is in
NPPP.
Proof. Membership:
Theorem
7.
Hardness:
MAP
for
Bayesian
networks
described without negation is already NPPP-hard [20, Theorem 5].
□

The Complexity of Inferences and Explanations
457
5
Conclusion
As conveyed by Table 1, we have presented several novel results concerning the
complexity of probabilistic logic programming, both analyzing conditional prob-
abilities (inferences) and explanations (MPE and MAP)—we note that previ-
ous work has not examined these latter problems in the context of probabilistic
logic programming. These computations go up several layers within the counting
hierarchy, reaching some interesting complexity classes that are rarely visited.
In particular, MAP is always NPPP-complete, a rather interesting result.
A future step is to obtain the complexity of relational programs without
bounds on arity (exponential complexity is sure to appear), and perhaps the
complexity of programs with functions (with suitable restrictions to guarantee
decidability). The complexity of other constructs, such as aggregates, should
also be explored. Future work should look at “query” complexity; that is, the
complexity of computing inferences when the program is ﬁxed and the query
varies—this is akin to data complexity as studied in database theory [7].
Acknowledgements. The ﬁrst author is partially supported by CNPq, grant
308433/2014-9. The second author received support from the S˜ao Paulo Research Foun-
dation (FAPESP), grant 2016/01055-1. The work reported in this paper was partially
funded by FAPESP grant #2015/21880-4 (project Proverbs).
References
1. Apt, K.R., Bezem, M.: Acyclic programs. New Gener. Comput. 9, 335–363 (1991)
2. Augustin, T., Coolen, F.P.A., de Cooman, G., Troﬀaes, M.C.M.: Introduction to
Imprecise Probabilities. Wiley, USA (2014)
3. Baral, C., Gelfond, M., Rushton, N.: Probabilistic reasoning with answer sets.
Theor. Pract. Logic Program. 9(1), 57–144 (2009)
4. Baral, C., Subrahmanian, V.: Dualities between alternative semantics for logic
programming and nonmonotonic reasoning. J. Autom. Reason. 10(3), 399–420
(1993)
5. Ceylan, ´I.´I, Lukasiewicz, T., Pe˜naloza, R.: Complexity results for probabilistic
Datalog±. In: European Conference on Artiﬁcial Intelligence, pp. 1414–1422 (2016)
6. Cozman, F.G., Mau´a, D.D.: The structure and complexity of credal semantics. In:
Workshop on Probabilistic Logic Programming, pp. 3–14 (2016)
7. Cozman, F.G., Mau´a, D.D.: Probabilistic graphical models speciﬁed by proba-
bilistic logic programs: semantics and complexity. In: Conference on Probabilistic
Graphical Models – JMLR Proceedings, vol. 52, pp. 110–121 (2016)
8. Cozman, F.G., Mau´a. D.D.: The well-founded semantics of cyclic probabilistic logic
programs: meaning and complexity. In: Encontro Nacional de Inteligˆencia Artiﬁcial
e Computacional, pp. 1–12 (2016)
9. Dantsin, E., Eiter, T., Voronkov, A.: Complexity and expressive power of logic
programming. ACM Comput. Surv. 33(3), 374–425 (2001)
10. Darwiche, A.: Modeling and Reasoning with Bayesian Networks, Cambridge (2009)
11. Polpo de Campos, C., Cozman, F.G.: The inferential complexity of Bayesian and
credal networks. In: IJCAI, pp. 1313–1318 (2005)
12. Eiter, T., Faber, W., Fink, M., Woltran, S.: Complexity results for answer set
programming with bounded predicate arities and implications. Ann. Math. Artif.
Intell. 5, 123–165 (2007)

458
F.G. Cozman and D.D. Mau´a
13. Eiter, T., Gottlob, G.: On the computational cost of disjunctive logic programming:
propositional case. Ann. Math. Artif. Intell. 15, 289–323 (1995)
14. Eiter, T., Ianni, G., Krennwallner, T.: Answer set programming: a primer. In:
Tessaris, S., Franconi, E., Eiter, T., Gutierrez, C., Handschuh, S., Rousset, M.-C.,
Schmidt, R.A. (eds.) Reasoning Web 2009. LNCS, vol. 5689, pp. 40–110. Springer,
Heidelberg (2009). doi:10.1007/978-3-642-03754-2 2
15. Fierens, D., Van den Broeck, G., Renkens, J., Shrerionov, D., Gutmann, B.,
Janssens, G., de Raedt, L.: Inference and learning in probabilistic logic programs
using weighted Boolean formulas. Theor. Pract. Logic Program. 15(3), 358–401
(2014)
16. Goldsmith, J., Hagen, M., Mundhenk, M.: Complexity of DNF minimization and
isomorphism testing for monotone formulas. Inf. Comput. 206(6), 760–775 (2008)
17. Hadjichristodoulou, S., Warren, D.S.: Probabilistic logic programming with well-
founded negation. In: International Symposium on Multiple-Valued Logic, pp. 232–
237 (2012)
18. Lukasiewicz, T.: Probabilistic description logic programs. In: Conference on Sym-
bolic and Quantitative Approaches to Reasoning with Uncertainty, pp. 737–749
(2005)
19. Lukasiewicz, T.: Probabilistic description logic programs. Int. J. Approx. Reason.
45(2), 288–307 (2007)
20. Mau´a, D.D., Polpo de Campos, C., Cozman, F.G.: The complexity of MAP infer-
ence in Bayesian networks speciﬁed through logical languages. In: International
Joint Conference on Artiﬁcial Intelligence (IJCAI), pp. 889–895 (2015)
21. Michels, S., Hommersom, A., Lucas, P.J.F., Velikova, M.: A new probabilistic con-
straint logic programming language based on a generalised distribution semantics.
Artif. Intell. J. 228, 1–44 (2015)
22. Papadimitriou, C.H.: Computational Complexity. Addison-Wesley, Longman
(1994)
23. Poole, D.: Probabilistic Horn abduction and Bayesian networks. Artif. Intell. 64,
81–129 (1993)
24. Poole, D.: The independent choice logic and beyond. In: Raedt, L., Frasconi,
P., Kersting, K., Muggleton, S. (eds.) Probabilistic Inductive Logic Program-
ming. LNCS, vol. 4911, pp. 222–243. Springer, Heidelberg (2008). doi:10.1007/
978-3-540-78652-8 8
25. Sato, T.: A statistical learning method for logic programs with distribution seman-
tics. In: International Conference on Logic Programming, pp. 715–729 (1995)
26. Sato, T., Kameya, Y., Zhou, N.-F.: Generative modeling with failure in PRISM.
In: International Joint Conference on Artiﬁcial Intelligence, pp. 847–852 (2005)
27. Stockmeyer, L.J.: The polynomial-time hierarchy. Theor. Comput. Sci. 3(1), 1–22
(1976)
28. Toda, S., Watanabe, O.: Polynomial-time 1-Turing reductions from #PH to #P.
Theor. Comput. Sci. 100, 205–221 (1992)
29. T´oran, J.: Complexity classes deﬁned by counting quantiﬁers. J. ACM 38(3), 753–
774 (1991)
30. van Gelder, A., Ross, J.A., Schlipf, J.S.: The well-founded semantics for general
logic programs. J. Assoc. Comput. Mach. 38(3), 620–650 (1991)
31. Wagner, K.W.: The complexity of combinatorial problems with succinct input
representation. Acta Informatica 23, 325–356 (1986)

Count Queries in Probabilistic Spatio-Temporal
Knowledge Bases with Capacity Constraints
John Grant1, Cristian Molinaro2(B), and Francesco Parisi2
1 University of Maryland, College Park, USA
grant@cs.umd.edu
2 DIMES Department, Universit`a della Calabria, Rende, Italy
{cmolinaro,fparisi}@dimes.unical.it
Abstract. The problem of managing spatio-temporal data arises in
many applications, such as location-based services, environment mon-
itoring, geographic information system, and many others. In real life,
this kind of data is often uncertain. The SPOT framework has been
proposed for the representation and processing of probabilistic spatio-
temporal data where probability is represented as an interval because
the exact value is unknown.
In this paper, we enhance the SPOT framework with capacity con-
straints, which allow users to better model many real-world scenarios.
The resulting formalization is called PST knowledge base. We study the
computational complexity of consistency checking, a central problem in
this setting. Speciﬁcally, we show that the problem is NP-complete and
also identify tractable cases. We then consider a relevant kind of queries
to reason on PST knowledge bases, namely count queries, which ask for
how many objects are in a region at a certain time point. We investigate
the computational complexity of answering count queries, and show cases
for which consistency checking can be exploited for query answering.
1
Introduction
Tracking moving objects is fundamental for all those applications that provide
location-based and context-aware services, such as emergency call-out assistance
and live traﬃc reports [2,14]. Such innovative services are becoming so widely
diﬀused that MarketsandMarkets forecasts that the location-based services mar-
ket will grow from $15.04 billion in 2016 to $77.84 billion in 2021 [16].
An important aspect of systems providing location-based and context-aware
services is that they need to manage spatial and temporal data together. For
this reason, researchers have investigated the representation and processing of
spatio-temporal data, both in AI [5,8,31,32] and databases [1,26]. However, in
many cases the location of objects is uncertain: such cases can be handled by
using probabilities [25,30]. Sometimes the probabilities themselves are not known
exactly. Indeed, the position of an object at a given time is estimated by means of
location estimation methods such as proximity (where the location of an object is
derived from its vicinity to antennas), ﬁngerprinting (where radio signal strength
c
⃝Springer International Publishing AG 2017
A. Antonucci et al. (Eds.): ECSQARU 2017, LNAI 10369, pp. 459–469, 2017.
DOI: 10.1007/978-3-319-61581-3 41

460
J. Grant et al.
measurements produced by a moving object are matched against a radio map
built before the system is working), and dead reckoning (where the position of
an object is derived from the last known position, assuming that the direction
of motion and either the speed or the travelled distance are known) [2,14]. How-
ever, since location estimation methods have limited accuracy and precision,
what can be asserted is that an object is at a given position at a given time
with a probability belonging to an interval. The SPOT (Spatial PrObabilistic
Temporal) framework was introduced in [24] to provide a declarative language
for the representation and processing of probabilistic spatio-temporal data with
probabilities that are not known exactly.
The SPOT framework allows statements of the form “object id is/was/will
be inside region r at time t with probability in the interval [ℓ, u]”. This allows
the representation of information concerning moving objects in several domains.
For instance, a cell phone provider is interested in knowing which cell phones
will be in the range of some towers at a given time and with what probability [4].
A transportation company is interested in predicting the vehicles that will be
on a given road at a given time (and with what probability) in order to avoid
congestion [13]. A retailer is interested in knowing the positions of people moving
in a shopping mall in order to oﬀer customized coupons [15].
Past work on the SPOT framework included a formal syntax and seman-
tics as well as checking for consistency. Additional research focused on the eﬃ-
cient processing of selection queries [20,22], database updates [10], and aggregate
count queries [9].
In particular, count queries ask how many objects are in a certain region
at a given time. Answering this kind of query is useful in several applications.
The cell phone provider, the transportation company, and the retailer mentioned
earlier are mostly interested in knowing the number of cell phones, vehicles, and
shoppers, respectively, in the regions of interest. Moreover, counting how many
people or vehicles are in a given region is important during natural disasters
or extreme weather in order to arrange evacuation operations and help injured
people. As a recent example, during Hurricane Matthew a massive sheltering
operation was launched with thousands of people seeking refuge in evacuation
shelters. A system providing information on safe places to ride out the dangerous
storm has to deal with (i) uncertainty on the actual positions of people; and (ii)
the maximum capacity of the roads that can be used to reach shelters, the
capacity of the shelters and other critical locations such as ﬁrst aid stations.
Analogously, for the applications mentioned earlier, exploiting knowledge on the
capacities of the regions that can be occupied by objects would help interpret
available data.
Although the SPOT framework can manage the uncertainty on the positions
of moving objects, it does not allow us to represent knowledge on the capacities
of regions.
In this paper we make the following contributions. We extend the SPOT frame-
work to include capacity constraints enabling us to express lower- and/or upper-
bounds on the number of objects that can be in a certain region. In particular, we
provide a formal syntax and semantics for probabilistic spatio-temporal (PST)

Count Queries in Probabilistic Spatio-Temporal Knowledge Bases
461
knowledgebases (KBs) consisting of atomic statements, such as those repre-
sentable in the SPOT framework, and capacity constraints. We investigate the
computational complexity of the problem of deciding whether a PST KB is con-
sistent and, after showing that the problem is NP-complete in general, we identify
restricted classes of PST KBs for which the problem is tractable. In fact, decid-
ing consistency is fundamental before answering queries. We introduce the formal
semantics of count queries in PST KBs, investigate the computational complex-
ity of answering such kind of queries, and show how checking consistency can be
exploited for query answering.
Due to space constraints, proofs are omitted and will be provided in an
extended version of the paper.
2
The PST Framework
This section introduces the syntax and semantics of PST KBs, augmenting the
framework with capacity constraints.
2.1
Syntax
We assume the existence of a ﬁnite set ID of object ids and a ﬁnite set Space of
spatial points. A non-empty subset of Space is called a region. We also assume
an arbitrarily large but ﬁxed size window of time T = [0, 1, . . . , tmax]. Time
point tmax can be as large as a developer needs, and the user may choose the
granularity of time according to her needs.
A spatio-temporal atom (st-atom, for short) is an expression of the form
loc(id, r, t), where id ∈ID, ∅⊊r ⊆Space, and t ∈T. The intuitive meaning of
loc(id, r, t) is that object id is/was/will be inside region r at time t.
Deﬁnition 1 (PST atom). A PST atom is an st-atom loc(id, r, t) annotated
with a probability interval [ℓ, u] ⊆[0, 1] (with ℓand u rational numbers), and
denoted as loc(id, r, t)[ℓ, u].
Intuitively, the PST atom loc(id, r, t)[ℓ, u] says that object id is/was/will be
inside region r at time t with probability in the interval [ℓ, u]. Hence, PST atoms
can represent information about the past and the present, but also information
about the future, such as when data are obtained from methods for predict-
ing the destination of moving objects [12,17,29], or from querying predictive
databases [3,21].
In our framework, Space is an arbitrary set of points and a region is any
non-empty subset of Space. For convenience, we use rectangular regions in our
running example where each point of Space is represented as an ordered pair
(x, y) with integer coordinates. We identify a region r with its bottom-left (x1, y1)
and top-right (x2, y2) endpoints.
Example 1. Figure 1(a) shows a map for our running example concerning a
delivery company that has trucks going to various addresses in a city. Here,

462
J. Grant et al.
Space = {(x, y) | x, y ∈N and 0 ≤x, y ≤8}. The map consists of the com-
pany warehouse (coloured in orange), streets (coloured in grey), a lake (coloured
in lightblue), and a botanic park (coloured in green). Eight regions are shown,
each of them represented by a rectangle containing the region’s points and with
the region’s name in the top-left corner of the rectangle. For instance r1 con-
sists of the points (0, 7), (1, 7), (0, 8), (1, 8). The bottom-left (x1, y1) and top-right
(x2, y2) endpoints of each region are reported in Fig. 1(b).
Fig. 1. (a) Running example’s map (best viewed in color); (b) regions’ bottom-left and
top-right endpoints; (c) PST atoms. (Color ﬁgure online)
Some regions denote speciﬁc places: r4 represents a part of the lake; r5 repre-
sents a bridge linking the street on the bottom to that on the top; r6 represents
the botanic park; and r7 represents the company warehouse. Other regions are
meant to represent areas where trucks were detected by sensors (e.g., GPS).
The information of the positions of the trucks is represented using the set
of PST atoms in Fig. 1(c). For instance, the PST atom loc(id1, r7, 0)[.9, 1] says
that the truck id1 was in region r7 (i.e., the company warehouse) at time 0
with probability in the interval [.9, 1] (the high-accuracy sensors used inside the
company warehouse entail a narrow probability interval with upper bound equal
to 1). Atom loc(id1, r3, 2)[.4, .6] says that id1 was recognized in r3 by a roadside
sensor at the later time 2 with probability in [.4, .6].
□
Although PST atoms express much useful information, they cannot express addi-
tional knowledge such as constraints on how many objects are allowed in a region,
which can be stated with capacity constraints, introduced below. Indeed, in many
real-life applications, it is useful to express a lower- and/or upper-bound on the
number of objects that can be in a certain region. For instance, the number of
trucks that can be in a company warehouse, or on a bridge, is clearly bounded
by some constant. Also, at some time points, as for instance during non-working
hours, all the trucks of the company must be in the warehouse.

Count Queries in Probabilistic Spatio-Temporal Knowledge Bases
463
Deﬁnition 2 (Capacity constraint). A capacity constraint is an expression
of the form capacity(r, k1, k2, t), where r is a region, k1 and k2 are two integers
such that 0 ≤k1 ≤k2 ≤|ID|, and t is a time point in T.
For
convenience,
we
write
a
constraint
capacity(r, k, k, t)
simply
as
capacity(r, k, t).
Example 2. In our running example, the constraint “there cannot be more than
one truck on the bridge (region r5) at any time between 0 and 2” can be
expressed by the capacity constraints κ1,t = capacity(r5, 0, 1, t) with t ∈[0, 2].
Similarly, κ2,t = capacity(r7, 1, 3, t), with t ∈[0, 1], says that “the number of
trucks in the company warehouse is between 1 and 3 at any time between 0 and 1”.
Herein, lower bound 1 can be derived for instance from the fact that one
truck was damaged in that period. Moreover, κ3,t = capacity(r4, 0, 0, t) and
κ4,t = capacity(r6, 0, 0, t), with t ∈[0, 2], say that no truck can be in the lake or
the botanic park at any time point (we are assuming tmax = 2).
□
Deﬁnition 3 (PST knowledge base). A PST knowledge base is a pair ⟨A, C⟩,
where A is a ﬁnite set of PST atoms and C is a ﬁnite set of capacity constraints.
Example 3. In our running example, ID = {id1, id2, id3}, T = [0, 2], Space is the
set of points (x, y) such that 0 ≤x ≤8 and 0 ≤y ≤8, and PST KB Kex is the
pair ⟨Aex, Cex⟩, where Aex is the set consisting of the PST atoms in Fig. 1(c),
and Cex is the set of capacity constraints deﬁned in Example 2.
□
Throughout the paper we use K to denote an arbitrary PST knowledge base.
2.2
Semantics
The set of all object ids appearing in K is denoted by ID(K). The semantics of
a PST KB is deﬁned through the concept of worlds.
Deﬁnition 4 (World). A world w for K is a function w : ID(K)×T →Space.
Basically, a world w speciﬁes a trajectory for each id ∈ID(K). That is, for
each id ∈ID(K), w says where object id was/is/will be in Space at each time
point t ∈T. This means that an object can be in only one location at a time.
However, a location may contain multiple objects. We use W(K) to denote the
set of all worlds for K.
Example 4. World w1 describing the positions of id1, id2 and id3 for time points
in [0, 2] is such that w1(id1, 0) = (1, 1), w1(id1, 1) = (7, 2), w1(id1, 2) = (7, 6),
w1(id2, 0) = (2, 1), w1(id2, 1) = (7, 5), w1(id2, 2) = (1, 7), w1(id3, 0) = (1, 2),
w1(id3, 1) = (1, 2), w1(id3, 2) = (6, 1).
□
Deﬁnition 5 (Satisfaction). A world w satisﬁes an st-atom a = loc(id, r, t),
denoted w |= a, iﬀw(id, t) ∈r. Moreover, w satisﬁes a capacity constraint κ =
capacity(r, k1, k2, t), denoted w |= κ, iﬀk1 ≤|{id ∈ID(K) | w(id, t) ∈r}| ≤k2.

464
J. Grant et al.
Example 5. World w1 of Example 4 satisﬁes the st-atom loc(id1, r7, 0), as
w1(id1, 0) = (1, 1) belongs to region r7 (see Fig. 1(a)). Moreover, for each
t ∈[0, 2], w1 satisﬁes κ1,t, as {id ∈ID(K) | w1(id, 0) ∈r5} = ∅, {id ∈ID(K) |
w1(id, 1) ∈r5} = {id2}, {id ∈ID(K) | w1(id, 2) ∈r5} = {id1}, and the cardi-
nalities of these sets are all in the interval [0, 1], as required by κ1,t.
□
Deﬁnition 6 (Interpretation). An interpretation I for K is a probability
distribution function (PDF) over W(K), that is, I
: W(K) →[0, 1] and

w∈W(K) I(w) = 1.
Intuitively, I(w) is the probability that w describes the actual trajectories of
all objects.
Deﬁnition 7 (Model). A model M for K = ⟨A, C⟩is an interpretation for K
such that:
1. ∀loc(id, r, t)[ℓ, u] ∈A,


w|w|=loc(id,r,t)
M(w)

∈[ℓ, u];
2. ∀κ ∈C,

w|w̸|=κ
M(w) = 0.
The ﬁrst condition in the deﬁnition above says that, for each PST atom
loc(id, r, t)[ℓ, u] ∈A, the sum of the probabilities assigned by M to the worlds
satisfying the st-atom loc(id, r, t) must belong to the probability interval [ℓ, u].
The second condition says that M must assign probability 0 to every world not
satisfying all constraints κ ∈C.
Example 6. Let w1 be the world introduced in Example 4. Let w2 be the same
as w1 except that w2(id1, 2) = (5, 7) and w2(id2, 2) = (4, 7). Let w3 be the same
as w2 except that w3(id1, 1) = (7, 3) and w3(id2, 1) = (7, 4). Let interpretation
M be such that M(w1) = .6, M(w2) = .2, M(w3) = .2, and M(w) = 0 for
all other worlds in W(Kex). It can be checked that M satisﬁes both conditions
of Deﬁnition 7 for the PST KB Kex of our running example. For instance, for
loc(id1, r8, 1)[.6, .8] ∈Aex, we have 
w|w|=loc(id1,r8,1) M(w)=M(w1)+M(w2)=
0.6+0.2. ∈[.6, .8]. Also, it is easy to check that w1, w2, w3 satisfy every capacity
constraint in Cex. In particular, we have shown in Example 5 that w1 |= κ1,t.
It is easy to see that w2 |= κ1,t and w3 |= κ1,t as well, as w2 and w3 coincide
with w1 for time point 0, and for time point 1 (resp. 2) only id2 (resp. id1) is in
r5. Thus, M is a model for Kex.
We say that K is consistent iﬀthere exists a model for it. The set of models for
K will be denoted as M(K). PST KB Kex of our running example is consistent,
because the interpretation M of Example 6 is a model for it.
3
Consistency Checking
In this section, we study the complexity of deciding whether a PST KB is consis-
tent. Speciﬁcally, we show that the problem is NP-complete. As checking the con-
sistency of PST KBs without capacity constraints is in PTIME [24], this shows

Count Queries in Probabilistic Spatio-Temporal Knowledge Bases
465
that capacity constraints increase the complexity. Then, we identify restricted
classes of PST KBs for which the problem is in PTIME. These restrictions are
fairly strong; however, they are also quite diﬀerent from one another. Thus, if
we have a PST KB that does not satisfy any of these classes, we may still be
able to make small modiﬁcations, such as deleting some capacity constraints, so
that the modiﬁed KB is in one of the classes whose consistency we can check
eﬃciently.
Theorem 1. Deciding whether a PST KB K is consistent is NP-complete.
The ﬁrst restricted class we consider is when the capacity constraints allow no
objects in some regions. For instance, there cannot be trucks in the lake.
Theorem 2. Let K = ⟨A, C⟩be a PST KB. If C consists of capacity constraints
of the form capacity(r, 0, t), then checking whether K is consistent is in PTIME.
We now propose sound but possibly incomplete ways of checking consistency,
that is, techniques that when the answer is ‘yes’, the KB is consistent, and when
the answer is ‘no’ we cannot conclude anything about the consistency of the KB.
Below we consider the case where the upper bounds of all PST atoms is 1 and
where we can divide Space into small enough regions so that regions in diﬀerent
capacity constraints are disjoint.
Theorem 3. Let K = ⟨A, C⟩be a PST KB that satisﬁes the following conditions:
– A consists of PST atoms of the form loc(id, r, t)[ℓ, 1] and there are no two
distinct PST atoms in A for the same object id and time point, and
– for
every
time
point
t,
every
pair
of
distinct
capacity
constraints
capacity(r, k1, k2, t) and capacity(r′, k′
1, k′
2, t) in C is such that r ∩r′ = ∅.
Deciding if there exists a world w ∈W(K) s.t. (i) w |= C and (ii) w(id, t) ∈r
for every loc(id, r, t)[ℓ, 1] in A with ℓ> 0, is in PTIME. If such a world exists,
then K is consistent.
A PST KB ⟨A, C⟩is called simple iﬀfor every time point t ∈T, there is at
most one capacity constraint of the form capacity(r, k1, k2, t) in C.
Theorem 4. Let K = ⟨A, C⟩be a simple PST KB. If ⟨A, ∅⟩is consistent and,
for every capacity(r, k1, k2, t) ∈C, [z, Z] ⊆[k1, k2], where
z =
min
M∈M(⟨A,∅⟩) |{id | id ∈ID ∧


w|w(id,t)∈r
M(w)

=1}|,
Z =
max
M∈M(⟨A,∅⟩) |{id | id ∈ID ∧


w|w(id,t)∈r
M(w)

̸=0}|,
then K is consistent. Checking consistency under such conditions is in PTIME.
The reverse implication does not hold. As an example, the PST KB con-
taining only the PST atom loc(id, Space, 0)[0, 1] and the capacity constraint
capacity({p}, 1, 2, 0) is consistent (here p is an arbitrary point in Space), but
[z, Z] = [0, 1] ̸⊆[k1, k2] = [1, 2].

466
J. Grant et al.
4
Count Queries
In this section, we consider the problem of answering count queries over PST
KBs. We ﬁrst deﬁne the syntax and semantics of count queries, and then ana-
lyze the complexity of query answering. Throughout this section PST KBs are
assumed to be consistent.
Deﬁnition 8 (Count query).
A count query is an expression of the form
Count(q, t), where q ⊆Space and t ∈T.
The count query Count(q, t) asks: “How many objects are inside region q at
time t?”. Before deﬁning the semantics of count queries, we need to introduce
the following auxiliary deﬁnition, which introduces the probability that exactly
i objects are in a region q at a time point t according to a given model M.
Deﬁnition 9. Let M be a model for K. For 0 ≤i ≤|ID|, the probability of
having exactly i objects in a region q at a time point t w.r.t. M is as follows:
ProbM(q, i, t) =

w|w|=capacity(q,i,t) M(w)
Next, we deﬁne the ranking answer Q(K) to a count query Count(q, t) as the
set of pairs of the form ⟨i, [ℓi, ui]⟩(with 0 ≤i ≤|ID|) where i is the number of
objects that may be in the given region q at the given time point t, and ℓi and
ui are the minimum and maximum probabilities of having exactly i objects in q
at a time point t over all models.
Deﬁnition 10. The ranking answer to a count query Q = Count(q, t) w.r.t. K
is:
Q(K) = {⟨i, [ℓi, ui]⟩|0 ≤i ≤|ID| ∧ℓi =
min
M∈M(K) ProbM(q, i, t) ∧
ui =
max
M∈M(K) ProbM(q, i, t)}.
Example 7. Continuing our running example, one may be interested in know-
ing the number of trucks that are at time 2 in the region q = {(x, y) ∈
Space | (6 ≤x ≤8) ∧(6 ≤y ≤8)} (this region includes the whole region
r3, a portion of r5, and some other points). This can be expressed by the
count query Q = Count(q, 2). With a little eﬀort, the reader can check that
Q(K) = {⟨0, [.4, .6]⟩, ⟨1, [.4, 1]⟩, ⟨2, [0, .3]⟩, ⟨3, [0, .1]⟩}.
□
Our deﬁnition of ranking answer generalizes that introduced in [9] where PST
KBs of the form ⟨A, ∅⟩(using our notation) were considered and the ranking
answer was deﬁned by assuming the independence of the events involving the
locations of diﬀerent objects. This does not hold for PST KBs where the presence
of capacity constraints entails that the events that diﬀerent objects occupy a
given region are implicitly correlated.
Theorem 5. Computing Q(K) is FP NP [log n]-hard.

Count Queries in Probabilistic Spatio-Temporal Knowledge Bases
467
Our ﬁnal result relates portions of the ranking answer to a consistency check,
showing that solving some particular instances of the consistency check problem
allows us to answer some speciﬁc count queries.
Proposition 1. Let Q = Count(q, t) and K = ⟨A, C⟩.
– If K′ = ⟨A, C ∪{capacity(q, k1, k2, t)}⟩is consistent, then ℓi = 0 in Q(K) for
all i such that i < k1 or i > k2.
– If K′ = ⟨A, C ∪{capacity(Space\q, k1, k2, t)}⟩is consistent, then ui = 1 in
Q(K) for all i ∈[|ID| −k2, |ID| −k1].
5
Summary and Outlook
The SPOT framework is a declarative language suitable in many current applica-
tions dealing with uncertain spatio-temporal data. We have enhanced the SPOT
formalism with capacity constraints, which enable users to model semantic infor-
mation commonly arising in practice. Furthermore, we considered count queries,
a relevant kind of queries in several real-world scenarios. We have investigated
the computational complexity of the consistency checking and query answering
problems, showing that they are intractable and proposed tractable approaches
for restricted cases.
Diﬀerent frameworks have been proposed in the literature to handle spatial
information [1,5,8,26,30–32], with some of them being able to model uncertainty
too. However, to the best of our knowledge, the SPOT framework is the only one
that allows probabilities to be uncertain—in diﬀerent real-world applications, it
is often the case that a precise estimation of the single-value probabilities cannot
be obtained. Diﬀerent frameworks to reason about time have been proposed
in [7,27,28], but no spatial information is taken into account.
A full logic (including negation, disjunction and quantiﬁers) for managing
SPOT data was proposed in [6]. Grant et al. [11] is a comprehensive survey of
the results on the SPOT framework. The original SPOT framework introduced
in [24] has been extended with diﬀerent kinds of constraints. Grant et al. [10] and
Parker et al. [23] considered reachability constraints on moving objects—e.g., an
object in a given location cannot reach another location within a time point.
Recently, [18] extended the SPOT framework with a general form of spatio-
temporal denial constraints, which allow us to state that some movements are
not allowed. However, the extensions previously introduced were not able to
express all the capacity constraints we considered.
As directions for future work, we plan to integrate the framework proposed
in this paper with the one proposed in [18] into a uniﬁed approach that allows
for a wide range of constraints to be expressed. We also plan to investigate
count queries and other kinds of aggregate queries in the uniﬁed framework.
Finally, following [19], where the problem of restoring consistency of PST KBs
without integrity constraints has been explored, we plan to address the problems
of repairing and querying inconsistent PST KBs with constraints.

468
J. Grant et al.
References
1. Agarwal, P.K., Arge, L., Erickson, J.: Indexing moving points. J. Comput. Syst.
Sci. 66(1), 207–243 (2003)
2. Ahson, S.A., Ilyas, M.: Location-Based Services Handbook: Applications, Tech-
nologies, and Security. CRC Press, Hoboken (2010)
3. Akdere, M., Cetintemel, U., Riondato, M., Upfal, E., Zdonik, S.B.: The case for
predictive database systems: opportunities and challenges. In: Proceedings of the
5th Biennial Conference on Innovative Data Systems Research (CIDR), pp. 167–
174 (2011)
4. Bayir, M.A., Demirbas, M., Eagle, N.: Mobility proﬁler: a framework for discovering
mobility proﬁles of cell phone users. Pervasive Mob. Comput. 6(4), 435–454 (2010)
5. Cohn, A.G., Hazarika, S.M.: Qualitative spatial representation and reasoning: an
overview. Fundamenta Informaticae 46(1–2), 1–29 (2001)
6. Doder, D., Grant, J., Ognjanovi´c, Z.: Probabilistic logics for objects located in
space and time. J. Logic Comput. 23(3), 487–515 (2013)
7. Dousson, C., Maigat, P.L.: Chronicle recognition improvement using temporal
focusing and hierarchization. In: Proceedings of International Joint Conference
on Artiﬁcial Intelligence (IJCAI), pp. 324–329 (2007)
8. Gabelaia, D., Kontchakov, R., Kurucz, ´A., Wolter, F., Zakharyaschev, M.: Com-
bining spatial and temporal logics: expressiveness vs. complexity. J. Artif. Intell.
Res. 23, 167–243 (2005)
9. Grant, J., Molinaro, C., Parisi, F.: Aggregate count queries in probabilistic spatio-
temporal databases. In: Liu, W., Subrahmanian, V.S., Wijsen, J. (eds.) SUM 2013.
LNCS (LNAI), vol. 8078, pp. 255–268. Springer, Heidelberg (2013). doi:10.1007/
978-3-642-40381-1 20
10. Grant, J., Parisi, F., Parker, A., Subrahmanian, V.S.: An AGM-style belief revision
mechanism for probabilistic spatio-temporal logics. Artif. Intell. 174(1), 72–104
(2010)
11. Grant, J., Parisi, F., Subrahmanian, V.S.: Research in probabilistic spatiotemporal
databases: the SPOT framework. In: Ma, Z., Yan, L. (eds.) Advances in Proba-
bilistic Databases for Uncertain Information Management, Studies in Fuzziness
and Soft Computing, vol. 304, pp. 1–22. Springer, Heidelberg (2013)
12. Hammel, T., Rogers, T.J., Yetso, B.: Fusing live sensor data into situational mul-
timedia views. In: Proceedings of International Workshop on Multimedia Informa-
tion Systems, pp. 145–156 (2003)
13. Karbassi, A., Barth, M.: Vehicle route prediction and time of arrival estimation
techniques for improved transportation system management. In: Proceedings of
the 2013 IEEE Intelligent Vehicles Symposium, pp. 511–516 (2003)
14. Karimi, H.A.: Advanced Location-Based Technologies and Services. CRC Press,
Boca Raton (2013)
15. Kurkovsky, S., Harihar, K.: Using ubiquitous computing in interactive mobile mar-
keting. Pers. Ubiquit. Comput. 10(4), 227–240 (2006)
16. MarketsandMarkets
(2016).
http://www.marketsandmarkets.com/Market-
Reports/location-based-service-market-96994431.html
17. Mittu, R., Ross, R.: Building upon the coalitions agent experiment (CoAX) -
integration of multimedia information in GCCS-M using impact. In: Proceedings
of International Workshop on Multimedia Information Systems (MIS), pp. 35–44
(2003)

Count Queries in Probabilistic Spatio-Temporal Knowledge Bases
469
18. Parisi, F., Grant, J.: Knowledge representation in probabilistic spatio-temporal
knowledge bases. J. Artif. Intell. Res. (JAIR) 55, 743–798 (2016)
19. Parisi, F., Grant, J.: On repairing and querying inconsistent probabilistic spatio-
temporal databases. Int. J. Approx. Reason. (IJAR) 84, 41–74 (2017)
20. Parisi, F., Parker, A., Grant, J., Subrahmanian, V.S.: Scaling cautious selection in
spatial probabilistic temporal databases. In: Jeansoulin, R., Papini, O., Prade, H.,
Schockaert, S. (eds.) Methods for Handling Imperfect Spatial Information, Stud-
ies in Fuzziness and Soft Computing, vol. 256, pp. 307–340. Springer, Heidelberg
(2010)
21. Parisi, F., Sliva, A., Subrahmanian, V.S.: A temporal database forecasting algebra.
Int. J. Approx. Reason. 54(7), 827–860 (2013)
22. Parker, A., Infantes, G., Grant, J., Subrahmanian, V.S.: SPOT databases: eﬃcient
consistency checking and optimistic selection in probabilistic spatial databases.
IEEE Trans. Knowl. Data Eng. (TKDE) 21(1), 92–107 (2009)
23. Parker, A., Infantes, G., Subrahmanian, V.S., Grant, J.: An AGM-based belief revi-
sion mechanism for probabilistic spatio-temporal logics. In: Proceedings of AAAI
Conference on Artiﬁcial Intelligence (AAAI), pp. 511–516 (2008)
24. Parker, A., Subrahmanian, V.S., Grant, J.: A logical formulation of probabilistic
spatial databases. IEEE Trans. Knowl. Data Eng. (TKDE) 19(11), 1541–1556
(2007)
25. Parker, A., Yaman, F., Nau, D.S., Subrahmanian, V.S.: Probabilistic go theories.
In: Proceedings of International Joint Conference on Artiﬁcial Intelligence (IJCAI),
pp. 501–506 (2007)
26. Pelanis, M., Saltenis, S., Jensen, C.S.: Indexing the past, present, and anticipated
future positions of moving objects. ACM Trans. Database Syst. 31(1), 255–298
(2006)
27. Saint-Cyr, F.D., Lang, J.: Reasoning about unpredicted change and explicit
time. In: Gabbay, D.M., Kruse, R., Nonnengart, A., Ohlbach, H.J. (eds.)
ECSQARU/FAPR -1997. LNCS, vol. 1244, pp. 223–236. Springer, Heidelberg
(1997). doi:10.1007/BFb0035625
28. de Saint-Cyr, F.D., Lang, J.: Belief extrapolation (or how to reason about obser-
vations and unpredicted change). Artif. Intell. 175(2), 760–790 (2011)
29. Southey, F., Loh, W., Wilkinson, D.F.: Inferring complex agent motions from par-
tial trajectory observations. In: Proceedings of International Joint Conference on
Artiﬁcial Intelligence (IJCAI), pp. 2631–2637 (2007)
30. Tao, Y., Cheng, R., Xiao, X., Ngai, W.K., Kao, B., Prabhakar, S.: Indexing multi-
dimensional uncertain data with arbitrary probability density functions. In: Pro-
ceedings of International Conference on Very Large Data Bases (VLDB), pp. 922–
933 (2005)
31. Yaman, F., Nau, D.S., Subrahmanian, V.S.: A logic of motion. In: Proceedings of
International Conference on Principles of Knowledge Representation and Reason-
ing (KR), pp. 85–94 (2004)
32. Yaman, F., Nau, D.S., Subrahmanian, V.S.: Going far, logically. In: Proceedings
of International Joint Conference on Artiﬁcial Intelligence (IJCAI), pp. 615–620
(2005)

RankPL: A Qualitative Probabilistic
Programming Language
Tjitze Rienstra(B)
Computer Science and Communication, University of Luxembourg,
Luxembourg City, Luxembourg
tjitze@gmail.com
Abstract. In this paper we introduce RankPL, a modeling language
that can be thought of as a qualitative variant of a probabilistic pro-
gramming language with a semantics based on Spohn’s ranking theory.
Broadly speaking, RankPL can be used to represent and reason about
processes that exhibit uncertainty expressible by distinguishing “normal”
from “surprising” events. RankPL allows (iterated) revision of rankings
over alternative program states and supports various types of reasoning,
including abduction and causal inference. We present the language, its
denotational semantics, and a number of practical examples. We also
discuss an implementation of RankPL that is available for download.
1
Introduction
Probabilistic
programming
languages
(PPLs)
are
programming
languages
extended with statements to (1) draw values at random from a given probability
distribution, and (2) perform conditioning due to observation. Probabilistic pro-
grams yield, instead of a deterministic outcome, a probability distribution over
possible outcomes. PPLs greatly simplify representation of, and reasoning with
rich probabilistic models. Interest in PPLs has increased in recent years, mainly
in the context of Bayesian machine learning. Examples of modern PPLs include
Church, Venture and Figaro [4,8,10], while early work goes back to Kozen [6].
Ranking theory is a qualitative abstraction of probability theory in which
events receive discrete degrees of surprise called ranks [11]. That is, events are
ranked 0 (not surprising), 1 (surprising), 2 (very surprising), and so on, or ∞if
impossible. Apart from being computationally simpler, ranking theory permits
meaningful inference without requiring precise probabilities. Still, it provides
analogues to powerful notions known from probability theory, like conditioning
and independence. Ranking theory has been applied in logic-based AI (e.g. belief
revision and non-monotonic reasoning [1,3]) as well as formal epistemology [11].
In this paper we develop a language called RankPL. Semantically, the lan-
guage draws a parallel with probabilistic programming in terms of ranking the-
ory. We start with a minimal imperative programming language (if-then-else,
while, etc.) and extend it with statements to (1) draw choices at random from
a given ranking function and (2) perform ranking-theoretic conditioning due to
observation. Analogous to probabilistic programs, a RankPL programs yields,
instead of a deterministic outcome, a ranking function over possible outcomes.
c
⃝Springer International Publishing AG 2017
A. Antonucci et al. (Eds.): ECSQARU 2017, LNAI 10369, pp. 470–479, 2017.
DOI: 10.1007/978-3-319-61581-3 42

RankPL: A Qualitative Probabilistic Programming Language
471
Broadly speaking, RankPL can be used to represent and reason about
processes whose input or behavior exhibits uncertainty expressible by distin-
guishing normal (rank 0) from surprising (rank > 0) events. Conditioning in
RankPL amounts to the (iterated) revision of rankings over alternative program
states. This is a form of revision consistent with the well-known AGM and DP
postulates for (iterated) revision [1,2]. Various types of reasoning can be mod-
eled, including abduction and causal inference. Like with PPLs, these reasoning
tasks can be modeled without having to write inference-speciﬁc code.
The overview of this paper is as follows. Section 2 deals with the basics of
ranking theory. In Sect. 3 we introduce RankPL and present its syntax and
formal semantics. In Sect. 4 we discuss two generalized conditioning schemes
(L-conditioning and J-conditioning) and show how they can be implemented in
RankPL. All the above will be demonstrated by practical examples. In Sect. 5
we discuss our RankPL implementation. We conclude in Sect. 6.
2
Ranking Theory
Here we present the necessary basics of ranking theory, all of which is due to
Spohn [11]. The deﬁnition of a ranking function presupposes a ﬁnite set Ω of
possibilities and a boolean algebra A over subsets of Ω, which we call events.
Deﬁnition 1. A ranking function is a function κ : Ω →N∪{∞} that associates
every possibiltiy with a rank. κ is extended to a function over events by deﬁning
κ(∅) = ∞and κ(A) = min({κ(w) | w ∈A}) for each A ∈A\∅. A ranking
function must satisfy κ(Ω) = 0.
As mentioned in the introduction, ranks can be understood as degrees of
surprise or, alternatively, as inverse degrees of plausibility. The requirement that
κ(Ω) = 0 is equivalent to the condition that at least one w ∈Ω receives a rank
of 0. We sometimes work with functions λ : Ω →N ∪{∞} that violate this
condition. The normalization of λ is a ranking function denoted by ||λ|| and
deﬁned by ||λ||(w) = λ(w) −λ(Ω). Conditional ranks are deﬁned as follows.
Deﬁnition 2. Given a ranking function κ, the rank of A conditional on B
(denoted κ(A | B) is deﬁned by
κ(A | B) =

κ(A ∩B) −κ(B) if κ(B) ̸= ∞,
∞
otherwise.
We denote by κB the ranking function deﬁned by κB(A) = κ(A | B).
In words, the eﬀect of conditioning on B is that the rank of B is shifted down
to zero (keeping the relative ranks of the possibilities in B constant) while the
rank of its complement is shifted up to ∞.
How do ranks compare to probabilities? An important diﬀerence is that ranks
of events do not add up as probabilities do. That is, if A and B are disjoint, then
κ(A ∪B) = min(κ(A), κ(B)), while P(A ∪B) = P(A) + P(B). This is, however,

472
T. Rienstra
consistent with the interpretation of ranks as degrees of surprise (i.e., A ∪B is
no less surprising than A or B). Furthermore, ranks provide deductively closed
beliefs, whereas probabilities do not. More precisely, if we say that A is believed
with ﬁrmness x (for some x > 0) with respect to κ iﬀκ(A) > x, then if A and
B are believed with ﬁrmness x then so is A ∩B. A similar notion of belief does
not exist for probabilities, as is demonstrated by the Lottery paradox [7].
Finally, note that ∞and 0 in ranking theory can be thought of as playing
the role of 0 and 1 in probability, while min, −and + play the role, respectively,
of +, ÷ and ×. Recall, for example, the deﬁnition of conditional probability, and
compare it with Deﬁnition 2. This correspondence also underlies notions such as
(conditional) independence and ranking nets (the ranking-based counterpart of
Bayesian networks) that have been deﬁned in terms of rankings [11].
3
RankPL
We start with a brief overview of the features of RankPL. The basis is a minimal
imperative language consisting of integer-typed variables, an if-then-else state-
ment and a while-do construct. We extend it with the two special statements
mentioned in the introduction. We call the ﬁrst one ranked choice. It has the
form {s1} ⟨⟨⟨e⟩⟩⟩{s2}. Intuitively, it states that either s1 or s2 is executed, where
the former is a normal (rank 0) event and the latter a typically surprising event
whose rank is the value of the expression e. Put diﬀerently, it represents a draw
of a statement to be executed, at random, from a ranking function over two
choices. Note that we can set e to zero to represent a draw from two equally
likely choices, and that larger sets of choices can be represented through nesting.
The second special statement is called the observe statement observe b. It
states that the condition b is observed to hold. Its semantics corresponds to
ranking-theoretic conditioning. To illustrate, consider the program
x := 10; {y := 1} ⟨⟨⟨1⟩⟩⟩{{y := 2} ⟨⟨⟨1⟩⟩⟩{y := 3}}; x := x × y;
This program has three possible outcomes: x = 10, x = 20 and x = 30, ranked
0, 1 and 2, respectively. Now suppose we extend the program as follows:
x := 10; {y := 1} ⟨⟨⟨1⟩⟩⟩{{y := 2} ⟨⟨⟨1⟩⟩⟩{y := 3}}; observe y > 1; x := x × y;
Here, the observation rules out the event y = 1, and the ranks of the remaining
possibilities are shifted down, resulting in two outcomes x = 20 and x = 30,
ranked 0 and 1, respectively.
A third special construct is the rank expression rank b., which evaluates to
the rank of the boolean expression b. Its use will be demonstrated later.
3.1
Syntax
We ﬁx a set Vars of variables (ranged over by x) and denote by Val the set of
integers including ∞(ranged over by n). We use e, b and s to range over the
numerical expressions, boolean expressions, and statements. They are deﬁned by
the following BNF rules:

RankPL: A Qualitative Probabilistic Programming Language
473
e := n | x | rank b | (e1 ♦e2) (for ♦∈{−, +, ×, ÷})
b := ¬b | (b1 ∨b2) | (e1 ♦e2) (for ♦∈{=, <})
s := {s0; s1} | x := e | if b then {s1} else {s2} |
while b do {s} | {s1} ⟨⟨⟨e⟩⟩⟩{s2} | observe b | skip
We omit parentheses and curly brackets when possible and deﬁne ∧in terms
of ∨and ¬. We write if b then {s} instead of if b then {s} else {skip}, and
abbreviate statements of the form {x := e1} ⟨⟨⟨e⟩⟩⟩{x := e2} to x := e1 ⟨⟨⟨e⟩⟩⟩e2. Note
that the skip statement does nothing and is added for technical convenience.
3.2
Semantics
The denotational semantics of RankPL deﬁnes the meaning of a statement s as
a function D[[s]] that maps prior rankings into posterior rankings. The subjects
of these rankings are program states represented by valuations, i.e., functions
that assign values to all variables. The initial valuation, denoted by σ0, sets all
variables to 0. The initial ranking, denoted by κ0, assigns 0 to σ0 and ∞to others.
We denote by σ[x →n] the valuation equivalent to σ except for assigning n to x.
From now on we associate Ω with the set of valuations and denote the set
of rankings over Ω by K. Intuitively, if κ(σ) is the degree of surprise that σ is
the actual valuation before executing s, then D[[s]](κ)(σ) is the degree of sur-
prise that σ is the actual valuation after executing s. If we refer to the result of
running the program s, we refer to the ranking D[[s]](κ0). Because s might not
execute successfully, D[[s]] is not a total function over K. There are two issues to
deal with. First of all, non-termination of a loop leads to an undeﬁned outcome.
Therefore D[[s]] is a partial function whose value D[[s]](κ) is deﬁned only if s ter-
minates given κ. Secondly, observe statements may rule out all possibilities. A
program whose outcome is empty because of this is said to fail. We denote failure
with a special ranking κ∞that assigns ∞to all valuations. Since κ∞̸∈K, we
deﬁne the range of D[[s]] by K∗= K ∪{κ∞}. Thus, the semantics of a statement
s is deﬁned by a partial function D[[s]] from K∗to K∗.
But ﬁrst, we deﬁne the semantics of expressions. A numerical expression is
evaluated w.r.t. both a ranking function (to determine values of rank expres-
sions) and a valuation (to determine values of variables). Boolean expressions
may also contain rank expressions and therefore also depend on a ranking func-
tion. Given a valuation σ and ranking κ, we denote by σκ(e) the value of the
numerical expression e w.r.t. σ and κ, and by [b]κ the set of valuations satisfying
the boolean expression b w.r.t. κ. These functions are deﬁned as follows.1
σκ(n) = n
σκ(x) = σ(x)
σκ(rank b) = κ([b]κ)
σκ(a1 ♦a2) = σκ(a1) ♦σκ(a2)
[¬b]κ = Ω\[b]κ
[b1 ∨b2]κ = [b1]κ ∪[b2]κ
[a1 ♦a2]κ = {σ ∈Ω | σκ(a1) ♦σκ(a2)}
1 We omit explicit treatment of undeﬁned operations (i.e. division by zero and some
operations involving ∞). They lead to program termination.

474
T. Rienstra
Given a boolean expression b we will write κ(b) as shorthand for κ([b]κ) and
κb as shorthand for κ[b]κ. We are now ready to deﬁne the semantics of statements.
It is captured by seven rules, numbered (D1) to (D7). The ﬁrst deals with the
skip statement, which does nothing and therefore maps to the identity function.
D[[skip]](κ) = κ.
(D1)
The meaning of s1; s2 is the composition of D[[s1]] and D[[s2]].
D[[s1; s2]](κ) = D[[s2]](D[[s1]](κ))
(D2)
The rank of a valuation σ after executing an assignment x := e is the minimum
of all ranks of valuations that equal σ after assigning the value of e to x.
D[[x := e]](κ)(σ) = κ({σ′ ∈Ω | σ = σ′[x →σ′
κ(e)]})
(D3)
To execute if b then {s1} else {s2} we ﬁrst execute s1 and s2 conditional on
b and ¬b, yielding the rankings D[[s1]](κb) and D[[s2]](κ¬b). These are adjusted
by adding the prior ranks of b and ¬b and combined by taking the minimum of
the two. The result is normalized to account for the case where one branch fails.
D[[if e then {s1} else {s2}]](κ) = ||λ||,
where λ(σ) = min

D[[s1]](κb)(σ) + κ(b),
D[[s2]](κ¬b)(σ) + κ(¬b)

(D4)
Given a prior κ, the rank of a valuation after executing s1 ⟨⟨⟨e⟩⟩⟩s2 is the minimum
of the ranks assigned by D[[s1]](κ) and D[[s2]](κ), where the latter is increased
by e. The result is normalized to account for the case where one branch fails.
D[[{s1} ⟨⟨⟨e⟩⟩⟩{s2}]](κ) = ||λ||, where λ(σ) = min

D[[s1]](κ)(σ),
D[[s2]](κ)(σ) + σκ(e)

(D5)
The semantics of observe b corresponds to conditioning on the set of valuations
satisfying b, unless the rank of this set is ∞or the prior ranking equals κ∞.
D[[observe b]](κ) =
κ∞if κ = κ∞or κ(b) = ∞, or
κb otherwise.
(D6)
We deﬁne the semantics of while b do {s} as the iterative execution of if b then
{s} else {skip} until the rank of b is ∞(the loop terminates normally) or the
result is undeﬁned (s does not terminate). If neither of these conditions is ever
met (i.e., if the while statement loops endlessly) then the result is undeﬁned.
D[[while b do{s}]](κ) =
F n
b,s(κ) for the ﬁrst n s.t. F n
b,s(κ)(b) = ∞, or
undef. if there is no such n,
(D7)
where Fb,s : K⊥→K⊥is deﬁned by Fb,s(κ) = D[[if b then {s} else{skip}]](κ).
Some remarks. Firstly, the semantics of RankPL can be thought of as a
ranking-based variation of the Kozen’s semantics of probabistic programs [6]

RankPL: A Qualitative Probabilistic Programming Language
475
(i.e., replacing × with + and + with min). Secondly, a RankPL implementation
does not need to compute complete rankings. Our implementation discussed in
Sect. 5 follows a most-plausible-ﬁrst execution strategy: diﬀerent alternatives are
explored in ascending order w.r.t. rank, and higher-ranked alternatives need not
be explored if knowing the lowest-ranked outcomes is enough, as is often the case.
Example. Consider the two-bit full adder circuit shown in Fig. 1. It contains
two XOR gates X1, X2, two AND gates A1, A2 and an OR gate O1. The function
of this circuit is to generate a binary representation (b1, b2) of the number of
inputs among a1, a2, a3 that are high. The circuit diagnosis problem is about
explaining observed incorrect behavior by ﬁnding minimal sets of gates that, if
faulty, cause this behavior.2
Fig. 1. A two-bit full adder
The listing below shows a RankPL solution. On line 1 we set the constants
L and H (representing a low and high signal); and OK and FAIL (to represent
the state of a gate). Line 2 encodes the space of possible inputs (L or H, equally
likely). The failure variables fa1, fa2, fo1, fx2 and fx2 represent the events
of individual gates failing and are set on line 3. Here, we assume that failure
is surprising to degree 1. The circuit’s logic is encoded on lines 4–8, where the
output of a failing gate is arbitrarily set to L or H. Note that ⊕stands for XOR.
At the end we observe φ.
1 L := 0; H := 1; OK := 0; FAIL := 1;
2 a1 := (L ⟨⟨⟨0⟩⟩⟩H); a2 := (L ⟨⟨⟨0⟩⟩⟩H); a3 := (L ⟨⟨⟨0⟩⟩⟩H);
3 fx1 := (OK ⟨⟨⟨1⟩⟩⟩FAIL); fx2 := (OK ⟨⟨⟨1⟩⟩⟩FAIL); fa1 := (OK ⟨⟨⟨1⟩⟩⟩FAIL);
fa2 := (OK ⟨⟨⟨1⟩⟩⟩FAIL); fo1 := (OK ⟨⟨⟨1⟩⟩⟩FAIL);
4 if fx1 = OK then l1 := a1 ⊕a2 else l1 := (L ⟨⟨⟨0⟩⟩⟩H);
5 if fa1 = OK then l2 := a1 ∧a2 else l2 := (L ⟨⟨⟨0⟩⟩⟩H);
6 if fa2 = OK then l3 := l1 ∧a3 else l3 := (L ⟨⟨⟨0⟩⟩⟩H);
7 if fx2 = OK then b2 := l1 ⊕a3 else b2 := (L ⟨⟨⟨0⟩⟩⟩H);
8 if fo1 = OK then b1 := l3 ∨l2 else b1 := (L ⟨⟨⟨0⟩⟩⟩H);
9 observe φ;
The diﬀerent valuations of the failure variables produced by this program
represent explanations for the observation φ, ranked according to plausibil-
ity. Suppose we observe that the input (a1, a2, a3) is valued (L,L,H) while the
2 See Halpern [5, Chap. 9] for a similar treatment of this example.

476
T. Rienstra
output (b1, b2) is incorrectly valued (H,L) instead of (L,H). Thus, we set φ to
a1 = L ∧a2 = L ∧a3 = H ∧b1 = H ∧b2 = L. The program then produces one
outcome ranked 0, namely (fa1, fa2, fo1, fx2, fx2) = (OK, OK, OK, FAIL, OK). That
is, φ is most plausibly explained by failure of X1. Other outcomes are ranked
higher than 0 and represent explanations involving more than one faulty gate.
4
Noisy Observation and Iterated Revision
Conditioning by A means that A becomes believed with inﬁnite ﬁrmness. This is
undesirable if we have to deal with iterated belief change or noisy or untrustwor-
thy observations, since we cannot, after conditioning on A, condition on events
inconsistent with A. J-conditioning [3] is a more general form of conditioning
that addresses this problem. It is parametrized by a rank x that indicates the
ﬁrmness with which the evidence must be believed.
Deﬁnition 3. Let A ∈Ω, κ a ranking function over Ω such that κ(A), κ(A) <
∞, and x a rank. The J-conditioning of κ by A with strength x, denoted by
κA→x, is deﬁned by κA→x(B) = min(κ(B|A), κ(B|A) + x).
In words, the eﬀect of J-conditioning by A with strength x is that A becomes
believed with ﬁrmness x. This permits iterated belief change, because the rank
of A is shifted up only by a ﬁnite number of ranks and hence can be shifted
down again afterwards. Instead of introducing a special statement represent-
ing J-conditioning, we show that we can already express it in RankPL, using
ranked choice and observation as basic building blocks. Below we write κb→x as
shorthand for κ[b]κ→x. Proofs are omitted due to space constraints.
Theorem 1. Let b be a boolean expression and κ a ranking function s.t. κ(b) < ∞
and κ(¬b) < ∞. We then have κb→x = D[[{observe b} ⟨⟨⟨x⟩⟩⟩{observe ¬b]](κ)}.
L-conditioning [3] is another kind of generalized conditioning. Here, the para-
meter x characterizes the ‘impact’ of the evidence.
Deﬁnition 4. Let A ∈Ω, κ a ranking function over Ω such that κ(A), κ(A) <
∞, and x a rank. The L-conditioning of κ is denoted by κA↑x and is deﬁned by
κA↑x(B) = min(κ(A ∩B) −y, κ(¬A ∩B) + x −y), where y = min(κ(A), x).
Thus, L-conditioning by A with strength x means that A improves by x
ranks w.r.t. the rank of ¬A. Unlike J-conditioning, L-conditioning satisﬁes
two properties that are desirable for modeling noisy observation: reversibility
((κA↑x)A↑x = κ) and commutativity ((κA↑x)B↑x = (κB↑x)A↑x) [11]. We can
expression L-conditioning in RankPL using ranked choice, observation and the
rank expression as basic building blocks. Like before, we write κb↑x to denote
κ[b]κ↑x.
Theorem 2. Let b be a boolean expression, κ a ranking function over Ω such
that κ(b), κ(¬b) < ∞, and x a rank. We then have:

RankPL: A Qualitative Probabilistic Programming Language
477
κb↑x = D


if (rank(b) ≤x) then
{observe b} ⟨⟨⟨x −rank(b) + rank(¬b)⟩⟩⟩{observe ¬b}
else
{observe ¬b} ⟨⟨⟨rank(b) −x⟩⟩⟩{observe b}

 (κ)
In what follows we use the statement observeL(b, x) as shorthand for the state-
ment that represents L-conditioning as deﬁned in Theorem 2.
Example. This example involves both iterated revision and noisy observation.
A robot navigates a grid world and has to determine its location using a map and
two distance sensors. Figure 2 depicts the map that we use. Gray cells represent
walls and other cells are empty (ignoring, for now, the red cells and dots). The
sensors (oriented north and south) measure the distance to the nearest wall or
obstacle. To complicate matters, the sensor readings might not match the map.
For example, the X in Fig. 2 marks an obstacle that aﬀects sensor readings, but
as far as the robot knows, this cell is empty.
The listing below shows a RankPL solution. The program takes as input:
(1) A map, held by an array map of size m × n, storing the content of each
cell (0 = empty, 1 = wall); (2) An array mv (length k) of movements (N/E/S/W
for north/east/south/west) at given time points; and (3) Two arrays ns and
ss (length k) with distances read by the north and south sensor at given time
points. Note that, semantically, arrays are just indexed variables.
Input: k: number of steps to simulate
Input: mv: array (size ≥k) of movements (N/E/S/W)
Input: ns and ss: arrays (size ≥k) of north and south sensor readings
Input: map: 2D array (size m × n) encoding the map
1 t := 0; x := 0 ⟨⟨⟨0⟩⟩⟩{1 ⟨⟨⟨0⟩⟩⟩{2 ⟨⟨⟨0⟩⟩⟩. . . m}}; y := 0 ⟨⟨⟨0⟩⟩⟩{1 ⟨⟨⟨0⟩⟩⟩{2 ⟨⟨⟨0⟩⟩⟩. . . n}};
2 while (t < k) do {
3
if (mv[t] = N) then y := y + 1
4
else if (mv[t] = S) then y := y −1
5
else if (mv[t] = W) then x := x −1
6
else if (mv[t] = E) then x := x + 1 else skip;
7
nd := 0; while map[x][y + nd + 1] = 0 do nd := nd + 1;
8
observeL(1, nd = ns[t]);
9
sd := 0; while map[x][y −sd −1] = 0 do sd := sd + 1;
10
observeL(1, sd = ss[t]);
11
t := t + 1;
12 }
The program works as follows. On line 1 the time point t is set to 0 and the
robot’s location (x, y) is set to a randomly chosen coordinate (all equally likely)
using nested ranked choice statements. Inside the while loop, which iterates
over t, we ﬁrst process the movement mv[t] (lines 3–6). We then process (lines
7–8) the north sensor reading, by counting empty cells between the robot and
nearest wall, the result of which is observed to equal ns[t]—and likewise for the

478
T. Rienstra
Fig. 2. Most plausible inferred locations during four iterations (Color ﬁgure online)
south sensor (lines 9–10). We use L-conditioning with strength 1 to account for
possible incorrect observations. On line 11 we update t.
Suppose we want to simulate a movement from (0, 5) to (4, 5). Thus, we use
the inputs mv = {E, E, E, E}, ns = {1, 1, 1, 1}, ss = {2, 1, 2, 3}, while map is
set as shown in Fig. 2 (i.e., 1 for every cell containing a wall, 0 for every other
cell). Note that the observed distances stored in ns and ss are consistent with
the distances observed along this path, where, at t = 1, the south sensor reads
a distance of 1 instead of 2, due to the obstacle X.
The diﬀerent values of x, y generated by this program encode possible loca-
tions of the robot, ranked according to plausibility. The dots in Fig. 2 show the
actual locations, while the red cells represent the inferred most plausible (i.e.,
rank zero) locations generated by the program. Terminating after t = 0 (i.e.,
setting k to 1) yields four locations, all consistent with the observed distances 1
(north) and 2 (south). If we terminate after t = 1, the robot wrongly believes to
be at (6, 4), due to having observed the obstacle. However, if we terminate after
t = 3, the program produces the actual location.
Note that using L-conditioning here is essential. Regular conditioning would
cause failure after the third iteration. We could also have used J-conditioning,
which gives diﬀerent rankings of intermediate results.
5
Implementation
A RankPL interpreter written in Java can be found at http://github.com/tjitze/
RankPL. It runs programs written using the syntax described in this paper, or
constructed using Java classes that map to this syntax. The latter makes it
possible to embed RankPL programs inside Java code and to make it interact
with and use classes and methods written Java. The interpreter is faithful to the
semantics described in Sect. 3 and implements the most-plausible-ﬁrst execution
strategy discussed in Sect. 3.2. All examples discussed in this paper are included,
as well as a number of additional examples.
6
Conclusion and Future Work
We have introduced RankPL, a language semantically similar to probabilistic
programming, but based on Spohn’s ranking theory, and demonstrated its utility

RankPL: A Qualitative Probabilistic Programming Language
479
using examples involving abduction and iterated revision. We believe that the
approach has great potential for applications where PPLs are too demanding
due to their computational complexity and dependence on precise probability
values. Moreover, we hope that our approach will generate a broader and more
practical scope for the topics of ranking theory and belief revision which, in the
past, have been studied mostly from purely theoretical perspectives.
A number of aspects were not touched upon and will be addressed in future
work. This includes a more ﬁne grained characterization of termination and a
discussion of the relationship with nondeterministic programming, which is a
special case of RankPL. Furthermore, we have omitted examples to show that
RankPL subsumes ranking networks and can be used to reason about causal rules
and actions [3]. We also did not contrast our approach with default reasoning
formalisms that use ranking theory as a semantic foundation (see, e.g., [9]).
Even though we demonstrated that RankPL is expressive enough to solve
fairly complex tasks in a compact manner, it is a very basic language that is
best regarded as proof of concept. In principle, the approach can be applied to
any programming language, whether object-oriented, functional, or LISP-like.
Doing so would make it possible to reason about ranking-based models expressed
using, for example, recursion and complex data structures. These features are
also supported by PPLs such as Church [4], Venture [8] and Figaro [10].
References
1. Darwiche, A., Pearl, J.: On the logic of iterated belief revision. Artif. Intell. 89(1–
2), 1–29 (1996)
2. G¨ardenfors, P., Rott, H.: Belief revision. In: Gabbay, D.M., Hogger, C.J., Robinson,
J.A. (eds.) Handbook of Logic in Artiﬁcial Intelligence and Logic Programming,
vol. 4, pp. 35–132. Oxford University Press, Oxford (1995)
3. Goldszmidt, M., Pearl, J.: Qualitative probabilities for default reasoning, belief
revision, and causal modeling. Artif. Intell. 84(1), 57–112 (1996)
4. Goodman, N.D., Mansinghka, V.K., Roy, D.M., Bonawitz, K., Tenenbaum, J.B.:
Church: a language for generative models. In: McAllester, D.A., Myllym¨aki, P.
(eds.) UAI 2008, Proceedings of the 24th Conference in Uncertainty in Artiﬁcial
Intelligence, Helsinki, Finland, 9–12 July 2008, pp. 220–229. AUAI Press, Helsinki
(2008)
5. Halpern, J.Y.: Reasoning about Uncertainty. MIT Press, Cambridge (2005)
6. Kozen, D.: Semantics of probabilistic programs. J. Comput. Syst. Sci. 22(3), 328–
350 (1981)
7. Kyburg Jr., H.E.: Probability and the Logic of Rational Belief (1961)
8. Mansinghka, V.K., Selsam, D., Perov, Y.N.: Venture: a higher-order probabilistic
programming platform with programmable inference (2014). CoRR abs/1404.0099
9. Pearl, J.: System Z: a natural ordering of defaults with tractable applications to
nonmonotonic reasoning. In: Parikh, R. (ed.) Proceedings of the 3rd Conference
on Theoretical Aspects of Reasoning about Knowledge, Paciﬁc Grove, CA, March
1990, pp. 121–135. Morgan Kaufmann, San Mateo (1990)
10. Pfeﬀer, A.: Figaro: an object-oriented probabilistic programming language. Charles
River Analytics Technical Report 137 (2009)
11. Spohn, W.: The Laws of Belief - Ranking Theory and Its Philosophical Applica-
tions. Oxford University Press, Oxford (2014)

Generalized Probabilistic Modus Ponens
Giuseppe Sanﬁlippo1(B), Niki Pfeifer2, and Angelo Gilio3
1 Department of Mathematics and Computer Science,
University of Palermo, Palermo, Italy
giuseppe.sanfilippo@unipa.it
2 Munich Center for Mathematical Philosophy, LMU Munich, Munich, Germany
niki.pfeifer@lmu.de
3 Department SBAI, University of Rome “La Sapienza”, Rome, Italy
angelo.gilio@sbai.uniroma1.it
Abstract. Modus ponens (from A and “if A then C” infer C) is one
of the most basic inference rules. The probabilistic modus ponens allows
for managing uncertainty by transmitting assigned uncertainties from
the premises to the conclusion (i.e., from P(A) and P(C|A) infer P(C)).
In this paper, we generalize the probabilistic modus ponens by replacing
A by the conditional event A|H. The resulting inference rule involves
iterated conditionals (formalized by conditional random quantities) and
propagates previsions from the premises to the conclusion. Interestingly,
the propagation rules for the lower and the upper bounds on the con-
clusion of the generalized probabilistic modus ponens coincide with the
respective bounds on the conclusion for the (non-nested) probabilistic
modus ponens.
Keywords: Coherence · Conditional random quantities · Conjoined
conditionals · Iterated conditionals · Modus ponens · Prevision
1
Introduction
There is a long ongoing interest in combining logic and probability (see, e.g.,
[7,13,27,31]). In this paper we use coherence-based probability logic, which is
characterized by properly managing conditioning events of zero probability and
by using arbitrary families of conditional events (see, e.g., [4,9,10,17,21]). Specif-
ically, we investigate and generalize the modus ponens (from A and “if A then C”
infer C) which is one of the most basic and important inference rules. By instanti-
ating the antecedent of a conditional it allows for detaching the consequent of the
conclusion. It is well-known that modus ponens is logically valid (i.e., it is impos-
sible that A and A∨C are true while C is false, where the event A∨C denotes the
material conditional as deﬁned in classical logic). It is also well-known that there
G. Sanﬁlippo—Partially supported by INdAM–GNAMPA Project 2016 Grant U
2016/000391
N. Pfeifer—Supported by his DFG project PF 740/2-2 (within the SPP1516)
A. Gilio—Retired
c
⃝Springer International Publishing AG 2017
A. Antonucci et al. (Eds.): ECSQARU 2017, LNAI 10369, pp. 480–490, 2017.
DOI: 10.1007/978-3-319-61581-3 43

Generalized Probabilistic Modus Ponens
481
are philosophical arguments [2,14] and psychological arguments [15,35] in favor of
the hypothesis that a conditional if A, then C is best represented by a suitable con-
ditional probability assertion P(C|A) and not by a probability of a corresponding
material conditional P(A ∨C). Consequently, coherence-based probability logic
generalizes the classical modus ponens probabilistically by propagating assigned
probabilities from the premises to the conclusion as follows (see, e.g., [36,37,41]):
Probabilistic modus ponens. From P(A) = x (probabilistic categorical
premise) and P(C|A) = y (probabilistic conditional premise) infer xy ≤P(C) ≤
xy + 1 −x (probabilistic conclusion).
In our paper, P(C|A) is the probability of the conditional event C|A (see, e.g.,
[10–12,21,29,38,39]). The probabilistic modus ponens is p-valid, which means
that the premise set {A, C|A} p-entails the conclusion C (i.e., if P(A) = 1
and P(C|A) = 1, then P(C) = 1); moreover, it is probabilistically informative
([19,21,24,37]). However, we recall that some other classical logic inference rules
are not p-valid, for instance transitivity is in general not p-valid, i.e., the premise
set {A|H, C|A} does not p-entail the conclusion C|H ([21]). We observe that
the lower and upper bounds for the conclusion of the CUT rule coincide with
the lower and upper bounds for the conclusion of the modus ponens; indeed, if
P(A|H) = x and P(C|A ∧H) = y it holds that xy ≤P(C|H) ≤xy + 1 −x
([17]). The CUT rule is also p-valid and reduces to modus ponens when H is the
sure event.
In this paper we generalize the probabilistic modus ponens by replacing the
categorical premise (i.e., A) and the antecedent of the conditional premise (i.e.,
A in “if A then C”) by the conditional event A|H. The resulting inference rule
involves the prevision P(C|(A|H)) of the iterated conditional C|(A|H) (formal-
ized by a suitable conditional random quantity, see [20,22,23,26]) and propagates
the uncertainty from the premises to the conclusion:
Generalized probabilistic modus ponens. From P(A|H) (generalized cat-
egorical premise) and P(C|(A|H)) (generalized conditional premise) infer P(C)
(conclusion).
The conditional event A|H is interpreted as a conditional random quantity, with
P(A|H) = P(A|H) (see below). As mentioned above, modus ponens instantiates
the antecedent of a conditional and governs the detachment of the consequent of
the conclusion. In our generalization, we study the case where the unconditional
event A is replaced by the conditional event (A|H) and the conditional event
C|A is replaced by the iterated conditional C|(A|H). The following instantiation
is an example of our generalization (see, e.g., [16, p. 237]):
A|H



The cup breaks if dropped.
If
A|H



the cup breaks if dropped, then
C



the cup is fragile.
Therefore,
C



the cup is fragile.

482
G. Sanﬁlippo et al.
In what follows, we study how to interpret the uncertainty of the premises and
how to propagate the uncertainty from the premises to the conclusion. The out-
line of the paper is as follows. In Sect. 2 we ﬁrst recall basic notions and results
on coherence and previsions of conditional random quantities. Then, we illus-
trate the notions of conjunction and of iterated conditional involving conditional
events, by recalling some results. In Sect. 3 we prove a generalized decomposition
formula for conditional events, with other results on compounded and iterated
conditionals. Then, we propagate the previsions from the premises of the gener-
alized probabilistic modus ponens to the conclusion. We observe that this prop-
agation rule coincides with the probability propagation rule for the (non-nested)
probabilistic modus ponens (where H = Ω) [37]. Section 4 concludes the paper
with an outlook for future work.
2
Preliminary Notions
In this section we recall some basic notions and results on coherence for condi-
tional prevision assessments. In our approach an event A represents an uncertain
fact described by a (non-ambiguous) logical entity, where A is two-valued and
can be true (T), or false (F). The indicator of A, denoted by the same symbol,
is a two-valued numerical quantity which is 1, or 0, according to whether A is
true, or false, respectively. The sure event is denoted by Ω and the impossible
event is denoted by ∅. Moreover, we denote by A ∧B, or simply AB, (resp.,
A ∨B) the logical conjunction (resp., logical disjunction). The negation of A is
denoted by A. Given any events A and B, we simply write A ⊆B to denote that
A logically implies B, that is, AB is the impossible event ∅. We recall that n
events are logically independent when the number m of constituents, or possible
worlds, generated by them is 2n (in general m ≤2n). Given two events A and
H, with H ̸= ∅, the conditional event A|H is deﬁned as a three-valued logical
entity which is true if AH is true, false if AH is true, and void if H is false. In
terms of random quantities, the symbol A|H also denotes the random quantity
AH + pH ∈{1, 0, p}, where p = P(A|H). Moreover, the negation of A|H is
deﬁned as A|H = 1 −A|H = A|H. Notice that, in the approach of de Finetti,
the usual terms random variable and expected value are replaced by random
quantity and prevision, respectively.
2.1
Coherent Conditional Prevision
We recall the notion of coherent conditional prevision (see, e.g., [5,6,8,10,21,26,
34]). Let K be an arbitrary family of conditional random quantities with ﬁnite
sets of possible values. Moreover, let P be a prevision function deﬁned on K.
Consider a ﬁnite subfamily Fn = {Xi|Hi, i ∈Jn} ⊆K, where Jn = {1, . . . , n},
and the vector Mn = (μi, i ∈Jn), where μi = P(Xi|Hi) is the assessed prevision
for the conditional random quantity Xi|Hi. With the pair (Fn, Mn) we associate
the random gain G = 
i∈Jn siHi(Xi −μi); moreover, we set Hn = H1 ∨· · ·∨Hn
and we denote by GHn the set of values of G restricted to Hn. Then, using the
betting scheme of de Finetti, we stipulate

Generalized Probabilistic Modus Ponens
483
Deﬁnition 1. The function P deﬁned on K is coherent if and only if, ∀n ≥1,
∀Fn ⊆K, ∀s1, . . . , sn ∈R, it holds that: min GHn ≤0 ≤max GHn.
Given a family Fn = {X1|H1, . . . , Xn|Hn}, for each i ∈Jn we denote by
{xi1, . . . , xiri} the set of possible values of the random quantity Xi when
the conditioning event Hi is true (that is, {xi1, . . . , xiri} is the set of pos-
sible values for the restriction of Xi to Hi); then, for each i ∈Jn and
j = 1, . . . , ri, we set Aij = (Xi = xij). Of course, for each i ∈Jn, the
family {Hi, AijHi , j = 1, . . . , ri} is a partition of the sure event Ω, with
AijHi = Aij, ri
j=1 Aij = Hi. Then, the constituents generated by the fam-
ily Fn are (the elements of the partition of Ω) obtained by expanding the
expression 
i∈Jn(Ai1 ∨· · · ∨Airi ∨Hi). We set C0 = H1 · · · Hn (it may be
C0 = ∅); moreover, we denote by C1, . . . , Cm the constituents contained in
Hn = H1 ∨· · · ∨Hn. Hence 
i∈Jn(Ai1 ∨· · · ∨Airi ∨Hi) = m
h=0 Ch. With
each Ch, h ∈Jm, we associate a vector Qh = (qh1, . . . , qhn), where qhi = xij
if Ch ⊆Aij, j = 1, . . . , ri, while qhi = μi if Ch ⊆Hi; C0 is associated with
Q0 = Mn = (μ1, . . . , μn). Denoting by In the convex hull of Q1, . . . , Qm, the
condition Mn ∈In amounts to the existence of a vector (λ1, . . . , λm) such that:

h∈Jm λhQh = Mn , 
h∈Jm λh = 1 , λh ≥0 , ∀h; in other words, Mn ∈In is
equivalent to the solvability of the system (Σn), associated with (Fn, Mn),
(Σn)

h∈Jm λhqhi = μi , i ∈Jn ; 
h∈Jm λh = 1 ; λh ≥0 , h ∈Jm.
(1)
Given the assessment Mn = (μ1, . . . , μn) on Fn = {X1|H1, . . . , Xn|Hn}, let S
be the set of solutions Λ = (λ1, . . . , λm) of system (Σn) deﬁned in (1). Then, the
following characterization theorem for coherent assessments on ﬁnite families of
conditional events can be proved ([5]).
Theorem 1 [Characterization of coherence]. Given a family of n conditional
random quantities Fn = {X1|H1, . . . , Xn|Hn}, with ﬁnite sets of possible val-
ues, and a vector Mn = (μ1, . . . , μn), the conditional prevision assessment
P(X1|H1) = μ1 , . . . , P(Xn|Hn) = μn is coherent if and only if, for every subset
J ⊆Jn, deﬁning FJ = {Xi|Hi , i ∈J}, MJ = (μi , i ∈J), the system (ΣJ)
associated with the pair (FJ, MJ) is solvable.
We point out that the solvability of system (Σn) (i.e., the condition Mn ∈In)
is a necessary (but not suﬃcient) condition for coherence of Mn on Fn.
Coherence can be also characterized in terms of proper scoring rules ([6]),
which can be related to the notion of entropy in information theory ([30]).
2.2
Conjunction and Iterated Conditional
Given a random quantity X and a non impossible event H, the conditional
random quantity X|H can be seen as the random quantity XH + μH, where
μ = P(X|H) ([22,23,26]). Before introducing the notion of conjunction (see also
[28] for related work), we observe that given any pair of conditional events A|H
and B|K, with P(A|H) = x, P(B|K) = y, in numerical terms they coincide with
the random quantities AH + xH and BK + yK, respectively; then, the symbol
min {A|H, B|K} denotes the random quantity min {AH + xH, BK + yK}.

484
G. Sanﬁlippo et al.
Deﬁnition 2. Given any pair of conditional events A|H and B|K, with
P(A|H) = x, P(B|K) = y, we deﬁne their conjunction as the conditional ran-
dom quantity (A|H) ∧(B|K) = Z | (H ∨K), where Z = min {A|H, B|K}.
Of course, the random quantity Z, as a function of the random quantities A|H
and B|K, is deﬁned on the set of possible values of the random vector (A|H, B|K).
Based on the betting scheme, the compound conditional (A|H)∧(B|K) coincides
with 1 · AHBK + x · HBK + y · AHK + z · HK, where z is the prevision of
the random quantity (A|H) ∧(B|K), denoted by P[(A|H) ∧(B|K)]. Notice that
z represents the amount you agree to pay, with the proviso that you will receive
the random quantity (A|H) ∧(B|K). In other words, you agree to pay z with the
proviso that you will receive: 1, if both conditional events are true; 0, if at least one
of the conditional events is false; z, if both conditional events are void; the proba-
bility of that conditional event which is void (i.e., either x or y), otherwise. Notice
that this notion of conjunction, with positive probabilities for the conditioning
events, has been already proposed in [33].
A well-known notion of conjunction among conditional events, which plays an
important role in nonmonotonic reasoning, is the quasi conjunction [1,3,24], i.e.,
the following conditional event: QC(A|H, B|K) = (AH∨H)∧(BK∨K)|(H∨K).
In numerical terms, since AH ∨H = AH +H and BK ∨K = BK +K, the quasi
conjunction is the following conditional random quantity: QC(A|H, B|K) =
min {AH + H, BK + K} | (H ∨K). As it is well known, AH ∨H is the mater-
ial conditional associated with the conditional “if H then A”. Then, the quasi
conjunction is deﬁned by taking the minimum of the material conditionals given
H ∨K. However, we deﬁne the conjunction by taking the minimum of the condi-
tional events given H ∨K. Our conjunction is (in general) a conditional random
quantity, whereas the quasi conjunction is a conditional event. Moreover, as
given in Theorem 2 ([26]), classical results concerning lower and upper bounds
for the conjunction of unconditional events still hold for our notion of conjunc-
tion, which do not hold for the upper bound of the quasi conjunction ([18,25]):
Theorem 2. Let A, H, B, K be logically independent events with H ̸= ∅, K ̸=
∅. Given any coherent assessment P(A|H) = x and P(B|K) = y, then the
extension z = P[(A|H) ∧(B|K)] is coherent if and only if the Fr´echet-Hoeﬀding
bounds are satisﬁed: max{x + y −1, 0} ≤z ≤min{x, y}.
Now, we recall the notion of iterated conditioning.
Deﬁnition 3 (Iterated conditioning). Given any pair of conditional events
A|H and B|K, the iterated conditional (B|K)|(A|H) is the conditional random
quantity (B|K)|(A|H) = (B|K) ∧(A|H) + μA|H, where μ = P[(B|K)|(A|H)].

Generalized Probabilistic Modus Ponens
485
Notice that, in the context of betting scheme, μ = P[(B|K)|(A|H)] represents
the amount you agree to pay, with the proviso that you will receive the quantity
(B|K)|(A|H) =
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩
1,
if AHBK true,
0,
if AHBK true,
y,
if AHK true,
μ,
if AH true,
x + μ(1 −x), if HBK true,
μ(1 −x),
if HBK true,
z + μ(1 −x), if HK true.
(2)
By applying Deﬁnition 3, with K
= Ω, the iterated conditional becomes
B|(A|H) = B ∧(A|H) + μA|H, where μ = P[B|(A|H)]. Moreover, the values of
B|(A|H) are 1, 0, μ, x+μ(1−x), and μ(1−x), associated with the constituents
AHB, AHB, AH, HB, and HB, respectively.
We recall that if a conditional random quantity is a conditional event, then
its prevision (P) coincides with its probability (P). By linearity of prevision
([26]) it holds that P[(B|K)|(A|H)] = μ = P[(B|K) ∧(A|H)] + μP(A|H) =
z + μ(1 −x), from which it follows z = μ · x, that is P[(B|K) ∧(A|H)] =
P[(B|K)|(A|H)]P(A|H). More formally (see also [23]),
Theorem 3 (Product formula). Given any assessment x = P(A|H), μ =
P[(B|K)|(A|H)], z = P[(B|K) ∧(A|H)], if (x, μ, z) is coherent, then z = μ · x.
Concerning Deﬁnition 3, it may seem strange that, in the context of betting
scheme, the bet is called oﬀwhen A|H is false and not when A|H is void.
However, we point out that our deﬁnition is reasonable because it preserves the
product formula.
We recall that coherence requires that (x, y, μ, z) ∈[0, 1]4 (see, e.g., [20]).
Remark 1. We note that in our approach the iterated conditional (A|H)|K does
not coincide with the conditional event A|HK ([26]). Moreover, in our approach
(A|H)|K is (not a conditional event but) a conditional random quantity. There-
fore, the Import-Export Principle ([33]) does not hold in our approach (like
in [1,28]). Thus, as shown in [26] we avoid the counter-intuitive consequences
related to well-known ﬁrst triviality result by Lewis ([32]).
Remark 2. Given any random quantity X and any events H, K, with H ⊆K,
H ̸= ∅, it holds that (see [26, Sect. 3.3]): (X|H)|K = X|HK = X|H. In particu-
lar, given any events A, H, K, with H ̸= ∅, it holds that: (A|H)|(H ∨K) = A|H.
3
Generalized Modus Ponens
In this section we present a decomposition formula, by also considering a par-
ticular case. Then, we give a result on the coherence of a prevision assessment
on F = {A|H, C|(A|H), C|(A|H)} which will be used to obtain the generalized
modus ponens.

486
G. Sanﬁlippo et al.
Proposition 1. Let A|H, B|K be two conditional events. Then
B|K = (A|H) ∧(B|K) + (A|H) ∧(B|K).
(3)
Proof. Let (x, y, z1, z2) be a (coherent) prevision on (A|H, B|K, (A|H) ∧
(B|K), (A|H) ∧(B|K)). Of course, coherence requires that P(A|H) = 1 −x. By
Deﬁnition 2 it holds that (A|H) ∧(B|K) = AHBK + xHBK + yKAH + z1HK
and (A|H) ∧(B|K) = AHBK + (1 −x)HBK + yKAH + z2HK. Then,
(A|H) ∧(B|K) + (A|H) ∧(B|K) = HBK + HBK + yKH + z1HK + z2HK
= BK + yKH + (z1 + z2)HK.
(4)
Moreover,
B|K = BK + yK = BK + yKH + yHK.
(5)
From (4) and (5), when H ∨K is true, it holds that
(A|H) ∧(B|K) + (A|H) ∧(B|K) = BK + yKH = B|K.
Then, the diﬀerence [(A|H) ∧(B|K) + (A|H) ∧(B|K)] −B|K is zero when
H ∨K is true. Thus, P[((A|H) ∧(B|K) + (A|H) ∧(B|K) −B|K)|(H ∨K)] =
P[((A|H)∧(B|K))|(H∨K)]+P[((A|H)∧(B|K))|(H∨K)]−P[(B|K)|(H∨K)] = 0.
By Remark 2 it holds that [(A|H) ∧(B|K)]|(H ∨K), [(A|H) ∧(B|K)]|(H ∨K),
and (B|K)|(H ∨K) coincide with (A|H) ∧(B|K), (A|H) ∧(B|K), and B|K,
respectively. Then,
P[((A|H) ∧(B|K) + (A|H) ∧(B|K) −B|K)|(H ∨K)] =
P[(A|H) ∧(B|K)] + P[(A|H) ∧(B|K)] −P(B|K) = z1 + z2 −y = 0.
Therefore, (A|H) ∧(B|K) + (A|H) ∧(B|K) and B|K also coincide when H ∨K
is false. Thus, (A|H) ∧(B|K) + (A|H) ∧(B|K) = B|K.
From Proposition 1, by the linearity of prevision, and by the product formula,
we obtain P(B|K) = P[(B|K)|(A|H)]P(A|H) + P[(B|K)|(A|H)]P(A|H).
Remark 3. Notice that Proposition 1 also holds when there are some logical rela-
tions among the events A, B, H, K, provided that H ̸= ∅and K ̸= ∅. In partic-
ular, if K = Ω the proof of Proposition 1 is simpler because, by Deﬁnition 2,
(A|H) ∧B = AHB + xHB, (A|H) ∧B = AHB + (1 −x)HB,
hence
(A|H) ∧B + (A|H) ∧B = HB + HB = B.
(6)
The next result shows that, assuming logical independence, every point (x, y, z) ∈
[0, 1]3 is a coherent assessment on {A|H, C|(A|H), C|(A|H)}.
Theorem 4. Let three logically independent events A, C, H be given, with
A ̸= ∅, H
̸= ∅. The set of all coherent assessments M = (x, y, z) on
F = {A|H, C|(A|H), C|(A|H)} is the unit cube [0, 1]3.

Generalized Probabilistic Modus Ponens
487
Due to the lack of space we omit the proof of Theorem 4. A detailed proof of
this theorem is available in [40]: by exploiting Theorem 1 the coherence of any
assessment M = (x, y, z) ∈[0, 1]3 on F = {A|H, C|(A|H), C|(A|H)} is proved
by showing that for each subset J ⊆{1, 2, 3} the respective system (ΣJ) is
solvable.
We now generalize the modus ponens to the case where the ﬁrst premise A
is replaced by the conditional event A|H.
Theorem 5. Given any coherent assessment (x, y) on {A|H, C|(A|H)}, with
A, C, H logically independent, with A ̸= ∅and H ̸= ∅, the extension z = P(C)
is coherent if and only if z ∈[z′, z′′], where
z′ = xy
and
z′′ = xy + 1 −x.
(7)
Proof. We recall that (Theorem 4) the assessment (x, y) on {A|H, C|(A|H)} is
coherent for every (x, y) ∈[0, 1]2. From (6), by the linearity of prevision, and by
Theorem 3, we obtain
z = P(C) = P[(A|H) ∧C + (A|H) ∧C] = P[(A|H) ∧C] + P[(A|H) ∧C]
= P(A|H)P[C|(A|H)] + P(A|H)P[C|(A|H)] = xy + (1 −x)P[C|(A|H)].
From Theorem 4, given any coherent assessment (x, y) on {A|H, C|(A|H)}, the
extension t = P[C|(A|H)] on C|(A|H) is coherent for every t ∈[0, 1]. Then, as
z = xy + (1 −x)t, it follows that z′ = xy and z′′ = xy + 1 −x.
We notice that Theorem 5 can be rewritten as
Theorem 5′. Given any logically independent events A, C, H, with A ̸= ∅and
H ̸= ∅, the set Π of all coherent assessments (x, y, z) on {A|H, C|(A|H), C} is
Π = {(x, y, z) ∈[0, 1]3 : (x, y) ∈[0, 1]2, z ∈[xy, xy + 1 −x]}.
(8)
Finally, we observe that the propagation rules for the lower and the upper
bounds on the conclusion of the generalized probabilistic modus ponens given in
Theorem 5 coincide with the respective bounds on the conclusion for the (non-
nested) probabilistic modus ponens.
4
Concluding Remarks
We generalized the probabilistic modus ponens in terms of conditional random
quantities in the setting of coherence. Speciﬁcally, we replaced the categorical
premise A and the antecedent A of the conditional premise C|A by the condi-
tional event A|H. We proved a generalized decomposition formula for conditional
events and we gave some results on compound conditionals and iterated condi-
tionals. We propagated the previsions from the premises of the generalized prob-
abilistic modus ponens to the conclusion. Interestingly, the lower and the upper
bounds on the conclusion of the generalized probabilistic modus ponens coincide
with the respective bounds on the conclusion for the (non-nested) probabilistic

488
G. Sanﬁlippo et al.
modus ponens. We obtained our results by also avoiding Lewis’ triviality results.
Thereby, we aim to provide a uniﬁed methodology for investigating compound
conditionals under uncertainty. In future work we will study other instantiations
to obtain further generalizations of modus ponens, e.g., by also replacing the
consequent C of the conditional premise C|A and the conclusion C by a condi-
tional event C|K: from {A|H, (C|K)|(A|H)} infer C|K. Moreover, we will focus
on similar generalizations (also involving imprecision) of other argument forms
like the probabilistic modus tollens.
Acknowledgments. We thank three anonymous referees for their useful comments
and suggestions. We thank DFG, FMSH, and Villa Vigoni for supporting joint meetings
at Villa Vigoni where parts of this work originated (Project: “Human Rationality:
Probabilistic Points of View”).
References
1. Adams, E.W.: The Logic of Conditionals. Reidel, Dordrecht (1975)
2. Adams, E.W.: A Primer of Probability Logic. CSLI, Stanford (1998)
3. Benferhat, S., Dubois, D., Prade, H.: Nonmonotonic reasoning, conditional objects
and possibility theory. Artif. Intell. 92, 259–276 (1997)
4. Biazzo, V., Gilio, A., Lukasiewicz, T., Sanﬁlippo, G.: Probabilistic logic under
coherence: complexity and algorithms. Ann. Math. Artif. Intell. 45(1–2), 35–81
(2005)
5. Biazzo, V., Gilio, A., Sanﬁlippo, G.: Generalized coherence and connection prop-
erty of imprecise conditional previsions. In: Proceedings of IPMU 2008, Malaga,
Spain, 22–27 June, pp. 907–914 (2008)
6. Biazzo, V., Gilio, A., Sanﬁlippo, G.: Coherent conditional previsions and proper
scoring rules. In: Greco, S., Bouchon-Meunier, B., Coletti, G., Fedrizzi, M.,
Matarazzo, B., Yager, R.R. (eds.) IPMU 2012. CCIS, vol. 300, pp. 146–156.
Springer, Heidelberg (2012). doi:10.1007/978-3-642-31724-8 16
7. Boole, G.: An Investigation of the Laws of Thought, On Which are Founded the
Mathematical Theories of Logic and Probabilities. Walton and Maberly, London
(1854)
8. Capotorti, A., Lad, F., Sanﬁlippo, G.: Reassessing accuracy rates of median deci-
sions. Am. Stat. 61(2), 132–138 (2007)
9. Capotorti, A., Vantaggi, B.: Locally strong coherence in inference processes. Ann.
Math. Artif. Intell. 35(1), 125–149 (2002)
10. Coletti, G., Scozzafava, R.: Probabilistic Logic in a Coherent Setting. Kluwer,
Dordrecht (2002)
11. de Finetti, B.: The logic of probability. Philos. Stud. 77, 181–190 (1995). Originally
published in 1936
12. de Finetti, B.: Foresight: its logical laws, its subjective sources. In: Kyburg, Jr. H.,
Smokler, H.E. (eds.) Studies in Subjective Probability, pp. 55–118. Robert E.
Krieger Publishing Company, Huntington (1980). Originally published in 1937
13. De Morgan, A.: Formal Logic: Or, the Calculus of Inference, Necessary and Proba-
ble. Taylor and Walton, London (1847). Reprinted 2002 by Eliborn Classics series
14. Edginton, D.: Indicative conditionals. In: Zalta, E.N. (ed.) The Stanford Encyclo-
pedia of Philosophy (Winter 2014 Edition). https://plato.stanford.edu/archives/
win2014/entries/conditionals

Generalized Probabilistic Modus Ponens
489
15. Evans, J.S.B.T., Handley, S.J., Over, D.E.: Conditionals and conditional probabil-
ity. J. Exp. Psychol.: Learn. Mem. Cogn. 29(2), 321–355 (2003)
16. Gibbard, A.: Two recent theories of conditionals. In: Harper, W.L., Stalnaker, R.,
Pearce, G. (eds.) Ifs, pp. 221–247. Reidel, Dordrecht (1981)
17. Gilio, A.: Probabilistic reasoning under coherence in System P. Ann. Math. Artif.
Intell. 34, 5–34 (2002)
18. Gilio, A.: Generalizing inference rules in a coherence-based probabilistic default
reasoning. Int. J. Approximate Reasoning 53(3), 413–434 (2012)
19. Gilio, A., Over, D.E., Pfeifer, N., Sanﬁlippo, G.: Centering with conjoined and
iterated conditionals under coherence. https://arxiv.org/abs/1701.07785
20. Gilio, A., Over, D.E., Pfeifer, N., Sanﬁlippo, G.: Centering and compound con-
ditionals under coherence. In: Ferraro, M., et al. (eds.) Soft Methods for Data
Science. AISC, vol. 456, pp. 253–260. Springer, Heidelberg (2017)
21. Gilio, A., Pfeifer, N., Sanﬁlippo, G.: Transitivity in coherence-based probability
logic. J. Appl. Logic 14, 46–64 (2016)
22. Gilio, A., Sanﬁlippo, G.: Conditional random quantities and iterated condition-
ing in the setting of coherence. In: van der Gaag, L.C. (ed.) ECSQARU 2013.
LNCS (LNAI), vol. 7958, pp. 218–229. Springer, Heidelberg (2013). doi:10.1007/
978-3-642-39091-3 19
23. Gilio, A., Sanﬁlippo, G.: Conjunction, disjunction and iterated conditioning of con-
ditional events. In: Kruse, R., Berthold, M., Moewes, C., Gil, M., Grzegorzewski,
P., Hryniewicz, O. (eds.) Synergies of Soft Computing and Statistics for Intelligent
Data Analysis. AISC, vol. 190, pp. 399–407. Springer, Berlin (2013)
24. Gilio, A., Sanﬁlippo, G.: Probabilistic entailment in the setting of coherence: the
role of quasi conjunction and inclusion relation. Int. J. Approximate Reasoning
54(4), 513–525 (2013)
25. Gilio, A., Sanﬁlippo, G.: Quasi conjunction, quasi disjunction, t-norms and t-
conorms: probabilistic aspects. Inf. Sci. 245, 146–167 (2013)
26. Gilio, A., Sanﬁlippo, G.: Conditional random quantities and compounds of condi-
tionals. Stud. Logica 102(4), 709–729 (2014)
27. Hailperin, T.: Probability semantics for quantiﬁer logic. J. Philos. Logic 29, 207–
239 (2000)
28. Kaufmann, S.: Conditionals right and left: probabilities for the whole family. J.
Philos. Logic 38, 1–53 (2009)
29. Lad, F.: Operational Subjective Statistical Methods: A Mathematical, Philosoph-
ical, and Historical Introduction. Wiley, New York (1996)
30. Lad, F., Sanﬁlippo, G., Agr´o, G.: Extropy: complementary dual of entropy. Stat.
Sci. 30(1), 40–58 (2015)
31. Lambert, J.H.: Neues Organon oder Gedanken ¨uber die Erforschung und Bezeich-
nung des Wahren und dessen Unterscheidung vom Irrthum und Schein. Wendler,
Leipzig (1764)
32. Lewis, D.: Probabilities of conditionals and conditional probabilities. Philos. Rev.
85, 297–315 (1976)
33. McGee, V.: Conditional probabilities and compounds of conditionals. Philos. Rev.
98(4), 485–541 (1989)
34. Petturiti, D., Vantaggi, B.: Envelopes of conditional probabilities extending a strat-
egy and a prior probability. Int. J. Approximate Reasoning 81, 160–182 (2017)
35. Pfeifer, N.: The new psychology of reasoning: a mental probability logical perspec-
tive. Thinking Reasoning 19(3–4), 329–345 (2013)
36. Pfeifer, N., Kleiter, G.D.: Inference in conditional probability logic. Kybernetika
42, 391–404 (2006)

490
G. Sanﬁlippo et al.
37. Pfeifer, N., Kleiter, G.D.: Framing human inference by coherence based probability
logic. J. Appl. Logic 7(2), 206–217 (2009)
38. Pfeifer, N., Sanﬁlippo, G.: Probabilistic squares and hexagons of opposition under
coherence. Int. J. Approximate Reasoning. doi:10.1016/j.ijar.2017.05.014. (in press)
39. Pfeifer, N., Sanﬁlippo, G.: Square of opposition under coherence. In: Ferraro, M.,
et al. (eds.) Soft Methods for Data Science. AISC, vol. 456, pp. 407–414. Springer,
Berlin (2017)
40. Sanﬁlippo, G., Gilio, A., Pfeifer, N.: A Generalized Probabilistic Version of Modus
Ponens. http://arxiv.org/abs/1705.00385 (2017)
41. Wagner, C.: Modus Tollens probabilized. Br. J. Philos. Sci. 55, 747–753 (2004)

A First-Order Logic for Reasoning About
Higher-Order Upper and Lower Probabilities
Nenad Savi´c1(B), Dragan Doder2, and Zoran Ognjanovi´c3
1 Institute of Computer Science, University of Bern, Bern, Switzerland
savic@inf.unibe.ch
2 Faculty of Mechanical Engineering, Belgrade, Serbia
dragan.doder@gmail.com
3 Mathematical Institute of SASA, Belgrade, Serbia
zorano@mi.sanu.ac.rs
Abstract. We present a ﬁrst-order probabilistic logic for reasoning
about the uncertainty of events modeled by sets of probability measures.
In our language, we have formulas that essentially say that “according
to agent Ag, for all x, formula α(x) holds with the lower probability at
least 1
3”. Also, the language is powerful enough to allow reasoning about
higher order upper and lower probabilities. We provide corresponding
Kripke-style semantics, axiomatize the logic and prove that the axioma-
tization is sound and strongly complete (every satisﬁable set of formulas
is consistent).
Keywords: Probabilistic logic · Uncertainty · Axiomatization · Strong
completeness
1
Introduction
Reasoning with uncertainty has gained an important role in computer science,
artiﬁcial intelligence and cognitive science. These applications require the devel-
opment of formal models which could capture reasoning through probability
[3,4,6–9,11,13,17,19].
We investigate a probabilistic logic approach, considering the situation when
there is also uncertainty about probabilities. In this case, the uncertainty is often
described using the two boundaries, called upper probability and lower probability
[14,15]. Those probabilities are previously formalized in logics developed in [12,
20,21]. Halpern and Pucella [12] give the following example: a bag contains 100
marbles, 30 of them are red and the remaining 70 are either blue or yellow, but
we do not know their exact proportion. Thus, we can assign exact probability
0.3 to the event that a randomly picked ball from the bag is red, while for
each possible probability p for picking a blue ball, we know that the remaining
probability for yellow one is 0.7 −p. For the set of possible probability measures
obtained in that way, we can assign a pair of functions, the upper and lower
probability measure, that assign the supremum and the inﬁmum the probability
of an event according to the probability measures in the set.
c
⃝Springer International Publishing AG 2017
A. Antonucci et al. (Eds.): ECSQARU 2017, LNAI 10369, pp. 491–500, 2017.
DOI: 10.1007/978-3-319-61581-3 44

492
N. Savi´c et al.
We use the papers [12,20,21] as a starting point and generalize them in two
ways:
– We want to reason not only about lower and upper probabilities an agent
assigns to a certain event, but also about her uncertain belief about other
agent’s imprecise probabilities. Thus, we introduce separate lower and upper
probability operators for diﬀerent agents, and we allow nesting of the opera-
tors, similarly as it has been done in [6], in the case of simple probabilities1.
Suppose that an agent a is planning a visit to the city C based on the weather
reports from several sources, and she decides to take an action if probability
of rain is at most
1
10, according to all reports she considers. Since she wishes
to go together with b, she should be sure with probability at least
9
10 that b
(who might consult diﬀerent weather reports) has the same conclusion about
possibility of rain. In our language, it can be formalized as
U a
≤1
10 Rain(C) ∧La
≥9
10 (U b
≤1
10 Rain(C)).
– We extend both [6,12,20,21] by allowing reasoning about events expressible in
a ﬁrst-order language. The papers [12,20] deal with propositional reasoning,
while [21] introduces a logic whose syntax allows only Boolean combinations
of formulas in which lower and upper probability operators are applied to ﬁrst
order sentences. On the other hand, here we use the most general approach,
allowing arbitrary combination of probability operators and quantiﬁers, so we
can express the statement like “according to the agent a, the lower probability
of rain in all cities is at least 1
3” (La
≥1
3 ∀xRain(x)), but also “There exists a
city in which it will surely not rain” ((∃x)U a
=0Rain(x)).
Formally, if the uncertainty about probabilities is modeled by a set of prob-
ability measures P deﬁned on a given algebra H, then the lower probability
measure P⋆and the upper probability measure P ⋆are deﬁned by P⋆(X) =
inf{μ(X) | μ ∈P} and P ⋆(X) = sup{μ(X) | μ ∈P}, for every X ∈H. Those
two functions are related by the formula P⋆(X) = 1 −P ⋆(Xc).
In this paper, we logically formalize such situations using a generalization
of Kripke models – for each agent, every world is equipped with a probabilistic
space which consists of the accessible worlds, algebra of subsets, and a set of
measures. We denote our logic by Llu.
We propose a sound and strongly complete axiomatization of the logic. Since
we use diﬀerent completion technique than the one used in [6,12], we did not
have to incorporate the arithmetical operations in the language. Instead, we use
unary operators for upper and lower probability, following [20]. Since, like the
other real-valued probabilistic logics, Llu is not compact, any ﬁnitary axiomatic
system would be incomplete [22]. In order to achieve completeness, we use two
inﬁnitary rules of inference, with countably many premises and one conclusion.
1 For a discussion on higher-order probabilities we refer the reader to [10].

Higher-Order Upper and Lower Probabilities
493
2
The Logic Llu – Syntax and Semantics
Let S = Q ∩[0, 1], V ar = {x, y, z, . . . } be a denumerable set of variables and let
Σ = {a, b, . . . } be a ﬁnite, non-empty set of agents. The language of the logic
Llu consists of:
– the elements of set V ar,
– classical propositional connectives ¬ and ∧,
– universal quantiﬁer ∀,
– for every integer k ≥0, denumerably many function symbols F k
0 , F k
1 , . . . of
arity k,
– for every integer k ≥0, denumerably many relation symbols P k
0 , P k
1 , . . . of
arity k,
– the list of upper probability operators U a
≥s, for every s ∈S,
– the list of lower probability operators La
≥s, for every s ∈S,
– comma, parentheses.
Functions of arity 0 will be called constants.
Note that we use conjunction and negation as primitive connectives, while ∨, →,
↔and ∃are introduced in the usual way. The notions of a term, atomic formula,
bound and free variables, sentence and a term free for a variable in formula, can
be deﬁned as usual.
Deﬁnition 1 (Formula). The set ForLlu of formulas is the smallest set con-
taining atomic formulas and that is closed under following formation rules: if
α, β are formulas, then La
≥sα, U a
≥sα, ¬α, α∧β, (∀x)α are formulas as well. The
formulas from ForLlu will be denoted by α, β, . . .
We use the following abbreviations to introduce other types of inequalities:
– U a
<sα is ¬U a
≥sα, U a
≤sα is La
≥1−s¬α, U a
=sα is U a
≤sα ∧U a
≥sα, U a
>sα is ¬U a
≤sα,
– La
<sα is ¬La
≥sα, La
≤sα is U a
≥1−s¬α, La
=sα is La
≤sα ∧La
≥sα, La
>sα is ¬La
≤sα.
We also denote α ∨¬α by ⊤, and α ∧¬α by ⊥.
The semantics for the logic Llu is based on the possible-world approach.
Deﬁnition 2 (Llu-structure).
An
Llu-structure
is
a
tuple
M = ⟨W, D, I, LUP⟩, where:
– W is a nonempty set of worlds,
– D associates a non-empty domain D(w) with every world w ∈W,
– I associates an interpretation I(w) with every world w ∈W such that:
• I(w)(F k
i ) : D(w)k →D(w), for all i and k,
• I(w)(P k
i ) ⊆D(w)k, for all i and k,
– LUP assigns, to every w ∈W and every agent a ∈Σ, a space, such that
LUP(a, w) = ⟨W(a, w), H(a, w), P(a, w)⟩, where:
• ∅̸= W(a, w) ⊆W,

494
N. Savi´c et al.
• H(a, w) is an algebra of subsets of W(a, w), i.e. a set of subsets of W(a, w)
such that:
– W(a, w) ∈H(a, w),
– if A, B ∈H(a, w), then W(a, w)\A ∈H(a, w) and A∪B ∈H(a, w),
• P(a, w) is a set of ﬁnitely additive probability measures deﬁned on
H(a, w), i.e. for every μ(a, w) ∈P(a, w), μ(a, w) : H(a, w) −→[0, 1]
and the following conditions hold:
– μ(a, w)(W(a, w)) = 1,
– μ(a, w)(A ∪B) = μ(a, w)(A) + μ(a, w)(B), whenever A ∩B = ∅.
Deﬁnition 3 (Variable valuation). Let M = ⟨W, D, I, LUP⟩be an Llu-
structure. A variable valuation υ assigns to every variable some element of the
corresponding domain to every world w ∈W, i.e. υ(w)(x) ∈D(w). For υ,
w ∈W and d ∈D(w) we deﬁne υw[d/x] is a valuation same as υ except that
υw[d/x](w)(x) = d.
Deﬁnition 4. Let M = ⟨W, D, I, LUP⟩be an Llu-structure and t a term. The
value of a term t, denoted by I(w)(t)υ is deﬁned as follows:
– if t is a variable x, then I(w)(x)υ = υ(w)(x), and
– if t = F m
i (t1, . . . , tm), then
I(w)(t)υ = I(w)(F m
i )(I(w)(t1)υ, . . . , I(w)(tm)υ).
Now we deﬁne satisﬁability of the formulas from ForLlu in the worlds of
Llu-structures.
Deﬁnition 5. The truth value of a formula α in a world w ∈W of a model
M = ⟨W, D, I, LUP⟩for a given valuation υ, denoted by I(w)(α)υ is deﬁned as
follows:
– if α = P m
i (t1, . . . , tm), then I(w)(α)υ = true if ⟨I(w)(t1)υ, . . . , I(w)(tm)υ⟩∈
I(w)(P m
i ), otherwise I(w)(α)υ = false,
– if α = ¬β, then I(w)(α)υ = true if I(w)(β)υ = false, otherwise I(w)(α)υ =
false,
– if α = β ∧γ, then I(w)(α)υ = true if I(w)(β)υ = true and I(w)(γ)υ = true,
– if α = U a
≥sβ, then I(w)(α)υ = true if P ⋆(w, a){u ∈W(w, a) | I(u)(β)υ =
true} ≥s, otherwise I(w)(α)υ = false,
– if α = La
≥sβ, then I(w)(α)υ = true if P⋆(w, a){u ∈W(w, a) | I(u)(β)υ =
true} ≥s, otherwise I(w)(α)υ = false,
– if α = (∀x)β, then I(w)(α)υ = true if for every d ∈D(w), I(w)(β)υw[d/x] =
true, otherwise I(w)(α)υ = false.
Recall that P⋆(w, a){u ∈W(w, a) | I(u)(β)υ = true} = inf{μ(w, a)({u ∈
W(w, a) | I(u)(β)υ = true}) | μ(w, a) ∈P(w, a)}, and P ⋆(w, a){u ∈W(w, a) |
I(u)(β)υ = true} = sup{μ(w, a)({u ∈W(w, a) | I(u)(β)υ = true}) | μ(w, a) ∈
P(w, a)}.

Higher-Order Upper and Lower Probabilities
495
Deﬁnition 6. A formula α holds in a world w from a model M
=
⟨W, D, I, LUP⟩, denoted by M, w |= α, if for every valuation υ, I(w)(α)υ =
true. If d ∈D(w), we will use M, w |= α(d) to denote that I(w)(α(x))υw[d/x] =
true, for every valuation υ.
A sentence α is satisﬁable if there is a world w in an Llu-model M such that
M, w |= α. A sentence α is valid if it is satisﬁed in every world in every Llu-
model M. A set of sentences T is satisﬁable if there is a world w in an Llu-model
M such that M, w |= α for every α ∈T.
We will consider a class of Llu models that satisfy:
– all the worlds from a model have the same domain, i.e., for all v, w ∈W,
D(v) = D(w),
– for every sentence α, for every agent a ∈Σ and every world w from a model
M, the set {u ∈W(w, a) | I(u)(α)υ = true} of all worlds from W(w, a) that
satisfy α is measurable,
– the terms are rigid, i.e., for every model their meanings are the same in all
the worlds.
We will use the notation [α]a
w for the set {u ∈W(w, a) | I(u)(α)υ = true},
and also LluMeas to denote the class of all ﬁxed domain measurable models with
rigid terms.
The following example shows that Compactness theorem does not hold for
the logic Llu, i.e. we can construct a set T such that every ﬁnite subset of a set
T is satisﬁable, but T itself is not.
Example 1. Consider the set of formulas
T = {¬U a
=0α} ∪{U a
< 1
n α | n
is
a
positive
integer}.
It is clear that every ﬁnite subset of T is LluMeas-satisﬁable, but the set T is not.
3
The Axiomatization AxLlu
In this section we introduce an axiomatic system for the logic Llu. That system
will be denoted by AxLlu. In order to axiomatize upper and lower probabilities,
we need to completely characterize them with a small number of properties.
There are many complete characterizations in the literature, and the earliest
appears to be by Lorentz [16]. We use the characterization result by Anger and
Lembcke [1]. It uses the notion of (n, k)-cover.
Deﬁnition 7 ((n, k)-cover). A set A is said to be covered n times by a multiset
{{A1, . . . , Am}} of sets if every element of A appears in at least n sets from
A1, . . . , Am, i.e., for all x ∈A, there exists i1, . . . , in in {1, . . . , m} such that for
all j ≤n, x ∈Aij. An (n, k)-cover of (A, W) is a multiset {{A1, . . . , Am}} that
covers W k times and covers A n + k times.

496
N. Savi´c et al.
Theorem 1 ([1]).
Let W be a set, H an algebra of subsets of W, and f a
function f : H −→[0, 1]. There exists a set P of probability measures such that
f = P ⋆iﬀf satisﬁes the following three properties:
(1) f(∅) = 0,
(2) f(W) = 1,
(3) for all natural numbers m, n, k and all subsets A1, . . . , Am in H, if the
multiset {{A1, . . . , Am}} is an (n, k)-cover of (A, W), then k + nf(A) ≤
m
i=1 f(Ai).
This theorem is also used in the Halpern and Pucella’s paper on the logical
formalization of upper and lower probabilities [12].
Axiom Schemes
(1) all instances of the classical propositional tautologies
(2) (∀x)(α →β) →(α →(∀x)β), where the variable x does not occur free in α
(3) (∀x)α(x) →α(t), where α(t) is obtained by substitution of all free occur-
rences of x in the ﬁrst-order formula α(x) by the term t which is free for x
in α(x)
(4) U a
≤1α ∧La
≤1α
(5) U a
≤rα →U a
<sα, s > r
(6) U a
<sα →U a
≤sα
(7) (U a
≤r1α1 ∧· · · ∧U a
≤rmαm) →U a
≤rα, if α →
J⊆{1,...,m},|J|=k+n

j∈J αj and

J⊆{1,...,m},|J|=k

j∈J αj are tautologies, where r =
m
i=1 ri−k
n
, n ̸= 0
(8) ¬(U a
≤r1α1 ∧· · · ∧U a
≤rmαm), if 
J⊆{1,...,m},|J|=k

j∈J αj is a tautology and
m
i=1 ri < k
(9) La
=1(α →β) →(U a
≥sα →U a
≥sβ)
Inference Rules
(1) From α and α →β infer β
(2) From α infer (∀x)α
(3) From α infer La
≥1α
(4) From the set of premises
{α →U a
≥s−1
k β | k ≥1
s}
infer α →U a
≥sβ
(5) From the set of premises
{α →La
≥s−1
k β | k ≥1
s}
infer α →La
≥sβ.

Higher-Order Upper and Lower Probabilities
497
The axioms 7 and 8 together capture the condition (3) from the Theorem 1.
Indeed, note that {{A1, . . . , Am}} covers a set A n times iﬀ
A ⊆

J⊆{1,...,m},|J|=n

j∈J
Aj.
Hence, the condition that a formula α →
J⊆{1,...,m},|J|=k+n

j∈J αj is a
tautology gives us that, for every a ∈Σ and w ∈W, [α]a
w is covered
n + k times by a multiset {{[α1]a
w, . . . , [αm]a
w}}, while the condition that

J⊆{1,...,m},|J|=k

j∈J αj is a tautology ensures that, for every a ∈Σ and
w ∈W, W(w, a) = [⊤]a
w is covered k times by a multiset {{[α1]a
w, . . . , [αm]a
w}}.
Rule 4 and Rule 5 are inﬁnitary rules of inference and intuitively says that
if upper/lower probability is arbitrary close to a rational number s then it is at
least s.
Deﬁnition 8 (Inference relation).
– ⊢α (α is a theorem) iﬀthere is an at most denumerable sequence of formulas
α1, α2, . . . , α, such that every αi is an axiom or it is derived from the preceding
formulas by an inference rule;
– T ⊢α (α is derivable from T) if there is an at most denumerable sequence of
formulas α1, α2, . . . , α, such that every αi is an axiom or a formula from the
set T, or it is derived from the preceding formulas by an inference rule, with
the exception that Inference Rule 3 can be applied only to the theorems;
– T is consistent if there is at least one formula α ∈ForLlu that is not deducible
from T, otherwise T is inconsistent;
– T is maximally consistent set if it is consistent and for every α ∈ForLlu,
either α ∈T or ¬α ∈T;
– T is deductively closed if for every α ∈ForLlu, if T ⊢α, then α ∈T;
– T is saturated if it is maximally consistent and satisﬁes:
if ¬(∀x)α(x) ∈T, then for some term t, ¬α(t) ∈T.
Note that T is inconsistent iﬀT ⊢⊥. Also, it is easy to check that every maxi-
mally consistent set is deductively closed.
It is straightforward to prove that our axiomatic system is sound with respect
to the class of LluMeas-models.
4
Completeness
Deduction theorem holds for AxLlu: if T is a set of formulas and α a sentence,
then T ∪{α} ⊢β iﬀT ⊢α →β. This theorem can be proved using the facts that
our inﬁnitary inference rules have implicative form, and that the application of
Rule 3 is restricted to theorems only.
Now, we show how to extend an arbitrary consistent set of formulas T to
a saturated set of formulas T ⋆. In the end the canonical model MCan is con-
structed and after that, it is proved that for every world w and every formula

498
N. Savi´c et al.
α, α ∈w iﬀw |= α, so the proof of the completeness theorem is an easy
consequence.
Theorem 2 (Lindenbaum’s theorem). Every consistent set of formulas can
be extended to a saturated set.
Sketch of the proof. Consider a consistent set T and let α0, α1, . . . be an
enumeration of all formulas from ForLlu. A sequence of sets Ti, i = 0, 1, 2, . . . is
deﬁned as follows:
(1) T0 = T,
(2) for every i ≥0,
(a) if Ti ∪{αi} is consistent, then Ti+1 = Ti ∪{αi}, otherwise
(b) if αi is of the form β →U a
≥sα, then Ti+1 = Ti ∪{¬αi, β →¬U a
≥s−1
n α},
for some positive integer n, so that Ti+1 is consistent, otherwise
(c) if αi is of the form β →La
≥sα, then Ti+1 = Ti ∪{¬αi, β →¬La
≥s−1
n α},
for some positive integer n, so that Ti+1 is consistent, otherwise
(d) if the set Ti+1 is obtained by adding a formula of the form ¬(∀x)β(x)
to the set Ti, then for some c ∈C (C is a countably inﬁnite set of new
constant symbols), ¬β(c) is also added to Ti+1, so that Ti+1 is consistent,
otherwise
(e) Ti+1 = Ti ∪{¬αi}.
(3) T ⋆= ∞
i=0 Ti.
Obviously, the set T0 is consistent. Natural numbers (n), from the steps 2(b)
and 2(c) of the construction exist (this is a direct consequence of the Deduction
Theorem), and each Ti is consistent. The maximality of T ⋆(either α ∈T or
¬α ∈T) is ensured by the steps (1) and (2) of the above construction. It is clear
that T ⋆does not contain all the formulas because for a formula α ∈ForLlu, the
set T ⋆does not contain both α = αi and ¬α = αj, since the set Tmax{i,j}+1 is
consistent.
It only remains to prove that T ⋆is deductively closed. Let α ∈ForLlu. We
will prove by the induction on the length of the inference that if T ⋆⊢α, then
α ∈T ⋆. Consider the inﬁnitary Rule 5. Let αi = β →La
≥sγ be obtained from the
set of premises {αk
i = β →La
≥skγ | sk ∈S}. Using the induction hypothesis, we
conclude that αk
i ∈T ⋆, for every k. If αi /∈T ⋆, by step (2)(c) of the construction,
there must be some l and j such that ¬(β →La
≥sγ), β →¬La
≥s−1
l γ ∈Tj. Hence,
we have that for some j′ ≥j: β∧¬La
≥sγ ∈Tj′; β ∈Tj′; ¬La
≥s−1
l γ, La
≥s−1
l γ ∈Tj′.
Therefore, we have that T ⋆is deductively closed set, and T ⋆does not contain
all the formulas, so it is consistent.
The step (2)(d) of the construction guarantees that T ⋆is saturated.
□
Now we deﬁne a canonical model, using the saturated sets of formulas.
Deﬁnition 9 (Canonical model). A canonical model MCan = ⟨W, D, I, LUP⟩
is a tuple such that:

Higher-Order Upper and Lower Probabilities
499
– W is the set of all saturated sets of formulas,
– D is the set of all variable-free terms,
– for every w ∈W, I(w) is an interpretation such that:
• for every function symbol F m
i , I(w)(F m
i ) : Dm →D such that for all
variable-free terms t1, . . . , tm, I(w)(F m
i ) : ⟨t1, . . . , tm⟩→F m
i (t1, . . . , tm),
• for
every
relation
symbol
P m
i ,
I(w)(P m
i )
=
{⟨t1, . . . , tm⟩
|
P m
i (t1, . . . , tm) ∈w}, for all variable-free terms t1, . . . , tm,
– for a ∈Σ and w ∈W, LUP(w, a) = ⟨W(w, a), H(w, a), P(w, a)⟩is deﬁned:
- W(w, a) = W,
- H(w, a) = {{u | u ∈W(w, a), α ∈u} | α ∈ForLlu},
- P(w, a) is any set of probability measures such that P ⋆(w, a)({u | u ∈
W(w, a), α ∈u}) = sup{s | U a
≥sα ∈w}.
Lemma 1. For every formula α and every w ∈W, α ∈w iﬀw |= α.
Theorem 3 (Strong completeness). Every consistent set of formulas T is
LluMeas −satisfiable.
Sketch of the proof. Let T be a consistent set of formulas and let MCan =
⟨W, D, I, LUP⟩be a canonical model. It can be shown that MCan is a well
deﬁned measurable structure. Furthermore, from Lemma 1 we obtain that for
every formula α, and every w ∈W, w
|=
α iﬀα ∈w. Finally, using
Theorem 2, we can extend T to a saturated set T ∗, and since T ∗∈W, we
obtain MCan, T ∗|= T.
□
5
Conclusion
In this paper we present the proof-theoretical analysis of a logic which allows
making statements about upper and lower probabilities of formulas according to
some agent. We combine the approaches from [6,12,20] and generalize them to
an expressive modal language Llu which extend ﬁrst-order logic with the unary
operators U a
≥r and La
≥r, where r ranges over the unit interval of rational numbers.
The corresponding semantics LluMeas consists of the measurable Kripke models
with a set of ﬁnitely additive probability measures attached to each possible
world. For a given world of a model, every probability form the corresponding set
of probabilities is deﬁned on the same algebra of a chosen sets of worlds. We prove
that the proposed axiomatic system AxLlu is strongly complete with respect to
the class of LluMeas-models. Since the logic is not compact, the axiomatization
contains inﬁnitary rules of inference.
Finally, upper and lower probabilities are just one approach in development
of imprecise probability models [2,5,18,23,24]. In the future work, we also wish
to logically formalize diﬀerent approaches to imprecise probabilities.
Acknowledgments. This work was supported by the SNSF project 200021 165549
Justiﬁcations and non-classical reasoning, and by the Serbian Ministry of Education
and Science through projects ON174026, III44006 and ON174008.

500
N. Savi´c et al.
References
1. Anger, B., Lembcke, J.: Infnitely subadditive capacities as upper envelopes of mea-
sures. Z. Wahrscheinlichkeitstheorie Verwandte Gebiete 68, 403–414 (1985)
2. de Cooman, G., Hermans, F.: Imprecise probability trees: bridging two theories of
imprecise probability. Artif. Intell. 172(11), 1400–1427 (2008)
3. Doder, D.: A logic with big-stepped probabilities that can model nonmonotonic
reasoning of system P. Pub. Inst. Math. 90(104), 13–22 (2011)
4. Doder, D., Ognjanovi´c, Z.: Probabilistic logics with independence and conﬁrma-
tion. Stud. Logica (2017). doi:10.1007/s11225-017-9718-z
5. Dubois, D., Prade, H.: Possibility Theory. Plenum Press, New York (1988)
6. Fagin, R., Halpern, J.: Reasoning about knowledge and probability. J. ACM 41(2),
340–367 (1994)
7. Fagin, R., Halpern, J., Megiddo, N.: A logic for reasoning about probabilities. Inf.
Comput. 87(1–2), 78–128 (1990)
8. Fattorosi-Barnaba, M., Amati, G.: Modal operators with probabilistic interpreta-
tions. Stud. Logica 46(4), 383–393 (1989)
9. Frisch, A., Haddawy, P.: Anytime deduction for probabilistic logic. Artif. Intell.
69, 93–122 (1994)
10. Gaifman, H., Haddawy, P.: A theory of higher order probabilities. Causation,
Chance and Credence, vol. 41, pp. 191–219. Springer, Netherlands (1988)
11. Halpern, J.Y.: An analysis of ﬁrst-order logics of probability. Artif. Intell. 46, 311–
350 (1990)
12. Halpern, J.Y., Pucella, R.: A logic for reasoning about upper probabilities. J. Artif.
Intell. Res. 17, 57–81 (2002)
13. Heifetz, A., Mongin, P.: Probability logic for type spaces. Games Econ. Behav. 35,
31–53 (2001)
14. Huber, P.J.: Robust Statistics. Wiley, New York (1981)
15. Kyburg, H.E.: Probability and the Logic of Rational Belief. Wesleyan University
Press, Middletown (1961)
16. Lorentz, G.G.: Multiply subadditive functions. Can. J. Math. 4(4), 455–462 (1952)
17. Meier, M.: An inﬁnitary probability logic for type spaces. Isr. J. Math. 192(1),
1–58 (2012)
18. Miranda, E.: A survey of the theory of coherent lower previsions. Int. J. Approxi-
mate Reasoning 48(2), 628–658 (2008)
19. Ognjanovi´c, Z., Raˇskovi´c, M.: Some ﬁrst-order probability logics. Theor. Comput.
Sci. 247(1–2), 191–212 (2000)
20. Savi´c, N., Doder, D., Ognjanovi´c, Z.: A logic with upper and lower probability
operators. In: Proceedings of the 9th International Symposium on Imprecise Prob-
ability: Theories and Applications, pp. 267–276, Pescara, Italy (2015)
21. Savi´c, N., Doder, D., Ognjanovi´c, Z.: Logics with lower and upper probability
operators. Int. J. Approximate Reasoning (2017). doi:10.1016/j.ijar.2017.05.013
22. van der Hoek, W.: Some consideration on the logics PF D. J. Appl. Non-Classical
Logics 7(3), 287–307 (1997)
23. Walley, P.: Statistical Reasoning with Imprecise Probabilities. Chapman and Hall,
London (1991)
24. Walley, P.: Towards a uniﬁed theory of imprecise probability. Int. J. Approximate
Reasoning 24(2–3), 125–148 (2000)

Author Index
Abassi, Lina
159
Abdelkhalek, Raoua
169
Aguzzoli, Stefano
353
Amgoud, Leila
25
Antonucci, Alessandro
282
Augustin, Thomas
329
Beierle, Christoph
225, 236
Ben Amor, Nahla
295, 306, 435
Ben-Naim, Jonathan
25
Bianchi, Matteo
353
Bolt, Janneke H.
83
Bonesana, Claudio
282
Boudet, Laurence
375
Boudjani, Nadira
36
Boukhris, Imen
159, 169, 201
Bronevich, Andrey G.
271
Campagner, Andrea
423
Ciucci, Davide
398, 423
Coletti, Giulianella
364
Cornez, Laurence
375
Cozman, Fabio G.
93, 449
Creignou, Nadia
387
Dao, Tien-Tuan
135
Destercke, Sébastien
179
Doder, Dragan
491
Dubois, Didier
398
Eichhorn, Christian
236, 257
EL khalﬁ, Zeineb
306
Elouedi, Zied
169, 201, 212
Espinosa, Bruno
375
Essghaier, Fatma
295
Fargier, Hélène
295, 306
Flaminio, Tommaso
246
Fragnito, Giulia
318
Gabarro, Joaquim
318
Gerla, Brunella
353
Gilio, Angelo
480
Godo, Lluis
246
Gouaich, Abdelkader
36
Grabisch, Michel
340
Grant, John
459
Guyet, Thomas
135
Haddad, Maroua
435
Helal, Nathalie
190
Hoang, Tuan Nha
135
Hosni, Hykel
246
Hunter, Anthony
46
Jansen, Christoph
329
Järvisalo, Matti
57
Jensen, Frank
115
Jeppesen, Nicolaj Søndberg
115
Kaci, Souhila
36
Kern-Isberner, Gabriele
236, 257
Kratochvíl, Václav
146
Ktari, Raïda
387
Kutsch, Steven
225
Labreuche, Christophe
340
Lefèvre, Éric
190, 201, 212
Lehtonen, Tuomo
57
Leray, Philippe
435
Lohse, Niels
115
Lopatatzidis, Stavros
104
Madsen, Anders L.
115
Mallek, Sabrine
201
Mangili, Francesca
282
Mauá, Denis D.
93, 449
Mercier, David
190
Molinaro, Cristian
459
Moser, Ulrich
115
Negrevergne, Benjamin
135
Neto, Luis
115
Niland, Richard
257
Ognjanović, Zoran
491

Papini, Odile
387
Parisi, Francesco
459
Petturiti, Davide
364
Pfeifer, Niki
480
Pichon, Frédéric
190
Plajner, Martin
125
Poli, Jean-Philippe
375
Porumbel, Daniel
190
Potyka, Nico
46
Pozzato, Gian Luca
409
Prade, Henri
3, 10
Prakken, Henry
69
Reis, Joao
115
Renooij, Silja
83
Richard, Gilles
3, 10
Ridaoui, Mustapha
340
Rienstra, Tjitze
470
Rozenberg, Igor N.
271
Sabaddin, Régis
306
Samet, Ahmed
135
Sanﬁlippo, Giuseppe
480
Savić, Nenad
491
Sayed, Mohamed S.
115
Schollmeyer, Georg
329
Serna, Maria
318
Tho, Marie Christine Ho Ba
135
Trabelsi, Asma
212
Valota, Diego
353
van der Gaag, Linda C.
104
Vantaggi, Barbara
364
Vomlel, Jiří
125, 146
Wallner, Johannes P.
57
Wilhelm, Marco
257
502
Author Index

