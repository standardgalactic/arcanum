  
Quantum Cognition 
John F. Sowa and Arun K. Majumdar
VivoMind Research, LLC
11 August 2014
Web Intelligence Congress, Warsaw

 
2
1. Quantum Theories of Cognition  
1. Quantum Theories of Cognition  
Early hopes for artificial intelligence have not been realized.
The tasks of perception, learning, reasoning, and understanding 
are much harder to simulate than anyone had thought.
Three-year-old children are the most creative people on earth.
Their learning abilities far surpass any and every AI system.
Questions:
● Have we been using the right theories, tools, and techniques?
● Why haven’t these tools worked as well as we had hoped?
● Was Roger Penrose correct in criticizing AI methods?
● Is quantum mechanics the foundation for human cognition?
● Does AI require a quantum computer or something similar?
● Should we replace current methods of knowledge representation (KR) 
  with some kind of quantum or quantum-like QKR?

 
3
  
Early Days of Artificial Intelligence 
1960: Hao Wang’s theorem prover took 7 minutes to prove all 378
FOL theorems of Principia Mathematica on an IBM 704 –     
far faster than the two brilliant logicians, Whitehead and Russell. 
1960: Emile Delavenay, in a book on machine translation:
“While a great deal remains to be done, it can be stated without
hesitation that the essential has already been accomplished.” 
1965: Irving John Good, in speculations on the future of AI:
“It is more probable than not that, within the twentieth century,
an ultraintelligent machine will be built and that it will be the last
invention that man need make.” 
1968:  Marvin Minsky, the technical adviser for the movie 2001:
“The HAL 9000 is a conservative estimate of the level of artificial
intelligence in 2001.”

 
4
Minsky’s Challenge
Adapted from a diagram by Minsky, Singh, & Sloman (2004).

 
5
  
Meeting the Challenge
As Minsky’s diagram shows, AI methods cannot efficiently 
reason about large numbers of causes and complex effects.
● Statistical methods can relate many causes (input data), but only    
  small-scale effects (simple outputs).
● Logic can reason about complex effects (multiple interrelated          
  phenomena), but only with simplified causes (few axioms).
● Those technologies are useful for what they can do.
● But they cannot represent and reason about the dynamic aspects   
  of life and the natural languages that express them.
In The Society of Mind (1986) and The Emotion Engine (2006), 
Minsky proposed systems of interacting modules:
● No single, uniform method of representation or reasoning.
● A society of modules may contain nests of modules to any depth.
● The modules interact by passing message via neurons.

 
6
  
The Emperor’s New Mind
A book by the physicist Roger Penrose (1989).
He claimed that the failures of AI are inevitable:
● Quantum mechanical effects are essential for conscious thought.
● Rule-based operations on symbols cannot simulate them.
● But he did not propose a detailed theory about how or where in       
  the brain QM might support intelligent thought.
The neuroscientist Stuart Hameroff had some suggestions:
● In the 1940s, Charles Sherrington noted that single-celled animals  
  could learn and perform complex behavior without neurons.
● He believed that microtubules inside the cells were involved.
Penrose and Hameroff collaborated over the past 20 years to 
develop the theory of Orchestrated Objective Reduction.

 
7
  
Cell Intelligence
Without neurons, single-celled organisms can act intelligently.
● On the left, a paramecium, bumps into an obstacle, remembers it,   
  backs up, and goes around it.
● On the right, a euglena has chloroplasts for photosynthesis, an       
  eyespot for detecting light, and a flagellum to swim toward light.
● But in the dark, the euglena can find and eat bacteria or algae.
Each cell of an animal body, including neurons, has basic 
methods of perception, action, learning, and reasoning.

 
8
  
Microtubules
The cytoskeleton of an animal cell is a network of microtubules.
● Each tubule is a polymer that consists of pairs (dimers) of two        
  forms of the protein tubulin:  α-tubulin and β-tubulin.
● Each dimer is a dipole, which may represent a bit, 0 or 1.
● But a dipole may be in a superposition that represents a qubit.
A single cell may contain a billion tubulin dimers (109).

 
9
  
Microtubule Automaton
Time-steps of a microtubule automaton at 10 megahertz. The dipole 
states of each tubulin dimer (yellow, blue) represent bits or qubits.
a. Spin currents interact and compute along spiral lattice pathways.       
    For example, two upward traveling blue spin waves intersect to          
    generate a new vertical spin wave (a “glider”).
b. A more general computation.
From Hameroff & Penrose (2014), Consciousness in the universe: A review of the ‘Orch OR’ 
theory, Figure 3, http://www.sciencedirect.com/science/article/pii/S1571064513001188 .

 
  
Orchestrated Objective Reduction
The diagram shows a synapse.
Both the axon at the left and         
the neuron at the right contain 
microtubules.
Inputs from the synapse trigger 
quantum vibrations in the 
microtubules inside the neuron.
Summary of the Orch OR theory:
● Synaptic inputs orchestrate and interact with patterns of tubulin     
  states (memories) stored in the microtubules of each neuron.
● The vibrations terminate with an objective reduction to stable bits.
● Of 20 testable predictions, 6 were confirmed, none refuted.
● New discoveries (Hameroff & Penrose 2014) add further support.

 
  
Conscious Moments
The diagram shows an OR 
transition at a conscious “now”.
At time steps 1, 2, and 3, the gray 
tubulins represent qubits in a state 
of quantum superposition.
At step 4,  the quantum vibrations 
terminate, and the qubits are 
reduced to classical bits.
Hypotheses of Orch OR theory:
● Conscious moments coincide with the 40 Hertz gamma waves         
  detected In an EEG.
● At those moments, the dimly sensed uncertainty of quantum           
  mechanics is resolved to a perceived state of clarity.

 
12
  
Orchestration
In music, an orchestra is a group of musicians who play the 
same or related melodies in harmony.
In Orch OR theory, gamma waves with a tempo of 40 Hertz 
orchestrate a harmony of melodies in the neurons.
The overall structure is similar to Minsky’s Society of Mind:
● Each neuron is an intelligent agent that sends and receives                   
  messages from other agents.
● Those agents may be neurons or other cells of the body.
● Groups of neurons form columns in the cerebral cortex.
● Groups of columns form larger functional units in the brain.
With 21st century hardware, a detailed simulation of Orch OR 
theory of the entire brain is unlikely.
But efficient approximations at various levels are possible.

 
13
  
Quantum or Quantum-Like?
Quantum effects at the cell level have been observed.
Penrose and Hameroff proposed some plausible hypotheses.
But there are many more questions than answers.
Three characteristics of quantum mechanical systems:
● Superposition:  A particle can exist in a mixture of multiple states.
● Coherence:  Multiple particles can coalesce in a unified state.
● Entanglement:  Particles that coalesced in a unified state may retain    
  aspects of that unification  even after they separate.     
How and whether these QM properties affect larger structures 
and systems in the brain is unknown.
Even if QM effects at the cell level influence higher levels, the 
mathematics at the higher levels may be quite different. 

 
14
  
Statistics and Structure
Statistics is important for evaluating alternatives and choosing 
among them.
For many applications, statistical methods based on or inspired 
by quantum mechanics have been useful.
But as Minsky observed, statistics alone is not sufficient:
● Before statistics can evaluate alternatives, there must be some way     
  to represent the structure of the alternatives.
● Quantum statistics must work with representions of structure.
Goals for QKR – a quantum-like knowledge representation:
● A continuous, wave-like function, perhaps complex-valued.
● Ability to encode all structures of thought:  imagery, feelings, natural   
  languages, logics, programming languages, trees, graphs, etc.
● Methods for reasoning with and about those encodings.
● And computable implementations.

 
15
2. Discrete, Continuous, and Dynamic
2. Discrete, Continuous, and Dynamic
Words are discrete, and patterns of words are discrete.
But the world is a continuum, and so are mental models.
Perception, action, and feelings are continuous, they reflect the 
dynamic changes in the world, and they make further changes.
Questions:
● How can discrete patterns map to a continuum?
● How can  they represent dynamic changes?
● Can the evidence from neuroscience suggest how?
● How could the neural mechanisms be implemented?

 
16
Catastrophe Theoretical Semantics
René Thom was a mathematician who invented catastrophe 
theory, which he originally applied to physical phenomena.
He later extended it to processes in biology and linguistics.
For language analysis, Thom mapped Lucien Tesnière’s 
dependency graphs to his elementary catastrophes.
Thom’s linguistic and mathematical theories were further 
developed by Wolfgang Wildgen and Jean Petitot.
Thom’s catastrophes have some intriguing similarities to the 
objective reductions of Orch OR theory:
● A catastrophe is a discontinuity in a continuous field.
● The discontinuities of catastrophe theory and Orch OR have a        
  similar effect of bridging discrete and continuous mathematics. 

 
Single Cusp Catastrophe
A surface of transitions from a dirty state to a clean state.
● A path along the back would make a continuous transition.
● But a path along the front would make a catastropic jump.
● Thom used the catastrophe types to classify linguistic patterns.

 
18
Catastrophe of Betrayal

 
19
Dependency Grammar
Theory and notation developed by Lucien Tesnière.
An epigram written by Voltaire and analyzed by Tesnière:
L’autre jour, au fond d’un vallon, un serpent piqua Jean Freron.
Que pensez-vous qu’il arriva?  Ce fut le serpent qui creva.
The verb is the focus of the clause.  Nouns represent actants.

 
20
Transfer Schema
Three actants:  giver, gift, recipient:
● At the start, the giver M1 has an object (a gift).
● In the catastrophe, possession of the gift jumps from M1 to M2.
● At the end, the recipient M2 has the gift.  

 
21
Schema With Four Actants
Two transfer schemata are combined to form a schema for 
buying and selling.
A buyer is the agent of giving object 1 (money) to a patient 
(seller), who is the agent of giving object 2 to the buyer.

 
22
From http://www.fb10.uni-bremen.de/homepages/wildgen/ppt/CompoundsinCelanCleveland.ppt  
Parts or features of a visual whole are 
linked by the synchronic firing of a set of 
neurons (an assembly) during a short time 
interval.
In the example the parts and features of 
the cat and those of the woman are bound 
together by the internal synchrony of the 
assemblies 1 and 2 and they are 
distinguished by the asynchrony of these 
assemblies.
The basic idea of temporal binding
Slide by Wildgen

 
23
Top down effects due to expectation and memory
Slide by Wildgen
At the left a Kanitza-triangle
At the right a non-Kanitza-triangle
If the tested person is instructed to 
recognize the non-Kanitza-triangle , 
the synchronization is higher for this 
configuration, although basic gestalt 
laws would predict the contrary.
From: Hermann, Munk und 
Engel, 2004:349
The remembered object 
produces higher synchronization 
at the γ-level (30 to 60 Hz)

 
24
Ambiguity and Binding
Slide by Wildgen
Picture a is ambiguous. If it is 
seen as one face (and a 
candle in front of it) the zones 
(1,2) and (3,4) (see series d) 
are bound; in the case two 
faces looking at each other are 
seen, the zones (1,3) und (2,4) 
are bound. The binding may be 
recognized by the synchronic 
firing rates in the series d 
versus e.

 
25
 „The different firing rates that can 
be easily discriminated on a 
background of inherent noise 
and accidental synchronies 
may set a low limit to the 
number of objects that can be 
simultaneously bound.” 
Teisman (1999: 108) 
This restriction is even more 
dramatic in the case of 
process-schemata, as the 
results of catastrophe theory 
show.
Restrictions on compositionality due to temporal 
binding, Slide by Wildgen
These already maximally 
complex processes exemplify 
the schemata for exchange 
(giving) and instrumental action. 
They contain as subfields the 
schemata of capture, emission, 
of beginning, end and stable 
existence.

 
26
3. Analogy and Case-Based Reasoning
Based on the same kind of pattern matching as perception:
● Associative retrieval by matching patterns.
● Approximate pattern matching for analogies and metaphors.
● Precise pattern matching for logic and mathematics.
Analogies can support informal, case-based reasoning:
● Long-term memory can store large numbers of previous experiences.
● Any new case can be matched to similar cases in long-term memory.
● Close matches are ranked by a measure of semantic distance.
Formal reasoning is based on a disciplined use of analogy:
● Induction:  Generalize multiple cases to create rules or axioms.
● Deduction:  Match (unify) a new case with part of some rule or axiom.
● Abduction:  Form a hypothesis based on aspects of similar cases.

 
Approximate Mapping
Example:  How is a cat like a car?
Metaphor and other aspects of language require approximations.
Cat
Car
Head
Hood
Eye
Headlight
Cornea
Glass plate
Mouth 
Fuel cap
Stomach
Fuel tank
Bowel
Combustion chamber
Anus
Exhaust pipe
Skeleton
Chassis
Heart
Engine
Paw
Wheel
Fur
Paint

 
28
Approximations
Concepts are related by ontology or common associations:
● Eyes and headlights are related to light.
● Heart and engine are internal parts with a regular beat.
● Skeleton and chassis are structures for attaching parts.
● Paws and wheels support the body, and there are four of each.
One-to-one structure matching is preferred:
● Head → Eyes → Cornea.
● Hood → Headlights → Glass plate. 
Approximate matches may skip some nodes (marked in red):
● Mouth → Esophagus → Stomach → Bowel → Anus.
● Fuel cap → Fuel tank → Combustion chamber → Muffler → Exhaust pipe. 
Two factors determine the semantic distance between graphs:
● Ontology:  How similar are the concept and relation types?
● Structure:  How many nodes and arcs are added or deleted?

 
29
Computational Complexity
Research by Falkenhainer, Forbus, & Gentner:
● Pioneers in finding analogies with their Structure Mapping Engine.
● Showed that SME algorithms take time proportional to N³, where     
  N is the number of frames (or graphs) in the knowledge base.
● MAC/FAC approach:  Use a search engine to narrow down the         
  number of likely candidates before using SME.
VivoMind approach:
● Encode graph structure and ontology in a Cognitive Signature™.
● For any graph, find closely matching signatures in log(N) time.
● Only graphs with similar signatures are likely candidates.
For papers by Falkenhainer, Forbus, Genter, and colleagues,           
http://www.qrg.northwestern.edu/papers/papers.html 

 
30
Algorithms for Chemical Graphs
Graphs of organic molecules are similar to conceptual graphs:
● Atoms  concept nodes labeled by the name of the element.
⇒
● Chemical bonds  relation nodes labeled by the name of the bond type.
⇒
● But conceptual graphs have many more types of concepts and relations. 
Chemical graphs inspired Peirce’s existential graphs as 
representations of “the atoms and molecules of logic.”
Some of the largest and most sophisticated systems for graph 
processing were developed by chemists, not computer scientists.
An early example was the use of chemical graph algorithms for 
building and searching hierarchies of conceptual graphs:
Robert A. Levinson, & Gerard Ellis (1992) Multilevel hierarchical retrieval,      
Knowledge Based Systems 5:3, pp. 233-244.

 
31
Finding Analogies
Find similar chemical graphs in logarithmic time:
    • Represent each graph by its unique International Chemical Identifier (InChI).
    • Map the InChI codes to numeric vectors that encode both the graph structure   
      and the labels of the atoms and bonds.
    • Estimate the semantic distance between graphs by a measure based on both   
      the graph structure and the labels on the nodes and arcs (atoms and bonds).
    • Index the vectors by a locality-sensitive hashing (LSH) algorithm.
    • Use the semantic distance measure to find the most similar graphs. 
For details of the chemical algorithms, see
Mining patents using molecular similarity search, by James Rhodes,                 
Stephen Boyer, Jeffrey Kreulen, Ying Chen, & Patricia Ordonez,
http://psb.stanford.edu/psb-online/proceedings/psb07/rhodes.pdf 
VivoMind algorithms use geometric algebras and Rvachev 
functions:  US Patent 8566321, Relativistic concept measuring system. 
For methods of pattern recognition with Rvachev functions, see 
Bougaev (2006):  http://docs.lib.purdue.edu/dissertations/AAI3263546/ 

 
32
Cognitive Memory™ 
Basis for the VivoMind Analogy Engine (VAE)

 
33
Evaluating Student Answers
Multiple-choice questions are easy to evaluate by computer.
Long essays are often evaluated by statistical methods.
But short answers about mathematics are very hard to evaluate. 
Sample question:
         The following numbers are 1 more than a square:  10, 37, 65, 82.
         If you are given an integer N that is less than 200,
         how would you determine whether N is 1 more than a square?
         Explain your method in three or four sentences. 
Even experienced teachers must spend a lot of time checking     
and correcting the answers to such questions.

 
34
Many Possible Answers
An example of a correct answer:
        To show that N is 1 more than a square,  show that N−1 is a square.
        Find some integer x whose square is slightly less than N−1.         
        Compare N−1 to the squares of  x,  x+1,  x+2,  x+3,   ...,
        and stop when some square is equal to or greater than N−1.
        If the last square is N−1,  then N is one more than a square. 
How could a computer system evaluate such answers?
How could it make helpful suggestions for incorrect answers?

 
35
Publisher’s Current Procedure
To evaluate new exam questions, the publisher normally
gives the exam to a large number of students.
For each problem, they would get about 50 different answers:
    ● Some are completely correct
         — but stated in different ways.
    ● Some are partially correct
         — and the teacher says what is missing.
    ● Others are wrong
         — in many different ways. 
Result:  50 pairs of student answer and teacher’s response.
Each answer-response pair is a case for case-based reasoning.

 
36
Case-Based Reasoning 
Given the same cases, analogy takes one step to derive an answer 
that can take many steps by induction and deduction.
Analogy is usually more flexible, but a theory would be valuable if 
the same theory can be used and reused in multiple applications.   

 
37
Using VLP and VAE 
VLP translates all answers to conceptual graphs (CGs):
   1. VLP uses a link grammar and a collection of lexical resources.
   2. Canonical graphs for verbs are based on the IBM-CSLI verb ontology.
   3. For this application, a small ontology of arithmetic was added.
   4. The next slide shows a canonical graph for Multiply.
VAE compares each new answer to the 50 cases:
   1. CGs for the answers of all 50 cases are stored in Cognitive Memory.
   2. Compare the CG for each new answer to the CGs in Cognitive Memory.
   3. If there is a good match, print out the teacher’s previous response.
   4. Otherwise, send the new student answer to some teacher to evaluate.
   5. Add the new answer-response pair to the collection of cases.
This method combines a formal ontology for arithmetic 
with a very informal method of case-based reasoning.

 
38
Conceptual Graph for Multiply
This CG represents a pattern or schema for the concept Multiply:
       [Someone] multiplies a number by a number to get a product.
The diamond node represents a function that multiplies two numbers 
in the roles Theme and Instrument to compute a number as Result.

 
39
Results 
VAE found a good match for nearly all student answers.
For good matches, the stored response was appropriate.
Student answers are often incomplete or ungrammatical.
● But canonical graphs make the parsing more robust.
● Resolve ambiguities by showing expected combinations.
● Use semantics to compensate and correct errors in syntax.
● Provide defaults for missing arguments.
● Show how information from multiple fragments can be related.
The CGs derived from student answers were incomplete 
and unreliable for precise reasoning and calculation.
But they were adequate for approximate matching by VAE.

 
40
Role of Analogy
The basis for human reasoning and language understanding.
Logic is a disciplined special case of analogical reasoning:
● Essential for precise reasoning in mathematics and science.
● Important for precision in any field.
● But even in science and engineering, analogy is necessary for                    
  knowledge discovery and innovation.
Conceptual graphs support logical and analogical methods:
● They are defined by the ISO/IEC standard 24707 for Common Logic.
● But they also support semantic distance measures for analogy.
● They provide a bridge between informal language and formal logic.
CGs derived from English can be used for analogies.
But CGs used for formal logic should be derived from formal 
languages or be corrected by comparison to formal CGs.

 
41
Application to Legacy Re-engineering
Analyze the software and documentation of a large corporation.
Programs in daily use, some of which were up to 40 years old.
    ● 1.5 million lines of COBOL programs.
    ● 100 megabytes of English documentation — reports, manuals,
       e-mails, Lotus Notes, HTML, and program comments. 
Goal:
    ● Analyze the COBOL programs.
          
    ● Analyze the English documentation.
    ● Compare the two to generate: 
          English glossary of all terms with index to the software,
          Structure diagrams of the programs, files, and data,
          List of discrepancies between the programs and documentation.

 
42
An Important Simplification
An extremely difficult and still unsolved problem:
● Translate English specifications to executable programs.
Much easier task:
● Translate the COBOL programs to conceptual graphs.
● Those CGs provide the ontology and background knowledge.
● The CGs derived from English may have ambiguous options.
● VAE matches the CGs from English to CGs from COBOL.
● The COBOL CGs show the most likely options.
● They can also insert missing information or detect errors.
The CGs derived from COBOL provide a formal semantics for 
the informal English texts.

 
Excerpt from the Documentation
The input file that is used to create this piece of the Billing 
Interface for the General Ledger is an extract from the 61 byte file 
that is created by the COBOL program BILLCRUA in the Billing 
History production run.  This file is used instead of the history file 
for time efficiency.  This file contains the billing transaction codes 
(types of records) that are to be interfaced to General Ledger for 
the given month.
For this process the following transaction codes are used: 32 — 
loss on unbilled, 72 — gain on uncollected, and 85 — loss on 
uncollected.  Any of these records that are actually taxes are 
bypassed.  Only client types 01 — Mar, 05 — Internal 
Non/Billable, 06 — Internal Billable, and 08 — BAS are selected.  
This is determined by a GETBDATA call to the client file.
Note that none of the files or COBOL variables are named.
By matching the graphs derived from English to the graphs derived from 
COBOL, VAE identified all the file names and COBOL variables involved.

 
44
Interpreting Novel Patterns  
Many texts contain unusual or ungrammatical patterns.
They may be elliptical forms that could be stored in tables.
But some authors write them as phrases in a sentence:
● 32 — loss on unbilled
● 72 — gain on uncollected
● 85 — loss on uncollected
VLP generated a conceptual graph with a default relation (Link):
     [Number: 32]→(Link)→[Punctuation: “–”]→(Link)→[Loss]→(On)→[Unbilled] 
The value 32 was stored as a constant in a COBOL program.
The phrase “loss on unbilled” was written as a comment.
The CGs derived from the COBOL data and comments matched 
the CGs derived from the English documentation.

 
45
Basis for Legacy Re-engineering
Job finished in 8 weeks by Arun Majumdar and André LeClerc.
    ● Four weeks for customization:
           Design, ontology, and additional programming for I/O formats. 
    ● Three weeks to run VLP + VAE + extensions:
           VAE handled matches with strong evidence (close semantic distance).
           Weak matches were confirmed or corrected by Majumdar and LeClerc. 
    ● One week to produce a CD-ROM with the desired results:
           Glossary, data dictionary, data flow diagrams, process architecture,       
           system context diagrams. 
A major consulting firm estimated that the job would take 40 people two 
years to analyze the documentation and generate the cross references.
With VivoMind software, it  was completed in 15 person weeks.

 
46
Mismatch Found by VAE
A diagram of relationships among data types in the database:
Question:  Which location determines the market?
According to the documentation:   Business unit.
According to the COBOL programs:   Client HQ.
Management had been making decisions based on incorrect 
assumptions.

 
47
Contradiction Found by VAE
From the ontology used for interpreting English:
● Every employee is a human being.
● No human being is a computer. 
From analyzing COBOL programs:
● Some employees are computers. 
What is the reason for this contradiction?

 
48
Quick Patch in 1979
A COBOL programmer made a quick patch:
● Two computers were used to assist human consultants.
● But there was no provision to bill for computer time.
● Therefore, the programmer named the computers Bob and      
   Sally,  and assigned them employee ids. 
For more than 20 years:
● Bob and Sally were issued payroll checks.
● But they never cashed them. 
VAE discovered the two computer “employees.”

 
Relating Formal and Informal CGs
The legacy-reengineering task required two kinds of processing.
Precise reasoning:
● Analyzing the COBOL programs and translating them to CGs.
● Detecting discrepancies between different programs.
● Detecting discrepancies between programs and documentation.
Indexing and cross references:
● Creating an index of English terms and names of programs.
● Mapping English documents to the files and programs they mention.
Conceptual graphs derived from COBOL are precise.
But the CGs derived from English are informal and unreliable.
Informal CGs are adequate for cross-references between the 
English documents and the COBOL programs.
All precise reasoning was performed on CGs from COBOL or   
on CGs from English that were corrected by CGs from COBOL. 

 
QKR Methods for AI and NLP
No detailed simulation of the brain is likely for a long, long time:
● Nobody knows exactly how the human brain works.
● If the Orch OR theory or anything similar is correct, the fastest known  
  supercomputers could not simulate the brain of a fruit fly.
● A faithful simulation would also require a detailed model of the              
  body with all its mechanisms of perception, feelings, and action. 
But efficient approximations to human reasoning are possible: 
● A continuous QKR can encode discrete onceptual graphs.
● Calculations on the QKR can perform efficient graph operations.
● They can support a high-speed associative memory for all formal and  
  informal methods of language analysis, learning, and reasoning.
The QKR approach is inspired by quantum theories, but the 
methods are quantum-like, not explicitly quantum mechanical.

 
Related Readings  
John F. Sowa (2013) From existential graphs to conceptual graphs,
      http://www.jfsowa.com/pubs/eg2cg.pdf 
John F. Sowa (2011) Peirce’s tutorial on existential graphs,                                         
      http://www.jfsowa.com/pubs/egtut.pdf 
Arun K. Majumdar & John F. Sowa (2009) Two paradigms are better than one and 
multiple paradigms are even better,  http://www.jfsowa.com/pubs/paradigm.pdf   
Arun K. Majumdar (2013)  Relativistic concept measuring system for data 
clustering, http://www.uspto.gov/web/patents/patog/week43/OG/html/1395-4/US08566321-20131022.html 
Roger Penrose (1989) The Emperor’s New Mind, Oxford University Press.
Stuart Hameroff & Roger Penrose (2014) Consciousness in the Universe,                 
      http://www.sciencedirect.com/science/article/pii/S1571064513001188 
Philip N. Johnson-Laird (2002) Peirce, logic diagrams, and the elementary 
processes of reasoning, http://mentalmodels.princeton.edu/papers/2002peirce.pdf 
Jean Petitot (2011) Cognitive Morphodynamics: Dynamical Morphological Models 
of Constituency in Perception and Syntax, Bern: Peter Lang. 
Wolfgang Wildgen (1994) Process, Image, and Meaning,                                       
     http://www.fb10.uni-bremen.de/homepages/wildgen/pdf/MeaningandReality.pdf 

