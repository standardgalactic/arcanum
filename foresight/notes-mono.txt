Semantics of Programming Languages
Computer Science Tripos, Part 1B
2014
Peter Sewell
Computer Laboratory
University of Cambridge
Lecture Theatre 1
Tuesday / Thursday 10am
4 February ‚Äì 11 March 2014
Time-stamp:
<2014-02-03 16:47:01 pes20>
c‚ÉùPeter Sewell 2014
c‚ÉùSam Staton 2009‚Äì2013
c‚ÉùPeter Sewell 2003‚Äì2009
1

Contents
Syllabus
3
Learning Guide
4
Summary of Notation
5
1
Introduction
8
2
A First Imperative Language
12
2.1
Operational Semantics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
13
2.2
Typing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
21
2.3
L1: Collected deÔ¨Ånition
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
28
2.4
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
30
3
Induction
31
3.1
Abstract Syntax and Structural Induction . . . . . . . . . . . . . . . . . . . . . . . .
33
3.2
Inductive DeÔ¨Ånitions and Rule Induction . . . . . . . . . . . . . . . . . . . . . . . . .
35
3.3
Example proofs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
38
3.4
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
45
4
Functions
46
4.1
Abstract syntax up to alpha conversion, and substitution
. . . . . . . . . . . . . . .
48
4.2
Function Behaviour . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
52
4.3
Function Typing
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
56
4.4
Local DeÔ¨Ånitions and Recursive Functions . . . . . . . . . . . . . . . . . . . . . . . .
58
4.5
Implementation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
61
4.6
L2: Collected DeÔ¨Ånition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
64
4.7
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
67
5
Data
68
5.1
Products and sums . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
68
5.2
Datatypes and Records
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
71
5.3
Mutable Store . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
73
5.4
Evaluation Contexts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
76
5.5
L3: Collected deÔ¨Ånition
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
77
5.6
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
81
6
Subtyping and Objects
82
6.1
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
88
7
Semantic Equivalence
89
7.1
Contextual equivalence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
94
7.2
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
94
8
Concurrency
95
8.1
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105
9
Epilogue
105
A Interpreter and type checker for L1 (ML)
107
B Interpreter and type checker for L1 (Java)
111
C How to do Proofs
117
C.1
How to go about it . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117
C.2
And in More Detail...
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119
C.2.1
Meet the Connectives
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119
C.2.2
Equivalences
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119
C.2.3
How to Prove a Formula . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120
C.2.4
How to Use a Formula . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122
C.3
An Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123
C.3.1
Proving the PL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123
C.3.2
Using the PL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124
C.4
Sequent Calculus Rules
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124
2

Syllabus
This course is a prerequisite for Types (Part II), Denotational Semantics (Part II), and
Topics in Concurrency (Part II).
Aims
The aim of this course is to introduce the structural, operational approach to program-
ming language semantics. It will show how to specify the meaning of typical programming
language constructs, in the context of language design, and how to reason formally about
semantic properties of programs.
Lectures
‚Ä¢ Introduction.
Transition systems.
The idea of structural operational semantics.
Transition semantics of a simple imperative language. Language design options.
‚Ä¢ Types. Introduction to formal type systems. Typing for the simple imperative lan-
guage. Statements of desirable properties.
‚Ä¢ Induction.
Review of mathematical induction.
Abstract syntax trees and struc-
tural induction. Rule-based inductive deÔ¨Ånitions and proofs. Proofs of type safety
properties.
‚Ä¢ Functions. Call-by-name and call-by-value function application, semantics and typ-
ing. Local recursive deÔ¨Ånitions.
‚Ä¢ Data. Semantics and typing for products, sums, records, references.
‚Ä¢ Subtyping. Record subtyping and simple object encoding.
‚Ä¢ Semantic equivalence. Semantic equivalence of phrases in a simple imperative lan-
guage, including the congruence property. Examples of equivalence and non-equivalence.
‚Ä¢ Concurrency. Shared variable interleaving. Semantics for simple mutexes; a serial-
izability property.
Objectives
At the end of the course students should
‚Ä¢ be familiar with rule-based presentations of the operational semantics and type systems
for some simple imperative, functional and interactive program constructs
‚Ä¢ be able to prove properties of an operational semantics using various forms of induction
(mathematical, structural, and rule-based)
‚Ä¢ be familiar with some operationally-based notions of semantic equivalence of program
phrases and their basic properties
Recommended reading
Hennessy, M. (1990). The semantics of programming languages. Wiley.
Out of print, but available on the web at
http://www.scss.tcd.ie/Matthew.Hennessy/slexternal/reading.php.
* Pierce, B.C. (2002). Types and programming languages. MIT Press. ebook available at
http://search.lib.cam.ac.uk/?itemid=|eresources|4228596.
Winskel, G. (1993). The formal semantics of programming languages. MIT Press.
3

Learning Guide
The books are all available in the Computer Laboratory Library. Books:
‚Ä¢ Hennessy, M. (1990). The Semantics of Programming Languages. Wiley. Out of print.
Introduces many of the key topics of the course. There‚Äôs a copy on the web at
http://www.scss.tcd.ie/Matthew.Hennessy/slexternal/reading.php.
‚Ä¢ Pierce, B. C. (2002) Types and Programming Languages. MIT Press.
This is a graduate-level text, covering a great deal of material on programming language
semantics. The Ô¨Årst half (through to Chapter 15) is relevant to this course, and some of the
later material relevant to the Part II Types course. ebook available at
http://search.lib.cam.ac.uk/?itemid=|eresources|1472
‚Ä¢ Winskel, G. (1993). The Formal Semantics of Programming Languages. MIT Press.
An introduction to both operational and denotational semantics.
‚Ä¢ Harper, R. W (2012). Practical Foundations for Programming Languages. MIT Press.
Also available from www.cs.cmu.edu/~rwh/plbook/book.pdf^aÀòAO.
Further reading:
‚Ä¢ Plotkin, G. D.(1981).
A structural approach to operational semantics.
Technical
Report DAIMI FN-19, Aarhus University.
These notes Ô¨Årst popularized the ‚Äòstructural‚Äô approach to operational semantics. Although
somewhat dated, they are still a mine of interesting examples. It is available at
http://homepages.inf.ed.ac.uk/gdp/publications/sos_jlap.pdf.
‚Ä¢ Two essays in: Wand, I. and R. Milner (Eds) (1996), Computing Tomorrow, CUP:
‚Äì
Hoare, C. A. R.. Algebra and Models.
‚Äì
Milner, R. Semantic Ideas in Computing.
Two accessible essays giving somewhat diÔ¨Äerent perspectives on the semantics of computation
and programming languages.
‚Ä¢ Andrew Pitts lectured this course until 2002. The syllabus has changed, but you might
enjoy his notes, still available at http://www.cl.cam.ac.uk/teaching/2001/Semantics/.
‚Ä¢ Pierce, B. C. (ed) (2005) Advanced Topics in Types and Programming Languages. MIT
Press.
This is a collection of articles by experts on a range of programming-language semantics topics.
Most of the details are beyond the scope of this course, but it gives a good overview of the
state of the art. The contents are listed at http://www.cis.upenn.edu/~bcpierce/attapl/.
Implementations: Implementations of some of the languages are available on the course
web page, accessible via http://www.cl.cam.ac.uk/teaching/current.
They are written in Moscow ML. This is installed on the Intel Lab machines. If you want to
work with them on your own machine instead, there are Linux, Windows, and Mac versions
of Moscow ML available at http://www.itu.dk/~sestoft/mosml.html.
Exercises: The notes contain various exercises, some related to the implementations. Those
marked ‚ãÜshould be straightforward checks that you are grasping the material; I suggest
you attempt all of these. Exercises marked ‚ãÜ‚ãÜmay need a little more thought ‚Äì both
proofs and some implementation-related; you should do most of them. Exercises marked
‚ãÜ‚ãÜ‚ãÜmay need material beyond the notes, and/or be quite time-consuming. Below is a
possible selection of exercises for supervisions.
1. ¬ß2.4: 1, 3, 4, 8, 9, 10, 11 (all these should be pretty quick); ¬ß3.4: 12, 15.
2. ¬ß4.7: 18, 19, 20, 21, 22; ¬ß5.6: 28; 2003.5.11.
4

3. ¬ß7.2: 37, ¬ß8.1: (39), 40; ¬ß6.1: 31, 32, 35; 2003.6.12, mock tripos from www.
Tripos questions: This version of the course was Ô¨Årst given in 2002‚Äì2003. The questions
since then are directly relevant, and there is an additional mock question on the course web
page. The previous version of the course (by Andrew Pitts) used a slightly diÔ¨Äerent form
of operational semantics, ‚Äòbig-step‚Äô instead of ‚Äòsmall-step‚Äô (see Page 63 of these notes), and
diÔ¨Äerent example languages, so the notation in most earlier questions may seem unfamiliar
at Ô¨Årst sight.
These questions use only small-step and should be accessible: 1998 Paper 6 Question 12,
1997 Paper 5 Question 12, and 1996 Paper 5 Question 12.
These questions use big-step, but apart from that should be ok: 2002 Paper 5 Question 9,
2002 Paper 6 Question 9, 2001 Paper 5 Question 9, 2000 Paper 5 Question 9, 1999 Paper 6
Question 9 (Ô¨Årst two parts only), 1999 Paper 5 Question 9, 1998 Paper 5 Question 12, 1995
Paper 6 Question 12, 1994 Paper 7 Question 13, 1993 Paper 7 Question 10.
These questions depend on material which is no longer in this course (complete partial
orders, continuations, or bisimulation ‚Äì see the Part II Denotational Semantics and Topics
in Concurrency courses): 2001 Paper 6 Question 9, 2000 Paper 6 Question 9, 1997 Paper 6
Question 12, 1996 Paper 6 Question 12, 1995 Paper 5 Question 12, 1994 Paper 8 Question
12, 1994 Paper 9 Question 12, 1993 Paper 8 Question 10, 1993 Paper 9 Question 10.
Feedback: Please do complete the on-line feedback form at the end of the course, and let
me know during it if you discover errors in the notes or if the pace is too fast or slow. A list
of corrections will be on the course web page.
Acknowledgements (P. Sewell): These notes are a modiÔ¨Åcation of the notes that Sam
Staton used for the course, 2010‚Äì2013.
Acknowledgements (S. Staton): These notes are a modiÔ¨Åcation of the notes that Peter
Sewell used for the course, 2003‚Äì2009.
Acknowledgements (P. Sewell): These notes draw, with thanks, on earlier courses by
Andrew Pitts, on Benjamin Pierce‚Äôs book, and many other sources.
Any errors are, of
course, newly introduced by me.
Summary of Notation
Each section is roughly in the order that notation is introduced.
The grammars of the
languages are not included here, but are in the Collected DeÔ¨Ånitions of L1, L2 and L3 later
in this document.
5

Logic and Set Theory
Œ¶ ‚àßŒ¶‚Ä≤
and
Œ¶ ‚à®Œ¶‚Ä≤
or
Œ¶ ‚áíŒ¶‚Ä≤
implies
¬¨ Œ¶
not
‚àÄx.Œ¶(x)
for all
‚àÉx.Œ¶(x)
exists
a ‚ààA
element of
{a1, ..., an}
the set with elements a1, ..., an
A1 ‚à™A2
union
A1 ‚à©A2
intersection
A1 ‚äÜA2
subset or equal
A1 ‚àóA2
cartesian product (set of pairs)
Finite partial functions
{a1 7‚Üíb1, ..., an 7‚Üíbn}
Ô¨Ånite partial function mapping each ai to bi
dom(s)
set of elements in the domain of s
f + {a 7‚Üíb}
the Ô¨Ånite partial function f extended or overridden with
a maps to b
Œì, x:T
the Ô¨Ånite partial function Œì extended with {x 7‚ÜíT}
‚Äì only used where x not in dom(Œì)
Œì, Œì‚Ä≤
the Ô¨Ånite partial function which is the union of Œì and Œì
‚Äì only used where they have disjoint domains
{l1 7‚Üín1, ..., lk 7‚Üínk}
an L1 or L2 store ‚Äì the Ô¨Ånite partial function mapping
each li to ni
{l1 7‚Üív1, ..., lk 7‚Üívk}
an L3 store ‚Äì the Ô¨Ånite partial function mapping each li to vi
l1:intref, ..., lk:intref
an L1 type environment ‚Äì the Ô¨Ånite partial function
mapping each li to intref
‚Ñì:intref, ..., x:T, ...
an L2 type environment
‚Ñì:Tloc, ..., x:T, ...
an L3 type environment
{e1/x1, .., ek/xk}
a substitution ‚Äì the Ô¨Ånite partial function
{x1 7‚Üíe1, ..., xk 7‚Üíek} mapping x1 to e1 etc.
Relations and auxiliary functions
‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©
reduction (or transition) step
‚ü®e, s‚ü©‚àí‚Üí‚àó‚ü®e‚Ä≤, s‚Ä≤‚ü©
reÔ¨Çexive transitive closure of ‚àí‚Üí
‚ü®e, s‚ü©‚àí‚Üík ‚ü®e‚Ä≤, s‚Ä≤‚ü©
the k-fold composition of ‚àí‚Üí
‚ü®e, s‚ü©‚àí‚Üíœâ
has an inÔ¨Ånite reduction sequence (a unary predicate)
‚ü®e, s‚ü©Ã∏‚àí‚Üí
cannot reduce (a unary predicate)
Œì ‚ä¢e:T
in type environment Œì, expression e has type T
value(e)
e is a value
fv(e)
the set of free variables of e
{e/x}e‚Ä≤
the expression resulting from substituting e for x in e‚Ä≤
œÉ e
the expression resulting from applying the substituting œÉ to e
‚ü®e, s‚ü©‚áì‚ü®v, s‚Ä≤‚ü©
big-step evaluation
Œì ‚ä¢s
store s is well-typed with respect to type environment Œì
T <: T ‚Ä≤
type T is a subtype of type T ‚Ä≤
e ‚âÉe‚Ä≤
semantic equivalence (informal)
e ‚âÉT
Œì e‚Ä≤
semantic equivalence at type T with respect to type
environment Œì
e
a
‚àí‚Üíe‚Ä≤
single thread transition step, labelled with action a
6

Particular sets
B = {true, false}
the set of booleans
L = {l, l1, l2, ...}
the set of locations
Z = {.., ‚àí1, 0, 1, ...}
the set of integers
N = {0, 1, ...}
the set of natural numbers
X = {x, y, ...}
the set of L2 and L3 variables
LAB = {p, q, ...}
the set of record labels
M = {m, m0, m1, ...}
the set of mutex names
T
the set of all types (in whichever language)
Tloc
the set of all location types (in whichever language)
L1
the set of all L1 expressions
TypeEnv
the set of all L1 type environments, Ô¨Ånite partial functions
from L to Z
TypeEnv2
the set of all L2 type environments, the Ô¨Ånite partial functions
from L ‚à™X to Tloc ‚à™T
such that ‚àÄ‚Ñì‚ààdom(Œì).Œì(‚Ñì) ‚ààTloc and ‚àÄx ‚ààdom(Œì).Œì(x) ‚ààT
Metavariables
b ‚ààB
boolean
n ‚ààZ
integer
‚Ñì‚ààL
location
op
binary operation
e, f
expression (of whichever language)
v
value (of whichever language)
s
store (of whichever language)
T ‚ààT
type (of whichever language)
Tloc ‚ààTloc
location type (of whichever language)
Œì
type environment (also, set of propositional assumptions)
i, k, y
natural numbers
c
conÔ¨Åguration (or state), typically ‚ü®e, s‚ü©with expression e and store s
Œ¶
formula
c
tree constructor
R
set of rules
(H , c)
a rule with hypotheses H ‚äÜA and conclusion c ‚ààA for some set A
SR
a subset inductively deÔ¨Åned by the set of rules R
x ‚ààX
variable
œÉ
substitution
lab ‚ààLAB
record label
E
evaluation context
C
arbitrary context
œÄ
permutation of natural numbers
m ‚ààM
mutex name
M
state of all mutexes (a function M :M ‚àí‚ÜíB)
a
thread action
Other
hole in a context
C[e]
context C with e replacing the hole
7

1
Introduction
Slide 1
Semantics of Programming Languages
Peter Sewell
1B, 12 lectures
2014
In this course we will take a close look at programming languages. We will focus on how to
deÔ¨Åne precisely what a programming language is ‚Äì i.e., how the programs of the language
behave, or, more generally, what their meaning, or semantics, is.
Slide 2
Semantics ‚Äî What is it?
How to describe a programming language? Need to give:
‚Ä¢ the syntax of programs; and
‚Ä¢ their semantics (the meaning of programs, or how they behave).
Styles of description:
‚Ä¢ the language is deÔ¨Åned by whatever some particular compiler does
‚Ä¢ natural language ‚ÄòdeÔ¨Ånitions‚Äô
‚Ä¢ mathematically
Mathematical descriptions of syntax use formal grammars (eg BNF) ‚Äì
precise, concise, clear. In this course we‚Äôll see how to work with
mathematical deÔ¨Ånitions of semantics/behaviour.
Many programming languages that you meet are described only in natural language, e.g.
the English standards documents for C, Java, XML, etc. These are reasonably accessible
(though often written in ‚Äòstandardsese‚Äô), but there are some major problems. It is very
hard, if not impossible, to write really precise deÔ¨Ånitions in informal prose. The standards
often end up being ambiguous or incomplete, or just too large and hard to understand.
That leads to diÔ¨Äering implementations and Ô¨Çaky systems, as the language implementors
and users do not have a common understanding of what it is. More fundamentally, natural
language standards obscure the real structure of languages ‚Äì it‚Äôs all too easy to add a feature
and a quick paragraph of text without thinking about how it interacts with the rest of the
language.
Instead, as we shall see in this course, one can develop mathematical deÔ¨Ånitions of how
programs behave, using logic and set theory (e.g. the deÔ¨Ånition of Standard ML, the .NET
CLR, recent work on XQuery, etc.). These require a little more background to understand
and use, but for many purposes they are a much better tool than informal standards.
Slide 3
What do we use semantics for?
1. to understand a particular language ‚Äî what you can depend on as a
programmer; what you must provide as a compiler writer
2. as a tool for language design:
(a) for expressing design choices, understanding language features
and how they interact.
(b) for proving properties of a language, eg type safety, decidability of
type inference.
3. as a foundation for proving properties of particular programs
8

Semantics complements the study of language implementation (cf. Compiler Construction
and Optimising Compilers). We need languages to be both clearly understandable, with
precise deÔ¨Ånitions, and have good implementations.
This is true not just for the major programming languages, but also for intermediate lan-
guages (JVM, CLR), and the many, many scripting and command languages, that have
often been invented on-the-Ô¨Çy without suÔ¨Écient thought.
More broadly, while in this course we will look mostly at semantics for conventional pro-
gramming languages, similar techniques can be used for hardware description languages,
veriÔ¨Åcation of distributed algorithms, security protocols, and so on ‚Äì all manner of subtle
systems for which relying on informal intuition alone leads to error.
Some of these are
explored in SpeciÔ¨Åcation and VeriÔ¨Åcation and Topics in Concurrency.
Slide 4
Warmup
In C, if initially x has value 3, what‚Äôs the value of the following?
x++ + x++ + x++ + x++
Slide 5
C‚ôØ
delegate int IntThunk();
class M {
public static void Main() {
IntThunk[] funcs = new IntThunk[11];
for (int i = 0; i <= 10; i++)
{
funcs[i] = delegate() { return i; };
}
foreach (IntThunk f in funcs)
{
System.Console.WriteLine(f());
}
}
}
Slide 6
JavaScript
function bar(x) { return function() { var x =
5; return x; }; }
var f = bar(200);
f()
Slide 7
JavaScript
function bar(x) { return function() { var x =
x; return x; }; }
var f = bar(200);
f()
Various diÔ¨Äerent approaches have been used for expressing semantics.
9

Slide 8
Styles of Semantic DeÔ¨Ånitions
‚Ä¢ Operational semantics
‚Ä¢ Denotational semantics
‚Ä¢ Axiomatic, or Logical, semantics
Operational: deÔ¨Åne the meaning of a program in terms of the computation steps it takes in
an idealized execution. Some deÔ¨Ånitions use structural operational semantics, in which the
intermediate states are described using the language itself; others use abstract machines,
which use more ad-hoc mathematical constructions.
Denotational: deÔ¨Åne the meaning of a program as elements of some abstract mathematical
structure, e.g. regarding programming-language functions as certain mathematical functions.
cf. the Denotational Semantics course.
Axiomatic or Logical: deÔ¨Åne the meaning of a program indirectly, by giving the axioms of
a logic of program properties. cf. SpeciÔ¨Åcation and VeriÔ¨Åcation.
Slide 9
‚ÄòToy‚Äô languages
Real programming languages are large, with many features and, often,
with redundant constructs ‚Äì things that can be expressed in the rest of the
language.
When trying to understand some particular combination of features it‚Äôs
usual to deÔ¨Åne a small ‚Äòtoy‚Äô language with just what you‚Äôre interested in,
then scale up later. Even small languages can involve delicate design
choices.
Slide 10
What‚Äôs this course?
Core
‚Ä¢ operational semantics and typing for a tiny language
‚Ä¢ technical tools (abstract syntax, inductive deÔ¨Ånitions, proof)
‚Ä¢ design for functions, data and references
More advanced topics
‚Ä¢ Subtyping and Objects
‚Ä¢ Semantic Equivalence
‚Ä¢ Concurrency
Slide 11
(assignment and while ) L11,2,3,4
(functions and recursive deÔ¨Ånitions) L25,6
Operational semantics
Type systems
Implementations
Language design choices
Inductive deÔ¨Ånitions
Inductive proof ‚Äì structural; rule
Abstract syntax up to alpha
(products, sums, records, references) L38
Subtyping
and Objects9
‚úâ
‚úâ
‚úâ
‚úâ
‚úâ
‚úâ
‚úâ
‚úâ
‚úâ
Semantic
Equivalence10
‚úµ‚úµ‚úµ‚úµ‚úµ‚úµ‚úµ‚úµ‚úµ‚úµ‚úµ‚úµ‚úµ‚úµ‚úµ‚úµ‚úµ‚úµ‚úµ‚úµ‚úµ‚úµ
Concurrency12
‚ùÅ‚ùÅ‚ùÅ‚ùÅ‚ùÅ‚ùÅ‚ùÅ‚ùÅ‚ùÅ‚ùÅ‚ùÅ‚ùÅ‚ùÅ‚ùÅ‚ùÅ‚ùÅ‚ùÅ‚ùÅ‚ùÅ‚ùÅ‚ùÅ‚ùÅ‚ùÅ‚ùÅ‚ùÅ‚ùÅ‚ùÅ‚ùÅ‚ùÅ‚ùÅ‚ùÅ‚ùÅ‚ùÅ‚ùÅ‚ùÅ‚ùÅ‚ùÅ‚ùÅ‚ùÅ
10

In the core we will develop enough techniques to deal with the semantics of a non-trivial
small language, showing some language-design pitfalls and alternatives along the way. It
will end up with the semantics of a decent fragment of ML. The second part will cover a
selection of more advanced topics.
Slide 12
The Big Picture
Discrete
Maths
%‚ñ≤
‚ñ≤
‚ñ≤
‚ñ≤
‚ñ≤
‚ñ≤
‚ñ≤
‚ñ≤
‚ñ≤
‚ñ≤
‚ñ≤
‚ñ≤
‚ñ≤
‚ñ≤
‚ñ≤
‚ñ≤
‚ñ≤
‚ñ≤
‚ñ≤
‚ñ≤
‚ñ≤
‚ñ≤
‚ñ≤
‚ñ≤
‚ñ≤
‚ñ≤
‚ñ≤
RLFA
‚úæ‚úæ‚úæ‚úæ‚úæ‚úæ‚úæ‚úæ‚úæ‚úæ‚úæ‚úæ‚úæ‚úæ‚úæ‚úæ‚úæ‚úæ‚úæ
Logic
& Proof

ML
‚úÜ‚úÜ‚úÜ‚úÜ‚úÜ‚úÜ‚úÜ‚úÜ‚úÜ‚úÜ‚úÜ‚úÜ‚úÜ‚úÜ‚úÜ‚úÜ‚úÜ‚úÜ‚úÜ
Java and
C&DS
yssssssssssssssssssssssssss
Computability
t‚úê‚úê‚úê‚úê‚úê‚úê‚úê‚úê‚úê‚úê‚úê‚úê‚úê‚úê‚úê‚úê‚úê‚úê‚úê‚úê‚úê‚úê
Compiler
Construction
and Optimising
Compilers
Semantics
yrrrrrrrrrrrrrrrrrrrrrrrrrrrr
‚úÜ‚úÜ‚úÜ‚úÜ‚úÜ‚úÜ‚úÜ‚úÜ‚úÜ‚úÜ‚úÜ‚úÜ‚úÜ‚úÜ‚úÜ‚úÜ‚úÜ

‚úæ‚úæ‚úæ‚úæ‚úæ‚úæ‚úæ‚úæ‚úæ‚úæ‚úæ‚úæ‚úæ‚úæ‚úæ‚úæ‚úæ‚úæ
Concepts in
Programming
Languages
Types
Topics in
Concurrency
Spec&Ver I,II
Denotational
Semantics
Advanced
Programming
Languages?
Slide 13
Admin
‚Ä¢ Please let me know of typos, and if it is too fast/too slow/too
interesting/too dull (please complete the on-line feedback at the end)
‚Ä¢ Not all previous Tripos questions are relevant (see the notes)
‚Ä¢ Exercises in the notes.
‚Ä¢ Implementations on web.
‚Ä¢ Books (Hennessy, Pierce, Winskel)
11

2
A First Imperative Language
Slide 14
L1
Slide 15
L1 ‚Äì Example
L1 is an imperative language with store locations (holding integers),
conditionals, and while loops. For example, consider the program
l2 := 0;
while !l1 ‚â•1 do (
l2 :=!l2+!l1;
l1 :=!l1 + ‚àí1)
in the initial store {l1 7‚Üí3, l2 7‚Üí0}.
Slide 16
L1 ‚Äì Syntax
Booleans b ‚ààB = {true, false}
Integers n ‚ààZ = {..., ‚àí1, 0, 1, ...}
Locations ‚Ñì‚ààL = {l, l0, l1, l2, ...}
Operations op ::= + |‚â•
Expressions
e
::=
n | b | e1 op e2 | if e1 then e2 else e3 |
‚Ñì:= e |!‚Ñì|
skip | e1; e2 |
while e1 do e2
Write L1 for the set of all expressions.
Points to note:
‚Ä¢ we‚Äôll return later to exactly what the set L1 is when we talk about abstract syntax
‚Ä¢ unbounded integers
‚Ä¢ abstract locations ‚Äì can‚Äôt do pointer arithmetic on them
‚Ä¢ untyped, so have nonsensical expressions like 3 + true
‚Ä¢ what kind of grammar is that (c.f. RLFA)?
‚Ä¢ don‚Äôt have expression/command distinction
‚Ä¢ doesn‚Äôt much matter what basic operators we have
‚Ä¢ carefully distinguish metavariables b, n, ‚Ñì, op , e etc. from program locations l etc..
12

2.1
Operational Semantics
In order to describe the behaviour of L1 programs we will use structural operational seman-
tics to deÔ¨Åne various forms of automata:
Slide 17
Transition systems
A transition system consists of
‚Ä¢ a set ConÔ¨Åg, and
‚Ä¢ a binary relation ‚àí‚Üí‚äÜConÔ¨Åg ‚àóConÔ¨Åg.
The elements of ConÔ¨Åg are often called conÔ¨Ågurations or states. The
relation ‚àí‚Üíis called the transition or reduction relation. We write ‚àí‚Üí
inÔ¨Åx, so c ‚àí‚Üíc‚Ä≤ should be read as ‚Äòstate c can make a transition to
state c‚Ä≤‚Äô.
To compare with the automata you saw in Regular Languages and Finite Automata: a
transition system is like an NFAŒµ with an empty alphabet (so only Œµ transitions) except (a)
it can have inÔ¨Ånitely many states, and (b) we don‚Äôt specify a start state or accepting states.
Sometimes one adds labels (e.g. to represent IO) but mostly we‚Äôll just look at the values of
terminated states, those that cannot do any transitions.
Notation.
‚Ä¢ ‚àí‚Üí‚àóis the reÔ¨Çexive transitive closure of ‚àí‚Üí, so c ‚àí‚Üí‚àóc‚Ä≤ iÔ¨Äthere exist k ‚â•0 and
c0, .., ck such that c = c0 ‚àí‚Üíc1... ‚àí‚Üíck = c‚Ä≤.
‚Ä¢ Ã∏‚àí‚Üíis a unary predicate (a subset of ConÔ¨Åg) deÔ¨Åned by c Ã∏‚àí‚ÜíiÔ¨Ä¬¨ ‚àÉc‚Ä≤.c ‚àí‚Üíc‚Ä≤.
The particular transition systems we use for L1 are as follows.
Slide 18
L1 Semantics (1 of 4) ‚Äì ConÔ¨Ågurations
Say stores s are Ô¨Ånite partial functions from L to Z. For example:
{l1 7‚Üí7, l3 7‚Üí23}
Take conÔ¨Ågurations to be pairs ‚ü®e, s‚ü©of an expression e and a store s, so
our transition relation will have the form
‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©
DeÔ¨Ånition. A Ô¨Ånite partial function f from a set A to a set B is a set containing a Ô¨Ånite
number n ‚â•0 of pairs {(a1, b1), ..., (an, bn)}, often written {a1 7‚Üíb1, ..., an 7‚Üíbn}, for which
‚Ä¢ ‚àÄi ‚àà{1, .., n}.ai ‚ààA (the domain is a subset ofA)
‚Ä¢ ‚àÄi ‚àà{1, .., n}.bi ‚ààB (the range is a subset of B)
‚Ä¢ ‚àÄi ‚àà{1, .., n}, j ‚àà{1, .., n}.i Ã∏= j ‚áíai Ã∏= aj (f is functional, i.e. each element of A is
mapped to at most one element of B)
For a partial function f , we write dom(f ) for the set of elements in the domain of f (things
that f maps to something) and ran(f ) for the set of elements in the range of f (things that
something is mapped to by f ). For example, for the store s above we have dom(s) = {l1, l3}
and ran(s) = {7, 23}. Note that a Ô¨Ånite partial function can be empty, just {}.
We write store for the set of all stores.
13

Slide 19
Transitions are single computation steps. For example we will have:
‚ü®l := 2+!l,
{l 7‚Üí3}‚ü©
‚àí‚Üí
‚ü®l := 2 + 3,
{l 7‚Üí3}‚ü©
‚àí‚Üí
‚ü®l := 5,
{l 7‚Üí3}‚ü©
‚àí‚Üí
‚ü®skip,
{l 7‚Üí5}‚ü©
Ã∏‚àí‚Üí
want to keep on until we get to a value v, an expression in
V = B ‚à™Z ‚à™{skip}.
Say ‚ü®e, s‚ü©is stuck if e is not a value and ‚ü®e, s‚ü©Ã∏‚àí‚Üí. For example
2 + true will be stuck.
We could deÔ¨Åne the values in a diÔ¨Äerent, but equivalent, style: Say values v are expressions
from the grammar v ::= b | n | skip.
Now deÔ¨Åne the behaviour for each construct of L1 by giving some rules that (together)
deÔ¨Åne a transition relation ‚àí‚Üí.
Slide 20
L1 Semantics (2 of 4) ‚Äì Rules (basic operations)
(op +)
‚ü®n1 + n2, s‚ü©‚àí‚Üí‚ü®n, s‚ü©
if n = n1 + n2
(op ‚â•)
‚ü®n1 ‚â•n2, s‚ü©‚àí‚Üí‚ü®b, s‚ü©
if b = (n1 ‚â•n2)
(op1)
‚ü®e1, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
1, s‚Ä≤‚ü©
‚ü®e1 op e2, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
1 op e2, s‚Ä≤‚ü©
(op2)
‚ü®e2, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
2, s‚Ä≤‚ü©
‚ü®v op e2, s‚ü©‚àí‚Üí‚ü®v op e‚Ä≤
2, s‚Ä≤‚ü©
How to read these? The rule (op +) says that for any instantiation of the metavariables
n, n1 and n2 (i.e. any choice of three integers), that satisÔ¨Åes the sidecondition, there is a
transition from the instantiated conÔ¨Åguration on the left to the one on the right.
We use a strict naming convention for metavariables: n can only be instantiated by integers,
not by arbitrary expressions.
The rule (op1) says that for any instantiation of e1, e‚Ä≤
1, e2, s, s‚Ä≤ (i.e. any three expressions
and two stores), if a transition of the form above the line can be deduced then we can
deduce the transition below the line.
Observe that ‚Äì as you would expect ‚Äì none of these Ô¨Årst rules introduce changes in the store
part of conÔ¨Ågurations.
14

Slide 21
Example
If we want to Ô¨Ånd the possible sequences of transitions of
‚ü®(2 + 3) + (6 + 7), ‚àÖ‚ü©... look for derivations of transitions.
(you might think the answer should be 18 ‚Äì but we want to know what this
deÔ¨Ånition says happens)
(op1)
(op +)
‚ü®2 + 3, ‚àÖ‚ü©‚àí‚Üí‚ü®5, ‚àÖ‚ü©
‚ü®(2 + 3) + (6 + 7), ‚àÖ‚ü©‚àí‚Üí‚ü®5 + (6 + 7), ‚àÖ‚ü©
(op2)
(op +)
‚ü®6 + 7, ‚àÖ‚ü©‚àí‚Üí‚ü®13, ‚àÖ‚ü©
‚ü®5 + (6 + 7), ‚àÖ‚ü©‚àí‚Üí‚ü®5 + 13, ‚àÖ‚ü©
(op +)
‚ü®5 + 13, ‚àÖ‚ü©‚àí‚Üí‚ü®18, ‚àÖ‚ü©
First transition: using (op1) with e1 = 2 + 3, e‚Ä≤
1 = 5, e2 = 6 + 7, op = +, s = ‚àÖ, s‚Ä≤ = ‚àÖ,
and using (op +) with n1 = 2, n2 = 3, s = ‚àÖ. Note couldn‚Äôt begin with (op2) as e1 = 2 + 3
is not a value, and couldn‚Äôt use (op +) directly on (2 + 3) + (6 + 7) as 2 + 3 and 6 + 7 are
not numbers from Z ‚Äì just expressions which might eventually evaluate to numbers (recall,
by convention the n in the rules ranges over Z only).
Second transition: using (op2) with e1 = 5, e2 = 6 + 7, e‚Ä≤
2 = 13, op = +, s = ‚àÖ, s‚Ä≤ = ‚àÖ,
and using (op +) with n1 = 6, n2 = 7, s = ‚àÖ. Note that to use (op2) we needed that e1 = 5
is a value. We couldn‚Äôt use (op1) as e1 = 5 does not have any transitions itself.
Third transition: using (op +) with n1 = 5, n2 = 13, s = ‚àÖ.
To Ô¨Ånd each transition we do something like proof search in natural deduction: starting
with a state (at the bottom left), look for a rule and an instantiation of the metavariables
in that rule that makes the left-hand-side of its conclusion match that state. Beware that
in general there might be more than one rule and one instantiation that does this. If there
isn‚Äôt a derivation concluding in ‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©then there isn‚Äôt such a transition.
Slide 22
L1 Semantics (3 of 4) ‚Äì store and sequencing
(deref)
‚ü®!‚Ñì, s‚ü©‚àí‚Üí‚ü®n, s‚ü©
if ‚Ñì‚ààdom(s) and s(‚Ñì) = n
(assign1)
‚ü®‚Ñì:= n, s‚ü©‚àí‚Üí‚ü®skip, s + {‚Ñì7‚Üín}‚ü©
if ‚Ñì‚ààdom(s)
(assign2)
‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©
‚ü®‚Ñì:= e, s‚ü©‚àí‚Üí‚ü®‚Ñì:= e‚Ä≤, s‚Ä≤‚ü©
(seq1)
‚ü®skip; e2, s‚ü©‚àí‚Üí‚ü®e2, s‚ü©
(seq2)
‚ü®e1, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
1, s‚Ä≤‚ü©
‚ü®e1; e2, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
1; e2, s‚Ä≤‚ü©
15

Slide 23
Example
‚ü®l := 3; !l, {l 7‚Üí0}‚ü©
‚àí‚Üí
‚ü®skip; !l, {l 7‚Üí3}‚ü©
‚àí‚Üí
‚ü®!l, {l 7‚Üí3}‚ü©
‚àí‚Üí
‚ü®3, {l 7‚Üí3}‚ü©
‚ü®l := 3; l :=!l, {l 7‚Üí0}‚ü©
‚àí‚Üí
?
‚ü®15+!l, ‚àÖ‚ü©
‚àí‚Üí
?
Slide 24
L1 Semantics (4 of 4) ‚Äì The rest (conditionals and while)
(if1)
‚ü®if true then e2 else e3, s‚ü©‚àí‚Üí‚ü®e2, s‚ü©
(if2)
‚ü®if false then e2 else e3, s‚ü©‚àí‚Üí‚ü®e3, s‚ü©
(if3)
‚ü®e1, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
1, s‚Ä≤‚ü©
‚ü®if e1 then e2 else e3, s‚ü©‚àí‚Üí‚ü®if e‚Ä≤
1 then e2 else e3, s‚Ä≤‚ü©
(while)
‚ü®while e1 do e2, s‚ü©‚àí‚Üí‚ü®if e1 then (e2; while e1 do e2) else skip, s‚ü©
Slide 25
Example
If
e = (l2 := 0; while !l1 ‚â•1 do (l2 :=!l2+!l1; l1 :=!l1 + ‚àí1))
s = {l1 7‚Üí3, l2 7‚Üí0}
then
‚ü®e, s‚ü©‚àí‚Üí‚àó?
That concludes our deÔ¨Ånition of L1. The full deÔ¨Ånition is collected on page 28.
Slide 26
Determinacy
Theorem 1 (L1 Determinacy) If ‚ü®e, s‚ü©‚àí‚Üí‚ü®e1, s1‚ü©and
‚ü®e, s‚ü©‚àí‚Üí‚ü®e2, s2‚ü©then ‚ü®e1, s1‚ü©= ‚ü®e2, s2‚ü©.
Proof ‚Äì see later
Note that top-level universal quantiÔ¨Åers are usually left out ‚Äì the theorem really says ‚ÄúFor
all e, s, e1, s1, e2, s2, if ‚ü®e, s‚ü©‚àí‚Üí‚ü®e1, s1‚ü©and ‚ü®e, s‚ü©‚àí‚Üí‚ü®e2, s2‚ü©then ‚ü®e1, s1‚ü©= ‚ü®e2, s2‚ü©‚Äù.
16

Slide 27
L1 implementation
Many possible implementation strategies, including:
1. animate the rules ‚Äî use uniÔ¨Åcation to try to match rule conclusion
left-hand-sides against a conÔ¨Åguration; use backtracking search to Ô¨Ånd
all possible transitions. Hand-coded, or in Prolog/LambdaProlog/Twelf.
2. write an interpreter working directly over the syntax of conÔ¨Ågurations.
Coming up, in ML and Java.
3. compile to a stack-based virtual machine, and an interpreter for that.
See Compiler Construction.
4. compile to assembly language, dealing with register allocation etc. etc.
See Compiler Construction/Optimizing Compilers.
Slide 28
L1 implementation
Will implement an interpreter for L1, following the deÔ¨Ånition. Use mosml
(Moscow ML) as the implementation language, as datatypes and pattern
matching are good for this kind of thing.
First, must pick representations for locations, stores, and expressions:
type loc = string
type store = (loc * int) list
We‚Äôve chosen to represent locations as strings, so they pretty-print trivially. A lower-level
implementation would use ML references.
In the semantics, a store is a Ô¨Ånite partial function from locations to integers.
In the
implementation, we represent a store as a list of loc*int pairs containing, for each ‚Ñìin the
domain of the store and mapped to n, exactly one element of the form (l,n). The order of
the list will not be important. This is not a very eÔ¨Écient implementation, but it is simple.
Slide 29
datatype oper = Plus | GTEQ
datatype expr =
Integer of int
| Boolean of bool
| Op of expr * oper * expr
| If of expr * expr * expr
| Assign of loc * expr
| Deref of loc
| Skip
| Seq of expr * expr
| While of expr * expr
The expression and operation datatypes have essentially the same form as the abstract
grammar.
Note, though, that it does not exactly match the semantics, as that allowed
arbitrary integers whereas here we use the bounded Moscow ML integers ‚Äì so not every
term of the abstract syntax is representable as an element of type expr, and the interpreter
will fail with an overÔ¨Çow exception if + overÔ¨Çows.
17

Slide 30
Store operations
DeÔ¨Åne auxiliary operations
lookup :
store*loc -> int option
update :
store*(loc*int) -> store option
which both return NONE if given a location that is not in the domain of the
store. Recall that a value of type T option is either NONE or
SOME v for a value v of T.
Slide 31
The single-step function
Now deÔ¨Åne the single-step function
reduce : expr*store -> (expr*store) option
which takes a conÔ¨Åguration (e,s) and returns either
NONE, if ‚ü®e, s‚ü©Ã∏‚àí‚Üí,
or SOME (e‚Äô,s‚Äô), if it has a transition ‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©.
Note that if the semantics didn‚Äôt deÔ¨Åne a deterministic transition system
we‚Äôd have to be more elaborate.
(you might think it would be better ML style to use exceptions instead of these options;
that would be Ô¨Åne).
Slide 32
(op +), (op ‚â•)
fun reduce (Integer n,s) = NONE
| reduce (Boolean b,s) = NONE
| reduce (Op (e1,opr,e2),s) =
(case (e1,opr,e2) of
(Integer n1, Plus, Integer n2) =>
SOME(Integer (n1+n2), s)
| (Integer n1, GTEQ, Integer n2) =>
SOME(Boolean (n1 >= n2), s)
| (e1,opr,e2) =>
...
Contrast this code with the semantic rules given earlier.
Slide 33
(op1), (op2)
...
if (is value e1) then
case reduce (e2,s) of
SOME (e2‚Äô,s‚Äô) =>
SOME (Op(e1,opr,e2‚Äô),s‚Äô)
| NONE => NONE
else
case reduce (e1,s) of
SOME (e1‚Äô,s‚Äô) =>
SOME(Op(e1‚Äô,opr,e2),s‚Äô)
| NONE => NONE )
18

Note that the code depends on global properties of the semantics, including the fact that it
deÔ¨Ånes a deterministic transition system, so the comments indicating that particular lines
of code implement particular semantic rules are not the whole story.
Slide 34
(assign1), (assign2)
| reduce (Assign (l,e),s) =
(case e of
Integer n =>
(case update (s,(l,n)) of
SOME s‚Äô => SOME(Skip, s‚Äô)
| NONE => NONE)
|
=>
(case reduce (e,s) of
SOME (e‚Äô,s‚Äô) =>
SOME(Assign (l,e‚Äô), s‚Äô)
| NONE => NONE ) )
Slide 35
The many-step evaluation function
Now deÔ¨Åne the many-step evaluation function
evaluate: expr*store -> (expr*store) option
which takes a conÔ¨Åguration (e,s) and returns the (e‚Äô,s‚Äô) such that
‚ü®e, s‚ü©‚àí‚Üí‚àó‚ü®e‚Ä≤, s‚Ä≤‚ü©Ã∏‚àí‚Üí, if there is such, or does not return.
fun evaluate (e,s) =
case reduce (e,s) of
NONE => (e,s)
| SOME (e‚Äô,s‚Äô) => evaluate (e‚Äô,s‚Äô)
The full interpreter code is in Appendix A, and you can also download it from the course
website, in the Ô¨Åle l1.ml, together with a pretty-printer and the type-checker we will come
to soon. For comparison, there is also a Java implementation in l1.java.
Slide 36
The Java Implementation
Quite different code structure:
‚Ä¢ the ML groups together all the parts of each algorithm, into the
reduce, infertype, and prettyprint functions;
‚Ä¢ the Java groups together everything to do with each clause of the
abstract syntax, in the IfThenElse, Assign, etc. classes.
19

L1 is a simple language, but it nonetheless involves several language design choices.
Slide 37
Language design 1. Order of evaluation
For (e1 op e2), the rules above say e1 should be fully reduced, to a
value, before we start reducing e2. For example:
‚ü®(l := 1; 0) + (l := 2; 0), {l 7‚Üí0}‚ü©‚àí‚Üí5 ‚ü®0, {l ‚Üí
2 }‚ü©
For right-to-left evaluation, replace (op1) and (op2) by
(op1b)
‚ü®e2, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
2, s‚Ä≤‚ü©
‚ü®e1 op e2, s‚ü©‚àí‚Üí‚ü®e1 op e‚Ä≤
2, s‚Ä≤‚ü©
(op2b)
‚ü®e1, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
1, s‚Ä≤‚ü©
‚ü®e1 op v, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
1 op v, s‚Ä≤‚ü©
In this language (call it L1b)
‚ü®(l := 1; 0) + (l := 2; 0), {l 7‚Üí0}‚ü©‚àí‚Üí5 ‚ü®0, {l ‚Üí
1 }‚ü©
Left-to-right evaluation is arguably more intuitive than right-to-left.
One could also underspecify, taking both (op1) and (op1b) rules. That language doesn‚Äôt
have the Determinacy property.
Slide 38
Language design 2. Assignment results
Recall
(assign1)
‚ü®‚Ñì:= n, s‚ü©‚àí‚Üí‚ü®skip, s + {‚Ñì7‚Üín}‚ü©
if ‚Ñì‚ààdom(s)
(seq1)
‚ü®skip; e2, s‚ü©‚àí‚Üí‚ü®e2, s‚ü©
So
‚ü®l := 1; l := 2, {l 7‚Üí0}‚ü©
‚àí‚Üí
‚ü®skip; l := 2, {l 7‚Üí1}‚ü©
‚àí‚Üí‚àó
‚ü®skip, {l 7‚Üí2}‚ü©
We‚Äôve chosen ‚Ñì:= n to result in skip, and e1; e2 to only progress if
e1 = skip, not for any value. Instead could have this:
(assign1‚Äô)
‚ü®‚Ñì:= n, s‚ü©‚àí‚Üí‚ü®n, s + (‚Ñì7‚Üín)‚ü©
if ‚Ñì‚ààdom(s)
(seq1‚Äô)
‚ü®v; e2, s‚ü©‚àí‚Üí‚ü®e2, s‚ü©
Matter of taste? Another possiblity: return the old value, e.g. in ANSI C signal handler
installation.
Slide 39
Language design 3. Store initialization
Recall that
(deref)
‚ü®!‚Ñì, s‚ü©‚àí‚Üí‚ü®n, s‚ü©
if ‚Ñì‚ààdom(s) and s(‚Ñì) = n
(assign1)
‚ü®‚Ñì:= n, s‚ü©‚àí‚Üí‚ü®skip, s + {‚Ñì7‚Üín}‚ü©
if ‚Ñì‚ààdom(s)
both require ‚Ñì‚ààdom(s), otherwise the expressions are stuck.
Instead, could
1. implicitly initialize all locations to 0, or
2. allow assignment to an ‚Ñì/‚ààdom(s) to initialize that ‚Ñì.
20

In the next section we will introduce a type system to rule out any program that could reach
a stuck expression of these forms. (Would the two alternatives be a good idea?)
Slide 40
Language design 4. Storable values
Recall stores s are Ô¨Ånite partial functions from L to Z, with rules:
(deref)
‚ü®!‚Ñì, s‚ü©‚àí‚Üí‚ü®n, s‚ü©
if ‚Ñì‚ààdom(s) and s(‚Ñì) = n
(assign1)
‚ü®‚Ñì:= n, s‚ü©‚àí‚Üí‚ü®skip, s + {‚Ñì7‚Üín}‚ü©
if ‚Ñì‚ààdom(s)
(assign2)
‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©
‚ü®‚Ñì:= e, s‚ü©‚àí‚Üí‚ü®‚Ñì:= e‚Ä≤, s‚Ä≤‚ü©
Can store only integers. ‚ü®l := true, s‚ü©is stuck.
Why not allow storage of any value? of locations? of programs?
Also, store is global. We will consider programs that can create new
locations later.
Slide 41
Language design 5. Operators and basic values
Booleans are really not integers (unlike in C)
The L1 impl and semantics aren‚Äôt quite in step.
Exercise: Ô¨Åx the implementation to match the semantics.
Exercise: Ô¨Åx the semantics to match the implementation.
Slide 42
Expressiveness
Is L1 expressive enough to write interesting programs?
‚Ä¢ yes: it‚Äôs Turing-powerful (try coding an arbitrary register machine in
L1).
‚Ä¢ no: there‚Äôs no support for gadgets like functions, objects, lists, trees,
modules,.....
Is L1 too expressive? (ie, can we write too many programs in it)
‚Ä¢ yes: we‚Äôd like to forbid programs like 3 + false as early as possible,
rather than let the program get stuck or give a runtime error. We‚Äôll do
so with a type system.
2.2
Typing
Slide 43
L1 Typing
21

Slide 44
Type systems
used for
‚Ä¢ describing when programs make sense
‚Ä¢ preventing certain kinds of errors
‚Ä¢ structuring programs
‚Ä¢ guiding language design
Ideally, well-typed programs don‚Äôt get stuck.
Type systems are also used to provide information to compiler optimizers; to enforce security
properties, from simple absence of buÔ¨Äer overÔ¨Çows to sophisticated information-Ô¨Çow policies;
and (in research languages) for many subtle properties, e.g. type systems that allow only
polynomial-time computation. There are rich connections with logic, which we‚Äôll return to
later.
Slide 45
Formal type systems
We will deÔ¨Åne a ternary relation Œì ‚ä¢e:T , read as ‚Äòexpression e has type
T , under assumptions Œì on the types of locations that may occur in e‚Äô.
For example (according to the deÔ¨Ånition coming up):
{}
‚ä¢
if true then 2 else 3 + 4
:
int
l1:intref
‚ä¢
if !l1 ‚â•3 then !l1 else 3
:
int
{}
Ã∏‚ä¢
3 + false
:
T
for any T
{}
Ã∏‚ä¢
if true then 3 else false
:
int
Note that the last is excluded despite the fact that when you execute the program you will
always get an int ‚Äì type systems deÔ¨Åne approximations to the behaviour of programs, often
quite crude ‚Äì and this has to be so, as we generally would like them to be decidable, so that
compilation is guaranteed to terminate.
Slide 46
Types for L1
Types of expressions:
T
::=
int | bool | unit
Types of locations:
Tloc
::=
intref
Write T and Tloc for the sets of all terms of these grammars.
Let Œì range over TypeEnv, the Ô¨Ånite partial functions from locations L
to Tloc. Notation: write a Œì as l1:intref, ..., lk:intref instead of
{l1 7‚Üíintref, ..., lk 7‚Üíintref}.
‚Ä¢ concretely, T = {int, bool, unit} and Tloc = {intref}.
‚Ä¢ in this language, there is only one type in Tloc, so a Œì can be thought of as just a set
of locations. (Later, Tloc will be more interesting.)
22

Slide 47
DeÔ¨Åning the type judgement Œì ‚ä¢e:T
(1 of 3)
(int)
Œì ‚ä¢n:int
for n ‚ààZ
(bool)
Œì ‚ä¢b:bool
for b ‚àà{true, false}
(op +)
Œì ‚ä¢e1:int
Œì ‚ä¢e2:int
Œì ‚ä¢e1 + e2:int
(op ‚â•)
Œì ‚ä¢e1:int
Œì ‚ä¢e2:int
Œì ‚ä¢e1 ‚â•e2:bool
(if)
Œì ‚ä¢e1:bool
Œì ‚ä¢e2:T
Œì ‚ä¢e3:T
Œì ‚ä¢if e1 then e2 else e3:T
Note that in (if) the T is arbitrary, so long as both premises have the same T.
In some rules we arrange the premises vertically to save space, e.g.
(op +)
Œì ‚ä¢e1:int
Œì ‚ä¢e2:int
Œì ‚ä¢e1 + e2:int
but this is merely visual layout. Derivations using such a rule should be written as if it was
in the horizontal form.
(op +)
Œì ‚ä¢e1:int
Œì ‚ä¢e2:int
Œì ‚ä¢e1 + e2:int
Slide 48
Example
To show {} ‚ä¢if false then 2 else 3 + 4:int we can give a type
derivation like this:
(if)
(bool)
{} ‚ä¢false:bool
(int)
{} ‚ä¢2:int ‚àá
{} ‚ä¢if false then 2 else 3 + 4:int
where ‚àáis
(op +)
(int)
{} ‚ä¢3:int
(int)
{} ‚ä¢4:int
{} ‚ä¢3 + 4:int
Slide 49
DeÔ¨Åning the type judgement Œì ‚ä¢e:T
(2 of 3)
(assign)
Œì(‚Ñì) = intref
Œì ‚ä¢e:int
Œì ‚ä¢‚Ñì:= e:unit
(deref)
Œì(‚Ñì) = intref
Œì ‚ä¢!‚Ñì:int
Here the Œì(‚Ñì) = intref just means ‚Ñì‚ààdom(Œì).
23

Slide 50
DeÔ¨Åning the type judgement Œì ‚ä¢e:T
(3 of 3)
(skip)
Œì ‚ä¢skip:unit
(seq)
Œì ‚ä¢e1:unit
Œì ‚ä¢e2:T
Œì ‚ä¢e1; e2:T
(while)
Œì ‚ä¢e1:bool
Œì ‚ä¢e2:unit
Œì ‚ä¢while e1 do e2:unit
Note that the typing rules are syntax-directed ‚Äì for each clause of the abstract syntax for
expressions there is exactly one rule with a conclusion of that form.
Slide 51
Properties
Theorem 2 (Progress) If Œì ‚ä¢e:T and dom(Œì) ‚äÜdom(s) then either e
is a value or there exist e‚Ä≤, s‚Ä≤ such that ‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©.
Theorem 3 (Type Preservation) If Œì ‚ä¢e:T and dom(Œì) ‚äÜdom(s)
and ‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©then Œì ‚ä¢e‚Ä≤:T and dom(Œì) ‚äÜdom(s‚Ä≤).
From these two we have that well-typed programs don‚Äôt get stuck:
Theorem 4 (Safety) If Œì ‚ä¢e:T , dom(Œì) ‚äÜdom(s), and
‚ü®e, s‚ü©‚àí‚Üí‚àó‚ü®e‚Ä≤, s‚Ä≤‚ü©then either e‚Ä≤ is a value or there exist e‚Ä≤‚Ä≤, s‚Ä≤‚Ä≤ such
that ‚ü®e‚Ä≤, s‚Ä≤‚ü©‚àí‚Üí‚ü®e‚Ä≤‚Ä≤, s‚Ä≤‚Ä≤‚ü©.
(we‚Äôll discuss how to prove these results soon)
Semantic style: one could make an explicit deÔ¨Ånition of what conÔ¨Ågurations are runtime
errors. Here, instead, those conÔ¨Ågurations are just stuck.
Slide 52
Type checking, typeability, and type inference
Type checking problem for a type system: given Œì, e, T , is Œì ‚ä¢e:T
derivable?
Type inference problem: given Œì and e, Ô¨Ånd T such that Œì ‚ä¢e:T is
derivable, or show there is none.
Second problem is usually harder than the Ô¨Årst. Solving it usually results
in a type inference algorithm: computing a type T for a phrase e, given
type environment Œì (or failing, if there is none).
For this type system, though, both are easy.
Slide 53
More Properties
Theorem 5 (Type inference) Given Œì, e, one can Ô¨Ånd T such that
Œì ‚ä¢e:T , or show that there is none.
Theorem 6 (Decidability of type checking) Given Œì, e, T , one can
decide Œì ‚ä¢e:T .
Also:
Theorem 7 (Uniqueness of typing) If Œì ‚ä¢e:T and Œì ‚ä¢e:T ‚Ä≤ then
T = T ‚Ä≤.
24

The Ô¨Åle l1.ml contains also an implementation of a type inference algorithm for L1 ‚Äì take
a look.
Slide 54
Type inference ‚Äì Implementation
First must pick representations for types and for Œì‚Äôs:
datatype type L1 =
int
| unit
| bool
datatype type loc =
intref
type typeEnv = (loc*type loc) list
Now deÔ¨Åne the type inference function
infertype :
typeEnv -> expr -> type L1 option
In the semantics, type environments Œì are partial functions from locations to the singleton
set {intref}. Here, just as we did for stores, we represent them as a list of loc*type loc
pairs containing, for each ‚Ñìin the domain of the type environment, exactly one element of
the form (l,intref).
Slide 55
The Type Inference Algorithm
fun infertype gamma (Integer n) = SOME int
| infertype gamma (Boolean b) = SOME bool
| infertype gamma (Op (e1,opr,e2))
= (case (infertype gamma e1, opr, infertype gamma e2) of
(SOME int, Plus, SOME int) => SOME int
| (SOME int, GTEQ, SOME int) => SOME bool
|
=> NONE)
| infertype gamma (If (e1,e2,e3))
= (case (infertype gamma e1, infertype gamma e2, infertype gamma e3) of
(SOME bool, SOME t2, SOME t3) =>
if t2=t3 then SOME t2 else NONE
|
=> NONE)
| infertype gamma (Deref l)
= (case lookup (gamma,l) of
SOME intref => SOME int
| NONE => NONE)
| infertype gamma (Assign (l,e))
= (case (lookup (gamma,l), infertype gamma e) of
(SOME intref,SOME int) => SOME unit
|
=> NONE)
| infertype gamma (Skip) = SOME unit
| infertype gamma (Seq (e1,e2))
= (case (infertype gamma e1, infertype gamma e2) of
(SOME unit, SOME t2) => SOME t2
|
=> NONE )
| infertype gamma (While (e1,e2))
= (case (infertype gamma e1, infertype gamma e2) of
(SOME bool, SOME unit) => SOME unit )
25

Slide 56
The Type Inference Algorithm ‚Äì If
...
| infertype gamma (If (e1,e2,e3))
= (case (infertype gamma e1,
infertype gamma e2,
infertype gamma e3) of
(SOME bool, SOME t2, SOME t3) =>
if t2=t3 then SOME t2 else NONE
|
=> NONE)
(if)
Œì ‚ä¢e1:bool
Œì ‚ä¢e2:T
Œì ‚ä¢e3:T
Œì ‚ä¢if e1 then e2 else e3:T
Slide 57
The Type Inference Algorithm ‚Äì Deref
...
| infertype gamma (Deref l)
= (case lookup (gamma,l) of
SOME intref => SOME int
| NONE => NONE)
...
(deref)
Œì(‚Ñì) = intref
Œì ‚ä¢!‚Ñì:int
Again, the code depends on a uniqueness property (Theorem 7), without which we would
have to have infertype return a type L1 list of all the possible types.
Slide 58
Executing L1 in Moscow ML
L1 is essentially a fragment of Moscow ML ‚Äì given a typable L1
expression e and an initial store s, e can be executed in Moscow ML by
wrapping it
let val skip = ()
and l1 = ref n1
and l2 = ref n2
..
.
and lk = ref nk
in
e
end;
where s is the store {l1 7‚Üín1, ..., lk 7‚Üínk} and all locations that occur
in e are contained in {l1, ..., lk}.
(watch out for ‚àº1 and -1)
26

Slide 59
Why Not Types?
‚Ä¢ ‚ÄúI can‚Äôt write the code I want in this type system.‚Äù
(the Pascal complaint) usually false for a modern typed language
‚Ä¢ ‚ÄúIt‚Äôs too tiresome to get the types right throughout development.‚Äù
(the untyped-scripting-language complaint)
‚Ä¢ ‚ÄúType annotations are too verbose.‚Äù
type inference means you only have to write them where it‚Äôs useful
‚Ä¢ ‚ÄúType error messages are incomprehensible.‚Äù
hmm. Sadly, sometimes true.
‚Ä¢ ‚ÄúI really can‚Äôt write the code I want.‚Äù
Some languages build the type system into the syntax. Original FORTRAN, BASIC etc.
had typing built into variable names, with e.g. those beginning with I or J storing inte-
gers). Sometimes typing is built into the grammar, with e.g. separate grammatical classes
of expressions and commands. As the type systems become more expressive, however, they
quickly go beyond what can be captured in context-free grammars. They must then be
separated from lexing and parsing, both conceptually and in implementations.
27

2.3
L1: Collected deÔ¨Ånition
Syntax
Booleans b ‚ààB = {true, false}
Integers n ‚ààZ = {..., ‚àí1, 0, 1, ...}
Locations ‚Ñì‚ààL = {l, l0, l1, l2, ...}
Operations op ::= + |‚â•
Expressions
e
::=
n | b | e1 op e2 | if e1 then e2 else e3 |
‚Ñì:= e |!‚Ñì|
skip | e1; e2 |
while e1 do e2
Operational semantics
Note that for each construct there are some computation rules, doing ‚Äòreal work‚Äô, and some
context (or congruence) rules, allowing subcomputations and specifying their order.
Say stores s are Ô¨Ånite partial functions from L to Z. Say values v are expressions from the
grammar v ::= b | n | skip.
(op +)
‚ü®n1 + n2, s‚ü©‚àí‚Üí‚ü®n, s‚ü©
if n = n1 + n2
(op ‚â•)
‚ü®n1 ‚â•n2, s‚ü©‚àí‚Üí‚ü®b, s‚ü©
if b = (n1 ‚â•n2)
(op1)
‚ü®e1, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
1, s‚Ä≤‚ü©
‚ü®e1 op e2, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
1 op e2, s‚Ä≤‚ü©
(op2)
‚ü®e2, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
2, s‚Ä≤‚ü©
‚ü®v op e2, s‚ü©‚àí‚Üí‚ü®v op e‚Ä≤
2, s‚Ä≤‚ü©
(deref)
‚ü®!‚Ñì, s‚ü©‚àí‚Üí‚ü®n, s‚ü©
if ‚Ñì‚ààdom(s) and s(‚Ñì) = n
(assign1)
‚ü®‚Ñì:= n, s‚ü©‚àí‚Üí‚ü®skip, s + {‚Ñì7‚Üín}‚ü©
if ‚Ñì‚ààdom(s)
(assign2)
‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©
‚ü®‚Ñì:= e, s‚ü©‚àí‚Üí‚ü®‚Ñì:= e‚Ä≤, s‚Ä≤‚ü©
(seq1)
‚ü®skip; e2, s‚ü©‚àí‚Üí‚ü®e2, s‚ü©
(seq2)
‚ü®e1, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
1, s‚Ä≤‚ü©
‚ü®e1; e2, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
1; e2, s‚Ä≤‚ü©
(if1)
‚ü®if true then e2 else e3, s‚ü©‚àí‚Üí‚ü®e2, s‚ü©
(if2)
‚ü®if false then e2 else e3, s‚ü©‚àí‚Üí‚ü®e3, s‚ü©
(if3)
‚ü®e1, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
1, s‚Ä≤‚ü©
‚ü®if e1 then e2 else e3, s‚ü©‚àí‚Üí‚ü®if e‚Ä≤
1 then e2 else e3, s‚Ä≤‚ü©
(while)
‚ü®while e1 do e2, s‚ü©‚àí‚Üí‚ü®if e1 then (e2; while e1 do e2) else skip, s‚ü©
28

Typing
Types of expressions:
T
::=
int | bool | unit
Types of locations:
Tloc
::=
intref
Write T and Tloc for the sets of all terms of these grammars.
Let Œì range over TypeEnv, the Ô¨Ånite partial functions from locations L to Tloc.
(int)
Œì ‚ä¢n:int
for n ‚ààZ
(bool)
Œì ‚ä¢b:bool
for b ‚àà{true, false}
(op +)
Œì ‚ä¢e1:int
Œì ‚ä¢e2:int
Œì ‚ä¢e1 + e2:int
(op ‚â•)
Œì ‚ä¢e1:int
Œì ‚ä¢e2:int
Œì ‚ä¢e1 ‚â•e2:bool
(if)
Œì ‚ä¢e1:bool
Œì ‚ä¢e2:T
Œì ‚ä¢e3:T
Œì ‚ä¢if e1 then e2 else e3:T
(assign)
Œì(‚Ñì) = intref
Œì ‚ä¢e:int
Œì ‚ä¢‚Ñì:= e:unit
(deref)
Œì(‚Ñì) = intref
Œì ‚ä¢!‚Ñì:int
(skip)
Œì ‚ä¢skip:unit
(seq)
Œì ‚ä¢e1:unit
Œì ‚ä¢e2:T
Œì ‚ä¢e1; e2:T
(while)
Œì ‚ä¢e1:bool
Œì ‚ä¢e2:unit
Œì ‚ä¢while e1 do e2:unit
29

2.4
Exercises
Exercise 1 ‚ãÜWrite a program to compute the factorial of the integer initially in location
l1. Take care to ensure that your program really is an expression in L1.
Exercise 2 ‚ãÜGive full derivations of all the reduction steps of
‚ü®(l0 := 7); (l1 := (!l0 + 2)), {l0 7‚Üí0, l1 7‚Üí0}‚ü©
Exercise 3 ‚ãÜGive full derivations of the Ô¨Årst four reduction steps of the ‚ü®e, s‚ü©of the Ô¨Årst
L1 example on Slide 15.
Exercise 4 ‚ãÜAdapt the implementation code to correspond to the two rules (op1b) and
(op2b) on Slide 37. Give some test cases that distinguish between the original and the new
semantics.
Exercise 5 ‚ãÜAdapt the implementation code to correspond to the two rules (assign1‚Äô) and
(seq1‚Äô) on Slide 38. Give some test cases that distinguish between the original and the new
semantics.
Exercise 6 ‚ãÜ‚ãÜFix the L1 semantics to match the implementation, taking care with the
representation of integers.
Exercise 7 ‚ãÜGive a type derivation for (l0 := 7); (l1 := (!l0+2)) with Œì = l0:intref, l1:intref.
Exercise 8 ‚ãÜGive a type derivation for e on Slide 25 with Œì = l1:intref, l2:intref, l3:intref .
Exercise 9 ‚ãÜDoes Type Preservation hold for the variant language with rules (assign1‚Äô)
and (seq1‚Äô)? on Slide 38? If not, give an example, and show how the type rules could be
adjusted to make it true.
Exercise 10 ‚ãÜAdapt the type inference implementation to match your revised type system
from Exercise 9.
Exercise 11 ‚ãÜCheck whether mosml, the L1 implementation and the L1 semantics agree
on the order of evaluation for operators and sequencing.
30

3
Induction
Key concepts in this chapter:
‚Ä¢ Structural induction
‚Ä¢ Rule induction
Slide 60
Induction
Slide 61
We‚Äôve stated several ‚Äòtheorems‚Äô, but how do we know they are true?
Intuition is often wrong ‚Äì we need proof.
Use proof process also for strengthening our intuition about subtle
language features, and for debugging deÔ¨Ånitions ‚Äì it helps you examine all
the various cases.
Most of our deÔ¨Ånitions are inductive. To prove things about them, we need
the corresponding induction principles.
Slide 62
Three forms of induction
Prove facts about all natural numbers by mathematical induction.
Prove facts about all terms of a grammar (e.g. the L1 expressions) by
structural induction.
Prove facts about all elements of a relation deÔ¨Åned by rules (e.g. the L1
transition relation, or the L1 typing relation) by rule induction.
We shall see that all three boil down to induction over certain trees.
Slide 63
Principle of Mathematical Induction
For any property Œ¶(x) of natural numbers x ‚ààN = {0, 1, 2, ...}, to
prove
‚àÄx ‚ààN.Œ¶(x)
it‚Äôs enough to prove
Œ¶(0) and ‚àÄx ‚ààN.Œ¶(x) ‚áíŒ¶(x + 1).
i.e.
 Œ¶(0) ‚àß(‚àÄx ‚ààN.Œ¶(x) ‚áíŒ¶(x + 1))

‚áí‚àÄx ‚ààN.Œ¶(x)
(NB, the natural numbers include 0)
31

Slide 64
 Œ¶(0) ‚àß(‚àÄx ‚ààN.Œ¶(x) ‚áíŒ¶(x + 1))

‚áí‚àÄx ‚ààN.Œ¶(x)
For example, to prove
Theorem 8 1 + 2 + ... + x = 1/2 ‚àóx ‚àó(x + 1)
use mathematical induction for
Œ¶(x) = (1 + 2 + ... + x = 1/2 ‚àóx ‚àó(x + 1))
There‚Äôs a model proof in the notes, as an example of good style. Writing a
clear proof structure like this becomes essential when things get more
complex ‚Äì you have to use the formalism to help you get things right.
Emulate it!
Theorem 8 1 + 2 + ... + x = 1/2 ‚àóx ‚àó(x + 1) .
I have annotated the proof to say what‚Äôs going on.
Proof
We prove ‚àÄx.Œ¶(x), where
(state Œ¶ explicitly)
Œ¶(x)
def
=
(1 + 2 + ... + x = 1/2 ‚àóx ‚àó(x + 1))
by mathematical induction
(state the induction principle you‚Äôre using)
.
(Now show each conjunct of the premise of the induction principle)
Base case:
(conjunct Œ¶(0) )
Œ¶(0) is
(instantiate Œ¶)
(1 + ... + 0 = 1/2 ‚àó0 ‚àó(0 + 1)), which holds as both sides are equal to 0.
Inductive step:
(conjunct ‚àÄx ‚ààN.Œ¶(x) ‚áíŒ¶(x + 1) )
Consider an arbitrary k ‚ààN
(it‚Äôs a universal (‚àÄ), so consider an arbitrary one).
Suppose Œ¶(k)
(to show the implication Œ¶(k) ‚áíŒ¶(k + 1), assume the premise and try to
show the conclusion).
We have to show Œ¶(k + 1), i.e.
(state what we have to show explicitly)
(1 + 2 + ... + (k + 1)) = 1/2 ‚àó(k + 1) ‚àó((k + 1) + 1)
Now, the left hand side is
(1 + 2 + ... + (k + 1))
=
(1 + 2 + ... + k) + (k + 1)
(rearranging)
=
(1/2 ‚àók ‚àó(k + 1)) + (k + 1)
(using Œ¶(k) )
(say where you use the ‚Äòinduction hypothesis‚Äô assumption Œ¶(k) made above)
and the right hand side is (rearranging)
1/2 ‚àó(k + 1) ‚àó((k + 1) + 1)
=
1/2 ‚àó(k ‚àó(k + 1) + (k + 1) ‚àó1 + 1 ‚àók + 1)
=
1/2 ‚àók ‚àó(k + 1) + 1/2 ‚àó((k + 1) + k + 1)
=
1/2 ‚àók ‚àó(k + 1) + (k + 1)
which is equal to the LHS.
‚ñ°
32

3.1
Abstract Syntax and Structural Induction
Slide 65
Abstract Syntax and Structural Induction
How to prove facts about all expressions, e.g. Determinacy for L1?
Theorem 1 (Determinacy) If ‚ü®e, s‚ü©‚àí‚Üí‚ü®e1, s1‚ü©and
‚ü®e, s‚ü©‚àí‚Üí‚ü®e2, s2‚ü©then ‚ü®e1, s1‚ü©= ‚ü®e2, s2‚ü©.
First, don‚Äôt forget the elided universal quantiÔ¨Åers.
Theorem 1 (Determinacy) For all e, s, e1, s1, e2, s2, if
‚ü®e, s‚ü©‚àí‚Üí‚ü®e1, s1‚ü©and ‚ü®e, s‚ü©‚àí‚Üí‚ü®e2, s2‚ü©then ‚ü®e1, s1‚ü©= ‚ü®e2, s2‚ü©.
Slide 66
Abstract Syntax
Then, have to pay attention to what an expression is.
Recall we said:
e
::=
n | b | e op e | if e then e else e |
‚Ñì:= e |!‚Ñì|
skip | e; e |
while e do e
deÔ¨Åning a set of expressions.
Slide 67
Q: Is an expression, e.g. if !l ‚â•0 then skip else (skip; l := 0):
1. a list of characters [‚Äòi‚Äô, ‚Äòf‚Äô, ‚Äò ‚Äô, ‚Äò!‚Äô, ‚Äòl‚Äô, ..];
2. a list of tokens
[ IF, DEREF, LOC "l", GTEQ, ..]; or
3. an abstract syntax tree?
if then else
‚â•
t
t
t
t
t
t
skip
;
‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº
!l
‚úå‚úå‚úå
0
skip l :=
‚ùÉ‚ùÉ‚ùÉ‚ùÉ‚ùÉ
0
Slide 68
A: an abstract syntax tree. Hence: 2 + 2 Ã∏= 4
+
2
‚úå‚úå‚úå
2
‚ú∂‚ú∂‚ú∂
4
1 + 2 + 3 ‚Äì ambiguous
(1 + 2) + 3 Ã∏= 1 + (2 + 3)
+
+
‚òõ‚òõ‚òõ
3
‚ú∂‚ú∂‚ú∂
1
‚úå‚úå‚úå
2
‚ú∏‚ú∏‚ú∏
+
1
‚úå‚úå‚úå
+
‚ú∏‚ú∏‚ú∏
2
‚òõ‚òõ‚òõ
3
‚ú∂‚ú∂‚ú∂
Parentheses are only used for disambiguation ‚Äì they are not part of the
grammar. 1 + 2 = (1 + 2) = ((1 + 2)) = (((((1)))) + ((2)))
33

For semantics we don‚Äôt want to be distracted by concrete syntax ‚Äì it‚Äôs easiest to work
with abstract syntax trees, which for this grammar are Ô¨Ånite trees, with ordered branches,
labelled as follows:
‚Ä¢ leaves (nullary nodes) labelled by B ‚à™Z ‚à™({!} ‚àóL) ‚à™{skip} = {true, false, skip} ‚à™
{..., ‚àí1, 0, 1, ...} ‚à™{!l, !l1, !l2, ...}.
‚Ä¢ unary nodes labelled by {l :=, l1 :=, l2 :=, ...}
‚Ä¢ binary nodes labelled by {+, ‚â•, ; , while do }
‚Ä¢ ternary nodes labelled by {if then else }
Abstract grammar suggests a concrete syntax ‚Äì we write expressions as strings just for
convenience, using parentheses to disambiguate where required and inÔ¨Åx notation, but really
mean trees.
Slide 69
Principle of Structural Induction (for abstract syntax)
For any property Œ¶(e) of expressions e, to prove
‚àÄe ‚ààL1.Œ¶(e)
it‚Äôs enough to prove for each tree constructor c (taking k ‚â•0 arguments)
that if Œ¶ holds for the subtrees e1, .., ek then Œ¶ holds for the tree
c(e1, .., ek). i.e.
 ‚àÄc.‚àÄe1, .., ek.(Œ¶(e1) ‚àß... ‚àßŒ¶(ek)) ‚áíŒ¶(c(e1, .., ek))

‚áí‚àÄe.Œ¶(e)
where the tree constructors (or node labels) c are n, true, false, !l, skip,
l :=, while do , if then else , etc.
Slide 70
In particular, for L1: to show ‚àÄe ‚ààL1.Œ¶(e) it‚Äôs enough to show:
nullary:
Œ¶(skip)
‚àÄb ‚àà{true, false}.Œ¶(b)
‚àÄn ‚ààZ.Œ¶(n)
‚àÄ‚Ñì‚ààL.Œ¶(!‚Ñì)
unary:
‚àÄ‚Ñì‚ààL.‚àÄe.Œ¶(e) ‚áíŒ¶(‚Ñì:= e)
binary:
‚àÄop .‚àÄe1, e2.(Œ¶(e1) ‚àßŒ¶(e2)) ‚áíŒ¶(e1 op e2)
‚àÄe1, e2.(Œ¶(e1) ‚àßŒ¶(e2)) ‚áíŒ¶(e1; e2)
‚àÄe1, e2.(Œ¶(e1) ‚àßŒ¶(e2)) ‚áíŒ¶(while e1 do e2)
ternary:
‚àÄe1, e2, e3.(Œ¶(e1) ‚àßŒ¶(e2) ‚àßŒ¶(e3)) ‚áíŒ¶(if e1 then e2 else e3)
(See how this comes directly from the grammar)
Slide 71
Proving Determinacy (Outline)
Theorem 1 (Determinacy) If ‚ü®e, s‚ü©‚àí‚Üí‚ü®e1, s1‚ü©and
‚ü®e, s‚ü©‚àí‚Üí‚ü®e2, s2‚ü©then ‚ü®e1, s1‚ü©= ‚ü®e2, s2‚ü©.
Take
Œ¶(e)
def
=
‚àÄs, e‚Ä≤, s‚Ä≤, e‚Ä≤‚Ä≤, s‚Ä≤‚Ä≤.
(‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©‚àß‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤‚Ä≤, s‚Ä≤‚Ä≤‚ü©)
‚áí‚ü®e‚Ä≤, s‚Ä≤‚ü©= ‚ü®e‚Ä≤‚Ä≤, s‚Ä≤‚Ä≤‚ü©
and show ‚àÄe ‚ààL1.Œ¶(e) by structural induction.
To do that we need to verify all the premises of the principle of structural induction ‚Äì the
formulae in the second box below ‚Äì for this Œ¶.
34

Slide 72
Œ¶(e)
def
=
‚àÄs, e‚Ä≤, s‚Ä≤, e‚Ä≤‚Ä≤, s‚Ä≤‚Ä≤.
(‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©‚àß‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤‚Ä≤, s‚Ä≤‚Ä≤‚ü©)
‚áí‚ü®e‚Ä≤, s‚Ä≤‚ü©= ‚ü®e‚Ä≤‚Ä≤, s‚Ä≤‚Ä≤‚ü©
nullary:
Œ¶(skip)
‚àÄb ‚àà{true, false}.Œ¶(b)
‚àÄn ‚ààZ.Œ¶(n)
‚àÄ‚Ñì‚ààL.Œ¶(!‚Ñì)
unary:
‚àÄ‚Ñì‚ààL.‚àÄe.Œ¶(e) ‚áíŒ¶(‚Ñì:= e)
binary:
‚àÄop .‚àÄe1, e2.(Œ¶(e1) ‚àßŒ¶(e2)) ‚áíŒ¶(e1 op e2)
‚àÄe1, e2.(Œ¶(e1) ‚àßŒ¶(e2)) ‚áíŒ¶(e1; e2)
‚àÄe1, e2.(Œ¶(e1) ‚àßŒ¶(e2)) ‚áíŒ¶(while e1 do e2)
ternary:
‚àÄe1, e2, e3.(Œ¶(e1) ‚àßŒ¶(e2) ‚àßŒ¶(e3)) ‚áíŒ¶(if e1 then e2 else e3)
We will come back later to look at some of these details.
3.2
Inductive DeÔ¨Ånitions and Rule Induction
Slide 73
Inductive DeÔ¨Ånitions and Rule Induction
How to prove facts about all elements of the L1 typing relation or the L1
reduction relation, e.g. Progress or Type Preservation?
Theorem 2 (Progress) If Œì ‚ä¢e:T and dom(Œì) ‚äÜdom(s) then either e
is a value or there exist e‚Ä≤, s‚Ä≤ such that ‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©.
Theorem 3 (Type Preservation) If Œì ‚ä¢e:T and dom(Œì) ‚äÜdom(s)
and ‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©then Œì ‚ä¢e‚Ä≤:T and dom(Œì) ‚äÜdom(s‚Ä≤).
What does ‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©really mean?
Slide 74
Inductive DeÔ¨Ånitions
We deÔ¨Åned the transition relation ‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©and the typing
relation Œì ‚ä¢e:T by giving some rules, eg
(op +)
‚ü®n1 + n2, s‚ü©‚àí‚Üí‚ü®n, s‚ü©
if n = n1 + n2
(op1)
‚ü®e1, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
1, s‚Ä≤‚ü©
‚ü®e1 op e2, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
1 op e2, s‚Ä≤‚ü©
(op +)
Œì ‚ä¢e1:int
Œì ‚ä¢e2:int
Œì ‚ä¢e1 + e2:int
What did we actually mean?
35

Slide 75
These relations are just normal set-theoretic relations, written in inÔ¨Åx
notation.
For the transition relation:
‚Ä¢ Start with A = L1 ‚àóstore ‚àóL1 ‚àóstore.
‚Ä¢ Write ‚àí‚Üí‚äÜA inÔ¨Åx, e.g. ‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©instead of
(e, s, e‚Ä≤, s‚Ä≤) ‚àà‚àí‚Üí.
For the typing relation:
‚Ä¢ Start with A = TypeEnv ‚àóL1 ‚àótypes.
‚Ä¢ Write ‚ä¢‚äÜA mixÔ¨Åx, e.g. Œì ‚ä¢e:T instead of (Œì, e, T) ‚àà‚ä¢.
Slide 76
For each rule we can construct the set of all concrete rule instances,
taking all values of the metavariables that satisfy the side condition. For
example, for (op + ) and (op1) we take all values of n1, n2, s, n
(satisfying n = n1 + n2) and of e1, e2, s, e‚Ä≤
1, s‚Ä≤.
(op+ )
‚ü®2 + 2, {}‚ü©‚àí‚Üí‚ü®4, {}‚ü©,
(op + )
‚ü®2 + 3, {}‚ü©‚àí‚Üí‚ü®5, {}‚ü©, ...
(op1)
‚ü®2 + 2, {}‚ü©‚àí‚Üí‚ü®4, {}‚ü©
‚ü®(2 + 2) + 3, {}‚ü©‚àí‚Üí‚ü®4 + 3, {}‚ü©,
(op1)
‚ü®2 + 2, {}‚ü©‚àí‚Üí‚ü®false, {}‚ü©
‚ü®(2 + 2) + 3, {}‚ü©‚àí‚Üí‚ü®false + 3, {}‚ü©
Note the last has a premise that is not itself derivable, but nonetheless this is a legitimate
instance of (op1).
Slide 77
Now a derivation of a transition ‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©or typing judgment
Œì ‚ä¢e:T is a Ô¨Ånite tree such that each step is a concrete rule instance.
‚ü®2 + 2, {}‚ü©‚àí‚Üí‚ü®4, {}‚ü©
(op+)
‚ü®(2 + 2) + 3, {}‚ü©‚àí‚Üí‚ü®4 + 3, {}‚ü©
(op1)
‚ü®(2 + 2) + 3 ‚â•5, {}‚ü©‚àí‚Üí‚ü®4 + 3 ‚â•5, {}‚ü©
(op1)
Œì ‚ä¢!l:int (deref)
Œì ‚ä¢2:int (int)
Œì ‚ä¢(!l + 2):int
(op +)
Œì ‚ä¢3:int (int)
Œì ‚ä¢(!l + 2) + 3:int
(op +)
and ‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©is an element of the reduction relation
(resp. Œì ‚ä¢e:T is an element of the transition relation) iff there is a
derivation with that as the root node.
Now, to prove something about an inductively-deÔ¨Åned set, we use rule induction.
Slide 78
Principle of Rule Induction
For any property Œ¶(a) of elements a of A, and any set of rules which
deÔ¨Åne a subset SR of A, to prove
‚àÄa ‚ààSR.Œ¶(a)
it‚Äôs enough to prove that {a | Œ¶(a)} is closed under the rules, ie for each
concrete rule instance
h1
..
hk
c
if Œ¶(h1) ‚àß... ‚àßŒ¶(hk) then Œ¶(c).
36

For some proofs a slightly diÔ¨Äerent principle is useful ‚Äì this variant allows you to assume
each of the hi are themselves members of SR.
Slide 79
Principle of rule induction (a slight variant)
For any property Œ¶(a) of elements a of A, and any set of rules which
inductively deÔ¨Åne the set SR, to prove
‚àÄa ‚ààSR.Œ¶(a)
it‚Äôs enough to prove that
for each concrete rule instance
h1
..
hk
c
if Œ¶(h1) ‚àß... ‚àßŒ¶(hk) ‚àßh1 ‚ààSR ‚àß.. ‚àßhk ‚ààSR then Œ¶(c).
(This is just the original principle for the property (Œ¶(a) ‚àßa ‚ààSR).)
Slide 80
Proving Progress (Outline)
Theorem 2 (Progress) If Œì ‚ä¢e:T and dom(Œì) ‚äÜdom(s) then either e
is a value or there exist e‚Ä≤, s‚Ä≤ such that ‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©.
Proof Take
Œ¶(Œì, e, T)
def
= ‚àÄs. dom(Œì) ‚äÜdom(s) ‚áí
value(e) ‚à®(‚àÉe‚Ä≤, s‚Ä≤.‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©)
We show that for all Œì, e, T , if Œì ‚ä¢e:T then Œ¶(Œì, e, T), by rule
induction on the deÔ¨Ånition of ‚ä¢.
Slide 81
Principle of Rule Induction (variant form): to prove Œ¶(a) for all a in the
set SR, it‚Äôs enough to prove that for each concrete rule instance
h1
..
hk
c
if Œ¶(h1) ‚àß... ‚àßŒ¶(hk) ‚àßh1 ‚ààSR ‚àß.. ‚àßhk ‚ààSR then Œ¶(c).
Instantiating to the L1 typing rules, have to show:
(int)
‚àÄŒì, n.Œ¶(Œì, n, int)
(deref)
‚àÄŒì, ‚Ñì.Œì(‚Ñì) = intref ‚áíŒ¶(Œì, !‚Ñì, int)
(op +)
‚àÄŒì, e1, e2.(Œ¶(Œì, e1, int) ‚àßŒ¶(Œì, e2, int) ‚àßŒì ‚ä¢e1:int ‚àßŒì ‚ä¢e2:int)
‚áíŒ¶(Œì, e1 + e2, int)
(seq)
‚àÄŒì, e1, e2, T.(Œ¶(Œì, e1, unit) ‚àßŒ¶(Œì, e2, T) ‚àßŒì ‚ä¢e1:unit ‚àßŒì ‚ä¢e2:T)
‚áíŒ¶(Œì, e1; e2, T)
etc.
Slide 82
Having proved those 10 things, consider an example
Œì ‚ä¢(!l + 2) + 3:int. To see why Œ¶(Œì, (!l + 2) + 3, int) holds:
Œì ‚ä¢!l:int (deref)
Œì ‚ä¢2:int (int)
Œì ‚ä¢(!l + 2):int
(op +)
Œì ‚ä¢3:int (int)
Œì ‚ä¢(!l + 2) + 3:int
(op +)
37

Slide 83
Which Induction Principle to Use?
Which of these induction principles to use is a matter of convenience ‚Äì
you want to use an induction principle that matches the deÔ¨Ånitions you‚Äôre
working with.
For completeness, observe the following:
Mathematical induction over N is essentially the same as structural induction over n ::= zero |
succ (n).
Instead of using structural induction (for an arbitrary grammar), you could use mathematical
induction on the size of terms.
Instead of using structural induction, you could use rule induction: supposing some Ô¨Åxed
set of tree node labels (e.g. all the character strings), take A to be the set of all trees with
those labels, and consider each clause of your grammar (e.g.e ::= ... | e + e) to be a rule
e
e
e + e
3.3
Example proofs
Slide 84
Example Proofs
In the notes there are detailed example proofs for Determinacy (structural
induction), Progress (rule induction on type derivations), and Type
Preservation (rule induction on reduction derivations).
You should read them off-line, and do the exercises.
Slide 85
When is a proof a proof?
What‚Äôs a proof?
Formal: a derivation in formal logic (e.g. a big natural deduction proof
tree). Often far too verbose to deal with by hand (but can
machine-check such things).
Informal but rigorous: an argument to persuade the reader that, if
pushed, you could write a fully formal proof (the usual mathematical
notion, e.g. those we just did). Have to learn by practice to see when
they are rigorous.
Bogus: neither of the above.
Remember ‚Äì the point is to use the mathematics to help you think about things that are too
complex to keep in your head all at once: to keep track of all the cases etc. To do that, and
to communicate with other people, it‚Äôs important to write down the reasoning and proof
structure as clearly as possible. After you‚Äôve done a proof you should give it to someone
(your supervision partner Ô¨Årst, perhaps) to see if they (a) can understand what you‚Äôve said,
and (b) if they believe it.
Slide 86
Sometimes it seems hard or pointless to prove things because they seem
‚Äòtoo obvious‚Äô....
1. proof lets you see (and explain) why they are obvious
2. sometimes the obvious facts are false...
3. sometimes the obvious facts are not obvious at all
4. sometimes a proof contains or suggests an algorithm that you need ‚Äì
eg, proofs that type inference is decidable (for fancier type systems)
38

Theorem 1 (Determinacy) If ‚ü®e, s‚ü©‚àí‚Üí‚ü®e1, s1‚ü©and ‚ü®e, s‚ü©‚àí‚Üí‚ü®e2, s2‚ü©then ‚ü®e1, s1‚ü©=
‚ü®e2, s2‚ü©.
Proof
Take
Œ¶(e)
def
=
‚àÄs, e‚Ä≤, s‚Ä≤, e‚Ä≤‚Ä≤, s‚Ä≤‚Ä≤.(‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©‚àß‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤‚Ä≤, s‚Ä≤‚Ä≤‚ü©) ‚áí‚ü®e‚Ä≤, s‚Ä≤‚ü©= ‚ü®e‚Ä≤‚Ä≤, s‚Ä≤‚Ä≤‚ü©
We show ‚àÄe ‚ààL1.Œ¶(e) by structural induction.
Cases skip, b, n. For e of these forms there are no rules with a conclusion of the form
‚ü®e, ...‚ü©‚àí‚Üí‚ü®.., ..‚ü©so the left hand side of the implication cannot hold, so the
implication is true.
Case !‚Ñì. Take arbitrary s, e‚Ä≤, s‚Ä≤, e‚Ä≤‚Ä≤, s‚Ä≤‚Ä≤ such that ‚ü®!‚Ñì, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©‚àß‚ü®!‚Ñì, s‚ü©‚àí‚Üí‚ü®e‚Ä≤‚Ä≤, s‚Ä≤‚Ä≤‚ü©.
The only rule which could be applicable is (deref), in which case, for those tran-
sitions to be instances of the rule we must have
‚Ñì‚ààdom(s)
‚Ñì‚ààdom(s)
e‚Ä≤ = s(‚Ñì)
e‚Ä≤‚Ä≤ = s(‚Ñì)
s‚Ä≤ = s
s‚Ä≤‚Ä≤ = s
so e‚Ä≤ = e‚Ä≤‚Ä≤ and s‚Ä≤ = s‚Ä≤‚Ä≤.
Case ‚Ñì:= e. Suppose Œ¶(e) (then we have to show Œ¶(‚Ñì:= e)).
Take arbitrary s, e‚Ä≤, s‚Ä≤, e‚Ä≤‚Ä≤, s‚Ä≤‚Ä≤ such that ‚ü®‚Ñì:= e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©‚àß‚ü®‚Ñì:= e, s‚ü©‚àí‚Üí
‚ü®e‚Ä≤‚Ä≤, s‚Ä≤‚Ä≤‚ü©.
It‚Äôs handy to have this lemma:
Lemma 9 For all e
‚àà
L1, if e is a value then ‚àÄs.¬¨ ‚àÉe‚Ä≤, s‚Ä≤.‚ü®e, s‚ü©‚àí‚Üí
‚ü®e‚Ä≤, s‚Ä≤‚ü©.
Proof
By defn e is a value if it is of one of the forms n, b, skip. By
examination of the rules on slides ..., there is no rule with conclusion
of the form ‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©for e one of n, b, skip.
‚ñ°
The only rules which could be applicable, for each of the two transitions, are
(assign1) and (assign2).
case ‚ü®‚Ñì:= e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©is an instance of (assign1). Then for some n we have
e = n and ‚Ñì‚ààdom(s) and e‚Ä≤ = skip and s‚Ä≤ = s + {‚Ñì7‚Üín}.
case ‚ü®‚Ñì:= n, s‚ü©‚àí‚Üí‚ü®e‚Ä≤‚Ä≤, s‚Ä≤‚Ä≤‚ü©is an instance of (assign1) (note we are using
the fact that e = n here). Then e‚Ä≤‚Ä≤ = skip and s‚Ä≤‚Ä≤ = s + {‚Ñì7‚Üín} so
‚ü®e‚Ä≤, s‚Ä≤‚ü©= ‚ü®e‚Ä≤‚Ä≤, s‚Ä≤‚Ä≤‚ü©as required.
case ‚ü®‚Ñì:= e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤‚Ä≤, s‚Ä≤‚Ä≤‚ü©is an instance of (assign2). Then ‚ü®n, s‚ü©‚àí‚Üí
‚ü®e‚Ä≤‚Ä≤, s‚Ä≤‚Ä≤‚ü©, which contradicts the lemma, so this case cannot arise.
case ‚ü®‚Ñì:= e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©is an instance of (assign2). Then for some e‚Ä≤
1 we have
‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
1, s‚Ä≤‚ü©(*) and e‚Ä≤ = (‚Ñì:= e‚Ä≤
1).
case ‚ü®‚Ñì:= e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤‚Ä≤, s‚Ä≤‚Ä≤‚ü©is an instance of (assign1). Then for some n we
have e = n, which contradicts the lemma, so this case cannot arise.
case ‚ü®‚Ñì:= e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤‚Ä≤, s‚Ä≤‚Ä≤‚ü©is an instance of (assign2).
Then for some
e‚Ä≤‚Ä≤
1 we have ‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤‚Ä≤
1 , s‚Ä≤‚Ä≤‚ü©(**) and e‚Ä≤‚Ä≤ = (‚Ñì:= e‚Ä≤‚Ä≤
1 ). Now, by the
induction hypothesis Œ¶(e), (*) and (**) we have ‚ü®e‚Ä≤
1, s‚Ä≤‚ü©= ‚ü®e‚Ä≤‚Ä≤
1 , s‚Ä≤‚Ä≤‚ü©, so
‚ü®e‚Ä≤, s‚Ä≤‚ü©= ‚ü®‚Ñì:= e‚Ä≤
1, s‚Ä≤‚ü©= ‚ü®‚Ñì:= e‚Ä≤‚Ä≤
1 , s‚Ä≤‚Ä≤‚ü©= ‚ü®e‚Ä≤‚Ä≤, s‚Ä≤‚Ä≤‚ü©as required.
Case e1 op e2. Suppose Œ¶(e1) and Œ¶(e2).
Take arbitrary s, e‚Ä≤, s‚Ä≤, e‚Ä≤‚Ä≤, s‚Ä≤‚Ä≤ such that ‚ü®e1 op e2, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©‚àß‚ü®e1 op e2, s‚ü©‚àí‚Üí
‚ü®e‚Ä≤‚Ä≤, s‚Ä≤‚Ä≤‚ü©.
39

By examining the expressions in the left-hand-sides of the conclusions of the rules,
and using the lemma above, the only possibilities are those below (you should
check why this is so for yourself).
case
op
= + and ‚ü®e1 + e2, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©is an instance of (op+) and ‚ü®e1 +
e2, s‚ü©‚àí‚Üí‚ü®e‚Ä≤‚Ä≤, s‚Ä≤‚Ä≤‚ü©is an instance of (op+ ).
Then for some n1, n2 we have e1 = n1, e2 = n2, e‚Ä≤ = n3 = e‚Ä≤‚Ä≤ for n3 = n1+n2,
and s‚Ä≤ = s = s‚Ä≤‚Ä≤.
case
op
=‚â•and ‚ü®e1 ‚â•e2, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©is an instance of (op‚â•) and ‚ü®e1 ‚â•
e2, s‚ü©‚àí‚Üí‚ü®e‚Ä≤‚Ä≤, s‚Ä≤‚Ä≤‚ü©is an instance of (op‚â•).
Then for some n1, n2 we have e1 = n1, e2 = n2, e‚Ä≤ = b = e‚Ä≤‚Ä≤ for b = (n1 ‚â•n2),
and s‚Ä≤ = s = s‚Ä≤‚Ä≤.
case ‚ü®e1
op
e2, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©is an instance of (op1) and ‚ü®e1
op
e2, s‚ü©‚àí‚Üí
‚ü®e‚Ä≤‚Ä≤, s‚Ä≤‚Ä≤‚ü©is an instance of (op1).
Then for some e‚Ä≤
1 and e‚Ä≤‚Ä≤
1 we have ‚ü®e1, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
1, s‚Ä≤‚ü©(*), ‚ü®e1, s‚ü©‚àí‚Üí‚ü®e‚Ä≤‚Ä≤
1 , s‚Ä≤‚Ä≤‚ü©
(**), e‚Ä≤ = e‚Ä≤
1 op e2, and e‚Ä≤‚Ä≤ = e‚Ä≤‚Ä≤
1 op e2. Now, by the induction hypothesis
Œ¶(e1), (*) and (**) we have ‚ü®e‚Ä≤
1, s‚Ä≤‚ü©= ‚ü®e‚Ä≤‚Ä≤
1 , s‚Ä≤‚Ä≤‚ü©, so ‚ü®e‚Ä≤, s‚Ä≤‚ü©= ‚ü®e‚Ä≤
1 op e2, s‚Ä≤‚ü©=
‚ü®e‚Ä≤‚Ä≤
1 op e2, s‚Ä≤‚Ä≤‚ü©= ‚ü®e‚Ä≤‚Ä≤, s‚Ä≤‚Ä≤‚ü©as required.
case ‚ü®e1
op
e2, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©is an instance of (op2) and ‚ü®e1
op
e2, s‚ü©‚àí‚Üí
‚ü®e‚Ä≤‚Ä≤, s‚Ä≤‚Ä≤‚ü©is an instance of (op2).
Similar, save that we use the induction hypothesis Œ¶(e2).
Case e1; e2. Suppose Œ¶(e1) and Œ¶(e2).
Take arbitrary s, e‚Ä≤, s‚Ä≤, e‚Ä≤‚Ä≤, s‚Ä≤‚Ä≤ such that ‚ü®e1; e2, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©‚àß‚ü®e1; e2, s‚ü©‚àí‚Üí
‚ü®e‚Ä≤‚Ä≤, s‚Ä≤‚Ä≤‚ü©.
By examining the expressions in the left-hand-sides of the conclusions of the rules,
and using the lemma above, the only possibilities are those below.
case e1 = skip and both transitions are instances of (seq1).
Then ‚ü®e‚Ä≤, s‚Ä≤‚ü©= ‚ü®e2, s‚ü©= ‚ü®e‚Ä≤‚Ä≤, s‚Ä≤‚Ä≤‚ü©.
case e1 is not a value and both transitions are instances of (seq2). Then for some
e‚Ä≤
1 and e‚Ä≤‚Ä≤
1 we have ‚ü®e1, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
1, s‚Ä≤‚ü©(*), ‚ü®e1, s‚ü©‚àí‚Üí‚ü®e‚Ä≤‚Ä≤
1 , s‚Ä≤‚Ä≤‚ü©(**), e‚Ä≤ = e‚Ä≤
1; e2,
and e‚Ä≤‚Ä≤ = e‚Ä≤‚Ä≤
1 ; e2
Then by the induction hypothesis Œ¶(e1) we have ‚ü®e‚Ä≤
1, s‚Ä≤‚ü©= ‚ü®e‚Ä≤‚Ä≤
1 , s‚Ä≤‚Ä≤‚ü©, so
‚ü®e‚Ä≤, s‚Ä≤‚ü©= ‚ü®e‚Ä≤
1; e2, s‚Ä≤‚ü©= ‚ü®e‚Ä≤‚Ä≤
1 ; e2, s‚Ä≤‚Ä≤‚ü©= ‚ü®e‚Ä≤‚Ä≤, s‚Ä≤‚Ä≤‚ü©as required.
Case while e1 do e2. Suppose Œ¶(e1) and Œ¶(e2).
Take arbitrary s, e‚Ä≤, s‚Ä≤, e‚Ä≤‚Ä≤, s‚Ä≤‚Ä≤ such that ‚ü®while
e1
do
e2, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©‚àß
‚ü®while e1 do e2, s‚ü©‚àí‚Üí‚ü®e‚Ä≤‚Ä≤, s‚Ä≤‚Ä≤‚ü©.
By examining the expressions in the left-hand-sides of the conclusions of the rules
both must be instances of (while), so ‚ü®e‚Ä≤, s‚Ä≤‚ü©= ‚ü®if e1 then (e2; while e1 do e2) else skip, s‚ü©=
‚ü®e‚Ä≤‚Ä≤, s‚Ä≤‚Ä≤‚ü©.
Case if e1 then e2 else e3. Suppose Œ¶(e1), Œ¶(e2) and Œ¶(e3).
Take arbitrary s, e‚Ä≤, s‚Ä≤, e‚Ä≤‚Ä≤, s‚Ä≤‚Ä≤ such that ‚ü®if e1 then e2 else e3, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©‚àß
‚ü®if e1 then e2 else e3, s‚ü©‚àí‚Üí‚ü®e‚Ä≤‚Ä≤, s‚Ä≤‚Ä≤‚ü©.
By examining the expressions in the left-hand-sides of the conclusions of the rules,
and using the lemma above, the only possibilities are those below.
case e1 = true and both transitions are instances of (if1).
case e1 = false and both transitions are instances of (if2).
40

case e1 is not a value and both transitions are instances of (if3).
The Ô¨Årst two cases are immediate; the last uses Œ¶(e1).
‚ñ°
(check we‚Äôve done all the cases!)
(note that the level of written detail can vary, as here ‚Äì if you and the reader agree ‚Äì but you
must do all the steps in your head. If in any doubt, write it down, as an aid to thought...!)
Slide 87
Lemma: Values don‚Äôt reduce
Lemma 10 For all e ‚ààL1, if e is a value then
‚àÄs.¬¨ ‚àÉe‚Ä≤, s‚Ä≤.‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©.
Proof
By defn e is a value if it is of one of the forms n, b, skip. By
examination of the rules on slides ..., there is no rule with conclusion of
the form ‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©for e one of n, b, skip.
‚ñ°
41

Theorem 2 (Progress) If Œì ‚ä¢e:T and dom(Œì) ‚äÜdom(s) then either e is a value or there
exist e‚Ä≤, s‚Ä≤ such that ‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©.
Proof
Take
Œ¶(Œì, e, T)
def
= ‚àÄs.dom(Œì) ‚äÜdom(s) ‚áívalue(e) ‚à®(‚àÉe‚Ä≤, s‚Ä≤.‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©)
We show that for all Œì, e, T, if Œì ‚ä¢e:T then Œ¶(Œì, e, T), by rule induction on the
deÔ¨Ånition of ‚ä¢.
Case (int). Recall the rule scheme
(int)
Œì ‚ä¢n:int
for n ‚ààZ
It has no premises, so we have to show that for all instances Œì, e, T of the con-
clusion we have Œ¶(Œì, e, T).
For any such instance, there must be an n ‚ààZ for which e = n.
Now Œ¶ is of the form ‚àÄs.dom(Œì) ‚äÜdom(s) ‚áí..., so consider an arbitrary s and
assume dom(Œì) ‚äÜdom(s).
We have to show value(e) ‚à®(‚àÉe‚Ä≤, s‚Ä≤.‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©). But the Ô¨Årst disjunct is
true as integers are values (according to the deÔ¨Ånition).
Case (bool) similar.
Case (op+ ). Recall the rule
(op +)
Œì ‚ä¢e1:int
Œì ‚ä¢e2:int
Œì ‚ä¢e1 + e2:int
We have to show that for all Œì, e1, e2, if Œ¶(Œì, e1, int) and Œ¶(Œì, e2, int) then Œ¶(Œì, e1+
e2, int).
Suppose Œ¶(Œì, e1, int) (*), Œ¶(Œì, e2, int) (**), Œì ‚ä¢e1:int (***), and Œì ‚ä¢e2:int (****)
(note that we‚Äôre using the variant form of rule induction here).
Consider an arbitrary s. Assume dom(Œì) ‚äÜdom(s).
We have to show value(e1 + e2) ‚à®(‚àÉe‚Ä≤, s‚Ä≤.‚ü®e1 + e2, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©).
Now the Ô¨Årst disjunct is false (e1 + e2 is not a value), so we have to show the
second, i.e.‚àÉ‚ü®e‚Ä≤, s‚Ä≤‚ü©.‚ü®e1 + e2, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©.
By (*) one of the following holds.
case ‚àÉe‚Ä≤
1, s‚Ä≤.‚ü®e1, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
1, s‚Ä≤‚ü©.
Then by (op1) we have ‚ü®e1 + e2, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
1 + e2, s‚Ä≤‚ü©, so we are done.
case e1 is a value. By (**) one of the following holds.
case ‚àÉe‚Ä≤
2, s‚Ä≤.‚ü®e2, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
2, s‚Ä≤‚ü©.
Then by (op2) ‚ü®e1 + e2, s‚ü©‚àí‚Üí‚ü®e1 + e‚Ä≤
2, s‚Ä≤‚ü©, so we are done.
case e2 is a value.
(Now want to use (op+ ), but need to know that e1 and e2 are really
integers. )
Lemma 11 for all Œì, e, T, if Œì ‚ä¢e:T, e is a value and T = int then for
some n ‚ààZ we have e = n.
Proof
By rule induction. Take Œ¶‚Ä≤(Œì, e, T) = ((value(e) ‚àßT = int) ‚áí
‚àÉn ‚ààZ.e = n).
Case (int). ok
42

Case (bool),(skip). In instances of these rules the conclusion is a
value but the type is not int, so ok.
Case otherwise. In instances of all other rules the conclusion is
not a value, so ok.
(a rather trivial use of rule induction ‚Äì we never needed to use the
induction hypothesis, just to do case analysis of the last rule that
might have been used in a derivation of Œì ‚ä¢e:T).
‚ñ°
Using the Lemma, (***) and (****) there exist n1
‚àà
Z and n2
‚ààZ
such that e1 = n1 and e2 = n2. Then by (op+) ‚ü®e1 + e2, s‚ü©‚àí‚Üí‚ü®n, s‚ü©
where n = n1 + n2, so we are done.
Case (op ‚â•). Similar to (op + ).
Case (if). Recall the rule
(if)
Œì ‚ä¢e1:bool
Œì ‚ä¢e2:T
Œì ‚ä¢e3:T
Œì ‚ä¢if e1 then e2 else e3:T
Suppose Œ¶(Œì, e1, bool) (*1), Œ¶(Œì, e2, T) (*2), Œ¶(Œì, e3, T) (*3), Œì ‚ä¢e1:bool (*4),
Œì ‚ä¢e2:T (*5) and Œì ‚ä¢e3:T (*6).
Consider an arbitrary s. Assume dom(Œì) ‚äÜdom(s). Write e for if e1 then e2 else e3.
This e is not a value, so we have to show ‚ü®e, s‚ü©has a transition.
case ‚àÉe‚Ä≤
1, s‚Ä≤.‚ü®e1, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
1, s‚Ä≤‚ü©.
Then by (if3) ‚ü®e, s‚ü©‚àí‚Üí‚ü®if e‚Ä≤
1 then e2 else e3, s‚ü©, so we are done.
case e1 is a value.
(Now want to use (if1) or (if2), but need to know that e1
‚àà{true, false}.
Realize should have proved a stronger Lemma above).
Lemma 12 For all Œì, e, T. if Œì ‚ä¢e:T and e is a value, then T = int ‚áí
‚àÉn ‚ààZ.e = n, T = bool ‚áí‚àÉb ‚àà{true, false}.e = b, and T = unit ‚áí
e = skip.
Proof
By rule induction ‚Äì details omitted.
‚ñ°
Using the Lemma and (*4) we have ‚àÉb ‚àà{true, false}.e1 = b.
case b = true. Use (if1).
case b = false. Use (if2).
Case (deref). Recall the rule
(deref)
Œì(‚Ñì) = intref
Œì ‚ä¢!‚Ñì:int
(This is a leaf ‚Äì it has no Œì ‚ä¢e:T premises - so no Œ¶s to assume).
Consider an arbitrary s with dom(Œì) ‚äÜdom(s).
By the condition Œì(‚Ñì) = intref we have ‚Ñì‚ààdom(Œì), so ‚Ñì‚ààdom(s), so there is
some n with s(‚Ñì) = n, so there is an instance of (deref) ‚ü®!‚Ñì, s‚ü©‚àí‚Üí‚ü®n, s‚ü©.
Cases (assign), (skip), (seq), (while). Left as an exercise.
‚ñ°
Slide 88
Lemma: Values of integer type
Lemma 13 for all Œì, e, T , if Œì ‚ä¢e:T , e is a value and T = int then for
some n ‚ààZ we have e = n.
43

Theorem 3 (Type Preservation) If Œì ‚ä¢e:T and dom(Œì) ‚äÜdom(s) and ‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©
then Œì ‚ä¢e‚Ä≤:T and dom(Œì) ‚äÜdom(s‚Ä≤).
Proof
First show the second part, using the following lemma.
Lemma 14 If ‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©then dom(s‚Ä≤) = dom(s).
Proof
Rule induction on derivations of ‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©. Take Œ¶(e, s, e‚Ä≤, s‚Ä≤) =
(dom(s) = dom(s‚Ä≤)).
All rules are immediate uses of the induction hypothesis except (assign1),
for which we note that if ‚Ñì‚ààdom(s) then dom(s + (‚Ñì7‚Üín)) = dom(s).
‚ñ°
Now prove the Ô¨Årst part, ie If Œì ‚ä¢e:T and dom(Œì) ‚äÜdom(s) and ‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©
then Œì ‚ä¢e‚Ä≤:T.
Prove by rule induction on derivations of ‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©.
Take Œ¶(e, s, e‚Ä≤, s‚Ä≤) = ‚àÄŒì, T.(Œì ‚ä¢e:T ‚àßdom(Œì) ‚äÜdom(s)) ‚áíŒì ‚ä¢e‚Ä≤:T.
Case (op+). Recall
(op +)
‚ü®n1 + n2, s‚ü©‚àí‚Üí‚ü®n, s‚ü©
if n = n1 + n2
Take arbitrary Œì, T. Suppose Œì ‚ä¢n1 + n2:T (*) and dom(Œì) ‚äÜdom(s). The last
rule in the derivation of (*) must have been (op+ ), so must have T = int. Then
can use (int) to derive Œì ‚ä¢n:T.
Case (op ‚â•). Similar.
Case (op1). Recall
(op1)
‚ü®e1, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
1, s‚Ä≤‚ü©
‚ü®e1 op e2, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
1 op e2, s‚Ä≤‚ü©
Suppose Œ¶(e1, s, e‚Ä≤
1, s‚Ä≤) (*) and ‚ü®e1, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
1, s‚Ä≤‚ü©. Have to show Œ¶(e1 op e2, s, e‚Ä≤
1 op e2, s‚Ä≤).
Take arbitrary Œì, T. Suppose Œì ‚ä¢e1 op e2:T and dom(Œì) ‚äÜdom(s) (**).
case op = +. The last rule in the derivation of Œì ‚ä¢e1 + e2:T must have been
(op+), so must have T = int, Œì ‚ä¢e1:int (***) and Œì ‚ä¢e2:int (****). By the
induction hypothesis (*), (**), and (***) we have Œì ‚ä¢e‚Ä≤
1:int. By the (op+)
rule Œì ‚ä¢e‚Ä≤
1 + e2:T.
case op =‚â•. Similar.
Case s (op2) (deref), (assign1), (assign2), (seq1), (seq2), (if1), (if2), (if3), (while).
Left as exercises.
‚ñ°
Theorem 4 (Safety) If Œì ‚ä¢e:T, dom(Œì) ‚äÜdom(s), and ‚ü®e, s‚ü©‚àí‚Üí‚àó‚ü®e‚Ä≤, s‚Ä≤‚ü©then either e‚Ä≤
is a value or there exist e‚Ä≤‚Ä≤, s‚Ä≤‚Ä≤ such that ‚ü®e‚Ä≤, s‚Ä≤‚ü©‚àí‚Üí‚ü®e‚Ä≤‚Ä≤, s‚Ä≤‚Ä≤‚ü©.
Proof
Hint: induction along ‚àí‚Üí‚àóusing the previous results.
‚ñ°
Theorem 7 (Uniqueness of typing) If Œì ‚ä¢e:T and Œì ‚ä¢e:T ‚Ä≤ then T = T ‚Ä≤. The proof
is left as Exercise 17.
Theorem 5 (Decidability of typeability) Given Œì, e, one can decide ‚àÉT.Œì ‚ä¢e:T.
Theorem 6 (Decidability of type checking) Given Œì, e, T, one can decide Œì ‚ä¢e:T.
Proof
The implementation gives a type inference algorithm, which, if correct, and to-
gether with Uniqueness, implies both of these results.
‚ñ°
44

Slide 89
Summarising Proof Techniques
Determinacy
structural induction for e
Progress
rule induction for Œì ‚ä¢e:T
Type Preservation
rule induction for ‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©
Safety
mathematical induction on ‚àí‚Üík
Uniqueness of typing
...
Decidability of typability
exhibiting an algorithm
Decidability of checking
corollary of other results
3.4
Exercises
You should be able to prove all the theorems about L1 independently. These exercises are
to get you started.
Exercise 12 ‚ãÜWithout looking at the proof in the notes, do the cases of the proof of The-
orem 1 (Determinacy) for e1 op e2, e1; e2, while e1 do e2, and if e1 then e2 else e3.
Exercise 13 ‚ãÜTry proving Determinacy for the language with nondeterministic order of
evaluation for e1 op e2 (ie with both (op1) and (op1b) rules), which is not determinate.
Explain where exactly the proof can‚Äôt be carried through.
Exercise 14 ‚ãÜComplete the proof of Theorem 2 (Progress).
Exercise 15 ‚ãÜ‚ãÜComplete the proof of Theorem 3 (Type Preservation).
Exercise 16 ‚ãÜ‚ãÜGive an alternate proof of Theorem 3 (Type Preservation) by rule induc-
tion over type derivations.
Exercise 17 ‚ãÜ‚ãÜProve Theorem 7 (Uniqueness of Typing).
45

4
Functions
Slide 90
Functions ‚Äì L2
Slide 91
Functions, Methods, Procedures...
fun addone x = x+1
public int addone(int x) {
x+1
}
<script type="text/vbscript">
function addone(x)
addone = x+1
end function
</script>
Slide 92
C‚ôØ
delegate int IntThunk();
class M {
public static void Main() {
IntThunk[] funcs = new IntThunk[11];
for (int i = 0; i <= 10; i++)
{
funcs[i] = delegate() { return i; };
}
foreach (IntThunk f in funcs)
{
System.Console.WriteLine(f());
}
}
}
Most languages have some kind of function, method, or procedure ‚Äì some way of abstracting
a piece of code on a formal parameter so that you can use the code multiple times with
diÔ¨Äerent arguments, without having to duplicate the code in the source.
The next two
lectures explore the design space for functions, adding them to L1.
46

Slide 93
Functions ‚Äì Examples
We will add expressions like these to L1.
(fn x:int ‚áíx + 1)
(fn x:int ‚áíx + 1) 7
(fn y:int ‚áí(fn x:int ‚áíx + y))
(fn y:int ‚áí(fn x:int ‚áíx + y)) 1
(fn x:int ‚Üíint ‚áí(fn y:int ‚áíx (x y)))
(fn x:int ‚Üíint ‚áí(fn y:int ‚áíx (x y))) (fn x:int ‚áíx + 1)
 (fn x:int ‚Üíint ‚áí(fn y:int ‚áíx (x y))) (fn x:int ‚áíx + 1)

7
For simplicity, we‚Äôll deal with anonymous functions only. Functions will always take a single
argument and return a single result ‚Äî though either might itself be a function or a tuple.
Slide 94
Functions ‚Äì Syntax
First, extend the L1 syntax:
Variables x ‚ààX for a set X = {x, y, z, ...}
Expressions
e
::=
... | fn x:T ‚áíe | e1 e2 | x
Types
T
::=
int | bool | unit | T1 ‚ÜíT2
Tloc
::=
intref
Concrete syntax.
By convention, application associates to the left, so e1 e2 e3 de-
notes (e1 e2) e3, and type arrows associate to the right, so T1 ‚ÜíT2 ‚ÜíT3 denotes
T1 ‚Üí(T2 ‚ÜíT3). A fn extends to the right as far as parentheses permit, so fn x:unit ‚áíx; x
denotes fn x:unit ‚áí(x; x), not (fn x:unit ‚áíx); x. These conventions work well for functions
that take several arguments, e.g.fn x:unit ‚áífn y:int ‚áíx; y has type unit ‚Üíint ‚Üíint, and
we can fully apply it simply by juxtaposing it with its two arguments
(fn x:unit ‚áífn y:int ‚áíx; y) skip 15.
‚Ä¢ Variables are not locations ( L ‚à©X = {} ), so x := 3 is not in the syntax.
‚Ä¢ You can‚Äôt abstract on locations. For example, (fn l:intref ‚áí!l) is not in the syntax.
‚Ä¢ The (non-meta) variables x, y, z are not the same as metavariables x, y, z. In the notes
they are distinguished by font; in handwriting one just have to keep track in your head
‚Äì not often a problem.
‚Ä¢ These expressions look like lambda terms (and fn x:int ‚áíx could be written Œªx:int.x).
But, (a) we‚Äôre adding them to a rich language, not working with the pure lambda
calculus (cf. Foundations of Functional Programming), and (b) we‚Äôre going to explore
several options for how they should behave.
Type-directed language design. This type grammar (and expression syntax) suggests
the language will include higher-order functions ‚Äì you can abstract on a variable of any
type, including function types. If you only wanted Ô¨Årst-order functions, you‚Äôd say
A
::=
int | bool | unit
T
::=
A | A ‚ÜíT
Tloc
::=
intref
Note that Ô¨Årst-order function types include types like int ‚Üí(int ‚Üíint) and int ‚Üí(int ‚Üí(int ‚Üíint)),
of functions that take an argument of base type and return a (Ô¨Årst-order) function, e.g.
(fn y:int ‚áí(fn x:int ‚áíx + y))
47

Some languages go further, forbidding partial application. We‚Äôll come back to this.
4.1
Abstract syntax up to alpha conversion, and substitution
In order to express the semantics for functions, we need some auxiliary deÔ¨Ånitions.
Slide 95
Variable shadowing
(fn x:int ‚áí(fn x:int ‚áíx + 1))
class F {
void m() {
int y;
{int y; ...
} // Static error
...
{int y; ...
}
...
}
}
Variable shadowing is not allowed in Java. For large systems that would be a problem, eg
in a language with nested function deÔ¨Ånitions, where you may wish to write a local function
parameter without being aware of what is in the surrounding namespace.
Slide 96
Alpha conversion
In expressions fn x:T ‚áíe the x is a binder.
‚Ä¢ inside e, any x‚Äôs (that aren‚Äôt themselves binders and are not inside
another fn x:T ‚Ä≤ ‚áí...) mean the same thing ‚Äì the formal parameter
of this function.
‚Ä¢ outside this fn x:T ‚áíe, it doesn‚Äôt matter which variable we used for
the formal parameter ‚Äì in fact, we shouldn‚Äôt be able to tell. For
example, fn x:int ‚áíx + 2 should be the same as
fn y:int ‚áíy + 2.
cf
R 1
0 x + x2dx =
R 1
0 y + y2dy
Slide 97
Alpha conversion ‚Äì free and bound occurrences
In a bit more detail (but still informally):
Say an occurrence of x in an expression e is free if it is not inside any
(fn x:T ‚áí...). For example:
17
x + y
fn x:int ‚áíx + 2
fn x:int ‚áíx + z
if y then 2 + x else ((fn x:int ‚áíx + 2)z)
All the other occurrences of x are bound by the closest enclosing
fn x:T ‚áí....
Note that in fn x:int ‚áí2 the x is not an occurrence. Likewise, in fn x:int ‚áíx + 2 the left
x is not an occurrence; here the right x is an occurrence that is bound by the left x.
48

Sometimes it is handy to draw in the binding:
Slide 98
Alpha conversion ‚Äì Binding examples
fn x:int ‚áíx

+2
fn x:int ‚áíx

+z
fn y:int ‚áíy

+z
fn z:int ‚áíz

+z

fn x:int ‚áí(fn x:int ‚áíx

+2)
Slide 99
Alpha Conversion ‚Äì The Convention
Convention: we will allow ourselves to any time at all, in any expression
...(fn x:T ‚áíe)..., replace the binding x and all occurrences of x that
are bound by that binder, by any other variable ‚Äì so long as that doesn‚Äôt
change the binding graph.
For example:
fn x:int ‚áíx

+z = fn y:int ‚áíy

+z Ã∏= fn z:int ‚áíz

+z

This is called ‚Äòworking up to alpha conversion‚Äô. It amounts to regarding
the syntax not as abstract syntax trees, but as abstract syntax trees with
pointers...
Slide 100
Abstract Syntax up to Alpha Conversion
fn x:int ‚áíx + z
=
fn y:int ‚áíy + z
Ã∏=
fn z:int ‚áíz + z
Start with naive abstract syntax trees:
fn x:int ‚áí
+
x
t
t
t
t
t
t
z
‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†
fn y:int ‚áí
+
y
‚úâ
‚úâ
‚úâ
‚úâ
‚úâ
‚úâ
z
‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†
fn z:int ‚áí
+
z
‚úâ
‚úâ
‚úâ
‚úâ
‚úâ
‚úâ
z
‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†
add pointers (from each x node to the closest enclosing fn x:T ‚áínode);
remove names of binders and the occurrences they bind
fn ¬∑¬∑¬∑ :int ‚áí
+
‚Ä¢
t
t
t
t
t
t
=
z
‚ùè‚ùè‚ùè‚ùè‚ùè‚ùè
fn ¬∑¬∑¬∑ :int ‚áí
+
‚Ä¢
t
t
t
t
t
t
=
z
‚ùè‚ùè‚ùè‚ùè‚ùè‚ùè
fn ¬∑¬∑¬∑ :int ‚áí
+
‚Ä¢
t
t
t
t
t
t
=
‚Ä¢
‚ùè‚ùè‚ùè‚ùè‚ùè‚ùè
a
49

Slide 101
fn x:int ‚áí(fn x:int ‚áíx + 2)
= fn y:int ‚áí(fn z:int ‚áíz + 2)
Ã∏=
fn z:int ‚áí(fn y:int ‚áíz + 2)
fn ¬∑¬∑¬∑ :int ‚áí
fn ¬∑¬∑¬∑ :int ‚áí
+
‚Ä¢
‚úâ
‚úâ
‚úâ
‚úâ
‚úâ
‚úâ
=
2
‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†
fn ¬∑¬∑¬∑ :int ‚áí
fn ¬∑¬∑¬∑ :int ‚áí
+
‚Ä¢
‚úâ
‚úâ
‚úâ
‚úâ
‚úâ
‚úâ
8
2
‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†
Slide 102
(fn x:int ‚áíx) 7
fn z:int ‚Üíint ‚Üíint ‚áí(fn y:int ‚áíz y y)
@
fn ¬∑¬∑¬∑ :int ‚áí
t
t
t
t
t
7
‚ú∑‚ú∑‚ú∑
‚Ä¢
B
fn ¬∑¬∑¬∑ :int ‚Üíint ‚Üíint ‚áí
fn ¬∑¬∑¬∑ :int ‚áí
@
@
‚ù•
‚ù•
‚ù•
‚ù•
‚ù•
‚ù•
‚ù•
‚ù•
‚ù•
‚ù•
‚ù•
‚ù•
‚Ä¢
‚ùô‚ùô‚ùô‚ùô‚ùô‚ùô‚ùô‚ùô‚ùô‚ùô‚ùô‚ùô
k
‚Ä¢
‚òõ‚òõ‚òõ‚òõ
6
‚Ä¢
‚ùö‚ùö‚ùö‚ùö‚ùö‚ùö‚ùö‚ùö‚ùö‚ùö‚ùö‚ùö‚ùö
]
Slide 103
De Bruijn indices
Our implementation will use those pointers ‚Äì known as De Bruijn indices.
Each occurrence of a bound variable is represented by the number of
fn ¬∑¬∑¬∑ :T ‚áínodes you have to count out to to get to its binder.
fn ¬∑¬∑¬∑ :int ‚áí(fn ¬∑¬∑¬∑ :int ‚áív0 + 2)
Ã∏=
fn ¬∑¬∑¬∑ :int ‚áí(fn ¬∑¬∑¬∑ :int ‚áív1 + 2)
fn ¬∑¬∑¬∑ :int ‚áí
fn ¬∑¬∑¬∑ :int ‚áí
+
‚Ä¢
‚úâ
‚úâ
‚úâ
‚úâ
‚úâ
‚úâ
=
2
‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†
fn ¬∑¬∑¬∑ :int ‚áí
fn ¬∑¬∑¬∑ :int ‚áí
+
‚Ä¢
‚úâ
‚úâ
‚úâ
‚úâ
‚úâ
‚úâ
8
2
‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†
Slide 104
Free Variables
Say the free variables of an expression e are the set of variables x for
which there is an occurence of x free in e.
fv(x)
=
{x}
fv(e1 op e2)
=
fv(e1) ‚à™fv(e2)
fv(fn x:T ‚áíe)
=
fv(e) ‚àí{x}
Say e is closed if fv(e) = {}.
If E is a set of expressions, write fv(E) for S
e ‚ààE fv(e).
(note this deÔ¨Ånition is alpha-invariant - all our deÔ¨Ånitions should be)
50

For example
fv(x + y)
=
{x, y}
fv(fn x:int ‚áíx + y)
=
{y}
fv(x + (fn x:int ‚áíx + y)7)
=
{x, y}
Full deÔ¨Ånition of fv(e) is by recursion on the structure of e:
fv(x)
=
{x}
fv(fn x:T ‚áíe)
=
fv(e) ‚àí{x}
fv(e1 e2)
=
fv(e1) ‚à™fv(e2)
fv(n)
=
{}
fv(e1 op e2)
=
fv(e1) ‚à™fv(e2)
fv(if e1 then e2 else e3)
=
fv(e1) ‚à™fv(e2) ‚à™fv(e3)
fv(b)
=
{}
fv(skip)
=
{}
fv(‚Ñì:= e)
=
fv(e)
fv(!‚Ñì)
=
{}
fv(e1; e2)
=
fv(e1) ‚à™fv(e2)
fv(while e1 do e2)
=
fv(e1) ‚à™fv(e2)
The semantics for functions will involve substituting actual parameters for formal parame-
ters.
Slide 105
Substitution ‚Äì Examples
The semantics for functions will involve substituting actual parameters for
formal parameters.
Write {e/x}e‚Ä≤ for the result of substituting e for all free occurrences of x
in e‚Ä≤. For example
{3/x}(x ‚â•x)
=
(3 ‚â•3)
{3/x}((fn x:int ‚áíx + y)x)
=
(fn x:int ‚áíx + y)3
{y + 2/x}(fn y:int ‚áíx + y)
=
fn z:int ‚áí(y + 2) + z
Note that substitution is a meta-operation ‚Äì it‚Äôs not part of the L2 expression grammar.
The notation used for substitution varies ‚Äì people write {3/x}e, or [3/x]e, or e[3/x], or
{x ‚Üê3}e, or...
Slide 106
Substitution ‚Äì DeÔ¨Ånition
DeÔ¨Åning that:
{e/z}x
=
e
if x = z
=
x
otherwise
{e/z}(fn x:T ‚áíe1)
=
fn x:T ‚áí({e/z}e1)
if x Ã∏= z (*)
and x /‚ààfv(e) (*)
{e/z}(e1 e2)
=
({e/z}e1)({e/z}e2)
...
if (*) is not true, we Ô¨Årst have to pick an alpha-variant of fn x:T ‚áíe1 to
make it so (always can)
51

Slide 107
Substitution ‚Äì Example Again
{y + 2/x}(fn y:int ‚áíx + y)
=
{y + 2/x}(fn y‚Ä≤:int ‚áíx + y‚Ä≤) renaming
=
fn y‚Ä≤:int ‚áí{y + 2/x}(x + y‚Ä≤) as y‚Ä≤ Ã∏= x and y‚Ä≤ /‚ààfv(y + 2)
=
fn y‚Ä≤:int ‚áí{y + 2/x}x + {y + 2/x}y‚Ä≤
=
fn y‚Ä≤:int ‚áí(y + 2) + y‚Ä≤
(could have chosen any other z instead of y‚Ä≤, except y or x)
Slide 108
Simultaneous substitution
A substitution œÉ is a Ô¨Ånite partial function from variables to expressions.
Notation: write a œÉ as {e1/x1, .., ek/xk} instead of
{x1 7‚Üíe1, ..., xk 7‚Üíek} (for the function mapping x1 to e1 etc.)
A deÔ¨Ånition of œÉ e is given in the notes.
Write dom(œÉ) for the set of variables in the domain of œÉ; ran(œÉ) for the set of expressions
in the range of œÉ, ie
dom({e1/x1, .., ek/xk})
=
{x1, .., xk}
ran({e1/x1, .., ek/xk})
=
{e1, .., ek}
DeÔ¨Åne the application of simultaneous substitution to a term by:
œÉ x
=
œÉ(x)
if x ‚ààdom(œÉ)
=
x
otherwise
œÉ(fn x:T ‚áíe)
=
fn x:T ‚áí(œÉ e)
if x /‚ààdom(œÉ) and x /‚ààfv(ran(œÉ)) (*)
œÉ(e1 e2)
=
(œÉ e1)(œÉ e2)
œÉ n
=
n
œÉ(e1 op e2)
=
œÉ(e1) op œÉ(e2)
œÉ(if e1 then e2 else e3)
=
if œÉ(e1) then œÉ(e2) else œÉ(e3)
œÉ(b)
=
b
œÉ(skip)
=
skip
œÉ(‚Ñì:= e)
=
‚Ñì:= œÉ(e)
œÉ(!‚Ñì)
=
!‚Ñì
œÉ(e1; e2)
=
œÉ(e1); œÉ(e2)
œÉ(while e1 do e2)
=
while œÉ(e1) do œÉ(e2)
4.2
Function Behaviour
Slide 109
Function Behaviour
Consider the expression
e = (fn x:unit ‚áí(l := 1); x) (l := 2)
then
‚ü®e, {l 7‚Üí0}‚ü©‚àí‚Üí‚àó‚ü®skip, {l 7‚Üí???}‚ü©
52

Slide 110
Function Behaviour. Choice 1: Call-by-value
Informally: reduce left-hand-side of application to a fn-term; reduce
argument to a value; then replace all occurrences of the formal parameter
in the fn-term by that value.
e = (fn x:unit ‚áí(l := 1); x)(l := 2)
‚ü®e, {l = 0}‚ü©
‚àí‚Üí
‚ü®(fn x:unit ‚áí(l := 1); x)skip, {l = 2}‚ü©
‚àí‚Üí
‚ü®(l := 1); skip
, {l = 2}‚ü©
‚àí‚Üí
‚ü®skip; skip
, {l = 1}‚ü©
‚àí‚Üí
‚ü®skip
, {l = 1}‚ü©
This is a common design choice ‚Äî ML, Java. It is a strict semantics ‚Äì fully evaluating the
argument to function before doing the application.
Slide 111
L2 Call-by-value
Values v ::= b | n | skip | fn x:T ‚áíe
(app1)
‚ü®e1, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
1, s‚Ä≤‚ü©
‚ü®e1 e2, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
1 e2, s‚Ä≤‚ü©
(app2)
‚ü®e2, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
2, s‚Ä≤‚ü©
‚ü®v e2, s‚ü©‚àí‚Üí‚ü®v e‚Ä≤
2, s‚Ä≤‚ü©
(fn)
‚ü®(fn x:T ‚áíe) v, s‚ü©‚àí‚Üí‚ü®{v/x}e, s‚ü©
Slide 112
L2 Call-by-value ‚Äì reduction examples
‚ü®(fn x:int ‚áífn y:int ‚áíx + y) (3 + 4) 5 , s‚ü©
=
‚ü®
 (fn x:int ‚áífn y:int ‚áíx + y) (3 + 4)

5 , s‚ü©
‚àí‚Üí
‚ü®
 (fn x:int ‚áífn y:int ‚áíx + y) 7

5 , s‚ü©
‚àí‚Üí
‚ü®
 {7/x}(fn y:int ‚áíx + y)

5 , s‚ü©
=
‚ü®
 (fn y:int ‚áí7 + y)

5 , s‚ü©
‚àí‚Üí
‚ü®7 + 5 , s‚ü©
‚àí‚Üí
‚ü®12 , s‚ü©
(fn f:int ‚Üíint ‚áíf 3) (fn x:int ‚áí(1 + 2) + x)
‚Ä¢ The rules for these constructs don‚Äôt touch the store. In a pure functional language,
conÔ¨Ågurations would just be expressions.
‚Ä¢ A naive implementation of these rules would have to traverse e and copy v as many
times as there are free occurrences of x in e. Real implementations don‚Äôt do that,
using environments instead of doing substitution. Environments are more eÔ¨Écient;
substitutions are simpler to write down ‚Äì so better for implementation and semantics
respectively.
53

Slide 113
Function Behaviour. Choice 2: Call-by-name
Informally: reduce left-hand-side of application to a fn-term; then replace
all occurrences of the formal parameter in the fn-term by the argument.
e = (fn x:unit ‚áí(l := 1); x) (l := 2)
‚ü®e, {l 7‚Üí0}‚ü©
‚àí‚Üí
‚ü®(l := 1); l := 2, {l 7‚Üí0}‚ü©
‚àí‚Üí
‚ü®skip
; l := 2, {l 7‚Üí1}‚ü©
‚àí‚Üí
‚ü®l := 2
, {l 7‚Üí1}‚ü©
‚àí‚Üí
‚ü®skip
, {l 7‚Üí2}‚ü©
This is the foundation of ‚Äòlazy‚Äô functional languages ‚Äì e.g. Haskell
Slide 114
L2 Call-by-name
(same typing rules as before)
(CBN-app)
‚ü®e1, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
1, s‚Ä≤‚ü©
‚ü®e1 e2, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
1 e2, s‚Ä≤‚ü©
(CBN-fn)
‚ü®(fn x:T ‚áíe)e2, s‚ü©‚àí‚Üí‚ü®{e2/x}e, s‚ü©
Here, don‚Äôt evaluate the argument at all if it isn‚Äôt used
‚ü®(fn x:unit ‚áískip)(l := 2), {l 7‚Üí0}‚ü©
‚àí‚Üí
‚ü®{l := 2/x}skip
, {l 7‚Üí0}‚ü©
=
‚ü®skip
, {l 7‚Üí0}‚ü©
but if it is, end up evaluating it repeatedly.
Slide 115
Function Behaviour. Choice 3: Full beta
Allow both left and right-hand sides of application to reduce. At any point
where the left-hand-side has reduced to a fn-term, replace all
occurrences of the formal parameter in the fn-term by the argument.
Allow reduction inside lambdas.
(fn x:int ‚áí2 + 2) ‚àí‚Üí(fn x:int ‚áí4)
Slide 116
L2 Beta
(beta-app1)
‚ü®e1, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
1, s‚Ä≤‚ü©
‚ü®e1 e2, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
1 e2, s‚Ä≤‚ü©
(beta-app2)
‚ü®e2, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
2, s‚Ä≤‚ü©
‚ü®e1 e2, s‚ü©‚àí‚Üí‚ü®e1 e‚Ä≤
2, s‚Ä≤‚ü©
(beta-fn1)
‚ü®(fn x:T ‚áíe)e2, s‚ü©‚àí‚Üí‚ü®{e2/x}e, s‚ü©
(beta-fn2)
‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©
‚ü®fn x:T ‚áíe, s‚ü©‚àí‚Üí‚ü®fn x:T ‚áíe‚Ä≤, s‚Ä≤‚ü©
This reduction relation includes the CBV and CBN relations, and also reduction inside
lambdas.
54

Slide 117
L2 Beta: Example
(fn x:int ‚áíx + x) (2 + 2)
}‚ë¢‚ë¢‚ë¢‚ë¢
+‚ù≤
‚ù≤
‚ù≤
‚ù≤
‚ù≤
‚ù≤
‚ù≤
‚ù≤
‚ù≤
‚ù≤
‚ù≤
‚ù≤
‚ù≤
‚ù≤
‚ù≤
(fn x:int ‚áíx + x) 4
$‚ñ†
‚ñ†
‚ñ†
‚ñ†
‚ñ†
‚ñ†
‚ñ†
‚ñ†
‚ñ†
‚ñ†
‚ñ†
‚ñ†
‚ñ†
‚ñ†
‚ñ†
(2 + 2) + (2 + 2)
u‚ù¶‚ù¶‚ù¶‚ù¶‚ù¶‚ù¶‚ù¶
)‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
4 + (2 + 2)

(2 + 2) + 4
r‚ù°‚ù°‚ù°‚ù°‚ù°‚ù°‚ù°‚ù°‚ù°‚ù°‚ù°‚ù°‚ù°‚ù°‚ù°‚ù°‚ù°‚ù°‚ù°‚ù°‚ù°‚ù°
4 + 4

8
Slide 118
Function Behaviour. Choice 4: Normal-order reduction
Leftmost, outermost variant of full beta.
‚Ä¢ What will (fn x:unit ‚áískip) (while true do skip) do in the diÔ¨Äerent semantics?
‚Ä¢ What about (fn x:unit ‚áískip) (‚Ñì:=!‚Ñì+ 1)?
Slide 119
Purity
Without strict, call-by-value semantics, it becomes hard to understand what order your code
is going to be run in. Non-strict languages typically don‚Äôt allow unrestricted side eÔ¨Äects (our
combination of store and CBN is pretty odd). Haskell encourages pure programming, without
eÔ¨Äects (store operations, IO, etc.) except where really necessary. Where they are necessary,
it uses a fancy type system to give you some control of evaluation order.
For a pure language, Call-By-Name gives the same results as Call-By-Need, which is more
eÔ¨Écient. The Ô¨Årst time the argument evaluated we ‚Äòoverwrite‚Äô all other copies by that value.
Slide 120
Call-By-Need Example (Haskell)
let notdivby x y = y ‚Äòmod‚Äò x /= 0
enumFrom n = n :
(enumFrom (n+1))
sieve (x:xs) =
x :
sieve (filter (notdivby x) xs)
in
sieve (enumFrom 2)
==>
[2,3,5,7,11,13,17,19,23,29,31,37,41,43,47,53,
59,61,67,71,73,79,83,89,97,101,103,107,109,
113,127,131,137,139,149,151,157,163,167,173,
179,181,191,193,197,199,211,223,227,229,233,
,,Interrupted!
Slide 121
Back to CBV (from now on).
55

4.3
Function Typing
Slide 122
Typing functions (1)
Before, Œì gave the types of store locations; it ranged over TypeEnv
which was the set of all Ô¨Ånite partial functions from locations L to Tloc.
Now, it must also give assumptions on the types of variables: e.g.
l1:intref, x:int, y:bool ‚Üíint.
Type environments, Œì ‚ààTypeEnv2, are Ô¨Ånite partial functions from
L ‚à™X to Tloc ‚à™T such that
‚àÄ‚Ñì‚ààdom(Œì).Œì(‚Ñì) ‚ààTloc
‚àÄx ‚ààdom(Œì).Œì(x) ‚ààT
Notation: if x /‚ààdom(Œì), write Œì, x:T for the partial function which
maps x to T but otherwise is like Œì.
Slide 123
Typing functions (2)
(var)
Œì ‚ä¢x:T
if Œì(x) = T
(fn)
Œì, x:T ‚ä¢e:T ‚Ä≤
Œì ‚ä¢fn x:T ‚áíe : T ‚ÜíT ‚Ä≤
(app)
Œì ‚ä¢e1:T ‚ÜíT ‚Ä≤
Œì ‚ä¢e2:T
Œì ‚ä¢e1 e2:T ‚Ä≤
Slide 124
Typing functions ‚Äì Example
x:int ‚ä¢x:int (var)
x:int ‚ä¢2:int (int)
x:int ‚ä¢x + 2:int
(op+)
{} ‚ä¢(fn x:int ‚áíx + 2):int ‚Üíint
(fn)
{} ‚ä¢2:int
(int)
{} ‚ä¢(fn x:int ‚áíx + 2) 2:int
(app)
‚Ä¢ Note that sometimes you need the alpha convention, e.g. to type
fn x:int ‚áíx + (fn x:bool ‚áíif x then 3 else 4)true
It‚Äôs a good idea to start out with all binders diÔ¨Äerent from each other and from all
free variables. It would be a bad idea to prohibit variable shadowing like this in source
programs.
‚Ä¢ In ML you have parametrically polymorphic functions, e.g. (fn x:Œ± ‚áíx):Œ± ‚ÜíŒ±, but
we won‚Äôt talk about them here ‚Äì that‚Äôs in Part II Types.
Another example:
l:intref, x:unit ‚ä¢1:int (int)
l:intref, x:unit ‚ä¢(l := 1):unit (asn)
l:intref, x:unit ‚ä¢x:unit (var)
l:intref, x:unit ‚ä¢(l := 1); x:unit
(seq)
l:intref ‚ä¢(fn x:unit ‚áí(l := 1); x):unit ‚Üíunit (fn)
l:intref ‚ä¢2:int (int)
l:intref ‚ä¢(l := 2):unit (asn)
l:intref ‚ä¢(fn x:unit ‚áí(l := 1); x) (l := 2):unit
(app)
56

Slide 125
Properties of Typing
We only consider executions of closed programs, with no free variables.
Theorem 15 (Progress) If e closed and Œì ‚ä¢e:T and
dom(Œì) ‚äÜdom(s) then either e is a value or there exist e‚Ä≤, s‚Ä≤ such that
‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©.
Note there are now more stuck conÔ¨Ågurations, e.g.((3) (4))
Theorem 16 (Type Preservation) If e closed and Œì ‚ä¢e:T and
dom(Œì) ‚äÜdom(s) and ‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©then Œì ‚ä¢e‚Ä≤:T and e‚Ä≤
closed and dom(Œì) ‚äÜdom(s‚Ä≤).
Slide 126
Proving Type Preservation
Theorem 16 (Type Preservation) If e closed and Œì ‚ä¢e:T and
dom(Œì) ‚äÜdom(s) and ‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©then Œì ‚ä¢e‚Ä≤:T and e‚Ä≤
closed and dom(Œì) ‚äÜdom(s‚Ä≤).
Taking
Œ¶(e, s, e‚Ä≤, s‚Ä≤) =
‚àÄŒì, T.
Œì ‚ä¢e:T ‚àßclosed(e) ‚àßdom(Œì) ‚äÜdom(s)
‚áí
Œì ‚ä¢e‚Ä≤:T ‚àßclosed(e‚Ä≤) ‚àßdom(Œì) ‚äÜdom(s‚Ä≤)
we show ‚àÄe, s, e‚Ä≤, s‚Ä≤.‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©‚áíŒ¶(e, s, e‚Ä≤, s‚Ä≤) by rule
induction.
Slide 127
To prove this one uses:
Lemma 17 (Substitution) If Œì ‚ä¢e:T and Œì, x:T ‚ä¢e‚Ä≤:T ‚Ä≤ with
x /‚ààdom(Œì) then Œì ‚ä¢{e/x}e‚Ä≤:T ‚Ä≤.
Determinacy and type inference properties also hold.
Slide 128
Normalization
Theorem 18 (Normalization) In the sublanguage without while loops or
store operations, if Œì ‚ä¢e:T and e closed then there does not exist an
inÔ¨Ånite reduction sequence ‚ü®e, {}‚ü©‚àí‚Üí‚ü®e1, {}‚ü©‚àí‚Üí‚ü®e2, {}‚ü©‚àí‚Üí...
Proof
? can‚Äôt do a simple induction, as reduction can make terms grow.
See Pierce Ch.12 (the details are not in the scope of this course).
‚ñ°
57

4.4
Local DeÔ¨Ånitions and Recursive Functions
Slide 129
Local deÔ¨Ånitions
For readability, want to be able to name deÔ¨Ånitions, and to restrict their
scope, so add:
e
::=
... | let val x:T = e1 in e2 end
this x is a binder, binding any free occurrences of x in e2.
Can regard just as syntactic sugar:
let val x:T = e1 in e2 end
‚áù
(fn x:T ‚áíe2)e1
Slide 130
Local deÔ¨Ånitions ‚Äì derived typing and reduction rules (CBV)
let val x:T = e1 in e2 end
‚áù
(fn x:T ‚áíe2)e1
(let)
Œì ‚ä¢e1:T
Œì, x:T ‚ä¢e2:T ‚Ä≤
Œì ‚ä¢let val x:T = e1 in e2 end:T ‚Ä≤
(let1)
‚ü®e1, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
1, s‚Ä≤‚ü©
‚ü®let val x:T = e1 in e2 end, s‚ü©‚àí‚Üí‚ü®let val x:T = e‚Ä≤
1 in e2 end, s‚Ä≤‚ü©
(let2)
‚ü®let val x:T = v in e2 end, s‚ü©‚àí‚Üí‚ü®{v/x}e2, s‚ü©
Our alpha convention means this really is a local deÔ¨Ånition ‚Äì there is no way to refer to the
locally-deÔ¨Åned variable outside the let val .
x + let val x:int = x in (x + 2) end
=
x + let val y:int = x in (y + 2) end
Slide 131
Recursive deÔ¨Ånitions ‚Äì Ô¨Årst attempt
How about
x = (fn y:int ‚áíif y ‚â•1 then y + (x (y + ‚àí1)) else 0)
where we use x within the deÔ¨Ånition of x? Think about evaluating x 3.
Could add something like this:
e
::=
... | let val rec x:T = e in e‚Ä≤ end
(here the x binds in both e and e‚Ä≤) then say
let val rec x:int ‚Üíint =
(fn y:int ‚áíif y ‚â•1 then y + (x(y + ‚àí1)) else 0)
in x 3 end
58

Slide 132
But...
What about
let val rec x = (x, x) in x end ?
Have some rather weird things, eg
let val rec x:int list = 3 :: x in x end
does that terminate? if so, is it equal to
let val rec x:int list = 3 :: 3 :: x in x end ? does
let val rec x:int list = 3 :: (x + 1) in x end terminate?
In a CBN language, it is reasonable to allow this kind of thing, as will only
compute as much as needed. In a CBV language, would usually disallow,
allowing recursive deÔ¨Ånitions only of functions...
Slide 133
Recursive Functions
So, specialize the previous let val rec construct to
T
=
T1 ‚ÜíT2
recursion only at function types
e
=
fn y:T1 ‚áíe1
and only of function values
e
::=
... | let val rec x:T1 ‚ÜíT2 = (fn y:T1 ‚áíe1) in e2 end
(here the y binds in e1; the x binds in (fn y:T ‚áíe1) and in e2)
(let rec fn)
Œì, x:T1 ‚ÜíT2, y:T1 ‚ä¢e1:T2
Œì, x:T1 ‚ÜíT2 ‚ä¢e2:T
Œì ‚ä¢let val rec x:T1 ‚ÜíT2 = (fn y:T1 ‚áíe1) in e2 end:T
Concrete syntax: In ML can write let fun f (x:T1):T2 = e1 in e2 end,
or even let fun f (x) = e1 in e2 end, for
let val rec f :T1 ‚ÜíT2 = fn x:T1 ‚áíe1 in e2 end.
Slide 134
Recursive Functions ‚Äì Semantics
(letrecfn)
let val rec x:T1 ‚ÜíT2 = (fn y:T1 ‚áíe1) in e2 end
‚àí‚Üí
{(fn y:T1 ‚áílet val rec x:T1 ‚ÜíT2 = (fn y:T1 ‚áíe1) in e1 end)/x}e2
59

For example:
let val rec x:int ‚Üíint =
(fn y:int ‚áíif y ‚â•1 then y + (x(y + ‚àí1)) else 0)
in
x 3
end
‚àí‚Üí
(letrecfn)
 fn y:int ‚áí
let val rec x:int ‚Üíint =
(fn y:int ‚áíif y ‚â•1 then y + (x(y + ‚àí1)) else 0)
in
if y ‚â•1 then y + (x(y + ‚àí1)) else 0
end

3
‚àí‚Üí
(app)
let val rec x:int ‚Üíint =
(fn y:int ‚áíif y ‚â•1 then y + (x(y + ‚àí1)) else 0)
in
if 3 ‚â•1 then 3 + (x(3 + ‚àí1)) else 0)
end
‚àí‚Üí
(letrecfn)
if 3 ‚â•1 then
3 + (
 fn y:int ‚áí
let val rec x:int ‚Üíint =
(fn y:int ‚áíif y ‚â•1 then y + (x(y + ‚àí1)) else 0)
in
if y ‚â•1 then y + (x(y + ‚àí1)) else 0
end

(3 + ‚àí1))
else
0
‚àí‚Üí...
Slide 135
Recursive Functions ‚Äì Minimization Example
Below, in the context of the let val rec , x f n Ô¨Ånds the smallest n‚Ä≤ ‚â•n
for which f n‚Ä≤ evaluates to some m‚Ä≤ ‚â§0.
let val rec x:(int ‚Üíint) ‚Üíint ‚Üíint
= fn f:int ‚Üíint ‚áífn z:int ‚áíif (f z) ‚â•1 then x f (z + 1) else z
in
let val f:int ‚Üíint
= (fn z:int ‚áíif z ‚â•3 then (if 3 ‚â•z then 0 else 1) else 1)
in
x f 0
end
end
As a test case, we apply it to the function (fn z:int ‚áíif z ‚â•3 then (if 3 ‚â•z then 0 else 1) else 1),
which is 0 for argument 3 and 1 elsewhere.
60

Slide 136
More Syntactic Sugar
Do we need e1; e2?
No: Could encode by e1; e2 ‚áù(fn y:unit ‚áíe2)e1
Do we need while e1 do e2?
No: could encode by while e1 do e2 ‚áù
let val rec w:unit ‚Üíunit =
fn y:unit ‚áíif e1 then (e2; (w skip)) else skip
in
w skip
end
for fresh w and y not in fv(e1) ‚à™fv(e2).
In each case typing is the same. Reduction is ‚Äòessentially‚Äô the same ‚Äî we will be able to
make this precise when we study contextual equivalence.
4.5
Implementation
Slide 137
Implementation
There is an implementation of L2 on the course web page.
See especially Syntax.sml and Semantics.sml. It uses a front
end written with mosmllex and mosmlyac.
The implementation lets you type in L2 expressions and initial stores and watch them
resolve, type-check, and reduce.
Slide 138
Implementation ‚Äì Scope Resolution
datatype expr raw = ...
| Var raw of string
| Fn raw of string * type expr * expr raw
| App raw of expr raw * expr raw
| ...
datatype expr = ...
| Var of int
| Fn of type expr * expr
| App of expr * expr
resolve scopes :
expr raw -> expr
(it raises an exception if the expression has any free variables)
61

Slide 139
Implementation ‚Äì Substitution
subst : expr -> int -> expr -> expr
subst e 0 e‚Äô substitutes e for the outermost var in e‚Äô.
(the deÔ¨Ånition is only sensible if e is closed, but that‚Äôs ok ‚Äì we only
evaluate whole programs. For a general deÔ¨Ånition, see [Pierce, Ch. 6])
fun subst e n (Var n1) = if n=n1 then e else Var n1
| subst e n (Fn(t,e1)) = Fn(t,subst e (n+1) e1)
| subst e n (App(e1,e2)) = App(subst e n e1,subst e n e2)
| subst e n (Let(t,e1,e2))
= Let (t,subst e n e1,subst e (n+1) e2)
| subst e n (Letrecfn (tx,ty,e1,e2))
= Letrecfn (tx,ty,subst e (n+2) e1,subst e (n+1) e2)
| ...
If e‚Äô represents a closed term fn x:T ‚áíe‚Ä≤
1 then e‚Äô = Fn(t,e1‚Äô) for t and e1‚Äô representing
T and e‚Ä≤
1. If also e represents a closed term e then subst e 0 e1‚Äô represents {e/x}e‚Ä≤
1.
Slide 140
Implementation ‚Äì CBV reduction
reduce (App (e1,e2),s) = (case e1 of
Fn (t,e) =>
(if (is value e2) then
SOME (subst e2 0 e,s)
else
(case reduce (e2,s) of
SOME(e2‚Äô,s‚Äô) => SOME(App (e1,e2‚Äô),s‚Äô)
| NONE => NONE))
|
=> (case reduce (e1,s) of
SOME (e1‚Äô,s‚Äô)=>SOME(App(e1‚Äô,e2),s‚Äô)
| NONE => NONE ))
Slide 141
Implementation ‚Äì Type Inference
type typeEnv
= (loc*type loc) list * type expr list
inftype gamma (Var n) = nth (#2 gamma) n
inftype gamma (Fn (t,e))
= (case inftype (#1 gamma, t::(#2 gamma)) e of
SOME t‚Äô => SOME (func(t,t‚Äô) )
| NONE => NONE )
inftype gamma (App (e1,e2))
= (case (inftype gamma e1, inftype gamma e2) of
(SOME (func(t1,t1‚Äô)), SOME t2) =>
if t1=t2 then SOME t1‚Äô else NONE
|
=> NONE )
62

Slide 142
Implementation ‚Äì Closures
Naively implementing substitution is expensive. An efÔ¨Åcient
implementation would use closures instead ‚Äì cf. Compiler Construction.
We could give a more concrete semantics, closer to implementation, in
terms of closures, and then prove it corresponds to the original
semantics...
(if you get that wrong, you end up with dynamic scoping, as in original
LISP)
Slide 143
Aside: Small-step vs Big-step Semantics
Throughout this course we use small-step semantics, ‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©.
There is an alternative style, of big-step semantics ‚ü®e, s‚ü©‚áì‚ü®v, s‚Ä≤‚ü©, for
example
‚ü®n, s‚ü©‚áì‚ü®n, s‚ü©
‚ü®e1, s‚ü©‚áì‚ü®n1, s‚Ä≤‚ü©
‚ü®e2, s‚Ä≤‚ü©‚áì‚ü®n2, s‚Ä≤‚Ä≤‚ü©
‚ü®e1 + e2, s‚ü©‚áì‚ü®n, s‚Ä≤‚Ä≤‚ü©
n = n1 + n2
(see the notes from earlier courses by Andy Pitts).
For sequential languages, it doesn‚Äôt make a major difference. When we
come to add concurrency, small-step is more convenient.
63

4.6
L2: Collected DeÔ¨Ånition
Syntax
Booleans b ‚ààB = {true, false}
Integers n ‚ààZ = {..., ‚àí1, 0, 1, ...}
Locations ‚Ñì‚ààL = {l, l0, l1, l2, ...}
Variables x ‚ààX for a set X = {x, y, z, ...}
Operations op ::= + |‚â•
Types
T
::=
int | bool | unit | T1 ‚ÜíT2
Tloc
::=
intref
Expressions
e
::=
n | b | e1 op e2 | if e1 then e2 else e3 |
‚Ñì:= e |!‚Ñì|
skip | e1; e2 |
while e1 do e2|
fn x:T ‚áíe | e1 e2 | x|
let val x:T = e1 in e2 end|
let val rec x:T1 ‚ÜíT2 = (fn y:T1 ‚áíe1) in e2 end
In expressions fn x:T ‚áíe the x is a binder.
In expressions let val x:T = e1 in e2 end
the x is a binder.
In expressions let val rec x:T1 ‚ÜíT2 = (fn y:T1 ‚áíe1) in e2 end the
y binds in e1; the x binds in (fn y:T ‚áíe1) and in e2.
Operational Semantics
Say stores s are Ô¨Ånite partial functions from L to Z.
Values v ::= b | n | skip | fn x:T ‚áíe
(op +)
‚ü®n1 + n2, s‚ü©‚àí‚Üí‚ü®n, s‚ü©
if n = n1 + n2
(op ‚â•)
‚ü®n1 ‚â•n2, s‚ü©‚àí‚Üí‚ü®b, s‚ü©
if b = (n1 ‚â•n2)
(op1)
‚ü®e1, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
1, s‚Ä≤‚ü©
‚ü®e1 op e2, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
1 op e2, s‚Ä≤‚ü©
(op2)
‚ü®e2, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
2, s‚Ä≤‚ü©
‚ü®v op e2, s‚ü©‚àí‚Üí‚ü®v op e‚Ä≤
2, s‚Ä≤‚ü©
(deref)
‚ü®!‚Ñì, s‚ü©‚àí‚Üí‚ü®n, s‚ü©
if ‚Ñì‚ààdom(s) and s(‚Ñì) = n
(assign1)
‚ü®‚Ñì:= n, s‚ü©‚àí‚Üí‚ü®skip, s + {‚Ñì7‚Üín}‚ü©
if ‚Ñì‚ààdom(s)
(assign2)
‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©
‚ü®‚Ñì:= e, s‚ü©‚àí‚Üí‚ü®‚Ñì:= e‚Ä≤, s‚Ä≤‚ü©
(seq1)
‚ü®skip; e2, s‚ü©‚àí‚Üí‚ü®e2, s‚ü©
(seq2)
‚ü®e1, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
1, s‚Ä≤‚ü©
‚ü®e1; e2, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
1; e2, s‚Ä≤‚ü©
64

(if1)
‚ü®if true then e2 else e3, s‚ü©‚àí‚Üí‚ü®e2, s‚ü©
(if2)
‚ü®if false then e2 else e3, s‚ü©‚àí‚Üí‚ü®e3, s‚ü©
(if3)
‚ü®e1, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
1, s‚Ä≤‚ü©
‚ü®if e1 then e2 else e3, s‚ü©‚àí‚Üí‚ü®if e‚Ä≤
1 then e2 else e3, s‚Ä≤‚ü©
(while)
‚ü®while e1 do e2, s‚ü©‚àí‚Üí‚ü®if e1 then (e2; while e1 do e2) else skip, s‚ü©
(app1)
‚ü®e1, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
1, s‚Ä≤‚ü©
‚ü®e1 e2, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
1 e2, s‚Ä≤‚ü©
(app2)
‚ü®e2, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
2, s‚Ä≤‚ü©
‚ü®v e2, s‚ü©‚àí‚Üí‚ü®v e‚Ä≤
2, s‚Ä≤‚ü©
(fn)
‚ü®(fn x:T ‚áíe) v, s‚ü©‚àí‚Üí‚ü®{v/x}e, s‚ü©
(let1)
‚ü®e1, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
1, s‚Ä≤‚ü©
‚ü®let val x:T = e1 in e2 end, s‚ü©‚àí‚Üí‚ü®let val x:T = e‚Ä≤
1 in e2 end, s‚Ä≤‚ü©
(let2)
‚ü®let val x:T = v in e2 end, s‚ü©‚àí‚Üí‚ü®{v/x}e2, s‚ü©
(letrecfn)
let val rec x:T1 ‚ÜíT2 = (fn y:T1 ‚áíe1) in e2 end
‚àí‚Üí
{(fn y:T1 ‚áílet val rec x:T1 ‚ÜíT2 = (fn y:T1 ‚áíe1) in e1 end)/x}e2
Typing
Type environments, Œì ‚ààTypeEnv2, are Ô¨Ånite partial functions from L ‚à™X to Tloc ‚à™T
such that
‚àÄ‚Ñì‚ààdom(Œì).Œì(‚Ñì) ‚ààTloc
‚àÄx ‚ààdom(Œì).Œì(x) ‚ààT
(int)
Œì ‚ä¢n:int
for n ‚ààZ
(bool)
Œì ‚ä¢b:bool
for b ‚àà{true, false}
(op +)
Œì ‚ä¢e1:int
Œì ‚ä¢e2:int
Œì ‚ä¢e1 + e2:int
(op ‚â•)
Œì ‚ä¢e1:int
Œì ‚ä¢e2:int
Œì ‚ä¢e1 ‚â•e2:bool
(if)
Œì ‚ä¢e1:bool
Œì ‚ä¢e2:T
Œì ‚ä¢e3:T
Œì ‚ä¢if e1 then e2 else e3:T
(assign)
Œì(‚Ñì) = intref
Œì ‚ä¢e:int
Œì ‚ä¢‚Ñì:= e:unit
(deref)
Œì(‚Ñì) = intref
Œì ‚ä¢!‚Ñì:int
65

(skip)
Œì ‚ä¢skip:unit
(seq)
Œì ‚ä¢e1:unit
Œì ‚ä¢e2:T
Œì ‚ä¢e1; e2:T
(while)
Œì ‚ä¢e1:bool
Œì ‚ä¢e2:unit
Œì ‚ä¢while e1 do e2:unit
(var)
Œì ‚ä¢x:T
if Œì(x) = T
(fn)
Œì, x:T ‚ä¢e:T ‚Ä≤
Œì ‚ä¢fn x:T ‚áíe : T ‚ÜíT ‚Ä≤
(app)
Œì ‚ä¢e1:T ‚ÜíT ‚Ä≤
Œì ‚ä¢e2:T
Œì ‚ä¢e1 e2:T ‚Ä≤
(let)
Œì ‚ä¢e1:T
Œì, x:T ‚ä¢e2:T ‚Ä≤
Œì ‚ä¢let val x:T = e1 in e2 end:T ‚Ä≤
(let rec fn)
Œì, x:T1 ‚ÜíT2, y:T1 ‚ä¢e1:T2
Œì, x:T1 ‚ÜíT2 ‚ä¢e2:T
Œì ‚ä¢let val rec x:T1 ‚ÜíT2 = (fn y:T1 ‚áíe1) in e2 end:T
66

4.7
Exercises
Exercise 18 ‚ãÜWhat are the free variables of the following?
1. x + ((fn y:int ‚áíz) 2)
2. x + (fn y:int ‚áíz)
3. fn y:int ‚áífn y:int ‚áífn y:int ‚áíy
4. !l0
5. while !l0 ‚â•y do l0 := x
Draw their abstract syntax trees (up to alpha equivalence).
Exercise 19 ‚ãÜWhat are the results of the following substitutions?
1. {fn x:int ‚áíy/z}fn y:int ‚áíz y
2. {fn x:int ‚áíx/x}fn y:int ‚áíx y
3. {fn x:int ‚áíx/x}fn x:int ‚áíx x
Exercise 20 ‚ãÜGive typing derivations, or show why no derivation exists, for:
1. if 6 then 7 else 8
2. fn x:int ‚áíx + (fn x:bool ‚áíif x then 3 else 4)true
Exercise 21 ‚ãÜ‚ãÜGive a grammar for types, and typing rules for functions and application,
that allow only Ô¨Årst-order functions and prohibit partial applications (see page 47).
Exercise 22 ‚ãÜ‚ãÜWrite a function of type unit ‚Üíbool that, when applied to skip, returns
true in the CBV semantics and false in the CBN semantics. Is it possible to do it without
using the store?
Exercise 23 ‚ãÜ‚ãÜProve Lemma 17 (Substitution).
Exercise 24 ‚ãÜ‚ãÜProve Theorem 16 (Type Preservation).
Exercise 25 ‚ãÜ‚ãÜAdapt the L2 implementation to CBN functions. Think of a few good test
cases and check them in the new and old code.
Exercise 26 ‚ãÜ‚ãÜ‚ãÜRe-implement the L2 interpreter to use closures instead of substitution.
67

5
Data
Slide 144
Data ‚Äì L3
So far we have only looked at very simple basic data types ‚Äì int, bool, and unit, and functions
over them. We now explore more structured data, in as simple a form as possible, and revisit
the semantics of mutable store.
5.1
Products and sums
The two basic notions are the product and the sum type.
The product type T1 ‚àóT2 lets you tuple together values of types T1 and T2 ‚Äì so for example
a function that takes an integer and returns a pair of an integer and a boolean has type
int ‚Üí(int ‚àóbool). In C one has structs; in Java classes can have many Ô¨Åelds.
The sum type T1 + T2 lets you form a disjoint union, with a value of the sum type either
being a value of type T1 or a value of type T2. In C one has unions; in Java one might
have many subclasses of a class (see the l1.java representation of the L1 abstract syntax,
for example).
In most languages these appear in richer forms, e.g. with labelled records rather than simple
products, or labelled variants, or ML datatypes with named constructors, rather than simple
sums.
We‚Äôll look at labelled records in detail, as a preliminary to the later lecture on
subtyping.
Many languages don‚Äôt allow structured data types to appear in arbitrary positions ‚Äì e.g. the
old C lack of support for functions that return structured values, inherited from close-to-
the-metal early implementations. They might therefore have to have functions or methods
that take a list of arguments, rather than a single argument that could be of product (or
sum, or record) type.
Slide 145
Products
T
::=
... | T1 ‚àóT2
e
::=
... | (e1, e2) | #1 e | #2 e
Design choices:
‚Ä¢ pairs, not arbitrary tuples ‚Äì have int ‚àó(int ‚àóint) and (int ‚àóint) ‚àóint, but (a) they‚Äôre
diÔ¨Äerent, and (b) we don‚Äôt have (int ‚àóint ‚àóint). In a full language you‚Äôd likely allow
(b) (and still have it be a diÔ¨Äerent type from the other two).
‚Ä¢ have projections #1 and #2, not pattern matching fn (x, y) ‚áíe. A full language
should allow the latter, as it often makes for much more elegant code.
‚Ä¢ don‚Äôt have #e e‚Ä≤ (couldn‚Äôt typecheck!).
68

Slide 146
Products ‚Äì typing
(pair)
Œì ‚ä¢e1:T1
Œì ‚ä¢e2:T2
Œì ‚ä¢(e1, e2):T1 ‚àóT2
(proj1)
Œì ‚ä¢e:T1 ‚àóT2
Œì ‚ä¢#1 e:T1
(proj2)
Œì ‚ä¢e:T1 ‚àóT2
Œì ‚ä¢#2 e:T2
Slide 147
Products ‚Äì reduction
v
::=
... | (v1, v2)
(pair1)
‚ü®e1, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
1, s‚Ä≤‚ü©
‚ü®(e1, e2), s‚ü©‚àí‚Üí‚ü®(e‚Ä≤
1, e2), s‚Ä≤‚ü©
(pair2)
‚ü®e2, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
2, s‚Ä≤‚ü©
‚ü®(v1, e2), s‚ü©‚àí‚Üí‚ü®(v1, e‚Ä≤
2), s‚Ä≤‚ü©
(proj1)
‚ü®#1(v1, v2), s‚ü©‚àí‚Üí‚ü®v1, s‚ü©
(proj2)
‚ü®#2(v1, v2), s‚ü©‚àí‚Üí‚ü®v2, s‚ü©
(proj3)
‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©
‚ü®#1 e, s‚ü©‚àí‚Üí‚ü®#1 e‚Ä≤, s‚Ä≤‚ü©
(proj4)
‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©
‚ü®#2 e, s‚ü©‚àí‚Üí‚ü®#2 e‚Ä≤, s‚Ä≤‚ü©
We have chosen left-to-right evaluation order for consistency.
Slide 148
Sums (or Variants, or Tagged Unions)
T
::=
... | T1 + T2
e
::=
... | inl e:T | inr e:T |
case e of inl (x1:T1) ‚áíe1 | inr (x2:T2) ‚áíe2
Those xs are binders, treated up to alpha-equivalence.
Here we diverge slightly from Moscow ML syntax ‚Äì our T1 + T2 corresponds to the Moscow
ML (T1,T2) Sum in the context of the declaration
datatype (‚Äôa,‚Äôb) Sum = inl of ‚Äôa | inr of ‚Äôb;
Slide 149
Sums ‚Äì typing
(inl)
Œì ‚ä¢e:T1
Œì ‚ä¢inl e:T1 + T2:T1 + T2
(inr)
Œì ‚ä¢e:T2
Œì ‚ä¢inr e:T1 + T2:T1 + T2
(case)
Œì ‚ä¢e:T1 + T2
Œì, x:T1 ‚ä¢e1:T
Œì, y:T2 ‚ä¢e2:T
Œì ‚ä¢case e of inl (x:T1) ‚áíe1 | inr (y:T2) ‚áíe2:T
69

Slide 150
Sums ‚Äì type annotations
case e of inl (x1:T1) ‚áíe1 | inr (x2:T2) ‚áíe2
Why do we have these type annotations?
To maintain the unique typing property. Otherwise
inl 3:int + int
and
inl 3:int + bool
You might instead have a compiler use a type inference algorithm that can infer them,
or require every sum type in a program to be declared, each with diÔ¨Äerent names for the
constructors inl , inr (cf OCaml).
Slide 151
Sums ‚Äì reduction
v
::=
... | inl v:T | inr v:T
(inl)
‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©
‚ü®inl e:T, s‚ü©‚àí‚Üí‚ü®inl e‚Ä≤:T, s‚Ä≤‚ü©
(case1)
‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©
‚ü®case e of inl (x:T1) ‚áíe1 | inr (y:T2) ‚áíe2, s‚ü©
‚àí‚Üí‚ü®case e‚Ä≤ of inl (x:T1) ‚áíe1 | inr (y:T2) ‚áíe2, s‚Ä≤‚ü©
(case2)
‚ü®case inl v:T of inl (x:T1) ‚áíe1 | inr (y:T2) ‚áíe2, s‚ü©
‚àí‚Üí‚ü®{v/x}e1, s‚ü©
(inr) and (case3) like (inl) and (case2)
(inr)
‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©
‚ü®inr e:T, s‚ü©‚àí‚Üí‚ü®inr e‚Ä≤:T, s‚Ä≤‚ü©
(case3)
‚ü®case inr v:T of inl (x:T1) ‚áíe1 | inr (y:T2) ‚áíe2, s‚ü©
‚àí‚Üí‚ü®{v/y}e2, s‚ü©
Slide 152
Constructors and Destructors
type
constructors
destructors
T ‚ÜíT
fn x:T ‚áí
e
T ‚àóT
( , )
#1
#2
T + T
inl ( )
inr ( )
case
bool
true
false
if
70

Slide 153
Proofs as programs: The Curry-Howard correspondence
(var)
Œì, x:T ‚ä¢x:T
(fn)
Œì, x:T ‚ä¢e:T ‚Ä≤
Œì ‚ä¢fn x:T ‚áíe : T ‚ÜíT ‚Ä≤
(app)
Œì ‚ä¢e1:T ‚ÜíT ‚Ä≤
Œì ‚ä¢e2:T
Œì ‚ä¢e1 e2:T ‚Ä≤
Œì, P ‚ä¢P
Œì, P ‚ä¢P ‚Ä≤
Œì ‚ä¢P ‚ÜíP ‚Ä≤
Œì ‚ä¢P ‚ÜíP ‚Ä≤
Œì ‚ä¢P
Œì ‚ä¢P ‚Ä≤
Slide 154
Proofs as programs: The Curry-Howard correspondence
(var)
Œì, x:T ‚ä¢x:T
(fn)
Œì, x:T ‚ä¢e:T ‚Ä≤
Œì ‚ä¢fn x:T ‚áíe : T ‚ÜíT ‚Ä≤
(app)
Œì ‚ä¢e1:T ‚ÜíT ‚Ä≤
Œì ‚ä¢e2:T
Œì ‚ä¢e1 e2:T ‚Ä≤
(pair)
Œì ‚ä¢e1:T1
Œì ‚ä¢e2:T2
Œì ‚ä¢(e1, e2):T1 ‚àóT2
(proj1)
Œì ‚ä¢e:T1 ‚àóT2
Œì ‚ä¢#1 e:T1
(proj2)
Œì ‚ä¢e:T1 ‚àóT2
Œì ‚ä¢#2 e:T2
(inl)
Œì ‚ä¢e:T1
Œì ‚ä¢inl e:T1 + T2:T1 + T2
(inr), (case), (unit), (zero), etc.. ‚Äì but not (letrec)
Œì, P ‚ä¢P
Œì, P ‚ä¢P‚Ä≤
Œì ‚ä¢P ‚ÜíP‚Ä≤
Œì ‚ä¢P ‚ÜíP‚Ä≤
Œì ‚ä¢P
Œì ‚ä¢P‚Ä≤
Œì ‚ä¢P1
Œì ‚ä¢P2
Œì ‚ä¢P1 ‚àßP2
Œì ‚ä¢P1 ‚àßP2
Œì ‚ä¢P1
Œì ‚ä¢P1 ‚àßP2
Œì ‚ä¢P2
Œì ‚ä¢P1
Œì ‚ä¢P1 ‚à®P2
The typing rules for a pure language correspond to the rules for a natural deduction calculus.
5.2
Datatypes and Records
Slide 155
ML Datatypes
Datatypes in ML generalize both sums and products, in a sense
datatype IntList = Null of unit
| Cons of Int * IntList
is (roughly!) like saying
IntList = unit + (Int * IntList)
In L3 you cannot deÔ¨Åne IntList. It involves recursion at the type level (e.g. types for binary
trees). Making this precise is beyond the scope of this course.
71

Slide 156
Records
A generalization of products.
Take Ô¨Åeld labels
Labels lab ‚ààLAB for a set LAB = {p, q, ...}
T
::=
... | {lab1:T1, .., labk:Tk}
e
::=
... | {lab1 = e1, .., labk = ek} | #lab e
(where in each record (type or expression) no lab occurs more than once)
Note:
‚Ä¢ Labels are not the same syntactic class as variables, so (fn x:T ‚áí{x = 3}) is not an
expression.
‚Ä¢ In ML a pair (true, fn x:int ‚áíx) is syntactic sugar for a record {1 = true, 2 = fn x:int ‚áíx}.
‚Ä¢ Note that #lab e is not an application, it just looks like one in the concrete syntax.
‚Ä¢ Again we will choose a left-to-right evaluation order for consistency.
Slide 157
Records ‚Äì typing
(record)
Œì ‚ä¢e1:T1
..
Œì ‚ä¢ek:Tk
Œì ‚ä¢{lab1 = e1, .., labk = ek}:{lab1:T1, .., labk:Tk}
(recordproj)
Œì ‚ä¢e:{lab1:T1, .., labk:Tk}
Œì ‚ä¢#labi e:Ti
‚Ä¢ Here the Ô¨Åeld order matters, so (fn x:{‚Ñì1:int, ‚Ñì2:bool} ‚áíx){‚Ñì2 = true, ‚Ñì1 = 17} does
not typecheck.
‚Ä¢ Here you can reuse labels, so {} ‚ä¢({‚Ñì1 = 17}, {‚Ñì1 = true}):{‚Ñì1:int} ‚àó{‚Ñì1:bool} is legal,
but in some languages (e.g. OCaml) you can‚Äôt.
Slide 158
Records ‚Äì reduction
v
::=
... | {lab1 = v1, .., labk = vk}
(record1)
‚ü®ei, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
i, s‚Ä≤‚ü©
‚ü®{lab1 = v1, .., labi = ei, .., labk = ek}, s‚ü©
‚àí‚Üí‚ü®{lab1 = v1, .., labi = e‚Ä≤
i, .., labk = ek}, s‚Ä≤‚ü©
(record2)
‚ü®#labi {lab1 = v1, .., labk = vk}, s‚ü©‚àí‚Üí‚ü®vi, s‚ü©
(record3)
‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©
‚ü®#labi e, s‚ü©‚àí‚Üí‚ü®#labi e‚Ä≤, s‚Ä≤‚ü©
72

5.3
Mutable Store
Slide 159
Mutable Store
Most languages have some kind of mutable store. Two main choices:
1 What we‚Äôve got in L1 and L2:
e
::=
... | ‚Ñì:= e |!‚Ñì| x
‚Ä¢ locations store mutable values
‚Ä¢ variables refer to a previously-calculated value, immutably
‚Ä¢ explicit dereferencing and assignment operators for locations
fn x:int ‚áíl := (!l) + x
Slide 160
2 In C and Java,
‚Ä¢ variables let you refer to a previously calculated value and let you
overwrite that value with another.
‚Ä¢ implicit dereferencing,
void foo(x:int) {
l = l + x
...}
‚Ä¢ have some limited type machinery to limit mutability.
‚Äì pros and cons: ....
We are staying with option 1 here. But we will now overcome some limitations of references
in L1/L2:
‚Ä¢ can only store ints ‚Äì we would like to store any value
‚Ä¢ cannot create new locations (all must exist at beginning)
‚Ä¢ cannot write functions that abstract on locations fn l:intref ‚áí!l
Slide 161
References
T
::=
... | T ref
Tloc
::=
intref T ref
e
::=
... | ‚Ñì:= e | !‚Ñì
| e1 := e2 |!e | ref e | ‚Ñì
We are now allowing variables of T ref type, e.g.fn x:int ref ‚áí!x. Whole programs should
now have no locations at the start. They should create new locations with ref.
73

Slide 162
References ‚Äì Typing
(ref)
Œì ‚ä¢e:T
Œì ‚ä¢ref e : T ref
(assign)
Œì ‚ä¢e1:T ref
Œì ‚ä¢e2:T
Œì ‚ä¢e1 := e2:unit
(deref)
Œì ‚ä¢e:T ref
Œì ‚ä¢!e:T
(loc)
Œì(‚Ñì) = T ref
Œì ‚ä¢‚Ñì:T ref
Slide 163
References ‚Äì Reduction
A location is a value:
v
::=
... | ‚Ñì
Stores s were Ô¨Ånite partial maps from L to Z. From now on, take them to
be Ô¨Ånite partial maps from L to the set of all values.
(ref1)
‚ü®ref v, s‚ü©‚àí‚Üí‚ü®‚Ñì, s + {‚Ñì7‚Üív}‚ü©
‚Ñì/‚ààdom(s)
(ref2)
‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©
‚ü®ref e, s‚ü©‚àí‚Üí‚ü®ref e‚Ä≤, s‚Ä≤‚ü©
Slide 164
(deref1)
‚ü®!‚Ñì, s‚ü©‚àí‚Üí‚ü®v, s‚ü©
if ‚Ñì‚ààdom(s) and s(‚Ñì) = v
(deref2)
‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©
‚ü®!e, s‚ü©‚àí‚Üí‚ü®!e‚Ä≤, s‚Ä≤‚ü©
(assign1)
‚ü®‚Ñì:= v, s‚ü©‚àí‚Üí‚ü®skip, s + {‚Ñì7‚Üív}‚ü©
if ‚Ñì‚ààdom(s)
(assign2)
‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©
‚ü®‚Ñì:= e, s‚ü©‚àí‚Üí‚ü®‚Ñì:= e‚Ä≤, s‚Ä≤‚ü©
(assign3)
‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©
‚ü®e := e2, s‚ü©‚àí‚Üí‚ü®e‚Ä≤ := e2, s‚Ä≤‚ü©
‚Ä¢ A ref has to do something at runtime ‚Äì ( ref 0, ref 0) should return a pair of two new
locations, each containing 0, not a pair of one location repeated.
‚Ä¢ Note the typing and this dynamics permit locations to contain locations, e.g. ref( ref 3).
‚Ä¢ This semantics no longer has determinacy, for a technical reason ‚Äì new locations are
chosen arbitrarily. At the cost of some slight semantic complexity, we could regain
determinacy by working ‚Äòup to alpha for locations‚Äô.
‚Ä¢ Within the language you cannot do arithmetic on locations (can in C, can‚Äôt in Java)
or test whether one is bigger than another. In L3 you cannot even test locations for
equality (in ML you can).
‚Ä¢ This store just grows during computation ‚Äì an implementation can garbage collect.
74

We don‚Äôt have an explicit deallocation operation ‚Äì if you do, you need a very baroque
type system to prevent dangling pointers being dereferenced.
Slide 165
Type-checking the store
For L1, our type properties used dom(Œì) ‚äÜdom(s) to express the
condition ‚Äòall locations mentioned in Œì exist in the store s‚Äô.
Now need more: for each ‚Ñì‚ààdom(s) need that s(‚Ñì) is typable.
Moreover, s(‚Ñì) might contain some other locations...
Slide 166
Type-checking the store ‚Äì Example
Consider
e
=
let val x:(int ‚Üíint) ref = ref(fn z:int ‚áíz) in
(x := (fn z:int ‚áíif z ‚â•1 then z + ((!x) (z + ‚àí1)) else 0);
(!x) 3) end
which has reductions
‚ü®e, {}‚ü©‚àí‚Üí‚àó
‚ü®e1, {l1 7‚Üí(fn z:int ‚áíz)}‚ü©‚àí‚Üí‚àó
‚ü®e2, {l1 7‚Üí(fn z:int ‚áíif z ‚â•1 then z + ((!l1) (z + ‚àí1)) else 0)}‚ü©
‚àí‚Üí‚àó‚ü®6, ...‚ü©
For reference, e1 and e2 are
e1
=
l1 := (fn z:int ‚áíif z ‚â•1 then z + ((!l1) (z + ‚àí1)) else 0);
((!l1) 3)
e2
=
skip; ((!l1) 3)
Have made a recursive function by ‚Äòtying the knot by hand‚Äô, not using let val rec . To do
this we needed to store function values. We couldn‚Äôt do this in L2, so this doesn‚Äôt contradict
the normalization theorem we had there.
Slide 167
DeÔ¨Ånition 19 (Well-typed store) Let Œì ‚ä¢s if dom(Œì) = dom(s) and if
for all ‚Ñì‚ààdom(s), if Œì(‚Ñì) = T ref then Œì ‚ä¢s(‚Ñì):T .
Theorem 20 (Progress) If e closed and Œì ‚ä¢e:T and Œì ‚ä¢s then either
e is a value or there exist e‚Ä≤, s‚Ä≤ such that ‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©.
Theorem 21 (Type Preservation) If e closed and Œì ‚ä¢e:T and Œì ‚ä¢s
and ‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©then e‚Ä≤ is closed and for some Œì‚Ä≤ with disjoint
domain to Œì we have Œì, Œì‚Ä≤ ‚ä¢e‚Ä≤:T and Œì, Œì‚Ä≤ ‚ä¢s‚Ä≤.
Theorem 22 (Type Safety) If e closed and Œì ‚ä¢e:T and Œì ‚ä¢s and
‚ü®e, s‚ü©‚àí‚Üí‚àó‚ü®e‚Ä≤, s‚Ä≤‚ü©then either e‚Ä≤ is a value or there exist e‚Ä≤‚Ä≤, s‚Ä≤‚Ä≤ such
that ‚ü®e‚Ä≤, s‚Ä≤‚ü©‚àí‚Üí‚ü®e‚Ä≤‚Ä≤, s‚Ä≤‚Ä≤‚ü©.
Slide 168
Implementation
The collected deÔ¨Ånition so far is in the notes, called L3.
It is again a Moscow ML fragment (modulo the syntax for T + T ), so you
can run programs. The Moscow ML record typing is more liberal than that
of L3, though.
75

5.4
Evaluation Contexts
We end this chapter by showing a slightly diÔ¨Äerent style for deÔ¨Åning operational semantics,
collecting together many of the context rules into a single (eval) rule that uses a deÔ¨Ånition
of a set of evaluation contexts to describe where in your program the next step of reduction
can take place. This style becomes much more convenient for large languages, though for
L1 and L2 there‚Äôs not much advantage either way.
Slide 169
Evaluation Contexts
DeÔ¨Åne evaluation contexts
E
::=
op e | v op
| if
then e else e |
; e |
e | v
|
let val x:T =
in e2 end |
( , e) | (v, ) | #1
| #2
|
inl
:T | inr
:T |
case
of inl (x:T) ‚áíe | inr (x:T) ‚áíe |
{lab1 = v1, .., labi = , .., labk = ek} | #lab
|
:= e | v :=
|! | ref
Slide 170
and have the single context rule
(eval)
‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©
‚ü®E[e], s‚ü©‚àí‚Üí‚ü®E[e‚Ä≤], s‚Ä≤‚ü©
replacing the rules (all those with ‚â•1 premise) (op1), (op2), (seq2), (if3),
(app1), (app2), (let1), (pair1), (pair2), (proj3), (proj4), (inl), (inr), (case1),
(record1), (record3), (ref2), (deref2), (assign2), (assign3).
To (eval) we add all the computation rules (all the rest) (op + ), (op ‚â•),
(seq1), (if1), (if2), (while), (fn), (let2), (letrecfn), (proj1), (proj2), (case2),
(case3), (record2), (ref1), (deref1), (assign1).
Theorem 23 The two deÔ¨Ånitions of ‚àí‚ÜídeÔ¨Åne the same relation.
Slide 171
A Little History
Formal logic
1880‚Äì
Untyped lambda calculus
1930s
Simply-typed lambda calculus
1940s
Fortran
1950s
Curry-Howard, Algol 60, Algol 68, SECD machine (64)
1960s
Pascal, Polymorphism, ML, PLC
1970s
Structured Operational Semantics
1981‚Äì
Standard ML deÔ¨Ånition
1985
Haskell
1987
Subtyping
1980s
Module systems
1980‚Äì
Object calculus
1990‚Äì
Typed assembly and intermediate languages
1990‚Äì
And now? module systems, distribution, mobility, reasoning about objects, security, typed compilation,.......
76

5.5
L3: Collected deÔ¨Ånition
L3 syntax
Booleans b ‚ààB = {true, false}
Integers n ‚ààZ = {..., ‚àí1, 0, 1, ...}
Locations ‚Ñì‚ààL = {l, l0, l1, l2, ...}
Variables x ‚ààX for a set X = {x, y, z, ...}
Labels lab ‚ààLAB for a set LAB = {p, q, ...}
Operations op ::= + |‚â•
Types:
T
::=
int | bool | unit | T1 ‚ÜíT2|T1 ‚àóT2|T1 + T2|{lab1:T1, .., labk:Tk}|T ref
Expressions
e
::=
n | b | e1 op e2 | if e1 then e2 else e3 |
e1 := e2 |!e | ref e | ‚Ñì|
skip | e1; e2 |
while e1 do e2|
fn x:T ‚áíe | e1 e2 | x|
let val x:T = e1 in e2 end|
let val rec x:T1 ‚ÜíT2 = (fn y:T1 ‚áíe1) in e2 end|
(e1, e2) | #1 e | #2 e|
inl e:T | inr e:T |
case e of inl (x1:T1) ‚áíe1 | inr (x2:T2) ‚áíe2|
{lab1 = e1, .., labk = ek} | #lab e
(where in each record (type or expression) no lab occurs more than once)
In expressions fn x:T ‚áíe the x is a binder.
In expressions let val x:T = e1 in e2 end
the x is a binder.
In expressions let val rec x:T1 ‚ÜíT2 = (fn y:T1 ‚áíe1) in e2 end
the y binds in e1; the x binds in (fn y:T ‚áíe1) and in e2. In case e of inl (x1:T1) ‚áíe1 |
inr (x2:T2) ‚áíe2 the x1 binds in e1 and the x2 binds in e2.
L3 semantics
Stores s are Ô¨Ånite partial maps from L to the set of all values.
Values v ::= b | n | skip | fn x:T ‚áíe|(v1, v2)|inl v:T | inr v:T|{lab1 = v1, .., labk = vk}|‚Ñì
(op +)
‚ü®n1 + n2, s‚ü©‚àí‚Üí‚ü®n, s‚ü©
if n = n1 + n2
(op ‚â•)
‚ü®n1 ‚â•n2, s‚ü©‚àí‚Üí‚ü®b, s‚ü©
if b = (n1 ‚â•n2)
(op1)
‚ü®e1, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
1, s‚Ä≤‚ü©
‚ü®e1 op e2, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
1 op e2, s‚Ä≤‚ü©
(op2)
‚ü®e2, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
2, s‚Ä≤‚ü©
‚ü®v op e2, s‚ü©‚àí‚Üí‚ü®v op e‚Ä≤
2, s‚Ä≤‚ü©
(seq1)
‚ü®skip; e2, s‚ü©‚àí‚Üí‚ü®e2, s‚ü©
(seq2)
‚ü®e1, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
1, s‚Ä≤‚ü©
‚ü®e1; e2, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
1; e2, s‚Ä≤‚ü©
77

(if1)
‚ü®if true then e2 else e3, s‚ü©‚àí‚Üí‚ü®e2, s‚ü©
(if2)
‚ü®if false then e2 else e3, s‚ü©‚àí‚Üí‚ü®e3, s‚ü©
(if3)
‚ü®e1, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
1, s‚Ä≤‚ü©
‚ü®if e1 then e2 else e3, s‚ü©‚àí‚Üí‚ü®if e‚Ä≤
1 then e2 else e3, s‚Ä≤‚ü©
(while)
‚ü®while e1 do e2, s‚ü©‚àí‚Üí‚ü®if e1 then (e2; while e1 do e2) else skip, s‚ü©
(app1)
‚ü®e1, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
1, s‚Ä≤‚ü©
‚ü®e1 e2, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
1 e2, s‚Ä≤‚ü©
(app2)
‚ü®e2, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
2, s‚Ä≤‚ü©
‚ü®v e2, s‚ü©‚àí‚Üí‚ü®v e‚Ä≤
2, s‚Ä≤‚ü©
(fn)
‚ü®(fn x:T ‚áíe) v, s‚ü©‚àí‚Üí‚ü®{v/x}e, s‚ü©
(let1)
‚ü®e1, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
1, s‚Ä≤‚ü©
‚ü®let val x:T = e1 in e2 end, s‚ü©‚àí‚Üí‚ü®let val x:T = e‚Ä≤
1 in e2 end, s‚Ä≤‚ü©
(let2)
‚ü®let val x:T = v in e2 end, s‚ü©‚àí‚Üí‚ü®{v/x}e2, s‚ü©
(letrecfn)
let val rec x:T1 ‚ÜíT2 = (fn y:T1 ‚áíe1) in e2 end
‚àí‚Üí
{(fn y:T1 ‚áílet val rec x:T1 ‚ÜíT2 = (fn y:T1 ‚áíe1) in e1 end)/x}e2
(pair1)
‚ü®e1, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
1, s‚Ä≤‚ü©
‚ü®(e1, e2), s‚ü©‚àí‚Üí‚ü®(e‚Ä≤
1, e2), s‚Ä≤‚ü©
(pair2)
‚ü®e2, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
2, s‚Ä≤‚ü©
‚ü®(v1, e2), s‚ü©‚àí‚Üí‚ü®(v1, e‚Ä≤
2), s‚Ä≤‚ü©
(proj1)
‚ü®#1(v1, v2), s‚ü©‚àí‚Üí‚ü®v1, s‚ü©
(proj2)
‚ü®#2(v1, v2), s‚ü©‚àí‚Üí‚ü®v2, s‚ü©
(proj3)
‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©
‚ü®#1 e, s‚ü©‚àí‚Üí‚ü®#1 e‚Ä≤, s‚Ä≤‚ü©
(proj4)
‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©
‚ü®#2 e, s‚ü©‚àí‚Üí‚ü®#2 e‚Ä≤, s‚Ä≤‚ü©
(inl)
‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©
‚ü®inl e:T, s‚ü©‚àí‚Üí‚ü®inl e‚Ä≤:T, s‚Ä≤‚ü©
(case1)
‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©
‚ü®case e of inl (x:T1) ‚áíe1 | inr (y:T2) ‚áíe2, s‚ü©
‚àí‚Üí‚ü®case e‚Ä≤ of inl (x:T1) ‚áíe1 | inr (y:T2) ‚áíe2, s‚Ä≤‚ü©
(case2)
‚ü®case inl v:T of inl (x:T1) ‚áíe1 | inr (y:T2) ‚áíe2, s‚ü©
‚àí‚Üí‚ü®{v/x}e1, s‚ü©
(inr) and (case3) like (inl) and (case2)
78

(inr)
‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©
‚ü®inr e:T, s‚ü©‚àí‚Üí‚ü®inr e‚Ä≤:T, s‚Ä≤‚ü©
(case3)
‚ü®case inr v:T of inl (x:T1) ‚áíe1 | inr (y:T2) ‚áíe2, s‚ü©
‚àí‚Üí‚ü®{v/y}e2, s‚ü©
(record1)
‚ü®ei, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
i, s‚Ä≤‚ü©
‚ü®{lab1 = v1, .., labi = ei, .., labk = ek}, s‚ü©
‚àí‚Üí‚ü®{lab1 = v1, .., labi = e‚Ä≤
i, .., labk = ek}, s‚Ä≤‚ü©
(record2)
‚ü®#labi {lab1 = v1, .., labk = vk}, s‚ü©‚àí‚Üí‚ü®vi, s‚ü©
(record3)
‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©
‚ü®#labi e, s‚ü©‚àí‚Üí‚ü®#labi e‚Ä≤, s‚Ä≤‚ü©
(ref1)
‚ü®ref v, s‚ü©‚àí‚Üí‚ü®‚Ñì, s + {‚Ñì7‚Üív}‚ü©
‚Ñì/‚ààdom(s)
(ref2)
‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©
‚ü®ref e, s‚ü©‚àí‚Üí‚ü®ref e‚Ä≤, s‚Ä≤‚ü©
(deref1)
‚ü®!‚Ñì, s‚ü©‚àí‚Üí‚ü®v, s‚ü©
if ‚Ñì‚ààdom(s) and s(‚Ñì) = v
(deref2)
‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©
‚ü®!e, s‚ü©‚àí‚Üí‚ü®!e‚Ä≤, s‚Ä≤‚ü©
(assign1)
‚ü®‚Ñì:= v, s‚ü©‚àí‚Üí‚ü®skip, s + {‚Ñì7‚Üív}‚ü©
if ‚Ñì‚ààdom(s)
(assign2)
‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©
‚ü®‚Ñì:= e, s‚ü©‚àí‚Üí‚ü®‚Ñì:= e‚Ä≤, s‚Ä≤‚ü©
(assign3)
‚ü®e, s‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤‚ü©
‚ü®e := e2, s‚ü©‚àí‚Üí‚ü®e‚Ä≤ := e2, s‚Ä≤‚ü©
L3 Typing
Type environments, Œì ‚ààTypeEnv2, are Ô¨Ånite partial functions from L ‚à™X to Tloc ‚à™T
such that
‚àÄ‚Ñì‚ààdom(Œì).Œì(‚Ñì) ‚ààTloc
‚àÄx ‚ààdom(Œì).Œì(x) ‚ààT
(int)
Œì ‚ä¢n:int
for n ‚ààZ
(bool)
Œì ‚ä¢b:bool
for b ‚àà{true, false}
(op +)
Œì ‚ä¢e1:int
Œì ‚ä¢e2:int
Œì ‚ä¢e1 + e2:int
(op ‚â•)
Œì ‚ä¢e1:int
Œì ‚ä¢e2:int
Œì ‚ä¢e1 ‚â•e2:bool
(if)
Œì ‚ä¢e1:bool
Œì ‚ä¢e2:T
Œì ‚ä¢e3:T
Œì ‚ä¢if e1 then e2 else e3:T
79

(skip)
Œì ‚ä¢skip:unit
(seq)
Œì ‚ä¢e1:unit
Œì ‚ä¢e2:T
Œì ‚ä¢e1; e2:T
(while)
Œì ‚ä¢e1:bool
Œì ‚ä¢e2:unit
Œì ‚ä¢while e1 do e2:unit
(var)
Œì ‚ä¢x:T
if Œì(x) = T
(fn)
Œì, x:T ‚ä¢e:T ‚Ä≤
Œì ‚ä¢fn x:T ‚áíe : T ‚ÜíT ‚Ä≤
(app)
Œì ‚ä¢e1:T ‚ÜíT ‚Ä≤
Œì ‚ä¢e2:T
Œì ‚ä¢e1 e2:T ‚Ä≤
(let)
Œì ‚ä¢e1:T
Œì, x:T ‚ä¢e2:T ‚Ä≤
Œì ‚ä¢let val x:T = e1 in e2 end:T ‚Ä≤
(let rec fn)
Œì, x:T1 ‚ÜíT2, y:T1 ‚ä¢e1:T2
Œì, x:T1 ‚ÜíT2 ‚ä¢e2:T
Œì ‚ä¢let val rec x:T1 ‚ÜíT2 = (fn y:T1 ‚áíe1) in e2 end:T
(pair)
Œì ‚ä¢e1:T1
Œì ‚ä¢e2:T2
Œì ‚ä¢(e1, e2):T1 ‚àóT2
(proj1)
Œì ‚ä¢e:T1 ‚àóT2
Œì ‚ä¢#1 e:T1
(proj2)
Œì ‚ä¢e:T1 ‚àóT2
Œì ‚ä¢#2 e:T2
(inl)
Œì ‚ä¢e:T1
Œì ‚ä¢inl e:T1 + T2:T1 + T2
(inr)
Œì ‚ä¢e:T2
Œì ‚ä¢inr e:T1 + T2:T1 + T2
(case)
Œì ‚ä¢e:T1 + T2
Œì, x:T1 ‚ä¢e1:T
Œì, y:T2 ‚ä¢e2:T
Œì ‚ä¢case e of inl (x:T1) ‚áíe1 | inr (y:T2) ‚áíe2:T
(record)
Œì ‚ä¢e1:T1
..
Œì ‚ä¢ek:Tk
Œì ‚ä¢{lab1 = e1, .., labk = ek}:{lab1:T1, .., labk:Tk}
(recordproj)
Œì ‚ä¢e:{lab1:T1, .., labk:Tk}
Œì ‚ä¢#labi e:Ti
80

(ref)
Œì ‚ä¢e:T
Œì ‚ä¢ref e : T ref
(assign)
Œì ‚ä¢e1:T ref
Œì ‚ä¢e2:T
Œì ‚ä¢e1 := e2:unit
(deref)
Œì ‚ä¢e:T ref
Œì ‚ä¢!e:T
(loc)
Œì(‚Ñì) = T ref
Œì ‚ä¢‚Ñì:T ref
5.6
Exercises
Exercise 27 ‚ãÜ‚ãÜProve Theorem 14: Type Preservation for L3.
Exercise 28 ‚ãÜ‚ãÜLabelled variant types are a generalization of sum types, just as records
are a generalization of products. Design abstract syntax, type rules and evaluation rules for
labelled variants, analogously to the way in which records generalise products.
Exercise 29 ‚ãÜ‚ãÜDesign type rules and evaluation rules for ML-style exceptions.
Start
with exceptions that do not carry any values. Hint 1: take care with nested handlers within
recursive functions. Hint 2: you might want to express your semantics using evaluation
contexts.
Exercise 30 ‚ãÜ‚ãÜ‚ãÜExtend the L2 implementation to cover all of L3.
81

6
Subtyping and Objects
Slide 172
Subtyping and Objects
Our type systems so far would all be annoying to use, as they‚Äôre quite rigid (Pascal-like).
There is little support for code reuse, so you would have to have diÔ¨Äerent sorting code for,
e.g., int lists and int ‚àóint lists.
Slide 173
Polymorphism
Ability to use expressions at many different types.
‚Ä¢ Ad-hoc polymorphism (overloading).
e.g. in Moscow ML the built-in + can be used to add two integers or to
add two reals. (see Haskell type classes)
‚Ä¢ Parametric Polymorphism ‚Äì as in ML. See the Part II Types course.
can write a function that for any type Œ± takes an argument of type
Œ± list and computes its length (parametric ‚Äì uniform in whatever Œ± is)
‚Ä¢ Subtype polymorphism ‚Äì as in various OO languages. See here.
Dating back to the 1960s (Simula etc); formalized in 1980,1984,...
Slide 174
Subtyping ‚Äì Motivation
Recall
(app)
Œì ‚ä¢e1:T ‚ÜíT ‚Ä≤
Œì ‚ä¢e2:T
Œì ‚ä¢e1 e2:T ‚Ä≤
so can‚Äôt type
Ã∏‚ä¢(fn x:{p:int} ‚áí#p x) {p = 3, q = 4} : int
even though we‚Äôre giving the function a better argument, with more
structure, than it needs.
82

Slide 175
Subsumption
‚ÄòBetter‚Äô? Any value of type {p:int, q:int} can be used wherever a value
of type {p:int} is expected. (*)
Introduce a subtyping relation between types, written T <: T ‚Ä≤, read as
T is a subtype of T ‚Ä≤ (a T is useful in more contexts than a T ‚Ä≤ ).
Will deÔ¨Åne it on the next slides, but it will include
{p:int, q:int} <: {p:int} <: {}
Introduce a subsumption rule
(sub)
Œì ‚ä¢e:T
T <: T ‚Ä≤
Œì ‚ä¢e:T ‚Ä≤
allowing subtyping to be used, capturing (*).
Can then deduce {p = 3, q = 4}:{p:int}, hence can type the example.
Slide 176
Example
x:{p:int} ‚ä¢x:{p:int}
(var)
x:{p:int} ‚ä¢#p x:int
(record-proj)
{} ‚ä¢(fn x:{p:int} ‚áí#p x):{p:int} ‚Üíint
(fn)
{} ‚ä¢3:int
(var)
{} ‚ä¢4:int
(var)
{} ‚ä¢{p = 3,q = 4}:{p:int,q:int}
(record)
(‚ãÜ)
{} ‚ä¢{p = 3,q = 4}:{p:int}
(sub)
{} ‚ä¢(fn x:{p:int} ‚áí#p x){p = 3,q = 4}:int
(app)
where (‚ãÜ) is {p:int, q:int} <: {p:int}
Now, we deÔ¨Åne the subtype relation.
Slide 177
The Subtype Relation T <: T ‚Ä≤
(s-reÔ¨Ç)
T <: T
(s-trans)
T <: T ‚Ä≤
T ‚Ä≤ <: T ‚Ä≤‚Ä≤
T <: T ‚Ä≤‚Ä≤
Slide 178
Subtyping ‚Äì Records
Forgetting Ô¨Åelds on the right:
{lab1:T1, .., labk:Tk, labk+1:Tk+1, .., labk+k‚Ä≤:Tk+k‚Ä≤}
<:
(s-record-width)
{lab1:T1, .., labk:Tk}
Allowing subtyping within Ô¨Åelds:
(s-record-depth)
T1 <: T ‚Ä≤
1
..
Tk <: T ‚Ä≤
k
{lab1:T1, .., labk:Tk} <: {lab1:T ‚Ä≤
1, .., labk:T ‚Ä≤
k}
Combining these:
{p:int, q:int} <: {p:int}
(s-record-width)
{r:int} <: {}
(s-record-width)
{x:{p:int, q:int}, y:{r:int}} <: {x:{p:int}, y:{}}
(s-record-depth)
83

Another example:
{x:{p:int, q:int}, y:{r:int}} <: {x:{p:int, q:int}} (s-rec-w)
{p:int, q:int} <: {p:int} (s-rec-w)
{x:{p:int, q:int}} <: {x:{p:int}} (s-rec-d)
{x:{p:int, q:int}, y:{r:int}} <: {x:{p:int}}
(s-trans)
Slide 179
Allowing reordering of Ô¨Åelds:
(s-record-order)
œÄ a permutation of 1, .., k
{lab1:T1, .., labk:Tk} <: {labœÄ(1):TœÄ(1), .., labœÄ(k):TœÄ(k)}
(the subtype order is not anti-symmetric ‚Äì it is a preorder, not a partial
order)
Slide 180
Subtyping ‚Äì Functions
(s-fn)
T ‚Ä≤
1 <: T1
T2 <: T ‚Ä≤
2
T1 ‚ÜíT2 <: T ‚Ä≤
1 ‚ÜíT ‚Ä≤
2
contravariant on the left of ‚Üí
covariant on the right of ‚Üí(like (s-record-depth))
Slide 181
If f :T1 ‚ÜíT2 then we can give f any argument which is a subtype of
T1; we can regard the result of f as any supertype of T2. e.g., for
f = fn x:{p:int} ‚áí{p = #p x, q = 28}
we have
{} ‚ä¢f :{p:int} ‚Üí{p:int, q:int}
{} ‚ä¢f :{p:int} ‚Üí{p:int}
{} ‚ä¢f :{p:int, q:int} ‚Üí{p:int, q:int}
{} ‚ä¢f :{p:int, q:int} ‚Üí{p:int}
as
{p:int, q:int} <: {p:int}
Slide 182
On the other hand, for
fn x:{p:int, q:int} ‚áí{p = (#p x) + (#q x)}
we have
{} ‚ä¢f :{p:int, q:int} ‚Üí{p:int}
{} Ã∏‚ä¢f :{p:int} ‚ÜíT
for any T
{} Ã∏‚ä¢f :T ‚Üí{p:int, q:int}
for any T
84

Slide 183
Subtyping ‚Äì Products
Just like (s-record-depth)
(s-pair)
T1 <: T ‚Ä≤
1
T2 <: T ‚Ä≤
2
T1 ‚àóT2 <: T ‚Ä≤
1 ‚àóT ‚Ä≤
2
Subtyping ‚Äì Sums
Exercise.
Slide 184
Subtyping ‚Äì References
Are either of these any good?
T <: T ‚Ä≤
T ref <: T ‚Ä≤ ref
T ‚Ä≤ <: T
T ref <: T ‚Ä≤ ref
No...
Slide 185
Semantics
No change (note that we‚Äôve not changed the expression grammar).
Properties
Have Type Preservation and Progress.
Implementation
Type inference is more subtle, as the rules are no longer syntax-directed.
Getting a good runtime implementation is also tricky, especially with Ô¨Åeld
re-ordering.
Slide 186
Subtyping ‚Äì Down-casts
The subsumption rule (sub) permits up-casting at any point. How about
down-casting? We could add
e
::=
... | (T)e
with typing rule
Œì ‚ä¢e:T ‚Ä≤
Œì ‚ä¢(T)e:T
then you need a dynamic type-check...
This gives Ô¨Çexibility, but at the cost of many potential run-time errors.
Many uses might be better handled by Parametric Polymorphism, aka
Generics. (cf. work by Martin Odersky at EPFL, Lausanne, now in Java
1.5)
The following development is taken from [Pierce, Chapter 18], where you can Ô¨Ånd more
details (including a treatment of self and a direct semantics for a ‚Äòfeatherweight‚Äô fragment
of Java).
85

Slide 187
(Very Simple) Objects
let val c:{get:unit ‚Üíint, inc:unit ‚Üíunit} =
let val x:int ref = ref 0 in
{get = fn y:unit ‚áí!x,
inc = fn y:unit ‚áíx := 1+!x}
end
in
(#inc c)(); (#get c)()
end
Counter = {get:unit ‚Üíint, inc:unit ‚Üíunit}.
Slide 188
Using Subtyping
let val c:{get:unit ‚Üíint, inc:unit ‚Üíunit, reset:unit ‚Üíunit} =
let val x:int ref = ref 0 in
{get = fn y:unit ‚áí!x,
inc = fn y:unit ‚áíx := 1+!x,
reset = fn y:unit ‚áíx := 0}
end
in
(#inc c)(); (#get c)()
end
ResetCounter = {get:unit ‚Üíint, inc:unit ‚Üíunit, reset:unit ‚Üíunit}
<: Counter = {get:unit ‚Üíint, inc:unit ‚Üíunit}.
Slide 189
Object Generators
let val newCounter:unit ‚Üí{get:unit ‚Üíint, inc:unit ‚Üíunit} =
fn y:unit ‚áí
let val x:int ref = ref 0 in
{get = fn y:unit ‚áí!x,
inc = fn y:unit ‚áíx := 1+!x}
end
in
(#inc (newCounter ())) ()
end
and onwards to simple classes...
86

Slide 190
Reusing Method Code (Simple Classes)
Recall Counter = {get:unit ‚Üíint, inc:unit ‚Üíunit}.
First, make the internal state into a record.
CounterRep = {p:int ref}.
let val counterClass:CounterRep ‚ÜíCounter =
fn x:CounterRep ‚áí
{get = fn y:unit ‚áí!(#p x),
inc = fn y:unit ‚áí(#p x) := 1+!(#p x)}
let val newCounter:unit ‚ÜíCounter =
fn y:unit ‚áí
let val x:CounterRep = {p = ref 0} in
counterClass x
Slide 191
Reusing Method Code (Simple Classes)
let val resetCounterClass:CounterRep ‚ÜíResetCounter =
fn x:CounterRep ‚áí
let val super = counterClass x in
{get = #get super,
inc = #inc super,
reset = fn y:unit ‚áí(#p x) := 0}
CounterRep = {p:int ref}.
Counter = {get:unit ‚Üíint, inc:unit ‚Üíunit}.
ResetCounter = {get:unit ‚Üíint, inc:unit ‚Üíunit, reset:unit ‚Üí
unit}.
Slide 192
Reusing Method Code (Simple Classes)
class Counter
{ protected int p;
Counter() { this.p=0; }
int get () { return this.p; }
void inc () { this.p++ ; }
};
class ResetCounter
extends Counter
{ void reset () {this.p=0;}
};
87

Slide 193
Subtyping ‚Äì Structural vs Named
A‚Ä≤
=
{} with {p:int}
A‚Ä≤‚Ä≤
=
A‚Ä≤ with {q:bool}
A‚Ä≤‚Ä≤‚Ä≤
=
A‚Ä≤ with {r:int}
{}
{p:int}
{p:int, q:bool}
‚ô•
‚ô•
‚ô•
‚ô•
‚ô•
‚ô•
{p:int, r:int}
‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ
Object (ish!)
A‚Ä≤
A‚Ä≤‚Ä≤
q
q
q
q
q
q
q
A‚Ä≤‚Ä≤
‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº
6.1
Exercises
Exercise 31 ‚ãÜFor each of the following, either give a type derivation or explain why it is
untypable.
1. {} ‚ä¢{p = {p = {p = {p = 3}}}}:{p:{}}
2. {} ‚ä¢fn x:{p:bool, q:{p:int, q:bool}} ‚áí#q #p x : ?
3. {} ‚ä¢fn f:{p:int} ‚Üíint ‚áí(f {q = 3}) + (f {p = 4}) : ?
4. {} ‚ä¢fn f:{p:int} ‚Üíint ‚áí(f {q = 3, p = 2}) + (f {p = 4}) : ?
Exercise 32 ‚ãÜFor each of the two bogus T ref subtype rules on Slide 184, give an example
program that is typable with that rule but gets stuck at runtime.
Exercise 33 ‚ãÜ‚ãÜWhat should the subtype rules for sums T + T ‚Ä≤ be?
Exercise 34 ‚ãÜ‚ãÜ...and for let and let rec ?
Exercise 35 ‚ãÜ‚ãÜProve a Progress Theorem for L3 with subtyping.
88

7
Semantic Equivalence
Slide 194
Semantic Equivalence
Slide 195
2 + 2
?‚âÉ4
In what sense are these two expressions the same?
They have different abstract syntax trees.
They have different reduction sequences.
But, you‚Äôd hope that in any program you could replace one by the other
without affecting the result....
Z 2+2
0
esin(x)dx =
Z 4
0
esin(x)dx
Slide 196
How about (l := 0; 4)
?‚âÉ(l := 1; 3+!l)
They will produce the same result (in any store), but you cannot replace
one by the other in an arbitrary program context. For example:
C[ ] = +!l
C[l := 0; 4] =
(l := 0; 4)+!l
Ã∏‚âÉ
C[l := 1; 3+!l] =
(l := 1; 3+!l)+!l
On the other hand, consider
(l :=!l + 1); (l :=!l ‚àí1)
?‚âÉ(l :=!l)
Slide 197
Those were all particular expressions ‚Äì may want to know that some
general laws are valid for all e1, e2, .... How about these:
e1; (e2; e3)
?‚âÉ(e1; e2); e3
(if e1 then e2 else e3); e
?‚âÉif e1 then e2; e else e3; e
e; (if e1 then e2 else e3)
?‚âÉif e1 then e; e2 else e; e3
e; (if e1 then e2 else e3)
?‚âÉif e; e1 then e2 else e3
Slide 198
let val x = ref 0 in fn y:int ‚áí(x :=!x + y); !x
?‚âÉ
let val x = ref 0 in fn y:int ‚áí(x :=!x ‚àíy); (0‚àí!x)
89

Slide 199
Temporarily extend L3 with pointer equality
op ::= ... |=
(op =)
Œì ‚ä¢e1:T ref
Œì ‚ä¢e2:T ref
Œì ‚ä¢e1 = e2:bool
(op =)
‚ü®‚Ñì= ‚Ñì‚Ä≤, s‚ü©‚àí‚Üí‚ü®b, s‚ü©
if b = (‚Ñì= ‚Ñì‚Ä≤)
Slide 200
f =
let val x = ref 0 in
let val y = ref 0 in
fn z:int ref ‚áíif z = x then y else x
end end
g =
let val x = ref 0 in
let val y = ref 0 in
fn z:int ref ‚áíif z = y then y else x
end end
f
?‚âÉg
The last two examples are taken from A.M. Pitts, Operational Semantics and Program
Equivalence. In: G. Barthe, P. Dybjer and J. Saraiva (Eds), Applied Semantics. Lecture
Notes in Computer Science, Tutorial, Volume 2395 (Springer-Verlag, 2002), pages 378-412.
http://www.cl.cam.ac.uk/~amp12/papers/opespe/opespe-lncs.pdf
Slide 201
With a ‚Äògood‚Äô notion of semantic equivalence, we might:
1. understand what a program is
2. prove that some particular expression (say an efÔ¨Åcient algorithm) is
equivalent to another (say a clear speciÔ¨Åcation)
3. prove the soundness of general laws for equational reasoning about
programs
4. prove some compiler optimizations are sound (source/IL/TAL)
5. understand the differences between languages
90

Slide 202
What does it mean for ‚âÉto be ‚Äògood‚Äô?
1. programs that result in observably-different values (in some initial
store) must not be equivalent
(‚àÉs, s1, s2, v1, v2.‚ü®e1, s‚ü©‚àí‚Üí‚àó‚ü®v1, s1‚ü©‚àß‚ü®e2, s‚ü©‚àí‚Üí‚àó‚ü®v2, s2‚ü©
‚àßv1 Ã∏= v2) ‚áíe1 Ã∏‚âÉe2
2. programs that terminate must not be equivalent to programs that don‚Äôt
3. ‚âÉmust be an equivalence relation
e ‚âÉe,
e1 ‚âÉe2 ‚áíe2 ‚âÉe1,
e1 ‚âÉe2 ‚âÉe3 =‚áíe1 ‚âÉe3
4. ‚âÉmust be a congruence
if e1 ‚âÉe2 then for any context C we must have C[e1] ‚âÉC[e2]
5. ‚âÉshould relate as many programs as possible subject to the above.
Slide 203
Semantic Equivalence for L1
Consider Typed L1 again.
DeÔ¨Åne e1 ‚âÉT
Œì e2 to hold iff forall s such that dom(Œì) ‚äÜdom(s), we
have Œì ‚ä¢e1:T , Œì ‚ä¢e2:T , and either
(a) ‚ü®e1, s‚ü©‚àí‚Üíœâ and ‚ü®e2, s‚ü©‚àí‚Üíœâ, or
(b) for some v, s‚Ä≤ we have ‚ü®e1, s‚ü©‚àí‚Üí‚àó‚ü®v, s‚Ä≤‚ü©and
‚ü®e2, s‚ü©‚àí‚Üí‚àó‚ü®v, s‚Ä≤‚ü©.
In this deÔ¨Ånition, part (b), we require that e1 and e2 result in the same value and moreover
the same store. This is because, if we were to equate two programs e1 and e2 that result
in diÔ¨Äerent stores ‚Äî say s1(l)Ã∏= s2(l) ‚Äî then we could distinguish them using the following
contexts, and the semantic equivalence would not be a congruence.
Slide 204
If T = unit then C = ; !l.
If T = bool then C = if
then !l else !l.
If T = int then C = l1 := ; !l.
Slide 205
Congruence for Typed L1
The L1 contexts are:
C
::=
op e2 | e1 op
|
if
then e2 else e3 | if e1 then
else e3 |
if e1 then e2 else
|
‚Ñì:=
|
; e2 | e1;
|
while
do e2 | while e1 do
Say ‚âÉT
Œì has the congruence property if whenever e1 ‚âÉT
Œì e2 we have,
for all C and T ‚Ä≤, if Œì ‚ä¢C[e1]:T ‚Ä≤ and Œì ‚ä¢C[e2]:T ‚Ä≤ then
C[e1] ‚âÉT ‚Ä≤
Œì
C[e2].
91

Slide 206
Theorem 24 (Congruence for L1) ‚âÉT
Œì has the congruence property.
Proof Outline By case analysis, looking at each L1 context C in turn.
For each C (and for arbitrary e and s), consider the possible reduction
sequences
‚ü®C[e], s‚ü©‚àí‚Üí‚ü®e1, s1‚ü©‚àí‚Üí‚ü®e2, s2‚ü©‚àí‚Üí...
For each such reduction sequence, deduce what behaviour of e was
involved
‚ü®e, s‚ü©‚àí‚Üí‚ü®ÀÜe1, ÀÜs1‚ü©‚àí‚Üí...
Using e ‚âÉT
Œì e‚Ä≤ Ô¨Ånd a similar reduction sequence of e‚Ä≤.
Using the reduction rules construct a sequence of C[e‚Ä≤].
Theorem 24 (Congruence for L1) ‚âÉT
Œì has the congruence property.
Proof
By case analysis, looking at each L1 context in turn. We give only one case here,
leaving the others for the reader.
Case C = (‚Ñì:=
). Suppose e
‚âÉT
Œì
e‚Ä≤, Œì ‚ä¢‚Ñì:= e:T ‚Ä≤ and Œì ‚ä¢‚Ñì:= e‚Ä≤:T ‚Ä≤. By
examining the typing rules we have T = int and T ‚Ä≤ = unit.
To show ‚Ñì:= e ‚âÉT ‚Ä≤
Œì
‚Ñì:= e‚Ä≤ we have to show for all s such that dom(Œì) ‚äÜdom(s),
then Œì ‚ä¢‚Ñì:= e:T ‚Ä≤ (‚àö), Œì ‚ä¢‚Ñì:= e‚Ä≤:T ‚Ä≤ (‚àö), and either
1. ‚ü®‚Ñì:= e, s‚ü©‚àí‚Üíœâ and ‚ü®‚Ñì:= e‚Ä≤, s‚ü©‚àí‚Üíœâ, or
2. for some v, s‚Ä≤ we have ‚ü®‚Ñì:= e, s‚ü©‚àí‚Üí‚àó‚ü®v, s‚Ä≤‚ü©and ‚ü®‚Ñì:= e‚Ä≤, s‚ü©‚àí‚Üí‚àó‚ü®v, s‚Ä≤‚ü©.
Consider the possible reduction sequences of a state ‚ü®‚Ñì:= e, s‚ü©. Recall that (by
examining the reduction rules), if ‚ü®‚Ñì:= e, s‚ü©‚àí‚Üí‚ü®e1, s1‚ü©then either that is an
instance of (assign1), with ‚àÉn.e = n ‚àß‚Ñì‚ààdom(s) ‚àße1 = skip ‚àßs‚Ä≤ = s +{‚Ñì7‚Üín},
or it is an instance of (assign2), with ‚àÉÀÜe1.‚ü®e, s‚ü©‚àí‚Üí‚ü®ÀÜe1, s1‚ü©‚àße1 = (‚Ñì:= ÀÜe1). We
know also that ‚ü®skip, s‚ü©does not reduce.
Now (using Determinacy), for any e and s we have either
Case: ‚ü®‚Ñì:= e, s‚ü©‚àí‚Üíœâ, i.e.
‚ü®‚Ñì:= e, s‚ü©‚àí‚Üí‚ü®e1, s1‚ü©‚àí‚Üí‚ü®e2, s2‚ü©‚àí‚Üí...
hence all these must be instances of (assign2), with
‚ü®e, s‚ü©‚àí‚Üí‚ü®ÀÜe1, s1‚ü©‚àí‚Üí‚ü®ÀÜe2, s2‚ü©‚àí‚Üí...
and e1 = (‚Ñì:= ÀÜe1), e2 = (‚Ñì:= ÀÜe2),...
Case: ¬¨(‚ü®‚Ñì:= e, s‚ü©‚àí‚Üíœâ), i.e.
‚ü®‚Ñì:= e, s‚ü©‚àí‚Üí‚ü®e1, s1‚ü©‚àí‚Üí‚ü®e2, s2‚ü©... ‚àí‚Üí‚ü®ek, sk‚ü©Ã∏‚àí‚Üí
hence all these must be instances of (assign2) except the last, which must be
an instance of (assign1), with
‚ü®e, s‚ü©‚àí‚Üí‚ü®ÀÜe1, s1‚ü©‚àí‚Üí‚ü®ÀÜe2, s2‚ü©‚àí‚Üí... ‚àí‚Üí‚ü®ÀÜek‚àí1, sk‚àí1‚ü©
and e1 = (‚Ñì:= ÀÜe1), e2 = (‚Ñì:= ÀÜe2),..., ek‚àí1 = (‚Ñì:= ÀÜek‚àí1) and for some n we
have ÀÜek‚àí1 = n, ek = skip, and sk = sk‚àí1 + {‚Ñì7‚Üín}.
(the other possibility, of zero or more (assign1) reductions ending in a stuck
state, is excluded by Theorems 2 and 3 (type preservation and progress))
Now, if ‚ü®‚Ñì:= e, s‚ü©‚àí‚Üíœâ, by the above there is an inÔ¨Ånite reduction sequence for
‚ü®e, s‚ü©, so by e ‚âÉT
Œì e‚Ä≤ there is an inÔ¨Ånite reduction sequence of ‚ü®e‚Ä≤, s‚ü©, so (using
(assign2)) there is an inÔ¨Ånite reduction sequence of ‚ü®‚Ñì:= e‚Ä≤, s‚ü©.
92

On the other hand, if ¬¨(‚ü®‚Ñì:= e, s‚ü©‚àí‚Üíœâ) then by the above there is some n and
sk‚àí1 such that ‚ü®e, s‚ü©‚àí‚Üí‚àó‚ü®n, sk‚àí1‚ü©and ‚ü®‚Ñì:= e, s‚ü©‚àí‚Üí‚ü®skip, sk‚àí1 + {‚Ñì7‚Üín}‚ü©.
By e ‚âÉT
Œì e‚Ä≤ we have ‚ü®e‚Ä≤, s‚ü©‚àí‚Üí‚àó‚ü®n, sk‚àí1‚ü©. Then using (assign1) ‚ü®‚Ñì:= e‚Ä≤, s‚ü©‚àí‚Üí‚àó
‚ü®‚Ñì:= n, sk‚àí1‚ü©‚àí‚Üí‚ü®skip, sk‚àí1 + {‚Ñì7‚Üín} = ‚ü®ek, sk‚ü©as required.
‚ñ°
Slide 207
Back to the Examples
We deÔ¨Åned e1 ‚âÉT
Œì e2 iff for all s such that dom(Œì) ‚äÜdom(s), we have
Œì ‚ä¢e1:T , Œì ‚ä¢e2:T , and either
1. ‚ü®e1, s‚ü©‚àí‚Üíœâ and ‚ü®e2, s‚ü©‚àí‚Üíœâ, or
2. for some v, s‚Ä≤ we have ‚ü®e1, s‚ü©‚àí‚Üí‚àó‚ü®v, s‚Ä≤‚ü©and
‚ü®e2, s‚ü©‚àí‚Üí‚àó‚ü®v, s‚Ä≤‚ü©.
So:
2 + 2 ‚âÉint
Œì
4 for any Œì
(l := 0; 4) Ã∏‚âÉint
Œì (l := 1; 3+!l) for any Œì
(l :=!l + 1); (l :=!l ‚àí1) ‚âÉunit
Œì
(l :=!l) for any Œì including l:intref
Slide 208
And the general laws?
Conjecture 25 e1; (e2; e3) ‚âÉT
Œì (e1; e2); e3 for any Œì, T , e1, e2 and e3
such that Œì ‚ä¢e1:unit, Œì ‚ä¢e2:unit, and Œì ‚ä¢e3:T
Conjecture 26
((if e1 then e2 else e3); e) ‚âÉT
Œì (if e1 then e2; e else e3; e) for
any Œì, T , e, e1, e2 and e3 such that Œì ‚ä¢e1:bool, Œì ‚ä¢e2:unit,
Œì ‚ä¢e3:unit, and Œì ‚ä¢e:T
Conjecture 27
(e; (if e1 then e2 else e3)) ‚âÉT
Œì (if e1 then e; e2 else e; e3) for
any Œì, T , e, e1, e2 and e3 such that Œì ‚ä¢e:unit, Œì ‚ä¢e1:bool,
Œì ‚ä¢e2:T , and Œì ‚ä¢e3:T
Slide 209
Q: Is a typed expression Œì ‚ä¢e:T , e.g.
l:intref ‚ä¢if !l ‚â•0 then skip else (skip; l := 0):unit:
1. a list of tokens
[ IF, DEREF, LOC "l", GTEQ, ..];
2. an abstract syntax tree
if then else
‚â•
‚úâ‚úâ‚úâ
skip
;
‚ùë‚ùë‚ùë
!l ‚úû‚úû
0
skip
l :=
‚ùÜ‚ùÜ
0
;
3. the function taking store s to the reduction sequence
‚ü®e, s‚ü©‚àí‚Üí‚ü®e1, s1‚ü©‚àí‚Üí‚ü®e2, s2‚ü©‚àí‚Üí...; or
4. ‚Ä¢ the equivalence class {e‚Ä≤ | e ‚âÉT
Œì e‚Ä≤}
‚Ä¢ the partial function [[e]]Œì that takes any store s with
dom(s) = dom(Œì) and either is undeÔ¨Åned, if ‚ü®e, s‚ü©‚àí‚Üíœâ, or is
‚ü®v, s‚Ä≤‚ü©, if ‚ü®e, s‚ü©‚àí‚Üí‚àó‚ü®v, s‚Ä≤‚ü©
(the Determinacy theorem tells us that this is a deÔ¨Ånition of a function).
Slide 210
Suppose Œì ‚ä¢e1:unit and Œì ‚ä¢e2:unit.
When is e1; e2 ‚âÉunit
Œì
e2; e1 ?
A suÔ¨Écient condition: they don‚Äôt mention any locations (but not necessary... e.g. if e1 does
but e2 doesn‚Äôt)
93

7.1
Contextual equivalence
The deÔ¨Ånition of semantic equivalence works Ô¨Åne for L1. However, when we come to L2 and
L3, the simple notion does not give a congruence.
Here is a basic deÔ¨Ånition of an equivalence for L3.
Slide 211
Contextual equivalence for L3
DeÔ¨Ånition 28 Consider typed L3 programs, Œì ‚ä¢e1:T and Œì ‚ä¢e2:T .
We say that they are contextually equivalent if, for every context C such
that {} ‚ä¢C[e1]:unit and {} ‚ä¢C[e2]:unit, we have either
(a) ‚ü®C[e1], {}‚ü©‚àí‚Üíœâ and ‚ü®C[e2], {}‚ü©‚àí‚Üíœâ, or
(b) for some s1 and s2 we have ‚ü®C[e1], {}‚ü©‚àí‚Üí‚àó‚ü®skip, s1‚ü©and
‚ü®C[e2], {}‚ü©‚àí‚Üí‚àó‚ü®skip, s2‚ü©.
Notice that contextual equivalence is a congruence by deÔ¨Ånition.
Contextual equivalence is undecidable in general. An important research topic is Ô¨Ånding
techniques for proving contextual equivalence.
7.2
Exercises
Exercise 36 ‚ãÜ‚ãÜProve some of the other cases of the Congruence theorem for semantic
equivalence in L1.
Exercise 37 ‚ãÜ‚ãÜProve that if Œì1 ‚ä¢e1:unit and Œì2 ‚ä¢e2:unit in L1, and Œì1 is disjoint from
Œì2 , then e1; e2 ‚âÉunit
Œì
e2; e1 where Œì = Œì1 ‚à™Œì2
Exercise 38 ‚ãÜ‚ãÜProve that the programs l:int ref ‚ä¢l := 0:unit and l:int ref ‚ä¢l := 1:unit,
considered as L3 programs, are not contextually equivalent. Hint: Ô¨Ånd a context that will
diverge for one of them, but not for the other.
94

8
Concurrency
Slide 212
Concurrency
Slide 213
Our focus so far has been on semantics for sequential computation. But
the world is not sequential...
‚Ä¢ hardware is intrinsically parallel (Ô¨Åne-grain, across words, to
coarse-grain, e.g. multiple execution units)
‚Ä¢ multi-processor machines
‚Ä¢ multi-threading (perhaps on a single processor)
‚Ä¢ networked machines
Slide 214
Problems
‚Ä¢ the state-spaces of our systems become large, with the combinatorial
explosion ‚Äì with n threads, each of which can be in 2 states, the
system has 2n states.
‚Ä¢ the state-spaces become complex
‚Ä¢ computation becomes nondeterministic (unless synchrony is
imposed), as different threads operate at different speeds.
‚Ä¢ parallel components competing for access to resources may deadlock
or suffer starvation. Need mutual exclusion between components
accessing a resource.
Slide 215
More Problems!
‚Ä¢ partial failure (of some processes, of some machines in a network, of
some persistent storage devices). Need transactional mechanisms.
‚Ä¢ communication between different environments (with different local
resources (e.g. different local stores, or libraries, or...)
‚Ä¢ partial version change
‚Ä¢ communication between administrative regions with partial trust (or,
indeed, no trust); protection against mailicious attack.
‚Ä¢ dealing with contingent complexity (embedded historical accidents;
upwards-compatible deltas)
95

Slide 216
Theme: as for sequential languages, but much more so, it‚Äôs a complicated
world.
Aim of this lecture: just to give you a taste of how a little semantics can
be used to express some of the Ô¨Åne distinctions. Primarily (1) to boost
your intuition for informal reasoning, but also (2) this can support rigorous
proof about really hairy crypto protocols, cache-coherency protocols,
comms, database transactions,....
Going to deÔ¨Åne the simplest possible concurrent language, call it L1, and
explore a few issues. You‚Äôve seen most of them informally in C&DS.
Slide 217
Booleans b ‚ààB = {true, false}
Integers n ‚ààZ = {..., ‚àí1, 0, 1, ...}
Locations ‚Ñì‚ààL = {l, l0, l1, l2, ...}
Operations op ::= + |‚â•
Expressions
e
::=
n | b | e1 op e2 | if e1 then e2 else e3 |
‚Ñì:= e |!‚Ñì|
skip | e1; e2 |
while e1 do e2|
e1 e2
T
::=
int | bool | unit | proc
Tloc
::=
intref
Slide 218
Parallel Composition: Typing and Reduction
(thread)
Œì ‚ä¢e:unit
Œì ‚ä¢e:proc
(parallel)
Œì ‚ä¢e1:proc
Œì ‚ä¢e2:proc
Œì ‚ä¢e1 e2:proc
(parallel1)
‚ü®e1, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
1, s‚Ä≤‚ü©
‚ü®e1 e2, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
1 e2, s‚Ä≤‚ü©
(parallel2)
‚ü®e2, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
2, s‚Ä≤‚ü©
‚ü®e1 e2, s‚ü©‚àí‚Üí‚ü®e1 e‚Ä≤
2, s‚Ä≤‚ü©
Slide 219
Parallel Composition: Design Choices
‚Ä¢ threads don‚Äôt return a value
‚Ä¢ threads don‚Äôt have an identity
‚Ä¢ termination of a thread cannot be observed within the language
‚Ä¢ threads aren‚Äôt partitioned into ‚Äòprocesses‚Äô or machines
‚Ä¢ threads can‚Äôt be killed externally
96

Slide 220
Threads execute asynchronously ‚Äì the semantics allows any interleaving
of the reductions of the threads.
All threads can read and write the shared memory.
‚ü®() l := 2, {l 7‚Üí1}‚ü©
/ ‚ü®() (), {l 7‚Üí2}‚ü©
‚ü®l := 1 l := 2, {l 7‚Üí0}‚ü©
4‚ù•
‚ù•
‚ù•
‚ù•
‚ù•
‚ù•
‚ù•
‚ù•
‚ù•
‚ù•
‚ù•
‚ù•
‚ù•
‚ù•
‚ù•
*‚ùö
‚ùö
‚ùö
‚ùö
‚ùö
‚ùö
‚ùö
‚ùö
‚ùö
‚ùö
‚ùö
‚ùö
‚ùö
‚ùö
‚ùö
‚ü®l := 1 (), {l 7‚Üí2}‚ü©
/ ‚ü®() (), {l 7‚Üí1}‚ü©
NB from here on, we are using () instead of skip ‚Äî that‚Äôs the ML syntax.
Slide 221
But, assignments and dereferencing are atomic. For example,
‚ü®l := 3498734590879238429384 | l := 7, {l 7‚Üí0}‚ü©
will reduce to a state with l either 3498734590879238429384 or 7, not
something with the Ô¨Årst word of one and the second word of the other.
Implement?
But but, in (l := e) e‚Ä≤, the steps of evaluating e and e‚Ä≤ can be
interleaved.
Think of (l := 1+!l) (l := 7+!l) ‚Äì there are races....
97

The behaviour of (l := 1+!l) (l := 7+!l) for the initial store {l 7‚Üí0}:
‚ü®() (l := 7+!l), {l 7‚Üí1}‚ü©
r
/ ‚Ä¢
+
/ ‚Ä¢
w
/ ‚ü®() (), {l 7‚Üí8}‚ü©
‚ü®(l := 1) (l := 7+!l), {l 7‚Üí0}‚ü©
r
)‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
w
5‚ù¶
‚ù¶
‚ù¶
‚ù¶
‚ù¶
‚ù¶
‚ù¶
‚ù¶
‚ù¶
‚ù¶
‚ù¶
‚ù¶
‚ù¶
‚ù¶
‚ü®() (l := 7 + 0), {l 7‚Üí1}‚ü©
+
)‚ùò
‚ùò
‚ùò
‚ùò
‚ùò
‚ùò
‚ùò
‚ùò
‚ùò
‚ùò
‚ùò
‚ùò
‚ùò
‚ü®(l := 1 + 0) (l := 7+!l), {l 7‚Üí0}‚ü©
r
'‚ùñ
‚ùñ
‚ùñ
‚ùñ
‚ùñ
‚ùñ
‚ùñ
‚ùñ
‚ùñ
‚ùñ
‚ùñ
+
7‚ô¶
‚ô¶
‚ô¶
‚ô¶
‚ô¶
‚ô¶
‚ô¶
‚ô¶
‚ô¶
‚ô¶
‚ô¶
‚ü®(l := 1) (l := 7 + 0), {l 7‚Üí0}‚ü©
+
)‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
w
5‚ù¶
‚ù¶
‚ù¶
‚ù¶
‚ù¶
‚ù¶
‚ù¶
‚ù¶
‚ù¶
‚ù¶
‚ù¶
‚ù¶
‚ù¶
‚ù¶
‚ü®() (l := 7), {l 7‚Üí1}‚ü©
w
/ ‚ü®() (), {l 7‚Üí7}‚ü©
‚ü®(l := 1+!l) (l := 7+!l), {l 7‚Üí0}‚ü©
r
7‚ô¶
‚ô¶
‚ô¶
‚ô¶
‚ô¶
‚ô¶
‚ô¶
‚ô¶
‚ô¶
‚ô¶
‚ô¶
r
'‚ùñ
‚ùñ
‚ùñ
‚ùñ
‚ùñ
‚ùñ
‚ùñ
‚ùñ
‚ùñ
‚ùñ
‚ùñ
‚ü®(l := 1 + 0) (l := 7 + 0), {l 7‚Üí0}‚ü©
+
5‚ù¶
‚ù¶
‚ù¶
‚ù¶
‚ù¶
‚ù¶
‚ù¶
‚ù¶
‚ù¶
‚ù¶
‚ù¶
‚ù¶
‚ù¶
‚ù¶
+
)‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
‚ü®(l := 1) (l := 7), {l 7‚Üí0}‚ü©
w
5‚ùß
‚ùß
‚ùß
‚ùß
‚ùß
‚ùß
‚ùß
‚ùß
‚ùß
‚ùß
‚ùß
‚ùß
‚ùß
w
)‚ùò
‚ùò
‚ùò
‚ùò
‚ùò
‚ùò
‚ùò
‚ùò
‚ùò
‚ùò
‚ùò
‚ùò
‚ùò
‚ü®(l := 1+!l) (l := 7 + 0), {l 7‚Üí0}‚ü©
r
7‚ô¶
‚ô¶
‚ô¶
‚ô¶
‚ô¶
‚ô¶
‚ô¶
‚ô¶
‚ô¶
‚ô¶
‚ô¶
+
'‚ùñ
‚ùñ
‚ùñ
‚ùñ
‚ùñ
‚ùñ
‚ùñ
‚ùñ
‚ùñ
‚ùñ
‚ùñ
‚ü®(l := 1 + 0) (l := 7), {l 7‚Üí0}‚ü©
+
5‚ù¶
‚ù¶
‚ù¶
‚ù¶
‚ù¶
‚ù¶
‚ù¶
‚ù¶
‚ù¶
‚ù¶
‚ù¶
‚ù¶
‚ù¶
‚ù¶
w
)‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
‚ü®l := 1 (), {l 7‚Üí7}‚ü©
w
/ ‚ü®() (), {l 7‚Üí1}‚ü©
‚ü®(l := 1+!l) (l := 7), {l 7‚Üí0}‚ü©
r
5‚ù¶
‚ù¶
‚ù¶
‚ù¶
‚ù¶
‚ù¶
‚ù¶
‚ù¶
‚ù¶
‚ù¶
‚ù¶
‚ù¶
‚ù¶
‚ù¶
w
)‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
‚ùô
‚ü®l := 1 + 0 (), {l 7‚Üí7}‚ü©
+
5‚ùß
‚ùß
‚ùß
‚ùß
‚ùß
‚ùß
‚ùß
‚ùß
‚ùß
‚ùß
‚ùß
‚ùß
‚ùß
‚ü®l := 1+!l (), {l 7‚Üí7}‚ü©
r
/ ‚Ä¢
+
/ ‚Ä¢
w
/ ‚ü®() (), {l 7‚Üí8}‚ü©
98

Note that the labels +, w and r in the picture are just informal hints as to how those
transitions were derived ‚Äì they are not actually part of the reduction relation.
Some of the nondeterministic choices ‚Äúdon‚Äôt matter‚Äù, as you can get back to the same state.
Others do...
Slide 222
Morals
‚Ä¢ There is a combinatorial explosion.
‚Ä¢ Drawing state-space diagrams only works for really tiny examples ‚Äì we
need better techniques for analysis.
‚Ä¢ Almost certainly you (as the programmer) didn‚Äôt want all those 3
outcomes to be possible ‚Äì need better idioms or constructs for
programming.
Slide 223
So, how do we get anything coherent done?
Need some way(s) to synchronize between threads, so can enforce
mutual exclusion for shared data.
cf. Lamport‚Äôs ‚ÄúBakery‚Äù algorithm from Concurrent and Distributed
Systems. Can you code that in L1? If not, what‚Äôs the smallest extension
required?
Usually, though, you can depend on built-in support from the scheduler,
e.g. for mutexes and condition variables (or, at a lower level, tas or
cas).
See this ‚Äì in the library ‚Äì for a good discussion of mutexes and condition variables: A. Birrell,
J. Guttag, J. Horning, and R. Levin. Thread synchronization: a Formal SpeciÔ¨Åcation. In G.
Nelson, editor, System Programming with Modula-3, chapter 5, pages 119-129. Prentice-
Hall, 1991.
See N. Lynch. Distributed Algorithms for other mutual exclusion algorithms (and much else
besides).
Consider simple mutexes, with commands to lock an unlocked mutex and to unlock a locked
mutex (and do nothing for an unlock of an unlocked mutex).
Slide 224
Adding Primitive Mutexes
Mutex names m ‚ààM = {m, m1, ...}
ConÔ¨Ågurations ‚ü®e, s, M ‚ü©where M :M ‚ÜíB is the mutex state
Expressions e ::= ... | lock m | unlock m
(lock)
Œì ‚ä¢lock m:unit
(unlock)
Œì ‚ä¢unlock m:unit
(lock)
‚ü®lock m, s, M ‚ü©‚àí‚Üí‚ü®(), s, M + {m 7‚Üítrue}‚ü©if ¬¨M (m)
(unlock)
‚ü®unlock m, s, M ‚ü©‚àí‚Üí‚ü®(), s, M + {m 7‚Üífalse}‚ü©
Note that (lock) atomically (a) checks the mutex is currently false, (b) changes its state,
and (c) lets the thread proceed.
Also, there is no record of which thread is holding a locked mutex.
99

Slide 225
Need to adapt all the other semantic rules to carry the mutex state M
around. For example, replace
(op2)
‚ü®e2, s‚ü©‚àí‚Üí‚ü®e‚Ä≤
2, s‚Ä≤‚ü©
‚ü®v op e2, s‚ü©‚àí‚Üí‚ü®v op e‚Ä≤
2, s‚Ä≤‚ü©
by
(op2)
‚ü®e2, s, M ‚ü©‚àí‚Üí‚ü®e‚Ä≤
2, s‚Ä≤, M ‚Ä≤‚ü©
‚ü®v op e2, s, M ‚ü©‚àí‚Üí‚ü®v op e‚Ä≤
2, s‚Ä≤, M ‚Ä≤‚ü©
Slide 226
Using a Mutex
Consider
e = (lock m; l := 1+!l; unlock m) (lock m; l := 7+!l; unlock m)
The behaviour of ‚ü®e, s, M ‚ü©, with the initial store s = {l 7‚Üí0} and initial
mutex state M0 = Œªm ‚ààM.false, is:
‚ü®(l := 1+!l; unlock m) (lock m; l := 7+!l; unlock m), s, M ‚Ä≤‚ü©
(P
P
P
P
P
P
P
P
P
P
P
P
‚ü®e, s, M0‚ü©
lock m
8r
r
r
r
r
r
r
r
r
r
lock m
&‚ñ≤
‚ñ≤
‚ñ≤
‚ñ≤
‚ñ≤
‚ñ≤
‚ñ≤
‚ñ≤
‚ñ≤
‚ñ≤
‚ü®() (), {l 7‚Üí8}, M ‚ü©
‚ü®(lock m; l := 1+!l; unlock m) (l := 7+!l; unlock m), s, M ‚Ä≤‚ü©
6‚ô•
‚ô•
‚ô•
‚ô•
‚ô•
‚ô•
‚ô•
‚ô•
‚ô•
‚ô•
‚ô•
‚ô•
(where M ‚Ä≤ = M0 + {m 7‚Üítrue})
In all the intervening states (until the Ô¨Årst unlock ) the second lock can‚Äôt proceed.
Look back to behaviour of the program without mutexes. We‚Äôve essentially cut down to the
top and bottom paths (and also added some extra reductions for lock , unlock , and ;).
In this example, l := 1+!l and l := 7+!l commute, so we end up in the same Ô¨Ånal state
whichever got the lock Ô¨Årst. In general, that won‚Äôt be the case.
Slide 227
Using Several Mutexes
lock m can block (that‚Äôs the point). Hence, you can deadlock.
e =
(lock m1; lock m2; l1 :=!l2; unlock m1; unlock m2)
(lock m2; lock m1; l2 :=!l1; unlock m1; unlock m2)
Slide 228
Locking Disciplines
So, suppose we have several programs e1, ..., ek, all well-typed with
Œì ‚ä¢ei:unit, that we want to execute concurrently without ‚Äòinterference‚Äô
(whatever that is). Think of them as transaction bodies.
There are many possible locking disciplines. We‚Äôll focus on one, to see
how it ‚Äì and the properties it guarantees ‚Äì can be made precise and
proved.
100

Slide 229
An Ordered 2PL Discipline, Informally
Fix an association between locations and mutexes. For simplicity, make it
1:1 ‚Äì associate l with m, l1 with m1, etc.
Fix a lock acquisition order. For simplicity, make it m, m0, m1, m2, ....
Require that each ei
‚Ä¢ acquires the lock mj for each location lj it uses, before it uses it
‚Ä¢ acquires and releases each lock in a properly-bracketed way
‚Ä¢ does not acquire any lock after it‚Äôs released any lock (two-phase)
‚Ä¢ acquires locks in increasing order
Then, informally, (e1 ... ek) should (a) never deadlock, and (b) be
serializable ‚Äì any execution of it should be ‚Äòequivalent‚Äô to an execution of
eœÄ(1); ...; eœÄ(k) for some permutation œÄ.
These are semantic properties again. In general, it won‚Äôt be computable whether they hold.
For simple ei, though, it‚Äôs often obvious. Further, one can construct syntactic disciplines
that are checkable and are suÔ¨Écient to guarantee these.
Slide 230
Problem: Need a Thread-Local Semantics
Our existing semantics deÔ¨Ånes the behaviour only of global conÔ¨Ågurations
‚ü®e, s, M ‚ü©. To state properties of subexpressions, e.g.
‚Ä¢ ei acquires the lock mj for each location lj it uses, before it uses it
which really means
‚Ä¢ in any execution of ‚ü®(e1 ... ei ... ek), s, M ‚ü©, ei acquires the lock
mj for each location lj it uses, before it uses it
we need some notion of the behaviour of the thread ei on its own
Slide 231
Solution: Thread local semantics
Instead of only deÔ¨Åning the global ‚ü®e, s, M ‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤, M ‚Ä≤‚ü©, with rules
(assign1)
‚ü®‚Ñì:= n, s, M ‚ü©‚àí‚Üí‚ü®skip, s + {‚Ñì7‚Üín}, M ‚ü©
if ‚Ñì‚ààdom(s)
(parallel1)
‚ü®e1, s, M ‚ü©‚àí‚Üí‚ü®e‚Ä≤
1, s‚Ä≤, M ‚Ä≤‚ü©
‚ü®e1 e2, s, M ‚ü©‚àí‚Üí‚ü®e‚Ä≤
1 e2, s‚Ä≤, M ‚Ä≤‚ü©
deÔ¨Åne a per-thread e
a
‚àí‚Üíe‚Ä≤ and use that to deÔ¨Åne
‚ü®e, s, M ‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤, M ‚Ä≤‚ü©, with rules like
(t-assign1)
‚Ñì:= n
‚Ñì:=n
‚àí‚Üískip
(t-parallel1)
e1
a
‚àí‚Üíe‚Ä≤
1
e1 e2
a
‚àí‚Üíe‚Ä≤
1 e2
(c-assign)
e
‚Ñì:=n
‚àí‚Üíe‚Ä≤
‚Ñì‚ààdom(s)
‚ü®e, s, M ‚ü©‚àí‚Üí‚ü®e‚Ä≤, s + {‚Ñì7‚Üín}, M ‚ü©
101

Slide 232
Note the per-thread rules don‚Äôt mention s or M . Instead, we record in the
label a what interactions with the store or mutexes it has.
a
::=
œÑ | ‚Ñì:= n |!‚Ñì= n | lock m | unlock m
Conventionally, œÑ (tau), stands for ‚Äúno interactions‚Äù, so e
œÑ
‚àí‚Üíe‚Ä≤ if e does
an internal step, not involving the store or mutexes.
Theorem 29 (Coincidence of global and thread-local semantics) The
two deÔ¨Ånitions of ‚àí‚Üíagree exactly.
Proof strategy: a couple of rule inductions.
The full thread local semantics are on the next page.
Slide 233
Example of Thread-local transitions
For e = (lock m; (l := 1+!l; unlock m)) we have
e
lock m
‚àí‚Üí
skip; (l := 1+!l; unlock m)
œÑ
‚àí‚Üí
(l := 1+!l; unlock m)
!l=n
‚àí‚Üí
(l := 1 + n; unlock m)
for any n ‚ààZ
œÑ
‚àí‚Üí
(l := n‚Ä≤; unlock m)
for n‚Ä≤ = 1 + n
l:=n‚Ä≤
‚àí‚Üí
skip; unlock m
œÑ
‚àí‚Üí
unlock m
unlock m
‚àí‚Üí
skip
Hence, using (t-parallel) and the (c-*) rules, for s‚Ä≤ = s + {l 7‚Üí1 + s(l)},
‚ü®e e‚Ä≤, s, M0‚ü©‚àí‚Üí‚àí‚Üí‚àí‚Üí‚àí‚Üí‚àí‚Üí‚àí‚Üí‚àí‚Üí‚ü®skip e‚Ä≤, s‚Ä≤, M0‚ü©
(need l ‚ààdom(s) also)
One often uses similar labelled transitions in deÔ¨Åning communication between threads (or
machines), and also in working with observational equivalences for concurrent languages (cf.
bisimulation) ‚Äì to come in Topics in Concurrency.
102

Global Semantics
Thread-Local Semantics
(op +)
‚ü®n1 + n2, s, M ‚ü©‚àí‚Üí‚ü®n, s, M ‚ü©
if n = n1 + n2
(op ‚â•)
‚ü®n1 ‚â•n2, s, M ‚ü©‚àí‚Üí‚ü®b, s, M ‚ü©
if b = (n1 ‚â•n2)
(op1)
‚ü®e1, s, M ‚ü©‚àí‚Üí‚ü®e‚Ä≤
1, s‚Ä≤, M ‚Ä≤‚ü©
‚ü®e1 op e2, s, M ‚ü©‚àí‚Üí‚ü®e‚Ä≤
1 op e2, s‚Ä≤, M ‚Ä≤‚ü©
(op2)
‚ü®e2, s, M ‚ü©‚àí‚Üí‚ü®e‚Ä≤
2, s‚Ä≤, M ‚Ä≤‚ü©
‚ü®v op e2, s, M ‚ü©‚àí‚Üí‚ü®v op e‚Ä≤
2, s‚Ä≤, M ‚Ä≤‚ü©
(deref)
‚ü®!‚Ñì, s, M ‚ü©‚àí‚Üí‚ü®n, s, M ‚ü©
if ‚Ñì‚ààdom(s) and s(‚Ñì) = n
(assign1)
‚ü®‚Ñì:= n, s, M ‚ü©‚àí‚Üí‚ü®skip, s + {‚Ñì7‚Üín}, M ‚ü©
if ‚Ñì‚ààdom(s)
(assign2)
‚ü®e, s, M ‚ü©‚àí‚Üí‚ü®e‚Ä≤, s‚Ä≤, M ‚Ä≤‚ü©
‚ü®‚Ñì:= e, s, M ‚ü©‚àí‚Üí‚ü®‚Ñì:= e‚Ä≤, s‚Ä≤, M ‚Ä≤‚ü©
(seq1)
‚ü®skip; e2, s, M ‚ü©‚àí‚Üí‚ü®e2, s, M ‚ü©
(seq2)
‚ü®e1, s, M ‚ü©‚àí‚Üí‚ü®e‚Ä≤
1, s‚Ä≤, M ‚Ä≤‚ü©
‚ü®e1; e2, s, M ‚ü©‚àí‚Üí‚ü®e‚Ä≤
1; e2, s‚Ä≤, M ‚Ä≤‚ü©
(if1)
‚ü®if true then e2 else e3, s, M ‚ü©‚àí‚Üí‚ü®e2, s, M ‚ü©
(if2)
‚ü®if false then e2 else e3, s, M ‚ü©‚àí‚Üí‚ü®e3, s, M ‚ü©
(if3)
‚ü®e1, s, M ‚ü©‚àí‚Üí‚ü®e‚Ä≤
1, s‚Ä≤, M ‚Ä≤‚ü©
‚ü®if e1 then e2 else e3, s, M ‚ü©‚àí‚Üí‚ü®if e‚Ä≤
1 then e2 else e3, s‚Ä≤, M ‚Ä≤‚ü©
(while)
‚ü®while e1 do e2, s, M ‚ü©‚àí‚Üí‚ü®if e1 then (e2; while e1 do e2) else skip, ‚ü©
(parallel1)
‚ü®e1, s, M ‚ü©‚àí‚Üí‚ü®e‚Ä≤
1, s‚Ä≤, M ‚Ä≤‚ü©
‚ü®e1 e2, s, M ‚ü©‚àí‚Üí‚ü®e‚Ä≤
1 e2, s‚Ä≤, M ‚Ä≤‚ü©
(parallel2)
‚ü®e2, s, M ‚ü©‚àí‚Üí‚ü®e‚Ä≤
2, s‚Ä≤, M ‚Ä≤‚ü©
‚ü®e1 e2, s, M ‚ü©‚àí‚Üí‚ü®e1 e‚Ä≤
2, s‚Ä≤, M ‚Ä≤‚ü©
(lock)
‚ü®lock m, s, M ‚ü©‚àí‚Üí‚ü®(), s, M + {m 7‚Üítrue}‚ü©if ¬¨M (m)
(unlock)
‚ü®unlock m, s, M ‚ü©‚àí‚Üí‚ü®(), s, M + {m 7‚Üífalse}‚ü©
(t-op +)
n1 + n2
œÑ
‚àí‚Üín
if n = n1 + n2
(t-op ‚â•)
n1 ‚â•n2
œÑ
‚àí‚Üíb
if b = (n1 ‚â•n2)
(t-op1)
e1
a
‚àí‚Üíe‚Ä≤
1
e1 op e2
a
‚àí‚Üíe‚Ä≤
1 op e2
(t-op2)
e2
a
‚àí‚Üíe‚Ä≤
2
v op e2
a
‚àí‚Üív op e‚Ä≤
2
(t-deref)
!‚Ñì
!‚Ñì=n
‚àí‚Üín
(t-assign1)
‚Ñì:= n
‚Ñì:=n
‚àí‚Üískip
(t-assign2)
e
a
‚àí‚Üíe‚Ä≤
‚Ñì:= e
a
‚àí‚Üí‚Ñì:= e‚Ä≤
(t-seq1)
skip; e2
œÑ
‚àí‚Üíe2
(t-seq2)
e1
a
‚àí‚Üíe‚Ä≤
1
e1; e2
a
‚àí‚Üíe‚Ä≤
1; e2
(t-if1)
if true then e2 else e3
œÑ
‚àí‚Üíe2
(t-if2)
if false then e2 else e3
œÑ
‚àí‚Üíe3
(t-if3)
e1
a
‚àí‚Üíe‚Ä≤
1
if e1 then e2 else e3
a
‚àí‚Üíif e‚Ä≤
1 then e2 else e3
(t-while)
while e1 do e2
œÑ
‚àí‚Üíif e1 then (e2; while e1 do e2) else skip
(t-parallel1)
e1
a
‚àí‚Üíe‚Ä≤
1
e1 e2
a
‚àí‚Üíe‚Ä≤
1 e2
(t-parallel2)
e2
a
‚àí‚Üíe‚Ä≤
2
e1 e2
a
‚àí‚Üíe1 e‚Ä≤
2
(t-lock)
lock m lock
m
‚àí‚Üí
()
(t-unlock)
unlock m unlock
m
‚àí‚Üí
()
(c-tau)
e
œÑ
‚àí‚Üíe‚Ä≤
‚ü®e, s, M ‚ü©‚àí‚Üí‚ü®e‚Ä≤, s, M ‚ü©
(c-assign)
e
‚Ñì:=n
‚àí‚Üíe‚Ä≤
‚Ñì‚ààdom(s)
‚ü®e, s, M ‚ü©‚àí‚Üí‚ü®e‚Ä≤, s + {‚Ñì7‚Üín}, M ‚ü©
(c-lock)
e lock
m
‚àí‚Üí
e‚Ä≤
¬¨ M (m)
‚ü®e, s, M ‚ü©‚àí‚Üí‚ü®e‚Ä≤, s, M + {m 7‚Üítrue}‚ü©
(c-deref)
e
!‚Ñì=n
‚àí‚Üíe‚Ä≤
‚Ñì‚ààdom(s) ‚àßs(‚Ñì) = n
‚ü®e, s, M ‚ü©‚àí‚Üí‚ü®e‚Ä≤, s, M ‚ü©
(c-unlock)
e unlock
m
‚àí‚Üí
e‚Ä≤
‚ü®e, s, M ‚ü©‚àí‚Üí‚ü®e‚Ä≤, s, M + {m 7‚Üífalse}‚ü©
103

Slide 234
Now can make the Ordered 2PL Discipline precise
Say e obeys the discipline if for any (Ô¨Ånite or inÔ¨Ånite)
e
a1
‚àí‚Üíe1
a2
‚àí‚Üíe2
a3
‚àí‚Üí...
‚Ä¢ if ai is (lj := n) or (!lj = n) then for some k < i we have
ak = lock mj without an intervening unlock mj.
‚Ä¢ for each j , the subsequence of a1, a2, ... with labels lock mj and
unlock mj is a preÔ¨Åx of ((lock mj)(unlock mj))‚àó. Moreover, if
¬¨(ek
a
‚àí‚Üí) then the subsequence does not end in a lock mj.
‚Ä¢ if ai = lock mj and ai‚Ä≤ = unlock mj‚Ä≤ then i < i‚Ä≤
‚Ä¢ if ai = lock mj and ai‚Ä≤ = lock mj‚Ä≤ and i < i‚Ä≤ then j < j‚Ä≤
Slide 235
... and make the guaranteed properties precise
Say e1, ..., ek are serializable if for any initial store s, if
‚ü®(e1 ... ek), s, M0‚ü©‚àí‚Üí‚àó‚ü®e‚Ä≤, s‚Ä≤, M ‚Ä≤‚ü©Ã∏‚àí‚Üíthen for some permutation
œÄ we have ‚ü®eœÄ(1); ...; eœÄ(k), s, M0‚ü©‚àí‚Üí‚àó‚ü®e‚Ä≤‚Ä≤, s‚Ä≤, M ‚Ä≤‚ü©.
Say they are deadlock-free if for any initial store s, if
‚ü®(e1 ... ek), s, M0‚ü©‚àí‚Üí‚àó‚ü®e‚Ä≤, s‚Ä≤, M ‚ü©Ã∏‚àí‚Üíthen not e‚Ä≤ lock m
‚àí‚Üíe‚Ä≤‚Ä≤,
i.e.e‚Ä≤ does not contain any blocked lock m subexpressions.
(Warning: there are many subtle variations of these properties!)
Slide 236
The Theorem
Conjecture 30 If each ei obeys the discipline, then e1, ...ek are
serializable and deadlock-free.
(may be false!)
Proof strategy: Consider a (derivation of a) computation
‚ü®(e1 ... ek), s, M0‚ü©‚àí‚Üí‚ü®ÀÜe1, s1, M1‚ü©‚àí‚Üí‚ü®ÀÜe2, s2, M2‚ü©‚àí‚Üí...
We know each ÀÜei is a corresponding parallel composition. Look at the
points at which each ei acquires its Ô¨Ånal lock. That deÔ¨Ånes a serialization
order. In between times, consider commutativity of actions of the different
ei ‚Äì the premises guarantee that many actions are semantically
independent, and so can be permuted.
Slide 237
We‚Äôve not discussed fairness ‚Äì the semantics allows any interleaving
between parallel components, not only fair ones.
Slide 238
Language Properties
(Obviously!) don‚Äôt have Determinacy.
Still have Type Preservation.
Have Progress, but it has to be modiÔ¨Åed ‚Äì a well-typed expression of type
proc will reduce to some parallel composition of unit values.
Typing and type inference is scarcely changed.
(very fancy type systems can be used to enforce locking disciplines)
104

8.1
Exercises
Exercise 39 ‚ãÜ‚ãÜAre the mutexes speciÔ¨Åed here similar to those described in C&DS?
Exercise 40 ‚ãÜ‚ãÜCan you show all the conditions for O2PL are necessary, by giving for
each an example that satisÔ¨Åes all the others and either is not serialisable or deadlocks?
Exercise 41 ‚ãÜ‚ãÜ‚ãÜ‚ãÜProve the Conjecture about it.
Exercise 42 ‚ãÜ‚ãÜ‚ãÜWrite a semantics for an extension of L1 with threads that are more
like Unix threads (e.g. with thread ids, fork, etc..). Include some of the various ways Unix
threads can exchange information.
9
Epilogue
Slide 239
Epilogue
Slide 240
Lecture Feedback
Please do Ô¨Åll in the lecture feedback form ‚Äì we need to know how the
course could be improved / what should stay the same.
Slide 241
Good language design?
Need:
‚Ä¢ precise deÔ¨Ånition of what the language is (so can communicate among
the designers)
‚Ä¢ technical properties (determinacy, decidability of type checking, etc.)
‚Ä¢ pragmatic properties (usability in-the-large, implementability)
Slide 242
What can you use semantics for?
1. to understand a particular language ‚Äî what you can depend on as a
programmer; what you must provide as a compiler writer
2. as a tool for language design:
(a) for expressing design choices, understanding language features
and how they interact.
(b) for proving properties of a language, eg type safety, decidability of
type inference.
3. as a foundation for proving properties of particular programs
105

106

A
Interpreter and type checker for L1 (ML)
Here is an interpreter and type checker for L1. You can download the source code from the
course website.
(* 2002-11-08 -- Time-stamp: <2006-10-25 09:22:33 pes20>
-*-SML-*- *)
(* Peter Sewell
*)
(* This file contains an interpreter, pretty-printer and type-checker
for the language L1.
To make it go, copy it into a working
directory, ensure Moscow ML is available, and type
mosml -P full l1.ml
That will give you a MoscowML top level in which these definitions
are present.
You can then type
doit ();
to show the reduction sequence of < l1:=3;!l1 , {l1=0 } >, and
doit2 ();
to run the type-checker on the same simple example; you can try
other examples analogously.
This file doesn‚Äôt have a parser for
l1, so you‚Äôll have to enter the abstract syntax directly, eg
prettyreduce (Seq( Assign ("l1",Integer 3), Deref "l1"), [("l1",0)]);
This has been tested with Moscow ML version 2.00 (June 2000), but
should work with any other implementation of Standard ML.
*)
(* *********************)
(* the abstract syntax *)
(* *********************)
type loc = string
datatype oper = Plus | GTEQ
datatype expr =
Integer of int
| Boolean of bool
| Op of expr * oper * expr
| If of expr * expr * expr
| Assign of loc * expr
| Deref of loc
| Skip
| Seq of expr * expr
| While of expr * expr
(* **********************************)
(* an interpreter for the semantics *)
(* **********************************)
fun is_value (Integer n) = true
| is_value (Boolean b) = true
| is_value (Skip) = true
| is_value _ = false
107

(* In the semantics, a store is a finite partial function from
locations to integers.
In the implementation, we represent a store
as a list of loc*int pairs containing, for each l in the domain of
the store, exactly one element of the form (l,n).
The operations
lookup : store * loc
-> int option
update : store * (loc * int) -> store option
both return NONE if given a location that is not in the domain of
the store.
This is not a very efficient implementation, but it is
simple. *)
type store = (loc * int) list
fun lookup ( [], l ) = NONE
| lookup ( (l‚Äô,n‚Äô)::pairs, l) =
if l=l‚Äô then SOME n‚Äô else lookup (pairs,l)
fun update‚Äô
front [] (l,n) = NONE
|
update‚Äô
front ((l‚Äô,n‚Äô)::pairs) (l,n) =
if l=l‚Äô then
SOME(front @ ((l,n)::pairs) )
else
update‚Äô ((l‚Äô,n‚Äô)::front) pairs (l,n)
fun update (s, (l,n)) = update‚Äô [] s (l,n)
(* now define the single-step function
reduce :
expr * store -> (expr * store) option
which takes a configuration (e,s) and returns either NONE, if it has
no transitions, or SOME (e‚Äô,s‚Äô), if it has a transition (e,s) -->
(e‚Äô,s‚Äô).
Note that the code depends on global properties of the semantics,
including the fact that it defines a deterministic transition
system, so the comments indicating that particular lines of code
implement particular semantic rules are not the whole story.
*)
fun reduce (Integer n,s) = NONE
| reduce (Boolean b,s) = NONE
| reduce (Op (e1,opr,e2),s) =
(case (e1,opr,e2) of
(Integer n1, Plus, Integer n2) => SOME(Integer (n1+n2), s)
(*op + *)
| (Integer n1, GTEQ, Integer n2) => SOME(Boolean (n1 >= n2), s)(*op >=*)
| (e1,opr,e2) => (
if (is_value e1) then (
case reduce (e2,s) of
SOME (e2‚Äô,s‚Äô) => SOME (Op(e1,opr,e2‚Äô),s‚Äô)
(* (op2) *)
| NONE => NONE )
else (
case reduce (e1,s) of
SOME (e1‚Äô,s‚Äô) => SOME(Op(e1‚Äô,opr,e2),s‚Äô)
(* (op1) *)
| NONE => NONE ) ) )
| reduce (If (e1,e2,e3),s) =
(case e1 of
Boolean(true) => SOME(e2,s)
(* (if1) *)
| Boolean(false) => SOME(e3,s)
(* (if2) *)
| _ => (case reduce (e1,s) of
SOME(e1‚Äô,s‚Äô) => SOME(If(e1‚Äô,e2,e3),s‚Äô)
(* (if3) *)
108

| NONE => NONE ))
| reduce (Deref l,s) =
(case lookup
(s,l) of
SOME n => SOME(Integer n,s)
(* (deref) *)
| NONE => NONE )
| reduce (Assign (l,e),s) =
(case e of
Integer n => (case update (s,(l,n)) of
SOME s‚Äô => SOME(Skip, s‚Äô)
(* (assign1) *)
| NONE => NONE)
| _ => (case reduce (e,s) of
SOME (e‚Äô,s‚Äô) => SOME(Assign (l,e‚Äô), s‚Äô)
(* (assign2) *)
| NONE => NONE
) )
| reduce (While (e1,e2),s) = SOME( If(e1,Seq(e2,While(e1,e2)),Skip),s) (* (while) *)
| reduce (Skip,s) = NONE
| reduce (Seq (e1,e2),s) =
(case e1 of
Skip => SOME(e2,s)
(* (seq1) *)
| _ => ( case reduce (e1,s) of
SOME (e1‚Äô,s‚Äô) => SOME(Seq (e1‚Äô,e2), s‚Äô)
(* (seq2) *)
| NONE => NONE ) )
(* now define the many-step evaluation function
evaluate :
expr * store -> (expr * store) option
which takes a configuration (e,s) and returns the unique (e‚Äô,s‚Äô)
such that
(e,s) -->* (e‚Äô,s‚Äô) -/->.
*)
fun evaluate (e,s) = case reduce (e,s) of
NONE => (e,s)
| SOME (e‚Äô,s‚Äô) => evaluate (e‚Äô,s‚Äô)
(* **********************************)
(* typing
*)
(* **********************************)
(* types *)
datatype type_L1 =
int
| unit
| bool
datatype type_loc =
intref
type typeEnv = (loc*type_loc) list
(* in the semantics, type environments gamma are partial functions
from locations to the singleton set {intref}. Here, just as we did for
stores, we represent them as a list of loc*type_loc pairs containing,
for each l in the domain of the type environment, exactly one element
of the form (l,intref).
*)
(* ****************)
(* type inference *)
(* ****************)
109

(* infertype : typeEnv -> expr -> type_L1 option *)
(* again, we depend on a uniqueness property, without which we would
have to have infertype return a type_L1 list of all the possible types *)
fun infertype gamma (Integer n) = SOME int
| infertype gamma (Boolean b) = SOME bool
| infertype gamma (Op (e1,opr,e2))
= (case (infertype gamma e1, opr, infertype gamma e2) of
(SOME int, Plus, SOME int) => SOME int
| (SOME int, GTEQ, SOME int) => SOME bool
| _ => NONE)
| infertype gamma (If (e1,e2,e3))
= (case (infertype gamma e1, infertype gamma e2, infertype gamma e3) of
(SOME bool, SOME t2, SOME t3) =>
(if t2=t3 then SOME t2 else NONE)
| _ => NONE)
| infertype gamma (Deref l)
= (case lookup (gamma,l) of
SOME intref => SOME int
| NONE => NONE)
| infertype gamma (Assign (l,e))
= (case (lookup (gamma,l), infertype gamma e) of
(SOME intref,SOME int) => SOME unit
| _ => NONE)
| infertype gamma (Skip) = SOME unit
| infertype gamma (Seq (e1,e2))
= (case (infertype gamma e1, infertype gamma e2) of
(SOME unit, SOME t2) => SOME t2
| _ => NONE )
| infertype gamma (While (e1,e2))
= (case (infertype gamma e1, infertype gamma e2) of
(SOME bool, SOME unit) => SOME unit
| _ => NONE )
110

B
Interpreter and type checker for L1 (Java)
Here is an interpreter and type checker for L1, written in Java by Matthew Parkinson.
Note the diÔ¨Äerent code organization between the ML and Java versions: the ML has a
datatype with a constructor for each clause of the abstract syntax grammar, and reduce
and infertype function deÔ¨Ånitions that each have a case for each of those constructors; the
Java has a subclass of Expression for each clause of the abstract syntax, each of which
deÔ¨Ånes smallStep and typecheck methods.
public class L1 {
public static void main(String [] args) {
Location l1 = new Location ("l1");
Location l2 = new Location ("l2");
Location l3 = new Location ("l3");
State s1 = new State()
.add(l1,new Int(1))
.add(l2,new Int(5))
.add(l3,new Int(0));
Environment env = new Environment()
.add(l1).add(l2).add(l3);
Expression e =
new Seq(new While(new GTeq(new Deref(l2),new Deref(l1)),
new Seq(new Assign(l3, new Plus(new Deref(l1),new Deref(l3))),
new Assign(l1,new Plus(new Deref(l1),new Int(1))))
),
new Deref(l3))
;
try{
//Type check
Type t= e.typeCheck(env);
System.out.println("Program has type: " + t);
//Evaluate program
System.out.println(e + "\n \n");
while(!(e instanceof Value) ){
e = e.smallStep(s1);
//Display each step of reduction
System.out.println(e + "\n \n");
}
//Give some output
System.out.println("Program has type: " + t);
System.out.println("Result has type: " + e.typeCheck(env));
System.out.println("Result: " + e);
System.out.println("Terminating State: " + s1);
} catch (TypeError te) {
System.out.println("Error:\n" + te);
System.out.println("From code:\n" + e);
} catch (CanNotReduce cnr) {
System.out.println("Caught Following exception" + cnr);
System.out.println("While trying to execute:\n " + e);
System.out.println("In state: \n " + s1);
}
}
}
class Location {
String name;
111

Location(String n) {
this.name = n;
}
public String toString() {return name;}
}
class State {
java.util.HashMap store = new java.util.HashMap();
//Used for setting the initial store for testing not used by
//semantics of L1
State add(Location l, Value v) {
store.put(l,v);
return this;
}
void update(Location l, Value v) throws CanNotReduce {
if(store.containsKey(l)) {
if(v instanceof Int) {
store.put(l,v);
}
else throw new CanNotReduce("Can only store integers");
}
else throw new CanNotReduce("Unknown location!");
}
Value lookup(Location l) throws CanNotReduce {
if(store.containsKey(l)) {
return (Int)store.get(l);
}
else throw new CanNotReduce("Unknown location!");
}
public String toString() {
String ret = "[";
java.util.Iterator iter = store.entrySet().iterator();
while(iter.hasNext()) {
java.util.Map.Entry e = (java.util.Map.Entry)iter.next();
ret += "(" + e.getKey() + " |-> " + e.getValue() + ")";
if(iter.hasNext()) ret +=", ";
}
return ret + "]";
}
}
class Environment {
java.util.HashSet env = new java.util.HashSet();
//Used to initially setup environment, not used by type checker.
Environment add(Location l) {
env.add(l); return this;
}
boolean contains(Location l) {
return env.contains(l);
}
}
class Type {
int type;
Type(int t) {type = t;}
public static final Type BOOL = new Type(1);
public static final Type INT = new Type(2);
public static final Type UNIT = new Type(3);
112

public String toString() {
switch(type) {
case 1: return "BOOL";
case 2: return "INT";
case 3: return "UNIT";
}
return "???";
}
}
abstract class Expression {
abstract Expression smallStep(State state) throws CanNotReduce;
abstract Type typeCheck(Environment env) throws TypeError;
}
abstract class Value extends Expression {
final Expression smallStep(State state) throws CanNotReduce{
throw new CanNotReduce("I‚Äôm a value");
}
}
class CanNotReduce extends Exception{
CanNotReduce(String reason) {super(reason);}
}
class TypeError extends Exception { TypeError(String reason) {super(reason);}}
class Bool extends Value {
boolean value;
Bool(boolean b) {
value = b;
}
public String toString() {
return value ? "TRUE" : "FALSE";
}
Type typeCheck(Environment env) throws TypeError {
return Type.BOOL;
}
}
class Int extends Value {
int value;
Int(int i) {
value = i;
}
public String toString(){return ""+ value;}
Type typeCheck(Environment env) throws TypeError {
return Type.INT;
}
}
class Skip extends Value {
public String toString(){return "SKIP";}
Type typeCheck(Environment env) throws TypeError {
return Type.UNIT;
}
}
113

class Seq extends Expression {
Expression exp1,exp2;
Seq(Expression e1, Expression e2) {
exp1 = e1;
exp2 = e2;
}
Expression smallStep(State state) throws CanNotReduce {
if(exp1 instanceof Skip) {
return exp2;
} else {
return new Seq(exp1.smallStep(state),exp2);
}
}
public String toString() {return exp1 + "; " + exp2;}
Type typeCheck(Environment env) throws TypeError {
if(exp1.typeCheck(env) == Type.UNIT) {
return exp2.typeCheck(env);
}
else throw new TypeError("Not a unit before ‚Äô;‚Äô.");
}
}
class GTeq extends Expression {
Expression exp1, exp2;
GTeq(Expression e1,Expression e2) {
exp1 = e1;
exp2 = e2;
}
Expression smallStep(State state) throws CanNotReduce {
if(!( exp1 instanceof Value)) {
return new GTeq(exp1.smallStep(state),exp2);
} else if (!( exp2 instanceof Value)) {
return new GTeq(exp1, exp2.smallStep(state));
} else {
if( exp1 instanceof Int && exp2 instanceof Int ) {
return new Bool(((Int)exp1).value >= ((Int)exp2).value);
}
else throw new CanNotReduce("Operands are not both integers.");
}
}
public String toString(){return exp1 + " >= " + exp2;}
Type typeCheck(Environment env) throws TypeError {
if(exp1.typeCheck(env) == Type.INT && exp2.typeCheck(env) == Type.INT) {
return Type.BOOL;
}
else throw new TypeError("Arguments not both integers.");
}
}
class Plus extends Expression {
Expression exp1, exp2;
Plus(Expression e1,Expression e2) {
exp1 = e1;
exp2 = e2;
}
Expression smallStep(State state) throws CanNotReduce {
114

if(!( exp1 instanceof Value)) {
return new Plus(exp1.smallStep(state),exp2);
} else if (!( exp2 instanceof Value)) {
return new Plus(exp1, exp2.smallStep(state));
} else {
if( exp1 instanceof Int && exp2 instanceof Int ) {
return new Int(((Int)exp1).value + ((Int)exp2).value);
}
else throw new CanNotReduce("Operands are not both integers.");
}
}
public String toString(){return exp1 + " + " + exp2;}
Type typeCheck(Environment env) throws TypeError {
if(exp1.typeCheck(env) == Type.INT && exp2.typeCheck(env) == Type.INT) {
return Type.INT;
}
else throw new TypeError("Arguments not both integers.");
}
}
class IfThenElse extends Expression {
Expression exp1,exp2,exp3;
IfThenElse (Expression e1, Expression e2,Expression e3) {
exp1 = e1;
exp2 = e2;
exp3 = e3;
}
Expression smallStep(State state) throws CanNotReduce {
if(exp1 instanceof Value) {
if(exp1 instanceof Bool) {
if(((Bool)exp1).value)
return exp2;
else
return exp3;
}
else throw new CanNotReduce("Not a boolean in test.");
}
else {
return new IfThenElse(exp1.smallStep(state),exp2,exp3);
}
}
public String toString() {return "IF " + exp1 + " THEN " + exp2 + " ELSE " + exp3;}
Type typeCheck(Environment env) throws TypeError {
if(exp1.typeCheck(env) == Type.BOOL) {
Type t = exp2.typeCheck(env);
if(exp3.typeCheck(env) == t)
return t;
else throw new TypeError("If branchs not the same type.");
}
else throw new TypeError("If test is not bool.");
}
}
class Assign extends Expression {
Location l;
Expression exp1;
115

Assign(Location l, Expression exp1) {
this.l = l;
this.exp1 = exp1;
}
Expression smallStep(State state) throws CanNotReduce{
if(exp1 instanceof Value) {
state.update(l,(Value)exp1);
return new Skip();
}
else {
return new Assign(l,exp1.smallStep(state));
}
}
public String toString() {return l + " = " + exp1;}
Type typeCheck(Environment env) throws TypeError {
if(env.contains(l) && exp1.typeCheck(env) == Type.INT) {
return Type.UNIT;
}
else throw new TypeError("Invalid assignment");
}
}
class Deref extends Expression {
Location l;
Deref(Location l) {
this.l = l;
}
Expression smallStep(State state) throws CanNotReduce {
return state.lookup(l);
}
public String toString() {return "!" + l;}
Type typeCheck(Environment env) throws TypeError {
if(env.contains(l)) return Type.INT;
else throw new TypeError("Location not known about!");
}
}
class While extends Expression {
Expression exp1,exp2;
While(Expression e1, Expression e2) {
exp1 = e1;
exp2 = e2;
}
Expression smallStep(State state) throws CanNotReduce {
return new IfThenElse(exp1,new Seq(exp2, this), new Skip());
}
public String toString(){return "WHILE " + exp1 + " DO {" + exp2 +"}";}
Type typeCheck(Environment env) throws TypeError {
if(exp1.typeCheck(env) == Type.BOOL && exp2.typeCheck(env) == Type.UNIT)
return Type.UNIT;
else throw new TypeError("Error in while loop");
}
}
116

C
How to do Proofs
The purpose of this handout is give a general guide as to how to prove theorems. This
should give you some help in answering questions that begin with ‚ÄúShow that the following
is true . . . ‚Äù. It is based on notes by Myra VanInwegen, with additional text added by Peter
Sewell in ¬ßC.1. Many thanks to Myra for making her original notes available.
The focus here is on doing informal but rigorous proofs. These are rather diÔ¨Äerent from
the formal proofs, in Natural Deduction or Sequent Calculus, that were introduced in the
Logic and Proof course. Formal proofs are derivations in one of those proof systems ‚Äì they
are in a completely well-deÔ¨Åned form, but are often far too verbose to deal with by hand
(although they can be machine-checked). Informal proofs, on the other hand, are the usual
mathematical notion of proof: written arguments to persuade the reader that you could, if
pushed, write a fully formal proof.
This is important for two reasons. Most obviously, you should learn how to do these proofs.
More subtly, but more importantly, only by working with the mathematical deÔ¨Ånitions in
some way can you develop a good intuition for what they mean ‚Äî trying to do some proofs
is the best way of understanding the deÔ¨Ånitions.
C.1
How to go about it
Proofs diÔ¨Äer, but for many of those you meet the following steps should be helpful.
1. Make sure the statement of the conjecture is precisely deÔ¨Åned. In particular, make
sure you understand any strange notation, and Ô¨Ånd the deÔ¨Ånitions of all the auxiliary
gadgets involved (e.g. deÔ¨Ånitions of any typing or reduction relations mentioned in the
statement, or any other predicates or functions).
2. Try to understand at an intuitive level what the conjecture is saying ‚Äì verbalize out
loud the basic point.
For example, for a Type Preservation conjecture, the basic
point might be something like ‚Äúif a well-typed conÔ¨Åguration reduces, the result is still
well-typed (with the same type)‚Äù.
3. Try to understand intuitively why it is true (or false...).
Identify what the most
interesting cases might be ‚Äî the cases that you think are most likely to be suspicious,
or hard to prove. Sometimes it‚Äôs good to start with the easy cases (if the setting
is unfamiliar to you); sometimes it‚Äôs good to start with the hard cases (to Ô¨Ånd any
interesting problems as soon as possible).
4. Think of a good basic strategy. This might be:
(a) simple logic manipulations;
(b) collecting together earlier results, again by simple logic; or
(c) some kind of induction.
5. Try it! (remembering you might have to backtrack if you discover you picked a strategy
that doesn‚Äôt work well for this conjecture). This might involve any of the following:
(a) Expanding deÔ¨Ånitions, inlining them. Sometimes you can just blindly expand all
deÔ¨Ånitions, but more often it‚Äôs important to expand only the deÔ¨Ånitions which
you want to work with the internal structure of ‚Äî otherwise things just get too
verbose.
(b) Making abbreviations ‚Äî deÔ¨Åning a new variable to stand for some complex gadget
you‚Äôre working with, saying e.g.
117

where e = (let x:int = 7+2 in x+x)
Take care with choosing variable names.
(c) Doing equational reasoning, e.g.
e = e1
by ...
= e2
by ...
= e3
as ...
Here the e might be any mathematical object ‚Äî arithmetic expressions, or ex-
pressions of some grammar, or formulae. Some handy equations over formulae
are given in ¬ßC.2.2.
(d) Proving a formula based on its structure. For example, to prove a formula ‚àÄx ‚àà
S.P(x) you would often assume you have an arbitrary x and then try to prove
P(x).
Take an arbitrary x
‚àà
S.
We now have to show P(x):
This is covered in detail in ¬ßC.2.3. Much proof is of this form, automatically
driven by the structure of the formula.
(e) Using an assumption you‚Äôve made above.
(f) Induction. As covered in the 1B Semantics notes, there are various kinds of induc-
tion you might want to use: mathematical induction over the natural numbers,
structural induction over the elements of some grammar, or rule induction over
the rules deÔ¨Åning some relation (especially a reduction or typing relation). For
each, you should:
i. Decide (and state!) what kind of induction you‚Äôre using. This may need
some thought and experience, and you might have to backtrack.
ii. Remind yourself what the induction principle is exactly.
iii. Decide on the induction hypothesis you‚Äôre going to use, writing down a pred-
icate Œ¶ which is such that the conclusion of the induction principle implies
the thing you‚Äôre trying to prove. Again, this might need some thought. Take
care with the quantiÔ¨Åers here ‚Äî it‚Äôs suspicious if your deÔ¨Ånition of Œ¶ has
any globally-free variables...
iv. Go through each of the premises of the induction principle and prove each one
(using any of these techniques as appropriate). Many of those premises will
be implications, e.g. ‚àÄx ‚ààN.Œ¶(x) ‚áíŒ¶(x + 1), for which you can do a proof
based on the structure of the formula ‚Äî taking an arbitrary x, assuming
Œ¶(x), and trying to prove Œ¶(x+1). Usually at some point in the latter you‚Äôd
make use of the assumption Œ¶(x).
6. In all of the above, remember: the point of doing a proof on paper is to use the
formalism to help you think ‚Äî to help you cover all cases, precisely ‚Äî and also to
communicate with the reader. For both, you need to write clearly:
(a) Use enough words! ‚ÄúAssume‚Äù, ‚ÄúWe have to show‚Äù, ‚ÄúBy such-and-such we know‚Äù,
‚ÄúHence‚Äù,...
(b) Don‚Äôt use random squiggles. It‚Äôs good to have formulae properly nested within
text, with and no ‚Äú‚áí‚Äù or ‚Äú‚à¥‚Äù between lines of text.
7. If it hasn‚Äôt worked yet... either
(a) you‚Äôve make some local mistake, e.g. mis-instantiated something, or used the
same variable for two diÔ¨Äerent things, or not noticed that you have a deÔ¨Ånition
you should have expanded or an assumption you should have used. Fix it and
continue.
118

(b) you‚Äôve discovered that the conjecture is really false. Usually at this point it‚Äôs
a good idea to construct a counterexample that is as simple as possible, and to
check carefully that it really is a counterexample.
(c) you need to try a diÔ¨Äerent strategy ‚Äî often, to use a diÔ¨Äerent induction principle
or to strengthen your induction hypothesis.
(d) you didn‚Äôt really understand intuitively what the conjecture is saying, or what
the deÔ¨Ånitions it uses mean. Go back to them again.
8. If it has worked: read through it, skeptically, and check. Maybe you‚Äôll need to re-write
it to make it comprehensible: proof discovery is not the same as proof exposition. See
the example proofs in the Semantics notes.
9. Finally, give it to someone else, as skeptical and careful as you can Ô¨Ånd, to see if they
believe it ‚Äî to see if they believe that what you‚Äôve written down is a proof, not that
they believe that the conjecture is true.
C.2
And in More Detail...
First, I‚Äôll explain informal proof intuitively, giving a couple of examples. Then I‚Äôll explain
how this intuition is reÔ¨Çected in the sequent rules from Logic and Proof.
In the following, I‚Äôll call any logic statement a formula. In general, what we‚Äôll be trying to
do is prove a formula, using a collection of formulas that we know to be true or are assuming
to be true. There‚Äôs a big diÔ¨Äerence between using a formula and proving a formula. In fact,
what you do is in many ways opposite. So, I‚Äôll start by explaining how to prove a formula.
C.2.1
Meet the Connectives
Here are the logical connectives and a very brief decription of what each means.
P ‚àßQ
P and Q are both true
P ‚à®Q
P is true, or Q is true, or both are true
¬¨P
P is not true (P is false)
P ‚áíQ
if P is true then Q is true
P ‚áîQ
P is true exactly when Q is true
‚àÄx ‚ààS.P(x)
for all x in S, P is true of x
‚àÉx ‚ààS.P(x)
there exists an x in S such that P holds of x
C.2.2
Equivalences
These are formulas that mean the same thing, and this is indicated by a ‚âÉbetween them.
The fact that they are equivalent to each other is justiÔ¨Åed by the truth tables of the con-
nectives.
119

deÔ¨Ånition of ‚áí
P ‚áíQ
‚âÉ
¬¨P ‚à®Q
deÔ¨Ånition of ‚áî
P ‚áîQ
‚âÉ
(P ‚áíQ) ‚àß(Q ‚áíP)
deÔ¨Ånition of ¬¨
¬¨P
‚âÉ
P ‚áífalse
de Morgan‚Äôs Laws
¬¨(P ‚àßQ)
‚âÉ
¬¨P ‚à®¬¨Q
¬¨(P ‚à®Q)
‚âÉ
¬¨P ‚àß¬¨Q
extension to quantiÔ¨Åers
¬¨(‚àÄx.P(x))
‚âÉ
‚àÉx.¬¨P(x)
¬¨(‚àÉx.P(x))
‚âÉ
‚àÄx.¬¨P(x)
distributive laws
P ‚à®(Q ‚àßR)
‚âÉ
(P ‚à®Q) ‚àß(P ‚à®R)
P ‚àß(Q ‚à®R)
‚âÉ
(P ‚àßQ) ‚à®(P ‚àßR)
coalescing quantiÔ¨Åers
(‚àÄx.P(x)) ‚àß(‚àÄx.Q(x))
‚âÉ
‚àÄx.(P(x) ‚àßQ(x))
(‚àÉx.P(x)) ‚à®(‚àÉx.Q(x))
‚âÉ
‚àÉx.(P(x) ‚à®Q(x))
these ones apply if
(‚àÄx.P(x)) ‚àßQ
‚âÉ
(‚àÄx.P(x) ‚àßQ)
x is not free in Q
(‚àÄx.P(x)) ‚à®Q
‚âÉ
(‚àÄx.P(x) ‚à®Q)
(‚àÉx.P(x)) ‚àßQ
‚âÉ
(‚àÉx.P(x) ‚àßQ)
(‚àÉx.P(x)) ‚à®Q
‚âÉ
(‚àÉx.P(x) ‚à®Q)
C.2.3
How to Prove a Formula
For each of the logical connectives, I‚Äôll explain how to handle them.
‚àÄx ‚ààS.P(x)
This means ‚ÄúFor all x in S, P is true of x.‚Äù Such a formula is called a
universally quantiÔ¨Åed formula. The goal is to prove that the property P, which has some
xs somewhere in it, is true no matter what value in S x takes on. Often the ‚Äú‚ààS‚Äù is left
out. For example, in a discussion of lists, you might be asked to prove ‚àÄl.length l > 0 ‚áí
‚àÉx. member(x, l). Obviously, l is a list, even if it isn‚Äôt explicitly stated as such.
There are several choices as to how to prove a formula beginning with ‚àÄx. The standard
thing to do is to just prove P(x), not assuming anything about x. Thus, in doing the proof
you sort of just mentally strip oÔ¨Äthe ‚àÄx. What you would write when doing this is‚ÄúLet x be
any S‚Äù. However, there are some subtleties‚Äîif you‚Äôre already using an x for something else,
you can‚Äôt use the same x, because then you would be assuming something about x, namely
that it equals the x you‚Äôre already using. In this case, you need to use alpha-conversion1 to
change the formula you want to prove to ‚àÄy ‚ààS.P(y), where y is some variable you‚Äôre not
already using, and then prove P(y). What you could write in this case is ‚ÄúSince x is already
in use, we‚Äôll prove the property of y‚Äù.
An alternative is induction, if S is a set that is deÔ¨Åned with a structural deÔ¨Ånition. Many
objects you‚Äôre likely to be proving properties of are deÔ¨Åned with a structural deÔ¨Ånition.
This includes natural numbers, lists, trees, and terms of a computer language. Sometimes
you can use induction over the natural numbers to prove things about other objects, such
as graphs, by inducting over the number of nodes (or edges) in a graph.
You use induction when you see that during the course of the proof you would need to use
the property P for the subparts of x in order to prove it for x. This usually ends up being
the case if P involves functions deÔ¨Åned recursively (i.e., the return value for the function
depends on the function value on the subparts of the argument).
A special case of induction is case analysis. It‚Äôs basically induction where you don‚Äôt use the
inductive hypothesis: you just prove the property for each possible form that x could have.
Case analysis can be used to prove the theorem about lists above.
A Ô¨Ånal possibility (which you can use for all formulas, not just for universally quantiÔ¨Åed
ones) is to assume the contrary, and then derive a contradiction.
1Alpha-equivalence says that the name of a bound variable doesn‚Äôt matter, so you can change it at will
(this is called alpha-conversion). You‚Äôll get to know the exact meaning of this soon enough so I won‚Äôt explain
this here.
120

‚àÉx ‚ààS.P(x) This says ‚ÄúThere exists an x in S such that P holds of x.‚Äù Such a formula is
called an existentially quantiÔ¨Åed formula. The main way to prove this is to Ô¨Ågure out what
x has to be (that is, to Ô¨Ånd a concrete representation of it), and then prove that P holds of
that value. Sometimes you can‚Äôt give a completely speciÔ¨Åed value, since the value you pick
for x has to depend on the values of other things you have Ô¨Çoating around. For example,
say you want to prove
‚àÄx, y ‚ààR.x < y ‚àßsin x < 0 ‚àßsin y > 0 ‚áí‚àÉz.x < z ‚àßz < y ‚àßsin z = 0
where R is the set of real numbers. By the time you get to dealing with the ‚àÉz.x < z ‚àßz <
y ‚àßsin z = 0, you will have already assumed that x and y were any real numbers. Thus the
value you choose for z has to depend on whatever x and y are.
An alternative way to prove ‚àÉx ‚ààS.P(x) is, of course, to assume that no such x exists, and
derive a contradiction.
To summarize what I‚Äôve gone over so far: to prove a universally quantiÔ¨Åed formula, you must
prove it for a generic variable, one that you haven‚Äôt used before. To prove an existentially
quantiÔ¨Åed formula, you get to choose a value that you want to prove the property of.
P ‚áíQ This says ‚ÄúIf P is true, then Q is true‚Äù. Such a formula is called an implication,
and it is often pronounced ‚ÄúP implies Q‚Äù. The part before the ‚áísign (here P) is called
the antecedent, and the part after the ‚áísign (here Q) is called the consequent. P ‚áíQ is
equivalent to ¬¨P ‚à®Q, and so if P is false, or if Q is true, then P ‚áíQ is true.
The standard way to prove this is to assume P, then use it to help you prove Q. Note that
I said that you will be using P. Thus you will need to follow the rules in Section C.2.4 to
deal with the logical connectives in P.
Other ways to prove P ‚áíQ involve the fact that it is equivalent to ¬¨P ‚à®Q. Thus, you can
prove ¬¨P without bothering with Q, or you can just prove Q without bothering with P.
To reason by contradiction you assume that P is true and that Q is not true, and derive a
contradiction.
Another alternative is to prove the contrapositive: ¬¨Q ‚áí¬¨P, which is equivalent to it.
P ‚áîQ This says ‚ÄúP is true if and only if Q is true‚Äù. The phrase ‚Äúif and only if‚Äù is usually
abbreviated ‚ÄúiÔ¨Ä‚Äù. Basically, this means that P and Q are either both true, or both false.
IÔ¨Äis usually used in two main ways: one is where the equivalence is due to one formula
being a deÔ¨Ånition of another. For example, A ‚äÜB ‚áî(‚àÄx. x ‚ààA ‚áíx ‚ààB) is the standard
deÔ¨Ånition of subset. For these iÔ¨Ästatements, you don‚Äôt have to prove them. The other use
of iÔ¨Äis to state the equivalence of two diÔ¨Äerent things. For example, you could deÔ¨Åne an
SML function fact:
fun fact 0 = 1
| fact n = n * fact (n - 1)
Since in SML whole numbers are integers (both positive and negative) you may be asked
to prove: fact x terminates ‚áîx ‚â•0. The standard way to do this is us the equivalence
P ‚áîQ is equivalent to P ‚áíQ ‚àßQ ‚áíP. And so you‚Äôd prove that (fact x terminates ‚áí
x ‚â•0) ‚àß(x ‚â•0 ‚áífact x terminates).
¬¨P
This says ‚ÄúP is not true‚Äù. It is equivalent to P ‚áífalse, thus this is one of the ways
you prove it: you assume that P is true, and derive a contradiction (that is, you prove
false). Here‚Äôs an example of this, which you‚Äôll run into later this year: the undecidability
of the halting problem can be rephrased as ¬¨‚àÉx ‚ààRM. x solves the halting problem, where
RM is the set of register machines. The proof of this in your Computation Theory notes
follows exactly the pattern I described‚Äîit assumes there is such a machine and derives a
contradiction.
121

The other major way to prove ¬¨P is to Ô¨Ågure out what the negation of P is, using equiva-
lences like De Morgan‚Äôs Law, and then prove that. For example, to prove ¬¨‚àÄx ‚ààN. ‚àÉy ‚àà
N. x = y2, where N is the set of natural numbers, you could push in the negation to get:
‚àÉx ‚ààN. ‚àÄy ‚ààN. x Ã∏= y2, and then you could prove that.
P ‚àßQ This says ‚ÄúP is true and Q is true‚Äù. Such a formula is called a conjunction. To
prove this, you have to prove P, and you have to prove Q.
P ‚à®Q This says ‚ÄúP is true or Q is true‚Äù. This is inclusive or: if P and Q are both true,
then P ‚à®Q is still true. Such a formula is called a disjunction. To prove this, you can prove
P or you can prove Q. You have to choose which one to prove. For example, if you need to
prove (5 mod 2 = 0) ‚à®(5 mod 2 = 1), then you‚Äôll choose the second one and prove that.
However, as with existentials, the choice of which one to prove will often depend on the
values of other things, like universally quantiÔ¨Åed variables.
For example, when you are
studying the theory of programming languages (you will get a bit of this in Semantics), you
might be asked to prove
‚àÄP ‚ààML.
P is properly typed ‚áí
(the evaluation of P runs forever) ‚à®(P evaluates to a value)
where ML is the set of all ML programs. You don‚Äôt know in advance which of these will be
the case, since some programs do run forever, and some do evaluate to a value. Generally,
the best way to prove the disjunction in this case (when you don‚Äôt know in advance which
will hold) is to use the equivalence with implication. For example, you can use the fact
that P ‚à®Q is equivalent to ¬¨P ‚áíQ, then assume ¬¨P, then use this to prove Q. For
example, your best bet to proving this programming languages theorem is to assume that
the evaluation of P doesn‚Äôt run forever, and use this to prove that P evaluates to a value.
C.2.4
How to Use a Formula
You often end up using a formula to prove other formulas. You can use a formula if someone
has already proved that it‚Äôs true, or you are assuming it because it was in an implication,
namely, the A in A ‚áíB. For each logical connective, I‚Äôll tell you how to use it.
‚àÄx ‚ààS.P(x) This formula says that something is true of all elements of S. Thus, when
you use it, you can pick any value at all to use instead of x (call it v), and then you can use
P(v).
‚àÉx ‚ààS.P(x) This formula says that there is some x that satisÔ¨Åes P. However, you do not
know what it is, so you can not assume anything about it. The usual approach it to just
say that the thing that is being said to exist is just x, and use the fact that P holds of x to
prove something else. However, if you‚Äôre already using an x for something else, you have to
pick another variable to represent the thing that exists.
To summarize this: to use a universally quantiÔ¨Åed formula, you can choose any value, and
use that the formula holds for that variable. To use an existentially quantiÔ¨Åed formula, you
must not assume anything about the value that is said to exists, so you just use a variable
(one that you haven‚Äôt used before) to represent it. Note that this is more or less opposite
of what you do when you prove a universally or existentially quantiÔ¨Åed formula.
¬¨P
Usually, the main use of this formula is to prove the negation of something else.
An example is the use of reduction to prove the unsolvability of various problems in the
Computation Theory (you‚Äôll learn all about this in Lent term). You want to prove ¬¨Q,
where Q states that a certain problem (Problem 1) is decidable (in other words, you want
to prove that Problem 1 is not decidable). You know ¬¨P, where P states that another
problem (Problem 2) is decidable (i.e. ¬¨P says that Problem 2 is not decidable). What you
122

do basically is this. You Ô¨Årst prove Q ‚áíP, which says that if Problem 1 is decidable, then
so is Problem 2. Since Q ‚áíP ‚âÉ¬¨P ‚áí¬¨Q, you have now proved ¬¨P ‚áí¬¨Q. You already
know ¬¨P, so you use modus ponens2 to get that ¬¨Q.
P ‚áíQ The main way to use this is that you prove P, and then you use modus ponens to
get Q, which you can then use.
P ‚áîQ The main use of this is to replace an occurrence of P in a formula with Q, and
vise versa.
P ‚àßQ Here you can use both P and Q. Note, you‚Äôre not required to use both of them, but
they are both true and are waiting to be used by you if you need them.
P ‚à®Q Here, you know that one of P or Q is true, but you do not know which one. To use
this to prove something else, you have to do a split: Ô¨Årst you prove the thing using P, then
you prove it using Q.
Note that in each of the above, there is again a diÔ¨Äerence in the way you use a formula,
verses the way you prove it. They are in a way almost opposites. For example, in proving
P ‚àßQ, you have to prove both P and Q, but when you are using the formula, you don‚Äôt
have to use both of them.
C.3
An Example
There are several exercises in the Semantics notes that ask you to prove something. Here,
we‚Äôll go back to Regular Languages and Finite Automata.
(If they‚Äôve faded, it‚Äôs time
to remind yourself of them.) The Pumping Lemma for regular sets (PL for short) is an
astonishingly good example of the use of quantiÔ¨Åers. We‚Äôll go over the proof and use of the
PL, paying special attention to the logic of what‚Äôs happening.
C.3.1
Proving the PL
My favorite book on regular languages, Ô¨Ånite automata, and their friends is the Hopcroft
and Ullman book Introduction to Automata Theory, Languages, and Computation. You
should locate this book in your college library, and if it isn‚Äôt there, insist that your DoS
order it for you.
In the Automata Theory book, the Pumping Lemma is stated as: ‚ÄúLet L be a regular set.
Then there is a constant n such that if z is any word in L, and |z| ‚â•n, we may write z = uvw
in such a way that |uv| ‚â§n, |v| ‚â•1, and for all i ‚â•0, uviw is in L.‚Äù The Pumping Lemma
is, in my experience, one of the most diÔ¨Écult things about learning automata theory. It
is diÔ¨Écult because people don‚Äôt know what to do with all those logical connectives. Let‚Äôs
write it as a logical formula.
‚àÄL ‚ààRegularLanguages.
‚àÉn. ‚àÄz ‚ààL. |z| ‚â•n ‚áí
‚àÉu v w. z = uvw ‚àß|uv| ‚â§n ‚àß|v| ‚â•1 ‚àß
‚àÄi ‚â•0. uviw ‚ààL
Complicated, eh?
Well, let‚Äôs prove it, using the facts that Hopcroft and Ullman have
established in the chapters previous to the one wih the PL. I‚Äôll give the proof and put in
square brackets comments about what I‚Äôm doing.
Let L be any regular language.
[Here I‚Äôm dealing with the ‚àÄL ‚ààRegularLanguages by
stating that I‚Äôm not assuming anything about L.] Let M be a minimal-state deterministic
2Modus ponens says that if A ‚áíB and A are both true, then B is true.
123

Ô¨Ånite state machine accepting L. [Here I‚Äôm using a fact that Hopcroft and Ullman have
already proved about the equivalence of regular languages and Ô¨Ånite automata.] Let n be
the number of states in this Ô¨Ånite state machine. [I‚Äôm dealing with the ‚àÉn by giving a very
speciÔ¨Åc value of what it will be, based on the arbitrary L.] Let z be any word in L. [Thus
I deal with ‚àÄz ‚ààL.] Assume that |z| ‚â•n. [Thus I‚Äôm taking care of the ‚áíby assuming the
antecedent.]
Say z is written a1a2 . . . am, where m ‚â•n. Consider the states that M is in during the
processing of the Ô¨Årst n symbols of z, a1a2 . . . an. There are n + 1 of these states. Since
there are only n states in M, there must be a duplicate. Say that after symbols aj and ak
we are in the same state, state s (i.e. there‚Äôs a loop from this state that the machine goes
through as it accepts z), and say that j < k. Now, let u = a1a2 . . . aj. This represents the
part of the string that gets you to state s the Ô¨Årst time. Let v = aj+1 . . . ak. This represents
the loop that takes you from s and back to it again. Let w = ak+1 . . . am, the rest of word
z. [We have chosen deÔ¨Ånite values for u, v, and w.] Then clearly z = uvw, since u, v, and
w are just diÔ¨Äerent sections of z. |uv| ‚â§n since u and v occur within the Ô¨Årst n symbols
of z. |v| ‚â•1 since j < k. [Note that we‚Äôre dealing with the formulas connected with ‚àßby
proving each of them.]
Now, let i be a natural number (i.e. ‚â•0). [This deals with ‚àÄi ‚â•0.] Then uviw ‚ààL. [Finally
our conclusion, but we have to explain why this is true.] This is because we can repeat the
loop from s to s (represented by v) as many times as we like, and the resulting word will
still be accepted by M.
C.3.2
Using the PL
Now we use the PL to prove that a language is not regular. This is a rewording of Example
3.1 from Hopcroft and Ullman. I‚Äôll show that L = {0i2|i is an integer, i ‚â•1} is not regular.
Note that L consists of all strings of 0‚Äôs whose length is a perfect square. I will use the PL.
I want to prove that L is not regular. I‚Äôll assume the negation (i.e., that L is regular) and
derive a contradiction. So here we go. Remember that what I‚Äôm emphasizing here is not
the Ô¨Ånite automata stuÔ¨Äitself, but how to use a complicated theorem to prove something
else.
Assume L is regular. We will use the PL to get a contradiction. Since L is regular, the PL
applies to it. [We note that we‚Äôre using the ‚àÄpart of the PL for this particular L.] Let n
be as described in the PL. [This takes care of using the ‚àÉn. Note that we are not assuming
anything about its actual value, just that it‚Äôs a natural number.] Let z = 0n2. [Since the PL
says that something is true of all zs, we can choose the one we want to use it for.] So by the
PL there exist u, v, and w such that z = uvw, |uv| ‚â§n, |v| ‚â•1. [Note that we don‚Äôt assume
anything about what the u, v, and w actually are; the only thing we know about them is
what the PL tells us about them. This is where people trying to use the PL usually screw
up.] The PL then says that for any i, then uviw ‚ààL. Well, then uv2w ‚ààL. [This is using
the ‚àÄi ‚â•0 bit.] However, n2 < |uv2w| ‚â§n2 + n, since 1 ‚â§|v| ‚â§n. But n2 + n < (n + 1)2.
Thus |uv2w| lies properly between n2 and (n + 1)2 and is thus not a perfect square. Thus
uv2w is not in L. This is a contradiction. Thus our assumption (that L was regular) was
incorrect. Thus L is not a regular language.
C.4
Sequent Calculus Rules
In this section, I will show how the intuitive approach to things that I‚Äôve described above
is reÔ¨Çected in the sequent calculus rules. A sequent is Œì ‚ä¢‚àÜ, where Œì and ‚àÜare sets of
124

formulas.3 Technically, this means that
A1 ‚àßA2 ‚àß. . . An ‚áíB1 ‚à®B2 ‚à®. . . Bm
(1)
where A1, A2, . . . An are the formulas in Œì , and B1, B2, . . . Bn are the formulas in ‚àÜ. Less
formally, this means ‚Äúusing the formulas in Œì we can prove that one of the formula in ‚àÜis
true.‚Äù This is just the intuition I described above about using vs proving formulas, except
that I only talked about proving that one formula is true, rather than proving that one of
several formulas is true. In order to handle the ‚à®connective, there can be any number of
formulas on the right hand side of the ‚ä¢.
For each logic connective,4 I‚Äôll give the rules for it, and explain how it relates to the intuitive
way of using or proving formulas. For each connective there are at least two rules for it: one
for the left side of the ‚ä¢, and one for the right side. This corresponds to having diÔ¨Äerent
ways to treat a formula depending on whether you‚Äôre using it (for formulas on the left hand
side of the ‚ä¢) or proving it (for formulas on the right side of the ‚ä¢).
It‚Äôs easiest to understand these rules from the bottom up. The conclusion of the rule (the
sequent below the horizontal line) is what we want to prove. The hypotheses of the rule
(the sequents above the horizontal line) are how we go about proving it. We‚Äôll have to use
more rules, adding to the top, to build up the proof of the hypothesis, but this at least tells
us how to get going.
You can stop when the formula you have on the top is a basic sequent. This is Œì ‚ä¢‚àÜwhere
there‚Äôs at least one formula (say P) that‚Äôs in both Œì and ‚àÜ. You can see why this is the
basic true formula: it says that if P and the other formulas in Œì are true, then P or one of
the other formula in ‚àÜis true.
In building proofs from these rules, there are several ways that you end up with formulas
to the left of the ‚ä¢, where you can use them rather than proving them. One is that you‚Äôve
already proved it before. This is shown with the cut rule:
Œì ‚ä¢‚àÜ, P
P, Œì ‚ä¢‚àÜ
Œì ‚ä¢‚àÜ
(cut)
The ‚àÜ, P in the Ô¨Årst sequent in the hypotheses means that to the right of the ‚ä¢we have
the set consisting of the formula P plus all the formulas in ‚àÜ, i.e., if all formulas in Œì are
true, then P or one of the formulas in ‚àÜis true. Similarly P, Œì to the left of the ‚ä¢in the
second sequent means the set consisting of the formula P plus all the formulas in Œì.
We read this rule from the bottom up to make sense of it. Say we want to prove one of the
formulas in ‚àÜfrom the formulas in Œì, and we want to make use of a formula P that we‚Äôve
already proved. The fact that we‚Äôve proved P is shown by the left hypothesis (of course,
unless the left hypothesis is itself a basic sequent, then in a completed proof there will be
more lines on top of the left hypothesis, showing the actual proof of the sequent). The fact
that we are allowed to use P in the proof of ‚àÜis shown in the right hand hypothesis. We
continue to build the proof up from there, using P.
Some other ways of getting formulas to the left of the ‚ä¢are shown in the rules (¬¨r) and
(‚áír) below.
‚àÄx ‚ààS.P(x) The two rules for universally quantiÔ¨Åed formulas are:
P(v), Œì ‚ä¢‚àÜ
‚àÄx.P(x), Œì ‚ä¢‚àÜ(‚àÄl)
Œì ‚ä¢‚àÜ, P(x)
Œì ‚ä¢‚àÜ, ‚àÄx.P(x) (‚àÄr)
3In your Logic and Proof notes, the symbol that divides Œì from ‚àÜis ‚áí. However, that conÔ¨Çicts with the
use of ‚áías implication. Thus I will use ‚ä¢. You will see something similar in Semantics, where it separates
assumptions (of the types of variables) from something that they allow you to prove.
4I won‚Äôt mention iÔ¨Ähere: as P ‚áîQ is equivalent to P ‚áíQ ‚àßQ ‚áíP, we don‚Äôt need separate rules for
it.
125

In the (‚àÄr) rule, x must not be free in the conclusion.
Now, what‚Äôs going on here? In the (‚àÄl) rule, the ‚àÄx.P(x) is on the left side of the ‚ä¢. Thus, we
are using it (along with some other formula, those in Œì) to prove something (‚àÜ). According
to the intuition above, in order to use ‚àÄx.P(x), you can use it with any value, where v is
used to represent that value. In the hypothesis, you see the formula P(v) to the left of the
‚ä¢. This is just P with v substituted for x. The use of this corresponds exactly to using the
fact that P is true of any value whatsoever, since we are using it with v, which is any value
of our choice.
In the (‚àÄr) rule, the ‚àÄx.P(x) is on the right side of the ‚ä¢. Thus, we are proving it. Thus,
we need to prove it for a generic x. This is why the ‚àÄx is gone in the hypothesis. The x
is still sitting somewhere in the P, but we‚Äôre just using it as a plain variable, not assuming
anything about it. And this explains the side condition too: ‚ÄúIn the (‚àÄr) rule, x must not
be free in the conclusion.‚Äù If x is not free in the conclusion, this means that x is not free in
the formulas in Œì or ‚àÜ. That means the only place the x occurs free in the hypothesis is in
P itself. This corresponds exactly with the requirement that we‚Äôre proving that P is true
of a generic x: if x were free in Œì or ‚àÜ, we would be assuming something about x, namely
that value of x is the same as the x used in those formulas.
Note that induction is not mentioned in the rules. This is because the sequent calculus used
here just deals with pure logic. In more complicated presentations of logic, it is explained
how to deÔ¨Åne new types via structural induction, and from there you get mechanisms to
allow you to do induction.
‚àÉx ‚ààS.P(x) The two rules for existentially quantiÔ¨Åed formulas are:
P(x), Œì ‚ä¢‚àÜ
‚àÉx.P(x), Œì ‚ä¢‚àÜ(‚àÉl)
Œì ‚ä¢‚àÜ, P(v)
Œì ‚ä¢‚àÜ, ‚àÉx.P(x) (‚àÉr)
In the (‚àÉl) rule, x must not be free in the conclusion.
In (‚àÉl), we are using ‚àÉx.P(x). Thus we cannot assume anything about the value that the
formula says exists, so we just use it as x in the hypothesis. The side condition about x not
being free in the conclusions comes from the requirement not to assume anything about x
(since we don‚Äôt know what it is). If x isn‚Äôt free in the conclusion, then it‚Äôs not free in Œì or
‚àÜ. If it were free in Œì or ‚àÜ, then we would be assuming that the x used there is the same
as the x we‚Äôre assuming exists, and this isn‚Äôt allowed.
In (‚àÉr), we are proving ‚àÉx.P(x). Thus we must pick a particular value (call it v) and prove
P for that value. The value v is allowed to contain variables that are free in Œì or ‚àÜ, since
you can set it to anything you want.
¬¨P
The rules for negation are:
Œì ‚ä¢‚àÜ, P
¬¨P, Œì ‚ä¢‚àÜ(¬¨l)
P, Œì ‚ä¢‚àÜ
Œì ‚ä¢‚àÜ, ¬¨P (¬¨r)
Let‚Äôs start with the right rule Ô¨Årst. I said that the way to prove ¬¨P is to assume P and
derive a contradiction. If ‚àÜis the empty set, then this is exactly what this rule says: If
there are no formulas to the right hand side of the ‚ä¢, then this means that the formulas in
Œì are inconsistent (that means, they cannot all be true at the same time). This means that
you have derived a contradiction. So if ‚àÜis the empty set, the hypothesis of the rule says
that, assuming P, you have obtained a contradiction. Thus, if you are absolutely certain
about all your other hypotheses, then you can be sure that P is not true. The best way to
understand the rule if ‚àÜis not empty is to write out the meaning of the sequents in terms
of the meaning of the sequent given by Equation 1 and work out the equivalence of the top
and bottom of the rule using the equivalences in your Logic and Proof notes.
The easiest way to understand (¬¨l) is again by using equivalences.
126

P ‚áíQ The two rules for implication are:
Œì ‚ä¢‚àÜ, P
Q, Œì ‚ä¢‚àÜ
P ‚áíQ, Œì ‚ä¢‚àÜ
(‚áíl)
P, Œì ‚ä¢‚àÜ, Q
Œì ‚ä¢‚àÜ, P ‚áíQ (‚áír)
The rule (‚áíl) easily understood using the intuitive explanation of how to use P ‚áíQ given
above. First, we have to prove P. This is the left hypothesis. Then we can use Q, which is
what the right hypothesis says.
The right rule (‚áír) is also easily understood. In order to prove P ‚áíQ, we assume P,
then use this to prove Q. This is exactly what the hypothesis says.
P ‚àßQ The rules for conjunction are:
P, Q, Œì ‚ä¢‚àÜ
P ‚àßQ, Œì ‚ä¢‚àÜ(‚àßl)
Œì ‚ä¢‚àÜ, P
Œì ‚ä¢‚àÜ, Q
Œì ‚ä¢‚àÜ, P ‚àßQ
(‚àßr)
Both of these rules are easily explained by the intuition above. The left rule (‚àßl) says that
when you use P ‚àßQ, you can use P and Q. The right rule says that to prove P ‚àßQ you must
prove P, and you must prove Q. You may wonder why we need separate hypotheses for
the two diÔ¨Äerent proofs. We can‚Äôt just put P, Q to the right of the ‚ä¢in a single hypothesis,
because that would mean that we‚Äôre proving one of the other of them (see the meaning of
the sequent given in Equation 1). So we need separate hypotheses to make sure that each
of P and Q has actually been proved.
P ‚à®Q The rules for disjunction are:
P, Œì ‚ä¢‚àÜ
Q, Œì ‚ä¢‚àÜ
P ‚à®Q, Œì ‚ä¢‚àÜ
(‚à®l)
Œì ‚ä¢‚àÜ, P, Q
Œì ‚ä¢‚àÜ, P ‚à®Q (‚à®r)
These are also easily understood by the intuitive explanations above. The left rule says that
to prove something (namely, one of the formulas in ‚àÜ) using P ‚à®Q, you need to prove it
using P, then prove it using Q. The right rule says that in order to prove P ‚à®Q, you can
prove one or the other. The hypothesis says that you can prove one or the other, because
in order to show a sequent Œì ‚ä¢‚àÜtrue, you only need to show that one of the formulas in
‚àÜis true.
127

