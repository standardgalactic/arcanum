 
 
  
Foundations for Ontology
John F. Sowa
VivoMind Research, LLC
5 October 2011

 
 
Foundations for Ontology
Foundations for Ontology
Outline:
 1. Problems and challenges
 2. Psycholinguistics and neuroscience
 3. Semantics of natural languages
 4. Wittgenstein’s early and later philosophy
 5. Lattice of theories
 6. Processing unrestricted natural language texts
 7. Meeting the challenges
Note:  This outline and the section summaries have a green background, and the detailed slides are in white. 

 
 
1. Problems and Challenges  
1. Problems and Challenges  
 Ontology is the study of existence.
 An ontology defines the things that exist in some domain.
Ontology is supposed to be important for artificial intelligence, 
natural language processing, and software design.
There have been some important applications, but many people 
have become disillusioned by the slowness of the developments.
NLP systems more often use informal resources such as 
WordNet, VerbNet, FrameNet, and Roget’s Thesaurus.
Questions:
● Have we been using the right tools, logics, and foundations?
● What other options have been proposed?
● Could any of these be more promising?

 
 
Prospects for a Universal Ontology
Attempts to create a universal classification of concepts:
● 4th century BC:  Aristotle’s categories and syllogisms.
● 17th century:  Universal language schemes by Descartes, Mersenne,   
   Pascal, Leibniz, Newton, Wilkins;  l’Académie française.
● 18th century:  More schemes;  Jonathan Swift’s satire of the Grand      
   Academy of Lagado;  Kant’s categories.
● 19th century:  Roget’s Thesaurus, Oxford English Dictionary.
● Early 20th century:  Many terminologies in many different fields.
● 1960s:  Computerized versions of the terminologies.
● 1970s:  ANSI/SPARC Conceptual Schema for databases.
● 1980s:  Cyc, WordNet, machine-readable dictionaries.
● 1990s:  Shared Reusable Knowledge Base (SRKB) project, ISO            
   Conceptual Schema project, Semantic Web, ontology workshops.
● 2000s:  Many proposals, no consensus. 

 
 
  
Early Days of Artificial Intelligence 
1960: Hao Wang’s theorem prover took 7 minutes to prove all 378
FOL theorems of Principia Mathematica on an IBM 704 –     
far faster than the two brilliant logicians, Whitehead and Russell. 
1960: Emile Delavenay, in a book on machine translation:
“While a great deal remains to be done, it can be stated without
hesitation that the essential has already been accomplished.” 
1965: Irving John Good, in speculations on the future of AI:
“It is more probable than not that, within the twentieth century,
an ultraintelligent machine will be built and that it will be the last
invention that man need make.” 
1968:  Marvin Minsky, the technical adviser for the movie 2001:
“The HAL 9000 is a conservative estimate of the level of artificial
intelligence in 2001.”

 
 
  
Why Has Progress Been So Slow?
Theorem provers in 1960 were much faster than humans.
Today’s computers are a million times bigger and faster.
If deduction were the critical bottleneck, the predictions by 
Delavenay, Good, and Minsky would have come true years ago.
What is the bottleneck?  Is it the amount of knowledge required?
Claims by Lenat and Feigenbaum (1987):
1. “Slowly hand-code a large, broad knowledge base.”
2. “When enough knowledge is present, it will be faster to acquire more        
    through reading, assimilating data bases, etc.”
3. “To go beyond the frontier of human knowledge, the system will have to   
     rely on learning by discovery, carrying out research and development      
     projects to expand its KB.”
Lenat began the Cyc project with Feigenbaum’s support in 1984.

 
 
Cyc Project
The largest system based on formal logic and ontology:
● Cyc project founded by Doug Lenat in 1984.
● Starting goal:  Implement the background knowledge of a typical    
  high-school graduate.
● Ultimate goal:  Learn new knowledge by reading textbooks.
After the first 25 years,
● 100 million dollars and 1000 person-years of work,
● 600,000 concepts,
● Defined by 5,000,000 axioms,
● Organized in 6,000 microtheories.
Some good applications, but more needs to be done:
● Cyc cannot yet learn by reading a textbook.
● Cyc cannot understand language as well as a child.

 
 
Views of Formal Semantics
Richard Montague (1970): 
“I reject the contention that an important theoretical difference exists 
between formal and natural languages.” 
Hans Kamp (2001): 
“The basic concepts of linguistics — and especially those of semantics —       
have to be thought through anew...  Many more distinctions have to be             
drawn than are dreamt of in current semantic theory.” 
Barbara Partee (2005): 
“The present formalizations of model-theoretic semantics are undoubtedly  
still rather primitive compared to what is needed to capture many important 
semantic properties of natural languages...  There are other approaches to 
semantics that are concerned with other aspects of natural language, 
perhaps even cognitively “deeper” in some sense, but which we presently 
lack the tools to adequately formalize.”
Kamp was a student of Montague’s who developed Discourse Representation 
Theory.  Both Kamp and Partee have promoted formal semantics for years.

 
 
Visualization in Mathematics
Paul Halmos, mathematician: 
“Mathematics — this may surprise or shock some — is never deductive in its 
creation.  The mathematician at work makes vague guesses, visualizes broad 
generalizations, and jumps to unwarranted conclusions.  He arranges and 
rearranges his ideas, and becomes convinced of their truth long before he 
can write down a logical proof...  the deductive stage, writing the results 
down, and writing its rigorous proof are relatively trivial once the real insight 
arrives;  it is more the draftsman’s work not the architect’s.” 
Albert Einstein, physicist: 
“The words or the language, as they are written or spoken, do not seem to 
play any role in my mechanism of thought.  The psychical entities which 
seem to serve as elements in thought are certain signs and more or less clear 
images which can be voluntarily reproduced and combined...  The above-
mentioned elements are, in my case, of visual and some of muscular type. 
Conventional words or other signs have to be sought for laboriously only in  
a secondary stage, when the mentioned associative play is sufficiently 
established and can be reproduced at will.”

 
 
The Ultimate Understanding Engine
Sentences uttered by a child named Laura before the age of 3. *
    Here’s a seat.  It must be mine if it’s a little one.
    I went to the aquarium and saw the fish.
    I want this doll because she’s big.
    When I was a little girl, I could go “geek geek” like that,
    but now I can go “This is a chair.” 
Laura used a larger subset of logic than Montague formalized.
No computer system today can understand and generate 
language at the level of a 3-year-old child.
* John Limber, The genesis of complex sentences. In T. Moore (Ed.), Cognitive 
development and the acquisition of language. New York: Academic Press, 1973.  
http://pubpages.unh.edu/~jel/JLimber/Genesis_complex_sentences.pdf 

 
 
Foundations for Language and Logic
For everyone from Laura to Einstein, perception, action, and 
mental models are more fundamental than language or logic.
Meanings expressed in language are based on perception.
Thinking and reasoning are based on mental models that use the 
same mechanisms as perception and action.
The symbols and syntax of mathematics and logic are abstractions 
from the symbols and patterns in natural languages.
Computer systems can manipulate those symbols much faster and 
more accurately than any human.
But computers are much less efficient in perception and action.
That limitation makes them unable to process language in the same 
way that people do.
Challenge:  How could computers support human-like methods?

 
 
Minsky’s Suggestion
Adapted from a diagram by Minsky, Singh, & Sloman (2004).

 
 
Meeting the Challenge
As Minsky’s diagram shows, AI methods could not process large 
numbers of causes and effects as efficiently as humans.
Statistical methods and neural networks could handle many 
causes (inputs), but not complex effects (outputs).
Logic could generate complex effects (multiple interrelated 
outputs), but they start with few causes (axioms).
Case-based reasoning and analogies could handle greater 
complexity, but their combination was intractable.
In his Society of Mind and Emotion Engine, Minsky proposed 
systems of heterogeneous interacting agents.
Multiple agents could support and combine multiple paradigms, 
but computational efficiency is the critical requirement. 

 
 
2. Psycholinguistics and Neuroscience  
2. Psycholinguistics and Neuroscience  
Language is a late development in evolutionary time.
Systems of perception and action were highly developed long 
before some early hominin began to talk.
People and other animals do a lot of reasoning with mental 
models that use the mechanisms of perception and action.
Language understanding and generation use those mechanisms.
The mechanisms of logic and mathematics are based on the  
same systems of perception and action as language.
Language can express logic, but it does not depend on logic.
Language is situated, embodied, distributed, and dynamic.

 
 
Classical Natural Language Processing
Assumptions about language that led to this approach:
● Frege’s principle of compositionality.
● Chomsky’s distinction between competence and performance.
● Tarski-Kripke-Montague’s model-theoretic semantics.
● A formal ontology that defines all word senses.
● A linear flow of information from phonology to semantics.
Those assumptions are unrealistic as a theory of the way 
people understand language.

 
 
Psycholinguistic Studies
Everything at every stage can and does interact with everything else.

 
 
Evolutionary View of Cognition
All human cognition except language is at the chimpanzee level.
Language is supported by and integrated with that level.
The huge increase in the size of the human cerebral cortex results 
from “the co-evolution of language and the brain” (Deacon 1997).

 
 
Language Areas in the Left Hemisphere
Two areas of the left hemisphere that are involved with language.
Lesions in Broca’s area disrupt syntax in speech generation.
Lesions in Wernicke’s area disrupt language understanding.

 
 
Motor Control Areas for Producing Speech
Broca’s area is next to the projection area for the motor neurons.
Wernicke’s area is closer to the sensory projection areas.

 
 
Association Areas in the Cortex
The shaded areas are the primary projection areas for sensory 
and motor neurons.  Association areas are in white.
The relative size of the association areas and the complexity of 
the interconnections are strongly correlated with intelligence.
Diagram adapted from Lamb (2011).

 
 
Arcuate Fasciculus
The arcuate fasciculus is a bundle of fibers that connect 
Broca’s area and Wernicke’s area in the human brain.
The corresponding connections in the chimpanzee and 
macaque brains are simpler and sparser.
Diagram adapted from Lamb (2011).

 
 
Cognitive Complexity
Each level inherits the abilities of all previous levels.
But larger association areas and more complex connections 
support more complex thought and methods of reasoning.

 
 
Areas Involved in Language Processing
Many areas of the brain are involved in language and reasoning:
● Nouns and adjectives are represented in the temporal lobe.
● Frames, maps, and semantic schemata are in the parietal lobe.
● Verb patterns are closer to the motor areas of the frontal lobe.
● Reasoning is controlled by the frontal lobes, but involves all other lobes.

 
 
Information Flow in Speech Generation
Speech is generated from information in multiple areas of the 
brain.  It is not translated from some “language of thought”.
Diagram adapted from MacNeilage (2008). 

 
 
Neurocognitive Network for the Word 'fork'
Network of locations in the LH, adapted from Lamb (2011):
● C:     Concept of a fork in the parietal lobe links to all other areas.
● V:      Visual recognition in the temporal lobe links to the visual cortex.
● T:      Tactile feel of a fork in the somatosensory cortex.
● M:     Motor schemata for manipulating a fork in the motor area.
● PR:   Phonology for recognizing the word 'fork' in Wernicke’s area.
● PA:   Phonology for the sound /fork/ in the primary auditory cortex.
● PP:   Phonology for producing the articulation of /fork/ in Broca’s area.

 
 
Localization and Distribution
Is knowledge in the brain localized or distributed?
● Memories can survive damage to large parts of the brain.
● Neurons can die without destroying a concept or association.
● But most areas of the brain are highly specialized.
Lamb’s hypothesis:
● Each node of a network is a column in the cortex that contains        
  an average of 75 to 80 neurons.
● If one neuron is lost, some associations may be lost, but the            
  other neurons in the column can recover most or all the function.
● Neighboring columns represent related concepts that can recover  
  many of the associations, even if an entire column  is lost.
● The complete information for a concept, including words and          
   images, is distributed in multiple nodes across both hemispheres.
● Even damage to a large area of the brain won’t destroy all the          
   information associated with the concept.

 
 
Situated Simulation
Neural and psychological research by Lawrence Barsalou:
● Mental simulation is the re-enactment of perceptual, motor and                   
  introspective states acquired during experience.
● Unconscious re-enactments occur during memory and reasoning.
● Conscious re-enactments are usually called mental imagery.
Cognition is grounded in perception, action, and internal states.
● Simulations can re-enact the social interactions in situations.
● Situated conceptualizations can also stimulate the emotional states.
Mirror neurons promote learning and social understanding:
● The neurons used in performing an action are also activated in seeing       
  another person perform the same action.
● Simulations in motor and emotional systems are critical to empathy,          
  social understanding, and successful cooperation.
See http://www.psychology.emory.edu/cognition/barsalou/onlinepapers.html 

 
 
Relating Psycholinguistics to Neuroscience
Neurocognitive networks are not a “Language of Thought”:
● They link nodes in the sensory, motor, and association areas.
● Some nodes are associated with images, sounds, feelings, and actions.
● Other nodes and patterns of nodes, which may be called concepts and         
  schemata, have indirect links to the sensory and motor nodes.
● Some of those nodes and patterns are associated with words.
● But they don’t form a language-like representation.    
Reasoning is a process of forming new patterns:
● The basic mechanisms form, strengthen, weaken, and inhibit links.
● The frontal lobes are actively involved in the process.
● But the new links or modified links may be anywhere in the cortex.
● The resulting patterns may be mapped to actions (including speech). 
Syntax, semantics, and pragmatics are theoretical abstractions:
● They can be useful for analyzing and interpreting neural patterns.
● But neural connections combine continuity with a binary threshold. 

 
 
“A Moving Picture of Thought”
A brilliant discovery by Charles Sanders Peirce:
● In 1885, Peirce published the algebraic notation for predicate calculus.
● In 1897, he invented existential graphs (EGs) as an equivalent notation.
● EG logic has no variables, no substitutions, and no transformations.
● Peirce claimed that EG rules generate “a moving picture of thought.” 
● The psychologist Philip Johnson-Laird (2002) agreed:  EGs with Peirce’s  
   rules of inference are a good candidate for a realistic neural theory.
EG extensions to the networks proposed by Sydney Lamb:
● A mechanism for treating any graph or subgraph as a single chunk.
● Inhibitory links for negating any chunk.
● Graphs with negated chunks can represent full first-order logic.
Neural mechanisms for supporting Peirce’s rules of inference:
● Analogies for matching graphs and subgraphs.
● Some mechanism for inserting, erasing, or inhibiting links and chunks.

 
 
Existential Graphs Without Negation
A simple version of logic that can represent the content of many 
graphical notations, including RDF, Concept Maps, and Topic Maps.
This example by Peirce can be translated to the following formula:
     ∃x∃y∃z (isaStagirite(x)  
∧teaches(x,y)  
∧isaMacedonian(y) ∧
            conquersTheWorld(y)  
∧isaDiscipleOf(x,z)  
∧isanOpponentOf(x,z) 
                        
∧isaPhilosopherAdmiredByChurchFathers(z)) 
To represent negation, networks such as Lamb’s could use the neural 
mechanism of inhibition to deny any graph or subgraph.
See Peirce’s tutorial on EGs:  http://www.jfsowa.com/pubs/egtut.pdf 

 
 
EGs With Negation Support Full FOL
 

 
 
A Cognitive Theory of Reasoning
Based on the same kind of pattern matching as perception:
● Associative access by matching percepts, concepts, and patterns.
● Approximate matches for analogies and metaphors in RH.
● Precise, detailed pattern matches in LH.
Analogies support informal case-based reasoning:
● Long-term memory can store large numbers of previous experiences.
● Any new case can be matched to similar cases in LTM.
● Close matches suggest likely outcomes or features of the new case. 
Methods of logic are disciplined applications of analogy:
● Induction:  Generalize multiple cases to create rules or axioms.
● Deduction:  Match (unify) a new case with part of some rule or axiom.
● Abduction:  Form a hypothesis based on aspects of similar cases.
Continuity in the strength of neural connections is important for 
perception, but the binary threshold is important for action.

 
 
3. Semantics of Natural Languages
3. Semantics of Natural Languages
Language about things, events, and situations is based on the 
way that people think about them.
And thinking is intimately integrated with perception and action.
The semantics and pragmatics of language are
● Situated in time and space,
● Distributed throughout the cerebral cortex of every speaker,
● Dynamically generated and interpreted in terms of a constantly                   
  developing and changing context,
● Embodied and supported by the sensory and motor organs.
These points summarize current thinking by psycholinguists.
But philosophers and logicians cluster around other views:
● NLs as formal logic; a sharp dichotomy between NLs and logics;                
  a continuum between NLs and logics; an open-ended multiplicity.

 
 
Four Views by Logicians
Four Views by Logicians
1. Montague declared that NL semantics is formal:
“I reject the contention that an important theoretical difference exists between 
formal and natural languages.” 
2. Frege, Russell, and Carnap believed in a sharp dichotomy:
“a task of philosophy [is] to break the power of words over the human mind, by 
uncovering illusions that through the use of language often almost unavoidably 
arise concerning the relations of concepts, by freeing thought from the taint of 
ordinary linguistic means of expression.”  Gottlob Frege
3. Peirce and Whitehead emphasized the continuity:
“Symbols grow.  They come into being by development out of other signs,   
particularly from icons, or from mixed signs partaking of the nature of icons        
and symbols.”  Charles Sanders Peirce
“The simple-minded use of the notions 'right or wrong' is one of the chief 
obstacles to the progress of understanding.”  Alfred North Whitehead
4. Wittgenstein moved from view #1 to an open-ended multiplicity:
“And this multiplicity is not something fixed, given once for all; but new types of 
language, new language-games, as we may say, come into existence, and others 
become obsolete and get forgotten.”

 
 
Relating Language to Perception
Claude Vandeloise drew diagrams to explain spatial terms:
L’espace en français: Sémantique des prepositions spatiales, Editions du Seuil, 1986.
His book was translated to English, but there is no one-to-one 
mapping of English and French prepositions.
Dictionaries list the common ways that prepositions are used, 
and the number of possible ways is open ended.

 
 
Issues about Orientation
For a tree, any side could be could be considered the front.
But a cannon has distinct front, back, and sides.

 
 
Issues about Motion
For stationary objects, such as trees, the speaker’s viewpoint 
determines the choice of preposition.
For moving objects, their relative position is more significant.
But objects like snails and turtles, which move very slowly, are 
treated like stationary objects (unless their motion is relevant).

 
 
Issues about Function
The French preposition dans or the English in normally links 
something to a container.
The primary function of a bowl is to serve as a container.
That function is more relevant than the question whether the 
bowl actually encloses the pear.

 
 
Issues about Background Knowledge
A cage is sometimes used to enclose a bird.
But a cage is an unlikely container for a knife.
Normal comment:  “The knife is to the right of the cage.”
To say “The knife is outside the cage” implies that there is some 
reason why it might have been in the cage.

 
 
What is a Chair?
The egg-yolk theory puts typical examples in the yolk and 
unusual examples in the egg white (Lehmann & Cohn 1994).

 
 
What is a Number?
Concepts in science and mathematics grow and change.

 
 
Microsenses
The linguist Allen Cruse coined the term microsense for a 
specialized sense of a word in a particular application.
Examples of microsenses:
● Spatial terms in different situations and points of view.
● The many kinds of chairs or numbers in the egg whites.
● The kinds of balls in various ball games:  baseball, basket ball,        
   billiard ball, bowling ball, football, golf ball, softball, tennis ball.
● Computer science requires precise definitions, but the meanings    
  of words change whenever programs are revised or extended.
● Consider the term file system in Unix, Apple OS X, Microsoft              
   Windows, and IBM mainframes.
Microsenses develop through usage in different situations.
The number and kinds of new uses and innovations grow 
independently of any attempt to limit the meanings of words.

 
 
Using Background Knowledge
People resolve ambiguities and choose the correct microsenses 
by retrieving background knowledge about the options.
Choosing the microsense:  My dog bit the visitor’s ear.
● From knowledge about the size of dogs, one would assume it was more   
  likely to be a doberman than a dachshund.
● But if one knew the visitor was in the habit of bending over to pet a dog,   
  it might even be a chihuahua.
Resolving an ambiguous parse:  The chicken is ready to eat.
● From knowledge about typical food, one would assume the chicken had   
  been cooked and prepared as a meal.
● If the word chicken were replaced with dog, one might assume the dog      
  was begging for food.
● But people in different cultures may make different assumptions. 
The many microsenses and the dependence on background 
knowledge require highly flexible methods of reasoning.

 
 
Language and Logic  
By the age of three, children speak and understand language     
far better than any computer system today.
But it takes longer for them to learn more abstract methods. 
The mechanisms of perception, action, mental models, and 
analogy are sufficient for language learning.
But older children and adolescents can learn abstract methods, 
such as mathematics and complex verbal reasoning.
Abstract reasoning seems to require language or language-like 
symbols.  It is not the foundation for language.
As Halmos and Einstein noted, even expert mathematicians rely 
on prelinguistic methods as aids to intuition and invention. 
Peirce, Whitehead, and Wittgenstein understood the relations 
between language and logic more clearly than Frege or Russell.

 
 
Mental Maps, Images, and Models 
Quotation by the neuroscientist Antonio Damasio (2010):
“The distinctive feature of brains such as the one we own is their 
uncanny ability to create maps...  But when brains make maps, they  
are also creating images, the main currency of our minds.  Ultimately 
consciousness allows us to experience maps as images, to  
manipulate those images, and to apply reasoning to them.”
The maps and images form mental models of the real world or  
of the imaginary worlds in our hopes, fears, plans, and desires.
Those models create a kind of “model theoretic” semantics that 
determines truth and falsity for natural language statements.
But the models created by neural mechanisms are much more 
flexible, dynamic, and image-like than Tarski’s or Montague’s.
How can we design AI systems that implement that kind of 
flexibility in digital computers? 
  

 
 
4. Ludwig Wittgenstein
Considered one of the greatest philosophers of the 20th century.
Wrote his first book under the influence of Frege and Russell.
That book had an enormous influence on analytic philosophy, 
formal ontology, and formal semantics of natural languages.
But Wittgenstein retired from philosophy to teach elementary 
school in an Austrian mountain village.
In 1929, Russell and others persuaded him to return to 
Cambridge University, where he taught philosophy.
During the 1930s, he began to rethink and criticize the   
foundations of his earlier book, including many ideas he had 
adopted from Frege and Russell.

 
 
Wittgenstein’s First Book
From the Tractatus Logico-Philosophicus,
    
    1  The world is everything that is the case.
    1.1  The world is the totality of facts, not of things.
    3.25  There is one and only one complete analysis of the proposition.
    4.001  The totality of propositions is the language.
    4.116  Everything that can be said can be said clearly.
    5  Propositions are truth-functions of elementary propositions.
    6.13  Logic is not a theory but a reflexion of the world.
    7  Whereof one cannot speak, thereof one must be silent.
This book set the agenda for formal semantics in the 20th century.
If it were adequate for language understanding and reasoning,    
then the HAL 9000 would be ruling the world today.

 
 
Model-Theoretic Semantics
In the Tractatus, Wittgenstein assumed that the world was the model.
Since there is exactly one world, there is exactly one model, there is 
exactly one ontology, and no approximation is conceivable.
George Box, a professor of engineering, was cynical, but realistic:
“All models are wrong.  Some are useful.”

 
 
What Kind of Language is Meaningless?
According to the Tractatus, only factual statements about the world 
and Boolean combinations of them are meaningful.
    6.421  It is clear that ethics cannot be expressed.  Ethics is transcendental.  (Ethics   
        and aesthetics are one.)
    6.52  We feel that even if all possible scientific questions be answered, the problems
        of life have still not been touched at all.   Of course there is then no question left,  
        and just this is the answer.
    6.54  My propositions are elucidatory in this way:  he who understands me finally
        recognizes them as senseless, when he has climbed out through them, on them,
        over them.
Since the Tractatus consists of language about language, it does not 
state facts about the world.  Therefore, it too is meaningless.

 
 
Wittgenstein’s Transitional Period
In 1929-30, he analyzed some “minor” inconsistencies in the Tractatus.
That analysis led to two important innovations:
● Satzsystem:  System of sentences or propositions. 
● Beweißsystem:  Proof system that defines a logic for a Satzsystem.
This approach distinguishes the model from the world:
    “The Satzsystem is like a ruler laid against reality.  An entire system     
    of propositions is now compared to reality, not a single proposition.”
For a given logic, each consistent Satzsystem expressed in that logic is 
a theory that defines an ontology.
The model is no longer identical to the world, and different Satzsysteme 
could be better or worse approximations for different purposes.

 
 
Uses and Limitations of Satzsysteme
 
In his transitional period, Wittgenstein was still addressing the 
issues about scientific language.
He allowed multiple logics and ontologies, and he relaxed the truth 
criteria to map entire systems to the world, not just single sentences.
But he did not explicitly accommodate ethics, aesthetics, and 
metalevel statements that talked about language itself.
The option of distinguishing the model from the world makes it 
possible to introduce new features into the model that do not have   
a direct mapping to anything in the world.
For example, the model might contain abstractions, values, and the 
words or phrases of a language, independent of any mapping to any 
observable entities in the world.
Such a generalization would enable language to talk about a broader 
range of subjects, but it would still be a formal language, not a truly 
natural language. 

 
 
Wittgenstein’s Language Games
In the mid 1930s and for the rest of his life, Wittgenstein focused on 
his theory of language games as a more general and flexible approach 
than the Satzsysteme and Beweißsysteme of 1929-30.
In his book Philosophical Investigations, he presented them as a 
correction to the “grave errors” (schwere Irrtümer) of his first book.
Every use of language is intimately integrated with social activity.
The meaning of language is grounded in purposeful activity.
As he said in his notebooks (Zettel), language is an “extension of 
primitive behavior.  (For our language game is behavior.)”
As an example, he said that a word is like a piece in the game of 
chess.  Its meaning is based on the way the word is used in a game.

 
 
Games of Go and Go-moku
Two games with the same syntax, but different goals:
Syntax defines legal moves, but not meaningful moves.
The meaning of any move is determined by its purpose.
In go, the goal is to place stones that surround territory.
In go-moku, the goal is to place five stones in a row.
Different goals lead to very different patterns of stones.

 
 
Wittgenstein’s Examples  
“And this multiplicity is not something fixed, given once for all; but new 
types of language, new language-games, as we may say, come into 
existence, and others become obsolete and get forgotten...
Giving orders, and obeying them – 
Describing the appearance of an object, or giving its measurements –  
Constructing an object from a description (a drawing) –  
Reporting an event –  
Speculating about an event –  
Forming and testing a hypothesis –  
Presenting the results of an experiment in tables and diagrams –  
Making up a story; and reading it –  
Play-acting – 
Singing catches – 
Guessing riddles – 
Making a joke; telling it – 
Solving a problem in practical arithmetic – 
Translating from one language into another – 
Asking, thanking, cursing, greeting, praying.”

 
 
Formal Definition of Language Game?
Probably impossible.
Wittgenstein crossed many different academic boundaries:
     syntax, semantics, pragmatics, logic, ontology, speech acts,              
     scenarios, sublanguage, and genre.
He emphasized the connection between a language game and
social activity:
     “speaking a language is part of an activity, or of a form of life.”
But he also compared language games to the different ways of using 
terms such as “number” in mathematics:
     “We can get a rough picture of this [the variety of language games]  
     from the changes in mathematics.”

 
 
Implementing Language Games
Wittgenstein’s language games have stimulated a lot of debate.
Many logicians considered them “a step in the wrong direction”    
away from the clarity and logical precision of his first book.
Some computational linguists have found his writings inspirational, 
but they found it hard to implement that inspiration.
In fact, Wittgenstein himself would probably object to any attempt to 
formalize the language games.
The Satzsysteme of his transitional period are easier to formalize,   
and they can be considered special cases of language games.
The question is how to implement them in practical systems.

 
 
A Neo-Wittgenstenian Model of Language
Developed by Margaret Masterman —
One of six students in Wittgenstein’s course of 1933-34 whose 
notes were compiled as The Blue Book.
Cofounded the Cambridge Language Research Unit (CLRU) with 
the linguist Michael Halliday.
Emphasized semantics, not syntax: 
“I want to pick up the relevant basic-situation-referring
     habits of a language in preference to its grammar.”
Invented a context-dependent method of analysis:
1. Thesaurus with words grouped by areas of use.
2. Word “fans” radiating from each word type to each area of the        
    thesaurus in which it occurs.
3. Dynamically generated combinations of fans for word tokens. 

 
 
A Word Fan for “Bank”
Numbers and labels represent areas in Roget’s Thesaurus.

 
 
Method of Disambiguation
Example:  “up the steep bank” and “in the savings bank”.
All the words except “the” have similar fans.
Masterman’s method for selecting an appropriate word sense:
● Combinations of fans “pare down” the ambiguities “by retaining      
  only the spokes that retain ideas which occur in each.”
● For this example,
          — OBLIQUITY 220 is common to 'STEEP' and 'BANK'.
          — STORE 632 and TREASURY 799 are common
                to 'SAVINGS' and 'BANK'.
 

 
 
Precision and Ambiguity 
Charles Sanders Peirce:
    “It is easy to speak with precision upon a general theme.  Only, one      
    must commonly surrender all ambition to be certain.   It is equally        
    easy to be certain.   One has only to be sufficiently vague.   It is not      
    so difficult to be pretty precise and fairly certain at once about a very   
    narrow subject.”
Many linguists:
    Lexical ambiguity can be avoided within a semantically restricted         
    sublanguage, such as weather reports or airplane reservations.
Ludwig Wittgenstein:
    Outside a Satzsystem, a word is like “a wheel turning idly.”
Words acquire a precise, unambiguous meaning only in a narrow 
domain, such as a Satzsystem, sublanguage, or language game.

 
 
Observations about Language
From psycholinguistics, neuroscience, and Wittgenstein:
● Language develops, both in the species and in the individual,    
  as an accompaniment to social activity.
● Pragmatics is the primary purpose of language and the first       
  aspect to emerge in the genus Homo and in every infant.
● Semantics develops as a mapping of words and sentences to    
  the mental models used in perception and purposeful action.
● Different aspects of meaning are emphasized in language           
  games for different purposes in different kinds of activities.
● Formal logics are abstractions from certain language games.
What can these observations tell us about AI and NLP? 
Can they be formalized in computable methods?
Would those methods support the power and flexibility of 
human language and reasoning?

 
 
5. Lattice of Theories  
For any given logic L, the set of all possible theories expressible 
in L forms an infinite lattice.
Theories are ordered by generalization and specialization.
Only a finite subset of the lattice, which may be called a hierarchy 
of theories, can ever be implemented.
But the lattice provides a framework with guidelines for relating, 
organizing, and generating the theories in the hierarchy.
Theories in the lattice can be of any size.
They can include the microtheories of Cyc or large theories that 
are formed by combining any number of smaller theories.
Classical Tarski-style semantics is a special case that can support 
controlled natural language for narrow domains.
 

 
 
Lattice Operations   
For any version of logic L, theory X is more general than theory Y    
and Y is more specialized than X, if and only if
● X is true of everything (or every model) for which Y is true.
Generalization defines a Lindenbaum Lattice of theories:
● If theory X is more general than Y, write X≥Y or Y≤X.
● For any X and Y, there is a unique minimal common generalization, written     
  X⋃Y, such that  X⋃Y≥X  and  X⋃Y≥Y.
● For any X and Y, there is a unique maximal common specialization, written     
  X⋂Y, such that  X⋂Y≤X  and  X⋂Y≤Y.
● The most general theory at top of the lattice, written ⊤, is true of everything.
● The most specialized theory at the bottom, written ⊥, is true of nothing. 
The lattice of theories provides a framework for organizing and 
relating every ontology that can be expressed in the logic L.
The lattice formalizes microtheories in Cyc and other ontologies.
 

 
 
Formalizing Wittgenstein’s Satzsysteme
For a given logic, each Satzsystem may be represented by a formal 
theory that defines the ontology of a narrow subject.
All the theories (Satzsysteme) for a given logic form a lattice.
The universal theory at the top contains nothing but tautologies, which
are true in all the theories.
In Peirce’s terms, general theories near the top are “sufficiently vague” 
to characterize a wide range of subjects.
Specialized theories at lower levels are sufficiently “narrow” to be
“pretty precise and fairly certain” for more specialized subjects.
But to provide a semantics for language, those theories must be 
mapped to words, sentences, and extended discourse.

 
 
Supporting Language Games
Satzsysteme and language games can both be supported by the 
same three mechanisms:
  1. Lattice of theories.
  2. Word fans that map lexical items to the type hierarchy.
  3. Canonical graphs that match patterns of words to determine which theory     
      in the lattice is appropriate.
The difference between the Satzsysteme and the language games 
is in the amount of flexibility and variability they support:
● A Satzsystem corresponds to a controlled natural language that restricts        
  the syntax, semantics, and vocabulary to one precisely-defined sublanguage.
● Language games include the Satzsysteme as special cases, but they support 
  much more flexibility, including the option of mixing language games even      
  in the same sentence.
● A wider range of operations are needed to support that flexibility.

 
 
Canonical Graphs
A canonical graph is a conceptual graph that represents a 
pattern or schema that is typical for a given concept type.
Canonical graphs for the concept types Give, Easy, and Eager.
They encode the expected patterns of concepts and relations and 
select an appropriate theory or Satzsystem for each type.
But canonical graphs for special cases can be more complex:    
easy to please person, easy to read book, or easy to drive car.
The canonical graphs for verbs specify the case relations or thematic roles and the constraints 
on concept types.   See the IBM-CSLI verb ontology, http://www-csli.stanford.edu/~arunm/ 

 
 
Mapping Word Fans to a Lattice of Theories
words → types → canonical graphs → theories 

 
 
Navigating the Lattice of Theories  
Methods of belief revision for relating one theory to another.
Four operators:  contraction, expansion, revision, and relabeling.
Every method of learning or nonmontonic reasoning determines  
a strategy for finding a path through the lattice.

 
 
Learning
Children learn language by starting with words and patterns of 
words that are closely tied to perception and action.
To simplify and optimize the connections, they learn to form  
generalizations and to group words into general categories.
They use analogies and metaphors to extend the generalizations 
to other categories that can be organized in similar patterns.
By methods of trial and error, children and adults extend and test 
the generalizations as far as they can go.
But Peirce’s warning applies to all such generalizations:
“It is easy to speak with precision upon a general theme.  Only, one  must 
commonly surrender all ambition to be certain.   It is equally easy to be 
certain.  One has only to be sufficiently vague.   It is not so difficult to be 
pretty precise and fairly certain at once about a very narrow subject.” 

 
 
Learning a New Theory
Observational data can be stated as a theory with ground-level 
facts, each of which is independent of the others:
     Tweety is a bird.    Tweety flies.
     Daffy is a bird.     Daffy flies.
     Hooty is a bird.     Hooty flies.
Generalizations can reduce the number of axioms:
     Every bird flies.
     Every flying thing is a bird.
     For every x, x is a bird if and only if x flies.
Any one of these three generalizations can be added to some 
subset of the facts in order to generate the other facts.
Heuristics give a slight preference for “Every bird flies.”
But the other options cannot be ruled out. 

 
 
New Information Triggers Belief Revision
New observation:
   Vampy is not a bird. Vampy flies.
This observation rules out two options, leaving just one:
   Every bird flies.
Another observation:
   Tux is a penguin. Tux is a bird. Tux does not fly.
This observation restricts the universal quantifier:
   Every bird that is not a penguin flies.
Learning and belief revision can be interpreted as walks 
through the lattice to find a more appropriate theory.

 
 
Proofs in Nonmonotonic Logic
A proof by any method of nonmonotonic logic can be interpreted 
as a walk through a lattice of purely classical FOL theories.
Ray Reiter’s default logic is a popular example:
● Each default theory has two sets of axioms: classical and default.
● Any proof is a sequence of steps:  S0, S1, …, Sn.
● Some steps are classical, and some use a default axiom.
● The collection of classical axioms defines some theory C in the lattice.
● Each default step Si makes some assumption Ai in classical FOL.
● Adding Ai to the current classical axioms is a revision by expansion.
● When the proof ends at step Sn, the classical theory C has been                 
  expanded to a more specialized classical theory C′.
● In theory C′, exactly the same conclusion can be derived by the usual        
  FOL rules of inference.
By a similar method, any proof by negation as failure or other
nonmonotonic rules can be mapped to a walk through a lattice. 

 
 
A Dynamic Model Theory
For any first-order logic L, there are two lattices    and    :  
●     is a Lindenbaum lattice of all theories expressible in L.
● Each theory t in   , except the bottom ⊥, has one or more models.
● Each model m for a theory t can be represented by a set of facts      
  (ground-level atoms) expressed in the logic L.
● The set     of all models for all theories forms a sublattice of    .
The two lattices can support reasoning about mental models 
and the dynamic ways they behave, interact, and evolve:
● Each model m in     can state facts about some mental model.
● Each theory t in    can state constraints or laws that are considered      
  necessarily true of every model in a sublattice M of    .  (Sowa 2006)
● For a fixed theory t, a story or a language game that obeys the laws     
  of t determines a walk through the models in the sublattice M.
● Debate among multiple participants may lead to nonmonotonic walks  
  through the lattice    that can cause irregular jumps through     .

 
 
Relating Theories to Mental Models
Mental models are more complex than abstract theories: 
● They are intimately connected to perception, action, and feelings.
● Language that expresses them reflects all those nuances.
● Wittgenstein tried to capture “a form of life” with all its complexity.
But the lattices are a better approximation than Tarski’s models:
● Instead of a fixed theory and model, the lattices support dynamic and        
  systematic walks to find new theories and models as required. 
● Dynamic changes in mental models  ⇒  walks among models in     .
● Learning and nonmonotonic reasoning  ⇒  walks among theories in    .
● Familiar computational methods can be used to determine the walks.   
Only finite subsets of the lattices can ever be implemented, but 
the framework allows new theories and models to be computed:
● Conflicts, contrasts, and disagreements among multiple points of view     
  (theories) can be detected, debated, resolved, or abandoned.

 
 
Peirce’s Cycle of Pragmatism
This diagram, based on Peirce’s writings about reasoning, relates 
perception and action to methods for creating and modifying theories.
Every step of every cycle corresponds to a walk through the lattices.

 
 
Computational Issues
Perfect understanding of natural language is an elusive goal: 
● Even native speakers don’t understand every text in their language.
● Without human bodies and feelings, computational models will            
  always be imperfect approximations to human thought.
For technical subjects, computer models can be quite good:
● Subjects that are already formalized, such as mathematics and             
  computer programs, are good for computers.
● Physics is harder, because the applications require visualization.
● Poetry and jokes are the hardest to understand.
The critical requirement is to develop theories for the lattice:
● The Cyc project shows that hand coding is slow and expensive.
● For many projects, fully formalized theories aren’t required.
● Automated and semi-automated methods of knowledge acquisition      
  can generate sufficiently accurate information for many purposes.

 
 
6. Processing Unrestricted NLs
Natural languages are the normal means for people to express 
their meaning, but they are not the most computable.
Full natural language understanding involves unsolved research 
problems, but there are many useful ways of processing NLs 
short of total understanding.
Finding relevant background knowledge is critical to resolving 
ambiguities and determining the correct interpretation.
A high-speed analogy engine is necessary to make such 
methods efficient and practical.
Analogies can support informal case-based reasoning and more 
formal methods of deduction, induction, and abduction.

 
 
Four Views of Analogy
1.  By logicians: 
      Deduction is reasoning from “first principles.”
2.  By psychologists: 
       Analogy is fundamental to human and animal cognition. 
       All aspects of language understanding depend on analogy. 
3.  Theoretical: 
       All methods of formal logic — deduction, induction, and abduction 
       — are disciplined special cases of analogy. 
4.  Computational: 
      A powerful and flexible technique with important applications in       
      reasoning, learning, and language processing.
      But practicality depends on finding analogies efficiently. 

 
 
Computational Complexity
Research by Falkenhainer, Forbus, & Gentner:
     Pioneers in finding analogies with their Structure Mapping Engine.
     Showed that SME algorithms take time proportional to N³, where       
     N is the number of graphs (or frames) in the knowledge base.
     MAC/FAC approach:  Use a search engine to narrow down the           
     number of likely candidates before using SME.
VivoMind approach:
    Encode graph structure and ontology in a Cognitive Signature™.
    Find the closest matching signatures in logarithmic time.
    Use structure mapping only on a very small number of graphs.
For papers by Falkenhainer, Forbus, Genter, and their colleagues, see                                                 
      http://www.qrg.northwestern.edu/papers/papers.html 
For references to VivoMind technology, see the last slide in this presentation.

 
 
Algorithms for Chemical Graphs
Graphs of organic molecules are similar to conceptual graphs:
    ● Atoms 
 concept nodes labeled by the name of the element.
⇒
    ● Chemical bonds 
 relation nodes labeled by the name of the bond type.
⇒
    ● But conceptual graphs have many more types of concepts and relations. 
Chemical graphs inspired Peirce’s existential graphs as 
representations of “the atoms and molecules of logic.”
Some of the largest and most sophisticated systems for graph 
processing were developed by chemists, not computer scientists.
An important application was the use of chemical graph algorithms 
for building and searching hierarchies of conceptual graphs:
      Robert A. Levinson, & Gerard Ellis (1992) Multilevel hierarchical retrieval,     
      Knowledge Based Systems 5:3, pp. 233-244.

 
 
Chemical Graph Search Engine
Find similar chemical graphs in logarithmic time:
    • Represent each graph by its unique International Chemical Identifier (InChI).
    • Map the InChI codes to numeric vectors that encode both the graph structure   
      and the labels of the atoms and bonds.
    • Estimate the semantic distance between graphs by a measure based on both   
      the graph structure and the labels on the nodes and arcs (atoms and bonds).
    • Index the vectors by a locality-sensitive hashing (LSH) algorithm.
    • Use the semantic distance measure to find the most similar graphs. 
Similar techniques can be adapted to conceptual graphs.
For details of the chemical algorithms, see
    Mining Patents Using Molecular Similarity Search, by James Rhodes,                   
    Stephen Boyer, Jeffrey Kreulen, Ying Chen, & Patricia Ordonez,
    http://psb.stanford.edu/psb-online/proceedings/psb07/rhodes.pdf 

 
 
Cognitive Memory™ 
Basis for the VivoMind Analogy Engine (VAE)

 
 
Applications of VivoMind Software
General approach:
● Apply VAE, VLP, and related tools to any data a customer has.
● Relate the customer’s ontology (if any) to VivoMind resources.
● Supplement the ontology with semi-automated methods for             
  deriving further information from NL documents.
● Analyze and relate any combination of unstructured NL                     
  documents and structured information of any kind.
● Translate the results to any format the customer prefers.
Three applications:
1. Evaluate student answers in free-form English sentences.
2. Legacy re-engineering:  Analyze computer programs and relate     
    them to the English documentation.
3. Extract information from textbooks and research reports about      
    oil and gas fields and answer English questions by a geologist.

 
 
1. Evaluating Student Answers
Multiple-choice questions are easy to evaluate by computer.
Long essays are often evaluated by statistical methods.
But short answers about mathematics are very hard to evaluate. 
Sample question:
         The following numbers are 1 more than a square:  10, 37, 65, 82.
         If you are given an integer N that is less than 200,
         how would you determine whether N is 1 more than a square?
         Explain your method in three or four sentences. 
How could a computer system evaluate such answers?
Determine whether they are correct, incorrect, or partially correct?
And make helpful suggestions about the incorrect answers? 

 
 
Many Possible Answers
An example of a correct answer:
        To show that N is 1 more than a square,  show that N−1 is a square.
        Find some integer x whose square is slightly less than N−1.         
        Compare N−1 to the squares of  x,  x+1,  x+2,  x+3,   ...,
        and stop when some square is equal to or greater than N−1.
        If the last square is N−1,  then N is one more than a square. 
Even experienced teachers must spend a lot of time checking 
and correcting such answers.
How can a computer system evaluate them?
How can it make helpful suggestions for incorrect answers?

 
 
Publisher’s Current Procedure
To evaluate new exam questions, the publisher normally
gives the exam to a large number of students.
For each problem, they would get about 50 different answers:
    ● Some are completely correct
         — but stated in different ways.
    ● Some are partially correct
         — and the teacher says what is missing.
    ● Others are wrong
         — in many different ways. 
Result:  50 pairs of student answer and teacher’s response.
Each answer-response pair is a case for case-based reasoning.

 
 
Case-Based Reasoning 
Given the same cases, analogy takes one step to derive an answer 
that can take many steps by induction and deduction.
Analogy is usually more flexible, but a theory would be valuable if 
the same theory can be used and reused in multiple applications.   

 
 
Using VLP and VAE 
VLP translates all answers to conceptual graphs (CGs):
   1. VLP uses a link grammar and a collection of lexical resources.
   2. Canonical graphs for verbs are based on the IBM-CSLI verb ontology.
   3. For this application, a small ontology of arithmetic was added.
   4. The next slide shows a canonical graph for Multiply.
VAE compares each new answer to the 50 cases:
   1. CGs for the answers of all 50 cases are stored in Cognitive Memory.
   2. Compare the CG for each new answer to the CGs in Cognitive Memory.
   3. If there is a good match, print out the teacher’s previous response.
   4. Otherwise, send the new student answer to some teacher to evaluate.
   5. Add the new answer-response pair to the collection of cases.
This method combines a formal ontology for arithmetic 
with a very informal method of case-based reasoning.

 
 
Canonical Graph for Multiply
The boxes and circles represent an English sentence pattern:
       [Someone] multiplies a number by a number to get a product.
The diamond node, called an actor, represents a function that  
computes the result of multiplying values inside the concept boxes.

 
 
Results 
VAE found a good match for nearly all student answers.
For good matches, the stored response was appropriate.
Student answers are often incomplete or ungrammatical.
● But the canonical graphs make the parsing more robust.
● Resolve ambiguities by showing expected combinations.
● Use semantics to compensate and correct errors in syntax.
● Provide defaults for missing arguments.
● Show how information from multiple fragments can be related.
The CGs derived from student answers were incomplete 
and unreliable for precise reasoning and calculation.
But they were adequate for approximate matching by VAE.

 
 
2. Problem for Legacy Re-engineering
Analyze the software and documentation of a large corporation.
Programs in daily use, some of which were up to 40 years old.
    ● 1.5 million lines of COBOL programs.
    ● 100 megabytes of English documentation — reports, manuals,
       e-mails, Lotus Notes, HTML, and program comments. 
Goal:
    ● Analyze the COBOL programs.
          
    ● Analyze the English documentation.
    ● Compare the two to generate: 
          English glossary of all terms with index to the software,
          Structure diagrams of the programs, files, and data,
          List of discrepancies between the programs and documentation.

 
 
An Important Simplification
An extremely difficult and still unsolved problem:
    ● Translate English specifications to executable programs.
Much easier task:
    ● Translate the COBOL programs to conceptual graphs.
    ● Use the conceptual graphs from COBOL to interpret the English.
    ● Use VAE to compare the graphs derived from COBOL to the          
       graphs derived from English.
    ● Record the similarities and discrepancies.
The graphs derived from COBOL define the semantics.
They provide a formal semantics for the informal English.
But the semantics of one COBOL program might be 
inconsistent with the semantics of other programs.

 
 
Excerpt from the Documentation
The input file that is used to create this piece of the Billing 
Interface for the General Ledger is an extract from the 61 byte file 
that is created by the COBOL program BILLCRUA in the Billing 
History production run.  This file is used instead of the history file 
for time efficiency.  This file contains the billing transaction codes 
(types of records) that are to be interfaced to General Ledger for 
the given month.
For this process the following transaction codes are used: 32 — 
loss on unbilled, 72 — gain on uncollected, and 85 — loss on 
uncollected.  Any of these records that are actually taxes are 
bypassed.  Only client types 01 — Mar, 05 — Internal 
Non/Billable, 06 — Internal Billable, and 08 — BAS are selected.  
This is determined by a GETBDATA call to the client file.
Note that none of the files or COBOL variables are named.
By matching the English graphs to the COBOL graphs, VAE 
identified all the file names and COBOL variables involved.

 
 
Interpreting Novel Patterns  
Many texts contain unusual or ungrammatical patterns.
They may be elliptical forms that could be stored in tables.
But some authors write them as phrases in a sentence:
● 32 — loss on unbilled
● 72 — gain on uncollected
● 85 — loss on uncollected
Intellitex generated a CG with a default relation (Link):
     [Number: 32]→(Link)→[Punctuation: “–”]→(Link)→[Loss]→(On)→[Unbilled] 
The value 32 was stored as a constant in a COBOL program.
The phrase “loss on unbilled” was written as a comment.
The value and the comment from COBOL were translated to a 
CG that was the closest match to the CG derived from the text.

 
 
Results
Job finished in 8 weeks by two programmers, Arun Majumdar and André LeClerc.
    ● Four weeks for customization:
           
           Design, ontology, and additional programming for I/O formats. 
    ● Three weeks to run Intellitex + VAE + extensions:
           
           VAE handled matches with strong evidence (close semantic distance).
           
           Matches with weak evidence were confirmed or corrected by Majumdar       
           and LeClerc. 
    ● One week to produce a CD-ROM with integrated views of the results:
           Glossary, data dictionary, data flow diagrams, process architecture,              
           system context diagrams. 
A major consulting firm had estimated that the job would take 40 people two 
years to analyze the documentation and generate the cross references.
With VivoMind software, it  was completed in 15 person weeks.

 
 
Relating Formal and Informal CGs
The legacy-reengineering task required two kinds of processing.
Precise reasoning:
● Analyzing the COBOL programs and translating them to CGs.
● Detecting discrepancies between different programs.
● Detecting discrepancies between programs and documentation.
Indexing and cross references:
● Creating an index of English terms and names of programs.
● Mapping English documents to the files and programs they mention.
Conceptual graphs derived from COBOL are precise.
But the CGs derived from English are informal and unreliable.
Informal CGs are adequate for cross-references between the 
English documents and the COBOL programs.
All precise reasoning was performed on CGs from COBOL or   
on CGs from English that were corrected by CGs from COBOL. 

 
 
3. Application to Oil and Gas Exploration
Source material:
    ● 79 documents, ranging in length from 1 page to 50 pages.
    ● Some are reports about oil or gas fields, and others are chapters       
       from a textbook on geology used as background information.
    ● English, as written for human readers (no semantic tagging).
    ● Additional data from relational DBs and other structured sources.
    ● Lexical resources derived from WordNet, CoreLex, IBM-CSLI Verb
       Ontology, Roget's Thesaurus, and other sources. 
    ● An ontology for the oil and gas domain written in controlled English  
       by geologists from the University of Utah.
Queries:
    ● One or more sentences that describe a potential oil or gas field.
    ● Analogies compare the query to passages in the documents.

 
 
Answering Queries with VAE
For each sentence or structured data item in the sources,
    ● Translate the sentence or data item to a conceptual graph.
    ● Translate the CGs to Cognitive Signatures™ in time proportional to      
       (N log N), where N is the total number of CGs.
    ● Store each Cognitive Signature in Cognitive Memory™ with a pointer   
       back to the original source.
    ● Use previously translated CGs to help interpret new sentences.  
For a query stated as an  English sentence or paragraph,
    ● Translate the query to conceptual graphs.
    ● Find matching patterns in the source data and rank them in order of    
       semantic distance.  (Zero distance means an exact match.)
    ● For each match within a given threshold, use structure mapping to      
       verify which parts of the query CG match the source CG.
    ● As answer, return the English phrases from the source document         
       from which the best matches were derived.

 
 
Turbiditic sandstones and mudstones deposited as a passive 
margin lowstand fan in an intraslope basin setting.   Hydrocarbons 
are trapped by a combination of structural and stratigraphic onlap 
with a large gas cap.  Low relief basin consists of two narrow feeder 
corridors that open into a large low-relief basin approximately 32 
km wide and 32 km long.
THE QUERY

 
 
RESULTS, ranked by evidence (Dempster-Shafer) & confidence factors

 
 
After clicking the “Details” button on the previous window

 
 
DETAILS – Next, click the “Source Visualization” button

 
 
Top-level source visualization and the highest-ranked result

 
 
Drill down to one of the documents for the human readers

 
 
Drill down into the query and its relationships to the source documents

 
 
Emergent Knowledge
When reading the 79 documents,
● VLP translates the sentences and paragraphs to CGs.
● But it does not do any further analysis of the documents.
When a geologist asks a question,
● The VivoMind system may find related phrases in many sources.
● To connect those phrases, it may need to do further searches.
● The result is a large conceptual graph that relates the question to    
   multiple passages in multiple sources.
● Some of those sources can contribute information that does not      
  have any words that came from the original question.
● That new CG can be added to Cognitive Memory for future use.
By a “Socratic” dialog, the geologist can lead the system to 
explore novel paths and discover unexpected patterns.

 
 
Role of Analogy
Analogy is the foundation for human reasoning.
Without analogy, language understanding is impossible.
Logic is a disciplined special case of analogical reasoning:
   ● Essential for precise reasoning in mathematics and science.
   ● Important for precision in any field.
   ● But even in science, engineering, and computer programming,
      analogy is necessary for knowledge discovery and innovation.
Conceptual graphs support logical and analogical methods:
   ● They are defined by the ISO/IEC standard 24707 for Common Logic.
   ● But they also support semantic distance measures for analogy.
   ● They provide a bridge between informal language and formal logic.
CGs derived from English can be used for analogies.
But CGs used for formal logic should be derived from formal 
languages or be corrected by comparison to formal CGs.

 
 
7. Meeting the Challenges
7. Meeting the Challenges
A universal ontology of everything is highly unlikely.
But useful ontologies for multiple domains are more practical.
Such ontologies (explicit or implicit) have supported computer 
applications for over half a century.
Consistency of the internal details of all ontologies would be 
impossible to ensure and maintain.
But computer systems interoperate by guaranteeing consistency 
only at the interfaces, not in the internals.
The goal is to develop tools and methodologies for supporting 
and extending such ontologies. 

 
 
Interfaces to Semantic Systems
All computer systems, including legacy systems, are becoming 
semantic systems that directly or indirectly access the WWW.
Different people require different interfaces:
● Casual users – anybody who opens an unfamiliar application.
● Subject matter experts who develop the knowledge bases.
● IT professionals who develop the computer tools and systems.
For any subject, terminology is the key to interoperability:
● Subject matter experts (SMEs) know their subject.
● Their terminology is the basis for all communications about the subject.
● Their preferred languages and diagrams must be translatable to and from   
   computable representations.
● And the formal definitions of their terms must be consistent.

 
 
The World as Interface
From a book by Otto Rössler with the above title:
Exophysics:  The many, often incompatible theories about 
invisible entities such as atoms, molecules, fields, etc.
Endophysics:  The many, often incompatible views of the world 
(mental models) by all the people and beasts who live in it.
Interface:  The phenomena that people and other animals see, 
feel, interpret, and manipulate.
Consistency with the phenomena at the interface is the ultimate 
criterion of accuracy for both exophysics and endophysics.
Ambiguities in ordinary language result from reusing the same 
words in multiple versions of exophysics and endophysics.
Any formal theory can only express one version at a time.

 
 
Multiple Incompatible Theories
Different versions of exophysics may use incompatible 
ontologies.
Example of a three-dimensional ontology:
● A person is born at a time t1.
● A person dies at a time t2.
● For any time between t1 and t2, the person is alive at some               
  location x and has attributes that may change from time to time.
Example of a four-dimensional ontology:
● A person corresponds to a 4D volume.
● The times t1 and t2 are the lower and upper bounds on the time        
  coordinates of that volume.
● Some attributes of the person may be true or false at different         
  points in that volume.

 
 
Reconciling Ontologies
Any theory (exo- or endo-) that claims to be true about the world 
must be consistent with observations:
● No observation can contradict a true theory.
● But many observations may be irrelevant to a theory that is true      
  about some limited aspect of the world.
● Theories may also have internal variables that are not directly         
   related to observations.
● The internal variables of one theory may be very different from        
   or inconsistent with the internal variables of another theory.
● But all true theories must be consistent with observations.
Conclusion:
● Consistency of data shared among independently developed           
  applications should be possible for observable phenomena.
● But the consistency of their internal data is unlikely, unless they     
  are based on consistent theories.

 
 
COLORE Project
COmmon Logic Ontology REpository (COLORE) addresses the 
question
How can an Open Ontology Repository (OOR) support the 
integration of upper ontologies and also support the design     
and reuse of ontologies for existing and emerging standards?
 
Goals:
● Support ontologies expressed in Common Logic.
● Characterize logical relationships among ontologies.
● Develop logic-based tools to test those relationships.
● Use them to develop ontologies for manufacturing standards.
Project led by Michael Grüninger, Department of Mechanical   
and Industrial Engineering, University of Toronto.
http://stl.mie.utoronto.ca/colore/index.html

 
114
COLORE Foundation Ontologies
orderings
algebraic
structures
graphs
geometries
mereotopology
time
processes
resources
Ontologies for Manufacturing Standards

 
 
Bremen Ontology Research Group
Ongoing activities:
● Collaborative Research Center on Spatial Cognition
● Within the EU FP7 Project OASIS (Open Architecture for         
   Accessible Services Integration and Standardization)
● Developing logic-based tools and methodologies for               
  ontology structuring, sharing, and integration.
● Plan to collaborate with OOR, SIO, and COLORE projects.
Project members:
John Bateman (project leader),  Oliver Kutz,                       
Joana Hois,  Till Mossakowski,  Immanuel Normann,                  
Alexander Garcia Castro,  Bernd Krieg-Brückner,  Mehul Bhatt
http://www.fb10.uni-bremen.de/ontology/

 
 
Spatial Representation and Reasoning
Ontology
Geographic Information
Science (GIS)
Qualitative Spatial
Reasoning and
Representation (QSR)
Mapping to and from Natural Languages

 
 
A Hierarchy of Mathematical Theories

 
 
Tools for Processing Multiple Logics
http://www.informatik.uni-bremen.de/agbkb/forschung/formal_methods/CoFI/hets/index_e.htm

 
 
Sharing and Integrating Ontologies
The COLORE and Bremen projects have compatible tool kits 
that can be used with the Open Ontology Repository.
Their tools and theoretical frameworks can support lattices.
The full lattice of theories is infinite, but only a subset, called 
the Hierarchy of Ontologies, could ever be stored in the OOR.
The tools can perform lattice operations on the hierarchy:
● Combine ontologies.
● Check for inconsistencies (as far as computationally practical).
● Find mappings between ontologies with different terminology.
● Combine consistent ontologies to form larger ontologies.
● Find a common consistent subset of inconsistent ontologies.
● Save metadata about all the ontologies and their applications.
http://ontolog.cim3.net/file/work/OOR/OOR_presentations_publications/OOR-SemTech_Jun2010.pdf

 
 
Foundations for Ontology
Requirements for computational ontologies:
● Enable all software systems, including legacy systems, to share       
  information with people and with other computer systems.
● Support tools that facilitate collaboration, review, and testing by      
  people with different levels and kinds of expertise.
● Interpret and relate the huge volumes of linked data on the WWW     
  that is represented or described in natural language texts.
No single ontology can be compatible with all possible systems.
But a framework with a hierarchy of ontologies can support each 
system and show its relationships to every other system.
The same hierarchy of ontologies can also support flexible 
methods for natural language – controlled, unrestricted, or both.

 
 
Related Readings  
Future directions for semantic systems,
      http://www.jfsowa.com/pubs/futures.pdf 
Cognitive architectures for conceptual structures,
      http://www.jfsowa.com/pubs/ca4cs.pdf 
Role of Logic and Ontology in Language and Reasoning,
      http://www.jfsowa.com/pubs/rolelog.pdf 
Fads and Fallacies About Logic,
      http://www.jfsowa.com/pubs/fflogic.pdf
Conceptual Graphs for Representing Conceptual Structures,
      http://www.jfsowa.com/pubs/cg4cs.pdf
Peirce’s tutorial on existential graphs,
      http://www.jfsowa.com/pubs/egtut.pdf 
ISO/IEC standard 24707 for Common Logic,
      http://standards.iso.org/ittf/PubliclyAvailableStandards/c039175_ISO_IEC_24707_2007(E).zip

 
 
References
References for the VivoMind Cognitive Architecture:
Majumdar, Arun K., John F. Sowa, & John Stewart (2008) Pursuing the goal of language understanding,  
http://www.jfsowa.com/pubs/pursuing.pdf
Majumdar, Arun K., & John F. Sowa (2009) Two paradigms are better than one and multiple paradigms are 
even better,   http://www.jfsowa.com/pubs/paradigm.pdf   
Sowa, John F. (2002) Architectures for intelligent systems,   http://www.jfsowa.com/pubs/arch.htm 
Sowa, John F., & Arun K. Majumdar (2003) Analogical reasoning,  http://www.jfsowa.com/pubs/analog.htm  
Sowa, John F. (2006) Worlds, models, and descriptions, http://www.jfsowa.com/pubs/worlds.pdf   
Sowa, John F. (2011) Cognitive architectures for conceptual structures, http://www.jfsowa.com/pubs/ca4cs.pdf 
Other references:
Peirce, Charles Sanders (1909) Tutorial on existential graphs, MS 514 with commentary by J. F. Sowa, 
http://www.jfsowa.com/peirce/ms514.htm
Johnson-Laird, Philip N. (2002) Peirce, logic diagrams, and the elementary processes of reasoning, Thinking 
and Reasoning 8:2, 69-95.  http://mentalmodels.princeton.edu/papers/2002peirce.pdf 
Lamb, Sydney M. (2011) Neurolinguistics, Class Notes for Linguistics 411, Rice University.  
http://www.owlnet.rice.edu/~ling411
Harrison, Colin James (2000) PureNet: A modeling program for neurocognitive linguistics, 
http://scholarship.rice.edu/bitstream/handle/1911/19501/9969261.PDF 
For more references, see the combined bibliography for this site:  http://www.jfsowa.com/bib.htm    

