
Lecture Notes in Artificial Intelligence
2385
Subseries of Lecture Notes in Computer Science
Edited by J. G. Carbonell, and J. Siekmann
Lecture Notes in Computer Science
Edited by G. Goos, J. Hartmanis, and J. van Leeuwen

3
Berlin
Heidelberg
New York
Barcelona
Hong Kong
London
Milan
Paris
Tokyo

Jacques Calmet
Belaid Benhamou
Olga Caprotti
Laurent Henocque
Volker Sorge (Eds.)
Artiﬁcial Intelligence,
Automated Reasoning,
and Symbolic Computation
Joint International Conferences
AISC 2002 and Calculemus 2002
Marseille, France, July 1-5, 2002
Proceedings
1 3

Volume Editors
Jacques Calmet
University of Karlsruhe (TH)
Am Fasanengarten 5, Postfach 6980, D-76128 Karlsruhe, Germany
E-mail: calmet@ira.uka.de
Belaid Benhamou
Universit´e de Provence, CMI
39 rue F. Juliot-Curie, 13453 Marseille Cedex 13, France
E-mail: Belaid.Benhamou@cmi.univ-mrs.fr
Olga Caprotti
Johannes Kepler University
Research Institute for Symbolic Computation (RISC-Linz)
A-4040 Linz, Austria
E-mail: ocaprott@risc.uni-linz.ac.at
Laurent Henocque
Universit´e de la M´editerann´ee, ESIL
163 Avenue de Luminy, Marseille Cedex 09, France
E-mail: henocque@esil.univ-mrs.fr
Volker Sorge
University of Birmingham, School of Computer Science
Birmingham B15 2TT, United Kingdom
E-mail: V.Sorge@cs.bham.ac.uk
Cataloging-in-Publication Data applied for
Die Deutsche Bibliothek - CIP-Einheitsaufnahme
Artiﬁcial intelligence, automated reasoning, and symbolic computation :
joint international conferences ; proceedings / AISC 2002 and Calculemus
2002, Marseille, France, July 1 -5, 2002. Jacques Calmet ... (ed.). - Berlin
; Heidelberg ; New York ; Barcelona ; Hong Kong ; London ; Milan ; Paris ;
Tokyo : Springer, 2002
(Lecture notes in computer science ; Vol. 2385 : Lecture notes in
artiﬁcial intelligence)
ISBN 3-540-43865-3
CR Subject Classiﬁcation (1998): I.2.1-4, I.1, G.1-2, F.4.1
ISSN 0302-9743
ISBN 3-540-43865-3 Springer-Verlag Berlin Heidelberg New York
This work is subject to copyright. All rights are reserved, whether the whole or part of the material is
concerned, speciﬁcally the rights of translation, reprinting, re-use of illustrations, recitation, broadcasting,
reproduction on microﬁlms or in any other way, and storage in data banks. Duplication of this publication
or parts thereof is permitted only under the provisions of the German Copyright Law of September 9, 1965,
in its current version, and permission for use must always be obtained from Springer-Verlag. Violations are
liable for prosecution under the German Copyright Law.

Springer-Verlag Berlin Heidelberg New York
a member of BertelsmannSpringer Science+Business Media GmbH
http://www.springer.de
© Springer-Verlag Berlin Heidelberg 2002
Printed in Germany
Typesetting: Camera-ready by author, data conversion by PTP-Berlin, Stefan Sossna
Printed on acid-free paper
SPIN 10870512
06/3142
5 4 3 2 1 0

Preface
AISC 2002, the 6th international conference on Artiﬁcial Intelligence and Sym-
bolic Computation, and Calculemus 2002, the 10th symposium on the Integra-
tion of Symbolic Computation and Mechanized Reasoning, were held jointly
in Marseille, France on July 1–5, 2002. This event was organized by the three
universities in Marseille together with the LSIS (Laboratoire des Sciences de
l’Information et des Syst`emes).
AISC 2002 was the latest in a series of specialized conferences founded by
John Campbell and Jacques Calmet with the initial title “Artiﬁcial Intelligence
and Symbolic Mathematical Computation” (AISMC) and later denoted “Artiﬁ-
cial Intelligence and Symbolic Computation” (AISC). The scope is well deﬁned
by its successive titles.
AISMC-1 (1992), AISMC-2 (1994), AISMC-3 (1996), AISC’98, and AISC
2000 took place in Karlsruhe, Cambridge, Steyr, Plattsburgh (NY), and Madrid
respectively. The proceedings were published by Springer-Verlag as LNCS 737,
LNCS 958, LNCS 1138, LNAI 1476, and LNAI 1930 respectively.
Calculemus 2002 was the 10th symposium in a series which started with three
meetings in 1996, two meetings in 1997, and then turned into a yearly event in
1998. Since then, it has become a tradition to hold the meeting jointly with an
event in either symbolic computation or automated deduction.
Both events share common interests in looking at Symbolic Computation,
each from a diﬀerent point of view: Artiﬁcial Intelligence in the more general
case of AISC and Automated Deduction in the more speciﬁc case of Calculemus.
Holding the two conferences jointly should trigger interdisciplinary research, with
the ﬁrst results expected at AISC 2004 (Austria) and at Calculemus 2003.
This volume includes papers accepted for presentation at both AISC 2002
and Calculemus 2002. From the 52 contributions submitted, 17 full papers were
accepted for AISC, plus 7 full papers and 2 system descriptions for the Cal-
culemus program. In addition, the invited speakers’ abstracts are included as
part of this volume. Several work-in-progress contributions were accepted for
presentation at Calculemus 2002 but are not published in these proceedings.
We would like to express our thanks to the members of the two program
committees, to the AISC steering committee, to the Calculemus trustees, to
the referees, and to the organizing committee. Finally, we gratefully thank the
sponsors for their ﬁnancial support. Names are listed on the following pages.
April 2002
Jacques Calmet
Belaid Benhamou
Olga Caprotti
Laurent Henocque
Volker Sorge

Organization
Both AISC 2002 and CALCULEMUS 2002 were organized by the three uni-
versities of Marseille: L’Universit´e de Provence (Aix-Marseille I), L’Universit´e
de la M´editerran´ee (Aix-Marseille II), La Facult´e des Sciences de Saint-Jerˆome
(Aix-Marseille III), and the LSIS (Laboratoire des Sciences de l’Information et
des Syst`emes).
Conference Organization (AISC)
Conference and local chair:
Belaid Benhamou (Univ. de Provence, Aix-
Marseille I)
Program chair:
Laurent Henocque (Univ. de la M´editerran´ee,
Aix-Marseille II)
Steering committee:
Jacques Calmet (Univ. Karlsruhe, Germany)
John Campbell (Univ. College London, UK)
Eugenio Roanes-Lozano (Univ. Complutense de
Madrid, Spain)
Symposium Organization (CALCULEMUS)
Program chairs:
Olga Caprotti (RISC, Hagenberg, Austria)
Volker Sorge (Univ. of Birmingham, UK)
Local chair:
Belaid Benhamou (Univ. de Provence, Aix-
Marseille I)
Local Committee (AISC / CALCULEMUS)
Gilles Audemard
(Univ. de Provence, Aix-Marseille I)
Belaid Benhamou
(Univ. de Provence, Aix-Marseille I)
Philippe Jegou
(Fac. de Saint Jerˆome, Aix-Marseille III)
Laurent Henocque
(Univ. de la M´editerran´ee, Aix-Marseille II)
Pierre Siegel
(Univ. de Provence,Aix-Marseille I)

Organization
VII
Program Committee (AISC)
Luigia C. Aiello
(Univ. La Sapienza, Roma, Italy)
Jose A. Alonso
(Univ. de Sevilla, Spain)
Michael Beeson
(San Jose State Univ., USA)
Belaid Benhamou
(Univ. de Provence, France)
Greg Butler
(Univ. Concordia, Montreal, Canada)
Simon Colton
(Univ. of York, UK)
Jim Cunningham
(Imperial College London, UK)
James Davenport
(Univ. of Bath, UK)
Carl van Geem
(LAAS-CNRS, Toulouse, France)
Reiner Haehnle
(Univ. of Technology, Chalmers, Sweden)
Deepak Kapur
(Univ. New Mexico, USA)
Luis M. Laita
(Univ. Politecnica de Madrid, Spain)
Luis de Ledesma
(Univ. Politecnica de Madrid, Spain)
Eric Monfroy
(Univ. de Nantes, France)
Jose Mira
(UNED, Spain)
Ewa Orlowska
(Inst. Telecommunications, Warsaw, Poland)
Jochen Pfalzgraf
(Univ. Salzburg, Austria)
Jan Plaza
(Univ. Plattsburgh, USA)
Zbigniew W. Ras
(Univ. North Carolina, Charlotte, USA)
Tomas Recio
(Univ. de Santander, Spain)
Peder Thusgaard Ruhoﬀ
(MDS, Proteomics, Denmark)
Pierre Siegel
(Univ. de Provence, France)
Andrzej Skowron
(Warsaw Univ., Poland)
John Slaney
(ANU, Canberra, Australia)
Viorica Sofronie-Stokkermans
(Max Planck Institut, Germany)
Karel Stokkermans
(Univ. Salzburg, Austria)
Carolyn Talcott
(Stanford Univ., USA)
Rich Thomason
(Univ. of Pittsburgh, USA)
Dongming Wang
(Univ. Paris VI, France)
Additional Referees (AISC)
W. Ahrendt
F. Benhamou
R. Bernhaupt
B. Buchberger
O. Caprotti
M. Ceberio
M. Damsbo
L. Bordeaux
M. Jaeger
P.A. Madsen
A. C. Norman
H. Wang

VIII
Organization
Program Committee (CALCULEMUS)
Alessandro Armando
(Univ. of Genova, Italy)
Christoph Benzm¨uller
(Univ. of Saarbr¨ucken, Germany)
Jacques Calmet
(Univ. of Karlsruhe, Germany)
Alessandro Coglio
(Kestrel Institute, Palo Alto, USA)
Arjeh Cohen
(Univ. of Eindhoven, The Netherlands)
Simon Colton
(Univ. of Edinburgh, Scotland, UK )
James Davenport
(Univ. of Bath, UK)
William M. Farmer
(McMaster Univ., Hamilton, Canada)
Th´er`ese Hardin
(Univ. de Paris VI, France)
Hoon Hong
(Univ. of North Carolina State, Raleigh, USA)
Manfred Kerber
(Univ. of Birmingham, UK)
Michael Kohlhase
(Carnegie Mellon Univ., Pittsburgh, USA)
Steve Linton
(Univ. of St. Andrews, Scotland, UK)
Ursula Martin
(Univ. of St. Andrews, Scotland, UK)
Julian Richardson
(Heriot-Watt Univ., Edinburgh, Scotland,UK)
Renaud Rioboo
(Univ. de Paris VI, France)
Roberto Sebastiani
(Univ. di Trento, Italy)
Andrew Solomon
(Univ. of Technology, Sydney, Australia)
Andrzej Trybulec
(Bialystok Univ., Poland)
Volker Weisspfenning
(Univ. of Passau, Germany)
Wolfgang Windsteiger
(RISC, Hagenberg, Austria)
Additional Referees (CALCULEMUS)
M. Benerecetti
D. Doligez
A. Fiedler
M. Jaume
V. M´enissier-Morain
M. Moschner
G. Norman
S. Ranise
Sponsoring Institutions
L’Ecole d’Ing´enieur en Informatique de Luminy, ESIL
L’Universit´e de Provence, Aix-Marseille I
Le Conseil G´en´eral de Marseille
La Mairie de Marseille
Calculemus Project
CologNet, European Network of Excellence

Table of Contents
Invited Talks
Constraint Acquisition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
Eugene C. Freuder
Expressiveness and Complexity of Full First-Order Constraints in
the Algebra of Trees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2
Alain Colmerauer
Deduction versus Computation: The Case of Induction . . . . . . . . . . . . . . . . .
4
Eric Deplagne, Claude Kirchner
Integration of Quantiﬁer Elimination with Constraint Logic
Programming. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7
Thomas Sturm
AISC Regular Talks
Towards a Hybrid Symbolic/Numeric Computational Approach in
Controller Design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
12
Madhu Chetty
Inductive Synthesis of Functional Programs . . . . . . . . . . . . . . . . . . . . . . . . . . .
26
Emanuel Kitzelmann, Ute Schmid, Martin M¨uhlpfordt, Fritz Wysotzki
A Symbolic Computation-Based Expert System for Alzheimer’s
Disease Diagnosis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
38
Bego˜na Herrero, Luis M. Laita, Eugenio Roanes-Lozano, V´ıctor Maojo,
Luis de Ledesma, Jos´e Crespo, Laura Laita
On a Generalised Logicality Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
51
Marc Aiguier, Diane Bahrami, Catherine Dubois
Using Symbolic Computation in an Automated Sequent Derivation
System for Multi-valued Logic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
64
Elena Smirnova
The Wright ω Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
76
Robert M. Corless, D.J. Jeﬀrey
Multicontext Logic for Semigroups of Contexts . . . . . . . . . . . . . . . . . . . . . . . .
90
Rolf Nossum, Luciano Seraﬁni

X
Table of Contents
Indeﬁnite Integration as a Testbed for Developments
in Multi-agent Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 102
J.A. Campbell
Expression Inference – Genetic Symbolic Classiﬁcation
Integrated with Non-linear Coeﬃcient Optimisation . . . . . . . . . . . . . . . . . . . . 117
Andrew Hunter
A Novel Face Recognition Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128
Li Bai, Yihui Liu
Non-commutative Logic for Hand-Written Character Modeling. . . . . . . . . . . 136
Jacqueline Castaing
From Numerical to Symbolic Data during the Recognition of Scenarii . . . . . 154
S. Loriette-Rougegrez
On Mathematical Modeling of Networks and Implementation Aspects . . . . 168
Regina Bernhaupt, Jochen Pfalzgraf
Continuous First-Order Constraint Satisfaction . . . . . . . . . . . . . . . . . . . . . . . . 181
Stefan Ratschan
Coloring Algorithms for Tolerance Graphs: Reasoning and
Scheduling with Interval Constraints . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 196
Martin Charles Golumbic, Assaf Siani
A Genetic-Based Approach for Satisﬁability Problems . . . . . . . . . . . . . . . . . . 208
Mohamed Tounsi
On Identifying Simple and Quantiﬁed Lattice Points in the 2SAT
Polytope . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 217
K. Subramani
Calculemus Regular Talks
Integrating Boolean and Mathematical Solving: Foundations, Basic
Algorithms, and Requirements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231
Gilles Audemard, Piergiorgio Bertoli, Alessandro Cimatti,
Artur Korni8lowicz, Roberto Sebastiani
The Meaning of Inﬁnity in Calculus and Computer Algebra Systems. . . . . . 246
Michael Beeson, Freek Wiedijk
Making Conjectures about Maple Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . 259
Simon Colton
Employing Theory Formation to Guide Proof Planning . . . . . . . . . . . . . . . . . 275
Andreas Meier, Volker Sorge, Simon Colton

Table of Contents
XI
Uniﬁcation with Sequence Variables and Flexible Arity Symbols
and Its Extension with Pattern-Terms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 290
Temur Kutsia
Combining Generic and Domain Speciﬁc Reasoning by Using Contexts. . . . 305
Silvio Ranise
Inductive Theorem Proving and Computer Algebra in the MathWeb
Software Bus . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 319
J¨urgen Zimmer, Louise A. Dennis
Yacas: A Do-It-Yourself Symbolic Algebra Environment . . . . . . . . . . . . . . . . 332
Ayal Z. Pinkus, Serge Winitzki
Focus Windows: A New Technique for Proof
Presentation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 337
Florina Piroi, Bruno Buchberger
Author Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343

Constraint Acquisition⋆
Eugene C. Freuder
Cork Constraint Computation Centre
University College Cork, Cork, Ireland
e.freuder@4c.ucc.ie; www.4c.ucc.ie
Abstract. Many problems may be viewed as constraint satisfaction problems.
Application domains range from construction scheduling to bioinformatics. Con-
straint satisfaction problems involve ﬁnding values for problem variables subject
to restrictions on which combinations of values are allowed. For example, in
scheduling professors to teach classes, we cannot schedule the same professor to
teach two different classes at the same time. There are many powerful methods
for solving constraint satisfaction problems (though in general, of course, they are
NP-hard). However, before we can solve a problem, we must describe it, and we
want to do so in an appropriate form for efﬁcient processing. The Cork Constraint
Computation Centre is applying artiﬁcial intelligence techniques to assist or auto-
mate this modelling process. In doing so, we address a classic dilemma, common
to most any problem solving methodology. The problem domain experts may not
be expert in the problem solving methodology and the experts in the problem
solving methodology may not be domain experts.
⋆The author is supported by a Principal Investigator Award from Science Foundation Ireland.
J. Calmet et al. (Eds.): AISC-Calculemus 2002, LNAI 2385, p. 1, 2002.
c⃝Springer-Verlag Berlin Heidelberg 2002

Expressiveness and Complexity of Full
First-Order Constraints in the Algebra of Trees
Alain Colmerauer
Laboratoire d’Informatique Fondamentale de Marseille, Universit´e Aix-Marseille II,
France, alain.colmerauer@lim.univ-mrs.fr
Extended Abstract
What can be expressed by constraints, in the algebra of trees, if quantiﬁers and
all the logical connectors are allowed? What is the complexity of algorithms for
solving such general ﬁrst-order constraints? This talk answers these two ques-
tions.
Preliminaries. Let F be a set of function symbols. The algebra of trees consists
of the set of trees, whose nodes are labelled by elements of F, together with the
construction operations linked to the elements f of F. Such an operation, with
f of arity n, is the mapping (a1, . . . , an) →a, where a is the tree, whose initial
node is labelled f and whose sequence of daughters is a1, . . . , an. A general ﬁrst-
order constraint is a formula made from: variables, elements of F, the equality
symbol =, the logical constants and connectors true, false, ¬, ∧, ∨and the usual
quantiﬁers ∃, ∀.
Expressiveness. With respect to expressiveness, we show how to express a con-
straint of the form
ϕn(x, y)
def
=


∃u0 . . . ∃un
x=u0 ∧
ϕ(u0, u1) ∧
ϕ(u1, u2) ∧
· · ·
ϕ(un−1, un) ∧
un =y


by an equivalent constraint ψn(x, y), of size almost proportional to the size of
the constraint ϕ(x, y). More precisely, we show that there exists a constant c
such that, for any n,
|ψn(x, y)α(n)| ≤c |ϕ(x, y)|,
where α(n) is the huge integer
α(n)
def
= 2···

2(22)
	



n
.
For n = 5, this integer is already larger than the number of atoms of the universe.
J. Calmet et al. (Eds.): AISC-Calculemus 2002, LNAI 2385, pp. 2–3, 2002.
c
⃝Springer-Verlag Berlin Heidelberg 2002

Expressiveness and Complexity of Full First-Order Constraints
3
Complexity. With respect to complexity, by making use of the previous result,
we show that there exists a constant d and an integer n0 such that:
For any n ≥n0, there exists a constraint ψ of size n, without free variables,
such that any algorithm, which decides whether ψ is satisﬁed in the algebra of
trees, executes at least α(⌊dn⌋) instructions.

Deduction versus Computation: The Case of
Induction
Eric Deplagne and Claude Kirchner
LORIA & INRIA,
615 rue du Jardin Botanique, BP 101,
54602 Villers-l`es-Nancy Cedex, Nancy, France.
{Eric.Deplagne,Claude.Kirchner}@loria.fr
Abstract. The fundamental diﬀerence and the essential complementar-
ity between computation and deduction are central in computer algebra,
automated deduction, proof assistants and in frameworks making them
cooperating. In this work we show that the fundamental proof method
of induction can be understood and implemented as either computation
or deduction.
Inductive proofs can be built either explicitly by making use of an induc-
tion principle or implicitly by using the so-called induction by rewriting
and inductionless induction methods. When mechanizing proof construc-
tion, explicit induction is used in proof assistants and implicit induction
is used in rewrite based automated theorem provers. The two approaches
are clearly complementary but up to now there was no framework able to
encompass and to understand uniformly the two methods. In this work,
we propose such an approach based on the general notion of deduction
modulo. We extend slightly the original version of the deduction modulo
framework and we provide modularity properties for it. We show how
this applies to a uniform understanding of the so called induction by
rewriting method and how this relates directly to the general use of an
induction principle.
Summary
Induction is a fundamental proof method in mathematics. Since the emergence
of computer science, it has been studied and used as one of the fundamental
concepts to build mathematical proofs in a mechanized way. In the rising era of
proved softwares and systems it plays a fundamental role in frameworks allowing
to search for formal proofs. Therefore proofs by induction have a critical role in
proof assistants and automated theorem provers. Of course these two comple-
mentary approaches of proof building use induction in very diﬀerent ways. In
proof assistants like COQ, ELF, HOL, Isabelle, Larch, NQTHM, PVS, induc-
tion is used explicitly since the induction axiom is applied in an explicit way:
the human user or a clever tactics should ﬁnd the right induction hypothesis
as well as the right induction variables and patterns to conduct the induction
steps. In automated theorem provers speciﬁc methods have been developed to
J. Calmet et al. (Eds.): AISC-Calculemus 2002, LNAI 2385, pp. 4–6, 2002.
c
⃝Springer-Verlag Berlin Heidelberg 2002

Deduction versus Computation: The Case of Induction
5
automatically prove inductive properties. The most elaborated ones are based on
term rewriting and saturation techniques. They are respectively called induction
by rewriting and inductionless induction or proof by consistency. Systems that
implement these ideas are Spike, RRL or INKA.
The latter automated methods have been studied since the end of the sev-
enties and have shown their strengths on many practical examples from simple
algebraic speciﬁcations to more complicated ones like the Gilbreath card trick.
But what was intriguing from the conceptual point of view was the relationship
between explicit and implicit induction: implicit induction was shown to prove
inductive theorems, but the relationship with the explicit use of the induction
principle was open.
In this work, we provide a framework to understand both approaches in a
uniﬁed way. One important consequence is that it allows us to combine in a
well-understood way automated and assisted proof search methods. This rec-
onciliation of the two approaches will allow automated theorem provers and
proof assistants to collaborate in a safe way. It will also allow proof assistants to
embark powerful proof search tactics corresponding to implicit induction tech-
niques. This corresponds to the deduction versus computation scheme advocated
in [1] under the name of deduction modulo: we want some computations to be
made blindly i.e. without the user interaction and in this case this corresponds
to implicit induction; but one also needs to explicitly control deduction, just
because we know this is unavoidable and this can also be more eﬃcient.
It is thus not surprising to have our framework based on deduction modulo.
This presentation of ﬁrst-order logic relies on the sequent calculus modulo a
congruence deﬁned on terms and propositions. But since we need to formalize
the induction axiom which is by essence a second-order proposition, we need to
use the ﬁrst-order representation of higher-order logic designed in [2]. In this
formalism, switching from explicit induction to implicit one becomes clear and
amounts to push into the congruence some of the inductive reasoning, then to
apply standard automated reasoning methods to simplify the goal to be proved
and possibly get a better representation of the congruence.
This work relies on the notions and notations of deduction modulo [1] as
well as on the ﬁrst-order presentation of higher-order logic presented in [2].
We refer to these two papers for full deﬁnitions, details and motivations of the
framework. Using this new framework, we uniformly review the induction by
rewriting method and show how it directly relates to the induction principle,
thus providing proof theoretic instead of model theoretic proofs of this rewrite
based method.
Consequently, since the proof method is completely proof theoretic, to any
rewrite based inductive proof we can canonically associate an explicit proof in
the sequent calculus, thus providing a proof assistant with all the necessary
informations to replay the proof as needed.

6
E. Deplagne and C. Kirchner
References
1. Gilles Dowek, Th´er`ese Hardin, and Claude Kirchner.
Theorem proving modulo.
Rapport de Recherche 3400, Institut National de Recherche en Informatique et en
Automatique, April 1998.
ftp://ftp.inria.fr/INRIA/publication/RR/RR-3400.ps.gz.
2. Gilles Dowek, Th´er`ese Hardin, and Claude Kirchner. HOL-λσ an intentional ﬁrst-
order expression of higher-order logic. Mathematical Structures in Computer Sci-
ence, 11(1):21–45, 2001.

Integration of Quantiﬁer Elimination with
Constraint Logic Programming
Thomas Sturm
University of Passau, Germany
sturm@uni-passau.de
http://www.fmi.uni-passau.de/˜sturm/
Abstract. We examine the potential of an extension of constraint logic
programming, where the admissible constraints are arbitrary ﬁrst-order
formulas over some domain. Constraint solving is realized by eﬀective
quantiﬁer elimination. The arithmetic is always exact. We describe the
conceptual advantages of our approach and the capabilities of the current
implementation clp(rl). Supported domains are currently R, C, and Qp.
For our discussion here we restrict to R.
1
Constraint Logic Programming
Logic programming languages have emerged during the early seventies with Pro-
log by Colmerauer and Kowalski being the by far most prominent example. The
major conceptual contribution was disconnecting logic from control [Kow79].
The programmer should not longer be concerned with specifying and coding al-
gorithmic control structures but instead declaratively specify a problem within
some formal logical framework (Horn clauses). The system would then provide
a universal control algorithm (resolution) for solving the speciﬁed problem. Pro-
log became surprisingly successful during the eighties. This pure approach of
declarative speciﬁcation, however, turned out to be not suﬃciently eﬃcient. On
the basis of the observation that the arithmetic capabilities of the processing
machine had remained unused, there had then been numbers added to Prolog
and built-in predicates on these numbers. This approach, however, was not com-
patible with the original idea of separating logic and control.
This dilemma has been resolved with the step from logic programming (lp)
to constraint logic programming (clp) around the mid of the eighties. Clp com-
bines logic programming languages with constraint solvers. Constraint solving
was another established declarative programming paradigm that had come into
existence already in the early sixties in connection with graphics systems. A
constraint solving problem is given by a ﬁnite set of constraints. A constraint is
a relational dependence between several objects, variables, and certain functions
on these numbers and variables. The type of objects and the admitted functions
and relational dependences make up the domain of the constraint solver. One
example are linear programming problems (the target function can be coded as
an extra constraint). A solution of a constraint system is one binding of all vari-
ables such that all constraints are simultaneously satisﬁed. A constraint solver
J. Calmet et al. (Eds.): AISC-Calculemus 2002, LNAI 2385, pp. 7–11, 2002.
c
⃝Springer-Verlag Berlin Heidelberg 2002

8
T. Sturm
computes such a solution if possible, or otherwise states that the system is not
feasible. In clp, constraints may appear, besides regular atoms, within the bod-
ies of program clauses and within queries. Constraint solvers are supposed to
admit at least equations as valid constraints such that the uniﬁcation within
resolution can be replaced by a constraint solving step.
The initial step towards this type of systems was Colmerauer’s Prolog II
introducing negated equality “̸=” and an extended uniﬁcation that could han-
dle inﬁnite cyclic terms, also known as rational trees. Around 1988, three con-
straint logic systems of high inﬂuence appeared independently: chip, clp(r),
and Prolog III. Chip includes constraint solvers for arithmetic over ﬁnite do-
mains, ﬁnite Boolean algebra, and linear rational arithmetic. Clp(r) supports
real linear arithmetic using ﬂoating point numbers. Colmerauer’s Prolog III sup-
ports Boolean constraints, ﬁnite lists, and exact linear rational arithmetic.
2
Eﬀective Quantiﬁer Elimination
The historical development of eﬀective quantiﬁer elimination (qe) is independent
from that of clp. It origins from model theory, where the existence of quantiﬁer-
free equivalents over some model class has important theoretical consequences.
Given a ﬁrst-order formula over a domain in the above sense, a quantiﬁer elim-
ination procedure computes an equivalent formula that does not involve any
quantiﬁers. For parameter-free formulas this amounts to solving the correspond-
ing decision problem for the domain provided that variable-free atomic formulas
can be evaluated to truth values, which is most often the case.
Qe is an extremely powerful tool, and for many domains it can be shown
that such procedures do not exist. One famous example for this is the ordered
ring of integers. Luckily, they exist for a variety of very interesting domains, such
as for instance the following:
– Real closed ﬁelds (real numbers R with ordering).
– Algebraically closed ﬁelds (complex numbers C).
– Linear formulas in discretely valued ﬁelds (p-adic numbers Qp for primes
p with p-adic valuation). Qe for general formulas can be obtained here by
adding inﬁnitely many unary relations that state the existence of n-th roots.
For a thorough survey of implemented real qe methods and application ex-
amples, we refer the reader to [DSW98]. Besides qepcad as the currently most
advanced complete implementation of partial cylindrical algebraic decomposition
for the reals, we mention here the computer logic system redlog [DS97] based
on reduce, which implements the domains listed above. In addition, redlog
provides interfaces to other qe implementations including qepcad. Redlog is
the platform for the implementation of clp(rl), which is our connection be-
tween clp and qe discussed in the sequel.
Before turning to this, we wish to mention that clp(rl) is not the ﬁrst system
combining lp with qe. Around 1992, Hong and others have started to develop
clp(risc) which combines lp with qepcad as a constraint solver [Hon93]. In

Integration of Quantiﬁer Elimination with Constraint Logic Programming
9
contrast to clp(rl) the use of qe in clp(risc) is not visible to the user, who
just gains a solver for pure relational constraints of arbitrary degree over the
reals. In other words, clp(risc) completely lives in the clp world.
3
QE-Based CLP
Neglecting the programming language aspect of clp a little bit, it can be con-
sidered an approach to modeling certain scenarios and automatically deriving
knowledge about these scenarios. This is done by combining methods of math-
ematical logic in the lp part with algebraic methods in the constraint solving
part.
This very characterization as well applies to the application of eﬀective quan-
tiﬁer elimination procedures. Within this framework, a domain is chosen in the
same way as in clp. Then scenarios are modeled by ﬁrst-oder formulas over
this domain. Information is derived by possibly adding further ﬁrst-order for-
mulas, possibly adding further quantiﬁers, and then automatically computing a
quantiﬁer-free equivalent of the obtained input system.
It is a considerable restriction of clp that logical constructions are restricted
to Horn formulas. In spite of extensive research, there is no satisfying solution for
handling arbitrary Boolean combinations of constraints or quantiﬁcation. Vice
versa, it is a considerable restriction of qe that it operates exclusively over the
chosen domain. There is no facility for deﬁning extra functions or predicates.
Also there is no formalism for connecting quantiﬁer elimination procedures over
several domains to cooperatively solve a problem.
These observations, together with the fact that all services required from a
constraint solver for use within clp can be formulated as qe problems, gave
rise to the idea for clp(rl), which uses quantiﬁer elimination procedures in the
same way as constraint solvers are used in clp [Stu02]. There are at least two
possible ways to look at this:
1. In terms of clp, the gain is a sophisticated constraint solver, which can han-
dle not only relational dependences but arbitrary ﬁrst-order formulas over
the corresponding domain. Over the reals, constraints of arbitrary degree are
supported with exact arithmetic.
2. From a qe point of view, the deﬁnition of extra predicates and functions
in the lp part becomes possible. Furthermore, there is a perspective for
smoothly integrating qe procedures over several domains by means of a
type concept.
For both sides, the extensions are conservative in the following sense: Clp pro-
grammers can restrict to relational dependences, or use the extended concepts
only to such an extent that they feel comfortable about it. Vice versa, every qe
problem can be stated by means of an empty program with a query consisting
of a single quantiﬁed “constraint.”
We are going to give an impression of clp(rl) over the reals by means of
some simple examples. All computations have been performed on a 667 MHz
Pentium III.

10
T. Sturm
Arbitrary Degrees and Exact Arithmetic
Our ﬁrst example is taken from Hong [Hon93]. The program describes the
Wilkinson polynomial equation:
wilkinson(X, E) ←
20

i=1
(X + i) + EX19 = 0.
Mind that the left hand side polynomial of the equation occurs in the program
in expanded form. On the query ←wilkinson(X, 0), −20 ⩽X ⩽−10 we obtain
after 0.3 s the answer 20
i=1 X + i = 0.
For the query ←wilkinson(X, 2−23), −20 ⩽X ⩽−10 with a slight pertur-
bation, we obtain after 0.9 s the following answer (in expanded form):
8388608 ·
 20

i=1
(X + i) + 2−23X19

= 0 ∧X + 20 ⩾0 ∧X + 10 ⩽0.
This answer is contradictory, which could be tested, e.g., by applying qe to
its existential closure. Qepcad immediately yields “false” on this. Since our
clp(rl) lives inside a computer algebra system, we leave the responsibility of
how to proceed with such an answer to the user. They might alternatively ap-
ply the partly numerical function realroots of reduce to the left hand side
polynomial of the equation. This yields after 0.5 s the result
X ∈{−20.8469, −8.91725, −8.00727, −6.9997, −6.00001, −5, −4, −3, −2, −1}.
We have just been reminded how sensitive the root behavior of polynomials
and thus algebraic equations and inequalities are even to smallest rounding er-
rors. Within clp(rl) all arithmetic is exact. We have learned that the price to
be payed is possibly obtaining only implicit solutions. Then one has the choice
either to remain exact, or to apply approximate methods.
Disjunction
In traditional clp, constraints are ﬁnite sets of relational dependences regarded
as conjunctions. All suggested approaches to introducing disjunction in the clp
literature are based on extending the resolution procedure to handle these con-
structs. This leads to further restrictions of completeness of the resolution proce-
dure while the true declarative semantics of disjunction has never been obtained.
Within our framework, we leave the treatment of disjunction to qe. Consider
the following program for the minimum:
min(X, Y, Z) ←(X ⩽Y ∧Z = X) ∨(Y ⩽X ∧Z = Y ).
The answers that can be derived from this program are as complete and concise
as the deﬁnition itself. For the query ←min(3, 4, Z) we obtain Z −3 = 0. For
←min(X, Y, 3) the answer is
(X −3 = 0 ∧Y −3 ⩾0) ∨(X −3 ⩾0 ∧Y −3 = 0).
Asking for ←min(X, Y, Z), we obviously get the deﬁnition itself. All these com-
putations take no measurable time.

Integration of Quantiﬁer Elimination with Constraint Logic Programming
11
Quantiﬁed Constraints
Since our admissible constraints are ﬁrst-order formulas, they may also contain
quantiﬁcation. This does not increase the expressiveness but supports the concise
formulation of programs. The following program describes that in real 2-space
the point (u1, u2) is the image of the point (x1, x2) under central projection from
the punctual light source (c1, c2):
pr(C1, C2, X1, X2, U1, U2) ←∃T

T > 0 ∧
2
i=1
Ui = T(Xi −Ci)

.
Notice that this description covers all degenerate cases that arise when some
of the points or coordinates coincide. The following is a possible quantiﬁer-free
description with 10 atomic formulas:
(C1 = 0 ∧C2 = 0 ∧U1 = X1 ∧U2 = X2) ∨
(C2 ̸= 0 ∧C2U2 > C2X2 ∧C1U2 −C1X2 −C2U1 + C2X1 = 0) ∨
(C1 ̸= 0 ∧C1U1 > C1X1 ∧C1U2 −C1X2 −C2U1 + C2X1 = 0).
In higher dimensions the eﬀect becomes more dramatic. The corresponding
quantiﬁer-free description in 3-space has 18 atomic formulas, the one in 4-space
has 28.
4
Conclusions
We have introduced an extension of clp, where the constraints are arbitrary
ﬁrst-order formulas over some domain. Constraint solving then consists in var-
ious applications of qe. The advantages of our approach include constraints of
arbitrary degree, exact arithmetic, absolutely clean treatment of disjunction and
other Boolean operators, and quantiﬁed constraints. Alternatively, our approach
can be considered an extension of qe by lp facilities. Our concept is implemented
in our system clp(rl) based on redlog.
References
[DS97]
Andreas Dolzmann and Thomas Sturm. Redlog: Computer algebra meets
computer logic. ACM SIGSAM Bulletin, 31(2):2–9, June 1997.
[DSW98]
Andreas Dolzmann, Thomas Sturm, and Volker Weispfenning. Real quan-
tiﬁer elimination in practice. In B. H. Matzat, G.-M. Greuel, and G. Hiss,
editors, Algorithmic Algebra and Number Theory, pages 221–247. Springer,
Berlin, 1998.
[Hon93]
Hoon Hong. RISC-CLP(Real): Constraint logic programming over real num-
bers. In Frederic Benhamou and Alain Colmerauer, editors, Constraint Logic
Programming: Selected Research. MIT Press, 1993.
[Kow79]
Robert A. Kowalski. Algorithm = Logic + Control. Communications of the
ACM, 22(7):424–435, July 1979.
[Stu02]
Thomas Sturm. Quantiﬁer elimination-based constraint logic programming.
Technical Report MIP-0202, FMI, Universit¨at Passau, D-94030 Passau, Ger-
many, January 2002.

J. Calmet et al. (Eds.): AISC-Calculemus 2002, LNAI 2385, pp. 12–25, 2002.
© Springer-Verlag Berlin Heidelberg 2002
Towards a Hybrid Symbolic/Numeric Computational
Approach in Controller Design
Madhu Chetty
Gippsland School of Computing and Information Technology
Monash University, Churchill-3842, Australia
madhu.chetty@infotech.monash.edu.au
Abstract. Application of general computer algebra systems like MAPLE V
® can
prove advantageous over conventional ‘numerical’ simulation approach for
controller design. In this paper, an approach for the application of hybrid
symbolic/numeric computations to obtain explicit equations leading to the
design of an output feedback controller is presented. The methodology for
controller design using symbolic algebra is exemplified by considering the
design of an excitation controller for a simplified model of the synchronous
generator connected to an infinite bus. The output feedback controller is
obtained from a symbolic full-state feedback controller by eliminating feedback
from unmeasurable states using the free parameters in the symbolic feedback
gain expressions. The entire analysis is carried out using the MATLAB
®
symbolic algebra toolbox that supports MAPLE V
®.
1 Introduction
Due to the phenomenal developments in computer hardware and software, the
approach to the solution of control and other problems is also undergoing fundamental
changes. Implementation of new tools and techniques, such as the new generation of
mathematical computation systems like MAPLE V
® or MATHEMATICA
®, have also
increased the mathematical facilities available to investigators. Designers can now
hopefully conceive techniques that were traditionally considered too complex or
tedious. Such situations can arise in the modeling, sensitivity analysis and design or
optimisation aspects of control systems. The recent development of linkages to
application software such as MATLAB
®, familiar to control engineers, will open
further interesting possibilities for investigations in this area.
Recently, in the field of control engineering, symbolic computation has been used for
studying zero dynamics, which plays an important role in the areas of modelling,
analysis and control of linear and non-linear systems [1]. Furthermore, calculations of
controllability and observability grammians and the determination of balanced
realizations have also been considered in a symbolic framework [2]. The use of
symbolic algebra in the analysis and design of robust control systems and the necessity

Towards a Hybrid Symbolic/Numeric Computational Approach in Controller Design         13
of symbolic environment for the development of the software implementation of the
algorithms has also been demonstrated [3]. In [4], usefulness of the complex symbolic
computations for the analysis of systems with parametric uncertainty has been
highlighted. Further, it has been shown in [5] that the mapping approach, which is
considered to be numerically unstable, performs better than the other known pole
assignment methods in a symbolic algebra environment. Stability investigations using
symbolic Hurwitz determinants and eigenvalue sensitivity analysis were reported by
the present authors in [6]. Other problems in control system design, e.g. designing a
sub-optimal controller using only the available state measurements [7], or parameter
sensitivity and robustness analyses (some of which may have explicit and even closed
form solutions [8]), could now be revisited by using the power of symbolic algebra
packages available.
This paper highlights the salient features of hybrid symbolic/numeric computation
technique. This is illustrated using a simplified configuration of the simple power
system consisting of a synchronous generator connected to an infinite bus. For the
sake of simplicity, the analysis is carried out with two simplifications in power system
representation, although a realistic generator representation is considered. The first
simplification is that the excitation system of the generator is representted by a first
order system instead of the traditional third order IEEE Type-1 excitation sytem. The
second simplification is that a direct feedback of speed is considered in the excitation
system, instead of the application of a conventional third order power system
stabiliser. The full-state controller for the excitation control of synchronous generator
is obtained using the Bass-Gura algorithm [9]. The elements of feedback gain matrix
K are obtained in symbolic form i.e. expressed in terms of the real and imaginary parts
of the desired closed loop poles specified also in symbolic form. Use of the symbolic
representation of the desired closed-loop poles allows choice or imposition of
appropriate relations among them (e.g. between the real and imaginary parts of the
poles) to achieve other desirable goals. One such obvious goal is to eliminate the
unmeasurable states from feedback law by requiring the corresponding gains to be set
to zero. Plots are presented for the variation of the feedback gains of the output
feedback controller and the parameters of one complex pair of desired eigenvalue as a
function of the real part of the other assigned complex eigenvalue. For the
investigations reported in this paper, the MATLAB
® symbolic algebra toolbox was
chosen to carry out investigations.
2 Pole Placement Controller Using Full State Feedback
Consider the state-space model of a single input single output linear system described
by the following state and output equations.
x
Ax
Bu
y
Cx
Du
=
+
=
+
(1)

14         M. Chetty
x is the column vector of state variables. The matrices A, B, C and D are the system
matrices. y is the plant output vector.
The open loop characteristic polynomial of the plant matrix A can be written as
s
a s
a
a
s
a
n
n
n
n
+
+
+
+
−
−
1
1
2
1
s
 
 
n-2 
(2)
 Here n is the order of the system and a1, a2 ….an are the constants of polynomial.
Let the desired closed loop polynomial of the plant be given as
s
s
s
n
n
n
n
+
+
+
+
−
−
α
α
α
α
1
1
2
1
s
 
 
n-2 
(3)
1,  2, …., n are the constants. These values fix the location of the desired closed
loop poles of the plant effectively deciding the plant behaviour.
The coefficients of the two polynomials given in eqn. (1) and eqn. (2), can be arranged
as row vectors as follows
[
]
a
a
a
a
a
n
n
=
−
1
2
1
  
  
  
  

(4)
[
]
α
α
α
α
α
=
−
1
2
1
  
  
 
  

n
n
(5)
The full-state feedback vector K can be obtained by the Bass-Gura formula [9] as
K
a
T
=
−
−
−
(
)(
)
α
β
γ
1
1
(6)
where  is the lower-triangular Toeplitz matrix given by eqn. (7),




















−
−
−
−
1
1
0
1
0
0
0
0
0
0
1
0
0
0
0
1
a
a
a
a
a
a
a
a
a
1
3
n
2
n
1
n
2
n
2
1
2
1











(7)
 is the controllability matrix defined by
[
]
γ = B AB A B
A
B
  
  
  
 
 
n-1
2

and Z
T denotes the transpose of a matrix Z.

Towards a Hybrid Symbolic/Numeric Computational Approach in Controller Design         15
3 Partial State Feedback
The application of Bass–Gura formula discussed above gives the full-state feedback
matrix Ks as
[
]
ns
s)
1
n
(
2
s
1
s
s
K
 
K
 
 
K
 
K
K
−
=

(8)
where all the system states are fed back. With full state feedback, the matrix elements,
  ;n ,
 ,2 ,1
i  ;0
K
   
si

=
≠
In practice, some of the states are not measurable and the actual feedback law used is a
partial state feedback or an output feedback for the reasons discussed above.
The output feedback matrix Ko is then written as
[
]
no
o
)
1
n
(
2
o
1
o
o
K
 
K
 
 
K
 
K
K
−
=

(9)
where some of the elements of Ko are equated to zero reflecting the unmeasured states,
i.e.
If the Ks matrix can be obtained in symbolic form, it may then prove very useful in
implementing the output feedback controller. The gains of the state feedback then will
be available in terms of the parameters of the desired closed loop poles. The output
feedback matrix Ko can be formulated by proper choice of the desired closed-loop
poles, based on the available measurements of the system states or outputs.
4 The Problem Formulation
The objective of the work reported here being mainly to illustrate a hybrid
symbolic/numeric approach for the design, a simplification in power system
representation is sought to minimise the complexities and details. Following
simplifications are carried out in modelling the excitation system and also the transfer
function for the supplementary feedback. In spite of these assumptions and
simplifications, a realistic representation of the generator and the power system is
maintained. Any increase in the plant order is avoided without affecting the design
procedure. Without these assumptions, the order of the system would have been nine
instead of the current fourth order system that will merely complicate the presentation
of essential ideas of the paper.

16         M. Chetty
4.1 
Assumptions and Simplifications in Plant Modelling
1. In power system stability studies, an IEEE Type-1 excitation system is
considered for investigations. This representation of excitation system requires
additional 3 states. Hence, a much simpler first order representation with a single
time constant is considered in this work.
2. In practice, an auxiliary signal such as the speed signal is fed back via a power
system stabiliser comprising a cascaded lead-lag network and a wash out circuit.
This representation requires three additional states. For simplification, a direct
feedback of speed is considered in this paper.
With these assumptions, the closed loop power system under investigation with the
supplementary feedback incorporated is shown in Figure 1.
Infinite
  Bus
Generator
Fig. 1. Synchronous generator connected to an Infinite Busbar
4.2       The Plant Model
The constants K1, K2, … K6 depend on the operating conditions and system parameters.
The relations to evaluate the constants, operating conditions and parameters of the
system considered for analysis are the same as those of [12-13].
The dynamic power system model in state space form with the supplementary
feedback of  is given as

Towards a Hybrid Symbolic/Numeric Computational Approach in Controller Design         17
(
)
(
)
(
)
U
1
1
 f
2
H
2
1
H
2
1
K
K
K
E
K
K
E
T
E
E
K
K
K
E
K
T
E
T
E
K
K
A
5
A
’q
6
A
fd
A
.
fd
fd
3
4
3
’q
3
’do
.
’q
.
m
’q
2
1
.
+
δ
∆
−
∆
−
∆
−
=
∆
∆
+
δ
∆
−
∆
−
=
∆
ω
∆
π
=
δ
∆
∆






+
∆
−
δ
∆
=
ω
∆
The synchronous generator is represented as a simplified third order system [14]. The
state variables are the increments in rotor speed , rotor angle  and voltage behind
the transient reactance E
’
q. In this paper, the generator excitation system is
represented by a first order system and the associated state of the exciter is Efd. A
supplementary feedback of speed deviation  to the excitation system is necessary to
ensure an improved transient behavior.
For the system under consideration, the control signal U is same as . The state
vector x of the combined generator-exciter system is then given by
[
]
∆
∆
∆
∆
∆
x
E
E
q
fd
=
ω
δ
   
   
  
’
(10)
The state-space model of the linearised power system incorporating the inner-loop
feedbacks incorporated can be described by the following state and output equations.
x
 
C
y
 
x
 
A
x
Tm
∆
=
∆
Γ
+
∆
=
∆
(11)
where  is the disturbance matrix and 
Tm
∆
 is the step disturbance.
5 Full-State Feedback Controller
For the given operating condition 
)
6.0
Q
 
and
 8.0
P
(
o
o
=
=
, the four eigenvalues of
the open-loop system (without incorporating the feedback U, i.e. , of the speed
signal) are
+0.10279 + j 5.5008
+0.10279  j 5.5008
-6.3709
-14.298

18         M. Chetty
Due to the location of a complex pair of eigenvalues in the right half of s-plane, it can
be seen that the system is unstable. The open loop characteristic polynomial is then
obtained from the plant matrix A. Let the desired closed loop poles be defined as
)
2
img
(j
2
real
   
and
   
)1
img
(j
1
real
±
±
(12)
With the desired closed-loop poles described symbolically in this manner, the
following symbolic Ks matrix is obtained using eqn. (6)
K
K
K
K
K
s
E
E
q
fd
=




ω
δ
  
  
  
’
(13)
where the elements of the Ks   matrix are given in symbolic form as follows
Feedback gain from the speed signal  is
Kω  =
–.3796 – 3.805 real1 – 3.805 real2 – .5434 	10 
-16 real1
2
 + .1271 real1
2
real2 + .1271 img1
2
 real2 – .3526 	10 
-16 real1
2
 real2
2
  – .5434 	10 
-16 img1
2
– .5434 	10 
-16 img2
2
  – .5434 	10 
-16 real2
2
  – .3526 	10 
-17 img1
2
  real2
2
 –
.3526 	10 
-17 real1
2
  img2
2
  – .3526 	10 
-17   img1
2
  img2
2
  – .2174 	10 
-15
real1 real2 + .1271 real1 img2
2
  + .1271 real1 real2
2
(14)
Feedback gain from rotor angle  is
Kd =
0.002418 real1 + .002418 real2 + .006059 real1
2
  + .7726 	10 
-18 real1
2
 real2
+ .7726 	10 
-18 img1
2
 real2 –.0002023 real1
2
  real2
2
  + .006059 img1
2
 +
.006059 img2
2
  + .006059 real2
2
  – .0002023 img1
2
  real2
2
 –.0002023 real1
2
img2
2
  – .0002023 img1
2
  img2
2
  + .02424 real1 real2 + .7726 	10 
-18 real1
img2
2
  + .7726 	10 
-18   real1 real2
2
  – .1271
(15)
Feedback gain from the voltage behind the transient reactance,  KEq
’
is
KEq
’ =
0.005556 real1 + .005556 real2 - .6458 + .006000 real2
2
  + .02400 real1
real2  + .006000 img1
2
  + .006000 img2
2
  + .006000 real1
2
  – .4996 	10 
-18

Towards a Hybrid Symbolic/Numeric Computational Approach in Controller Design         19
img1
2
 real2  – .4996 	10 
-18  real1
2
 real2 – .4996 	10 
-18  real1 real2
2
– .4996
	10 
-18 real1 img2
2
(16)
Feedback gain from the excitation system state variable KE fd   is
KE fd =
–.002000 real1 – .002000 real2 – .02046
(17)
6 Output-Feedback Controller
As seen from eqn. (13), there are four state feedback signals. However, the
synchronous generator is usually stabilised by an output feedback. This is because the
speed signal () is easily measurable while rotor angle () and the transient voltage
(Eq’) signals are difficult to measure. The excitation system voltage is also easily
measurable and can be fed back if required. For numerical analysis, proposed
algorithms [14], [15], [16] are available for computing output feedback law. However,
for a hybrid symbolic/numeric computations approach, we propose to implement the
output feedback law by setting or forcing the gain from an unavailable signal to zero.
The information contained in the symbolic expressions given by eqn. (14) to eqn. (17)
can be used for obtaining the output feedback controller Ko from the state feedback
controller Ks defined by eqn. (3).
6.1 Determining Range of Values for Imaginary Parts
As a first step, the range of values of img1 and img2 corresponding to the desired stable
region (negative values of real parts of the roots real1 and real2) of the system was
determined. This range of values for img1 and img2 is obtained by varying the values of
rea11 (or real2) between 
5.0
)
2
real
or  
 1
real
(
3
−
≤
≤
−
. It is observed that the
corresponding range of values for the absolute values of the imaginary parts img1 or
img2 lie between 3.68 and 10.408.
6.2 Identifying Signals to Be Eliminated
For the reasons given above, it is desired to stabilise the plant with the feedback of
only speed signal. Hence, the next step is to identify which of the remaining three state
feedback signal gains from , Efd, Eq’ (retaining the feedback from speed, ) can be
eliminated. This elimination process is achieved as follows.

20         M. Chetty
Verifying the scope for elimination of Efd feedback. From eqn. (18), it can be
observed that the feedback of 
fd
E
K
 depends directly on the values of real1 and real2
only.
For KE fd  to be eliminated, following relationship is obtained from eqn. (17) by
forcing KE fd =0.
real1 = –10.23 + real2
 (18)
This is a linear relationship between real1 and real2.
It is verified by time simulations that for the system to have a satisfactory response,
both complex roots must lie beyond  –1.0. Thus, by applying the constraint on real1 
– 1, a corresponding value of real2 is obtained from eqn. (18). These values of real1
and real1 are then substituted in eqn. (15) and eqn. (16) and the two equations solved
for img1 and img2.
It is observed that this computation does not result in real values for img1 and img2.
Hence, it can be concluded that feedback from KE fd  cannot be made zero and the
output feedback matrix, Ko, must essentially have feedback from Efd to guarantee good
system stability and both the poles located appropriately, say to the left of  –1.0. This
restriction, however, does not pose any practical difficulty since the signal Efd is easily
measurable.
Verifying the scope for elimination of δ and Eq’ signals. Next, it is necessary to
check whether the gains from remaining two signals, i.e. δ and E’
q, can be eliminated.
For this purpose, from the range of noted values of img2 between 3.68 and 10.408, the
value of img2 is chosen as img2 = 7.5 rad/sec (corresponding to real2 approximately
equal to –1.2). Fixing img2 at this value, it is observed that the two symbolic
equations i.e. Kδ = 0 and KEq
’  = 0 can be solved simultaneously for various values of
real2, implying that the signals δ and E’q can be eliminated from feedback and still
system stability maintained. To further investigate system behaviour, the value of
real2 is varied between –1.0 and –2.0 for the variables img1 and real1 for each of the
values of real2. The corresponding numerical values for Kw and KE fd  are then
computed. Plots of Kw, KE fd , real1 and img1 as a function of real2 are then obtained.
These are shown in Figures 2(a)-2(d).
It may be noted that the second and third elements of the feedback matrix,
corresponding to feedback gains of  and Eq’, are negligible (thus eliminated from the
feedback), effectively resulting in an output feedback controller using only  (gain

Towards a Hybrid Symbolic/Numeric Computational Approach in Controller Design         21
Fig. 2. (a) Plot of Kω vs. real2
Fig. 2. (b) Plot of Kefd vs. real2
Fig. 2. (c) Plot of real1 vs. real2

22         M. Chetty
Fig. 2. (d) Plot of img1 vs. real2
Fig. 2. Effects of variation of real part of the second eigenvalue, real2
of –7.38) and  Efd (gain of –1.53e-002). Further, the fourth element of the matrix,
corresponding to the gain of Efd, is also very small and thus the effective control is thus
reduced to the feedback from of speed signal  alone.
7 Time Responses
The time responses of the speed signal of the generator rotor of both the open loop and
closed loop power system are shown in Figure 3. It can be clearly seen that the third
order open loop power system, which is highly unstable, has been stabilised by the
symbolically designed output feedback controller with significant improvement in
transient behaviour. It is observed that the system settles down in less than 4 seconds
to produce a satisfactory transient behaviour. As expected, the performance of the
output feedback controller does not compare well with a conventional power system
stabiliser [12], [13] primarily due to the assumptions mentioned in sec. 4.1.
8 Conclusions
A novel approach to controller design using mixed symbolic/numeric computation is
presented. The simplified power system consists of a generator represented by a third
order model. Since the objective is basically to illustrate the hybrid symbolic-numeric
design approach, complexities are avoided by making assumptions in the excitation
system and in the feedback path of the speed signal from their usual representation
reported in the literature. A symbolic full-state feedback controller is designed using

Towards a Hybrid Symbolic/Numeric Computational Approach in Controller Design         23
Fig. 3. Time responses of speed signal
the Bass-Gura algorithm. A simplified output controller is then obtained from the full-
state controller by eliminating the states, which are not easily measurable due to the
physical constraints of the power system. For the power system (with the
simplifications) under consideration, it was found that the feedback gain of excitation
system voltage depends on the real parts of the desired closed-loop poles and its
feedback is essential for system stability. Numerical analysis is carried out and plots of
the gains Kw and KE fd  are obtained as a function of the real parts of the desired
closed-loop poles. Similarly, the real and imaginary parts of the closed-loop poles are
obtained for the variation in the real part of the other complex pole selected as the
desired closed-loop pole. The time responses indicate that the system, which was open
loop unstable, has been stabilised with a significant improvement in its transient
performance.
Acknowledgement. The author wishes to thank Dr. Kishor Dabke, honorary research
associate, for his help, discussions and valuable suggestions.
References
1. 
A. G.(Bram) de Jager, Applications of zero dynamics with symbolic computation, UKACC
international conference on control’98, September 1998, pp. 1311-1316.
2. 
H. Baki and N.Munro, Implementation of balanced realisation algorithms in a symbolic
environment, UKACC International conference on control’98, pp. 1317-1321.

24         M. Chetty
3. 
E. Kontogiannis and N. Munro, The use of symbolic algebra in robust control, UKACC
International conference on control’98, September 1998. pp. 1328-1332.
4. 
D.J. Balance and W. Chen, Symbolic computation in value sets of plants with uncertain
parameters, UKACC International Conference on Control’98, September 98, pp. 1322-
1327.
5. 
M.T. Soylemez and N.Munro, Pole assignment and symbolic algebra: A new way of
thinking, UKACC International Conference on Control’98, September 1998, pp. 1306-
1310.
6. 
M. Chetty and K.P Dabke, Symbolic computations: An overview and application to
controller design, proceedings of international conference on Information, Decision and
Control, Adelaide, 8
th-10
th February, 1999, pp. 451-456.
7. 
K. P. Dabke, Linear control with incomplete state feedback and known initial-state
statistics, Int. J. Control, vol. 11, No. 1, pp. 133-141, 1970.
8. 
G. Zames, Input-Output Feedback Stability and Robustness, 1959-85, IEEE Control
Systems, vol. 16, No. 3, pp. 61-66, June 1996.
9. 
T. Kailath, Linear systems, Prentice Hall, Englewood cliffs, New Jersey, 1980.
10. B. Porter and M.A. Woodhead, Performance of optimal control systems when some of the
state variables are not measurable, Int. Jr. of Control, vol. 8, pp. 191-195, 1968.
11. The Mathworks Inc., Symbolic math tool for use with MATLAB, user’s guide, Version 2.
12. M.L. Kothari, J. Nanda and K. Bhattacharya, Discrete-mode power system stabilisers,
Proc. IEE part-C, Generation Transmission and Distribution, November, 1993, pp. 523-
531.
13. M. Aldeen and M. Chetty, A dynamic output power system stabiliser, Control’95, October
1997, vol. 2, pp. 575-579.
14. D.D. Moerder and A.J Calise, Convergence of a numerical algorithm for calculating
optimal output feedback gains, IEEE Trans. On Automatic Control, Vol. AC-30, No. 9, pp.
900-903, September 1985.
15. W.S. Levine and M. Athans, On the determination of optimal output feedback gains for
linear multivariable systems, IEEE Trans on Automatic Control, Vol. AC-15, pp.44-48,
1970.
16. S.S Choi and H.R. Sirisena, Computation of optimal output feedback controls for unstable
linear multivariable systems, IEEE Trans on Automatic Control, Vol. AC-22, pp.134-136,
Feb 1977.
17. P.M. Anderson and A.A. Fouad, Power system control and stability, New York, IEEE
press, 1994.
APPENDIX-A: System Parameters
The nominal parameters of the system under investigation are as follows. All data is in
pu except the inertia constant, H and the time constants which are given in seconds.

Towards a Hybrid Symbolic/Numeric Computational Approach in Controller Design         25
4.0
xe
line
on 
Transmissi
s 
05
.0
TA
    
,0.
50
KA
system
 
excitation
order 
 
First
55
.1
xq
  ,
32
.0
x’d
  ,6.1
xd
 
s,
 0.6
T’do
  
s,
 0.5
H
Generator
0.1
Vto
  
Hz,
 
50
f
  ,6.0
Qo
  ,8.0
Po
conditions
 
Operating
=
=
=
=
=
=
=
=
=
=
=
=
APPENDIX-B: Model Constants
The constants 
K
K
6
1
,
,


 are evaluated using the relations given below. The
subscript o means steady state value. The steady state values of d-q axis voltage and
current components (such as 
V
I
do
qo  ,
etc.) for the single machine infinite bus system
are calculated using the phasor diagram relations as given in [14].
Vto
Vqo
x’d
xe
xe
K6
o
sin
V
Vto
Vqo
x’d
xe
x’d
o
cos
V
Vto
Vdo
xq
xe
xq
K5
o
sin
V
x’d
xe
x’d
xd
K4
xe
xd
xe
x’d
K3
o
sin
x’d
xe
V
K2
o
cos
xq
xe
V
Eqo
0
sin
V
Iqo
x’d
xe
x’d
xq
K1
+
=
δ
∞
+
−
δ
∞
+
=
δ
∞
+
−
=
+
+
=
δ
+
∞
=
δ
+
∞
+
δ
∞
+
−
=

Inductive Synthesis of Functional Programs
Emanuel Kitzelmann1, Ute Schmid2, Martin M¨uhlpfordt3, and Fritz Wysotzki1
1 Department of Computer Science, Technical University Berlin, Germany,
{jemanuel,wysotzki}@cs.tu-berlin.de,
2 Institute of Computer Science, University of Osnabr¨uck, Germany,
schmid@informatik.uni-osnabrueck.de
3 German National Research Center for Information Technology (GMD), Darmstadt, Germany,
mamue@ipsi.fhg.de
Abstract. We present an approach to folding of ﬁnite program terms based on
the detection of recurrence relations in a single given term which is considered as
the kth unfolding of an unknown recursive program. Our approach goes beyond
Summers’ classical approach in several aspects: It is language independent and
works for terms belonging to an arbitrary term algebra; it allows induction of
sets of recursive equations which are in some arbitrary ‘calls’ relation; induced
equations can be dependent on more than one input parameters and we can detect
interdependencies of variable substitutions in recursive calls; the given input
terms can represent incomplete unfoldings of an hypothetical recursive program.
Keywords: Inductive program synthesis, folding, recursive program schemes
Topics: Symbolic computations and machine learning, term rewriting
1
Introduction
Automatic induction of programs from I/O examples is an active area of research since
the sixties and of interest for AI research as well as for software engineering [LM91].
We present an approach which is based on the recurrence-detection method of Summers
[Sum77]. Induction of a recursive program is performed in two steps: First, input/output
examples are rewritten into a ﬁnite program term, and second, the ﬁnite term is checked
for recurrence. If a recurrence relation is found, the ﬁnite program is folded into a
recursive function which generalizes over the given examples. The ﬁrst step of Summers’
approach is knowledge dependent: In general, there are inﬁnitely many possibilities to
representinput/outputexamplesasterms.Summersdealswiththatproblembyrestricting
his approach to structural list problems.Alternatively, the ﬁnite program can be generated
by the user [SE99] or constructed by AI planning [SW00].
In the following, we are only concerned with the second step of program synthesis
– folding a ﬁnite program term in a recursive program. This corresponds to program
synthesis from traces and is an interesting problem in its own right. Providing a powerful
approach to folding is crucial for developping synthesis tools for practical applications.
Furthermore, because recursive programs correspond to a subset of context-free tree
grammers, our approach to folding can be applied to artiﬁcial and natural grammer
inference problems. Finally, combining program synthesis and AI planning makes it
J. Calmet et al. (Eds.): AISC-Calculemus 2002, LNAI 2385, pp. 26–37, 2002.
c⃝Springer-Verlag Berlin Heidelberg 2002

Inductive Synthesis of Functional Programs
27
possible to infer general control policies for planning domains with recursive domains,
such as the Tower of Hanoi [SW00].
Our approach extends Summers’ approach in several aspects: First, it is language
independent and works for terms belonging to an arbitrary term algebra, while Summers
was restricted to Lisp programs; second, it allows induction of sets of recursive equations
which are in some arbitrary ‘calls’ relation, while Summers was restricted to induction
of a single, linear recursive equation; third, induced equations can be dependent on more
than one input parameters and we can detect interdependencies of variable substitutions
in recursive calls, while Summers was restricted to a single input list; ﬁnally, the given
input terms can represent incomplete unfoldings of an hypothetical recursive program
– which is important if the program terms to be folded are obtained by other sources,
such as a user or an AI tool.
In the following, we ﬁrst present our basic terminology, then we formulate the induc-
tion problem. We will give a simple example of inductive program synthesis to illustrate
our approach and afterwards present the approach formally. Because the approach is
rather complex, we will only present the central deﬁnitions and theorems and do not
give the algorithms. A complete description can be found in [Sch01].
2
Basic Terminology
2.1
Terms and Term Rewriting
Terms. A signature Σ is a set of (function) symbols with α : Σ →N giving the arity of
a symbol. With X (X ∩Σ = ∅) we denote the set of variables, with TΣ(X) the terms
over Σ and X, and with TΣ the ground terms (terms without variables). var(t) is the
set of all variables in term t. We use tree and term as synonyms. If {x1, . . . , xn} are the
variables of a term t, then t[x1 ←t1, . . . , xn ←tn] (or t[t1, . . . , tn] for short) denotes
the tree obtained by simultaneously substituting the terms ti for each occurence of the
variables xi in t, i = 1, . . . , n.
A position in t is deﬁned in the usual way as a sequence of natural numbers: (a) λ
is the root position of t, (b) if t = f(t1, . . . , tn) and u is a position in ti then i.u is a
position in t. The composition v ◦w of two positions is deﬁned as u.w, if v = u.λ,
the composition v ◦k of a position v and a natural number k as u.k.λ, if v = u.λ. A
partial order over positions is deﬁned by v ≤w iff v = w or it exists a position u with
v ◦u = w. A set of positions U is called segmentation set if for all u ∈U it holds:
̸ ∃u′ ∈U with u′ < u.
A subterm of a term t at a position u (written t|u) is deﬁned as: (a) t|λ = t, (b) if
t = f(t1, . . . , tn) and u a position in ti, then t|i.u = ti|u, i = 1, . . . , n. For a term t and a
position u, function node(t, u) returns the ﬁxed symbol f ∈Σ, if t|u = f(t1, . . . , tn).
The set of all positions at which a ﬁxed symbol f appears in a term is denoted by
pos(t, f). With pos(t) we refer to the set of all positions in term t. Obviously it holds
that v ∈pos(t), if w ∈pos(t) and v ≤w. The replacement of a sub-term t|w by a
term s in a term t is written as t[w ←s].
A term p ∈TΣ({y1, . . . , yn}) is called ﬁrst order pattern of a term t ∈TΣ(X),
{y1, . . . , yn}∩X = ∅, if there exist subtrees ti, such that t = p[y1 ←t1, . . . , yn ←tn],
i = 1, . . . , n. A pattern p of a term t is called trivial, if p is a variable and non-trivial
otherwise. We write p ≤t if p is a pattern of t and p < t if p and t can not be uniﬁed by

28
E. Kitzelmann et al.
variable renaming only. p is called maximal (ﬁrst order) pattern of t, if p ≤t and there
exists no term p′ with p < p′ and p′ ≤t.
Term rewriting.A term rewrite system over Σ is a set of pairs of terms R ⊆TΣ(X)×
TΣ(X). The elements (l, r) of R are called rewrite rules and are written as l →r.A term
t′ can be derived in one rewrite step from a term t using R (t →R t′), if there exists a
position u in t, a rule l →r ∈R, and a substitution σ : X →TΣ(X), such that (a) t|u =
σ(l) and (b) t′ = t[u ←σ(r)]. R implies a rewrite relation →R⊆TΣ(X) × TΣ(X)
with (t, t′) ∈→R if t →R t′. The reﬂexive and transitive closure of →R is
∗→R.
2.2
Recursive Program Schemes
Let Σ be a signature and Φ = {G1, . . . , Gn} a set of function variables with Σ ∩Φ = ∅
and arity α(Gi) = mi > 0. A recursive program scheme (RPS) S on a signature Σ,
variables X and a set of function variables Φ = {G1, . . . , Gn} with Σ ∩Φ = ∅is a pair
(G, t0) with a calling “main program” t0 ∈TΣ∪Φ(X) and G as a system of n equations
(recursive “subprograms”): G = ⟨Gi(x1, . . . , xmi) = ti⟩with ti ∈TΣ∪Φ(X), i =
1, . . . , n.
Language of an RPS. For an RPS S = (G, t0) and a special symbol Ω, the equations
in G constitute rules RS = {Gi(x1, . . . , xmi) →ti | i ∈{1, . . . , n}} of a term rewrite
system. The system additionally contains rules RΩ= {Gi(x1, . . . , xmi) →Ω| i ∈
{1, . . . , n}}.We write
∗→Σ,Ωforthereﬂexiveandtransitiveclosureoftherewriterelation
implied by RS ∪RΩ.
For a substitution with ground terms β : X →TΣ, called initial instantiation of
variables X, the set of all terms L(S, β) = {t | t ∈TΣ∪{Ω}, β(t0)
∗→Σ,Ωt} is
called the language generated by S with initial instantiation β. For a particular equation
Gi ∈G the rewrite relation →Gi,Ωis implied by the rules RGi,Ω= {Gi(x1, . . . xmi) →
ti, Gi(x1, . . . xmi) →Ω} and for an instantiation β : {x1, . . . xmi} →TΣ of pa-
rameters of Gi, the language generated by subprogram Gi is the set of all terms
L(Gi, β) = {t | t ∈TΣ∪{Ω}∪Φ\{Gi}, β(Gi(x1, . . . , xmi))
∗→Gi,Ωt}.
Relations between subprograms. For an RPS S let H /∈Φ be a function variable (for
the unnamed main program). A relation callsS ⊆{H} ∪Φ × Φ between subprograms
and main program of S is deﬁned as: callsS = {(H, Gi) | Gi ∈Φ, pos(t0, Gi) ̸=
∅} ∪{(Gi, Gj) | Gi, Gj ∈Φ, pos(ti, Gj) ̸= ∅}. The transitive closure calls∗
S of
callsS is the smallest set calls∗
S ⊆{H}∪Φ×Φ for which holds: (a) callsS ⊆calls∗
S,
(b) for all P ∈{H} ∪Φ and Gi, Gj ∈Φ: If P calls∗
S Gi and Gi calls∗
S Gj then
P calls∗
S Gj.
For a recursive equation Gi(x1, . . . , xmi) = ti in G, the set of transitively called
(tc) equations Gi with initial equation Gi is deﬁned as Gi = {Gj(x1, . . . , xmj) =
tj | Gi calls∗
S Gj}. A set of tc equations for an initial equation Gi is the set of all
equations in an RPS called by Gi, directly or indirectly by means of further equations.
For a set of tc equations Gi and its initial equation Gi the extended rewrite relation
→Gi,Ωis implied by the rules RGi = {Gi(x1, . . . , xmi) →ti | Gi ∈Gi}, RΩ=
{Gi(x1, . . . , xmi) →Ω| Gi ∈Gi} and for an instantiation β : {x1, . . . xmi} →TΣ
the set of all terms Lext(Gi, β) = {t | t ∈TΣ∪{Ω}, β(Gi(x1, . . . , xmi))
∗→Gi,Ωt} is
the extended language generated by subprogram Gi with instantiation β.

Inductive Synthesis of Functional Programs
29
2.3
Unfolding of RPSs
For a recursive equation Gi(x1, . . . , xmi) = ti with parameters Xi = {x1, . . . xmi} the
set of recursion points is given by Urec = pos(ti, Gi) with indices R = {1, . . . , |Urec|}.
Each recursive call of Gi at position ur ∈Urec, r ∈R in ti implies substitutions σr :
Xi →TΣ(Xi) of the parameters in Gi. The substitution terms, denoted by sub(xj, r),
are deﬁned by sub(xj, r) = σr(xj) for all xj ∈Xi and it holds sub(xj, r) = ti|ur◦j.
Thesetofunfoldingpoints,denotedbyUunf,isconstructedoverUrec andinductively
deﬁned as the smallest set for which holds: (a) λ ∈Uunf, (b) if uunf ∈Uunf and urec ∈
Urec, then uunf ◦urec ∈Uunf. Unfolding points imply compositions of substitutions,
denoted by sub∗(xj, uunf), which are inductively deﬁned by: (a) sub∗(xj, λ) = xj,
(b) sub∗(xj, uunf ◦ur) = sub(xj, r){x1 ←sub∗(x1, uunf), . . . , xmi ←
sub∗(xmi, uunf)}, j = 1, . . . , mi.
Unfoldings. For an initial instantiation β : Xi →TΣ, the instantiations of parameters
in unfoldings of an equation Gi are indexed by Uunf and deﬁned as: βuunf (xj) =
β(sub∗(xj, uunf)). The set of all unfoldings Υi of equation Gi over instantiation β is
indexed by Uunf and deﬁned as Υi = {υuunf |υuunf = βuunf (ti)}.
The following lemma states the relation between the concepts introduced, that is,
between an RPS and its unfoldings:
Lemma 1 (Inductive Structure of L). Let t ∈L(Gi, β) be an element of the language of Gi over
an initial instantiation β : Xi →TΣ. Then for all uunf ∈Uunf ∩pos(t) it holds: t|uunf = Ω
or t|uunf [Urec ←Ω] = υuunf [Urec ←Ω]. (Proof by induction over Uunf.)
The relations existing between a given RPS and its unfoldings can be exploited for
the reverse process – the induction of an unknown RPS from a given term which is
considered as some unfolding of a set of recursive equations.
3
Induction of Recursive Program Schemes
3.1
Initial Programs
An initial program is a ground term t ∈TΣ∪{Ω} which contains at least one Ω. A t
which contains function variables, i.e. t ∈TΣ∪Φ∪{Ω}, is called reduced initial program.
We use initial program and initial tree as synonyms. For terms which contain Ωs, an
order relation is deﬁned by: (a) Ω≤Ωt′, if pos(t′, Ω) ̸= ∅, (b) x ≤Ωt′, if x ∈X
and pos(t′, Ω) = ∅, (c) f(t1, . . . , tn) ≤Ωf(t′
1, . . . t′
n), if ∀i ∈{1, . . . , n} it holds
ti ≤Ωt′
i.
Initial programs correspond to the elements of the language of an RPS or a set of
tc equations, whereas reduced initial programs correspond to elements of the language
of a particular recursive equation. We say that an RPS S = (G, t0) explains an initial
program tinit, if there exists an instantiation β : var(t0) →TΣ of the parameters of
the main program t0 and a term t ∈L(S, β), such that tinit ≤Ωt. S is a recurrent
explanation of tinit, and if exists a term t′ ∈L(S, β) which can be derived by at least
two applications of rules RS, such that t′ ≤Ωtinit. Analogously we say that a set of tc
equations (or a particular recursive equation) explains a (reduced) initial program. An
equation/RPS explains a set of initial programs Tinit, if it explains all terms tinit ∈Tinit
and if there is a recurrent explanation for at least one of them.

30
E. Kitzelmann et al.
3.2
Characteristics of Program Schemes
There are some restrictions of RPSs which can be folded using our approach:
No Nested Program Calls: Calls of recursive equations within subtstitution terms of
another call of an equation are not allowed, that is Urec ∪Usub is a segmentation
set for each equation in G.
No Mutual Recursion: There are no recursive equations Gi, Gj, i ̸= j, with
Gi calls∗
S Gj and Gj calls∗
S Gi, that is, the relation calls∗
S is antisymmetric.
The ﬁrst restriction is semantical, that is, it reduces the class of calculable functions
which can be folded.The second restriction is only syntactical since each pair of mutually
recursive functions can be transformed into semantically equivalent functions which are
not mutually recursive.
The appearance of RPSs which will be folded are characterized in the following way:
For each program body ti of an equation in G it holds
– var(ti) = {x1, . . . , xmi}, that is, all variables in the program head are used in the
program body, and
– pos(ti, Gi) ̸= ∅, that is, each equation is recursive.
These characteristics do not restrict the class of RPSs which can be folded.
Furthermore the folded RPSs are minimal according to the following conditions:
No unused subprograms: H calls∗
S Gi.
No unused parameters: For each instantiation β : Xi →TΣ and instantiations βj :
Xi →TΣ, j = 1, . . . , mi constructed as βj(xk) = t, if k = j, t ∈TΣ, t ̸= β(xj),
βj(xk) = β(xk), if k ̸= j holds L(Gi, β) ̸= L(Gi, βj).
No identical parameters: For all β : Xi →TΣ and all xi, xj ∈Xi holds: For all
unfoldings υuunf ∈Υi, uunf ∈Uunf with instantiation βuunf of variables follows
i = j from βuunf (xi) = βuunf (xj).
Deﬁnition 1 (Substitution Uniqueness of an RPS). An RPS S = (G, t0) over Σ and
Φ which explains recursively a set of initial trees Tinit is called substitution unique wrt
Tinit if there exists no S′ over Σ and Φ which explains Tinit recursively and for which
it holds: (a) t′
0 = t0, (b) for all Gi ∈Φ holds pos(ti, Gi) = pos(t′
i, Gi) = Urec,
t′
i[Urec ←Ω] = ti[Urec ←Ω], and it exists an r ∈R with sub(xj, r) ̸= sub′(xj, r).
Substitution uniqueness guarantees that it is not possible to replace a substitution term in
S, such that the resulting RPS S′ still explains a given set of initial programs recursively.
It can be shown that each RPS satisfying the given characteristics is substitution unique
wrt the set of all terms which can be derived by it.
3.3
The Synthesis Problem
Now all preliminaries are given to state the synthesis problem:
Deﬁnition 2 (Synthesis Problem). Let Tinit ⊂TΣ∪{Ω} be a set of initial programs.
The synthesis problem is to induce

Inductive Synthesis of Functional Programs
31
– a signature Σ,
– a set of function variables Φ = {G1, . . . , Gn},
– a minimal RPS S = (G, t0) with a main program t0 ∈TΣ∪Φ(X) and a set of
recursive equations G = ⟨G1(x1, . . . , xm1) = t1, . . . , Gn(x1, . . . , xmn) = tn⟩
such that
– S recursively explains Tinit, and
– S is substitution unique (Def. 1).
4
A Simple Example
We will illustrate our method, described in the following sections, by means of a (very)
simple example. Consider the following RPS S = (G, t0):
G = ⟨G(x) = if(eq0(x), 1, ∗(x, G(pred(x)))) ⟩, t0 = G(x).
If the symbols are interpreted in the usual way, this RPS calculates the factorial function.
An example for an initial program which can be generated by this RPS with initial
instantiation β(x) = succ(succ(0)) is tinit =
if(eq0(succ(succ(0))),
1,*(succ(succ(0)),
if(eq0(pred(succ(succ(0)))),
1,*(pred(succ(succ(0))),
if(eq0(pred(pred(succ(succ(0))))),1,*(pred(pred(succ(succ(0)))),Ω)))))).
In a ﬁrst step (Sect.5.1), the recursion points (positions, at which a recursive call
appeared) will be infered. Only those positions are possible which lie on a path leading
to an Ω(only one in this example). Furthermore, it must hold that the positions between
the root and the recursion point reiterate itself up to arriving the Ω. This results in
Urec = {2.3.λ} in this example. The minimal pattern which includes the mentioned
symbols is tskel = if(x1, x2, ∗(x3, Ω)). The recursion point devides the initial term
into three segments:
if(eq0(succ(succ(0))), 1, ∗(succ(succ(0)), G))
if(eq0(pred(succ(succ(0)))), 1, ∗(pred(succ(succ(0))), G))
if(eq0(pred(pred(succ(succ(0))))), 1, ∗(pred(pred(succ(succ(0)))), G))
Since there are no further Ωs in the initial tree, the searched for equation can only contain
the found position as recursion point. In more complex RPSs it might happen that not all
Ωs can be explained in the described way. In this case, we assume that another equation
is called by the searched for equation. An RPS for the resulting subtrees will be induced
seperately.
In a second step (Sect.5.2), the program body will be constructed by extending
the term tskel by all positions which remain constant over the segments. This method
results in the term ˆtG = if(eq0(x1), 1, ∗(x1)). Identical subtrees in one segment are
represented by the same variable (x1 in our example).
At last (Sect. 5.3), the substitution terms for the variables will be infered.The subtrees
which differ over the segments represented by the variables in ˆtG are instantiations of the

32
E. Kitzelmann et al.
parameters in the recursive equation. For the single variable in our example we obtain
the trees:
succ(succ(0))
(1)
pred(succ(succ(0)))
(2)
pred(pred(succ(succ(0))))
(3)
Now a recurrence relation will be searched such that the instantiations in one segment
can be generated by instantiations in the preceding segment in a recurrent way. This
results in the substitution term sub(x1, 1) = pred(x1), since for the instantiations in
the three segments it holds (2) = pred((1)), and (3) = pred((2)).
With our method we are able to fold initial trees for RPSs of substantially more com-
plexity, namely with a constant part in the main programs, with more than one recursive
equation, and with interdependent, switching and hidden variables in the equations. In
the following, we present the theory and methodology formally, concluding each section
with a theorem which backs up our approach.
5
Inducing a Subprogram
5.1
Segmentation
When we start with segmentation, the hypothesis is that there exists a set of tc equations
Gi with initial equation Gi(x1, . . . , xmi) = ti which explains a set of given initial trees
Tinit. The goal is to ﬁnd a set of possible recursion points Urec for such an equation Gi
which divides the initial trees into segments which correspond to the unfoldings of Gi.
Each equation of an RPS occurs in some context. For instance, the main program
might be a term t0 = G1([1, 2, 3]), that is, G1 is called in an “empty” context. Within
G1, another equation G2 might be called with in a term t′ = cons(42, G2(x)). In this
case, cons(42, . ) is the context of G2. In the following, we call a recursive equation
together with its context a sub-scheme. Consequently, for each recursive equation Gi,
a set of hypothetical recursion points Urec and a (possibly empty) set of sub-scheme
positions Usub must be determined.
Sub-scheme positions. The set of sub-scheme positions of an equation Gi is deﬁned
as Usub = {u ◦k ∈ti | ∃urec ∈Urec : u < urec, ̸ ∃urec ∈Urec : u ◦k ≤urec, ∃usp ∈
pos(ti, Gj) : i ̸= j and u ◦k ≤usp}. Sub-scheme positions in a program term indicate
the call of another subprogram in the subterm at a sub-scheme position. Moreover it
must hold, that the sub-scheme positions are the “deepest” positions in a program term
at which a call of a subprogram is possible wrt the condition of no nested program calls.
The Ωs in an initial tree give us a ﬁrst restriction for the choice of possible recursion
points, since each recursion point (and moreover each unfolding point constructed over
the recursion points) and also each sub-scheme position composed to an unfolding point
must lie on a path leading to an Ωin the initial tree. We say that an Ωis explained by the
recursion points and sub-scheme positions. It must hold that all Ωs in tinit are explained
in this way.
Method. The method is to search in the initial trees for possible recursion points. If a
position was found, the set of sub-scheme positions is determined by the yet unexplained

Inductive Synthesis of Functional Programs
33
Ωs. Such a pair (Urec, Usub) is called a valid hypothesis of recursion points and sub-
scheme positions. Up to now, we only regarded the structure of the initial trees. We now
regard additionally the symbols (i. e., the node labels) which lie between the root of
the initial trees and the so far infered recursion points. These symbols imply a special
minimal pattern of the body of the searched for subprogram which is deﬁned by means
of the function skeleton.
Deﬁnition 3 (Skeleton). The skeleton of a term t ∈TΣ∪{Ω}(X), written skeleton(t),
is the minimal pattern of t for which holds pos(t, Ω) = pos(skeleton(t), Ω).
Obviously it holds: t ≤Ωskeleton(t). The mentioned pattern is named tskel and
deﬁned as skeleton(tinit[Urec ∪Usub ←Ω]). As stated in the following deﬁnition,
tskel mustreiterateitselfateachunfoldingpointconstructedoverthecalculatedrecursion
points, since each unfolding point indicates an unfolding of the same recursive equation
Gi (see Lemma 1).
Deﬁnition 4 (Valid Segmentation). Let Uunf be the unfolding points constructed over
a set of possible recursion points Urec. The hypothesis (Urec, Usub) together with tskel
is called a valid segmentation of an initial tree tinit, if for all uunf ∈Uunf ∩pos(tinit)
holds: Given the set of all positions of Ωs in tinit|uunf which are above the recursion
points as U cut
uunf = {u | pos(tinit|uunf ◦u) = Ω, ∃urec ∈Urec with u < urec}, it holds
tskel[U cut
uunf ←Ω] ≤Ωtinit|uunf . (Urec, Usub) with tskel is called a valid recurrent
segmentation of tinit, if additionally it holds that: ∃urec ∈Urec : Urec ⊆tinit|urec.
If a hypothesis can be veriﬁed by means of tskel, then the trees will be searched for
further possible recursion points, because the algorithm should detect a set of recursion
points as large as possible. This sequence of steps for inferring a valid segmentation
– (a) search for a further possible recursion point, (b) calculate the set of sub-scheme
positions, (c) calculate tskel and verify the hypothesis – will be repeated, until no further
possible recursion point can be found.
It is possible, that a valid segmentation doesn’t lead to an equation which explains the
initial trees together with a set of tc equations. Therefore, the presented method results
in a backtracking algorithm.
Theorem 1 (Segmentation Theorem). If a set of tc equations Gi with initial equation
Gi(x1, . . . xmi) = ti with recursion points Urec and sub-scheme positions Usub explains
an initial tree tinit for an initial instantiation β : {x1, . . . xmi} →TΣ, then (Urec, Usub)
together with tskel is a valid segmentation for tinit.
If Gi explains a set of initial trees Tinit, then (Urec, Usub) together with tskel is a
valid segmentation for all trees in Tinit and a valid recurrent segmentation for at least
one tree in Tinit.
Proof. LetbeΥi thesetofallunfoldingsofequationGi anduunf ∈Uunf∩pos(tinit)an
arbitrary unfolding point in tinit. If (case 1) Urec ⊂tinit|uunf , then follows U cut
uunf = ∅.
From the deﬁnition of unfoldings (Sect.2.3) and Lemma 1 follows tinit|uunf [Urec ∪
Usub ←Ω] = υuunf [Urec ∪Usub ←Ω]. From this and with deﬁnition of tskel follows
the assertion. For (case 2) Urec ̸⊂tinit|uunf the proof is analogous to case 1.
The second paragraph of the theorem follows directly from the just proved ﬁrst part,
the deﬁnition of recursive explanation (Sect.2.3) and Deﬁnition 4.

34
E. Kitzelmann et al.
If a valid recurrent segmentation (Urec, Usub) was found for a set of initial trees
Tinit and if Usub ̸= ∅, then induction of an RPS is performed recursively over the set of
subtrees at the positions in Usub. Therefore, for each u ∈Usub a new set of initial trees
will be constructed by including the subtrees at position u in each segment of each tree
in Tinit to T u
init.
5.2
Inducing a Program Body
When we start with inferring the body of subprogram Gi, a valid segmentation (Urec,
Usub) is given for Tinit. Moreover, for each sub-scheme position u ∈Usub a sub-
scheme Su = (Gu, tu
0) of Gi which explains the subtrees in T u
init is already induced.
That allows us to fold (the inverse process of unfolding) the initial trees to reduced initial
trees, denoted by Tred, which can be explained by one recursive equation (the initial
equation of the set of tc equations explaining Tinit, Sect.3.1).
Method. A subprogram body is uniquely determined by a valid segmentation:
Deﬁnition 5 (Valid Subprogram Body). For a valid segmentation (Urec, Usub) of Tinit
and the reduced initial trees tred ∈Tred, the term ˆtG ∈TΣ∪Φu∪G(X) is deﬁned as the
maximal pattern of all complete segments {tred|uunf [Urec ←G] | uunf ∈Uunf ∩
pos(trec), Urec ⊂trec|uunf } and is called valid subprogram body.
A segment is complete, if it includes all recursion points in Urec. The following
lemma states that this method results in a valid solution.
Lemma 2 (Maximization of the Body). Let E be a ﬁnite index set with indices e ∈
E. Let G(x1, . . . , xn) = tG be a recursive equation with X = {x1, . . . , xn}, tG ∈
TΣ∪Φ(X) and initial instantiations βe : X →TΣ for all e ∈E. Then it exists a
recursive equation G′(x1, . . . , xn′) = t′
G with X′ = {x1, . . . , xn′}, tG′ ∈TΣ∪Φ(X′),
unfolding points Uunf and initial instantiations β′
e : X′ →TΣ for all e ∈E, such that
L(G, βe) = L(G′, β′
e) for each e ∈E. Additionally, for each x ∈X′ it holds that the
instantiations which can be generated by G′ from β′
e, {β′
(e,uunf )(x) | e ∈E, uunf ∈
Uunf} do not share a common not-trivial pattern.
Proof. It can be shown that substitution terms exist which generate the instantiations
in the unfoldings of elements in L(G′, β′
e) from the initial instantiation β′
e. The idea
is to extend the body of equation G by the common pattern of the instantiations in the
unfoldings of the elements of L(G, βe). Then the initial instantiation will be reduced by
this pattern. It must be considered, that variables can be interdependent.
The maximal pattern of a set of terms can be calculated by ﬁrst order anti-uniﬁcation.
Only complete segments are considered. For incomplete segments, it is in general not
possible to obtain a consistent introduction of variables during generalization. The vari-
ables in the resulting subprogram body represent that subtrees which differ over the
segments of the initial trees. Identical subtrees are represented by the same variable.
Equivalence of sub-schemes. Because we handle induction of sub-schemes Su as
independent problem, we must insure that if for each u ∈Usub exists a sub-scheme Su
which explains the trees in T u
init and it exists a recursive equation which explains the

Inductive Synthesis of Functional Programs
35
resulting reduced initial trees Tred, then for arbitrary other sub-schemes S′u explaining
the trees in each T u
init, it exists a recursive equation which explains the resulting reduced
initial trees T ′
red. Such an “Equivalence of Sub-Schemes”-condition can be shown by
considering the parameters with the initial instantiations of two different schemes which
both explain the same initial trees. If they are constructed by maximizing the body, as
described, it holds, that the parameters and instantiations are equal.
Theorem 2 (Subprogram Body Theorem). If it exists a set of tc equations G′ with
initial equation G′(x1, . . . , xn′) = tG′ with recursion points Urec and sub-scheme
positions Usub which explains Tinit, then it exists a set of tc equations G with initial
equation G(x1, . . . , xn) = tG which explains Tinit and such it holds: tG[Urec ←G] =
ˆtG. (Proof follows from Def. 5, Lemma 2 and the fact, that two independently infered
sub-schemes are equivalent (see text).)
5.3
Inducing Substitution Terms
The subtrees of the trees in Tred which differ over the segments represent instantiations
of the variables var(ˆtG). The goal is to infer a set of variables X with var(ˆtG) ⊂X
and substitution terms for each variable and each recursion point in Urec, such that the
corresponding subtrees can be generated by an initial instantiation and compositions
(Sect.2.3) of the infered substitution terms. We are able to deal with quite complex
substitution terms. Consider the following examples:
f1(x, y) = if(eq0(x), y, +(x, f1(pred(x), +(x, y))))
(4)
f2(x, y, z) = if(eq0(x), +(y, z), +(x, f2(pred(x), z, succ(y))))
(5)
f3(x, y, z) = if(eq0(x), y, +(x, f3(pred(x), z, succ(y))))
(6)
A variable might be substituted by an operation involving other program parameter (4).
Additionally, variables can switch there positions (given in the head of the equation) in
the recursive call (5). Finally, there might be “hidden” variables which only occur within
the recursive call (6). If you look at the body of f3, variable z occurs only within the
recursive call. The existence of such a variable cannot be detected when the program
body is constructed by anti-uniﬁcation but only a step later, when substitutions for the
recursive call are inferred.
Method. The method for inferring substitution terms is based on the fact that instan-
tiations of variables in an unfolding (resp. a segment) can be generated by instantiating
the variables in the substitution terms with the instantiations of the preceding unfolding,
βuunf ◦ur(xj) = βuunf (sub(xj, r)) for an arbitrary variable and recursion point index.
Moreover – starting with u = λ – it holds that the substitution terms are inductively
characterized by:
sub(xj, r)|u =









xk
∀uunf ∈Uunf :
βuunf ◦ur(xj)|u = βuunf (xk)
f(sub(xj, r)|u◦1, . . . , ∀uunf ∈Uunf :
sub(xj, r)|u◦n)
node(βuunf ◦ur(xj), u) = f ∈Σ
with arity α(f) = n.
This characterization can directly be transformed into a recursive algorithm which
calculates the substitution terms, if we identify the instantiations in the unfoldings with

36
E. Kitzelmann et al.
the subtrees in Tred which differ over the segments. If for a variable in var(ˆtG) no
substitution term can be calculated, because at a position u it holds neither condition
(a) nor (b), then it will be assumed that a “hidden” variable (that is x ̸∈var(ˆtG)) is on
this position in the substitution term. The set of variables X will be extended by a new
variable x ̸∈X and then reversed application of condition (a) yields the instantiations
of the new variable in the unfoldings. The substitution terms for the new variable will
be generated as described.
Incomplete unfoldings. Because we allow for incomplete unfoldings in the initial
trees, it can occur that for a particular variable no represented subtree in an unfolding
can be found. In this case, the instantiation of the variable is undeﬁned in this unfolding
and will be set to ⊥. This can result in substitution terms which generate subtrees
(representing instantiations) of the subtrees in the preceding unfolding (as described
above), but don’t generate the same instantiations by applying the original deﬁnition
(Sect.2.3). Furthermore, it can occur that a substitution term is not unique wrt Deﬁnition
1. By means of the following deﬁnition, the infered substitution terms will be veriﬁed
wrt the mentioned problems.
Deﬁnition 6 (Valid Substitution Terms). Let be Xh a set of hidden variables with
Xh ∩var(ˆtG) = ∅, X = Xh ∪var(ˆtG) the set of infered variables. The set of all
substitution terms sub(x, r), x ∈X, r ∈R is called valid, if it holds:
Consistency: ∀te ∈Tred ∃βe : X →TΣ ∀xj ∈var(ˆtG), uunf ∈Uunf ∩te, u ∈
pos(ˆtG, xj) : te|uunf ◦u =⊥βe(sub∗(xj, uunf)).
Uniqueness: It not exists a variable x ∈X and a recursion point ur such that another
substitution term sub′(x, r) ̸= sub(x, r) exists which is consistent.
Minimality: Let be X′
h ⊂Xh a set of variables and X′ = X′
h ∪var(ˆtG): It doesn’t
exist a set of consistent and unique substitution terms for the variables X′.
Theorem 3 (Substitution Theorem). Let sub : X ×R →TΣ(X) with X = {x1, . . . ,
xn} be valid substitution terms. Let G(x1, . . . , xn) = tG be a recursive equation such
that it holds: (a) tG[Urec ←G] = ˆtG and (b) ∀r ∈R, xj ∈X : tG|ur◦j = sub(xj, r).
Then it holds: The set of tc equations G = Gu ∪{G(x1, . . . , xn) = tG} explains Tinit
substitution unique.
Proof. From the condition of consistence in Deﬁnition 6 and Theorem 2 follows di-
rectly that equation G explains Tred constructed over Tinit and the sub-schemes Su.
From the condition of uniqueness follows directly that this explanation is substitu-
tion unique (as postulated in Def. 3.3). Additionally, with Lemma 1 follows that
G = Gu ∪{G(x1, . . . , xn) = tG} explains Tinit and from the substitution unique-
ness of all sub-schemes Su and equation G follows that the explanation of Tinit by G is
substitution unique too.
6
Inducing an RPS
If an RPS can be induced from a set of initial trees using the approach presented here,
then induction can be seen as a proof of existence of a recursive explanation – given the
restrictions presented in Sect.3.2.

Inductive Synthesis of Functional Programs
37
Theorem 4 (Existence of an RPS). Let Tinit be a set of initial trees indexed over E.
Tinit can be explained recursively by an RPS iff:
1. Tinit can be recursively explained by a set of tc equations, or
2. ∀e ∈E : ∃f ∈Σ with α(f) = n, n > 0, and node(te, λ) = f, and ∀T k =
{te|k.λ | k = 1, . . . , n} it holds:
a) ∀t ∈T k : pos(t, Ω) = ∅, or
b) ∀t ∈T k : pos(t, Ω) ̸= ∅and it exists an RPS Sk = (Gk, tk
0) which recursively
explains the trees in T k.
(Proof in [Sch01].)
To inductively construct an RPS from a set of initial trees, ﬁrst a valid segmentation
for the initial trees is searched-for. If one is found, body and substitutions are constructed
as described above; if segmentation fails, recursively sub-schemes for the subtrees will
be induced, and at the end, the ﬁnal RPS will be constructed.A consequence of inferring
sub-schemes separately is that subprograms are introduced locally with unique names.
It can happen that two such subprograms are identical. After folding is completed, the
set of subprograms can be reduced.
7
Conclusion
We presented a new, powerful approach to folding of ﬁnite program terms, focussing on
the formal framework. The synthesis algorithms and a variety of examples can be found
in [Sch01]. The induction method described in this paper is able to deal with all (tail,
linear, tree recursive) structures which can be generated by a set of recursive functions
of arbitrary complexity. We already demonstrated the applicability of our approach to
control-rule learning for planning [SW00]. In future we plan to investigate applicability
to grammar learning and to enduser programming.
References
[LM91]
M. L. Lowry and R. D. McCarthy, editors. Autmatic Software Design. MIT Press,
Cambridge, MA, 1991.
[Sch01]
Ute Schmid. Inductive synthesis of functional programs – Learning domain-speciﬁc
control rules and abstract schemes. http://www.inf.uos.de/schmid/pub-ps/habil.ps.gz,
Mai 2001. unpublished habilitation thesis.
[SE99]
S. Schr¨odl and S. Edelkamp. Inferring ﬂow of control in program synthesis by example.
In Proc. Annual German Conference on Artiﬁcial Intelligence (KI’99), Bonn, LNAI,
pages 171–182. Springer, 1999.
[Sum77]
P. D. Summers. A methodology for LISP program construction from examples. Journal
ACM, 24(1):162–175, 1977.
[SW00]
U. Schmid and F. Wysotzki. Applying inductive programm synthesis to macro learn-
ing. In Proc. 5th International Conference on Artiﬁcial Intelligence Planning and
Scheduling (AIPS 2000), pages 371–378. AAAI Press, 2000.

A Symbolic Computation-Based Expert System
for Alzheimer’s Disease Diagnosis⋆
Bego˜na Herrero1, Luis M. Laita1, Eugenio Roanes-Lozano2, V´ıctor Maojo1,
Luis de Ledesma1, Jos´e Crespo1, and Laura Laita3
1 Depto. de Inteligencia Artiﬁcial, Facultad de Inform´atica, Universidad Polit´ecnica
de Madrid, Boadilla del Monte, 28660-Madrid, Spain
2 Depto. de ´Algebra, Universidad Complutense de Madrid, c/ Rector Royo Villanova
s/n, 28040-Madrid, Spain
3 Escuela de Enfermer´ıa, Universidad Complutense de Madrid
{laita,eroanes}@fi.upm.es
Abstract. In this paper we summarize a method of construction of
a rule-based expert system (denoted RBES) for Alzheimer’s disease
diagnosis. Once the RBES is constructed, Symbolic Computation
techniques are applied to automatically both verify (that is, check for
consistency) and extract new knowledge to produce a diagnosis.
Keywords: Rule-based expert systems, diagnosis of Alzheimer’s disease,
ideal membership problem, Gr¨obner bases
1
Introduction
In this paper we summarize a method of construction of a rule-based expert
system (denoted as RBES) for Alzheimer’s disease diagnosis. The full RBES is
described in [6]1. After building the RBES, symbolic computation techniques are
applied to both automatically verify (that is, check for consistency) and extract
new knowledge to output a diagnosis.
RBES usually have two components: a “knowledge base”and an “inference
engine”. In this article, the knowledge base and the inference engine are, respec-
tively, symbolically expressed and symbolically implemented using the computer
algebra language CoCoA [4]2. We use the 3.0b MSDOS version of CoCoA be-
cause, even though the Windows version [14] is more user friendly, it appears to
be less eﬃcient.
⋆Partially supported by projects TIC2000-1368-C03-01 and TIC2000-1368-C03-03
(Ministry of Science and Technology, Spain).
1 This Master thesis (in Spanish) contains a large amount of information about the
illness, an explanation of the 343 rules entered, a glossary and a diskette with the
entire program.
2 CoCoA, a system for doing Computations in Commutative Algebra. Authors: A.
Capani, G. Niesi, L. Robbiano. Available via anonymous ftp from:
cocoa.dima.unige.it
J. Calmet et al. (Eds.): AISC-Calculemus 2002, LNAI 2385, pp. 38–50, 2002.
c
⃝Springer-Verlag Berlin Heidelberg 2002

A Symbolic Computation-Based Expert System
39
Our particular knowledge base consists of production rules, ADDI (additional
information given by the experts) and facts. Classic bi-valued logic will be used
in this system.
The “production rules” are, in this article, logical implications of the following
forms:
◦x[i] ∧◦x[j] ∧... ∧◦x[k] →◦y[l]
or
◦x[i] ∨◦x[j] ∨... ∨◦x[k] →◦y[l]
(or, possibly, a combination of ∨and ∧in the antecedent), where “◦” represents
the symbol “¬” or no symbol at all.
For example the ﬁrst rule of our system, R1, refers to memory disorder. It is:
x[1] ∧x[2] ∧x[3] ∧[4] →x[5] .
The most relevant “facts” are what are known as “potential facts”, which
are the literals (that is, variables or variables preceded by “¬”). These are on
the left-hand side of the production rules and never on the right-hand side.
For example the ﬁrst fact of our system, x[1], is “diﬃculty in remembering
what day it is” (the list of the potential facts can be found in section 4.2).
Potential facts allow “ﬁre” the rules. A rule is ﬁred when, given the literals
of its left-hand side, its right-hand side is obtained by the logical rule of modus
ponens (from α and α →β, to get β).
It is important to note that, in this paper, we consider the set of both po-
tential facts and their negations. But, in each case study (that is, each class
of patients w.r.t. the equivalence relation “his/her relatives have answered the
questions about the symptoms the same way and the results of the neurological
evaluation and laboratory tests are equal”), we consider one maximal consistent
subset of such a set of facts. “Consistent”, because a fact and its negation are
never included in any case study; “maximal”, because either each fact or its
negation must be included. Note that, depending on which maximal consistent
set of facts is used, diﬀerent rules are ﬁred, giving diﬀerent results.
Regarding the additional auxiliary information, denoted “ADDI”, these are
formulae that the experts judge should or must be taken into account.
Let us say that CoCoA requires all logical formulae of the RBES to be written
in preﬁx form. For instance, the preﬁx form of the ﬁrst formula above is:
IMP(AND1(AND1(AND1...(AND1(◦x[i],◦x[j]),...,◦x[k])...),◦y[l]).
AND1 (also OR1 in other formulae) are used instead of AND and OR, because
these last two words are reserved words in CoCoA.
Our inference engine proceeds as follows: ﬁrst, logical formulae are automat-
ically translated into polynomials and, second, “Gr¨obner bases” and “normal
forms” are applied to these polynomials (using CoCoA). A substantial part of
the background theory is the original work of a group of researchers to which
the authors belong [2,5,9,15].

40
B. Herrero et al.
The information about Alzheimer’s disease has been gathered from several
sources, mainly [3,12] and several experts in the ﬁeld. It has been coordinated by
the fourth author (MD and director of the Medical Informatics Research Group
at the Universidad Polit´ecnica de Madrid). Public information can be found on
the web.
2
The Alzheimer Knowledge Base
The knowledge base we have developed contains 343 production rules, grouped
in the following subsets:
(1) Clinical history and neuropsychological tests (production rules 1 to 54). For
example, production rule R6 (written in preﬁx form) is:
R6:=NF(IMP(AND1(AND1(AND1(AND1(NEG(x[12]),NEG(x[13])),
NEG(x[14])),NEG(x[15])),NEG(x[16])),NEG(x[17])),I);3
that translates the IF-THEN statement:
“If the patient experiences no problems in using machines or domestic ap-
pliances AND no problems in pursuing his/her preferred hobbies AND no
problem in dressing AND no problem in gesturing using hands and face AND
no problem in writing and drawing THEN the patient has no diﬃculty in
making controlled movements”.
(2) Neurological evaluation; subdivided in turn into:
(2.1) Cranial pairs (production rules 55 to 80).
(2.2) Reﬂexes (production rules 81 to 100).
(2.3) Motor system (production rules 101 to 120). For example, production
rule R119 (written in preﬁx form) is:
R119:=NF(IMP(OR1(OR1(OR1(OR1(x[160],x[163]),x[167]),x[169]),
x[172]),x[173]),I);
that translates the IF-THEN statement:
“If spinal column muscle injury exists OR extrapyramidal injury exists
OR spinal cord injury exists OR cerebellum injury exists OR psychogenic
disturbances exist THEN motor disturbance exists”.
(2.4) Sensitivity (production rules 121 to 122).
(2.5) Coordination (production rules 123 and 124).
(2.6) Normal or abnormal walking (production rules 125 and 126).
(2.7) Neurological evaluation (production rules 127 and 128).
(3) Laboratory tests; subdivided in its turn into:
(3.1) Nutritional deﬁcit (production rules 129 and 130).
(3.2) Hypothyroidism (production rules 131 and 132).
(3.3) Neurosyphilis (production rules 133 and 134).
(3.4) Hypercalcemia (production rules 135 and 136).
(3.5) HIV (production rules 137 and 138).
3 The notation NF(..., I); means “Normal Form, modulo the ideal I”. The ideal I.
will be speciﬁed later.

A Symbolic Computation-Based Expert System
41
(3.6) Hematology (production rules 139 to 272).
(3.7) Biochemistry (production rules 273 to 318). For example, production
rule R291 (written in preﬁx form) is:
R291:=NF(IMP(AND1(AND1(AND1(AND1(AND1(AND1(AND1(
NEG(x[266]),x[264]),x[268]),x[270]),x[273]),x[275]),x[277]),
x[279]),x[280]),I);
that translates the IF-THEN statement:
“IF the urea level is abnormal AND the glucose, cholesterol, uric acid,
creatinine, HDL-cholesterol, LDL-cholesterol and triglycerides levels are
all normal THEN Biochemistry results are normal”.
(3.9) Systematic analysis of urine (production rules 319 to 343).
For reasons of simplicity and eﬀectiveness, our inference engine studies each
one of these subsets of production rules separately, together with their respective
maximal consistent sets of facts and ADDIs.
The translation from the medical knowledge to logic is not one-to-one, as
usually happens in the medical ﬁeld. On the contrary, the translation of classes
of equivalent propositional formulae into classes of equal polynomials is one-to-
one [7].
3
Outline of the Algebraic Background of the Inference
Engine
The basic concepts and results on which the inference engine is based are summa-
rized next and explained in more detail in the Appendix. The full development
can be found in [2,5,9,15].
The inference engine proceeds as follows.
• First step: it translates production rules into polynomials. The translation
of the basic bi-valued logic formulae is:
¬x1
⇝
1 + x1
x1 ∨x2 ⇝x1x2 + x1 + x2
x1 ∧x2 ⇝
x1x2
x1 →x2 ⇝x1x2 + x1 + 1
• Second step: it applies a mathematical result, which relates the fact that any
piece of information, say α, follows from (more precisely, “is a tautological
consequence of”4) the facts, production rules and any other additional infor-
mation (ADDI) of a RBES, iﬀthe polynomial that translates the (negation
of the) above-mentioned piece of information belongs to a certain polynomial
ideal. For the sake of clarity and for eﬃciency reasons, this ideal is actually
the sum of three ideals I + L + N. I is the ideal generated by the polynomi-
als of the form xp
i −xi, the role of which is to simplify the exponents of the
4 A formula A0 is a tautological consequence of other formulae A1, A2, ..., Am iﬀwhen-
ever A1, A2, ..., Am are true, A0 is also true.

42
B. Herrero et al.
variables xi. L is the ideal generated by the polynomials that translate the
negations of the facts in some chosen maximal consistent set of facts. N is
the ideal generated by the polynomials that translate the negations of both
the production rules and the ADDIs.
The theorem says:
Theorem 1. A formula A0 of the language in which the RBES is expressed is
a tautological consequence, in any p-valued logic, where p is a prime number, of
a set of formulae {A1, A2, ..., Am} iﬀthe polynomial translation of the (negation
of) A0 belongs to the ideal generated in the quotient ring Zp [x1, x2, ..., xn] /I by
the polynomial translation of the (negations of) A1, A2, ..., Am, where I is the
ideal generated by the polynomials xp
1 −x1, xp
2 −x2, ..., xp
n −xn .
Corollary 1. In the context of the RBES mentioned above, A0 follows from a
certain maximal consistent set of facts, which polynomial translation (of their
negations) generate ideal L, and certain production rules and other additional
information, which polynomial translation (of their negations) generate ideal N,
iﬀ
pol(NEG(A0)) ∈I + L + N
in the ring Zp [x1, x2, ..., xn] .
The polynomial variables x1, ..., xn each correspond to the propositional vari-
ables contained in the RBES.
Two important steps can be performed thanks to this theorem:
(1) look for inconsistencies in the expert system
(2) extract new information from the information contained in the expert sys-
tem.
Let us detail them.
(1) Let us recall that a RBES is inconsistent if all formulae of the language of the
RBES are (tautological) consequences of a maximal consistent set of facts
and the information contained in the RBES (because, in particular, both a
formula and its negation, that is, a contradiction, would be consequences of
the RBES).
It can be proved from the main result above that inconsistency is expressed
by the algebraic fact that polynomial 1 belongs to the ideal generated by
the polynomials that translate the (negation of) facts, rules and ADDIs (the
ideal is the whole ring in this case). That is, the RBES is inconsistent if and
only if
1 ∈I + L + N .
Therefore, step (1) merely involves typing the following CoCoA command:

A Symbolic Computation-Based Expert System
43
GBasis(I+L+N);
(GBasis means “Gr¨obner basis”). If the output is [1], there is inconsistency
in the expert system.
Let us observe that, to assure that there are no inconsistencies in the expert
system this should be done for all maximal consistent set of facts.
(2) Let us just say that to extract information translated as, say, a formula α (of
the language in which the RBES is built), from the rules, ADDI and facts,
all that has to be done is to type:
NF(NEG(α), I+L+N);
(where NF means “Normal Form”). The output of this command is 0 iﬀα
follows from the information provided in I+L+N.
An introduction to Gr¨obner bases (GB) can be found in [16,1].
Other methods could be used to perform these tasks. For instance SAT-
solvers may be more eﬃcient in the bi-valued case. Even though, GB-based
methods also have advantages, e.g.:
– we wanted to choose a general tool for all systems (see section “Acknowl-
edgements” at the end). GB-based methods can be applied to multi-valued
logics (which is not the case for SAT-solvers)
– GB-based method allows to save time when adding a new polynomial.
Adding new polynomials to a set that is already a GB is faster in general
than starting the calculations from scratch.
4
CoCoA Implementation of the Expert System
4.1
Introduction
As advanced in Section 2, the 343 production rules of the Alzheimer RBES are
divided into three subsets:
(1) clinical history and neuropsychological tests
(2) neurological evaluation
(3) laboratory tests
These subsets are, in turn, subdivided into the subsubsets already listed in Sec-
tion 2.
Each of these subsubsets, when ﬁred using appropriate maximal consistent
sets of facts, gives rise to partial information on Alzheimer’s disease.
As the RBES is quite large, for reasons of space, simplicity and clarity, we
will deal in some detail with only the partial information that refers to clinical
history. This means dealing with 49 production rules, 23 potential facts (and
their negations) and one ADDI. This partial information leads to either a positive
answer- “the patient has cognitive disturbance”- or a negative one- “the patient

44
B. Herrero et al.
does not have cognitive disturbance”. This existence or non-existence of cognitive
disturbances is what we have called “diagnosis of the clinical history”, and is
expressed by variable x[74].
As the full veriﬁcation of such a RBES is a huge task, the program checks
for any inconsistency that could appear in the current process, alerting the user
if needed.
The information dealing with neuropsychological tests, neurological evalua-
tion and laboratory test results is treated similarly.
The diﬀerent partial information on clinical history, neuropsychological tests,
neurological evaluation and laboratory test results, makes up in turn, the facts
of a ﬁnal production rule that returns the diagnosis of the patient’s illness.
4.2
Clinical History
In the code below, comments are preceded by --.
The polynomial ring A with coeﬃcients in Z2 (that is, permitting coeﬃcients
0 and 1) and 318 variables (for the whole RBES) is declared ﬁrst:
A ::= Z/(2)[x[1..318]];
USE A;
Deﬁnition of the ideal I:
I:=Ideal(x[1]ˆ2-x[1],x[2]ˆ2-x[2],x[3]ˆ2-x[3],....,x[74]ˆ2-x[74],
...,x[318]ˆ2-x[318]);
Translation of the basic bi-valued logic formulae to polynomials:
NEG(M):=NF(1+M,I);
OR1(M,N):=NF(M+N-M*N,I);
AND1(M,N):=NF(M*N,I);
IMP(M,N):=NF(1+M+M*N,I);
The following is the list of the potential facts that appear in the 49 production
rules corresponding to clinical history (for the sake of space, only aﬃrmative facts
are included). Both these facts and their negations make up a list that is pre-
sented to family members of the patient who the doctors suspect has Alzheimer’s
disease. They should select one of the two alternatives for each symptom in the
list. That is, they must provide a “maximal consistent set of facts”.
F1:=x[1];
-- difficulty in remembering what day it is.
F2:=x[2];
-- difficulty in remembering what he/she has eaten.
F3:=x[3];
-- difficulty in remembering recent events.
F4:=x[4];
-- difficulty in learning new things.
F5:=x[6];
-- difficulty in finding the right words.
F6:=x[7];
-- mistakes when naming things.
F7:=x[8];
-- poor pronunciation.
F8:=x[9];
-- inability to read.

A Symbolic Computation-Based Expert System
45
F9:=x[10];
-- problems with verbal expressions.
F10:=x[12]; -- problems with using machines.
F11:=x[13]; -- problems with pursuing hobbies.
F12:=x[14]; -- problems with getting dressed.
F13:=x[15]; -- problems with making the right gesture.
F14:=x[16]; -- problems with writing.
F15:=x[18]; -- problems with recognizing common objects.
F16:=x[19]; -- problems with recognizing common smells.
F17:=x[20]; -- problems with recognizing people.
F18:=x[21]; -- mixing up hands.
F19:=x[23]; -- problems with cooking simple meals.
F20:=x[24]; -- problems with money use.
F21:=x[25]; -- problems with very simple mathematical operations.
F22:=x2[6]; -- alteration of planning capabilities.
F23:=x[71]; -- MMSE test score of less than 24.
The production rules referring to clinical history are included below (there are 49
production rules and 74 propositional variables). In the following code each rule
is assigned ﬁrst (R:=...), and is then shown (R;) and remarked upon afterwards
(--...):
R1:=NF(IMP(AND1(AND1(AND1(x[1],x[2]),x[3]),x[4]),x[5]),I);
R1;
-- Refers to memory disorder.
R2:=NF(IMP(OR1(OR1(OR1(NEG(x[1]),NEG(x[2])),NEG(x[3])),NEG(x[4])),
NEG(x[5])),I);
R2;
-- Refers to memory disorder.
R3:=NF(IMP(AND1(AND1(AND1(AND1(x[6],x[7]),x[8]),x[9]),x[10]),
x[11]),I);
R3;
-- Refers to aphasia (difficulty with verbal expression).
R4:=NF(IMP(OR1(OR1(OR1(OR1(NEG(x[6]),NEG(x[7])),NEG(x[8])),
NEG(x[9])),NEG(x[10])),NEG(x[11])),I);
R4;
-- Refers to aphasia.
R5:=NF(IMP(AND1(AND1(AND1(AND1(x[12],x[13]),x[14]),x[15]),x[16]),
x[17]),I);
R5;
-- Refers to apraxia (difficulty in coordinating movements)
...
...
R48:=NF(IMP(AND1(x[70],OR1(OR1(x[71],x[72]),x[73])),x[74]),I);
R48; -- Refers to disturbances of two or more cognitive functions.
R49:=NF(IMP(NEG(x[70]),NEG(x[74])),I); R49; -- Refers to
disturbances of two or more cognitive functions.
The ADDI says that cognitive disturbance needs to be corroborated by tests:
ADDI:=NF(NEG(Y(x[70],x[74])),I);
Suppose that the 23 facts have been aﬃrmatively answered when referring to
some patient. They form a maximal consistent set of facts, which gives rise to
the ideal L:

46
B. Herrero et al.
L:=Ideal(NEG(F1),NEG(F2),NEG(F3),NEG(F4),NEG(F5),NEG(F6),
NEG(F7),NEG(F8),NEG(F9),NEG(F10),NEG(F11),NEG(F12),
NEG(F13),NEG(F14),NEG(F15),NEG(F16),NEG(F17),NEG(F18),
NEG(F19),NEG(F20),NEG(F21),NEG(F22),NEG(H23));
The ideal for all rules and the ADDI of the clinical history is:
N:=Ideal(NEG(R1),NEG(R2),NEG(R3),...,NEG(R48),NEG(R49),NEG(ADDI));
Consistency checking:
G:=GBasis(I+L+N);
(remember that if the output is [1], which is not the case here, there would be
inconsistency).
We have implemented a simple program named CONSIST that checks the
ideal incrementally and underlines the ﬁrst rule that, when added, produces
inconsistency.
If the answer to NF(NEG(x[74]),I+L+N); is 0 (we assume that there are
no inconsistencies), x[74] is tautological consequence of the information in the
RBES, that is, cognitive disturbance supported by tests exists. Remember that
the existence or non-existence of cognitive disturbances is what was called “di-
agnosis of clinical history” above.
4.3
Production Rule for Final Diagnosis
Once (1) the clinical history and neuropsychological tests, (2) the neurological
evaluation and (3) the laboratory tests have been evaluated as shown in the
previous section for clinical history, a production rule can be applied leading to
the diagnosis. Its code is shown below. Note that this RBES will give Alzheimer’s
disease as a diagnosis only if there are no other simultaneous serious illnesses
with similar symptoms.
If (Clinical History=0) And (Depression=0)
And (Neurological-Evaluation=0) And (Nutritional-Evaluation<>0)
And (Hypothyroidism<>0) And (Neurosyphilis<>0)
And (Hypercalcemia<>0) And (HIV<>0) And (Hematology=0)
And (Biochemistry=0) And (Urine=0) And (EAProbable=0)
Then Alzheimer:=0
Else Alzheimer:=1 ;
End ;
We must remark that the assessment that “Alzheimer disease occurs under
the assumption that other simultaneous serious illnesses are not present”, is
not a trivial assertion. As in many cases in Medicine there are several illnesses
with similar symptoms that are diﬃcult to distinguish. The complete system
includes production rules that translate precise knowledge and is able to perform
this discarding of presence of other illnesses. These rules are based on complex

A Symbolic Computation-Based Expert System
47
tests: neurological tests, laboratory tests (for instance hematological: folic acid,
TSH, T4L, T3, VDRL, treponemic, HIV, VCM, HCM, CHCM), radiological
tests (ECG, CAT, NMR, SPECT, PET...).
5
Performance, Motivation, and Evaluation
The input to the expert system (i.e., which of the facts hold) are the clinical
history (including the answers of the family of the patient to the questions asked
by the system) and the results of the neurological tests, laboratory tests, radio-
logical test... The extraction of knowledge for each block of rules (e.g. to obtain
the partial diagnosis for each of the parts of the neurological evaluation -see sec-
tion 2-) takes a few seconds in a standard 1.1MHz 384 MB of RAM PC. When
all the blocks have been ﬁred, the ﬁnal diagnosis is obtained in a similar timing.
About the evaluation, the system is still a prototype. It has been reviewed
by three medical doctors (two of them specialized in degenerative illnesses).
Their opinion is positive, and they think that it could be a very useful tool for
family doctors, as the early detection of this illness is not always obvious for a
non-specialist. That was the main motivation to design this system.
Nevertheless a validation of the system through its use in medical practice is
needed (and is planned as the next step of its development).
6
Conclusion
We have summarized the construction of a RBES for diagnosis of Alzheimer’s
disease. Once the RBES has been constructed, symbolic computation techniques
were applied to automatically verify and extract new knowledge and output a
diagnosis. Both the knowledge base and the inference engine have been symbol-
ically expressed and implemented using the computer algebra language CoCoA.
As the full RBES is quite large (it contains 343 production rules), we have de-
tailed only the rules that lead to the particular partial information about the
illness which we have called “clinical history”.
This partial information, together with others (neurological evaluation and
laboratory tests), are in turn the antecedents of a set of ﬁnal production rules
that lead to a diagnosis. As illustration, one such ﬁnal production rule has been
considered by way of an illustration.
Acknowledgements. This new work by our research team is another medical
application of algebraic techniques. Our work in this ﬁeld began by studying ver-
iﬁcation and knowledge extraction in Coronary By-Pass Surgery Medical Prac-
tice Guidelines. It was possible thanks to the support received from the Spanish
Ministry of Health (FIS 95/1952) and the Ministry of Science and Technology
(DGES PB96-0098-C04) [10,11]. This was followed by the development of two
RBES for the detection of anorexia [13] and depression [8], respectively (both

48
B. Herrero et al.
of which were developed within a Spanish Ministry of Science and Technology
research project, TIC2000-1368-C03, which has supported this work too).
We would also like to thank the anonymous referees for their most valuable
comments.
7
Appendix
7.1
Introduction
• Let us detail how a polynomial is assigned to each logical formula. This is
achieved by assigning to each propositional variable Xi a monomial xi and
deﬁning, for each connective cj, a function:
fj : (Zp [x1, x2, ..., xn] /I)sj −→Zp [x1, x2, ..., xn] /I.
The symbol I represents the ideal generated by the polynomials xp
1−x1, xp
2−
x2, ..., xp
n −xn:
I =< xp
1 −x1, xp
2 −x2, ..., xp
n −xn >
As the process has has been published by the authors elsewhere [9,15], we
simply transcribe the ﬁnal expressions, for example, for the functions fj for
Kleene’s three-valued and modal logic. The letters q and r are variables that
range over the elements (polynomials) of Zp [x1, x2, ..., xn] /I. In this case
p = 3.
f¬(q) = (2 + 2q) + I
f♦(q) = 2q2 + I
f✷(q) = (q2 + 2q) + I
f∨(q, r) = (q2r2 + q2r + qr2 + 2qr + q + r) + I
f∧(q, r) = (2q2r2 + 2q2r + 2qr2 + qr) + I
f→(q, r) = (q2r2 + q2r + qr2 + 2q + 2) + I
The complexity of the expressions of the functions f→increase with the value
of p. for instance fj for p = 7 is:
f→(q, r) = (3q6r2 + 6q5r3 + 4q4r4 + 6q3r5 + 3q2r6 + 3q6r + 4q5r2 + 2q4r3+
2q3r4 + 4q2r5 + 3qr6 + 5q5r + 6q4r2 + q2r3 + 6q2r4 + 5qr5 + q4r + 2q3r2+
2q2r3 + qr4 + 4q3r + q2r2 + 4qr3 + 4q2r + 4qr2 + 5qr + 6q + 6) + I
• The functions fj translate the basic propositional formulae ¬Xi, ✸Xi, ✷Xi,
Xi ∧Xk,..., Xi ∨Xk, Xi →Xk into (classes of) polynomials. The next
deﬁnition determines a function θ that, interacting with the functions fj,
translates any propositional formula, in particular the rules and other items
of any RBS, into (classes of) polynomials.
PC(X1, X2, ..., Xn) represents the set of all well constructed propositional
formulae with the propositional variables X1, X2, ..., Xn.
θ : PC(X1, X2, ..., Xn) −→Zp [x1, x2, ..., xn] /I is a function from proposi-
tions to (classes of) polynomials, recursively deﬁned as follows:
θ(Xi) = xi + I, for all i = 1, ..., n.
θ(A) = fj(θ(A1), ..., θ(Asj)) if A is cj(A1, ..., Asj).

A Symbolic Computation-Based Expert System
49
• Each logical truth valuation of propositional variables, v, can be extended re-
cursively to a valuation of the propositional formulae in PC(X1, X2, ..., Xn),
denoted v′. For each v we can deﬁne the homomorphism v∗:
v∗: Zp [x1, x2, ..., xn] /I −→Zp
such that v∗(xi + I) = v(Xi) for i = 0, ..., n. It can be proved that for any
valuation v, v′ = v∗· θ .
Lemma 1. {0}+I = (
i=1,..,k ker(v∗
i ))∩(θ(PC(X1, X2, ..., Xn))), where k = pn
is the number of all valuations, the v′
is range over all possible valuations.
Lemma 2. Let A1, A2,...,Am, A0 ∈PC(X1, X2, ..., Xn). The following two as-
sertions are equivalent:
(i) for all valuations vi(i = 1, ..., k) such that v∗
i (θ(A1)) = v∗
i (θ(A2)) = ... =
v∗
i (θ(Am)) = 0 it follows that v∗
i (θ(A0)) = 0.
(ii) θ(A0) ∈< θ(A1), θ(A2), ..., θ(Am) > .
Let us remember Theorem 1:
A formula A0 is a tautological consequence of a set {A1, A2, ..., Am} of for-
mulae, in any p-valued logic where p is a prime number, if and only if
the polynomial translation of the negation of A0 belongs to the ideal gen-
erated in Zp [x1, x2, ..., xn] /I by the polynomial translation of the negations
A1, A2, ..., Am.
We can rewrite it in a more formal way:
Let A0, A1, ..., Am ∈PC(X1, X2, ..., Xn). The following assertions are equivalent:
(i) {A1, A2, ..., Am} |= A0,
(ii) f¬(θ(A0)) ∈< f¬(θ(A1)), ..., f¬(θ((Am)) > (in Zp [x1, x2, ..., xn] /I).
Proof. {A1, A2, ..., Am} |= A0 iﬀfor any v, v′(A1) = p −1, ..., v′(Am) = p −
1 implies v′(A0) = p −1 (remember that p −1 is the value “true”). This is
equivalent to the condition: (p −1) −v′(A1) = 0, ..., (p −1) −v′(Am) = 0 implies
(p −1) −v′(A0) = 0 which is equivalent to v′(¬A1) = 0, ..., v′(¬Am) = 0 implies
v′(¬A0) = 0.
This implication is equivalent to that, for any v,
v∗
i (θ(¬A1)) = 0, ..., v∗
i (θ(¬Am)) = 0 implies v∗
i (θ(¬A0)) = 0
which is equivalent to
v∗
i (f¬(θ(A1))) = 0, ..., v∗
i (f¬(θ(Am))) = 0 implies v∗
i (f¬(θ(A0)) = 0.
By the last lemma above, the last implication is equivalent to
f¬(θ(A0)) ∈< f¬(θ(A1)), ..., f¬(θ(Am) >.

50
B. Herrero et al.
References
1. V. Adams and P. Loustaunau: An Introduction to Gr¨obner Bases. Graduate Studies
in Mathematics 3. American Mathematical Society Press, Providence, RI, 1994.
2. J.A. Alonso and E. Briales: L´ogicas polivalentes y bases de Gr¨obner. In M. Vide
(ed.): Proceedings of the V Congress on Natural Languages and Formal Languages.
P.P.U. Press, Barcelona, 1989 (307-315).
3. American Psychiatric Association: DSM III-R, Manual diagn´ostico estad´ıstico de
los transtornos mentales. Masson, Barcelona, 1988.
4. A. Capani and G. Niesi: CoCoA User’s Manual (v. 3.0b). Dept. of Mathematics,
University of Genova, Genove, 1996.
5. J. Chazarain, A. Riscos, J.A. Alonso and E. Briales: Multivalued Logic and Gr¨obner
Bases with Applications to Modal Logic. Journal of Symbolic Computation, 11
(1991) 181-194.
6. B. Herrero: Desarrollo de un Sistema Experto para el Diagn´ostico del Alzheimer
usando CoCoA. Master thesis (advisor: Luis M. Laita), Facultad de Inform´atica,
Universidad Polit´ecnica de Madrid, 2002.
7. L.M. Laita, L. de Ledesma, E. Roanes-Lozano and E. Roanes-Mac´ıas: An Interpre-
tation of the Propositional Bolean ALgebra as a k-Algebra. IEﬀective Calculus. In
J. Calmet, J.A. Campbell (eds.): Integrating Symbolic Mathematical Computation
and Artiﬁcial Intelligence. Selected Papers of AIMSC-2. Springer-Verlag LNAI-958,
Berlin, 1995 (255-263).
8. L.M. Laita, G. Gonz´alez-P´aez, E. Roanes-Lozano, V. Maojo, L. de Ledesma, L.
Laita: A Methodology for Constructing Expert Systems for Medical Diagnosis. In:
J. Crespo, V. Maojo, F. Mart´ın (eds.): Medical data Analysis. Procs. of IMSDA
2001. Springer-Verlag LNCS-1933, 2001 (212-217).
9. L.M. Laita, E. Roanes-Lozano, L. de Ledesma, J.A. Alonso: A Computer Alge-
bra Approach to Veriﬁcation and Deduction in Many-valued Expert Systems. Soft
Computing, 3/1 (1999) 7-19.
10. L.M. Laita, E. Roanes-Lozano and V. Maojo: Inference and Veriﬁcation in Med-
ical Appropriateness Criteria. In J. Calmet, J. Plaza (eds.): Artiﬁcial Intelligence
and Symbolic Computation, Proceedings of AISC’98. Springer-Verlag LNAI-1476,
Berlin, 1998 (183-194).
11. L. M. Laita, E. Roanes-Lozano, V. Maojo, L. de Ledesma, L. Laita: An Expert
System for Managing Medical Appropriateness Criteria based on Computer Al-
gebra Techniques. Computers and Mathematics with Applications, 42/12 (2001)
1505-1522.
12. J.J. L´opez-Ibor (ed.): CIE10. Transtornos mentales y del comportamiento. De-
scripciones cl´ınicas y pautas para el diagn´ostico. Organizaci´on Mundial de la Salud
- Ed. Meditor, 1992.
13. C. P´erez-Carretero, L.M. Laita, E. Roanes-Lozano, L. L´azaro, J. Gonz´alez-Cajal,
L. Laita: A Logic and Computer Algebra Based Expert System for Diagnosis of
Anorexia. Mathematics and Computers in Simulation, 58/3 (2002) 183-202.
14. D. Perkinson: CoCoA 4.0 Online Help (electronic ﬁle), 2000.
15. E. Roanes-Lozano, L.M. Laita and E. Roanes-Mac´ıas: A Polynomial Model for
Multivalued Logics with a Touch of Algebraic Geometry and Computer Algebra.
Mathematics and Computers in Simulation, 45/1 (1998) 83-99.
16. F. Winkler: Polynomial Algorithms in Computer Algebra. Springer, Wien, 1996.

On a Generalised Logicality Theorem
Marc Aiguier1, Diane Bahrami1, and Catherine Dubois2⋆
1 Universit´e d’´Evry Val d’Essonne, CNRS UMR 8042, LaMI, F-91025 ´Evry, France
{aiguier, bahrami}@lami.univ-evry.fr
2 Institut d’Informatique d’Entreprise, CEDRIC, ´Evry, France dubois@iie.cnam.fr
Abstract. In this paper, the correspondence between derivability
(syntactic consequences obtained from ⊢) and convertibility in rewrit-
ing (
∗↔), the so-called logicality, is studied in a generic way (i.e.
logic-independent). This is achieved by giving simple conditions to
characterise logics where (bidirectional) rewriting can be applied. These
conditions are based on a property deﬁned on proof trees, that we
call semi-commutation. Then, we show that the convertibility relation
obtained via semi-commutation is equivalent to the inference relation ⊢
of the logic under consideration.
Keywords: Formal system, semi-commutation, abstract rewrite tree,
abstract convertibility relation, logicality
Topics: Term Rewriting, Reasoning , Integration of Logical Reasoning
and Computer Algebra
1
Introduction
A classical result due to Birkhoﬀensures that equational reasoning coincides with
convertibility in rewriting for equational logic. This property, named logicality,
is expressed by:
Γ ⊢t = t′ ⇐⇒t
∗↔Γ t′
(Γ : set of equations).
V. van Oostrom [9] has shown that this result could be extended to any sub-
equational logic (such as the rewrite logic [8]) and S. Kaplan [6] has shown
that it also held for conditional equational logic (this last result as well as new
ones about logicality of conditional rewrite systems can be found in [13]). We
show here that logicality can be extended to a larger class of logics. To achieve
this purpose, we study convertibility in rewriting in a generic way. We have a
proof-theoretic approach, in the sense that we use the underlying formal system
of logics to study rewriting. This comes from the observation that, for all log-
ics where logicality holds, the convertibility relation
∗↔each time deﬁnes proof
strategies which select proof trees equipped with a speciﬁc structure. Roughly
⋆This work was partially supported by the European Commission under WGs
Aspire (22704) and is partially supported by the French research program “GDR
Algorithmique-Langage-Programmation (ALP)”
J. Calmet et al. (Eds.): AISC-Calculemus 2002, LNAI 2385, pp. 51–63, 2002.
c
⃝Springer-Verlag Berlin Heidelberg 2002

52
M. Aiguier, D. Bahrami, and C. Dubois
speaking, these trees, that we will call rewrite trees, denote closures of basic
rewriting relations. Thus, proof trees that specify basic rewriting relations are
always above proof trees that specify closures (considering that the leaves are
at the top and the root at the bottom of the tree). For instance, in the mono-
sorted equational logic, a convertibility relation is obtained by closing any set of
equations Γ under substitution and context and then under transitivity.
The logicality result will hold if we can ensure that all statements of the form
Γ ⊢ϕ accept some rewrite trees as proof trees. This can be checked thanks to ba-
sic proof tree transformations produced from the property of semi-commutation
of some inference rules with other ones. For instance, in the mono-sorted equa-
tional logic, substitution semi-commutes (denoted by ⇝) with transitivity:
Subst
Trans
t=t′
t′=t′′
t=t′′
σ(t)=σ(t′′)
⇝
Trans
Subst
t=t′
σ(t)=σ(t′)
Subst
t′=t′′
σ(t′)=σ(t′′)
σ(t)=σ(t′′)
From the property of semi-commutation, we will then be able to divide the
inference rules into two disjoint sets, Up and Down, such that Up semi-commutes
with Down and the converse is not true. Therefore, proof trees resulting from
the composition of inference rules in Up will deﬁne basic rewriting steps, and
those in Down will be used to compose rewriting steps together.
We assume that the reader is conversant with the deﬁnitions of basic equational
logic and abstract rewriting as found in the introductory chapters of a textbook
on the subject such as [3]. The paper is organised as follows: in Section 2, we
recall standard notations about formal systems, deductions and proof trees. In
Section 3, we instantiate formal systems in order to deal with predicates. In
Section 4, we introduce the concept of semi-commutation and, from this, we show
how to deﬁne rewriting relations such that logicality holds. Section 5 proposes
as an example to study rewriting in distributive lattices.
2
Preliminaries
A formal system (a so-called calculus) S over an alphabet Ωconsists of a set F
of strings over Ω, and a ﬁnite set R of n-ary relations on F. It is denoted by
S = (F, R). The elements of F are usually called formulae and the relations of
R are called inference rules. Thus, a rule with arity n (n ≥1) is a set of tuples
(ϕ1, . . . , ϕn) of strings in F. Each sequence (ϕ1, . . . , ϕn) belonging to a rule r of
R is called an instance of that rule with premises ϕ1, . . . , ϕn−1 and conclusion
ϕn. It is usually written ϕ1 ... ϕn−1
ϕn
. A deduction in S from a set of formulae Γ
of F is any ﬁnite sequence (ψ1, . . . , ψm) of formulae such that m ≥1 and, for all
i = 1, . . . , m, either ψi is an element of Γ or there is an instance ϕ1 ... ϕn−1
ϕn
of a
rule in S where ϕn = ψi and {ϕ1, . . . , ϕn−1} ⊆{ψ1, . . . , ψi−1}. A theorem from
a set of formulae Γ in S is any formula ϕ such that there exists a deduction in S
from Γ with last element ϕ. This is usually denoted by Γ ⊢ϕ. Instances can be
composed to build proof trees. Thus, we obtain another way to denote deduction
of theorems in formal systems. Formally, a proof tree π in a formal system S is
a ﬁnite tree whose nodes are labelled with formulae of F in the following way: if

On a Generalised Logicality Theorem
53
a non-leaf node is labelled with ϕn and its predecessor nodes are labelled (from
left to right) with ϕ1, . . . , ϕn−1, then ϕ1 ... ϕn−1
ϕn
is an instance of a rule of S. A
proof tree π with root ϕ is denoted by π : ϕ and L(π) denotes the set of leaves
of π. Obviously, for any statement of the form Γ ⊢ϕ in a formal system S, there
is an associated proof tree π : ϕ whose leaves are instances of relations of arity
1 or formulae from Γ. We call any proof tree associated to the statement ∅⊢ϕ
a tautological proof tree.
Using a standard numbering of the tree nodes by strings of natural numbers, we
can refer to positions in a proof tree. Thus, given a proof tree π, a position of π
is a string w on IN which represents the path from the root of π to the subtree
at that position. This subtree is denoted by π|w. Given a position w in a proof
tree π, π[π′]w denotes the proof tree obtained from π by replacing the subtree at
position w by π′. When w is a leaf position of π such that π|w = ϕ and π′ : ϕ is
a proof tree, we use the expression π ·w π′ to denote the proof tree π[π′]w. This
operation is called composition of π and π′ on (leaf) position w. Two proof trees
π : ϕ and π′ : ϕ are equivalent w.r.t. a set of formulae Γ if and only if they both
are proof trees associated to the statement Γ ⊢ϕ.
3
Predicative Formal Systems
Rewriting necessarily deals with binary relations (e.g. equality [3], inclusion [7],
more general transitive relations [4,12,10], the ideal membership problem, etc.).
It can be constrained by other relations (such as the deﬁnedness predicate in the
partial logic - see example below). This leads us to consider logics where formulas
are of the form p(t1, . . . , tn) where p is a predicate name. Since we do not want to
impose constraints that are useless for the establishment of the logicality result,
the elements t1, . . . , tn do not necessarily belong to an inductively deﬁned set.
Deﬁnition 1. (Predicative formal system). A predicative formal system is
a triple P = (T, P, R) such that T is a set, P is a set of n-ary relations on T
and (F, R) is a formal system, with F the set of formulae deﬁned as follows :
F = {p(t1, . . . tn) | p ∈P ∧(t1, . . . tn) ∈p}.
Example 1. The Partial Conditional Logic
Let us deﬁne the predicative formal system for the many-sorted partial condi-
tional equational logic with deﬁnedness, total valuation and existential equality
(see [2]) and then study rewriting within it. First, we recall the basic notions and
notations of this logic. A signature Σ = (S, F, V ) contains a set S of sorts, a set
F of partial function names with arity in S+ and a S-indexed family V of sets
of variables. For every s ∈S, WΣ(V )s denotes the standard set of terms of sort
s over Σ, free with generating set V and WΣ(V ) denotes the set 
s∈S WΣ(V )s.
Given a term t in WΣ(V ), V ar(t) denotes the set of variables occurring in t.
Atoms are either equations t = t′ where t and t′ are terms of the same sort,
or formulae D(t) where t is a term. Semantically, t = t′ states that both sides
of the equality are deﬁned and denote the same value and D(t) states that t is

54
M. Aiguier, D. Bahrami, and C. Dubois
deﬁned, i.e., t necessarily yields a value when it is evaluated. A conjunction over
Σ is a formula of the form α1 ∧. . . ∧αn where, for 1 ≤i ≤n, αi is an atom.
The empty conjunction is denoted by ∅. Let us denote by ConjΣ the whole
set of conjunctions over Σ. A conditional formula over Σ is then any formula
of the form c ⇒α where c ∈ConjΣ and α is an atom. A substitution is an
S-indexed family of functions σs : Vs →WΣ(V )s. It is naturally extended to
terms, conjunctions and conditional formulae. If c is a conjunction and Γ a set
of conditional formulae, a substitution σ is c-deﬁned with respect to Γ if and
only if, for all x ∈Vs, we have Γ ⊢c ⇒D(σs(x)).
Given a signature Σ = (S, F, V ), we deﬁne the predicative formal system PΣ =
(TΣ, PΣ, RΣ) as follows:
– TΣ = WΣ(V );
– PΣ
= EΣ ∪DΣ where EΣ is the (ConjΣ × S)-indexed family {=c,s
}(c,s)∈ConjΣ×S of binary relations s.t. (t, t′) ∈=(c,s) iﬀt and t′ are terms
of sort s, and DΣ is the ConjΣ-indexed family {Dc}c∈ConjΣ of unary re-
lations on terms s.t. Dc = T.1 Thus, an equation t =(c,s) t′ (resp. Dc(t))
denotes the formula c ⇒t = t′ (resp. c ⇒D(t)), where t, t′ ∈WΣ(V )s.
Afterwards, we will forget the sort s and simply write =c rather than =(c,s)
when this does not bring about any ambiguity.
– FΣ is the set of all formulae of the form t =c t′ and Dc(t).
– Finally, RΣ is the set of inference rules generated from the following inference
rule schemata, where αc denotes either t =c t′ or Dc(t), C is a context (i.e.,
any term with a unique hole □) and the notation C[t] denotes the term
obtained by substituting the symbol □by t in C :
Reﬂexivity: x=∅x
Symmetry: t=ct′
t′=ct
Transitivity: t=ct′
t′=ct′′
t=ct′′
Strictness: Dc(f(t1,... ,tn))
Dc(ti)
Replacement: t=ct′
Dc(C[t])
C[t]=cC[t′]
Existential equality: t=ct′
Dc(t)
Tautology: αc
if α occurs in c
Substitution:
αc
σ(α)σ(c) where σ is a c-deﬁned substitution
Monotonicity:
αc
αc∧c′
Modus Ponens: αc ∧α′
α′
c
αc
4
Logicality
4.1
Predicates Appropriate for Rewriting
In a predicative formal system, statements of the form Γ ⊢p(t, t′) will be proved
by rewriting if there is an associated rewrite tree π : p(t, t′). Any binary predicate
having this property will be said appropriate for rewriting. These notions will
be deﬁned in this section.
Notation 1. We denote by π = (π1, · · · , πk, ϕ), with k ≥0, the proof tree
whose last inference rule is ϕ1,... ,ϕk
ϕ
and such that, for all i ∈{1, . . . , k}, πi : ϕi
is the subtree of π at position i (i.e. π|i = πi : ϕi).
1 Syntactically, we can write c ⇒D(t) for any term t ∈T

On a Generalised Logicality Theorem
55
Notation 2. Let S be a set of proof trees. We denote by S♯the closure of S
under the composition operation. Formally, it is the least set (according to the
set-theoretical inclusion) satisfying:
– S ⊆S♯;
– if π ∈S♯with π|w = ϕ and π′ : ϕ ∈S♯then π ·w π′ ∈S♯.
Deﬁnition 2. (Structured proof trees). Let P = (T, P, R) be a predicative
formal system and E ⊆P a non-empty set of binary predicates. Let UpE =
(Upp)p∈E and DownE = (Downp)p∈E be two families of sets of rule instances
such that for all p ∈E, every instance of R whose conclusion is of the form
p(t, t′) belongs either to Upp or to Downp. The set PrUpE > DownE is the least set
of proof trees (according to the set-theoretical inclusion) such that:
– Up♯
E ∪DownE ⊆PrUpE > DownE;
– Let p ∈E be a binary predicate, let
ϕ1 ... ϕn
p(t,t′)
be an instance of Downp
with n > 0, and let (πi : ϕi)1≤i≤n be n proof trees such that, if ϕi is
of the form p′(u, v) with p′ ∈E, then πi ∈PrUpE > DownE. Then, the tree
(π1, . . . , πn, p(t, t′)) belongs to PrUpE > DownE.
The set PrUpE > DownE contains the trees of Up♯
E, the trees of Down♯
E and the
trees described in ﬁgure 1.
⊆Up♯
E
⊆Up♯
E
⊆Down♯
E
Fig. 1. Trees belonging to PrUpE > DownE
Deﬁnition 3. (Semi-commutation). With the notations of Deﬁnition 2, UpE
semi-commutes with DownE if and only if for every p, p′ ∈E, and every proof
tree π of the form:
i′ ψ1 . . . i ϕ1...ϕn
p(t,t′) . . . ψm
p′(u, v)
where i ∈Downp, i′ ∈Upp′ and ψ1 . . . ψm are formulae, there exists an equiva-
lent proof tree π′ ∈PrUpE > DownE w.r.t. L(π).
When the semi-commutation property is satisﬁed, proof trees in PrUpE > DownE
are called rewrite trees.

56
M. Aiguier, D. Bahrami, and C. Dubois
Deﬁnition 3 calls for some comments:
– The sets UpE and DownE will be used to build the convertibility relation
(UpE for the basic relation and DownE for its closure).
– Deﬁnition 3 does not ensure unicity for the couple (UpE, DownE) (when
it exists). For instance, in the equational logic framework, many couples
(Up{=}, Down{=}) can be candidate. Let us suppose that Up{=} contains all
rule instances except one instance of the transitivity rule t1=t2
t2=t3
t1=t3
(which
is thus the only instance of Down{=}). Easily, we can show that all the
instances of symmetry, replacement and substitution rules semi-commute
with this instance (actually, they semi-commute with all instances of the
transitivity rule - see examples below). Moreover, we have:
t1=t2
t2=t3
t1=t3
t3=t4
t1=t4
⇝
t1=t2
t2=t3
t3=t4
t2=t4
t1=t4
.
Consequently, Up{=} semi-commutes with Down{=}.
Now, for many logics (anyway, all logics used in computer science or math-
ematics) the underlying inference relation ⊢is generated from a ﬁnite set of
inference rule schemata, that is, a single form with inﬁnitely many instantia-
tions. This allows to denote all the instances by a set of generic forms (up to
meta-variable renaming). We take advantage of these forms to give a choice
strategy for the two sets : we put all the instances of a same rule schema in
the same set (either UpE or DownE). This strategy is natural : this is the
way convertibility relations are built in the literature (even though the two
sets are not mentioned).
This strategy also makes the study of semi-commutation easier. Indeed, the
number of instances of a formal system is usually inﬁnite. Therefore, check-
ing the semi-commutation property between them can be a hard task. But
this property can be checked only by reasoning on the generic forms. We
will use this method in the two examples of the paper, but we have not
formalised the rule schemata because the theory would have been too heavy.
– Usually, tautologies are simply recognised on their syntactical structure. For
instance, in equational logic, tautologies are all equations of the form t = t.
Regarding conditional equational logic, tautologies are either of the form
t =c t or t =c1∧t=t′∧c2 t′. In such logics, proof trees denoting tautologies are
removed from the rewrite tree set. The underlying bidirectional rewriting
will then be closed under tautologies.
The semi-commutation property between instances of UpE and DownE gives
rise to basic transformation rules. They transform any proof tree only composed
of two instances (one from DownE and the other from UpE) into an equivalent
rewrite tree. Thus, if semi-commutation holds, there is one basic transformation
rule for each one of these trees. When the set of basic transformation rules is
terminating, it obviously allows to transform any proof tree into a rewrite tree.
Deﬁnition 4. (Appropriate for rewriting). With the notations of Deﬁni-
tion 3, E is said appropriate for rewriting if and only if there exists a couple

On a Generalised Logicality Theorem
57
(UpE, DownE) such that UpE semi-commutes with DownE and the application
of the resulting transformation rules terminates.
As an immediate consequence of Deﬁnition 4, we obtain:
Proposition 5. Let P = (T, P, R) be a predicative formal system and let E ⊆P
be a set appropriate for rewriting. For any p ∈E and any proof tree π : p(t, t′),
there exists a rewrite tree equivalent to π w.r.t. L(π).
Proof As E is appropriate for rewriting, the proof tree transformation rules
resulting of the semi-commutation property are terminating. Therefore, repeat-
edly applying these rules on any proof tree always terminates in a rewrite tree.
✷
However, termination cannot be ensured in general. New conditions must be
added. In next section, we deﬁne a terminating sub-case from two simple easy-to-
check conditions which generalise basic transformation rules obtained for usual
logics (anyway all logics for which the logicality result holds).
4.1.1
A Terminating Sub-case
Here, we give two simple conditions which ensure that any set E satisfying the
semi-commutation property is appropriate for rewriting (i.e. termination of basic
proof tree transformation rules holds).
Deﬁnition 6. (Distributive). With the notations of Deﬁnition 3, E is called
distributive if and only if there exists a couple (UpE, DownE) such that UpE
semi-commutes with DownE and the following conditions hold:
1. all instances ϕ1...ϕn
ϕ
∈UpE ∪DownE satisfy: ∀1 ≤i ≤n, ϕi ̸= ϕ;
2. for every proof tree transformation rule
ψ1...
ϕ1...ϕn
p(t,t′) ...ψm
p′(u,v)
→π resulting from
the semi-commutation property, π contains at least an instance of DownE.
Remark. The name “distributive” results from the fact that, for many logics,
semi-commutation is recognised as “distribution” of some inference rules over
other ones (see the two examples developed in this paper). But distribution
rules are simple sub-cases of Deﬁnition 6, Point 2..
The interest of distributive sets is that the semi-commutation property gives
rise to basic proof tree transformation rules which always terminate. This is
expressed by the following lemma:
Lemma 7. Any distributive set E is appropriate for rewriting.
Proof
With every predicative formal system P = (T, P, R), we can associate
the following multi-sorted signature ΣP = (S, Op):
– S = {sϕ | ϕ ∈F};
– Op = {cϕ :→sϕ | ϕ ∈F} ∪{fi : sϕ1 . . . sϕn →sϕ | i ϕ1...ϕn
ϕ
∈R}

58
M. Aiguier, D. Bahrami, and C. Dubois
Proof trees are then ΣP-ground terms. Therefore, basic proof transformation
rules resulting from the semi-commutation property can be transformed into
the following term rewriting system: with every proof tree transformation rule
i′ ψ1... i
ϕ1...ϕn
p(t,t′) ...ψm
p′(u,v)
→π, we associate the rewriting rule:
fi′(xψ1, . . . , fi(xϕ1, . . . , xϕn), . . . , xψm) →tπ
where xψj (resp. xϕk) with 1 ≤j ≤m (resp. 1 ≤k ≤n) is a variable of sort sψj
(resp. sϕk), and tπ is the ΣS-term obtained from π where any leaf ϕ has been
replaced in tπ by the variable xϕ of sort sϕ.
Then, E is appropriate for rewriting if the rewriting system deﬁned just
above is terminating. Let > be the partial order deﬁned on ΣP as fol-
lows: ∀fi
:
sϕ1 . . . sϕn
→
sϕ
∈
UpE, ∀fi′
:
sϕ′
1 . . . sϕ′
n
→
sϕ
∈
DownE,
fi
>
fi′. Obviously, > is well-founded. Therefore, the induced
lexicographic path order >lpo is a simpliﬁcation order on TΣS(V ). As E
is distributive, tπ is of the form fj(t1, . . . , tl) with j
∈
DownE. Thus,
fi′(xψ1, . . . , fi(xϕ1, . . . , xϕn), . . . , xψm) >lpo fj(t1, . . . , tl) results of the fact
that fi > fj and Point 1. of Deﬁnition 6.
✷
Example 2. The Partial Conditional Logic (continuation) Let us show that
the set EΣ is appropriate for rewriting. By Deﬁnition 4, this requires to study
the semi-commutation property between all instances of inference rules of PΣ,
and show that the resulting set of transformation rules is terminating. First,
we can notice that the partial conditional logic has a predicative formal system
deﬁned from a ﬁnite set of rule schemata. Then, deﬁning Up=c and Down=c for
any =c∈EΣ only requires to prove the following result :
Proposition 8. Replacement, Substitution, Monotonicity and Symme-
try semi-commute with Transitivity and Modus-Ponens, but not the con-
verse. Moreover, all resulting transformation rules satisfy Deﬁnition 6, Point
2..
Proof [(Sketch)] For lack of space, we cannot give the entire proof, which can be
found in [1]. Here, let’s only detail (as an example) the semi-commutation prop-
erty between monotonicity and modus-ponens. To help the reading, we use the
standard notation c ⇒t = t′ (resp. c ⇒D(t)) rather than t =c t′ (resp. Dc(t)).
The symbol ⇝denotes the transformation of a proof tree into an equivalent one.
Mono
MP
c∧t1=t2∧c′⇒t=t′
c∧c′⇒t1=t2
c∧c′⇒t=t′
c∧c′′∧c′⇒t=t′
⇝
MP
Mono
c∧t1=t2∧c′⇒t=t′
c∧t1=t2∧c′′∧c′⇒t=t′
Mono
c∧c′⇒t1=t2
c∧c′′∧c′⇒t1=t2
c∧c′′∧c′⇒t=t′
Notice that this is distributivity of monotonicity over modus-ponens.
✷
Modus-Ponens semi-commutes with Transitivity when it is juxtaposed on
the left premise of the Modus-Ponens rule. This property is no longer veriﬁed
on its right premise. Transitivity does not semi-commute with any other rule.

On a Generalised Logicality Theorem
59
Thus, for any =c∈EΣ, Up=c contains all the instances of Replacement, Sub-
stitution, Monotonicity and Symmetry, and Down=c contains all instances
of Transitivity and Modus-Ponens (with conclusions of the form t =c t′).
4.2
Convertibility Relations
Here, we deﬁne the basic (bidirectional) rewriting relations associated with a
set E appropriate for rewriting. Each relation is obtained by closing a set of
equations Γ under the instances of Up.
Deﬁnition 9. (Basic rewriting relations).
Let P = (T, P, R) be a predicative formal system equipped with a set E appro-
priate for rewriting. Let Γ be a set of formulae of P. For any p ∈E, ↔p
Γ is the
least binary relation on T (according to the set-theoretical inclusion) satisfying :
t ↔p
Γ t′
if and only if either p(t, t′) ∈Γ or there is an instance ϕ1...ϕn
p(t,t′) ∈Upp such that
– for all premises p′(u, v) ∈{ϕ1 . . . ϕn} with p′ ∈E we have u ↔p′
Γ v,
– and for all other premises ϕ, we have Γ ⊢ϕ.
Let us note ↔Γ the E-indexed family ↔Γ = {↔p
Γ }p∈E.
Be careful, ↔p
Γ does not mean at all that this relation is symmetric. It only
means that operational aspects are not considered, and then no direction of
rewriting is imposed. To deal with operational aspects of rewriting, one needs
to provide each binary relation p with a reduction relation >p (not necessarily
transitive) and two rewrite relations →p= p ∩>p and ←p= p ∩(>p)−1. When p
is symmetric we have: ←p= (→p)−1. However, this last point is not the concern
of the logicality result where rewriting is studied as a deduction mechanism.
Example 3. The partial conditional logic (continuation)
Given a set of conditional formulae Γ and a conjunction c ∈ConjΣ, ↔=c
Γ
is the
least binary relation on T satisfying the following clauses:
– if t =c t′ ∈Γ, then t ↔=c
Γ
t′;
– if t ↔=c
Γ
t′ and σ : V →WΣ(V ) is a c-deﬁned substitution w.r.t. Γ, then
σ(t) ↔
=σ(c)
Γ
σ(t′);
– if t ↔=c
Γ
t′ and C is a context such that Γ ⊢Dc(C[t]), then C[t] ↔=c
Γ
C[t′];
– if t ↔=c
Γ
t′ and c′ ∈ConjΣ, then t ↔=c∧c′
Γ
t′.
A more concise deﬁnition of each ↔=c
Γ
can be given. It is the result of the
study of semi-commutation between the rule schemata representing the instances
of Up=c. Indeed, it is easy to show that Substitution semi-commutes with
Replacement and Monotonicity (substitutions are homomorphisms) and that
Replacement semi-commutes with Monotonicity.
Thus, t ↔=c
Γ
t′ if and only if there exists a conditional equation u =c′ v in Γ, a
substitution σ, a conjunction c′′ ∈CΣ and a context C such that:

60
M. Aiguier, D. Bahrami, and C. Dubois
1. ∀x ∈V ar(u) ∪V ar(v), Γ ⊢Dc′(σ(x)),
2. c=σ(c′) ∧c′′,
3. Γ ⊢Dc(C[t]),
4. t=C[σ(u)] and t′ =C[σ(v)].
Deﬁnition 10. (Closure of rewriting steps). With the notations of Deﬁ-
nition 9, and given a rewriting relation ↔Γ , we deﬁne the E-indexed family
∗↔Γ = {
∗↔
p
Γ }p∈E of binary relations on T such that, for any p ∈E,
∗↔
p
Γ is the
closure of ↔p
Γ under instances of Downp.
In other words, ↔p
Γ ⊆
∗↔
p
Γ and, for any instance ϕ1 ... ϕn
p(t,t′)
∈Downp such that
– for each premise of the form p′(u, v) with p′ ∈E, we have u
∗↔
p′
Γ v,
– and for the other premises ϕi, we have Γ ⊢ϕi,
then t
∗↔
p
Γ t′.
As already explained above, tautologies are usually recognised on their syntacti-
cal structure, and then proof trees denoting them are removed from the rewrite
tree set. In this case, closure of rewriting steps are decomposed in two closures.
The ﬁrst is under proof trees of DownE (e.g. transitivity in equational logic).
The second closure is under tautologies (e.g. all equations of the form t = t in
equational logic). This last closure can be deﬁned in this generic framework as
follow:
0↔Γ = {(u, v) | ∃p ∈E, ∅⊢p(u, v)}.
From Deﬁnition 10, the following result holds:
Proposition 11. t
∗↔
p
Γ t′ iﬀthere exists a rewrite tree π : p(t, t′) with all non-
tautology leaves in Γ.
Proof
(⇒) We can even build this rewrite tree thanks to the deﬁnition of
∗↔
p
Γ . We
prove it by induction on the structure of
∗↔
p
Γ :
– If t ↔p
Γ t′, there is a proof tree π′ : p(t, t′) belonging to Up♯
p. Since all
proof trees of Up♯
p are rewrite trees (cf. Deﬁnition 2), so is π′ : p(t, t′).
– If t
∗↔
p
Γ t′, then, by Deﬁnition 10, there is a proof tree ϕ1,... ,ϕn
p(t,t′)
in Downp
such that, for all ϕi of the form p′(ui, vi) (p′ ∈E), we have ui
∗↔
p′
Γ vi
(less than k steps) and for the other ϕj, we have Γ ⊢ϕj. By induction
hypothesis, for all ϕi there is a single rewrite tree πi : ϕi, corresponding
to ui
∗↔
p′
Γ vi. Moreover, for all ϕj, there is a proof tree πj : ϕj. By
Deﬁnition 2, the tree obtained by replacing every ϕi by the rewrite tree
πi : ϕi and all ϕj by the tree πj : ϕj is still a rewrite tree.
(⇐) Three cases can occur :

On a Generalised Logicality Theorem
61
– π ∈Up♯
p.
Let ϕ be a leaf of π. By hypothesis, ϕ is either a tautology or an element
of Γ. Therefore, if ϕ = p′(u, v) with p′ ∈E, then u ↔p′
Γ v (Deﬁnition 9).
If ϕ is any other leaf, then either ∅⊢ϕ or Γ ⊢ϕ.
According to Deﬁnition 9, and since π ∈Up♯
p, we have t ↔p
Γ t′ and thus
t
∗↔
p
Γ t′ (Deﬁnition 10).
– π ∈Downp.
Let ϕ be a premise of π. Such as in the previous case, if ϕ = p′(u, v)
with p′ ∈E, then u ↔p′
Γ v, and thus u
∗↔
p′
Γ v (Deﬁnition 10). If ϕ is any
other leaf, then Γ ⊢ϕ. Thus, from Deﬁnition 10, t
∗↔
p
Γ t′.
– π = (π1 : ϕ1, . . . , πn : ϕn, p(t, t′)) such that:
- the instance ϕ1 ... ϕn
p(t,t′)
belongs to Downp,
- ∀i such that ϕi = pi(u, v) with pi ∈E, πi : ϕi is a rewrite tree.
Since ∀i πi : ϕi is a subtree of π, the non-tautology leaves of πi also
belong to Γ. Thus, by induction hypothesis, ∀πi : pi(u, v) such that
pi ∈E, we have u
∗↔
pi
Γ v. For the other premises ϕi, we have Γ ⊢ϕi.
Therefore, according to Deﬁnition 10, t
∗↔
p
Γ t′.
✷
Theorem 12. (Logicality.) Let P = (T, P, R) be a predicative formal system
equipped with a set E appropriate for rewriting. Let Γ be a set of formulae. For
any predicate p ∈E and any formula p(t, t′), we have:
t
∗↔
p
Γ t′ ⇔Γ ⊢p(t, t′)
Proof Follows from Proposition 5 and Proposition 11.
✷
5
Example: The Distributive Lattice Theory
Herein, we give the predicative formal system for distributive lattice [12]. This
example of logic, unlike the previous one, allows us to study bidirectional rewrit-
ing on a binary predicate which is not symmetric.
Signatures for this theory are any set Σ ∪{∧; ∨; , ; (; )} where Σ is a set of
function names and ∧(resp. ∨) is the function join (resp. the function meet) to
denote inﬁmum (resp. supremum). We suppose here that every function of Σ is
monotonic in all its variable positions, i.e. Σ is compatible (cf. [11])2. Let X be
a set of variables. Then, T is the set of lattice terms free with generating set X
in the class of all Σ ∪{∧; ∨}-algebras. Formulae are strings of the form t ≼t′
or t = t′ where t and t′ are lattice terms. Thus, P only contains the two binary
relations = and ≼. Finally, R is the set of instances generated from the standard
2 Without the monotonicity condition we must add, for each function f ∈Σ, the two
following rule schemata : Leibniz1
ti=t′
i
f(t1,... ,γ,... ,tn)≼t
f(t1,... ,γ′,... ,tn)≼t
Leibniz2
ti=t′
i
t≼f(t1,... ,γ,... ,tn)
t≼f(t1,... ,γ′,... ,tn)
with γ ̸= γ′ ∈{ti, t′
i}

62
M. Aiguier, D. Bahrami, and C. Dubois
rule schemata which denote both that the predicate = is a congruence and
that ∧and ∨are commutative and associative, in addition to the following rules:
Rest t=t′
t≼t′
Antisym t≼t′
t′≼t
t=t′
Trans t≼t′
t′≼t′′
t≼t′′
Lb t∧t′≼t
Ub t≼t∨t′
Glb t≼t′
t≼t′′
t≼t′∧t′′
Lub t≼t′′
t′≼t′′
t∨t′≼t′′
Dist t1≼t′
1∨t
t2∧t≼t′
2
t1∧t2≼t′
1∨t′
2
Subst
t p t′
σ(t) p σ(t′) with p ∈{=, ≼} and σ : X →T
Repl≼
ti≼t′
i
f(t1, ... , ti, ... , tn)≼f(t1, ... , t′
i, ... , tn)
We will see that the set P is appropriate for rewriting. As previously stated, for
the distributive lattice logic, both sets UpP and DownP are deﬁned from the
semi-commutation of some inference rules with others. All this is established by
the following result. Herein, we only give the statement for the rules describing
the behaviour of the binary relation ≼. The statement for the equality predicate
is identical to Proposition 8. We can establish that:
Proposition 13. Subst, Glb, Lub, Dist and Repl≼semi-commute with
Trans.
Antisym does not semi-commute with Trans. Thus, Up≼contains all the in-
stances of Subst, Glb, Lub, Rest, Dist and Repl≼and Down≼contains all
the instances of Trans ; Up= and Down= are deﬁned as in the previous example
(Section 4), except we add for Down= all the instances of the rule Antisym.
In the distributive lattice theory, given a set of formulae Γ, the relation ↔≼
Γ is
deﬁned as the closure of Γ under the application of the rules Subst, Glb, Lub,
Rest, Dist and Repl≼according to Deﬁnition 9.
Despite the tedious (but simple) proofs on semi-commutation of proof trees,
our method easily allowed to build a bidirectional rewriting relation for the
distributive lattice, satisfying the logicality property according to Theorem 12.
6
Conclusion
In this paper, we have given basic properties to characterise logics where rewrit-
ing can be used as a deduction mechanism. We have shown that rewriting is
equivalent to deriving in the underlying calculus of the logic. This is called
logicality and is based on a simple property of semi-commutation between in-
ference rule instances. This naturally led to deﬁne basic transformation rules
which allowed to transform any proof tree into a rewrite tree and then ensure
the logicality result. In addition of the two examples developed in this paper,
in [5] this generic framework has also been instantiated on the logic of special
relations developed in [10]. This logics is interesting because it has been deﬁned
as an extension of the usual algebraic logic where it is possible to specify some
generalisations of the Leibniz law between any binary relation (as transitivity or
typing) and combining them.

On a Generalised Logicality Theorem
63
An important research issue that we are investigating is to extend this ap-
proach in order to deﬁne, in a generic manner, the notion of rapid prototyping of
property-oriented speciﬁcations by using rewriting techniques. In this scope, we
are working on an adaptation of Knuth-Bendix completion in a generic way. This
mainly requires to axiomatise the usual notions of terminating, Church-Rosser,
conﬂuence, and local-conﬂuence, and retrieve standard theorems (mainly Lank-
ford and Newman’s theorems).
Acknowledgements. We especially thank Micha¨el Rusinowitch, Florent Ja-
cquemard, H´el`ene Kirchner and Claude Kirchner for constructive comments on
the idea developed in this paper. We also thank Jean-Louis Giavitto, Pascal
Poizat and Sandrine Vial for careful readings of the draft version of the paper.
References
1. M.Aiguier, D.Bahrami and C.Dubois, On the General Structure of Rewrite Proofs.
Technical report, University of Evry, 2001. ftp://ftp.lami.univ-evry.fr/pub/publi-
cations/reports/2001/index.html/lami 58.ps.gz.
2. E.Astesiano and M.Cerioli, Free Objects and Equational Deduction for Partial Con-
ditional Speciﬁcations. TCS, 152(1):91-138. Amsterdam: Elsevier, 1995.
3. F.Baader and T.Nipkow, Term Rewriting and All That. Cambridge University
Press, 1998.
4. L.Bachmair and H.Ganzinger, Rewrite techniques for transitive relations. 9th IEEE
Symposium on Logic in Computer Science, pp. 384-393, 1994.
5. F.Barbier, M´eta-r´e´ecriture : application `a la logique des relations sp´eciales. Master
thesis, University of Evry, 2001. Supervised by M. Aiguier and D. Bahrami (In
french), avalaible at http://www.lami.univ-evry.fr/∼fbarbier/recherche-fr.html
6. S.Kaplan, Simplifying Conditional Term Rewriting Systems: Uniﬁcation, Simpliﬁ-
cation and Conﬂuence. Journal of Symbolic Computation, 4(3):295-334. Amster-
dam: Academic Press, 1987.
7. J.Levy and J.Agusti, Bi-rewriting systems. Journal of Symbolic Computation,
22(3):279-314. Amsterdam: Academic Press, 1996.
8. J.Meseguer, Conditional rewriting logic as a uniﬁed model of concurrency. TCS,
96(1):73-155. Amsterdam: Elsevier, 1992.
9. V.van Oostrom, Sub-Birkhoﬀ. Draft, 13 pages, 18 December 2000, available at
www.phil.uu.nl/∼oostrom/publication/rewriting.html.
10. M.Schorlemmer, On Specifying and Reasoning with Special Relations. PhD thesis,
Institut d’Investigaci`o en Intel.lig`encia Artiﬁcial, University of Catalunya, 1999.
11. G.Struth, Knuth-Bendix Completion for Non-Symmetric Transitive Relations. Pro-
ceedings of the Second International Workshop on Rule-Based Programming
(RULE2001), Electronic Notes in TCS, 59(4). Elsevier 2001.
12. G.Struth, Canonical Transformations in Algebra, Universal Algebra and Logic.
PhD thesis, Institut f¨ur Informatik, University of Saarland, 1998.
13. T.Yamada, J.Avenhaus, C.Lor´ıa-S´aenz, and A.Middeldorp, Logicality of Condi-
tional Rewrite Systems. TCS, 236(1,2):209-232. Amsterdam: Elsevier, 2000.

Using Symbolic Computation in an Automated
Sequent Derivation System for Multi-valued
Logic
Elena Smirnova
Ontario Research Center for Computer Algebra
University of Western Ontario
London, Ontario, CANADA N6A 5B7
alena@orcca.on.ca
Abstract. This paper presents a way in which symbolic computation
can be used in automated theorem provers and specially in a system
for automated sequent derivation in multi-valued logic. As an example
of multi-valued logic, an extension of Post’s Logic with linear order is
considered. The basic ideas and main algorithms used in this system are
presented. One of the important parts of the derivation algorithm is a
method designed to recognize axioms of a given logic. This algorithm
uses a symbolic computation method for establishing the solvability of
systems of linear inequalities of special type. It will be shown that the
algorithm has polynomial cost.
1
Automated Theorem Provers and Automated Sequent
Derivation Systems
The main goal of any automated theorem prover is to derive some statement
from existing data or expressions, whose certainty is established because it is
an axiom or because it is proved in one of the previous steps. Sometimes one
wishes to verify whether a given statement can be derived from existing facts by
using speciﬁed rules. In this case we can construct a logic containing these rules
as rules of its sequent calculus, then present an input statement in the form of
a sequent of this logic, and then try to ﬁnd its derivation by using backward
deduction.
The system to be presented here is designed to construct the backward de-
duction of an input statement, given in the form of a sequent of classical or
multi-valued logic.
One of the most popular multi-valued logics is Post’s logic [1]. We will con-
sider Post’s logic, extended by comparisons of logical values of predicate for-
mulas, that allows us to compare the certainty of several facts or expression.
This logic is able to replace fuzzy and continuous logics in practice, since only
ﬁnite sets of rational numbers from a ﬁnite diapason are used. The calculus
of these logics may be applied to computer representation of knowledge. There
J. Calmet et al. (Eds.): AISC-Calculemus 2002, LNAI 2385, pp. 64–75, 2002.
c
⃝Springer-Verlag Berlin Heidelberg 2002

Using Symbolic Computation in an Automated Sequent Derivation System
65
may be another approach consisting in using even-valued Post’s logics for natu-
ral sciences and odd-valued Post’s logics (which include a paradoxical value) for
humanitarian and applied sciences [2] and [3].
2
Sequent Derivation in Post’s Logics Extended by
Logical Comparisons
2.1
Logical Values for Data Representation
For graded knowledge representation, data in this logic are represented by integer
or rational numbers from a given interval. Fix a natural number k and consider
one of two sets, either LZ = [−k, k] ∩Z or LQ = [−k, k] ∩Q as the set of logical
values for our logic.
All logical values that are greater than zero are considered as true. All logical
values less then zero, are false. When L contains zero, the logical value that is
equal to zero is named paradoxical (neither true or false).
Even-valued Post’s logics, applied for natural sciences, cannot contain the
logical paradoxical value. For this case we take a segment [−k, k]\0 and consider
one of sets LZ\{0} = [−k, k] ∩Z \ {0} or LQ\{0} = [−k, k] ∩Q \ {0}
For the general case, the set of logical values is noted simply as L.
2.2
Predicate Formulas and Sequents for the Representation of
Statements
Predicate formulas of this logic are used to represent extended expressions, com-
bining given facts or data by using negation, conjunction, disjunction, four-place
connective if B < A then C else D fi (called conditional expression), and quan-
tiﬁers.
The logical value of conjunction and disjunction are deﬁned by the minimum
and maximum of logical values of their arguments respectively. The operation
of logical negation corresponds to arithmetic negation, i.e., to unary minus. The
conditional expression is interpreted as in programming languages. Let the com-
parison sign ≺be one of the following types: ≤, <. A comparison sign is placed
between predicate formulas. For example p(x) ≤q(y). Such a formula is called a
logical comparison, or more brieﬂy comparison. We consider also the relation of
equality: p = q. Logical values of comparisons are deﬁned in the usual way (i.e.
in the classical two-valued logic).
A sequent is a chain of predicate formulas (called the members of the sequent),
beginning with the sign ”→” and with the members separated by commas. The
meaning of a sequent is a disjunction of its members. The formula representing
this disjunction is called an image formula of a sequent. For example, the image
formula of the sequent →F1, F2, . . . Fn is F1 ∨F2 ∨. . . ∨Fn.
The simplest sequents this logic are sequents containing only elementary
logical comparisons, i.e. formulas having the form (a < b) or (a ≤b), where a and
b are constants, predicate variables, or predicates variables with negation. This

66
E. Smirnova
type of sequent is called an elementary sequent. An example of an elementary
sequent is →(a < b), (p(x) ≤q(x)), (c ≤d), (q(z) ≤1).
2.3
Sequent Derivation, Theorems, and Axioms
A derivation in a logic is a consequence of sequents, each of which represents an
axiom or is obtained from preceding sequents by applying one of the derivation’s
rules of this logic.
A sequent is derivable in a logic if it is the last sequent of some derivation
(i.e. it is possible to construct its derivation in this logic). A sequent derivable
in a given logic is also called a theorem of this logic.
A formula A, that does not contain any logical comparisons, is derivable in
our logic, if it is possible to derive the sequent →(0 ≤A).
To recognize whether a given sequent is a theorem of our logic, we have to
ﬁnd its derivation (i.e. after applying all possible rules, we must obtain axioms
only).
A sequent is an axiom of this logic if the image formula of its maximal
elementary subsequent is identical true.
In order to recognize whether a given sequent Γ is an axiom of a considered
logic we must ﬁrst build its elementary subsequent Γ ∗by erasing all members
containing logical binary connectives, external negations and equality signs, then
consider the image formula FΓ ∗of an obtained elementary sequent. If a formula
FΓ ∗is true for any values of its variables, then input sequent Γ is an axiom.
3
Axiom Recognition Algorithm
One of the main problems during automated sequent derivation is axiom recog-
nizing. If in step n of a derivation process the system obtains a sequent, that is
an axiom, it must not continue deduction of this sequent. Otherwise if it obtains
a sequent, containing only atomic formulas (meaning there is no rule to apply
in the next step) and if this sequent is not an axiom then the derivation process
can be stopped, because in this case the initial sequent can be derived in a given
logic.
This section presents an algorithm for axiom recognition in extended Post’s
logic.
Let Γ be a sequent of a Post’s logic extended with logical comparisons. In
the general case that sequent has the form
→((a1
1 < a2
1), . . . , (a1
k < a2
k), (a1
k+1 ≤a2
k+1), . . . , (a1
m ≤a2
m)), A1, A2, . . . At
(1)
where k, m, t ≥0, aj
i for i ∈{1, 2, . . . m}, j ∈{1, 2} is an atomic formula or
the negation of an atomic formula, and each of Ai is diﬀerent from elementary
comparison. Then the maximal elementary subsequent Γ ∗of Γ has the following
form
→((a1
1 < a2
1), . . . , (a1
k < a2
k), (a1
k+1 ≤a2
k+1), . . . , (a1
m ≤a2
m))
(2)
The formula-image of this elementary sequent Γ ∗is

Using Symbolic Computation in an Automated Sequent Derivation System
67
FΓ ∗= ((a1
1 < a2
1) ∨. . . ∨(a1
k < a2
k) ∨(a1
k+1 ≤a2
k+1) ∨. . . ∨(a1
m ≤a2
m))
(3)
As deﬁned above, to establish that the sequent Γ is an axiom it is necessary to
prove that the formula FΓ ∗is the identically truth. We suggest considering an
equivalent statement: Γ is an axiom if the negation of FΓ ∗is identically false.
It means that the logical value of ¬FΓ ∗is false for any values of the variables,
contained in this formula.
Let us construct the negation of FΓ ∗:
¬FΓ ∗= ¬((a1
1 < a2
1) ∨. . . ∨(a1
k < a2
k) ∨(a1
k+1 ≤a2
k+1) ∨. . . ∨(a1
m ≤a2
m)) =
¬(a1
1 < a12)& . . . &¬(a1
k < a2
k)&¬(a1
k+1 ≤a2
k+1)& . . . &(a1
m ≤a2
m) =
(4)
(a2
1 ≤a1
1)& . . . &(a2
k ≤a1
k)&(a2
k+1 < a1
k+1)& . . . &(a2
m < a1
m)
Now we must show that this formula cannot be satisﬁed for any values of the
variables {aj
i}1≤i≤m,1≤j≤2 from the set of logical values L. Or in other words,
the system of linear inequalities



















a2
1 ≤a1
1
...
a2
k ≤a1
k
a2
k+1 < a1
k+1
...
a2
m < a1
m
(5)
has no solution in the set L.
Theorem 1. The input sequent (1) is an axiom iﬀthe system (5) is unsolv-
able in the set L.
The proof of this theorem is evident from the preceding reasoning.
Example 1. The sequent →(x ≤y), (w < z), (y < x) is an axiom in extended
Post’s logic with the set of logical values L = [−100, 100], because the system



y < x
z ≤w
x ≤y
has no solution in this set.
Example 2. The sequent →(−x < y), (x < −x), (y < x) is an axiom in
extended Post’s logic with the set of logical values L = [−5, 5] ∩Z \ {0}, because
the system



y ≤−x
−x ≤x
x ≤y
has no solution in integer numbers from [−5, 5] \ {0}. But this sequent is not an
axiom of extended Post’s logic with the set of logical values L = [−5, 5] ∩Z,
because this system has the solution x = y = 0.

68
E. Smirnova
Thus the problem of axiom recognition for extended Post’s logic reduces to
the problem of establishing the insolubility of a system of linear inequalities.
To solve this problem we suggest using a symbolic computing method and an
algorithm based on this method these are described in the following section.
4
Method for Solvability Testing of Linear Inequalities
System of Special Type
Let us consider a system of linear inequalities S0









x1
1 ≺1 x2
1
x1
2 ≺2 x2
2
...
x1
m ≺m x2
m
where here each xj
i is either a constant, a variable or the opposite of a variable,
and ≺i∈{<, ≤} for 1 ≤i ≤m, 1 ≤j ≤2.
The problem to solve is to test the solvability of this system in the given
set L.
As we explore solvability of system in the set L ⊂[−k, k], in order to respect
variables values limitation, for each variable x we add inequalities : −k ≤x ≤k
and after that for each inequality x ≺y we add the opposite inequality −y ≺
−x (where ≺is the sign of strict or weak inequality). Then we process a new
”symmetric” system S, equivalent to input system S0.



























x1
1 ≺1 x2
1
−x2
1 ≺1 −x1
1
...
x1
i ≺2 x2
i
−x2
i ≺2 −x1
i
...
x1
n ≺n x2
n
−x2
n ≺n −x1
n,
where here each xj
i is either a constant, a variable or the opposite of a variable,
and ≺i∈{<, ≤} for 1 ≤i ≤n, 1 ≤j ≤2.
The (un)solvability of system (7) is establishing according to the following
theorem:
Theorem 2. The system S, having the form (7), is unsolvable iﬀat least
one of the following conditions is fulﬁlled.
1. The system S contains a cycle x1 ≺1 x2 ≺2 x3 ≺3 . . . ≺m−1 xm ≺m x1 for
some m ≥2 and at least one of inequalities ≺i is strict.
2. The system S contains a cycle x1 ≤x2 ≤x3 ≤. . . ≤xm ≤x1 for some
m ≥2 and

Using Symbolic Computation in an Automated Sequent Derivation System
69
1) this cycle contains two diﬀerent constants c1 and c2
2) or among the xi there are a non zero constant and a opposite pair
{−x, x}, where x is a variable
3) or this cycle does not contain any constant diﬀerent from zero, but it
contains a opposite pair {−x, x} or the constant zero and
a. the set of logical values L does not contain zero
b. or zero belongs to the set of logical values L and the system S1 which
is obtained from S by replacing all variables from that cycle by zero
is insolvable
4) or this cycle does not contain any opposite pairs, but it contains a unique
constant c, diﬀerent from zero, and the system S2, obtained from S by
replacing all variables from that cycle by this constant c is insolvable
5) or there no constant in this cycle neither opposite pair and the system S3
which follows is insolvable; S3 obtained from S by replacing all variables
from that cycle by a new variable xnew and all opposite them variables
by −xnew
3. The system S has no cycles but contains a chain x1 ≺x2 ≺x3 ≺. . . ≺xm
where x1 and xm and only them are constants and xm < x1
The following condition is considered only if L ⊆Z
4. The system S has no cycles but contains a chain x1 ≺1 x2 ≺2 x3 ≺3
. . . ≺m−1 xm where xi are pairwise distinct, x1 and xm and only them are
constants and the length of this chain measured as the number of signs ’¡’
strictly greater than following value
1) xm −x1 −1 if 0 ̸∈L and xmx1 < 0
2) xm < x1 in other cases.
Notice that the conditions 2.3.b, 2.4 and 2.5 let us reduce the initial system S
and iterating the test with the smaller systems S1, S2 or S3 gives a terminating
process.
4.1
Algorithm for Solvability Testing
The algorithm for solvability testing is based on veriﬁcation of the Theorem 2
conditions and lies to encoding of the initial system (7) into a ﬁnite oriented
graph.
For verify whether conditions of the Theorem 2 are satisﬁed , we suggest
constructing a graph G, associated with the system (7). The graph G is built as
follows. Let V is a set of (signed) variables, appearing in S, and C be the set of
constants appearing in the system (7). The set of vertices of graph G is V ∪C.
Edges of G are labelled by elements in {<, ≤}. The triple (x, ≺, y) is an edge in
G iﬀx ≺y is an inequality of the system (7).

70
E. Smirnova
Example. Let the system (7) is















0 ≤x
x < y
2 ≤−y
x ≤2
−2 ≤x
y < 2
then corresponding graph G is
Therefore the conditions of the Theorem 2 may be represented like graph
with following patterns
Pattern 1: The graph G contains a cycle with the edge, marked by sign of strict
inequality
Example: x ≤y ≤z < x.
Pattern 2.1: The graph G contains a cycle with two diﬀerent constants

Using Symbolic Computation in an Automated Sequent Derivation System
71
c ̸= c1
Example: x ≤3 ≤y ≤4 ≤x
Pattern 2.2: The graph G contains a nonstrict cycle with opposite pair {−x, x}
and non-zero constant
c ̸= 0
Example: −x ≤5 ≤x ≤−x
Pattern 2.3: The graph G contains a nonstrict cycle with opposite pair {−x, x}
or constant zero

72
E. Smirnova
Pattern 2.4: The graph G contains a nonstrict cycle with a unique constant
Pattern 2.5: The graph G contains a nonstrict cycle without any opposite pairs
or constants
Pattern 3: The graph G contains a path between constants c and c1 and c1 > c
Example: 8 ≤x < y < 3
Pattern 4 (considered only in case in which L ⊆Z): the graph G contains
a path between constants c and c1, let r is a number of edges in this path,
marked with sign ’<’ and c1−c < r−1, if c1c < 0 and 0 ̸∈L or c1−c < r otherwise
Example: 1 < x < y < 3

Using Symbolic Computation in an Automated Sequent Derivation System
73
An implementation of solvability test algorithm uses strongly connected com-
ponents [4] instead of cycles for a better eﬃciency.
Algorithm works as follow
– First compute the strongly connected components of graph G. If some com-
ponent satisﬁes condition 1, 2.1, or 2.2.a of Theorem 2 we are done.
– Otherwise, apply to each component satisfying condition 2.2.b, 2.3 or 2.4 the
corresponding modiﬁcation until we get a system S′ which associated graph
G′ is acyclic.
– Test whether G′ satisﬁes condition 3, or condition 4 if we are in the integer-
values case.
– If no condition is satisﬁed (graph G does not contain any considered pat-
tern) algorithm gives an answer that the input (7) has at least one solution,
because the conditions of the Theorem 2 are necessary and suﬃcient.
4.2
Complexity of Solvability Testing Algorithm
Now we can show that solvability of system (7) can be establish in polynomial
time.
Theorem 3(Un)solvability of a given system (7) with m inequalities and n
variables and constants, is computable in time O(mn)
Proof. Steps 1 and 2 use an algorithm for searching strongly connected
component [4] are computed in time O(m). Step 3 uses an algorithm for minimal
cost covering tree [5], with is computed in time O(mn).
4.3
Case When the Set of Logical Values Is Not Symmetric Around
Zero
Sometimes one wish to deal with a set of logical values, than is not symmetric
around zero. For example an interval [0,1] is used in many of multi-valued logics.
In the general case the set of logical values L = [a, b] ∩Q(Z), where a, b ∈Z.
To recognize axioms in such logics we suggest using the same algorithm for
system insolvability testing, as for symmetric the case. But the input system S
and the set of logical values L need a transformation to make the input conform
to the requirement of the previous case.
The following transformation suﬃces
1. The new set of logical values is L′ = [−k, k] ∩Q(Z), where
k =





b −a
2
,
if L = [a, b] ∩Q
b −a + 1
2

, if L = [a, b] ∩Z
2. The input system S is transforming using the following formula :
x′ = x −δ(a, b, x)

74
E. Smirnova
where x is a variable or constant of the initial system S, x′ is a member of
the new system S′ corresponding to x and the shift function is deﬁned as
δ(a, b, x) =





(a + b)
2
,
if L = [a, b] ∩Q or L = [a, b] ∩Z and 2|(b −a)
a + b
2
−1
2 · sgn

x −a + b
2

, if L = [a, b] ∩Z and 2 ̸ |(b −a)
In the case in which logical values are rationals or integers from an interval
[a, b], when the diﬀerence (b −a) is even, we just make a parallel shift of the
system, but in case of integer values when (b −a) is odd, we must perform a
non-parallel linear transformation, as shown in Figure 1.
Fig. 1. Transformation of nonzero symmetric set [3, 8] ∩Z to symmetric set [−3, 3] \
{0} ∩Z
5
Applications
The logic considered here, proposed by Kossovski [2], is only one example of
a multi-valued ﬁrst-order logics with a ﬁnite number of values. Such logics are
included in the database of the automatic theorem prover for automated sequent
derivation in classical and non-classical logics.
The goal of this automated system is to give a general idea about Logics
and Artiﬁcial Intelligence. The prover is intended to teach students how to con-
struct derivation in non-classical logic and also it can be used as an application
for research in multi-valued logic. In comparison with other automatic theorem
provers, for example Deep Thought [6], the present system does not require the
input of huge tables for the valuation function. For instance, to describe a propo-
sitional multi-valued logic with ﬁve values {−2, −1, 0, 1, 2} and only three logical
connectives {¬, &, ∨}, a user of Deep Thought must enter 3 tables: one [5 × 1]
for negation and two [5 × 5] for conjunction and disjunction.
Using the system considered here, a user has to choose the kind of logic
to be used and to enter the set of logical values, for example L=[-5,5]. Af-
terwards the system will use its internal database of inference rules and ax-
iom recognition algorithms. The main ideas used for the design of this prover

Using Symbolic Computation in an Automated Sequent Derivation System
75
correspond to the approach described in [7]. Taking advantage of the special
native of the system of linear inequalities, used for axiom recognition in the
present logic, we were able to create a particular algorithm for solvability test-
ing, rather then having to the use simplex [8] or ellipsoid methods [9]. Demo
version of this automatic sequent derivation system is available in the Internet
at www.orcca.on.ca/MathML/Elena/software.
Acknowledgements. Ideas of considered logics and of data representation in it
are due to Dr. N.K. Kossovski. First formulation of Theorem 2 was proposed by
A.Tishkov. Proof of the Theorem 2 and 3 and also many ideas of implementation
of main algorithm of this system are due to Dr. Dani`ele Beauquier. Special thanks
to Dr. D.J. Jeﬀrey and Dr. Robert M. Corless for their kindness, support and
great help during preparation this paper.
References
[1] A.S. Karpenko, Multivalued logics. Logic and Computer. Issue 4, Moscow, Nauka,
1997.
[2] Kossovski N.K., Tishkov A.V. Logical theory of Post Logic with linear order.
TR-98-11, Department of Informatics University Paris-12. 9p.
[3] N.Kossovski, A. Tishkov. Gradable Logical Values For Knowledge Representation.
Notes of Scientiﬁc Seminars vol. 241 pp 135–149 St.Petersburg University 1996.
[4] R. Tarjan, Depth First Search and Linear Graph Algorithms, SIAM J. Computing
1 (1972), 146–160
[5] R. Tarjan, Data Structures and Network Algorithms, SIAM Philadelphia,(1983)
71–95
[6] Gerberding S. Deep Thought. University of Darmstadt, Dept. of Computer Sci-
ence, 1996.
[7] Lowerence C.Paulson. Designing a theorem Prover. Oxford, 1995. pp. 416–476.
[8] Michael J.Panik. Linear Programming: Mathematics, Theory and Algorithms.
Kluwer Academic Publishers, 1996. pp.125–139.
[9] L.G. Hachiyan, A polinomial algorithm in linear programming, Soviet Mathemat-
ics Doclady 20,(1979), pp. 191–194.
[10] Jorge Nocedal, Stephen J. Wright. Numerical Optimization, Springer, 1999.

The Wright ω Function
Robert M. Corless and D.J. Jeﬀrey
Ontario Research Centre for Computer Algebra
and the Department of Applied Mathematics
University of Western Ontario
London, Canada
{Rob.Corless,David.Jeffrey}@uwo.ca
Abstract. This paper deﬁnes the Wright ω function, and presents some
of its properties. As well as being of intrinsic mathematical interest, the
function has a speciﬁc interest in the context of symbolic computation
and automatic reasoning with nonstandard functions. In particular, al-
though Wright ω is a cognate of the Lambert W function, it presents a
diﬀerent model for handling the branches and multiple values that make
the properties of W diﬃcult to work with. By choosing a form for the
function that has fewer discontinuities (and numerical diﬃculties), we
make reasoning about expressions containing such functions easier. A
ﬁnal point of interest is that some of the techniques used to establish
the mathematical properties can themselves potentially be automated,
as was discussed in a paper presented at AISC Madrid [3].
1
Notation and Deﬁnitions
The Wright ω function is a single-valued function, deﬁned in terms of the Lam-
bert W function. Lambert W satisﬁes W(z) exp(W(z)) = z, and has an inﬁnite
number of branches, denoted Wk(z), for k ∈Z. See [4] for a discussion of why
the branches were chosen as they are. The Lambert W function is therefore mul-
tivalued. The Wright ω function1 is a single-valued function, deﬁned as follows:
ω(z) = WK(z) (ez)
(1)
where K(z) = ⌈(Im(z) −π)/(2π)⌉is the unwinding number of z. Note that the
sign of this unwinding number is such that ln(exp(z)) = z + 2πiK(z), which is
opposite to the sign used in [5], because we discovered after that publication
that the present sign choice leads to fewer minus signs in formulas.
1 This nomenclature has never, to our knowledge, appeared in print before. We use the
letter ω as a cognate of W, and we name this function after Sir Edward M. Wright,
for his works [12] establishing the complex branching behaviour of this function as a
tool for investigating the roots of y exp(y) = z (later called the Lambert W function)
J. Calmet et al. (Eds.): AISC-Calculemus 2002, LNAI 2385, pp. 76–89, 2002.
c
⃝Springer-Verlag Berlin Heidelberg 2002

The Wright ω Function
77
2
Graphs and Special Values
A graph of ω(z) for real z can be produced easily in Maple by the command
plot([y+ln(y),y,y=0.001..2]);. A section of the Riemann surface for ω(z)
can be plotted by the following commands:
omega := mu + I*nu;
x := evalc(Re(omega+ln(omega)));
y := evalc(Im(omega+ln(omega)));
plot3d( [x,y,mu], mu=-4..2, nu=-4..4,
colour=black, axes=BOXED,
style=PATCHNOGRID, labels=["x","y","mu"],
view=[-2..1, -5..5, -5..3],
grid=[200,200], style=POINT );
See Table 1 for special values.
Table 1. Special values of ω(z).
z
ω(z)
−∞
0
0
W0(1)
1
1
2 + ln 2
2
−1/3 + ln(1/3) + iπ −1/3 = W0

−1
3e−1/3
−1/3 + ln(1/3) −iπ
W−1

−1
3e−1/3
−1 + iπ
−1
−1 −iπ
−1
−2 + ln 2 + iπ
W0

−2e−2
−2 + ln 2 −iπ
−2 = W−1

−2e−2
∞
∞
2.1
Summary of Results of This Note
The main result is a clariﬁcation, using this new function, of results due originally
to Wright [12] and independently rediscovered in [11] and [9]. Although y = ω(z)
satisﬁes the equation (in this paper ln(z) is the principal branch of the logarithm
of z)
y + ln y = z ,
(2)
when z ̸= t ± iπ for t ≤−1, there should be a distinction made between the
solutions of the equation, and Wright ω. In other words, (2) is not a satisfactory
deﬁnition of ω.

78
R.M. Corless and D.J. Jeﬀrey
In addition to this basic point, we here present new branch point series (with
the correct closure), new asymptotic series (from the equivalent series for the
Lambert W function), and new proofs of the analytic properties of ω(z), using
properties of the unwinding number.
h
f
d
e
b
c
a
π
−π
g
z
–3
–2
–1
1
2
3
Fig. 1. The z-plane, showing the slit (equivalently, branch cut) we call the “doubling
line” (above) and its “reﬂection”, across each of which the Wright ω function is discon-
tinuous. Along both slits, the closure (indicated by short lines extending down from
the slits) is taken from below—clockwise around the branch points—to agree with the
closure of the unwinding number.
We here summarize some properties of ω, proved in [9]. First, equation (2) has
a unique solution, ω(z), for all z ∈C except on the line LD deﬁned by z = t±iπ
for t ≤−1. When z is on LD, the equation has precisely two solutions, these
being ω(z) and ω(z−2πi); we therefore call LD the “doubling line”. See Figure 1
and Figure 2. On the reﬂection of the doubling line, namely, the line deﬁned by
z = t −iπ, with t ≤−1, equation (2) has no solution at all2. Second, ω is an
analytic function of z except on the doubling line and its reﬂection; on these two
lines, ω(z) is discontinuous. This immediately gives the following.
2 Unfortunately, in the paper [6], we got this wrong—we missed the fact that there
was no solution on this line. Indeed, at that time, we hadn’t realized this function is
discontinuous there. Additionally, we were using the opposite sign for the unwinding
number, which made the formulas messier.

The Wright ω Function
79
Theorem: For all z ∈C and integers k,
Wk(z) = ω(lnk(z)),
(3)
where lnk(z) = ln z + 2πik. [This logarithmic notation is discussed further in a
later section.]
Proof. This holds at least provided z is not in the interval −exp(−1) ≤z < 0
and k = −1, which is the image in the domain of W of the critical doubling line
(and also the image of its reﬂection). If z is in the interval −exp(−1) ≤z < 0, and
k = −1, then we have instead that W0(z) = ω(ln |z|+iπ) since K(ln |z|+iπ) = 0,
and that W−1(z) = ω(ln |z| −iπ) since K(ln |z| −iπ) = −1. Phrasing this the
other way, we have
W0(z) = ω(ln z)
and
W−1(z) = ω(ln z −2πi) .
♮
d
a
b
c
f
e
h
g
w
–3
–2
–1
0
1
2
3
–2
–1
0
1
2
3
Fig. 2. The ω-plane, showing the images of doubling slit and its reﬂection. The negative
real ω-axis is not, per se, a branch cut (this is the range of the function) but it is a
branch cut of ω + ln ω, which is why that expression is not exactly the inverse function
for ω.

80
R.M. Corless and D.J. Jeﬀrey
2.2
Properties of ω
We group the properties into analytic properties and algebraic properties.
Analytic properties. Theorems and lemmas:
(i)
ω(z) is single-valued
(ii)
ω : C →C is onto C \ {0}.
(ii)(a) Except at z = −1 ± iπ, where ω(z) = −1, ω : C →C is injective; hence
ω−1 exists uniquely except at 0 and −1.
(iii)
See Figure 2.
ω−1(y) =



y + ln(y) −2πi
−∞< y < −1
−1 ± iπ
y = −1
y + ln(y)
otherwise.
(iv)
(a) ω is continuous (in fact analytic) except at z = t ± iπ for t ≤−1.
(b) For z = t ± iπ and t ≤−1, we have
(1)
ω(t + iπ−) = ω(t + iπ) = ω(t −iπ−)
(2)
ω(t + iπ+) = ω(t −iπ) = ω(t −iπ+)
(v)
(a) ω + ln ω = z ⇐⇒K(ω + ln ω) = K(z).
(b) K(ω + ln ω) = K(z) unless z = t −iπ, t ≤−1.
(vi)
If z ̸= t −iπ for t ≤−1, then ω(z) + ln ω(z) = z.
If moreover z ̸= t+iπ, t ≤−1, then this solution is unique; if z = t+iπ, t ≤−1,
then y = ω(t−iπ) is also satisﬁes y+ln y = z. There is no y such that y+ln y = z
if z = t −iπ.
2.3
Proofs.
(i)
The functions exp z, K(z) and Wk(z) (for each ﬁxed k) are single-valued.
Hence the composition WK(z)(exp z) is single-valued.
(ii) K(z) covers all of Z as z covers all of C, and the branches of W partition
the plane, except that −1 is hit twice: W−1(−1/e) = W0(−1/e) = −1.
Only W0(0) = 0, and 0 is the only point not in the range of ez; hence
there is no ﬁnite z such that ω(z) = 0, but no other points in the range are
missed.
(iii) (v) =⇒(iii) because ωeω = ez, and hence ln(ωeω) = ln ω + ω −2πiK(ω +
ln ω) = z −2πiK(z) and since K(ω + ln ω) = K(z) except on z = t −iπ for
t ≤−1, we have z = ω + ln ω for the “otherwise” case; the case y = −1
is by computation; and the case where z = t −iω, ω(z) ∈(−∞, −1) ⇐⇒
K(z) = −1 and direct computation from ωeω = ez ∈(−1/e, 0) gives z =
ω + ln(−ω) −iπ as claimed. Equivalently, z = ω + ln(ω).
(iv) (iii) =⇒(iv) because ω is the inverse of y →y + ln(y) except when −∞<
y ≤−1 when ω has a diﬀerent inverse. Moreover, y + ln y is continuous
except when y ≤0. Its derivative is 1 + 1/y, which is zero only if y = −1.
Therefore ω is continuous (analytic) except possibly when ω < 0. This is
precisely z = t ± iπ, t ≤1. Inspection shows that ω really is discontinuous
on z = t ± iπ for t < 1; but ω(t + iπ) = ω(t + iπ−) and ω(t −iπ) =

The Wright ω Function
81
ω(t −iπ+) are both continuous from below, because K(z) is. The fact that
ω(t + iπ−) = ω(t −iπ−) follows from the analyticity of W0(z) in |z| < 1/e.
(v)
(a) WK(z)(ez)eWK(z)(ez) = ez
= ω(z)eω(z) by deﬁnition. Taking logs,
ln(ωeω) = ln ez, or ω + ln ω −2πiK(ω + ln ω) = z −2πiK(z). Therefore,
ω + ln ω = z ⇐⇒K(ω + ln ω) = K(z).
(v)
(b) K(WK(z)(ez) + ln WK(z)(ez)) = K(z). K(a) can change only when a =
t + (2k + 1)π for k ∈Z, or when a is itself discontinuous. We distinguish
two cases, therefore:
(1) WK(z)(ez)+ln WK(z)(ez) can be discontinuous at discontinuities of K(z),
namely z = t + (2k + 1)π for k ∈Z, or when WK(z)(ez) < 0. We ignore
discontinuities of K(z) for the moment. WK(z)(ez) < 0 only when (i)
K(z) = 0 and ez < 0 ⇐⇒z = t + iπ, t ≤−1, or (ii) K(z) = −1 and
ez < 0 ⇐⇒z = t −iπ, t ≤−1. Both (i) and (ii) are discontinuities of
K(z) anyway.
(2) K(ω(z)+ln ω(z)) can be discontinuous when ω+ln ω = t+(2k+1)πi =⇒
ωeω = −et ⇐⇒ω(z) ⊆an image of R−under W. Therefore z ⊆a pre-
image of R−under ez.
But this is just z = t + (2k + 1)πi, which is a place of discontinuity of K(z).
Note that K is integral-valued. Therefore, if ω(z) is such that K(ω(z) +
ln(ω(z))) = K(z) for any z in a strip (2k −1)π < Imz ≤(2k + 1)π, where
ω + ln(ω) is continuous, then we have K(ω(z) + ln ω(z)) = K(z) everywhere
in that strip. Let us choose k ∈Z, and look at the pre-image of ω = 2kπi.
Then ω + ln ω = 2kπi + ln(2kπ) + iπ/2 and hence K(ω + ln ω) = k. Since
ω = WK(z)(ez) we have ωeω = ez and 2kπi · e2kπi = ez ⇐⇒ez = 2kπi;
moreover 2kπi ∈range WK(z), and therefore K(z) = k. Therefore
z = ln(2kπi) + 2kπi
= ω + ln ω.
This establishes that if ω(z) = WK(z)(ez), then ω + ln ω = z except
possibly on the edges of the strips z = t + (2k + 1)πi. Now we have
K(ω(z) + ln(ω(z))) = K(z) if (2k −1)π < Im(z) < (2k + 1)π, and
hence ω + ln ω = z. Note that ω(z) = WK(z)(ez) is continuous from
below as Im(z) →(2k + 1)π−. Therefore, provided that ω(z) ̸∈R−,
ω(z) + ln(ω(z)) will be continuous as Im(z) →(2k + 1)π−. Therefore, since
Im(ω(z) + ln ω(z)) = Im(z) for (2k −1)π < Im(z) < (2k + 1)π, we have
K(ω + ln ω) = K(z) even if Im(z) = (2k + 1)π by continuity:
lim
Im(z)→(2k+1)π−K(ω(z) + ln ω(z))
=
lim
Im(z)→(2k+1)π−K(z) .
Therefore K(ω(z) + ln ω(z)) = K(z) unless ω(z) < 0, and Im(z) = −iπ.
(vi) This now follows immediately.

82
R.M. Corless and D.J. Jeﬀrey
2.4
Corollary
Deﬁne z(k, θ) = x + i · (2k + θ)π. Then z(k + 1, −1) = z(k, 1) since x + i · (2k +
2 −1)π = x + i · (2k + 1)π, since K(x + i · (2k + θ)π) = k for −1 < θ ≤1. Since
Wk(ex+i(2k+θ)π) = Wk(ex+iπθ) = Wk(ex(cos πθ + i sin πθ)) ,
we have Wk(ex+iπθ) →Wk(−ex + i · 0+) as θ →1−, and
lim
θ→−1+ WK(z(k+1,θ))(ez(k+1,θ)) =
lim
θ→−1+ Wk+1(ex+i(2k+2+θ)π)
since K(x+i·(2k+2+θ)π) = k+1 for −1 < θ ≤1. Since Wk+1(ex+i·(2(k+1)+θπ)) =
Wk+1(ex+iπθ) = Wk+1(ex(cos πθ + i sin πθ)) we have
Wk+1(ex+iπθ) →Wk+1(−ex + i · 0−)
as θ →−1+. By continuity of ω, then, unless k = 0 or k = −1 and 0 > −ex > 1
Wk(−ex + i · 0+) = Wk+1(−ex + i · 0−) .
Alternative (direct) proof of (iv) (a).
Lemma : Wk(−ex + i · 0+) = Wk+1(−ex + i · 0−) unless −e−1 ≤−ex < 0 and
k = 0.
Proof .
Images of the lines y = t, x = constant < 0, are smooth curves under
ω(x + iy), by inspection, except if ω(x + iy) < 0. This is what we have to
prove. Can we deﬁne ez as a value on the Riemann Surface for W? Yes, except
when −e−1 ≤ez < 0, by placing it on the sheet with winding number K(z).
This is a bijection between the Riemann Surface for log and for W, except on
−e−1 ≤ez < 0. Once this is done, the cut’s images on the Riemann Surface can
obviously be moved at will. Since Wk(−ex + i · 0−) lies on the other side of the
cut, we have equality.
Algebraic properties.
– Derivatives and integrals:
dω
dz =
ω
1 + ω

ωn dz =



ωn+1−1
n+1
+ ωn/n if n ̸= −1
ln ω −1/ω
if n = −1
The derivative formula is valid except on the doubling line and its reﬂection,
when it is valid as a derivative in the real direction only. The integrals can be
veriﬁed directly by diﬀerentiation of both sides. The addition of the constant
term −1/(n + 1) to the integral of ωn is a trick due, in the case

xn dx, to
W. Kahan. Using this trick, the formula for limiting case n = −1 is a simple
limit of the formula for n ̸= −1.

The Wright ω Function
83
– Series about z = a, where a = ωa+ln ωa: the following (computed by Maple)
is the beginning of the series for ω which contains second order Eulerian
numbers.
ωa +
ωa
1 + ωa
(z −a) + 1
2!
ωa
(1 + ωa)3 (z −a)2
−1
3!
ωa (2 ωa −1)
(1 + ωa)5
(z −a)3 + 1
4!
ωa (6 ωa2 −8 ωa + 1)
(1 + ωa)7
(z −a)4
−1
5!
ωa (24 ωa3 −58 ωa2 + 22 ωa −1)
(1 + ωa)9
(z −a)5
+ 1
6!
ωa (120 ωa4 −444 ωa3 + 328 ωa2 −52 ωa + 1)
(1 + ωa)11
(z −a)6
+O((z −a)7)
The general term is [6]:
ω(z) =

n≥0
qn(ωa)
(1 + ωa)2n−1
(z −a)n
n!
(4)
where
qn(w) =
n−1

k=0
n −1
k

(−1)kwk+1 .
(5)
is deﬁned in terms of second order Eulerian numbers.
– Series about ∞: This series was originally due to de Bruijn, and Comtet
identiﬁed the coeﬃcients as Stirling numbers.
ω ∼z −ln(z) + ln(z)
z
+ 1
2
ln(z) (ln(z) −2)
z2
+ 1
6
ln(z) (−9 ln(z) + 6 + 2 ln(z)2)
z3
+ 1
12
ln(z) (3 ln(z)3 −22 ln(z)2 + 36 ln(z) −12)
z4
+
1
60ln(z)(−125 ln(z)3 + 350 ln(z)2 + 12 ln(z)4
−300 ln(z) + 60)/z5 + O( 1
z6 )
The general term is (translating from the Lambert W results of [2,7]) ω(z) =
z −ln z +

ℓ≥0

m≥0
cℓm
lnm z
zℓ+m
(6)
where cℓm = (−1)ℓ	
ℓ+m
ℓ+1

/m! is deﬁned in terms of Stirling cycle num-
bers [8]. This series converges for large enough z, outside the region bounded
by the doubling line and its reﬂection. The proof is unpublished. The series

84
R.M. Corless and D.J. Jeﬀrey
can be rearranged in several ways, following [9] and [6]: ω(z) =
z −ln z +

n≥1
(−1)n
zn
n

m=1
(−1)m
m!

n
n −m + 1

lnm z .
(7)
Using a new variable ζ = z/(1 + z), we get ω(z) =
z −ln z +

m≥1
lnm z
m!zm
m−1

p=0
(−1)p+m−1ζp+m
p + m −1
p

≥2
(8)
where the numbers in curly braces are 2-associated Stirling numbers. Using
Lτ = ln(1 −τ) = ln(1 −ln z/z) and η = σ/(1 −τ) = 1/(z(1 −ln z/z)) =
1/(z −ln z), series (83) and (84) from [6] become
ω(z) = z −ln z −Lτ
+

n≥1
(−η)n
n

m=1
(−1)m

n
n −m + 1
 Lm
τ
m!
(9)
and
ω(z) = z −ln z −Lτ
+

m≥1
1
m!Lm
τ ηm
m−1

p=0
p + m −1
p

≥2
(−1)p+m−1
(1 + η)p+m .
(10)
The series converge for large enough real z, though the detailed regions of
convergence are not yet settled. Curiously enough (10) is exact at z = 1 and
at z = ∞, and moreover if we truncate it to N terms it agrees with the N
term Taylor series expansion at z = e as well, making one think of ‘Hermite’
interpolation at 1 and at ∞. Convergence is rapid.
– Series about −∞: from the series W(z)
=

n≥1(−n)n−1zn/n!, for
| exp(z)| < exp(−1) we have
ω(z) =

n≥1
(−n)n−1
n!
enz
(11)
2.5
Branch Point Series for ω(z)
The Wright ω function has branch points at z = −1 ± iπ. The following series
obtain. Near z = −1 + iπ,
ω(z) = −

n≥0
an

i

2(z + 1 −iπ)
n
(1)

The Wright ω Function
85
where the double conjugation gives us the correct closure from below on t + iπ
for t ≤−1. Near z = −1 −iπ,
ω(z) = −

n≥0
an

−i

2(z + 1 + iπ)
n
.
(2)
In both cases an is given by the recurrence relation [10]
a0 = a1 = 1
ak =
1
(k + 1)a1

ak−1 −
k−1

i=2
iaiak+1−i

.
(3)
The derivation of these series from the results of [10] is straightforward, except
for the use of
√
z. We here verify that this construction, which is one of a family
of transformations modelled on some used by G.K. Batchelor, gives us the correct
closure. We know that ω(t + iπ−) = W0(−et) whilst ω(t + iπ+) = W1(−et), and
ω(t −iπ+) = W0(−et) whilst ω(t −iπ−) = W−1(−et). Putting z = t + iπ+ in

2(z + 1 −iπ) gives

2(t + 1 + i · 0+), for t ≈−1. If t + 1 ≥0 then we have
no branch cut to cross—this series will be continuous, therefore, along the line
t+1+iπ, t ≥−1. If t+1 < 0, we are on the branch cut. t + 1 + i · 0+ is t+1+i·0−,
and arg

2(t + 1 + i · 0−) = −π/2. Therefore arg

2(t + 1 + i · 0−) = +π/2,
and this means that the series (2) can be written
ω(z) = −

n≥0
an(ρ)n
and by inspection of the signs of the series for W−1(−et) and hence W+1(−et)
just above the branch cut, this is correct. [Here ρ =

−2(t + 1) > 0.] Next,
consider z = −1 + iπ−. A similar argument leads to the conclusion
ω(z) = −

n≥0
an(−ρ)n
which is the series for W0(−et) for t ≈−1, because its signs alternate. Consid-
eration of z = t −iπ+ and t −iπ−gives, for t + 1 < 0,
ω(z) = −
n≥0 an(−ρ)n z = t −iπ+
= −
n≥0 anρn
z = t −iπ−
and continuity if t + 1 ≥0.
Remark. The use of

(z −a) to represent a square root function with a closure
diﬀerent from the CCC closure, as explained by Kahan, is a useful tool in a
computer algebra setting. However, it relies on the designers to be sophisticated
enough to provide symbolic means of representing (and not over-simplifying)
these series, and the users to be sophisticated enough to know that
√
z ̸= √z on
the branch cut.

86
R.M. Corless and D.J. Jeﬀrey
3
Interpolating Wk(z)
Finally, we interpret equation (3) as an interpolation scheme for Wk(z). We note
that k need not be an integer in that equation; the geometric interpretation is
precisely that of a circular cylinder cutting the Riemann surface for W. Note
also that k = 0 and k = −1 are special, and not interpolated by this scheme.
We deduce that Wk(z) is, in some sense, analytic in k, except if −exp(−1) ≤
z < 0 and k = 0 or k = −1.
dWk(z)
dk
= d
dk ω(ln z + 2πik)
= 2πi
ω(ln z + 2πik)
1 + ω(ln z + 2πik) .
By the analytic properties of ω, this derivative is not continuous on
−exp(−1) ≤z < 0 at k = 0 or k = −1. Otherwise, indeed, Wk(z) is analytic in
k.
4
Why
Computer algebra is about expressiveness, and simplicity is power. There are an
essentially inﬁnite number of applications of the Lambert W function and its
cognates.
1. The Lambert W function provides the ﬁrst example of a function just outside
the standard body of Risch-like theory: its derivative is rational in x and W,
not polynomial. One cannot use the same theorems, but one can hope to use
similar methods, to establish its non-elementarity [1].
2. The Lambert W function is the simplest example of a root of an exponen-
tial polynomial; and exponential polynomials are the next simplest class of
functions after polynomials. Computer algebra systems have a real edge over
numerical systems (though not everyone knows it) in dealing with polyno-
mials; the next big area will be non-polynomials, starting with exponential
polynomials. This is the ﬁeld of Cylindrical Non-Algebraic Decomposition.
3. The Lambert W function is the ﬁrst nontrivial example of a multivalued
function. The trivial ones (ln and the inverse trigonometric functions) have
branching behaviour so simple that it doesn’t even need a notation: we
can say ln(z) + 2πik and not have to invent a new notation lnk(z) to do
so (though in fact we have introduced and used this notation—one can’t
use logk because the “log to the base k” interpretation would get in the
way—for conciseness and as the thin entering point of the wedge for more
complicated functions). The multivalued nature of W “stress tests” naming
conventions, numerics on branches, computer-aided analysis, and the results
of series computation. Right now, Maple knows the series for W0(z) about
the branch point z = −exp(−1), but it doesn’t know the series for W−1(z)

The Wright ω Function
87
or W1(z) about the same point, even though these series were all introduced
in the same paper [4]. We think that this is because the series are deﬁned
piecewise: for W−1 and W1, the series about the branch point have to deal
with the fact that the range is split by the branch cut, and so the series are
(radically) diﬀerent if Im(z) > 0 or Im(z) < 0; each branch of W has both
a Puiseux series and a Taylor series—about the same point! But diﬀerent
series apply above and below the branch cut. This remarkable behaviour
puts a signiﬁcant stress on the ability of series to express its answer to the
question series(LambertW(-1,x),x=-exp(-1)) (which it currently refuses
to answer).
4.1
Why Invent the Wright ω Function?
It is certain that for some applications, just the ordinary Lambert W function
will be superior—this new function cannot supplant the old. Bill Gosper did not
succeed in introducing his cognate of W (which he jokingly called “the Dilbert
Lambda Function”); Don Knuth has so far been unable to get action on our
promise to him to introduce the TreeT function into Maple (T(x) = −W(−x),
and this is more convenient for combinatorial applications). So why should we
bother with a new one?
In equation (1) we give the deﬁnition of the Wright ω function, in terms of
W and one new function, the unwinding number K(z), which we will be needing
anyway. So why not just use the right hand side of the deﬁnition and not bother
with a notation?
1. W is multivalued, but ω is single-valued.
2. Numerically evaluating ω(z) for large z by way of the deﬁnition (1) is like
driving from the south of London to the north of London via Waterloo3:
it’s possible (unless there’s freezing rain) but unless you have a reason to
be in Waterloo, it’s probably better to go directly. Less metaphorically, tak-
ing exp(z) for large z gives a signiﬁcant risk of overﬂow, and a signiﬁcant
restriction on the numerical range of z that we can do the computation for;
but W is like ln, and in some sense just undoes the exponentiation, making
it wasted eﬀort in any case. The asymptotics are that ω(z) ∼z −ln z + · · ·;
so we see just how wasted. This is not a theoretical consideration: Jon Bor-
wein has had to implement his version of ω precisely to avoid this overﬂow
diﬃculty in his convex optimization problems.
3. Numerically evaluating omega( -0.9 + I*Pi ) by way of the formula un-
covers a subtle diﬃculty: because ceil( (Im(z)-Pi)/(2*Pi) ) will do some
symbolic processing, it will compute K(z) exactly right, and cancel the sym-
bolic Pi. But exp(-0.9+I*Pi) is left alone, until the user calls evalf. Then
something awful happens: at 10 Digits, Pi rounds to something larger than
3 London, Ontario via Waterloo, Ontario, of course. That sentence reads quite diﬀer-
ently if you think of train travel in London, England, for example (thanks to Arthur
Norman for pointing that out)

88
R.M. Corless and D.J. Jeﬀrey
π; this then gives us a negative imaginary part on the order of roundoﬀin
the result of the call to exp. This is all explainable in terms of the Maple
model of ﬂoating-point arithmetic, but it’s a disaster nonetheless—one made
visible by the next step, the computation of W0(x −i · ε), which is on the
wrong side of the branch cut. The numerical value of W0(x −i · ε) is not
at all close to the value of W0(x + i · ε), and this discontinuity is spurious.
The ω function is continuous at this point. So: we should have a separate
routine for the numerical evaluation of ω that guarantees that we get conti-
nuity (where ω is continuous), because the deﬁnition combines discontinuous
functions in such a way that their discontinuities (mostly) cancel.
There are other advantages to using the Wright ω function directly.
1. In addition to being single-valued, ω is continuous (indeed analytic) for all z
not on the two half-lines z = t ± iπ for t ≤−1. It is discontinuous across
these lines.
2. The Wright ω function has a simpler Taylor series than the Lambert W
function does. Indeed, it is the series for the Wright ω function that leads to
nearly all the series given in [6].
3. The fabulously simple equation Wk(z) = ω(ln z + 2πik) = ω(lnk z) explains
the branching behaviour of W perfectly, once we understand the branching
behaviour of ω.
4. The solution of the equation y + ln y = z is given by
y =



ω(z)
z ̸= t ± iπ, t ≤−1
ω(z), ω(z −2πi) z = t + iπ, t ≤−1
nonesuch
z = t −iπ, t ≤−1
(12)
The paper [11] seems to be the ﬁrst to use this fact.
What are the disadvantages? Well, the principal one is that the counting
applications depend on the use of W (or, rather, TreeT) as a generating function.
There, the series at the origin is what is important. With this transformation,
we have moved this point to −∞. The series are still there—just less convenient.
And, that is what introducing this function is all about: convenience. We will
need to have all of these functions around—well, certainly TreeT, but probably
not Dilbert Lambda. Even Bill Gosper has mostly given up on that one.
5
Concluding Remarks
This paper presents a number of mathematical results describing the properties
of the function ω(z). These results have some intrinsic mathematical interest,
and they are written here for the ﬁrst time, and so in a technical sense the paper
contains novel results. However, the results are really interesting only because:
1. Without symbolic computation making the function’s deﬁnition, simpliﬁca-
tion rules, and numerical evaluation widely available, the function is merely
arcane.

The Wright ω Function
89
2. Discontinuity (along the branch cuts) is especially visible, and nontrivial, in
this function. Therefore it will make a good test case for reasoning about
complex-valued expressions.
3. The methods used to prove properties of ω are essentially old-fashioned
mathematics, not commonly seen in standard curricula, and may poten-
tially be automated. This is in the spirit of [3] and represents a potentially
interesting direction for future research.
Acknowledgements. The code for the numerical evaluation of ω(z) (which
will be discussed in a future paper) was scrutinized by Dave Hare. The colour
graph of the Riemann Surface for ω (not shown here, but used in the upcom-
ing Lambert W poster, was produced with a Maple program written by George
Labahn (getting the colours to come out continuous, while making Maple show
the discontinuity, is not trivial.) Jon Borwein and Bill Gosper provided motiva-
tion to look at ω. Our thanks also to Prof. John Wright (Reading & Oxford),
and his father Sir Edward Maitland Wright, for permission to use a picture of
Sir Edward on the poster of the Lambert W function.
References
[1] Bronstein, M., and Davenport, J. H. Algebraic properties of the Lambert W
function.
[2] Comtet, L. Advanced Combinatorics. Reidel, 1974.
[3] Corless, R. M., Davenport, J. H., David J. Jeffrey, Litt, G., and Watt,
S. M. Reasoning about the elementary functions of complex analysis. In Pro-
ceedings AISC Madrid (2000), vol. 1930 of Lecture Notes in AI, Springer. On-
tario Research Centre for Computer Algebra Technical Report TR-00-18, at
http://www.orcca.on.ca/TechReports.
[4] Corless, R. M., Gonnet, G. H., Hare, D. E. G., Jeffrey, D. J., and Knuth,
D. E. On the Lambert W function. Advances in Computational Mathematics 5
(1996), 329–359.
[5] Corless, R. M., and Jeffrey, D. J. The unwinding number. Sigsam Bulletin
30, 2 (June 1996), 28–35.
[6] Corless, R. M., Jeffrey, D. J., and Knuth, D. E.
A sequence of series
for the Lambert W function. In Proceedings of the ACM ISSAC, Maui (1997),
pp. 195–203.
[7] de Bruijn, N. G. Asymptotic Methods in Analysis. North-Holland, 1961.
[8] Graham, R. L., Knuth, D. E., and Patashnik, O. Concrete Mathematics.
Addison-Wesley, 1994.
[9] Jeffrey, D. J., Hare, D. E. G., and Corless, R. M. “Unwinding the branches
of the Lambert W function”. Mathematical Scientist 21 (1996), 1–7.
[10] Marsaglia, G., and Marsaglia, J. C. “A new derivation of Stirling’s approx-
imation to n!”. American Mathematical Monthly 97 (1990), 826–829.
[11] Siewert, C. E., and Burniston, E. E. “Exact analytical solutions of zez = a”.
Journal of Mathematical Analysis and Applications 43 (1973), 626–632.
[12] Wright, E. M. “Solution of the equation zez = a”. Bull. Amer. Math Soc. 65
(1959), 89–93.

Multicontext Logic for Semigroups of Contexts
Rolf Nossum1 and Luciano Seraﬁni2
1 Agder University College, Department of Mathematics,
Gimlemoen, N-4604 Kristiansand, Norway
Rolf.Nossum@hia.no
2 ITC-IRST, Centro per la Ricerca Scientiﬁca e Tecnologica,
Via Sommarive 18, I-38050 Povo, Italy
Serafini@itc.it
Abstract. A multicontext logic with algebraic structure is proposed,
where contexts are either primitive or composed from other contexts.
Composition of two contexts can support various intuitions: sequence
concatenation, set union, multiset union, etc.
A local models semantics for algebraic context composition is deﬁned,
with a corresponding deductive calculus containing multilanguage
bridge rules. Soundness and completeness results are proved for the
case of semigroups of contexts, i.e. where context composition is an
associative operation. Other properties of context composition, besides
associativity, are deﬁned by additional algebraic equations.
Keywords: Integration of Logical Reasoning and Computer Algebra,
Logic and Symbolic Computing, Reasoning
1
Introduction
The Multi-Context Systems (MCS) formalism for contextual reasoning was pro-
posed in [9] (under the name of Multi Language systems), and its semantics
and proof theory have been developed in a series of papers [10,8,18]. MCSs are
rich in vocabulary, having languages diﬀerentiated by context. They support the
integration between reasoning in context and annotation about context. Most
MCS deﬁned in the literature presume some sort of structure of the context
within which reasoning takes place, but here the richness varies a lot. In MCS
there is a relatively simple indexing scheme which identiﬁes context, and this has
been extended to a partial order in some cases. Previous works do not provide
a theoretical foundation for sets of contexts with a more complex structure.
However, in many applications, where contexts are used to represent pieces
of knowledge that are dynamically modiﬁed, combined, copied, etc, it is useful to
store (in the labels) the information about structural relations between context,
as for instance, the fact that a context is a copy of another, or that a context is
the union of other two diﬀerent contexts. For this purpose we have to reﬁne the
labeling mechanisms so that we allow, for instance, the label c ⊕d to denote a
context obtained by combining the two contexts c and d.
J. Calmet et al. (Eds.): AISC-Calculemus 2002, LNAI 2385, pp. 90–101, 2002.
c
⃝Springer-Verlag Berlin Heidelberg 2002

Multicontext Logic for Semigroups of Contexts
91
In this paper, we are proposing MCSs with an enriched context structure,
allowing contexts to combine into new composite contexts according to equa-
tionally speciﬁed patterns.
This paper is structured as follows: We start by giving two motivational ex-
amples, and then go on to introduce the algebraic notation and logical language
we are using. Then, we deﬁne a semantics for interpreting formulas labeled by
contexts, and a corresponding deductive calculus with inter-contextual deduc-
tion rules. Then a class of algebras called AFG algebras is introduced, and a
completeness proof for that class is carried out. Finally, a comparison is made
with some related work on formal models of contextual reasoning.
2
Partiality Motivates Algebraic Contexts
Predicates about the world are partial, both in the absolute sense that no known
theory covers everything in the universe, and also in the relative sense that
usually, many facts which could have been expressed in the theory at hand are
left unexpressed.
The term ‘context’ is used in a variety of senses in the literature, and we
point out two competing ones:
In the philosophy of language, ‘context’ has been used to denote the total
state of aﬀairs which applies to an utterance being interpreted, while a projection
onto selected facets of reality has been called an ‘index’ [13,16].
This is contrast to emergent terminology in AI, where ‘context’ is almost
invariably used to denote a partial state of aﬀairs, and where the idea of a
‘most general context’, i.e. the context representing the total state of aﬀairs, is
sometimes denounced [14].
Without taking a metaphysical stand, we shall proceed to deal with represen-
tations of partial states of aﬀairs, and refer to such representations as contexts.
For the purposes of this paper, a context is either a primitive entity c (com-
pare the ‘micro-contexts’ of [12,11]), or a composite entity x ⊕y obtained by
combining other contexts x and y.
Whenever chunks of context combine into a larger joint context, issues of
partiality, granularity, and speciﬁcity arise:
– what is the language of the joint context?
– what is true in the joint context?
– is one way of forming a joint context equivalent to another way?
– how do we move from one composite context to another?
In [2] it is suggested that contextual reasoning patterns come in three broad
categories: localised reasoning, shifting, and push/pop. Localised reasoning is
conﬁned to one speciﬁc context, and shifting exchanges one context for another
according to intercontextual rules. The third category, push/pop, includes pat-
terns of reasoning where progression is from formulas asserted in one context to
formulas asserted in an incrementally augmented/depleted context.

92
R. Nossum and L. Seraﬁni
We propose to take an algebraic look at the operation of incrementally adding
information to a context, or combining an existing context with another. Let us
illustrate:
Example 1 In this example, a context is deﬁned by weather reports gathered
from meteorological oﬃces at airports. One important parameter for air traﬃc
is horizontal visibility on the ground.
In order for a scheduled ﬂight to depart on time, it is necessary that certain
weather minima are fulﬁlled, such as suﬃcient horizontal visibility for take-oﬀ
and landing at the departure and destination airports.
A pilot planning a ﬂight from Moscow via Paris to Washington must take
into account three weather reports. Let us denote the contexts of local weather
reports from each town by Mo, Pa, Wa, respectively. Beginning in context Mo,
the pilot learns about Pa, and forms an accumulated context that we denote by
Mo ⊕Pa
Looking up the weather in Washington, this context is augmented further to
(Mo ⊕Pa) ⊕Wa
In this example, the order in which weather reports are looked up does not
matter:
(Mo ⊕Pa) ⊕Wa = (Mo ⊕Wa) ⊕Pa
and retrieving the same weather report twice is equal to having it once:
Mo ⊕Mo = Mo
In fact, it seems adequate to think about a series of such amendments in
terms of the set of increments that are made overall, so the ⊕operation in
this example is a kind of set union. Set union is associative, commutative and
idempotent, and the algebra of sets has equations corresponding to these three
properties:
(u ⊕v) ⊕w = u ⊕(v ⊕w)
(1)
u ⊕v = v ⊕u
(2)
u ⊕u = u
(3)
In other examples (see below), there will be other algebraic equations deﬁning
other properties of context augmentation. Far from all context systems combine
in the same way as sets do.
Before we leave this example, let us observe another trait having to do with
translation between contexts: Visibility reports are routinely gathered and ex-
changed between airports worldwide. We can represent them as triples ⟨v, p, t⟩,
where v is a measure of visibility, p is a geographical location, and t is a time-
point. It is natural to think of these triples as members of a relation in a rela-
tional database, with attributes for visibility, location and time. When diﬀerent

Multicontext Logic for Semigroups of Contexts
93
contexts are combined, triples from each component relation are put together in
a joint relation. But, in a Russian database the visibility attribute would be called
’vidinost’, and would be measured in meters, while in an American database the
corresponding ‘visibility’ attribute would be measured in miles. The semantics of
the ⊕operation should take this into account by providing a correspondence in
the form of translations between entities of diﬀerent local context languages.
This motivates a mapping which translates between local context languages,
and later on this will be formalized. For more details of the formalization of
federated databases in a multilanguage environment, see [8,17].
Example 2 Let us take an example with a diﬀerent ﬂavour; the context deﬁned
by a person’s beliefs. Here, the intuitive interpretation of the ⊕operation is the
following. Given two contexts u and v, the context u⊕v is the context u extended
with a description of v, (from u’s perspective). For instance if u is the context of
John’s beliefs, and suppose that John does not know about the existence of Mary.
Let v be the context of Mary’s beliefs. Suppose that John meets Mary, and then
he has to do two things:
1. deﬁne a new context (denoted u ⊕v) representing John’s view of Mary’s
beliefs;
2. relate this new context with his beliefs, i.e. with u.
This might involve things not expressed (or even expressible) in the original
context u, for instance:
– extending the language. u does not contain any predicate for Mary’s beliefs
(this is the case if John does not know Mary), John has to add a new predicate
(or modality) to express Mary’s beliefs.
– extending the set of true formulae. John has to insert some new axioms
expressing what he actually believes about Mary’s beliefs.
With this intuitive interpretation we can stipulate epistemic variants of belief
by admitting equations on ⊕terms. Admitting or rejecting equations like the
following amounts to placement within an epistemic taxonomy.
For instance, we have that the idempotence equation
u ⊕u = u
states perfect introspection, while the associativity equation
(u ⊕v) ⊕w = u ⊕(v ⊕w)
means that for all u, v, w, from u’s point of view, v is a credible witness of w’s
beliefs, i.e. mutual perfect introspection.

94
R. Nossum and L. Seraﬁni
3
Algebras of Contexts
Our concern in this paper is the context combination operator ⊕and its interac-
tion with other features of MC formalism. We shall give a semantical structure
which is complete for certain intercontext deduction rules, when the properties
of context combination are given as algebraic equations of a certain class. As
shown by the previous examples, it is natural to think about algebraic concepts
when two or more entities combine to form a new entity. If a countable set C of
atomic contexts is given a priori, we can take it as the carrier of an algebra with
one binary operator ⊕and equations
yi = zi,
1 ≤i ≤N
(4)
for some N > 0, where yi and zi are terms on ⊕.
As an example consider bags (multisets) over C, generated by the ⊕oper-
ation. In a bag, as opposed to a sequence, the order of elements is immaterial.
The relevant equations express associativity and commutativity of ⊕:
(u ⊕v) ⊕w = u ⊕(v ⊕w)
(5)
u ⊕v = v ⊕u
(6)
In a proper set over C, where repeated context entries don’t count, the ⊕oper-
ation is also idempotent:
u ⊕u = u
(7)
We’ll use E to denote the set of algebraic equations governing the ⊕symbol.
The set of all ⊕-terms over C can be denoted C⊕, and the set of equivalence
classes imposed by the algebraic equations E is then denoted C⊕
E .
Intuitively, C is the set of primitive labels for contexts. Each label c ∈C
is associated with a context. Notice that diﬀerent labels can be associated to
the same context. The set C⊕is the set of terms for denoting contexts. Each
x ∈C⊕is associated with a context, and, as for primitive labels, diﬀerent terms
can be associated to the same context. Finally, C⊕
E can be viewed as the set of
”canonical names” for contexts. Each element x ∈C⊕
E is also associated with a
context ctx, and x can be thought as a canonical name for ctx, or equivalently,
the equivalence class (under the set of equation E) of the terms in C⊕associated
with ctx. Notice that, for any x, y ∈C⊕
E , if x is diﬀerent from y then the context
associated to x is diﬀerent from the context associated to y. Keeping this in mind,
in the rest of the paper, when it is not ambiguous, we use the term “context” as
a shortcut of the description “label for context”.
We proceed to deﬁne a semantics and a proof system for a large class of
algebras of contexts. For simplicity of presentation we restrict ourselves to the
case in which the languages associated to each context is propositional, and leave
the ﬁrst order case out for now.

Multicontext Logic for Semigroups of Contexts
95
3.1
Context Languages
As a typographical convention, we use a, b, c, d, sometimes subscripted, to denote
primitive contexts from C, while t, u, v, w, x, y, z and their subscripted variants
are used liberally to denote primitive contexts from C, composite contexts from
C⊕, or equivalence classes of contexts from C⊕
E .
For each context u ∈C⊕
E we have a propositional language Lu, that is used
to express facts in this context.
Deﬁnition 1 (Well formed formulae) Well formed formulae are deﬁned as
follows (for all u ∈C⊕
E ). If φ is a propositional formula in Lu, then for all
y ∈C⊕y : φ is a well formed formula, and φ is called a y-formula.
Deﬁnition 2 (Language mapping) For all c ∈C, there is a partial recursive
function lc that maps u ⊕c-formulae into u-formulae for arbitrary u ∈C⊕
E .
Intuitively, a language mapping from u⊕c to u states which part and how the
content of the context u⊕c is represented in the context u. Considering the belief
example (Example 2), the usual language mapping is the reiﬁcation function, i.e.
the total function that associates to each u⊕c-formula φ the u-formula bel(c, φ).
3.2
Local Model Semantics
Every equivalence class of contexts, i.e. each u ∈C⊕
E , has its own formula lan-
guage Lu. The semantical structure we are about to deﬁne, takes as its basic
building blocks the local interpretations of each language Lu. We can identify
interpretations with subsets of Lu, i.e. the true formulas in each interpretation.
The semantical structure for the entire system of languages reﬂects the way
in which contexts are augmented by adding ground contexts by the ⊕operation.
We start by deﬁning ground extensions of context terms:
Deﬁnition 3 (x-continuation) Given x ∈C⊕
E , an x-continuation is a context
(. . . (x ⊕c1) ⊕c2 . . .) ⊕ch
where 0 ≤h and ci ∈C for 1 ≤i ≤h. When h = 0, this is just x. Note that
unless ⊕is associative, the parentheses are not redundant.
Deﬁnition 4 (x-chain) For x ∈C⊕
E , an x-chain m is a function which maps
every x-continuation y to a set my of interpretations of Ly (the local models of
context y), such that for some x-continuation y, my is not empty, and for all
x-continuations y, and ground contexts c ∈C:
1
m |= y : lc(φ) if and only if m |= y ⊕c : φ
2
the cardinality of my is at most 1.

96
R. Nossum and L. Seraﬁni
Deﬁnition 5 (Satisﬁability) An x-chain m satisﬁes a formula y : φ where y
is an x-continuation, in symbols m |= y : φ, if for any s ∈my, s |= φ according
to the deﬁnition of satisﬁability for propositional formulae.
Deﬁnition 6 (Logical consequence) A formula x : φ is a logical consequence
of a set of formulae Γ, in symbols Γ |=E x : φ if, for any z-chain m, such that
x is an z-continuation, if m |= {y : γ ∈Γ|x ̸=E y and y is a z-continuation},
then for all s ∈mx, s |= {ψ|z : ψ ∈Γ, x =E z}, implies that s |= φ.
3.3
Reasoning between Contexts
The notion of x-continuations induces a partial order among contexts, each con-
text preceding its continuations. Let us see how one moves between composite
contexts which are related in a partial order. We rely on a natural deduction
calculus extended with indices as described in [18], extended with the following
bridge rules for any set of algebraic equations E.
u : lc(φ)
u ⊕c : φ Rupc
u ⊕c : φ
u : lc(φ) Rdwc
u ⊕c : φ ↔ψ
u : lc(φ) ↔lc(ψ) RRI
v : φ
u : φ u =E v
Derivability from a set Γ of formulae can be deﬁned from a set E of equations
Γ ⊢E u : φ, if there is a deduction of u : φ from Γ, that uses u-rules (as deﬁned
in [18]) and the above bridge rules.
4
Semigroups with Ground Equations
Whenever associativity of the ⊕operation is given or implied, the resulting
algebra is called a semigroup. In the present paper, we are restricting ourselves
to certain semigroups of contexts called AFG algebras.
As shown in [15], AFG algebras have sets and bags (multisets) of contexts
as special cases, as well as the ’ﬂat contexts’ of [4]. Technically, AFG algebras
simplify the proof of completeness, and in the proof it is pointed out where
associativity is used.
Deﬁnition 7 (AFG algebras) An associative ﬁnite ground algebra, abbrevi-
ated AFG algebra, is one that satisﬁes these criteria:
– it is associative, i.e. contains the equation
(u ⊕v) ⊕w = u ⊕(v ⊕w)
– every equation apart from associativity is restricted so that the variables in
it can only be instantiated by constants, not by terms containing ⊕.
– the number of equations is ﬁnite.

Multicontext Logic for Semigroups of Contexts
97
In semigroups, parentheses are redundant, so we may write for instance (a ⊕
b)⊕(c⊕d) as a⊕b⊕c⊕d, or for that matter as abcd. The latter form is common
in pure semigroups, i.e. where terms represent strings of atomic symbols and ⊕
represents concatenation of strings.
There are many other AFG algebras besides strings, however, and we prefer
to retain the generic ⊕symbol when writing terms from C⊕.
Observe that in sets, the axiom of commutativity can be restricted to context
constants:
c ⊕d = d ⊕c
(8)
because with associativity we can get any permutation of
c1 . . . cm
by a series of applications of (8) on adjacent elements.
Idempotence can then be adequately taken as an AFG equation too:
c ⊕c = c
(9)
because with associativity and commutativity it is possible to collect equal ele-
ments of
c1 . . . cm
so that they are adjacent, and then repeatedly deleting an element where adja-
cent ones are equal by applying (9).
It is sometimes convenient to include a special context ϵ, such that
ϵ ⊕u = u = u ⊕ϵ
(10)
For example, in applications where there is an outermost supercontext, enclosing
all other contexts, that could be ϵ.
5
Soundness and Completeness
We can prove the following soundness and completeness result for AFG algebras:
Theorem 1 (Soundness and Completeness) For any set of AFG equations
E, Γ |=E u : φ if and only if Γ ⊢E u : φ.
5.1
Soundness
Soundness of Rdwc and Rupc are direct from item 1 of the chain conditions,
and RRI is sound by virtue of item 2 of the chain conditions. Soundness of the
remaining bridge rule
v : φ
u : φ u =E v
follows because when u =E v, any u-chain is also a v-chain.

98
R. Nossum and L. Seraﬁni
5.2
Completeness
The completeness proof relies on canonical models which respect the bridge rules
of our Multi Context system. The basic building blocks will be maximal con-
sistent sets of well-formed formulae, adapted to the multilanguage environment.
Let us state the versions of consistency and maximality that we need.
Deﬁnition 8 (x-consistency) A ﬁnite set ∆of well-formed formulae is said
to be x-consistent iﬀ∆̸⊢E x : ⊥, and an inﬁnite set is x-consistent iﬀevery
ﬁnite subset is x-consistent.
Deﬁnition 9 (x-maximality) A set ∆of well-formed formulae is said to be
x-maximal iﬀ∆is x-consistent and for all well-formed labelled formulae y : δ
such that ∆∪{y : δ} is x-consistent, y : δ ∈∆.
Theorem 2 (Lindenbaum) Any x-consistent set of wﬀs can be extended to
an x-maximal set.
Proof: Start with an x-consistent set ∆0 and an enumeration of all well-
formed formulae ⟨xi : δi⟩, i ≥1, and deﬁne inductively
∆i = ∆i−1 ∪{xi : δi} if ∆i−1 ∪{xi : δi} is x −consistent
∆i−1 otherwise
(11)
Now
∆=
∞

i=0
∆i
is x-consistent, because otherwise by deﬁnition there would be a ﬁnite subset
∆f such that ∆f ⊢E x : ⊥, and an index n such that ∆f ⊆∆n, contradicting
x-consistency of ∆n. To prove x-maximality, suppose ∆∪{x : δ} is x-consistent
for some δ. Then ∆i−1 ∪{x : δ} is also x-consistent, where i is the index of x : δ
in the enumeration of wﬀs, therefore x : δ ∈∆i ⊆∆.
⊓⊔
Canonical model. Now let us choose an arbitrary x-consistent wﬀx : δ and
construct an x-chain for it. To begin with, we expand {x : δ} to an x-maximal
set ∆by the construction in the previous lemma.
Deﬁnition 10 (Canonical model) For all x-continuations y =E x⊕c1 . . .⊕ch
– let ∆y = {λ | x : lc1(. . . lch(λ)) ∈∆}
– let Sy be the set of interpretations of the language Ly
– let Ty = {s ∈Sy | s |= ∆y} be the subset of interpretations that validate ∆y
– and let m be the function that maps y to ∅if Ty = ∅and to {t} otherwise,
where t is some arbitrary member of Ty.
Our canonical model is the x-chain m.

Multicontext Logic for Semigroups of Contexts
99
∆y is well-deﬁned, so m is really an x-chain. To see this, we prove that
x : lc1(. . . lch(λ)) ∈∆
iﬀ
x : ld1(. . . ldk(λ)) ∈∆
whenever
x ⊕c1 . . . ⊕ch =E x ⊕d1 . . . ⊕dk.
(12)
In fact,
x : lc1(. . . lch(λ)) ∈∆
iﬀ, by h applications of Rup,
((x ⊕c1) . . . ⊕ch) : λ ∈∆
iﬀ, by associativity,1
x ⊕c1 ⊕. . . ⊕ch : λ ∈∆
iﬀ, by (12),
x ⊕d1 ⊕. . . ⊕dk : λ ∈∆
iﬀ, by associativity,
((x ⊕d1) . . . ⊕dk) : λ ∈∆
iﬀ, by k applications of Rdw,
x : ld1(. . . ldk(λ)) ∈∆.
As regards the model conditions, the m we have deﬁned here trivially fulﬁlls
condition 2, and condition 1 is fulﬁlled because for c ∈C and an x-continuation
y = x ⊕c1 ⊕. . . ⊕ch, we have
y : lc(λ) ∈∆
iﬀ
y ⊕c : λ ∈∆
by Rup, Rdw, and x-maximality of ∆.
The x-chain m satisﬁes the wﬀx : δ (take h = 0), so we have completeness.
6
Related Work
Algebras of contexts were proposed in [15] for single-language axiomatic context
systems. In that work the modal logic with the ist modality deﬁned in [12,3,7]
is augmented with an algebra on the domain of contexts (the ﬁrst argument of
the ist modality). The results extend to arbitrary equational varieties. The ist
formalism lacks much of the expressivity of a multilanguage formalism for con-
text reasoning. The present work contains the ﬁrst formalization of multicontext
logics with algebraically structured contexts.
1 The construction does not depend essentially on associativity, so the results of this
paper will be generalizable to arbitrary equational varieties by adjusting the deﬁni-
tion of language mappings and using the initiality of term algebras. This is a work
in progress.

100
R. Nossum and L. Seraﬁni
A ﬁrst proposal for an algebra of contexts is described in [6]. This work is
more focused on the speciﬁc nature of the operation (the union) rather than a
generic operation characterized via a set of equations, as it is here. On the other
hand it seems that properties such as associativity, commutativity, idempotence,
are relevant when one has to deﬁne operations between contexts.
A further theoretical framework, similar to a theory of contexts combina-
tion is proposed in [5], where contexts are formalized via a modal operator. The
fact that φ is true in the context c is represented by the modal formula ✷cφ.
Under this intuitive interpretation of modal formulas, combining contexts be-
comes combining modalities. An example of formula with a combined modality
is ✷c1∪c2φ. This formula intuitively means that φ holds in the context c1 ∪c2,
i.e., in the context obtained by combining c1 and c2 via a union operator. The
main diﬀerences between this work and our approach are two. First, we have
a general calculus for any operation deﬁnable via a set of equations, while [5]
considers speciﬁc operations such as union, inverse, etc. Second, we deal with
contexts with diﬀerent languages, while in [5] all contexts share a common global
language.
Algebras for contexts are relevant for the semantic web. The main assump-
tion of the semantic web is that it is populated by a set of well-designed modular
ontologies, each of which partially describes, from a speciﬁc perspective, a piece
of knowledge. Constructing a new ontology is often a matter of assembling exist-
ing ones. Instead of building ontologies from scratch, one wants to reuse existing
ontologies. Operations for combining ontologies are: ontology inclusion, ontology
restriction, and polymorphic reﬁnement. In [1], an argument is made in favour
of encapsulating ontology in autonomous but partially coordinated contexts.
Clearly to combine ontologies we need a way to combine contexts, which is what
the present work is about.
7
Conclusion
In this paper we have described a general algebra for context combination in
which the relation between source contexts and combined contexts is stored in
the structure of the labels. This information was exploited semantically and
proof-theoretically in order to infer relations between the content of diﬀerent
contexts. We have provided a semantics based on Local Model Semantics for the
general case, and a proof method, based on Multi Context System for a limited,
but signiﬁcant, case, namely the set of contexts that are built via an operation
axiomatisable by an AFG algebra.
The results of this paper can be lifted to other groupoids, and equational
varieties in general, at the expense of slightly more complicated deﬁnitions and
proofs. Furthermore, the results will generalize to local languages other than the
propositional ones considered here, if only a minimal notion of satisﬁability is
deﬁned. Work in these directions is in progress.

Multicontext Logic for Semigroups of Contexts
101
References
1. M. Benerecetti, P. Bouquet, and M. Bonifacio. Distributed context-aware applica-
tions. Human Computer Interaction, 16:213–228, 2001. Special issue on Context-
aware computing.
2. M. Benerecetti, P. Bouquet, and C. Ghidini. Contextual reasoning distilled. Jour-
nal of Theoretical and Experimental Artiﬁcial Intelligence, 2000.
3. Saˇsa Buvaˇc, Vanja Buvaˇc, and Ian A. Mason.
The semantics of propositional
contexts. In Proceedings of the Eight International Symposium on Methodologies for
Intelligent Systems, volume 869 of Lecture Notes in Artiﬁcial Intelligence. Springer
Verlag, 1994.
4. Saˇsa Buvaˇc, Vanja Buvaˇc, and Ian A. Mason. Metamathematics of context. Fun-
damenta Informaticae, 23(3), 1995.
5. T. Costello and A. Patterson. Quantiﬁers over contexts. In KR & R, 1998.
6. C. Dichev.
Theory relations and context dependencies.
In Proceedings of the
6th Australian Joint Conference on Artiﬁcial Intelligence (AI-93), pages 266–272,
Melbourne, 1993.
7. Dov Gabbay and Rolf Nossum.
Structured contexts with ﬁbred semantics.
In
P. Bonzon, M. Cavalcanti, and R. Nossum, editors, Formal Aspects of Context.
Applied Logic Series, Kluwer, 2000.
8. Chiara Ghidini. A Semantics for Contextual Reasoning: Theory and Two Relevant
Applications. Ph.d. dissertation, Dipartimento di Informatica e Studˆı Aziendali,
Universit`a degli Studˆı di Roma “La Sapienza”, Roma, 1998.
9. Fausto Giunchiglia. Contextual reasoning. Epistemologia, special issue on I Lin-
guaggi e le Macchine(XVI):345–364, 1993. IRST Technical Report 9211-20, IRST,
Trento, Italy.
10. Fausto Giunchiglia and Luciano Seraﬁni.
Multilanguage hierarchical logics (or:
how we can do without modal logics). Artiﬁcial Intelligence, 65:29–70, 1994.
11. Ramanathan Guha and Douglas Lenat. Language, representation and contexts.
Journal of Information Processing, 15(3):340–349, 1992.
12. Ramanathan V. Guha. Contexts: A Formalization and Some Applications. PhD
thesis, Stanford University, 1991.
13. David Kaplan.
Demonstratives: an essay on the semantics, logic, metaphysics,
and epistemology of demonstratives and other indexicals. In Joseph Almog, John
Perry, and Howard Wettstein, editors, Themes from Kaplan, pages 481–563. Oxford
University Press, Oxford, 1989.
14. J. McCarthy and S. Buvaˇc. Formalising context, (expanded notes). In A. Aliseda,
R. van Glabbeek, and D. Westerst˚ahl, editors, Computing Natural Language, vol-
ume 81 of CSLI Lecture Notes, pages 13–50. Stanford University, Center for the
Study of Language and Information, 1998.
15. Rolf Nossum. A uniform quantiﬁcational logic for algebraic notions of context.
Skriftserien 82, Agder University College, N-4604 Kristiansand, Dec 2001. ISBN
82-7117-448-7.
16. John Perry.
Indexicals, contexts, and unarticulated constituents.
In Atocha
Aliseda, Rob van Glabbeek, and Dag Westerst˚ahl, editors, Computing Natural
Language, pages 1–11. CSLI Publications, Stanford, California, 1998.
17. Luciano Seraﬁni and Chiara Ghidini. Context-based semantics for information in-
tegration. In Pierre Bonzon, Marcos Cavalcanti, and Rolf Nossum, editors, Formal
Aspects of Context, pages 175–192. Kluwer Academic Publishers, Dordrecht, 2000.
18. Luciano Seraﬁni and Fausto Giunchiglia. ML systems: A proof theory for contexts.
Journal of Logic, Language and Information, July 2001.

Indeﬁnite Integration as a Testbed for
Developments in Multi-agent Systems
J.A. Campbell
Department of Computer Science
University College London
Gower Street, London WC1E 6BT, UK
jac@cs.ucl.ac.uk
Abstract. Coordination of multiple autonomous agents to solve prob-
lems that require each of them to contribute their limited expertise in
the construction of a solution is often ensured by the use of numerical
methods such as vote-counting, payoﬀfunctions, game theory and eco-
nomic criteria. In areas where there are no obvious numerical methods
for agents to use in assessing other agents’ contributions, many ques-
tions still remain open for research. The paper reports a study of one
such area: heuristic indeﬁnite integration in terms of agents with diﬀer-
ent single heuristic abilities which must cooperate in ﬁnding indeﬁnite
integrals. It examines the reasons for successes and lack of success in
performance, and draws some general conclusions about the usefulness
of indeﬁnite integration as a ﬁeld for realistic tests of methods for multi-
agent systems where the usefulness of “economic” criteria is limited. In
this connection, the role of numerical taxonomy is emphasised.
1
Introduction
Apart from a few obviously algorithmic topics (evaluation and simpliﬁcation
of algebraic expressions, diﬀerentiation), symbolic mathematical computing was
in its early days a well-recognised sub-area of artiﬁcial intelligence because it
was an excellent source of tests and illustrations of heuristics. Because sym-
bolic computation has progressed by moving away from heuristics towards the
use and improvement of algorithms for mathematical operations, the degree of
recognition within AI has decreased: AI is basically not about algorithms. This is
understandable, because the primary interest of a subject is usually the technical
content of the subject itself. The fact that the state of its art happens to make it
a useful area of application for AI (or not) is secondary. When this state of the
art ceases to be heuristic, the history of AI says that the heuristics themselves
have typically ceased to be of interest for AI research.
But “typically” does not mean “always”. There are situations where heuris-
tics left behind by the progress of a topic towards an algorithmic state of the
art are still useful - especially if they can help to throw light on current general
problems in AI. One such general problem-area is the behaviour of autonomous
agents in reaching consensus in a multi-agent system, where some coordination
J. Calmet et al. (Eds.): AISC-Calculemus 2002, LNAI 2385, pp. 102–116, 2002.
c
⃝Springer-Verlag Berlin Heidelberg 2002

Indeﬁnite Integration as a Testbed for Developments in Multi-agent Systems
103
of varieties of expertise is needed for the solution of problems but where an
individual agent has no more than one particular expertise.
This paper suggests that a good testbed for questions of consensus and coor-
dination in multi-agent systems is indeﬁnite integration, if the examples of par-
ticular expertise that are used are single heuristics of the kind taught to students
of calculus. That is, indeﬁnite integration is of value for studies in multi-agent
systems if we set aside the progress in algorithmic integration in ﬁnite terms
that started with the work of Moses (on the SIN package) [8] and Risch [13],
and revive the heuristic understanding of the subject that was current in about
1965 and which is still taught at the level of ﬁrst-year undergraduate calculus
courses.
Section 3 below surveys the relevant topics from agency and multi-agent
systems. Section 4 puts a version of heuristic indeﬁnite integration into this
framework, and section 5 summarises what has happened when the version was
tested on a representative sample of exercises in integration. Section 6 discusses
the experience gained in the work, mentions topics that deserve further research,
and argues for further attention to be paid to integration as a testbed for ideas
that may enhance future multi-agent systems.
2
Related Work
Although the standard methods for indeﬁnite integration are now fully algorith-
mic [2,5], and commercially-available packages like Mathematica make use of
them, there is still some activity on and around integration by heuristic means.
This is typically either to improve the ﬂexibility of services available to users,
with the help of large repositories of information (as in the TILU project [17] of
R. Fateman, T.H. Einwohner and collaborators), or for reasons connected with
human problem-solving and mathematical education [4,16]: it is desirable to un-
derstand better the use of heuristics, and even to automate some of the tutoring
of students in such uses. Indeﬁnite integration is an obvious target-area. The
emphasis is on embodiment of heuristics that students do or should adopt.
The exercise reported in the present paper has the diﬀerent motivation of
studying the interaction of simple (but not necessarily student- friendly) heuris-
tics or heuristic fragments in a multi-agent framework. But there is certainly
scope for a future combination of the two motivations, e.g. in considering how
software agents could communicate with and help human agents.
On that last point, there is already relevant work [10] which uses a multiple-
agent scheme for the modelling of (social) interactions in mathematical creativ-
ity, and various software projects (e.g. [1]) for computational algebra, mainly in
connection with development of proofs. These are of interest even if they do not
treat integration as a problem-area; many of the questions concerning agents are
not speciﬁc to a particular topic.
The design of autonomous agents and systems of such agents is a large ﬁeld,
as various monographs (e.g. [18]) show. The most relevant results are mentioned
in Section 4. Two topics that have not received much attention, despite their

104
J.A. Campbell
likely importance in the future, are the determination of preferences between
alternatives when economic or other simple numerical criteria are not evident,
and the use of existing examples or cases to permit agents to decide on current
actions. Heuristic integration was chosen as a test ﬁeld precisely because both
of those considerations occur routinely within it.
3
Consensus and Coordination among Multiple Agents
The outline of the usual cycle in an approach of a multi-agent system to a
problem is:
(i)
it is decided what the next relevant task or subproblem P is;
(ii) agents receive information on (i), assess its relevance to themselves, and
state their opinion about participation in any attempt to solve P;
(iii) (optionally) statements from (ii) may involve questions about possible shar-
ing with other agents the eﬀort towards solving P, and there may be several
iterations of (ii) and (iii) until a ﬁnal pass through (ii) occurs, leading to
some conclusive output (oﬀer, promise, refusal to contribute to the work on
P) from each agent;
(iv) P is allocated to one agent, or some part of the work is allocated to each
member of a (sub)set of the agents;
(v)
the work allocated in (iv) is performed or attempted, and the results are
made available.
(vi) (optionally) some assessment of the results of (v) is carried out, and its
conclusions are fed back into (i) in the next iteration of the cycle if the
original goal of the computation has not yet been reached.
Although straighforward in outline, this description hides questions of tech-
nical detail which are in some respects still subject to research and improvement.
In particular:
1. how is the decision in (i) made?
2. how do agents determine relevance and the opinions that follow rom this, in
(ii)?
3. what forms can the iterations in (iii) take, and what are the conditions for
the iterations to terminate?
4. how is the allocation in (iv) decided?
5. how is the quality of the results from (v) assessed in (vi)?
There are some standard answers to those questions under particular con-
ditions. If the conditions are fulﬁlled for a particular application, multi-agent
systems have functioned quite well for it in practice - hence the rapid recent
expansion of interest in such systems. Nevertheless, it is still desirable to extend
the range of conditions under which they can function well. This is a motivation
for the present paper.
Indeﬁnite integration is a good test example for a number of reasons, as indi-
cated in the experience reported in Section 5. In particular, unlike some problems

Indeﬁnite Integration as a Testbed for Developments in Multi-agent Systems
105
for which the underlying knowledge compels only one realistic way of answering
questions (1) and (2) above, it allows many plausible alternative approaches to
be evaluated and compared. Conclusions from any such comparison are relevant
for multi-agent systems in general. (The present project has not yet taken much
advantage of this ﬂexibility). Because skill in heuristic integration relies signif-
icantly on ability to recognise similarities of an exercise with past completed
or failed exercises, it is a good source of particular or case-like knowledge for
research on how agents can exploit cases in addition to their usual stocks of
generalisations via rules, inheritance networks etc.
The summary in the rest of Section 3 unites scientiﬁc contributions from
various authors. Further background, and references, can be found in the book
edited by Weiss [18] or any of the (few, so far) other good general monographs
on multi-agent systems.
3.1
Control of a Multi-agent System
The main distinction with respect to (1) is between dictatorial and democratic
methods. At one extreme, a super-agent with an understanding of an overall
problem-area uses this understanding to decide what should be done next, which
agent(s) should do it, and how well the various agents have been dealing with
their assigned jobs. At the other extreme, each agent has a vote of equal weight
concerning the next step for the system, and the voting majority always wins.
(In principle this implies that the agents have at least some of the understanding
that a super-agent would possess - but even when this is not so, as in politics,
the outcome is usually somewhat better than totally random confusion). There
are various intermediate possibilities, e.g. elected or selected semi-super-agents
with ﬁnal responsibilities over parts of the overall expertise.
The typical present approach is more dictatorial than democratic. The orig-
inal dictator was the “blackboard manager” in the blackboard- architecture
scheme [9] pioneered in HEARSAY (often regarded as the ﬁrst successful ex-
ample of distributed AI - for real-time speech recognition - and the immediate
ancestor of multi-agent systems). This manager had enough knowledge of the
application to be able to manage the blackboard (a central combined repository
of results and agenda) dynamically and rearrange the agenda creatively.
The HEARSAY application was near-linear; it consisted of several tasks that
(for a short passage of speech) could be performed in sequence, with limited
overlap and feedback between stages. The manager’s main unifying knowledge
was in scheduling, and in responding to demands for feedback (e.g. of the form
“this phrase of text makes no sense; can you compose another one out of the
phonemes that have just been used?”) from the software processing one of the
tasks. Where an application does not have this near-linear character, it is usually
not possible to build a convincing dictatorial super-agent.
It is more common to ﬁnd administrative super-agents that behave dicta-
torially in enforcing the results of a tendering process, but without resistance
because agents are engineered to respect the conventions of the process of calling
for bids to a tender speciﬁcation and having the tender for a task awarded to

106
J.A. Campbell
the bid that is best according to a fully-known prior criterion. This describes the
“contract net” protocol [14], due originally to R. Smith. For a contract net, a
super-agent is just a convenience that reduces the overheads of running a multi-
agent system. (Given full transparency of the bids, all the agents could access
the information and agree on what the award of the tender should be).
The contract net is semi-democratic, because a bid amounts to a weighted
vote. This is a simple quantitative criterion. Quite often in knowledge-intensive
subjects, however, experts are reluctant to reduce their opinions to numbers: they
see their exchanges of opinions with other experts (or the teaching of apprentices)
in terms of statements in the language of their expertise. Of course, the opinions
must ultimately be expressible as single numbers, because when an opinion or
result X is ﬁnally preferred to another one Y, it must then be possible to associate
some numbers x and y with them such that x ¿ y. But experts in many areas
would prefer that to happen only at the last step, after all other considerations,
negotiations etc. have been exhausted.
For the study reported in this paper, the intention was to choose a test
topic for which this was substantially true and where no obvious real-number
measure of progress towards solving problems existed. At the same time, for the
results to have some general interest it was desirable to avoid a topic where the
knowledge was highly specialised or was complicated to express. This is part of
the explanation for the choice of indeﬁnite integration as a topic.
3.2
Agents’ Reactions to Statements of Tasks
A non-autonomous agent in AI can be regarded as an object, In the sense = of
object-oriented computing. If it receives a message containing a problem that it
recognises as being appropriate to its internal method( s), it answers with a mes-
sage containing the result that it computes. If an object is part of a multi-agent
system, it may be rebuilt slightly so that it can distinguish between messages of
the types “Does this problem match your method(s)?” (to which the expected
response is Boolean) and “Solve this problem”. For neither type does it display
autonomy; its designer would always be able to predict whether its Boolean
“bid” in stage (ii) under a contract-net protocol would be 1 or 0.
An autonomous agent is more than an object: it has some internal charac-
teristics that inﬂuence its responses to external messages. A common scheme for
expressing the characteristics is the BDI model [12], in which the information
essential for autonomy is represented inside the agent in terms of beliefs (about
the current problem, other agents, and itself), desires (goals for itself) and inten-
tions (relatively short-term plans or means for trying to achieve its goals). This
scheme is both general and ﬂexible; it gives considerable freedom to experiment
with the details of how to represent and use all three components. It is therefore
respected here.
In a standard contract-net scheme, an agent’s ﬁrst response to the statement
of a task would be a numerical bid (sometimes 0, or “I do not wish to be in-
volved”). This implies that the agent can carry out a numerical computation
about the value (in terms of its own view of the world) of being awarded the

Indeﬁnite Integration as a Testbed for Developments in Multi-agent Systems
107
tender for the task, and therefore that its relevant BDI information is numerical
or can yield numbers for the computation.
The most thoroughly-developed formalism for measuring advantage numeri-
cally is economic, with reference to payoﬀfunctions, penalties and proﬁts, prop-
erties of markets and games, bargaining based on price, etc. This has already
led to an accepted set of techniques, from economics and game theory, for multi-
agent systems. It is therefore more interesting now to examine alternatives where
these techniques do not capture the primary sense of the knowledge, including
BDI knowledge, in an application. Integral calculus is one such application.
3.3
How Agents with Diﬀerent Views Arrive at a Consensus
The simplest way of obtaining consensus has been described above: the contract-
net protocol. It relies on the quantitative considerations in Section 3.2. In a
situation where the stage (iii) of the process summarised at the beginning of
Section 3 is absent, the contract net can bring about a consensus in one step.
If stage (iii) is needed, then the iterations of stages (ii) and (iii) amount to
an exercise of bargaining, where trade-oﬀs are involved. For example, an agent
with a desire to get the payoﬀthat might follow from being allocated all of a
task T with parts T1 and T2 where it is rather more (cost-)eﬀective at doing T1
than T2, but having a limited capital on which to bid, might appreciate from
what other agents had said in a ﬁrst round of (ii) that it could not hope to
compete with other bids for the entire task, and might therefore try to interest
high bidders B for T in a deal where it subcontracts to do T1 on terms that
might be advantageous to B. One could even ﬁnd an agent introducing T1 and
T2 into the debate because of its knowledge of the structure of T despite the
fact that a tender speciﬁcation had mentioned only T and not the parts.
Stage (iii) is probably, for AI, the most interesting stage of the behaviour of a
multi-agent system. Most of the interest is in the properties of the iteration. For
various models of total or bounded economic rationality of agents, termination
is assured (or arbitrary termination can be imposed otherwise, along the same
lines as in Section 3.5).
Negotiation among agents, which is a large subject in itself [7], has almost
always referred to models of that kind. The situation is diﬀerent, and deserves
more research, if we do not have that tight and quantitative economic framework
at our disposal. There are obviously applications where such a framework is not
evident; the issue is mentioned near the end of Section 3.1. This is a further
motivation for experimenting with integral calculus.
3.4
Task Allocation
For a system using the contract net, the allocation itself is simple. After the
agents have devoted eﬀort to formulating bids, coalitions and/or subcontracting
arrangements, the bids can be compared automatically and a criterion for the
best bid applied to select the winner(s). This criterion may be that the lowest bid
is the best, or some modiﬁcation (e.g. use of the second-lowest bid in deciding

108
J.A. Campbell
how/ where a contract will be awarded) selected to minimise adverse eﬀects of
bidding that may be rigged against the entity that makes the speciﬁcation for
the tender.
Other ways of allocating tasks have also been used. If some part of a system is
given dictatorial powers, that part may assign tasks to agents unilaterally, with
reference to (say) known competences of the agents and the competences required
for those tasks. This has the drawback of requiring the dictator to understand
the whole computation well enough to make good assignments consistently and
eﬀectively. In a position intermediate between dictatorship and a pure contract
net, assignment depends on some combination of bidding and evidence of agents’
ability to perform tasks of the kind currently under consideration. A very sim-
ple form of evidence is the labelling of any “known competences” that may be
attached to an agent when it is created. Richer forms may involve records of
previous histories of good and bad performances by the individual agents during
solution of past problems, or indications that agents can produce convincing so-
lutions to trial exercises which are cut-down or abstracted versions of the latest
task that is to be assigned.
The study reported here was intended in part to explore the usefulness of
such intermediate approaches, which are at present less well understood than
dictatorships or contract-net schemes. It turns out that indeﬁnite integration
has some features that make it natural to adopt an intermediate approach.
3.5
Assessing the Quality of Intermediate and Final Results
In some applications, a payoﬀfunction exists that rates the value of any result.
Progress can then be ensured by demanding that the results of successive steps
increase the payoﬀ, or at least that they do not decrease it signiﬁcantly and
systematically. Alternatively - and equivalent to it - the attempt to solve a
problem can be formulated as a search in a state space, where the nature (e.g.
the set of constraints that only a goal can satisfy) of the goal state is known and
where an estimate of the distance from the latest state to the goal is available.
The search is then directed towards new states that show the biggest reduction
in the estimated distance to the goal.
Termination occurs when the goal is reached, or it can be enforced when the
percentage of improvement in the payoﬀbetween successive steps falls below a
given threshold, or by “satisﬁcing”: acceptance of the ﬁrst result found whose
payoﬀvalue is above some preset threshold for acceptability.
These considerations rely on numerical estimates. When there are no obvi-
ous means of numerical estimation, as in the situations described near the end of
Section 3.1, some knowledge-intensive alternative must be used. The subject of
multi-agent systems gives no general guidelines for these situations. It is there-
fore desirable to experiment with realistic examples of the situations, to deﬁne
possible alternatives and to draw conclusions about how they work in practice.
This is one further justiﬁcation for studying indeﬁnite integration, where natu-
ral payoﬀfunctions and clear formulations of appropriate state spaces are not
evident.

Indeﬁnite Integration as a Testbed for Developments in Multi-agent Systems
109
4
Indeﬁnite Integration as a Multi-agent Application
Students learn various techniques for taking the next step in a multiple-step
process of ﬁnding an indeﬁnite integral of a given expression. Good students
learn also how to select the best one for each stage of the process. Less eﬀective
students may learn one technique well and try to apply it to every step where it
has any eﬀect. No student of this kind is likely to get good marks in tests, but
a collective made up of one-technique students with diﬀerent techniques may be
able to pool their eﬀorts and produce acceptable results. This is the view under
examination in the present work. The equivalent of a one-technique student is
an agent that has one approach for any problem of indeﬁnite integration.
Examples of one-technique approaches embodied in agents include: access to
deﬁnitions that can be regarded as basic (integrals with respect to x for con-
stants, polynomials in x, trigonometric functions, and instances such as 1/x and
1/(1 + x2)); integration by parts; guess and diﬀerentiate; half-angle substitution
(x →trigonometric function of some half-angle); trigonometric product substi-
tution; algebraic transformation/matching and access to a memory of solved
examples).
A scheme based on this model of behaviour is described in detail in Section
4.1. The scheme’s consequent implications for agents and for knowledge held in
the multi-agent system are outlined in Section 4.2.
4.1
The Operation of a Multi-agent Computation for Integration
The pooling process starts with a contribution from each agent to the attempted
solution of a problem. This contribution is either null (an indication that the
problem contains no features that the agent can relate to its own expertise) or
a one-step development of the problem. For example, an agent specialised for
a trigonometric substitution oﬀers a restatement of the problem in which the
substitution has been made.
Following this ﬁrst round of contributions, each agent receives the opportu-
nity to comment on the contributions of all the other agents. Agents comment
on their own contributions in the same way as they comment on others.
To maintain the essential character of a system of agents with limited ex-
pertise, agents do not have any advanced knowledge of integration that can be
used to generate comments. Examples of individual agents’ simple observations
applicable at this point are: interest in a contribution because its form allows an
agent to use its own technique easily on that contribution; approval because a
contribution has reduced the length or apparent diﬃculty of the problem (or dis-
approval if that quantity has been increased); detection of similarity between a
contribution and some stored information about the solution of a past problem.
At present, these observations are implemented simply; essentially by inspec-
tion of syntactic details such as lengths of expressions E, presence or absence
of functions or sub-expressions that an agent can integrate and/or that occur
in its own case knowledge, and changes in these details between E and what it
becomes after an agent applies its own integration method once to E. We would

110
J.A. Campbell
not regard a student with just this limited knowledge of integration as a good
student; nevertheless, in computations, it is quite eﬀective (while not being par-
ticularly eﬃcient). There is certainly room for research on adding more advanced
or realistic knowledge, especially if we wish to build a system that performs at
the level of a group of good students. But the point of the present project is
diﬀerent: investigation of whether and how a group of rather unsophisticated
agents can produce overall behaviour that does not seem unsophisticated.
In eﬀect, each agent always has access to the standard diﬀerentiation and
algebraic simpliﬁcation procedures, and can therefore check by diﬀerentiation
whether its latest contribution is the answer to the overall problem. The ﬁrst
contribution that is announced as the answer after this checking then receives no
further comment: the system returns it as such, and the computation terminates.
After a round of comments, the comments themselves are evaluated further.
Contributions that receive no approvals or indications of interest (in the senses
described above) are eliminated. An agent expressing interest in a contribution is
given the opportunity to operate once on that contribution, and the outcome O
is noted. Detection of similarity with something in the records of past solutions
is treated in the same way, because it is equivalent to an expression of interest:
the detecting agent indicates an O which is an outcome of the detection.
The evaluations can be regarded as leaf nodes in a tree whose root is the
problem in its current state. The nodes representing contributions that have
received only approvals are at depth 1; those that have just received further
attention are at depth 2. The depth-2 nodes are again evaluated further.
In principle this kind of look ahead can be pursued recursively to depth n until
all depth-n leaf nodes have approval ratings and no agent indicates that it wants
to evaluate any such node further. However, in practice there is no guarantee
that the recursion will terminate for arbitrary problems of integration, and no
problem tested so far has
shown any apparent beneﬁt from being followed beyond a depth of 2. This
is a provisional conclusion, based on experience obtained until now.
When the look ahead is completed, the contributions surviving from the ﬁrst
round possess expressions of interest and approval, or merely approval. Approvals
are just votes or numbers; expressions of interest can be counted also, but in
addition, because of the look ahead beyond depth 1, they carry non-numerical
information. How to rate them by comparison with approvals is a question of
the kind raised near the end of Section 3.1; this is discussed further in section 6.
But it can be assumed that an expression of interest is not worth less than an
approval. This permits approval-only contributions whose numbers of approvals
are less than the maximum number of approvals plus expressions of interest
found among the contributions to be eliminated.
If more than one contribution remains, there is no obvious way to select the
winner (which is then used as the starting-point for the next cycle). This is an
issue for further research, which is considered in Section 6. A simple way is to
rate a contribution with A approvals and E expressions of interest as worth A

Indeﬁnite Integration as a Testbed for Developments in Multi-agent Systems
111
+ nE for some n (e.g slightly greater than 1), and to break any tie by a random
choice.
The overall process has the obvious weakness that agents may not be suf-
ﬁciently expert about problems outside their competence to be able to state
reliable approvals or expressions of interest. This reliability could be improved
if agents were given more and wider knowledge - but that would defeat the ﬁrst
purpose of the present study, which is to investigate whether a system of spe-
cialised agents can produce anything better than simple specialised behaviour.
This is as interesting as, say, investigating the behaviour of a programme com-
mittee for a conference covering a wide and new ﬁeld, with respect to selecting
a set of papers that does a good job of representing the state of the art of the
whole ﬁeld.
4.2
Choices for Representation of Knowledge
If the multi-agent system contains only techniques and no memory for results,
the performance is poor. In tests, it has then solved only simple problems, and
not even all the simple problems tested have been solved. This is not a surprise.
In the most convincing applications of agent technology in AI, a stock of relevant
knowledge is held somewhere: in a communal store, or spread over the individual
agents, or both.
Holding generalised knowledge (e.g. in rules) improves performance in many
ﬁelds. But when a ﬁeld does not have many such rules, and if they would permit
good performance merely by being built into a single and fairly simple program,
there would be no advantage in dividing them up to make some more complicated
(e.g. multi-agent) software for the same job. This is true of indeﬁnite integration.
This leaves particular knowledge (examples of previous solutions), which is
a signiﬁcant part of human problem-solving knowledge for integration. It is well
suited for use in a multi-agent system, and is employed here.
The actual representation used is a repository held independently of the
agents. An item of knowledge should be at least a statement of an integrand and
its integral, but typical entries also contain sequences
of steps leading from the former to the latter. Some entries have been devel-
oped by hand; others have been extracted from traces of the computation of the
system. Negative knowledge has been useful unexpectedly often: if an integrand
is associated with a transformed version V in a sequence that is recorded as lead-
ing nowhere, and an agent detects a similarity between V and a contribution to a
current problem-solving exercise, that agent can (and does) express disapproval
of the contribution.
The present format of the repository allows for annotations of the entries.
It is intended as a representation for cases, in the sense of case-based reasoning
[6]. Some annotations have been added to negative entries, to explain why they
have led to unsatisfactory behaviour, though with limited use so far. The main
concept used in treating the entries as cases is the determination of similarity
(between parts of the entries and contributions to a current problem of integra-
tion). Similarity is estimated by a distance metric set up on the characteristics

112
J.A. Campbell
(e.g. function types) that ﬁgure in these items, by methods of numerical taxon-
omy [15]. This is a subjective estimation because the construction of distance
metrics is subjective, but that is in the basic nature of numerical taxonomy. The
justiﬁcation here, as in the other areas where it has been applied, is that its
results are convincing.
Metrics express distances between entities A and B, e.g. the distance between
physical locations in terms of their N coordinates in an N- dimensional space.
One adds together the pth. powers of the absolute values of the diﬀerences
between the coordinates of A and B in the individual dimensions, and takes
the pth. root of the sum. The most common metrics are the Euclidean (p = 2)
and Manhattan (p = 1) metrics. p = 1 is used here. The greater/smaller the
distance between A and B, the smaller/greater is their similarity.The “art” of
numerical taxonomy consists of arriving at a good scaling between dimensions
for properties that are (unlike map coordinates) not of the same type, mapping
non-numerical information onto a numerical scale, and making good choices for
the representative properties themselves. For example, if one of the properties
is at ﬁrst sight Boolean - say, explicitly trigonometric character of an integrand,
so that its contribution to the distance between two integrands is either 1 or 0
- should “explicitly exponential character” be a separate property (as a school
student might believe) or not (as a specialist in integration might believe)? And
how should specialist knowledge that the Boolean picture is oversimpliﬁed be
exploited so that distances between 0 and 1 become possible? As stated in the
previous paragraph, the answers contained in the present system are subjective,
involving trial and error. They can certainly be improved (e.g. the answer to the
last question above is at present the answer of the student and not the specialist),
but they have not led to unsatisfactory behaviour.
The fact that case-like and “past history” knowledge is held outside the
agents is a detail of implementation. The knowledge acts like the agents’ bank.
Each agent has an account, consisting of all the items of knowledge that it
can access. An item is labelled with identiﬁers for the agent or agents that
can see it during normal operation. In addition, each agent is given access to a
certain number of items, selected randomly, which are not in its own account, if
that agent has searched through that account without ﬁnding anything relevant
to its reason for initiating the search. Some improvement of problem- solving
eﬀectiveness has been noticed (via agents’ comments on contributions that other
agents have made during the basic problem- solving cycle) when that number
is raised from 2 to 3, but it is too early to draw general conclusions from that
behaviour.
5
Experience of the Multi-agent System in Use
Examples have been taken from B. Peirce’s compilation [11] of standard indeﬁ-
nite integrals, to cover roughly the range of types and diﬃculty of problem that
are seen in ﬁrst-year undergraduate courses in calculus (including polynomi-
als, trigonometric and inverse trigonometric functions, exponentials, logarithms,

Indeﬁnite Integration as a Testbed for Developments in Multi-agent Systems
113
fractional powers, products, and rational expressions whose integrals are not
particularly complicated).
An example of a set of contributions from specialised agents is presented
below, to give an indication of the method at work. Consider the ﬁrst step for

x cos 2x dx.
Some of the contributions are
(Integration by parts)
(1/2)x sin 2x −(1/2)

sin 2x dx
(1)
(half-angle substitution)
(1/2)

tan(t/2) sec2(t/2) cos(2 tan t/2) dt
(2)
(adding 0 and rewriting)

(x + a) cos 2(x + a −a) dx −a

cos 2(x + a −−−a) dx
(3)
(guess and diﬀerentiate)
(1/2)x sin 2x
(4)
(access to past history)

x cos x dx = xsinx −

sin x dx = xsinx + cosx
(5)
(2) and (3) each attract no expressions of interest, and (2) additionally gets a
disapproving vote for excessive length. The other three are investigated over one
more step of looking ahead. (1) receives the substitution 2x →z, which produces
the new subproblem of integrating sin z with respect to z; (4) is diﬀerentiated,
leading to the subproblem of ﬁnding an integral for sin 2x, and (5) receives the
substitution x →2z, which leads to a calculus-free problem of algebraic sim-
pliﬁcation and (re)substitution. Algebraic operations are part of the underlying
environment, not part of the agents’ expertise, and are applied at each step be-
fore agents see the results of the previous step. On the next step, therefore, it is
observed that (5) has already led to a solution. (The process is robust, here and
in general: if some knowledge, such as that supporting (5), had been absent but
the remaining knowledge could support solution, a solution could be found - as
would happen from (1) and (4) if they passed through one more step of looking
ahead).
The case-like stock of knowledge mentioned in Section 4.2 has 22 entries
at present, taken with no particular selection criteria from Peirce’s examples.

114
J.A. Campbell
On a sample of 45 problems, each being either an example quoted by Peirce
or derived from one by algebraic transformations and substitution, the system
reached the correct answer 36 times with cutoﬀs (e.g. the look-ahead depth) set
conservatively, as at present. In the remaining 9 examples, 5 were victims of this
conservative attitude, but (because the scheme does not always follow a sequence
of steps to a solution that a mathematician would regard as eﬃcient) would have
required generous cutoﬀs in order to reach their targets. Of the others, 3 had not
found an appropriate search path because the knowledge base (range of single-
agent expertises or relevant information in the case-like stock of knowledge) was
not yet rich enough for the problems, 1 was in eﬀect in a loop for the same
reason, and 1 had traversed a large loop from a trigonometric problem P to the
eventual discovery that this was equivalent to a problem 0 + P. (A cure for that
particular instance of agents’ failure to cooperate eﬀectively is easy enough to
produce, but it has not been examined thoroughly for side-eﬀects that might
appear elsewhere).
There was no apparent correlation between diﬃculty of a problem, from the
viewpoint of integral calculus, and its presence in the set of 9 exercises for which
the system did not compute an integral.
The computer-algebra part of the software is a development of an old set of
programs [3] originally written to deal with integration of functions of a com-
plex variable. It would be preferable to employ a good general computer algebra
system, if it were easy, or even possible, to control (e.g. for single steps of in-
tegration) or access (e.g. arbitrary syntactic patterns of expressions and their
parts) that system externally from an AI-based program.
6
Discussion
By the standards of symbolic mathematical computation, the results in Sec-
tion 5 are not impressive. But that is (fortunately) not the point. The paper
reports a successful use of an old approach to a traditional symbolic comput-
ing application, as a demonstration that that application is a good testbed for
experimentation with and assessment of alternative ideas about how to build
systems of autonomous agents with diﬀerent expertises that contribute to the
solution of exercises in a non-trivial area - particularly where there is no natural
or immediate numerical way (involving notions of payoﬀs and similar economic
criteria) to prefer one agent’s contribution over another. How to deal with that
latter situation is a live research issue in AI, which can only beneﬁt from detailed
and controlled further experimental work. Indeﬁnite integration has all the right
properties to be a test ﬁeld.
A good example of an associated question for research is in how to treat and
rate non-quantitative comments about the qualities of diﬀerent items when it is
necessary to choose the one item that is “best” or most popular. In the present
work (and probably in general), a qualitative comment contains or implies rat-
ings by several diﬀerent criteria, including criteria applied by an entity other
than the source of the comment (e.g. criteria of distance from or relevance to a

Indeﬁnite Integration as a Testbed for Developments in Multi-agent Systems
115
goal, demands for resources in following up the commented suggestion, perceived
quality of related past comments from the same source). In the work reported
here, it has been found that identifying and distinguishing the various possible
criteria gives signiﬁcantly better results than turning each comment immedi-
ately into a slightly enhanced numerical vote (see the end of Section 4.1). It has
also been found that evaluating the criteria with respect to each other and to
numerical data like votes of approval can be reduced (at least for the material
studied so far) to the measurement of distances between qualitative items (or
“operational taxonomic units”, in the language of [15]), after ﬁrst establishing a
convincing scaling between the diﬀerent criteria or dimensions.
There are further topics in which research of general interest - not just interest
for indeﬁnite integration - is possible, For example, there is scope for a more
substantial investigation of the eﬀects of the volume, kind, representation (case-
based or otherwise) and accessibility (for all agents, versus accessibility only for
individual agents or groups of agents) of knowledge in a multi-agent system on
the performance of that system. Case-based, historical, episodic etc. knowledge
is clearly relevant in knowledge-based computations where the emphasis is on
particular rather than generalised knowledge - as is usually true in multi-agent
computations - but multi-agent systems research has paid rather little attention
to this knowledge and its possible exploitation, to date.
Acknowledgement. It is a pleasure to acknowledge the hospitality of Prof. J.
W. Perram and the Maersk Mc-Kinney Moller Institute for Production Technol-
ogy, University of Southern Denmark, where this work was begun.
References
1. C. Benzem¨uller, and V. Sorge. Critical Agents Supporting Interactive Theorem
Proving. In Progress in Artiﬁcial Intelligence, eds. P. Barahona and J. J. Alferes,
208-221 (Springer-Verlag, Berlin, 1999)
2. M. Bronstein. Symbolic Integration I: Transcendental Functions (Springer-Verlag,
Berlin, 1997)
3. J. A. Campbell, J. G. Kent, and R. J. Moore. B.I.T., 16, 241-259 (1976)
4. A. Cardon, and C. Moulin.
Adaptation of a Learning System to the Student’s
Behaviour. Paper No. 185, PSI-LIRINSA, INSA de Rouen, Mont Saint-Aignan,
France (1996)
5. J. H. Davenport, Y. Siret, and E. Tournier. Computer Algebra Systems and Algo-
rithms for Algebraic Computation. (Academic Press, London, 1993)
6. J. Kolodner. Case-Based Reasoning (Morgan Kaufmann, Los Altos, CA, 1993)
7. S. Kraus. Strategic Negotiation in Multiagent Environments (MIT Press, Cam-
bridge, MA, 2001)
8. J. Moses. Comm. A.C.M., 14, 548-560 (1971)
9. H. P. Nii. Blackboard Systems: The Blackboard Model, Problem Solving and the
Evolution of Blackboard Architecture. AI Magazine, 38-53 ( August 1986)
10. A. Pease, S. Colton, A. Smaill, and J. Lee. = A Multi-Agent Approach to Mod-
elling Interaction in Human Mathematical Reasoning. Report EDI- INF-RR-0056,
Division of Informatics, University of Edinburgh, Scotland (2001)

116
J.A. Campbell
11. B. Peirce. A Short Table of Integrals (Ginn & Co., Boston, MA, 1957)
12. A. S. Rao, and M. P. Georgeﬀ. Modeling Rational Agents with a BDI- Architecture.
In Principles of Knowledge Representation and Reasonin g, eds. J. Allen, R. Fikes,
and E. Sandewall, 473-484 (Morgan Kaufmann, San Mateo, CA, 1991)
13. R. Risch. Trans. Amer. Math. Soc., 139, 167-189 (1969)
14. R. Smith. IEEE Transactions on Computers, 29, 1104-1113 (1980)
15. P. A. Sneath, and R. R. Sokal. Numerical Taxonomy (Freeman, San Francisco,
1976)
16. V. Tarasov.
Applying Intelligent Agent Technology to Create Instruction Pro-
grams. Proc. FIPW’297-98: Developments in Distributed Systems and Data Com-
munications, 190-204 (Petrozavodsk, Russia, 1998)
17. A TILU Web site is at torte.cs.berkeley.edu:8010/tilu
18. G. Weiss, editor. Multiagent Systems (MIT Press, Cambridge, MA, 1999)

Expression Inference – Genetic Symbolic
Classiﬁcation Integrated with Non-linear
Coeﬃcient Optimisation
Andrew Hunter
Department of Computer Science,
University of Durham
Science Labs, Durham, UK
andrew1.hunter@durham.ac.uk
http://www.durham.ac.uk/andrew1.hunter/index.html
Abstract. Expression Inference is a parsimonious, comprehensible
alternative to semi-parametric and non-parametric classiﬁcation tech-
niques such as neural networks, which generates compact symbolic
mathematical expressions for classiﬁcation or regression. This paper
introduces a general framework for inferring symbolic classiﬁers, using
the Genetic Programming paradigm with non-linear optimisation of
embedded coeﬃcients. An error propagation algorithm is introduced
to support the optimisation. A multiobjective variant of Genetic
Programming provides a range of models trading oﬀparsimony and
classiﬁcation performance, the latter measured by ROC curve analysis.
The technique is shown to develop extremely concise and eﬀective
models on a sample real-world problem domain.
Keywords. Symbolic Regression; Classiﬁcation; Genetic Programming;
ROC Curves; Multiobjective Optimisation.
Topic. Symbolic Computations for Expert Systems and Machine Learn-
ing.
1
Introduction
A large number of techniques are currently used for non-linear classiﬁcation,
including neural networks, decision trees and parametric statistical models. The
general task, given a data set, D, which includes a number of cases, each holding
a target value for a dependent or output variable, t, together with a vector of
values for potential independent or input variables, x = {xi}, is to infer a model
y = f(x) that best predicts the target variable.
The model inference task is often split into two separate parts: selection of
the model architecture; and optimisation of the coeﬃcients. For example, the
Back Propagation algorithm provides an eﬃcient method to calculate the gra-
dient of the error function of a neural network with respect to the weights (the
coeﬃcients of the model); this gradient may be “plugged into” a non-linear
J. Calmet et al. (Eds.): AISC-Calculemus 2002, LNAI 2385, pp. 117–127, 2002.
c
⃝Springer-Verlag Berlin Heidelberg 2002

118
A. Hunter
optimisation algorithm such as Quasi-Newton BFGS [13] to determine the co-
eﬃcients. However, the algorithm requires a ﬁxed network structure, which is
often selected “by hand.” Algorithmic approaches to determine the structure
include: constructive algorithms, that add units [6]; pruning approaches, that
build an over-speciﬁed model and then remove parts [15]; and feature selection
algorithms that identify and remove irrelevant variables [5] [10].
A useful general framework views non-linear models as the functional com-
position of input variables and adjustable coeﬃcients. Models such as neural
networks and decision trees use particular restricted sets of functions, structural
conventions governing permitted compositions, and deﬁne algorithms to infer
the coeﬃcients and/or model form.
An important issue in many application domains is comprehensibility of the
inferred model. For example, in medical applications neural networks may not be
acceptable, even if performance is good, as the clinician cannot comprehend how
the model comes to a decision. We may then prefer to generate a symbolic clas-
siﬁer – a mathematical expression in the input variables that is relatively easy
to comprehend. In a recent paper [9] we introduced one such restricted model
suitable for classiﬁcation – a logistic function applied to a polynomial. The re-
quirement for comprehensibility also implies that there are two broad inferential
objectives: to maximize the “comprehensibility” of the inferred model, and to
maximize its “performance” – and that we may need to trade-oﬀperformance
in these two objectives.
Genetic Programming [12] is a general framework for model inference, where
a model is represented by an expression-tree, and a set of genetic operators
specialized for tree structures is used in searching the model space. Koza [12]
originally suggested symbolic regression as an application of GP, but the tech-
nique is seldom used, primarily because the inclusion of adjustable coeﬃcients
in GP is problematic. Rodr´ıguez-V´azquez et. al. [14] suggested using Genetic
Programming with the operator set limited to {Σ, Π} to generate polynomial
models sans coeﬃcients for a regression application. The GP is translated into
the equivalent polynomial, and then the coeﬃcients are added and optimised
by least squares. Recently, we extended this approach to classiﬁcation by ap-
plying a logistic activation function and optimising coeﬃcients in the maximum
likelihood framework using Quasi-Newton methods [9].
This paper introduces a more general framework for handling coeﬃcients
in symbolic regression. We embed coeﬃcients at the nodes of the expression
tree, and introduce an error propagation algorithm that eﬃciently calculates the
gradient of the error function with respect to the coeﬃcients. Genetic Program-
ming is used to generate expression trees, each of which is optimised by Quasi-
Newton techniques using error propagation. The technique neatly divides the
model inference process into architecture design (for which GP is well-suited)
and coeﬃcient optimisation, for which Quasi-Newton is preferable. We use a
Multi-objective version of the Genetic Programming algorithm to control the
trade-oﬀbetween model performance (measured by ROC curve analysis) and
parsimony, the latter being closely related to comprehensibility. The result is an

Expression Inference – Genetic Symbolic Classiﬁcation
119
exploratory inferential algorithm that generates a large number of alternative
symbolic classiﬁers, and retains a set representing a range of trade-oﬀs between
performance and parsimony.
2
GP Expression Representation
Genetic Programming represents a model using an expression-tree – internal
nodes are drawn from a set of permissible functions (operators), and terminals
from the set of variables, {xi}. The standard technique to handle coeﬃcients is
to introduce a special terminal symbol, the ephemeral constant[12], the value of
which may be altered by evolution. This is an ineﬀectual search method, however.
In this paper, we instead embed coeﬃcients at nodes in the tree (as multiplicative
coeﬃcients at all terminals, and as special coeﬃcients of some speciﬁc operators;
for example, the decision threshold of the IFTS operator)1. For example, the GP
shown in ﬁgure 1, which (discarding coeﬃcients) is expressed in Polish notation
as (∗x1(+(+x7x8)x3)), translates to the quadratic polynomial:
y = c2c5x1x7 + c2c6x1x8 + c2c7x1x3
(1)
c2x1
c5x7
c6x8
Σ (4)
c7x3
Σ (3)
Π (1)
Fig. 1. A simple Genetic Program
If the only operators are {Σ, Π} it is appropriate to omit the embedded co-
eﬃcients, translate the expression tree into the corresponding polynomial, and
then to add coeﬃcients, which avoids the redundancies evident in equation 1.
Similar translate-and-embed procedures may be available for other choices of
operator sets. However, we consider models with the operators drawn from the
set O = {Σ, Π, Φ, IFTS}, which cannot always be reduced to a simpler form; the
deﬁnition of these operators is given in table 1.
Genetic Programming has a number of desirable properties for model infer-
ence. First, it is constructive, in the sense that it starts with simple trees, and
then attempts to combine successful models together. Optimisation of the coef-
ﬁcients makes this process viable – crossover is not destructive, as in most GP
1 A valid alternative is to embed coeﬃcients on edges, as occurs in neural networks

120
A. Hunter
applications, since the coeﬃcients are “tweaked” to form the best possible com-
bination of two crossed-over models. The inherent tendency of GP to “bloat”
(increase tree size arbitrarily) is a useful property in constructive search, and
can be controlled and exploited by the techniques discussed later in this paper.
Table 1. Deﬁnition and Gradient of Operators. The xi are inputs, ci coeﬃcients, and
a the output (activation). Coeﬃcients, if any, are shown after the semi-colon.
Operator
Deﬁnition
Gradient (∇(x; c))
Σ(x1, x2)
x1 + x2
[1, 1]
Π(x1, x2)
x1x2
[x2, x1]
Φ(x1; c1)
1
1+e−(x1+c1)
[a(1 −a); a(1 −a)]
IFTS(x1, x2, x3; c1) Φ(x1, −c1)x2+
(1 −Φ(x1, −c1))x3
[−a(1 −a)(x2 −x3),
Φ(x1, −c1),
(1 −Φ(x1, −c1));
−a(1 −a)(x2 −x3)]
3
Coeﬃcient Error Propagation
To optimise the coeﬃcients of the expression tree, we isolate them into a vector,
c, design an error function, E(c) together with its gradient with respect to
the coeﬃcients, ∇c, and then use the Quasi-Newton non-linear optimisation
procedure. For classiﬁcation, it is desirable that the output be in the range
[0, 1], so that it can be interpreted as a probability, which is easily achieved in
the two-class case by adding an implicit logistic operator, Φ, at the root of the
tree. We choose the cross-entropy [2] error function, given in equation 2 (tn and
yn are the target and predicted output for the nth case respectively), so that
the optimisation corresponds to maximum likelihood estimation of the model
coeﬃcients.
E = −

n
tn log yn + (1 −tn) log(1 −yn)
(2)
We write the error function in terms of a functional composition of the vari-
ables and coeﬃcients, and diﬀerentiate with respect to the latter. Applying the
chain rule, the partial derivative w.r.t. a given coeﬃcient can be written as the
product of terms starting at the root and involving all ancestors of the node
where the coeﬃcient is embedded. Evaluation can be performed very eﬃciently,
in a similar fashion to back propagation in neural networks, by ﬁrst executing
the expression tree, storing activation levels at each node, and then propagat-
ing errors downwards. At each node, the partial derivative of the node operator
with respect to each child is multiplied by the error propagated from its parent,

Expression Inference – Genetic Symbolic Classiﬁcation
121
then passed to the child. In some cases the operator may have a coeﬃcient, and
the partial derivative of this is also calculated. The partial derivatives of the
operators used in this paper are given in table 1.
Example. The diﬀerential of the GP shown in ﬁgure 1 with respect to coeﬃcient
c7 is given by the equation below, where ai is the activation of node i:
∂E
∂c7
= ∂E
∂a1
∂a1
∂a3
∂a3
∂a7
∂a7
∂c7
= ∂E
∂a1
.a2.1.x3 = ∂E
∂a1
.c2x1x3
(3)
Error propagation begins with the delta value
∂E
∂a1 , which for the cross-entropy
error function is given by:
∂E
∂a1
=
yn −tn
yn(1 −yn)
(4)
With the addition of an implicit logistic operator at the root, this simpliﬁes to:
∂E
∂a1
=

yn −tn
yn(1 −yn)

. (yn(1 −yn)) = yn −tn.
(5)
The error propagation algorithm has O(TN) execution time, where N is the
number of cases, and T the number of nodes in the tree.
4
Operators
Expression Inference is a very general framework, and can handle any diﬀeren-
tiable operators. However, we may validly ask which operators are “most useful?”
Speciﬁc problem domains might have a requirement for specialised operators
such as trigonometric functions (e.g. signal processing) or logarithms and expo-
nentials (for suitably distributed variables). Nominal variables should be treated
using indicator variables and logical functions such as {∧, ∨, ¬}. However, we
limit our attention real continuous input variables.
First, we include the “polynomial operators”, Σ and Π, since polynomi-
als are reasonably comprehensible models with a sound theoretical basis (e.g.
the decision boundaries in classiﬁcation problems with normal distributions are
quadratics; higher order polynomials are arbitrarily ﬂexible). We add the logistic
sigmoid, Φ, due to its helpful role in “squashing” values.
The hard threshold-if operator, IFTH (see equation 6), is extremely useful
in “splitting” the model into parts that correspond to diﬀerent partitions of
input space, thus allowing the inference of a “mixture of experts” [11]. Such
decomposition can greatly aid comprehensibility. Unfortunately, IFTH is not
diﬀerentiable with respect to the conditional operand or its threshold coeﬃcient.
Instead, we use the soft threshold-if operator, IFTS, whose equation is shown in
table 1, which is diﬀerentiable. This is somewhat less comprehensible that IFTH,
but retains an appealing “fuzzy-decision rule” interpretation.
IFTH(x1, x2, x3; θ) =
x2, x1 ≥θ
x3, x1 < θ ,
(6)

122
A. Hunter
5
Multiobjective Genetic Programming
Multiobjective optimisation algorithms ﬁnd models that maximize a number
of objective function measures, M = {m1, m2, ..., mk}, without combining them
into a single objective. They establish a number of solutions representing diﬀerent
trade-oﬀs between objectives. The decision about acceptable trade-oﬀs between
objectives may then be made a posteriori, after inference, rather than a priori.
The key concept in Multiobjective optimization is the Pareto optimal set [1].
Given two models, A and B, we say that A ≻B (A dominates B) if A has at
least one objective value strictly greater than B, and all objective values at least
equal to B:
A ≻B ⇐⇒∀i, mi(A) >= mi(B); ∃i, mi(A) > mi(B)
(7)
The Pareto-optimal set consists of all non-dominated solutions (i.e. those that are
not dominated by any other solution). Multiobjective algorithms search along a
Pareto front — the non-dominated subset of the models found during the search.
Multiobjective Genetic Programming implements this concept in the context
of GP. If one objective is tree size, Multiobjective GP can control the inherent
tendency of GP to bloat [3] [4], and produces a range of models of diﬀerent
parsimony versus performance trade-oﬀs. Parsimony is closely related to model
comprehensibility. Rodr´ıguez-V´azquez [14] used the MOGA designed by Fonseca
and Fleming [7] to optimise a number of performance and complexity measures
in GP, and also demonstrated the division of eﬀort between GP structure de-
sign and coeﬃcient optimisation by least squares in the context of polynomial
modelling. We use a variant of the niched Pareto GA developed by Horn [8],
modiﬁed for GP evolution by Hunter [9] based on the variant for feature selec-
tion developed by Emmanouilidis [5].
The niched Pareto GA [8] maintains a population, and a separate non-
dominated set, which contains copies of all solutions found on the Pareto front
(if this set reaches a maximum size, it is pruned by niching). Selection is im-
plemented by generating a separate mating pool; once generated, the mating
set is subjected to crossover, mutation or cloning to generate the new popula-
tion, and the non-dominated set is updated. A specialised form of tournament
selection is used. The tournament members are selected from the union of the
population and the non-dominated set; the inclusion of the latter introduces an
elitist element to the algorithm, as high-performance individuals are preserved
unchanged and used in subsequent breeding. Rather than competing with each
other, as in a standard tournament algorithm, the tournament members are
compared with a larger dominance set randomly selected from the current pop-
ulation (Horn’s analysis indicates that this approach performs better than the
naive tournament). If there exists a single tournament member non-dominated
by all members of the dominance set, it wins the tournament and is copied to
the mating pool. If two or more tournaments members are non-dominated, they
are each candidate winners; if all tournament members are dominated, they are
all candidate winners. In such cases, a niching strategy is used to decide which

Expression Inference – Genetic Symbolic Classiﬁcation
123
candidate should be placed in the mating pool. Each candidate is compared
against existing members of the mating pool, and the one with the best niche
score, Ni, which reﬂects its dissimilarity from existing members of the mating
pool, is chosen. The niche score in general may be phenotypic or genotypic.
To adapt the niched Pareto GA to GP selection, we deﬁne a niching similarity
measure based on counting the number of nodes that the two trees have in
common (see equation 8; SG(k) is the symbol – operator or terminal – at node
k, # is the number of matches). We then locate the K nearest neighbors in
the mating pool (the neighborhood, K), using the similarity measure, and set
the niche score to the mean distance; see equation 9. The value K is selected
using equation 10, where M is the current size of the mating pool. Strictly, to
handle sub-tree size variability, we should use a more sophisticated tree similarity
metric; however, the simple measure deployed here has the beneﬁt of easy and
rapid evaluation.
D(Gi, Gj) = #{k : SGi(k) = SGj(k)}
(8)
Ni =

K D(Gi, Gk)
K
(9)
K =

M/5, M < 25
5,
M ≥25 ,
(10)
We assess performance by using the concept of ROC dominance. Receiver
Operating Characteristic [16] curves are a standard technique, widely used in
medical applications, which characterise the performance of a classiﬁer as the
decision threshold is altered, by displaying the sensitivity versus 1−speciﬁcity. A
perfect classiﬁer hugs the left-hand side and top of the graph, as there is no need
to trade sensitivity and speciﬁcity – a threshold can be selected which classiﬁes
all cases correctly. In a recent paper [9] we described how to exploit multiobjec-
tive optimisation in designing classiﬁers with diﬀering ROC performance. Rather
than aiming for best performance in a single measure, such as the cross-entropy
error rate, we compare ROC curves in the domination tournament. One model
is said to ROC dominate another if its ROC curve has no points below the other
and at least one point strictly above it. Using this concept can yield alternative
models that perform well at diﬀerent sensitivity levels. If two models of equal
complexity have overlapping ROC curves, then they each perform best at diﬀer-
ent parts of the sensitivity range; such models are mutally non ROC dominant,
and so both will be preserved by the algorithm.
6
Empirical Results
We conducted ten experiments using the new algorithm. Control parameters for
the runs are given in table 6. The data used was the standard Ionosphere data
set (available from the UCI Machine Learning Repository); only the ﬁrst ten
variables were used, and the cases were divided into 200 for training, and 151

124
A. Hunter
Table 2. GA Settings
Population
100
Non-dominated set size 25
Tournament size
2
Dominance group size
10
Generations
200
Crossover rate
0.3
Mutation rate
0.3
for model selection and test. Average execution time was about two hours per
run on an 800MHz PC.
The algorithm generated solutions with numbers of nodes in the range 1-135;
non-dominated fronts on each run of the algorithm contained trees ranging up
to 35 nodes. The algorithm purged larger trees, indicating that it is very good
at controlling bloat. The joint non-dominated front across all models searched
in all experimental runs contained solutions with 1–14 nodes – all extremely
parsimonious. It also contained a signiﬁcant number of repeated models, and
also of models with the same complexity and marginal overlap of a few points
between the ROC curves, which prevents domination. We therefore deﬁne an
equivalent non-dominated set as a minimal sized subset which contains models
equivalent to all members of the full non-dominated set, where equivalent implies
an equal number of nodes, and ROC curves which are either strictly equal, or
overlap at less than 5% of the points on the curve. Using this deﬁnition, we
construct an overall equivalent non-dominated set, which is the basis of the
results reported below. The overall equivalent non-dominated set contains thirty-
two models with between 1 and 14 nodes, with models of 3 and 6–8 nodes most
heavily represented.
6.1
Predictive Performance
To assess the eﬃcacy of the algorithm, we compared the results with two bench-
marks – a logistic regression, and a thirty hidden-unit Radial Basis Function
neural network, both using all ten input variables. These benchmarks were cho-
sen as logistic regression is a standard statistical technique in widespread use
in medical applications, and the RBF network is a powerful (if poorly compre-
hensible) technique that provides an eﬀective “gold standard” for comparison
of performance. All predictions were performed on a hold-out set of 151 cases.
Figure 2b shows the ROC curve for a model with 7 nodes – the logistic quadratic
Φ(−0.88x1(−1.2x7 −1.6x8 −1.1x3)) (the root Φ is implicit in all our models);
the corresponding tree is shown in ﬁgure 1. Performance is somewhat inferior to
the RBF network, but the model has many fewer free parameters (four, as com-
pared with 311 for the RBF), and uses only four of the available ten variables.

Expression Inference – Genetic Symbolic Classiﬁcation
125
Figure 2a is the three node model Φ(0.87x6 +1.19x7) – a logistic regression with
only 2 variables. Both these models have good performance and relatively high
comprehensibility, compared with the logistic regression and neural network al-
ternatives. The fact that the two models have only one variable in common is
typical of the problems encountered in searching for models in domains with so
many interrelated variables, and highlights the diﬃculty of the task – we would
not ﬁnd model b via a forward selection algorithm which visited model a, for
example. The more complex models had better performance than the ﬁrst model
shown above on parts of the ROC curve, and included examples using the Φ and
IFTS operators; ﬁgure 2c shows the ROC curve for the most complex, 14-node
model. An astute choice of these models would give broadly comparable results
to the neural network at any point on the ROC curve.
0
0.5
1
0
0.2
0.4
0.6
0.8
1
Log. Reg.
RBF
GP (3 nodes)
0
0.2
0.4
0.6
0.8
1
0
0.2
0.4
0.6
0.8
1
Log. Reg.
RBF
GP (7 nodes)
0
0.2
0.4
0.6
0.8
1
0
0.2
0.4
0.6
0.8
1
Log. Reg.
RBF
GP (14 nodes)
a) 3 node tree
b) 7 node tree
c) 14 node tree
Fig. 2. ROC Comparison against benchmark models.
6.2
Consistency
It is diﬃcult to assess with certainty whether such algorithms search the Pareto
front eﬀectively, as the size of the search space makes it impossible to exhaus-
tively sample to establish the true front as a standard of comparison (in a ten
variable problem there are 261 quadratic expressions alone). A useful indicator
is to measure the consistency of the algorithm – the proportion of experimen-
tal runs that ﬁnd each point on the front. Figure 3a shows the proportion of
the united front found by each run. This is quite low (average 18%), indicating
poor consistency – the algorithm is not exploring the admittedly extremely large
search space very eﬀectively (it is worth stressing that the diﬀering runs all ﬁnd
good performance models, but they are often of higher complexity than the non-
dominated front member with comparable performance). It may be that a more
constrained heuristic search technique, rather than the “generalist” GA, would
improve performance.
Figure 3b shows the proportion of the equivalent non-dominated front found
on each generation. It is clear that the algorithm has not converged even after

126
A. Hunter
1 2 3 4 5 6 7 8 9 10
0
5
10
15
20
25
30
0
100
200
0
0.2
0.4
0.6
0.8
1
a) Per run
b) Per generation
Fig. 3. Proportion of equivalent non-dominated front covered
two hundred generations, and we could reasonably expect to ﬁnd more improved
solutions if we ran for longer.
7
Conclusion
We have described a general technique to perform inference of mathemati-
cal expressions. Expression trees are evolved using the Genetic Programming
paradigm. Coeﬃcients are embedded at each node and separately optimised us-
ing an eﬃcient error propagation algorithm. The use of multiobjective Genetic
Programming allows the generation of a range of alternative solutions, which
trade oﬀmodel parsimony versus ROC curve performance. We have demon-
strated that the method can achieve performance levels approaching those of
a neural network on a highly non-linear classiﬁcation problem with signiﬁcant
interdependencies between variables, but with a much more parsimonious and
comprehensible model, and can also produce a range of diverse complexity mod-
els with reasonably good performance.
Future work will include the integration of binary and ordinal variables, the
integration of constraints on operator placement to improve inference, and the
analysis of alternative heuristic structure search mechanisms, including the in-
tegration of top-down “purity” based methods derived from decision tree theory
and bottom-up model merging algorithms.
References
1. A. Ben-Tal. Characterization of pareto and lexicographic optimal solutions. In
Fandel and Gal, editors, Multiple Criteria Decision Making Theory and Applica-
tion, pages 1–11. Springer-Verlag, 1979.
2. Christopher M. Bishop. Neural Networks for Pattern Recognition. Clarendon Press,
Oxford, 1995.

Expression Inference – Genetic Symbolic Classiﬁcation
127
3. Stefan Bleuler, Martin Brack, Lothar Thiele, and Eckart Zitzler. Multiobjective
genetic programming: Reducing bloat by using spea2. In L. Spector, E. Goodman,
A. Wu, W.B. Langdon, H.-M. Voigt, M. Gen, S. Sen, M. Dorigo, S. Pezeshk,
M. Garzon, and E. Burke, editors, Proceedings of the Congress on Evolutionary
Computation, CEC-2001, pages 536–543, IEEE Press, 2001. Piscataway, NJ.
4. Edwin D. De Jong, Richard A. Watson, and Jordan B. Pollack. Reducing bloat and
promoting diversity using multi-objective methods. In L. Spector, E. Goodman,
A. Wu, W.B. Langdon, H.-M. Voigt, M. Gen, S. Sen, M. Dorigo, S. Pezeshk,
M. Garzon, and E. Burke, editors, Proceedings of the Genetic and Evolutionary
Computation Conference, GECCO-2001, pages 11–18, San Francisco, CA, 2001.
Morgan Kaufmann.
5. Christos Emmanouilidis, Andrew Hunter, and John MacIntyre. A multiobjective
evolutionary setting for feature selection and a commonality-based crossover oper-
ator. In Proc. of the 2000 Congress on Evolutionary Computation, pages 309–316,
Piscataway, NJ, 2000. IEEE Service Center.
6. S.E. Fahlman and C. Lebiere. The cascade-correlation learning architecture. In
D.S.Touretzky, editor, Advances in Neural Information Processing Systems, vol-
ume 2, pages 524–532, San Mateo, CA, 1990. Morgan Kaufmann.
7. C. Fonseca and P. Fleming. An overview of evolutionary algorithms in multiob-
jective optimization. Evolutionary Computation, 3(1):1–16, 1995.
8. Jeﬀrey Horn and Nicholas Nafpliotis. Multiobjective optimization using the niched
pareto genetic algorithm. Technical Report IllIGAL 93005, University of Illinois,
Urbana, IL, 1993.
9. Andrew Hunter. Using multiobjective genetic programming to infer logistic poly-
nomial regression models. In Proceedings of the European Conference on Artiﬁcial
Intelligence, ECAI 2002. IOS Press, 2002.
10. A. Hunter, L. Kennedy, J. Henry, and R.I. Ferguson. Application of neural net-
works and sensitivity analysis to improved prediction of trauma survival. Computer
Methods and Algorithms in Biomedicine, 62:11–19, 2000.
11. R.A. Jacobs, M.I. Jordan, S.J. Nowlan, and G.E. Hinton. Adaptive mixtures of
local experts. Neural Computation, 3:79–87, 1991.
12. J.R. Koza. Genetic Programming. MIT Press, Cambridge, MA., 1992.
13. William H. Press, Brian P. Flannery, Saul A. Teukolsky, and William T. Vetterling.
Numerical Recipes: The Art of Scientiﬁc Computing. Cambridge University Press,
Cambridge, UK, 1986.
14. Katya Rodr´ıguez-V´azquez, Carlos M. Fonseca, and Peter J. Fleming. Multiob-
jective Genetic Programming : A Nonlinear System Identiﬁcation Application. In
John R. Koza, editor, Late Breaking Papers at the Genetic Programming 1997 Con-
ference, pages 207–212, Stanford University, California, 1997. Stanford Bookstore.
15. A.S. Weigend, D.E. Rumelhart, and B.A. Huberman. Generalization by weight-
elimination with application to forecasting. In R.P. Lippmann, J.E. Moody, and
D.S. Touretzky, editors, Advances in Neural Information Processing Systems, vol-
ume 3, pages 875–882, San Mateo, CA, 1990. Morgan Kaufmann.
16. M. Zweig and G. Cambell. ROC plots: A fundamental evaluation tool in clinical
medicine. Clinical Chemistry, 39(4):551–577, 1993.

A Novel Face Recognition Method
Li Bai and Yihui Liu
School of Computer Science & IT
University of Nottingham
Nottingham NG8 1BB, UK
bai@cs.nott.ac.uk
Abstract. This paper introduces a new face recognition method that
treats 2D face images as 1D signals to take full advantages of wavelet
multi-resolution analysis. Though there have been many applications of
wavelet multi-resolution analysis to recognition tasks, the eﬀectiveness
of the approach on 2D images of varying lighting conditions, poses, and
facial expressions remains to be resolved. We present a new face recogni-
tion method and the results of extensive experiments of the new method
on the ORL face database, using a neural network classiﬁer trained by
randomly selected faces. We demonstrate that the method is computa-
tionally eﬃcient and robust in dealing with variations in face images. The
performance of the method also decreases gracefully with the reduction
of the number of training faces.
1
Introduction
In the past decade, considerable amount of research has been done on developing
face recognition methods. Recognizing faces in images and videos is an important
task with many applications, including access control, suspect identiﬁcation,
and content-based retrieval. It is a diﬃcult task because the appearance of a
face varies dramatically because of illumination, facial expression, head pose,
and image quality. To further compound the problem, we often have only a few
images of a person from which to learn the distinguishing features and then have
to recognize the person in all possible situations.
Face recognition methods may be categorised into three main approaches:
facial feature-based approach whereby biometric details of a face concerning the
eyes, nose, and mouth are extracted from the test face and matched against
those of the stored model faces; structural approach whereby face images are
represented as graphs and recognition relies on an elastic graph matching process;
holistic approach in which the whole face image (or its transformation) is passed
on to the classiﬁer.
Facial feature-based approach is the most intuitive approach to face recog-
nition. However, not only are normal facial features diﬃcult to extract but also
unreliable especially when there are signiﬁcant variations present in images. High
level features such as those based on texture, shape, or wavelet coeﬃcients have
been reported to perform better. Liu[4] proposes a method that uses both shape
J. Calmet et al. (Eds.): AISC-Calculemus 2002, LNAI 2385, pp. 128–135, 2002.
c
⃝Springer-Verlag Berlin Heidelberg 2002

A Novel Face Recognition Method
129
and texture information to assist face recognition. A shape vector is produced
for each face image though a manual process and a texture vector is produced
by warping each image to the average image of the whole training set. The shape
and the texture vectors produced are then combined to make the ﬁnal feature
vector for the image. Because of the high dimensionality of the face vectors
produced the eigenface method is employed to reduce the dimension.
The most well known structural approach to face recognition is the dynamic
link structure, ﬁrst proposed by Von Der Malsburg [9]. It belongs to the family
of elastic graph matching methods. Image points are sampled and those on a
rectangular grid are selected. Gabor wavelet responses at these selected image
points are taken as the features of the image. Initially image points of a test
face are randomly connected to those of a stored model and the connections are
then updated during the matching process. The goal of the matching process
is to maximise the similarity of Gabor wavelet responses, as well as the simi-
larity of topological relationships, at the image points of the test face and the
corresponding image points of the model face.
There have since been many variants of the dynamic link architecture as the
approach associates face images on the basis of their structural relationships.
The approach is believed to be robust to variations. However, Zhang et al’s [8]
experiments using elastic matching reports a 80% classiﬁcation accuracy on the
ORL face database using 5 faces per person for training and 5 for testing.
We mention the eigenface method [1][6] as an example of holistic approach to
face recognition. The purpose of this approach is to ﬁnd a set of basis vectors that
capture image variance more optimally than the Euclidean coordinate axes, in
order to reduce pixel correlation redundancy) therefore image dimension. These
basis vectors are called eigenfaces, and each face image is then represented by
its projection coeﬃcients onto the eigenfaces. As the number of eigenfaces is
much smaller than the number of pixels of an image, the dimension of face
vectors are thus reduced. The dimension can be reduced further by discarding
those eigenfaces corresponding to small eigen values. Experiments show that the
eigenface method is not robust in dealing with variations in lighting conditions.
Various attempts to improve the eigenface method have been made [3].
In summary, there is still the need to develop robust face recognition methods.
We present a robust face recognition method based on wavelets.
2
The Wavelet1D Method
Almost all the published face recognition methods based on wavelets use 2D
wavelet decomposition. This decomposes the approximation coeﬃcients at level
j into four components: the approximation at level j +1 and the details in three
orientations (horizontal, vertical, and diagonal). More precisely, the rows of the
jth approximation coeﬃcient matrix are convolved with both a low-pass ﬁlter
and a high-pass ﬁlter and the results are column downsampled (only even indexed
columns are kept); The columns of each downsampled results are then convolved
with both a low-pass and a high-pass ﬁlter and the results are row downsampled

130
L. Bai and Y. Liu
(only even indexed rows are kept). The resulting four matrix are the level j + 1
approximation and the details in three orientations. The size of each coeﬃcient,
either approximation or detail, at the 1st decomposition level is 1/41 that of
the original image, at the 2nd level 1/42, and at the 3rd level is 1/43 of that
of the original, and so on. Intuitively the decomposition coeﬃcients obtained
could be used to represent the original image, however, this would result in an
even higher dimensional face vector than the original face vector. This is because
that the combined size of 1st level coeﬃcients alone (both approximation and
details coeﬃcients) is equal to that of the original image, and to represent the
original image suﬃciently one would have to use the decomposition coeﬃcients
at several levels. Some researchers abandon coeﬃcients and resort to extracting
facial features from approximation and detail images instead [2], which we believe
suﬀers the same problem as extracting features from the original image.
We propose a more eﬀective method, namely the wavelet1D method. We
begin by producing 3 approximation images ˜ζi1, ˜ζi2, ˜ζi3 for each m×n face image
ζi and replace ζi with the average of the approximation images: ζi = 1/3  ˜ζij
We then turn ζi into a 1D vector by coalescing its row vectors ζi = (ζkj), where
k = 1 →m, j = 1 →n. Finally we decompose ζi to the 5th level and take the
approximation coeﬃcients at that level as the feature vector for the image. The
feature vector is shown in Fig.1 below.
Fig. 1. Facial feature extraction
3
Neural Network Classiﬁer
We use a radial basis function network to classify the images. The network has
two layers of neurons. Each neuron in the hidden layer is created for an input
vector and implements the radial basis transfer function. The weight vectors

A Novel Face Recognition Method
131
connecting the input to the hidden layer neurons are the transpose of the input
matrix. Input to a hidden layer neuron is therefore the distance between the
input vector and the weight vector connecting to the hidden layer neuron. If
the distance is small the output of the hidden layer neuron is 1 otherwise 0.
The second layer neurons implement the linear transfer function and the weight
vectors connecting to the second layer neurons are calculated using the input
(so radial basis function outputs) and the target matrices.
A neural network normally associates an input object with its class, not
necessarily with any concrete object of the class in the training set. As there are
10 varying faces per subject in the ORL face database it would be useful to know
the nearest object to the input. To make this possible we use a composite network
with several networks linked into a hierarchical structure. The subnetwork at
the ﬁrst level of the hierarchy is the normal radial basis function network that
associates a test input with one of the 40 classes. The 40 subnetworks at the
second level of the hierarchy are created for the 40 classes to associate the input
with the nearest object of its class. Each of the second level subnetworks is
trained separately with the faces of its own class. Its ﬁrst layer implements
the normal radial basis transfer function and the second layer implements the
competitive transfer function and its second-layer weights are set to the matrix
made of target vectors.
4
Experiments
We present our experimental results of the wavelet1D method. We use the ORL
face database for the experiments. The ORL database is created at the Olivetti &
Oracle Research Laboratory in Cambridge. It contains 400 face images altogether
with 10 face images for each of the 40 individuals. It is by far the most challenging
database for face recognition, covering variations in lighting condition, facial
expression, head pose (±200), and eye ware. These variations occur even across
the images of the same individual. The experiments are extensive because several
parameters have to be optimised for both wavelet feature extraction and the
neural network classiﬁer.
With the wavelet1D method we need to decide on the level to which an
image should be decomposed to produce meaningful and robust features for
classiﬁcation. There is no better way of doing this other than decomposing each
image to the 4th, 5th, and the 6th level and observe classiﬁcation results using
the features extracted at each level.
For the neural network classiﬁer, ﬁrstly, we have to decide which faces to use
to train the neural network classiﬁer. Some researchers manually select training
faces of each class in order to cover most of the variations of the class. This would
mean that invariance is the result of crafty network training rather than the
inherent property of the method. To demonstrate that our method is invariant
to variations we select training faces purely by random and use whatever left
afterwards to test the network. Secondly, the number of training faces and the
radial basis function network spread parameter need to be set. Most of the

132
L. Bai and Y. Liu
published works on the ORL face database use 5 faces per class for training and
5 for testing. To demonstrate that our method works well with fewer training
faces, we do three sets of tests using the training/testing ratios 5/5, 4/6, and 3/7
respectively. In the 5/5 test there are 200 training faces, 200 test faces, in the
4/6 test there are 160 training faces, 240 test faces, and in the 3/7 experiment
there are 120 training faces and 280 test faces. We run each of these tests several
times with diﬀerent network spread values to decide on the best value of network
spread.
As stated above we need to conduct three sets of tests corresponding to the
three training/testing ratios 5/5, 4/6, and 3/7, and for each of these three tests
we need to ﬁnd the best wavelet decomposition level by decomposing face images
to the 4th, 5th and 6th level respectively and observing the performance at each
level. The dimensions of face vectors at these three decomposition levels are 658,
336 and 175 respectively. Thereafter for each of the test and level combination
we also try a few network spread values to ﬁnd the best. The best performance
is achieved at level 5 for each of the three tests.
We now make the test results more transparent by showing in Figure 2,3,4
the classiﬁcation errors of the three tests, using the optimal decomposition level
5. For the 5/5 test we show the four wrongly classiﬁed faces. For the 4/6 and
3/7 tests, rather than showing the images involved, we use network activation
graphs and misclassiﬁcation graphs to illustrate the errors.
The activation graph plots the output values of the radial basis function. The
output values describe the classes of the test faces. The network gives 40 output
values, representing network certainty values of the test face being of each of the
40 classes. Ideally only one output should be 1 and all others should be 0, but
this extreme case will only happen if the test face is one of the training face.
Typically nearly all the neurons respond to a test face so we pick the neuron
that gives the maximum response to the test face and the test face is associated
with the class represented by that neuron. The ’*’s in the graph represents the
maximum output value when the test face is correctly classiﬁed and the ’o’s in
the graph represents the maximum output value when the test face is wrongly
classiﬁed. For example in the third column there is one ’o’. It means that one
of 6 test faces of class 3 is wrongly classiﬁed, the maximum output value is
around 0.3. The activation graph is divided into 40 columns. For the 4/6 test
the activations of 6 test faces are distributed in a column, for the 3/7 test 7
faces in a column. The misclassiﬁcation graph shows the test face of which class
is wrongly classiﬁed as which other class.
5
Discussion
Most of the published face recognition results on the ORL face database use
the 5/5 ratio for classiﬁer training and testing, there is no mentioning how the
methods perform when the number of training faces is reduced. We have given
performance statistics of our method for varying training/testing ratios using
randomly selected training faces. The results demonstrate that our method is

A Novel Face Recognition Method
133
Fig. 2. Mis-classiﬁed faces of the 5/5 test (4 errors, 98% accuracy)
Fig. 3. Mis-classiﬁed faces of the 4/6 test (8 errors, 96.67% accuracy)
accurate and performs well with a small number of training faces. To put this in
perspective we mention two of the methods that produce comparable accuracy
to our method. One is Tolba’s [5] that has achieved a 99.5% recognition rate
on the ORL face database using 5 training faces per class, by combining multi-
classiﬁers, the Learning Vector Quantization and Radial Basis Function network,
as well as by multi-training of these classiﬁers. The classiﬁers are trained with
the original training data as a whole ﬁrst, then again with two groups of data

134
L. Bai and Y. Liu
Fig. 4. Mis-classiﬁed faces of the 3/7 test (20 errors, 92.86% accuracy)
by splitting the original training set. One group contains previously correctly
identiﬁed data and one previously wrongly identiﬁed. Thereafter, a front-end
classiﬁer has to be trained on the outputs of the two classiﬁers to produce the
ﬁnal classiﬁcation. Both their two classiﬁers assign some test faces to classes
that bear little resemblance to the test faces. The other is O.de Vel’s line-based
method [7] that extracts image features by sampling the image (assuming the
boundary of the face is known) with a set of line segments and take some pixel
values on the line segments. The number of sampling line segments and the
positions of them on the face make a dramatic diﬀerence to the performance,
so both the training and recognition process have to be repeated on an image
many times with diﬀerent line populations before a classiﬁcation decision can be
made. The classiﬁer is trained by manually selected 5 training faces from each
class, and the selected training faces cover variations in head positions and facial
expressions.
References
1. P. Belhumeur et al: Eigen Faces vs. Fisherfaces. Recognition Using Class Speciﬁc
Linear Projection. IEEE Transactions on Pattern Analysis and Machine Intelligence,
Vol. 19, July 1997
2. C.Garcia, G.Zikos, G.Tziritas: Wavelet packet analysis for face recognition. Image
and Vision Computing, 18(2000) 289-297

A Novel Face Recognition Method
135
3. P.McGuire and M.T.D’Eluteriom: Eigenpaxels and a neural network approach to
image classiﬁcation. IEEE Tansactions on Neural Networks, VOL.12, NO.3, May
2001
4. Chengjun Liu, Harry Wechsler: A Shape and Texture Based Enhanced Fisher Clas-
siﬁer for Face Recognition. IEEE Transactions on Image Processing, VOL.10, NO.4,
April 2001
5. A. S. Tolba and A.N.Anu-Rezq: Combined Classiﬁers for Invariant Face Recognition.
0-7695-0446-9/99, 1999
6. M.Turk, and A.Pentland: Eigenfaces for Recognition. Journal of Cognitive Neuro-
science, 3 (1), 1991
7. Olivier de Vel and Stefan Aeberhard, Line-based Face Recognition under Varying
Pose. IEEE Transactions on Pattern Analysis and Machine Intelligence, VOL.21,
NO.10, October 1999
8. J.Zhang, Y.Yan, and M. Lades. Face Recognition: Eigenface, Elastic Matching, and
Neural Nets. Proc. IEEE, VOL.85, 1997
9. Von der Masburg C, Pattern recognition by Labeled Graph Matching. Neural Net-
works, vol. 1, 141-148, 1988

Non-commutative Logic for Hand-Written
Character Modeling
Jacqueline Castaing
Galil´ee University, LIPN-UMR 7030
93430 Villetaneuse, FRANCE,
jc@lipn.univ-paris13.fr
Abstract. We
have
proposed
a
structural
approach
for
on-line
handwritten character recognition. Models of characters are writer-
dependent. They are codiﬁed with the help of graphic primitives and
represented in a data base. The originality of our approach comes from
the ability for the system, to explain and justify its own choice, and to
deal with all diﬀerent writing systems, such as the Latin alphabet, or the
Chinese or Japanese scrip for example, providing that an appropriate
data base has been built up. For this reason, our recognizer can be
very helpful for learners of “exotic” scripts. In this paper, we propose
to analyse the recognition process in an appropriate logical framework,
given by non-commutative Logic. We ﬁrst point out the class of sequents
which allows us to describe accurately the recognition process in terms
of proofs, then, we will give some results about the complexity of
the recognition problem depending on the expressive power of the
representation language.
Keywords: Linear Logic, Character Recognition, Distance Computing,
Proofs
Topics: Foundations and Complexity of Symbolic Computation, Logic
and Symbolic Computing
1
Introduction
We have proposed in [4] a structural approach for on-line handwritten character
recognition. Models of characters are writer-dependent, They are codiﬁed with
the help of graphic primitives. As our recognizer is dedicated to learners of
“exotic” scripts, the Chinese or Japanese one see [3] for example, the primitives
are chosen in order to point out the speciﬁc features of the Master’s models. So,
learners have just to reproduce the good models. The originality of our approach
comes from the ability of our recognizer to explain and justify its own choice,
and to deal with all diﬀerent writing systems, providing that an appropriate data
base has been built up. The classiﬁcation (or recognition) of an input character I
is then carried out by computing distances between I and the models represented
in the data base. As the number of models introduced in the data base may be
very high, we use a symbolic learning algorithm see [2], to extract from the
knowledge base a smaller number of more general models.
J. Calmet et al. (Eds.): AISC-Calculemus 2002, LNAI 2385, pp. 136–153, 2002.
c
⃝Springer-Verlag Berlin Heidelberg 2002

Non-commutative Logic for Hand-Written Character Modeling
137
We ﬁrst attempted to formalize our approach by means of classical logic.
But standard logic, with contraction and weakening rules, doesn’t allow us to
analyse accurately the classiﬁcation procedure. In this paper, we show how we
use Ruet’s non-commutative Logic see [18], to build a logical system in order to
achieve our goal. The logical rules of the system are selected mainly to facilitate
the design of the recognition procedure. Input characters have now a straight-
forward representation by means of formulas of the form P1 •...• Pn, where the
strokes P1,..., and Pn, separated by the non-commutative conjunctive operation
• neither can disappear nor can be duplicated. Proofs can then be carried out,
step-by-step, related to the rules involved.
In section 2 of this paper we present a survey of OCR (Optical Character Recog-
nition); so, the reader can evaluate the originality of our work. In section 3 we
indicate how from the numerical coding we get the symbolic representation of
handwritten characters. We only deal with Latin letters. In section 4, we in-
troduce the character recognition procedure and we will give some experimental
results. Section 5 presents the non-commutative linear system. Section 6 analyses
recognition process by means of proofs Finally, section 7 examines complexity
results and makes clear what can be learnt from our theoretical approach. The
symbolic learning algorithm used is out of scope of this paper. For a good under-
standing of sections 5 and 6, we suppose that the reader is familiar with (linear)
sequent calculus.
2
A Quick Survey of OCR (Optical Character
Recognition)
In OCR, diﬀerent approaches depending on the type of data, handwritten or
printed characters, and on the application considered have been investigated
see [20]. In the case of printed characters, the recognition rate is about 98%
for monofont texts, and varies between 80% and 98% for multifont texts. In
the case of handwritten characters, oﬀ-line and on-line recognition methods are
distinguished. For oﬀ-line recognition the reader can refer to [21]. In our frame-
work, we are only interested in on-line recognition. A handwriting recognition
system can further be broken down into the categories of writer-dependant, or
writer-independant. A writer-independant system is trained to recognize hand-
writing in a great variety of writing styles, while a writer-dependant system is
trained to recognize handwriting of a single individual. The inﬁnite variations
of shapes limit the recognition rate to 98% for word recognition. For isolated
character recognition (neither grammar nor dictionary is used), the recognition
rate can get low to 88%. Some particular applications such that the interface
for Personal Digital assistant (PDA) may reach the score of 99%, but on unnat-
ural character set (e.g., graﬃti). The technologies usually employed are based
on stochastic methods, such as hidden Markov model (HMM) ﬁrst developped
for speech recognition [15], on connectionist methods [11], and on k nearest
neighbors procedure. Some approaches permit to take into account the struc-
tural information. Frey & Slate method [7], can be compared to our approach

138
J. Castaing
as they use graphic primitives and rules of the form “IF ... THEN”. However,
their method only deals with printed characters.
We give below some recent results taken from [6]. Table 1 shows some isolated
character recognition accuracies. Table 2 gives recent outcomes for handwrit-
ten word recognition. The lack of common datasets makes it very diﬃcult to
Table 1. Some recent results on isolated character recognition
Author
Method
Accuracy
Comments
Scattolin
Nearest Neighbor
88.67%
33 writers used
& Krzyzak [19]
Chan
Manually Designed
97.4%
150 writers used
& Yeung[5]
Structural Models
Prevost
Combined Online
96.4%-98.7% data from
& Milgram [14] and Oﬄine Nearest Neighbor
Unipen data used
Classiﬁers
Table 2. Some recent results on handwritten word recognition
Author
Method
Accuracy
Comments
Nathan
Hidden
81.1% on
25 writers
& al. [12]
Markov Model unconstrained
Writer-independent.
word examples
21K word vocab.
Rigoll
Hidden
95% on
Writer-dependant
& al.[16]
Markov Model 200 examples
3 writers
30K vocab.
Hu, Brown
Stroke-
94.5 on %
Writer-independant.
and Turin [10] level HMM
3,823 unscontrained 18 writers
word examples
32 word lexicon
compare these results. (At the time of these results, the database coming from
Unipen project was not publicly available for word examples).
In handwritten word recognition, many approaches consist in chaining char-
acter models together to form words. For these methods, a necessary step is the
process of segmenting the input in such a way that isolated characters can be
presented to the recognition system. So, the style of writing (in particular cursive
handwriting) makes the problem of segmentation very diﬃcult.

Non-commutative Logic for Hand-Written Character Modeling
139
Our motivation is two-fold. First, we are obviously concerned with how to
recognize handwritten data correctly. Second, and more fundamentally, we are
concerned with how to explain the recognition step in order to help learners
to master diﬀerent writing scripts. To this end, we provide a recognition sys-
tem which is writer-dependant, in fact Master-dependant. The data base only
contains character models. Our approach is based on distance computing, the
isolated character recognition rate is 94,3%. We also run our experimentation
on small test sets containing 120 words from a total word lexicon of 400 words.
We obtained word recognition rates up to 90% by restricting the segmentation
hypotheses.
We now describe our approach.
3
Knowledge Representation
An electromagnetic data tablet is used as an input device. The tablet samples
pen movement in terms of x,y-coordinate values, and det.
3.1
Numerical Representation
Each character written down is numerically represented by sets of coordinate
values separated by pen-up and pen-down marks.
Example 1. The character “a” (see Fig.1) has the following numerical represen-
tation:
Pen-Up
// “a”
Pen-Down
(38 114) (34 113) (33 113 ) (32 114) ..... (43 125) (44 125)
Pen-Up
Fig. 1. The character “a”
For our experimental evaluation, we use a numerical data base built up by the
author of this paper. Each latin character is written down two hundred times.
3.2
Symbolic Representation
The choice of a symbolic codiﬁcation can be driven by a variety of considerations.
As we aim at helping learners, we choose primitives in order to point out the
writing order of the strokes in a character, and to describe the cursive forms

140
J. Castaing
of characters. In our experimentation involving the latin letters, we select the
following primitives:
1. To capture the direction of the strokes drawn by the graphic pen, we borrow
from Freeman’s alphabet the graphic primitives. The Freeman’s alphabet
used(see Fig. 2) has eight directions denoted numerically by the number 0,
1, 2, 3, 4, 5, 6, 7, and symbolically by the primitives h, f, t, e, k, g, d and v.
As our method is based upon some distance between graphic primitives, we
give the following deﬁnition:
Deﬁnition 1. The distance between two graphic primitives p1 and p2, de-
noted by |p1, p2|, is the minimal number of steps to take for reaching p2 from
p1, depending on the way taken to reach p2 from p1 (clockwise or counter-
clockwise in the ﬁgure Fig.2).
h
f
t
e
k
g
v
d
Fig. 2. Freeman’s Alphabet
2. To this basic alphabet, we add “cultural” elements, called descriptive primi-
tives which are the following one: the primitives s, o, u, x mark respectively
the absence of hole, the presence of one hole, the presence of two holes, the
presence of three holes or more; the primitives q and r are related to the size
of the holes; the primitives i, j, w give the position of the last stroke (high-
est, lowest, medium position); the two last primitives z and y corresponds
to pen-up signal (presence or absence). So, characters in the data base are
codiﬁed with the help of primitives deﬁnite over an alphabet of 19 letters P
= { h, f, t, e, k, g, v, d, s, o, u, x, q, r, i, j, w, y, z}. Let us give an example.
Example 2.
The character “a” (see Fig.3) is described by the string “gdfvh”. Its par-
ticular cursive form can be fully captured by the sequence “oqqrrrjy”. The
symbolic code of “a” is then given by the string “gdfvhoqqrrrjy”.
Deﬁnition 2. The distance between two descriptive primitives, denoted by
⌊p1, p2⌋, is given by:
if p1 = p2 then ⌊p1, p2⌋= 0 otherwise ⌊p1, p2⌋= 1.

Non-commutative Logic for Hand-Written Character Modeling
141
g
d
f
v
h
Fig. 3. Symbolic Representation of the character “a”
3. The size of the strings is normalized to 22: if the length of a string is less
than 22, we duplicate the Freeman’s values corresponding to the strokes of
greatest length untill to reach the ﬁxed value 22.
Example 3. So, the complete representation of our character “a” is now given
by the string: “gggdddﬀﬀvvvhoqqrrrjy”.
3.3
Logical Representation
If we interprete normalized strings with the help of standard connectives, con-
junction(&) and implication (→), we may infer g & g →g, and f & g →g
& f from the deﬁnition of the connective &. If standard conjunction is roughly
applied to graphic primitives, strokes may disappear in a string, and/or the writ-
ing order may no longer be respected. To avoid this “bad” eﬀect, we propose
to transform the representation of strings. In section 6, we will introduce the
appropriate logical framework based upon non-commutaive Logic.
From the initial alphabet of primitives P, we deﬁne a set of new predicates, pi,j,
(i = 1, 22 et j = 0, 18), to mean that the primitive Pj occurs at the ith position
of a string. Each normalized string is interpreted by the conjunctive formula W
= 22
k=1 pk,ik, where i1, ..., i22 ∈{0, 18}, and the conjunction ∧is the standard
one. From now in our paper, a string refers to such a normalized conjunctive
form.
To mean that a string W is used to codify a latin letter L deﬁnite over the set of
latin letters LL, LL= {A,...,Z}, we invoke Horn clauses, i.e, clauses of the form
L →R, where the premise L is W, the conclusion R is L, and the implication
→is the standard one.
Example 4. The character “a” given in the previous example has the following
meaning in our knowledge data base:
p1,5 ∧p2,5 ∧p3,5 ∧p4,7 ∧p5,7 ∧p6,7 ∧p7,1 ∧p8,1 ∧p9,1 ∧p10,1 ∧p11,6 ∧p12,6 ∧p13, 6∧
p14,0 ∧p15,9 ∧p16,12 ∧p17,12 ∧p18,13 ∧p19,13 ∧p20,13 ∧p21,15 ∧p22,17 →A.
Distances between primitives are captured by means of formulas involving im-
plication. We will make clear this idea in section 7 by means of proof-trees.
– If the distance between two primitives p1 and p2 is equal to 1, we set p1 →p2.
– In the general case, the transitivity of the connective →is invoked to compute
the distance between two graphic primitives p1 and p2.
– Let E be the set of implications introduced. In our application, the cardi-
nality of E is et to the value 49, C(E)= 49 depending on the number of
primitives involved.

142
J. Castaing
We show now, how we proceed to classify input characters by means of these
formulas.
4
Recognition Process
Let us begin with a deﬁnition. Let I and J be two strings. I= 22
k=1 pk,ik and J
= 22
k=1 pk,jk
Deﬁnition 3. We extend the notion of distance deﬁnite over the set of prim-
itives to the strings I and J. The distance between I an J denoted by ∥I, J ∥is
given by:
∥I, J ∥= ∥I, J ∥1,14 + ∥I, J ∥15,22, where ∥I, J ∥1,14 = 
k=1,14 |pk,ikpk,jk|,
and ∥I, J ∥15,22 = 
k=15,22⌊pk,ikpk,jk⌋
Example 5. Let a0 = p1,5 ∧p2,5 ∧p3,5 ∧p4,7 ∧p5,7 ∧p6,7 ∧p7,7 ∧p8,1 ∧p9,1 ∧p10,1 ∧
p11,1∧p12,6∧p13, 6∧p14,6∧p15,9∧p16,12∧p17,12∧p18,13∧p19,13∧p20,13∧p21,15∧p22,17,
and
a1 = p1,4 ∧p2,4 ∧p3,5 ∧p4,6 ∧p5,6 ∧p6,7 ∧p7,7 ∧p8,1 ∧p9,1 ∧p10,1 ∧p11,12 ∧p12,6 ∧
p13, 6 ∧p14,7 ∧p15,9 ∧p16,12 ∧p17,12 ∧p18,13 ∧p19,13 ∧p20,13 ∧p21,15 ∧p22,17, be
two variants of the same letter a. The distance between a0 and a1, ∥a0, a1 ∥=
|p1,5p1,4| + |p2,5p2,4| + |p4,7p4,6| + |p5,7p5,6| = 4 .
We ﬁrst sketch the recognition process informally, then we will detail further.
4.1
Basic Idea
Let I be the input character to be classiﬁed, I = 22
k=1 pk,ik Let L ∈LL be a
letter codiﬁed in the data base by means of the family of clauses Li →L, i
=1,200. We proceed as follows:
1. For each letter L ∈LL, we compute the mean distance between I and L
given by the formula: DL=
1
200
200
k=1∥I, Li ∥.
2. Let L0 ∈LL be such that : DL0 = min (DL), L ∈LL (If L0 is not unique,
we consider the ﬁrst letter in the alphabetical order). The input character I
is identiﬁed with the letter L0.
4.2
What We Have Implemented
To achieve the recognition process in some bounded time, we have reduced the
number of rules in the data base, not only by removing redundant rules but also
by generalizing them with the help of our learning algorithm.
Example 6. Let us consider again the clause corresponding to the character “a”
given in the previous examples, p1,5 ∧p2,5 ∧p3,5 ∧p4,7 ∧p5,7 ∧p6,7 ∧p7,7 ∧p8,1 ∧
p9,1 ∧p10,1 ∧p11,1 ∧p12,6 ∧p13, 6 ∧p14,6 ∧p15,9 ∧p16,12 ∧p17,12 ∧p18,13 ∧p19,13 ∧
p20,13 ∧p21,15 ∧p22,17 →A.
Our learning algorithm generalizes this rule into a more general one of the fol-
lowing form:
p1,5 ∧p5,7 ∧p20,13 →A.

Non-commutative Logic for Hand-Written Character Modeling
143
So, in our experimentation, from the set of rules of the form Li →L, we point
out a smaller subset of rules, (253 rules), of more general form L′
i →L, where
the premises Li and L′
i are linked by the formula Li →L′
i. Those of the predi-
cates of Li which remain in the premise L′
i are called relevant predicates. The
recognition process is carried out in the same way as indicated in section 3.1 by
focusing only on relevant predicates. It means that when we compute the dis-
tance between strings, we set to 0 the distances between non relevant predicates.
Let nL be the respective number of new rules pointed out by our learning al-
gorithm for each class of latin letter L ∈LL. Our solution can be sketched as
follows:
1. For each letter L ∈LL, we compute the mean distance between the input
character I and L given by the formula: DL=
1
nL
nL
i=1 ∥I, Li ∥.
2. Let L0 ∈LL be such that : DL0 = min (DL), L ∈LL (If L0 is not unique,
we consider the ﬁrst letter in the alphabetical order). The input character I
is identiﬁed with the letter L0).
4.3
Experimental Results
We give the results obtained by our recognizer compared to those obtained with
the k nearest neighbors procedure (kNN) using the same data bases. The exper-
imental evaluation is based on a standard “cross-validation”. We have a set of n
instances (n = 3240). We have iterated 40 times the following procedure: i) n*0.9
instances are randomly selected; the other instances are used as test instances,
ii) learning, iii) testing. Thus, we report hereunder averages on 40 trials. Our
results are summerized in arrays of 4 lines. The ﬁrst line gives the recognition
rates of our recognizer and the kNN procedure. The second line gives the number
of rules learned, third line the number of premises of these latter, and the last
line the learning time.
Table 3. Comparison with KNN
Method Accuracy Nb of rules Nb of Premises Learning time
OURS
0.943
253
14
1516 seconds
kNN
0.955
3240
22
0
4.4
First Conclusion
We can formally describe the recognition process by means of proofs involv-
ing Horn clauses, for instance by applying the Robinson’s method [17] called
resolution. But, this approach doesn’t allow us to :

144
J. Castaing
– capture fully the recognition process without “trick” (transformulation of
formulas)
– analyse accurately the recognition problem in order to answer to the follow-
ing questions:
• what happens if we don’t normalize strings,
• and how to analyse the complexity of the recognition problem depending
on the expressive power of the representation language.
5
Non-commutative Logic for OCR: N CLocr
In this section, we introduce the logical framework NCLocr in which proofs are
carried out. The representation of written characters is now straightforward by
using the non-commutative conjunction • and the linear implication ⊸.
5.1
Preliminary
In Gentzen calculus, the structural rules - exchange, contraction and weakening-
are explicitly applied. In Girard’s logic [9], the contraction and weakening rules
are forbidden: an immediate repercussion is the distinction of two connectives for
conjunction ⊗(times), & (with), and two connectives ℘(par), ⊕(plus) for dis-
junction. But, unrestricted exchange rules force the commutativity of these con-
nectives. In some applications in computer science, such as in our application, we
actually desire non-commutative connectives. Some works on non-commutativity
can be found in [1]. In Ruet[18], two equivalent versions of non-commutative lin-
ear calculus have been introduced. The ﬁrst version is deﬁned on presentations,
i.e, partial orders; the second version works with order varieties of occurrences
of formulas. In practice, we work with a fragment of the ﬁrst version because the
structural rules used, seesaw and entropy presented below (section 4.4), allow us
to explicitly change the presentation, so we can focus on any formula to apply a
rule, and to apply cyclic exchange.
5.2
Language
The formulas of NCLocr are built from the latin letters A,..., and Z, the set of
primitives P, the constant ⊤, the negation ⊥, and the following linear connec-
tives: (we just give those we need)
– non-commutative (but associative) conjunction • (next) and disjunction
∇(sequential),
– commutative multiplicative conjunction ⊗(times) and disjunction ∂(par),
(obviously associative)
– exponentials !(of course) and ? (why not).
De Morgan rules hold, so we have the following results:
– (p)⊥= p⊥, (p⊥)⊥= p, where p is an atom,

Non-commutative Logic for Hand-Written Character Modeling
145
– (A • B)⊥= B⊥∇A⊥(A∇B)⊥= B⊥• A⊥
– (A ⊗B)⊥= B⊥∂A⊥(A∂B)⊥= B⊥⊗A⊥
– (!A)⊥= ?A⊥(?A)⊥= !A⊥.
For any formula A, we have A = A⊥⊥. We also use the linear implication ⊸
under the form A ⊸B = A⊥∂B.
With these connectives, NCLocr is a multiplicative fragment of non-commutative
logic.
5.3
A Formulation in N CLocr
Let us show now how the recognition problem can be formulated in NCLocr.
Normalized input characters I are then fully captured with the help of nexted
formulas of the form: (i1 • ... • (i21 • i22)...), where the primitives ik for k=1,22
belong to the set P. As the connective • is associative, we can set I = (i1•...•i22).
In such a formula, the graphic primitives involved follow each other according
to the rewriting order introduced by the pen movement; and in absence
of the contraction and weakening rules, these primitives can neither disappear
nor be duplicated.
Distances between connected primitives are captured by means of rewriting rules:
– E1= {h ⊸f, f ⊸h ... d ⊸h, h ⊸d }, for graphic primitives.
– E2= {s ⊸o, o ⊸s, ..., y ⊸z, z ⊸y }, for descriptive primitives.
The set E = E1 ∪E2 of rewriting rules gives the context in which proofs ared
carried out.
Clauses in the data base have the following meaning :
(l1 •...•l22) ⊸L. where only relevant primitives appear in the premise, the non
relevant ones being set to the constant value ⊤(which holds for any predicate).
Let us give an example of representation in NCLocr.
Example 7. The character “a” represented in standard logic by the clause (see
Example-4) :
(p1,5 ∧p2,5 ∧p3,5 ∧p4,7 ∧p5,7 ∧p6,7 ∧p7,1 ∧p8,1 ∧p9,1 ∧p10,1 ∧p11,6 ∧p12,6 ∧
p13,6 ∧p14,0 ∧p15,9 ∧p16,12 ∧p17,12 ∧p18,13 ∧p19,13 ∧p20,13 ∧p21,15 ∧p22,17) →A.
has the following more appropriate meaning:
(g • g • g • d • d • d • d • f • f • f • f • v • v • v • o • q • q • r • r • r • j • y) ⊸A,
A generalized form of the character “a” may then be represented as follows:
(g • ⊤• ⊤• ⊤• ⊤• d • ⊤... • ⊤• r • ⊤• ⊤) ⊸A, where the constant ⊤holds for
any predicate.
Let I = ((i1 • ... • (im−1 • im)...) be the linear representation of an input
character; let L be the premise of a clause: L= ((l1 • ... • (ln−1 • ln)...)
Instead of computing the distance between I and L, ∥I, L ∥(for m =n = 22),
we propose to carry out the proofs of the sequents !E, I ⊢L, where !E means
that we can apply the rewriting rules of the context E the number of
times we need in the proofs. In the next section, we will show that the main
step of our recognition process, can be in fact achieved formally by means of

146
J. Castaing
proofs of this family of sequents. As we only deal with right-hand side sequents,
we transform the formulas with the help of De Morgan rules. The dual of the
formula I is
I⊥= ((i1 • ... • (im−1 • im)...)⊥= (...(i⊥
m∇i⊥
m−1)...)∇i⊥
1 ).
Each !ed formula of the set E has a dual in the set ∆which then contains the
following formulas: {(f ⊥⊗h), (h⊥⊗f), ..., (z⊥⊗y), (y⊥⊗z)}. So, we are left
with sequents of the form ⊢?∆, I⊥, L to be proved in the calculus we introduce
now.
5.4
Rules
Sequents are of the form ⊢Γ, where Γ is a partially ordered set of occurrences
of formulas.
– Identity-Cut
⊢A⊥, A
⊢Γ, A
⊢A⊥, ∆
⊢Γ, ∆
cut
– Structural Rules
⊢Γ, ∆
⊢Γ; ∆seesaw
⊢Γ[∆; Σ]
⊢Γ[∆, Σ]entropy
⊢Γ[?∆, Σ]
⊢Γ[?∆; Σ]center1
⊢Γ[∆, ?Σ]
⊢Γ[∆; ?Σ]center2
– Non-commutative Rules
⊢Γ; A
⊢B; ∆
⊢Γ; A • B; ∆
•
⊢Γ; A; B
⊢Γ; A∇B ∇
– Commutative Rules
⊢Γ, A
⊢B, ∆
⊢Γ, A ⊗B, ∆
⊗
⊢Γ, A, B
⊢Γ, A∂B ∂
– Exponentials
⊢Γ, A
⊢Γ, ?Ad
⊢?Γ, A
⊢?Γ, !A!
⊢Γ, ?A, ?A
⊢Γ, ?A
c
⊢Γ
⊢Γ, ?Aw
– Constant
⊢Γ, ⊤
Remark 1. About seesaw: It is the key of the system. It is reversible and its
inverse, called co-seesaw, is a particular case of entropy:
⊢Γ; ∆
⊢Γ, ∆co-seesaw

Non-commutative Logic for Hand-Written Character Modeling
147
Together, they imply cyclic exchange in the usual sense. Intuitively the seesaw
rule means that proofs with at most 2 conclusions can freely pivotate, thus for
such subproofs of a larger proof, commutative and non-commutative composi-
tions should be indistinguishable.
For proofs with more than two conclusions, only cyclic exchange is permitted,
for instance the sequent ⊢(Γ; ∆); Σ) can be mapped to ⊢Σ; (Γ; ∆)) but not to
⊢(∆; Γ); Σ). In this general case, commutative and non-commutative composi-
tions are to be distinguished.
Remark 2. About the Constant rule: we restrict the use of the Constant
rule to the case where the set of formulas Γ contains only one negative atomic
formula.
The usual general results about Cut elimination and Gentzen’s subformula prop-
erty hold obviously.
Let us give now some examples of proofs in NCLocr.
Example 8. The sequent ((g • d) • f) ⊢(g • (⊤• f)) mapped to the sequent
⊢(g • (⊤• f), (f ⊥∇(d⊥∇g⊥)) is provable in NCLocr without applying rewriting
rule.
We proceed as follows:
– We ﬁrst apply the entropy rule, then we apply twice the ∇rule follow by
the seesaw rule :
⊢(g • (⊤• f)); f ⊥; d⊥, g⊥
⊢(g • (⊤• f)); f ⊥; d⊥; g⊥
⊢(g • (⊤• f)); f ⊥; (d⊥∇g⊥)
⊢(g • (⊤• f)); (f ⊥∇(d⊥∇g⊥))
⊢(g • (⊤• f)), (f ⊥∇(d⊥∇g⊥))
entropy
∇
∇
seesaw
– we exchange the formulas (it is a cyclic exchange) in ⊢(g•(⊤•f)); f ⊥; d⊥, g⊥
to obtain the sequent:⊢g⊥, (g • (⊤• f)); f ⊥; d⊥to be proved.
⊢g⊥; g
⊢(⊤• f); f ⊥; d⊥
⊢g⊥; (g • (⊤• f)); f ⊥; d⊥
⊢g⊥, (g • (⊤• f)); f ⊥; d⊥entropy
•
the sequent ⊢g⊥; g is an identity (after applying the seesaw) rule. We
are left with the sequent ⊢(⊤• f); f ⊥; d⊥to be proved. In order to do
a cyclic exchange, we again apply the seesaw rule to obtain the sequent
⊢(⊤• f); f ⊥, d⊥and, after exchanging the formulas, we are left with the
sequent ⊢d⊥, (⊤• f); f ⊥to be proved.
⊢d⊥; ⊤
⊢f; f ⊥
⊢d⊥; (⊤• f); f ⊥
⊢d⊥, (⊤• f); f ⊥e
•

148
J. Castaing
– it remains to apply the seesaw rule to obtain the sequents ⊢d⊥, ⊤and
⊢f, f ⊥, which proofs can be achieved easily by applying respectively the
Constant rule and the Identity rule.
Example 9. The sequent !E, g ⊢d mapped to ⊢?∆, g⊥, d is provable in NCLocr.
Only commutative rules are invoked.
– We apply recursively the weakening rule on ?ed formulas of ∆untill we
obtain the sequent ⊢?(v⊥⊗g), ?(d⊥⊗v), g⊥, d to be proved.
– Then, by applying the exponential rule (d) on the formula ?(v⊥⊗g), we
are left with the sequent ⊢(v⊥⊗g), ?(d⊥⊗v), g⊥, d to be proved. As the
formulas freely commutate, we map this sequent to the sequent ⊢d, ?(d⊥⊗
v), (v⊥⊗g), g⊥.
– We apply the ⊗rule on the formula (v⊥⊗g) for sharing context, so we obtain
the two sequents ⊢d, ?(d⊥⊗v), v⊥and ⊢g, g⊥to be proved. The latter is
an identity. Let us give the proof-tree of the sequent ⊢d, ?(d⊥⊗v), v⊥.
⊢d, d⊥
⊢v, v⊥
⊢d, (d⊥⊗v), v⊥
⊢d, ?(d⊥⊗v), v⊥d
⊗
We can conclude by applying the Identity rule twice.
6
Recognition in N CLocr
In this section, we characterize the proofs of the sequents ⊢?∆, I⊥, L; then, in
the next section we will list what can be gained from our theoretical approach
in terms of proofs.
6.1
Proofs in N CLocr
Lemma 1. There exists a cut-free proof of the sequent ⊢?∆, I⊥∂L in NCLocr
iﬀ:
1. m=n
2. for every k : 1 ≤k ≤m, the sequents ⊢?∆, i⊥
k , lk are provable.
Proof. For proving the lemma-1, we need the following result:
Lemma 2. The sequent ⊢?∆, I⊥, L is provable in NCLocr iﬀ:
the sequent ⊢?∆, i⊥
m; ...; i⊥
1 , ((l1• ... •(ln−1 • ln)...) is provable in NCLocr.
The proof of the lemma-2 is obvious, so we only focus on the proof of the lemma-
1.
1. Necessary Condition Let us suppose that there exists a cut-free proof
of the sequent ⊢?∆, i⊥
m; ...; i⊥
1 , ((l1 • ... • (ln−1 • ln)...); let us show that the
conditions 1) and 2) are then satisﬁed. We essentially use the induction
principle applied to proof-trees.

Non-commutative Logic for Hand-Written Character Modeling
149
a) Basic case: the proof-tree is a one-node tree. The sequent ⊢?∆, i⊥
k , lk , is
an axiom of NCLocr after applying weakening rules (w) to ?ed formulas.
The conditions i) and ii) are satisﬁed.
b) General case: let T be the proof-tree of the sequent ⊢?∆, i⊥
m; ...; i⊥
1 , ((l1•
... • (ln−1 • ln)...). The last rule applied may be (d), (w), (c), a struc-
tural rule (entropy, seesaw, center1, center2), ⊗(times) or the rule •
(next). The rules (d), (w), (c), (center1), (center2) only involve ?ed for-
mulas. The (entropy) or (seesaw) rules lead to cyclic exchanges. So, the
induction hypothesis holds and we can conclude easily in one of these
cases.
i. the last rule applied is ⊗: this connective only involves a for-
mula of ∆, let (p⊥⊗q) be this formula; the proof-tree T is then the
following one:
T1
T2
⊢Γ1, (p⊥⊗q), Γ2
⊗
A. proof of the condition 1) T1is the proof-tree of the sequent
⊢Γ1, p⊥. By the induction hypothesis, we have m1 = n1 and the
sequents ⊢?∆, i⊥
k1, lk1 are provable for every k1 : 1 ≤k1 ≤m1.
In particular, we can isolate the sequent ⊢?∆, p, p⊥, which is
provable too. This result also holds for T2 : we have m2 = n2, and
the sequents ⊢?∆, i⊥
k2, lk2are provable for every k2 : 1 ≤k2 ≤m2.
In particular, the sequent ⊢q, q⊥, ∆(obtained by exchanging) is
provable too. As the connective juxtaposes the contexts, we are
left with the following results: m = m1+m2−1 = n1+n2−1 = n;
then the condition i) is satisﬁed.
B. proof of the condition 2) We know that the sequents ⊢
?∆, i⊥
k1, lk1 and ⊢?∆, i⊥
k2, lk2 are provable for every k1 : 1 ≤k1 ≤
m −1, and for every k2 : 1 ≤k2 ≤m −1. Let us focus on the
pair ⊢?∆, p, p⊥and ⊢q, q⊥, ?∆. As they are provable we can ap-
ply the ⊗rule to prove the sequent ⊢?∆, p, (p⊥⊗q), q⊥, ?∆. By
iterating the contraction rule on ?ed formulas, we get the proof
of the sequent ⊢?∆, p, (p⊥⊗q), q⊥; by applying the (d) rule, we
prove the sequent ⊢?∆, p, ?(p⊥⊗q), q⊥, and at last, by applying
the contraction rule on the formula ?(p⊥⊗q) (which also has an
occurrence in ?∆), we satisfy the condition 2).
ii. the last rule applied is • (next) we can proceed in the same
manner because the contexts are also juxtaposed. So, from m1 = n1
and m2 = n2, we can conclude that m = m1 +n1 = m2 +n2, and for
every k: 1 ≤k ≤m, the sequents ⊢?∆, i⊥
k , lk are obviously provable
by using the induction hypothesis.
2. Suﬃcient Condition: we just give an idea of the proof of the sequent
⊢?∆, i⊥
m; ...; i⊥
1 , ((l1•...•(ln−1•ln)...). Let us suppose that the two conditions
1) and 2) are satisﬁed. From the sequents ⊢?∆, i⊥
k , lk, which are provable for
every i: 1 ≤k ≤m, the proof consists in iterating the application of the

150
J. Castaing
(next) rule, followed by some contractions on ?ed formulas combined with
cyclic exchanges.
7
What Is Gained by Carrying Out Proofs in N CLocr
What is learnt from our formal analysis can be outlined now. First, we are able
to evaluate accurately the complexity of our method. This point is not clear
at all for the approaches refered to in section 2. Second, we will show that the
word recognition problem is as diﬃcult to solve as the reachability problem for a
Petri net [13]; so, it still remains a challenge. We also will prove that segmenting
a word consists in either duplicating some stroke or removing another one in
this word. NCLocr is an appropriate framework to study the problem of word
segmentation.
7.1
Complexity of Our Approach
As our recognition process can be fully captured by means of proofs in NCLocr of
the sequents of the form: ⊢?∆, i⊥
m; ...; i⊥
1 , ((l1 •...•(ln−1 •ln)...), the two following
points are straigthforward.
1. From the condition 1) m = n of the lemma-1, we can conclude that the
strings manipulated in our system of recognition in the context of the
rewriting rules E must have the same length. This result justiﬁes our
choice to normalize all the input characters by giving them the same size
(set to 22).
2. From the condition 2) for every k : 1 ≤k ≤m, the minimal number of times
we apply the ⊗rule in the proofs of the sequents ⊢?∆, i⊥
k , lk can be used
to compute the distance between the two graphic primitives |ik, lk| (see the
deﬁnitions in section 3, and the Example-9). So, the distance between two
normalized strings can also be computed by means of depths of proof-trees.
As the formulas of ?∆are restricted to atoms of the language, the recognition
process can be achieved in linear time, depending only on the length m of
strings, and on the number of rewriting rules involved in the proofs of the
sequents ⊢?∆, i⊥
k , lk).
Moreover, we can carry out proofs faster with the help of our symbolic
learning algorithm because some sequents of the form ⊢?∆, i⊥
k , ⊤allow us to
conclude at once by applying the Constant rule.
7.2
Segmentation and Recognition
To illustrate the segmentation problem, we give an example of cursive writing
in which a number of consecutive characters may be written between the two
marks of pen-up and pen-down.

Non-commutative Logic for Hand-Written Character Modeling
151
Fig. 4. The word “tall” in cursive style
Example 10. The word “tall” may have the form given in Fig.4. The ﬁrst char-
acter “t” can be isolated in a box from the rest of the word because the writer
explicitly has introduced the marks of pen-up and pen-down when he added the
cross of the letter “t”. But the consecutive characters “all”are written using an
unbroken stroke. So, we cannot count on the beginning and ending marks to
deﬁne possible character segmentation. Let us formalise this point.
In NCLocr, the word “tall” is represented by the formula W = (f • g • v • f • e •
h) • e • g • d • f • d • f • t • e • v • d • f • e • v • h • f.
A correct recognition of the word “tall” supposes that some strategy is available
to stress the frontier of the characters which are hidden in the word “tall”, i.e,
to transform the formula W into the formula WS = (f • g • v • f • e • h) • (e •
g • d • f • d • f•)(f • t • e • v • d • f) • (f • e • v • h • f), where the strokes at the
frontier of characters are duplicated. All the characters contained in the word W
are isolated now, and can be submitted to our character recognition procedure.
A major diﬃculty to deal with is to locate the segmentation point.
Complexity of Word Recognition. If we extend roughly our approach to
word recognition, as we don’t know the number of characters which appear in a
word, we can no longer normalize them.
Let us consider this general case, where the input I is given by the formula I =
(i1 • ... • im−1 • im...), and some chain of character models is represented by the
formula L = (l1 • ...) • (... • ln−1 • ln)...) have diﬀerent lengths : m ̸= n. We know
from the lemma-1, that we have to improve the expressive power of the set E in
order to carry out a proof of the sequent !E, I ⊢L. So, let us now suppose that the
rewriting rules of E are of the form: (p1•...•(pr−1•pr)...) ⊸(q1•...•(qs−1•qs)...),
where r ̸= s, the premise and the conclusion are no longer limited to atomic
formulas. We are left with the following sequents !E, I ⊢L, to be proved in a
more general context.
It is likely that our problem is very complex; we can compare it to the reachability
problem for a Petri net, see [8,13], problem which can be stated as follows :
Given a Petri net R (R is a tuple (S, T ), where S is the set of places, and T is
a set of transitions), and two markings mi and mf ﬁnd an algorithm to decide
if there exists a sequence of transitions such that mf can be reached from mi.
In our application the markings are given by the atoms which appear in formulas
I and L, the sequence of transitions are the rewriting rules of the set E.
A rough approach to word recognition is likely to be of exponential complexity,
depending on the number of variables in NCLocr and their interconnections to
the linear implications of the set E.

152
J. Castaing
First Investigation in Word Recognition. Consequently, we have investi-
gated a new solution by restricting the segmentation hypotheses. We propose to
proceed as follows:
1. First Step: Let I be the input formula. Let L be a (non normalized) character
model of length m in the data base; we match L to I from the position 1
to m. The predicate im is duplicated, and we submit the subformula of I,
I1 = i1 • ... • im to our recognition process. We repeat this step for all the
character models of diﬀerent lengths in the data base.
2. Second Step: We select the best match (see section 4). Then, we iterate again
the process on the rest of the word.
We run this experimentation on small test sets containing 120 words from a total
word lexicon of 400 (usual english) words. The word recognition rate is 80% for
unconstrained cursive style, and can go up to 90% for limited cursive style.
8
Conclusion
From our point of view it is beneﬁcial to analyse recognition system with the
help of NCLocr. The connective •(next) has the good “properties” to capture
knowledge in data base. When structural rules - contraction, weakening and
exchange- are used, their role appears clearly. Inferences are carried out step by
step, and so, computational complexity can be accurately evaluated. We also
learn from this formal analysis, that we need appropriate strategies to limit the
complexity of the word recognition problem.
Acknowledgements. I wish to thank Jacqueline Vauzeilles for helpful com-
ments on the contents of this paper. I would also like to thank Pierre Br´ezellec
for coming to my assistance when I used his learning algorithm. Finally, I thank
the AISC’02 reviewers for their helpful reviews.
References
1. Abrusci, V.M., Ruet, P.: Non-Commutative Logic I : the Multiplicative Fragment,
Annals Pure Appl. Logic, 1998.
2. Br´ezellec, P., Soldano, H.: ´EL´ENA: A Bottom-Up Learning Method, Proceedings
of the Tenth International Conference on Machine Learning, Ahmerst 93, Morgan
Kaufmann, pp 9–16.
3. Castaing, J., Br´ezellec, P.: On-Line Chinese Characters Recognition by means of
Symbolic Learning, Proceedings of the International Conference on Chinese Com-
puting’96 June 4-7 Univ. of Singapor
4. Castaing, J., Br´ezellec, P.: Une M´ethode Symbolique pour la Reconnaissance de
l’´ecriture Manuelle en Ligne, RFIA 96 Rennes
5. Chan, K.-F., Yeung, D.-Y.: Elastic Structural Matching for On-Line Handwritten
Alphanumeric Character Recognition, Proceedings 14th Int. Conf. Pattern Recog-
nition vol.2, Brisbane, Australia, pp. 1508–1511

Non-commutative Logic for Hand-Written Character Modeling
153
6. Connell, S.: On-Line Handwriting Recognition using Multiple Pattern Class Mod-
els, submitted to Michigan State University in partial fulﬁllment of the require-
ments for the degree Doctor of Pilosophy Department of Computer Science and
Engineering 2000
7. Frey, P. , Slate, D.: Letter Recognition Using Hollad-Style Adaptive Classiﬁers,
Machine Learning Vol.6 num.2, Kluwer Academic Publishers pp. 161–182
8. Kanovitch, M.I.: Linear Logic as a Logic of Computations, Proceedings 7-th Annual
IEEE Symposium on Logic in Computer science, Santa Cruz, pp 200–210, 1992
9. Girard, J.-Y,: Linear Logic, Theoret.Comp. Sci., 50(1) :1–102, 1987
10. Hu, J., Turin, W.: HMM Based On-Line Handwriting Recognition, IEEE Trans.
Pattern Analysis and Machine Intelligence, vol.18, n0. 10, pp. 1039–1045, Oct.
1996.
11. Manke, S., Finke, M., Waibel A.: The Use of Dynamic Writing Information in a
Connectionist On-Line Cursive Handwriting Recognition System, Neural Informa-
tion Processing System NIPS 94, pp 1093–1100
12. Nathan, K.S., Bellegarda, J.R., Nahamou, D., Bellegarda, E.J. :On-Line Hand-
writing Recognition Using Continuous Parameter Hidden Markov Models, Proc.
ICASSP’93, vol.5, Minneapolis, MN, pp. 121–124, May 1993.
13. Peterson, J.L,: Computation sequence sets, J.Comput. System Sci.13 1–24 1976
14. Prevost, L., Milgram, M.: Automatic Allograph Selection and Multiple Classiﬁ-
cation for Totally UnconstrainedHandwritten Character Recognition, Proceedings
14th Int. Conf. Pattern Recognition vol.2, Brisbane, Australia, pp 381–383
15. Rabiner, L.R: A tutorial on Hidden Markov Models and Selected Application in
Speech Recognition, Proceedings of IEEE, 77(2) 1989
16. Rigoll, G., Kosmala, A., Willet, D.: A New Hybrid Approach to Large Vocabulary
Cursive handwriting Recognition, Proc. 14th Int. Conf. on Pattern Recognition,
Brisbane, Australia, pp. 1512–1514, Aug. 1998.
17. Robinson, J.A.: A Machine Oriented Logic Basedon the Resolution Principle
J.ACM 12(1), 23–41
18. Ruet, P.: Non-commutative logic II : sequent calculus and phase semantics, to
appear in Mathematical Structure in Computer Science
19. Scattolin, P., Krzyzak, A.: Weighted Elastic Matching Method for Recognition of
Handwritten Numerals in Vision Interface’94, pp178–185, 1994
20. Editor Wang, P.S.P: Characters & Handwriting Recognition: Expanding Frontiers,
World Scientiﬁc Series 1991
21. Yanikoglu, B.A, Sandon, P.A: Recognizing Oﬀ-Line Cursive Handwriting, IEEE
Computer Society Conference On Computer Vision and Pattern Recognition,
CVPR’94, pp397–403

From Numerical to Symbolic Data during the
Recognition of Scenarii
S. Loriette-Rougegrez
University of Technology of Troyes, Laboratory LM2S,
BP 2060, 10010 Troyes, France,
loriette@utt.fr
Abstract. The objective of this paper is to present a system that is able
to recognize the occurrence of a scenario evolving over time and space.
Scenarii are considered to be made up of several stages. The transition
from a stage to another one requires the satisfaction of conditions. These
features have led us to the construction of a graph which is run by means
of a rule-based system. Transitions are validated with the transformation
of numerical data into symbolic ones. Data’s uncertainty is considered
by means of the computation of an evidence’s mass for each transition.
The system described in this paper is applied to the recognition of ma-
neuvers performed by a car driver.
1
Introduction
Our work takes place inside the CASSICE project. It aims at building a sys-
tem permitting to acquire the description of driving situations, and facilitate
their analyzis. These situations are assumed to take place on a straight urban
motorway. CASSICE includes several components. We focus in this paper on
one of them, the DSRC1 system, which role is the recognition of the performed
maneuvers, namely the overtakings.
Several data inform the system DSRC about the respective positions of the con-
sidered cars. The recognition of the overtaking maneuver is fulﬁlled by means
of several steps. In the next part, we will present the CASSICE project. We
will carry on in section 3 with the description of the input data, permitting
the recognition of the performed maneuver. Then the system DSRC will be
presented: the principles underlying the development of the system will be il-
lustrated inside DSRC version 1 in section 4, and a second version taking into
account the uncertainty of data will be presented in section 5. Knowledge repre-
sentation used in DSRC v2 will be detailed in section 6. We will conclude with
results and perspectives in part 7.
2
The CASSICE Project
Over the last years, several driving assistance systems have been developed, in
order to increase the security of the car driver or facilitate his task. In order
1 Acronym for Driving Situation ReCognition.
J. Calmet et al. (Eds.): AISC-Calculemus 2002, LNAI 2385, pp. 154–167, 2002.
c
⃝Springer-Verlag Berlin Heidelberg 2002

From Numerical to Symbolic Data during the Recognition of Scenarii
155
to improve these systems’ quality, it is necessary to evaluate their impact on
the driver’s behavior. To do so, comparisons are fulﬁlled between the driving
activity with assistance system(s) and the driving activity without assistance
system(s) [1]. Now, this activity can not be evaluated independently from its
context: infrastructure, driver’s actions, social data (driver’s experience, gender,
driver’s knowledge of the way, etc.).
The methodology used consists in observing and video-recording the driver’s
behavior inside an equipped vehicle [2]. They allow to conduct interviews
after the journey so as to identify his (resp. her) objectives and strategies,
his (resp. her) knowledge and representations of the studied driving situation.
Several kinds of data are acquired. Some of them are context-dependent (e.g.,
social data). Other ones are time-dependent. These last ones, except for a few
ones2, allow ﬁrst to ﬁll in a grid of a spreadsheet. They are time-stamped.
They describe what the driver may observe or do: the motorway infrastructure
(traﬃc entry zones, directional zones, traﬃc joining zones, etc.), the intensity
of traﬃc, and several features of the considered car (speed, action on the
brake, lane changing, distance to the followed vehicle), or of the car followed
(speed, lane occupied). Diﬀerent proﬁles of driver, deﬁned by diﬀerent expe-
riences, etc. lead to the ﬁlling of diﬀerent grids, which will be analyzed separately.
Each grid allows afterwards the psychologist to compute the answer to
questions such as: how many seconds does the driver require in order to perform
an overtaking?. Between a left changing lane and the corresponding right
changing lane, calculate the number of vehicles that have been overtaken by
the equipped car, etc. Such questions, and many other ones, permit to the
psychologist to model the driver’s behavior.
The interest of the CASSICE project, and its originality, is to automatize
this analysis. The objective is indeed to build an integrated system, made up of
two parts [3]:
– an equipped vehicle (EV) to record automatically a physical description of
the driving situation,
– a software to build a database of driving situations, and automatically answer
questions such as the ones mentioned above.
The ﬁrst part of CASSICE manipulates raw numerical data, whereas the
second one requires a symbolic description of the situations. A transformation’s
step of numerical data into symbolic ones is then necessary.
3
Input Data
The diﬀerent layers of CASSICE are fulﬁlled at the same time by diﬀerent re-
searchers. Especially, the experimental vehicle has just been equipped with diﬀer-
2 e.g., the ﬂashes of the left turn signal of the vehicle to be overtaken. This data is
considered during a later analysis.

156
S. Loriette-Rougegrez
ent sensors [4]. That’s the reason why DSRC has been tested on simulated data
that we present next. The java-written simulator permits to enter the deﬁnition
of road scenarii, to visualize them graphically, and to generate corresponding
sensors data [5]. We interested only in the overtaking maneuver. This maneuver
will be presented afterwards.
Table 1. Simulated data.
Time
X
Y
V
θ
φ
Rg
Rd
0.01 -32.00
0
15
0
0 -3.50 1.50
0.02 -31.85
0
15
0
0 -3.50 1.50
0.03 -31.70
0
15
0
0 -3.50 1.50
...
...
...
...
...
...
...
...
1.12 -15.52 -2.01 15 -9.91 3 -1.46 3.54
1.13 -15.37 -2.04 15 -9.68 3 -1.44 3.56
1.14 -15.22 -2.06 15 -9.46 3 -1.41 3.59
Table 2. Data’s meaning.
Acc
Acceleration of EV relative to TV (m2/s)
φ (phi) Front wheel angle of EV (in degrees)
Rd
Position of EV relatively to the right side of the road(m)
Rg
Position of EV relatively to the left side of the road (m)
θ (theta) Angle that the target TV forms with the direction indicated by the road
(degrees)
V
Speed of EV relative to TV (m/s)
X
Position on the x’s axis of TV against EV (m)
Y
Position on the y’s axis of EV against EV (m)
3.1
Raw Data Acquired
The maneuver recognition needs ﬁrst to measure a lot of parameters that char-
acterize the driving situation. The simulated data used are presented in table
1. The meaning of the diﬀerent variables is presented in table 2. They refer to
a target vehicle (TV). It is the vehicle which is assumed to be followed, then
overtaken, by the driver of the equipped vehicle (EV).
Simulated data, as well as the future real data, are time-stamped.
3.2
Overtaking Maneuver Example
The overtaking maneuver, that one has to recognize inside the data of table 1,
may be simply described in this way: an experimental vehicle (EV) goes to the

From Numerical to Symbolic Data during the Recognition of Scenarii
157
right lane of the highway. It catches a target vehicle (TV) running on the same
lane with a lower speed. The EV is beginning an overtaking of the TV. It begins
going to left for a lane changing, then it is running straight forward. When EV
has overtaken TV, it goes right to the right lane.
Each step needs to consider several variables. For instance, to detect a change of
lane inside an overtaking, one has to compare the variable Y with 0, consider the
speed of EV, etc. Each step of the maneuver depends on a conﬁguration of certain
variables’ values. It depends too on the stage of recognition of the maneuver.
Indeed, a given conﬁguration of variables’ values will not always have the same
signiﬁcation during the recognition process. For instance, we have to detect that
the four wheels of the EV are on the same lane. This condition is useful for 3
diﬀerent stages in the recognition process: before EV begins its overtaking, when
EV is passing, when EV has completed its maneuver. The recognition process is
thus context-dependent.
4
Recognition of a Maneuver by Means of a Graph
The last remark has led us to this conclusion: to recognize a maneuver perfor-
mance, one needs to take into account:
– the variables relative to the position of EV towards TV,
– the actions of the EV’s driver,
– the stage of recognition of the maneuver.
We chose to model a manoeuver with a graph. An extract is described in ﬁg-
ure 1. A state corresponds to a stage of fulﬁllment of the maneuver, some of them
are optional. For instance, if we consider the overtaking maneuver, several steps
may be identiﬁed: indication of the intention of overtaking, crossing of the left
continuous line, etc. The ﬁrst is optional whereas the second is obligatory. Tran-
sitions between states are fulﬁlled by means of the occurrence of precise events
or special conﬁgurations of the location of EV towards TV. Events or conﬁgu-
rations will be uniformly called in the follow-up conditions. Wait for overtaking,
turn of the steering wheel, EV behind TV, are instances of such conditions. These
conditions are potentially numerous.
In DSRC v1 [6], the maneuver is considered recognized if the last state is reached.
In DSRC v2, things are slightly diﬀerent because an evidence’s mass should be
associated with each state. This problem will be considered in section 5.
4.1
A Rule-Based Recognition
Input data are processed in batch mode. Lines of table 1 representing simulated
data, are processed line by line. The conditions’ satisfaction evoked in paragraph
3.2, such as four wheels on the same lane is detected by means of tests on a
subset of variables’ values in 2 or 3 successive lines. Once the satisﬁed conditions
have been detected, we have to search for the transitions of the graph that
these conditions permit to validate. They will permit in turn to validate states

158
S. Loriette-Rougegrez
flashing,
EV behind TV.
Wait for 
overtaking (WO)
Initial state
Steering wheel to
the left,
EV behind TV,
EV and TV on the
same lane, etc.
Steering wheel to
the left,
EV behind TV,
EV and TV on the
same lane.
EV and TV on
the same lane,
vs >= Vmin.
EV behind TV,
Crossing of the 
right continous
line (CRCL)
End of pulling
left turn signal
in front of EV
overtaking (IIO)
(EPF)
TV in front of
EV,
EV and TV on
the same lane.
changing lanes
(BCL)
Beginning of
Crossing of the
left continuous 
line (CLCL)
A wheel on the line
Indication of the
intention of
Fig. 1. States making up the overtaking maneuver
of the graph. The data processing relies at the beginning on the detection of
variables’ values’ combinations, such as X, Y, etc. That’s the reason why we
chose to handle this problem by means of a rule-based approach.
The DSRC system is made up of two levels of rules. We have used the CLIPS
formalism [7] [8]. The ﬁrst-level’s rules use raw data and they have to detect the
satisfaction of the transitions’ conditions. Subsets of conditions recognized make
up the transitions validated in the graph. Validated transitions allow in turn the
second-level of rules to generate hypotheses about the stage of fulﬁllment of the
maneuver, that is saying to identify the current state.
Table 3. First-level rules in DSRC.
If at time t, EV has a negative value for X then
EV is behind TV
If, at time t, Y is in [-1.00, +1.00] then
both vehicles are on the same lane
First-Level Rules. The condition part of this kind of rule evaluates the variables’
values relating to the detection of a transition’s condition. The values are con-
sidered over a time period of 2 or 3 ms. This rule-set contains about 20 rules.
Two rules are presented in table 3.

From Numerical to Symbolic Data during the Recognition of Scenarii
159
Second-Level Rules. They allow to run through the graph. For a couple of states
Ei, Ej, and a transition noted “A” between both states, we deﬁne the following
rule: if, at instant t, state Ei is the current state, and condition(s) in A is (resp.
are) detected then the current state becomes Ej. Two other rules are used, of
which a rule allowing to initialize the maneuver’s recognition.
Rule basis have been used on several occasions in the CASSICE project. The
system IDRES [3] has to recognize maneuvers performed too. It is independent
from any graph. Input data are directly transformed into states, then states’
sequences are pieced together to match maneuver models consisting of a states’
succession.
4.2
Results
DSRC has been experimented on simulated data. These data contain about 600
descriptions of variables’ values descriptions, with an interval of length 0.01 s
between 2 descriptions. The fulﬁlled recognition presented in ﬁgure 2 shows the
time periods during which each condition associated with one or several tran-
sitions’ graph is recognized. On the top of the ﬁgure, conditions are associated
with intervals during which they are validated. To go from a state to another
one at a given time point, all the conditions associated with the corresponding
transition need to be validated. We show in the bottom of the ﬁgure a succession
of time points at which each state is validated3. These results permit to conclude
that an overtaking maneuver has been recognized inside the considered set of
data.
1
223
102
102
333
303
210 222
215
1
333
1
75
61
19
60
16
110
154
251
294
a wheel on the left line
EV goes closer to the left line
steering wheel to the left
EV’s lane left to TV’s lane
EV same level as TV
EV in front of TV
steering wheel to the right
EV goes closer to the right line
4 wheels on the same lane
same lane
behind
a wheel on the right line
WO
CRCL
BCL
CLCL
CRCL
OR
BP
19
19
102
210
223
251
O
345 388
345
255
EPF
345
The graph has been consequently run through this way :
1
84 100
305 321
600
600
600
255
295
61
Fig. 2. DSRC v1 results
In this version of DSRC, the recognition of conditions, then transitions and
states, is boolean. A state/condition/transition is true or false. In the reality,
3 Time-stamps are the earliest time-points at which the states are validated. States are
abbreviated. Abbreviations appear in ﬁgure 1, except for “O”, “OR”, “BP”, which
mean respectively overtaking, overtaking fulﬁlled, beginning of pulling in.

160
S. Loriette-Rougegrez
things are not so clear. For instance, to recognize that the car driver has turned
the steering wheel, which rotation is considered signiﬁcative?. In fact, almost all
the conditions of the graph’s transitions are concerned about this problem. The
second problem is how to run through the graph. If true conditions at a given
time point allow the recognition process to remain in the same state or to go to
the following, the software will choose to go in the next state. We would like to
introduce in DSRC a choice based on solid criteria, such as a conﬁdence in the
next state for instance.
5
Taking into Account the Data’s Uncertainty
If we consider the following condition: The car driver has turned the steering
wheel, we need to know the value of the rotation’s angle, represented with
the variable φ. φ takes values in [-3,3]. It should have a negative value so as
to satisfy the condition. If the value is -3, we may consider that the driver
has intentionally turned to the left. If the value is -0.5, we may consider
that the car driver has slightly, perhaps accidentally, turned the steering
wheel. We can tell that this action’s detection is uncertain. We propose to
associate with each transition’s condition, a belief into the condition’s fulﬁllment.
We suggest to apply the Dempster-Shafer theory [9]. This theory’s interest is
that it allows to associate an evidence’s mass with a set of hypotheses. We can
model a basic belief assignment by a distribution of evidence’s masses m on the
propositions A, subsets of the hypotheses’ set Ω= {Hi, Hj, Hk...}. A can be a
singleton (or single) proposition such as {Hi} but also a composed proposition
such as {Hi, Hj} for instance. The mass’ distribution takes values in 2Ω, the
power set of Ω. The sum of the masses over 2Ωis 1.
m : 2Ω→[0, 1]
A →m(A)
In the following section, we will explain how we translate numerical variables’
values into an evidence’s mass. We then obtain a set of conditions associated with
a belief in their fulﬁllment. We will then explain how we work out a conﬁdence
in the transitions.
5.1
From Values of Variables to Conditions
Conditions associated with transitions, such as “EV is behind TV”, requires
the consideration of one or more input data variables. Inversely, each variable
will allow to validate one or more conditions. We choose to evaluate for each
condition C a conﬁdence in the following statements: “C is true”, “C is false”,
“C is true or false”. ΩC = {Ctrue, Cfalse} makes then up our discernment’s
space towards the Dempster-Shafer theory.
We have used the fuzzy sets theory [10]. We have deﬁned the DSRC’s fuzzy sets

From Numerical to Symbolic Data during the Recognition of Scenarii
161
by means of a comparison between simulated data and our knowledge of the
maneuver’s progress. It will be interesting later to use the same fuzzy sets with
real data and to compare the results.
Let’s consider the fuzzy sets of ﬁgure 3. They gather information about
the conditions steering wheel to the left (SWL) and steering wheel to the right
(SWR), which validation depends on phi. We interest here in SWL. We deﬁne
ΩSW L = {SWLtrue, SWLfalse}. Figure 3 indicates that this condition is true
in ] −∞, −1], that it is true or false in ] −1, 0], and that it is false in [0, +∞[.
The conﬁdences in the statement SWL are summarized in table 4. This stage
in the data processing is fulﬁlled with an adapted version of ﬁrst-level rules of
paragraph 4.1.
SWL is a condition depending on one single variable. It means that in the
condition part of the ﬁrst-level rule permitting the calculation of the conﬁdence
into its fulﬁllment, one has only to read the associated fuzzy set to extract from
it the value in [0, 1]. Certain conditions are related, not to one, but to 2 variables.
We obtain then from the relating fuzzy sets’ reading, 2 values in [0, 1]. We have to
combine them. We then use the combination-rule of Dempster-Shafer described
in the next paragraph.
left U steering wheel 
to the right
Steering wheel 
to the left
Steering wheel to the
Steering wheel 
to the right
0
1
-1
phi
Fig. 3. Belief functions for the conditions steering wheel to the left (resp. right)
Table 4. Conﬁdence in the condition “steering wheel to the left”.
Truth value/interval ]- ∞, -1] ]-1, 0] [0, + ∞[
true
1
0
0
false
0
0
1
true or false
0
1
0

162
S. Loriette-Rougegrez
5.2
From Conditions to Transitions
The result of the last paragraph is to associate a condition with a masses’ distri-
bution over the truth-values true, false, true or false. A transition is a disjunction
of conditions for which we have to evaluate a conﬁdence in its validation.
A condition may be viewed as a source of information for one or more transi-
tions. A transition is then associated with several sources of information: all of
them contribute to the truthfulness or the falsity of the transition’s validation.
Dempster-Shafer’s theory allows to model this situation by the combination-
rule. Let’s consider m1 and m2 the distribution of masses associated with 2
information’ sources S1 and S2. Let’s consider X, an hypothesis, which we wish
to compute its evidence’s mass. X is given by:
m(X) =

i,j,Ai 
Aj=X
mS1(Ai) ∗mS2(Bj)
in which Ai and Bj represent hypotheses coming out from S1 and S2.
We calculate now the evidence’s mass associated with a transition T, assumed to
be dependent on 2 conditions condi and condj, that is to say T = condi
 condj.
Notations. We use the following notations:
1. T is the transition considered,
2. ΩT = {Ttrue, Tfalse} is the discernment’s space of T,
3. Ωcondi = {condtrue
i
, condfalse
i
} is the discernment’s space of condi,
4. Ωcondj is the discernment’s space of condj with Ωcondj =
{condtrue
j
condfalse
j
},
5. mi is a distribution of mass associated with condi,
6. mj is a distribution of mass associated with condj.
We have to compute mT = mi ⊕mj.
Computing of the Evidence’s mass of a Transition. Table 5 indicates in its
ﬁrst line and ﬁrst column the values of the mass’ distributions mi and mj,
computed in the paragraph 5.1. Each square contains the product of the evi-
dence’s masses of the corresponding line and column, which by application of
the Dempster-Shafer theory’s combination-rule, will contribute to the calcula-
tion of the mass’ distribution of mT . For instance, the table 5 indicates how to
compute mtrue or false
T
:
mtrue or false
T
= mtrue
i
× mtrue or false
j
+ mtrue or false
i
× mtrue
j
+mtrue or false
i
× mtrue or false
j
A transition may be associated with more than 2 conditions. The algorithm
of ﬁgure 4 considers this case.

From Numerical to Symbolic Data during the Recognition of Scenarii
163
Table 5. Computing of the mass of evidence of a disjunction of conditions.
Masses
mtrue
i
mfalse
i
mtrue or false
i
mtrue
j
mtrue
T
mfalse
T
mtrue or false
T
mfalse
j
mfalse
T
mfalse
T
mfalse
T
mtrue or false
j
mtrue or false
T
mfalse
T
mtrue or false
T
+
cond_i <- 1st condition of List; List <- rest(List)
If the number of conditions associated with T = 1 then
mass(T) = mass(cond_i)
else
while all the conditions have not been processed do
List <- rest(List)
T) = cond_i       cond_j
cond_i <- cond_j
End while
End if
Return mass(T)
List <- list of conditions relative to the transition T  considered
cond_j <- 1st condition of List
mass(
Fig. 4. Computation of a transition’s mass
6
Knowledge Representation
In this section, we describe the knowledge representation chosen. The constraints
are the following:
– the description of input data is a list of lines. A line associates a time-point
with several variables’ values, as described in table 1,
– each variable is likely to validate one or more conditions of the graph. In-
versely, a condition may be validated with one or several variables, as told
about in paragraph 5.1,
– a condition is likely to validate one or more transitions. Inversely, a transition
is associated with a conditions’ disjunction, as described in paragraph 5.2,
– a ﬁrst-level rule, in order to compute the evidence’s mass of a given condition,
has to quickly examine the fuzzy set associated with a variable for this
condition. This has been presented in section 5.1.
We have used the object-oriented language (COOL) which is part of CLIPS.
The main classes deﬁned are: C −maneuver −t, C −interval −condition.
The graph has an object-oriented representation too. It gathers transitions,
considered too as objects. An object transition is associated with a transition

164
S. Loriette-Rougegrez
of a graph, a time-point and a mass’ distribution, such as the one talked about
in the next paragraph.
Other knowledge structures are used, in order to link transitions to condi-
tions, ﬁrst-level rules to considered variables, etc.
C −maneuver −t. This class permits to describe at a given time point
the mass’ distribution associated with each condition of the graph. There is a
slot for the time, and a slot for each condition considered. To associate a mass’
distribution with each condition, we have deﬁned another class C −condition −
mass with the slots true, false, true or false. This class is useful for the action part
of the ﬁrst-level rules. It allows indeed to store the evidence’s masses computed
for all the conditions. Some conditions need the ﬁring of several ﬁrst-level rules
to compute their mass’ distribution. That’s the case for all the conditions in
which several variables are implied. The instances of the class C −maneuver −t
allows then to temporarily store the results of the rules calculations. The C −
maneuver −t is partially described below:
(defclass C_maneuver_t (is-a
C_conditions)
(role concrete)
(pattern-match reactive)
(slot time (default-dynamic
(new_C_masse_condition))
(create-accessor read-write))
(slot meme_file (default-dynamic
(new_C_masse_condition))
(create-accessor read-write))
(slot vitesse_sup (default-dynamic
(new_C_masse_condition))
(create-accessor read-write))...
(slot vol_a_G (default-dynamic
(new_C_masse_condition))
(create-accessor read-write)))
C −interval −condition. This class permits to associate with each couple
⟨variable, condition⟩, the list of values’ intervals of the variable, where the evi-
dence’s mass of the condition may be diﬀerent of 0. This class is very useful for
the condition part of the ﬁrst-level rules. Each interval is associated with an in-
terval of variable’s values, and an aﬃne function allowing to know the evidence’s
mass associated with it.
(defclass C_interval_condition (is-a
USER)
(slot inf (default U)
(create-accessor read-write))
(slot sup

From Numerical to Symbolic Data during the Recognition of Scenarii
165
T true
1
22
43
64
85
106
127
600
0
0.2
0.4
0.6
0.8
Mass
1
T true or false
T false
time
Fig. 5. Mass of the source transition
(default U)
(create-accessor read-write))
(multislot listeI
(default U)
(create-accessor read-write)))
One of its instances is partially described below:
(IVC_phi_vol_a_G of C_intervalle_condition
(inf #-infini)
(sup 0)
(listeI
(create$ -1 (affine phi_vol_a_G_1 -2 1 -1 1)
0
(affine phi_vol_a_G_2 -1 1 0 0))))
The syntax of the instances’ names4, such as IVC-phi-vol-a-G, has been cho-
sen so as to recognize immediately the variables and the condition concerned by
it. It allows the ﬁrst-level rules too to quickly identify the instance to which it has
to send a message in order to ask it to return an evidence’s mass. The instance
above indicates that the condition vol-a-G (steering wheel to the left), which
depends on φ may be associated with a non zero evidence’s mass in ] −∞, 0]. It
details afterwards the values of the mass in subintervals. Each subinterval is as-
sociated with an aﬃne function which will automatically be generated from the
description, in the instance, of the coordinates (X, Y) of 2 points of this subin-
terval. X concerns the value of φ. Y concerns the evidence’s mass associated with
X.
4 < IV C > −< variable considered > −< condition considered >, IVC standing
for Interval of Validity of Conditions.

166
S. Loriette-Rougegrez
7
Results and Perspectives
We have presented a system, DSRC, which, from a graph-based representation
of a maneuver, computes the conditions’ validity and then the transitions’ va-
lidity, so as to recognize a fulﬁllment of the maneuver. The process is 2-steps.
A ﬁrst step consists of transforming, by means of a rule-basis, raw numerical
data into symbolic ones, i.e. conditions. DSRC v2 furthermore associates with
each condition a conﬁdence into its recognition. The second step combines the
conﬁdences associated with each transition’s conditions, in order to obtain a
single conﬁdence. Fuzzy sets theory and Dempster-Shafer theory seemed to be
very suitable to us. The computation of an evidence’s mass for each transition is
indeed important for the recognition of the overall maneuver. Our work is to our
knowledge the ﬁrst one that uses the Dempster-Shafer theory for the recognition
of the validity of transitions inside a graph.
We have next to choose the criteria that will permit to consider that the maneu-
ver is fulﬁlled. This task is not simple. Transitions are validated upon intervals
and they are associated with a conﬁdence. If a transition Tk between states Ei
and Ej is validated during an interval [t1, t2], when will Ej be validated?.
From the works fulﬁlled on Petri nets [11], namely the consideration of uncer-
tainty with fuzzy sets on the transitions, we may by means of the combination-
rule of Dempster-Shafer theory compute an evidence’s mass for each state, and
for each time point, like in [12]. We may then simply consider that the maneuver
is recognized if states are validated one after the other, or if the ﬁnal state has
been reached etc. But for the realism of the recognition, shouldn’t we consider
that the recognition process should remain in each state during a minimal time,
to deﬁne?. We will then have to introduce temporal constraints [13].
We then have to pursue our research in the direction of the graphs and/or Petri
nets. We do not forget that we have worked until now with simulated data. One
of our future perspectives is the use of real data.
References
1. Saad, F., Villame, T.: Int´egration d’un nouveau syst`eme d’assistance dans l’activit´e
des conducteurs d’automobile. In Ganascia, J., ed.: S´ecurit´e et cognition, Herm`es
France (1999) 105–114 chap. 9.
2. Saad, F.: Driver strategies in car-following situations. In et al., A.G., ed.: Vision
in Vehicles, Elsevier Science B.V. (1996) 61–70
3. Nigro, J., Loriette-Rougegrez, S.: Characterization of driving situation. In: Inter-
national Conference on Modelling and Simulation, MS’99, Santiago de Compostela,
Spain (1999) 287–297
4. Shawky, M., Crubille, P., Bonnifait, P.: Archiving and indexing of large volume
sensor data of an equipped vehicle. In: DriiVE - Driving research in instrumented
vehicles workshop, Helsinki, Finland (1999)
5. Simulator: (http://www.hds.utc.fr/ crubille/web/simulateur/)

From Numerical to Symbolic Data during the Recognition of Scenarii
167
6. Loriette-Rougegrez, S., Nigro, J.M., Jarkass, I.:
Rule-based approaches for the
recognition of driving maneuvers. In: AISTA’2000 (International Conference on
Advances in Intelligent Systems: Theory and Applications), Canberra (Australia)
(2000)
7. Giarratano, Riley: Expert systems: Principles and programming. (ISBN 0-534-
95053-1)
8. Clips: (http://www.ghg.net/clips/download/documentation/)
9. Shafer, G.: A mathematical theory of evidence. Volume 2702. Princeton University
Press (1976)
10. Bouchon-Meunier, B.:
La logique ﬂoue.
In: Que sais-je? Volume 2702.
Presse
universitaire de France (1993)
11. David, R., Alla, H.:
Du Grafcet aux r´eseaux de Petri. 2i`eme edn.
Trait´e des
nouvelles technologies. S´erie automatique. Herm`es (1992)
12. Jarkass, I., Rombaut, M.: Reconnaissance de s´equences temporelles `a l’aide de
r´eseau de petri cr´edibiliste. In Herm`es, ed.: Journal Europ´een des Syst`emes Au-
tomatis´es (APII-JESA). Volume 32. (1998)
13. Fontaine, D.: Une approche par graphes pour la reconnaissance de scenarios tem-
porels. Revue d’intelligence artiﬁcielle 10 (1996) 439–468

On Mathematical Modeling of Networks and
Implementation Aspects
Regina Bernhaupt and Jochen Pfalzgraf
Department of Computer Science
University of Salzburg
Jakob-Haringer-Str. 2
A-5020 Salzburg/Austria
{rbern, jpfalz}@cosy.sbg.ac.at
Abstract. Based on existing work where categorical and geometrical
methods were used to establish a mathematical model of neural net
structures, we develop a new very general model for artiﬁcial neural
networks (ANN), where all basic components of a network are described
abstractly. This mathematical model serves as a guideline for design and
implementation of a new ANN-simulator. The proposed model of neuron
types will be illustrated by the discussion of an example, using the Single
Spiking Neuron Model (SSM). The main building blocks of the simula-
tion tool, a new construction principle for ANN, and abstract modeling
of connection weights are presented.
1
Introduction
Currently, there is a large number of software packages in use for simulations of
artiﬁcial neural networks (ANN), ranging from general simulators to very special
ones. A general simulator used in Europe is the SNNS [Zel94]. On the scale
between general and specialized simulators there are many software packages e.
g. SpikeNet in use for large networks with specialized neuron types [DGRT99].
A special software package is the sophisticated program GENESIS performing
detailed physiological simulations [BB98]. All these simulators are lacking the
ability to use special connection structures between neurons. In addition they
can hardly be linked to other software modules to allow hybrid approaches, like
the combination of fuzzy-logic, multi agent systems, and ANN.
We are currently working on a new connectionist simulator which was in-
spired as described subsequently. First the fruitful cooperation of the second
author with H. Geiger let to the foundation of the mathematical framework
presented in [Pfa01], [Pfa02]. H. Geiger is working with ANN in industrial appli-
cations [GP95], [Gei94]. Second the working group of the second author at RISC-
Linz started to implement a simulation tool with a special command language
for network simulation [Six94]. Later this tool was extended at the University of
Salzburg. The results of these cooperations can be found in several diploma and
doctoral theses [Lan01], [Six94].
J. Calmet et al. (Eds.): AISC-Calculemus 2002, LNAI 2385, pp. 168–180, 2002.
c
⃝Springer-Verlag Berlin Heidelberg 2002

On Mathematical Modeling of Networks and Implementation Aspects
169
Using these contributions and ideas we are now designing and implement-
ing a new improved simulation tool. The previously mentioned mathematical
framework provides the guideline for implementing and simulating a large class
of neural network structures in a ﬂexible way. The emphasis of the mathematical
approach is on modeling the neural network structures in the interpretation of
geometric nets. Initially it was established to represent the structure of Geiger’s
network paradigm, but our new general mathematical deﬁnition of a network
goes far beyond.
2
Towards a General Deﬁnition for ANN
As already mentioned before, very important for our construction of the sim-
ulator is the formulation of a general mathematical framework. In the past we
observed that the analysis of network structures showed the possibility to intro-
duce geometric and categorical modeling approaches. As pointed out in [Pfa01],
[Pfa02] to any given ANN a geometric net can be associated. Since geometric
spaces form a category, one obtains a category of geometric nets with a suitable
notion of morphism. Neurons and connection structures can now be described
using these formalisms. For a suitable implementation the mathematical descrip-
tion has to comprise further aspects, as described below.
– Implementing ANN is always based on the possibilities to simulate neurons
and their connections. An important aspect is the description of a layer. In
practice layers are named e. g. input, hidden or output layer.
– The possibility of describing network structures must be given. When do we
call two neurons connected? And how can the neuron model be described
using these structure descriptions? Do there exist curcuits (feedback loops)?
– Is the mathematical description of a neuron type a good basis for the imple-
mentation? A diﬀerential equation describing a neuron type may be precise,
but can hardly be implemented without further knowledge. We have to ﬁnd
a way to describe neurons more generally, easy to understand for the user
and still easy to implement.
– Neurons and their models are biologically oriented. In hybrid approaches
these neurons have to communicate with other processing entities or mod-
ules. In image processing fast algorithms are used for preprocessing images.
In general, the notion of a neuron may not suﬃciently describe this be-
haviour. A new concept with a generic description can solve this problem.
– The general mathematical model of an ANN as proposed below shall al-
low ﬂexible construction of ANN. Any neural network can be connected to
another (sub-) network without further deﬁnitions, despite the specialized
connection structure.
With these introductory and motivating remarks we start to prepare our
general deﬁnition as previously announced.

170
R. Bernhaupt and J. Pfalzgraf
2.1
Mathematical Deﬁnition of ANN
The following deﬁnition of an artiﬁcial neural network forms the basis for the
implementation of the new simulator.
The elementary basis of the general ANN model that we are developing is the
notion of a geometric net as introduced in [Pfa01], [Pfa02], where we mention
the category GeoNET induced by the category of noncommutative geometric
spaces NCG. We brieﬂy recall: let X be a set of points and R a set, then
a geometric space (i. e. object in NCG) is given by a so-called parallel map
(parallelism structure) <, >: X × X →R.
Interpreted in terms of a geometric net (object in GeoNET) this map de-
scribes a net with X as a set of nodes, X2 = X × X the set of all possible
directed edges and <, >: X2 →R is the coloring (weighting) of edges. We say R
is the set of weights and for x, y ∈X the element < x, y > is the weight of the
edge (x, y).
For practical purposes we want to be able to model (feedback) loops in an
ANN. Mathematically, we deﬁne a loop as a closed path (circuit) in the underly-
ing geometric net. More speciﬁcally: a loop of length n in a geometric net consists
of a sequence of consecutively connected nodes x = x0, x1, x2, ..., xn−1, xn = x,
where (xi−1, xi) are edges of the net with weights < xi−1, xi >, for i = 1, ..., n.
In our general deﬁnition below it is necessary to distinguish between diﬀerent
types of nodes. We will use the following notation. Very generally spoken, the
types of nodes will be expressed by a set T (X) (the ’names’ of the types) and an
element t ∈T (X) will be called a (speciﬁc) type. Let X[t] denote the set of nodes
of type t, then X is partitioned by all X[t],t ∈T (X), i. e. X = 
t∈T (X) X[t]
(disjoint union).
We can express this equivalently by introducing the ’type function’ τ(X) :
X →T (X) assigning to a node x ∈X its type τ(x) ∈T (X). Thus we obtain
X[t] = τ −1(t) (= {x ∈X|τ(x) = t} the preimage set of type t).
Analogously, we will speak of diﬀerent types of weights expressed by a cor-
responding type function τ(R) : R →T (R). Now we come to the introduction
of our general model of an ANN.
Deﬁnition 1 An artiﬁcial neural net is deﬁned in the following way:
(i)
A set of nodes (neurons) X, a set of weights R, a weight mapping <, >:
X2 →R, assigning to a directed edge (x,y) the (abstract) weight < x, y >.
Sometimes we symbolize it by the triple (X, <, >, R).
(ii)
With corresponding type functions τ(X) and τ(R) we deﬁne the occurring
types of neurons and weights respectively.
(iii) There is a partitioning of X into disjoint subsets X1, ..., Xn called the layers
of the ANN. If <, >l: X2
l →Rl denotes the restriction of <, > to layer Xl,
with corresponding set of weights Rl, then we can interpret this structure
as a ’subnet’ (Xl, <, >l, Rl) of (X, <, >, R).
(iv) As mentioned, < x, y > is the weight of the directed edge (x, y) ∈X2. If
there is no ’synaptic connection’ between two neurons u, v, i. e. if u, v ∈X

On Mathematical Modeling of Networks and Implementation Aspects
171
are not connected by an edge in the underlying directed graph of the ANN,
then we can deﬁne < u, v >:= ∞, for a distinguished symbol ∞added to
R. This can be interpreted, for example, as inﬁnite resistors, symbol of no
information ﬂow, no connection.
(v)
In practical applications, if it is necessary to model feedback loops, we use
the notion of a circuit as deﬁned above.
(vi) For the moment in our deﬁnition the type of a neuron t ∈T is determined
by parameter sets Pstat(t) and Pdyn(t) and a set of mathematical equations
(calculation rules) F(t).
This deﬁnition evolved through various stages. A ﬁrst version is mentioned in
[Pfa02]. A new aspect is the interpretation of the partitioning of X not only into
layers but into sub nets and the notion of the preprocessor. These interpretations
shall lead to a completely new implementation of the simulator. The deﬁnition
of neuron types as implementational relevant functions is a new aspect in the
mathematically oriented net community and shall lead to comparable neuron
type implementations. To make the notation of a neuron type more precise
and comparable, we describe a neuron type using the implementation relevant
functions (cf. neuron type implementation).
We will now turn to the description of a special single spiking neuron type
and its deﬁning sets Pstat(t), Pdyn(t) and F(t) to make the above deﬁnition of
node (neuron) types more concrete.
3
Single Spiking Neuron Model
The Single Spiking Neuron Model (SSM) was ﬁrst used by H. Geiger and cowork-
ers. We will use this biologically oriented model to instantiate the general deﬁ-
nition of an artiﬁcial neural network and its neuron types. Related work in the
area of time coded neuron types mainly deals with some specialized image pro-
cessing problems. The SSM is a central point in the work of the ﬁrst author.
The main idea is solving the recognition of several objects within a scene using
diﬀerent time stamps for diﬀering objects. The construction of the ANN shall
consist of several ANN-subnets (e.g. subnets are called V1, V2, V4). Each subnet
is capable of the specialized information processing (close to biology).
In our framework a neuron type t is described using the ’tupel’ (Pstat(t),
Pdyn(t), F(t)). This ’tupel’ can always be completed by further mathematical
descriptions needed to make the functionality of the neuron type more precise.
We use the abstract and general mathematical model as a guideline for our
implementation of the simulation tool.
Corresponding to this, the mathematical description of the SSM can be ex-
pressed in the following way: The Single Spiking Neuron Model (SSM) is a spe-
cialized model of a compartmental neuron model. For a mathematical descrip-
tion see [BP01]. The mathematical description can be summed up as follows:
The spike train of a neuron i is described as a series of δ-functions. The ﬁring
times tf
i of a neuron i are labeled by an upper index f. To simplify the formulas

172
R. Bernhaupt and J. Pfalzgraf
subsequently presented, we simply replace tf by t (not to be confused with the
same symbol used for neuron type t).
The membrane potential Vm(t) is given by
Vm(t) =

k g(k)
i
(t)Ek
i
gtotal
(1 −e−gtotal.Cm(t))
(1)
the discrete representation of the solved diﬀerential equation (using a ﬁxed
time window) [Lan01]. The membrane potential depends on the typical conduc-
tances of the various synapse types gi (they may be diﬀerent for the branches k of
each synapse type), the synaptic potentials Ei are summed up over all branches
k, the capacity of the cell (Cm(t)) and the sum of all conductances (gtotal).
The refractory function is denoted by η(t) which describes the refractory
period of the neuron after a spike. The membrane potential at time t may thus
be expressed by Fsum(t) = Vm(t) + η(t).
Fthreshold is used to compare the membrane potential with the given thresh-
old θ, and to compute the diﬀerence between them.
Fprob =
1
2 ∗(1 + eβ∗diff
noise )
(2)
describes the probability function used to determine when the neuron ﬁres. β,
noise are constants, diff = θ −Vm(t) and θ is the threshold.
If the neuron ﬁres (randomly generated number less than Fprob), we will use
a norming-function (Fnorm) to simply add the time stamp to the ﬁring time
array (tf
i ).
Summarizing, the SSM can be described following the above notation of a
neuron type t consisting of (Pstat(t), Pdyn(t), F(t)). Subsequently, we suppress
the corresponding neuron type letter t.
F = {Fsum, Fthreshold, Fprob, Fnorm}
(3)
Pdyn = {Vm(t), Cm(t), g(k)
i
, Ek
i }
(4)
Pstat = {η, θ, β, noise}
(5)
To summarize the above statements: ﬁrst we start with the mathematical
description of the neuron type and the neuron states and second the compu-
tation of the neuron state is decomposed into several functions, close to the
implementation. These functions and their dynamical and static parameter sets
may be used (implemented) directly in any simulator. The description is easy
comparable to other implemented neuron types, since the biologically oriented
processing steps F = {Fsum, Fthreshold, Fprob, Fnorm} can be the basis for any
comparison with other implemented neuron types.
The behaviour of the SSM is similar to the Spike Response Model (SRM)
[MB99]. The signiﬁcant diﬀerence is the use of the capacitor and the possibility

On Mathematical Modeling of Networks and Implementation Aspects
173
to describe several synapse types (besides inhibitory and excitatory connections)
in our model. While the SRM is closely related to the integrate and ﬁre model
[Ger01], the SSM is a specialized type of a compartmental model. It would be
a very interesting topic of future research to represent SRM in a similar way as
the SSM in terms of suitable functions. As far as we know this has not been
done yet.
Besides biological oriented neuron types we use the notion of a preprocessor.
Any combination of mathematical functions can be interpreted as a neuron type.
4
The New Simulation Tool
The new tool for the simulation of artiﬁcial neural networks is under construction
in our working group. Having started in August 2001, we expect the ﬁrst release
by the end of june 2002. The main focus is on the realization of the special
connection structures and processing entities described in deﬁnition 1. The ANN-
Simulator will be used in image and speech processing and in the ﬁeld of multi
agent systems (MAS) and in combination with fuzzy-logic modules and computer
algebra systems. Therefore an interface to other modules like fuzzy-logic module,
genetic algorithms and symbolic computation modules has to be speciﬁed.
Both architecture and design are object oriented, using UML for design and
C++ for implementation. From the architecture point of view the simulator itself
is decomposed into several modules. The main module, called kernel, implements
processing entities, net structure and learning algorithms. The kernel with its net
components and structures will be explained in detail in the following section.
From the software engineering point of view, the usage of linear lists as data
structures to reduce memory load and to speed up the system is of interest.
Besides the kernel, the simulator further consists of an XML-handling mod-
ule, which mainly deals with load and save operations based on the XML-
standards (e.g. saving the neural networks, training patterns, weights and even
user deﬁned workspace settings). The training- and simulation module will be
used to build the training- and simulation sets. Combined with the GUI-module
Version 1.0 is completely described.
Comparing the new simulation tool with other ANN-Tools we introduce the
following new concepts and possibilities, which can not be achieved using either
SNNS or GENESIS [Zel94], [DGRT99]:
– A new net construction principle, allowing the ﬂexible combination of neural
networks with other neural networks, the usage of several diﬀerent neuron
types within these neural networks, and the usage of so called preproces-
sors. We invented a new embedding principle for the recursive neural net
construction (ﬁgure 1 gives a basic idea).
– We use the XML standard for saving and loading of neural networks. The
ANN description can thus be edited by hand (scripting language).
– Based on the mathematical framework we are able to implement a ﬂexible
connection structure (called projection) to model structure in ANN’s.

174
R. Bernhaupt and J. Pfalzgraf
– We model abstract connection weights (e.g. logical values), which can serve
as a possible connection to existing multi agent system implementations.
– Neuron types are added dynamically using dynamic link libraries (dll) during
runtime.
Fig. 1. A layer is of abstract nodetype (a layer has a nodetype). Using inheritance
we get the class of a preprocessor, a neurontype or the abstract nodetype represents
a whole (sub-)net. The (sub-) net has several layers. A neural net can be constructed
recursively adding several (sub-) nets, which are ’represented’ by an abstract node.
4.1
Building a Neural Net
Net construction. A neural network is described in the simulator via a recur-
sive construction principle. The net consists of at least one layer. Each layer is
assigned to a special node type. Figure 1 shows the description of an abstract
node. We inherit from the abstract nodetype the classes preprocessor, neuron
type, and net. Net can be again a whole subnet. Thus we are able to deﬁne nets
recursively. This recursive inheritance principle allows us a special kind of ANN
construction. To make the usage more precise: Starting with an ANN consist-
ing of 3 layers (input layer, hidden layer, output layer) all of neuron type SSM,
we can add a whole subnet easily. We deﬁne a new layer of type sub net. The
position of the layer is described (e. g. between hidden layer and output layer)
and then the connection structures is deﬁned. The nodes of the hidden layer are
connected to the subnet as described in the connection structure e. g. the nodes
of the hidden layer are connected to the designated input layer of the subnet
and the nodes of the output layer of the subnet are connected to the output
layer of the original net. For simplicity we choose the function ’all’ (all nodes are

On Mathematical Modeling of Networks and Implementation Aspects
175
New Net - [Projection - LRF]
OK
New
Projection 1
New Projection:
New
My View
New View:
New
Distrribution 1
New Distribution:
Fig. 2. Dialog for the deﬁnition of a special large receptive ﬁeld (LRF) projection
connected to all other nodes) between these layers. Connections may be speciﬁed
in detail using the connection structure features (cf.).
Consequently the instance of a layer in the simulation tool will consist of
abstract nodes of one and the same type. For real applications this yields great
ﬂexibility in constructing ANN having processing entities of various types. The
partitioning of the global net into layers corresponding to the description in
our general deﬁnition is a separate process (currently done by the user while
construction the network).
The internal structure of a neural net consists of net components (layers of
neurons or preprocessors or subnets). The data structure used for the represen-
tation of the internal net structure is independent from the connection structure
between processing entities (nodes) or subnets. All processing entities (layers)
are linked using linear lists. The structure of the network (in the sense of graph
theory, i. e. its topology) will be speciﬁed separately following our mathematical
model.
Realization of net structures. Connections between ANN components are
stored in a second step. The data structures used for the locally regularly mod-
eled connection structures are multi-dimensional linear lists. To make the usage
of these structures more clear we start with a description of the user interaction.
(Figure 2 shows the prototype GUI-dialogue for structure modeling.)
From the user point of view a locally regular structure is modeled in 4 steps.
– Selection of a reference point in the postsynaptic layer.

176
R. Bernhaupt and J. Pfalzgraf
reference point
information flow
projection 1
projection 2
Layer 1
Layer 2
002
001
000
003
010
020
011
012
013
021
022
023
002
001
000
003
010
020
011
012
013
021
023
022
Fig. 3. Visualization of an internal structure of two layers and their connections. The
connections are deﬁned by two projection, projection 1 between layer 1 and layer 2,
projection 2 within layer2.
– Determination of the visible area in the presynaptic layer, this area is called
view.
– Determination of the distribution of the connections to the presynaptic layer.
The distribution is the number of neurons connected with the reference point.
A projection is deﬁned as the collection of a reference point, distribution and
view.
– Layers can be diﬀerent in size (in the amount of neurons). To make the
automatic usage of structure more convenient, we use a so-called step size.
E. g. given a retina layer of 256 x 256 neurons and an edge detection layer
consisting of 64 x 64 neurons a step size of 8 is used. If the reference point
is shifted to a neighboring neuron in the edge detection layer, the view is
shifted 8 neurons. Additionally the step size is dependent on the view. In
this example the receptive ﬁeld spans an area of at least 8 neurons.
To ease the use of the simulator, the user may deﬁne several projections. We
noticed that in practice the user can easier deﬁne connection structures within
a layer (lateral connections) in contrast to generating interconnections between
diﬀerent layers. The implementation enables the combination of several (user
friendly) projections. Internally we exploit the mathematical concept of pointed
spaces [Pfa01], [Pfa02]. Figure 3 shows an example of a projection between two
layers.

On Mathematical Modeling of Networks and Implementation Aspects
177
Modeling abstract connection weights. Following our general deﬁnition
connection weights can be of abstract type. For concrete applications we have to
specify the types. A possible connection type can be shunting inhibition being
modeled as a simple data structure. Invisible for the user the two possibilities
are handled diﬀerently in the implementation. In the classical case where con-
nection weights are real values, they are modeled as simple data structures. In
contrast to that, where we have to represent more complex weights (abstract
weights), the connection between two neurons is decomposed into a sequence of
two arrows as shown in ﬁgure 4, using a preprocessor as an intermediate node
between two neurons under consideration. Biologically the preprocessor models
the synaptic behaviour and simulates the electro-chemical processes between the
two connected neurons.
Preprocessor
Presynaptic Neuron
Postsynaptic Neuron
Information Flow
Fig. 4. Internal representation of specialized weights / synapses
Neuron type implementation. A neuron type can be deﬁned by the user.
In a ﬁrst step a neuron base class must be chosen. Then the user has to choose
from a set of functions his neuron type deﬁning set F (see deﬁnition 1). The
current version allows to choose up to 4 functions. Neuron types can be added
dynamically during runtime.
As an example we choose the class rate coded neuron and the neuron type
deﬁning set of functions F = {fsum, fthres}, where fsum represents the forming
of weighted input sums and fthres the step function. The user has to decide
whether the neurons have constant threshold or variable thresholds. Depending
on this speciﬁcation we obtain Pstat = {θfix} and Pdyn = {activity}, where
activity is the variable (in the software engineering sense) representing the neural
activation. Concrete instances of this variable are calculated by fsum. In the
speciﬁc case of a classical McCulloch-Pitts neuron the variable activity has values
{0, 1}.

178
R. Bernhaupt and J. Pfalzgraf
Considering a standard perceptron model where the threshold varies, Pstat =
{} and Pdyn = {θ, activation}, in a concrete application the values of θ are
determined by the used learning procedure and active by evaluating the weighted
sum and the comparison with the current threshold (i. e. the application of the
actual fthres).
4.2
Current State of Work
Currently we are improving the basic modules, like the kernel, training and sim-
ulation handling, XML-handling and we are implementing the ANN-simulator
interface. The number of available functions constituting the neuron types are
limited in the current version. The available functions are rate coded neuron
types (the perceptron and the conductivity coded neuron model). Next steps
are the implementation of the SSM and the implementations of further modules
(e. g. additional learning algorithms). Our goal is to keep the interface of the
ANN-simulator as ’open’ and ﬂexible as possible. An additional module may
complete the ANN-simulator to act as an ANN-simulator-server, accessible for
clients over any net via a special command language. Using a GUI-module a
user-friendly version of the simulator is given for teaching purposes. We already
implemented a prototype- GUI. The main goal in the GUI design is a user-
friendly interface, capable of several visualization features (e. g. a 3D-engine for
the visualization of structures and weight changes during learning steps).
5
Summary and Prospects
This contribution deals with the development of a generic mathematical model
for neural networks. It is a formal basis for design and implementation of a
new neural network simulator where non standard network paradigms can be
simulated. A major aspect of our mathematical approach is the representation
of the network structures (geometric and categorical methods can be applied
and successfully exploited). The main components of the new simulation tool
are described in the second part of the article. A variety of problems remains
providing interesting topics for future work.
Among others we mention the following subjects. As pointed out in [Pfa02]
group operations play a basic role in the problem ﬁeld of network structuring.
With a view to the new simulator it will be relevant to extend the tool by a
module (interface) to computer algebra systems for group theory to handle the
corresponding groups represented by generators and relations. Such a module
will be useful with respect to automatic generation of network structures.
During the implementation process we have learned that ﬂexible design of
ANN, especially when specialized connection structures are used, must lead to a
new insight on learning and learning algorithms. At the moment we are working
on the possibilities to assign each connection to a learning algorithm, not a whole
layer or even subnet. Using diﬀerent neuron types leads to an extensive use of
preprocessors e. g. between time coded and rate coded neuron types. We are

On Mathematical Modeling of Networks and Implementation Aspects
179
seeking to ﬁnd new algorithms to close this gap, to easily transform rate coded
information into time coded information and vice versa.
Further modules extending the simulator concern fuzzy-techniques, genetic
algorithms, robot simulation, and multi agent system (MAS) techniques. In our
group, a new area of activity deals with the combination of MAS and ANN
approaches. Intended applications, among others, will be in the realm of search
engines. A large area of future research concerns homomorphic learning.
Concerning the promising combination of MAS techniques and ANN we aim
at modeling learning agents (and learning MAS). The simulator with its special
network structure may simulate several subnets, representing the agents, which
all use the same input layer (database of the search engine). Logic modeling
(especially so called logical ﬁberings) will also play a basic role [PM00], [Pfa00].
References
[BB98]
J. M. Bower and D. Beeman. The book of GENESIS: Exploring realistic
neural models with the GEnereal SImulation System. Springer-Verlag, New
York, 1998.
[BP01]
R. Bernhaupt and J. Pfalzgraf.
Time Coded Neurons, Geometric Net-
works and Homomorphic Learning In: Advances in Neural Networks and
Applications, pages 268–273. World SES Press, 2001.
[DGRT99]
A. Delorme, J. Gautrais, R. Rullen, and S. Thorpe. SpikeNET: a simulator
for modeling large networks of integrate and ﬁre neurons. Neurocomputing,
26-27:989–996, 1999.
[Gei94]
H. Geiger. Optical quality control with selﬂearning systems using a combi-
nation of algorithmic and neural network approaches. Proceedings of the
Second European Congress on Intelligent Techniques and Soft Computing,
EUFIT’94, Aachen, September 20-23, 1994.
[Ger01]
W. Gerstner. The Handbook of Biological Physics, volume 4, chapter 12,
pages 447–494. Elsevier Science, 2001.
[GP95]
H. Geiger and J. Pfalzgraf. Quality control connectionist networks sup-
ported by a mathematical model.
Proceedings of the International
Conference on Engineering Applications of Artiﬁcial Neural Networks
(EANN’95), 21-23 August 1995, Helsinki. A.B.Bulsari, S.Kallio (Editors),
Finnish AI Society, 1995.
[Lan01]
K. Lang. Single spiking neuronal networks for object recognition. Master’s
thesis, Universit¨at Salzburg, Institut f¨ur Computerwissenschaften, 2001.
[MB99]
W. Maass and C. M. Bishop. Pulsed Neural Networks. MIT Press, 1999.
[Pfa00]
J. Pfalzgraf. The concept of logical ﬁberings and ﬁbered logical controllers.
Proceedings CASYS 2000, August 2000, Liege, Belgium, American Insti-
tute of Physics, D. M. Dubois (ed.), 2000.
[Pfa01]
J. Pfalzgraf. A note on modeling connectionist network structures: geo-
metric and categorical aspects. In Proceedings Artiﬁcial Intelligence and
Symbolic Computation, AISC’2000, July 17-19, 2000, Madrid. Springer
Lecture Notes in AI, vol.1930. J.Calmet, E.Roanes (Eds.), 2001.
[Pfa02]
J. Pfalzgraf. Modeling Connectionist Network Structures: Some Geometric
and Categorical Aspects. Annals of Mathematics and AI (to appear), 2002.

180
R. Bernhaupt and J. Pfalzgraf
[PM00]
J. Pfalzgraf and W. Meixl. A logical approach to model concurrency in
multi agent systems. Proceedings EMCSR 2000, April 25 - 28, Vienna,
2000.
[Six94]
J. Sixt. Design of an artiﬁcial neural network simulator and its integration
with a robot simulation environment. Master’s thesis, Johannes Kepler
University Linz, Institute of Mathematics, 1994.
[Zel94]
A. Zell. Simulation Neuronaler Netze. Addison-Wesley, Bonn, 1994.

Continuous First-Order Constraint Satisfaction
Stefan Ratschan
Institut d’Informatica i Aplicacions, Universitat de Girona, Spain,
stefan.ratschan@risc.uni-linz.ac.at
Abstract. This paper shows how to use constraint programming
techniques for solving ﬁrst-order constraints over the reals (i.e., formulas
in the ﬁrst-order predicate language over the structure of the real
numbers). More speciﬁcally, based on a narrowing operator that
implements an arbitrary notion of consistency for atomic constraints
over the reals (e.g., box-consistency), the paper provides a narrowing
operator for ﬁrst-order constraints that implements a corresponding
notion of ﬁrst-order consistency, and a solver based on such a narrowing
operator. As a consequence, this solver can take over various favorable
properties from the ﬁeld of constraint programming.
Keywords: Constraint Programming, Reasoning
1
Introduction
The problem of solving ﬁrst-order constraints over the reals has numerous appli-
cations (we have created a web-page that lists more than ﬁfty references [23]).
This paper shows how to solve this problem, based on techniques from the ﬁeld
of constraint programming [5,6,29,12]. The basic idea of these techniques is to
reduce the average run-time of algorithms for computationally hard problems
by replacing expensive exhaustive search as much as possible by methods for
pruning elements from the search space for which it is easy to show that they
do not contain solutions. In this paper we extend this idea to ﬁrst-order con-
straints: For proving existential quantiﬁers, one has to search for true elements;
for disproving universal quantiﬁers, one has to search for false elements; as usual
for continuous domains, search means branching here, and in our case, replacing
sub-constraints of the form ∀x∈I φ by ∀x∈I1 φ ∧∀x∈I2 φ where I = I1 ∪I2
(and the corresponding existential case). We try to avoid branching as much
as possible, by ﬁrst extracting elements for which it is easy to compute that
they are (are not) a solution, that is, by replacing a sub-constraint of the form
∀x∈I φ by ∀x∈I′ φ where I′ ⊂I (and the corresponding existential case).
The structure of the proposed solution is parametric in the sense that it
takes as input theory and algorithms from constraint programming, and pro-
vides as output corresponding new theory and algorithms for solving ﬁrst-order
constraints. More speciﬁcally, it takes at input: A speciﬁcation describing a con-
sistency notion for atomic constraints (e.g., box-consistency [5]), and a narrowing
operator that implements this speciﬁcation. It provides as output: A speciﬁca-
tion describing a corresponding consistency notion for ﬁrst-order constraints, a
J. Calmet et al. (Eds.): AISC-Calculemus 2002, LNAI 2385, pp. 181–195, 2002.
c
⃝Springer-Verlag Berlin Heidelberg 2002

182
S. Ratschan
narrowing operator that implements this speciﬁcation, a branch and prune al-
gorithm for computing approximate solutions of ﬁrst-order constraints over the
reals that uses this narrowing operator for pruning. These outputs are accompa-
nied with proofs of their usefulness/optimality. The advantage of using such a
parametric structure is that it provides a clear separation between dealing with
quantiﬁers and narrowing of atomic constraints. This allows the use and combi-
nation of diﬀerent implementations of narrowing operators [12,4,14] for atomic
constraints. As a consequence one can directly beneﬁt from further progress in
continuous (atomic) constraint satisfaction.
As the emphasis of this paper is a general framework on which one can
soundly base various algorithms and further developments, it strives for ease
of reasoning, elegance, and foundational results, instead of detailed eﬃciency
improvements. However, existing similar algorithms and special cases of our
framework [3,25], give strong evidence for the eﬃciency of algorithms based on
our approach.
Up to recently, all algorithms for dealing with this problem, have been based
on computer algebra methods [8,7], which resulted in certain drawbacks (e.g.,
eﬃciency, restriction to polynomials). In an earlier paper [25] the author of this
paper proposed a scheme for solving ﬁrst-order constraints approximately that
followed the idea of quantiﬁer elimination by cylindrical algebraic composition [8,
7], but decomposed space into ﬂoating-point boxes instead of semi-algebraic
cells. This approach was successful in showing that one can eﬃciently compute
approximate solutions of ﬁrst-order constraints using interval methods. However
it still had several drawbacks. Especially, it was not clear when and how to
optimize box splitting, because the algorithm was not separated into (inherently
exponential) search, and pruning. The current paper provides a solution to this,
and other, problems of the older approach.
To our knowledge, other authors have applied constraint programming tech-
niques only to the special case of ﬁrst-order constraints with one universally
quantiﬁed variable [3], or to the special case of disjunctive constraints [16,13,
19,11]. Up to now it was unclear how to extend these approaches to ﬁrst-order
constraints, and which properties such an extension would have.
The content of the paper is as follows: Section 2 gives various preliminaries.
Section 3 introduces the notion of narrowing operator for ﬁrst-order constraints.
Section 4 describes an according notion of ﬁrst-order consistency that speciﬁes
the pruning power of narrowing operators. Section 5 gives a generic algorithm
that implements a ﬁrst-order narrowing operator ensuring ﬁrst-order consistency.
Section 6 bases an according branch-and-prune solver for ﬁrst-order constraints
on this narrowing algorithm. Section 7 discusses the relation of the results to
classical decision algorithms, and Section 8 concludes the paper.
2
Preliminaries
We ﬁx a set V of variables. A ﬁrst-order constraint is a formula in the ﬁrst-
order predicate language over the reals with predicate and function symbols

Continuous First-Order Constraint Satisfaction
183
interpreted as suitable relations and functions, and with variables in V . In this
paper we restrict ourselves to the predicate symbols <, >, ≤, and ≥, and assume
that equalities are expressed by inequalities on the residual (i.e., f = 0 as |f| ≤ε
or f 2 ≤ε, where ε is a small positive real constant1). Furthermore we only deal
with ﬁrst-order constraints without negation symbols because one can easily
eliminate negation symbols from ﬁrst-order constraints by pushing them down,
and replacing atomic constraints of the form ¬(f ≤g) by f > g, and ¬(f < g)
by f ≥g, respectively. As a slight modiﬁcation to the usual syntax in logic we
require that every quantiﬁer be bounded by an associated quantiﬁer bound. This
means that quantiﬁers are of the form ∃x ∈I or ∀x ∈I, where I is a closed
interval.
A variable assignment is a function from V to IR. We denote the semantics
of a constraint φ, the set of variables assignments that make φ true, by [[φ]].
For any variable assignment d, variable v ∈V and real number r, we denote
by d r
v the variable assignment that is equal to d except that it assigns r to v.
The semantics of a constraint of the form ∃x ∈I φ is equal to the semantics of
∃x x∈I ∧φ, and the semantics of a constraint of the form ∀x∈I φ is equal to
the semantics of ∀x x∈I →φ.
Let I be the set of closed real intervals. We denote by I1 ⊎I2 the smallest
interval containing both intervals I1 and I2. A box assignment is a set of variable
assignments that can be represented by functions from V to I; that is, for every
box assignment B, there is a function D : V →I such that B is the set of all d
such that for all v ∈V , d(v) ∈D(v). From now on we will use a box assignment
and its interval function representation interchangeably. For any box assignment
B, variable v ∈V and interval I, we denote by B I
v the box assignment that is
equal to B except that it assigns I to v.
The notation {x →[−1, 1], y →} denotes a box assignment that assigns the
interval [−1, 1] to the variable x and an arbitrary value to the variable y.
Traditionally, constraint programming techniques [5,6,29,12] use boxes (i.e.,
Cartesian products of intervals) instead of box assignments. However, when
working with predicate logic, the additional ﬂexibility of box assignments is
very convenient in dealing with the scoping of variables. For eﬃciency reasons,
an actual implementation might represent box assignments by boxes.
Note that set of box assignments is closed under the operations ∩and ⊎.
A box assignment B′ is a facet of a box assignment B iﬀit results from B by
replacing one of the assigned intervals [a, a] by either [a, a] or [a, a]. For any box
assignment B and term t, interval evaluation [20] yields an overestimation of the
range of t on B (i.e., a superset of all values of t under a variable assignment in
B) and consequently for any atomic constraint φ an overestimation of the truth
of φ on B.
We let ﬁx : ((A →A)×A) ⇀A be a partial function such that for f : A →A
and a ∈A, if there is a positive integer n and a b ∈A such that for all k > n,
f k(a) = b then ﬁx(f, a) = b, and otherwise it is undeﬁned.
1 The constant ε needs to be non-zero because otherwise solutions would vanish under
small perturbations of ε.

184
S. Ratschan
3
First-Order Narrowing
Let us call pairs (φ, B), where φ is a ﬁrst-order constraint and B is a box assign-
ment, bounded constraints. We call the second element of a bounded constraint
its free-variable bound. Now suppose that for a given bounded constraint (φ, B)
we want to remove elements from B that are guaranteed not to be within the
solution set of φ. In a similar way we want to remove elements from B that are
guaranteed to be within the solution set of φ.
Deﬁnition 1. A narrowing operator is a function N↕on bounded constraints
such that for bounded constraints (φ, B), and (φ, B′), and for N ↕(φ, B) =
(φN, BN), and N↕(φ, B′) = (φ′
N, B′
N),
– B ⊇BN (contractance),
– [[φN]] ∩BN = [[φ]] ∩BN (soundness),
– B′ ⊆B implies B′
N ⊆BN (monotonicity), and
– N↕(N↕(φ, B)) = N↕(φ, B) (idempotence).
Note that, in contrast to narrowing operators for constraints without quan-
tiﬁers [2,6], here a narrowing operator can also modify the constraint itself.
Furthermore note that we use a soundness condition here, instead of a correct-
ness condition: We require that the solution set of the resulting constraint be
the same only on the resulting box, but not necessarily on the initial box. We
will ensure full correctness by the next deﬁnition.
Constraint programming techniques for continuous domains traditionally
compute outer approximations of the solution set. However, here we also want to
compute inner approximations for three reasons: First, the solution set of ﬁrst-
order constraints with inequality predicates usually does not consist of singular
points, but of sets that can have volume, and for many applications it is impor-
tant to ﬁnd points that are guaranteed to be within this solution set. Second,
available inner approximations can speed up the computation of outer approxi-
mations and vice versa, because any element known to be within the solution set,
or known to be not in the solution set, does not need to be inspected further.
Third, inner estimations are needed for pruning the search space of universal
quantiﬁers.
So we will allow two kinds of narrowing operators—one that only removes
elements not in the solution set, and one that only removes elements in the
solution set.
Deﬁnition 2. An up-narrowing operator is a narrowing operator N↑such that
for every bounded constraint (φ, B), for the free-variable bound BN of N↑(φ, B),
BN ⊇B ∩[[φ]]. A down-narrowing operator is a narrowing operator N↓such that
for every bounded constraint (φ, B), for the free-variable bound BN of N↓(φ, B),
BN ⊇B \ [[φ]].
For any ﬁrst-order constraint φ, let ⃗¬φ (the opposite of φ) be the ﬁrst-order
constraints that results from ¬φ by eliminating the negation by pushing it down
to the predicates. Now we have:

Continuous First-Order Constraint Satisfaction
185
Theorem 1. Let N↑be a function on bounded constraints and let N↓(φ, B) :=
(⃗¬φN, BN) where (φN, BN) = N↑(⃗¬φ, B). Then N↑is an up-narrowing operator
iﬀN↓is a down-narrowing operator.
Proof. Obviously N↓is a narrowing operator iﬀN↑is a narrowing operator. N↑
is up-narrowing iﬀN↓is down-narrowing because for any bounded constraint
(φ, B), B ∩[[⃗¬φ]] = B \ [[φ]], and B \ [[⃗¬φ]] = B ∩[[φ]].
⊓⊔
A similar observation has already been used for the special case of ﬁrst-order
constraints with one universal quantiﬁer [3]. The above theorem allows us to
concentrate on up-narrowing operators from now on. We get the corresponding
down-narrowing operator for free by applying the up-narrowing operator on the
opposite of the input.
4
First-Order Consistency
In constraint programming the notion of consistency is used to specify the prun-
ing power of narrowing operators. In this section we generalize this approach to
ﬁrst-order constraints. We will call any predicate on bounded constraints that
we will use for such speciﬁcation purposes consistency property.
Example 1. For an atomic bounded constraint (φ, B), BC(φ, B) holds if there is
no facet of B for which interval evaluation will prove that it contains no element
of [[φ]]. In this case we say that φ is box-consistent wrt. B [5,12].
Note that the original deﬁnition of box consistency is slightly weaker in order
to allow a ﬂoating-point implementation. However, in this paper we prefer to
work with abstract, implementation-independent concepts.
The following is the strongest form of consistency that does not result in loss
of information, that is, for which an up-narrowing operator exists.
Example 2. For an atomic bounded constraint (φ, B), HC(φ, B) holds if there
is no box assignment B′ such that B′ ⊂B and [[φ]] ∩B′ = [[φ]] ∩B. In this case
we say that φ is hull-consistent wrt. B [6].
We can use consistency properties as speciﬁcations for the eﬀectiveness of
narrowing operators:
Deﬁnition 3. Given a consistency property C, a narrowing operator N↕ensures
C iﬀfor all bounded constraints (φ, B), C(N↕(φ, B)) holds.
Now we assume a certain consistency property on literals (i.e., atomic con-
straints and their negations) and give a corresponding consistency property on
ﬁrst-order constraints.
Deﬁnition 4. Given a ﬁrst-order constraint φ and a consistency property C on
atomic constraints, let FOCC be the following consistency property

186
S. Ratschan
– if φ is atomic, then FOCC(φ, B) iﬀC(φ, B)
– if φ is of the form φ1 ∧φ2 then FOCC(φ, B) iﬀFOCC(φ1, B) and
FOCC(φ2, B).
– if φ is of the form φ1 ∨φ2 then FOCC(φ, B) iﬀB = B1 ⊎B2 where
FOCC(φ1, B1) and FOCC(φ2, B2).
– if φ is of the form Qy ∈I′ φ′, where Q is a quantiﬁer, then FOCC(φ, B) iﬀ
FOCC(φ′, B I′
y ).
If for a bounded constraint (φ, B), FOCC(φ, B) holds, we say that (φ, B) is
ﬁrst-order C-consistent (FOC-consistent). Note that, in the above deﬁnition, re-
cursion for quantiﬁcation puts the quantiﬁer bound into the free-variable bound
of the quantiﬁed constraint. This means that a narrowing operator also will have
to modify the quantiﬁer bounds in order to achieve ﬁrst-order consistency.
Example 3. The bounded constraint

∃y ∈[0, 1]

x2 + y2 ≤1 ∧y ≥0

, {x →
[−1, 1], y →}

is ﬁrst-order hull consistent, and it will be the result of applying
an according narrowing operator to an input such as

∃y ∈[−2, 2]

x2 + y2 ≤
1 ∧y ≥0

, {x →[−2, 2], y →}

.
Note that Deﬁnition 4 is compatible with the usual consistency notions for
sets of constraints [5,4]. For example a set of atomic constraints {φ1, . . . , φn} is
box-consistent wrt. a box assignment B iﬀ(φ1 ∧· · ·∧φn, B) is FOBC-consistent.
In addition, the method for solving constraints with one universally quantiﬁed
variable by Benhamou and Goualard [3] computes a special case of Deﬁnition 4.
In the following sense, our deﬁnition of FOC-consistency is optimal (remem-
ber that hull consistency is the strongest possible consistency property when
considering bounded constraints as atomic).
Theorem 2. A FOHC-consistent bounded constraint (φ, B), where φ neither
contains conjunctions nor universal quantiﬁers, is HC-consistent.
Proof. We proceed by induction over the structure of constraints. The atomic
case trivially holds. Now assume constraints of the following types:
– For a FOHC-consistent bounded constraint of the form (φ1 ∨φ2, B), by def-
inition, we have B = B1 ⊎B2 where FOCHC(φ1, B1) and FOCHC(φ2, B2).
By the induction hypothesis both (φ1, B1) and (φ2, B2) are hull consistent.
So for no box assignment B′
1 ⊂B1, we have B′
1 ⊇B1 ∩[[φ1]], and for no
box assignment B′
2 ⊂B2, we have B′
2 ⊇B2 ∩[[φ2]]. Thus also for no box
assignment B′ ⊂B1 ⊎B2, we have B′ ⊇B ∩([[φ1]] ∪[[φ2]]) = B ∩[[φ1 ∨φ2]].
– For a FOHC-consistent bounded constraint of the form (∃y ∈I′ φ′, B), by
deﬁnition FOHC(φ′, B I′
y ). Thus, by the induction hypothesis (φ′, B I′
y ) is
hull consistent. So for no box assignment B′
p ⊂B I′
y , B′
p ⊇B I′
y ∩[[φ′]]. As a
consequence also for no box assignment Bp ⊂B, Bp ⊇B ∩[[∃y∈I′ φ′]], and
so (∃y∈I′ φ′, B) is hull consistent.
⊓⊔

Continuous First-Order Constraint Satisfaction
187
The fact that the above theorem does not hold for constraints with conjunc-
tions is well known [6]. It is illustrated in Figure 1, where both φ1 and φ2 are
hull consistent wrt. the box B (i.e. the larger box encloses the ellipses tightly),
but φ1 ∧φ2 is only hull consistent wrt. the smaller box B′ (i.e., the smaller, but
not the larger box, encloses the intersection of the ellipses tightly).
[[φ2]]
B
[[φ1 ∧φ2]]
B′
[[φ1]]
Fig. 1. Fully Pruned Conjunction
For universal quantiﬁcation there is a similar problem: In Figure 2, φ is hull
consistent wrt. the box B, but when considering ∀y∈I φ one can still narrow B
horizontally. So any stronger consistency notion would have to treat universal
quantiﬁcation diﬀerent from existential quantiﬁcation.
B
[[φ]]
Fig. 2. Fully Pruned Universal Quantiﬁcation
5
Narrowing Algorithm
Now assume that we have a consistency property C deﬁned on atomic constraints
and an up-narrowing operator A↑such that for all bounded constraints (φ, B),
where φ is atomic, C(A↑(φ, B)) holds. From this we can construct a general
up-narrowing operator that ensures FOC −consistency.
Narrowing for conjunctive and disjunctive constraints is straightforward. For
bounded constraints of the form (Qx ∈I φ, B) the narrowing operator removes
elements both from the free-variable bound B and the quantiﬁer bound I. It
removes those elements from B for which narrowing of (φ, B I
x) showed that

188
S. Ratschan
they are certainly not in the overall solution set. For existential quantiﬁcation
it additionally removes those elements from the quantiﬁer bound for which nar-
rowing showed that they are not in the solution set of φ. This does not change
the solution set of the overall constraint (i.e., [[∃x ∈I φ]] ∩B), and thus keeps
the soundness property of the narrowing operator. For universal quantiﬁcation
we do not remove elements from the quantiﬁer bound, because here, whenever
narrowing of the sub-constraint shows that certain elements of the quantiﬁer
bound are not in the solution set, we can immediately infer that the universal
quantiﬁer does not hold.
Deﬁnition 5.
– For atomic φ, N↑A (φ, B) = A↑(φ, B),
– N↑A (φ1 ∧φ2, B) = ﬁx(N↑′
A)(φ1 ∧φ2, B)
where N↑′
A (φ1 ∧φ2, B) = (φ′
1 ∧φ′
2, B′
1 ∩B′
2)
where (φ′
1, B′
1) = N↑A (φ1, B) and (φ′
2, B′
2) = N↑A (φ2, B)
– N↑A (φ1 ∨φ2, B) = (φ′
1 ∨φ′
2, B′
1 ⊎B′
2)
where (φ′
1, B′
1) = N↑A (φ1, B) and (φ′
2, B′
2) = N↑A (φ2, B)
– N↑A (∃x∈I φ, B) = (∃x∈B′(x) φ′, B′),
where (φ′, B′) = N↑A (φ, B I
x)
– N↑A (∀x∈I φ, B) = (∀x∈I φ′, D),
where (φ′, B′) = N↑A (φ, B I
x)
and d ∈D iﬀfor all r ∈I, d r
x ∈B′
The reason why here, in contrast to the ﬁrst-order consistency deﬁnition, we
need diﬀerent rules for existential and universal quantiﬁcation, lies in the fact
that for universal quantiﬁcation we even have to remove these elements from
the free-variable bound for which a single corresponding element of the bound
variable has been removed by narrowing of the sub-constraint.
Example 4. For the input

∃y∈[−2, 2]

x2+y2 ≤1∧y ≥0

, {x →[−2, 2], y →}

already used in Example 3, a narrowing operator based on hull consistency ap-
plies itself recursively to (x2 + y2 ≤1 ∧y ≥0 , {x →[−2, 2], y →[−2, 2]}).
Repeated applications of the atomic narrowing operator—until a ﬁxpoint is
reached—will create the constraint (x2 + y2 ≤1 ∧y ≥0 , {x →[−1, 1], y →
[0, 1]}). As a ﬁnal result we get

∃y∈[0, 1]

x2+y2 ≤1∧y ≥0

, {x →[−1, 1], y →
}

.
Example 5. For the input (∀x ∈[−2, 2] x ≥0, {x →}), the algorithm will ﬁrst
narrow (x ≥0, {x →[−2, 2]}) to (x ≥0, {x →[0, 2]}), and then create (∀x ∈
[−2, 2] x ≥0, ∅), indicating that the constraint is false.
Note that the ﬁxed-point operator ﬁx could result in a partial function, that
is, the narrowing algorithm could fail to terminate. For ensuring termination, we
require that narrowing on atomic constraints eventually terminates even when
intermingled with shrinking of the free-variable bound by other operations:

Continuous First-Order Constraint Satisfaction
189
Deﬁnition 6. A narrowing operator N↕is ﬁnitely contracting iﬀthere is no
inﬁnite chain (φ1, B1), (φ2, B2), . . . for which for all k ∈IN, for (φ′, B′) = N↕
(φk, Bk), φk+1 = φ′ and Bk+1 is a strict subset of B′.
This property usually holds for practical implementations, because of the
ﬁniteness of ﬂoating point numbers.
Lemma 1. If A↑is a ﬁnitely contracting narrowing operator then N↑A is a total
function.
Proof. We assume that A↑is ﬁnitely contracting but N↑A is not total. This can
only happen if ﬁx(N↑′
A) is undeﬁned. Consider the chain (φ1
1 ∧φ1
2, B1), (φ2
1 ∧
φ2
2, B2), . . . of bounded constraints created by repeated applications of N↑′
A.
Here (φ1
1, B1), (φ2
1, B2), . . . is an inﬁnite chain as in Deﬁnition 6. So N↑A is
not ﬁnitely contracting, and by induction also A↑is not ﬁnitely contracting—a
contradiction.
⊓⊔
Theorem 3. For every ﬁnitely contracting (atomic) up-narrowing operator A↑,
N↑A is an up-narrowing operator.
Proof. Contractance and idempotence hold by easy induction. For proving that
N↑A is up-narrowing, sound and monotonic we proceed by induction. The ground
case of atomic constraints holds by deﬁnition. Now we have:
– Obviously the composition of two narrowing operators is also a narrowing
operator. So, for constraints of the form φ1 ∧φ2 we just need to show that
N↑′
A is up-narrowing. For (φ′
1, B′
1) = N↑(φ1, B) and (φ′
2, B′
2) = N↑(φ2, B),
by the induction hypothesis B′
1 ⊇B ∩[[φ1]] and B′
2 ⊇B ∩[[φ2]]. Thus also
B′
1 ∩B′
2 ⊇B ∩[[φ1]] ∩[[φ2]] = B ∩[[φ1 ∧φ2]]. The induction step for soundness
and monotonicity is easy.
– For constraints of the form φ1 ∨φ2, for (φ′
1, B) = N↑(φ1, B1) and (φ′
2, B′
2) =
N↑(φ2, B), by the induction hypothesis B′
1 ⊇B ∩[[φ1]] and B′
2 ⊇B ∩[[φ2]].
Thus also B′
1 ⊎B′
2 ⊇B1 ∪B′
2 ⊇B ∩([[φ1]] ∪[[φ2]]) = B ∩[[φ1 ∨φ2]]. The
induction step for soundness and monotonicity is easy.
– For constraints of the form ∃x ∈I φ, the induction step for up-narrowing
is easy. For soundness we have to prove that [[∃x ∈I φ]] ∩B′ = [[∃x ∈
B′(x) φ′]]∩B′, where B′ = N↑A (φ, B I
x). Now by the up-narrowing property
B′ ⊇B ∩[[φ]], and so [[∃x ∈I φ]] ∩B′ = [[∃x ∈B′(x) φ]] ∩B′. This is equal to
[[∃x ∈B′(x) φ′]]∩B, because by the induction hypothesis [[φ′]]∩B′ = [[φ]]∩B′.
– For constraints of the form ∀x ∈I φ, for up-narrowing we have to prove
that D ⊇B ∩[[∀x ∈I φ]], where D is deﬁned as in the corresponding rule
of Deﬁnition 5. So we assume a variable assignment d that is both in B and
[[∀x ∈I φ]], and prove that d ∈D. This means that we have to prove that
for all r ∈I, d r
x ∈B′, where (φ′, B′) = N↑A (φ, B I
x). This is clearly the case
by the semantics of universal quantiﬁcation and the induction hypothesis.
For soundness we have to prove that [[∀x ∈I φ]] ∩D = [[∀x ∈I φ′]] ∩D,
where D is as above. By the quantiﬁer semantics it suﬃces to prove that

190
S. Ratschan
[[φ]] ∩D I
x = [[φ′]] ∩D I
x. This holds, because for all variable assignments
d ∈D, for all r ∈I, d r
x ∈B′, and moreover, by the induction hypothesis
[[φ′]] ∩B′ = [[φ]] ∩B′.
⊓⊔
By easy induction we also get:
Theorem 4. N↑A ensures FOA-consistency.
By applying Theorem 1 we get a corresponding down-narrowing operator
N ↓A from N ↑A. Note, however, that N ↑A and N ↓A do not commute, and
N↑A ◦N↓A is not idempotent.
As for the classical conjunctive case, the complexity of the algorithm in
a ﬂoating-point implementation is polynomial in the problem dimension (the
number of ﬂoating point numbers that one can remove from the quantiﬁcation
bounds is polynomial). So, as desired, narrowing is eﬃcient compared to expen-
sive exhaustive search, and even more so compared to the doubly exponential
complexity of symbolic solvers [8,7].
6
Solver
Now a solver can use narrowing operators to avoid computationally expensive
search (i.e., branching) as much as possible. Algorithm 1 is such a solver for
closed ﬁrst-order constraints. A solver for open ﬁrst-order constraints is an easy
extension that would record the boxes that a narrowing operator proved to be
in or out of the solution set.
Algorithm 1
Input:
A closed ﬁrst-order constraint φ
Output:
The truth-value of φ
(φF , LF ) ←N↑(φ, IR|V |)
(φT , LT ) ←N↑(⃗¬φ, IR|V |)
while LF is not empty and LT is not empty do
φF ←Branch(φF )
φT ←Branch(φT )
(φF , LF ) ←N↑(φF , LF )
(φT , LT ) ←N↑(φT , LT )
if LF is empty then
return F
else
return T
Here the function Branch either replaces a sub-constraint of the form ∃x∈I φ
by ∃x ∈I1 φ ∨∃x ∈I2 φ, where I1 ∪I2 = I, or replaces a sub-constraint of
the form ∀x ∈I φ by ∀x ∈I1 φ ∧∀x ∈I2 φ, where I1 ∪I2 = I. We assume

Continuous First-Order Constraint Satisfaction
191
branching to be fair, in the sense that every quantiﬁer will eventually be split
(ﬁnding such a strategy is easy, but ﬁnding an optimal branching strategy is
highly non-trivial).
For discussing termination of Algorithm 1 it is important to see, that the
problem of computing truth-values/solution sets of ﬁrst-order constraints can
be numerically ill-posed [26]. An example is the ﬁrst-order constraint ∃x ∈
[−1, 1] −x2 ≥0 which is true, but becomes false under arbitrarily small positive
perturbations of the constant 0. As a consequence, it is not possible to design
an algorithm based on approximation that will always terminate (with a correct
result). Note that this situation is similar for most computational problems of
continuous mathematics (e.g., solving linear equations, solving diﬀerential equa-
tions). However, as in these cases, most inputs are still numerically well-posed
(in fact, in a certain, realistic model this is the case with probability one [24]).
One can even argue that, philosophically speaking, the well-posed problems are
exactly the problems that model real-life problems in a meaningful way.
It is beyond the scope of this paper to present all the formal details for char-
acterizing well-posed ﬁrst-order constraints and we will introduce the necessary
concepts in a semi-formal way. For this we replace the discrete notion of truth
of a ﬁrst-order constraint by a continuous notion [26]. We interpret universal
quantiﬁers as inﬁmum operators, existential quantiﬁers as supremum operators,
conjunction as minimum, disjunction as maximum, atomic constraints of the
form f > g or f ≥g as the function denoted by f −g, and atomic constraints
of the form f < g or f ≤g as the function denoted by g −f. We call the result
the degree of truth of a ﬁrst-order constraint and denote it by [[φ]]◦for any con-
straint φ. This function assigns to every variable assignment a real value that is
independent of the variables that are not free in φ. The idea is that the degree
of truth is greater or equal zero for variable assignments that make φ true, and
less or equal zero for variable assignments that make φ false. One can prove [26]
that the problem of computing the truth value of a closed ﬁrst-order constraint
is numerically well-posed iﬀits degree of truth is non-zero.
For giving a termination proof of Algorithm 1, we assume that the given
narrowing operator for atomic constraints always succeeds for well-posed inputs:
Deﬁnition 7. An up-narrowing operator A↑is converging iﬀfor all atomic
constraints φ and chains B0 ⊇B1 ⊇. . . such that
– for all i ∈IN, Bi ⊇Bi+1,
– and 
i∈IN Bi = {d}, where the degree of truth of φ at the variable assignment
d is negative,
there is a k, such that for all l ≥k, the free-variable bound of A↑(φ, Bl) is
empty.
Note that narrowing operators that implement (our abstract version of) box
consistency or hull consistency always fulﬁll this property. However, it is in gen-
eral impossible to fulﬁll for any narrowing operator based on ﬁxed-precision
ﬂoating-point arithmetic. However, the application of the implementation [22]

192
S. Ratschan
of an older method [25] to real-life problems has shown that ﬂoating-point arith-
metic almost always suﬃces in practice.
Lemma 2. Let A↑be a converging up-narrowing operator and let the sequence
(φ1, B1), (φ2, B2), . . . be such that
– for all i ∈IN, Bi ⊇Bi+1, and
– 
i∈IN Bi = {d} such that the degree of truth of φ at the variable assignment
d is negative,
– for all i ∈N, φi+1 results from φi by branching, and
– for all ε > 0 there is a k such that for all l ≥k, the volume of all quantiﬁ-
cation sets in φl is less or equal ε.2
Then there is a k such that for all l ≥k, the free-variable bound of N↑A (φl, Bl)
is empty.
Proof. We proceed by induction over the structure of the constraint φ1. For
atomic constraints the lemma holds because A↑is converging. Now consider the
following cases:
– For constraints of the form φ1 ∧φ2, [[φ1 ∧φ2]]◦(d) = min{[[φ1]]◦(d), [[φ2]]◦(d)}
being negative implies that either [[φ1]]◦(d) is negative or [[φ2]]◦(d) is neg-
ative. Therefore at least one of the sequences (φ1
1, B1), (φ2
1, B2), . . . and
(φ1
2, B1), (φ2
2, B2), . . . where φi
1 is the sub-constraint of φi corresponding to
φ1 and φi
2 is the sub-constraint of φi corresponding to φ2, fulﬁlls the pre-
conditions of the induction hypothesis. Let r ∈{1, 2} be the number of this
sequence. Then there is a k, such for all k ≥l, the free-variable bound of
N↑A (φl
r, Bl) is empty. Thus, by deﬁnition of N↑A, also the corresponding
free-variable bound in the original sequence is empty.
– For constraints of the form φ1 ∨φ2, [[φ1 ∨φ2]]◦(d) = max{[[φ1]]◦(d), [[φ2]]◦(d)}
being negative implies that both [[φ1]]◦(d) and [[φ2]]◦(d) are negative. There-
fore both sequences (φ1
1, B1), (φ2
1, B2), . . . and (φ1
2, B1), (φ2
2, B2), . . . where
φi
1 is the sub-constraint of φi corresponding to φ1 and φi
2 is the sub-constraint
of φi corresponding to φ2, fulﬁll the preconditions of the induction hypoth-
esis. As a consequence there is a k1, such for all l ≥k1, the free-variable
bound of N↑A (φl
1, Bl) is empty, and there is a k2, such for all l ≥k2, the
free-variable bound of N↑A (φl
1, Bl) is empty,
Thus, by deﬁnition of N↑A, for all l ≥max{k1, k2} the free-variable bound
of the l-th element in the original sequence is empty.
– Constraints of the form ∀x ∈I φ′, are replaced by branching into the form
∀x ∈I1 φ′ ∧. . . ∧∀x ∈Ikφ′. Since the degree of truth of ∀x ∈I φ′
at d is negative, by deﬁnition of inﬁmum, there is a b ∈I for which the
degree of truth of φ′ at d × b is negative. Consider the sequence for which
the i-th element consists of the branch of φi that contains d × b, and of Bi.
This sequence fulﬁlls the preconditions of the induction hypothesis, and as
a consequence there is a k, such for all k ≥l, the k-th free-variable bound in
2 This item formalizes the notion of a fair branching strategy.

Continuous First-Order Constraint Satisfaction
193
this sequence is empty. Thus, by deﬁnition of N↑A, also the corresponding
free-variable bound in the original sequence is empty.
– Constraints of the form ∃x ∈I φ′, are replaced by branching into the form
∃x ∈I1 φ′ ∨. . . ∨∃x ∈Ikφ′. Since the degree of truth of ∃x ∈I φ′ at
d is negative, by deﬁnition of supremum, for all b ∈I the degree of truth
of φ′ at d × b is negative. This means that each sequence for which the i-th
element consists of a branch of φi and of Bi fulﬁlls the preconditions of the
induction hypothesis, and as a consequence there is a k, such for all k ≥l,
the k-th free-variable bound in this sequence is empty. Thus, by deﬁnition
of N↑A, also the corresponding free-variable bound in the original sequence
is empty.
⊓⊔
From Lemma 2 and its dual version we get:
Theorem 5. Algorithm 1 terminates for well-posed inputs.
7
Relation to Classical Algorithms
A. Tarski [31] showed that real ﬁrst-order constraints with equality and inequal-
ity predicates, multiplication and addition are decidable. Adding additional func-
tion symbols (e.g., sin, tan), usually removes this property [28,32,17]. Using the
method in this paper one can still compute useful information for these cases,
provided that the input is numerically well-posed.
The complexity bound supplied by Tarski’s method has been improved sev-
eral times [8,27,1]—but the problem is inherently doubly exponential [10,33] in
the number of variables.
The only general algorithm for which a practically useful implementation ex-
ists, is the method of quantiﬁer elimination by cylindrical algebraic decomposi-
tion [8]. This algorithm employs similar branching as the algorithm presented in
this paper. However, its branching operation is much more complicated because
it branches into a ﬁnite set of truth-invariant cells, that is, into pieces whose
value can be computed by evaluation on a single sample point. For being able to
do this, its quantiﬁer bounds can depend on the free variables, and branching is
done based on information from projection polynomials. For implementing these
operations one needs expensive real algebraic number computations.
Instead of branching, quantiﬁer elimination by partial cylindrical algebraic
decomposition [9] employs pruning in a similar sense as described in this pa-
per. However it still decomposes into truth-invariant cells, which again needs
expensive computation of projection polynomials, and real algebraic numbers.
In contrast to this, the narrowing operator provided in this paper is cheap,
and can do pruning in polynomial time. As a result, we have a clear separation
between polynomial time pruning, and exponential branching. So we have a way
of working around the high worst-case complexity of the problem, whenever a
small amount of branching is necessary.

194
S. Ratschan
8
Conclusion
In this paper we have extended constraint satisfaction techniques to ﬁrst-order
constraints over the reals. The result has several advantages over earlier ap-
proaches: Compared to symbolic approaches [8,7] it is not restricted to polyno-
mials, and avoids complicated and ineﬃcient computation with real algebraic
numbers. Furthermore it decreases the necessity for expensive space decomposi-
tion by extracting information using fast consistency techniques. Compared to
earlier interval approaches that could deal with quantiﬁers of some form, it can
either handle a more general case [15,18,3,30], or provides a much cleaner, more
elegant, and eﬃcient framework [25].
In future work we will provide an implementation of an instantiation of our
framework with box-consistency [5], explore diﬀerent branching strategies, ex-
ploit continuity information for eﬃciently dealing with equalities, and study
analogous algorithms for discrete domains.
This work has been supported by a Marie Curie fellowship of the European
Union under contract number HPMF-CT-2001-01255.
References
1. S. Basu, R. Pollack, and M.-F. Roy. On the combinatorial and algebraic complexity
of quantiﬁer elimination. In S. Goldwasser, editor, Proceedings fo the 35th Annual
Symposium on Foundations of Computer Science, pages 632–641, Los Alamitos,
CA, USA, 1994. IEEE Computer Society Press.
2. F. Benhamou. Interval constraint logic programming. In Podelski [21].
3. F. Benhamou and F. Goualard. Universally quantiﬁed interval constraints. In Proc.
of the Sixth Intl. Conf. on Principles and Practice of Constraint Programming
(CP’2000), number 1894 in LNCS, Singapore, 2000. Springer Verlag.
4. F. Benhamou, F. Goualard, L. Granvilliers, and J. F. Puget. Revising hull and
box consistency. In Int. Conf. on Logic Programming, pages 230–244, 1999.
5. F. Benhamou, D. McAllester, and P. V. Hentenryck. CLP(Intervals) Revisited.
In International Symposium on Logic Programming, pages 124–138, Ithaca, NY,
USA, 1994. MIT Press.
6. F. Benhamou and W. J. Older. Applying interval arithmetic to real, integer and
Boolean constraints. Journal of Logic Programming, 32(1):1–24, 1997.
7. B. F. Caviness and J. R. Johnson, editors. Quantiﬁer Elimination and Cylindrical
Algebraic Decomposition. Springer, 1998.
8. G. E. Collins. Quantiﬁer elimination for the elementary theory of real closed ﬁelds
by cylindrical algebraic decomposition. In Second GI Conf. Automata Theory and
Formal Languages, volume 33 of LNCS, pages 134–183. Springer Verlag, 1975. Also
in [7].
9. G. E. Collins and H. Hong. Partial cylindrical algebraic decomposition for quanti-
ﬁer elimination. Journal of Symbolic Computation, 12:299–328, 1991. Also in [7].
10. J. H. Davenport and J. Heintz. Real quantiﬁer elimination is doubly exponential.
Journal of Symbolic Computation, 5:29–35, 1988.
11. L. Granvilliers. A symbolic-numerical branch and prune algorithm for solving non-
linear polynomial systems. Journal of Universal Computer Science, 4(2):125–146,
1998.

Continuous First-Order Constraint Satisfaction
195
12. P. V. Hentenryck, D. McAllester, and D. Kapur. Solving polynomial systems using
a branch and prune approach. SIAM Journal on Numerical Analysis, 34(2), 1997.
13. P. V. Hentenryck, V. Saraswat, and Y. Deville. The design, implementation, and
evaluation of the constraint language cc(FD). In Podelski [21].
14. H. Hong and V. Stahl. Safe starting regions by ﬁxed points and tightening. Com-
puting, 53:323–335, 1994.
15. L. Jaulin and ´E. Walter. Guaranteed tuning, with application to robust control
and motion planning. Automatica, 32(8):1217–1221, 1996.
16. J. Jourdan and T. Sola. The versatility of handling disjunctions as constraints. In
M. Bruynooghe and J. Penjam, editors, Proc. of the 5th Intl. Symp. on Program-
ming Language Implementation and Logic Programming, PLILP’93, number 714
in LNCS, pages 60–74. Springer Verlag, 1993.
17. A. Macintyre and A. Wilkie. On the decidability of the real exponential ﬁeld. In
P. Odifreddi, editor, Kreiseliana—About and Around Georg Kreisel, pages 441–467.
A K Peters, 1996.
18. S. Malan, M. Milanese, and M. Taragna. Robust analysis and design of control
systems using interval arithmetic. Automatica, 33(7):1363–1372, 1997.
19. K. Marriott, P. Moulder, P. J. Stuckey, and A. Borning. Solving disjunctive con-
straints for interactive graphical applications. In Seventh Intl. Conf. on Principles
and Practice of Constraint Programming - CP2001, number 2239 in LNCS, pages
361–376. Springer, 2001.
20. A. Neumaier. Interval Methods for Systems of Equations. Cambridge Univ. Press,
Cambridge, 1990.
21. A. Podelski, editor. Constraint Programming: Basics and Trends, volume 910 of
LNCS. Springer Verlag, 1995.
22. S. Ratschan. Approximate quantiﬁed constraint solving (AQCS).
http://www.risc.uni-linz.ac.at/research/software/AQCS, 2000.
Software package.
23. S. Ratschan. Applications of real ﬁrst-order constraint solving — bibliography.
http://www.risc.uni-linz.ac.at/people/sratscha/appFOC.html, 2001.
24. S. Ratschan. Real ﬁrst-order constraints are stable with probability one.
http://www.risc.uni-linz.ac.at/people/sratscha, 2001. Draft.
25. S. Ratschan. Approximate quantiﬁed constraint solving by cylindrical box decom-
position. Reliable Computing, 8(1):21–42, 2002.
26. S. Ratschan.
Quantiﬁed constraints under perturbations.
Journal of Symbolic
Computation, 33(4):493–505, 2002.
27. J. Renegar.
On the computational complexity and geometry of the ﬁrst-order
theory of the reals. Journal of Symbolic Computation, 13(3):255–352, March 1992.
28. D. Richardson. Some undecidable problems involving elementary functions of a
real variable. Journal of Symbolic Logic, 33:514–520, 1968.
29. D. Sam-Haroud and B. Faltings. Consistency techniques for continuous constraints.
Constraints, 1(1/2):85–118, September 1996.
30. S. P. Shary. Outer estimation of generalized solution sets to interval linear systems.
Reliable Computing, 5:323–335, 1999.
31. A. Tarski. A Decision Method for Elementary Algebra and Geometry. Univ. of
California Press, Berkeley, 1951. Also in [7].
32. L. van den Dries. Alfred Tarski’s elimination theory for real closed ﬁelds. Journal
of Symbolic Logic, 53(1):7–19, 1988.
33. V. Weispfenning. The complexity of linear problems in ﬁelds. Journal of Symbolic
Computation, 5(1–2):3–27, 1988.

J. Calmet et al. (Eds.): AISC-Calculemus 2002, LNAI 2385, pp. 196–207, 2002.
© Springer-Verlag Berlin Heidelberg 2002
Coloring Algorithms for Tolerance Graphs: Reasoning
and Scheduling with Interval Constraints
Martin Charles Golumbic1 and Assaf Siani2
1 Dept. of Computer Science, University of Haifa, Haifa, Israel
 golumbic@cs.haifa.ac.il
2 Dept. of Computer Science, Bar-Ilan University, Ramat-Gan, Israel
siani@cs.biu.ac.il
Abstract. Interval relations play a significant role in constraint-based temporal
reasoning, resource allocation and scheduling problems. For example, the
intervals may represent events in time which may conflict or may be
compatible, or they may represent tasks to be performed according to a
timetable which must be assigned distinct resources like processors or people.
In previous work [G93, GS93, G98], we explored the interaction between the
interval algebras studied in artificial intelligence and the interval graphs and
orders studied in combinatorial mathematics, extending results in both
disciplines.
In this paper, we investigate algorithmic problems on tolerance graphs, a family
which generalizes interval graphs, and which therefore have broader
application. Tolerance graph models can represent qualitative and quantitative
relations in situations where the intervals can tolerate a certain degree of
overlap without being in conflict. We present a coloring algorithm for a
tolerance graph on n vertices whose running time is O(n2), given the tolerance
representation, thus improving previously known results.  The coloring problem
on intervals has direct application to resource allocation and scheduling
temporal processes.
Keywords and Topics: AI, OR applications, reasoning, coloring tolerance
graphs
1   Introduction
Graph G=(V,E) is a tolerance graph if each vertex vV can be assigned an interval on
the real line that represents it, denoted Iv, and a real number tv >0 referred to as its
tolerance, such that for each pair of adjacent vertices, uvE if and only if
|IuIv|min{tu,tv}. The intervals represented by the vertices and the tolerances
assigned to the intervals form the tolerance representation of graph G [see Figure 1].
If the graph has a tolerance representation for which the tolerance tv of the interval Iv
representing each vertex vV is smaller than or equal to the interval’s length, i.e.,
tv|Iv|, then that graph is called a bounded tolerance graph and its representation is a
bounded representation. The family of tolerance graphs was first introduced by

Coloring Algorithms for Tolerance Graphs         197
Golumbic and Monma [GM82]. Their motivation was the need to solve scheduling
problems in which resources that normally we would use exclusively, like rooms,
vehicles, etc. can tolerate some sharing. Since then, properties of this model and quite
a number of variations of it have appeared, and are the topic of a forthcoming
monograph [GT02].  The tolerance graphs are a generalization of probe graphs, a
graph family used for Genome research, which is in itself a generalization of the well-
known family of interval graphs. Tolerance graphs are a sub-family of the Perfect
Graphs [GMT84], and shares the latter’s variety of mathematical and algorithmic
properties [G80]. We are particularly interested in finding algorithms to calculate
specific problems concerning these graphs, like graph coloring or maximum clique
cover, because of their application to constraint-based temporal reasoning, resource
allocation and scheduling problems.
As part of our algorithmic research, we present a coloring algorithm for a tolerance
graph on n vertices whose running time is O(n2), given the interval tolerance
representation. This is an improvement over previously known results of [NM92].
Another problem we deal with in this research is finding all the maximal cliques in a
tolerance graph. Let k be the number of a maximal cliques of a graph G. Since it is
known that k is not polynomially bounded by n for tolerance graphs, we present an
algorithm for iteratively generating all maximal cliques in a graph, which uses as a
subroutine an efficient algorithm for finding all the maximal cliques in a bounded
tolerance graph.
2   Basic Definitions and Background
Let G = (V, E) be an undirected graph. We call N(v)={w | (v,w)E} the (open)
neighborhood of vertex v, and we call N[v] = N(v){v} the closed neighborhood
of v. The pair (v,w)E is an edge and we say that w is adjacent to v, and v and w
are endpoints of the edge (v,w). When it is clear, we will often drop the
parenthesis and the comma when denoting an edge. Thus xyE and (x,y)E will
have the same meaning.
We define the complement of G to be the graph G  = (V, E ), where E ={(x,y)V
 V | x  y and xyE }. Given a subset A	V of the vertices, we define the
subgraph induced by A to be GA=(A,EA), where EA = {xyE |  xA and yA}.
A graph in which every pair of distinct vertices are adjacent is called a complete
graph. Kn denotes the complete graph on n vertices. A subset A	V of r vertices is
an r-clique if it induces a complete subgraph, i.e., if GA isomorphic to Kr. A
single vertex is a 1-clique. A clique A is maximal if there is no clique of G, which
properly contains A as a subset. A clique is maximum if there is no clique of G of
larger cardinality. We denote by (G) the number of vertices in a maximum
clique of G; it is called the clique number of G.

198         M.C. Golumbic and A. Siani
A clique cover of size k is a partition of the vertices V=A1+A2+...+Ak such that
each Ai is a clique. We denote by k(G) the size of the smallest possible clique
cover of G and is called the clique cover number of G.
A stable set (or independent set) is a subset X of vertices no two of which are
adjacent.  We denote (G) to be the number of vertices in a stable set of
maximum cardinality; it is called the stability number of G.
A proper c-coloring is a partition of the vertices V=X1+X2+...+Xc such that each
Xi is a stable set. In such a case, the members of Xi are "painted" with the color i
and adjacent vertices will receive different colors. We denote by (G) the
smallest possible c for which there exists a proper c-coloring of G; it is called the
chromatic number of G.
A graph G is a perfect graph if G has the property that for every induced
subgraph GA of G, its chromatic number equals its clique number (i.e., (GA) =
(GA) ). Due to a theorem of Lovász [L72] perfect graphs may be defined
alternatively, G has the property that for every induced subgraph GA of G, its
stability number equals its clique cover number (i.e., (GA) = k(GA) ). Perfect
graphs are important for their applications and because certain decision problems
that are NP-complete in general have polynomial-time algorithms when the
graphs under consideration are perfect. Tolerance graphs were shown to be
perfect in [GMT84].
Let F be a family of nonempty sets. The intersection graph of F is obtained by
representing each set in F by a vertex and connecting two vertices by an edge if
and only if their corresponding sets intersect. The intersection graph of a family
of intervals on a linearly ordered set is called an interval graph, see Figure 2. The
interval graph's real world applications vary from classic computer science
problems such as scheduling or storage, to a chemical, biological and even
archeological problems (refer to [G80] for details).
                                         a                                    a     2
                                                                                     b  1
                       e                           b                                c        
                                                                                            d  1
                       d                           c                             e         4
                                                                                1  2  3 4 5 6  7  8
Fig. 1. A tolerance graph and a tolerance representation for it.

Coloring Algorithms for Tolerance Graphs         199
It can be easily shown that an interval graph is the special case of a tolerance
graph where the tolerance tv of interval Iv for all vV equals some very small
constant  >0.
Being an interval graph is a hereditary property, i.e., an induced subgraph of an
interval graph is an interval graph. Another hereditary property of interval graph
is that every simple cycle of length strictly greater than 3 possesses a chord.
Graphs that satisfy this property are called chordal graphs. The graph in Figure 2
is chordal, but the graph in Figure 1 is not chordal because it contains a chordless
4-cycle. Therefore, it is not an interval graph. It is, however, a tolerance graph,
which can be seen by the tolerance representation in Figure 1.
                                         a                                   a
                                                                                     b
                       e                           b                                       c
                                                                                                    d
                       d                           c                             e
Fig. 2. An interval graph and an interval representation for it.
A graph said to be weakly chordal if it contains no induced subgraph isomorphic to
Cn or to the complement of Cn for n5. Golumbic, Monma and Trotter [GMT84]
showed that tolerance graphs are weakly chordal. Hayward [H85] showed that
weakly chordal graphs are perfect, and gave some polynomial time algorithms for
problems relating with the chromatic number and the stability number for weakly
chordal graphs. Raghunathan [R89] improve these results and provide O(|E||V|2)
algorithms to find a maximum clique and a minimum coloring of a weakly chordal
graph. He also obtained an O(|V|4) algorithm to find a maximum independent set and
a minimum clique cover of such a graph, and O(|V|5) algorithms for weighted
versions of these problems
A graph G is a comparability graph if each edge in E can be assigned a direction so
that the resulting oriented graph (V,F) satisfies the following condition: ijF and
jkF implies that ikF for all i,j,kV(G). Such an orientation is called a transitive
orientation of G and when such an orientation exists we say that G is transitively
orientable. A co-comparability graph is a graph whose complement is a
comparability graph.
Theorem 2.1 [GM82]. Bounded tolerance graphs are co-comparability graphs.
One proof of this theorem is given in [BFIL95] and uses parallelogram
graphs, which provide another useful way to think about bounded tolerance graphs. A
graph G is a parallelogram graph if we can fix two parallel lines L1 and L2 with L1

200         M.C. Golumbic and A. Siani
above L2, and for each vertex iV(G) we can assign a parallelogram Pi with parallel
sides along L1 and L2 so that G is the intersection graph of {Pi | iV(G)}.
Lemma 2.2 [BFIL95]. A graph is a bounded tolerance graph if and only if it is a
parallelogram graph.
Finally, it is sometimes convenient to assume, without loss of generality as shown in
[GMT84], that any tolerance graph has a regular tolerance representation which
satisfies the following addition properties:
   1. Any tolerance larger than the length of its corresponding interval is set to infinity.
   2. All tolerances are distinct (except for those set to infinity).
   3. No two different intervals share an endpoint.
3   Coloring Tolerance Graphs
The problem of coloring a graph has many applications. Basically, a graph can
represent a collection of objects: the vertices, which relate to each other through the
edges. It is very common to use this structure to model objects that consume
resources, whereby the edges symbolize some restriction on two objects that cannot
consume the same resource simultaneously. The act of coloring a graph, i.e., labeling
the vertices of the graph such that each of any two adjacent vertices receives a
different label, is actually the act of allocating a resource (the label) to an object (the
vertex). Minimal coloring in that sense is therefore utilizing minimal resources
without violating any restriction. For example, consider a model in which lectures are
represented by vertices, any two lectures which take place simultaneously cause an
edge. A minimal coloring of the graph may signify a minimal allocation of
classrooms for this set of lectures. The graph coloring problem is NP-complete for
general graphs, however, efficient polynomial time algorithms are known for many
classes of perfect graphs.
Narasimhan and Manber [NM92] suggested a simple method for computing the
chromatic number (G) of a tolerance graph. This method is based on the facts that
(1) the bounded intervals in the tolerance model form a co-comparability graph
(Theorem 2.1) and that there exists a known algorithm for computing the chromatic
number of co-comparability graphs. Their algorithm results in O(qn3) time, where q is
the number of unbounded intervals in the tolerance model, n is the number of vertices
and O(n3) is the time required for computing the chromatic number of a co-
comparability graph. However, as was shown subsequently, bounded tolerance graphs
are parallelogram graphs (Lemma 2.2), and Felsner et al. [FMW97] suggested an
algorithm for computing the chromatic number of trapezoid graphs (which contain
parallelogram graphs) in optimal O(nlogn) time. Hence, we can use this algorithm for
computing the chromatic number of the bounded intervals, and using the same idea of
[NM92] obtain the chromatic number (G) of a tolerance graph in O(qnlogn) time.
However, their method does not give a coloring for the graph.

Coloring Algorithms for Tolerance Graphs         201
We took this problem a step forward to produce a coloring of the graph. Our
algorithm has complexity O(n2) for general tolerance. In all these algorithms, it is
assumed that a tolerance representation for the graph is given as input, which is
typically the case in most applications. The problem of recognizing tolerance graphs
is a longstanding open question.
3.1   Definitions, Terminology, and Lemmas
Let G=(V,E) be a tolerance graph with a regular tolerance representation <I,t>. We
define the subset of bounded vertices of V as VB={vV | tv  |Iv|}, and the unbounded
vertex subset of V as VU={vV| tv>|Iv|}. Similarly, the induced bounded subgraph is
GB=(VB,E), and the induced unbounded subgraph is GU=(VU,E).
Definition 3.1. An unbounded tolerance vertex vV is labeled an inevitable
unbounded vertex in G (for a certain tolerance representation), if the following holds:
(1) v is not an isolated vertex.
(2) tv > |Iv|.
(3) Setting v’s tolerance to its length (i.e. tv=|Iv|) creates a new edge in the
representation (i.e., the representation is no longer a tolerance representation for G).
Definition 3.2. An inevitable unbounded tolerance representation for G is a tolerance
representation, where every unbounded tolerance vertex is an inevitable unbounded
vertex.
Lemma 3.3. Every tolerance representation can be transformed into an inevitable
unbounded representation in O(n2) time.
Proof. We will scan the representation from left to right. At any point during the
algorithm we are aware of the active intervals, i.e., the intervals whose left endpoint
has been scanned but whose right endpoint hasn’t. Whenever a left endpoint of
unbounded interval I is scanned, we check whether there is, among the active
intervals, an interval which contains the interval I (i.e., its right endpoint is larger than
r(I) and the interval’s tolerance is larger than |I|). If such an interval exists, then
reducing I's tolerance to its length will cause a new edge in the representation between
I and that interval. If no such interval exists, reduce I to its length. Otherwise, check
whether there is some interval that forms an edge with I. If no such interval exists,
then I is a isolated interval. In this case, make it the rightmost interval and make its
tolerance equal to its length. If there is an interval adjacent to I, then I is left with
unbounded tolerance. The scan is continued with the modified representation.   
Definition 3.4. Let vV be an inevitable unbounded vertex in G (for some
representation <I,t>), then there is (at least) one bounded vertex uV for which uvE
and IvIu (tu > |Iv|). The vertex u is called a hovering vertex for v and Iu is called a
hovering interval for Iv.

202         M.C. Golumbic and A. Siani
Definition 3.5. We define the hovering vertex set (abbreviated HVS) for some
inevitable unbounded vertex vV to be the set of all hovering vertices of v, i.e.,
HVS(v)={u| u is a hovering vertex for v).
Lemma 3.6. Let vV be an inevitable unbounded vertex in G (for some representation
<I,t>). The set HVS always contains (at least) one bounded interval.
Proof. Since v is an inevitable unbounded vertex, hence there is some vertex w1V
where Iv
1
w
I
. Supposing 
1
wt
= 
, then w1 is an inevitable unbounded vertex and
there is some vertex w2V where 
1
w
I

2
w
I
. By induction this continues until we get
Iv
1
w
I

2
w
I
 ... 
k
w
I
 where wk is a bounded vertex and 
k
w
I
 > 
1
−
k
w
I
 >
...>
1
w
I
> 
vI
, hence wkvE and therefore 
k
w
I
HVS(v). 
Lemma 3.7. Let vV be an inevitable unbounded vertex in G (for a representation
<I,t>). We can find some bounded interval Iw, IwHVS(v), to be a representative
interval for the set HVS(v) in O(n2) time.
Proof. We will scan the representation from left to right. At any point during the
algorithm we are aware of the active intervals, i.e., the intervals whose left endpoint
has been scanned but their right endpoint hasn’t. We will search amongst the active
intervals for some bounded interval Iw that contains Iv, which is not adjacent to Iv (we
know that such an interval exists from Lemma 3.6). We choose this interval to be a
representative for HVS(v).                                                                                          
3.2   Algorithm for Coloring Tolerance Graphs
On one hand, if every maximum clique in G contains an unbounded vertex, then we
can color GB as a co-comparability graph (or parallelogram graph), give the set of
vertices VU a different color, and we are done. If, on the other hand, there exists a
maximum clique in G which does not contain an unbounded vertex, then we should
do the following: (1) color GB as a co-comparability graph or parallelogram graph, (2)
for every vertex vVU, insert v into the color-set of a representative vertex wHVS(v).
This is justified since vwE and so N(v)	N(w), hence no neighbor of v is present in
the color-set of w, and thus this is a proper coloring of G .
Thus, a preliminary algorithm could require that we find all maximum cliques in the
graph and check whether they contain an unbounded tolerance vertex or not.
However, for every inevitable unbounded tolerance vertex vV, HVS(v) contains
some bounded vertex which would be colored when coloring GB, and thus can
determine a color for v. It follows that we do not need the maximum cliques after the
transformation of Lemma 3.3 has been applied. Knowing the above, we conclude the
following algorithm:

Coloring Algorithms for Tolerance Graphs         203
Algorithm 3.1.
Color GB as a co-comparability graph (or parallelogram graph).
For every inevitable unbounded vertex vVU,
insert v into the color-set of some representative vertex wHVS(v).
Correctness
Clearly, the coloring for GB is proper. For every unbounded interval Ii we have some
bounded interval Ij such that IiIj but vivjE, which implies that tj>|Ii|. Clearly, every
interval Ik which forms an edge with Ii has to be bounded, and thus we get
|IjIk||IkIi|min{tk,ti}=tk, implying that vjvkE, and that vk is not in the color set of
vj. Therefore, if we insert vi into the color set of vj, there will be no vertex in that color
set to form an edge with vi, and thus the coloring is proper.  
Complexity
The algorithm consists of three stages: the first stage is a transformation of the
tolerance representation into an inevitable unbounded one. The transformation takes
O(n2) time (because we need to check each intersecting interval of every unbounded
tolerance interval). The second stage is finding a representative interval for the HVS
set of every unbounded tolerance interval which also takes O(n2) time, for the reasons
mentioned above. Finally, the third stage is the coloring itself, which is also divided
into three parts: the first part is a transformation of the tolerance representation (of the
bounded intervals) into a parallelogram representation, which takes linear time. The
second part is the coloring of the parallelogram representation, which is done in
O(nlogn) time [FMW97]. The third part is the coloring of each unbounded tolerance
interval; this takes linear time, for the procedure is simply labeling the unbounded
intervals with the color of their HVS’s set representative. The total time is therefore
O(n2). 
We conclude by noting that since tolerance graphs are perfect, (G) = (G), and our
coloring algorithm can easily find a maximum clique at the same time.
4   All Maximal Cliques of Tolerance Graphs
A maximal clique in a graph G is a complete set X of vertices such that no superset of
X is a clique of G. Finding all maximal cliques is sometimes necessary to find a
solution for other problems. For example, cut vertices, bridges and vertex-disjoint
paths can all be determined easily once the maximal cliques are known. In this
section, we will present a method for computing all maximal cliques of tolerance
graphs, given the tolerance model of the graph. For solving the all-maximal cliques
problem we used the same method as with the coloring problem in section 3, i.e., we
solve the problem for the induced graph containing only the bounded vertices and

204         M.C. Golumbic and A. Siani
later we deal with the unbounded vertices. Unfortunately, the number of maximal
cliques for the induced bounded intervals may be exponential. However, for interval
graphs, as with all chordal graphs, the number of maximal cliques is at most |V|. Our
algorithm especially suits subfamilies of tolerance graphs where computing all
maximal cliques for the induced subgraph containing only bounded vertices is done in
polynomial time.
4.1   All Maximal Cliques of a Tolerance Graph
Let G=(V,E) be a tolerance graph and let <I,t> be a regular tolerance representation
for G. Let VB be the set of all bounded vertices in V in this representation, and let VU
be the set of all unbounded vertices in V. We will use KX to denote the set of all
maximal cliques of any set of vertices X, X	V. We define the set KG to be the set of
all maximal cliques in G, and let KB denote the set of all maximal cliques in GB. For
every u VU, let KN(u) denote the set of all maximal cliques in the graph GN(u), which is
the subgraph induced from G by the neighbors of the vertex u. Clearly, for every u
VU and YKN(u), Y{u} is a maximal clique in G. Finally, let KN[u] denote the set of all
maximal cliques in 
]
[u
N
G
, i.e., KN[u]={Y{u} | YKN(u) }.
Theorem 4.1. 


















=
∈
∈



U
u
u
N
U
u
u
N
B
G
K
K
K
K
]
[
)
(
\
.
Proof. ("	" part.) Let Y be a maximal clique in G, i.e. YKG. If Y does not contain
any unbounded vertex, then YKB and is not in any KN[u] where uU. Otherwise, Y
contains an unbounded vertex u VU (Y may contain only one such vertex since Y is a
clique). Y\{u} is a maximal clique in GN(u) and YKN[u].
("" part.) Assume Y 


















∈
∈



U
u
u
N
U
u
u
N
B
K
K
K
]
[
)
(
\
.
Suppose to the contrary that there is some Y’KG such that YY’. If Y’ does not
contain an unbounded vertex, then YKB  - a contradiction. Hence, Y’ contains an
unbounded vertex uU. But in that case Y’\{u}KN(u), and Y’KN[u], a contradiction.

Now, if GB belongs to a known hereditary graph family, for which we have an
algorithm for computing all maximal cliques of that family, we can use that algorithm
to compute KB and KN[u] for every uU, since GN(u) is also a graph of the same family
because all the vertices in N(u) are bounded.
Recall from section 3, that we defined the terms inevitable unbounded representation
and the HVS set of an inevitable unbounded interval/vertex. Also recall that each
neighbor vertex of some unbounded vertex u VU is a neighbor vertex of every vertex
vHVS(u). Algorithm 4.1 is based on the following lemma.

Coloring Algorithms for Tolerance Graphs         205
Lemma 4.2. Let vB be a hovering vertex of u, i.e., vHVS(u). For every YKN(u),
there is some Y’KN[v] for which Y	Y’.
Proof. Clearly, for every vertex wN(u), wN(v). Hence, for every maximal clique
YKN(u), either Y is maximal clique of KN[v] or there is some other maximal clique
Y’KN[v] such that YY’.
Let vB be a hovering vertex of u. By lemma 4.2, we can compute all the maximal
cliques of GN(u) by taking all the maximal cliques in G containing v and deleting any
vertex which is not adjacent to u, as we do next in algorithm 4.1.
Algorithm 4.1
Let G=(V,E) be a tolerance graph and let <I,t> be an inevitable unbounded
representation for G.
(1) Compute KB, let 
Computed
B
K
KB.
(2) For any unbounded vertex u VU,
(2.1) Let w VB be a hovering vertex of u, i.e., w is some representative of
HVS(u).
(2.2) For any maximal clique YKB containing w, compute the set
Y’={Y\{w}}N(u).
(2.3) If Y’ then 
Computed
U
K

Computed
U
K
{Y’{u}}.
Theorem 4.3. KG = 
Computed
B
K

Computed
U
K
Proof. . ("	" part) Let Y KG  be a maximal clique in G. If Y does not contain any
unbounded vertex, then Y
Computed
B
K
. Otherwise, Y contains some unbounded vertex
uU (Y may contain only one such vertex since Y is a clique). For each vHVS(u),
there exists some maximal clique Y’ such that Y\{u}Y’, hence by the algorithm
Y
Computed
U
K
.
("" part) Assume that Y
Computed
B
K

Computed
U
K
. Suppose to the contrary that there
is some Y’KG where YY’. If Y’ contains only bounded tolerance vertices it is a
contradiction for 
Computed
B
K
 being the set of all maximal cliques of GB. Hence, Y’
must contain some uU. The set Y’\{u} is a set of bounded vertices, hence there is a
clique set Y’’
Computed
B
K
 such that Y’\{u}Y’’, and Y’’ contains vHVS(u) (v is the
reason for the proper inclusion of Y’\{u} in Y’’). But this is a contradiction since
Y’’\{v}N(u) 
Computed
U
K
.

206         M.C. Golumbic and A. Siani
4.2   The Number of All Maximal Cliques in a Tolerance Graph
As previously mentioned, the number of all maximal cliques of tolerance graph may
be exponential. Bounded tolerance graphs, a subfamily of tolerance graphs, contains
the permutation graph family. Consider the permutation diagram in Figure 3, which
has 2n lines, such that each line intersects with all the other lines except for one line.
We can choose one line of any two parallel lines, and the result would be a maximal
clique in the permutation graph. It is easy to see that we have 2n maximal cliques in
this graph. Hence, the number of maximal cliques of a tolerance graph may be
exponential.
As a result, the algorithm presented for computing all maximal cliques of tolerance
graphs is one, which iteratively generates them. In the case where the bounded
vertices of the graph form a subgraph of a structured family whose maximal cliques
may be computed in polynomial time using a known algorithm, as with the family of
probe graphs, the method then becomes polynomially efficient.
                                           v1  v2         v3  v4      ...      v2n-1  v2n
                                                                         ...
                                            v2n-1 v2n         ...         v3  v4      v1  v2
Fig. 3. Permutation diagram whose permutation graph has 2n vertices and exactly 2n maximal
cliques.
References
[BFIL95]
K. Bogart, P. Fishburn, G. Isaak and P. Langley, Proper and unit tolerance graphs,
Discrete Applied Math. 60 (1995) 37-51.
[F98]
S. Felsner, Tolerance graphs and orders, J. of Graph Theory 28 (1998) 129-140.
[FMW97] S. Felsner, R. Müller, L. Wernisch, Trapezoid graphs and generalizations,
geometry and algorithms, Discrete Applied Math. 74 (1997) 13-32.
[G80]
M.C. Golumbic, Algorithmic Graph Theory and Perfect Graphs, Academic Press,
New York, 1980.
[G93]
M.C. Golumbic, Reasoning about time, Invited talk, AISMC-1 Karlsruhe,
Germany, August 3-6, 1992, abstract in LNCS 737 (1993) p. 276.
[G98]
M.C. Golumbic, Reasoning about time, in "Mathematical Aspects of Artificial
Intelligence", F. Hoffman, ed., American Math. Society, Proc. Symposia in Applied
Math., vol. 55, 1998, pp. 19-53.
[GM82]
M.C. Golumbic and C.L. Monma, A generalization of interval graphs with
tolerances, in: Proceedings 13th Southeastern Conference on Combinatorics, Graph
Theory and Computing, Congressus Numerantium 35 (1982) 321-331.
[GMT84]
M.C. Golumbic, C.L. Monma and W.T. Trotter Jr., Tolerance graphs, Discrete
Applied Math. 9 (1984) 157-170.

Coloring Algorithms for Tolerance Graphs         207
[GS93]
M.C. Golumbic and R. Shamir, Complexity and algorithms for reasoning about
time: a graph-theoretic approach, J. Assoc. Comput. Mach. 40 (1993), 1108-1133.
[GT02]
M.C. Golumbic and Ann N. Trenk, Tolerance Graphs, monograph in preparation.
[H85]
R. Hayward, Weakly triangulated graphs, J. Combin. Theo. Ser. B 39 (1985) 200-
209.
[HHM90] R. Hayward, C. Hoàng, and F. Maffray, Optimizing weakly triangulated graphs,
Graphs and Combinatorics 6 (1990) 33-35. Erratum to ibid, 5:339-349.
[L72]
L. Lovász, Normal hypergraphs and the perfect graph conjecture, Discrete Math. 2
(1972), 253-267.
[NM92]
G. Narasimhan and R. Manber, Stability number and chromatic number of
tolerance graphs. Discrete Applied Math. 36 (1992) 47-56.
[R89]
A. Raghunathan, Algorithms for weakly triangulated graphs, Univ. of Calif.
Berkeley, Technical Report CSD-89-503 (April 1989).

A Genetic-Based Approach for Satisﬁability
Problems
Mohamed Tounsi
Computer Science Department,
Ecole des Mines de Nantes
4, Rue Alfred Kastler, 44307 Nantes, France
Mohamed.Tounsi@emn.fr
Abstract. We present a genetic-based approach to solve SAT problem
and NP-complete problems. The main idea of the approach presented
here is to exploit the fact that, although all NP-complete problems
are equally diﬃcult in a general computational sense, some have much
better genetic representations than others, leading to much more suc-
cessful use of genetic-based algorithm on some NP-complete problems
than on others. Since any NP-complete problem can be mapped into
any other one in polynomial time by a transformation, the approach
described here consists of identifying and ﬁnding a canonical or generic
NP-complete problem on which genetic algorithm work well, and solving
other NP-complete problems indirectly by translating them onto the
canonical problem. We presented some initial results where we have
the Boolean Satisﬁability Problem (SAT) as a canonical problem, and
results on Hamiltonian Circuit problem which represent a family of
NP-complete problems, it can be solved eﬃciently by mapping them
ﬁrst onto SAT problems.
Keywords: SAT, Genetic Algorithm, NP-complete Problem, Hamilto-
nian Circuit.
1
Introduction
A strong progress on solving SAT problems, as local search methods [LSM92]
and many of its variants were made last decade. These methods were applied
on strong instances of SAT and given a good results. The canonical example of
a problem in NP is the boolean satisﬁability problem (SAT): given an arbitrary
boolean expression of n variables, does exist an assignment to those variables
such that the expression is true? Other examples include job shop scheduling
and traveling salesman problems. The concept of NP-completeness comes from
the observation that, although every problem L in NP can be transformed into
an equivalent SAT problem in polynomial time1, the reverse polynomial time
transformation may not exist. Those problems in NP which do have 2 way trans-
formations form an equivalence class of ”equally hard” problems and have been
1 Cookes theorem
J. Calmet et al. (Eds.): AISC-Calculemus 2002, LNAI 2385, pp. 208–216, 2002.
c
⃝Springer-Verlag Berlin Heidelberg 2002

A Genetic-Based Approach for Satisﬁability Problems
209
called NP-complete problems [GJ79]. Although NP-complete problems are com-
putationally equivalent in this complexity theoretic sense, they do not appear
to be equivalent at all with respect to how well they map onto genetic rep-
resentations (GAs). For example, in the case of GAs, the SAT problem has a
very natural representation while ﬁnding eﬀective representations for bin pack-
ing problem, job shop scheduling problem, and travel salesman problem seems to
be quite diﬃcult [Gol89] [GL85]. Those observations suggest the following idea:
suppose we are able to identify an NP-complete problem which has an eﬀective
representation in the methodology of interest Genetic Algorithms (GAs) and
develop an eﬃcient problem solver for that particular case. Other NP-complete
problems which don’t have eﬀective representations can then be solved by trans-
forming them into the canonical problem, solving it, and transforming the solu-
tion back to the original one. We have explored this strategy in detail for genetic
algorithms using SAT as the canonical NP-complete problem. The (GAs) can
achieve power and generality by demanding that problems be mapped into their
own particular representation in order to be solved. If a natural mapping exists,
good performance results. On the other hand, if the mapping is diﬃcult, our ap-
proach behave much like the more traditional weak methods yielding mediocre,
unsatisfying results. These observations suggest two general issues which deserve
further study. First, we need to understand how severe the mapping problem is.
Are there large classes of problems for which eﬀective mappings exist? Clearly,
if we have to spend large amounts of time and eﬀort in constructing a mapping
for each new problem, then it is not a better way than the more traditional
complete methods. It focuses on GAs and how they can be applied to a large,
well known class of combinatorially explosive problems: NP-complete problems.
We introduce in this paper a genetic algorithm to SAT and recall what is genetic
and SAT problem and the components of our algorithm: population, mutation
and crossover operators, then followed by a new valuation function to be used in
our algorithm. Some preliminary results on two families of SAT problem are pre-
sented with results on a NP-complete problem : the Hamiltonien Circuit problem
(HC). We conclude with a discussion and future works.
2
Genetic Algorithms for SAT
The ﬁeld of Genetic Algorithms has grown into a huge area over the last few
years [Raw91]. GAs are adaptvie methods [EvdH97] [Koz92], which can be used
to solve search and optimization problems over a period of generations, based
upon the genetic processes of biological organisms over principles of natural se-
lection and survival of ﬁttest. In order to apply GAs to a particular problem,
we need to select an internal string representation for the solution space and de-
ﬁne an external evaluation function which assigns utility to candidate solutions.
Both components are critical to the success or failure of the GAs on the prob-
lem of interest [Rud94]. We have selected SAT as the choice for our canonical
NP-complete problem because it appears to have a good string representation,
namely, binary strings of length N in which the ith bit represents the truth value

210
M. Tounsi
of the ith boolean variable of the N boolean variables present in the expression.
It is hard to imagine a representation much better suited for use with GAs
[ARS93]: it is ﬁxed length, binary, and context independent in the sense that
the meaning of one bit is unaﬀected by changing the value of other bits [H79].
Thus, the use of genetic algorithm to solve an optimization problem requires a
data encoding to build gene strings [Lan98].
Our basic genetic algorithm fellows the following steps :
1. Encoding data problems on binary variables: The encoding function
is easy, so population is composed of individuals, an individual is a suite of
N bits, each bit represent one variable.
2. Valuation function: The ﬁtness function or valuation function is computed
during the search, it gives the adequation of the bits sequence. Takes value
in [0, 1] (cf. next section), it is function to maximize.
3. Crossover:
the crossover operator is easily done, for two individuals of
N bits randomly chosen, they are crossed by randomly choosing a position,
cutting each individuals in this position and glue the ﬁrst part of each with
the second part of the others and inversely. In our experiments, we have
taken the crossover rate equal 60%.
4. Mutation: from each individual of N bits, we inverse one bit randomly, the
rate of mutation taken is 1%.
5. Back to step 2
2.1
A New Valuation Function
In order to compare between two individuals, we must have an utility function
called “valuation function” or “ﬁtness function”. The simplest and most natural
function assigns a valuation of 1 to a candidate solution (string) if the values
speciﬁed by that string result in the boolean expression evaluating to TRUE,
and 0 otherwise. However, for problems of interest the valuation function
would be 0 almost every where and would not support the formation of useful
intermediate building blocks. Even though in the real problem domain, partial
solutions to SAT are not of much interest, they are critical components of a
genetic approach [Gat98]. One approach to providing intermediate feedback
would be to transform a given boolean expression into conjunctive normal
form (CNF) and deﬁne the valuation to be the total number of conjuncts
which evaluate to true. While this makes some intuitive sense, one cannot in
general perform such transformations in polynomial time without introducing
a large number of additional boolean variables which, in turn, combinatorially
increase the size of the search space [BEV98]. An alternative would be to assign
valuation to individual clauses in the original expression and combine them in
some way to generate a total valuation value. In this context the most natural
approach is to deﬁne the value of TRUE to be 1, the value of FALSE to be 0,
and to deﬁne the value of simple expressions as follows:

A Genetic-Based Approach for Satisﬁability Problems
211
valuation(NOT
x) = 1 −valuation(x)
valuation(AND
x1...xn) = Min(valuation(x1), ..., valuation(xn))
valuation(OR
x1...xn) = Max(valuation(x1), ..., valuation(xn))
Since any boolean expression can be writen into these basic elements, one has
a systematic mechanism for assigning valuation. Unfortunately, this mechanism
is no better than the original one since it still only assigns valuation values of
0 and 1 to both individual clauses and the entire expression. However, a minor
change to this mechanism can generate diﬀerential valuations:
valuation(AND
x1...xn) = average(valuation(x1), ..., valuation(xn))
This suggestion was made ﬁrst by Smith [H79] and justiﬁed by the expression
can be “more nearly true” [EvdH97], for example the (table 1) gives the results
of valuation: X1
AND
(X1
OR
X2).
Table 1. Valuation Function
X1 X2
VALUATION
0
0 (average 0 (Max(0(1 −0))))= 0.5
0
1 (average 0 (Max(0(1 −1))))= 0.0
1
0 (average 1 (Max(1(1 −0))))= 1.0
1
1 (average 1 (Max(1(1 −1))))= 1.0
Notice that both of the correct solutions (lines 3 and 4) are assigned a val-
uation of 1 and, of the incorrect solutions (lines 1 and 2), line 1 gets higher
valuation because it got half of the AND right. However, there were a number
of features of this valuation function that must be improved. The ﬁrst and ob-
vious property of using average to evaluate AND clauses is that the valuation
function is not invariant under standard boolean equivalence transformations.
For example, it violates the associativity law:
valuation((X1 AND X2) AND X3) ̸= valuation(X1 AND (X2 AND X3))
since : (average(average X1 X2) X3) ̸= (average X1(average X2 X3))
However, one could argue that a weaker form of invariance could be adequate
for use with genetic algorithms. By that we mean that the valuation function
should assign the same value (1, but could even be a set of values) to all correct
solutions of the given boolean expression, and should map all incorrect solutions
into a set of values (0 ≤value < 1) which is distinct and lower than the correct
ones. In general, it can be shown that, although the valuation does not assign
the value of 1 to non-solutions, it frequently assigns values ≤1 to good solutions
and can potentially give higher valuation to non-solutions.
A careful analysis, indicates that these problems only arise when DeMorgan laws
are involved in introducing terms of the form (AND...). This suggests a simple
preprocess: for each boolean expression apply DeMorgan laws to remove such

212
M. Tounsi
constructs. It also suggests another interesting opportunity. Constructs of the
form OR... are computed correctly, but only take on value 0 or 1. By using
DeMorgan laws to convert these to AND constructs, we introduce additional
diﬀerential valuation. Fortunately, unlike the conversion to CNF, this process
has only linear complexity and can be done quickly and eﬃciently.
In summary, with the addition of this preprocessing steps, we now have an ef-
fective valuation function for applying genetic algorithm to boolean satisﬁability
problems.
3
Experiments on SAT Problems
Our ﬁrst set of experiments involves constructing several families of boolean
expressions for which we can control the size and the diﬃculty of the problem.
The ﬁrst family selected consists of family of two solutions (SAT2S) of the form:
(AND
x1...xn)
OR
(AND
x1...xn)
which have exactly two solutions (all 0s and all 1s). By varying the number n
of boolean variables, one can observe how the genetic algorithm perform as the
size of the search space increases exponentially while the number of solutions
remains ﬁxed. Figure 1 presents the results of varying N between 10 and 90 (i.e.
for search spaces ranging in size from 210 to 290 ). It is clear that the diﬀerential
valuation function is working as intended, and that our algorithm can locate
solutions to (SAT2S) problems without much diﬃculty (ﬁgures 1,2).
90
80
70
60
10
20
30
40
50
0
5000
10000
15000
20000
#tests
#variables
Fig. 1. Results on SAT(2S)
80
60
40
1
2
3
4
5
20
#variables
log(#tests)
Fig. 2. The log-log results on SAT(2S)
To make things more diﬃcult, we changed the problem by turning one of the
solutions into a one solution problem (SAT1S) as follows:
(AND
x1...xn)
OR
(AND
x1x1...xn)
so that the solution is all at 1.

A Genetic-Based Approach for Satisﬁability Problems
213
Figure 3 presents the results of log-log of applying our algorithm to the
SAT1S family with n ranging from 10 to 90. As before, we see that the GAs
have no diﬃculty in ﬁnding the correct solution.
0 
1 
2 
3 
4 
5 
20 
80 
60 
40 
#variable=log(search space) 
log(tests) 
Fig. 3. The log-log results on SAT(1S)
Since we are dealing with problems for which there are no known polynomial
time algorithms, we have been particularly interested in the log-log graphs.
Notice that, for both the (2S) and (1S) problems, a sub-linear curve is gener-
ated, indicating an improvement over systematic search. The form that these sub-
linear curves take give some indication of the speedup (over systematic search)
obtained by using genetic algorithm. If, for example, these curves are all loga-
rithmic in form, we will have a good algorithm. Additional discussion of these
curves will occur in a later section after more data has been presented. With
these ﬁrst results, we were eager to apply a genetic algorithm to more naturally
arising boolean expressions. So, we have chosen to look at other NP-complete
problems: Hamiltonian Circuit problems.
3.1
Solving Hamiltonian Circuit Problems
The Hamiltonian Circuit (HC) problem consists of ﬁnding a tour through a
directed graph that touches all nodes exactly once. It is a particular case of
travel salesman problem. Clearly, if a graph is fully connected, this is an easy
task. However, as edges are removed the problem becomes much more diﬃcult,
and the general problem is known to be NP-Complete. Attempting to solve this
problem directly with genetic algorithm raises many of the same representation
issues as in the case of traveling salesman problems [Ga84]. However, it is not
diﬃcult to construct a polynomial time transformation from HC problems to
SAT problems. The deﬁnition of the HC problem implies that, for any solution,
each node must have exactly one input edge and one output edge. If any tour

214
M. Tounsi
violates this constraint, it cannot be a solution. Therefore, an equivalent boolean
expression is simply the conjunction of terms indicating valid edge combinations
for each node. As an example, consider node X5. Node X5 has two output edges
and one input edge. The output edge constraints are given by the exclusive
OR, ((X5X1
AND
X5X2)
OR
(X5X1
AND
X5X2)). The input edge
is described simply by X4X5. The assignments to the edge variables indicate
which edges make up a tour, with a value of 1 indicating an edge is included and
a value of 0 if it is not. This transformation is computed in polynomial time,
and a solution to the HC problem exists if and only if the boolean expression is
satisﬁable.
x1
5
6
x2
x3
x4
x5
1
2
3
4
7
Fig. 4. An example of circuit Hamilto-
nian problem
1 
2 
3 
4 
5 
6 
20 
60 
40 
#lvariables=log(search space) 
#log(#tests) 
Fig. 5. The log-log results on HC prob-
lem
As before, we wish to systematically study the performance of our genetic
algorithm on a series of HC problems. Clearly, the complexity in this case is a
function of both the number of nodes and the number of directed edges. For a
given number N of nodes, problems with only a small number of edges N or
nearly fully connected (approximately N 2 edges) are not very interesting. We
feel that problems with approximately N 2
2
edges would, in general, present the
most diﬃcult problems. In addition, we wanted the problems to have exactly
one solution. So, we have deﬁned the following family of HC problems for our
experiments :
Consider a graph of N nodes, which are labeled using consecutive integers. Sup-
pose the ﬁrst node has directed edges to all nodes with larger labels (except for
the last node). The next N −2 nodes have directed edges to all nodes with larger
labels (including the last one). The last node has a directed edge back to the
ﬁrst node. A complete tour consists of following the node labels in increasing
order, until you reach the last node. From the last node you travel back to the
ﬁrst. Because the edges are directed, it is clear that this is also the only legal
tour. Intuitively, such instances of HC problems should be diﬃcult because only
one tour exists in each instance.

A Genetic-Based Approach for Satisﬁability Problems
215
In summary, our experimental framework consists of varying the number
N of nodes in the range 4 ≤N ≤60 and, for each value of N, generating a
directed graph of the form described above containing approximately N 2
2
edges
and exactly one solution.
Each of these HC problems is transformed into its equivalent SAT problem
using the transformation described above. GAs are then used to solve each of the
corresponding SAT problems which, in turn, describes a legal HC tour. Figures
5 presents the results of these experiments. Notice that we have succeeded in
generating signiﬁcantly more diﬃcult SAT problems. However, even with these
diﬃcult problems, the log-log plot is still sub-linear.
One of the theoretical results in Holland [Hol75] analysis of the power of
genetic algorithm is sets a lower bound of an N 3 speedup over systematic search
[Hol75]. It suggests that, in the worst case, genetic algorithm should not have to
search more than
3√
N of the search space in order to ﬁnd a solution. One of the
our results presented here is to improvements of speedups. As noted earlier, the
log-log curves appear to be sub-linear. To get a better idea for the form of these
curves, we have tried to ﬁt a linear and quadratic curves to the data. For each of
the families of SAT problems, a quadratic form produces a better ﬁt. So, we can
calculate the observed speedup (table 2). Clearly, on the easier problems (1S and
2S) we are better than the predicted lower bound, however, for HC problems,
we have the same lower bound as the theoretical one.
Table 2. Improvements on SAT
improve on SAT(1s) N 7
improve on SAT(2S) N 6.5
improve on HC
N 3
4
Conclusions and Future Works
This paper presents a series of initial results regarding a strategy for using genetic
algorithm to solve SAT and NP-complete problems. This strategy avoids many
of the genetic representation diﬃculties associated with various NP-complete
problems by mapping them into SAT problems for which an eﬀective GA repre-
sentation exists. These initial results based on a basic genetic algorithm support
the view that genetic algorithms are an eﬀective, robust search procedure for
NP-complete problems in the sense that, although they may not outperform
highly problem speciﬁc algorithms, genetic algorithm can be easily applied to a
broad range of NP-complete problems with performance characteristics no worse
than the theoretical lower bound of an N 3 speedup. More expreriments on strong
instance of SAT and comparaison with speciﬁc HC algorithms should valid our
results, we feel also that more strong valuation function and very speciﬁc oper-
ators may give a better results.

216
M. Tounsi
References
[ARS93]
Rudolf F. Albrecht, Colin R. Reeves, and Nigel C. Steele, editors. Artiﬁcial
neural nets and genetic algorithms. Springer, April 14-16 1993. ANNGA
93, International Conference on Artiﬁcial Neural Networks & Genetic Al-
gorithms.
[BEV98]
Back, Eiben, and Vink. A superior evolutionary algorithm for 3-SAT. In In-
ternational Conference on Evolutionary Programming, in cooperation with
IEEE Neural Networks Council. LNCS, 1998.
[EvdH97]
Eiben and van der Hauw.
Solving 3-SAT by (gas) adapting constraint
weights. In Proceedings of The IEEE Conference on Evolutionary Compu-
tation, World Congress on Computational Intelligence, 1997.
[Ga84]
J. Grefenstette and al. Genetic algorithms fot the traveling salesman prob-
lem. In Conference on Intelligent Systems and Machines, 1984.
[Gat98]
Chris Gathercole. An investigation of supervised learning in genetic pro-
gramming. In Ph.D. thesis. Department of Electronics and Electrical Engi-
neering. University of Edinburg, 1998, 1998.
[GJ79]
M. Garey and D. Johnsond. Computers and intractability : A guide to the
theory of np-completeness. In W. H. Freeman and Company, CA., 1979.
[GL85]
D. Goldberg and Robert Lingle. Alleles, loci, and the traveling salesman
problem. In Conference on Intelligent Systems and Machines 161-165, 1985.
[Gol89]
D. Goldberg. Genetic algorithms in search, optmization and machine learn-
ing. In Addison Wesley Pubslishing, ISBN :0-201-15767-5, 1989.
[H79]
Gerald Smith H. Adaptive genetic algorithms and the boolean satisﬁability
problem. In Conference on genetic algorithm, 1979.
[Hol75]
J. H. Holland. Adaptation in natural and artiﬁcial systems. In The univer-
sity of Michigan Press, 1975.
[Koz92]
J.R. Koza. Genetic Programming. MIT Press, 1992.
[Lan98]
William B. Langdon. Data structures and genetic programming. In Ph.D.
thesis. University College, London, 1998.
[LSM92]
H. Levesque, B. Selman, and D. Mitchell. A new method for solving hard
satisﬁability problems. In Proceeding of AAAI, pages 440-446, 1992.
[Raw91]
Gregory J. E. Rawlins, editor.
Foundations of Genetic Algorithms, San
Mateo, California, 1991. Morgan Kaufmann.
[Rud94]
G¨unter Rudolph.
Convergence analysis of canonical genetic algorithms.
IEEE Trans. Neural Networks, Special Issue on Evolutionary Computation,
5(1):96–101, 1994.

On Identifying Simple and Quantiﬁed Lattice
Points in the 2SAT Polytope
K. Subramani
LDCSEE,
West Virginia University,
Morgantown, WV
ksmani@csee.wvu.edu
Abstract. This paper is concerned with techniques for identifying sim-
ple and quantiﬁed lattice points in 2SAT polytopes. 2SAT polytopes gen-
eralize the polyhedra corresponding to Boolean 2SAT formulae, Vertex-
Packing (Covering, Partitioning) and Network ﬂow problems; they ﬁnd
wide application in the domains of Program veriﬁcation (Software En-
gineering) and State-Space search (Artiﬁcial Intelligence). Our tech-
niques are based on the symbolic elimination strategy called the Fourier-
Motzkin elimination procedure and thus have the advantages of being
extremely simple (from an implementational perspective) and incremen-
tal. We also provide a characterization of the 2SAT polytope in terms
of its extreme points and derive some interesting hardness results for
associated optimization problems.
1
Introduction
Consider the standard integer feasibility (IP) program ∃⃗x A.⃗x ≤⃗b,⃗x ≥⃗0, xi ∈
{0, 1}; this problem is also referred to as the problem of ﬁnding a simple lattice
point in a polytope and is NP-complete [GJ79,CLR92]. A related problem is the
Quantiﬁed Integer feasibility (QIP) problem, in which one or more of the problem
variables are universally quantiﬁed. It is well known that the quantiﬁed integer
programming problem is PSPACE-complete although there are polynomial time
algorithms for certain special cases [Sub02a]. Both the IP and QIP models have
been used to model problems within a range of domains, ranging from state-
space search in AI applications [Nil98,Gen90] to Program Veriﬁcation in Software
Engineering [AO97,LS85].
In this paper we are concerned with a special structure called the 2SAT poly-
tope; these polytopes are a generalization of the polytopes representing 2SAT
formulae and those representing vertex packing and covering problems in an
undirected graph.
Deﬁnition 1. A polyhedral system A · ⃗x ≤⃗b is said to be a 2SAT polytope sys-
tem if
1. Every entry aij ∈A belongs to the set {−1, 0, 1},
J. Calmet et al. (Eds.): AISC-Calculemus 2002, LNAI 2385, pp. 217–230, 2002.
c
⃝Springer-Verlag Berlin Heidelberg 2002

218
K. Subramani
2. There are at most 2 non-zero entries per row,
3. ⃗b is an arbitrary integral vector.
Our focus is on the development of algorithms for determining the existence
of simple and quantiﬁed lattice points in a given 2SAT polytope. We show that
2SAT polytope problems admit polyhedral elimination techniques; in particular
we show that the Fourier-Motzkin elimination procedure can be applied to these
problems. The advantage of using elimination procedures are twofold: (a) they
are inherently incremental, and (b) a number of symbolic computation programs
have such procedures built-in [CH99]. To the best of our knowledge, our results
are the ﬁrst of their kind.
The rest of this paper is organized as follows: Section §2 provides a formal de-
scription of the problem(s) under study; the motivation for our work is detailed
in Section §3, while Section §4 discusses related work in the literature. In Section
§5, we present our algorithm for the problem of ﬁnding a simple lattice point
within a 2SAT polytope; in Section §6, we extend these ideas to develop an algo-
rithm for the problem of ﬁnding a quantiﬁed lattice point in a 2SAT polytope.
Important properties of 2SAT polytopes are identiﬁed and proved in Section §7;
these properties are important from the perspective of optimization problems.
We conclude in Section §8, by summarizing our contributions and pointing out
directions for future research.
2
Statement of Problem(s)
We consider the following two problems in this paper:
P1
:
Does
an
arbitrary
2SAT
polytope
system
A · ⃗x ≤⃗b,
as
deﬁned
in
Deﬁnition
(1),
have
a
lattice
point
solution,
i.e.
∃⃗x , A · ⃗x ≤⃗b, ⃗x integer?
P1 is referred to as the simple lattice point problem for 2SAT polytopes.
Note that the only restriction on ⃗x is integrality, i.e. the solution points belong
to Zn
+ and not {0, 1}n.
Let Q be an arbitrary quantiﬁer string over the n variables x1, x2, . . . , xn;
i.e. Q = Q1x1Q2x2 . . . Qnxn, where each Qi is either an existential quantiﬁer
(∃) or a discrete-range universal quantiﬁer (∀xi ∈{ai −bi}, ai, bi integer)1.
P2
: Does a given 2SAT polytope system A · ⃗x ≤⃗b, as deﬁned
in
Deﬁnition
(1),
have
a
quantiﬁed
lattice
point
solution,
i.e.
Q1x1Q2x2 . . . Qnxn A · ⃗x ≤⃗b, ⃗x integer, for arbitrary Qi?
1 Note that ∀xi ∈{ai −bi} means that the variable xi can assume any integral value
in the discrete range {ai, ai + 1, . . . , bi}

On Identifying Simple and Quantiﬁed Lattice Points in the 2SAT Polytope
219
P2 is referred to as the quantiﬁed lattice point problem for 2SAT polytopes.
In order to simplify the analysis, we distinguish between the existentially and
universally quantiﬁed variables as follows:
1. The ith existentially quantiﬁed variable is represented by xi,
2. The ith universally quantiﬁed variable is represented by yi
Without loss of generality, we can assume that the variables are strictly alter-
nating, so that problem P2 can be represented as:
∃x1∀y1 ∈{a1 −b1}∃x2∀y2 ∈{a2 −b2} . . . ∃xn∀yn ∈{an −bn}
A · [⃗x ⃗y]T ≤⃗b?
(1)
where A · [⃗x ⃗y]T ≤⃗b is a 2SAT polytope system and ⃗x is integral.
In the rest of this paper, we shall discuss algorithms for deciding problems
P1 and P2.
3
Motivation
The 2SAT polytope generalizes three types of polytopes that are widely studied,
viz.
1. The network polytope - In this case, every row of A has precisely 2 entries,
one of them being 1 and the other being −1. For formulations of network
polytopes, see [NW99];
2. Vertex Packing, Partitioning and Covering Polytopes of an undirected graph
- Consider the vertex covering problem; in this case, every row of A has
precisely 2 entries, with both entries being −1; in case of the vertex packing
problem, both entries are 1, while for the partitioning problem, the entries
are 1 but the polytope system has the form: A · ⃗x = ⃗b, as opposed to the
form A · ⃗x ≤⃗b in Deﬁntion (1). In all these cases, the values assumed by the
variables belong to the set {0, 1}; further ⃗b = [1, 1, . . . , 1]. For formulations
of Vertex Packing, Partitioning and Covering problems, see [Hoc96,Sch87].
3. The clausal 2SAT polytope - In this case, the (at most) 2 entries of each row
may have the same sign or the opposite sign; however the solution vectors
are in {0, 1}n; further each bi ∈{0, 1, −1}. There is an additional restriction,
viz. bi = 0, if and only if the entries in the ith row are of opposite sign,
bi = 1, if and only if both entries in the ith row are 1 and bi = −1, if and
only of both entries in the ith row are −1.
We now show that the Clausal Quantiﬁed 2SAT problem can be expressed as
problem P2. Let
F = Q1x1Q2x2 . . . Qnxn C
(2)
where C is a conjunction of m clauses in which each clause has at most 2 literals.
The quantiﬁed satisﬁability problem is concerned with answering the question:
Is F true ?

220
K. Subramani
We ﬁrst note that F has the following Integer Programming formulation,
F = Q1x1 ∈{0, 1}Q2x2 ∈{0, 1} . . . Qnxn ∈{0, 1} A.⃗x ≤⃗b
(3)
where,
1. A has n columns corresponding to the n variables and m rows corresponding
to the m constraints,
2. A clause (xi, xj) is replaced by the integer constraint xi + xj ≥1; a clause
( ¯xi, xj) is replaced by 1 −xi + xj ≥1 ⇒−xi + xj ≥0; a clause of the form
(xi, ¯xj) is replaced by xi + 1 −xj ≥1 ⇒xi −xj ≥0, and a clause of the
form ( ¯xi, ¯xj) is replaced by 1 −xi + 1 −xj ≥1 ⇒−xi −xj ≥−1.
3. Each Qi is one of ∃or ∀.
The equivalence of of the clausal system and the integer programming for-
mulation is obvious and has been argued in [Pap94].
From the above discussion, it is clear that the study of 2SAT polytopes
uniﬁes the study of problems in a wide variety of domains including Network
Optimization, Operations Research and Logic. In this paper, we show that a very
generic symbolic computation technique called the Fourier-Motzkin elimination
procedure can be used for deciding 2SAT polytope problems.
4
Related Work
In this section, we brieﬂy review the work on ﬁnding feasible linear and integer
solutions over polyhedral systems composed of 2-support constraints. A con-
straint is said to be 2-support, if at most 2 entries are non-zero. Note that a
2-support constraint generalizes a 2SAT polytope constraint since the non-zero
entries are not restricted to {1, −1}.
LP(2) i.e. the linear programming feasibility problem when each constraint
has at most 2 non-zero variables has been studied extensively in [Sho81,AS79]
and [HN94]. [HN94] provides the fastest algorithm to date, for this problem
(O(mn2 log m), assuming m constraints over n variables). [HN94] also studied
the IP(2) problem, i.e the problem of checking whether a 2−support polyhedron
contains a lattice point. This problem is NP-complete and they provide a pseudo-
polynomial time algorithm for the same.
Packing and covering problems for graphs as well as for set systems have been
studied extensively in the literature; [NT74] showed that packing and covering
polytopes were half-integral, while [NT75] discussed algorithms for optimization
problems over these polytopes.
[Sch78] argued that the clausal Q2SAT problem could be solved in polynomial
time, but provided no algorithm for the same; [APT79] gave the ﬁrst algorithm
(linear time) for the clausal SAT and QSAT problems. The parallel complexity
of this problem has been explored in [Che92], [CM88] and [Gav93] and it has
been demonstrated that Q2SAT is in the parallel complexity class NC2. Although
our algorithms take O(n3) time, it must be noted that we are solving a far more

On Identifying Simple and Quantiﬁed Lattice Points in the 2SAT Polytope
221
general class of problems than those studied in [APT79] and [CM88]; it is not
clear how their techniques (verifying reachability conditions in the constraint
graph) extend to ﬁnding arbitrary integral solutions over 2SAT polytopes.
Fourier-Motzkin elimination as a technique for resolving feasibility in linear
systems was proposed in [Fou24] and elaborated in [DE73]. Extending the tech-
nique to resolving integer programs was the thrust of [Wil76] and [Wil83]. A
direct application of Fourier’s theorem to integer programs results in congru-
ences and modulo arithmetic. We show that for 2SAT polytopes, we can avoid
modulo arithmetic altogether.
5
The Simple Lattice Point Problem
Algorithm (1) outlines our strategy for problem P1; details of the Fourier-
Motzkin elimination procedure are available in Section §A.
Algorithm 1 An elimination strategy for checking whether a 2SAT polytope
has a simple lattice point
Function Simple-Lattice-Point (A, ⃗b)
1: for ( i = n down to 2 ) do
2:
Eliminate xi using Fourier-Motzkin
3:
Prune-Constraints()
4:
if (Check-Inconsistency()) then
5:
return (false)
6:
end if
7: end for
8: if (a ≤x1 ≤b, a ≤b) then
9:
return (true)
10: else
11:
return (false)
12: end if
When a variable xi is eliminated from 2 constraints containing the same
variable xj it is possible to derive a constraint of the form xj ≤1
2c1,
c1 odd;
since xj must be integral, this constraint is replaced by the constraint xj ≤c1−1
2
.
(Note that c1−1
2
is always integral, when c1 is odd.) This is carried out in Prune-
Constraints(). Note that there can be at most 4 non-redundant constraints
between any 2 variables. When a variable is eliminated, it gives rise to new
constraints between other variables. These constraints could be the redundant, in
which case they are eliminated (through Prune-Constraints()) or they could
create an inconsistency, in which case the 2SAT polytope is declared infeasible.
Identiﬁcation of inconsistencies is carried out in Check-Inconsistency().
During the elimination of variable xn, each constraint involving xn is put
into the set Lxn = {xn ≤()} or the set Uxn = {xn ≥()}. Thus, we have

222
K. Subramani
max Uxn ≤xn ≤Lxn. The sets Lxi, Uxi, i = 1, 2, . . . , n represent a model for
the 2SAT polytope; in that the value of xi can be computed from x1, x2, . . . , xi−1
and the sets Lxj, Uxj, j = 1, 2, . . . , (i −1).
5.1
Correctness
The correctness of the Fourier-Motzkin procedure for linear programs has been
argued in [DE73] and [Sch87]; we need to argue that it works over 2SAT poly-
topes as well. Assume that we are eliminating variable xn of an n-dimensional
2SAT polytope P, by pairing oﬀconstraints which appear as xn ≤() and
−xn ≤() as described in Section §A. Let P′ be the (n−1)-dimensional polytope
that results after the elimination. Clearly, if P′ is infeasible, i.e. it does not have
a lattice point, then P cannot have a lattice point solution. Consider the case
when P′ has a lattice point solution ⃗x′ = [x′
1, x′
2, . . . , x′
n−1]T . We show that this
lattice point can be complented to obtain a lattice point in P. Substitute the
components of ⃗x′ in the linear system deﬁning P; we get a system of inequalities
of the form xn ≤ci, ci integer. This is because the co-eﬃcient of xn is either 1
or −1 in all the constraints and ⃗b is integral. This system deﬁnes a single integer
point or an interval with integral end-points. We cannot get an infeasible inter-
val, since that would imply that the point ⃗x′ does not belong to the polyhedron
P′! To see this, note that max Uxn ≤xn ≤min Lxn. Further both max Uxn and
min Lxn are integers. Thus, in either case, we can pick an integral value of xn
and obtain a lattice point solution for the 2SAT polytope system.
We must point out that the technique breaks down, even in 2 dimensions, if
we allow arbitrary constraints between 2 variables [Wil76].
5.2
Complexity
Let us store the 2SAT polytope as a graph structure; the variables xi represent
the vertices of the graph, while a constraint between xi and xj is represented as
an edge of the graph. This graph structure can have at most 4 edges between
2 vertices. Every edge has 2 labels describing its direction with respect to its
end-points. The edge xi + xj ≤7 is labeled (+, +) to indicate that it is positive
for both xi and xj; likewise xi −xj ≤3 is labeled (+, −) and so on. We use
the special variable x0 to represent constraints involving only one variable; for
instance the constraint xi ≤7 will be represented by the edge xi + x0 ≤7
between xi and x0. When variable xi is to be eliminated, all the edges that are
positive for xi are combined with all the edges that are negative for xi to derive
new edges in the graph structure. This step takes time at most O(n2), since the
number of positive and negative edges could each be at most O(n) in number.
It follows that Algorithm (1) takes time at most O(n3).
6
The Quantiﬁed Lattice Point Problem
In this section, we discuss an elimination procedure to decide problem P2; Al-
gorithm (2) represents our strategy.

On Identifying Simple and Quantiﬁed Lattice Points in the 2SAT Polytope
223
Algorithm 2 A Quantiﬁer Elimination Algorithm for deciding whether a 2SAT
polytope has a quantiﬁed lattice point
Function Quantified-Lattice-Point (A, ⃗b)
1: for ( i = n down to 1 ) do
2:
if (Qi = ∃) then
3:
Eliminate xi using Fourier-Motzkin
4:
Prune-Constraints()
5:
if (Check-Inconsistency()) then
6:
return ( false )
7:
end if
8:
end if
9:
if (Qi = ∀) then
10:
Elim-Univ-Variable(yi)
11:
Prune-Constraints()
12:
if (Check-Inconsistency()) then
13:
return ( false )
14:
end if
15:
end if
16: end for
17: return ( true )
Algorithm 3 Eliminating Universally Quantiﬁed variable yi ∈{ai −bi}
Function Elim-Univ-Variable (A, ⃗b, yi)
1: Substitute yi = ai in each constraint that can be written in the form yi ≥()
2: Substitute yi = bi in each constraint that can be written in the form yi ≤()
The elimination of a variable (existential or universal) results in one or more
of the following consequences:
1. Some redundant constraints result, which can be pruned out. This is the
function of the subroutine Prune-Constraints().
2. An inconsistency results and we return false through the function Check-
Inconsistency().
3. We get a smaller subset of variables to work with. Observe that the total
number of constraints is always bounded by 4 times the square of the number
of variables.
6.1
Correctness
We need to argue the correctness of the procedure for eliminating Universally
quantiﬁed variables. We have already established that the procedure for elimi-
nating existentially quantiﬁed variables is solution-preserving (Section §5.1).
Lemma (1) establishes that if the last quantiﬁer is universal, the interval of
the corresponding interval can be relaxed to a continuous interval. This permits
the use of polyhedral techniques, in particular Algorithm (3).

224
K. Subramani
Lemma 1. Let
L : ∃x1 ∈{a1 −b1} ∀y1 ∈{ci −di} ∃x2 ∈{a2 −b2} ∀y2 ∈{c2 −d2}
. . . ∃xn ∈{an −bn} ∀yn ∈{cn −dn} A · [⃗x ⃗y]T ≤⃗b
and
R :; ∃x1 ∈{a1 −b1} ∀y1 ∈{ci −di} ∃x2 ∈{a2 −b2} ∀y2 ∈{c2 −d2}
. . . ∃xn ∈{an −bn} ∀yn ∈[cn, dn]
A · [⃗x ⃗y]T ≤⃗b?
Then L ⇔R. i.e. if the last quantiﬁer of a Quantiﬁed Integer Program (QIP)
is universal, then the discrete range can be relaxed into a continuous range, while
preserving the solution space.
Proof: The detailed proof is available in [Sub02a]. ✷
Since the interval of the outermost universally quantiﬁed variable is con-
tinuous, we can use the strategy outlined in [Sub02b] to eliminate it, which is
precisely Algorithm (3).
6.2
Complexity
Once again, we assume that the 2SAT polytope is stored as a graph structure, as
described in Section §5.2. Note that the elimination of a universally quantiﬁed
variable through substitution, could result in constraints between a program
variable and the special variable x0. In O(1) time, each such constraint can be
identiﬁed as required, redundant or inconsistency-creating. Thus the total time
taken for eliminating a universally quantiﬁed variable is at most O(n) and hence
the total time taken to eliminate all the universally quantiﬁed variables is at
most O(n2).
The total time taken for the elimination of all the existentially quantiﬁed
variables is at most O(n3) as argued in Section §5.2. It follows that the total
time taken by Algorithm (2) is at most O(n3).
7
Properties of the 2SAT Polytope
In this section, we identify and prove some properties of 2SAT polytopes, that
are useful from the perspective of optimization.
Theorem 1. The 2SAT polytope is half-integral, i.e. every component of an
extreme point of the 2SAT polyhedron is either an integer or an integral multiple
of 1
2.

On Identifying Simple and Quantiﬁed Lattice Points in the 2SAT Polytope
225
Proof: Our proof is based on the correctness of the Fourier-Motzkin elimi-
nation procedure and is much simpler than the proof in [NT74] (which analyzed
covering and packing polytopes only). We use mathematical induction on the
number of variables, i.e. the dimension of the 2SAT polytope P = A · ⃗x ≤⃗b.
We assume without loss of generality that P is non-empty. Clearly, the theorem
is true for n = 1; in this case, every constraint is of the form x1 ≤±ci, where
the ci are integral. Hence the end-points of the interval describing x1 are inte-
gral and Theorem (1) holds. Let us assume that the theorem holds for all 2SAT
polytopes having dimension at most n−1. Now consider a 2SAT polytope having
dimension n. When we eliminate the variable xn we are in fact projecting the
2SAT polytope onto n−1 dimensions to get a 2SAT polytope P′ = A′ · ⃗x′ ≤⃗b′2 ,
where ⃗x′ = [x1 x2 . . . xn−1]. From the induction hypothesis, we know that all the
extreme points of P′ are half-integral. Each extreme point of P can be generated
as follows:
1. Let ⃗x′ be an extreme point of P′; substitute the components of ⃗x′ in the
polyhedral system P;
2. The resultant system of linear inequalities in one variable results in either
a single half-integral point or an interval with half-integral end-points. This
is because, every constraint involving xn is of the form bi −x′
j, for some bi
and x′
j representing the jth component of ⃗x′. Since bi is integral and x′
j is
half-integral (by the inductive hypothesis), the claim follows.
✷
Theorem 2. Every square submatrix of a 2SAT polytope has determinant
{0, ±1, ±2}
Proof: Consider a 2SAT polytope A · ⃗x ≤⃗b (A is an m×n matrix); by The-
orem (1) every basic solution to the system [A, I] · [⃗x ⃗xI]T = ⃗b is half-integral
(Not all basic solutions are feasible). Pick some arbitrary k ×k square submatrix
in A (say A′). Without loss of generality, we can assume that A′ is formed us-
ing the ﬁrst k rows and ﬁrst k columns of A (otherwise perform the appropriate
permutations!). Consider the m × m square matrix C formed by combining the
ﬁrst k columns of A with the last m −k columns of I. Figure (1) describes the
composition.
We thus have
C =

A′ 0
B I

(4)
It is not hard to see that |det(C)| = |det(A′)|; we now show that det(C) ∈
{0, ±1, ±2}. If det(C) = 0, we are done; let us consider the case, where det(C) ̸=
0. Consider the sequence of linear equality systems C · ⃗xi = ⃗ei, i = 1, 2, . . . , m,
where ⃗ei is the unit-vector in the ith dimension. Since ⃗xi is half-integral, by
Theorem (1) (⃗xi is a basic solution), it follows that C−1 · ⃗ei is half-integral.
2 We argued in Section §5 that the elimination procedure preserves the 2SAT structure

226
K. Subramani
k
k
n-k
k
m-k
m-k
I
A’
B
0
I
0
Fig. 1. Creating a basis
This is possible, only if all the entries of the ith column of C−1 are half-
integral. We can thus conclude that all the entries of C−1 must be half-integral.
We write C−1 =
1
2C′−1, i.e. the factor
1
2 can be taken out from every el-
ement in C−1 to give an integral matrix C′−1. Thus, det(C′−1) is integral
and hence det(C−1) must be half-integral. Observe that det(C) is integral and
det(C).det(C−1) = 1. Thus if, det(C−1) is integral, then |det(C)| = 1; likewise
if det(C−1) is an odd multiple of 1
2, then |det(C)| = 2, since that is the only
way for det(C).det(C−1) = 1 to hold. We have thus shown that for any square
sub-matrix A′ of a 2SAT polytope det(A′) = ±1 or ±2.
Our proof follows the lines of [VD68] in [KV00] for totally unimodular ma-
trices. ✷
Theorem 3. If ⃗c is an integral vector, max⃗c.⃗x is over a 2SAT polytope is
reached at a half-integral point.
Proof: Follows immediately from Theorem (1), since the maximum of a linear
function is reached at an extreme point of the polyhedron. ✷
We say that a cost vector ⃗c is positive, if all its components are positive.
Observe that the problems of ﬁnding an integer minimum or the integer max-
imum of a positive cost vector over a network polyhedron can be carried out
in polynomial time, since network polyhedra are totally unimodular. Likewise,
maximizing (integer maximum) a positive cost vector over a covering polytope
is trivial, whereas minimizing (integer minimum) a positive cost vector over the
same is NP-complete. In case of packing polytopes, ﬁnding the integral minimum
of a positive cost vector is trivial, whereas the integral maximization problem is
NP-complete.

On Identifying Simple and Quantiﬁed Lattice Points in the 2SAT Polytope
227
Theorem 4. Finding the integral maximum or integral minimum of a positive
cost vector over a 2SAT polytope is NP-complete.
Proof: We will argue that the problems of maximizing and minimizing the
number of true variables in a clausal 2SAT system are NP-complete; the theo-
rem follows. Clearly the problem of minimizing the number of true variables in
a clausal 2SAT system (called Pmin) is NP-complete, since the standard vertex
cover problem is a special case of this problem.
Now consider the problem of maximizing the number of true variables
in a clausal 2SAT system (called Pmax). We show that this problem is also
NP-complete by reducing Pmin to it. Given an instance of Pmin we construct
an instance of Pmax as follows:
1. Replace each positive literal xi with a negative literal ¯yi and each negative
literal ¯xi with a positive literal yi.
2. Thus minimizing the number of true variables in the original system corre-
sponds to minimizing the number of false variables in the new system, which
is equivalent to the problem of maximizing the number of true variables in
the new system.
✷
Theorem 5. Finding the integer optimum of any linear function over an arbi-
trary 2SAT polytope is NP-complete.
Proof: We can use the substitution technique of Theorem (4) to reduce either
Pmin or Pmax to this problem. ✷
8
Conclusions
In this paper, we demonstrated the existence of polynomial time algorithms for
the problems of ﬁnding simple and quantiﬁed lattice points in a 2SAT polytope.
To the best of our knowledge, polynomial time algorithms for these problems
do not exist in the literature, although various special cases have been well
studied. Our techniques are useful because of their simplicity, generality and
incrementality.
An important property of polytopes from the property of Operations Re-
search, is the ﬁxing variables property. Let ⃗x1 be the (unique) solution to the
polyhedral system: max⃗c.⃗x A · ⃗x ≤⃗b. The polyhedral system is said to have the
ﬁxing variables property, if there exists an integer optimum of a linear function
over that system which is equal to the linear optimum ( ⃗x1) in all its integer com-
ponents. While it is known that the vertex covering and packing polytopes have
the ﬁxing variables property, the question of whether 2SAT polytopes have the
same property is open. This property is useful from the perspective of deriving
approximation algorithms for integer optimization problems over the polytope
[Hoc96].

228
K. Subramani
We can deﬁne Horn-SAT polytopes in a fashion, similar to the deﬁnition of
2SAT polytopes; however, the techniques discussed in this paper do not yield
polynomial time strategies. The interesting question then is whether there are
larger classes of polytopes for which our techniques do provide polynomial time
strategies.
Finally, this paper focussed on deterministic approaches only, which we be-
lieve was the reason for the rather pessimistic bound of O(n3); we are currently
exploring the existence of randomized approaches with a view to improving the
running time of our algorithms.
Algorithm 4 The Fourier-Motzkin Elimination Procedure
Function Fourier-Motzkin elimination (A, ⃗b)
1: for ( i = n down to 2 ) do
2:
Let I+ = { set of constraints that can be written in the form xi ≥()}
3:
Let I−= { set of constraints that can be written in the form xi ≤()}
4:
for ( each constraint k ∈I+ ) do
5:
for ( each constraint l ∈I−) do
6:
Add k ≤l to the original constraints
7:
end for
8:
end for
9:
Delete all constraints containing xi
10: end for
11: if ( a ≤x1 ≤b,
a, b ≥0 ) then
12:
Linear program is consistent
13:
return
14: else
15:
Linear program is inconsistent
16:
return
17: end if
A
Fourier-Motzkin Elimination
The Fourier-Motzkin elimination procedure is an elegant, syntactic, variable
elimination scheme to solve constraint systems that are comprised of linear in-
equalities. It was discovered initially by Fourier [Fou24] and later by Motzkin
[DE73], who used it to solve general purpose Linear programs.
The key idea in the elimination procedure is that a constraint system in n
variables ( i.e. ℜn ), can be projected onto a space of n−1 variables ( i.e. ℜn−1 ),
without altering the solution space. In other words, polyhedral projection of a
constraint set is solution preserving. This idea is applied recursively, till we are
left with a single variable ( say x1 ). If we have a ≤x1 ≤b, a ≤b, then the system
is consistent, for any value of x1 in the interval [a, b]. Working backwards, we
can deduce the values of all the variables x2, . . . , xn. If a > b, we conclude that
the system is infeasible.

On Identifying Simple and Quantiﬁed Lattice Points in the 2SAT Polytope
229
Algorithm (4) is a formal description of the above procedure.
Though elegant, this syntactic procedure suﬀers from an exponential growth
in the constraint set, as it progresses. This growth has been observed both in
theory [Sch87] and in practice [HLL90,LM91]. By appropriately choosing the
constraint matrix A, it can be shown that eliminating k variables causes the size
of the constraint set to increase from m to O(m2k) [Sch87]. Algorithm (4) remains
useful though as a tool for proving theorems on polyhedral spaces [VR99]. [Sch87]
gives a detailed exposition of this procedure.
References
[AO97]
Krzystof R. Apt and Ernst R. Olderog. Veriﬁcation of Sequential and Con-
current Programs. Springer-Verlag, 1997.
[APT79]
Bengt Aspvall, Michael F. Plass, and Robert Tarjan. A linear-time algorithm
for testing the truth of certain quantiﬁed boolean formulas. Information
Processing Letters, (3), 1979.
[AS79]
Bengt Aspvall and Yossi Shiloach. A polynomial time algorithm for solving
systems of linear inequalities with two variables per inequality.
In 20th
Annual Symposium on Foundations of Computer Science, pages 205–217,
San Juan, Puerto Rico, 29–31 October 1979. IEEE.
[CH99]
V. Chandru and J. N. Hooker. Optimization Methods for Logical Inference.
Series in Discrete Mathematics and Optimization. John Wiley & Sons Inc.,
1999.
[Che92]
Z. Chen. A fast and eﬃcient parallel algorithm for ﬁnding a satisfying truth
assignment to a 2-cnf formula. Information Processing Letters, pages 191–
193, 1992.
[CLR92]
T. H. Cormen, C. E. Leiserson, and R. L. Rivest. Introduction to Algorithms.
MIT Press and McGraw-Hill Book Company, 6th edition, 1992.
[CM88]
S.A. Cook and M.Luby. A simple parallel algorithm for ﬁnding a satisfying
truth assignment to a 2-cnf formula. Information Processing Letters, pages
141–145, 1988.
[DE73]
G. B. Dantzig and B. C. Eaves. Fourier-Motzkin Elimination and its Dual.
Journal of Combinatorial Theory (A), 14:288–297, 1973.
[Fou24]
J. B. J. Fourier. Reported in: Analyse de travaux de l’Academie Royale des
Sciences, pendant l’annee 1824, Partie Mathematique, Historyde l’Academie
Royale de Sciences de l’Institue de France 7 (1827) xlvii-lv. (Partial English
translation in: D.A. Kohler, Translation of a Report by Fourier on his work
on Linear Inequalities. Opsearch 10 (1973) 38-42.). Academic Press, 1824.
[Gav93]
F. Gavril. An eﬃciently solvable graph partition, problem to which many
problems are reducible. Information Processing Letters, pages 285–290, 1993.
[Gen90]
Michael Genesereth. Logical Foundations of Artiﬁcial Intelligence. Morgan
Kaufmann, 1990.
[GJ79]
M. R. Garey and D. S. Johnson. Computers and Intractability: A Guide to
the Theory of NP-Completeness. W. H. Freeman Company, San Francisco,
1979.

230
K. Subramani
[HLL90]
Tien Huynh, Catherine Lassez, and Jean-Louis Lassez. Fourier Algorithm
Revisited. In H´el`ene Kirchner and W. Wechler, editors, Proceedings Sec-
ond International Conference on Algebraic and Logic Programming, volume
463 of Lecture Notes in Computer Science, pages 117–131, Nancy, France,
October 1990. Springer-Verlag.
[HN94]
Dorit S. Hochbaum and Joseph (Seﬃ) Naor. Simple and fast algorithms for
linear and integer programs with two variables per inequality. SIAM Journal
on Computing, 23(6):1179–1192, December 1994.
[Hoc96]
Hochbaum, editor. Approximation Algorithms for NP-Hard Problems. PWS
Publishing Company, 1996.
[KV00]
B. Korte and J. Vygen. Combinatorial Optimization. Number 21. Springer-
Verlag, New York, 2000.
[LM91]
Jean-Louis Lassez and Michael Maher.
On fourier’s algorithm for linear
constraints. Journal of Automated Reasoning, to appear, 1991.
[LS85]
Jacques Loeckx and Kurt Sieber. The Foundations of Program Veriﬁcation.
John Wiley and Sons, 1985.
[Nil98]
Nils J. Nilsson. Artiﬁcial Intelligence: A New Synthesis. Morgan Kaufmann,
1998.
[NT74]
G. L. Nemhauser and L. E. Trotter Jr. Properties of vertex packing and
independence system polyhedra. mathprog, 6:48–61, 1974.
[NT75]
G. L. Nemhauser and J. L. E. Trotter. Vertex packing: structural properties
and algorithms. Mathematical Programming, 8:232–248, 1975.
[NW99]
G. L. Nemhauser and L. A. Wolsey. Integer and Combinatorial Optimization.
John Wiley & Sons, New York, 1999.
[Pap94]
Christos H. Papadimitriou.
Computational Complexity.
Addison-Wesley,
New York, 1994.
[Sch78]
T.J. Schaefer.
The complexity of satisﬁability problems.
In Alfred Aho,
editor, Proceedings of the 10th Annual ACM Symposium on Theory of Com-
puting, pages 216–226, New York City, NY, 1978. ACM Press.
[Sch87]
Alexander Schrijver.
Theory of Linear and Integer Programming.
John
Wiley and Sons, New York, 1987.
[Sho81]
Robert Shostak. Deciding linear inequalities by computing loop residues.
Journal of the ACM, 28(4):769–779, October 1981.
[Sub02a]
K. Subramani. An analysis os selected qips, 2002. Submitted to Journal of
Logic and Computation.
[Sub02b]
K. Subramani. A polynomial time algorithm for a class of quantiﬁed linear
programs, 2002. Submitted to Mathematical Programming.
[VD68]
A.F. Veinott and G.B. Dantzig. Integral extreme points.
SIAM Review,
10:371–372, 1968.
[VR99]
V.Chandru and M.R. Rao. Linear programming. In Algorithms and Theory
of Computation Handbook, CRC Press, 1999. CRC Press, 1999.
[Wil76]
H.P. Williams. Fourier-motzkin elimination extension to integer program-
ming. J. Combinatorial Theory, (21):118–123, 1976.
[Wil83]
H.P. Williams.
A characterisation of all feasible solutions to an integer
program. Discrete Appl. Math., (5):147–155, 1983.

Integrating Boolean and Mathematical Solving:
Foundations, Basic Algorithms, and
Requirements⋆
Gilles Audemard1,2, Piergiorgio Bertoli1, Alessandro Cimatti1,
Artur Kornilowicz1,3, and Roberto Sebastiani1,4
1 ITC-IRST, Povo, Trento, Italy
{audemard,bertoli,cimatti,kornilow}@itc.it
2 LSIS, University of Provence, Marseille, France
3 Institute of Computer Science, University of Bia!lystok, Poland
4 DIT, Universit`a di Trento, Povo, Trento, Italy
roberto.sebastiani@dit.unitn.it
Abstract. In the last years we have witnessed an impressive advance
in the eﬃciency of boolean solving techniques, which has brought large
previously intractable problems at the reach of state-of-the-art solvers.
Unfortunately, simple boolean expressions are not expressive enough for
representing many real-world problems, which require handling also in-
teger or real values and operators. On the other hand, mathematical
solvers, like computer-algebra systems or constraint solvers, cannot han-
dle eﬃciently problems involving heavy boolean search, or do not handle
them at all. In this paper we present the foundations and the basic al-
gorithms for a new class of procedures for solving boolean combinations
of mathematical propositions, which combine boolean and mathemati-
cal solvers, and we highlight the main requirements that boolean and
mathematical solvers must fulﬁll in order to achieve the maximum ben-
eﬁts from their integration. Finally we show how existing systems are
captured by our framework.
1
Motivation and Goals
In the last years we have witnessed an impressive advance in the eﬃciency of
boolean solving techniques (SAT), which has brought large previously intractable
problems at the reach of state-of-the-art solvers.1 As a consequence, some hard
real-world problems have been successfully solved by encoding them into SAT.
Propositional planning [KMS96] and boolean model-checking [BCCZ99] are
among the best achievements.
⋆This work is sponsored by the CALCULEMUS! IHP-RTN EC project, contract
code HPRN-CT-2000-00102, and has thus beneﬁted of the ﬁnancial contribution of
the Commission through the IHP programme.
1 SAT procedures are commonly called solvers in the SAT community, although the
distinction between solving, proving and computing services may suggest to call them
provers.
J. Calmet et al. (Eds.): AISC-Calculemus 2002, LNAI 2385, pp. 231–245, 2002.
c
⃝Springer-Verlag Berlin Heidelberg 2002

232
G. Audemard et al.
Unfortunately, simple boolean expressions are not expressive enough for rep-
resenting many real-world problems. For example, problem domains like tem-
poral reasoning, resource planning, veriﬁcation of systems with numerical data
or of timed systems, require handling also constraints on integer or real quanti-
ties (see, e.g., [ACG99,WW99,CABN97,MLAH01]). Moreover, some problem do-
mains like model checking often require an explicit representation of integers and
arithmetic operators, which cannot be represented eﬃciently by simple boolean
expressions (see, e.g., [CABN97,MLAH01]). On the other hand, mathematical
solvers, like computer-algebra systems or constraint solvers, cannot handle ef-
ﬁciently problems involving heavy boolean search, or do not handle them at
all.
In 1996 we have proposed a new general approach to build domain-speciﬁc
decision procedures on top of SAT solvers [GS96,GS00]. The basic idea was
to decompose the search into two orthogonal components, one purely proposi-
tional component and one “boolean-free” domain-speciﬁc component and to use
a (modiﬁed) Davis Putnam Longemann Loveland (DPLL) SAT solver [DLL62]
for the former and a pure domain-speciﬁc procedure for the latter. So far the
SAT based approach proved very eﬀective in various problem domains like, e.g.,
modal and description logics [GS00], temporal reasoning [ACG99], resource plan-
ning [WW99].
In this paper we present the foundations and the basic algorithms for a new
class of procedures for solving boolean combinations of mathematical proposi-
tions, which integrate SAT and mathematical solvers, and we highlight the main
requirement SAT and mathematical solvers must fulﬁll in order to achieve the
maximum beneﬁts from their integration. The ultimate goal is to develop solvers
able to handle complex problems like those hinted above.
The paper is structured as follows. In Section 2 we describe formally the
problem we are addressing. In Section 3 we present the logic framework on
which the procedures are based. In Section 4 we present a generalized search
procedure which combine boolean and mathematical solvers and introduce some
eﬃciency issues. In Section 5 we highlight the main requirements that boolean
and mathematical solvers must fulﬁll in order to achieve the maximum beneﬁts
from their integration. In Section 6 we brieﬂy describe some existing systems
which are captured by our framework,and our own implemented procedure.
For lack of space, in this paper we omit the proofs of all the theoretical results
presented, which can be found in [Seb01].
2
The Problem
We address the problem of checking the satisﬁability of boolean combinations of
primitive and mathematical propositions. Let D be the domain of either integer
numbers Z or real numbers R, with the respective set OPD of arithmetical op-
erators {+, −, ·, /, mod} or {+, −, ·, /} respectively. Let {⊥, ⊤} denote the false
and true boolean values. Given the standard boolean connectives {¬, ∧} and
math operators {=, ̸=, >, <, ≥, ≤}, let A = {A1, A2, . . .} be a set of primitive

Integrating Boolean and Mathematical Solving
233
propositions, let C = {c1, c2, . . .} and V = {v1, v2, . . .} respectively be a set of
numerical constants in D and variables over the D.
We call Math-terms the mathematical expressions built up from constants,
variables and arithmetical operators over D:
– a constant ci ∈C is a Math-term;
– a variable vi ∈V is a Math-term;
– if t1 is a Math-term, then −t1 is a Math-term;
– if t1, t2 are Math-terms, then (t1 ⊗t2) is a Math-term, ⊗∈OPD.
We call Math-formulas the mathematical formulas built on primitive propo-
sitions, Math-terms, operators and boolean connectives:
– a primitive proposition Ai ∈A is a Math-formula;
– if t1, t2 are Math-terms, then (t1 ▷◁t2) is a Math-formula, ▷◁∈{=, ̸=, >, <
, ≥, ≤};
– if ϕ1 is a Math-formula, then ¬ϕ1 is a Math-formula;
– if ϕ1, ϕ2 are Math-formulas, then (ϕ1 ∧ϕ2) is a Math-formula.
For instance, A1 ∧((v1 + 5.0) ≤(2.0 · v3)) and A2 ∧¬(((2 · v1) mod v2) > 5) are
Math-formulas.2
Notationally, we use the lower case letters t, t1, ... to denote Math-terms,
and the Greek letters α, β, ϕ, ψ to denote Math-formulas. We use the standard
abbreviations, that is: “ϕ1 ∨ϕ2” for “¬(¬ϕ1 ∧¬ϕ2)”, “ϕ1 →ϕ2” for “¬(ϕ1 ∧
¬ϕ2)”, “ϕ1 ↔ϕ2” for “¬(ϕ1∧¬ϕ2)∧¬(ϕ2∧¬ϕ1)”, “⊤” for any valid formula, and
“⊥” for “¬⊤”. When this does not cause ambiguities, we use the associativity
and precedence rules of arithmetical operators to simplify the appearance of
Math-terms; e.g, we write “(c1(v2 −v1) −c1v3 + c3v4)” instead of “(((c1 · (v2 −
v1)) −(c1 · v3)) + (c3 · v4))”.
We call interpretation a map I which assigns D values and boolean values to
Math-terms and Math-formulas respectively and preserves constants and arith-
metical operators:3
– I(Ai) ∈{⊤, ⊥}, for every Ai ∈A;
– I(ci) = ci, for every ci ∈C;
– I(vi) ∈D, for every vi ∈V;
– I(t1 ⊗t2) = (I(t1) ⊗ID(t2)), for all Math-terms t1, t2 and ⊗∈OPD.
2 The assumption that the domain is the whole Z or R is not restrictive, as we can re-
strict the domain of any variable vi at will by adding to the formula some constraints
like, e.g., (v1 ̸= 0.0), (v1 ≤5.0), etc.
3 Here we make a little abuse of notation with the constants and the operators in
OPD. In fact, e.g., we denote by the same symbol “+” both the language symbol in
ID(t1 + t2) and the arithmetic operator in (ID(t1) + ID(t2)). The same discourse
holds for the constants ci ∈C and also for the operators {=, ̸=, >, <, ≥, ≤}.

234
G. Audemard et al.
The binary relation |= between a interpretation I and a Math-formula ϕ, written
“I |= ϕ” (“I satisﬁes ϕ” or “I satisﬁes ϕ”) is deﬁned as follows:
I |= Ai, Ai ∈A
⇐⇒I(Ai) = ⊤;
I |= (t1 ▷◁t2), ▷◁∈{=, ̸=, >, <, ≥, ≤} ⇐⇒I(t1) ▷◁I(t2);
I |= ¬ϕ1
⇐⇒I ̸|= ϕ1;
I |= (ϕ1 ∧ϕ2)
⇐⇒I |= ϕ1 and I |= ϕ2.
We say that a Math-formula ϕ is satisﬁable if and only if there exists an interpre-
tation I such that I |= ϕ. E.g., if D = R, then A1 →((v1+2v2) ≤4.5) is satisﬁed
by an interpretation I such that I(A1) = ⊤, I(v1) = 1.1, and I(v2) = 0.6. For
every ϕ1 and ϕ2, we say that ϕ1 |= ϕ2 if and only if I |= ϕ2 for every I such
that I |= ϕ1. We also say that |= ϕ (ϕ is valid) if and only if I |= ϕ for every I.
It is easy to verify that ϕ1 |= ϕ2 if and only if |= ϕ1 →ϕ2, and that |= ϕ if and
only if ¬ϕ is unsatisﬁable.
3
The Formal Framework
3.1
Basic Deﬁnitions and Results
Deﬁnition 1. We call atom any Math-formula that cannot be decomposed
propositionally, that is, any Math-formula whose main connective is not a boolean
operator. A literal is either an atom (a positive literal) or its negation (a neg-
ative literal).
Examples of literals are, A1, ¬A2, (v1 + 5.0 ≤2.0v3), ¬((2v1 mod v2) > 5). If
l is a negative literal ¬ψ, then by “¬l” we conventionally mean ψ rather than
¬¬ψ. We denote by Atoms(ϕ) the set of atoms in ϕ.
Deﬁnition 2. We call a total truth assignment µ for a Math-formula ϕ a
set
µ = {α1, . . . , αN, ¬β1, . . . , ¬βM, A1, . . . , AR, ¬AR+1, . . . , ¬AS},
(1)
such that every atom in Atoms(ϕ) occurs as either a positive or a negative literal
in µ. A partial truth assignment µ for ϕ is a subset of a total truth assignment
for ϕ. If µ2 ⊆µ1, then we say that µ1 extends µ2 and that µ2 subsumes µ1.
A total truth assignment µ like (1) is interpreted as a truth value assignment to
all the atoms of ϕ: αi ∈µ means that αi is assigned to ⊤, ¬βi ∈µ means that βi
is assigned to ⊥. Syntactically identical instances of the same atom are always
assigned identical truth values; syntactically diﬀerent atoms, e.g., (t1 ≥t2) and
(t2 ≤t1), are treated diﬀerently and may thus be assigned diﬀerent truth values.
Notationally, we use the Greek letters µ, η to represent truth assignments.
We often write a truth assignment µ as the conjunction of its elements. To this
extent, we say that µ is satisﬁable if the conjunction of its elements is satisﬁable.

Integrating Boolean and Mathematical Solving
235
Deﬁnition 3. We say that a total truth assignment µ for ϕ propositionally
satisﬁes ϕ, written µ |=p ϕ, if and only if it makes ϕ evaluate to ⊤, that is, for
all sub-formulas ϕ1, ϕ2 of ϕ:
µ |=p ϕ1, ϕ1 ∈Atoms(ϕ) ⇐⇒ϕ1 ∈µ;
µ |=p ¬ϕ1
⇐⇒µ ̸|=p ϕ1;
µ |=p ϕ1 ∧ϕ2
⇐⇒µ |=p ϕ1 and µ |=p ϕ2.
We say that a partial truth assignment µ propositionally satisﬁes ϕ if and
only if all the total truth assignments for ϕ which extend µ propositionally satisfy
ϕ.
From now on, if not speciﬁed, when dealing with propositional satisﬁability we
do not distinguish between total and partial assignments.
We say that ϕ is propositionally satisﬁable if and only if there exist an as-
signment µ such that µ |=p ϕ. Intuitively, if we consider a Math-formula ϕ as
a propositional formula in its atoms, then |=p is the standard satisﬁability in
propositional logic. Thus, for every ϕ1 and ϕ2, we say that ϕ1 |=p ϕ2 if and
only if µ |=p ϕ2 for every µ such that µ |=p ϕ1. We also say that |=p ϕ (ϕ is
propositionally valid) if and only if µ |=p ϕ for every assignment µ for ϕ. It is
easy to verify that ϕ1 |=p ϕ2 if and only if |=p ϕ1 →ϕ2, and that |=p ϕ if and
only if ¬ϕ is propositionally unsatisﬁable.
Notice that |=p is stronger than |=, that is, if ϕ1 |=p ϕ2, then ϕ1 |= ϕ2, but
not vice versa. E.g., (v1 ≤v2) ∧(v2 ≤v3) |= (v1 ≤v3), but (v1 ≤v2) ∧(v2 ≤
v3) ̸|=p (v1 ≤v3).
Example 1. Consider the following math-formula ϕ:
ϕ = {¬(2v2 −v3 > 2) ∨A1} ∧
{¬A2 ∨(2v1 −4v5 > 3)} ∧
{(3v1 −2v2 ≤3) ∨A2}
∧
{¬(2v3 + v4 ≥5) ∨¬(3v1 −v3 ≤6) ∨¬A1} ∧
{A1 ∨(3v1 −2v2 ≤3)}
∧
{(v1 −v5 ≤1) ∨(v5 = 5 −3v4) ∨¬A1} ∧
{A1 ∨(v3 = 3v5 + 4) ∨A2}.
The truth assignment given by the underlined literals above is:
µ = {¬(2v2−v3 > 2), ¬A2, (3v1−2v2 ≤3), (v1−v5 ≤1), ¬(3v1−v3 ≤6), (v3 = 3v5+4)}.
Notice that the two occurrences of (3v1 −2v2 ≤3) in rows 3 and 5 of ϕ are
both assigned ⊤. µ is an assignment which propositionally satisﬁes ϕ, as it sets
to true one literal of every disjunction in ϕ. Notice that µ is not satisﬁable, as
both the following sub-assignments of µ
{(3v1 −2v2 ≤3), ¬(2v2 −v3 > 2), ¬(3v1 −v3 ≤6)}
(2)
{(v1 −v5 ≤1), (v3 = 3v5 + 4), ¬(3v1 −v3 ≤6)}
(3)
do not have any satisfying interpretation.
✸

236
G. Audemard et al.
Deﬁnition 4. We say that a collection M = {µ1, . . . , µn} of (possibly partial)
assignments propositionally satisfying ϕ is complete if and only if
|=p ϕ ↔

j
µj.
(4)
where each assignment µj is written as a conjunction of its elements.
M is complete in the sense that, for every total assignment η such that η |=p ϕ,
there exists µj ∈M such that µj ⊆η. Therefore M is a compact representation
of the whole set of total assignments propositionally satisfying ϕ. Notice however
that ||M|| is worst-case exponential in the size of ϕ, though typically much
smaller than the set of all total assignments satisfying ϕ.
Deﬁnition 5. We say that a complete collection M = {µ1, . . . , µn} of assign-
ments propositionally satisfying ϕ is non-redundant if for every µj ∈M,
M \ {µj} is no more complete, it is redundant otherwise. M is strongly
non-redundant if, for every µi, µj ∈M, (µ1 ∧µ2) is propositionally unsatisﬁ-
able.
It is easy to verify that, if M is redundant, then µi ⊆µj for some i, j, and that,
if M is strongly non-redundant, then it is non-redundant too, but the vice versa
does not hold.
Example 2. Let ϕ := (α ∨β ∨γ) ∧(α ∨β ∨¬γ), α, β and γ being atoms. Then
1. {{α, β, γ}, {α, β, ¬γ}, {α, ¬β, γ}, {α, ¬β, ¬γ}, {¬α, β, γ}, {¬α, β, ¬γ}} is the
set of all total assignments propositionally satisfying ϕ;
2. {{α}, {α, β}, {α, ¬γ}, {α, β}, {β}, {β, ¬γ}, {α, γ}, {β, γ}} is complete but re-
dundant;
3. {{α}, {β}} is complete, non redundant but not strongly non-redundant;
4. {{α}, {¬α, β}} is complete and strongly non-redundant.
✸
Theorem 1. Let ϕ be a Math-formula and let M = {µ1, . . . , µn} be a complete
collection of truth assignments propositionally satisfying ϕ. Then ϕ is satisﬁable
if and only if µj is satisﬁable for some µj ∈M.
3.2
Decidability and Complexity
Having a Math-formula ϕ, it is always possible to ﬁnd a complete collection of
satisfying assignments for ϕ (see later). Thus from Theorem 1 we have trivially
the following fact.
Proposition 1. The satisﬁability problem for a Math-formula over atoms of a
given class is decidable if and only if the satisﬁability of sets of literals of the
same class is decidable.

Integrating Boolean and Mathematical Solving
237
For instance, the satisﬁability of a set of linear constraints on R or on Z, or a
set of non-linear constraints on R is decidable, whilst a set of non-linear (poly-
nomial) constraints on Z is not decidable (see, e.g., [RV01]). Consequently, the
satisﬁability of Math-formulas over linear constraints on R or on Z, or over non-
linear constraints on R is decidable, whilst the satisﬁability of Math-formulas
over non-linear constraints over Z is undecidable.
For the decidable cases, as standard boolean formulas are a strict subcase
of Math-formulas, it follows trivially that deciding the satisﬁability of Math-
formulas is “at least as hard” as boolean satisﬁability.
Proposition 2. The problem of deciding the satisﬁability of a Math-formula ϕ
is NP-hard.
Thus, deciding satisﬁability is computationally very expensive. The complexity
upper bound may depend on the kind of mathematical problems we are dealing.
For instance, if we are dealing with arithmetical expressions over bounded inte-
gers, then for every I we can verify I |= ϕ in a polynomial amount of time, and
thus the problem is also NP-complete.
4
A Generalized Search Procedure
Theorem 1 allows us to split the notion of satisﬁability of a Math-formula ϕ into
two orthogonal components:
– a purely boolean component, consisting of the existence of a propositional
model for ϕ;
– a purely mathematical component, consisting of the existence of an inter-
pretation for a set of atomic (possibly negated) mathematical propositions.
These two aspects are handled, respectively, by a truth assignment enumerator
and by a mathematical solver.
Deﬁnition 6. We call a truth assignment enumerator a total function As-
sign Enumerator which takes as input a Math-formula ϕ and returns a com-
plete collection {µ1, . . . , µn} of assignments satisfying ϕ.
Notice the diﬀerence between a truth assignment enumerator and a standard
boolean solver: a boolean solver has to ﬁnd only one satisfying assignment —or
to decide there is none— while an enumerator has to ﬁnd a complete collection
of satisfying assignments. (We will show later how some boolean solvers can be
modiﬁed to be used as enumerators.)
We say that Assign Enumerator is
– strongly
non-redundant
if
Assign Enumerator(ϕ)
is
strongly
non-
redundant, for every ϕ,
– non-redundant if Assign Enumerator(ϕ) is non-redundant for every ϕ,
– redundant otherwise.

238
G. Audemard et al.
boolean Math-SAT(formula ϕ, assignment & µ, interpretation & I)
do
µ := Next(Assign Enumerator(ϕ)) /* next in {µ1, ..., µn} */
if (µ ̸= Null)
I :=MathSolver(µ);
while ((I = Null) and (µ ̸= Null))
if (I ̸= Null)
then return True;
/* a D-satisﬁable assignment found */
else return False;
/* no D-satisﬁable assignment found */
Fig. 1. Schema of the generalized search procedure for D-satisﬁability.
Deﬁnition 7. We call a mathematical solver a total function MathSolver
which takes as input a set of (possibly negated) atomic Math-formulas µ and
returns an interpretation satisfying µ, or Null if there is none.
The general schema of a search procedure for satisﬁability is reported in
Figure 1. Math-SAT takes as input a formula ϕ and (by reference) an initially
empty assignment µ and an initially null interpretation I. For every assignment µ
in the collection {µ1, .., µn} generated by Assign Enumerator(ϕ), Math-SAT
invokes MathSolver over µ, which either returns a interpretation satisfying µ,
or Null if there is none. This is done until either one satisﬁable assignment is
found, or no more assignments are available in {µ1, ..., µn}. In the former case
ϕ is satisﬁable, in the later case it is not.
Math-SAT performs at most ||M|| loops. Thus, if every call to Math-
Solver terminates, then Math-SAT terminates. Moreover, it follows from The-
orem 1 that Math-SAT is correct and complete if MathSolver is correct and
complete. Notice that, it is not necessary to check the whole set of total truth
assignments satisfying ϕ, rather it is suﬃcient to check an arbitrary complete col-
lection M of partial assignments propositionally satisfying ϕ, which is typically
much smaller.
It is very important to notice that the search procedure schema of Figure 1 is
completely independent on the kind of mathematical domain we are addressing,
once we have a mathematical solver for it. This means that the expressivity of
Math-SAT, that is, the kind of math-formulas Math-SAT can handle, depends
only on the kind of sets of mathematical atomic propositions MathSolver can
handle.
4.1
Suitable Assign Enumerators
The following are the most signiﬁcant boolean reasoning techniques that we can
adapt to be used as assignment enumerators.

Integrating Boolean and Mathematical Solving
239
Tableau Search Graph
α
−γ
α
−γ
α
−γ
α
γ
{α} {α,β}{α,−γ} {α,β} {β} {β,−γ} {α,γ} {β,γ}
α
−α
β 
−β
{α}
{−α,β}
γ
β
β
β
β
α
Τ
F
F
{α}
{−α,β}
β 
Τ
Τ
F
(α)
(α)
(β)
(β)
OBDD
DPLL search graph
Fig. 2. OBDD, Tableau search graph and DPLL search graph for the formula (α ∨
β ∨γ) ∧(α ∨β ∨¬γ).
DNF. The simplest technique we can use as an enumerator is the Disjunctive
Normal Form (DNF) conversion. A propositional formula ϕ can be converted
into a formula DNF(ϕ) by (i) recursively applying DeMorgan’s rewriting rules
to ϕ until the result is a disjunction of conjunction of literals, and (ii) removing
all duplicated and subsumed disjuncts. The resulting formula is normal, in the
sense that DNF(ϕ) is propositionally equivalent to ϕ, and that propositionally
equivalent formulas generate the same DNF modulo reordering.
By Deﬁnition 4, we can see (the set of disjuncts of) DNF(ϕ) as a com-
plete and non-redundant —but not strongly non-redundant— collection of as-
signments propositionally satisfying ϕ. For instance, in Example 2, the set of
assignments at point 2. and 3. are respectively the results of step (i) and (ii)
above.
OBDD. A more eﬀective normal form for representing a boolean formula if
given by the Ordered Binary Decision Diagrams (OBDDs) [Bry86], which are
extensively used in hardware veriﬁcation and model checking. Given a total
ordering v1, ..., vn on the atoms of ϕ, the OBDD representing ϕ (OBDD(ϕ))
is a directed acyclic graph such that (i) each node is either one of the two
terminal nodes T, F, or an internal node labeled by an atom v of ϕ, with two
outcoming edges T(v) (“v is true”) and F(v) (“v is false”), (ii) each arc vi →
vj is such that vi < vj in the total order. If a node n labeled with v is the
root of OBDD(φ) and n1, n2 are the two son nodes of n through the edges
T(v) and F(v) respectively, then n1, n2 are the roots of OBDD(φ[v = ⊤]) and
OBDD(φ[v = ⊥]) respectively. A path from the root of OBDD(ϕ) to T [resp.
F] is a propositional model [resp. counter-model] of ϕ, and the disjunction of
such paths is propositionally equivalent to ϕ [resp. ¬ϕ].
Thus, we can see OBDD(ϕ) as a complete collection of assignments propo-
sitionally satisfying ϕ. As every pair of paths diﬀer for the truth value of at
least one variable, OBDD(ϕ) is also strongly non-redundant. For instance, in
Figure 2 (left) the OBDD of the formula in Example 2 is represented. The paths
to T are those given by the set of assignments at point 4. of Example 2.

240
G. Audemard et al.
Semantic tableaux. A standard boolean solving technique is that of semantic
tableaux [Smu68]. Given an input formula ϕ, in each branch of the search tree
the set {ϕ} is decomposed into a set of literals µ by the recursive application of
the rules:
µ′ ∪{ϕ1, ..., ϕn}
µ′ ∪{n
i=1 ϕi} (∧)
µ′ ∪{ϕ1}
....
µ′ ∪{ϕn}
µ′ ∪{n
i=1 ϕi}
(∨),
plus analogous rules for (→), (↔), (¬∧), (¬∨), (¬ →), (¬ ↔). The main steps
are:
– (closed branch) if µ contains both ϕi and ϕi for some subformula ϕi of ϕ,
then µ is said to be closed and cannot be decomposed any further;
– (solution branch) if µ contains only literals, then it is an assignment such
that µ |=p ϕ;
– (∧-rule) if µ contains a conjunction, then the latter is unrolled into the set
of its conjuncts;
– (∨-rule) if µ contains a disjunction, then the search branches on one of the
disjuncts.
The search tree resulting from the decomposition is such that all its solu-
tion branches are assignments in a collection Tableau(ϕ), whose disjunction is
propositionally equivalent to ϕ. Thus Tableau(ϕ) is complete, but it may be re-
dundant. For instance, in Figure 2 (center) the search tree of a semantic tableau
applied on the formula in Example 2 is represented. The solutions branches give
rise to the redundant collection of assignments at point 2. of Example 2.
DPLL. The most commonly used boolean solving procedure is DPLL [DLL62].
Given ϕ in input, DPLL tries to build recursively one assignment µ satisfying
ϕ, at each step adding a new literal to µ and simplifying ϕ, according to the
following steps:
– (base) If ϕ = ⊤, then µ propositionally satisﬁes the original formula, so that
µ is returned;
– (backtrack) if ϕ = ⊥, µ propositionally falsiﬁes the original formula, so that
DPLL backtracks;
– (unit propagation) if a literal l occurs in ϕ as a unit clause, then DPLL is
invoked recursively on ϕl=⊤and µ∪{l}, ϕl=⊤being the result of substituting
⊤for l in ϕ and simplifying;
– (split) otherwise, a literal l is selected, and DPLL is invoked recursively on
ϕl=⊤and µ ∪{l}. If this call succeeds, then the result is returned, otherwise
DPLL is invoked recursively on ϕl=⊥and µ ∪{¬l}.
Standard DPLL can be adapted to work as a boolean enumerator by simply
modifying in the base case “µ is returned” with “µ is added to the collection,
and backtrack” [GS96,Seb01].
The resulting set of assignments DPLL(ϕ) is complete and strongly non-
redundant [Seb01]. For instance, in Figure 2 (right) the search tree of DPLL

Integrating Boolean and Mathematical Solving
241
applied on the formula in Example 2 is represented. The non closed branches
give rise to the set of assignments at point 4. of Example 2.
Notice the diﬀerence between an OBDD and (the search tree of) DPLL: ﬁrst,
the former is a direct acyclic graph whilst the second is a tree; second, in OBDDs
the order of branching variables if ﬁxed a priori, while DPLL can choose each
time the best variable to split.
4.2
Non-suitable Assign Enumerators
It is very important to notice that, in general, not every boolean solver can be
adapted to work as a boolean enumerator. For instance, many implementations
of DPLL include also the following step between unit propagation and split:
– (pure literal) if an atom ψ occurs only positively [resp. negatively] in ϕ,
then DPLL is invoked recursively on ϕψ=⊤and µ ∪{ψ} [resp. ϕψ=⊥and
µ ∪{¬ψ}];
(we call this variant DPLL+PL). DPLL+PL is complete as a boolean solver,
but does not generate a complete collection of assignments, so that it cannot be
used as an enumerator.
Example 3. If we used DPLL+PL as Assign Enumerator in Math-SAT and
gave in input the formula in Example 2, DPLL+PL might return the one-
element collection {{α}}, which is not complete. If α is (x2 + 1 ≤0) and β is
(y ≤x), x, y ∈R, then {α} is not satisﬁable, so that Math-SAT would return
unsatisﬁable. On the other hand, the formula ϕ is satisﬁable because, e.g., the
assignment {¬α, β} is satisﬁed by I(x) = 1.0 and I(y) = 0.0.
5
Requirements for Assign Enumerator and MathSolver
Apart from the eﬃciency of MathSolver —which varies with the kind of prob-
lem addressed and with the technique adopted, and will not be discussed here—
and that of the SAT solver used —which does not necessarily imply its eﬃciency
as an enumerator— many other factors inﬂuence the eﬃciency of Math-SAT.
5.1
Eﬃciency Requirements for Assign Enumerator
Polynomial vs. exponential space in Assign Enumerator. We would
rather Math-SAT require polynomial space. As M can be exponentially big
with respect to the size of ϕ, we would rather adopt a generate-check-and-drop
paradigm: at each step, generate the next assignment µi ∈M, check its sat-
isﬁability, and then drop it —or drop the part of it which is not common to
the next assignment— before passing to the i + 1-step. This means that As-
sign Enumerator must be able to generate the assignments one at a time.
To this extent, both DNF and OBDD are not suitable, as they force generat-
ing the whole assignment collection M one-shot. Instead, both semantic tableaux
and DPLL are a good choice, as their depth-ﬁrst search strategy allows for gen-
erating and checking one assignment at a time.

242
G. Audemard et al.
Non-redundancy of Assign Enumerator. We want to reduce as much as
possible the number of assignments generated and checked. To do this, a key
issue is avoiding MathSolver being invoked on an assignment which either is
identical to an already-checked one or extends one which has been already found
unsatisﬁable. This is obtained by using a non-redundant enumerator. To this
extent, semantic tableaux are not a good choice.
Non-redundant enumerators avoid generating partial assignments whose un-
satisﬁability is a propositional consequence of those already generated. If M is
strongly non-redundant, however, each total assignment η propositionally satis-
fying ϕ is represented by one and only one µj ∈M, and every µj ∈M represents
univocally 2|Atoms(ϕ)|−|µj| total assignments. Thus strongly non-redundant enu-
merators also avoid generating partial assignments covering areas of the search
space which are covered by already-generated ones.
For enumerators that are not strongly non-redundant, there is a tradeoﬀ
between redundancy and polynomial memory. In fact, when adopting a generate-
check-and-drop paradigm, the algorithm has no way to remember if it has already
checked a given assignment or not, unless it explicitly keeps track of it, which
requires up to exponential memory. Strong non-redundancy instead provides a
logical warrant that an already checked assignment will never be checked again.
5.2
Exploiting the Interaction between Assign Enumerator and
MathSolver
Intermediate assignment checking. If an assignment µ′ is unsatisﬁable, then
all its extensions are unsatisﬁable. Thus, when the unsatisﬁability of µ′ is de-
tected during its recursive construction, this prevents checking the satisﬁability
of all the up to 2|Atoms(ϕ)|−|µ′| truth assignments which extend µ′. Thus, another
key issue for eﬃciency is the possibility of modifying Assign Enumerator so
that it can perform intermediate calls to MathSolver and it can take advantage
of the (un)satisﬁability information returned to prune the search space.
With semantic tableaux and DPLL, this can be easily obtained by intro-
ducing an intermediate test, immediately before the (∨-rule) and the (split)
step respectively, in which MathSolver is invoked on an intermediate assign-
ment µ′ and, if it is inconsistent, the whole branch is cut [GS96,ABC+02]. With
OBDDs, it is possible to reduce an existing OBDD by traversing it depth-ﬁrst
and redirecting to the F node the paths representing inconsistent assignments
[CABN97]. However, this requires generating the non-reduced OBDD anyway.
Generating and handling conﬂict sets. Given an unsatisﬁable assignment
µ, we call a conﬂict set any unsatisﬁable sub-assignment µ′ ⊂µ. (E.g., in Ex-
ample 1 (2) and (3) are conﬂict sets for the assignment µ.) A key eﬃciency
issue for Math-SAT is the capability of MathSolver to return the conﬂict set
which has caused the inconsistency of an input assignment, and the capability
of Assign Enumerator to use this information to prune search.
For instance, both Belman-Ford algorithm and Simplex LP procedures
can produce conﬂict sets [ABC+02,WW99]. Semantic tableaux and DPLL

Integrating Boolean and Mathematical Solving
243
can be enhanced by a technique called mathematical backjumping [HPS98,
WW99,ABC+02]:
when
MathSolver(µ)
returns
a
conﬂict
set
η,
As-
sign Enumerator can jump back in its search to the deepest branching point
in which a literal l ∈η is assigned a truth value, pruning the search tree below.
DPLL can be enhanced also with learning [WW99,ABC+02]: the negation of
the conﬂict set ¬η is added in conjunction to the input formula, so that DPLL
will never again generate an assignment containing the conﬂict set η.
Generating and handling derived assignments. Another eﬃciency issue
for Math-SAT is the capability of MathSolver to produce an extra assign-
ment η derived deterministically from a satisﬁable input assignment µ, and the
capability of Assign Enumerator to use this information to narrow the search.
For instance, in the procedure presented in [ABC+02,ACKS02], Math-
Solver computes equivalence classes of real variables and performs substitu-
tions which can produce further assignments. E.g., if (v1 = v2), (v2 = v3) ∈µ,
(v1 −v3 > 2) ̸∈µ and µ is satisﬁable, then MathSolver(µ) ﬁnds that v1
and v3 belong to the same equivalence class and returns an extra assignment η
containing ¬(v1 −v3 > 2), which is unit-propagated away by DPLL.
Incrementality of MathSolver. Another eﬃciency issue of MathSolver is
that of being incremental, so that to avoid restarting computation from scratch
whenever it is given in input an assignment µ′ such that µ′ ⊃µ and µ has already
proved satisﬁable. (This happens, e.g., at the intermediate assignments checking
steps.) Thus, MathSolver should “remember” the status of the computation
from one call to the other, whilst Assign Enumerator should be able to keep
track of the computation status of MathSolver.
For instance, it is possible to modify a Simplex LP procedure so that to
make it incremental, and to make DPLL call it incrementally after every unit
propagation [WW99].
6
Implemented Systems
In order to provide evidence of the generality of our approach, in this section
we brieﬂy present some examples. First we enumerate some existing procedures
which are captured by our framework. Then we present a brief description of
our own solver Math-SAT.
6.1
Examples
Our framework captures a signiﬁcant amount of existing procedure used in var-
ious application domains. We brieﬂy recall some of them.
Omega [Pug92] is a procedure used for dependence analysis of software. It is
an integer programming algorithm based on an extension of Fourier-Motzkin
variable elimination method. It handles boolean combinations of linear con-
straints by simply pre-computing the DNF of the input formula.

244
G. Audemard et al.
TSAT [ACG99] is an optimized procedure for temporal reasoning able to handle
sets of disjunctive temporal constraints. It integrates DPLL with a simplex
LP tool, adding some form of forward checking and static learning.
LPSAT [WW99] is an optimized procedure for Math-formulas over linear real
constraints, used to solve problems in the domain of resource planning. It
accept only formulas with positive mathematical constraints. LPSAT
in-
tegrates DPLL with an incremental simplex LP tool, and performs back-
jumping and learning.
SMV+QUAD-CLP [CABN97] integrates OBDDs with a quadratic constraint
solver to verify transition systems with integer data values. It performs a
form of intermediate assignment checking.
DDD [MLAH01] are OBDD-like data structures handling boolean combinations
of temporal constraints in the form (x−z ≤3), which are used to verify timed
systems. They combine OBDDs with an incremental version of Belman-Ford
minimal path and cycle detection algorithm.
Unfortunately, the last two approaches inherit from OBDDs the drawback of
requiring exponential space in worst case.
6.2
A DPLL-Based Implementation of Math-SAT
In [ABC+02,ACKS02] we presented Math-SAT, a decision procedure for Math-
formulas over boolean and linear mathematical propositions over the reals.
Math-SAT uses as Assign Enumerator an implementation of DPLL, and
as MathSolver a hierarchical set of mathematical procedures for linear con-
straints on real variables able to handle theories of increasing expressive power.
The latter include a procedure for computing and exploiting equivalence classes
from equality constraints like (x = y), a Bellman-Ford minimal path algorithm
with cycle detection for handling diﬀerences like (x −y ≤4), and a Sim-
plex LP procedure for handling the remaining linear constraints. Math-SAT
implements and uses most of the tricks and optimizations described in Sec-
tion 5. Technical details can be found in [ABC+02]. Math-SAT is available at
http://www.dit.unitn.it/˜rseba/Mathsat.html.
In [ABC+02,ACKS02] preliminary experimental evaluations were carried out
on tests arising from temporal reasoning [ACG99] and formal veriﬁcation of
timed systems [ACKS02]. In the ﬁrst class of problems, we have compared our
results with the results of the specialized procedure Tsat; although Math-SAT
is able to tackle a wider class of problems, it runs faster that the Tsat solver,
which is specialized to the problem class. In the second class, we have encoded
bounded model checking problems for timed systems into the satisﬁability of
Math-formulas, and run Math-SAT on them. It turned out that our approach
was comparable in eﬃciency with two well-established model checkers for timed
systems, and signiﬁcantly more expressive [ACKS02].

Integrating Boolean and Mathematical Solving
245
References
[ABC+02]
G. Audemard, P. Bertoli, A. Cimatti, A. Korni!lowicz, and R. Sebastiani. A
SAT Based Approach for Solving Formulas over Boolean and Linear Math-
ematical Propositions. In Proc. CADE’2002., 2002. To appear. Available
at http://www.dit.unitn.it/˜rseba/publist.html.
[ACG99]
A. Armando, C. Castellini, and E. Giunchiglia. SAT-based procedures for
temporal reasoning. In Proc. European Conference on Planning, CP-99,
1999.
[ACKS02]
G. Audemard, A. Cimatti, A. Korni!lowicz, and R. Sebastiani. SAT-Based
Bounded Model Checking for Timed Systems. 2002. Available at
http://www.dit.unitn.it/˜rseba/publist.html.
[BCCZ99]
A. Biere, A. Cimatti, E. Clarke, and Y. Zhu. Symbolic model checking
without BDDs. In Proc. CAV’99, 1999.
[Bry86]
R. E. Bryant. Graph-Based Algorithms for Boolean Function Manipula-
tion. IEEE Transactions on Computers, C-35(8):677–691, August 1986.
[CABN97]
W. Chan, R. J. Anderson, P. Beame, and D. Notkin. Combining constraint
solving and symbolic model checking for a class of systems with non-linear
constraints. In Proc. CAV’97, volume 1254 of LNCS, pages 316–327, Haifa,
Israel, June 1997. Springer-Verlag.
[DLL62]
M. Davis, G. Longemann, and D. Loveland. A machine program for the-
orem proving. Journal of the ACM, 5(7), 1962.
[GS96]
F. Giunchiglia and R. Sebastiani. Building decision procedures for modal
logics from propositional decision procedures - the case study of modal
K. In Proc. of the 13th Conference on Automated Deduction, LNAI, New
Brunswick, NJ, USA, August 1996. Springer Verlag.
[GS00]
F. Giunchiglia and R. Sebastiani. Building decision procedures for modal
logics from propositional decision procedures - the case study of modal
K(m). Information and Computation, 162(1/2), October/November 2000.
[HPS98]
I. Horrocks and P. F. Patel-Schneider.
FaCT and DLP.
In Procs.
Tableaux’98, number 1397 in LNAI, pages 27–30. Springer-Verlag, 1998.
[KMS96]
H. Kautz, D. McAllester, and Bart Selman. Encoding Plans in Proposi-
tional Logic. In Proc. KR’96, 1996.
[MLAH01]
J. Moeller, J. Lichtenberg, H. Andersen, and H. Hulgaard. Fully Symbolic
Model Checking of Timed Systems using Diﬀerence Decision Diagrams.
In Electronic Notes in Theoretical Computer Science, volume 23. Elsevier
Science, 2001.
[Pug92]
W. Pugh.
The Omega Test: a fast and practical integer programming
algoprithm for dependence analysis. Communication of the ACM, August
1992.
[RV01]
A. Robinson and A. Voronkov, editors. Handbook of Automated Reasoning.
Elsevier Science Publishers, 2001.
[Seb01]
R. Sebastiani. Integrating SAT Solvers with Math Reasoners: Foundations
and Basic Algorithms. Technical Report 0111-22, ITC-IRST, November
2001. Available at http://www.dit.unitn.it/˜rseba/publist.html.
[Smu68]
R. M. Smullyan. First-Order Logic. Springer-Verlag, NY, 1968.
[WW99]
S. Wolfman and D. Weld. The LPSAT Engine & its Application to Re-
source Planning. In Proc. IJCAI, 1999.

The Meaning of Inﬁnity in Calculus and
Computer Algebra Systems
Michael Beeson1 and Freek Wiedijk2
1 San Jos´e State University
2 University of Nijmegen
Abstract. We use ﬁlters of open sets to provide a semantics justifying
the use of inﬁnity in informal limit calculations in calculus, and in the
same kind of calculations in computer algebra. We compare the behavior
of these ﬁlters to the way Mathematica behaves when calculating with
inﬁnity.
We stress the need to have a proper semantics for computer algebra
expressions, especially if one wants to use results and methods from
computer algebra in theorem provers. The computer algebra method
under discussion in this paper is the use of rewrite rules to evaluate
limits involving inﬁnity.
1
Introduction
1.1
Problem
In calculus, when calculating limits, one often ﬁrst uses the heuristic of ‘calcu-
lating with inﬁnity’ before trying to evaluate the limit in a more formal way. For
instance one ‘calculates’:
lim
x→∞
1
x + 1 =
1
∞+ 1 = 1
∞= 0
which indeed gives the correct answer. However, it is not clear what the mean-
ing of this use of the symbol ‘∞’ is, and why this method works. This problem
arises in calculus textbooks, which usually avoid examples of such calculations
for fear of ‘lack of rigor’, although students are taught these methods at the
blackboard. It arose in the design of the ﬁrst author’s software, MathXpert [1,2,
3]. This software, which is designed to assist a student in producing step-by-step
solutions to calculus problems, had to be able to produce ‘ideal’ step-by-step
solutions of limit problems. Are such ‘ideal solutions’ allowed to use calculations
involving inﬁnity? Or are those calculations just private preliminary consider-
ations intended to guide a rigorous proof? MathXpert does allow calculations
involving inﬁnity, but not the full system justiﬁed in this paper, since that goes
beyond what one ﬁnds in calculus textbooks.
In the Mathematica system [9] the approach of calculating with inﬁnity is
used. Since Mathematica gives answers, rather than step-by-step solutions, one
will not notice the calculations with inﬁnity, in cases where the limit turns out to
J. Calmet et al. (Eds.): AISC-Calculemus 2002, LNAI 2385, pp. 246–258, 2002.
c
⃝Springer-Verlag Berlin Heidelberg 2002

The Meaning of Inﬁnity in Calculus and Computer Algebra Systems
247
exist (and be a ﬁnite number). But in fact, in Mathematica there is a complete
‘calculus of inﬁnity’ (and some related symbols):
In[1]:= 1/(Infinity + 1)
Out[1]= 0
In[2]:= Sqrt[Infinity]
Out[2]= Infinity
In[3]:= Infinity - Infinity
Infinity::indet:
Indeterminate expression (-Infinity) + (Infinity) encountered.
Out[3]= Indeterminate
In[4]:= Indeterminate + Infinity
Out[4]= Indeterminate
In[5]:= Sin[Infinity]
Out[5]= Interval[{-1, 1}]
In[6]:= 1/Interval[{-1, 1}]
Out[6]= Interval[{-Infinity, -1}, {1, Infinity}]
In[7]:= Interval[{-1, 1}]*Interval[{-1, 1}]
Out[7]= Interval[{-1, 1}]
In[8]:= Interval[{-1, 1}]ˆ2
Out[8]= Interval[{0, 1}]
In[9]:= 0*Sin[Infinity]
Out[9]= Interval[{0, 0}]
In[10]:= Infinity/Sin[Infinity]
Out[10]= Interval[{-Infinity, -Infinity}, {Infinity, Infinity}]
In[11]:= Infinity/Sin[Infinity]ˆ2
Out[11]= Interval[{Infinity, Infinity}]
Other computer algebra systems implement similar calculi. For instance, the
Maple system [6] uses the symbols infinity and undefined in answers to limit
problems.1
It is well known that many computer algebra packages make errors. One
of the reasons for that is that they fail to check the pre-conditions or ‘side
conditions’ that must be satisﬁed for a simpliﬁcation rule to be applicable. For
example, before applying
√
x2 = x we need to check that x ≥0. Systematically
keeping track of such assumptions is diﬃcult. The errors in computer algebra
systems sometimes give the impression that those systems place a higher priority
1 There is also some notion of interval in Maple, written as 1 .. 2, but our attempts to
calculate with these terms led only to error messages. These terms seem primarily
to be used for generating integer sequences, although the answer to limx→∞sin x
comes out as -1 .. 1.

248
M. Beeson and F. Wiedijk
on performing as many simpliﬁcations as possible than on ensuring that only
correct computations are performed. Generally, ‘evaluation errors’ which users
complain about are taken care of on an ad hoc basis only, to get rid of the most
embarrassing ones.
Related to these errors is the fact that these systems have no uniﬁed se-
mantics for their expression language. In this paper we focus on the apparatus
for limits and oﬀer a solution: a semantics explaining and supporting the use
of inﬁnities in limit calculations. We will present a formal semantics of limits,
which not only explains the calculations usually performed with inﬁnities, but
oﬀers some extensions by introducing some other symbols for common ways in
which a function can fail to have a limit. Thus, we will be able to get an answer
by calculation for such a limit as limx→∞1/(2 + sin x) which will be ‘oscilla-
tions through the interval [ 1
3, 1]’. We then compare the resulting semantics to
the behavior of Mathematica as illustrated above. There is a rough general cor-
respondence, and our semantics agrees with some of the examples above, but
in some instances Mathematica does give incorrect answers, and in some cases
we are able to distinguish between identical Mathematica expressions which are
diﬀerent in our semantics.
1.2
Approach
We will represent ∞and its cousins indeterminate and interval by ﬁlters over some
underlying topological space (which in calculus textbooks and Mathematica is
the space of real numbers, but could also be the complex numbers or more
general spaces). For each point of the space there will be a ﬁlter associated with
it, which is called the principal ﬁlter of the point. For each function on the space
there will be a lifted version that works on the ﬁlters instead of on the points.
Furthermore we will deﬁne classes of ﬁlters called the interval ﬁlters and
the connected ﬁlters. It will turn out that those two classes coincide and that
connectedness of ﬁlters is preserved under continuous mappings. Also we will
deﬁne the join and the meet of two ﬁlters.
It turns out that the calculus used in Mathematica corresponds directly to
the set of ﬁnite joins of interval ﬁlters.
1.3
Related Work
First, in topology, the two standard approaches for deﬁning limits in topological
spaces make use of nets or ﬁlters. There is therefore nothing original in the use
of ﬁlters to analyze the notion of limits. However, our focus to use them in an
applied setting, and identify speciﬁc ﬁlters associated with ‘extra-mathematical’
symbols such as ∞, seems to be new.
Second, the interval ﬁlters are directly related to the active ﬁeld of interval
arithmetic. We throw a new light on the calculations with intervals by looking
at them as ﬁlters.
Third, justifying ‘calculations with inﬁnite objects’ rigorously, is close to
doing the same with ‘calculations with inﬁnitesimal objects’, which is the domain

The Meaning of Inﬁnity in Calculus and Computer Algebra Systems
249
of nonstandard analysis. In nonstandard analysis one also has inﬁnity as a ﬁrst
class citizen. This relation is even more manifest when noting that the simplest
way to get non-standard objects is as ultraﬁlters, a special kind of ﬁlter. The
diﬀerence between ﬁlters and ultraﬁlters indicates what the diﬀerence between
our approach and the non-standard one is. In nonstandard analysis there is not
one, designated, inﬁnity; instead there are many inﬁnite nonstandard numbers,
without a ‘canonical’ one. In our case there is a canonical inﬁnity. To illustrate
this diﬀerence concretely, let ω be the inﬁnity of nonstandard analysis. Then we
have ω + 1 ̸= ω, but ∞+ 1 = ∞. Another diﬀerence between the ultraﬁlters of
nonstandard analysis and the ﬁlters that we study here is that our ﬁlters only
contain open sets instead of arbitrary sets. Nonstandard analysis has been used
in [4] to help in the computation of limits in a computer algebra system.
2
Filters, Lifting, Reﬁnement, and Limits
Deﬁnition 1. Let X be a topological space. Denote the open sets of X by O(X).
A ﬁlter on X is a set A ⊆O(X) that satisﬁes:
∀U ∈A. ∀V ∈O(X). U ⊆V ⇒V ∈A
∀U ∈A. ∀V ∈A. U ∩V ∈A
In words: a ﬁlter is a set of open sets that is closed under supersets and ﬁnite
intersections. The collection of ﬁlters on X is written ¯X.
A ﬁlter that does not contain the empty set is called proper. A ﬁlter that does
not contain any set at all is called empty.
Often the property of being proper is made part of the deﬁnition of a ﬁlter.
However we did not do this, because otherwise we would be unable to deﬁne the
notion of meet on page 254 below. Sometimes the property of being non-empty
is made part of the deﬁnition of a ﬁlter too. However the empty ﬁlter, which is
called domain-error below, is essential to our application. We found variants of
the deﬁnition of ﬁlter in the literature, both allowing for improper [5] and for
empty [7] ﬁlters. Therefore we feel free to deﬁne the concept of ﬁlter to suit our
purposes.
In the topological literature a ﬁlter is generally not deﬁned on a topological
space but on an arbitrary set. In that case the restriction to open sets is not
present. However, for our application it is more natural to restrict ourselves to
ﬁlters of open sets.
Deﬁnition 2. Here are some common ﬁlters on the real numbers, where a ∈R
is an arbitrary real number:
improper ≡† ≡O(R)
domain-error ≡⊥≡∅
indeterminate ≡↔≡{R}
principal(a) ≡¯a ≡{U ∈O(R) | a ∈U}

250
M. Beeson and F. Wiedijk
= {U ∈O(R) | ∃ε ∈R>0. (a −ε, a + ε) ⊆U}
left(a) ≡a−≡{U ∈O(R) | ∃ε ∈R>0. (a −ε, a) ⊆U}
right(a) ≡a+ ≡{U ∈O(R) | ∃ε ∈R>0. (a, a + ε) ⊆U}
punctured(a) ≡a± ≡{U ∈O(R) | ∃ε ∈R>0. (a −ε, a) ∪(a, a + ε) ⊆U}
inﬁnity ≡∞≡{U ∈O(R) | ∃ε ∈R>0. (1/ε, ∞) ⊆U}
minus-inﬁnity ≡−∞≡{U ∈O(R) | ∃ε ∈R>0. (−∞, −1/ε) ⊆U}
bi-inﬁnity ≡±∞≡{U ∈O(R) | ∃ε ∈R>0. (−∞, −1/ε) ∪(1/ε, ∞) ⊆U}
positive ≡→≡{U ∈O(R) | (0, ∞) ⊆U}
negative ≡←≡{U ∈O(R) | (−∞, 0) ⊆U}
non-zero ≡±→≡{U ∈O(R) | (−∞, 0) ∪(0, ∞) ⊆U}
For each of these ﬁlters we have a ‘long’ and a ‘short’ notation. The ﬁrst four
ﬁlters can be deﬁned for any topological space. The other ﬁlters have analogues
in any order topology.
Deﬁnition 3. Let again X be a topological space. Let A be a collection of subsets
of X (not necessarily open) that satisﬁes:
∀U ∈A. ∀V ∈A. ∃W ∈A. W ⊆U ∩V
(∗)
The ﬁlter generated by A is deﬁned to be:
generated-by(A) ≡{U ∈O(X) | ∃V ∈A. V ⊆U}
The collection of sets A is called the basis of the ﬁlter generated-by(A).
Being closed under ﬁnite intersections implies (∗). If all elements of A are open
sets, the ﬁlter generated by A is the intersection of all ﬁlters that contain A as
a subset.
The ﬁlters given in Deﬁnition 2 can be deﬁned more naturally using the
notion of a generated ﬁlter. For instance, we have:
improper = generated-by({∅})
principal(a) = generated-by({{a}})
right(a) = generated-by({(a, a + ε) | ε ∈R>0}
inﬁnity = generated-by({(1/ε, ∞) | ε ∈R>0}
All other ﬁlters from Deﬁnition 2 can be deﬁned in a similar way.
Deﬁnition 4. Let f : X →X be some (possibly partial) function with domain
dom(f). The lift of f is a function ¯f : ¯X →¯X, deﬁned by:
¯f(A) ≡generated-by

{f[U] | U ⊆dom(f) ∧U ∈A}

This deﬁnition can be generalized to arbitrary arities. The function ¯f : ¯X × ¯X ×
. . . × ¯X →¯X is deﬁned by:
¯f(A1, A2, . . . , An) ≡
generated-by

{f[U] | U ⊆dom(f) ∧U = U1 × U2 × . . . × Un ∧
U1 ∈A1 ∧U2 ∈A2 ∧. . . ∧Un ∈An}


The Meaning of Inﬁnity in Calculus and Computer Algebra Systems
251
Although f can be a partial function, the lift of f is always total. One can get
rid of the problems of partial functions in calculus by lifting the whole theory
to ﬁlters. In some sense by going to ﬁlters we are adding a ‘bottom element’ ⊥
to the values of the theory. Looked at in this way, we have a strict partial logic,
because a function applied to ⊥will always give ⊥again.
Note also that the deﬁnitions of ¯a as a principal ﬁlter and as lift of a 0-ary
constant function coincide. This justiﬁes using one notation for both.
From now on we will often write f instead of ¯f when one or more of the
arguments of f are ﬁlters. So we will write sin(A) instead of sin(A). This will
allow us to write things like
√
A, and mean the lift of the square root function.
To state this convention more precisely: if t[x1, . . . , xn] is a term that does not
involve ﬁlters (so x1, . . . , xn are variables ranging over the ordinary reals) then
t[A1, . . . , An] will mean the lift of the function λx1 · · · xn. t[x1, . . . , xn] applied
to the ﬁlters A1, . . . , An. Note that with this convention 1/A means something
diﬀerent from ¯1/A. The ﬁrst is the lift of the unary function λx. 1/x applied to
A. The second is the lift of the binary function λx y. x/y applied to ¯1 and A.
Those are not necessarily equal: 1/1+ = 1−but ¯1/1+ = ¯1.
Deﬁnition 5. The ﬁlter limit of the function f : X →X when taking the limit
to the ﬁlter A is deﬁned to be:
Lim
x→A f(x) ≡¯f(A)
We distinguish a ﬁlter limit from an ordinary limit by writing ‘Lim’ with a capital
letter L. Note that the ﬁlter limit is always deﬁned, even for non-continuous f.
It might seem silly to introduce a new notation for this when we already have
deﬁned lifting, as it is the same operation. However, now we can write:
Lim
x→0+ x/x
which is something diﬀerent from
0+/ 0+
The ﬁrst is the lift of the unary function λx. x/x applied to 0+ and has as value
¯1. The second is the lift of the binary function λx y. x/y applied to the pair
(0+, 0+) and has as value →.
Deﬁnition 6. A ﬁlter A reﬁnes a ﬁlter B, notation A ⊑B when A ⊇B as
collections of open sets. When the two ﬁlters A and B diﬀer we write A ⊏B.
Here are some reﬁnement relations between the ﬁlters deﬁned in Deﬁnition 2.
For any proper and non-empty ﬁlter A we have:
† ⊏A ⊑↔⊏⊥
At any real number a ∈R we have:
a−, a+ ⊏a± ⊏¯a
and the ‘inﬁnite’ ﬁlters are related by:

252
M. Beeson and F. Wiedijk
−∞, ∞⊏±∞⊏↔,
−∞⊏←⊏±→⊏↔,
∞⊏→⊏±→⊏↔
Note that the ﬁlters from Deﬁnition 2 are not the only ones. There are many
‘wild’ ﬁlters reﬁning ¯a and ∞. For instance the ﬁlter generated by the sets
{2πn | n > N} is a ﬁlter which reﬁnes ∞. It has the property that the ﬁlter limit
of sin to this ﬁlter is ¯0.
We can now state the ﬁrst theorem2, which lists some of the many calculation
rules that one needs for arithmetic on ﬁlters:
Theorem 1. Let a ∈R>0 be some positive real number. Then:
∞+ ¯a = ∞
∞−¯a = ∞
∞+ ∞= ∞
∞−∞= ↔
¯a/¯0 = ⊥
¯a/0+ = ∞
¯a/0± = ±∞
0+/0+ = →
¯a/∞= 0+
¯a/±∞= 0±
¯a/→= →
¯a/↔= ⊥
¯0 ∞= ↔
0+∞= →
0±∞= ±→
∞∞= ∞
Note that, although the lift of division is a total function, ‘division by zero’ is
still not allowed in a sense, because the result of ¯a/¯0 is domain-error. This is
essentially diﬀerent from the way that Mathematica behaves. We will come back
to this in Section 4
The next theorem tells us how to evaluate the lift of a continuous function
in a point:
Theorem 2. Let f be a function that is continuous at a and monotonically
increasing in a neighborhood of a. Then:
¯f(¯a) = f(a),
¯f(a±) = f(a)±,
¯f(a−) = f(a)−,
¯f(a+) = f(a)+
Similar theorems hold for decreasing functions and functions at a local maximum
or minimum.
The next theorems show how to evaluate ﬁlter limits:
Theorem 3. Bringing ﬁlter limits inside expressions:
Lim
x→A f(g1(x), g2(x), . . . , gn(x)) ⊑¯f(Lim
x→A g1(x), Lim
x→A g2(x), . . . , Lim
x→A gn(x))
Note again that this theorem also holds for non-continuous f.
As an example of the fact that we do not always have equality here, not even
when all functions are continuous, consider:
Limx→∞(x −x) = Limx→∞0 = ¯0
(Limx→∞x) −(Limx→∞x) = ∞−∞= ↔
This agrees with the Theorem, since ¯0 ⊑↔.
2 We omit the straightforward proofs of the theorems in this paper. A paper containing
a full development of the theory presented here, including all the proofs, can be found
on the web pages of the authors.

The Meaning of Inﬁnity in Calculus and Computer Algebra Systems
253
Theorem 4. Monotonicity with respect to reﬁnement:
A1 ⊑B1, A2 ⊑B2, . . . , An ⊑Bn ⇒¯f(A1, A2, . . . , An) ⊑¯f(B1, B2, . . . , Bn)
Together these two theorems allow one to evaluate a ﬁlter limit ‘up to reﬁnement’
by substituting the ﬁlter inside the expression. Often this reﬁnement does not
hurt, because the right hand side will be a reﬁnement of ¯a or ∞anyway, allowing
us to apply the next theorem, which gives the relation between ﬁlter limits and
the usual kind of limits:
Theorem 5. Limit correspondence theorem:
lim
x→a f(x) = b ⇔
Lim
x→a± f(x) ⊑¯b
lim
x→a+ f(x) = b ⇔
Lim
x→a+ f(x) ⊑¯b
lim
x→∞f(x) = b ⇔Lim
x→∞f(x) ⊑¯b
Similar theorems hold at a−and −∞and for limits to plus or minus inﬁnity.
In Europe limx→a+ is sometimes written as limx↓a. The ∞and a+ in the
‘ordinary’ limits on the left are not ﬁlters: those are just the customary notations
for limits from the right and to inﬁnity. The a±, a+ and ∞on the right are ﬁlters.
Together these theorems now give us a method to rigorously evaluate ordinary
limits using ﬁlters:
1. Replace the limit by the corresponding ﬁlter limit.
2. ‘Evaluate’ the ﬁlter limit using ﬁlter calculations, leading to a reﬁnement.
3. If the right hand side of the reﬁnement reﬁnes ¯a, −∞or ∞then we have
succeeded and can use Theorem 5 (or its analogue for inﬁnite limits) to ﬁnd
the answer to the original question. If not, the method failed.
As an example, we use this method to evaluate limx→∞1/(x + 1):
Lim
x→∞
1
x + 1 ⊑
¯1
Limx→∞(x + 1) ⊑
¯1
∞+ ¯1 =
¯1
∞= 0+
(The reﬁnements here are really equalities but the theorems that we have do not
give that, and in fact we do not need it.) Now 0+ ⊑¯0 and so from Theorem 5
we ﬁnd that:
lim
x→∞
1
x + 1 = 0
3
Interval Filters and Connected Filters
Deﬁnition 7. We will deﬁne a class of ﬁlters on R called the interval ﬁlters.
Consider the set:
R = {−∞+} ∪{a−, a+ | a ∈R} ∪{∞−}

254
M. Beeson and F. Wiedijk
For each pair of elements α and β from R for which α ≤β in the natural order
on R, we will deﬁne a ﬁlter interval(α, β). We map the elements of R to formulas
as:
α
φl(x, α, ε)
φr(x, α, ε)
−∞+
⊤
x < −1/ε
a−
a −ε < x
x < a
a+
a < x
x < a + ε
∞−
1/ε < x
⊤
and then we deﬁne:
interval(α, β) ≡{U ∈O(R) | ∃ε ∈R>0. ∀x ∈R. φl(x, α, ε) ∧φr(x, β, ε) ⇒x ∈U}
We will write interval ﬁlters using interval notation:
[a, b) ≡interval(a−, b−)
[a, b] ≡interval(a−, b+)
(a, b) ≡interval(a+, b−)
(a, b] ≡interval(a+, b+)
We suppose that it will be clear from the context when we mean an interval as a
set of real numbers and when we mean an interval as an interval ﬁlter. Generally,
for ﬁnite a and b they are related like:
(a, b] = generated-by({(a, b]})
but not always. If a = b, then the left hand side is a+ but the right hand side is
improper because the set (a, a] is empty.
When we analyze a two-sided limit into two one-sided limits, and then want
to put the results back together, we need the concept of the ‘join’ of two ﬁlters,
which we write A ∨B. For example, 0−∨0+ = 0±. This concept is deﬁned as
follows:
Deﬁnition 8. The operations join and meet on ﬁlters are deﬁned by:
A ∨B = A ∩B
A ∧B = {U ∩V | U ∈A ∧V ∈B}
We can now write the ﬁlters from Deﬁnition 2 as interval ﬁlters or as joins of
interval ﬁlters:
¯a = [a, a]
a−= [a, a)
a+ = (a, a]
a± = [a, a) ∨(a, a]
∞= [∞, ∞)
−∞= (−∞, −∞]
±∞= (−∞, −∞] ∨[∞, ∞)
↔= (−∞, ∞)
→= (0, ∞)
←= (−∞, 0)
±→= (−∞, 0) ∨(0, ∞)
Now that we have the class of interval ﬁlters, we will deﬁne the class of connected
ﬁlters. This deﬁnition is much simpler:
Deﬁnition 9. A ﬁlter A is called connected when:
∀U ∈A. ∃V ∈A. V ⊆U ∧V is a connected set

The Meaning of Inﬁnity in Calculus and Computer Algebra Systems
255
Note that each of improper, domain-error and indeterminate is a connected ﬁlter.
The next three theorems give the relevant properties of the connected ﬁlters.
Together they ‘explain’ why in practice one encounters only joins of interval
ﬁlters: the ﬁlters one starts with are of that kind, and the operations that one
applies to them conserve the property.
Theorem 6. The interval ﬁlters are the proper non-empty connected ﬁlters.
So all interval ﬁlters are connected, and the only connected ﬁlters which are not
an interval ﬁlter are the ‘error ﬁlters’ improper and domain-error.
Theorem 7. If f is a function that is continuous on its domain, and A is a
connected ﬁlter, then ¯f(A) is also connected.
Theorem 8. ¯f(A ∨B) = ¯f(A) ∨¯f(B) and ¯f(A ∧B) ⊑¯f(A) ∧¯f(B).
These last two theorems show that if one applies functions that are continuous
on their domain to ﬁnite joins of interval ﬁlters, one always will end up with
ﬁnite joins of interval ﬁlters again.
4
Mathematica Revisited
Now that we have given a calculus of ﬁlters that resembles the way Mathematica
calculates with inﬁnity, we will compare the behavior of our calculus and that of
Mathematica in detail. This is what the calculations in the example Mathematica
from Section 1.1 become when we redo them in our ﬁlter calculus:
1/(∞+ 1) = 0+
√∞= ∞
∞−∞= ↔
↔+ ∞= ↔
sin ∞= [−1, 1]
1/[−1, 1] = ⊥
[−1, 1] · [−1, 1] = [−1, 1]
[−1, 1]2 = [0, 1]
¯0 sin ∞= ¯0
∞/ sin ∞= ∞/(sin ∞)2 = ⊥
Here are some diﬀerences with Mathematica:
– Mathematica does not like to give ‘no’ for an answer. So it prefers not to
complain about undeﬁnedness of a function. According to Mathematica:
1
[−1, 1] = (−∞, −1] ∨[1, ∞)
instead of ⊥. Our deﬁnitions have diﬀerent behavior because we want the
correspondence theorem about limits, Theorem 5, to hold. As an example of
this diﬀerence in attitude consider the limit:
lim
x→0+ x arctan(tan 1
x)
The graph of x arctan(tan(1/x)) looks like a ‘saw tooth’ converging to 0, and
it is undeﬁned inﬁnitely often in each neighborhood of 0. Still Mathematica
says3:
3 In version 3.0. In version 4.1 it leaves the expression unevaluated.

256
M. Beeson and F. Wiedijk
In[12]:= Limit[x*ArcTan[Tan[1/x]], x->0, Direction->-1]
Out[12]= 0
If you ask MathXpert to evaluate this limit, you get the message: This func-
tion is undeﬁned for certain values arbitrarily close to the limit point, so the
limit is undeﬁned.
– Mathematica does not identify as many expressions as it might. For instance,
in the example session it might have simpliﬁed:
Interval[{0, 0}] = 0
Interval[{Infinity, Infinity}] = Infinity
Interval[{-Infinity, Infinity}] = Indeterminate
– Mathematica does not distinguish between open and closed intervals, nor
does it have the concept of left and right ﬁlters to a point. In order to add
this subtlety to its Interval calculus all that would be needed is to mark
all the endpoints of the intervals with a + or a −.
– We have two kinds of ‘undeﬁned’ in our ﬁlter calculus: domain-error = ⊥and
indeterminate = ↔. (The third ﬁlter, improper = †, only occurs as the meet
of two disjoint interval ﬁlters, and never occurs in practice.) Mathematica
only has Indeterminate, and does not distinguish between these two kinds
of undeﬁnedness.
– Mathematica issues a ‘warning’ message like:
Power::infy: Infinite expression 1
0 encountered.
when it gets inﬁnite or indeterminate results. This seems to imply that such
results are errors. However, in our theory those results are not errors at all
but the correct answers, and they should not generate such a message.
– We gave the details of the ﬁlter theory for the space of real numbers. However,
the expression language of Mathematica is about the complex numbers. This
is clear, for example, from the results of applying Sqrt and Log to negative
numbers. It is therefore strange that Mathematica gives answers involving
intervals to limit questions, since such answers are appropriate to real limits.
In any case, our ﬁlter theory can be adapted to the complex numbers. For ex-
ample, complex inﬁnity is represented by the ﬁlter generated by the exteriors
of disks centered at 0 (i.e., ‘neighborhoods of inﬁnity’). The ‘one-sided’ ﬁlters
a+ and a−are replaced by a wide variety of other ﬁlters representing diﬀerent
ways in which a complex number z can ‘approach’ a limit point a: for example,
in complex analysis it is common to consider a limit restricted to an angular
sector, such as |θ| < π/4. It is easy to deﬁne a ‘sector ﬁlter’ generated by such a
sector. Our theorems that do not involve interval ﬁlters carry over to the com-
plex setting: pushing ﬁlter limits inside functions, the method of limit evaluation
by reﬁnement, etc. We have not given a characterization of the connected ﬁlters
in the complex case. For example, there are more than just the sector ﬁlters: the
ﬁlter generated by |θ| < r2 is not reﬁned by any sector ﬁlter.

The Meaning of Inﬁnity in Calculus and Computer Algebra Systems
257
5
Conclusion and Future Directions
We have presented the ﬁlter approach to evaluating limits involving inﬁnity.
The usual way of calculating with inﬁnities is not rigorous; indeed the central
concept inﬁnity is never deﬁned in calculus textbooks. The issue is skirted by
such statements as: ‘The symbol ∞does not represent a real number and we
cannot use it in arithmetic in the usual way.’ [8], p. 112.
Consider a student who says that limx→0+ 1/x is ‘undeﬁned’, while the
teacher says that ∞is a better answer. ‘But’, says the student, ‘you said ∞
is undeﬁned.’ Such dialogues do occur regularly in classrooms and teachers are
unable to answer these questions on any rigorous basis. We have now, at least in
principle, provided a remedy for this situation, since our theory of inﬁnite limits
is completely rigorous. Questions at the student level in our theory can usually
be proved or refuted.
When computer algebra systems make use of a set of calculation rules, there
should ideally be a semantics according to which these calculation rules are
correct. Even for ordinary algebra, this is not usually the case. But it is usually
the case that the rules are correct except that the system fails to check the pre-
conditions. That is, the semantics of algebra is understood – but systems fail to
implement the rules in a semantically correct way. Up until now, the semantics
of limits has not been properly understood, and so the behavior of computer
algebra systems did not even have a standard against which implementations
could be measured. In using intervals as answers to limits, Mathematica has
ventured into uncharted territory. We are now providing maps.
Our work, being completely rigorous, and based on simple set theory, is also
completely formal.4 Therefore computer-checking the theory from this paper
is possible, and the resulting formalization would not only be an interesting
exercise, but also probably could be used to make the prover automatically
evaluate more limits. In another direction, this material is suitable for inclusion
in an undergraduate real-analysis course, and the distinctions between diﬀerent
types of limits that it makes are suitable for inclusion in calculus books. In
particular, calculus books need no longer steer away from calculations involving
inﬁnity. Simple rules for manipulating inﬁnity can be given and the justiﬁcations
omitted, as is usually the case now when the justiﬁcations involve epsilon-delta
arguments.
References
1. Beeson, M., Mathpert Calculus Assistant. This software program (now known as
MathXpert) was published in July, 1997 by Mathpert Systems, Santa Clara, CA,
and is commercially available from <http://www.mathxpert.com/>.
4 Rigorous implies that the concepts and theorems have a clear meaning and the
theorems can be correctly proved. Formal implies that the concepts can be deﬁned
and the theorems proved in terms of set theory (or some other foundational theory
of mathematics).

258
M. Beeson and F. Wiedijk
2. Beeson, M., Design Principles of Mathpert: Software to support education in al-
gebra and calculus, in: Kajler, N. (ed.) Computer-Human Interaction in Symbolic
Computation, Texts and Monographs in Symbolic Computation, Springer-Verlag,
Berlin/Heidelberg/New York (1998), pp. 89-115.
3. Beeson, M.
MathXpert: un logiciel pour aider les ´el`eves `a apprendre les math´e-
matiques par l’action, to appear in Sciences et Techniques Educatives. An English
translation of this article under the title MathXpert: learning mathematics in the
twenty-ﬁrst century is available at
<http://www.mathcs.sjsu.edu/faculty/beeson/Pubs/pubs.html>.
4. Beeson, M., Using nonstandard analysis to verify the correctness of computations,
International Journal of Foundations of Computer Science, 6 (3) (1995), pp. 299-
338.
5. K. Kuratowski. Topology, volume 1. Academic Press, New York, London, 1966.
6. M. Monagan, K. Geddes, K. Heal, G. Labahn, and S. Vorkoetter. Maple V Pro-
gramming Guide for Release 5. Springer-Verlag, Berlin/Heidelberg, 1997.
7. B. Sims. Fundamentals of Topology. MacMillan, New York, 1976.
8. Stewart. Calculus, 3rd edition, Brooks-Cole, Paciﬁc Grove, CA 1995.
9. S. Wolfram. The Mathematica book. Cambridge University Press, Cambridge, 1996.

Making Conjectures about Maple Functions
Simon Colton
Division of Informatics
University of Edinburgh
United Kingdom
simonco@dai.ed.ac.uk
http://www.dai.ed.ac.uk/˜simonco
Abstract. One of the main applications of computational techniques
to pure mathematics has been the use of computer algebra systems to
perform calculations which mathematicians cannot perform by hand.
Because the data is produced within the computer algebra system, this
becomes an environment for the exploration of new functions and the
data produced is often analysed in order to make conjectures empirically.
We add some automation to this by using the HR theory formation
system to make conjectures about Maple functions supplied by the user.
Experience has shown that HR produces too many conjectures which
are easily proven from the deﬁnitions of the functions involved. Hence,
we use the Otter theorem prover to discard any theorems which can
be easily proven, leaving behind the more interesting ones which are
empirically true but not trivially provable. By providing an application
of HR’s theory formation in number theory, we show that using Otter to
prune HR’s dull conjectures has much potential for producing interesting
conjectures about standard computer algebra functions.
1
Introduction
There is an unfortunate dichotomy between the application of computer algebra
systems (CASs) and automated theorem provers (ATPs) to pure mathematics:
the concepts usually dealt with by computer algebra techniques are of too high a
complexity to prove things about (at the moment) using automated techniques.
There have been some attempts to bridge the gap in order to usefully apply
automated theorem proving to computer algebra, including (i) the routine prov-
ing of fairly trivial theorems such as side conditions holding when calculating
integrals and (ii) a less automated approach, where the user is actively involved
in theory exploration within the CAS and the prover is called upon at speciﬁc
times during the exploration [1].
Ideally, automated theorem provers would be called from within a CAS when-
ever the user made a conjecture about the functions they were deﬁning. However,
this will take increased sophistication in the automated theorem provers and is
unlikely to happen in the short term. If the aim of the integration of mathemati-
cal systems is to generate conjectures, rather than theorems about the functions
J. Calmet et al. (Eds.): AISC-Calculemus 2002, LNAI 2385, pp. 259–274, 2002.
c
⃝Springer-Verlag Berlin Heidelberg 2002

260
S. Colton
being explored using a CAS, then it is possible to put a positive spin on the rela-
tive diﬀerences between CAS and ATP. Rather than stating that a disadvantage
of ATPs is their limited abilities with concepts of a higher complexity, we note
that an advantage of ATPs is that they can be used to prove theorems from
ﬁrst principles, i.e., directly from the axioms of a domain. Furthermore, these
theorems are less likely to be of interest to the user than those which cannot be
proved by an ATP system. Therefore, in a conjecture-making context, we can use
ATP systems to prune conjectures which are provably true from the deﬁnitions
of the functions, thus improving the quality of the conjectures produced.
We assume a plausible 4-step model of progress in pure mathematics:
1. Some functions are deﬁned in a particular context
2. The functions are calculated over a set of input values
3. The input/output pairs are examined in order to highlight patterns
4. Any observed patterns are stated as conjectures and proved or disproved
We note that, in general, the second step can be automated by computer algebra
systems and the fourth step can be automated by theorem provers. Automating
the third step — thus providing a possible bridge between CAS and ATP —
is the subject of this paper. The making of conjectures necessitates a certain
amount of concept formation, as sophisticated conjecture making involves not
only making conjectures about the given functions, but also about closely related
functions. Hence, we will also be automating the ﬁrst step and closing a cycle of
theory formation.
We use the HR theory formation system [4] to produce conjectures about a
set of computer algebra functions provided by the user. In particular, we will use
functions from the Maple CAS [16] and we will use the Otter theorem prover
[13] to prove some of HR’s conjectures, so that we can discard them. In §2, we
describe the core functionality behind HR which enables it to make conjectures.
In §3 we describe the additional functionality implemented for this application to
the generation of conjectures about Maple functions. In §4, we describe a session
using HR to generate conjectures about some Maple functions from number
theory, and in appendix A, we prove one of the results which HR discovered
during the session.
2
Conjecture Making in HR
Much of HR’s functionality was used for this application to making conjectures
about Maple functions. Each functionality can be broadly characterised as part
of one of ﬁve tasks: (i) inventing concepts (ii) making conjectures (iii) ﬁnding
counterexamples (iv) proving theorems and (v) reporting results.
2.1
Inventing Concepts
HR forms theories about a set of objects of interest, which are integers in number
theory, graphs in graph theory, groups in group theory, etc. It is given background

Making Conjectures about Maple Functions
261
information which describes the objects of interest, namely some initial concepts.
As discussed in §3 and §4 below, the objects of interest in the session described in
this paper are integers, and the background information is supplied in the form
of Maple functions. From the background information, HR uses ten production
rules to produce a new concept from one (or two) old concepts. The production
rules are described in more detail in [5], and we concentrate here on four:
• The compose production rule composes functions using conjugation
• The disjunct production rule joins concepts using disjunction
• The exists production rule introduces existential quantiﬁcation
• The split production rule instantiates objects
As an example construction, we suppose that HR is given the background
concepts of the isprime(n) Maple function, which checks whether n is prime
and the tau(n) Maple function, which calculates the number of divisors of n.
Using the compose production rule, HR invents the concept of pairs of integers,
[a, b] for which b = tau(a) and isprime(b). Following this, it uses the exists pro-
duction rule to deﬁne the concept of integers, a, for which there exists such a b,
i.e., [a] : ∃b (tau(a) = b & isprime(b)). Hence HR has invented the concept of
integers which have a prime number of divisors, a concept which we discuss fur-
ther later. This construction is represented in ﬁgure 1. We say that the complexity
of a concept is the number of concepts (including itself) in the construction path
of the concept, as explained further in [5]. Hence, the complexity of the concept
in ﬁgure 1 is the number of boxes, i.e., four.
[a] : isprime(a)
[a, b] : sigma(a)=b & isprime(b)
compose
[a, b] : sigma(a)=b
compose
[a] : exists b (sigma(a)=b & isprime(b))
exists
Fig. 1. Construction of a number theory concept

262
S. Colton
2.2
Making Conjectures
HR has a number of ways to make conjectures, both by noticing empirical pat-
terns and by extracting conjectures from others. Firstly, whenever HR invents a
concept, it checks two things empirically:
(i) whether the concept has no examples whatsoever, in which case it makes a
non-existence conjecture, i.e., that the deﬁnition of the concept is inconsistent
with the axioms of the domain. For example, if HR invented the concept of square
numbers which are prime, it would ﬁnd no examples, and make the conjecture
that none exist on the number line.
(ii) whether the concept has exactly the same examples as a previous one, in
which case, it makes a conjecture that the deﬁnitions of the new and old concepts
are logically equivalent. For example, if HR invented the concept of integers for
which the number of divisors is 2, it would make the conjecture that the new
concept is equivalent to the concept of integers which are prime.
If the concept has a non-empty set of examples which diﬀers from all pre-
vious concepts, the concept is new and is added to the theory. When added
to the theory, HR determines which concepts the new concept subsumes, i.e.,
which concepts have a proper subset of the examples for the new concept.
For each old concept that the new concept subsumes, HR makes the impli-
cation conjecture that the old deﬁnition implies the new deﬁnition. Similarly,
HR determines which old concepts subsume the new concept, and makes the
appropriate implication conjectures. From each subsumption conjecture, HR ex-
tracts implicate conjectures. For instance if it made the implication conjecture
that f(a) & g(a) →h(a) & x(a), it would extract two implicate conjectures:
f(a) & g(a) →h(a) and f(a) & g(a) →x(a).
HR also extracts implicate conjectures from equivalence conjectures and non-
existence conjectures. For instance if HR made the equivalence conjecture that
f(a) & g(a) ↔h(a) & x(a), it would extract four implicates from this:
f(a) & g(a) →h(a)
f(a) & g(a) →x(a)
h(a) & x(a) →f(a)
h(a) & x(a) →g(a)
Similarly, if HR made the non-existence conjecture that ̸ ∃a (f(a) & g(a)), it
would extract two implicate conjectures: f(a) →¬g(a) and g(a) →¬f(a). We
enabled HR to extract implicates, as these are often easier to comprehend than
the conjectures from which they are extracted. Often, as in the case in §4, we
instruct HR to discard all but the implicates. Note that HR checks whether a
new implicate has already been added to the theory, to avoid redundancy.
From implicates, HR can also extract prime implicates, which are such that
no proper subset of the premises implies the goal. To do this, it tries to prove
that each subset of the premises of an implicate imply the goal, starting with the

Making Conjectures about Maple Functions
263
singleton subsets and trying ever larger subsets. For instance, if starting with
the implicate: f(a) & g(a) →h(a), HR tries the two prime implicates:
f(a) →h(a)
g(a) →h(a)
If Otter can prove either of these conjectures, then they are added to the set of
prime implicates, because clearly no proper subset of the premises imply the goal.
The prime implicates represent some of the fundamental truths in a domain. To
summarise, HR makes non-existence, equivalence and subsumption conjectures
empirically, then extracts implicates from these and prime implicates, where
possible, from the implicates.
2.3
Finding Counterexamples
The user can specify that certain objects of interest are given to HR to form
a theory with, and others are held back in order to use for counterexamples.
Then, whenever HR makes a conjecture, the held-back set is searched in order
to ﬁnd a counterexample. An advantage to this is an increase in eﬃciency, as
often only a fraction of the objects of interest will ﬁnd their way into the theory
as counterexamples, thus whenever HR invents a concept, it will have less work
to do to calculate the example set for the concept. Taking this to the extreme,
in §4, we give HR only the number 1 to start with, but allow it access to the
numbers 2 to 30 in order to ﬁnd counterexamples to false conjectures. This not
only increases eﬃciency, but it is also instructive to look at the false conjectures
HR makes for which each counterexample is introduced. In algebraic domains,
HR can also use the MACE model generator [15] to ﬁnd counterexamples, but
discussion of this is beyond the scope of this paper.
2.4
Proving Theorems
HR has some built-in abilities to decide when a conjecture it makes is trivially
true, e.g., it can tell that the conjecture f(a) & g(a) ↔g(a) & f(a) is true. It
also keeps a record of which concepts it generates are functions, so that it can
tell that the conjecture ̸ ∃a(f(a) = k1 & f(a) = k2) is true, where k1 and k2 are
diﬀerent ground instances. In fact, it uses its primitive theorem proving to avoid
inventing concepts such as this, because it knows in advance that the concept
will have no examples, leading to a dull non-existence conjecture. If HR had
any more sophisticated theorem proving, then we would, to a certain extent, be
re-inventing the wheel, as there are many good theorem provers available for HR
to use. In particular, HR invokes the Otter theorem prover to attempt to prove
the conjectures it makes. HR has been interfaced to Otter via MathWeb [9,17],
but the application here was undertaken using a simple ﬁle interface.
2.5
Reporting Results
HR is able to prune the conjectures it produces and order those remaining in
terms of measures of interestingness. In particular, for this application, we use

264
S. Colton
[a] : isprime(a)
[a, b] : sigma(a)=b & isprime(b)
compose
[a, b] : tau(a)=b & isprime(b)
compose
[a, b] : sigma(a)=b
compose
[a] : exists b (sigma(a)=b & isprime(b))
exists
[a] : exists b (tau(a)=b & isprime(b))
implies
[a, b] : tau(a)=b
compose
exists
Fig. 2. Construction of an implicate conjecture
HR to keep only implicates extracted from equivalence, non-existence and sub-
sumption conjectures, as these are usually easier to understand. We also instruct
HR to discard any conjectures which Otter can prove, as these are likely to follow
from the deﬁnitions of the Maple functions provided and be fairly uninteresting.
Of those implicates remaining, we use two measures of interestingness to
order them. Firstly, each implicate comprises a concept which implies a single
clause. The applicability of a concept gives an indication of the scope of the
conjecture, where the applicability is measured as the proportion of objects of
interest in the theory which have non-trivial examples for the concept. The
applicability of an implicate conjecture is taken as the applicability of the concept
on the LHS of the conjecture. For instance, if HR had the integers 1 to 30 as
objects of interest, then the concept of prime numbers would score 10/30 for
applicability, as there are 10 prime numbers between 1 and 30, namely 2, 3,
5, 7, 11, 13, 17, 19, 23 and 29. Hence implicate conjectures where the concept
which makes up the premises is the concept of prime numbers will score 1/3 for
applicability. Conjectures with very low applicability tend to be uninteresting,
so sorting the conjectures in terms of decreasing applicability can be useful.
Secondly, equivalence and subsumption conjectures relate two concepts from
the theory. HR measures the surprisingness of these conjectures as the propor-
tion of concepts in the construction path of either concept which are in the
construction path of just one concept. If two concepts conjectured to be related

Making Conjectures about Maple Functions
265
share many concepts in their construction paths, their deﬁnitions are likely to be
similar, and the relationship between them will be less surprising, so they score
less for surprisingness. For example, in ﬁgure 2, there are 7 concepts involved in
the construction history of the conjecture relating the two concepts joined by a
dotted line. Only one of these is shared by the two concepts in the conjecture,
hence the conjecture scores 6/7 for surprisingness. The implicates extracted from
equivalence and subsumption conjectures inherit the surprisingness value from
their parent, so that these too can be measured in terms of surprisingness.
3
Additional Functionality
Each new application of HR necessitates some new functionality. In this case,
we have extended HR’s functionality in all the ﬁve areas discussed in §2 above.
In terms of improved concept formation, HR is now able to communicate with
Maple. At present, it does this in the same way as it does with Otter, by reading
a ﬁle, invoking Maple in such a way that it outputs answers to a ﬁle, and then
reading that ﬁle. HR, Maple and Otter are already part of the MathWeb soft-
ware bus [9] and we have been successful in enabling HR to invoke Otter (and
other provers) via MathWeb [17]. We can see no problem in enabling the com-
munication between HR and Maple on a more sophisticated level via MathWeb,
and we hope to do this soon.
HR calls Maple at the start of a session to get the initial data for the back-
ground concepts. For instance, if the user decides to start HR with the integers
1 to 10 and the Maple number theory functions of tau(n)and sigma(n), (with
tau(n) being the number of divisors of n and sigma(n) being the sum of divi-
sors of n), then HR will use Maple to calculate tau(1)=1, . . ., tau(10)=4, doing
likewise for sigma. HR also calls Maple during concept formation, for instance, if
HR used its compose rule to invent the concept of tau(sigma(n)), then it would
need to calculate tau(sigma(10)) which is tau(18)=6. In future, we envisage
a more sophisticated interface between Maple and HR, in particular, enabling
HR to write conjectures in a format Maple can read, then using Maple to check
them empirically (over a large set of integers, or graphs, etc.). This interface
would improve the eﬃciency of checking the conjectures, as HR is not optimised
like Maple for performing lengthy calculations.
We also improved the way in which HR writes deﬁnitions, so that the con-
jectures about the concepts would be easier to read for the user (intended to be
a mathematician). In particular, in order to make the deﬁnitions of functions
which have been composed more understandable, HR was given the ability to
collate and remove existential variables where possible. For example, when HR
invents a concept with, say, the deﬁnition:

266
S. Colton
[a] : ∃b (f(a) = b & ∃c (g(b) = c & h(a) = c))
it ﬁrst collects together the existential variables thus:
[a] : ∃b, c (f(a) = b & g(b) = c & h(a) = c),
then removes the existential variables b and c thus:
[a] : g(f(a)) = h(a)
It has done this by both substituting f(a) for b and by removing c by equating
g(b) and h(a). As a concrete example, HR rewrites the deﬁnition for integers
with a prime number of divisors described in §2.1 above in this way:
[a] : ∃b (tau(a) = b & isprime(b))
becomes
[a] : isprime(tau(a))
which is easier to understand. This functionality is also useful for an application
to constraint generation [7].
In terms of improved conjecture making and reporting, HR can now make
applicability conjectures, which state that a concept is restricted to having only a
small number of examples. For instance, when HR invents the concept of integers
which are equal to their number of divisors, it notices that this property is only
true for integers 1 and 2. It then adds concept formation steps to the agenda
which invent (a) the concept of an integer being the number 1 (b) the concept
of being the number 2 and (c) the concept of being either 1 or 2. We call such
concepts instantiation concepts, as they are basically the instantiation of a single
object of interest (or a disjunction of similar instantiations). Having invented
concept (c) using the disjunct production rule, HR then makes the conjecture
that an integer is equal to the number of divisors if and only if it is equal to
1 or 2. HR is then able to identify the conjectures which involve instantiation
concepts and discard them, as they are, in general, not particularly interesting.
In terms of improved theorem proving, we gave HR the ability to pass Otter
ground instances of the Maple functions. For example, in §4, we describe a session
with HR using the Maple tau(n) function, which counts the number of divisors
of n. Because during that session, HR makes instantiations, it will eventually
discover conjectures such as ∀a, ((a = 1 ∨a = 2) →tau(a) = a). As HR uses
Maple to calculate ground instances such as tau(1) = 1 and tau(2) = 2,etc.,
and HR gives Otter these ground instances, Otter is able to prove the above
theorem and HR discards it because it is unlikely to be interesting.
Furthermore, the user is now able to act as a theorem prover and tell HR that
certain conjectures are true and should be given to Otter as additional axioms
for future proof attempts. For instance, in the session described in §4 below, HR
identiﬁes the conjecture that isprime(n) →tau(n) = 2. This follows from the
deﬁnitions, and we told HR to use this as an axiom of the domain. With that
information, it was able to prove many more theorems. This also means that, to
a certain extent, the user does not have to worry about specifying the axioms of
the domain in advance, as HR will come across (some of) them. In fact, for the
application in §4, we gave HR no axioms of number theory in advance.

Making Conjectures about Maple Functions
267
In terms of improved counterexample ﬁnding, we enabled the user to step in
and check whether certain objects of interest are counterexamples to a particular
conjecture HR has made. In number theory, the user can specify a lower and
upper bound on a set of integers, and HR checks if any integer in the set breaks
the conjecture. To perform the check, HR invokes Maple to calculate the user-
given Maple functions for each integer. Using this information, HR calculates
examples of the concepts in the conjecture for each integer and tests whether
the conjecture still holds. This functionality is useful once HR has identiﬁed
the interesting conjectures in a session, as the user can choose one and test it
empirically before attempting a proof (as we do in §4).
4
Results
In §5 we discuss a planned application of HR to discovery in pure mathematics,
for which the interface with Maple will be very important. Our aims for this
paper were to show that the pruning measures discussed above are eﬀective and
that it is possible to ﬁnd interesting conjectures about CAS functions using HR.
We give details here of a session with HR in number theory, where HR was
given as background knowledge three functions from the Maple numtheory pack-
age. The three functions were tau(n), which calculates the number of divisors
of n, sigma(n), which calculates the sum of divisors of n, and isprime(n),
which tests whether or not n is a prime number. We gave HR only the number
1 to start with, but gave it access to the numbers 2 to 30 from which to ﬁnd
counterexamples to false conjectures. Using a complexity limit of 6, we ran a
breadth ﬁrst search to completion using the compose, exists and split produc-
tion rules. We also enabled applicability conjecture making, so that HR could
make applicability conjectures when concepts applied to 2 or fewer objects of
interest. This meant that the disjunct production rule was also used to produce
concepts. We speciﬁed that HR should produce conjectures through equivalence
checking, non-existence checking and subsumption checking. We also speciﬁed
that it should extract implicates from these conjectures and that it should keep
only the implicates. Finally, we speciﬁed that it should use Otter to try to prove
any implicates it produced. After experimentation, we decided not to extract
prime implicates, as this was computationally expensive and mostly fruitless.
The session took around 2 minutes on a Pentium 500Mhz processor, and
lasted for 378 theory formation steps. HR produced 48 concepts. Due to the com-
position of functions, HR called Maple on 120 occasions, to calculate isprime,
tau, and sigma for integers ranging from 1 to 195 (which is the sum of the
divisors of 72). HR also introduced the numbers 2, 3, 4, 5, 6, 9 and 16 as coun-
terexamples to false conjectures. These false conjectures were made in this order,
given with the counterexample HR found to disprove them:
all a b (((tau(a)=b) <-> (sigma(a)=b))) [counterexample = 2]
all a b (((tau(a)=b) <-> (tau(a)=b & tau(b)=a))) [3]
all a b (((sigma(a)=b) <-> (sigma(a)=b & tau(b)=a))) [4]
all a ((isprime(a)) <-> ((a=2 | a=3))) [5]

268
S. Colton
all a ((a=2 | a=4) <-> (isprime(sigma(a)))) [9]
all a b (tau(a)=b <-> tau(a)=b & tau(sigma(b))=b) [6]
all a b (tau(a)=b & isprime(b) -> tau(a)=b & tau(sigma(b))=b) [16]
In the session, HR produced 137 implicate conjectures. Of these, 43 had
already been proven by Otter, including ones which followed from a calculation
on particular integers, such as:
(68) all a ((((a=2 | a=3)) -> (tau((sigma(a)))=a)))
Otter could prove this because HR gave it ground instances such as tau(3)=2
and sigma(2)=3. There were also theorems which didn’t follow from calculations,
but were still obviously true, such as:
(56) all a b (tau(a)=b & sigma(b)=a & isprime(b) -> tau(sigma(b))=b)
Of the 94 conjectures which remained unsolved, we looked through the ﬁrst
10 which were produced and added these 9 as axioms:
(0) all a (((exists b (tau(a)=b))))
(1) all a (((tau(a)=1) -> (a=1)))
(3) all a (((isprime(a)) -> (tau(a)=2)))
(4) all a (((tau(a)=2) -> (isprime(a))))
(5) all a (((exists b (sigma(a)=b))))
(7) all a (((sigma(a)=1) -> (a=1)))
(8) all a b (((tau(a)=b & sigma(a)=b) -> (tau(b)=a)))
(9) all a b (((tau(a)=b & sigma(a)=b) -> (sigma(b)=a)))
(10) all a b (((sigma(a)=b & sigma(b)=a) -> (tau(a)=b)))
Note that conjectures (2) and (6) were proved, hence not in the list of those
unsolved conjectures that HR presented to us. The conjecture we did not add
from the ﬁrst 10 unsolved ones was:
(11) all a b (((tau(a)=b & isprime(a)) -> (isprime(b))))
which we thought might follow from the other axioms, so we left it out. We see
that HR has identiﬁed the deﬁnition of prime numbers in conjectures (3) and
(4): all a (isprime(a) <-> tau(a)=2). We also looked through the unsolved
conjectures which were instantiations, and added these three as axioms:
(15) all a b (sigma(a)=b & sigma(b)=a -> a=1)
(21) all a (tau(tau(a))=a -> (a=1 | a=2))
(135) all a (a=3 -> isprime(sigma(sigma(a))))
Having given HR the additional axioms, we then asked it to attempt to re-prove
all the unsolved conjectures. This was very eﬀective, and reduced the number
of unsolved conjectures from 94 to just 22. We looked at the 17 unsolved con-
jectures which were not instantiations, and ordered these in terms of a measure
of interestingness which was obtained by averaging the normalised applicabil-
ity and normalised surprisingness. At the top of the ordered list was conjecture
number 46, which we found very interesting:
(46) all a (isprime(sigma(a)) -> isprime(tau(a)))

Making Conjectures about Maple Functions
269
Paraphrased, this states that, if you take a number and add up the divisors, with
the result being a prime number, then the coeﬃcient of divisors you have just
added up will also be a prime. We used HR to check this conjecture empirically
for the numbers 1 to 100, and it used Maple to perform the appropriate cal-
culations. The empirical test was positive, so we tried to prove this conjecture,
which we managed, as reported in appendix A. We then added conjecture 46 as
an axiom and asked HR to attempt to prove the remaining unsolved conjectures
in the light of this theorem. This reduced the unsolved non-instantiation conjec-
tures to just the following 10, ordered in terms of the interestingness measure
mentioned above:
(127) all a (tau(tau(a))=a -> tau(sigma(sigma(a)))=sigma(a))
(129) all a (tau(tau(a))=a -> tau(sigma(a))=a)
(130) all a (tau(sigma(a))=a & tau(sigma(sigma(a)))=sigma(a) ->
tau(tau(a))=a)
(64) all a b (sigma(a)=b & isprime(a) & isprime(b) -> tau(sigma(b))=b)
(111) all a b (sigma(a)=b & isprime(sigma(b)) -> isprime(tau(a)))
(90) all a b (sigma(a)=b & isprime(tau(b)) -> isprime(tau(a)))
(128) all a (tau(sigma(sigma(a)))=sigma(a) -> tau(sigma(tau(a)))=tau(a))
(108) all a b (sigma(a)=b & isprime(sigma(b))
-> tau(b)=a)
(47) all a b (sigma(a)=b & isprime(a) & isprime(b) -> tau(b)=a)
(109) all a b (sigma(a)=b & isprime(sigma(b)) -> isprime(a))
We note that conjectures (127) and (129) above should be proved because we
gave HR conjecture (21) as an axiom, which states that, given the left hand side
of conjecture (127) or (129), then a = 1 or a = 2. However, we found that Otter
could not prove either conjecture (with default settings), even when allowed ﬁve
minutes to prove them. This is an anomaly we are currently investigating. We
must also determine the signiﬁcance – if any – of the other results. However,
we feel it is a success that, in such a short session with HR, it managed to
ﬁnd a non-trivial conjecture of enough interest that a generalised theorem (see
appendix A) was found and proved with some diﬃculty. Also, we think that the
pruning using Otter and the user to prove easy theorems worked well. In ﬁgure
3, we show the decrease in the number of unsolved conjectures at various stages
of the session, and we note that the number of unsolved conjectures presented
to the user was reduced from 137 to just 11.
5
Conclusions and Further Work
In the ﬁnal sentence of [4], we state that:
“... if this technology can be embedded into computer algebra systems,
we believe that theory formation programs will one day be important
tools for mathematicians.” (page 361)
The work presented here represents the ﬁrst step towards using automated theory
formation to enable computer algebra systems to intelligently make research

270
S. Colton
0
20
40
60
80
100
120
140
0
1
2
3
4
5
6
7
number of conjectures
pruning stage
Fig. 3. Pruning of conjectures in stages: stage 1 (all the conjectures), stage 2 (after
using Otter to discard trivially true results), stage 3 (after the user chose conjectures to
add as axioms), stage 4 (after another round of proving using the additional axioms),
stage 5 (after pruning instantiation conjectures), stage 6 (after a ﬁnal round of proving
with a single new axiom added).
conjectures about functions the user is experimenting with. It compliments, but
is distinct to, our work datamining the Encyclopedia of Integer Sequences to
ﬁnd conjectures [3,6] which also led to discoveries in number theory.
Other approaches to making research conjectures for mathematicians have
either performed an exhaustive search for theorems using the power of an eﬃ-
cient theorem prover, or have required bespoke programs. For instance, in [14],
McCune uses an exhaustive search with Otter to ﬁnd new axiomatisations of
group theory and other algebras. Similarly, in [2], Chou used the power of Wu’s
method to ﬁnd new constructions in plane geometry. The Graﬃti program [8] has
produced scores of conjectures which the graph theory community have eagerly
proved and disproved, but this is a graph theory speciﬁc program which isn’t
publicly available. To our knowledge, HR is the only program which uses both
computer algebra and theorem proving systems to make research conjectures.
We have shown how the HR theory formation system can be used to make
conjectures about Maple functions chosen by the user. Given HR’s current abil-
ities to form concepts and make conjectures, the main technical diﬃculty to
overcome for this project was to reduce the number uninteresting conjectures
produced. To do this, we used much of HR’s functionality, including:
[1] Its ability to call Otter to prove theorems from ﬁrst principles. Such theo-
rems are likely to be uninteresting, and hence can be discarded. In our example

Making Conjectures about Maple Functions
271
session, this enabled HR to discard 43 such theorems (31% of the 137 implicate
conjectures HR produced in total). For this to be eﬀective in number theory, we
enabled HR to pass ground instances from Maple to Otter.
[2] A new ability, which allows the user to choose some of HR’s conjectures to
add as axioms. Subsequent attempts to prove the unsolved conjectures allows
more pruning of the theorems because they can be proved from ﬁrst principles
and the (usually simple) axioms added by the user. After giving some of HR’s
obviously true theorems to Otter as axioms, this reduced the number of unsolved
conjectures from 94 to just 22, an acceptable number for the user to look through.
[3] The ability to extract simply stated implicates and order conjectures in terms
of measures of interestingness, so that the user can browse the most interesting
conjectures ﬁrst.
The second point above represents a ﬁrst step towards a more interactive
environment for theory development within HR. We hope to pursue such an
interactive mode – similar to that employed by Lenat with his AM program [11] –
by allowing the user to step in and provide new concepts, conjectures, theorems,
proofs and counterexamples at will during the theory formation session. This
will be useful for an extended application to mathematical discovery we have
planned for HR: the exploration of the domain of Zariski spaces developed by Roy
McCasland [12]. Due to the relative complexity of this domain, the interactive
mode in HR will be essential. Also, HR’s links via MathWeb to various pieces
of mathematical software including provers such as Otter, Spass and E, model
generators such as MACE, computer algebra systems such as Maple and Gap,
and constraint solvers such as Solver, will be essential for this project. Our aim
for the HR system is for the theory behind it to encompass more and more
abilities, while the tasks reliant on HR’s code become fewer, as HR interfaces
with more mathematics programs.
The application of HR to ﬁnding conjectures about CAS functions is still
in its early stages. Our choice of which Maple functions to form conjectures
about was inspired by working with these functions in a diﬀerent project [6],
but in general, the user will specify a much larger set of functions. HR must
therefore decide which ones to use, possibly discarding some after an initial
investigation reveals that there are very few interesting properties about which
HR can make conjectures. Furthermore, we need to undertake extended testing of
HR to highlight its strengths and limitations when working with CAS functions.
Finally, we need to improve the integration of HR and Maple, in terms of (i) the
communication between them (i.e., enable HR to write Maple functions so that
Maple, rather than HR, can be used to check conjectures empirically) and (ii)
the way in which that communication is performed (i.e., by enabling HR to talk
to Otter and Maple via the MathWeb software bus).
We hope to have shown here a glimpse of the potential for using HR to
discover interesting facts about computer algebra functions and concepts related
to them. As the most popular pieces of software within pure mathematics are
computer algebra systems, it is essential that HR is able to interact with such

272
S. Colton
programs, and it is a long-term goal of the HR project to embed HR’s discovery
functionality into computer algebra systems.
Acknowledgments. This work is supported by EPSRC grant GR/M98012.
The author is also aﬃliated to the Department of Computer Science at the Uni-
versity of York. This research was inspired by discussions with Jacques Calmet
and Clemens Ballarin during the author’s visit to Karlsruhe University, funded
by the European Union IHP grant CALCULEMUS HPRN-CT-2000-00102. As
with all projects involving HR, the input from Alan Bundy and Toby Walsh
has been essential. We would also like to thank the anonymous referees for their
interesting comments and suggestions about this work.
References
1. B Buchberger.
Theory exploration versus theorem proving.
In Proceedings of
Calculemus 99, Systems for Integrated Computation and Deduction, 1998.
2. S Chou. Proving and discovering geometry theorems using Wu’s method. Technical
Report 49, Computing Science, University of Austin at Texas, 1985.
3. S Colton. Refactorable numbers - a machine invention. Journal of Integer Se-
quences, 2, 1999.
4. S Colton. Automated Theory Formation in Pure Mathematics. PhD thesis, De-
partment of Artiﬁcial Intelligence, University of Edinburgh, 2000.
5. S Colton, A Bundy, and T Walsh. Automatic identiﬁcation of mathematical con-
cepts.
In Machine Learning: Proceedings of the 17th International Conference,
2000.
6. S Colton, A Bundy, and T Walsh. Automatic invention of integer sequences. In
Proceedings of the Seventeenth National Conference on Artiﬁcial Intelligence, 2000.
7. S Colton and I Miguel. Constraint generation via automated theory formation. In
Proceedings of CP-01, 2001.
8. S Fajtlowicz. On conjectures of Graﬃti. Discrete Mathematics 72, 23:113–118,
1988.
9. Andreas Franke and Michael Kohlhase. System description: MathWeb, an agent-
based communication layer for distributed automated theorem proving. In Pro-
ceedings of CADE-16, pages 217–221, 1999.
10. G Hardy and E Wright. The Theory of Numbers. Oxford University Press, 1938.
11. D Lenat.
AM: Discovery in mathematics as heuristic search.
In D Lenat and
R Davis, editors, Knowledge-Based Systems in Artiﬁcial Intelligence. McGraw-Hill
Advanced Computer Science Series, 1982.
12. R McCasland, M Moore, and P Smith. An introduction to Zariski spaces over
Zariski topologies. Rocky Mountain Journal of Mathematics, 28:1357–1369, 1998.
13. W McCune. The OTTER user’s guide. Technical Report ANL/90/9, Argonne
National Laboratories, 1990.
14. W McCune. Single axioms for groups and Abelian groups with various operations.
Journal of Automated Reasoning, 10(1):1–13, 1993.
15. W McCune.
A Davis-Putnam program and its application to ﬁnite ﬁrst-order
model search. Technical Report ANL/MCS-TM-194, Argonne National Laborato-
ries, 1994.
16. D. Redfern. The Maple Handbook: Maple V Release 5. Springer Verlag, 1999.

Making Conjectures about Maple Functions
273
17. J Zimmer, A Franke, S Colton, and G Sutcliﬀe. Integrating HR and tptp2x into
MathWeb to compare automated theorem provers. Technical report, Division of
Informatics, University of Edinburgh, 2001.
A. Proof That isprime(sigma(n)) →isprime(tau(n))
Lemma
For all n, τ(n) is prime
⇐⇒n = pq−1 for primes p and q.
Proof
If n = pq−1 then τ(n) = q, hence τ(n) is prime. Conversely, suppose that the
prime factorisation of n is pk1
1 . . . pkl
l , and that τ(n) is prime. Now τ(n) = (k1 +
1) . . . (kl + 1), hence l = 1, and n must be of the form pa for some a. So,
τ(pa) = a + 1, and a must be one less than a prime, q.
Lemma 2
If the prime factorisation of integer n is: n = l
i=1 pki
i , then
σm(n) =
l
i=1

pm(ki+1)
i
−1
pi −1

.
(Where σm(n) is the sum of the mth powers of the divisors of n). For the proof of
this result, see thm. 274 of [10]. We also need the following well known identity:
ab −1
a −1 = 1 + a2 + . . . + ab−1 =
b−1

i=0
ai.
Theorem
∀m, n ∈N,
τ(σm(n)) = 2 ⇒τ(τ(n)) = 2.
Proof
Let the prime factorisation of n be pk1
1 . . . pkl
l , and let m be an integer. Suppose
also that τ(σm(n)) = 2, i.e. that σm(n) is prime. We see from lemma 2 that σm(n)
has at least l+1 factors (counting 1 as well). Therefore, as σm(n) is prime, l = 1.
Hence we can write n = pa for some prime p and some a ∈N. If we assume
that τ(n) is composite, then τ(n) = a + 1 = xy for some x, y ∈N, x > 1, y > 1.
Hence a = xy −1. So, using lemma 2 again:
σm(n) = pm(a+1) −1
p −1
= pm(xy−1+1) −1
p −1
= pmxy −1
p −1
= (pmx −1)(p(y−1)mx + p(y−2)mx + . . . + pmx + 1)
p −1
= pmx −1
p −1
y

i=1
p(y−i)mx =
mx−1

i=0
pi

·


y

j=1
p(y−j)mx



274
S. Colton
As x > 1 and y > 1, neither of the factors in this ﬁnal product equal 1. Hence,
this provides a contradiction, because σm(n) is prime. Hence our assumption
that τ(n) is composite must be false, and we see that τ(n) is a prime. ✷
Corollary
Taking m = 1 above, we see that: ∀n ∈N,
τ(σ(n)) = 2 ⇒τ(τ(n)) = 2, i.e, if
the sum of divisors of n is prime, then the number of divisors of n will be prime.

Employing Theory Formation to Guide Proof
Planning
Andreas Meier1, Volker Sorge2, and Simon Colton3⋆
1 Fachbereich Informatik, Universit¨at des Saarlandes, Germany,
ameier@ags.uni-sb.de, http://www.ags.uni-sb.de/˜ameier
2 School of Computer Science, University of Birmingham, UK,
V.Sorge@cs.bham.ac.uk, http://www.cs.bham.ac.uk/˜vxs,
3 Division of Informatics, University of Edinburgh, UK,
simonco@dai.ed.ac.uk, http://www.dai.ed.ac.uk/˜simonco
Abstract. The invention of suitable concepts to characterise mathe-
matical structures is one of the most challenging tasks for both human
mathematicians and automated theorem provers alike. We present an
approach where automatic concept formation is used to guide non-iso-
morphism proofs in the residue class domain. The main idea behind the
proof is to automatically identify discriminants for two given structures
to show that they are not isomorphic. Suitable discriminants are gen-
erated by a theory formation system; the overall proof is constructed
by a proof planner with the additional support of traditional automated
theorem provers and a computer algebra system.
1
Introduction
In [10] and [11] we present a case study concerned with the automatic classiﬁ-
cation of residue class sets over the integers into sets of isomorphic structures.
The residue class sets have given binary operations and our approach is to prove
that two given structures are isomorphic or not in terms of their basic alge-
braic properties. The necessary proofs are constructed with the Multi proof
planner [13], which forms part of the Ωmega theorem proving environment [1].
Multi uses the guidance of computer algebra and model generation. Particu-
larly hard problems arising in the domain are non-isomorphism proofs, i.e. to
show that two given structures are non-isomorphic, since a na¨ıve proof attempt
with an exhaustive case analysis is infeasible in most cases. A better approach is
to ﬁnd an invariant of the residue class sets (a property which does not change
under isomorphism) and show that it diﬀers for a particular pair of residue class
sets. We say that the particular invariant found for two structures acts as a dis-
criminant for the structures if it has a diﬀerent value for each. Unfortunately,
employing a small set of predeﬁned invariants cannot necessarily deal with all
cases which might occur.
⋆The author’s work is supported by EPSRC grant GR/M98012 and European Union
IHP grant CALCULEMUS HPRN-CT-2000-00102. He is also aﬃliated with the
Department of Computer Science at the University of York.
J. Calmet et al. (Eds.): AISC-Calculemus 2002, LNAI 2385, pp. 275–289, 2002.
c
⃝Springer-Verlag Berlin Heidelberg 2002

276
A. Meier, V. Sorge, and S. Colton
In this paper we overcome this dilemma by using the HR automatic theory
formation system [3] to automatically detect discriminants for given structures.
We then model the discriminants into appropriate concepts and the overall proof
is constructed by Multi with the support of traditional automated theorem
provers and a computer algebra system.
The paper is structured as follows: in section 2 we introduce the problem do-
main and motivate the use of automatic concept formation for non-isomorphism
proofs. Section 3 gives a brief overview of the various systems we employ to
construct non-isomorphism proofs. Section 4 gives a detailed account of how the
proofs are constructed and we present some preliminary results in section 5.
2
Proving Non-isomorphism Problems
In this section we ﬁrst brieﬂy introduce the problem domain of residue class
structures and the proof techniques we have already developed for non-isomor-
phism proofs as described in [10,11]. Following this, we generalise one of these
proof techniques to a new proof scheme which enables the construction of arbi-
trary discriminants for two algebraic structures that suﬃce to demonstrate that
the structures involved are not isomorphic.
2.1
The Residue Class Domain
We deﬁne a residue class set over the integers as the set of all congruence classes
modulo an integer n, i.e., Zn, or as an arbitrary subset of Zn. More concretely,
we are dealing with sets of the form Z3, Z5, Z3\{¯13}, Z5\{¯05}, {¯16, ¯36, ¯56}, etc.
where ¯16 denotes the congruence class of 1 modulo 6. If c is an integer we also
write cln(c) for the congruence class of c modulo n. A binary operation ◦on a
residue class set is given in λ-function notation, and ◦can be of the form λxy x,
λxy y, λxy c where c is a constant congruence class (e.g., ¯13), λxy x¯+y, λxy x¯∗y,
λxy x¯−y, where ¯+, ¯∗, ¯−denote addition, multiplication, and subtraction of
congruence classes over the integers, respectively. Furthermore, ◦can be any
combination of the basic operations with respect to a common modulo factor,
e.g., λxy (x¯+¯13)¯−(y ¯+¯23). We often abbreviate the operations λxy x¯+y, λxy x¯∗y
and λxy x¯−y by ¯+, ¯∗and ¯−, respectively.
For two given structures (RS1
n, ◦1) and (RS2
m, ◦2) we examine whether or not
they are isomorphic; that is, we determine whether or not there is a function
h:(RS1
n, ◦1) →(RS2
m, ◦2) such that h is injective, surjective, and homomorphic.1
For proof planning both isomorphism and non-isomorphism proofs, the appro-
priate guidance for the proof planner is crucial for success. In cases where two
structures are isomorphic, it is usually fairly simple to compute an appropriate
mapping h with either a computer algebra system or a model generator, and
subsequently show that h is indeed an isomorphism. However, when the struc-
tures are not isomorphic, it is much more diﬃcult to appropriately guide the
necessary non-isomorphism proof.
1 Observe that we avoid confusion between indices and modulo factors by writing
indices as superscripts, except in indexed variables such as xi, yj as they are clearly
distinct from congruence classes of the form cli(x).

Employing Theory Formation to Guide Proof Planning
277
2.2
Techniques for Non-isomorphism Proofs
In our previous work [10,11], we have implemented several proof techniques for
the proof planner Multi to show that two structures are not isomorphic. These
require varying degrees of guidance from computer algebra or model generation:
Testing all possible functions h. Essentially this corresponds to a case split
on all possible instantiations for the mapping h and showing in each case that h
is not an isomorphism. While this technique does not require any guidance for
Multi, for two structures whose sets have cardinality n, Multi has to consider
nn possible functions, which becomes infeasible even for relatively small n.
Proof by contradiction. The idea of this technique is to ﬁnd a pair of dis-
tinct elements in one structure that is always mapped to the same image under
each homomorphism h. This shows that there exists no injective h and there-
fore no isomorphism. For this technique, a prospective pair of elements can be
computed either with the computer algebra system Maple [16] or, more reli-
ably, with the Sem model generator [17]. However, even with this guidance, the
subsequent proof process is essentially equational theorem proving, and success
is not guaranteed.
Using predeﬁned invariants. An intuitive way to show non-isomorphism is
to ﬁnd an invariant property of one structure that the other structure does not
exhibit. We have already implemented a proof planning approach for the follow-
ing predeﬁned invariants: (1) the structures involved are of diﬀerent cardinality;
(2) the structures form diﬀerent algebraic entities; e.g., one structure is a group
while the other is a semigroup; (3) one of the structures contains an element of
some order k and no element in the other structure has order k. For structures
without a unit element, we can similarly use the order of traces of elements.
Multi checks these invariants in this order. To compute both orders and traces
of elements, Multi uses the computer algebra system Gap [8]. In the automatic
exploration of the residue class domain (see [11]) we usually start with sets of
similar algebraic structures of the same cardinality (e.g., quasigroups of order
5). Hence invariant (3) is the only one of relevance, and the predeﬁned criteria
are often not suﬃcient to successfully construct a non-isomorphism proof.
2.3
Systematically Constructing Discriminants
The new proof technique we describe in this paper aims to be a more reliable
proof strategy for non-isomorphism proofs. It is essentially a generalisation of
the technique presented in section 2.2. Given two structures, we construct an
appropriate, bespoke discriminant (i.e., an invariant property that only one of
the structures exhibits) to show that the structures are not isomorphic. More
formally, for two structures S1 and S2 we want to ﬁnd a property P such that
P(S1) ∧¬P(S2) holds2.
For example, consider the pairwise non-isomorphic quasigroups S1, S2, S3
given with their respective multiplication tables in Fig. 1. When comparing the
2 In the remainder of the paper we often use a pair (Set, Op) consisting of a set Set
and a binary operation Op to describe a structure S.

278
A. Meier, V. Sorge, and S. Colton
S1 = (Z5, ¯−)
S2 = (Z5, λxy (¯25¯∗x)¯+y)
S3 = (Z5, λxy (¯35¯∗x)¯+y)
S1 ¯05 ¯15 ¯25 ¯35 ¯45
¯05 ¯05 ¯45 ¯35 ¯25 ¯15
¯15 ¯15 ¯05 ¯45 ¯35 ¯25
¯25 ¯25 ¯15 ¯05 ¯45 ¯35
¯35 ¯35 ¯25 ¯15 ¯05 ¯45
¯45 ¯45 ¯35 ¯25 ¯15 ¯05
S2 ¯05 ¯15 ¯25 ¯35 ¯45
¯05 ¯05 ¯15 ¯25 ¯35 ¯45
¯15 ¯25 ¯35 ¯45 ¯05 ¯15
¯25 ¯45 ¯05 ¯15 ¯25 ¯35
¯35 ¯15 ¯25 ¯35 ¯45 ¯05
¯45 ¯35 ¯45 ¯05 ¯15 ¯25
S3 ¯05 ¯15 ¯25 ¯35 ¯45
¯05 ¯05 ¯15 ¯25 ¯35 ¯45
¯15 ¯35 ¯45 ¯05 ¯15 ¯25
¯25 ¯15 ¯25 ¯35 ¯45 ¯05
¯35 ¯45 ¯05 ¯15 ¯25 ¯35
¯45 ¯25 ¯35 ¯45 ¯05 ¯15
Fig. 1. Some quasigroup multiplication tables
tables of S1 and S2, one discriminant is fairly obvious: while S1 has only ¯05 on
the main diagonal, all elements on the main diagonal of S2 are distinct. Thus,
the invariant property we can use is ∃x ∀y x = y ◦y. Things become less obvious
when we compare the multiplication tables of S2 and S3. Here, one invariant of
S3, which does not hold for S2, is ∀x ∀y (x ◦x = y) ⇒(y ◦y = x),.
The generalised proof procedure is as follows: given two structures S1 and
S2 we have to:
1. ﬁnd an appropriate discriminant P,
2. show that P(S1) holds,
3. show that ¬P(S2) holds, and ﬁnally
4. show that ∀X ∀Y P(X) ∧¬P(Y ) ⇒X ̸∼Y holds 3.
The single proof parts combine to give the following, sketched formal proof:
?.... (2)
P(S1)
?.... (3)
¬P(S2)
P(S1) ∧¬P(S2) ∧Intro
?.... (4)
∀X ∀Y P(X) ∧¬P(Y ) ⇒X ̸∼Y
P(S1) ∧¬P(S2) ⇒S1 ̸∼S2
∀Elim(S1, S2)
S1 ̸∼S2
ModusPonens
In the following section, we describe how we realize this proof technique with a
combination of Multi and several other heterogenous systems. As we observed
in the example, discriminants are not necessarily obvious and can have fairly
complicated deﬁnitions. Thus, our realization of this technique aims to auto-
matically generate discriminants for an arbitrary pair of structures and provide
them to Multi.
3
The Systems Involved
The proof technique described at the end of the previous section is realized in
Ωmega’s proof planner Multi. Given two residue class structures (RS1
n, ◦1) and
3 While step 4 is fairly obvious for a human mathematician, it is crucial for a formal
proof.

Employing Theory Formation to Guide Proof Planning
279
(RS2
m, ◦2) its task is to show (RS1
n, ◦1) ̸∼(RS2
m, ◦2) by coordinating the steps 1
to 4 above. To compute a suitable discriminant P, we employ HR [3], a system
for theory formation. To obtain a formal proof that P is a discriminant for two
arbitrary structures X and Y (i.e., step 4) we use ﬁrst-order automated theorem
provers (ATPs), which we call via Tramp [9], an interface and transformation
system. The proofs that P is a discriminant for the two residue class structures
(i.e., that P(RS1
n, ◦1) and ¬P(RS2
m, ◦2) holds) are done by Multi itself possibly
with the help of the general purpose computer algebra system Maple. In this
section, we give a short overview of the diﬀerent systems involved and explain in
more detail how the proof planner integrates and coordinates the computations
of these systems to assemble an overall proof.
3.1
The HR System
The HR system performs automated theory formation by inventing concepts,
making conjectures, proving theorems, and ﬁnding counterexamples [3]. The
main functionality used for the application to ﬁnding discriminants discussed
here is concept formation, which is achieved by using production rules which
take one (or two) old concepts as input and output a new concept. In particular,
we used the following four production rules:
– Compose: this composes functions using conjugation.
– Match: this equates variables in predicate deﬁnitions.
– Forall: this introduces existential quantiﬁcation.
– Exists: this introduces universal quantiﬁcation.
[a, b, c, d] : b*c=d
[a, b, c] : b*b=c
match
[a, b] : (all c ((c*c=b)))
forall
[a, b] : b in a
forall
[a] : (exists b ((all c ((c*c=b)))))
exists
Fig. 2. Example construction
As an example construction which is fur-
ther discussed later, consider the concept of
there being a single element on the diagonal
of the multiplication table of an algebra, as
is the case for S1 in Fig. 1. This concept is
constructed by HR using the match, forall
and exists production rules, as depicted in
Fig. 2. In this scenario, two concepts are sup-
plied by the user, namely the concept of an
element of the algebra and the multiplication
of two elements to give a third. Using the
match production rule with the multiplica-
tion concept, it invents the notion of mul-
tiplying an element by itself. By using this
in the forall production rule, it invents the
concept of elements which all other elements
multiply by themselves to give. Then, using
the exists production rule, HR invents the
notion of algebras where there is such an element. As we shall see in section 4,
this concept can be used to discriminate between the non-Abelian quasigroups
in Fig. 1. For more details of how HR forms concepts, see [6].

280
A. Meier, V. Sorge, and S. Colton
There are many parameters that users can experiment with in order to get
the best performance out of HR for a particular application. For instance, the
user can tell HR to ignore concept formation steps if the arity of the function
produced will be greater than a certain limit. HR can tell in advance what arity
the function will be for a particular concept formation step involving a particular
production rule, and the user can specify a limit for individual production rules.
3.2
Calling Automated Theorem Provers via Tramp
Calls to ATPs are not directly executed but rerouted via the Tramp system.
Tramp comprises two functionalities: ﬁrstly, it is an interface to several ATPs
for ﬁrst-order logic. For a given problem, it produces input in the formats of
the connected systems and runs the systems concurrently. Secondly, Tramp can
transform the output of the ATPs into natural deduction (ND) proofs.
Tramp currently interfaces a variety of ﬁrst order ATPs and term rewriting
systems. For our problems, Tramp employs Otter, Bliksem, and Spass. All
three systems are based on the resolution principle and can deal with ﬁrst-order
logic problems with equality. In our scenario, it is necessary that the provers
can deal with equality, since the discriminant properties found by HR usually
contain equations (see the examples discussed in section 4.1).
3.3
The Multiple-Strategies Proof Planner Multi
Proof planning [2] considers mathematical theorems as planning problems where
an initial partial plan is composed of the proof assumptions and the theorem as
an open goal. A proof plan is then constructed with the help of abstract planning
steps, called methods, that are essentially partial speciﬁcations of tactics known
from tactical theorem proving. In order to ensure correctness, proof plans have
to be executed to generate a sound calculus level proof.
In the Ωmega system, the traditional proof planning approach is enriched
by incorporating mathematical knowledge into the planning process (see [14] for
details). That is, methods can encode general proving steps as well as knowledge
particular to a mathematical domain. Moreover, control rules provide the pos-
sibility of introducing mathematical knowledge on how to proceed in the proof
planning process by specifying how to traverse the search space. Depending on
the mathematical domain or proof situation, they can inﬂuence the planner’s
behaviour at choice points (e.g., which goal to tackle next or which method to
apply next).
Ωmega’s proof planner Multi additionally provides a strategic level that ex-
tends proof planning. For instance, diﬀerent planning strategies can implement
diﬀerent proof techniques by specifying particular sets of methods and control
rules. Thus they enable the same problem to be tackled in diﬀerent ways. More-
over, diﬀerent strategies for backtracking and other facilities for reﬁning or mod-
ifying proof plans can be speciﬁed. When more than one strategy is applicable
to a problem, Multi can reason about which strategy to employ and switch
strategies during a proof attempt. In particular, the planner can backtrack from
applied strategies and thus perform search on the level of strategies.

Employing Theory Formation to Guide Proof Planning
281
3.4
Incorporating HR and Tramp
One way to incorporate speciﬁc knowledge into the planning process is by ex-
ploiting knowledge implicitly given in specialised external systems. Multi sup-
ports the access of external systems in methods, control rules, and strategies.
In general, computations from external systems can be treated in two ways: as
hints or as proof steps. The diﬀerence is that the soundness of hints is checked
by the subsequent proof planning process, which either fails or succeeds for the
given hint. On the other hand, to guarantee the soundness of proof steps, special
procedures have to be provided which transform the output of external systems
into subproofs that Ωmega can check.
In our scenario, we have both: the concepts provided by HR are hints and
the output of ATPs are proof steps where we employ Tramp as a correspond-
ing transformation module. Multi employs HR in a control rule4. When HR
succeeds in providing a discriminant P for the problem at hand, the control rule
triggers the introduction of this P into the proof plan. Note that Multi can
backtrack on diﬀerent instantiations of P.
The interface to Tramp is realized in the method CallTrampM. When Multi
applies this method to an open goal, a problem consisting of the formula of the
goal and the formulas of the proof assumptions is passed to Tramp. The method
is applicable only if one of the provers interfaced by Tramp succeeds to prove
the problem. Then the goal is simply closed by CallTrampM without producing
further subgoals. Thus at the method level, the proof of this goal is just one
step. However, when the correctness of this method application is checked, its
expansion results in the ND proof that Tramp provides as output.
4
Constructing the Proofs
In this section, we describe the whole proof process and the contributions of the
individual systems involved in more detail. We illustrate the procedure with the
proof that (Z5, ¯−) ̸∼(Z5, λxy ¯25¯∗x¯+y) as an example.
The proof procedure is realized with a Multi proof planning strategy. Among
other planning methods, the strategy also contains methods to invoke Tramp on
an appropriately prepared subproblem and a control rule to inject results from
HR. When the strategy is applied to a goal of the form (Set1, Op1) ̸∼(Set2, Op2)
Multi splits this goal into three subgoals of the form:
1. P(Set1, Op1)
2. ¬P(Set2, Op2)
3. ∀Set1, Op1, Set2, Op2 P(Set1, Op1) ∧¬P(Set2, Op2)
⇒[(Set1, Op1) ̸∼(Set2, Op2)]
Here P is a newly introduced meta-variable (i.e., a placeholder that has to be
replaced with some concrete term later in the proof) for the discriminant. Next,
4 Note that the interface between Multi and HR is currently not automated. That
is, the control rule currently allows the user to supply HR’s results. However, we
intend to make the interface completely automatic.

282
A. Meier, V. Sorge, and S. Colton
Multi receives a suitable discriminant P from HR via the afore-mentioned
control rule in order to replace the meta-variable P.
For our example, the discriminant5 property that HR provides is:
λSet λOp ∃x:Set ∀y:Set x = Op(y, y).
The concrete instantiated subgoals are therefore of the form:
1. ∃x:Z5 ∀y:Z5 x = y ¯−y
2. ¬∃x:Z5 ∀y:Z5 x = ¯25¯∗y ¯+y
3. ∀Set1, Op1, Set2, Op2
[∃x:Set1 ∀y:Set1 x = Op1(y, y)] ∧¬[∃x:Set2 ∀y:Set2 x = Op2(y, y)]
⇒[(Set1, Op1) ̸∼(Set2, Op2)]
Subgoals (1) and (2) are subsequently proved by other Multi strategies possibly
using the computations of the computer algebra system Maple. Subgoal (3) is
solved with an ATP via Tramp. In the remainder of this section, we describe
the interesting parts of these subproofs in more detail. However, we ﬁrst explain
how we obtain discriminants from HR that are actually useful in our context.
4.1
Obtaining Useful Discriminants from HR
In our scenario, HR needs only to be supplied with the multiplication tables of
the example algebras for which it is to ﬁnd a discriminant, and to be invoked with
a ﬂag stating that they are indeed algebraic multiplication tables. Not all possible
discriminants are appropriate for our problem. Multi needs discriminants that
are concerned with relations between elements of the sets involved, in particular,
existentially or universally quantiﬁed statements. For instance, discriminants
that involve natural numbers, (e.g., if two structures contain a diﬀerent number
of elements satisfying a certain property) are generally too diﬃcult to handle
both for the proof planner and the ATPs. Thus, some of HR’s production rules
are not appropriate for our application, so they are turned oﬀ. In particular, the
size production rule that calculates cardinalities of sets – which has been used to
ﬁnd group theory invariants in a diﬀerent context (see [7] and chapter 12 of [3])
– is not used. We choose only the compose, exists, forall, and match production
rules discussed in section 3.1, since they guarantee that only discriminants which
are usable in the rest of the proof procedure are found.
HR is run for a given number of concept formation steps and told to out-
put those concepts which both specialise the algebras (e.g., Abelian) and dis-
criminate between the two multiplication tables supplied. The output is then
transformed into suitable concepts for Multi. Currently, the interface between
Multi and HR is not automated. Thus, the discriminants are manually ordered
and provided to the control rule that establishes the interface between Multi
and Tramp. We are currently implementing an automatic interface. The dis-
criminants will then be ordered with respect to their complexity, so that Multi
chooses the least complex ﬁrst, thereby increasing the chances of success during
the subsequent proof planning process and the application of the ATPs.
5 A sorted quantiﬁcation with a variable x:Set states that the variable x ranges over
the set Set, only.

Employing Theory Formation to Guide Proof Planning
283
For our example from Fig. 1, some of the discriminants HR discovered are:
– ∃x ∀y x = y◦y [There is a single element on the diagonal of the multiplication
table (true for S1, not true for S2 and S3).]
– ∀x, y (x ◦x = y ⇒y ◦y = x) [There is a symmetry on the diagonal, (true
for S1 and S3, not true for S2).]
– ∀x, y (x ◦y = x ⇒y ◦x = y) [If y is a right identity for x, then x is a right
identity for y (true for S1, not true for S2 and S3).]
Here ◦stands for the binary operation of the respective structures Si. When HR
passes the properties to Multi, they are transformed into a lambda abstraction
that can be directly inserted for the meta-variable. For the ﬁrst of the above
discriminants, this results in the term λSet λOp ∃x:Set ∀y:Set x = Op(y, y),
where the quantiﬁed variables are restricted to range over the given set Set,
only.
4.2
Subproofs with ATPs
The goal we want to prove with an ATP is generally of the form
∀Set1, Op1, Set2, Op2 P(Set1, Op1) ∧¬P(Set2, Op2)
⇒[(Set1, Op1) ̸∼(Set2, Op2)]
and contains the deﬁned concept of isomorphism. Providing the usual deﬁnition
of isomorphism to an ATP was often unsuccessful; that is, the ATPs did not
ﬁnd a proof. Instead the following alternative formalisation is better suited: two
structures X and Y are isomorphic iﬀthere are two homomorphisms h:X →Y
and j:Y →X, such that for all x, h(j(x)) = x and j(h(x)) = x.
In order to send the problem with the above deﬁnition of isomorphism to the
ATPs, the original subproblem has to be adequately rewritten. Therefore, Multi
applies an appropriate theorem from Ωmega’s knowledge base which results in
the following new subgoal to be proved:
∀Set1, Op1, Set2, Op2 P(Set1, Op1) ∧¬P(Set2, Op2) ⇒
¬(∃h ∃j hom(h:(Set1, Op1) →(Set2, Op2))∧hom(j:(Set2, Op2) →(Set1, Op1))
∧(∀x : Set1 j(h(x)) = x ∧∀y : Set2 h(j(y)) = y))
After the expansion of the occurrences of the concept hom with the usual deﬁ-
nition of homomorphism, the goal can be sent to an ATP.
When trying to close the above subgoal Multi applies the method Call-
TrampM. It is applicable when one of the ATPs interfaced by Tramp succeeds
in ﬁnding a proof. Tramp then returns the corresponding ND proof. The for-
mula passed to Tramp seems to be a higher-order theorem since it contains
quantiﬁcations on sets, operations, and the functions h and j. However, when
Tramp calls the connected ATPs it ﬁrst creates a clause normal form of the
given theorem and thereby all the higher-order variables become constants (the
theorem is negated for clause normalisation). Tramp does not use any particular
settings for the ATPs but calls them all in their default mode.
On the planning level, the subgoal is simply closed by the application of
CallTrampM. When the plan is executed, the ND proof provided by Tramp
is the expansion of the CallTrampM step. Although Tramp has the ability to

284
A. Meier, V. Sorge, and S. Colton
translate refutation proofs into direct ND proofs for our domain the proofs are
nevertheless indirect since the indirect argument is an inherent part of the prob-
lem. Moreover, in our domain, Tramp’s proofs suﬀer from the fact that they
are low level and can become quite lengthy. For our example, Tramp produces
ND proofs containing between 71 (ND proof transformed from Spass proof)
and 104 steps (from Bliksem proof). Thus, the expanded subproofs are usually
relatively diﬃcult to understand for the user. Nevertheless, Tramp provides a
proof format that Ωmega can directly check.
4.3
Subproofs with Multi
In the remainder of the proof, we have to prove the two goals P(Set1, Op1) and
¬P(Set2, Op2), where P is the instantiated discriminant. This part is proved
by Multi using one of two proof planning strategies that have already been
implemented to prove simple properties of residue class structures such as asso-
ciativity, existence of unit elements etc. (see [12] for details).
The ﬁrst strategy implements an exhaustive case analysis. This is possible
since in our problems all quantiﬁers range over ﬁnite sets. The strategy proceeds
with the case analysis in two diﬀerent ways, depending on whether (1) a universal
or (2) an existential statement has to be proved. In case (1) a split over all the
elements in the set involved is performed and the statement in question is proved
for every single element separately. In case (2) the single elements of the set
involved are examined stepwise until one is found for which the statement holds.
The idea of the second strategy is to use equational reasoning as much as
possible to prove properties of residue classes. Instead of checking the validity
of the statements for all possible cases, it tries to reduce goals to equations.
Then these equations are passed to the computer algebra system Maple to
check whether the equality actually holds. If an equation contains meta-variables,
these are considered as the variables the equation is to be solved for, and they
are supplied to Maple as additional arguments.
Multi always tries to apply the equational reasoning strategy ﬁrst since it is
generally faster and produces shorter proofs. If it fails (e.g., if a goal cannot be
reduced to equations), an exhaustive case analysis is used, which is applicable
to all occurring problems.
In our example, the goals to prove are:
∃x:Z5 ∀y:Z5 x = y ¯−y and ¬∃x:Z5 ∀y:Z5 x = ¯25¯∗y ¯+y
The latter goal can only be proved with exhaustive case analysis. Multi ﬁrst
rewrites the goal by pushing the negation inside: ∀x:Z5 ∃y:Z5 x ̸= ¯25¯∗y ¯+y. Then
a case split on the universally quantiﬁed variable x over its range {¯05,¯15,¯25,¯35,¯45}
is performed. This results in one goal for each of the ﬁve elements of the domain.
For instance, the resulting goal for ¯05 is ∃y:Z5 ¯05 ̸= ¯25¯∗y ¯+y. To prove this goal,
Multi tries to ﬁnd a suitable instantiation for y from the set {¯05, ¯15, ¯25, ¯35, ¯45}
by inserting each possible instantiation for y in succession and attempting to
prove the resulting inequality. In our example, it succeeds for ¯15.

Employing Theory Formation to Guide Proof Planning
285
Table 1. Proportion of pairs of algebras for which HR found discriminants
Algebra Size Pairs Successes Proportion
Abelian Quasigroups
5
3
3
100.0%
Non-Abelian Quasigroups
5
91
90
98.9%
Non-Abelian Semigroups
5
3
3
100.0%
Abelian Magmas
5
14
13
92.8%
Non-Abelian Magmas
5
630
609
96.7%
Non-Abelian Quasigroups
6
1
1
100.0%
Abelian Semigroups
6
6
6
100.0%
Non-Abelian Semigroups
6
28
25
89.3%
Non-Abelian Quasigroups 10
21
21
100.0%
Abelian Semigroups 10
1
1
100.0%
Non-Abelian Semigroups 10
1
1
100.0%
Abelian Magmas 10
15
15
100.0%
Non-Abelian Magmas 10
3
3
100.0%
Total
817
791
96.8%
The second subgoal, ∃x:Z5 ∀y:Z5 x = y ¯−y, can be proved by the equational
reasoning strategy. Thereby, Multi ﬁrst decomposes the quantiﬁers which re-
sults in the goal cl5(z) = cl5(c)¯−cl5(c) where z is a new meta-variable and c
is a new constant. Since this goal is a statement on congruence classes, it is
transformed into the corresponding goal on integers: z mod 5 = (c −c) mod 5,
and passed to Maple. Maple applies its function msolve to compute that the
equation holds in general for z = 0. This result is used as instantiation for z in
the proof plan and the goal is closed.
5
Results
To test HR’s eﬀectiveness at ﬁnding discriminants for arbitrary pairs of algebraic
objects, we used 817 pairs over 6 diﬀerent algebras (of sizes 5, 6, and 10). For each
pair, HR was allowed 500 concept formation steps in order to ﬁnd discriminants.
We allowed HR to use the four production rules previously mentioned, and after
some experimentation, we chose the following function arity limits: compose(3),
exists(1), forall(2) and match(3). The average session took around 22 seconds on
a 500Mhz pentium machine. The results are given in table 1. We note that HR
found discriminants for nearly 97% of the pairs given to it, which was a higher
success rate than we anticipated given the short session lengths we allowed for
these tests. On average, HR found 20 discriminants for each pair, and in total,
517 distinct concepts were used as discriminants.
In the sets of discriminants HR constructed, there were usually some of a
complexity similar to those discriminants discussed in section 4.1. In fact, one of
the most complex discriminants HR found was for the two non-Abelian magmas
M 1 and M 2 given in Fig. 3. HR constructed only two discriminants for M 1 and
M 2, including: ∃x (x◦x = x∧∀y (y ◦y = x ⇒y ◦y = y)). This states that there
exists an idempotent element, x, such that any other element which squares to

286
A. Meier, V. Sorge, and S. Colton
M 1 = (Z5, λxy (x¯−¯15)¯∗(y¯∗¯25))
M 2 = (Z5, λxy (x¯+¯15)¯∗(y¯∗¯25))
M 1 ¯05 ¯15 ¯25 ¯35 ¯45
¯05 ¯05 ¯35 ¯15 ¯45 ¯25
¯15 ¯05 ¯05 ¯05 ¯05 ¯05
¯25 ¯05 ¯25 ¯45 ¯15 ¯35
¯35 ¯05 ¯45 ¯35 ¯25 ¯15
¯45 ¯05 ¯15 ¯25 ¯35 ¯45
M 2 ¯05 ¯15 ¯25 ¯35 ¯45
¯05 ¯05 ¯25 ¯45 ¯15 ¯35
¯15 ¯05 ¯45 ¯35 ¯25 ¯15
¯25 ¯05 ¯15 ¯25 ¯35 ¯45
¯35 ¯05 ¯35 ¯15 ¯45 ¯25
¯45 ¯05 ¯05 ¯05 ¯05 ¯05
Fig. 3. The multiplication tables of two non-Abelian magmas.
give x is itself idempotent. After some thought, it is obvious that this means that
there must be an idempotent element which appears only once on the diagonal.
Such an element exists in M 2 (the element is ¯25), but not in M 1.
The relative simplicity of the discriminants facilitates the subsequent proofs
of Multi and the ATPs. In particular, for the latter, it is usually hard to pre-
dict whether or not they will succeed for a given discriminant. Here, a large
set of diﬀerent discriminants can increase the chance of success, since Multi
can backtrack if the ATPs cannot come up with a proof for one discriminant
and instantiate another one. So far, we have tested the planning and ATP side
with roughly 100 examples for which HR found discriminants. All tested exam-
ples were successfully proved. Among the ATPs, Spass and Bliksem performed
best on our problems. In particular, we also proved the example of the two
non-Abelian magmas with the discriminant given above. The resulting proof
plan consists of 154 steps. The ATP part was proved by Bliksem, which was
transformed by Tramp into an ND proof containing 112 steps.
A comparison of attempts to solve problems with structures using Z5 or Z6
as opposed to structures using Z10 shows that the incorporated systems depend
on the cardinality of the involved residue class structures to diﬀerent degrees. In
our experiments, HR’s performance did not vary signiﬁcantly when applied to
problems with Z5 or Z10. That is, HR solved 100% of the problems of size 10 (see
Table 1), but more importantly, it took roughly the same time to provide the
solutions. This is because, in this application, HR works with only two structures
at a time, which is a much smaller amount of data than it usually works with,
so the diﬀerence between size 5 and 10 algebras was minimal.
The ATPs were also not aﬀected by the cardinality of the involved struc-
tures simply because the subproblem they are responsible for does not contain
the residue class structures. The complexity of the problem part for the ATPs
depends only on the complexity of the discriminants provided by HR. However,
in our experiments, we found that the complexity of HR’s discriminants does
not depend on the cardinality of the involved residue class structures.
Unlike HR and the ATPs, Multi’s performance depends on both the car-
dinality of the residue class sets, and the strategy applied. When performing
equational reasoning, Multi solves a subproblem with set Z5 in the same num-
ber of steps as the same subproblem with set Z10. On the other hand, Multi’s

Employing Theory Formation to Guide Proof Planning
287
performance considerably diﬀers when it applies the exhaustive case analysis
strategy. A subproblem with l nested quantiﬁcations for Z5 results in 5l cases,
whereas for Z10, it results in 10l cases. Although Multi prefers the application of
the equational reasoning, it is never the case that both of Multi’s subproblems,
P(Set1, Op1) and ¬P(Set2, Op2), are solvable by this strategy.
6
A Comparison with a Diﬀerent Approach
We have also experimented with the model generator Sem [17] to construct
discriminants. Here, properties are created in Ωmega and Sem tests whether
each property is a discriminant. That is, Sem ﬁnds models for each of the two
involved structures with respect to the created property. A property is a can-
didate for a discriminant if Sem succeeds for one structure and fails for the
other one. The possible properties are constructed as follows. The basic con-
struction element is the equation x = Op(y, z). Associated with this equation
are all formulas/properties that result (1) from quantifying the x, y, z either ex-
istentially or universally (e.g., ∀x ∃y ∃z x = Op(y, z) or ∃x ∀y ∀z x = Op(y, z)
etc.). Further properties are generated by (2) permuting the sequence of the
quantiﬁcations for x, y, z (e.g., ∀y ∃z ∃x x = Op(y, z) etc.) and by (3) mak-
ing some variables equal (e.g., ∃y ∀x x = Op(y, x)). More complicated prop-
erties result from the combination of several copies of the basic construction
element by ∧, ∨, ⇒, for instance, x1 = Op(y1, z1) ⇒x2 = Op(y2, z2) or
x1 = Op(y1, z1) ∧(x2 = Op(y2, z2) ⇒x3 = Op(y3, z3)) etc. The properties
associated with such combined equations are again constructed using the mech-
anisms (1), (2), and (3) etc.
For a residue class structure (RSn, ◦) and a property p, Sem is passed the
multiplication table of the operation of the residue class structure together with
the clauses resulting from the normalization of the property p. The multiplication
table for RSn is encoded as a set of n2 equations of the form c = Op(a, b) where c
is the result of a◦b. Then Sem is asked to ﬁnd a model for this input. We tried to
ﬁnd discriminants for two given residue class structures by either systematically
or randomly checking the properties in the space of our construction mechanism.
However, it turned out that we could only ﬁnd very simple discriminants, such
as λSet λOp ∃x:Set ∀y:Set x = Op(y, y). More complicated discriminants like
the discriminant ∃x (x∗x = x∧∀y (y◦y = x ⇒y◦y = y)) discussed in section 5
are in our search space but are out of the reach of this approach6.
The problems of the approach using Sem are twofold. First, we search in an
enormous space of possible candidates and second we search blindly since we were
not able to guide the search by powerful heuristics. Restricted to the 4 production
rules mentioned, HR searches a similar space, but its search mechanism is a little
more sophisticated, as it recognises two things. Firstly, if it constructs a concept
with no examples, then no further concepts are built from that, as they will also
6 Note that even for the combination of two copies of the basic construction element
(e.g., x1 = y1 op z1 ⇒x2 = y2 op z2) the number of possible properties resulting
from the construction mechanisms (1), (2), and (3) is roughly 100000.

288
A. Meier, V. Sorge, and S. Colton
have no examples (and hence will be useless as a discriminant). Secondly, if it
constructs a concept with the same examples as a previous concept, the new
concept is discarded, to reduce redundancy. Such simple empirical checks are
very powerful in reducing the amount of search HR undertakes.
HR’s success was achieved using only one of many mechanisms available to it:
a limited search, where certain search steps are taken oﬀthe agenda if they would
result in functions of too high an arity. If the problems had been more diﬃcult,
there are two additional mechanisms we could have experimented with, namely:
(i) a heuristic search, which measures the concepts in various ways and builds
new concepts from the most interesting old ones ﬁrst [5] and (ii) a forward look
ahead mechanism, which can tell in advance whether the application of up to
three concept formation steps will lead to a concept which achieves a particular
categorisation task, in our case ﬁnding an invariant, as discussed at length in [6].
7
Conclusion
To produce more sophisticated systems to tackle increasingly diﬃcult problems,
it is necessary to combine programs so that the whole is greater than the sum
of the parts. We have presented an example here of a fruitful cooperation of
heterogeneous mathematical systems to prove non-isomorphism theorems in the
residue class domain. The cooperation is essentially orchestrated by a proof plan-
ner, Multi, which uses a theory formation system, HR, to construct appropriate
discriminants for given structures. The proof is then planned with the help of
automated theorem provers and sometimes a computer algebra system.
The problem of identifying a discriminant for two objects is a machine learn-
ing problem, which could, in theory, be solved by a program such as Progol [15],
which uses Inductive Logic Programming to identify a concept which correctly
categorises a set of positive and negative examples. However, as mentioned in
[4], this may be diﬃcult in practice because we only supply a single positive and
a single negative example, which would suggest that the amount of compression
in a concept would not be high enough to be suggested as a viable solution.
Currently, we call HR manually and supply the proof planner with the appro-
priate information, but we are working on automating this communication. Nev-
ertheless, we have already tested the cooperation with a number of examples and
HR proved successful for the vast majority of these examples. Moreover, HR’s
discriminants could be handled both by the proof planner and the automated
theorem provers successfully even for relatively complicated discriminants.
References
1. C. Benzm¨uller, L. Cheikhrouhou, D. Fehrer, A. Fiedler, X. Huang, M. Kerber,
M. Kohlhase, K. Konrad, E. Melis, A. Meier, W. Schaarschmidt, J. Siekmann, and
V. Sorge. ΩMega: Towards a Mathematical Assistant. In Proceedings of the 14th
International Conference on Automated Deduction (CADE–14), volume 1249 of
LNAI, pages 252–255. Springer Verlag, Germany, 1997.

Employing Theory Formation to Guide Proof Planning
289
2. A. Bundy. The Use of Explicit Plans to Guide Inductive Proofs. In Proceedings
of the 9th International Conference on Automated Deduction (CADE–9), volume
310 of LNCS, pages 111–120. Springer Verlag, Germany, 1988.
3. S. Colton. Automated Theory Formation in Pure Mathematics. PhD thesis, De-
partment of Artiﬁcial Intelligence, University of Edinburgh, 2000.
4. S. Colton. An application-based comparison of automated theory formation and
inductive logic programming. Linkoping Electronic Articles in Computer and In-
formation Science (special issue: Proceedings of Machine Intelligence 17), forthco-
ming, 2002.
5. S. Colton, A Bundy, and T Walsh. On the notion of interestingness in automa-
ted mathematical discovery. International Journal of Human Computer Studies,
53(3):351–375, 2000.
6. S. Colton, A. Bundy, and T. Walsh.
Automatic identiﬁcation of mathematical
concepts. In Proceedings of the 17th International Conference on Machine Learning
(ICML2000), pages 183–190. Morgan Kaufmann, USA, 2001.
7. S. Colton, S Cresswell, and A Bundy. The use of classiﬁcation in automated ma-
thematical concept formation. In Proceedings of SimCat 1997: An Interdisciplinary
Workshop on Similarity and Categorisation. University of Edinburgh, 1997.
8. The GAP Group, Aachen, St Andrews. GAP – Groups, Algorithms, and Program-
ming, Version 4, 1998. http://www-gap.dcs.st-and.ac.uk/˜gap.
9. A. Meier. Tramp: Transformation of Machine-Found Proofs into ND-Proofs at the
Assertion Level. In Proceedings of the 17th International Conference on Automated
Deduction (CADE–17), volume 1831 of LNAI, pages 460–464. Springer Verlag,
Germany, 2000.
10. A. Meier, M. Pollet, and V. Sorge. Classifying Isomorphic Residue Classes. In
Proceedings of the 8th International Workshop on Computer Aided Systems Theory
(EuroCAST 2001), volume 2178 of LNCS, pages 494–508. Springer Verlag, Ger-
many, 2001.
11. A. Meier, M. Pollet, and V. Sorge. Comparing Approaches to Explore the Domain
of Residue Classes. Journal of Symbolic Computations, 2002. forthcoming.
12. A. Meier and V. Sorge. Exploring Properties of Residue Classes. In Proceedings of
the CALCULEMUS-2000 Symposium, pages 175–190. AK Peters, USA, 2001.
13. E. Melis and A. Meier. Proof planning with multiple strategies. In Proceedings of
the First International Conference on Computational Logic, volume 1861 of LNAI.
Springer Verlag, Germany, 2000.
14. E. Melis and J. Siekmann. Knowledge-Based Proof Planning. Artiﬁcial Intelligence,
115(1):65–105, 1999.
15. S. Muggleton. Inverse entailment and Progol. New Generation Computing, 13:245–
286, 1995.
16. D. Redfern. The Maple Handbook: Maple V Release 5. Springer Verlag, Germany,
1999.
17. J. Zhang and H. Zhang. SEM: a System for Enumerating Models. In Proceedings of
the 14th International Joint Conference on Artiﬁcial Intelligence (IJCAI), pages
298–303. Morgan Kaufmann, USA, 1995.

Uniﬁcation with Sequence Variables and Flexible
Arity Symbols and Its Extension with
Pattern-Terms⋆
Temur Kutsia1,2
1 Research Institute for Symbolic Computation
Johannes Kepler University Linz
A-4040, Linz, Austria
kutsia@risc.uni-linz.ac.at
2 Software Competence Center Hagenberg
Hauptstrasse 99
A-4232, Hagenberg, Austria
teimuraz.kutsia@scch.at
Abstract. A minimal and complete uniﬁcation procedure for a theory
with individual and sequence variables, free constants and free ﬁxed and
ﬂexible arity function symbols is described and a brief overview of an
extension with pattern-terms is given.
1
Introduction
We design a uniﬁcation procedure for a theory with individual and sequence
variables, free constants and free ﬁxed and ﬂexible arity function symbols. The
subject of this research was proposed by B. Buchberger in [4] and in a couple
of personal discussions [5]. The research described in this paper is a part of the
author’s PhD thesis.
We refer to uniﬁcation in a theory with individual and sequence variables, free
constants and free ﬁxed and ﬂexible arity function symbols shortly as uniﬁcation
with sequence variables and ﬂexible arity symbols, underlining the importance of
these two constructs. Sequence variables are variables which can be instantiated
by an arbitrary ﬁnite (possibly empty) sequence of terms. Flexible arity function
symbols can take arbitrary ﬁnite (possibly empty) number of arguments. In the
literature the symbols with similar property are also referred to as ”variable
arity”, ”variadic” or ”multiple arity” symbols. Languages with sequence variables
and variable arity symbols have been used in various areas. Here we enumerate
some of them:
– Knowledge management - Knowledge Interchange Format KIF ([10]) and its
version SKIF ([23]) are extensions of ﬁrst order language with (among other
constructs) individual and sequence variables and variable arity function
⋆Supported by the Austrian Science Foundation (FWF) under Project SFB F1302
and by Software Competence Center Hagenberg (Austria) under MathSoft project.
J. Calmet et al. (Eds.): AISC-Calculemus 2002, LNAI 2385, pp. 290–304, 2002.
c
⃝Springer-Verlag Berlin Heidelberg 2002

Uniﬁcation with Sequence Variables and Flexible Arity Symbols
291
symbols. KIF is used to interchange knowledge among disparate computer
systems. Another example of using sequence variables and variable arity
symbols in knowledge systems is Ontolingua ([8]) - a tool which provides a
distributed collaborative environment to browse, create, edit, modify, and
use ontologies.
– Databases - sequences and sequence variables provide ﬂexibility in data re-
presentation and manipulation for genome or text databases, where much of
the data has an inherently sequential structure. Numerous formalisms invol-
ving sequences and sequence variables, like Sequence Logic ([11]), Alignment
Logic ([12]), Sequence Datalog ([20]), String Calculus ([13],[3]), have been
developed for this ﬁeld.
– Rewriting - variable arity symbols used in rewriting usually come from ﬂat-
tening terms with associative top function symbol. Sequences and sequence
variables (sometimes called also patterns), which are used together with
variable arity symbols, make the syntax more ﬂexible and expressive, and
increase the performance of a rewriting system (see [29], [14]).
– Programming languages - variable arity symbols are supported by many of
them. The programming language of Mathematica ([30]) is one of such ex-
amples, which uses the full expressive power of sequence variables as well. A
relation of Mathematica programming language and rewrite rule languages,
and the role of sequence variables in this relation is discussed in [4].
– Theorem proving - the Epilog package ([9]) can be used in programs that
manipulate information encoded in Standard Information Format (SIF) - a
subset of KIF ([10]) language, containing sequence variables and variable
arity symbols. Among the other routines, Epilog includes pattern matchers
of various sorts, and an inference procedure based on model elimination.
These applications involve (and in some cases, essentially depend on) solving
equations with sequence variables and variable arity symbols. The most used
solving technique is matching. However, for some applications, like theorem pro-
ving or completion, more powerful solving techniques (uniﬁcation, for instance)
are needed.
The problem whether Knuth-Bendix completion procedure ([16]) can be ex-
tended to handle term rewriting systems with function symbols of variable arity,
sequences and sequence variables (patterns) is stated as an open problem in [29].
The primary reason why it is an open problem is the absence of appropriate uni-
ﬁcation algorithm.
In this paper, we make the ﬁrst step towards solving this problem, providing
a uniﬁcation procedure with individual and sequence variables, ﬁxed and ﬂexible
arity function symbols and its extension with pattern-terms. Sequence variables
and pattern-terms can be seen as particular examples of the pattern construct
of [29]. The term ”ﬂexible arity” was suggested by Buchberger ([5]) instead of
”variable arity”, mainly because of the following reason: variable arity symbols,
as they are understood in theorem proving or rewriting, are ﬂattened associative
symbols, i.e. ﬂat symbols which take at least two arguments, while ﬂexible arity
symbols can have zero or one argument as well and are not necessarily ﬂat. Non-
ﬂatness is one of main diﬀerences between uniﬁcation with sequence variables

292
T. Kutsia
and ﬂexible arity symbols and associative uniﬁcation: the uniﬁcation problem
f(x, f(y, z)) ?=f(f(a, b), c), with the variables x, y, z and constants a, b, c, has no
uniﬁer, if f has a ﬂexible arity, but admits a uniﬁer {x ←a, y ←b, z ←c} for
associative f. Even when f is a ﬂat ﬂexible arity symbol the problem would not
be equivalent to A-uniﬁcation: the substitution {x ←f(a), y ←f(b, c), z ←f()}
is a uniﬁer for a ﬂat f, but not for an associative f.
The type of uniﬁcation with sequence variables and ﬂexible arity symbols
in the Siekmann uniﬁcation hierarchy ([28]) is inﬁnitary: for any uniﬁcation
problem there exists the minimal complete set of uniﬁers which is inﬁnite for
some problems.
It should be mentioned that in the theorem proving context quantiﬁcation
over sequence variables naturally introduces ﬂexible arity symbols and constructs
that we call patterns. For instance, Skolemizing the expression ∀x∃yΦ[x, y],
where x is a sequence variable, y is an individual variable and Φ[x, y] is a for-
mula which depends on x and y, introduces a ﬂexible arity Skolem function f:
∀xΦ[x, f(x)]. On the other hand, Skolemizing the expression ∀x∃yΦ[x, y] intro-
duces a pattern h1,n(x)(x), which can be seen as an abbreviation of a sequence
of terms h1(x), . . . , hn(x)(x) of unknown length, where h1, . . . , hn(x) are Skolem
functions.
The procedure we describe can be used in the theorem proving context in the
way similar to [24]: building in equational theories. Although uniﬁcation with
sequence variables and ﬂexible arity symbols is inﬁnitary, special cases can be
identiﬁed when the procedure terminates.
It is shown in [17] that uniﬁcation with sequence variables and ﬂexible arity
symbols is decidable. Based on the decision procedure, a constraint-based ap-
proach to theorem proving with sequence variables and ﬂexible arity symbols
can be developed (compare [22], [25]).
Particular instances of uniﬁcation with sequence variables and ﬂexible arity
symbols are word equations ([1],[15], [26]), equations over free semigroups ([19]),
equations over lists of atoms with concatenation ([7]), pattern matching.
We have implemented the uniﬁcation procedure (without decision algorithm)
as a Mathematica package and incorporated it into the Theorema system [6],
which aims at extending computer algebra systems by facilities for supporting
mathematical proving. Currently the package is used in the Theorema Equatio-
nal Prover. It makes Theorema probably the only system being able to handle
equations which involve sequence variables and ﬂexible arity symbols. The pack-
age also enhances Mathematica solving capabilities, considering uniﬁcation as
a solving method. We used the package, for instance, to ﬁnd matches for S-
polynomials in non-commutative Gr¨obner Bases algorithm [21].
The results in this paper are given without proofs. They can be found in [17].
2
Preliminaries
We consider an alphabet consisting of the following pairwise disjoint sets of
symbols: the set of individual variables IV, the set of sequence variables SV, the

Uniﬁcation with Sequence Variables and Flexible Arity Symbols
293
set of object constants CONST , the set of ﬁxed arity function symbols FFIX,
the set of ﬂexible arity function symbols FFLEX and a singleton consisting of
a binary predicate symbol .= (equality).
Let now V stand for (IV, SV) (variables), C - for (CONST , FFIX, FFLEX,
.=) (a domain of constants) and P - for {(, ), , } (”parentheses and comma”). We
deﬁne terms and equations over (V, C, P).
Deﬁnition 1 (Term). The set of terms (over (V, C, P)) is the smallest set of
strings over (V, C, P) that satisﬁes the following conditions:
– If t ∈IV ∪SV ∪CONST then t is a term.
– If f ∈FFIX, f is n-ary, n ≥0 and t1, . . . , tn are terms such that for all
1 ≤i ≤n, ti /∈SV, then f(t1, . . . , tn) is a term.
– If f ∈FFLEX and t1, . . . , tn (n ≥0) are terms, then so is f(t1, . . . , tn).
f is called the head of f(t1, . . . , tn).
Deﬁnition 2 (Equation). The set of equations (over the alphabet (V, C, P)) is
the smallest set of strings over (V, C, P) that satisﬁes the following condition:
– If t1 and t2 are terms over (V, C, P) such that t1 /∈SV and t2 /∈SV, then
.= (t1, t2) is an equation over (V, C, P). .= is called the head of .= (t1, t2).
If not otherwise stated, the following symbols, with or without indices, are
used as metavariables: x, y and z - over individual variables, x, y and z - over
sequence variables, v and u - over (individual or sequence) variables, c - over
object constants, f, g and h - over (ﬁxed or ﬂexible arity) function symbols, s
and t - over terms. We generalize standard notions of uniﬁcation theory ([2]) for
a theory with sequence variables and ﬂexible arity symbols.
Deﬁnition 3 (Substitution). A substitution is a ﬁnite set {x1 ←s1, . . . ,
xn ←sn, x1 ←t1
1, . . . , t1
k1, . . . , xm ←tm
1 , . . . , tm
km} where
– n ≥0, m ≥0 and for all 1 ≤i ≤m, ki ≥0,
– x1, . . . , xn are distinct individual variables,
– x1, . . . , xm are distinct sequence variables,
– for all 1 ≤i ≤n, si is a term, si /∈SV and si ̸= xi,
– for all 1 ≤i ≤m, ti
1, . . . , ti
ki is a sequence of terms and if ki=1 then ti
ki ̸= xi.
Greek letters are used to denote substitutions. The empty substitution is
denoted by ε.
Deﬁnition 4 (Instance). Given a substitution θ, we deﬁne an instance of a
term or equation with respect to θ recursively as follows:
– xθ =

s if x ←s ∈θ,
x otherwise
– xθ =
s1, . . . , sm if x ←s1, . . . , sm ∈θ, m ≥0,
x
otherwise
– f(s1, . . . , sn)θ = f(s1θ, . . . , snθ)
– (s1 .= s2)θ = s1θ .= s2θ.

294
T. Kutsia
We extend the notion of instance to sequences in a straightforward way -
instance of a sequence is a sequence of instances.
Deﬁnition 5 (Composition of Substitutions). Let θ = {x1 ←s1, . . . , xn ←
sn, x1 ←t1
1, . . . , t1
k1, . . . , xm ←tm
1 , . . . , tm
km} and λ = {y1 ←d1, . . . , yn ←
dl, y1 ←e1
1, . . . , e1
q1, . . . , yr ←er
1, . . . , er
qr} be two substitutions. Then the com-
position of θ and λ is the substitution, denoted by θ ◦λ, obtained from the set
{ x1 ←s1λ, . . . , xn ←snλ, x1 ←t1
1λ, . . . , t1
k1λ, . . . , xm ←tm
1 λ, . . . , tm
kmλ,
y1 ←d1, . . . , yl ←dl, y1 ←e1
1, . . . , e1
q1, . . . , yr ←er
1, . . . , er
qr}
by deleting
– all the elements xi ←siλ (1 ≤i ≤n) for which xi = siλ,
– all the elements xi ←ti
1λ, . . . , ti
kiλ (1 ≤i ≤m) for which ki = 1 and
xi = ti
1λ,
– all the elements yi ←di (1 ≤i ≤l) such that yi ∈{x1, . . . , xn},
– all the elements yi ←ei
1, . . . , ei
qi (1 ≤i ≤r) such that yi ∈{x1, . . . , xm}.
Example 1. Let θ = {x ←f(y), x ←y, x, y ←y, z} and λ = {y ←g(c, c), x ←
c, z ←}. Then θ ◦λ = {x ←f(g(c, c)), y ←g(c, c), x ←y, c, z ←}.
These versions of the notions of substitution, composition, and instance have
the same important properties as the standard versions of the same notions:
Theorem 1. For a term t and substitutions θ and λ tθ ◦λ = tθλ.
Theorem 2. For any substitutions θ, λ and σ, (θ ◦λ) ◦σ = θ ◦(λ ◦σ).
3
Equational Theory with Sequence Variables and
Flexible Arity Symbols
A set of equations E (called representation) deﬁnes an equational theory, i.e. the
equality of terms induced by E. We use the term E-theory for the equational
theory deﬁned by E. We will write s .=E t for s .= t modulo E. Solving equations
in an E-theory is called E-uniﬁcation. The fact that the equation s .=E t has to
be solved is written as s ?=Et. A ﬁnite system of equations ⟨s1 ?=Et1, . . . , sn ?=Etn⟩
is called an E-uniﬁcation problem. Some examples of E-theories are:
1. Free theory (∅): E = ∅;
2. Flat theory (F): E = {f(x, f(y), z) .= f(x, y, z)}.
3. Restricted ﬂat theory (RF): E = {f(x, f(y1, x, y2), z) .= f(x, y1, x, y2, z)}.
4. Orderless theory (O): E = {f(x, x, y, y, z) .= f(x, y, y, x, z)}.
5. FO: E = {f(x, f(y), z) .= f(x, y, z), f(x, x, y, y, z) .= f(x, y, y, x, z)}.
6. RFO:
E = {f(x, f(y1, x, y2), z) .= f(x, y1, x, y2, z), f(x, x, y, y, z) .= f(x, y, y, x, z)}.

Uniﬁcation with Sequence Variables and Flexible Arity Symbols
295
Deﬁnition 6 (Uniﬁer). A substitution θ is called an E-uniﬁer of an E-uniﬁ-
cation problem ⟨s1 ?=Et1, . . . , sn ?=Etn⟩iﬀsiθ .=E tiθ for all 1 ≤i ≤n.
Deﬁnition 7 (More General Substitution). A substitution θ is more ge-
neral than a substitution σ on a ﬁnite set of variables V ar modulo a theory E
(denoted θ ≪V ar
E
σ ) iﬀthere exists a substitution λ such that
– for all x ∈V ar,
• x ←/∈λ;
• there exist terms t1, . . . , tn, s1, . . . , sn, n ≥0 such that xσ = t1, . . . , tn,
xθ ◦λ = s1, . . . , sn and for each 1 ≤i ≤n, either ti and si are the same
sequence variables or ti .=E si;
– for all x ∈V ar, xσ .=E xθ ◦λ.
Example 2. {x ←y} ≪{x,y}
∅
{x ←a, z, y ←a, z}, but not {x ←y} ≪{x,y}
∅
{x ←, y ←}.
Deﬁnition 8 (The Minimal Complete Set of Uniﬁers). The minimal com-
plete set of E-uniﬁers of Γ, denoted MCUE(Γ), is an E-minimal set of substi-
tutions with respect to the set of variables V ar of Γ, satisfying the following
conditions:
E-Correctness - for all θ ∈MCUE(Γ), θ is an E-uniﬁer of Γ.
E-Completeness - for any E-uniﬁer σ of Γ there exists θ ∈MCUE(Γ) such
that θ ≪V ar
E
σ.
E-minimality - for all θ, σ ∈MCUE(Γ), θ ≪V ar
E
σ implies θ = σ.
Example 3. Compute the minimal complete set of uniﬁers in the ∅, F and RF
theories (f and g are free ﬂexible arity symbols, h is ﬂat, rh - restricted ﬂat):
1. MCU∅(⟨f(x, a) ?=∅f(a, x)⟩) = {{x ←}, {x ←a}, {x ←a, a}, . . . }.
2. MCU∅(⟨f(g(a, g(y, c)), x) ?=∅f(u, g(b, v))⟩)
=
{{u ←g(a, x), y ←b, v ←
c}, {x ←, u ←g(a), y ←b, v ←c}, {u ←g(a, x), y ←b, y, v ←
y, c}, {x ←, u ←g(a), y ←b, y, v ←y, c}}.
3. MCUF (⟨x ?=F h(x)⟩) = {{x ←h(x)}}.
4. MCUF (⟨h(x) ?=F h(a)⟩) = {{x ←a}, {x ←h(a)}, {x ←a, h()}, {x ←
h(a), h()}, {x ←h(), a}, {x ←h(), h(a)}, {x ←h(), a, h()}, . . . }.
5. MCURF (⟨rh(x) ?=RF rh(a)⟩) = {{x ←a}, x ←rh(a)}.
Below in this paper we consider only the ∅-theory, although the results that
are valid for arbitrary E-theories are formulated in a general setting.

296
T. Kutsia
4
General Uniﬁcation Procedure in the Free Theory with
Sequence Variables and Flexible Arity Symbols
In this section we design a uniﬁcation procedure to solve general uniﬁcation pro-
blem of the form t1 ?=∅t21, built over the alphabet which consists of sequence
and individual variables, free ﬂexible arity function symbols, free constants and
free ﬁxed arity function symbols. We denote it as GUP∅. The uniﬁcation pro-
cedure is a tree generation process based on two basic steps: projection and
transformation.
4.1
Projection
The idea of projection ([1]) is to eliminate some sequence variables from the
given uniﬁcation problem UP. Let Π(UP) be the following set of substitutions:
{{x ←| x ∈S} | S ⊆vars(UP) ∩SV}, where vars(UP) is a set of variables
of UP. Π(UP) is called the set of projecting substitutions for UP. Each π ∈
Π replaces some sequence variables from UP with the empty sequence. The
projection rule is shown in Figure 1.
Projection:
s ?=∅t ⇝⟨⟨sπ1 ?=∅tπ1, π1⟩, . . . ,
where {π1, . . . , πk} = Π(s ?=∅t).
⟨sπk ?=∅tπk, πk⟩⟩
Fig. 1. Projection rule.
4.2
Transformation
Each of the transformation rules for uniﬁcation have one of the following forms:
UP ⇝⊥or UP ⇝⟨⟨SUC1, σ1⟩, . . . , ⟨SUCn, σn⟩⟩where each of the successors
SUCi is either ⊤or a new uniﬁcation problem.
The full set of transformation rules are given on Figure 2. It consists of four
family of rules: Success, Failure, Elimination and Splitting. Note the usage of
widening techniques (similar to [18],[24],[27],[28]) in the elimination rules for
sequence variables.
4.3
Uniﬁcation Procedure – Tree Generation
In [15] and [26] tree generation construction is used for solving word equations.
We use the similar idea for uniﬁcation procedure with sequence variables and
ﬂexible arity symbols. Projection and transformation can be seen as single steps
1 In the case of ∅-theory it is enough to consider single equations instead of systems
of equations in uniﬁcation problems, because ⟨s1 ?=∅t1, . . . , sn ?=∅tn⟩has the same set
of uniﬁers as f(s1, . . . , sn) ?=∅f(t1, . . . , tn), where f is a free ﬂexible arity symbol.

Uniﬁcation with Sequence Variables and Flexible Arity Symbols
297
Success:
t ?=∅t ⇝⟨⟨⊤, ε⟩⟩.
x ?=∅t ⇝⟨⟨⊤, {x ←t}⟩⟩,
if x /∈vars(t).
t ?=∅x ⇝⟨⟨⊤, {x ←t}⟩⟩,
if x /∈vars(t).
Failure:
c1 ?=∅c2 ⇝⊥,
if c1 ̸= c2.
x ?=∅t ⇝⊥,
if t ̸= x and x ∈vars(t).
t ?=∅x ⇝⊥,
if t ̸= x and x ∈vars(t).
f1(˜t) ?=∅f2(˜s) ⇝⊥,
if f1 ̸= f2.
f() ?=∅f(t1, ˜t) ⇝⊥.
f(t1, ˜t) ?=∅f() ⇝⊥.
f(x, ˜t) ?=∅f(s1, ˜s) ⇝⊥,
if s1 ̸= x and x ∈vars(s1).
f(s1, ˜s) ?=∅f(x, ˜t) ⇝⊥,
if s1 ̸= x and x ∈vars(s1).
f(t1, ˜t) ?=∅f(s1, ˜s) ⇝⊥,
if t1 ?=∅s1 ⇝⊥.
Eliminate: f(t1, ˜t) ?=∅f(s1, ˜s) ⇝⟨⟨g(˜tσ) ?=∅g(˜sσ), σ⟩⟩, if t1 ?=∅s1 ⇝⟨⟨⊤, σ⟩⟩.
f(x, ˜t) ?=∅f(x, ˜s) ⇝⟨⟨g(˜t) ?=∅g(˜s), ε⟩⟩.
f(x, ˜t) ?=∅f(s1, ˜s) ⇝
if s1 /∈SV and x /∈vars(s1),
⟨⟨g(˜tσ1) ?=∅g(˜sσ1), σ1⟩,
where σ1 = {x ←s1},
⟨g(x, ˜tσ2) ?=∅g(˜sσ2), σ2⟩⟩,
σ2 = {x ←s1, x}.
f(s1, ˜s) ?=∅f(x, ˜t) ⇝
if s1 /∈SV and x /∈vars(s1),
⟨⟨g(˜sσ1) ?=∅g(˜tσ1), σ1⟩,
where σ1 = {x ←s1},
⟨g(˜sσ2) ?=∅g(x, ˜tσ2), σ2⟩⟩,
σ2 = {x ←s1, x}.
f(x, ˜t) ?=∅f(y, ˜s) ⇝
where
⟨⟨g(˜tσ1) ?=∅g(˜sσ1), σ1⟩,
σ1 = {x ←y},
⟨g(x, ˜tσ2) ?=∅g(˜sσ2), σ2⟩,
σ2 = {x ←y, x},
⟨g(˜tσ3) ?=∅g(y, ˜sσ3), σ3⟩⟩,
σ3 = {y ←x, y}.
Split:
f(t1, ˜t) ?=∅f(s1, ˜s) ⇝
if t1, s1 /∈IV ∪SV and
⟨⟨f(r1, ˜tσ1) ?=∅f(q1, ˜sσ1), σ1⟩, . . . ,
t1 ?=∅s1 ⇝⟨⟨r1 ?=∅q1, σ1⟩, . . . ,
⟨f(rk, ˜tσk) ?=∅f(qk, ˜sσk), σk⟩⟩
⟨rk ?=∅qk, σk⟩⟩.
Fig. 2. Transformation rules. ˜t and ˜s are possibly empty sequences of terms. f, f1, f2 ∈
FFIX ∪FFLEX. g ∈FFLEX is a new symbol, if in the same rule f ∈FFIX.
Otherwise g = f.
in a tree generation process. Each node of the tree is labeled either with a
uniﬁcation problem, ⊤or ⊥. The edges of the tree are labeled by substitutions.
The nodes labeled with ⊤or ⊥are terminal nodes. The nodes labeled with
uniﬁcation problems are non-terminal nodes. The children of a non-terminal
node are constructed in the following way:

298
T. Kutsia
Given a nonterminal node, let UP be a uniﬁcation problem attached to it.
First, we decide whether UP is uniﬁable. If the answer is negative, we replace UP
with the new label ⊥. If UP is uniﬁable, we apply projection or transformation
on UP and get ⟨⟨SUC1, σ1⟩, . . . , ⟨SUCn, σn⟩⟩. Then the node UP has n children,
labeled respectively with SUC1, . . . , SUCn and the edge to the SUCi node is
labeled with σi (1 ≤i ≤n). The set {σ1, . . . , σn} is denoted by SUB(UP).
We design the general uniﬁcation procedure as a breadth ﬁrst (level by level)
tree generation process. Let GUP∅be a uniﬁcation problem. We label the root
of the tree with GUP∅(zero level). First level nodes (the children of the root)
of the tree are obtained from the original problem by projection. Starting from
the second level, we apply only a transformation step to a uniﬁcation problem
of each node, thus getting new successor nodes. The branch which ends with a
node labeled by ⊤is called a successful branch. The branch which ends with a
node labeled by ⊥is a failed branch. For each node in the tree, we compose sub-
stitutions (top-down) displayed on the edges of the branch which leads to this
node and attach the obtained substitution to the node together with the uniﬁ-
cation problem the node was labeled with. The empty substitution is attached
to the root. For a node N, the substitution attached to N in such a way is called
the associated substitution of N. Let Σ(GUP∅) be the set of all substitutions
associated with the ⊤nodes. We call the tree a uniﬁcation tree for GUP∅and
denote it UT(GUP∅).
Example 4. Figure 3 shows development of successful branches of the uniﬁcation
tree for GUP∅= f(x, b, y, f(x)) ?=∅f(a, x, f(b, y)). Σ(GUP∅) = {{x ←a, x ←
b, x, y ←x}, {x ←a, x ←b, y ←}}.
A stronger notion than minimality – disjointness – is used to prove Theorem 3
below. Formally, disjointness is deﬁned as follows:
Deﬁnition 9. A set of substitutions Σ is called disjoint modulo E with respect
to a set of variables V ar iﬀfor all θ, σ ∈Σ, if there exist substitutions λ1, λ2
such that
– for all sequence variables x ∈V ar,
• x ←/∈λ1,
• x ←/∈λ2,
• there exist terms t1, . . . , tn, s1, . . . , sn, n ≥0 such that xθ ◦λ1 =
t1, . . . , tn, xσ ◦λ2 = s1, . . . , sn and for all 1 ≤i ≤n, either ti and
si are the same sequence variables or ti .=E si and
– for all individual variables x ∈V ar,
• xθ ◦λ1 .=E xσ ◦λ2,
then θ = σ.
The main result of this paper says that Σ(GUP∅) is a minimal complete set
of free uniﬁers of GUP∅:
Theorem 3. Σ(GUP∅) = MCU∅(GUP∅).

Uniﬁcation with Sequence Variables and Flexible Arity Symbols
299
f(x, b, f(x)) ?=f(a, x, f(b))
f(b, f(x)) ?=f(x, f(b))
SUCCESS
f(f(b)) ?=f(f(b))
f(x, b, y, f(x)) ?=f(a, x, f(b, y))
f(b, y, f(x)) ?=f(x, f(b, y))
SUCCESS
f(f(b, x)) ?=f(f(b, x))
f(y, f(b, x)) ?=f(x, f(b, y))
f(x, b, y, f(x)) ?=f(a, x, f(b, y))
{x ←a}
fx ←b, x}
fy ←x}
ε
{x ←a}
fx ←b}
ε
{y ←}
ε
Fig. 3. Successful branches of UT(f(x, b, y, f(x)) ?=∅f(a, x, f(b, y))).
Proof. Here we brieﬂy sketch the idea. Details can be found in [17].
Completeness follows from the fact that for every uniﬁer φ of GUP∅there
exists a branch β in UT(GUP∅) such that for every substitution θ associated
with a uniﬁcation problem in β we have θ ≪vars(GUP∅)
∅
φ.
Minimality is implied by disjointness of Σ(GUP∅), which itself follows from
the facts that for each non-terminal node UP in UT(GUP∅) the set SUB(UP) is
a disjoint set of substitutions and every projecting or transforming substitution
preserves disjointness.
⊓⊔
It is clear that the uniﬁcation procedure terminates if GUP∅contains no sequence
variables (in this case the problem can be considered as a Robinson uniﬁcation).
Another terminating case is when one of the terms to be uniﬁed is ground. It
yields to the following result:
Theorem 4. Matching in a theory with individual and sequence variables, free
constants, free ﬁxed and ﬂexible arity function symbols is ﬁnitary.
We can add a cycle-checking method to the procedure: stop with failure if
a uniﬁcation problem attached to a node of uniﬁcation tree coincides with a
uniﬁcation problem in the same branch of the tree. Then the following theorem
holds:
Theorem 5. The uniﬁcation procedure with cycle-checking for GUP∅termina-
tes if no individual and sequence variables occur more than twice in GUP∅.
If GUP∅= t1 ?=t2 has the property that sequence variables occur only as
arguments of t1 or t2, then we can weaken the condition of the previous theorem:

300
T. Kutsia
Theorem 6. The uniﬁcation procedure with cycle-checking for GUP∅= t1 ?=t2,
where sequence variables occur only as arguments of t1 or t2, terminates if no
sequence variable occurs more than twice in GUP∅.
The following termination condition does not require cycle-checking and does
not depend on the number of occurrences of sequence variables. Instead, it re-
quires for a uniﬁcation problem of the form f(x) ?=∅f(t1, . . . , tn), n > 1, to check
whether x occurs in f(t1, . . . , tn). We call it the sequence variable occurrence
checking. We can tailor this checking into the uniﬁcation tree generation pro-
cess as follows: if in the tree a successor of the uniﬁcation problem of the form
f(x) ?=∅f(t1, . . . , tn), n > 1, has to be generated, perform the sequence variable
occurrence checking. If x occurs in f(t1, . . . , tn), label the node with ⊥, otherwise
proceed in the usual way (projection or transformation).
Theorem 7. If GUP∅is a uniﬁcation problem such that all sequence variables
occurring in GUP∅are only the last arguments of the term they occur, then the
uniﬁcation procedure with the sequence variable occurrence checking terminates.
The fact that in most of the applications sequence variables occur precisely
only at the last position in terms, underlines the importance of Theorem 7. The
theorem provides an eﬃcient method to terminate uniﬁcation procedure in many
practical applications.
5
Extension with Pattern-Terms
In this section we give a brief informal overview of an extension of the theory
with patterns. Detailed exposition can be found in [17]. Pattern is an extended
construct of the form hm,k(t1, . . . , tn), where h is a ﬁxed or ﬂexible arity function
symbol, m and k are linear polynomials with integer coeﬃcients with the spe-
cial types of variables - called index variables, which are disjoint from sequence
and individual variables. Instances of patterns are: h1,vn+3(x, y), fvm,vk(a), etc.,
where vn, vm and vk are index variables. The intuition behind patterns is
that they abbreviate term sequences of unknown length: hvm,vk(t) abbrevia-
tes hvm(t), . . . , hvk(t). Patterns can occur as arguments in terms with ﬂexible
arity heads only. Such terms are called pattern-terms (P-terms). A minimal and
complete uniﬁcation procedure with patterns, individual and sequence variables,
free constants, ﬁxed and ﬂexible arity function symbols is described in [17]. The
procedure enumerates substitution/constraint pairs which constitute the mini-
mal complete set of solutions of the problem.
Example 5. Let Γ = f(x, y) ?=∅f(hvm,vk(z)). Then the uniﬁcation procedure re-
turns the set of substitution/constraint pairs
{ {{x ←, y ←hvm,vk(z)}, 1 ≤vm ∧vm ≤vk},
{{x ←hvm,vk(z), y ←}, 1 ≤vm ∧vm ≤vk},
{{x ←hvm,vn(z), y ←hvn+1,vk(z)}, 1 ≤vm ∧vm ≤vn ∧vn + 1 ≤k} },

Uniﬁcation with Sequence Variables and Flexible Arity Symbols
301
with the property that each integer solution of a constraint, applied to the
corresponding substitution, generates an element of the minimal complete set
of solutions. For instance, the solution vm = 1, vn = 3, vk = 4 of the con-
straint 1 ≤vm ∧vm ≤vn ∧vn + 1 ≤vk applied on the substitution
{x ←hvm,vn(z), y ←hvn+1,vk(z)} gives a substitution {x ←h1,3(z), y ←
h4,4(z), vm ←1, vn ←3, vk ←4} which belongs to the minimal com-
plete set of solutions of Γ. In the expanded form the substitution looks like
{x ←h1(z), h2(z), h3(z), y ←h4(z), vm ←1, vn ←3, vk ←4}.
As we have already mentioned in the Introduction, patterns naturally appear
in the proving context, when one wants to Skolemize, for instance, the expres-
sion ∀x∃y (g(x) .= g(y)). Here y should be replaced with a sequence of terms
f1(x), . . . , fn(x)(x), where f1, . . . , fn(x) are Skolem functions. The problem is
that we can not know in advance the length of such a sequence. Note that in the
uniﬁcation we use an index variable vn instead of n(x). This is because, given a
uniﬁcation problem UP in which n(x) occurs, we can do a variable abstraction
on n(x) with a fresh index variable vn and instead of UP consider UP ′ together
with the constraint vn = n(x), where UP ′ is obtained from UP by replacing
each occurrence of n(x) with vn. One of the tasks for uniﬁcation with patterns
is to ﬁnd a proper value for vn, if possible.
6
Applications
We have implemented the uniﬁcation procedure (without the decision algorithm)
as a Mathematica package and incorporated it into the Theorema system, where
it is used by the equational prover. Besides using it in the proving context, the
package can be used to enhance Mathematica solving capabilities, in particular,
the Solve function of Mathematica. Solve has a rich arsenal of methods to solve
polynomial and radical equations, equations involving trigonometric or hyper-
bolic functions, exponentials and logarithms. The following example shows, for
instance, how a radical equation is solved:
In[1]:= Solve

x1/3 + √x == 1, x

Out[1]=

x →−2
3 −11
3

2
101 + 15
√
69
1/3
+ 1
3
1
2

101 + 15
√
69
1/3		
However, it is unable to solve a symbolic equation like f(x, y) = f(a, b):
In[2]:= Solve[f[x, y] == f[a, b], {x, y}]
Solve::”dinv”: The expression f[x, y] involves unknowns in more than one argu-
ment, so inverse functions cannot be used
Out[2]= Solve[f[x, y] == f[a, b], {x, y}]
Also, Solve can not deal with equations involving sequence variables.
On the basis of the uniﬁcation package, we implemented a function called
SolveExtended, which has all the power of Solve and, in addition, deals with
symbolic equations which can be solved using uniﬁcation methods. An equation
like f(x, y) = f(a, b) becomes a trivial problem for SolveExtended:

302
T. Kutsia
In[3]:= SolveExtended[f[x, y] == f[a, b], {{x, y}, {}}]
Answer 1
{x →a, y →b}
The procedure terminated
Out[3]= {{x →a, y →b}}
The function is able to solve (a system of) equations involving sequence
variables as well. In the following example x is an individual variable and X and
Y are sequence variables:
In[4]:= SolveExtended[f[x, b, Y, f[X]] == f[a, X, f[b, Y]], {{x}, {X, Y}}]
Answer 1
{x →a, X →b, Y →Sequence[]}
Answer 2
{x →a, X →Sequence[b, X], Y →X}
The procedure terminated
Out[4]= {{x →a, X →b, Y →Sequence[]}, {x →a, X →Sequence[b, X], Y →X}}
All the problems Solve deals with can also be solved by SolveExtended, e.g.:
In[5]:= SolveExtended

x1/3 + √x == 1, x

Out[5]=

x →−2
3 −11
3

2
101 + 15
√
69
1/3
+ 1
3
1
2

101 + 15
√
69
1/3		
Options allow SolveExtended to switch on/oﬀcycle-detecting and last se-
quence variable checking modes. Printing answers as they are generated is use-
ful when the problem has inﬁnitely many solutions and the procedure does not
terminate, but this facility can also be switched oﬀ, if the user wishes so. It is
possible to terminate execution after generating a certain number of solutions.
We found another application of the uniﬁcation package in computing mini-
mal matches for non-commutative Gr¨obner basis procedure. We show it on the
following example: let p and q be non-commutative polynomials a∗a∗b∗a+a∗b
and a ∗b ∗a ∗a + b ∗a. In order to ﬁnd S-polynomials of p and q one needs to
compute all minimal matches between the leading monomials a ∗a ∗b ∗a and
a ∗b ∗a ∗a, which, in fact, is a problem of solving equations (for instance, of
the form a ∗a ∗b ∗a ∗R1 = L2 ∗a ∗b ∗a ∗a for the variables R1 and L2)
in a free semigroup. Solving equations in a free semigroup is a particular case
of uniﬁcation with sequence variables and ﬂexible arity symbols. Even more,
the equations we need to solve to ﬁnd the matches, belong to a case when the
uniﬁcation procedure terminates. The example below demonstrates how the fun-
ction MinimalMatches, based on the uniﬁcation package, computes matches for
a ∗a ∗b ∗a and a ∗b ∗a ∗a:
In[6]:= MinimalMatches[a ∗a ∗b ∗a, a ∗b ∗a ∗a]

Uniﬁcation with Sequence Variables and Flexible Arity Symbols
303
Out[6]={{a ∗a ∗b ∗a ∗R1, L2 ∗a ∗b ∗a ∗a, {L2 →a, R1 →a}},
{a ∗a ∗b ∗a ∗R1, L2 ∗a ∗b ∗a ∗a, {L2 →a ∗a ∗b, R1 →b ∗a ∗a}},
{L1 ∗a ∗a ∗b ∗a, a ∗b ∗a ∗a ∗R2, {L1 →a ∗b, R2 →b ∗a}},
{L1 ∗a ∗a ∗b ∗a, a ∗b ∗a ∗a ∗R2, {L1 →a ∗b ∗a, R2 →a ∗b ∗a}}}
7
Conclusion
We considered a uniﬁcation problem for the equational theory with sequence
and individual variables, free ﬁxed and free ﬂexible arity function symbols and
gave a uniﬁcation procedure which enumerates the minimal complete set of uni-
ﬁers. Several suﬃcient termination conditions have been established. We gave a
brief overview of a theory extended with constructs called patterns, which are
used to abbreviate sequences of unknown lengths of terms matching a certain
”pattern”. Uniﬁcation procedure for the extended theory enumerates substitu-
tion/constraint pairs which constitute the minimal complete set of solutions of
the problem. Computer algebra related applications have been discussed.
Acknowledgments. I wish to thank Prof. Bruno Buchberger for supervising
the work and for many helpful discussions.
References
1. H. Abdulrab and J.-P. P´ecuchet. Solving word equations. J. Symbolic Computation,
8(5):499–522, 1990.
2. F. Baader and W. Snyder.
Uniﬁcation theory.
In A. Robinson and A. Voron-
kov, editors, Handbook of Automated Reasoning, volume I, pages 445–532. Elsevier
Science, 2001.
3. M. Benedikt, L. Libkin, T. Schwentick, and L. Segouﬁn.
String operations in
query languages.
In Proceedings of the 20th ACM SIGACT-SIGMOD-SIGART
Symposium on Principles of Database Systems, 2001.
4. B. Buchberger.
Mathematica as a rewrite language.
In T. Ida, A. Ohori, and
M. Takeichi, editors, Proceedings of the 2nd Fuji International Workshop on Fun-
ctional and Logic Programming), pages 1–13, Shonan Village Center, Japan, 1–4
November 1996. World Scientiﬁc.
5. B. Buchberger. Personal communication, 2001.
6. B. Buchberger, C. Dupre, T. Jebelean, F. Kriftner, K. Nakagawa, D. Vasaru, and
W. Windsteiger. The Theorema project: A progress report. In M. Kerber and
M. Kohlhase, editors, Symbolic Computation and Automated Reasoning (Procee-
dings of CALCULEMUS 2000), pages 98–113, St.Andrews, 6–7 August 2000.
7. A. Colmerauer. An introduction to Prolog III. CACM, 33(7):69–91, 1990.
8. A. Farquhar, R. Fikes, and J. Rice. The Ontolingua Server: A tool for collaborative
ontology construction. Int. J. of Human-Computer Studies, 46(6):707–727, 1997.
9. M. R. Genesereth. Epilog for Lisp 2.0 Manual. Epistemics Inc., Palo Alto, 1995.
10. M. R. Genesereth and R. E. Fikes. Knowledge Interchange Format, Version 3.0
Reference Manual. Technical Report Logic-92-1, Computer Science Department,
Stanford University, Stanford, June 1992.

304
T. Kutsia
11. S. Ginsburg and X. S. Wang. Pattern matching by Rs-operations: Toward a uniﬁed
approach to querying sequenced data. In Proceedings of the 11th ACM SIGACT-
SIGMOD-SIGART Symposium on Principles of Database Systems, pages 293–300,
San Diego, 2–4 June 1992.
12. G. Grahne, M. Nyk¨anen, and E. Ukkonen. Reasoning about strings in databases.
In Proceedings of the Thirteenth ACM SIGACT-SIGMOD-SIGART Symposium on
Principles of Database Systems, pages 303–312, Minneapolis, 24–26 May 1994.
13. G. Grahne and E. Waller. How to make SQL stand for string query language.
Lecture Notes in Computer Science, 1949:61–79, 2000.
14. M. Hamana. Term rewriting with sequences. In Proceedings of the First Interna-
tional Theorema Workshop, Hagenberg, Austria, 9–10 June 1997.
15. J. Jaﬀar. Minimal and complete word uniﬁcation. J. of ACM, 37(1):47–85, 1990.
16. D. E. Knuth and P. B. Bendix. Simple word problems in universal algebras. In
J. Leech, editor, Computational Problems in Abstract Algebra, pages 263–298, Ox-
ford, 1967. Pergamon Press. Appeared 1970.
17. T. Kutsia. Uniﬁcation in a free theory with sequence variables and ﬂexible arity
symbols and its extensions. Technical report, RISC-Linz, 2002. Available from
ftp://ftp.risc.uni-linz.ac.at/pub/people/tkutsia/reports/uniﬁcation.ps.gz.
18. A. Lentin. Equations in free monoids. In M. Nivat, editor, Automata, Languages
and Programming, pages 67–85, Paris, 3–7 July 1972. North-Holland.
19. G. S. Makanin. The problem of solvability of equations on a free semigroup. Math.
USSR Sbornik, 32(2), 1977.
20. G. Mecca and A. J. Bonner. Sequences, Datalog and transducers. In Proceedings
of the Fourteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of
Database Systems, pages 23–35, San Jose, 22–25 May 1995.
21. F. Mora. Gr¨obner bases for non-commutative polynomial rings. In J. Calmet,
editor, Proceedings of the 3rd International Conference on Algebraic Algorithms
and Error-Correcting Codes (AAECC-3), volume 229 of LNCS, pages 353–362,
Grenoble, July 1985. Springer Verlag.
22. R. Nieuwenhuis and A. Rubio. Theorem proving with ordering and equality con-
strained clauses. Journal of Symbolic Computation, 19:321–351, 1995.
23. P.Hayes and C. Menzel.
A semantics for the knowledge interchange format.
Available from
http://reliant.teknowledge.com/IJCAI01/HayesMenzel-SKIFIJCAI2001.pdf,
2001.
24. G. Plotkin. Building in equational theories. In B. Meltzer and D. Michie, editors,
Machine Intelligence, volume 7, pages 73–90. Edinburgh University Press, 1972.
25. A. Rubio. Theorem proving modulo associativity. In Proceedings of the Conference
of European Association for Computer Science Logic, LNCS, Paderborn, Germany,
1995. Springer Verlag.
26. K. U. Schulz. Word uniﬁcation and transformation of generalized equations. J.
Automated Reasoning, 11(2):149–184, 1993.
27. J. Siekmann. String uniﬁcation. Research paper, Essex University, 1975.
28. J. Siekmann. Uniﬁcation and matching problems. Memo, Essex University, 1978.
29. M. Widera and C. Beierle. A term rewriting scheme for function symbols with
variable arity. TR 280, Prakt. Informatik VIII, FernUniversitaet Hagen, 2001.
30. S. Wolfram. The Mathematica Book. Cambridge University Press and Wolfram
Research, Inc., fourth edition, 1999.

Combining Generic and Domain Speciﬁc
Reasoning by Using Contexts
Silvio Ranise⋆
Universit´e H. Poincar´e-Nancy 2 & LORIA-INRIA-Lorraine
615, rue du Jardin Botanique, BP 101,
54602 Villers Les Nancy Cedex, France
Silvio.Ranise@loria.fr
Abstract. The most eﬀective theorem proving systems (such as PVS,
Acl2, and HOL) provide a kind of two-level reasoning, where the knowl-
edge of a given domain is treated by a special purpose reasoner and a
generic reasoning module is used for the actual problem speciﬁcation. To
obtain an eﬀective integration between these two levels of reasoning is
far from being a trivial task. In this paper, we propose a combination
of Window Reasoning and Constraint Contextual Rewriting to achieve
an eﬀective integration of such levels. The former supports hierarchical
reasoning for arbitrarily complex expressions. The latter provides the
necessary theorem proving support for domain speciﬁc reasoning. The
two levels of reasoning cooperate by building and exploiting a context,
i.e. a set of facts which can be assumed true while transforming a given
subexpression. We also argue that the proposed combination schema can
be useful for building sound simpliﬁers to be used in computer algebra
systems.
1
Introduction
In the veriﬁcation arena, the most eﬀective theorem proving systems (such as
PVS, Acl2, and HOL) provide some kind of two-level reasoning, where the knowl-
edge of a given domain (or theory) is separated and treated by a special purpose
reasoner (called the background reasoner) and a generic reasoning module (called
the foreground reasoner) is used for the actual problem speciﬁcation. As already
experienced by Boyer and Moore in their seminal work [8], to obtain an eﬀective
integration between these two levels of reasoning is far from being a trivial task.
This is so mainly for two reasons.
– First, it is diﬃcult to design an eﬀective interface between the two levels of
reasoning which is independent on the theory handled by the background
reasoner. In fact, most incorporation schemas available in state-of-the-art
⋆This work is partly supported by the European Union “CALCULEMUS Project”
(HPRN-CT-2000-00102). The author would like to thank A. Armando and M. Rusi-
nowitch for many helpful discussions on issues related to this paper. The anonymous
referees helped improving the paper.
J. Calmet et al. (Eds.): AISC-Calculemus 2002, LNAI 2385, pp. 305–318, 2002.
c
⃝Springer-Verlag Berlin Heidelberg 2002

306
S. Ranise
systems (see e.g. [8,7]) apply to decision procedures for speciﬁc theories only
and therefore they are not immediately applicable to decision procedures
for diﬀerent theories. On the other hand, formal veriﬁcation requires a high
degree of automation for a wide variety of domain speciﬁc reasoning tasks.
So, a generic interface between the two levels of reasoning which allows for
the “plug-and-play” of a wide class of background reasoners is required.
– Second, it is often the case that only a tiny portion of the proof obli-
gations arising in practical applications fall exactly into the domain the
background reasoners are designed to solve. This is so because speciﬁca-
tions include both symbols with their usual mathematical meaning as well
as additional function symbols that correspond to entities in the system
being speciﬁed. For example, in a program veriﬁcation scenario, facts like
L ̸= [ ] =⇒min(L) ≤max(L) involve the symbol ≤with its usual meaning
of (weak) “less-than” relation over integers in addition to the functions min
and max appearing in the program of which some behaviour is expressed
and which are supposed to return the minimum and the maximum of the
non-empty list (cf. L ̸= [ ]) of integers L. As a consequence, either the avail-
able decision procedures need to be supplemented with mechanisms capable
of widening their scope or dedicated background reasoners should be built
from scratch.
Similar problems are experienced in the computer algebra community. To
illustrate, consider the problem of computing the deﬁnite integral
 1
0
√
x2dx.
The following simpliﬁcation is one of the most important steps towards the
desired result:
 1
0
√
x2dx =
 1
0
xdx.
The justiﬁcation is that
√
x2 = x for each x s.t. 0 ≤x ≤1. We can regard
0 ≤x ≤1 as an additional assumption which justiﬁes the simpliﬁcation
√
x2 = x.
Here, it is correct to assume 0 ≤x ≤1 since it is a consequence of the context in
which the expression
√
x2 is placed (namely, the bounds of the deﬁnite integral).
In this informal discussion, we have left implicit the fact that a suitable theory of
analysis is assumed as the background theory w.r.t. which all the simpliﬁcation
steps are performed. Furthermore, it is crucial to notice that the additional as-
sumption 0 ≤x ≤1 only holds in the context (under the theory of analysis) since
the variable x is captured by the integral and it cannot be referenced outside its
scope. This rather complicated way of building and using the context is almost
completely neglected by many computer algebra systems which often perform
incorrect simpliﬁcations. For example, consider the problem of computing the
(slightly diﬀerent) deﬁnite integral
 1
−1
√
x2dx. Some versions of Maple will in-
correctly return 0 as the result. The simpliﬁcation
√
x2 = x is applied regardless
the fact that the context of
√
x2 is changed and we are no more entitled to
apply the previous simpliﬁcation rule (i.e.
√
x2 = x). Also in this situation, two
cooperating activities for background and foreground reasoning would allow to

Combining Generic and Domain Speciﬁc Reasoning by Using Contexts
307
cope with the problem of simplifying complex (possibly containing quantiﬁers)
symbolic expressions. In fact, the background reasoner would perform the sim-
pliﬁcations in the theory of analysis and the foreground reasoner would soundly
build up the context used for simpliﬁcation.
Given the importance of the problem of obtaining an eﬀective integration be-
tween background and foreground reasoning both for automated theorem prov-
ing and for computer algebra, this paper will investigate how to obtain such
an eﬀective integration between a sophisticated form of contextual rewriting (as
the background reasoner) and a form of hierarchical reasoning which builds up
a context once a given subexpression is selected (as the foreground reasoner).
1.1
A More Precise Statement of the Problem
In order to provide a ﬂexible incorporation schema of (ground) satisﬁability
procedures in rewriting, we have proposed (see [3,4]) a generalised form of con-
textual rewriting [25], called Constraint Contextual Rewriting (CCR for short),
which allows the available satisﬁability procedure to access and manipulate the
rewriting context. CCR is independent of the theory handled by the procedure
and therefore its applicability is not restricted to procedures for certain theo-
ries. Furthermore, CCR features a powerful mechanism capable of extending the
information available to the satisﬁability procedure with facts encoding proper-
ties of symbols the procedure does not know anything about. This mechanism
can greatly widen the scope of the satisﬁability procedure thereby dramatically
improving its eﬀectiveness. The ﬂexibility of CCR is demonstrated in [3] where
it is shown that the integration schemas employed in the simpliﬁers of Acl2 [8]
and Tecton [19] are all instances of CCR as well as in [1] where a rational re-
construction of Maple’s evaluation process is obtained by suitably instantiating
CCR.
Another important feature of CCR (as explained in [3]) is the possibility to
make CCR independent of the way the context manipulated by both the rewriter
and the satisﬁability procedure is built. To do this, it is suﬃcient to assume the
existence of a suitable function which returns a ﬁnite conjunction of literals which
can be assumed true during the constraint contextual rewriting activity. As an
example, let us consider clauses only. Then, the function building the context
returns the conjunction of the negation of all literals in the clause but one which
is currently being rewritten. Although it is possible to translate any ﬁrst-order
formula into clausal normal form (CNF) by well-known means, this situation is
not completely satisfactory since many veriﬁcation eﬀorts are expressed in larger
fragments of full ﬁrst-order logic and it is well-known that the “quality” of the
CNF translation is crucial for any afterwards applied theorem proving method
(see [24] for an exhaustive discussion about this issue). Furthermore, the original
structure of the formula is partially (if not totally) lost in the translation and a
problem-reduction style of reasoning cannot be supported this way. In order to
overcome this problem, more sophisticated instances of the process of building
the context are required. Window reasoning (WR, for short) [22,15] provides a
sophisticated way of obtaining a context in such a way that the original structure

308
S. Ranise
of the formula is unaltered and also hierarchical reasoning is supported. More
precisely, WR is the activity of transforming a logical expression by restricting
to one of its subexpressions (the focus expression) and transforming it. The
remainder of the surrounding expression (the context) is left unchanged and
it can be assumed true while transforming the focus expression. For example,
when transforming ψ into an equivalent formula ψ′ in the expression φ ∧ψ, we
can assume that φ is true. WR has been found particularly useful for program
veriﬁcation and program reﬁnement (see [15] for a complete discussion of this
issue).
This paper describes our experience in building and using a system which
features a combination of CCR and WR in order to support the activity of sim-
plifying complex (possibly containing quantiﬁers) expressions. On the one hand,
CCR plays the rˆole of the background reasoner. It provides an adequate degree
of automation for reasoning in rich background theories as well as the ﬂexibility
of ﬁne tuning the domain speciﬁc reasoning to the actual veriﬁcation eﬀort. On
the other hand, WR plays the rˆole of the foreground reasoner, thereby providing
the support for hierarchical top-down reasoning. The two levels of reasoning co-
operate via a context built by WR and used during the simpliﬁcation activity by
CCR. The interface between the two levels of reasoning is the process of building
the context. In order to validate our approach, we apply a (prototype) imple-
mentation of the proposed combination to the task of proving the correctness of
Hoare’s Find algorithm [17] which also requires dealing with quantiﬁers.
The paper is organised as follows. Sections 2 and 3 brieﬂy describe CCR
and WR. In section 4, the combination of CCR and WR is discussed and its
implementation is brieﬂy sketched. Then, Section 5 overviews the case study.
Finally, section 6 draws some conclusions and sketches some lines of research for
future work.
2
Constraint Contextual Rewriting
CCR features a tight integration of three reasoning activities: contextual rewrit-
ing, satisﬁability checking, and lemma speculation. In the following, let Tc be a
ﬁrst-order theory whose satisﬁability problem is decidable and T be the back-
ground theory obtained by closing Tc ∪R under logical implication, where R is
a set of facts of the form ∀x1, ..., xm.h1 ∧· · · ∧hn =⇒c and x1, ..., xm are all the
variables in the formula, h1, ..., hn are literals, and c is either an equality or a
literal whose top-most function symbol is in the language of Tc. We now describe
how CCR can realize the background reasoning activity in the theory T.1
In CCR, we assume the availability of a satisﬁability procedure for Tc. The
procedure works on a data structure (called constraint store) representing a
conjunction of ground literals which are assumed true during rewriting. Three
interface functionalities must be provided by a satisﬁability procedure to be
plugged in CCR. First, cs init(C) initialises the constraint store C. Second,
1 For lack of space, the description of CCR is not exhaustive but only suﬃcient to
make the paper self-contained. A complete overview of CCR can be found in [3].

Combining Generic and Domain Speciﬁc Reasoning by Using Contexts
309
cs unsat(C) checks whether C is unsatisﬁable in Tc. Third, P :: C −−−−−−→
cs−extend C′
extends the constraint store C with the set of literals P yielding a new constraint
store C′.
The activity of constraint contextual rewriting the literal p to p′ in context
C (in symbols C :: p−→
ccr p′) is done in two ways. First, the literal p can be
rewritten to true in a given context C if p is entailed by C. In order to check
whether a literal p is entailed by C, we can check the unsatisﬁability of C and
the negation of p. In CCR, this can be done by invoking cs unsat(C′), where C′
is the extension of C with the negation of the literal p. Similarly, we can rewrite
to false the literal p if CCR is capable of checking that the negation of p is
entailed by the context C. Second, given a literal p[lσ], the rewriting activity of
CCR returns p[rσ] if the following condition is satisﬁed; there exists a rewrite
rule of the form ∀x1, ..., xm.h1∧· · ·∧hn =⇒l = r in R and a ground substitution
σ such that each hiσ (for i = 1, ..., n) can be simpliﬁed to true by recursively
invoking the activity of constraint contextual rewriting.
By lemma speculation we mean the activity of ﬁnding out and feeding the
satisﬁability procedure with new facts about function symbols which are other-
wise uninterpreted in Tc. Augmentation is a form of lemma speculation which
extends the information available to the satisﬁability procedure with selected
instances of facts in R (which are supposed to encode properties of symbols the
satisﬁability procedure does not know anything about). We still need to describe
how such facts are exploited in CCR. First of all, recall that instances of facts in
R are of the form (h1∧· · ·∧hn =⇒c)σ, where σ is a ground substitution and c is
a literal whose topmost predicate symbol is in the language of Tc. In order to add
cσ to the actual constraint store, the hypotheses h1σ, ..., hnσ must preliminary
be relieved. This problem is solved by trying to constraint contextually rewrite
each hiσ (for i = 1, ..., n) to true.
3
Window Reasoning
In [15], window reasoning transforms an expression of interest (the focus) F
under some preorder relation R (such as, e.g. implication). A window is an
object of the form
! Γ1
· · ·
! Γn
ρ ⋆F
(1)
where Γ1, ..., Γn are (sets of) assumptions, F is the focus expression, and ρ
is the relation to be preserved. The window (1) states the intention to prove
n
i=1 Γi ⊢F ρ F ′ for some resulting expression F ′, where ⊢is the derivability
relation in (say) the Natural Deduction calculus [21].
There are four basic operations in WR. The ﬁrst is to make an initial window
for a speciﬁc focus F and relation ρ. The second is to transform a window by

310
S. Ranise
replacing the focus expression F[f] with F[f ′] whenever Γ ′ ⊢f ρ′ f ′ has been
proved for a given relation ρ′ and Γ ′ ⊇Γ. The third is to open a new window at a
selected subexpression. To do this, the child window is pushed on a window stack,
the new focus is the selected subexpression of the parent window and the relation
in the child window is determined by the opening rule used. The hypotheses of
the parent window are inherited by the child window and possibly the opening
rule can add extra hypotheses. The last operation is to close back to a parent
window by replacing the original subexpression in the parent window which was
selected for opening. The child window is then popped from the window stack.
A usable mechanisation of WR requires to hide the explicit choice of opening
rules. It must be possible to specify an arbitrary position in the formula and the
window opening mechanism should be capable of implicitly composing many
rules so as to open a window at the desired position. Indeed, a set of basic rules
must be identiﬁed. These rules can be found by considering the deﬁnition of
(ﬁrst-order) formula and ﬁnding out at which position a window can be opened.
Hence, there will be opening rules for the connectives and for the universal
and the existential quantiﬁers. In addition to the basic window rules, others are
required to make WR usable in practice. Such additional rules preserve domain
speciﬁc relations such as ≤.
4
Combining Constraint Contextual Rewriting and
Window Reasoning
In our combination, the background reasoning activity is provided by CCR and
the foreground reasoning by WR. These two activities cooperate via a context
which is built by WR and used by CCR. In fact, WR builds the context while
breaking down the formula to literal level. Once at the literal level, CCR is
capable of simplifying the literal in a suitable context w.r.t. a given background
theory.
As already observed in Section 3, the task of breaking down a formula is
straightforward as soon as we consider the inductive deﬁnition of the set of
ﬁrst-order formulae. The concurrent activity of building a context is also simple
since the notion of truth (in ﬁrst order logic) is recursively deﬁned over the
structure of the formulae (see, e.g., [12]). The only diﬃculty in doing this is
posed by the requirements which the resulting context and focus expression are
supposed to satisfy in order to be suitably exploited by CCR. Let us analyse
these requirements. First, the focus expression and the context must be ground.
Second, the context C must be such that ( C =⇒(l ⇐⇒l′)) =⇒(φ[l]u ⇐⇒
φ[l′]u) holds in the background theory for a formula φ.
To see how these two requirements can be easily satisﬁed, consider the set L
of ﬁrst order literals built in the usual way over the signature in which the actual
veriﬁcation problem is expressed. Then, consider the set H containing L as well as
the (ﬁnite) conjunctions of literals in L. We restrict our attention to the sentences
in the (inductively deﬁned) set VC of formulae such that (i) L ⊆VC, (ii) if G1
and G2 are in VC then G1 ∧G2 is in VC, (iii) if H is in H and G is in VC then

Combining Generic and Domain Speciﬁc Reasoning by Using Contexts
311
H =⇒G is in VC, and (iv) if G is in VC then ∀x.G is in VC. If a sentence φ in VC
contains the universally quantiﬁed variables x1, ..., xn, then replace each xi (i =
1, ..., n) by a “fresh” (i.e. not occurring in φ) constant. In the following, we assume
that all sentences in VC are transformed in this way to eliminate all universal
quantiﬁers. As a consequence, we consider only ground formulae. We are now
in the position to deﬁne the function Cxt(G, u) building the context C for any
sentence G in VC and literal position u in G as follows: Cxt(L, ϵ) := {L} when L
is in L, Cxt(G1 ∧G2, i.u) := Cxt(Gi, u) where i = 1, 2, and Cxt(H =⇒G, 2.u) :=
{h|h is a literal in the conjunction H} ∪Cxt(G, u); otherwise, the function Cxt
returns the empty set.2 (We notice that WR can easily mechanise the function
Cxt.) With this deﬁnition of the function building the context, it is easy to check
that both requirements above are satisﬁed. Furthermore, if the activity of CCR
is complete w.r.t. the background theory T (i.e. for any context C and literal p
we have that C :: p −→
ccr true iﬀT ∪C |= p), then the proposed combination of
WR and CCR is complete for the set of sentences in VC (i.e. a sentence α in VC
is simpliﬁed to true iﬀT |= α). We can exploit a complete implementation of
CCR whenever we have a background theory T = Tc for which a satisﬁability
procedure is available (and hence R = ∅since T is the deductive closure of Tc∪R).
In this case, as already described in Section 2, any focus literal p is rewritten
to true (false) in Cxt(G, u) where u is the position of G at which p is located
by checking the unsatisﬁability of the ground set of literals {¬p} ∪Cxt(G, u)
({p} ∪Cxt(G, u), respectively).
Unfortunately, in some cases, the set of sentences in VC is not suﬃcient to
express the veriﬁcation conditions arising in practice. Often, the reason for this
is that invariants involving existential quantiﬁcation are required. So, we extend
the set VC to include the formulae with existential quantiﬁers as follows. First,
we consider the set He ⊇H to be such that if H is in He then ∀x.H is in
He. Then, we deﬁne (by induction) the set VCe to be such that (i) VCe ⊇He,
(ii) VCe ⊇VC, (iii) if G is in VCe then ∃x.G is in VCe, and (iv) if H is in
H then ∀x.H is in VCe. (Notice that the universal quantiﬁer in ∀x.H =⇒G
encodes an existential choice.) The situation is now more complicated. In fact,
for sentences in VCe, WR can generate contexts containing non-ground literals.
As a consequence, we need to extend the background reasoner to handle non-
ground literals. From an operational point of view, this requires to lift rewriting
to narrowing and the activity of checking the satisﬁability of ground literals to
handling (and possibly instantiating) variables in search of an inconsistency in
the background theory. To understand how diﬃcult this problem is, let the back-
ground theory be (ﬁnitely) axiomatised by a set of equations E, the context be
the singleton set containing the literal P(u1, ..., un) and P(v1, ..., vn) be the focus
literal. Then, consider the situation in which we want to rewrite the focus literal
to true by checking the unsatisﬁability of the conjunction of its negation (namely
¬P(v1, ..., vn)) with the context. In this scenario, the background reasoner must
be capable of answering the following question: given a set E of equations and
2 The uniqueness of the function Cxt is an immediate consequence of the recursion
theorem (see, e.g. [12]).

312
S. Ranise
some pairs of terms (ui, vi), is there a substitution σ such that for all equations
(ui = vi)σ holds that Eσ ∪{(ui = vi)σ} is unsatisﬁable? This problem can be
shown equivalent (see, e.g. [6]) to the rigid E-uniﬁcation problem [14], which
is known to be decidable and NP-complete.3 So, ensuring completeness for the
set of sentences in VCe is quite expensive from a computational point of view.
Furthermore, the situation is much more complicated as soon as we consider the-
ories which are not axiomatised by a ﬁnite set equations (see [7] for a discussion
of this problem in the context of a refutation procedure).
Instead of handling existential quantiﬁers in a general way by using narrowing
in place of rewriting and constraint solving in place of satisﬁability checking, we
take a more pragmatic (although incomplete) approach. There are two cases to
be considered depending on the fact that the existential quantiﬁcation is implicit
or explicit. Firstly, when the existential quantiﬁcation is encoded by a universal
quantiﬁcation whose scope is the antecedent of an implication, the implication is
added to the set R of background facts and augmentation is asked to (possibly)
ﬁnd a suitable instance for the universally quantiﬁed variables in the fact (see
Section 5.1 for an example of this). Secondly, when the existential quantiﬁcation
is explicit in the formula, we extend the function Cxt building the context with
a ground substitution for the existential variables in the formula as an extra
argument. Indeed, this allows us to easily obtain a suitable ground version of
the context and the focus literal. In both cases, CCR can be applied without
modiﬁcations. (Notice that also this version of the function Cxt can easily be
mechanised by WR.)
4.1
Generality of the Approach
So far, we have been able to give completeness results of the combination between
CCR and WR for some restricted classes of formulae, namely VC and VCe. This
characterization, although important from a practical point of view since many
veriﬁcation conditions fall in these two classes, is not completely satisfactory.
In [10], Corella investigates the problem of determining what sentences can be
assumed true when proving s = t so to establish—by the principle of substitution
of equals for equals—that C[s] = C[t] for a suitable context C[·] and some set of
assumptions Γ. He notices that there are some sentences related to the context
C[·] which can be assumed to hold although they are not in Γ and that there
exists a closed form characterization of such a set of sentences in Church’s system
[9] (which combines the simple theory of types with Church’s lambda-calculus).
To obtain a similar closed form solution for a natural deduction calculus for
ﬁrst-order logic [21], the introduction of an “if-then-else” construct is required
due to a lack of expressive power of ﬁrst-order logic. Let A(Γ, C[·]) be the set of
sentences which can be assumed true in order to prove that Γ ⊢C[s] = C[t] for
a suitable derivability relation ⊢. In general, it is undecidable whether a formula
α is in A(Γ, C[·]) or not; but it is possible to identify useful suﬃcient conditions
3 Notice that the related problem of simultaneous rigid E-uniﬁcation is undecidable
[11].

Combining Generic and Domain Speciﬁc Reasoning by Using Contexts
313
for α to be an element of A(Γ, C[·]) which are decidable, as we have done for VC
and VCe. So, it is natural to investigate more sophisticated WR rules for building
the context which can be afterwards used by CCR. For example, we think that
a characterization of some classes of formulae (in the same spirit of VC and VCe)
can be given by considering proof obligations arising in typical computer algebra
sessions. To illustrate, consider the task of computing deﬁnite integrals. We can
think of deriving the elements of A(Γ, C[·]) from the function which is going to be
integrated (more precisely from its deﬁnition) and the bounds of the integral. For
example, consider the following integral:
 1
0 |x|dx. From the deﬁnition of absolute
value (namely, |x| = x if x ≥0 and |x| = −x if x < 0) which is assumed to be in
Γ and the interval considered for integration (namely, [0, 1]), it is not diﬃcult
to derive the following sentence in A(Γ, C[·]): ∀x.(0 ≤x ∧x ≤1 =⇒|x| = x).
This fact together with some form of extensionality (which again we assume to
be in Γ) allow us to perform the desired simpliﬁcation
 1
0 |x|dx =
 1
0 xdx.
Finally, it is important to notice (as shown in [10]) the incompleteness of
the method of showing that Γ ⊢C[s] = C[t] by proving that s = t follows
from Γ and A(Γ, C[·]). This means that for some context C[·] and some set of
assumptions Γ, there exists an equality s = t which is not in A(Γ, C[·]) but is
such that Γ ⊢C[s] = C[t].
4.2
Implementation
We have implemented the proposed combination schema on top of RDL(acronym
for Rewrite and Decision procedure Laboratory) [2], an automatic theorem
prover based on CCR. We have extended the input set of formulae to the system
to full ﬁrst-order logic and we have implemented the various operations to sup-
port WR (see Section 3). This task has been routine since the implementation
language of RDL is Prolog and this allows the programmer to easily manipulate
symbolic expressions. Furthermore, since CCR provide the uniform interface to
background reasoning, there has been no need to implement many domain spe-
ciﬁc window inference rules preserving a variety of relations such as ≤. This is in
contrast with previous systems based on WR. For example, the window library
distributed with the HOL system consists of about 40 rules, whereas our imple-
mentation consists of 11 rules to handle the connectives and the quantiﬁers as
well as to combine them. An additional rule allows to invoke CCR on the focus
literal of the active window in the context obtained by collecting the hypothe-
ses of the window. For the sentences in VC, the WR mechanism implemented
in our system gives exactly the implementation of function Cxt(φ, u) deﬁned in
Section 4 when φ is a sentence in VC. As a consequence, our system becomes
complete for sentences in VC as soon as a complete satisﬁability procedure for
the background theory is available. This is the case for the theory of arrays with
extensionality and permutation for which a satisﬁability procedure has been ob-
tained by coupling the equational theorem prover E [23] to our system, following
the methodology described in [5] (see Section 5 for more details on this).

314
S. Ranise
5
The Proof of Correctness of Hoare’s Find
In [17], Hoare shows the correctness and termination of his algorithm Find [16].
Given an array a of comparable elements and an element sel(a, f) at position
f of a, Find consists in reorganising the elements of a in such a way that all
elements on the left side of f are smaller than or equal to sel(a, f) and all
elements on the right side of f are greater than or equal to sel(a, f). Hoare’s
proof is based on the use of invariants. Proof obligations are made explicit at
each step and proved as lemmas in a hierarchical (top-down) way. In order to
prove most lemmas, reasoning in the background theory of comparable elements
(and arrays) is essential.
Since WR supports hierarchical reasoning and CCR provides the background
reasoning in a theory of comparable elements and arrays, Hoare’s correctness
proof appears as an interesting case study for our system. Furthermore, Find is
a non-trivial program.
Both the indexes and the elements of the array are modeled as integers so
that the available (in RDL) satisﬁability procedure for Universal Presburger
Arithmetic can be used. Arrays are axiomatised by using the following axioms:
∀A, I, E.sel(store(A, I, E), I) = E
(2)
∀A, I, J, E.I ̸= J =⇒sel(store(A, I, E), J) = sel(A, J),
(3)
where store(A, I, E) is the array whose I-th element is E and whose J-th com-
ponent for I ̸= J is sel(A, J). These axioms are stored in the set R thereby
specifying an extension of Universal Presburger Arithmetic as the background
theory.
We consider the proof of the lemmas listed in Hoare’s paper [17]. Each lemma
states that a given invariant of the algorithm is satisﬁed at a certain point in
the algorithm. Lemmas 1–9 can be easily proved by our system by invoking
the augmentation mechanism only to ﬁnd suitable instances of the existentially
quantiﬁed variable encoded in the universal quantiﬁcation whose scope is the
antecedent of an implication. There is no need of ﬁnding instantiations of the
axioms for arrays, since lemmas 1–9 encode the correctness of operations which
perform comparisons on the elements of the array but do not alter it, thus
only reasoning in Universal Presburger Arithmetic is necessary. Lemmas 10–13
require the augmentation mechanism also to ﬁnd suitable instances of the axioms
for arrays. In fact, these four lemmas express the correctness of exchanging two
elements in the array, thus the fundamental properties of arrays are necessary.
Lemmas 14–18 concern the proof of termination of the algorithm. Notice
that these lemmas require an explicit existential quantiﬁcation in the conclusion
of the formula. As already said in Section 4, our system takes a ground term
as input in order to instantiate the explicitly existentially quantiﬁed variable of
the formulae. All the required terms are extracted from Hoare’s paper and the
proofs are then automatically completed by our system.
There are still two important aspects of the correctness proof to be con-
sidered. The former is proving that all indices used in the program are within

Combining Generic and Domain Speciﬁc Reasoning by Using Contexts
315
the bounds of the array. Although mentioned, the problem is not formalised
in Hoare’s paper. The lemmas encoding these properties can be easily stated in
Universal Presburger Arithmetic and automatically proved in our system thanks
to the available satisﬁability procedure for such a theory. The second aspect
amounts to proving that the initial elements stored in the array are preserved
by the program. In [17], Hoare informally proves this property by observing that
the program only performs exchanges of pairs of elements and, as a consequence,
the elements in the array after the execution of the program are disposed in a
permutation of the original array. Hoare also points out that the formalisation
of this argument is quite involved and it implies tedious proofs. In [13], Filliˆatre
formalises the above argument in Coq [18] by using inductive deﬁnitions for the
concept of permutation and he claims that the resulting proofs obligations are
easy to prove. Since our system does not provide facilities to handle inductive
deﬁnition, we take another approach to prove the property of preservation of the
algorithm.
In [5], a methodology to build satisﬁability procedures for certain equational
theories is described and it is applied to the theory of arrays considered here.
The satisﬁability procedure for such a theory roughly consists of the exhaustive
application of the rules of a superposition calculus [20] to the axioms of the theory
and the ground literals whose satisﬁability we want to check. Now, consider the
following deﬁnition of permutation (expressed in second-order logic, see [12]):
∀M, N.(Perm(M, N) ⇐⇒
∃p.(Bijective(p) ∧∀I.(sel(M, I) = sel(N, p(I)))))
(4)
where Bijective(p) encodes the property that the function p is a bijection.4
Notice that given two arrays denoted by two (ﬁrst order) ground terms m and
n formula (4) can be reduced to the following ﬁrst-order formula:
Perm(m, n) ⇐⇒∀I.(p(q(I)) = q(p(I)) ∧sel(M, I) = sel(N, p(I))
(5)
where q is the inverse of the function p. This deﬁnition of Perm is suﬃcient for
our case study since we need to handle the (un-)satisﬁability of ground literals
only. The satisﬁability procedure for arrays described in [5] can be easily ex-
tended to handle lemmas of the form (5).5 Thus a superposition based theorem
prover can be used to rapid prototype a satisﬁability procedure for the theory of
arrays with permutations. To this end, we have used the theorem prover E [23].
A simple interface between our system and E has been implemented so that the
satisﬁability procedure can be readily plugged into our system. At this point,
the proof obligations expressing the preservation of the elements of the array are
automatically proved.
4 A permutation is formally deﬁned as a bijection.
5 This is so because (roughly) no superpositions are possible between the right hand
sides of formulae of the form (5) and the axioms of arrays.

316
S. Ranise
5.1
A Worked Out Example
Let us consider the following veriﬁcation condition corresponding to Lemma 10
of [17]:
(m ≤i ≤j ∧∀p.(1 ≤p < i =⇒sel(a, p) ≤r)) =⇒
(m ≤i ∧∀p.(1 ≤p < i =⇒sel(store(store(a, i, sel(a, j)), j, sel(a, i)), p) ≤r))
(6)
where A ≤B < C abbreviates A ≤B ∧B < C, and m, i, j, a, and r are
constants. (Notice that (6) is a sentence in VCe and ∀p.(1 ≤p < i =⇒sel(a, p) ≤
r) in (6) encodes an existential quantiﬁcation.)
Our system begins the proof by opening a window on the literal m ≤i
(occurring in the conclusion of the implication) and CCR is invoked on it in a
suitable context as follows: {m ≤i, ...} :: m ≤i −→
ccr true, since m ≤i is readily
found entailed by the context thanks to the available satisﬁability procedure for
Universal Presburger Arithmetic. Then, we close the window and we go back
to its parent where the literal we originally opened the sub-window on (namely
m ≤i) is replaced by true, thereby obtaining the following formula (equivalent
to (6)):
(m ≤i ≤j ∧∀p.(1 ≤p < i =⇒sel(a, p) ≤r)) =⇒
(true ∧∀p.(1 ≤p < i =⇒sel(store(store(a, i, sel(a, j)), j, sel(a, i)), p) ≤r))
(7)
Then the system opens a sub-window on the literal sel(store(store(a, i, sel(a, j))
j, sel(a, i)), p) ≤r (where p is a fresh constant) of (7) and we invoke CCR on it:
{p < i, i ≤j, ...} ::
sel(store(store(a, i, sel(a, j)), j, sel(a, i)), p) ≤r −→
ccr
sel(store(a, i, sel(a, j))), p) ≤r −→
ccr sel(a, p) ≤r −→
ccr true
(8)
(notice also that ∀p.(1 ≤p < i =⇒sel(a, p) ≤r) is added to R) since axiom (3)
is instantiated to
p ̸= j =⇒sel(store(store(a, i, sel(a, j)), j, sel(a, i)), p) = sel(store(a, i, sel(a, j)), p)
and the focus literal can be rewritten to sel(store(a, i, sel(a, j))), p) ≤r (the
condition p ̸= j is rewritten to true since it is entailed by the context), then
axiom (3) is instantiated to
p ̸= i =⇒sel(store(a, i, sel(a, j))), p) = sel(a, p)
and the focus literal can be rewritten to sel(a, p) ≤r (the condition p ̸= i is
rewritten to true since it is entailed by the context). Finally, the literal sel(a, p) ≤
r is rewritten to true since augmentation instantiates the fact ∀p.(1 ≤p < i =⇒
sel(a, p) ≤r))—which, we recall, has been added to the set R—to 1 ≤p < i =⇒
sel(a, p) ≤r. The conditions of this fact are easily found to be entailed by the
context and the conclusion is added to the context. At this point, the literal
sel(a, p) ≤r can be rewritten to true by detecting that it is obviously entailed
by the (extended) context.

Combining Generic and Domain Speciﬁc Reasoning by Using Contexts
317
Now, we close the sub-window and we replace the rewritten focus expression
in the parent, thereby obtaining the following formula:
(m ≤i ≤j ∧∀p.(1 ≤p < i =⇒sel(a, p) ≤r)) =⇒(true ∧true)
which is easily transformed to true by applying some obvious window inferences.
6
Conclusions
We have presented a combination of generic and domain speciﬁc reasoning which
allowed us to easily prototype a reasoning system which supports the activity of
veriﬁcation in a ﬂexible way and with a high degree of automation. The generic
reasoning module is based on WR which is particularly suited for program veriﬁ-
cation and reﬁnement. The domain speciﬁc reasoning is mechanised in a uniform
way by CCR. The two reasoning activities communicate via a context. We have
also seen how the combined reasoning activity allows CCR to handle a class of
formulae containing existentially quantiﬁed variables, not only ground formulae.
The prototype system has been successfully used for proving the correctness of
Hoare’s Find algorithm, thereby conﬁrming the validity of our approach. A key
to the ﬂexibility and high degree of automation provided by the proposed com-
bination schema is the ability to extend and to build satisﬁability procedures
for rich background theories. In our case study, this is exempliﬁed by the pro-
cedure for arrays with permutations. An interesting line of research is to extend
the system by incorporating a module which analyses the axioms in the back-
ground theory and automatically proves the termination property required to
obtain a satisﬁability procedure along the lines given in [5] and ﬁnally invokes
an equational theorem prover.
Another promising development of this work is to systematically investigate
classes of proof obligations arising in computer algebra sessions for which the
method proposed in the paper can be proved complete. We think that in order to
do this in a ﬁrst-order setting, we should investigate how to cope with some form
of extensionality which seems to be the key ingredient to handle simpliﬁcations
taking place in the scope of quantiﬁers.
References
1. A. Armando and C. Ballarin. Maple’s Evaluation Process as Constraint Contextual
Rewriting. In Proc. of the 2001 Int. Symp. on Symbolic and Algebraic Computation
(ISSAC-01), pages 32–37, New York, July 22–25 2001. ACMPress.
2. A. Armando, L. Compagna, and S. Ranise. RDL—Rewrite and Decision procedure
Laboratory. In Proceedings of the International Joint Conference on Automated
Reasoning (IJCAR 2001), Siena, Italy, June 2001.
3. A. Armando and S. Ranise. Constraint Contextual Rewriting. In Proc. of the 2nd
Intl. Workshop on First Order Theorem Proving (FTP’98), 1998.
4. A. Armando and S. Ranise. Termination of Constraint Contextual Rewriting. In
Proc. of the 3rd Intl. W. on Frontiers of Comb. Sys.’s (FroCos’2000), LNCS 1794,
2000.

318
S. Ranise
5. A. Armando, S. Ranise, and M. Rusinowitch.
Uniform Derivation of Decision
Procedures by Superposition. In Computer Science Logic (CSL01), Paris, France,
10-13 September, 2001.
6. P. Baumgartner. An Ordered Theory Resolution Calculus. In Logic Programming
and Automated Reasoning, number 624 in LNAI, pages 119–130, 1992.
7. N. Bjørner. Integrating Decision Procedures for Temporal Veriﬁcation. PhD thesis,
Stanford University, 1999.
8. R.S. Boyer and J S. Moore. Integrating Decision Procedures into Heuristic Theorem
Provers: A Case Study of Linear Arithmetic. Machine Intelligence, 11:83–124, 1988.
9. A. Church. A Formulation of the Simple Theory of Types. J. of Symbolic Logic,
5(1):56–68, 1940.
10. F. Corella. What Holds in a Context? J. of Automated Reasoning, 10:79–93, 1993.
11. A. Degtyarev and A. Voronkov.
The Undecidability of Simultaneous Rigid E-
Uniﬁcation. Theoretical Computer Science, 166(1–2):291–300, 1996.
12. H. B. Enderton. A Mathematical Introduction to Logic. Academic Pr., 1972.
13. J.-C. Filliˆatre. Formal Proof of a Program: Find. Science of Computer Program-
ming, To appear.
14. J. H. Gallier, S. Ratz, and W. Snyder. Theorem Proving Using Rigid E-Uniﬁcation:
Equational Matings. In Logic in Computer Science (LICS’87), Ithaca, New York,
1987.
15. Jim Grundy. A Method of Program Reﬁnement. PhD thesis, University of Cam-
bridge, Computer Laboratory, New Museums Site, Pembroke Street, Cambridge
CB2 3QG, England, November 1993. Technical Report 318.
16. C. A. R. Hoare. Algorithm 65, Find. Comm. of the ACM, 4(7):321, July 1961.
17. C. A. R. hoare. Proof of a Program: FIND. Comm. of the ACM, 14(1):39–45,
January 1971.
18. G. Huet, G. Kahn, and C. Paulin-Mohring. The Coq Proof Assistant: a tutorial.
Technical Report 204, INRIA-Rocquencourt, 1997.
19. D. Kapur and X. Nie. Reasoning about Numbers in Tecton. Technical report, De-
partment of Computer Science, State University of New York, Albany, NY 12222,
March 1994.
20. R. Nieuwenhuis and A. Rubio.
Paramodulation-based theorem proving.
In
A. Robinson and A. Voronkov, editors, Hand. of Automated Reasoning. 2001.
21. D. Prawitz.
Natural Deduction. Acta Universitatis Stockholmiensis, Stockholm
Studies in Philosophy 3. Almqvist & Wiksell, Stockholm, 1965.
22. P. J. Robinson and J. Staples. Formalising the Hierarchical Structure of Practical
Mathematical Reasoning. Journal of Logic and Computation, 3(1):47–61, February
1993.
23. S. Schulz. System Abstract: E 0.61. In R. Gor´e, A. Leitsch, and T. Nipkow, editors,
Proc. of the 1st IJCAR, Siena, number 2083 in LNAI, pages 370–375. Springer,
2001.
24. C. Weidenbach and A. Nonnengart. Small clause normal form. In A. Robinson
and A. Voronkov, editors, Hand. of Automated Reasoning. 2001.
25. H. Zhang. Contextual Rewriting in Automated Reasoning. Fundamenta Informa-
ticae, 24(1/2):107–123, 1995.

Inductive Theorem Proving and Computer
Algebra in the MathWeb Software Bus
J¨urgen Zimmer1⋆and Louise A. Dennis2⋆⋆
1 Division of Informatics, University of Edinburgh,
jzimmer@mathweb.org
2 School of Computer Science and Information Technology, University of Nottingham,
lad@cs.nott.ac.uk
Abstract. Reasoning systems have reached a high degree of maturity
in the last decade. However, even the most successful systems are usually
not general purpose problem solvers but are typically specialised on prob-
lems in a certain domain. The MathWeb Software Bus (MathWeb-SB) is
a system for combining reasoning specialists via a common software bus.
We describe the integration of the λ-Clam system, a reasoning specialist
for proofs by induction, into the MathWeb-SB. Due to this integration,
λ-Clam now oﬀers its theorem proving expertise to other systems in
the MathWeb-SB. On the other hand, λ-Clam can use the services of
any reasoning specialist already integrated. We focus on the latter and
describe ﬁrst experiments on proving theorems by induction using the
computational power of the Maple system within λ-Clam.
1
Introduction
Reasoning systems have reached a high degree of maturity in the last decade.1
However, these systems are usually not general purpose problem solvers but
should be seen as reasoning specialists with individual expertise in a certain
domain. Automated Theorem Provers (ATPs), for instance, are specialised in
equality proofs or proof by induction. Some Computer Algebra Systems (CASs)
are, for example, specialised on group theory, others in computations in polyno-
mial rings.
The MathWeb Software Bus (MathWeb-SB) [FK99] provides the means for
inter-operability of reasoning specialists. It connects a wide-range of reasoning
systems (MathWeb services), such as ATPs, CASs, model generators (MGs),
(semi-)automated proof assistants, constraint solvers (CSs), human interaction
units, and automated concept formation systems, by a common mathematical
⋆The author is supported by the European Union IHP grant CALCULEMUS HPRN-
CT-2000-00102.
⋆⋆The author was funded by EPSRC grant Gr/M45030.
1 Throughout this paper, by reasoning system we mean both logic-based Deduction
Systems and computation-based systems such as Computer Algebra Systems or Con-
straint Solvers.
J. Calmet et al. (Eds.): AISC-Calculemus 2002, LNAI 2385, pp. 319–331, 2002.
c
⃝Springer-Verlag Berlin Heidelberg 2002

320
J. Zimmer and L.A. Dennis
software bus. Reasoning systems integrated in the MathWeb-SB can therefore
oﬀer new functionality to the pool of services, and can in turn use all services
oﬀered by other systems. The communication between systems in the Math-
Web-SB is based on the standards OpenMath [CC98] and OMDoc [Koh00] for
encoding mathematical content.
A crucial idea behind frameworks like the MathWeb-SB is that opening ex-
isting reasoning specialists and combining them via a common software bus can
lead to synergetic eﬀects. By using the expertise of other reasoning specialists, a
reasoning system can solve problems that are way beyond its previous problem
solving horizon. A typical example for this kind of synergy is the use of external
reasoning systems, like CASs, MGs, CSs, and ATPs, in the mathematical assis-
tant system Ωmega [BCF+97]. The use of external reasoners allows Ωmega to
solve problems in many diﬀerent domains, such as group theory, analysis, and
economics.
In the last three years we have steadily increased the list of reasoning spe-
cialists integrated in the MathWeb-SB. In this paper, we describe our work in
progress on the integration of the λ-Clam [RSG98] system, a proof planning
system specialised on proof by induction. The advantages of integrating λ-Clam
into the MathWeb-SB are twofold: i) λ-Clam can oﬀer its expertise in inductive
theorem proving to other reasoning systems, e.g., to the Ωmega proof planner
which does not have the expertise to perform inductive proofs, and ii) λ-Clam
can use all reasoning specialists already available in the MathWeb-SB.
For our work we have investigated both directions, λ-Clam oﬀering services
and λ-Clam using external reasoning systems. Due to space limitations we focus
on the latter in this paper, especially on the use of CAS computation in the
λ-Clam proof planner. For our ﬁrst experiments with λ-Clam using CAS we
studied theorems proved by the systems Analytica [CZ92,BCZ98] and CLAM-
Lite [Wal00]. Analytica is a theorem prover implemented in the programming
language of the CAS Mathematica. CLAM-Lite is a simple re-implementation of
the proof planner CLaM [BvHHS90] in Maple’s programming language. Thus,
both systems are based on the (re-)implementation of a theorem prover in the
programming language of a CAS. Preliminary results of our experiments show
that, in principle, we can prove the same theorems as Analytica and CLAM-Lite
using a far more general approach which is even easier to implement, namely the
combination of existing reasoning systems via a software bus. In our case, the
Maple system was already available in the MathWeb-SB which reduced the task
to the integration of λ-Clam and the implementation of services (phrase-books)
for the translation of OpenMath and OMDoc from and to λ-Clam’s logic.
The structure of this paper is as follows. We ﬁrst give brief descriptions
of the MathWeb-SB and the λ-Clam system in sections 2 and 3 respectively.
In section 4, we describe the integration of λ-Clam into the MathWeb-SB. We
also describe the reasoning services oﬀered by λ-Clam and discuss the use of
external reasoning systems in inductive theorem proving in λ-Clam. In section
5 we present ﬁrst results from experiments with λ-Clam using the CAS Maple.

Inductive Theorem Proving and Computer Algebra
321
Birmingham
Pittsburgh
Edinburgh
MathWeb Clients 
MathWeb Servers
broker to broker communication 
client to broker communication (Mozart, XMLRPC, HTTP)
server to broker communication (service offers/requests)
Saarbrücken
Broker
Broker
Broker
Broker
(Lisp)
Client
request
HR
Client
(Java)
Broker
(Mozart)
Maple
MBase
KB
Spass
ATP
Otter
ATP
SEM
MG
Client
Clam
(Prolog)
mega
Ω
λ
CoSIE
CS
E
ATP
forward   request
(un−)   register
CAS
service reference
Fig. 1. The MathWeb Software Bus
We draw a conclusion in section 6 and list various directions for future work in
section 8.
2
The MathWeb Software Bus
The MathWeb Software Bus [FK99] is a platform for distributed automated
reasoning that supports the connection of a wide range of mathematical ser-
vices by a common software bus.2 The MathWeb-SB provides the functionality
for turning existing reasoning systems into mathematical services that are ho-
mogeneously integrated into a networked proof development environment. Each
system beneﬁts from being able to use the features of the other components
in the MathWeb-SB. The MathWeb-SB is implemented in the multi-paradigm
programming language Mozart which enables easy distribution of applications
over a LAN or the Internet [Smo95,Con]. This allows the MathWeb-SB to oﬀer
a stable network of distributed mathematical services that is in every day use.
Client applications can access 23 diﬀerent reasoning systems, for instance, the
CASs Maple, MagMa, and CoCoA, the CS CoSIE, mediators, and MGs such
as Mace and Satchmo. Moreover, the MathWeb-SB integrates nine ﬁrst order
ATPs, such as Otter, Spass, Bliksem, and E.
The current architecture of the MathWeb system is depicted in Fig. 1. Lo-
cal brokers provide routing and authentication information to the mathematical
services. MathWeb-SB servers (wrappers) encapsulate the actual reasoning sys-
tems and oﬀer the mathematical services to their local broker. Brokers register to
other brokers running remotely and thus build a dynamic web of brokers. Client
2 Further information about the MathWeb-SB is available at
http://www.mathweb.org/mathweb/.

322
J. Zimmer and L.A. Dennis
applications such as the Ωmega system, HR, or λ-Clam, connect to one of the
MathWeb brokers and request services. If the requested service is not oﬀered by
a local reasoning system, the broker forwards the request to all known remote
brokers until the service is found. If the requested service is found, the client
application receives a reference to a newly created service object. The client can
then send messages directly to this service object.
The MathWeb-SB originated in the use of external reasoning specialists in
the Ωmega system. It turned out that the use of external reasoners in proof
planning can give valuable support to a human user constructing a proof plan
and can signiﬁcantly extend the problem solving horizon of an automated proof
planner. Currently, Ωmega’s use of external reasoning systems via the Math-
Web-SB can be classiﬁed into the following categories:
– the use of CAS computations during proof planning
– controlling the proof planning process with the help of CAS computation
– sending subgoals to ﬁrst order (higher order) ATPs
– ﬁnding witness terms for existentially quantiﬁed variables using model gen-
erators and constraint solvers
The successful use of these reasoning systems in Ωmega was one of the main
motivations for the work described in this paper, namely the integration λ-Clam
into the MathWeb-SB. On the one hand, λ-Clam can now use all reasoning
specialists available in the MathWeb-SB. On the other hand, λ-Clam can oﬀer
its expertise in inductive theorem proving to other reasoning systems, e.g., the
Ωmega proof planner which does not provide the proof planning methods and
the control knowledge needed for proofs by induction.
In the following, we brieﬂy describe the λ-Clam system and its main reasoning
features.
3
The λ-Clam Proof Planner
λ-Clam [RSG98] is a higher-order proof planning system. It is a descendant of
the CLaM [BvHHS90] series and is specialised for proof by induction, but it is also
intended to allow the rapid prototyping of automated theorem proving strategies.
It is implemented in Teyjus λ-PROLOG which is a higher order extension of
standard PROLOG.
Proof Methods. λ-Clam works by using depth-ﬁrst planning with proof methods.
Atomic methods encode more or less complex reasoning steps ranging from quan-
tiﬁer elimination to the step case of an induction proof or diﬀerence reduction
between a goal and its hypotheses. Atomic methods can be composed to com-
pound methods using methodicals [RS01]. Compound methods oﬀer the means to
deﬁne search strategies at various levels of abstraction. A proof plan produced
by λ-Clam is a tree of the subgoals generated during proof labelled with the
atomic method applications applied to that subgoal. The leaves of the tree are

Inductive Theorem Proving and Computer Algebra
323
the trivial subgoals: true. These proofs are not fully formal but are closer to the
formality of proofs found in mathematical textbooks.
Rippling is one of the most widely used and most powerful proof methods. It
is used for diﬀerence reduction, particularly in inductive proof planning. It was
ﬁrst introduced in [BSvH+93]. The implementation of rippling in λ-Clam is based
on the theory presented by Smaill & Green [SG96] who proposed a version that
naturally coped with higher-order features. The main advantages of rippling are
that it allows an equation to be treated as a rewrite in both directions without
loss of termination and provides useful information for automatically patching
failed proof attempts.
Proof Critics. The methodical expressions which make up compound methods
provide a guide to which proof methods should be chosen at any given stage of
the proof. Knowing which method is expected to apply gives additional informa-
tion in case the system generating the plan fails to apply it. Since heuristics are
employed in the generation of proof plans it is possible for a proof planning sys-
tem to fail to ﬁnd a plan even when one exists. To this end proof critics [IB96] can
be employed to analyse the reasons for failure and propose alternative choices.
The proof critics currently implemented in λ-Clam allow for generalising the
original goal, modifying the chosen induction scheme or speculating a missing
lemma (rewrite rule).
4
λ-Clam in the MathWeb-SB
We integrated λ-Clam into the MathWeb-SB using the methodology that has
been successfully used for the integration of other systems like the Ωmega proof
planner or the higher order theorem prover TPS: A MathWeb-SB wrapper im-
plements the interface to the services oﬀered by λ-Clam and has full control over
λ-Clam by simulating user input using socket communication. λ-Clam itself can
use the wrapper to access other services as external reasoning systems.
4.1
Services Oﬀered by λ-Clam
All services oﬀered and used by λ-Clam are based on the OpenMath [CC98]
and the OMDoc [Koh00] standard. We implemented a translation service (a
phrase-book) to translate incoming formulae, deﬁnitions, and conjectures into
λ-Clam’s higher order abstract syntax. For the sake of eﬃciency, this translation
is performed by the MathWeb-SB wrapper. λ-Clam currently oﬀers two services
to the MathWeb-SB:
planProblem. This service takes an OMDoc document, containing a single con-
jecture, as an argument. The service starts the λ-Clam proof planning mech-
anism on the conjecture. In our current implementation, the service expects
the conjecture to be about natural number arithmetic. We plan an extension
of the service such that clients can also provide the theory the conjecture is
deﬁned in.

324
J. Zimmer and L.A. Dennis
Client applications using the planProblem service can use optional argu-
ments to determine which proof strategy (compound method) λ-Clam should
use for the planning attempt, and to give a time limit in seconds. In the cur-
rent implementation, the service simply returns the OpenMath symbol true
if λ-Clam could ﬁnd a proof plan within the given time limit, and false if
no proof plan could be found.
ripple. We argued in section 3 that rippling is one of the most successful
heuristics for guiding (inductive) proof planning. Therefore, λ-Clam oﬀers
its rippling mechanism as a separate service to the MathWeb-SB. The service
is given a single input formatted using the OMDoc standard. The OMDoc
must contain a non-empty set of rewrite rules, formalised as lemmas, and a
goal sequent H ⊢φ as a conjecture. The ripple service tries to reduce the
diﬀerence between φ and the best suitable hypothesis in H using the rewrite
rules. The ripple service also tries to apply fertilisation to reduce the goal
φ to the trivial goal true. As a result, the service ripple returns an OMDoc
which contains the resulting proof planning goal as a sequent H ⊢φ′.
The services oﬀered by λ-Clam can be used by other reasoning systems via the
MathWeb-SB. First experiments with the use of the planProblem service and the
ripple service within the Ωmega proof planner were successful. We formalised
problems in the natural number theory of Ωmega and implemented proof plan-
ning methods that call the planProblem and the ripple service of λ-Clam to
close open subgoals or to reduce a subgoal to a simpler one, respectively.
One advantage of passing lemmas from Ωmega’s theories as rewrites to
λ-Clam’s ripple service is that the rewriting process is completely indepen-
dent of λ-Clam’s theories. Thus, λ-Clam can be used as an abstract rewriting
engine whose termination is guaranteed. However, the current version of λ-Clam
does not maintain a trace of the positions of the subterms to which a rewrite
rules was applied. The latter would allow the ripple service to tell a client ap-
plication, like Ωmega, exactly which rewrite has been applied to which subterm
of the planning goal not just the rewrite rule that had been applied to that goal.
Ωmega could then use this information to construct a natural deduction proof
for the reasoning steps performed during rippling.
4.2
λ-Clam Using MathWeb Services
For the use of external reasoning systems, we extended λ-Clam by a module
which abstracts from socket communication details and oﬀers a convenient in-
terface to MathWeb-SB wrapper. Furthermore, we implemented a module to
translate λ-Clam’s formulae into the OpenMath standard using the core Open-
Math Content Dictionaries (CDs). Thus, the module forms the second half of
an OpenMath phrase-book for λ-Clam. Using the mathweb module, λ-Clam
can now access every reasoning system available in the MathWeb-SB. We are
currently thinking of the following applications of external reasoners in λ-Clam:
Using ATPs to prove simple subgoals: This approach has already been
used in the Ωmega proof planner to restrict the search space. In some cases,

Inductive Theorem Proving and Computer Algebra
325
even higher order problems can be transformed to ﬁrst order problems and
then sent to one or more ﬁrst order ATPs in the MathWeb-SB.
Using ATPs on the control level: It is a known shortcoming of λ-Clam that
it does not check the consistency of hypotheses after performing a case split.
This leads to λ-Clam missing easy proofs by inconsistency. Modern ATPs are
very eﬃcient and could detect trivial inconsistencies in a few milliseconds.
We therefore try to prune inconsistent search paths in proof planning with
the help of ATPs like Otter.
CAS computation in proof planning: Due to our positive experience with
CAS computations in many proof planning domains, we think that the use
of CASs in inductive proof planning can enable λ-Clam to solve problems it
couldn’t solve before. The rewriting capabilities of a CAS can complement
the rewriting of λ-Clam and can thus enhance the reasoning capabilities of
λ-Clam.
In our work, we followed all three applications of external reasoning system
but focused on the last application, namely the use of Maple’s simpliﬁcation
in inductive proof planning. On the Maple side, we therefore extended the
simplifyTerm service. This service now accepts a term (formula) in OpenMath
representation. It returns the OpenMath representation of the term (formula)
resulting from the call of the simplify function of Maple. Before this extension,
simplifyTerm accepted only Maple syntax. To allow the access of external
reasoning systems in the proof planner, we implemented two new proof methods
for λ-Clam. The method otter can be used to send an open subgoal to the ATP
Otter. The maple simplify method calls the simplifyTerm service of Maple
on the current subgoal and introduces the resulting formula as a new subgoal.
λ-Clam treats both these systems as oracles and simply labels the appropriate
node in the proof plan with the name of the Oracle.
In the following section we present ﬁrst experience with the use of Maple in
λ-Clam.
5
Using Maple in λ-Clam
Our experiments should rather be seen as a proof of concept than as an extensive
case study. So far, we have focused on theorems taken from two works: The Ana-
lytica theorem prover and the CLAM-Lite proof planner. All theorems have been
formalised in λ-Clam’s theories and will be available in version 3.2 of λ-Clam. In
the following, we describe the theorems we have been looking at so far and give
examples for the rewriting (simpliﬁcation) performed by Maple in the diﬀerent
cases. As we mentioned above, the communication between λ-Clam and Maple
is fully based on the OpenMath standard, but for the sake of readability we
use a convenient mathematical notation here.
5.1
Analytica Theorems
The Analytica system [CZ92,BCZ98] is a theorem prover implemented in the pro-
gramming language of the CAS Mathematica. It is based on rewriting and uses

326
J. Zimmer and L.A. Dennis
term simpliﬁcation and other computations available in Mathematica. E. Clarke
and X. Zhao used their system to prove rather complex theorems in real-valued
standard analysis, such as theorems about inequalities, limit theorems, ﬁnite
sums, and about the convergence of series. Analytica can also prove that a func-
tion found by Weierstrass is continuous over the real numbers but nowhere dif-
ferentiable.
Since λ-Clam is specialised to inductive proofs we ﬁrst tried to prove Analyt-
ica problems that require induction. We formalised the two induction problems
presented in [CZ92] and [BCZ98]. The ﬁrst theorem gives a closed representation
for the Fibonacci numbers:
Theorem 1. Let Fib(n) be the nth Fibonacci number, i.e. Fib(0) = 0, Fib(1) =
1, and ∀n ∈N. n ≥2 ⇒Fib(n) = Fib(n −1) + Fib(n −2). Then the following
holds:
∀n. Fib(n) = (1+
√
5)n−(1−
√
5)n
2n√
5
.
Proving Theorem 1 requires complex reasoning about the square root function
and exponentiation which is very hard if not infeasible to encode as rewriting
rules in λ-Clam. λ-Clam therefore uses Maple’s simpliﬁcation whenever the
rewrite rules initially given are not suﬃcient to perform the required reason-
ing steps. λ-Clam uses the following induction scheme for the proof planning
attempt:
P (0)∧P (s(0))∧∀n. (P (n)∧P (s(n))⇒P (s(s(n))))
∀n. P (n)
,
where s is the successor function on the natural numbers. In the step case (P(n)∧
P(s(n)) ⇒P(s(s(n))) of the inductive proof, λ-Clam uses the deﬁnition of the
Fibonacci numbers to rewrite the goal until no rewriting is applicable anymore.
At this point of the proof λ-Clam tries to apply the maple simplify method
which performs the following rewriting:
(1+
√
5)n−(1−
√
5)n
2n·
√
5
+ (1+
√
5)n+1−(1−
√
5)n+1
2n+1·
√
5
= (1+
√
5)n+2−(1−
√
5)n+2
2n+2·
√
5
⇝
1
10 · 5
1
2 · 2−n · (3 · (1 + 5
1
2 )n −3 · (1 −5
1
2 )n + ( 1 + 5
1
2 )n · 5
1
2 + (1 −5
1
2 )n · 5
1
2 =
1
10 · 5
1
2 · 2−n · (3 · (1 + 5
1
2 )n −3 · (1 −5
1
2 )n + (1 + 5
1
2 )n · 5
1
2 + (1 −5
1
2 )n · 5
1
2 .
λ-Clam can easily reduce the resulting goal to the trivial goal by applying equal-
ity reﬂexivity.
The second theorem proved by λ-Clam is taken from [BCZ98] and gives a
closed form of a modiﬁed geometric sum:
Theorem 2. For all natural numbers m ̸= 1 the following holds:
∀n.
n
k=0
2k
1+m2k =
1
m−1 +
2n+1
1−m2n+1
During the planning for this theorem, one crucial simpliﬁcation step that
cannot be performed by λ-Clam, but by Maple, occurs in the step case:
1
−1+m +
2
1−m2 ⇝
1
1+m.

Inductive Theorem Proving and Computer Algebra
327
5.2
CLAM-Lite Theorems
In [WNB92], T. Walsh, A. Nunes and A. Bundy presented automatically synthe-
sised closed forms of sums. Recently, T. Walsh implemented the simple “proof
planning” shell CLAM-Lite in the CAS Maple and used his system to prove the
correctness of some of these closed forms using Maple computations [Wal00].
We formalised all theorems of [WNB92] in λ-Clam and tried to prove them
using Maple via the MathWeb-SB. The theorems and results are shown in Fig.
2.
λ-Clam
No
Closed Form
CLAM-Lite using Maple
3
 i = n·(n+1)
2
+
+
4
 i2 = 2n3+3n2+n
6
+
+
5
 i + i2 = 2n3+6n2+4n
6
+
+
6
 ai = an+1−1
a−1
+
+
7
 iai =
(n+1)an+1−a· an+1−1
a−1
a−1
+
-
8 (i + 1) · ai = (n+1)an+1
a−1
−an+1−1
(a−1)2
+
+
9

1
i(i+1) =
n
n+1
+
-
10
 Fib(i) = Fib(n + 2) −1
-
+
Fig. 2. Closed forms proved by CLAM-Lite and by λ-Clam. All sums are over i from
0 to n, a ̸= 1
A plus sign in the column for CLAM-Lite or λ-Clam means that the respec-
tive system could ﬁnd a proof plan for the problem at hand. A minus indicates
failure.
The proof of Theorem 3 in λ-Clam is very similar to the proof presented
in [Wal00] and Maple performs the same rewriting in the step case of the proof.
The reason for λ-Clam’s failure on Theorems 7 and 9 is more a technical than a
conceptual problem: The normal form of terms returned by Maple is sometimes
much bigger than the original term and due to a bug in Teyjus λ-PROLOG (the
implementation language of λ-Clam), λ-Clam can currently not read in terms
that exceed a certain size.
Interestingly, CLAM-Lite could not ﬁnd a proof plan for Theorem 10 al-
though it had access to the same version of Maple that λ-Clam is using. On
the other hand, λ-Clam could ﬁnd a proof plan, using Maple to perform the
following rewrite at the end of the step case:
(Fib(n) + Fib(n + 1) −1) + Fib(n + 1) = (Fib(n + 1) + (Fib(n) + Fib(n + 1))) −1
⇝2 · Fib(n + 1) + Fib(n) −1 = 2 · Fib(n + 1) + Fib(n) −1,
which again is diﬃcult to perform solely with rewriting in λ-Clam because we
would have to deﬁne a special term ordering to guaranty the termination of the
rewriting system. Walsh names the simplicity of CLAM-Lite’s planning methods
as a reason for CLAM-Lite’s failure on Theorem 10. The fact that λ-Clam could

328
J. Zimmer and L.A. Dennis
prove the theorem underlines our thesis that it is a better choice to combine
existing deduction systems via protocols instead of re-implementing them on
top of a Computer Algebra System.
6
Conclusion
We describe the integration of the λ-Clam proof planner that is specialised to
inductive theorem proving into the MathWeb-SB. We described the advantages
of this integration: λ-Clam can now oﬀer its expertise in proof by induction to
other reasoning systems in the MathWeb-SB and can use the reasoning services
already oﬀered in the MathWeb-SB. We focused on the latter and described ﬁrst
experiments with the use of the CAS Maple in λ-Clam to prove theorems about
Fibonacci numbers and closed forms of sums. λ-Clam could not ﬁnd proof plans
for these theorems without Maple’s computational power. This paper describes
work in progress and we hope to present more results in the ﬁnal version.
7
Related Work
Several frameworks for the combination of reasoning systems have been devel-
oped. The Logic Broker Architecture (LBA) [AZ00] is most similar to the Math-
Web-SB. It is a platform for the distributed automated reasoning based on the
distribution facilities of the Corba middle-ware and the OpenMath standard.
The Prosper project [DCN+00] aims at developing the technology needed
to deliver the beneﬁts of formal speciﬁcation and veriﬁcation to system designers
in industry. The central idea of the Prosper project is that of a proof engine (a
custom built veriﬁcation engine) which can be accessed by applications via an
application programming interface (API). This API is supposed to support the
construction of CASE-tools.
Our experiments were strongly inspired by our positive experience with the
use of CAS computations in the Ωmega proof planner [KKS96]. Similar work
has been done for an integration of CASs in the higher order theorem prover
HOL [HT93] and for the Maple-PVS interface described in [DGKM01].
8
Future Work
The preliminary results we got from our experiments with the use of CAS in
inductive proof planning were promising and in the near future we will extend
our experiments to a fully-ﬂedged case study. We are going to formalise more
theorems about closed forms of summations and try to ﬁnd proof plans for these
theorems. We plan a more detailed comparison of our work with [Wal00] also on
the basis of quantitative results (runtime comparisons).
λ-Clam oﬀers the means to formalise and prove theorems in non-standard
analysis (NSA) [MFS02]. Using NSA, λ-Clam could already ﬁnd proof plans for
the limit theorems Lim+ and Lim-Times and some other analysis theorems,

Inductive Theorem Proving and Computer Algebra
329
e.g., the mean-value theorem. In contrast to the classical ϵ-δ proofs, NSA proofs
tend to be much shorter and more intuitive. Hence, it would be interesting to use
λ-Clam’s NSA theory to construct alternative proofs for some of the complex
theorems proved by the Analytica system using the computational power of CASs
available in the MathWeb-SB.
We hope in future to experiment, where appropriate, with the communication
of plans between systems. This would allow λ-Clam’s proof plans to be replayed
in an LCF-style theorem prover to produce fully formal proofs. It would also
allow the output of oracles such as Maple to be expanded within λ-Clam to
alleviate concerns about the combinations of diﬀerent logics etc.
The proper use of context in the communication between reasoning systems
is still an open research question. Context can not only reduce the amount
of information that has to be transfered between systems, it is also crucial to
establish more complex forms of collaboration and coordination between reason-
ing systems. The λ-Clam proof planner, for instance, oﬀers the powerful critics
mechanism which analyses the failure of a proof attempt and gives feedback to
the user about possible ways of correcting the proof. This feedback can include
generalising the original goal, modifying the chosen induction scheme, or specu-
lating a new rewrite rule. Potentially this feedback could also be given to another
reasoning system using λ-Clam and this would involve far more complex inter-
actions in terms of context. For instance, if λ-Clam were to suggest modifying
the induction scheme this new proposed scheme might have to be transmitted
back to the client system for veriﬁcation in terms of its own logic. To enable this
form of ﬁne-grained interaction between reasoning systems we plan to develop a
general notion of context in inter-system communication and to use λ-Clam as
a prototypical reasoning system that builds up a context.
References
[AZ00]
A. Armando and D. Zini. Towards Interoperable Mechanized Reasoning
Systems: the Logic Broker Architecture. In A. Poggi, editor, Proceedings
of the AI*IA-TABOO Joint Workshop ‘From Objects to Agents: Evolu-
tionary Trends of Software Systems’, Parma, Italy, May 2000.
[BCF+97]
C. Benzm¨uller, L. Cheikhrouhou, D. Fehrer, A. Fiedler, X. Huang, M. Ker-
ber, K. Kohlhase, A. Meirer, E. Melis, W. Schaarschmidt, J. Siekmann,
and V. Sorge. Ωmega: Towards a mathematical assistant. In W. McCune,
editor, Proc. of the 14th Conference on Automated Deduction, volume
1249 of LNAI, pages 252–255. Springer Verlag, 1997.
[BCZ98]
A. Bauer, E. Clarke, and X. Zhao. Analytica — an Experiment in Combin-
ing Theorem Proving and Symbolic Computation. Journal of Automated
Reasoning (JAR), 21(3):295–325, 1998.
[BSvH+93]
A. Bundy, A. Stevens, F. van Harmelen, A. Ireland, and A. Smaill. Rip-
pling: A heuristic for guiding inductive proofs. AI, 62:185–253, 1993. Also
available from Edinburgh as DAI Research Paper No. 567.

330
J. Zimmer and L.A. Dennis
[BvHHS90]
A. Bundy, F. van Harmelen, C. Horn, and A. Smaill. The Oyster-Clam
system. In M. E. Stickel, editor, Proc. of the 10th International Conference
on Automated Deduction, pages 647–648. Springer-Verlag, 1990. LNAI No.
449. Also available from Edinburgh as DAI Research Paper 507.
[CC98]
O. Caprotti and A. M. Cohen. Draft of the Open Math standard. The
Open Math Society,
http://www.nag.co.uk/projects/OpenMath/omstd/, 1998.
[Con]
The Mozart Consortium. The mozart programming system.
http://www.mozart-oz.org/.
[CZ92]
E. Clarke and X. Zhao. Analytica – A Theorem Prover for Mathematica.
Technical Report CMU//CS-92-117, Carnegie Mellon University, School
of Computer Science, October 1992.
[DCN+00]
L. A. Dennis, G. Collins, M. Norrish, R. Boulton, K. Slind, G. Robinson,
M. Gordon, and T. Melham. The prosper toolkit. In Proc. of the 6th
International Conference on Tools and Algorithms for the Construction
and Analysis of Systems, TACAS-2000, LNCS, Berlin, Germany, 2000.
Springer Verlag.
[DGKM01]
M. Dunstan, H. Gottliebsen, T. Kelsey, and U. Martin.
A maple-pvs
interface. Proc. of the Calculemus Symposium 2001, 2001.
[FK99]
A. Franke and M. Kohlhase. System description: MathWeb, an agent-
based communication layer for distributed automated theorem proving.
In Harald Ganzinger, editor, Proc. of the 16th Conference on Automated
Deduction, volume 1632 of LNAI, pages 217–221. Springer Verlag, 1999.
[HT93]
J. Harrison and L. Th´ery. Extending the HOL Theorem Prover with a
Computer Algebra System to Reason About the Reals. In C.-J. H. Seger
J. J. Joyce, editor, Higher Order Logic Theorem Proving and its Applica-
tions (HUG ‘93), volume 780 of LNCS, pages 174–184. Springer Verlag,
1993.
[IB96]
A. Ireland and A. Bundy. Productive use of failure in inductive proof.
JAR, 16(1–2):79–111, 1996. Also available as DAI Research Paper No
716, Dept. of Artiﬁcial Intelligence, Edinburgh.
[KKS96]
M. Kerber, M. Kohlhase, and V. Sorge. Integrating Computer Algebra
with Proof Planning. In Jaques Calmet and Carla Limongelli, editors,
Design and Implementation of Symbolic Computation Systems; Interna-
tional Symposium, DISCO ’96, Karlsruhe, Germany, September 18-20,
1996; Proc., volume 1128 of LNCS. Springer Verlag, 1996.
[Koh00]
M. Kohlhase. OMDoc: An open markup format for mathematical doc-
uments. Seki Report SR-00-02, Fachbereich Informatik, Universit¨at des
Saarlandes, 2000. http://www.mathweb.org/omdoc.
[MFS02]
E. Maclean, J. Fleuriot, and A. Smaill. Proof-planning non-standard anal-
ysis. In Proc. of the 7th International Symposium on Artiﬁcial Intelligence
and Mathematics, 2002.
[RS01]
J. Richardson and A. Smaill. Continuations of proof strategies. In Maria
Paola Bonacina and Bernhard Gramlich, editors, Proc. of the 4th Interna-
tional Workshop on Strategies in Automated Deduction, Siena, Italy, June
2001.
[RSG98]
J.D.C. Richardson, A. Smaill, and I. Green. System description: Proof
planning in higher-order logic with lambda-clam.
In C. Kirchner and
H. Kirchner, editors, Proc. of the 15th International Conference on Auto-
mated Deduction, volume 1421 of LNCS, pages 129–133. Springer-Verlag,
1998.

Inductive Theorem Proving and Computer Algebra
331
[SG96]
A. Smaill and I. Green. Higher-order annotated terms for proof search.
In Joakim von Wright, Jim Grundy, and John Harrison, editors, The-
orem Proving in Higher Order Logics: 9th International Conference,
TPHOLs’96, volume 1275 of LNCS, pages 399–414, Turku, Finland, 1996.
Springer-Verlag. Also available as DAI Research Paper 799.
[Smo95]
G. Smolka. The Oz programming model. In Jan van Leeuwen, editor,
Computer Science Today, volume 1000 of LNCS, pages 324–343. Springer-
Verlag, Berlin, 1995.
[Wal00]
T. Walsh. Proof Planning in Maple. In Proc. of the CADE-17 workshop
on Automated Deduction in the Context of Mathematics, 2000.
[WNB92]
T. Walsh, A. Nunes, and A. Bundy. The use of proof plans to sum series. In
D. Kapur, editor, Proc. of the 11th Conference on Automated Deduction,
volume 607 of LNCS, pages 325–339, Saratoga Spings, NY, USA, 1992.
Springer Verlag.

Yacas: A Do-It-Yourself Symbolic Algebra
Environment
Ayal Z. Pinkus1 and Serge Winitzki2
1 3e Oosterparkstraat 109-III, Amsterdam, The Netherlands (apinkus@xs4all.nl)
2 Tufts Institute of Cosmology, Department of Physics and Astronomy, Tufts
University, Medford, MA 02155, USA (serge@cosmos.phy.tufts.edu)
Abstract. We describe the design and implementation of Yacas, a free
computer algebra system currently under development. The system con-
sists of a core interpreter and a library of scripts that implement symbolic
algebra functionality. The interpreter provides a high-level weakly typed
functional language designed for quick prototyping of computer algebra
algorithms, but the language is suitable for all kinds of symbolic manip-
ulation. It supports conditional term rewriting of symbolic expression
trees, closures (pure functions) and delayed evaluation, dynamic creation
of transformation rules, arbitrary-precision numerical calculations, and
ﬂexible user-deﬁned syntax using inﬁx notation. The library of scripts
currently provides basic numerical and symbolic functionality. The main
advantages of Yacas are: free (GPL) software; a ﬂexible and easy-to-use
programming language with a comfortable and adjustable syntax; cross-
platform portability and small resource requirements; and extensibility.
1
Introduction
Yacas is a computer algebra system (CAS) which has been in development since
the beginning of 1999. The goal was to make a small system that allows to easily
prototype and research symbolic mathematics algorithms. A secondary future
goal is to evolve Yacas into a full-blown general purpose CAS.
Yacas is primarily intended to be a research tool for easy exploration and
prototyping of algorithms of symbolic computation. The main advantage of Ya-
cas, besides being free software, is its rich and ﬂexible scripting language. The
language is closely related to LISP [WH89] but has a recursive descent inﬁx
grammar parser [ASU86], includes expression transformation (term rewriting),
and supports deﬁning inﬁx operators at run time similarly to Prolog [B86].
The Yacas language interpreter comes with a library of scripts that imple-
ment a set of computer algebra features. The Yacas script library is in active
development and at the present stage does not oﬀer the rich functionality of
industrial-strength systems such as Mathematica or Maple. Extensive imple-
mentation of algorithms of symbolic computation is one of the future develop-
ment goals.
Yacas handles input and output in plain ASCII, either interactively or in
batch mode. (A graphical interface is under development.) There is also an op-
J. Calmet et al. (Eds.): AISC-Calculemus 2002, LNAI 2385, pp. 332–336, 2002.
c
⃝Springer-Verlag Berlin Heidelberg 2002

Yacas: A Do-It-Yourself Symbolic Algebra Environment
333
tional plugin mechanism whereby external libraries can be linked into the system
to provide extra functionality.
Yacas currently (at version 1.0.49) consists of approximately 22000 lines of
C++ code and 13000 lines of script code, with 170 functions deﬁned in the C++
kernel and 600 functions deﬁned in the script library.
2
Basic Design
Yacas consists of a “core engine” (kernel), which is an interpreter for the Yacas
scripting language, and a library of script code.
The Yacas engine has been implemented in a subset of C++ which is sup-
ported by almost all C++ compilers. The design goals for Yacas core engine
are: portability, self-containment (no dependence on extra libraries or packages),
ease of implementing algorithms, code transparency, and ﬂexibility. The Yacas
system as a whole falls into the “prototype/hacker” rather than into the “ax-
iom/algebraic” category, according to the terminology of Fateman [F90]. There
are relatively few speciﬁc design decisions related to mathematics, but instead
the emphasis is made on extensibility.
The kernel oﬀers suﬃciently rich but basic functionality through a limited
number of core functions. This core functionality includes substitutions and
rewriting of symbolic expression trees, an inﬁx syntax parser, and arbitrary pre-
cision numerics. The kernel does not contain any deﬁnitions of symbolic mathe-
matical operations and tries to be as general and free as possible of predeﬁned
notions or policies in the domain of symbolic computation.
The plugin inter-operability mechanism allows to extend the Yacas kernel
or to use external libraries, e.g. GUI toolkits or implementations of special-
purpose algorithms. A simple C++ API is provided for writing “stubs” that
make external functions appear in Yacas as new core functions. Plugins are on
the same footing as the Yacas kernel and can in principle manipulate all Yacas
internal structures. Plugins can be compiled either statically or dynamically as
shared libraries to be loaded at runtime from Yacas scripts.
The script library contains declarations of transformation rules and of func-
tion syntax (preﬁx, inﬁx etc.). The intention is that almost all symbolic manip-
ulation algorithms and deﬁnitions of mathematical functions should be held in
the script library and not in the kernel.
For example, the mathematical operator “+” is an inﬁx operator deﬁned in
the library scripts. To the kernel, this operator is on the same footing as any other
function deﬁned by the user and can be redeﬁned. The Yacas kernel itself does
not store any properties for this operator. Instead it relies entirely on the script
library to provide transformation rules for manipulating expressions involving
the operator “+”. In this way, the kernel does not need to anticipate all possible
meanings of the operator “+” that users might need in their calculations.

334
A.Z. Pinkus and S. Winitzki
3
Advantages of Yacas
The “policy-free” kernel design means that Yacas is highly conﬁgurable through
its scripting language. It is possible to create an entirely diﬀerent symbolic ma-
nipulation engine based on the same kernel, with diﬀerent syntax and diﬀerent
naming conventions, by loading another script library. An example of the ﬂex-
ibility of the Yacas system is a sample script wordproblems.ys. It contains
a set of rule deﬁnitions that make Yacas recognize simple English sentences,
e.g. “Tom has 3 chairs” or “Jane gave an apple to Jill”, as valid Yacas expres-
sions. Yacas can then “evaluate” these sentences to True or False according
to the semantics of the described situation.
This example illustrates a major advantage of Yacas—the ﬂexibility of its
syntax. Although Yacas works internally as a LISP-style interpreter, the script
language has a C-like grammar. Inﬁx operators deﬁned in the script library or by
the user may contain non-alphabetic characters such as “=” or “#”. This means
that the user works with a comfortable and adjustable inﬁx syntax, rather than
a LISP-style syntax. The user can introduce such syntactic conventions as are
most convenient for a given problem. For example, algebraic expressions can be
entered in the familiar inﬁx form such as
(x+1)ˆ2 - (y-2*z)/(y+3) + Sin(x*Pi/2)
The same syntactic ﬂexibility is available for deﬁning transformation rules. Sup-
pose the user needs to reorder expressions containing non-commutative oper-
ators of quantum theory. It takes about 20 rules to deﬁne an inﬁx operation
“**” to express non-commutative multiplication with the appropriate commu-
tation relations and to automatically reorder all expressions involving both non-
commutative and commutative factors. Thanks to the Yacas parser, the rules
for the new operator can be written in a simple and readable form. Once the
operator “**” is deﬁned, the rules that express distributivity of this operation
with respect to addition may look like this:
15 # (_x + _y) ** _z <-- x ** z + y ** z;
15 # _z ** (_x + _y) <-- z ** x + z ** y;
Here, “15 #” is a speciﬁcation of the rule precedence, “_x” denotes a pattern-
matching variable x and the expression to the right of “<--” is to be substituted
instead of a matched expression on the left hand side.
Rule-based and functional programming can be freely combined with pro-
cedural programming style when the latter is more appropriate for reasons of
eﬃciency or simplicity. Standard patterns of procedural programming, such as
subroutines that return values, with code blocks and temporary local variables,
the familiar if / else construct and For(), ForEach() loop functions are de-
ﬁned in the script library for the convenience of users. The Yacas interpreter is
suﬃciently powerful to deﬁne these functions in the script library itself rather
than in the kernel. This power is fully given to the user, since the library scrips
are on the same footing as any user-deﬁned code. Many library functions are
intended mainly as tools available to a Yacas user to make algorithm imple-
mentation more comfortable.

Yacas: A Do-It-Yourself Symbolic Algebra Environment
335
4
The Yacas Kernel Functionality
Yacas script is a functional language based on various ideas that seemed useful
for an implementation of a CAS: list-based data structures, object properties,
functional programming (`a la LISP); term rewriting [BN98] with pattern match-
ing somewhat along the lines of Mathematica; user-deﬁned inﬁx operators ´a la
PROLOG; delayed evaluation of expressions; and arbitrary precision arithmetic.
Garbage collection is implemented through reference counting.
The kernel provides three basic data types: numbers, strings, and atoms and
two container types: list and static array (for speed). Additional container or data
types (“generic objects”) can be made available through C++ plugins. Atoms
are implemented as strings that can be assigned values and evaluated. Boolean
values are simply atoms True and False. Hash tables, stacks, and closures (pure
functions) are implemented using nested lists. Kernel primitives are available
for arbitrary precision arithmetic, string and list manipulation, control ﬂow,
deﬁning transformation rules, and declaring function syntax. Expression trees
are internally represented by nested lists. Expressions can be “tagged” (assigned
a “property object” `a la LISP).
The interpreter engine recursively evaluates expression trees according to
the transformation rules from the script library. Evaluation proceeds from the
leaves of the tree upwards. The engine tries to apply all existing rules to each
subexpression, rewriting leaves or branches of the expression tree, until no more
rules apply. This type of semantic matching has been implemented in the past
(see, e.g., [C86]). However, the Yacas language includes some advanced features
to create a more ﬂexible and powerful term rewriting system.
Rules have predicates that determine whether a rule should be applied to an
expression. Predicates can be any Yacas expressions that evaluate to the atoms
True or False and are typically functions of pattern variables.
All rules are assigned a precedence value (a positive integer) and rule match-
ing is attempted in the order of precedence. (Thus Yacas provides somewhat
better control over the automatic recursion than e.g. the pattern-matching sys-
tem of Mathematica which does not allow for rule precedence.) Using rule
precedence and predicates, a recursive implementation of the integer factorial
function may look like this:
10 # Factorial(0) <-- 1;
20 # Factorial(n_IsInteger) _ (n>0) <-- n*Factorial(n-1);
The rules have precedence 10 and 20, therefore the ﬁrst rule will be tried ﬁrst
and the recursion will stop when n = 0 is reached.
New rules can be deﬁned dynamically as a side-eﬀect of evaluation. This
means that there is no predeﬁned “ranking alphabet” of “ground terms” (in the
terminology of [TATA99]). It is possible to deﬁne a “rule closure” that deﬁnes
rules depending on its arguments, or to erase rules. Thus, a (read-only) Yacas
script library does not actually represent a ﬁxed tree rewriting automaton; an
implementation of machine learning is possible.

336
A.Z. Pinkus and S. Winitzki
The Knuth-Bendix termination algorithm [KB70] is not used because rules
in Yacas are not an expression of mathematical equivalence but a programming
technique. Termination is the responsibility of the user who has complete control
over the order of rule application.
5
Current Status
Currently, the script library implements basic algorithms of computer algebra:
manipulation of polynomials and elementary functions, limits, derivatives and
(basic) symbolic integration, solution of (simple) equations, and some special-
purpose functions. (The primary sources of inspiration were the books [K98],
[GG99] and [B86].) The system is free (GNU GPL) software and comes with
ample documentation to facilitate cooperative development. The main Internet
site for Yacas is http://www.xs4all.nl/˜apinkus/.
The main development platform is GNU/Linux, but Yacas runs also under
various Unix ﬂavors, Windows environments, Psion organizers (EPOC32), Ipaq
PDAs running the Linux kernel, BeOS, and Mac OS X. Creating an executable
for another platform (including embedded platforms) should not be diﬃcult.
In the future, Yacas is intended to grow into a general-purpose CAS as well
as a repository and a testbed of algorithms. In our opinion, Yacas is a promising
research tool for exploring symbolic computation.
References
[ASU86]
A. Aho, R. Sethi and J. Ullman, Compilers (Principles, Techniques and
Tools), Addison-Wesley, 1986.
[B86]
I. Bratko, Prolog (Programming for Artiﬁcial Intelligence), Addison-
Wesley, 1986.
[BN98]
F. Baader and T. Nipkow, Term rewriting and all that, Cambridge Uni-
versity Press, 1998.
[C86]
G. Cooperman, A semantic matcher for computer algebra, in Proceedings
of the symposium on symbolic and algebraic computation (1986), Water-
loo, Ontario, Canada (ACM Press, NY).
[F90]
R. Fateman, On the design and construction of algebraic manipulation
systems, also published as: ACM Proceedings of the ISSAC-90, Tokyo,
Japan.
[GG99]
J. von zur Gathen and J. Gerhard, Modern Computer Algebra, Cambridge
University Press, 1999.
[K98]
D. E. Knuth, The Art of Computer Programming (Volume 2, Seminumer-
ical Algorithms), Addison-Wesley, 1998.
[KB70]
D. E. Knuth and P. B. Bendix, Simple word problems in universal alge-
bras, in Computational problems in abstract algebra, ed. J. Leech, p. 263,
Pergamon Press, 1970.
[TATA99]
H. Comon, M. Dauchet, R. Gilleron, F. Jacquemard, D. Lugiez, S. Ti-
son, and M. Tommasi, Tree Automata Techniques and Applications, 1999,
online book: http://www.grappa.univ-lille3.fr/tata
[WH89]
P. Winston and B. Horn, LISP, Addison-Wesley, 1989.

Focus Windows: A New Technique for Proof
Presentation⋆
Florina Piroi and Bruno Buchberger
Research Institute For Symbolic Computation,
4232 Hagenberg, Austria
{fpiroi,buchberg}@risc.uni-linz.ac.at
Abstract. Whether they are hand written or generated by an auto-
mated prover, long proofs may be diﬃcult to understand and follow.
The main reason for this is that at some point in the proof formulae
that occur lines, paragraphs or even pages before, are used. The proof
presentation method proposed here tries to overcome this by showing, in
each proof step, exactly the formulae that are relevant for the particular
proof step. We describe the implementation of this method in the frame
of the Theorema system.
1
Introduction
Proofs in mathematical publications are linear texts. We view them as sequences
of proof steps, i.e. at each step a new formula is derived from formulae appearing
in earlier steps, by some proof technique. In long proofs, the used formulae may
occur a couple of lines, paragraphs, or even pages distant from the place where
they are used. These formulae are usually referred by labels and the reader has
to jump back and forth between the referenced formulae and the proof step in
which they are needed. This is unpleasant and makes understanding proofs quite
diﬃcult even if the proofs are nicely structured and well presented.
Most automated theorem provers do not put emphasis on producing proofs
that are easy to read and understand. (A telling illustration of this is given in
[7].) Even those which provide tools for studying proofs (as, for example, the
Omega system [5]) have the problem described above.
From the outset, in Theorema [2] we tried to emphasize on attractive proof
presentation. Theorema proofs are designed to resemble proofs generated by
humans, i.e. they contain formulae and explanatory text in english. In addi-
tion, Theorema provides various tools that help the reader in browsing proofs:
references to formulae are realized as hyper–links that display the referenced
formula in a small auxiliary window; nested brackets at the right–hand margin
make contracting entire sub–proofs to just one line possible; various color codes
distinguish the (temporary) proof goals from the (temporary) knowledge base
⋆partially supported by the RISC PhD scholarship program of the government of
Upper Austria and by the FWF (Austrian Science Foundation) SFB project P1302
J. Calmet et al. (Eds.): AISC-Calculemus 2002, LNAI 2385, pp. 337–341, 2002.
c
⃝Springer-Verlag Berlin Heidelberg 2002

338
F. Piroi and B. Buchberger
formulae; etc. Still, reading and understanding long linear proofs is diﬃcult even
for proofs generated by the typical Theorema provers.
Focus windows provide means to overcome this diﬃculty. The idea of focus
windows as a technique for proof presentation was introduced in [1] and is as
follows: Starting from the root of a proof object, in each proof step, one analyzes
which formulae are used and which ones are produced. Then, a window contain-
ing exactly these formulae for the proof step that is being analyzed is composed.
The window also contains buttons for moving to, and analyzing the next proof
step in the proof. For proof steps that branch into two or more sub–proofs the
subsequent windows are displayed in contracted form the user being allowed to
decide which one to open next.
In the following we give some comments on the Focus Windows from the
user’s point of view. In Section 3, we brieﬂy describe the implementation of the
Focus Windows technique in Theorema and then present the ﬁnal conclusions.
2
Using Focus Windows
In this section we try to shortly present the Focus Windows from the user’s side.
A typical call for starting a Theorema prover to work on a proof problem
looks like this:
Prove[Lemma[“Lm”], using →KnowledgeBase, by →SomeProver,
ProverOptions →{options for the Prover}, showBy →SomeDisplayer];
The user of Theorema can control both the work of SomeProver by setting the
ProverOptions and the way the proof is presented by setting the showBy option.
By default, Theorema will present the proof in a new Mathematica notebook as
a linear proof text. By setting showBy →FocusWindows the Focus Windows
display method will be invoked. (For a complete description of the options of
the Prove command and other details about Theorema see [8], [6]).
As mentioned before, the Focus Windows method presents proofs in a step–
wise manner. Each step of the proof will be shown to the user in two phases: the
attention phase and the transformation phase with the corresponding Attention
Window (the formulae inferred at the inspected proof step are not yet shown to
the user) and the Transformation Window. Each of these windows has
• a “goal area” in which the current goals are shown,
• an “assumptions area” in which the “relevant” assumptions are shown,
• a “proof tree area” in which the proof tree is displayed in a schematic form,
• an area that presents all the assumptions that are available (the “all as-
sumptions area”),
• and a “navigation area” that allows the user to step forward or backward
in the proof, in the order suggested by the prover that generated it.
As a concrete example, the goal area of the Transformation Window in the
picture below contains the formulae (2.1) and (3). The latter is the formula that
was inferred in the presented proof step, therefore its ’New Goal’ heading. The
assumptions area contains the deﬁnitions of the functions ’class’ and ’factor–set’
and the predicate ’is–all–nonempty’. If new assumptions would have been derived

Focus Windows: A New Technique for Proof Presentation
339
in this proof step, the corresponding formulae would have been shown under the
heading ’New Assumptions’. The area containing all the assumptions that are
currently available is shown in a closed cell, following the basic philosophy of the
Focus Windows technique, that the user will normally not want to see all the
assumptions that are available in the proof at that point. If the user is interested
to see the contents of it (s)he has to double–click on the respective cell bracket.
(The organization of notebooks using cells is a standard Mathematica feature,
see [9]).
Fig. 1.
The simpliﬁed proof representation in the proof tree area, at the top of the
above focus window, is not only a graphical representation but it also has some
functionality. The nodes of the simpliﬁed tree representation are in one–to–one
correspondence with the proof steps of the proof object, the current one being
high–lighted (□). Clicking any of these nodes will cause the window to shift its
focus to the proof step linked to the clicked node. Thus, the user is allowed to
read the proof in the order (s)he prefers.
3
Implementation Issues
The proof presentation technique explained in the section above should not be
diﬃcult to implement in any existing automated prover, even for systems that do
not actually generate proofs automatically but restrict automation to checking
proofs generated by humans (like HOL [3], Mizar [4]). The main pre–requisite is

340
F. Piroi and B. Buchberger
that the results of the provers in the system must be formal proof objects that
contain suﬃcient information for extracting the used and inferred formulae, in
any particular step.
We implemented the Focus Windows method in Mathematica [9], which is
also the language we chose for the implementation of Theorema. In fact, the
implementation was straightway because of two reasons:
• From the outset, the data structure of Theorema proof objects was carefully
designed in order to give easy access to the relevant formulae in each proof step.
• The front end of Mathematica provides convenient programming tools for
active objects that, basically, allow to apply the usual Mathematica program-
ming style also for programming man–machine interfaces. We use this facility
for attaching certain information to the buttons of the navigation area and of
the schematic proof tree representation, reducing drastically the time needed for
searching information in the proof tree. We give some more details below.
The user actions are taken in via the buttons ’Next’, ’Previous’ and ’Done’
in the navigation area and the schematic proof tree presentation whose nodes
are, in fact, buttons. The schematic proof tree representation is a static object in
the sense that the data attached to its node buttons does not change during the
presentation of the proof by the focus window viewer. In contrast, the buttons
’Next’ and ’Previous’ are dynamic objects, whose information is used in the
following way:
• Suppose that the focus window is presenting the Attention Window of some
node n of the proof tree. Then the data attached to the ’Previous’ button is a
link to the parent node of n. The data attached to the ’Next’ button is a link
to the node n because when pressing it we want to bring up the Transformation
Window of the same node n.
• Suppose that the focus window is presenting the Transformation Window
of some node n of the proof tree. Note that such a window may have several
branches. Then the data attached to the ’Previous’ button in each of the branches
is a link to the node n because when pressing it we want to bring up the Attention
Window of the same node n. The data attached to the ’Next’ button in each of
the branches is a link to the corresponding child node of n.
4
Conclusions
The essence of the method we presented is that we show, in each proof step,
exactly the formulae that are relevant for the particular proof step and we put
these formulae into our focus.
In the context of automated theorem proving, when proofs are naturally
available as processable data objects (the “proof objects”) this focusing opera-
tion can be described by an algorithm and can be made available for the users
of automated theorem proving systems.
Note that the Focus Windows tool is not a prove method! The Focus Windows
technique does not assert that each of the proof steps should be “easily” veriﬁable
but, rather, it just gives a method to keep track of the relevant information used
in each proof step a particular prover generates.

Focus Windows: A New Technique for Proof Presentation
341
When comparing the linear proof presentation and the focus windows proof
presentation of one and the same proof one may make the following observations:
• In short proofs, the focus windows presentation may generate presentation
overhead that will distract the reader rather than help him.
• In proofs that are more than one or two pages long, the focus windows
presentation may increase the possibility of verifying proofs drastically.
• Linear presentations are helpful for obtaining a quick overview on the over-
all ﬂow of the proof whereas the focus windows presentation may drastically
increase the process of thoroughly understanding proofs.
• Most probably, browsing a proof in linear representation and, then, studying
the details of the proof by focus windows presentation style is the most reasonable
and eﬃcient way of understanding proofs.
After having implemented the Focus Windows technique in Theorema, we
also made another, interesting and unexpected, experience: The tool can of
course be applied to wrong proofs. In particular it can be used to check the
proofs generated by theorem provers that are under construction and not yet
fully tested. Here we noticed that checking the proofs by the Focus Windows
technique makes it much easier to detect errors in the provers. Thus, the Focus
Window tool may also be a useful research instrument for people working in the
design and implementation of automated theorem provers.
References
1. B.Buchberger. Focus Windows Presentation: A New Approach to Presenting Math-
ematical Proofs (in Automated Theorem Proving Systems). Theorema Technical Re-
port, 2000–01–30, RISC,
http://www.risc.uni–linz.ac.at/people/buchberg/downloads.html
2. B. Buchberger, C. Dupr´e, T. Jebelean, F. Kriftner, K. Nakagawa, D. Vasaru, W.
Windsteiger. The Theorema Project: A Progress Report. In: Symbolic Computation
and Automated Reasoning (Proceedings of CALCULEMUS 2000, Symposium on
the Integration of Symbolic Computation and Mechanized Reasoning, August 6–7,
2000, St. Andrews, Scotland, M. Kerber and M. Kohlhase eds.), A.K. Peters, Natick,
Massachusetts, pp. 98–113. ISBN 1–56881–145–4.
3. The HOL System. Developed at the University of Cambridge, directed by R. Milner.
http://www.cl.cam.ac.uk/Research/HVG/HOL/.
4. Mizar System. Developed at the University of Warsaw, directed by A. Trybulec.
http://mizar.uwb.edu.pl/system/.
5. Omega System. Developed at the University of Saarbr¨ucken, directed by J. Siek-
mann. http://www.ags.uni–sb.de/ omega/intro.html.
6. D. Vasaru–Dupr´e, Automated Theorem Proving by Integrating Proving, Solving and
Computing. RISC Institute, May 2000, RISC report 00–19. PhD Thesis.
7. F. Wiedijk, The Fourteen Provers of the World. 2001,
http://www.cs.kun.nl/ freek/notes/index.html
8. W. Windsteiger, A Set Theory Prover in Theorema: Implementation and Practical
Applications, RISC Institute, May 2001, RISC report 01–03. PhD Thesis.
9. S.Wolfram. The Mathematica Book, Wolfram Media and Cambridge University
Press, 1996.

Author Index
Aiguier, Marc
51
Audemard, Gilles
231
Bahrami, Diane
51
Bai, Li
128
Beeson, Michael
246
Bernhaupt, Regina
168
Bertoli, Piergiorgio
231
Buchberger, Bruno
337
Campbell, J.A.
102
Castaing, Jacqueline
136
Chetty, Madhu
12
Cimatti, Alessandro
231
Colmerauer, Alain
2
Colton, Simon
259, 275
Corless, Robert M.
76
Crespo, Jos´e
38
Dennis, Louise A.
319
Deplagne, Eric
4
Dubois, Catherine
51
Freuder, Eugene C.
1
Golumbic, Martin Charles
196
Herrero, Bego˜na
38
Hunter, Andrew
117
Jeﬀrey, D.J.
76
Kirchner, Claude
4
Kitzelmann, Emanuel
26
Korni8lowicz, Artur
231
Kutsia, Temur
290
Laita, Laura
38
Laita, Luis M.
38
Ledesma, Luis de
38
Liu, Yihui
128
Loriette-Rougegrez, S.
154
Maojo, V´ıctor
38
Meier, Andreas
275
M¨uhlpfordt, Martin
26
Nossum, Rolf
90
Pfalzgraf, Jochen
168
Pinkus, Ayal Z.
332
Piroi, Florina
337
Ranise, Silvio
305
Ratschan, Stefan
181
Roanes-Lozano, Eugenio
38
Schmid, Ute
26
Sebastiani, Roberto
231
Seraﬁni, Luciano
90
Siani, Assaf
196
Smirnova, Elena
64
Sorge, Volker
275
Sturm, Thomas
7
Subramani, K.
217
Tounsi, Mohamed
208
Wiedijk, Freek
246
Winitzki, Serge
332
Wysotzki, Fritz
26
Zimmer, J¨urgen
319

