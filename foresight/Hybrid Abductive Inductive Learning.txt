University of London
Imperial College of Science, Technology and Medicine
Department of Computing
Hybrid Abductive Inductive Learning
Oliver Ray
Submitted in part fulﬁlment of the requirements for the degree of
Doctor of Philosophy in Computing of the University of London and
the Diploma of Imperial College, December 2005

Abstract
This thesis introduces a new Machine Learning technique called Hybrid Abductive
Inductive Learning (HAIL) that integrates Abductive Logic Programming (ALP) and
Inductive Logic Programming (ILP) in order to automate the learning of ﬁrst-order
theories from examples and prior knowledge. A semantics is proposed called Kernel
Set Subsumption (KSS) that generalises the well-known inference method of Bottom
Generalisation by deriving hypotheses with more than one clause. A corresponding
proof procedure is presented, called HAIL, which extends the ALP procedure of Kakas
and Mancarella and integrates it within a generalisation of Muggleton’s widely-used
ILP system Progol5. HAIL is shown to overcome some of the limitations of Progol5
— including a previously unsuspected incompleteness — and to enlarge the class of
learning problems soluble in practice.
i

Acknowledgements
I am especially grateful to my supervisors Alessandra Russo and Krysia Broda for
their generous support, guidance and patience throughout this research.
Special
thanks also go to Antonis Kakas and Stephen Muggleton for several stimulating and
fruitful discussions. I am grateful to Dov Gabbay and Christopher Hogger for their
inspiration and encouragement. I would also like to mention Francesca Toni, Simon
Colton and Artur Garcez for their helpful advice and Gerson Zaverucha for his useful
comments regarding ancestor resolution. Discussions with Gordon Plotkin and Robin
Smith helped to improve the historical accuracy of the work. I thank my family for
their many sacriﬁces that made this work possible. Sasivimol Kittivoravitkul was my
constant companion through the highs and lows of this research. I gladly acknowledge
the ﬁnancial support of the EPSRC and the Department of Computing at Imperial
College. I extend my appreciation to the examiners Peter Flach and Murray Shanahan
for their close reading of the thesis and valuable suggestions for improvement. Thanks
are also due to the anonymous reviewers of [75, 74, 73, 72] for their useful comments.
(These papers are all the original work of the author and were published during the
course of this research.) Finally, I dedicate this thesis to an old friend, Wilfred Leng,
who sadly died just as the work was nearing completion.
ii

Preface
This thesis advances the claim that abduction and induction can be usefully integrated
in the context of scientiﬁc knowledge discovery. However, while the motivation is
practical, many of the results are technical and contribute to the formal area of
computational logic. The mathematical emphasis adopted in this thesis aﬀords the
beneﬁts of a rigorous semantics and automated logic programming procedures. For
the sake of concreteness, this work focuses on two highly regarded proof procedures —
the abductive procedure of Kakas and Mancarella and Muggleton’s inductive learning
system Progol5 — which are discussed in the ﬁrst half of the thesis.
Though the contributions of this thesis could be presented with less regard to these
existing systems, the present structure has two advantages. First, it allows a formal
account of Progol5 to be developed that is lacking from the literature. This account
is based on a detailed examination of the Progol5 source code [57], a close reading
of the relevant published work, including [58, 61, 55], and personal correspondence
with Stephen Muggleton, who also provided some original notes [60].
But, more
importantly, an analysis of this procedure adds a strong motivation to the thesis by
revealing an incompleteness of Progol5 with an evident abductive solution.
This observation provides the basis for a more general hybrid approach that places
equal emphasis on its abductive and inductive components. Consequently, the main
challenge addressed in this thesis is that of integrating abductive and inductive logic
programming in a logically principled and practically viable way. A biological case
study is justiﬁably included to complement the more theoretical aspects of this thesis
and to demonstrate their practical utility.
iii

Contents
1
Introduction
1
1.1
Background . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2
1.2
Motivation
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
8
1.3
Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
10
1.4
Overview
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
11
2
Preliminaries
13
2.1
Mathematical Notation
. . . . . . . . . . . . . . . . . . . . . . . . . .
13
2.2
Classical Logic
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
15
2.2.1
Syntax . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
15
2.2.2
Semantics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
17
2.3
Clausal Logic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
19
2.3.1
Syntax . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
19
2.3.2
Semantics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
20
2.3.3
Resolution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
21
2.3.4
C-derivations . . . . . . . . . . . . . . . . . . . . . . . . . . . .
24
2.4
Logic Programming
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
25
3
Abductive Logic Programming
30
3.1
Abductive Logic Programming (ALP) Task . . . . . . . . . . . . . . .
30
3.2
Generalised Stable Model (GSM) Semantics . . . . . . . . . . . . . . .
33
3.3
Kakas-Mancarella (KM) Proof Procedure
. . . . . . . . . . . . . . . .
35
3.4
Bibliographic Remarks . . . . . . . . . . . . . . . . . . . . . . . . . . .
42
iv

CONTENTS
v
4
Inductive Logic Programming
44
4.1
Inductive Logic Programming (ILP) Task . . . . . . . . . . . . . . . .
44
4.2
Bottom Generalisation (BG) Semantics
. . . . . . . . . . . . . . . . .
50
4.3
Progol5 Proof Procedure . . . . . . . . . . . . . . . . . . . . . . . . . .
52
4.4
Bibliographic Remarks . . . . . . . . . . . . . . . . . . . . . . . . . . .
56
5
Analysis of the Progol5 StartSet
58
5.1
Formalisation of the StartSet Procedure . . . . . . . . . . . . . . . . .
58
5.1.1
Contrapositive Reasoning of StartSet . . . . . . . . . . . . . . .
59
5.1.2
Concrete Speciﬁcation of StartSet
. . . . . . . . . . . . . . . .
68
5.1.3
Abstract Speciﬁcation of StartSet . . . . . . . . . . . . . . . . .
72
5.2
Proof of the Soundness of StartSet . . . . . . . . . . . . . . . . . . . .
73
5.3
Proof of the Incompleteness of StartSet
. . . . . . . . . . . . . . . . .
77
5.4
Characterising the Incompleteness of StartSet . . . . . . . . . . . . . .
83
5.5
Solving the Incompleteness of StartSet . . . . . . . . . . . . . . . . . .
86
5.5.1
Ancestor Resolution . . . . . . . . . . . . . . . . . . . . . . . .
87
5.5.2
Abduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
91
6
Hybrid Abductive Inductive Learning
95
6.1
Hybrid Abductive Inductive Learning (HAIL) . . . . . . . . . . . . . .
96
6.2
Kernel Set Subsumption (KSS) Semantics . . . . . . . . . . . . . . . . 101
6.3
HAIL Proof Procedure . . . . . . . . . . . . . . . . . . . . . . . . . . . 110
6.3.1
HAIL computations
. . . . . . . . . . . . . . . . . . . . . . . . 110
6.3.2
HAIL Implementation . . . . . . . . . . . . . . . . . . . . . . . 114
6.3.3
Contextual Transform . . . . . . . . . . . . . . . . . . . . . . . 120
7
Case Study
127
7.1
Regulation of Lactose Metabolism in E. coli . . . . . . . . . . . . . . . 127
7.2
Application of HAIL . . . . . . . . . . . . . . . . . . . . . . . . . . . . 132
7.3
Application of Progol5 . . . . . . . . . . . . . . . . . . . . . . . . . . . 136
7.4
Comparison of HAIL and Progol5 . . . . . . . . . . . . . . . . . . . . . 142

CONTENTS
vi
8
Related Work
145
8.1
Formal Characterisation of Abduction & Induction . . . . . . . . . . . 145
8.2
Conceptual Integration of Abduction & Induction . . . . . . . . . . . . 148
8.3
Procedural Integration of Abduction & Induction . . . . . . . . . . . . 150
9
Conclusions and Future Work
155
9.1
Summary and Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . 155
9.2
Future Work
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 157

List of Figures
1.1
Peirce’s ‘Syllogistic Theory’ . . . . . . . . . . . . . . . . . . . . . . . .
3
1.2
Peirce’s ‘Inferential Theory’ . . . . . . . . . . . . . . . . . . . . . . . .
4
3.1
Graphical representation of Example 3.3.3 . . . . . . . . . . . . . . . .
40
3.2
Textual representation of Example 3.3.3 . . . . . . . . . . . . . . . . .
40
5.1
CProgol5.0 Grammar Experiment — Revisited . . . . . . . . . . . . .
80
5.2
Derivations R1 −R5 in the ‘only if’ direction of Theorem 5.4.1 . . . .
85
5.3
Derivations S1 −S5 in the ‘if’ direction of Theorem 5.4.1 . . . . . . . .
86
5.4
Solution to Example in Lemma 5.3.1 using Ancestor Resolution . . . .
90
5.5
Solution to Example in Fig. 5.1 using Ancestor Resolution . . . . . . .
90
5.6
Solution to Example in Lemma 5.3.1 using Abduction . . . . . . . . .
92
5.7
Solution to Example in Fig. 5.1 using Abduction . . . . . . . . . . . .
92
6.1
Overview of HAIL Learning Cycle
. . . . . . . . . . . . . . . . . . . . 100
6.2
Prolog Description of HAIL Learning Cycle . . . . . . . . . . . . . . . 115
6.3
Pseudocode Description of HAIL Learning Cycle . . . . . . . . . . . . 115
6.4
Prolog Description of HAIL Abductive Phase . . . . . . . . . . . . . . 117
6.5
Prolog Description of HAIL Deductive Phase
. . . . . . . . . . . . . . 117
6.6
Prolog Description of HAIL Inductive Phase . . . . . . . . . . . . . . . 117
7.1
Transcriptional regulation of the LAC Operon . . . . . . . . . . . . . . 129
7.2
HAIL/Progol5 input ﬁle . . . . . . . . . . . . . . . . . . . . . . . . . . 131
7.3
HAIL Contextual Transform for Fig. 7.2 . . . . . . . . . . . . . . . . . 133
vii

LIST OF FIGURES
viii
7.4
Successful HAIL/KM computation for Fig. 7.3
. . . . . . . . . . . . . 135
7.5
Progol5 Contrapositives for Fig. 7.2
. . . . . . . . . . . . . . . . . . . 137
7.6
Failed Progol5/StartSet SLD-tree for Fig. 7.5 . . . . . . . . . . . . . . 139
7.7
Successful Progol5/StartSet SLD-tree for Fig. 7.5 using additional back-
ground facts conc(lac, hi, e1), exp(lac(z), e1) and sugar(glu) . . . . . . 141
7.8
Comparison of HAIL/KM and Progol5/StartSet Search Spaces . . . . 143

Chapter 1
Introduction
Abduction and induction are two forms of reasoning that alongside deduction have
played a prominent role in the study of logic and philosophy of science. Historically,
these three reasoning forms have their roots in the work of Aristotle, but were placed
in their modern context by C.S. Peirce around the turn of the twentieth century.
According to Peirce, in the same way deduction epitomises analytic (or necessary)
inference, so abduction and induction exemplify synthetic (or hypothetical) reasoning.
The key distinction is that whereas deduction aims to make explicit the consequences
already implicit in some existing body of knowledge, abduction and induction aim to
discover genuinely new knowledge from empirical data relating to some phenomenon
or phenomena of interest.
In essence, abduction is the process of explanation — of reasoning from eﬀects
to possible causes; while induction is the process of generalisation — or reasoning
from samples to wider populations. Although the logical foundations of abduction
and induction are less clear than for deduction, signiﬁcant progress has been made in
the areas of Artiﬁcial Intelligence (AI) [80] and Machine Learning (ML) [53] where
recent attempts to formalise and automate these forms of reasoning have led to greater
understanding and convincing real-world applications, such as [42, 11, 39, 32]. Much
of this success stems from work in the ﬁelds of Abductive Logic Programming (ALP)
[34] and Inductive Logic Programming (ILP) [63].
1

1.1. BACKGROUND
2
This thesis builds upon recent work in ALP and ILP by showing how automatic
methods for abduction and induction can be generalised and integrated semantically
and procedurally in a fashion that could assist researchers in the pursuit of scientiﬁc
knowledge. This introductory chapter outlines the context and motivations of the
thesis and brieﬂy describes its main contents and contributions. Section 1.1 explains
the historical development of abduction and induction from Peirce to their modern
formalisations in the ﬁelds of ALP and ILP. Section 1.2 presents some key motivations
for integrating ALP and ILP, and points out some of the expected practical beneﬁts.
Section 1.3 summarises the main contributions of the thesis, and Section 1.4 provides
a brief overview of each chapter.
1.1
Background
The modern classiﬁcation of logical reasoning into abduction, induction and deduction
is due to the American Pragmatist C.S. Peirce (1839-1914).
Before Peirce, only
two of these three reasoning forms had been widely recognised. On the one hand,
deduction represented necessary inference from the general to the particular and,
on the other hand, induction represented probable inference from the particular to
the general. But, while deduction had been formally studied for over two thousand
years in the context of the Aristotelian syllogism1, the form and validity of inductive
reasoning was a major philosophical question in the nineteenth century. A key step
was taken by Peirce when he realised that inductive reasoning could be formalised
by exchanging the major premise and conclusion of the traditional syllogism. This
immediately suggested a third form of reasoning where the conclusion is exchanged
with the minor premise instead. Peirce called this new process Hypothesis and then
retroduction, before ﬁnally coining the term abduction.
1Very brieﬂy, a syllogism is an argument with two premises and a conclusion. The minor premise
connects the subject of the conclusion with a middle term, while the major premise connects the
middle term with the predicate of the conclusion. Thus, from the minor premise ‘Socrates is a man’
and the major premise ‘All men are mortal’, follows the well-known conclusion ‘Socrates is mortal’.

1.1. BACKGROUND
3
All the beans from this bag are white
These beans are from this bag
∴These beans are white











Deduction
All the beans from this bag are white
These beans are white
∴These beans are from this bag











Abduction
These beans are white
These beans are from this bag
∴All the beans from this bag are white











Induction
Figure 1.1: Peirce’s ‘Syllogistic Theory’
Peirce himself illustrated the idea with an example concerning the colour of beans
drawn from a certain bag [25, 2.623]. As shown in Fig. 1.1, the deductive argument is
a syllogism with major premise (or rule) ‘All the beans from this bag are white’, minor
premise (or case) ‘These beans are from this bag’, and conclusion (or result) ‘These
beans are white’. The abductive argument, in which the case is inferred from the rule
and result, provides a plausible explanation of why some observed individuals (these
beans) all share a certain characteristic (being white) indicative of some particular
class (the beans in this bag). Conversely, the inductive argument, in which the rule
is inferred from the case and result, provides a probable explanation of why some
representative individuals (these beans) of a certain class (the beans in this bag) all
share some particular characteristic (being white).
The characterisation above has become known as Peirce’s syllogistic theory [20].
But, around 1900, Peirce’s views on abduction and induction underwent a shift of
emphasis from their syllogistic form to their inferential function. According to Peirce,
‘I was too much taken up in considering syllogistic forms and the doctrine of logical

1.1. BACKGROUND
4
A b d u c t i o n
D e d u c t i o n
Experiment
I n d u c t i o n
hypothesis
knowledge
predictions
observations
anomaly
Figure 1.2: Peirce’s ‘Inferential Theory’
extension and comprehension, both of which I made more fundamental than they
really are.’ [25, 2.102]. Drawing upon his earlier philosophical and scientiﬁc work,
Peirce was led to his so-called inferential theory [20], where abduction and induction
are seen as complementary processes cooperating with deduction and experiment in
a cycle of scientiﬁc knowledge discovery. In this later view, abduction and induction
play roles roughly analogous to hypothesis generation and hypothesis evaluation.
As shown in Fig. 1.2, the cycle usually begins with the an anomaly or a ‘surprising
fact’ [25, 5.188] that is not explicable by one’s existing knowledge. Some plausible
hypothesis or ‘ﬂash of insight’ [25, 5.181] must then be sought to account for this fact.
This process of hypothesis is what Peirce now calls abduction. Testable predictions
must then be extracted that would follow if the hypothesis were true. This process of
prediction is the task of deduction. The predictions must then be compared against
the result of experiment.
Support for the predictions may justify the (tentative)
acceptance of the hypothesis as part of one’s growing knowledge, but insuﬃcient
support may rule out one hypothesis in favour of another and may result in the
discovery of new anomalies in need of further explanation (thereby invoking a new

1.1. BACKGROUND
5
cycle). This process of evaluation is what Peirce now calls induction. In his own
words, Peirce summarised the four stages of scientiﬁc enquiry as follows:
Abduction: Accepting the conclusion that an explanation is needed when facts con-
trary to what we should expect emerge, ... A hypothesis then, has to be adopted,
which is likely in itself, and renders the facts likely. This step of adopting a
hypothesis as being suggested by the facts, is what I call abduction. [25, 7.202]
Deduction: When this is duly recognized, the ﬁrst thing that will be done, as soon
as a hypothesis has been adopted, will be to trace out its necessary and probable
experiential consequences. This step is deduction. [25, 7.203]
Experiment: Having, then, by means of deduction, drawn from a hypothesis pre-
dictions as to what the results of the experiment will be, we proceed to test the
hypothesis by making the experiments and comparing those predictions with
the actual results of the experiment. [25, 7.206]
Induction: When, however, we ﬁnd that prediction after prediction ... is veriﬁed
...
we begin to accord to the hypothesis a standing among scientiﬁc results
This sort of inference it is, from experiments testing predictions based on a
hypothesis, that is alone properly entitled to be called induction. [25, 7.206]
The publication of Peirce’s collected works [25] between 1931 and 1958 reignited
the philosophical debate concerning the inferential properties of abduction, induction
and their roles in the process of scientiﬁc discovery.
Of course, by this time the
traditional Aristotelian logic had been wholly superseded by the modern predicate
calculus — to which Peirce himself had made signiﬁcant contributions. Ironically,
it was the invention of the resolution principle [78] in 1965 as an eﬃcient technique
for automated reasoning that led to a renewed interest in Peirce’s syllogistic theory.
This is because resolution is, in many respects [20], the ﬁrst-order analogue of the
classical syllogism.
In the early 1970’s resolution theorem proving inspired three
seminal investigations into the mechanisation of deductive [44], abductive [33] and

1.1. BACKGROUND
6
inductive [70] reasoning in clausal logic. Finally, with the rapid development of logic
programming in the late 1980’s, the stage was set for the emergence of the ﬁelds now
called ALP and ILP.
Fundamentally, ALP and ILP are both concerned with the task of inverting logical
entailment. In other words, they both seek hypotheses that, together with a given
body of knowledge, entail some observations and are consistent with some others.
The main diﬀerences between the tasks of ALP and ILP concern the various syntactic
restrictions imposed on the inputs and outputs. The most obvious distinction is that
ALP hypotheses are usually restricted to sets of ground literals, while ILP hypotheses
are typically sets of non-ground clauses.
In this way, ALP and ILP embody the
intuitive notions of explanation and generalisation, respectively. The remainder of
this section introduces the tasks of ALP and ILP in order to highlight their key
similarities and diﬀerences. Further details are provided in Chapters 3 and 4.
ILP.
Formally, the ILP task takes as input three theories B, E+ and E−, called
background knowledge, positive and negative examples, respectively. The output is a
theory H, called a hypothesis, such that B and H entail E+ and are consistent with
E−. In practice, most ILP systems operate in a restricted setting where B and H are
deﬁnite theories and E+ and E−are ground unit theories. Even then, the hypothesis
space is often so large that further syntactic constraints must be imposed upon H.
As explained in Chapter 4, such constraints can be conveniently speciﬁed by a set M
of mode declarations that deﬁne a hypothesis space LM, called the language of M,
within which the clauses in H must fall. To select between competing hypotheses, it
is usual to employ some form of compression heuristic that prefers hypotheses with
few literals covering many examples.
By eﬃciently realising these principles, ILP
systems such as Progol5 [61] have proven to be eﬀective tools for reﬁning incomplete
theories in domains such as bioinformatics — as shown for example in [42].
ALP.
Conversely, the ALP task takes as input a logic program T, called a theory,
a set G of literals, called goals, and a set IC of closed formulae, called integrity

1.1. BACKGROUND
7
constraints. The output is a set ∆of ground atoms, called an explanation, such that
T and ∆cover the goals G and are consistent with the integrity constraints IC. As
explained in Chapter 3, the atoms in ∆are usually restricted to a predeﬁned set
A of predicates, called abducibles. In addition, most ALP techniques are applicable
to so-called normal logic programs with Negation as Failure (NAF) [4] and so the
abductive notions of coverage and consistency are not classical, as are their inductive
counterparts, but refer to some form of non-monotonic semantics such as Generalised
Stable Models (GSMs) [36].
By eﬃciently realising these principles, ALP systems
such as those based on the Kakas Mancarella (KM) procedure [34] have proven to be
eﬀective tools for reasoning with incomplete theories.
There are many similarities between ALP and ILP: the theory T is analogous to
the background knowledge B; the goals G correspond to the positive examples E+;
and the abducibles A are a simple form of language bias M. One diﬀerence, however,
concerns the satisfaction of integrity constraints and negative examples. By virtue
of its classical semantics, ILP employs a consistency view [34] where E−must be
satisﬁed in an arbitrary model of B ∪H. But, due to its non-monotonic semantics,
ALP uses an epistemic view [34] where IC must be satisﬁed in a speciﬁc model of
T ∪∆. In practice, this means ALP systems can take remedial action on detecting
an integrity violation, while ILP systems can only abort the computation. Another
diﬀerence is that the abduced predicates in ∆are usually disjoint from those in G, but
the predicates induced in H usually coincide with those of E+. Intuitively, ALP aims
to ﬁnd causal explanations ∆of given eﬀects G, while ILP aims to learn intentional
deﬁnitions H from extensional data E+.
The declarative and procedural semantics of logic programming provide an ideal
context for the analysis and mechanisation of abduction and induction — especially
compared with some of the less focussed philosophical disagreements of the past. In
addition, attempts to apply ALP and ILP in real world problems have led to tangible
results in areas such as diagnosis, planning, classiﬁcation and knowledge acquisition.
Finally, the formalisation and mechanisation of abduction and induction has not only

1.2. MOTIVATION
8
shed new light on the these forms of reasoning, but has prompted a reassessment of
the underlying philosophical, cognitive, logical and computational issues, culminating
in an recently published survey in [19] upon which this thesis builds.
1.2
Motivation
In their own rights, ALP and ILP are established techniques that are becoming more
and more important in practical applications that require the ability to explain or
generalise observed phenomena with respect to prior knowledge.
As discussed in
the previous section, ALP is a well known technique for reasoning with incomplete
knowledge and ILP is a widely applied methodology for learning new knowledge.
However, there are compelling reasons to believe that combining ALP and ILP within
a common framework will lead to even greater beneﬁts in relation to the exploitation
and discovery of scientiﬁc knowledge.
To begin, the very fact that learning can only be operative when knowledge is
incomplete, suggests that enhancing one’s ability to reason with incompleteness could
improve one’s capacity for learning. From this it follows inductive learning might
beneﬁt from a facility for abductive reasoning. In addition, combining ALP and ILP
techniques could help to overcome their individual limitations (e.g. that abductive
explanations contain just ground literals or that inductive generalisations deﬁne only
observational predicates).
In this regard, one of the most exciting results to have emerged from [19] is the
suggestion that abduction and induction can indeed be integrated in an iterative cycle
of knowledge reﬁnement. The idea is to simply use the facts generated by abduction as
additional examples for the inductive task, and to use the rules generated by induction
as additional background knowledge in the abductive task. In this way, abduction
and induction can cooperate beneﬁcially within a common learning framework. But,
so far, no practical systems have been developed that are able to exploit the full
potential of the abductive and inductive components.

1.2. MOTIVATION
9
The aim of this thesis
is to show how ALP and ILP techniques can be generalised
and integrated in a logically principled and practically viable way that enlarges the
class of problems soluble in practice and could assist researchers in the process of
scientiﬁc discovery. To provide a technical justiﬁcation for these philosophical claims,
this thesis focuses on two of the most prominent techniques currently available: the
ILP system Progol5 and the KM ALP procedure. In particular, the thesis shows
how these methods can be eﬃciently generalised and integrated in a learning cycle
inspired by Peirce’s inferential view of scientiﬁc theory development.
This thesis places a special emphasis on the ability to infer general deﬁnitions for
concepts that are not directly observable: as this is clearly paramount in scientiﬁc
discovery applications. In ILP parlance, this ability is referred to as non-Observation
Predicate Learning (non-OPL) [61], since the predicates being learnt are distinct from
those in the examples. The utility of non-OPL is clearly demonstrated by some recent
ILP applications (e.g. [42]) where the phenomena of interest (e.g. gene function) are
not directly observable, and must be inferred indirectly from experimental data (e.g.
phenotypic eﬀects) and prior background knowledge.
Some additional applications of ILP that require non-OPL capabilities include the
discovery of natural language grammars [65], the learning of robot navigation control
programs [56], and the modelling of inhibition patterns in metabolic pathways [92].
But, despite the growing importance of these and other non-OPL tasks, it is true to
say that most Machine Learning systems are still ﬁrmly rooted in the Observation
Predicate Learning (OPL) tradition. Progol5 is one notable exception to this rule,
having been speciﬁcally developed to support non-OPL learning through the use of
a special contrapositive reasoning mechanism called StartSet.
The technical motivation for this thesis is based on a detailed analysis of the
Progol5 StartSet procedure which shows that it can be regarded as an ineﬃcient and
restricted form of abduction whose limitations mean, ﬁrst, that Progol5 can learn
just one clause in response to each example and, second, that Progol5 is incomplete
with respect to its intended semantics. It is then shown how the KM procedure can

1.3. CONTRIBUTIONS
10
be used to overcome these limitations of Progol while also enabling the inference of
more than one clause in response to a single positive example.
1.3
Contributions
This thesis has two main contributions:
The ﬁrst contribution
is to provide a logical analysis of Progol5 with respect to its
semantics of Bottom Generalisation (BG) [58, 99] — an established inductive inference
method based on the construction and generalisation of a special clause called a
Bottom Set. The main result is to conﬁrm the soundness, but to reveal an unexpected
incompleteness of Progol5 with respect to BG. It is shown how this incompleteness
has compromised the performance of Progol5 in at least one published application,
but that it was mistakenly attributed to a well-known incompleteness of BG itself.
To clarify matters, the procedural incompleteness of Progol5 is characterised and
distinguished from the semantic incompleteness of BG. The former is then traced
back to a possible misunderstanding concerning the need for ancestor resolution when
answering queries in Horn clause logic. Finally, it is shown how abduction can be
used to eﬃciently overcome some of these limitations.
The second contribution
is to propose a novel Machine Learning approach called
Hybrid Abductive Inductive Learning (HAIL) that integrates abductive and inductive
reasoning in an incremental cycle of knowledge discovery. A semantics is proposed
called Kernel Set Subsumption (KSS) which generalises the inference method BG so
as to derive hypotheses with more than one clause. A Horn clause proof procedure
is described, called HAIL, that integrates an extension of the KM procedure within
a generalisation of Progol5. By means of a case study, the HAIL approach is shown
to overcome several limitations of Progol5, including the sources of incompleteness
mentioned above, and to further enlarge the class of problems soluble in practice.

1.4. OVERVIEW
11
The main conclusion
is that abduction and induction can be usefully integrated
in a cycle of learning that overcomes some of the limitations of existing systems.
In particular, comparing HAIL and Progol5 shows how abduction avoids the clear
ineﬃciencies of contrapositives, overcomes the incompleteness of StartSet, and can
be used to seed multiple-clause hypotheses outside the semantics of BG. Informally
speaking, these features allow HAIL to outperform Progol5 in real-world tasks where
a single eﬀect has multiple causes or where two related eﬀects share a common cause.
1.4
Overview
The rest of the thesis is structured as follows:
Chapter 2
summarises the basic notation and terminology that is used throughout
the thesis. The syntax and semantics of classical logic, clausal logic, and of logic
programming is brieﬂy reviewed, with particular emphasis on resolution derivations
and C-derivations (which are closely related to the semantics of BG).
Chapters 3 and 4
recall the necessary background material relating to the ﬁelds
of ALP and ILP. Chapter 3 focuses on the KM proof procedure and its underlying
GSM semantics.
Chapter 4 concentrates on the Progol5 proof procedure and the
corresponding semantics of BG.
Chapter 5
introduces the notion of contrapositives and shows how they are used
by Progol5.
A logical analysis conﬁrms the soundness of Progol5, but reveals an
unexpected incompleteness that undermines its performance in real applications. This
incompleteness is characterised and alternative solutions are considered.
Chapter 6 introduces the HAIL approach. A ﬁrst-order semantics is presented,
called Kernel Set Subsumption (KSS), that generalises BG to infer multiple clause
hypotheses. A Horn clause proof procedure is described, called HAIL, that integrates
an extension of the KM procedure within a generalisation of Progol5.

1.4. OVERVIEW
12
Chapter 7 shows the application of HAIL to a biological case study involving the
metabolic regulation of the bacterium Escheria. coli. Comparing HAIL with Progol5
highlights the ineﬃciency of contrapositives compared to abduction, and shows the
need for inferring multiple clause hypotheses in response to single examples.
Chapter 8
brieﬂy reviews the extensive literature on the integration of abduction
and induction and compares HAIL with some related systems that combine abductive
and inductive techniques within a common reasoning framework.
Chapter 9
summarises the main conclusions of this thesis and discusses several
directions for future work.
Note:
In the sequel, the following conventions will be observed. As a general rule,
key references will be indicated only at the start of the relevant chapter or section
and will not be continually cited throughout the text. The notation ‘iﬀ’ abbreviates
‘if and only if’.
The notation ‘wrt.’
abbreviates ‘with respect to’.
The notation
‘resp.’ abbreviates ‘respectively’.
The terminology ‘modulo’ and ‘up to’ are used
interchangeably.

Chapter 2
Preliminaries
This chapter summarises the notation and terminology that is used throughout the
thesis. First of all, Section 2.1 recalls some elementary set theoretic conventions [91].
Then, Section 2.2 reviews the syntax and semantics of classical ﬁrst-order logic [16].
Section 2.3 introduces clausal form logic and formalises the notions of resolution [78]
and C-derivations [70]. Finally, Section 2.4 outlines some relevant deﬁnitions from
logic programming [47].
2.1
Mathematical Notation
The set of n ≥1 objects a1, . . . , an is denoted {a1, . . . , an}. The set of all objects a that
satisfy a property φ is denoted {a | φ(a)}. The empty set is denoted ∅. The (binary)
relations of set membership, containment and strict containment are denoted ∈, ⊆
and ⊂, respectively. The (binary) operations of set union, intersection and diﬀerence
are denoted respectively ∪, ∩and /, respectively. The notations Sn
i=1 Si and Tn
i=1 Si
abbreviate respectively the sets S1∪· · ·∪Sn and S1∩· · ·∩Sn. (If n = 0, then the former
is deﬁned as the empty set, while the latter is deﬁned as the universe of discourse.)
The cardinality of a set S is written |S|, and its power-set is written 2S. The sequence
(or n-tuple) of n ≥1 objects a1, . . . , an is denoted ⟨a1, . . . , an⟩. The empty sequence is
denoted ⟨⟩. A subsequence of ⟨a1, . . . , an⟩is any sequence of the form ⟨b1, . . . , bm⟩for
which there exist integers i1, . . . , im such that 1 ≤i1 < · · · < ij < · · · < im ≤n and
13

2.1. MATHEMATICAL NOTATION
14
bj = aij for all 1 ≤j ≤m. The (n-fold) Cartesian product of n ≥2 sets is denoted
S1 × · · · × Sn and deﬁned as the set {⟨a1, . . . , an⟩| ai ∈Si for all 1 ≤i ≤n}. The
n-th Cartesian power of a set S is denoted Sn and deﬁned as the n-fold Cartesian
product S×· · ·×S. (For completeness, the 1-st Cartesian power S1 of a set S is simply
deﬁned as S, and the 0-th Cartesian power S0 is deﬁned as the set {⟨⟩} containing
the empty sequence.) The (binary) operation of sequence concatenation is denoted +.
An (n-ary) relation (on sets S1, . . . , Sn) is a set r ⊆S1 × · · · × Sn. Objects a1, . . . , an
are said to be related by r, denoted r(a1, . . . , an), iﬀ⟨a1, . . . , an⟩∈r. An object a is
said to be in r, denoted r(a), iﬀa ∈r. An (n-ary) function (from sets S1, . . . , Sn to
S) is a relation f ⊆S1 × · · · × Sn × S satisfying the additional property that for each
⟨a1, . . . , an⟩∈S1 ×· · ·×Sn there is exactly one a ∈S such that f(a1, . . . , an, a). This
unique element a is called the value of f at ⟨a1, . . . , an⟩and is denoted f(a1, . . . , an).
The fact that f is a function is symbolised f : S1 × · · · × Sn →S. If f is a function
then f(a/b) denotes the function whose value at x is b, if x = a; and is f(x) otherwise.
A binary relation r ⊆S × S is reﬂexive iﬀr(x, x) for all x ∈S, irreﬂexive iﬀr(x, x)
for no x ∈S, symmetric iﬀr(x, y) implies r(y, x) for all x, y ∈S, antisymmetric
iﬀr(x, y) and r(y, x) implies x = y for all x, y ∈S, transitive iﬀr(x, y) and r(y, z)
implies r(x, z) for all x, y, z ∈S. A partial order is a relation ≤that is reﬂexive,
transitive and antisymmetric. A strict partial order is a relation < that is irreﬂexive,
transitive and (hence) antisymmetric. An equivalence is a relation ≡that is reﬂexive,
transitive and symmetric. Fix a set S and a partial order ≤. For any subset T ⊆S,
an element x ∈T is a minimal (resp. maximal) element of T iﬀy ≤x (resp. x ≤y)
implies y = x for all y ∈T. For any subset T ⊆S, an element x ∈T is a least (resp.
greatest) element of T iﬀx ≤y (resp. y ≤x) for all y ∈T. The order ≤is well-
founded iﬀevery non-empty subset T ⊆S has a least element. For any subset T ⊆S,
an element x ∈S is a lower bound (resp. upper bound) of T iﬀx ≤y (resp. y ≤x) for
all y ∈T. The set S is a (complete) lattice iﬀevery pair of elements x, y ∈S have a
least upper bound (lub) and a greatest lower bound (glb) For any function f : S →S,
an element x ∈S is a ﬁxed-point of f iﬀf(x) = x.

2.2. CLASSICAL LOGIC
15
2.2
Classical Logic
In this thesis, logical formulae will be written in a ﬁrst-order language L, whose syntax
and semantics is understood to be that of the classical ﬁrst-order predicate calculus
(without equality). The following summary of the relevant syntactic and semantic
notions is based mainly upon [16] and partly on [7] with some minor diﬀerences in
notation and terminology.
2.2.1
Syntax
Like any formal language, the syntax of a ﬁrst-order logic is speciﬁed by stating
the primitive symbols in its alphabet and then deﬁning the grammatical rules for
constructing well formed expressions. These are deﬁned below for the language L.
The alphabet of L
consists of the following symbols (with informal names):
• The logical symbols: ‘∀’ (all), ‘∃’ (some), ‘∧’ (and), ‘∨’ (or),
‘¬’ (not), ‘→’ (implies), ‘⊤’ (true), ‘⊥’ (false).
• The punctuation symbols: ‘,’ , ‘(’ , ‘)’.
• The variable symbols: ‘x’, ‘x1’, ‘y’, . . .
• The function symbols: ‘f’, ‘f1’, ‘g’, . . .
• The predicate symbols: ‘p’, ‘p1’, ‘q’, . . .
The logical symbols are classiﬁed into three groups: the quantiﬁers ‘∀’, ‘∃’, the
connectives ‘∧’, ‘∨’, ‘¬’, ‘→’, and the logical constants ‘⊤’, ‘⊥’.
Collectively, the
function and predicate symbols are called the parameters (or signature) of L. Unlike
the logical symbols, whose meaning is ﬁxed, the meaning of the parameters is context
dependent. It is assumed each parameter is associated with a non-negative integer,
called its arity, which will be evident from context and determines the number of
arguments the parameter takes. As usual, function and predicate symbols of arity
zero are called constant and proposition symbols, respectively

2.2. CLASSICAL LOGIC
16
The (well-formed) expressions of L
are constructed as follows1:
• A term is either a variable x, a constant c, or an expression of the form
f(t1, . . . , tn), where f is a function of arity n ≥1 and t1, . . . , tn are terms.
• An atom is an expression of the form p(t1, . . . , tn), where p is a predicate of
arity n ≥0 and t1, . . . , tn are terms. (For convenience, the propositional atom
p() will simply be written p in case n = 0.)
• A formula is either an atom p(t1, . . . , tn), a universal (∀x)F, an existential
(∃x)F, a negation (¬F), a conjunction (F ∧G), a disjunction (F ∨G), an
implication (F →G), truth ⊤, or falsity ⊥; where x is a variable and F and G
are formulae.
• Finally, the conditional (F ←G) is an alternative way of writing (G →F),
where formulae F and G are called the consequent and antecedent, respectively;
and the equivalence (F ↔G) abbreviates the formula ((F →G) ∧(G →F)).
The two formulae (∀x)F and (∃x)F are said to be (universally and existentially)
quantiﬁed in x. To avoid excess punctuation, standard binding conventions are used.
Brackets will be freely removed or inserted to improve readability providing there are
enough to unambiguously reconstruct the original expression. In order of decreasing
priority, the operator precedence is: ∀, ∃, ¬, ∧, ∨, ←, →, ↔. Each occurrence of a
variable x in an expression E is either bound or free. An occurrence of x is bound if it
occurs within a sub-expression quantiﬁed in x and is free otherwise. Each expression E
is either open or closed. An expression is open if it contains a free variable and is closed
otherwise. If F is a formula with free variables x1, . . . , xn (in some order), then the
universal closure of F, denoted ∀(F), abbreviates the formula (∀x1) . . . (∀xn)F, and
the existential closure of F, denoted ∃(F), abbreviates the formula (∃x1) . . . (∃xn)F.
1Note that while care was taken above to enclose the symbols of L within quotation marks in order
to delimit them from the surrounding text, and to properly speak of variable symbols as opposed to
just variables, for simplicity, the same care will not always be taken hereafter.

2.2. CLASSICAL LOGIC
17
An expression is ground iﬀit contains no variables (bound or free). Two expressions
are said to be standardised apart iﬀthey have no variables in common.
A substitution θ is a set of bindings {x1/t1, . . . , xn/tn} where the xi are distinct
variables, and each ti is a term distinct from xi. The empty substitution is denoted
ǫ. The restriction of θ to an expression E with free variables V , written θ|E, is the
substitution {x/t ∈θ
|
x ∈V }. The application of θ to E, written Eθ, is the
expression obtained from E by replacing each free occurrence of a variable x ∈V by
the term t, for each binding x/t ∈θ. An expression E1 is an instance of an expression
E2 iﬀE1 = E2θ for some substitution θ. Two expressions are variants iﬀthey are
instances of each other. The composition of substitutions θ1 and θ2, denoted θ1θ2, is
the substitution {x/tθ2 | x/t ∈θ1 and x ̸= tθ2} ∪{y/s ∈θ2 | y ̸= x for all x/t ∈
θ1}. A substitution θ1 is (as or) more general than a substitution θ2 iﬀθ2 = θ1θ
for some substitution θ. If E is an expression, then a renaming substitution for E
is a substitution θ such that E and Eθ are variants. A grounding substitution is a
substitution θ such that Eθ is ground. A uniﬁer of n ≥2 expressions E1, . . . , En is
a substitution θ such that Eiθ = Ejθ for all 1 ≤i ≤j ≤n. A most general uniﬁer
(mgu) is a uniﬁer that is more general than all other uniﬁers. In this thesis it is
assumed that mgu’s are computed by a standard algorithm, such as the one in [78],
that introduces no variables external to the set of expressions being uniﬁed.
2.2.2
Semantics
Meaning is given to the formulae of a ﬁrst-order language by associating its logical
expressions with mathematical statements in some given domain of discourse. With
respect to the language L and a set D called the domain, an assignment is a function
h that associates with each variable symbol x in L an element h(x) ∈D, and an
interpretation is a function I that associates with each constant c in L an element
cI ∈D, with each function symbol f in L of arity n ≥1 a function f I : Dn →D,
and with each predicate symbol p in L of arity n ≥0 a relation pI ⊆Dn. (Note that,
when n = 0, the interpretations {} and {⟨⟩}, are simply called false and true.)

2.2. CLASSICAL LOGIC
18
The value of a term t
is determined by the function [t]I,h (read:
the value of t in I under h) from the terms of L to D, deﬁned as follows:
• [c]I,h = cI, for a constant c
• [x]I,h = h(x), for a variable x
• [f(t1, . . . , tn)]I,h = f I([t1]I,h, . . . , [tn]I,h) for a function f of arity n ≥1
The truth of a formula F
is determined by the relation I, h |= F (read:
F is true in I under h) over the formulae of L, deﬁned as follows:
• I, h |= ⊤and I, h ̸|= ⊥
• I, h |= p(t1, . . . , tn) iﬀpI([t1]I,h, . . . , [tn]I,h)
• I, h |= (F →G) iﬀI, h ̸|= F or I, h |= G
• I, h |= (F ∨G) iﬀI, h |= F or I, h |= G
• I, h |= (F ∧G) iﬀI, h |= F and I, h |= G
• I, h |= (¬F) iﬀI, h ̸|= F
• I, h |= (∃x)F iﬀI, h(x/d) |= F for some d ∈D
• I, h |= (∀x)F iﬀI, h(x/d) |= F for every d ∈D
An interpretation M is a model of a formula F, denoted M |= F, iﬀM, h |=
F for all assignments h. A formula F is satisﬁable (or consistent) iﬀat least one
interpretation is a model; is falsiﬁable iﬀat least one interpretation is not a model;
is a tautology (or valid) iﬀevery interpretation is a model; and is a contradiction (or
inconsistent) iﬀno interpretation is a model. An interpretation M is a model of a
set of formulae F, denoted M |= F, iﬀM |= F for all F ∈F. A set of formulae
F (logically) entails a formula G, written F |= G, iﬀevery model of F is a model
of G.
If L denotes the set of all formulae in the language L then, formally, the
notion of logical entailment can be viewed as a binary relation ‘|=’ ⊆2L × L. It is

2.3. CLAUSAL LOGIC
19
well known that for all formulae F, G, and for all sets of formulae F, this relation
satisﬁes the following properties: (reﬂexivity) F ∪{G} |= G; (monotonicity) if F |= G
then F ∪{F} |= G; (cut) if F |= F and F ∪{F} |= G then F |= G; (deduction)
F ∪{F} |= G iﬀF |= F →G; and (contraposition) F ∪{F} |= G iﬀF ∪{¬G} |= ¬F.
2.3
Clausal Logic
The goal of developing practical techniques for automated reasoning has led to the
study of computationally viable subsets of classical logic. Clausal form is by far the
most successful of these due to its regular (Skolem) normal form, its simple class of
(Herbrand) models, and its eﬃcient (resolution) inference procedure. Since notation
and terminology vary, this section recalls the deﬁnitions best suited to this thesis. To
highlight some key points, general clauses are written as disjunctions L1 ∨. . . ∨Ln
while Horn clauses are usually written as implications A ←A1, . . . , An. Following
[67], the deduction of a clause refers to the derivation of a θ-subsuming clause. The
treatment of SLD resolution and the subsumption theorem is based upon [67]. The
treatment of C-derivations and relative subsumption follows [70], but, like much of
the following review, tends towards the notation of [67].
2.3.1
Syntax
The syntax of clausal logic is computationally convenient in the sense that formulae
are uniformly encoded as sequences of atoms and their negations. Formally, a literal
is either an atom A (a positive literal with atomic part A) or a negated atom ¬A (a
negative literal with atomic part A). If L is a literal with atomic part A, then the
complement of L, denoted L, is deﬁned as the literal ¬A, if L = A; and as A, if
L = ¬A. A clause C is a ﬁnite sequence of literals L1, . . . , Ln that for convenience
will be written as a disjunction L1 ∨. . .∨Ln. A Horn clause is a clause with either no
positive literals (a negative clause) or exactly one positive literal (a deﬁnite clause).
A unit clause is a (Horn) clause with exactly one literal. The empty clause, denoted
□, is the (negative Horn) clause containing no literals. If C = L1 ∨. . .∨Ln is a clause

2.3. CLAUSAL LOGIC
20
and θ is a substitution, then Cθ denotes the clause L1θ∨. . .∨Lmθ. Logically, clause C
is understood as denoting the universal closure of the disjunction of its literals — and
logical falsity if the clause is empty. A clause C = L1 ∨. . . ∨Lm is said to θ-subsume
a clause D = M1 ∨. . . ∨Mn, written C ⪯D, iﬀthere exists a substitution θ such
that for all 1 ≤i ≤m it holds that Liθ = Mj for some 1 ≤j ≤n.2 A clause C is
said to be reduced iﬀit does not θ-subsume some proper sub-clause (i.e. subsequence)
of itself. It is well known [70, 67] that θ-subsumption induces a ordering on the set
of reduced clauses (up to the renaming of variables). A theory is a set of clauses
C1, . . . , Cm that for convenience will be written as a conjunction C1 ∧. . . ∧Cm. A
unit, deﬁnite, negative, etc., theory is a set of unit, deﬁnite, negative, etc., clauses.
The empty theory is denoted ■. Logically, a theory T = {C1, . . . , Cm} is understood
as the conjunction of its clauses — and logical truth if the theory is empty. A theory
S is said to θ-subsume a theory T, written S ⪯T, iﬀeach clause in T is θ-subsumed
by (at least) one clause in S and each clause in S θ-subsumes (at least) one clause
in T.
With respect to a theory T, a Skolemising substitution for a clause C is a
substitution σ that binds each variable in C to a distinct constant not appearing in
T or C. With respect to a Skolemising substitution σ, the complement of a clause C,
denoted C, is the (ground unit) theory L1σ ∧. . . ∧Lnσ.
2.3.2
Semantics
The semantics of clausal logic is usually restricted to the class of so-called Herbrand
models, which are especially amenable to symbolic manipulation. With respect to a
given language L, the Herbrand universe, HL, is the set of all ground terms in L, and
the Herbrand base, BL, is the set of all ground atoms in L. A Herbrand interpretation
is an interpretation I with domain HL that associates each constant c in L with
the (same) element c ∈HL, and each function f in L of arity n with the function
2Note how the symbol ⪯has the same direction as the symbol ⊆in the sense that ⪯, ≤, ⊑, ⊆all
have the same direction. This convention (which follows [69], but contradicts [76]) emphasises the
intuitive equivalence of C ⪯D and Cθ ⊆D. Note also that θ-subsumption is ‘non-strict’ in the sense
that no restriction is placed on the relative sizes of the subsumed and subsuming clauses.

2.3. CLAUSAL LOGIC
21
f I : Hn
L →HL such that f I(t1, . . . , tn) = f(t1, . . . , tn) for all t1, . . . , tn ∈HL. Thus,
the value of any ground term is itself (i.e. for all terms t ∈HL and for all assignments
h, it holds that [t]I,h = t) and the truth of any ground atom is solely determined by
the interpretation of its predicate symbol (i.e. for all atoms p(t1, . . . , tn) ∈BL, it
holds that I |= p(t1, . . . , tn) iﬀpI(t1, . . . , tn)). Without loss of generality, a Herbrand
interpretation is conventionally identiﬁed with the subset of the Herbrand base that
it interprets as true (i.e. for all atoms a ∈BL, one writes a ∈I iﬀI |= a). If T
is a clausal theory, then a Herbrand model of T is any Herbrand interpretation that
satisﬁes T. It is well known [47] that the set Herbrand models of T form a complete
lattice under the partial order of set inclusion, and that the theory T is satisﬁable
iﬀit has a Herbrand model.
Moreover, any ﬁrst-order formula can be eﬃciently
transformed into a set of clauses such that the latter is satisﬁable iﬀthe former
is satisﬁable. Consequently, the notions of (un-)satisﬁability and logical entailment
can be computed by semi-decision procedures for determining the (non-)existence of
Herbrand models of clausal theories.
2.3.3
Resolution
The resolution principle is an extremely powerful method for clausal reasoning.3 If
C = C1 ∨. . . ∨Cm and D = D1 ∨. . . ∨Dn are two clauses, and C′ = Ci1 ∨. . . ∨Cip
and D′ = Dj1 ∨. . . ∨Djq are two non-empty sub-clauses thereof, then a resolvent
of C and D (on the literals Ci1, . . . , Cip and Dj1, . . . , Djq) is a clause R of the form
L1θ ∨. . . ∨Lm−pθ ∨M1θ ∨. . . ∨Mn−qθ, where (i) L1 ∨. . . ∨Lm−p is the clause
obtained from C by removing all of the literals in C′, (ii) M1 ∨. . . ∨Mn−q is the
clause obtained from D by removing all of the literals in D′, and (iii) θ is an mgu of
the literals {Ci1, . . . , Cip, Dj1, . . . , Djq}. If both p = 1 and q = 1, then R is called a
factor-free (or binary) resolution (of C and D). If m = p (resp. n = q), then R is
3As deﬁned in this thesis, resolution is essentially the ordered resolution of [7] except that, following
[78], factoring is built into the resolution step and, following [44], the renaming of variables is not.
When factoring is not required, this will be explicitly stated.

2.3. CLAUSAL LOGIC
22
called a unit resolution of D (resp. of C). Each literal Liθ in R (resp. Mjθ in R)
is said to be contributed by the corresponding literal Li in C (resp. Mj in D) and is
said to be contingent upon (each of) the selected literals D′
j in D′ (resp. C′
i in C′).
An illustration of one resolution step is provided in the ﬁgure below, which shows
the resolution of two parent clauses C and D (on the underlined literals) to give the
resolvent clause R. Intuitively, the resolvent is the clause obtained by concatenating
the parents, deleting the selected literals, and applying the mgu {x/0, y/0, v/0} of the
selected literals to the remaining literals. This is not a factor-free resolution because
more than one literal is selected in one of the parents; nor is it a unit resolution since
at least one literal is not selected in both of the parents. The ﬁrst literal a(0) in R
is contributed by the literal a(x) in C, and it is contingent upon the literal ¬b(v, v)
in D. The last literal a(0) in R is contributed by the literal a(v) in D, and it is
contingent upon the literals b(x, y) and b(0, y) in C.
C = a(x) ∨b(x, y) ∨c(x, y, z) ∨b(0, y) ∨a(y)
D = a(u) ∨¬b(v, v) ∨a(v)
R = a(0) ∨c(0, 0, z) ∨a(0) ∨a(u) ∨a(0)
The full power of the resolution principle becomes apparent when individual steps
are composed into derivations. Let D be a clause, and let T be a theory. A resolution
derivation R (of D) (from T) (of length n + 1) is a ﬁnite non-empty sequence of
clauses ⟨R0, . . . , Rn⟩such that Rn = D and for all 0 ≤i ≤n clause Ri is either (i)
a variant of some clause C ∈T, or (ii) a resolvent of two preceding clauses Rj and
Rk for some 0 ≤j ≤k ≤n. In case (i), Ri is called an input clause, and C is called
the generator of Ri (and Ri is said to be an input occurrence of C). In case (ii), Ri is
called a resolvent clause, and Rj and Rk are called the parents of Ri (and Ri is said
to be a child of Rj and Rk). The last clause Rn = D in the sequence is called the root

2.3. CLAUSAL LOGIC
23
clause. A tree derivation is a resolution derivation in which (a) all input clauses are
standardised apart, (b) each non-input clause has two distinct parents, and (c) each
non-root clause has one unique child. For convenience, a tree derivation is simply
called a derivation. A factor-free derivation is a derivation in which every resolvent
is a factor-free resolution (of its parents). A unit derivation is a derivation in which
every resolvent is a unit resolution (of at least one parent). A deduction of D from
T is a derivation from T of some clause D′ that θ-subsumes D. A refutation of T is
a derivation from T of the empty clause □. The annotation ⟨C = R0, . . . , Rn = D⟩
represents the derivation ⟨R0, . . . , Rn⟩together with the information R0 = C and
Rn = D.
It is well known that T |= D iﬀD is a tautology or there exists a deduction of D
from T — a result called the subsumption theorem [46, 43, 70, 67]. If R is a derivation
from a theory T, then a clause Rj in R is said to be a descendant of another clause
Rk in R iﬀRj is a child of Rk or is the child of a descendant of Rk. A literal L
in Rj is said to be descended from a literal M in Rk iﬀL is contributed by M or is
contributed by some literal descended from M. Literal L in Rj is said to be dependent
upon some other literal M in Rk iﬀL is contributed by or contingent upon M or
is contributed by or contingent upon some literal dependent upon M. In addition,
every literal is dependent upon itself. An illustrative derivation is provided in the
ﬁgure below, which portrays a (tree) derivation of the root clause R5 from the input
clauses R1, R2 and R4. Clause R3 is the descendant of clauses R1 and R2. Clause
R5 is the descendant of clauses R1, R2, R3 and R4. Literal c(0, 0, z) in clause R5 is
descended from literal c(x, y, z) in clause R1 and from literal c(0, 0, z) in clause R3.
Literal d(0) in clause R5 is dependent upon literal d(w) in clause R4, upon all of the
selected literals in clause R3 and upon all of the literals in clauses R1 and R2 except
c(x, y, z).

2.3. CLAUSAL LOGIC
24
R1 = a(x) ∨b(x, y) ∨c(x, y, z) ∨b(0, y) ∨a(y)
R2 = a(u) ∨¬b(v, v) ∨a(v)
R3 = a(0) ∨c(0, 0, z) ∨a(0) ∨a(u) ∨a(0)
R4 = ¬a(w) ∨d(w)
R5 = c(0, 0, z) ∨d(0)
2.3.4
C-derivations
Resolution derivations with additional restrictions will play a key role in this thesis.
Ultimately, these restrictions all build upon the notion of C-derivation, which was
introduced by Gordon Plotkin in his doctoral thesis [70] together with the closely
related concept of relative subsumption. In brief, the practical signiﬁcance of relative
subsumption comes from its status as a logical relation that is more expressive than
θ-subsumption, but more tractable than classical entailment. In turn, the theoretical
interest in C-derivations is due to the fact that they provide a procedural semantics
for relative subsumption.
Moreover, because they formalise the generalisation of
(example) clauses relative to (background) theories, relative subsumption and C-
derivations are intimately connected to the ILP systems discussed in this thesis. The
rest of this section recalls the relevant deﬁnitions using the notation and terminology
of previous sections. Formally, if T is a theory and C and D are clauses, then C
is said to subsume D relative to T, denoted C ⪯T D, iﬀthere exists a clause E
such that T |= ∀(E ↔D) and C ⪯E.4 Additionally, if T is a theory and C and
D are clauses, then a C-derivation of D from T (wrt. C) is a derivation of D from
4This deﬁnition of relative subsumption is taken from [70, p.49] subject to the following revisions:
ﬁrst, [70] uses the terminology ‘relative generalisation’ instead of ‘relative subsumption’; second,
[70] uses the typography ‘C ≤D (Th)’ rather than ‘C ⪯T D’, where Th represents a ﬁrst-order
theory; third, [70] uses the free variable notation ‘⊢T h E ≡D’ in place of the quantiﬁed formula
‘T |= ∀(E ↔D)’; and fourth, [70] deﬁnes a clause as a set rather than a sequence of literals.

2.4. LOGIC PROGRAMMING
25
T ∪{C} in which C is the generator of at most one (input) clause.5 As shown in [70],
an alternative characterisation of relative subsumption is given by the equivalence:
C ⪯T D iﬀthere exists a substitution σ such that T |= ∀(Cσ →D); and the
relationship between relative subsumption and C-derivations can be stated: C ⪯T D
iﬀD is a tautology or there exists a C-deduction of D from T. (Recalling the remarks
at the start of Section 2.3, a C-deduction of D refers to a C-derivation of a clause
C that θ-subsumes D.) In fact, this latter result is not quite correct since, setting
T = (p∨¬q(a)∨¬q(b))∧q(x) and C = q(x) and D = p, it is clear that C subsumes D
relative to T (using E = p∨q(x) in the deﬁnition above), but there is no C-deduction
of D from T (as C must, strictly speaking, be used twice to derive D).
This is
because it is implicit in both the deﬁnition of the C-derivation and in proofs of the
above results that no restriction is actually imposed on the use of the clause C if it
is already contained in the theory T.
2.4
Logic Programming
The Horn clause fragment of ﬁrst-order logic is especially suitable for computational
purposes due to its procedural (ﬁxed-point) semantics and its eﬃcient (SLD) reso-
lution proof procedure. A deﬁnite clause R = A ∨¬A1 ∨. . . ∨¬An is also called
a (deﬁnite) rule and denoted A ←A1, . . . , An.
The atom A is called the head
atom and the atoms A1, . . . , An are called body atoms.
If n = 0 then R is also
called a fact (and is simply written A). Rule R is generative iﬀevery variable that
appears in its head atom also appears in some body atom; and is constrained iﬀ
every variable that appears in some body atom also appears in the head atom.
(Ssee [66] for an explanation of these and other restrictions.)
A negative clause
5This deﬁnition of C-derivation is taken from [70, p.51] subject to the following revisions: ﬁrst,
[70] uses the terminology ‘C-derivation of D from T ∪{C}’ as opposed to ‘C-derivation of D from T’;
and second, [70] actually deﬁnes the C-derivation as a derivation in which ‘no two descendants of an
occurrence of C at a tip are resolved together’ and subsequently observes that ‘in any C-derivation
there are either no occurrences of C on a tip or else there is exactly one’.

2.4. LOGIC PROGRAMMING
26
G = ¬A1 ∨. . . ∨¬An is also called a goal or query and denoted ←A1, . . . , An or
?A1, . . . , An. If n = 1 then G is called a counter-fact (and is simply written ¬A). A
deﬁnite theory P = {R1, . . . , Rn} is also called a (deﬁnite) program. For simplicity,
where there is no danger of ambiguity, clauses will often be separated by full-stops,
semi-colons or vertical space. The Herbrand base, BP , of a program P is the set of
all ground atoms in BL whose predicate appears in P. The ground instantiation,
GP , of P is the set of all ground rules in L that are instances of a rule in P. The
immediate consequence operator, TP , of P is the function TP : 2BP →2BP such that
TP (I) = {A | A ←A1, . . . , An ∈GP and A1, . . . , An ∈I}. It is well known [47]
that there is a least Herbrand model (LHM), denoted MP , of P which is both the
intersection of all other Herbrand models, and also the least ﬁxed-point (lfp) of TP.
For any deﬁnite program P and any formula F, the notation P |=∗F will be used as
an abbreviation for MP |= F, and states that F is true in the LHM of P.
In order for two Horn clauses to resolve, at least one must be deﬁnite and exactly
one must resolve on its head atom. By convention, the parent that resolves on its
head atom is called the side clause, while the other parent is called the centre clause.
The resolvent of two Horn clauses is understood as the Horn clause obtained by
resolving the side parent with the centre parent (in that order). An SLD derivation
is a Horn (factor-free tree) derivation ⟨C = C0, S1, C1, . . . , Sn, Cn = D⟩of a clause D
from a theory T such that for all 1 ≤i ≤n (i) Ci is a binary resolvent of Ci−1 and
Si on some selected body atom of Ci−1, and (ii) Si is a (fresh) variant of some clause
in T. For convenience, an SLD derivation will often be represented as a sequence
of 3-tuples of the form: ⟨(∅, ∅, C0), (θ1, S1, C1), . . . , (θn, Sn, Cn)⟩, where θi is the mgu
used to resolve the clauses Ci−1 and Si (i.e. the two clauses either side of θi in the
sequence above).
If G = ←A1, . . . , An is a goal and P is a program, then G is
said to succeed from P (in n steps) (with answer θ) iﬀthere is an SLD refutation
⟨(∅, ∅, G), (θ1, S1, C1), . . . , (θn, Sn, □)⟩of P ∪{G} and θ is the composition of the mgu’s
θ1θ2 · · · θn. Such a refutation is also called a refutation of G by P. The restriction θ|G
of θ to the variables in G is called the computed answer substitution. It is well known

2.4. LOGIC PROGRAMMING
27
that P |= ∀(A1φ∧· · ·∧Anφ) for some substitution φ iﬀG succeeds from P with some
answer θ such that θ|G is more general than φ — a result called the soundness and
completeness of SLD [47, 4, 67]. As shown in [67], the subsumption theorem holds for
Horn clause logic when restricted to SLD resolution: thus, if T is a Horn theory and
C is a Horn clause, then T |= C iﬀC is a tautology or there is an SLD-deduction of
C from T (i.e. an SLD-derivation from T of a clause that θ-subsumes C).
The attraction of Horn clause logic is further enhanced by the existence of highly
developed computational engines and programming environments for the Prolog logic
programming language [89, 10]. For ease of execution, many of the examples in this
thesis are written using Prolog style syntax. In contrast to the notation presented
earlier, Prolog variables begin with upper case letters the connective ‘:-’ is used to
separate the head and body of a rule. This notation is illustrated on the left hand side
of the ﬁgure below, which shows a logic program composed of ﬁve clauses: three rules
and two facts. This thesis assumes a familiarity with SLD trees [47, 26] generated by
a given goal with respect to a program whose literals are implicitly ordered from left
to right and whose clauses are ordered from top to bottom. This notion is illustrated
on the right hand side of the ﬁgure below, which shows the SLD-tree for the goal
←a(x) on the program shown. The three branches show respectively a successful
computation with answer {x/1}, an inﬁnitely failed sub-computation, and a ﬁnitely
failed computation.
a(X):-b(X),c(X)
b(1)
b(X):-a(X)
b(X):-d(X)
c(X)
a(x)
b(x), c(x)
c(1)
□
{x/1}
a(x), c(x)
∞
...
d(x), c(x)
■

2.4. LOGIC PROGRAMMING
28
To make logic programming more convenient for knowledge engineering purposes,
several extensions of pure logic programs have been proposed. The most important of
these are normal programs which provide a facility for default reasoning by allowing
so-called Negation as Failure (NAF) [9] in the bodies of clauses. Formally, a normal
rule (resp. goal) is an expression of the form A ←L1, . . . , Ln (resp. ←L1, . . . , Ln)
where A is an atom and each Lj is a literal of the form Ai or ¬Ai for all 1 ≤i ≤n.
A normal program is a set of normal rules. Most Prolog systems provide support
for normal programs using a procedural extension of pure SLD-resolution known as
SLDNF [47] (i.e. SLD resolution with Negation as Failure rule), which operates as
follows: whenever a positive goal literal A is selected, it is resolved with a program
clause in the normal way; whenever a negative goal literal ¬A is selected, its success
or failure is determined by querying the positive goal literal A instead. Very simply,
if the positive literal A ﬁnitely fails (resp. succeeds), then the negative literal ¬A is
regarded as succeeding (resp. failing). If A inﬁnitely fails, then so does ¬A.
There is no universally accepted semantics for normal logic programs. Instead,
diﬀerent semantics are used that each identify one or more preferred Herbrand models
as the intended meaning of a program.
Fortunately, in the case of deﬁnite logic
programs, which applies throughout most of this thesis, all of these models coincide
with the LHM. But, since future extensions of this work to normal programs are
discussed in Chapter 9, and as the connection between NAF and ALP is described
in Chapter 3 and exploited in Chapter 6, it is appropriate to brieﬂy recall the stable
model semantics [24], which is the most relevant to this thesis. Formally, if P is a
normal program and I is an interpretation for P, then the reduct of P wrt. I, denoted
P I, is the set of deﬁnite ground clauses obtained from P by removing each ground
rule in GP which contains a negative literal that is not satisﬁed in I, and by removing
all of the negative literals in the remaining clauses. A stable model of the program P
is then deﬁned as any interpretation I such that I = MP I.
Stable models are known to exist for several classes of logic program that are
summarised in the ﬁgure below together with their inter-relationships recalled from

2.4. LOGIC PROGRAMMING
29
[83].
Note that the arrows in this ﬁgure indicate strict containment: so that the
class of order-consistent programs includes the class of locally-stratiﬁed programs,
which includes the class of stratiﬁed programs, which includes the class of hierarchical
programs. Equivalently, every hierarchical program is stratiﬁed, and hence locally-
stratiﬁed and thus order-consistent. Another well-known result [24] is that all locally-
stratiﬁed programs possess a unique stable model.
hierarchical
stratiﬁed
call-consistent
acyclic
locally-stratiﬁed
order-consistent
In the terminology of [83], the above notions are deﬁned using the predicate and
atom dependency graphs of a program. For any normal program P, the predicate
dependency graph (pdg) is the directed graph with signed edges whose nodes are the
predicate symbols appearing in P such that there is a positive (resp. negative) edge
from p to q iﬀthere is a clause in P with p in the head atom and q in a positive (resp.
negative) body literal. Similarly, the atom dependency graph (adg) is the directed
graph with signed edges whose nodes are the ground atoms appearing in GP such
that there is a positive (resp. negative) edge from a to b iﬀthere is a clause in GP with
a as the head atom and b as a positive (resp. negative) body literal. By convention,
node a is said to depend positively on b iﬀthere is a (possibly empty) path from a to
b with an even number of negative edges; whereas a is said to depend negatively on b
iﬀthere is a path from a to b with an odd number of negative edges. Based on these
deﬁnitions, P is hierarchical (resp. acyclic) iﬀthere are no cycles in the pdg (resp.
adg); P is stratiﬁed (resp. locally-stratiﬁed) iﬀthere are no cycles with a negative
edge in the pdg (resp. adg); P is call-consistent iﬀthere are no cycles with an odd
number of negative edges in the pdg; and P is order-consistent iﬀthe descendancy
relation {(a, b)
|
a depends both positively and negatively on b} is a well-founded
strict partial order.

Chapter 3
Abductive Logic Programming
This chapter introduces the task of Abductive Logic Programming (ALP) [34], recalls
the semantics of Generalised Stable Models (GSM’s) [36] and reviews the ALP proof
procedure of Kakas and Mancarella (KM) [35].
Section 3.1 begins by formalising
the notions of abductive context, abductive explanation, minimality and basicality [34].
Sections 3.2 and 3.3 review the GSM semantics and the KM procedure. Section 3.4
concludes with some bibliographic remarks.
3.1
Abductive Logic Programming (ALP) Task
ALP is the ﬁeld of Artiﬁcial Intelligence concerned with ﬁnding hypotheses ∆to
explain a goal G with respect to a theory T and integrity constraints IC. In brief, the
goal G is a set of literals to be explained, the theory T is a normal program expressing
some prior knowledge, and the integrity constraints IC are a set of formulae that
restrict the acceptable hypotheses. Informally, the explanation ∆is a set of ground
atoms that, relative to T, ‘cover’ G and are ‘consistent’ with IC. Typically, ∆is
restricted to the ground instances A of some given set of abducible predicates. The
idea is that T represents an almost complete theory where the abducible predicates
are not completely speciﬁed; and the goal G denotes an existentially quantiﬁed query
which must be made to succeed by adding a set ∆of abducibles A to the theory T
subject to the constraints in IC.
30

3.1. ABDUCTIVE LOGIC PROGRAMMING (ALP) TASK
31
To formalise the ALP task, it remains to make precise the concepts of coverage
and consistency used above. As explained in [34], a standard solution is to deﬁne
both these notions as truth in a stable model of the augmented program T ∪∆. In
particular, if A is the set of abducibles, then the task of ALP is to ﬁnd a subset
∆⊆A and a substitution θ such that Gθ and IC are satisﬁed in some stable model
of T ∪∆. Following [34], it is convenient to regard the abducibles as the set of all
ground instances of some predicate symbols which are initially declared as abducible
(and, by convention, to let A refer to both the abducible predicates and their ground
instances).
As in standard logic programming approaches, the answer θ indicates
the successful instances of the goal; but in ALP, each answer now comes with an
accompanying explanation ∆representing a set of additional assumptions needed for
the goal to succeed.
In this thesis, the inputs ⟨T, G, IC, A⟩and output ∆of the ALP task are called
respectively an abductive context and an abductive explanation.
As formalised in
Deﬁnitions 3.1.1 and 3.1.2 below, a set of ground abducibles ∆is an explanation for
the context ⟨T, G, IC, A⟩— for some computed answer substitution θ — iﬀat least
one stable model of T ∪∆satisﬁes Gθ and that same model also satisﬁes IC. Note that
the possibility of restricting G by the substitution θ reﬂects the convention of reading
the goal as an existentially quantiﬁed query. As mentioned at the end of the previous
chapter, if T is a deﬁnite program, then the unique stable model of T ∪∆coincides
with the LHM of T ∪∆. In the deﬁnite case, using the notation of Section 2.4, the
two conditions in Deﬁnition 3.1.2 become T ∪∆|=∗Gθ and T ∪∆|=∗IC.
Deﬁnition 3.1.1 (Abductive context). An abductive context is a tuple ⟨T, G, IC, A⟩
where T is a normal program, G is a set of literals, IC is a set of closed ﬁrst-order
formulae, and A is a set of ground atoms.
Deﬁnition 3.1.2 (Abductive explanation). Suppose that X = ⟨T, G, IC, A⟩is an
abductive context.
Then an abductive explanation of X is a set of ground atoms
∆⊆A for which there exists a stable model M of T ∪∆and a ground instance Gθ
of G such that M |= Gθ and M |= IC.

3.1. ABDUCTIVE LOGIC PROGRAMMING (ALP) TASK
32
Since one abductive context may admit several diﬀerent abductive explanations,
additional preference criteria are needed to discriminate between alternative solutions.
Two popular desiderata are the properties of minimality and basicality, which were
originally introduced in [12] and are simpliﬁed in Deﬁnition 3.1.3 below. Informally,
an explanation ∆is minimal if it contains no redundant atoms (i.e. ∆contains no
sub-explanation of the goal) and it is basic if it is as fundamental as possible (i.e. ∆
is contained in all explanations of itself).
Deﬁnition 3.1.3 (Minimal, Basic). Let X be an abductive context ⟨T, G, IC, A⟩,
∆be an abductive explanation of X, and Y be the abductive context ⟨T, ∆, IC, A⟩.
Then ∆is minimal iﬀthere is no ∆′ ⊂∆such that ∆′ is an explanation for X; and
∆is basic iﬀthere is no explanation ∆′ of Y such that ∆̸⊆∆′.
Example 3.1.4. Let X = ⟨T, G, IC, A⟩be the abductive context deﬁned below. The
theory T contains three clauses that partially describe a domain relating to fast food
outlets, or bistros. The ﬁrst rule states that to have a meal in an outlet x, it is
suﬃcient to have a burger and fries there. The second rule states that a free burger
comes with every order of fries at outlets with a special offer. The remaining fact
states that mcDonalds is currently participating in such an offer.
T
=











meal(x) ←fries(x), burger(x)
burger(x) ←fries(x), offer(x)
offer(mcDonalds)











G
=
{meal(mcDonalds)}
IC
=
{ ←fries(x), ¬bistro(x)}
A
=
{fries/1, bistro/1}
The abducibles A allow assumptions of the form fries(t) and bistro(t), where t is
a ground atom; but the integrity constraint IC requires that fries can only be served
in outlets that are bistros. (Literally: for any x, one cannot have fries(x) and fail to
have bistro(x).) The goal G can be regarded as asking whether there is an explanation

3.2. GENERALISED STABLE MODEL (GSM) SEMANTICS
33
of the fact meal(mcDonalds). With reference to Deﬁnitions 3.1.2 and 3.1.3, above, it
can be shown that the hypothesis ∆, below, is an abductive explanation of X that is
both minimal and basic. (Note that ∆′ = {fries(mcDonalds)} violates the integrity
constraint, and ∆′′ = {fries(mcDonalds), bistro(mcDonalds), bistro(burgerKing)}
is not minimal.)
∆
=



fries(mcDonalds)
bistro(mcDonalds)



3.2
Generalised Stable Model (GSM) Semantics
Equivalently to the formalisation of abductive explanations in the previous section,
the task of ALP can alternatively be characterised in terms of the so-called Generalised
Stable Models (GSMs) of an abductive framework. Just as stable models represent
the deductive meaning of a program, so GSMs provide the abductive semantics of
a program in a way that is independent of any particular goal.
As formalised in
Deﬁnition 3.2.1 below, an abductive framework is simply a triple of the form ⟨T, IC, A⟩
i.e. an abductive context but without any goal.
Deﬁnition 3.2.1 (Abductive framework). An abductive framework is a triple ⟨T, IC, A⟩
where T is a normal program, IC is a set of closed ﬁrst-order formulae, and A is a
set of ground atoms.
As formalised in Deﬁnition 3.2.2 below, the GSMs of a framework ⟨T, IC, A⟩are
deﬁned as the stable models of the theory and all abductive extensions of the theory
that satisfy the integrity constraints. Intuitively, the GSM semantics generalises the
stable model semantics by considering not only the stable models of program P,
but also the stable models of all valid abductive extensions P ∪∆. It is immediate
from Deﬁnitions 3.2.1 and 3.2.2 that ∆is an abductive explanation of a context
⟨T, G, IC, A⟩iﬀG is satisﬁed in some GSM M(∆) of the framework ⟨T, IC, A⟩.

3.2. GENERALISED STABLE MODEL (GSM) SEMANTICS
34
Deﬁnition 3.2.2 (Generalised Stable Model - GSM). Let X = ⟨T, IC, A⟩be an
abductive framework. Then a GSM of X, denoted M(∆), is an interpretation M for
which there exists a set of ground atoms ∆⊆A such that M is a stable model of
T ∪∆that satisﬁes IC.
When viewed in these terms, abduction is essentially the process of assuming
(consistent) ground atoms in order to make a goal succeed. This is true whether the
program is normal or deﬁnite. There is, however, an important connection between
abduction in deﬁnite programs and deduction in normal programs. Speciﬁcally, it
is shown in [17] how NAF can be transformed into an equivalent ALP problem by
re-writing negated atoms ¬p(t1, . . . , tn) as positive abducibles p∗(t1, . . . , tn), where p∗
is a new predicate that intuitively represents the absence of p. This technique was
then generalised in [36] to the case of arbitrary abductive frameworks by means of
the syntactic transformation formalised in Deﬁnitions 3.2.3 and 3.2.4 below.
Deﬁnition 3.2.3 (Positive form of an expression). The positive form of an expression
X, denoted X∗, is the expression obtained from X by replacing each negative literal
¬p(t1, . . . , tn) with predicate p by the positive literal p∗(t1, . . . , tn), where p∗is fresh
predicate called a starred predicate.
Deﬁnition 3.2.4 (Positive form of a framework). The positive form of an abductive
framework ⟨T, IC, A⟩, is the framework ⟨T ∗, IC∗∪IC′, A ∪A′⟩, where A′ contains
one starred atom a∗for each unstarred ground atom a ∈BT , and IC′ is the set of
constraints ∀(p∗(x1, . . . , xn) ↔¬p(x1, . . . , xn)).
Informally, the positive form of an expression is obtained by replacing every
negated predicate ¬p by the positive predicate p∗.
Then, the positive form of a
context is obtained by (i) taking the positive forms of T, G and IC, (ii) declaring
the predicates p∗as abducible, and (iii) adding a canonical integrity constraint for
each new predicate. Note that the constraint above is equivalent to the constraints
∀¬(p∗(...) ∧p(...)) and ∀(p∗(...) ∨p(...)) used in [36], and states that, for each ground
atom, either p(t1, . . . , tn) or p∗(t1, . . . , tn) is true, but not both.

3.3. KAKAS-MANCARELLA (KM) PROOF PROCEDURE
35
Because there is a formal one-to-one correspondence [36] between the GSMs of
the framework ⟨T, IC, A⟩and those of its positive form ⟨T ∗, IC∗∪IC′, A ∪A′⟩, the
transformation formalised above can be used to provide a common semantic context
for abduction and negation. Under certain restrictions, this observation can be used to
implement eﬃcient computational techniques for performing abduction over normal
logic programs. The best known example is the ALP proof procedure of Kakas and
Mancarella, which is described in the next section.
3.3
Kakas-Mancarella (KM) Proof Procedure
One of the main diﬃculties when computing abductive explanations for a given goal,
is the problem of eﬃciently ensuring the satisfaction of the integrity constraints:
both the explicit domain constraints IC∗, and also the implicit canonical constraints
for negation IC′. The KM procedure addresses this issue by interleaving two types
of computation: namely, abductive computations, in which abducibles are assumed,
and consistency computations, in which those assumptions are tested for consistency
against the integrity constraints.
The KM procedure takes as input a context ⟨T, G, IC, A⟩and returns as output
a set of explanations ∆. A key design principle underlying the KM procedure is the
avoidance of extensive integrity checking every time an atom is abduced. For this
reason, two restrictions are imposed upon the inputs. First, T is a set of normal rules
in which no abducibles are deﬁned (i.e. none of the rules in T has a predicate from
A in its head).1 Second, IC is a set of normal goals each containing at least one
abducible (i.e. each of the goals in IC has a predicate from A in its body).
Before describing the KM procedure, it is helpful to ﬁrst explain the signiﬁcance
of these restrictions. First, they ensure the integrity constraints are initially satisﬁed,
before any abducibles are assumed. This is because a constraint is only violated if
1 As explained in [34], this is not restrictive since any abductive framework can be transformed
into an equivalent framework (with isomorphic GSMs) satisfying this property.
This is done by
replacing every abducible p deﬁned in T by a new predicate p′ and adding the clause p′ ←p.

3.3. KAKAS-MANCARELLA (KM) PROOF PROCEDURE
36
there is at least one ground instance where all of the literals are true. But, at least one
of those literals is an abducible, and, since no abducible is deﬁned in the theory, the
only way to make that literal true is to assume it. Second, they enable the consistency
of an abducible to be established by reasoning backwards from only those constraints
that resolve with the abducible.
Given a context ⟨T, G, IC, A⟩satisfying the conditions above, the KM procedure
initiates an abductive derivation whose aim is to generate a set of abducibles that
satisfy both the goal and the integrity constraints. In brief, an abductive derivation
involves unfolding the goal in standard Prolog fashion until an abducible a is selected.
Whereas Prolog would fail the computation and backtrack at this point, KM treats
the abducible as a candidate hypothesis, and invokes a consistency derivation to see
if a can be consistently added to the current hypothesis ∆.
Every consistency computation has one separate branch for each resolvent of the
integrity constraints and the abducible a under investigation.2 Every such resolvent is
regarded as a query that must be made to ﬁnitely fail in order for the integrity check to
succeed. If needed this failure can be expedited by initiating a subordinate abductive
derivation in order to hypothesise some other abducible (explicit or negative). To
ensure correctness, any abducibles assumed on one branch of the integrity check are
incrementally carried over to the next.
If all branches of the consistency derivation are passed (i.e. they are all made to
fail), the enclosing abductive computation continues with the abducible a added to ∆
(along with any other abducibles accumulated during the consistency computation);
indicating that all subsequent calls to a should immediately succeed. If some branch
of the consistency derivation does not succeed (i.e. it cannot be made to fail), the
enclosing abductive computation is failed subject to backtracking; indicating that a
is inconsistent with ∆. Formally, successful abductive and consistency derivations
are sequences of goal-hypothesis pairs that satisfy the following conditions.
2The formalisation in Deﬁnition 3.3.1 below only resolves the integrity constraints with positive
abducibles, but it could be extended to perform integrity checking for negative abducibles as well.

3.3. KAKAS-MANCARELLA (KM) PROOF PROCEDURE
37
Deﬁnition 3.3.1 (Abductive Derivation). An abductive derivation from ⟨G1, ∆1⟩to
⟨Gn, ∆n⟩is a ﬁnite sequence of pairs (⟨G1, ∆1⟩, . . . , ⟨Gn, ∆n⟩) such that each Gi is a
set of literals, each ∆i is a set of ground literals, and for all 1 ≤i < n (at least) one
of the following four conditions is satisﬁed:
(A1) ∆i+1 = ∆i and ←Gi+1 is a resolvent of ←Gi and some clause Ci ∈T
(A2) ∆i+1 = ∆i and Gi+1 = Gi/{Li} for some (ground abduced) literal Li ∈Gi ∩∆i
(A3) ∆i+1 = ∆′ and Gi+1 = Gi/{Li} for some positive ground abducible Li ∈Gi/∆i
and some set ∆′ ⊇∆i ∪{Li} such that Li ̸∈∆i and there exists a consistency
derivation from ⟨IC′, ∆i ∪{Li}⟩to ⟨∅, ∆′)⟩— where IC′ denotes the set of all
resolvents of Li with the goals in IC
(A4) ∆i+1 = ∆′ and Gi+1 = Gi/{Li} for some negative ground literal Li ∈Gi/∆i
and some set ∆′ ⊇∆i ∪{Li} such that Li ̸∈∆i and there exists a consistency
derivation from ⟨{ ←Li}, ∆i ∪{Li}⟩to ⟨∅, ∆′)⟩.
Deﬁnition 3.3.2 (Consistency Derivation). A consistency derivation from ⟨F1, ∆1⟩
to ⟨Fn, ∆n⟩is a ﬁnite sequence of pairs (⟨F1, ∆1⟩, . . . , ⟨Fn, ∆n⟩) where each Fi is a set
of normal goals, each ∆i is a set of ground literals, and for all 1 ≤i < n there exists
some goal Gi ∈Fi satisfying (at least) one of the following four conditions:
(C1) ∆i+1 = ∆i and Fi+1 = (Fi/{Gi}) ∪IC′ — where IC′ denotes the set of all
resolvents of Gi and the clauses in T on some positive non-abducible literal
Li ∈Gi such that □̸∈IC′
(C2) ∆i+1 = ∆i and Fi+1 = Fi/{Gi} and there exists some (ground) negative literal
Li ∈Gi such that Li ∈∆i
(C3) ∆i+1 = ∆i ∪{Li} and Fi+1 = Fi/{Gi} for some positive ground abducible
Li ∈G/∆i
(C4) ∆i+1 = ∆′ and Fi+1 = Fi/{Gi} for some set ∆′ ⊇∆i for which there exists an
abductive derivation from ⟨{Li}, ∆i⟩to ⟨∅, ∆′⟩for some negative ground literal
Li ∈G such that {Li, Li} ∩∆i = ∅.

3.3. KAKAS-MANCARELLA (KM) PROOF PROCEDURE
38
In these deﬁnitions, the complement L of a positive literal L = p(t1, . . . , tn) is
taken as the positive form p∗(t1, . . . , tn) of the negative literal ¬L, and vice versa.
In addition, the goal ←G corresponding to a set G = {L1, . . . , Ln} is understood
as the goal ←L1, . . . , Ln obtained in the obvious way. Finally, an abducible literal
refers either to a positive literal with an abducible predicate or to (the positive form
of) a negative literal. A detailed technical description of these deﬁnitions is provided
in [35] and an intuitive illustration is now presented in Example 3.3.3 below.
Example 3.3.3. Let X =⟨T, G, IC, A⟩be the abductive context previously speciﬁed
in Example 3.1.4 above. For brevity, let mcDonalds be abbreviated to simply md.
Using Deﬁnitions 3.3.1 and 3.3.2, above, it can be shown that S1 and S3, below,
are successful abductive derivations, and that S2 and S4 are successful consistency
derivations wrt. X.
S1
=
(⟨{meal(md)}, ∅⟩,
⟨{fries(md), burger(md)}, ∅⟩,
⟨{burger(md)}, {fries(md), bistro(md)}⟩,
⟨{fries(md), offer(md)}, {fries(md), bistro(md)}⟩,
⟨{offer(md)}, {fries(md), bistro(md)}⟩,
⟨∅, {fries(md), bistro(md)}⟩)
S2
=
(⟨{ ←bistro∗(md)}, {fries(md)}⟩,
⟨∅, {fries(md), bistro(md)}⟩)
S3
=
(⟨{bistro(md)}, {fries(md)}⟩,
⟨∅, {fries(md), bistro(md)}⟩)
S4
=
(⟨∅, {fries(md), bistro(md)}⟩)
Derivation S1 starts with the goal meal(md) and the empty hypothesis ∅. The goal
is then resolved with the ﬁrst clause in T to leave the two sub-goals fries(md) and
burger(md) (by rule A1). The ﬁrst sub-goal is then abduced along with bistro(md)
(by rule A3 with the consistency derivation S2, noting that ←bistro∗(md) is the
only resolvent of fries(md) with the integrity constraints).

3.3. KAKAS-MANCARELLA (KM) PROOF PROCEDURE
39
The second sub-goal is then resolved with the second clause in T to leave two
further sub-goals fries(md) and offer(md) (by rule A1). The ﬁrst of these, which
has already been abduced, is simply removed (by rule A2). The other one is then
resolved away using the remaining fact in T (by rule A1). In this way, the abductive
derivation concludes with the abductive explanation ∆= {fries(md), bistro(md)}
Derivation S2 starts with the single goal ←bistro∗(md) and the initial hypothesis
{fries(md)}. The complement of this goal is then abduced (by rule C4, using the
abductive derivation S3, noting that bistro(md) is the complement of bistro∗(md)).
Finally, the trivial derivation S3 is obtained using rule A3 and the equally trivial
derivation S4.
With respect to an abductive context ⟨T, G, IC, A⟩, an abductive derivation of
the form (⟨G, ∅⟩, . . . , ⟨∅, ∆⟩) is called a KM computation and (the positive subset of)
∆is called a computed explanation. These notions are formalised in Deﬁnition 3.3.4
below, which recalls the restrictions on T and IC noted above. For technical reasons
explained in the next section, it is also assumed that T is order-consistent.
Deﬁnition 3.3.4 (KM computation). Let X = ⟨T, G, IC, A⟩be an abductive context
such that T is an order-consistent program in which no abducibles are deﬁned, and
IC is a set of normal goals each containing at least one abducible predicate. Then,
a KM computation for X is an abductive derivation from ⟨G, ∅⟩to ⟨∅, ∆⟩. If such a
derivation exists, then ∆is called a computed explanation of X.
Following [34], it is convenient to employ a graphical notation in which abductive
and consistency derivations are drawn within single and double boxes, respectively.
As shown by Fig. 3.1 below, this representation has the advantage of making explicit
the nesting of abductive and consistency derivations and the incremental construction
of the hypothesis. If the correspondence between Fig. 3.1 and Example 3.3.3 is not
immediately clear, the reader is referred to [34] for a more detailed explanation.
By adapting the notation of [13], it is possible to use a more compact textual
representation of KM computations, in which the nesting of derivations is encoded

3.3. KAKAS-MANCARELLA (KM) PROOF PROCEDURE
40
? meal(md)
? fries(md), burger(md)
∆= {fries(md)}
? bistro∗(md)
? bistro(md)
∆= {fries(md), bistro(md)}
...
■
□
■
? burger(md)
? fries(md), oﬀer(md)
? oﬀer(md)
□
Figure 3.1: Graphical representation of Example 3.3.3
?+ meal(md)
?+ fries(md), burger(md)
fries(md)
?−bistro∗(md)
?+ bistro(md)
bistro(md)
?−■
?+ □
?−■
?+ burger(md)
?+ fries(md), offer(md)
?+ offer(md)
?+ □
Figure 3.2: Textual representation of Example 3.3.3

3.3. KAKAS-MANCARELLA (KM) PROOF PROCEDURE
41
through indentation rather than boxes.
For emphasis, abductive and consistency
goals are delimited by the ?+ and ?−symbols, respectively. As shown in Fig. 3.2,
this notation preserves all the advantages of the standard graphical representation,
but is arguably easier to interpret.
The main abductive goal is indicated at the very top of the derivation. Abduced
literals are shown in the column to the left of the derivation (and can be used to
resolve away any goal literal appearing on or below the line of the derivation in
which the abducible is entered). To the right of each such literal is the corresponding
consistency derivation — which aims to show the failure of a negative abducible’s
complement (rule A4) or the resolvents of a positive abducible with the integrity
constraints (rule A3).
As explained above, all consistency derivations are suitably indented from the
enclosing abductive derivation. Similarly, any abductive derivations invoked during
a consistency derivation (rule C4) are correspondingly indented from the enclosing
consistency derivation. If none of the integrity constraints resolve with the abduced
atom, the consistency derivation is denoted ? −■and is understood to have trivially
succeeded — thereby allowing the enclosing derivation to proceed.
Having deﬁned and illustrated the KM proof procedure, it remains to summarise
the main soundness and completeness results with respect to the ALP semantics
presented earlier. Subject to the conditions stated in Deﬁnition 3.3.4, the KM proof
procedure is in fact sound but not complete with respect to the computation of
abductive explanations. In practice, there are two main sources of incompleteness
The ﬁrst source of incompleteness is called ﬂoundering and occurs when all of
the sub-goals in an abductive or consistency derivation are non-ground abducibles.
In this case, none of the rules in Deﬁnitions 3.3.1 and 3.3.2 are applicable and the
computation cannot proceed. For example, the context ⟨∅, {a(0, x)}, ∅, {a/2}⟩has an
explanation {a(0, 0)}, but the KM procedure ﬂounders.
One way to avoid the possibility of ﬂoundering is to prevent the introduction of
variables into any abductive or consistency derivations. For the former, it is suﬃcient

3.4. BIBLIOGRAPHIC REMARKS
42
to ensure G is ground and T is constrained (i.e. all variables in a clause appear in
the head). For the latter, it is suﬃcient to ensure that each variable in an integrity
constraint occurs in at least one positive non-abducible literal of that constraint and
that T is generative (i.e. all variables in a clause appear in the body).
The second source of incompleteness is looping and occurs when program clauses
are searched in a ﬁxed order. For example, the context ⟨{p ←p ; p ←a}, {p}, ∅, {a/0}⟩
has an explanation {a}, but the KM procedure loops using a Prolog search policy.
To prevent looping, it is suﬃcient to ensure T is acyclic. Under these conditions, the
KM procedure is complete in the sense that, for each abductive explanation ∆, there
is a computed explanation ∆′ ⊆∆.
3.4
Bibliographic Remarks
The relationship between ALP and NAF was originally studied in [17] and resulted
in the so-called Eshgi-Kowalski (EK) procedure for realising NAF using ALP. The
EK procedure was later generalised by Kakas and Mancarella in [35] to support
‘proper’ abducibles and ‘explicit’ integrity constraints.
Though closely related to
stable models, both the KM and EK procedures are only sound with respect to the
(generalised) stable model semantics for the class of order-consistent programs This
observation prompted two directions of subsequent work. On the one hand, Satoh and
Iwayama [84] modiﬁed the KM procedure to ensure soundness with respect to stable
model semantics; and on the other, Dung [15] proposed an argumentation semantics
for which the KM procedure is sound in general.
In [37], Kakas and Mancarella
later showed that that Dung’s semantics was in fact equivalent to the partial stable
model semantics of Sacc`a and Zaniolo [81], which, in turn, is closely related to the
stationary model semantics of Przymusinski [71]. In fact, by simply replacing the
notion of stable model with that of a partial stable model, the semantics presented
in this chapter can be generalised in order to characterise the explanations computed
by the KM proof procedure for arbitrary normal programs.
Since its introduction, the KM procedure has been used in a number of systems

3.4. BIBLIOGRAPHIC REMARKS
43
(some of which are discussed in later chapters) and has been extended in several ways.
Of these, the most signiﬁcant extensions are for constructive abduction [38], constraint
logic programming [40] and active rules [49]. For this thesis, an enhanced procedure
was designed and implemented, in collaboration with Antonis Kakas, that modiﬁes
the KM procedure by supporting built-in Prolog predicates, by using more dynamic
integrity constraints to avoid ﬂoundering in consistency derivations, by imposing a
depth bound on abductive and consistency derivations to ensure termination, and by
pruning redundant branches of the search space to improve eﬃciency. In addition
to the application described in this thesis, the enhanced ALP procedure has also
been applied (by other groups) to temporal reasoning in the event calculus [6], for
modelling the inhibitory eﬀects of toxins on mammalian metabolic networks [92], and
for the modelling and inference of genetic regulatory networks [68]. Some of these
applications build on earlier work applying ALP to the event calculus such as [85] and
[86]. But, even though these applications and the extended ALP procedure would
make for interesting discussions in their own right, the focus of this thesis is on how
such procedures can be used in the context of ILP — which is discussed in the next
chapter.

Chapter 4
Inductive Logic Programming
This chapter introduces the task of Inductive Logic Programming (ILP) [63], recalls
the ILP semantics of Bottom Generalisation (BG) [99], and reviews the (predictive)
ILP proof procedure Progol5 [61].
Section 4.1 begins by formalising the notions
of inductive context, inductive explanation, mode declarations and compression [58].
Sections 4.2 and 4.3 review the BG semantics and the Progol5 procedure. Section 4.4
concludes with some bibliographic remarks.
4.1
Inductive Logic Programming (ILP) Task
ILP is the branch of Machine Learning concerned with ﬁnding Horn clause hypotheses
H to generalise positive and negative examples E+ and E−with respect to background
knowledge B. In fact, two diﬀerent learning tasks are studied in ILP that reﬂect two
distinct notions of generality. The predictive setting aims to ﬁnd a hypothesis H that
together with B logically entails E+ and is consistent with E−; while the descriptive
setting aims to ﬁnd a hypothesis H that is true (resp. false) in the LHM of B and each
positive (resp. negative) example. This thesis is concerned only with the predictive
setting, as it is better suited to learning the principles that underlie the positive and
negative examples — as opposed to simply describing the distinctive features of those
examples. For simplicity, this chapter does not consider well-known variations of the
ILP task that allow the possibility of mis-classiﬁed or noisy examples.
44

4.1. INDUCTIVE LOGIC PROGRAMMING (ILP) TASK
45
By analogy with the previous chapter, the inputs and output of the ILP task are
called an inductive context and an inductive generalisation, respectively. As formalised
in Deﬁnitions 4.1.1 and 4.1.2 below, the input comprises four Horn theories B, E+,
E−and M, while the output is a Horn theory H. The idea is that B represents a
body of knowledge that must be extended with some hypothesis H so as to cover the
positive examples E+ without contradicting the negative examples E−. The theory
M, called the language bias, contains the clauses that may appear in H.
Deﬁnition 4.1.1 (Inductive context). An inductive context is a tuple ⟨B, E+, E−, M⟩
where B, E+, E−and M are Horn theories such that B ̸|= E+ and B∪E+∪E−̸|= □.
Deﬁnition 4.1.2 (Inductive generalisation). Let X = ⟨B, E+, E−, M⟩is an inductive
context. Then an inductive generalisation of X is a Horn theory H ⊆M such that
B ∪H |= E+ and B ∪H ∪E−̸|= □.
As formalised in Deﬁnition 4.1.2, the ILP notions of coverage and consistency
correspond to classical entailment and consistency.
As stated in Deﬁnition 4.1.1,
inductive contexts must satisfy two non-triviality conditions. Speciﬁcally, B should
not entail E+ and it should be mutually consistent with both E+ and E−. Clearly,
if these requirements are not satisﬁed, then it would be either unnecessary or else
impossible to ﬁnd an inductive generalisation. It should also be noted that the two
conditions in Deﬁnition 4.1.1 are often called prior necessity and satisﬁability, while
those in Deﬁnition 4.1.2 are often called posterior suﬃciency and satisﬁability, as
evidenced, for example, in [63].
In general, it is not practical to explicitly list all of the clauses in the language
bias M, and so more compact representations of the hypothesis space are commonly
used. Without danger of ambiguity, the language bias will hereafter be represented
by a set M of mode declarations that deﬁne a hypothesis space called the language
of M and denoted LM. The syntax and semantics of mode declarations is formalised
in Deﬁnitions 4.1.3 and 4.1.4 below, which extends the standard formalisation in [58]
from deﬁnite clauses to Horn clauses.

4.1. INDUCTIVE LOGIC PROGRAMMING (ILP) TASK
46
In brief, mode declarations are of two types, called head declarations and body
declarations, that determine which predicates may appear in the heads and bodies of
hypothesised clauses, respectively, and impose certain additional constraints on the
terms appearing as arguments of those predicates. Mode declarations consist of an
integer called the recall, and a ground atom called a scheme. Unlike normal atoms,
schemes are allowed to contain special terms, called placemarkers, that take the form
+p or −p or #p for some unary predicate p.
Intuitively, a scheme can be thought of as a ‘template’ with placemarkers as its
‘slots’. The idea is that # placemarkers stand for ground terms (of some appropriate
type p), whereas + and −placemarkers stand for variables, called input and output
variables. The distinction between these last two, is that when using a set of mode
declarations to construct a hypothesis clause, it is necessary to ensure that all input
variables in the body of the clause are ‘linked’ to an input variable in the head through
some intervening ‘chain’ of output variables.
Deﬁnition 4.1.3 (Mode declaration).
A mode declaration m is either a head dec-
laration, m = modeh(r, s), or a body declaration, m = modeb(r, s), where r is a
positive integer called the recall, and s is a scheme. A scheme is a ground atom,
possibly containing placemarkers. A placemarker is one of the three symbols ‘+’, ‘−’,
or ‘#’, followed by a unary predicate called a type. For convenience, the recall of a
mode declaration can be replaced by the symbol ‘∗’, which is understood as denoting
an arbitrarily large integer; and the type of a placemarker can be omitted, in which
case the everywhere true predicate any/1 is assumed.
As formalised in Deﬁnition 4.1.4 below, the language LM of M is deﬁned in steps.
First, the atomic instances of a single mode declaration m ∈M are deﬁned as the
atoms obtained by replacing the placemarkers in the schema of m by appropriate
terms.
Then, the deﬁnite instances of M are deﬁned as the clauses obtained by
suitably composing the instances of one head declaration and zero or more body
declarations. Next, a negative instance of M is deﬁned as a clause that would be in
the language of M if its ﬁrst body atom were treated as a head atom.

4.1. INDUCTIVE LOGIC PROGRAMMING (ILP) TASK
47
Deﬁnition 4.1.4 (Mode language). Let M be a set of mode declarations, and let
M+ and M−denote, respectively, the sets of head and body declarations in M.
• An atomic instance of some m ∈M is any atom obtained from the schema s
of m by replacing all # placemarkers by ground terms, and all + and −place-
markers by variables. Formally, each occurrence of a variable v used to replace
a + (resp. −) placemarker is called an input (resp. output) occurrence of v.
• A deﬁnite instance of M is any deﬁnite clause a0 ←a1, . . . , an for which there
exists a head declaration m0 ∈M+ and body declarations m1, . . . , mn ∈M−
such that, for all 0 ≤i ≤n, ai is an atomic instance of mi and each variable
v with an input occurrence in ai has an input occurrence in a0 or an output
occurrence in aj for some 0 < j < i.
• A negative instance of M is any negative clause ←a1, a2, . . . , an for which
there exists a body declaration modeb(r, s) ∈M −such that a1 ←a2, . . . , an is
a deﬁnite instance of {modeh(r, s)} ∪M −.
• A (Horn) instance of M is any deﬁnite or negative instance of M. The set of
all such instances is called the language of M and denoted LM.
Note that the ordering of literals within a clause plays an important role all of the
deﬁnitions above. Note also how, in the standard formulation of mode-declarations
for ILP [58], the recall and type information do not formally aﬀect on the hypothesis
space in any way! In eﬀect, they are treated as a form of search bias — with recall
limiting the number of times a particular mode declaration may be used and type
predicates restricting the ground terms that may replace a given placemarker —
rather than language bias. If the reader considers this position unsatisfactory, then
he is referred to [75] for an extended formulation of the mode language in which recall
and types are also included.
For convenience, if M is a set of mode declarations, then the notations M+ and
M−will denote the head and body declarations of M, respectively. By convention,
the symbol ∗will be used to denote an arbitrary recall, and type predicates will often

4.1. INDUCTIVE LOGIC PROGRAMMING (ILP) TASK
48
be omitted — in which case they are assumed to default to the predicate any/1,
which holds of all possible arguments. Finally, it is convenient to introduce the three
functions formalised in Deﬁnition 4.1.5 below. In brief, the predicate of m is simply
the predicate in the scheme of m. The schema of m is just the scheme, but with
all placemarkers replaced by fresh variables. The type of m is a set of atoms pi(xi),
indicating the type pi of the placemarker each schema variable xi replaced.
Deﬁnition 4.1.5 (Pred, Schema, Type). Let m be a mode declaration.
• pred(m) denotes the predicate p in the schema s = p(t1, . . . , tn) of m
• schema(m) denotes the atom obtained from s by replacing each placemarker
(as they appear from left to right) with a distinct variable x1, x2, . . . , xk
• type(m) denotes the set of atoms {p1(x1), p2(x2), . . . , pk(xk)} such that pi is the
type of the placemarker that was replaced by xi, for all 1 ≤i ≤k
Example 4.1.6. If m = modeh(∗, uncle(+male, +person)), then
• pred(m) = uncle,
• schema(m) = uncle(x1, x2), and
• type(m) = {male(x1), person(x2)}.
Example 4.1.7. Let X = ⟨B, E+, E−, M⟩be the inductive context deﬁned below,
where the background knowledge B is an extension of the theory previously used
in Example 3.1.4 above. In addition to the ﬁrst three clauses, described earlier, B
contains three new facts which state that burgerKing is participating in the special
offer, and that burgers have been eaten at both burgerKing and theRitz.
The positive examples state that meals have been eaten at both mcDonalds and
burgerKing. The negative examples state, ﬁrstly, that no meal has been eaten at
theRitz, and, secondly, that no burger may be eaten at any outlet classiﬁed as vegan.
(Literally: for any x, one cannot have burger(x) and also have vegan(x).) The two
non-triviality conditions of Deﬁnition 4.1.1 are clearly satisﬁed as B does not entail
either positive example and it is consistent with both negative examples.

4.1. INDUCTIVE LOGIC PROGRAMMING (ILP) TASK
49
B
=































meal(x) ←fries(x), burger(x)
burger(x) ←fries(x), offer(x)
offer(mcDonalds)
offer(burgerKing)
burger(mcDonalds)
burger(theRitz)































E+
=



meal(mcDonalds)
meal(burgerKing)



E−
=



←meal(theRitz)
←burger(x), vegan(x)



M
=



modeh(∗, fries(+))
modeb(∗, oﬀer(+))



The mode declarations specify a language bias in which hypothesis clauses are
allowed to contain atoms of the form fries(x) in their heads and/or atoms of the
form offer(x) in their bodies. With reference to Deﬁnition 4.1.2 above, it can be
shown that the hypothesis H, below, is an inductive generalisation of X. (Note that
H′ = {fries(x)} violates the negative examples, and H′′ = {fries(mcDonalds),
fries(burgerKing)} falls outside the hypothesis space LM.)
H
=
n
fries(x) ←offer(x)
o
In order to select between competing hypotheses it is necessary, in practice, to
introduce additional preference criteria called search bias. This thesis adopts a widely
used form of search bias, called compression [58], that attempts to minimise the num-
ber of literals in the hypothesised clauses. Deﬁnition 4.1.8 gives a simple formulation
of compression for the noise-free case — where, by deﬁnition, hypotheses are consis-
tent with all of the negative examples.

4.2. BOTTOM GENERALISATION (BG) SEMANTICS
50
Brieﬂy, the complexity of a hypothesis is the number of literals it contains, the
coverage is the number of positive examples it entails, and its compression is just the
diﬀerence between the two. Thus, the compression of H in the previous example is
2-2=0. Informally, the compression metric embodies the principle of Occam’s Razor,
which prefers the ‘simplest’ hypothesis that ﬁts the data (see [53]). If required, this
simple deﬁnition of compression can be extended to take into account the removal of
any clauses in the theory that may be subsumed or entailed by the hypothesis.
Deﬁnition 4.1.8 (Complexity, Coverage, Compression). Let B be a Horn theory,
E+ a set of ground atoms, and H = {h1, . . . , hn} a Horn theory. Then the complexity
of H is the integer x = Σn
i=1|hi|, the coverage of H (with respect to B and E+) is the
integer y = |{e ∈E+ | B ∪H |= e}|, and the compression of H (with respect to B
and E+) is the integer z = y −x.
4.2
Bottom Generalisation (BG) Semantics
Many ILP techniques exploit the fact that it is usually easier to construct hypotheses
incrementally as a succession of small theories each covering a few examples at a
time, than it is to construct one large theory covering all of the examples in one go.
For this reason, several systems employ a so-called covering loop [50] that uses one
seed example at a time to focus the generalisation process. Among these, some of the
most successful systems are based on the inductive inference method of BG.
Although most of these systems are restricted to Horn clause logic, the semantics
of BG is deﬁned for full clausal logic. Given a theory B (background knowledge)
and a clause e (seed example), BG constructs and generalises a special clause1, called
the Bottom Set [61] of B and e, to return a clause h such that B ∪{h} |= e. The
Bottom Set plays a crucial role in this process by restricting the search to part of the
hypothesis space that is highly structured and rich in potential solutions.
1Strictly, it is incorrect to call the Bottom Set a clause — even one that is unordered — since it
may contain an inﬁnite number of literals. However, since only a ﬁnite subset of these literals will
actually be computed, this distinction is unimportant in practice.

4.2. BOTTOM GENERALISATION (BG) SEMANTICS
51
As formalised in Deﬁnition 4.2.1 below, Bot(B, e) is the set of ground literals
whose negation is entailed by B and the complement e of e. (i.e. the unit theory
containing the Skolemised negations of the literals in e.) Moreover, as formalised in
Deﬁnition 4.2.1, a clause h is derivable by BG from B and e iﬀh subsumes Bot(B, e)
(i.e. for some substitution θ, each literal in hθ is contained in Bot(B, e)).
Deﬁnition 4.2.1 (Bottom Set). Let B be a theory and let e be a clause. Then the
Bottom Set of B and e, denoted Bot(B, e), is deﬁned as the set of ground literals L
such that B ∪e |= ¬L.
Deﬁnition 4.2.2 (Bottom Generalisation - BG). Let B be a theory and let e and h
be clauses. Then h is derivable by BG from B and e iﬀh ⪯Bot(B, e) and h contains
no Skolem constants from Bot(B, e).
The key point here is that instead of considering all of the clauses that logically
entail e wrt. B, BG only considers the θ-subsumption lattice bounded by the Bottom
Set and the empty set. This lattice can be searched much more eﬃciently than the
full hypothesis space. Moreover, even though any gain in tractability is ultimately
paid for by a loss of completeness, BG achieves a balance between eﬃciency and
generality that has consistently proved very successful in practice.
In addition to overcoming some of the practical limitations of earlier ILP systems
based on the concepts of rlgg’s [64] and inverse resolution [62] (particularly regarding
the syntactic restrictions on background knowledge and hypotheses), BG also has the
advantage of being far easier to analyse from a semantic point of view. In particular,
it has been shown [99] that a clause h is derivable by BG from B and e iﬀthere exists
a C-refutation of B ∪e wrt. h.
As shown in [99], it follows BG is a sound and complete method for inverting
relative subsumption.
Consequently, since relative subsumption is more tractable
than full relative entailment [67], this suggests that BG can be used as the basis of
practical ILP systems — providing that language and search bias can be eﬃciently
utilised. A prominent example of this approach is the prominent ILP system Progol5,
which is described in the next section.

4.3. PROGOL5 PROOF PROCEDURE
52
4.3
Progol5 Proof Procedure
The success of any ILP system based on BG will depend upon its ability to make
eﬃcient use of language and search bias in the construction and generalisation of the
Bottom Set. In order to address this issue, Progol5 uses a reﬁnement of BG called
Theory Completion by Inverse Entailment (TCIE) [61]. Given a background theory
B, a seed example e, and a set M of mode declarations, TCIE will return a maximally
compressive hypotheses h that subsumes the Bottom Set of B and e, falls within the
language of M, and is computable within some pre-speciﬁed resource bounds.
Progol5 takes an inductive context ⟨B, E+, E−, M⟩and returns a generalisation H,
that is constructed one clause at a time, using a covering loop. On each cycle, a seed
example e is selected from E+ and, if it is not already a ground atom, then it is turned
into one by applying a Skolemising substitution σ and temporarily transferring any
body atoms as facts to B. At the same time, the atom false is temporarily inserted
into the head of every negative clause in B and e. TCIE then ﬁnds a compressive
clause h, which is added to H after removing any covered examples from E+.
Each clause h returned by TCIE is obtained in three stages. First, a contrapositive
reasoning method, called StartSet, computes a ground head atom α in Bot(B, e)
that is subsumed by some atom in LM. Then, a mode directed procedure, called
BottomSet, computes a set of ground body atoms δ1, . . . , δn from Bot(B, e) such
that α ←δ1, . . . , δn is subsumed by a clause in LM.
Finally, a search routine,
called LatticeSearch computes a highly compressive clause h in LM that subsumes
α ←δ1, . . . , δn and is consistent with the theory B and the examples E+ and E−.
Since the optimal atom α is not known in advance, all solutions are computed
and a maximally compressive hypothesis is constructed for each one to determine the
most compressive overall hypothesis. The BottomSet and LatticeSearch procedures
are detailed in [58] and StartSet is analysed in Chapter 5 of this thesis. For now,
these routines are brieﬂy described one by one. In these descriptions, P refers to the
program B ∪{e1σ, . . . , enσ} and g refers to atom e0σ, where e0 and e1, . . . , en are the
head and body atoms of the seed example e, and σ is a Skolemising substitution.

4.3. PROGOL5 PROOF PROCEDURE
53
The Progol5 StartSet procedure
takes as input a program P, a ground atom g,
and set M of mode declarations; and it returns as output a set of ground atoms α
each of which is θ-subsumed by some atom in LM+ and satisﬁes the condition that
P ∪{α} |= g. Each atom α is computed by a Prolog engine extended with the use of
contrapositives [90] — which allow negative information to be propagated backwards
through the clauses in P. As explained in Chapter 5, each clause A0 ←A1, . . . , An
contributes n contrapositives A∗
i ←A∗
0, A1, . . . , Ai−1, Ai+1, . . . , An, where A∗
i denotes
the positive form of the negative literal ¬Ai (in the sense of Deﬁnition 3.2.3). For
each head declaration m in M+ with schema s, the starred atom s∗is run as a depth-
bounded SLD query over the program P ∗∪{g∗}, where P ∗is obtained by adding
to P all of its contrapositives.
(In fact, Progol5 avoids an excessive proliferation
of contrapositives by suppressing those that are redundant in a sense detailed in
Chapter 5.) For each successful ground substitution θ, the corresponding atom α = sθ
is returned by the Progol5 StartSet.
The Progol5 BottomSet procedure
takes as input a program P, a ground atom
α, and set M of mode declarations; and it returns as output a ground clause C = α ←
δ1, . . . , δn that is subsumed by some clause in LM and, for all 1 ≤i ≤n, satisﬁes
the condition that P |= δi.
As described in [58], the computation of C proceeds
from left to right starting with the given head atom α. The BottomSet procedure
begins by selecting a head declaration m ∈M+ of whose schema the atom α is a
well-typed ground instance. It then identiﬁes the terms in α corresponding to input
placemarkers in the scheme of m, and adds these terms to an initially empty set of
so-called InTerms. The body atoms are then computed in successive strata starting
at depth one and increasing up to some predeﬁned maximum. At any given depth
the InTerms are extended with the terms in any body atoms of the previous stratum
that correspond to output placemarkers. The computed body atoms are the successful
well-typed instances of SLD queries over P obtained by substituting InTerms into
the input variables of the schemas of all body declarations m′ ∈M−.

4.3. PROGOL5 PROOF PROCEDURE
54
The Progol5 LatticeSearch procedure
takes as input three programs B, E+
and E−, a ground deﬁnite clause C, and a set M of mode declarations; and it returns
as output a maximally compressive Horn clause h in LM such that h ⪯C and
B ∪{h}∪E+ ∪E−̸|= □. As formalised in [58], the LatticeSearch procedure performs
a general-to-speciﬁc A*-like search through the θ-subsumption sub-lattice bounded
from above and below by □and C, respectively. At each stage in the search the
current clause is reﬁned by adding body atoms and binding variables to terms in
accordance with the mode declarations M. The search metric is based on the current
compression of the clause and an estimate of the number of body atoms that still need
to be added. The consistency of each candidate hypothesis is established by the ﬁnite
failure of the goal ?false from the program B ∪{h}∪E+ ∪E−(where the atom false
is regarded as the head of every nominally negative clause). In addition, pruning
techniques are used to avoid processing dead-end branches of the search space.
Example 4.3.1. Let X = ⟨B, E+, E−, M⟩be the inductive context speciﬁed in
Example 4.1.7 above; and let mcDonalds, burgerKing and theRitz be abbreviated
to md, bk and rz.
Then, using the seed example e = meal(md), the hypothesis
H = {fries(x) ←offer(x)} is computed by Progol5, as explained next.
Since e is already a ground atom, the only normalisation performed by Progol5
is to replace the two negative clauses in E−by the corresponding deﬁnite clauses
false ←meal(rz) and false ←burger(x), vegan(x).
Next, StartSet forms the
theory B∗∪{e∗} by adding to B the four (non-redundant) contrapositives B′ below.
B′ =











fries∗(x) ←meal∗(x), burger(x)
burger∗(x) ←meal∗(x), fries(x)
fries∗(x) ←burger∗(x), offer(x)











∪
n
meal∗(md)
o
After obtaining the schema fries(x) of the only available head declaration, Start-
Set runs the query ?fries∗(x) over the program B∗∪{e∗} or, equivalently, over B∪B′.
As shown by the SLD tree below, this query succeeds with exactly one answer x/md.
Consequently, StartSet returns exactly one atom: fries(md).

4.3. PROGOL5 PROOF PROCEDURE
55
fries∗(x)
meal∗(x), burger(x)
burger(md)
□
{x/md}
fries(md), offer(md)
■
burger∗(x), offer(x)
meal∗(x), fries(x), offer(x)
fries(md), offer(md)
■
Given the head atom fries(md), BottomSet identiﬁes md as an InTerm. After
obtaining the schema offer(x) of the only available body declaration, it binds the
input variable x to md and runs the query ?offer(x) over the program B.
This
trivially succeeds and BottomSet returns the clause C = fries(md) ←offer(md).
LatticeSearch must now ﬁnd a maximally compressive consistent hypothesis that
θ-subsumes C. For this, it searches the (positive part) of the subsumption lattice
below, and ﬁnds that h = fries(x) ←offer(x) is the only clause in LM consistent
with B, E+ and E−. As it covers both positive examples, h is computed by Progol5.
□
fries(x)
←offer(y)
fries(md)
fries(x) ←offer(y)
←offer(md)
fries(md) ←offer(y)
fries(x) ←offer(x)
fries(x) ←offer(md)
fries(md) ←offer(md)

4.4. BIBLIOGRAPHIC REMARKS
56
4.4
Bibliographic Remarks
While the notation and terminology of this section are standard, many variations have
previously appeared in the literature. First, the Bottom Set has been alternatively
called a Most Speciﬁc Clause [58, 61], a Bottom Clause [96], and has been variously
represented with the notation ⊥[58], ⊥(B, E) [61], bot(B, E) [96], Bot(E, B) [99].
Second, the terminology Bottom Generalisation (BG) was introduced in [99] to denote
a simple reﬁnement of the semantics of Inverse Entailment (IE) [58]. Speciﬁcally, BG
is the special case of IE where subsumption is used instead of logical entailment as
the generalisation relation.
It was initially suggested in [58] that IE comprised a
sound and complete inference method for inverting logical entailment relative to a
background theory, but its supposed completeness was later refuted by a counter-
example in [96]. It was subsequently claimed in [97] that the hypotheses derivable by
IE can be semantically characterised in terms of Plotkin’s relative subsumption, but
it was later realised in [98] and [99] that this result only applied to the special case
of IE now called BG.
After the original formulation of IE in [58] was shown to be incomplete in [96],
two separate extensions of the Bottom Set were proposed in [22] and [59]. But it was
subsequently shown in [23] that the former extension was incomplete while the latter
was unsound. A sound and complete generalisation of BG for observation predicate
learning in deﬁnite clause logic was eventually proposed in [23] based on the notion of
model constraining clauses. Finally, the relative complexity of this generalisation led
to a sound and complete semantics for full clausal logic that was proposed in [28] and
elaborated in [29] called Consequence Finding Induction (CFI). However, it should be
noted that, even though the theoretical limitations of BG are becoming increasingly
apparent, the practical diﬃculties associated with more complete techniques such as
CFI are still far from solved. Consequently, the need for practical techniques that
achieve an eﬀective compromise between tractability and completeness remains an
important open question (and one which is addressed in the remainder of this thesis).
Work on the ﬁrst Progol prototypes started in 1993 and, one year later, three

4.4. BIBLIOGRAPHIC REMARKS
57
systems had been developed: C-Progol4 was Stephen Muggleton’s implementation
that was written in C and included a proprietary Prolog interpreter; P-Progol was
Ashwin Srinivassan’s implementation written in YAP Prolog; and Indlog (Induction
in Logic) was Rui Camacho’s implementation also written in YAP Prolog.
Since
then, P-Progol has also been ported to the Sicstus Prolog and SWI platforms. The
C-Progol and P-Progol families were continuously developed for at least six years
before being superseded by the Progol5 [61] and Aleph [88] systems. In addition to
the core Progol algorithm, the Progol5 and Aleph systems both include additional
features for assessing statistical signiﬁcance, for handling noisy data, and for learning
from positive-only examples.
However, unlike Aleph, Progol5 is able to perform
non-OPL learning (where the hypothesis predicates are distinct from those in the
examples). The contrapositive reasoning mechanism that gives Progol5 this ability
was originally called Logical Back Propagation [56] and only later was referred to as
TCIE [61]. This procedure is the subject of the next chapter.

Chapter 5
Analysis of the Progol5 StartSet
This chapter gives a formal description and logical analysis of the Progol5 StartSet
procedure. After conﬁrming the soundness of StartSet with respect to BG semantics,
the analysis exposes an unexpected incompleteness that is shown to undermine the
performance of Progol5 in real applications.
The (procedural) incompleteness of
StartSet is characterised and distinguished from the (semantic) incompleteness of
BG. The cause of the incompleteness is revealed and two solutions are compared.
Section 5.1 explains the notion of contrapositives and shows how they are used by
StartSet to compute positive Bottom Set literals. The soundness and incompleteness
of StartSet are proved in Sections 5.2 and 5.3, and the extent of this incompleteness
is characterised in Section 5.4. Two alternative solutions are compared in Section 5.5
and the beneﬁts to be gained from replacing the contrapositive reasoning mechanism
of StartSet with an abductive proof procedure are discussed.
5.1
Formalisation of the StartSet Procedure
The Progol5 StartSet routine is responsible for computing the positive Bottom Set
literals of a program B and ground fact e. As explained in the previous chapter,
these literals are the ‘negations of the negative ground literals entailed by B and the
complement of e’; and StartSet computes them using simple form of contrapositive
reasoning. Before giving a logical speciﬁcation of the StartSet procedure, this section
58

5.1. FORMALISATION OF THE STARTSET PROCEDURE
59
introduces the notion of contrapositives and explains how they are used by StartSet
to compute non-trivial positive Bottom Set literals. It also introduces an optimisation
used by StartSet to improve the eﬃciency of this computation.
5.1.1
Contrapositive Reasoning of StartSet
In classical logic, the contrapositive of a conditional A ←B refers to the formula
¬B ←¬A obtained by negating and interchanging the consequent and antecedent.
While they are logically equivalent, these formulae are complementary in the sense
that, intuitively, the conditional states that the truth of A is implied by the truth of B,
while its contrapositive states that the falsity of A implies the falsity of B. In a logic
programming context, assuming A = p(t1, . . . , tk) and B = q(s1, . . . , sm) are atoms,
these inferences can be simulated with the two rules p(t1, . . . , tk) ←q(s1, . . . , sm)
and q∗(s1, . . . , sm) ←p∗(t1, . . . , tk) — where p∗and q∗are predicates, called starred
predicates1, that represent the negations of p and q. By analogy with their classical
counterparts, these rules will be called contrapositives.
More generally, the contrapositives of a rule C = A0 ←A1, . . . , An are deﬁned
as the n rules of the form C∗(i) = A∗
i ←A∗
0, A1, . . . , Ai−1, Ai+1, . . . , An for some
1 ≤i ≤n — where, as formalised in Deﬁnition 5.1.1 below, A∗
i and A∗
0 are the
starred atoms, called the contrapositive complements of Ai and A0, that represent the
negative literals ¬Ai and ¬A0, respectively. For convenience, each such rule is said to
be formed by contraposing the (body) atom Ai with the (head) atom A0. Similarly,
the contrapositives of a goal C = ←A1, . . . , An are deﬁned as the n rules of the
form C∗(i) = A∗
i ←A1, . . . , Ai−1, Ai+1, . . . , An, each of which is said to be formed
by transposing Ai. (Note that a single atom is said to be transposed, while a pair of
atoms — one positive, one negative — are said to be contraposed.)
1Although syntactic conventions vary, this thesis follows the notation of [34] in its use of starred
predicates to represent the negations of unstarred predicates. It is worth emphasising, however, that
the asterisk symbol is merely syntactic sugar. In the literature, the positive form of an negative
literal ¬p(t1, . . . , tn) is variously denoted ‘non p(t1, . . . , tn)’ or ‘˜p(t1, . . . , tn)’, The only requirement
is that the chosen symbol be speciﬁcally introduced in order to denote the negation of p.

5.1. FORMALISATION OF THE STARTSET PROCEDURE
60
As formalised in Deﬁnition 5.1.1 below, the contrapositives of a Horn clause C are
collectively denoted C∗and consist of all the rules that can be obtained by transposing
or contraposing (zero or more) atoms in C. (Note that, strictly speaking, a rule C is
included also among its own contrapositives C∗.) This is illustrated in Example 5.1.2
below, which shows the contrapositives of six diﬀerent Horn clauses. Having now
formalised the contrapositives of a single Horn clause C, the contrapositives of a
Horn theory T = {C1, . . . , Cm} can then be deﬁned as the program T ∗obtained from
T by composing the contrapositives C∗
i of each of the individual clauses Ci in T. As
formalised in Deﬁnition 5.1.1 and illustrated in Example 5.1.3 below, the program T ∗
obtained in this way is called the contrapositive expansion of T.
Deﬁnition 5.1.1 (Contrapositives). If A = p(t1, . . . , tk) is an atom, then A∗denotes
the atom p∗(t1, . . . , tk). If C is a rule A0 ←A1, . . . , An (resp. goal ←A1, . . . , An)
with n ≥0 body atoms and i is an integer 1 ≤i ≤n, then C∗(i) denotes the
rule A∗
i ←A∗
0, A1, . . . , Ai−1, Ai+1, . . . , An (resp. A∗
i ←A1, . . . , Ai−1, Ai+1, . . . , An)
and C∗denotes the set of rules {C, C∗(1), . . . , C∗(n)} (resp. {C∗(1), . . . , C∗(n)}). If
T = {C1, . . . , Cm} is a Horn theory, then T ∗denotes the program C∗
1 ∪· · · ∪C∗
m.
Atom A∗is called the contrapositive complement of A, rule C∗(i) is called the (i-th)
contrapositive of C, and theory T ∗is called the contrapositive expansion of T.
Example 5.1.2. Let C1 −C6 denote the following six clauses: C1 = □, C2 = a,
C3 = ←a, C4 = b ←c, C5 = ←b, c, and C6 = a ←b, c. Then C∗
1 = ■, C∗
2 = {a},
C∗
3 = {a∗}, C∗
4 = {b ←c ;
c∗←b∗}, C∗
5 = {b∗←c ;
c∗←b}, and ﬁnally
C∗
6 = {a ←b, c ; b∗←a∗, c ; c∗←a∗, b},
Example 5.1.3. Let T1 = {a(x) ←b(x), c(x) ;
b(x) ←c(x) ;
←a(0)} and
T2 = {a(x) ←c(x) ;
c(0) ←a(1) ;
b(x) ;
←a(0)}.
Then T ∗
1 = {a(x) ←
b(x), c(x) ;
b∗(x) ←a∗(x), c(x) ;
c∗(x) ←a∗(x), b(x) ;
b(x) ←c(x) ;
c∗(x) ←
b∗(x) ;
a∗(0)} and T ∗
2 = {a(x) ←c(x) ;
c∗(x) ←a∗(x) ;
c(0) ←a(1) ;
a∗(1) ←
c∗(0) ; b(x) ; a∗(0)}.

5.1. FORMALISATION OF THE STARTSET PROCEDURE
61
In the Horn clause case, contrapositives provide a simple way of reasoning with
negative information using conventional logic programming techniques. In the general
case, contrapositives can be deﬁned for arbitrary clausal theories, thereby allowing
full clausal inference to be achieved using eﬃcient Prolog engines [90].
However,
the computational machinery is far more complex in the non-Horn case, where, in
order to guarantee completeness, it is necessary [90] to augment SLD-resolution with
some form of ancestor resolution and to provide a mechanism for extracting indeﬁnite
answers from successful computations. On the other hand, since all of the reasoning
performed by Progol5 is within Horn clause logic, StartSet just uses standard SLD-
resolution combined with the introduction of contrapositives formalised above.
The ability of contrapositives to compute the negative consequences of a given
Horn theory is demonstrated in Lemma 5.1.4 below, which provides an algorithm for
transforming any derivation from a theory T into a corresponding derivation from
the contrapositive expansion T ∗and vice versa. The ‘if’ direction is trivial because
it is suﬃcient to replace every contrapositive in the given derivation by the clause
that produced it. The ‘only if’ direction requires a recursive algorithm that works
up from the root to the leafs. The four non-trivial cases are illustrated by the left
to right transformations in Example 5.1.5 below. Strictly, the transformation is only
guaranteed for factor-free derivations and may involve reordering the atoms within
derived clauses, as illustrated in Examples 5.1.6 and 5.1.7. Nevertheless, as explained
below, this lemma provides suﬃcient justiﬁcation for the methodology that underlies
the StartSet procedure.
Lemma 5.1.4. Let T ∗be the contrapositive expansion of an (unstarred) Horn theory
T, and let C′ be a contrapositive of some (unstarred) Horn clause C. Then there exists
a factor-free derivation R = ⟨R1, . . . , Rn = C⟩from T iﬀthere exists a factor-free
derivation R′ = ⟨R′
1, . . . , R′
n = C′⟩from T ∗(up to the reordering of unstarred body
atoms in resolvent clauses) such that R′
i is a contrapositive of Ri for all 1 ≤i ≤n.

5.1. FORMALISATION OF THE STARTSET PROCEDURE
62
Proof. To obtain R from R′ it is suﬃcient to simply un-transpose every starred atom
in R′. To obtain R′ from R it is suﬃcient to work up recursively from the root with
the following algorithm. If the root C is a deﬁnite clause, then either C′ = C, in
which case the lemma trivially holds. or else R′
n is formed by contraposing the head
atom with of Rn with one of its body atoms. If both these atoms are contributed
by the same parent, then it is suﬃcient to contrapose the two contributing atoms
in that parent clause and recursively apply the algorithm (case A). If the atoms are
contributed by diﬀerent parents, then it is suﬃcient to contrapose the contributing
atoms with the resolved atom in their respective parents and recurse (case B). If
the root C is a negative clause, then C′ is formed by transposing one body atom in
the original clause and there are exactly two cases. If this atom is contributed by
the negative parent, then it is suﬃcient to transpose the contributing atom in the
negative parent and recursively apply the algorithm (case C). If the transposed atom is
contributed by the positive parent, then it is suﬃcient to contrapose the contributing
atom with the head atom in the positive parent and transpose the resolved literal in
the negative parent and then recurse (case D). Note that the mgu’s remain unchanged
in every resolution step.
Example 5.1.5. This example illustrates the four non-trivial cases of Lemma 5.1.4.
From the tree on the left, which is a derivation R of the clause C = ←c from some
theory T the aim is to construct on the right a derivation R′ of the contrapositive
C′ = c∗from T ∗. As described in the lemma, R′ is constructed incrementally, working
up from the root using a case analysis to determine which atoms, if any, must be
transposed in the parents of the current clause. In the example below, each resolution
step corresponds to one of the four cases. The ﬁrst case, indicated by the dotted line
marked ‘case C’, shows how the bottom resolution step on the left (where ←c is
derived from ←c, d and d) is transformed to the corresponding step on the right
(where c∗is derived from c∗←d and d).

5.1. FORMALISATION OF THE STARTSET PROCEDURE
63
b ←a, e
e
b ←a
a ←c
←d, b
b ←c
←c, d
d
←c
case A
case B
case D
case C
a∗←b∗, e
e
a∗←b∗
c∗←a∗
b∗←d
c∗←b∗
c∗←d
d
c∗
Example 5.1.6. This example shows why it is sometimes necessary to reorder the
body atoms of derived clauses.
The tree on the left is a derivation of the clause
a ←e, f, b, d, of which the clause e∗←a∗, b, f, d in the centre is a contrapositive.
But, strictly, the transformation of Lemma 5.1.4 can only be used to obtain the
derivation, shown on the right, of the permutation e∗←a∗, b, d, f.
a ←b, c, d
c ←e, f
a ←e, f, b, d
e∗←a∗, f, b, d
c∗←a∗, b, d
e∗←c∗, f
e∗←a∗, b, d, f
Example 5.1.7. This example illustrates why the transformation in Lemma 5.1.4
only applies to factor-free derivations. The problem is simply that only one of the
factored literals in a non-binary resolution, can be transposed into the head of the
contrapositive. As shown below, any other(s) remain in the body of the contraposi-
tive, where they contribute additional atoms to the resolvent.
a ←b, c, c
c ←e, f
a ←b, e, f
e∗←a∗, b, f
c∗←a∗, b, c
e∗←c∗, f
e∗←a∗, b, c, f

5.1. FORMALISATION OF THE STARTSET PROCEDURE
64
Rationale for the StartSet procedure:
Because SLD is a complete resolution procedure for Horn clause logic, Lemma 5.1.4
suggests a methodology for using contrapositives to compute the ground atoms α in
the Bottom Set of a program B and ground atom e.2
The rationale is motivated
by the following four observations: (i) by Deﬁnition 4.2.1, an atom α ∈Bot(B, e)
iﬀ¬α is entailed by the Horn theory B ∪{¬e}; (ii) by the subsumption theorem,
this is true iﬀthere is an SLD-deduction of ¬α from B ∪{¬e}; (iii) by Lemma 5.1.4,
there is an SLD (and therefore factor-free) derivation of ¬α from B ∪{¬e} iﬀthere
is a corresponding derivation of the fact α∗from the program B∗∪{e∗}; and ﬁnally
(iv) by the soundness and completeness of SLD, this holds iﬀthe goal ←α∗succeeds
from the program B∗∪{e∗}. Since each step of this argument is reversible, it follows
that a ground atom α is contained in Bot(B, e) if the corresponding starred atom α∗
succeeds as an SLD query from B∗∪{e∗}.
One of the contributions of this thesis is to explain how this reasoning is used
by the Progol5 StartSet and to reveal why the resulting approach is subtly ﬂawed
in the sense that not all Bottom Set atoms may actually be computed in this way.
(The reader is encouraged to look for such counter-examples.) But, before that, it is
convenient to introduce a key optimisation used by the Progol5 StartSet to constrain
the large search space [48] associated with the introduction of contrapositives. The
idea is to avoid the formation of contrapositives that are provably redundant with
respect to the speciﬁed language bias. As shown below, eliminating these unnecessary
clauses can help improve eﬃciency. To balance the computational cost of determining
which contrapositives should be omitted against the potential speedup in the resulting
computations, the method is based on simple syntactic analysis [61] of the background
theory B, as explained next.
2Without loss of generality, it is assumed throughout this chapter that the seed example e is
a ground atom.
As described in Section 4.3, this can always be ensured by Skolemising e and
transferring any body atoms as facts to B to give a normalised program P and ground atom g. If
desired, B and e can be replaced by P and g throughout the following discussion.

5.1. FORMALISATION OF THE STARTSET PROCEDURE
65
Optimisation of the StartSet procedure:
In order to formalise the eﬃciency optimisation used by the Progol5 StartSet, the
notions of indexed path and contrapositive restriction are introduced in Deﬁnitions
5.1.8 and 5.1.9 and illustrated in Examples 5.1.10 and 5.1.11 below. Intuitively, a
path in a program B is a sequence of rules in which the head of one clause has the
same predicate as a selected body atom in the preceding clause. Moreover, a path
from predicate p to predicate q is a path in which p is the predicate in the head of
the ﬁrst clause and q is the predicate in the selected body atom of the last clause.
Formally, a path is represented as sequence of pairs (Ci, ki) where ki is the index
of the selected atom in clause Ci. Finally, the contrapositive restriction of B from
p to q, denoted B∗
p→q, is deﬁned as the subset of B∗obtained by adding to B the
ki-th contrapositive of each rule Ci on some path in B from p to q. (Note that the
contrapositive restriction is a subset of the contrapositive expansion.)
Deﬁnition 5.1.8 (Indexed path). Let B be a program, and p and q be predicates.
Then, an (indexed) path in B from p to q is a sequence ⟨(C1, k1), . . . , (Cn, kn)⟩of pairs
(Ci, ki), where Ci = Ai
0 ←Ai
1, . . . , Ai
mi is a rule in B and 1 ≤ki ≤mi is the index
of a body atom Aki in Ci, such that (i) pred(A1
0) = p, (ii) pred(An
kn) = q, and (iii)
pred(Ai
ki) = pred(Ai+1
0
) for all 1 ≤i < n.
Deﬁnition 5.1.9 (Contrapositive restriction). Let B be a program, and let p and
q be two predicates. Then, the contrapositive restriction of B from p to q, denoted
B∗
p→q, is deﬁned as the program obtained by adding to B the set of contrapositives
C∗
i (ki) ∈B∗for each (Ci, ki) that appears on some (i.e. at least one) indexed path
in B from p to q.
Example 5.1.10. Let B = {a(x) ←b(x), c(x) ; b(x) ←c(x)}. Then (i) B∗
a→a = B,
(ii) B∗
a→b = B ∪{b∗(x) ←a∗(x), c(x)}, and (iii) B∗
a→c = B ∪{b∗(x) ←a∗(x), c(x) ;
c∗(x) ←b∗(x) ;
c∗(x) ←a∗(x), b(x)}.
The last of these results follows because
⟨a(x) ←b(x), c(x) ;
b(x) ←c(x)⟩and ⟨a(x) ←b(x), c(x)⟩are paths in B from a to
c (where, for convenience, indexed literals have simply been underlined).

5.1. FORMALISATION OF THE STARTSET PROCEDURE
66
Example 5.1.11. Let B = {a(x) ←c(x) ;
c(0) ←a(1) ;
b(x)}.
Then (i)
B∗
a→a = B ∪{c∗(x) ←a∗(x) ;
a∗(1) ←c∗(0)}, (ii) B∗
a→b = B, and (iii) B∗
a→c =
B ∪{c∗(x) ←a∗(x) ;
a∗(1) ←c∗(0)}. The last of these follows as ⟨a(x) ←c(x)⟩
and ⟨(a(x) ←c(x) ; c(0) ←a(1) ; a(x) ←c(x)⟩are paths in B from a to c.
The importance of contrapositive restrictions in the context of StartSet is shown
in Lemma 5.1.12 below. This lemma shows that the restriction B∗
p→q can be used in
place of the expansion B∗without aﬀecting the atoms computed by StartSet. The
‘if’ direction is trivial as every clause in the restriction is also in the expansion. The
‘only-if’ direction proves that no successful refutation can utilise any clause from B∗
that is not also in B∗
p→q. The beneﬁts of leaving out the unnecessary contrapositives
are now illustrated in Example 5.1.13 below.
Lemma 5.1.12. Let B be a program and let e and α be two atoms with predicates
p and q respectively. Then the goal ←α∗succeeds from the program B∗∪{e∗} with
answer θ iﬀthe same goal ←α∗succeeds from the restricted program B∗
p→q ∪{e∗}
with the same answer θ.
Proof. In the ‘if’ direction, it is suﬃcient to observe that B∗
p→q ⊆B∗.
In the
‘only if’ direction, it is suﬃcient to show that every SLD-refutation of ←α∗by
B∗∪{e∗} is also an SLD-refutation of ←α∗by B∗
p→q ∪{e∗}. To show this, sup-
pose that R is an SLD-refutation of ←α∗by B∗∪{e∗}.
By the independence
of the selection rule, it may be freely supposed that the leftmost atom is selected
from each (non-empty) goal in R.
In this case, R can be written R = ⟨(∅, ∅, ←
α∗), (θ1, C1, G1), . . . , (θr, e∗, Gr), . . . , (θn, Cn, □)⟩, where the side clauses C1, . . . , Cr−1
are variants of some contrapositives in B∗/B, and the side clauses Cr+1, . . . , Cn are
variants of some clauses in B. This is because, until the clause e∗is used, the goals
G1, . . . , Gr−1 all have one leftmost starred atom (as every clause in B∗with a starred
atom in the head, has one leftmost starred atom in the body), but, once the clause e∗
has been used, the goals Gr+1, . . . , Gn contain no starred atoms (as every clause in B∗
with an unstarred atom in the head, has no starred atoms in the body). Consequently,
for all 1 ≤i ≤r −1 it holds that Ci = (Ai
ki
∗←Ai
0
∗, Ai
1, . . . , Ai
ki−1, Ai
ki+1, . . . , Ai
mi)ρi

5.1. FORMALISATION OF THE STARTSET PROCEDURE
67
is obtained by applying a renaming substitution ρi to the ki-th contrapositive of some
clause C′
i = Ai
0 ←Ai
1, . . . , Ai
mi in B. Furthermore, it follows that (i) pred(A1
ki) =
pred(α) = q, (ii) pred(Ar−1
0
) = pred(e) = p, and (iii) pred(Ai
0) = pred(Ai+1
ki+1) for all
1 ≤i < r−1. Therefore, ⟨(C′
r−1, kr−1), . . . , (C′
1, k1)⟩is a path in B from p to q, which
means that {C1, . . . , Cr−1} ⊆B∗
p→q/B. Hence, R is also an SLD-refutation of ←α∗
by B∗
p→q ∪{e∗}.
Example 5.1.13. This example shows how the eﬃciency of StartSet can be improved
by using B∗
p→q ∪{e∗} in place of B∗∪{e∗}. Let B = {r(x) ←r(y), r(z) ;
r(x) ←
p(x) ;
p(x) ←q(x)}, let e = p(0), and let α = q(0). The SLD-trees on the right
hand side of the ﬁgure below show the search spaces obtained by running the query
?q∗(0) against the programs shown on the left. Clearly, the avoidance of redundant
contrapositives helps to prune away many unsuccessful branches of the search space
(of which there are an inﬁnite number in this example).
B∗∪{e∗} =
8
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
<
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
:
r(x) ←r(y), r(z)
r∗(y) ←r∗(x), r(z)
r∗(z) ←r∗(x), r(y)
r(x) ←p(x)
p∗(x) ←r∗(x)
p(x) ←q(x)
q∗(x) ←p∗(x)
p∗(0)
9
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
=
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
;
q∗(0)
p∗(0)
□
r∗(0)
r∗(x), r(z)
∞
...
∞
...
r∗(x), r(y)
∞
...
∞
...
(i) Contrapositive Expansion
(ii) inﬁnite SLD-tree
B∗
p→q ∪{e∗} =
8
>
>
>
>
>
>
>
>
>
>
<
>
>
>
>
>
>
>
>
>
>
:
r(x) ←r(y), r(z)
r(x) ←p(x)
p(x) ←q(x)
q∗(x) ←p∗(x)
p∗(0)
9
>
>
>
>
>
>
>
>
>
>
=
>
>
>
>
>
>
>
>
>
>
;
q∗(0)
p∗(0)
□
(i’) Contrapositive Restriction
(ii’) ﬁnite SLD-tree

5.1. FORMALISATION OF THE STARTSET PROCEDURE
68
5.1.2
Concrete Speciﬁcation of StartSet
As explained in the previous section, the Progol5 StartSet computes positive literals
α in the Bottom Set Bot(B, e) by searching for the starred ground atoms α∗for which
there exists an SLD-refutation from the contrapositive expansion B∗∪{e∗}. Because
there may be an inﬁnite number of such atoms, the StartSet procedure is restricted
in three key respects. First, to ensure they satisfy the required language bias, each
atom computed by StartSet must be a well-typed ground instance of the schema s of
some head declaration m ∈M. Second, to avoid becoming trapped in inﬁnite loops,
a depth bound N is imposed upon the maximum number of steps in any resolution
derivation. Third, to avoid redundant computations, contrapositives are only formed
that are contained in a restriction of B from the predicate p in the example e to a
predicate q in the scheam s of some head declaration.
These restrictions are formalised in Deﬁnition 5.1.14 below, which deﬁnes the
set denoted StartSet[N,M](B, e) of atoms α that satisfy the conditions stated above.
Since it is generally infeasible to query all possible ground atoms α individually,
Deﬁnition 5.1.14 takes each head declaration m ∈M+ and constructs a goal G by
appending the unstarred type atoms t1, . . . , tn of m to the starred schema s∗. It then
returns the successful ground instances of this starred atom with respect to the starred
example e∗and the contrapositive restriction B∗
p→q of B from the example predicate p
to the schema predicate q. As explained above, these instances are computed using a
depth-bounded SLD interpreter with a maximum limit N on the number of resolution
steps in any computation.
Deﬁnition 5.1.14 (Concrete StartSet). Let B be a program, and e be a ground fact
with predicate p. With respect to an integer N, called the depth, and a set of mode-
declarations M, called the bias, the StartSet of B and e, denoted StartSet[N,M](B, e),
is the set of ground atoms α such that for some head declaration m ∈M+ with
predicate q, schema s, and types t1, . . . , tn, the goal G = ←s∗, t1, . . . , tn succeeds
from program B∗
p→q ∪{e∗} in at most N steps with answer θ such that α is a ground
instance of aθ.

5.1. FORMALISATION OF THE STARTSET PROCEDURE
69
Deﬁnition 5.1.14 is an accurate speciﬁcation of the Progol5 StartSet procedure
in the sense that every atom computed by the former is contained in the latter.
However, the algorithm used in the actual Progol5 StartSet implementation diﬀers
from that presented in Deﬁnition 5.1.14 above in two key respects. First, the actual
Progol5 StartSet searches a larger hypothesis space than strictly necessary. This is
because, to avoid recomputing contrapositives for every query, Progol5 forms con-
trapositives for all head declaration predicates at once. More precisely, it uses the
program B∗
P →Q ∪{e∗} where B∗
P →Q is an abbreviation for the theory S{B∗
p→q | p =
pred(e) and q = pred(m) for some m ∈M+}. But, even then, Progol5 adds more
clauses than are actually needed because it adds contrapositives for predicates lying
above the query predicate in the predicate dependency graph As expected, this can
result in unnecessary ineﬃciency 3.
More signiﬁcantly, Progol5 is unable compute all of the atoms in Deﬁnition 5.1.14.
This is because, to avoid the problematic unlinking of variables, Progol5 adds type
calls not to the query, but to the contrapositives of head declaration predicates. To
be precise, the contrapositives used by Progol5 are internally represented as clauses of
the form ˜ai :-˜a0, a1, . . . , ai−1, ∗ai, ai+1, . . . , an, where ˜a denotes the negation of
a and ∗a denotes its type.4 In addition, each head declaration m ∈M+ with schema
s and types t1, . . . , tn gives rise to a Progol5 clause of the form ∗s :- t1, . . . , tn that
has the eﬀect of grounding the variables in any types atoms of the form ∗ai. (This
is illustrated in Chapter 7, which lists an actual Progol5 clause base.) Interestingly,
this policy of adding type atoms into the contrapositives of the theory as opposed to
the query, leads to an inherent incompleteness of Progol5 5 — which, it should be
noted, is quite distinct from the incompleteness studied in the rest of this chapter.
3 An example of this ineﬃciency can be seen by running Example 5.1.13 on Progol5.0 with the
default settings. Evidently, the system cannot compute the hypothesis q(0) in reasonable time.
4It needs hardly be remarked that there is a mismatch between the notation of this thesis and
the syntactic conventions of Progol5, but this is of no practical concern whatsoever.
5 An example of this incompleteness can be seen by running Example 5.1.15 with b(x) replaced
by b(1). Clearly, the system cannot compute the hypothesis c(1).

5.1. FORMALISATION OF THE STARTSET PROCEDURE
70
Having characterised the atoms which can be computed by the Progol5 StartSet,
two examples are now provided to illustrate Deﬁnition 5.1.14 in terms of Examples
5.1.10 and 5.1.11 above. This is done in Examples 5.1.15 and 5.1.16 below, both
of which present an executable Progol5 input ﬁle together with an SLD-tree for the
associated StartSet computation.
For convenience, the input ﬁles have each been
commented into three sections that correspond to the language bias, background
knowledge, and seed example, respectively.
Example 5.1.15. Let B = {a(x) ←c(x) ;
c(0) ←a(1) ;
b(x)}, e = a(0), N = 9,
and M = {modeh(∗, c(#b))}. Then StartSet[N,M](B, e) = {c(0), c(1)} as the goal
G = ←c∗(x), b(x) obtained from head declaration modeh(∗, c(#b)), with predicate
c, schema c(x), and types b(x), succeeds within 9 steps from B∗
a→c ∪{a∗(0)} (c.f.
Example 5.1.11), with answers {x/0} and {x/1}.
% Bias
:-set(h,9)?
:-observable(a/1)?
:-modeh(*,c(#b))?
% Background
a(X):-c(X).
c(0):-a(1).
b(X).
% Example
a(0).
c∗(x), b(x)
a∗(x), b(x)
c∗(0), b(1)
a∗(0), b(1)
b(1)
□
{x/1}
b(0)
□
{x/0}
(i) CProgol5.0 input
(ii) successful SLD-tree

5.1. FORMALISATION OF THE STARTSET PROCEDURE
71
Example 5.1.16. Let B = {a(x) ←b(x), c(x) ; b(x) ←c(x)}, e = a(0), N = 9, and
M = {modeh(∗, c(0))}. Then StartSet[N,M](B, e) = ∅as the goal ←c∗(0) obtained
from the head declaration modeh(∗, c(0)), with predicate c and schema c(0), ﬁnitely
fails within 9 steps from B∗
a→c ∪{a∗(0)} (c.f. Example 5.1.10).
% Bias
:-set(h,9)?
:-observable(a/1)?
:-modeh(*,c(0))?
% Background
a(X):-b(X),c(X).
b(X):-c(X).
% Example
a(0).
c∗(0)
a∗(0), b(0)
b(0)
c(0)
■
b∗(0)
a∗(0), c(0)
c(0)
■
(i) CProgol5.0 input
(ii) failed SLD-tree
In both examples above, the bias sets the maximum resolution depth to 9 and
asserts the predicate a as observable. In Example 5.1.15, valid hypotheses are declared
as atoms of the form c(k) where k is a constant of type b. Executing this example with
CProgol5.0 shows the two hypotheses c(0) and c(1) are computed, with the former
being preferred on account of its greater compression. As a result, Progol5 eventually
returns the theory B′ = {a(x) ←c(x) ;
c(0) ;
b(x)}. In Example 5.1.16, the atom
c(0) is declared as the only valid hypothesis. Running this example shows that no
hypotheses are computed, and CProgol5.0 fails to return a solution. This outcome is
unexpected because c(0) is a correct hypothesis, and it motivates a formal analysis
of the StartSet procedure — which is achieved in the following sections.

5.1. FORMALISATION OF THE STARTSET PROCEDURE
72
5.1.3
Abstract Speciﬁcation of StartSet
To facilitate the soundness and incompleteness analysis, it is convenient to work
with a simpliﬁed speciﬁcation of the Progol5 StartSet obtained from Deﬁnition 5.1.14
by abstracting away some of the details relating to the language and search bias.
The required speciﬁcation is formalised in Deﬁnition 5.1.17 below, which deﬁnes the
StartSet(B, e) of a program B and example e. Intuitively, this abstract deﬁnition
represents the set of all atoms that can be computed in principle by the StartSet
procedure for some depth N and some bias M. As conﬁrmed in Proposition 5.1.18,
the concrete StartSet[N,M](B, e) of Deﬁnition 5.1.14 above is a special case of the
abstract StartSet(B, e) in Deﬁnition 5.1.17 below.
Deﬁnition 5.1.17 (Abstract StartSet). Let B be a program, and e be a ground
atom. Then the StartSet of B and e, denoted StartSet(B, e), is the set of ground
atoms α such that the goal ←α∗succeeds from the program B∗∪{e∗}.
Proposition 5.1.18. For any integer N and for any mode declarations M, it is the
case that StartSet[N,M](B, e) ⊆StartSet(B, e).
Proof. Suppose α ∈StartSet[N,M](B, e). By Deﬁnition 5.1.14, for some m ∈M+
with predicate q, schema s, and types t1, . . . , tn, the goal ←s∗, t1, . . . , tn succeeds
from the program B′ = B∗
p→q∪{e∗} with an answer θ such that α is a ground instance
of aθ. By the soundness of SLD, it follows B′ |= ∀(a∗θ), and, since α∗is an instance
of s∗θ, that B′ |= α∗. By the completeness of SLD, the goal ←α∗succeeds from B′,
and, since B∗∪{e∗} ⊇B′, it also succeeds from B∗∪{e∗}. Thus α ∈StartSet(B, e)
by Deﬁnition 5.1.17.
A corollary of Proposition 5.1.18, is that any soundness or incompleteness results
which apply to the abstract StartSet speciﬁcation above and thus, a-fortiori, to the
earlier concrete speciﬁcation and the actual Progol5 StartSet procedure. This fact is
illustrated in Examples 5.1.19 and 5.1.20 below, which show the abstract StartSets
corresponding to the background theories and examples previously used in Examples
5.1.15 and 5.1.16.

5.2. PROOF OF THE SOUNDNESS OF STARTSET
73
Example 5.1.19. If B = {a(x) ←c(x) ;
c(0) ←a(1) ;
b(x)} and e = a(0), then
StartSet(B, e) = {a(0), a(1), c(0), c(1)}. For, as shown by the following SLD-trees,
these are the only atoms to succeed as ground starred unit goals from B∗∪{e∗}.
a∗(0)
□
a∗(1)
c∗(0)
a∗(0)
□
b∗(0)
■
b∗(1)
■
c∗(0)
a∗(0)
□
c∗(1)
a∗(1)
c∗(0)
a∗(0)
□
Example 5.1.20. If B = {a(x) ←b(x), c(x) ;
b(x) ←c(x)} and e = a(0), then
StartSet(B, e) = {a(0)}. For, as shown by the following SLD-trees, this is the only
atom to succeed as a starred unit goal from B∗∪{e∗}.
a∗(0)
□
a∗(1)
■
b∗(0)
a∗(0), c(0)
c(0)
■
b∗(1)
a∗(1), c(1)
c(1)
■
c∗(0)
a∗(0), b(0)
b(0)
c(0)
■
b∗(0)
a∗(0), c(0)
c(0)
■
c∗(1)
a∗(1), b(1)
b(1)
c(1)
■
b∗(1)
a∗(1), c(1)
c(1)
■
5.2
Proof of the Soundness of StartSet
The same argument used in Section 5.1.1 to motivate the rationale underlying the
StartSet procedure can also be used to construct the following proof of its soundness
(obtained by expanding parts (iv)-(i) of the original argument). Step 1: assume that
α ∈StartSet(B, e). Step 2: then ←α∗succeeds from B∗∪{e∗} by Deﬁnition 5.1.17.
Step 3: thus B∗∪{e∗} |= α∗by the soundness of SLD. Step 4: therefore, by the
subsumption theorem, there is an SLD-deduction of α∗from B∗∪{e∗}. Step 5:

5.2. PROOF OF THE SOUNDNESS OF STARTSET
74
equivalently, there is an SLD-derivation of a unit clause a∗from B∗∪{e∗} such that
a∗⪯α∗. Step 6: consequently, by Lemma 5.1.4, there is an SLD-derivation of ←a
from B ∪{ ←e} . Step 7: Hence B ∪{¬e} |= ¬α by the soundness of SLD and the
fact a∗⪯α∗. Step 8: ﬁnally α ∈Bot(B, e), by Deﬁnition 4.2.1.
However, an alternative proof is possible that does not appeal to the soundness of
SLD or the subsumption theorem, and more clearly shows how the StartSet procedure
is related to abduction and deduction. This relationship is formalised in Lemma 5.2.1
which shows, in parts (i) and (ii), that if a goal G with starred atoms a∗
1, . . . , a∗
p and
unstarred atoms b1, . . . , bq succeeds from the program B∗∪{e∗} with answer θ, then
B ∪{aiθ} |= eθ and B |= bjθ for all 1 ≤i ≤p and 1 ≤j ≤q. Informally, the
successful instances of any starred atoms entail e relative to B (i.e. they abductively
explain e) and the successful instances of any non-starred atoms are entailed by B
(i.e. they deductively follow from B). Finally, part (iii) proves that every refutation
has as many input occurrences of e∗as there are starred atoms in G.
In contrast to Lemma 5.1.4 before, Lemma 5.2.1 below gives a formal proof by
induction on the number of steps n in the refutation. As might be expected, the base
case is trivial, but the induction step is by cases on the number of starred atoms m
in the ﬁrst side clause C1. Evidently, there are exactly three such cases: m = 0 iﬀ
C1 ∈B, m = 1 iﬀC1 = e∗, and m = 2 iﬀC1 ∈B∗/B. In each case, the induction
hypothesis proves the lemma for all of the goal atoms except the one that is resolved
upon — for which the lemma is then shown to hold also. (It should be noted that,
for convenience and without loss of generality, clauses are written in the proof below
with starred atoms at the front.)
Lemma 5.2.1. Let B be a program, e be a ground atom, and G = ←a∗
1, . . . , a∗
p,
b1, . . . , bq be a goal with p ≥0 starred and q ≥0 non-starred atoms.
If R is an
SLD-refutation in which G succeeds from B∗∪{e∗} with answer θ, then (i) for each
1 ≤i ≤p, the following statement holds: B ∪{aiθ} |= e, and (ii) for each 1 ≤j ≤q,
the following statement holds: B |= bjθ, and ﬁnally (iii) R contains exactly p (input)
occurrences of the clause e∗.

5.2. PROOF OF THE SOUNDNESS OF STARTSET
75
Proof. By induction on the number of steps n in the refutation R:
1. First, suppose n = 0. Then R = ⟨(∅, ∅, G)⟩with G = □. As there are no atoms in
G, and no side clauses in R the lemma holds trivially when n = 0.
2. Next, suppose n > 0 and assume the lemma holds for all refutations with fewer
than n steps. Then R = ⟨(∅, ∅, G), (θ1, C1, G1), . . . , (θn, Cn, □)⟩. Now, let θ′ be the
composition of θ2 · · · θn, and observe G1 succeeds from B∗∪{e∗} in n−1 steps with
answer θ′, where θ = θ1θ′. The proof is now by cases, according to the number m
of starred atoms in the side clause C1:
If m=0 then C1 is an ordinary clause c ←c1, . . . , cr ∈B, and G1 is a resolvent of
G and C1 on some non-starred atom bj. Without loss of generality, assume j = 1,
so that G1 = ←(a∗
1, . . . , a∗
p, c1, . . . , cr, b2, . . . , bq)θ1, where θ1 is the mgu of b1 and c.
Because G1 contains p starred atoms, it follows by the inductive hypothesis that p
occurrences of e∗are used in any refutation of G1; and because C1 ̸= e∗, it follows
that p occurrences of e∗are also used in R. Since, by the inductive hypothesis,
B ∪{aiθ} |= e for all 1 ≤i ≤p and B |= bjθ for all 2 ≤j ≤q, it only remains
to show B |= b1θ. Clearly B |= c ←c1, . . . , cr and since, also by the inductive
hypothesis, B |= ckθ for all 1 ≤k ≤r, it follows B |= cθ. But cθ1 = b1θ1 and so
cθ = b1θ. Thus B |= b1θ as required.
If m=1 then C1 is the ground fact e∗, and G1 is a resolvent of G and C1 on
some starred atom a∗
i . Without loss of generality, assume i = p, so that G1 = ←
(a∗
1, . . . , a∗
p−1, b1, . . . , bq)θ1, where θ1 is the mgu of ap and e. Because G1 contains
p −1 starred atoms, it follows by the inductive hypothesis that p −1 occurrences
of e∗are used in any refutation of G1; and because C1 = e∗, it follows that p
occurrences of e∗are used in R. Since, by the inductive hypothesis, B∪{aiθ} |= eθ
for all 1 ≤i ≤p −1 and B |= bjθ for all 1 ≤j ≤q, it only remains to show
B ∪{apθ} |= e. But apθ1 = e and so apθ = e. Thus B ∪{apθ} |= e as required.
If m=2 then C1 is a contrapositive c∗
k ←c∗, c1, . . . , ck−1, ck+1, . . . , cr for some
clause C = c ←c1, . . . , cr ∈B and some 1 ≤k ≤n, and G1 is a resolvent of

5.2. PROOF OF THE SOUNDNESS OF STARTSET
76
G and C1 on a starred atom a∗
i . Without loss of generality, assume i = p and
k = 1, so that G1 = ←(a∗
1, . . . , a∗
p−1, c∗, c2, . . . , cn, b1, . . . , bq)θ1, where θ1 is the
mgu of ap and c1. Because G1 contains p starred atoms, it follows by the inductive
hypothesis that p occurrences of e∗are used in any refutation of G1; and because
C1 ̸= e∗, it follows that p occurrences of e∗are also used in R. Since, by the
inductive hypothesis, B ∪{aiθ} |= e for all 1 ≤i ≤p −1 and B |= bjθ for all
1 ≤j ≤q, it only remains to show B ∪{apθ} |= e. Clearly B |= c ←c1, . . . , cr
and since, also by the inductive hypothesis, B |= ckθ for all 2 ≤k ≤r, it follows
B |= cθ ←c1θ. Hence B ∪{c1θ} |= cθ. But apθ1 = c1θ1 and so apθ = c1θ. Thus
B ∪{apθ} |= cθ. Since, again by inductive hypothesis, B ∪{cθ} |= e, it follows
B ∪{apθ} |= e as required.
Although it is possible to generalise the results proved above6, Lemma 5.2.1 is
already more general than necessary to prove the soundness of StartSet.
This is
because each goal in a StartSet refutation can only contain at most one starred
atom.
For, by Deﬁnition 5.1.17, the top goal has exactly one starred atom, and,
by Deﬁnition 5.1.1, the number of starred atoms in each subsequent centre clause
either remains the same (if the side clause is from B∗) or decreases by one (if the side
clause is e∗). Consequently, as shown in Theorem 5.2.2, the soundness of the StartSet
procedure follows directly from Lemma 5.2.1.
Theorem 5.2.2. For any program B and ground atom e, StartSet(B, e) ⊆Bot(B, e).
Proof. Suppose α ∈StartSet(B, e).
Then, by Deﬁnition 5.1.17, the goal ←α∗
succeeds from the program B∗∪{e∗}. Consequently, B ∪{α} |= e by Lemma 5.2.1.
Equivalently, B ∪{¬e} |= ¬α. Therefore, since α and e are ground atoms, it follows
α ∈Bot(B, e) by Deﬁnition 4.2.1.
6In particular, the requirement that e be ground can be relaxed and part (i) of Lemma 5.2.1 can
be strengthened to (i’) B ∪{αiθγi} |= eσiθγi, where γi is an arbitrary substitution and e∗σi is the
variant of e∗uniquely associated with the atom α∗
i in the sense of part (iii) of the lemma.

5.3. PROOF OF THE INCOMPLETENESS OF STARTSET
77
5.3
Proof of the Incompleteness of StartSet
At ﬁrst sight, it might appear that the rationale used in Section 5.1.1 to motivate
the StartSet procedure of Deﬁnition 5.1.17 could also be used to obtain the following
proof of its completeness (by expanding parts (i)-(iv) of the original argument in a
complementary fashion to that used at the start of the previous section). Step 1:
assume that α ∈Bot(B, e).
Step 2: then B ∪{¬e} |= ¬α by Deﬁnition 4.2.1.
Step 3: therefore, by the subsumption theorem, there is an SLD-deduction of ←α
from B ∪{ ←e}. Step 4: equivalently, there is an SLD-derivation of a unit clause
←a from B ∪{ ←e} such that a ⪯α. Step 5: consequently, by Lemma 5.1.4, there
is an SLD-derivation of a∗from B∗∪{e∗}. Step 6: thus B∗∪{e∗} |= a∗|= α∗by
the subsumption theorem. Step 7: hence ←α∗succeeds from B∗∪{e∗} by the
completeness of SLD. Step 8: ﬁnally α ∈StartSet(B, e) by Deﬁnition 5.1.17.
However, this line of reasoning is ﬂawed. The reason is that Step 4 (which has
been crossed out) does not hold in general. While it is true that an SLD-deduction of
←α from B ∪{ ←e} means there is an SLD-derivation of a clause that θ-subsumes
←α, it does not necessarily follow that the derived clause is a unit clause.
In
particular, if the B and ←e are inconsistent, then the empty clause can be derived,
and, even if they are not, then it may only be possible to derive a subsuming clause
with more than one atom (as illustrated shortly). Unfortunately, in both these cases,
Lemma 5.1.4 cannot be used to show that a∗is derivable from B∗∪{e∗} and, as
a result, the completeness proof cannot be completed. (Note that, by contrast, the
dual Step 5 in the soundness argument of the previous section is valid because the
(deﬁnite) program B∗∪{e∗} is clearly consistent, and the (deﬁnite) clause α has just
one head atom.)
The invalidity of the supposed argument above is not unexpected given that, as
hinted in previous sections, the StartSet procedure is in fact incomplete with respect
to the computation of positive Bottom Set literals. This is formally demonstrated
in Lemma 5.3.1 below, which simply presents a counter-examples showing that, for
the background knowledge B and seed example e used earlier in Example 5.1.20,

5.3. PROOF OF THE INCOMPLETENESS OF STARTSET
78
the ground atom c(0) is in the BottomSet of B and e but not in the StartSet. As
remarked in Sections 5.1.3 and 5.1.2, it follows from Proposition 5.1.18, that the
actual Progol5 StartSet fails to compute the required solution c(0) — which is why,
as illustrated previously in Example 5.1.16, Progol5 fails to compute the hypothesis
c(0), even though it is derivable by BG and lies within the speciﬁed language and
search bias.
Lemma 5.3.1. For some program B and ground atom e, StartSet(B, e) ̸= Bot(B, e).
Proof. It suﬃces to show that for some program B and some ground atom e, there
exists a ground atom α such that α ̸∈StartSet(B, e) but α ∈Bot(B, e). For this
purpose, let B = {a(x) ←b(x), c(x) ; b(x) ←c(x)}, let e = a(0), let α = c(0). First,
to show α ̸∈StartSet(B, e) it is suﬃcient, by Deﬁnition 5.1.17, to show that the goal
←c∗(0) fails ﬁnitely from the program B∗∪{a∗(0)}. But this is immediate from
the SLD-tree (i) on the left hand side of the ﬁgure below — which, for convenience,
is recalled from Example 5.1.20. Second, to show α ∈Bot(B, e), it is suﬃcient, by
[99], to show there exists a C-derivation of e from B wrt. α. But this is veriﬁed by
the derivation (ii) on the right hand side of the ﬁgure below — in which, for conve-
nience, the resolved literals are underlined, and the input occurrence of α is circled.
(Alternatively, using Deﬁnition 4.2.1, it suﬃces to show B ∪{¬a(0)} |= ¬c(0), which
is equivalent to B ∪{c(0)} |= a(0), which is immediate.)
c∗(0)
a∗(0), b(0)
b(0)
c(0)
■
b∗(0)
a∗(0), c(0)
c(0)
■
a(x) ←b(x), c(x)
b(x) ←c(x)
a(x) ←c(x), c(x)
c(0)
a(0)
(i) Failed SLD-refutation
(ii) Successful C-derivation

5.3. PROOF OF THE INCOMPLETENESS OF STARTSET
79
Having formally exposed the incompleteness of StartSet, it now remains to show
whether the example of Lemma 5.3.1 is an isolated and inconsequential case, or
the symptom of a more signiﬁcant limitation. To begin, Examples 5.3.2 and 5.3.3
exhibit two additional examples of this incompleteness, which arguably represent
the two simplest possible cases in point.
Following on, Example 5.3.4 provides a
further illustration based on a less trivial example taken from graph theory. Given
the standard deﬁnitions of (directed) arc and path, a cycle from a node x via a node
y is deﬁned as a path from x to y followed by a path y to x. Assuming nodes are
represented by integers, a cycle from a node 0 via itself is most easily explained by
hypothesising an arc from 0 to itself. The reader can verify that this hypothesis is
derivable by BG, but that any Progol5 fails to compute this hypothesis.
Example 5.3.2. Let B = {a ←b, d ;
b ←c ;
d ←c}, let e = a, and let α = c.
Then α ∈Bot(B, e) but α ̸∈StartSet(B, e).
Example 5.3.3. Let B = {a(x, y) ←c(x), c(y)}, let e = a(0, 0), and let α = c(0).
Then α ∈Bot(B, e) but α ̸∈StartSet(B, e).
Example 5.3.4. Let B = {path(x, y) ←arc(x, y) ;
path(x, y) ←arc(x, z), path(z, y) ;
cycle(x, y) ←path(x, y), path(y, x)}, let e = cycle(0, 0), and α = arc(0, 0).
Then
α ∈Bot(B, e) but α ̸∈StartSet(B, e).
A more interesting illustration of StartSet’s incompleteness is provided in Fig. 5.1
below, which shows an executable Progol5 input for a parser that converts numeric
strings such as [one, hundred, and, twenty, three] into their integer representations
[1, 2, 3], and vice versa. This application is closely based on an experiment described
in [61], except that the code in Fig. 5.1 simpliﬁes that of [61] in two respects: (i) to
ﬁt on one page, its range is reduced by a factor of 10 to numbers between 1 and 999;
and (ii) to avoid impure logic programming primitives, it uses list operators instead
of built-in integer arithmetic. In brief, the predicates unit, teen, and ten encode,

5.3. PROOF OF THE INCOMPLETENESS OF STARTSET
80
% language bias
:- observable(wordnum/2)?
:- modeh(*,unit(#,[#]))?
% background knowledge
unit(one,[1]).
unit(two,[2]).
unit(three,[3]).
unit(four,[4]).
unit(five,[5]).
unit(six,[6]).
unit(seven,[7]).
unit(eight,[8]).
%unit(nine,[9]).
teen(eleven,[1,1]).
teen(twelve,[1,2]).
teen(thirteen,[1,3]).
teen(fourteen,[1,4]).
teen(fifteen,[1,5]).
teen(sixteen,[1,6]).
teen(seventeen,[1,7]).
teen(eighteen,[1,8]).
teen(nineteen,[1,9]).
tens(ten,[1,0]).
tens(twenty,[2,0]).
tens(thirty,[3,0]).
tens(forty,[4,0]).
tens(fifty,[5,0]).
tens(sixty,[6,0]).
tens(seventy,[7,0]).
tens(eighty,[8,0]).
tens(ninety,[9,0]).
wordnum([X],N):-unit(X,N).
%e.g. 2
wordnum([X],N):-teen(X,N).
%e.g. 12
wordnum([X],N):-tens(X,N).
%e.g. 20
wordnum([X,Y],[N,M]):-tens(X,[N,0]),unit(Y,[M]).
%e.g. 22
wordnum([X,hundred],[N,0,0]):-unit(X,[N]).
%e.g. 200
wordnum([X,hundred,and|Ys],[N,0,M]):-unit(X,[N]),wordnum(Ys,[M]).
%e.g. 202
wordnum([X,hundred,and|Ys],[N,L,M]):-unit(X,[N]),wordnum(Ys,[L,M]). %e.g. 222
% example
wordnum([nine,hundred,and,ninety,nine],[9,9,9]).
% for testing
% wordnum([nine,hundred,and,ninety,eight],[9,9,8]).
Figure 5.1: CProgol5.0 Grammar Experiment — Revisited

5.3. PROOF OF THE INCOMPLETENESS OF STARTSET
81
respectively, the digits from 1 to 9, the numbers 11 through 19, and the multiples of
ten from 10 to 90. The predicate wordnum encodes the translation (from words to
numbers) of all integers in the range 1 to 999.7
As shown in Fig. 5.1 the ground fact α = unit(nine, [9]) has been commented out
of the program, and it is required to try and recover this background fact using the
given positive example. (More generally, one could try and recover several randomly
deleted background clauses using a set of randomly generated examples.) However,
running this code reveals that CProgol5.0 is unable to ﬁnd a solution when given the
example e = wordnum([nine, hundred, and, ninety, nine], [9, 9, 9]), but that it does
recover α when given the example e′ = wordnum([nine, hundred, and, ninety, eight],
[9, 9, 8]) instead. This is surprising as the same ground atom α is a correct hypothesis
in both cases. (Moreover, even though α intuitively accounts for both the ﬁrst and
third digits in e, this does not change the fact that only one instance of α is needed
to prove e from B, as shown below).
This observation was previously reported in [61], but was incorrectly attributed to
the semantic incompleteness of BG reported in [99]. (In other words, it was wrongly
assumed in [61] that the required hypothesis is not computed by Progol5 because it
is not derivable by BG.) In actual fact, given the background knowledge B shown in
Fig. 5.1 and the example e = wordnum([nine, hundred, and, ninety, nine], [9, 9, 9]),
the results in [99] demonstrate that the hypothesis α = unit(nine, [9]) is derivable
by BG because, as shown in the ﬁgure below, there exists a C-derivation of e from
B with respect to α. Consequently, it is the incompleteness of StartSet, and not
the incompleteness of BG, that is responsible for the failure of Progol5 to solve this
previously published problem.
7The grammar experiment reported in [61] may be downloaded from http://www.doc.ic.ac.uk/˜
shm/Software/progol5.0/NumbersExperiment/numbers.pl.
Unfortunately, analysis of the code is
complicated by its use of integer multiplication and addition.
By contrast, the code in Fig. 5.1
employs a list representation of integers and uses list operations to simulate the necessary arithmetic.
As it does not rely on side-eﬀects the code above translates expressions in both directions.

5.3. PROOF OF THE INCOMPLETENESS OF STARTSET
82
wordnum([X, hundred, and|Y s], [N, L, M])
←unit(X, [N]), wordnum(Y s, [L, M])
wordnum([X′, Y ′], [N ′, M ′])
←tens(X′, [N ′, 0]), unit(Y ′, [M ′])
wordnum([X, hundred, and, X′, Y ′], [N, L, M])
←unit(X, [N]), tens(X′, [L, 0]), unit(Y ′, [M])
tens(ninety, [9, 0])
wordnum([X, hundred, and, ninety, Y ′], [N, 9, M])
←unit(X, [N]), unit(Y ′, [M])
unit(nine, [9])
wordnum([nine, hundred, and,
ninety, nine], [9, 9, 9])
This example serves two purposes. First, it shows that, in real applications of
Progol5, the incompleteness of StartSet has a measurable and debilitating eﬀect. (It
is even stated in [61] that ‘methods to circumvent this form of incompleteness are
important for future research’.) Second, it highlights the potential confusion between
the (procedural) incompleteness of StartSet and the (semantic) incompleteness of
BG. Thus, to avoid any further confusion and to begin taking practical counter-
measures, a formal characterisation of the StartSet is necessary that deﬁnes the extent
of its incompleteness, distinguishes it from the incompleteness of BG, and provides
some indication of how diﬃcult it is to overcome. The required characterisation is
obtained in the next section, and two techniques for surmounting it are then discussed
in the subsequent section.

5.4. CHARACTERISING THE INCOMPLETENESS OF STARTSET
83
5.4
Characterising the Incompleteness of StartSet
The previous section exposed an inherent incompleteness of the StartSet procedure
by exhibiting several examples of positive Bottom Set literals that StartSet is unable
to compute. This section shows how a more detailed study of those examples can be
used to derive to a formal characterisation of this newly recognised incompleteness.
The resulting characterisation, which is formalised in Theorem 5.4.1 below, exploits
the fact that every positive Bottom Set literal is associated with one or more C-
deductions obtained in the following way: ﬁrst, by Deﬁnition 4.2.1, for any program
B and ground atom e, it holds that α ∈Bot(B, e) only if α is derivable by BG from B
and e; hence, by the characterisation derived in [99],it follows there is a C-deduction
of e from B wrt. α.
It is interesting to note that, for each example in the previous section, every such
C-deduction requires the use of factoring in at least one resolution step. Indeed, even
though factoring is not usually required in Horn clause logic, it is needed in all of
these examples to ensure that α is used only once as an input clause. By contrast, it
can be easily veriﬁed that, associated with every successful StartSet computation in
this chapter, there is at least one C-deduction which does not require factoring. This
observation is exploited in Theorem 5.4.1, which proves that the StartSet procedure
computes precisely those atoms α such that there exists a factor-free C-deduction of
e from B wrt. α.
Strictly, Theorem 5.4.1 makes explicit the self-evident assumption that the seed
example e is not already entailed by the background knowledge B.
As described
in Chapter 4, the Progol5 covering loop ensures this by removing all such examples
prior to selecting the seed example. Clearly, there is no use in ﬁnding redundant
explanations for observations that have already been explained. (More importantly,
if B = {p} and e = p and α = q, then there is a trivial factor-free C-derivation
of e from B wrt. α but the goal ←α∗does not succeed from program B∗∪{e∗}.)
Incidentally, it is implicitly assumed here and throughout that B, e and α are all
unstarred expressions.

5.4. CHARACTERISING THE INCOMPLETENESS OF STARTSET
84
The proof of Theorem 5.4.1 takes each direction of the equivalence in turn, and
transforms the C-derivation into a StartSet computation and vice versa. In both cases,
a sequence of ﬁve derivations is considered, with Lemma 5.1.4 being used to transform
between the relevant starred and unstarred derivations. The only subtlety is that,
before applying the lemma, it is necessary to temporarily insert a previously unused
proposition symbol into the derivation and to remove its contrapositive complement
from the transformed derivation.
Informally the proposition ⊤represents logical
truth, while its contrapositive complement ⊤∗represents falsity. For convenience,
the derivations are illustrated in Figs. 5.2 and 5.3.
Theorem 5.4.1. Let B be a program and let e be a ground atom such that B ̸|= e.
Then for any ground atom α, the following equivalence holds: α ∈StartSet(B, e) iﬀ
there exists a factor-free C-deduction of e from B wrt. α.
Proof. Taking the ‘only if’ and ‘if’ directions in turn:
1. Suppose α ∈StartSet(B, e). By Deﬁnition 5.1.17, there is an SLD-refutation R1
of ←α∗from B∗∪{e∗}. By the soundness of SLD, it follows B∗∪{e∗} |= α∗,
which is equivalent to B∗∪{ ←α∗} |= ←e∗. Consequently, by the subsumption
theorem, there is an SLD-derivation R2 from B∗∪{ ←α∗} of a negative unit clause
←E that θ-subsumes ←e∗. (Notice that the derived clause cannot contain n = 0
atoms, or else R2 would violate part (iii) of Lemma 5.2.1; and the derived clause
cannot contain n > 1 atoms, or else the refutation obtained from R2 by resolving
away these atoms with n occurrences of the clause e∗would violate part (iii) of
Lemma 5.2.1.) Now, let ⊤and ⊤∗be propositions not used in R2, and let R3 be
the SLD (and hence factor-free) derivation of ⊤∗←E∗from B∗∪{⊤∗←α∗}
obtained from R2 by adding the atom ⊤∗into the head of each centre clause. By
Lemma 5.1.4, there exists a corresponding factor-free derivation R4 of E ←⊤from
B ∪{α ←⊤}. Finally, let R5 be the factor-free derivation of E from B ∪{ ←α}
obtained from R4 by removing the atom ⊤from the body of each centre clause.
Since E clearly θ-subsumes e, it follows that R5 is a factor-free C-deduction of e
from B wrt. α (as illustrated in Fig. 5.2).

5.4. CHARACTERISING THE INCOMPLETENESS OF STARTSET
85
E
E
E
Figure 5.2: Derivations R1 −R5 in the ‘only if’ direction of Theorem 5.4.1
2. Suppose there is a factor-free C-deduction of e from B wrt. α. Then there is a
factor-free C-derivation S1 from B ∪{α} of a unit clause E that θ-subsumes e.
(Notice that the derived clause cannot contain any body atoms, or else it would
not subsume e — which has no body atoms; and the derived clause must contain
exactly one positive atom, or else it would not be derivable from B and α — which
are both deﬁnite). Since B ̸|= e, it follows there is at least one input occurrence of
α in S1; and since S1 is a C-derivation wrt. α, it follows there is exactly one input
occurrence of α in S1. Now, let ⊤and ⊤∗be propositions not used in S1, and let
S2 be the factor-free derivation of E ←⊤from B ∪{α ←⊤} obtained from S1
by inserting the atom ⊤into the body of each clause formerly descended from the
(one and only) input occurrence of α. By Lemma 5.1.4, there exists a factor-free
derivation S3 of ⊤∗←E∗from B∗∪{⊤∗←α∗}. (Note that since the atom ⊤is
transposed in the root clause, it must therefore be transposed wherever it occurs
in the derivation.) Next, let S4 be the C-derivation of ←E∗from B ∪{ ←α∗}
obtained from S3 by removing the atom ⊤∗from the head of each clause formerly
descended from the input occurrence of ⊤∗←α∗. By the soundness of SLD, it
follows B∗∪{ ←α∗} |= ←E∗|= ←e∗. Equivalently, B∗∪{e∗} |= α∗. Hence, by
the subsumption theorem, there is an SLD-refutation S5 of ←α∗from B∗∪{e∗}.
Thus α ∈StartSet(B, e) by Deﬁnition 5.1.17 (as illustrated in Fig. 5.3).

5.5. SOLVING THE INCOMPLETENESS OF STARTSET
86
E
E
E
E
Figure 5.3: Derivations S1 −S5 in the ‘if’ direction of Theorem 5.4.1
By characterising the atoms that are (not) computable by StartSet, Theorem 5.4.1
also clariﬁes the distinction between the procedural incompleteness of StartSet and
the semantic incompleteness of BG. Speciﬁcally, an atom α is in the Bottom Set of B
and e iﬀthere exists a C-deduction of e from B wrt. α; but atom α is in the StartSet
of B and e iﬀat least one such derivation is factor-free. (Note that, at the ground
level, this is equivalent to requiring a merge-free derivation — in the sense of [3] —
as conjectured in [73]).
While it is well known [99] that a clause h is derivable by BG from B and e iﬀ
there exists a C-deduction of e from B wrt. h, it follows from Theorem 5.4.1 that h is
only computable by Progol5 if at least one such derivation is factor free. Informally,
the former requires that just one ground instance of the hypothesis is used, while the
latter requires that the ground instance is used to resolve away just one atom. As
shown in the previous section, the second is clearly a strict subset of the ﬁrst.
5.5
Solving the Incompleteness of StartSet
Having exposed and characterised the incompleteness of the Progol5 StartSet with
respect to the computation of positive Bottom Set literals, this section compares
two diﬀerent solutions to this incompleteness. The ﬁrst solution is to give StartSet
the ability to perform ancestor resolution, as used in the Prolog Technology Theorem

5.5. SOLVING THE INCOMPLETENESS OF STARTSET
87
Proving (PTTP) [90] and Model Elimination (ME) [48] proof procedures; and the
second solution is to replace StartSet by a highly constrained form of abduction.
A comparison of these two approaches reveals several advantages of abduction over
contrapositives that motivate the rest of the thesis.
5.5.1
Ancestor Resolution
As remarked in [61], the contrapositive reasoning mechanism used by StartSet is
a special case of the PTTP proof procedure. The main diﬀerence is that to ensure
completeness in the non-Horn case, as well as furnishing contrapositives of the theory,
PTTP uses ancestor resolution when unfolding the query, and supports the extraction
of indeﬁnite answers — all of which is explained in detail in [90]. Because StartSet
ultimately involves the computation of ground atoms, indeﬁnite answers can be safely
ignored in the present context. Ancestor resolution, on the other hand is discussed
further below. For convenience, a brief introduction to ancestor resolution is provided
here and, for further details, the reader is referred to any standard text on the ME
[48], PTTP [90], SL [44], OL [7] or SOL [27] proof procedures.
Historically, Ancestor resolution is an important technique in clausal theorem
proving which allows the implementation of complete ﬁrst-order inference procedures
based on computationally eﬃcient input resolution strategies. As described in [90]
this is easily done by retaining resolved goal literals as so-called framed literals (which
are enclosed in square braces to denote their framed status) and allowing unframed
literals to resolve with complementary framed literals to their right. Informally the
framed literals to the right of a given literal denote the previously resolved upon
ancestors of that literal; whereas the unframed literals to the left of a given literal
denote the pending sub-goals of that literal. By convention, framed literals with no
unframed literals to their left are automatically deleted.
It should be noted that
ancestor resolution is not strictly a resolution operation because it exploits the fact
(originally introduced through the ME reduction operation) that only the resolved
upon literals of ancestor clauses need actually be retained during a derivation.

5.5. SOLVING THE INCOMPLETENESS OF STARTSET
88
The need for ancestor resolution in non-Horn applications of PTTP is well-known
and illustrated in the ﬁgure below for a speciﬁc example taken from [90], which veriﬁes
that the literal q is entailed by the theory T = (p ∨q) ∧(¬p ∨q). As shown by the
two search trees, the computation for q fails when executed as a standard SLD query
over the contrapositives T ∗, but succeeds as a PTTP query using SLD with ancestor
resolution. In the left hand branch of the PTTP computation, the initial goal ?q
resolves with the contrapositive q ←p∗to yield the derived goal ?p∗, [q]. In turn, this
resolves with p∗←q∗to give ?q∗[p∗][q]. At this point, the unframed goal literal q∗is
resolved away by the complementary framed ancestor literal [q] to its right. Formally,
this leaves the new goal ?[p∗][q], which reduces to the empty clause after removing
framed literals with no unframed literals to their left. By contrast, the query fails
using SLD without ancestor resolution as there are no contrapositives for q∗.



p ∨q
¬p ∨q




















p ←q∗
q ←p∗
p∗←q∗
q ←p

















q
p∗
q∗
■
p
q∗
■
q
p∗[q]
q∗[p∗][q]
□
p[q]
q∗[p][q]
□
non-Horn theory: T
contrapositives: T ∗
SLD
PTTP
At ﬁrst sight, it might appear that ancestor resolution is made redundant in Horn
clause applications of PTTP by the refutation completeness of SLD-resolution in Horn
clause logic. When combined with the with the known ineﬃciencies [90] of ancestor
resolution, this fact would seem to justify the exclusion of ancestor resolution from
the StartSet procedure. However, as explained in [72], this view is not correct. In
fact, the simple example below shows that ancestor resolution is required for the
completeness of PTTP in the Horn clause case — even when the theory is a single
Horn clause and the query is a single literal! The search trees show that ancestor
resolution is needed to ﬁnd which instances of the literal ¬p(z) are entailed by the

5.5. SOLVING THE INCOMPLETENESS OF STARTSET
89
clause ←p(0), p(x). With respect to the contrapositives of this clause, the query
p∗(z) succeeds with answer z/0 using SLD with ancestor resolution, but ﬁnitely fails
using SLD without ancestor resolution.
{ ←p(0), p(x)}



p∗(0) ←p(x)
p∗(x) ←p(0)



p∗(z)
p(x)
■
p(0)
■
p∗(z)
p(x)[p∗(0)]
□
{z/0}
p(0)[p∗(0)]
□
{z/0}
Horn theory: T
contrapositives: T ∗
SLD
PTTP
Of course, it is necessary to observe an important distinction here. On the one
hand, it is true that any literal entailed by a Horn theory can be deduced from that
theory using standard SLD resolution: neither contrapositives nor ancestor resolution
are needed for this. It is also true that in the standard formulation of the ME calculus
[48] the reduction rule is not needed to show the inconsistency of a Horn theory. But,
on the other hand, PTTP is not simply a refutation or consequence ﬁnding procedure;
it is ﬁrst and foremost a query answering procedure. With this distinction in mind, the
example above clearly shows that ancestor resolution is necessary for the completeness
of PTTP in the Horn clause case: when the theory is a set of Horn clauses and the
query is a set of literals. Conversely, this observation also explains why StartSet —
which does not employ ancestor resolution — is incomplete in the ﬁrst place.
Here, it could be mentioned that, in general, indeﬁnite answers are also needed for
the completeness of PTTP in the Horn clause case. This can be shown by considering
the theory containing the single Horn clause ←p(0), p(1) and the query containing
the single literal p∗(x). Even though the theory entails ∃x(¬p(x)), the query fails from
the contrapositives p∗(0) ←p(1) and p∗(1) ←p(0) unless provision is made for the
extraction of indeﬁnite answers. But, since this is beyond the scope of the present
discussion, the section concludes instead with Figs. 5.4 and 5.5, which show how

5.5. SOLVING THE INCOMPLETENESS OF STARTSET
90
c∗(0)
a∗(0), b(0), [c∗(0)]
b(0), [c∗(0)]
c(0), [c∗(0)]
□
b∗(0), [c∗(0)]
a∗(0), c(0), [c∗(0)]
c(0), [c∗(0)]
□
Figure 5.4: Solution to Example in Lemma 5.3.1 using Ancestor Resolution
unit∗(U, [V ])
wnum∗([U], [V ])
unit∗(U, [V ])
wnum∗([X, hun,
and, U], [N, 0, V ])
unit(X, [N])
wnum∗([U], [V ])
unit∗(U, [V ])
■
wnum∗([X, U], [N, V ])
tens(X, [N, 0])
unit∗(U, [V ])
wnum∗([W, hun,
and, X, U], [P, N, V ])
unit(W, [P])
wnum∗([X, U], [N, V ])
tens(X, [N, 0])
unit∗(U, [V ])
unit(nine, [9])
wnum∗([ninety, nine], [9, 9])
tens(ninety, [9, 0])
unit∗(nine, [9])
tens(ninety, [9, 0])
unit∗(nine, [9])
□
{U/nine, V/9}
wnum∗([U, hun],
[V, 0, 0])
unit∗(U, [V ])
■
wnum∗([U, hun,
and|Y ], [V, 0, M])
wnum(Y, [M])
unit∗(U, [V ])
■
wnum∗([U, hun,
and|Y ], [V, L, M])
wnum(Y, [L, M])
unit∗(U, [V ])
wnum([ninety, nine],
[9, 9])
unit∗(nine, [9])
tens(ninety, [9, 0])
unit(nine, [9])
unit∗(nine, [9])
unit(nine, [9])
unit∗(nine, [9])
□
{U/nine, V/9}
Figure 5.5: Solution to Example in Fig. 5.1 using Ancestor Resolution

5.5. SOLVING THE INCOMPLETENESS OF STARTSET
91
ancestor resolution overcomes the incompleteness of StartSet noted in Lemma 5.3.1
and Fig. 5.1. In the latter, to save space, queries are abbreviated in the obvious way
and written from top-to-bottom. In addition, framed literals have been completely
enclosed (to avoid confusing them with lists) and only negative ancestors are retained.
5.5.2
Abduction
By deﬁnition, the Progol5 StartSet procedure is required to compute the ground
atoms α such that B ∪{¬e} |= ¬α. Since this is equivalent to computing the ground
atoms α such that B ∪{α} |= e, it follows that the task of computing positive
Bottom Set literals is in fact a highly restricted form of abduction: where the theory
is a deﬁnite program and the goal and hypothesis are single ground atoms. These
restrictions mean that very simple abductive procedures provide a sound and complete
and relatively eﬃcient means of computing such atoms. This is because no negation
or consistency checking need be supported. In fact, all that is required is the ability to
abduce or assume a single goal atom during a computation and to allow that atom to
resolve away subsequent goal atoms. In order to ensure the language bias is satisﬁed,
the abduced atom is simply required to unify with the schema of a head declaration.
Figs. 5.6 and 5.7, above, show how this approach overcomes the incompleteness
of StartSet noted in Lemma 5.3.1 and Fig. 5.1. Unlike the approach described in the
previous section, abduction does not employ contrapositives or ancestor literals, but
unfolds e using the rules in B just like a conventional Prolog query — except that, as
stated above, the abductive procedure is able to abduce one atom α that uniﬁes with
the schema of a head declaration. In Figs. 5.6 and 5.7, the underlined atoms c(0) and
unit(nine, [9]) are abduced. The computation then continues just like a conventional
Prolog derivation — except that any subsequent atom which uniﬁes with the abduced
atom can automatically succeed after applying the unifying substitution. In Figs.
5.6 and 5.7, the last goal in each computation succeeds because it uniﬁes with the
corresponding abduced atom α. Upon completion of each successful computation,
the abduced atom α is returned as the computed answer.

5.5. SOLVING THE INCOMPLETENESS OF STARTSET
92
?
a(0)
% query is the seed example e
?
b(0), c(0)
% resolve a(0) with a(x) ←b(x), c(x)
?
c(0), c(0)
% resolve b(0) with b(x) ←c(x)
α =
c(0)
% abduce c(0)
?
c(0)
% resolve c(0) with abduced atom c(0)
?
□
% succeed returning abduced atom c(0)
Figure 5.6: Solution to Example in Lemma 5.3.1 using Abduction
?
wnum([nine, hun, and, ninety, nine], [9, 9, 9])
?
unit(9, [9]), wnum(ninety, nine, [9, 9])
α =
unit(9, [9])
?
wnum(ninety, nine, [9, 9])
?
tens(ninety, [9, 0]), unit(nine, [9])
?
unit(nine, [9])
?
□
Figure 5.7: Solution to Example in Fig. 5.1 using Abduction
Comparing Figs. 5.6 and 5.7 with Figs. 5.4 and 5.5, shows the abductive search
spaces are signiﬁcantly smaller. Informally, this is because contrapositives tend to
increase the size of the search space [48], while reasoning abductively backwards from
the goal reduces the number of unbound variables and failed branches. One more
diﬀerence is that only one abductive query is run for each seed example, while n
contrapositive queries must be run for each seed example, where n is the number of
head declarations. Thus, if the atom teen(nineteen, [1, 9]) were removed from Fig. 5.1
and replaced by the head declaration modeh(∗, teen(#, [1, #])), then, with respect
to the example wordnum([nine, hundred, and, ninety, nine], [9, 9, 9]), the abductive
computation would remain unchanged from Fig. 5.7, but StartSet must now run two
queries for ?teen(x, [y, z]) and ?unit(x, [y]).

5.5. SOLVING THE INCOMPLETENESS OF STARTSET
93
The potential beneﬁts to be gained by replacing the contrapositive reasoning
mechanism of StartSet with a simple abductive procedure are further illustrated in
Chapter 7. But, the real purpose of this thesis is to show that there are even greater
beneﬁts to be had by not restricting the abductive procedure at all, but by generalising
the inductive methodology to exploit a full strength abductive procedure instead. For
example, given the seed example wordnum([nine, hundred, and, nineteen], [9, 1, 9])
an ALP procedure with the ability to compute multiple atom hypotheses could recover
the two background facts unit(nine, [9]) and teen(nineteen, [1, 9]). More generally, it
is shown in Chapter 6 how the ability to abduce more than one atom can be exploited
within a generalisation of Progol5 to induce more than one rule at a time, which is
shown in Chapter 7 to extend the practical utility of Machine Learning systems in
real-world applications. By contrast, it is diﬃcult to see how a procedure based on the
use of contrapositives could be eﬀectively used to compute multiple atom hypotheses.
Clearly, it would be impractical to query all possible n-atom combinations of head
declaration schemas, as the number of queries grows exponentially with n.
Another useful ALP feature is the use of eﬃcient integrity checking techniques.
For instance, when attempting to abduce an atom such as teen(ten, [1, 0]), ALP
procedures can use the constraint ←teen(x, [1, 0]), stating that 10 is not a teen, to
abort the computation. By contrast, StartSet would ﬁnish the entire computation
before detecting this violation. Another important feature is the ability of ALP to
support negation. Although a full treatment of negation is beyond the scope of this
thesis, it will be shown that the controlled use of negation in integrity constraints
enables a more sophisticated handling of language bias than Progol. In particular, it
will allow type information in the head declarations to be used, when appropriate, to
infer type information missing from the background theory. Unlike Progol, which can
only use type information to fail a computation when a type violation is detected, the
system described in Chapter 6 can also take remedial action to actively circumvent
that violation — by abducing the missing type information. Once again, Chapter 7
shows how this ability further enlarges the class of problems soluble in practice.

5.5. SOLVING THE INCOMPLETENESS OF STARTSET
94
To conclude,
this chapter exposed and characterised an inherent incompleteness
of the ILP system Progol5 and suggested several reasons why ALP could be used to
overcome this incompleteness and further enhance the underlying approach. (It is
also interesting to note that the incompleteness of StartSet is equivalent to abducing
one atom and then preventing the abduced atom from resolving away subsequent
goal atoms.) These suggestions now provide the motivation for the following chapter,
which shows how the potential advantages can indeed be realised, in practice, by
combining the KM ALP procedure within an ILP procedure that generalises the
successful mode-directed TCIE approach of Progol5. A corresponding semantics is
also developed that extends the key principles of BG from clauses to theories in order
to characterise the hypotheses derivable by the new procedure.

Chapter 6
Hybrid Abductive Inductive
Learning
This chapter introduces a novel Machine Learning approach called Hybrid Abductive
Inductive Learning (HAIL) that integrates abduction and induction within an overall
cycle of learning. A proof procedure is described, called HAIL, that combines the
ALP procedure of Kakas and Mancarella within a generalisation of Muggleton’s ILP
system Progol5. A semantics is also presented, called Kernel Set Subsumption (KSS),
that extends the principles of BG from clauses to theories and includes the hypotheses
computable by HAIL.
First of all, Section 6.1 discusses the motivation underlying the HAIL approach
and describes the main intuition behind the technical results that are presented in the
following sections. Then, Section 6.2 formalises the semantics of KSS and derives a
proof theoretic characterisation of KSS that generalises the well-known C-derivation
characterisation of BG. Finally, Section 6.3 describes the HAIL proof procedure and
shows how it overcomes some of the limitations of Progol5 and enlarges the class of
problems soluble in practice.
95

6.1. HYBRID ABDUCTIVE INDUCTIVE LEARNING (HAIL)
96
6.1
Hybrid Abductive Inductive Learning (HAIL)
The motivation for a hybrid learning approach that integrates both ALP and ILP is
suggested by the analysis in the last chapter, which showed how Progol5 suﬀers from
a procedural incompleteness that aﬀects its performance in real world applications.
Even though Progol5 is widely regarded as one of the most successful ILP systems
currently available, this analysis suggests there is considerable room for improvement.
In particular, it was argued at the end of the preceding chapter that incorporating a
full ALP procedure within a generalisation of Progol5 could potentially lead to three
signiﬁcant improvements which, for convenience, are recalled below:
• using an abductive proof procedure would avoid the need for contrapositives
and overcome the incompleteness of the Progol5 StartSet
• exploiting abductive hypotheses with more than one atom would enable the
inference of potentially useful hypotheses outside the semantics of BG
• utilising abductive integrity checking mechanisms would increase eﬃciency and
permit a more eﬀective use of language bias.
The present chapter aims to show these advantages can be realised in a logically
principled and practically viable way. The strategy is to generalise the semantics of
BG from clauses to theories and to show how the core Progol5 methodology can then
be lifted to the new semantics. The resulting procedure, called HAIL, takes exactly the
same inputs as Progol5, deliberately reuses as much as of the tried and tested Progol5
machinery as possible — speciﬁcally with regard to its eﬃcient use of language and
search bias — but is able to infer hypotheses outside the semantics of BG. In the next
chapter, the above claims will be validated by comparing the performance of HAIL
and Progol5 on a biologically based case study.
To explain the close connection between HAIL and Progol5, it is worth recalling
how each hypothesis returned by Progol5 is found by constructing and generalising
a ﬁnite Horn clause Bottom Set of the form C in (6.1) below. Crucial to Progol5’s

6.1. HYBRID ABDUCTIVE INDUCTIVE LEARNING (HAIL)
97
success is its eﬀective utilisation of language and search bias in the construction
and generalisation of this clause.
First of all, the head atom α is computed by
StartSet in accordance with the head declarations. Then, the body atoms δ1, . . . , δm
are computed by BottomSet using the body declarations (to give the most speciﬁc
clause up to some ﬁnite depth). Lastly, this clause is generalised by LatticeSearch,
which uses both the language bias and a compression heuristic.
C = α ←δ1, · · · · · · , δm
(6.1)
As explained in Chapter 4, the clause C in (6.1) plays a key role in the Progol5
methodology as it bounds a hypothesis space that would otherwise be intractable to
search. By deﬁnition, the head atom α satisﬁes the property B ∧¬eσ |= ¬α and
each body atom δj satisﬁes B ∧¬eσ |= δj — for some Skolemising substitution σ.1
Logically, these properties are equivalent to B∧α |= eσ and B∧(¬δ1∨. . .∨¬δm) |= eσ.
In this way, the computation of α is seen to be the task of computing a single atom
abductive explanation of the goal eσ with respect to the theory B. It is then a small
step to envisage a generalisation of this method in which the abductive explanation
is not restricted to a single atom.
In particular, this observation suggests a generic three phase methodology whereby
an abductive procedure would ﬁrst compute a set of head atoms αi (for 1 ≤i ≤n)
such that B ∧(α1 ∧. . . ∧αn) |= eσ. A deductive procedure would then be applied
to each head atom αi to append a set of body atoms δi
j (for 1 ≤j ≤mi) such that
B∧(¬δi
1∨· · ·∨¬δi
mi) |= eσ — where mi denotes the number of body atoms in the i-th
clause. This would give a ground theory of the form K in (6.2) below, from which a
hypothesis H could then be obtained using an inductive search procedure to ﬁnd a
highly compressive theory that subsumes K and falls within a given bias M.
1From Deﬁnition 4.2.1 it follows B ∪e |= ¬α and B ∪e |= δj for all 1 ≤j ≤m. From Section 2.3.1
it follows e ≡¬eσ, where σ is the Skolemising substitution used in e. Hence, B ∧¬eσ |= ¬α and
B ∧¬eσ |= δj. Thus B ∧α |= eσ and B ∧¬δj |= eσ by contraposition.

6.1. HYBRID ABDUCTIVE INDUCTIVE LEARNING (HAIL)
98
K =











α1
←
δ1
1, · · · · · · , δ1
m1
...
αn
←
δn
1 , · · · · · · , δn
mn











(6.2)
Henceforth, the ground theory K in (6.2) will be called a Kernel Set of B and e
and the above method of ﬁnding theories that subsume a Kernel Set will be called
Kernel Set Subsumption (KSS). Of course, since there are many possible Kernel Sets
for a given B and e, in practice the success of this approach will depend on its
ability to make extensive use of language and search bias in the construction and
generalisation of K. Since Kernel Sets eﬀectively generalise the notion of Bottom Sets
from clauses to theories, a promising solution would be to adapt the techniques used
so successfully by Progol5 for exploiting language and search bias in the construction
and generalisation of Bottom Sets.
In particular, if the abductive procedure could be constrained to return minimal
sets of atoms conforming to the given head declarations, then the Progol5 BottomSet
procedure can be applied to each abduced head atom αi in turn to obtain a ﬁnite
set of body atoms δi
j satisfying the given language bias and resource bounds. In this
way, the Progol5 methodology can be generalised to induce single and multiple clause
hypotheses outside the semantics of BG. For example, if B = {p(x, y) ←q(x), q(y)}
and e = p(0, 1), then the three hypotheses H1 = q(x), H2 = (q(0) ∧q(1)) and
H3 = p(0, 1) are all derivable by this new method (using the Kernel Sets K1 = H2,
K2 = H2 and K3 = H3), but only the last is derivable by BG from B and e.
In order to generalise a Kernel Set, one could employ a general reﬁnement operator
for theories (as opposed to single clauses). But while this method would have the
advantage of being complete with respect to the semantics of KSS, it would have the
disadvantage of being computationally expensive to implement. More eﬃcient would
be an incremental greedy approach that applies the Progol5 Search procedure to each
successive Kernel Set clause to ﬁnd the most compressive generalisation consistent
with the remaining Kernel Set clauses. Even though this methodology may miss a

6.1. HYBRID ABDUCTIVE INDUCTIVE LEARNING (HAIL)
99
globally optimal hypotheses, it is guaranteed to return a hypothesis that is at least
as compressive as any hypothesis returned by Progol5.
More importantly, by using this method, the cost of constructing and generalising
each n-clause Kernel Set grows linearly (on average) with the number of clauses n.
Furthermore, in the limiting case when n=1, the cost of constructing and generalising
each Bottom Set clause will typically be lower with the new method than Progol5 due
to improved performance of abduction over contrapositives. Consequently, assuming
reasonable limits on the number of abductive solutions investigated — which will be
limited through a number of system parameters set by the user — the ability to solve
a larger class of practical problems (as evidenced in the next chapter) would seem to
justify the manageable increase in computational eﬀort.
Just as Progol5 operates by iterating the inference method of BG using a standard
covering approach, the HAIL proof procedure is obtained by combining the three phase
methodology for KSS within a covering loop. The result is the learning cycle shown
in Fig. 6.1.2 Like Progol5, the input (a) is an inductive context ⟨B, E+, E−, M⟩and
the output (g) is an inductive generalisation H1 ∪· · · ∪Hk. As usual, the covering
loop (b, f) selects a seed example ei from the remaining positive examples E+
i , adds
the hypothesis Hi to the current background knowledge Bi, and then removes any
newly covered examples. Initially B1 = B and E+
1 = E+. The negative examples E−
and the mode declarations M remain unchanged throughout.
Each theory Hi is formed in three steps.
In the abductive step (c), an ALP
procedure is used to construct an abductive explanation ∆i of the seed example ei
with respect to the current background knowledge Bi. In the deductive step (d), the
Progol5 BottomSet routine is used to construct a Kernel Set Ki from the head atoms
α1, . . . αn in ∆i. In the inductive step (e), the Progol5 Search procedure is adapted to
construct a compressive theory Hi that subsumes Ki (by variablising constants and
dropping atoms). Further details of these procedure can be found in Section 6.3.
2Although Fig. 6.1 closely resembles Peirce’s inferential cycle of knowledge discovery in Fig. 1.2,
the abductive and inductive components are more closely related to his syllogistic view in Fig. 1.1.

6.1. HYBRID ABDUCTIVE INDUCTIVE LEARNING (HAIL)
100
Deduction
d
Induction
e
Abduction
c
Seed Selection
b
Input
Cover Removal
f
Output
a
g
Figure 6.1: Overview of HAIL Learning Cycle
So far, the KSS approach has only been deﬁned for the Horn clause case; but
there is a natural generalisation of KSS to full clausal logic. The main diﬀerence is
that, in the general case, the special role previously played by the head atom of a
Horn clause is now played by an arbitrary literal in each clause called a key literal.
For convenience, key literals will always be written at the front of their respective
clauses. A Kernel Set of a theory B and clause e is then deﬁned as a ground theory
of the form K in (6.3) below, where the key literals collectively entail eσ relative to
B (i.e. B ∧(L1
0 ∧. . .∧Li
0 ∧. . .∧Ln
0) |= eσ) and the non-key literals individually entail
eσ relative to B (i.e. B ∧(L1
1 ∨. . . ∨Li
j ∨. . . ∨Ln
mn) |= eσ).

6.2. KERNEL SET SUBSUMPTION (KSS) SEMANTICS
101
K =











L1
0
∨
L1
1 ∨· · · · · · ∨L1
m1
...
Ln
0
∨
Ln
1 ∨· · · · · · ∨Ln
mn











(6.3)
Comparing (6.2) with (6.3), it is easy to see that Horn clause KSS is a special
case of the ﬁrst-order KSS. Moreover, it can also be shown that the latter is a sound
extension of BG in the general case. Furthermore, just as the hypotheses derivable
by BG are characterised by Plotkin’s C-derivation, the hypotheses derivable by KSS
are characterised by a more general type of derivation obtained by extending the
C-derivation from single to multiple clauses and restricting the way those clauses
interact.
After formally proving these properties of KSS in the next section, the
section after that will describe and illustrate a concrete Horn clause implementation
of the HAIL proof procedure described in Fig. 6.1 above.
6.2
Kernel Set Subsumption (KSS) Semantics
In order to formalise the intuitions presented above, it is convenient to deﬁne the
notion of a key literal, which simply refers to some (arbitrarily selected) literal within
a given clause.
For convenience, it will be always be assumed hereafter that the
key literal is always written at the front of its clause, as formalised in Deﬁnition 6.2.1
below. (Note that, without loss of generality, this can easily be achieved by reordering
the literals within the clause.)
Deﬁnition 6.2.1 (Key literal). If C = L0 ∨L1 ∨. . . ∨Ln is a clause with n ≥1
literals, then the ﬁrst literal L0 is called the key literal of C and any following literals
L1 . . . Ln are called non-key literals.
As formalised in Deﬁnition 6.2.2 below, a Kernel Set of a theory B and a clause
e (neither of which is necessarily Horn) is deﬁned as a set K of ground clauses ki
whose key literals collectively entail the Skolemisation of e relative to B, and whose

6.2. KERNEL SET SUBSUMPTION (KSS) SEMANTICS
102
non-key literals individually entail the Skolemisation of e relative to B. In addition,
as formalised in Deﬁnition 6.2.3, a theory H is said to be derivable by KSS iﬀit
subsumes some Kernel Set of B and e (in the sense of Section 2.3.1).
Deﬁnition 6.2.2 (Kernel Set). Let B be a theory, e be a clause, and σ be a
Skolemising substitution for e (wrt. B).
Then a Kernel Set of B and e (wrt. σ)
is a set K = {k1, . . . , kn} of ground clauses ki = Li
0 ∨Li
1 ∨. . . ∨Li
mi such that (i)
B ∧(L1
0 ∧. . . ∧Li
0 ∧. . . ∧Ln
0) |= eσ and (ii) B ∧(L1
1 ∨. . . ∨Li
j ∨. . . ∨Ln
mn) |= eσ, for
all 1 ≤i ≤n and 1 ≤j ≤mi.
Deﬁnition 6.2.3 (Kernel Set Subsumption - KSS). Let B be a theory, e be a clause,
σ be a Skolemising substitution for e (wrt. B), and let H be a theory that contains
no Skolem constants in σ. Then H is derivable by KSS from B and e iﬀthere exists
a Kernel Set K of B and e (wrt. σ) such that H ⪯K.
A important property of these deﬁnitions is proved in Theorem 6.2.4 below, which
shows the semantics of KSS is sound in the sense that every theory H derivable by
KSS from B and e logically entails e relative to B. At the same time, KSS is clearly
incomplete because, if B = ∅and e = n(s(s(0))) ∨¬n(0), then the two clauses
n(s(x))∨¬n(x) and n(s(s(x)))∨¬n(x) both entail e relative to B, but only the latter
is derivable by KSS from B and e.
Theorem 6.2.4 (Soundness of KSS). Let B and H be theories and let e be a clause.
If H is derivable by KSS from B and e, then B ∧H |= e.
Proof. Suppose H is derivable by KSS from B and e. Then, by Deﬁnitions 6.2.3
and 6.2.2, it follows H ⪯K for some theory K = {k1, . . . , kn} of ground clauses ki =
Li
0∨Li
1∨. . .∨Li
mi such that (i) B∧(L1
0∧. . .∧Ln
0) |= eσ, and (ii) B∧(L1
1∨. . .∨Ln
mn) |= eσ,
where σ is a Skolemising substitution for e wrt. B and H. Now, let M be any model
of B ∧H. Since H ⪯K it follows that H |= K and so M is also a model of K.
Therefore, M satisﬁes at least one literal from each clause in ki of K. Evidently, there
are exactly two cases: either M satisﬁes all of the key literals L1
0 . . . Ln
0 or M satisﬁes
at least one non-key literal Li
j. But, by (i) and (ii) above, in both cases M satisﬁes

6.2. KERNEL SET SUBSUMPTION (KSS) SEMANTICS
103
eσ. Consequently, B ∧H |= eσ. Since σ is an arbitrary ground instance of e whose
Skolem constants do not appear in B or H or e, it follows that B ∧H |= e.
Nevertheless, in spite of its incompleteness, KSS is considerably more powerful
than BG. As shown in Theorem 6.2.5 below, any hypothesis derivable by BG is also
derivable by KSS. However, many hypotheses are derivable by KSS that are not
derivable by BG. For instance, as noted in the previous section, if B = p(x, y) ∨
¬q(x) ∨¬q(y) and e = p(0, 1), then q(x) and q(0) ∧q(1) are derivable by KSS, but
not by BG. A less trivial example is given in Example 6.2.6 below.
Theorem 6.2.5 (KSS extends BG). Let B be a theory and e be a clause. If some
clause h is derivable by BG from B and e, then it follows that that theory H = {h}
is derivable by KSS from B and e.
Proof. Suppose a clause h = L0 ∨L1 ∨. . . ∨Ln is derivable by BG from B and e.
Then, by Deﬁnition 4.2.2, it follows h ⪯Bot(B, e), which means hθ ⊆Bot(B, e)
for some substitution θ. Thus, by Deﬁnition 4.2.1, it follows B ∧e |= ¬Liθ, for all
0 ≤i ≤n. But, this is equivalent to B ∧Liθ |= eσ, for all 0 ≤i ≤n, where σ is the
Skolemising substitution used in e. Consequently, it follows that (i) B ∧(L0) |= eσ,
and (ii) B ∧(L1 ∨. . . ∨Ln) |= eσ. Hence, the theory K = {hθ} is a Kernel Set of B
and e, by Deﬁnition 6.2.2. Also, H ⪯K since, by construction, Hθ = K. Therefore,
H is derivable by KSS from B and e, by Deﬁnition 6.2.3.
Example 6.2.6. Consider the theory B and clause e shown below (which are written
using a Prolog-like notation in which variables commence with uppercase letters).
The background theory B states that ‘any clause D is a tautology if contains some
particular proposition p and its negation neg(p)’. The seed example e states that
‘the Bottom Set, denoted bot(T, C), of a theory T and clause C is a tautology if T
entails C’. With respect to the Skolemising substitution σ, it is easily veriﬁed that the
theory K is a Kernel Set of B and e and that the theory H is derivable by KSS from
B and e. This hypothesis, which happens to be a true theorem about the semantics
of BG asserts that bot(T, C) contains all propositions and their negations if T entails

6.2. KERNEL SET SUBSUMPTION (KSS) SEMANTICS
104
C. But, since the actual Bottom Set of B and e is the clause eσ, the clause H is not
actually derivable by BG from B and e.
B
=
taut(D) ∨¬in(p, D) ∨¬in(neg(p), D)
e
=
taut(bot(T, C)) ∨¬entails(T, C)
σ
=
{T/t, C/c}
K
=



in(p, bot(t, c)) ∨¬entails(t, c)
in(neg(p), bot(t, c)) ∨¬entails(t, c)



H
=
in(L, bot(T, C)) ∨¬entails(T, C)
To better understand the class of hypotheses derivable by KSS, it is desirable
to obtain a proof theoretic characterisation similar to the well known C-derivation
characterisation of BG [99]. Since Kernel Sets can be seen as generalising Bottom
Sets from clauses to sets of clauses, this suggests attempting to lift the C-derivation
from one clause to several clauses. The result, which is formalised in Deﬁnition 6.2.7
below, is called a K-derivation.
Intuitively, a K-derivation of a clause D from a theory T is a derivation of D
from T ∧K that is simultaneously a Ci-derivation wrt. each clause Ci ∈K/T. In
the limiting case when K contains a single clause C, the K-derivation reduces to a
C-derivation.
(As explained in Section 2.3.4, if a clause Ci happens to appear in
both K and T, then Ci is treated just like any other clause in T and can generate
arbitrarily many input occurrences).
Deﬁnition 6.2.7 (K-derivation). Let D be a clause and let T and K be theories.
Then a K-derivation (of D) (from T) (wrt. K) is a derivation of D from T ∧K in
which each clause Ci ∈K/T is the generator of at most one (input) clause.
Although it can now be shown that if K is a Kernel Set of B and e then there is
a K-refutation of B ∧¬e, the converse direction does not always hold. For example,
if B = ∅and e = a and K = (a ∨¬b) ∧b, then there are two K-refutations of B ∪e
(as shown by the two K-derivations R1 and R2 below), but K is not a Kernel Set

6.2. KERNEL SET SUBSUMPTION (KSS) SEMANTICS
105
of B and e (since the negative literal ¬b, which must be a non-key literal, violates
condition (ii) in Deﬁnition 6.2.2).
a ∨¬b
b
a
¬a
□
a ∨¬b
¬a
¬b
b
□
K-derivation R1
K-derivation R2
But the desired equivalence can be obtained, at least for minimal theories K,
by imposing one further restriction on the K-derivation. The idea is to rule out K-
derivations like R1 and R2 where a key literal of one input clause generated by some
k ∈K/T interacts, directly or indirectly, with a non-key literal in another. As shown
in Deﬁnition 6.2.9 this restriction is formalised using the notion of dependency from
Section 2.3.3 and the terminology in Deﬁnition 6.2.8 below.
Deﬁnition 6.2.8 (K-input clause, K-descendant clause, K-clause). Let R be a K-
derivation of D from T wrt. K, and C be a clause in R. C is a K-input clause iﬀit
is generated by a clause in K/T. C is a K-descendant clause iﬀit is descended from
a K-input clause. C is a K-clause iﬀit is a K-input or K-descendant clause.
Deﬁnition 6.2.9 (K*-derivation). Let D be a clause and let T and K be disjoint
theories. Then a K*-derivation (of D) (from T) (wrt. K) is a K-derivation of D from
T in which two K-clauses only resolve together if neither contains any literal that is
dependent upon any non-key literal in any K-input clause.
Informally, a K*-derivation is a K-derivation in which the descendants of any
clauses in K are prohibited from resolving together until all of their non-key literals
have been completely ‘resolved away’. It should be noted that Deﬁnition 6.2.9 could
be generalised by taking into account the particular literals resolved upon in each
resolution step, but this would result in a more complex formulation than needed for
the purposes of this thesis.
As required, the K-derivations R1 and R2 depicted above are not K*-derivations.
Derivation R1 is not a K*-derivation because the two K-clauses a ∨¬b and b are

6.2. KERNEL SET SUBSUMPTION (KSS) SEMANTICS
106
resolved together, but the former contains a non-key literal ¬b. Derivation R2 is not
a K*-derivation because the two K-clauses ¬b and b are resolved together, but the
former contains a literal ¬b that is contributed by the non-key literal mentioned in
the previous sentence.
It follows immediately from the above deﬁnitions that the K*-derivation is both a
restriction of the K-derivation and a generalisation of the C-derivation. For, suppose
R is a C-derivation of D from T wrt. C. Then R is a K-derivation of D from T wrt.
K = {C} in which no K-clauses resolve together. Thus R is a K*-derivation of D
from T wrt. K = {C}. Conversely, suppose R is a K*-derivation of D from T wrt.
K. Then R is trivially a K-derivation of D from T wrt. K.
Before characterising Kernel Sets in terms of K*-derivations, Lemma 6.2.10 ﬁrst
shows how every literal L′ in some input clause of a derivation is abductively related to
the literals D′ in some descendant clause that are dependent upon L′. Lemma 6.2.11
then proves an important link between abduction and K*-derivations by showing that
each of the ground facts in a derivation need only in fact be used at most once, right
at the very end (a result that was ﬁrst reported in [74]).
Lemma 6.2.10. Let R be a derivation of a clause D from a theory T. If there is
a clause C in T such that D is descended from exactly one input occurrence C′ of
C, and if T ′ is the theory (T −{C}) obtained by removing C from T, and if D′ is
the (possibly empty) sub-clause of D whose literals are dependent upon some selected
literal L′ of C′, then T ′ ∪{L′} |= D′.
Proof. By induction on the number of steps n in the refutation R:
1. First, suppose n = 0. Then R = ⟨D⟩where D = C′ = Cρ for some renaming
substitution ρ. Since L′ is the only literal in C′ dependent upon itself, it follows
that D′ = L′. Thus T ′∪{L′} |= D′ for any theory T ′ and the lemma holds trivially
when n = 0.
2. Next, suppose n > 0 and assume the lemma holds for all refutations with fewer
than n steps. Then D must be the resolvent of two clauses E and F using some

6.2. KERNEL SET SUBSUMPTION (KSS) SEMANTICS
107
mgu θ.
By considering the sub-derivations of each parent, it follows (i) there
is a derivation R′ of E from T in which E is descended from the one and only
input occurrence C′ of C; and (ii) there is a derivation R′′ of F from T −{C}.
Then, let E′ be the (non-empty) sub-clause of E whose literals are dependent
upon the selected literal L′ of C′. By the induction hypothesis it holds that (a)
T ′ ∪{L′} |= E′ and by the soundness of resolution it holds that (b) T |= F. Now,
there are exactly two possibilities: either none of the literals resolved upon in E is
dependent on L′, or at least one of them is. If none of the literals resolved upon
in E are dependent on L′, then E′ |= D′ since it is easily shown that E′θ = D′.
Consequently, T ′ ∪{L′} |= D′, using (a) above. If one of the literals resolved upon
in E is dependent on L′ then {E′, F} |= D′ since it is easily shown that D′ is an
instance of a resolvent of E′ and F. Consequently, T ′ ∪{L′} |= D′, using the two
facts (a) and (b) above.
Lemma 6.2.11. Let T be a theory and ∆be a ground unit theory ∆= L1 ∧. . . ∧Ln.
Then T ∧∆|= □iﬀthere is a K*-refutation of T wrt. ∆.
Proof. Taking the ‘if’ and ‘only if’ directions in turn:
1. First, suppose there is a K*-refutation of T wrt. ∆. Then by the soundness of
resolution it follows that T ∧∆|= □(even if only a subset ∆′ of ∆is used in the
computation).
2. Conversely, suppose T ∧∆|= □. By contraposition T |= ∆, where ∆= L1∨. . .∨Ln
is the ground clause containing the complement of each literal in ∆. Now, there are
exactly two possibilities: either ∆is a tautology or it is not. If ∆is a tautology then
∆must contain two complementary literals Li and Lj. In this case, the refutation
R = ⟨Li, Lj, □⟩is clearly a K-refutation of T wrt. ∆by Deﬁnition 6.2.7. Moreover,
as there are no non-key atoms in any of the (unit) clauses in ∆, it trivially follows
by Deﬁnition 6.2.9 that R is a K*-refutation of T wrt. ∆. If ∆is not a tautology
then, by the Subsumption Theorem, there is a derivation R′ of a clause C from

6.2. KERNEL SET SUBSUMPTION (KSS) SEMANTICS
108
the theory T such that Cθ ⊆∆for some substitution θ. Now, deﬁne the ground
unit theory ∆′ = {Lk1, . . . , Lkp} ⊆∆such that ∆′ = Cθ ∩∆. (Note that ∆′
contains the literals in ∆whose complements appear in Cθ.) Next, deﬁne the
unique refutation R′′ = ⟨C =C1, Lk1, . . . , Ci, Lki, . . . , Cp, Lkp, Cp+1 =□⟩such that
for all 1 < i ≤p, clause Ci+1 is the resolvent of Ci and Lki — obtained by resolving
Ci on each literal M such that Mθ = Lki. (Note that the resolved literals in Ci are
those literals that are complementary to Lki under θ.) In this case, the refutation
R obtained by joining R′ and R′′ is clearly a K-refutation of T wrt. ∆and, once
again, R is trivially a K*-refutation of T wrt. ∆.
Lemmas 6.2.10 and 6.2.11 are now utilised in Theorem 6.2.12 to show that a
(minimal) theory K is a Kernel Set of B and e iﬀthere is a K*-refutation from B ∪e
with respect to K. As shown in the two ﬁgures (a) and (b) below, the ‘only if’ direction
constructs a canonical K*-derivation from a given Kernel set K. Conversely, the ‘if’
direction shows that given the minimality of K, the existence of a K*-derivation can
be used to establish the required Kernel Set properties.
Theorem 6.2.12. Let B be a theory, e be a clause, and K be a ground theory such
that B ∧K |= eσ and B ∧K′ ̸|= eσ for all K′ ⊂K. Then a set K = {k1, . . . , kn}
of non-empty ground clauses ki = Li
0 ∨Li
1 ∨. . . ∨Li
mi is a Kernel Set of B and e iﬀ
there is a K*-refutation of B ∪e wrt. K, where e is the complement of e wrt. σ.
Proof. For convenience, let ∆= {L1
0 ∧. . . ∧Ln
0} be the theory obtained by conjoining
the key literals from each clause in K; and let Γi
j = Li
j be the complement of the
non-key literal Li
j. Then, recalling e ≡¬eσ, take the ‘only if’ and ‘if’ cases in turn:
1. Suppose K is a Kernel Set of B and e. From Deﬁnition 6.2.2 it holds that (i)
B ∧∆|= eσ and (ii) B ∧Li
j |= eσ, for all 1 ≤i ≤n and 1 ≤j ≤mi. From
(i) it follows that B ∧¬eσ ∧∆|= □and so, by Lemma 6.2.11, there is a K*-
refutation R0 of B ∧¬eσ wrt. ∆, as shown in the ﬁgure (a). From (ii) it follows
that B ∧¬eσ |= Γi
j and so, by the Subsumption Theorem, there is a derivation Ri
j

6.2. KERNEL SET SUBSUMPTION (KSS) SEMANTICS
109
B ∪e
□
L1
0
Ln
0
Li
0
Li
0 ∨Li
mi
Li
0 ∨Li
2 ∨. . . ∨Li
mi
Li
0 ∨Li
1 ∨. . . ∨Li
mi
M i
mi
B ∪e
M i
1
B ∪e
(a) Refutation R0
(b) Derivation Ri
of some clause Mi
j from the theory B ∧¬eσ such that Mi
j ⪯Γi
j. Thus, for each
clause ki = Li
0 ∨Li
1 ∨. . .∨Li
mi there is a derivation Ri of Li
0 from B ∧¬eσ wrt. the
clause ki obtained by successively resolving away each non key literal Li
j with the
complementary subsuming clause Mi
j, as shown in the ﬁgure (b). Consequently,
it follows that the refutation R obtained from R0 by replacing the (one and only)
input occurrence Li
0 by the derivation Ri, in which there is exactly one input
occurrence of ki, is a K-refutation of B ∧¬eσ wrt. K. Finally, since all of the
non-key literals in K are resolved away by clauses derived from B ∪e, it follows
that R is also a K*-refutation of B ∪e wrt. K.
2. Suppose there is a K*-refutation R of B ∪e. First, note that B ∧¬eσ ∧K |= □by
the soundness of resolution. But, since ∆|= K, it follows B ∧¬eσ ∧∆|= □and so
B∧∆|= eσ. Therefore the key literals of K satisfy condition (i) of Deﬁnition 6.2.2.
Next, note that the minimality condition on K ensures each clause ki in K has
exactly one input occurrence in R. Now, there are exactly two possibilities: either
there is just one clause in K or else there are more than one. If there is just one
clause k in K, then the empty clause, at the root of the derivation, is descended
from exactly one input occurrence of k. Moreover, for each literal L in k, the empty
clause clearly has no literals that are dependent upon L, and so B ∧¬eσ ∧L |= □

6.3. HAIL PROOF PROCEDURE
110
trivially follows from Lemma 6.2.10. Hence, in this case the non-key literals satisfy
condition (ii) of Deﬁnition 6.2.2. If there is more than one clause in K, then, for
each such clause ki, there are exactly two possibilities: either ki resolves with a
K-clause or else it does not. If ki resolves with a K-clause, then it trivially follows
from Deﬁnition 6.2.9 that ki has no non-key literals. If ki does not resolve with
a K-clause then (at least) one descendant of ki must resolve with a K-clause. Let
Ci be the ﬁrst descendant of ki that resolves with a K-clause and consider the
sub-derivation Ri of Ci from B ∧¬eσ ∧ki. Let Li
j be any non-key literal in ki.
From Deﬁnition 6.2.9 it follows that Ci has no literals that are dependent upon Li
j
Moreover, since Ci is descended from exactly one input occurrence of ki it follows
from Lemma 6.2.10 that B ∧¬eσ |= Li
j. Therefore the non-key literals of K satisfy
condition (ii) of Deﬁnition 6.2.2.
6.3
HAIL Proof Procedure
This section introduces the HAIL proof procedure, which applies the semantics of
KSS in a mode-directed cover-set fashion for computing highly compressive inductive
generalisations. This is achieved by integrating the KM proof procedure (Section 3.3)
within a generalisation of Progol5 (Section 4.3) in order to implement the three-phase
learning cycle described above (Section 6.1).
Section 6.3.1 introduces the HAIL computation as an abstract formalisation of
the HAIL learning cycle. Section 6.3.2 describes the HAIL proof procedure, which is
a concrete realisation of that learning cycle. Section 6.3.3 formalises the contextual
transform: a key component of the HAIL algorithm that facilitates the integration of
the abductive and inductive components.
6.3.1
HAIL computations
The HAIL approach is formally based on the notion of a HAIL computation, which
reﬁnes the generic learning cycle shown in Fig. 6.1 above. As formalised in Deﬁnition

6.3. HAIL PROOF PROCEDURE
111
6.3.1 below, a HAIL computation is a sequence of quintuples ⟨ei, σi, ∆i, Ki, Hi⟩, each
of which represents one application of KSS and corresponds to one iteration of the
learning cycle. Each tuple consists of a seed example ei, the Skolemising substitution
σi applied to that example, as well as the abductive explanation ∆i, the Kernel Set
Ki, and the hypothesis Hi produced on the i-th iteration of the cycle.
For convenience, the abbreviation Bi is used to denote the cumulative background
theory B∪H1∪· · ·∪Hi−1 at the start of the i-th iteration (i.e. the original background
theory plus any previously induced hypotheses), and the abbreviation E+
i is used to
denote the positive examples {e ∈E+ | Bi ̸|= e} remaining at the start of the i-th
iteration (i.e. those positive examples not covered by the current background theory).
Note that, before the start of the ﬁrst iteration, B1 = B and E+
1 = E+, and, after
the end of the last iteration, Bm+1 = B ∪H and E+
m+1 = ∅.
Deﬁnition 6.3.1 (HAIL computation). Let X = ⟨B, E+, E−, M⟩be an inductive
context and H = H1 ∪· · · ∪Hm be a Horn theory. Let Bi = B ∪H1 ∪· · · ∪Hi−1
and E+
i = {e ∈E+ | Bi ̸|= e} for all 1 ≤i ≤m + 1. Let GM denote the set of all
clauses that are ground instances of some clause in the language LM of M. Then a
HAIL computation of H from X is a sequence of ﬁve-tuples (⟨e1, σ1, ∆1, K1, H1⟩, . . . ,
⟨em, σm, ∆m, Km, Hm⟩) such that E+
m+1 = ∅and for all 1 ≤i ≤m the following ﬁve
conditions are satisﬁed:
(i) ei is a Horn clause a ←b1, . . . , br ∈E+
i
(ii) σi is a Skolemising substitution for ei wrt. Bi
(iii) ∆i is positive ground unit theory {α1, . . . , αn} ⊆GM
such that Bi ∧∆i |= eiσi and Bi ∪∆i ∪E+
i ∪E−̸|= □
(iv) Ki is a ground Horn theory Sn
k=1{αk ←δk
1, . . . , δk
mk} ⊆GM
such that Bi ∧¬eiσi |= δk
j and Bi ∪Ki ∪E+
i ∪E−̸|= □
(v) Hi is a Horn theory {h1, . . . , hn′} ⊆LM
such that Hi ⪯Ki and Bi ∪Hi ∪E+
i ∪E−̸|= □

6.3. HAIL PROOF PROCEDURE
112
Each tuple ⟨ei, σi, ∆i, Ki, Hi⟩in a HAIL computation must satisfy ﬁve conditions
stated in Deﬁnition 6.3.1 above: (i) the seed example ei must be selected from E+
i ; (ii)
the substitution σi must be a Skolemising substitution for ei with respect to Bi; (iii)
the abductive explanation ∆i must entail the Skolemised seed example eiσi relative
to Bi; (iv) the Kernel Set Ki is formed by adding a set of body atoms to the head
atoms in ∆i, each of which is entailed by Bi and the complement of eiσi; and (v) the
hypothesis Hi subsumes Ki.
To ensure the computed hypothesis H = H1 ∪· · · ∪Hm is consistent with the
initial background theory and satisﬁes the required language bias, conditions (iii),
(iv) and (v) include appropriate syntactic and consistency constraints. In particular,
each theory Hi must be consistent with the positive and negative examples E+ and
E−and the cumulative background theory Bi, and it must fall within the hypothesis
space LM speciﬁed by the mode declarations M. In turn, these requirements dictate
the corresponding syntactic constraints on Ki and ∆i.
Importantly, as shown in Theorem 6.3.2 below, the individual hypotheses Hi
in a HAIL computation are sound with respect to the semantics of KSS; and the
computed hypothesis H = H1∪· · ·∪Hm is sound with respect to the task of inductive
generalisation. In particular, each Hi is derivable by KSS from Bi and ei; and H is an
inductive generalisation of the original context X. The two parts of the theorem are
proved by showing how Deﬁnition 6.3.1 ensures the satisfaction of Deﬁnitions 6.2.2
and 4.1.2, respectively.
Theorem 6.3.2 (Soundness of HAIL Computations). Let X = ⟨B, E+, E−, M⟩be
an inductive context and (⟨e1, σ1, ∆1, K1, H1⟩, . . . , ⟨em, σm, ∆m, Km, Hm⟩) be a HAIL
computation of H = H1 ∪· · · ∪Hm from X. Let Bi = B ∪H1 ∪· · · ∪Hi−1 and
E+
i = {e ∈E+ | Bi ̸|= e}. Then (1) Hi is derivable by KSS from Bi and ei for all
1 ≤i ≤m; and (2) H is an inductive generalisation of X.
Proof. Taking each part in turn:
1. By Deﬁnition 6.3.1 it holds that (iii) Bi ∧∆i |= eiσi and (iv) Bi ∧¬eiσi |= δk
j
for all 1 ≤k ≤n and 1 ≤j ≤mk — where ei = a ←b1, . . . , br and ∆i =

6.3. HAIL PROOF PROCEDURE
113
{α1, . . . , αn}. From (iii) it follows Bi ∧(α1 ∧. . . ∧αn) |= eiσi. From (iv) it follows
Bi ∧(¬δ1
1 ∨. . . ∨¬δn
nn) |= eiσi.
Thus, letting Lk
0 = αk and Lk
j = ¬δk
j for all
1 ≤k ≤n and 1 ≤j ≤mk, it follows from Deﬁnition 6.2.2 that K is a Kernel set
of Bi and ei. By Deﬁnition 6.3.1 it also holds that (v) Hi ⪯Ki. Hence, it follows
from Deﬁnition 6.2.3 that Hi is derivable by KSS Bi and ei.
2. By Deﬁnition 4.1.2 it suﬃces to show that (i) H ⊆LM, (ii) B ∪H |= E+, and
(iii) B ∪H ∪E−̸|= □. The ﬁrst point follows from Deﬁnition 6.3.1 using the facts
that H = H1 ∪· · · ∪Hm and Hi ⊆LM for all 1 ≤i ≤m. The second point follows
from Deﬁnition 6.3.1 using the facts that Bm+1 = B ∪H and E+
m+1 = {e ∈E+ |
Bm+1 ̸|= e} = ∅. The third point follows from Deﬁnition 6.3.1 using the facts that
Bm ∪Hm = B ∪H and Bm ∪Hm ∪E+
m ∪E−̸|= □.
Conversely, as shown in Lemma 6.3.3 below, HAIL computations are trivially
complete with respect to the computation of inductive generalisations that can be
incrementally constructed using the semantics of KSS (assuming, as usual, that key
literals are head atoms).
Lemma 6.3.3 (Completeness of HAIL Computations). Let X =⟨B, E+, E−, M⟩be an
inductive context and H = H1∪· · ·∪Hm be an inductive generalisation of X such that,
for all 1 ≤i ≤m, each Hi is derivable by KSS from the theory Bi = B∪H1∪· · ·∪Hi−1
and a clause ei ∈E+ such that Bi ̸|= ei. Then there is a HAIL computation of H
from X.
Proof. For all 1 ≤i ≤m, it follows from Deﬁnitions 6.2.3 and 6.2.2 there exists a
subsuming substitution θi and a Skolemising substitution σi such that the theory
Ki = Hiθi is a Kernel Set of Bi and ei wrt. σi. From Deﬁnition 4.1.2 it follows that
Hi ⊆LM and so Ki ⊆GM. If ∆i denotes the set of head atoms contained in Ki, then
it can be veriﬁed that (⟨e1, σ1, ∆1, K1, H1⟩, . . . , ⟨em, σm, ∆m, Km, Hm⟩) satisﬁes all
of the conditions in Deﬁnition 6.3.1. Consequently, there exists a HAIL computation
of H from X.

6.3. HAIL PROOF PROCEDURE
114
6.3.2
HAIL Implementation
HAIL computations formalise the iterative application of KSS within the learning
cycle of Fig. 6.1 above. Procedurally, this process can be understood in terms of the
Prolog speciﬁcation in Fig. 6.2, below, which shows the outer covering loop and three
inner generalisation procedures. The main purpose of Fig. 6.2 is to convey the key
dependencies between the individual components. For this reason, the background
theory is shown as a parameter and not — as in the actual implementation — part
of the clause base.
The inputs to HAIL (line 2) comprise the background theory (BkGnd), positive and
negative examples (PosExs,NegExs), mode declarations (ModeDecs), and the output
is a hypothesis (Hyps) — all represented by lists of clauses, with negative clauses
treated as deﬁnite clauses with the atom false in their head. The generalisation
loop, which coordinates the computation of candidate hypotheses, is driven by the
findall construct (line 5). The covering loop, which performs the selection and
removal of examples, etc., is driven by a recursive call hail(...) (line 13).
In the base case (i.e. line 1), there are no remaining positive examples and thus
an empty hypothesis is returned.
In the general case (i.e.
lines 2-14), at least
one uncovered seed example (E) may be selected and hence at least one non-empty
hypothesis (Hyp) is returned. First, a Skolemising substitution (S) is obtained for the
seed example. Then, the collection of theories (Hs) is constructed of all hypotheses
(H) that can be obtained by applying the generalisation routines abduce, deduce and
induce — which are described in more detail below.
A maximally compressive hypothesis (Hyp) is then selected from Hs. In the usual
cover-set fashion, this hypothesis is asserted into BkGnd to give an augmented back-
ground theory (NewBkGnd). Any newly covered examples (including SeedEx) are then
removed from PosExs to give a diminished set of positive examples (NewPosEx). The
whole procedure is then recursively called to compute a hypothesis (NewHyps) for
the inductive context comprising the new background theory and positive examples.
Finally, the theory Hyp is added to NewHyps to give the overall hypothesis (Hyps).

6.3. HAIL PROOF PROCEDURE
115
1.
hail( ,[], , ,[]).
2.
hail(BkGnd,PosExs,NegExs,ModeDecs,Hyps):-
3.
selectSeed(PosExs,E),
4.
skolemise(E,BkGnd,S),
5.
findall(H,(
6.
abduce(E,S,BkGnd,PosExs,NegExs,ModeDecs,D),
7.
deduce(D,E,S,BkGnd,ModeDecs,K),
8.
induce(K,BkGnd,PosExs,NegExs,ModeDecs,H)
9.
),Hs),
10.
selectHypothesis(Hs,BkGnd,PosExs,Hyp),
11.
assertHypothesis(Hyp,BkGnd,NewBkGnd),
12.
removeCover(PosExs,NewBkGnd,NewPosExs),
13.
hail(NewBkGnd,NewPosExs,NegExs,ModeDecs,NewHyps),
14.
assertHypothesis(Hyp,NewHyps,Hyps).
Figure 6.2: Prolog Description of HAIL Learning Cycle
1.
HAIL(BkGnd,PosExs,NegExs,ModeDecs)
2.
while PosExs is not empty {
3.
let E be any clause in PosExs
4.
let S be a Skolemising substitution for E wrt. BkGnd
5-6.
for all Di ∈abduce(E, S, BkGnd, PosExs, NegExs, ModeDecs) {
7.
let Ki = deduce(Di, E, S, BkGnd, ModeDecs)
8.
let Hi = induce(Ki, BkGnd, PosExs, NegExs, ModeDecs)
9.
}
10.
let Hyp be any maximally compressive theory Hi
11.
add to BkGnd all of the clauses contained in Hyp
12.
remove from PosExs any clauses covered by BkGnd
13.
}
14.
return the theory Hyps containing all the clauses added to BkGnd
Figure 6.3: Pseudocode Description of HAIL Learning Cycle

6.3. HAIL PROOF PROCEDURE
116
As expected, the four procedures used in the covering loop are trivial: selectSeed
(line 3) returns the ﬁrst clause E in the list of examples PosExs; skolemise (line 4)
returns a Skolemising substitution S for E wrt. BkGnd; select hypothesis (line 10)
returns the ﬁrst theory Hyp in the list of hypotheses Hs that is maximally compressive
wrt. BkGnd and PosExs; assertHypothsis (lines 11,14) concatenates the ﬁrst two lists
to return the third; and removerCover (line 12) returns as NewPosExs those clauses
in PosExs not entailed by the clauses in NewBkGnd.3
Before focussing on the generalisation routines abduce, deduce and induce below,
the reader may care to examine the equivalent pseudo code description in Fig. 6.3,
which provides (as far as possible) a line-for-line translation of the Prolog description
in Fig. 6.2. Even though the pseudocode is less formal, it does have the advantage
of better illustrating which of the declarative procedure calls are deterministic and
which are not; and it serves to clarify which of the parameters are input variables
and which of them are output variables.
The abduce procedure
is responsible for computing a positive unit Kernel Set D
of the theory BkGnd and example E. As shown in Fig. 6.4, the main work is done by
the call to km, which denotes an eﬃcient implementation of the KM procedure (code
not given) for computing abductive explanations of the context ⟨T, G, IC, A⟩, obtained
from the original inductive context by applying the helper routines normalise and
transform. First, normalise takes the example E, theory BkGnd, and substitution S,
and it returns as NewE the Skolemised head atoms of E (i.e. a list with one ground
atom), and as NewBkGnd the theory BkGnd augmented with the Skolemised body
atoms of E. Then, as formalised in the next section, transform encodes the head
declarations into an abductive context whose explanations are unit Kernel Sets that
fall within the given language bias. Finally, consistent ensures that any abducibles
are consistent with the theory and all of the examples.
3In fact, selectHypothesis and removerCover have very little work to do as the coverage and
compressivity of each hypothesis H, which is computed by the induce procedure described below, is
simply stored in a data structure associated with Hs.

6.3. HAIL PROOF PROCEDURE
117
1.
abduce(E,S,BkGnd,PosExs,NegExs,ModeDecs,D):-
2.
normalise((E,S,BkGnd),(NewE,NewBkGnd)),
3.
transform((NewE,NewBkGnd,NegExs,ModeDecs),(T,G,IC,A)),
4.
call(km(T,G,IC,A,D)),
5.
consistent(D,BkGnd,PosExs,NegExs).
Figure 6.4: Prolog Description of HAIL Abductive Phase
1.
deduce([], , , , ,[]).
2.
deduce([A|As],E,S,BkGnd,ModeDecs,[K|Ks]):-
3.
normalise((E,S,BkGnd),( ,NewBkGnd)),
4.
call(bs(A,NewBkGnd,ModeDecs,K)),
5.
deduce(As,E,S,BkGnd,ModeDecs,Ks).
Figure 6.5: Prolog Description of HAIL Deductive Phase
1.
induce([], , , , ,[]).
2.
induce([K|Ks],BkGnd,PosExs,NegExs,ModeDecs,[H|Hs]):-
3.
call(ls(K,Ks,BkGnd,PosExs,NegExs,ModeDecs,H)),
4.
assertHypothesis(H,BkGnd,NewBkGnd)),
5.
removeCover(PosExs,NewBkGnd,NewPosExs),
6.
induce(Ks,NewBkGnd,NewPosExs,NegExs,ModeDecs,Hs).
Figure 6.6: Prolog Description of HAIL Inductive Phase

6.3. HAIL PROOF PROCEDURE
118
The deduce procedure
is responsible for computing maximally speciﬁc Kernel
Set K with head atoms from D that conforms to the speciﬁed language bias.
As
shown in Fig. 6.5, the main work is performed by the call to bs (code not given),
which is the Progol5 BottomSet procedure, modiﬁed in one minor respect. Namely,
the type-checking mechanism of bs is free to use any type atoms in ∆that were
hypothesised in the abductive phase. After normalising the background theory and
seed example (by means of the same procedure used in the abductive phase), this
modiﬁed BottomSet procedure is applied in turn to each abduced atom A to produce
a Kernel Set clause K. Of course, in the actual implementation, normalisation is only
be performed once; outside the generalisation loop. Though not explicitly stated, like
the Progol5 BottomSet, bs does not strictly return a ground theory, but conservatively
replaces all input and output terms by variables.
The induce procedure
computes a maximally compressive consistent hypothesis
H that subsumes K. As shown in Fig. 6.5, the main work is performed by the call to
ls (code not given), which is the Progol5 LatticeSearch procedure, modiﬁed in one
small way. Namely, the consistency-checking mechanism of ls must not only take into
account the theory BkGnd and examples PosExs and NegExs, but it must also ensure
consistency with respect to those hypotheses arising from any previously generalised
Kernel clauses, as well as those Kernel clauses are still waiting to be generalised.
This modiﬁed LatticeSearch procedure is applied in turn to each Kernel clause K
to produce one clause H in the overall hypothesis. This hypothesis is added to the
background knowledge, before generalising the next Kernel clause. In the present
implementation, positive examples are removed as soon as they are covered.
Example 6.3.4. Let BkGnd, PosExs, NegExs and ModeDecs denote the following
inductive context (adapted from Example 4.1.7). The earlier fact burger(mcDonalds)
has been removed, and a new head declaration modeh(∗, bistro(#any)) has been
added, thereby allowing hypotheses to contain ground atoms of the form bistro(t).

6.3. HAIL PROOF PROCEDURE
119
BkGnd
=























meal(x) ←fries(x), burger(x)
burger(x) ←fries(x), offer(x)
offer(mcDonalds)
offer(burgerKing)
burger(theRitz)























PosExs
=



meal(mcDonalds)
meal(burgerKing)



NegExs
=



←meal(theRitz)
←burger(x), vegan(x)



ModeDecs
=











modeh(∗, fries(+bistro))
modeb(∗, offer(+bistro))
modeh(∗, bistro(#any))











Now suppose that selectSeed assigns E to be the seed example meal(mcDonalds).
Because this is already a ground atom, skolemise returns an empty substitution S
(and normalise trivially returns NewE=E and NewBkGnd=BkGnd, respectively).
As
explained in the next section, after forming the contextual transformation of this
inductive context, the abduce procedure returns the abductive explanation D shown
below. Analogously to the previous chapter, deduce and induce return the following
Kernel Set K and hypothesis H.
D
=



fries(mcDonalds)
bistro(mcDonalds)



K
=



fries(mcDonalds) ←offer(mcDonalds)
bistro(mcDonalds)



H
=



fries(x) ←offer(x)
bistro(mcDonalds)




6.3. HAIL PROOF PROCEDURE
120
It is interesting to note that, given exactly these inputs, CProgol5.0 is unable to
compute any hypothesis at all, even though H it is a valid inductive generalisation.
There are two separate reasons for this failure, both of which are caused by the
inability of StartSet to compute the positive Bottom Set literal fries(mcDonalds).
In the ﬁrst place, StartSet cannot derive the type atom bistro(mcDonalds) that is
needed in order for StartSet’s typing mechanism to succeed. More seriously, however,
even if the type atom bistro(mcDonalds) were to be added to the background theory,
the reader can verify that Progol5 is still unable to return a solution. This time, the
failure is due to the incompleteness of StartSet noted in the previous chapter, which
prevents StartSet from computing the atom fries(mcDonalds) even though it is in
the Bottom Set of B and e.
6.3.3
Contextual Transform
In order to usefully integrate the abductive and inductive components of the HAIL
approach, an important problem must ﬁrst be addressed. Speciﬁcally, how can the
abductive procedure be incorporated within the inductive learning cycle in a way that
makes eﬀective use of language bias? Because abduced atoms will become the head
atoms of some Kernel Set, every abductive explanation must at least be a grounding of
the head declarations. Unfortunately, the standard abductive mechanism of language
bias, by which certain predicates can be declared abducible, aﬀords less control of the
hypothesis space than the inductive mechanism of mode declarations. Thus, to avoid
ineﬃciently generating and discarding hypotheses, the abductive procedure must be
made to return only abducibles that fall within the speciﬁed language bias.
The solution used in HAIL is to syntactically encode the inductive language bias
as abductive integrity constraints. As well as eliminating redundant solutions, this
explicit encoding of language bias also means that integrity handling mechanisms can
be used to infer missing type atoms. In particular, when the ALP procedure tries to
abduce an atom, the constraints are ﬁred to ensure the atom falls within the language
bias. If integrity is violated, then either the abducible will be rejected (as in most

6.3. HAIL PROOF PROCEDURE
121
other approaches), or else additional assumptions — such as missing type atoms —
will be investigated (in contrast to most other approaches).
The encoding that produces this behaviour is called a contextual transform as it
maps an inductive context X into an abductive context Y . As formalised in Deﬁni-
tions 6.3.5 and 6.3.6 below, the mapping is a syntactic process with four aims: ﬁrst,
it apportions the clauses in B, E+ and E−among T, G and IC; then, it identiﬁes the
abducibles A and adds appropriate clauses to T and IC to reﬂect the bias speciﬁed in
M+; next, it ensures no abducibles are deﬁned in T (using the well-known technique
described in Footnote 1 of Chapter 3); ﬁnally, it tries to ensure that all constraints
have an abducible — so they can be eﬃciently handled by the KM procedure
Since the interaction of these four tasks is responsible for the apparent complexity
of the formal deﬁnitions below, it is simpler to ﬁrst explain the intuition of each one
separately and then to formally prove the correctness of their combination. But ﬁrst,
it is remarked that the transformation is based on the introduction of fresh predicates,
p† and p‡, for each predicate p in the language L. Intuitively p† is a new predicate that
represents the ‘well-typedness’ of the associated predicate p; while p‡ is eﬀectively a
synonym for p. The latter is used to rename any abducibles deﬁned in T, and the
former is used to encode the type information in M, as explained below.
Regarding the encoding of language bias, the idea is that each head declaration
m with schema p(t1, . . . , tn), type atoms p1(x1), . . . , pk(xk), and predicate p/n gives
rise to one integrity constraint of the form ←p(x1, . . . , xn), ¬p†(x1, . . . , xn), and one
clause of the form p†(t1, . . . , tn) ←p1(x1), . . . , pk(xk). Informally, the rule states that
‘a ground instance of p is well-typed if it uniﬁes with the schema of m and all terms
are of the correct type’. Conversely, the constraint states that ‘one should not be
able to derive any ground instance of p that is not well-typed’.
As the transform must return an abductive context whose explanations conform
to the bias M, the abducibles A are clearly those predicates appearing in the schema
of a head declaration. But, to ensure no abducibles are deﬁned in T (as required by
the KM procedure), the transform replaces each deﬁned abducible p in B, E+ and

6.3. HAIL PROOF PROCEDURE
122
E−by the non-abducible p‡ and adds the clause p‡(x1, . . . , xn) ←p(x1, . . . , xn) to
T. It also adds the deﬁnite clauses in B to T and the ground atoms in E+ to G.
As an optional extra, the transform can try to unfold any constraints in E−and B
so as to introduce abducibles which can be used by the KM procedure to eﬃciently
process the constraints too. (Alternatively, these constraints can simply be checked
at the end of each computation, as in other systems like Progol5.)
Deﬁnition 6.3.5 (Extended Language). Fix a ﬁrst-order language L. Let L′ be the
language obtained by extending L with a set of fresh predicates so that each predicate
p in L is uniquely associated with two new predicates, denoted p† and p‡, of the same
arity as p. For each atom a = p(t1, . . . , tn) in L, let a† and a‡ denote the atoms
p†(t1, . . . , tn) and p‡(t1, . . . , tn) in L′, respectively. For each set D of predicates in L,
let a‡D denote the atom a‡, if p ∈D; and denote a otherwise.
Deﬁnition 6.3.6 (Contextual Transform). Let X = ⟨B, E+, E−, M⟩be an inductive
context in which E+ is a set of ground atoms, and let N be a positive integer. Then
the contextual transform of X is the abductive context Y = ⟨T, G, IC, A⟩deﬁned as
follows:
• Let A be the set of predicates p/n appearing in some head declaration m ∈M+.
• Let D be the set of predicates p/n ∈A in the head of some rule C ∈B.
• Let G = {a‡D | a ∈E+}.
• Let T = TB ∪TA ∪TM ∪{any(x)} where
TB
=

a‡D
0
←a‡D
1 , . . . , a‡D
n
| a0 ←a1, . . . , an ∈B

TA
=

p‡(x1, . . . , xn) ←p(x1, . . . , xn) | p/n ∈D

TM
=





a†
0 ←a‡D
1 , . . . , a‡D
n
a0 =schema(m) and {a1, . . . , an}=type(m)
for some head declaration m ∈M+






6.3. HAIL PROOF PROCEDURE
123
• Let IC0 = ICB ∪ICE ∪ICM where
ICB
=

←a‡D
1 , . . . , a‡D
n
| ←a1, . . . , an ∈B ∪E−

ICE
=

←¬a‡D
0 , a‡D
1 , . . . , a‡D
n
| a0 ←a1, . . . , an ∈E−

ICM
=

←p(x1, . . . , xn), ¬p†(x1, . . . , xn) | p/n ∈D

• For all 1 ≤n ≤N, let ICn denote the result of (optionally) replacing zero or
more goals G in ICn−1 by the set of resolvents of G and the clauses in T on
some (selected) non-abducible positive literal in G.
• Let IC be the subset of the goals ICN that contain an abducible predicate.
Example 6.3.7. Let X = ⟨BkGnd, E, NegExs, ModeDecs⟩be the inductive context
from Example 6.3.4 above, where E = meal(mcDonalds) is the seed example selected
earlier. Then the contextual transform of X is the abductive context X = ⟨T, G, IC, A⟩
shown below.
T
=











































meal(x) ←fries(x), burger(x)
burger(x) ←fries(x), offer(x)
offer(mcDonalds)
offer(burgerKing)
burger(theRitz)
fries†(x) ←bistro(x)
bistro†(x) ←any(x)
any(x)











































G
=
n
meal(mcDonalds)
o
IC
=











←fries(theRitz), burger(theRitz)
←fries(x), ¬fries†(x)
←bistro(x), ¬bistro†(x)











A
=
n
fries/1, bistro/1
o

6.3. HAIL PROOF PROCEDURE
124
Since no abducibles are deﬁned, D = ∅and T is the union of B and the typing
clauses for the head declarations M+ and the atom any(x). IC contains the type
constraints from M+ and E−. Since the negative example ←meal(theRitz) contains
no abducibles, it is unfolded in one step to ←fries(theRitz), burger(theRitz), shown
above. Similarly, by resolving on its second atom, ←burger(x), vegan(x) is unfolded
to the empty set — indicating that it can never be violated. (As vegan is neither
abducible nor mentioned in the head of any rule.) More importantly, as mentioned in
Example 6.3.4 above, applying the KM proof procedure to the resulting context yields
the explanation D = {fries(mcDonalds),bistro(mcDonalds)}, which, as expected,
satisﬁes the required language bias.
?+ meal(md)
?+ fries(md), burger(md)
fries(md)
?−not(fries†(md))
?+ fries†(md)
?+ bistro(md)
bistro(md)
?−not(bistro†(md))
?+ bistro†(md)
?+ any(md)
?+ □
?−■
?+ □
?−■
?
burger(md)
?
fries(md), offer(md)
?
offer(md)
?
□
The use of the contextual transform is shown in Lemma 6.3.8 and Corollary 6.3.9
below.
It should be noted that the inductive contexts in these results might not
include all positive examples. In fact, for the implementation in Figs. 6.2 and 6.3,
the theory E+ mentioned below will only contain the Skolemised head of the seed
example. By contrast, the theory B will be the background knowledge augmented
with the Skolemised body atoms of the seed example.

6.3. HAIL PROOF PROCEDURE
125
The reason E+ has not been restricted to a single atom in the results below is
that, if some subset of the positive examples contains only ground atoms, these could
all be passed in one go to contextual transform.
In principle, this could lead to
faster learning since any abductive explanations will cover more positive examples.
However, as mentioned before, it is often easier in practice to generalise one example
at a time with the standard covering approach described above.
Lemma 6.3.8. Let X = ⟨B, E+, E−, M⟩be an inductive context, let Y = ⟨T, G, IC, A⟩
be the contextual transform of X, let ∆be an abductive explanation of Y , let φ be
any formula containing no predicates of the form p† or p‡, let ψ be the formula φ‡A.
Then T ∪∆|= ψ iﬀB ∪∆|= φ.
Proof. The “if” case is given here and the “only-if” case is proved similarly.
For
simplicity, it is assumed that all abducibles are renamed by the contextual transform
irrespective of whether they are actually deﬁned in B (as this is merely an eﬃciency
optimisation that does not aﬀect correctness). First note that T ∪∆and B ∪∆are
Horn theories whose (unique) stable models coincide with their LHMs. Now, suppose
B ∪∆|= φ and assume, contrary to what is required, that T ∪∆̸|= ψ. Equivalently,
assume that while every model of B ∪∆satisﬁes φ, there exists a model M′ of T ∪∆
that does not satisfy ψ.
Now obtain a contradiction by using M′ to construct a
model M of B ∪∆that does not satisfy φ. In particular, let M be an interpretation
that satisﬁes a ground atom α iﬀM′ satisﬁes the atom α‡A. Then, show that M
is a model of ∆. By assumption M′ is a model of T ∪∆, and so M′ satisﬁes each
ground atom in ∆and (each ground instance of) each clause in T. Since each atom
α = p(t1, . . . , tn) in ∆has some predicate p/n ∈A for which, by Deﬁnition 6.3.6,
there is a corresponding clause C′ = p‡(x1, . . . , xn) ←p(x1, . . . , xn) in TA and hence
in T, and since M′ satisﬁes both α and C′, it follows that M satisﬁes the atom
α‡A = p‡(t1, . . . , tn). Therefore, by construction, M satisﬁes α. Hence, M is a model
of ∆. Next, show that M is a model of B. For each clause C = a0 ←a1, . . . , an
in B, it follows by Deﬁnition 6.3.6 that the clause C′ = a‡A
0
←a‡A
1 , . . . , a‡A
n
is in
TB and hence in T. Clearly, for each ground instance D = α0 ←α1, . . . , αn of C,

6.3. HAIL PROOF PROCEDURE
126
there is a corresponding ground instance D′ = α‡A
0
←α‡A
1 , . . . , α‡A
n
of C′. Since M′
satisﬁes (each ground instance of) each clause in T, it follows that M′ satisﬁes D′.
This means that either M′ satisﬁes α‡A
0 , or else M′ does not satisfy α‡A
i
for some
1 ≤i ≤n. Consequently, by construction, either M satisﬁes α0 or else M does not
satisfy αi. In either case M satisﬁes D. Hence M is a model of B. Finally, show
that M does not satisfy φ. By assumption, M′ does not satisfy ψ, which means that
M′ does not satisfy φ‡A, and so, by construction, M does not satisfy φ. Thus, M is
a model of B ∪∆that does not satisfy φ. This is the contradiction required. Hence
T ∪∆|= ψ.
Corollary 6.3.9. Let X =⟨B, E+, E−, M⟩be an inductive context, let Y =⟨T, G, IC, A⟩
be the contextual transform of X, and let ∆be an abductive explanation of Y . Then
∆⊆GM and B ∪∆|= E+.
Proof. Immediate from Deﬁnitions 6.3.6 and 3.1.2 using Lemma 6.3.8.
To conclude,
this chapter presented the semantics and proof procedure for a novel
machine learning approach called HAIL that overcomes some of the limitations of
Progol5. The approach is based on the principle of using ground atoms generated by
ALP to ‘seed’ the construction of a ground theory which can be generalised by ILP.
The main advantage of HAIL is its ability to infer more than one clause in response
to a single seed example. The HAIL approach was implemented by integrating an
extension of the KM ALP procedure within a generalisation of Progol5.
At the
heart of this implementation is a technique for transforming inductive language bias
into abductive integrity constraints and enabling the KM procedure to be applied to
general inductive contexts. In addition to its abductive phase, this implementation
includes one deductive and one inductive sub-routine, both of which are based upon
core Progol5 principles. Consequently, HAIL operates on exactly the same inputs
as Progol5 and is guaranteed to return a hypothesis as or more compressive than
Progol5’s. In the next chapter, these two systems are compared in practice by means
of a simple biological case study.

Chapter 7
Case Study
This chapter describes the application of HAIL to a biological case study modelling
the transcriptional regulation of lactose metabolism in Escheria coli (E. coli). This
regulatory mechanism is biologically very well understood, and was chosen in order
to validate the HAIL proof procedure and to compare its performance and accuracy
with Progol5. This comparison highlights the ineﬃciency of contrapositives compared
to abduction, and shows the need to induce multiple clause hypotheses in response
to a single seed example. First, Section 7.1 introduces the case study and deﬁnes
a concrete learning task. Then, Sections 7.2 and 7.3 describe the result of applying
HAIL and Progol5 to that task. Finally, Section 7.4 compares the two approaches in
terms of their eﬃciency and ability to solve this particular problem.
7.1
Regulation of Lactose Metabolism in E. coli
E. coli is an intensively studied bacterium that has been widely used as a model
organism in the study of microbiology and genetics. One very interesting and well
understood aspect of E. coli is the regulation of the metabolic processes by which
it breaks down sugars to derive energy and sustain the processes necessary for life.
The preferred food source of E. coli is the simple (mono-saccharide) sugar glucose.
But, if concentrations of glucose in the growth medium are insuﬃcient for survival,
then E. coli is also able to metabolise, albeit less eﬃciently, the more complex (di-
127

7.1. REGULATION OF LACTOSE METABOLISM IN E. COLI
128
saccharide) sugar lactose. Before they can process lactose, however, the E. coli cells
must produce two enzymes: a transporter called lactose-permease, which imports
lactose into the cell, and a catalyst called β-galactosidase, which converts it to glucose.
These enzymes are coded by two genes called lac(z) and lac(y) that are located on a
cluster of co-regulated genes known as the lac operon.
Like all gene products, the enzymes needed for lactose metabolism are produced
when a molecule called polymerase binds to a promoter region on the DNA sequence
and transcribes the gene. However, in contrast to most bacterial genes, which are
often permanently expressed, transcription of the lac operon is carefully controlled by
two independent mechanisms discovered in the 1960’s [31] and illustrated in Fig. 7.1
below. First, polymerase only binds to the lac promoter if an activator known as the
catabolite activator protein (CAP) attaches to a site on the DNA just upstream of the
promoter. But this only happens when the activator is enabled by a molecule called
cyclic adenosine monophosphate (cAMP). Second, polymerase only transcribes the
genes if a repressor known as the lac repressor detaches from an operator site next
to the promoter. But this only happens when the repressor is disabled by a molecule
called allolactose.
Because allolactose is only present when lactose concentrations are high (since
allolactose is produced as a by-product of lactose), and cAMP is only present when
glucose concentrations are low (since the production of cAMP is inhibited by glucose),
the net result is that lactose metabolism is only enabled when lactose is readily
available as a food source to the E. coli cells, but glucose is not. This means no energy
is used to produce enzymes that participate in less eﬃcient metabolic processes, unless
absolutely necessary for survival. These mechanisms are depicted in Fig. 7.1, where
the lac operon is shown as a rectangular strip at the bottom of each sub-ﬁgure. Parts
(a) and (b) show the activator attaching to its binding site when enabled by cAMP;
thereby inducing polymerase to bind to the promoter. Parts (c) and (d) show the
repressor detaching from the operator when disabled by allolactose; thereby enabling
polymerase to transcribe the lac genes.

7.1. REGULATION OF LACTOSE METABOLISM IN E. COLI
129
polymerase
activator
1.
2.
cAMP
repressor
Promoter
Operator
lac(z)
lac(y)
CAP
allolactose
(a) activator being enabled by cAMP and binding to CAP site
polymerase
3.
repressor
activator
Promoter
Operator
lac(z)
lac(y)
CAP
allolactose
(b) activator inducing polymerase to bind to promoter site
repressor
4.
5.
polymerase repressor
allolactose
Promoter
Operator
lac(z)
lac(y)
CAP
activator
(c) repressor being disabled by allolactose and detaching from operator
galactosidase
permease
6.
7.
8.
Promoter
Operator
lac(z)
lac(y)
CAP
polymerase
repressor
activator
(d) polymerase transcribing genes
Figure 7.1: Transcriptional regulation of the LAC Operon

7.1. REGULATION OF LACTOSE METABOLISM IN E. COLI
130
Having introduced the necessary biological background, the rest of this section
derives a simpliﬁed logical model of the regulatory mechanisms described above and
incorporates that model within a concrete learning task that will be used in the
following sections to compare the HAIL and Progol5 proof procedures. To this end,
consider an experimental setting in which the metabolism of E. coli is being studied
under diﬀerent growth conditions. For simplicity, assume four experiments are being
conducted (exp1-exp4), each of which is one of two types (typeA and typeB) —
that could represent experimental and control conditions, for example. Suppose that
measurements are made concerning whether or not the E. coli are metabolising lactose
in each particular experiment, and it is required to induce some hypothesis to explain
this data.
This situation could be represented by the inductive learning problem
formalised in Fig. 7.2 below.
Because Fig. 7.2 depicts a complete input ﬁle, which can be executed by both
HAIL and Progol5, this problem will used to compare the performance of each system
and the accuracy of any hypotheses produced. But ﬁrst, the contents of the ﬁle are
brieﬂy explained and related to the biological setting described above. The ﬁrst line of
the input ﬁle contains the Progol5 directive :- observable(metabolism/2), which
means that any ground clause1 with the predicate metabolism in its head will be
treated as a positive example. The positive examples themselves, which are shown at
the bottom of the ﬁle, are ground atoms stating that lactose metabolism was observed
in experiments 1, 2 and 4 (but not in experiment 3). The mode declarations state that
hypothesis clauses can contain concentration and sugar atoms in their heads, and
experiment and saccharide atoms in their bodies — providing that all placemarkers
are replaced by appropriate terms.
The rest of the ﬁle comprises the background knowledge. The ﬁve rules state
that, in any experiment (Exp), lactose is metabolised if the enzymes permease and
1Note that, unlike earlier versions of Progol, Progol5 is unable to process non-ground positive
examples.
This is the reason why the ﬁrst clause in the background theory of the input ﬁle in
Fig. 7.2 is not treated as a positive example.

7.1. REGULATION OF LACTOSE METABOLISM IN E. COLI
131
:- observable(metabolism/2)?
% Mode Declarations:
M
:- modeh(*,concentration(+sugar,#,+))?
:- modeh(*,sugar(#))?
:- modeb(*,experiment(+,#))?
:- modeb(*,saccharide(+,#))?
% Background Knowledge:
B
metabolism(lactose,Exp):-produce(permease,Exp),produce(galactosidase,Exp).
produce(Enz,Exp):-codes(Gene,Enz),express(Gene,Exp).
produce(allolactose,Exp):-concentration(lactose,hi,Exp).
produce(cAMP,Exp):-concentration(glucose,lo,Exp).
express(lac( ),Exp):-produce(allolactose,Exp),produce(cAMP,Exp).
codes(lac(z),galactosidase).
codes(lac(y),permease).
saccharide(glucose,mono).
saccharide(lactose,di).
experiment(exp1,typeA).
experiment(exp2,typeA).
experiment(exp3,typeB).
experiment(exp4,typeA).
concentration(glucose,hi,exp3).
concentration(lactose,lo,exp3).
:- concentration(Sub,lo,Exp), concentration(Sub,hi,Exp).
% Positive Examples:
E+
metabolism(lactose,exp1).
metabolism(lactose,exp2).
metabolism(lactose,exp4).
Figure 7.2: HAIL/Progol5 input ﬁle

7.2. APPLICATION OF HAIL
132
galactosidase are produced; that any enzyme (Enz) is produced if the gene which
codes that enzyme is expressed; that allolactose is produced if the concentration of
lactose is high (i.e. hi); that cAMP is produced if the concentration of glucose is
low (i.e. lo); and that the lac genes are expressed when both allolactose and cAMP
are produced. The ﬁrst four facts state that galactosidase and permease are coded
by the lac(z) and lac(y) genes, and that glucose and lactose are mono-saccharides
and di-saccharides, respectively. The next four facts state that experiments 1,2 and
4 are of typeA, while experiment 3 is of typeB. The last two facts state that the
concentrations of glucose and lactose are high and low in experiment 3, respectively.
Finally, the constraint states that the concentration of any particular substance (Sub)
cannot be both high and low in the same experiment.
Given the learning task formalised in Fig. 7.2, the theory H, shown below, is
a plausible hypothesis. It states ﬁrstly, that the concentration of all di-saccharides
(which include lactose) is high in all experiments of typeA; and it states secondly
that the concentration of all mono-saccharides (which include glucose) is low in all
experiments of typeA. Because this hypothesis satisﬁes all of the requirements in
Deﬁnition 4.1.2, it is in fact a valid inductive generalisation of the context in Fig. 7.2.
H =

















concentration(S, hi, E)
←
saccharide(S, di),
experiment(E, typeA)
concentration(S, lo, E)
←
saccharide(S, mono),
experiment(E, typeA)
7.2
Application of HAIL
Given the input shown in Fig. 7.2, HAIL will select the ﬁrst positive example as the
seed example e = metabolism(lactose, exp1). The inductive context ⟨B, {e}, ∅, M⟩is
then used to obtain the contextual transform ⟨T, G, IC, A⟩shown in Fig. 7.3 below.
The KM procedure is called, and produces the abductive explanation ∆shown below,
as shown by the KM computation in Fig. 7.4.

7.2. APPLICATION OF HAIL
133
T
=





















































































































metabolism(lactose, Exp) ←produce(permease, Exp), produce(galactosidase, Exp)
produce(Enz, Exp) ←codes(Gene, Enz), express(Gene, Exp)
produce(allolactose, Exp) ←concentration‡(lactose, hi, Exp)
produce(cAMP, Exp) ←concentration‡(glucose, lo, Exp)
express(lac( ), Exp) ←produce(allolactose, Exp), produce(cAMP, Exp)
codes(lac(z), galactosidase)
codes(lac(y), permease)
saccharide(glucose, mono)
saccharide(lactose, di)
experiment(exp1, typeA)
experiment(exp2, typeA)
experiment(exp3, typeB)
experiment(exp4, typeA)
concentration‡(glucose, hi, exp3)
concentration‡(lactose, lo, exp3)
concentration‡(x, y, z) ←concentration(x, y, z)
concentration†(x, y, z) ←sugar(x), any(y), any(z)
sugar†(x) ←any(x)
any(x)
G
=
n
metabolism(lactose, exp1)
IC
=











←concentration(Sub, lo, Exp), concentration(Sub, hi, Exp)
←concentration(x, y, z), ¬concentration†(x, y, z)
←sugar(x), ¬sugar†(x)
A
=
n
concentration/3, sugar/1
Figure 7.3: HAIL Contextual Transform for Fig. 7.2

7.2. APPLICATION OF HAIL
134
For convenience, the KM computation shown in Fig. 7.4 is split into two columns
(starting at the top left, running to the bottom left, continuing to the top right, and
ending at the bottom right). In addition, wherever an abducible triggers more than
one constraint, the resulting consistency computations are separated by a horizontal
line.
For compactness, predicate and constant names have been abbreviated (i.e.
truncated) in the obvious way.
In addition to the four atoms shown below, KM adds two negative atoms to the
hypothesis. Since these are only needed for consistency purposes, they are discarded
at the end of the computation. The deductive phase then produces the Kernel Set K
below, which is generalised by the inductive phase to give the hypothesis H. Since
the two ground atoms do not increase compression, these can be optionally discarded.
Since all of the examples are covered, HAIL successfully returns the hypothesis H.
∆
=

















concentration(lactose, hi, exp1)
concentration(glucose, lo, exp1)
sugar(lactose)
sugar(glucose)
K
=































concentration(lactose, hi, exp1) ←saccharide(lactose, di),
experiment(exp1, typeA)
concentration(glucose, lo, exp1) ←saccharide(glucose, mono),
experiment(exp1, typeA)
sugar(lactose)
sugar(glucose)
H
=































concentration(S, hi, E) ←saccharide(S, di),
experiment(E, typeA)
concentration(S, lo, E) ←saccharide(S, mono),
experiment(E, typeA)
sugar(lactose)
sugar(glucose)

7.3. APPLICATION OF PROGOL5
135
?+ met(lac, e1)
?+ prod(perm,e1), prod(gala,e1)
?+ codes(G, perm), expr(G,e1), prod(gala,e1)
?+ expr(lac(y),e1), prod(gala,e1)
?+ prod(allo, e1), prod(cAMP, e1), prod(gala, e1)
?+ conc‡(lac, hi, e1), prod(cAMP, e1), prod(gala, e1)
?+ conc(lac, hi, e1), prod(cAMP, e1), prod(gala,e1)
conc(lac, hi, e1)
?−conc(lac, lo, e1)
not(conc(lac, lo, e1))
?−■
?−not(conc†(lac, hi, e1))
?+ conc†(lac, hi, e1)
?+ sugar(lac),any(hi), any(e1)
sugar(lac)
?−not(sugar†(lac))
?+ sugar†(lac)
?+ any(lac)
?+ □
?−■
?+ any(hi), any(e1)
?+ any(e1)
?+ □
?−■
?+ prod(cAMP, e1), prod(gala,e1)
?+ conc‡(glu, lo, e1), prod(gala,e1)
...
...
?+ conc(glu, lo, e1), prod(gala,e1)
conc(glu, lo, e1)
?−conc(glu, hi, e1)
not(conc(glu, hi, e1))
?−■
?−not(conc†(glu, lo, e1))
?+ conc†(glu, lo, e1)
?+ sugar(glu),any(lo), any(e1)
sugar(glu)
?−not(sugar†(glu))
?+ sugar†(glu)
?+ any(lac)
?+ □
?−■
?+ any(lo), any(e1)
?+ any(e1)
?+ □
?−■
?+ prod(gala, e1)
?+ codes(G, gala), expr(G, e1)
?+ expr(lac(z), e1)
?+ prod(allo, e1), prod(cAMP, e1)
?+ conc‡(lac, hi, e1), prod(cAMP, e1)
?+ conc(lac, hi, e1), prod(cAMP, e1)
?+ prod(cAMP, e1)
?+ conc‡(glu, lo, e1)
?+ conc(glu, lo, e1)
?+ □
Figure 7.4: Successful HAIL/KM computation for Fig. 7.3

7.3. APPLICATION OF PROGOL5
136
7.3
Application of Progol5
Given the input shown in Fig. 7.2, Progol5 also selects the ﬁrst positive example as the
seed example e = metabolism(lactose, exp1). The StartSet procedure will then form
the contrapositives of the theory. After eliminating any redundant contrapositives,
this results in the set of clauses shown in Fig. 7.5 below — which are written exactly
as they appear in the Progol5 clause base. As shown in the ﬁgure, instead of using
the notation p∗to represent the negation of p, Progol5 actually uses the predicate
symbol ˜p; and instead of using the notation p† to represent the well-typedness of p
Progol5 actually uses the predicate symbol ∗p. In this way, the complement of the
seed example is represented by the ground atom ˜metabolism(lactose, exp1).
Having formed these contrapositives, the StartSet procedure then attempts to
query the complement of each head declaration schema. This results in two queries:
˜? concentration(X, Y, Z) and ˜? sugar(X), neither of which succeed. The latter
fails trivially because there are no clauses for it to resolve with, while the former fails
inﬁnitely, as shown by the SLD-tree in Fig. 7.6. For convenience, some ﬁnitely failed
branches in the ﬁgure are abbreviated with ‘ ... ’, and the inﬁnitely failed branches
are abbreviated with ‘∞’.
Also, the sub-goal codes(lac(W), X), prod(cAMP, E),
∗conc(lac, hi, E) has been abbreviated to ‘. . . ’ in the four leftmost subtrees at depth
5. As before, predicates and constants have been truncated in the obvious way.
Because StartSet fails to return any solutions, the BottomSet and LatticeSearch
procedures are never called, and Progol5 aborts the computation without returning
a hypothesis. Upon further investigation, there are three independent reasons for
the failure of the Progol5 StartSet to produce a solution in this case.
First and
foremost, is the simple fact that there are no atoms in the Bottom Set of B and e
for the StartSet procedure to compute! Strictly speaking, the only positive Bottom
Set literals are the seed example metabolism(lactose, exp1) and the two inconsistent
facts concentration(glu, lo, exp3) and concentration(lac, hi, exp3) — none of which
fall within the language bias speciﬁed by M.
Fundamentally, the problem is that none of the positive examples can be explained

7.3. APPLICATION OF PROGOL5
137
metabolism(lactose,Exp):-produce(permease,Exp),produce(galactosidase,Exp).
produce(Enz,Exp):-codes(Gene,Enz),express(Gene,Exp).
produce(allolactose,Exp):-concentration(lactose,hi,Exp).
produce(cAMP,Exp):-concentration(glucose,lo,Exp).
express(lac(_),Exp):-produce(allolactose,Exp),produce(cAMP,Exp).
codes(lac(z),galactosidase).
codes(lac(y),permease).
saccharide(glucose,mono).
saccharide(lactose,di).
experiment(exp1,typeA).
experiment(exp2,typeA).
experiment(exp3,typeB).
experiment(exp4,typeA).
concentration(glucose,hi,exp3).
concentration(lactose,lo,exp3).
false:-concentration(Sub,lo,Exp),concentration(Sub,hi,Exp).
~metabolism(lactose,exp1).
~concentration(lactose,hi,Exp):-~produce(allolactose,Exp),*concentration(lactose,hi,Exp).
~concentration(glucose,lo,Exp):-~produce(cAMP,Exp),*concentration(glucose,lo,Exp).
~concentration(Sub,lo,Exp):-~false,*concentration(Sub,lo,Exp),concentration(Sub,hi,Exp).
~concentration(Sub,hi,Exp):-~false,concentration(Sub,lo,Exp),*concentration(Sub,hi,Exp).
~produce(permease,Exp):-~metabolism(lactose,Exp),produce(galactosidase,Exp).
~produce(galactosidase,Exp):-~metabolism(lactose,Exp),produce(permease,Exp).
~produce(allolactose,Exp):-~express(lac(_),Exp),produce(cAMP,Exp).
~produce(cAMP,Exp):-~express(lac(_),Exp),produce(allolactose,Exp).
~express(Gene,Exp):-~produce(Enz,Exp),codes(Gene,Enz).
*concentration(A,B,C):-sugar(A),any(B),any(C).
*sugar(A):-any(A).
any(X).
Figure 7.5: Progol5 Contrapositives for Fig. 7.2

7.3. APPLICATION OF PROGOL5
138
by adding only one clause to the theory. As often happens in the study of complex
phenomena, one eﬀect may only have explanations that involve several underlying
causes. In this case, the observation metabolism(lactose, exp1) can only be explained
by hypothesising concentration(glu, lo, exp1) and concentration(lac, hi, exp1). But,
neither the StartSet procedure, nor Progol5 more generally, nor even the semantics
of BG are equipped to make such an inference. As a result, the limitation of Progol5
and BG to deriving single clause hypotheses demonstrably reduces their eﬀectiveness
in this and presumably other more interesting problems.
Clearly Progol5 cannot be expected to solve any problem where the inference of
more than one clause is need in response to a single seed example. However, if one
of the facts above, e.g. concentration(lac, hi, exp1), were added to an augmented
background theory B′, then the other one, i.e. concentration(glu, lo, exp1), would be
contained in the Bottom Set of B′ and e. In this case, the single hypothesis H′, shown
below, would be derivable by BG from B′ and e. Since it falls within the language
bias speciﬁed by M, it might be expected that Progol5 would now be able to compute
the hypothesis H′. However, by running this example, the reader can verify that, as
before, Progol5 fails to compute a hypothesis.
e
=
metabolism(lactose, exp1)
B′
=
B ∪{concentration(lac, hi, exp1)}
H′
=
{concentration(S, lo, E) ←saccharide(S, mono), experiment(E, typeA)}
Once again, the failure of Progol5 is caused by the inability of StartSet to return
any solutions. However, this time, the reason is due to the incompleteness of StartSet
discovered in Chapter 5. For, even though the atom α = concentration(glu, lo, exp1)
is in the Bottom Set of B′ and e, the reader can verify that there does not exist
any factor-free C-deduction of e from B′ wrt. α. Thus, it follows by Theorem 5.4.1
that the idealised StartSet of Section 5.1.3, and hence the actual Progol5 StartSet
procedure cannot compute this atom. As a result, the incompleteness of StartSet
discovered in this thesis demonstrably reduces the eﬀectiveness of Progol5 in this and
presumably other more interesting problems.

7.3. APPLICATION OF PROGOL5
139
˜conc(U, V, E)
˜prod(allo, E), ∗conc(lac, hi, E)
˜exp(lac(W), E), prod(cAMP, E), ∗conc(lac, hi, E)
˜prod(X, E), codes(lac(W), X), prod(cAMP, E), ∗conc(lac, hi, E)
˜met(lac, E), prod(gala, E), ...
prod(gala, e1), ...
codes(Y, gala), exp(Y, e1), ...
exp(lac(z), e1), ...
prod(allo, e1), prod(cAMP, e1), ...
codes(G, allo), prod(cAMP, e1), ...
■
conc(lac, hi, e1), prod(cAMP, e1), ...
■
˜met(lac, E), prod(perm, E), ...
prod(perm, e1), ...
codes(Y, perm), exp(Y, e1), ...
exp(lac(y), e1), ...
prod(allo, e1), prod(cAMP, e1), ...
codes(G, allo), prod(cAMP, e1), ...
■
conc(lac, hi, e1), prod(cAMP, e1), ...
■
˜exp(lac(W ′), E), prod(cAMP, E), ...
˜prod(X′, E), codes(lac(W ′), X′), prod(cAMP, E), ...
...
...
∞
∞
˜exp(lac(W ′), E), prod(cAMP, E), ...
˜prod(X′, E), codes(lac(W ′), X′), prod(cAMP, E), ...
...
...
∞
∞
˜prod(cAMP, E), ∗conc(glu, lo, E)
˜exp(lac(W), E), prod(allo, E), ∗conc(glu, lo, E)
˜prod(X, E), codes(lac(W), X), prod(allo, E), ∗conc(glu, lo, E)
...
...
∞
∞
˜false, ∗conc(U, lo, E), conc(U, hi, E)
■
˜false, conc(U, lo, E), ∗conc(U, hi, E)
■
Figure 7.6: Failed Progol5/StartSet SLD-tree for Fig. 7.5

7.3. APPLICATION OF PROGOL5
140
In order to continue this line of thought, suppose that, in addition to the atom
concentration(lac, hi, exp1), the atom express(lac(z), exp1) were also added to an
augmented background theory B′′. Clearly, the hypothesis H′ is derivable from B′′
and e. Moreover, the reader can now verify that there does exist a factor-free C-
deduction of e from B′′ wrt. to the atom α = concentration(glu, lo, exp1). Since, by
Theorem 5.4.1, the atom α is now computable by the idealised StartSet procedure of
Section 5.1.3, it might be expected that Progol5 would now be able to compute the
hypothesis H′. However, by running this example, the reader can verify once again,
that Progol5 fails to compute a hypothesis.
B′′
=
B ∪{concentration(lac, hi, exp1), express(lac(z), exp1)}
This failure is also caused by the inability of StartSet to return any solutions. On
this occasion, the problem is that StartSet cannot infer the type atom sugar(glucose),
which is needed for the Progol5 type system to continue the computation. While the
inference of this atom is licensed by the head declarations, StartSet cannot take
advantage of this fact.
This is partly related to the fact, mentioned above, that
StartSet and Progol5 cannot infer more than one clause for a single seed example2.
Once again, the limitation of Progol5 and BG to deriving single clause hypotheses
demonstrably reduces their eﬀectiveness in this and presumably other more interesting
problems.
Suppose, just for the sake of argument, that, in addition to the two atoms
concentration(lac, hi, exp1) and express(lac(z), exp1), the atom sugar(glucose) were
also added to an augmented background theory B′′′. By running this example, the
reader can now verify that Progol5 does successfully compute the hypothesis H′,
shown above. For, as shown in Fig. 7.7 below, there is now one successful branch
in the StartSet search space (that uses each of the three additional facts exactly
once).
As a result StartSet computes the atom concentration(glu, lo, exp1).
The
2This shortcoming is also due to the inﬂexibility of Progol5’s type system, which, as noted in
Footnote 5 of Section 5.1.2, is responsible this quite distinct incompleteness of Progol5.

7.3. APPLICATION OF PROGOL5
141
˜conc(U, V, E)
...
˜prod(cAMP, E), ∗conc(glu, lo, E)
˜exp(lac(W), E), prod(allo, E), ∗conc(glu, lo, E)
˜prod(X, E), codes(lac(W), X), prod(allo, E), ∗conc(glu, lo, E)
˜met(lac, E), prod(gala, E), codes(lac(W), perm), prod(allo, E), ∗conc(glu, lo, E)
...
prod(gala, e1), codes(lac(W), perm), prod(allo, e1), ∗conc(glu, lo, e1)
codes(Y, gala), exp(Y, e1), codes(lac(W), perm), prod(allo, e1), ∗conc(glu, lo, e1)
exp(lac(z), e1), codes(lac(W), perm), prod(allo, e1), ∗conc(glu, lo, e1)
codes(lac(W), perm), prod(allo, e1), ∗conc(glu, lo, e1)
prod(allo), ∗conc(glu, lo, e1)
...
conc(lac, hi, e1), ∗conc(glu, lo, e1)
∗conc(glu, lo, e1)
sugar(glu), any(lo), any(e1)
any(lo), any(e1)
any(e1)
□
{U/glu, V/lo}
...
...
...
...
...
...
Figure 7.7: Successful Progol5/StartSet SLD-tree for Fig. 7.5 using additional back-
ground facts conc(lac, hi, e1), exp(lac(z), e1) and sugar(glu)

7.4. COMPARISON OF HAIL AND PROGOL5
142
body atoms saccharide(glucose, mono) and experiment(exp1, typeA) are added by
the BottomSet procedure, and the resulting clause is generalised by LatticeSearch to
produce H′.
B′′′
=
B ∪{concentration(lac, hi, exp1), express(lac(z), exp1), sugar(glucose)}
At this point Progol5 does not actually return H′ as a hypothesis, but, instead,
it terminates instead with a warning which states that no suﬃciently compressive
hypothesis was found. However, Progol5 can be forced to return the hypothesis by
adding the directive :- set(inflate,300)?, which eﬀectively multiplies the coverage
of any hypothesis by a factor of three.
7.4
Comparison of HAIL and Progol5
The application of HAIL (Section 7.2) and Progol5 (Section 7.3) to the case study
introduced in Section 7.1, has produced several interesting conclusions. In particular,
it has demonstrated two practical limitations of Progol5 that are overcome by HAIL.
They are the following:
1. The inability of Progol5 to infer more than one clause for a given example:
Intuitively, this limitation means that Progol5 cannot handle examples that
can only be explained in terms of multiple causes. This limitation is naturally
overcome using an abductive engine, which is designed to compute multiple
atom hypotheses for given observations.
2. The incompleteness of StartSet with respect to the computation of Bottom Set
atom: Intuitively, this limitation means Progol5 cannot compute atoms that
must be used several times to derive the example. This limitation is naturally
overcome using an abductive engine, which is able to reuse any of the atoms it
has abduced to resolve away subsequent goal atoms.

7.4. COMPARISON OF HAIL AND PROGOL5
143
Search space for Fig. 7.2
Excluding additional facts
Including additional facts
with depth bound 30
HAIL
Progol5
HAIL
Progol5
Successful Branches
1
0
4
1
Failed Branches
4
16,379
11
25,358
Open Branches
0
98,304
0
111,616
Resolution Steps
39
376,805
<120
427,988
Figure 7.8: Comparison of HAIL/KM and Progol5/StartSet Search Spaces
In addition to considering the situation in which HAIL is able to compute a
hypothesis when Progol5 cannot, it is also important to take into account the relative
sizes of the search spaces.
Experimental investigation of the number of branches
and the total number of resolution steps (including consistency computations) in the
abductive and contrapositive search spaces reveals the statistics in Fig. 7.8. The left
and right sides of the table relate to the inductive context shown in Fig. 7.2 and the
inductive context obtained by augmenting the background theory B with the three
additional facts in B′′′. The Progol5 depth bound was set to 30. The HAIL depth
bound was also set to 30. The rows show the total number of successful, ﬁnitely
failed, and open branches, and the total number of resolution steps.
It is interesting to note that, even though HAIL overcomes the incompleteness of
StartSet, ﬁnds multiple atom hypotheses, and does consistency checking, the HAIL
search space is signiﬁcantly smaller than Progol5’s. This is because the goal-directed
abductive mechanism avoids the well-known ineﬃciencies [48] associated with the
use of contrapositives, which are only partly ameliorated by the optimisation used
in Progol5. (In this particular example, the Progol5 pruning mechanism correctly
suppresses the formation of exactly one contrapositive, and this optimisation prunes
exactly zero branches from the search space.) As mentioned in Section 5.5.2, as well as
avoiding the need for additional rules, abduction also has the advantage of executing
fewer queries than StartSet for each seed example (i.e. abduction requires just one in
total, whereas contrapositives require one per head declaration).

7.4. COMPARISON OF HAIL AND PROGOL5
144
In more realistic applications, HAIL is likely to discover a greater number of
abductive hypotheses than Progol5.
In such cases, HAIL would have to expend
more resources than Progol5 in the deductive and inductive phases to investigate
hypotheses with more than one clause. Of course, this means that HAIL may be able
to ﬁnd better quality hypotheses than Progol5. As explained earlier, so as not to
compromise eﬃciency, the current HAIL prototype employs a greedy search strategy
that generalises Kernel Sets incrementally one clause at a time (at a cost which
increases linearly with the number of clauses). While this strategy is not guaranteed
to ﬁnd globally optimal hypotheses, it will always return a hypothesis that is equally
or more compressive than any hypothesis returned by Progol5.
Before concluding this section, it is necessary to point out that, for brevity, the
case study used in the chapter has been intentionally kept as simple as possible.
One obvious over-simpliﬁcation is that the lac-operon contains three genes and not
two. The third gene, which is called lac(a) codes for an enzyme called thiogalactoside
transacetylase whose function is not well understood, but is believed to be involved in
the hydrolysis of lactose. To take account of this third gene, it is necessary to insert
the atom produce(transacetylase, Exp) into the body of the ﬁrst rule in Fig. 7.2
and to add the ground fact codes(lac(a), transacetylase) to the theory, as shown
below. The reader will be able to conﬁrm that this modest change adds more than
200,000 resolution steps to the Progol5/StartSet search space, but fewer than 20 to
the HAIL/KM search space.
metabolism(lactose, Exp)
←
produce(permease, Exp),
produce(galactosidase, Exp)
produce(transacetylase, Exp).
...
codes(lac(a), transacetylase).
...

Chapter 8
Related Work
This chapter gives a short introduction to the extensive literature on the integration
of abduction and induction and brieﬂy compares HAIL with some related systems
that exploit these techniques. First, Section 8.1 reviews some of the main approaches
for characterising and distinguishing abduction and induction.
Then, Section 8.2
describes some general methodologies for integrating these two forms of reasoning.
Finally, Section 8.3 compares HAIL with some other systems that utilise abductive
and inductive operators.
8.1
Formal Characterisation of Abduction & Induction
As explained in Chapter 1, the modern distinction between abduction and induction
was introduced by C.S. Peirce, but was the subject of some controversy when his views
underwent a shift in emphasis around the turn of the twentieth century. Interestingly,
although he is considered the inventor of abduction, towards the end of his life Peirce
promoted the view that abduction, like deduction and induction, had its roots in the
work of Aristotle. But, even if there is some truth in this claim, a close reading of
Aristotle’s logical works (as expounded in the Prior and Posterior Analytics) shows
they are concerned almost exclusively with deductive and inductive reasoning.
Since the posthumous publication of Peirce’s collected works, philosophers have
debated the merits of his syllogistic and inferential theories of abduction and induction
145

8.1. FORMAL CHARACTERISATION OF ABDUCTION & INDUCTION
146
in logical and scientiﬁc reasoning. More recently, there have been attempts in AI to
place these distinctions on a more secure mathematical foundation. These eﬀorts,
which have explored the philosophical, cognitive, logical and computational aspects
of abduction and induction, are collected in an edited volume [19] entitled Abduction
and Induction: essays on their relation and integration. In retrospect, the approaches
discussed in this survey fall into the following ﬁve categories.1
1.
Pseudo-deductive.
These approaches all deﬁne abduction and induction in
terms of some underlying deductive relation. In essence, they are based upon the idea
that while abduction and induction are not deduction per-se, they might nevertheless
be seen as deduction from a suitably transformed theory. This is illustrated by the
principle of Inverse Entailment (IE), which states that, for any theory B and examples
E, ﬁnding a hypothesis H such that B ∧H |= E is equivalent to ﬁnding a hypothesis
H such that B ∧¬E |= ¬H. In other words, abductive explanations and inductive
generalisations of E with respect to B are simply the negated deductive consequences
of the transformed theory B ∧¬E.
As a result, this category includes the hypothetico-deductive paradigm, discussed
in Bessant’s chapter, whereby abductive and inductive hypotheses are deﬁned such
that they would, if added to the theory, deductively entail the examples.
It also
includes the approach of Console and Saitta, who propose a spectrum of abductive-
inductive reasoning parameterised by the complementary notions of logical extension
and intention, and that of Lachiche, who views abduction and induction as deduction
from a theory extended with the examples by means of various completion policies. (In
particular, Lachiche argues that Clark’s program completion and Hempel’s similarity
assumption embody the notions of abduction and induction, respectively.)
2. Metalogical.
These approaches characterise abduction and induction by stating
the mathematical properties of their respective entailment relations, treating them as
1These categories are partly based on the chapter by Bessant and they are not necessarily intended
to be mutually exclusive. The discussion above refers to the chapters in [19].

8.1. FORMAL CHARACTERISATION OF ABDUCTION & INDUCTION
147
independent logics with distinct structural properties. The chapter by Flach ﬁts into
this mould by deﬁning rationality postulates for abductive and inductive inference.
So does the chapter by Christiansen, who discusses the integration of abduction and
induction in a metalogical framework.
3. Epistemological.
Many attempts to distinguish abduction and induction focus
on their diﬀerent epistemological or inferential functions. The obvious example is
Peirce’s inferential theory, which, as described in Chapter 1, views abduction and
induction as complementary processes in an overall cycle of scientiﬁc discovery. It
also includes characterisations which argue that abduction and induction diﬀer only
in their intended purpose and not in their logical form.
4. Formalistic.
Many popular accounts of abduction and induction are based on
purely formalistic or syntactic distinctions. This includes Peirce’s syllogistic theory,
which, as described in Chapter 1, treats abduction and induction as variations of the
Aristotelian syllogism in which the major and minor premises are exchanged with the
conclusion. It also applies to the extended term logic in Wang’s chapter.
5.
Probabilistic.
The uncertainty of non-deductive inference leads naturally to
the considerations of hypothesis testing and measures of conﬁrmation, which often
introduce probabilistic elements into the formalism.
In this vein, Poole considers
the relationship between Bayesian networks and probabilistic Horn abduction. By
contrast, Josephson argues that smart inductive generalisation is a special case of
abductive reasoning to the best explanation.
From the outset, this thesis adopted a logic programming view in which abduction
and induction are treated as types of hypothetico-deductive reasoning with distinct
syntactic forms (returning ground facts and non-ground rules, respectively). More-
over, as remarked in [29], BG is itself just a special case of the principle of IE, since the
complement Bot(B, e) of the Bottom Set of B and e can be seen as an intermediary
between B ∧¬E and ¬H in the sense that B ∧¬E |= Bot(B, e) |= ¬H.

8.2. CONCEPTUAL INTEGRATION OF ABDUCTION & INDUCTION
148
8.2
Conceptual Integration of Abduction & Induction
Whichever philosophical stance is adopted, it is generally agreed that abduction
and induction are complementary processes with the potential to cooperate together
in a common reasoning framework. Starting with Peirce’s syllogistic and inferential
theories, there have been many attempts to provide a uniﬁed account of abduction and
induction. Recent work has utilised formal semantics from computational logic and
belief revision. One example is the Abductive Inductive Logic Programming (AILP) [1]
framework, which treats abduction and induction as mechanisms for reasoning with
incomplete knowledge in the context of Bry’s framework for intentional knowledge
base updates. Michalski’s inferential theory of learning [51] might also be cited here,
even if it places rather less emphasis on abduction.
More relevant to this thesis is the discussion in [14], which includes two general
approaches for integrating ALP and ILP, and explores their relation to explanation-
based and multi-strategy learning.
The ﬁrst approach, called Abductive Concept
Learning, concerns the inductive learning of abductive frameworks.
This involves
treating theories and hypotheses as abductive logic programs (rather than just logic
programs) and using an abductive notion of entailment (such as the Generalised
Stable Models of Chapter 3).2 The beneﬁt of this approach is that abductive methods
can exploit information that is missing or implicit in the inductive problem. The
second approach, which could be called Abductive Preprocessing, advocates a two-
stage learning process whereby ALP is used to transform or prepare the data into a
form that is more suitable for the ILP task.
In fact, [14] identiﬁes two diﬀerent ways in which ALP may fulﬁl its preparatory
role. In the ﬁrst case, called the identiﬁcation case, ALP is used to identify the actual
training examples presented to ILP. The idea is that by using ALP to explain the
2In other words the background theory is regarded as a partial theory in which the extents of
some of the predicates (the abducible predicates) are essentially unknown except, possibly, for some
general constraints (the integrity constraints).

8.2. CONCEPTUAL INTEGRATION OF ABDUCTION & INDUCTION
149
original examples, regularities in the explanations may become apparent and reveal
a deeper learning problem hidden in the original examples. In the second case, called
the extraction case, ALP is used to extract some relevant part of the background
theory for use in ILP. The idea is that abductively explaining the examples may
uncover assumptions implicit in the original problem which can then be used as
supplementary background knowledge in the inductive generalisation.
Although no concrete procedures are suggested in [14], the general approaches
discussed therein have proved highly inﬂuential and inspired several of the hybrid
systems mentioned in the next section. While HAIL does not exactly conform to any
of these approaches, each iteration of the covering loop can be viewed as a form of
identiﬁcation case abductive preprocessing. The diﬀerence is that HAIL abductively
explains just one positive example, not all of them. Intuitively, HAIL uses abduction
to perform non-OPL learning, as opposed to identifying an implicit learning problem.
On the other hand, if the examples were all ground atoms, then HAIL could easily be
made explain all of them at once; which is the reason why the contextual transform
is not restricted to a single example in Deﬁnition 6.3.6.
Another important diﬀerence is that the HAIL approach is iterative, whereas the
methodologies discussed in [14] are not. However, many of the ideas in [14] were later
developed in [21] into a plausible cycle of integration. After introducing an inferential
characterisation of abduction and induction based on the (often subtle) distinction
between domain and scenario knowledge, the authors review some of the ways in
which these forms of reasoning can cooperate.
Finally, they describe an abstract
cycle of integration. The present thesis was motivated by this previous work and, in
many respects, can be seen as extending and substantiating the abstract proposals
of [21] into a concrete semantics and proof procedure for integrating abduction and
induction in a logic programming context.

8.3. PROCEDURAL INTEGRATION OF ABDUCTION & INDUCTION
150
8.3
Procedural Integration of Abduction & Induction
This section now compares HAIL with some related systems that combine abductive
and inductive reasoning in a single approach.
Progol.
The relation between HAIL and Progol5 has been discussed at length in
previous chapters. In particular, it was shown that Progol5 can be viewed as a special
case of HAIL in which the abductive procedure is limited to deriving single ground
atoms that may not be reused in a derivation. In actual fact, a connection between
abduction and StartSet was ﬁrst conjectured in [61], although no evidence for this
claim was presented. This thesis conﬁrms the view of [61] but shows that StartSet
and thus Progol5 are incomplete with respect to the semantics of BG.
As mentioned in Section 4.4, C-Progol4 [58] is a special case of Progol5, in which
the abductive phase trivially returns the Skolemised head of the seed example. Since
C-Progol4 computes fewer abductive solutions, it constructs fewer Bottom Sets and
searches a smaller hypothesis space than either HAIL or Progol5. The trade-oﬀis
that, like most Machine Learning approaches, C-Progol4 cannot be used in non-OPL
tasks (such as the applications described in [61] or the case study in the previous
chapter) where hypotheses are needed for non-observable predicates.
Recently, the growing importance of non-OPL has led to interest in techniques that
exploit some form of abduction within the semantics of BG.
SOLD.
One of the ﬁrst works to consider the relation between abduction and BG
is found in [100], where it is shown that the head and body atoms of a Bottom
Set can be given distinct abductive and deductive formulations. Speciﬁcally, for a
deﬁnite theory B and clause e, the author shows the body atoms of Bot(B, e) are
those atoms in the least Herbrand model of the deﬁnite theory consisting of B and
the Skolemised body of e, while the head atoms are those which can be computed by
an abductive procedure called SOLD-resolution (Skip Ordered Linear resolution for
Deﬁnite clauses) [100], from this theory with respect the Skolemised head of e.

8.3. PROCEDURAL INTEGRATION OF ABDUCTION & INDUCTION
151
Based on this result, the author describes a methodology for BG in which the
head and body atoms of a deﬁnite Bottom Set are computed by separate adductive
and inductive procedures. Speciﬁcally, SOLD is used in the abductive phase and
a generic bottom-up saturation procedure [79] is proposed for the deductive phase.
However, the author does not suggest how any form of language or search bias can be
used to constrain the search space, and nor does he provide any heuristics to guide
the selection of head or body atoms. Unlike HAIL, this procedure does not cater for
negative examples is only deﬁned for deﬁnite clause logic.
The author goes on to describe an extension of his procedure that, given a deﬁnite
theory B and a deﬁnite clause e, returns either a deﬁnite clause h or a set ∆of
atoms covering the example; but conjectures that it would be diﬃcult to extend the
procedure to induce conjunctions of deﬁnite clauses.
As described in Chapter 6,
HAIL overcomes these limitations because it caters for negative examples and can
return conjunctions of Horn clauses. Like StartSet, SOLD-resolution can be seen as
a primitive form of abduction in which there is no support for integrity checking (and
little prospect of generalising the procedure to normal logic programs).
Another way for combining SOLD-resolution and BG is to use the former to perform
identiﬁcation case abduction (in the sense of [14]) before applying the latter.
ALECTO.
An approach called ALECTO (Abductive LEarning by Completing
Theories from Observations) [55] uses SOLD to preprocess a given set of examples
before they are generalised by the Aleph ILP system (which, as stated in Section 4.4,
is a variant of C-Progol4). In more detail, ALECTO uses SOLD to ﬁnd abductive
explanations (h-lists) for each positive example. It then forms diﬀerent combinations
(cross-lists) of abducibles by conjoining one explanation for each example. Finally,
Aleph is used to generalise each such combination of abducibles in turn in order to
ﬁnd the most compressive generalisation of these explanations.3
3The only subtlety is that ALECTO modiﬁes Aleph’s scoring heuristic so that it eﬀectively assumes
the truth of any abducibles which have not yet been generalised.

8.3. PROCEDURAL INTEGRATION OF ABDUCTION & INDUCTION
152
ALECTO only supports positive examples, which are assumed to be ground
atoms. Another signiﬁcant drawback of this approach is that the number of cross-lists
increases exponentially with the number of examples, which compromises eﬃciency
and scalability.
In addition, no consistency or type checking is performed during
SOLD computations, resulting in potentially unusable cross-lists and compromising
eﬃciency.4 As described in Chapter 6, HAIL avoids these limitations by exploiting
abductive integrity constraints to ensure that all explanations fall within the language
bias and are consistent with the background theory.
Moreover, because HAIL does not attempt to explain all of the examples in one
go, it avoids the combinatorial explosion faced by ALECTO. On the other hand,
simply because it does consider all of the examples at once, unlike HAIL and Progol,
ALECTO is not sensitive to the ordering of the examples. However, in general, any
hypothesis computed by ALECTO can be computed by HAIL (for some ordering of
the examples), whereas some hypotheses are computed by HAIL which ALECTO
cannot compute.
Intuitively, these rely on the fact that, unlike ALECTO, HAIL
extends the background theory after generalising each example.
All of the systems discussed above are restricted to Horn clause logic. This is in
contrast to some other approaches speciﬁcally designed for full clausal reasoning.
CF-Induction.
An important non-Horn learning method is called CF-Induction
(Consequence Finding Induction) [29] and is known to be a sound and complete
inductive inference method for full clausal logic. This approach is an extension of
SOL-resolution [27], which is a Consequence Finding technique that uses a type of
language bias known as a production ﬁeld to deﬁne the so-called characteristic clauses
of a given theory. Formally, a production ﬁeld P is a pair ⟨Lits, Cond⟩where Lits
is a set of literals closed under instantiation and Cond is ‘a certain condition to
be satisﬁed’ [27]. A clause C belongs to P iﬀC ⊆Lits and C satisﬁes Cond. A
4Although so-called acceptability constraints are used to generate valid h-lists, these are only
applied after the SOLD computation has returned a complete set of atoms known as a skip-list.

8.3. PROCEDURAL INTEGRATION OF ABDUCTION & INDUCTION
153
characteristic clause of a theory T with respect to P is a non-tautologous consequence
of T that belongs to P and is not properly subsumed by any other such clause. Like
HAIL, CF-Induction constructs its hypotheses by generalising a ground theory. But,
whereas HAIL uses a Kernel Set, CF-Induction uses the Skolemised negation of a
certain theory CC containing a set of (instances of) the characteristic clauses of the
theory T consisting of the background knowledge B and the Skolemised negation of
the examples E. In the current implementation CF-Induction, the clauses in CC
are selected by the user from a menu. After this theory is negated, it is converted
to conjunctive normal form (CNF) and generalised using operators such as inverse-
subsumption and inverse-resolution.
In practice, some of the main drawbacks of CF-Induction are: (i) the need for
the user to interactively select the characteristic clauses required to derive a useful
hypothesis; (ii) the need for complex generalisers, such as inverse resolution, for which
complete implementations do not exist; (iii) the need to convert the negation of CC
CNF, which is computationally expensive; and, most importantly, (v) the fact that
the CF-Induction language bias does not apply to the hypothesis being learnt, but to
the set of characteristic clauses, which must be negated and converted to CNF before
they can be generalised. In particular, this last rearrangement makes it diﬃcult to
exploit non-trivial forms of language bias such as mode declarations. Moreover, as
explained in [75], the language LM of a set M of mode declarations typically violates
a property, called stability, that is needed by SOL for the completeness of its pruning
methods.5 In contrast to CF-Induction, HAIL is a fully automatic technique that
does not require user interaction and only utilises a tractable inverse-subsumption
generaliser. Formally, HAIL can be seen as a special case of CF-Induction, where
the theory CC contains one negative clause (whose literals are the negations of the
positive atoms in a Kernel Set) and zero or more positive unit clauses (whose atoms
are the negations of the negative literals in a Kernel Set).
5As explained in [27], a production ﬁeld is stable iﬀ, for any clauses C and D, whenever D belongs
to P and it holds that C ⪯D, then C also belongs to P.

8.3. PROCEDURAL INTEGRATION OF ABDUCTION & INDUCTION
154
Another sound and complete method for hypothesis ﬁnding in full clausal logic is
proposed in [101].
Residue Hypotheses.
Very brieﬂy, the Residue of a ground theory G is deﬁned as
the ground theory consisting of all non-tautological clauses that contain the negation
of one literal from each clause in G. A Residue Hypothesis of two clausal theories B
and E is then deﬁned as the Residue of a subset of the ground instances of clauses in
B and clauses in the Residue of the Skolemisation of E. A hypothesis H is derived
by the Residue Procedure from B and E iﬀH generalises a Residue Hypothesis of
B and E. From a computational perspective, the main drawback of this approach is
that it is not clear how residue hypotheses may be eﬃciently computed or even how
language and search bias may be usefully incorporated into this framework.
Many systems have explored the use of abductive and inductive theory revision
operators and others have examined the inductive learning of abductive theories.
Other Systems.
INTHELEX (INcremental THEory Learner from EXamples) [18]
and DemoII [8] are multi-strategy systems that combine abduction and induction with
other operators. BORDA (BOttom ReDuction Algorithm) [30] is a variation of SOLD
that computes the least generalisation of the Bottom Sets of two or more examples.
AUDRYII [95], NEITHER (New Explanation-based and Inductive THeory Extension
and Revision) [5], FORTE (First-Order Revision of Theories from Examples) [77],
RX [93], RUTH (Revising and Updating Theories) [2], and SLDNFAI (SLD with
Negation as Failure, Abduction and Induction) [1] are theory revision systems that
perform abductive and inductive updates. LAB (Learning for Abduction) [54], LAP
(Learning Abductive Programs) [45] and ACL (Abductive Concept Learning) [41]
are systems that learn abductive frameworks: i.e. they realise Abductive Concept
Learning in the sense of [14].
Like HAIL, these last three systems all utilise the
Kakas-Mancarella ALP procedure; but, in contrast to these systems, HAIL operates
exclusively within the predictive ILP setting.

Chapter 9
Conclusions and Future Work
This chapter concludes the thesis with a summary of its main contributions and some
suggestions for future work.
9.1
Summary and Conclusions
This thesis proposed a Machine Learning approach called Hybrid Abductive Induc-
tive Learning (HAIL), which integrates Abductive and Inductive Logic Programming
(ALP and ILP) in a logically principled and practically viable way that overcomes
some of the limitations of related systems and enlarges the class of problems soluble
in practice. The integration is based on the idea of using atoms generated by ALP to
‘seed’ a ground theory which can be generalised by ILP. HAIL is logically principled
because the hypotheses produced are semantically and procedurally characterised by
the two new notions of Kernel Sets and K*-derivations, which lift the two earlier
notions of Bottom Sets and C-derivations from clauses to theories. The approach
is practically viable because the ILP component reuses the eﬃcient mode-directed
compression-based heuristics of Progol5, while the ALP part exploits the integrity
handling ability of the Kakas-Mancarella procedure to guarantee that the abduced
explanations are consistent with the theory and fall within the language bias. By
ensuring that the cost of constructing and generalising a Kernel Set grows linearly
with the number of clauses therein, tractability is maintained.
155

9.1. SUMMARY AND CONCLUSIONS
156
The thesis also presented an analysis of the Progol5 StartSet procedure that
exposed an incompleteness with respect to the semantics of BG. The signiﬁcance of
this incompleteness was revealed by showing how it had reduced the eﬀectiveness of
Progol5 in a published real-world application. However, instead of recognising it as
an incompleteness of the StartSet procedure, the authors attributed this limitation to
the underlying semantic incompleteness of BG. By rewriting the background theory
to avoid the explicit use of integer arithmetic, this error was made apparent here.
To avoid any further confusion, the incompleteness of Progol5 was characterised and
distinguished from the incompleteness of BG. While it is well-known [99] that a
hypothesis is derivable by BG only if there is a derivation of the example from the
theory that uses the hypothesis just once, it was shown in this thesis that a hypothesis
is only derivable by Progol5 if at least one such derivation is factor-free. It was then
shown how this incompleteness can be overcome by using the notion of ancestor
resolution as in the PTTP theorem prover. It was also noted how this limitation
of Progol5 shows that ancestor resolution is in fact needed for the completeness of
PTTP in Horn clause applications.
More importantly, it was argued that the incompleteness of StartSet could be
better overcome using a simple form of ALP, which then could be further generalised
to exploit the full beneﬁts of ALP. This observation motivated the HAIL approach,
which was shown to solve three key limitations of Progol5. First, by utilising ALP
hypotheses with more than one atom, HAIL can learn more than one clause for a
single seed example, and return hypotheses outside the semantics of BG. Second,
by using ALP instead of contrapositives, HAIL avoids unnecessarily enlarging the
search space, reduces the number of queries that need to be run, produces more eﬃ-
cient goal-directed computations, and avoids the incompleteness of StartSet. Third,
by compiling inductive language bias as ALP integrity constraints, HAIL can use
placemarker predicates to actively learn type information that may be missing from
the background theory. Finally, using a biological case study, all three limitations
were shown to reduce the performance of Progol5, thereby demonstrating that HAIL

9.2. FUTURE WORK
157
enlarges the class of problems soluble in practice.
HAIL clearly shows the potential beneﬁts of hybrid ALP-ILP systems and seems
to provide a reasonable practical balance between eﬃciency and incompleteness — in
the sense that its enhanced performance justiﬁes the modest increase in computational
eﬀort compared to Progol5. Here, it is important to note that even if the abductive
phase of HAIL is more eﬃcient than Progol5’s, the main computational costs will
arise in the inductive phase, due to the repeated testing of coverage and consistency.
Since it returns more abductive solutions than Progol5, HAIL must generalise more
clauses in the inductive phase to identify the most compressive hypothesis. Of course,
in reality, the total number of clauses is ﬁnitely bounded by a number of system
parameters. In particular, if m is an upper bound on the number of atoms in any
Kernel Set clause (enforced by restricting the maximum depth and recall used in the
deductive phase), and k is an upper bound on the number of clauses in any Kernel Set
(enforced by restricting the maximum number of atoms in an abductive explanation),
and n is an upper bound on the number of k-clause Kernel Sets (enforced by restricting
the number of abductive explanations returned), then the worst case complexity of
HAIL is order k2 greater than Progol5’s.1
9.2
Future Work
The approach proposed in this thesis is arguably the most conservative extension
of Progol5 that is capable of addressing the speciﬁc practical limitations described
above. Even though HAIL improves upon the generalisation ability of Progol5 in
these key respects, HAIL shares many other limitations with Progol5. Most obviously,
HAIL is still incomplete with respect to the general ILP task. Consequently, further
investigation of the tradeoﬀs between eﬃciency and incompleteness is a necessary
1Speciﬁcally, if C is an upper bound on the cost generalising an m-atom clause. Then it can be
shown that the worst case complexities of Progol5 and HAIL are nC and 1
2(k2 + k)nC, respectively,
per iteration of the cover-set loop. Clearly, this 1
2(k2 + k)-fold increase in complexity is needed to
pay for the k-fold increase in the number of possible solutions investigated by HAIL.

9.2. FUTURE WORK
158
and important direction for future work. One source of incompleteness is the greedy
search procedure, which is liable to miss optimal hypotheses. Thus, strategies for
theory (as opposed to clause) reﬁnement [52] are a promising area of future research.
Another reason is the strict sequential application of the abductive, deductive and
inductive phases, which means hypotheses cannot be learnt that would, in eﬀect, have
to be added to the theory in order for the necessary atoms to become available that
could be used to construct a Kernel Set from which the hypothesis could be derived.
Addressing this limitation by interleaving the three phases appears to be a fruitful
line of attack and may be able to build upon some of the ideas in [23].
Extensions of HAIL that are able to account for noisy data (i.e.
misclassiﬁed
examples) will be essential in real Machine Learning applications. Following Progol5,
this behaviour could be achieved by simply relaxing the consistency requirement and
modifying the scoring heuristic used in the inductive search procedure to penalise
any covered negative examples. A distinction could then be made between integrity
constraints, which can never be violated, and negative examples, which can sometimes
be contradicted. While this distinction is determined implicitly in Progol5, allowing
the user to specify this information explicitly would seem to provide a more ﬂexible
solution. One way of achieving this is to specify background knowledge, positive and
negative examples in separate ﬁles — as done in many other systems such as Aleph.
In the long run, additional support similar to that provided by Progol5 and Aleph
should also be added to HAIL for assessing the statistical signiﬁcance of hypotheses
and for learning from positive-only examples.
From a knowledge representation perspective, it would be interesting to build Nega-
tion as Failure (NAF) into the HAIL formalism. In principle, this would not only
facilitate the knowledge engineering task by allowing defaults and priorities to be
readily formalised, but it would also enable the learning of exceptions to rules in
the background knowledge, thereby enabling the possibility of true theory revision
as opposed to mere theory extension.
In fact, the close connection between ALP

9.2. FUTURE WORK
159
and NAF means that HAIL is an ideal platform for studying non-monotonic exten-
sions of ILP. Since HAIL already includes a full ALP interpreter for normal logic
programs, a non-monotonic extension of HAIL can easily be envisioned. However, a
viable solution must avoid the diﬃculties exposed by recent attempts to learn with
NAF (summarised in [82]), where the fact that adding new hypotheses may invali-
date earlier covered examples makes standard cover-set approaches diﬃcult to apply.
Fortunately, at the Kernel Set level, these problems can be avoided by using ALP
to explain all the examples at once (assuming the positive examples are all ground
atoms — as they usually are in practice). Of course, these ground hypotheses still
have to be generalised and the key here will be to retain the consistency information
generated by ALP (in the form of abduced negative literals) and to use it in the
deductive and inductive phases to avoid uncovering any examples. Clearly, it will
be necessary to allow negative atoms of the form not(p(...)) to appear in the body
declarations and the HAIL semantics would have be generalised accordingly.
Extensions of the HAIL proof procedure to the full ﬁrst-order case could also be
investigated. Here, the monotonicity of classical logic means that standard cover-
set techniques can be safely applied, even if non-Horn reasoning techniques have to
be used.
Full clausal abduction could be eﬃciently realised using SOL-resolution
with a production ﬁeld comprising the ground instances of the head declarations and
the negations of any body declarations. The deductive phase could be implemented
using a generalisation of MDIE that employs a full PTTP theorem prover in place
of Prolog. Finally the inductive search procedure could be realised by extending the
greedy multi-clause search strategy of HAIL to the general case using PTTP or SOL
to test the coverage and consistency of candidate hypotheses. The resulting extension
of HAIL would be a reﬁnement of CF-Induction that exploits the language and search
bias of HAIL. Although it would be less complete than CF-Induction, the tractability
and autonomy of HAIL would allow a better appraisal of the practical utility of non-
Horn ILP and the possibility of investigating more complete systems better suited to
the needs of real applications.

9.2. FUTURE WORK
160
An exciting direction for future work concerns the interaction of logical systems
with the physical world. Some promising steps have been taken in this direction in
work exploring the role of abduction in robot visual perception [87]. One way forward
might be to extend the cognitive architectures used in this work with the capability of
inductive learning. In another project called the ‘Robot Scientist’, Progol5 was linked
to a robotic experimental platform able to physically test the hypotheses produced.
The selection of experiments was performed by a module that attempts to minimise
the costs involved (and is not unrelated to some of the pragmatic concerns that
Peirce often discusses in relation to his inferential theory). The system was used to
predict the function of genes deleted in auxotrophic growth experiments involving
the yeast Saccharomyces cerevisiae. However, all of the hypotheses were restricted to
ground facts and all of the mutations were single-gene deletions. It would therefore be
interesting to undertake a similar experiment using a system with superior reasoning
capabilities and to exploit more informative datasets, such as those described in [94],
involving double-gene mutations. Since two separate hypotheses would be needed to
explain each example, this is a task in which HAIL could potentially perform very
well. Certainly, this line of research holds great promise as it may one day lead to
reasoning agents that are truly able to automate or assist in the process of scientiﬁc
knowledge discovery.

Bibliography
[1] H. Ad´e and M. Denecker. AILP: Abductive Inductive Logic Programming. In
Proceedings of the 14th International Joint Conference on Artiﬁcial Intelligence,
pages 1201–1207. Morgan Kaufmann, 1995.
[2] H. Ad´e, B. Malfait, and L. De Raedt. RUTH: an ILP Theory Revision System.
In Z.W. Ras and M. Zermankova, editors, Proceedings of the 8th International
Symposium on Methodologies for Intelligent Systems, volume 869 of Lecture
Notes in Artiﬁcial Intelligence, pages 336–345. Springer Verlag, 1994.
[3] P.B. Andrews. Resolution with Merging. Journal of the ACM, 15(3):367–381,
1968.
[4] K.R. Apt and R.N. Bol. Logic Programming and Negation: A Survey. Journal
of Logic Programming, 19/20:9–71, 1994.
[5] P. Baﬀes and R.J. Mooney. Extending theory reﬁnement to m-of-n rules. In-
formatica Learning, 17:387–397, 1993.
[6] A. Bracciali. Temporal Reasoning Software, 2004.
http://www.di.unipi.it/˜braccia/.
[7] C. Chang and R.C. Lee.
Symbolic Logic and Mechanical Theorem Proving.
Academic Press, 1973.
[8] H. Christiansen. Abduction and induction combined in a metalogic framework.
In Flach and Kakas [19], pages 195–211.
161

BIBLIOGRAPHY
162
[9] K. L. Clark. Negation as failure rule. In H. Gallaire and J. Minker, editors,
Logic and Data Bases, pages 293–322. Plenum Press, 1978.
[10] W.F. Clocksin and C.S. Mellish. Programming in Prolog. Springer, 4 edition,
1994.
[11] A. Cootes, S.H. Muggleton, and M.J.E. Sternberg. The automatic discovery of
structural principles describing protein fold space. Journal of Molecular Biology,
330(4):839–850, 2003.
[12] P.T. Cox and T. Pietrzykowski. Causes for Events: Their computation and
Application.
In J.H. Siekmann, editor, Proceedings of the 8th International
Conference on Automated Deduction, volume 230 of Lecture Notes in Computer
Science, pages 608–621. Springer, 1986.
[13] M. Denecker and D. De Schreye. SLDNFA: An Abductive Procedure for Ab-
ductive Logic Programs. Journal of Logic Programming, 34(2):111–167, 1998.
[14] Y. Dimopoulos and A.C. Kakas.
Abduction and Inductive Learning.
In
L. De Raedt, editor, Advances in Logic Programming, pages 144–171. IOS Press,
1996.
[15] P.M. Dung. Negation as hypotheses: An abductive framework for logic pro-
gramming. In K. Furukawa, editor, Proceedings of the 8th International Con-
ference on Logic Programming, pages 3–17. MIT Press, 1991.
[16] H.B. Enderton. A Mathematical Introduction to Logic. Academic Press, 1972.
[17] K. Eshghi and R.A. Kowalski. Abduction compared with negation by failure.
In G. Levi and M. Martelli, editors, Proceedings of the 6th International Con-
ference on Logic Programming, pages 234–254. MIT Press, 1989.
[18] F. Esposito, G. Semeraro, N. Fanizzi, and S. Ferilli. Multistrategy Theory Revi-
sion: Induction and Abduction in INTHELEX. Machine Learning, 38(1/2):133–
156, 2000.

BIBLIOGRAPHY
163
[19] P.A. Flach and A.C. Kakas, editors. Abduction and Induction: essays on their
relation and integration, volume 18 of Applied Logic Series. Kluwer, 2000.
[20] P.A. Flach and A.C. Kakas. Abductive and Inductive Reasoning: Background
and Issues. In Flach and Kakas [19], pages 1–27.
[21] P.A. Flach and A.C. Kakas. The Cycle of Abductive and Inductive Knowledge
Development. In D. Michie K. Furukawa, S.H. Muggleton and L. De Raedt,
editors, Proceedings of the Machine Intelligence 17 workshop, pages 17–24. Keio
University, 2000.
[22] K. Furukawa. On the completion of the most speciﬁc hypothesis computation in
inverse entailment for mutual recursion. In S. Arikawa and H. Motoda, editors,
Proceedings of the ﬁrst International Conference on Discovery Science, volume
1532 of Lecture Notes in Computer Science, pages 315–325. Springer, 1998.
[23] K. Furukawa and T. Ozaki. On the Completion of Inverse Entailment for Mutual
Recursion and its Application to Self Recursion. In J. Cussens and A. Frisch,
editors, Proceedings of the Work-in-Progress Track of the 10th International
Conference on Inductive Logic Programming, volume 1866 of Lecture Notes in
Computer Science, pages 107–119. Springer Verlag, 2000.
[24] M. Gelfond and V. Lifschitz. The Stable Model Semantics for Logic Program-
ming. In R.A. Kowalski and K. Bowen, editors, Proceedings of the Fifth Inter-
national Conference on Logic Programming, pages 1070–1080. The MIT Press,
1988.
[25] C. Hartshorne, P. Weiss (Vols 1-6), and A.W. Burks (Vols 7-8), editors. Col-
lected papers of Charles Sanders Peirce. Harvard University Press, 1931-1958.
[26] C.J. Hogger. Essentials of logic programming. OUP, 1990.
[27] K. Inoue.
Linear resolution for consequence ﬁnding.
Artiﬁcial Intelligence,
56(2-3):301–353, 1992.

BIBLIOGRAPHY
164
[28] K. Inoue. Inverse Entailment for Full Clausal Theories. In Proceedings of the
LICS-2001 Workshop on Logic and Learning, 2001.
[29] K. Inoue. Induction as Consequence Finding. Machine Learning, 55:109–135,
2004.
[30] K. Ito and A. Yamamoto. Finding hypotheses from examples by computing the
least generalization of bottom clauses. In S. Arikawa and H. Motoda, editors,
Proceedings of the 1st Conference on Discovery Science, volume 1532 of Lecture
Notes in Computer Science, pages 303–314. Springer, 1998.
[31] F. Jacob and J. Monod. Genetic regulatory mechanisms in the synthesis of
proteins. Journal of Molecular Biology, 3:318–356, 1961.
[32] J.R. Josephson and S.G. Josephson (Eds.). Abductive inference: computation,
philosophy, technology. Cambridge University Press, 1994.
[33] H.E. Pople Jr. On The Mechanization of Abductive Logic. In Proceedings of
the 3rd International Joint Conference on Artiﬁcial Intelligence, pages 147–152.
William Kaufmann, 1973.
[34] A.C. Kakas, R.A. Kowalski, and F. Toni. Abductive Logic Programming. Jour-
nal of Logic and Computation, 2(6):719–770, 1992.
[35] A.C. Kakas and P. Mancarella. Database Updates through Abduction. In Pro-
ceedings of the 16th International Conference on Very Large Databases, pages
650–661. Morgan Kaufmann, 1990.
[36] A.C. Kakas and P. Mancarella. Generalized Stable Models: a Semantics for
Abduction. In Proceedings of the 9th European Conference on Artiﬁcial Intel-
ligence, pages 385–391. Pitman, 1990.
[37] A.C. Kakas and P. Mancarella. Preferred extensions are partial stable models.
Journal of Logic Programming, 14(3-4):341–348, 1992.

BIBLIOGRAPHY
165
[38] A.C. Kakas and P. Mancarella. Constructive Abduction in Logic Programming.
Technical report, Dipartimento di Informatica, Universit di Pisa, 1993.
[39] A.C. Kakas and A. Michael. An abductive-based scheduler for air-crew assign-
ment. Applied Artiﬁcial Intelligence, 15(3):333–360, 2001.
[40] A.C. Kakas, A. Michael, and C. Mourlas. ACLP: Abductive constraint logic
programming. Journal of Logic Programming, 44(1-3):129–177, 2000.
[41] A.C. Kakas and F. Riguzzi.
Abductive concept learning.
New Generation
Computing, 18(3):243–294, 2000.
[42] R.D. King, K.E. Whelan, F.M. Jones, P.K.G. Reiser, C.H. Bryant, S.H. Mug-
gleton, D.B. Kell, and S.G. Oliver. Functional genomic hypothesis generation
and experimentation by a robot scientist. Nature, 427:247–252, 2004.
[43] R.A. Kowalski. Studies in the Completeness and Eﬃciency of Theorem-Proving
by Resolution. PhD thesis, University of Edinburgh, UK, 1970.
[44] R.A. Kowalski and D. Kuehner. Linear Resolution with Selection Function.
Artiﬁcial Intelligence, 2:227–260, 1971.
[45] E. Lamma, P. Mello, F. Riguzzi, F. Esposito, S. Ferilli, and G. Semararo.
Cooperation of Abduction and Induction in Logic Programming. In Flach and
Kakas [19], pages 233–252.
[46] C.T. Lee. A completeness theorem and a computer program for ﬁnding theorems
derivable from given axioms. PhD thesis, University of California, Berkeley,
USA, 1967.
[47] J.W. Lloyd. Foundations of Logic Programming. Springer Verlag, 1987.
[48] D.W. Loveland. Automated Theorem Proving: A Logical Basis. North Holland,
1978.

BIBLIOGRAPHY
166
[49] P. Mancarella and G. Terreni. An Abductive Proof Procedure Handling Active
Rules. In A. Cappelli and F. Turini, editors, Advances in Artiﬁcial Intelligence,
8th Congress of the Italian Association for Artiﬁcial Intelligence, volume 2829
of Lecture Notes in Artiﬁcial Intelligence, pages 105–117. Springer, 2003.
[50] R.S. Michalski. A Theory and Methodology of Inductive Learning. In R.S.
Michalski, J.G. Carbonell, and T.M. Mitchell, editors, Machine Learning: an
Artiﬁcial Intelligence Approach. Morgan Kaufmann, 1983.
[51] R.S. Michalski.
Inferential Theory of Learning: Developing Foundations for
Multistrategy Learning.
In R.S. Michalski and G. Tecuci, editors, Machine
Learning: A Multistrategy Approach. Morgan Kaufmann, 1993.
[52] H. Midelfart. A Bounded Search Space of Clausal Theories. In S. Dˇzeroski and
P.A. Flach, editors, Proceedings of the 9th International Workshop on Inductive
Logic Programming, volume 1634 of Lecture Notes in Computer Science, pages
210–221. Springer Verlag, 1999.
[53] T. Mitchell. Machine Learning. McGraw Hill, 1997.
[54] R.J. Mooney. Integrating Abduction and Induction in Machine Learning. In
Flach and Kakas [19], pages 181–191.
[55] S. Moyle. An investigation into theory completion techniques in inductive logic
programming. PhD thesis, University of Oxford, UK, 2003.
[56] S.A. Moyle and S.H. Muggleton.
Learning programs in the event calculus.
In S. Dˇzeroski and N. Lavraˇc, editors, Proceedings of the 7th International
Workshop on Inductive Logic Programming, volume 1297 of Lecture Notes in
Artiﬁcial Intelligence, pages 205–212. Springer Verlag, 1997.
[57] S.H. Muggleton. Progol5.0 Source code.
http://www.doc.ic.ac.uk/˜shm/Software/progol5.0/.

BIBLIOGRAPHY
167
[58] S.H. Muggleton. Inverse Entailment and Progol. New Generation Computing,
Special issue on Inductive Logic Programming, 13(3-4):245–286, 1995.
[59] S.H. Muggleton. Completing Inverse Entailment. In Proceedings of the 8th In-
ternational Workshop on Inductive Logic Programming, volume 1446 of Lecture
Notes in Artiﬁcial Intelligence, pages 245–249. Springer Verlag, 1998.
[60] S.H. Muggleton. Personal Correspondence, 2003.
[61] S.H. Muggleton and C.H. Bryant. Theory Completion Using Inverse Entail-
ment. In Proceedings of the 10th International Conference on Inductive Logic
Programming, volume 1866 of Lecture Notes in Computer Science, pages 130–
146. Springer Verlag, 2000.
[62] S.H. Muggleton and W. Buntine. Machine invention of ﬁrst-order predicates by
inverting resolution. In Proceedings of the 5th International Machine Learning
Workshop, pages 339–352. Morgan Kaufmann, 1988.
[63] S.H. Muggleton and L. De Raedt. Inductive Logic Programming: Theory and
Methods. Journal of Logic Programming, 19,20:629–679, 1994.
[64] S.H. Muggleton and C. Feng. Eﬃcient induction of logic programs. In Proceed-
ings of the 1st Conference on Algorithmic Learning Theory, pages 368–,381.
Ohmsma, 1990.
[65] S.H. Muggleton, D. Page, and A. Srinivasan.
Learning to Read by Theory
Revision.
Technical Report PRG-TR-26-96, Programming Research Group,
Oxford University Computing Laboratory, UK, 1996.
[66] C. Nedellec, C. Rouveirol, H. Ad´e, F. Bergadano, and B. Tausend. Declarative
bias in ILP. In L. De Raedt, editor, Advances in Inductive Logic Programming,
volume 32 of Frontiers in Artiﬁcial Intelligence and Applications, pages 82–103.
IOS Press, 1996.

BIBLIOGRAPHY
168
[67] S.H. Nienhuys-Cheng and R. de Wolf. Foundations of Inductive Logic Program-
ming, volume 1228 of Lecture Notes in Artiﬁcial Intelligence. Springer Verlag,
1997.
[68] I. Papatheodorou, A.C. Kakas, and M.J. Sergot. Inference of gene relations
from microarray data by abduction. In Proceedings of the 8th International
Conference on Logic Programming and Non-Monotonic Reasoning, volume 3662
of Lecture Notes in Computer Science, pages 389–393. Springer, 2005.
[69] G.D. Plotkin. A note on inductive generalization. In B. Meltzer and D. Michie,
editors, Machine Intelligence 5, pages 153–163. Edinburgh University Press,
1970.
[70] G.D. Plotkin. Automatic Methods of Inductive Inference. PhD thesis, University
of Edinburgh, UK, 1971.
[71] T. Przymusinski.
Semantics of disjunctive logic programs and deductive
databases. In Proceedings of the 2nd International Conference on Deductive
and Object-Oriented Databases, pages 85–107. Springer-Verlag, 1991.
[72] O. Ray.
The need for Ancestor Resolution when answering queries in Horn
clause logic. In M. Gabbrielli and G. Gupta, editors, Proceedings of the 21st
International Conference on Logic Programming, volume 3668 of Lecture Notes
in Computer Science, pages 410–411. Springer Verlag, 2005.
[73] O. Ray, K. Broda, and A.M. Russo. Hybrid Abductive Inductive Learning: a
Generalisation of Progol. In T. Horv´ath and A. Yamamoto, editors, Proceedings
of the 13th International Conference on Inductive Logic Programming, volume
2835 of Lecture Notes in Artiﬁcial Intelligence, pages 311–328. Springer Verlag,
2003.
[74] O. Ray, K. Broda, and A.M. Russo. Generalised Kernel Sets for Inverse Entail-
ment. In B. Demoen and V. Lifschitz, editors, Proceedings of the 20th Inter-

BIBLIOGRAPHY
169
national Conference on Logic Programming, volume 3132 of Lecture Notes in
Computer Science, pages 165–179. Springer Verlag, 2004.
[75] O. Ray, K. Broda, and A.M. Russo. A hybrid abductive inductive proof proce-
dure. Logic Journal of the IGPL, 12(5):371–397, 2004.
[76] J.C. Reynolds. Transformational systems and the algebraic structure of atomic
formulas. In B. Meltzer and D. Michie, editors, Machine Intelligence 5, pages
135–151. Edinburgh University Press, 1970.
[77] B.L. Richards and R.J. Mooney. Reﬁnement of ﬁrst-order Horn-clause domain
theories. Machine Learning, 19(2):95–131, 1995.
[78] J.A. Robinson. A Machine-Oriented Logic based on the Resolution Principle.
Journal of the ACM, 12(1):23–41, 1965.
[79] C. Rouveirol. Extensions of inversion of resolution applied to theory comple-
tion. In S.H. Muggleton, editor, Inductive Logic Programming, pages 63–92.
Academic Press, 1992.
[80] S. Russell S and P. Norvig. Artiﬁcal Intelligence a Modern Approach. Prentice
Hall, 1995.
[81] D. Sacc`a and C. Zaniolo. Stable models and non-determinism in logic programs
with negation.
In Proceedings of the 9th ACM SIGACT-SIGMOD-SIGART
Symposium on Principles of Database Systems, pages 205–217. ACM Press,
1990.
[82] C. Sakama.
Nonmonotonic inductive logic programming.
In Proceedings of
the 6th International Conference on Logic Programming and Non-Monotonic
Reasoning, volume 2173 of Lecture Notes in Artiﬁcial Intelligence, pages 62–80.
Springer, 2001.
[83] T. Sato. Completed logic programs and their consistency. Journal of Logic
Programming, 9(1):33–44, 1990.

BIBLIOGRAPHY
170
[84] K. Satoh and N. N. Iwayama. A correct top-down proof procedure for a general
logic program with integrity constraints. In Proceedings of the 3rd International
Workshop on Extensions of Logic Programming, pages 19–34, 1992.
[85] M. Shanahan. Prediction is deduction but explanation is abduction. In Pro-
ceedings of the 11th International Joint Conference on Artiﬁcial Intelligence,
pages 1055–1060. Morgan Kaufmann, 1989.
[86] M. Shanahan. An abductive event calculus planner. Logic Programming, 44(1-
3):207–240, 2000.
[87] M. Shanahan and D. Randell. A logic-based formulation of active visual percep-
tion. In D. Dubois, C. A. Welty, and M. Williams, editors, Proceedings of the
Ninth International Conference on the Principles of Knowledge Representation
and Reasoning, pages 64–72. AAAI Press, 2004.
[88] A. Srinivasan. The Aleph Manual (version 4), 2003.
http://web.comlab.ox.ac.uk/oucl/research/areas/machlearn/Aleph/index.html.
[89] L. Sterling and E. Shapiro. The Art of Prolog. MIT Press, 2 edition, 1994.
[90] M.E. Stickel.
A Prolog technology theorem prover: A New Exposition and
Implementation in Prolog. Theoretical Computer Science, 104:109–128, 1992.
[91] R.R. Stoll. Set Theory and Logic. Dover, 1979.
[92] A. Tamaddoni-Nezhad, A.C. Kakas, S.H. Muggleton, and F. Pazos. Modelling
inhibition in metabolic pathways through abduction and induction. In R. Ca-
macho, R.D. King, and A. Sirinivasan, editors, Proceedings of the 14th Inter-
national Conference on Inductive Logic Programming, volume 3194 of Lecture
Notes in Computer Science, pages 305–322. Springer Verlag, 2004.
[93] S. Tangkitvanich and M. Shimura. Reﬁning a relational theory with multiple
faults in the concept and subconcepts. In D. Sleemanand P. Edwards, editor,

BIBLIOGRAPHY
171
Proceedings of the 9th International Workshop on Machine Learning, pages
436–444. Morgan Kaufmann, 1992.
[94] A.H. Tong et al. Systematic genetic analysis with ordered arrays of yeast dele-
tion mutants. Science, 294(5550):2364–2368, 2001.
[95] J. Wogulis and M.J. Pazzani.
A Methodology for Evaluating Theory Revi-
sion Systems: Results with Audrey II.
In Proceedings of the 13th Interna-
tional Joint Conference on Artiﬁcial Intelligence, pages 1128–1134. Morgan
Kaufmann, 1993.
[96] A. Yamamoto. Improving Theories for Inductive Logic Programming Systems
with Ground Reduced Programs. Technical Report AIDA-96-19, Fachgebiet
Intellektik, Fachbereich Informatik, Technische Hochschule, Darmstadt, Ger-
many, 1996.
[97] A. Yamamoto. Which hypotheses can be found with Inverse Entailment?
In
S. Dˇzeroski and N. Lavraˇc, editors, Proceedings of the 7th International Work-
shop on Inductive Logic Programming, volume 1297 of Lecture Notes in Artiﬁ-
cial Intelligence, pages 296–308. Springer Verlag, 1997.
[98] A. Yamamoto. Logical aspects of several bottom-up ﬁttings. In M.M. Richter,
C.H. Smith, R. Wiehagen, and T. Zeugmann, editors, Proceedings of the 9th In-
ternational Conference on Algorithmic Learning Theory, volume 1501 of Lecture
Notes in Computer Science, pages 158–168, 1998.
[99] A. Yamamoto. An Inference Method for the Complete Inverse of Relative Sub-
sumption. New Generation Computing, 17(1):99–117, 1999.
[100] A. Yamamoto. Using Abduction for Induction based on Bottom Generalisation.
In Flach and Kakas [19], pages 267–280.
[101] A. Yamamoto. Hypothesis ﬁnding based on upward reﬁnement of residue hy-
potheses. Theoretical Computer Science, 298:5–19, 2003.

