Library Learning for Neurally-Guided Bayesian Program Induction
Kevin Ellis1, Lucas Morales1, Mathias Sabl´e-Meyer2,
Armando Solar-Lezama1, Joshua B. Tenenbaum1
1: MIT. 2: ENS Paris-Saclay.
List processing:
[5 2 9] →[9 2 5]
[1 1 2 2] →[2 2 1 1]
[1 2 3 2] →[2 3 2 1]
Text editing:
P Kohli →Dr. Kohli
Sumit Gulwani →Dr. Gulwani
Danny Tarlow →Dr. Tarlow
Symbolic regression:
ax3 + bx2+
cx + d
a/(x −b)
Explore/Compress/Compile (EC2) learns to solve programming tasks like these by growing a
library of code and training a neural net to search for programs written using the library

Library learning
[7 2 3]→[7 3]
[1 2 3 4]→[3 4]
[4 3 2 1]→[4 3]

Library learning
[7 2 3]→[7 3]
[1 2 3 4]→[3 4]
[4 3 2 1]→[4 3]
Library:
f1(ℓ,p) = (foldr ℓnil (λ (x a) (if (p x) (cons x a) a)))
(f1: Higher-order ﬁlter function)
(Get elements x from ℓwhere (p x) returns true)

Library learning
[7 2 3]→[7 3]
[1 2 3 4]→[3 4]
[4 3 2 1]→[4 3]
f (ℓ) =(f1 ℓ(λ (x) (> x 2)))
Library:
f1(ℓ,p) = (foldr ℓnil (λ (x a) (if (p x) (cons x a) a)))
(f1: Higher-order ﬁlter function)
(Get elements x from ℓwhere (p x) returns true)

Subset of 38 learned library routines for list processing
f0(ℓ,r) = (foldr r ℓcons)
f0: Append lists r and ℓ
f1(ℓ,p) = (foldr ℓnil (λ (x a)
(if (p x) (cons x a) a)))
f1: Higher-order ﬁlter function
f2(ℓ) = (foldr ℓ0 (λ (x a)
(if (> a x) a x)))
f2: Maximum element in list ℓ
f3(ℓ,k) = (foldr ℓ(is-nil ℓ)
(λ (x a) (if a a (= k x))))
f2: Whether ℓcontains k

Explore/Compress/Compile as Bayesian Inference
DSL
prog
task
prog
task
prog
task

Explore/Compress/Compile as Amortized Bayesian Inference
DSL
prog
task
prog
task
prog
task
is

Explore/Compress/Compile as Amortized Bayesian Inference
Explore: Infer programs, ﬁxing DSL and neural recognition model
DSL
prog
task
prog
task
prog
task
is

Explore/Compress/Compile as Amortized Bayesian Inference
Explore: Infer programs, ﬁxing DSL and neural recognition model
DSL
f1, f2, ...
Task
[7 2 3]→[7 3]
[1 2 3 4]→[3 4]
[4 3 2 1]→[4 3]
Recog.
model
Neurally-Guided
Enumerative Search
Programs:
(f1 ℓ(λ (x) (> x 2)))
DSL
prog
task
prog
task
prog
task
is

Explore/Compress/Compile as Amortized Bayesian Inference
Compress: Update DSL, ﬁxing programs
DSL
prog
task
prog
task
prog
task
is

Explore/Compress/Compile as Amortized Bayesian Inference
Compress: Update DSL, ﬁxing programs
progs. for task1
progs. for task2
DSL
DSL+
+
1
+
1
1
cons
+
1
car
z
DSL
prog
task
prog
task
prog
task
is

Explore/Compress/Compile as Amortized Bayesian Inference
Compile: Train recognition model
DSL
prog
task
prog
task
prog
task
is

Explore/Compress/Compile as Amortized Bayesian Inference
Compile: Train recognition model
DSL
program
sample
task
run
DSL
prog
task
prog
task
prog
task
is

Explore/Compress/Compile as Amortized Bayesian Inference
DSL
prog
task
prog
task
prog
task
is
DSL
prog
task
prog
task
prog
task
DSL
prog
task
prog
task
prog
task
Explore
Compile
Compress

Domain: Text Editing
In the style of FlashFill (Gulwani 2012). Starts with map, fold, etc.
Input
Output
+106 769-438
106.769.438
+83 973-831
83.973.831
Temple Anna H
TAH
Lara Gregori
LG

Text editing: Library learning builds on itself
Learned DSL primitives over 3 iterations (3 columns). Learned primitives call each other (arrows).

Programs with numerical parameters: Symbolic regression from visual
input
Fits parameters by autograd-ing thru program
Recognition model looks at picture of function’s graph
Programs & Tasks
DSL
f (x) =(f1 x)
f (x) =(f5 x)
f (x) =(f4 x)
f (x) =(f3 x)
f0(x) = (+ x real)
f1(x) = (f0 (* real x))
f2(x) = (f1 (* x (f0 x)))
f3(x) = (f0 (* x (f2 x)))
f4(x) = (f0 (* x (f3 x)))
(f4: 4th order polynomial)
f5(x) = (/ real (f0 x))
(f5: rational function)

New domain: Generative graphics programs (Turtle/LOGO)
Training tasks:

Generative graphics programs: Samples from DSL
DSL samples before learning
DSL samples after learning

Generative graphics programs: Learned library contains parametric drawing
routines
Semicircle:
Spiral:
Greek Spiral:
S-Curves:
Polygons & Stars:
Circles:

Learning to program: Poster AB #24

