Parsimony Hierarchies For Inductive Inference ∗
Andris Ambainis
Institute of Mathematics and Computer Science
University of Latvia
Raina bulv. 29, Riga, LV-1459
Latvia
John Case
Department of Computer and Information Sciences
University of Delaware
Newark, DE 19716
USA
Sanjay Jain
School of Computing
National University of Singapore
Singapore 119260
Republic of Singapore
Mandayam Suraj
Department of Computer and Information Sciences
University of Delaware
Newark, DE 19716
USA
Abstract
Freivalds deﬁned an acceptable programming system independent criterion for learning pro-
grams for functions in which the ﬁnal programs were required to be both correct and “nearly”
minimal size, i.e, within a computable function of being purely minimal size. Kinber showed
that this parsimony requirement on ﬁnal programs limits learning power. However, in scientiﬁc
inference, parsimony is considered highly desirable. A lim-computable function is (by deﬁnition)
one calculable by a total procedure allowed to change its mind ﬁnitely many times about its
output. Investigated is the possibility of assuaging somewhat the limitation on learning power
resulting from requiring parsimonious ﬁnal programs by use of criteria which require the ﬁnal,
correct programs to be “not-so-nearly” minimal size, e.g., to be within a lim-computable func-
tion of actual minimal size. It is shown that some parsimony in the ﬁnal program is thereby
retained, yet learning power strictly increases. Considered, then, are lim-computable functions
as above but for which notations for constructive ordinals are used to bound the number of mind
changes allowed regarding the output. This is a variant of an idea introduced by Freivalds and
Smith. For this ordinal notation complexity bounded version of lim-computability, the power of
the resultant learning criteria form ﬁnely graded, inﬁnitely ramifying, inﬁnite hierarchies inter-
mediate between the computable and the lim-computable cases. Some of these hierarchies, for
the natural notations determining them, are shown to be optimally tight.
Keywords:
Computational Learning Theory, Minimal Size Program, Constructive Ordinal
Notations, Limiting Computable Function.
AMS Subject Code Classiﬁcation: 68Q32.
∗The authors thank the anonymous referee for helpful comments, including simpliﬁcation of some examples and
proofs.
Email addresses of the authors are: ambainis@lanet.lv, case@cis.udel.edu, sanjay@comp.nus.edu.sg, and
suraj@cis.udel.edu, respectively. Grant support was received by A. Ambainis from Latvian Science Council Grant
01.0354, J. Case from NSF grant CCR-0208616, and by S. Jain from NUS grant R252-000-127-112.
1

1
Introduction
This work is in the context of computability-theoretic inductive inference or learning theory [Put63,
Gol67, JORS99, Odi99].
In Section 1.1 are informally presented what we need of the basic concepts and motivations
from inductive inference including parsimony constraints on inferred (learned) programs.
As we will see, degrees of parsimony will be measured with notations from Kleene’s O for
the constructive ordinals [Rog67]. Section 1.2 presents a corresponding informal introduction with
motivations and examples.
Section 1.3 summarizes our principal results. These feature inﬁnite hierarchies of success criteria
re inferring parsimonious programs, and they are based on O-measured degrees of parsimony.
Section 2 contains the needed basic terminology and deﬁnitions presented rigorously.
Our main results are presented with proof in Section 3, and Section 4 presents further and
preliminary results and open questions.
1.1
Inductive Inference Machines and Parsimony
N denotes the set of natural numbers, {0, 1, 2, 3, . . .}. A basic paradigm from machine inductive
inference pertains to the algorithmic, trial and error “learning” of programs for (computable) func-
tions f : N →N — given, as input, enumerations of the successive values of f, i.e., f(0), f(1), . . . .
We can think of a function f : N →N as encoding the set of all possible deterministic outcomes
of the experiments on some corresponding phenomenon (e.g., from chemistry): an input x to f
represents the code of a possible experiment, e.g., mixing particular volumes of particular chemi-
cals in a test tube, and f(x) represents the outcome, e.g., the mixture turned blue and ﬁzzed (see,
for example, [BB75, CS83]).1 A program p for such a function corresponds, then, to a predictive
explanation for the associated phenomenon. Possession of p enables one to predict the outcomes of
any experiment (with associated code) x regarding the phenomenon: use p to compute f(x) (and
decode). The trial and error aspect of algorithmically learning such explanatory programs p models
that the scientiﬁc community changes its “mind” over time as to explanations for a phenomenon.
Informally, acceptable programming systems (synonym: acceptable numberings) [Rog58, Rog67,
MY78, Roy87] are those programming systems for the partial computable functions which are
intercompilable with naturally occurring general purpose programming formalisms such as Turing
machine formalisms and the LISP programming language.2
The programs output by inductive
inference algorithms (or machines) will be from some ﬁxed acceptable system ϕ. ϕp denotes the
partial computable function : N →N computed by the program p in the ϕ-system. When an
inductive inference machine M is given the successive values of a function f as input and, after
some resultant succession of (trial and error) output programs, it converges to a single program
p, we write M(f) = p.
If this p is a correct program (explanation) for f, i.e., if ϕp = f, we
say that M Ex-identiﬁes f. If some M Ex-identiﬁes every function in a class of functions C, we
write C ∈Ex. For example, the class of primitive recursive functions is in Ex, and the class of
computable functions is not [Gol67, BB75].
1Fulk [Ful85] argues that the set of possible, distinguishable experiments one can actually do on a phenomenon is
countable.
2Typically, for theoretical work, one works with numerical names for the programs in these systems — whence
the term ‘numbering.’
2

In scientiﬁc inference, parsimony of explanations is considered highly desirable. Program size is
one of many ways to measure parsimony of programs [JORS99], and one can think of parsimony as
a special case or variant of Occam’s Razor. It is known, for computability-theoretic inductive infer-
ence, that requiring the ﬁnal and correct programs to be minimal size [Sch98] is highly restrictive
on inferring power [Fre75, Fre90] (and that the resultant inferring or learning power is dependent
on which acceptable programming system is employed). Known too is the adverse eﬀect on learn-
ing power of requiring the ﬁnal and correct programs to be merely within a computable factor of
minimal size [Kin74, Che82] (but that the resulting inferring power is independent of the under-
lying acceptable programming system [Fre75]). Hence, we see that, while parsimony is desirable,
parsimony restrictions of even the weaker kind described just above limit inferring power.3
In the present study we will be exclusively concerned with criteria of success for inductive
inference (parsimony restricted or not), and these criteria will be independent of the ﬁxed underlying
acceptable programming system from which the output hypotheses are drawn. For computable f,
let MinProg(f) def
= the numerically least program for f. For C ∈Ex as witnessed by M, if there is
a computable function g such that, for every f ∈C, M(f) ≤g(MinProg(f)), then we say C ∈Mex
(as witnessed by M and g). In this setting we call g a parsimony factor. From [Kin74] we have,
then, that Mex ⊂Ex.4 For example, the set of functions which have value zero on almost all
arguments ∈(Ex −Mex) [Kin74]. However, the class S0 of functions f which, on input zero,
output a program for f is in Mex [Che82], and S0 is very large since, by the Kleene recursion
theorem [Rog67], it contains a 1-variant of each computable function [BB75].
1.2
Using Notations for Constructive Ordinals As Parsimony Measures
To begin explaining the results of the present paper: a lim-computable function is one calculable
by a total procedure allowed to change its mind ﬁnitely many times about its output.5
Let LimMex be the variant of Mex in which the parsimony factors g can be lim-computable. It
is noted in [Che82] that LimMex ⊂Ex. Hence, even the parsimony restriction for which the parsi-
mony factors are allowed to be lim-computable lowers inferring or learning power compared with no
parsimony restriction. However, we see, by Corollary 35 in Section 3 below, that Mex ⊂LimMex.
Hence, while use of lim-computable parsimony factors lowers learning power compared with no par-
simony restriction, use of lim-computable parsimony factors does not lower learning power as much
as the use of computable parsimony factors.
Therefore, the use of lim-computable parsimony
factors partly assuages the limitation on learning power of parsimony restrictions compared with
computable parsimony factors. With the use of lim-computable parsimony factors some desirable
parsimony in the ﬁnal programs is retained, yet learning power strictly increases over the use of
computable parsimony factors.
As we described above, a (total) procedure that computes a lim-computable function is allowed
to change its mind ﬁnitely many times about its output. One may, of course, consider the eﬀects of
restricting the number of mind changes of such procedures. In a diﬀerent context, Putnam [Put65]
studied mind change bounds k ∈N on the way to convergence of lim-computable characteristic
functions and Ershov [Ers68a] showed these form a strict hierarchy in k.
3Case, Jain and Sharma [CJS96] study the eﬀects on learning power of placing restrictions on the size diﬀerences
between successive hypotheses output by an inductive inference machine. This topic is not pursued herein.
4‘⊆’ denotes subset; ‘⊂’ denotes proper subset.
5Post [Sha71] ﬁrst noticed that such functions characterize the functions computable from an oracle for the halting
problem.
3

Intuitively ordinals [Sie65, KM67] are representations of well-orderings. 0 represents the empty
ordering, 1 represents the ordering of 0 by itself, 2 the ordering 0 < 1, 3 the ordering 0 < 1 < 2,
. . . . The ordinal ω represents the standard ordering of all of N. ω +1 represents the ordering of N
consisting of the positive integers in standard order followed by 0. ω + ω represents the ordering of
N consisting of the even numbers in standard order followed by the odd numbers in standard order.
The constructive ordinals are just those that have a program (called a notation) in some system
which speciﬁes how to build them (lay them out end to end, so to speak). We will employ, as our
system of notations, Kleene’s general system O [Kle38, Kle44, Kle55, Rog67, Sac90]. This system
has at least one notation for each constructive ordinal and comes with Kleene’s standard, useful
order relation <o on the notations in O. <o naturally embeds into the ordering of the corresponding
constructive ordinals.
Everyone knows how to use ﬁnite ordinals (the natural numbers) for counting, including for
counting down. Freivalds and Smith [FS93] employed notations for constructive ordinals as devices
for algorithmic counting down.6 They used such notations, for example, for algorithmic counting
down the mind changes of inductive inference procedures. This allowed for handling and studying
constructive, “transﬁnite” bounds on mind changes of inductive inference machines.
Herein we use notations u from O to bound the mind changes on the way to convergence of
(total) procedures for lim-computable functions. The resultant functions we call limu-computable.
In Section 2.4 below we will formally deﬁne the associated O-countdown functions and use them
to deﬁne formally the limu-computable functions. Further below, in the current section, we present
some informal examples. Of course we want to use limu-computable functions as parsimony fac-
tors. Actually, for u ∈O for a positive constructive ordinal, to make the corresponding parsimony
restricted inference criterion LimuMex acceptable system independent, we need to employ mono-
tonically non-decreasing limu-computable parsimony factors. Of course it is natural anyhow to
employ non-decreasing parsimony factors. Our main results present interesting inﬁnite hierarchies
for the criteria LimuMex associated with particular transﬁnite subsequences of u’s along certain
natural <o-paths. Thus, with the (non-decreasing) limu-computable functions providing degrees of
parsimony, we get inﬁnite gradations in inferring or learning power.
In the present paper, we do not study the interesting connection between the limu-computable
functions and (transﬁnite) Ershov hierarchies [Add65, Ers68b, Ers70, EHK81, Sel84].7 However,
in [CS03], we show how to characterize the limu-computable functions and variants in terms of
concepts from [EHK81, Sel84].8
The ﬁnite ordinals have unique notations in O (see Section 2.3 below). For n ∈N, we write n
for the corresponding notation in O. The limn-computable functions are just those for which an
associated (total) mind changing procedure makes not more than n mind changes.
Let K be the diagonal halting problem set [Rog67]. Then, since K is c.e. [Soa96]9, the charac-
6The results of [FS93] are also informally surveyed in [GS95].
Case, Jain and Suraj [CJS95] announced preliminary versions of some of the results of the present work, and herein
are presented considerable improvements (and an emendation).
Subsequently to [CJS95], natural O-notations for constructive ordinals polynomial in ω have been extensively
employed to provide natural classiﬁcations of standard problems within the context of learning grammars for formal
languages [JS97, AJS99, JS99].
7The Ershov hierarchies are based on eﬀective iteration of the Boolean operations including up into the constructive
transﬁnite.
8While notations in O as employed in [Ers68b, Ers70, EHK81, Sel84] are not directly treated as counters, in
Jockusch’s review [Joc82] of [EHK81] he provides the explicit intuition that a notation, as employed in [EHK81],
serves as a kind of counter. This intuition is also explicit in [GD01].
9Where appropriate, we use “computably enumerable” (c.e.) and “computable” instead of “recursively enumer-
4

teristic function of K is lim1-computable.10
The ﬁrst limit ordinal, ω, and each constructive ordinal larger than ω, have inﬁnitely many
distinct notations in O. Suppose w is any notation in O for ω. The limw-computable functions are
just those for which some mind changing procedure declares, if and when it makes its ﬁrst mind
change, the number of further mind changes that it may make about its output. Visually, think of
ω as
0 1 2 3 . . . n . . . )
where the right parenthesis can be thought of as an “open” right hand end marker. The correspond-
ing counter starts at the right parenthesis (or at some number to the left of the right parenthesis);
if and when there is a ﬁrst mind change, the counter algorithmically leaps to some n to the left;
this leaves room for at most n more mind changes with the counter moving to the left.
Let F(x) = max({ϕe(y) | ϕe(y) is deﬁned ∧e, y ≤x}). Clearly, for any notation w in O for
ω, F(x) is limw-computable, non-decreasing and not dominated by any computable function. By
Lemma 22 below, F is not limn-computable.
For the next examples it is useful to discuss the very basic computable operations (for O-
notations), +o, ×o, and {··}o.
These operations on O naturally embed into the corresponding
(constructive) ordinal operations of addition, multiplication, and exponentiation, respectively.11
Just as Kleene essentially changed his deﬁnition of +o between [Kle38] and [Kle55] to obtain some
auxiliary, useful properties, we have added an extra base case to his latter deﬁnition of +o to get
useful properties we need. Our deﬁnition of ×o also features an extra base case over what would be
needed merely to get the embedding into the corresponding ordinal operation. We did this too for
technical usefulness. We guarantee thereby, for example, the technically helpful properties that,
for all y, 0 +o y = y, 0 ×o y = 0, and 1 ×o y = y. In Section 2.5 below we present our “deﬁnitions”
of +o, ×o, and {··}o (as theorems) and present the resultant properties we need.
Convention 1 If e is an expression evaluating to a number n in N, then e is the unique notation
for n in the O notation system.
Suppose w ∈O is for ω and k ∈N. Of course w +o k is a notation for the ordinal ω + k, which
ordinal looks like a copy of the ordinal ω followed (on the right) by a copy of the ordinal k. The
limw+ok-computable functions are those computed by (total) procedures which may make up to k
mind changes before they behave like a limw-procedure. For w +o w = w ×o 2, the corresponding
ordinal, ω + ω = ω × 2, looks like a copy of ω followed by a copy of ω, i.e, like two copies of ω laid
end to end. A limw×o2-procedure is one which declares, if and when it makes its ﬁrst mind change,
the number of further mind changes that it may make about its output, but can later revise this
number once (possibly making a mind change with the revision too). We leave to the reader to
work out the equivalence with visualizing a counter leaping and walking down from the right end
— in a picture of ω × 2. For n > 2, a limw×on-procedure is similar to a limw×o2-procedure, except
that it can revise the number of further mind changes it may make (n −1) times. w ×o w = {w2}o,
and the corresponding ordinal ω ×o ω = ω2, can be visualized as ω copies of ω laid out end to end.
able” (r.e.) and “recursive”, respectively, following recommendations in [Soa96].
10Recall that 1 is the notation in O for the ﬁnite ordinal 1.
11Intuitively, for u, v ∈O, u +o v is a program for laying out the ordinal u o followed by the ordinal v o to form
the ordinal u +o v o. ×o, and {··}o are for standardly iterating this action of +o.
5

A lim{w2}o-procedure is one that can revise the number of further mind changes it may make “ω”
times; that is, it can computably pick any number as the number of such revisions it can make.12
Suppose w ∈O is for ω. For each n > 0, we next give a fairly natural example below (based
on pattern languages) of a function fn that is limwn-computable, but not limwn−1-computable. A
pattern language is (by deﬁnition) one generated by all the positive length substitution instances in a
pattern, such as, for example, abXYcbbZXa — where the variables (for substitutions) are depicted in
upper case and the constants/terminals in lower case.13 Let Dj denote the ﬁnite set with canonical
index j and let Wi be the c.e. set which is the domain of program i in our ﬁxed acceptable system
[Rog67]. Suppose n > 0. By careful modiﬁcation of the proofs of [JS97, Theorem 1 and Corollary 1,
pages 74–80], we have that, for each n > 0, there exists a total function fn such that,
(a) for each i, j, if Wi happens to be the union of 1 to n pattern languages and fn(i) = j, then
Dj is a set of (code numbers of) 1 to n patterns, the union of whose corresponding pattern
languages is Wi, and,
(b) for each w ∈O for ω, fn is limwn-computable, but not limwn−1-computable.
N.B. The notations featured above are natural ones for the corresponding ordinals — natural
for those of us accustomed to thinking in terms of building ordinals from, for example, ﬁnite
ordinals and ω by +, ×, etc. From Theorem 55 below in Section 4.2, we have, for example, a not
so natural notation v for ω2 such that f3 from just above is limv-computable! This illustrates why
we emphasize that our counters for counting down are notations for ordinals (and not ordinals
themselves).14 On the other hand, as we note in the last paragraph of Section 4.2 below, by an
obvious embedding, our Strong Hierarchy Theorem (Theorem 40 below) mutatis mutandis also holds
for some weaker systems of notations than O, including non-maximal systems based on exponential
polynomials in ﬁnite ordinals, ω, . . . . Such latter systems may have no “problematic” notations,
but the corresponding hierarchies are not as extensive as those based on O. By Theorem 59 (also
in Section 4.2) the interestingly “problematic” O-notations don’t appear for ordinals below ω2.
1.3
Informal Summary of Results
By Theorems 20 and 23 in Section 3, we have that, for all n ∈N, LimnMex = Mex and, for all
u, u′ ∈O and notations w for ω, such that u ≤o u′ <o u×ow, Limu′Mex = LimuMex. Hence, this
suggests, for LimuMex strict hierarchies, we should examine leaps of notation from u to u ×o w,
where w is a notation for ω.
One of our main results, the Strong Hierarchy Theorem (Theorem 40 in Section 3 below) implies
that the collapses of Theorems 20 and 23 are optimal for u’s along certain natural <o-paths. In
12This characterization of counting down from {w2}o very much depends on the use of this particular notation for
ω2. See below for more on such dependence on notation for ordinals ω2 and higher.
13The pattern languages were formally introduced by Angluin [Ang80]. Since then, much work has been done
on pattern languages [Sal94a, Sal94b, CJK+01] and ﬁnite unions thereof [Shi83, Wri89, KMU95, BUV96, CJLZ99].
Nix [Nix83] as well as Shinohara and Arikawa [SA95] outline interesting applications of pattern inference algorithms.
For example, pattern language learning algorithms have been successfully applied toward some problems in molecular
biology (see [SSS+94, SA95]). Pattern languages and ﬁnite unions of pattern languages turn out to be subclasses of
Smullyan’s [Smu61] Elementary Formal Systems (EFSs), and Arikawa, Shinohara and Yamamoto [ASY92] show that
the EFSs can also be treated as a logic programming language over strings. The investigations of the learnability of
subclasses of EFSs are interesting because they yield corresponding results about the learnability of subclasses of logic
programs. Hence, these results have relevance for Inductive Logic Programming (ILP) [MR94, LD94, BM95, Mit97].
14Of course algorithmic counting down would seem to require working with a ﬁnite object/program such as a
notation instead of a possibly inﬁnite object such as an ordinal.
6

particular it yields, for v, w ∈O where w is for ω,
(i) Lim{wv}oMex ⊂Lim{wv}o×owMex, and
(ii) [v is a notation for a limit ordinal ⇒(∀u <o v)[Lim{wu}oMex ⊂Lim{wv}oMex]].
Hence, for example, for w ∈O for ω, Theorem 40 implies the hierarchy shown in Figure 1.15
Mex
⊂
LimwMex ⊂Lim{w2}oMex ⊂. . . ⊂Lim{wn}oMex ⊂. . .
⊂
Lim{ww}oMex ⊂Lim{w(w+o1)}oMex ⊂. . . ⊂Lim{w(w+on)}oMex ⊂. . .
⊂
Lim{w(w×o2)}oMex ⊂Lim{w(w×o2)+o1}oMex ⊂. . . ⊂Lim{w(w×o2)+on}oMex ⊂. . .
⊂
Lim{w(w×o3)}oMex ⊂. . .
...
⊂
Lim{w{w2}o}oMex ⊂. . . ⊂Lim{w{w2}o+on}oMex ⊂. . .
⊂
Lim{w{w2}o+ow}oMex ⊂. . . ⊂Lim{w{w2}o+o(w+on)}oMex ⊂. . .
⊂
Lim{w{w2}o+o(w×o2)}oMex ⊂. . . ⊂Lim{w{w2}o+o((w×o2)+on)}oMex ⊂. . .
⊂
Lim{w{w2}o+o(w×o3)}oMex ⊂. . .
...
⊂
Lim{w{w2}o×o2}oMex ⊂. . .
...
⊂
Lim{w{w3}o}oMex ⊂. . .
...
⊂
Lim{w{ww}o}oMex ⊂. . .
...
Figure 1: Example optimal hierarchy along a natural <o-path for ordinals < ǫ0.
The hierarchy of Figure 1 extends, for example, to certain notations for the ǫ numbers and
beyond too (see the discussion after Theorem 40 in Section 3 below).
Theorem 40 features notations in O of the form {wv}o, where w is for ω. Our other main result,
the General Hierarchy Theorem (Theorem 32 in Section 3 below), holds for any notations u ∈O,
but the hierarchy it speciﬁes is not as tight as that of Theorem 40. Theorem 32 yields, for all
u ∈O, for all w for ω, LimuMex ⊂Lim{(u+o2)w}oMex.
Theorem 32 implies, for example, there are inﬁnite, inﬁnitely ramifying hierarchies of our par-
simony restricted learning criteria which lie along <o-paths, which paths have notations for each
constructive ordinal (see the discussion following the proof of Theorem 32 and see Corollary 33).
The use of O (instead of other systems mentioned in this paper) enables us to have both Theorem 40
and Corollary 33.
15We note that by our carefully chosen deﬁnitions of +o, ×o, and {··}o, the following example equivalences, used
in this hierarchy, hold: w +o w = w ×o 2 and {ww}o ×o w = {ww+o1}o.
7

Section 4, which presents further and preliminary results and open questions, is divided into
three sections.
Section 4.1 presents some preliminary results involving parsimony factors obtained by iterating
the limit taking process. Theorems 47 and 49 essentially characterize all the criteria Lim2
u2,u1Mex,
where, for the associated parsimony factors, the ﬁrst limit taken is restricted to ≤o u1 mind changes,
and the second limit taken is restricted to ≤o u2 mind changes. For example, by Theorem 47, for
notations w2, w1 for ω, Lim2
w2,w1Mex = Ex. Theorem 53 yields Lim3
1,2,2Mex = Ex.
In Section 4.2, by Theorem 60, for u, v ∈O for the same ordinal < ω2, LimuMex = LimvMex,
but, by Corollary 58, for each constructive ordinal α ≥ω2, there exist notations u, v for α such that
LimuMex ̸= LimvMex. It is also seen, in this same section, that if we deﬁne, for constructive
ordinals α, LimαMex def
= S
u for α LimuMex, then there are only three distinct criteria of the
form LimαMex, and they are in ⊂-order: Mex ⊂LimωMex ⊂Limω2Mex. This contrasts with
the subtle and ﬁnely graded and ramiﬁed inﬁnite LimuMex-hierarchies based instead on u’s ∈O.
In Section 4.3 we recall the deﬁnition of the criteria Exu, for u ∈O, essentially from [FS93].
This is a variant of Ex where the learning or inductive inference machines themselves make ≤o u
mind changes. From Theorems 62 and 66, we have that Mex ̸⊆S
u∈O Exu, and, for all u, w ∈O
such that w is for ω, Exw×o(u+o1) ̸⊆LimuMex. However, by Theorem 63, for all u ∈O, for all w
for ω, Exu ⊂Lim{(u+o2)w}oMex. Also, by Theorem 64, for u, v, w ∈O such that u <o {wv}o and
w is for ω, we have, Exu ⊂Lim{wv}oMex.
2
Preliminaries
This section includes formal deﬁnitions from inductive inference, a description of notations for
constructive ordinals, formal deﬁnitions for O-countdown functions and the LimuMex criteria
mentioned above, and other necessary terminology.
2.1
Notation
As noted earlier, N denotes the set of natural numbers, {0, 1, 2, 3, . . .}. N + denotes the set of
positive natural numbers, {1, 2, 3, . . .}. i, j, k, m, n, p, q, s, t, w, x, y, z (with or without subscripts,
superscripts, . . . ) range over N. ∗denotes a non-member of N such that (∀n ∈N)[n < ∗< ∞] (∗
represents ‘unbounded but ﬁnite’). u, v, range over N ∪{∗}. X, Y, Z, (with or without superscripts,
subscripts, . . . ) range over subsets of N.
∅denotes the empty set. ∈, ̸∈, ⊆, ⊂, ⊇, ⊃respectively denote ‘is a member of’, ‘is not a member
of’, ‘is a subset of’, ‘is a proper subset of’, ‘is a superset of’ and ‘is a proper superset of’. ↑denotes
‘is undeﬁned’. ↓denotes ‘is deﬁned’.
For S, a subset of N, card(S) denotes the cardinality of S. So then, ‘card(S) ≤∗’ means
that card(S) is ﬁnite. max(S) and min(S) denote, respectively, the maximum and minimum of
the set S, where max(∅) = 0 and min(∅) = ∞. f, g, h and F, G, H (with or without subscripts,
superscripts, . . . ) range over total functions with arguments and values from N. We say that g
dominates f ⇔(∀x)[g(x) ≥f(x)]. ψ ranges over partial functions with arguments and values from
N. range(ψ) denotes the range of ψ. The set of all total computable functions of one variable is
denoted by R. C, S (with or without subscripts, superscripts, . . . ) range over subsets of R. P
(with or without subscripts, superscripts, . . . ), ranges over predicates with arguments from N.
8

⟨·, ·⟩stands for an arbitrary, computable, one-to-one encoding of all pairs of natural numbers
onto N that is strictly monotonically increasing in both arguments [Rog67]. Similarly, ⟨·, . . . , ·⟩
can be used for encoding tuples of n numbers onto N.
πn
i denote the corresponding inverses:
πn
i (⟨x1, . . . , xn⟩) = xi.
As in Section 1.1 above ϕ denotes a ﬁxed acceptable programming system. Wp denotes the
domain of ϕp. Φ denotes an arbitrary ﬁxed Blum complexity measure for the ϕ-system [Blu67].16
We let
ϕp,s(x) =
 ϕp(x),
if x ≤s and Φp(x) ≤s;
↑,
otherwise.
As deﬁned earlier in Section 1.1, for a computable function f, MinProg(f) def
= min({p | ϕp = f}).
The quantiﬁer ‘∀∞’ means ‘for all but ﬁnitely many’; ‘∃∞’ means ‘there exists inﬁnitely many’;
and, ‘∃!’ means ‘there exists a unique’.
2.2
Inductive Inference Criteria and Identiﬁcation
In this section, we present relevant deﬁnitions and results from computability-theoretic learning
theory.
If ψ is deﬁned at least on 0, 1, . . . , n−1, then let ψ[n] denote the sequence ψ(0), ψ(1), . . . , ψ(n−1).
Let SEG be the set of sequences of natural numbers, i.e., the set of all f[n], where f ∈R and n ∈N.
A learning machine [Gol67, BB75, CS83] is a computable mapping from SEG into N ∪{?}.
Natural number outputs are interpreted as programs in the ϕ-system.
Initially, a learning
machine is allowed to output ?’s to indicate that it has not decided on its ﬁrst program output
yet, but once it outputs some program, it is not allowed to output ?’s again. We say that M(f)
converges to p (written M(f)↓= p) iﬀ(∀∞n)[M(f[n]) = p]; M(f) is undeﬁned if no such p exists
(written M(f)↑).
Deﬁnition 2 (Gold [Gol67], Blum–Blum [BB75], Case–Smith [CS83])
(a) M Ex–identiﬁes f (written: f ∈Ex(M)) def
⇔(∃i | ϕi = f)[M(f)↓= i].
(b) Ex = {S | (∃M)[S ⊆Ex(M)]}.
A machine M that Ex–identiﬁes f eventually converges to a program for f in the ϕ system. The
criterion Ex is, however, independent of the acceptable programming system from which programs
for functions are learned.17 In other words, if ψ is any acceptable programming system, and Exψ
is deﬁned just as Ex is deﬁned in Deﬁnition 2, except ϕ is replaced by ψ (therefore the outputs of
inductive inference machines are interpreted as programs in the ψ system), then Exψ = Ex.
The criterion Mex (Deﬁnition 3 just below) is also independent of the underlying acceptable
programming system [Fre75].
Deﬁnition 3 (Freivalds [Fre75], Chen [Che82])
(a) Suppose g is a total (not necessarily computable) monotonically non-decreasing function.
Then, a learning machine M g-Mex–identiﬁes f (written: f ∈g-Mex(M)) def
⇔M Ex–identiﬁes f
and M(f) ≤g(MinProg(f)).
16For example, if ϕ is based on Turing machines, we could take Φp(x) to be the number of Turing machine steps
Turing machine p executes on input x (undeﬁned if inﬁnite).
17This result easily follows from the deﬁnition of Ex and the fact that any two acceptable programming systems
are computably isomorphic [Rog58, Rog67].
9

(b) A learning machine M Mex-identiﬁes S def
⇔there exists a computable monotonically non-
decreasing g such that S ⊆g-Mex(M).
(c) Mex = {S | (∃M)[M Mex-identiﬁes S]}.
In the deﬁnition just above, the g’s represent parsimony factors by which the parsimony con-
straints are loosened. The ﬁnal programs are, in a sense, nearly-minimal-size. Kinber was ﬁrst
[Kin74, Fre75] to show that Mex ⊂Ex.
Nearly minimal size program inference, as deﬁned by Mex, requires that the ﬁnal program size
be within a computable parsimony factor of the actual minimum program. In the present paper,
we relax the computable parsimony factor constraint imposed by Mex and investigate whether
learning power is thereby enhanced. One way we do so is by allowing lim-computable parsimony
factors. It will be convenient to refer sometimes to lim-computable functions as lim∗-computable
functions — and their formal deﬁnition is handled with the next two deﬁnitions.
Deﬁnition 4 Suppose h : (N × N) →N. Then,
lim
t→∞h(x, t) def
=

y,
if (∀∞t)[h(x, t) = y];
↑,
otherwise.
We write h(x, ∞) for lim
t→∞h(x, t).
Deﬁnition 5
(a) g : N →N is lim∗-computable def
⇔(∃computable h : (N ×N) →N)(∀x)[g(x) = h(x, ∞)].
(b) g : N →N is lim∗-computable as witnessed by h def
⇔h computable: (N × N) →N and
(∀x)[g(x) = h(x, ∞)].
Intuitively, in Deﬁnition 5, h(x, t) is the output at discrete time t of a mind changing algorithm
for g (acting on input x). (∀x)[g(x) = h(x, ∞)], for h computable, means, then, that, for all x, at
all but ﬁnitely many times t, the output of the mind changing algorithm on input x is g(x).
It is easy to show that
(∃lim-computable g)(∀computable f)(∀∞x)[g(x) > f(x)].
We can extend Deﬁnition 5 to deﬁne lim∗-computable functions from N n →N, for n > 1. We
omit the details.
Deﬁnition 6
(a) A learning machine M Lim∗Mex–identiﬁes S def
⇔there is a monotonically non-decreasing
lim-computable function g such that, S ⊆g-Mex(M).
(b) Lim∗Mex = {S | (∃M)[M Lim∗Mex–identiﬁes S]}.
Hence, our deﬁnition requires that the machines converge to a program that is not-so-nearly-
minimal-size.
We mostly write LimMex instead of Lim∗Mex.
Chen [Che82] showed that
LimMex ⊂Ex. From Corollary 35 in Section 3, Mex ⊂LimMex.
In Deﬁnition 5, the underlying mind-changing algorithm is allowed to change its mind a ﬁnite,
yet unbounded, number of times. One may, of course, consider the eﬀects of restricting the number
of mind changes of such algorithms.
10

As noted earlier, in the context of computability-theoretic learning theory, Freivalds and
Smith [FS93] ﬁrst introduced the use of notations for constructive ordinals to bound mind changes.
In this paper, we use notations for constructive ordinals to bound the mind changes in procedures
for lim-computable functions.
We will formally deﬁne, for each notation u ∈O, the concept
of a limu-computable function below (Deﬁnition 10).
We will then use (non-decreasing) limu-
computable functions as parsimony factors.
But ﬁrst, we present an introduction to O, constructive ordinals, and needed associated prop-
erties.
2.3
O and Constructive Ordinals
We proceed very informally. Some familiarity with a treatment of constructive ordinals such as the
ones in [Rog67, Sac90] may be useful to readers of this section.
In Kleene’s system O [Kle38, Kle44, Kle55, Rog67, Sac90], 20 is (by deﬁnition) the notation for
the ordinal 0. Successor ordinals are those with an immediate predecessor; for example, 1, 2, 3, ω +
1, . . . are successor ordinals with respective immediate predecessors 0, 1, 2, ω, . . . . If u is a notation
for the immediate predecessor of a successor ordinal, then a notation for that successor ordinal is
(by deﬁnition) 2u. All other ordinals are limit ordinals; for example, ω, ω +ω, . . . are limit ordinals.
Kleene [Kle38, Kle44, Kle55, Rog67, Sac90] deﬁned a natural partial ordering of notations, <o, so
that two notations so ordered represent respective ordinals with the second larger than the ﬁrst.
We omit details. Suppose ϕp(0), ϕp(1), ϕp(2), . . . are each notations in <o order. Suppose that
the corresponding ordinals are longer and longer initial segments of some limit ordinal which is
their sup. For example, some such p generates the respective notations for 0, 1, 2, . . . in <o order,
and ω is the sup of this sequence. In general, then, p essentially describes how to build the limit
ordinal which is the sup of the ordinals with notations ϕp(0), ϕp(1), ϕp(2), . . . . A notation for
this limit ordinal is (by deﬁnition) 3 · 5p. Clearly such limit ordinals have inﬁnitely many such
notations, diﬀerent ones for diﬀerent generating p’s. Nothing else is a notation. We deﬁne ‘x =o y’
to mean ‘x, y ∈O and x = y’. As in the literature on constructive ordinals, we use ‘x ≤o y’ for
‘x <o y ∨x =o y’, ‘x ≥o y’ to mean ‘y ≤o x and ‘x >o y’ to mean ‘y <o x’. We also recall the
function
·
o : O →the set of ordinals, deﬁned as follows [Kle38, Kle55, Rog67, Sac90]
1 o
=
0;
2u o
=
u o + 1;
3 · 5p o
=
lim
n→∞ϕp(n) o.
For all x, y ∈O, it is true that, if x <o y then x o < y o. It is also true that, for all y ∈O,
if y o = β, then for every α < β, there is an x such that x <o y and
x o = β. If u ∈O and
u o = α, then we say that u is for α.
It is useful, while reading this paper, to remember that 1 o = 0, 2 o = 1, and 4 o = 2. Hence,
for example, 4 is, then, the notation for the ordinal 2, i.e, 2 = 4.
We shall use the following properties of <o in later proofs.
Fact 7 (Kleene [Kle55]) For all x, y ∈N,
(a) x <o y ⇒x ∈O ∧y ∈O.
(b) x ∈O ⇒1 ≤o x.
(c) x <o y ⇒y ̸= 1.
(d) x <o 2y ⇒x ≤o y.
11

(e) x <o 3 · 5p ⇒(∃n)[x <o ϕp(n)].
(f) x ≤o z ∧y ≤o z ⇒x <o y ∨x =o y ∨x >o y.
The following fact about notations will also be used.
Fact 8 (Rogers [Rog67], Sacks [Sac90]) There exist computable functions h1 and h2 such that,
for all v ∈O,
(a) Wh1(v) = {u | u <o v};
(b) Wh2(v) = {⟨u1, u2⟩| u1 <o u2 <o v} is a well-ordering isomorphic to v o.
2.4
O-Countdown Functions and Learning Criteria
Deﬁnition 9
A computable mapping F : (N × N) →O is an O-countdown function def
⇔for all
x, t, F(x, t + 1) ≤o F(x, t).
Intuitively, h in Deﬁnition 10 just below plays a similar role to h in Deﬁnition 5, and the
function F in Deﬁnition 10 serves as a “transﬁnite” counter that counts down from a preset value.
As before, t can be thought of a discrete time paramenter. Further explanation is given just after
Deﬁnition 10.
Deﬁnition 10 Suppose u ∈O. g : N →N is limu-computable def
⇔there exists a computable
function h : (N × N) →N and an O-countdown function F, such that, for all x and t,
(a) g(x) = h(x, ∞),
(b) F(x, 0) ≤o u, and
(c) h(x, t + 1) ̸= h(x, t) ⇒F(x, t + 1) <o F(x, t).
We deﬁne limu-computable as witnessed by F and h along the lines of part (b) of Deﬁnition 5;
we omit the details.
Part (b) of Deﬁnition 10 initializes the transﬁnite counter at ≤o u. From Fact 7(a), it follows
that part (c) restricts the counter values to be notations ∈O. By Fact 8, the notations <o u are
well-ordered; hence, part (c) also implies that the counter cannot descend inﬁnitely. Part (c) also
guarantees that, when h has a mind change, then the counter must decrement. This part does not
restrict how much it decrements. It also allows the transﬁnite counter to decrement without an
accompanying mind change in h. Note that parts (b) and (c) imply that h(y, ∞) is deﬁned and
part (a) deﬁnes g(y) to be the value h(y, ∞). Thus, F acts as a countdown function that starts
with a notation in O and then counts down.
In Deﬁnition 11 below, we use (non-decreasing) limu-computable functions as parsimony factors.
This is similar to what we did in Deﬁnition 6. When limu-computable functions are so used as
parsimony factors, we shall ofter refer to them as parsimony factors of order u.
Deﬁnition 11
Suppose u ∈O. Then,
(a) A learning machine M LimuMex–identiﬁes S def
⇔there is a monotonically non-decreasing
limu-computable function g such that, S ⊆g-Mex(M).
(b) LimuMex = {S | (∃M)[M LimuMex–identiﬁes S]}.
In Deﬁnition 11 just above, we restrict the parsimony factor, g, to be monotonically non-
decreasing. The reason is that then (but not otherwise) the LimuMex criteria are easily shown
to be independent of the underlying acceptable system. It even turns out (and is easy to show)
that there is a lim1-computable function g such that, for no n ∈N and for no limn-computable,
monotonically non-decreasing function g′ do we have that g′ dominates g.
12

2.5
Basic Properties of O-Notations
We need the results of this section regarding addition, multiplication and exponentiation of ordinal
notations; as noted above, these operations are denoted +o, ×o and {··}o respectively. Recall from
Section 1.2 above that our +o and ×o feature extra base cases over what would be needed merely
to get the embedding into the corresponding ordinal operations and that these extra base cases are
to ensure some additional technically useful properties.
In unparenthesized expressions involving these operations, {··}o has higher priority than ×o
which in turn has higher priority than +o.18
Note 12 For these theorems, it is useful to recall that 1 is a notation for 0 and that 2 is a notation
for 1 (i.e., 1 o = 0, 2 o = 1) and that 0 and 7 are not notations (for any ordinal) in the O system
of notations.
Theorem 13 There exists a computable function +o such that, for all x, y ∈N,
x +o y =













y,
if x = 1; (clause i)
x,
if y = 1 ∧x ̸= 0 ∧x ̸= 1; (clause ii)
2(x+om),
if y = 2m ∧m ̸= 0 ∧x ̸= 1; (clause iii)
3 · 5q,
if y = 3 · 5p ∧x ̸= 1, (clause iv)
( where (∀n)[ϕq(n) = x +o ϕp(n)] );
7,
otherwise. (clause v)
Furthermore, q in Clause (iv) just above is a computable, 1–1 function of x and p.
Proof.
The proof is an easy modiﬁcation of that of [Rog67, Theorem XVII, Chapter 11, pages 209-210]
and uses the 1–1 Parametric Recursion Theorem.19
The 1–1-ness of q in Theorem 13 is crucial for proving the right-to-left implication of part (e)
of Theorem 14, which in turn is necessary for proving many results that follow.
The just above theorem is a modiﬁcation of a theorem in [Kle55]. The ﬁrst Clause (clause (i))
has been added in order to make +o have the useful property: for all y, 1 +o y = y (i.e., for all
y, 0 +o y = y), which is not true without the special handling of the x = 1 case.20 This property
is used, for example, in the proof of Lemma 37. As in [Kle55], we treat the x = 0 case specially
(doing so helps to ensure that 0+o 2 = 27 (and not 1), which is essential in proving the right-to-left
side of Theorem 14(a).)
Theorem 14 For all x, y and z ∈N,
(a) x, y ∈O ⇔x +o y ∈O.
(b) x, y ∈O ⇒x +o y o = x o + y o.
(c) x, y ∈O ∧y ̸= 1 ⇒x <o x +o y.
(d) x, y ∈O ∧z <o y ⇔x +o z <o x +o y.
(e) x ∈O ∧z =o y ⇔x +o z =o x +o y.
(f) y ∈O ∧x ≤o z <o x +o y ⇔(∃y′)[y′ <o y ∧x +o y′ =o z].
Furthermore, in the left-to-right implication of (f), y′ is unique.
18Also, we assume that each of these operators has higher priority than <o, ≤o, >o, . . ., which have higher priority
than ∈, =, ̸=, which have higher priority than ∧and ∨, which in turn have higher priority than ⇒and ⇔.
19Our extra base case causes no subtleties with modifying Rogers’ construction.
20Recall from Note 12, 1 is the notation for the ordinal 0.
13

Proof.
The proof is straightforward, but tedious, and involves Fact 7(a-e) and careful application of
transﬁnite induction on notations.21
We note that, similar to the case of + for ordinals, +o for notations is non-commutative; +o is,
however, also non-associative unlike + for ordinals. We adopt the convention that x+oy+oz means
(x +o y) +o z. The non-associativity of +o leads to some subtleties while working with notations,
that are otherwise absent when working with ordinals.
We next deﬁne ×o.22
Theorem 15 There is a computable function ×o such that, for all x, y ∈N,
x ×o y =

















1,
if y = 1 ∨x = 1; (clause i)
y,
if x = 2 ∧y ̸= 1; (clause ii)
(x ×o m) +o x,
if y = 2m ∧m ̸= 0 ∧
x ̸= 1 ∧x ̸= 2; (clause iii)
3 · 5q,
if y = 3 · 5p ∧x ̸= 1 ∧x ̸= 2, (clause iv)
( where (∀n)[ϕq(n) = x ×o ϕp(n)] );
7,
otherwise. (clause v)
Furthermore, q as in Clause (iv) is a computable, 1–1 function of x and p.
Proof.
The proof is also similar to that of [Rog67, Theorem XVII, Chapter 11, pages 209-210] (and
uses the 1–1 Parametric Recursion Theorem).
The 1–1-ness of q in Theorem 15 is crucial for proving the right-to-left implication of part (e)
of Theorem 16, which in turn is necessary for proving many results that follow.
The ﬁrst two Clauses (clauses (i) and (ii)) in the just above Theorem ensure that useful prop-
erties of ×o hold. For example: (a) for all y, 1 ×o y = 1 (i.e., for all y, 0 ×o y = 0); (b) for all y,
2 ×o y = y (i.e., for all y, 1 ×o y = y). Property (b) just listed, is essential, for example, in proving
Lemma 25 presented further below.
Similar to the case of × (usually written ·) for ordinals, ×o for notations is not commutative;
however, × for ordinals is associative, but ×o for notations is not. As for +o, in any unparenthesized
expressions involving ×o, we associate to the left.
Analogous to Theorem 14, we have the following theorem for ×o.
Theorem 16 For all x, y and z ∈N,
(a) x, y ∈O ∨x = 1 ∨y = 1 ⇔x ×o y ∈O.
(b) x, y ∈O ⇒x ×o y o = x o × y o.
(c) x >o 1 ∧y >o 2 ⇒x <o x ×o y.
(d) x >o 1 ∧y ∈O ∧z <o y ⇔x ×o z <o x ×o y.
(e) x = 1 ∨(x ∈O ∧z =o y) ⇔x ×o z =o x ×o y.
(f) y ∈O ∧x ≤o z <o x ×o y ⇔(∃x′ <o x)(∃y′ | 1 <o y′ <o y)[z =o (x ×o y′) +o x′].
Furthermore, in (f)⇒, x′ and y′ are both unique.
21An example of a proof by transﬁnite induction is part of the proof of Theorem 36. See [Kle44, Kle55, Sac90] for
other examples of such inductions.
22See Note 12 regarding the notations 1, 2 ∈O.
14

Proof.
As for +o, the proof is straightforward, but tedious, and involves Fact 7(a-e), Theorem 14(a-f)
and careful application of transﬁnite induction on notations.
Finally, we deﬁne exponentiation for notations in O as follows.23
Theorem 17 There is a computable function {··}o such that, for all x, y ∈N,
{xy}o =





















1,
if x = 1 ∧y ̸= 1; (clause i)
2,
if x = 2 ∨
(y = 1 ∧x ̸= 1 ∧x ̸= 2); (clause ii)
{xm}o ×o x,
if y = 2m ∧m ̸= 0 ∧
x ̸= 1 ∧x ̸= 2; (clause iii)
3 · 5q,
if y = 3 · 5p ∧x ̸= 1 ∧x ̸= 2, (clause iv)
( where (∀n)[ϕq(n) = {xϕp(n)}o] );
7,
otherwise. (clause v)
Furthermore, q as in Clause (iv), is a computable, 1–1 function of x and p.
Proof.
The proof is again similar to that of [Rog67, Theorem XVII, Chapter 11, pages 209-210] (and
uses the 1–1 Parametric Recursion Theorem).
The 1–1-ness of q in Theorem 17 is crucial for proving the right-to-left implication of part (e)
of Theorem 18.
Similar to exponentiation for ordinals, {··}o for notations is neither commutative nor associative.
We note that, in general, for x, y ∈N, {xy}o is quite diﬀerent from xy.
The following are some useful properties of {··}o.
Theorem 18 For all x, y and z ∈N,
(a) x, y ∈O ∧(x ̸= 1 ∨y ̸= 1) ⇒{xy}o ∈O.
(b) x, y ∈O ∧(x ̸= 1 ∨y ̸= 1) ⇒{xy}o o = x
y o
o
.
(c) x >o 2 ∧y >o 2 ⇒x <o {xy}o.
(d) x >o 2 ∧z <o y ⇒{xz}o <o {xy}o.
(e) x >o 2 ∧z = y ∈O ⇒{xz}o = {xy}o ∈O.
(f) x >o 1 ∧x′ <o x ∧y ∈O ⇒{xy}o ×o x′ <o {x(y+o2)}o.
Proof.
As for +o and ×o, the proof is straightforward, but tedious, and involves Fact 7(b-e), Fact 8(b),
Theorem 16(a-d) and careful application of transﬁnite induction on notations.
We note that, with modiﬁcations for special cases, the right-to-left implications of parts (a),
(d), (e) and (f) of Theorem 18 are true, but not necessary for this paper. So also is a property
similar to Theorem 16(f).
23Again, see Note 12 regarding the notations 1, 2 ∈O.
15

3
Main Results
We recall that by Convention 1, for n ∈N, n is the unique notation in O for n. Clearly, we have
Proposition 19 For all u, v ∈O such that u ≤o v,
Mex = Lim0Mex ⊆LimuMex ⊆LimvMex ⊆LimMex ⊆Ex.
The next Theorem shows that one does not always get increased learning power by using
parsimony factors of greater orders. It shows more speciﬁcally that, when boosting the order u to
any order strictly <o the order obtained by multiplying (on the right, with ×o) u by some w for ω,
we get collapse of the corresponding parsimony restricted criteria.
Theorem 20 For all u, u′ ∈O and notations w for ω, such that u ≤o u′ <o u ×o w, Limu′Mex =
LimuMex.
Proof of Theorem 20.
Follows from
Lemma 21 For all u, u′ ∈O and all notations w for ω such that u′ <o u×ow, every monotonically
non-decreasing limu′-computable function is dominated by a monotonically non-decreasing limu-
computable function.
Proof of Lemma 21.
Let u, u′, w ∈O, where w o = ω, be such that u′ <o u ×o w. Using the
deﬁnition of ×o and Fact 7(e), there exists k ∈N such that u′ <o u×o k. Clearly, such a k must be
greater than 0. Hence, it suﬃces to prove that for each k > 0, every monotonically non-decreasing
limu×ok-computable function is dominated by a monotonically non-decreasing limu-computable
function.
Therefore, suppose k > 0 and g is a monotonically non-decreasing limu×ok-computable function
as witnessed by h and F. Therefore, for all x, F(x, 0) ≤o u ×o k. Let k′ be the largest integer,
0 ≤k′ ≤k, such that, for all but ﬁnitely many x, F(x, ∞) ≥o u ×o k′. Let xm be such that, for all
x ≥xm, F(x, ∞) ≥o u ×o k′.
Clearly, by our choice of k′ and xm, there exist inﬁnitely many x ≥xm such that u ×o k′ ≤o
F(x, ∞) <o u ×o k′ + 1. Also, using Fact 8(a), X = {x ≥xm | u ×o k′ ≤o F(x, ∞) <o u ×o k′ + 1}
is computably enumerable. Let Y = {y0 < y1 < . . .} be an inﬁnite computable subset of X.
We now deﬁne h′, F′ as follows.
For all x, let h′(x, 0) = h(yx, t′), where t′ is the least number such that F(yx, t′) <o u ×o k′ + 1;
for t > 0, h′(x, t) = h(yx, t′ + t).
For all x, let F′(x, t) = u′, where F(yx, t′+t) = u×ok′+ou′ (u′ can be eﬀectively found as follows:
since u×ok′ ≤o F(yx, t′+t) <o u×ok′+ou, by Theorem 14(f), (∃! u′ <o u)[F(yx, t′+t) = u×ok′+ou′];
then, using Fact 8(a), we can eﬀectively ﬁnd this u′).
Let g′(x) = h′(x, ∞). It is easy to verify that for all x, g′(x) ≥g(x), and g′ is monotonically
non-decreasing, and that h′ and F′ witness that g′ is limu-computable.
(Lemma 21)
Clearly, the theorem follows from Lemma 21.
(Theorem 20)
When u is a notation for a ﬁnite ordinal, we can get the following result.
Lemma 22 For all n ∈N, every monotonically non-decreasing limn-computable function is dom-
inated by a monotonically non-decreasing computable function.
16

Proof.
From Lemma 21, we get that for every n > 0, every monotonically non-decreasing limn-
computable function is dominated by a monotonically non-decreasing lim1-computable function.
Hence, it is suﬃcient to prove that every monotonically non-decreasing lim1-computable function
is dominated by a monotonically non-decreasing computable function.
Therefore, suppose g is a monotonically non-decreasing lim1-computable function as witnessed
by h and F. Hence, for each x, there exists at most one t such that h(x, t) ̸= h(x, t + 1).
Case 1: (∀∞x)(∀t)[h(x, t) = h(x, t + 1)].
In this case, let x0 be such that (∀x ≥x0)(∀t)[h(x, t) = h(x, t + 1)]. Deﬁne g′ as follows: for all
x, g′(x) = h(x0 + x, 0).
Case 2:. Not Case 1.
Let X = {x | (∃t)[h(x, t) ̸= h(x, t + 1)]}. Let Y = {y0 < y1 < . . .} be an inﬁnite computable
subset of X. Deﬁne g′ as follows: for all x, g′(x) = h(yx, t + 1), where t is such that h(yx, t) ̸=
h(yx, t + 1); clearly, by the properties of h and Y , there is exactly one such t for each y ∈Y .
Also, in both the above cases, g′ is computable, monotonically non-decreasing and dominates
g.
Hence, we get
Theorem 23 For all n ∈N, LimnMex = Mex.
One of our main results, our Strong Hierarchy Theorem (Theorem 40 below), shows that the
collapses of the previous two theorems are optimal for parsimony orders along naturally associated
<o-paths. Before we present our Strong Hierarchy Theorem, we present another of our main results,
our General Hierarchy Theorem, as the next theorem (Theorem 32 below). To do this, we require
some preliminary results.
As noted earlier, parsimony factors are always monotonically non-decreasing (limu-computable)
functions. In constructions below, we sometimes ﬁrst deﬁne limu-computable functions that are
not necessarily monotonically non-decreasing, before we deﬁne appropriate parsimony factors that
dominate them. Lemma 24 below gives us useful suﬃcient conditions to determine the orders of so
obtained dominating parsimony factors.
Lemma 24 Suppose u ∈O. Suppose {ψn | n ∈N} is a family of (partial) computable functions,
where each ψn is a function from N n+1 to N (which are deﬁned when all their arguments ≤o u),
with the following three properties:
(1) For un, . . . , u0 ≤o u, ψn(un, . . . , u0) can be obtained eﬀectively from n and un, . . . , u0.
(2) For each n, ψn is strictly monotonically increasing (with respect to ≤o) on each of its
arguments (as long as its arguments are ≤o u).
(3) For each n, ψn(u, . . . , u) <o ψn+1(u, . . . , u).
Let v be a notation for limn→∞ψn(u, . . . , u) o, obtained using any computable procedure that
generates, in increasing order w.r.t <o, an inﬁnite subset of {z ≤o ψn(u, . . . , u) | n ∈N}. Then,
every limu-computable function f is dominated by a monotonically non-decreasing limv-computable
function f′ (i.e., for all x, f(x) ≤f ′(x)).
Proof. Suppose the hypotheses. Suppose f is limu-computable as witnessed by h and F. We will
deﬁne a function f ′ bounding f, which is limv-computable as witnessed by h′ and F′ deﬁned below.
17

Let
h′(x, t)
=
max({h(x′, t) | x′ ≤x})
F′(x, t)
=
ψx+1(F(0, t), F(1, t), . . ., F(x, t))
f′(x)
=
h′(x, ∞).
It is easy to verify that f ′, h′, F′ satisfy the properties as claimed.
Lemma 25 Suppose u, w ∈O and w is for ω. Then, for each limu-computable g, there exists a
monotonically non-decreasing lim{(u+o1)w}o-computable g′, such that g′ dominates g.
Proof of Lemma 25.
If g is a lim0-computable function, then it is clearly computable. Deﬁne g′(x) = max({g(i) |
i ≤x}). Clearly, g′ is computable, monotonically non-decreasing, and dominates g. Also, for all w
for ω, {(0+o 1)w}o = 1. Since every computable function is also lim1-computable, the lemma holds
for u = 0.
For the u > 0 cases, we will use Lemma 24. Let ψn be deﬁned recursively as follows (Note:
we are only interested in deﬁning ψn on arguments ≤o u; by Fact 8(a), doing so is algorithmically
possible.)
Firstly, for all i ∈N, let
vi = {(u +o 1)i}o.
For all u0 ≤o u, let
ψ0(u0) def
= u0.
For all n > 0, for all u0, . . . , un ≤o u, let
ψn(un, . . . , u0) def
= (vn ×o un) +o ψn−1(un−1, . . . , u0)
We note that ψn(un, . . . , u0) is just the summation of vn ×o un, . . . , v1 ×o u1, u0 in a right
associative manner. Clearly, {ψn | n ∈N} satisﬁes property (1) of Lemma 24.
Claim 26 For all n, for all u0, . . . , un ≤o u, we have that ψn(un, . . . , u0) <o vn+1.
Proof of Claim 26.
We prove this Claim by induction on n.
Base Case: n = 0.
ψ0(u0) = u0. Also, v1 = {(u +o 1)1}o = u +o 1. Since u0 ≤o u, we get ψ0(u0) <o v1.
Inductive Case: Suppose the claim is true for n = k (Inductive Hypothesis (IH)).
We will show that it holds for n = k + 1.
ψk+1(uk+1, . . . , u0) = vk+1 ×o uk+1 +o ψk(uk, . . . , u0) <o (by IH) vk+1 ×o uk+1 +o vk+1 = (by
Theorems 13 and 15) vk+1 ×o (uk+1 +o 1) = {(u +o 1)k+1}o ×o (uk+1 +o 1); also, since uk+1 ≤o
u, we get24 that uk+1 +o 1 ≤o u +o 1, and then, by parts (d) and (e) of Theorem 16, we get
{(u+o1)k+1}o×o(uk+1+o1) ≤o {(u+o1)k+1}o×o(u+o1) = (by Theorem 17) {(u+o1)k+2}o = vk+2.
(Claim 26)
From Claim 26 and the deﬁnitions of ψn’s, we get for all n, ψn(u, . . . , u) <o vn+1 ≤o (since
u >o 0) ψn+1(u, . . . , u). Hence, {ψn | n ∈N} satisﬁes property (3) of Lemma 24.
24Proof: If uk+1 = u, then uk+1 +o 1 = 2uk+1 = 2u = u +o 1; otherwise, if uk+1 <o u, then using the contrapositive
of Fact 7(d), we get uk+1 +o 1 ≤o u, which, by Theorem 14(c), is <o u +o 1. Therefore, uk+1 +o 1 ≤o u +o 1.
18

Claim 27 Suppose n, un, . . . , u0 and u′
n, . . . , u′
0 are given such that for i ≤n, each ui, u′
i ≤o u,
and, there exists a j ≤n, such that
(a) for all j′, j < j′ ≤n, uj′ = u′
j′.
(b) uj <o u′
j.
Then ψn(un, . . . , u0) <o ψn(u′
n, . . . , u′
0).
Proof of Claim 27.
Suppose the hypotheses.
To show the claim, it suﬃces to show that for all j ≤n, ψj(uj, . . . , u0) <o (vj ×o u′
j). For then,
since uj = u′
j for all j′ such that j < j′ ≤n, we get
ψn(u′
n, . . . , u′
0)
=o
((vn ×o u′
n) +o (. . . +o ((vj+1 ×o u′
j+1) +o (vj ×o u′
j)) . . .))
=o
((vn ×o un) +o (. . . +o ((vj+1 ×o uj+1) +o (vj ×o u′
j)) . . .))
>o
((vn ×o un) +o (. . . +o ((vj+1 ×o uj+1) +o ψj(uj, . . . , u0)) . . .))
=o
ψn(un, . . . , u0).
We proceed with the proof of Claim 27. If j = 0, then ψ0(u0) = u0 <o u′
0. Also, by Theorem 17
we have that v0 = 1. Furthermore, since we ensured that for all y, 1 ×o y = y (as noted a few
paragraphs after Theorem 15), we get u′
0 = (v0 ×o u′
0). Hence, ψ0(u0) <o (v0 ×o u′
0).
If j > 0, then we have
ψj(uj, . . . , u0)
=o
(vj ×o uj) +o ψj−1(uj−1, . . . , u0)
<o
(vj ×o uj) +o vj
(by Claim 26)
=o
(vj ×o (uj +o 1))
(by Theorem 15)
≤o
(vj ×o u′
j).
(by Fact 7(d), Theorem 16)
(Claim 27)
Thus ψn is monotonically increasing in each of its arguments (as long as they are ≤o u).
Hence, property (2) of Lemma 24 is satisﬁed by {ψn | n ∈N}.
We note that, for all n,
ψn(u, . . . , u) <o {(u +o 1)n+1}o <o (by Theorem 18(d)) {(u +o 1)w}o, for any w for ω.
Also,
for all n, limn→∞ψn(u, . . . , u) o = ( u +o 1 o)ω. Hence, taking v = {(u +o 1)w}o in Lemma 24,
Lemma 25 follows.
(Lemma 25)
We next deﬁne, for each u ∈O, a useful, self-referential class of computable functions, Cu,
that helps to establish our Hierarchy Theorems: Cu is learnable with parsimony factors of order
{(u +o 2)w}o, for any w for ω (Lemma 30); however, Cu is not learnable with parsimony factors of
order u (Lemma 31).
We recall that ⟨·, ·, ·, ·⟩denotes a computable bijection from N × N × N × N onto N and that
π4
i , 1 ≤i ≤4, denote the corresponding projection functions (i.e π4
i (⟨x1, x2, x3, x4⟩) = xi).
Deﬁnition 28 Suppose u ∈O. Then,
Cu = {f | for some p
(a) limx→∞π4
1(f(x))↓= p ∧ϕp = f, and
(b) limx→∞π4
2(f(x))↓≥p, and
(c) π4
3(f(0)) ≤o u, and
(d) (∀x)[π4
3(f(x + 1)) ≤o π4
3(f(x))], and
(e) (∀x)[π4
2(f(x)) ̸= π4
2(f(x + 1)) ⇒π4
3(f(x + 1)) <o π4
3(f(x))].
}
19

It is helpful to note the following facts about the just above deﬁnition. Values in the range
of each f ∈Cu are interpreted as quadruples; on inputs 0, 1, 2, . . . to f, the ﬁrst elements of these
quadruples may vary but they eventually settle down at some number, say p; the second elements
settle down at a number ≥p; the third elements form a non-increasing (w.r.t. ≤o) chain of notations
in O constrained to decrease whenever there is a mind change in the corresponding second elements;
ﬁnally, the fourth elements of the quadruple are completely unrestricted (which freedom we use in
the diagonalization in step 4 of the proof of Lemma 31).
Lemma 29 For every u ∈O, there exists a limu+o1-computable g (which is not necessarily mono-
tonically non-decreasing) and a machine M such that,
(a) M Ex-identiﬁes Cu and
(b) for all ϕi ∈Cu, M(ϕi) ≤g(i).
Proof. Let M be deﬁned as follows. M(f[0]) = 0; for n > 0, M(f[n]) = π4
1(f(n −1)).
Let h and F be deﬁned as follows.
For all i, let h(i, 0) = 0, F(i, 0) = u +o 1.
For all i, t, we deﬁne h(i, t + 1), F(i, t + 1) as follows.
begin computation of h(i, t + 1), F(i, t + 1).
if Φi(0) > t
then
Let h(i, t + 1) = h(i, t) and F(i, t + 1) = F(i, t);
else
Let x be the largest value ≤t, such that (∀x′ ≤x)[Φi(x) ≤t].
Enumerate S = {u′ | u′ <o F(i, t)} for t steps using a ﬁxed enumerator.
(This is possible since S is uniformly c.e. in F(i, t), by Fact 8(a).)
if π4
3(ϕi(x)) ∈S within t steps of the ﬁxed enumeration above
then
Let h(i, t + 1) = π4
2(ϕi(x)) and F(i, t + 1) = π4
3(ϕi(x));
else
Let h(i, t + 1) = h(i, t) and F(i, t) = F(i, t).
endif
endif
end computation of h(i, t + 1), F(i, t + 1).
Let g(i) = h(i, ∞). It is easy to verify that g and M satisfy the requirements of the theorem.
Now, given any u ∈O, by Lemma 29, there exists a limu+o1-computable function g and a ma-
chine M which Ex-identiﬁes Cu such that, for all i, ϕi ∈Cu implies that M(ϕi) ≤g(MinProg(ϕi)).
This g is not necessarily monotonically non-decreasing. However, by noting that the Deﬁnition of
+o gives (u+o 1)+o 1 = u+o 2, and then using Lemma 25, we get that there exists a monotonically
non-decreasing lim{(u+o2)w}o-computable function g′ such that g′ dominates g. Hence, we get the
following.
Lemma 30 For all u ∈O, for all w for ω, Cu ∈Lim{(u+o2)w}oMex.
20

Lemma 31 (∀u ∈O)[Cu ̸∈LimuMex].
Proof. Suppose by way of contradiction that Cu ⊆g-Mex(M), where g is a monotonically non-
decreasing limu-computable function as witnessed by h and F.
Then by the Operator Recursion Theorem [Cas74, Cas94], there exists a 1–1 increasing function
p such that the initial segments (ﬁnite or inﬁnite) ϕp(·) may be deﬁned as follows. Intuitively, while
deﬁning these functions, we attempt to deﬁne ϕp(0) such that ϕp(0) ∈Cu, and, either (a) M(ϕp(0))↓
and MinProg(ϕp(0)) is such that g(MinProg(ϕp(0))) < M(ϕp(0)), or (b) M(ϕp(0))↑; failing this, we
will ensure that for some i > 0, ϕp(i) ∈Cu and either (a) M(ϕp(i))↓and ϕM(ϕp(i)) ̸= ϕp(i), or
M(ϕp(i))↑.
The procedure uses global variables cur bound, cur notation, cur maxindex, cur index, Cancel,
and last mindchange. Then cur bounds, cur notations, cur maxindexs, cur indexs, Cancels, and
last mindchanges denote the values of these variables at the start of stage s.
Initially, we let cur bound0 = h(p(0), 0), cur notation0 = u, cur maxindex0 = cur bound0 + 2.
cur index0 = 1. Cancel0 = ∅, last mindchange0 = 0.
xs denotes the least x such that ϕp(0)(x) has not been deﬁned at the start of stage s. Thus
x0 = 0. Go to stage 0.
Begin stage s.
1.
For x < xs, let ϕp(cur indexs)(x) = ϕp(0)(x).
2.
Let y = xs.
repeat
2.1.
Let ϕp(cur indexs)(y) = ⟨p(cur indexs), p(cur maxindexs), cur notations, 0⟩.
2.2.
If h(p(0), last mindchanges) ̸= h(p(0), y), then go to step 3.
2.3.
If there exists i ≤cur bounds, i ̸∈Cancels, and z, such that xs < z ≤y and Φi(z) ≤y,
then go to step 4.
2.4.
If M(ϕp(cur indexs)[y + 1]) > cur bounds, then go to step 5.
2.5.
Let y = y + 1.
forever
3.
For x ≤y, let ϕp(0)(x) = ϕp(cur indexs)(x).
Decrement notation: cur notations+1 = F(p(0), y).
Change current bound: cur bounds+1 = h(p(0), y).
Change current maximum index: cur maxindexs+1 = cur maxindexs + cur bounds+1 + 2.
Record where the last mind change happened: last mindchanges+1 = y.
Carry forward unchanged all other global variables (cur index and Cancel).
Go to stage s + 1. (Therefore xs+1 = y + 1.)
4.
Let k ∈{0, 1} such that
ϕi(z) ̸= ⟨p(cur indexs), p(cur maxindexs), cur notations, k⟩. For xs ≤x ≤y, let ϕp(0)(x) =
⟨p(cur indexs), p(cur maxindexs), cur notations, k⟩.
Change to next unused index: cur indexs+1 = cur indexs + 1.
Record diagonalized program: Cancels+1 = Cancels ∪{i}.
Carry forward unchanged all other global variables (cur notation, cur bound, cur maxindex,
and last mindchange).
21

Go to stage s + 1. (Therefore xs+1 = y + 1.)
5.
For xs ≤x ≤y, let ϕp(0)(x) = ϕp(cur indexs)(x).
Carry forward unchanged all global variables (cur notation,
cur bound,
cur maxindex,
last mindchange, cur index, and Cancel).
Go to stage s + 1. (Therefore xs+1 = y + 1.)
End stage s.
We now consider the following cases.
Case 1: Each stage is entered and terminates.
Since ordinals are well ordered, step 2.2 can succeed only ﬁnitely often. Thus, (as s goes to inﬁn-
ity) cur notations, cur bounds, cur maxindexs, last mindchanges all stabilize to, say, cur notation,
cur bound, cur maxindex, last mindchange. Now after the last success of step 2.2, step 2.3 can suc-
ceed only ﬁnitely often (≤cur bound+1 times, since each success of step 2.3 cancels a new program
≤cur bound). Thus for all but ﬁnitely many stages, step 2.4 must succeed. It follows, from steps
1 and 5, that ϕp(cur index) = ϕp(0) and M(ϕp(cur index)) outputs a program > h(p(0), ∞) = g(p(0))
inﬁnitely often.
Clearly,
ϕp(0)
∈
Cu.
Also,
since
g
is
monotonically
non-decreasing,
g(p(0))
≥
g(MinProg(ϕp(0))) = g(MinProg(ϕp(cur index))).
Therefore, either M(ϕp(0))↑or M(ϕp(0))↓̸≤
g(MinProg(ϕp(0))).
Thus ϕp(0) ∈Cu −g-Mex(M).
Case 2: Stage s is entered but does not terminate.
In this case ϕp(cur indexs) ∈Cu, but M(ϕp(cur indexs)) either does not converge, or converges to
a program ≤cur bounds. However each of the programs ≤cur bounds either convergently diﬀers
from ϕp(cur indexs) (i.e., is in Cancels) or is undeﬁned on all x > xs (since step 2.3 does not succeed).
Thus, M does not g-Mex-identify ϕp(cur indexs) (In fact, in this case, M does not even Ex-identify
ϕp(cur indexs)).
Theorem 32 (General Hierarchy Theorem) For all u ∈O, for all w for ω, LimuMex ⊂
Lim{(u+o2)w}oMex.
Proof. By Theorem 14(c), we get that for all u, u <o (u +o 2), which, by Theorem 18(c), is
<o {(u +o 2)w}o (we recall that 2 = 221 = 4 >o 2). Hence, the theorem follows from Proposition 19
and Lemmas 31 and 30.
Theorem 32 implies that there are inﬁnite, inﬁnitely ramifying hierarchies of parsimony re-
stricted learning criteria. Furthermore, we have
Corollary 33 There are inﬁnite hierarchies of parsimony restricted learning criteria which lie
along <o-paths, which paths have notations for each constructive ordinal.
Proof. First ﬁx w ∈O for ω.
Let O = {x0, x1, x2, . . .}.
Let y0 = z0 = x0.
Let yn+1 =
{(zn +o 2)w}o.
Let zn+1 = yn+1 +o xn+1.
Then, by Theorem 14 parts (c) and (e), for all n,
yn <o (yn +o xn) +o 2. This latter, by Theorem 18(c), is <o {((yn +o xn) +o 2)w}o, which = yn+1.
Hence, the downward closure under <o of the set of O-notations, {y0 <o y1 <o y2 <o · · ·}, is, for
terminology from [Rog67], a maximal, univalent system of notations, and, from Proposition 19 and
Theorem 32, (∀n ∈N)[LimynMex ⊂Limyn+1Mex].
As another Corollary to Theorem 32 and Proposition 19, we get
22

Corollary 34 For all u ∈O, LimuMex ⊂LimMex.
Since Lim0Mex = Mex, we get
Corollary 35 Mex ⊂LimMex.
Our next few results (Theorem 36, Lemma 37 and Lemma 39) lead up to another of our main
results, our Strong Hierarchy Theorem (Theorem 40), which essentially states that for notations of
the form {wv}o, where v ∈O and w is for ω, Theorem 20 gives as much collapsing as possible.
The following Theorem is a notational analog of Cantor’s Normal Form (CNF) Theorem25 for
ordinals ([Sie65, Theorem 2, Chapter XIV.19, page 323] and [KM67, Theorems 2 and 5, Chapter
VII, Section 7]).26 In Theorem 36 below, as stated, the parenthesization of the +o terms to the
right is essential, since +o is not associative.
Theorem 36 (Notational CNF Theorem) For all v ∈O, for all w for ω, for all x >o 0,
x <o {wv}o ⇔



there exists a unique k ∈N, unique n0, n1, . . . , nk ∈N +,
and unique v0, v1, . . . , vk where v >o v0 > v1 . . . >o vk, such that
x = {wv0}o ×o n0 +o ({wv1}o ×o n1 +o (. . . +o ({wvk}o ×o nk) . . .)).
Furthermore, for the left to right direction of the ⇔statement just above, the values of
k, n0, . . . , nk, and v0, . . . , vk can be algorithmically obtained from v, w, and x.
We call the above unique representation of x <o {wv}o, for v, w, and x as in the above theorem,
the notational CNF of x with respect to {wv}o. Where it is clear from the context, we will drop
the phrase “with respect to {wv}o” while referring to the notational CNF of such an x. Also,
Theorem 36 above has several other variants that are also true; for example, we could get similar
theorems for notations of the form w1 ×o w2 ×o w3, or {ww2
1 }o ×o w3, where w1, w2 and w3 are
notations for ω. We omit the details.
Furthermore, we note that for every ordinal α > 0, there exists a (unique) ordinal β such that
ωβ ≤α < ωβ+1 [Sie65, Theorem 2, Chapter XIV.18, page 321]. Therefore, the above Notational
CNF Theorem is suﬃciently general to apply to notations for as large a constructive ordinal as we
may choose.
Proof of Notational CNF.
We ﬁrst prove the ‘⇔’ part of the theorem.
(⇐) This direction of the proof uses reasoning and facts very similar to those used in the proofs
of Claims 26 and 27 of Lemma 25. It uses the fact that, for all w for ω, and for all n ∈N, for all
v′, v′′ ∈O, v′ <o v′′ ⇒{wv′}o ×o n <o {wv′′}o.
(⇒) The proof is by transﬁnite induction on v. Suppose v, w ∈O such that w is for ω. Suppose
x ∈O such that 0 <o x <o {wv}o.
Base Case: v = 0. Since {w0}o = 1, this case is vacuously true.
Inductive Case: v >o 0.
Inductive Hypothesis (IH): The (⇒) direction holds for all notations <o v.
25The CNF Theorem states: for any ordinal β > 0, there exists a unique k, unique n0, n1, . . . , nk ∈N +, and unique
ordinals α0, α1, . . . , αk, where α0 > α1 > . . . > αk, such that β = ωα0 × n0 + ωα1 × n1 + . . . + ωαk × nk.
26For a web page describing a programmatic implementation of an algorithm that may be used to perform operations
such as addition, subtraction, etc., on ordinals represented in Cantor Normal Form, see [Beh97].
23

We will show that the (⇒) direction holds for v.
Subcase 1: v = u +o 1.
Clearly, either x <o {wu}o or {wu}o ≤o x <o {wu+o1}o. If the former is true, the (⇒) direction
follows from IH. Therefore, suppose the latter. Then, by Theorem 16(f), there exists a unique
n ∈N + and a unique x′ <o {wu}o such that x = {wu}o ×o n +o x′. If x′ = 0, then clearly the (⇒)
direction holds with k = 0, v0 = u, and n0 = n; otherwise, if x >o 0, the (⇒) direction follows by
applying IH to x′ and noting that v >o u.
Subcase 2: v = 3 · 5p.
Let {wv}o = 3 · 5q.
Therefore, by Fact 7(e), (∃n ∈N)[x <o ϕq(n)].
From Theorem 17,
ϕq(n) = {wϕp(n)}o, and since ϕp(n) <o v, the (⇒) direction follows using IH.
(‘⇔’ part)
Finally, we prove the ‘furthermore’ part of the theorem.
Suppose v, w ∈O such that w
is for ω.
Suppose x ∈O such that 0 <o x <o {wv}o.
By using Fact 8(a) we can enu-
merate, uniformly eﬀectively in v and w, the set S = {(k, n0, n1, . . . , nk, v0, v1, . . . , vk) | k ∈
N, n0, n1, . . . , nk ∈N +, v >o v0 >o v1 . . . >o vk and {wv0}o ×o n0 +o ({wv1}o ×o n1 +o (. . . +o
({wvk}o ×o nk) . . .)) <o {wv}o}. Clearly, then, there is a procedure that is eﬀective in v, w, and x
to ﬁnd (k, n0, n1, . . . , nk, v0, v1, . . . , vk) ∈S such that x = {wv0}o ×o n0 +o ({wv1}o ×o n1 +o (. . . +o
({wvk}o ×o nk) . . .)).
(Notational CNF Theorem)
We next present a lemma (Lemma 37) which is a strengthening of Lemma 25 for notations
in certain forms.
In Lemma 25, if we let u = {wv}o, for some notation v ∈O and some w
for O, then we get that every limu-computable function is dominated by a parsimony factor of
order {({wv}o +o 1)w}o. Lemma 37, however, implies that we can in fact do much better and use
parsimony factors of order just {wv+o1}o.
Lemma 37 Suppose u <o {wv}o, where w is for ω.
Then, every limu-computable function is
dominated by a monotonically non-decreasing lim{wv}o-computable function.
Proof of Lemma 37.
Suppose v, w ∈O such that w is for ω. If u = 0, then the lemma follows using reasoning similar
to that in the proof of Lemma 25. For the u >o 0 cases, we will use Lemma 24.
Firstly, for all notations x, y <o {wv}o, we deﬁne the natural sum of x and y and denote the
operation by (+)o ; this operation is a notational analog of the natural sum of ordinals from [KM67,
Chapter VII, Section 7, pages 259-260].27
Suppose x, y >o 0. Let x’s and y’s (unique) notational CNFs, obtained via the Notational CNF
Theorem 36, be
x
=
{wv′
0}o ×o n′
0 +o ({wv′
1}o ×o n′
1 +o (. . . +o ({wv′
k′}o ×o n′
k′) . . .)),
y
=
{wv′′
0 }o ×o n′′
0 +o ({wv′′
1 }o ×o n′′
1 +o (. . . +o ({wv′′
k′′}o ×o n′′
k′′) . . .)),
where k′, k′′ ∈N, n′
0, . . . , n′
k′, n′′
0, . . . , n′′
k′′ ∈N +, v >o v′
0 . . . >o v′
k′, and v >o v′′
0 . . . >o v′′
k′′. (We
note that in general, k′ may be diﬀerent from k′′.)
By Fact 7(f), we get that for all v′ ∈V ′ = {v′
i | i ≤k′}, for all v′′ ∈V ′′ = {v′′
i | i ≤k′′}, either
v′ <o v′′ or v′ =o v′′ or v′ >o v′′. Let v0 >o v1 . . . >o vk be the notations in V ′ ∪V ′′.
27N.B. our notational (+)o depends on the choice of the pre-given v and w.
24

By Theorem 15 (clause i), we have that for all x, x×o 0 = 0. Also, as we noted a few paragraphs
after Theorem 13, clause (i) of Theorem 13 is a special base case that we added to Kleene’s deﬁnition
of +o from [Kle55], in order to get that for all y, 0 +o y = y. Thus, we have that for any x, y, ∈O,
(x ×o 0) +o y = y.
Using the facts from the just above paragraph, then, there is exactly one way to write x and y
as
x
=
{wv0}o ×o m′
0 +o ({wv1}o ×o m′
1 +o (. . . +o ({wvk}o ×o m′
k) . . .)),
y
=
{wv0}o ×o m′′
0 +o ({wv1}o ×o m′′
1 +o (. . . +o ({wvk}o ×o m′′
k) . . .)),
where m′
0, . . . , m′
k and m′′
0, . . . , m′′
k are possibly 0, and v >o v0. Furthermore, we clearly can still
eﬀectively determine all notations involved in the above representations of x and y. We call the
immediately above forms of x and y the mutually completed notational CNFs of x and y. It is
similarly possible to extend the deﬁnition of mutual completion of notational CNFs to sequences
of more than two notations. We omit the details.
Now, the natural sum of x and y: If x = 0 or y = 0,
x (+)o y def
= x +o y;
Otherwise, x (+)o y def
=
{wv0}o ×o (m′
0 + m′′
0) +o ({wv1}o ×o (m′
1 + m′′
1) +o (. . . +o ({wvk}o ×o (m′
k + m′′
k)) . . .)).
Clearly, (+)o is an eﬀective operation. It is also commutative and associative, unlike +o. Next,
we prove the following properties of (+)o .
Claim 38 Suppose v, x, y, w ∈O such that w is for ω. Suppose x, y <o {wv}o. Then,
(a) x (+)o y <o {wv}o,
(b) (∀y′)[y′ <o y ⇒(x (+)o y′ <o x (+)o y)],
(c) (∀x′)[x′ <o x ⇒(x′ (+)o y <o x (+)o y)].
Proof of Claim 38.
The proof is fairly straightforward, and, hence, we only sketch the details.
Part (a) may
be proved along the lines of Claim 27 of Lemma 25.
Part (c) follows from Part (b) and the
commutativity of (+)o .
Part (b) may be proved by transﬁnite induction. In the induction, we use the fact that if the
leftmost term of (the notational CNF of) y that is diﬀerent from the corresponding term of (the
notational CNF of) y′ is {wv0}o ×o n0 and the corresponding term of y′ is {wv′
0}o ×o n′
0, then either
v′
0 <o v0 or (v′
0 = v0 ∧n′
0 < n0). Then, we consider the mutually completed notational CNFs of
x (+)o y and x (+)o y′ and use a proof that is similar to that of the proofs of Claims 26 and 27 of
Lemma 25, to show that x (+)o y′ <o x (+)o y.
(Claim 38)
Next, we deﬁne a family of partial computable functions {ψn | n ∈N} that will enable us to
use Lemma 24 to get the desired result. For all n, for all u0, . . . , un ≤o u <o {wv}o, let
ψn(un, . . . , u0) = u0 (+)o . . . (+)o un.
Clearly, using Claim 38, the deﬁnition of (+)o and the fact that u >o 0, we see that u and
{ψn | n ∈N} satisfy the hypotheses of Lemma 24.
Also, using Claim 38, it is easy to show
25

that α = limn→∞ψn(u, . . . , u) o ≤
{wv}o o.
Let v∗be the unique notation for α such that
v∗≤o {wv}o. Therefore, we have u <o v∗≤o {wv}o.
Lastly, applying Lemma 24 to u, {ψn | n ∈N} and v∗, Lemma 37 follows.
(Lemma 37)
As an application of Lemma 37, we get the following. It is important to note that, for any
notations v, w, where w is for ω, the notations ({wv}o ×o w) and {wv+o1}o are not only for the
same ordinal, but also are exactly the same number, i.e., notation (this follows from our carefully
chosen “deﬁnitions” of ×o and {··}o).
Lemma 39 For all v, w ∈O, where w is for ω, C{wv}o ∈Lim{wv}o×owMex.
Proof. Follows from Lemmas 29 and 37, using reasoning similar to that presented just before
Lemma 30.
As indicated earlier, we get, for notations in special form, the following strengthening of the
General Hierarchy Theorem (Theorem 32).
Theorem 40 (Strong Hierarchy Theorem) Suppose u, v, w ∈O where w is for ω. Then,
(a) [{wv}o ≤o u <o {wv}o ×o w] ⇒LimuMex = Lim{wv}oMex,
(b) Lim{wv}oMex ⊂Lim{wv}o×owMex,
(c) v is a notation for a limit ordinal ⇒[ for all u <o v, Lim{wu}oMex ⊂Lim{wv}oMex].
Proof. (a) Follows from Theorem 20.
(b) Follows from Lemmas 31 and 39, and Proposition 19.
(c) Suppose v ∈O is for a limit ordinal and v′ <o v. By part (b), we have Lim{wv′}oMex ⊂
Lim{w(v′+o1)}oMex. Also, since v is for a limit ordinal, (v′ +o 1) <o v.28 Hence, by Theorem 18(d),
{w(v′+o1)}o <o {wv}o. Therefore, by Proposition 19, Lim{w(v′+o1)}oMex ⊆Lim{wv}oMex. Thus
Lim{wv′}oMex ⊂Lim{wv}oMex.
As a corollary to Theorem 40, we get
Corollary 41 Suppose u, v, w ∈O, where w is for ω. Then,
u <o {wv}o ⇒LimuMex ⊂Lim{wv}oMex.
Proof.
Follows using an easy induction on v, along with Proposition 19, Theorems 36 and 40, and
Fact 7(e).
Next,
suppose n
∈
N
and w is for ω.
Then,
Theorem 40 gives us,
for exam-
ple, (i) Lim{wn}oMex ⊂Lim{wn+1}oMex; (ii) Lim{wn}oMex ⊂Lim{ww}oMex, and (iii)
Lim{w(w×on)}oMex ⊂Lim{w{w2}o}oMex. We may repeatedly apply the Strong Hierarchy The-
orem to get a hierarchy of the form shown in Figure 1, Section 1.3.
Ordinal ǫ0 is the limit of the sequence ω, ωω, ωωω, . . . as well as the least ﬁxed point of λβ[ωβ].
Furthermore, it is the least ordinal not expressible as a polynomial in 0, 1, . . . , ω using ﬁnitely
many applications of addition, multiplication and exponentiation.29 The example of Figure 1 may
be extended to notations for ǫ numbers and beyond by a strategy we illustrate for ǫ0. Let
S = {u | u ≤o some notation in w, {ww}o, {w{ww}o}o, . . .}
28Proof: Since v′ <o v, by Fact 7(d), we get v′ +o 1 ≤o v. Since v is a limit ordinal, v′ +o 1 ̸= v. Hence v′ +o 1 <o v.
29See [Rog67, Exercises 11-51 to 11-53, Page 221].
26

Let e′ be such that for all n, (a) ϕe′(n) ∈S, (b) ϕe′(n) <o ϕe′(n + 1), and (c) for all u ∈S, there
exists an n such that u ≤o ϕe′(n). Then, clearly, 3 · 5e′ ∈O and e = 3 · 5e′ is a notation for
ǫ0. Choosing any such e for ǫ0, we can employ {we}o as another notation for ǫ0 and continue the
hierarchy of Figure 1, by that shown in Figure 2 below, for example.
...
⊂
Lim{we}oMex ⊂Lim{we+o1}oMex ⊂. . . ⊂Lim{we+on}oMex ⊂. . .
⊂
Lim{we+ow}oMex ⊂. . . ⊂Lim{we+o{ww}o}oMex ⊂. . . ⊂Lim{we+o{w{ww}o }o}oMex ⊂. . .
⊂
Lim{we×o2}oMex ⊂. . .
...
⊂
Lim{we×ow}oMex ⊂. . . ⊂Lim{we×o{ww}o}oMex ⊂. . . ⊂Lim{we×o{w{ww}o }o}oMex ⊂. . .
⊂
Lim{w{e2}o}oMex ⊂. . .
⊂
Lim{w{e3}o}oMex ⊂. . .
...
⊂
Lim{w{ew}o}oMex ⊂. . .
...
⊂
Lim{w{e{ww}o }o}oMex ⊂. . .
...
⊂
Lim{w{ee}o}oMex ⊂. . .
...
⊂
Lim{w{e{ee}o }o}oMex ⊂. . .
...
Figure 2: Example optimal continuation of hierarchy of Figure 1 along a <o-path for ordinals < ǫ1.
We have not attempted to obtain notational analogs of ordinal normal form theorems other than
for Cantor’s Normal Form Theorem but expect there are such results which would yield interesting
Strong Hierarchies for the LimuMex criteria and which are based on notations, e.g., for the ǫ
ordinals, which do not have to be of the form {wv}o (for example, e just above).
4
Further Results and Future Work
As stated in Theorem 23, for all n ∈O, LimnMex = Mex. We had originally hoped that this
result would not be true and that there would be a ﬁne hierarchy between Mex and LimMex
based on limn-computable parsimony factors. In the next section we successfully explore some
diﬀerent sources of restricted–parsimony ﬁne structure.
27

4.1
Iterated-Limits Parsimony Factors
Just as we deﬁned limu-computable in Deﬁnition 10, we may deﬁne, for n > 1, limn
un,...,u1-
computable functions. These limn
un,...,u1-computable functions are used in the deﬁnitions of cor-
responding Limn
un,...,u1Mex learning criteria.
We can extend Deﬁnition 4 to
Deﬁnition 42 Suppose n > 0. Suppose h : N n+1 →N. Then,
(a) for all x, and any sequence of n −1 numbers t1, . . . , tn−1,
lim
t→∞h(x, tn−1, . . . , t1, t) def
=

y,
if (∀∞t)[h(x, tn−1, . . . , t1, t) = y];
↑,
otherwise.
(b) for each m such that 0 < m ≤n, for any sequence of n −m numbers tm, . . . , tn−1,
h(x, tn−1, . . . , tm, ∞, . . . , ∞) def
= lim
t→∞h(x, tn−1, . . . , tm, t, ∞, . . . , ∞).
Deﬁnition 43
Suppose m, n ∈N such that 0 < m ≤n. Then,
F : N n+1 →O is an (m, n)O-countdown function def
⇔for all x, for all sequences of n −m + 1
numbers tm, . . . , tn, F(x, tn, . . . , tm + 1, ∞, . . . , ∞) ≤o F(x, tn, . . . , tm, ∞, . . . , ∞).
We next illustrate our general deﬁnition for, n > 0, of limn
un,...,u1-computable functions, via the
n = 2 case.
Deﬁnition 44 Suppose u2, u1 ∈(O ∪{∗}). Then,
g : N →N is lim2
u2,u1-computable def
⇔there exists computable h such that, for all x, t1, t2
(a) g(x) = h(x, ∞, ∞),
(b) card({t | h(x, t2, t) ̸= h(x, t2, t + 1)}) is ﬁnite,
(c) card({t | h(x, t, ∞) ̸= h(x, t + 1, ∞)}) is ﬁnite,
(d) (u1 ̸= ∗) ⇒there exists a (1, 2)O-countdown function F1 such that
F1(x, t2, 0) ≤o u1 ∧
h(x, t2, t1) ̸= h(x, t2, t1 + 1) ⇒F1(x, t2, t1 + 1) <o F1(x, t2, t1),
and
(e) (u2 ̸= ∗) ⇒there exists a (2, 2)O-countdown function F2 such that
F2(x, t2, ∞) ≤o u2 ∧
h(x, t2, ∞) ̸= h(x, t2 + 1, ∞) ⇒F2(x, t2 + 1, ∞) <o F2(x, t2, ∞).
We deﬁne lim2
u2,u1-computable as witnessed by h, F1, and F2 along the lines of part (b) of
Deﬁnition 5; we omit the details.
Let N def
= {n | n ∈N}. It turns out that limn
un,...,u1-computable functions, where each ui ∈(N ∪
{∗}), have useful characterizations as stated in Proposition 45 below. When we are proving results
for the Limn
un,...,u1Mex criteria where each ui ∈(N ∪{∗}), we shall use these characterizations in
our proofs involving iterated limits below, since, then, we do not have to explicitly consider the
more complicated corresponding (m, n)O-countdown functions.
Proposition 45 Suppose n > 0 and u1, . . . , un ∈(N ∪{∗}). Then, g : N →N is limn
un,...,u1-
computable ⇔there exists a computable h : N n+1 →N such that for all x,
(a) g(x) = h(x, ∞, . . . , ∞),
(b) for all i such that 1 ≤i < n and ui ̸= ∗, for any sequence of n −i numbers tn, . . . , ti+1,
card({t | h(x, tn, . . . , ti+1, t, ∞, . . . , ∞) ̸= h(x, tn, . . . , ti+1, t + 1, ∞, . . . , ∞)}) ≤ui o, and
(c) for all i such that 1 ≤i < n and ui = ∗, for any sequence of n −i numbers tn, . . . , ti+1,
card({t | h(x, tn, . . . , ti+1, t, ∞, . . . , ∞) ̸= h(x, tn, . . . , ti+1, t + 1, ∞, . . . , ∞)}) is ﬁnite.
28

We write limn-computable for limn
∗,...,∗-computable. For n > 0, we deﬁne Limn
un,...,u1Mex just
as in Deﬁnition 11, except that we use limn
un,...,u1-computable parsimony factors instead of limu-
computable ones. We mostly write LimnMex instead of Limn
∗,...,∗Mex.
For parsimony factors computed by two levels of iterated limits, the resulting learning criteria
turn out to be, in some cases, identical to Mex, and in other cases, to LimMex. This is illustrated
by the next two results. Proposition 46 just below is easy to prove.
Proposition 46
(a) For u ∈(O ∪{∗}), Lim2
u,0Mex = Lim2
0,uMex = LimuMex.
(b) For u1, u2, v1, v2 ∈O, u1 ≤o v1
∧
u2 ≤o v2 ⇒Lim2
0,0Mex ⊆Lim2
u2,u1Mex ⊆
Lim2
v2,v1Mex ⊆Lim2Mex.
Theorem 47 For any notations w1 and w2 for ω, Lim2
w2,w1Mex = Ex.
Proof. (⊆) Follows from the deﬁnition of Lim2
w2,w1Mex.
(⊇) Suppose S ∈Ex as witnessed by M.
We ﬁrst deﬁne the following two (computable) predicates. For each i, t1 and t2, let P(i, t2, t1) ≡
(∀x < t2)[Φi(x) ≤t1] and Q(i, t2, t1) ≡(∀y | t2 ≤y ≤t1)[(∀x < y)[Φi(x) ≤t1] ⇒[M(ϕi[t2]) =
M(ϕi[y])]].
Also, for all x, t2, let P(i, t2, ∞) = limt→∞P(i, t2, t) and Q(i, t2, ∞) = limt→∞Q(i, t2, t); then
P(i, t2, ∞) ≡(∀x < t2)[ϕi(x)↓] and Q(i, t2, ∞) ≡(∀y ≥t2)[(∀x < y)[ϕi(x)↓] ⇒M(ϕi[t2]) =
M(ϕi[y])].
We next deﬁne h′ as follows. It is to be understood, that for values of h′, any ?’s are changed
to 0’s.
h′(i, t2, t1) =
 M(ϕi[t2]),
if P(i, t2, t1) ∧Q(i, t2, t1);
0,
otherwise.
The following can be easily veriﬁed.
(1) (∀i)(∀t1, t2)[P(i, t2, t1) ⇒P(i, t2, t1 + 1)].
(2) (∀i)(∀t1, t2)[¬Q(i, t2, t1) ⇒¬Q(i, t2, t1 + 1)].
(3) (∀i)(∀t1, t2)[¬P(i, t2, ∞) ⇒¬P(i, t2 + 1, ∞)].
(4) (∀i)(∀t1, t2)[Q(i, t2, ∞) ⇒Q(i, t2 + 1, ∞)].
Item (1) implies that for all i, t2, card({t | P(i, t2, t) ̸= P(i, t2, t + 1)}) ≤1. Item (2) implies
that for all i, t2, card({t | Q(i, t2, t) ̸= Q(i, t2, t+1)}) ≤1. Hence, for all i, t2, card({t | (P(i, t2, t) ∧
Q(i, t2, t)) ̸= (P(i, t2, t + 1) ∧Q(i, t2, t + 1))}) ≤2. Therefore, from the deﬁnition of h′, we get
that for all i, t2, card({t | h′(i, t2, t) ̸= h′(i, t2, t + 1)}) ≤2. Similarly, from items (3) and (4), we
can conclude that card({t | h′(i, t, ∞) ̸= h′(i, t + 1, ∞)}) ≤2.
Let g′(i) = h′(i, ∞, ∞). Hence, g′ is a not necessarily monotonically non-decreasing, lim2
2,2-
computable function. It is easy to verify that, for all i, if ϕi ∈Ex(M), then g′(i) = M(ϕi). Let po
be the predecessor function for O (i.e., for all x, if x = 2y, then po(x) = y; po(x)↑, otherwise.) Let
h be deﬁned as follows. h(i, t2, t1) = max({h′(x, t2, t1) | x ≤i}). Let g(i) = h(i, ∞, ∞).
29

We get for all i, t2, card({t | h(i, t2, t) ̸= h(i, t2, t + 1)}) ≤2(i + 1); and for all i, card({t |
h(i, t, ∞) ̸= h(i, t + 1, ∞)}) ≤2(i + 1). For all i, t1 and t2, let
F1(i, t2, t1) =



2(i + 1),
if t1 = 0;
po(F1(i, t2, t1 −1)),
if t1 > 0 ∧h(i, t2, t1) ̸= h(i, t2, t1 −1);
F1(i, t2, t1),
otherwise.
F2(i, t2, t1) =



2(i + 1),
if t2 = 0;
po(F2(i, t2 −1, t1)),
if t2 > 0 ∧h(i, t2, t1) ̸= h(i, t2 −1, t1);
F2(i, t2 −1, t1),
otherwise.
Let w1 and w2 be any notations for ω. Clearly, h, F1 and F2 witness that g is a monotonically
non-decreasing lim2
w2,w1-computable function. Also, g dominates g′.
Therefore, S ∈Lim2
w2,w1Mex.
Corollary 48
For any notations w1 and w2 for ω, Mex ⊂LimMex ⊂Lim2
w2,w1Mex = Ex.
The following theorem resolves the remaining relationships between Lim2
u2,u1Mex classes.
Theorem 49 For all n ≥0: LimMex = Lim2
n,∗Mex = Lim2
∗,nMex = Lim2
1,1Mex.
Proof of Theorem 49.
We ﬁrst prove Lemmas 50, 51 and 52. The theorem then follows easily
from these lemmas.
Lemma 50 Every lim-computable function g is a lim2
1,1-computable function.
Proof of Lemma 50.
Suppose g is lim-computable as witnessed by computable h. We deﬁne
h1(x, y) =
 h(x, y),
if (∀t ≥y)[h(x, t) = h(x, y)];
0,
otherwise;
and
h2(x, y, z) =
 h(x, y),
if (∀t | y ≤t ≤y + z)[h(x, y) = h(x, t)];
0,
otherwise.
Clearly, h2 is a computable function. It is easy to verify the following:
(a) For each x, y, card({z | h2(x, y, z) ̸= h2(x, y, z + 1)}) ≤1;
(b) For each x, card({y | h1(x, y) ̸= h1(x, y + 1)}) ≤1;
(c) For all x, y, h2(x, y, ∞) = h1(x, y);
(d) For all x, h1(x, ∞) = h(x, ∞) = g(x).
Clearly, g is lim2
1,1-computable as witnessed by h2.
(Lemma 50)
Lemma 51 Suppose n ∈N. Then, for each monotonically non-decreasing lim2
n,∗-computable func-
tion g, there exists a lim-computable function g′ such that g′ dominates g.
30

Proof of Lemma 51.
By induction on n.
The lemma clearly holds for n = 0. Suppose by induction that the lemma holds for n = m. We will
show that the lemma holds for n = m+1. Therefore, suppose g is a lim2
m+1,∗-computable function.
Hence, there exist h1 and computable h2 such that the following three conditions are true.
(a) For all x, y, h1(x, y) = h2(x, y, ∞).
(b) For all x, g(x) = h1(x, ∞).
(c) For all x, card({y | h1(x, y) ̸= h1(x, y + 1)}) ≤m + 1.
Case 1: For all but ﬁnitely many x, card({y | h1(x, y) ̸= h1(x, y + 1)}) ≤m.
In this case, it is easy to show that g(x) is lim2
m,∗-computable. To see this, let y0 be such that,
(∀x | card({y | h1(x, y) ̸= h1(x, y + 1)}) = m + 1)(∀y ≥y0)[h1(x, y) = h1(x, y0)]
Let h′
2 be computable, such that for all x, y and y, h′
2(x, y, z) = h2(x, y + y0, z). It is easy to verify
that g is lim2
m,∗-computable as witnessed by h′
2. Hence, by the inductive hypothesis, there is a
lim-computable g′ such that g′ dominates g.
Case 2: For inﬁnitely many x, card({y | h1(x, y) ̸= h1(x, y + 1)}) = m + 1.
We deﬁne a function H as follows.
H(x) = min({⟨z, y0, y1, y2, . . . , ym+1⟩| z ≥x ∧(∀j ≤m)[yj < yj+1 ∧h1(z, yj) ̸= h1(z, yj+1)]})
H
is
lim-computable
since,
for
each
x,
the
characteristic
function
of
the
set,
{⟨z, y0, y1, y2, . . . , ym+1⟩| z ≥x
∧
(∀j ≤m)[yj < yj+1
∧
h1(z, yj) ̸= h1(z, yj+1)]} is
lim-computable.
We next use H to deﬁne g′ satisfying the requirements of the lemma. First deﬁne H1, H2 as
follows: suppose H(x) = ⟨z, y0, y1, . . . , ym+1⟩; then let H1(x) = z and H2(x) = ym+1. Clearly,
H1, H2 are lim-computable functions. Now it is easy to verify that, if x ≤x′, then H1(x) ≤H1(x′).
Let g′(x) = h1(H1(x), H2(x)) = g(H1(x)). Since h1, H1, H2 are lim-computable functions, it follows
that g′ is also lim-computable and dominates g.
(Lemma 51)
Lemma 52 Every lim2
∗,n-computable function g is lim2
n,∗-computable.
Proof of Lemma 52.
Let h1, h2 be such that
(a) for all x, g(x) = h1(x, ∞);
(b) for all x, y, h1(x, y) = h2(x, y, ∞);
(c) for all x, y, card({t | h2(x, y, t) ̸= h2(x, y, t + 1)}) ≤n.
For all i, x, y, we deﬁne
Gi
2(x, y) =







h2(x, y, z),
if card({t | h2(x, y, t) ̸= h2(x, y, t + 1)}) ≥i and z = 1+
min({z′ | card({t ≤z′ | h2(x, y, t) ̸= h2(x, y, t + 1)})
≥i});
↑,
otherwise.
Intuitively, Gi
2, for each x, y assumes that h2(x, y, ·) makes exactly i mind changes. Based on this
assumption, it tries to compute limt→∞h2(x, y, t).
We note that max({i ≤n | card({z | Gi
2(x, z)↓}) ≥y}), is a lim-computable function in x, y.
Let X be a computable function such that X(x, y, ∞) = max({i ≤n | card({z | Gi
2(x, z)↓}) ≥y}).
X(x, y, ∞) is monotonically non-increasing in y and is bounded by n. Moreover, for all x, for all
i > X(x, ∞, ∞), card({z | Gi
2(x, z)↓}) is ﬁnite.
31

We recall from Section 2.1 that max(∅) = 0.
Let H(x, y, z) = GX(x,y,z)
2
(x, w), where w =
max({w′ ≤z | GX(x,y,z)
2
(x, w′)↓in ≤z steps}). Then, for all x, card({y | H(x, y, ∞) ̸= H(x, y +
1, ∞)}) ≤n.
Moreover, using the deﬁnition of X, GX(x,∞,∞)
2
and H, it is easy to verify that
H(x, ∞, ∞) = h2(x, ∞, ∞) = g(x). Lemma follows.
(Lemma 52)
From Lemma 50, we get LimMex ⊆Lim2
1,1Mex. Clearly, for any lim-computable g′, there
exists a monotonically non-decreasing lim-computable g′′ such that g′′ dominates g′. Hence, by
Lemma 51, we get that for all n, Lim2
n,∗Mex ⊆LimMex.
Finally, by Lemma 52, for all n,
Lim2
∗,nMex ⊆Lim2
n,∗Mex. Thus, the theorem follows from the above three lemmas.
(Theorem 49)
Thus, if both u1 and u2 are 0, Lim2
u2,u1Mex = Mex. Else, when both of u1, u2 are not equal
to 0, Lim2
u2,u1Mex is equal to either LimMex or Ex; otherwise, if ui is the member of {u1, u2}
that is not 0, then Lim2
u2,u1Mex is identical to LimuiMex.
We next brieﬂy consider iterating limits to three levels. A proposition similar to Proposition 46
holds, but we omit stating it here. The following theorem shows that for parsimony factors that
use three levels of iterated limits, allowing even a small number of mind changes in each limit
essentially retains no parsimony in the ﬁnal programs learned.
Theorem 53 Ex = Lim3
1,2,2Mex.
Proof of Theorem 53.
We ﬁrst prove Lemma 54 below.
Lemma 54 Suppose f is a computable function from N 2 →N. Let F(i) = limt→∞f(i, t). Then,
there exists a lim3
1,2,2 function g such that, for all i, g(i) = max({F(j) | j ≤i ∧F(j)↓}).
Proof of Lemma 54.
Suppose f, F
are given as in the lemma.
Below, we deﬁne
g(.), h1(., .), h2(., ., .) and h3(., ., ., .) (where h3 is computable), such that each of the following seven
clauses is true.
(a) For all i, g(i) = h1(i, ∞);
(b) For all i, n, h1(i, n) = h2(i, n, ∞).
(c) For all i, n, m, h2(i, n, m) = h3(i, n, m, ∞).
(d) For all i, card({n | h1(i, n) ̸= h1(i, n + 1)}) ≤1.
(e) For all i, n, card({m | h2(i, n, m) ̸= h2(i, n, m + 1)}) ≤2.
(f) For all i, n, m, card({t | h3(i, n, m, t) ̸= h3(i, n, m, t + 1)}) ≤2.
(g) g(i) = max({F(j) | j ≤i ∧F(j)↓}).
The lemma then easily follows from the above clauses. We now deﬁne h3.
Let Xi,n,m,t
3
= {j ≤i | (∀w ≤m)[f(j, n) = f(j, n + w)]}.
Let Y i,n,m,t
3
= {j ≤i | (∀w ≤m + t)[f(j, n) = f(j, n + w)]}.
Let Zi,n,m,t
3
= {j ≤i | (∃w ≤t)[f(j, n + m) ̸= f(j, n + m + w)]}.
Let P3(i, n, m, t) ≡[(Xi,n,m,t
3
= Y i,n,m,t
3
) and (Xi,n,m,t
3
∪Zi,n,m,t
3
= {x | x ≤i})].
h3(i, n, m, t) =

max({f(j, n) | j ∈Xi,n,m,t
3
}),
if P3(i, n, m, t);
0,
otherwise.
If i, n and m are ﬁxed, Y i,n,m,t
3
is monotonically non-increasing and Zi,n,m,t
3
is monotonically
non-decreasing in t (in the set containment sense). Xi,n,m,t
3
is, clearly, ﬁxed once i, m and n are.
32

Thus, if t < t′ < t′′, then P3(i, n, m, t) and ¬P3(i, n, m, t′) implies ¬P3(i, n, m, t′′). So (f) is true.
Let
Xi,n,m
2
= Xi,n,m,∞
3
= Xi,n,m,0
3
= {j ≤i | (∀w ≤m)[f(j, n) = f(j, n + w)]}.
Y i,n,m
2
= Y i,n,m,∞
3
= {j ≤i | (∀w)[f(j, n) = f(j, n + w)]}.
Zi,n,m
2
= Zi,n,m,∞
3
= {j ≤i | (∃w)[f(j, n + m) ̸= f(j, n + m + w)]}.
P2(i, m, n) = P3(i, n, m, ∞) ≡[(Xi,n,m
2
= Y i,n,m
2
) and (Xi,n,m
2
∪Zi,n,m
2
= {x | x ≤i})].
Let h2(i, n, m) = h3(i, n, m, ∞). Thus (c) holds. It is easy to verify that
h2(i, n, m) =

max({f(j, n) | j ∈Xi,n,m
2
}),
if P2(i, n, m);
0,
otherwise.
Now Xi,n,m
2
is a monotonically non-increasing function of m, Y i,n,m
2
is independent of m, and
Zi,n,m
2
is a monotonically non-increasing function of m. Thus, if m < m′ < m′′, then P2(i, n, m)
and ¬P2(i, n, m′) implies ¬P2(i, n, m′′). It immediately follows that (e) holds. Let
Xi,n
1
= Xi,n,∞
2
= {j ≤i | (∀w)[f(j, n) = f(j, n + w)]}.
Y i,n
1
= Y i,n,∞
2
= Y i,n,0
2
= {j ≤i | (∀w)[f(j, n) = f(j, n + w)]},
Zi,n
1
= Zi,n,∞
2
= {j ≤i | F(j)↑}.
P1(i, n) = P2(i, n, ∞) ≡[Xi,n
1
= Y i,n
1
and Xi,n
1
∪Zi,n
1
= {x | x ≤i}]
Let h1(i, n) = h2(i, n, ∞). Thus (b) holds.
It is easy to verify that
h1(i, n) =

max({f(j, n) | j ∈Xi,n
1 }),
if P1(i, n);
0,
otherwise.
Note that Xi,n
1
= Y i,n
1
always holds. Thus P1(i, n) is equivalent to Xi,n
1
= {j ≤i | F(j)↓}.
Hence,
h1(i, n) =
 max({f(j, n) | j ≤i ∧F(j)↓}),
if P1(i, n);
0,
otherwise.
Note that for all i, n, n′ such that n < n′, if P1(i, n) then P1(i, n′).
Thus (d) holds.
Let
g(i) = limn→∞h1(i, n). Thus (a) holds. Now, g(i) = h1(i, ∞) = max({F(j) | j ≤i ∧F(j)↓}).
Thus (g) holds.
(Lemma 54)
Since, for every machine M there exists a computable function f such that, (∀i | ϕi ∈
Ex(M))[f(i, ∞) = M(ϕi)] the theorem follows.
(Theorem 53)
There are many mostly uninvestigated questions still open.
For u ∈O, do the LimuMex
criteria have “limiting-standardizability” style characterizations similar to those ﬁrst obtained for
Mex in [Fre75].
Generally, except for the cases noted above and their easy consequences, for
u1, . . . , un ∈(O ∪{∗}), how do the learning classes Limn
un,...,u1Mex compare to one another?
4.2
Notation Dependence Results
As mentioned in Section 1.2, Case and Suraj [CS03] show how to characterize the limu-computable
functions and variants in terms of concepts from [EHK81, Sel84]. One of these characterizations is
exploited to prove
Theorem 55 (Case–Suraj [CS03]) Every lim-computable function is also limv-computable, for
some notation v for ω2.
33

Using Theorem 55, we can get the following.
Theorem 56 For all C, if C ∈LimMex then there exists a notation v for ω2 such that C ∈
LimvMex.
Proof. Suppose C ∈LimMex as witnessed by M and a monotonically non-decreasing lim-
computable g. By Theorem 55, there exists a notation v for ω2, such that g is limv-computable.
Hence, C ∈LimvMex as witnessed by the same M and g.
Theorem 56 essentially says that for every class of functions that is LimMex-identiﬁable, there
is some notation v for an ordinal as small as ω2, such that this class of functions is LimvMex-
identiﬁable. However, we note that by General Hierarchy Theorem (Theorem 32), that one may
Limv′Mex-identify strictly more classes of functions by using a suitable notation v′ >o v.
Also, by Corollary 34, for all u ∈O, there exist a class of functions C such that C ∈(LimMex−
LimuMex). Hence, by Theorem 56, we have
Corollary 57 For each u ∈O, there exists a notation v for ω2, such that LimvMex ̸⊆LimuMex.
Using Corollary 57, we get
Corollary 58 For each constructive ordinal α such that α ≥ω2, there exist notations u, v for α
such that LimuMex ̸= LimvMex.
Proof. Suppose α is a constructive ordinal ≥ω2 and u is for α. By Corollary 57, we get that
there exists a notation u′ for ω2, such that Limu′Mex ̸⊆LimuMex.
Let v be a notation for α such that u′ ≤o v ≤o (u′ +o u); as noted in Section 2.3, such a
notation exists, and by Fact 7, it is unique. By Proposition 19, Limu′Mex ⊆LimvMex; therefore,
LimvMex ̸⊆LimuMex. Hence the corollary follows.
We do not know if there are u, v ∈O such that LimuMex ⊂LimvMex and yet u o > v o.
Also from [CS03], we have
Theorem 59 (Case–Suraj [CS03]) For all u, v ∈O, such that u and v are for the same ordinal
< ω2, every limu-computable function is also limv-computable.
From Theorem 59, we get
Theorem 60 For all u, v ∈O, such that u and v are for the same ordinal < ω2, LimuMex =
LimvMex.
It is interesting to ask what happens if we base parsimony restricted criteria on constructive
ordinals instead of on notations in O for them. One way to do so is to let, for any constructive
ordinal α,
LimαMex def
=
[
u for α
LimuMex.
While we have seen that the criteria LimuMex, for u ∈O, form subtle and ﬁnely graded
and ramiﬁed inﬁnite hierarchies, there are but three distinct criteria of the form LimαMex, for
constructive ordinals α, and they form a linear, ﬁnite hierarchy thus.
Theorem 61
(a) For all constructive ordinals α such that α ≥ω2, LimαMex = LimMex.
(b) Mex ⊂LimωMex ⊂Limω2Mex.
34

Proof.
From Theorem 56, we get LimMex ⊆Limω2Mex. From Proposition 19, we get Limω2Mex ⊆
LimMex. Hence Part (a) follows.
(b) Follows from Theorems 60, 40 and 23.
We have not fully considered the possible dependencies of the limu-computable functions or
of the classes LimuMex on the many notation systems alternative to O([Amb95]). Of course,
for example, by an obvious embedding, our Strong Hierarchy Theorem (Theorem 40 just above)
mutatis mutandis clearly follows for computably related, non maximal ([Rog67]) notation sys-
tems based on exponential polynomials in ﬁnite ordinals, ω, and a suitably speciﬁed collection
of ǫ numbers. Also, we have not considered parsimony restricted criteria based on notations or
programs for non-well orderings (with, for example, no computable inﬁnite descending chains)
[Ers68b, SSV97, AFS99].
4.3
Comparison with O-Bounded Mind Change Ex-Identiﬁcation
We recall that SEG is the set of all ﬁnite initial sequences of natural numbers. We next consider,
for u, v ∈O, connections between the LimvMex criteria and the Exu criteria that were introduced
by Freivalds and Smith [FS93]. To deﬁne Exu, we ﬁrst deﬁne O-mind change counters, similar
to those deﬁned in [JS97, AJS99]: an O-mind change counter is a computable mapping, F, from
SEG into O, such that for all n and f, F(f[n]) ≥o F(f[n + 1]). Now, for each u ∈O, a machine
M Exu-identiﬁes f if and only if M (i) Ex-identiﬁes f, and (ii) there exists an O-mind change
counter F such that for every n, [? ̸= M(f[n]) ̸= M(f[n + 1])] ⇒F(f[n + 1]) <o F(f[n]) ≤o u.
As can be seen, the Exu criteria impose restrictions on the mind changes of the learning machines
themselves.
Besides [FS93], other works that study various aspects of imposing similar restrictions on
the mind changes of learning machines include those of Aps¯ıtis [Aps94], Ambainis [Amb95], Jain
and Sharma [JS97, JS99, JS01], Sharma, Stephan and Ventsov [SSV97], Ambainis, Freivalds and
Smith [AFS99] and, Ambainis, Jain, and Sharma [AJS99].
Theorem 62 Mex ̸⊆S
u∈O Exu.
Proof of Theorem 62.
Let C = {f | (∀∞x)[f(x) = 0] ∧2 ∗MinProg(f) ≥max({x | f(x) ̸=
0} ∪{f(x) | x ∈N})}.
Now, for any ﬁnite set S ⊆N × N, where, S is single-valued, i.e., S is the graph of a ﬁnite
partial function, let pzext(S) be a standard program for the zero-extension of S, i.e.,
ϕpzext(S)(x) =
 y,
if (x, y) ∈S;
0,
if there is no y with (x, y) ∈S.
Let g(z) = max(pzext(S) | S ⊆{0, · · · , 2z} × {0, · · · , 2z} and S is single-valued).
Let M(f[n]) = pzext({(x, f(x)) | x < n ∧f(x) ̸= 0}).
Clearly, for any ϕe ∈C, g(e) bounds pzext(S), for S = {(x, ϕe(x)) | ϕe(x) ̸= 0}. Hence M
g-Mex-identiﬁes C.
We next show that, for all u ∈O, C ̸∈Exu.
35

Note ﬁrst that C is dense, i.e., for any element f[n] ∈SEG, there exists an extension g of f[n]
such that g ∈C. To see this, let z = 1 + max({n} ∪{f(x) | x < n}). For each y, let
gy(x) =



f(x),
if x < n;
y,
if x = n;
0,
otherwise.
Now, there exists a y ∈{x | z ≤x ≤2z}, such that MinProg(gy) ≥z. Thus gy ∈C.
Now suppose by way of contradiction that, for some u ∈O, C ∈Exu as witnessed by some
machine M′ and O-mind change counter F. Since for every n, [? ̸= M′(f[n]) ̸= M′(f[n + 1])] ⇒
F(f[n + 1]) <o F(f[n]) ≤o u, and there are no inﬁnite descending chains of notations in O, we get
that M′ makes only ﬁnitely many mind changes on any f. Therefore, there is a σ such that M′
does not make a mind change on any τ that is an extension of σ. Clearly, since C is dense, there
are inﬁnitely many f’s in C that are each extensions of σ; yet, M′ Exu-identiﬁes at most one of
them. Therefore, M′ does not Exu-identify C.
Hence, the theorem follows.
(Theorem 62)
Theorem 63 For all u ∈O, for all w for ω, Exu ⊂Lim{(u+o2)w}oMex.
Proof.
We show that for all u, for all w for ω, Exu ⊆Lim{(u+o2)w}oMex. Then, the theorem follows
using Theorem 62.
Suppose C ∈Exu as witnessed by machine M and O-mind change counter F′. We ﬁrst show
how to construct a (not necessarily monotonically non-decreasing) limu+o1-computable function g,
such that, (∀f ∈C)[g(MinProg(f) ≥M(f)]. In this interest, we present a simple modiﬁcation of the
construction from the proof of Lemma 29 to get h and F that witness that g is limu+o1-computable.
Let h and F be deﬁned as follows. For all i, let h(i, 0) = 0, F(i, 0) = u +o 1. For all i, t, we
deﬁne h(i, t + 1), F(i, t + 1) as follows.
begin computation of h(i, t + 1), F(i, t + 1).
if Φi(0) > t
then
Let h(i, t + 1) = h(i, t) and F(i, t + 1) = F(i, t);
else
Let x be the largest value ≤t, such that (∀x′ ≤x)[Φi(x′) ≤t].
Let h(i, t + 1) = M(ϕi[x + 1]) and F(i, t + 1) = F′(ϕi[x + 1]).
endif
end computation of h(i, t + 1), F(i, t + 1).
Let g(i) = h(i, ∞). Clearly, for all i such that ϕi ∈C, we get h(i, ∞) = M(f); in particular,
for all f ∈C, h(MinProg(f), ∞) = M(f).
Clearly, also, h and F witness that g is limu+o1-
computable. Suppose w is a notation for ω. Then, by Lemma 25, there exists a monotonically
non-decreasing lim{(u+o2)w}o-computable function g′ which dominates g. It is easy to verify that
C ∈Lim{(u+o2)w}oMex as witnessed by M and g′. Hence, Exu ⊂Lim{(u+o2)w}oMex.
36

Theorem 64 Suppose u, v, w ∈O such that u <o {wv}o and w is for ω. Then,
Exu ⊂Lim{wv}oMex.
Proof.
We show that for all u, v, w ∈O such that u <o {wv}o and w is for ω, Exu ⊆Lim{wv}oMex.
Then, the theorem follows using Theorem 62.
If v = 0, then {wv}o = 1.
Therefore, Lim{wv}oMex = Lim1Mex.
From Corollary 23,
Lim1Mex = Mex. Also, Ex0 ⊆Mex [Che82, Theorem 6.1, page 80]. Therefore, the v = 0 case
follows.
The v >o 0 case is similar to the proof of Theorem 63, except that it makes use of Lemma 37
instead of Lemma 25 and the fact that u <o {wv}o ⇒u +o 1 <o {wv}o. We omit the details.
As a corollary to the theorem just above, we get
Corollary 65 Suppose v, w ∈O such that w is for ω. Then, Ex{wv}o ⊂Lim{wv}o×owMex.
For n ∈N +, Theorem 63 implies for all notations w for ω, Exn ⊂Lim{(n+o2)w}oMex; the
latter, by Theorem 60 and the fact that
{(n +o 2)w}o o = ω, is = LimωMex.
Chen [Che82,
Corollary 6.2, pages 80-81] shows that, in fact, Exn ⊂Mex; hence Exn ⊂Lim0Mex. However,
Exw ̸⊆Mex follows from Theorem 66 below.
Theorem 66 For all u, w ∈O such that w is for ω, Exw×o(u+o1) −LimuMex ̸= ∅.
Proof.
Let u, w ∈O be such that w is for ω.
We use Cu from Deﬁnition 28 to show that Cu ∈
Exw×o(u+o1) −LimuMex. The negative part of this follows from Lemma 31.
The positive part follows, in part, from a careful analysis of a construction from [FW79] as
presented in [JORS99]. So that we do not need to present this construction again, in the remainder
of this proof we proceed informally to show that Cu ∈Exw×o(u+o1).
For f ∈Cu, from Parts (a) through (e) of Deﬁnition 28, we see that limx→∞π4
2(f(x))↓≥a
program for f, and that this convergence involves ≤o u mind changes.
Hence, informally, the
number of diﬀerent values of π4
2(f(x)) on the way to convergence is ≤o (u +o 1).
Proposition 10.7 of [JORS99, Page 227] generalizes a result from [FW79], and careful examina-
tion of the proof of this Proposition (for the special case from [FW79]) provides the existence of
a machine we’ll call MFW with the following useful property. If MFW receives as input both an
upper bound on a program for a function f and successively longer initial segments of f, then it
converges to a program for f. Furthermore, in the process, MFW makes ≤o w mind changes.
We present informally, then, a machine M which witnesses that Cu ∈Exw×o(u+o1). For any
x ∈N and any function f, M, on f[x + 1], employs π4
2(f(x)) as a candidate upper bound on a
program for f to feed to MFW together with f[x + 1]; then M outputs MFW ’s resultant output.
Each time π4
2(f(x)) makes a mind change, the MFW component of M starts over. From above, M
need look at ≤o (u+o 1) diﬀerent values of π4
2(f(x)), and, for each of these, the MFW component of
M can be restricted to make ≤o w mind changes. Hence, M makes ≤o (w×o(u+o1)) mind changes.
To see this, think of w ×o (u +o 1) o informally as ( u o + 1) copies of ω laid out end to end; and
the counting down for M as starting at the right end of the rightmost copy of ω, jumping to right
end of the next copy of ω to the left whenever π4
2(f(x)) makes a mind change, and counting down
inside its currently employed copy of ω when operating MFW between π4
2(f(x))’s mind changes.
37

The notation (w ×o (u +o 1)) makes it possible to ﬁnd ones way algorithmically from right to left
across the corresponding ordinal conceptualized as ( u o + 1) copies of ω laid out end to end.
Since for all u ∈O, Mex ⊆LimuMex, using Theorem 62, we get the following corollary to
Theorem 66 above.
Corollary 67 For all u, w ∈O such that w is for ω, LimuMex ̸⊆Exw×o(u+o1).
We also note that the proof of Theorem 66 may be easily adapted to show that for all u, v ∈O,
such that v o ≥ω, we get Exv×o(u+o1) −LimuMex ̸= ∅.
It is open whether the comparisons of this section can be substantially improved.
References
[Add65]
J. W. Addison. The method of alternating chains. In J. W. Addison, Leon Henkin, and
Alfred Tarski, editors, Theory of Models (Proc. 1963 International Symposium, Berkeley,
Calif.), pages 1–16, Amsterdam, 1965. North–Holland.
[AFS99]
A. Ambainis, R. Freivalds, and C. H. Smith. Inductive inference with procrastination:
Back to deﬁnitions. Fundamenta Informaticae, 40:1–16, 1999.
[AJS99]
A. Ambainis, S. Jain, and A. Sharma. Ordinal mind change complexity of language
identiﬁcation. Theoretical Computer Science, 220(2):323–343, 1999.
[Amb95]
A. Ambainis. The power of procrastination in inductive inference: How it depends on
used ordinal notations. Lecture Notes in Computer Science, 904:99–111, 1995.
[Ang80]
D. Angluin. Finding patterns common to a set of strings. Journal of Computer and
System Sciences, 21:46–62, 1980.
[Aps94]
Kalvis Aps¯ıtis. Derived sets and inductive inference. In Setsuo Arikawa and Klaus P.
Jantke, editors, Algorithmic Learning Theory, Proc. 4th International Workshop on Ana-
logical and Inductive Inference (AII’94) and the 5th International Workshop on Algorith-
mic Learning Theory (ALT’94), October 10-15, 1994, Reinhardsbrunn Castle, Germany,
volume 872 of LNAI, pages 26–39. Springer-Verlag, 1994.
[ASY92]
S. Arikawa, T. Shinohara, and A. Yamamoto.
Learning elementary formal systems.
Theoretical Computer Science, 95:97–113, 1992.
[BB75]
L. Blum and M. Blum. Toward a mathematical theory of inductive inference. Information
and Control, 28:125–155, 1975.
[Beh97]
Libor Behounek. Ordinal calculator, 1997. Web document at: http://www.ﬀ.cuni.cz/ be-
hounek/ordinalc.htm.
[Blu67]
M. Blum. A machine independent theory of the complexity of recursive functions. Jour-
nal of the ACM, 14:322–336, 1967.
[BM95]
I. Bratko and S. Muggleton. Applications of inductive logic programming. Communica-
tions of the ACM, 38(11):65–70, 1995.
38

[BUV96]
A. Brazma, E. Ukkonen, and J. Vilo. Discovering unbounded unions of regular pattern
languages from positive examples. In Proceedings of the Seventh International Sympo-
sium on Algorithms and Computation (ISAAC’96), volume 1178 of Lecture Notes in
Computer Science, pages 95–104, 1996. Osaka, Japan.
[Cas74]
J. Case. Periodicity in generations of automata. Mathematical Systems Theory, 8:15–32,
1974.
[Cas94]
J. Case. Inﬁnitary self-reference in learning theory. Journal of Experimental and Theo-
retical Artiﬁcial Intelligence, 6:3–16, 1994.
[Che82]
K. Chen. Tradeoﬀs in inductive inference of nearly minimal sized programs. Information
and Control, 52:68–86, 1982.
[CJK+01] J. Case, S. Jain, S. Kaufmann, A. Sharma, and F. Stephan. Predictive learning models
for concept drift. Theoretical Computer Science, 268:323–349, 2001. Special Issue for
ALT’98.
[CJLZ99] J. Case, S. Jain, S. Lange, and T. Zeugmann. Incremental concept learning for bounded
data mining. Information and Computation, 152:74–110, 1999.
[CJS95]
J. Case, S. Jain, and M. Suraj. Not-so-nearly-minimal-size program inference. In Klaus P.
Jantke and Steﬀen Lange, editors, Algorithmic Learning for Knowledge-Based Systems,
volume 961 of Lecture Notes in Artiﬁcial Intelligence, pages 77–96. Springer-Verlag,
1995.
[CJS96]
J. Case, S. Jain, and A. Sharma. Machine induction without revolutionary changes in
hypothesis size. Information and Computation, 128:73–86, August 1996.
[CS83]
J. Case and C. Smith. Comparison of identiﬁcation criteria for machine inductive infer-
ence. Theoretical Computer Science, 25:193–220, 1983.
[CS03]
J. Case and M. Suraj. Characterizing Ershov hierarchies by algorithmic O-count down,
2003. Working paper.
[EHK81]
R. L. Epstein, R. Haas, and R. L. Kramer. Hierarchies of sets and degrees below 0′. In
Logic Year 1979–80, volume 859 of Lecture Notes in Mathematics, pages 32–48, Heidel-
berg, 1981. Springer–Verlag.
[Ers68a]
Yu. L. Ershov. A hierarchy of sets, I. Algebra i Logika, 7(1):47–74, 1968. In Russian
(English translation in Algebra and Logic, 7:25–43, 1968).
[Ers68b]
Yu. L. Ershov. A hierarchy of sets, II. Algebra i Logika, 7(4):15–47, 1968. In Russian
(English translation in Algebra and Logic, 7:212–232, 1968).
[Ers70]
Yu. L. Ershov. A hierarchy of sets, III. Algebra i Logika, 9(1):34–51, 1970. In Russian
(English translation in Algebra and Logic, 9:20–31, 1970).
[Fre75]
R. Freivalds. Minimal G¨odel numbers and their identiﬁcation in the limit. Lecture Notes
in Computer Science, 32:219–225, 1975.
39

[Fre90]
R. Freivalds. Inductive inference of minimal programs. In M. Fulk and J. Case, editors,
Proceedings of the Third Annual Workshop on Computational Learning Theory, pages
3–20. Morgan Kaufmann Publishers, Inc., August 1990.
[FS93]
R. Freivalds and C. Smith. On the role of procrastination in machine learning. Infor-
mation and Computation, 107(2):237–271, 1993.
[Ful85]
M. Fulk. A Study of Inductive Inference Machines. PhD thesis, SUNY at Buﬀalo, 1985.
[FW79]
R. Freivalds and R. Wiehagen. Inductive inference with additional information. Elec-
tronische Informationverarbeitung und Kybernetik, 15:179–195, 1979.
[GD01]
A. Gale and R. Downey. On genericity and Ershov’s hierarchy. Mathematical Logic
Quarterly, 47(2):161–182, 2001.
[Gol67]
E. Gold. Language identiﬁcation in the limit. Information and Control, 10:447–474,
1967.
[GS95]
W. I. Gasarch and C. H. Smith. Recursion theoretic models of learning: some results
and intuitions. Annals of Mathematics and Artiﬁcial Intelligence, 15(2):151–166, 1995.
[Joc82]
C. G. Jockusch, Jr. Review of “Hierarchies of Sets and Degrees Below 0′” by Richard L.
Epstein and Richard Haas and Richard L. Kramer. Mathematical Reviews, 1982. MR
82k:03073.
[JORS99] S. Jain, D. Osherson, J. Royer, and A. Sharma. Systems that Learn: An Introduction to
Learning Theory. MIT Press, Cambridge, Mass., second edition, 1999.
[JS97]
S. Jain and A. Sharma. Elementary formal systems, intrinsic complexity, and procras-
tination. Information and Computation, 132:65–84, 1997.
[JS99]
S. Jain and A. Sharma. Mind change complexity of learning logic programs. In P. Fis-
cher and H.U. Simon, editors, Fourth European Conference on Computational Learning
Theory, volume 1572 of Lecture Notes in Artiﬁcial Intelligence, pages 198–213. Springer-
Verlag, Berlin, 1999.
[JS01]
S. Jain and A. Sharma. On a generalized notion of mistake bounds. Information and
Computation, 166:156–166, 2001.
[Kin74]
E. Kinber. On the synthesis in the limit of almost minimal G¨odel numbers. Theory Of
Algorithms and Programs, LSU, Riga, 1:221–223, 1974.
[Kle38]
S. C. Kleene. On notation for ordinal numbers. Jounal of Symbolic Logic, 3:150–155,
1938.
[Kle44]
S. C. Kleene. On the forms of predicates in the theory of constructive ordinals. American
Journal of Mathematics, 66:41–58, 1944.
[Kle55]
S. C. Kleene. On the forms of predicates in the theory of constructive ordinals (second
paper). American Journal of Mathematics, 77:405–428, 1955.
40

[KM67]
K. Kuratowski and A. Mostowski. Set Theory. North-Holland, 1967.
[KMU95] P. Kilpel¨ainen, H. Mannila, and E. Ukkonen. MDL learning of unions of simple pattern
languages from positive examples. In Paul Vit´anyi, editor, Second European Conference
on Computational Learning Theory, volume 904 of Lecture Notes in Artiﬁcial Intelli-
gence, pages 252–260. Springer-Verlag, 1995.
[LD94]
N. Lavraˇc and S. Dˇzeroski. Inductive Logic Programming: Techniques and Applications.
Ellis Horwood, 1994.
[Mit97]
T. Mitchell. Machine Learning. McGraw Hill, 1997.
[MR94]
S. Muggleton and L. De Raedt. Inductive logic programming: Theory and methods.
Journal of Logic Programming, 19/20:669–679, 1994.
[MY78]
M. Machtey and P. Young. An Introduction to the General Theory of Algorithms. North
Holland, New York, 1978.
[Nix83]
R. Nix. Editing by examples. Technical Report 280, Department of Computer Science,
Yale University, New Haven, CT, USA, 1983.
[Odi99]
P. Odifreddi. Classical Recursion Theory, volume II. Elsivier, Amsterdam, 1999.
[Put63]
H. Putnam. Probability and conﬁrmation. Voice of America, Forum on Philosophy of
Science, 10, 1963.
[Put65]
H. Putnam. Trial and error predicates and the solution to a problem of Mostowski.
Journal of Symbolic Logic, 30:49–57, 1965.
[Rog58]
H. Rogers. G¨odel numberings of partial recursive functions. Journal of Symbolic Logic,
23:331–341, 1958.
[Rog67]
H. Rogers. Theory of Recursive Functions and Eﬀective Computability. McGraw Hill,
New York, 1967. Reprinted, MIT Press, 1987.
[Roy87]
J. Royer. A Connotational Theory of Program Structure, volume 273 of Lecture Notes
in Computer Science. Springer-Verlag, Berlin, 1987.
[SA95]
T. Shinohara and A. Arikawa. Pattern inference. In Klaus P. Jantke and Steﬀen Lange,
editors, Algorithmic Learning for Knowledge-Based Systems, volume 961 of Lecture Notes
in Artiﬁcial Intelligence, pages 259–291. Springer-Verlag, 1995.
[Sac90]
G. Sacks. Higher Recursion Theory. Springer-Verlag, 1990.
[Sal94a]
A. Salomaa. Patterns (The Formal Language Theory Column). EATCS Bulletin, 54:46–
62, 1994.
[Sal94b]
A. Salomaa.
Return to patterns (The Formal Language Theory Column).
EATCS
Bulletin, 55:144–157, 1994.
[Sch98]
M. Schaefer. A guided tour of minimal indices and shortest descriptions. Archives for
Mathematical Logic, 18:521–548, 1998.
41

[Sel84]
V. L. Selivanov. On a hierarchy of limiting computations. Sibirskii Mathematicheskii
Zhurnal, 25(5):146–156, 1984. In Russian (English translation in Siberian Mathematical
Journal, 25:798-806, 1984).
[Sha71]
N. Shapiro. Review of “Limiting recursion” by E.M. Gold and “Trial and error predicates
and the solution to a problem of Mostowski” by H. Putnam. Journal of Symbolic Logic,
36:342, 1971.
[Shi83]
T. Shinohara. Inferring unions of two pattern languages. Bulletin of Informatics and
Cybernetics, 20:83–88., 1983.
[Sie65]
W. Sierpinski. Cardinal and ordinal numbers. PWN –Polish Scientiﬁc Publishers, 1965.
Second revised edition.
[Smu61]
R. Smullyan.
Theory of Formal Systems.
Annals of Mathematics Studies, No. 47.
Princeton University Press, 1961.
[Soa96]
Robert I. Soare. Computability and recursion. Bulletin of Symbolic Logic, 2(3):284–321,
1996.
[SSS+94]
S. Shimozono, A. Shinohara, T. Shinohara, S. Miyano, S. Kuhara, and S. Arikawa.
Knowledge acquisition from amino acid sequences by machine learning system BONSAI.
Trans. Information Processing Society of Japan, 35:2009–2018, 1994.
[SSV97]
A. Sharma, F. Stephan, and Y. Ventsov. Generalized notions of mind change complexity.
In Proceedings of the Tenth Annual Conference on Computational Learning Theory,
pages 96–108. ACM Press, 1997.
[Wri89]
K. Wright. Identiﬁcation of unions of languages drawn from an identiﬁable class. In
R. Rivest, D. Haussler, and M. Warmuth, editors, Proceedings of the Second Annual
Workshop on Computational Learning Theory, Santa Cruz, California, pages 328–333.
Morgan Kaufmann Publishers, Inc., 1989.
42

