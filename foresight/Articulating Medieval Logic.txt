
contents 
i
Articulating Medieval Logic

This page intentionally left blank 

Articulating 
Medieval Logic
Terence Parsons

Great Clarendon Street, Oxford, OX2 6DP, 
United Kingdom
Oxford University Press is a department of the University of Oxford. 
It furthers the University’s objective of excellence in research, scholarship, 
and education by publishing worldwide. Oxford is a registered trade mark of 
Oxford University Press in the UK and in certain other countries
© Terence Parsons 2014
Th e moral rights of the author have been asserted
Impression: 1
All rights reserved. No part of this publication may be reproduced, stored in 
a retrieval system, or transmitted, in any form or by any means, without the 
prior permission in writing of Oxford University Press, or as expressly permitted 
by law, by licence or under terms agreed with the appropriate reprographics 
rights organization. Enquiries concerning reproduction outside the scope of the 
above should be sent to the Rights Department, Oxford University Press, at the 
address above
You must not circulate this work in any other form 
and you must impose this same condition on any acquirer
British Library Cataloguing in Publication Data
Data available
Library of Congress Control Number: 2014930996
ISBN 978-0-19-968884-5
As printed and bound by
CPI Group (UK) Ltd, Croydon, CR0 4YY
Links to third party websites are provided by Oxford in good faith and 
for information only. Oxford disclaims any responsibility for the materials 
contained in any third party website referenced in this work.

To Calvin Normore

This page intentionally left blank 

Contents
List of Tables 
xii
Preface 
xiii
Introduction 
1
 1. An Overview of Aristotelian Logic as seen by Medieval Logicians 
6
1.1 Categorical propositions 
6
1.2 Logical relations among categorical propositions 
9
1.3 Th e square of opposition 
10
1.4 Issues concerning empty terms 
12
 
1.4.1 Universal affi  rmatives 
12
 
1.4.2 Particular negatives 
12
1.5 Conversions 
14
1.6 Syllogisms 
15
1.7 Infi nite negation 
18
1.8 Formal validity 
18
 2. Aristotle’s Proofs of Conversions and Syllogisms 
21
2.1 Formal derivations 
21
2.2 Proofs of the conversion principles 
25
 
2.2.1 Conversion of universal negatives 
26
 
2.2.2 Conversion of universal affi  rmatives (conversion per accidens) 
27
 
2.2.3 Conversion of particular affi  rmatives 
28
2.3 Reduction of all syllogisms to perfect ones 
30
 
2.3.1 Figure 1 syllogisms 
30
 
2.3.2 Reduction to the fi rst fi gure 
31
 
2.3.3 Figure 2 syllogisms 
32
 
2.3.4 Barocho 
33
 
2.3.5 Figure 3 syllogisms 
34
 
2.3.6 First fi gure indirect moods 
38
2.4 Proving the fi rst fi gure syllogisms 
39
2.5 Propositions with repeated terms 
40
2.6 Th e indispensability of exposition and expository syllogism 
41
2.7 A contemporary assessment of Aristotle’s basic theory 
43
 
2.7.1 Generalized quantifi ers 
43
 
2.7.2 Axiomatizing generalized quantifi ers 
48
 
2.7.3 A qualifi cation concerning existential import 
49
2.8 Singular propositions 
50
2.9 13th-century texts 
51
2.10 Summary of Aristotle’s rules of proof 
53

viii 
contents
 3. Quantifying Predicates, Singular Term Predicates, Negative Terms  
56
3.1 Expanded notation 
56
3.2 Equipollences  
60
3.3 Semantics and rules 
62
3.4 Singular terms as predicates 
67
3.5 Infi nitizing negation and conversion 
72
 
3.5.1 Conversion by contraposition and obversion 
74
3.6 Completeness of the rules 
77
 
3.6.1 Verbs other than the copula 
77
3.7 Summary of the rules of proof used so far 
77
 4. Linguish 
81
4.1 Basics 
81
4.2 Categorical propositional logical forms 
87
4.3 Rules of inference 
90
 
4.3.1 Some theorems that may be of interest 
92
 
 
4.3.1.1 Symmetry of ‘is’ 
93
4.4 Signifi cation and supposition 
95
4.5 Truth conditions 
98
 
4.5.1 Affi  rmative and negative propositions and existential import 
109
4.6 Validity  
110
4.7 Completeness of the rules 
113
 5. Expanding the Notation  
123
5.1 Adjectives 
123
5.2 Intransitive verbs 
126
 
5.2.1 Being 
128
5.3 Transitive verbs 
129
5.4 Additional rules for parasitic terms 
133
5.5 Some complex terms 
134
 
5.5.1 Attributive adjectives and participles modifying nouns 
134
 
5.5.2 Participles of transitive verbs with their objects 
135
 
5.5.3 Terms modifi ed by complex terms 
138
5.6 Relative clauses 
140
 
5.6.1 Semantics of relative clauses 
142
 
5.6.2 Representing ordinary language Latin (and English) 
143
5.7 Genitives 
145
 
5.7.1 What the genitive means 
146
 
5.7.2 Relational common nouns 
147
 
5.7.3 Non-relational uses 
148
 
5.7.4 Non-relational possessives 
150
 
5.7.5 Complex terms with genitives  
152
5.8 Demonstratives 
153
5.9 Molecular propositions 
155
 
5.9.1 Constructions with free markers 
158

contents 
ix
 6. Some Illustrative Topics 
160
6.1 Relational expressions and De Morgan’s challenge 
160
 
6.1.1 Dealing with explicit relational expressions 
161
 
6.1.2 Dealing with parasitic terms 
162
6.2 Buridan on subjects and predicates 
164
 
6.2.1 Identifying subjects and predicates 
164
 
6.2.2 Subjects and predicates in Linguish 
167
 
6.2.3 Agreeing with Buridan (mostly)  
169
 
6.2.4 Th e asymmetry of subjects and predicates 
173
 
 
6.2.4.1 Way 1: Quantifi er signs  
173
 
 
6.2.4.2 Way 2: Negative signs  
175
6.3 Simple and complex terms 
176
 
6.3.1 Some interesting constructions 
176
 
6.3.2 Simple and complex terms 
180
 
 
6.3.2.1 Th e fi rst type of determinable/determinant pairs 
181
 
 
6.3.2.2 Th e second type of determinable/determinant pairs 
181
 7. Modes of Personal Supposition 
184
7.1 Introduction to medieval theory 
184
7.2 Th e 14th-century defi nitions of the modes 
186
7.3 Clarifi cation of the defi nitions 
189
 
7.3.1 Th e nature of ascent and descent 
190
 
7.3.2 Occurrences of terms have modes of supposition  
190
 
7.3.3 Repeated occurrences must be ignored 
190
 
7.3.4 Empty terms  
192
7.4 Causes of the modes 
193
7.5 Restricted descent and parasitic terms 
197
7.6 A variant account of merely confused supposition 
199
7.7 Useful inferences 
202
 
7.7.1 Superiors and inferiors 
202
 
7.7.2 Monotonicity  
205
 
7.7.3 Parasitic terms 
206
 
7.7.4 Additional useful inferences and non-inferences 
207
7.8 Refi ning the theory: Distinguishing two kinds of distributive supposition 
209
7.9 Causes of the refi ned modes  
211
 
7.9.1 Modes of supposition in Linguish 
212
7.10 Useful inferences again 
214
 
7.10.1 Complete induction 
214
 
7.10.2 Switching scopes (thereby switching modes of supposition)  
216
 
7.10.3 Algorithms 
217
7.11 Modes of supposition as analyses of quantifi cation 
218
 
7.11.1 Categorical propositions whose terms are non-parasitic and simple 
220
 
7.11.2  Categorical propositions whose terms are simple with one or more 
parasitic terms 
 
221
 
7.11.3 Categorical propositions with complex terms 
221
 
7.11.4 Rules from inferior to superior and from superior to inferior 
222

x 
contents
7.12 Global quantifi cational import 
223
 
7.12.1 What are modes of common personal supposition? 
223
 
7.12.2 Causes of the modes and global import 
225
 
7.12.3 Parasitic terms 
226
 8. Relatives (Anaphoric Words) 
227
8.1 Relatives of identity 
227
8.2 Refl exive pronouns 
229
8.3 Relatives in Linguish 
233
 
8.3.1 Th e semantics of relatives that fall within the scope of their antecedents 
234
 
8.3.2 Rules of inference for indexed expressions 
236
8.4 Non-refl exive relatives of identity 
239
8.5 Applying the singulation theory 
244
8.6 An application of relatives to syllogistic 
252
8.7 Donkey anaphora 
254
8.8 Common term relatives of identity and diversity 
256
 9. Comparison of Medieval Logic with Contemporary Logic 
259
9.1 Th e expressive power of medieval logic 
259
 
9.1.1 Medieval logic without anaphoric pronouns 
260
 
9.1.2 Medieval logic with anaphoric expressions 
261
9.2 Representing medieval logic within modern predicate logic with identity 
262
9.3 Representing modern logic within medieval logic: Th e problem of 
existential import 
262
9.4 Representing modern logic within medieval logic: Grammatical issues 
265
9.5 First-order arithmetic in medieval logic 
269
 
9.5.1 Peano’s postulates 
269
 
9.5.2 Defi nition of addition 
271
 
9.5.3 Multiplication 
275
10. Ampliation and Restriction 
276
10.1 Univocation as the source of ampliation and restriction 
276
10.2 Ampliation and restriction by tenses 
280
 
10.2.1 Tenses 
280
 
10.2.2 A Complexity: Ambiguity or disjunction? 
280
 
10.2.3 Coordination of times in tensed sentences  
281
 
 
10.2.3.1 Coordination of times between subject and predicate  
281
 
 
10.2.3.2 Tenses with relative clauses  
282
 
 
10.2.3.3 Coordination of times among parts of the subject or predicate 
285
 
 
10.2.3.4 Subclauses and coordination of tense 
285
 
10.2.4 Buridan’s special use of appellation 
286
 
10.2.5 Tenses in Linguish 
288
 
 
10.2.5.1 If singular terms are not subject to restriction and ampliation 
294
 
10.2.6 Infi nitizing negation 
294
10.3 Ampliation by modal terms 
295
 
10.3.1 What are modal propositions? 
295
 
10.3.2 Modal propositions: Semantics  
296

contents 
xi
 
10.3.3 Diff erences between medieval and modern readings 
297
 
10.3.4 Modal propositions in Linguish 
298
10.4 Ampliation due to semantic words 
299
 
10.4.1 Looking ahead 
299
10.5 Ampliation due to words which pertain to the soul 
300
10.6 Promising and owing 
302
Appendix: Artifi cial Quantifi ers in Early 16th-Century Logic 
306
1. Th e signs 
307
2. What the signs mean 
308
3. Th e signs are, in a sense, logically dispensable 
310
4. A doubt: Certain examples do not work as advertised  
311
5. Another doubt: Th e paradigm use of sign ‘d’ is incoherent 
313
6. Some examples from John Major 
315
Selected Bibliography 
319
Index 
 
328

List of Tables
1.1. Logical forms of categorical propositions 
8
1.2. Th e quality and quantity of propositions 
8
1.3. Aristotle’s contributions to the diagram 
10
1.4. Th e square of opposition 
11
1.5. All valid categorical syllogisms 
16
2.1. Figure 1 from Prior Analytics, chapter 4 
30
2.2. Figure 2 from Prior Analytics, chapter 5 
32
2.3. Figure 3 from Prior Analytics, chapter 6 
34
2.4. Figure 1 indirect moods from Prior Analytics, chapter 7 
38

Preface
I have benefi tted greatly from discussion with the participants in several meetings of 
the Moody Conference over the years, as well as occasional collaborative seminars at 
UCLA, from participants in the 2001 Copenhagen meeting on Buridan’s philosophy, 
in the 2003 Midwest Conference on Medieval Philosophy in Omaha, and at a pair of 
talks in 2006 at the University of Barcelona, from the 2007 International Conference 
on the Square of Opposition in Montreux, from the 17th meeting of the European 
Symposium for Medieval Logic and Metaphysics in Leiden in 2008, and the 19th meeting 
in Geneva in 2012, from talks at McGill University in 2008 and again in 2010, from 
a talk at the University of Nevada at Las Vegas in 2009, and another at the Society for 
Exact Philosophy in 2010.
I have particularly benefi tted in various ways from interactions with E.J. Ashworth, 
Steve Barney, David Blank, John Carriero, Sten Ebbesen, Elizabeth Karger, Peter King, 
Gyula Klima, Henrik Lagerlund, Marko Malink, Chris Martin, John Martin, Gary 
Matthews, Ana Maria Mora, Catarina Dutilh Novaes, Claude Panaccio, Alex Radulescu, 
Stephen Read, Paul Vincent Spade, Joke Spruyt, Paul Th om, Sara Uckelman, Jack Zupko.
Th is book has been years in preparation. Th roughout this time I have benefi tted 
from occasional sabbaticals granted by the University of California, and I have been 
nurtured by my family and by my UCLA colleagues. I have been aided by discussions 
with my various colleagues. I owe special debts of gratitude to Brian Copenhaver and 
to David Kaplan, and especially to Calvin Normore for his support and insight over the 
years. And, of course, to my wife Anette, who claims not to understand the work I do, 
but in some ways understands it most of all.

This page intentionally left blank 

introduction 
1
Introduction
Modern logic can be seen as a group of theories and practices clustered around a well-
studied and well-understood paradigm theory, namely, fi rst-order predicate logic with 
relation symbols and identity. Th is central theory is a formal logic, and formal tech-
niques can be used to validate a vast number of arguments using only a small number 
of basic principles.
Th e main theme of this book is that medieval logic can also be seen as a group of 
theories and practices clustered around a core theory which is a paradigm of logic; this 
theory consists of a number of widely known principles, all of which can be derived 
from a very simple core of rules and axioms. Unlike today, however, this was not widely 
known, and there were only a few attempts to carry out the project of deriving most 
principles from a basic few. (Buridan’s TC is a prominent exception.) It has taken me 
some time to arrive at this view. Medieval writings by logicians can seem to consist of a 
variety of unsystematic and disparate remarks, and it is not at all obvious whether or 
how they fi t together. Th at is what this book is about.
Th ere are two striking diff erences between medieval logic and modern logic. One is 
the assumptions that are made concerning existential import; in medieval logic ‘every 
A is B’ entails that something is A. Th is needs to be taken seriously, and the details need 
to be worked out, but from a point of view of general logical principle, this diff erence is 
not a great one. Th e other diff erence is that medieval logic is formulated entirely within 
a natural language, Latin. Th is is a major constraint that needs to be respected and dealt 
with. It shapes the development of the theory from start to fi nish. To be sure, medieval 
Latin is a somewhat artifi cial natural language. In medieval times it was no longer any-
body’s native tongue; everyone learned it by schooling, as a second language. However, 
what is important for my purposes is that it has the grammatical structure of a natural 
language; in particular, it obeys the “theta-criterion”, as discussed in section 4.1.
Medieval logic begins from the logical theory developed by Aristotle. It is well 
known that Aristotle formulated a system of logic involving conversions (Some A is a 
B; therefore some B is an A) and syllogisms. It is also fairly well known that he assumed 
certain “fi rst fi gure” syllogisms as axiomatic; these are argument forms such as:
Every B is a C
Every A is a B
∴ Every A is a C

2 
introduction
and he proved all of the other forms from these and the conversion principles. What is 
much less well known is that he did not just assume the conversion principles; he 
proved them. I see the techniques that he used to prove those principles as much more 
important and interesting than the developed system of logic for which he is known. 
One of these techniques is well known today: indirect derivation, or, as he called it, 
reductio: to prove a proposition, assume its contradictory and then derive something 
absurd. Two other principles are oft en lumped together under the Greek term ‘ekthesis’. 
One of these is that if you are given an existential proposition, you can “choose one of 
the things that makes it true.” In modern logic, this is existential instantiation; given 
‘∃xFx,’ pick some name ‘n’ that is not used elsewhere in the derivation and write ‘Fn,’ and 
then reason from this rather than from ‘∃xFx.’ In Aristotle’s notation you are given 
something like ‘some F is a G’ and you pick a name ‘n’ not used elsewhere, and write 
both ‘n is an F’ and ‘n is a G.’ (In modern logic one would write the conjunction of these 
formulas, but Aristotle didn’t bother with conjunctions.) Th e third technique is an 
analogue of our modern existential generalization: given ‘Fn’ one can infer ‘∃xFx.’ 
In Aristotle’s notation, given both ‘n is an F’ and ‘n is such and such’ one infers ‘some F is 
such and such.’ Using these three techniques Aristotle proved the conversion principles, 
and he also made occasional use of those principles in reducing some syllogisms to 
others. Th is was a major advance. What was not known then, or throughout the Middle 
Ages, is that using these three techniques, one may also prove all of the fi rst fi gure 
syllogisms,1 so that those three principles provide a foundation for all of Aristotle’s 
well-known system of logic. Th is is laid out in Chapters 1 and 2 of this book.
Medieval logicians inherited Aristotle’s work together with propositional logic 
as developed principally by Stoic logicians. Chapter 3 addresses the evolution of this 
theory in the early 13th century. Much of the additional advances at this time were 
driven rather straightforwardly by expansions of the logical notation. For example, 
Aristotle did not allow quantifi ed predicate terms; he argued that one should not write 
‘Every man is every animal’ because it is not true. But ‘No man is every animal’ is true, 
and it has a quantifi ed predicate, and logicians began using such forms freely. Th ey also 
constructed sentences with negations sprinkled throughout. Once you can write 
things like ‘Every A isn’t a B’ it doesn’t take much to notice that this is equivalent to 
‘No A is a B’, and logicians formulated principles for interchanging quantifi er signs 
and negations, holding, for example, that ‘No A  .  .  .’ is equivalent to ‘Not some A  .  .  .  ,’ 
and that ‘Some A  .  .  .’ is equivalent to ‘Not every A not  .  .  .  ,’ and so on. And once singular 
terms are allowed to occur anywhere that a quantifi ed common term can, it is clear 
that singular terms permute with negations, and with other terms, so that ‘Socrates no 
stone is’ is equivalent to ‘No stone Socrates is.’ And once instances of the transitivity of 
identity became formulable it too was recognized as a valid principle. All of this results 
in a rich system of logic in which a few fundamental principles permit the derivation 
of the rest.
1 Th om 1976.

introduction 
3
Th e richness of medieval logic is especially interesting because the entire enterprise 
is formulated entirely within natural language—at least, within a somewhat regimented 
version of natural language. So this is a version of logic in which there is no logical 
form except for grammatical form.2 Logicians made this work in part by stipulating 
how Latin is to be understood, holding e.g. that surface order of words determines 
their semantic scope, so that a sentence having Latin words in this order: ‘A woman 
owns each cat’ is understood to have exactly one reading, meaning that there is a 
woman such that she owns every cat. To articulate the other reading that is possible 
in natural English you would have to use a Latin sentence with the word order: ‘Each 
cat a woman owns,’ which is completely grammatical in Latin, and is stipulated to mean, 
unambiguously, that every cat is such that some woman owns it. Th is stipulation takes 
advantage of the relatively free word order of Latin to express quantifi er scope. (It is 
distinctive of medieval logicians that they spend substantial time on matters of scope.) 
To make clear the logical theory that was developed it is essential to know the exact 
grammatical forms of the propositions that are employed. Chapter 4 develops a system 
for encoding and clarifying the grammatical structures of propositions, and there are 
additional expansions and applications in Chapters 5 and 6.
Th ese expansions of the notation permit the validation of rather complex arguments, 
such as:
Some farmer’s every donkey sees every horse which a merchant owns.
∴ Not every horse no donkey sees.
However, the resulting system of logic, because of grammatical constraints, is still 
limited in its expressive resources. To become adequate one also needs anaphoric pro-
nouns, as in ‘Some woman owns a donkey which she feeds.’ Th is is the task of Chapter 8. 
If I am right, we are confronted in the texts by two ideas about how anaphoric pro-
nouns work. One of these—the method of singulation—is invoked as an analysis of 
refl exive pronouns. Th is is roughly the idea that anaphoric pronouns are unaff ected by 
inferences involving their antecedents. For example, given that Socrates is a man and 
every man loves his mother, we infer that Socrates loves his mother, where the ‘his’ 
remains unchanged while its antecedent changes from ‘every man’ to ‘Socrates.’ Th is 
method works well for refl exives and for a host of other pronouns as well. Th ere is 
a second method that is much discussed, and that works well in a fairly broad range 
of cases, but gives clearly wrong results in quite a few. Th is is roughly the idea that 
an anaphoric pronoun is an independent term; it stands for the same things as its 
antecedent, and has the same kind of quantifi cational status. As Reinhard Hülsen 
2 Th is needs certain qualifi cation. For example, in Latin all of the following sentences have the same 
grammatical form: ‘Man is a noun,’ ‘Man is a species,’ ‘A man is a philosopher.’ In the fi rst, the term ‘man’ is 
said to have “material supposition”; it is taken to stand for itself. In the second, the term is said to have “simple 
supposition”; it is taken to refer to a form (if there are such things; otherwise it refers to a concept or a word). 
In the third, the term ‘man’ is said to have “personal supposition”; it is taken to stand for individual men. All 
of the logic investigated in this book pertains to this last interpretation. 

4 
introduction
notes,3 if the fi rst method, the one developed for refl exives, is used in place of the 
second method, a much better theory results. And at least some later medieval logi-
cians did just that. With the fi rst method, inference principles previously given yield 
a system of logic that is similar to the predicate calculus in richness and power. At least, 
this is what I argue in Chapter 9.
In addition to the topics already mentioned, we look in Chapter 7 at what is most 
distinctive of late medieval logic, and most well known: the useful theory of modes 
of personal supposition. We also examine the special terms that were used to accom-
modate sentences containing three or more main quantifi ed phrases. A great deal 
is now known about these matters, but it is clear that this project will leave far more 
questions open than it answers.
Chapter 10 and the Appendix touch on further developments of the logical theory.
In focusing on principles of inference that were widely acknowledged I may fail to 
convey an accurate impression of the diversity of the various writings in medieval 
logic, and of the various ways in which authors disagreed with one another. Th ese 
diff erences and disagreements are widely discussed in the secondary literature. Much 
of this is fascinating, but it is not my goal to cover it all here. Instead I focus on a few 
principles that are widely acknowledged and that are rarely debated. It has been sug-
gested that I am trying to impersonate a 15th-century logician who happens to have 
the skills and habits of a 21st-century graduate student. I discuss known medieval 
views with some care, and show how far one can go without introducing any logical 
principles beyond the medieval ones.
I have tried to give enough quotes and citations to ground my assertions in the 
historical record. However, it is a skewed record. First of all, my work is based entirely 
on western European texts that have been edited and published, and there are a vast 
number of yet unedited manuscripts. Further, most of the work I report on here is 
available in English translation, so untranslated works are not emphasized. Fortunately, 
the number of fi rst-rate English translations has now reached the point where some-
one can learn much about medieval logic directly without being able to read Latin. 
Almost all of the quotations that I give are in English. When quoting from a published 
translation I use the translator’s own words; otherwise I am responsible for them. 
Most citations to medieval works are given in terms of an abbreviation of the title of 
the work (e.g. ‘SD’ for ‘Summulae de Dialectica’) followed by a series of numbers, such 
as ‘2.3.7.’4 Page numbers, when given, refer to the English translation, or to the page 
numbers of the Latin edition if they are included in the English translation, or if there 
is no published translation. Th e texts referred to mostly date from 1200 to 1425, aft er 
Abelard and up to and including Paul of Venice, with a few later texts also discussed. 
3 Hülsen 1994, 2000.
4 Th e meaning of the numbers will vary, depending on how the text in question is demarcated; e.g. it 
might mean the seventh section of the third chapter of the second book, or the seventh subsection of the 
third section of the second chapter. Such numbering is usually common to both the Latin edition and to the 
English translation.

introduction 
5
In addition to several anonymous writings, the main logicians referred to are Peter of 
Spain, William Sherwood, Lambert of Lagny, Roger Bacon, Walter Burley, William 
Ockham, John Buridan, Albert of Saxony, Marsilius of Inghen, John Wyclif, and Paul 
of Venice. Th is group includes both metaphysical realists and nominalists. Although 
realists and nominalists provide semantic accounts that diff er in important details,5 
the logical principles that they endorse are pretty much the same, and so metaphysical 
diff erences are mostly not relevant. Likewise for disputes between Th omists and 
non-Th omists.6
It should be apparent that this book does not contain any new historical discoveries; 
rather it relies on discoveries by others. Over the years I have benefi tted enormously 
from the secondary literature in learning about medieval logic. However, much of the 
discussion there is not directly relevant to the issues taken up here, and it would be 
distracting to include it—and it would lengthen this book considerably. I want to 
hereby acknowledge my indebtedness to the many authors who have published on this 
topic, and from whom I have learned.
Th is book is not meant as a general introduction to medieval logic.7 Further, there 
are several areas of great logical interest that are not discussed here at all: these include 
medieval discussion of Aristotle’s topics8 and fallacies,9 insolubles (semantic and other 
paradoxes),10 obligations (rules for debates),11 syncategoremata (special logical prin-
ciples of individual words),12 sophisms (logical and grammatical puzzles),13 exponibles 
(analyses of special words, such as ‘only’),14 future contingents,15 consequences (meta-
principles of propositional logic),16 and systems of modal logic17 (though modal 
sentences are discussed to some extent). Th ese are all widely treated elsewhere. 
 5 For an illustration of some of the contrast between realists and nominalists see Klima 2011.
 6 Aquinas did not discuss general principles of logic much. A full set of views are laid out by his follower 
John of Saint Th omas (Jean Poinsot) in a very competent work from the early 1600s; the logical doctrines 
laid out there mesh nicely with the ones discussed here. I do not cite passages from this work because it was 
written considerably later than the period I am discussing.
 7 For a good general introduction see Kretzmann, Kenny, and Pinborg 1982; Marenbon 1987; also 
Lagerlund 2012, Broadie 2002, Spade 1996. Boehner 2012 is still a good overview.
 8 See Stump 1982.
 9 See the Introduction to Copenhaver, forthcoming, as well as Peter of Spain’s own discussions; also the 
Introduction to Klima 2001, as well as Buridan’s own discussions.
10 For a very brief overview see Spade 1982; also Spade 1988b, Simmons 2008, Yrjönsurri 2008.
11 For a brief overview see Stump 1982 and Spade 1982b; also Dutilh Novaes 2007.
12 For a brief overview see Kretzmann 1982.
13 For a brief overview see Kretzmann 1982; also Read 1993.
14 For a brief overview see Kretzmann 1982.
15 For a brief overview see Normore 1982.
16 For a brief overview see Boh, “Consequences,” pp. 300–14 in Kretzmann, Kenny, and Pinborg 1982; 
also Dutilh Novaes 2007.
17 For a brief overview see Knuuttila 1982 and 2008; also Th om 2003.

6 
an overview of aristotelian logic as seen by medieval logicians
1
An Overview of Aristotelian Logic 
as seen by Medieval Logicians
Medieval Logic is built on a foundation of logical terminology, principles, and 
methodology contained in the traditional liberal arts, in particular in that part of the 
Trivium called Logic or Dialectic. Th is material is mostly from the writings of Aristotle 
and his commentators, plus the Stoics and others, much of it as interpreted by 
Boethius.1 Th is chapter and the next are devoted to these fundamental parts of logic 
that medieval logicians accepted as the basis of their work.
I begin with an account of the forms of propositions that constitute the subject 
matter of Aristotle’s symbolic logic, as understood by medieval logicians. In keeping 
with medieval terminology, I use the term ‘proposition’ to refer to what we today would 
call a meaningful sentence. It stands for a sentence with meaning, not for a sentential 
form, and not for an abstract meaning expressed by a sentence which is named by a 
that-clause. So ‘Snow is white’ and ‘Schnee ist weiss’ are diff erent propositions.2
1.1 Categorical propositions
I begin with an oversimplifi ed account of what Aristotle had to say, mostly in the fi rst 
seven sections of his short work that is today called On Interpretation, and in the fi rst 
seven sections of his longer work called Prior Analytics. Th is is defi nitely not the only 
way to interpret Aristotle’s works, but it’s a common and straightforward one, and it fi ts 
the usual medieval explanations. I also use some standard medieval terminology 
which Aristotle didn’t use.
1 Th e parts of Aristotle’s symbolic logic that were well known around the year 1000 were his On Inter-
pretation, Categories, and material (oft en second-hand) from the fi rst several sections of his Prior Analytics. 
Th is subject matter was later called the “Old Logic,” to distinguish it from the “New Logic” which was based 
on several additional writings by Aristotle that became available later. 
2 Opinions diff ered on whether there are also mind-independent entities corresponding to propositions. 
For many medievals, propositions are tokens, not types, and this is important in certain cases, such as 
addressing semantic paradoxes, where two tokens of the same type might diff er in truth value. But for the 
most part little would be changed in the theory if propositions were types. 

categorical propositions 
7
In any system of logic it is essential to be clear about the vocabulary you are using, 
and about what propositions can be made using it. Aristotle was clear about this. Th e 
basic propositions are categorical propositions—meaning something like “predicational” 
propositions. Every such proposition consists of a subject term (perhaps modifi ed) 
and a copula (perhaps with a negation) and a predicate term. Th e copula is ‘is.’3 Every 
predicate term is a common noun, such as ‘donkey’ or ‘animal’ or ‘substance’ or an 
adjective such as ‘just.’ Every subject term is a proper noun or a common noun. Th ere 
are eight forms of proposition; four affi  rmative and four negative. First, there are 
affi  rmative and negative “universal” propositions:
Affi  rmative 
Negative
Every A is a B 
No A is a B
where ‘A’ and ‘B’ are common nouns or adjectives. Examples are ‘Every donkey is 
an animal’ and ‘No donkey is an animal.’ In these examples I have used the indefi nite 
article ‘a’ in order to form grammatical English propositions. Th ere is no indefi nite 
article in Greek, and so the indefi nite article appears here as an artifact of English 
grammar.
Th ere are “particular” propositions:
Affi  rmative 
Negative
Some A is a B 
Some A isn’t a B4
Examples are: ‘Some donkey is an animal’ and ‘Some donkey isn’t an animal.’
Th ere are “indefi nite” propositions:
Affi  rmative 
Negative
An A is a B 
An A isn’t a B
Examples are ‘A donkey is an animal’ and ‘A donkey isn’t an animal.’ Again, the English 
examples contain indefi nite articles, where Greek and Latin have nothing at all. Finally, 
there are “singular” propositions:
Affi  rmative 
Negative
n is a B 
n isn’t a B
where ‘n’ is a singular term: specifi cally, ‘n’ is a proper name, such as ‘Socrates,’ or a 
demonstrative term such as ‘this’ or ‘this animal.’ Examples are ‘Socrates is an animal’ 
and ‘Socrates isn’t an animal.’
3 It may be more true to Aristotle to say that there are two (or more) copulas, an affi  rmative one, ‘is’, and 
a negative one ‘isn’t.’ Th is will not be important for the applications discussed in this chapter.
4 In the Latin texts that we will be dealing with the negation naturally precedes the verb, so the word order 
is ‘Some A not is B.’ Generally I use a grammatical English form. I use the contracted form ‘isn’t’ instead of 
‘is not’ in order to de-emphasize the English word order, which diff ers from the Latin. 

8 
an overview of aristotelian logic as seen by medieval logicians
Table 1.1 shows the logical forms of categorical propositions:
Table 1.1. Logical forms of categorical propositions
Affi  rmative
Negative
Universal
Every A is a B
No A is a B
Particular
Some A is a B
Some A isn’t a B
Indefi nite
An A is a B
An A isn’t a B
Singular
n is a B
n isn’t a B
Eventually people began describing the status of being affi  rmative or negative as 
the quality of a proposition, and the other statuses as the quantity of a proposition. 
Table 1.2 shows the eventual classifi cation:5
Table 1.2. Th e quality and quantity of propositions
Quantity
Quality
Affi  rmative
Negative
UNIVERSAL
Every A is a B
No A is a B
PARTICULAR
Some A is a B
Some A isn’t a B
INDEFINITE
An A is a B
An A isn’t a B 
SINGULAR
n is a B
n isn’t a B
5 Many centuries later, Peter of Spain lays out the kinds of non-modal categorical propositions and their 
ingredients. His terminology was standard:
Of categorical propositions, one is universal, another particular, another indefi nite, another 
singular.
A universal proposition is one in which a common term determined by a universal sign is 
made the subject, like ‘every man runs.’ Or else a universal proposition is one that signifi es 
that something is in every item or none.
A common term is one that is naturally suited to be predicated of many, like ‘man’ of Sortes, 
Plato and each one of the other men.
Universal signs are these: ‘every,’ ‘none,’ ‘nothing,’ ‘any-at-all,’ ‘either,’ ‘neither’ and the like.
A particular proposition is one in which a common term determined by a particular sign is 
made the subject, like ‘some man runs.’
Particular signs are these: ‘some’, ‘a-certain’, ‘the-other’, ‘the-remaining’ and the like.
An indefi nite proposition is one in which a common term without a sign is made the subject, 
like ‘man runs.’
A singular proposition is one in which a singular term, or a common term joined with 
a demonstrative pronoun, is made the subject, like ‘Sortes runs’ or ‘that man runs.’
A singular term is one that is naturally suited to be predicated of just one item.
Also, of categorical propositions, one is affi  rmative, another negative.
An affi  rmative categorical proposition is one in which the predicate is affi  rmed of the subject, 
like ‘a man runs.’
A negative categorical proposition is one in which the predicate is eliminated from the subject, 
like ‘a man does not run.’ (Peter of Spain LS I.8–9 (4))

logical relations among categorical propositions 
9
applications
Classify each of the following as to quantity and quality.
A wolf is an animal
Madonna is a singer
No actor is a tycoon
Some actor isn’t a dancer
George Washington isn’t an actor
Every actor is a dancer
1.2 Logical relations among categorical propositions
Singular propositions: Affi  rmative and negative singular propositions with the same 
subject and predicate are contradictories; that is, one of them must be true and the 
other one false.6 So given ‘Socrates is a philosopher’ and ‘Socrates isn’t a philosopher’ we 
know as a matter of logic that one of these is true and the other one false, though we 
may not know which is which. If Socrates actually exists, then ‘Socrates is a philosopher’ 
is true if and only if that man, Socrates, is actually a philosopher, and ‘Socrates isn’t 
a philosopher’ is true if and only if that man, Socrates, is not a philosopher. In case 
Socrates does not exist, the affi  rmative form: ‘Socrates is a philosopher’ is false, and 
the negative form: ‘Socrates isn’t a philosopher’ is true. Since Socrates actually died 
a long time ago, he does not now exist, and so today ‘Socrates is a philosopher’ is false 
and ‘Socrates isn’t a philosopher’ is true.7
Most medieval theorists assume that every well-formed categorical proposition is 
either true or false (and not both). (Th e possible exceptions that were discussed are 
6 In OI Aristotle uses the word ‘contradictory’ to mean something like what we would call ‘opposite,’ and 
he investigates under what conditions pairs of “contradictories” must have one member true and the other 
false. Sometimes they can be true together, as in ‘a man is white’ and ‘a man isn’t white’ (OI 17b30). (See 
Whitaker 1996 for discussion.) But in the ensuing tradition, ‘contradictory’ is taken to mean having opposite 
truth values. Ammonius, writing as early as 470 CE, says (81.14–16) “the defi nition of contradiction  .  .  .  is 
a confl ict of an affi  rmation and a negation which always divide the true and the false so that when one 
of them is false the other is true, and vice versa.” Peter of Spain (LS 1.14): “Th e law of contradictories is this, 
that if one is true, the remaining one is false, and conversely, for they cannot be true or false at the same time 
with any [subject] matter.”
7 Aristotle OI 17b26 (48): “Of contradictory statements about a universal taken universally it is necessary 
for one or the other to be true or false; similarly if they are about particulars, e.g. ‘Socrates is white’ and 
‘Socrates isn’t white’. ” (‘particulars’ could as well be translated ‘singulars.’) Categories 13b30–34 (37): “For take 
‘Socrates is sick’ and ‘Socrates isn’t sick’: if he exists it is clear that one or the other of them will be true or false, 
and equally if he does not; for if he does not exist ‘he is sick’ is false but ‘he isn’t sick’ true.”
I call these eight forms “standard” categorical propositions, to distinguish them from 
the extended forms to be discussed later.

10 
an overview of aristotelian logic as seen by medieval logicians
mostly semantic paradoxes or contingent statements about the future, which are not 
discussed here.)
In his essay On Interpretation Aristotle states that a universal affi  rmative proposition 
is the contradictory of the corresponding particular negative proposition, so ‘Every 
man is a philosopher’ is true if and only if ‘Some man isn’t a philosopher’ is false, and 
vice versa. Th is is supposed to be apparent, given one’s understanding of what those 
propositions say. He holds the same for the negative case; the universal negative is 
the contradictory of the corresponding particular affi  rmative propositions, so that 
‘No man is a philosopher’ is true if and only if ‘Some man is a philosopher’ is false, and 
vice versa.
Aristotle also holds that corresponding universal propositions are contraries, 
meaning that they cannot both be true, although they might both be false. For example, 
‘Every man is a philosopher’ and ‘No man is a philosopher’ cannot both be true, though 
they can both be false. Most logicians today assume that these propositions are not 
contraries; they are not contraries because they are both true if there are no humans; 
they are “vacuously” true. Aristotle did not discuss this possibility, but medieval 
logicians did, and they concluded that Aristotle was right to take them to be contraries. 
Th is is because the universal affi  rmative proposition ‘Every man is a philosopher’ is false 
if there are no men. We will discuss this further later.
1.3 Th e square of opposition
Some commentators on Aristotle found it convenient to use a diagram to keep straight 
Aristotle’s assumptions about the logic of these propositions. Th e diagram (see Table 1.3) 
begins with some of the relationships we have discussed; the universal propositions at 
the top are contraries, and diagonally opposite propositions are contradictories:
Table 1.3. Aristotle’s contributions to the diagram
contradictories
Every A is B
contraries
No A is B
Some A is B
Some A isn’t B
Th e doctrines that Aristotle himself laid out entail others. All of these together were 
typically encapsulated in a square diagram, today called the “square of opposition” 
(Table 1.4):

the square of opposition 
11
Table 1.4. Th e square of opposition
Every A is B
contraries
No A is B
Some A is B
subcontraries
Some A isn’t B
subalternates
subalternates
Aristotle contributed the top side and the diagonals (and he discussed the bottom 
at PA 2.15, where he calls the bottom propositions “opposites verbally”). Th e bottom 
and side relationships follow from the others. In particular, since the propositions 
at the top are contraries, their contradictories at the bottom are “subcontraries”: they 
can both be true but their form prevents them from both being false.8
Universal and particular affi  rmative propositions are related by subalternation, as 
are universal and particular negatives: each universal proposition entails the particular 
directly below it.9 Th is is easy to see. For the affi  rmative case, suppose that ‘Every A is B’ 
is true. Th en its contrary, ‘No A is B’ must be false. So the contradictory of ‘No A is B,’ 
namely, ‘Some A is B’ must be true. Th e reasoning is the same for the negative case: if 
‘No A is B’ is true, then its contrary, ‘Every A is B,’ must be false, so the contradictory 
of ‘Every A is B,’ which is ‘Some A isn’t B,’ is true.
applications
Say how each of the following pairs of propositions are logically related.
Some wolf is an animal, Some wolf isn’t an animal
Madonna is a singer, Madonna isn’t a singer
No actor is a tycoon, Some actor is a tycoon
Some actor isn’t a dancer, No actor is a dancer
George Washington isn’t an actor, George Washington is an actor
Every actor is a dancer, Some actor isn’t a dancer
8 “Th e law of subcontraries is this, that if one is false, the remaining one is true, and not conversely, for 
they can both be true at the same time” (Peter of Spain LS 1.14).
9 “Th e law of subalternates is this, that if the universal is true, the particular is true, and not conversely, 
for the universal can be false with its particular being true. And if the particular is false, its universal is false, 
and not conversely” (Peter of Spain LS 1.14). 

12 
an overview of aristotelian logic as seen by medieval logicians
1.4 Issues concerning empty terms
Th ere are two issues concerning the relations encoded in the square having to do with 
the truth values of propositions with empty subject terms.
1.4.1 Universal affi  rmatives
Th e fi rst issue concerns universal affi  rmative propositions when the subject term is 
empty; for example, ‘Every donkey is a mammal’ when there are no donkeys. Suppose 
that the term ‘A’ is empty.10 Th en ‘Some A is B’ is false.11 According to the principles 
embodied in the square, ‘No A is B’ is its contradictory, and so it must be true. So, by the 
law of contraries, the universal proposition ‘Every A is B’ must be false. Th is goes against 
the modern custom whereby a universal affi  rmative proposition with an empty subject 
term is considered to be trivially true. Th is is because the canonical translation of 
‘Every A is B’ into symbolic logic is ‘∀x(Ax → Bx),’ which is true when ‘A’ is empty.
Modern students oft en balk at the proposal that universal affi  rmatives are true when 
their subject terms are empty. In response they may be told:
Th is is a convention which is useful in logic—it makes for theoretical simplicity. 
Ordinary usage is unclear regarding such propositions with empty subjects. If 
you think that universal affi  rmatives are false when their subjects are empty, 
then you may simply represent them by adding a condition: symbolize them as 
‘∃xAx & ∀x(Ax → Bx).’
It is apparent that one can also adopt the opposite convention, that universal affi  rmatives 
are false when their subject term is empty. Th is is a convention that is convenient for 
doing logic—it makes for theoretical simplicity (we return to this shortly). If you want 
to represent ordinary usage in the contemporary way, as ‘∀x(Ax → Bx),’ then just write 
‘Every A is B, or no A is A.’12
1.4.2 Particular negatives
Th e other issue with the traditional square of opposition concerns particular negatives. 
Suppose that the term ‘A’ is empty. Th en ‘Some A is B’ is false. So according to the prin-
ciples embodied in the square, ‘No A is B’ is its contradictory, and is thus true. So, by 
the principle of subalternation, ‘Some A isn’t B’ is also true. But to modern ears, ‘Some A 
isn’t B’ should be false if ‘A’ is empty. Aft er all, ‘some A,’ has scope over the rest of the 
proposition. What is going on?
Th is result is built into the diagram in other ways as well. Again, suppose that ‘A’ is 
empty, so that ‘Some A is B’ is false. Th en its subcontrary, ‘Some A isn’t B’ must be true. 
10 By an empty term I mean one that has no individuals falling under it. Aristotle uses ‘goat-stag’ for 
an example (Posterior Analytics 2.7). 
11 Th is presupposes an “extensional” interpretation of ‘Some A is B’; on this understanding the proposition 
has exactly the truth conditions assumed in modern logic: ∃x(Ax&Bx). For an interesting and plausible 
alternative see Malink 2013.
12 Th e issue becomes more complicated when propositions become more complex. See section 9.3 for 
discussion.

issues concerning empty terms 
13
Or suppose that ‘Some A is B’ is false; then its superalternate ‘Every A is B’ is also false; 
so the contradictory of that, ‘Some A isn’t B’, is again true.
Some authors did not notice this result, but many did. Most who noticed held that 
this is the right result:13 if ‘A’ is empty, then ‘Some A isn’t B’ is indeed true. Th is may not 
accord well with ordinary speakers of Latin, but logicians insisted that this was the 
right way to read the proposition. Th is is part of their regimentation of the language 
that will be discussed later. It may be defended in the way that any regimentation is 
defended, by claiming that it is useful for logical purposes, even if it does not conform 
well to ordinary usage.14
Of course, this proposal will not work unless other parts of logic are formulated with 
this in mind. For example, we do not want to include the validity of ‘Some A isn’t B ∴ 
Some A is A.’ Th is inference, of course, is not considered valid.
I said that these proposals make for theoretical simplicity, but I didn’t say how. It is this:
Affi  rmative categorical propositions are false when any of their main terms are 
empty.
Negative categorical propositions are true when any of their main terms are empty.
Th ese principles hold for singular propositions and for the forms of categorical pro-
positions we have discussed; they will hold without exception, even when categorical 
propositions are expanded far beyond the forms that Aristotle discussed.
applications
Classify each of the following as to truth or falsehood. (Assume that there are 
now no dodos, that Elvis does not exist, and that Madonna exists.)
Some dodo is an animal 
Some dodo isn’t an animal
Madonna is a singer 
Elvis isn’t a singer
No dodo is an animal 
Every dodo is a dodo
13 Abelard (D, p. 170) thought that this is wrong; he held that the particular negative form should be read ‘Not 
every A is B’ instead of ‘Some A isn’t B.’ He blamed the latter “misreading” on Boethius, who wrote the latter form 
instead of the former, which Aristotle had used. But Aristotle (PA 27a36) uses both forms interchangeably.
14 I think that this interpretation of Aristotle’s logic is consistent with his writings. Other writers disagree 
with this. For example, Robin Smith in the Stanford Encyclopedia of Philosophy on Aristotle’s Logic says: 
“Aristotle in eff ect supposes that all terms in syllogisms are non-empty.” (Smith does not give reasons in that 
work.) Th is view has a substantial following; it was reached in Kneale and Kneale’s classic 1962: “In order to 
justify Aristotle’s doctrine as a whole it is necessary, then, to suppose that he assumed application for all the 
general terms with which he dealt” (60). (I am not certain that I follow their reasoning. I think that it relies 
on only considering the two options: that universals never have existential import, or that universals, both 
affi  rmative and negative, always have existential import.) 

14 
an overview of aristotelian logic as seen by medieval logicians
1.5 Conversions
Th e square of opposition deals with logical relations among propositions which have 
the same subject and same predicate. Th ere are also other relations. If a proposition is 
generated from another by interchanging the original subject and predicate, those 
propositions are candidates for a logical relation of “conversion”:15
Simple conversion: A proposition is said to convert simply if it entails the result of 
interchanging its subject and predicate terms. Universal Negative and Particular 
Affi  rmative propositions convert simply, resulting in equivalent propositions:
‘No A is a B’ converts simply to ‘No B is an A’
‘Some A is a B’ converts simply to ‘Some B is an A.’
Conversion per Accidens (Accidental conversion): Whereas simple conversion 
produces a proposition equivalent to the original, conversion per accidens is not 
symmetric. A universal proposition may be converted per accidens: you interchange 
its subject and predicate terms and change the universal sign to a particular sign 
(adding a negation, if necessary, to preserve quality). Th is inference is not reversible.
‘Every A is a B’ converts per accidens to ‘Some B is an A’
‘No A is a B’ converts per accidens to ‘Some B isn’t an A.’16
Since the universal changes to a particular, this form of conversion is sometimes called 
“conversion by limitation.” Aristotle himself discusses per accidens conversion of the 
universal affi  rmative form; later writers typically include both forms. (Cf. Roger Bacon, 
ASL, para 279.) We discuss proofs of both forms in the next chapter.17
applications
Say which of the following are valid conversions, which are invalid conversions, 
and which are not conversions at all.
Some dodo is an animal ∴ Some animal is a dodo
No dodo is an animal ∴ No animal is a dodo
Some dodo isn’t an animal ∴ Some animal isn’t a dodo
Every dodo is an animal ∴ Every animal is a dodo
Every dodo is an animal ∴ Some animal is a dodo
Every dodo is an animal ∴ Some dodo is an animal
15 Th e conversion laws were proved by Aristotle in Prior Analytics I.2 (2–3). Th ey appear (usually without 
proof) in every major logic text in the Aristotelian tradition, except that conversion per accidens is some-
times dropped from 20th-century texts. 
16 Cf. Peter of Spain, LS I.15, (8). Many authors (including Aristotle) did not mention converting the 
Universal Negative in this way. Th is conversion is a consequence of other logical relations assumed in the 
square. Buridan (SD 1.6.3) argues: “We should note that in this type of conversion even a universal negative is 
validly converted into a particular negative: ‘No B is A; therefore, some A isn’t B.’ For by simple conversion the 
following is valid: ‘No B is A; therefore no A is B’, whence further ‘No A is B; therefore, some A isn’t B’ for 
a universal implies its subaltern particular; therefore ‘No B is A; therefore, some A isn’t B’ is valid, since 
whatever follows from the consequent follows from the antecedent.”
17 An additional mode of conversion—conversion by contraposition—is discussed in section 3.5.

syllogisms 
15
1.6 Syllogisms
Syllogisms form the heart of what is today commonly called Aristotelian logic. A 
syllogism is a special form of argument containing two premises and a conclusion, 
each of which is a non-singular standard form categorical proposition. Th ere are three 
distinct terms;18 one of them, the “middle” term, occurs once in each premise. Each 
of the other terms occurs once in a premise and once in the conclusion. An example of 
a syllogism is any argument having the following pattern:
Every M is P
Some M is S
∴ Some S is P
Th e fi rst premise is called the major premise and the second is called the minor. Th ese 
individual argument patterns are called “moods,”19 and the moods in turn are classifi ed 
into three “fi gures.” Th e fi rst fi gure includes moods in which the middle term occurs as 
subject in the fi rst premise and predicate in the second; in the second fi gure the middle 
term is predicate in both; and in the third fi gure it is the subject in both. Aristotle dis-
cusses some of the fi rst fi gure moods as well as the second and third fi gure moods in 
chapters 4–6 of Prior Analytics I, and he discusses some additional fi rst fi gure moods in 
chapter 7, for a total of 19 good moods.
Th ere are fi ve additional valid patterns that neither he nor many medieval authors 
mention; these are forms which conclude with a particular proposition when the super-
alternate universal proposition is provable from the same premises.20 An example is:
Every A is B
Every C is A
∴ Some C is B
Th e moods are divided into direct and indirect, where a direct mood is one in which 
the fi rst premise contains the predicate of the conclusion. In the second and the third 
fi gures all of the moods that Aristotle discusses are direct. Interchanging the premises 
in these fi gures produces indirect moods that are in the same fi gure. Since interchang-
ing the premises of a mood cannot aff ect validity, the results of swapping premises are 
not listed as additional moods (though in the fi rst fi gure the direct and indirect moods 
are separately listed). Sometimes only the direct moods are listed in fi gure 1, and the 
18 Aristotle also discusses cases in which two terms are identifi ed, so there are four occurrences of one 
term and two of the other. 
19 Th e term ‘mood’ might better be translated ‘mode,’ but the former term is standard in the tradition.
20 Aristotle has only 19 moods because he is examining which combinations of premises can yield a valid 
syllogism, and there are 19 of these. Five of those yield more than one conclusion, and thus there are 24 all 
told if the pattern includes the form of the conclusion. Th e tradition typically discusses only the forms with 
the stronger conclusion. E.g. Arnauld and Nicole 1662, 142: “people have been satisfi ed with classifying 
syllogisms only in terms of the nobler conclusion, which is the general. Accordingly they have not counted as 
a separate type of syllogism the one in which only a particular conclusion is drawn when a general conclu-
sion is warranted.” 

16 
an overview of aristotelian logic as seen by medieval logicians
indirect moods of the fi rst fi gure are said to constitute a fourth fi gure, but that was not 
the custom in medieval times.
All 24 valid moods are included in Table 1.5, using medieval names of the moods 
with Peter of Spain’s spelling (LS 4.13).21 (For the signifi cance of these names, see 
section 2.9.)
Every valid categorical syllogism either has one of these forms explicitly, or it yields 
one of these forms by transposing the premises. Th e unnamed moods in the chart were 
not mentioned by Aristotle. Chapter numbers indicate the chapter of Prior Analytics I 
in which Aristotle discusses the fi gure. Th e specifi c reference codes indicate where in 
the chapter he discusses the mood.
21 Some authors say that Aristotle has only 14 valid moods; these are the moods he discussed explicitly in 
chapters 4–6 of the Prior Analytics. Five more are sketched in chapter 7. Medieval authors included all 19. 
Aristotle also provides counterexamples for all invalid moods, for a complete case-by-case coverage of all 
possible syllogisms. 
Table 1.5. All valid categorical syllogisms
Figure 1 (ch. 4)
Figure 1: indirect (ch. 7)
Figure 2 (ch. 5)
Figure 3 (ch. 6)
Barbara (26a1)
Every M is P
Every S is M
∴ Every S is P
Baralipton
Every M is S
Every P is M
∴ Some S is P
Cesare (27a5)
No P is M
Every S is M
∴ No S is P
Darapti (28a18)
Every M is P
Every M is S
∴ Some S is P
Every M is P
Every S is M
∴ Some S is P
Celantes (29a26)
No M is S
Every P is M
∴ No S is P
No P is M
Every S is M
∴ Some S isn’t P
Felapto (28a27*)
No M is P
Every M is S
∴ Some S isn’t P
Celarent (26a3)
No M is P
Every S is M
∴ No S is P
No M is S
Every P is M
∴ Some S isn’t P
Camestres (27a8)
Every P is M
No S is M
∴ No S is P
Disamis (28b7)
Some M is P
Every M is S
∴ Some S is P
No M is P
Every S is M
∴ Some S isn’t P
Dabitis (29a26)
Every M is S
Some P is M
∴ Some S is P
Every P is M
No S is M
∴ Some S isn’t P
Datisi (28b12*)
Every M is P
Some M is S
∴ Some S is P
Darii (26a23)
Every M is P
Some S is M
∴ Some S is P
Fapesmo (29a22)
Every M is S
No P is M
∴ Some S isn’t P
Festino (27a31)
No P is M
Some S is M
∴ Some S isn’t P
Bocardo (28b18*)
Some M isn’t P
Every M is S
∴ Some S isn’t P
Ferio (26a25)
No M is P
Some S is M
∴ Some S isn’t P
Frisesomorum (29a22)
Some M is S
No P is M
∴ Some S isn’t P
Barocho (27a36)
Every P is M
Some S isn’t M
∴ Some S isn’t P
Ferison (28b33)
No M is P
Some M is S
∴ Some S isn’t P

syllogisms 
17
Th e names of the moods encode logically signifi cant information about the mood. 
Th ese are discussed in section 2.9. But part of the code is already evident here. In each 
case the fi rst three vowels of the name of the mood indicate the quality and quantity of 
the premises and conclusion, in order, using the correlation:
a: universal affi  rmative
e: universal negative
i: particular affi  rmative
o: particular negative
For example, Barocho has a universal affi  rmative proposition (‘a’) as its fi rst premise, 
and it has particular negative propositions (‘o’) for its second premise and conclusion. 
If you know which fi gure the mood is, and (in the fi rst fi gure) if you know whether it 
is direct or indirect, this completely determines the logical form of the mood.
Some of the valid forms of syllogism, such as Darapti, rely on universal affi  rmatives 
having existential import. None of the 19 traditional syllogisms rely on particular 
negatives being true when their subject term is empty, although two of the unmentioned 
moods rely on this (namely, the unmentioned fi rst fi gure indirect mood and the second 
of the unmentioned second fi gure moods).
applications
Identify the mood of each of the following syllogisms. (In answering this it will 
be effi  cient to fi rst identify the fi gure of the syllogism by locating the positions of 
the middle term.)
 
Some dodo is a bird
 
Every dodo is an animal
∴ 
Some animal is a bird
 
Every dodo is a bird
 
Some animal is a dodo
∴ 
Some bird is an animal
 
Every bird is an animal
 
Every dodo is a bird
∴ 
Every dodo is an animal
 
No dodo is a bird
 
Every animal is a bird
∴ 
No animal is a dodo
 
No dodo is a bird
 
Some dodo is an animal
∴ 
Some animal isn’t a bird

18 
an overview of aristotelian logic as seen by medieval logicians
1.7 Infi nite negation
In addition to terms consisting of common nouns or adjectives, Aristotle included 
what he called “infi nite” or “indefi nite” terms. Such a term consists of a common noun 
with the prefi x ‘non,’ such as ‘non-donkey.’ Aristotle insisted that such a term is not 
a noun, although it occurs in exactly the same place in a proposition as a common 
noun. Th ese terms require special discussion because the same word occurs both 
as sentential negation and as term negation in Greek, and this is also true in Latin, 
which uses ‘non’ for both purposes. Conventions of word spacing did not allow one to 
distinguish between them. So e.g. the Latin sentence:
Non homo est animal
is ambiguous between the false proposition ‘Not: [a] man is [an] animal’ and the true 
proposition ‘[A] non-man is [an] animal.’ Aristotle took pains to distinguish the two 
kinds of negation with respect to forming contradictories. For example he pointed out 
that these are four diff erent propositions:
A man is just
A man is not just
A man is non-just
A man is not non-just
Later logicians made much of the presence of indefi nite terms, proposing special 
equivalences governing them. Th ese are discussed in section 3.5.
1.8 Formal validity
We have used the term ‘valid’ in assessing Aristotle’s syllogisms. He himself did not use 
such terminology. He merely defi ned what a deduction is:
A deduction is a discourse in which, certain things having been supposed, something diff erent 
from the things supposed results of necessity because these things are so. (PA 1.1)
Many medieval logicians interpreted this modally, holding that a purported argument 
is good if and only if it is not possible for its premises all to be true when its conclusion 
is false. Variants of this idea were common. Notice that this says nothing about an 
argument’s being formal. And indeed, it was common in the medieval period to take 
the following as a paradigm of a good argument:
 
Socrates is a man
∴ 
Socrates is an animal
But in Aristotle’s systematic development—his theory of syllogisms—he concentrates 
on formally good arguments. A formally good argument remains good if the non-
logical terms are replaced by other terms. Th e argument just given is not formally good 

formal validity 
19
because it does not remain good when ‘animal’ is changed to ‘stone.’ Aristotle’s endorsed 
syllogisms however are all formally good. For example, this instance of Barbara is good 
by Aristotle’s defi nition:
 
Every animal is a substance
 
Every donkey is an animal
∴ 
Every donkey is a substance
And it will still be good by his defi nition even if the terms are changed, as in:
 
Every stone is a tree
 
Every monkey is a stone
∴ 
Every monkey is a tree
It is clear that Aristotle is interested in formal goodness of an argument, since at PA 1.4 
he says that no argument of the form:
 
No C is B
 
Some B isn’t A
∴ 
Some A is C
is good because this argument is no good:
 
No raven is a horse
 
Some horse isn’t white
∴ 
Some white thing is a raven
Th is certainly does establish that no argument of the fi rst form is formally valid, but it 
does not address whether any such argument might be non-formally valid.
Medieval logicians held a wide variety of views about the nature of validity, and 
many articulated notions of formal validity. I cannot survey them all here.22 For my 
purposes I need a straightforward notion that will allow me to classify principles that 
are intended to validate a class of resembling arguments as good arguments. I will 
use this simple modern notion: an argument is formally valid if and only if no matter 
how its terms and verbs other than the copula are interpreted one never gets all true 
premises and a false conclusion. All of Aristotle’s conversions and syllogisms are 
clearly valid in this sense, and many additional principles will also be valid in this 
sense. Using this notion we can raise the question of whether the available rules of 
inference capture all valid arguments.
Th ere is a well-known objection to using this notion of validity in modern logic. 
Th e objection holds that it classifi es certain intuitively invalid arguments as valid. 
An example is this argument:
 
∀x x=x 
<everything is self-identical>
∴ 
∃x∃y∼x=y 
<there are at least two distinct things>
22 For a brief review see Dutilh Novaes 2008, section 3.3, 474–7.

20 
an overview of aristotelian logic as seen by medieval logicians
In this argument there are no terms at all, and the only verb is the copula. Since there 
are in fact two distinct things, it is vacuously true that no matter how the terms and 
verbs other than the copula are interpreted, one never gets a true premise and a false 
conclusion. But the conclusion—that there are at least two things—does not follow 
intuitively from the premise, since it could be that there are not two things. Th is is an 
awkwardness for symbolic logic. But it is not a problem for medieval logic. For from a 
medieval point of view the source of the awkwardness rests on a defect in the notation 
of symbolic logic. Consider each of the following phrases:
some donkey
some tree
some thing
Each of these consist of a formal logical word, ‘some,’ and a common noun. Th e com-
mon noun is not a piece of formal logical notation. And when the two words in the 
last phrase are put together to form the word ‘something,’ this should not be a piece of 
formal logical notation either. Th e symbolic argument earlier ought to be worded 
something like:
for every thing x, x=x ∴ for some thing x, for some thing y, ∼x=y
And this is not valid on the substitutional criterion, because the following has the same 
form, and its conclusion isn’t true:
 
for every moon (of earth) x, x=x
∴ 
for some moon (of earth) x, for some moon of (earth) y, ∼x=y
For defi niteness, throughout this book I will be employing the modern notion, applied 
to medieval symbolism. Th e rules of inference that I discuss throughout are valid 
in this modern sense (and they are also valid in several of the senses employed by 
medieval logicians).

formal derivations 
21
2
Aristotle’s Proofs of Conversions 
and Syllogisms
Early in Aristotle’s Prior Analytics I 1–7 he proves the conversion principles. Th en he 
assumes that certain syllogistic moods are “perfect,” and he “reduces” all of the remain-
ing valid syllogisms to the perfect ones—that is, he derives the imperfect syllogisms 
using the conversion principles and the perfect syllogisms. In my opinion, the logical 
techniques that Aristotle himself uses to prove the conversion principles and derive all 
syllogisms from the evident ones are of much greater interest than the conversions and 
syllogisms that he validates. Th e goal of this chapter is to look in detail at his proofs 
and to state a very simple system of rules within which the proofs can be carried out 
formally. Th ese are all rules which were known by medieval logicians.
2.1 Formal derivations
Aristotle’s proofs are stated informally. To come up with formal analogues I will use a 
lines-and-bars natural deduction system. In this system a derivation contains a vertical 
bar with a horizontal bar extending to its right. Any proposition may occur on a line 
above the main horizontal bar; these are the premises of the derivation. Lines below 
the bar can only appear if justifi ed by a rule of derivation.
← premises
← things derived from the premises
As an illustration, a formal derivation in modern symbolic logic to establish the validity 
of this argument:
A&B
B→C
∴ C
could look like this:

22 
aristotle’s proofs of conversions and syllogisms
from 1 by Simplification
from 2 and 3 by Modus Ponens
A&B
B→C
B
C
1.
2.
3.
4.
Derivations may also contain subderivations. A subderivation is exactly like a derivation 
except that it contains only one line (the “assumption”) above its horizontal bar.
Th ere are two sorts of rules. One sort lets you infer things from available lines depend-
ing on their logical form. (Available lines are previous lines that are not within an already 
completed subderivation.) Another kind of rule lets you infer things from a subderiva-
tion itself. For example, the modern rule of “conditional proof” lets you write ‘A→B’ 
immediately aft er any subderivation whose assumption is ‘A’ and whose last line is ‘B.’
A properly constructed derivation shows that an argument is valid if the sentences 
above the main horizontal line in the derivation are all among the premises of the 
argument, and the last line of the derivation (1) is the conclusion of the argument and 
(2) is not within a subderivation and (3) does not contain a name introduced by rule 
EX discussed shortly.
Aristotle primarily used three principles of proof. One is indirect proof, which he 
called “reduction to the impossible,” or just “reductio.” Th e idea is that you can prove 
a proposition if you assume its contradictory (as an assumption of a subderivation) 
and then derive something impossible (within that subderivation). For him, you have 
derived something impossible if you derive some proposition that is the contradictory 
or the contrary of some other available proposition in the derivation. Th is rule then 
lets you immediately follow the subderivation by the contradictory of its assumption.
Indirect proof (Reductio):
If there is a subderivation of this form:
P
A
← a contrary or contradictory of an available line
then immediately following the subderivation one may write
Q
provided that Q is a contradictory of P
For this to work you need a specifi cation of which pairs of propositions are contradic-
tories and which are contraries. Th ese are given in his On Interpretation (discussed in 
section 1.3).

formal derivations 
23
Contradictories and contraries:
‘Every A is B’ and ‘Some A isn’t B’ are contradictories.
‘No A is B’ and ‘Some A is B’ are contradictories.
‘Every A is B’ and ‘No A is B’ are contraries.
Th is technique also permits a trivial version in which the assumption is the only thing in 
the subderivation. If you assume a proposition, and if it is the contradictory or contrary 
of some available line, then you may follow its subderivation by its contradictory. An 
example is the following derivation showing the validity of subalternation for universal 
affi  rmatives. To show this argument valid:
Every A is B
∴ Some A is B
we can give this very short derivation:
Every A is B
Some A is B
1.
2.
3.
<assumption>
No A is B
1 2 reductio
Since the assumption on line 2 is the contrary of the proposition on line 1, you may 
infer its contradictory, which is the proposition on line 3.
application
Give a similar proof of the validity of subalternation from any universal negative 
proposition to the particular negative with the same subject and predicate.
Aristotle also uses a technique that he calls exposition (ecthesis); Robin Smith translates 
this in PA 28a24 (9) as “setting-out.” Following Th om 1976, I will call the explicit laying 
out portion ‘Exposition,’ abbreviated as ‘EX.’ Th is is a kind of existential instantiation. 
If there is a proposition of the form ‘some T is P’ then a singular term ‘n’ that has not 
occurred earlier in the derivation is chosen to “set out” one of the T’s. Two steps are to 
be produced: one states that n is one of the T’s, and the other says of n that it is P. For 
example, if ‘some donkey is an animal’ occurs in the derivation, this may be followed 
by choosing the term ‘d’ to stand for such a donkey; one then enters the lines:
d is a donkey
d is an animal

24 
aristotle’s proofs of conversions and syllogisms
Th e exposition rule for particular affi  rmatives is:1
EX (Exposition)
some T is P
∴ n is T
∴ n is P 
where n is a name that does not already occur in the derivation
A use of exposition is oft en followed later in the derivation by an analogue of existential 
generalization. Medieval logicians called this generalization step “Expository Syllogism,” 
and I will too, abbreviating it as ‘ES.’ Th e generalization rule has two forms:
ES (Expository Syllogism)
n is T 
n is T
n is P 
n isn’t P
∴ some T is P   ∴ some T isn’t P
where n is any singular term
Th ese two rules will be illustrated in section 2.2. Our task now is to look in detail at 
Aristotle’s own proofs, and to formalize them using no more than the technique of 
reductio and the two basic rules just stated.
1 Th is rule is similar to the well-known “existential instantiation” in modern logic. An example of a use of 
existential instantiation is this derivation to show the validity of the argument: ∃x(Fx&Gx) ∴ ∃xFx:
∃x(Fx&Gx) 
premise
Fa&Ga 
existential instantiation
Fa 
simplifi cation
∃xFx 
existential generalization
Th is rule is variously formulated and it usually comes with several restrictions involving the use of free 
variables and constraints on the rule of universal generalization due to the presence of existential instan-
tiations. Since we will not be using derivations containing formulas with free variables, and we will not 
have a rule of universal generalization, we will not need such extra constraints. Th is is discussed further in 
section 6.8.
In modern textbooks it is common to use a diff erent rule, oft en called “existential specifi cation.” With this 
rule, instead of following an existentially quantifi ed formula with an instance of it, one begins a subproof 
using that instance as the assumption of the subproof. Th en when you have derived what you want in the 
subproof you end the subproof, immediately following it by a repetition of the sentence on its last line, 
reclassifying the sentence as now depending logically on the existentially generalized formula. Cf. Mates 
1972 (122). I could have used such a technique here; I avoid it primarily in order to avoid the complexity of 
the additional subproofs.

proofs of the conversion principles 
25
2.2 Proofs of the conversion principles
Here is the part of Prior Analytics §2 where Aristotle states and proves the conversion 
principles. (In this translation a ‘privative’ proposition means a negative one.) Aristotle 
begins by stating the conversion principles:
[Conversions stated:]
It is necessary for a universal privative premise of belonging to convert with respect to its terms. 
For instance, if no pleasure is a good, neither will any good be a pleasure.
And the positive premise necessarily converts, though not universally but in part. For instance, 
if every pleasure is a good, then some good will be a pleasure.
Among the particular premises, the affi  rmative must convert partially (for if some pleasure is 
a good, then some good will be a pleasure),
but the privative premise need not (for it is not the case that if man does not belong to some 
animal, then animal will not belong to some man).
He immediately gives proofs of the principles:
[Conversions proved:]
First, then, let premise AB be universally privative. Now, if A belongs to none of the Bs, then 
neither will B belong to any of the As. For if it does belong to some (for instance to C), it will not 
be true that A belongs to none of the Bs, since C is one of the Bs.
And if A belongs to every B, then B will belong to some A. For if it belongs to none, neither will A 
belong to any B; but it was assumed to belong to every one.
And similarly if the premise is particular: if A belongs to some of the Bs, then necessarily B 
belongs to some of the As. (For if it belongs to none, then neither will A belong to any of the Bs.)
[Non-conversions:] But if A does not belong to some B, it is not necessary for B also not to belong 
to some A (for example if B is animal and A man: for man does not belong to every animal, but 
animal belongs to every man).
Aristotle uses this terminology ‘belongs to’ throughout the Prior Analytics, but not 
much elsewhere. I will follow the general practice of rephrasing this into the more 
familiar forms, based on the equivalents:
Every A is B 
B belongs to every A
No A is B 
B belongs to no A
Some A is B 
B belongs to some A
Some A isn’t B 
B does not belong to some A
Filling in some pronominal reference, his text just quoted presents the following three 
arguments justifying conversions:
If no B is A, A will not be any B. For if some A (for instance, C) is B, it will not be true 
that no B is A—since C is one of the B’s.

26 
aristotle’s proofs of conversions and syllogisms
If every B is A, then some A will be B. For if no A is B, then no B will be A—but it was 
assumed that every B is A.
If some B is A, necessarily some A is B. For if no A is B, no B will be A.
We will consider each of these arguments in detail.
2.2.1 Conversion of universal negatives
Th e fi rst argument uses a six-line proof to justify simple conversion of the universal 
negative form. Th e argument begins with:
If no B is A, A will not be any B;
Th is identifi es the argument to be validated. Th e proof will be of this form:
No B is A
No A is B
1.
6.
Premise
Conclusion
He goes on: For if some A  .  .  .  is B, it will not be true that no B is A. Th is is a part of the 
argument which leads from the assumption of ‘Some A is B’ to a disproof of ‘No B 
is A.’ Th is can be interpreted in diff erent ways, but the most natural one, which fi ts 
into the rest of Aristotle’s reasoning, is that this is a use of reductio ad absurdum. Th e 
technique is to prove ‘No A is B’ by assuming its contradictory, ‘Some A is B,’ and then 
deriving something absurd from it. Th e absurdity shows that ‘Some A is B’ is false, so its 
con tradictory, ‘No A is B,’ is true. So the argument has this structure:
No B is A
No A is B
1.
2.
5.
6.
← Assumption of the contradictory of ‘No A is B’
← Something absurd
Reductio from the subproof
Some A is B
???
Th e rest of the argument fi lls in the remaining lines:
.  .  .  some A (for instance, C)  .  .  .  , for C is one of the B’s.
So we need to fi ll in the proof with “for instance, C (which is some A)” and “for C is one 
of the B’s”:
“for instance, C (which is some A)”
“C is one of the B’s”
Reductio from the subproof
from 2 by EX
from 2 by EX
No B is A
No A is B
1.
2.
3.
4.
5.
6.
Some A is B
C is A
C is B
???

proofs of the conversion principles 
27
Lines 3 and 4 are an application of Exposition. It is easy to fi ll in the remainder of the 
proof, following a pattern that Aristotle uses elsewhere. Th e point of this subproof is to 
arrive at some proposition that contradicts or is contrary to something that is already 
there. In fact, the proposition ‘Some B is A’ follows immediately from the two previous 
lines by expository syllogism, and it contradicts the original premise:
EX from 2
EX from 2
ES from 3,4
Reductio: line 5 contradicts line 1
“for instance, C”
“one of the B’s”
No B is A
No A is B
1.
2.
3.
4.
5.
6.
Some A is B
C is A
C is B
Some B is A
Th is completes the proof. Th e technique used in steps 3–5 is a common one in modern 
logic: existentially instantiate line 2 and then existentially generalize 3 and 4 to get 
step 5.2
Th is particular argument is in fact the most complicated one that Aristotle gives. Th e 
remaining proofs are easier because once Aristotle has established a principle he lets 
himself use it thereaft er. So we now have a right to use conversion for universal negatives 
as a derived principle of inference. Th e next two arguments are short and easy.
2.2.2 Conversion of universal affi  rmatives (conversion per accidens)
If every B is A, then some A will be B. For if no A is B, then no B will be A—but it was 
assumed that every B is A.
2 Th ere is some dispute about the interpretation of Aristotle here. I am interpreting Aristotle as introduc-
ing a term, C, which is a singular term. Th is term is then used in a kind of existential generalization. Logically, 
this makes perfect sense of his reasoning. It is also the interpretation given by various medieval authors, who 
referred to the generalization step as an “expository syllogism” (cf. Buridan’s QIAPP, Question 6). However, 
some 20th-century scholars believe that Aristotle did not introduce a singular term at this point; instead, 
‘C’ must be a general term. Th is is not straightforward since there is no quantifi er symbol preceding the ‘C,’ so 
lines 3 and 4 appear to be indefi nite propositions, and thus equivalent to particulars, in which case line 5 does 
not follow. So instead, it is sometimes suggested that when Aristotle says ‘for C is one of the Bs’ he actually 
means ‘for every C is B.’ Th en the generalization step is of the form:
Every C is A
Every C is B
∴ Some B is A
Th is interpretation then makes the generalization step have the form of the mood Darapti, which is a form 
of reasoning that Aristotle takes to be in need of justifi cation. Th e justifi cation that he gives later for Darapti 
(we return to this shortly) makes indirect use of the conversion of universal negatives, so his reasoning 
would be circular. (Th is argument in favor of interpreting Aristotle as using a singular term here is already 
spelled out by Alexander of Aphrodisias sometime around 200 CE; see Alexander of Aphrodisias 1991 
32,34–34,3, pp. 88–9.) Th is does not exhaust the options, but exploring others would introduce a lengthy 
digression. For a discussion of these issues see Smith 1982, especially section 4. For a very interesting alterna-
tive view see Malink 2013, which may be a more accurate account of Aristotle’s intent, though one which 
confl icts with medieval principles.

28 
aristotle’s proofs of conversions and syllogisms
Th e initial part again announces what is to be proved:
Every B is A
Some A is B
1.
4.
Th e next part is: for if no A is B, then no B will be A. Clearly a subproof is here being 
off ered which begins with the assumption ‘No A is B’ and continues on to ‘No B is A.’ 
In fact, that inference is conversion for universal negatives, which has just been proved. 
So we have as the argument:
Every B is A
Some A is B
Conversion of line 2
No A is B
No B is A
1.
2.
3.
4.
Th e next step is
but it was assumed that every B is A.
Th e ‘but’ suggests some kind of opposition of some line to ‘Every B is A,’ which is the 
initial premise. In fact, it is apparent that line 3 is contrary to the premise on line 1. Th is 
short proof is already in the form of a completed reductio:
Conversion of line 2
Reductio; line 3 is contrary to line 1
Every B is A
Some A is B
No A is B
No B is A
1.
2.
3.
4.
(You might wonder why conversion per accidens is so easy to prove, since it is nowadays 
not considered legitimate to infer ‘Some A is B’ from ‘Every B is A.’ Th e key assumption 
that Aristotle makes is that the universal affi  rmative and universal negative forms are 
contraries. Whether this is coherent is discussed in section 1.4.)
2.2.3 Conversion of particular affi  rmatives
If some B is A, necessarily some A is B. For if no A is B, no B will be A.
As usual, he fi rst indicates the task, which is to validate this argument:
Some B is A
Some A is B
1.
4.

proofs of the conversion principles 
29
Th en we have: For if no A is B, no B will be A. Th e proof is so terse that we expect 
a simple structure, somehow involving ‘no A is B’ and ‘no B is A.’ I suggest that he is 
here using reductio, and the structure is to assume ‘No A is B’ and derive ‘No B is A’:
Some B is A
Some A is B
1.
2.
3.
4.
Conversion of the previous line
Reductio: the previous line contradicts the premise
No A is B
No B is A
Th is is trivial from the previously proved conversion for universal negatives. Th is conver-
sion is so salient that it would be natural for Aristotle to use it without needing to restate it.3
So Aristotle validates the conversion principles using three simple rules of reasoning. 
He also shows that conversion is not valid for particular negatives, by giving a counter-
example. Let B = Animal and A = Man. Th en this argument has a true premise and 
a false conclusion:
Some animal isn’t [a] man /∴ Some man isn’t [an] animal.
Oddly, Aristotle does not discuss conversion per accidens for universal negative 
propositions, even though this principle can be established as easily as the others. 
An example of a proof would be:
If no B is A, then some A will not be B. For if no B is A, no A is B, so it can’t be that 
every A is B.
Conversion of premise
Reductio: line 3 is contrary to line 2
No B is A
Some A isn’t B
1.
2.
3.
4.
Every A is B
No A is B
Th is is a principle that is oft en unmentioned in the tradition.4
We now have fi ve principles that can be appealed to in further proofs; the funda-
mental ones:
Reductio  Exposition (EX)  Expository syllogism (ES)
and two derived ones:
Simple conversion (two forms)  Conversion per accidens
(Subalternation is not included here because Aristotle does not make use of it in this 
context.)
3 People sometimes ask: “Didn’t Aristotle already prove conversion for particular affi  rmatives in the sub-
proof in the middle of his proof of conversion for universal negatives?” Yes, I think so. So he did not use an 
optimal strategy in these proofs; he could have proved conversion for particular affi  rmatives fi rst, in a simple 
proof, and then easily proved conversion for universal negatives from that. My job here is to explain 
Aristotle’s reasoning, not to improve on it.
4 But it is mentioned in several places, e.g. in Paul of Venice LM (123).

30 
aristotle’s proofs of conversions and syllogisms
2.3 Reduction of all syllogisms to perfect ones
Chapter 3 of Prior Analytics I concerns modal propositions, which are not discussed 
here. In chapters 4–7 Aristotle turns to the assertoric syllogisms.
2.3.1 Figure 1 syllogisms
Aristotle begins in chapter 4 with the fi rst fi gure direct moods: moods in which the fi rst 
premise contains the predicate of the conclusion as its own predicate, and the second 
premise has the subject of the conclusion as its own subject. He recognizes four good 
moods within this fi gure. Table 2.1 states them, using their medieval names.
Table 2.1. Figure 1 from Prior Analytics, chapter 4
Barbara (26a1) 
Every M is P
 
Every S is M
∴ Every S is P
Darii (26a23) 
Every M is P
 
Some S is M
∴ Some S is P
Celarent (26a3) 
No M is P
 
Every S is M
∴ No S is P
Ferio (26a25) 
No M is P
 
Some S is M
∴ Some S isn’t P
Aristotle’s argument for the goodness of these moods is simple: no argument is needed 
because they are perfect (sometimes translated “complete”).5 A perfect syllogism is 
defi ned to be one whose goodness is evident in itself (PA 1.1), and these moods are all 
evident. (He off ers no argument that these particular forms are evident. Th at, I imagine, 
is supposed to be evident.)
Th e perfect syllogisms thereaft er are taken to justify other forms of syllogisms. Th us, 
for Aristotle’s purposes the rules stated at the end of the last section may be expanded 
by adding the four fi rst fi gure moods.
Aristotle also gives counterexamples to some fi rst fi gure bad moods. A form of 
argument that is not a (good) deduction is one that can have true premises and a false 
conclusion. Aristotle shows that several fi rst fi gure moods are not deductions; he does 
this by providing counterexamples to them.
Th ere are two valid fi rst fi gure moods that Aristotle does not discuss. Since 
Aristotle’s goal seems only to be to fi nd which premise pairs lead to valid syllogisms, 
5 In spite of the fact that no argument is needed, some commentators think that Aristotle did provide 
an argument, or at least he stated a semantic principle that supports these moods, when he says at PA 1.1 
24b28–32 (2):
For one thing to be in another as a whole is the same as for one thing to be predicated of every 
one of another. We use the expression ‘predicated of every’ when none of the subject can be 
taken of which the other term cannot be said, and we use ‘predicated of none’ likewise.
One way to read this is that it is simply giving the equivalence ‘Every A is B iff  no thing which is A isn’t B.’ On 
this interpretation it discusses a relation between two terms, and it’s hard to see how it can validate a syllogism 
involving three terms. But it can also be read ‘Every A is B iff  there is no term C which is part of A that B is not said 
of’ and this can be viewed as a kind of meta-validation of Barbara and Darii. Viewed in this way it is traditionally 
called (including the negative clause) “the dictum of all and none,” or, in Latin the “dici de omni et de nullo.”

reduction of all syllogisms to perfect ones 
31
if multiple conclusions are possible, he only discusses one of them. Th e unmentioned 
moods can easily be validated using the forms that he accepts as perfect. For example, 
this mood:
Every M is P
Every S is M
∴ Some S is P
can be validated as follows:
Every M is P
Every S is M
Some S is P
1.
2.
3.
4.
5.
from the ﬁrst two premises by Barbara
Reductio: the previous line is contrary to the assumption
No S is P
Every S is P
Th ese forms played little role in the medieval period.
applications
Give a similar proof of the validity of the other fi rst fi gure form that Aristotle 
does not discuss, namely:
No M is P
Every S is M
∴ Some S isn’t P
Show by giving counterexamples that these fi rst fi gure moods are not valid.
Some M is P
Some S isn’t M
∴ Every S is P
No M is P
Some S is M
∴ No S is P
2.3.2 Reduction to the fi rst fi gure
In sections 5–6 Aristotle goes on to discuss the second and third fi gures of syllogism. 
He thinks that these are not perfect, but they may be “made perfect” (PA 28a5) by reduc-
ing them to fi rst fi gure syllogisms. A reduction goes as follows: You state the premises of 
the mood in question, and then you argue to its conclusion using the logical techniques 
that we have indicated earlier (the rules and, usually, the fi rst fi gure direct syllogisms). 

32 
aristotle’s proofs of conversions and syllogisms
It is far from obvious that this can be done, and it is neat that he does it simply and 
straightforwardly.
What will reduction accomplish? Th is is not made clear. It does not turn an imper-
fect syllogism into a perfect one. Th at is impossible; an imperfect syllogism is imperfect 
precisely because it is not evident on its own. No argumentation will change this. Th e 
reduction does not make a mood perfect, but it establishes a kind of trust-worthiness 
for it. In particular, aft er the reduction it is known that whenever an inference has the 
form of the imperfect mood in question, one can get from its premises to its conclusion 
using an argument that makes appeal only to a perfect syllogism (and to the three basic 
rules of argumentation plus the others that have been previously justifi ed).
2.3.3 Figure 2 syllogisms
Table 2.2 shows the good fi gure 2 syllogisms that Aristotle discusses.
Table 2.2. Figure 2 from Prior Analytics, chapter 5
Cesare (27a5)
No P is M
Every S is M
∴ No S is P
Festino (27a31)
No P is M
Some S is M
∴ Some S isn’t P
Camestres (27a8)
Every P is M
No S is M
∴ No S is P
Barocho (27a36)
Every P is M
Some S isn’t M
∴ Some S isn’t P
Th e proofs that Aristotle gives for the fi gure 2 and fi gure 3 syllogisms mostly employ 
the conversion principles together with fi rst fi gure forms. I will consider two of the 
second fi gure syllogisms as examples. Th e fi rst is Cesare. Aristotle’s argument for 
Cesare is:
Cesare: Let no N be M, but every X be M. Th en, since the privative converts, no M will be N; but 
every X was assumed to be M, so that no X will be N (this has been proved earlier).6
What is to be shown (Cesare) is:
No N is M
Every X is M
No X is N 
1.
2.
4.
Th e argument goes: Th en, since the privative converts, no M will be N. Th is adds a line by 
conversion:
6 As usual, I have reworded this in the standard way. A literal translation goes: Let M be predicated of no N, 
but of every X. Th en, since the privative converts, N will belong to no M. But M was assumed to belong to every 
X, so that N belongs to no X ( for this has been proved earlier) (27a5–9).

reduction of all syllogisms to perfect ones 
33
No N is M
Every X is M
No M is N
No X is N  
1.
2.
3.
4.
Conversion of the first premise
Th e argument continues: but every X was assumed to be M, so that no X will be N (for 
this has been proved earlier). Th is fl eshes out the reasoning (without adding any lines at 
all), by pointing out that the perfect mood Celarent justifi es the last line:
No N is M
Every X is M
No M is N
No X is N
1.
2.
3.
4.
Conversion of ﬁrst premise
CELARENT: from the previous line plus the second premise
Several of the moods have proofs that are this brief and straightforward—not using 
any subproofs at all. Two, however, require the use of reductio. One of these is Barocho:
2.3.4 Barocho
Two arguments are given. Th e fi rst argument is:
If every N is M, but some X isn’t M, it is necessary for some X not to be N. For if every X 
is N, and every N is M, every X must be M; but it was assumed that some X isn’t M.
Th e fi rst sentence states what is to be shown:
Every N is M
Some X isn’t M
Some X isn’t N
1.
2.
5.
Th en we have: for if every X is N, and every N is M, every X must be M; but we assumed 
that some X isn’t M. Th is must be a reductio within the main argument:
Every N is M
Some X isn’t M
Some X isn’t N
1.
2.
3.
5.
Every X is N
Barbara supplies what is needed:
Every N is M
Some X isn’t M
Some X isn’t N
1.
2.
3.
4.
5.
Every X is N
Every X is M
BARBARA from lines 1 and 3
Reductio; line 4 contradicts line 2

34 
aristotle’s proofs of conversions and syllogisms
Aristotle also gives a second argument: And if every N is M but not every O is M there 
will be a deduction that not every O is N: the demonstration is the same. Th is is the same 
argument for another form of Barocho, in which the wording ‘not every X is Y’ is used 
instead of ‘some X is not Y.’ Th is seems to indicate that Aristotle holds these two forms 
(‘Some X isn’t Y’ and ‘Not every X is Y’) to be interchangeable.
application
“Reduce” the second fi gure moods not discussed here, namely:
Every P is M 
<Camestres>
No S is M
∴ No S is P
No P is M 
<Festino>
Some S is M
∴ Some S isn’t P
2.3.5 Figure 3 syllogisms
Table 2.3 shows the good fi gure 3 syllogisms that Aristotle discusses.
Table 2.3. Figure 3 from Prior Analytics, chapter 6
Darapti (28a18)
Every M is P
Every M is S
∴ Some S is P
Datisi (28b12*)
Every M is P
Some M is S
∴ Some S is P
Felapto (28a27*)
No M is P
Every M is S
∴ Some S isn’t P
Bocardo (28b18*)
Some M isn’t P
Every M is S
∴ Some S isn’t P
Disamis (28b7)
Some M is P
Every M is S
∴ Some S is P
Ferison (28b33)
No M is P
Some M is S
∴ Some S isn’t P
Various moods of fi gure 3 can be reduced as before. But new options also arise. For 
example, Aristotle reduces Darapti by means of a very simple proof (using only con-
version per accidens and Darii). Th en he goes on to remark that Darapti can also be 
proved by reductio, and by exposition. He gives the following proof with exposition:
For if both every S is P and every S is R, if some one of the S’s be chosen (for instance 
N), this will be both P and R, consequently some R will be P.

reduction of all syllogisms to perfect ones 
35
Th is seems to produce the following form of proof:
Every S is P
Every S is R
N is S
N is P
N is R
Some R is P
1.
2.
3.
4.
5.
6.
By ??? “for instance”
By ???
By ???
ES from the last two lines
Two new forms of argument are used here, without comment. One is an analogue 
of Exposition but applied to a universal affi  rmative proposition. Th is is clearly valid, 
since exposition is applicable to the corresponding particular affi  rmative, which can 
be derived from the universal affi  rmative by an application of conversion per accidens 
followed by an application of simple conversion:
Every S is P
Some P is S 
from previous line by conversion per accidens
Some S is P 
from previous line by simple conversion
I will thus assume that it is a legitimate shortcut to apply exposition directly to a universal 
proposition, as Aristotle does here.
Every S is P
Every S is R
N is S
N is P
N is R
Some R is P
1.
2.
3.
4.
5.
6.
EX for universal affirmative, from the first premise
EX for universal affirmative, from the first premise
By ???
ES from the last two lines
But then how do we derive ‘N is R’? It appears to me that Aristotle is here using that 
most famous of valid arguments, epitomized by:
Every man is mortal
Socrates is a man
Th erefore, Socrates is mortal.
It is odd that this famous argument form has no name in either traditional (“Aristotelian”) 
logic or in modern logic. In modern logic the fi rst premise would be a quantifi ed 
conditional, and the argument can be justifi ed by universal instantiation followed by 
modus ponens. In Aristotle’s logic, it is easy to derive from principles we are already 
using. Let me call the principle we are discussing “universal application”:
Rule UA (Universal Application):
Positive form: From ‘n is X’ and ‘Every X is Y’ infer ‘n is Y.’
Negative form: From ‘n is X’ and ‘No X is Y’ infer ‘n isn’t Y.’

36 
aristotle’s proofs of conversions and syllogisms
(I use small letter ‘n’ here to indicate that this rule applies to singular terms. Th ere were 
no small letters in Aristotle’s time.)
Th ese forms of Universal Application can be easily derived from our basic rules as 
follows:
Every X is Y
n is X
n is Y
1.
2.
3.
4.
5.
n isn’t Y
Some X isn’t Y
2 3 ES
reductio: line 4 contradicts line 1.
No X is Y
n is X
n isn’t Y
1.
2.
3.
4.
5.
n is Y
Some X is Y
2 3 ES
reductio: line 4 contradicts line 1.
So Universal Application is another derived rule that we can use. So the argument for 
Darapti, using rule UA, takes the form:
Every S is P
Every S is R
N is S
N is P
N is R
Some R is P
1.
2.
3.
4.
5.
6.
1 EX
1 EX
2 3 UA
4 5 ES
Hereaft er I will assume UA as an available rule.
Something interesting happens in the proof of Bocardo. Aristotle gives a reduction 
by reductio, but then he says that reductio is unnecessary if you use exposition: “This 
can also be proved without the leading-away, if some one of the Ss should be 
chosen to which P does not belong.” Th is alternative proof would have the form:
Every S is R
Some S isn’t P
X is S
X isn’t P
X is R
Some R isn’t P
1.
2.
3.
4.
5.
6.
2 EX
2 EX
1 3 UA
4 5 ES
Now this is an interesting move, for it appears to apply exposition to a particular nega-
tive proposition. And this is not in general valid. Suppose, for example, that there are no 

reduction of all syllogisms to perfect ones 
37
As. Th en, as we saw in section 1.4, the negative proposition ‘Some A isn’t B’ is true. If we 
could apply exposition to this proposition, then the following derivation would be good:
Some A isn’t B
n is A
n isn’t B
Some A is A
1.
2.
3.
4.
1 EX
1 EX
2,2 ES (line 2 is used twice)
And if there are no As, the premise is true and the last line is false.
What then is going on? It is possible, of course, that Aristotle just made a mistake, 
overlooking the problem of existential import. I don’t know of any way to disprove this 
interpretation. However, other alternatives are worth considering. An obvious option 
to note is that exposition is indeed valid from a particular negative if there is some 
independent way to establish that its subject is not empty. And in the example under 
discussion that is the case. For the argument has two premises, and the fi rst premise is a 
universal affi  rmative proposition which has the term in question as subject. So let us 
consider this more general version of exposition:
EX (Exposition)
some T is P 
some T isn’t P
∴ n is T 
∴ n is T
∴ n is P 
∴ n isn’t P
where n is a name that does not already occur in the derivation, and where 
‘T’ occurs affi  rmatively in an available affi  rmative proposition.
(For the time being we can say that any main term7 of an affi  rmative proposition 
occurs affi  rmatively in it.)
In justifying a use of this rule one must cite both the line which is being 
instantiated and the line on which ‘T’ occurs affi  rmatively.
In the affi  rmative version of this rule, the premise ‘Some T is P’ itself is already an 
affi  rmative proposition in which ‘T’ occurs as a main term, so no additional premise is 
necessary. When the premise is not affi  rmative (‘Some T isn’t P’), there must be some 
available affi  rmative proposition containing ‘T’ as a main term.
With this revised rule, the proof of Bocardo is correct as Aristotle gives it.
I am not aware of any discussion of this revised version of the rule, ancient or 
medieval.
7 So far, all terms are main terms, so the word ‘main’ is redundant here. In later chapters we consider 
propositions of more complex forms in which there may be terms which occur within other complex terms. 
An example is ‘B’ in ‘Some A which is not B is C.’ Th at complex proposition is affi  rmative, and it contains ‘B,’ 
but not as a main term. Its truth does not establish that ‘B’ is not empty.

38 
aristotle’s proofs of conversions and syllogisms
2.3.6 First fi gure indirect moods
Table 2.4 shows the good fi gure 1 indirect moods in chapter 7 of Aristotle’s Prior Analytics.
Table 2.4. Figure 1 indirect moods from Prior Analytics, chapter 7
Baralipton
Every M is S
Every P is M
∴ Some S is P
Dabitis
Every M is S
Some P is M
∴ Some S is P
Frisesomorum (29a22)
Some M is S
No P is M
∴ Some S isn’t P
Celantes
No M is S
Every P is M
∴ No S is P
Fapesmo (29a22)
Every M is S
No P is M
∴ Some S isn’t P
applications
Th e rule Universal Application is similar to the modern rule of universal instan-
tiation. In modern logic much use is made of another universal quantifi er rule: 
universal generalization. In Aristotle’s framework the eff ect of this rule can be 
accomplished in a slightly roundabout fashion.
Universal Generalization (derived rule)
Given a derivation of either of these forms:
Some F is F
a is F
a is G
a is F
a is not G
where the name ‘a’ does not occur in the derivation preceding the subderivation,
one may infer the appropriate universal generalization:
Some F is F
Every F is G
rule UG
rule UG
a is F
a is G
a is F
a is not G
No F is G
Show that one can get the eff ect of this rule UG using our already existing rules. 
(Th e derivation will use reductio and EX and ES, and will rely on the fact that if 
‘a’ does not already occur before the subderivation then any subderivation using 
a non-occurring name other than ‘a’ is equally good.)

proving the first figure syllogisms 
39
In chapter 7, Aristotle states Fapesmo and Frisesomorum without proof. He then states 
that “a deduction always results by means of conversion.” Presumably this means that 
given any valid mood, if you convert something in it the resulting mood is also valid. 
By doing this you can generate Fapesmo from Felapto and Frisesomorum from 
Ferison. Undiscussed consequences also include: that Baralipton comes from Barbara, 
Celantes from Cesare, and Dabitis from Datisi. Th is completes the good fi gure 1 indirect 
moods.
applications
Reduce the following fi rst fi gure indirect moods to fi rst fi gure direct moods:
Fapesmo
Baralipton
Dabitis
In chapter 7, Aristotle notes that the universal second fi gure moods have all been 
reduced to the direct fi rst fi gure universal moods (the ones we are calling Barbara and 
Celarent). He then shows that the direct fi rst fi gure particular moods can be reduced to 
universal second fi gure moods. Th e result of this is that all of the moods are reducible, 
either directly or indirectly, to the direct universal moods of the fi rst fi gure.
applications
Reduce the fi rst fi gure particular moods to universal second fi gure moods:
Darii
Ferio
2.4 Proving the fi rst fi gure syllogisms
Aristotle has been criticized for choosing the fi rst fi gure moods as basic rules; many 
people fi nd some of the other moods just as evident as the fi rst fi gure ones. What is 
surprising is that he needn’t have chosen any such rules at all. Th is is because the same 
resources that allow Aristotle to prove the conversion rules and to reduce all moods to 
fi rst fi gure moods suffi  ce for proving the fi rst fi gure moods as well. He needn’t have 
chosen any evident syllogisms at all.8 Proofs to show this are:
8 Th is is shown in a somewhat diff erent and elegant form in Th om 1976. He notices that Aristotle gives 
proofs of Bocardo and of Datisi that do not employ the fi rst fi gure syllogisms. Th en he points out that 
Barbara may be reduced to Bocardo and Celarent to Datisi.

40 
aristotle’s proofs of conversions and syllogisms
BARBARA
Every B is A
Every C is B
Every C is A
1.
2.
3.
4.
5.
6.
7.
8.
Some C isn’t A
c is C
c isn’t A
c is B
Some B isn’t A
3 2 EX
3 2 EX
4 2 UA
5 6 ES
reductio: 7 contradicts 1
(In steps 4 and 5 line 2 provides the existential import needed to apply EX to line 3.)
CELARENT
No B is A
Every C is B
No C is A
1.
2.
3.
4.
5.
6.
7.
8.
Some C is A
c is C
c is A
c is B
Some B is A
3 3 EX
3 3 EX
2 4 UA
5 6 ES
reductio: 7 contradicts 1
Of course, the fact that the fi rst fi gure moods can be proved in this way might mean 
little to Aristotle, since he already regards those moods as perfect.
applications
Give similar derivations to directly validate the other two fi rst fi gure moods, namely:
Darii
Ferio
2.5 Propositions with repeated terms
Aristotle mentions only briefl y propositions in which the subject and predicate terms 
are the same (e.g. at PA 2.22, 68a19). If these are allowed, it is well known that a natural 
additional principle becomes valid:
 
Some A is A
 
/∴ Every A is A

the indispensability of exposition and  expository syllogism 
41
Th e proposition ‘Every A is A’ is not provable by itself because it is false when ‘A’ is 
empty. Th e particular proposition ‘Some A is A’ rules out emptiness.
Th is inference is provable by reductio using exposition applied to the O form:
Some A is A
Every A is A
1.
2.
3.
4.
5.
Some A isn’t A
c is A
c isn’t A
1 2 EX
1 2 EX
reductio: 4 contradicts 3
In this derivation the only role played by the premise is to legitimatize the use of 
Exposition applied to the particular negative form.
2.6  Th e indispensability of exposition and 
expository syllogism
Typically, “Aristotelian” logic is understood as follows: Th e fi rst fi gure direct syllo-
gisms are taken for granted. Th en, using the conversion principles, all of the remain-
ing syllogisms are validated. However, as we have seen, Aristotle did not take the 
conversion principles for granted; he proved them, using reductio and exposition 
and expository syllogism. Since exposition and expository syllogism are oft en not 
discussed at all, one naturally asks whether they can be dispensed with. Th e simple 
answer is “no.” Th at is, if exposition and expository syllogism are eliminated from the 
resources we have with which to validate arguments, and if they are not replaced by 
some other principles not already present, Aristotle’s project could not be carried 
out. Th at is, the project of proving the conversion principles and all of the syllogistic 
moods assuming only the fi rst fi gure direct syllogisms (and using the reductio tech-
nique) cannot succeed. Th is is because the principles of exposition and expository 
syllogism are vital to proving the principles of simple conversion. Th is is easy to 
show. Suppose that we reinterpret the truth conditions for universal negative propo-
sitions so as to require existential import for the subject term. Th at is, a proposition 
of the form ‘No A is B’ is to be true if and only if something is an A and nothing is 
both A and B. Make a corresponding change in the truth conditions for particular 
affi  rmative propositions so that they remain the contradictories of universal nega-
tives; that is, ‘Some A is B’ is to be true either if there are no As, or at least one thing is 
both A and B. Leave the truth conditions for universal affi  rmatives as they are, and 
likewise for particular negative propositions. Th en all of the relations in the square 
of opposition remain unchanged. Diagonally opposite propositions are still contra-
dictories, universal affi  rmative and universal negative propositions are still contraries, 
and each universal proposition still entails the particular proposition directly below 
it. Accidental conversion remains valid, since that depends only on the universal 

42 
aristotle’s proofs of conversions and syllogisms
propositions being contraries (assuming that diagonally opposite propositions are 
contradictories).9 But simple conversion for particular affi  rmatives and universal 
negatives fails, for ‘Some chimera is a stone’ is true but ‘Some stone is a chimera’ is 
false; likewise for ‘No stone is a chimera’ and ‘No chimera is a stone.’ Without exposi-
tion and expository syllogism, the failure of these conversions cannot be disproved. 
All of the fi rst fi gure syllogisms remain valid, and could be assumed as Aristotle did. 
However, some of the other syllogisms would fail; for example, this instance of 
Celantes:
No substance is a chimera
Every stone is a substance.
So no chimera is a stone. 
<false because the subject is empty>
So without exposition and expository syllogism Aristotle’s project cannot be carried out.
Now this claim fl ies in the face of an old tradition according to which simple conversion 
can be proved using only fi rst fi gure (direct) syllogistic principles. Th e argument is 
given by Alexander of Aphrodisias (1991, 90):
suppose that A holds of no B, and—if it does not convert—let B hold of some A. We get, in the 
fi rst fi gure, that A does not hold of some A—which is absurd.
Th e argument is a simple reductio:
No B is A
No A is B
1.
2.
3.
4.
Some A is B
Some A isn’t A
hypothesis for reductio
1 2 Ferio
Reductio; line 3 is absurd
Th e catch is simple: line 3 is not absurd; it is true when A is empty. Th is is so on Aristotle’s 
own account, as discussed in section 1.4.2. And this is exactly the case in which ‘No A 
is B’ and ‘No B is A’ can diverge in truth value on the variant model proposed earlier. 
So this traditional argument designed to avoid assuming exposition and expository 
syllogism fails.
So without exposition and expository syllogism, nothing forces simple conversion 
to hold, and without simple conversion nothing forces some of the imperfect syllo-
gisms to hold. So those principles are essential to Aristotle’s project. And as we will see 
throughout this book, they are essential to having a medieval logic that can ground its 
widely held assumptions in simple basic rules.
9 Actually, the proof that Aristotle gives also uses simple conversion, which is no longer valid. What is 
needed is the fact that ‘Every A is B’ and ‘No B is A’ are contraries. Th ey are indeed contraries using the 
reinterpreted truth conditions, but this assumption was not one of Aristotle’s original ones. So there would 
also be a problem proving accidental conversion on these conditions, though it would be valid. But this is not 
relevant to the point under discussion, which is that simple conversion no longer holds.

a contemporary assessment of aristotle’s basic theory 
43
2.7  A contemporary assessment of Aristotle’s 
basic theory
(Th is section may be skipped without loss of comprehension.)
Aristotle has been criticized for focusing on a particularly limited and arbitrary 
set of sentences with which to develop logical principles: ‘Every A is B,’ ‘No A is B,’ 
‘Some A is B,’ ‘Some A isn’t B.’ He has also been criticized for selecting the four forms 
mentioned previously: Barbara, Celarent, Darii, and Ferio as axiomatic (i.e. for choos-
ing to use them as accepted principles from which to derive the others). I think instead 
that the sentence forms that he focuses on are central and important, and his choice of 
axiomatic principles is (mostly) not arbitrary at all. To make this case I turn briefl y to 
a theory from contemporary linguistics, the theory of generalized quantifi ers.
2.7.1 Generalized quantifi ers10
Generalized quantifi ers are determiner phrases of natural language, phrases like ‘every 
donkey’, ‘no brown horse,’ ‘some donkey which Socrates owns,’ and so on. Structurally, 
they consist of a determiner (D) and a noun phrase (NP):
DP
D
NP
every
donkey
DP
D
NP
no
brown horse
DP
D
NP
some donkey which Socrates owns
Elsewhere in this book I call these phrases “denoting phrases,” using a term from the 
philosophy of language. Determiner phrases are the same as denoting phrases.11 In the 
10 For background on generalized quantifi ers, see e.g. Keenan 1996.
11 In the philosophical tradition it is unclear whether or not proper names are denoting phrases; likewise, 
it is unclear in the linguistic tradition whether proper names are determiner phrases. I use both ‘denoting 
phrase’ and ‘determiner phrase’ so as to include proper names.

44 
aristotle’s proofs of conversions and syllogisms
present section I call them determiner phrases because the theory to be discussed 
comes from modern linguistics, in which this terminology is used.
According to generalized quantifi er theory, a determiner stands for a relation between 
two classes. A sentence having a DP with scope over the rest of the sentence is true if 
the relation that the determiner stands for relates the class of things picked out by its 
NP to the class of things picked out by the rest of the sentence. Th at is:
DP
S
D
NP
δ
X
Y
12
is true when the relation that δ stands for relates the class of things that X stands for to 
the class of things that Y stands for. For example, this sentence:
DP
S
D
NP
every
donkey is running
is true when the relation that ‘every’ stands for relates the class of donkeys to the class 
of things that are running. Th e relation that ‘every’ stands for is in fact the relation 
that relates a class X (here, the donkeys) to a class Y (here, the things that run) if and 
only if X is a subset of Y. So the sentence:
every donkey is running
is true when the class of donkeys is a subset of the class of running things. And that 
seems to be right. (On Aristotle’s view, adopted by the medievals, the sentence is true 
when the class of donkeys is non-empty and is a subset of the class of running things. 
Th is diff erence between the ancient and modern theory is discussed in section 2.7.3.)
Th e three determiners that Aristotle discusses stand (according to modern theory) 
for these relations:
every relates X to Y when X is a subset of Y 
X⊆Y
some 
relates X to Y when X and Y overlap 
X∩Y ≠ ∅
no 
relates X to Y when X and Y are disjoint 
X∩Y = ∅
12 ‘S’ is used here for whatever the category is of the part of the sentence that the DP combines with. 
In some contemporary theories, DPs are all subject to a principle of “quantifi er raising,” and they typically 
end up with scope over a “sentence,” symbolized by ‘S,’ which contains a free variable (a “trace”) that is bound 
by the DP.

a contemporary assessment of aristotle’s basic theory 
45
Natural language determiners have a number of properties that are especially interest-
ing. One is this: it appears that every natural language determiner—in any language—
is “conservative,” meaning that the determiner relates X to Y if and only if it relates X to 
X∩Y. For example, every donkey is running if and only if every donkey is a donkey that 
is running. And some brown horse is an animal if and only if some brown horse is 
a brown horse that is an animal. And so on. Th is is a remarkable fact, since it’s easy to 
defi ne relations between classes such that any determiner that stood for one of them 
would not be conservative. For example, consider the relation that holds between X 
and Y if and only if something that is not X is Y. Th en the class of donkeys stands in that 
relation to the class of brown things, since some things that are not donkeys are brown; 
but the class of donkeys does not stand in that relation to the class of donkeys that are 
brown things, since nothing that is not a donkey is a donkey that is brown.13 Naturally, 
Aristotle’s determiners, which are found in natural language, are all conservative.
It is important that the determiners that Aristotle focuses on have other, special, 
properties that do not hold of natural language determiners in general. In particular, 
they are “monotonic in both places.” Monotonicity is a logically important property of 
determiners. A determiner can be monotonic up on the left , or monotonic down on the 
left , or neither, and it can be monotonic up on the right or monotonic down on the right, 
or neither. We indicate that a determiner is monotonic by writing arrows to its left  or right:
↓D 
monotonic down on the left 
↑D 
monotonic up on the left 
D↓ 
monotonic down on the right
D↑ 
monotonic up on the right
For a determiner to be monotonic up on the left  means that when it relates class X to 
class Y, it also relates any superclass of X to Y:
If ↑D relates X to Y, and if X⊆Z, then ↑D relates Z to Y
Likewise for monotonicity up on the right:
If D↑ relates X to Y, and if Y⊆Z, then D↑ relates X to Z
Th e determiner ‘some’ is monotonic up on the left , and also on the right: ↑some↑.
Monotonicity-up on the left : If ‘some’ relates the class of donkeys to the class of 
running things, and if the class of donkeys is a subset of the class of animals, then 
‘some’ must relate the class of animals to the class of running things.
13 Another example: If ‘only’ were a determiner in the context ‘Only As are Bs’ it would fail to be conserva-
tive, since ‘Only donkeys are animals’ is false but ‘Only donkeys are donkeys which are animals’ is true. Most 
modern linguists do not consider ‘only’ a determiner. Nor do medieval logicians; it is typical to take ‘Only As 
are Bs’ to be an “exponible” proposition, that is, one in need of expounding. For example, Billingham (para 18 
in de Rijk 1982) says “An exponible term is what has two, or many, exponents with which it is converted. And 
in this it diff ers from a resoluble  .  .  .  But in the exponents of an exponible term it follows well and conversely: 
as ‘only a man runs; therefore a man runs and nothing other than a man runs’ and conversely.”

46 
aristotle’s proofs of conversions and syllogisms
Th at is, if some donkey is running, and every donkey is an animal (donkeys ⊆ 
animals), then some animal must be running.
Monotonicity up on the right: If ‘some’ relates the class of donkeys to the class of 
running things, and if the class of running things is a subset of the class of moving 
things, then ‘some’ must relate the class of donkeys to the class of moving things.
Th at is, if some donkey is running, and every running thing is moving (running 
things ⊆ moving things), then some donkey must be a moving thing.
Th e determiner ‘no’ is the opposite of ‘some’; it is monotonic down on the left  and also 
monotonic down on the right. Examples to illustrate this are:
Monotonicity down on the left : If ‘no’ relates the class of animals to the class of 
running things, and if the class of donkeys is a subset of the class of animals, then 
‘no’ must relate the class of donkeys to the class of running things.
Th at is, if no animal is running, and every donkey is an animal (donkeys ⊆ 
animals), then no donkey can be running.
Monotonicity down on the right: If ‘no’ relates the class of animals to the class of 
running things, and if the class of brown things is a subset of the class of running 
things, ‘no’ relates the class of animals to the class of brown things.
Th at is, if no animal is running, and every brown thing is running (brown things ⊆ 
running things), then no animal can be brown.
Th e determiner ‘↓every↑’ is monotonic down on the left , and monotonic up on the 
right.
Monotonicity down on the left : If ‘every’ relates the class of animals to the class of 
running things, and if the class of donkeys is a subset of the class of animals, then 
‘every’ must relate the class of donkeys to the class of running things.
Th at is, if every animal is running, and every donkey is an animal (donkeys ⊆ 
animals), then every donkey must be running.
Monotonicity up on the right: If ‘every’ relates the class of donkeys to the class of 
running things, and if the class of running things is a subset of the class of brown 
things, ‘every’ must relate the class of donkeys to the class of brown things.
Th at is, if every donkey is running, and every running thing is brown (running 
things ⊆ brown things), then every donkey must be brown.
Most determiners are not doubly monotonic in this way. Th e determiner ‘few’ is 
monotonic down on the right—if few X’s are Y, then few X’s are Z if Z⊆Y—but it is 
neither monotonic up nor monotonic down on the left . It is not monotonic up on the 
left  because few infants can lift  20 pounds, and infants are a subclass of humans, but 
it’s not true that few humans can lift  20 pounds. And it’s not monotonic down on the 
left  because few humans weigh less than fi ve pounds, and preemies are a subclass of 
humans, but it’s not true that few preemies weigh less than fi ve pounds. Th e determiner 

a contemporary assessment of aristotle’s basic theory 
47
‘fi ve’ (meaning exactly fi ve) is not monotonic in any way. If fi ve cars are blue it does not 
follow that fi ve vehicles (a superclass of cars) are blue, or that fi ve convertibles are blue 
(a subclass of cars) or that fi ve cars are colored things (a superclass of blue things) or 
that fi ve cars are small blue things (a subclass of blue things).
applications
Determine which monotonicity properties the following determiners of English 
have (if any), and explain why.
many
most
at least three
at most three
In addition to conservativity and monotonicity there is another property worth 
mentioning, which I will call non-triviality. A determiner δ is non-trivial if whenever 
class A is non-empty, there is some class B such that ‘δ A is B’ is true, and there is some 
class C such that ‘δ A is C’ is not true.
An example of a trivial determiner is one that relates every class to every class. 
Th ere is no simple natural language determiner that does so, so let me invent one, call it 
‘trivial-any.’ Its meaning is:
trivial-any relates class A to class B if and only if A and B are classes.
Any simple affi  rmative sentence made using ‘trivial-any’ is automatically true. So some 
truths using trivial-any are:
Trivial-any donkey is an animal
Trivial-any donkey is not an animal
Trivial-any stone is a donkey
and so on
All of Aristotle’s determiners are non-trivial.
What other determiners have all of the neat properties shared by those that Aristotle 
uses? We may state here a relevant result of the study of generalized quantifi ers: Th ere 
are only four possible determiners of any natural language that are all of:14
Conservative
Monotonic on the left 
Monotonic on the right
Non-trivial
14 Cf. van Benthem 2008.

48 
aristotle’s proofs of conversions and syllogisms
Th ree of the determiners of this sort already exist in most natural languages; in English, 
they are ‘every,’ ‘some,’ and ‘no.’ Th e fourth apparently does not exist in any natural 
language,15 but it is easy to see what it would be like if there were one. It would be 
equivalent to the fourth corner of Aristotle’s square of opposition. Such a determiner, 
δ, would hold under these conditions:
δ A is B ≈ some A is not B
So, as others have noted,16 Aristotle chose for his logical notation the three (or four) 
most logically interesting determiners (or quasi-determiners) that can exist in any 
language. Th is is why I say that his selection of sentential forms is especially interesting 
in logic.
2.7.2 Axiomatizing generalized quantifi ers
Suppose that we want to axiomatize the monotonicity properties of the determiners 
that are used in Aristotle’s logical theory. It would be natural to choose something 
very close to the syllogistic forms that Aristotle considers as “perfect.” For these tell us 
much of the story about these logical behaviors of the interesting determiners, at least 
regarding the monotonicity properties of ‘every,’ ‘no,’ and ‘some.’
Barbara tells us that ‘every’ is monotonic down on the left  and monotonic up on the 
right. Th is is because monotonicity down on the left  for ‘every’ means:
If every X is Y, and if every Z is X (if Z⊆X) then every Z is Y.
And monotonicity up on the right for ‘every’ means:
If every X is Y, and if every Y is Z (if Y⊆Z) then every X is Z.
And both of these are correct according to Barbara:
Every M is P
Every S is M
∴ Every S is P
Th e fi rst follows by putting ‘X’ for M and ‘Y’ for P and ‘Z’ for S. Th e second follows by 
putting ‘X’ for S and ‘Y’ for M and ‘Z’ for P.
Celarent tells us that ‘no’ is monotonic down on the left :
If no X is Y and if Z⊆X then no Z is Y.
Th is follows by putting ‘X’ for M and ‘Y’ for P and ‘Z’ for S in:
No M is P
Every S is M
∴ No S is P
15 Cf. Horn 2001, section 4.5.
16 Van Benthem 2008.

a contemporary assessment of aristotle’s basic theory  
49
Monotonicity down on the right follows from this by applying simple conversion to 
any universal negative proposition.
Darii tells us that ‘some’ is monotonic up on the right:
If some X is Y and if Y⊆Z then some X is Z.
Th is follows by putting ‘X’ for S and ‘Y’ for M and ‘Z’ for P in:
Every M is P
Some S is M
∴ Some S is P
Monotonicity up on the left  follows from this by applying simple conversion to any 
particular affi  rmative proposition.
So the choice of the fi rst three moods of the fi rst fi gure, together with the principles 
of simple conversion, are ideal forms to take as axiomatic for the symbolism Aristotle 
uses. Th is is why I say that Aristotle’s choice of axiomatic principles is not arbitrary. 
(Or not very arbitrary; he could have omitted Ferio.)
applications
Suppose there is a new determiner added to English, spelled ‘smnot.’ It works 
like this:
‘smnot A is B’ is true if and only if some A is not B
Particular negative propositions that occur in the lower right-hand corner of the 
square of opposition could then be worded ‘Smnot A is B.’
Say whether ‘smnot’ is left  monotonic up, or left  monotonic down, or neither, 
and whether it is right monotonic up, or right monotonic down, or neither. In 
each case cite a syllogistic mood which would validate your claim (assuming 
that ‘smnot A is B’ is equivalent to ‘some A isn’t B.’
2.7.3 A qualifi cation concerning existential import
Th ere remains an issue concerning existential import. We have been discussing parts 
of Aristotle’s theory from a modern perspective. Our applications of monotonicity 
to ‘every,’ ‘some,’ and ‘no’ as discussed earlier presume that the subjects of universal 
propositions do not have existential import, and the subjects of particulars do. And 
we have seen that Aristotle’s assumptions rule this out. We have avoided trouble about 
this by confi ning our discussion to issues where this fact is not relevant. For example, 
the diff erences between the modern and the ancient interpretations of propositions 
do not show up in the fi rst fi gure moods that Aristotle took to be perfect. But if we insist 
on giving propositions the ancient readings, then we notice, e.g. that Barbara does not 

50 
aristotle’s proofs of conversions and syllogisms
actually entail standard monotonicity for ‘every.’ Th is is because Barbara by itself does 
not force monotonicity to hold in complete generality. Th is is because its premises are 
themselves universal affi  rmatives, and since such propositions have existential import 
for their subject terms, Barbara never gets to apply non-vacuously to a case with 
an empty subject. So all that is shown is that monotonicity holds for all applications 
in which the subject terms of universal affi  rmatives are non-empty. Th is is a coherent, 
but qualifi ed form of monotonicity.
For a determiner to be qualifi edly monotonic17 down on the left  means that when it 
relates a class X to class Y, it also relates any non-empty subclass of X to Y:
If ↓D relates X to Y, and if Z⊆X and Z≠∅, then ↓D relates Z to Y
Likewise for qualifi ed monotonicity down on the right. And for a determiner to be 
qualifi edly monotonic up on the left  means that when it relates a non-empty class X to a 
class Y, it also relates any superset of X to Y:
If ↑D relates X to Y, and if X≠∅ and X⊆Z, then ↑D relates Z to Y
Likewise for qualifi ed monotonicity up on the right.
Applications of Barbara, Celarent, and Darii only directly prove that the determin-
ers ‘every,’ ‘some,’ and ‘no’ are qualifi edly monotonic. In fact, it is easy to extend that 
result, using only reductio and simple conversion, to show that ‘some’ and ‘no’ are 
indeed fully monotonic both on the left  and on the right, and ‘every’ is fully monotonic 
up on the right. But it cannot be shown within Aristotle’s system that ‘every’ is fully 
monotonic down on the left , because that isn’t true in the theory as a whole. A counter-
example is that ‘every’ relates the class of animals to the class of living things, and the 
class of chimeras (which is empty) is a subclass of the class of animals, but ‘every’ does 
not relate the class of chimeras to the class of living things.18
For many purposes (such as those discussed in section 9.4) the diff erence between 
monotonicity and qualifi ed monotonicity is not important. Applications in which it 
may be important are discussed in section 9.3.
2.8 Singular propositions
What happens when we turn to syllogisms containing singular propositions?
We already have established some of these; we have assumed Expository Syllogism, 
and we have proved affi  rmative and negative forms of Universal Application. I think 
17 Westerstahl 2012 calls this “weakened monotonicity.”
18 In fact there is no interpretation of ‘every’ as a relation between two classes that satisfi es the full 
Aristotelian square once the notation is generalized (as medieval logicians generalized it). For example, 
one may not in general hold that ‘every’ relates a class A and a class B if and only if A is non-empty and A is 
a subset of B. For this would make ‘Every chimera is no stone’ false, since the class of chimeras is empty, and 
on the medieval view that sentence is true. (It is true since it is negative and any negative proposition with 
an empty main term is true.)

13th-century texts 
51
that we don’t need any more rules than we already have. Th is is partly because the 
symbolism is so restricted. For example, our current rules do not validate this version 
of Leibniz’s Law:
a is b
b is F
∴ a is F
Th is is not validated for the simple reason that it is not well formed. Th e fi rst premise is 
not among Aristotle’s categorical propositions since he does not use propositions 
which have singular terms as predicates. So this inference is not yet expressible. We will 
consider such propositions in the medieval versions of the theory.
2.9 13th-century texts
(Th is short section may be skipped without aff ecting understanding of later material.)
Starting sometime before the year 400, logic was standardly taught as part of the 
Trivium to students entering higher education. So there was a need for textbooks. By 
the late medieval period, Aristotle’s logic was taught in the following manner. First, the 
conversion principles were taken without proof. Aristotle’s reduction of syllogisms to 
the fi rst fi gure moods was oft en ignored. Eventually it was taught in a form that was 
susceptible to rote memorization, based on special names of the various moods. Th e 
names of the individual moods that we have used in the theory given here are taken 
from Peter of Spain (Peter of Spain LS 4.13). Th ese names are all post-Aristotelian 
inventions; they are cleverly devised so as to encode useful logical information. 
Medieval students were expected to memorize a verse consisting of the names. Peter’s 
version of the verse is:
Barbara Celarent Darii Ferio Baralipton
Celantes Dabitis Fapesmo Frisesomorum.
Cesare Cambestres Festino Barocho Darapti.
Felapto Disamis Datisi Bocardo Ferison.
Th e names in the verse contain codes which show how to mimic Aristotle’s reduction 
of all moods to the fi rst fi gure direct moods. Here are Peter’s instructions (LS 4.13) for 
doing this:
In these four verses are nineteen words representing the nineteen moods of the three fi gures, 
so that by the fi rst word we understand the fi rst mood of the fi rst fi gure, by the second word 
the second mood, and so on for the others. Hence, the fi rst two verses represent the moods of 
the fi rst fi gure, while the third verse—except for its last word—represents the moods of the 
second fi gure, so that the fi rst word of the third verse represents the fi rst mood of the second 
fi gure, the second word the second mood, and so on for the others. But the last word of the third 
verse, along with the words remaining in the fourth verse, represent the moods of the third fi gure 
in order.

52 
aristotle’s proofs of conversions and syllogisms
It must be recognized, however, that by the vowels a e i o are understood the four genera of 
propositions. Th us, by the vowel a we understand the universal affi  rmative, by e the universal 
negative, by i the particular affi  rmative and by o the particular negative. Also, in each word are 
three syllables, and if anything is left  over, it is superfl uous—except m, as will be made clear later. 
And by the fi rst of those three syllables we understand the major proposition of the syllogism, by 
the second the minor and by the third the conclusion. For example, the fi rst word—barbara—
has three syllables with an a in each one, and the a put there three times signifi es that the fi rst 
mood of the fi rst fi gure consists of two universal affi  rmatives concluding a universal affi  rmative. 
And the same understanding applies to the other words regarding the vowels put into them.
Also, it must be recognized that the fi rst four words of the fi rst verse begin with these conso-
nants, b c d f, like all the other words that follow. By this it must be understood that all the moods 
indicated by a word beginning with b are to be reduced to the fi rst mood of the fi rst fi gure, and all 
the moods signifi ed by a word beginning with c to the second mood, those beginning with d to 
the third and those with f to the fourth. Also, wherever an s is put in these words, it signifi es that 
the proposition understood by the immediately preceding vowel is to be converted simply. And 
by p it signifi es that the proposition is to be converted accidentally. Wherever m is put, it signifi es 
that a transposition in premises is to be done, and a transposition is making a minor out of 
a major, and the converse. Where c is put, however, it signifi es that the mood understood by that 
word is to be confi rmed by impossibility.
Earlier, (LS 4.8) Peter has given an example of what he calls reduction by impossibility:
Th e fourth [mood of the second fi gure] consists of a universal affi  rmative and a particular 
negative concluding a particular negative, like
Every man is an animal;
a-certain stone is not an animal;
therefore, a-certain stone is not a man.
And this is reduced to the fi rst mood of the fi rst fi gure by impossibility.
Peter goes on to explain (LS 4.9):
And to reduce by impossibility is to infer, from the opposite of the conclusion and one of the 
premises, the opposite of the other premise. Th e opposite of the conclusion is used—namely,
every stone is a man—
along with the major of the fourth mood just mentioned, and there will be a syllogism in the fi rst 
mood of the fi rst fi gure, as follows:
Every man is an animal;
every stone is a man;
therefore, every stone is an animal.
Th is conclusion is opposed to the minor premises of the fourth mood. And this is to confi rm by 
impossibility.
Th ese instructions work perfectly provided that conversion by limitation is used in the 
correct order; from universal to particular in premises, and from particular to universal 
in conclusions (the verse is written so as to require this).

summary of aristotle’s rules of proof 
53
Th is little theory allows one to reproduce something like Aristotle’s reductions by rote 
memorization of the verse and by the techniques encoded therein. It is a pity that 
the material is so easily learnable without much logical comprehension. In particular, 
it is a pity that Aristotle’s proofs of the conversion principles, using exposition and 
expository syllogism, are not included.
I say that Peter’s text contains “something like” Aristotle’s reductions because 
Peter’s version of reductio is not Aristotle’s. In another work, S 10.9 (431), Peter dis-
tinguishes between a conversive syllogism which “is always formed aft er some other 
syllogism has previously been formed,” and a “syllogism ad impossible,” where this is 
not necessary. He explains the former: “a conversive syllogism is formed aft er another 
syllogism has previously been formed by taking the opposite of the <latter’s> conclu-
sion in combination with one of its premises in order to destroy the remaining one.” 
What Peter calls reduction per impossible in his rules for reducing syllogisms seems 
to be the conversive technique: you validate an argument by validating a diff erent 
argument, one of whose premises is the contradictory of the desired conclusion, and 
whose conclusion is the contradictory of one of the desired premises. It relies on the 
principle:
If the argument: P, contradictory-of-R ∴ contradictory-of- Q is valid,
then: P, Q ∴ R is valid.
It is ironic that Peter calls this reduction by impossibility, since no impossibility need 
be involved in either of the arguments. Although this technique successfully handles 
the reduction of syllogisms, I believe that it could not be used to derive conversion by 
limitation, since that reductio appeals to the absurdity of contrary propositions, 
whereas the conversive technique is limited to mimicking reductios in which the 
absurdity involves contradictories.
2.10 Summary of Aristotle’s rules of proof
It is convenient here to summarize the rules of proof that underlie Aristotle’s logic. 
We still have exactly three basic principles; the others can all be derived from these:
applications
Use Peter’s instructions to reduce the following syllogistic moods.
Cesare
Cambestres
Fapesmo
Bocardo

54 
aristotle’s proofs of conversions and syllogisms
BASIC PRINCIPLES:
Reductio
Exposition (EX)
Expository Syllogism (ES)
DERIVED PRINCIPLES:
Simple conversion
Conversion per accidens
Subalternation
Exposition (EX) for universal affi  rmatives
Universal Application
All standard syllogisms
We are understanding these principles in the following ways.
BASIC PRINCIPLES
Indirect proof (Reductio):
P
A
/∴ Q
where P is a contradictory of Q, and where A is a contrary or contradictory of 
some line that dominates it.
EX (Exposition)
some T is P 
some T isn’t P
/∴ n is T 
/∴ n is T
/∴ n is P 
/∴ n isn’t P
where n is a name that does not already occur in the derivation, and where ‘T’ 
occurs affi  rmatively in an available affi  rmative proposition. For the time being we 
can say that any main term of an affi  rmative proposition occurs affi  rmatively in it.
In justifying a use of this rule one must cite both the line which is being instantiated 
and the line on which ‘T’ occurs affi  rmatively.

summary of aristotle’s rules of proof 
55
ES (Expository Syllogism)
n is P 
n isn’t P
n is T 
n is T
/∴ some T is P   /∴ some T isn’t P
where n is any singular term
DERIVED PRINCIPLES:
Simple conversion
Some A is B 
No A is B
∴ Some B is A 
∴ No B is A
Conversion per accidens
Every A is B 
No A is B
∴ Some B is A 
∴ Some B isn’t A
Subalternation
Every A is B 
No A is B
∴ Some A is B 
∴ Some A isn’t B
UA (Universal Application):
n is X 
n is X
Every X is Y 
No X is Y
∴ n is Y 
∴ n isn’t Y
All standard syllogisms discussed earlier (as described)

56 
quantifying, singular term predicates, negative terms
3
Quantifying Predicates, Singular 
Term Predicates, Negative Terms
By the 1200s, medieval authors were using propositions that are more complex than 
those introduced by Aristotle. Th is chapter explores the consequences of expand-
ing Aristotle’s syntax. Mostly, everything works smoothly, with all of Aristotle’s 
techniques continuing to apply to the new propositions. I have called Aristotle’s 
propositions ‘standard categorical propositions’; I will call the expanded forms ‘cate-
gorical pro positions.’ Th e expanded forms of categorical propositions are discussed 
here in their simplest form. Th e material will be dealt with in more detail in the next 
chapter.
3.1 Expanded notation
We explore here three main expansions of Aristotle’s syntax. Th e fi rst has to do with 
quantifi ed predicates. Aristotle rejected propositions with explicitly quantifi ed pre-
dicates, such as ‘Every man is every animal’ because, he said, they are not true.1 Medieval 
writers noticed that this proposition would be true if there were exactly one animal, 
which was a man.2 It is also clear that other propositions with quantifi ed predicates are 
already true, propositions such as ‘No man is every animal.’3 By the 13th century such 
propositions were clearly acceptable.
1 Aristotle OI 7: “It is not true to predicate a universal universally of a subject, for there cannot be an affi  rma-
tion in which a universal is predicated universally of a subject, for instance ‘every man is every animal’.” 
2 Ockham SL II.4: “it should be noted that every universal proposition in which the predicate is taken 
universally is false if the subject or predicate is predicated of more than one thing. However, if the predicate 
were predicated of exactly one thing and if the same held for the subject, then the proposition could be true. 
Hence, if there were only one animal, say one man, then ‘Every man is every animal’ would be true, as would 
‘Every animal is every man.’ But if there were more than one man or if there were any number of animals 
greater than one, then these propositions would be false. Th erefore, ‘Every phoenix is every animal’ is false, 
even though ‘Every phoenix is every phoenix’ is true. Still, sometimes an indefi nite or particular proposition, 
in which a uni versally taken predicate is predicated, can be true, even though the subject has many things 
contained under it. For example, if there were only one man, then even if there were many animals, ‘Some 
animal is every man’ would be true.”
3 Sherwood S 1.9 (27–8): “It is asked whether [‘every’] can be added to a predicate. It seems that it can, 
since ‘no man is every man’ is true.  .  .  .  it can be added to a term as such—e.g., to ‘man’—and this [resultant] 
whole can be predicated.” See also Bacon ASL Part 2, para 238.

expanded notation 
57
Second, logicians permitted negations to occur more widely than just before the 
copula, so that ‘Not every donkey is running’ is recognized as a logically useful proposition 
whose negation sign is the same word that occurs in ‘Some donkey isn’t running.’
Th ird, by the 14th century logicians regularly used propositions in which singular 
terms occur as predicates, such as ‘Some man isn’t Socrates.’ All of these expanded forms 
of proposition have a rich logic which will be explored in this chapter.
Some writers (e.g. Buridan SD 5.1.8) made use of propositions in which the copula 
occurs at the end, such as ‘No man every animal is.’ In classical Latin the standard posi-
tion for the verb in a simple sentence is at the end. However, by medieval times, many 
scholars began life speaking languages in which the verb occurs in the middle, as in 
English, French, and German. When they used Latin they customarily put the verb 
in the middle. Th is was so common that Buridan called propositions with the verb at 
the end “propositions not in accordance with common usage” (Buridan SD 5.1.8). For 
logical reasons, it is convenient to include such propositions, since putting the verb at 
the end yields a useful canonical form where the verb does not interfere with relations 
among negations and quantifi ers. I will thus describe a notation of logical forms in 
which the verb initially occurs at the end, and logical principles will apply directly to 
such forms. Ordinary propositions, with verbs either in the middle or at the end can 
be generated from the logical forms, and it will be important to carefully state how 
to do this.
We will proceed as follows. First we will state rules for generating what we call 
logical forms. Th ese will appear in bold face, and this custom of having logical forms 
appear in bold face will be maintained throughout the book. Th en we will give rules 
for converting logical forms into propositions of ordinary language. Th e propositions 
of ordinary language will be given in italics, and this too will be a practice followed for 
the rest of the book.
So fi rst we need to carefully describe how logical forms are constructed. Th e process 
will be to begin with a verb and then to add denoting phrases and negations so as 
to form a completed proposition. (A denoting phrase is either a singular term or 
a common term preceded by a quantifi er sign.) In the present notation, the only verb 
we have is ‘is,’ so we will begin with that.
One more idiosyncrasy: It will be convenient to use a dot, ‘·,’ to make logical forms 
that underlie indefi nite propositions. For English, this dot may be considered to repre-
sent the indefi nite article. For Latin, which lacks indefi nite articles, it represents only 
a position in the sentence.
Atomic: Th e single word ‘is’ is a partly constructed propositional logical form
Complex: If ϕ is a partly constructed propositional logical form with less than 
two terms, then the following are partly constructed propositional forms (where 
‘t’ is any singular term and ‘T’ any common term):

58 
quantifying, singular term predicates, negative terms
· T ϕ
some T ϕ
no T ϕ
every T ϕ
t ϕ
Negations: If ϕ is a partly constructed propositional logical form, so is ‘not ϕ.’4
Finally, any partly constructed propositional logical form with two terms is 
a categorical propositional form (or a “categorical proposition” for short).
As mentioned in the previous chapter, I will use the term ‘denoting phrase’ for any 
combination of a quantifi er word (or ‘.’) and common term, or for any singular term. 
So the construction rule just given can be summed up by the following: start with ‘is’ 
and keep putting denoting phrases or negations on the front, but do not put on more 
than two denoting phrases.
Examples of constructions of categorical propositions are given here:
every donkey
· animal
is
≈
every donkey an animal is
some animal
not
≈
some animal not a donkey is
· donkey
is
no animal
not
≈
no animal not some donkey is
some donkey
is
It is most convenient to develop semantics and logic using the logical forms generated 
here. We also need to give a rigorous way to generate the actual sentences that medieval 
logicians use. We can do this as follows:
4 It is possible to restrict this rule to apply only to partly constructed propositions which do not begin 
with ‘not,’ so that double negations never occur. However, it is more natural from a modern perspective to 
admit double (and triple, and  .  .  .) negations, and I will do so. Double negations are always dispensable. 

expanded notation 
59
To turn a categorical propositional logical form (as generated previously) into 
a sentence of natural language:
1. Unbold the logical form and replace the symbol ‘.’ by ‘a(n)’ for English, 
and by nothing for Latin.
2. If ϕ is a categorical proposition containing ‘is,’ where there is a denoting 
phrase immediately to the left  of ‘is,’ the ‘is’ may optionally move to the left  
of the denoting phrase.
3. For English, replace ‘not is’ by ‘isn’t.’
Th e last clause accommodates the fact that in Latin the common position of a negation 
sign is immediately preceding the verb, whereas in English the ‘not’ comes aft er the 
verb ‘is.’ Th ese rules generate the Latin word orders.
An example using the indefi nite article:
some animal not . donkey is
unbold and replace the dot by ‘a’ for English, and by nothing for Latin:
⇒ some animal not a donkey is
Th is is one of the sentences generated from that logical form. We can also move the 
verb to the middle position:
⇒ some animal not is a donkey
change ‘not is’ to ‘isn’t’ for English:
⇒ some animal isn’t a donkey
(For Latin, omit the ‘a.’)
Not every form with its verb at the end can generate a proposition with its verb 
shift ed to the middle like this; the rule applies only if there is nothing between the 
copula and the denoting phrase to its left . For example, the proposition ‘Some A every 
B not is’ is a well-formed proposition meaning that there is some A such that every B is 
such that it (the A) is not it (the B). It is grammatical Latin. Th e ‘is’ cannot be moved 
forward to make ‘Some A is every B not,’ which is not well formed. (In Latin that is not 
a form that would be used by a logician.5)
Although our logical forms all have the verb at the end, this does not mean that such 
a word order is privileged in any way. Indeed, most medieval logicians primarily made 
use of the word order with the verb in middle position. But they would recognize the 
sentence with either order.
5 It is not an ordinary grammatical sentence. It could be produced, however, by the principle that in Latin 
a word may be emphasized by shift ing it into an unusual position. Th e sentence would then be understood as 
one in which the negation has been moved for emphasis. 

60 
quantifying, singular term predicates, negative terms
3.2 Equipollences6
With these expanded forms, lots of logically equivalent forms are possible. One 
common equivalence pattern resembles our contemporary principles of quantifi er 
exchange, such as the equivalence of ‘∀x’ with ‘∼∃x∼.’ Writers acknowledged these 
by formulating a series of equipollences—pairs of logically equivalent propositions 
that diff er only in having one part replaced by an “equipollent” part.7
William Sherwood’s Equipollences:8 Replacing a phrase here by another on the 
same line yields a logically equivalent proposition:
every A 
no A not 
not some A not
no A 
not some A 
every A not
some A 
not no A 
not every A not
some A not 
not no A not 
not every A
An example of a new result is the equivalence of the form ‘No A no B is’ (No A is no B) 
with the form ‘Every A not no B is’ (Every A isn’t no B), which is in turn equivalent 
to ‘Every A some B is’ (Every A is some B). Another is the equivalence of ‘Some A some 
6 Th e term ‘equipollent’ appears as early as the Introductiones Montane Minores (pp. 37–9 in De Rijk 1967 
part II), which de Rijk dates about 1130 (p. 147 in De Rijk 1967 part I), and the Introductiones Norimbergenses 
(p. 139 in De Rijk 1967), which de Rijk dates to the middle of the 12th century (p. 155 in De Rijk 1967 part I), 
where it is used to characterize the principle now called obversion; an instance of this is that ‘every A is B’ is 
said to be equipollent to ‘no A is non-B.’ (See section 3.4 for a discussion of the prefi x ‘-non.’) By sometime in 
the second half of the 12th century (p. 410 in De Rijk 1967 part I) in the Dialectica Monacensis (pp. 474–6 in 
De Rijk 1967 part II) it is used to characterize the quantifi er equivalences discussed here by Sherwood; it 
is also used to characterize the principle that ‘Socrates runs’ is equipollent to ‘Not Socrates doesn’t run.’ 
Th e term ‘equipollent’ is not usually defi ned, but it seems to just mean the logical equivalence between two 
propositions. So understood, simple conversion produces equipollent propositions, but I am not aware of 
anywhere that the term is used to characterize the results of conversions.
7 Sherwood IL I.19 words things this way; he takes equipollence to be a relation that relates the pairs of 
signs in the chart. Paul of Venice LP 1.10 (128) speaks as if it is whole propositions that are equipollent.
8 Th ese equivalences are from William Sherwood IL I.19. Th ey appear widely in other works, then and 
later; cf. Wyclif TDL fi rst tractate, chapter VII (Vol. I, 22–3).
applications
Generate each of the following sentences by fi rst generating a propositional 
logical form and then converting it to its ordinary language form.
No animal is every donkey
Not every animal is a donkey
Socrates isn’t a donkey
No donkey is Socrates
Not every animal isn’t a donkey

equipollences 
61
B is’ (Some A is some B) with ‘Not every A no B is’ (Not every A is no B). Likewise, ‘No A 
every B is’ (No A is every B) is equivalent to ‘Every A some B not is’ (Every A some 
B isn’t).9
It is best to see these equipollences as operating directly on propositional forms 
whose verbs are on the end, and indirectly on sentences generated from these with the 
verb moved to the middle. If applied directly to a sentence with its verb in the middle 
the verb can get in the way of direct application of the equivalences. For example, ‘Some 
A not some B is’ can have its ‘not some B’ changed directly to ‘no B’ to yield ‘Some A no B 
is’ (which can have its verb shift ed left  to yield ‘Some A isn’t B’). But if the verb is in the 
middle, as in ‘Some A not is some B,’ the ‘not’ and ‘some’ are not contiguous, and the 
equipollence rules given earlier do not literally directly apply. (Medieval logicians did 
not fuss over the exact position of the verb when applying these principles.)
Notice that application of any of these equipollences leaves an affi  rmative proposition 
affi  rmative, and a negative proposition negative, where a proposition is affi  rmative if 
it contains no negative signs or an even number of negative signs; otherwise it is 
negative. (Th is assumes that ‘no’ and ‘not’ are the only negative signs.)
To the equipollences we should add the equivalence of ‘some’ with ‘·,’ the symbol 
for the indefi nite article:
some A  ≈  ·A
Th is assumes that indefi nites (denoting phrases with ‘.’) are exactly equivalent to 
denoting phrases with ‘some’ so far as truth conditions are concerned. Aristotle 
himself states that indefi nite sentences are equivalent to particular sentences.10 Th is 
is probably not accurate regarding the normal Greek that was spoken at his time, 
and many later logicians took this to be a stipulation.11 In any event, it was for this 
reason that Aristotle did not give any additional logical principles governing indefi nite 
sentences (they are absent from his syllogistic forms).
Th is is a point that merits some discussion, because in English, indefi nite sentences 
seem to have at least two quite diff erent uses. One is probably the sort that Aristotle 
 9 It seems that the equipollences were originally proposed in application to subjects only, where they 
yielded some of the relations in the square of opposition. However, eventually they were applied to expres-
sions inside of propositions.
10 Aristotle PA 1.7 (11): “It is also clear that putting an indeterminate premise in place of a positive 
particular will produce the same deduction in every fi gure.”
11 Buridan SD 1.4.2: “indefi nites have to be judged in the same way with respect to truth and falsity and 
with respect to oppositions and consequences as particulars.” Elsewhere Buridan admits that this is an 
artifi cial stipulation; in SD 4.2.2 he says “Indeed, by an indefi nite proposition [people] quite oft en mean 
a universal and not a particular proposition.”
Ockham SL 2.3: “It should fi rst be noted that if a proposition is not called indefi nite or particular except 
when its subject term supposits personally, then an indefi nite and a particular are always interchangeable. 
For example, the following are interchangeable: ‘[A] man is running’ and ‘Some man is running’; ‘[An] 
animal is a man’ and ‘Some animal is a man’; ‘[An] animal is not a man’ and ‘Some animal is not a man’.”
Sherwood IL 1.15 (31): “Note that it is unnecessary to add the indefi nite class [of statements] to this last 
division, because indefi nite judgment is like particular judgment.”

62 
quantifying, singular term predicates, negative terms
had in mind. If I say ‘A dog ate my lunch’ then this is probably the same as ‘Some dog 
ate my lunch.’ But indefi nite propositions are also used to make generic statements: 
‘A whale is a mammal,’ ‘A horse is a quadruped,’ ‘A bird has wings.’ It is apparent that 
these do not mean the same as ‘Some whale is a mammal,’ etc. I think it would be a 
distortion of the tradition to lump these together with the indefi nite propositions that 
are said to be equivalent to particulars. (Th ere is in fact a substantial body of medieval 
discussion of generic indefi nites, focusing on examples like ‘A man is an animal,’ 
which is taken by some to be equivalent to a usage from Aristotle’s Categories using 
the form ‘Animal is predicated of man.’) Hereaft er we will treat indefi nites as equivalent 
to particulars, with the understanding that we are not discussing propositions with 
generic readings.
With this in mind, suppose that we take Aristotle’s original list of four (non-singular, 
non-indefi nite) categorical propositions and add the quantifi er sign ‘every’ to the 
predicate. Th is gives us a list of eight forms:
Every A is [a] B 
Every A is every B
No A is [a] B 
No A is every B
Some A is [a] B 
Some A is every B
Some A isn’t [a] B 
Some A isn’t every B
Using Sherwood’s equipollences together with double negation and the equivalence 
of indefi nites with particulars it is straightforward to show that every proposition 
without singular terms in the expanded notation is equivalent to one of these eight 
forms.
applications
Use Sherwood’s equipollences together with double negation to show that the 
propositional forms underlying each of the following sentences is equivalent to 
a proposition with one of the eight forms just given.
Not every animal is every donkey
Every donkey isn’t an animal
Some animal isn’t every donkey
No donkey some animal isn’t
No animal is no animal
3.3 Semantics and rules
Th e semantics of these propositions is straightforward, provided that we keep in 
mind that the surface order of denoting phrases corresponds to their semantic 

semantics and rules 
63
scope,12 and that an affi  rmative proposition is false (and a negative one true) when 
any of its main terms are empty. In the next chapter we will explore the semantics 
more deeply, but a rough understanding will suffi  ce for present purposes.
Validity: It is easy to defi ne a modern form of validity for this new notation. Let 
an interpretation specify what things each term stands for (stipulating that a singular 
term stands for at most one thing). Th en an argument is formally valid iff  there is 
no interpretation that makes the premises all true and the conclusion false. (Since 
quantifi er signs only occur along with common terms, there is no “domain” or “universe” 
to be specifi ed.) 13
Rules: We can now state an expanded set of rules of inference for proofs of proposi-
tions using the expanded notation. Th e rules are mostly extended versions of those 
discussed in Chapter 2.
I begin with a simple one. In the expanded notation, it is now possible for double 
negations to arise, so we need a rule for this:
Double negation
‘not not’ can always be deleted, and it can be inserted wherever it is grammatical 
to do so
Th en we have the quantifi er equipollences (recalling that ‘.’ is being used non-
generically):
12 Th e question of whether surface order of denoting phrases determines scope was unsettled for 
a while. A popular early view was that how to read scope is up to the person speaking. In Anonymous 
[On the Properties of Discourse], p. 717: “When it is said [regarding] ‘every man is [an] animal,’ that the 
supposition of this term ‘animal’ is multiplied, and [that] ‘animal’ does not stand there for one animal, 
but for many, this is not [the case] except by the intention of the speaker. For I am able thus to talk about 
one animal only, and according to this it is false, or for many in common, and thus true. Th erefore, that it 
supposits for one, or for many, is not [the case] except by the intention of the speaker.” Also, On the 
Properties of Discourse, p. 719: “It should be said, however, according to the truth, that this: ‘For every man 
existing some man sees him’ is twofold {ambiguous}, because the commonness of this term ‘some man’ is 
able to be multiplied or not to be multiplied. However, the cause on account of which it ought simply to be 
multiplied is not shown from the force of this locution. For it is not necessary in truth that it be multiplied. 
For it is possible for all to see all, or some [to see] all. Th erefore, that it is multiplied will not be [the case] 
except by the intention of the speaker.”
Later writers tended to ignore this option, and to see scope as determined by word order. In fact, in 1277, 
Robert Kilwardby prohibited the faculty at Oxford from teaching several propositions, one of which is 
the proposition that an animal is every man. Th is proposition would be acceptable in ordinary parlance, as 
a stylistic variant of every man is an animal; presumably the word order made this reading unacceptable 
in teaching logic. (See Uckelman 2009, 20–32.)
13 It is oft en suggested that forms of Aristotelian logic can be symbolized in the monadic predicate 
calculus. Th e expansions of notation discussed in this chapter require the use of a slightly richer notation; 
they are equivalent to forms in monadic predicate logic with identity. Th ey also require the use of 
“quantifi er overlay,” that is, quantifi ers within the scopes of other quantifi ers, to symbolize e.g. ‘Some A is 
every B.’

64 
quantifying, singular term predicates, negative terms
Substitution of equipollences: Any proposition is equivalent to the result of 
replacing an expression in it by an equipollent expression, with the equipollent 
pairs given here.
Quantifi er equipollences:
every T 
≈ 
no T not 
≈ 
not some T not
no T 
≈ 
not some T 
≈ 
every T not
some T 
≈ 
not no T 
≈ 
not every T not
some T not 
≈ 
not no T not 
≈ 
not every T
.T 
≈ 
some T
Because of double negation and the quantifi er equipollences, it becomes possible to 
formulate a general principle of contradiction that Aristotle did not have: any proposi-
tion is contradictory to itself preceded by ‘not.’14 We also have an expansion of his 
specifi cation of contraries: that any proposition beginning with ‘every T’ is contrary to 
the same proposition with ‘not’ inserted aft er ‘every T’ (which is equivalent to changing 
‘every’ to ‘no’).15 Reductio (indirect proof) thus becomes much more widely applicable.
Indirect proof (Reductio):
P
A
Q
where P is a contradictory of Q, and where A is a contradictory or contrary of 
some available line.
Contradictories: Any proposition ϕ is a contradictory of ‘not ϕ,’ and vice versa.
Contraries: Any proposition of the form ‘every T ϕ’ is contrary to ‘no T ϕ,’ and 
vice versa.
14 Peter of Spain S 5.38 (231): “Whenever a negation is placed before some proposition, whether categorical 
or conditional, it always contradicts the latter.” Also Wyclif TDL fi rst tractatus, chapter VII: “ ‘With negation 
preposed, contradiction’: Th is is when a negation is preposed to a universal sign or a particular [sign] in some 
proposition, then [this] makes a proposition equipollent to that proposition which was its contradictory 
before the appearance of the negation, as this proposition: ‘Not everyone who says to me, “Lord, Lord,” will 
enter into the kingdom of heaven’ is equipollent to this: ‘Some man who says to me “Lord, Lord,” will not 
enter into the kingdom of heaven.’ And this proposition ‘not none are chosen’ is equipollent with this: ‘Some 
or many are chosen.’ 
15 William Sherwood IL 1.19 (37) states the general principle of equipollence: “every universal sign is 
equivalent to its contrary with a following negation.” Th is presupposes that ‘every’ and ‘no’ are contrary signs; 
that is, they produce contrary propositions when preceding the same phrase, as Aristotle says. 

semantics and rules 
65
Th ese rules improve on Aristotle’s in the treatment of contradictories. For we now have 
a general procedure to make the contradictory of any proposition—adding a ‘not’ to its 
front—instead of postulating the diagonals of the square of opposition. Aristotle’s own 
stipulations are now provable, since ‘every A . B is’ is equivalent to ‘not some A not . B 
is’ by quantifi er equipollences, and likewise ‘some A . B is’ is equivalent to ‘not no A . B 
is.’ Previously in order to prove ‘no stone is a man’ from some premises by reductio 
we posited ‘some stone is a man’ and derived something impossible. Now we posit 
‘not no stone is a man’ and, if we like, we can turn it into ‘some stone is a man’ by the 
equipollences. Everything else proceeds as before.
In addition to Aristotle’s original principles of simple conversion and conversion per 
accidens it is now possible to derive general principles of subalternation using reductio 
and the equipollences:
Subalternation (DERIVED RULE)
every T ϕ 
no T ϕ
∴ some T ϕ   ∴ some T not ϕ
where ϕ is any string of symbols such that preceding it by a denoting phrase 
makes a propositional logical form
applications
Using only the equipollence rules and reductio, show that the logical forms of 
these arguments are valid.
 
Every A is a B 
 
Some A isn’t a B
∴ 
Some A is a B 
∴ Not every A is a B
 
No A is a B 
 
Not some A is a B
∴ 
Some A isn’t a B 
∴ Not every A is a B
As we use our rule of exposition, it will be increasingly convenient to have a simple way 
of stating that a term is/is not empty. For simplicity, I will use the term itself followed by 
‘is non-empty’ in angle brackets to mean this. Actually we can take this notation to 
abbreviate a certain affi  rmative proposition with that term as the only main term, one that 
is true whenever the term is non-empty. So if ‘T’ is a general term, ‘<T is non-empty>’ 
will be taken as an abbreviation of the proposition ‘Some T .T is’ (‘some T is a T’).16 And 
16 It would be more faithful to the historical tradition to use the form ‘An F is,’ in which there is a subject term 
and a copula, but no predicate term. A common view was that this has the meaning of ‘An F is a being.’ Th at 
noun is supposed to be true of everything there is. We could use that construction here, but it would require 
some way to say that ‘being’ is true of everything that there is. One way to do that would be to state the equiva-
lence of ‘n is a being’ with ‘n is n,’ which is the form used here. Th ere are a number of techniques that would work 
equally well. Th e method adopted here has the advantage of not introducing any new primitive vocabulary.

66 
quantifying, singular term predicates, negative terms
when ‘t’ is a singular term ‘<t is non-empty>’ will abbreviate the proposition ‘t t is’ (‘t is 
t’). We then have an explicit rule which says that any term that occurs as the subject of 
any affi  rmative proposition is not empty:
Non-emptiness
some T ϕ
∴ <T is non-empty> 
if ‘some T ϕ’ is affi  rmative
t ϕ
∴ <t is non-empty> 
if ‘t ϕ’ is affi  rmative
It is convenient to have a broader rule for non-emptiness. Th e following is a derived rule:
Non-emptiness (DERIVED RULE)
ϕ
∴ <T is non-empty> 
if ‘ϕ’ is affi  rmative and ‘T’ is a main term in ϕ
ϕ
∴ <t is non-empty> 
if ‘ϕ’ is affi  rmative and ‘t’ is a main term in ϕ
Exposition is now naturally stated using the defi ned notation:
EX (Exposition)
some T ϕ
<T is non-empty>
∴ n ϕ
∴ n .T is
where n is a singular term that does not already occur in the derivation 
or on its last line
In practice it is convenient to combine uses of Non-Emptiness and Exposition, so 
instead of explicitly inferring non-emptiness on a line and then citing that line in a use 
of EX, we perform exposition in a single step, citing both the line from which non-
emptiness may be inferred and the line which is being exposited. (Th is is the pattern 
that was used in Chapter 2.)
Expository syllogism is unchanged:
ES (Expository Syllogism)
n ϕ
n .T is
∴ some T ϕ
where n is any singular term

singular terms as predicates 
67
applications
Show that the logical forms of these arguments are valid by using the basic rules 
given in this chapter.
 
Some A is a B 
<simple conversion>
∴ 
Some B is an A
 
Every A is a B <conversion per accidens> 
<using simple conversion>
∴ 
Some B is an A
 
Every A is a B <universal application >
 
n is an A
∴ 
n is a B
 
Every A is a B <Darapti> 
<using rule UA>
 
Every A is a C
∴ 
Some C is a B
3.4 Singular terms as predicates
Some new rules are needed to handle propositions with singular terms as predicates. 
A guiding principle is that singular terms permute with whatever they come in contact 
with.17 Th ey permute with each other:18
Marcus Tully is ≈ Tully Marcus is 
Marcus is Tully ≈ Tully is Marcus
17 Buridan (SD 1.6.3): “As far as the conversion of a singular proposition is concerned, about which the 
author [Peter of Spain] does not speak, we should say that it is convertible, be it affi  rmative or negative; 
and it is converted into a singular if the predicate is singular, into an indefi nite or particular if the predicate 
was a non-distributed common term, and into a universal if the predicate was a distributed common term; 
for example, ‘Th is is Socrates; therefore, Socrates is this,’ or ‘Th is is not Socrates; therefore Socrates is not 
this,’ or ‘Socrates is a man; therefore, a man is Socrates’ or ‘Socrates does not run; therefore, no runner is 
Socrates’.”
Ockham (SL II.21): “Similarly, a singular affi  rmative proposition is converted simply into a particular and 
an indefi nite proposition, or into a singular proposition. For example, this follows: ‘Socrates is a man; there-
fore a man is Socrates,’ and ‘therefore some man is Socrates’—and conversely. Likewise, this follows: ‘Socrates 
is Plato; therefore Plato is Socrates’—and conversely. “A singular negative proposition is converted simply 
into either a universal negative or a singular negative. For example, this follows: ‘Socrates is not white; there-
fore no white thing is Socrates,’ and conversely. Likewise, this follows: ‘Socrates is not Plato; therefore Plato is 
not Socrates,’ and conversely.”
18 Th is does not mean that the names switch roles as grammatical subject and predicate. In a sentence 
with a transitive verb, case infl ections will indicate which is subject and which is predicate: ‘Socratesnominative 
Platoaccusative sees’ and ‘Platoaccusative Socratesnominative sees’ illustrate the permutation, where ‘Socrates’ is the 
subject in both sentences and ‘Plato’ is direct object in both, and the two sentences are logically equivalent. 
In actual usage they would be treated as stylistic variants. (Both are normal Latin sentences.) When the verb 
is ‘is’ our current notation off ers no means of distinguishing the grammatical roles of subject and predicate 
nominative. Th at will change in the next chapter.

68 
quantifying, singular term predicates, negative terms
Th ey permute with particular denoting phrases (this is a case of conversion):
Tully a man is ≈ A man Tully is 
Tully is a man ≈ A man is Tully
And they permute with negation:19
Not Tully a stone is ≈ Tully not a stone is 
Not Tully is a stone ≈ Tully isn’t a stone
Given Sherwood’s quantifi er equipollences, singular terms also permute with universal 
denoting phrases. Th e following are all equivalent:
Tully every stone is
Tully not some stone not is 
Quantifi er equipollence
Not Tully some stone not is 
Permutation with negation
Not some stone Tully not is 
Permutation with particulars
Not some stone not Tully is 
Permutation with negation
Every stone Tully is 
Quantifi er equipollence
So we have the rules (using ‘≈’ to relate forms which can replace each other yielding 
logical equivalent propositions):
Permutation for singular terms
Singular terms permute with other denoting phrases:
t quant T 
≈ 
quant T t  where quant is every, some, no, or ..
Singular terms permute with each other:
t s 
≈ 
s t
Singular terms permute with negation:
t not 
≈ 
not t
applications
Show that the logical forms of these arguments are valid.
Socrates isn’t every animal
∴ Some animal isn’t Socrates
Socrates isn’t Plato
∴ Plato isn’t Socrates
No stone is an animal
Some animal is Socrates
∴ Socrates isn’t a ston
19 Peter of Spain S 2.28 (97): “Note that a negation placed before or aft er a singular term signifi es the same 
(as in ‘Socrates is not running’ and ‘Not: Socrates is running’).”

singular terms as predicates 
69
Now that singular terms can occupy predicate positions, transitivity of identity becomes 
formulable, and it needs to be included as a rule. I am not aware of any discussion of 
exactly this principle by medieval logicians. However, there are some 14th-century 
comments by John Buridan on the foundations of syllogistic which supply principles 
from which transitivity of identity can be derived. Buridan says:
I declare, therefore, that every affi  rmative syllogism holds by virtue of the principle ‘whatever 
things are said to be numerically identical with one and the same thing, are also said to be identical 
between themselves.’ For example, if a white thing is identical with Socrates and a running thing 
also is identical with Socrates, then it is necessary that a white thing and a running thing should 
be identical; since, therefore, it amounts to the same thing to say ‘Socrates is identical with a 
white thing’ and to say ‘Socrates is white,’ the inference ‘Socrates is white and he runs; therefore 
a running thing is white’ is valid.20
.  .  .
At this point we should also remark in connection with negative syllogisms that they all are valid 
in virtue of that other principle, namely: ‘whatever things are so related that one of them is said to 
be identical and the other is said to be not identical with one and numerically the same thing, 
they necessarily have to be said not to be identical with each other.’ (SD 5.1.8, 313, 315)
Buridan’s remarks suggest the following principles, from which the rest all follow:
Quasi-transitivity of identity
a b is 
 
a b is
a c is 
 
a c isn’t
/∴ b c is 
/∴ b c isn’t
(Th e negative form is easily provable from the affi  rmative form using reductio.)
Since singular terms permute, transitivity of identity follows immediately from this 
principle.
Transitivity of identity (DERIVED RULE)
a b is
b c is
/∴ a c is
20 Th is inference was widely discussed in its application to the Trinity. Th e worry is that it would validate 
this inference: Th e father is God, and the son is God, so the father is the son. Th e premises are both articles 
of faith, and the conclusion is heretical. A number of ways were found to escape this conclusion. Buridan 
himself took an unusual way out; he holds that the inference holds in all cases that do not pertain to divine 
matter. Th is seems artifi cial. A more common way was to deny the premises in their interpretation that 
makes the inference valid, and to say that the intended reading is ‘Th e thing which the father is is God, and 
likewise for the son. Th is is to be understood something like “the substance which the father (in some sense) 
is is God. Th is allows us to conclude that the substance which the father is is the substance which the son is, 
but that is unproblematic. For a fuller discussion see Th om 2012.

70 
quantifying, singular term predicates, negative terms
We can now derive a version of Leibniz’s Law for identity. We derive the principle only 
for substitutivity of initial terms; the permutation principles and equipollences extend 
this to terms occurring in other than initial position.
Substitutivity of identity (DERIVED RULE)
n m is
n ϕ
/∴ m ϕ
Wyclif states this pattern, including it among expository syllogisms.21
Th is may be proved as follows. It will suffi  ce to prove two instances of the principle, 
namely:
n m is 
 
n m is
n some T is 
 
n some T not is
/∴ m some T is 
/∴ m some T not is
Proof of the fi rst instance:
n m is
n some T is
some T n is
t some T is
t n is
n t is
m t is
t m is
some T m is
m some T is
2 Permutation
3 3 EX
3 3 EX
5 Permutation
1 6 Quasi-Transitivity
7 Permutation
4 8 ES
9 Permutation
1.
2.
3.
4.
5.
6.
7.
8.
9.
10.
Th is proof is complex because we are being fastidious, justifying every change of order. 
If we suppress reference to the changes of order of the elements of the propositions, 
an informal rendition would look much simpler and more natural:
1. 
n is m
2. 
n is some T
 
------------------
3. 
Let t be a T that n is 
2 EX
4. 
n is t 
2 EX
5. 
m is t 
1 4 Quasi-transitivity
6. 
m is some T 
3 5 ES
21 Wyclif TDL fi rst tractatus, chapter XI: “And it should be noted that in every fi gure it is possible to have 
an expository syllogism. In the fi rst fi gure thus: ‘Th is is a man, and Socrates is this: therefore, Socrates is a man.”

singular terms as predicates 
71
Proof of the other instance:
n m is
n some T not is
m some T not is
1.
2.
3.
4.
5.
6.
7.
8.
9.
10.
11.
12.
not m some T not is
some T n not is
t some T is
t n not is
n t not is
m t not is
t m not is
some T m not is
m some T not is
2 Permutation
3 4 EX
3 4 EX
6 Permutation
1 7 Quasi-Transitivity
8 Permutation
5 9 ES
10 Permutation
3 11 Reductio
By symmetry of n and m, the two principles just proved along with a simple use of 
indirect derivation entail the following forms:
n m is 
 
n m is
not n some T is 
 
not n some T not is
/∴ not m some T is 
/∴ not m some T not is
It is then straightforward to show that every proposition expressible in our notation 
that contains exactly one singular term is equivalent to one of these four forms:
n some T is 
n some T not is
not n some T is 
not n some T not is
So Substitutivity of Identity is established for propositions containing exactly one 
singular term. It is not diffi  cult to establish the principle for propositions with two 
singular terms.
applications
Show that the logical forms of these arguments are valid.
Marcus is Tully 
Not every orator is Cicero
Tully is an orator 
Marcus is Cicero
∴ Marcus is an orator 
∴ Some orator isn’t Marcus
Cicero is Tully 
Not every orator is Cicero
Marcus is Tully 
Marcus is Cicero
∴ Not Marcus isn’t Cicero 
∴ Marcus some orator isn’t

72 
quantifying, singular term predicates, negative terms
As noted earlier, self-identity does not generally hold, but it holds for non-empty names:
Self-identity for non-empty terms
<t is non-empty>
∴ t t is
(Of course, if ‘<t is non-empty>’ is taken to abbreviate the particular proposition ‘t t is,’ 
as we have done, this rule is completely trivial.)
3.5 Infi nitizing negation and conversion
Recall from Chapter 1 the theory of “conversion” inherited from Aristotle: conversion 
means the interchange of the subject and predicate terms of a categorical proposition. 
“Simple conversion” was universally recognized as being valid for the universal negative 
and particular affi  rmative forms, and conversion by limitation held for the universal 
forms.
Conversions become more interesting when term negation is allowed. We do this 
in English with the prefi x ‘non-,’ writing complex terms like ‘non-donkey.’ Th e Latin 
version of the negative prefi x is called “infi nitizing negation” by medieval authors; 
it is distinguished from ordinary propositional negation, which is called “negating 
negation.” Th e title “infi nitizing” comes from Aristotle’s calling terms with a negative 
prefi x “infi nite names.”22 Th ere was a special reason to be sensitive to this distinction, 
because in Latin negating negation and infi nitizing negation are spelled the same 
(‘non’) and there are no hyphens to tell you whether or not to attach ‘non’ to a term. 
Th us a proposition containing a negation is oft en ambiguous between the two. (Th is is 
true in Greek as well, so the ambiguity was present when Aristotle made the distinction.) 
An example of such a sentence is:
Non homo est animal
which is ambiguous between the false proposition ‘Not: [a] man is [an] animal’ and 
the true proposition ‘[A] non-man is [an] animal.’ Examples of propositions with 
infi nitizing negations:
Some non-donkey some stone is
Some non-donkey is some stone
Socrates · non-donkey is
Socrates is [a] non-donkey
22 OI §2. Although ‘infi nite name’ is the commonest translation, the expression can also be translated as 
‘indefi nite name’ or ‘unlimited name.’ It does not seem to mean that the term supposits for an infi nite number 
of things (though that is oft en so).

infinitizing negation and conversion 
73
When deciding whether a proposition is affi  rmative or negative, infi nitizing negation 
does not have the eff ect that negating negation has in reversing quality. Although 
this proposition is negative: ‘Some donkey isn’t an animal,’ this one is affi  rmative: ‘Some 
donkey is a non-animal.’
Typically infi nitizing negation combines with a simple term, not a complex term 
such as ‘grey donkey’; Sherwood and others argue for this,23 and other writers seem to 
assume it. Tentatively, I adopt that option.24 We can accommodate infi nite terms by 
stipulating:
Infi nitizing negation
If ‘T’ is a simple common term, ‘non-T’ is a common term.
If ‘t’ is a simple singular term, ‘non-t’ is a common term.
Th e term ‘non-T’ stands for every existing thing that ‘T’ does not stand for.
Th e term ‘non-t’ stands for every existing thing that ‘t’ does not stand for.
We might want to modify this by dropping the condition ‘existing.’ With such a change, 
in a present tense sentence ‘non-donkey’ would stand for past, present, and future 
fi sh, planets, dodos, and merely possible gold mountains. As we have worded the 
condition, the sentence ‘Every non-donkey is a being’ turns out true; on the changed 
version it might be false. (Th is would depend on whether the ‘every’ is restricted 
to presently existing things. See Chapter 10 for discussion.) As we have worded the 
condition it obeys the common constraint that all common terms in an ordinary pre-
sent tense sentence are restricted to standing for presently existing things. But I am not 
sure that there is unanimity on the question.25 Other issues like this arise when past 
tense sentences and modal sentences are involved. We return to discussing this issue in 
23 Sherwood S XI.8: “suppose that Socrates is black. Th en ‘Socrates is a non-man [colored] white’ is false, 
even though ‘Socrates is not a man [colored] white’ is true. Th e cause of this is that when the infi nitating 
negation cuts into one and the same word with that which is infi nitated, it is necessary that it fall over one 
word alone.” Burley Shorter Treatise para 198: “the term to be infi nitized should be simple and not composed 
of a substantive and an adjective, or of adjectives. For what is to be infi nitized should be one. But an aggregate 
term like that is not absolutely one. Th us the term ‘white wood’ {word-order in Latin: “wood white”} cannot 
be infi nitized. And if a negation is added, by saying ‘non white wood’ {“non wood white” in Latin}, nothing is 
infi nitized but the term ‘wood’.”
24 Since ‘non-’ can only combine with a simple term, “double negations” such as ‘non-non-donkey’ are not 
permitted. Albert of Saxony QCL para. 108 (76) says “Infi nite terms cannot be infi nitized. Th is is shown, 
because infi nite terms do not have fi nite signifi cation, which is required if they could be infi nitized. Hence, 
the term ‘non-man’ cannot be infi nitized, nor the term ‘non-horse’.”
25 Peter of Spain S 2.9–15 has both options. He argues that an infi nitized term is ambiguous, for the non 
can either make a “negative” term ‘non-man’ that is said of absolutely everything that is not a man, including 
non-beings, or it can make a “privative” term ‘non-man’ which is true only of (existing) beings that are not 
men. Peter also seems to think that on the fi rst reading, infi nitizing negation makes a proposition containing 
it negative (if it is affi  rmative without the negative term). His fi rst reading then resembles the result of treat-
ing the negation as negating rather then infi nitizing. Before and during Peter’s time there were a variety of 
other views; cf. Kneepkens 1993 for others.

74 
quantifying, singular term predicates, negative terms
sections 10.2 and 10.4 of the chapter on ampliation and restriction. In the meantime 
we will use the version as formulated previously.
Infi nitizing negation is sometimes explained in terms of relative clauses: something 
is a non-P if and only if it is a thing which isn’t a P.26 We will return to this issue when 
we get to relative clauses. In the meantime, we can introduce some adequate rules that 
do not involve relative clauses:
Rule Non:
n · non-P is 
 
<n is non-empty>
∴ <n is non-empty>27 
 
not n · P is
∴ not n · P is 
∴ n · non-P is
3.5.1 Conversion by contraposition and obversion
Along with simple conversion and conversion by limitation, many authors writing 
in the Old Logic tradition discussed conversion by contraposition. To convert by 
contraposition you interchange subject and predicate, changing each from fi nite 
to infi nite, or vice versa. Th at is, if a term lacks an infi nitizing negation, you put one 
on, and if it has an infi nitizing negation you remove it. Universal affi  rmatives and 
particular negatives are said to convert by contraposition as follows:
Every A is B 
is said to be equivalent to 
Every non-B is non-A
Some A isn’t B 
is said to be equivalent to 
Some non-B isn’t non-A
Several early authors endorse conversion by contraposition for universal affi  rmatives 
and particular negatives.28 Others point out that this is not quite correct, since the 
affi  rmative form has existential import for the subject and predicate terms, and the 
contrapositives of such forms have existential import for the negatives of those terms.29 
Examples of nonequivalent pairs are:
Every chimera is an animal [false]
26 Albert of Saxony SL 1.6: “this proposition, ‘Not-man runs,’ is equivalent to this proposition ‘something 
which is not a man is running.’ And this proposition ‘Every not-man runs’ is equivalent to this sentence 
‘Everything which is not a man is running’ ” (Moody’s translation). Notice that this explanation is only 
obviously correct for present tense sentences.
27 Th e inference of non-emptiness is already guaranteed by the fact that the premise is affi  rmative. It is 
included here for comparison with the other inference.
28 Contraposition is discussed in several 12th- and early 13th-century anonymous texts edited in De Rijk 
1967, where it is seen as a type of equipollence. It is endorsed in several of these: Excerpta Norimbergenses 
(138–9), Ars Burana (190), Tractatus Anagnini (238), Introductiones Parisienses (362), Logica: Ut dicit (385), 
Logica: Cum sit nostra (426), Dialectica Monacensis (478). Another text, Ars Emmerana (157) endorses con-
traposition, but then says that it does not hold for the particular negative unless understood with “constancy,” 
a term that had to do with assuming instances of the terms in question. Sherwood IL 3.3 (59) also endorses it.
29 For example, Buridan TC 1.8.100 (224).

infinitizing negation and conversion 
75
versus
Every non-animal is a non-chimera [true]
Likewise, a particular negative is vacuously true if its subject term is empty, but its 
contrapositive is not vacuously true if that very same term (which now occurs within 
the predicate) is empty.
Some donkey isn’t a being [false]
versus
Some nonbeing isn’t a non-donkey [true]
(Th ese invalid transitions are not yielded by our rules of inference. Th e problematic 
inferences become OK when a premise is added making the term in question 
non-empty.)
A similar thing happens with the principle of obversion.30 Th is is the principle 
that states that you can change a proposition to an equivalent form if you change it 
from affi  rmative to negative (or vice versa) and change the predicate term from fi nite 
to infi nite (or infi nite to fi nite). Some examples are:
Every A is B 
is said to be equivalent to 
No A is non-B
No A is B 
is said to be equivalent to 
Every A is non-B
Some A is B 
is said to be equivalent to 
Some A isn’t non-B
Some A isn’t B 
is said to be equivalent to 
Some A is non-B
It is apparent that these inferences are valid when moving from affi  rmative to negative, 
but not in the reverse direction, because the terms may be empty. Buridan (TC I.8.107 
(226)) makes this clear, stating:
From any affi  rmative there follows a negative by changing the predicate according to fi nite and 
infi nite, keeping the rest the same, but there is no formal consequence from a negative to an 
affi  rmative, although there is a consequence under the assumption that all of the terms supposit 
for something.
Th e good direction he gives as:
Every A is B; therefore no A is non-B.
Th e fallacious direction is illustrated by
A chimera isn’t a woman; therefore a chimera is a non-woman.
30 Although ‘contraposition’ is a medieval term, ‘obversion’ is not. I don’t think medieval authors had 
terminology for this pattern of reasoning, though they discussed it.

76 
quantifying, singular term predicates, negative terms
Some medieval writers before Buridan accepted the fallacious versions, and some 
did not.31 Th ese principles are already taken care of by our rules. Proofs of the valid 
directions for two of the four forms are:
every A · B is
no A · non-B is
1.
2.
3.
4.
5.
6.
7.
8.
not no A · non-B is
some A · non-B is
a · A is
a · non-B is
a · B is
not a · B is
2 equipollences
3 EX
3 EX
1 4 UA
5 Non
6 7 reductio
some A · non-B is
some A not · B is
1.
2.
3.
4.
5.
6.
7.
8.
not some A not · B is
every A · B is
a · non-B is
a · A is
a · B is
not a · B is
2 equipollences
1 EX
1 EX
3 5 UA
4 Non
6 7 reductio
Th e last inference can be reversed if you are given the non-emptiness of the subject term:32
some A not · B is
<A is non-empty>
a not · B is
a · A is
<a is non-empty>
not a · B is
a · non-B is
some A · non-B is
1.
2.
3.
4.
5.
6.
7.
8.
1 2 EX
1 2 EX
4 non-emptiness
3 Permute
5 6 Non
4 7 ES
31 Obversion is discussed in several 12th and early 13th-century anonymous texts edited in De Rijk 1967, 
where it is seen as a type of equipollence. It is endorsed in four of these: Excerpta Norimbergenses (138–9), 
Logica: Ut dicit (385), Logica: Cum sit nostra (426), Dialectica Monacensis (478). Th ree texts, Ars Burana, Intro-
ductiones Parisienses, Tractatus Anagnini omit it (while including a discussion of contraposition). One text, 
Introductiones Montane Minores (37–8) objects to it because it mishandles empty terms. Roger Bacon 
ASL para 261 is clear in rejecting obversion when going from negative to affi  rmative: “Infi nitization does not 
follow for any other reason than because a proposition with an infi nite predicate is affi  rmative, and so the 
being [of the predicate] is affi  rmed of the subject. In a negative, however, i.e., in a proposition with a denied 
predicate, the being [of the predicate] is denied of the subject, and from the negation of something there 
does not follow the affi  rmation of the same.”
32 Buridan makes a similar point, assuming that all of the terms stand for something. It is suffi  cient to 
assume that the subject term stands for something.

summary of the rules of proof used so far 
77
3.6 Completeness of the rules
Completeness is the condition that
Completeness: For any argument from a set of propositions Γ to a proposition ϕ, 
if the argument is valid then ϕ is derivable from Γ by the stated rules.
In the next chapter a completeness proof is given for a system of rules similar to the 
one given here. Th e proof given there can be turned into a completeness proof for 
the present notation by erasing all of the markers and parentheses in the formulas 
discussed there.
3.6.1 Verbs other than the copula
Another innovation was widely practiced, though usually without comment. Th is is 
the use of verbs other than the copula, as in ‘Socrates sees Brownie.’ Although we have 
confi ned ourselves to propositions containing the copula as their only verb, a survey of 
the rules given earlier shows that except for the rules that explicitly mention identity, 
none of them depend on the nature of the verb itself. As we move forward we will allow 
for other verbs, with details to be given in the next chapter.
Some expansions of the ancient logic have been discussed here using pretty much 
the forms of expression that medieval authors themselves used. But things will become 
more complex. Th e next chapter enhances the notation of the present chapter so that 
more complex forms can be dealt with.
3.7 Summary of the rules of proof used so far
Here is a summary of the basic rules for derivations discussed in this chapter.
applications
Consider the remaining alleged equivalents, namely:
No A is B 
equivalent to 
Every A is non-B
Some A is B 
equivalent to 
Some A isn’t non-B
Give derivations to validate the affi  rmative to negative directions of each.
Give a derivation to validate the negative to affi  rmative direction of one of the 
equivalences when given the appropriate non-emptiness condition.

78 
quantifying, singular term predicates, negative terms
Double negation
not not can always be deleted, and it can be inserted wherever it is grammati-
cal to do so
Substitution of equipollences: If ϕ diff ers from ϕ* only in containing ψ where 
ϕ* contains ψ*, and if ψ and ψ* are equipollent (ψ ≈ ψ*), then ϕ /∴ ϕ*
Quantifi er equipollences:
every T 
≈ 
no T not 
≈ 
not some T not
no T 
≈ 
not some T 
≈ 
every T not
some T 
≈ 
not no T 
≈ 
not every T not
some T not 
≈ 
not no T not 
≈ 
not every T
·T 
≈ 
some T
Indirect proof (Reductio):
P
A
/∴ Q
where P is a contradictory of Q, and where A is a contradictory or contrary of 
some other line that dominates it.
Contradictories: Any proposition ϕ is a contradictory of ‘not ϕ,’ and vice versa.
Contraries: Any proposition of the form ‘every T ϕ’ is contrary to ‘no T ϕ,’ and 
vice versa.
Non-emptiness
some T ϕ
/∴ <T is non-empty> if ‘some T ϕ’ is affi  rmative
t ϕ
/∴ <t is non-empty> where ‘t ϕ’ is affi  rmative

summary of the rules of proof used so far 
79
EX (Exposition)
some T ϕ
<T is non-empty>
/∴ n ϕ
/∴ n · T is
where n is a singular term that does not already occur in the derivation
As noted earlier, it is oft en convenient to collapse Non-Emptiness and EX into a 
single step.
ES (Expository Syllogism)
n ϕ
n · T is
/∴ some T ϕ
where n is any singular term
Permutation for singular terms
Singular terms permute with other denoting phrases:
t quant T 
≈ 
quant T t,  where quant is every, some, no, or ·.
Singular terms permute with each other:
t s 
≈ 
s t
Singular terms permute with negation:
t not 
≈ 
not t
Quasi-transitivity of identity
a b is 
a b is
a c is 
a c not is
/∴ b c is 
/∴ b c not is
Self-identity for non-empty terms
<t is non-empty>
∴ t t is

80 
quantifying, singular term predicates, negative terms
Rule Non:
n · non-P is 
 
<n is non-empty>
∴ <n is non-empty> 
 
not n · P is
∴ not n · P is 
∴ n · non-P is

basics 
81
4
Linguish
4.1 Basics
Th e propositions that we have discussed so far have very simple forms. Th ere is always 
a single verb, which is ‘is,’ and two terms, plus a quantifi er symbol for each common 
term. Th ere may also be some negation signs. By the 14th century medieval logicians 
regularly dealt with propositions which are much more complex: there are verbs other 
than the copula, there are relative clauses, there are terms which are related by the 
grammatical “possessive,” as in ‘Every woman’s donkey is running,’ and there are various 
kinds of complex terms, as in ‘A donkey seeing some horse is running.’ When things 
get complicated we will need a way to keep track of how the parts of sentences are 
grammatically and logically related to one another. Th e job of this chapter is to devise 
a notation that will permit this. For the sake of continuity, our new notation will be 
an enhanced version of that of the last chapter.
An example: suppose we start with a verb, the transitive verb ‘sees.’ It takes a subject 
and a direct object. We can precede the verb with a term that is to be its subject, say 
‘Socrates.’ Th is gives us ‘Socrates sees,’ in which the subject role is taken by ‘Socrates,’ and 
the direct object role is not yet taken. We can put another term in front of this, with the 
understanding that it takes the role of the direct object of ‘sees’; an example would be 
‘Some horse Socrates sees’ (where the term ‘horse’ has brought a quantifi er word with it). 
We cannot now add any more terms, because there are no grammatical roles for them 
to fi ll. So we have a complete sentence, one that is grammatical in Latin, where it means 
that Socrates sees some horse.
We could have put the same terms in front of the same verb in the same order, but 
with the understanding that ‘Socrates’ takes the direct object role and ‘some horse’ takes 
the subject role. Th e sentence would then mean that there is some horse that sees 
Socrates.
In order to have a notation that makes clear which term is the subject and which 
the direct object, we need to have some device to encode that information. In Latin, 
this job is done partly by case infl ections on the terms. In our fi rst example, ‘Socrates’ 
would receive a nominative case infl ection and ‘horse’ would receive an accusative 
infl ection; in the second example, these infl ections would be reversed. However, case 

82 
linguish
infl ections fall short of doing the job of determining grammatical relations in two 
ways. One is that sometimes a word with a nominative case infl ection is spelled 
the same as the same word with an accusative case infl ection, so you can’t tell from 
the spelling which infl ection the word has. We could treat this as a simple case of 
ambiguity, and add subscripts to words indicating which case infl ection they bear. 
But this would not address a second problem, which is that when there is more than 
one verb in a sentence, case infl ections will not tell you which verb a term is related 
to. For example, in ‘A donkey which sees a horse sees a man,’ both ‘horse’ and ‘man’ are 
accusative, and there are two verbs which take direct objects. To understand the 
sentence you have to know that ‘horse’ is the direct object of the fi rst ‘sees,’ and ‘man’ is 
the direct object of the second ‘sees.’ Th is is easy to determine in English by the English 
word order. But Latin word order is freer than English, and in complicated sentences 
there may be several grammatical relationships to keep track of.
Our approach will utilize a version of what linguists call the “theta-criterion.” Th e 
idea behind the theta-criterion is that certain words, such as verbs, provide roles, 
called theta-roles, and each of these roles must be fi lled by exactly one denoting phrase. 
(Cf. Fromkin et al. 2000.) Further, it is only by fi lling a theta-role that a denoting phrase 
can get into a sentence. As an example, the verb ‘see’ provides two theta-roles, that of the 
seer and that of the thing seen. If the names ‘Socrates’ and ‘Plato’ fi ll these theta-roles 
to make ‘Socrates sees Plato’ then no additional denoting phrase may be put into the 
sentence, so that ‘Socrates Cicero sees Plato’ for example is not well formed.
One way to implement this idea would be to draw arrows to indicate which theta-
role is being fi lled by which denoting phrase. So we could distinguish the two ways to 
read ‘Some horse Socrates sees’ as follows:
Some horse Socrates sees
Some horse Socrates sees
where the fi rst indicates that ‘Socrates’ fi lls the subject role and ‘Some horse’ fi lls the 
direct object role, and the second indicates the opposite. Th ese arrows work fi ne in the 
simplest cases, but they make an unreadable mess in complicated ones. So I will resort 
instead to the use of letters as grammatical role markers for the theta-roles, adopting 
the letters α, β, γ, δ, ε, η, for this purpose (adding subscripts if more are needed). Each verb 
will be accompanied by such markers indicating the grammatical roles that the verb 
provides for fi lling by terms. In English the theta-roles oft en correspond to places in 
the sentence, so that the denoting phrase fi lling the seer role occupies subject position, 
preceding the verb, and the denoting phrase fi lling the seen role occupies direct object 
position, following the verb. I will put the role markers in those positions so that it is 
easy for English speakers to keep track of them without additional explanation. For 
example, we will have forms like:

basics 
83
α sees β
γ runs
δ is ε
In all three cases the marker before the verb indicates the theta-role fi lled by the sub-
ject of the verb. Th e ‘β’ coming aft er ‘sees’ indicates the theta-role fi lled by the direct 
object. Th e verb ‘run’ provides only the subject role. Th e ‘ε’ aft er ‘is’ indicates the predi-
cate role. (I am not quite sure what to call this role. It is the role that is fi lled by a term 
occupying what is usually called a “predicate nominative” position.) When a denot-
ing phrase is added to the verb to build up a sentence the term is to be accompanied by 
a marker that matches some available marker provided by the verb; this indicates 
that the term bears to that verb whatever grammatical relation the marker indicates. 
Th us in the examples discussed previously we had two structures whose meanings 
will be encoded as:
(some horse δ)(Socrates ε) ε sees δ
(some horse ε)(Socrates δ) ε sees δ
Th e fi rst indicates that ‘Socrates’ is the seer and ‘horse’ is the thing seen; the second 
indicates the reverse. I have used parentheses to group together terms with their mark-
ers, including any quantifi er sign that precedes the term. I am pretty sure that no harm 
at all is done if these parentheses enclosing denoting phrases are omitted; the struc-
tures are suffi  ciently clear without them. But the parentheses make it easy visually to 
keep track of the relationships.
It is important that each role gets a unique grammatical marker. Th us, not only must 
the subject and the object of ‘sees’ have diff erent markers, the subject and object of 
‘owns’ must not only be diff erent from one another, they must also be diff erent from 
the markers for the subject and object of ‘sees.’ Th is is because as we conceive of roles, 
the subjects of diff erent verbs are diff erent items. A role is not just a status like “subject,” 
it is a status of being the subject of a particular occurrence of a particular verb in the 
sentence. No denoting phrase may be the subject simultaneously of two diff erent verbs. 
At least, not in natural language.1
I call sentential structures with the roles indicated as earlier logical forms. Th ese 
logical forms are meant to underlie actual sentences of Latin with the indicated gram-
matical structure. Th e sentences that they represent are the ones that are generated by 
this simple procedure, similar to that from the last chapter:
1 Note that in a sentence like ‘Some horse prances and runs’ the ‘horse’ is not the subject of both verbs. It is 
the subject of a unique conjunctive verb phrase ‘prances and runs.’ (Such constructions are not implemented 
in this text.) Also in the sentence ‘Some horse prances and it runs’ the subject is still not the subject of 
the second verb; the subject of the second verb is ‘it.’ If ‘it’ is understood to have ‘horse’ as its grammatical 
antecedent, then this is still not a conjunction in which ‘horse’ is subject of both verbs. Th ese constructions 
(where pronouns have antecedents) are discussed in Chapter 8.

84 
linguish
To generate sentences from logical forms:
 • In a logical form, erase the parentheses and the theta-role-markers.
 • Replace ‘.’ by the indefi nite article in English, and by nothing in Latin.
 • Mark each term to indicate its grammatical case (null marking indicates 
nominative).
 • Optionally move any verb which is immediately to the right of a denoting 
phrase to the left  of that denoting phrase.
For example, from the logical form ‘(some horse ε)(Socrates δ) ε sees δ’ we erase the 
parentheses and role markers to get ‘Some horse Socratesacc sees,’ and we can optionally 
move the verb to get: ‘Some horse sees Socratesacc.’
Th e sentences generated from logical forms are the things that medieval logicians 
took to be their subject matter. Th ey are meaningful sentences of Latin. Th e theta-role 
markers in the logical forms explicitly indicate grammatical (syntactic) relationships 
present in the sentences that are generated by those forms. Th is encapsulates the idea 
that the subject matter of medieval logic consists of meaningful sentences together 
with their grammatical (syntactic) structure.
If two diff erent logical forms produce the same sentence upon erasure of the markers 
and parentheses, then that sentence is ambiguous. (When things get complicated 
there will be ample cases of such ambiguity.) Medieval logicians are sensitive to 
such ambiguities. When logicians describe logical relationships among ambiguous 
sentences, they always have in mind certain grammatical forms that they take the 
sentences to have.
I assume that it is appropriate to apply medieval methods to the structures with 
markers, since these are just sentences with their grammatical structure made explicit. 
I assume that this grammatical structure was something clearly known to logicians. 
(Th ere won’t be anything subtle about it.)
I use the title “Linguish” to stand for the system of logical forms together with 
the algorithms we use to generate (transliterations of ) actual sentences of Latin. It 
is essential to my enterprise that a logical form of Linguish is transformable into a 
unique actual sentence of Latin of the sort that medieval logicians discuss. I write the 
logical forms using English vocabulary, but this is only for the convenience of English 
readers.
Some examples may be helpful. Th e logical form:
(some horse δ)(Socrates ε) δ sees ε
directly generates the English sentence:
Some horse Socratesacc sees

basics 
85
and the Latin sentence:
Aliquis equus Sortem2 videt
Th e Latin sentence, unlike the English sentence, has case endings on the words to 
clarify their cases. Th e ‘uis’ of ‘aliquis’ and the ‘us’ of ‘equus’ tell us that ‘some horse’ is 
nominative (and so it must be the subject of ‘sees’), and the ‘em’ on ‘Sortem’ tells us that 
‘Socrates’ is accusative (and so it must be the direct object of ‘sees’). So in this case the 
Latin sentence is unambiguous whereas the English version is not. To disambiguate 
the English sentence I have subscripted the term ‘Socrates’ with the sign ‘acc’ to indicate 
that it has accusative case. To avoid clutter, I take a lack of marking on a term to indicate 
that it has nominative case.
Alternatively, the logical form:
(some horse ε)(Socrates δ) δ sees ε
directly generates the same English sentence:
Some horseacc Socrates sees
and the Latin sentence:
Aliquem equum Sortes videt
Th e Latin spellings are diff erent from those in the fi rst example; this Latin sentence 
requires that ‘Socrates’ is the subject of ‘sees’ and ‘some horse’ is the direct object.
I have spoken cavalierly of the “English” sentences generated previously, even 
though they are pretty unusual. I assume that they can be understood as intended, 
using the case subscripts as a guide.
Th e logical forms directly generate sentences whose verbs occur at the end, but there 
is nothing special about that order. As in the last chapter, we allow those verbs to 
migrate to the left  under certain circumstances. E.g. the logical form:
(some horse δ)(Socrates ε) δ sees ε
means that there is a horse that sees Socrates. Using the verb-movement option, it 
generates the quasi-English sentences:
Some horse Socratesacc sees  <no movement yet>
Some horse sees Socratesacc
Sees some horse Socratesacc
and generates the Latin sentences:
Aliquis equus Sortem videt
Aliquis equus videt Sortem
Videt aliquis equus Sortem
2 It is common in medieval manuscripts for Socrates’ name to be spelled ‘Sortes’ in the nominative 
and ‘Sortem’ in the accusative.

86 
linguish
Th e fi rst English sentence is grammatical only in poetry or unusual writing. Th e second 
is perfectly grammatical. Th e third is completely ungrammatical. Th e corresponding 
Latin sentences are all grammatical. Th ey all say that some horse sees Socrates. For a 
medieval logician the center form would be most natural, and the fi rst form would be 
clearly understandable. Th e bottom form is not uncommon in classical Latin; it would 
be used to emphasize the verb for some reason. I’ll follow the practice of most medieval 
logicians in mostly ignoring these forms, as stylistically unusual.
Consider a related logical form, one like the previous one with its markers changed:
(some horse ε)(Socrates δ) δ sees ε
Th is means that Socrates sees some horse. It generates almost the same surface forms 
as before:
Some horseacc Socrates sees
Some horseacc sees Socrates
Sees some horseacc Socrates
and generates the Latin sentences:
Aliquem equum Sortes videt
Aliquem equum videt Sortes
Videt aliquem equum Sortes
In this case the fi rst English sentence could be used in poetry with the right meaning. 
Likewise the second sentence, although its normal interpretation has the horse seeing 
Socrates, which is not what the logical form says. Th e third is still ungrammatical. As 
before the Latin sentences are all grammatical and they mean exactly what the logical 
form will be taken to mean: that there is a horse that Socrates sees. Notice that the Latin 
case endings have changed, so as to require that ‘Socrates’ is the subject and ‘some horse’ 
is the direct object.
As a general policy from now on, when I give a logical form of Linguish I will usually 
also give the sentence or sentences that it generates, with an explanation of unusual 
word order if necessary.
Notice that when a natural language form is generated from a logical form, the order 
of the denoting phrases is the same in the native language sentence as in the logical 
form. Th is is wrong for English, which generally requires that its subject precede the 
verb and its direct object follow the verb, even if the sentence may have a meaning in 
which the direct object quantifi er takes scope over that of the subject, as in one natural 
reading of ‘A boy dated each girl.’ As mentioned earlier, by the late medieval period 
logicians were reading sentences as if the surface order of the quantifi er expressions 
corresponds exactly with the semantic scope of those expressions. Th ey thus used a 
regimented version of Latin, one that was very convenient for use in logic. Since it is their 
usage that is under investigation, I will take this regimentation for granted, including 
the assumption that the surface order of terms corresponds to their semantic scope.

categorical propositional logical forms 
87
4.2 Categorical propositional logical forms
We will work up to the full complexity of Linguish slowly. We begin with a stock of 
verbs, with markers indicating their theta-roles:
α exists
α runs
α is β
α sees β
α owns β
In addition to these we will focus entirely on analogues of the logical forms of the last 
chapter. We will then give analogues of the rules of inference from the last chapter; 
these will be mostly the same as before but with grammatical markers added. Th en 
using the markers in the logical forms we will formulate a precise semantics for each 
form—and thus indirectly a semantics for the actual sentences generated from that 
form. We can then defi ne formal validity and prove a completeness theorem. Th e 
techniques of this chapter will continue to be used later when we complicate the forms 
to accommodate more complex sentences.
We begin with a defi nition of categorical propositional logical forms. In the follow-
ing it is convenient to borrow some modern terminology. When a denoting phrase is 
added to a formula I will say that its grammatical marker binds the marker in the for-
mula that uses the same Greek letter. A marker is bound in a formula if some denoting 
phrase binds it; otherwise it is free.
 • Any verb accompanied by one or more distinct markers to indicate gram-
matical roles is a categorical formula. Examples were given earlier.
 • if ‘ϕ’ is a categorical formula, ‘P’ a common term, ‘t’ a singular term, these are 
categorical formulas:
not ϕ
(every P δ) ϕ 
where the marker ‘δ’ appears free in ϕ
(some P δ) ϕ 
where the marker ‘δ’ appears free in ϕ
(no P δ) ϕ 
where the marker ‘δ’ appears free in ϕ
(· P δ) ϕ 
where the marker ‘δ’ appears free in ϕ
(t δ) ϕ 
where the marker ‘δ’ appears free in ‘ϕ’
 • A categorical propositional logical form is a categorical formula with no free 
markers.
Notice that there is no “vacuous quantifi cation.” Th is is because when a quantifi ca-
tional phrase is put on the front of the formula, the marker indicates its grammatical 

88 
linguish
role in the resulting sentence. Vacuous quantifi cation would be a case in which a 
denoting phrase occurs in a sentence without having any grammatical role in that 
sentence. Th at would not be grammatically well formed.
Examples of the construction of some logical forms:
α is β ⇒ (some animal β) α is β ⇒ (every donkey α) (some animal β) α is β
Every donkey some animal is
Every donkey is some animal
α is β ⇒ (· donkey β) α is β ⇒ not (· donkey β) α is β ⇒
(some animal α) not (· donkey β) α is β
Some animal not a donkey is
Some animal isn’t a donkey
α is β ⇒ (· donkey β) α is β ⇒ (no stone α)(· donkey β) α is β
No stone a donkey is
No stone is a donkey
α is β ⇒ not α is β ⇒ (· donkey β) not α is β ⇒
(· stone α)(· donkey β) not α is β
A stone a donkey not is
A stone a donkey isn’t
In this last example, the verb cannot move to a middle position since it is not con-
tiguous to a denoting phrase. (Recall that ‘isn’t’ is an English abbreviation of the Latin 
word order ‘not is.’)
Th ese examples all use the verb ‘is.’ Some examples with other verbs are:
α exists ⇒ (some animal α) α exists
Some animal exists
α sees β ⇒ (· donkey β) α sees β ⇒ (no stone α)(· donkey β) α sees β
No stone a donkeyacc sees
No stone sees a donkeyacc
α sees β ⇒ (· donkey β) α sees β ⇒ not (· donkey β) α sees β ⇒
(some animal α) not (· donkey β) α sees β
Some animal not a donkeyacc sees
Some animal doesn’t see a donkeyacc
Th is last example illustrates one additional complication in generating sentences. 
When the word ‘not’ occurs directly in front of a verb in Latin, that word order is 
normal. In English the helping verb ‘do’ is needed for verbs other than the copula. 
Here is an expanded statement of the principles for generating sentences from logical 
forms:

categorical propositional logical forms 
89
To generate sentences from logical forms:
 • In a logical form, erase the parentheses and the theta-markers.
 • Replace ‘·’ by the indefi nite article in English, and by nothing in Latin.
 • Mark each term for grammatical case, depending on its grammatical marker.
 • Optionally move any verb which is immediately to the right of a denoting 
phrase to the left  of that denoting phrase.3
 • For English, replace ‘not is’ by ‘isn’t’ and replace ‘not VERBs’ by ‘doesn’t VERB’ 
for verbs other than ‘is.’
α owns β ⇒ (· donkey α) α owns β ⇒ (no stone β)(· donkey α) α owns β
No stoneacc a donkey owns
No stoneacc owns a donkey
<i.e. no stone is owned by a donkey>
α sees β ⇒ not α sees β ⇒ (· donkey β) not α sees β ⇒
(· stone α)(· donkey β) not α sees β
A stone a donkeyacc not sees
A stone a donkeyacc doesn’t see
applications
Generate the following sentences by fi rst generating a propositional logical form 
and then converting it to its ordinary language form. (Interpret the sentence 
using ordinary English word order.) If the form cannot be generated, explain 
why.
No animal is every donkey
Not every animal sees a donkey
Socrates isn’t a donkey
Socrates doesn’t see a donkey
No donkey exists
Not every animal isn’t a donkey
Socrates sees Plato a stone
3 It might be advisable to liberalize the constraint on verb movement so as to allow a verb to move past 
a ‘not’ when that ‘not’ did not start out directly in front of the verb. Th is would allow for the generation of 
the surface proposition ‘Some horse sees not every donkey’ from ‘(Some horse α) not (every donkey β) α sees β.’ 
I fi nd such wordings awkward, and I do not recall seeing them in any examples discussed by medieval 
logicians. But they seem to have straightforward meanings. Th is requires further thought.

90 
linguish
4.3 Rules of inference
Th ese rules are essentially those of Chapter 3 with parentheses and markers added. 
For comments on the rules see the previous chapter.
Indirect proof (Reductio):
P
A
∴ Q
where P is a contradictory of Q, and where A is a contradictory or contrary of the 
proposition on some line that dominates A.
Contradictories: One sentence is a contradictory of another if one consists of 
the other preceded by ‘not,’ or is equipollent to the other preceded by ‘not.’
Contraries: Any sentence of the form ‘(every T α) ϕ’ is contrary to ‘(no T α) ϕ.’
Substitution of equipollences: Any proposition is equivalent to the result of 
replacing an expression in it by an equipollent expression, with the equipollent 
pairs given here.
Quantifi er equipollences:
(every T α) 
≈ 
(no T α) not 
≈ 
not (some T α) not
(no T α) 
≈ 
not (some T α) 
≈ 
(every T α) not
(some T α) 
≈ 
not (no T α) 
≈ 
not (every T α) not
(some T α) not 
≈ 
not (no T α) not 
≈ 
not (every T α)
(· T α) 
≈ 
(some T α)
Double negation: not not ≈ -
(double not’s are equipollent to the null string)
Singular terms permute:
(t ε)(quant T δ) 
≈ (quant T δ)(t ε), where quant is ‘every,’ ‘some,’ ‘·’ or no
(t ε)(r δ) 
≈ (r δ)(t ε)
(t ε) not 
≈ not (t ε)

rules of inference 
91
Abbreviations:
‘<T is non-empty>’ is to abbreviate the proposition ‘(some T α)(some T β) α is β.’
‘<t is non-empty>’ is to abbreviate the proposition ‘(t α)(t β) α is β.’
Non-emptiness:
 
(some T α) ϕ
∴ <T is non-empty> 
if ‘(some T α) ϕ’ is affi  rmative
 
(t α) ϕ
∴ <t is non-empty> 
if ‘(t α) ϕ’ is affi  rmative
EX 
(some T α) ϕ
 
<T is non-empty>
 
∴ (n α) ϕ
 
∴ (n α)(some T β) α is β
 
where n is a name that does not already occur in the derivation
ES 
(n α) ϕ
 
(n α)(some T β) α is β
 
∴ (some T α) ϕ   where ‘n’ is any singular term
Quasi-transitivity of identity:
(n α)(m β) α is β
(n α)(p β) α is β
∴ (m α)(p β) α is β
Self-identity:
<n is non-empty>
∴ (n α)(n β) α is β
Finally, we need a housekeeping rule, indicating that the choice of which letters to use 
for grammatical markers is not logically signifi cant:

92 
linguish
Interchange of bound markers: Any proposition is equipollent to the result of 
replacing any bound marker in it (in all its occurrences) by a marker that does 
not occur in it.
In order to avoid lengthy derivations, I will occasionally reorder the bound markers 
within a formula without mention. I will also assume that all rules that specifi cally 
mention the quantifi er sign ‘some’ have parallel versions using the indefi nite sign ‘·.’
4.3.1 Some theorems that may be of interest
Boethius’s principle (“nothing is truer than when something is said of itself”)
<A is non-empty>
∴ (Every A α)(· A β) α is β
Proof :
<A is non-empty>
(every A α)(some A β) α is β
1.
2.
3.
4.
5.
6.
7.
not (every A α)(some A β) α is β
(some A α) not (some A β) α is β 
(a α)(some A β) α is β
(a α) not (some A β) α is β
not (a α)(some A β) α is β
2 equipollence
1 3 EX
1 3 EX
5 permutation
Reductio: 4 and 6 are contradictories
Recall that ‘(Every A α)(· A β) α is β’ does not hold if ‘A’ is empty.4
Generalized subalternation (DERIVED RULE)
(every T α) ϕ 
(no T α) ϕ
∴ (some T α) ϕ   ∴ (some T α) not ϕ
4 Buridan SD 1.8.4: “no affi  rmative is true in which the subject supposits for nothing.”
Ockham SL 2.14: “Now someone might ask: isn’t ‘A chimera is a chimera’ true? It seems that it is true, 
since the same thing is predicated of itself. And Boethius claims that no proposition is more true than one 
in which the same thing is predicated of itself.  .  .  .  Boethius meant that no proposition in which some-
thing is predicated of something is more true than one in which the same thing is predicated of itself. But 
since his point is a negative one, it is consistent with its being the case that neither proposition is true—
neither the one in which the same thing is predicated of itself nor the one in which something else is 
predicated of it.”

rules of inference 
93
Substitutivity of identity (DERIVED RULE)
(n α)(m β) α is β
(n α) ϕ
∴ (m α) ϕ
UA (DERIVED RULE)
 
(every T α) ϕ 
 (no T α) ϕ
 
(n α)(some T β) α is β 
 (n α)(some T β) α is β
  ∴ (n α) ϕ 
∴ not (n α) ϕ
A form of Universal Generalization is derivable, but it’s just as easy to derive general-
izations using reductio, so we won’t bother to formulate it.
Affi  rmative import (DERIVED RULE)
   ϕ
∴ <T is non-empty> where ϕ is affi  rmative and ‘T’ occurs as a main term in ϕ
   ϕ
∴ <t is non-empty> where ϕ is affi  rmative and ‘t’ occurs as a main term in ϕ
Proof of the fi rst part (for common terms): Take ϕ and replace ‘(no P γ)’ by ‘(every P γ) 
not,’ and ‘(· P γ)’ by ‘(some P γ),’ and move all negations and singular terms as far to 
the right as possible, using equipollences when necessary to change ‘not (some P γ)’ 
to ‘(every P γ) not’ and ‘not (some P γ)’ to ‘(every P γ) not.’ If the initial denoting phrase 
is ‘(some T α),’ we are done, because of the Non-Emptiness rule. If it is ‘(every T α)’ then 
use subalternation to get ‘(some T α)’ and we are again done. Otherwise, some other 
denoting phrase is on the front. If that term uses ‘every,’ apply subalternation. Th en use 
EX to infer the result of replacing the initial denoting phrase with a new singular 
denoting phrase. Now permute the new singular term to the right, and start over.
Proof of the second part (for singular terms): permute the singular term denoting 
phrases to the front and apply the Non-Emptiness rule.
4.3.1.1 symmetry of ‘is’
In the notation of Chapter 3 there were two propositions that you could make using 
two names and the copula; they were:
Marcus is Tully
Tully is Marcus

94 
linguish
(I am here ignoring the position of the copula itself, which is a surface issue.) In our 
new notation there are four. Th e diff erences cannot be illustrated using only third-
person singular forms, but with other persons they are:
Marcus I am
I am Marcus
Marcus is me 
<or Marcus is I>
Me is Marcus 
<or I is Marcus>
In the fi rst two examples the subject of the verb is ‘I’ and in the fi nal two the subject 
is ‘Marcus.’ In the Linguish notation, using only third-person singular terms, the 
forms are:
(Marcus α)(Tully β) α is β
(Tully β)(Marcus α) α is β
(Marcus α)(Tully β) β is α
(Tully β)(Marcus α) β is α
In the fi rst two forms the term ‘Marcus’ is the subject; in the latter two the subject is 
‘Tully.’ Th e fi rst two forms are equivalent to one another by permutation of singular 
terms; likewise for the fi nal two forms. But what about the fi rst two versus the fi nal 
two? In fact, we can prove they are equivalent. I will show one particular case of this, 
the inference:
(Marcus α)(Tully β) α is β
∴ (Marcus α)(Tully β) β is α
(m α)(t β) α is β
<m is non-empty>
(m α)(m β) α is β
(t α)(m β) α is β
(m β)(t α) α is β
(m γ)(t δ) δ is γ
(m α)(t β) β is α
1.
2.
3.
4.
5.
6.
7.
1 non-emptiness
2 self-identity
1 3 quasi-transitivity of identity
4 permutation
5 interchange of bound markers
6 interchange of bound markers
I believe that the following derived rule holds in general.
Symmetry of ‘is’: (DERIVED RULE)
If ‘α’ and ‘β’ are any two distinct markers, any proposition containing ‘α is β’ is 
equivalent to the same proposition with ‘β is α.’
(If this is not derivable, it should be posited as a basic rule.)

signification and supposition 
95
4.4 Signifi cation and supposition
To give the semantics of Linguish, we will proceed in the usual way, by fi rst linking the 
simple expressions of the language—terms and verbs—to things in the world, and then 
characterizing truth conditions for sentences based on those links. Our semantics is 
stated for propositions in logical form; the results are to automatically apply to the real 
surface propositions that are generated from them, where the logical form indicates 
how the surface proposition is read.
Two key semantic relations that were used by philosophers during the 12th–14th 
centuries are signifi cation and supposition. First, signifi cation.
Th e word ‘signifi cation’ occurs over the centuries in a wide variety of uses. It is used 
here in one of its common 14th-century meanings. A simple account given by both 
Ockham and Buridan is that words are signs of (or subordinated to) mental con-
cepts, and the words thereby signify the things those concepts are concepts of. Th e 
things in question are things such as particular donkeys, persons, things. All that 
is needed for the logical theory is that signifi cation is a relation between terms and 
things.5
5 Realist accounts hold that words are signs of Forms, and words signify the Forms. Th ese will be Forms 
of particular donkeys, persons, things. In the nominalist tradition, words will typically stand not for Forms, 
but for the particular things that the Forms are of. For simplicity of exposition, we will not give the details of 
realist accounts. (Th ey would not aff ect the logical forms studied here.)
applications
Provide derivations to validate the following derived rules.
Generalized Subalternation
Universal Application
Provide derivations to show that empty denoting phrases may be intersubsti-
tuted. For example:
 
not (n α)(n β) α is β 
‘n’ is empty
 
not (some P α)(some P β) α is β 
‘P’ is empty
 
(n α) ϕ
∴ (some P α) ϕ
 
not (n α)(n β) α is β 
‘n’ is empty
 
not (some P α)(some P β) α is β 
‘P’ is empty
 
(some P α) ϕ
∴ (n α) ϕ

96 
linguish
Signifi cation
Each common term is a sign of a concept which is naturally a concept of some 
(or no) things. Each common term signifi es at time t each thing the concept is 
a concept of at time t.
Each singular term is a sign of a concept which is naturally a concept of at 
most one thing. Each singular term signifi es at time t the thing (if any) that the 
concept is a concept of at time t.
Th e concept associated with a written or spoken term is a stable thing; it is assigned to a 
term independent of its use in a sentence. Th e written word ‘young’ is subordinated to 
a concept that at any given time is a concept of certain things, and the word signifi es 
those things then; at a later time that concept is no longer a concept of some of those 
things, and the word no longer signifi es them then. Th is is an idealized account; variants 
are discussed in Chapter 10 (including an account by Buridan in which signifi cation 
does not vary with time).
For purposes of discussing truth conditions, the most important semantic relation 
is what medieval theorists came to call “supposition.”6 Supposition presupposes signi-
fi cation; that is, only a term that already has signifi cation can have supposition.7 
Supposition in general is usually defi ned in terms of the accepting or taking of a term 
for something, or a term’s taking the place of something, when that term occurs in a 
proposition. An occurrence of a term in a proposition supposits for (stands for) a thing 
iff  it is taken for, or is accepted for, or takes the place of, that thing.8 “Suppositing for” is 
6 ‘Supposit’ was originally a word from the syntactic part of grammar; for a word to supposit originally 
meant for it to occur as the subject of a verb. It gradually began to be used for a semantic relation between a 
subject term and what that term stands for in that position. Eventually it was extended to a relation between 
any occurrence of a term and what that particular occurrence of the term stands for.
7 Lambert 2c (105) [in Kretzmann and Stump 1988]: “For the signifi cation is the concept of the thing 
represented by means of the utterance, and before the union of it with the utterance there is no term; rather, a 
term is constituted in the union of that concept of a thing with an utterance. Supposition, on the other hand, 
is a certain property of a term that has been constituted in that way.” Also Roger Bacon ASL para 212 (107–8): 
“supposition is not a property except of a term actually ordered within an expression, and not outside it. 
Signifi cation, however, is a condition of an utterance and a term in and of itself,  .  .  .  So it signifi es both outside 
an expression and within an expression, although it supposits only within.”
Th ere is one acknowledged exception to this: a nonsense term can be used to supposit for itself. So in 
the sentence ‘Bu has no signifi cation’ the sentence is true because ‘Bu’ does indeed supposit for itself in this 
special context.
8 Some other explications are: Sherwood IL V.1, p. 105: “Signifi cation, then, is a presentation of the form of 
something to the understanding. Supposition, however, is an ordering of the understanding of something 
under something else.” Albert of Saxony, Summa Logica, Part Two, Chapter One: “Supposition, in the sense here 
intended, is the interpretation, or usage, of a categorematic term, for some thing or things in a proposition.” 
Marsilius of Inghen. <1. Suppositions>, page 53: “supposition is the acceptance of a term in a proposition for 
something, or things” Paul of Venice II.1 (30): “Supposition is the acceptance of a term in a proposition for some 
thing or things.” Peter of Spain LS VI 2–3: “Supposition is the acceptance of a substantival term for something.” 
Walter Burley LTPAL 1.1.1.6 (80): “Speaking generally, supposition is the taking of a term for something.” 
William Ockham SL 1.63 (189): “Supposition is said to be a sort of taking the place of another.”

signification and supposition 
97
pretty much what we would express today by “standing for” or perhaps by “referring 
to” in some of the ways that ‘refer’ is used. So ‘x supposits for β’ means essentially ‘x 
stands for β.’ I’ll stick with ‘supposit’ to clarify that it is the medieval theory that is 
under discussion.
Like signifi cation, “supposition” relates linguistic expressions with extra-linguistic 
things, but which things a term supposits for depends on its use in a proposition. For 
purposes of this chapter we will only consider terms used in present tense non-modal 
propositions without special verbs such as ‘believe’ or ‘signify.’ (Other propositions are 
discussed in Chapter 10.) We also confi ne ourselves to occurrences of terms which are 
not used to stand for themselves (as in ‘Donkey has two syllables’) or for the associated 
concept or form (as in ‘Donkey is a species’). In the propositions discussed here, sup-
position can be characterized in terms of signifi cation as follows:
Supposition
Each common term supposits at time t for all of the things that it signifi es at t 
and which exist at t.9
Each proper name supposits at time t for the thing (if any) that it signifi es at t, 
provided that that thing exists at t;10 otherwise it supposits at t for nothing.
Truth conditions for present tense sentences are all given in terms of suppositing with 
respect to the present time. (Th at is, the time of utterance of the sentence, or the feigned 
time.) Until we reach Chapter 10 on tenses, we will suppress explicit mention of the 
relativity to the present time. Th at is, instead of saying ‘supposits at the present time’ we 
will just say ‘supposits.’ (Th is is for simplicity of expression only.) So we have:
‘bishop’ supposits for x iff  x is a (presently existing) bishop
‘dodo’ supposits for x iff  x is a presently existing dodo
‘Magic Johnson’ supposits for presently existing Magic Johnson
‘Socrates’ supposits for presently existing Socrates
 9 I am ignoring a view that is endorsed e.g. by Peter of Spain SL (11.16) according to which certain pres-
ent things do not exist. For example, false propositions do not exist even if they are uttered: “All statables that 
are false in the present are present but not existent since nothing false exists.” For Peter’s version of this view 
‘which exist at t’ should be replaced by ‘which are present at t.’
10 Th e requirement that a term used in a present tense sentence supposit only for presently existing things 
is called “restriction,” a phenomenon that is discussed in Chapter 10. Before about 1400 restriction for proper 
names is not generally part of the theory. Certain authors (Anonymous, Treatise on Univocation 338; 
Lambert of Auxerre/Lagny PT 5b; Peter of Spain LS 9.2) explicitly say that singular terms are not restricted; 
others state restriction conditions only for common terms, implying thereby that singular terms are not 
restricted (Anonymous Cum sit nostra 450–1; Anonymous Properties of Discourse 723–5; William Sherwood 
IL 5.16.1; Walter Burley, Longer Treatise paras (206)–(208)). But some later authors (Marsilius of Inghen 
Ampliations 121; Paul of Venice, Parva Logica II.8 and passages in Ashworth 1974a II.6 pp 89ff .) give examples 
in which proper names are said to be ampliated or restricted. Ockham SL II.22 seems to imply that only com-
mon terms are subject to ampliation. Buridan’s views are discussed in Chapter 10.

98 
linguish
Since no dodos presently exist, ‘dodo’ supposits for nothing at all. Likewise, since 
Socrates does not presently exist, ‘Socrates’ supposits for nothing.
4.5 Truth conditions
In this section we give truth conditions for logical forms of Linguish. We have already 
explained in an informal way how the symbolism is to be understood, suggesting that 
the sentences be understood as they are pronounced in English, with the proviso that 
terms in affi  rmative sentences have existential import, and terms in negative sentences 
the reverse. It is not clear how this is to work when things get complicated, and so we will 
formulate the semantics in a more detailed and rigorous way. Generally, when students 
learn modern logic they are given an informal explanation of how to read the symbolism. 
Eventually they catch on, and are able to use the notation well. However, when one wishes 
to prove something about the logical system, such as a completeness theorem to the eff ect 
that any valid argument may be proved to be valid by means of a formal derivation 
using specifi ed rules of inference, then one needs a rigorous statement of when a sentence 
in the notation is true. Th is will be especially important here since the notation is 
slightly diff erent from the notation we have all learned in logic courses, and some of the 
sentences are given a slightly diff erent interpretation than we are used to.
Th e techniques detailed here are modern, not medieval. Medieval writers occasionally 
discuss truth conditions, and these remarks will be useful as a guide. But their remarks are 
usually limited to a particular construction, such as the standard categorical propositions 
that Aristotle used, or molecular sentences that are conjunctions or disjunctions, or 
conditionals. Th e idea of giving a single unifi ed theory was not pursued. We will pursue 
it here, using 20th-century techniques. Our goal is to formulate a precise semantics 
that agrees with the truth conditions that were discussed by medieval authors, and that 
permits a general defi nition of formal validity that will allow us to pose the questions 
of how adequate are the rules of inference that were discussed in medieval times.
Th e goal is this: given a specifi cation of what the terms supposit for, and what things the 
verbs hold of, to state explicitly when an arbitrary logical form in Linguish notation is true.
We begin with what is usually called the “intended interpretation,” where what the 
terms supposit for and what the verbs hold of is determined by the normal meanings of 
the words used.
TERMS
‘donkey’ supposits for all presently existing donkeys
‘dodo’ supposits for all presently existing dodos (and thus for nothing)
‘Madonna’ supposits for presently existing Madonna
‘Socrates’ supposits for presently existing Socrates (and thus for nothing)
etc.

truth conditions 
99
VERBS
‘runs’ holds of all things that presently run
‘sings’ holds of all things that presently sing
‘is’ holds of every pair of things whose fi rst and second members are the same
‘sees’ holds of every pair of things whose fi rst member presently sees the 
second member
etc.
We will need to specify under what conditions a logical form is true. Usually this is done 
by making assignments to the variables in the formulas, and giving truth conditions 
relative to assignments to the variables. Th ere are no variables in Linguish, so we can-
not do exactly the same. But there is an equivalent technique, which is to introduce 
temporary names, and to give truth conditions relative to assignments to the temporary 
names. Th ese names will be written ‘§k’ where ‘k’ is a positive numeral. So that the 
formula ‘(§3 α) α F’ will be true relative to an assignment to the temporary names if and 
only if the thing assigned to the temporary name ‘§3’ is in the extension of the predicate 
‘F.’ For a regular verb, the sentence ‘(§5 α) α runs’ is true relative to an assignment to 
the temporary names if and only if the verb ‘runs’ holds of the thing assigned to the 
temporary name ‘§5.’
Is there anything like this in the medieval tradition? Perhaps. Th ere are some writings 
on the topic of “proving terms,” which seem to give partial theories of truth conditions 
for propositions. An example is this passage from Richard Billingham’s Speculum 
Puerorum {“A Boys’ Mirror”}, in De Rijk 1982 (84):
8 First example: ‘a man runs.’ Th is proposition is mediate. And it is proved thus: a man runs: ‘this 
runs; and this is a man; therefore a man runs.’ And consequently through inferiors of it, because 
an inferior is that from which something follows, and not conversely.
Billingham might here be discussing the rule of inference, expository syllogism, in 
which case this passage may not be relevant. But in context “proving the terms” in ‘A 
man runs’ seems less like giving a proof than giving an explanation of truth conditions 
for that proposition, using ‘this’ somewhat as we will use temporary names. For example, 
‘a man runs’ is true iff  a thing—call it ‘this’—which is a man is such that ‘this runs’ 
is true. And ‘this runs’ is true relative to an assignment of a thing to the “temporary 
name”  ‘this.’
Th is is the idea we shall pursue. We will introduce a series of temporary names: 
§1, §2, §3,  .  .  .  Because they are temporary, they do not come already suppositing 
for things; instead we will assign them things to supposit for, relative to that assign-
ment. We will use σ to stand for an arbitrary assignment of things to the temporary 
names.

100 
linguish
An assignment, σ, to the temporary names of the language is any way of associat-
ing with each temporary name a single thing (or nothing at all).
Th e notation ‘σ(§1)’ will stand for the thing, whatever it is, that σ assigns to the 
temporary name ‘§1.’
DEFINITION OF NOTATION
If σ is an assignment of things to the temporary names, and if ‘§k’ is a tempo-
rary name, then σ(§k) is the thing, if any, that σ assigns to ‘§k.’
If σ assigns nothing at all to ‘§k’ then we say that σ(§k) is undefi ned.
For the simplest type of sentence with a two-place verb, and containing no terms except 
for temporary names, we will want to say:
‘(§j α)(§k β) α V β’ is trueσ iff  ‘V’ holds of the pair <σ(§j), σ(§k)>.
Th is says e.g. that the logical form underlying ‘§1 sees §2’ is true on the assignment σ if 
and only if ‘sees’ holds of the pair of things that σ assigns to the names §1 and §2. So we 
will defi ne truth conditions for whole propositions based on an assignment of things 
to the temporary names.
One-place “verbs” such as ‘α is brown’ should be treated similarly.
So let us talk about assignments of things to temporary names. We will use the Greek 
letters ‘σ’, ‘σ′’, ‘σ″,’ and so on for assignments of things to the temporary names of the 
language.
Here are some assignments:
σ′ assigns Madonna to ‘§1’ and assigns Socrates to ‘§2’ and assigns Plato to ‘§3’
σ″ assigns Madonna to both ‘§1’ and ‘§2’ and assigns Bono to ‘§3’
σ′″ assigns Socrates to ‘§1’ and assigns Bono to ‘§2’ and assigns nothing at all to ‘§3’
Th ese assignments determine these identities:
σ′(§1) = Madonna
σ′(§2) = Socrates
σ′(§3) = Plato
σ″(§1) = Madonna
σ″(§2) = Madonna
σ″(§3) = Bono
σ′″(§1) = Socrates
σ′″(§2) = Bono
σ′″(§3) = nothing at all

truth conditions 
101
Once we have completed our semantic theory, it will turn out that relative to assign-
ment σ′, the formula ‘(§1 α) α sings’ is true (because Madonna currently sings) and 
the formula ‘(§2 α) α sings’ is false (because Socrates does not currently sing) and the 
formula ‘(§3 α) α sings’ is false (because Plato does not currently sing). Also, relative 
to the assignment σ′″, ‘(§3 α) α sings’ will be false because ‘§3’ is assigned nothing 
at all.
For a more compact notation we will use ‘trueσ’ to abbreviate ‘true relative to the 
assignment σ.’
‘trueσ’ abbreviates ‘true relative to the assignment σ’
So we can also say:
‘(§1 α) α sings’ is trueσ′ and ‘(§2 α) α sings’ is falseσ′ and ‘(§3 α) α sings’ is falseσ′
And for the other two assignments:
‘(§1 α) α sings’ is trueσ″ and ‘(§2 α) α sings’ is trueσ″ and ‘(§3 α) α sings’ is trueσ″
‘(§1 α) α sings’ is falseσ′″ and ‘(§2 α) α sings’ is trueσ′″ and ‘(§3 α) α sings’ is falseσ′″
With this in mind, we will give a recursive description of when any formula is true 
on any given assignment σ to the temporary names. We begin our account of truthσ 
with atomic formulas, making use of the VERBS condition given earlier (which states 
which verbs hold of which things or of which pairs of things):
ATOMIC:
An atomic formula of the form ‘(§1 α) α V’ is trueσ iff  ‘V’ holds of σ(§1).
(Th e formula is not trueσ if σ(§1) is undefi ned.)
An atomic formula of the form ‘(§1 α)(§2 β) α V β’ is trueσ iff  ‘V’ holds of the pair 
whose fi rst member is σ(§1) and whose second member is σ(§2).
(Th e formula is not trueσ if either σ(§1) or σ(§2) or both is undefi ned.)
We can now show that our theory yields the results mentioned previously. For example, 
‘(§1 α) α sings’ is trueσ″ because ‘(§1 α) α sings’ is an atomic formula, and so by the 
ATOMIC principle just given, ‘(§1 α) α sings’ is trueσ″ iff  ‘sings’ holds of σ″(§1). But 
σ″(§1) = Madonna (given a moment ago) and by the VERBS principle ‘sings’ holds of 
a thing iff  it sings. So ‘(§1 α) α sings’ is trueσ″ iff  Madonna sings. And since Madonna 
does sing, ‘(§1 α) α sings’ is trueσ″. In an orderly form, this reasoning is:

102 
linguish
‘(§1 α) α sings’ is trueσ″
   iff  
<ATOMIC>
‘sings’ holds of σ″(§1)
   iff  
<Defi nition of σ″>
‘sings’ holds of Madonna
   iff  
<VERBS>
Madonna sings
So the theory gives us that ‘(§1 α) α sings’ is trueσ″ iff  Madonna sings. Th e theory, of 
course, doesn’t tell us that Madonna actually sings; it only states the conditions under 
which ‘(§1 α) α sings’ is trueσ″
Negations work as expected:
NEGATION:
A formula of the form ‘not ϕ’ is trueσ iff  it is not the case that ϕ is trueσ.
(Also, we freely permute negation with singular terms when applying the semantics.)
So we can show that ‘not (§1 α) α sings’ is trueσ″ iff  it’s not the case that Madonna 
sings:
‘not (§1 α) α sings’ is trueσ″
   iff  
<NEGATION>
it is not the case that ‘(§1 α) α sings’ is trueσ″
   iff  
<ATOMIC>
it is not the case that ‘sings’ holds of σ″(§1)
   iff  
<Defi nition of σ″>
it is not the case that ‘sings’ holds of Madonna
   iff  
<VERBS>
it is not the case that Madonna sings
Modifi ed assignments: Shortly, we will want to talk about what happens when we take 
an assignment σ and modify it in certain ways. Th e following terminology will be handy:
When §k is a temporary name, and t is a thing, ‘σ[§k/t]’ stands for the assign-
ment that is just like σ except that it assigns the thing t to the temporary name §k.
Similarly, ‘σ[§k/-]’ stands for the assignment that is just like σ except that it 
assigns nothing at all to §k.
In case σ already assigns t to §k, σ[§k/t] will be the same assignment as σ. Recall the 
assignment σ′ discussed earlier:

truth conditions 
103
σ′ assigns Madonna to ‘§1’ and assigns Socrates to ‘§2’ and assigns Plato to ‘§3’
Consider these modifi cations to σ′:
σ′[§1/Madonna] is the same assignment as σ′
σ′[§2/Socrates] is the same assignment as σ′
σ′[§1/Socrates] is not the same assignment as σ′
σ′[§1/-] is not the same assignment as σ′
If you take an assignment and change what it assigns to a t-name, and then apply that 
assignment to that same t-name, you get what you changed it to. For example, for any 
assignment σ:
σ[§1/Plato](§1) = Plato
An assignment that has been modifi ed can be modifi ed again. For example, 
σ[§1/Socrates][§2/Bono] is the assignment that you get by starting with σ and 
changing what it assigns to ‘§1’ and then taking that changed assignment and changing 
what it assigns to ‘§2.’ It is an assignment that assigns Socrates to ‘§1’ and assigns Bono 
to ‘§2’ and assigns Plato to ‘§3.’
applications
Using the examples given earlier, namely:
σ′ assigns Madonna to ‘§1’ and assigns Socrates to ‘§2’ and assigns Plato to ‘§3’
σ″ assigns Madonna to both ‘§1’ and ‘§2’ and assigns Bono to ‘§3’
σ′″ assigns Socrates to ‘§1’ and assigns Bono to ‘§2’ and assigns nothing to ‘§3’
give the values of each of the following:
σ″(§3)
σ′″(§3)
σ′″(§2)
σ′[§3/Madonna](§3)
σ′[§3/Madonna](§1)
σ′[§3/Madonna][§2/Bono](§3)
σ′[§3/Madonna] [§2/Bono](§1)
σ″[§3/Madonna](§1)
σ″[§3/Madonna][§2/Bono](§3)
σ″[§3/Madonna] [§2/-](§1)
σ′″[§3/Madonna][§1/Bono](§2)
σ′″[§3/Madonna] [§2/Bono](§1)
σ′″[§3/Madonna] [§2/-](§2)

104 
linguish
Next, we give the truth conditions for propositional formulas that contain ordinary 
denoting phrases. Applying one of our clauses for denoting phrases in what follows, 
we replace the outermost denoting phrase with one containing a temporary name. 
Th en we move to the next denoting phrase, always working with the denoting phrase 
which has only temporary name denoting phrases to its left . Eventually we get a sen-
tence whose denoting phrases all contain temporary names, at which point we apply 
the basic conditions for TERMS and for VERBS given earlier.
We will need to talk about sentences that optionally begin with denoting phrases 
containing temporary names. We will use ‘τi’ to stand for any string of zero or more 
denoting phrases with temporary names.
(SINGULAR) Denoting Phrases:
If ρ is a non-empty singular term, then ‘τi(ρ α)ϕ’ is trueσ iff  τi(§k α)ϕ is trueσ[§k/a], 
where a is the thing that ρ supposits for (and where ‘§k’ is a temporary name 
not already occurring in ‘τi(ρ α)ϕ’).
If ρ does not supposit for anything, then ‘τi(ρ α) ϕ’ is trueσ iff  τi(§k α) ϕ is 
trueσ[§k/-].
For example, the sentence ‘(Socrates α) α runs’ has no temporary names, so ‘τi’ is empty. 
Applying the condition SINGULAR we have
If ‘Socrates’ is a singular term, then ‘(Socrates α) α runs’ is trueσ iff  ‘(§k α) α runs’ 
is trueσ[§k/a], where a is the thing that ‘Socrates’ supposits for.
If ‘Socrates’ supposits for Socrates, this says that ‘(Socrates α) α runs’ is trueσ iff  ‘(§k α) α 
runs’ is trueσ[§k/Socrates]. Th en our condition ATOMIC says that this is equivalent to 
saying that ‘(Socrates α) α runs’ is trueσ iff  ‘runs’ holds of Socrates.
For denoting phrases with common terms the conditions are:
(COMMON) Denoting Phrases:
If T is a common term that supposits for something, then ‘τi(every T α)ϕ’ is trueσ 
iff  for every thing a that T supposits for, τi(§k α) ϕ is trueσ[§k/a].
If T does not supposit for anything, ‘τi(every T α)ϕ’ is trueσ iff  ‘τi(§k α) ϕ’ is 
trueσ[§k/-].
If T is a common term that supposits for something, then ‘τi(some T α)ϕ’ is trueσ 
iff  for some thing a that T supposits for, τi(§k α) ϕ is trueσ[§k/a].
If T does not supposit for anything, ‘τi(some T α)ϕ’ is trueσ iff  ‘τi(§k α) ϕ’ is 
trueσ[§k/-].

truth conditions 
105
If T is a common term that supposits for something, then ‘τi(· T α)ϕ’ is trueσ iff  
for some thing a that T supposits for, τi(§k α) ϕ is trueσ[§k/a].
If T does not supposit for anything, ‘τi(· T α) ϕ’ is trueσ iff  ‘τi(§k α) ϕ’ is trueσ[§k/-].
If T is a common term that supposits for something, then ‘τi(no T α) ϕ’ is trueσ iff  
for every thing a that T supposits for, it is not the case that τi(§k α) ϕ is trueσ[§k/a].
If T does not supposit for anything, ‘τi(no T α) ϕ’ is trueσ iff  it is not the case that 
‘τi(§k α) ϕ’ is trueσ[§k/-].
Th is method of handling common terms so as to get the right truth conditions with 
respect to existential import is equivalent to a method fi rst proposed (so far as I know) 
in Klima 1988: 24, 50.
Finally we want to talk about a sentence being simply true. If there are no temporary 
names in a sentence, then it will turn out that it is either true on every assignment 
whatsoever to the temporary names, or false on every assignment. So it is customary to 
say that a sentence is true iff  it’s true on every assignment to the temporary names:
TRUTH: A formula ϕ is true iff  for every assignment σ, ϕ is trueσ.
Th is completes the semantic theory.
To illustrate the semantics, let us show fi rst that, assuming that Madonna exists, then 
according to the theory we have just given, ‘(Madonna α) α sings’ is true iff  Madonna 
sings. Here is a proof with each transition in the proof justifi ed by a provision in the 
theory in angle brackets.
‘(Madonna α) α sings’ is true
   iff  
<TRUTH>
for every σ, ‘(Madonna α) α sings’ is trueσ
   iff  
<SINGULAR DP>
for every σ, ‘(§1 α) α sings’ is trueσ[§1/a] where a is the thing that ‘Madonna’ supposits 
for
   iff  
<TERMS>
for every σ, ‘(§1 α) α sings’ is trueσ[§1/Madonna]
   iff  
<ATOMIC>
for every σ, ‘sings’ holds of σ[§1/Madonna](§1)
   iff  
<DEFINITION OF NOTATION>
for every σ, ‘sings’ holds of Madonna
   iff  
<VERBS>
for every σ, Madonna sings
   iff  
<elimination of redundant quantifi er>
Madonna sings

106 
linguish
Th is proof may be easier to follow if we identify exactly which parts of the conditions 
are being changed from one step to the next. Here is the same proof with those parts 
identifi ed:
‘(Madonna α) α sings’ is true
<TRUTH>
for every σ, ‘(Madonna α) α sings’ is trueσ  
<SINGULAR DP>
for every σ, ‘(§1 α) α sings’ is trueσ[§1/a] where a is the thing that ‘Madonna’ supposits for 
<TERMS>
for every σ, ‘(§1 α) α sings’ is trueσ[§1/Madonna]
<ATOMIC>
for every σ, ‘sings’ holds of σ[§1/Madonna](§1) 
<DEFINITION OF NOTATION>
for every σ, ‘sings’ holds of Madonna  
<VERBS>
for every σ, Madonna sings  
<elimination of redundant quantifier>
Madonna sings
Here is an example with two denoting phrases. We show that, assuming there is at 
least one donkey, and at least one animal, then ‘(Every donkey α)(· animal β) α is β’ is 
trueσ iff  for every presently existing donkey d, for at least one presently existing animal 
a, d=a:
(Every donkey α)(· animal β) α is β is trueσ
   iff  
<COMMON DP>
for everything d that ‘donkey’ supposits for, ‘(§1 α)(· animal β) α is β’ is trueσ[§1/d]
   iff  
<TERMS>
for every presently existing donkey d, ‘(§1 α)(· animal β) α is β’ is trueσ[§1/d]
   iff  
<COMMON DP>
for every presently existing donkey d, for at least one thing a that ‘animal’ supposits 
for, ‘(§1 α)(§2 β) α is β’ is trueσ[§1/d][§2/a]
   iff  
<TERMS>

truth conditions 
107
for every presently existing donkey d, for at least one presently existing animal a,
‘(§1 α)(§2 β) α is β’ is trueσ[§1/d][§2/a]
   iff  
<ATOMIC>
for every presently existing donkey d, for at least one presently existing animal a, 
‘is’ holds of the pair whose fi rst member is σ[§1/d][§2/a](§1) and whose second 
member is σ[§1/d][§2/a](§2)
   iff  
<VERBS>
for every presently existing donkey d, for at least one presently existing animal a, 
σ[§1/d][§2/a](§1) = σ[§1/d][§2/a](§2)
   iff  
<DEFINITION OF NOTATION>
for every presently existing donkey d, for at least one presently existing animal a, 
d=a
If no donkeys presently exist, then ‘(Every donkey α)(· animal β) α is β’ is not trueσ for 
any σ. For if there are no donkeys, ‘donkey’ supposits for nothing. Th en the semantics 
goes as follows:
‘(Every donkey α)(· animal β) α is β’ is trueσ
   iff          <COMMON DP>
‘(§1 α)(· animal β) α is β’ is trueσ[§1/-]
   iff          <COMMON DP>
‘(§1 α)(§2 β) α is β’ is trueσ[§1/-][§2/a] for at least one thing a that ‘animal’ supposits for.
‘(§1 α)(§2 β) α is β’ is trueσ[§1/-][§2/a] for at least one animal, a
But σ[§1/-][§2/a] assigns nothing to ‘§1,’ and ‘(§1 α)(§2 β) α is β’ is never trueσ for any 
assignment σ that assigns nothing to one of its temporary names.
An example to show that if some donkeys presently exist, and also some stones, then 
‘(Some donkey α) not (· stone β) α is β’ is trueσ iff  for some presently existing donkey d, 
it is not the case that for at least one presently existing stone s, d=s:
(Some donkey α) not (· stone β) α is β is trueσ
   iff 
for something d that ‘donkey’ supposits for, ‘(§1 α) not (· stone α) α is β’ is trueσ[§1/d]
   iff 
for some presently existing donkey d, ‘not (§1 α)(· stone β) α is β’ is trueσ[§1/d]
   iff 
for some presently existing donkey d, it is not the case that ‘(§1 α)(· stone β) α is β’ is 
trueσ[§1/d]
   iff 
for some presently existing donkey d, it is not the case that for at least one presently 
existing thing s that ‘stone’ supposits for, ‘(§1 α)(§2 β) α is β’ is trueσ[§1/d][§2/s]
   iff 

108 
linguish
for some presently existing donkey d, it is not the case that for at least one presently 
existing stone s, ‘(§1 α)(§2 β) α is β’ is trueσ[§1/d][§2/s]
   iff 
for some presently existing donkey d, it is not the case that for at least one presently 
existing stone s, σ[§1/d][§2/s](§1) = σ[§1/d][§2/s](§2)
   iff 
for some presently existing donkey d, it is not the case that for at least one presently 
existing stone s, d=s
Recall that a particular negative proposition was said to be true if its subject term 
is empty, even though its subject term has scope over the rest of the proposition. As 
an example, we can show that if no dodos presently exist (though there are stones), 
then ‘(Some dodo α) not (· stone β) α is β’ is true.
(Some dodo α) not (· stone β) α is β is trueσ
   iff 
‘(§1 α) not (· stone β) α is β’ is trueσ[§1/-]
   iff 
it is not the case that ‘(§1 α)(· stone β) α is β’ is trueσ[§1/-]
   iff 
it is not the case that for at least one presently existing thing s that ‘stone’ supposits 
for, ‘(§1 α)(§2 β) α is β’ is trueσ[§1/-][§2/s]
But ‘(§1 α)(§2 β) α is β’ cannot be trueσ[§1/-][§2/s], since one of its temporary names is 
assigned nothing. So it is indeed not the case that for at least one presently existing 
thing s that ‘stone’ supposits for, ‘(§1 α)(§2 β) α is β’ is trueσ[§1/-][§2/s]
(It is easy to show that the proposition is also true if there are no stones.) Th is example 
illustrates the fact that a particular negative proposition is true when its subject term 
is empty, even though its subject term has wide scope. Th is fl eshes out the discussion 
of particular negatives in section 1.4, showing that a systematic semantics is possible 
which makes them true when their subject terms are empty, even when they are read 
with the scopes that they intuitively seem to have.
applications
Using the pattern given earlier, identify which provisions of the semantic theory 
justify each step:
Assuming that there are both donkeys and stones:
(Some donkey α) not (. stone β) α is β is trueσ
   iff 
for something d that ‘donkey’ supposits for, ‘(§1 α) not (· stone β) α is β’ is trueσ[§1/d]
   iff 

truth conditions 
109
4.5.1 Affi  rmative and negative propositions and existential import
For Aristotle, categorical propositions are either affi  rmative or negative. As discussed 
in Chapter 1, affi  rmative standard categorical propositions are false when their subject 
terms are empty, and negative standard categorical propositions are true when their sub-
ject terms are empty. Th is held for medieval philosophers as well. In addition, some of 
them expanded the scope of this principle, so that the following became widely adopted:
Existential import:
All main terms in an affi  rmative proposition have existential import; that is, if 
any main term of an affi  rmative proposition supposits for nothing, then the pro-
position is false. Th e reverse is true for negative propositions: if any main term 
of a negative proposition supposits for nothing, then the proposition is true.
for some presently existing donkey d, ‘not (§1 α)(· stone β) α is β’ is trueσ[§1/d]
   iff 
for some presently existing donkey d, it is not the case that (§1 α)(· stone β) α is β’ is 
trueσ[§1/d]
   iff 
for some presently existing donkey d, it is not the case that for at least one presently 
existing thing s that ‘stone’ supposits for, ‘(§1 α)(§2 β) α is β’ is trueσ[§1/d][§2/s]
   iff 
for some presently existing donkey d, it is not the case that for at least one presently 
existing stone s, ‘(§1 α)(§2 β) α is β’ is trueσ[§1/d][§2/s]
   iff 
for some presently existing donkey d, it is not the case that for at least one presently 
existing stone s, ‘is’ holds of the pair <σ[§1/d][§2/s](§1), σ[§1/d][§2/s](§2)>
   iff 
for some presently existing donkey d, it is not the case that for at least one presently 
existing stone s, ‘is’ holds of the pair <d, s>
   iff 
for some presently existing donkey d, it is not the case that for at least one presently 
existing stone s, d=s
Supposing that there are donkeys, show that ‘(No donkey α) α runs’ is true if and 
only if for every donkey d it is not the case that d runs.
Supposing that there are donkeys, and there are horses, show that ‘(Every donkey 
α)(· horse β) α sees β’ is true if and only if for every donkey d there is at least one 
horse h such that d sees h.

110 
linguish
A “main term” of a proposition is a term in that proposition that is not part of another 
term in the proposition. In the simple structures studied in this chapter, terms occur 
only as main terms.
With expanded notions of “affi  rmative” and “negative,” this principle of existential 
import is validated by the semantics given earlier. To establish these results we defi ne 
when a proposition is affi  rmative or negative. We do this by means of a recursive 
characterization.
Affi  rmative and negative formulas:
Any atomic categorical formula is affi  rmative.
If ϕ is affi  rmative (negative) then not ϕ is negative (affi  rmative).
If ϕ is affi  rmative (negative) then so are the following:
(every T α) ϕ
(some T α) ϕ
(. T α) ϕ
(t α) ϕ
If ϕ is affi  rmative (negative) then the following is negative (affi  rmative):
(no T α) ϕ
Th ere is an easy algorithm for determining whether a categorical proposition is affi  rm-
ative or negative: count the number of negative signs in it, where the negative signs are 
‘not’ and ‘no.’ If the sum is odd, the proposition is negative; if it is even, the proposition 
is affi  rmative.11
Example: Th e proposition ‘not (every animal α)(no bishop β) α is β’ is affi  rmative, so if 
there are no bishops it is false. And ‘(some donkey α) not (· stone β) α is β’ is negative, so if 
there are no donkeys, it is true.
4.6 Validity
As mentioned in Chapter 1, Aristotle’s explanation of a good deduction includes both 
what we would call formally valid arguments and non-formally valid ones. Medieval 
authors addressed this dichotomy in a variety of ways, which are not summarized here. 
Instead, in this section we will study formal validity in one modern-day sense. An argu-
ment is formally valid in one modern sense if and only if no way of interpreting the 
terms and verbs in that argument (other than the copula) produces an argument whose 
11 Buridan SD 1.5.4 (47), argues that two negations cancel each other out so far as the quality (affi  rmativ-
ity or negativity) is concerned.

validity 
111
premises are true and whose conclusion is false. For example, suppose that you want to 
show that this argument is not valid:
Every man is an animal
Socrates is an animal
∴ Socrates is a man
Th e argument itself has true premises and a true conclusion, so its actual truth values 
do not establish that it is invalid. But you could ask “What if ‘Socrates’ referred to a 
donkey?” Interpreted in that way, the original argument would have true premises and 
a false conclusion, and this will show that it is invalid. Th is is the idea that we will 
explore here. To make sense of this account, we need to say what interpreting is.
We will say that an interpretation, I, is any way of specifying what the terms of the 
language supposit for and what things the verbs hold of. For example, we will say that 
a name ‘I-supposits’ for certain things, and a verb ‘I-holds’ of certain things. We 
have already seen this in the previous section where we talked about the intended inter-
pretation of the symbolism. To say e.g. that ‘donkey’ supposits for donkeys on the 
intended interpretation, we just used the unmodifi ed term ‘supposit.’ From now on we 
will talk about what a term I-supposits for, so as to make clear which interpretation 
we have in mind. For example, we might want to consider an interpretation I* which 
interprets ‘donkey’ as suppositing for trees, and interprets ‘Madonna’ as suppositing for 
Bono, and so on. Spelling this out we might have e.g.
‘donkey’ I*-supposits for all presently existing trees
‘dodo’ I*-supposits for all presently existing tamales
‘Madonna’ I*-supposits for Bono
‘Socrates’ I*-supposits for Michelle Obama
‘runs’ I*-holds of all things that are presently eating
‘sings’ I*-holds of all things that are presently sleeping
‘is’ I*-holds of every pair whose fi rst and second members are the same
‘sees’ I*-holds of every pair whose fi rst member owns the second member
etc.
Notice that ‘is’ is still given as I*-holding of pairs whose members are identical. Th is 
carries out the medieval idea that ‘is’ is a unique verb with a special meaning. Every 
other verb can vary in its interpretation.
We will need to say what it means for a logical form to be true on the interpretation I, 
that is, for it to be “I-true.” As before, we will need to talk about formulas being I-true 
with respect to an assignment to the temporary names; that is, a formula’s being I-trueσ. 
Th e provisions in what follows diff er hardly at all from those given previously for the 
intended interpretation.
TRUTH: A formula ϕ is I-true iff  for every assignment σ, ϕ is I-trueσ.

112 
linguish
Th e remaining provisions are the same as before, with truth replaced by I-truth.
ATOMIC:
An atomic sentence of the form ‘(§1 α) α V’ is I-trueσ iff  ‘V’ I-holds of σ(§1).
(Th e sentence is not I-trueσ if σ(§1) is undefi ned.)
An atomic sentence of the form ‘(§1 α)(§2 β) α V β’ is I-trueσ iff  ‘V’ I-holds of the 
pair whose fi rst member is σ(§1) and whose second member is σ(§2).
(Th e sentence is not I-trueσ if either σ(§1) or σ(§2) or both is undefi ned.)
Negations work as expected:
NEGATION:
A sentence of the form ‘not ϕ’ is I-trueσ iff  it is not the case that ϕ is I-trueσ.
Also, we freely permute negation with singular terms when applying the semantics.
For non-temporary denoting phrases we have: (As before τi is any string of zero or 
more denoting phrases with temporary names.)
(SINGULAR) Denoting Phrases:
If ρ is a singular term, then ‘τi(ρ α)ϕ’ is I-trueσ iff  τi(§k α)ϕ is I-trueσ[§k/a], where 
a is the thing that ρ I-supposits for.
If ρ does not I-supposit for anything, then ‘τi(ρ α) ϕ’ is I-trueσ iff  τi(§k α) ϕ is 
I-trueσ[§k/-].
(COMMON) Denoting Phrases:
If T is a common term that I-supposits for something, then ‘τi(every T α)ϕ’ is 
I-trueσ iff  for every thing a that T I-supposits for, ‘τi(§k α) ϕ’ is I-trueσ[§k/a].
If T does not I-supposit for anything, ‘τi(every T α)ϕ’ is I-trueσ iff  ‘τi(§k α) ϕ’ is 
I-trueσ[§k/-].
If T is a common term that I-supposits for something, then ‘τi(some T α)ϕ’ is 
I-trueσ iff  for some thing a that T I-supposits for, ‘τi(§k α) ϕ’ is I-trueσ[§k/a].
If T does not I-supposit for anything, ‘τi(some T α)ϕ’ is I-trueσ iff  ‘τi(§k α) ϕ’ is 
I-trueσ[§k/-].

completeness of the rules 
113
If T is a common term that I-supposits for something, then ‘τi(· T α) ϕ’ is I-trueσ 
iff  for some thing a that T I-supposits for, ‘τi(§k α) ϕ’ is I-trueσ[§k/a].
If T does not I-supposit for anything, ‘τi(· T α) ϕ’ is I-trueσ iff  ‘τi(§k α) ϕ’ is 
I-trueσ[§k/-].
If T is a common term that I-supposits for something, then ‘τi(no T α) ϕ’ is I-trueσ 
iff  for every thing a that T I-supposits for, it is not the case that ‘τi(§k α) ϕ’ is 
I-trueσ[§k/a].
If T does not I-supposit for anything, ‘τi(no T α) ϕ’ is I-trueσ iff  it is not the case 
that ‘τi(§k α) ϕ’ is I-trueσ[§k/-].
applications
Interpretations treat equipollent expressions equivalently. Show that the follow-
ing holds for any interpretation I:
‘not not ϕ’ is I-true if and only if ‘ϕ’ is I-true
We can now defi ne formal validity for arguments consisting of propositions, that is, of 
sentences with no temporary names.
An argument is formally valid iff  for every interpretation, I, if the premises of the 
argument are all I-true then the conclusion is also I-true.
(Th e following two sections are technical in nature; they may be skipped without loss 
of continuity. Th ey do not contain any innovative techniques.)
4.7 Completeness of the rules
Now that we have an explicit defi nition of validity, the question arises as to whether the 
rules we have proposed are adequate to provide derivations for all valid arguments. 
Completeness is the condition that all (formally) valid arguments can be shown valid 
by derivations using the rules given earlier.
Completeness: For any argument from a set of propositions Γ to a proposition ϕ, 
if the argument is valid then there is a derivation leading from Γ to ϕ (where no 
name in ϕ is introduced by rule EX).

114 
linguish
When we say that there is a derivation leading from Γ to ϕ we mean that there exists an 
actual derivation whose premises are members of Γ and which ends with the proposi-
tion ϕ (which is not within a subderivation). In this section we will use well-known 
contemporary techniques to prove that the logical system described in earlier sections 
is complete. Th e technique we will use for proving completeness was developed by the 
logician Leon Henkin in the late 1940s.
It will be useful to have some terminology. We will say that a set of sentences Γ is 
d-consistent (consistent with respect to derivability) iff  there is no proposition ϕ such 
that ‘ϕ’ is derivable from Γ and ‘not ϕ’ is also derivable from Γ. We will then prove 
a theorem from which completeness will follow:
Th eorem HMT: Th e Henkin Modeling Th eorem: If Γ is d-consistent then there 
is an interpretation I such that every sentence in Γ is I-true.
We will prove the HMT theorem, and then we will use this theorem to prove 
completeness.
Since the quantifi er equipollences are both valid and derivable, it will suffi  ce to show 
that the theorem holds for a stripped-down version of the language. In fact, using the 
equipollences we may eliminate every use of ‘·’ or ‘every’ or ‘no’ by a combination of 
‘not’ and ‘some.’ So we may concentrate on sentences where common terms T occur 
only within denoting phrases of the form ‘some T.’
Th e theorem, HMT, will be proved shortly from three lemmas. Th e fi rst lemma says 
that any d-consistent set of propositions Γ0 may be embedded in a maximal d-consistent 
set Γ with witnesses.
Lemma One: For any d-consistent set of sentences Γ0 there is a set of sentences Γ 
such that:
1. Γ0 ⊆ Γ
2. Γ is d-consistent
3. Γ is maximal, in the sense that for every proposition ϕ, either ‘ϕ’ ∈Γ or ‘not ϕ’ ∈Γ
4. Particular sentences in Γ have “witnesses”, i.e. for every sentence in Γ of the form 
‘(Some T α) ϕ,’ if ‘<T is non-empty>’ is also in Γ, there are sentences of the form 
‘(t α)(some T β) α is β’ and ‘(t α) ϕ’ in Γ. (‘t’ is called the witness for ‘(Some T α) ϕ.’)
Proof of Lemma One
We will show how, starting with a d-consistent set of sentences Γ0, we can produce a 
set Γ containing every sentence in Γ0 such that Γ satisfi es the provisions of Lemma One.
To begin, we choose an infi nite set of new names n0, n1, n2,  .  .  .  which do not occur in 
any sentence in Γ0. (Th ese names will be used to provide the witnesses just mentioned.) 
Th en we make a sequence of all sentences in the language made from the vocabulary 
of the sentences in Γ0 together with the new names n0, n1, n2,  .  .  .  Th e sequence of 
sentences will be laid out as:

completeness of the rules 
115
, 
, 
, 
, 
, 
, 
, 
, 
, 
.  .  .  .
Next, we insert a sentence in front of the sequence that says that n0 is empty:
       h,       h,       h,       h,       h,       h,       h,       h,       h,       . . . .
not (n0 α)(n0 β) α is β
Th en for each sentence in the sequence of the form ‘(some T α) ϕ’ we insert three sen-
tences right aft er it:
       h,       h,        (some T α) ϕ,           h,       h,       h,       h,       . . . .
                                 (some T α)(some T β) α is β, (nj α)(some T β) α is β, (nj α) ϕ
where nj is the fi rst of the newly introduced names which does not occur in any 
sentence in the sequence so far.
Call the sequence that results from making these changes sentences S1, S2, S3, .  .  .
 
S1 
S2 
S3 
S4 
S5 
.  .  .  .
We then make a corresponding sequence of sets of sentences Γk:
 
S1 
S2 
S3 
S4 
S5 
.  .  .  .
Γ0  Γ1  Γ2  Γ3  Γ4  Γ5  .  .  .  .
Th ese sets of sentence are constructed as follows. Th e fi rst member is our original set 
Γ0. Th en each set Γn+1 is formed as follows:
If Γn∪{Sn+1} is d-consistent, Γn+1 = Γn∪{Sn+1}
If Γn∪{Sn+1} isn’t d-consistent, Γn+1 = Γn
that is, if Sn+1 is consistent with what we have so far, we add it to what we have; otherwise 
we ignore it and go on.
applications
1. Show that for each n≥0, Γn is d-consistent.
2. Show that for each n≥0, Γn ⊆ Γn+1.
3. Show that for each n≥1, if Sn is not a member of Γn, then the negation of Sn 
is derivable from Γn.
4. Show that if Sn∈Γm for some m, then Sn∈Γn.
5. Show that if Sn is derivable from Γn−1, then Sn∈Γn.
6. Show that ‘not (n0 α)(n0 β) α is β’ is in Γ1.
Finally, let Γ be the set containing every sentence in any one of the Γn’s. Th is set of 
sentences, Γ, will satisfy the conditions of Lemma One.

116 
linguish
Proof that Γ has the properties 1–4 listed in Lemma One
1. Γ0 ⊆ Γ:
 
Proof: Th e sequence Γ0, Γ1,  .  .  .  , Γn,  .  .  .  was constructed by starting with Γ0. And 
Γ contains every sentence in any set in the sequence. So it contains all of the 
sentences in Γ0.
2. Γ is d-consistent:
 
Proof: Notice fi rst that each of the sets Γ0, Γ1,  .  .  .  , Γn,  .  .  .  is d-consistent, because 
the initial set Γ0 is d-consistent by hypothesis, and each further set is either 
the same as its predecessor, or it diff ers from its predecessor by containing 
a sentence which is d-consistent with the others. If the fi nal set Γ were not 
d-consistent then for some sentence S you could derive both ‘S’ and ‘not S’ from 
Γ. Th e derivation itself would be fi nite, so it would use only a fi nite number of 
sentences from Γ as premises. So there would be some set Γn that contains all of 
the premises. But that Γn is d-consistent, so there isn’t any such derivation.
3. Γ is maximal, in the sense that for every proposition ‘ϕ,’ either ‘ϕ’∈Γ or ‘not 
ϕ’∈Γ: Proof: Suppose not. Th en for some sentence ‘ϕ,’ neither ‘ϕ’ nor ‘not ϕ’ is 
in any Γn. Now for some integers n and m, ‘ϕ’ is Sn and ‘not ϕ’ is Sm. Since ‘ϕ’ is 
not in Γ, that means that Sn was not added to Γn−1 when forming Γn. So Sn is not 
d-consistent with Γn−1. But then its negation, namely ‘not ϕ’ is derivable from 
Γn−1, and thus from Γ.
 
Similarly, the negation of Sm, namely ‘ϕ,’ is derivable from Γm−1, and thus from Γ.
 
Since both ‘not ϕ’ and ‘ϕ’ are derivable from Γ, Γ isn’t d-consistent, contrary to 
what was proved earlier.
4. Particular sentences in Γ have “witnesses”; that is, for each sentence in Γ of the 
form ‘(Some T α) ϕ,’ if ‘<T is non-empty>’ is also in Γ, there are sentences of the 
form ‘(nj α)(some T β) α is β’ and ‘(nj α) ϕ’ is in Γ.
 
Proof: Suppose that ‘(Some T α) ϕ’ is in Γ and that ‘<T is non-empty>’ is also in Γ. 
Let Sn be the earliest occurrence of ‘(Some T α) ϕ’ in the sequence S1, S2,  .  .  .  Th en 
‘(Some T α) ϕ’∈Γn. By construction of the sequence, ‘<T is non-empty>’ is Sn+1 
and so ‘<T is non-empty>’∈Γn+1. By rule EX, both ‘(nj α)(some T β) α is β’ and 
‘(nj α) ϕ’ are derivable from Γn+1, and so they will be members of Γn+2 and Γn+3, 
which means that they will both be members of Γ.
Th is concludes Lemma One.
applications
7. Show that for any subset Δ of Γ, if ϕ is derivable from Δ then ϕ∈Γ.
Lemma Two: We now construct a certain useful interpretation I for the language. To 
assist us in this, we fi rst defi ne what we mean by a name-set.

completeness of the rules 
117
For each name ‘n’ let ‘[n]’ be the set of all names ‘m’ in the language which appear 
in a sentence in Γ of the form ‘(m α)(n β) α is β.’ Call any such set a name-set. 
If a name ‘n’ does not appear in a sentence in Γ of the form ‘(m α)(n β) α is β,’ 
then [n] will be empty. Otherwise [n] will contain ‘n’ itself, typically together with 
other names.
applications
10. Show that ‘(n α)(m β) α is β’ is I-true in this interpretation if and only if ‘n’ 
and ‘m’ have the same non-empty name-set.
11. Show that ‘(n α)(m β) α V β’ is I-true if and only if ‘V’ holds of <[m],[n]>.
applications
8. Show that if [n] is not empty, then n is a member of [n].
9. Show that these are all equivalent:
‘(m α)(n β) α is β’ is in Γ
‘(m α)(n β) β is α’ is in Γ
‘(n α)(m β) α is β’ is in Γ
‘(n α)(m β) β is α’ is in Γ
To say what I is, we need only say how it interprets the terms and how it interprets 
the verbs.
Interpretation of the terms:
Singular terms: Each singular term ‘n’ is to I-supposit for its own name-set [n] if [n] 
is non-empty; otherwise ‘n’ is to I-supposit for nothing.
Common terms: Any common term ‘T’ is to I-supposit for each name-set u such 
that for some name ‘n’ ∈ u, the sentence ‘(n α)(some T β) α is β’ is a member of Γ.
Interpretation of the verbs:
Each verb ‘V’ that takes a single grammatical marker I-holds of a non-empty name-
set u if and only if there is some name ‘n’ in u such that ‘(n α) α V’ is a member of Γ.
Each verb ‘V’ that takes two grammatical markers I-holds of a pair of non-empty 
name-sets <u, v> if and only if there are names ‘n’∈u and ‘m’∈v such that ‘(n α)(m β) 
α V β’ is a member of Γ.

118 
linguish
Th is completes the specifi cation of I, and thus of Lemma Two.
Lemma Th ree: A sentence S is I-true iff  S is a member of Γ.
Note that the permutations of singular terms, and double negation hold both 
semantically, and by means of rules of inference. Th ese will be taken for granted. Also, 
because of consistency and maximality, if Lemma Th ree holds for ‘S’ it also holds for 
‘not S.’ Th is will be taken for granted later.
applications
12. Show that if a sentence S is I-true iff  S is a member of Γ, then not S is I-true 
iff  not S is a member of Γ.
Th e proof of the lemma proceeds by induction on the number of common terms in S. 
First we show (the “basis step”) that the lemma holds for all sentences that contain 
no common terms. Th en we show (the “induction step”) that if the lemma holds 
for all sentences with k or fewer common terms, then it holds for all sentences with 
k+1 common terms.
Basis Step: Th ere are no common terms in S.
Form with no negations: Suppose that S is of the form ‘(n α)(m β) α V β.’
Case 1: Suppose that ‘n’ and ‘m’ both I-supposit for something. Th en:
‘(n α)(m β) α V β’ is I-true
   iff  
<TRUTH>
for any σ, ‘(n α)(m β) α V β’ is I-trueσ
   iff  
<SINGULAR DP>
for any σ, ‘(§1 α)(§2 β) α V β’ is I-trueσ[§1/a] [§2/b] where a and b are what ‘n’ and ‘m’ 
I-supposit for
   iff  
<TERMS>
for any σ, ‘(§1 α)(§2 β) α V β’ is I-trueσ[§1/[n]] [§2/[m]]
   iff  
<ATOMIC>
for any σ, ‘V’ I-holds of <σ[§1/[n]][§2/[m]](§1), σ[§1/[n]][§2/[m]](§2)>
   iff  
<DEFINITION OF NOTATION>
for any σ, ‘V’ I-holds of <[n], [m]>
   iff  
<REDUNDANT QUANTIFIER>
‘V’ I-holds of <[n], [m]>
   iff  
<CONSTRUCTION OF I – application 11 above>
‘(n α)(m β) α V β’ is in Γ
(Recall that when I was constructed we made any two-place verb I-hold of the pairs of 
name-sets of names that occur with the verb in a sentence in Γ.)
Case 2: Suppose that ‘n’ or ‘m’ I-supposits for nothing.

completeness of the rules 
119
Th en ‘(n α)(m β) α V β’ is not I-true.
To show that ‘(n α)(m β) α V β’ isn’t a member of Γ:
For reductio, suppose that it is a member. Since it entails ‘<n is non-empty>’ and 
‘<m is non-empty>’ they too are in Γ. But then the name-sets for ‘n’ and ‘m’ aren’t 
empty, and so neither ‘n’ nor ‘m’ I-supposits for nothing, as was assumed.
In summary, if ‘n’ and ‘m’ both I-supposit for something, then ‘(n α)(m β) α V β’ is 
I-true iff  ‘(n α)(m β) α V β’ is in Γ.
And if either ‘n’ or ‘m’ I-supposit for nothing then ‘(n α)(m β) α V β’ isn’t I-true and 
also it isn’t in Γ, so again ‘(n α)(m β) α V β’ is I-true iff  ‘(n α)(m β) α V β’ is in Γ.
Negative form: As noted previously, if the lemma holds for S, it also holds for not-S.
Because of double negation and the permutations, any logical form that contains 
exactly two singular terms is equivalent to another form that either contains no 
negations, or contains a single negation on the front. So the lemma holds of every 
formula which contains no common terms and contains two singular terms.
It is easy to also prove the lemma for the case in which the formula contains exactly 
one singular term and no common terms.
applications
13. Show that the lemma holds when S is of the form ‘(n α) α V.’
Induction Step: Assume that Lemma Th ree is true for sentences containing ≤k com-
mon terms. (Th is is the “inductive hypothesis.”) Show that it is true for any 
sentence with k+1 terms.
(So far in this text we have only discussed sentences with at most two common 
terms. But later on we will extend the notation so that a sentence may contain any 
number of common terms. We give an argument here that can be extended later when 
additional vocabulary and syntactic structures are added.)
We may assume that there is a common denoting phrase to the left  of all other 
denoting phrases, since the only other alternative is for a singular denoting phrase 
to come fi rst, and it may be permuted to the right. So S is of the form ‘(some P α) ϕ’ or 
‘not (some P α) ϕ.’ If we prove the lemma for the fi rst form, then by consistency and 
maximality it will hold for the second form as well. We will fi rst show
I. if  ‘(some P α) ϕ’ is in Γ, it is I-true,
and then we will show
II. if  ‘(some P α) ϕ’ is I-true, then it is in Γ.
I. Suppose that ‘(some P α) ϕ’ is in Γ. To show that ‘(some P α) ϕ’ is I-true.

120 
linguish
By the construction of Γ, ‘(some P α) ϕ’ is Sn for some n, and ‘<P is non-empty>’ 
is Sn+1, followed by ‘(nj α)(some P β) α is β’ and then by ‘(nj α) ϕ.’ Th ere are two cases to 
consider:
Case 1: ‘<P is non-empty>’ is added to Γn+1 and is in Γ. By section 4 of the proof of 
Lemma 1, ‘(nj α)(some P β) α is β’ and ‘(nj α) ϕ’ are also in Γ. By the construction in 
Lemma 2, since ‘(nj α)(some P β) α is β’ is in Γ, ‘P’ I-supposits for [nj], and thus ‘(nj α)
(some P β) α is β’ is I-true. Since ‘(nj α) ϕ’ is in Γ and ‘(nj α) ϕ’ has fewer common terms 
than ‘(some P α) ϕ,’ by the inductive hypothesis, ‘(nj α) ϕ’ is I-true. Since ‘(nj α)(some 
P β) α is β’ and ‘(nj α) ϕ’ are both I-true, so is ‘(some P α) ϕ.’
Case 2: ‘<P is non-empty>’ is not added to Γn+1 and thus is not in Γ. Th en by 
maximality ‘not <P is non-empty>’ is in Γ. Notice that ‘not <n0 is non-empty>’ is 
also in Γ. By the principle of substitution of empties, ‘(some P α) ϕ’ together with the 
emptiness of both ‘P’ and ‘n0’ entails ‘(n0 α) ϕ,’ which is thus in Γ. Th is has fewer com-
mon terms than ‘(some P α) ϕ,’ and so by the inductive hypothesis ‘(n0 α) ϕ’ is I-true.
Now ‘not <P is non-empty>’ must also be I-true, because otherwise ‘P’ would 
I-supposit for something of the form [u]; so by construction of I, a sentence of the 
form ‘(some P α)(u β) α is β’ would be in Γ, which would entail ‘<P is non-empty>,’ 
contradicting the fact that ‘<P is non-empty>’ is not in Γ.
Since ‘not <n0 is non-empty>’ has no common terms, by the inductive 
hypothesis, it is also I-true. But then these are all I-true:
not <P is non-empty>
not <n0 is non-empty>
(nj α) ϕ
and so by the substitutivity of empties, ‘(some P α) ϕ’ is I-true.
II. Suppose that ‘(some P α) ϕ’ is I-true. To show that ‘(some P α) ϕ’ is in Γ.
Now ‘P’ may or may not I-supposit for something. Th ere are two cases to consider:
Case 1: ‘P’ I-supposits for something.
By our semantic theory we have:
‘(some P α) ϕ’ is I-true
   iff  
<TRUTH>
For every σ, ‘(some P α) ϕ’ is I-trueσ
   iff  
<COMMON DP <non-empty case>>
For every σ, for some name-set [v] for which ‘P’ I-supposits, ‘(§1 α) ϕ’ is I-trueσ[§1/[v]]
   iff  
<since ‘v’ I-supposits for [v]>
For every σ, for the name-set [v] for which ‘v’ I-supposits, ‘(§1 α) ϕ’ is I-trueσ[§1/[v]]
   iff  
<SINGULAR DP <non-empty case>>
For every σ, ‘(v α) ϕ’ is I-trueσ
   iff  
<TRUTH>
‘(v α) ϕ’ is I-true

completeness of the rules 
121
So ‘(v α) ϕ’ is I-true, where ‘P’ I-supposits for ‘[v].’
By the inductive hypothesis, ‘(v α) ϕ’ is in Γ.
Since ‘P’ I-supposits for [v], by the construction of I, ‘(some P α)(v β) α is β’ is in Γ.
By maximality and consistency, ‘(v β)(some P α) α is β’ is also in Γ.
Th en by the semantic version of rule ES, ‘(some P α) ϕ’ is in Γ.
Case 2: ‘P’ does not I-supposit for anything.
Notice fi rst that ‘not <P is non-empty>’ is in Γ, since other wise ‘<P is non-empty>’ 
would be in Γ, and since this is an existentially quantifi ed sentence, ‘(some P α)
(some P β) α is β,’ it would have a witness in Γ of the form ‘(nj α)(some P β) α is β,’ 
and then by the construction of I, ‘P’ would I-supposit for [nj], contrary to the 
assumption of Case 2.
Now by our semantic theory we have:
‘(some P α) ϕ’ is I-true
   iff  
<TRUTH>
For every σ, ‘(some P α) ϕ’ is I-trueσ
   iff  
<COMMON DP <empty case>>
For every σ, ‘(§1 α) ϕ’ is I-trueσ[§1/[-]]
   iff  
<SINGULAR DP <empty case>>
For every σ, ‘(n0 α) ϕ’ is I-trueσ
   iff  
<TRUTH>
‘(n0 α) ϕ’ is I-true
So ‘(n0 α) ϕ’ is I-true.
By the inductive hypothesis, ‘(n0 α) ϕ’ is in Γ.
So then these are all in Γ:
not <P is non-empty>
not <n0 is non-empty>
(n0 α) ϕ
and so by the rule of substitutivity of empties, ‘(some P α) ϕ’ is also in Γ.
Th is completes the proof of HMT. We may now proceed to prove the Completeness 
Th eorem.
Completeness Th eorem: For any argument from a set of propositions Γ to a pro-
position ϕ, if the argument is valid then there is a derivation leading from Γ to ϕ (where 
no name in ϕ is introduced by rule EX).
Proof: We will show this using a reductio argument. Suppose that completeness does 
not hold, that is, there is an argument from some set of sentences Γ to a sentence ϕ that 
is valid, but there is no derivation of ϕ from Γ. Th en we can show that Γ ∪ {not ϕ} must be 
d-consistent. (Γ ∪ {not ϕ} is the set containing every sentence in Γ and also containing 
‘not ϕ.’) Th is is so because if Γ ∪ {not ϕ} were not d-consistent, one could derive contra-
dictory propositions from Γ ∪ {not ϕ}. Th at is, there would be a derivation of the form:

122 
linguish
Γ
not ϕ
S
not S
But then one could rearrange the parts of that derivation as follows:
Γ
ϕ
Reductio
not ϕ
S
not S
Th e subderivation is to consist of exactly the same sentences as the whole derivation 
earlier. Th is reasoning is justifi ed because when applying our rules of inference, it doesn’t 
matter whether ‘not ϕ’ is an original premise or the assumption of a subderivation. Th e 
result then is a subderivation leading from ‘not ϕ’ to contradictory propositions, and so 
our reductio rule lets us add ‘ϕ’ following the subderivation. Th e result is a derivation 
leading from Γ to ‘ϕ,’ contradicting our assumption that there is no such derivation.
So Γ ∪ {not ϕ} is d-consistent. But then by the HMT theorem there is a interpre-
tation I such that every sentence in Γ ∪ {not ϕ} is I-true. But this is an interpretation I 
in which every sentence in Γ is I-true and ϕ is not I-true. So by the defi nition of validity, 
the argument from Γ to ϕ is not valid, contradicting the assumption we made at the 
beginning of the original reductio argument.
So the Completeness Th eorem is proved.

adjectives 
123
5
Expanding the Notation
In the previous chapter a notation, Linguish, was devised. It is intended to be a per-
spicuous presentation of the grammatical structures of the sentences that medieval 
logicians dealt with. It encodes only information clearly available to medieval writers. 
Th e fundamental rules of inference that were included are confi ned to rules that were 
explicitly stated in the literature, or were clearly expressed (with the possible exception 
of Aristotle’s use of exposition applied to a negative proposition). Truth conditions 
were stated using modern techniques, but the inputs to the provisions used (in terms 
of the signifi cations and suppositions of terms) are those of the medievals, and the 
outputs are intended to match the truth conditions of those propositions that were 
explicitly discussed.
Medieval logicians make free use of forms of language that go far beyond those generated 
in the previous chapter. Th e goal of this chapter is to expand the notation to include 
some of these rich forms, and to add rules of inference to govern them. Th e notation 
continues to encode only grammatical information available to medieval logicians. 
Th e rules will sometimes go beyond those that were stated by the authors, and this will 
need discussion. Th e truth conditions, though expressed using modern notation, are 
still intended to agree with those attributed to propositions by the authors.
In this chapter we continue to focus on non-modal present tense propositions, leaving 
additional complications to Chapter 10.
5.1 Adjectives
Aristotle’s logic is problematic when applied to propositions that have adjectives as 
predicates. If you apply simple conversion to:
Some donkey is grey
you get
Some grey is [a] donkey
which, according to some authors, is ungrammatical; a quantifi er word like ‘some’ must 
combine with a noun, not with an adjective like ‘grey.’1
1 Buridan SD 4.2.6: “in a conversion the subject should become the predicate and the predicate should 
become the subject, and an adjective cannot become the subject in itself, unless it gets substantivated.”

124 
expanding the notation
Th is problem has a straightforward solution. In Latin it is possible to “substantivate” 
an adjective, which is to use it as a common noun.2 (Some authors hold that when this 
is done, the new noun ends up with a neuter gender, but this idea does not seem to be 
universal.) For example, the earlier sentence:
Some donkey is grey
contains the adjective ‘grey’ which, in this sentence, would bear a singular nominative 
masculine infl ection to agree with ‘donkey.’ But in this sentence:
Every grey is tired   (Meaning ‘Every grey thing is tired.’)
it is substantivated; it bears a neuter infl ection of its own, and it is essentially a noun. 
Th e adjective ‘tired’ is still an adjective; it has an adjectival infl ection that agrees with 
the case and number of ‘grey.’
Since substantivated adjectives literally are nouns, they are already automatically 
included in the language we have developed. To make this clear, I will append ‘-thing’ 
to each adjective used substantivally in the logical notation, with the understanding 
that the result is a common term.3 In Latin the appended ‘-thing’ is invisible; the 
status of a term as a noun is understood by means of the fact that the word takes 
the infl ections of a noun. In English the ‘thing’ is needed to produce a (complex) noun. 
Th e logical form:
(Every grey-thing α)(·donkey β) α is β
yields the proposition:
Every grey-thing a donkey is   or  Every grey-thing is a donkey
What about adjectives that occur alone in predicate position? A proposition with an 
adjectival predicate is logically equivalent to the same proposition with the adjective 
substantivated. Th is is forced on us by the fact that particular propositions with adjec-
tives as predicates are said to undergo simple conversion, with the understanding that 
the adjectives are converted to their substantivated forms. Th us ‘Some donkey is grey’ 
converts to ‘Some grey-thing is [a] donkey.’ But ‘Some grey-thing is [a] donkey’ is itself 
a particular affi  rmative proposition, which in turn automatically converts to ‘Some 
donkey is [a] grey-thing.’ So the form with the adjective in the predicate is logically 
equivalent to that with the substantivated adjective in the subject, and the form with the 
2 Th is is not to be confused with the common(er) practice in Latin of using adjectives (with adjectival 
infl ections) without an accompanying noun when the missing noun is “understood” from context. For logical 
purposes understood nouns need to occur overtly in logical forms.
3 Regarding the use of ‘thing,’ Buridan SD 4.2.2 says: “an adjective substantivated [by being put] in the 
neuter gender can be a subject, for it is resolved into an adjective and a substantive, e.g., ‘white’ [album] 
means the same as ‘white thing’ [res alba].”

adjectives 
125
substantivated adjective in the subject is equivalent to the form with the substantivated 
adjective in the predicate. Th us the form with the adjective in the predicate must be 
equivalent to the form with that adjective substantivated in the predicate. (Th e use of 
the substantivated form of the adjective in predicate position would be unusual in 
Latin, but not ungrammatical.)
We can exploit this equivalence to generate un-substantivated adjectives that occur 
with ‘is’ by allowing Linguish logical forms to generate both ‘is ADJ’ and ‘[an] ADJ-
thing is,’ where the second ‘is’ is the same copula that occurs in all of our previous forms. 
Th is equivalence will hold in both Latin and English. Th us, these are equivalent:
(Socrates α) α is healthy
Socrates is healthy
(Socrates α)(· healthy-thing β) α is β
Socrates a healthy-thing is
Socrates is a healthy-thing
(Later we will discuss how to treat adjectives that appear in attributive position modify-
ing nouns.)
Adjectival common terms
For each ordinary4 adjective α, α-thing is a common term. It signifi es (at a time) 
whatever is α at that time.5
In transition to natural language, the ‘thing’ is pronounced in English, but 
omitted in Latin; instead, the adjective is given nominal infl ections.
We should also have an explicit rule of inference connecting the adjectival form with 
the associated common term:
Rule Adj
Th e forms: α is Adj and (· Adj-thing β) α is β are interchangeable everywhere
E.g. Socrates is clever if and only if Socrates is a clever-thing.
4 As a rough guide, an “ordinary” adjective is one whose meaning can be analyzed along the patterns 
of Aristotle’s Categories, such as ‘x is yellow’ ≈ ‘a yellowness is in x.’ Th ese are all “intersective” in the current 
linguistic sense. Th e adjective ‘former’ is an example of an adjective that does not pass this test.
5 Th is condition on signifi cation is probably inadequate for the semantics of modal contexts. See 
Chapter 10 for a discussion of problems.

126 
expanding the notation
5.2 Intransitive verbs
Intransitive verbs appear in sentences in two ways. We have already seen that 
logicians were comfortable using them, as in ‘Brownie runs.’ But they also appear 
as common terms. Th is stems from the common view that there is really only one true 
verb, and that is the copula. So sentences that have other verbs must be analyzed 
in such a way that the apparent verb is really a combination of the copula with a 
common term. In particular, several medieval logicians hold that the use of an intran-
sitive verb is equivalent to the use of the copula along with its present participle. 
For example, they say that ‘Brownie runs’ is equivalent to ‘Brownie is running.’ At least, 
this is how the proposal sometimes appears in English, because people sometimes 
translate the Latin examples word for word. But the normal way to understand the 
English sentence ‘Brownie is running’ is that it contains the verb ‘run’ in its present 
progressive form: ‘run’ ⇒ ‘is running,’ meaning that Brownie is engaged in the process 
of running. But that is not what the medieval authors intend. Th ere is no way to 
understand in Latin the combination of the copula with a participle of a verb as 
a progressive form of the verb because verbs do not have progressive forms in Latin. 
Instead, what the authors intend is a form of the copula followed by a common term 
in participle form. So a better English translation is ‘Brownie is a running-thing.’ 
Th is seems not to be common Latin usage, but it is what many logicians insisted 
on, and I will go along with this. As a result, if you want to treat a sentence with an 
intransitive verb, you can take its form to be that of the copula followed by the verb’s 
applications
For each of the following arguments, represent the argument in Linguish notation 
and show that it is valid.
 
Socrates is tall
∴ A tall thing is Socrates
 
Some donkey is tall
∴ Some donkey is a tall thing
 
Some tall thing is grey
∴ Some grey thing is tall
 
Every donkey is grey
∴ Every donkey is a grey thing

intransitive verbs 
127
present participle used as a common term.6 Since present participles are adjectives 
in Latin, they can be substantivated and used as nouns. Th at is what happens here.7 
So we again have a procedure for applying the existing formal theory to a new class 
of items. We treat these uses of Latin participles as nouns (‘running-thing’):
(Brownie α)(· running-thing β) α is β
Brownie [a] running-thing is
Brownie is a running thing
Participles of intransitive verbs
Any present participle of an intransitive verb followed by ‘-thing’ is a common 
term. It supposits for whatever the verb itself is true of.
In transition to natural language, the ‘thing’ is pronounced in English, but 
omitted in Latin; instead, the participle is substantivated.
Other examples:
(no stone α)(· speaking-thing β) α is β
no stone is a speaking thing
(no creature α)(· creating-thing β) α is β
no creature is a creating thing
In order to make a logical transition between the two ways in which an intransitive 
verb is used, we need to add a rule of inference for each intransitive verb that is used 
in this way.
6 Paul of Venice LP 1.6 (5). “A categorical proposition is one which has a subject, a predicate and a copula 
as its principle parts, e.g., ‘a man is an animal,’ ‘man’ is the subject; ‘animal’ is the predicate, and the copula is 
always that verb ‘is’ because it conjoins the subject with the predicate. And if someone says ‘a man runs’ 
(homo currit) is a categorical proposition but it does not have a predicate, it can be replied that it has 
an implicit predicate, viz., ‘running.’ Th is is clear by analyzing that verb ‘runs’ into ‘I am,’ ‘you are,’ ‘it is’ and 
its participle.”
Buridan S.D.1.3.2 (23): “to make the subject, predicate and copula explicit, such a verb has to be analyzed 
into the verb ‘is’ as third adjacent, provided that the proposition is assertoric and in the present tense, 
and into the participle of that verb, as for example, ‘A man runs’ is to be analyzed into ‘A man is running,’ and 
similarly, ‘A man is’ into ‘A man is a being.’ ”
Albert of Saxony SL 3.1: “a categorical proposition is one which has a subject and a predicate and copula as 
its principal components. Against this it might be objected that there are many propositions which have only 
a subject and a predicate, and no copula, such as the sentence ‘Man runs’.  .  .  .  To this we reply that although 
they do not have an explicit copula, they do have it implicitly. Th us the verb ‘runs,’ and in general any active 
verb, includes in it a participle of present time along with a copula—as is seen when we analyze this sentence 
‘Man runs’ into this ‘Man is running.’ ”
7 Albert of Saxony SL 1.5 (5): “And the participle is also treated as a noun, and not as a verb, because the 
participle is never the copula in the logical sense, but it can very well be a subject or a predicate.”

128 
expanding the notation
Special rule of inference for intransitive verbs
Th e forms: α VERBs and (· VERBing-thing β) α is β are interchangeable.
Th is lets us prove the equivalence of the logical forms underlying:
no stone is a speaking thing 
≈ 
no stone speaks
no creature is a creating thing 
≈ 
no creature creates
Once participles appear as common terms, they can be used anywhere in a sentence 
that a common noun can be used. So there are sentences such as these:
(no speaking-thing α) α runs
No speaking thing runs
(every speaking-thing α) α moves
Every speaking thing moves
applications
For each of the following arguments, represent the argument in Linguish notation 
and show that it is valid.
 
Socrates doesn’t speak
∴ Socrates isn’t a speaking thing
 
Some donkey speaks
∴ Some speaking thing is a donkey
 
Some speaking thing runs
∴ Some running thing speaks
 
Every donkey speaks
∴ Every donkey is a speaking thing
5.2.1 Being
Some authors extended this idea to analyze propositions of the form ‘Socrates is’ or 
‘a donkey is.’ Th ey took this use of ‘is’ to be like the use of an intransitive verb, to be 
analyzed in terms of a copula together with the present participle of the (“intransitive”) 
verb ‘is,’ namely ‘being.’ Since that participle already occurs as a noun, the natural analysis 
of ‘Socrates is’ is ‘Socrates is [a] being.’
(Instead of the view just mentioned, some authors held that ‘Socrates is’ means 
‘Socrates is a thing.’ Still others were said to hold the view that ‘Socrates is’ means 

transitive verbs 
129
‘Socrates is Socrates’.8 It would be neat to appeal to this last view to replace the artifi cial 
notation ‘<t is non-empty>’ by ‘(t α) α is.’ However, that would be to take sides on 
a controversial issue.)
Independent of how to analyze ‘α is,’ the noun ‘being’ was widely discussed. It seems 
to be taken to be the most unrestricted noun which signifi es everything, including 
both God and creatures. Given its use, it is apparent that if ‘donkey’ is non-empty then 
‘every donkey is a being’ is true. I will take this for granted.9 However, we will not make 
any use of it before Chapter 10.
5.3 Transitive verbs
So far, we have been able to include adjectives and intransitive verbs without putting 
anything new into the logical notation (except for the ‘-thing’ on the end of adjectives, 
which has no logical eff ect at all). One naturally wonders if the same kind of paraphrase 
is available with transitive verbs. Transitive verbs have present participles just as 
intransitive verbs do—so one could replace a transitive verb with the copula and its 
participle and proceed as previously. And indeed, some medieval logicians do so. For 
example, Buridan (SD 1.3.3) discusses this example:
Every horse [a] man is seeing
where we have the participle of a transitive verb. If we treat the participles of transitive 
verbs just like those of intransitives, then a complication needs to be addressed: the 
verb is ‘is,’ and it provides grammatical roles for two terms, as usual. However, there are 
three terms in this proposition: ‘horse,’ ‘man,’ and ‘seeing.’ Th e solution is to suppose that 
the participle of a transitive verb itself provides a grammatical role: the role of direct 
object of the participle. Th e participle ‘seeing’ has a direct object just as much as ‘see’ 
does. (Th is is clear in the example from Buridan, for ‘horse’ has accusative case there, 
because of its being the object of the participle.) And something like this seems to be 
what Buridan has in mind, because he says (S.D. 1.3.3, 28) “ ‘horse’ is construed with 
‘seeing’ to make one extreme of the proposition.” In order to accommodate this idea 
with our present technique of using markers to indicate grammatical relations, we 
need to include a grammatical marker along with each participle of a transitive verb. 
(Intuitively, this is the “same” grammatical marker that would occur aft er the verb itself 
if it appeared in its verbal form.) It is heuristic to put that marker immediately aft er 
the participle. So take the sentence ‘Cicero sees a donkey,’ and represent it as suggested, 
to get:
8 See Andrews 1993, 8.
9 How singular terms interact with ‘being’ depends on the decision, discussed in section 4.3, of whether a 
singular term that signifi es something that does not presently exist supposits for that thing in a present tense 
sentence, or not. If so, then if a singular term such as ‘Brownie’ is non-empty, then ‘Brownie is a being’ will be 
true or false depending on whether Brownie currently exists; if not, ‘Brownie is a being’ will be true exactly 
when ‘Brownie’ is non-empty. Th ese will usually be equivalent.

130 
expanding the notation
(Cicero α)(· donkey β)(· seeing-β-thing γ) α is γ
Cicero of-a donkeyacc a seeing thing is
Cicero of-a donkeyacc is a seeing thing
Cicero is of-a donkeyacc a seeing thing
Th e term whose denoting phrase binds a marker in a transitive-verb participle gets an 
accusative ending in Latin because its grammatical role is direct object of the participle. 
I have also introduced the preposition ‘of ’ in front of the denoting phrase which is the 
object of the participle because that preposition is oft en used in English for the direct 
object of a verb when the verb itself is present in a non-verb form, for example in ‘the 
destruction of the city,’ where ‘the city’ is understood to be the direct object of ‘destroy.’ 
Th is is for readability only, and it may be ignored if it is not helpful.
Call a term that incorporates a variable as just described a “parasitic” term, since what 
it supposits for depends on the denoting phrase occupying the role that it provides.
Parasitic terms (participles of transitive verbs)
If ‘V’ is a transitive verb, then ‘Ving-α-thing’ is a common term.
It goes into propositions where common terms go (understanding that when 
a denoting phrase containing it is added to a formula, the role marker ‘α’ does 
not already occur in that formula).
In context, when we specify what a parasitic term supposits for we must do so relative 
to something else. For example, we will say that ‘seeing-α-thing’ supposits for a thing o 
relative to a thing o′ if and only if o sees o′.
Supposition for parasitic terms: Participles of transitive verbs
Th e term ‘Ving-α-thing’ supposits for a thing o relative to o′ iff  ‘V’ holds of 
<o, o′>
Th en we need to see how this fi ts into the recursive semantics. It will be relevant in a case 
in which it is the main term of the fi rst denoting phrase not containing a temporary 
name, but where some preceding temporary name binds the role marker provided 
with the participle. Here is an example when the quantifi er sign is ‘some.’
‘τj(§n α)τk (some Ving-α-thing β) φ’ is trueσ iff  for some thing o such that ‘Ving-α-
thing’ supposits for o relative to σ(‘§i’), ‘τj τk (§i β) φ’ is trueσ[‘§i’/o], where ‘§i’ is the 
fi rst temporary name not occurring in ‘τj(§n α)τk’
If ‘V’ supposits for nothing relative to σ(‘§i’), replace ‘trueσ[‘§i’/o]’ by ‘trueσ[‘§i’/-].’

transitive verbs 
131
Th e earlier example is:
(Cicero α)(· donkey β)(· seeing-β-thing γ) α is γ
Cicero of-a donkeyacc a seeing thing is
Th is logical form is built up in stages, where each addition of a denoting phrase binds 
a grammatical marker that is free in the formula it is added to. Th e formula then says:
Cicero is a thing x such that a donkey is a thing y such that a thing z which sees y is x
For another example, consider the proposition:
(Every woman α)(Brownie β)(· seeing-β-thing γ) α is γ
Every woman is of-Brownieacc a seeing thing
Th is has the following truth conditions:
   ‘(Every woman α)(Brownie β)(· seeing-β-thing γ) α is γ’ is trueσ
iff  (supposing that ‘woman’ is not empty) for any thing w such that w is a woman,
   ‘(§1 α)(Brownie β)(· seeing-β-thing γ) α is γ’ is trueσ[§1/w],
iff  for any thing w such that w is a woman, for the thing b which is Brownie:
   ‘(§1 α)(§2 β)(· seeing-β-thing γ) α is γ’ is trueσ[§1/w][§2/b],
iff  for any thing w such that w is a woman, for the thing b which is Brownie, for a thing 
s such that ‘seeing-β-thing’ suppositsσ[§1/w][§2/b] for s relative to σ[§1/w][§2/b](‘§2’):
   ‘(§1 α)(§3 γ) α is γ’ is trueσ[§1/w][§3/s].
iff  for any thing w such that w is a woman, for the thing b which is Brownie, for 
a thing s such that ‘sees’ holds of <s, σ[§1/w][§2/b](‘§2’)>:
   ‘(§1 α)(§3 γ) α is γ’ is trueσ[§1/w][3/s].
iff  for any thing w such that w is a woman, for the thing b which is Brownie, for 
a thing s such that s sees b:
   ‘(§1 α)(§3 γ) α is γ’ is trueσ[§1/w][3/s].
iff  for any thing w such that w is a woman, for the thing b which is Brownie, for 
a thing s such that s sees b, ‘is’ holds of the pair of things:
   <σ[§1/w][§3/s](‘§1’), σ[§1/w][§3/s](‘§3’)>.
iff  for any thing w such that w is a woman, for the thing b which is Brownie, for 
a thing s such that s sees b, ‘is’ holds of the pair of things:
   <w, s>
iff  for any thing w such that w is a woman, for the thing b which is Brownie, for 
a thing s such that s sees b: w = s.

132 
expanding the notation
Th is then is logically equivalent to:
iff  for any thing w such that w is a woman, for the thing b which is Brownie, w sees b.
or
iff  for any thing w such that w is a woman, w sees Brownie.
Th is seems to be the right truth conditions for the sentence ‘Every woman is of-Brownieacc 
a seeing thing.’
As with participles of intransitive verbs, we need to include a rule of inference to link 
uses of the verb with uses of its participle. Th e obvious condition is:
Participles of transitive verbs: Interchange rule
Th e forms: (· Ving-β-thing γ) α is γ and α V β are interchangeable everywhere.
As with participles of intransitive verbs, participles of transitive verbs can occur with 
other quantifi ers, as in:
Of-every donkeyacc a seeing thing is a horse
meaning that for each donkey, something seeing it is a horse. Or:
A donkeyacc every seeing thing sees a horse
meaning that there is a donkey such that everything seeing it sees a horse.
Notice that we continue with a logical development that is consistent with, though 
not committed to, the view that there is only one “real” verb, namely ‘is.’
applications
Take each of the following sentences and generate its equivalent form that 
contains no verb other than the copula.
No animal sees Socratesacc
Some donkey sees every horseacc
Every bird sees every birdacc
Generate these sentences from their logical forms.
Of Socratesacc no seeing thing runs
Of every donkeyacc some seeing thing is an orating thing
For each of the following arguments, represent the argument in Linguish notation 
and show that it is valid.

additional rules for parasitic terms 
133
5.4 Additional rules for parasitic terms
With parasitic terms added, we need our rules of inference to accommodate them. 
Some rules require no changes at all; for example, the quantifi er equipollence rules 
already apply to sentences involving parasitic terms, because parasitic terms are com-
mon terms. Th e changes that are needed are due to the fact that a parasitic term carries 
a free marker along with it, and thus no denoting phrase with a parasitic term can be 
the initial denoting phrase in a sentence. But several of our rules are explicitly formu-
lated in terms of denoting phrases that appear on the front of a proposition. Th ese rules 
must be adapted so as to apply somehow to a proposition which has a parasitic term 
occurring second, preceded by a singular term. For example, we should be able to vali-
date this inference, which resembles simple conversion:
An animal is of-Socratesacc a seeing thing 
<An animal is a Socrates seer>
∴ of-Socratesacc a seeing thing is an animal  <A Socrates seer is an animal>
Th e obvious way to do this is with a proof like this:
(· animal α)(Socrates β)(· seeing-β-thing γ) α is γ
(n α)(· animal β) α is β
(n α)(Socrates β)(· seeing-β-thing γ) α is γ
(Socrates β)(· seeing-β-thing γ)(· animal α) α is γ
1.
2.
3.
4.
1 EX
1 EX
2 3 ES ?????
Th is would be straightforward if the combination of the singular term, ‘Socrates’ with 
the denoting phrase ‘a seeing-thing’ were itself a common term. Is it? Th e answer seems 
to be that given the freedom of Latin word order, and given the practices of medieval 
logicians, it is possible to treat ‘Socratesacc seeing thing’ as a single complex common 
term, and it is also possible to treat it as a string of two grammatically related terms. 
Based on the logical form, it consists of two separate terms. In the next section we will 
show how this form is equivalent to one consisting of a single complex term. (Th is will 
be the rule Complex Term 2 in section 5.5.2.) Th at equivalence will allow us to com-
plete the derivation just given. Th at will have to await the construction of complex 
terms in the next section.
With the introduction of parasitic terms we have expanded on medieval practice 
in the new rules just given. When medieval writers introduced, say, substantivated 
versions of participles of transitive verbs, there is no evidence that they recognized the 
 
Plato sees Socratesacc
∴ Plato of Socratesacc is a seeing thing
 
No animal sees Socratesacc
∴ No animal of Socratesacc is a seeing thing

134 
expanding the notation
signifi cance of what they were doing. In context, it appears as if participles of intransitive 
and transitive verbs were taken to be alike, with no comment made of their important 
logical and semantic diff erences. Introducing parasitic terms is straightforward medi-
eval practice, but identifying additional logical rules that pertain to them is, I think, 
unknown.10 I am confi dent that medieval writers would recognize instances of the 
expanded rules to be given shortly as valid, but they did not give the rules themselves.
5.5 Some complex terms
Generally a complex term is made by combining a common term with something that 
modifi es it. Th is section is devoted to some ways in which terms are combined with 
modifi ers. (Modifi cation of a term by relative clauses is discussed in the following 
section.) Th is topic might seem an unnecessary complication, but medieval logicians 
took the Latin language as is, including many of its complications, and so it would be 
ahistorical to ignore them.
Medieval authors discussed such constructions, but they rarely gave any explicit 
rules for handling them. Th e discussion in this section is meant to be faithful to their 
discussions (this will be covered in more detail in Chapter 6); the explicit rules given 
here go beyond their discussion.
5.5.1 Attributive adjectives and participles modifying nouns
Th e simplest type of modifying is when an adjective modifi es a noun, as in ‘grey donkey.’ 
In Latin an adjective usually follows the noun that it modifi es, though it may precede it 
or even be widely separated from it. As usual, I will generate only the basic form that 
the logicians themselves used, where the adjective immediately follows the expression 
it is modifying (though I’ll display natural language versions for English speakers with 
the adjective preceding the noun).11 Th is construction is to include the case in which 
the adjective is the participle of an intransitive verb, as in ‘running donkey.’
Attributive adjectives and participle constructions12
If ‘P’ is a common term and ‘X’ a term representing an adjective or participle 
of an intransitive verb, then {PX} is a common term.
‘{PX}’ supposits (with respect to time t) for whatever ‘P’ and ‘X’ both supposit 
for (with respect to t).
10 Buridan does note the special behavior of certain of these constructions in his discussion of “restricted 
descent”; but his comments are limited. See section 7.4.
11 In Latin most adjectives follow the noun that they modify, though certain classes of adjectives typically 
precede the verb. I’ll ignore this variation.
12 Th is provision is aimed at what are usually called “intersective” adjectives, which are the simplest cases. 
Treating others would take us far afi eld.

some complex terms 
135
In modern logic these constructions are not present in offi  cial notation. When students 
symbolize sentences of natural language they are expected to apply something like the 
rules given here in their heads, so that ‘grey donkey’ gets symbolized as a conjunction 
using predicates for ‘grey’ and ‘donkey’ separately. Given ‘Every grey donkey is running,’ 
the students are expected to analyze ‘grey donkey’ in their heads, writing down the 
result of such an analysis: ‘∀x(grey x & donkey x → x is running).’ Medieval logicians 
took the complex forms seriously as logical units. If this is done a special rule of infer-
ence is needed to get the results that modern students calculate in their heads:
Th e Rule Modifi er:
(n α)(· {PX} β) α is β
∴ (n α)(· P β) α is β
∴ (n α)(· X-thing β) α is β
(n α)(· P β) α is β
(n α)(· X-thing β) α is β
∴ (n α)(· {PX} β) α is β
Th is rule may be applied recursively. Some examples are:
{donkey grey} 
<grey donkey>
{donkey running} 
<running donkey>
{{donkey running} grey} 
<grey running donkey>
applications
For each of the following arguments, represent the argument in Linguish notation 
and show that it is valid.
 
Some grey donkey is a running thing
∴ Some running donkey is grey
 
Every donkey is grey
∴ Every running donkey is grey
 
Socrates sees a grey donkeyacc
 
Every donkey is an animal
∴ Socrates sees a grey animalacc
5.5.2 Participles of transitive verbs with their objects
Th e participle of a transitive verb may combine with its direct object (and any quantifi er 
that its direct object might have) to form a complex term. Its object may either precede 

136 
expanding the notation
or follow the noun being modifi ed. (Th is is based on observation of examples dis-
cussed by logicians.) Examples are:
of-Socratesacc seeing thing 
i.e. thing seeing Socrates
of-every horseacc seeing thing 
i.e. thing seeing every horse
Th ese complex common terms occur in sentences such as:
Every seeing-thing of-some horseacc is running
Every of-some horseacc seeing-thing is running
each meaning that everything that sees some horse is running. Th ese constructions are 
quite common. Th ey may be included as follows:
Participle of transitive verb with its direct object
If ‘P’ is the participle of a transitive verb, ‘T’ a common term, ‘t’ a singular term, 
and ‘Q’ a quantifi er sign, then these are all common terms:
{(Q T γ)P-γ-thing}
{P-γ-thing (Q T γ)}
{(t γ)P-γ-thing}
{P-γ-thing (t γ)}
In this type of construction it is a merely stylistic question whether the direct object 
precedes or follows the participle. To accommodate this it is convenient to have a rule 
saying that the diff erent forms are equivalent:
Rule Modifi er-Permute:13
Any proposition containing ‘{(Q T γ)P-γ-thing}’ is logically equivalent to the 
result of replacing it by ‘{P-γ-thing (Q T γ)}’
Any proposition containing ‘{(t γ)P-γ-thing}’ is logically equivalent to the 
result of replacing it by ‘{P-γ-thing (t γ)}’
Supposition conditions need to be stated by cases, with one case for each quantifi er. For 
example, ‘{(every T γ)P-γ-thing}’ supposits for something if and only if that thing is 
related by the P relation to everything for which ‘T’ supposits.
We have two forms of a rule for dealing with such complex terms. Th e fi rst form 
is confi ned to instances in which the embedded denoting phrase is singular; it lets us 
13 In some of these constructions a marker precedes the denoting phrase which binds it. Th is is not prob-
lematic so long as the semantics of the whole construction is clear.

some complex terms 
137
replace any such term anywhere. In general, the term is eliminable when it is one term 
of a simple identity.
Rule Complex Term 2:
Form A:   (Q{(t γ)P-γ-thing} β) is equipollent to (t γ)(Q P-γ-thing β)
Form B: 
(t α)(· {(Q T γ)P-γ-thing} β) α is β
 
is logically equivalent to
 
(t α)(Q T γ)(· P-γ-thing β) α is β
Example A: ‘every Socrates-seeing-thing’ is equipollent to ‘of-Socrates every seeing-thing,’ 
where the former is a single complex denoting phrase and the latter is a string of two 
denoting phrases.
Example B: ‘Brownie is an every-donkey-seeing-thing’ is logically equivalent to ‘Brownie 
is of every donkey a seeing-thing,’ where the former sentence in addition to ‘Brownie’ 
contains one (complex) denoting phrase and the latter contains two.
Th e fi rst form of this rule is of special interest because it meets the goal of section 5.4. 
Th is is because it makes a singular term followed by any denoting phrase equivalent 
to a single complex term. Since the new complex term is a common term, all of our old 
rules apply to it. Recall the issue of how to validate this inference:
An animal is of-Socrates a seeing thing
∴ of-Socrates a seeing thing is an animal
(· animal α)(Socrates β)(· seeing-β-thing γ) α is γ
(n α)(· animal β) α is β
(n α)(Socrates β)(· seeing-β-thing γ) α is γ
(Socrates β)(· seeing-β-thing γ)(· animal α) α is γ
1.
2.
3.
4.
1 EX
1 EX
2 3 (?????)
Th is can be achieved as follows:
(· animal α)(Socrates β)(· seeing-β-thing γ) α is γ
(n α)(· animal β) α is β
(n α)(Socrates β)(· seeing-β-thing γ) α is γ
(n α)(· {(Socrates β)seeing-β-thing} γ) α is γ
(· {(Socrates β)seeing-β-thing} γ)(· animal α) α is γ
(Socrates β)(· seeing-β-thing γ)(· animal α) α is γ
1.
2.
3.
4.
5.
6.
1 EX
1 EX
3 Complex Term 2
2 4 ES
5 Complex Term 2
It is apparent from this example that it is an acceptable shortcut to treat a combination 
of a singular denoting phrase binding the marker in a parasitic term immediately 
following it as a unit so far as rule ES is concerned. And the analogous technique should 
also apply to rules EX and UA. So we have the following shortcut rules:

138 
expanding the notation
EX+   (t β)(some Ting-β-thing α) ϕ
 
 
<(t β)T-β-thing is non-empty>
 
∴ (n α) ϕ
 
∴ (n α)(t β)(some Ting-β-thing γ) α is γ
 
where n is a name that does not already occur in the derivation
ES+ 
 
(n α) ϕ
 
 
(n α)(t β)(some Ting-β-thing γ) α is γ
 
∴ (t β)(some Ting-β-thing α) ϕ   where ‘n’ is any singular term
UA+
  
(t β)(every Ting-β-thing α) ϕ 
(t β)(no Ting-β-thing α) ϕ
  
(n α)(t β)(· Ting-β-thing γ) α is γ 
(n α)(t β)(· Ting-β-thing γ) α is γ
 ∴ (n α) ϕ 
∴ not (n α) ϕ
applications
For each of the following arguments, represent the argument in Linguish notation 
and show that it is valid.
 
Plato is an of-Socratesacc seeing thing
∴ Of-Socratesacc a seeing thing is Plato
 
Some of-Socratesacc seeing thing is a running thing
∴ Some running thing is of-Socratesacc a seeing thing
 
Some donkey sees an of-Platoacc seeing thingacc
∴ Of-Platoacc a seeing thingacc some donkey sees
5.5.3 Terms modifi ed by complex terms
Once the complex terms in section 5.5.2 are formed, they in turn can modify nouns. Th ey 
go in the same positions as adjectives and participles discussed previously. Examples are:
Every {donkey {seeing some horse}} is running
Every {{seeing some horse} donkey} is running
In addition, it is possible for a negation to appear, as in:
Every {donkey not {seeing some horse}} is running
Every {not {seeing some horse} donkey} is running

some complex terms 
139
Attributive adjectives and participle constructions (updated)
If ‘P’ is a common term and ‘X’ is a combination of a transitive verb with its 
direct object, then ‘{PX}’ and ‘{P not X}’ are common terms.
‘{PX}’ supposits (with respect to time t) for whatever ‘P’ and ‘X’ both supposit 
for (with respect to t). ‘{P not X}’ supposits (with respect to time t) for whatever 
‘P’ supposits for and ‘X’ does not supposit for (with respect to t).
Some logical forms are:
(every {donkey {(some horse α) seeing-α-thing}} β) β runs
Every donkey of-some horseacc seeing thing runs
(every {donkey {seeing-α-thing (some horse α)}} β) β runs
Every donkey seeing thing of-some horseacc runs
(every {{(some horse α) seeing-α-thing}donkey} β) β runs
Every of-some horseacc seeing thing donkey runs
(every {{seeing-α-thing (some horse α)}donkey} β) β runs
Every seeing thing of-some horseacc donkey runs
To accommodate these in Linguish we add a clause to the inference rule given earlier 
for adjectives and participles modifying common terms:
Rules of inference for attributive adjectives and participle constructions (updated)
Rule for Complex Term 3:
If ‘P’ and ‘X’ are as previously, then these are valid:
(n α)(· {PX} β) α is β
∴ (n α)(· P β) α is β
∴ (n α)(· X β) α is β
(n α)(· P β) α is β
(n α)(· X β) α is β
∴ (n α)(· {PX} β) α is β
(n α)(· {P not X} β) α is β
∴ (n α)(· P β) α is β
∴ (n α) not (· X β) α is β
(n α)(· P β) α is β
(n α) not (· X β) α is β
∴ (n α)(· {P not X} β) α is β

140 
expanding the notation
Again, these rules were not stated by medieval logicians, but I think that they would 
endorse instances of them if they were pointed out.
applications
For each of the following arguments, represent the argument in Linguish notation 
and show that it is valid.
 
Plato is a farmer of-Socratesacc seeing thing
<Plato is a farmer seeing Socrates>
∴ A farmer sees Socratesacc
 
Every seeing thing of-some horseacc donkey runs
∴ Some donkey sees some horse
 
No donkey not a seeing thing of a horseacc sees Platoacc
 
Brownie is a donkey
 
Brownie doesn’t see a horseacc
∴ Brownie doesn’t see Platoacc
5.6 Relative clauses
Relative clauses come in two forms, namely restrictive and non-restrictive:14
Th e woman who left  early was miff ed. 
RESTRICTIVE
Th e woman, who left  early, was miff ed. 
NON-RESTRICTIVE
We will only discuss restrictive relative clauses. Restrictive relative clauses make complex 
terms. In distinguishing restrictive from non-restrictive relative clauses Buridan says:
[In ‘A man who is white is colored’] there is one predicate here, namely, ‘colored,’ which by the 
mediation of the copula is predicated of the whole of the rest as of its subject, namely, of the 
whole phrase: ‘man who is white’; for the whole phrase: ‘who is white’ functions as a determina-
tion of the subject ‘man.’ And the case is not similar to ‘A man is colored, who is white,’ for there 
are two separate predicates here, which are predicated separately of their two subjects, and there 
is not a predicate here which would be predicated by the mediation of one copula of the whole of 
the rest. And although these [propositions] are equivalent, they are not equivalent if we add a 
universal sign. For positing the case that every white man runs and there are many others who 
do not run, the proposition ‘Every man who is white runs’ is true, and is equivalent to: ‘Every 
white man runs’; but the proposition ‘Every man, who is white, runs’ is false, for it is equivalent to: 
‘Every man runs and he is white.’ (Buridan SD 1.3.2)
14 Sherwood S 1.10 (28): “When ‘every’ or ‘all’ is added to a term involving a clause or phrase, the [resultant] 
locution is ambiguous in that the distribution can be united either for the whole term together with the 
clause or phrase or [for the term] without it.”

relative clauses 
141
With few exceptions, a relative clause takes the form of a relative pronoun followed 
by a sentence with a gap in it. Th at is, it is followed by what would be a sentence if 
a denoting phrase were inserted into it in a certain place. Examples are:
dog which [Sam lost __ ]
book which [I gave __ to Martha]
dog which [ __ chased my cat]
Th e case of the relative pronoun (e.g. nominative ‘who’ versus objective ‘whom’) is 
whatever case a denoting phrase would have if it were placed in the gap. Th us we have:
woman whom [he loved __ ]
*woman whom [ __ loved him]   <*ungrammatical>
Th e common explanation for both the gap and the case agreement is that the relative 
pronoun originates inside the sentence (where it has case) and moves to the front, leaving 
a gap in the place where it was. For our purposes we needn’t adopt the movement 
account; what is important for us is that a relative pronoun, like an ordinary denoting 
phrase, needs to play a grammatical role in the sentence making up the relative clause. 
Th en, once formed, the relative clause combines with a common term, immediately 
preceding it to make a complex term. So to accommodate restrictive relative clauses 
we can simply add a new rule for complex terms:
Complex terms:
If T is a common term, and ϕ is a formula with exactly one free marker α, then 
‘{T whichα ϕ}’ is a common term.
Since a relative pronoun is grammatically like a term, I could symbolize the ‘which’ with 
parentheses and a non-subscripted grammatical role marker, to write: {T (which α) ϕ}. 
I use the parenthesis-free notation partly for readability, and because putting a relative 
pronoun on the front of a relative clause produces something special: a modifi er 
instead of a sentence. Th ose who prefer the representation that is more like other 
denoting phrases can understand ‘whichα’ to abbreviate ‘(which α).’
On one modern view, the ‘α’ in ‘{T whichα ϕ}’ is a bound variable, bound by ‘which,’ 
and ‘which’ plays a role similar to ‘λ’ in λ-abstracts.15 Th e whole phrase ‘{T whichα ϕ}’ 
then consists of two one-place predicates next to each other, ‘T’ and ‘whichα ϕ,’ enclosed 
in curly brackets; the interpretation of the whole is the conjunction of those predicates. 
An example of a complex common term made by modifying a common term with 
a restrictive relative clause is:
{donkey whichα α runs}   a complex common term
donkey which runs
15 See Andrews 2009 for an exposition of the λ-calculus.

142 
expanding the notation
5.6.1 Semantics of relative clauses
Since a term modifi ed by a relative clause is itself a (complex) term, what is needed for 
the semantics of these terms is to specify what they supposit for relative to an assign-
ment to any temporary name:
Supposita of complex terms modifi ed by relative clauses:
‘{T whichα ϕ}’ suppositsσ (with respect to time t) for a thing o iff 
T suppositsσ (with respect to t) for o and (§n α) ϕ is trueσ[§n/o]
Although this gives the right truth conditions for complex terms made using relative 
clauses, it is not expressed in a way that is faithful to some medieval authors. Th is is 
because the rule as stated ignores the suppositional status of the relative pronoun, 
treating it as a piece of logical apparatus. Th is is prima facie inappropriate because 
relative pronouns have grammatically prominent characters; for example, they have 
grammatical case just as other terms do. Some medieval authors seem to have 
thought of relative pronouns as terms that have logically signifi cant roles. It is not 
certain what those roles should be. One natural idea is that relative pronouns by 
themselves modify the terms that they follow, and the role of the relative clause itself 
is to constrain what the relative pronoun supposits for.16 Th at view can be encapsu-
lated in this rule:
Supposita of complex terms modifi ed by relative clauses:
‘{T whichα ϕ}’ suppositsσ (with respect to time t) for a thing o iff  T suppositsσ 
(with respect to t) for o and whichα, in that context, also suppositsσ (with 
respect to t) for o.
Th is puts modifi cation of a term by a relative pronoun on a par with its modifi cation by 
adjectives. We just need to explain what it is that the relative pronoun supposits for. 
Th at is straightforward:
Supposita of relative pronouns
In the context ‘{T whichα ϕ}’, ‘whichα’ suppositsσ (with respect to time t) for 
a thing o iff  ‘(§n α) ϕ’ is trueσ[§n/o]
16 Th ough the quote from Buridan which begins this section seems to endorse the analysis we have 
already given.

relative clauses 
143
Th ese two conditions together are equivalent to the simpler one given fi rst. Th ey do, 
however, supply more meaningful parts of the construction; these will be discussed 
in Chapter 10.
On either account, a single two-way rule of derivation suffi  ces for the logic of restrictive 
relative clauses:
RelClause:
(n α)(· {T whichγ ϕ} β) α is β
∴ (n α)(· T β) α is β
∴ (n γ) ϕ
(n α)(· T β) α is β
(n γ) ϕ
∴ (n α)(· {T whichγ ϕ} β) α is β
To expand the completeness theorem to include sentences containing relative clauses, 
it should be enough to add the rules given in this section, and to use the semantic pro-
vision given earlier as a guide to how to interpret the complex term when constructing the 
interpretation I. I think the changes are straightforward, but they are not discussed here.
5.6.2 Representing ordinary language Latin (and English)
Only one addition is required for turning sentences with relative clauses into their 
natural language forms. We have been indicating the case of a denoting phrase by 
putting a case subscript on its main term; the case is determined by the grammatical 
marker that the denoting phrase binds.17 We extend this practice so as to put a case 
subscript on the word ‘which’; the subscript is again the one determined by the marker 
that ‘whichx’ binds. In Latin, relative pronouns take various forms for the diff erent cases; 
except for ‘who/whom/whose’ this is invisible in English.
From the logical form:
(Some {donkey whichα (Plato β) β sees α} γ)(Socrates δ) γ strikes δ
we generate:
Some donkey whichacc Plato sees Socratesacc strikes
and then the more natural form:
Some donkey whichacc Plato sees strikes Socratesacc
17 Our practice is that a marker preceding a verb, or following the verb ‘is’ determines nominative case, 
and a marker following a non-copular verb or a participle determines accusative case. Th ese are the only two 
cases discussed so far. Genitive case will be discussed in the next section.

144 
expanding the notation
Some additional sentences containing relative clauses follow. (In these examples the 
verbs have been moved forward just far enough to yield the natural word order for 
English. Any of the word orders are grammatical in Latin.)
(Some {donkey whichα (every animal β) α sees β} γ)(Socrates δ) γ strikes δ
Some donkey which every animalacc sees Socratesacc strikes
Some donkey which sees every animalacc strikes Socratesacc
(Some {donkey whichα (every animal β) β sees α} γ)(Socratesacc δ) γ strikes δ
Some donkey whichacc every animal sees Socratesacc strikes
Some donkey whichacc every animal sees strikes Socratesacc
(Some {donkey whichα (every animal β) α sees β} γ)(Socrates δ) δ strikes γ
Some donkeyacc which every animalacc sees Socrates strikes
Some donkeyacc which sees every animalacc Socrates strikes
(Socrates δ)(Some {donkey whichα (every animal β) α sees β} γ) δ strikes γ
Socrates some donkeyacc which every animalacc sees strikes
Socrates strikes some donkeyacc which sees every animalacc
As a test for adequacy we can derive either of Buridan’s sentences from the other:
Every man who is white runs
Every white man runs
Another ordinary language complication: in Latin, relative clauses can be located apart 
from the noun that they are modifying. Our rules do not generate such sentences, 
but one might ask whether our formation rules should permit them to be generated 
from constructions in which the relative clause immediately follows the term that 
is modifi ed. It is not clear to me at the moment whether this off ers special possibilities 
for scope relations, as in ‘Some man sees every donkey who kicks it,’ where the ‘who’ 
refers back to ‘man’ and the ‘it’ to ‘donkey.’ I will assume that when a relative clause is 
separated from the term that it modifi es, it is to be interpreted semantically as if it were 
not separated. I don’t think that this was a unanimous view, since at least one author 
who insists on it says that others have denied it.18 But I don’t know what else to say here. 
At the moment such constructions are not generated, and they will be ignored.
18 Anonymous, About Univocation, p. 570: “However, there can be a doubt, when the order of a locution 
on the front is contrary to the principle of the construction. By which in locutions of this sort an appellative 
name which supposits ought to contract appellation. As when it is said: ‘Something will be Antichrist which is 
not a human,’ the principle of the construction requires that the order of the locution is this: ‘Something 
which isn’t a human will be Antichrist’; and thus this name ‘human’ contracts the appellation from this verb 
‘is.’ However the order of the locution on the front requires that it contract the appellation from this verb: 
‘will be,’ since it is spoken fi rst in that locution.
Some say to this that the appellative name always contracts the appellation from the near one, so that if the 
one nearer to it be a present tense verb it contracts the appellation from that, if it is a past tense verb, from 
that, if of future time, from that. However we say that it always contracts the appellation from that with 
which it is construed intransitively, whether that is spoken fi rst, or not. And if therefore in the foregoing 
locution the appellative name is construed with this verb ‘will be’ intransitively, it contracts the appellation 
from that, no matter how the locution is ordered.”

genitives 
145
applications
Give the logical forms underlying Buridan’s sentences, and derive each from 
the other:
Every man who is white runs
Every white man runs
Give the logical forms for these arguments and show that they are valid.
 
Brownie is an animal whichacc Plato sees
∴ Plato sees Brownieacc
 
Brownie is an animal whichacc Plato sees
∴ Plato sees an animalacc
 
Some animal which runs sees a donkeyacc
∴ Some donkeyacc an animal sees
 
No animal which runs sees a donkeyacc
 
Brownie is an animal which sees a donkeyacc
∴ Brownie doesn’t run
5.7 Genitives
Th e genitive shows up in English in two diff erent forms, as a genitive ending and as 
a prepositional phrase construction with ‘of ’:
Th is is the woman’s donkey
Th is is the donkey of the woman.
In the Latin of the logic texts there is only one construction commonly discussed:19 the 
genitive noun (the one that in English gets the possessive ending or is object of the 
preposition ‘of ’) is infl ected for genitive case. Th e diff erence from the English use of 
“-’s” is that in Latin the possessive noun needn’t immediately precede what it modifi es. 
Th e following word orders are all OK in Latin:
Every woman’s donkey is lame.
A donkey every woman’s is lame.
A donkey is lame every woman’s.
Th ese forms are confusing in English; to increase comprehension I will usually use the 
‘of ’ form in the English transliterations. Th is is a convention sometimes used in the 
literature, because it is useful to English readers.20 I will assume that if an ‘of-’ occurs on 
19 I am not aware of discussion by logicians of the use of the dative case to indicate possession. 
20 See Karger 1997 for an illustration of this convenient usage.

146 
expanding the notation
the front of a denoting phrase whose term is not marked as accusative, then the term is 
in the genitive case. (I refrain from introducing genitive subscripts merely to avoid 
clutter.) Th us, although the following are not standard English, you should easily be 
able to fi gure out what they mean:
Of-every woman a donkey is lame.
A donkey of-every woman is lame.
Th e fi rst means that for each woman w, some donkey of w’s is lame. Th e second means 
that there is a donkey that is every woman’s, and it is lame. It is apparent that there is 
more freedom to order the denoting phrases than in English. (I will continue occasion-
ally to use the English apostrophe ‘-s’ construction when this produces a more natural 
rendition.)
Genitives are important to medieval logicians because they aff ord a natural means 
to make propositions with multiple quantifi ers with interacting scopes.21 Some 
examples are:
Of-every man some donkey sees every horse.
Of-some man every donkey sees some horse.
Of-some man every donkey sees of-every woman no horse.
with the last meaning that there is some man such that every donkey of his is such 
that for every woman, the donkey sees none of her horses. Each of those sentences 
is naturally read as containing three or more simple terms. It is equally easy to make 
sentences which are naturally read as containing complex terms such as:
Some donkey of every man sees every horse of a woman.
Reading scopes from left  to right this is a sentence with two complex terms: ‘donkey 
of every man’ and ‘horse of a woman.’ Clearly there are plenty of potential complexities 
for logicians to untangle.
5.7.1 What the genitive means
Some common nouns, such as ‘mother,’ ‘owner,’  .  .  .  are inherently relational; others 
such as ‘woman,’ ‘chair’ are not. Typically the genitive construction used with a non-
relational noun indicates some kind of possession (‘a horse of Fred’s’) or something 
analogous to possession (‘Mary’s job’), or almost any other kind of relation that can be 
doped out from context (‘Mary’s hill’ = the hill Mary has been assigned to climb).22 
Usually the genitive construction used with a relational noun indicates the relation 
21 Th e same potential exists with parasitic terms that are participles of transitive verbs, but these were not 
so widely discussed. An example would be ‘Every man some donkey seeing sees no horse’ meaning that for 
every man there is a donkey seeing him who doesn’t see any horse (if ‘man’ is in the accusative case) or 
meaning that for every man who sees some donkey he sees no horse (if ‘donkey’ is in the accusative case).
22 Buridan SD 4.4.7 (287) distinguishes similar kinds of use of the genitive; he adds to these the use of the 
genitive to indicate effi  cient cause, and he states that the genitive is “taken in many ways.” I lump together all of 
the ways that are not uses of relational nouns, leaving it to context to determine how they are to be interpreted.

genitives 
147
conventionally associated with the noun; ‘Mary’s mother’ usually means the female 
person who gave birth to Mary. Relational nouns also have non-relational uses, as in: 
‘Four mothers showed up.’ I assume that these non-relational uses are best construed as 
paronyms; they are non-relational nouns whose meaning is derived from a relational 
use of the same noun, as in ‘mother,’ meaning ‘mother of someone.’23 Th ese non-relational 
nouns then also enter into the fi rst kind of genitive construction, so that ‘Mary’s mother’ 
can mean the mother (of someone) to whom Mary has been assigned as a case worker. 
Th e diff erence between these two diff erent genitive relations is illustrated by the popular 
medieval sophism:
Th at dog is yours
Th at dog is a father
So that dog is your father
On the most natural reading, the genitive relation indicated by ‘yours’ in the fi rst 
premise is ownership and that in the conclusion is fatherhood; and ‘father’ is used 
non-relationally in the second premise and relationally in the conclusion. So there is 
a fallacy of ambiguity, though it is not equivocation or amphibole or composition/
division; at best it falls under Aristotle’s fallacy of form of expression. (Th ere is also 
a less natural reading on which the argument is valid; this is the reading on which 
‘father’ in the conclusion has its non-relational use, and the genitive in the conclusion 
is interpreted as the generic possession relation.)
On either the relational noun or the possession interpretation, one ingredient 
of interpreting the genitive in a sentence is to mark the grammatical relation between 
the denoting phrase which is marked as genitive and the denoting phrase that is 
the “possessed.” We will do this as usual by including a grammatical marker with the 
“possessed” term; that marker will be bound by the “possessor” denoting phrase. For 
example, in ‘some owner of Brownie’ or ‘of Brownie some owner’ the relational noun 
‘owner’ is the one that must be logically special; it will include a grammatical marker 
which will be bound by a denoting phrase containing ‘Brownie,’ which fi lls that gram-
matical role and is thus in the genitive case, and which is logically ordinary. We will 
consider fi rst the relational noun uses of the genitive, and then the possession uses; 
fi nally we look briefl y at complex terms made using the genitive.
5.7.2 Relational common nouns
We begin with relational common nouns, such as ‘mother.’ It seems natural to suppose 
that each of these signifi es a relation, such as the relation of being a mother of. Th e 
presence of such a noun provides a grammatical role for the denoting phrase that picks 
23 Ockham SL 1.52 (171–2) says: “But there are  .  .  .  names which cannot be truly predicated of any-
thing unless it is possible to add to them names which are not their abstract forms; the added names are in 
one of the oblique cases,  .  .  .  Examples are names like ‘master’ and ‘slave’ and ‘father’ and ‘son’; for no one 
is a father unless he is someone’s father, nor is anything similar unless it is similar to something.” I take him 
here to be saying that any non-relational use of ‘father’ is equivalent to ‘someone’s father.’

148 
expanding the notation
out which thing the mother is a mother of. Th is is similar to participles of transitive 
verbs providing grammatical roles for their direct objects. We will add a new category 
of terms to the vocabulary of Linguish:
Relational nouns:
If ‘N’ is a relational noun, then ‘N-of-α’ is a common term. Th e term ‘N-of-α’ 
supposits for a thing o relative to o′ iff  o is related to o′ by the relation that 
‘N’ signifi es.
E.g. relative to Socrates, the common term ‘mother-of-α’ supposits for those things that 
are Socrates’ mother. So on this assignment, ‘(Socrates α)(every mother-of-α β)’ will 
mean something like ‘every mother of Socrates.  .  .  .’ So we have sentences like:
(every donkey α)(· mother-of-α β) β speaks
Of-every donkey a mother speaks   <Every donkey’s mother speaks>
In Latin the relational noun needn’t immediately follow the term it is construed with:
(every donkey α)(Socrates β)(· mother-of-α γ) β sees γ
Of-every donkey Socrates sees a mother
Unlike English,24 the terms related to relational nouns in Latin easily take quantifi er 
expressions other than indefi nites, as in:
(some woman α)(every child-of-α β) β speaks
Of-some woman every child speaks   <Some woman’s every child speaks>
5.7.3 Non-relational uses
We can provide for the non-relational use of relational nouns by defi ning as follows:
Non-relational occurrences of relational nouns:
If ‘N’ is a relational noun, then ‘N-∃’ is a common term. ‘N-∃’ supposits (with 
respect to time t) for a thing o iff  o is related to something by the relation that 
‘N’ signifi es (with respect to t).
Th e ‘∃’ symbol is heuristic only. We suppose that in the transition to natural language, 
the ‘-∃’ vanishes. An example is:
24 It is a common view that genitives in English are part of the quantifi cational structure of the “possessed” 
noun. So ‘Every donkey’s mother speaks’ contains a single complex denoting phrase, where the “quantifi er” of 
‘mother’ is ‘every donkey’s.’ As a result, something like ‘Some woman’s every child speaks’ is ungrammatical in 
English. I take it, however, that it can be understood, and that it is clear what it means. It is grammatical in 
Latin. Because of the way in which genitives in English are formed, it may not be right to see them as cases of 
role-fi lling, as we are doing here. I think there is no consensus on whether this is the right analysis for Latin.

genitives 
149
(every mother-∃ β) β speaks
Every mother speaks
We have a rule of inference relating non-relational uses of relational nouns to those 
nouns:
Non-relational uses of relational nouns
 
(m α)(· N-of-α β) ϕ
∴ 
(· N-∃ β) ϕ      when ϕ is affi  rmative
If we had a “universal” term ‘thing’ we could add a two-way rule, giving:
Non-relational uses of relational nouns
 
(· thing α)(· N-of-α β) ϕ
∴ 
(· N-∃ β) ϕ      and vice versa
To fl esh this out would require some additional constraints on ‘thing,’ requiring some-
thing like “everything that is is a thing”:
Th ings
 
<P is non-empty>
∴ 
(every P α)(· thing β) α is β      and vice versa
However this is speculative, and we will not pursue it further here.
applications
Give the logical forms for these arguments and show that they are valid.
 
 Xanthippe is of-some woman an aunt <Xanthippe is some woman’s aunt>
 
Every woman is an animal
∴ Xanthippe is of-some animal an aunt
 
Every woman is of-some woman a daughter
 
Every woman is a human
∴ Every woman is of-some human a daughter
 
Some woman is of-Socrates a wife
∴ Some woman is a wife

150 
expanding the notation
5.7.4 Non-relational possessives
Suppose that a sentence contains a word in the genitive case, but there is no relational 
noun, as in ‘Some woman’s donkey runs.’ Th en there is a possessor and a possessed. 
In English there is a use of ‘have’ that stands for this abstract relation, whatever it is in 
a given context. Mary’s book is a book that she has; and if she has been assigned to 
climb hill number 413 she can say either ‘Hill 413 is my hill’ or ‘I have hill 413.’ Th is 
means that non-relational possessives can be explained in terms of a highly context-
sensitive form of the verb ‘have.’
Non-relational nouns and having:
If N is a non-relational noun, then ‘N-poss-α’ is a common term that suppositsσ 
(with respect to time t) for a thing o that ‘N’ signifi es (relative to t) relative to o′ 
iff  o′ is had (with respect to t) by o′.
Th e verb ‘has’ holds of a pair of things iff  its fi rst member has its second 
member.
Th e sequence of denoting phrases ‘(Socrates α)(every horse-poss-α β)’ will mean 
‘Socrates’ every horse,’ or ‘Of Socrates, every horse.’ Th e ‘poss’ that is hyphenated 
between the noun and the grammatical marker is there to indicate generalized posses-
sion. It is part of the logical apparatus, and is thus to be erased in the transition from 
Linguish to natural language.
In Latin the possessor phrase may precede the possessed with quantifi er words on 
the possessed. A typical Latin construction would be:
Of-some farmer every donkey is brown
meaning that there is a farmer such that every one of his/her donkeys is brown. In 
English this would be worded somewhat awkwardly as:
Some farmer’s every donkey is brown.
Th e logical form underlying this sentence is:
(Some farmer α) (every donkey-poss-α β) β is brown.
Erasing the markers and parentheses yields the desired:
Of-some farmer every donkey is brown.
Unlike the genitive associated with a relational noun, the genitive of possession is 
logically complex: Brownie is Socrates’ donkey if and only if Brownie is a donkey and 
Socrates has Brownie. We have this inference rule for ‘N-poss-α’:

genitives 
151
Possession:
 
(m δ)(n α)(·N-poss-α ε) δ is ε 
 
(m δ)(·N ε) δ is ε
∴ 
(m δ)(·N ε) δ is ε 
 
(n α)(m β) α has β
∴ 
(n α)(m β) α has β 
∴ 
(m δ)(n α)(·N-poss-α ε) δ is ε
Th is will let us make inferences that are not possible with relational nouns. For exam-
ple, given that every donkey is an animal, we can infer:
 Some farmer’s donkey is running
∴ 
Some farmer’s animal is running
But given that every mother is a daughter,25 we may not infer:
 Some farmer’s mother is running
∴ 
Some farmer’s daughter is running
(Th at is, we may not infer this if the genitives in the premise and conclusion are under-
stood as meaning the motherhood and daughterhood relations, as opposed to some 
kind of possession.)
But since every mother of someone is an ancestor of theirs, this inference is good:
 Some farmer’s mother is running
∴ 
Some farmer’s ancestor is running
I am not aware of any discussion of these inferences by medieval authors. For that 
reason I will not comment on them further.
applications
Give the logical forms for these arguments and show that they are valid.
 
 Brownie is of-some woman a donkey <Brownie is some woman’s donkey>
 
Every donkey is an animal
∴ Brownie is an animal
 
Every woman has a donkey
 
Xanthippe is a woman
∴ Some donkey is of-Xanthippe a donkey
 
Some animal is of-Socrates a donkey
∴ Socrates has a donkey
25 Of course, the claim that every mother is a daughter makes sense only if the terms ‘mother’ and ‘daugh-
ter’ are used in their non-relational senses. In any event, the inference is not valid.

152 
expanding the notation
5.7.5 Complex terms with genitives
As with participles, genitives form complex terms. Th eir constructions mirror those 
with participles. Examples are:
every donkey of Socrates is running
every father of some donkey is running
every donkey’s father is running
Complex genitive terms
If ‘P’ is a relational common term, ‘T’ a non-relational common term, ‘t’ a 
singular term, and ‘Q’ a quantifi er sign, then ‘{(t γ)P-of-γ},’ ‘{(t γ)P-poss-γ},’ 
‘{(Q T γ)P-of-γ},’ and ‘{(Q T γ)P-poss-γ}’ are common terms.
Supposition conditions: Th ese are similar to those for complex terms formed 
using the participles of transitive verbs.
Th ese terms are subject to the same rules as those made up with participles:
Rule Complex Term 2:
(Q{(t γ)P-of-γ} β) is equipollent to (t γ)(Q P-of-γ β)
(Q{(t γ)P-poss-γ} β) is equipollent to (t γ)(Q P-poss-γ β)
(·{(· T γ)P-of-γ} β) is equipollent to (· T γ)(·P-of-γ β)
(·{(· T γ)P-poss-γ} β) is equipollent to (· T γ)(·P-poss-γ β)
Similarly, permutations are possible.
Th e derived rule Modifi er-Permute:
Any proposition containing ‘{(Q T γ)P-of-γ-thing}’ is logically equivalent to 
the result of replacing it by ‘{P-of-γ-thing (Q T γ)}’
Any proposition containing ‘{(t γ)P-of-γ-thing}’ is logically equivalent to the 
result of replacing it by ‘{P-of-γ-thing (t γ)}’
Any proposition containing ‘{(Q T γ)P-poss-γ-thing}’ is logically equivalent 
to the result of replacing it by ‘{P-poss-γ-thing (Q T γ)}’
Any proposition containing ‘{(t γ)P-poss-γ-thing}’ is logically equivalent to 
the result of replacing it by ‘{P-poss-γ-thing (t γ)}’

demonstratives 
153
Given our rules for forming sentences with genitives, when the possessed term in 
a genitive relation precedes the possessor term they must both be part of a single 
complex term. For if the terms are in independent denoting phrases, there is no way 
for a marker attached to the possessed term to be bound by a denoting phrase to its 
right. But when the possessed term follows the possessor term then those terms may 
either be parts of independent denoting phrases, with the possessor denoting phrase 
binding the marker attached to the possessed term, or they may be parts of the same 
complex term by the rule just given for complex genitive terms. If they are part of a 
single complex term then there will be two quantifi er signs in a row, as in ‘some every 
farmer’s donkey,’ meaning some donkey possessed by all the farmers. In Latin, where 
the indefi nite construction does not involve a visible indefi nite sign, the surface word-
ing may be ambiguous, so that ‘every farmer’s donkey’ may mean either “for every 
farmer there is a donkey such that,” or “for every donkey-belonging-to-some-farmer.” 
Given the various options for including genitive constructions in sentences, it may 
not always be obvious which construction is present, given only the surface order of 
the words and their grammatical cases. Late medieval logicians put some energy into 
clarifying this; see section 6.3 for discussion.
applications
Give the logical forms for these arguments and show that they are valid.
 
Every every farmer’s donkey is grey
∴ Some donkey of every farmer is grey
 
Every some farmer’s donkey is grey
 
Brownie is of some farmer a donkey
∴ Brownie is grey
 
Some every farmer’s donkey is grey
∴ Of every farmer some donkey is grey
5.8 Demonstratives
Medieval authors make frequent use of two kinds of demonstrative terms. Th ere are 
simple demonstratives, such as ‘this’ and ‘that,’ which function on their own as singular 
terms. And there are complex demonstrative terms consisting of a demonstrative plus 
a common term, such as ‘this donkey’ and ‘that stone.’ Each of these supposits for at most 
one thing. In the tradition, a demonstrative supposits for whatever is demonstrated by 
a use of a word like ‘this.’ (Note that the demonstration could be virtual, since people 
spoke of demonstrating non-perceivable things, such as God.) Simple demonstratives 

154 
expanding the notation
supposit for whatever it is that they are used to demonstrate;26 if they do not in fact 
demonstrate anything, they supposit for nothing. A complex demonstrative supposits 
for whatever its demonstrative part demonstrates provided that its common term 
supposits for the thing demonstrated; so ‘this donkey’ supposits for the donkey that 
is demonstrated if a donkey is demonstrated; otherwise it supposits for nothing.
We can incorporate simple demonstrative singular terms in the language by using: 
‘this1,’ ‘this2,’ ‘this3,’  .  .  .  Complex demonstratives will be of the form ‘thisn T’ where ‘T’ is 
any common term:
Simple demonstratives
Each positive numeral indicates a possible demonstration of a thing. For each 
n, ‘thisn’ is a singular term which supposits (with respect to time t) for the 
nth thing demonstrated (or for nothing if the nth demonstration does not 
succeed in picking out a thing).
Complex demonstratives
If ‘T’ is a common term then ‘thisn T’ is a singular term which supposits (with 
respect to time t) for whatever ‘thisn’ supposits for (with respect to t) if ‘T’ also 
supposits for that thing (with respect to t); otherwise ‘thisn T’ supposits for 
nothing (with respect to t).27
Rule Demonstrative:
 
(thisk T α)(n β) α is β 
 
(thisk α)(n β) α is β
∴ 
(thisk α)(n β) α is β 
 
(·T α)(n β) α is β
∴ 
(·T α)(n β) α is β 
∴ 
(thisk T α)(n β) α is β
Th e completeness theorem given earlier can be extended to sentences using mixed 
demonstratives by including the rules just given, and adding the provision that in con-
structing the interpretation Γ a simple demonstrative is assigned a supposition just as 
a name is assigned one, and the term ‘thisk F’ supposits for whatever ‘thisk’ supposits for 
(if anything) if ‘F’ supposits for that thing; otherwise it supposits for nothing.
26 Th is is the right condition if singular terms are immune to restriction by tenses, etc. Otherwise one 
must say that simple demonstratives supposit for whatever they are demonstrating providing that that thing 
meets the restricting conditions.
27 An anonymous comment on restrictions (in Marsilius of Inghen TPT appendix 2) gives an equivalent 
condition, phrased in terms of how the demonstrative restricts the supposition of the common term that it 
precedes: “a demonstrative pronoun or a relative [i.e. anaphoric pronoun] restricts a term to standing for that 
which is assigned to it by the pronoun or relative, as this man runs.”

molecular propositions 
155
applications
Give the logical forms for these arguments and show that they are valid.
 
Socrates sees that3 donkey
∴ Socrates sees a donkey
 
Some horse sees that4 donkey
 
Every donkey is an animal
∴ Some horse sees an animal
 
No woman sees that5
∴ No woman sees that5 donkey
5.9 Molecular propositions
Aristotle did not formulate logical principles governing propositions containing 
connectives. Whatever his view on this matter (assuming that he had a view),28 he 
managed to validate conversions and syllogisms without ever himself using mole-
cular propositions containing connectives, as we have seen. Principles such as modus 
ponens or disjunctive syllogism were just not relevant.
Propositional logic in fact existed, even in ancient times. Its development seems to 
be primarily due to the Stoics. Martianus Capella, writing apparently before 429, 
describes that part of the liberal arts curriculum called dialectic, or logic. It includes 
Aristotle’s conversions and syllogisms, though not his proofs of conversion or reductions 
of syllogisms to the fi rst fi gure. It also contains a set of seven principles of propositional 
logic, including various “modes” (in which disjunction is treated as exclusive). Th e fi rst 
fi ve of these, which eventually became known as the “fi ve indemonstrables,” are:
From antecedents: 
P; if P then Q ∴ Q
From consequents: 
P; if not Q then not P ∴ Q
From incompatibles: not (P and not Q); P ∴ Q
By disjunction: 
P or Q; P ∴ not Q
By disjunction: 
P or Q; not P ∴ Q
(For more on Stoic logic see Bobzien 2006 or Mates 1961.)
Boethius wrote about molecular propositions, and they formed a standard part 
of the curriculum that was inherited by medieval logicians. Eventually, six types of 
molecular proposition were typically identifi ed:
28 One of Aristotle’s commentators, Apuleius (p. 95), seems to hold that molecular inferences are super-
fl uous “because they do not infer beyond what has been accepted.” He gives as an example of such a 
superfl uous inference ‘If it is day, it is light; but it is day, therefore it is light.’ (Ascription of this text to Apuleius 
is disputed.)

156 
expanding the notation
Conjunctions
Disjunctions
Conditionals
Causals
Temporal Propositions
Locational Propositions
All of these are called hypotheticals, not just the conditionals.
Conjunctions and disjunctions are just what one expects; they are combinations 
of propositions made with ‘and’ (et) and ‘or’ (vel), or similar words. A conjunction is 
true if both of its conjuncts are true, and false if either or both are false. In Stoic logic 
disjunction was taken to be exclusive, but in medieval logic a disjunction is usually 
taken to be true if either or both of its disjuncts are true, and false if both disjuncts are 
false. So they were usually given modern truth conditions.29
Conditionals are made with ‘if’ (si), or equivalent words. Conditionals were given 
various analyses; a common one is that a conditional is taken to be true if it is necessary 
that the antecedent not be true without the consequent also being true.30 Th is makes 
the truth of a conditional equivalent to the goodness of the related argument, as some 
writers observed.31 Indeed, when an author is discussing “consequences” it is some-
times unclear whether it is arguments or conditionals that are meant—unclear because 
the discussion makes sense read either way. Some authors also discuss “ut nunc” (as of 
now) conditionals; as usually explained, these turn out to be equivalent to our material 
implication.32 But the commonest unqualifi ed meaning of a conditional is that it is 
true if and only if it is impossible for the antecedent to be true and the consequent false. 
One can get a feel for medieval theorizing about conditionals from Walter Burley’s 
“Consequences” in Kretzmann and Stump 1988.
Causal, temporal, and locational propositions are not generally integrated with the 
other logical principles, and they will not be discussed here.
29 Sherwood S XXI.1 (141) holds that “ ‘or’ is taken sometimes as a disjunctive and at other times as a sub-
disjunctive. In the fi rst case it indicates that one is true and the other is false; in the second case it indicates 
solely that one is true while touching on nothing regarding the other part.” Later, Paul of Venice LP I.14 (132) 
gives inclusive truth conditions: “For the truth of an affi  rmative disjunctive it is required and it suffi  ces that 
one of the parts is true; e.g. ‘you are a man or you are a donkey.’ For the falsity of an affi  rmative disjunctive it is 
required that both parts be false; e.g., ‘you are running or no stick is standing in the corner.’ ”
30 Ockham SL II.31; Peter of Spain LS I.17. Sherwood IL I.18 gives truth conditions that are not clearly 
modal: “whenever the antecedent is [true], the consequent is [true].”
31 Ockham SL II.31.
32 Buridan TC 1.4.7 (185) gives as the conditions of an ut nunc consequence: “it is completely impossible 
with things related as they are now related for the antecedent to be true without the consequent <being true 
as well>.” Th is is understood so that if the antecedent is false, the antecedent cannot be true as things are now 
related (since they are so related as to make the antecedent false), and the ut nunc reading is true; likewise, if 
the consequent is true then, again, with things as they are now, it can’t but be true. So the result is our material 
conditional. Buridan 1.4.11 (186) points out that “if the antecedent is false, though not impossible, the conse-
quence is acceptable ut nunc.” At 1.4.12 he gives a case in which the antecedent is true, and whether or not the 
consequence is acceptable ut nunc depends on whether or not the consequent is actually true.

molecular propositions 
157
Th e Stoics pursued propositional logic through giving axioms and deriving theorems 
from them. In medieval logic tautological relations were oft en stated without justifi ca-
tion. For example, versions of De Morgan’s laws were stated as if pointing them out is 
justifi cation enough.
Conjunctions, disjunctions, and ut nunc conditionals: It is easy to include 
molecular sentences which have no free markers in them in Linguish. Just add the 
following:
If ‘ϕ’ and ‘ψ’ are formulas with no free variables, so are ‘[ϕ and ψ]’ and ‘[ϕ or ψ]’ 
and ‘[if ϕ then ψ].’
‘[ϕ and ψ]’ is trueσ iff  ‘ϕ’ is trueσ and ‘ψ’ is trueσ
‘[ϕ or ψ]’ is trueσ iff  ‘ϕ’ is trueσ or ‘ψ’ is trueσ (or both)
‘[if ϕ then ψ]’ is trueσ iff  ‘ϕ’ is falseσ or ‘ψ’ is trueσ (or both) <the as-of-now reading>
Rules: All tautological implications, including e.g.:
 
From ‘[ϕ and ψ]’ infer ‘ϕ,’ and infer ‘ψ’
 
From ‘ϕ’ and ‘ψ’ infer ‘[ϕ and ψ].’
 
From ‘[ϕ or ψ]’ and ‘not ϕ,’ infer ‘ψ’; and
 
   from ‘[ϕ or ψ]’ and ‘not ψ,’ infer ‘ϕ.’
 
From ‘ϕ’ or from ‘ψ’ infer ‘[ϕ or ψ].’
 
From ‘[if ϕ then ψ]’ and ‘ϕ,’ infer ‘ψ’; and
 
   from ‘[if ϕ then ψ]’ and ‘not ψ,’ infer ‘not ϕ.’
 
From ‘not ϕ’ or from ‘ψ’ infer ‘[if ϕ then ψ].’
With the addition of molecular propositions we should expand our account of when 
a term occurs in an affi  rmative or negative context. We can say the following:
If a term ‘α’ occurs affi  rmatively in ‘ϕ,’ then it also occurs affi  rmatively in ‘[ϕ and ψ]’ 
and in ‘[ψ and ϕ].’
If a term ‘α’ occurs negatively in ‘ϕ,’ then it also occurs negatively in ‘[ϕ or ψ]’ and in 
‘[ψ or ϕ].’
If a term ‘α’ occurs negatively in ‘not ϕ,’ then it also occurs negatively in ‘[if ϕ then 
ψ]’ and if ‘α’ occurs negatively in ‘ψ,’ then it also occurs negatively in ‘[if ϕ then ψ].’
Th is still holds:
If a term ‘α’ occurs affi  rmatively (negatively) in ‘ϕ,’ then it occurs negatively 
(affi  rmatively) in ‘not ϕ.’
It is clear from this that some occurrences of terms are no longer either affi  rmative or 
negative. For example, this is true of ‘donkey’ in ‘Some donkey runs or some horse runs’; 

158 
expanding the notation
it does not occur affi  rmatively because its emptiness does not make the whole sentence 
false, and it does not occur negatively because its emptiness does not make the whole 
sentence true.
5.9.1 Constructions with free markers
Th ere is a problem with propositions containing conjunctions and disjunctions of 
sentences with free markers: it is not clear that there are such things. Recall that markers 
mark grammatical roles. If a whole conjunct, say, contains a free marker, then it must be 
bound by some denoting phrase not within that conjunct. But then the main term 
of that denoting phrase is occupying a grammatical role in that conjunct while not 
itself occurring in the conjunct. If we were not concerned to stick to the resources 
recognizable to medieval logicians, this would be easy; just allow conjunctions and 
disjunctions with free markers to be bound by additional denoting phrases, and don’t 
worry about it. Th e truth conditions are no problem. But we would have a genuinely 
artifi cial language that corresponds to nothing in natural language. For example, sup-
pose we conjoin the formulas:
(some donkey α) α runs
β sits
into the conjunction:
[(some donkey α) α runs and β sits]
Th en we add a denoting phrase to the front:
(every horse β)[(some donkey α) α runs and β sits]
Th e truth conditions are straightforward; the sentence is true if and only if every horse 
is such that some donkey runs and it (the horse) sits. But that logical form of Linguish 
yields a natural language sentence that doesn’t actually seem to be a sentence at all:
(every horse β)[(some donkey α) α runs and β sits] ⇒
every horse some donkey runs and sits
Th is is not grammatical English, and its analogue in Latin is not grammatical either.
It thus appears that we must—at least for the time being—forbid the formation of 
conjunctions and disjunctions containing free grammatical markers. Th is topic will be 
explored further, aft er we have considered how medieval logicians treated anaphoric 
expressions in Chapter 8.

molecular propositions 
159
applications
Give the logical forms for these arguments and show that they are valid.
 
Socrates sees a horse or Brownie is grey
 
Brownie isn’t grey
 
Every horse is an animal
∴ Socrates sees an animal
 
If some horse sees a donkey then no donkey sees a horse
 
Some donkey sees a horse
∴ No horse sees a donkey
 
No horse which sees a donkey is grey
 
Brownie is a donkey and some horse sees Brownie
∴ Some horse isn’t grey
In the next two chapters molecular propositions will be ignored, since nothing else to 
be discussed depends on them. Th ey will reappear in Chapter 8.

160 
some illustrative topics
6
Some Illustrative Topics
In the last chapter a number of linguistic constructions were introduced with a 
minimum of discussion. Th is chapter discusses a few particular cases in which those 
constructions are employed. Section 6.1 is about relational verbs, parasitic terms, 
and complex terms. Section 6.2 focuses on some particular views about subjects and 
predicates; this section contains some test cases for the new constructions. Section 6.3 
focuses on how one tells in particular cases whether one is dealing with independent 
terms or complex terms with terms as parts.
6.1 Relational expressions and De Morgan’s challenge
In De Morgan 1847, Augustus De Morgan states that there are certain good inferences 
that are not syllogistically good. He says:
Th ere is another process which is oft en necessary, in the formation of the premises of a syllogism, 
involving a transformation which is neither done by syllogism, nor immediately reducible to it. 
It is the substitution, in a compound phrase, of the name of the genus for that of the species, 
when the use of the name is particular. For example, ‘man is animal, therefore the head of a man 
is the head of an animal’ is inference, but not syllogism. (114)
He says that this is an application of the dictum de omni et nullo,1 which he explains as:
dictum de omni et nullo  .  .  .  is as follows. For every term used universally less may be substituted, 
and for every term used particularly, more. (114–15)2
Th is principle will be discussed in section 7.5, where it will be seen to be a good one. 
However, the principle can only be used in reasoning when one can show that the term 
in question is indeed used universally, or used particularly. In the example cited by 
De Morgan, that is not at all trivial. In this section, we will see how to derive some 
1 Th e dictum de omni et nullo has been interpreted diff erently by diff erent writers over the centuries. 
De Morgan’s version is typical.
2 In De Morgan 1966 he repeats the point, saying “I gave a challenge in my work on formal logic to deduce 
syllogistically from ‘Every man is an animal’ that ‘every head of a man is the head of an animal’” (29; written 
in 1850). Th e same point is also made on page 216 (written in 1860). On page 252–3 (written in 1860) he sets 
a related but diff erent problem: “let Α be an existing animal; it follows that the tail of X is the tail of an animal,” 
and he says that the consequence is formal, not material.

relational expressions and de morgan’s challenge 
161
inferences of the kind that De Morgan is interested in. Later writers interpret the 
signifi cance of De Morgan’s challenge as one involving relational expressions (the 
relation “head of ” in the quotation from De Morgan). In fact, his challenge raises 
a number of diff erent issues. Since the example he himself gives is fairly complicated, 
I’ll start with a simpler example involving relations, and then turn to De Morgan’s 
specifi c example.
6.1.1 Dealing with explicit relational expressions
A typical illustration of how relational expressions interrelate with quantifi ers is the 
following valid argument:
Some A sees every B
∴ Every B is seen by some A
Th e argument is not reversible; the premise does not follow from the conclusion. 
Th is kind of argument uses an unanalyzed relational term, ‘sees,’ instead of the 
copula. Arguments of this sort are straightforward to deal with, not syllogistically, 
but using the logical techniques that Aristotle used to validate syllogisms together 
with some 13th-century doctrines about quantifi ers and singular terms. Here is 
a derivation for the argument in Linguish notation. One posits the premise, and 
then the negation of the conclusion to set up a reductio. Th e derivation appeals to 
Aristotle’s technique of exposition and universal application and then quantifi er 
equipollences and, fi nally, principles for permuting singular terms and negations 
(which are laid out in section 4.3).
1.
2.
3.
4.
5.
6.
7.
8.
9.
10.
11.
12.
13.
Premise
Hypothesis (for reductio)
2 quantifier equipollences
1 3 EX <line 1 guarantees non-emptiness of ‘B’>
1 3 EX <line 1 guarantees non-emptiness of ‘B’>
5 permute singular term
1 1 EX <line 1 guarantees non-emptiness of ‘A’>
1 1 EX < line 1 guarantees non-emptiness of ‘A’>
8 permute singular term
4 9 UA
6 7 UA
11 permute negation and singular terms
reductio; line 12 contradicts line 10
(Some A α)(every B β) α sees β
(every B β)(some A α) α sees β
not (every B β)(some A α) α sees β
(some B β)(every A α) not α sees β
(b γ)(· B β) γ is β
(b β)(every A α) not α sees β
(every A α)(b β) not α sees β
(a α)(· A β) α is β
(a α)(every B β) α sees β
(every B β)(a α) α sees β
(b β)(a α) α sees β
(a α)(b β) not α sees β
not (b β)(a α) α sees β
Attempting to derive the premise from the conclusion just results in a dead end. For 
a medieval type counterexample to inferring the premise from the conclusion, suppose 
that Plato and Socrates are all of the As and also all of the Bs. Suppose that Plato sees 
only Socrates, Socrates sees only Plato. Th en every B is seen by some A, but it’s not true 
that some A sees every B.

162 
some illustrative topics
applications
Produce the Linguish logical forms underlying the following arguments and 
(1) provide derivations to validate the good ones and (2) for the invalid ones, 
provide an argument with the same form having true premises and a false 
conclusion. (In the fi rst two arguments ignore the readings in which dogs are 
said to own or not to own women.)
 
Some woman owns no dog
∴ 
Every dog some woman doesn’t own
 
Every dog some woman doesn’t own
∴ 
Some woman owns no dog
 
Some animal is every phoenix
∴ 
Every phoenix is an animal
 
Every phoenix is an animal
∴ 
Some animal is every phoenix
6.1.2 Dealing with parasitic terms
De Morgan’s own example is diff erent from the one just given, because, as he says, 
it involves complex terms (“compound phrases”): ‘head of a man,’ ‘head of an animal.’ 
In contemporary logic this would not be considered a problem for logic, since such 
phrases do not occur in standard logical notation. If it is a problem, it is a problem for 
ordinary language, and the problem is to be solved by fi nding a way to mimic the logic 
of the complex term of ordinary language by using some combination of quantifi ers, 
connectives, etc. For example, one might decide to use a relational predicate, as in ‘x 
is-of y.’ Th en the ordinary language sentence:
every head of a man is a head of an animal
could be symbolized as:
∀x[head(x) & ∃y[man(y) & x is-of y] → head(x) & ∃y[animal(y) & x is-of y]]
or one could use the relational predicate ‘x is-a-head-of y,’ and write:
∀x[∃y[man(y) & x is-a-head-of y] → ∃y[animal(y) & x is-a-head-of y]]
Neither of these formulas contain any complex terms. Either of these can easily be 
deduced from the symbolization of ‘every man is an animal’:
∀x[man(x) → animal(x)].
In medieval logic there is no such clear distinction between what is ordinary lan-
guage and what is logical notation, and that is why I included complex terms in the 

relational expressions and de morgan’s challenge 
163
notation in section 5.8, so that ‘head of a man’ would be represented as the complex 
Linguish term ‘{head-of-α (· man α)},’ which is pronounced, as usual, by erasing 
logical notation: ‘head of a man.’ Using this notation, and taking the existence of 
a head of a man as an additional premise (since otherwise the argument is invalid), 
the derivation can be done using the principle for complex terms from section 5.7.3, 
as follows.
To show: (every {head-of-α (· man α)} β)(· {head-of-δ (· animal δ)} ε) β is ε
1.
2.
3.
4.
5.
6.
7.
8.
9.
10.
11.
12.
13.
14.
15.
16.
17.
18.
19.
(every man α)(· animal β) α is β
<{head-of-α (· man α)} is non-empty>
(every {head-of-α (· man α)} β)(· {head-of -δ (· animal δ)} ε) β is ε
not (every {head-of-α (· man α)} β)(· {head-of -δ (· animal δ)} ε) β is ε
(some {head-of-α (· man α)} β)(every {head-of -δ (· animal δ)} ε) not β is ε
(h β)(· {head-of-α (· man α)} ε) β is ε
(h β)(every {head-of-δ (· animal δ)} ε) not β is ε
(h β)(·man α)(· head-of-α ε) β is ε
(· man α)(· head-of-α ε)(h β) β is ε
(a α)(· head-of-α ε)(h β) β is ε
(a α)(· man β) α is β
(a α)(· animal β) α is β
(· animal α)(· head-of-α ε)(h β) β is ε
(h β)(· animal α)(· head-of-α ε) β is ε
(h β)(· {head-of-δ (· animal δ)} ε) β is ε
(every {head-of-δ (· animal δ)} ε)(h β) not β is ε
(h ε)(h β) not β is ε
not (h ε)(h β) β is ε
(h ε)(h β) β is ε         
3 Equipoll
2 4 EX
2 4 EX
5 complex term 2
7 permute
8 8 EX
8 8 EX
1 10 UA
9 11 ES
12 permute
13 complex term 2
6 permute
14 15 UA
16 permute
13 self-iden
17 18 reductio              
Although somewhat lengthy, there are no surprises. Relational notions, per se, are not 
problematic in medieval logic.
applications
Some of these arguments are valid. Produce the Linguish logical forms underly-
ing them and (1) provide derivations to validate the good ones and (2) for the 
invalid ones, provide an argument with the same form having true premises and 
a false conclusion.
 
Every woman is an animal
 
Some head of a woman is a head of a woman
∴ 
Some head of an animal is a head of a woman
 
Every woman is an animal
 
Some head of an animal is a head of an animal
∴ 
Some head of an animal is a head of a woman

164 
some illustrative topics
6.2 Buridan on subjects and predicates
In the original Aristotelian treatment, each proposition contains exactly one term used 
as subject and exactly one term used as predicate. In the expanded notation of medieval 
logic things become more complicated. Th e most sophisticated treatment of these 
complications is due to John Buridan. Th is section discusses some details of his views.
6.2.1 Identifying subjects and predicates
Th e logic that Buridan inherited contained a number of principles involving subjects 
and predicates of categorical propositions:
Quantity
A categorical proposition is universal, particular, indefi nite, or singular iff  its 
subject is universal, particular, indefi nite, or singular. So you have to be able to 
identify the subject in order to determine the quantity of the proposition.
Conversions
Conversions are the result of interchanging subject and predicate. So you have to 
know what the subject and predicate are to determine what a conversion is.
Syllogisms
Syllogistic inferences are given in terms of fi gures, and the fi gures are defi ned in 
terms of whether the middle term is a subject or a predicate. So you have to know 
what the subject and predicate are in order to apply the theory of the syllogism to 
particular examples.
Ampliations
Tenses and modal words and words about conceiving, etc, can alter what the 
terms in a proposition supposit for. (Chapter 10.) Medieval logicians agree that 
these aff ect subject and predicate terms diff erently. So you need to know what the 
subject and predicate are to know how ampliation works.
Th ese issues become interesting when categorical propositions get complicated. 
For example, what are the subject and predicate of ‘Every farmeracc some donkey sees’? 
(Buridan would say that this proposition contains a copula, ‘is,’ a subject, ‘donkey,’ and 
a predicate, ‘farmer seeing.’) We can get no guidance about subjects and predicates from 
contemporary logicians, because they have abandoned the notions of subject and 
predicate as understood by ancient and medieval logicians.3 But Buridan retained the 
notions of subject and predicate, and thought it vital to determine what these are in 
complicated cases. He also retained the idea that every categorical proposition consists 
of one subject and one predicate, together with the copula and some syncategorematic 
3 Frege, Begriff sschrift , Section 3: “A distinction of subject and predicate fi nds no place in my way 
of representing a judgment  .  .  .  In my fi rst draft  of a formalized language I was misled by the example of 
ordinary language into compounding judgments out of subject and predicate. But I soon convinced myself 
that this was obstructive of my special purpose and merely led to useless prolixity.”

buridan on subjects and predicates 
165
signs—and nothing else. Th us, when a proposition has more than two terms, either the 
subject or the predicate has to contain more than two terms. Th is is unproblematic 
when the extra terms get into the proposition as parts of complex terms. But there are 
propositions with more than two main terms. Examples are:
Of-every farmer some donkey is running
Some donkey every farmer seeing is
Of-every farmer some donkey sees every leg of-some horse
It is also necessary in identifying subjects and predicates that one be able to tell when 
a string of terms constitutes a single complex term (such as ‘leg of-some horse’ in our 
last example) and when not, and this can be diffi  cult as well.
Buridan defi nes a subject and predicate as follows: “A subject is that of which some-
thing is said; a predicate is that which is said of something else, namely, of the subject” 
(Buridan SD 1.3.3 (25)). Th is is too vague to be of much help in diffi  cult cases. Mostly, 
what Buridan does is to say what he thinks the right analysis into subject and predicate 
is in particular cases, sometimes with no argument at all, and sometimes by arguing 
that this yields the right answer as to which pairs of propositions are contradictories 
and which are contraries—generally assuming that such pairs contain the same units 
as subjects and as predicates (though, in the case of simple conversions, the units may 
switch from one to the other status). I will not try to review the reasoning that he gives 
(I fi nd much of it inconclusive). Instead, I will try to give a precise account of a method 
that agrees with his classifi cations, and then compare the results of applying this 
method with his own judgments in the cases that he discusses.
Th ere is one important constraint on any choice. A spoken or written proposition 
signifi es a mental proposition, and a mental proposition must consist of some simple 
concepts, which correspond to the subject and predicate of the spoken proposition, 
together with a complexive concept “by means of which the intellect affi  rms or denies 
the one of the other” (SD 1.3.2 (24)). Th e complexive concept corresponds to the 
copula4 of the spoken proposition. Th is is usually not helpful in detail, since if it is 
unclear what are the subject and predicate of a spoken proposition, we won’t know 
more about the mental one. But it does absolutely require that a categorical proposition 
have the copula ‘is’ as the verb, and have a unique subject and a unique predicate. 
Buridan says that in order to determine the subject and predicate of a proposition with 
a non-copular verb, one needs to re-express the proposition by replacing the verb 
with a copula and the participle of the verb. He also sometimes does this replacement 
without comment. I will follow him here, rephrasing when necessary so that all pro-
positions have the copula as their main verb.
Here is how to determine the subject and predicate of any categorical proposition. 
We begin by analyzing any verbs other than the copula into a copula and a participle, 
4 Th e copula of the spoken proposition, in simple cases anyway, is either the affi  rmative copula ‘is’ or the 
negative copula ‘is not’; these may be wholly or partly incorporated into another verb.

166 
some illustrative topics
as discussed in sections 5.2–5.3. Th en we “link” the main terms of the proposition with 
one another.
 • If a main term is in the genitive case then there is another term in the proposition 
that is related to the fi rst as possessed to possessor; when this is so, link those terms. 
(It may be a matter of interpretation which pairs are so related. If so, the proposition 
is ambiguous, and we need to consider its diff erent readings separately.)
 • If a main term is in the accusative case, this is because it is serving as the direct 
object of a transitive verb, which will appear in the proposition in participle form; 
link that term with the participle term as well. (Again, there may be more than one 
way to analyze the proposition.)
When no more linkings are possible, make sequences out of the mutually linked terms. 
(A sequence will have only one member if there is a term that is not linked to any 
other.) In any categorical proposition you will fi nd that you have exactly two sequences. 
Each sequence will contain exactly one term in the nominative case (it’s the rightmost 
term in the sequence). Th e subject will be the string of expressions formed from one of 
the sequences, and the predicate will be the other.
Which string is the subject, and which the predicate? One natural response might be 
that so long as the verb is the copula, there is no answer to this question, since, speaking 
logically, it treats its terms the same. A similar response is that such a proposition 
is ambiguous; it may be read with either term as grammatical subject and either term 
as predicate. At least, this is true when both terms are in the third person singular; 
in that case there is no grammatical diff erence between subject and predicate. But if 
the persons are mixed, there may be a grammatical diff erence. For example, these are 
grammatically diff erent propositions:
You are Marcus.5
Marcus is you.
In the fi rst proposition, ‘you’ is the subject, and in the second proposition ‘Marcus’ is the 
subject; you can tell this by the fact that the verb agrees with its subject in (grammatical) 
person. Th e same thing happens in Latin if you put the verb at the end:
Marcus you are.
Marcus you is.
(In English the latter is ill formed, but it’s OK in Latin.) One might think then that the 
same possibilities of grammatical analysis are possible if both terms are third-person:
Marcus Tully is   <‘Tully’ is subject.>
Marcus Tully is   <‘Marcus’ is subject.>
5 Buridan SD 4.2.6 gives the example ‘White am I,’ where the subject follows the predicate.

buridan on subjects and predicates 
167
Th is approach has the unintuitive consequence that all categorical propositions in the 
third person whose verb is ‘is’ are ambiguous. For example, ‘Every donkey is an animal’ 
can be read with ‘donkey’ as the subject and ‘animal’ as the predicate, or the other 
way round. Th is is contrary to the tradition, which tends to take the fi rst option for 
granted.
Th ere is a Buridanian tradition, explained in Karger 1997, which holds that when all 
terms are in the third person, the grammar works diff erently than when they are mixed. 
It holds in particular that such a proposition is unambiguous, and you can tell which 
(string) is subject and which is not by the rule that the subject string is that string 
whose nominative term precedes the nominative term of the other string. Th is has the 
advantage of yielding natural unique readings in simple cases, where authors seem to 
see no ambiguity.
Some examples to illustrate Buridan’s view about subjects and predicates:
Every donkey is an animal.
Subject = donkey   Predicate = animal
(No terms are linked. Th e subject is the term that comes fi rst.)
Of every farmer a donkey is running
Subject = of-farmer donkey   Predicate = running
(Th e fi rst two terms are linked; they precede the predicate term.)
Some donkeyacc every farmer is seeing
Subject = farmer   Predicate = donkeyacc seeing
Some donkey every farmeracc is seeing
Subject = donkey   Predicate = farmeracc seeing
(Th is proposition is ambiguous in English because either term can be the seer. In 
Latin the nouns would have observable case infl ections which would oft en eliminate 
any ambiguity.)
6.2.2 Subjects and predicates in Linguish
In this section we formulate precise criteria for identifying subjects and predicates in 
Linguish propositions, and in the surface sentences that are generated from them.
Some observations: When we build up any proposition in Linguish whose main 
verb is ‘is’ we begin with a copular formula with exactly two free markers, say α and β. 
Th ere are two ways of making a propositional formula ϕ into a more complex categorical 
formula. One way is to add a not, which leaves the free markers unchanged; that is, the 
free markers in not ϕ are the same as those in ϕ. Th e other way is to add to ϕ a denoting 
phrase, D, which binds one of the free markers in ϕ. If D itself contains no free marker, 
the number of free markers in Dϕ will be one less than the number in ϕ. If D contains 
a free marker (as it will if its main term originates from a (participle of a) transitive 
verb, or is the “object” of a genitive denoting phrase) the number of free markers in Dϕ 

168 
some illustrative topics
will be the same as the number in ϕ. So the total number of free markers is never more 
than two, and it eventually reaches zero when we end up with a proposition (which by 
defi nition has no free markers).
To generate Linguish subjects and predicates: Given a Linguish categorical proposi-
tional logical form ϕ, make a sequence of denoting phrases starting with the fi rst main 
denoting phrase, D, in ϕ. Th e next member of the sequence is whatever denoting 
phrase, if any, contains a free marker that is bound by D. Continue this process. Th e last 
member of this fi rst sequence is whatever member binds a marker in the copular 
formula itself. Th en form another sequence starting with the fi rst denoting phrase in ϕ 
that is not in the fi rst sequence. It is easy to show that for any categorical proposition 
ϕ exactly two sequences may be formed in this way, and every main denoting phrase 
in ϕ is a member of exactly one of them. (Th is yields essentially the same sequences as 
discussed earlier for natural language examples.)
I will stipulate that the sequence whose last term binds the marker preceding the 
copula is the subject sequence, and the other is the predicate. Th is seems like a funda-
mental assumption of how the markers used as indices of grammatical position work. 
If we also wish to go along with Buridan and avoid the ambiguity of surface sentences 
with regard to subject and predicate discussed in the last section, we can additionally 
stipulate that the term binding the subject marker must precede the term binding the 
predicate marker. Th at is, the Linguish logical form is ill formed when the term binding 
the subject marker follows the term binding the predicate marker. I’ll suppose that this 
stipulation is in eff ect for the purpose of discussing examples in this chapter. Th is issue 
will re-arise in Chapter 10.
Some examples follow in which the subjects and predicates are identifi ed. We 
express what the subject and the predicate are using ordinary language terminology, 
as Buridan does. Th is can be done by fi rst taking the Linguish subjects and predicates 
and applying our previously given rules for generating natural language. Th en we 
eliminate the commas that punctuate the sequence, and also erase all overt quantifi er 
signs:
(Every donkey α)(· animal β) α is β
Every donkey is an animal
Subject: 
(Every donkey α)
 
Every donkey
 
donkey
Predicate: 
(· animal β)
 
an animal
 
animal
(Every farmer α)(some donkey-poss-α β)(· running-thing γ) β is γ
Of-every farmer some donkey a running-thing is
Of-every farmer some donkey is running

buridan on subjects and predicates 
169
Subject: 
(Every farmer α), (some donkey-poss-α β)
 
Of-every farmer, some donkey
 
of-farmer donkey
 
(or: farmer’s donkey)
Predicate: 
(· running-thing γ)
 
running-thing in English; running in Latin.
(Some donkey α)(every farmer β)(· seeing-α-thing γ) α is γ
Some donkeyacc every farmer a seeing-thing is
Subject: 
(Every farmer β)
 
every farmer
 
farmer
Predicate: 
(some donkey α), (· seeing-α-thing γ)
 
some donkeyacc, seeing-thing
 
donkeyacc seeing-thing
applications
Determine the subject and predicate of the Linguish logical forms underlying 
each of the following propositions.
Buridan is no fool.
Some horse sees a donkey.
Every farmer’s donkey sees a horse’s leg.
Every farmer’s donkey sees a leg of a horse.
Every farmer which owns a donkey owns an animal.
6.2.3 Agreeing with Buridan (mostly)
Here I review some judgments that Buridan makes about the subjects and predicates 
of categorical propositions, and some of his reasons. Th e examples are mostly from 
Buridan SD Treatise 1, Chapter 3. (Unless otherwise noted, our theory agrees with 
Buridan’s opinions.)
Buridan considers the view that the subject and predicate in
(1) A man runs
are ‘man’ and ‘runs,’ and rejects that answer. He says “the verb is not the predicate, 
strictly speaking.” Instead, an intransitive verb needs to be analyzed into the copula 
plus a participle, as in ‘A man is running.’ In ‘a man runs,’ ‘man’ is the subject and 
‘running’ is predicated (SD 1.3.2 (22)).

170 
some illustrative topics
Th e analysis of an intransitive verb into a copula plus participle applies also to any 
use of ‘is’ as “second adjacent,” as in
(2) A man is
where the verb needs to be analyzed into a copula and participle, as in ‘A man is [a] 
being’ (SD 1.3.2 (22)).
Buridan considers (SD 1.3.2 (22))
(3) Th e one lecturing and disputing is a master or a bachelor
which he classifi es as categorical, having complex subjects and subjects which are 
made using connectives. We have not implemented these in Linguish, but if we did so 
the natural way of doing so would probably agree with Buridan.
Buridan considers
(4) A man who is white is colored
and judges that its subject is ‘man who is white’ and its predicate is ‘colored’ (SD 1.3.2 (23)). 
Th is agrees with our account which would generate the sentence and analyze it as:
(· {man whoα (· white β) α is β} γ)(· colored δ) γ is δ
A man who white is colored is
A man who is white is colored
Subject: 
(· {man whoα (· white β) α is β} γ)
 
man who white is
 
man who is white
Predicate: 
(· colored δ)
 
colored
Buridan claims that
(5) A man is colored, who is white
is not a categorical proposition at all, because it contains two main verbs. (Th is propo-
sition contains a non-restrictive relative clause. Our analysis does not apply to it.)
In the inherited tradition, categorical propositions are classifi ed in terms of quantity: 
universal, particular, indefi nite, or singular. When subjects are sequences of terms, 
things are more complicated. Buridan decides that a proposition can have more than 
one quantity; e.g. it may be universal with respect to one term and particular with 
respect to another. In discussing one example he says:
in the divided sense it is partly universal and partly indefi nite, for not the whole subject is 
distributed, but one part is distributed while the other part remains indefi nite. And this is not 
unacceptable concerning propositions whose subjects are composed of several substantives, 
whether in the nominative or in any of the oblique cases, as in ‘Every-man’s donkey runs’ 
[cujuslibet hominis asinus currit—‘Of every man a donkey runs’] or even in ‘A man’s every 

buridan on subjects and predicates 
171
donkey runs’ [hominis quilibet asinus currit]; for the fi rst is universal with respect to its oblique 
term and indefi nite with respect to its nominative term, while the second is the other way round. 
Th e proposition ‘Every man’s-donkey runs’ [quilibet hominis asinus currit] is absolutely universal, 
however, for its total subject is distributed together; and the same goes for the proposition ‘Every 
donkey of a man runs’ [quilibet asinus hominis currit], for they are equivalent, both with respect 
to grammaticality, as far as grammar is concerned, and with respect to truth and falsity, as far as 
logic is concerned. (SD 1.3.3 (27))
Our theory analyzes these sentences as follows:
(6) Of every man a donkey runs
(every man α)(· donkey-poss-α β)(· running-thing γ) β is γ
of-every man a donkey a running-thing is
of-every man a donkey runs
Subject: 
(every man α), (· donkey-poss-α β)
 
of-every man, a donkey
Predicate: 
(· running-thing γ)
 
running-thing 
English
 
running 
Latin
Th e subject has two parts. Th e fi rst is preceded by ‘every’ and so Buridan says that the 
proposition is universal with respect to it (with respect to the oblique term) and 
the second is preceded by ‘·,’ so the proposition is indefi nite with respect to it (to the 
nominative term). He compares this to the similar sentence:
(7) Of a man every donkey runs
which is like the fi rst but with its quantifi er signs reversed, and he naturally classifi es 
this as “the other way round.”
He compares those two with the structure:
(8) Every man’s-donkey runs
He says that in this case the proposition is universal because its total subject is. And 
he says the same of
(9) Every donkey of a man runs
In fact, he says that these propositions are both grammatically and logically the same. 
Our analysis generates these propositions from equivalent Linguish sources, given 
in section 5.8.3, validating his claim that the propositions are logically equivalent. 
One is:
(Every {(· man α) donkey-poss-α}} δ) δ runs
Every man’s donkey runs

172 
some illustrative topics
or:
Every donkey of-a man runs
Th e other:
(Every {donkey-poss-α (· man α)}} δ) δ runs
Every donkey-poss-a-man runs
Next example: Buridan says that in
(10) [A] man’s donkey runs
the whole phrase ‘man’s donkey’ is the subject. Th is could be generated exactly the same 
as the previous example, except for having an indefi nite quantifi er instead of the ‘every.’ 
Th at would yield:
(· {(· man α) donkey-poss-α} δ) δ runs
A man’s donkey runs
Th e subject is obviously ‘man’s donkey.’ However, it could also be generated from the 
form:
(· man α)(· donkey-poss-α δ) δ runs
Of-a man a donkey runs
Our theory says that the subject of this sentence is:
of-a man donkey
Th ese are diff erent constructions. Th e two are logically equivalent, but they are diff erent. 
Because there are no articles in Latin, the surface sentences are the same in Latin. Th is 
may be a case in which the lack of articles in Latin covers up a logical phenomenon. 
I am not sure of the signifi cance of this.
Buridan’s reason for classifying ‘man’s donkey’ as the subject is “it is obviously of this 
whole phrase that the predicate ‘running’ is predicated by the mediation of the verb ‘is’ 
implied in the verb ‘runs’ ” (SD 1.3.3). I guess this is obvious. In any event, our theory 
predicts it.
Contrasted with this is the proposition
(11) Every horse a man is seeing
whose subject Buridan says is ‘man’ and whose predicate is ‘horse seeing.’6 Our analysis 
would be:
6 Buridan SD 1.3.3: Buridan also discusses the very same example at 4.2.6 (245) in which he identifi es 
the predicate as ‘[someone] seeing [a] horse’; he argues that these ingredients go together because “the deter-
mination should be united with its determinable.” Th e theory I have given does not produce that order from 
the sentence ‘Every horse a man is seeing.’ Apparently Buridan is casual about the ordering of the parts of 
a subject or a predicate if the orderings are logically equivalent.

buridan on subjects and predicates 
173
(every horse α)(·man β)(·seeing-α-thing γ) β is γ
every horseacc a man a seeing-thing is
every horseacc a man is a seeing-thing
every horseacc a man is seeing
Th e subject is: (· man β)
man
Th e predicate is: (every horse α), (· seeing-α-thing γ)
horse, seeing
horse seeing
Buridan notes that part of the predicate, namely ‘horse’ is placed before the verb, and 
indicates that this is OK. In fact, he notes, sometimes the whole predicate occurs before 
the verb, as in ‘every man an animal is’ or ‘every man an animal is not’ (SD 1.3.3).
Buridan also opines that infi nitizing negations are always integral parts of the 
subjects or predicates of propositions (SD 1.3.3). Th is also falls out of our analysis, 
simply because the only elements that are not included in the subject and predicate 
are the copula, negation, and the quantifi er signs, and ‘non-’ cannot be a part of any 
of these.
6.2.4 Th e asymmetry of subjects and predicates
Buridan has another view in addition to those discussed already. He believes that parts 
of predicates that occur to the right of the verb are to be treated diff erently from the 
parts of those predicates occurring to the left  of the verb. (Th is has not been relevant 
so far.) Th is happens in two ways.
6.2.4.1 way 1: quantifier signs
First, he says that the parts of the predicate that occur to the right of the verb are to 
include their quantifi er signs. His reason for this is his view that contradictories should 
have the same predicate. And the following are contradictory:
Every man is every man
Some man isn’t every man
likewise for:
No man is no man
Some man is no man
Th is is odd reasoning because if you leave off  the quantifi er signs in the predicate 
the contradictories already have the same predicates, so he has not given examples 
that illustrate what he is trying to show. Also, his general principle that contradictories 
must have the same predicates is violated in the simplest of cases, for, since these are 
contradictories:

174 
some illustrative topics
No S is P
Some S is P
so are these by simple conversion:
No S is P
Some P is S
Probably Buridan has more in mind than I have interpreted him as saying. A clue may 
come from his discussion of conversion. He discusses the following principle of simple 
conversion:
the sign of quantity in the subject of the proposition to be converted has to be added to the predi-
cate and the resulting whole has to be placed on the side of the subject, for example: ‘Some man is 
an animal; therefore, some animal is a man.’ (SD 1.6.5 (56))
Th is leads to an objection:
it was said earlier, and it is commonly held, that the whole which is placed on the side of the 
predicate is an integral part of that predicate (for example, if I say ‘Some man is some animal.’ 
the whole phrase ‘some animal’ is the predicate, and similarly if I say ‘No man is no animal.’ the 
whole phrase ‘no animal’ is the predicate); therefore, when adding the sign of the subject to the 
predicate, in performing the conversion we are committed to saying ‘Some some animal is a man’ 
and ‘No no animal is a man.’ (SD 1.6.5 (56))
Clearly this incongruity could be avoided by retracting the view that a predicate 
to the right of the copula contains its own quantifi er signs as part of it. Buridan 
does not do this. Instead, he argues that the form of conversion sometimes needs 
to be altered:
Solution: I say that if this appears to be an unacceptable locution, then in such a case conversion 
may take place by applying the name ‘which’ [quod]. For example, ‘Some man is some animal; 
therefore, something which is some animal is a man.’ and similarly ‘No man is no animal; there-
fore, nothing which is no animal is a man.’ ”7 (SD 1.6.5 (56))
Th is shows that he is consistent in his thinking about the ingredients of predicates. But 
the argument is not very informative, since conversion only holds for some forms of 
propositions, and it is not clear whether the propositions he considers are ones for 
which conversion should hold.
In general, I have ignored this view of Buridan’s. In fact, it’s hard not to ignore it, 
since apart from conversions, whether a quantifi er sign is part of a predicate doesn’t 
seem to interact with any other logical issues. Th is is because none of our rules of infer-
ence or semantic principles employ the notions ‘subject’ or ‘predicate.’ (Th is will change 
in Chapter 10.)
7 Introducing a relative clause in this way was quite common in discussions of conversions of complex 
propositions.

buridan on subjects and predicates 
175
6.2.4.2 way 2: negative signs
Buridan holds that if a negative sign comes aft er the verb then it cannot actually be 
negating; it must be “infi nitizing” (see section 3.5). For example, if the Latin phrase ‘non 
homo’ comes aft er the copula, then it cannot be interpreted as ‘not a man’; it must be 
interpreted as ‘a non-man.’ Th is view is problematic in part because it is incompatible 
with applications of the patterns of quantifi er equipollences. He explains his view 
when commenting on the equipollence rules that lead to these consequences:
Th erefore ‘Nothing is nothing’ is equipollent to ‘Anything is something’, for, by the second rule, 
‘Nothing  .  .  .  is not  .  .  .’ is equivalent to ‘Anything’, just as ‘None  .  .  .  is not  .  .  .’ is equivalent to 
‘Everything,’ and, by the fi rst rule, ‘Not nothing’ and ‘Something’ are equipollent. (SD 1.5.5 (47))
Buridan thinks those conclusions are, strictly, wrong when one of the negation signs 
follows the copula:
But if the second negation does not precede the copula, then the rule is not formally valid. For 
the one is then negative with an infi nite predicate, as with ‘Nothing is nothing’ or ‘No chimera is 
no chimera,’ and the second then is affi  rmative with a fi nite predicate, as for example, ‘Anything 
is something’ or ‘Every chimera is some chimera,’ and such are not convertible between them-
selves, except supposing the constancy of terms. For the proposition ‘No chimera is no man’ 
is true, since its contradictory ‘Some chimera is no man’ is false, for it is an affi  rmative whose 
subject supposits for nothing; and the proposition ‘Every chimera is some man’ is false; there-
fore this consequence is not valid: ‘No chimera is no man; therefore every chimera is some man’ 
for a falsity does not follow from a truth. But the consequence would be valid assuming 
the constancy of its terms, namely, that each of the terms did in fact supposit for something. 
(SD 1.5.5 (48))
Th e negative signs ‘no’ and ‘not’ in the equipollence rules are understood to be negating. 
But on Buridan’s view, a proposition that appears to have a negative sign ‘no’ aft er the 
verb, as in ‘Some A is no B,’ does not really contain a negative sign; as a result, it is not 
of a form where the equipollences apply. If you do apply the equipollences to get ‘Some 
A is not some B’ then you either get an ungrammatical proposition, since ‘not’ may 
not immediately follow the copula in Latin, or the proposition is equivalent to ‘Some A 
not is some B’ which is not equivalent to the original sentence, because the original 
sentence is affi  rmative (the ‘no’ occurs aft er the verb, and so it does not make the pro-
position negative) and the resulting proposition is negative (the ‘not’ occurs before 
the verb).
Th e common view is that the Latin word ‘non’ can combine with a term to form a 
complex term, and when it does this it is called infi nitizing negation. But Buridan is 
here discussing the quantifi er word ‘no’ (Latin, ‘nullus’). So his view needs to be fl eshed 
out with an explanation of what it means for a ‘no’ to be infi nitizing. We get such 
an explanation—or at least an illustrative example—at SD 4.2.2 (230):
as regards ‘nobody’ and ‘nothing,’ we should hold that a negation following the copula of a 
proposition cannot constitute a negating [i.e. propositional] negation, but only an infi nitizing 

176 
some illustrative topics
[i.e. term-]negation, which infi nitizes the term to which it is prefi xed. Hence the proposition 
‘A stone is no man’ is affi  rmative with an infi nite predicate term and is equivalent to ‘A stone is 
a non-man’; for an infi nitizing negation is quite correctly [taken to be] a part of the subject or of 
the predicate term.
Th e pattern seems to be that aft er the copula we analyze ‘no F’ as ‘a non-F.’ (And we 
analyze ‘not an F’ as ‘a non-F.’) In the example Buridan gives, this seems unproblematic; 
‘A stone is no man’ does seem to say about the same as ‘A stone is a non-man,’ the only 
diff erence being that the former appears to be negative, and so true if there are 
no stones, and the latter is affi  rmative, and so false if there are no stones. I don’t see 
how one could argue this one way or the other. However, things change if the verb is 
something other than the copula. Consider
Socrates sees no donkey
i.e. replacing the verb with the copula plus participle:
Socrates is seeing no donkey or Socrates is no donkey seeing
Th e pattern just mentioned would analyze this as
Socrates is seeing a non-donkey or Socrates is a non-donkey seeing
But if Socrates sees both a donkey and a horse, ‘Socrates sees no donkey’ is clearly false, 
and ‘Socrates is seeing a non-donkey’ is clearly true, quite apart from issues of affi  rmative 
and negative. So the pattern breaks down here.
Unfortunately, I do not know why Buridan holds the view he does. More work needs 
to be done on this matter. I will ignore it in further discussion here.
6.3 Simple and complex terms
Previous discussion has all been based on the assumption that one can tell what the 
main terms of a categorical proposition are. In Linguish notation this is easy: A main 
term is any term that does not occur within curly brackets. But in Latin the problem is 
not so clear. Some substantial discussion went into this question. I begin with some 
problematic sentences and how they were viewed. Th en I turn to a general theory.
6.3.1 Some interesting constructions
(Th is subsection uses some of the terminology of the theory of modes of supposition, 
which is presented in Chapter 7. Most of the discussion can be followed without reading 
that chapter, but some details will need fi lling in.8)
8 Roughly, a mode of supposition is a kind of quantifi cational status. Determinate supposition ≈ 
Existentially quantifi ed with wide scope; Merely confused supposition ≈ Existentially quantifi ed with scope 
inside a universal; Distributive supposition ≈ Universally quantifi ed.

simple and complex terms 
177
Paul of Venice, in a discussion of what we would call truth conditions of propositions 
with multiple quantifi ers, discusses the proposition (LM, Tractatus on Terms, chapter 4 
in Kretzmann 1979, 257–9):9
Of-every man a donkey runs
or
Every man’s donkey runs
He suggests that the proposition is ambiguous. Th ere are two interpretations:
(1) ‘donkey’ belongs to the predicate
On this interpretation, the proposition is universal; ‘man’ has distributive supposition; 
‘donkey’ has merely confused supposition. Th e proposition means that for every man 
there is a donkey of his that runs.
(2) ‘donkey’ belongs to the subject
On this interpretation, the proposition is indefi nite; ‘man’ has distributive supposition; 
‘donkey’ has determinate supposition. He says that in this case, the proposition is 
equivalent to: a donkey of every man runs.
(Th e notion of subject and predicate used here are not Buridan’s. For Buridan, 
‘donkey’ will belong to the subject on any reading.)
Understood in the fi rst way, the sentence has two main terms: ‘man’ and ‘donkey,’ and 
they are not part of a single complex term; understood in the second way, the sentence 
has one main term, the complex term ‘every man’s donkey.’
Using our formulation of Linguish, the sentence may be generated in two diff erent 
ways. One way corresponds to (1):
(1′) (every man α)(· donkey-poss-α β) β runs
of-every man a donkey runs
or:
Every man’s donkey runs
On this construal, ‘man’ has distributive supposition, and ‘donkey’ is merely confused, 
as Paul says. (Or ‘donkey’ would have merely confused supposition if it were not for the 
fact that it is here a parasitic term, and parasitic terms do not have modes of supposi-
tion. See section 7.4.)
9 Th e Latin version is ‘Cuiuslibet hominis asinus currit.’ Th e translator translates the genitive as ‘belonging 
to’; I have changed this to ‘of ’; also, he translates ‘currit’ as ‘is running’, instead of ‘runs’ as I have it. Th is is 
arguably better than ‘runs’ in terms of capturing its meaning, so long as the ‘is running’ is read in English as 
the present progressive form of the verb ‘run.’ One must avoid interpreting it as the English translation of ‘est 
currens,’ which is held by logicians to be the copula followed by a substantive common term (a participle). 
Note that ‘every’ is in the genitive case, so it goes with ‘man’ and not with ‘donkey.’ So the sentence does not 
permit a reading that says roughly ‘Every belonging-to-a-man donkey runs.’

178 
some illustrative topics
Th e other way of generating the sentence corresponds to (2):
(2′) (· {(every man α) donkey-poss-α} β) β runs
An of-every man donkey runs
or
An every man’s donkey runs
(Note that in Latin, without an indefi nite article, the two surface sentences are 
identical.) For English the fi rst wording is not grammatical. Th e second probably isn’t 
either, though it seems to make sense to me, and to give one of the meanings of the 
corresponding Latin (which transliterates into ‘Every man’s donkey runs’). With this 
structure, the proposition is indefi nite, as Paul says. Th e complex term ‘every man’s 
donkey’ ({(every man α) donkey-poss-α}) has determinate supposition. On the popular 
view that the supposition of a complex term is also attributed to its head noun (see 
section 7.6.1 on modifi ed supposition), ‘donkey’ would be said to have determinate 
supposition, as Paul says. And ‘man’ has distributive supposition here. Th is is because, 
given that a donkey owned by every man runs, then a donkey owned by this man runs, 
for any man:
(· {(this man α) donkey-poss-α} β) β runs, and
(· {(that man α) donkey-poss-α} β) β runs, and
(· {(that man α) donkey-poss-α} β) β runs, and
.  .  . and so on for every man
Paul notes further that understood in way (2) the following propositions are not 
contraries, but subcontraries:
Of-every man a donkey runs
Of-every man a donkey does not run
Th ey aren’t contraries because both propositions would be true if there were two 
donkeys, each owned by every man, one of which runs and one of which doesn’t. Th ey 
are subcontraries because if the former is not true, either there is a donkey owned by 
every man, but no such donkey runs, and this will make the latter true, or there isn’t 
a donkey owned by every man, in which case the latter (which is negative) is vacuously 
true. He also states that these are logically independent of one another (still reading the 
constructions in way 2):
Of-every man a donkey runs
Of-some man a donkey does not run
Th is seems right to me. It holds for their Linguish logical forms. William Sherwood 
(S I.15) discusses the same example (‘Every man’s donkey runs’), though I am not cer-
tain what he has to say about it. My impression is that he denies that the second way of 
interpreting the proposition is a possible interpretation of it. (Th is is what Kretzmann 

simple and complex terms 
179
says in a footnote.)10 Th is interpretation is uncertain because soon aft er this point (at 
S I.20) he gives another example which seems to have exactly the same grammatical 
structure so far as the initial portion of the proposition is concerned, and he takes it to 
be ambiguous. His example diff ers only in that he uses the relational noun ‘possessor’ 
instead of the non-relational term ‘donkey’:
Every head’s possessor is only one head’s possessor
He holds that this proposition is ambiguous, and that it is true on one reading and 
false on another:
‘Every head’s possessor is only one head’s possessor’ (omne caput habens est unum solum caput 
habens) (where the word ‘every’ is taken accusatively11 and as attached to ‘head’ rather than to 
‘possessor’) is proved as follows: ‘this head’s possessor [is only one head’s possessor]’ and so on with 
respect to the single things. But on the contrary, an opposite is here predicated of an opposite, and 
so the locution is false.
 It must be said that the word ‘possessor’ in the subject can either be compounded with the predicate 
or divided [from it], but it is always named under one and the same construction. If it is com-
pounded the locution signifi es that the force of the distribution extends to the predicate as well as 
to the subject. In that case the phrase ‘only one [head’s possessor]’ in the predicate is [merely] 
confused, and it is not true, as was claimed above, that an opposite is predicated of an opposite. If 
it is divided the division signifi es that the force of the distribution does not go over to the predicate, 
in which case the phrase ‘only one [head’s possessor]’ is not confused [but determinate] and the 
locution is false. (S I.20, p. 38)
Th is appears to be the same as Paul’s analysis of the similar example given earlier, with 
the compounded reading being way (1) and the divided reading being way (2). (When 
he says “the force of the distribution does not go over to the predicate” this means that 
the scope of the universal quantifi er does not include the predicate.)
Notice that the examples we are discussing are ones in which a certain string of 
words, ‘every man’s donkey’ or ‘every head’s possessor’ can be taken either as consisting 
of two simple main terms, each having scope over the remainder of the sentence, or as 
a single complex main term containing a universal quantifi er whose scope is confi ned 
10 Sherwood says: “Suppose that each man owns one ass and it is running, and that Brownie is the ass they 
own in common and it is not running. Th en each man’s ass is running. But whatever is each man’s ass is 
Brownie; therefore Brownie is running—because the supposition of the word ‘ass’ is changed in a similar way.
Nevertheless, some maintain that these expressions are ambiguous in that the locution can be judged 
either in connection with the subject of the locution or in connection with the subject of the attribution. 
(Th ey call the nominative itself the subject of the attribution and the oblique case itself the subject of the 
locution, but others name them the other way around.)
But this is nothing, because when the phrase ‘each man’s’ precedes the word ‘ass’ it has power over it (i.e. the 
nominative), and so the locution is to be judged in relation to it (i.e. the [distributive] sign). It is not a func-
tion of the discourse that it is judged this way or that way, but a function of ourselves only” (Sherwood S I.15).
11 A literal translation of the Latin example would be ‘Every head possessing is one only head possessing’ in 
which ‘every head’ is taken accusatively because it functions as the direct object of the participle ‘possessing.’ 
Kretzmann changes ‘possessing’ to ‘possessor’ to produce a more natural English sentence, and this is why 
‘every head’ is in the genitive case in the translation.

180 
some illustrative topics
to the complex subject term. As we will see in the next subsection, some theorists tried 
to develop a theory that would systematize the question of how to tell when we have 
two simple terms versus when we have a single complex term.
6.3.2 Simple and complex terms
Buridan is one of several logicians to concentrate on the logical structures of categorical 
propositions containing more than two terms. His work is part of a tradition that con-
tinued for centuries. Th at tradition includes a general theory of what those structures 
are. Th is section discusses that general theory.
All of the historical information in this section and much of the analysis is based on 
the very useful paper, Karger 1997.
As I understand the theory, it contains instructions for how to tell when two con-
tiguous terms, or a term and a contiguous grammatical expression, are part of a single 
complex term, and when not.
Th e theory begins with a grammatical task, which is to identify when two terms 
bear a certain relation to one another; this relation is summed up by saying that one of 
them is a determinable, and the other is a determinant of that determinable. Examples 
are a common noun and an adjective modifying (and “determining”) it, a term in 
the genitive case determining (“possessing”) another term, a term in the accusative 
case being the direct object of (and thereby determining) a present participle, and 
so on. Th ese relations are all grammatical, and the theory supposes that they are all 
identifi able by grammatical means. Sometimes the surface form of a proposition can 
be analyzed in diff erent ways vis-à-vis what determines what; in such a case the propo-
sition is grammatically ambiguous, and we are to apply the theory to be presented 
shortly to each of its readings.
Determinable/determinant pairs are of two sorts. One sort contains determinants 
that must grammatically follow the term that they determine. Th e three examples 
of this that Karger culls from the theory are: the relation of an adjective (including 
a participle) to the preceding noun that it modifi es (which is the normal position for 
such an adjective in Latin), the relation of a relative clause to the noun that it modifi es, 
and the relation of a complex phrase which “may be regarded as derived from a relative 
clause by substituting for the [relative] pronoun and the verb a participle of that 
verb (as in ‘man seeing every horse’).”12 (Th at is, we regard ‘man seeing every horse’ as 
generated from ‘man who sees every horse’ by replacing ‘who sees’ by ‘seeing.’)
Th e other sort of determinable/determinant pair may occur in either order in 
a proposition. Such a pair either consists of a term in the genitive case determining 
the other term, which is what I have elsewhere called the (grammatical) possessed 
term, or it consists of a term in the accusative case determining the other term, which 
is a participle, by being its direct object.
12 My terminology diff ers from Karger’s. She uses ‘complex term’ to stand for a string of terms; these may 
or may not themselves be part of a larger term. I instead use ‘complex term’ only for a string that itself forms a 
term. When a complex term in her sense is “taken as one” then it does indeed form part of a single complex 
term in my sense. When it is “taken as several” it does not.

simple and complex terms 
181
6.3.2.1 the first type of determinable/determinant pairs
Regarding the fi rst type of combination, Karger says:
In terms of the fi rst type, the determinant necessarily follows the determinable. Whenever such 
a term forms the subject of a basic categorical, it is taken as one. In the sentence “a man seeing 
every horse is an animal,” for example, the subject “man seeing every horse,” which is a term 
of that type, is taken as one. [Underlined terms are in a grammatical case other than the 
nominative.] (1997, 68)
Karger here uses ‘term’ to include phrases that are potentially either a single term or 
more than one term in a row. To say that the “term” is taken as one amounts to saying 
that it forms a single complex term in my sense. One can show that the Linguish forma-
tion rules given in Chapters 4 and 5 produce this result. Except for a change in the 
position of the verb, surface sentences generated by logical forms of Linguish have 
their words in exactly the same order as their occurrences in the logical form. So I can 
concentrate on those forms. Th ey are:
Adjective + noun: Th e only way provided in Linguish for an adjective to modify a 
noun is for it to be generated by the rule for making complex terms (section 5.6.1), 
which has the adjective following the noun.
Common term + relative clause: Th ese combinations can only be formed into a 
single term (section 5.7).
Phrases like ‘man seeing every horse’: Th ese phrases are defi ned in section 5.6.2. 
Th ey are all complex terms.
6.3.2.2 the second type of determinable/determinant pairs
Regarding constructions of the second type, Karger says:
In complex terms of the other type, the determinant may follow or precede the determinable. 
Th ese terms form the sensitive and interesting cases. When used as subject of a basic categorical, 
a complex term of that type is, in some cases, taken as one, in others, severally. According to the 
Hagenau commentary, the rule is as follows.
If the determinable precedes the determinant or if the determinant precedes the determinable 
both terms being preceded by a sign of quantity which agrees grammatically with the deter-
minable, the complex term is taken as one. In all other cases, i.e. if the determinant precedes 
the determinable and is not preceded by a sign of quantity agreeing with the determinable, the 
complex term is taken severally.
Th e examples given of cases where the complex term, subject of the sentence, is to be taken as 
one are: “a donkey of-a-man runs” and “every of-a-king animal runs.” Th e example given of a case 
where the component parts of the term are to be taken separately is: “of-a-man a donkey runs.” 
(1997, 68)
Recall that these are cases in which the determinant is a genitive whose “possessed” 
is the other term, or the determinant is in the accusative case and is the direct object 
of the other term, which is a present participle.

182 
some illustrative topics
It is easy to see that when either of these kinds of pair occurs in the Linguish logical 
form and the determinant follows the determinable the two terms must be part of a 
single complex term. Th is is because for these pairs the determinable is a parasitic term 
with a free marker that needs to be bound by the (denoting phrase containing the) 
determinant. If the terms are taken as independent, with the determinant occurring 
second, there is no way for it to bind the marker in the determinable. So the only option 
is for them to combine by means of a rule for producing complex terms.
It is also clear that when the determinant precedes the determinable and both terms 
are preceded by a quantifi er sign agreeing with (and construed with) the determinable, 
then the terms must be taken as one. For this is the only way that anything at all 
(the determinant, in this case) can get in between a quantifi er sign and its term (the 
determinable, in this case).
It is also clear that when the determinant precedes the determinable, then it is 
possible for those terms (actually, their denoting phrases) to be independent. For then 
the determinable with its free marker falls within the scope of the determinant, which 
binds that marker. Th e rule cited earlier says that this is the only way for things to be. 
However, our rules for constructing complex terms allow the formation of complex 
terms consisting of a term in the genitive or accusative case binding a marker in the 
determinable. So our rules are more liberal than the opinion in the text. In fact, this is 
a matter on which medieval authors disagreed. If we recall the previous section, we fi nd 
there two examples of the sort we are discussing here. And both Paul of Venice and 
William Sherwood hold that it is possible to understand the construction as a single 
complex term. My linguistic instincts go along with Paul and William here, so I am 
inclined to be satisfi ed with the fact that the Linguish construction rules permit these 
structures. I am not aware of any argument against the existence of such constructions, 
and so I will leave the issue there.
I have been discussing cases in which the verb occurs at the end of the proposition. 
Th e rules that Karger cites also specify that:
If the verb comes between two terms, they must not be taken as making up one 
complex term.
Th e Linguish construction rules agree with this. Th e verb always starts out at the end, 
and it moves toward the beginning only by permuting with a contiguous term. I under-
stand that if a verb is contiguous with a complex term, it is not thereby contiguous with 
any of its parts. As a result, a verb can never move into a complex term.
One more part of the rules cited by Karger is not accommodated here. Following 
Buridan, these authors hold that when the terms in question are part of the predicate, 
and when they occur to the right of the verb, they are always taken to be parts of a 
single complex term. Th is is an extension of Buridan’s idea that any negation occurring 
to the right of a verb must be infi nitizing, and not negating. As with Buridan’s views on 
negation, the Linguish rules do not treat words or phrases diff erently when they follow 
the verb than when they precede it. It would be easy enough to invoke Buridan’s ideas 

simple and complex terms 
183
here, but the resulting theory is quite odd. For example, it interferes with natural prin-
ciples of logic. Consider the following argument:
 
Brownie sees some man’s every donkey
 
Every donkey is an animal
∴ 
Brownie sees some man’s animal.
On the theory under discussion, ‘some man’s every donkey’ is a single complex term. We 
cannot break it into parts by moving it in front of the verb, because that is tantamount 
to saying that its position aft er the verb is irrelevant to its logical behavior. But so long 
as it remains a unit, there is no way by known logical rules to exploit the quantifi ca-
tional behavior of the ‘every.’ Of course, there might be additional rules, but I am not 
aware of any. It is also unclear what the diff erence in logical import is as a result of 
shift ing the position of the main verb in a proposition. Clearly, there is more research 
to do on this matter.
applications
Give the Linguish logical form for this argument and show that it is valid.
 
An every woman’s donkey runs
∴ 
Of-every woman a donkey runs
Give the Linguish logical forms for two readings of this sentence and decide 
whether either reading entails the other.
Every head’s possessor is one head’s possessor
<supposing ‘one’ is a quantifi er word>
In the following sentences identify the complex terms and the separate terms. 
Say if the sentence is ambiguous.
Every grey donkey sees a lion which runs
A dog chasing every cat is brown
Some woman’s every donkey is running
Every some woman’s donkey is running
An animal seeing every woman is a dog

184 
modes of personal supposition
7
Modes of Personal Supposition
Th is chapter has two parts. Th e fi rst part, sections 7.1–7.7, explains an historical 
version of the theory of modes of personal supposition. Th e second part, sections 
7.8–7.12, deals with a refi ned version of that theory.
7.1 Introduction to the medieval theory
A common term which is used personally1 has what is called a mode of (common) 
personal supposition.2 A mode of supposition is something like a kind of quantifi ca-
tional status. It is a status that a term has in a proposition based on where it occurs in 
the proposition and what quantifi er word occurs with it and with other terms in the 
proposition. Th ree modes of common personal supposition are widely discussed:
 • Determinate Supposition
 • (Confused and) Distributive3 Supposition
 • Merely Confused Supposition
Determinate supposition has something to do with a term’s being existentially 
quantifi ed; a paradigm example is ‘donkey’ in ‘Some donkey is spotted.’ Distributive 
1 Medieval logicians held that expressions can be used in three ways. An expression can be used materially 
(with “material supposition”) as in ‘Man is a noun’; used in this way the expression supposits for itself or for a 
similar expression. An expression can be used simply (with “simple supposition”) as in ‘Man is a species’; used 
in this way the expression supposits for a related form in the external world or for a mental concept. (Realists 
held the former; nominalists something like the latter.) Finally, an expression can be used personally (with 
“personal supposition”) as in ‘A man is an animal,’ to supposit for things that “fall under” the term. (Realists 
would say that in personal supposition a term supposits for things that fall under the form that the word 
supposits for when used with simple supposition; some nominalists would say that in personal supposition a 
term supposits for the things that its associated mental concept naturally signifi es.) Th e topic of this chapter 
concerns words used personally.
2 Some authors (see Marsilius of Inghen 1 (57–9)) believe that terms used materially can also be assigned 
a mode of supposition, since they are common terms. (Dutilh Novaes 2007, 62 suggests that he was the fi rst 
to hold this.) For example, in ‘Every donkey in that sentence is bisyllabic’ the word ‘donkey’ is a common term 
that stands for any word spelled d-o-n-k-e-y. On this analysis, ‘donkey’ has distributive material supposition 
in that sentence. According to some, even discrete terms used materially are common terms, and can have 
modes of supposition, as in ‘Every this uttered this morning was the subject of the sentence in which it occurred.’ 
Most authors either disagree with this view, or ignore it. 
3 Some authors use ‘distributed’ and some use ‘distributive’; I use these interchangeably. (Th e term ‘distributed’ 
may presuppose that a term cannot have that mode of supposition unless it has been distributed by some 
distributing sign; see section 7.4.)

introduction to the medieval theory 
185
supposition has something to do with a term’s being universally quantifi ed; a paradigm 
of distributive supposition is ‘donkey’ in ‘Every donkey is spotted.’ Merely confused sup-
position is neither of these; it needs to be discussed. (An example of a term with merely 
confused supposition is ‘donkey’ in ‘Every animal is a donkey.’)
Almost all authors agreed on the classifi cation of terms of the Aristotelian standard 
forms of categorical propositions:4
 • Th e subjects of universal propositions and the predicates of negative propositions 
have distributive supposition.
 • Th e subjects and predicates of particular affi  rmatives, and the subjects of particu-
lar negatives, have determinate supposition.
 • Th e predicate of a universal affi  rmative has merely confused supposition.
distributed
merely confused
determinate
 
Every S is P
No S is P 
 
Some S is P
Some S is not P
 
 
Usually this three-part classifi cation of terms results from two bifurcations: personal 
supposition is divided into determinate versus confused, and confused supposition is 
divided into distributed-and-confused versus merely confused:5
common personal supposition
determinate
confused
distributed
merely confused
In Parsons 2008a I argue that the theory of modes of supposition took diff erent forms 
in the 13th and 14th centuries. Only the 14th century form will be considered here.
4 Exception: Peter of Spain LS VI.6 (70–1) holds that all predicates have simple supposition, and do not have 
any mode of personal supposition. Also, some authors did not discuss the predicates of particular negatives.
5 So the ‘merely’ in ‘merely confused’ contrasts with the ‘distributed’ in ‘distributive and confused.’ Th e term 
‘confused’ does not here mean ‘bewildered’; it means something more like ‘taken all together.’

186 
modes of personal supposition
7.2 Th e 14th-century defi nitions of the modes
In the 14th century, Walter Burley, William Ockham, and John Buridan (among others) 
developed a systematic approach to the analysis of the modes of common personal 
supposition.6 Th e new accounts defi ne the mode of supposition of a term in a proposi-
tion7 in terms of conditions on ascent and descent under that term in the proposition.8 
A descent is similar to a quantifi er instantiation step in modern logic; an ascent is 
similar to a quantifi er generalization step. Each of the three modes has a distinctive 
pattern of allowable ascents and descents.
What follows is an account that takes what is most common to the views of 
Walter Burley, William Ockham, and John Buridan—the best of BOB. Th e theory 
is based on three defi nitions; they give necessary and suffi  cient conditions for a 
term’s having determinate, distributive, or merely confused supposition. We begin (as 
medieval authors usually do) with determinate supposition:
Determinate supposition9
An occurrence of a term F has determinate supposition in a proposition P if and 
only if
[Descent]: you may descend under that occurrence of F to a disjunction of 
propositional instances about all Fs, and
[Ascent]: from any single propositional instance you may ascend back to the 
original proposition P.
A propositional instance of a proposition with respect to F is the proposition you get 
by replacing the quantifi er word of the denoting phrase containing F by ‘this’ or ‘that,’ 
6 For an historical comparison with earlier views, see Parsons 2008a.
7 Some authors held that only main terms have personal supposition in a proposition (where a main term 
is one that is not part of another term). Burley DS para 5–15 argues this. But the defi nitions to be given of 
modes of supposition apply meaningfully to any term in a proposition. In practice, authors sometimes apply 
the defi nitions to parts of terms, even when denying that this is possible.
8 Th e notions of ascent and descent were present in many earlier writings, though not in a systematic way.
9 Th is account is common to both Ockham and Buridan. Burley omits the ascent clause. 
Buridan SD 4.3.5 (262–3) says “there are two conditions for the determinate supposition of some com-
mon term. Th e fi rst is that from any suppositum of that term it is possible to infer the common term, the 
other parts of the proposition remaining unchanged. For example, since, in ‘A man runs,’ the term ‘man’ 
supposits determinately, it follows that ‘Socrates runs; therefore, a man runs,’ ‘Plato runs; therefore, a man 
runs,’ and so on for any singular contained under the term ‘man.’ Th e second condition is that from a com-
mon term suppositing in this manner all singulars can be inferred disjunctively, by a disjunctive proposition. 
For example, ‘A man runs; therefore, Socrates runs, or Plato runs or John runs  .  .  .’ and so on for the rest.”
Ockham SL I.70 (200) says: “whenever it is possible to descend to the particulars under a general term by 
way of a disjunctive proposition and whenever it is possible to infer such a proposition from a particular, the 
term in question has personal determinate supposition.”
Burley PAL 1.1.3 para. 82 (102) says: “Supposition is determinate when a common term supposits disjunc-
tively for its supposita in such a way that one can descend to all of its supposita under a disjunction, as is plain 
with ‘Some man runs.’ For it follows: ‘Some man runs; therefore, Socrates runs, or Plato runs, and so on.’ ”

the 14th-century definitions of the modes 
187
and adding a ‘not’ if the quantifi er word is negative. Descent and ascent are inferences, 
picturesquely expressed in terms of the directions in which the inferences go. As 
an example, we validate the claim that ‘donkey’ has determinate supposition in ‘Some 
donkey is spotted’ by establishing these two claims:
Descent: You may descend under ‘donkey’ in ‘Some donkey is spotted’ to a disjunction 
of instances about all donkeys. Th at is, from:
  Some donkey is spotted
you may infer:
  Th is donkey is spotted or that donkey is spotted or  .  .  .  and so on for all donkeys.
Ascent: You may ascend back to the original proposition. From any instance of the 
form:
  Th is donkey is spotted
you may infer the original proposition:
  Some donkey is spotted.
Distributive supposition has a parallel explanation:
Distributive supposition10
An occurrence of a term F has distributive supposition in a proposition P if and 
only if
[Descent]: you may descend under that occurrence of F to a conjunction of 
propositional instances about all Fs, and
[Ascent]: from any single propositional instance you may not ascend back to 
the original proposition P.
So ‘donkey’ has distributive supposition in ‘Every donkey is spotted’ because
Descent: You may descend under ‘donkey’ in ‘Every donkey is spotted’ to a con-
junction of instances about all donkeys. Th at is, from:
  Every donkey is spotted
you may infer:
  Th is donkey is spotted and that donkey is spotted and  .  .  .  and so on for all donkeys.
10 Buridan’s account omits the non-ascent condition. Ockham includes additional options for immobile 
distribution. Burley does not defi ne distributive supposition; instead he defi nes two kinds of distributive 
supposition. Th is will be discussed later.
Buridan SD 4.3.6 (264) says: “Distributive supposition is that in accordance with which from a common 
term any of its supposita can be inferred separately, or even all of them at once conjunctively, in terms of 
a conjunctive proposition. For example, from ‘Every man runs’ it follows that therefore ‘Socrates runs,’ [there-
fore ‘Plato runs’, or even that] therefore ‘Socrates runs and Plato runs’ and so on for the rest.”
Ockham SL I.70 (201) says: “Confused and distributive supposition occurs when, assuming that the 
relevant term has many items contained under it, it is possible in some way to descend by a conjunctive 
proposition and impossible to infer the original proposition from any of the elements in the conjunction.”

188 
modes of personal supposition
Ascent: You may not ascend back to the original proposition. From an instance 
of the form:
  Th is donkey is spotted
you may not infer the original proposition:
  Every donkey is spotted.
Finally, merely confused supposition:
Merely confused supposition11
An occurrence of a term F has merely confused supposition in a proposition P 
if and only if
[Descent]: you may not descend under that occurrence of F to either a 
conjunction or a disjunction of propositional instances about all Fs, but
[Ascent]: from any propositional instance you may ascend back to the original 
proposition P.
Th e term ‘mammal’ has merely confused supposition in ‘Every donkey is a mammal’ 
because:
Descent: You may not descend under ‘mammal’ in ‘Every donkey is a mammal’ to 
either:
Every donkey is this mammal and every donkey is that mammal and  .  .  .  , and 
so on for all donkeys
or to:
Every donkey is this mammal or every donkey is that mammal or  .  .  .  , and so on 
for all donkeys.
Ascent: You may ascend back to the original proposition from any instance. From:
   Every donkey is this mammal
you may infer the original proposition:
   Every donkey is a mammal.
11 Th e account given is that of Burley PAL. Burley 1.1.4 para 85 (103): “Supposition is merely confused 
when a common term supposits (a) for several things in such a way that (b) the proposition is inferred from 
any one of them and (c) one cannot descend to any of them either copulatively or disjunctively. Th e predicate 
supposits in this way in ‘Every man is an animal,’ because: (a) the term ‘animal’ supposits for several things. 
For if it supposited for some determinate one, the proposition would be false. (b) Th e proposition is inferred 
from any of its singulars. For it follows: ‘Every man is this animal; therefore, every man is an animal.’ And 
(c) one cannot descend under ‘animal’ either disjunctively or copulatively. For it does not follow: ‘Every 
man is an animal’ therefore, every man is this animal or every man is that animal.’ Neither does it follow: 
‘Every man is an animal; therefore, every man is this animal and every man is that animal,’ and so on.” He 
gives an equivalent account in TKS para 2.41 (see Spade 1997, para 34).
Buridan agrees, but omits the ascent condition. Buridan SD 4.3.6 (264): “But merely confused supposition 
is that in accordance with which none of the singulars follows separately while retaining the other parts of 
the proposition, and neither do the singulars follow disjunctively, in terms of a disjunctive proposition, 
although perhaps they do follow by a proposition with a disjunct term.”
Ockham adds a condition on descent which is discussed in Parsons 2008a, section 8.9.3, and here in section 7.6.

clarification of the definitions 
189
In illustrating the defi nitions we have shown that the subjects of affi  rmative proposi-
tions and the predicate of the universal affi  rmative have the modes that they were 
assigned throughout the tradition. All of the other terms in the standard categorical 
propositions are like this. For example, we can show that by these defi nitions the pre-
dicate term of a particular negative proposition has distributive supposition:
Th e term ‘donkey’ has distributive supposition in ‘Some animal is not a donkey’
because
Descent: You may descend under ‘donkey’ to a conjunction of instances of all 
donkeys. Th at is, from:
  Some animal is not a donkey
you may infer:
Some animal is not this donkey and some animal is not that donkey and  .  .  .  and 
so on for all donkeys.
Ascent: You may not ascend back to the original proposition; from an instance of 
the form:
  Some animal is not this donkey
you may not infer the original proposition:
  Some animal is not a donkey.
applications
Determine which modes of supposition are possessed by the subject and 
predicate terms in the following propositions. (Recall that when producing 
a propositional instance under a term with a negative quantifi er such as ‘no’ 
you need to place a ‘not’ in front of the demonstrative term that replaces the 
quantifi er.)
No donkey is a stone
Some animal is every phoenix
No animal is every donkey
Socrates sees every donkey
<singular terms do not have modes of supposition>
Every donkey sees every horse
Some donkey sees no horse
7.3 Clarifi cation of the defi nitions
Some clarifi cations of the defi nitions are necessary.

190 
modes of personal supposition
7.3.1 Th e nature of ascent and descent
Th e fi rst point has to do with the nature of the inferences involved in ascent and 
descent. Consider the following explanation of why ‘donkey’ is determinate in ‘Some 
donkey is an animal’:
From:
Some donkey is an animal
one may infer
Th is donkey is an animal or that donkey is an animal or  .  .  .  for all donkeys.
Th is does not mean that if the displayed conjunction contains a term for every donkey 
then ‘Some donkey is an animal’ entails ‘Th is donkey is an animal or that donkey is an 
animal or  .  .  .’ For the former sentence does not entail the latter. What is meant instead 
is that from the truth of ‘Some donkey is an animal,’ together with the information 
that ‘Th is donkey is an animal or that donkey is an animal or  .  .  .’ contains a term for 
each donkey, and only terms for donkeys, one may infer that the disjunction is true. 
Th e inference is from the generalization plus the information about the exhaustiveness 
of the disjunction to the truth of the disjunction. Th is is how the test should be 
understood.
To keep matters straight in what follows it will be helpful to have a term for one of 
these conjunctions or disjunctions which have been supplemented by a ‘for all the Fs’ 
clause. I’ll refer to them as augmented conjunctions or disjunctions, with the under-
standing that an augmented conjunction is not a special sort of conjunction, but a 
construction having a conjunction as a central part.
7.3.2 Occurrences of terms have modes of supposition
Second, the classifi cation into modes of suppositions is a classifi cation of term-
occurrences, not of term-types. In the proposition
Every donkey is a donkey
there are two terms (two term-occurrences) each of which has its own mode of sup-
position: the subject term has distributed supposition and the predicate term has 
merely confused supposition. You can’t just ask for the mode of supposition of ‘donkey’ 
in the proposition without specifying which occurrence is meant.
7.3.3 Repeated occurrences must be ignored
Th ird, the classifi cation is meant to be a classifi cation of an occurrence of a term 
independent of the particular nature of any other terms in the sentence. In particular, 
if a term is repeated, as in the example just discussed, you don’t just apply the test 
for modes of supposition to an occurrence of the term in that very sentence. For if 
you do, the results may depend on the very same term occurring elsewhere, and that 

clarification of the definitions 
191
may give unintended results. For example, the following is an incorrect way to try 
to show (falsely) that the subject term of ‘Every donkey is a donkey’ has determinate 
supposition:
Th e subject term of ‘Every donkey is a donkey’ seems to have determinate 
supposition, because that proposition does indeed entail ‘Th is donkey is a donkey or 
that donkey is a donkey or  .  .  .  ,’ and any one of these disjuncts alone entails the 
original proposition.12
Th e subject term is supposed to have distributive, not determinate, supposition. To 
avoid the bad consequence just illustrated, one must ignore the fact that a repeated 
term is the same term. To test the subject term of
Every donkey is a donkey
you should apply the test to
Every donkey is a blah
And although the descent condition is satisfi ed—that proposition does indeed entail
Th is donkey is a blah or that donkey is a blah or  .  .  .
—the ascent condition fails; the original proposition is not entailed by any of the 
disjuncts alone. So the subject term does not have determinate supposition. It is 
straightforward to show that it has distributive supposition.
A similar provision is needed regarding complex terms that contain repeated 
terms within themselves. Consider what kind of supposition is possessed by the sub-
ject term of:
Every donkey which is not a donkey is running
Th e sentence is logically false, and each instance (‘this donkey which is not a donkey is 
running’) is also logically false. Logically false propositions entail anything.13 So if the 
term is left  unchanged, it is possible to descend to a disjunction of instances, and, 
because each instance is logically false, and anything follows from a proposition which 
is logically false, it is also possible to ascend back from any instance. Th is means that 
the subject term has determinate supposition. On the other hand, the proposition is 
a universal affi  rmative proposition, and we said that the subject term of a universal 
affi  rmative has distributive supposition. Which is right?
It is not clear from the texts what to say about this. Th e issue is similar to the modern 
question of whether one may instantiate ‘∃x[F(x) & ¬F(x)]’ to get ‘F(Socrates) & 
12 Each disjunct is affi  rmative and so it entails that ‘donkey’ isn’t empty, and non-emptiness is all that is 
required for the truth of ‘Every donkey is a donkey.’
13 Th is was a common view. For example, Buridan TC I.8.3 (196): “From any impossible sentence any 
other follows.” Paul of Venice LP III.1 (65) “From the impossible follows anything, i.e. from any impossible 
proposition any other proposition follows.”

192 
modes of personal supposition
¬F(Socrates).’ Certainly one may infer the latter from the former, since the former is 
logically false. But can one infer the latter by instantiating? Either answer is possible. 
(My intuition is that we should say that the inference, though valid, is not an 
application of existential instantiation.) Th e analogue for the medieval example given 
a moment ago is to say that the subject term has distributive supposition, and that the 
ascent condition is not met because although the original proposition may be inferred 
from the instance, this is not a proper case of ascent. However, it is not clear how to 
defi ne ascent so as to rule out this inference. Probably the best approach is to extend 
the prohibition on repeated terms to include terms that occur within a complex term. 
For the medieval example, one would then test:
Every donkey which is not a blah is running
Th is does indeed entail the conjunction of all instances of the form:
Th is donkey which is not a blah is running and  .  .  .  and so on for all donkeys
and the original proposition may not be inferred from any instance. So the conditions 
for distributive supposition are met.
7.3.4 Empty terms
Th ere is a problem about how to apply the tests for ascent and descent when the term 
under which one is ascending or descending is empty. If the tests are taken literally, 
this seems to require an augmented conjunction or disjunction with no conjuncts 
or disjuncts. But there is no such thing. For example, one cannot make a conjunction 
or disjunction of the true instantiations of the true proposition ‘No chimera is living,’ 
because there are no true instantiations of the form ‘Th is chimera is not living’ where 
the subject term refers to one of the chimeras.
Some writers took this to establish that empty terms cannot have modes of supposition. 
Ockham is more cautious in the wording of his account of distributive supposition:
Confused and distributive supposition occurs when, assuming that the relevant term has many 
items contained under it [my italics], it is possible in some way to descend by a conjunctive 
proposition and impossible to infer the original proposition from any of the elements in the 
conjunction. (SL I.70 (201))
Th is is subject to diff erent interpretations; on one of them he appears to say that the test 
is to be applied on the assumption that the term is not empty. Just suppose that there 
are some chimeras, and make an augmented conjunction with instances of these:
Th is chimera is not living and that chimera is not living, and  .  .  .  and so on for all 
chimeras.
Th en if the original were true, the augmented conjunction would be true (and no 
ascent would be possible). So this device seems to work fi ne (though it is not com-
pletely clear how to spell it out).

causes of the modes 
193
Another option suggests itself; it is somewhat artifi cial, but it seems to fall within the 
stated conditions. First, we are to understand ‘a disjunction of propositional instances’ 
to be a disjunction, that is, a proposition containing at least one ‘or,’ and thus containing 
at least two disjuncts. (Similarly for conjunctions.) And we are to understand ‘about all 
Fs’ to mean that for each F there is a disjunct (or conjunct) with a term standing for it. 
Th ese two conditions together allow that there may be several disjuncts with distinct 
occurrences of the term ‘that F’ standing for the same entity. (In fact, where there 
is exactly one F this will be required, for there will have to be at least two disjuncts and 
there will be only one F for the terms to stand for.) When there are no Fs at all, we can 
suppose that each term of the form ‘this F’ stands “vacuously” for one of the Fs—that is, 
it stands for nothing at all. So the terms will all be empty. (Th ough this is understood 
to be allowed only when ‘F’ is empty.) Th en the defi nitions of the modes are adequate as 
they stand, even when the term in question is empty. For example, the term ‘chimera’ 
has determinate supposition in ‘Some chimera is not running’ because from ‘Some 
chimera is not running’ we can indeed descend to:
Th is chimera is not running or that chimera is not running  .  .  .  etc. for all chimeras
and we can ascend back to the original from the augmented disjunction. In this case 
both the original proposition and the descended form are true; if the example were ‘Some 
chimera is running’ both would be false. But the actual truth values are irrelevant.
applications
Determine which modes of supposition are possessed by the subject and predi-
cate terms in the following propositions.
No donkey isn’t a donkey
Some animal isn’t an animal
No animal sees every animal
Every donkey which sees a horse sees a horse
Some donkey sees no grey donkey
7.4 Causes of the modes
Th e theory under consideration here continues an earlier tradition that modes of 
supposition other than determinate must be caused. Th e theory of causation takes 
the form of rules that can be applied recursively to the ingredients of a proposition, 
working from right to left . For example, the ‘every’ in ‘Every donkey is running’ causes 
the subject term ‘donkey’ to have distributive status; embedding this within a ‘not’ 
allows for the ‘not’ to reclassify the mode of supposition of ‘donkey’ as determinate in 
‘Not every donkey is running.’ Th is process as a whole is an algorithm for determining 
modes of personal supposition almost by inspection.

194 
modes of personal supposition
Here are some rules that are common to several authors:14
DEFAULT: A main term of a proposition has determinate supposition unless 
something causes it not to.15 A particular affi  rmative sign, such as ‘some,’ adjoined to 
a term makes it have determinate supposition (or, equivalently, has no eff ect).
UA:16 A universal affi  rmative sign, such as ‘every,’ distributes the term it is adjoined 
to and confuses any other main term in its scope if that term is not already 
confused.
UN:17 A universal negative sign, such as ‘no,’ distributes the term it is adjoined to, 
and regarding any other main term in its scope:
If that term is determinate or merely confused, the negative sign confuses and 
distributes it.
If that term is already distributed, the negation sign makes it merely confused
NEG:18 A negating negation, ‘not,’ has the following eff ect on any main term in its 
scope:
14 Paul of Venice LP II.5 (45–52) has similar rules plus a host of others. For example, the superlative and 
comparative constructions distribute their terms; an exceptive expression (as in ‘every man except Socrates’) 
makes its term be merely confused, as does a reduplicative expression (as in ‘Every man as a man’), 
and likewise for expressions concerning an act of the mind, such as ‘know,’ ‘believe.’ Paul speaks here of 
signs “confounding” terms, and thereby aff ecting their mode of supposition. Marsilius TPT 1 (65–71) gives 
19 rules.
15 Buridan SD 4.3.5 (263): “If you ask ‘How do I know when the supposition is determinate?. I say  .  .  .  you 
will know if you see that there is no cause for confusion.”
Ockham SL I.71 (202): “when in a categorical proposition no universal sign distributing the whole 
extreme is added to a term, either mediately, or immediately,  .  .  .  , and when no negation or any expression 
equivalent to a negative or a universal sign is added to a common term, that common term supposits 
determinately.”
16 Buridan SD 4.3.7.1 (265) says: “a universal affi  rmative sign distributes the term immediately following 
and construed with it,” and 4.3.8.1 (273): “there are many causes of nondistributive confusion. Th e fi rst 
obtains when the universal affi  rmative sign confuses a common term following upon it, but not immediately, 
as when in the proposition ‘Every man is an animal’ the term ‘animal’ supposits by nondistributive confused 
supposition.”
Ockham SL I.74 (213) says: “in every universal affi  rmative and universal negative proposition that is 
neither exclusive nor exceptive, the subject has confused and distributive mobile supposition.” I.73 (211): 
“where a common term mediately follows an affi  rmative sign of universality, it has merely confused 
supposition.”
17 Buridan SD 4.3.7.2 (269–70) says: “a negative universal sign is nothing else but a word that implies in 
itself a negation with a particular affi  rmative sign. For ‘no-one’ is equivalent to ‘not one,’ ‘nothing’ to ‘not 
something.’” Since Buridan takes the universal negative sign to be equivalent to negations plus the particular 
affi  rmative sign, his views must follow in part from his view about these two items. Th ese provisions seem 
to yield the right answers.
Ockham SL 1.74 (213) says: “Th e fi rst rule is that in every universal affi  rmative and universal negative 
proposition that is neither exclusive nor exceptive, the subject has confused and distributive mobile supposi-
tion.” For the predicate term, Ockham only mentions the fi rst subcase: “Th e second rule is that in every such 
universal negative proposition the predicate stands confusedly and distributively.” However he probably 
intends his treatment of negation to apply to the universal negative sign.
18 Buridan 4.3.7.2 (269): “a negating negation distributes every common term following it that without 
it would not be distributed and does not distribute anything that precedes it.” Th is applies to the fi rst two 
subcases. For the third case, see note 19.

causes of the modes 
195
If the term is determinate or merely confused, the negation confuses and dis-
tributes it.
If the term is distributed, the negation makes it merely confused (according to 
Buridan)19 or determinate (according to Ockham)20
Th e main terms of standard categorical propositions are correctly classifi ed by these rules:
Every A is B 
A is distributed and B is merely confused by UA
No A is B 
A and B are both distributed by UN
Some A is B 
A and B are both determinate by DEFAULT
Some A is not B 
A is determinate by DEFAULT; B is distributed by NEG
Applied to non-standard categorical propositions, almost all classifi cations agree with 
the defi nitions of the modes in terms of ascent and descent:
Every A is every B 
A and B are both distributed by UA. (Th e fi rst ‘every’ has no 
eff ect on B because B is already confused by the second 
‘every.’)
No A is every B 
A is distributed by UN; B is distributed by UA but then 
made merely confused by UN.
Some A is every B 
A is determinate by default and B is distributed by UA.
Some A is not every B 
A is determinate by DEFAULT; B is distributed by UA but 
this is then made by NEG to be merely confused accord-
ing to Buridan, or determinate according to Ockham.
Th e question remains how to resolve the diff erence between Buridan and Ockham 
concerning the mode of supposition of a term that is apparently distributed by two 
signs. Buridan says that it ends up merely confused, and Ockham says that it ends up 
determinate.21 In the example just given, ‘Some A is not every B,’ the right answer in 
terms of ascent and descent is that ‘B’ should be determinate. But in other cases the 
term must be merely confused, as Buridan says; an example is ‘donkey’ in
19 Buridan 4.3.8.2 (275): “a common term is confused nondistributively by two distributive [parts of 
speech] preceding it, either of which would distribute it without the other.” Examples include the predicate 
terms of ‘No man is no man’ and ‘No man is every man.’ He also (277) cites the predicate of ‘No man sees 
every donkey’ as an example, and notes that the predicate term of ‘Every man is every donkey’ is not an 
application of the rule, since the fi rst ‘every’ by itself would not distribute the predicate term. He adds that the 
rule must have an exception for “two negations taken together, relating in the same way to what follows upon 
them. For these only cancel each other out, and so the supposition remains the same, as it would be if the 
negations were removed. Th us, in ‘Not: no man runs’ or in ‘Socrates does not see no man,’ ‘man’ supposits 
determinately,”
20 Ockham SL I.74 (214): “if the term were to stand confusedly and distributively when one of these 
expressions were taken away, then with the addition of such an expression it would stand determinately.” His 
example is ‘Socrates is not every man,’ wherein ‘man’ stands determinately.
21 Ashworth, Double Distribution and Conjoint Predicates (unpublished manuscript) states: “Ockham and 
Buridan do not disagree, for in the passages cited, Buridan is talking about universal propositions, and 
Ockham is talking about singular propositions.” If Ashworth is correct, instead of disagreement we have a 
lack of stated opinions, and we have even less to go on.

196 
modes of personal supposition
Not: some farmer sees every donkey
Both the ‘every’ and the ‘not’ would distribute ‘donkey’ on their own; together they make 
it merely confused. (Descent is not possible, but ascent is possible from ‘Not: some 
farmer sees this donkey.’) So neither Buridan nor Ockham is right, and we have no other 
option.
Th ere is a way around this problem, by using a technique which was practiced by 
several logicians.22 It is based on the assumption that modes of supposition are not 
aff ected by the quantifi er equipollences discussed in section 3.2. For example, the sub-
ject term of ‘No A is B’ has distributive supposition, since one can descend to:
Th is A is not B, and that A is not B, and so on for all As.
(and one cannot ascend back from any single conjunct). We can apply one of the quantifi er 
equipollences to the ‘no A’ and turn it into ‘not some A,’ thus yielding ‘Not some A is B.’ 
And ‘A’ also has distributive supposition here, because one may descend to:
Not this A is B, and not that A is B, and so on for all As.
(and one cannot ascend back from any single conjunct). Now consider the fi rst case 
mentioned in which it is not clear what the rules from causes should say, namely the 
case of the mode of supposition of ‘B’ in ‘Some A is not every B.’ If we apply a quantifi er 
equipollence to ‘not every B’ it becomes ‘some B not,’ and so the original proposition 
turns into ‘Some A some B isn’t.’ And in this proposition the term ‘B’ has determinate 
supposition according to the rules from causes. Likewise the second case mentioned, 
namely ‘not some farmer sees every donkey’; here applying the equipollences to ‘not 
some farmer’ turns the proposition into ‘every farmer not every donkey sees,’ and then 
the ‘not every donkey’ can be turned into ‘some donkey not,’ so that the original proposition 
becomes ‘every farmer some donkey doesn’t see,’ in which ‘donkey’ has merely confused 
supposition according to the rules from causes of mode of supposition.
So the rules are not completely formulated as is, though we can get around this 
problem.23 I will discuss this further a few sections later, where we consider a revision 
of the theory in which distribution comes in two sorts. Negating one sort produces 
determinate supposition, while negating the other sort produces merely confused sup-
position. Th is permits rules that are complete without a work-around.
22 See Read 1991, 75 ff . He summarizes thus: “It is likely that the medievals did not believe that such a 
procedure always worked—that corresponding terms in equivalent propositions always have the same 
mode of supposition. Nonetheless, it was a standard procedure in certain cases.” In fact, when the equivalents 
are produced by merely applying the quantifi er equipollences it always works.
23 I should also mention an idea that had currency as late as the 17th century (I do not know when it 
arose). Th is is, when two signs act on a term and either sign alone would distribute it, you remove the outer 
sign and then ask whether the distributed term is distributed “with reference to a term having determinate 
supposition, or with reference to a term having merely confused supposition.” In the former case the result 
of the two signs together is that the term ends up merely confused; in the latter case it ends up determinate. 
Cf. John Poinsot OFL 2.12 rule 5. Th is could perhaps be developed into a completely accurate procedure. 
See also Dutilh Novaes 2008, section 2.1 (465).

restricted descent and parasitic terms 
197
7.5 Restricted descent and parasitic terms
Recall that in order to handle relational common nouns, transitive verbs, and genitive 
constructions we need to use parasitic terms; intuitively, terms that supply a grammatical 
role to be occupied by another term. An example is ‘Some farmer’s every donkey is 
running.’
(Of-some farmer α)(every donkey-poss-α β) β is running
Of-some farmer every donkey is running
So far in this chapter we have not looked at propositions with such terms. When we do, 
we fi nd they are problematic. For, some of them have distributive supposition accord-
ing to the rules for causes of the modes of supposition, but they do not satisfy the 
descent/ascent conditions for distributed supposition. Th e example just given is of this 
sort. Th e term ‘donkey’ is distributed by its ‘every’ (according to rule UA). However, 
its mode of supposition is not well defi ned. Th e problem is apparent even with the 
informal statement of the conditions for descent. Th e test requires that one can descend 
from the original proposition to:
Of some farmer this donkey is running and of some farmer that donkey is running 
and  .  .  .  , and so on for all donkeys.
So stated, the descent fails, for there may be donkeys that are not owned by any farmer, 
and that are not running, even though all of the donkeys of some specifi c farmer are 
running.24
In this case it appears as if we should not descend to all of the donkeys that there are, 
but to only those that are owned by  .  .  .  ? By what? By some farmer? Th is also would 
make the descent fail, since there may be donkeys that are owned by a farmer and are 
24 Tests for determinate and merely confused supposition also fail, because the ascent condition does 
not hold.
applications
Determine which modes of supposition are possessed by the subject and pre-
dicate terms in the following propositions according to the theory of causes of 
modes.
No donkey isn’t a donkey
Some animal isn’t an animal
No animal sees every animal
Every donkey which sees a horse sees a horse
Some donkey sees no grey horse

198 
modes of personal supposition
not running, even though all of some farmer’s donkeys are running. Th e term would 
still not have distributive supposition.
Buridan discusses an example just like this, and he says:
But concerning the third proposition, ‘A man’s any donkey runs,’ I say that the word ‘man’s’ is 
not distributed at all, and remains in its determinate acceptation. But the word ‘donkey’ is dis-
tributed, not absolutely, however, but restricted by the word ‘man’s’ taken determinately. And so if 
we need to make a subsumption under this distribution in a syllogism, then we have to syllogize 
as follows: ‘A man’s any donkey runs, Brownie is that man’s donkey; therefore Brownie runs.’ 
(SD 4.3.7.1 (266))
Th ere are two issues here. One is “how to syllogize.” Buridan does indeed give a good 
syllogism. We will discuss this syllogism in Chapter 8 when we discuss anaphoric 
terms, terms that have grammatical antecedents (‘that man’s donkey’). Th e other issue 
is a diff erent one; it is that however plausible his remarks about syllogizing are, they do 
not justify the claim that the descent condition for distributive supposition is satisfi ed 
in a modifi ed way. As we saw earlier, one cannot descend to:
Of some man this donkey is running and of some man that donkey is running 
and  .  .  .  , and so on for all men
for this will fail for unowned donkeys. Buridan suggests that we need to descend to 
a restricted set of donkeys—those belonging to “that man.” Th at wording would be:
Of some man this donkey is running and of some man that donkey is running 
and  .  .  .  , and so on for all donkeys of that man.
but here there is clearly no possible antecedent for the anaphoric ‘that man.’
When Buridan says that ‘donkey’ is not distributed “absolutely” we must agree that it 
is not distributed at all, according to the defi nition of distribution given earlier. In fact, 
it has no mode of supposition at all, as these have been defi ned. We can say that it has 
restricted supposition, but this stands for an idea that we have not spelled out, and that 
perhaps cannot be spelled out.
Th ere is an exception to this, which is when a singular term binds the free marker in 
the parasitic term. Suppose the example were:
Of Socrates any donkey runs
Th en we could descend to a conjunction containing a conjunct for each one of Socrates’ 
donkeys:
Of Socrates this donkey runs and of Socrates that donkey runs and  .  .  .  and so on for 
all donkeys of Socrates
But although this is coherent, it is a technique that is applicable only when it is a singular 
term that the parasitic term is parasitic on. And even in this case, the term ‘donkey’ 
still lacks supposition as we have defi ned it previously. Since the singular term case is 
indeed coherent, I will assume that it makes sense to discuss restricted descent in this 
case. Th is will turn out to be useful in section 7.11.

a variant account of merely confused supposition 
199
In general, a parasitic term will have no mode of supposition at all as defi ned in 
section 7.2. Th is will not prevent other terms from having modes of supposition; for 
example, in Buridan’s sample sentence ‘man’ is indeed determinate, as Buridan says, 
and ‘running’ is merely confused; both of these are predicted by the rules for causes of 
supposition. But parasitic terms do not have these modes according to their defi nitions 
in terms of ascent and descent.
7.6 A variant account of merely confused supposition
We have been using this defi nition of merely confused supposition:
A term F has merely confused supposition in a proposition P if and only if
[Descent]: you may not descend under F to either a conjunction or a disjunction of 
propositional instances of all Fs, and
[Ascent]: from any instance you may ascend back to the original proposition P.
Th ere is a famous alternative defi nition of this mode, apparently devised by Ockham. 
Ockham noted that in some paradigm cases of merely confused supposition, although 
one may not descend to a conjunction or disjunction of propositional instances under 
the term, you may instead descend to a disjunctive term. Th is results in:
A term F has merely confused supposition in a proposition P if and only if
[Descent]: you may not descend under F to either a conjunction or a disjunction of 
propositional instances of all Fs, but you may descend to a proposition with a term 
in place of F that enumerates all of the Fs disjunctively, and
[Ascent]: from any instance you may ascend back to the original proposition P.
For example, in ‘Every horse is an animal’ one may not descend under ‘animal’ either 
to a disjunction or conjunction of instances of the form ‘Every horse is this animal.’ 
But one may descend to:
Every horse is (this animal or that animal or  .  .  .  for all animals).
(Buridan also mentions this option, but does not endorse it as a requirement.)
Ockham’s proposal was very popular, and several other writers adopted it.25 Th is was 
a somewhat peculiar development. Th e reason is that the possibility of descent to 
a disjunctive term is a grammatical issue, not a logical one. Th is is because:
25 For example, Albert of Saxony, L II.3 says: “Merely confused personal supposition is the interpretation 
of a term for each thing it signifi es by its imposition, or which it signifi es naturally (if it is a mental term), in 
such manner that a descent to its singulars can be made by a proposition of disjunct predicate, but not by a 
disjunctive or conjunctive proposition.” And Paul of Venice LP 2.4 (150) gives: “Common mobile personal 
supposition which is merely confused is the acceptance of a common term standing personally beneath 
which one descends to all of its referents in disjuncts, as in ‘every man is [an] animal and these are all animals; 
therefore, every man is this animal or that animal and thus of singulars.’ ”

200 
modes of personal supposition
some P
can always be paraphrased as
this P or that P or  .  .  .
but it cannot be paraphrased as ‘this P and that P and  .  .  .’
(Likewise for ‘a P’ and so on.)
Conversely:
every P
can always be paraphrased as
this P and that P and  .  .  .
though not as ‘this P or that P or  .  .  .’26
So the paraphraseability of a denoting phrase using a disjunctive term is a matter of 
which quantifi er word it contains. But it was generally presumed that the quantifi er can 
be changed (if additional changes are made) so as to preserve the mode of supposition. 
Several of Sherwood’s equipollences do this. For example, ‘donkey’ has determinate 
supposition in
Some donkey is not spotted
and also in the logically equivalent
Not every donkey is spotted
Th e former can be paraphrased as
Th is donkey or that donkey or  .  .  .  is not spotted
but the latter certainly cannot be paraphrased as
Not (this donkey or that donkey or  .  .  .  ) is spotted.
Th is might not be important when the term already has determinate or distributive 
supposition, for paraphrasing a common term into a disjunctive term is not relevant 
to these classifi cations. But consider the following example. Th is inference is a case of 
a descent under ‘animal’ to a disjunctive term:
Not some donkey every animal isn’t
∴ Not some donkey (this animal or that animal  .  .  .) isn’t
26 Likewise, ‘no P’ can always be paraphrased as
 this P and that P and  .  .  .  not
but not as this P or that P or  .  .  .  not.

a variant account of merely confused supposition 
201
Th e inference fails,27 thus establishing that ‘animal’ does not have merely confused 
supposition in the premise according to Ockham’s account. But it should have merely 
confused supposition. Th e premise is the result of applying equipollences to a universal 
affi  rmative proposition:
every donkey an animal is ⇒ not some donkey not an animal is ⇒ not some donkey 
every animal isn’t
Th e other modes of supposition are preserved through these equipollences, and merely 
confused supposition is also preserved on all accounts other than Ockham’s. A related 
example concerns the predicate term in ‘No animal is every man.’ Marilyn Adams28 
points out that ‘man’ does not have either determinate or distributive supposition, 
and on Ockham’s account it does not have merely confused supposition either, because 
one cannot descend to a proposition with a disjunctive term. From:
No animal is every man
we may not infer
No animal is this man or that man or  .  .  .29
It thus appears that Ockham’s account does not yield the classifi cations that people 
were aft er.
John Dorp30 has a solution to this. He proposes that in order to tell what mode 
of supposition a term has we should fi rst move the verb to the end, and then move 
any negation to the right of all of the terms (fi rst changing ‘no A’ to ‘every A not’). 
(Applications of Sherwood’s equipollences given in section 3.2 will do this.) Th is needs 
to be done before applying Ockham’s test. Th en, every term in the categorical will end 
up with ‘every’ or ‘some’ as its quantifi er sign. If its sign is ‘every’ it has distributive sup-
position. If the sign is ‘some,’ then either it will satisfy the conditions for determinate 
supposition, or not. If it does not, it may be paraphrased by a disjunctive term. 
Th is renders Ockham’s test for merely confused supposition accurate. However, it may 
also render it redundant, because based on cases, it seems that this convoluted way 
of applying Ockham’s provision yields that same classifi cation you would get by not 
having it at all, as in the account we discussed originally.
Some authors31 defi ned merely confused supposition in terms of descent to either a 
disjunctive or a conjunctive term. Since one or the other of these descents is always pos-
sible, this also appears to be a redundant addition to the conditions given in section 7.2.
27 In assessing the inference it is essential to keep the scopes straight in the conclusion. Th e ‘not’ in ‘isn’t’ 
does not have scope over anything else with scope in the proposition.
28 Adams 1987, 366–7.
29 Similarly, Buridan SD 4.3.8.2 (277) says that ‘donkey’ is merely confused in ‘No man sees every donkey.’ 
But ‘every donkey’ cannot be paraphrased here as ‘this donkey or that donkey or  .  .  .’
30 Cited in Karger 1993, 418–20; also described in Dutilh Novaes 2008, who also cites another solution 
proposed in Poinsot OFL.
31 Maulfelt; see Read 1991, 77–82.

202 
modes of personal supposition
It should also be mentioned that quite a few authors held that certain verbs, mainly 
ones that we think of as creating non-extensional contexts, merely confuse terms 
following them. Th e commonest example is ‘promise’ in constructions like ‘I promise 
you a horse,’ understood in such a way that there is no particular horse that I promise 
you. Some, including Ockham, held that this sort of confusion satisfi es Ockham’s 
account, so that we can say ‘I promise you (this horse or that horse or  .  .  .  ).’ Th is 
phenomenon will be discussed in Chapter 10. Th e remainder of the present chapter 
is restricted to discussing the syntactic structures introduced in Chapters 4 and 5.
7.7 Useful inferences
Th e discovery and development of useful ways to judge inferences is distinctive of the 
medieval era. When the notions of modes of supposition were introduced, they brought 
along with them new and useful ways to assess inferences. Th is already occurred within 
the 13th-century theory (see Parsons 2008a for details). Some of these applications are 
clear and compelling.
7.7.1 Superiors and inferiors
One is the case of inference “from a superior to an inferior” with a distributed term.
From a superior to an inferior: If a term A is distributed in a proposition P, then 
from P together with a proposition indicating that term B is inferior to A, the 
proposition that results from P by replacing A by B follows.32
A common term B is inferior to a common term A iff  ‘every B is A’ is true; this is also 
the condition for A being superior to B. And a singular term a is inferior to a common 
term A iff  ‘a is A’ is true; again, in this case A is superior to a. (When replacing a 
common term by a singular term one must delete the quantifi er sign accompanying 
the common term.)
32 Buridan TC 3.7.8 (283): “For any given proposition with a distributed term, whether nominative or 
oblique, an acceptable syllogism can be constructed by taking another term under the given term as the 
minor proposition.” “Paul of Venice LP III.3 (71) “From a higher-level term to its corresponding lower-level 
term distributed affi  rmatively the argument is not solid unless with the due mean, because it does not follow: 
‘every animal runs; therefore, every man runs’.  .  .  .  But with the due mean, the argument is solid.” (Th e “due 
mean” would be ‘Every man is an animal.’)
Parasitic terms are not subject to the rule because they do not have modes of supposition. If such terms 
were assigned modes of supposition in accord with the rules for the causes of modes of supposition the rule 
discussed here would be fallacious. Here are two counterexamples:
Of some farmer every animal is running
∴ Of some farmer every donkey is running
Of every farmer every animal is running
∴ Of every farmer every donkey is running

useful inferences 
203
Th e simplest illustration of this rule is Aristotle’s syllogism BARBARA:
Every M is P
Every S is M
∴ Every S is P
According to the rules for causes of modes, the term M is distributed in the fi rst premise. 
Th e second premise states that S is inferior to M. Th e conclusion follows by replacing 
M with S in the fi rst premise. Th e same principle also validates CELARENT:
No M is P
Every S is M
∴ No S is P
Again, according to the rules, M is distributed in the fi rst premise, and the second states 
that S is inferior to M. Th e conclusion again follows by replacing M with S in the fi rst 
premise.33
Th is principle goes beyond Aristotle’s syllogistic. Buridan points out that this inference 
is a good one (SD 4.2.6 (244)):
 
Socrates is seeing every horse
 
Brownie is a horse
∴ 
Socrates is seeing Brownie.34
Our rule Universal Application is an instance of applying this principle when replacing 
a common term with its quantifi er with an inferior singular term. But applications of 
the principle outrun that particular rule. For example, the following argument:
 
Every donkey runs
 
Brownie is a donkey
∴ 
Brownie runs
is an instance of Universal Application, and also of the principle “From a superior to 
an inferior.” But the following inference is an equally good application of the latter 
principle, but not of the former:
33 Recall that Aristotle reduced all of the other moods of syllogisms to BARBARA and CELARENT. Th ere 
is a long tradition of interpreting Aristotle which has him reasoning in the way just described. In PA 1.1 (2) 
he says “For one thing to be in another as a whole is the same as for one thing to be predicated of every one of 
another. We use the expression ‘predicated of every’ when none of the subject can be taken of which the other 
term cannot be said, and we use ‘predicated of none’ likewise.” Keynes S&E 1884, 126 (p. 157), for example, 
calls this the dictum de omni et nullo (“principle of all and none”) and interprets it as saying “Whatever is 
predicated, whether affi  rmatively or negatively, of a term distributed, may be predicated in like manner of 
everything contained under it.” Th is principle is supposed to directly yield Barbara and Celarent; so inter-
preted it is a special case of the principle “From a superior to an inferior.” In this tradition, when Aristotle 
calls the fi rst fi gure deductions perfect, he means that they follow from the dictum de omni et nullo. Th is does 
not strike me as what Aristotle means, but the principles cited are certainly good ones.
34 Actually, in this example ‘seeing every horse’ is a complex term, and one needs the principles of section 
5.6.2 to eliminate the complex term. If the proposition is understood as ‘Socrates is every horse seeing’ then 
the principle “From a superior to an inferior” directly applies.

204 
modes of personal supposition
 
Plato doesn’t see a donkey
 
Brownie is a donkey
∴ 
Plato doesn’t see Brownie
Th is is like having a rule of universal instantiation that applies within formulas, and 
can be applied also to existential quantifi ers, as in:
 
¬ ∃x Fx
∴ 
¬ Fa 
by “universal instantiation” applied to ‘∃xFx’ in this context
Th is is not the way we usually think of things, but we could, and it would be useful in 
shortening derivations.
Th e reverse principle holds for determinate and merely confused supposition:35
From an inferior to a superior: If a term B has determinate or merely confused 
supposition in a proposition P, then from P together with a proposition stating 
that A is superior to B, the proposition that results by replacing B by A follows.
Another of Aristotle’s fi rst fi gure syllogisms follows by this principle:
Darii
Every M is P
Some S is M
∴ Some S is P
Th e fi rst premise states that ‘P’ is superior to ‘M,’ which is determinate in the second 
premise; the conclusion follows by replacing ‘M’ by ‘P’ in the second premise.
Th is principle also applies when replacing a singular term b by a superior term B 
with a quantifi er sign provided that B ends up having determinate or merely confused 
supposition. For example:
35 Paul of Venice LP III.3 (70): from a lower-level term to its corresponding higher-level term affi  rmatively 
and without a sign of distribution and without any confounding signs impeding there is a solid inference. 
E.g. ‘man runs; therefore, animal runs.’” (I don’t know why Paul does not require a “due mean” here, as he does 
for the inference from a higher-level term to its corresponding lower-level term.) Ockham SL III.3–6 (600) 
cites this rule: “ab inferiori ad superius sine distributione et affi  rmative est bona consequentia et simplex.” 
He then gives a number of counterexamples to it, such as examples in which terms do not have personal 
supposition. He then qualifi es the rule (page 601): “from an inferior to a superior without distribution and 
affi  rmatively is a good consequence if the terms are suppositing personally and signifi catively” (ab inferiori ad 
superius sine distributione et affi  rmative est bona consequentia si termini supponant personaliter et signifi cative)” 
(cited in Moody 1955, 288 note 1).
Counterexamples to the principle for parasitic terms that (apparently) have merely confused and deter-
minate supposition are:
 Of no farmer every donkey is running
 ∴ Of no farmer every animal is running
 Of some farmer not every donkey is running   <premise is true if there are no donkeys>
 ∴ Of some farmer not every animal is running

useful inferences 
205
 
Plato owns Brownie
 
Brownie is a donkey
∴ 
Plato owns a donkey
Of course, this inference is easily validated by combining permutation for singular 
terms with expository syllogism. Other examples are less obvious:
 
Plato doesn’t own Brownie
 
Brownie is a donkey
∴ 
Plato doesn’t own every donkey
Th e inference is good because ‘donkey’ has determinate supposition in the conclusion.
We have stated these useful principles, but we have not justifi ed them in any way. 
Such a justifi cation will be given at the end of section 7.11.
applications
Say which of the following inferences can be justifi ed by one of the rules just 
discussed; also indicate how the principles for the causes of modes of supposi-
tion establish that the rule in question applies.
 
Some farmer sees every donkey
 
Every farmer is a woman
∴ 
Some woman sees every donkey
 
Some farmer sees every animal
 
Every farmer is a woman
 
Every donkey is an animal
∴ 
Some woman sees every donkey
 
Some donkey is not a pet
 
Every pet is a grey-thing
∴ 
Some donkey is not a grey-thing
 
Some donkey is not a pet
 
Every grey-thing is a pet
∴ 
Some donkey is not a grey-thing
7.7.2 Monotonicity
Th ese two principles allowing one to move from inferior to superior or vice versa 
are generalizations of the notion of monotonicity discussed in section 2.7, with mono-
tonicity down being an inference from a superior to an inferior, and monotonicity up 
being an inference from an inferior to a superior. (Since the defi nitions of superior 

206 
modes of personal supposition
and inferior given in section 7.7.1 require that the terms in question be non-empty, the 
diff erences between monotonicity and qualifi ed monotonicity are not relevant here.) 
What we see here is that the monotonicity behavior of terms that are the immediate 
arguments of determiners can be altered by other signs in the proposition. An example 
of this eff ect is:
 
Some A is not a B
 
Every C is a B
∴ 
Some A is not a C
Th e term B in the fi rst premise is immediately governed by an indefi nite determiner, 
which is monotonic up regarding that term. But the presence of the ‘not’ reverses 
the direction of the inference, so that ‘B’ is in an overall monotonic-down context. In 
medieval terms, the ‘not’ distributes ‘B’ (and nothing else interferes with this) so that 
one may make an inference from a superior to an inferior.
Similarly, in this inference:
 
No A is no B
 
Every B is a C
∴ 
No A is no C
since ‘no’ is monotonic down on the right, this puts ‘B’ in a monotonic down position, 
but the ‘no’ in front of ‘A’ reverses this so that ‘B’ is in an overall monotonic up context. 
In medieval terms, ‘B’ ends up having merely confused supposition, and so one may 
make an inference from an inferior to a superior.
7.7.3 Parasitic terms
Note that these principles do not apply to parasitic terms, for such terms do not have 
modes of supposition. But we saw earlier that a parasitic term with a singular term 
as antecedent has a kind of restricted mode of supposition. One might try to apply 
the principles in those cases. Th is can occasionally be done. For example, consider 
‘Plato’s donkey is running.’ Since ‘donkey’ has restricted determinate supposition here—
restricted by ‘Plato’s’ —and since ‘donkey’ is inferior to ‘animal’ it seems that we can go 
from an inferior to a superior and infer that Plato’s animal is running. Th is is in fact a 
good inference. But the technique does not generalize. We need only consider ‘Plato’s 
donkey isn’t running.’ Since this is a negative proposition it will be true if Plato doesn’t 
have a donkey. And at the same time ‘Plato’s animal isn’t running’ will be false if Plato 
owns only one animal, say a horse, that is running. So an inference from an inferior 
to a superior is not in general trustworthy for parasitic terms, even when they have 
restricted supposition.

useful inferences 
207
7.7.4 Additional useful inferences and non-inferences
In addition to the Superior/Inferior inferences, several other patterns were discussed 
involving modes of supposition. Th e following are given by William Sherwood 
(IL V.13.2 (118–19)). Th ey are presented here with minimal discussion; we will return 
to them in section 7.10.
Rule II An argument from merely confused supposition to distributive con fused supposition does 
not follow.
Th us when every man sees only himself this does not follow: ‘every man a man does not see; 
therefore every man does not see a man.’
Th e point here seems straightforward: the second ‘man’ in the premise is merely con-
fused (by the ‘every’) but it is distributed in the conclusion. Sherwood sees this as an 
instance of a general pattern involving a term’s changing its mode of supposition from 
merely confused to distributive.
Another rule:
Rule III An argument from many cases of determinate supposition to one of determinate supposition 
does not follow, but [only] to one of confused supposition.
Th us when every man sees only himself this does not follow: ‘a man is seen by Socrates, and 
[a man is seen] by Plato (and so on with respect to [all] individual [men]); therefore a man is 
seen by every man.’ But this does follow: ‘therefore by every man a man is seen,’ for a distribution 
has force in a succeeding phrase but not in a preceding phrase.
applications
Produce a derivation (without using Superior to Inferior, or vice versa) to show 
the following argument valid. (You will need to use the Possession rule from 
section 5.7.2.)
 
Plato’s donkey is running
 
Every donkey is an animal
∴ 
Plato’s animal is running
Try producing similar derivations for these invalid arguments to see where they 
fail.
 
Plato’s donkey is not running
 
Every donkey is an animal
∴ 
Plato’s animal is not running
 
Plato’s father is running
 
Every father is a son
∴ 
Plato’s son is running

208 
modes of personal supposition
Th e inference resembles what was elsewhere called “induction”: concluding that a 
universal generalization is true because each of its instances are. But this principle 
holds only when the generalized ‘every man’ ends up with wide scope, and this is not 
the case in the bad example that Sherwood discusses. Th e good example, the one that 
does follow, diff ers exactly in that ‘every man’ ends up with wide scope. Instead of scope, 
Sherwood discusses symptoms of scope: the resulting modes of supposition; in 
the good example ‘a man’ has merely confused supposition (because the ‘every man’ 
has scope over it), and in the bad one it has determinate supposition. So the rule is for-
mulated in terms of whether you move from many cases of determinate supposition to 
determinate supposition, or to merely confused supposition.
Rule IV An argument from determinate supposition to distributive confused supposition does not 
follow, but only to merely confused supposition.
Th us this does not follow: ‘a man is not seen by Socrates; therefore Socrates does not see a man’—
e.g. if Socrates sees one man only. But this follows correctly: ‘a man is seen by every man; there-
fore every man sees a man.’36
Th e badness of the fi rst inference and goodness of the second are obvious; the rule 
identifi es the diff erence in terms of a principle about modes of supposition.
Rule V An argument from distributive confused supposition to determinate supposition does 
follow, but not from merely confused supposition.
Th us this follows: ‘Socrates does not see a man; therefore a man is not seen by Socrates.’ But this 
does not: ‘every man sees a man (e.g. every man sees only himself); therefore a man is seen by 
every man.’
In the fi rst inference ‘man’ goes from distributive supposition to determinate supposi-
tion, and in the second it goes from merely confused to determinate. Th e rule blames 
the goodness/badness of these inferences on the pattern of the modes of supposition.
Th ese rules all seem to have insight behind them, and they look promising as part 
of an overall theory of inference in terms of modes of supposition. But for them to 
be useful we need to be able to apply the rules in other cases, and in every case the 
description that Sherwood gives is too terse for us to do this. In general the rule cites 
a change of mode of supposition without describing in detail the setting in which it 
occurs. For example, in this example of subalternation:
Every P is Q ∴ Some P is Q
the term ‘P’ goes from distributive supposition to determinate supposition, so the 
inference should be good according to the fi rst half of rule V, but the term ‘Q’ goes from 
merely confused to determinate supposition, so the inference should be bad according 
to the second half of rule V. I think that there are in fact some useful generalizations 
here, but we will be better able to formulate them (in section 7.10) aft er a refi nement 
in the theory of modes of supposition.
36 Th e translation quoted here has been altered in conformity with discussion in the Preface to Kretzmann 
1968.

distinguishing two kinds of distributive supposition 
209
7.8  Refi ning the theory: Distinguishing two kinds of 
distributive supposition
Various writers have noticed that there seems to be an asymmetry in the account of the 
modes of supposition. On Ockham’s account, which is the best known, there is descent 
to a disjunction of propositions, descent to a conjunction of propositions, and descent 
to a disjunctive term. Various proposals have been made about how to make the 
account more balanced by adding a fourth mode of supposition.37 I will suggest that 
four modes do make a better theory, but this should be accomplished not by adding 
a fourth mode independent of the ones that are traditionally discussed, but rather 
by subdividing the mode of distributive supposition. For reasons to be given later, I will 
call one sort of distribution “wide distribution” and the other “narrow distribution.”
Wide distributive supposition is traditional distributive supposition restricted 
to cases in which one can ascend back to the original proposition from the whole con-
junction of propositional instances under the term. (Not from a single instance, but 
from the whole conjunction.) For example, from this proposition:
Every donkey is running
one may descend to:
Th is donkey is running, and that donkey is running, and so on for all donkeys
And one may, from that entire conjunction, ascend back to the original proposition. 
So ‘donkey’ has wide distribution in that proposition.
Narrow distributive supposition is distribution where one cannot make this ascent. 
An example is the term ‘vegetarian’ in
Some philosopher is not a vegetarian.
From this proposition one may descend to the conjunction:
Some philosopher is not this vegetarian, and some philosopher is not that vegetarian, 
and so on for all vegetarians.
But from that whole conjunction one may not ascend back to the original proposition.
With this bifurcation of distributed supposition the four modes are:
Determinate
Descent to a disjunction of propositions, and ascent back from the whole 
disjunction.
Merely confused
No descent to a disjunction of propositions but ascent back from such a 
disjunction.
37 Read 1991, section 6, argues that a proposal that there be a fourth mode of supposition may have 
occurred in 1370 for the fi rst time. Spade 1988a argues that there cannot be a fourth mode in addition to the 
three already recognized. My proposal for four modes is in agreement with Spade’s conclusion.

210 
modes of personal supposition
Wide distributive
Descent to a conjunction of propositions and ascent back from the whole 
conjunction.
Narrow distributive
Descent to a conjunction of propositions and no ascent back from the 
conjunction.
Th ere is precedent for the category of wide distribution; it is what Paul of Venice (LM: 
TS 3.11a (95))38 proposes for what he calls mobile distribution. So far as I know, narrow 
distribution has not been proposed as a distinct category.39 (Immobile distribution 
generally refers to cases in which no descent is possible.)
If we think of denoting phrases as restricted quantifi ers, then this is equivalent to 
saying:
Determinate
Existential Instantiation holds, and so does Existential Generalization.
Merely confused
Existential Instantiation does not hold, but Existential Generalization does.
Wide distributive
Universal Instantiation holds, and so does Universal Generalization.
Narrow distributive
Universal Instantiation holds, but Universal Generalization does not hold.
Th is more refi ned classifi cation of terms yields a more symmetrical pattern. Let us 
call wide distribution and determinate supposition opposites, and likewise narrow dis-
tribution and merely confused supposition. Th en when a proposition is negated, each 
term has its mode of supposition reversed. Since diagonally opposite propositions 
in the square of opposition are (logically equivalent to) negations of one another, 
the modes of supposition of the terms in any proposition mirror (in reverse) those in 
its opposite. Th e modes of supposition in the traditional square are now:
38 “Distributive general reference is twofold because some is mobile, some immobile. Distributive mobile 
general reference is the meaning of a common term beneath which one can infer to all of its singulars 
conjunctively on the condition of a proper middle and, conversely, with the same middle. Th us this follows: 
‘Th is animal runs and this animal runs and thus of each individual and these are all animals; therefore, every 
animal runs.’ ” Paul correctly includes subjects of universal affi  rmatives, and both subjects and predicates of 
universal negatives as having this mode of supposition.
39 Spade 1976 argues that distributive supposition should be restricted to what I am here calling wide 
distribution, and the category of merely confused supposition should be expanded to include the remaining 
instances of distributive supposition (i.e. narrow distribution). Priest and Read 1980 argue that distributive 
supposition should be restricted to wide distribution, and the category of merely confused supposition 
should be abolished. I think that each of these proposals would yield a less useful theory. Priest and Read also 
argue that Ockham’s defi nition of distributive supposition is a defi nition of wide distribution. Th is has been 
disputed e.g. by Matthews 1984, and it is not now a widely held view.

causes of the refined modes 
211
7.9 Causes of the refi ned modes
With these new distinctions we can refi ne the theory of the causes of the modes of 
personal supposition developed previously. Th e principles used then yielded mostly 
intended results, except for the problem about what mode a term has if it is acted upon 
by two distributing signs. Ockham and Buridan disagreed about this, and neither of 
their views is completely correct. Th eir theory lacked the resources for giving a simple 
correct answer, since it does not subdivide the category of distributive supposition.
Th e revised theory makes a new set of rules possible. Th e refi ned rules in what 
follows are to be applied recursively to the signs of a sentence that have scope over 
the verb; as before, they apply fi rst to the sign that is rightmost and has scope over 
the verb.
DEFAULT: A main term of a proposition has determinate supposition unless 
something causes it not to. A particular affi  rmative sign adjoined to a term gives it 
determinate supposition (or, equivalently, has no eff ect). In either case, any terms to 
the right and within the scope of the denoting phrase containing the term retain the 
mode of supposition they already have, except that a wide distributed term becomes 
narrow distributed.
applications
Say which terms have which kinds of refi ned modes of supposition.
Every donkey sees every horse
Some donkey sees every horse
Some donkey sees of every farmer a horse
Every donkey sees of some farmer every horse.
widely distributed
determinate
 
Every S is P
No S is P
 
Some S is P
Some S is not P
 
 
merely confused
narrowly distributed

212 
modes of personal supposition
UA: A universal affi  rmative sign widely distributes the term it is adjoined to and 
makes any other term to its right merely confused if it is determinate, leaving terms 
with the other modes unchanged.
UN: A universal negative sign widely distributes the term it is adjoined to; if a term 
mediately following the universal negative sign has determinate supposition, it 
becomes wide distributed; if the term has wide distribution it becomes merely 
confused; if the term has merely confused supposition it becomes narrowly 
distributed, and if it has narrow distribution it becomes merely confused.
NEG:  A negating negation has the following eff ect on any main term following it 
and in its scope:
If the term is determinate it becomes wide distributed, and vice versa.
If the term is merely confused it becomes narrowly distributed, and vice versa.
All provisions except for the fi rst and last are consistent with the earlier rules, though 
they provide more detailed information. Th e previous version of the last rule said that 
if a term has distributed supposition then the negation makes it merely confused 
(according to Buridan) or determinate (according to Ockham). On the new account if 
the term has narrow distribution it becomes merely confused, as Buridan says, and if it 
has wide distribution it becomes determinate, as Ockham says. Two relevant examples 
are these:
Not no man runs
Not some farmer sees every donkey
Th e new rules correctly classify ‘man’ as having determinate supposition in the fi rst 
proposition, and they correctly classify ‘donkey’ as having merely confused supposition 
in the second proposition.
applications
Say which terms have which kinds of refi ned modes of supposition according to 
the causes of modes of supposition.
Every donkey sees every horse
Some donkey sees every horse
Some donkey sees of every farmer a horse
Every donkey sees of some farmer every horse.
7.9.1 Modes of supposition in Linguish
Following out this theory of causes of modes of supposition we can defi ne the modes 
of supposition for all non-parasitic main terms in propositions of Linguish, as follows 

causes of the refined modes 
213
(where it is understood that the term ‘T’ is not a parasitic term, and ‘R’ may or may not 
be a parasitic term):
‘T’ has wide distributive supposition in ‘(every T α) ϕ’ and in ‘(no T α) ϕ.’
‘T’ has determinate supposition in ‘(some T α) ϕ’ and in ‘(· T α) ϕ.’
Whatever mode of supposition ‘T’ has in ‘ϕ,’ it has that same mode of supposition in:
  (t α) ϕ
  [ψ and ϕ] and in [ϕ and ψ]
  [ψ or ϕ]  and in [ϕ or ψ]
If ‘T’ has wide distributive supposition in ‘ϕ’ then:
  ‘T’ has wide distributive supposition in
    (every R α) ϕ
  ‘T’ has narrow distributive supposition in:
    (some R α) ϕ
  ‘T’ has determinate supposition in:
    not ϕ
  ‘T’ has merely confused supposition in:
    (no R α) ϕ
If ‘T’ has determinate supposition in ‘ϕ’ then:
  ‘T’ has determinate supposition in
    (some R α) ϕ
  ‘T’ has merely confused supposition in:
    (every R α) ϕ
  ‘T’ has wide distributive supposition in:
    not ϕ
    (no R α) ϕ
If ‘T’ has narrow distributive supposition in ‘ϕ’ then:
  ‘T’ has narrow distributive supposition in
    (every R α) ϕ
    (some R α) ϕ
  ‘T’ has merely confused supposition in:
    not ϕ
    (no R α) ϕ
If ‘T’ has merely confused supposition in ‘ϕ’ then:
  ‘T’ has merely confused supposition in
    (some R α) ϕ
    (every R α) ϕ
  ‘T’ has narrow distributive supposition in:
    not ϕ
    (no R α) ϕ

214 
modes of personal supposition
7.10 Useful inferences again
With these refi ned modes in mind, we can look again at some useful inferences 
expressible with the terminology of modes of supposition. It is clear that all of the 
instances of inferences from Superior to Inferior and from Inferior to Superior still 
hold good, since subdividing the mode of distributive supposition has no eff ect on 
these. In addition Sherwood’s special rules lead to some interesting applications.
7.10.1 Complete induction
Let us look fi rst at Sherwood’s Rule III:
Rule III An argument from many cases of determinate supposition to one of determinate supposition 
does not follow, but [only] to one of confused supposition.
Th us when every man sees only himself this does not follow: ‘a man is seen by Socrates, and 
[a man is seen] by Plato (and so on with respect to [all] individual [men]); therefore a man is 
seen by every man.’ But this does follow: ‘therefore by every man a man is seen,’ for a distribution 
has force in a succeeding phrase but not in a preceding phrase.
Th is rule deals with “complete” induction, which has a form something like this:
 
.  .  .  man #1  .  .  .
 
.  .  .  man #2  .  .  .
 
.  .  .  man #3  .  .  .   where these are all men
∴ 
.  .  .  every man  .  .  .
At fi rst glance it seems that we can say that when we have premises of the given form, 
we can just replace ‘man #n’ by ‘every man’ to get the conclusion. And we can do this in 
simple cases, such as:
 
Socrates sees man #1
 
Socrates sees man #2
 
Socrates sees man #3   etc. for all men
∴ 
Socrates sees every man
But Sherwood shows us that this will not always work. Th is inference is clearly 
fallacious:
 
A horse is seen by man #1
 
A horse is seen by man #2
 
A horse is seen by man #3   etc. for all men
∴ 
A horse is seen by every man
From a modern point of view we would like to say that complete induction works when 
the generalized term in the conclusion has wide scope. Sherwood’s rule is phrased 
in terms of a symptom of this: if there is a term in the proposition with determinate 
supposition and the generalized term is not given wide scope then that term still has 

useful inferences again 
215
determinate supposition in the conclusion, whereas if the generalized term appeared 
on the front it would confuse that term, so that it would have merely confused 
supposition.
So why don’t we just say that the conclusion of a complete induction must have 
‘every P’ on the very front, instead of being located where the singular terms were? In 
the case in point this would work fi ne; we would have:
Every man a horse is seen by
However, there are circumstances in which an induction should be OK even though it 
is not grammatical to put the generalized term on the front. A simple example of this is
 
Th e sun rose and man #1 got up
 
Th e sun rose and man #2 got up
 
Th e sun rose and man #3 got up 
etc. for all men
∴ 
*Every man the sun rose and got up 
<*ungrammatical>
We can generally avoid the problem of ungrammaticality by saying that any argument 
of the following form is a good complete induction:
 
.  .  .  man #1  .  .  .
 
.  .  .  man #2  .  .  .
 
.  .  .  man #3  .  .  .   where these are all men
∴ 
ϕ where ϕ is got by inserting ‘Quant man’ any place in ‘.  .  . .  .  .’ where it occupies 
the same grammatical role as ‘man #n,’ and where ‘Quant’ is an affi  rmative 
quantifi er sign,40 namely ‘every’ or ‘some’ or ‘a,’ and where ‘man’ ends up with 
wide distribution.
So these would be good inductions:
 
Th e sun rose and man #1 got up
 
Th e sun rose and man #2 got up
 
Th e sun rose and man #3 got up   etc. for all men
∴ 
Th e sun rose and every man got up
 
Not man #1 ran
 
Not man #2 ran
 
Not man #3 ran   etc. for all men
∴ 
Not some man ran
We can see Sherwood’s rule as a consequence of this one for the special case of 
categorical propositions. Suppose that there are one or more determinate terms in the 
inductive premises, which are categorical propositions. Th en replacing the varying 
term with the term ‘man’ with a quantifi er that yields wide distributive supposition 
40 If we applied the suggested rule to a case with ‘no’ we could get a faulty inference: Man#1 ran, and 
Man#2 ran, and so on, therefore No man ran.

216 
modes of personal supposition
would convert those determinate terms to merely confused terms. So one cannot have 
a complete induction with determinate terms in the premises and a determinate term 
in the conclusion (except for molecular cases, which are not the cases Sherwood had in 
mind). So Sherwood’s rule is a correct special case of a correct general principle about 
concluding with a term with wide distributive supposition in complete inductions.
I do not know at this point if there is always a way to provide a grammatical conclu-
sion for any proposed induction. For example, it is not clear to me how to conclude:
Every man who owns donkey #1 is running
Every man who owns donkey #2 is running
Every man who owns donkey #3 is running   etc. for all donkeys
?????
It seems that we can conclude:
Every man who owns a donkey is running
But this is weaker than the conclusion we want to draw, which requires every donkey to 
be owned. (Since each premise is affi  rmative, it requires that ‘man who owns donkey #n’ 
to be non-empty, and that entails that donkey #n is owned.) What we want to conclude 
is something like:
For each donkey, every man who owns it is running
However, this makes essential use of a pronoun with a grammatical antecedent. Th ese 
will be discussed in the next chapter.
7.10.2 Switching scopes (thereby switching modes of supposition)
Sherwood’s rule II and the fi rst half of rule IV are easy to sum up: It is fallacious to 
move a negation from the right of a determinate (rule IV) or merely confused (rule II) 
term to the left  of that term. If this is done then you have changed the term from 
determinate or merely confused supposition to distributive supposition, which is how 
Sherwood words the prohibition. Since our rules of inference do not contain such a 
provision for moving negations, Sherwood’s rules prohibit something which our rules 
of inference—fortunately—cannot produce. Th e prohibition of these negation moves 
is complemented by the fi rst half of rule V, which illustrates the principle that a move 
in the opposite direction is always OK—you can move a negation from the left  of a 
term to the right of that term if that term ends up with determinate or merely confused 
supposition. If this is done then you will have changed a term from distributive 
supposition to determinate or merely confused supposition, which is how Sherwood 
words the permitted cases. (Actually he only states the fi rst half.) I think this is a good 
principle, though I haven’t proved it here.
Th e second half of rule IV is more interesting. We can formulate it in general as this: 
If you move a denoting phrase from one place to another in the formula in such a way 
that it does not change its grammatical role, then if it had determinate supposition 

useful inferences again 
217
before the move and has merely confused supposition (and if its quantifi er sign 
remains with it and unchanged) aft er the move then the resulting proposition follows 
from the fi rst. Is this principle a good one? Well, if you change a term from determinate 
to merely confused, then you have moved it to the right, past a term with distributive 
supposition. And in general this is a good technique; it is like the valid quantifi er switch 
from ∃x∀y to ∀y∃x. In fact, sometimes this move is a good one even if you change the 
term’s quantifi er’s sign, as in:
Some A not some Bacc sees 
‘A’ has determinate supposition
∴ not some Bacc every A sees 
‘A’ has merely confused supposition
Th ere seems to be a good generalization here, but I am not sure how to state it.
7.10.3 Algorithms
Elizabeth Karger (1993) points out (424) that Buridan gives some rules similar to those 
just discussed, and (423–4) that those rules can be turned into an algorithm for entail-
ment between categorical sentences with the same quality and exactly the same two 
(non-parasitic) terms in each.41 A paraphrase of the algorithm that she gives is this:
Let P and Q be categorical sentences of the same quality and containing the same 
two (non-parasitic) terms. Th en:
(i) P and Q mutually entail one another iff  their terms have the same mode of 
supposition in both P and Q
(ii) P entails Q but not vice versa iff  these three conditions hold:
some term has a diff erent mode of supposition in P than in Q
no term has non-distributive supposition in P and distributive supposition in Q
no term has merely confused supposition in P and determinate supposition in 
Q, unless it is preceded by a term in P which has distributive supposition in P 
and determinate supposition in Q
Karger suggests (427) that it was a major goal of the theory of modes of supposition 
to provide such algorithms, since no author had provided a general theory of truth 
conditions even for categorical sentences, and inferences between categoricals outrun 
the familiar principles of conversion and subalternation. She may be right about this 
motivation. She also points out (429) that this type of approach cannot be extended to 
categoricals with three terms, and that an attempt to do so led John Dorp to mistakenly 
judge that the following two sentences, whose terms have the same modes of supposi-
tion, mutually entail each other:
At every time an animal every man is
At every time every man an animal is
41 See Dutilh Novaes 2007, section 2.4 for further discussion.

218 
modes of personal supposition
With our refi ned theory of modes of supposition we could point out that ‘man’ in 
fact has narrow distributive supposition in the former sentence and wide distributive 
supposition in the latter, and a parallel to Sherwood’s rules would include something 
like:
An inference from narrow to wide distribution holds, but not from wide to narrow.
However, even though this might save the algorithm for propositions with three terms, 
it is only a stopgap method, since it will fail for propositions with four terms, such as:
At every time a woman sells an animal to every farmer
At every time a woman sells to every farmer an animal
7.11 Modes of supposition as analyses of quantifi cation
Th ere has been a great deal of discussion in the secondary literature about the hypo-
thesis that modes of supposition were introduced by medieval logicians in an eff ort to 
explain quantifi cation.42 Th e idea is that the semantic eff ect of a quantifi er in a given 
position in a proposition is explained by doing a descent under that quantifi er. For 
example, the semantics of the word ‘some’ in this proposition:
Some donkey is grey
is explained by the fact that that proposition is a priori equivalent in truth value to this 
descended form:
Th is donkey is grey or that donkey is grey or  .  .  .  etc. for all donkeys
In fact, this disjunction looks a lot like some proposals 20th-century philosophers have 
made to analyze quantifi ers in terms of combinations of connectives. Th e primary 
stumbling block for this proposal is that in some cases—indeed, always in a case of 
merely confused supposition—descent is not to an equivalent proposition, but only 
to one that entails or is entailed by the original proposition. But this problem may 
be avoided by a more refi ned idea which is based on a set of principles that were 
developed by medieval authors, principles that are meant to govern the order in which 
one should analyze the terms in a proposition. Th ese principles came to be called in the 
secondary literature principles of “priority of analysis.”43 Th ree principles were usually 
included:
 • One should descend fi rst under a determinate term if there is one.
 • One should descend under a distributed term before descending under a merely 
confused term.
42 Cf. Matthews 1973 and references therein; Priest and Read 1977, 1980; Matthews 1984. (Note that 
Matthews denies that modes of supposition provide an analysis of quantifi cation.)
43 Cf. Swiniarski 1970, Matthews 1973, Spade 1976, Ashworth 1978.

modes of supposition as analyses of quantification 
219
 • When terms are grammatically related as determinable to determinant, one 
should descend under the determining term before descending under the deter-
minable term.
(Some examples of determinable terms are participles of transitive verbs that are 
determined by their direct object terms in the accusative case, or grammatically 
“possessed” terms that are determined by their “possessors” in the genitive case.) A key 
question to ask about these principles is why they should be obeyed; why should one 
do things in this order? Suppose that I have the proposition:
Some donkey is not a pet
which contains both a term, ‘donkey,’ with determinate supposition and a term, pet, 
with distributive supposition, and suppose that I violate the fi rst principle by descend-
ing under the distributed term to get:
Some donkey is not this pet, and some donkey is not that pet,  .  .  .  and so on for all pets44
Th is seems like a valid inference, so what is wrong with it? I think the intended answer 
is that if you do this you will indeed infer a consequence of the proposition you are 
dealing with, but you will not thereby produce an analysis of it. You won’t produce 
an analysis because you haven’t descended to an equivalent proposition. If instead 
you obey the rule, and descend under the term with determinate supposition, you get 
an analysis of the original proposition:
Th is donkey is not a pet or that donkey is not a pet or  .  .  .  etc. for all donkeys.
Of course these conjuncts still contain a common term, ‘pet’ which has distributive 
supposition. And now the priority rules allow us to analyze it, getting:
Th is donkey is not this pet and this donkey is not that pet  .  .  .  etc. for all pets
    or
Th at donkey is not this pet and that donkey is not that pet  .  .  .  etc. for all pets
    or
    .  .  .  .  .
  and so on for all donkeys.
So the original proposition turns out to be equivalent to an augmented disjunction 
of augmented conjunctions of propositions containing only singular terms. Ideally, if 
the priority principles are obeyed, it will always be possible to analyze a proposition 
into one containing only singular terms. Th ere are many interesting questions about 
what this sort of analysis achieves, but I will not try to settle them here; instead I will 
concentrate on exploring just how the theory works. I will also avoid discussing the 
signifi cance of the widely discussed fact that if these rules are obeyed one never 
44 In order to claim that this follows from ‘Some donkey is not a pet’ we may need to appeal to the “other 
option” in section 7.3.4 for handling the possibly empty term ‘donkey.’

220 
modes of personal supposition
descends under a merely confused term when it is merely confused. If you have a merely 
confused term it will be confused by the presence of a distributed term with wider 
scope. By the second principle, that distributed term is analyzed fi rst, and when all such 
distributed terms are analyzed they are replaced by singular terms, which confuse 
nothing—and so the original merely confused term becomes determinate, and is then 
a candidate for analysis. Th is fact has led some in the secondary literature to suggest 
that it was a theoretical mistake for medieval authors to include merely confused as a 
status for terms; I will ignore this issue here.45 (Th ough one should keep in mind that 
inference rules such as “From an inferior to a superior” apply to terms with merely 
confused supposition.)
How well do the three priority principles work? Let us consider applications of 
them, restricting ourselves to the notations developed so far. Clearly molecular propo-
sitions can be “analyzed” into conjunctions and disjunctions, since they are already in 
such forms. (And “as-of-now” conditionals, explained in section 5.9 are equivalent to 
disjunctions of the negation of the antecedent with the consequent.) So that leaves 
categorical propositions. Let us begin with the simplest cases: categorical propositions 
all of whose main terms are non-parasitic and simple.
7.11.1 Categorical propositions whose terms are non-parasitic and simple
For categorical propositions the rules given earlier are close to having the principle 
that you only analyze a term which is on the front and has widest scope. For if the rule 
about descending under a term which is determinate in the current proposition is 
applicable, then that term can’t be within the scope of a distributed term, for that would 
confuse it, and it cannot have a determinant term grammatically determining it, 
for this is ruled out by the third principle. So it is either on the front, or it is within 
the scope of other determinate terms and can be interchanged with them. Suppose 
instead that the second rule is applicable, and the term identifi ed to descend under is 
distributed. Must this be on the front? No, and this is a case for which the rules need 
adjusting. Consider a proposition like:46
Of every farmer some donkey sees every horse.
Now the rules as currently formulated permit us to descend under ‘horse,’ which is 
distributed. But if we do so, we do not reach an equivalent proposition. (Because, 
intuitively, ‘every horse’ does not have a wide enough scope.) Th e adjustment that 
is called for is clear; the rules should be expanded to say that one descends under 
a term with wide distribution before descending under a term that is merely confused 
45 One might note that if medieval authors had distinguished wide and narrow distribution, narrow 
distribution would be subject to the same charge. Th is would not worry some writers, such as Priest and 
Read 1980, who have also argued, in eff ect, that distribution ought to have been limited to wide distribution 
all along.
46 Th is example contains a parasitic term, but that is not essential. If we choose a verb that takes both 
direct and indirect objects we get ‘Every woman shows some farmer every horse.’

modes of supposition as analyses of quantification 
221
or narrowly distributed. Since ‘horse’ has narrow distribution in the example, the 
problem vanishes.
7.11.2  Categorical propositions whose terms are simple with one or more 
parasitic terms
Now let us consider parasitic terms. When there are no complex terms, parasitic terms 
are simple and they follow and are within the scopes of the terms on which they are 
parasitic. If those other terms are not singular, then by the discussion earlier about 
determinables we will descend under those other terms fi rst, until all terms which 
have the given parasitic term within their scopes are singular. Here is where restricted 
supposition becomes important. If a parasitic term has wider scope than any other 
common term, and if its determinant is a singular term, then we have seen earlier that 
it makes sense to descend under it by the principle of restricted descent discussed 
in section 7.5. As a result, parasitic terms behave under analysis just like other terms. 
Th is may be part of the reason why medieval logicians have so little to say about them. 
From a modern point of view parasitic terms are inherently relational, and so they 
are very special, but for many medieval purposes, such as analysis, this specialness 
doesn’t matter.
7.11.3 Categorical propositions with complex terms
Finally let us consider complex terms. Th e most common examples are common terms 
modifi ed by adjectives (or participles), and common terms modifi ed by relative clauses. 
In each of these cases principles of analysis can be applied to them as well. (Although 
I am not aware of cases in which this was done.)
Consider fi rst the term ‘grey donkey’ and suppose that we have reached the point 
where all quantifi er signs have been eliminated, and so this occurs in a proposition 
in the context ‘.  .  .  thisj grey donkey  .  .  .’ Since there are no quantifi er signs, this pro-
position will be equivalent to a conjunction of this form: ‘.  .  .  thisj grey-thing  .  .  .  and  .  .  . 
thisj donkey  .  .  .’ (See the rule of inference in section 5.5.1.) Th us the complex term is 
eliminated.47
In the case of a relative clause, it will help to consider the Linguish form, since this 
allows us to keep the relevant grammatical roles straight. We will have a proposition of 
the form
‘.  .  .  (thisj {F whichγ ψ} α) ϕ  .  .  .’
Th is will be equivalent to a conjunction of the form:
‘.  .  .  [(thisj F γ) ψ and (thisj F α) ϕ]  .  .  .’
47 In the actual case given, it would not be important to eliminate the complex term, since there are no 
quantifi ers within it. Th is would be diff erent for ‘this grey donkey which ψ’ if it had the logical form ‘(thisj 
{grey {donkey whichγ ψ}} α)’ when there are quantifi er expressions within ‘ψ.’ In this case, separating the 
adjective from the complex term that it modifi es yields an expression which is treated by other rules.

222 
modes of personal supposition
An example would be that ‘this donkey which some woman feeds is running’ becomes 
‘this donkey some woman feeds and this donkey is running,’ from the logical forms 
‘.  .  .  (thisj {donkey whichγ (some woman β) β feeds γ} α) α is running  .  .  .’ which is equivalent 
to ‘.  .  .  [(thisj donkey γ)(some woman β) β feeds γ and (thisj donkey α) α is running]  .  .  .’ 
(See the rule of inference in section 5.6.)
Some similar eliminations are possible with other sorts of complex terms. It is not 
clear how far this idea can be pushed. But since we have already gone beyond work 
done by medieval logicians, I will not pursue this further here.
7.11.4 Rules from inferior to superior and from superior to inferior
It is now possible to validate the inferior/superior principles discussed in section 7.7. 
Consider fi rst a common term T with determinate supposition in this context:
.  .  .  (Q T α)  .  .  .
Since T has determinate supposition, that proposition is equivalent to this disjunction:
.  .  .  (this T α)  .  .  .  or  .  .  .  (that T α) or  .  .  .  etc. for all T’s
Suppose that S is a superior of T. Th at means that the augmented disjunction is equiva-
lent to
.  .  .  (this S α)  .  .  .  or  .  .  .  (that S α) or  .  .  .  etc. for all S’s that are T
Th ere may, of course, be more propositions involving S’s of the same form. By the 
logic of ‘or,’ the proposition just displayed entails the result of extending it with more 
disjuncts:
.  .  .  (this S α)  .  .  .  or  .  .  .  (that S α) or  .  .  .  etc. for all S’s (including S’s that aren’t T)
Notice that the original proposition with S instead of T will be a proposition in which 
S has determinate supposition, and it will be equivalent to the disjunction just dis-
played. So:
.  .  .  (Q S α)  .  .  .
will follow from the original proposition. Th e superior is thus inferable from the 
inferior when the term has determinate supposition.
Suppose now that T has wide distributive supposition. Th en the argument here 
applies except that we are dealing with conjunctions instead of disjunctions, and 
we will be going from a conjunction about all the Ts to a sub-conjunction about all 
the Ss.
Suppose now that the term T has merely confused or narrow distributive supposition. 
If we follow the pattern described earlier in this section for analyzing the proposition 
containing T, we will end up with a disjunction of conjunctions of  .  .  .  of propositions 
involving T, in which it is not determinate or wide distributive. At this point the argu-
ments just given apply.

global quantificational import 
223
7.12 Global quantifi cational import
7.12.1 What are modes of common personal supposition?48
Th is is a long-standing problem in the secondary literature: We have defi nitions of the 
modes, but what are we defi ning?
What we have is a theory of what I call global quantifi cational import. Th is is the 
import a quantifi ed denoting phrase actually has, described in terms of the import it 
would have if it had scope over the whole global context (or almost the whole context).
Th is idea can be made precise within the theory of “prenex forms.” In contemporary 
symbolic logic, if no biconditional sign appears in a formula of quantifi cation theory 
then you can take any quantifi er in that formula and move it in stages toward the front 
of the formula, each stage being equivalent to the original formula, provided that you 
switch the quantifi er from universal to existential (or vice versa) whenever you move it 
past a negation sign or out of the antecedent of a conditional, and provided that you do 
not move it past a quantifi er of opposite quantity (i.e. you don’t move a universal past 
an existential, or vice versa). For example, you can take the universal quantifi er in:
¬(Gy → ∀xPx)
and move it onto the front of the conditional to get:
¬∀x(Gy → Px),
and then the resulting universal sign can be moved further front, turning into an 
existential:
∃x¬(Gy → Px).
Th is chain of equivalences can be interpreted as the movement of a quantifi er to the 
front, retaining its identity while sometimes changing its quantity. If you do this sys-
tematically to all the quantifi ers in a formula, the result is a formula in “prenex normal 
form,” in which the quantifi ers are all on the front in a row, each of them having scope 
over the rest of the formula to its right. In terms of these prenex forms you can defi ne 
the global quantifi cational import of any quantifi er in a main term in any categorical 
formula. Let us take this idea and use it to analyze the terminology of supposition 
theory. Th e subject matter here is terms, not quantifi ers, but each main term comes 
with its own quantifi er, so we can treat the theory as if it is a theory of restricted quanti-
fi cation (with denoting phrases being the restricted quantifi ers). We then give this 
account for terms in categorical sentences:
A prenex string for a formula ϕ is a string of affi  rmative denoting phrases on the 
very front of ϕ, with no other signs between them.
(Th at is, each is of the form ‘Every T’ or ‘Some T’ or ‘d,’ and there are no negations, 
and each denoting phrase has scope over the rest of ϕ to its right.)
48 Th is section covers material also discussed in Parsons 2008a.

224 
modes of personal supposition
An example with the prenex string underlined:
Every dog some donkey isn’t
Th ere is a systematic way to convert any categorical proposition into another one in 
which all of the main terms in the original one are in prenex position in the new one, 
and the converted proposition is logically equivalent to the original. Here is the process:
Change every main denoting phrase of the form ‘No T’ into ‘every T not,’ and every 
main denoting phrase of the form ‘a T’ into ‘some T.’ Th is leaves ‘every’ and ‘some’ as 
the only quantifi er signs on main terms.
Remove any double not’s anywhere in the formula whenever they appear.
Starting at the left , replace each ‘not every T’ by ‘some T not,’ and each ‘not some T’ by 
‘every T not,’ and each ‘not d’ by ‘d not.’ Remove double not’s whenever they appear.
Every categorical proposition has a unique prenex-convert produced by these rules.
Call the quantifi er signs ‘every’ and ‘some’ opposites. We can then defi ne:
a main term has (wide)/(narrow) quantifi cational import in a proposition iff  when 
the proposition is converted into prenex form the term (is not)/(is) preceded by a 
main term with the opposite quantifi er sign
a main term has (universal)/(existential) global quantifi cational import in a 
proposition iff  when the proposition is converted into prenex form the term ends 
up with (‘every’)/(‘some’) as its quantifi er sign
Th is defi nes global quantifi cational import for all main terms in any categorical 
proposition.
Note that the discussion here applies only to categorical propositions. If a term 
occurs in a conjunct of a conjunct, say, it may not be possible to move it to the front 
because the result is not grammatical. For example, if we move ‘every horse’ to the 
front of ‘some donkey is running and Socrates owns every horse’ we get ‘every horse some 
donkey is running and Socrates owns.’ We could make this work by altering the lan-
guage, but I’m not sure what the signifi cance of that would be.
applications
Say which terms have which kinds of quantifi cational import.
Every donkey sees every horse
Some donkey sees every horse
Some donkey sees of every farmer a horse
Every donkey sees of some farmer every horse.

global quantificational import 
225
7.12.2 Causes of the modes and global import
One can now establish the following equivalence between the previous classifi cations 
in terms of global quantifi cational import and the refi ned modes of supposition that 
are yielded by the rules governing causes of the modes in the last section, at least so far 
as categorical propositions are concerned. If these rules are applied to the categorical 
forms we have been discussing:
A term has determinate supposition according to the rules for causing modes of 
supposition iff  it has wide existential quantifi cational import
A term has merely confused supposition according to the rules iff  it has narrow 
existential quantifi cational import
A term has wide distributive supposition according to the rules iff  it has wide 
universal quantifi cational import
A term has narrow distributive supposition according to the rules iff  it has narrow 
universal quantifi cational import
Illustration: Let us test ‘donkey’ for its mode of supposition in ‘Some donkey is a predator.’ 
‘Donkey’ has determinate supposition here, because it is already in prenex form, 
existentially quantifi ed:
Some donkey is a predator
It has wide distributive supposition here, for the same reason:
Every donkey is a predator
Th e term ‘predator’ in the sentence just displayed has merely confused supposition 
because it is existentially quantifi ed with scope inside that of ‘every donkey.’
Now consider:
Some predator is not a donkey
in its equivalent form
Some predator not a donkey is
Here the ‘not a donkey’ is equivalent to ‘every donkey not,’ yielding:
Some predator every donkey isn’t
Th e original ‘a donkey’ has now become universal, thus classifying it as having dis-
tributive supposition. Th is illustrates the importance of looking at things globally; 
although ‘donkey’ is not preceded by any universal quantifying sign here, it has universal 
import. You could universally instantiate it! Th is is why it is classifi ed in this theory as 
distributive.

226 
modes of personal supposition
7.12.3 Parasitic terms
We have just established that a main term in a categorical proposition has a certain 
mode of supposition according to the rules for the causes of supposition iff  it has a 
corresponding quantifi cational import. But, as we have noted earlier, both of these 
disagree with the modes of supposition as defi ned in terms of ascent and descent in the 
case of parasitic terms. Such terms do not admit of either ascent or descent, and so they 
have no mode of supposition at all. Th e situation is summed up by:
A main term that is not parasitic has the mode of supposition that is attributed to it 
by the refi ned rules for the causes of modes of supposition—equivalently, if it has 
the corresponding global quantifi cational import.
Parasitic main terms have no modes of supposition, though they are classifi ed 
as having modes by the rules from causes of modes, and they do have global 
quantifi cational import.
As noted earlier, the useful rules “From a superior to an inferior” and “From an inferior 
to a superior” do not in general apply to parasitic terms.

relatives of identity 
227
8
Relatives (Anaphoric Words)
Medieval logicians use the grammatical term ‘relative’ for what we would call an 
anaphor—for an expression that has a grammatical antecedent.1 Relatives are divided 
into relatives of substance and relatives of attribute. An example of a relative of attribute 
is the ‘such’ in ‘Socrates is white and Plato is such.’ I will not discuss relatives of attribute 
here. So what follows is about relatives of substance. As Ockham and many others 
point out, relatives of substance do not always concern substances. For example, 
in ‘Every attribute inheres in whatever has it’ the ‘it’ is a paradigm of what is called a
 relative of substance, even though it is attributes, and not substances, that are under 
discussion. Buridan SD 4.4.2 (282) explains:
a relative term is not called [a relative term] ‘of substance’ for the reason that its antecedent has to 
be a term of the category of substance; on the contrary, its antecedent can be equally of any other 
category, as in ‘A white [thing] is a wall and it is seen,’ ‘A whiteness is in a wall and it is seen,’ 
‘A six-foot-tall [thing] sees itself,’ ‘My master rides his horse.’ Rather, it is called a relative term of 
substance, because it does not signify what it refers to, or that which it is taken for, to be of quality, 
to be of some quantity, or to be somewhere, and so on for the rest of accidental predications, but 
only to be something; relative terms of accidents, on the other hand, signify something’s being of 
some quality or being of some quantity or being somewhere, and so forth.
Relatives are divided into relatives of identity and relatives of diversity. An example of 
a relative of identity is the ‘it’ in ‘Socrates owns a donkey and Plato sees it.’ An example 
of a relative of diversity is the ‘other’ in ‘Socrates owns a donkey and Plato owns some 
other donkey.’ I will discuss relatives of identity and then (very briefl y) relatives of 
diversity.
8.1 Relatives of identity
Th e commonest accounts of relatives are rooted in a conception according to which 
a relative is a term which has supposition of its own; what that supposition is is deter-
mined by the term’s antecedent. Th e antecedent of a term determines both the kind of 
supposition the term has and what it supposits for. Th e most basic view is that a relative 
has the same kind of supposition its antecedent has—material, simple, or personal; 
1 Th e same term, ‘relative,’ was used for relational terms, such as ‘father.’ Th e two uses were kept distinct.

228 
relatives (anaphoric words)
ampliated or restricted; determinate, distributive, or merely confused—and (if it is 
a relative of identity) it supposits for exactly the same things as its antecedent. Th is 
view gets substantially qualifi ed and modifi ed, but the core idea persists.
Anonymous, Treatise on Univocation, 347: “an anaphoric pronoun must supposit for the same 
and in the same way as its antecedent.”
Peter of Spain SL 8.3: “A relative of identity is what refers to and supposes for the same item.”
Anonymous Cum sit nostra, 448: “the same supposition is in the relative and in its antecedent.”
Th ere is a good bit of discussion of relatives whose antecedents have material or simple 
supposition, as in ‘Man is a noun and it has three letters.’ For simplicity I will skip those 
discussions. So for the remainder of this chapter I will discuss only relatives that clearly 
have personal supposition.
A fundamental principle seems to be generally agreed on; I call it the replacement 
principle.
Th e Replacement Principle: A relative of identity may always be replaced by its 
antecedent if the antecedent is singular; otherwise it may not always be so replaced.
[I]t is not always permissible to put the antecedent in place of the relative. For saying ‘A man runs 
and he argues’ is not the same as saying ‘A man runs and a man argues,’ because for the truth of 
‘a man runs and a man argues’ it suffi  ces that one man run and another one argues. Instead, the 
rule ‘It is permissible to put the antecedent in place of the relative’ is to be understood as holding 
when the antecedent is singular and not common to [several] supposita. For saying ‘Socrates 
runs and he argues’ is the same as saying ‘Socrates runs and Socrates argues.’ (Burley PAL longer 
treatise para 117 (112))
Several other authors make this same point. I will take for granted that the positive part 
of this principle is included in all of the theories under discussion.
Rule SA (Singular Antecedents)
A proposition containing a relative of identity with a singular antecedent is 
equivalent to the proposition that results from replacing that relative with its 
antecedent.
applications
Suppose that a refl exive pronoun is symbolized just as a proper name is, with 
something in the notation to indicate which denoting phrase is its antecedent. 
Just using the rule for Singular Antecedents provide derivations for the follow-
ing arguments.

reflexive pronouns 
229
Some relatives are refl exive, like ‘herself,’ and some are not. I discuss refl exive pronouns 
in the next section.
8.2 Refl exive pronouns
Medieval authors use the Latin term ‘reciprocus’ for what we today call refl exive pro-
nouns. If a pronoun and its antecedent occur as the main terms of the same categorical 
proposition, then the pronoun must be refl exive. In English a refl exive third-person 
pronoun takes the form ‘itself/himself/herself ’ (unless it is genitive, when it takes 
the form ‘his/her/its’). In Latin a refl exive third-person singular pronoun is of one of 
the forms ‘se/sui/sibi.’ Refl exive pronouns occur as direct objects, such as ‘himself ’ in 
‘Socrates sees himself,’ and they also occur as genitives related to direct or indirect 
objects, as in ‘Each donkey sees its owner’ and in ‘Socrates sees his donkey.’
Th e Latin ‘reciprocus’ is oft en translated as ‘reciprocal’; however, ‘reciprocal’ has a 
technical meaning in modern linguistics, where it includes expressions like ‘each other,’ 
but it does not include e.g. ‘itself,’ which is a paradigm refl exive pronoun. I have thus 
changed ‘reciprocal’ to ‘refl exive’ in the translations, when necessary.
Writers oft en say that a relative has the same mode of supposition as its antecedent: 
determinate if the antecedent is determinate, distributive if the antecedent is distribu-
tive, and similarly for merely confused supposition. For refl exive pronouns this needs 
a major qualifi cation. Walter Burley (PAL, longer treatise, paras 125–6) explains a 
special mode of supposition that these pronouns have:
You need to know that a refl exive relative referring to a term in the same categorical has 
the same kind of supposition as its antecedent has. But the relative adds ‘singulation’ 
onto the supposition its antecedent has, so that if its antecedent supposits confusedly and 
distributively, the relative has confused and distributive ‘singled’ supposition. And if its 
antecedent supposits particularly, the relative supposits particularly ‘singly.’ For example, 
when someone says ‘Every man sees himself,’ ‘himself’ supposits confusedly and distributively 
singly.  .  .  .  [Confused and distributive singled supposition] diff ers from absolute confused 
and distributive supposition, because under a term that supposits absolutely and confusedly 
distributively one can descend to anything for which the distribution is made. But under 
 
Socrates sees Socrates
∴ 
Socrates sees himself
 
Socrates sees his donkey 
(Socrates sees of himself a donkey)
∴ 
Socrates sees Socrates’ donkey
 
Socrates is a man who sees every man
∴ 
Socrates sees himself

230 
relatives (anaphoric words)
a term that supposits confusedly and distributively singly one cannot descend absolutely to 
any suppositum. Rather, to any suppositum one can descend with respect to itself. Th erefore, it 
is called ‘singled’ supposition because it assigns singulars to singulars. For it does not follow: 
‘Every man sees himself; therefore, every man sees Socrates.’ But it quite well follows: ‘Every 
man sees himself; therefore, Socrates sees Socrates.’ 2
It is not clear exactly what the principle of descent is here. Burley speaks as if he 
is discussing a descent “with respect to itself ” under the relative ‘himself.’ But 
the illustration that he gives also involves a descent under its antecedent, ‘man,’ 
which is replaced by ‘Socrates.’ It appears that a descent cannot be made under the 
relative without also descending under its antecedent. Ockham (SL 1.76) makes this 
explicit:
It should also be noted that a relative of this sort has the same kind of supposition and supposits 
for the same things as its antecedent. However, when its antecedent supposits either confusedly 
and distributively or determinately, it has a similar form of supposition but exhibits this 
singularly—by referring particulars to particulars. Th erefore, it is not possible to descend either 
conjunctively or disjunctively or in any way other than with respect to something contained 
under the antecedent. For example, in ‘Every man sees himself,’ the word ‘himself’ supposits for 
every man by means of confused and distributed mobile supposition; but it does this singularly 
since it is not possible to descend without altering the other extreme. It does not follow that 
if every man sees himself every man sees Socrates. Nonetheless, it is possible here to descend 
to Socrates with respect to Socrates. Th us, ‘Every man sees himself; therefore, Socrates sees 
Socrates’.  .  .  .  Likewise, in ‘A man sees himself’ the word ‘himself’ supposits determinately yet 
singularly, for it is possible to make the descent only in the following way: a man sees himself; 
therefore, Socrates sees Socrates or Plato sees Plato or  .  .  .’ (and so on for all the relevant particu-
lars). It is also possible to ascend, but not in the following way: a man sees Plato; therefore a 
man sees himself. Th e ascent operates as follows: Socrates sees Socrates; therefore, a man sees 
himself.
Here, so far as inference is concerned, the point seems to be that one cannot descend 
under a refl exive without also descending under its antecedent, descending simultane-
ously to the same thing, and one cannot ascend to a refl exive without also ascending 
from its antecedent, and from the same thing.
2 Th is view is not original with Burley. Lambert (pt 8q(ii)) says: “sometimes a [refl exive] relative refers to 
a common term  .  .  .  But if the common term to which it refers is taken universally, then the [refl exive] rela-
tive refers to its distributive antecedent singularly or one by one for each and every one of the single things.” 
Th e same idea may be present in Sherwood (S 1.16) “although ‘himself’ is the same as ‘every man’ [accusative] 
with respect to supposita, nevertheless ‘himself’ and ‘every man’ [accusative] relate in diff erent ways to ‘every 
man’ [nominative]. Th us they diff er in respect of it, since ‘himself’ relates one of its supposita to one belong-
ing to ‘every man’ [nominative], and another to another.” Th e view became quite widespread. In addition to 
citations in the body of this chapter, it also occurs e.g. in Paul of Pergula L 2.4 (37–8): “when it is said: ‘Every 
man sees himself,’ the relative supposits distributively, just as the antecedent, not simply, but referring one 
each to one each, and on that account it does not signify that every man sees every man, but that this sees 
himself, and this himself, and thus of singulars.” It lasts at least until the 17th century; Poinsot OFL 2.13 (72) 
says it is called “imaged” supposition.

reflexive pronouns 
231
Buridan makes the same point in SD 4.4.6.3 See also Albert of Saxony QCL, Question 
18, especially paragraph 332.
Since in the 14th-century tradition modes of supposition are defi ned in terms of 
allowable descents and ascents, these discussions seem straightforwardly to character-
ize modes of supposition. As a by-product, these accounts are very informative about 
the eff ects of singled supposition regarding inferences. Marsilius of Inghen goes further 
in describing how one can accomplish this by descending under the antecedent of a 
relative alone while letting the relative remain unchanged. Although his case deals with 
a non-refl exive relative, there is a similar technique of descent:
Th e third rule is: a relative of identity has the same kind of supposition in the proposition 
in which it supposits as its antecedent: viz. materially, if its antecedent supposits materially, 
and personally, if its antecedent supposits personally, determinately, discretely, confusedly, 
or confusedly distributively in completely the same way as its antecedent supposits. I prove this 
rule solely on the basis of the intention of thought itself. Th e common way to understand the 
proposition every man is an animal and he runs, is that, just as the term man has confused dis-
tributive supposition, so the term he has confused distributive supposition. Th erefore, in all such 
propositions the valid inference is: every man is an animal and he runs, therefore this man is an 
animal and he runs, and so on. (TPT 1 (75))
Th e theory that is stated is worded so that it treats the ‘he’ in the example as a distributed 
term whose supposita are the same as the supposita of its antecedent ‘man.’ A descent 
under such a term would take the form:
Every man is an animal and he runs, therefore: every man is an animal and this man 
runs and every man is an animal and that man runs and  .  .  .  , and so on.
But Marsilius does not give a descent under the pronoun; he gives a descent under 
the antecedent term ‘man,’ with the relative left  totally unchanged. (Paul of Pergula L 2.4 
(38) also illustrates a descent in which the relative is preserved unchanged aft er 
descent.) Th ey seem to be employing the principle that rules of inference that normally 
apply to terms (or their denoting phrases) remain valid when those denoting phrases 
are antecedents of pronouns. Th is is indeed a very natural thing to do; we just apply all 
of our familiar rules—exposition, expository syllogisms, the quantifi er equipollences
—even when the denoting phrase in question is the antecedent of a pronoun. You just 
“leave the relative alone,” with the understanding that when the antecedent is modifi ed 
in some way, its new form is the antecedent of the same pronoun.4
3 Buridan: “Of the relative term ‘him/her/itself’ [se] we have to assert that it has the property of always 
being posited in the same categorical proposition as its antecedent, as in ‘Socrates likes himself.’ Its other 
property is that, if it is taken distributively, it is impossible to descend to one determinate suppositum thereof, 
the others remaining the same, rather it is necessary to descend one by one (sigillatim); for the inference 
‘Every man likes himself; therefore, every man likes Socrates’ is invalid, but you can infer, therefore, ‘Socrates 
likes Socrates and Plato likes Plato,’ and so on for the rest” (SD 4.4.6).
4 Th is “leave the relative alone” can be justifi ed on the grounds that, in a sense, the relative doesn’t really 
have supposition of its own. Poinsot OFL 2.13 (72) says “Th e [refl exive] relative supposes through the sup-
position of its antecedent, so that by descending or ascending from the antecedent the descent from the 
[refl exive] relative takes place.”

232 
relatives (anaphoric words)
In fact, we can do some reverse engineering and conclude that Burley, Ockham, and 
Buridan are committed to this principle in the examples they give. For suppose that 
this is a good inference:
Every man sees himself
Socrates is a man
∴ Socrates sees Socrates
By the rule for singular antecedents, these two are equivalent:
Socrates sees himself
Socrates sees Socrates
Th erefore any argument with the latter as a conclusion is just as valid as one having the 
former as a conclusion. So we have:
Every man sees himself
Socrates is a man
∴ Socrates sees himself
It is most natural to see the Burley–Ockham–Buridan inference then as involving a 
two-step inference: fi rst, descend in ‘Every man sees himself ’ under the antecedent 
‘man’ in the normal way to get ‘Socrates sees himself ’ and then substitute ‘Socrates’ for 
‘himself ’ by the replacement principle cited earlier, that any relative of identity may 
be replaced by its antecedent if its antecedent is singular. If that is how things work, 
singled supposition does not require any new principles of inference at all; it is a con-
sequence of already existing methods, none of which ever involve descending under 
a relative. (Th is conclusion will be sustained in discussion later.)
Before proceeding it may be of interest to expand somewhat the class of pronouns 
under discussion. Th e medieval authors focus specifi cally on refl exives, but there is 
a broader class of anaphoric pronouns of identity that also seem to work by the prin-
ciples just discussed: this is the class of such pronouns that already fall within the scope 
of their antecedents. All refl exives do this, but there are other cases as well. An example 
is the pronoun in:
Every man owns a donkey which sees him.
Th e pronoun is not refl exive, because it is not the “whole predicate,” but on the most 
natural construal it certainly falls within the scope of its antecedent. And the two 
principles we have been discussing seem to hold for it. Given that sentence together 
with ‘Socrates is a man’ we can infer:
Socrates owns a donkey which sees him.
And then by the replacement principle for pronouns with singular antecedents 
we infer:

relatives in linguish 
233
Socrates owns a donkey which sees Socrates.
I do not recall any medieval discussion of such examples, but they are so similar to the 
examples of refl exives that they do discuss, I will assume that the same techniques may 
be applied to them. It is also relevant that the main alternative account discussed later 
which is designed for non-refl exives cannot be applied coherently to these examples, 
since they do not have an applicable form (the antecedent is not in a categorical 
independent of the pronoun).
applications
Provide informal derivations for the following arguments.
At SL I.76 Ockham says that the fi rst of these is a good argument. Show that each 
argument is good using the techniques just discussed.
 
Socrates sees Socrates
 
Socrates is a man
∴ 
A man sees himself
 
A donkey sees itself
 
Brownie is a donkey
∴ 
Brownie sees Brownie
 
Some donkey sees itself
∴ 
Some donkey sees a donkey
8.3 Relatives in Linguish
Let me explore how to formalize this idea—that the notion of singled supposition 
can be captured in Linguish by already existing methods, together with the idea that 
a relative with a singular antecedent is equivalent to that antecedent. First, we need 
some way to encode the anaphoric relation between an expression and its antecedent. 
Th is is handled in contemporary linguistics by marking such pairs of expressions with 
indices: i, j, k,  .  .  .  , as superscripts or subscripts. I’ll do this. Any denoting phrase may 
have one index added to it so long as that index is not used on any other denoting 
phrase in the sentence. A potential anaphor, such as a pronoun, that is within the scope 
of such a denoting phrase, can have that index added to it as a superscript; So the 
sentence:
Socrates sees himself
will be generated by taking the form:
(Socrates α) (it β) α sees β

234 
relatives (anaphoric words)
and adding an index as follows:
(Socrates α)i (iti β) α sees β
We also stipulate that in its transition to surface form, any pronoun agrees with its 
antecedent in gender, and if it appears as a main term in the same categorical pro-
position as its antecedent, it must take the grammatically refl exive form. So the logical 
form just given yields ‘Socrates himself sees,’ or, in Latin, ‘Sortes se videt.’
Th is particular use of superscripts involves two theoretical choices: we consider 
pronouns themselves (such as ‘it’) as anaphors, instead of considering their whole 
denoting phrases (such as ‘(it β)’) as anaphors, and we consider whole denoting phrases 
(such as ‘(Socrates α)’) as antecedents instead of considering the terms within them 
(such as ‘Socrates’) as antecedents. Th ese choices minimize confusion when a pronoun 
occurs both as an anaphor and an antecedent; an example is:
Brownie is a donkey and he sees himself
where ‘he’ is an anaphor with ‘Brownie’ as its antecedent and it is also the antecedent of 
the anaphor ‘himself.’ Our Linguish representation will be:5
(Brownie α)i[(· donkey β) α is β and (iti δ)j(itj ε) δ sees ε]
Of course, medieval authors always took the terms themselves as being antecedents 
and anaphors, but this is consistent with our notation; we need only understand that 
when we place a superscript on a denoting phrase this is the equivalent of taking 
the head noun of that denoting phrase as the antecedent discussed by the medieval 
authors.
We will use the letters ‘i,’ ‘j,’ ‘k,’ ‘l,’ ‘m,’ and ‘n’ as indexes. Our specifi c rules for adding 
indices to fully formed propositions are:
Indexing propositions
Any denoting phrase may have an index added to it as a right superscript, so 
long as no other denoting phrase has the same index.
Any pronoun may have an index added to it as a right superscript if it is within 
the scope of a denoting phrase with that superscript.
8.3.1 Th e semantics of relatives that fall within the scope of their antecedents 
Th e medieval descriptions of singled supposition did not say what their semantics is to 
be. We will do so by describing the eff ect of the indexing just described. To accomplish 
this we stipulate that when an indexed antecedent is changed to a temporary name in 
its semantic analysis, any pronoun anaphorically co-indexed with that antecedent is 
5 Th e use of square brackets in this example will be discussed shortly.

relatives in linguish 
235
to be replaced by a copy of the same name, and the indices are dropped. An example 
with ‘every’:
Semantic rules for indexed denoting phrases:
If T is a common term that supposits for something, then ‘τi(every T α)jϕ’ is 
trueσ iff  for every thing a that T supposits for, τi(§k α) ϕ* is trueσ[§k/a], where ϕ* 
is got from ϕ by replacing every occurrence of ‘itj’ by ‘§k.’
If T does not supposit for anything, ‘τi(every T α)jϕ’ is trueσ iff  ‘τi(§k α) ϕ*’ is 
trueσ[§k/-].
and similarly for denoting phrases with other quantifi er signs.
As a result, the sentence ‘Socrates sees himself ’ has the following truth conditions with 
respect to an arbitrary assignment σ:
‘(Socrates α)i (iti β) α sees β’ is trueσ
   iff 
‘(§1 α) (§1 β) α sees β’ is trueσ[§1/s]   <where s is Socrates>
   iff 
‘sees’ holds of <σ[§1/s](§1), σ[§1/s](§1)>
   iff 
‘sees’ holds of <s,s>
   iff 
s sees s
Th e same device works when the refl exive pronoun is possessive, as in ‘Socrates sees 
his donkey’:6
‘(Socrates α)i (iti β)(· donkey-poss-β γ) α sees γ’ is trueσ
   iff 
‘(§1 α)(§1 β)(· donkey-poss-β γ) α sees γ’ is trueσ[§1/s]   <where s is Socrates>
   iff 
for some donkey d had by σ[§1/s](§1), ‘(§1 α)(§2 γ) α sees γ’ is trueσ[§1/s][§2/d] 
7
   iff 
for some donkey d had by s, ‘sees’ holds of <σ[§1/s][§2/d](§1), σ[§1/s][§2/d](§2)>
   iff 
for some donkey d had by s, s sees d
6 Th ere is a complication here to be taken care of somehow. In Latin, the possessive would be an adjective, 
which would typically follow the possessed in surface order. But the Linguish logical form requires that the 
term for the possessor precede the term for the possessed, since the possessor term binds the extra variable 
in the possessed term. Th is requires a special provision in the generation of the surface Latin from the logical 
form that has not been worked out here.
7 Th is derivation cheats at this point by assuming that ‘donkey-poss-α’ is not empty when Socrates is 
assigned to ‘§1.’ Cheating can be avoided by a slightly more complicated derivation which arrives at the same 
conclusion.

236 
relatives (anaphoric words)
8.3.2 Rules of inference for indexed expressions
Th e main innovation required in rules of inference to handle singled supposition is 
one that is so obvious it almost escapes notice. Th is is the principle that when a term 
is instantiated, if it is the antecedent of a pronoun, the term that it is instantiated to 
receives the index of the instantiated term, and thus it becomes the new antecedent of 
the pronoun. For example, in the inference:
Every donkey sees a horse that sees it.
Brownie is a donkey
∴ Brownie sees a horse that sees it.
if ‘donkey’ is the antecedent of the pronoun ‘it’ in the fi rst premise, then ‘Brownie’ is the 
antecedent of that pronoun in the conclusion. Th e inference takes the form:
(Every donkey α)i(a {horse whichγ (iti δ) γ sees δ} β) α sees β
(Brownie α)(· donkey β) α is β
∴ (Brownie α)i(a {horse whichγ (iti δ) γ sees δ} β) α sees β   by rule UA
Although this seems almost trivial, it needs to be made explicit when we specify our 
rules of inference. A similar pattern occurs with the quantifi er equipollences. Th is is an 
example of a quantifi er equipollence:
Not every donkey sees a horse that sees it.
Some donkey doesn’t see a horse that sees it.
When ‘not every donkey’ turns into ‘some donkey not,’ if the original antecedent of ‘it’ 
is ‘every donkey,’ the resulting antecedent is ‘some donkey.’
not (every donkey α)i(· {horse whichγ (iti δ) γ sees δ} β) α sees β
(some donkey α)i not (· {horse whichγ (iti δ) γ sees δ} β) α sees β
Here are several rules from Chapter 4 with indices added:
Quantifi er equipollences:
(every T α)i 
≈ (no T α)i not 
≈  not (some T α)i not
etc.
Singular terms permute:
(t β)i(quant T α)j 
≈ (quant T α)j(t β)i, 
with quant: every, some, no
etc.
EX 
(some T α)i ϕ
 
<T is non-empty>
 
/∴ (n α)i ϕ
 
/∴ (n α)(some T β) α is β
where n is a name that does not already occur in the derivation

relatives in linguish 
237
ES 
(n α)i ϕ
 
(n α)(some T β) α is β
 
/∴ (some T α)i ϕ   where ‘n’ is any singular term
Non-emptiness:
(some T α)i ϕ
/∴ <T is non-empty>   if ‘(some T α)i ϕ’ is affi  rmative
etc.
Subalternation
(every T α)i ϕ 
 
(no T α)i ϕ
/∴ (some T α)i ϕ 
/∴ (some T α)i not ϕ
Substitutivity of identity:
(n α)(m β) α is β
(n α)i ϕ
/∴ (m α)i ϕ
Universal application [derived rule]
(every T α)i ϕ 
 
(no T α)i ϕ
(n α)(some T β) α is β 
 
(n α)(some T β) α is β
/∴ (n α)i ϕ 
/∴ not (n α)i ϕ
Interchange of indices (this may already be a derived rule)
Any proposition is equivalent to the result of replacing any index in it (in all its 
occurrences) by an index that does not occur in it.
And here is an example from Chapter 5 of a case in which a relative pronoun is itself 
an antecedent:
(every {donkey whichγ
i (iti δ) γ sees δ} β) β is grey
Every donkey which sees itself is grey
RelClause:
 
(n α)(· {T whichγ
i ϕ} β) α is β
∴ 
(n α)(· T β) α is β
∴ (n γ)i ϕ
 
(n α)(· T β) α is β
 
(n γ)i ϕ
∴ 
(n α)(· {T whichγ
i ϕ} β) α is β
Finally, we need to offi  cially adopt the special rule of inference that lets relatives with 
singular antecedents be replaced by those antecedents, and vice versa:

238 
relatives (anaphoric words)
Replacement rule for Singular Antecedents:
Suppose that ϕ contains a relative of the form ‘(iti γ)’ and no denoting phrase in 
ϕ is indexed with ‘i.’ Th en ‘(t α)i ϕ’ is equivalent to ‘(t α) ϕ*,’ where ‘ϕ*’ is the 
result of replacing any ‘(iti γ)’ in ‘ϕ’ by ‘(t γ).’
It is straightforward to see that the examples of good inferences involving refl exive 
relatives of identity given in the passages quoted earlier are validated by these rules. 
An example is ‘Every man sees himself; therefore, Socrates sees Socrates.’ Th is inference 
(with the added premise that Socrates is a man) would go:
1.
2.
3.
4.
(Every man α)i(iti β) α sees β
(Socrates α)(· man β) α is β
(Socrates α)i(iti β) α sees β
(Socrates α)(Socrates β) α sees β
1 2 UA
3 Singular Antecedents
Th is account also seems to work well for cases in which non-refl exives fall within the 
scope of their antecedents. Some examples are:
(Every man α)i(·{horse whichγ (iti β) γ saw β} δ) α saw δ
Every man saw a horse which saw him
(Every {man whichε
i (·{horse whichγ (iti δ) γ saw δ} β) ε saw β} α) α is running
Every man who saw a horse which saw him is running
(note that the antecedent of ‘it’ in the second example is ‘whichε,’ which is considered 
to be a denoting phrase for present purposes.)
Here is another example; a statement of transitivity of the exceeds relation:
(Every number α)i(every {number whichγ (·{number whichη (iti ε) ε exceeds η} δ) 
δ exceeds γ} β) α exceeds β
Every number exceeds every number which a number which it exceeds exceeds.
applications
Produce the Linguish logical forms that generate these sentences and provide 
formal derivations for the following arguments.
(At SL I.76 Ockham says that the fi rst of these is a good argument.)
 
Socrates sees Socrates 
 
A donkey sees itself
 
Socrates is a man 
 
Brownie is a donkey
∴ 
A man sees himself 
∴ 
Brownie sees Brownie
 
Some donkey sees itself
∴ 
Some donkey sees a donkey

non-reflexive relatives of identity 
239
We now turn to the cases in which the pronoun is (at least apparently) not within the 
scope of its antecedent.
8.4 Non-refl exive relatives of identity
Most medieval theorizing deals with non-refl exive relatives of identity. Th e standard 
theory of non-refl exive relatives gives content to relative terms of identity. It identifi es 
the mode of supposition of such a term as being the same as that of its antecedent. 
And the theory also identifi es what the relative supposits for. Sometimes it seems that 
a non-refl exive relative term is thought to supposit for exactly what its antecedent 
supposits for. Peter of Spain says:
On the relative of identity the following rule is given:
every non-refl exive relative of identity should have the same supposition 
that its antecedent has.
For example, when someone says ‘every man runs, and he is Sortes,’ the relative ‘he’ supposes for 
every man, and the meaning is ‘he is Sortes’ or ‘every man is Sortes.’ (LS 8.15)
Th is seems pretty clear. And on this account non-refl exive relatives can be paraphrased 
in terms of their antecedent coupled with whatever quantifi er sign is needed to give it 
the same mode of supposition as the antecedent. Th e sentence ‘every man is running 
and he is Socrates’ does indeed seem to be logically equivalent to saying that every man 
is running and every man is Socrates. So the stated account at least has the intended 
truth conditions in this case. However, this simple account will not work in other cases. 
Th is is pointed out in several places, such as this comment by Walter Burley (already 
quoted):
You need to know that it is not always permissible to put the antecedent in place of the relative. 
For saying ‘A man runs and he argues’ is not the same as saying ‘A man runs and a man argues,’ 
because for the truth of ‘A man runs and a man argues’ it suffi  ces that one man runs and another 
one argues. (PAL, longer treatise, para. 117 (112))8
A modifi cation of the theory is needed. Buridan SD 4.4.3 states a theory that he 
suggests is already widely held:
Th e universal rule is that a relative term of identity need not supposit or stand in a proposition 
for all those things which its antecedent supposits or stands for. On the contrary, the relative 
term refers back to its antecedent only with respect to those of the antecedent’s supposita for 
8 Peter himself seems to know about this example and to agree with Burley’s point. In LS 8.6 (165) he says: 
“From what was said it is clear that all relatives of identity recall a substance identical with its antecedent and 
that they recall and stand for the numerically same thing. It is also clear from this, that more certainty is 
eff ected by a relative of identity than by its antecedent substituted for a relative. In ‘a man is running, a man is 
debating,’ it is dubious whether the same man is spoken of or not. But in saying: ‘a man is running and that 
one is debating,’ it is certain that the same man is spoken of.”
Ockham SL I.76 uses the same example, while making a sweeping claim: “when the antecedent of a relative 
is a common term with personal supposition, one can never, by substituting the antecedent for the relative, 
generate a proposition which is convertible with and equivalent to the original proposition. Th us, ‘A man 
runs and he disputes’ and ‘A man runs and a man disputes’ are not equivalent.”

240 
relatives (anaphoric words)
which the categorical proposition in which the antecedent occurred was verifi ed; hence, the 
proposition ‘An animal is a man and he is a donkey’ is false.9
From this rule it is immediately evident that a relative term cannot be more ampliated than its 
antecedent is ampliated. Th us, if I say ‘A man runs and he disputed,’ the relative term ‘he’ supposits 
only for present[ly existing men], just as ‘man’ does. But [the relative term] can be more restricted, 
for if I say ‘A man runs and he is white,’ then the antecedent ‘man’ supposits for all men, although 
indefi nitely, but the relative term ‘he’ does not so supposit for all men, but only for those for 
which the proposition ‘A man runs’ is true, and if it were true for none, then the relative term 
would supposit for nothing, whence both members of the previous conjunctive proposition 
would be false if no man were running, even if all men were white.
Marsilius of Inghen TPT 1 (73, 75) makes pretty much the same point.10 He then goes 
on to clarify:
A relative does not necessarily supposit for as many instances as its antecedent,  .  .  .  For it does 
not have supposition in a proposition other than for those instances for which its antecedent is 
verifi ed in the proposition in which it is used, whereas an antecedent oft en supposits for many 
more instances. As in the case an ass is an animal, the term animal stands distributively11 for all 
animals, but is verifi ed only of brayers.
So the relative is supposed to supposit for only those animals for which the proposition 
containing the antecedent is verifi ed. Hülsen 1994 and 2000 (43) points out that this 
is almost exactly the same as a proposal put forward in the 20th century by Gareth 
Evans 1977 (499) in his discussion of what became known as E-type pronouns. Evans 
says: “Roughly, the pronoun denotes those objects which verify (or that object which 
verifi es) the sentence containing the quantifi er antecedent.” Th is has been a very infl u-
ential idea in the last few decades, though there is no agreement on its details.
In order to implement this idea, we need to be clear about which things a term is 
verifi ed for in a proposition. In the simple cases discussed here, it appears that this may 
be characterized as follows: a main term ‘P’ in a proposition ‘.  .  .  P  .  .  .’ is verifi ed for 
exactly those things that the complex term ‘P which  .  .  . .  .  .’ supposits for (dropping 
any quantifi er sign in front of ‘P’). For example, in:
 9 Both Burley (PAL, longer treatise, Chapter 4, para. 117) and Ockham (SL I.76, 218) also speak of relatives 
being limited to what their antecedents are verifi ed for, but it is unclear to me exactly what they are saying.
10 “A relative of identity does not have supposition unless its antecedent is verifi ed concerning some-
thing.  .  .  .  otherwise it would be true to say an ass is an animal and that is a man, because if that were to stand 
for animals other than for those concerning which animal is verifi ed in the proposition an ass is an animal, 
then it would stand for man, because it would stand for all animals; therefore the subject and the predicate of 
the proposition and that is a man would stand for the same thing. Th erefore the proposition would be true. 
.  .  .  [but] on hearing the [original] proposition, it is understood that the same animal that is an ass is a man.  .  .  . 
From this the corollary is inferred: it does not follow that, if an antecedent, used instead of a relative, were to 
cause a proposition to be true, a relative used in the same place, would also cause it to be true. For whilst it is 
true to say an ass is an animal and an animal is a man, it is false to say: an ass is an animal and the same is a 
man. Th e reason is that the antecedent of the relative supposits for more cases than the relative itself.”
11 I don’t know why he says “distributively.” It is clear that the term has determinate supposition. (If the 
indefi nite article is read universally, then ‘animal’ still does not stand distributively; it has merely confused 
supposition.)

non-reflexive relatives of identity 
241
An ass is an animal
the term ‘animal’ is verifi ed for whatever this term supposits for:
animal which an ass is
Th at is, it is verifi ed for all those animals that are asses. So in the example ‘an ass is an 
animal and the same is a man’ the term ‘the same’ supposits for animals which are asses. 
In the example, that means that
an ass is an animal and the same is a man
is equivalent to:
an ass is an animal and an animal which an ass is is a man
(where the ‘an’ preceding ‘animal’ in the underlined passage is there to cause the relative 
to have determinate supposition, as does the antecedent of ‘the same’). Th is seems to 
have the right truth conditions. (If this isn’t obvious, note that the second conjunct of 
the lower sentence is logically equivalent to the whole upper sentence, and the fi rst 
conjunct of the lower sentence is redundant.)
Can the theory be extended to other sorts of examples? Burley discusses the 
proposition
A man argues and his ass runs
Th e theory under discussion would replace the relative ‘his’ with a term suppositing 
for those things that the term ‘man’ is verifi ed for in the fi rst conjunct. Th is yields 
(changing ‘which’ to ‘who’):
A man argues and an ass of a man who argues runs
Th is too seems to be logically equivalent to the proposition under discussion.
It turns out that this example is typical, in the sense that the vast majority of examples 
of non-refl exive relatives of identity discussed by writers have this syntactic form: 
a conjunction of two simple categorical propositions in which a relative in the second 
conjunct has a quantifi ed antecedent in the fi rst conjunct.
Some forms of this sort are a bit odd, though they were taken to be coherent by 
medieval writers. Here are a few natural combinations each followed by a paraphrase 
equivalent to what is yielded by the analysis of relatives under discussion:
A man sees a donkey and he speaks
A man sees a donkey and a man who sees a donkey speaks
A man sees a donkey and it is grey
A man sees a donkey and a donkey which a man sees is grey
A man sees every donkey and he speaks
A man sees every donkey and a man who sees every donkey speaks

242 
relatives (anaphoric words)
A man sees every donkey and it is grey
A man sees every donkey and every donkey that a man sees is grey
Every man sees every donkey and he speaks
Every man sees every donkey and every man who sees every donkey speaks
Every man sees every donkey and it is grey
Every man sees every donkey and every donkey which every man sees is grey
Every man sees a donkey and he speaks
Every man sees a donkey and every man who sees a donkey speaks
Every man sees a donkey and it is grey
Every man sees a donkey and a donkey which every man sees is grey
It is easy to tell by inspection that in each of these cases the paraphrase is what is 
intended as the analysis of a relative as having a mode of supposition the same as its 
antecedent and suppositing for the things that its antecedent is verifi ed for. And in 
every case but the last, the result of the analysis is a proposition having truth conditions 
equivalent to the proposition containing the relative. (At least, that is my judgment.) So 
one can see why this approach was taken to be plausible. Th e last example, however, 
seems to me to be clearly incorrect. And it is just the tip of an iceberg.
In the second half of the 14th century a number of writers discussed relatives, and 
a major theme of some of their writings was the many faults in the view that relatives 
supposit for the same things as their antecedents. Th ese writers also go on to fi nd fault 
with the revised view that we have been discussing, that a non-refl exive relative sup-
posits for whatever its antecedent is verifi ed for. A common type of counterexample 
uses disjunctions or conditionals instead of conjunctions. For example:
A man is a donkey or he is a man12
In this example the antecedent is verifi ed for men who are donkeys, namely, for 
nothing. As a result, the second disjunct contains a relative without supposition, and 
it is thus false. Since the fi rst disjunct is clearly false, the whole proposition must be 
false on the theory in question. But it is taken to be true. Another example is:
God is not, if he is13
Th e fi rst clause is verifi ed for gods which are not, namely for nothing. So the ‘he’ in the 
second clause lacks supposition, and thus the second clause is false. Since that clause is 
the antecedent of a conditional, the whole conditional, which is the proposition in 
question, is true. (Th e proposition is true if the conditional is read “as-of-now.” I think 
12 Bernhard Berwart, L, 277 in Hülsen 1994. Similar examples also appear in other works edited in 
Hülsen: Hugo Kym, STR, 301; Anonymous, Q, 426.
13 Bernhard Berwart, L, 277.

non-reflexive relatives of identity 
243
it would also be true on the reading under discussion even if it were read as a strict 
conditional.) But it is taken to be false.
Some authors, such as Bernhard Berwart, conclude that the principle that a non-
refl exive relative supposits for those things that the antecedent is verifi ed for:
should be understood to be about relatives put in conjunctions, not in disjunctions 
or conditionals; rather, a relative in a disjunction or in a conditional refers to its 
antecedent without restriction. (L, 278)14
With this provision, ‘he’ in the fi rst example supposits for men in general, and ‘he’ in the 
second example supposits for God, and both examples turn out to have the intended 
truth values. And this seems to have evolved into a general view, for it is endorsed by 
one author over a century later.15 But this success does not extend to other examples. 
For example, the ‘it’ in:
Every donkey is grey or it is not grey
would supposit for every donkey, and would have distributed supposition, so the prop-
osition would be equivalent to:
Every donkey is grey or every donkey is not grey
Th is is false, though I think that the original proposition would be taken to be true. 
And:
Every animal is grey if it is a donkey
would be equivalent to:
Every animal is grey if every animal is a donkey
But this is true—because it has a false antecedent—whereas the original proposition 
is false.
I think that some of these counterexamples might be got around, at least by tinkering 
with the details of the theory. But I don’t think it can be saved in the end. For consider 
this example:
Every thing is a being, and either it is God or it is created by God
where the antecedent of each ‘it’ is ‘thing.’ Th e basic theory would yield truth conditions 
something like:
14 A similar diagnosis appears in Hugo Kym, STR, 301.
15 Broadie 1985 (74) quotes a discussion by David Cranston (early 16th century) which states this gener-
alization, concluding: “in the affi  rmative conjunction it is not permissible, in place of the relative, to put its 
antecedent without restriction, but  .  .  .  it is permissible in the case of the affi  rmative disjunction, the negative 
conjunction, and the conditional.”

244 
relatives (anaphoric words)
Every thing is a being and either every thing which is a being is God or every thing 
which is a being is created by God
Th is is false, while the original sentence is true. Th e problem is one of principle: by 
parity both ‘it’s’ must be treated alike, and no matter what they supposit for the analysis 
will come out false. (Examples of this sort also cause trouble for modern attempts to 
treat these pronouns as E-type pronouns.)
It seems to me that the theory under discussion is not likely to have any kind of 
workable version. (Th ough I hope I am wrong.)
8.5 Applying the singulation theory
At this point a suggestion in Hülsen 2000 (40) is pertinent. He notes
Surprisingly, the concept of supposition singillatim [what I am calling singled supposition] was 
diagnosed only in the case of refl exive relatives. It should have appeared natural to analyze 
sentences such as [‘A man is debating and he is running’] with its help.
I agree completely with Hülsen. I think that the theory developed earlier for refl exive 
relatives can handle most of the problem cases, including all of those mentioned in 
section 8.4. For example, a paraphrase for
A man is a donkey or he is a man
would be:
A man xk is a donkey or xk is a man
And
Every animal is grey if it is a donkey
would be:
Every animal xk is grey if xk is a donkey
which is false as desired.
In fact, there is some evidence that some medieval logicians did exactly this. We 
have already seen (in section 8.2) that Marsilius of Inghen illustrates what appears 
to be the singulation theory applied to a non-refl exive example, ‘every man is an 
animal and he runs.’ Th is sort of example is also illustrated by Richard Campsall L, 
Chapter 60, p. 229:
just as the antecedent in a universal affi  rmative proposition which is part of a conjunction 
supposits confusedly and distributively, so does the relative which refers to the antecedent also 
supposit distributively, for example, in saying thus: ‘every man runs and he disputes,’ for just as 
‘man’ supposits confusedly and distributively, so does this relative ‘he.’ Nevertheless this ought 
not to be understood so that a descent is made under the antecedent for one individual and 

applying the singulation theory 
245
under the relative for another, but under both for the same; for instance in saying ‘every man 
runs and he disputes’; therefore Socrates runs and disputes, and Plato runs and Plato disputes, 
and thus of the others. And this is to be understood properly and in virtue of the words, although 
thanks to the matter it could be done otherwise.
Indeed, another medieval logician seems, in essence, to propose as a perfectly general 
principle that regardless of how the mode of supposition of a relative is described, one 
can never descend under the relative itself. Richard Lavenham says (Spade 1974, page 
98, paragraph 20, my translation):
it should be known that no relative has descent to its supposita, because it does not have supposi-
tion from its own self, but from its antecedent. And for that reason if it is asked in what way 
‘he’ supposits in this proposition ‘Any man runs and he is white,’ it should be said [to supposit] 
confusedly and distributively. But if it is asked further in what way it has [descent], it should be 
said that it doesn’t have descent, because a relative lacks descent to supposita.
So although relatives in general are described as having the same mode of supposition 
as their antecedents, this is not an exact statement, for they have their modes of sup-
position in a kind of parasitic way. And as far as inference is concerned, you can’t 
descend under them at all. And this applies to non-refl exives as well as refl exives, as 
Lavenham’s example illustrates. I think that this approach is workable.
Th e theory seems relatively clear, but we have not yet seen how to implement its 
logical forms. For our particular idea for making non-refl exive relatives depend on 
their antecedents just as refl exives do requires those relatives to be within the scopes of 
their antecedents. So we need to face a question that was postponed from section 5.10: 
how can we get a term in an earlier categorical proposition to have scope over a relative 
that occurs in a later categorical proposition? Th ese are examples like ones we have 
already seen in earlier sections:
Every man is running and he is Socrates
An ass is an animal and the same [animal] is a man.
Every man is an animal and every risible is it [i.e. is the animal]
Th e simplest way to give the antecedents in these examples scope over their anaphors 
would be to expand our conditions for generating conjunctions and disjunctions from 
Chapter 5 so as to form molecular formulas which contain unfi lled roles. For example, 
in addition to generating the conjunction:
[(Every man α) α runs and (·farmer β)(Socrates γ) β is γ]
Every man runs and a farmer is Socrates
we could instead generate a structure like:
(Every man α)[α runs and (·farmer β)(Socrates γ) β is γ]
Every man [runs and a farmer is Socrates]
where the initial denoting phrase has scope over both categoricals within the brackets.

246 
relatives (anaphoric words)
A similar example with anaphora would be:
(·man α)i[α runs and (iti β)(Socrates γ) β is γ]
A man [runs and he is Socrates]
Th is raises a problem of grammatical principle. Aren’t the natural language sentences 
under discussion conjunctions (or disjunctions, or conditionals)? It would seem that 
putting a denoting phrase on the front with scope over the whole means that we do not 
have a conjunction; we have a denoting phrase in front of something like a conjunction. 
Isn’t that wrong? Th is very problem already occurs in English with a sentence like:
Every woman showed up and she brought a book.
Grammatically this seems like a paradigm conjunction. But there is something odd 
about the second conjunct:
she brought a book
since it seems to have no self-contained meaning on its own. It gets its meaning from 
the denoting phrase on the front of the sentence. It appears perhaps that the surface 
syntax of the sentence is at odds with its semantics. Th is is an option worth considering. 
Linguists already take seriously the idea that there is more to logical form than surface 
syntactical form. For example, surface syntactical form oft en leaves quantifi er scopes 
unsettled; it is common to hold that a sentence in addition to its surface form has a 
logical form that includes displaced quantifi ers which have scope. In most of the theory 
we have been dealing with, medieval theorists have taken advantage of the fl exible 
word order of Latin to make a usable syntax where logical form and grammatical form 
are the same. Perhaps we need to extend that idea a bit to have an adequate theory of 
relatives. It is easy to develop such a theory using Linguish notation. We just expand 
our formation rules from section 5.10 by inserting the word ‘partial’ as follows:
If ϕ is a partial categorical proposition and ψ is a categorical proposition with no 
free markers, then these are partial categorical propositions:
[ϕ and ψ]
[ϕ or ψ]
[ϕ if ψ]
Our old formation rule lets us generate these “partial” categorical propositions:
α runs
(·farmer β)(Socrates γ) β is γ
Our new one lets us put them together to get this partial categorical proposition:
[α runs and (·farmer β)(Socrates γ) β is γ]

applying the singulation theory 
247
By a previous generation rule we can put a denoting phrase on the front to get our fi rst 
sample sentence:
(Every man α)[α runs and (·farmer β)(Socrates γ) β is γ]
Every man runs and a farmer is Socrates
Starting instead with the partial propositions:
α runs
(it β)(Socrates γ) β is γ
we can put them together by our new provision to make:
[α runs and (it β)(Socrates γ) β is γ]
and then we add a denoting phrase to the front using our old rules:
(Every man α)[α runs and (it β)(Socrates γ) β is γ]
Our rules for adding indices then lets us make:
(Every man α)i[α runs and (iti β)(Socrates γ) β is γ]
Every man runs and he is Socrates
in which the initial denoting phrase is the antecedent of the pronoun.
Notice that the surface sentences we are generating are indistinguishable in wording 
from ordinary conjunctions, which explains perhaps why their special forms would 
not be noticed. We may need to restrict the formation of such sentences so as to 
disallow the occurrences of negatives, so as not to produce:
No donkey [is grey and it is running]
A donkey not [is grey and it is running]
Th is is because many people tend to see such wordings as ill formed. However, within 
the medieval tradition this is not completely clear. So I will simply ignore examples of 
this sort.16
16 As stated, our generation principles may be too permissive. Th is is pointed out in Anonymous, Treatise 
on Univocation (340): “we also say that a [pronominal] reference cannot be made to a predicate preceded by 
a negative particle, a particle which is confused and which makes the predicate be held confused, as in: 
‘Antichrist is not an animal, and that [animal] exists’ or ‘.  .  .  does not exist.’” Th e example does seem odd, so 
maybe we should prohibit it. However, writers disagreed about this. For example, Lambert, PT, section 8o, 
says, “when one says ‘A man is not a donkey, and he is rational,’ ‘he’ can refer to ‘man’ (in which case it is true) 
or to ‘donkey’ (in which case it is false). Another example concerns antecedents with ‘no.’” Later in the Treatise 
on Univocation (349), it is stated: “To the subject of a negative proposition a pronominal anaphoric reference 
can be made, if (the negation) is placed aft er the subject, as in ‘A man does not run, and he moves.’ Because if 
the negation is placed before, it negates the whole, and therefore a reference cannot be made to it (the sub-
ject), just as we have said of the predicate.” Th e quotes taken from that work seem to imply that a denoting 
phrase whose quantifi er sign is ‘no’ cannot be an antecedent, as in ‘No man runs, and he moves.’ I am not sure 
how to decide which are the good cases, and which not, nor to state a proper restriction that would permit 
the good cases and prevent the others.

248 
relatives (anaphoric words)
An advantage of this new formation rule is that we need no new semantic provisions 
at all. Th e semantic principles we already have apply to the new forms. However, 
there will have to be additional rules of inference to exploit the new forms. Two sorts 
of provisions come to mind. Th e fi rst is that our semantics validates versions of con-
temporary confi nement rules for affi  rmative denoting phrases, and we have to add 
rules for these:
Confi nement
Th e following equivalences hold whenever they are well formed:
(t α)[ϕ and ψ] is equivalent to [(tx) ϕ and ψ]
(some T α)[ϕ and ψ] is equivalent to [(some T α) ϕ and ψ]
(every T α)[ϕ and ψ] is equivalent to [(every T α) ϕ and ψ]
and also when the denoting phrase has a parasitic term, as in:
(t α)(· T-of-α β)[ϕ and ψ] ≈ (t α)[(· T-of-α β) ϕ and ψ]
In addition these principles hold when ‘and’ is replaced by ‘or’ or ‘if.’
In addition, these principles all hold when the “confi ned” denoting phrase 
bears an anaphoric index and there is no pronoun using that index in ‘ψ.’
(Th e well-formedness constraint prohibits using these equivalences when the denoting 
phrase bears an anaphoric index that appears free in ψ.)
Th e other sort of rule we need concerns the conditions under which our rule for 
exposition applies. In order to apply that rule, we need to show that the term being 
instantiated is non-empty. Previously that could be shown only by its occurrence as a 
main term in an affi  rmative proposition. But now there are additional positions that 
guarantee non-emptiness. An example is when the term has scope over a conjunction 
in which it (and whatever else is outside the conjunction along with it) along with the 
left  conjunct would make up an affi  rmative proposition if so assembled. An example is 
the term ‘donkey’ in:
(some donkey α)i[α runs and not (iti β)(· horse γ) β sees γ]
some donkey runs and it doesn’t see a horse
which occurs here as a main term, but not in an affi  rmative proposition. (Th e proposition 
is not defi ned as either affi  rmative or negative.) If there were no anaphora, we could 
apply a confi nement rule and then derive the affi  rmative proposition:
(some donkey α) α runs
in which ‘donkey’ appears as a main term. But the anaphora prevents this. So we need 
a provision such as

applying the singulation theory 
249
Affi  rmative contexts
If a term ‘α’ occurs as the main term of an affi  rmative proposition, ϕ, it is in an 
affi  rmative context in ϕ.
If a term ‘α’ occurs in an affi  rmative context in ϕ, it also occurs in an affi  rma-
tive context in ‘[ϕ and ψ]’ and in ‘ϕ* and ψ],’ where ‘ϕ*’ consists of ‘ϕ’ with a left  
bracket in it that matches the bracket to the right of ‘ψ.’
If a denoting phrase ‘(n α)i’ occurs in an affi  rmative context in ψ, then it also 
occurs affi  rmatively in ‘(n β)i[ϕ and ψ*],’ where ‘β’ occurs in ‘ϕ’ and where ‘ψ*’ is 
the result of replacing ‘(n α)i’ by ‘(iti α)’ in ‘ψ.’
I think that this last condition should be expanded. Th e point is to let an antecedent of 
a pronoun occur affi  rmatively under certain conditions if the pronoun does. Further, 
recall our proof in section 4.3 of the principle called substitutivity of empties; that 
proof relied on the assumption that every sentence is either affi  rmative or negative. 
Th at assumption no longer holds. As a result, that substitutivity principle may need to 
be posited. More work is needed here.
As a test of adequacy we can check some of the conclusions drawn earlier.
One had to do with the claim ‘a man runs and he argues,’ about which Burley says:
In order that ‘a man runs and he argues’ be true, ‘a man runs’ has to be made true for some 
suppositum of ‘man’ and the second part made true for the same suppositum. (Burley, PAL, 
longer treatise, para. 118 (112))
Th e truth conditions for:
(· man α)i[α runs and (iti β) β argues]
A man [runs and he argues]
are indeed that there is something for which ‘man’ supposits and that thing runs and 
that thing argues. Another conclusion was that the sentence ‘every man is running and 
he is Socrates,’ seems to be equivalent to saying that every man is running and every 
man is Socrates. In our Linguish notation, the logical forms are:
(Every man α)i[(· running β) α is β and (iti γ)(Socrates δ) γ is δ]
[(Every man α)(· running β) α is β and (Every man γ)(Socrates δ) γ is δ]
It is straightforward to prove that these are equivalent. Here are derivations which 
show this:

250 
relatives (anaphoric words)
(Every man α)i[(· running β) α is β  and  (iti γ)(Socrates δ) γ is δ]
[(Every man α)(· running β) α is β  and  (Every man γ)(Socrates δ) γ is δ]      
1.
2.
3.
4.
5.
6.
7.
8.
9.
10.
11.
12.
13.
14.
15.
16.
17.
18.
19.
20.
21.
22.
23.
not [(Every man α)(· running β) α is β  and  (Every man γ)(Socrates δ) γ is δ]
not (Every man α)(· running β) α is β  or   not (Every man γ)(Socrates δ) γ is δ]
(Every man α)(· running β) α is β
not (Every man γ)(Socrates δ) γ is δ
(some man γ) not (Socrates δ) γ is δ
(n γ)(· man β) γ is β
(n γ) not (Socrates δ) γ is δ
(n α)i[(· running β) α is β  and  (iti γ)(Socrates δ) γ is δ]
(n α)[(· running β) α is β  and  (n γ)(Socrates δ) γ is δ]
[(n α)(· running β) α is β  and  (n γ)(Socrates δ) γ is δ]
(n γ)(Socrates δ) γ is δ
not (n γ)(Socrates δ) γ is δ          
4 Equipoll
1 5 EX
1 5 EX
6 1 UA
8 Sing Ante
9 Conf
10 Simp
7 Permute
11 12 Reductio
13 3 Taut
14 Equipoll
1 15 EX
1 15 EX
1 16 UA
18 Sing Ante
19 Conf
20 Simp
17 Permute
21 22 Reductio  
 
2 Taut  
not (Every man α)(· running β) α is β
(some man α) not (· running β) α is β
(m α)(· man β) α is β
(m α) not (· running β) α is β
(m α)i[(· running β) α is β  and  (iti γ)(Socrates δ) γ is δ]
(m α)[(· running β) α is β  and  (m γ)(Socrates δ) γ is δ]
(m α)(· running β) α is β  and  (m γ)(Socrates δ) γ is δ]
(m α)(· running β) α is β
not (m α)(· running β) α is β              
[(Every man α)(· running β) α is β  and  (Every man γ)(Socrates δ) γ is δ]
(Every man α)(· running β) α is β
(Every man γ)(Socrates δ) γ is δ
(Every man α)i[(· running β) α is β  and  (iti γ)(Socrates δ) γ is δ]
1.
2.
3.
4.
5.
6.
7.
8.
9.
10.
11.
12.
13.
14.
not (Every man α)i[(· running β) α is β  and  (iti γ)(Socrates δ) γ is δ]
(some man α)i not [(· running β) α is β  and  (iti γ)(Socrates δ) γ is δ]
(m α)(· man β) α is β
(m α)i not [(· running β) α is β and (iti γ)(Socrates δ) γ is δ]
(m α) not [(· running β) α is β and (m γ)(Socrates δ) γ is δ]
not (m α)[(· running β) α is β and (m γ)(Socrates δ) γ is δ]
not [(m α)(· running β) α is β and (m γ)(Socrates δ) γ is δ]
(m α)(· running β) α is β
(m γ)(Socrates δ) γ is δ
[(m α)(· running β) α is β and (m γ)(Socrates δ) γ is δ]
1 Simp
1 Simp
4 Equipoll
2 5 EX
2 5 EX
7 SA
8 Permute
9 Conf
2 6 UA
3 6 UA
12 Adjoin
10 13 Reductio

applying the singulation theory 
251
Another example—one that illustrates the importance of what the antecedent of an 
anaphor is verifi ed for:
an ass is an animal and the same is a man
is equivalent to:
an ass is an animal and an animal which an ass is is a man
Th e (equivalent) Linguish logical forms will be:
(· ass α)(· animal β)i[α is β and (iti γ)(· man δ) γ is δ]
[(· ass α)(· animal β) α is β and (· {animal whichε (· ass η) η is ε} γ)(· man δ) γ is δ]
Th ese too can be proved equivalent by our rules. Another example is the equival-
ence of:
A man argues and his ass runs
and
A man argues and an ass of a man who argues runs
Th e logical forms would be:
(· man α)i [α argues and (iti β)(· ass-poss-β γ) γ runs]
[(· man α) α argues and (· {man whichε ε argues} β)(· ass-poss-β γ) γ runs]
Finally recall the problem example
Socrates is a donkey or he is a man. (antecedent of ‘he’ is ‘Socrates’)
It can be generated as follows:
(Socrates α)i[(· donkey β) α is β or (iti γ)(· man η) γ is η]
If we apply the rule for singular antecedents we get the equivalent form:
(Socrates α)[(· donkey β) α is β or (Socrates γ)(· man η) γ is η]
which by confi nement becomes:
[(Socrates α)(· donkey β) α is β or (Socrates γ)(· man η) γ is η]
Th is is clearly true, as desired.

252 
relatives (anaphoric words)
8.6 An application of relatives to syllogistic
Buridan thought that relatives of identity are important because they permit one to 
get around certain traditional prohibitions on what kind of syllogisms may be valid. 
For example, a traditional rule says that a syllogism cannot be valid if neither of its 
premises is universal. Buridan (SD 5.1.8) points out that this rule does not hold when 
relatives of identity are present:
But we should also realize that by the same principle an affi  rmative syllogism would be valid 
even with a common middle term in every fi gure, if in the minor proposition we were to add a 
relative [pronoun] of identity, and even if neither of the premises were universal, as for example: 
‘A man is running, and a white thing is that man; therefore, a white thing is running’; similarly, 
in the second fi gure: ‘A running thing is a man, and a white thing is that man; therefore, a white 
thing is running’; similarly, in the third fi gure: ‘A man is white, and that man is running; there-
fore, a running thing is white.’ It is clear that all these syllogisms are valid; and they should be 
called ‘expository,’ as though their middle term were singular, for the relative [pronoun] of iden-
tity ensures that, if the premises are true, the minor is true for the same suppositum of the middle 
term for which the major was true, and thus the extremities are said to be the same as the middle 
term in respect of numerically the same thing; whence it has to be concluded that they are them-
selves the same.
Here is a proof of Buridan’s second example, where I understand the premise to be 
a “conjunction” with anaphora:
applications
Produce the Linguish logical forms that generate these sentences and provide 
formal derivations for the following arguments.
 
Socrates owns Brownie
 
Socrates feeds Brownie
 
Socrates is a man
 
Brownie is a donkey
∴ 
A man owns a donkey and he feeds it
 
Every man who is not running is sitting
∴ 
Every man is running or he is sitting
 
Every man who is not running is sitting
∴ 
Every man is running if he is not sitting
 
Every man is Socrates or he is Plato
 
Socrates is running and Plato is running
∴ 
Every man is running

an application of relatives to syllogistic 
253
A running thing is a man, and a white thing is that man; therefore, a white thing is 
running
(· running-thing α)(· man β)i[α is β and (· white-thing δ)(iti ε) δ is ε]
∴ (· white-thing α)(· running-thing β) α is β
(· running-thing α)(· man β)i[α is β and (· white-thing δ)(iti ε) δ is ε]
(r α)(· running-thing β) α is β
(r α)(· man β)i[α is β and (· white-thing δ)(iti ε) δ is ε]
(· man β)i(r α)[α is β and (· white-thing δ)(iti ε) δ is ε]
(m α)(· man β) α is β
(m β)i(r α)[α is β and (· white-thing δ)(iti ε) δ is ε]
(m β)(r α)[α is β and (· white-thing δ)(m ε) δ is ε]
(m β)(r α) α is β and (· white-thing δ)(m ε) δ is ε
(m β)(r α) α is β
(· white-thing δ)(m ε) δ is ε
(r α)(m β) α is β
(m α)(· running-thing β) α is β
(m ε)(· white-thing δ) δ is ε
(· white-thing α)(· running-thing β) α is β             
1.
2.
3.
4.
5.
6.
7.
8.
9.
10.
11.
12.
13.
14.
1 1 EX
1 1 EX
3 Permute
4 4 EX
4 4 EX
6 Singular antecedent
Confinement (twice)
8 simp
8 simp
9 Permute
2 11 LL
10 Permute
12 13 ES        
Th is indeed yields a syllogism with a singular middle term, as Buridan says. Th en a 
little bit of rearranging together with an expository syllogism yields:
A white thing is running
Another example from Buridan is this one:
For example, we truly say: ‘Th e fi rst cause exists and it is God,’ or even ‘Th e almighty is not evil 
and he is God.’ But this is not so with ‘chimera,’ for even if we said ‘A chimera is not, and she is 
a chimera,’ the proposition ‘She is a chimera’ is false. (SD 4.1.2)
Of course, ‘she is a chimera’ is not a free-standing part of ‘A chimera is not, and she is 
a chimera’ with a truth value of its own. Buridan’s point is that the truth of ‘A chimera 
is not’ does not license one to add ‘and she is a chimera.’ If we do, ‘A chimera is not, and 
she is a chimera’ must be false. We can show this.
To disprove: A chimera is not and she is a chimera
i.e. to disprove: (· C α)i[not α is and (iti δ)(· C ε) δ is ε]
<assuming that Buridan’s ‘x is’ means the same as ‘x is x’>.

254 
relatives (anaphoric words)
1.
2.
3.
4.
5.
6.
7.
8.
9.
10.
not (· C α)i[not α is and (iti δ)(· C ε) δ is ε]
(· C α)i[not α is and (iti δ)(· C ε) δ is ε]
(c α)i[not α is and (iti δ)(· C ε) δ is ε]
(c α)[not α is and (c δ)(· C ε) δ is ε]
[(c α) not α is and (c δ)(· C ε) δ is ε]
(c α) not α is
(c δ)(· C ε) δ is ε
(c α)(c β) α is β
not (c α) α is
not (c α)(c β) α is β 
1 EX <‘C’ occurs aﬃrmatively>
2 Singular antecedent
3 Conﬁnement
4 Simp
4 Simp
6 is aﬃrmative
5 Permutation
8 <assured equivalence>
7 9 reductio        
applications
Produce the Linguish logical forms that generate these sentences and provide 
formal derivations for the following arguments.
 
A man owns a donkey and it is running
 
Every donkey is an animal
∴ 
An animal is running
 
Every man owns a donkey and it is not running
∴ 
Not every donkey is running
 
Every man sees a donkey
 
Every donkey sees a horse
 
Every donkey is an animal
∴ 
Every man sees an animal and it sees a horse
8.7 Donkey anaphora
Th e theory that we have been discussing deals with relatives of identity that occur within 
the scopes of their antecedents. But there are grammatically well-formed sentences in 
which a relative does not lie within the scope of its antecedent. (Th ese were the kinds of 
cases that Evans’ discussion was aimed at.) Here is a case that was considered by Walter 
Burley in the early 14th century (PAL, longer treatise, para. 130–2):
Every man having an ass sees it
In the 20th century this example was changed by Peter Geach (1962, 117) into:
Any man who owns a donkey beats it

donkey anaphora 
255
He discussed this example in Geach 1962, and in this donkey-beating form it entered 
the fi eld of modern linguistics as a problematic kind of construction. For years the 
problem was referred to as the problem of “donkey sentences.” It is now called “unbound 
anaphora,” because it deals with pronouns which apparently cannot be bound by their 
antecedents (because they do not fall within the scopes of their antecedents). I think it 
is fair to say that there is no consensus on how to handle the semantics of such pronouns. 
So it will be no surprise if medieval accounts fall short. I will confi ne myself to discuss-
ing the views of Walter Burley on this matter.
Upon inspection it is clear that the methods given so far do not generate this 
sentence with a reading in which ‘it’ has ‘ass’ as its antecedent. Th is is because ‘man 
having an ass’ is a complex common term which occurs totally within the subject of 
the sentence. So ‘it’ cannot be within the scope of ‘ass.’ What is to be done?
Th ere is a problem in understanding this sentence. What does the sentence have to 
say about men who own more than one donkey? Most people (not all; and not Burley) 
take it that for the sentence to be true, any man having many donkeys must see every 
one of them. Th ere is no argument for this (or against it); it is just a matter of how 
the sentence is understood in natural language. However, this view is undercut when 
we consider other sentences with the same form, where the intuitions go diff erently. 
A standard example is:
Everyone who had a credit card used it.
Hardly anyone thinks that this sentence requires for its truth that everyone who had 
more than one credit card used them all. Th e sentence only requires that everyone with 
at least one credit card used at least one of his/her credit cards.
Burley understood his sentence in the credit-card sense, to require only that men 
with multiple donkeys must see at least one of them. He took this to be problematic 
because he observed (PAL, longer treatise, para. 128–32) that on that understanding 
the following two sentences apparently do not contradict one another:
Every man having an ass sees it
Some man having an ass does not see it
If he is right, this means that the fundamental equipollences discussed in Chapter 3 
do not hold for such sentences. So the signifi cance for formulating a general theory of 
logic is substantial.
Th e problem in detail: Burley thinks that the sentences can both be true if some man 
owns more than one ass and sees one without seeing another. And that is the case if the 
second sentence requires only that some man not see one of his donkeys. But consider 
a credit-card variant:
Someone who had a credit card didn’t use it
Th is might naturally be understood as meaning that someone who had one or more 
credit cards didn’t use any credit card. Burley’s example might be understood in this 

256 
relatives (anaphoric words)
way too. It appears to me, then, that there are two ways to understand each of these 
sentences, and so Burley’s problematic pair of sentences can be read four ways altogether. 
Two ways make them contradictory and two don’t, so Burley’s problem about contra-
dictoriness is not forced on us.
I do not want to try to decide who is right here. Instead I will discuss one possible 
way to handle these sentences that validates Burley’s point of view regarding the fi rst 
sentence. Th is may be one of those examples in which the theory of relatives gives the 
right answer exactly as it was articulated by medieval authors. On this view, the ‘it’ in
Every man who has an ass sees it
is supposed to have the same mode of supposition as its antecedent, and it supposits for 
those things that its antecedent supposits for, for which the previous clause is verifi ed. 
Th is means that it supposits for asses seen by the man in question. Now the previous 
clause is a relative clause, which has independent meaning only if the relation of the 
relative pronoun to the man is handled in some way. If the ‘who’ indicates anaphora to 
the man, then it appears that the sentence will have the truth conditions of:
Every man who has an ass sees an ass that he has
If the ‘he’ is anaphorically linked to the term ‘man who has an ass’ then this gives exactly 
the truth conditions that Burley thinks it has. (When this account is applied to the 
example ‘Some man having an ass does not see it’ there are diff erent ways to take the 
scope of the negation, and so the sentence is structurally ambiguous.)
My analysis of this example is somewhat ad hoc (for example, in the choice of the 
anaphora for ‘he’) and it is not at all easy to spell this out in a systematic way. Nor do 
I know how to generalize this case.
Many questions are now left  open. Th ere is no really satisfactory theory of all 
relatives, either in the medieval period or today, and I can’t improve on that. Perhaps 
a question to keep in mind is whether there is any theoretically unavoidable need for 
purposes of logic for pronouns of natural language which do not occur within the 
scopes of their antecedents. Th e next chapter will suggest that there is not.
8.8 Common term relatives of identity and diversity
Two very useful common relative terms are ‘same’ and ‘other.’ When used as relatives,17 
they have antecedents. Th e fi rst supposits for whatever its antecedent supposits for, and 
the second for whatever its antecedent does not supposit for—though these are rough 
statements, because of the unclarity as to what an antecedent supposits for. A general 
account that seems to work well is:
17 Words like ‘same’ and ‘other’ can occur not as relatives, as in ‘Socrates is other than Plato.’ Th ese uses are 
not under discussion here. (In the case of a related word, ‘diff er,’ there is a well-established treatment of it as 
an exponible term. In particular, a proposition of the form ‘A diff ers from B’ is to be expounded in terms of 
a conjunction of three propositions: ‘A is, and B is, and A is not B,’ with it being controversial whether the 
second conjunct should be present. Cf. Marsilius of Inghen, TPT, Suppositions (85).)

common term relatives of identity and diversity 
257
‘samei’ suppositsσ for σ(§k), where ‘(§k ι)i’ is the antecedent
‘otheri’ suppositsσ for everything that is not σ(§k), where ‘(§k ι)i’ is the antecedent
An example of the use of ‘other’ is:
No number’s successor is some other number’s successor
Of-no numberi a successor some successor of-some otheri number is
(no number α)i(·successor-of-α δ)(some {successor-of-β (some {otheri number} β)} 
γ) δ is γ
Such words appear as independent terms, or modifying other common terms. When 
used independently they can be taken to be equivalent to headless relative clauses:
‘samek’ is equivalent to ‘{whichγ (itk δ) γ is δ}’
‘otherk’ is equivalent to ‘{whichγ (itk δ) not γ is δ}’
When used to modify common terms, they also seem to be equivalent to constructions 
with relative clauses:
‘samek T’ is equivalent to ‘{T whichγ (itk δ) γ is δ}’
‘otherk T’ is equivalent to ‘{T whichγ (itk δ) not γ is δ}’
With these equivalences, no additional rules of inference are necessary. An illustration 
of their use may be based on another example of Buridan’s. In his TC there is a passage 
parallel to the one cited earlier, concerning how syllogisms with relative terms are 
exempt from certain general principles governing syllogisms.
Sixth Conclusion: no syllogism is valid in which the middle is distributed in neither premise, 
unless the middle is used in the minor with a relative of identity.
 For the rules by which syllogisms hold require that if the middle is a general [term] the 
extremes are linked by reason of the same thing for which this general term supposits, as 
explained earlier. Since the middle is not distributed in either [premise] it is possible that its 
conjunction with the major extreme is true for one thing and its conjunction with the minor is 
true for another; and from this no conjunction of the extremes with one another can be inferred 
unless the middle is brought together by a relative of identity to hold for the same thing in the 
minor premise as that for which it was verifi ed in the major. But then the syllogism is valid, and 
clearly holds by the rules given above, and it is eff ectively an expository syllogism; for example, 
‘Some B is an A and a C is the same B, so some C is A.’ So such syllogisms hold in all moods in 
which expository syllogisms hold. (TC 89–90)
Th e relevant syllogism is:
Some B is an A and a C is the same B, so some C is an A
In Linguish notation:
(some B α)i[(· A β) α is β and (· C δ)(· samei B ε) δ is ε]
∴ (some C α)(· A β) α is β

258 
relatives (anaphoric words)
1.
2.
3.
4.
5.
6.
7.
8.
9.
10.
11.
12.
13.
14.
15.
16.
17.
(some B α)i[(· A β) α is β and (· C δ)(· samei B ε) δ is ε]
(b α)(· B β) α is β
(b α)i[(· A β) α is β and (· C δ)(· samei B ε) δ is ε]
(b α)i[(· A β) α is β and (· C δ)(· {B whichγ (iti η) γ is η} ε) δ is ε]
(b α)[(· A β) α is β and (· C δ)(· {B whichγ (b η) γ is η} ε) δ is ε]
[(b α)(· A β) α is β and (· C δ)(· {B whichγ (b η) γ is η} ε) δ is ε]
(b α)(· A β) α is β
(· A β)(b α) α is β
(a α)(· A β) α is β
(a β)(b α) α is β
(· C δ)(· {B whichγ (b η) γ is η} ε) δ is ε
(c α)(· C δ) δ is α
(c δ)(· {B whichγ (b η) γ is η} ε) δ is ε
(c δ)(· B ε) δ is ε
(c γ)(b η) γ is η
(c α)(· A β) α is β
(some · C α)(· A β) α is β 
1 EX
1 EX
3 rule ‘Same’
4 Sing Ante
5 Conf
6 Simp
7 permute
8 EX
8 EX
6 Simp
11 EX
11 EX
13 RelClause
13 RelClause
7 15 LL
12 16 ES           
Th e proof is, as Buridan says, “eff ectively an expository syllogism,” in the sense that that 
is the form of the major (last) inference in it.
Additional illustrations would be helpful. Some are given in section 9.5 on fi rst-
order arithmetic.
applications
Produce the Linguish logical forms that generate these sentences and provide 
formal derivations for the following arguments.
 
A man and another man are running
∴ 
No man is every man
 
A donkey is sitting
 
A donkey is running
 
No donkey which is sitting is running
∴ 
A donkey is sitting and another donkey is running
 
No number’s successor is another number’s successor
 
Zero is a number and one is another number
∴ 
Zero’s successor is not one’s successor

the expressive power of medieval logic 
259
9
Comparison of Medieval Logic 
with Contemporary Logic
Th e goal of this chapter is to explore the logical potential of medieval logic. Since 
medieval logic is couched in a regimented form of natural language, it is also a good 
test case for exploring the logical potential of natural language. A crucial step in Frege’s 
1879 eff ort to provide a logical foundation for arithmetic was to set aside natural 
language and to use an invented language instead, a conceptual notation. Clearly his 
notation is more useful than natural language for this task. But it is not clear—to me, 
anyway—whether it is essential, or only useful, to dispense with natural language in 
this way. Th e purpose of this chapter is to evaluate the expressive power of the natural 
language based systems of logic that were developed in medieval times.
In section 9.1, I discuss the expressive power of medieval logic as developed in 
previous chapters. Without anaphoric pronouns, the system is logically weak (it is 
probably decidable); with anaphoric pronouns it seems to have a power similar to that 
of modern logic. Section 9.2 discusses how to represent medieval logic within modern 
logic; this is easy, though somewhat clumsy. Th e next two sections discuss how to 
represent modern logic within medieval logic. In 9.3 problems of existential import 
are discussed and dealt with, and in 9.4 problems due to the restrictive grammar of 
medieval logic are discussed, and an algorithm is given for representing modern logic 
within medieval logic. Th e method is artifi cial, but it works. Finally, in section 9.5 we 
consider what it would be like to use medieval logic in a natural way to formulate a 
straightforward modern theory—fi rst-order arithmetic.
9.1 Th e expressive power of medieval logic
Th e simplest system of logic that we looked at (Chapter 1) was Aristotle’s, confi ned to 
the four standard forms of categorical propositions. Th is is pretty much the system that 
is taught today in sections of texts on “Aristotelian” logic (though oft en with altered 
truth conditions for the propositions, to make them conform to texts on symbolic 
logic). Th is is equivalent to a very simple fragment of monadic predicate logic. It is 
decidable by simple methods such as the use of Venn diagrams or the use of rules (such 
as “nothing may be distributed in the conclusion unless it is distributed in a premise”). 
Aristotle himself proved all of the principles of this logic using reductio, exposition, 

260 
comparison of medieval logic with contemporary logic
expository syllogism, and two fi rst fi gure syllogisms (and these are superfl uous; 
see Chapter 2 for details). Including singular propositions in syllogistic (that is, pro-
positions whose subject terms are singular terms) changes very little, though it com-
plicates the use of Venn diagrams.1
Th e early medieval expansion of Aristotle’s logic (Chapter 3) is equivalent to a frag-
ment of the monadic predicate calculus with identity. Quantifi er signs occur inelimin-
ably within the scopes of other quantifi er signs. Th e system of logic is still decidable, 
but it is harder to test for validity; e.g. Venn diagrams are inadequate. Medieval authors 
also invoked principles of supposition theory, but these do not go beyond what can be 
proved by Aristotle’s basic means of reductio, exposition, and expository syllogism, 
now supplemented with substitutivity of identity and a number of other rules such as 
quantifi er equipollences. (See Chapters 4 and 5 for details.)
Th e expanded form of Linguish is a stronger system. Here I will discuss the version 
of Linguish from Chapter 4 (basic Linguish) supplemented with the expansions given 
in sections
5.1 Adjectives
5.2 Intransitive verbs
5.3 Transitive verbs
5.6 Relative clauses
5.7 Genitives
5.9 Molecular propositions
Recall that participles of transitive verbs and genitives introduce parasitic (“rela-
tional”) terms. I omit
5.5 Some Complex Terms
5.8 Demonstratives
just for simplicity. (I also assume that there are no past or future tenses, or modal 
expressions, or any other sources of ampliation. Th ese are discussed in Chapter 10.)
9.1.1 Medieval logic without anaphoric pronouns
Notice that the system of logic demarcated here does not yet include the anaphoric 
pronouns from Chapter 8. Some examples of sentences that can be expressed with its 
resources are:
Every horse sees some donkey
Some farmer’s every donkey is running
Some farmer’s every grey donkey sees a horse which no woman who owns a donkey 
sees.
1 For example, one needs to decide how to diagram a sentence such as ‘n isn’t F,’ keeping in mind that ‘n’ 
might be empty.

the expressive power of medieval logic 
261
Although one can express some rather complex claims, I believe that this system of 
medieval logic, like its simpler predecessors, is decidable. Th at is, for any fi nite set 
of sentences in the symbolism, there is a mechanical way to decide whether or not 
there is an interpretation which makes them all true. Th is is a bit surprising, because 
the notation includes quantifi ers and relational verbs. Th e reason for the decidability 
is the constraint on the use of markers, which in this notation represent grammatical 
roles. If we were to express in modern logic the claim that exceeding is transitive, the 
notation would look something like this:
∀x∀y∀z[xEy & yEz → xEz]
Th e variables inside the parentheses look something like our grammatical role markers. 
But they can’t serve that purpose, since they each occur in multiple places, which gram-
matical markers cannot do. But anaphoric pronouns can accomplish this purpose.
9.1.2 Medieval logic with anaphoric expressions
Because the system of logic without anaphoric expressions is limited, we should see if 
adding pronouns and other anaphoric expressions helps. Some examples of sentences 
that can be expressed with the addition of anaphoric pronouns (Chapter 8) are:
Some donkey sees itself
Some donkey sees some other donkey
Every horse sees some donkey which it likes
Th ings are quite diff erent when we consider this system of logic with anaphoric expres-
sions added to it. With this notation it is easy to produce a small set of sentences that 
has an infi nite model, but no fi nite model. An example is this set, whose third member 
expresses that the relation of exceeding is transitive:
No number exceeds itself.
Every number is exceeded by some number.
Every number exceeds every number which is exceeded by some number which it (i.e. 
the fi rst number) exceeds.
Th e fi rst and third sentences contain anaphoric pronouns, which are underlined. In 
Linguish notation:
(no number α)i(iti β) α exceeds β
(every number α)(some number β) β exceeds α
(every number α)i(every {number whichβ (some {number whichγ (iti δ) δ exceeds γ} ε) 
ε exceeds β} η) α exceeds η
Notice that this set of sentences does not contain any parasitic terms, though it uses a 
verb other than the copula.
Th is system of logic is not decidable. Th is will follow from the fact, discussed in 
section 9.4, that the fi rst-order predicate calculus is representable in it.

262 
comparison of medieval logic with contemporary logic
9.2  Representing medieval logic within modern 
predicate logic with identity
It is no surprise that medieval logic can be emulated within modern logic; the only 
question is how complicated the procedure is to produce a formula in predicate logic 
that is equivalent to a given one in medieval logic. Th e procedure is a bit clumsy. 
For example, medieval logic and contemporary logic diff er with respect to how they 
represent generalities. Consider the symbolizations of ‘Every A is ϕ.’ Th e natural repre-
sentations are:
(Every A α) ϕ  vs  ∀x(Ax → ϕ*)
(where ‘ϕ’ and ‘ϕ*’ are the respective symbolizations of ‘ϕ’). Th ese forms, in isolation, 
are incommensurable. Th is is because when ‘A’ is empty, the Linguish version is auto-
matically false if ϕ is affi  rmative, but automatically true if ϕ is negative, whereas the 
symbolic logic sentence is automatically true when there are no A’s no matter what the 
character of ϕ* is. Th ere is, however, a natural way to go about representing sentences 
one at a time: one can mirror the medieval denoting phrases diff erently depending on 
whether the context is affi  rmative or negative. In particular, these are equivalent:
(Every A α) ϕ  ≈  ∃xAx & ∀x(Ax → ϕ*) if ϕ is affi  rmative
 
∀x(Ax → ϕ*) 
if ϕ is negative
However, there are cases in which the formula ϕ is neither affi  rmative nor negative. 
Consider:
(Every A α)i[α is running or [(iti γ)(Socrates β) γ sees β or (Brownie δ) δ runs]]
Here ‘(Every A α)’ is in neither an affi  rmative nor a negative position, and confi nement 
does not apply. Probably there is an algorithm that will yield an equivalent formula in 
all cases, but I have not produced one.
9.3  Representing modern logic within medieval logic: 
Th e problem of existential import
Suppose that we wish to represent modern predicate logic within medieval logic. 
Th e fi rst step seems clear: whereas medieval logic has an unlimited number of denot-
ing phrases, modern logic has only two: ‘everything’ and ‘something’—‘∀α’ and ‘∃α.’ 
According to medieval logicians, ‘everything’ means ‘every thing.’ So we can apparently 
mimic modern quantifi ers by using ‘(every thing α)’ and ‘(some thing α)’ for the quan-
tifi ers, provided that we add as a logical axiom that there is at least one thing: ‘(some 
thing α)(some thing β) α is β.’2 Th is is the analogue of the assumption made in classical 
logic that the domain of quantifi cation is non-empty. Names are also easy to handle: 
2 Medieval logicians would be happy to accept this, since God is a thing, and God necessarily exists.

the problem of existential import 
263
for the name ‘s’ just insert ‘(s α)’ with smallest scope over the atomic formula of modern 
logic within which ‘s’ occurs, and replace ‘s’ itself by ‘α.’ So for the sentence ‘Socrates sees 
everything,’ symbolized:
∀y sSy
we would have:
∀y (s α) α sees y
and then:
(every thing β)(s α) α sees β
For classical logic we must also add as a logical axiom that the name is not empty, 
and that it falls under the medieval quantifi ers: ‘(s α)(some thing β) α is β.’ Th e result is a 
fragment of medieval logic with no empty simple terms.
However, one cannot just take any old sentence of modern logic, change its quanti-
fi ers in this way, and end up with an equivalent sentence of medieval logic. Th is is 
because in medieval logic the markers are used only to mark grammatical roles, and 
there is no guarantee that such a transformation will produce a string of symbols that 
corresponds to a grammatical sentence. Take, for example, a modern symbolization of 
the transitivity of the relation of exceeding. If ‘xEy’ means that x exceeds y, then one 
naturally says that this relation is transitive by writing:
∀x∀y∀z[xEy & yEz → xEz]
Using the device outlined a moment ago, one gets a proposed “sentence” of medieval logic 
by changing the quantifi ers as indicated already and writing ‘E’ as ‘exceeds’; this produces:
(every thing α)(every thing β)(every thing γ)[if α exceeds β and β exceeds γ then α 
exceeds γ]
But this is not well formed in medieval logic since it makes each denoting phrase be the 
subject or direct object of two diff erent sentences (because the marker accompanying 
the common term occurs in two grammatical role-indicating positions).
Instead, if one wants to represent the transitivity of exceeding in medieval logic one 
needs to use a diff erent form, such as the one used in section 9.1.2 (changing ‘number’ 
to ‘thing’):
(every thing α)i(every {thing whichβ (some {thing whichγ (iti δ) δ exceeds γ} ε) ε 
exceeds β} η) α exceeds η
However, although this formula does require that exceeding be transitive, it also 
requires something more. Th is is because the sentence is affi  rmative, and so it has exis-
tential import for its terms. Consider now adding the truth that zero is something:
(zero α)(· thing β) α is β

264 
comparison of medieval logic with contemporary logic
If we then apply UA we infer the following:
(zero α)(every {thing whichβ (some {thing whichγ (zero δ) δ exceeds γ} ε) ε exceeds β} η) 
α exceeds η
Th e second main term of this is ‘thing which exceeds some thing which zero exceeds’ and 
since it is in a main term of an affi  rmative proposition it must be non-empty, which 
means that ‘thing which zero exceeds’ must also be non-empty. So from the statement 
that exceeding is transitive we infer that there is something which zero exceeds, which 
is not true. So this idea for symbolizing transitivity does not work in this case.3
Th ere seem to me to be two ways to proceed here. One is to show how to alter the 
truth conditions of the medieval logic forms when that seems desirable, and the other 
is to fi nd some way to mimic predicate calculus notation within medieval logic that 
bypasses the issue of existential import. Th e present section deals with the fi rst of these 
ideas: fi nding a way to eliminate the existential import of universal affi  rmative denot-
ing phrases that occur in affi  rmative propositions.
Th ere is a way to convert sentences of affi  rmative form into a negative form which 
is completely equivalent except that it is true when the main terms are empty. Recall 
the idea that the only true verb is the copula, and that other verbs are to be analyzed 
in terms of a copula plus a participle. We can replace ‘α exceeds β’ by ‘(· exceeding-β-
thing γ) α is γ’ (“α is an exceeding-β-thing”) as we did in section 5.3. It is then possible to 
write propositions in which this introduced parasitic term combines with infi nitizing 
negation. E.g. we can say that every number non-exceeds a number: ‘(every number α)
(· number β)(· non-exceeding-β-thing γ) α is γ.’ And we can also say that for every number 
there’s a number that it “exceeds” by saying there’s a number that it doesn’t non-exceed: 
‘(every number α)(· number β) not (· non-exceeding-β-thing γ) α is γ.’ Suppose now that 
we take our original sentence attempting to defi ne transitivity and change it to:
(every thing α)i(every {thing whichβ (some {thing whichγ (iti δ) δ exceeds γ} ε) ε 
exceeds β} η) not (· non-exceeding-η-thing δ) α is δ
Th is is just like the original sentence except that it has ‘isn’t a thing non-exceeding’ 
instead of ‘exceeds,’ and it is now a negative sentence, not an affi  rmative one. So it is true 
for instances of ‘every thing’ that make the second denoting phrase empty. Th is then 
avoids the problem of existential import. So the problem can be got around in this case, 
though it is quite clumsy and I am not sure how systematic it can be made.
3 Th is also raises a problem for a suggestion that was made in section 1.4.1. Th ere I suggested that diff er-
ent systems of logic might naturally diff er on the interpretation of universal affi  rmative sentences so long as 
each system can fi nd some way to duplicate the truth conditions yielded by the other theory. And in simple 
cases this is easy. For example, if you want ‘Every A is B’ to be true when ‘A’ is empty, and you are confi ned to 
using the medieval forms with their truth conditions, just write:
Every A is B or no A is an A
which is true if ‘A’ is empty. But the example of transitivity shows that this simple idea may not automatically 
extend to more complex cases.

grammatical issues 
265
9.4  Representing modern logic within medieval logic: 
Grammatical issues
Th ere is an additional limitation on our ability to represent modern logic in medieval 
logic. In medieval logic the marker within a denoting phrase links to the unique gram-
matical position in the sentence which that denoting phrase fi lls. Since each denoting 
phrase has a unique grammatical role, a medieval denoting phrase must bind exactly 
one occurrence of a marker. Now consider how to represent a sentence such as ‘every-
thing that sees Socrates is running’ in modern logic:
∀x(xSs → Rx).
It is essential to this representation that the initial universal quantifi er bind two 
occurrences of the variable ‘x,’ one in the antecedent and one in the consequent of 
the conditional. No denoting phrase in medieval logic can do this, because binding 
markers in two diff erent propositions would make that denoting phrase fi ll grammat-
ical roles in diff erent propositions, and natural language just doesn’t work like that. 
Of course, if your goal is to symbolize the English sentence ‘everything that sees Socrates 
is running’ you can do that:
(every {thing whichγ (Socrates β) γ sees β} α) α is running
Th is achieves the same purpose as the modern symbolization of that particular English 
sentence. But it is not obvious how to generalize this case to cover sentences of modern 
logic that do not obviously come from sentences of natural language, sentences such as:
∀x(∃yyRx ∨ ~Qx)
Th ere is a natural way to try to accomplish this goal. Th is is to give each denoting phrase 
the grammatical role of some one selected marker that it binds, and use anaphoric 
pronouns for the rest. For example, we might decide to assign to each denoting phrase 
the fi rst occurrence of its marker as its grammatical role identifi er, and use pronouns 
for the rest. Th e symbolic form:
∀x xRx
could be represented as:
(every thing α)i(iti β) αRβ
(Recall section 8.5 on anaphora.) Th e more complicated sentence would be repre-
sented as:
(every thing α)i[(some thing β) αRβ or not (iti γ)Qγ]
Th is approach seems artifi cial in that the grammatical role of the initial quantifi er 
seems capricious. But some instances of it are natural. For example, the analogue of:
∀x[donkey x → grey x]

266 
comparison of medieval logic with contemporary logic
could be the logical form:
(every thing α)i[α is grey if (· donkey β)(iti γ) γ is β]
Th is then goes over into natural language as:
every thing is grey if it is a donkey
But other examples don’t work this well. Consider:
∀x[donkey x → ~(grey x & young x)]
(every thing α)i[if α is a donkey not [(iti γ) γ is grey and (iti δ) δ is young]]
Th is would yield
everything if is a donkey not it is grey and it is young4
A slightly diff erent idea works better. Th is is to give the quantifi cational term no gram-
matical role in the sentence it combines with. Instead, it occurs in a prepositional 
phrase modifying the whole sentence. Th e preposition itself contributes no content; it 
just allows the term to combine with a sentence that the term is not a part of. To accom-
plish this, we read the ‘∀α’ of symbolic logic as ‘for every thing.’ Th en we read
∀x[donkey x → grey x]
as
for-(every thing)i[if (iti α)(· donkey β) α is β then (iti γ) γ is grey]
Applying our rules for turning logical forms into sentences of natural language, we get:
for every thing if it is a donkey then it is grey
Th is appears to be grammatical, and it seems to say just what is needed. We just need to 
add something like ‘for-(every T)’ to our language with the semantic rule:
‘for-(every T)i ϕ’ is trueσ if and only if either ‘T’ is non-empty and for every thing o 
for which ‘T’ supposits ‘ϕ’ is trueσ[i/o] or ‘T’ is empty and ‘ϕ’ is trueσ[i/-]
Notice that there is no marker in ‘for-(every T).’ Th is is because ‘every T’ does not have 
a grammatical role within the sentence following it; rather, it is the object of a preposi-
tional phrase that modifi es the whole sentence. Th e term (strictly, its denoting phrase) 
does have a grammatical role; it is the object of the preposition ‘for.’ So it has a grammat-
ical role in the whole sentence, as every denoting phrase must.5 Th is device apparently 
4 Writing the consequent fi rst is also problematic:
(every thing α)i[not α is grey and (iti δ) δ is young] if (iti η) η is a donkey]
It produces ‘everything isn’t grey and it is young if it is a donkey’ which has the wrong meaning.
5 We could let the preposition supply a grammatical role in its prepositional object position, by writing 
‘for α’ and then writing the denoting phrase before it, as ‘(every donkey α)i for α (some horse β)(iti γ) β sees 
γ.’ We would then need to specify that when pronounced, the denoting phrase is to follow its preposition, to 
yield e.g. ‘for every donkey, some horse sees it.’

grammatical issues 
267
works well, though it looks ad hoc. Th ere may well be problems with it that I do not 
currently understand.
Is this an idea that is part of medieval logic? I am not aware of any medieval discus-
sion of this construction; it appears instead to be a 21st-century construction. So it is 
not ideal.
Fortunately, there is a similar way to emulate modern logic within medieval logic 
using grammatical structures already existing in medieval logic. Th is is to use the fact 
that a term in one categorical can be the antecedent of another term occurring in 
a categorical conjoined to it. We saw in Chapter 8 how to do this. As previously, we 
use ‘thing’ as the common term in all denoting phrases that represent quantifi ers of 
modern logic. Th en instead of representing quantifi ed sentences by
for every thing ϕ
we represent them by
every thing is a thing and ϕ
In this form, ‘every thing’ has a grammatical role; it is the subject of the verb ‘is,’ and it 
can be the antecedent for any number of terms in ‘ϕ.’ For example, as in:
(every thing α)i[(· thing β) α is β and (iti δ)(iti ε) δ sees ε]
every thing is a thing and it sees itself
Here then is a recipe for converting any formula of modern logic (without names, for 
simplicity) into one in the medieval logic notation which is logically equivalent to it. 
Given any formula of predicate logic, make the following changes (one at a time, start-
ing with the most embedded formulas):
 • Eliminate all biconditional signs using combinations of the other connectives.
 • Delete all vacuous quantifi ers.
 • One at a time replace each atomic formula of the form ‘xRy’ with one of the form 
‘(itx δ) (ity ε) δRε’ where ‘δ’ and ‘ε’ are so far distinct unused grammatical markers. If 
the same variable occurs more than once fl anking ‘R,’ use it as a superscript on 
each pronoun, but introduce a new marker for each pronominal denoting phrase 
itself. E.g. ‘xRx’ becomes ‘(itx δ) (itx ε) δRε.’
 • Replace ‘¬ϕ’ by not ϕ.
 • Replace [ϕ&ψ] by [ϕ and ψ].
 • Replace [ϕ∨ψ] by [ϕ or ψ].
 • Replace [ϕ→ψ] by [ψ if ϕ].
 • Replace ‘∀xϕ’ by ‘(every thing δ)x[(· thing ε) δ is ε and ϕ],’ where ‘ε’ and ‘δ’ are new 
markers.
 • Replace ‘∃xϕ’ by ‘(some thing δ)x[(· thing ε) δ is ε and ϕ],’ where ‘ε’ and ‘δ’ are new 
markers.
(One may wish then to change the variables ‘x,’ ‘y,’ etc. to ‘i,’ ‘j,’ etc.)

268 
comparison of medieval logic with contemporary logic
For an illustration, consider the formula:
∃x[Px & ~Qx]
Th e atomic formulas yield:
∃x[(itx δ) Pδ & ~(itx ε)Qε]
the connectives are standard:
∃x[(itx δ) Pδ and not (itx ε)Qε]
and the quantifi er is then analyzed, yielding:
(some thing α)x[(· thing η) α is η and [(itx δ)Pδ and not (itx ε)Qε]]
Its pronunciation in natural language will be:
(some thing α)x[(· thing η) α is η and [(itx δ)Pδ and not (itx ε)Qε]]
some thing a thing is and it P and not it Q
something is a thing and it P and not it Q
If we suppose that ‘P’ means, say, ‘is grey’ and ‘Q’ means ‘is running’ we would get:
something is a thing and it is grey and not it is running
(For normal logician’s usage the ‘not’ should be read ‘it is not the case that.’)6
Th e results are well-formed propositions of medieval logic. Th ey are artifi cial and 
not ideal to read, but they are precise and logically fully expressive. And the required 
resources are from the core of medieval logic—what is used is notation that was dis-
cussed by medieval authors and the inference rules were almost all discussed by medi-
eval authors. In particular, what is required by this technique is:
 • Notation and rules from basic Linguish as introduced in Chapter 4
 • Molecular constructions from section 5.10
 • Anaphoric pronouns as introduced in sections 8.3–8.5
It is not necessary to use any parasitic terms, or complex terms, or infi nitizing negation. 
It can be done only with logical apparatus that was widely used and understood. And 
existential import is not a problem because the only common term is ‘thing.’
In the next section, we look at whether certain mathematical theories can be formal-
ized within medieval logic without the kind of artifi ciality appealed to here.
6 One can view the construction given here as implementing the previous idea of using “quantifi ers” on 
the fronts of formulas, but in place of the form ‘for every thing,’ we use ‘every thing is a thing and.’ Th is strikes 
some people as unnecessarily prolix, and in need of shortening. I don’t know how to shorten it in a way that 
will work in general. Th e ‘is a thing and’ portion is there to provide a location for the grammatical role that the 
initial ‘every thing’ is playing, and such a place is necessary. It is blatantly artifi cial, but that is no objection 
since the task is to fi nd natural language wordings for idioms of a patently artifi cial notation—that of sym-
bolic logic. 

first-order arithmetic in medieval logic 
269
9.5 First-order arithmetic in medieval logic
We have been comparing medieval logic with modern symbolic logic. But why should 
modern symbolic logic be the standard of comparison? Historically, symbolic logic 
did not come with a seal of approval on it. Instead, it achieved its present status by pro-
viding a system in which it was possible to formulate central claims of mathematics 
and (less evidently) science, in which the valid derivations correspond to what mathe-
maticians already recognize as valid reasoning. It is possible then that some other 
system of logic might accomplish the same goal, while being quite diff erent from 
modern predicate logic. It need only provide for the formulation of central parts of 
mathematics and science. Th is section provides a sample test: the formulation of fi rst-
order arithmetic in medieval logic.
Th e goal of this section is to see what it would be like to formulate fi rst-order arith-
metic within medieval logic in a natural way. Th e challenge is to use a logical language 
(an extension of Linguish) to formulate the theory—to state axioms and rules, and 
derive theorems. Th ere will continue to be a way to “pronounce” the logical notation 
in natural language, a way that is mechanically generated from the logical forms of 
Linguish, and that, in a transparent fashion, permits one to represent the logical struc-
ture of symbolic notation (although not without ambiguity). One constraint that 
must be maintained is that every denoting phrase in the logical notation gives rise 
to a surface denoting phrase which occupies a unique grammatical role. As long as 
this constraint is satisfi ed, we can continue to view grammatical markers as merely 
encoding the type of grammatical information that is taken into account by medieval 
theorists.
For readability of the natural language representations, I fi nd that it is natural to 
use ‘any’ rather than ‘every’ here, because the ‘any’ naturally takes wide scope. So I’ll use 
‘any’ with the understanding that it has the logical properties of ‘every’ in previous 
chapters. I will continue the policy of generating natural language translations of the 
logical forms by erasing all logical notation, and optionally moving verbs from the 
end of a proposition to an earlier position, as discussed and practiced previously. We 
also avail ourselves of the use of “relatives,” that is, of pronouns with antecedents, as 
developed in section 8.5.
We begin with the core of fi rst-order arithmetic, the axioms commonly called 
“Peano’s Postulates.”
9.5.1 Peano’s postulates
In order to symbolize the Dedekind/Peano axioms we need a notion of successor. 
I will introduce ‘successor’ as a one-place parasitic singular term. (Call it a one-place 
function symbol if you like.) Th is is just like a parasitic common noun, except that 
it is a singular term, not a common one. We could use a common term instead; 
it is quite a bit simpler to use a singular one because we thereby avoid the need to intro-
duce uniqueness clauses. It is to be pronounced ‘the successor,’ unless it is immediately 

270 
comparison of medieval logic with contemporary logic
preceded by a genitive construction with apostrophe ‘s,’ in which case it is simply pro-
nounced ‘successor.’ Th e axioms will guarantee that every number has a successor. It is 
neatest to suppose that non-numbers don’t have successors (so ‘the successor of Caesar’ 
is an empty term). However, that will not be relevant to any of the sentences we are 
interested in.
Here are the traditional axioms in Linguish notation:
AX1 (zero α)(· number β) α is β
 
Zero is a number
AX2 (Zero α)(no number β)(successor-of-β γ) α is γ
 
Zero is no number’s successor
AX3 (any number α)(successor-of-α β)(· number γ) β is γ
 
Any number’s successor is a number
AX4 (any number α)i(successor-of-α β)(no {otheri number} γ)(successor-of-γ δ) β is δ
 
Any number’s successor is no other number’s successor
Th e induction rule is normally stated as an axiom schema, using quantifi cation, con-
junction, and implication. We could state it that way here, but it is more convenient to 
introduce it as a rule schema, which holds for any formula ϕ:
Induction (zero α) ϕ
 
(any {number whichα ϕ} β)(successor-of-β α) ϕ
 
∴ (any number α) ϕ
 
zero is ϕ
 
of any number which is ϕ, the successor is ϕ
 
∴ any number is ϕ
(of course ‘is ϕ’ is a stand-in for the pronunciation of ‘ϕ,’ whatever it might be).
We also allow anaphora in the sentences used, as in section 8.3. So this form 
is OK:
(zero α)i ϕ
(any {number whichα
i ϕ} β)(successor-of-β α)i ϕ
∴ (any number α)i ϕ
(Note that the scope of the fi rst superscript ‘i’ in the second premise is confi ned to the 
complex term that it occurs in.) Allowing for anaphora in this particular way is just for 
convenience; we can get along without it, if necessary, by complicating ϕ. For example, 
instead of proving ‘(any number α)i ϕ,’ we could prove: ‘(any number γ)(some {number 
whichα
i ϕ} δ) γ is δ.’
Th e only logical innovation here is the introduction of parasitic singular terms. 
When an immediately preceding singular term binds the argument marker, the 
combination of the two terms is treatable as a unit for purposes of applying rules of 

first-order arithmetic in medieval logic 
271
inference; this is in analogy to the enhanced rules for parasitic terms described in section 
5.5.2. So one may apply the rules ES+ and UA+ to their combination. E.g. this inference 
is allowable:
 
(n α)(successor-of-α β)(· number γ) β is γ
 n’s successor is a number
 
(n α)(successor-of-α β)(· prime γ) β is γ
 n’s successor is a prime
∴ (some number β)(· prime γ) β is γ      by rule ES+
 some number is a prime
Peano’s postulates alone form a very weak system. To get fi rst-order arithmetic, one 
normally adds axioms for addition and multiplication.
9.5.2 Defi nition of addition
For addition we will introduce ‘added-to,’ which is a two-place parasitic singular 
term. (Call it a two-place function symbol if you like.) It is tricky to pronounce this 
so as to clearly indicate the order of the arguments of ‘added-to,’ because the denot-
ing phrases which bind the markers that accompany ‘added-to’ must occur in an 
order that indicates their quantifi cational scope. In the predicate calculus notation, 
this problem does not occur, since ‘+’ can be fl anked by variables, with the fi rst 
argument to the left  of the sign and the second to its right, where the quantifi ers 
that bind the variables occur elsewhere; the positions of the quantifi ers indicate their 
scope, independent of which binds the first, and which the second, variable flank-
ing ‘+.’ Th at is not the case in the natural language pronunciations, which contain 
no variables. So I have hit upon this artifi ce: Th e denoting phrases which bind the 
markers accompanying ‘added-to’ will be pronounced in the order in which they 
occur in the logical notation; the ‘to’ will immediately precede the denoting phrase 
that binds the second marker. For English, when the order of the markers follow-
ing ‘added-to’ is the same as the order of the denoting phrases binding those 
markers, the participle ‘added’ will be pronounced between the two denoting phrases, 
giving a natural ordering (such as ‘some number added to any number’); otherwise the 
‘added’ remains where is it, giving an unnatural ordering (such as ‘to some number any 
number added’). As an example, when the antecedents are names, the pronunciations 
will be:
(n α)(m β)(added-to-α-β γ) 
n added to m
(m α)(n β)(added-to-β-α γ) 
to m, n added
Th ese logical forms are provably equivalent by permuting the terms, and then chang-
ing the bound markers. Th e surface forms, ‘n added-to m’ and ‘to m, n added,’ are thus 
logically equivalent as well.
Like ‘successor,’ ‘added-to’ immediately preceded by two singular terms is equiva-
lent to having a complex singular term so far as the logical rules are concerned.

272 
comparison of medieval logic with contemporary logic
Th e usual axioms for addition (oft en called “recursive defi nitions”) in modern nota-
tion, using the prime mark for successor, look like this:
n+0 = n
n+m′ = (n+m)′
In our notation they are:
Added-to1 (any number α)i(zero β)(α-added-to-β γ)(iti δ) γ is δ
 
any number added to zero is itself 7
Added-to2 (any number α)i(any number β)j(α-added-to-β γ)(successor-of-γ δ)
 
(iti ε)(itj η)(successor-of-η s)(ε-added-to-s t) δ is t
 
 of (any number added to any number) the successor is it added to its 
successor
 
 i.e. the successor of (any number added to any number) is it [the former 
number] added to its successor [the latter number’s successor]
(In transition to natural language, the genitive produced by the markers accom-
panying ‘successor’ is attributed to the whole phrase of which ‘added-to’ is the 
center.)
Axiom Added-to1 says that zero leaves a number unchanged if it is added on the 
right. It is customary to begin development of the theory by proving a theorem saying 
that zero also leaves a number unchanged if it is added on the left . Th is is done here to 
illustrate how the theoretical development would go when the sentences in it become 
technically complex.
Th eorem:
(zero β)(any number α)i(β-added-to-α γ)(iti δ) γ is δ
zero added to any number is it [is that number]
To use the induction schema, we need a proposition that begins with a universal quan-
tifi er over numbers. So we will prove our theorem by proving this Lemma, which is 
equivalent to the theorem by permutation of the terms:
Lemma:
(any number α)i(zero β)(β-added-to-α γ)(iti δ) γ is δ
to any number, zero added is it
We prove this by induction, where ‘ϕ’ is ‘(zero β)(β-added-to-α γ)(iti δ) γ is δ.’
7 Th is ‘itself ’ should probably just be ‘it,’ because its antecedent is the fi rst part of the subject, and not all of 
the subject. I think that in the vernacular ‘itself ’ is natural, which is why I use it here. 

first-order arithmetic in medieval logic 
273
Base Case:
To show: (zero α)i(zero β)(β-added-to-α γ)(iti δ) γ is δ
 
to zero zero added is itself
1. (zero α)i(zero β)(α-added-to-β γ)(iti δ) γ is δ 
AX1 Added-to1 UA
2. (zero β)(zero α)i (α-added-to-β γ)(iti δ) γ is δ 
1 permutation
3. (zero α)(zero β)i(β-added-to-α γ)(iti δ) γ is δ 
2 change bound mkrs
4. (zero α)(zero β)(β-added-to-α γ)(zero δ) γ is δ 
3  relative term with singular 
term antecedent.
5. (zero α)i(zero β)(β-added-to-α γ)(iti δ) γ is δ 
4  relative term with singular 
term antecedent
Pronounced in natural language:
1. zero added to zero is itself 
AX1 Added-to1 UA
2. to zero zero added is it 
1 permutation
3. <no change>
4. to zero zero added is zero 
3 singular antecedent
5. to zero zero added is itself 
4 singular antecedent
Th e Induction Step: With modern semiformal notation, the strategy behind the 
inductive step is:
[A] Assume the inductive hypothesis:
 
0+n = n
[B] (0+n)′ = (0+n)′ 
Self-identity
[C] (0+n)′ = n′ 
[A] [B] Substitutivity of Identity
[D] (0+n)′ = 0+n′ 
Added-to2
[E] 0+n′ = n′ 
[C] [D] Transitivity of Identity
Th is reasoning takes for granted that all terms are non-empty, a well-known assump-
tion of mainstream classical logic. Reproducing the reasoning in Linguish requires 
quite a few additional steps to establish non-emptiness. We will also need to show, e.g. 
that 0+n is a number, since we are not making the common assumption that every-
thing is a number.
In the proof to be given, I will freely interchange bound markers without comment. 
I introduce the labels of the parts of the previous argument in the derivation to follow 
as an aid in tracking the reasoning. (Since the proof will be by reductio, the assumption 
of the inductive hypothesis is actually made in the assumption for reductio, line 1; it 
surfaces in an identifi able form only at line 7.)

274 
comparison of medieval logic with contemporary logic
Induction step:
To show: (any {number whichα
i (zero β)(β-added-to-α γ)(iti δ) γ is δ} β)
(successor-of-β α)i(zero ε)(ε-added-to-α γ)(iti δ) γ is δ
not  (any {number whichαi (zero β)(β-added-to-α γ)(iti δ) γ is δ} β)
(successor-of-β α)i(zero ε)(ε-added-to-α γ)(iti δ) γ is δ
(some {number whichαi (zero β)(β-added-to-α γ)(iti δ) γ is δ} β)
     not (successor-of-β α)i(zero ε)(ε-added-to-α γ)(iti δ) γ is δ
(n γ)(·{number whichαi (zero β)(β-added-to-α γ)(iti δ) γ is δ} β) γ is β
(n β) not (successor-of-β α)i(zero ε)(ε-added-to-α γ)(iti δ) γ is δ
(n α)(·number β) α is β 
(n α)i(zero β)(β-added-to-α γ)(iti δ) γ is δ
(n α)(zero β)(β-added-to-α γ)(n δ) γ is δ 
(any number α)(successor-of-α β)(· number γ) β is γ 
(n α)(successor-of-α β)(· number γ) β is γ
(n α)(zero δ)(δ-added-to-α γ)(successor-of-γ β)(· number ε) β is ε 
(n α)(zero δ)(δ-added-to-α γ)(successor-of-γ β)
             (n α)(zero δ)(δ-added-to-α η)(successor-of-η ε) β is ε
(n α)(zero δ)(δ-added-to-α γ)(successor-of-γ β)
             (n η)(successor-of-η ε) β is ε
(zero α)(·number β) α is β
(zero α)i(any number β)j(α-added-to-β γ)(successor-of-γ δ)
            (iti ε)(itj η)(successor-of-η σ)(ε-added-to-σ τ) δ is τ
(zero α)i(n β)j(α-added-to-β γ)(successor-of-γ δ)
            (iti ε)(itj η)(successor-of-η σ)(ε-added-to-σ τ) δ is τ
(zero α)(n β)(α-added-to-β γ)(successor-of-γ δ)
            (zero α)(n η)(successor-of-η σ)(ε-added-to-σ τ) δ is τ
(n β)(zero α)(α-added-to-β γ)(successor-of-γ δ)
            (zero ε)(n η)(successor-of-η σ)(ε-added-to-σ τ) δ is τ
(zero ε)(n η)(successor-of-η σ)(ε-added-to-σ τ)
            (n η)(successor-of-η δ) τ is δ
not (n δ)(successor-of-δ β)i(zero ε)(ε-added-to-β γ)(iti η) δ is η
not (n δ)(successor-of-δ β)(zero ε)(ε-added-to-β γ)
            (n δ)(successor-of-δ η) δ is η
not (zero ε)(n δ)(successor-of-δ β)(ε-added-to-β γ)
            (n δ)(successor-of-δ η) δ is η
(any {number whichαi (zero β)(β-added-to-α γ)(iti δ) γ is δ} β)
            (successor-of-β α)i(zero ε)(ε-added-to-α γ)(iti δ) γ  is δ                                                  
1 Equipoll
2 EX
2 EX
3 RelClause
3 RelClause
6 Sing Ante 
AX3
5 8 UA
7 9 Subst-Iden
10 Self-Iden
7 11 Subst-Iden
AX1
13 Added-to2
5 14 UA+
15 Sing Ante
16 permute
12 17 trans
of identity
4 Permute
19 Sing Ante
20 Permute 
18 21 Reductio      
1.
2.
3.
4.
5.
6.
7.
8.
9.
10.
11.
12.
13.
14.
15.
16.
17.
18.
19.
20.
21.
22.
[A]
[B]
[C]
[D]
[D]
[D]
[E]
It is apparent that, although completely rigorous, if this derivation were pronounced in 
natural language it would be extremely diffi  cult to follow.

first-order arithmetic in medieval logic 
275
9.5.3 Multiplication
Th e usual axioms for multiplication (oft en called “recursive defi nitions”) in modern 
notation look like this:
n×0 = 0  n×m′ = (n×m) + m
In our notation they are:
Times1 (any number α)i(zero β)(α-multiplied-by-β γ)(zero δ) γ is δ
 
any number multiplied by zero is zero
Times2  (any number α)i(any number β)j(successor-of-β ε)(α-multiplied-by-ε γ)
(iti s)(itj η)(s-multiplied-by-η)(iti τ)(η-added-to-τ ρ) γ is ρ
 
 any number multiplied by any number’s successor is itself multiplied by it 
added to itself
 
 i.e. any number multiplied by any number’s successor is it [the fi rst number] 
multiplied by it [the second number] added to it [the fi rst number]
Without exploring theorems at this point, it may be useful to see a few things that can 
be expressed in our notation. Here are some defi nitions:
(One α) 
(zero γ)(successor-of-γ α)
one 
zero’s successor
(Two α) 
(one γ)(successor-of-γ α)
two 
one’s successor
PosNumber 
{number whichγ not (zero β) γ is β}
positive (nmbr) number which is not zero
n < m 
(n α)(·Posnumber γ)(α-added-to-γ δ)(m β) δ is β
n < m 
n added to a positive number is m
n is prime 
(no {PosNumber whichγ not (one β) γ is β} ε)
 
(· {PosNumber whichγ not (one β) γ is β} η)(ε-multiplied-by-η δ)(n α) δ is α
n is prime 
 no positive number which is not one multiplied by a positive number 
which is not one is n
n is even 
(· number β)(two γ)(β-multiplied-by-γ δ)(n α) δ is α
n is even 
a number multiplied by two is n
Every even number is the sum of two primes:
(every {number whichγ γ is even} α)(·{number whichγ γ is prime} δ)
(·{number whichγ γ is prime} ε)(δ-added-to-ε η) α is η
every number which is even is a number which is prime added to a number which is prime
Of course, much more than this is needed to demarcate the logical power of medieval 
logic. What has been given here is only a fi rst step.

276 
ampliation and restriction
10
Ampliation and Restriction
10.1  Univocation as the source of ampliation 
and restriction
Aristotle uses ‘equivocation’ for a case in which things are called by the same name but 
the name does not have the same defi nition in each case. An example is ‘dog,’ which can 
apply to one thing because it is a canine, and to another because it is a certain star. So 
if you have inferred that something is a dog, and is not a dog, you haven’t inferred con-
tradictory propositions1 unless ‘dog’ has the same defi nition in each proposition.
According to Boethius,2 there is a way in which apparently contradictory proposi-
tions are not actually contradictory, even when you use the same word with the same 
defi nition in each application. His illustration is:
[A] man walks 
Homo ambulat
Man does not walk 
Homo non ambulat
Th ese propositions are not contradictory if ‘homo’ in the fi rst proposition stands for an 
individual man, and in the second proposition refers to the species man. Th is is not 
equivocation, because the word ‘homo’ does not have diff erent defi nitions in the two 
propositions. Boethius calls this phenomenon “univocation.” Some medieval treatises 
were written explicitly about univocation. Th eir understanding is that univocation 
occurs when a word is used twice with the same signifi cation, but what it stands for (its 
“supposition” or its “appellation”) changes. Th is kind of explanation is given e.g. in the 
(Anonymous) Treatise on Univocation, second paragraph:
Univocation therefore is when the appellation of a name varies and the signifi cation remains the 
same.
And in (Anonymous) About Univocation (562) we read:
Univocation is [a case of] the supposition of a name having varied, the signifi cation having 
remained the same.
1 Equivocation is discussed along with other fallacies in Aristotle’s Sophistical Refutations. A “refutation” 
is achieved when the respondent admits a proposition that contradicts the proposition being defended. So 
the relation of contradictoriness is central to that essay.
2 Boethius’s commentary on Aristotle’s On Interpretation, cited in de Rijk LM II.I.XV.1 (492).

univocation as the source of ampliation and restriction  
277
When a word is used as in our example to stand for the species, this is called simple 
supposition. When a word is used to stand for itself or for a related expression, as in 
‘Donkey is a noun,’ this is called material supposition. Normal kinds of supposition, 
including all of the cases discussed so far in this book, are called personal supposition.3 
Even when words are used personally it is still possible for univocation to occur: their 
supposition may vary—be “restricted” or “ampliated” diff erently—when their signifi -
cation does not vary. Th at is the topic of the present chapter.
In a non-modal present tense categorical proposition, common terms typically do 
not supposit for everything that they signify. Instead they supposit only for the pres-
ently existing things that they signify. As a result, in
Every donkey is running
the subject is restricted to suppositing for presently existing donkeys. If all of them are 
now running, then the proposition is true, even though there were or will be donkeys 
that are not now running. Similarly, in the proposition:
Socrates is a philosopher
the predicate is restricted to presently existing things. Since Socrates does not presently 
exist, the term ‘Socrates’ does not supposit for something for which the predicate sup-
posits. (Th e predicate only supposits for presently existing things.) So the affi  rmative 
proposition is false.4
Th is restriction of supposition in a present tense non-modal categorical pro-
position to presently existing things is an example of the ‘Restriction’ in ‘Ampliation 
and Restriction.’
Terms may also supposit for things in addition to their presently existing signifi -
cates. In
Some donkey was running
the subject term is taken to stand for present or past donkeys;5 the proposition is true 
if one of them was running sometime in the past. Th is expansion of what the terms 
may supposit for is the ‘Ampliation’ in ‘Ampliation and Restriction.’ It is somewhat 
arbitrary what is to be called restriction and what is to be called ampliation. So long as 
terms supposit only for things that they signify, one may call any use of a term a restric-
tion if the term does not supposit for everything that it signifi es. And any use of a term 
to supposit for things outside of some reference class of things, such as the presently 
existing things, can be called an ampliation. Th e custom is generally to say that terms 
are restricted when they are required to supposit exactly for the presently existing 
3 For discussion of these types of supposition see Parsons 2008a, section 4.
4 Some writers held that singular terms are also restricted by a tense (we return to this later). If that is so 
the proposition in question is false also because the subject term is empty.
5 My wording here is meant to be ambiguous. Some writers took the term to supposit disjunctively for all 
present and all past donkeys; others took the sentence to be ambiguous with the term suppositing for present 
donkeys on one reading and for past ones on the other reading. See section 10.2.2.

278 
ampliation and restriction
things that they presently signify, or for some subset of these, and to call any extension 
of this range of things ampliation.
Some kinds of restriction and ampliation are:6
1. Supposition restricted to presently existing things. (All previous chapters have 
taken this to be the default case.) Examples are:
Every donkey is grey
No donkey is a stone
In these cases the underlined words are “restricted” to the presently existing things that 
they signify. Th is restriction is caused by the present tense on the verb, when the verb 
itself is not special (we return to this later).
2. Supposition for past things (for formerly existing things) or for future things. 
Such supposition is caused by past and future tenses, as in:
A donkey was grey
A donkey will be grey
In these examples, the underlined words supposit for present or past or future things 
(details to be given shortly). Such ampliation is also caused by past or future participles used 
as predicates with present tense copulas, as in ‘A donkey is dead’ {Asinus mortuus est}.7
3. Supposition for never-existing but possible things, caused by an alethic modal word:
A mountain can be golden
Every pink donkey is necessarily an animal.8
Since no past, present, or future mountain is golden, ‘mountain’ must supposit for pos-
sible mountains in addition to actual ones in the fi rst proposition. Likewise, one must 
be discussing all possible pink donkeys in the second. Th is ampliation is caused by the 
modal words ‘can’ and ‘necessarily.’
4. Supposition for impossible but conceivable things, caused by words that “per-
tain to the soul”:
A chimera is believed to be an animal.
A bishop conceives [of] a donkey which is a stone.9
6 Cf. Anonymous, About Univocation, 563–4. Th e theory is developed in detail in Anonymous, Treatise on 
Univocation, sections 1 and 2, and Anonymous, On the Properties of Discourse, in the second major section, 
“Concerning Appellation.” It is discussed in Buridan, SD 4.6 and in chapter 5 of his treatise on Sophismata. 
It is mentioned by every writer on the properties of terms.
7 In English ‘dead’ is not a participle; here it translates ‘mortuus,’ which is a participle in Latin. 
8 Th e examples given here are to be read de re, not de dicto. In Aristotelian terminology, the examples are 
given the “divided” reading, not the “composed” reading.
9 Th e subject term is not ampliated in this last example, since it occurs with a present tense non-modal 
verb. Th e verb pertains to an act of the soul, and this aff ects the supposition of terms that come aft er it, but the 
subject of such a verb is not thereby ampliated.

univocation as the source of ampliation and restriction  
279
Authors disagree about the truth values of these cases, but they seem to agree with the 
semantic mechanism. Certain verbs such as ‘believe’ or ‘want’ are naturally used with 
terms that appear to supposit for things that are not possible. Since it is impossible for a 
chimera to exist, one must take the fi rst proposition to contain supposition for not just 
actual or possible chimeras, but for impossible ones (if there are any) too. Some authors 
reject this ampliation because they hold that there are no impossible things, and so 
terms cannot supposit for them. For simplicity, I will interpret these latter authors as 
agreeing with the semantic principle that in such contexts the correct semantics is to 
let the terms supposit for absolutely all things that they signify,10 and this will include 
impossible things if, and only if, there are any. Th e sentences will then be taken to have 
diff erent truth values for those who disagree about whether there are any impossible 
things. For example, Buridan does not accept impossible beings, so he would consider 
the proposition about chimeras to be false; since chimeras are impossible, there aren’t 
any chimeras to have beliefs about. Th e subject term is ampliated to supposit for impos-
sible things, but since there aren’t any impossible things, the subject is empty and the 
sentence is false.
Th e following subsections will discuss temporal ampliation by tenses, ampliation to 
the merely possible by (alethic) modal words, and ampliation to all things whatsoever 
by semantic verbs or by verbs which indicate an act of the soul.
Th e medieval accounts discussed here are remarkable in that they assume that 
tenses, modals, etc. (when given divided readings11), although they aff ect what the 
terms in the proposition supposit for, do not change the logical forms of the proposi-
tions in which they occur. A sentence of the form:
Every A is/was/will be/can be/is thought to be understood
is a universal affi  rmative proposition, and as such it is true iff  the subject has supposi-
tion, and everything for which the subject supposits is something for which the pre-
dicate supposits. Likewise:
Some A is not/was not/will not be/can not be understood
is a particular negative proposition, and it is true iff  either the subject lacks supposi-
tion, or it supposits for something that the predicate does not supposit for. Although 
the past tense shows up on the copula ‘was’ in ‘Some donkey was grey,’ it has no eff ect on 
the verb; the verb just represents identity in every case. Th e verb’s tense only aff ects 
(ampliates or restricts) what the subject and predicate terms supposit for. Likewise 
(apparently) for modal propositions: ‘every donkey possibly runs’ is true iff  every pos-
sible donkey is (tenselessly) a possible runner. And ‘every chimera is conceivable’ is true 
10 Not just verbs that pertain to the soul do this; according to many writers, semantic words such as 
‘signify’ and ‘supposit’ ampliate terms following them so that they supposit for everything that they signify. 
See section 10.6.
11 Th e divided reading is similar to what we call today the de re reading. E.g. Some A is such that it can be 
that it is understood.

280 
ampliation and restriction
iff  every chimera—possible or not—is (tenselessly) something able-to-be-conceived. 
(Th e term ‘conceivable’ does the ampliating here because it pertains to the soul.)
10.2 Ampliation and restriction by tenses
10.2.1 Tenses
For tenses, the account usually goes:
In a present tense proposition both the subject and predicate terms supposit only 
for the presently existing things which they presently signify.12
In a past tense proposition the subject supposits for presently and formerly existing 
things presently or formerly signifi ed by the term, whereas the predicate supposits 
only for formerly existing things formerly signifi ed by the term.13
In a future tense proposition the subject supposits for presently existing things 
presently signifi ed by the term and things that will exist and will be signifi ed by the 
term, whereas the predicate supposits only for things that will be signifi ed by the term 
that will exist.
Th is account is found as early as the 12th century and it is preserved throughout the 
rest of the medieval tradition. Th e present wording is similar to Ockham’s (SL 1.72, 
response to the fi rst diffi  culty).
10.2.2 A Complexity: Ambiguity or disjunction?
A sentence like ‘Some bishop was running’ can be true in two diff erent ways. In one way 
it is true if something that is a bishop now was running in the past, even if it was not a 
bishop then. Th e other way is that something which may not be a bishop now (indeed, 
may not even exist now) was a bishop in the past and ran in the past. Th eorists agree 
that there are these two options. Th ey disagree, however, about whether this is because 
the sentence is ambiguous between these two readings (as Ockham says14), or whether 
the sentence is unambiguous and has disjunctive truth conditions (as much of the 
12 I am ignoring a rather bizarre view, discussed by very many authors, according to which a term that 
does not signify any presently existing things “reverts to non-existents”; that is, it supposits for past and 
future things that it signifi ed or will signify. (According to some authors, this even happens when the term 
fails to signify at least three presently existing things.) Ockham famously argues against this view in SL 2.4 
(97–9).
13 Th is is the commonest option. In Anonymous, Properties of Discourse (726) it is held that when the 
predicate term is a substantive (though not when it is an accidental term, such as an adjective) it supposits 
both for presently existing and formerly existing things. In Anonymous, Treatise on Univocation (345) a view 
saying that accidental terms are never ampliated is mentioned, and rejected.
14 Ockham, SL II.22 (158): “every past-tense or future tense proposition in which the subject is a common 
term must be distinguished as equivocal  .  .  .  For if the proposition is past-tense, then the subject can supposit 
for that which is such-and-such or for that which was such-and-such.” Sherwood, IL 5.16.3 seems also to 
hold that the construction is ambiguous, due to an ambiguity of composition and division.

ampliation and restriction by tenses 
281
tradition says15) so that it is univocally true in either of these cases. I don’t know how to 
choose between these options.16 I will discuss the disjunctive truth condition option; it 
should be relatively straightforward to turn this account into one that appeals to ambi-
guity instead of disjunction.
Th eorists generally assume that this dual interpretation is not available for the pre-
dicate. Th e proposition ‘A bishop was running’ must be made true by something that ran 
in the past, not by something that only runs at present. So the subject and predicate of a 
past tensed sentence are aff ected diff erently by the tense. Th e predicate is ampliated/
restricted so as to supposit only for things which it formerly signifi ed. Th e subject how-
ever is ampliated so as to supposit for things which it signifi es with respect to the pre-
sent or with respect to some past time.
10.2.3 Coordination of times in tensed sentences
How tenses work in natural language is a complex matter, which is made diffi  cult by 
unclarity in the data—that is, unclarity due to speakers of the language not associating 
clear truth conditions with tensed sentences. As a result, it is not easy to assess the ulti-
mate success of the medieval theory. It confl icts with some standard paradigms of late 
20th-century tense logic, but it is oft en not completely clear which view better matches 
ordinary language usage. Since the intent is to develop the semantics of a somewhat 
artifi cial regimented use of Latin, I will be reluctant to draw many fi rm conclusions 
about its adequacy in terms of capturing Latin usage.
10.2.3.1 coordination of times between subject and predicate
Consider the sentence:
A bishop was grey
Th is is true iff  something that is now or was sometime a bishop was sometime grey. One 
part of these truth conditions is clearly right: if some present bishop was grey previously, 
whether it was then a bishop or not, the sentence has a true reading. But suppose that 
something was once a bishop, and was once grey, although that thing was never a bishop 
while being grey. In this situation the medieval reading comes out true. It is unclear to 
me whether this accords with how speakers of natural language treat such sentences.17 
In any event, these are the offi  cial truth conditions given to the sentence by the theory.
15 Buridan, SD 4.5.2 (293): “a term put before the verb appellates its form in a disjunctive manner, for the 
present and for the tense of the verb.” Paul of Venice, PL II.8 (58): “every term standing in initial position and 
with respect to a verb of past time or its participle is ampliated in order to stand for that which is or which 
was, e.g. in “white was black,” “white” does not stand for that which was white precisely or alone for that 
which is white; but in disjuncts [it stands for] that which is or was white.”
16 I thus endorse the agnostic view that Burley states (Longer Treatise, para. 209): “a proposition about the 
past in which a common term supposits has two causes of truth, or two senses of an ambiguity.” (Later, at 
para. 225, Burley takes the second option to be the right one.)
17 I think it is closer to actual current English usage than many present logicians think. Of course, this may 
be because speakers tend to speak loosely, and perhaps the meanings of their sentences should not refl ect 
that looseness.

282 
ampliation and restriction
A typical 20th-century tense logician might treat the sentence as if it is ambiguous, 
having the following three readings:18
∃x(bishop x & Past{grey x})
∃x(Past{bishop x} & Past{grey x})
Past{∃x(bishop x & grey x)}
Th e last option is not a reading that the medieval theory attributes to the sentence. On 
the medieval reading, the proposition cannot be read so as to entail that there is a time 
in the past such that the subject and predicate both stand for the same thing then; this 
is because the ampliation of the subject and predicate terms are independent of one 
another. Th is is a limit on the theory as articulated in the texts. To many modern philo-
sophical logicians this will seem wrong. Others will hold that the simultaneity of past 
times of being a bishop and of being grey is at most a possible implicature of the sen-
tence, and not a constraint on any of its readings.19
Th is lack of coordination of times of subject and predicate was sometimes featured 
by “truths” like:
A virgin was pregnant
A boy was an old man
An old man will be a boy
Th e fi rst is true because someone who was a virgin sometime in the past was pregnant 
sometime in the past. And so on. Th ese examples and ones like them are featured by 
many diff erent medieval writers,20 who seem to take them to be obviously correct.
10.2.3.2 tenses with relative clauses
We have not yet said how to handle complex terms with relative clauses occurring in 
tensed sentences. If we follow our instructions so far, we end up with an ampliated 
complex term, but with no account of how the ampliated complex term is to be under-
stood in terms of how its parts work. In the case of modifi cation by a relative clause 
there are two natural options. Option 1: We suppose that ampliating a complex term 
made with a relative clause ampliates only the simple term that is modifi ed by the rela-
tive clause. Th e terms in the relative clause itself, including the relative pronoun itself, 
are already taken care of, since that clause has a verb of its own, and the tense on that 
18 Th ese would be read: Some present bishop is such that there is a past time at which it was grey. For some 
presently existing thing, it was a bishop at some earlier time, and it was grey at some earlier time. At some 
earlier time it was the case that something was then a bishop and was then grey.
19 In favor of the latter, one might note that it is coherent to say ‘A bishop was grey until just before he 
became bishop.’ However, when ambiguity is at issue, reasoning of this sort is usually inconclusive. Th is is 
because of the diffi  culty in telling whether the additional clause with ‘until’ cancels an implicature of a non-
ambiguous proposition, or merely eliminates one of the readings of an ambiguous proposition.
20 E.g. by Paul of Venice, LP II.8 (59), who also gives ‘A prostitute will be a virgin,’ ‘A decapitated person 
will sing.’ Th ese examples were staples of the theory, and their apparent incorrectness was used in the early 
16th century by Juan Luis Vives (Guerlac 1979) to ridicule scholastic theorizing.

ampliation and restriction by tenses 
283
verb takes care of ampliating or restricting the terms in it, including the relative pro-
noun. Th is may be how the medieval theory was intended to work. Option 2: Like 
option 1 but we suppose that the relative pronoun itself is ampliated by the same verb 
that ampliates the common noun that is modifi ed by the relative clause. Th e contents 
of the relative clause, of course, will restrict what the relative pronoun supposits for, 
and this, in affi  rmative cases, will have much the same eff ect as restricting the relative 
pronoun based on the verb within the clause. But in some cases there will be a diff er-
ence. Notice that option 2 is equivalent to the principle that a relative pronoun is ampli-
ated as is its antecedent, holding (stipulating?) that the antecedent of a relative pronoun 
is the common term modifi ed by the relative clause. Marsilius of Inghen suggests this, 
and also suggests that the rules proposed for ampliation and restriction needn’t apply 
to anaphoric terms.21 Th is suggests option 3: relative pronouns are never restricted (or 
ampliated) at all. An example is the following sentence. It has a main verb in the past 
tense, and its subject term contains a relative clause in the future tense.
A donkey which will be grey was brown
Th e options are that (1) ‘which’ is ampliated by ‘will be’ to present and future things, 
but it is restricted by the clause following it to future grey things only; the sentence is 
true if a donkey that was brown is a future grey thing; (2) ‘which’ is ampliated by ‘was’ to 
stand for present and past things, and restricted by the clause to stand for things which 
will be grey; the sentence is true if a donkey that was brown is a thing which will be 
grey; (3) ‘which’ is not ampliated at all; it is restricted by its clause to stand for things 
which will be grey; the sentence is true if a donkey that was brown is a thing which will 
be grey.
Th e treatment just given accords with the view that a proposition with a past or 
future tense verb can be expounded in terms of one with a relative clause that spells out 
the eff ects of ampliation. Marsilius of Inghen, TPT, 115:
in the proposition a man will be, the term man is ampliated to have supposition for men who are 
or will be. Th erefore the sense is as follows: ‘a man who is or will be, will be.’ Similarly in the 
proposition a man will be generated, the term man supposits for those that are or will be. For the 
sense is: ‘what is or will be, will be generated.’22
If the contents of the relative clauses were ampliated by the tense on the main verb of 
the relative clause, the relative clauses would be obviously redundant. (Of course, if the 
rephrasals are truly equivalent to the originals, the relative clauses must be actually 
redundant. Th e point is supposed to be that the paraphrases are informative.)
21 Marsilius of Inghen, TPT, 91: “From this it is evident that the masters’ rules on ampliations and restric-
tions are to be understood to apply to non-relative [i.e. non-anaphoric] terms.”
22 Buridan, SD 4.6.2 also gives examples: “From these rules it follows that such propositions are 
expounded by propositions with disjunctive subjects. For example, ‘A will run’ is equivalent to ‘What is or will 
be A will run.’ Similarly, ‘A is dead’ equals ‘What is or was A is dead.’ Similarly, ‘A can run’ equals ‘What is or can 
be A can run.’ Similarly, ‘Th e one creating is of necessity God’ equals ‘What is or can be the one creating is of 
necessity God.’ Similarly, ‘A is thought of’ equals ‘What is or was or can be A is thought of.’”

284 
ampliation and restriction
Th ere remains a question about the coordination (or lack thereof) of times within 
the complex phrase. Consider:
A bishop which was grey was running
Th is sentence is true according to the account iff  there is some present or past time at 
which someone was a bishop, and some past time at which that person was grey, and 
some past time at which that person was running. It is not required that the times of 
being a bishop and being grey are the same. Th is may, arguably, be one correct reading 
of the sentence.
Buridan discusses a simple example which looks on the surface to be a clear coun-
terexample to the theory:
Everything which will be is23
Th e proposed truth conditions are that every presently existing thing which exists 
now or will exist in the future exists now. Because the ‘thing’ is restricted to presently 
existing things by the present tense of ‘is’ the sentence is true. Th is seems to be a 
straightforward application of the theory.24 Many readers will think the sentence 
should be false, since they will take it to say that every future thing exists now. Buridan 
anticipates this problem and suggests that people who think this are mistakenly read-
ing the sentence as saying:
Whatever will be is
Th is seems to be a universally quantifi ed “headless” relative clause, followed by ‘is.’ Since 
only the head noun of a relative clause is restricted by the tense of the main verb, and 
since it lacks a head, the ‘what’ is unaff ected by the tense of the main verb, and so it sup-
posits for every present or future thing, and the whole proposition is false so long as 
something exists in the future which doesn’t exist now—which is the reading we are 
inclined, perhaps wrongly, to attribute to the fi rst example.
Buridan seems to have a diff erent idea about the grammatical structure of the latter 
proposition. He says:
the word ‘whatever’ is here construed with the verb ‘will be,’ and it is necessary to add in thought 
a relative [i.e. an anaphoric pronoun] which should be construed with the ‘is,’ so that one has 
‘Whatever will be, that is.’ And so the term ‘whatever’ is ampliated to future things, and, consequently, 
23 Buridan, SD, Sophismata, chapter 5, eighth sophism, 925. Buridan has a somewhat intricate discussion. 
Th e point at issue is what things the complex term ‘thing which will be’ supposits for. I think that his point 
is that the ‘thing’ is initially restricted to the present by the verb ‘is’ and that the ‘which’ is restricted to 
the present-or-future by the ‘will be,’ and since each restricts the other, they both supposit (modifi edly) for 
presently existing things. As a consequence, the complex term ‘thing which will be’ supposits for presently 
existing things. Th e Linguish logical form displays the preliminary supposition for the individual terms (not 
yet restricted by each other), and the truth conditions for the whole relative clause are then equivalent 
to Buridan’s.
24 Paul of Venice, PL IV.2 (85) gives several similar examples, including e.g. ‘everything which was, is.’ 
He presents these as correct results of logical theory.

ampliation and restriction by tenses 
285
so is its relative, namely, ‘that.’ And thus we have counterinstances to the proposition ‘Whatever 
will be is’ in all future things which not yet are. (SD, Sophismata, chapter 5, eighth sophism, 925)
Buridan here seems to be suggesting that the ‘whatever will be’ is not construed with the 
main verb at all, and this would seem to give it no grammatical role in the proposition at 
all. Since it is not the subject of the main verb, you need to insert an anaphoric pronoun 
into the sentence to be subject. Th is would give the sentence a grammatical structure 
like that which quantifi ed sentences in modern logic have: there is an initial (restricted) 
quantifi er which has no grammatical role in the sentence it has scope over; it only aff ects 
the interpretation of the anaphoric expressions in that sentence that it is linked to. We 
could easily add such “quantifi ers” to the Linguish notation. Th ey would lack a marker, 
since they do not occupy a grammatical role in the sentence they combine with, and we 
are using markers only to indicate grammatical roles. Th e Linguish sentence would be:
(every {whichγ γ will be})i(thati α) α is
whatever will be, that is
where we generate ‘whatever’ (by stipulation) from ‘every which,’ and where ‘that’ is 
a pronoun like ‘it.’
Having explained what I take Buridan’s view to be, I admit that I don’t know why he 
holds it. All that seems to be necessary to get an intuitively plausible reading is to deny 
that the tense of the main verb aff ects ‘whatever.’
10.2.3.3  coordination of times among parts of the subject 
or predicate
Buridan says that in certain cases parts of the subject or predicate must all be treated as 
simultaneous (SD, Soph. 3.1 (887)). An example is I was eating an apple in Paris, where, 
he says, there must be some time in the past such that I was in Paris then, and I was then 
eating, and it was an apple then that I was eating. Th is is a natural intuition, but it is not 
clear how this idea can be combined with the fundamental theory. Th e problem is that 
‘eating-thing’ and ‘in Paris’ and ‘apple’ are all independent terms. Th e fi rst stands for all 
past eating things, the second for all things that were in Paris, and the third for all things 
that were apples. And they all can be independently quantifi ed: I ate every apple in 
Paris, meaning I some-past-time-ate every some-past-time-apple that was some-past-
time-in Paris. Th e issue is how to make this turn into At some past time I then-ate every 
then-apple that was then-in Paris. Th is would require some development of the seman-
tics; whether it would be a revision or a refi nement is unclear. But it is clear that this is 
not how the current theory goes.
10.2.3.4 subclauses and coordination of tense
Th ere is another way in which tenses are coordinated in natural language. Consider the 
sentence:
Socrates complained that Plato hit him.

286 
ampliation and restriction
Th is seems to have a reading in which the past tense in the subordinate clause (the 
tense of ‘hit’) is parasitic on the tense of the main clause (the tense of ‘complained’). On 
this reading, the sentence alleges that there was a past time at which Socrates made a 
complaint, and the content of the complaint concerns something that took place prior 
to the complaining. Not prior to now, but prior to the time of the complaining.
Note that the sentence contains an embedded that-clause. Th e medieval semantic 
account we have of this seems to be that it is true iff  Socrates is a present or past thing 
who is a past complainer regarding a certain proposition: one that existed in the past 
and was of the form:
Plato hit Socrates
A proposition of that past tense form evaluated at a certain time would say that Plato 
hit Socrates at some time before then (before the time at which it was uttered). So the 
whole sentence is true iff  at some past time Socrates complained, and his complaint 
was the content of a mental proposition existing then saying in the past tense that Plato 
hit him. Th us the coordination of tenses seems to work out exactly right.
Th e reading where one takes the past tense in the subordinate clause to be past rela-
tive to the past tense in the main clause is one option for the “past-under-past” reading. 
Some sentences with the past tense in both clauses have another reading. For example, 
this proposition:
Socrates thought that Euthyphro was a fool
has a natural reading according to which at some time in the past Socrates had a 
thought whose content was that Euthyphro was then a fool. Th is may be taken care of 
by stipulating that a past tense in a subordinate clause sometimes behaves semantically 
as a present tense. Th at is, the sentence is true iff  Socrates at some time in the past 
thought a mental proposition whose content was that of:
Euthyphro is a fool
(Th e general rule of thumb seems to be that past-of-past reading occurs with event 
sentences and the present-of-past occurs with state sentences.) Th e interaction of 
tenses in main and subordinate clauses is not well understood. Th ere is some hope of 
the medieval account doing as well in capturing the semantics of sentences with 
embedded subclauses as most modern theories. However, this topic was not discussed 
in detail by medieval writers.
10.2.4 Buridan’s special use of appellation
Th e theory we have been discussing makes what a term supposits for in a sentence 
dependent on its signifi cation and the time of utterance. It is patterned aft er Ockham’s 
view in that it makes use of a temporally relevant relation of signifi cation. For example, 
in a past tense sentence the word or concept ‘grey’ supposits for things that it signifi ed 
at some earlier time. Buridan has a diff erent view. For him, signifi cation is a relation 

ampliation and restriction by tenses 
287
between a term and some things, and this relation does not vary with time.25 For 
example, the concept donkey signifi es all donkeys, past, present, and future, and never-
existing but possible donkeys (if there are any), and even impossible but conceivable 
donkeys (if there are any—Buridan thinks that there aren’t any). Th is is how an abso-
lute concept works; it does not vary its signifi cation with time. To fi ll in the picture 
we need to distinguish between simple concepts and complex concepts. Examples of 
simple concepts are genus and species concepts such as “donkey,” as well as diff erentia, 
such as risibility for humans. It is important to Buridan’s account that it is not possible 
for an entity to fall under one of these concepts at one time and under another at 
another time; e.g. it is not possible for an animal to become a stone, or for a donkey 
to become a horse. If you’re a donkey at any time, you’re a donkey throughout your 
existence; you cease being a donkey only by ceasing to be. A simple mental concept, or 
a word that is a sign of a simple concept signifi es things absolutely, that is without 
respect to time. For words that indicate simple concepts we can then simplify these 
conditions from section 10.2.1 by eliminating the underlined words:
In a present tense proposition both the subject and predicate terms supposit only 
for presently existing things which they presently signify.
In a past tense proposition the subject supposits for presently and formerly existing 
things presently or formerly signifi ed by the term, whereas the predicate supposits 
only for formerly existing things formerly signifi ed by the term.
In a future tense proposition the subject supposits for presently existing things 
presently signifi ed by the term and things that will exist and will be signifi ed by the 
term, whereas the predicate supposits only for things that will be signifi ed by the 
term that will exist.
Th e underlined terminology was intended to deal with terms such as ‘white-thing’ or 
‘monarch.’ For Buridan, these terms are not absolute; they are signs of appellative con-
cepts. Th is means that their supposition is relative not just to what they signify, but also 
to what they appellate, and how. Th e simplest case of this is when a term has a nominal 
defi nition, that is, a complex phrase which is synonymous with the term in question 
where the relations among the parts of the phrase show how those simple concepts 
combine to make the complex one.
Some examples will be helpful. Th e word ‘white’ expresses an appellative concept. 
It applies to a thing at a time if that thing has a whiteness in it then. Th e term thus 
signifi es whitenesses, but it does not supposit for them; instead it supposits for things 
(substances) which have a whiteness in them, not for whitenesses. Since having or not 
having a whiteness occurs in time, what the term supposits for varies with time, as 
expected, even though the conceptual part of the term, ‘whiteness,’ does not signify with 
25 Buridan, SD Soph., chapter 2, sixth conclusion: “every present, past, and future man is signifi ed indiff er-
ently by the term ‘man,’ for it signifi es without time.”

288 
ampliation and restriction
respect to times; once a whiteness always a whiteness (so long as it exists). Th e time 
factor becomes relevant in explaining the supposition of the term by means of the 
account of relative clauses in Chapter 5. So that in a present tense sentence ‘white’ 
means ‘thing which a whiteness is in,’ and in a past tense sentence it means ‘thing which a 
whiteness is or was in.’ Th e word ‘vacuum’ is also an appellative term’; it has the nominal 
defi nition ‘place not fi lled with body.’ Presumably both ‘place’ and ‘body’ are simple 
terms that signify apart from time.
It seems that on this theory the notion of signifi cation is only needed for simple 
concepts, because the supposition of a term that expresses a complex concept is com-
pletely determined by its parts. Buridan, however, has much to say about this. In rough 
terms, his view is that an explicitly or implicitly complex expression signifi es every-
thing that is signifi ed by any of its parts, with the exception of those things for which it 
supposits. So that ‘white’ signifi es all whitenesses, while suppositing for white things, 
and ‘vacuum’ signifi es all places and all bodies, etc. And ‘chimera’ signifi es several 
things without suppositing for anything at all. Th is even extends to whole sentences, so 
that ‘A donkey is an animal’ would be said to signify all donkeys and all animals, and 
the sentences ‘God is God’ and ‘God is not God’ both signify the same thing, namely 
God. So far as I can see this extension of the notion of signifi cation to such complex 
expressions does not interact with anything else in the logic. More work needs to be 
done to understand the signifi cance of these ideas.
10.2.5 Tenses in Linguish
Adding tenses to Linguish is fairly straightforward, because the account itself is clear. 
First, we add tenses to the verbs of the language. Th at is simplest if we just stick to using 
familiar words such as ‘is,’ ‘was,’ ‘will be,’ ‘sees,’ ‘saw,’ ‘will see,’  .  .  .  , where the tense is 
obvious from the spelling. We then embellish the terms in the logical form of each 
proposition indicating what eff ect the tense of the verb has on its supposition. Th at is, 
we prefi x a sign to the term indicating how its supposition is restricted or ampliated. 
Th is notation is strictly redundant, since restriction and ampliation is predictable from 
other ingredients of the sentence, such as the tense; it only makes it easier to keep track. 
One can then take the embellished term to be a kind of term in its own right which has 
supposition independent of its context.
If the main verb is in the present tense, we embellish the subject and predicate terms 
of that verb with ‘≈’ to indicate that the embellished term is to suppositσ at each time 
t for exactly those things existing at t that the unembellished term suppositsσ for at t.
If the main verb is in the past tense, we embellish the subject term of that verb with ‘≤’ 
to indicate that the embellished term is to suppositσ at each time t for exactly those 
things that the term embellished by ‘≈’ suppositsσ for at t or some time prior to t 
(when it existed), and we embellish the predicate term of that verb with ‘<’ to indicate 
that the embellished term is to suppositσ at each time t for exactly those things that 
the term embellished by ‘≈’ suppositsσ for at some time prior to t (when it existed).

ampliation and restriction by tenses 
289
If the main verb is in the future tense, we embellish the subject term of that verb 
with ‘≥’ to indicate that the term is to suppositσ at each time t for exactly those future 
things that the term embellished by ‘≈’ suppositsσ for at t or some time aft er t, and 
we embellish the predicate term of that verb with ‘>’ to indicate that the term is to 
suppositσ at each time t for exactly those things that the term embellished by ‘≈’ 
suppositsσ for at some time aft er t.26
Th e verbs themselves work as follows:
Copulas of any tense relate a thing n and a thing m iff  n tenselessly is m.27
For this reason I will sometimes write the copula in a logical form using the identity sign.
Other verbs are not explicitly discussed in the literature, but it is easy to see how they 
would go. Consider a transitive verb V as an example, and let Vpast, Vpresent, and Vfuture be 
its tensed forms. Th e proposition ‘(§1 α)(§2 β) α Vpresent β’ is the same as before:
‘(§1 α)(§2 β) α Vpresent β’ is trueσ at t iff  σ(§1) bears the relation that ‘V’ signifi es to 
σ(§2) at t.
For the other tensed forms:
‘(§1 α)(§2 β) α Vpast β’ is trueσ at t iff  σ(§1) bears the relation that ‘V’ signifi es to σ(§2) 
at some time before t.
‘(§1 α)(§2 β) α Vfuture β’ is trueσ at t iff  σ(§1) bears the relation that ‘V’ signifi es to σ(§2) 
at some time aft er t.
(Th ese are the conditions that result from making a verb equivalent to its participle-
plus-copula form when the substantivated participle binds the marker following the 
copula.)
26 Th ese conditions work as intended only if the term is univocal across time. Without such a constraint, a 
term could supposit for certain unintended past things because the word used to have a diff erent meaning. 
For example, ‘Roses stank’ would be true because ‘stink’ used to supposit for roses (it used to supposit for roses 
because it used to mean ‘smell strongly’). It is not completely clear how to avoid this problem. One attempt is 
this: A term either is or is subordinated to a mental term (concept) T; in a past tense proposition the term 
supposits for things presently existing and presently signifi ed by T, or things previously existing and previ-
ously signifi ed by T; etc. Th is assumes that a concept cannot change what it is a concept of as time goes by. 
Probably that assumption is hard to justify within the medieval framework. A concept is an accident in the 
soul of the person who possesses it, and so it is subject to the persistence conditions of accidents. But what 
things it signifi es depends on what it represents; and that depends in turn on its connections with the envi-
ronment. Perhaps they could change without it becoming a new accident. Or perhaps not. Th is goes beyond 
matters discussed in the logic texts with which I am familiar.
27 Th is interpretation of the theory is based primarily on the fact that tensed identity is not appealed to in 
the texts in stating the semantics. In general, it would be redundant to appeal to tensed identity, since the 
terms in question are themselves confi ned to certain times. One might wonder however how to analyze 
‘Marcus will be Tully’ if one takes the option that singular terms are not restricted or ampliated. Th e theory as 
I have stated it would make this true since both singular terms would supposit for the same thing. But one 
might think that it should be false because Marcus/Tully do not now exist. Here is where one might want to 
have tensed versions of the copula as well. But this is speculation.

290 
ampliation and restriction
It is convenient to take the absence of an embellishing symbol to abbreviate embel-
lishment by ‘≈.’ If we do this, then all of the Linguish logical forms discussed in previ-
ous chapters are already properly embellished, and no changes are needed in them. (I 
will occasionally use the ‘≈’ to call attention to the restriction to the present.)
Th is theory relies on identifying which term is subject and which predicate. I assume 
that in Linguish logical forms, the subject term is the one whose denoting phrase binds 
the marker preceding the verb, as discussed in section 6.2. Th is means that a surface 
sentence whose verb is a third-person singular form of the copula will usually be 
ambiguous (in Latin, anyway) regarding which term is subject and which predicate. 
Th at did not matter previously when discussing only non-ampliative contexts, since 
the readings are equivalent. With ampliative contexts the readings are not equivalent, 
and so for surface sentences the ambiguity matters.
Some additional things can be said concerning even simple examples. One point is 
that as soon as tenses other than the present are allowed into the symbolism, many 
arguments that are valid when confi ned to the present tense are no longer formally 
valid in other tenses. An example is simple conversion:
 
Some white was black 
(some ≤white α)(· <black β) α=β
∴ Some black was white 
(some ≤black α)(· <white β) α=β
Suppose that something is white now, and it was black in the past, and that nothing was 
white in the past. Th en the premise is true and the conclusion false, for the conclusion 
requires a past white thing and the premise does not.
Interestingly, all of Aristotle’s direct syllogisms (the direct ones from fi gure 1 plus 
all of fi gures 2 and 3) remain valid when past or future tense is uniformly added (pro-
viding that there are no non-tense sources of ampliation—to be discussed later). An 
example is past-tense Barbara:
 
Every B was C 
(every ≤B α)(· <C β) α was β
 
Every A was B 
(every ≤A α)(· <B β) α was β
∴ Every A was C 
(every ≤A α)(· <C β) α was β
When tenses are added to a direct syllogism the embellishments yield an argument 
with four terms, with the “middle terms” related as ‘≤F’ and ‘<F’ or as ‘≥F’ and ‘>F.’ One 
could easily construct rules of proof for the new arguments if it were possible to express 
these relationships. But that would require propositions such as:
(every <F α)(· ≤F β) α is β
(every >F α)(· ≥F β) α is β
and these are not correctly embellished, and would not be correctly embellished even if 
‘is’ were changed to ‘was’ or ‘will be.’
Th e indirect fi gure 1 moods are all formally invalid. For example, this form of 
Baralipton can have true premises and a false conclusion if there are present Ps but no 
past ones:

ampliation and restriction by tenses 
291
 
Every M was S 
(every ≤M α)(· <S β) α=β
 
Every P was M 
(every ≤P α)(· <M β) α=β
∴ Some S was P 
(some ≤S α)(· <P β) α=β
(Embellishing these forms yields a syllogism with six distinct terms. It’s an uphill fi ght 
to get validity out of that many terms.)
Th ese facts hold for the disjunction treatment of tense. If past- and future-tensed 
propositions are held to be ambiguous as outlined earlier then validity of the direct 
forms would depend on how the ambiguity is resolved. Sometimes resolving them in 
one way yields a good inference while resolving them in another way yields an invalid 
one. Ockham discusses extensively how various of these options bear on conversions 
in SL 2.22 (158–62), including options where conversion is valid if a relative clause is 
introduced, as in ‘No white thing was a man; therefore nothing which was a man is white.’
We might consider how to expand the rules for Linguish given in Chapters 4–5 to 
include propositions with embellished terms. One change that needs to be made is that 
we need an expanded condition for when a term is non-empty. We could defi ne this by 
cases, including e.g.
≈P is non-empty 
(some P α)(· P β) α is β
<P is non-empty 
(some ≤P α)(· <P β) α was β
≤P is non-empty 
≈P is non-empty or <P is non-empty28
>P is non-empty 
(some ≥P α)(· >P β) α will be β
≥P is non-empty 
≈P is non-empty or >P is non-empty
Reductio is a basic rule that needs no alteration. Likewise, conditions for when two 
propositions are contradictories or contraries, the rule of double negation, and all of 
the quantifi er equipollences are unchanged. If singular terms are susceptible to ampli-
ation and restriction, permutation for singular terms with other denoting phrases still 
holds, though somewhat similar processes are no longer valid—namely, those that 
change which term is the subject and which the predicate. Th is, for example, is a good 
inference:
A runner Socrates was 
(· <runner β)(≤ Socrates α) α was β
∴ Socrates a runner was 
(≤Socrates α)(· <runner β) α was β
But this is fallacious:
A runner Socrates was 
(·≤runner α)(< Socrates β) α was β
∴ Socrates a runner was 
(≤Socrates α)(· <runner β) α was β
28 Th is use of the connective ‘or’ can be avoided by using inference rules, as I have done throughout. Th e 
rules could be (taking ‘≤’ as an example):
 
≈P is non-empty 
 
<P is non-empty
∴ ≤P is non-empty 
∴ ≤P is non-empty
 ≤P is non-empty, ≈P is not non-empty 
 
≤P is non-empty, <P is not non-empty
∴ <P is non-empty 
∴ ≈P is not non-empty

292 
ampliation and restriction
If Socrates existed in the past without running and exists and runs now, the fi rst is true, 
but the second is false.
Interestingly, the reverse inference seems to be valid:
Socrates a runner was 
(≤Socrates α)(· <runner β) α was β
∴ A runner Socrates was 
(· ≤runner α)(< Socrates β) α was β
Th is is because in order for the premise to be true Socrates must have run in the past, 
and so he must have existed in the past, so changing ‘≤Socrates’ to ‘<Socrates’ does not 
provide an additional constraint.
So we have the following new rule for tense permutations:
Tense permutation
If m and n are singular terms and P a common term, these inferences are valid:
 
(≤m α)(· <P β) α was β
/∴ (<m β)(· ≤P α) α was β
 
(≤m α)(<n β) α was β
/∴ (<m β)(≤ n α) α was β
Similarly for the future tense.
Th ere are additional constraints on Exposition. For example, taking a past tense form 
for illustration, this form of Exposition is OK:
(Some ≤A α)(· <B β) α was β
∴(<n β)(· ≤A α) α was β 
EX
∴(≤n α)(· <B β) α was β 
EX
But this is not even well formed:
(Some ≤A α)(· <B β) α was β
∴(<n α)(· ≤A β) α was β 
EX 
← not well formed
∴(≤n α)(· <B β) α was β 
EX
A similar constraint holds for Expository Syllogism, which, as usual, is the reverse of 
Exposition:
(<n β)(· ≤A α) α was β 
(≤n α)(· <B β) α was β
∴(Some ≤A α)(· <B β) α was β 
ES
In its general form, Exposition is:
(Some ≤A α) ϕ
∴(<n β)(· ≤A α) α was β 
EX 
provided that ‘≤A’ is non-empty
∴(≤n α) ϕ 
EX 
provided that ‘≤A’ is non-empty

ampliation and restriction by tenses 
293
and Expository Syllogism is:
(<n β)(· ≤A α) α was β
(≤n α) ϕ
∴(Some ≤A α) ϕ 
ES
Th e derived rule, Universal Application, takes the form:
 
(every ≤T α) ϕ
 
(<n β)(· ≤T α) α is β
/∴ (≤n α) ϕ
Proof of UA:
2 3 ES
4 Equipollence
Reductio; 5 Contradicts 1
(every ≤T α) ϕ
(<n β)(· ≤T α) α is β
(≤n α) ϕ
1.
2.
3.
4.
5.
6.
not (≤n α) ϕ
(some ≤T α) not ϕ
not (every ≤T α) ϕ
To illustrate the updated rules we give a proof of the past tense version of Barbara. Th e 
proof is like that given in Chapter 2, with an additional appeal to the new rule of Tense 
Permutation:
BARBARA
3 EX
3 EX
4 2 UA
6  Tense Permutation
5 7 ES
8 Equipollence
reductio: 9 contradicts 1
(every ≤B α)(· <A β) α was β
(every ≤C α)(· <B β) α was β
(every ≤C α)(· <A β) α was β  
1.
2.
3.
4.
5.
6.
7.
8.
9.
10.
(some ≤C α) not (· <A β) α was β 
(<c β)(· ≤C α) α was β
(≤c α) not (· <A β) α was β
(≤c α) (· <B β) α was β
(<c β)(· ≤B α) α was β
(some ≤B α) not (· <A β) α was β
not (every ≤B α)(· <A β) α was β 
Naturally, propositions in the future tense are to be handled similarly to those in the 
past tense.
Looking ahead, it is unclear whether a complete set of rules can be formulated for 
the system of Linguish as expanded here. Th is is because embellishments constrain the 
formation of formulas that can be used in stating the rules. It is not at all clear that all 

294 
ampliation and restriction
valid arguments can be proved by derivations using some set of rules where the deriva-
tions consist entirely of correctly embellished formulas. (An example of a good deriva-
tion was given earlier in connection with Barbara.) I am not certain of much at this 
point. Additional work is needed here.
10.2.5.1  if singular terms are not subject to restriction and 
ampliation
In section 4.3 it was noted that according to many earlier writers, singular terms are not 
subject to ampliation and restriction. In our framework, this means that they would 
not be embellished, so that they would be the same in all tensed propositions. I believe 
that everything that was said earlier about the embellishment option holds if singular 
terms are not embellished. Whenever there is only one singular term in a proposition, 
the embellishment of the other term is suffi  cient to require the special provisions dis-
cussed earlier. If all the terms in a proposition are singular, then the only diff erence 
now is that certain new rules are redundant. For example, the second pattern listed 
under “Tense Permutation” earlier is already provable when the terms are not embel-
lished at all.
10.2.6 Infi nitizing negation
Our treatment of infi nitizing negation from section 5.5 is:
Th e term ‘non-T’ suppositsσ (with respect to t) for everything that ‘T’ does not 
suppositσ for (with respect to t).
But if we are to calculate the supposition of non-T from that of T in a sentence, we 
must know what T supposits for there. We cannot assume that it supposits for the pres-
ently existing things that it signifi es, unless we can identify some cause of restricting 
the supposition to those present things. It thus appears that the tense of a verb must 
restrict or ampliate the sub-term ‘T’ when ‘non-T’ occurs as a main term. In terms of 
our present methods, this means that embellishing the term ‘non-T’ is accomplished 
by embellishing the ‘T’ itself. Th is leaves the ‘non’ to act on the embellished supposition 
of ‘T,’ as in the rule that we have stated. So in:
A non-bishop was running
the term ‘bishop’ supposits for present and past bishops, and ‘non-bishop’ supposits for 
absolutely everything that isn’t a present or past bishop. Since ‘running’ is ampliated to 
include all past running things, only the supposita of ‘non-bishop’ that are past things 
are relevant to the truth of the proposition; other things don’t matter. When other 
sources of ampliation are present, the other supposita may be relevant; we return to 
these cases in section 10.4.
One might wonder whether the term should be doubly ampliated/restricted, that is, 
the negated term and the whole negative term should both be ampliated/restricted. So 
that, for example, in the sentence ‘A non-white thing will run’ the term ‘non-white’ is 

ampliation by modal terms 
295
required to supposit for presently existing and future things that are not presently nor 
will be white. Th is is certainly an option. We will see in section 10.4 that Buridan, at 
least, did not do this. His account appears to be as we have taken it to be in the stated 
rule (i.e. the rule that the predicate governed by ‘non’ is ampliated or restricted, and not 
the whole complex predicate).
10.3 Ampliation by modal terms
10.3.1 What are modal propositions?
Today, a “modal proposition” is a proposition containing a modal word, like ‘necessary’ 
or ‘possible’ together with a non-extensional context, such as ‘It is necessary that no donkey 
is a stone.’ Such propositions are called modal by some in the medieval tradition; see 
Peter of Spain, LS 1.20–1.23; Ockham, SL 2.9 (109). Others, such as Buridan (SD 1.8.2 
(67–70)) reserve the term ‘modal’ for a proposition in which the copula is modifi ed by a 
word such as ‘necessarily’ or ‘possibly.’ Th ere is no such modifi cation in ‘It is necessary 
that no donkey is a stone’ since the ‘necessary’ is a predicate of the whole that-clause, not 
a modifi er of the copula. Such propositions containing embedded that-clauses29 were 
taken to attribute some property, such as necessity or possibility, to the thing that the 
that-clause stands for. For many writers (e.g. Ockham) a that-clause typically stands for 
the proposition that constitutes the contents of the clause. Th is might be a written or 
spoken proposition, or, more frequently, a mental proposition (a sentence of mental 
language). A minority of writers also think that that-clauses stand for abstract non-
linguistic things. Propositions with embedded that-clauses are not discussed (much) 
in this text. In any event, they are not considered to be modal for present purposes.
For Buridan, a real modal proposition is one in which a modal word applies to the 
copula. Th ese come in at least three varieties.
(i) 
Modal adverbs modifying the copula alone
 
Some animal possibly-is grey
 
Every donkey necessarily-is an animal
 
Every donkey of-necessity-is an animal
 
She possibly-is grey
(ii) 
Combinations with the helping verb ‘can’
 
Some animal can be grey
 
No donkey can be a stone
 
She can be grey
29 When I speak in general of that-clauses I include the constructions of Latin that are typically translated into 
English as that-clauses. Th ese are usually accusative-infi nitive clauses, which also occur in restricted contexts 
in English. An example is the underlined clause in ‘She considers him to be a fool,’ in which the subject of the 
embedded clause (‘him’) appears in the accusative case and in which the verb (‘to be’) takes the infi nitive form.

296 
ampliation and restriction
(iii) Combining a modal adjective with the copula
Th e third sort is more complex, with a syntax diff erent from that of English. 
Here a modal adjective together with a new copula combines with the exist-
ing copula, which assumes its infi nitive form. Th e subject and predicate terms 
also take the objective case. Transliterations of some Latin examples are:
 
Some animal possible is [to] be grey
 
No donkey possible is [to] be a stone
 
Her possible is [to] be a stone
My own opinion is that examples of type (iii) are really accusative-infi nitive construc-
tions with raised subjects, as evidenced by the accusative case of their subjects.30 But 
this is not the way that Buridan (and probably others) viewed them. So I will take them 
to be special cases of genuinely modal propositions.
10.3.2 Modal propositions: Semantics
Discussion in medieval texts leaves the truth conditions for modal propositions some-
what unclear. Th e unclarity that we face here has to do with the logical forms of such 
propositions. One option works fairly clearly, and matches most of the discussion in 
the texts. Th is is to make modal propositions behave semantically as much like tem-
poral ones as possible. In particular, in modal propositions we assume that the copula 
itself is unaff ected by the modal sign, and the terms themselves are ampliated by the 
modal expression to possible things, or to necessary things. In particular:
Th e subject is ampliated to possible things (including things that exist at any time).
Th e predicate is also ampliated; what it is ampliated to depends on the mode.
Th ere is no other eff ect.
Examples:
Every animal possibly-is [a] donkey ≈ Every possible-animal is a possible-donkey
Every animal necessarily-is [a] donkey ≈ Every possible-animal is a necessary-donkey
Which things does a term like ‘possible donkey’ supposit for? Presumably a possible 
donkey is an entity that is possibly a donkey. Th is will include all actual donkeys, past, 
present, and future—since modal words are explicitly said to ampliate their supposi-
tion to the past, present, and future.31 It will probably not include any other actual 
things, since e.g. a tree has a kind of essence that excludes being a donkey. (Th is 
depends on what view you have about necessary properties. I am assuming what I 
think is the most usual view, attributed to Aristotle.) Will it include never-existing 
30 E.g. an underlying form is ‘It is possible for some animal to be grey’; the ‘some animal’ raises to replace the 
dummy word ‘it’ to yield ‘Some animal is possible to be grey.’ Th e underlying form is one that Buridan would 
not regard as being modal.
31 Some theorists held that the ampliation is only to the present and future, since the past is necessary.

ampliation by modal terms 
297
things that are possible donkeys? So far as I can see, the semantic theory is neutral on 
this. If there are such things, then ‘donkey’ signifi es them, and it supposits for them in 
modal propositions. Buridan, SD 4.6.2 (299) says:
a term put before the verb ‘can’ or before the copula of a proposition about possibility [de pos-
sibili] in the divided sense is ampliated to stand for possible things, even if they do not and did not 
exist. Th erefore the proposition ‘A golden mountain can be as large as the Mont Ventoux’ is true.
So he seems to think that in some alethic modal contexts terms do stand for never-
existing things.
Since existing Fs are included among the possible Fs, in a proposition of possibility 
the subject and predicate are ampliated in the same way. As a result, conversions are 
possible (‘some A possibly is a B; therefore some B possibly is an A’), as are all of Aristotle’s 
syllogisms (e.g. ‘Every B possibly is a C, every A possibly is a B; therefore every A possibly 
is a C’). But conversion fails for propositions of necessity (‘some A necessarily is a B; 
therefore some B necessarily is an A’), although the direct syllogisms, but not the indi-
rect ones, are valid (e.g. ‘Every B necessarily is a C, every A necessarily is a B; therefore 
every A necessarily is a C’). (Th is assumes that every necessary P is a possible P.)
What then about necessary donkeys, which are needed for the second sentence. Th is 
will include all actual donkeys if each donkey is necessarily a donkey. (Th ough there 
may be none, since perhaps something that is necessarily a donkey necessarily exists, as 
Buridan argues early in TC 4 (Latin page 112).) Again, it will probably not include any 
other actual things. Again, there is a question as to whether there are also non-actual 
necessary donkeys. Perhaps these coincide with the non-actual possible donkeys (on 
Aristotle’s view—though probably not on contemporary views). Again, that is a meta-
physical view that the semantic theory is neutral on.
(Perhaps some of the uncertainty stems from the fact that one tradition has it 
that ‘necessarily’ means ‘essentially,’ and some later writers interpret it more like 
20th-century philosophers do.)
10.3.3 Diff erences between medieval and modern readings
Medieval and modern logicians have diff erent and confl icting paradigms. A clear 
example of this is given in Marsilius of Inghen, TPT, 119, discussing the ampliation of 
subject terms by modal words:
From this it is evident that a consequence from a proposition with is to a proposition with can 
by way of a distributive sign is never valid, as in the case: every B is A, therefore every B can be A. 
And the reason is that it is an argument from a less ample to a more ample suppositing term. In 
propositions of the present the term stands only for those things that are, because there is no 
ampliation. And in a proposition with can, it stands for every thing that is or can be.
An example would be:
 
Every animal is a donkey
∴ Every animal can be a donkey

298 
ampliation and restriction
From a modern point of view, this argument is obviously valid, since when ‘can’ is read 
de re it has no eff ect on ‘animal’; ‘animal’ stands for the same in both propositions. But 
on the medieval reading the premise would be true if all actual animals were donkeys, 
but the conclusion would be false in that case, since it means essentially “every possible 
animal can be a donkey,” and so far as logic is concerned there may be possible animals, 
such as possible humans, which cannot be donkeys. Clearly the disagreement in theory 
depends highly on diff erent intuitions about what the data are.
10.3.4 Modal propositions in Linguish
At a superfi cial level it is straightforward to add modal propositions to Linguish. 
For simplicity let us confi ne ourselves to necessity and possibility. We allow copulas to 
be modifi ed by them, so the modifi ed copulas now include ‘possibly-is’ and ‘necessarily-
is.’ Either of these ampliates the subject of the sentence to possibles, indicated by 
diamond-shaped embellishments. Th ey aff ect the predicate term diff erently. A couple 
of examples are:
(No ◊donkey α)(· ◊stone β) α possibly-is β
No donkey possibly is a stone.
(every ◊donkey α)(· □animal β) α necessarily-is β
Every donkey necessarily is an animal
Th e semantics of the embellished terms requires explanation, and this is a problem, 
because of uncertainty about how signifi cation is to be understood. Th ere are funda-
mentally two themes found in the texts (as already discussed).
 • One theme is the view that Ockham appears to have. His explanation is that in a 
modal context a term supposits for what it “can signify” (SL 1.72).32 Presumably 
things that a term can signify are in addition to those that it does signify.
 • Th e other theme is governed by the idea, discussed earlier, that non-appellative 
terms are ampliated to supposit for everything they signify which can exist, 
whereas the story is more complicated for appellative terms.
New rules of inference are needed to handle terms in modal contexts. I have not 
pursued these matters here because there is so little medieval discussion of the 
details that development would be mostly speculation. (One exception is Book 4 of 
Buridan’s TC.)
A special case: Medieval writers took some non-alethic words to create modal 
readings as well; these are modal because they modify the copula, and they ampliate 
the terms in the proposition. A special case is ‘always,’ mentioned in Lambert (PT 6c) 
32 Th is requires a caution similar to that mentioned in connection with tenses: since written and spoken 
terms have their signifi cation by convention, such a word can signify anything at all. Perhaps Ockham’s 
intent is better captured by saying something like “a word either is or is subordinated to a mental term (a 
concept) T, and in a modal context the term supposits for whatever T can signify.”

ampliation due to semantic words 
299
which ampliates the terms in the proposition to all times, though not to non-actual 
things.
10.4 Ampliation due to semantic words
Semantic terminology ampliates terms, just as do words that pertain to the soul. For 
example, ‘signify’ ampliates terms as widely as they can be ampliated. Th is is clear from 
examples like ‘In a position following “conceive,” “Dodo” signifi es all dodos,’ which is 
intended to apply to all dodos, not just to presently existing ones. Th is is consistent with 
no dodo presently existing. Some authors would accept ‘“chimera” signifi es chimeras 
and no chimera is possible.’ (Th ose who oppose this view do so because they think that 
there are no chimeras at all to be signifi ed.) Th e same goes for ‘supposit,’ as in ‘“dodo” 
supposits for dodos in past tense sentences.’
One might want to ask about the ontological commitments of such a theory. Th e 
logic and semantics alone don’t commit you to much. Saying that ‘donkey’ signifi es all 
donkeys is, by itself, a truism. Since it is an affi  rmative sentence it commits you to there 
being at least one actual, possible, or imaginable donkey. But no more. It is possible to 
state various commitments within the theory. For example, one might say ‘Some don-
key which is not will be grey. Th is commits you to future donkeys that do not exist now. 
But only if you endorse it. If you thought that God had just destroyed all donkeys, and 
would not permit there to be any more, you wouldn’t assert that sentence. Likewise 
‘Some donkey which was not and which is not and which will not be is possible’ commits 
you to possible donkeys that are not actual at any time; if you don’t believe in them, you 
needn’t endorse the proposition.
Consider however ‘A dodo lived.’ Presumably this is true, and so the semantics will 
say that in ‘A dodo lived’ the term ‘dodo’ supposits for dodos. However, one cannot 
argue from this to ‘Some dodos are,’ since in the fi rst sentence the term ‘dodo’ is ampli-
ated to supposit for past dodos and in the second sentence it is not ampliated. Th is is a 
classic case of the fallacy of univocation.
10.4.1 Looking ahead
In previous sections we have been studying propositions involving tenses and modali-
ties. Th ere has been much contemporary work in these areas, and the subject matter is 
relatively well behaved and relatively well understood. Much of this work falls under 
“intensional logic,” wherein logical structures can be given semantics involving alter-
native times or alternative (possible) worlds. Th e same cannot be said for propositions 
containing locutions for believing, wishing, saying, imagining, owing, and so on. Th ese 
are all notions that medieval logicians classifi ed as “pertaining to the soul.” In the 
remaining sections I will touch briefl y on some of the many things they had to say in 
this area. We begin with ampliation, but things fairly quickly branch out. I will consider 
the following sections successful if I succeed in communicating a glimpse at some of 
the rich ideas that were discussed.

300 
ampliation and restriction
10.5 Ampliation due to words which pertain to the soul
Th is doctrine is simple: the use of words which pertain to the soul ampliate certain 
terms so that they may supposit for everything that those terms signify (or did or will 
or can or can be imagined to signify).33 For example, in ‘Th e antichrist is opinable’ the 
adjective permits the subject to supposit for future things, so the subject is not empty, 
and presumably the term ‘opinable’ is able to supposit for anything—past, present, 
future, possible, conceivable—that one may have an opinion about. Since one may have 
opinions about the antichrist, the proposition is true. ‘Some person thinks of a gold 
mountain’ can be true because the verb ampliates the term ‘gold mountain.’ However, 
‘Socrates thinks of the antichrist’ is not true when Socrates himself does not exist, since 
the subject is not included in the pertaining to the soul.34
Buridan, SD 5.6.8 notes that when the term ‘believed’ is used, all syllogisms fail.
Buridan, SD Sophismata, chapter 5, 923 gives an example that applies this sort of 
ampliation to a negative term that uses infi nitizing negation. Regarding the sophism 
a non-being is understood, he says:
I respond that the sophism is false, for the term [‘non-being’] supposits for nothing.
And this is clear in the following manner: for the verb ‘to understand’ or ‘to be understood’ 
ampliates supposition to past, and future, and even all possible things. Th erefore, if I say, ‘A being 
is understood,’ the term ‘being’ supposits indiff erently for every present or past or future or pos-
sible thing. But the rule is that an infi nitizing negation added to a term removes its supposition 
for everything for which it supposited, and makes it supposit for everything for which it did not 
supposit, if there are any such things. Th erefore, in the proposition ‘A non-being is understood,’ 
the term ‘non-being’ does not supposit for some present, nor for some past, nor for some future, 
nor for some possible being; therefore, it supposits for nothing; and so the proposition is false.
33 Marsilius of Inghen, TPT, 125: “a term governed by terms that signify an inner act of the soul is ampliated 
to supposit for what is or was or will be or can be or can be imagined to be. Verbs of this kind are: to understand, 
to love, to think, to strive for, to long for, to foresee, to imagine, to know and so on.”
p. 111: “when it is asked if void is ampliated in this proposition the void is understood, I agree. Th e reason is 
that it supposits for its signifi cates with respect to diff erent times, for this verb is understood ampliates it to have 
supposition for all the signifi cates which it has. But it should be noted that it has signifi cates corresponding to 
it with respect to diff erent copulas, because it signifi es what can be and what can be imagined to be.”
Anonymous, Properties of Discourse, 729–30: “As when it is said ‘Something is true,’ ‘Something is false,’ 
‘Something is imaginable,’ that term ‘something’ is restricted as much for an existent [thing] as for a nonexist-
ent. And this happens because of this, that the form of the predicate is not joined to the content of the subject, 
but to something with respect to it. Hence when it is said ‘A chimera is imaginable,’ the imaginability is not 
joined to the chimera, but to something with respect to the chimera. Whence it should be observed generally 
that whenever the form of a predicate is not joined with the content of a subject, although any restriction 
may have to be made through the form, no form is joined to it.
Again it should be noted that verbs pertaining to the approving power of the soul have the force of ampli-
ating the supposition of a common term. As when it is said: ‘Socrates praises a man,’ ‘A man disdains a man,’ 
‘A man thinks about a man,’ that term ‘man’ in each supposits as much for an existent as for a nonexistent. 
Similarly, nominals deriving from those verbs have the force of ampliating. As when it is said ‘A man is laud-
able,’ that term ‘man’ supposits for a nonexistent. And this happens because of this: that nothing is joined to 
the praised thing, but to be praised with respect to it.”
34 Marsilius of Inghen, TPT, 127: “in the proposition I understand, the pronoun I is not ampliated because 
the act of understanding does not transmit to me.”

ampliation due to words which pertain to the soul 
301
(Th is was the example alluded to in section 10.2.10 regarding how ampliation works 
with negative terms.) He goes on to give a very similar proposition that seems almost 
equivalent to the one under discussion, but is true. It illustrates the lack of equivalence 
between ‘non-P’ and ‘what is not P’ in the context of ampliation. He argues:
And I say that ‘A non-being is understood’ and ‘What is not a being is understood’ are not equiv-
alent, for by the verb ‘is’ you restrict the infi nity [infi nitatem] to present things. Th erefore, the 
supposition for past and future [and possible] things remains, and thus this has to be conceded: 
‘What is not [a being] is understood.’ If, therefore, we are to give an equivalent analysis of ‘A 
non-being is understood,’ then it will be the following: ‘What neither is, nor was, nor will be, nor 
can be is understood,’ and this is false, just as the sophism was. We should say the same about the 
proposition ‘A non-being will be.’ For it is false, although this is true: ‘What is not a being will be.’
But there is a strong objection to this way of settling the matter [determinatio]: for in the propo-
sition ‘What is not a being is understood’ or even in ‘what is not a being will be’ the verb ‘is’ 
restricts the term ‘what’ so that it supposits only for things that exist [at present]. And then, since 
of everything that exists it is false to say that it is not a being, it follows that the whole subject 
‘what is not a being’ implies contradiction, therefore, it supposits for nothing; e.g., the whole 
[phrase] ‘man who is not a man’ supposits for nothing.
Also, ‘something that is not a being’ supposits for nothing, but to say ‘what is not a being’ and to 
say ‘something that is not a being’ amount to the same; therefore, this is false: ‘What is not a being 
is understood’ or ‘What is not a being will be,’ for the subject supposits for nothing.
To this I reply as before, that these propositions are true. For this reason we have to realize that 
such a proposition, namely, ‘What is not will be,’ or ‘What is not is understood,’ is not complete, 
except on account of what is added [to it] in thought, and this is so on two accounts. First, because 
here the relative [pronoun] ‘what’ is posited without an antecedent. Secondly, there are two verbs 
here, for which a single [name in the] nominative [case] cannot provide a suppositum; therefore, 
we have to supplement it [as follows]: ‘What is not will be,’ that is, ‘Something that is not will be.’ 
But in this proposition, the term ‘something’ is not construed with the verb ‘is,’ but with the verb 
‘will be’; therefore, it is not restricted to present things, but is ampliated to future ones. 
Furthermore, although the relative [pronoun] ‘what’ [or ‘that,’ quod] is construed with the verb 
‘is,’ nevertheless, it is not restricted by [this verb] to present things, for a characteristic feature of a 
relative [pronoun] is that it should supposit as does its antecedent. Th erefore, the whole subject 
‘something that is not a being’ does indeed supposit for something not present but future; there-
fore, the proposition is true. (SD Sophismata, chapter 5, 923–4)
Again, Buridan takes the proposition in question to have a grammatical form diff erent 
from its apparent grammatical form. But he treats this case diff erently from the one 
about what will be. Patterned aft er that other case, we would expect Buridan to say that 
the actual grammatical form of ‘What is not a being is understood’ is: ‘What is not a 
being, that is understood.’ But this would not accomplish his purpose, for the ‘what is not 
a being’ in this sentence supposits for nothing (according to the theory), and the verb 
cannot alter this. Instead, he proposes ‘something that is not a being is understood.’ Th is 
would seem to have the same problem, but he argues not. He seems to say that ‘thing’ is 

302 
ampliation and restriction
ampliated by the nature of the phrase ‘is understood,’ which seems to be what the theory 
forces us to say. But then he argues that the relative pronoun ‘that’ has ‘thing’ as its ante-
cedent, and pronouns with antecedents “should supposit as their antecedents do.” Th is 
then seems to require that we choose the option 2 semantics for relative pronouns as 
discussed in section 10.2.6, namely, the relative pronoun is not to be construed with the 
verb within the relative clause, at least so far as ampliation and restriction are con-
cerned. Instead, it is ampliated as is the noun that is modifi ed by the relative clause. Th e 
relative clause still restricts the relative pronoun, but only by what it says. In the case 
in question, the relative pronoun is ampliated to potentially supposit for absolutely 
everything, and the relative clause restricts these things to those that are not (present, 
actual) beings. Th e example then works as Buridan intends. In Linguish notation it is 
(using ‘^’ to indicate ampliation of a term for all of its signifi cates):
(some {^thing ^whichγ not (· ≈being β) γ is β} α) α is understood
Here the relative clause ‘^whichγ not (· ≈being β) γ is β’ supposits for everything that is 
not a being (that does not presently actually exist); ‘^thing’ supposits for everything; 
and so the subject term ‘{^thing ^whichγ not (· ≈being β) γ is β}’ supposits for every-
thing that does not presently exist. Presumably, one of those is understood, and so the 
proposition is true.
Th e meaning of the caret shares a problem with that of the tense and modal embellish-
ments discussed earlier. Th e two options from before would extend to the present case:
 • On the fi rst option, we would say something like: in the presence of a word 
pertaining to the soul, a term supposits for everything for which it signifi es and 
for which it has signifi ed and for which it will signify and for which it can signify 
and for which it can be thought to signify.
 • On the second option, we say simply that in the presence of a word pertaining to 
the soul, a non-appellative term supposits for everything which it signifi es (and 
the story for appellative terms needs articulation).
10.6 Promising and owing
Suppose that I promise to give you a particular horse, Blackie. Th en most researchers 
took this fact to verify the sentence:
A horse I promised you
In this position, the term horse was generally thought to satisfy the conditions for 
determinate supposition, because we can infer:
Horse1 I promised you or horse2 I promised you or horse3  .  .  .
and the original sentence follows from:
Th is horse I promised you

promising and owing 
303
Th is position licenses substitution; if all and only horses are running, then it follows:
A running thing I promised you
Th e interesting case, however, is if I do not specify a particular horse, but I merely 
promise to give you some horse or other. Th en most researchers took that to verify the 
sentence:
I promised you a horse
In this position it is not clear what mode of supposition the term ‘horse’ has. It is gener-
ally agreed that it does not have determinate supposition. And in particular the fi rst 
sentence, ‘A horse I promised you’ does not follow from it.
Some thought that in this position the term does not have personal supposition at 
all; it has simple supposition, as in ‘Horse is a species.’ Th is is initially problematic 
because it seems that this would validate the sentence ‘I promised you a universal,’ but 
others were not convinced of this inference, or were not bothered by it. Some opposed 
the analysis on other grounds: if what is promised is the universal, then the promise 
cannot be paid off  by giving a particular horse. But this was subject to the rejoinder that 
giving a particular horse is how you pay off  a promise when what is promised is a uni-
versal. Th is is explained in an early anonymous discussion:
It is customary to say that in this locution ‘this one promises you a horse’ the term ‘horse’ may 
have simple supposition. If that be true, that term ‘horse’ is not able to be taken for some inferior, 
but only for [a] common. Hence, whoever is thus obligated is not able to be released from the 
promise unless he were to give a horse in common. Which is impossible.
To this it should be said that this verb ‘promise’ brings in two acts, namely an act of obligating and 
an act of giving. Th at is evident in this exposition: ‘I promise’ is the same as ‘I oblige myself to 
give.’ But of these acts, one is mental, the other is corporeal. And on account of this, this verb 
‘promise’ insofar as it is said with respect to those two refl ections, refl ects upon this term ‘horse.’ 
Because with respect to the act of obligating, which is an act of the mind, it refl ects upon it sim-
ply, and with respect to this it confers on it simple supposition. But with respect to the act of giv-
ing, which is a refl ection of some inferior, it refl ects upon the same term personally. Hence 
whoever is thus obligated is able to give some particular horse and to be released from his/her 
promise. (Anonymous, On Signifi cant Words, 610)
Th is analysis is suggestive, though it is not part of a systematic theory. More needs to 
be said.
Many people took the term instead to have personal supposition. Burley held 
that the term has determinate supposition here, but “under a disjunction.” Th is is not 
very informative since he did not explain what it means to be determinate under a 
disjunction.
Burley may have had in mind merely confused supposition. Ockham took the term 
to have merely confused supposition, because the descent described earlier for deter-
minate supposition is not satisfi ed. Th e term ‘horse’ is confused by the verb ‘promise’ 

304 
ampliation and restriction
which pertains to the soul. Th e verb also ampliates the term at least to all future horses; 
otherwise there would be a possible impediment to the analysis. For Ockham thought 
that terms with merely confused supposition licensed descent to a disjunctive term, so 
that ‘I promised you a horse’ would entail:
I promised you horse1 or horse2 or horse3  .  .  .
Suppose that there exist now only three horses, h1, h2, and h3. Th en if the term were not 
ampliated to the future, we could infer:
I promised you h1 or h2 or h3  .  .  .
Th is would mean that if I wait for other horses to be born, and give you one of them, 
there would still be a promise of mine that was unfulfi lled, namely the promise to give 
you h1 or h2 or h3. Ampliating to future horses avoids this problem.
Even this may not be enough, for the previous argument could perhaps be iterated, 
naming all future horses. So perhaps ampliation would have to be to possible horses 
as well. In fact, this was one of the standard views. In another early anonymous work, 
we see:
Th is verb ‘is promised’ has a force similar in extension to the foregoing verbs [i.e. verbs pertaining 
to enunciations]. For when ‘A horse is promised’ is said, this name ‘horse’ is held there confusedly, 
so that it not only draws its appellation around to all times, but also is related to those which are 
able to be. (Anonymous, About Univocation, 569)
Buridan gave an interestingly diff erent solution which seems to grow out of the tradi-
tion of simple supposition. Buridan (and others) thought that when there is a verb 
pertaining to the soul a term that comes aft er the verb is made to “appellate” its 
own concept,35 and the verb is sensitive to the concept. Th is provides a solution to 
a puzzle originated by Aristotle: Suppose that someone is approaching, but they are 
too far off  for you to identify them. Th en Aristotle thought, and medieval authors 
agreed, you do not know the one approaching. But if the one approaching is in fact 
your father, it would seem to follow that you do not know your father. Since the verb 
‘know’ pertains to the soul, Buridan would construe the parts of the puzzle as actually 
having the form:
You do not know the one approaching under the concept “approaching.”
Your father is the one approaching.
You know your father under the concept “father.”
You may perhaps use the identity to substitute, but what you will get is:
You do not know your father under the concept “approaching.”
35 Th is is something like Frege’s thesis that in such contexts words come to refer to their customary senses. 
But on Frege’s view such words cease to have their ordinary references, whereas on the medieval account 
their original reference is maintained.

promising and owing 
305
Verbs have this eff ect only on words following them, so that the facts are:
Your father you know.
Th e one approaching you know.
Buridan proposes to apply this technique to the promising case, so that ‘I promised you 
a horse’ means something like ‘I promised under the concept horse to give you a horse.’ 
Th e case is similar with ‘I owe you a horse.’ In his Sophismata he argues:
Finally, concerning this matter, we posit the fi ft eenth sophism in this chapter, and it is a rather 
diffi  cult one, namely, ‘I owe you a horse’  .  .  .  And I posit the case that in return for some good 
service that you performed for me, I promised you one good horse, and that I obligated myself 
before a competent judge to give you one good horse.  .  .  .  (SD Sophismata, chapter 4, 907–8)
Th is sophism appears to be diffi  cult. First, however, I lay it down that in the case posited I would 
owe you a horse, but then the question arises whether I owe you Blackie. And we should reply 
that this is not so, and also that by promising you a horse I did not promise you Blackie; for, as 
was said earlier, the verbs ‘promise,’ ‘owe,’ just like the verbs ‘know’ and ‘think,’ make the terms 
following them appellate their concepts. Th erefore, a consequence is not valid in which the con-
cept or predicate is changed aft er [the verb]; indeed, it does not appear to be a valid consequence 
either if we descend from the species to the individual without distribution. However, it should 
be added that it makes a great diff erence whether we place ‘horse’ before or aft er [the verb], for 
the aforementioned verbs, because of the appellation of the concept, somehow confuse the [sup-
position of the] terms that follow them, so that it is not possible to descend to the singulars by 
means of a disjunctive proposition. For example, this is not valid: ‘I owe you a horse; therefore, I 
owe you Tawny, or I owe you Blackie,  .  .  .’, and so forth; for each [member of this disjunction] is 
false. But before [the verb] the term is not thus confused; therefore, it is possible to descend by 
means of a disjunctive [proposition]. Th erefore, if ‘A horse is owed by me to you’ is true, then it 
follows that either Tawny is owed by me to you or Blackie is owed by me to you, and so forth. 
(SD Sophismata, chapter 4, 909)
At this point we have only touched on a substantial set of issues. Th ey have been much 
discussed by others,36 and I have no doubt that new insights await us in the future.
36 See Ashworth 1974b, 1976; Klima 1993; Read 1985.

306 
appendix: artificial quantifiers in early 16th-century logic
Appendix
Artifi cial Quantifi ers in Early 
16th-Century Logic
It seems to me likely that important new insights in logic might yet be provided by 
the detailed investigation of those four artifi cial quantifi ers and of others that 
could be added.
(Broadie 1985, 68)
It is distinctive of medieval logic that it is formulated almost entirely in natural 
language. Authors did not feel the same need as Frege to abandon natural language and 
replace it with a specially designed artifi cial notation. However, towards the end of 
the 15th century (Ashworth 1978, 601), logicians began to introduce artifi cial signs to 
alter the meanings of otherwise purely natural language sentences.1 Th ese signs were 
designed to aff ect the quantifi cational status of terms. Th e signs were introduced 
apparently to increase the expressive power of the logical notation already in use. I will 
argue that in a certain sense this goal is accomplished; nonetheless, for any proposition 
containing such a sign, there is a mechanical way to convert that proposition into a 
logically equivalent proposition not containing such a sign. So in another sense the 
new signs did not increase the logical expressibility of the notation.
Th is discussion is tentative because I rely mostly on secondary sources, primarily the 
very useful essays Ashworth 1978 (hereaft er MQ), Broadie 1983 (hereaft er GL), and 
1985 (hereaft er CJM) in understanding both the theory of special signs and the goals 
that were supposed to be accomplished by their use. Further, the theory to which the 
artifi cial signs are added, as presented in the secondary sources, contains elements that 
do not fi t together neatly, so one must make choices. For example, Ashworth reports 
that by the 16th century, tests for modes of supposition had evolved so as to consist of a 
set of equivalences. As an illustration, a term has distributive supposition if and only if 
the sentence in which it occurs is equivalent to a conjunction of sentences each of 
which has a singular term in place of the term in question. ‘Donkey’ has distributive 
1 Th ese signs are ridiculed in Vives, APD 61 center.

the signs 
307
supposition in ‘Every donkey is running’ because it is equivalent to ‘Donkey1 is running 
and donkey2 is running and  .  .  .  and donkeyn is running’ (MQ 599). But theorists also 
held that ‘B’ has distributive supposition in ‘Some A is not B’ (MQ 600). And it is appar-
ent that ‘Some A is not B’ is not equivalent to ‘Some A is not B1 and some A is not B2 
and  .  .  .  some A is not Bn.’2 In this Appendix I ignore the equivalence constraint and go 
with the intended application, but additional study of the original texts could show this 
to be the wrong tack.
1. Th e signs
Th ere are four artifi cial signs explicitly introduced to aff ect the mode of supposition of 
a term. Th ey come with the following explanations:
Sign a Makes a term have merely confused supposition
 
Illustration: In ‘a A is not B’ the term ‘A’ has merely confused supposition3
Sign b Makes a term have determinate supposition
 
Illustration: In ‘Every A is b B’ the term ‘B’ has determinate supposition4
Sign c 
Used on a main term that occurs with two other main terms;
 
 makes the term have merely confused supposition relative to the fi rst term 
and determinate supposition relative to the second
 
 Illustration: In ‘Of every A every B is c C’ the term ‘C’ has merely confused 
supposition relative to ‘A’ and determinate supposition relative to ‘B’5
Sign d Used on a main term that occurs with two other main terms;
 
 makes the term have determinate supposition relative to the fi rst term and 
merely confused supposition relative to the second
 
 Illustration: In ‘Of every A every B is d C’ the term ‘C’ has determinate 
supposition relative to ‘A’ and merely confused supposition relative to ‘B’6
2 In practice attention would be diverted from this problem because a primary focus was on analyzing 
sentences, and for this purpose rules were given regarding the order in which terms were to be replaced by 
conjunctions and disjunctions of singulars so as to analyze the original sentence. In ‘Some A is not B’ the 
rules required that ‘A’ be replaced fi rst, yielding ‘A1 is not B or A2 is not B or  .  .  .  or An is not B.’ In each resulting 
disjunct, the term ‘B’ has distributive supposition by the equivalence test, and so no diffi  culty arises. Th is does 
not mean that there is no inconsistency, but it does mean that ignoring it would not lead to trouble when 
doing analysis.
3 Broadie, CJM 66. Th e example: ‘a man is not an animal’ is given in both GL 51 and Ashworth, MQ 601. 
(a. homo non est animal.)
4 Broadie, CJM 67. Th e example: ‘Every man is b animal’ is given in both GL 51 and Ashworth, MQ 602. 
(omnis homo est b. animal.)
5 Broadie, CJM 68. Th e example: ‘Of every man every ass is c animal’ is given in GL 52, and ‘Of every man 
every donkey is c. donkey’ in Ashworth, MQ 609. (Cuiuslibet hominis quilibet asinus est c. asinus.) 
6 Broadie, CJM 68. Th e example: ‘Of every man every ass is d animal’ is given in GL 53, where it is attrib-
uted to Lokert. Ashworth does not give an example.

308 
appendix: artificial quantifiers in early 16th-century logic
Why were these signs introduced? One purpose was to fi ll out the theory of con-
version. In the inherited tradition, universal affi  rmatives convert per accidens, that 
is, from 
Every A is B
one can infer:
Some B is A
but they do not convert simply; ‘Every A is B’ does not convert at all to a proposition 
that is equivalent to it. Apparently. But you can indeed get a proposition that is logically 
equivalent to what you started with if you use one of the new signs, as follows:7
Every A is B  ⇒  a B is every A
Since the term ‘B’ in the converted form has merely confused supposition, this in 
essence gives it scope to the right of the term ‘A’; that is, it is to be interpreted logically 
just like ‘Every A is B.’ So the forms are equivalent.
Broadie (CJM 66) also suggests that the signs were introduced to make notation 
more economical. He suggests that: 
Each B is something that some A or other is not
can be expressed more briefl y as 
a A is not B
Th is is certainly more economical. In general, these signs let you express old con-
tents with new combinations of symbols, and if a theory addresses, say, the order of 
signs—as does the theory of conversion—use of these signs can expand the existing 
theory.
2. What the signs mean
Th e explanations given in section 1 do not completely specify the meanings of the new 
signs. Th is is because giving a term a new mode of supposition typically aff ects the 
modes of supposition of other terms. For example, suppose that we change the mode 
of supposition of ‘A’ from determinate to distributive in this proposition:
Some A is B
by changing its initial quantifi er:
Every A is B
7 Th is is described in Ashworth, MQ 603.

what the signs mean 
309
Th is obviously makes the other term, ‘B,’ change from determinate to merely confused 
supposition. Introducing one of the new signs appears to have a similar eff ect. However, 
the explanations of the meanings of the special signs given in section 1 do not describe 
the eff ects of those special signs on other terms in the proposition. So one must 
speculate about the exact meaning of propositions containing the new signs, based in 
part on the intended applications. I do have a speculation about the intended meanings 
of the special signs. I will explain the meanings of these signs by giving an algorithm 
for converting a proposition containing the sign into an equivalent proposition with-
out special signs. I speculate that the eff ect of the sign on the proposition containing it 
is that the sign makes the proposition equivalent to the one yielded by the algorithm. 
Th e algorithm then needs to be tested by seeing if it gives results that accord with the 
logicians’ intent.
Th e idea behind the algorithm is to fi rst put the proposition in question into a kind 
of normal form, and then make the obvious alteration in that form.
Th e algorithm
1. Preparation: Move the verb to the rightmost position. (Th is isn’t always neces-
sary, but it never hurts.)8
2. Preparation: Now eliminate negative signs by moving them to the right, using 
the well-known equipollences for this. E.g. in ‘Some A not some B is,’ move the 
‘not’ to get ‘Some A every B not is.’ And change ‘Some A no B is’ to ‘Some A every B 
not is.’
3. Move terms (with any quantifi er signs that accompany them) as follows:
a. 
 Move a term with ‘a’ to the right of the fi rst universal term to its right, if 
there is such a term.
b. Move a term with ‘b’ all the way to the left .
c. 
Move the term with ‘c’ to the left  of the term next to it on its left .
d.  Move the second term in the sentence to the front of the sentence, 
and move the fi rst term in the sentence to the right of the term contain-
ing ‘d.’
4. Finally, replace the moved special sign by ‘some’ (or, equivalently, by nothing at 
all, thereby producing an indefi nite construction).9
For the paradigms cited earlier, the results of applying this algorithm are as follows. 
Th e sign ‘a’:  ‘a A isn’t B’ ⇒ ‘every B some A isn’t’
8 Based on examples cited in Broadie’s texts, the logicians he discusses were comfortable with such verb-
fi nal constructions.
9 If more special signs were added, some of them might need to have their terms replaced by ‘every.’ It just 
happens that the signs discussed all require something equivalent to ‘some.’

310 
appendix: artificial quantifiers in early 16th-century logic
Th is gives ‘A’ merely confused supposition, as required. 
Th e sign ‘b’: 
‘Every A is b B’ 
⇒ ‘some B every A is’
Th is gives ‘B’ determinate supposition, as required. 
Th e sign ‘c’: 
‘Of every A every B is c C’ 
⇒ ‘of every A some C every B is’
Th is gives ‘C’ merely confused supposition, because of the preceding ‘every A.’ It does 
not have determinate supposition, but if the ‘every A’ were removed, or if one were to 
descend under it, ‘C’ would then have determinate supposition. I take it that this is 
what is meant by saying that ‘C ’ has determinate supposition relative to ‘B.’ 
Th e sign ‘d’: 
‘Of every A every B is d C’ ⇒ ‘every B some C of every A is’
Th is gives ‘C ’ merely confused supposition, because of the preceding ‘every B.’ 
It does not have determinate supposition, but if the ‘every B’ were removed, or 
if one were to descend under it, ‘C’ would then have determinate supposition. I 
take it that this is what is meant by saying that ‘C ’ has determinate supposition relative 
to ‘A.’
3. Th e signs are, in a sense, logically dispensable
It is clear that if this algorithm works correctly, it is not logically necessary to intro-
duce these special signs, since any proposition containing one of them is equivalent 
to a proposition not containing any of them. But this goes against the judgment of 
some theorists. In discussing Lokert’s proposal that ‘Every A is B’ has a subcontrary, 
Broadie says:
What is being said here is that ‘Every A is B’ has a subcontrary in which the ‘A’ has merely con-
fused supposition and the ‘B’ has distributive supposition. Without the use of special quantifi ers 
such a proposition cannot be constructed, and indeed much of the impetus in early sixteenth-
century logic for developing the theory of special quantifi ers derived specifi cally from the need 
to describe the transformation rules by which, given any proposition, its contrary, contradictory, 
or subcontrary opposite could be described. Using the special quantifi er ‘a’ the subcontrary 
proposition described by Lokert can readily be constructed. It is
12. a A is not B.” (GL 170)
I think that sentence (12) is indeed a subcontrary of ‘Every A is B,’ and it is readily 
and simply constructed, but a subcontrary can also be constructed without the use of 
special signs. Th e proposition ‘Every B some A isn’t’ is equivalent to (12) by the algo-
rithm, and in any event it is clearly a subcontrary of ‘Every A is B.’ So this particular 
claim of indispensability does not hold. 
Later, Broadie describes Lokert’s attempt to fi nd a contradictory of 
30 a A is not B.

a doubt: certain examples do not work  as advertised 
311
Lokert says that ‘a man is not white’ has a contradictory whose predicate has determi-
nate supposition. Broadie says:
Th is highlights one reason why, granted the employment of the a operator, the b operator had to 
be introduced, for without the b operator there is no way, short of using a formula with a number 
of singular propositions, of saying what the contradictory of 30 is. (GL 174)
But again this can be done without special signs; the proposition ‘Some B is every A’ 
contains no special signs, and it is a contradictory of 30. Broadie does not quote Lokert 
himself as claiming that the new signs are indispensable, and I don’t know whether 
Lokert, or Major, or others make the claim. I think that the use of the signs is interesting 
even if they are not indispensible. I think that at this point we must regard their indis-
pensability as an open question.
4.  A doubt: Certain examples do not work 
as advertised
Th ere is an apparent problem with the theory as described, in that use of the sign ‘a’ 
does not always give its term merely confused supposition.
Broadie (GL 144) illustrates a descent from the proposition: 
(xiv) a A is not B
Assuming that there are only two Bs, he says that descent under (xiv) takes us to: 
(xviii) a A is not B1 & a A is not B2
(where ‘B1’ and ‘B2’ are singular terms standing for the two Bs). But this is problematic. 
Th e sign ‘a’ occurring in ‘a A is not B1’ cannot do its job of conferring merely confused 
supposition on its term, because it is in a proposition that contains no other common 
terms, and merely confused supposition is not possible in such a proposition. Suppose, 
contrary-to-fact, that ‘A’ were to have merely confused supposition in 
a A is not B1
Th en, by defi nition of merely confused supposition, the term ‘A’ does not have determinate 
supposition; so no descent under ‘a’ in that proposition to a disjunction of propositions 
is possible. Th at is, this does not follow:
A1 is not B1 ∨ A2 is not B1 ∨ A3 is not B1 ∨  .  .  .  etc.
But since ‘A’ has merely confused supposition, it is possible to descend to a proposition 
with a disjunct term: 
(A1 or A2 or A3 or  .  .  .) is not B1.

312 
appendix: artificial quantifiers in early 16th-century logic
However, since ‘B1’ is a singular term, these two propositions are equivalent; the dis-
junction of propositions is equivalent to the proposition with a disjunct term.10 So it 
can’t be that descent is impossible to the fi rst but possible to the second.11
I think that the solution to this is to ignore the fact that the words ‘merely confused’ 
appear in the standard defi nition of the sign ‘a.’ Th e meaning of the sign ‘a’ is correctly 
given by the algorithm in section 2; it has the eff ect of permuting its term with a universal 
one to its right— if there is one—with the term then becoming particular or indefi nite. 
In its intended central uses, the term to its right has distributive supposition, and the 
term marked with ‘a’ ends up with merely confused supposition. But if the term on 
the right is singular, the term with ‘a’ may end up with determinate supposition. So the 
term ends up with merely confused supposition in the featured cases, but not in sim-
pler cases. With this understanding, Broadie’s analysis is correct, and there is no prob-
lem at all with the theory. It is just not completely accurate to say that ‘a’ always confers 
merely confused supposition on its term. 
Th e same understanding is required by Broadie’s claim (GL 169) that this equiva-
lence is valid: 
A1 is B ↔ A1 is a B
Since the second ‘B’ cannot be permuted at all (and it cannot be given merely confused 
supposition) we must take this to be one of the applications of ‘a’ in which its term 
ends up having determinate supposition (which is essentially what the equivalence 
that Broadie claims requires).12
10 Th is is assuming that the negation has narrow scope here. If it were interpreted with wide scope the 
proposition would be the denial of ‘(A1 or A2 or A3 or  .  .  .) is B1.’ But then it would also be the denial of ‘A1 is 
B1 or A2 is B1 or A3 is B1 or  .  .  .  ,’ so it would be equivalent to ‘A1 is not B1 and A2 is not B1 and A3 is not B1 
and  .  .  .’ which would mean that ‘A’ actually has distributive supposition in the proposition from which 
descent is made, contradicting the assumption that it has merely confused supposition there. 
11 I am here presupposing the following analyses of the modes of personal supposition. Th ese are attrib-
uted to John Major by Broadie, CJM 52–4 and GL 46–7: 
Determinate supposition: descent to a disjunction and ascent from any disjunct 
Distributive supposition: descent to a conjunction and no ascent from a single conjunct
Merely Confused disjunctive supposition: no descent to a disjunction, but descent to a disjunctive term and ascent from any 
disjunct.
(Actually, Broadie does not include the proviso under Merely Confused disjunctive supposition that the 
descent conditions for Determinate supposition are not satisfi ed. Th is is needed because otherwise ‘A’ would 
have merely confused supposition in ‘Some A is B,’ which is not a view that anybody held.)
12 Actually, Broadie seems to claim that the predicate of the left -hand proposition has determinate sup-
position without having merely confused supposition, and the predicate on the right has merely confused 
supposition without having determinate supposition. (E.g. he speaks of a “transformation” of a term from 
one having determinate supposition to one with merely confused supposition.) But modes of supposition 
are defi ned in terms of ascent and descent, and if the equivalence is valid, the predicate terms must have the 
same mode(s) of supposition. 

another doubt: the paradigm use of sign ‘d’ is incoherent 
313
5.  Another doubt: Th e paradigm use of sign ‘d’ is 
incoherent
Perhaps the major objection to my proposed algorithm is that if my analysis of the sign 
‘d’ is applied to the paradigm given in section 1, the result is incoherent. Th is is because 
the paradigm illustration contains what in earlier chapters I have called a parasitic 
term; this is the “possessed” term in the genitive relation, namely, the term ‘B’ in the 
paradigm example:
Of every A every B is d C
If this is expressed in the Linguish notation, the example is: 
(Every A α)(every B-poss-α β)(d C γ) β is γ
If this is transformed as I suggest, you get:
(every B-poss-α β)(some C γ)(every A α) β is γ
where the ‘α’ in the initial denoting phrase is not bound. So the result of applying the 
transformation is not a meaningful proposition.
Th is may show that I haven’t given a correct way to analyze the special sign. But 
I think that a case can be made that the paradigm example itself is incoherent in terms 
of the theory itself, quite apart from the algorithm.
Before explaining this I need to say something about rules of priority of ascent and 
descent. It was commonly said that descent should be carried out under a determinate 
term fi rst, if one is present, and then under a (wide) distributive term if no determinate 
one is present. Why should one do these things in this order? If other descents are valid, 
why is it wrong to do them? Th e answer, I think, is that when priority rules are under 
discussion, they are being proposed within an enterprise of analyzing propositions 
with quantifi ed terms into conjunctions and disjunctions of propositions without 
quantifi ed terms. For the purpose of analysis one needs a descent to an equivalent con-
junction or disjunction. For example, one can analyze:
Some A is not B
as:
[A1 is not B] ∨ [A2 is not B] ∨  .  .  .  for all the As
And one can further descend under each conjunct to get:
[A1 is not B1 & A1 is not B2 & A1 is not B3  .  .  .  for all the Bs]
 
∨
[A2 is not B1 & A2 is not B2 & A2 is not B3  .  .  .  for all the Bs]
 
∨
 
.  .  .  for all the As

314 
appendix: artificial quantifiers in early 16th-century logic
Th e result is a disjunction of conjunctions, which is true if and only if the original 
proposition is true. It is equivalent to the original proposition, which is required if the 
descents are to be seen as a kind of analysis of it. Now if we were to descend under ‘B’ 
fi rst, and then ‘A,’ we would validly get a conjunction of disjunctions. But this could not 
be an analysis of the original proposition since it is not equivalent to it. So if we are 
looking for an equivalent proposition, we must descend fi rst under the term with 
determinate supposition.
Now let me return to my argument that the paradigm example is incoherent. I base 
this on Broadie’s explanation (which seems right to me):
In
(18) Of every A every B is d C
descent is made under B (which is distributed) before being made under C, and under C (which 
is determinate) before being made under A (which is distributed). (CJM 68)13
Broadie says this because of the rules for priority of descent: descent must be made fi rst 
under a determinate term, if there is one; then under a distributive term. (Although ‘C’ 
is determinate with respect to A, it is not determinate simpliciter.14) However, this con-
fl icts with another rule of the theory, which is that when terms are related as determi-
nable and determinant, then descent should be made fi rst under the determinant if 
both determinant and determinable have the same kind of supposition.15 In our exam-
ple, the determinant is ‘A’ and the determinable is ‘B,’ and both terms are distributed. So 
the analysis that Broadie proposes for this case is ruled out.16 And I can see no better 
proposal.
I suspect that this problem does not lie with the theory in general, but with the selec-
tion of the particular paradigm illustration. Th e problem is not with the suggested 
meaning of the special sign ‘d,’ but it is a problem with the attempt to use this sign 
along with a genitive construction, a construction which involves a determinable/
determinant (“possessed”/”possessor”) pair. If we change the example from a proposi-
tion with a genitive construction to one where the terms are not so related, the problem 
disappears. Th is requires a proposition with three main terms, none of them parasitic, 
13 Broadie’s wording seems to say that ‘C’ is determinate in ‘Of every A every B is d C,’ which is not right; 
but if descent is made fi rst under ‘B,’ then ‘C’ will be determinate in the results of that descent, and I think that 
this is what he means. In any event, I don’t see an issue here.
14 Strictly, a term’s being determinate or merely confused relative to another term doesn’t obviously say 
anything at all about it’s being determinate or merely confused in the whole proposition. Th e theory may be 
indeterminate here. Broadie’s judgment about the statuses of the terms would be correct if my proposal is 
right, and I don’t see anything else more plausible. 
15 CJM 64. Also GL 52: “in order of descent, determinator has precedence over determinable.” 
16 Another example of this is John Major’s claim, reported in GL 240, note 4, that this equivalence is valid:
Of B every A is C ↔ Of a B every A is C
Th e right-hand side of this is either ill formed, or else it means ‘Every A of B is C,’ where the fi rst two items 
form a complex term; the result is well formed, but it is not equivalent to the left -hand side. I am not sure 
what to conclude about this.

some examples from john major 
315
and this can be accomplished by using a verb that takes both direct and indirect objects. 
An example would be:
Every woman gives to every farmer d gift 
which would mean (on my proposed analysis):
To every farmer some gift  every woman gives
(“For every farmer d there is a gift  g such that every woman gives g to d.”) If we were to 
analyze this proposition by appeals to descent, one would descend fi rst under ‘farmer’ 
(for ‘gift ’ is merely confused and ‘woman’ has only narrow distribution), next under 
‘gift ’ (which would then be determinate), and fi nally under ‘woman.’ Th ere would be no 
problem at all. Th e problem with the paradigm given by medieval authors is just that 
they used a parasitic term—which cannot have a mode of supposition at all17—as if it 
could have a mode of supposition.
6. Some examples from John Major
Th ere are probably many other issues lurking in the unedited writings, which are volu-
minous. Here are a very few examples of uses of special signs taken from a collection of 
John Major’s works from the early 16th century.18
At fol lxiii “Dubium hoc est satis diffi  cile  .  .  .” Major is discussing how to produce 
the contradictories of various propositions. He proposes certain specifi c propositions 
to be the contradictories of certain given propositions. Th e propositions that he claims 
here to be contradictories are:19
Of a man a donkey any rudible is
Of any man any donkey c rudible not is
Th e algorithms from section 2 turn these sentences into:
Of a man any rudible a donkey is
Of any man a rudible any donkey not is
Considering quantifi er equipollences it is apparent that these propositions are indeed 
contradictories. (He then goes on to discuss intricacies of ascent and descent.)
At fol lxv “Pro quo adverte  .  .  .” Major is again discussing what propositions are 
contradictories. He proposes these slightly complicated cases as contradictories:
Of a man a donkey not is a donkey
Of any man any donkey c donkey is
17 See section 7.4.
18 Th roughout this section I am very indebted to Dr. Th omas Ward for assistance with the (unedited) 
Latin text.
19 In all of the examples to follow that contain genitives one needs to guess which term is related as the 
“possessed” to the genitive term. When it is possible I have chosen the fi rst term to the right of the genitive 
term. Otherwise the selection is made to parallel other examples.

316 
appendix: artificial quantifiers in early 16th-century logic
Our algorithm turns these into:
Of a man every donkey a donkey isn’t
Of any man a donkey any donkey is
Th ese are contradictories by the quantifi er equipollences.
Right aft er that example he claims that these are contradictories:
Of a man a donkey not is a donkey
Of any man any donkey d donkey is
Our algorithms turn these into:
A donkey every donkey of a man isn’t
Any donkey a donkey of any man is
Th ese are contradictories by quantifi er equipollences—or they would be if they were 
well formed. Th e problem is that each of them has a parasitic term that is not within 
the scope of the term it is parasitic on. So these sentences are not generable with the 
version of Linguish discussed earlier. If we ignore this diffi  culty, the algorithm seems to 
be working, in the sense that it produces examples that work as intended in the text.
At fol lxi “Septimo arguitur sic  .  .  .” Major is considering the principle that you can 
always produce a contradictory of any proposition by placing a ‘not’ on its front (with 
scope over the whole proposition). Th is is of special interest regarding how special 
signs are to be understood. Consider the proposition ‘not a man not is an animal.’ (1) One 
way to understand this proposition is that the special sign ‘a’ is to act locally; it is to be 
understood in the context of the sub-proposition ‘a man not is an animal,’ where it gives 
‘man’ merely confused supposition; putting a ‘not’ on the front of that sub-proposition 
would produce a larger proposition in which the negation would operate on an occur-
rence of ‘man’ having merely confused supposition, making ‘man’ have distributive 
supposition in the whole proposition. (2) Another way to understand this proposition 
is that the special sign ‘a’ is to be understood here globally, in the context of the whole 
proposition, ‘not a man not is an animal,’ where it gives ‘man’ merely confused suppo-
sition. Th e propositions that result from these two interpretations are not equivalent. 
It turns out that Major himself adopts the local interpretation. Th is allows him to 
maintain the view that putting a ‘not’ on the front of ‘a man not is an animal’ does 
indeed produce its contradictory. His examples are purported contradictories:
a man not is an animal
Not a man not is an animal
Th e algorithm from section 2 applied locally would turn these into:
Every animal a man isn’t
Not every animal a man isn’t
Th ese contain no special signs, and they are contradictories, as he says.

some examples from john major 
317
Major also says that the second proposition is equivalent to:
Every man is b animal.
Th e algorithm turns this into:
An animal every man is
and this proposition can be seen to be equivalent to ‘Not every animal a man isn’t’ by 
quantifi er equipollences, as desired.
He also discusses these purported contradictories:
Every man is b animal
Not every man is b animal
Th e algorithm, applied locally, turns these into:
An animal every man is
Not an animal every man is
Th ese are overt contradictories. He also says that ‘man’ in the second sentence is merely 
confused. Again, by quantifi er equipollences, that sentence is equivalent to ‘Every 
animal a man isn’t’ in which ‘man’ obviously has merely confused supposition. He 
also says that if the sign ‘b’ were removed from the second sentence, ‘man’ would be 
determinate. Th at proposition with ‘b’ removed is ‘Not every man is an animal’; by 
quantifi er equipollences, this becomes:
A man every animal isn’t
in which ‘man’ clearly has determinate supposition. 
Finally, at fol lxxxxvi “con-tingenter est homo  .  .  .” Major is considering a rule gov-
erning infi nitizing negation; the rule is that these are equivalent:
a is non-b
a is and a not is b
Th e equivalence does indeed hold when ‘a’ and ‘b’ are singular terms or common terms 
occurring alone (so that the construction is indefi nite). Major discusses lots of cases 
for which the equivalence fails to hold when the examples are not actually of the dis-
played form, though they have similar forms, and he discusses cases when there are 
quantifi er signs or modal signs present that interfere with the equivalence. An example 
of this that he gives is the failure of the equivalence:
a man is a non-animal
a man is and a man not is an animal
where the lower conjunction can be true without the upper proposition. He explains 
that the rule should not be said to hold when the subject is merely confused. Our 
algorithm would make the lower proposition equivalent to:

318 
appendix: artificial quantifiers in early 16th-century logic
a man is and every animal a man isn’t
which is actually true, and it would make the upper one equivalent to:
a man is a non-animal
which is false. (Here the sign ‘a’ is redundant because there is no universal term to its 
right.)
Not everything works this well, however. In one case Major states that the following 
pair of propositions are contradictories:
Of any man a donkey isn’t a donkey
Of some man any donkey is b donkey
Our algorithm would move the last term in the second sentence to the front:
A donkey of some man any donkey is
equivalently:
Of some man a donkey any donkey is
Th is is clearly not the contradictory of the fi rst sentence, since they could both be false. 
To make it a contradictory one would need to permute ‘a donkey’ with ‘any donkey.’ So 
perhaps the algorithm is wrong in this case. But maybe the problem does not lie with 
the algorithm, for the contradictory of the fi rst sentence is equivalent (by quantifi er 
equipollences) to:
Of some man every donkey is a donkey
And in this sentence the ‘donkey’ does not have determinate supposition, as its special 
sign would require. So it would seem that Major is wrong when he says that the second 
sentence contradicts the fi rst. Th e situation is not completely clear.
I have no more examples to give at this point. 20
A concluding caveat: Th ese signs were introduced late in the 15th century; they were 
being used at least a century and a half later. More writings need examination before 
we can be sure that we have the right picture. My tentative judgment must be to agree 
with Vives (APD),21 that the introduction of these special signs was not necessary. But 
perhaps other applications will show otherwise.
20 Th e algorithm also agrees with all of the analyses given on pp. 50–3 of Broadie’s GL, even including one 
interesting example that does not work as intended. Th is is the example ‘Of some man every ass is c white.’ 
Broadie gives an analysis of this sentence which (he says, correctly) is equivalent to “it is true of some man 
that there is some one white thing that all his asses are.” However, this analysis gives the term ‘white thing’ 
determinate, not merely confused, supposition. Th e algorithm gives the same analysis. 
I don’t think that there is any way to understand ‘Of some man every ass is c white’ that conforms to the 
intent of how the sign ‘c’ is to work. (Broadie does not attribute this example to any medieval source.) I sus-
pect that medieval logicians just avoided such examples, but that is a speculation.
21 Th ough I disagree strongly with Vives’s contemptuous attitude toward the use of these signs.

selected bibliography 
319
Selected Bibliography
Abelardus, Petru. 11th–12th century. Dialectica, ed. L. M. de Rijk. Assen: Van Gorcum & Co, 
1970.
Adams, Marilyn McCord. 1976. “What Does Ockham Mean by Supposition?,” Notre Dame 
Journal of Formal Logic 17: 375–91.
—— 1987. William Ockham. Notre Dame: University of Notre Dame Press.
Albert of Saxony. 14th century. Logica. Also known as Perutilis Logica. Edited in Harald Berger, 
Albert von Sachsen: Logik. With German translation. Hamburg: Felix Meiner Verlag, 2010. 
Portions are translated into English by Ernest Moody (unpublished), who cites Summa Logicae.
—— 14th century. Quaestiones circe logicam, in Fitzgerald 2002.
Alexander of Aphrodisias, 3rd century. Translated in Jonathan Barnes, Susanne Bobzien, Kevin 
Flannery, and Katrina Ierodiakonou (eds), Alexander of Aphrodisias: On Aristotle’s Prior 
Analytics 1.1-7. Ithaca, NY: Cornell University Press. 1991.
Al-Farabi. 10th century. Al-Farabi’s Short Commentary on Aristotle’s Prior Analytics, trans. 
Nicholas Rescher. Pittsburgh PA: University of Pittsburgh Press, 1963.
Ammonius. 6th century. On Aristotle’s Categories. Translated in Cohen and Matthews 1991.
—— 6th century. On Aristotle’s On Interpretation. Translated in Blank 1996.
Andrews, Peter. 2009. “Church’s Type Th eory,” Th e Stanford Encyclopedia of Philosophy, Edward 
N. Zalta (ed.), <http://plato.stanford.edu/archives/spr2009/entries/type-theory-church/>.
Andrews, Robert. 1993. “Resoluble, Exponible, and Offi  ciable Terms in the Sophistria of Petrus 
Olai, MS Uppsala C 599,” in Read (ed.) 1993, pp. 3–30.
Anonymi. 14th–15th century?. Disputata Magistri Maulfeldi Logicae. In Hülsen 1994, 393–417.
Anonymi. 14th–15th century?. Quaestio de supposition relativorum. In Hülsen 1994, 420–31.
Anonymous. 12th century?. About Supposition, a translation of a selection from Th e Logic begin-
ning: Ut dicit, pp. 375–411 of De Rijk 1967. Translation by Calvin Normore, assisted by Terence 
Parsons and Steve Barney.
Anonymous. 12th century?. About Terms, a translation of a selection from Th e Logic beginning: 
Cum sit nostra, pp. 413–51 of De Rijk 1967. Translation by Calvin Normore, assisted by 
Terence Parsons and Steve Barney.
Anonymous. 12th century?. About Univocation, a translation of a selection from Fallacie 
Parvipontane, pp. 545–609 of L.M. De Rijk, Logica Modernorum, volume I. Assen: Koninklijke 
Van Gorcum & Company N.V., 1962. Translation by Calvin Normore, assisted by Terence Parsons.
Anonymous. 12th century?. On Signifi cant Words, a translation of a selection from Th e 
Monacensis Dialectic, pp. 453–638 of De Rijk 1967. Translation by Calvin Normore, assisted 
by Terence Parsons and Steve Barney.
Anonymous. 12th century?. Treatise on Univocation, a translation of Tractatus de Univocatione 
Monacensis, pp. 333–51 of De Rijk 1967. Translation by Elizabeth Karger.
Anonymous. 13th century?. On the Properties of Discourse, a translation of Tractatus de 
Proprietatibus Sermonum, pp. 703–30 of De Rijk, 1967. Translation by Steve Barney, Wendy 
Lewis, Calvin Normore, and Terence Parsons.

320 
selected bibliography
Apuleius of Madaura. 2nd century. Peri Hermeneias. Translated in Londy and Johanson 
1987.
Aristotle. ≈340 BCE. Categories and De Interpretatione, trans. J.L. Ackrill. Oxford: Clarendon 
Press, 2002.
—— ≈340 BCE. Posterior Analytics, in Jonathan Barnes (ed.), Th e Complete works of Aristotle. 
Princeton: Princeton University Press, 1984.
—— ≈340 BCE. Prior Analytics, trans. Robin Smith. Indianapolis: Hackett, 1989.
Arnauld, Antoine and Pierre Nicole. 1662 La logique ou l’art de penser. Paris: Charles Savreux. 
Translated in Buroker 1996.
Ashworth, E.J. 1974a Language and Logic in the Post-Medieval Period. Dordrecht: D. Reidel.
—— 1974b. “‘For Riding is Required a Horse’ A Problem of Meaning and Reference in Late 
Fift eenth and Early Sixteenth Century Logic,” Vivarium 12: 146–72.
—— 1976. “‘I Promise You a Horse’: A Second Problem of Meaning and Reference in Late 
Fift eenth and Early Sixteenth Century Logic (I),” Vivarium XIV (1): 62–79.
—— 1978 “Multiple Quantifi cation and the Use of Special Quantifi ers in Early Sixteenth Century 
Logic,” Notre Dame Journal of Formal Logic XIX (4): 599–613.
—— manuscript. “Double Distribution and Conjoint Predicates.”
—— manuscript. “Ockham, Buridan, and their Followers on Suppositional Descent and Ascent.”
Augustine, Aurelius. 4th century. Concerning the Teacher and On the Immortality of the Soul, 
trans. George Leckie. New York: Appleton-Century-Croft s, 1938.
Averroes. 1998 Averroes Middle Commentaries on Aristotle’s Categories and de Interpretatione, 
trans. Charles E. Butterworth. Princeton: Princeton University Press.
Bacon, Roger. 13th century. Th e Art and Science of Logic. Translation of Summulae dialectics by 
Th omas S. Mahoney. Toronto: Pontifi cal Institute of Mediaeval Studies, 2009.
Barney, Steve, Wendy Lewis, Calvin Normore, and Terence Parsons (trans.). 1967. On the 
Properties of Discourse. Translation of the fi rst two-thirds of Tractatus de Proprietatibus 
Sermonum, in de Rijk 1967, pp. 703–30.
Berwart, Bernhard. 14th–15th century. Logica. In Hülsen 1994, 267–96.
Biard, J. 1988. “Le cheval de Buridan. Logique et philosophie du langage dans l’analyse d’un 
verbe intentionnel,” Die Philosophie im 14. und 15. Jahrhundert, ed. O. Pluta. Amsterdam: 
B.R. Grüner, pp. 119–37.
Blank, David (trans.). 1996. Ammonius: On Aristotle’s On Interpretation. Ithaca: Cornell 
University Press.
Bobzien, Susanne. 2006. “Ancient Logic,” Th e Stanford Encyclopedia of Philosophy, Edward N. 
Zalta (ed.), <http://plato.stanford.edu/entries/logic-ancient/>.
Boehner, Philotheus. 2012. Medieval Logic. San Bernardino CA: Forgotten Books Press, reprint 
of the 1952 edition from Manchester: Manchester University Press.
—— and Stephen Brown (eds and trans.). 1990. Ockham: Philosophical Writings. Indianapolis: 
Hackett.
Bos, Egbert P. 1983. Marsilius of Inghen: Treatises on the Properties of Terms. Dordrecht: Reidel.
Brands, Hartmut and Christoph Kann. 1995. William of Sherwood: Introductiones in Logicam: 
Einfürung in die Logik. Hamburg: Felix Meiner Verlag.
Broadie, Alexander. 1983. George Lokert. Edinburgh: Edinburgh University Press.
—— 1985. Th e Circle of John Mair. Oxford: Clarendon Press.
—— 2002. Introduction to Medieval Logic, 2nd edn. Oxford: Clarendon Press.

selected bibliography 
321
Brown, Sister Mary Anthony (ed.) 1961. Logica and Tractatus de Sensu Composito et Diviso. 
St. Bonaventure, NY: Th e Franciscan Institute, 1961.
Buridan, John. 14th century. Quaestiones in Analytica Priora Et Posteriora, ad suum com-
militonumque usum edidit Hubertus Hubien.
—— 14th century. Summulae de Dialectica. Translated in Klima 2001.
—— 14th century. Tractatus de Consequentiis, in Hubert Hubien, Iohannis Buridani tractatus de 
consequentiis: Édition critique, volume XVI of Philosophes médiévaux, Université de Louvain, 
1976. Translated in Read forthcoming.
Burley, Walter. 14th century. De Suppositionibus, in Stephen Brown (ed.), Walter Burleigh’s 
Treatise De Suppositionibus and its Infl uence on William of Ockham, Franciscan Studies 32, 
1972, pp. 15–64. First part translated in Spade 1997.
—— 14th century. Walter Burleigh: De puritate artis logicae tractatus longior, with a Revised 
Edition of the Tractatus brevior, ed. Philotheus Boehner. St. Bonaventure, NY: Th e Franciscan 
Institute, 1955. Translated in Spade 2000.
Buroker, Jill Vance (trans. and ed.). 1996. Logic or the Art of Th inking. Cambridge: Cambridge 
University Press. Translation of Arnauld and Nicole 1662.
Campsall, Richard. 14th century. Logica, portions in J. Reginald O’Donnell (ed.), Nine Mediaeval 
Th inkers. Toronto: Pontifi cal Institute of Mediaeval Studies, 1955.
Capella, Martianus. 5th century. Martianus Capella and the Seven Liberal Arts, trans. William 
Harris Stahl and Richard Johnson. New York: Columbia University Press, 1977.
Clarke, Arthur. 1986. Translation of Carl Friedrich Gauss, Disquisitiones Arithmeticae (1801). 
New York: Spinger-Verlag.
Cohen, S. Marc and Gareth B. Matthews. 1991. Ammonius On Aristotle’s Categories. Ithaca: 
Cornell University Press.
Conti, Alessandro. 1990. “Ontology in Walter Burley’s Late Commentary on the Ars Vetus,” 
Franciscan Studies 50: 121–76.
Copenhaver Brian with Calvin Normore and Terence Parsons. 2013. Peter of Spain: Summaries 
of Logic. Text, Translation, Introduction, and Notes. Oxford: Oxford University Press.
Corcoran, John and John Swiniarski. 1978. “Logical Structures of Ockham’s Th eory of 
Supposition,” Franciscan Studies 38: 161–83.
De Morgan, Augustus. 1847. Formal Logic: Th e Calculus of Inference, Necessary and Probable. 
Honolulu: University Press of the Pacifi c, 2003. Reprint of the 1847 edition.
—— 1966. On the Syllogism, and Other Logical Writings. London: Routledge and Kegan Paul.
De Rijk, L.M. 1962/1967. Logica Modernorum, volumes I (1962) and II (1967). Assen: Koninklijke 
Van Gorcum & Company N.V.
—— 1982. Some 14th Century Tracts on the Probationes Terminorum: Martin of Alnwick O.F.M., 
Richard Billingham, Edward Upton and Others. Nijmegen: Ingenium Publishers.
Dutilh Novaes, Catarina. 2007. Formalizing Medieval Logical Th eories: Suppositio, Consequentiae 
and Obligationes. Dordrecht: Springer.
—— 2008. “Logic in the 14th Century aft er Ockham,” in Gabbay and Woods (eds) 2008, 
pp. 433–504.
Evans, Gareth. 1977. “Pronouns, Quantifi ers and Relative Clauses (I),” Canadian Journal of 
Philosophy 8 (3): 467–536.
Fitzgerald, Michael J. 2002. Albert of Saxony’s Twenty-fi ve Disputed Questions on Logic. Leiden/
Boston/Köln: Brill.

322 
selected bibliography
Freddoso, Alfred J. 1980. “Ockham’s Th eory of Truth Conditions,” in William Ockham, Summa 
Logicae, Part II, trans. Alfred J. Freddoso and Henry Schuurman. Notre Dame: University of 
Notre Dame Press.
—— and Henry Schuurman (trans.). 1980. William Ockham, Summa Logicae, Part II. Notre 
Dame: Notre Dame Press.
Frege, Gottlob. 1879. Begriff sschrift . English translation in T.W. Bynum, Conceptual Notation and 
Related Articles. Oxford: Clarendon Press, 1972.
Fromkin, Victoria A. et al. 2000. Linguistics: An Introduction to Linguistic Th eory. Malden, MA 
and Oxford: Blackwell.
Gabbay, D. and J. Woods. 2008. Handbook of the History of Logic: Medieval and Renaissance Logic, 
volume 2. Amsterdam: Elsevier.
Gauss, Carl. 1801. Disquisitiones Arithmeticae. Translated in Clarke 1986.
Geach, Peter. 1956. “Th e Doctrine of Distribution,” Mind 65: 67–74.
—— 1962. Reference and Generality. Ithaca, NY: Cornell University Press.
—— 1972. “History of a Fallacy,” in Logic Matters. Oxford: Blackwell, pp. 1–13.
—— 1976. “Distribution and Suppositio,” Mind 85: 432–5.
Guerlac, Rita. 1979. Juan Luis Vives: Against the Pseudodialecticians. Dordrecht: D. Reidel.
Henninger, Mark G. 1989. Relations: Medieval Th eories 1250–1325. Oxford: Clarendon Press.
Henry, Desmond P. 1972. Medieval Logic and Metaphysics. London: Hutchinson.
Horn, Laurence. 2001. A Natural History of Negation. Stanford: CSLI Publications.
Hughes, G.E. 1982. John Buridan on Self-Reference. Cambridge: Cambridge University Press.
Hülsen, C. Reinhard. 1994. Zur Semantik Anaphorischer Pronomina: Untersuchungen scholastischer 
und moderner Th eorien. Leiden, New York, Köln: E.J. Brill.
—— 2000. “Understanding the semantics of ‘relative grammaticalia’: Some Medieval Logicians 
on Anaphoric Pronouns,” in K. von Heusinger and U. Egli (eds), Reference and Anaphoric 
Relations. Dordrecht: Kluwer, pp. 31–46.
Kann, Christoph and Raina Kirchoff . 2012. Syncategoremata: William of Sherwood. Hamburg: 
Meiner.
Karger, Elizabeth. 1984 “Modes of Personal Supposition: Th e Purpose and Usefulness of the 
Doctrine within Ockham’s Logic,” Franciscan Studies 44: 87–106.
—— 1993. “A Th eory of Immediate Inferences Contained in Buridan’s Logic,” in Klaus Jacobi 
(ed.), Argumentationstheorie: Scholastic Forschungen zu den logischen une semantischen 
Regeln korrekten Folgerns. Leiden-New York-Köln: E.J. Brill, pp. 407–29.
—— 1997. “Th e 15th and Early 16th Century Logicians on the Quantifi cation of Categorical 
Sentences,” Topoi 16 (1): 65–76.
—— 1999 “Treatise on Univocation.” A translation of pages 333–51 of de Rijk 1967. Unpublished.
Keenan, Edward. 1996. “Th e Semantics of Determiners,” in Shalom Lappin (ed.), Th e Handbook 
of Contemporary Semantic Th eory. Oxford: Blackwell, pp. 41–64.
Keynes, John Neville. 1906. Studies and Exercises in Formal Logic. London: Macmillan.
King, Peter. 1985. Jean Buridan’s Logic: Th e Treatise on Supposition, Th e Treatise on Consequences. 
Dordrecht: D. Reidel.
Klima, Gyula. 1988. Ars Artium: Essays in Philosophical Semantics, Mediaeval and Modern. 
Budapest: Hungarian Academy of Sciences.
—— 1993. “Debeo tibi equum: a Reconstruction of the Th eoretical Framework of Buridan’s 
Treatment of the Sophisma,” in Read (ed.) 1993, pp. 333–47.

selected bibliography 
323
—— (trans. and ed. with introduction) 2001. John Buridan: Summulae de Dialectica. New Haven 
and London: Yale University Press.
—— 2011. “Two Summulae, Two Ways of Doing Logic: Peter of Spain’s ‘Realism’ and John Buridan’s 
‘Nominalism’,” in Margaret Cameron and John Marenbon (eds), Methods and Methodologies: 
Aristotelian Logic East and West, 500–1500. Leiden and Boston: Brill, pp. 109–26.
Kneale, William and Martha Kneale. 1962. Th e Development of Logic. Oxford: Clarendon Press.
Kneepkens, C.H. 1993. “Orléans 266 and the Sophismata Collection: Master Joscelin of Soissons 
and the infi nite words in the early twelft h century,” in Read (ed.) 1993, pp. 64–85.
Knuuttila, Simo. 1982. “Modal Logic”, in Kretzmann, Kenny, and Pinborg (eds) 1982, pp. 342–57.
—— 2008. “Medieval Modal Th eories and Modal Logic”, in Gabbay and Woods (eds), 2008, 
pp. 505–78.
Kretzmann, Norman. 1966. William of Sherwood’s Introduction to Logic. Minneapolis: University 
of Minnesota Press.
—— 1968. William of Sherwood’s Treatise on Syncategorematic Words. Minneapolis: University of 
Minnesota Press.
—— 1979. Pauli Veneti: Logica Magna: Prima Pars: Tractatus de Terminis. Oxford: Oxford 
University Press. Contains a translation of the “Tractatus on Terms” from the Great Logic, 
by Paul of Venice.
——  1982. “Syncategoremata, exponibilia, sophismata”, in Kretzmann, Kenny, and Pinborg (eds) 
1982, pp. 211–45.
—— and Barbara Ensign Kretzmann. 1990. Th e Sophismata of Richard Kilvington. New York: 
Oxford University Press.
—— Anthony Kenny, and Jan Pinborg (eds). 1982. Th e Cambridge History of Later Medieval 
Philosophy. Cambridge: Cambridge University Press.
—— and Eleonore Stump. 1988. Th e Cambridge Translations of Medieval Philosophical Texts, 
volume 1. Cambridge: Cambridge University Press.
Kym, Hugo. 14th–15th century. De suppositionibus terminorum relativorum. In Hülsen 1994, 
297–335.
Lagerlund, Henrik. 2012. Essentials of Medieval Philosophy: Philosophy Between 500 to 1500. 
Dordrecht: Springer Briefs in Philosophy.
Lambert of Lagny (“of Auxerre”). 14th century. Properties of Terms. Logica (Summa Lamberti), 
ed. Franco Alessio; VIII: De suppositionibus et de signifi cationibus. Florence: Le Nuova Italia, 
1971, pp. 205–45. Translated in Kretzmann and Stump 1988.
Londy, David and Johanson, Carmen. Philosophia Antiqua: Th e Logic of Apuleius. Leiden: 
E. J. Brill, 1987.
Loux, Michael J. 1974. Ockham’s Th eory of Terms: Part I of the Summa Logicae. Notre Dame: 
University of Notre Dame Press.
Major, John. 1506. Inclitarum artium ac sacre pagine doctori acutissimi magistri Johannis Majoris 
Scoti. Libri quos in artibus in collegio Montis acuti Parisius regentando compilavit Venundantur 
vero a Dyonisio Roce. Paris.
Malink, Marko. 2013. Aristotle’s Modal Syllogistic. Cambridge, MA: Harvard University Press.
Marenbon, John. 1987. Later Medieval Philosophy (1150–1350): An Introduction. London: 
Routledge and Kegan Paul.
Markosian, Ned. 1988. “On Ockham’s Supposition Th eory and Karger’s Rule of Inference,” 
Franciscan Studies 10: 40–52.

324 
selected bibliography
Marsilius of Inghen. 14th century. Marsilius of Inghen: Treatises on the Properties of Terms trans. 
E.P. Bos. Dordrecht: Reidel, 1983.
Martin, Christopher. 1992. “Obligations and liars,” in Read (ed.) 1993, pp. 357–81.
—— 2001. “Obligations and liars,” in Yrjönsuuri (ed.) 2001, pp. 63–94. (Revised version of Martin 
1992.)
Mates, Benson. 1961. Stoic Logic. Berkeley and Los Angeles: University of California Press.
—— 1972. Elementary Logic. New York: Oxford University Press.
Matthews, Gareth B. 1964. “Ockham’s Supposition Th eory and Modern Logic,” Philosophical 
Review 73: 91–9.
—— 1973. “Suppositio and Quantifi cation in Ockham,” Nous 7: 13–24.
—— 1984. “A Note on Ockham’s Th eory of the Modes of Common Personal Supposition,” 
Franciscan Studies 44: 81–6.
—— 1997. “Two Th eories of Supposition?,” Topoi 16 (1): 35–40.
Meistermann, Ludolf. 14th century. Questiones de supposition relativorum. In Hülsen 1994, 
337–91.
Moody, Ernest. 1955. Th e Logic of William of Ockham. New York: Russell and Russell, reissued 
1965.
—— 1975. Studies in Medieval Philosophy, Science, and Logic. Berkeley, Los Angeles, London: 
University of California Press.
Mullally, Joseph P. 1945. Th e Summae Logicales of Peter of Spain. Notre Dame: Th e University of 
Notre Dame. Contains a translation of the tract on supposition.
Normore, Calvin. 1982. “Future Contingents,” in Kretzmann, Kenny, and Pinborg (eds) 1982, 
pp. 358–81.
—— 1997. “Material supposition and the mental language of Ockham’s Summa Logicae,” Topoi 
16: 27–33.
—— 1999. “Some aspects of Ockham’s logic,” in P.V. Spade (ed.) 1999, pp. 31–52.
—— with T. Parsons. Forthcoming. “Billingham and Buridan on the Foundations of Syllogistic 
Reasoning,” Proceedings of the 1st GPMR Workshop in Logic and Semantics.
Ockham, William. 14th century. Summa Logicae. Allegany, NY: Saint Bonaventure Press, 1974.
—— 14th century. Ockham’s Th eory of Terms: Part I of the Summa Logicae, trans. Michael J. Loux. 
Notre Dame: University of Notre Dame Press, 1974.
—— 14th century. Allegany, NY: Saint Bonaventure Press, 1974, trans. Alfred J. Freddoso and 
Henry Schuurman. Notre Dame: University of Notre Dame Press, 1980.
Panaccio, Claude. 2004. Ockham on Concepts. Burlington, VT: Ashgate.
Parsons, Terence. 2000–2010. A Primer in the Semantics of English, <http://www.philosophy.
ucla.edu/people/95-terence.html>.
—— 2006. “Th e Doctrine of Distribution,” Journal of History and Philosophy of Logic 27 (1): 
59–74.
—— 2008a. “Supposition Th eory in the Later 12th through 14th Centuries,” in Gabbay and 
Woods (eds) 2008, pp. 157–280.
—— 2008b. “Th ings Th at are Right with the Traditional Square of Opposition,” Logica Universalis 
2 (1): 3–11.
—— 2008c. “Comments on Stephen Read’s ‘Th e Truth-schema and the Liar’,” in S. Rahman, 
T. Tulenheimo, and E. Genot (eds), Truth, Unity and the Liar. Th e Relevance of Medieval 
Solutions to Semantic Paradoxes. Dordrecht: Springer, pp. 129–34.

selected bibliography 
325
—— forthcoming. “Th e Logic behind the Metaphysics,” in Rondo Keele and Charles Bolyard 
(eds), Essays in Later Mediaeval Metaphysics. New York: Fordham University Press.
—— with Calvin Normore. Forthcoming. “Billingham and Buridan on the Foundations of 
Syllogistic Reasoning,” Proceedings of the 1st GPMR Workshop in Logic and Semantics.
Pasnau, Robert. 2002. Th e Cambridge Translations of Medieval Philosophical Texts: Volume 3, 
Mind and Knowledge. Cambridge: Cambridge University Press.
Paul of Pergula. 15th century. Logica, in Brown 1961.
Paul of Venice. 14th–15th century. Logica Magna. Translations of some parts are in Kretzmann 
1979 and Perriah 1971.
—— 14th–15th century. Logica Parva. Venice, 1472. Reprinted by Georg Olms Verlag, 
Hildesheim/New York, 1970. Translated in Perreiah 1984.
Perreiah, Alan. 1971. Logica Magna: Tractatus de Suppositionibus. St. Bonaventure, NY: 
Franciscan Institute.
—— 1984. Logica Parva: Translation of the 1472 Edition. München: Philosophia Verlag. 
Translation of Paul of Venice’s Short Logic.
Peter of Spain. 13th century. Syncategoreumata, ed. by L.M. De Rijk and translated by Joke Spruyt. 
Leiden, New York: Köln: E.J. Brill, 1992.
—— 13th century. Th e Summule Logicales of Peter of Spain. English translation in Mullally 1945. 
Superseded by below.
—— 13th century. Tractatus (or Summulae Logicales), ed. L.M. De Rijk. Assen: Van Gorcum & 
Co, 1972.
—— 13th century. Tractatus (or Summule Logicales). Translated in Copenhaver 2013.
Poinsot, John. 17th century. John of St. Th omas: Outlines of Formal Logic, trans. Francis C. Wade. 
Milwaukee: Marquette University Press, 1955.
Price, Robert. 1970. “William of Ockham and Suppositio Personalis,” Franciscan Studies 30: 
131–40.
Priest, Graham and Stephen Read. 1977. “Th e Formalization of Ockham’s Th eory of Supposition,” 
Mind 86: 109–13.
—— 1980. “Merely Confused Supposition: A Th eoretical Advance or a Mere Confusion?,” 
Franciscan Studies 40: 265–97.
Read, Stephen. 1985. “‘I promise a penny that I do not promise’: Th e Realist/Nominalist Debate 
over Intensional Propositions in Fourteenth-Century British Logic and its Contemporary 
Relevance”, in P. Osmund Lewry (ed.), Th e Rise of British Logic. O.P. Papers in Mediaeval 
Studies 7. Toronto: Pontifi cal Institute of Mediaeval Studies, 1985, pp. 335–59.
—— 1991. “Th omas Cleves and Collective Supposition,” Vivarium 29: 50–84.
—— forthcoming. John Buridan: Treatise on Consequences. New York: Fordham University Press.
—— (ed.). 1993. Sophisms in Medieval Logic and Grammar. Dordrecht: Kluwer.
Sanderson, John. 1589. Institutionum dialecticarum libri quatuor. Antwerpiae: Ex offi  cina 
Christophori Plantini.
Sanderson, Robert. 1664. Logicae artis compendium. Oxoniae: Ric. & Nic. Dais.
Scott, Th eodore K. 1966. John Buridan: Sophisms on Meaning and Truth. New York: 
Appleton-Century-Croft s.
Seton, John. 1574 (fi rst published 1545). Dialectica Londini: Th omam Marsh.
Sherwood, William. 13th century. Introductiones in logicam, ed. Martin Grabman. Sitzungsberichte 
der Bayersichen Akademie der Wissenschaft en, Philosophisch-historische Abteilung, Jahrgang 

326 
selected bibliography
1937, H. 10. Munich, 1937. Translated in Kretzmann 1966; reedited and translated into 
German in Brands and Kahn 1995.
—— 13th century. Syncategoremata, ed. J.R. O’Donnell. Mediaeval Studies 3: 46–93. Toronto: 
Pontifi cal Institute of Mediaeval Studies, 1941. Translated in Kretzmann 1968; reedited and 
translated into German in Kann and Kirchoff  2012.
Simmons, Keith. 1993. Universality and the Liar: An Essay on Truth and the Diagonal Argument. 
Cambridge: Cambridge University Press.
Smith, Robin. 1982. “What is Aristotelian Ecthesis?,” History and Philosophy of Logic 3: 113–27.
—— 1983. “Completeness of an Ecthetic Syllogistic,” Notre Dame Journal of Formal Logic 
24 (2): 224–32.
—— 2011. “Aristotle’s Logic,” Th e Stanford Encyclopedia of Philosophy, Edward N. Zalta (ed.), 
<http://plato.stanford.edu/entries/aristotle-logic/>.
Spade, Paul Vincent. 1974. “Five Logical Tracts by Richard Lavenham,” in J.R. O’Donnell (ed.), 
Essays in Honor of Anton Charles Pegis. Toronto: Pontifi cal Institute of Mediaeval Studies, 
pp. 70–124.
—— 1976. “Priority of Analysis and the Predicates of ‘O’-Form Sentences,” Franciscan Studies 
36: 263–70.
—— 1982a. “Insolubilia,” in Kretzmann, Kenny, and Pinborg (eds) 1982, pp. 246–53.
—— 1982b. “Obligations: Developments in the fourteenth century,” in Kretzmann, Kenny, and 
Pinborg (eds) 1982, pp. 335–41.
—— 1988a. “Th e logic of the categorical: the medieval theory of descent and ascent,” in 
N. Kretzmann (ed.), Meaning and Inference in Medieval Philosophy. Dordrecht: Kluwer 
Academic Publishers, pp. 187–224.
—— 1988b. Lies, Language and Logic in the Late Middle Ages. London: Variorum Reprints.
—— 1994. Five Texts on the Mediaeval Problem of Universals. Indianapolis: Hackett.
—— 1996. Th oughts, Words and Th ings, <www.pvspade.com>.
—— 1997. Translation of the beginning of Walter Burley’s Treatise on the Kinds of Supposition 
(De Suppositionibus), from Stephen Brown, “Walter Burleigh’s Treatise De Suppositionibus and 
Its Infl uence on William of Ockham,” Franciscan Studies 32 (1972): 15–64.
—— (ed.). 1999. Th e Cambridge Companion to Ockham. Cambridge: Cambridge University Press.
—— (trans.) 2000. Walter Burley’s On the Purity of the Art of Logic. New Haven: Yale University 
Press.
Stump, Eleonore. 1982a. “Topics: their development and absorption into consequences,” in 
Kretzmann, Kenny, and Pinborg (eds) 1982, pp. 273–99.
—— 1982b. “Obligations: From the beginning to the early fourteenth century,” in Kretzmann, 
Kenny, and Pinborg (eds) 1982, pp. 315–34.
Swiniarski, John J. 1970. “A New Presentation of Ockham’s Th eory of Supposition with an 
Evaluation of Some Contemporary Criticisms,” Franciscan Studies N.S. XXX: 181–217.
Th om, Paul. 1976. “Ecthesis,” Logique et Analyse 19: 299–310.
—— 1981. Th e Syllogism. Munich: Philosophia.
—— 1996. Th e Logic of Essentialism: An Interpretation of Aristotle’s Modal Syllogistic. Dordrecht: 
Kluwer.
—— 2003. Medieval Modal Systems: Problems and Concepts. Burlington VT: Ashgate.
—— 2007. Logic and Ontology in the Syllogistic of Robert Kilwardby. Leiden, Boston: Brill.
—— 2012. Th e Logic of the Trinity: Augustine to Ockham. New York: Fordham University Press.

selected bibliography 
327
Uckelman, Sara L. 2009. Modalities in Medieval Logic. Amsterdam: Institute for Logic, Language 
and Computation, University of Amsterdam.
Van Benthem, Johan. 2008. “A Brief History of Natural Logic,” in M. Chakraborty, B. Löwe, 
M. Nath Mitra, and S. Sarukkai (eds), Logic, Navya-Nyāya & Applications, Homage to Bimal 
Krishna Matilal. London: College Publications, pp. 21–42.
Vives, Juan Luis. 16th century. Adversus pseudodialecticos. Translated in Guerlac 1979.
Weidemann, Hermann. 1979. “William of Ockham on Particular Negative Propositions,” Mind 
88: 270–5.
Westerstahl, Dag. 2012. “Classical vs. modern Squares of Opposition, and beyond,” in Jean-Yves 
Beziau and Gillman Payette (eds), Th e Square of Opposition: A General Framework for 
Cognition. Bern: Peter Lang, pp. 195–229.
Whately, Richard. 1975. Elements of Logic. Delmar, NY: Scholar’s Facsimiles & Reprints. Reprint 
of the 1827 edition.
Whitaker, C.W.A. 1996. Aristotle’s De Interpretatione: Contradiction and Dialectic. Oxford: 
Clarendon Press.
Wodeham, Adam. 2002. “Th e Objects of Knowledge.” Translated in Pasnau 2002.
Wyclif, John. 14th century. Tractatus de Logica, ed. Michael Henry Dziewicki. Frankfurt: 
Minerva. Vol. 1: 1893; vol. 2: 1896; vol. 3: 1899.
Yrjönsuuri, Mikko. 2008. “Treatments of the Paradoxes of Self-Reference”, in Gabbay and Woods 
(eds) 2008, pp. 579–608.
Yrjönsuuri, Mikko. (ed.). 2001. Medieval Formal Logic: Obligations, Insolubles and Consequences. 
Dordrecht: Kluwer.

328 
index
Index
Abelard 4, 13
Adams, Marilyn 201
addition 272–5
adjective 7, 73, 127, 123, 296, 300
 attributive 134, 139
 substantivated 123–5, 127, 133, 289
Albert of Saxony 5, 73, 74, 96, 127, 199, 231
Alexander of Aphrodisias 27, 42
Ammonius 9
ampliation 74, 97, 164, 260, 276–304
anaphora 227–58, 260–75
Andrews, Robert 129, 141
Anonymous 63, 74, 76, 97, 144, 154, 228, 242, 
247, 276, 278, 280, 300, 303, 304 
appellation 144, 276, 287–8, 298, 302–5
Aquinas 5
Aristotle 1, 2, 5, 6–55, 56, 61–2, 64, 65, 72, 98, 
109, 110, 123, 125, 147, 155, 161, 203, 204, 
259, 260, 276, 290, 296, 297, 304
arithmetic:
 fi rst-order 269–75
Arnauld 15
artifi cial quantifi er 306–18
artifi cial sign, see artifi cial quantifi er
ascent 186, 187, 188, 190, 191, 192, 195, 
196, 197, 199, 209, 210, 226, 230, 312, 
313, 315
Ashworth, E. J. 97, 195, 218, 305, 306, 307, 308
assignment 99–108, 111, 142, 148, 235
Bacon, Roger 5, 14, 56, 76, 96
Barbara 16, 19, 30, 31, 33, 39, 40, 43, 48, 49, 50, 
51, 203, 290, 293, 294
Barocho 16, 17, 32, 33, 34, 51
being 65, 128
Berwart, Bernhard 242, 243
Billingham, Richard 45, 99
binding 87, 130–1, 136, 143, 167–8, 182, 198, 
235, 265, 270–1, 289–90
bivalance 9
Bobzien, Susanne 155
Bocardo 16, 34, 36, 37, 39, 51, 53
Boehner, Philotheus 5
Boethius, Anacius Manlius Severinus 6, 13, 92, 
155, 276
Broadie, Alexander 5, 243, 306–14, 318
Buridan, John 1, 5, 14, 27, 57, 61, 67, 69, 74–6, 92, 
95–7, 110, 123–4, 126–7, 129, 134, 140, 142, 
144, 146, 156, 164–77, 180, 182, 186–8, 191, 
194–6, 198–99, 201, 202–3, 211–12, 217, 
227, 231–2, 239, 252–3, 257–8, 278–9, 
281–5, 286–8, 295–7, 298, 300–2, 304–5
Burley, Walter 5, 73, 96, 97, 156, 186–8, 228–32, 
239–41, 249, 254–6, 281, 303
Campsall, Richard 244
Celarent 16, 30, 33, 39, 40, 43, 48, 50, 51, 203
Cesare 16, 32, 39, 51, 53
chimera 42, 50, 74, 75, 92, 175, 192, 193, 253, 
278–9, 288, 299, 300
common noun:
 non-relational 148
 relational 147, 197
completeness 77, 87, 98, 113–22, 143, 154
concept 3, 96, 97, 165, 184, 244, 286–9, 298, 
304–5
conditional, as of now 156–7 
conditional, ut nunc 156–7 
conjunction 2, 83, 135, 141, 156, 158, 187, 188, 
189, 190, 192, 198, 199, 209, 210, 221, 222, 
241, 243, 244, 245, 246, 248, 252, 256, 257, 
270, 306, 312, 313, 314, 317
 augmented 190, 219
consequence 5
contradiction 2, 9, 10, 11, 12, 13, 18, 22, 23, 26, 
41, 42, 53, 54, 64, 65, 78, 90, 92, 121, 122, 165, 
173, 175, 256, 276, 291, 310, 311, 315, 
316–18
contrary 10–12, 22–3, 27–9, 31, 53, 54, 64, 78, 90, 
116, 121, 144, 167, 227, 239, 310, 311
conversion 1, 2, 14, 21, 25–35, 39, 41–2, 49, 50, 
51–3, 54, 60, 65, 67–8, 72, 74, 123–4, 133, 
155, 164, 174, 217, 290–1, 297, 308
 by contraposition 14, 74
 per accidens 14, 27, 28, 29, 34, 35, 54–5, 65, 67, 
308
Copenhaver, Brian 5
copula 7, 19–20, 57, 59, 65, 77, 81, 88, 93–4, 
110, 125–9, 132, 140, 161, 164–7, 168–9, 
170, 173–6, 177, 261, 264, 279, 289, 290, 
295–7, 298
 symmetry of 93–4
Darapti 16, 17, 27, 34, 36, 51, 67
Darii 16, 30, 34, 39, 40, 43, 49, 50, 51, 204
Datisi 16, 34, 39, 51
de Morgan, Augustus 157, 160–2
de Rijk, L. M. 45, 60, 74, 76, 99, 276

index 
329
denoting phrase 43, 57–9, 65, 82–4, 87–9, and 
throughout
descent 186–201, 209–10, 218, 221, 226, 230–1, 
244–5, 303, 311–15
 restricted 197
determiner 43–50, 206
 monotonic 45–50, 206
dictum de omni et nullo 30, 160, 203
dictum of all and none, see dictum de omni et nullo
‘diff er’ 256
direct object 67, 81–6, 129–30, 135–9, 166, 
179–81, 219, 263
disjunction 155–6, 186–93, 199, 209, 218–19, 
222, 243, 280–1, 291, 303, 305, 311–14
donkey anaphora 254
Dorp, John 201, 217
dot, indicating indefi nite article 57, 59
Dutilh Novaes, Catarina 5, 19, 184, 196, 201, 217
equipollence 60–70, 74–8, 90–3, 113–14, 133, 
137, 152, 161, 175, 196, 200, 201, 231, 236, 
255, 260, 291, 309, 315–18
equivocation 147, 276
existential import 1, 9, 12–13, 17, 37, 40–1, 49, 
74, 98, 105, 109, 110, 259, 262–4, 268
exponible 45, 256
exposition 2, 23–4, 27, 29, 34–7, 41–2, 53, 54, 
65, 66, 79, 95, 123, 161, 231, 248, 252, 259, 
260, 292, 303
expository syllogism 24, 29, 41, 50, 54, 66, 79, 
292, 293
fallacies 5
Ferio 16, 30, 39, 40, 42, 43, 49, 51
fi gure 1, 15–17, 30–34, 38–42, 49, 51–2, 61, 70, 
146, 155, 203, 204, 252, 260, 290
form:
 grammatical 3, 81–9, 246–7, 265–7, 301
 logical 8, 18–20, 57–9, 65–71, 83–9, 95, 98, 
124, 125, 128, 132, 139, 145, 149, 151, 153, 
155, 159, 162, 163, 169, 178, 181, 183, 222, 
238, 245, 249, 251, 252, 254, 258, 266, 269, 
271, 279, 290, 296
Frege, Gottlob 164, 259, 304, 306
Fromkin, Victoria 82
Geach, Peter 254–5
generalized quantifi er 43, 47
genitive 145–53, 166, 167, 177, 179–82, 197, 219, 
229, 270, 272, 313–15
 of possession, 147
global quantifi cational import 223–6
grammatical marker 82–7, 89, 117, 129, 131, 
143, 147, 150
Henkin modeling theorem 114
Henkin, Leon 114
Horn, Lawrence 48
Hülsen, Reinhard 4
identity
 self- 72, 94
 substitutivity of 70–1, 93, 237, 273
 transitivity of 2, 69, 94
indefi nite 7, 8, 18, 27, 56, 57, 59, 61, 62, 67, 72, 84, 
89, 92, 153, 164, 170, 171, 172, 177, 178, 206, 
240, 309, 312, 317
induction 214, 216
inference:
 algorithm 217
 from a superior to an inferior 202–6
 from an inferior to a superior 204, 226
 useful 202, 207, 214
insoluble 5
interpretation 110–22, 143, 154, 199, 261, 281
Karger, Elizabeth 145, 167, 180–2, 201, 217
Keenan, Edward 43
Kilwardby, Robert 63
Klima 5
Klima, Gyula 5, 105, 305
Kneale and Kneale 13
Knuuttila, Simo 5
Kretzmann, Norman 5, 96, 156, 177–9, 208
Kym, Hugo 242–3
Lagerlund, Henrik 5
Lambert of Lagny 5, 96–7, 230, 247, 298
language, natural 1, 3, 43, 45, 47–8, 59, 83, 86, 
125, 127, 134–5, 143, 148, 150, 158, 168, 
246, 255–6, 259, 265–6, 268–9, 271–4, 281, 
285, 306
Lavenham, Richard 245
Leibniz’s Law 51, 70
Lokert, George 307, 310–11
Major, John 311–18
Malink, Marko 12, 27
Marenbon, John 5
marker, grammatical 67, 81, 82, 84, 87, 129, 148, 
158, 221, 261, 263, 265, 285
Marsilius of Inghen 5, 96–7, 154, 184, 231, 240, 
244, 256, 283, 297, 300
Martianus Capella 155
Mates, Benson 24, 155
Matthews, Gareth 210, 218
Maulfelt, Th omas 201
modality 5, 8, 30, 73, 97, 123, 125, 156, 164, 260, 
277–9, 295–8, 302, 317
monotonicity 45–50, 205
mood 15–17, 21, 30, 31, 33, 34, 38–41, 49, 51–3, 
203, 257, 290
 direct 15
multiplication 275

330 
index
name, temporary 99–100, 104–5, 108, 
112–13
negation 7, 9, 14, 18, 57, 59, 62–4, 68, 72–81, 
90, 102, 112, 115–19, 138, 161, 173, 175, 
182, 194, 195, 201, 212, 216, 220, 223, 247, 
256, 264, 268, 291, 294, 300, 309, 312, 
316–17
 double 58, 63, 73
 indefi nite, see negation infi nitizing
 infi nitizing 18, 72–4, 173, 175–6, 182, 264, 
268, 294, 300, 317
Nicole 15
nominalist 5
Normore, Calvin 5
obligation 5
obversion 60, 75, 76
Ockham, William 5, 56, 61, 67, 92, 95–7, 147, 
156, 186–8, 192, 194–6, 199, 201, 202, 204, 
209–12, 227, 230, 232, 233, 238–40, 280, 
286, 291, 295, 298, 303, 304
‘only’ 45
participle 126–39, 143, 146, 148, 152, 165–7, 
169, 170, 176–7, 179–81, 219, 221, 260, 264, 
271, 278, 281, 289
Paul of Venice 4, 5, 29, 60, 96, 97, 127, 156, 177, 
179, 182, 191, 194, 199, 202, 204, 210, 281, 
282, 284
Peano’s postulates 269
permutation 68, 70, 71, 79, 254, 292, 293, 294
pertaining to the soul 280, 299, 304
Peter of Spain 5, 8, 9, 11, 14, 16, 51, 64, 67, 68, 73, 
96, 97, 156, 185, 228, 239, 295
Poinsot, John 5, 196, 201, 230, 231
possession, see genitive
predicate 2, 7–9, 14–15, 23, 30, 40, 56, 62–3, 65, 
67, 69, 72, 74–6, 83, 99, 123, 124, 127, 140, 
162, 164–79, 182, 185, 188, 189, 190, 193, 
194, 195, 197, 199, 201, 232, 240, 247, 259, 
260, 261, 262, 264, 267, 269, 271, 277, 279, 
280, 281, 282, 285, 287, 288, 289, 290, 291, 
295, 296, 297, 298, 300, 305, 311, 312
 quantifi ed 56
predicate calculus 4, 63, 260, 261, 264, 271
Priest, Graham 210, 218, 220
pronoun 3, 8, 154, 180, 216, 227–58, 267, 282, 
284–5, 300–1
 refl exive 3, 228, 229–45
 relative 141, 142, 283, 302
proposition 6
 affi  rmative 7–17, 25, 28, 35, 37, 41, 47, 49, 50, 
52, 54, 61, 63, 65–7, 69, 72–8, 91–3, 98, 109, 
110, 124, 149, 156, 157, 165, 175, 176, 185, 
189, 191, 194, 201, 204, 211, 212, 215, 216, 
223, 237, 243, 244, 248, 249, 252, 254, 262, 
263, 264, 277, 279, 283, 299
 categorical 7–9, 15, 56, 58, 59, 72, 110, 127, 
164–70, 176, 194, 224, 226, 229, 231, 234, 
240, 245, 246, 277
 conditional 156
  ut nunc 156, 157
 hypothetical 156
 indefi nite 7, 57–9
 mental 165, 286, 295
 molecular 155–9, 220
 negative 7–17, 23, 25–30, 36, 37, 41, 49, 50, 52, 
61, 63, 67, 69, 72–7, 92, 98, 108–10, 123, 157, 
165, 175, 176, 178, 185, 187, 189, 194, 206, 
212, 243, 247, 248, 249, 262, 264, 279, 294, 
300, 301
 particular 7–17, 23–5, 29, 35–7, 39, 41, 42, 49, 
52, 56, 61, 62, 64, 67, 68, 72, 74, 75, 95, 96, 
108, 124, 160, 164, 170, 185, 186, 189, 194, 
211, 279, 312
 universal 7–17, 23–9, 35, 37, 38, 39, 41, 42, 49, 
50, 52, 54, 55, 56, 61, 64, 67, 68, 72, 74, 124, 
140, 149, 161, 164, 170, 171, 176, 177, 179, 
185, 189, 191, 194, 195, 201, 204, 208, 210, 
212, 223, 224, 225, 239, 244, 252, 264, 265, 
272, 279, 303, 308, 309, 312, 318
quality 8
quantifi cation, analysis of 218
quantifi er, generalized 43
quantity 8, 164
Read, Stephen 5, 196, 201, 209, 210, 218, 220, 305
realist 5
reductio 22, 26–33, 42, 53, 54, 64, 71, 78, 90, 92, 
122, 250, 274, 291, 293
reduction by impossibility 52
relational expression 161
relative 227
 antecedent of 3, 14, 83, 156, 198, 206, 216, 
220, 223, 227–57, 265, 267, 272, 273, 283, 
301, 302
 non-refl exive 239
 of diversity 256
relative clause 140–4, 170, 174, 180, 181, 221, 
256, 282, 283, 284, 291, 302
 restrictive 140
replacement principle 228, 232
restriction 74, 97, 154, 243, 247, 276–83, 288, 
290, 291, 294, 300, 302
scope 3, 12, 44, 63, 86, 108, 109, 144, 176, 179, 
182, 194, 201, 208, 211, 212, 214, 216, 220, 
221, 223, 225, 232, 233, 234, 238, 239, 245, 
246, 248, 254, 255, 256, 260, 263, 269, 270, 
271, 285, 308, 312, 316
Sherwood, William 5, 56, 60–4, 68, 73, 74, 96, 97, 
140, 156, 178, 179, 182, 200, 201, 207, 208, 
214, 215, 216, 218, 230, 280

index 
331
signifi cation 73, 95, 96, 97, 125, 276, 277, 286, 
288, 298
Simmons, Keith 5
Smith, Robin 13, 23, 27
sophism 5
Sortes 85
Spade, Paul Vincent 5, 188, 209, 210, 218, 245
square of opposition 10, 12, 210
Stoic 2, 155, 156
Stump, Eleonore 5, 96, 156
subalternation 11, 12, 23, 29, 54, 55, 65, 92, 93, 
95, 208, 217, 237
subcontrary 11, 178
subject 6–9, 12, 14, 15, 17, 23, 30, 37, 40–2, 
44, 50, 56, 61, 65–7, 72, 74–6, 81–6, 92, 
94, 96, 97, 108, 109, 123, 124, 127, 140, 
164, 165–81, 184, 189–94, 196, 197, 202, 
203, 220, 240, 247, 255, 260, 263, 267, 
272, 277–83, 285, 287–91, 295–302, 
317
supposition 63, 96–7, 154, 176–9, 
184–245, 256, 260, 276–88, 294, 
296, 300–18
 determinate 176, 184, 186, 209, 210, 
225, 312
 distributive 176, 184, 187, 209, 210, 211, 
225, 312
 material 3, 184, 277
 merely confused 176, 184, 185, 188, 199, 209, 
210, 225, 312
 mode of 4, 177, 184, 190, 193, 196, 197, 199, 
202, 206, 208–17, 225, 226, 229, 231, 245, 
308, 312, 315
  cause of 193, 225
 narrow distributive 210
 personal 3, 184, 185, 186, 199, 204, 223, 228, 
239, 277, 303
 simple 3, 184, 185, 228, 277, 303, 304
 singled 3, 229, 244
 wide distributive 209, 210
Swiniarski, John 218
syllogism 1, 2, 15– 21, 24, 27, 30–4, 39, 41, 42, 
52–5, 66, 69, 70, 99, 155, 160, 164, 198, 
202–5, 231, 252, 253, 257, 258, 260, 290, 291, 
297, 300
 expository 2, 27
 fi gure 2
 perfect 30–1
 reduction of 30, 31, 39
syncategoremata 5
tense 164, 280–94
 coordination of times 281, 285
term:
 complex 73, 134–40, 141, 143, 152–3, 162–3, 
165, 175, 176–83, 192, 203, 221, 240, 260, 
270, 282, 284, 314
 demonstrative 7, 8, 153, 154, 189
 determinable 172, 180–2, 219, 314
 embellished 288–91, 294, 298
 empty 12, 13, 17, 37, 41, 42, 44, 47, 50, 63, 65, 
66, 72, 74–80, 91–5, 104, 108, 109, 114–21, 
129, 131, 138, 149, 163, 191–3, 206, 216, 219, 
235–7, 248, 260, 262–4, 266, 270, 273, 277, 
279, 291, 292, 300
 parasitic 130, 133, 134, 137, 146, 160, 177, 182, 
197, 198, 199, 204, 206, 212, 213, 217, 220, 
221, 226, 245, 248, 260, 261, 264, 268, 269, 
270, 271, 286, 313, 314, 315, 316
 singular 7, 8, 23, 24, 27, 55, 57, 58, 63, 66, 68, 
71, 73, 79, 87, 91, 93, 96, 104, 112, 117, 119, 
129, 133, 136, 137, 138, 152, 154, 161, 198, 
202, 203, 204, 206, 221, 237, 269, 270, 271, 
273, 294, 306, 312
 singular, permutation of 67
theta-criterion 82
theta-role 82
Th om, Paul 2, 5, 23, 39, 69
topics 5
truth conditions 12, 41, 42, 61, 96, 98–109, 123, 
131, 132, 142, 156, 158, 177, 217, 235, 239, 
241, 242, 243, 249, 256, 259, 264, 280, 281, 
284, 296
Uckelman, Sara 63
universal application 35–6
univocation 276, 277, 299
validity 13, 15, 19, 21, 23, 24, 31, 63, 87, 98, 110, 
113, 122, 260, 291
 formal 18–20
van Benthem, Johan 47
variable 24, 99, 261, 267, 271
Venn diagram 259, 260
verb:
 intransitive 126–8, 134, 169, 170
 transitive 67, 81, 129–36, 139, 146, 148, 152, 
166, 167, 197, 219, 260, 289
Vives, Juan Luis 282, 306, 318
Ward, Th omas 315
Westerstahl, Dag 50
Whitaker, C. W. A. 9
Wyclif, John 5, 60, 64, 70
Yrjönsurri, Mikko 5

