Are the AI apps on your phone right now mere productivity tools, or are they weapons designed
to give tech billionaires more power? Welcome to the NerdWrike podcast. I'm Gil Duran.
An explosive new book called Empire of AI, Dreams and Nightmares in Sam Altman's OpenAI
makes it clear that tech's current approach is a destructive effort to colonize the future.
Our guest today, journalist Karen Howe, author of Empire of AI, a brand new best-selling book
that exposes the truth behind OpenAI's quest for dominance. And Roger McNamee, a Facebook
investor turned Silicon Valley critic who is warning for a new reason that big tech is destroying
democracy. They're pulling back the curtain on the battle between billionaires like Sam Altman and
Elon Musk to control the future of AI and the world. A world where Congress is trying to kill any AI
regulation, even as every major company is racing to deploy artificial intelligence tools. All while
they warn, those tools might kill us. But Howe's book also illuminates the struggles of Kenyan
workers forced to moderate the most traumatic content imaginable for poverty wages. And she
writes about communities from Chile to Arizona defending their local resources from digital
colonialists. AI dystopia isn't just in the future. It's also an empire nightmare happening right now.
So who are the AI empire builders making billions off of AI hype? What do they really want? And what happens
when they get control of our future? Here's my conversation with Karen Howe and Roger McNamee.
Karen, Roger, welcome to the NerdWrike. Karen, your new book pulls back the curtain on AI development
and the company very much defining this moment, OpenAI, in ways that will make many in tech deeply
uncomfortable. And Roger, you've been an outspoken critic of Silicon Valley going back to your own
awakening experience with Facebook, which is why I thought it was notable that you've been a
tremendous advocate for Karen's book, even blurbing it. And you said this in your blurb,
with a cast of scientists, scammers and scoundrels, Empire of AI documents the hype campaign that caused
the world to fall in love with a technology whose immediate harms are legion and benefits remain
unproved. So let's talk about the people in that world, because I think that was the surprise to some
in your work, Karen. Your book isn't just about billionaire broligarchs. It's also about everyday
people in places like Colombia, Kenya, Arizona and Chile, pushing back, raising alarms, struggling to
get by in a world where they're dependent on these companies that don't really care about them, or maybe
about anybody. Tell us about some of these other characters who are caught up in this story, and what
their struggles tell us about AI. I think we get this idea sometimes that these billionaires are creating
magic machines. And we don't know about the other people who are involved in that.
Absolutely. And thank you so much, Gil, for having us and Roger for being here. Roger has been incredibly
supportive of my work in my book for so long. So I'm really grateful to him. The title of my book,
Empire of AI, is a nod to this argument that these new companies, we need to think of them as empires,
new forms of empire. And the reason why I go to all of these communities that you described is because
you cannot tell the story of an empire by just staying in the power center of that empire. You
have to go to the far reaches of empire to see how the technologies that are created within Silicon
Valley really start to break down for the majority of the global population. And so in Kenya, for example,
I went to speak with workers who had been contracted by OpenAI during a time when OpenAI was moving from
a more fundamental research orientation to commercialization. And they realized that if
they put text generation models into the hands of millions of users, they could run into a PR crisis
with the model spewing toxic, hateful speech in under those conditions. And so they went to Kenya to
contract workers to design a content moderation filter that would wrap around these models and
block anything that the model said that was unsavory before it reached the user. And what
that meant for the Kenyan workers was they were doing this detailed tax, they were they were reading
reams of the worst content on the internet, as well as AI generated content where OpenAI was prompting AI
models to imagine the worst content on the internet. And they were putting them in these
detailed taxonomies of is this hate speech? Is this harassment? Is this violent content?
Is this sexual content? To what degree is this content violent? To what degree does this sexual
content involve abuse or abuse of children? So that the filter could be taught to block all these
different categories of content. And like the era of social media, these content moderators were deeply
traumatized by their work. And it not only broke down their spirits, it broke down their families and
communities and the people that depended on them. And this is just one of the many stories that I
highlight to show this technology is not magic. There's a profound level of labor exploitation that's
happening. There's a profound level of environmental and public health harms that are happening to
develop these technologies. And ultimately, you begin to see the logic of empire when you center those
stories because there is no logical basis for why those workers are paid a few bucks an hour. And AI
researchers at the center of power are paid million dollar compensation packages. Their work is both
fundamental to the functioning of this technology. The only basis is an ideological one, which is that this
world should be a hierarchical one and that there are some groups that have a god given right or a nature
given right to be superior and others who are born inferior. Roger, so regular people get caught up in
an unregulated experiment that transforms their lives. And you've lived through this with social media,
which was a cool new technology that utterly changed the world in ways that were ultimately quite
harmful. Are there patterns repeating here? And how do you see this as different or possibly worse?
First of all, I want to just compliment Karen for that extraordinary description of the core
problem. That essentially what we have in this generation of what is called AI is essentially
a business where there's 10,000 mostly white men who are benefiting and 8 billion people around the
world who are being either exploited at a minimum or directly harmed by the success of those 10,000.
This is, I would describe as the kind of end state of the evolution of the tech industry that's been
taking place since 2009. Prior to 2009, for the first 35 years of my career and for the 15 years
before that or 20 years before that Silicon Valley existed, tech was about empowerment. It was about
productivity. It was about positive values. But when the financial crisis hit in 2009, they got this idea,
wow, we can use data and the free capital that was available from 0% interest rate to change our model.
And we can become predatory. We can exploit the weakness of others using data and to use that
to essentially take control of everything. And the part that makes me so angry is how long it
took me to understand. I first observed it in 2010 and told my partners, you know, when I looked at Uber
and Lyft, looking at that whole generation of ride sharing guys that, oh my God, this is totally
exploitative. And it's all based on breaking the law. I mean, Congress had decided Silicon Valley
should be protected from interference. So we're not going to create new laws against them.
But we also didn't enforce any of the old laws and Silicon Valley got used to this. And then after
2009, it just basically said, look, we're going to break the law of the community. And here we are
with the thing in AI that's based on, okay, we're going to basically end any effort to control climate
change. We're going to use up scarce water in places where water is really precious. We're going
to steal every copyright. We're going to steal everybody's personal data. And we're going to do
all that in order to unemployed tens of millions of people. And in order to make it work, we're going to
exploit hundreds of thousands of people in the global South who are used essentially as feedstock
to make all this work for the benefit of roughly 10,000 white guys. And I'm sitting there going,
hmm, that's why I'm so glad Karen wrote this book.
Let's switch to the main character in some ways of the book, just Sam Altman. And Karen,
you describe Altman in the book as someone with a stunning ability to persuade often and get his way,
which is a difference from a few of his key peers in AI right now, Elon Musk and Mark Zuckerberg,
who people have learned not to trust or view in a more negative light these days.
Yet underneath this sort of boyish boy wonder facade, there's something else, a ruthlessly ambitious
streak that often ends up turning lots of people close to him against him. People try to push him out of
companies more than once. You even report that Elon Musk felt he had been manipulated by Altman. And
Altman, of course, was mentored by Peter Thiel, who was part of the PayPal mafia with Musk,
because there's some connections here. And obviously, you've got a whole book that seeks
to understand Sam Altman and his key relationships. But what did you learn about Altman's specific
motivations in his quest for power?
The question of Altman's motivations is a really hard one, because one of the things I found most
fascinating while I was reporting this book is, I spoke to over 90 open AI people, as well as
several more people that were close to Altman, but not had not worked for open AI. And no matter how
long someone had worked with him, no matter how closely someone had worked with him, they could not
articulate what Altman's motivations and beliefs actually were. And the thing that makes Altman so
persuasive is three key ingredients. One, he is really great at telling these compelling stories
of the future that persuade people, as you mentioned, he has this persuasive power to join him on a quest or
give him capital for a quest. He is really good at understanding what people need, how to motivate them,
and how to push them towards joining the quest. And the third thing that people often reference is he
has a loose relationship with the truth. So that's what makes him so persuasive. He can say what people
need to hear to join on whatever journey he needs them to go. And because of those three things,
when I ask people, what does Altman believe, they would often just say to me, well, I think he believes
what I believe. Except that different people would have polar opposite beliefs and still be saying,
I think he believes what I believe. And over time, the reason why some people who are very close to him
then end up feeling this unease and then inevitably anger towards Altman is because they feel played
by him. They start to feel that his actions and where he's ultimately pushing the company, pushing the
trajectory of AI development is actually diverting from what they thought he believed, what he told
them he believed. And so that is kind of the heart of a lot of the open AI drama. It is also a really
important dynamic in how AI has ultimately ended up in this scale at all costs paradigm of AI development
is because of Altman's ability to persuade and also the polarizing nature of his character.
When I read that description of him in your book, it made me think, I do a lot of studying of psychology
and persuasion. And there's a tactic called mirroring, where you just kind of nod and you tell
people what they want to hear. And on some levels, you even mock or mimic their body posture because it
sends the subconscious persuasive signal, this person wants to agree with you. So
that kind of triggered to me that he's probably quite familiar with the technique of mirroring.
Roger, this isn't your first rodeo seeing a boy wonder CEO trying to save and change the world.
Any thoughts on Altman and what Karen just said?
So from 1956, when Silicon Valley was created by the AT&T consent decree until 2009, it was a completely
reasonable thing for people to trust that whatever Silicon Valley created was going to make their
life better. That was a completely reasonable hypothesis. Since 2009, I think you can make the
case the industry has been so predatory that one should not trust a single thing that they have done,
nor believe a single thing that they have said. Now, when Karen talks about a loose association with
the truth, that's just a beautiful euphemism because the underlying premises of many of the things that
have happened since 2009 are just like nonsense on their face, right? I mean, you look at crypto,
for example, right? It's based on the blockchain. Now, one thing you know about databases is that
you're supposed to have them become efficient as they scale. And yet the blockchain, every transaction
costs more than all previous transactions because the changes gets longer and longer and longer.
And so the premise is just ridiculous. The same thing is true here. So with generative AI, the idea
is that we can apply statistics to a training set and the mean value will give you something that is
intelligent. That is such an obviously flawed concept. And then when you throw into mix, the fact that
the training sets are not just biased, because the data is biased, but also filled with nonsense,
you know, you realize that there are use cases for generative AI that makes sense in the hands of
domain experts. But the notion that you can apply it generally, that you can use it for search, that you
can use it for, you know, chatbots and things that actually affect people's lives. I mean, that is so
obviously not true. But you have to ask yourself, how in God's name did this guy persuade these people?
I mean, how is it that they were able to take him around the world and meet heads of state as though
he was actually doing something important? I mean, to me, we're going to look back on this thing and
people are going to wonder, wow, how did everybody fall through this thing? And Microsoft is obviously
a huge factor in that. They legitimized this company. And Google clearly could have killed
them in the crib in 2022, had they simply pointed out the obvious that you cannot apply this to search
successfully. But all these CEOs in Silicon Valley, they're billionaires, completely isolated from
normal people. And they're really competitive with each other. And so Google, for whatever reason,
just had Microsoft entity and decided to chase into the space and all of this Altman had a lot to do
with all of that. And I look at it and I just go, it's unbelievable to me, because it is so obviously
BS. It just, it's stunning that they've gotten away with it for as long as they have. Now,
you see in the field, almost all the news reports are of the products failing, right? There are more
than 300 legal cases that have had citations that were made up. You know, you've had chat bots telling
people to commit suicide. You've had all these search results that are obviously ridiculous.
The technology clearly doesn't work. I mean, not in the generalized case, it clearly works for
for domain experts in their area of expertise. But 95% of the uses of the products is in places
where people don't know the topic and can't evaluate the results. And it's being used in schools
as a substitute for actually learning how to think or learning how to write or how to reason.
I mean, there's no good outcome that comes from any of that.
I know it's kind of scary. The children in my family begged me to show them AI. They know about
it. They want to get on there and use it. It's they see it like a toy that is some thing. And it's
scary what's going to happen to this next generation when they have access to these tools. I forbade it
myself. But we'll see what happens in the long run. It seems to me part of the whole fascination with
these guys is the archetype of Steve Jobs, that they all try to project this idea that everything will
change and technology will change everything. But we saw that happen the same with Elizabeth Holmes.
And that seems to be closer, Roger, to what the actual model is than to the Steve Jobs model there.
And it seems to be just this kind of quest for power as well, Roger. So let's unpack that dynamic
a bit. Sam Altman, CEO of OpenAI once considered running for governor of California. And there was
also a time when Mark Zuckerberg was very awkwardly exploring the idea of running for president. And we
increasingly see a trend in which money and power aren't enough for these guys. They want direct
political power, too. And it doesn't always work out as we're seeing right now, at least for the
moment with Elon Musk. Roger, what's the thinking here? And why isn't the money enough for some of
these guys? Why do they need more than that? So my hypothesis, I don't really know the answer,
but my hypothesis is that you have a whole generation in Silicon Valley that was essentially
raised on dystopian fiction and video games. Really, in many ways, their emotional development
was so affected by that, that they didn't go on to develop empathy or many other emotional tools that
allow you to navigate a complex world. And the one thing I'll never forget was in the days when I was
a mentor to Mark Zuckerberg, which was 2006 to 2009, that came apart when the company got to a quarter
of a billion users. And I pointed out to him that that was pretty much the limit of what you could do
in English speaking countries with an ad based model. And that if he wanted to get bigger than that,
he was going to have to start to do business in places he shouldn't want to be under terms he
shouldn't want to have. And he says to me, Roger, I'm not just going for a billion users. I'm going
for two or three billion. I'm going, Mark, that's crazy. Why would you do that? And I just said,
look, I can't be part of that. And the thing is that I think these guys have figured out and
Musk is really the guy who put it all together, right? Musk realized you could combine tech power with state
power. And once you did that, you created something that might be irreversible, right?
And Musk's whole idea is to replace the civil service with AI. That's a category error of the
most extreme kind. The whole point of government is to do the things capitalism doesn't do well.
All of this stuff, I think is just, I mean, it's terrifying. And, you know, the other guys all took
baby steps towards this and it took Musk to do the giant leap of, well, you know, I mean,
because Mark for a long time said, Hey, I got 3 billion users. I'm bigger than any country. You
guys can't tell me what to do, right? That was his whole way of handling regulators over the last
roughly 10 years. And you look at it now and you go, wow, Musk. I mean, I've been screaming about the
threat of big tech to democracy for nine years. And it never occurred to me that somebody would figure
out how to combine tech power with state power and do it in one shot, you know, do it literally
overnight as opposed to having to do it in steps. And I'm embarrassed that I got that wrong.
Karen, let's talk about Elon Musk for a second, since it's kind of hard to avoid right now. He's
currently attacking Donald Trump after cozying up to Trump. They've had a major falling out. And of course,
Musk is a co-founder of open AI. And he also had a major falling out with Sam Altman. And so he started
his own AI company. And now it's all playing out, but on a much bigger scale, these fights he has with
his colleagues and Musk and Altman both wanted to be CEO and it became a struggle. And now it seems that
Musk and Trump both wanted to be president and that became a struggle. So Musk helped Trump win the
presidency. Now we're seeing this dramatic explosion. Tell us about the relationship
between Altman and Musk and how do you think Musk's exit will factor into Altman's relationship
with Trump, given that Altman is so good at cozying up to power and telling people what they want to hear.
And now there's a space that is just opened up.
I'll talk a little bit about the individual dynamics of these people, but I also want to talk
about what I think this symbolizes because there's, there's a bigger picture thing happening
that I think is quite dangerous. So, so, so Musk and Altman, I mean, they're, they're on the,
on paper, they look like mirror opposites. You know, Musk is someone that seizes power through coercion.
Altman is one that persuades people to see power. Musk is the one that seems like the really,
the guy that lashes out. And Altman's the one that seems really contained and disciplined.
And you know, it also manifests in the way that they deal with legal things.
Musk is very much a legal offense player and Altman is very much a legal defense player.
You look at open AI structure, it's just all these nested entities. And that in and of itself is just
confusing for helping to understand what on earth is going on with this company. But ultimately they're
just using different tools to do the same thing, which is to accrue more wealth, accrue more influence,
accrue more resources towards their particular vision of the future. And so throughout opening
AI's history, it isn't just Musk and Altman that clash. It is all of these other former executives
at opening AI that clash with Altman because they have different ideological visions for how they want
to shape AI and how ultimately then that AI will shape the world in their own image. The thing that
happened with Musk and Trump, I think is emblematic of this bigger picture that goes back to my title,
Empire of AI. If we look at the history of empires, one of the analogies that I have been pointing to
that I didn't put in my book, but is extremely apt for the current moment that we're in with the Trump
administration is the British East Indy Company, which was a corporate empire that ultimately ended up being
nationalized by a state empire, the British crown. And that is when the Indian subcontinent went from
being ruled by company to being a formal colony of the British Empire. We are now seeing a corporate
empire and the US government in its own empire era as a state empire, each trying to subsume the other.
They currently have a tenuous alliance. As Roger pointed out, there is an alliance between state
and tech power that is unprecedented. But the alliance is happening because the state is trying to use
Silicon Valley for its empire building. And Silicon Valley is trying to use the state as its empire
building assets. So each one is trying to ultimately be the dominant one that ends up on top and can
direct the other. And Trump and Musk is the first illustration of this happening. I like
it was highly predictable that at some point it would break apart because of exactly what you said,
each one tried to gain power over the other. And then ultimately, Trump wins out and boots out
Musk saying, No, absolutely not. I'm president. I'm number one. And now Altman has this space,
and it's going to be the same dance. But Altman, I think he's quite clever in continuing to persuade
people into continuing to cede him power. So I think he might actually have more longevity than
Musk's typical tactics. But it is still the same exact thing. Like, you know, Silicon Valley is now
there. There's so many. It is so deeply influenced now by thinkers that talk about the politics of exit,
about this idea that democracy doesn't doesn't work anymore. And ultimately, the better way to
organize society is through corporations run by CEOs. And so that is ultimately the end game that Silicon
Valley has is they're trying to use the US government while they have this alliance to
build hardware and software all around the world, striking deals in the Middle East, striking deals
in other places to lay down infrastructure and ultimately get to escape velocity. What Roger was
saying that Mark was trying to achieve back in the day, try to get to a point where they become bigger
than countries themselves, and then take over the US government take over democracy. And we will once again,
see the playing out of how you know, how Altman fares and trying to do the same dance that Musk did. But the bottom
line is that it whether or not Trump or Altman ultimately win out, both versions are highly, highly dangerous, because in each
pathway, there is not a no one is trying to preserve democracy in either pathway. Both of these powerful
entities, both the state power and the corporate power are trying to ultimately ultimately move past
democracy and return back to an age of empire.
We do a lot of talking on this podcast about these exit ideas and the network state. And Altman is
definitely a part of that, although it seems like he's more in the teal model. It's hard to imagine
Altman going on Twitter and accusing Donald Trump of being in the Epstein files, right? He seems like he'll
take a much more diplomatic route and understands that to be in proximity to power means you got to lick a
lot of boot and hold your tongue. And it seems like he understands that in a way. I don't know,
I feel like that makes him more dangerous than the guy who goes off on Twitter.
I mean, I think it'll allow him to continue having access to extremely powerful spaces for longer.
Roger, let's go a bit macro on this. You've been arguing for years that tech self governance is a
failed experiment. And now they're trying to get into governing everybody else. Part of the reason
that it's hard to nail these guys is that they just shift definitions and reality around to suit
their current positions. And Karen says that very clearly in her book, the definitions always shift.
What is openness? What is transparency? Is it a nonprofit or a for profit? They just shift it all
around. And it seems like any federal regulation for the next few years, probably unlikely to do what
it needs to do in order to bring these guys to heel. What would genuine accountability look like?
So I spent nine years trying to bring about regulation. And it all starts with the data.
So it has to start with privacy. There's an NGO called the Electronic Privacy Information Center,
EPIC, which I'm on the board of that is the lead of trying to make this happen. And it is an incredible
struggle. And yet that's where it begins. I actually think that we as individuals have way more power
than we realize in this. Silicon Valley is actually a series of overlapping monopolies. And if you know,
the novelist Cory Doctorow, he has a term for the business model. He applies it mostly to social media,
but it really applies to all centralized cloud based apps, which is this idea of in shitification,
which is you start with a product that is immensely appealing, does something that changes people's
lives for the better, and they get completely hooked. And the vendor who has this product does
no monetization until everybody is addicted. And then when they do, they bring in usually advertising
or some other monetization form. And in that process, they in shitify the experience of the early
users. But they do it really gradually. And again, these people are addicted. So it's, you know,
they tolerate the in shitification. Then the second state, after they've gotten to great profitability,
they realize they can get even more because if they in shitify the experience of the advertisers,
they can just print money. And that's the phase we've been in for the last five years.
You know, if you use a product like Google search, or if you use Microsoft Office 365 or Google Apps,
if you use Facebook or Instagram, you know, the thing you notice immediately is that the experience
today is just dreadful, right? And these products are simply horrible. And the thing that just boggles my
mind is that it hasn't occurred to anyone that these guys are incredibly vulnerable.
And all you have to do is recognize the industry hit a fork in the road in 2009, and it left
empowerment and productivity in favor of exploitation and extraction. All you need to do is go back to 2009,
pick up where they were, and reinvent all of the core products,
and moving forward. So there's essentially no technical risk, huge market opportunities.
But nobody has attempted to do that. And I think this is something that will happen outside the United
States, because the behavior of the integrated tech state power in the United States is such a giant
threat to the European Union, to Canada, to countries around the world, that they have an enormous incentive
to do that. And, you know, so when I look at this, AI is funded by the profits on those monopolies.
And there is a race going on now, can you convince the guys in the Middle East to fill the void that's
going to be left when all of those monopolies collapse at their own weight? Because if you use
Google for search, you're getting garbage out of it. If you're using Microsoft Office or Google Apps,
you're getting your, your experience is just horrible. And so I do expect that this is an
unstable situation. I don't know how it's going to come down. But there is a race going on. And we as
individuals, we should just say no, just stop using the products. I was expecting young people to do it.
But I actually think it's going to be people in businesses that the really vulnerable products
are Office 365, Google Apps, Google Search, Gmail, right? Because they're all bogus. And there are
substitutes for all of them. A quick note from the NerdRike producers. And shittification is a great
word that can describe any number of things. Cars, platforms, smaller burrito bowls. Tell us how it
applies to something in your life and tag our blue sky at nerdrike.bluesky.social. Back to the pod.
Karen, let's talk about the would be colonizers of the future. The empire. That's the main metaphor.
Maybe it's not even a metaphor, really. It's very literal term that you describe, you use that term to
describe AI development. And that's not accidental language. Break that down for us. When you say empire,
what are you actually describing? And how does the AI empire specifically work?
Yeah, so there are four different features that I point to that are the parallels between what I
call empires of AI and empires of old. The first one is that they lay claim to resources that are not
their own. But they interpret the rules to suggest that it was always their own. That refers to the
data that these companies scrape from the internet. You know, people who put that data online, they never
gave informed consent for having their personal photos or their thoughts get taken and used to
train models that might ultimately constrain their future economic opportunity. But companies will
say, well, it's in the public domain. It's totally fair game. And all that intellectual property that
these artists and writers created, that's fair use. We're using it under fair use. The second feature is
that empires exploit a lot of labor. So that refers not just to these companies contracting workers all
over the global south and in economically vulnerable communities to help produce the technologies they
create, such as through concept moderation, data preparation, data cleaning for just a few bucks an
hour, as I talked about, but also the fact that their technologies are ultimately labor automating
technologies. OpenAI's definition of artificial general intelligence is highly autonomous systems that
outperform humans in most economically valuable work. So they are explicitly saying that their intent
is to do better the jobs that people usually get paid for. So there's labor exploitation going into
the creation of this technology, and then the technology itself perpetuates labor exploitation.
The third thing is that empires monopolize knowledge production. So in the past decade, what we've seen is
because AI companies have become so resource rich, they can give these million-dollar compensation
packages that I mentioned. And so the top AI researchers in the world used to mostly work for
academia or independent research labs. They now mostly work for AI companies. And that means the fundamental
science that underpins our public understanding of how AI works and its limitations is being filtered
through what is good or bad for the empire. And that's effectively the equivalent of all climate
science being predominantly done by researchers working for oil companies. You're obviously not going to get
an accurate picture. And the final feature of empire is that empires always engage in this narrative that
there's good empires and there are evil empires. And they, the good empire, need to do all this resource
extraction, need to do all this labor exploitation in order to be strong enough to beat back the evil
empire. And I talked throughout my book about how OpenAI consistently identifies new evil empires to hold
up. So originally the evil empire was Google, now increasingly the evil empire is China. And the idea is
they as a good empire are ultimately civilizing the world. They're not engaging in exploitation. They're
actually bringing progress and modernity to everyone and giving humanity this gift where they can bring
all of the human race to heaven instead of damn them to hell. And that is, you know, that is literally the
language that they use these days. They talk about building digital gods. They talk about heaven and hell. And
that is quite a profound echo of the way empires of old used to describe themselves as well.
So we're surrounded by technology. It's hard to escape no matter how hard we try. We're being sucked
into the consumer funnel of these companies. Most people who listen to this conversation will do so
on YouTube, which is owned by Google. Many liberal and progressive writers are on Substack, which means
the venture capital firm Andreessen Horowitz is profiting from their work while supporting the Trump
administration. Roger, these are powerful systems whose success depends on exploitation and harm
in many ways. Yet we're in a moment when everything is being pitched as AI enhanced. It's hard to escape.
You know, any program you get now is like AI, now with AI, your phone, now with AI. But some people do
try to escape. You, for instance, don't use certain products. Is there any ethical way to use these products
from large tech companies? And why don't we see venture capital backing projects that are good for the
public? So I don't think there's any ethical way to use AI. I don't think there's any ethical way to use
Uber and Lyft. I don't think there's any ethical way to use crypto. You know, I think these are products
that are rotten at their core. And the thing is, in the case of Uber and Lyft, it's for DoorDash. They're incredibly
convenient. And we have been trained for the last 70 years, in America in particular, to choose convenience
as the first order feature of anything that we use. And so we seek out convenience. And we seek it out
literally, you know, the way lemmings seek out cliffs, right? I mean, it's really terrifying. And
the thing is, we've been manipulated to believe that convenience is always the best path forward,
right? That's the thing driving kids to use ChatGPT instead of learning how to write. It's convenient,
right? It saves you time. And the thing that I would argue this, I mean, listen, I think caring
is absolutely brilliant. I think this book is amazing. And this her whole way of describing
empire is really important. But there's a fifth element that I would just like to add, which is my
own personal one, which is that empire is about essentially collecting wealth in the hands of a tiny
number of people by exploiting literally everyone else. And when you get into conversations about
democracy, I think people don't really understand what this really about is human rights. Are you going
to be a human being with agency with, you know, are you equal to everyone else? Or are you somehow going to be
lesser than others? And I think that the tech industry has a very clear plan, which they do not
hide any longer, they used to hide it. But now they're really open about it, which is you little
people, you have no rights, we're going to take whatever work you have product you have created,
whatever it is, it's your will, you're the thing that you do for a living, we're going to take that away
from you for our benefit. And I look at all of these things. And I simply point out to everybody,
you may have trouble imagining what life would be like, if you don't have the right to vote,
or you don't have the right to, you know, reproductive freedom, or you don't have the right to
healthcare, or you don't have the right to a job or any one of a gazillion other things.
You may have trouble imagining that. But guess what, you probably ought to work really hard at
imagining it. Because that's not a hypothetical. That is literally the game plan that these guys are
on. And so if you're using Microsoft Office 365, or Google Apps, you must assume that everything you're
putting into those systems is being processed by those companies for AI, and that there is some
prompt you can use with AI that will regurgitate your private information, your company strategic
information, in whole form, to the prying eyes of somebody else. And I'm looking at this and going,
why would anybody put up with that? I mean, I used to have a Microsoft Exchange server, for me,
for my wife, and three people who work with us. Right? And it's the same expenditure. And Microsoft
deprecated the thing every year, until it broke. Because they want to switch us to Office 365. And I
refuse to go. And I'm sitting there going, if everybody did what I do, this whole thing would be
completely different. But they don't. One thing that's been interesting to me to watch,
as someone who worked in politics for a long time, is that people I've known from California
Democratic politics for years, people who worked really hard on progressive policies, people who
worked really hard to get Kamala Harris elected, they've all now gone to work for a lot of these tech
companies. In fact, two people immediately after the Kamala campaign pop up at OpenAI now. And this has
been kind of surprising to me. I know a lot of people who are in the middle of some of these
pro tech things. So the ethics get very blurry when people see their own personal advancement, you know,
Shame on you. This has been going on the revolving door between Silicon Valley and
Democratic politics has been going on since the Clinton administration. And, you know, if you're just
noticing it now, I mean, seriously, let's just go back and look at the list. I mean, Kamala Harris's
husband is an Uber or brother-in-law, sorry, her brother-in-law, excuse me, her brother-in-law,
her husband's obviously an entertainment lawyer, her brother-in-law. And you look at this and you just go,
the Democratic Party sold its soul, the Silicon Valley. It did that in the Clinton administration.
And it was really bad under Obama. I mean, Obama had a Federal Trade Commission case against Google.
They could have nipped surveillance capitalism in the bud in 2013. And, you know, Eric Schmidt, who had
been like, at least the figurehead chairman of the campaign prevailed and they killed it. And I mean,
the notion that the Democratic Party is helpful on these issues is laughable.
No, the Democratic Party largely created Elon Musk, right? I mean, who made him richer? Who made him
the richest man in the world? People that I've had a long, great relationship, like Adam Schiff,
one of my favorite members of Congress, in order to get elected to the Senate, you know, took a ton of
money from the crypto guys and became an advocate. Nancy Pelosi became an advocate. I mean, what is up with
that? These people know better. But the incentives of politics in America are to take the money
so that nobody is working for us. And so the question is, when are we going to insist that our
politicians work for us? I don't think I agree with you. It's a longstanding
problem. I think what's become different lately is that the overt harms and imperial ambitions of
these companies has become very pronounced. And that's still not going to stop Democrats from
going directly into it. In my view, the cooptation and corruption of the Democratic Party is an even
bigger threat than the Republican Party. We know the Republicans are already there. But the Democrats
now, people who were fighting for this different future, supposedly, are actually going for the exact
same future, just with a different language and a different take on certain issues that we might all
agree on. But Karen, you recently described generative AI as fruit from a poisoned tree. And that's a legal
concept about evidence obtained through illegal means. What are the poisoned roots of AI development
that can't be wished away with better intentions? What would you say to those currently using AI products
as consumers about what they're actually participating in? One of the things I want to clarify is I
specifically talk about that when talking about Silicon Valley's conception of AI development, which
is the scale at all costs paradigm of AI development. This is the kind that is scraping all the English
language data on the internet. This is the kind of AI that is leading to the mass proliferation of data
centers and supercomputers, which is then creating environmental, public health, and freshwater crises.
All around the world. But there are other types of AI technologies where I would describe them
as tasks-specific, focused tools that can target computational problems that would in fact be
beneficial in different spaces, such as the mitigation of climate, improving healthcare access,
improving educational outcomes, and things like that. The reason why I call Silicon Valley's
conception of AI fruit from a poison tree is because of exactly that, that there is just so many social,
environmental, and labor harms along the supply chain production of this technology. And then ultimately,
as I mentioned, the technology itself then is also labor exploitative and is also leading to
detrimental effects like the erosion of critical thinking in schools, that every time someone uses
these tools, they are helping to perpetuate that imperial ambition. And as Roger mentioned, if
everyone stopped using these technologies, these companies would have to change. They would have
to change just in the same way that the fashion industry used to have also hugely exploitative practices
and lots of labor environmental harms and consumers shifted in mass to create new markets for sustainable
and ethically sourced fashion. And so Roger is exactly right that people forget how much power we have.
All of the resources that are used to create these technologies, the data, the land, the energy, the water,
and all of the spaces that these companies need to deploy their technologies into, schools, hospitals,
government agencies. These are actually all owned by individuals, by the public, or by communities.
You know, that data is our data. If we stopped using these tools, they would stop getting our data.
Artists and writers that are suing these companies now and saying you can't just take our intellectual
property, that is them reclaiming ownership over their data. Teachers and students that are objecting
now to the idea of AI just being deployed willy-nilly into the educational environment,
and saying can we figure out under what terms we deploy AI so that it actually fosters creativity
and fosters critical thinking. That is them pushing back and starting to deny access to a space that is
collectively owned and deny access to Silicon Valley. And if everyone did that all along the supply chain
of AI development and deployment, we would get to a place where we would start having more broadly beneficial
AI technologies. But we need to, as Roger said, recognize that convenience, the convenience of these tools
is the way that Silicon Valley is greasing the wheels for the perpetuation, fortification, continuation
of the empire. The core issue here is that in Silicon Valley, the play
was to spend so much money that they would crowd out literally everyone else, right? So the thing that
Karen's talked about is hypothetically true. But in practice, all of the engineers who are the leading thinkers in this
area have gone to work for the empire. And so the rebellion, such as it is, is not particularly well
funded, and it's not making that much progress. And, you know, as I look at it, and I think this is a
really important point here to keep in mind, it's not just that the big tech monopolies of old tech
are very vulnerable. The big five are vulnerable, because they have five essentially identical
development efforts, chasing what I suspect will be at most three viable opportunities, and maybe only
two. So you look at this, so if Musk is out with Trump, then maybe he loses this, but he put himself in
the pole position to be the guy for the US government, right? And he may still have that because his
people are still in there, right? Well, you got four other guys competing for that, right? Two of them
are almost certainly toast, and probably relatively quickly. Now, what are the knock on effects from
remember, the industry will have spent 600 billion by the end of this year on this stuff. So at least 200
of that is going to be a write off in the next year or two, right? Because there just isn't going to be
space for five of them. And the Chinese showed, hey, with a little ingenuity and stealing a little
IP here and there, we can do it for less than 1% of the cost. Because it turns out that LLM technology is
actually a commodity. It's not very valuable. Why? Because it doesn't do much. It's not the answer.
It's not the path to AGI. In fact, there is no path to AGI in, certainly not in our lifetimes. And
you look at this, the whole thing is just smoke, mirrors, more smoke, more mirrors, and Samo.
The politicians have sold out completely. CEOs have capitulated completely. And the press has
capitulated completely. And so it's like, there's nobody left but us. So if we don't act,
these people are going to win something. And whatever it is that they win, it's not going to be
good. Because the products aren't any good.
Karen, I went to your talk at the Commonwealth Club, and I noticed something interesting in
the book signing. You had a little stamp that you put in the book cover that said AI free.
Tell us a little bit about your personal relationship with technology.
I do not use generative AI tools. I don't use ChatGPT. I don't use Claude. I don't use any of them.
And part of it is I investigate these companies. So I'm absolutely not going to just give my data to
them. I only use it with fake email addresses and a fake account to understand when they release new
features so that I can continue doing my work. I do use predictive AI tools. And this is what I was
referencing when I was saying like task specific, smaller AI models that are used to tackle useful
things. So the stamp says Gen AI free, not AI free, because I did use predictive AI for some parts of
my reporting. I wanted to figure out how expensive opening eyes furniture was because I was trying to
explain the shift that happened when they were a nonprofit to becoming a very well backed Microsoft
funded company. And so I use Google image, reverse image search, which is a predictive AI tool, I took
the photos from opening eyes chairs from back in the day, and then I took a screenshot of the chairs
from their office that they upgraded to. And then I ran it through Google reverse images to try and figure
out what the price was. And it turned out that the original chairs were around $2,000 each. And the
upgraded chairs were going online for around $10,000 each. And so I ended up adding that detail into the
book to try and describe in a very concrete way, the escalation of wealth that this company was
experiencing as Roger mentioned, like the ultimately the empire metaphor really talks about the accumulation
of wealth occurring to the top at the detriment of the majority of the world. And so I do sometimes use
predictive AI tools in my life. But yeah, I avoid any of the generative AI tools that are made
specifically by these companies. May I push back on that slightly? So you use the term predictive like
somehow that category of AI is okay. Let's remember the predictive is only as good as its training set.
And I believe the four largest use cases of predictive AI have been predictive policing, mortgage review,
hiring. And I'm drawing a blank on what the fourth one was, but let's just look at those. So let's
look at the first three. So predictive policing is essentially using data filled with bias in order
to justify the over policing of black and brown communities. It has done it. I mean, the buyers
want, right, the police departments want the bias, because it essentially absolves them of responsibility
for over policing, right? You look at banks, right? Digital redlining. That's the same thing. The biases
are built into the data sets, and it gives them it absolves some responsibility for denying black,
brown people, and immigrants, and women mortgages. And the same thing happens in the job market.
You know what the fourth one was, the fourth one is, is, and it's actually the largest of them is
moderation of social media, where it's been an abject failure. So in the four largest use cases
of predictive, from an economic point of view, it has produced huge social harm. Now, there are
obviously other use cases in drug discovery and other places where smaller data sets have produced
positive outcomes. And the same thing is true in general. In the hands of a domain expert,
with a highly curated data set, you can produce something useful. But that's not what these
people are trying to do. They're claiming they have the answer to everything. This is literally
a Douglas Adams 42, right? The notion that we believe anything that these people are saying
is just unbelievable. Yeah, that is a very, it is a very good pushback.
Absolutely, Rogers, right, that just because something is predicted doesn't mean that it's suddenly okay.
For me, any technology that emerges out of Silicon Valley's quest to create everything machines is
inherently corrupted. I don't think that is true for predictive. There are certain predictive AI
technologies that could be beneficial if, you know, all the conditions apply, as Roger said,
they're developed and deployed in ways that are highly responsible and held accountable. But of course,
there are also many, many different ways to abuse predicted technologies. But I do not think anything
that comes out of this quest of building everything machines can have that same opportunity to be
ethically deployed. And it seems like the focus on AGI is something that distracts us from these very
real and present harms that are looming more closely to our reality than, oh, we have to save everybody from
this monster that, by the way, we're trying to create, which we probably maybe can't create,
but we're trying to create it in order to save you all from it. That seems to be the logic around that.
And we'll be right back after these messages.
And now it's time for the podcast plugs. Karen Howe's amazing book Empire of AI is available now
at bookshop.org, Barnes and Noble, local bookstores, and wherever books are sold. And you can follow
her on bluesky at karenhow.bluesky.social. Roger McNamee would also like to plug a book. Here's Roger.
And everybody, please buy Karen's book. I'm serious, because if everybody reads Karen's book,
you'll understand why I'm so convinced that we can win this thing. Well said, Roger. And now back to the
pod. And we're back. Roger, you've been in this fight longer than most people. When you look at
the current moment, do you see a genuine reckoning on the horizon? Or have we fallen further down the
will than ever? If there's a reckoning coming, it's going to come from the industry's
own failures. So the monopolies in social media, in enterprise applications and search and all that
are poised to break down. The big five in generative AI are going to have a day of reckoning because
there isn't room for five winners in that category. And I think the failures that will result from the
people actually using this stuff are going to be spectacular. And they're already terrible. But I
think they're going to become much more so. And so I think the big hope is that these things are coming.
And if we can persuade people, then when the collapse comes from the social media monopolies and the
enterprise monopolies and the failures of a couple of the generative AI guys,
then we have a chance to have a real reckoning here. But to expect it from government, I don't
think there's a chance. To expect it from corporate CEOs, from the customers, I don't see a chance. To
expect it from journalism, not a chance. If it weren't for Karen and a handful of other people,
we wouldn't know anything about this because most of journalism is just stenography for the PR department.
Karen, is Roger right? You know, we started this conversation talking about the people,
regular people being affected by all of this. What did you see writing your book that gave you
hope? And in the book, you do go into some ideas for the future. I never liked to give those ideas
in the interview because people got to buy the book. It's an important book. It's highly readable.
And when you buy books like these, it sends a signal to the publishing world
that they should publish more books like these. So we're not going to tell you the ending here,
but give us a little glimpse of what gives you hope in this David and Goliath struggle
against this dark vision of an empire future.
The thing that gave me hope was I met so many people along the way who you would assume
would have no agency that fundamentally remember that they did and remember that they had agency much
better than people who should actually have way more agency. And I'm talking about the Kenyan workers
that I met on the ground. I'm talking about the Chilean water activists that I spoke to that pushed
aggressively against data center expansion within their communities. These, objectively,
they're at the bottom of the global power hierarchy. These are communities that are in poor
communities in poor countries, combating a wealthy enclave in the wealthiest country.
It's extraordinary that they, first of all, knew that they had agency. And second of all,
then made so much noise that they got international media attention. The reason why I even went to visit
them and report on them as part of my book was because there had already been significant reporting
on these communities. So I knew that they existed. And I think we just need to remember that spirit. We
need to capture the spirit that they had and their willingness to fiercely protect their resources,
their labor, their dignity. And that is ultimately what is going to help get us out of this hole.
Thank you both for joining us on the NerdWrike podcast.
Thank you so much for having us, Gil.
The NerdWrike podcast is produced and edited by R.R. Robbins. It's written and hosted by Gil
Duran. Become a paid subscriber to the newsletter today at thenerdwrike.com. It's really helpful if
you write us a review on Spotify or Apple podcasts. And if you subscribe to our channel on YouTube,
it's possibly less helpful promoting us on LinkedIn, Pinterest, or Tinder, but hell,
give it a shot. Today's final words from FDR. The liberty of a democracy is not safe. The people
tolerated the growth of private power to a point where it becomes stronger than the democratic state
itself. See you next time.
