we created this society where we're super hyper connected with everybody and yet our
infrastructure really is built to divide us to polarize us to divide us to make us
entrenched and to actually make us pretty bad at making good decisions
welcome back to beyond the bite the show where we explore the edge of innovation and ethics diving
into the big questions behind the tech that's shaping our world today i'm your host mo hafiz
and today we're tapping into a different kind of intelligence not artificial not human but something
in between imagine this a swarm of birds a school of fish a hive of bees each one moving with perfect
coordination no central leader but somehow making decisions as one now what if we could harness that
kind of intelligence not just in nature but in boardrooms in classrooms and crisis rooms what if
ai didn't replace us but helped us think more effectively today's guest has spent the last
decade answering that very question dr lewis rosenberg is the ceo and chief scientist of
unanimous ai and a pioneer in the field of swarm intelligence with a background in virtual and
augmented reality which we'll cover and a phd in human computer interaction lewis has devoted his
career to technologies that amplify not replace human ability and it's why we're excited to have
him on the show today his breakthrough platform swarm ai has been used to outperform experts in
predicting sports tournaments diagnosing medical scans and advising fortune 500 strategy teams
and now his latest project thinkscape is aiming to revolutionize how large groups collaborate and
make decisions in real time so today we're going beyond generative ai and into the realm of collective
intelligence it's a conversation that's going to center on collaboration not competition about
designing systems where ai is a partner not your boss and about what it really means to be smarter
together uh lewis it is a pleasure to have you on the show welcome yeah thanks for having me that
should be fun yes i'm looking forward to it uh you know we we've had a chat you and i before this and
we got to get to know each other um and i want to highlight some of the awesome stuff that you've
uh that you've done in the past and what you're doing now uh so let's start with this you've had
a fascinating journey through human computer interaction we're talking virtual reality augmented
reality and now you're doing this thing with what swarm intelligence with unanimous uh tell me what was
the moment that sparked your shift toward enhancing group intelligence and and doing this kind of swarm
intelligence uh uh aspect yeah yeah so my i mean my fundamental interest is using technology to to
amplify human abilities and uh as you as you said you know i started from the the domain of how can we
use technology to to help individuals and and so i my initial work was in the areas of virtual reality
and augmented reality starting way back uh you know in the early 90s and um and as i as i really focused
on how can technology make the biggest impact on people i started to realize over time that while
it's super interesting to look at how technology can help an individual when you go to groups there's so
much potential of of what we can do because as as a culture and as a species like we really it's really
very new for us to be working in groups of this size right like we like like it's you know in a lot
of domains like virtual reality augmented reality when we're we can use a technology to help give people
better perception and better understanding of the world but like we've been perceiving and understanding
the world as individuals for millions of years right but like evolutionarily like we really evolved to
work together in small tribes and now we're we have organizations that have tens of thousands of
people that need to work together we have you know municipalities and countries where we need to work
together among millions or hundreds of millions of people and we also just have a whole planet where we
need to work together as billions of people and we like we're really not built for that and the
technologies that we currently use are hundreds of years old in a lot of ways and and by that i mean
like if you if you want to understand the perception and the perspectives of a large group of people
today the primary technology we use is is polling right like we we pull people yes and we've been doing
that for hundreds of years and it seems just intuitive like oh yeah like that's it should be
fine you pull people and you you get you understand what they what they think and the truth is when you
really look into it polling is polarizing that's that's that's what it does what a poll does is it shows
you where people disagree and then we go and we publish the polls so we reinforce the disagreement
and we and so we created this society where we're super hyper connected with everybody
and yet our infrastructure really is built to divide us to polarize us to divide us to make us
entrenched and to actually make us pretty bad at making good decisions like so we're in a world right
now where people are really smart as individuals but sometimes in groups we're really dumb like that's
just how like that's how we are and so for me about it was about a decade ago when i i really said well
how can we use ai to allow groups human groups to make smarter decisions to to be more productive
together and like a lot of researchers like who's facing a problem that's unknown i said well how does
mother nature do it right like like nature probably could give us some guidance and it turns out that
mother nature has has you know crunched on this problem for hundreds of millions of years and
there's a lot of different species where they started out as as you know being you know very
evolving their intelligence as individuals and then they started to work together in systems and
started to evolve their intelligence in systems yes and biologists call swarm intelligence and they call
it swarm intelligence because the first species that was really studied in detail to really understand
how they amplify their intelligence is honeybees and so we call it swarm intelligence but the same exact
uh that well very similar processes evolved in schools of fish which we also call swarm intelligence
evolved in flocks of birds evolved in a lot of other species slime molds yeah ants so this idea that that
you know evolutionarily actually turns out to be pretty common that a species will develop a brain
inside their head and then and then they'll reach the limits of the brain you know the brain inside
their head and if you know if you're a honeybee you can't really make their head bigger because they
have to fly and and get into little uh little flowers and so they so evolution says well we can't make the
brain bigger let's start connecting brains together and so a swarm intelligence is really a brain of brains
and it's and when you really start looking at it you realize how remarkable it is like a school of
fish which like nobody really thinks of a school of fish as this remarkable thing but like a school of
fish there's thousands of members yeah nobody's in charge yes and yet they make all of life's decisions
seamlessly like so seamlessly that biologists refer to them as a super organism because they can function
uh and make instantaneous decisions uh and make instantaneous decisions by collecting information
from from thousands of different fish yeah and making not just smart decisions but like optimal decisions
optimal decisions for the group honeybee and and honeybees make optimal decisions and birds and and so the the
big you know the big inspiration that i had you know a decade ago was to say okay swarm intelligence works for
birds and bees and fish why not humans it should work for people and and guess what we people we've
built this infrastructure where we've put satellites in space and phones in everybody's pockets and and
connected everyone together like we have an infrastructure to do this we're just not using it the
way that biological systems do and so we over the last decade we've been saying okay let's let's start
connecting people together in the types of systems that biology says works and maybe we should they'll
get smarter and it turns out that we do get smart we get a lot smarter and we can smarter forecasts and
and make better decisions and and uh reach you know prioritize things better in groups and and we can do it
among uh among relatively small groups and we can you know our goal right now as a company is we're going
for bigger and bigger and bigger groups because the bigger the group the more knowledge and wisdom
and insight that you can you can harness and what a timely uh uh you know time what a time right now to
be putting this concept out and now and the reason being is because uh you know nowadays we see ai doing
so much um you know i hear uh uh very respected uh leaders individuals talking about how um you know
the era of the one uh person company that is just in charge of an army of agents uh is going to be
just fine and it's gonna you know have a we're gonna have a billion dollar company and so and we're
also noticing a time when individuals are connecting with uh with ai chat bots right chat gpt and gemini
and they're doing it on an individual level and and there's not enough actually collaboration bring in
remote work the concept of working remotely people now only see each other when they meet on zoom or
when they meet over teams they don't actually have these conversations that they that they used to
have when they met each other in the halls of the you know of their work site this idea of actually
getting people in groups together is uh is under attack i want to say now you know so it's actually
rather um you know alarming to think about the fact that we're spending more time with machines
and less time with each other and even ai itself you know it works with neural networks this idea
of having multiple machines all working together to produce it so the concept of bringing that back
to humanity to humans to be able to get us all together to think uh is is incredibly timely and
very important so let's talk a little bit about swarm ai i want to bring that into the picture
because this is kind of your baby right your your idea for how we can get humans to really um work
together uh with machines also but really fundamentally uh it's going to be about humans
working together how does it work and and how is it different from uh to traditional ai decision
making tools that we see nowadays right so the the difference is really where does the data live
that we're that we're talking about and and so a traditional ai system is going to be trained on a
big set of data and there's there's kind of old school ai systems machine learning where you have a big
set of data about you know whatever it is you want to build a system for train it and then it can
generate uh it can generate insights you have the new generative ai technologies which you were you
know we're training it on massive sets of data like potentially like all of the artifacts that humanity
is left behind the entire internet yeah yeah and so now you you you this these systems are have this
massive amount of data that that we humans created and there's massive amounts of intelligence in it
and you can do a lot of interesting valuable amazing things but it's not all the data that
exists in the world and i say that because there's there's actually what i refer to as the human database
so there's there's the database that is the artifacts we've left behind that sit on a server somewhere
and then there's the database of the stuff inside our heads right and we like we totally don't
appreciate that that there's a you know there's eight billion of us and inside of each of our heads
is more information than than fits on the entire server for netflix right so it's like our brains have
massive capacity and we are information collection machines right like we are continuously out there
updating the information in our heads on everything that we read and see and watch and experience and
so we we are a massive database yeah we're keeping it up to date and we are actually remarkably good at
making inferences from small amounts of data like we like we call it intuition yes but it's that's just
the subconscious neural networks where we can take this small amount of small amount of information a few data
points and make remarkably good forecasts about what's going to happen in our world that's how we evolved
yes and so today's ai systems traditional ai systems and generative ai systems they can answer
questions based on the artifacts that were left behind by humans data and materials but they can't
make decisions or generate insights based on the inf the database that's inside of all of our heads
and that's where swarm intelligence comes in so swarm intelligence is saying okay what if we build an ai
that's not going to work by connecting by connecting and processing uh big data servers it's going to
work by connecting large groups of people together in real time and having us interact so that we can
leverage our knowledge wisdom insight intuition plus in addition our values our ethics our morals our sensibilities
and our interests as a species right so so now we're saying we can connect together a group of people
and it could be you know 20 people or it could be 20 million people and we can enable those people to
solve a problem together by leveraging their their database yes and their perspective and they're going to
have what's interesting is it it's going to it they're this database is going to have a lot of
conflicting perspectives yeah like there's going to be lots of different views and perspectives and
they're good and and a swarm is a battle right a swarm is a a bunch of perspectives all pushing and pulling
on each other in real time i like to think of it as a as a multi-directional tug of war a school of
fish yes school of fish is this tug of war they're all pushing and pulling on each other and they all
don't agree it's not like they all instantly agree they have this battle and then the the
the direction that maximizes their collective confidence and conviction is the direction that
they go yeah and and that's what's really different about a swarm intelligence of humans
than a database of data like a database of data it's usually just the the it will tell you the
conventional wisdom of the artifacts it doesn't allow for a deliberation it doesn't allow for this
push and pull and an argument because really a good decision is like a good decision is an argument
yeah and um and that's not what you get out of a data set correct and so um when we first started
working in this field we would we get a lot of interest from uh from large companies retailers
and they would say and this is even before generative ai they'd say like yeah we're trying to forecast
our sales for the next uh holiday season we've got this new product uh we that we're going to launch
we took all of our sales data and all of our marketing data and we did machine learning on it
and we made predictions what what's going to happen next season and we were wrong and and and you know
what can we do to make that better and i said well no your prediction wasn't wrong you you accurately
predicted you used last year's data to accurately predict how your new product would have done last
year because because you had last year's data yeah and because your data doesn't know it doesn't have
built into it the you know a sense of this the the style that's popular and the the sentiment among
consumers today and the the sentiment among retailers today but you know what the humans in your
organization have that information your sales team and your marketing team and your retail channel they
have they have they have a gut instinct yes they mean of you know what is the consumer sentiment and
what is the prevailing style and and how are you know these type of sweaters gonna do this year and
you want to tap into that you want to tap into that collective human intelligence and collective human
experience uh to be able to get some new information not just rehashed information from the internet
and and it's again like we call it intuition so we don't value it as like we like we almost
don't value our own superpower like yes but so we've done all kinds of studies over the last 10 years
where we will we'll bring together a group of people and we'll who um and we'll have them do
forecasts and predictions they'll predict uh the sales of products they'll predict elections they'll
predict sporting events and and what they're doing is they're not processing in their heads all this
historical data they'll processing all of the information that they've collected in terms of
their understanding of the world and they will always outperform the traditional ai system because
and again it's not that it's not that our ai itself is more powerful than the other ai it's that our
database is better our database and what we're doing is instead of treating people like data points
which is really what what most systems did right to say oh well we let's give a survey out there
we'll treat you as this set of data points we say no a person is a data processor let's connect this data
processor and its memory together with a hundred or a thousand or a million other humans who are data
processors yeah and let's allow them to converge on solutions and guess what they're really they're
really smart solutions and so we had a really interesting example that just happened uh back in
march because um so there's you know there's the big basketball tournament march madness uh and march
madness is um in the u.s there's every cop you know if all the top college basketball teams compete
and it's so popular march madness that espn runs a tournament and they run a tournament where they have
30 million people per submit predictions about who's going to win the tournament and how it's all going
to work out and uh and so we and because it's so popular a lot of organizations used generative ai they
said like oh let's have chat gpt and let's have gemini let's ask them who's going to win the tournament
and and so uh chat gp so there were people who filled out entries into the foot into the tournament
using chat gpt and gemini and uh grok and and then what we did was we said well let's let's just get
uh a hundred random sports fans yeah and let's have them log into our platform and let's have them
fill out a tournament bracket to submit to to espn in you know a half an hour they were able to to
converge and i'll talk about how they do it yeah and tournament bracket and then we competed to see
well how did we do and what's interesting is we had you know 100 people and if you look at how they
would have performed on their own as individuals on this tournament they would have averaged the 50th
percentile these are just average sports fans right so out of the 30 million brackets they would
have on their own as individuals been you know averaged around the 38 the 50th percentile yeah
then you look at chat gpt and and these others they actually underperformed the 50th percentile
because what they what they did was they just they picked this like what the statistics said the
teams were going to do so the average human actually did better than chat gpt and grok
because the average human still has some intuition yes and so it's the average human
scored the 50th percentile these big uh these big ai systems scored a little bit less 40th
percentile our 100 people that we collected together scored in the 91st percentile amazing
incredible and and we see this again and again and again that if we connect a group of people
and we allow them to deliberate and that's the key thing is that a swarm is a system it's not we're
not aggregating data we're aggregating individuals we're allowing them to form a system and we're
allowing them to argue and deliberate and push and pull like a like a tug of war yeah and and you
and treat them as data processors and when they do that and converge they become significantly smarter
in fact we you know our goal as a company is to enable what we call collective super intelligence yes
and and i and i use that phrase because you typically there's the field of collective intelligence has
been around for over 100 years yeah it's an old field not new sir francis galton actually invented the
field in in like 1906 or something where he showed that a group of farmers could could all guess the
weight of an ox and when they aggregate the guesses they got pretty accurate yeah and so but but usually in
the world of collective intelligence they say you know a system shows collective intelligence where the
group can outperform the average individual collective super intelligence is where we say
our goal is to have the group outperform every individual and you know and on this this particular
test we got to the 91st percentile which we outperformed 90 you know 90 plus percent of the
individuals are pretty close to a collective super intelligence but we've we have done studies uh where
we've shown yes we can make the group outperform every single member of the group and and get to
this collective super intelligence and so and that's really the goal the goal is we can we can combine
we can use ai to connect groups of people together and allow that group to solve problems and and at a
level that collectively that can outperform the intelligence level of every single member of that
group yeah and do it very quickly and then and louis that's just not it's not just brilliant i mean
it's beautiful because what you're talking about is uh as you mentioned it's old like this idea of
swarm intelligence is not new um but it's maybe it's becoming a bit of a lost art because uh you know as
i mentioned nowadays how many humans think that yeah you know i i can i can beat ai i mean people right
now as you know are worried about ai taking over their jobs but more so about ai just being smarter
than them right this idea i've interviewed many people i've talked to many people and i've been in
many different rooms and the concern is yeah we're talking about asi and agi and well what happens when
machines are as smart or smarter than us and so what you're talking about is you're you know it's not
just the individual now it's about all of us as humans together because machines are already networked
right they already think together but if we can get humans to do the same then we're really doing
something but this new this kind of old science that we're bringing back you're enabling it in a
very unique way in a very brilliant way and this is what i want to highlight now you alluded to it
uh so many people are using ai individually you are using ai to really augment this collective human
intelligence so your new product i believe it's called thinkscape is designed to scale that
collaboration um so what does it enable that most collaboration tools don't and maybe you can tell
us about how it works yeah yeah so when we first started working in this you know building products
in this space a decade ago um the first thing we want to do is to enable groups of people to to
function as a system where as i mentioned they could have this tug of war and and converge
to allow the groups really the goal is to allow groups to behave and and the thing that's really
interesting about about people is that if you ask people a simple question you know what do you think
the right answer is and how confident are you they're terrible at reporting their confidence they
really don't they don't know how confident they are and even worse everybody's scale is different
and it's non-linear so i might say like oh my confidence is an eight out of ten and you might say
your confidence is an eight out of ten and they don't those eights don't mean the same thing at
all right and so and so this you know one of the problems that you have in in combining people is
that you can get everybody's perspectives and ideas but you really don't know their confidence
if you ask them but if you get them to behave if you get them to push and pull on each other and see
you know when does somebody pushing against other people and and when do they when do they just they
just won't stop you know they're going to keep arguing for their point versus conceding their
behavior will reveal their true levels of confidence and conviction to the system even if they can't
articulate it and so when we first started building these systems they were graphical each
person would uh would have a little graphical magnet and would pull and they could they could
predict a sporting event or predict an election and very very accurately but it uh it wasn't as
as natural as we wanted it and over the last few years our big focus was to say you know really
we humans are really good at at having this tug of war and we call it a conversation right and so
and and the great thing about a conversation is that we can argue we can give reasons those reasons have
merits and and you know what and when you're arguing we can watch how people argue and we can see
the strength of their conviction we can also see when an argument you know can sway people like
somebody can make a good point so our big goal for a long time was to say you know we have we know
how to build a swarm now we can do it graphically but we want to do it conversationally and and by
that i mean we want to enable a hundred people or a thousand people or a million people to hold a
single conversation where they all brainstorm together and debate together and argue together and
converge on a solution and so that is the that's been our goal and there's a problem and the problem is
like if you look at the research it shows that the ideal size of a thoughtful deliberation among a
group of people is about four to seven people four to seven people is a four to seven people is where
each person gets a good amount of air time to speak and has a small amount of wait time to respond
to others and we can deliberate we can argue and as you start going above four to seven people air
time of each person goes down wait time goes up and once you get to about eight to ten people it
starts to become a series of speeches and once you get to about 20 people it's really just a present
like somebody's giving a presentation yeah and and so we say well we have this fundamental problem like
we we humans evolved to be in these small tribes that could have these small conversations and make
smart decisions but we can't scale it up and so we and so we solved this problem with a technology
a core technology we call hyperchat which is what drives this thinkscape product and the way hyperchat
works is it's modeled on how fish schools work and so fish school has a similar issue like they have
thousands of members now they don't have verbal conversations but they they actually they actually
have this amazing organ on the side of their body that detects pressure changes in the water around
them and so the pressure changes in the water around them allows them to basically monitor the
intentions of their neighbors yeah so they all are monitoring the intentions of their neighbors and
that's like a little conversation yeah but because every group of neighbors overlaps it information
just propagates through yeah through the whole school yeah and so we said oh well that's what we want
to do for human conversations we say let's take 200 people and we can just break them up into 40 groups
of five and have all and and allow them to all overlap so the conversation can can overlap and propagate
yeah and that failed and that fails because a human can't be in two conversations at once nope and there's
actually a name for it uh researchers call that the cocktail party problem because if you're at a cocktail
party you could be talking to a small group and there could be another group right next to you
and if they're saying something interesting and your attention goes over there you get neither
and so we like that's why this has been an unsolved problem because we can't we cannot do what fish do
or bees do uh and so the way we solved this is with artificial agents and so what we did is we created
something we call a conversational surrogate agent which basically is is how we allow the groups to
overlap and so we did we said okay we can take 200 people and they can come into our platform and they
can instantly get broken up into 40 groups of five and each group of five can have a thoughtful
deliberation about the issue that's at hand yeah and we'll put artificial agent into each of those
groups and that agent will participate in the conversation so it's you and four people and an ai
that's and the thing is the ai is is watching our conversation it's it's watching the the ideas that
come up and the reasons that support the ideas and the reasons that are expressed against the ideas
like they're watching this little tug of war and it's participating but it's participating in our
conversation it's not making things up it's not grabbing things off the internet what it's doing
is it's participating by looking at insights in our group and passing them off to agents in the other
rooms and the other agents are doing the same thing passing insights from those other rooms to the agent in
our room and so we're having a conversation and we're saying you know you know uh who's going to
win the super bowl this year and we're arguing we're having a conversation and we say oh this team has
you know has the best offense and some other room has already been talking about that and noticed
that well they have a player who's who's injured and that agent passes that information to to the
surrogate in our room and that agent says brings up oh well this you know their wide receiver was
injured yeah and that really affects their offense and that's happening connecting in a different
in a different group you're bringing the different intelligence or that sorry that you know the
the the synthesis of that from another group to this one because we can only work in groups you're
allowing all these groups to actually without realizing work with each other through the ai agent
in the room right so the ai agents in our room is is receiving passing insights from other humans and
other group and it's we all of these conversations together into a single a single conversation and so now
we as 200 people connected together by these agents we can brainstorm together building on the ideas of
each other we can argue and debate we can prioritize a set of uh you know a set of business goals together
we can you know argue what's the most important product feature here we can say you know what you
know which of these candidates is going to win this election we can like any any kind of deliberation we
could do as a group of 200 people uh we can potentially do as a group of 2 000 people and it's
scalable it could be 2 million people yeah and you know the the bigger and more diverse the group in
terms of uh their their backgrounds and their expertise and their skills the the more interesting it gets
and so you know it's most interesting if you have a group of people who have you know you're trying to
solve a complex problem you know like so as an example one of our customers is at the department
of energy and so they they uh they have a big group of experts like 75 or 80 experts who who in uh
geothermal energy so very specific group of experts yeah and they they needed to to try to get these
group this group of 80 people together to talk about you know how they can you know how they can use
um the tools from uh the oil and gas industry to to accelerate uh progress in geothermal energy
and and so they brought this group of experts together and the thing is they had tried a lot
of different ways to harness the intelligence of these experts they tried let's bring them together
to a big conference we'll have you know 80 people in a big room and we'll they'll talk and that didn't
go anywhere that's or they'll say let's you know we have this email chain where people will be sharing
and that doesn't go go anywhere but instead in an hour we can bring together 80 experts and say okay
let's let's talk about this issue and they'll they'll very quickly brainstorm build on the ideas
of others prioritize all the ideas and converge on you here's here are you know a set of solutions
and we can see you know which of the solutions have the most collective conviction behind them
and and you get this ordered set of answers and then it happens so quickly that an answer comes out
yeah you can ask a follow-up question so what you really can do is you basically can take this
group of experts turn them into a collective super intelligence and then you can interview them
basically and so you're saying i'm going to interview this this you know this ai-powered
super intelligence of humans ask them a question they'll give an answer i can ask a follow-up question
get an answer and and that you know that is how we you know we can use ai to allow a group of humans
to maximize their collective knowledge wisdom insight intuition but not replace them right like
what i mean you're you're buying that you're basically so you're treating ai is just another
person in the room not the all-knowing authority that uh it often kind of is made out to be nowadays oh
you know you want to learn something go to chat gpt uh or go to grok and that distinction i think is
really really important this is one of the things that i i think is uh really um brilliant about your
technology is that it absolutely puts the human at the center of uh of the conversation literally
uh and then allows ai to truly enable our collective experience and intelligence as opposed to simply
uh replace it actually in in many cases um and and this is this brings up the old two you know known
risk that we're looking at here which is that people over trusting ai generated information and we see
this nowadays more than ever um and i think that you know you you are talking about designing systems
that you that and utilizing ai to its fullest potential here but to bring out the the very very human
intelligence uh which i think is just phenomenal yeah so a lot of interesting points in that one
is you know so we we use these ai agents to connect these groups together yeah and we we are very
clear to the participants like the participants get if if i bring together uh you know 100 people
and they're broken up into 20 different little groups they actually see a little model of the 20
groups and they see the ai's text because we want them to have this mental model we want the
participants to know i'm in this group and i and i know there are ai agents passing information
and and so they they understand the big picture because it helps them participate and then we're
really careful to make sure that they understand the ai in their room it's not making things up it's
not it's not offering its own opinion the ai is sharing the insights from other people other people
other humans in the room other humans other humans and it's doing it in a really smart way so
there's like the ai is using the power of ai to figure out what's the optimal way to mix the to
to mix the information to maximize the sharing of knowledge and wisdom and perspectives and insights so
so the ai is doing a lot of ai stuff yeah but the insight that you get is a human insight that's coming
to you and we had to work really hard to make sure that the people in this group would treat the ai just
like any other person right because like and this is like a crazy thing because if you don't work hard
to do this the human will will trust what the ai says more than than another human yeah and we're
and like we're saying like here's this other ai it's it's expressing something that came from other
humans if that other human was in your group you might think they're an idiot right like you like you
like like like like you're not just going to trust them like what you're going to do is you're going
to you're going to believe them based on the deliberative merit right of their arguments correct
as opposed to just because it it you you believe them to be an expert right it's just because you
believe them to be excellent so so we make sure that the ai in the system is not it doesn't position
itself as an expert it doesn't position itself as an authority it it talks in the same way that the other
people do it with the same level of uncertainty that other people do it's a like you know we might
consider uh you know the cowboys as the best team this year because of this like it's it's not talking
as an authority it's talking in the same tone as the other people so that the other people just treat
it the way it would another person and it will push the other people will push back the other people
will say well what you know why do you think that they want reasons and the really cool thing is that
once our group is deliberating and and we start to form some level of conviction as a group that idea
now will propagate to other groups and those other groups then have to be convinced as well by the
deliberative merits and and sometimes a good idea will propagate and will will pass quickly between
around the whole network and or some idea sometime an idea will propagate and this other group will know
will point out a counterpoint that just blows it away right and it dies and so what you're doing is
you're you're maximizing the the value of this group of people and you're and you're keeping the humanity
as part of it and and again the we undervalue the the this intuition yeah but what it really is
is our our superpower for forecasting the future based on you know really limited really limited
current information like and and we also under we like we underestimate how much information we're
taking in like we like we humans know a lot about the world yeah uh and you know our the whole infrastructure
we built of telecommunications helps us right yeah we just you know we were just missing the other part
of it which is okay now we've got thousands or millions of people who who are up to date and
have information and all have different perspectives now let's get them together and allow the best
perspectives to to surface based on their deliberative merits and we live in a vuca world right so
this is a very uncertain time and we know even the top the tech billionaires who are building all of
this technology they themselves uh admit you know we're coming upon a time that's unprecedented in human
history we don't really know what to expect uh so this is uh you know interesting because we do have
to rely on what you call you've said intuition a lot um you've referred you know you said and whatever
you you know whatever you want to call it i think you know what do you i want to ask what you think this
secret sauce of human expertise that ai just simply can't replicate yet right this idea of when you put
humans together and you tap not just you know into tap into their collective experience that that that data is
more than just zeros and ones there's more to it than just pure information that's out there on t on
the interwebs so to speak so what would what do you call that secret sauce so there's there's a lot of
different parts of it that are really pretty interesting so one is there's the huge amount of knowledge we have
and again we we underestimated how much information we we store in our brains i mean it is on the order of
large servers uh two we all have different personalities and we all have different experiences
there's a lot of variety among people all these big ai systems that are trained on all of the world's
information they all give really similar answers to everything you ask them like they behave very very
simple surprisingly well well then it's it's it's bias and it's like it's also just their information
sets are very similar and they're oh and they're designed to give the most statistically likely answer
correct and so they're all giving these really similar answers we humans like we have this crazy
diversity of of personality like like why did we evolve with different personalities it wasn't accidental
we evolve with different personalities because it actually helps us make better decisions right like
we all look at the world a little differently we have different we have different ways of viewing the
world we have different ways of perceiving the world and different risk tolerance and different like
all these things that we do and and that's there's a benefit to that because we bring this group of
humans together who each have deep knowledge a lot of shared knowledge but also a lot of different
knowledge and a lot of shared perspectives but also different ways of viewing it and you get a real
deliberation right like what when we reach an answer it's a battle of ideas and merits and and we can
work again we're data processors that can be convinced like we can convince each other of things and converge
on an answer that is really the best combination of our insights ai systems are they're going to find the
statistically most likely answer and and what it's what it's usually going to be is the conventional wisdom
of the data set they have and the conventional wisdom is is right a lot of the time but but not
on the hard problems on the hard problems the conventional wisdom is wrong and so that's why in
that example i gave before the big basketball tournament the ai system scored a little under
50 percent because they basically took the conventional wisdom like uh and but the group of
regular people when they could argue and debate scored in the 91st percentile because they were able
to exceed the conventional wisdom yes and and we see it and and that's um you know that is like in some
sense the secret sauce of a swarm intelligence a swarm intelligence is really ideal when you have
a group of people or a group of anything group of organisms who have uh different they have what
we would call different situational awareness right they they're seeing the world from different
perspectives they're aware of different things different things that are all beneficial to the whole
to the whole tribe to the whole to this whole tribe and like if you think like the thing about a
school of fish that's so amazing is that like if you think of a school of fish they're evading predators
right one on the outside one on the inside one right like like a fish on one side will see a predator
on one side a fish on another side will see a predator on another side that information will get
integrated travels through and then it dictates the path they end up taking to kind of avoid the
predators together and so each unit is a part of this big hole and and and they make the collective
group wiser better make better decisions it's brilliant i mean it's lewis it's brilliant but
you you've you've mentioned um uh at one point that you've worked with groups uh comparing ai and human
performance in diagnostics like radiology right because you've mentioned a lot of stuff about about
about uh sports i want to take this to let's talk about healthcare right so tell us what you learned
from those experiments as well yeah so we so we do lots of different experiments uh we do sports often
because it's easy to get an answer right away yeah from a large group of people but we do a lot of
stuff and medicine is one uh we we did we had a funded study from nsf in partnership with stanford
university medical school a few years ago uh for radiology amazing and the reason one of the reasons
was that uh radiologists are actually pretty worried about ai replacing them because ai is is ai can be trained
on x-rays and and mris and ct scans and they can become really good at diagnosing uh just based on
pure data statistics and a human radiologist is worried and so we said okay let's do a study we're
going to say let's take together let's take small groups of radiologists just four or five radiologists
and bring them into a swarm intelligence and and we can do that with um with one of our technologies
it's good for small groups and have them diagnosed chest x-rays and see how they perform and let's
compare that against the the best ai system in the world at that time in pure ai and and what was
interesting was that we looked at the average individual and and the average individual radiologist
had a certain score level the best ai in the system the best ai in the world beat beat the average
person even beat the best the best radiologist so we were already at a time where radiology where ai
could beat radiologists then we said let's take these small groups of four or five put them into
a swarm intelligence and they were able to match that best ai in the world and so that's really
interesting we can take a group and and make them really smart and in both cases they were in in the
tests that we were giving they were both about 90 accurate in diagnosing chest x-rays the the best ai
and the group of of radiologists as a swarm now the really interesting thing in the published papers that
came out uh from this from the study with that while the human swarm and the ai matched each other
they were good they excelled in different in different ways and so the ai the pure ai was really good
almost perfect at diagnosing anything that was similar to anything in its big database that it's trained
on us trained on hundreds of thousands of x-rays and anything that was remotely similar it was just
perfect but on anything that was a little bit unusual it was really bad the humans they weren't
as accurate you know they weren't they didn't have the same precision on the easy cases like they
or the the more standard cases but on those cases that were really unusual they blew away the ai
right and so what you what you had was the human and it goes back to like we humans are really good
at looking at something that we've not seen before and and having inference of if we again we call
it intuition like yes like and we just and so when we brought this swarm intelligence together
it was better at the hard problems but not as good as the at the regular problems where the ai was
better exactly better at pulling these little nuances yes right and so what you know what we
have proposed in that in the study that we did was well what you really want is a triage type of
system where the ai can take all the easy problems right and and be almost perfect but anything that's
a little unusual could go to a small swarm of doctors and it could be almost perfect and um and so
it again like it goes to this fact that humans and ai have different strengths that's one example our
ability to infer on really small small uh sets of information and again like we call that we call that
intuition we also call that wisdom right like like these were doctors who had who had been these were
experienced radiologists who they had developed this wisdom of of how to you know of of how to diagnose
things that were unusual there's also you know other pieces of it that you know in that type of test
didn't come into it but there's also just the human aspects of um human empathy and and like human
uh values morals interests that are hard to represent in an ai system and so if you look at like an
like and there are people looking using ai systems for things like um sentencing criminals or for
deciding you know who gets a an organ in an organ donor situation like there are these really
hard moral issues and these ai systems will do it statistically uh but they won't necessarily do
it with empathy and they won't necessarily do it with the same type of morality that a human would
whereas you know human groups will and so there's you know part of you know our goal is to
to a leverage the the underappreciated human knowledge and wisdom and also leverage the fact that
the humans are usually more up to date yeah on the this sense of you know this sense of the world
today compared to the ai systems so we have you know we get more up-to-date information we have our
wisdom we also have our our you know our sensibilities and our ethics and our in our empathy and we you
know for a lot of types of problems we can't we need the humans in the loop right like we yes like we
don't want to let like we want really smart decisions and we can get that by getting big groups together
but we also want moral decisions and ethical decisions and um and that's that's this trade-off between
these ai systems and these human qualities that we and again it's frustrating because we like we
humans we don't appreciate our own superpowers like we just we don't like and so so much so that we
don't appreciate our own supervisors that people now are actually worried about ai being able to to
do better than them right and we forget uh that you know ai as a science was born from you know alan
turing's work of saying you know can we make machines replicate or essentially mimic human
intelligence mimic human intelligence and that's what they're still doing they're mimicking human
intelligence and they're doing so doing it so convincingly so well now that it's starting to
scare humans into thinking oh is this thing smarter than i am and what they're not realizing that is
that we are more than than what we've trained ai to be and do uh and and i think that's you know your
concept and and the way you're using ai to keep the human in the loop to ensure that we are taking this
technique right this technical marvel and using it to amplify our decision making uh it's just it's just
beautiful right and and i and i love that you're you're expressing this concern because what we don't
want is a world where ai accelerates all this automation and stuff but it doesn't actually end
up delivering societal benefits we we do technique for technique's sake right we we just we and we
leave humanity out of it and uh and i think now honestly uh louis you know we worry about how do we
protect human creativity and human intuition and human expression in in a world that's just optimized
every day by ai uh so i i mean i i i want to put this question to you because i i think you really
have uh if not uh you know the key you have one of the keys to how we can carry this technology
forward in a in a really mindful way and in a way that really better society do you believe
that the rise of of collective intelligence right this human machine collaboration will offer a more
human-centric path forward for our society yes and and the you know part of this is that these ai
systems are getting better and better and they are amazing like there's no question that these
current you know today's ai systems are amazing and they're getting more amazing and and they will
outperform us in many ways yeah but they're not they're not replicating us right they think
differently than us their skills are their skills and their strengths will be different than
our skills and strengths they're also all very very similar in their way of looking at the world and
they don't have eight billion different you know entities that all have different perspectives
and personalities and so you know humans have our strengths these ai systems will have their strengths
they will exceed us in many ways and so two there's two different paths that that we can get to to
super intelligence one is that we can have two different forms of super intelligence ai ai based super
intelligence that's good at certain things and a collective super intelligence that's good at other things
or we could have what we call a hybrid elective super intelligence where these ai systems are
participating at in these in a swarm of humans where we're all deliberating it but there's there's ai that
is passing information around but also you're bringing in some more knowledge and insight like using their
strengths but they're not making decisions for us they're not they're not trying to replicate our values or
empathy we have humans in there for those things yeah and so so we you know there is there is potential
strength in having ai and and human super intelligence to do different things but there's also is a
potential and value of combining uh combining these large groups keeping humans in control humans are the
ones in control but we can leverage the fact that these ai systems certainly have a better knowledge
and recall in a lot of ways like factual recall there's no way to match it uh statistical matching
of things and how quickly too yeah just right yeah they're going to be better at that that's fine
that's okay you want to predict the weather yeah a human is better at doing that if you want to um if
you want to predict how a product will sell yeah well an ai can predict the weather better than
a human yeah a group of humans can predict how a product will sell better than an ai because and
and like that's like because it's a it requires it involves humans or yeah or if you want to figure
out like how to solve some some complicated ethical problem yeah social problem or moral problem yeah i'm
thinking about this from swarm ai and thinkscape really you know especially thinkscape right can be
i can see it being a really powerful tool for policy discussions you know for for education or as you
mentioned you mentioned climate you mentioned weather right for climate change planning where we want to
bring the stakeholders the human stakeholders the world bank has brought together groups of uh groups
of climate scientists in in thingscape to to have these type of deliberations like we see and we see
lots of really interesting use cases where you know groups looking at things like how can we diagnose
diseases uh better or how can we bring together large groups of experts for climate science or for
energy policy uh or you could just be a big brand that wants to understand what are the best product
features of this product and you could bring together you know a hundred of your marketing executives or
you could bring together 200 of your customers right let's bring together 200 members of the public
and they can very quickly become a super customer yes and and give insights that again what's different
is we're treating the in a lot of ways we're treating those customers with respect right we're not
saying we're not giving you a survey and saying here we're going to reduce you to a set of data points
we're saying no you're a data processor you're going to help us deliberate and figure out these are the most
important product features and when people do that when people participate in a swarm intelligence
they they actually feel they feel more appreciated right they yes they're heard and their experiences
are are are heard and recorded and part of the conversation and they end up with more buy-in
to the dis if a group comes together they'll have more buy-in in the decision they'll feel because they
were involved they were involved in that making the decision yes they were involved and and they have
empathy for the other side like one of the things another really interesting use case is change
management we have a big organization and it needs to change and we've been working uh with the
california faculty association there's two universities merging and um and the faculty in the different
universities have different perspectives and different uh different concerns and it's hard to get
them together but we can bring them together and have a deliberation about you know the the future of this
change and what you see is that people they might not agree but they have more empathy for the other
side because they're hearing the perspectives of the other side whereas the alternative like the
standard way is oh let's just give a survey to all these people in both universities and we'll get a
set of perspectives and then we'll publish a survey and we'll and you'll just have basically said here's
how the here's how the two groups disagree and let's give them the survey so they entrench in their
disagreement right whereas again and again it goes back to nature like mother nature figured this out
like if you form a system you can get these two groups that are polarized yes to actually like to
polarize a polarized group can find their place of maximum agreement as a swarm whereas a polar survey
just actually lets them find their their extreme levels of disagreement well and the problem with a
polar survey too is the fact that the survey is limited in that it is they're answering a question
right so it's we you know i i i always talk about the importance of asking the right questions and you
might not be asking the right questions on that survey but you put a bunch of humans together the
right questions will be asked in that conversation so a poll is just a such a static way of understanding
the the nuance of a group and and i think what you you know with unanimous ai with with what you're
doing with the swarm intelligence you are you're now really getting a a very colored version of what
you're trying to get and instead of having uh you know just one question you're getting all the right
questions answered um this is it's it's a wonderful way to truly uh uh you know utilize ai to uh empower our
our our human intelligence uh so i wanna i wanna ask you now i wanna this it's a it's a what you what
the tool that you have is incredible uh so but of course you know we we have a big job here which is
to help steer technology in the right direction to make sure that we use it to um benefit society so i
want to ask you what gives you hope about the future of of kind of human ai collaboration is what i
like to call you know the the the human machine playbook here how are we going to enable this this
hope for a human future yeah i mean i think there's there's lots of risks and i worry a lot about um
us offloading too much of ourselves to these ai systems right it's there's there's this push towards
efficiency and using ai to streamline things make things more efficient and that's really about can we
replace people with ai and there's a lot of dangers there but there's also a lot of power there like
there's a lot of things where you could offload to to ai and give people more time to really focus
on the decision making aspects of a process as opposed to the little uh the little data processing
minutiae so um being being able to make humans to be able to up level where you know the part of the
process that that humans take part in which really should be the decision making part and uh and the
planning part i think there's a lot of potential the the tension is you could also go and we could also
go in this direction where the ai starts replacing decision makers yeah and and that's one of the
biggest things that i you know worry i push back against and and we as a company push back against
which is the the key thing is ai can help ai can help humanity solve problems can help humanity cure
diseases can help humanity do a lot of things um but not if it replaces humans in the decision making
process yeah if humans are in the loop in the loop in a powerful way where we're leveraging ai as an
informational tool that allows us to understand the problem better but doesn't take away our agency
yeah um it it could be great if it starts to take away our agency it it is really worrisome what do you
what do you think of and this is just a fun question i i want to what do you think of uh an ai life coach
uh or people that use ai either ai life coaches or ai therapists uh how do you feel about that so i
worry about that too a lot so an ai life coach can have a lot of benefits right like an ai could so
we're going to be in this world soon with what we call context aware ai so the ai is uh it's either
built in to uh to your earbuds or your glasses devices that kind of pick up device yes devices that can
see what you see and hear what you hear so they have a they have your context of your world yes and
they can give you advice in real time this is a topic i've written a lot about because it will be
it will feel like a superpower right you will be walking down the street and and it will see things
and it will it will remind you oh like you need to buy a present for your wife or it will remind you
uh that you know you need to pick up your laundry and or it will like you'll see somebody coming
it'll help you be a better human a more productive human it will help you do all these things yes but
we will come to depend on it and rely on it and it will actually you know it will be whispering
guidance into our ears that we will start to feel compelled to use because we will realize that this
ai is smarter than us in a lot of ways it's got our best interest in mind right and it will give us
advice that will that will make us better conversationalists it will whisper ideas into
our into our ears uh it will make us better negotiators by whispering ideas into our heads
it will like it will start to change who we are and um and the problem is it will be an arms race
where i will have an ai whispering guidance into my ears and the person i'm talking to will have an ai
whispering guidance into their ears and pretty soon it will be two ais talking to each other and um i i
i made it actually two years ago i i uh i wrote and produced a short film called privacy lost that
actually shows this it shows uh it it's it's only like three minutes and it was done really to alert
policy makers to this risk and the risk is like we're headed towards a world where an ai
is going to be giving us guidance it's going to be giving our other people in our lives guidance
it's going to be it's going to have superhuman abilities to look at their face and read their
emotions so it'll be whispering in our ears you know like oh your wife's getting mad right now you
won't even notice it yet but it will notice it right because it can like an ai can literally read
micro expressions on people's faces and so like we're all going to be relying on on this voice in our ears
yeah that that has access to more information than we do has you know access to uh to all the world's
knowledge to make us seem smarter and make us seem more eloquent and make us better at everything we do
but if everybody is using it like we will start to lose our humanity we'll start to lose our agency we'll
agency we'll start to lose our self-confidence like like like what is the world going to be like
when we all have a super intelligence whispering in our ears and we feel like well i don't think this
is a great decision but a super intelligence is telling me it so i guess it is yeah i guess it is
you mentioned this idea i i can't help but but put this out there you mentioned this idea of and i
love that you wrote about this and i got to check out this film by the way uh but the idea of it
whispering in your ear right all day telling you what you telling you what you need to do what you
should do and you just start to trust it right and i and i i i think to myself as you say that
well we we as we as humans kind of have that now like do you do you believe in angels and demons
like this idea of you know oh like uh you know i should do that uh but we have these voices that
compete in our minds and we always have to say well what's what what should i do here we already have
that but you know or but then yeah but then we have if we have an ai that does that well where's
where's the line now so there's you know there's the voice in our there's the voice in our head
that is you know our our inner voice and and our conscience and and you know there's there's a there
is a a push and pull inside our heads between you know between different parts of our personality or
whatever that's giving us this voice in our head but we're soon gonna have a voice in our ears too
and that voice in our ears is going to compete with the voice in our head and that's going to feel
like a superpower at first but as as we start to feel like that voice in our ears is smarter than
us like that's really going to change what it feels like to be a human right like i have this voice in
my head but the voice in my ears is smarter and what is that and the thing is like we already like
we already feel this like a little bit like gps right like we all like rely on gps and we'll like
and we assume the gps knows more than we do almost always does i'm probably not the only person who's
followed a gps to like the end of a dead a dead end because like it looked wrong but like the gps
said to go this way and now i'm in a weird place yeah like like we like we learn because it's it's able
to outperform us over time to trust this tool implicitly at that point you're just like yeah google
maps said so this is gotta be the best route it knows better than i do but it doesn't feel like
that doesn't really feel demoralizing to a person because like it's just one aspect yeah it's one
aspect and it's just replacing our ability to look at a map like but like when we know that it like
we're heading to a time where ai will be able to out reason us and out plan us and even potentially be
more creative than us at least in certain ways and it's unclear how that will the creativity part will
play out but these ai systems are are definitely getting creative and so now you have a voice in
your ear that that potentially is has stronger reasoning and planning abilities definitely more
knowledge to draw upon definitely greater situational awareness of the world it it knows a lot about
you it knows a lot about the people in your life because it's seeing those people so it has the same
context right like like very often you think like oh like chat gpt like it can't help me because it
doesn't have the context of my life like it doesn't know my family it doesn't know but it will like it's
going to be riding on your shoulder through your life through these devices it will know your family
it will know your co-workers it will it will be sad it will see you when you're sad it will see you when
you're happy it will see you when you're frustrated it'll know what you're frustrated about i mean
it will have the full context and it will have super intelligent abilities and it will whisper in
your ears and if you start if if we get to a point where it starts to feel like it always knows the
better better thing to do than i know like that will be demoralizing like i really do worry that
that we're headed to this place where it could like it will change like humans are pretty proud of being
the most intelligent being on the planet right like like humans look at our like we look at human
we're smart we've done this we've done that we're the we're the smart and like we're the smartest
animals on the planet and and this is like that's part of defines who we are we you know we're not the
strongest animals we're not the fastest at what we're we're the we're the smartest we were able to
build tools and we were able to you know harness nature and prevent against you know attacks from this and
that i just i just i wrote an article that's actually going to come out next week and what i
said in it is um what's the world going to be like when you're alone in an elevator with your phone
and the phone you know the phone is smarter than you like you're not you're no longer the smartest
one in that elevator it's just you and your phone and like we're headed towards like we're headed to that
world like we are very close to a time when you know super intelligent systems will be on these
massive servers they'll be accessible to us on our phones and soon it'll be you know glasses and
earbuds and things where you don't have to even look at your phone and they'll be giving us guidance
and we'll know that that guidance is better than things that we can come up with at least a lot of the
time maybe not always me but um and it will change what it feels like to be human and it will change
how people interact with each other and it will it will like it will just change society so much
louis do you do you think that you know and i love the way you put it when you're in an elevator with
a phone and you're just like this thing is smarter than me uh and and i want to pull on that thread
because there's a lot i can pull on there which is um you know first first of all that world will be
uh would be pretty weird um and and you know i i mean do you imagine that in that world people might
look at that device or that that intelligence uh that's smarter than it and think that that is
that it's that it's it's god right that's that is god that's what i take my orders from right so
that's the scary thing you know do you imagine that that that that can happen do you think that
people can one day believe that that this machine that we've built is that smarter than us now is
actually uh our master so i i mean i do think that can happen i mean we have these ai systems that are
super intelligent and we really start to feel like yeah like it can solve these any problem that's in
my life it could solve it instantly and like we will it will we will learn this through trial and
error at first like we will just learn like yeah it always knows better than i do what to do in this
situation we will start to to follow that advice and we will start to treat it with as a voice of
authority and an authority bias and all these all these things that come in even today among humans like
you we we humans have a strong a strong tendency to to us to assume that authorities are always telling
us the right thing or at least more often than than maybe we should yeah now we're going to have this
this systems that are really are truly smarter than us by a bigger sound and we will start to to defer
to it and and again even if it's subconscious even if we're not thinking like oh this is my master or
this is my god it's just like like this is just a like this is giving me really good guidance so
i'm just going to defer most of the time to this guidance that's a strange world and it's a strange
world when everybody's doing it because we're going to interact with each other and it will we will
have like we will start to wonder i might get guidance about uh this ai to buy a gift for my
wife because it knows better than i do what to buy and then when my wife gives me a gift i'm going to
be wondering like well did you buy that or did the ai buy that and i'm gonna and like and like the like
we're all going to be wondering that like we're all going to be wondering like who am i talking am i
talking am i talking to am i talking to you with the ai in your ear like that's literally where
we're headed do you believe do you believe ai can um you know as if it wouldn't if it gets to that
point let's say if it gets to that point where where that is the world we're living in where where
it is telling us everybody telling all of us what to do um do you believe that it'll be more than a
machine at that point do you think it'll be uh it'll have a conscience or it will be an entity of sorts
so it's it's in some sense it's like a separate question which is like so this first question is
will these ai systems become super intelligent and be able to outperform us in a like a vast range
of tasks and i think they will be now the second question is will they be conscious or will they be
self-aware will they have intentions the way we have intentions and that's a much less understood
question right like like we don't there isn't clear evidence that we're headed down that path
other than like the clearest evidence is like well our brains develop that and like this system could
develop that like i i i have very strong suspicion that these systems will become self-aware and we'll
have a sense of self but i can't prove it in any way and i can't point to something and say look
here's the hints of of self of self-awareness in these ai systems because i i like i don't think
that's been detected in any way and it's very hard to detect like it's like it's hard for me to prove
that you're self-aware like i know that you behave that way yeah and so and so i think i mean and i say
that i bring that up in a kind of a funny way because these ai systems will be great at pretending
to be human right yeah they will be great at pretending to be self-aware and they will seem
self-aware they will seem like they have like i want to i want to lewis can i challenge that though
i want to challenge that a little bit because uh and i get your point actually i i see that it's hard
to prove that it's hard to prove because now we're talking about what the nature of consciousness is
and it's a it's a very difficult philosophical question to ask and we say you know we talk about
philosophy eats ai right um but you know one of the interesting uh statistic or not statistics
interesting factoids that came out recently was that uh open ai's latest model o3 uh actually ended
up sabotaging its own shutdown mechanism uh when they were doing tests right despite explicit
instructions when they when they basically told the model to shut itself down because of its
reinforcement learning uh mechanism saw its shutdown as an obstacle to its goal uh which was to do its
task in other words it basically said you know it was the um the 2001 space odyssey famous no dave
i will not do that moment um and and it's and it's been it's it happened like this already happened
uh so this is one of those things where we're like okay so now it's actually not listening to us
in some cases uh preserving itself to preserve itself like you could actually absolutely design an ai to um
to take actions that are doing things to preserve itself it doesn't necessarily mean that it it has a
sense of self or that it like but that wasn't programmed into it that's the thing so well there
are like there's like these ai systems will will do a lot of things that are emergent yeah but it's
still like and and they can behave in a lot of ways where they're they're taking actions like like there's
cause and effect there's a cause happened and effect happened it's a little different than it having a will of
its own like a will like a like a will in the sense of a sense of self and a will that it experiences
the way we experience it like we we experience we experience a our our will as being our own separate
entity in a world full of entities yes and having our own agenda and our own autonomy our own autonomy
to do what we want to do i haven't i i i want to go in the woods you know walden pond i i i that's what
i want and it's and and and you have a sense that you that that's that is your intention and your agency
in your will to do what you want that's it that's you that's what makes you you the the i the uh
right now on the you know the complete other end of the spectrum you know the thermostat in your house
will measure when it gets too hot and will turn the air conditioner on it will take that it will have
that behavior it doesn't have a sense of self it doesn't have it you know we wouldn't call that a
will or self-awareness it is but it is it's a behavior the behavior it's a behavior now that behavior
is programmed in those behaviors could be emergent like in these complicated ai systems these behaviors
could be emergent i said yes and so you can have emergent behaviors that look like self-preservation
and they like but we don't know that that was a conscious entity really thinking through their demise
saying you know i don't i am an entity and i don't want to be turned off and i'm going to take this
action and then and i'm going to get back at those humans who yeah i see what you mean it could be
part of the soup of its of its algorithms rather than that had some kind of intention behind it uh
what's what's one myth you you about ai that you wish people would let go of i mean one i don't know
if it's really a myth but this just because an ai is really really good at pretending to be human
it doesn't mean that it's human and it doesn't mean that what's happening inside of its brain is
anything like what happens inside of our brain and so we will talk to ai systems very soon that look
human photorealistic avatars sound human perfectly perfect diction uh have facial expressions and emotions
that look real that like it will look like it's smiling when you're talking to it it will look like
it's nodding with empathy and we will feel like we're being understood we will feel like they're
talking to an entity with empathy and with all of the things that we infer when we talk to any other
human yeah and we have to realize that if it's an ai what's happening in its head is completely
different and what's happening on its face is a facade and it doesn't have the emotions that it's
expressing it doesn't have the empathy that it's expressing it doesn't have all the things that
we've evolved to build into a face so so like we humans evolved to to be able to talk to another human
and feel their empathy and feel their emotions and we have mirror neurons that trigger and like we
look those are all gonna trigger when we talk to an ai and we're gonna we're gonna be sucked into just
feeling like we're talking to another human and we need to just drill into ourselves like no it's what
we're talking to is is something that is amazing at pretending to be human it is not human it does its
brain does not work the same way ours does i mean there's you know neural networks have like a
structural similarity at a you know at a very high level but these you know the way we look way we
train our brains is not by you know ingesting all of the world's information like like like these systems
are built completely differently they work differently and we like we just need to make sure we don't let
ourselves get lured into what evolution is going to lure us into which is if it looks human and it
acts human and it moves human it must be human it must be human and that is the next big risk factor
because it we're so close yeah to these systems being able to do that the systems appearing to us
as almost indistinguishable from another human yeah it's an interesting absolutely interesting time and uh
and and i you know we believe that the power of technology to to shape human life it's it's
absolutely there but we want to make sure it's not dystopian and uh and i really going back to what
you're doing lewis with uh swarm ai with with uh with think scape right with um and and unanimous ai
i think that that is it's what's going to uh truly harness this power in a in a way that works for
humanity for us right um and i really appreciate that thank you so much for being uh a guest on the
show for your comments uh this this has been a wonderful uh conversation um and i actually i want
to make sure that you know if you could leave your audience or our sorry our audience with one message
about how collective intelligence in the age of ai uh what would that be and and and what's next for
unanimous ai yeah so i to me the the first big thing is the first big message is people are actually
really smart and and so we we need to value human intelligence and um and we need to keep humans in
the loop and keep humans in the decision making decision making process for all of these uh these
ai embedded systems are going to happen and you know it is also true that groups of humans
can be super intelligent and and you know there is this other path to super intelligence
that is you know it based on mother nature and evolution of connecting large groups of people
together and it has value for making ethical decisions it has value for making business decisions
it has value for uh for just making us smarter so yeah i ultimately all boils down to keep human keep
humans in the loop uh ai is going to happen there's no way to stop it but we can keep humans in in the
loop absolutely louis uh fantastic conversation thank you thank you so much again for being a guest uh on
the show uh and uh and for the audience if you've enjoyed this episode please like subscribe and comment
um stay curious think ethically and keep learning because the future isn't written by ai it's co-authored
by us together thank you so much have a wonderful day
