This is the Knowledge Graph Insights Podcast, episode number five. You might think that the
lofty perch of multiple decades in industry analyst roles would inspire grand visions
of tech transformation with leading-edge technology. Quite the opposite in the case of
Alan Morrison. He shows how enterprises can advance their data maturity by cultivating
basic graph thinking in their organizations and by taking small, pragmatic steps like
adopting established standards for interoperability or simply adding metadata to a
spreadsheet. Welcome to the Knowledge Graph Insights Podcast, where experts on
knowledge graphs and the semantic web share their wisdom with the digital and
business communities. Our mission is to demystify and democratize knowledge graph
technology and practices to make the benefits of knowledge graphs and semantic
technology accessible to all. And now, here's your host, Larry Swanson. Hi, everyone.
Welcome to episode number five of the Knowledge Graph Insights Podcast. I am really
happy today to welcome to the show Alan Morrison. Alan is currently, he's a
contributor at Data Science Central, a well-known publication in the field. He's a
freelancer and consultant around knowledge graphs and a lot of other areas as well. His
background, he comes out of the consulting world most recently before his current role
as a freelancer and consultant. He worked for many years at Price, Waterhouse, Cooper, the
big consultancy as a senior research fellow. So welcome, Alan. Tell the folks a little bit more
about what you're up to these days. Hey, Larry. Great to talk with you. And folks should know
that you and I have some history together as a part of the Data Worthy Collective, which is
like an informal meetup group, collaborative thinking going on every week. And it's been great
to know you over the years. What I'm doing currently is trying to help the Knowledge Graph community
in particular, gain more visibility, gain more traction in the enterprise. And it's a long haul.
Enterprises are slow to change. It's like, you know, turning an oil tanker on a dime. It's very,
very hard kind of thing to do. And so there's so much legacy involved. And so when I was at PwC,
we worked with a lot of large companies, and you'd look for pockets of innovation. And you'd look for
the foxes instead of the hedgehogs, because the foxes were the ones that were curious about doing
things different ways. The hedgehogs are the ones who were expert in doing things in one way. So we had
this kind of guerrilla approach to innovation. And we also worked with the centralized innovation group
inside the firm to try to help the firm itself modernize. And so in my last five years at the firm,
I was plugged into the AI efforts that were emerging because machine learning was becoming much more
feasible. And so I've taken this knowledge that I have of AI and the semantic web, so called an old term,
but it still has utility together. And I'm just trying to help enterprises see the advantages of these
things and adopt them to the extent they can be.
Well, you just said how hard, notoriously difficult it is to get enterprises to think and act differently.
But they're all jumping all over AI like it's the best thing since sliced bread.
So it seems like there's a little, but there's a lot of opportunities there, it seems like, to
not ride the coattails, but to enter the conversation around these new technologies. And there's a lot of
kind of interplay between generative AI and machine learning and LLMs and all that world.
And the knowledge graph world. Can you kind of stitch those worlds together for us a little bit?
Yeah, I think it's, it's good to do that. It's good to step back and say, you know, what are we
trying to do here? How are we trying to do it? And we've got some piece parts that are talked about
in the media ad infinitum. Generative AI is just all the time in the conversation because
it's, it's a powerful interface technology as it stands. And some enterprise providers are using GAI
as basically a front end, and then they will connect their own back end. And so,
you know, I think you have to think about generative AI and other kinds of AI in the context of this bigger
picture. And it's all driven by data. It's, and when we say data, we don't just mean binary bits.
I think we mean, ideally contextualized information, knowledge, getting wisdom, and decision making capability
to the right point, where it's actionable at the right time, for the right purpose. And so it's,
it's a distribution problem of knowledge, essentially the right kinds of knowledge. And, and so
you really have to think about data. And this is where I get passionate about it, because
you know, the information is really the heart of it is in this is in this contextualized environment that
should be being built. And it should be an organic kind of effort that involves both humans and machines.
And I'm a woodworker. So I think about machine learning as a kind of a table saw, you know, and,
and so the knowledge is like the wood that you're working with, you know, it's an organic thing.
And, and so you're, you're using all this different kinds of tooling. I got a lot of different kinds of
tooling in my workshop. And I'm not a great woodworker. But, you know, I think that
the source of the wood is really important, what kind of wood you're working with. And, and, you know,
we could do all sorts of things if we had the right resources inside of enterprises.
enterprises are really starved for good data. And they just are not in the habit of collecting it
very, very well. And I was, I was in intelligence in the Navy when I started and
just collecting voice traffic and analyzing it. And it was so systematic about how the data collection
happened. There was this whole data lifecycle environment that, that we were a part of and
everybody was managing according to the needs of that. And I just think that that was a very effective
way that enterprises could take advantage of to really collect what they need to and just understand
if you're going to digitize things, you have to have this continual process of collecting and analyzing
and managing this information. And it has to be organically constructed so that it's scalable and
it does what you need it to do. So, you know, that's basically where I've been focused over the past years.
Yeah. The way you describe that is so evocative of like, you know, like the wood, I love the
woodworking analogy, but also that your military experience, like there's, I think any enterprise
would argue that like, you know, that they're, that they would claim to attribute the same importance,
you know, or a similar level of importance as like Naval intelligence data, but you know, whatever you were,
whatever you were researching and yet they have these sloppy data practices and, or not, if not sloppy,
at least not thought through and, and, and sort of sub optimal. Are there, I guess, can you talk about,
well, two things, one, how could they be better at like that data hygiene and that data, um, practice
that you just described that was so well entrenched in your Navy days? Um, and then how, in particular,
how knowledge graphs and the whole world of like semantic tech, um, can help you do more with that
data once you, or, and is it a prerequisite to have that good data hygiene before you can do the cool
stuff with knowledge graphs? Uh, let me, let me start with the last question first. Um, it is a prerequisite
to have a certain amount of data maturity. Uh, when I was at PWC, we had a data maturity curve
and, um, it was frustrating to see that most of our audit clients were not terribly high on that
maturity curve. And I think the tooling gets in the way. Um, there's so much siloing that has gone on
over the decades. And, um, so many folks, including me are in the habit of just using certain tools. And so
the learning curve for learning something new is, is a bit steep. And so what's happened is that, um,
we've just proliferated these data silos that, that have limited utility in a short lifetime when you
could be just contributing to a much larger ecosystem that's shared and reusable. And so, um,
um, I think that there's just a, um, a mentality that goes along with the tooling that needs to be dispensed
with. So you could start up say, uh, a grill grill a team that just tries to do these, um,
these domain description kinds of exercises. You've seen pharmaceutical companies do this for years and
years, um, because they have to, um, do drug discovery at the molecular level and they have
to track things at the molecular level. So it's, it's very precise and detailed what they're doing
and they're still using spreadsheets, but they're S they're describing their, their findings in the
spreadsheets. And then they're making the spreadsheets part of this bigger knowledge graph mix. If they're,
they're, um, advanced. And so what you're seeing is the ability to, to do more metadata, let's say,
you know, semantic metadata, simple stuff, not complicated stuff, and just put enough of it
in a spreadsheet. So the spreadsheet is shareable and reusable in a sense. And so, uh, you're seeing
this in financial services too, where we've got, uh, the OMG, the object management group is working
on a standard for, uh, smart spreadsheets, you know, so we're trying to de-silo to the extent we
can. We're taking it a step at a time. Yeah. That's interesting. And when you talk about silos
and guerrilla teams, it's like, and there's this truism in consulting about, you know, just start small
and just start someplace and anywhere. I'm curious about these guerrilla teams that you would assemble
back in your consulting days. Cause that sounds like, I hope that a lot of my listeners are going
to be people who are in organizations that are like, oh, come on, we got to do something with
this. And they're going to be chomping at the bit. They might have big ambitions. So I guess,
first of all, like, you know, uh, and I get, I'm as guilty of this as anyone at first, like scaling back
your expectations and your ambitions, but also with the awareness that if you crush it at a small scale
that you might get bigger adoption. So I guess, but my question is like, what are those guerrilla
teams look like and how, how do they work? I sort of backed into this, um, years ago when we started
writing about the semantic web, so called back in 2009, uh, we were publishing a quarterly called
the technology forecast and we were looking at, um, business intelligence. What's the, what's the
stumbling block in business intelligence? And of course it's, it's having enough of the right data to
make good decisions. So you have to bring in all these different sources, these heterogeneous sources,
not only structured data, but less structured information. And so that was the starting point for
thinking about what organizations should do with their data. But, and within PwC, I wanted, once I,
once I had researched the topic, I got so interested in how this could be really a big thing and could
really help companies if, if they were to bring together all this heterogeneous information in a more
integrated and interoperable fashion. Um, so, you know, I started working with client companies and
internally at PwC with innovators who, um, were as passionate as I was about
organizational change and, you know, bringing these organizations up to speed in certain ways.
So we're really sort of working against the conventional org chart, the hierarchical org chart.
One of the things we, we knew to do was to, to sort of build our own informal organizations.
So we, we had the flexibility and a consultancy to, to sort of be tribal in how we organize. So we built
our own tribes and, um, partners who were
powerful partners would be the tribal leaders. And so you'd look for partners who had budget,
who could fund innovation projects. And, and so I think the same dynamic happens in a command and
control environment. Like, like the military, for example, I've seen champions emerge, for example,
in the department of Homeland security, uh, people who have, uh, a border control board, uh, border patrol
background, um, working to advance the, the cause of adopting knowledge graphs, um, for border security
and detecting and, uh, inter, intercepting, uh, drones, for example, on the border when they're
trying to smuggle drugs or guns or something, you know, um, same, same principle applies. Um, you, it's
just, um, it's harder to do inside a command and control environment than it is in a, um, a loosey
goosey thing, like a partnership, for example.
Mm-hmm. Yeah. And that, I love that guerrilla pressure, but kind of what you're getting at too
is, um, about the, the power and the benefits of a knowledge graph. Like you were talking about the
heterogeneous data, the structure and unstructured, just sort of this mishmash of stuff. And can you
talk a little bit about how a knowledge graph helps pull that, or maybe not pull it together,
but pull information about those kinds of bodies of data into a way that is more powerful and useful to
the organization? It's a great question. Um, the, the experiences that I've seen have mostly been
failures when it comes to these kinds of efforts over the years. And you think about, they've been
useful failures and, and I, I've had good friends who've been involved in these failures. Um, but the
situation has been that we're trying to boil the ocean when it comes to, uh, a model of, um,
of the data, uh, a unitary model of the data that brings all the data together so that you've got a
model of the business essentially in an enterprise. And, uh, this is something that Dave McCombs,
Semantic arts preaches all the time. You want to rationalize that model. And so I, I saw a model
at IBM back in the 2010s when they were working with ontologies, they were trying to get all their
software, uh, together, all their software development efforts together with a, with a knowledge graph at
that point. And they had, uh, over a thousand, 2000 concepts or something. Um, it's just a monster
thing. Um, FIBO was another effort, financial industry, business ontology, just a massive effort
of, of these big banks to, to try to model the environment that they needed to use for reporting
purposes. For example, um, it's much better. It's much better to have a few hundred concepts at, at,
at maximum, and then focus on domain specific efforts that will articulate the domain so that
you start to get a sense of these contexts that I was talking about and how the context fit together.
So the knowledge graph is essentially a relationship rich approach to connecting these things and
studying how they interact. And the thing about the way AI is currently done by comparison, uh,
AI currently with machine learning, it's, it's sort of like, um, a recipe in a kitchen, you know,
you, you put some of this ingredients and some of that, those ingredients in together and you mix it all
together in a mixer. Um, this is not really helpful for, um, disambiguation, you know, um, comparing
apples to apples, certain kinds of apples to apples, or certain kinds of molecules to other kinds of
molecules. Um, knowledge graphs have to be articulated in the relationships in the entity relationship models.
are what art makes the articulation possible. I'm married to Lee. So the fact that I'm married to Lee
leads to all sorts of interesting things about our history together. And that history together is
a context. My family is a context. And so similarly with organizational change,
you want to be able to model the organization, the people inside the organization, you want to empower
them. And so it's good. It'd be great if you could have the organizational change people, um, get together
with a knowledge graph, people build a knowledge graph about organization, about the organization,
and sort of empower the innovation, you know, do what, do that kind of thing we were trying to do
back in the day with our innovation groups, you know, that's interesting. But you you've mentioned
you've written fairly recently on LinkedIn about, um, I thought it was a success story about, uh,
about using, about using a knowledge graph is, I don't know, like, like I think in my, a lot of my
consulting and contracting work I've used, I think of all my deliverables, not as final deliverables,
but as conversation starters or conversation continuers, you know, that like, it's never
done and you never figured out. And, and so when I read that post, you, you, where you were talking
about knowledge graphs, that's how I was kind of picturing it. Like, hey, let's gather around this
knowledge graph and see if it helps us understand the org better. Was I reading that right?
Oh, absolutely. I, you, you have a, a whiteboarding dynamic, um, ideally where, where you're, you're
talking about the, um, the entities in the relationship. So you're representing, you're
basically representing, um, at a high level, um, the, the, the organization and the problems you're
trying to solve together. How can you best utilize the resources of the, of the organization to solve
certain problems? And so, um, you know, people do this all the time on whiteboards. They're always
drawing diagrams on whiteboards. Um, you, you always see mind mapping going on, but, um, this is the
knowledge graph is, is just an extra step that, um, articulates the digitization of it so that machines
can help humans do more with it. You can actualize the model that you've come up with on a whiteboard
in a knowledge graph environment. I mean, that's where we should be going with this technology is,
is kind of a Miro kind of thing that people can work on together and then activating it, you know,
uh, that way the, the enterprise architects would be much more empowered to do what they're supposed to
be doing. Yeah. That's a boy. You're preaching to the choir. That's I'm, I'm working with a friend
now on trying to get the precious data out of Miro boards into something more manageable and useful,
but just the way you talk about that. I love that, that description of, um, the, you know, like that,
that these are activities we're doing anyway. And I think one of the appeals of graph technology is the
nodes and edges, just nodes and connections between them. And, and which is very much like the things you
sketch out on a whiteboard in a, in a, you know, workshoppy kind of session, but the power of the
graph, and you just alluded, you just mentioned this as well, is that it's articulatable, those
connections, those entities and their relationships are articulatable in a way that both humans and
machines can understand, which I think is kind of the fundamental power of the knowledge graph.
Is that correct?
Yeah, certainly that's a big part of it. Um, I, I think of it in, you know, being a woodworker,
by hobby. Um, I think of it as sort of tinker toys. Um, and I don't know if many people are,
know what tinker toys are, but you've got a wooden hub with holes in it. And then you've got sticks that,
uh, that, uh, you, you used to build something and you can build, um, you know, three dimensional,
any kind of three dimensional object with tinker toys. And in a, in a knowledge graph environment,
the only difference is that you've got the potential for all sorts of different dimensions and humans can
only comprehend a few dimensions at once, but machines can go far further. So, but you can sort of,
um, design the interface so that humans have what they need and machines have what they need.
And then there's a coming together of those, those understandings in the, in the, uh, enriched
information and, and the, uh, the data and the metadata. Yeah. And that, and that, that, um,
interaction, I want to kind of swing back a little bit to the, the gen AI stuff and LLMs,
because you mentioned earlier that like, that's sort of the interface for a lot of this now,
and there's emerging architectures that try to like, I get the, it's like, you're trying to get
the best out of each of those kinds of technology. Like the people love the conversational interface and
conversing with their data aspect of like a, an LLM, but, but all those benefits you've just been
talking about, about knowledge representation with a knowledge graph. Um, what are, how do you,
it seems like there's been like just the last week or so Microsoft announced their graph rag,
um, uh, uh, uh, scheme, and there's many other, uh, rag and kind of things out there.
Um, what do you think is going to be the most like productive way or the, or the kinds of
architectures that'll emerge to get, to kind of optimize the, the benefits of these two sort of,
um, complementary technologies? Uh, yeah, I think there, there, um, needs to be a fuller picture
of all the things that could contribute the most to this kind of environment. And, um,
when you're, when you're focused on the knowledge graph space,
you learn a lot about different kinds of databases. And, and so the database people
in this space are really super smart and they're doing some really interesting things
and that stuff should not be neglected. Um, I think that that stuff is just as valuable as what's
going on in generative AI and neural networks. And, um, I think that, you know, one of the frustrating
things about web development and, and, um, data science is that there's not enough attention paid to
all the techniques that, that are still incredibly important today that have been around for decades.
And database technology is one of the primary ones that I would point to. And, and so the difference in,
in databases now versus 20 years ago, um, relational databases haven't scaled as well as graph databases
do. And the graph databases help you change the mentality of, of the people who are working on the
things. So you, you have, I, I'm sort of rambling here, but let me just finish the point. Um,
and then in the knowledge graph community, there are people who think in graphs,
not everybody thinks in graphs. So a lot, and, and tables are simpler tables. A lot of people can
utilize tables. Everybody uses tables, but the fact that you've got this graph mentality leads to
connectability and scaling and ecosystem development and, and where we should be going with this
ultimately Larry is, is not just feeding some data into a model and, and trying to evolve the model.
It's really building systems where we can share whatever we want to in a digital form that's
consumable by machines and humans at the same time. So we need more than just neural networks to be able
to do that. And I think that a lot of these technologies that have been around for 50 or 60
years are complimentary to what's happening in, in machine learning. And, um, what's frustrating to me is
that, that, um, a lot of people just think AI is just machine learning and intelligence is so much
more than just machine learning. Absolutely. Yeah. That's, um, cause I mean, knowledge graphs,
knowledge representation is a form of AI, um, and expert systems and robotics and vision and all,
there's all kinds of other stuff. And now I want to do a whole other episode just about the data,
database technology that underlies this, but today we're running short on time and I like to keep
these around a half hour, but before we wrap up, is there anything last, anything that you want to
revisit from the conversation or just want to make sure we share before we wrap up?
Yeah. I, I think that, um, in general, um, there's, there's so much opportunity out there. I don't know
where to get started. And sometimes I don't know who to talk to because, um, I like I've, I've been
looking at systems and how they're coming together and, and so I'm talking to a content person when
I'm talking to Larry and I talked to knowledge management people and I talked to data management
people and then I talked to business people and all of these people could be using the same system
to manage information and, um, make it, make it shareable. All of these people could be doing
things the same way we have the standards they've been solidified. Um, you know, we're really blessed
with a community in terms of semantics that, that has the vision to bring the system together.
And what we need is, is, is just more oomph to bring the organization into the picture more
somehow and make them understand, you know, you could, you can just have one department. You don't
need three departments to manage all this stuff. And why don't you all work together the same way?
You know, I, I wish we could have like a meta organization capability that we could apply
to, to all these, all these companies that have these issues.
I love that vision of a meta organization, like the, not overarching, but like just the,
the, the connecty part of it, which, um, is what graphs are so good at.
Yeah. Yeah. The collaboration is something that, I mean, that's another conversation itself,
isn't it? Yeah. Well, no, that's, well, this is only a collaboration.
I was going to say, this is only episode five. We got plenty of, and I definitely want to have
you back on for like several more conversations because there's five rabbit holes we didn't go
down today that I would love to go down. Um, well, thanks so much. Oh, hey, one very last thing,
Alan, if folks want to connect with you online, what's the best way to find you?
Uh, I, I tend to look at LinkedIn every day and I, I, I hope I'm findable on LinkedIn.
I'll put it in the show notes as well. I'm pretty, you're one of the more prominent Alan
Morrisons there I'll observe. So, well, me and an organist and, and a scientist are the ones.
So I think you could figure out which one's which. Yeah. Yeah. I'm duking it out with a brain
scientist for the Swanson crown. I don't know how my, I don't know. I don't like my odds. Um,
thanks so much, Alan. This is a blast. Sure. I'm happy to do it.
For show notes and to sign up for our newsletter, visit our website at knowledgegraphinsights.com
and please rate and review us on your favorite podcast platform. Thank you for listening.
