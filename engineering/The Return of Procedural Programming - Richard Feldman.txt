This is the return of procedural programming. I'm Richard Feldman. So back in the 1990s at my hometown, I used to go to Borders books on music a lot. Anyone ever been to a Borders? Not really a thing. Oh yeah, a ton of people. Wow.
So I would walk around. And this is sort of before the internet. Like we didn't have the internet at my house. Nobody I knew had the internet. My dad had like the internet at work at the university. A little bit, but it was mostly for email. So the main way that I learned about new programming things was from books. And I remember walking around this Borders and I would see all these books about this hot new, super hype thing, object-oriented programming. See books like this. Headfirst object-oriented analysis and design. Sometimes you'd see exciting new releases of object-oriented languages like Java 1.1.
You would sometimes see object-oriented programming books at different demographics. There was just this overwhelming tidal wave of hype and excitement around object-oriented programming. It was so clear that this was the future, that the old sort of procedural programming way was a thing of the past and the thing of the future was OO.
So I remember like walking around Borders and thinking this. And this kind of stuck in my mind. I got into industry. I became a professional programmer. Did a lot of object-oriented programming.
So imagine my surprise and imagine my sort of telling my past self about ETE a couple years ago, 2019. Here's Andrew Kelly talking about the Zig programming language, which he created. It's one of several new up-and-coming low-level programming languages.
And he's talking about, hey, we're trying to make a better C. We're not trying to be like C++. We're actually intentionally making this new programming language, not object-oriented.
And Zig's not the only one. You also see like Rust, not an object-oriented language. Very, very popular, getting a lot more popular. Odin, JAI, these are two other low-level systems-level programming languages.
Really, of the last like 10, 15 years, the only like low-level language in that group that I hear being talked about that is object-oriented is Carbon, which is a language that's explicitly designed to be a C++ successor and have C++ interop, so they kind of couldn't get away from it.
This is a really far cry from what I remember of like OO being like the obvious future, the thing that everybody was going to be doing.
So we're talking about here procedural programming, sort of the thing that came before OO and this talk I'm going to be talking about, to what extent is it coming back?
So procedural programming is not object-oriented. It's also not functional. So procedural is an imperative paradigm. It's not really concerned with mutation or side effects or the lack thereof.
And it's also not new. It is the thing that we had before object-oriented programming, and it's sort of starting to see a resurgence.
So partly it's in these new languages, but also it's just in existing mainstream procedural languages getting used more.
So Stack Overflow has been running this survey for the past six plus years about which programming, scripting, markup languages have you personally used in the last 12 months.
And we can see some interesting trends in here. Here's sort of the raw data, but just some highlights.
So among object-oriented languages in this survey, people saying, you know, I've used this in the past 12 months.
TypeScript and Kotlin, huge increase, massive increases in TypeScript.
This is probably not news to anyone in here. If you're in the Android development world, especially, you probably have heard about Kotlin just being this absolutely huge thing there.
Python and C++ both saw a 50% increase over the past six years, which is a big deal because they were already super high in terms of usage.
I'm assuming that AI has a big part of this. So both Python and C++ seeing a lot of use in AI.
There's a lot more work being done in AI these days. Also Python seeing a lot more work in data science.
That's been sort of an upward trend, and C++ also in games, and more and more games have been getting developed compared to, like, the 1990s, for example.
C Sharp, Java, JavaScript, kind of no change, but they're already sort of on top.
So it's like, moving up is really noteworthy when you have that much usage already.
Then we also saw some decreases, like Swift and Objective-C, 30% to 50% decrease there in terms of, like, popular, in terms of how many people said they'd use them in the past 12 months.
PHP, Ruby, Scala, I can think of various explanations for these things, like Swift and Objective-C, just maybe a smaller percentage of people are doing iOS development.
That's pretty much where Swift and Objective-C are being used.
Also, a lot of Objective-C is being moved to Swift intentionally.
PHP and Ruby, like, Rails is less popular.
Ruby's popularity in terms of, like, worldwide usage has been pretty coupled with Rails's.
So if fewer people are doing Rails, fewer people are doing Ruby.
PHP has become more of a niche thing that's kind of used for, like, WordPress and Drupal, and not nearly as much, like, general websites as it used to be.
And Scala, I think, its decrease would be explained in large part by the increase in Kotlin,
because one of the three different ways that people use Scala is sort of as, like, Java++,
or I've heard the joke being Java without semicolons, and Kotlin also offers some of that same sort of Java,
but sort of, you know, taken in a slightly different and maybe arguably improved direction.
Okay, what are procedural languages?
Because there are also certainly some long-standing mainstream procedural languages.
What do their trends look like?
Well, C has seen, like, a 30% increase over the past six years.
So part of that could be explained by C++.
I bet there's some double counting there where a lot of people who are saying,
I'm doing C++ are also answering, yes, I've done C in the last 12 months.
Go, 100% increase.
I don't have a double counting explanation there.
It's just, like, seems like a lot of people, you know, seem to be liking Go.
Anecdotally, this conference, I've had three different conversations
with random people in the last couple days, and two out of the three said
they are adopting Go at work, and I think that's just because people like Go,
and maybe it's because they got generics now, I don't know,
but one way or another, Go seems to be increasing in popularity,
and it's just not an object-oriented language.
It's procedural programming.
And then, of course, Rust.
I gave Rust 1,000% increase, but that's actually being generous
because six years ago, Rust wasn't even on the chart.
Like, it was kind of zero.
So you could say that's an infinity percent increase,
but that doesn't seem reasonable.
So to be generous to the other languages, we'll just cap it at 1,000%.
But point being, Rust went from essentially not being on the chart six years ago
to now it's like 10% of respondents said that they'd use Rust in the past 12 months.
So absolutely massive increase.
No classes, no objects in any of these languages, no subclasses,
no inheritance, just procedural programming.
And so, since we saw sort of a mix of up and down in the OO side
and all of the mainstream procedural languages,
or at least all the ones on the survey,
have seen some form of increase, putting those two together,
that means that in the last six years,
at least among Stack Overflow survey respondents,
object-oriented programming lost ground to procedural.
Like, some of them went down.
None of the procedural ones went down.
They all went up.
What's going on here?
I thought OO was supposed to be the future forever.
So this is what I want to talk about today.
This is why is it that procedural programming
is becoming proportionally more popular.
Now, to be clear, OO still rules the roost.
It's still the most popular paradigm on the planet,
for sure, by a healthy margin.
The question is about the trend.
Why is it becoming more popular?
Why is it sort of coming back,
even though it's the thing that came before OO?
So outline of the talk,
the first and largest section is going to be talking about
differences in features between the procedural paradigms
and OO paradigms.
I'm going to break it down into sort of two different categories of OO.
A little bit shorter section,
differences in style between the two,
and then the shortest section of all is going to be at the end.
So sort of what changed?
What is it that sort of putting all these things together
changed to make procedural programming start to come back?
So we'll start with differences in features
and just to sort of set the scope of what we're talking about.
For this talk, I'm just going to focus on the paradigms
of procedural and mostly object-oriented
and just kind of briefly mentioned functional.
This is mostly talk about imperative programming.
So I've talked a lot about functional programming in the past,
but this talk is not about that.
So also not going to get into other paradigms like logic programming.
It's really just kind of going to be procedural
and object-oriented and their differences.
Okay, so thinking about sort of like what's the essence of the paradigm?
So a language paradigm is in a lot of cases
about some combination of language features
and also the style in which you use it.
We're going to start off by talking about the features.
So the procedural sort of like feature set and style, I guess,
is the introduction of the idea of using procedures over go-tos.
So if you look at the hardware,
like the hardware doesn't have a concept of procedures.
This is a new paradigm that we sort of invented on top of the hardware
and having this sort of abstraction of the idea of a procedure
built in terms of essentially go-tos like conditional jumps
and non-conditional jumps and this concept of the stack
and things like that.
So it's basically just the idea of, hey,
what if we organize our programs into procedures?
This is becoming rather popular ideal.
Basically, all programming does this now.
You could be forgiven for thinking,
what do you mean paradigm?
That's just programming because this is a paradigm
that has really, really stuck around.
Functional would be sort of like procedural with restrictions,
I guess you could say.
It's sort of like, let's take procedural
and then also try to avoid mutation and side effects.
Object-oriented, a little bit trickier to define.
So let's sort of talk about that.
So another past ETE speaker, Alan Kay, gave a keynote.
Alan Kay is the person who coined the term object-oriented.
And he coined this term at the University of Utah.
So at first in 1966, he sort of described what his influences
were when he was doing object-oriented programming
as he later called it.
He talked about Simula.
So we'll talk about Simula a little bit later.
So Simula was the first language
that introduced the concept of objects and classes.
It started off as a DSL for describing simulations.
That was like its purpose as a language.
And then in the second edition of Simula,
they decided, you know what?
We think this is actually a good idea
and people should try to use this style of programming
for things other than simulations.
And that was when they introduced the terminology
of objects and classes in that second edition of Simula.
Whereas before they used like systems and procedures
or something like that, or processes.
So Alan Kay was inspired by that.
He also was inspired by the design for the ARPANET
or the internet as we now know it.
We'll definitely see that.
He really thought about objects as essentially kind
of like little tiny servers.
And finally, my background in biology and mathematics,
which had to do with like metaphors for how cells communicate
and mathematics in terms of like algebras
of how things are organized.
And he used this term.
He said, I thought of an architecture for programming.
We're going to contrast this with other sort of schools
of OO that don't really think about it as much
of an architecture as he did.
Probably in 1967, someone asked me what I was doing.
And I said, it's object-oriented programming.
And it stuck.
That's what people use to describe this style of programming
and other styles that he doesn't think count.
Okay.
So later in 2003, Alan Kay said, sort of by means
of clarification, to me, object-oriented programming
means only the following.
Messaging, we'll talk about what that means.
Local retention and protection hiding of state process.
I think he means encapsulation by this.
I don't know what else he could mean by this,
but let's assume he means encapsulation.
And extreme late binding of all things.
We'll also talk about that.
He says, it can be done in small talk and in Lisp.
I got to admit, I heard that and it kind of threw me for a loop
because A, I don't really think of Lisp
as an object-oriented language in the sense that
like it's what a lot of people call
the first functional language.
And also Lisp explicitly added,
like there's like the common Lisp object system,
like that was like a separate thing later.
And if it was already object-oriented,
why would you need to add an object system later?
Also, I don't use the term objects or classes
or anything like that in Lisp.
I don't know.
But apparently to Alan Cade,
this is an example of a language,
like one of the two languages that can do it.
And then he goes on to say something
that was even more confusing to me,
which is there are possibly other systems
in which this is possible, but I'm not aware of them.
Now, we said this in 2003,
at which point Objective-C and Ruby
had been around for like multiple decades.
So I'm not really sure.
I guess Ruby less than one decade is 1995,
but they've been around for a long time.
And both of these languages are due messaging,
encapsulation and extreme late binding.
So I'm not really sure what he was talking about there.
Regardless, let's talk about what messaging means
because this is maybe not something
that you might think of in terms
of object-oriented programming.
It's certainly not something I thought of
back in the 90s.
So messaging is essentially
in the object-oriented context.
What Alan Cade is talking about
is the idea that calling a method on an object
means sending a message to that object.
Like you've got some piece of information,
you're sending it to the object.
The object receives it
and then decides what to do with it.
So really, the object sort of decides
in real time, at run time,
when it gets this message,
what am I going to do
just based on looking at the message
and looking at the current my state,
the state of the world,
all those types of different things.
Essentially, just like what an HTTP server does.
If you've got a web server
and it receives a request,
it can decide on the fly
what to do with that, including nothing.
It can say not found
and it can change its answer about not found
all the time at run time, at real time.
This is exactly Alan Cade's concept
of what objects were.
In fact, he's talked at length
in different contexts
about how he sort of saw each object
as sort of like a tiny computer
or like a tiny server
and the idea of object-oriented programming
to him was this recursive design idea
where everything was like computers
all the way down.
Ruby explicitly includes this idea of messaging.
So if you look up the official Ruby documentation
about what calling methods is,
it says calling a method sends a message
to an object so it can perform some work.
And it's got like an example of the syntax,
my object.my method.
It says this sends the my method message to my object.
And if you included arguments in that,
those would also be part of the message
that gets sent to the object.
So Yukihiro Matsumoto, a.k.a. Mats,
was very directly influenced by Smalltalk
when he developed Ruby
and he wanted to include this idea of messaging in it.
Okay, so he also mentioned late binding,
extreme late binding in all things.
If you're not familiar with that idea,
this is essentially the idea
that like the list of methods and object supports
and what they can do can change in any way at runtime.
And this is kind of an extension
or like an implication of the messaging idea.
Essentially like you're getting a message in
and you can decide,
hey, like right there on the fly,
do I support this method?
Do I have it?
What arguments does it accept?
What are their types?
You can decide that as late as you want.
You can change them on the fly.
You can say every 30 seconds,
I completely scramble what methods I support
and I delete half of them
and then I add new ones.
You can do that, all that.
This is a really critical thing to Alan Kay.
Like this is an important part to him.
If you're not doing that,
if you don't support that
and do like extreme late binding in all things,
it's not object-oriented programming.
So in other words,
when you see some syntax like this,
that's what it's supposed to be doing.
You should have no idea at compile time
what that is possibly going to do,
if it's going to do anything,
if it's supported, any of that stuff.
Now, an interesting implication of this
is that this is completely at odds
with static type checking.
Static type checking is where you say
at compile time, not at runtime,
I've got an exact list of all the methods
that are supported.
I will check them.
I will give you a red squiggle in your editor
if any of them are not supported at compile time.
And they shouldn't change at runtime
if you want to be able to type check them.
If you do want to change them at runtime, fine,
but now we're outside the world of static type checking.
Now, I mention this because there's been
a pretty strong trend of increase
in the use of static type checking,
which is really at odds with this idea
of extreme late binding of all things.
So, we have small talk,
which is influenced by,
descended from Simula.
We have objective C in 1985.
So, Simula, 1960s or late 50s.
Small talk, 1972.
Yeah, 1972, because it was the same year C came out.
And then objective C in 1985,
Brad Cox creates this language.
And it's basically like he starts with C
and he wanted to add some productivity features to it.
He just read about Simula and Byte Magazine.
I'm sorry, small talk and Byte Magazine.
And he says, you know what?
I'm going to try and add some small talk features to C.
And he ended up calling that objective C.
He included the message passing idea,
the late binding idea, all that good stuff.
So, if you look at actually like even modern objective C
documentation, this is from Apple,
because the way objective C ended up being used in practice
essentially was exclusively as kind of an Apple thing.
But I'd like to have this method, you know,
message sends, sends a message with a simple return value
to an instance of a class, aka an object.
So, this idea of messaging persists today.
Although, again, for some reason,
LNK doesn't sync objective C counts as OOP,
but Lisp does.
Anyway, now Python, despite being a language
that a lot of people would consider object-oriented,
didn't do those things.
It was not like Guido von Rossum was not influenced,
at least not like really influenced strongly by small talk,
but rather he had personally used Simula
and had a good experience with it.
And he wanted to incorporate Simula into this language
or Simula ideas, maybe like classes and objects,
into this language he was creating called Python.
So, he did.
But he didn't include the messaging idea.
That was like kind of the LNK small talk thing.
And this is like one of the first examples
we'll see of object-oriented languages
or languages we think of as object-oriented
that didn't fit LNK's definition at all.
They didn't do messaging.
Certainly, it did the late-binding thing,
but not messaging at all.
Ruby was actually, so, again,
Yuki Hiro Matsumoto, aka Mats, created Ruby.
And he was aware of Python at the time,
and he specifically wanted in the design of Ruby
to make a scripting language
that was more object-oriented than Python.
And what he meant by that
is essentially more like small talk.
Like it actually included the idea of messaging,
like we saw.
There's another language that,
how many people have heard of self?
One, two, okay.
Not a lot.
So, self, don't worry.
You'll recognize the language
that ends up being descended from self.
So, self was this programming language
that descended from small talk.
The authors wrote this paper about it.
Self, the power of simplicity.
Unlike small talk, self includes neither classes
nor variables, variables meaning like members.
Instead, self has adopted a prototype metaphor
for object creation.
How many people have heard of
prototypal inheritance?
Okay, a lot more, a lot more.
How many people have heard of the most popular
prototypal inheritance language, JavaScript?
Hey.
All right.
Cool.
So, this is kind of self's legacy is that it inspired
JavaScript's original inheritance system.
I'm using JavaScript's original, like, 1995 logo for there
for reasons that will become apparent later.
You might know JavaScript by its more modern logo,
which looks like this.
Yeah.
So, the whole late binding thing,
not static type checking.
Yeah.
There's that trend.
So, basically, self was sort of an inspiration
for JavaScript.
But even before we got TypeScript and sort of the move
away from extreme late binding and all things
and towards static type checking,
we did see some other trends around, like,
self's idea of prototypal inheritance,
namely that, like, ES6 JavaScript introduces classes
and that sort of becomes the sort of preferred official way
to do inheritance and OOP in JavaScript
over the prototypal inheritance idea.
Still supported, but it's really, like,
when you read tutorials and stuff,
a lot of times people talk about kind of the new,
shiny ES6 classes way.
And the reason they added that is just pretty much
the rest of the world except for JavaScript
is doing class-based inheritance.
And it seems like the prototypal inheritance idea,
maybe it was cool at the time,
but it doesn't really seem to have stuck around.
It seems like it's kind of going to end with JavaScript.
You can look at Dart as another example of this.
So, Dart is a language that's like very, very directly
an offshoot of JavaScript,
but they didn't even bother to include
the prototypal inheritance thing.
They just used class-based inheritance.
So, this is one of several ideas
that we're going to see in this talk
of sort of branches of OOP that, you know,
they got tried out.
They were mainstream.
They had their, you know, their time in the sun.
And now, people are just moving away from them.
And for one reason or another,
there could be a lot of different factors to do with that.
But the idea just doesn't kind of seem to have stuck
as much as some of these others have.
Also, we've seen kind of a move away from messaging.
So, we saw that like Ruby and Objective-C
explicitly included messaging in their designs.
Well, Objective-C's successor language Swift,
which was, you know, developed at Apple
with the express purpose of being like,
let's do this for iOS developer and Coco and all that.
Instead of Objective-C, sort of the modern alternative,
doesn't even include messaging
except as a specifically as a way
to do backwards compatibility with old Objective-C code.
Similarly, Ruby, you've got sort of an offshoot
of Ruby called Crystal,
which is you could draw some parallels to Dart,
but not perfect parallels.
But it's basically like a very, very Ruby language
that explicitly uses static type checking
and static dispatch.
So, it sort of really walks away
from the idea of extreme late binding of all things.
Also, we noted that, you know,
back in the Stack Overflow survey,
that Ruby and Objective-C were two of the languages
that had the most decrease
of all the object-oriented languages in that list
over the past six years in usage.
So, again, I think that's mostly because of Rails
and because of Swift,
not necessarily because of any, you know,
problems in the Ruby language or Objective-C,
but it is worth noting that, again,
the industry seems to be moving away
from this idea of messaging.
And also, like I said,
moving away from the idea of late binding,
all of these languages down here,
Python, Ruby, Crystal, Swift, TypeScript,
either they have type checking baked in
or, in the case of, like, Python and Ruby,
they've now added official language extensions
so that you can add type checking.
So, it's really not looking good
for Alan Kay's sort of vision
of, you know, what he considers to be OOP.
So, you know, he said this only,
OOP means only messaging.
Okay, encapsulation, definitely still here,
definitely still a thing.
But as far as messaging,
extremely late binding of all things,
really doesn't seem like that's kind of like the future.
In fact, I don't want to say that it's dead,
but it really, it seems to be well past its peak
at this point in terms of popularity.
Okay, so we've seen some differences in features here.
So, the Alan Kay style of object-oriented programming,
messaging, and late binding.
Procedural programming, in contrast,
is kind of just, I don't know,
nah, don't do that.
Like, it's not really like procedural,
it's like, ah, here's what we do instead of that.
It's just sort of like, I don't know,
just don't do messaging and late binding, right?
That was sort of what came before.
And so, when I say that procedural programming
is, you know, rising in popularity,
it's not so much that people are like,
oh, here's this shiny new way of doing things.
It's more just like, actually,
maybe we'll just not do that
and go back to the old way before we did those things.
I guess if you could call it a feature
and sort of like express it in a more positive way,
it would be like, procedural is more about
just like plain old functions and plain old data
being passed around between them.
Okay, now, of course, there's another whole branch of OOP,
which is probably what most people, myself included,
think of more in terms of OOP,
which this is not the person who coined the term.
This is Bjarne Strustrup.
Does anyone know what he's most famous for?
Okay, yes.
That is, of course, the language
that I'm about to talk about next.
So, Bjarne Strustrup was,
he had used Simula in the past
and then he had also used C
and he decided to put them together
in a language that he called C with classes,
which I assume is what everyone was thinking of.
Anyone heard of C with classes?
I see a couple of hands.
Has anyone heard of C with classes
and they didn't hear about it from me?
Okay, one, cool, one and a half.
Right, so I didn't have a logo for C with classes
because it was kind of a short-lived language,
but I made one up, C with classes.
But basically, like, C with classes essentially
was kind of what the name says.
It's like he took the C programming language
and he just added classes to it.
He also, as a bonus, added static type checking
or, like, stronger static type checking to it.
So, already, he's, like, the polar opposite
of Alan Kay's vision for OOP.
But essentially, what he found,
this is, like, kind of an interesting case study,
was with C with classes,
he described it as a medium success,
meaning that, like, yeah, you know, it worked.
It, like, did the thing.
It added objects and classes to C.
The problem was that it was, like, kind of just a bunch
of his friends using it
and it wasn't really gaining widespread adoption.
And he considered this a problem
because he didn't really want to keep maintaining it
if it was just going to be this kind of, like,
little medium success.
And so, what he ended up doing was he decided,
well, I don't want to shut it down
because that's just going to, like, hurt all my friends.
And I also want to keep maintaining it on my own.
I bet if I add a bunch of other features
on top of the object-oriented stuff,
maybe more people will find it useful
and then they can help me maintain it.
So, he did.
And then he decided to rename it
from C with classes to C++.
How many people here have heard of C++?
Hey, it's, like, JavaScript again.
Cool. All right.
So, yes, this became slightly more popular.
Now, what's interesting about this
is that it is, it's a little subtle distinction,
but it's worth noting that if you just took C,
which is already a very popular language,
and you added just classes to it,
the OOP stuff, that wasn't enough for it to be popular.
He had to add all this other non-OOP stuff
before it got popular,
which kind of tells us something about
was it the OOP part that caused C++ to get popular?
Well, obviously not,
because when he added that,
it was C with classes, which nobody had heard of.
The thing that caused C++ to get popular
was that other stuff that he added on top of it,
because before that,
when it just had the OOP stuff,
it wasn't popular.
And yet, I remember the 90s thinking,
oh, yeah, OOP is big, just look at C++.
And these kind of got conflated.
Like, that was the causal relationship there,
but we did the experiment,
and the experiment was like,
actually, if you just add OOP to C,
it doesn't get popular,
and it's like the same guy even.
So, at any rate, C++, quite a popular language.
Alan Kay, not a fan.
He, in 1997, he said,
I made up the term object-oriented,
and I can tell you that I did not have C++ in mind.
Fair enough, be that as it may,
I mean, as we've seen,
it seems like this is sort of the family of OOP
that ended up taking over,
whether or not the originator of the term
is happy about that.
That's how it ended up happening.
So, one of the most famous languages
that sort of is descended from C++,
and in fact,
was explicitly designed to appeal
to C++ programmers is Java.
I've carefully organized this slide
so that you can see the Java logo
next to another logo,
which, you know,
remember JavaScript from 1995?
A little bit of a backstory there.
JavaScript was originally supposed to be Scheme,
like a functional programming language dialect,
functional programming Lisp, no less.
That was what Brendan Eich
was planning on developing at Mozilla
for their use in the browser,
the Netscape browser,
and essentially,
Java comes out.
There's this huge, like,
literally multiple hundreds of millions
of dollars of marketing
from Sun Microsystems
just for Java,
the programming language,
so type was real.
Mozilla says,
do you see this hype machine that's coming?
Put Java in the name
and, like, make the logo be Java,
make the syntax look like Java,
just Java-ify what you're doing,
and Brendan Eich's like,
all right, I guess.
So, yeah,
it sort of became JavaScript.
It was originally called LiveScript,
and the rest is history.
PHP, another offshoot of C++,
like Rasmus Lerdorf,
also Danish,
was sort of doing C++ programming
and doing web programming
and felt that it was, like,
kind of too clunky
to try to do web programming
in C++
and ended up inventing PHP.
Later on, C Sharp ended up
being sort of Microsoft's
kind of, like, version of Java
that had some differences
and things like that.
But this whole family of languages
really comes from sort of
Bjarne Struth's version of C++
where he just wasn't interested
in messaging.
He wasn't interested
in extreme late-binding of all things.
In fact, he was quite
into static type checking,
and as we've seen with kind of
the trends of these things,
this sort of seems to be
the version of OOP
that ends up being
most widely used in industry.
He gave a talk called
The Design of C++
where he sort of talked about,
like, his motivations and stuff,
it's, like, from, like,
the 1980s or something,
and he highlights some of his goals
with the, this was a C with classes
originally, but those goals,
you know, persisted through C++.
He talks about, like,
program organization
was the first thing.
He was sort of, like, you know,
Dennis Ritchie did a good job
creating C.
It had a lot of stuff,
but it doesn't really tell you
how to organize your programs.
He also talked about
wanting to maintain C's
runtime efficiency, availability,
importability, interoperability.
Like, he didn't want
to sacrifice those things.
But program organization
was the thing that he said
he was concerned with.
That's, like, what he was
really all about.
And when I talk to people
about things that they like
about OOP,
this is one of the things
that really commonly comes up.
So, Alan Kay was, like,
I had this vision
for, like, an architecture
of programming.
Strew said more about
program organization.
And the thing that he
ended up sort of popularizing
and that I hear a lot of people
say they like about OOP
is the idea of combining
actions on data types.
Like, you organize them
in the same place.
You've got your class
and then it's got a bunch
of, you know, pieces of information.
Then you've got methods
on that class.
It's a really natural way
to sort of, like,
couple these two things together.
And in fact,
even in modern programming languages
that are not object-oriented,
like, functional languages,
procedural languages,
they tend to use modules
for encapsulation
rather than classes.
But you really commonly see
this same sort
of organizational strategy.
So, Evan Chaplicki,
who made the Elm
programming language,
he used to have this saying
that I really liked
and found useful in Elm,
which was talking about,
he said, like, you know,
usually a good module
is built around
a particular data type.
Like, you'll have one type
and that usually will be
the same name.
The name of the type
is, like, the same name
as the module.
And the module will expose
that type.
And you have a bunch
of functions in that module
that, you know,
work on that data type.
Crucially, this is more
of a convention
in the modules world.
Like, in the classes world,
it's, like, very strong.
It's a very strong default.
It's a very strong cultural thing.
If you just got modules
and not classes,
you can still do it that way.
But it's not as strongly
encouraged as it was
in C++
and in all the object-oriented
languages that followed it.
Very strong organizational
culture around classes.
Another thing that I've heard
a lot of is the pillars
of OOP.
So, this is something
that comes up a lot
in OOP teaching.
It's interesting,
there seems to be
a bit of a disconnect
because when I look
at early beginner
object-oriented tutorials
and stuff,
this is super commonly
talked about.
When I talk to people
in the industry,
they're like, oh, yeah,
the pillars.
I think I've heard of that.
Does anyone here know
what the pillars are offhand?
Yeah, right?
Like, it's not,
you can't just, like,
rattle them off.
So, here's what you see.
If you look up, like,
you know, what are the pillars
or the principles of OOP,
you always see these four,
or sometimes only three,
but abstraction,
encapsulation,
polymorphism,
and inheritance.
So, let's kind of,
like, go through these
a little bit.
And by the way,
these are, like,
kind of a state of values,
not unique benefits,
as we will see in a second.
These are sort of things,
you know,
I wasn't quite sure
what the word pillars meant,
but my conclusion
after talking to various
different people about this
is essentially that these are,
these are not claiming
these are uniquely OO benefits,
because they're really not,
but rather that, like,
these are sort of values.
Like, if you're doing OOP,
these are things
that you should value.
So, abstraction,
kind of the idea of, like,
the general idea of, like,
don't depend on implementation details,
just depend on sort of an abstraction
of an idea of something,
rather than the specific,
like, here are the actual shape
of these bits and bytes in memory.
Encapsulation is sort of preventing,
depending on implementation details.
So, you have, like,
a public-private split,
and you're not allowed
to depend on the private details,
you're only allowed to depend
on what's publicly exposed.
Polymorphism is essentially,
again, about implementation.
It's where the implementation
of something abstract
is determined by its type.
Practically every modern language
has these.
They might call them different things,
but, like, you know,
abstraction,
what language doesn't have that?
Encapsulation,
sometimes you might hear
that called modularity,
but, again,
what language doesn't have modules
with, like, public and private stuff?
You know, some things are exposed,
some things aren't.
Polymorphism, again,
basically every language has that.
You know, Go just got generics,
aka parametric polymorphism.
Go doesn't have classes,
but, you know,
you don't need classes
to have polymorphism.
Which kind of leaves us
with inheritance,
which is, I would say,
something that is pretty uniquely OO.
Like, you don't find inheritance
in, like, functional languages,
or not necessarily,
unless they're, like, sort of,
hybrid OOFP.
You don't necessarily find it
in procedural languages,
especially not implementation
inheritance, which, to be fair,
there's interface inheritance,
there's implementation inheritance,
but, really, the one sort of OOP-centric
that you really only find
in OOP is implementation inheritance.
So, when I'm talking about inheritance here,
I'm talking about implementation inheritance.
Implementation inheritance
is essentially hierarchical code sharing.
I would contrast that with composition,
which is sort of non-hierarchical code sharing.
And, of course, we've all heard
that the recommendation in the OOP world
is to prefer composition over inheritance,
which is a thing that basically
every language can do.
Let's get a little bit more specific
about what that means
so we can kind of see
why people might prefer that.
So, why prefer composition
over implementation inheritance?
So, shout out to Martin Snyder.
He gave me this really concise example
of why people come up with this rule.
Let's say you have a class,
and it's got three methods,
and they sort of call each other.
And I'm making a subclass of that,
and I override one of those three methods.
The other two are still calling that method
that I overrode.
And the problem is that
if I didn't realize that those other two methods
were calling the one that I overrode,
I might have just broken them, like accidentally.
I didn't even know they were doing that,
because I don't really have it in any way
to see that they were doing that.
It's not really part of the semantics of the language.
It's just a thing that can happen.
This is potentially a source of bugs.
It's like I end up causing a bug in my program
because I accidentally overrode
the behavior of a superclass
completely unintentionally.
This is a downside of implementation inheritance.
Now, in contrast, the composition approach
is basically we're saying,
okay, well, instead of using subclassing
to override the method
to add new functionality,
I mean, why is it that I'm subclassing?
Well, it's because I want all the behavior
of the parent.
I want access to all that behavior,
but I want to do some other things
that are different.
What I can do instead of that
is I can essentially, well, okay,
I'll just make a new class
which has the original thing
as a member of that class.
So now I can still access all of its functionality,
but I'm not changing anything.
I'm not overriding anything in it.
All of its methods are still there,
still intact.
There's no chance of me causing that bug
that I just described
if I do it in that style.
But of course, once you're doing this,
it's like, well, that's just nested structs in C.
Every programming language could do that,
functional, procedural, et cetera.
So at this point,
we're not really talking about
sort of a strength of OOP.
Arguably, you could say that the fact
that implementation inheritance
is a downside of OOP,
the fact that the foot gun is there
when it's recommended to do
this other less error-prone thing instead.
Okay.
So going back to the idea
of like the essence of the paradigm,
procedural, you know,
use procedures over go-tos,
functional, slight procedural,
but with the added caveat
of avoiding mutation side effects.
And then we're going to break down
OOP to two categories for Alan Kay.
This is messaging
and extremely binding of all things.
And for Bjarne Strewstrup,
it's hierarchical code sharing
through implementation inheritance,
which is kind of disfavored
in favor of composition.
Okay.
So there ends the longest section
of the talk,
the differences in features.
Now let's talk about
the differences in style
between object-oriented
and procedural programming.
So it's pretty hard to find,
like, someone actually saying,
here is how to do
the procedural programming style.
Not quite the same level of hype
as the object-oriented style,
you know, even this many years later.
The best thing I've been able to find
is this YouTube video
that has two million views,
which is, you know,
not an entire bookshelf worth
at Borders, but, you know,
it's a lot of views
for a programming talk.
So in this talk,
he definitely talks about,
like, this is,
we're talking procedural
and imperative.
So this is not a talk about,
like, functional programming style.
But he does talk about
sort of what he sees
as the essence
of the procedural style,
which is something
that does have things in common
with the functional style,
namely that he says,
look, this is about
let data just be data
and let actions just be actions.
That's the essence
of the procedural style.
So not doing this
hierarchical organization
of classes and subclasses,
just data and procedures
that operate on that data.
That's kind of it.
And put them in modules
if you want to have encapsulation.
So he goes through
four different examples
in that talk.
of essentially taking
object-oriented code
and then, without changing
the language, rewriting it
into what he sees
as, like, the procedural
style version of that.
So one of these that he did,
he took an example
from Sandy Metz,
one of her talks.
So Sandy Metz,
awesome human being,
just a lovely, delightful person,
also complete authority
when it comes to object-oriented style,
like, absolutely legend
in the community.
And so, you know,
this is code that I think
is definitely fair to say
as, like, representative
of good object-oriented code.
So in that talk,
she sort of refactors some code
that has some problems
and ends up with this.
This has three classes,
FTP downloader,
patent job, and config,
and nine total methods.
And the refactored version
has no classes,
five total procedures,
and they're all named after verbs.
I mentioned the verbs thing
because there's this blog post
by Steve Yegey
called Execution in the Kingdom
of Nouns,
the author of that talk
referenced in that talk.
And this is a talk mostly about,
sorry, this is a blog post
mostly about Java.
Steve writes,
classes are really
the only modeling tool
Java provides you.
So whenever a new idea occurs to you,
you have to sculpt it
or wrap it or smash at it
until it becomes a thing,
even if it began life
as an action, a process,
or any other non-thing concept.
So in other words,
you might look back at this
and say, like, okay,
why do we need a thing
called FTP downloader?
Couldn't we just write a procedure
that says download over FTP?
That type of thing.
Why do we need a patent job?
Why don't we just have a function
that says, you know,
process the patent?
He goes on to say,
I've really come around
to what Pearl folks
were telling me eight
or nine years ago.
Dude, not everything is an object.
Fair enough.
There's definitely something
to that idea,
even though I distinctly remember
back in the 90s,
the first time I heard about Java
and I had been doing C++
before that,
I was thinking, like,
oh, everything is an object.
That's really nice and consistent.
I like that.
But much later,
I kind of came to appreciate
this perspective, too,
where it's like, okay,
maybe I would like to have,
you know,
the less of the,
what I have is a hammer
and everything starts
to look like a nail.
So, this idea of, like,
nouns and verbs,
like you see in the object-oriented version,
you have a class called FTP Downloader.
In the procedural rewrite,
he just says,
yeah, we're not going to have FTP Downloader,
we're just going to have
FTP Download File.
That's just a procedure
that downloads the file over FTP.
Instead of a patent job class,
he just says we're going to have
two procedures,
process patent and parse patent,
and then config, okay, fair enough.
That makes sense
because that is just a piece of data.
He didn't make a separate class for that
because, you know,
in Ruby, you don't have to.
But the point being
that this is sort of
much more verb-oriented
than noun-oriented
because he decided
that was just the better fit
for what they were doing
in this case.
Now, this idea
of hierarchical classification
of, like, classes and subclasses
and, you know,
implementations inheritance
is not unique to OOP, for sure.
I mean, hierarchical classification,
you find all over the place,
for example, in math.
So, this is, like,
the numeric hierarchy in Lisp,
which, okay,
maybe according to LNK,
that's object-oriented,
but I think most people
would say that's either
functional or procedural.
There just is a hierarchy here.
You look at Haskell,
you're going to see, again,
a further mathematical hierarchy
of monads and applicatives
and foldables
and functors
and stuff like that.
Again, like,
hierarchies definitely appear
in programming language.
It's not like hierarchy
is only an OOP thing.
But you do see
a lot more hierarchy in OOP
than you do
in procedural or functional.
How many people
have gone through
an object-oriented
programming tutorial
where you saw something
like this,
like dog inherits
from animal,
you know,
car inherits
from vehicle,
you know,
bicycle does, too.
Yeah, okay.
So, this is a really
common thing.
You don't really see this
in tutorials
for procedural programming
or functional programming.
This idea of hierarchy
is really kind of essential
to, especially
the Bjarne-Struzstrup
school of C++-based OOP
that just kind of isn't there
for procedural
or functional styles.
This is the sort of class
hierarchy inside Ruby
for all sorts of different
things in the standard
library.
And you can see that,
like, for example,
just within errors,
we have, like, float domain error
which is a subclass
of range error
which is a subclass
of standard error
which is a subclass
of exception
which is a subclass
of object.
Now, there's one way
you can organize errors.
You can certainly say, like,
this is a that,
is a that, is a that,
but it's not the only way
to do it.
Again, in Java,
we see here's, like,
the standard library.
This is a mix of interface
inheritance and implementation
inheritance.
If I just kind of zoom in
on tree set at the bottom
here, this is,
this has an equivalent
in Rust.
So, in Rust,
this would be a B tree set
in the standard
collections package.
Tree set inherits
in Java from sorted set
which inherits from set
which inherits from collection
inherits from iterable.
Whereas in Rust,
you have these things
called traits
and there's just a flat list
of them.
So, you still do have
a bunch of different things
that you can do
with a B tree set.
It's just that there isn't
this hierarchical description.
It's just, that's just
not the focus in Rust
because Rust isn't
object-oriented.
All of these things
that I just talked about
are examples of abstract types.
This is a particular type
of abstraction.
So, interface, for example,
in Java,
this is an example
of abstract types.
So, I'm saying,
hey, a shape?
I'm not telling you anything
about how the shape
is in memory.
All I'm telling you is
if you give me a shape,
whatever that means,
it has some method
on it called area.
I can ask you
what its area is.
It's going to give me
back an integer.
See the same thing in Go
even though Go is not
object-oriented.
It says,
you can have an interface
about shape.
It's like, yeah,
all I know about this thing
is if I ask it for its area,
it gives me back an integer.
Same thing in Rust
except now it's called
a trait instead of interface,
but same basic idea.
I got this thing called a shape.
If I ask it its area,
it gives me back an integer.
And in Haskell as well
with type classes.
It's different syntax,
different name for the thing.
All these are just examples
of abstract types
rather than concrete types.
So, concrete type might be,
for example,
like a rectangle
that's got a particular
implementation of area
that's specific to rectangles
or a triangle
that it's got a particular
implementation of area
that's specific
to how it works in triangles.
So, again,
it's this fundamental idea
of if I have a shape,
all I know about
is I can ask for its area
and get back an integer.
Now, these are all
in statically type checked languages.
I can't quite say as much
if I've got a dynamically typed
language like Python.
So, in Python,
again, this looks a little bit different.
So, I'd say class shape
and then deaf area
and then the convention
as far as I've been told,
I'm not actually
a professional Python programmer
and have most Python I've done
is helping other people
with their Python homework.
But apparently,
this is the style
is that you define the class
and then you say
you raise a not implemented error
by default
and the idea is that
if you want to make
a concrete class
like rectangle,
then you would say,
okay, I'm going to define
the area to actually do something
like the actual implementation
of the area of a rectangle
which is the width times the height.
Okay, you can do something
similar in JavaScript
but you can do it
with prototypal inheritance
like we talked about.
So, I'm again using
the 1995 JavaScript logo.
So, prototypal inheritance
version looks like this.
You got function shape.
I don't know why
they use function for that
but that's how it works.
Shape.prototype.area
equals and then you define
essentially the implementation
to initially just, you know,
throw an exception
and then you can override that
for a particular, like,
rectangle prototype
where you implement it as,
you know, width times height
just like before
and then you can say
answer equals rect.area.
Now, another thing you can do in JavaScript
is you can do this in a completely
not object-oriented style
if you want
and get exactly the same
sort of data abstraction
at the end of the day.
So, here's how that might look.
You might say rect equals
and this is just like an anonymous object.
I'm not defining any classes.
I'm not doing any prototypal stuff here.
Area is a field on the record
or the object
that is an anonymous function
that just says
return rect.width time rect.height.
So, what is rect here?
Well, this is just from the outer scope.
This is just an example of a closure
that's capturing something
outside of its scope.
Essentially, inside a function in JavaScript,
I'm allowed to refer to variables
that were defined outside the object
or the function,
including, you know,
things that are ultimately getting defined
like right now
in the middle of this thing.
So, this is a way
that I can write some JavaScript implementation
that will let me call
answer equals rect.area
exactly like before
and it's going to do the same thing
except that I didn't use classes.
I didn't use prototypes at all.
So, this is an example
of just a different style
of achieving the same data abstraction.
So, again, I could do the same thing
but make it be a triangle.
So, now instead of rect.area,
it's tri.area
and then base times height over two
instead of width times height.
Totally fine.
And then I could use the fact
that I'm allowed to do both of these
to generalize this
and make use of that abstraction
and write a function
that just says,
hey, I'm just taking in a shape.
I haven't even defined what a shape is.
I didn't write down the word
shape with a capital S anywhere in here.
There's no interface.
There's no class.
There's no prototype.
It's just,
I just wrote a function.
I wrote a function here,
wrote a function here
and now I can call shape.area
without knowing whether I'm going to be getting
rectangle style with times height
or triangle style base times height over two.
Both of those are going to work
because I've abstracted over shape like this
and I did it without doing any OOP stuff.
This is just another style you can use.
I could even take that a step further
and say, well, let's suppose I don't have
this language feature
of being able to refer to things
outside the function.
Maybe I'm writing C, for example,
which doesn't have that feature.
Well, I can make it a little bit less convenient.
I can say I'll just take an explicit argument
rather than referring to that one
and then say whatever that argument is
base times height
and then when I call it,
I have to do shape.area passing in shape
which looks weird,
but I can do it.
Like it works.
I've achieved the same level of abstraction
by doing this.
I still have the situation
where I don't know anything about this shape
other than that it's got an area method.
I can still call that
and get either base times height over two
or width times height
depending on whether I was given
a rectangle or a triangle.
All of that sort of fundamental abstraction stuff
still works.
It's really just a question
of how convenient it was or wasn't.
And this is a really important theme
of what paradigm does and doesn't get you.
It's not so much about getting you something
that you couldn't possibly do before.
It's really about how well supported that is.
So we can see,
we have just seen lots of different ways
to accept abstract data
in a function or a method.
So interfaces, traits, type classes,
closures, non-closure functions,
or even if you were in C,
you could go as far as function pointers.
All of these are ways to achieve
the idea of abstract types
and passing abstract data between functions.
They just have different ergonomics trade-offs
and different stylistic trade-offs.
So putting all that together,
language paradigms are less about
what styles of programming are possible.
I mean, come on,
they're all touring complete languages, right?
That means anything's kind of equally possible.
It's really just about
how well those styles are supported
and also what styles the ecosystem embraces.
Like if you're doing that last style I showed
where you're calling like shape.area,
passing in shape,
nobody else in the JavaScript ecosystem
is doing it that way.
That's kind of weird.
Similarly, if you're trying to do
that sort of like kind of overloading style in C,
I'm not going to find too many people doing that
unless they're trying to do something very specific.
So really putting all this together,
regardless of what features are present in the language,
you can choose to do things in a different style
that does or doesn't necessarily work well
with those features.
It's really kind of a question of
how well supported are you going to be in that?
How good are the ergonomics going to be
of that style you're choosing to write in?
And what's the ecosystem like around that?
Okay.
So the procedural style,
to wrap all this up,
I'm claiming is programming with less hierarchy,
organizing code into just plain old data and procedures,
and essentially just using modules for modularity
instead of classes for encapsulation
because they get you the same public-private thing.
Okay.
So which brings us all to the shortest part of the talk.
What changed putting all this stuff together?
So I'm walking around in borders.
I'm seeing all these great-looking books
about object-oriented programming.
And now, you know,
I think back on that time a couple decades later,
and I just have this sense
of having spent time with OO in industry
and remembering all of these sort of promises
of like this is going to make things so much better.
It's going to be like a really good answer to complexity.
Programs are going to be a lot less brittle and stuff.
And I just feel this sort of sense of disillusionment.
Like it was really exciting back at the time,
but now kind of the shine is worn off.
It doesn't feel like this exciting new thing
that's going to solve a lot of problems.
I mainly think about a lot of term I've heard a lot
when talking to people about this talk
is people say like broken promises
or not living up to the hype.
I mean, you know, I think about a book like Clean Code.
It's like, man, who doesn't want clean code?
I don't want dirty code.
I don't want clean code.
And then you think, well, okay, you know,
that's an exciting promise.
But then you think about like, well, UML diagrams.
I don't know.
Was that an improvement over procedural programming?
Uh, yikes.
That was, okay.
Maybe not.
And then you think about like abstract singleton proxy factory
being like, was that, was that like, that's okay.
I mean, is that a step forward?
I don't know.
So now that we've sort of gotten well past
the sort of honeymoon phase of OO and the like excitement phase
and kind of started to see like some of the excesses
or things where things went too far,
there's this reasonable and sort of natural reaction
to kind of go back and revisit like,
was this the right direction in the first place?
And in a lot of cases, a lot of things about OO
were likable or nice.
And you know, there's, there's plenty of good reasons
that OO languages continue to be widely used.
It's not like everyone's like, throw it all out.
But there's also plenty of reason to understand
why people could say, yeah, you know what?
I don't know.
I don't know if it was worth it.
I, I, I kind of want to take a step back
and maybe revisit some of the earlier things,
especially now that we've got a lot of modern conveniences
like modules that are mainstream
that weren't back in the days before OOP came out.
Um, a lot of people are looking at code like this
and saying, yeah, I mean, I could put this in three classes
named after nouns and have, you know, nine total methods.
Or I could just have like five procedures named after verbs.
I don't know.
Am I really missing out on a lot?
Is, is this code really going to be brittle
and hard to maintain?
Because at a baseline, it seems like there's less code there.
It's not doing as much.
It seems easier to follow.
I mean, I hear you, what you're saying in a lot of cases,
you know, OOP thought leaders and things like that about,
you know, oh, as your code base gets really, really big,
you're going to want this stuff.
But then a lot of us have had experience working in large OOP code bases
and thinking, I still had those problems.
I just had all this other stuff in addition to those problems.
So yeah, disillusionments, common thing that I hear
when I talk to people about this topic.
Um, especially when you consider like,
well, if I want to do stuff like abstraction, polymorphism,
you know, things like that, encapsulation,
there's just lots of ways to do that.
I can get encapsulation from modules.
We've seen lots of different ways to accept abstract data.
It's not like classes and subclasses and interfaces
is the only way to do that.
Um, composition over inheritance kind of makes sense.
And if that's what I'm going to be doing anyway,
do I need inheritance?
It's just kind of this thing that I'm supposed to avoid.
But in a lot of cases, the libraries I'm using
are using it anyway, so I kind of can't avoid it.
Is that, is that a pro?
Um, are we really still doing messaging,
extreme late binding of all things?
Or is that kind of like, well, you know,
it's cool that that was the vision,
but that's just not what people are doing
in the OOP world anyway.
So putting all these things together,
it starts to feel not like the end of the era is now,
but maybe like we're kind of heading
towards the end of an era.
Maybe we're past the peak of OOP
and there's a reason that procedural is coming back,
which is just that people are saying,
yeah, I don't know.
I think maybe things are a little bit better
and a little bit simpler in the old days.
And I think that is sort of a trend
and it's, it's why we're starting to see
new programming languages saying explicitly,
yeah, you know what, we're just,
we're just not going to do that.
We're going to explicitly need procedural.
We're not going to go in the C++ direction.
We're going to say, you know, start with C
and then try to fix some of the problems.
And you can see analogies with that
in other languages,
not just low-level system languages.
Granted, a lot of that is, you know,
going in a functional programming direction,
but it's the same kind of idea.
It's saying like, let's do less hierarchy.
Let's just have plain old functions and data.
And we think that's just going to make our lives better.
It's understandable.
So what changed?
Well, essentially to put all of this stuff together,
many of object-oriented programming selling points
are today just commonplace in other paradigms.
And many of its other signature features
like inheritance, message passing, late binding
have fallen out of favor,
in favor of things like static type checking,
just not doing messaging,
and doing composition over inheritance.
So putting all this together,
it's sort of like, well,
if you're going to be in the imperative world,
procedural programming today
offers a lot of common selling points
without the disfavored stuff.
So if you're sort of on board with this idea of,
hey, what if I just want to let data just be data,
let actions just be actions,
maybe you can understand
why we're starting to see
the return of procedural programming.
Thanks very much.
Hi.
Awesome talk.
Thanks so much.
Just a really quick question.
There's a kind of cynical view
that like more class-based programming languages
kind of force you into one style.
I'm thinking Java in particular,
whereas you have much more freedom,
which means people can kind of do whatever they want
and you don't have like a unified style guide
unless you enforce those patterns.
Can you maybe speak to that a little bit
with this kind of like move to a new paradigm?
Yeah, so the question is like,
there's somewhat of a cynical view
that you could look at
and you could say like,
you know, Java especially,
you gave the example of,
sort of forces you into this like hierarchical style
and like, you know,
noun-based programming and so forth,
whereas other paradigms like procedural and functional
give you more freedom to explore.
I think, I don't know if that's necessarily cynical.
I think you could very easily look at that
as a good thing or a bad thing.
Like in some sense, like I said,
a lot of the things like when I talk to people
about this topic that come up
are people saying,
you know what I really liked about OOP
is it was really clear how to organize my program.
It's like around classes
and you do lose that if you say,
we're just going to have modules
that don't really sort of give you
that really strong push to being like,
I'm going to co-locate my data
with the operations that work on it.
So I would say it's accurate
in the sense that like certainly Java
does very strongly push you in that direction.
I remember thinking it's really cool in Java,
like when I first used it,
that like everything is an object,
except for primitives,
that actually really bothered me
that like int was like not an object
and I heard it wasn't Ruby
and I was like, cool.
But at the same time,
it was also weird that like,
you know, before you had like
public static void main,
you had to put that in a class
and I was like, huh?
It's like, that's where the program starts.
What, why am I making a noun out of this?
It just felt weird
and it still feels weird.
So I see there's pros and cons to that.
I don't know that it's like,
you know, all upside or all downside there.
At least that's my perspective.
Yeah.
It's so weird to me
that still water comes in a can
because I feel like I'm like,
oh yeah, time to hit the sauce after that talk.
So speaking just for myself,
OOP was all about tying together the data
with the methods that work on the data.
And I think that that idea has persisted.
So if you look at Rust,
you have a struct and then you have an impel.
If you have go,
you can define functions with a receiver
that just looking at your code
looks like you're working with objects.
Comments?
Totally.
Yeah.
So, so, you know,
the idea of like coupling data
and, you know,
the operations that work on it,
especially like into a namespace,
especially with like public and private,
I think that that like has turned out
to be kind of a good idea.
The interesting thing though is the question,
at least to me,
the interesting thing is the question of,
A, do you have to do it that way
or do you make that like a convention
that sort of opt in
and maybe you can also have modules
that, that don't do that
or maybe operate on multiple data types at once?
And then B,
the question of,
okay, let's say that you have organized your code that way.
What does that imply?
Like you,
you gave the example like Rust traits
and like impels,
like even if you're not using traits,
you can still like have an impel
just to get the sort of method looking syntax,
which I personally do in Rust code all the time.
But then the question becomes,
well,
what are the implications of doing that?
And in Rust's case,
if you're not using a trait,
the implications are really just kind of syntax.
It just looks kind of method-y.
And also there's like some type conveniences.
You don't have to like repeat the type in as many places.
You can just say self
and that just is whatever the type of the original thing was.
But what you're not getting
is you're not opting into like inheritance.
You're not saying,
oh,
well now people can subclass this
or,
you know,
I might be subclassing someone else
and overriding things.
That whole part of it is sort of gone.
And that does seem to be something
that's a pretty bright line
between the like object-oriented languages
and the procedural and functional languages
is whether or not
sort of coupling the data
to the functions that operate on it
involves subclassing and overriding like that.
But I think the fundamental idea is like,
yeah,
it's a good way to organize things.
I think that's uncontroversial at this point.
And also credit to OOP for popularizing that,
I think.
Other questions?
Okay.
Thanks very much.
