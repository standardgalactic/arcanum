wake up it's 2027
in 2027 sarah takes care of everything
sarah is a virtual assistant who knows exactly what's best for you
everywhere you go artificial intelligence like sarah predicts your needs
and does the work for you
with all of these machines working for you isn't life wonderful in 2027
but let's not get carried away before sarah changes your life forever there's another story to tell
one with less special effects
this story takes place behind the scenes of those businesses
who are working to invent our future
for now it's hardly this wonderful world where machines are working entirely for mankind
in fact you could say it's exactly the opposite humans are involved in every step of the process
when you're using anything online but we're sold as this miracle of automation
google facebook amazon uber these digital giants are using a completely invisible workforce
to keep their applications running there we are with technology you can actually find them
pay them a tiny amount of money um and then get rid of them when you don't need them anymore
a workforce that is disposable and underpaid on a very good day i could do five dollars now
at a really bad day i could do 10 cents now i mean it's is it possible for you to pay less
than the american minimum wage i'm not sure we want to go in this direction yet
whilst millions of men and women are training artificial intelligence for next to nothing
others are being hired and hidden out of sight to clean up social networks
you must have been told by the recruiting team that you cannot mention that you are working for
this project okay we went undercover as one of these web cleaners working as a content moderator for
facebook there's a few things that i saw those things are going to stay with me because i i remember
them as if it was yesterday to meet the workers hiding behind your screen we're taking you to the
factory of the future the digital economy's best kept secret you know it's just like a sausage factory
they don't want people to come in to see how the sausage is made i mean i think it's just that simple
to delve into the mysteries of artificial intelligence we're heading to the west coast of the u.s
here in san francisco and the silicon valley the world of tomorrow is being developed
it's the high-tech hub of giants like apple facebook youtube uber netflix
and google we have a meeting of figure eight a business specializing in artificial intelligence
that primarily works with google the founder lucas bwald agreed to spend the morning with us
hello hello lucas nice to meet you thank you very much for your time of course i know you have a busy
schedule thank you at 38 years old this stanford graduate has already worked for the likes of
microsoft and yahoo before founding his own company once his microphone is on a quick tour of their
startup style californian office space this is our best dressed in play
cool and relaxed this is probably our worst dressed in play
do you play babyfoot i think i'm pretty good i don't know maybe this is kind of our eating area
is actually where i like to work my coffee got cold
and in the reception area an impressive display these are some of our some of our customers
and the the different things that they did with our our products so here's twitter
we helped them remove a lot of um people that were kind of bullying um on their website
you know american express is that in france i don't know yeah you know i feel especially proud of
you know something like tesco right is able to to use us to improve their um online website to show
better search results so people can find um the items that they're looking for and i don't see google
oh no i don't know what do you know how like why some of these get up here uh we frankly we we just
stopped because it was gonna it was getting out of hand this is mr brown head of pr
after our visit the founder explains the enigmatic name figure eight
we call our company figure eight because we think of it as a loop and the loop really has um these
these two parts right there's the humans that do the labeling um and then the machine learning that
learns from the humans and then it goes back to the humans um for more labeling right so um we we
think of um this kind of like beautiful loop right where humans do the best things that humans can do
and the algorithms the artificial intelligence does the best things that the algorithms can do and we
we put that together and that's why we call it figure eight
to get a better understanding of why ai needs humans to function we stop joking around and get out the
computer so here's an example you know a lot of people these days are trying to build cars that
automatically drive like for example tesla has a system where you can drive around in a car but of
course it's incredibly important that these cars don't run into pedestrians so the car camera just
sees something like this so it's really important that they build reliable systems that can identify
people and the way that they learn to identify people is looking at lots of pictures of what the
car is seeing from the camera and then actually literally labeling where the people are so here's a real
example example of how it works if you want to teach a self-driving car to recognize a pedestrian
a human like you or i it first has to identify pedestrians from photos and then feed this
information to the ai and this process has to be done over a thousand even a million times over which can be
very time consuming this is where figure eight gets involved using real people who are paid to do this work
so the task here is to look at this picture and then label where the people are and so you get paid for
this you get paid to draw boxes around the people how much um you know i'm not sure this task um but
you know maybe it would be like um you know maybe 10 cents per person that you draw a box around
who do this job do you have employees doing these jobs and labeling people yeah so it's contractors on
our in our network that that log in and do these jobs what do you mean by contractors on on your network
what kind of people so it's like people that that log into this and then um and then want to work on
these tasks how many people uh work for figure eight in this capacity as as labelers yeah um so again
it's people can kind of come and go if they want to so there's maybe around a hundred thousand people
that kind of consistently work um every day for you know for certain use cases that we have um but then
there's also millions of people that log in from time to time and work on tasks and where do those
people live they live all over the world actually so they live all over america and then they live all
over um the the world so who are these millions of people who are being paid to train ai technology
in order to meet these contractors as figure eight calls them we leave silicon valley and head 500
miles north of san francisco and oregon there we are aha success jared mansfield signed up to figure
eight three years ago he now spends several hours a week working for them every day the company offers
a list of tasks that he can complete for money for example training search engines
for this first one it's showing examples of how to do it the query is mac and cheese pierogies
and the two results are annie's homegrown organic mac and cheese and annie's really cheddar
microwavable macaroni and cheese which are neither of them are pierogies so it's saying that one would
be equally bad matches what's the use of doing that a lot of it i think uh is to train search search
algorithms so like when someone sits at their computer and types a product the algorithm will be able to
determine with more accuracy what product it is that that person's looking for
for every 10 answers jared earns less than one cent to get an idea of how much money he can make
we leave him to work for 30 minutes he's answered 180 questions over the course of half an hour
how much you earned 15 cents for how long a half hour which would be 30 cents the hour yeah which are
pretty definitely not a livable wage that's for sure do they have the right to do this i mean they
have the right to do whatever they want i'm the one coming to them for little tiny bits of of
coins on this website and uh it's not we there's no contract between me and them
no contract no salary no guaranteed minimum wage these ghost workers are paid to train software and
robots using only one rule supply and demand it definitely feels like like i'm part of this invisible
workforce that is kind of made up of just random people throughout the world and uh together we're kind
of uh training what's going to replace the workforce as a whole eventually jared is very philosophical about
the idea still he can afford to be to earn a real living he has another job selling chicken in this
supermarket for a little more than fifteen hundred dollars a month figure eight is just what he does on
the side to earn a little extra cash after leaving oregon we decided to take advantage of what we'd learned
in america and sign ourselves up to figure eight to train artificial intelligence on the site's welcome page
small tasks are proposed at one two or 12 cents we chose this as our first task drawing boxes around
objects in images following the instructions it took us several minutes to draw around 10 objects
and earn two cents on the list of tasks figure eight also offers evaluations of search engine answers
jared's jared's task of choice we could also listen to conversations and confirm if the recording
features a man or a woman's voice and if they are speaking english hi is james there please
we work for hours without ever earning more than 30 cents an hour
it's difficult to imagine that there are people who work on these tasks on a full-time basis
we're in maine on the east coast of the united states close to the canadian border we've arranged to
meet with one of the nets ghost workers the human side of the figure eight loop
her name is don carbone she is 46 years old
hello hello hello hello nice to meet you thank you so much for your welcome it's beautiful
yes i've never seen so much oh we had a blizzard not that long ago and then we got more stuff
and it's also i think negative seven out there
don is a single mother she lives here with three of her children
this is what subsidized housing looks like up here i mean it's not bad for public housing
she lives and works here working on the figure eight site all day
i'll turn it on like i said right before seven o'clock you know get the initial stuff done um i'll
turn it i'll turn this off at three o'clock in the afternoon and then turn it back on at nine o'clock
at night so i'll say eight hours minimum so i bust my butt though like this would be the dashboard
you can see i've done 6445 tasks since when three years see these different badges you start off you
have no badge and you have to do so many questions and get so many right and then you get your first
level badge and then then when you get to level three you have access to virtually all the tasks
that are put up um what is your level right now right now oh i'm on level three i've been level three
i've been level three for quite a while don is considered a high performing worker
figure eight therefore offers her more work than a beginner but it isn't necessarily more interesting
i have to put bounding boxes around people
i'm not really keen on this job
the biggest problem is trying to find jobs that
are viable and right now i don't have many and it's definitely not better paid
on a very good day i could do five dollars an hour on a really bad day i could do 10 cents now
i mean it's i mean i have had some really really good days until february yeah do you think uh this is a
fair payment for what you're doing no no no no not at all but i live in northern maine
we get a lot of snow it's there's a very low
job market and it helps me as a stay-at-home mom um it it helps with added income
so yeah don prefers to work from home because her youngest daughter jane has autism there you go what
happened don wants to be there to take care of her when she gets home from school at 3 p.m
so how was school good day or bad day really a good day with her autism i always have to be ready to
jump in my car and go get her from school i mean it could happen one day out of the week or not at
all or three days out of the week um and the school is very understanding so i mean i have to take out the
whole week if i was working out of the home don receives 750 dollars in government aid every month
which isn't enough to cover all of her bills this is why she signed up to figure eight by working
eight hours a day and five days a week she says she earns on average 250 a month on the site
on figure eight the pay is non-negotiable if you refuse the work there will always be someone else to take
it there is an unlimited supply of these ghost workers coming from all over the world it's probably
why lucas bwald is so happy but he isn't the only one to take advantage of this phenomenon
various other businesses propose these sorts of repetitive and underpaid online tasks the biggest
amongst them being click worker and amazon mechanical turk a platform provided by amazon and its boss jeff
bezos who invented the concept in 2005 think of it as micro work micro working is a growing concern for
the ilo the international labor organization a un agency in charge of protecting workers rights across the globe
hello janine berg is the resident expert on this subject at the ilo who speaks to us through skype with
globalization you can see the emergence of kind of a global labor force here uh it's the next step it's
really the the service industry that can break up work into kind of very short little succinct tasks
uh and then you know divulge it to to workers all over the world who compete for the jobs do the jobs
the the price of the wages are are driven down because of this global labor supply and the technology
has has facilitated this and it's cheap that's us the other the main advantage
janine berg wrote a report calculating that micro workers earn on average three dollars 31 cents an hour
without any rights in return workers extreme vulnerability is the key to lucas b walt's business
model after months of investigations we found this video from 2010 that sums up his view of the labor force
before the internet it would be really difficult to find someone sit them down for 10 minutes and get
them to work for you and then fire them after those 10 minutes but with technology you can actually
find them pay them a tiny amount of money um and then get rid of them when you don't need them anymore
while we were interviewing him we wanted to ask him if he still shared the same opinion
but when we start talking about work conditions the figure eight founder seemed to lose his sense of humor
do you have an idea of the average revenue per hour of your contributor you know i'm not sure it's
totally dependent on the task that someone puts in and it's hard to track time on the internet because
people can walk away from their computer and come back so i don't know how much people um generally make
there was a report on ilo saying that on average the people working on crowdsourcing were paid
3.31 dollars an hour would that be consistent with what you pay again i'm not sure is it possible for
you to pay less than the american minimum wage it could be possible so this is legal um
um i'm not sure we want to go in this direction yeah you know what can we take it to a different
direction i mean i'd rather just focus on more ai than than anything yeah but this is the whole
thing i mean this is about crowdsourcing as well so i have to ask questions on crowdsourcing
um because i thought it was more high i just i prepped them for more of an ai conversation
than uh than a crowdsourcing conversation no i don't you know i think we should we should i don't
really want to do this um yeah we can find you someone else to talk about this stuff okay so you're
not comfortable with with this part of the discussion no no no okay you're right it is an important part
of the conversation but i think it's just you know it's not the ai conversation we don't have time to
pull up the video lucas b walt makes a hasty exit without saying goodbye and leaves us alone with his
head of pr one last chance to ask how the business treats these contractors as they call them here
when i was working on this i found many people complaining being disconnected
and and and of course i actually have to go now too uh so it's 11 o'clock okay so um so you don't
want to to speak about human in the loop that's not that's not my role here so all right i think we're
done so only artificial intelligence no human well that's what we were prepared for so sorry okay
it's a pity to get some answers to our questions about lucas b walt and his views on his workers
we thought we'd try a different tactic on the day the figure eight founder made his statement on
disposable workers there were other entrepreneurs amongst him as well as a researcher lili irani just
on the right 10 years after the conference we find lili living south of los angeles california
lili irani teaches at the university of san diego and one of her specialist subjects is the working
culture of high-tech business we're lucky she has a good memory do you remember if somebody reacted after
this sentence which is very brutal in a certain way to be honest the reaction was nothing i remember
that panel everyone went up to him to talk to him and two or three people came up to me to talk about
the ethics of this form of labor this is a room full of highly educated people in san francisco
and nobody batted an eyelash how do you explain that
you know the kinds of people who have access to these spaces are the kinds of people who never
worked in a situation where they wondered if they could make rent or they never worked in a
situation where you know somebody gets sick and they can't pay someone to go take care of them
so they have to kind of take a really bad job at home and they have no connection to the kinds of
situations of the people that are willing to do this work it's what happens when you go to schools
like stanford and harvard and princeton that tell you you're the smartest person and you're going
to be a future leader and you've been chosen because you're special and that you have the power to
change the world a silicon valley elite who is out of touch with the rest of the world this is the key
to understanding lucas b waltz logic although it's not the only part these workers are invisible by design
um you can write code and send your work out never talk to anyone it's designed so you can
get the work back on a spreadsheet if you need to you just see these i you know letters and numbers
and identifying the worker you don't see a name you don't see where they live you don't see what
their situation is you don't see unless you keep track of it yourself have they worked for you before
or not do these ghost workers really know who they work for have they ever heard of lucas b wall
we showed them the footage of the figure eight founder talking about their work
with technology you can actually find them pay them a tiny amount of money um and then
get rid of them when you don't need them anymore giggling over paying people pennies and yeah
bye-bye okay now i'm going to start arguing what like i do about the ai's when they get me agitated
it's kind of surprising i guess a little bit to see they're so openly uh openly talking about
that view that they have of the workforce
it's i guess it doesn't really surprise me that much but yeah it it definitely kind of sucks i guess
when they could be paying them a lot more or at least showing some appreciation or maybe even some uh
some discretion basically saying in person you know you you hide somebody for 10 minutes and fire them
this way you don't have to look at the person and you just goodbye so that's kind of just it is kind
of the fact that the head of the company is people are that disposable that really isn't right
i don't i don't like that so i like what i do when i have something to say and i will say it so i'm not
disposable amongst this invisible workforce hiding behind your screen there are those who feed algorithms
for next to nothing it's the people in charge of tidying up the web the social media cleaners who work
on sites like facebook or instagram these workers are never mentioned in the slick presentations of the
silicon valley ceos i started building a service to do that to put people first and at the center of
our experience with technology because our relationships are what matters most to us
that's how we find meaning and how we make sense of our place in the world today with two billion users
facebook no longer has anything to do with mark zuckerberg's initial vision of the site
with violent videos hate speech and pornographic images more and more content has to be deleted
and it isn't always robots doing this job there are once again humans hidden behind the screen
determining if something is hate speech is very linguistically nuanced i am optimistic that over
a five to ten year period we will have ai tools that can uh get into some of the nuances the linguistic
nuances of of of different types of content to be more accurate in flagging things for our systems
but today we're just not there on that so a lot of this is still reactive people flag at us
um we we have people look at it these people are in charge of sorting and managing content on the network facebook
call them content reviewers according to their site facebook has 15 000 workers doing this job across the world
in ireland portugal the philippines and the u.s
we contacted facebook but the company refused our request for an interview
so in order to meet these moderators and understand their role we identified facebook's main subcontractors
multinationals such as majora cognizant or accenture we found this job offer for a content reviewer for
the french market in portugal
grégoire is one of the journalists in our team he responded to the ad and was offered the job
of the u.s
before taking off he received his contract which included his monthly salary 800 euros a little over
the minimum wage in portugal with a food allowance of 7 euros 63 cents a day
facebook isn't mentioned once in the document even when directly asked accenture refused to give the
client's name i was just wondering uh now that i took the job i'm going there i'm i'm doing it
i was just wondering you know if i could know the name of the company i'm gonna work for
no we cannot rebuild the name yet it's for one of our customers but we cannot we are not allowed to say the name
this is where grégoire will be working at the accenture offices in lisbon
before getting started our journalist was sent to a welcome meeting
the footage is a little shaky as grégoire is filming with a hidden camera
hello hello i'm having the meeting with accenture 930. grégoire isn't the only new employee 12 other
people are starting the role at the same time another french person along with some italians
and spaniards an hr representative is running the welcome meeting welcome you all my job as career
advisor is to help you in all the relationship with it okay
after the vacation documents and social security paperwork the small group finally find out which
company they are working for but it's top secret you must have been told by the recruiting team that
you cannot mention that you are working for this project okay the client is really very demanding you
cannot mention anyone that you are working for facebook okay if someone asks you where you work you
work for accenture okay we still we we have this code name that's they seal so if i'm talking to
some colleague from accenture not from this project and asks me where do i work i cannot tell that i work
for facebook okay this is not allowed it's completely like confidential that work is that facebook is working
here at this facility okay code names confidentiality clauses and a complete ban on cell phones
facebook gives you the life of a secret agent for 800 a month and if you're the chatty type the following
argument should shut you up pretty quickly you have like an agreement and you cannot break that agreement
because by law we can do like we can punish you by law you know it's confidential cleaning up social media
is a bit like doing your family's dirty laundry it has to be done but nobody talks about it
why so careful what does the job involve
we continue discreetly with gregoire
before becoming a moderator gregoire has to follow a three-week training program
moderating facebook's content doesn't only involve deleting violent videos or racist jokes it's a lot
more complicated at the moment the algorithms can't handle everything every decision must be justified
using very strict rules this is what we learn during the training every day is dedicated to a different
theme during the program for example nudity violent images or hate speech on the agenda today
dark humor and jokes and bad taste we will remove a violation if the person that you see in the image
we need to have a real person is visibly affected if you are making fun of the event
event then it's going to be in the mark as poor
what do we do when there's a knocking of the event
here's an example of an inappropriate joke about 9-11
it may seem over the top but there are dozens of rules like this for each category
which can be difficult to get your head around take nudity for example depending on what part of
the body you see or their position the moderator can't always make the same decision here's an example
from the exercises to better explain gregoire decided to delete this particular photo but according to
facebook's rules he was wrong to do so in the feedback session the trainer offers this explanation
if we cannot see and his head is not here
then it's ignored it's in between her boobs so if i don't see directly the contact with the nipple
it's nothing you know that's exactly why i am having so much trouble to understand things you have an
artistic picture of a photograph of a woman and you show a tiny nipple and so on one hand this is a delete
because we have 100 percent uncovered nipple on the other hand you have this almost one video
for a picture and you don't did it because it doesn't feel that's exactly why i yes but you
have a problem because you're still going from what you think in your decisions and we're in school to
learn rules applying facebook's rules without questioning them is the number one rule a principle
that will be drilled into you all day every day there has to be a line and they drill it around that
okay we just need to respect this and we just need to apply to do our jobs sometimes we'll find
disagreements but i mean this is a good job because this is not my social network it's theirs
a training program with the end goal of turning you into a machine
pedro worked for six months as a content reviewer for facebook at accenture
he agreed to respond to our questions but only if he remained anonymous
two years after leaving the company he still remembers the numbing side of the rule
you have to play by their game or else you won't have a job at the end of the month
and it's got to a point where i just felt i was a robot and just doing as many pictures and videos
as much as possible just because i was just that's the only thing i can do you're just there with
numbers and clicking enter numbers enter numbers enter the hardest thing for pedro is trying to forget
everything that he saw on that screen over six months
we're not prepared for it we're not mentally prepared for it all this stuff they don't really
give us the input before and it just comes to you as a shock it just comes to you like a wave
here have this in front of you and you can't really say yes or no to it
it's if you give me a million euros a billion euros i wouldn't go it's not for me
i don't know
what pedro described to us the wave of shock that washes over you unexpectedly is exactly what
happened to gregoire it started around the fifth day of training during the practical exercises
a stream of horrific images
and unbearable videos that must be watched closely in order to make the right decision
according to facebook's criteria
the same horrific scenes are unfolding on his neighbor's screen too
I'm looking for the second level where they can go see
this
is
is
this
is
the
the
the
let's
It's like this on a daily basis for Grégoire and his group.
Luckily, they can always rely on the useful advice of the trainers to feel better.
If the Macarena isn't quite enough to cheer you up,
the business also has psychologists available for the most traumatized moderators.
On this day, a video lasting several minutes brought the violence to another level for Grégoire.
During the break, everyone tries to shake off the shock by discussing the grim video they've just witnessed.
A girl was with two guys and they were playing with a gun.
And suddenly, the girl shot the guy.
But it was like...
It was like...
And Jonathan was like, close and close!
Yeah.
At the moment, I feel very bad.
Like...
I don't know.
But I think that the feeling didn't last a lot of times, you know?
It's like...
At the moment, I feel very, very sad.
I don't know.
But then I can, like, continue.
Grégoire realizes the extent of the damage this job can cause
when talking with a former moderator who is now a trainer.
And I have trouble, like, on the street.
Because I just see people being hit.
Like, in my brain, I see so many accidents that, like...
I cannot...
Fuck off, everybody is running across the street.
Like, I cannot anymore.
Oh, yeah.
You can take it?
Yeah, it's like...
Kind of a mini-PTSD.
We've got that.
Yes.
I mean, I don't take medication, but I know that, like...
I have to be like this.
I can't watch people running across the street.
Anymore.
You're still doing this while you have PTSD?
Yeah.
There is a purpose.
I do feel every day, like...
I'm cleaning the trash from...
Right.
You know?
I know.
I will watch it, but at least I know that I'm going to watch it.
Everyone who's 14 years old is going to get that.
I might know.
Even two years after quitting the post,
Pedro still has very vivid memories of certain videos.
There's a few things that I saw.
Those things are going to stay with me
because I remember them as if it was yesterday.
It's very emotional sometimes.
I remember sometimes people used to, like...
They were working, being productive,
and suddenly they just stand up and run out of the room.
That's okay, because sometimes...
Trauma built up.
And for Pedro, left him feeling helpless.
But if you see someone getting murdered,
the only action you take is delete, for example.
You just erase it out of the platform.
You don't really go into depth of, like,
calling the police, for example.
It's like...
You never really feel content with what you're doing.
You're just going round and round in circles
and just, like, bombarded with all this stuff.
So...
It's like a mixture of emotions that you go through
in one day.
Eight hours for it.
How many were you when you started?
We were 30 when we started.
30.
From that 30,
it started just decreasing month by month.
Until now, there's only, like, three people.
Pedro claims that a lot of people struggle
to deal with the role and end up quitting.
To understand what Pedro went through
and what Gregoire and his colleagues
are currently experiencing,
we met up with a psychiatrist.
Professor Thierry Bobet is a specialist
in post-traumatic stress disorder.
For example, he works with police officers
who have been involved in terrorist attacks.
We show him the footage we filmed.
He's a director of�를
and he's an individual person to arrest.
He can get scattered damage in divorce.
He's a collaborator.
To his family are easily removed.
He can get Hay stays.
Be called.
To his friends.
He what he has!
He with everyday estimates data.
He can get validation to his messes to his 확인!
He can be in depth in my life!
He could cause dialogue with taxes and time fuer.
Memphis, he needs going under pressure.
He wanted us to know
the same team.
He feels pranking out for him.
His cloak is crazy.
what we call an effraction traumatic, that is that one of these images, or some of these images,
will be placed in the deepest of us and come back to us without cesse. And what is
particular about the post-traumatic trauma is that when these images come back without cesse,
they produce without cesse, each time, the same distress. And so it is a distress
that is hard and does not close. We also talked to him about
the famous confidentiality clauses imposed by Facebook.
We also talked to him about different movements, like, for example, the sectarian movements.
And it makes us much more vulnerable to traumatic impacts.
Anxiety, trauma, stress. Cleaning up social media comes at a great cost.
Gregoire decides to quit only two weeks later, still in his training period.
He received his paycheck just before leaving, his hourly pay written at the top, four euros,
62 cents gross. This is a tough pill to swallow for his colleague.
The ice cream shop? Oh man, that's bad, right?
After our experience there, we contacted Accenture.
Their response was a brief email that didn't once reference Facebook.
It did, however, contain this phrase,
The well-being of our employees is our priority.
To finish our tour of the Internet's trash cleaners,
the invisible workforce behind your Facebook or Instagram feed, we had one last meeting.
Sarah Roberts is the leading researcher specializing in those who work as moderators.
She is a key figure in this field.
We met her at the university where she teaches in California.
She presented us with an analysis of the rise and development of content moderation over the past year.
We are talking about a scope and a scale of magnitude that has not been seen before.
Billions of things shared per day on Facebook.
Hundreds of hours of video uploaded to YouTube per minute, per day, and so on.
The response has continued to be, we'll put more content moderators on it,
which means that that continues to exponentially grow.
It has gone from a next-to-nothing kind of line item in the budget
to being a massive, massive cost center,
meaning it doesn't actually return revenue. It's not like a new product.
It's just seen as an economic drain.
And the way we manage that problem is by pushing it onto some low-wage workers
to do it as cheaply as possible, because again,
that stacks up when you double your workforce in two years, that it does not come for free.
This is why companies like Facebook use subcontractors.
But according to this researcher, this isn't the only reason.
It's about labor costs, but it's also about creating layers of lessening responsibility
between those who solicit this kind of work and need it
and those who do it and where they do it.
They remove themselves.
They put themselves at a distance from the workers and their conditions.
And it's not just a geographic distance, but sort of a moral distance.
So when that content moderator, some years later,
alleges harm or is having trouble psychologically or emotionally because of the work that they did,
then it may be possible for that company to disclaim responsibility for that,
even though ultimately they really are responsible
because they asked them to do that work in the first place.
Despite these precautions, three former moderators filed lawsuits
against Facebook in the U.S. a few months ago.
All three were working under subcontractors, all claimed to be victims of post-traumatic stress disorder.
The American company refused every request we made for an interview.
They did, however, send us an email to explain how Facebook, with its partners,
pays great attention to the well-being of content moderators working on its platform,
which is an absolute priority.
To finish off, here's some of the latest news from the sector.
While these ghost workers are left in the shadows,
it's business as usual for the companies working in this new sector.
A few weeks after filming, Figure 8's founder sold his company for $300 million.
Well, at least now, he has good reason to be happy.
OK.
So
Thank you.
