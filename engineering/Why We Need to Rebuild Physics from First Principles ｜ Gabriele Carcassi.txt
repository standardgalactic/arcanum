Just following blended mathematics and I think we're just losing all the physics we have for
physics backwards as what it should be. Because all the math that we do, our point set topology,
our differential geometry, all that, you start with points and then you define
infinitesimal things on points and then you integrate. But that's not what we do in a lab.
When did we first get in contact?
Oh geez, I don't remember. It must have been more than a year ago, yeah.
Okay, well I've been following your channel for approximately one year.
I believe I contacted you shortly afterward.
Okay, yeah.
And you have a fantastic channel people should know about.
So it's called the Assumptions of Physics, or at least that's the project name.
And Gabriel is going to take it over at some point and give the elevator pitch,
the five-minute version. So a long elevator. It's CN Tower. We're in Toronto.
That's our elevator.
What makes your channel different is that you focus on the equations and the rigor,
and many people who are into demonstrating that some conventional aspect of physics is incorrect.
If they're in the academy, they do so from the philosophy of physics angle,
so maybe some interpretation of quantum mechanics. But you don't focus on that.
You're much more about demonstrating with line-by-line proofs.
In that vein, you remind me of Jacob Berandes, and he's from Harvard, and you're based in Michigan.
Well, I'll list some examples for people who, if you just want a teaser of what's to come,
why is it that Heisenberg's uncertainty, or some analog of it, is already in classical mechanics,
under the proviso that you have to assume that thermodynamics is true?
Another is that the action principle, which the way that I thought of it is a compression mechanism,
so it encodes several different equations inside, and then you unpack it with Euler-Lagrange's
equations. But you show the action principle itself has a geometric meaning.
And the idea that you can translate between Newtonian mechanics and Hamiltonian mechanics
and Lagrangian mechanics is false. You can't. There are some systems that are only describable
in some, or not translatable to the other. There's not a one-to-one bijection between these guys.
Correct.
Okay. We'll also talk about what defines quantum mechanics.
So, many people think that it's commuting variables or non-commuting observables.
Is that actually what defines quantum mechanics? That makes it separate from classical mechanics?
And why reductionism is incorrect? You have a video on, you shouldn't think physics is
reductionistic, because at some point you get down to atomic facts.
At the fundamental level. Like, to justify the mathematical structure, you can't just say,
oh, there is another mathematical structure that I used to justify this, because how would you justify
the first thing?
People think of physics as a mechanistic science, that you're always looking for mechanisms,
but also that's another false view. I believe you say that, because you can't look for a mechanism
as something that's irreducible.
Right. Because it's more that if you are at the fundamental level, you can't invoke a deeper level
to justify the fundamental level that you have. There is no mechanism after that.
That's a bit of a teaser. Some of those are technical. But why don't you go over the assumptions
of physics project?
Right. So the goal of the project that I work on is essentially to find a minimal set of assumptions,
of physical assumptions, from which we can re-derive the laws. And we have essentially two
approaches. One we call reverse physics, that we start with the current laws of classical mechanics,
quantum mechanics, and so on, which in modern theories are just presented as sort of a mathematical
structure. And the idea is to go backwards from that mathematical structures and find
physical conditions that are equivalent to that mathematical structure. And that's why it's called
reverse physics, a little bit because it's like reverse engineering. You're taking the thing,
breaking apart, finding what pieces go together, what pieces are independent.
And another reason is because in the foundations of mathematics, there is an approach called reverse
mathematics that takes theorems and asks what is the minimal subsystem of mathematics that I need to
express that theorem and prove it. Now, just a moment. So in reverse mathematics, I've always wondered,
so just for people who are tuning in, there's a theorem and then you usually use assumptions to
prove a theorem. And the way that I understand reverse mathematics is instead of starting from your
axioms and moving forward to derive a theorem, you start with what could be true and then you think
about what needs to be true in order for that to be true. Well, you're looking for subsystems. So
to prove a simple theorem, you might not need, let's say, all of mathematics. You might need just a
smaller subset of starting points, let's say. And you sort of, by doing that, you sort of learn more
of what is the structure of mathematics itself. Now, I'm not an expert in this, but I actually had a chance
to talk to one of the people that work there. And so what I do, what we do in assumptions of physics,
in reverse physics, is slightly different because we're more interested at the conceptual structure,
like what is the minimal conceptual structure that I need to get to some parts of the mathematics,
all the physical laws. But the spirit is the same. You're taking what you think is physics,
what you think is mathematics, and trying to find what pieces are there, like the structure of physics
itself and mathematics itself. And one of the things that then we saw while doing this work is that
you can have these, you know, physical assumptions that are equivalent to the different laws,
but that sort of gives you only the higher level of mathematical structure.
And what we realized is that you really can't say that you understand the higher level mathematical
structure if you really don't understand all the nuts and bolts of the more fundamental mathematical
structures. And so we started another approach, which is called physical mathematics. And there,
the goal is really to start from scratch and layer in each axiom and definition, and each action
and definition has to have a physical justification. So it's not enough to say,
I have a mathematical structure. I have to say, these are the things that I have to model in the
real world. And this is why I will use this particular mathematical structure to model this thing.
So why don't you give an example right now?
So for example, the basic constituents that we use in physical mathematics, because we need a basic
building block for everything, is the idea of an experimentally verifiable statement. A statement for
which you have a test, and the test succeeds in finite time, if and only if the statement is true.
So for example, you say, the sky is blue, you can look, it's blue, finite time, verify. Something like
the mass of the electron is less than 10 to the minus 13 electron volt. That's something where we can go
and verify. But a massless photon. As another example, you can say the mass of the photon is
less than 10 to the minus 13 electron volt. And that's something that we can verify experimentally.
But if you said the mass of the photon is exactly zero, that's not something that we can verify
experimentally, because we always are bound to finite precision. Right? And so these are the things that
we want to have as a fundamental thing. We want to say, a physical theory has to give us statements
about the world. And a physical theory has to be fully explorable by testable statements. And so
those are the things that we axiomatize. We say, these things exist, and they have a particular way
to be composed. So for example, if you take two verifiable statements, right, you can verify the end,
the conjunction, because you test one, you test the other, they both finish in finite time,
then you know that the end finishes in finite time, and it's verifiable. But if you have
infinitely many, right, you're not going to be able to be guaranteed, because it would take you an
infinite time to do it. So for a verifiable statement, you're only guaranteed that the finite
conjunction is actually verifiable. You're not guaranteed the infinite conjunction. So the infinite
conjunction is still a statement, but it's not a verifiable statement. And again, we have, in the
justification, we have somewhat proofs that would have been accepted as proof probably in the 1700s,
but they don't follow the current standard mathematical rigor, because mathematical rigor
now starts with essentially elements that where the meaning has been stripped out is just symbols that
you manipulate and so on. And when we are trying to reason on the physical objects, well, the physical
objects are not meaningless marks of paper. And so we need to be able to reason what these things are,
such that then we can find this definition and say, okay, these things can be. And so all of this
process we call physical mathematics, because at the end of the day, we will come from mathematics,
we will have all the theorems, and we want to recover the mathematical structure that we already
have. We don't want to create crazy mathematical structure that we don't know what they are.
You want to justify the use of the mathematical structures that we already use?
Correct. And find whether those are 100% appropriate for the type of physics that we're
trying to describe, and what is the realm of applicability in those mathematical structures.
So something like the real numbers or even the complex numbers?
Correct.
Which are a continuum. Do they have a place in physical mathematics?
Yes. For example, we have a complete derivation where we have a set of necessary and sufficient
physical assumptions they have to make, such that a set of verifiable statements are going to
be identifying essentially open sets of the real numbers. And so we know when we can take those
things to be valid or not. And again, the idea is really to construct things that are a modelization
of what we do in a sort of operational settings. So how do we define numbers? Well, we're going to
have a reference, and then we say something is before the reference or after the reference. So for example,
we have clock ticks, and then we say something happened before the third ticks and after the second.
Or you have rulers, and you have notches on the rulers, and you can say before this notch and after
this notch. Or you have balance scales, and you have weights that you put on one side. It always works
like this. You have references, and the way that these references work is essentially they give you
three statements. Whatever you're measuring is before the reference, after the reference, or on
the reference, in the sense that it overlaps. And the before and after are assumed to be verifiable.
It's something that you can check. And now the question becomes, how many references do you need?
And what is their logical relationship needs to be, such that all these references are going to tell you,
aha, you're measuring something on a continuum of the real number. And what is most interesting
in doing this work, apparently that it's fascinating because you really understand exactly how these
things work. What we find is that there are three conditions that you need to have that are the most
important. And it's like the biggest difficulty is not getting the real numbers. The biggest difficulty
is to find a linear order. So a set of points that you always have to have something either before or
after. That's really where all the sort of a harder assumption that you need to put are there. Once you
have the linear order, whether you have the real numbers or the integer, it's just a matter of saying,
oh, I have two references. Can I put one in the middle of the two?
Okay. Now, why is it difficult to have an order on the real numbers? Because they already are ordered.
Right. No, it's justifying an order with just saying, oh, I have these references where things can
be before or after, right? So references don't need to be ordered. You have references in space
and you don't have a linear order there, right? And so the idea is that all the references have to be able
to be arrangeable in some way such that, for example, if I put a reference in another reference,
you know, having something that is before this implies that something is before the other,
right? Because the point is that you're starting from scratch. You just say, I have a bunch of
statements. What are the minimal conditions that I have on those statements such that an order emerges
from these statements? And that's the hard bit.
So what are you working on now? What I'm working right now, it's sort of
the piece that I need in between physical mathematics and reverse physics. I need...
Physical mathematics and reference physics. And reverse physics.
Reverse physics, right. Sorry, speak too fast. And then everything sort of merges together.
So from the reverse physics side, right, I have a lot of conditions that allow me to recover fully
classical mechanics. And quantum mechanics, let's say, in a hodgepodge way that a physicist might like,
but not a mathematician. And I need a place where I can run these arguments in a more precise way.
And so I need sort of a general theory of the states and processes that it's more abstract than
the two theories, such as I can say, these are things that you always need to have if you're doing
physics. You need to be able to define states and states have to have these characteristics.
And then if I have a classical system, I'm making this additional assumption. And if I have a quantum
system, I'm making these other additional assumptions. So I basically want to be able to push
as much as I can theorems that are true, both in classical mechanics and quantum mechanics,
push them up to a single theory, right, to a more general theory, so that I can see these
two other theories as instantiation of the two. And so, again, this is part more of physical
mathematics because I need to identify axioms that I have to assume to be able to do physics,
in the same way that I say, well, physics is about experimental evidence, so I need to have
statements of other words that are testable. What I want to say is that physical theory has to be
testable in a repeatable way, right? I need to be able to set up experiments and test them.
And so the basic objects that I have to describe a system must be at the level of ensemble,
because when I go and prepare things in a lab, that's what I prepare. I prepare ensembles,
I prepare statistical things that then I make statistical measurement, and it's on this statistical
measurement that we have the interest. So this sounds extremely practical. Like,
everything that comes from physics has to be some experiment or some statement about an experiment
or an observable. Would the theorem, if you have a vector outside the light cone, then you act on it
with the Lorentz group, you can rotate it to any other vector outside the light cone. Would that be
okay under yours, or would that not even be considered physical mathematics, because it's not making some
specific experimental statement? In other words, if you have a space-like vector, it'll always be
space-like under any Lorentz transformation. Right. That's going to be, if you have set up things correctly,
right, that's going to be something that comes out from the math. So that's an okay statement?
Yeah, it probably comes. So that's going to be true when we are doing even reverse physics
in classical mechanics. You do find that when you set up your assumptions for classical mechanics,
that, by the way, are not very difficult. You need three things to get to classical mechanics.
One is what we call the assumption of infinitesimal reducibility. You have a system,
and the system is made of parts, and the parts are made of parts, the parts are made of parts,
and giving the state of the whole is equivalent to giving the state of these infinitesimal parts.
Aha. And so the infinitesimal parts are essentially what we think of the classical particles, right?
And the whole system is giving as a distribution over the space of the particles. You're going to be
able to say, you need to be able to say, 10% of the system is within this part, you know, this 10%
of the system is within these states, 90% of the system is in the other states. So it's really a
distribution over all the possible configuration of the infinitesimal parts. And because you want
this distribution, the count of states, the densities, and the entropy to be the same for different
observers, right? So if you have a set of units and you are there, and I have a set of units and I'm here,
we want still to be able to count states in the same way, and we want to be able to define entropy
in the same way, because otherwise, you know, entropy would be increasing for you and not for me,
and that wouldn't make sense. Because I would see something that is deterministic and reversible,
you see something that is not deterministic and reversible, that that would not make sense. So
even this constraint, basically, it's what gives you the structure of the classical phase space,
is what gives you the idea of conjugate variables. And mathematically is what gives you the idea of
a symplectic structure, which is sort of the geometrical way that we describe phase space.
So with that assumption, infinitesimal and reducibility, we get all this stuff. And then you say,
now I want the system to be deterministic and reversible, meaning that for each initial
configuration, I have a final configuration, and the number of states are mapped to each other,
right? Then that's what's going to give you Hamiltonian mechanics. It's this preservation of volume,
this basically gives you the preservation of the number of states. The other thing that you need,
that I sort of didn't say before, to make all this work, is the assumption that you're describing a
system that is made of independent degrees of freedom, so that the total number of states can be
understood as the count of states on one degree of freedom multiplied by the count of states on an
ability for your freedom. If you have these three conditions, you get classical Hamiltonian mechanics,
and that's it. Then if you allow an extra assumption that basically says, all that I'm
studying are actually trajectories, meaning that I can go from the kinematics to the dynamics, so from
position and velocity to position and momentum, and this transition is invertible. If you say that it's
invertible, that's what gives you Lagrangian mechanics. And then if you if you go one step
forward and say, look, both momentum and velocity are linear structure, and I need that linear structure
to be preserved, then the map between position from momentum to velocity has to be linear. And if you do just
a couple of integrals, you find that you're constraining yourself to massive particles under a scalar and vector
potentials. So you basically find the laws of charged particles in electromagnetic field.
And again, this was a surprise to me, right? Like when I set up to do all these things, we said,
I just want to understand these things a little bit better. And I had no sense that from just four
simple assumptions. Four simple assumptions. Yes. Okay. Right. It's infinitesimal reducibility,
independence of degrees of freedom, determinism and reversibility, and what I call kinematic
equivalence, the fact that you can go from position and velocity to position and momentum, that looking at
the trajectory is enough to understand what's going on at the dynamical level, to reconstruct the energy,
the momentum and all that. And that sort of gave me a difference in sight in physics, right? Because
I don't need anything below to justify this mathematical structure. I don't need a mechanism
for how we get an Hamiltonian or how we get the Lagrange. It's just the definition. I have a system in
front of me. I can assume that this system satisfied this assumption in these particular circumstances,
and you get the laws. And so I never think that philosophers ask themselves, right,
could we have a universe that have different laws? Well, if we have objects that can be infinitesimal
reducible, independence, degrees of freedom, and all this, you're going to get the same laws.
Interesting. That's a question that many philosophers, as you mentioned, ask. What would the universe look
like under different physical laws? And then there's also the thought experiment that proves that you can
demonstrate to yourself, just without going to the Leaning Tower of Pisa, that a bowling ball and a
feather will fall at the same rate if you remove air resistance. Do you know that?
Yeah, yeah. That's actually in Galileo's dialogues.
Uh-huh.
So this is another myth that people always think, oh, Galileo, you know, didn't know whether objects
fell, you know, at the same rate or not, went to the Tower of Pisa and dropped them. And no, in his
dialogue, he creates this simple thought experiment. They say, OK, let's suppose that I have two rocks
and one is heavier than the other. And let's suppose that these fall faster than this. Now,
you put them together, you tie them up, right? What is the velocity of this? Well, you say, well,
the faster object is going to be slowed down by the slower object. So the velocity should be in the
middle of the faster object than the smaller object. But now you've put them together and now
it's a more massive object. So it should go faster than the faster object than we were before.
Right.
And also here is the configuration is how tight do you have to bind these things such that you're
going to consider these two separate objects with different mass and how, you know, when you tie them
together that they're actually one object of different mass. So like how tight you have to bind them,
right? And then of course, it makes no sense. And then it's how in the dialogue, he concludes that
that all objects have to fall at the same rate. So the type of things that I'm trying to do is exactly
these type of things on steroids, right? To really go and find all these sort of reasoning that you can
from simple things and build as much as possible. And that's kind of the game that I've been playing.
And a lot of the time, some arguments when I start, I'm really just trying to find an argument and I
try to find many, right? And at the beginning, they all seem impossible because you're not used to it.
Like any argument, even false one, as long as you think about them enough times, they're going to seem
plausible to you. And the reverse is true. Even if an argument is false, it's true, but you are not used
to thinking in that way. You still think that it's false. There is something weird about it.
So you need to sort of get comfortable with them a little bit. Then you say, okay, well,
this argument that I just made for fun actually has some merit. And then you find that there is
a correlation with something else. And actually two different arguments becomes the same one.
And you say, oh, then I must have something. In fact, the first time where I said I have something
is where I was able to re-derive Hamiltonian mechanics from deterministic and reverse stability
in four different ways. Because I could say I have determinants because I map states one to one.
I could have determinants because I preserve the information. All the information that I know at
the beginning is the same amount that I have at the end. So it's an information theoretic argument.
Or I have something that conserves thermodynamic entropy. So it's reversible, not in the sense
that I do a one to one map with the state. It's reversible because the entropy does not increase.
Right? And so these are all the uncertainties, right? You think of determinants as points in math,
but we never really measure points. We really measure some statistical distribution and some
uncertainty around it. And so if you say, I want something to be deterministic and reversible,
then you're going to say, well, the measurement uncertainty has to be preserved,
because I need to sort of describe the system at the same level of accuracy. And so I saw that
however I made the case in those four different case, I would get to the same result. And then I
say, okay, now I have something stable, right? Because if you just have one type of argument,
you can always fool yourself. But now I have four of them that are starting from the same point and
reach the same conclusion. And that tells me, oh, I must not be fooling myself.
Now, are those four equivalent to one another?
Yes. And mathematically, they're basically just assuming that the Jacobian of the transformation
is unitary, that the volumes preserve the same. And in our book, we show, we have all these different
ways. And then you see that they're all equivalent. It's quite fascinating. I think 10 years ago or so,
I learned about the thought experiment of Galileo. And then I wondered how much more of physics can we
derive from purely, well, you're thinking in terms of assumptions, but I was thinking in terms of
thought experiments. Then there's also the Newton's bucket thought experiment. Have you thought much
about that? I'm not familiar with that one.
Then don't worry about that. Because I'm not familiar enough with it to be able to describe it
with confidence. But I believe it's an argument for absolute space. It has to do with you have water
in a bucket, and then you start rotating it. And then the water creeps up the sides of the bucket,
making a U-shape. So you're able to tell that this is being rotated. And somehow,
that's an argument for absolute space that Newton gave. And then Mach takes that and says,
actually, Newton, if you examine that, that's an argument for relational space.
You probably have to talk to Julian Barbour for Machian stuff. He is the expert.
Now for the Hamiltonian mechanics, do you recover that momentum is a co-vector?
Yes. And the reason is quite simple. And it has to do with units. And this is one of the problems
that in physics, we follow the math too much. And the math does not care about units. But a lot of
geometrical structures that we have there are actually there to keep track of the units. So
the setup is basically this. You want to be able to count states. And the count of states have to have a
unit that is independent of anything else. And then you're going to have the units that you use
to identify the state, which could be meters, angle, and so on, to start defining the configuration.
And so what you need now is if you only had
the variable that defines the units, and let's call that Q, then you would have a problem because now
there would be special reference system that for which the count of state would actually be the unit
and others, all the others would not be the same. So you start having special coordinate systems that
are sort of privileged because you're using the exact using units to kind of say. So what you really want
to do is to be able to change that unit and still preserve the structure such that the units that you use for
for the states is independent of the units. So you're going to say, okay, I'm going to have multiple variables.
In fact, what happens is that I'm going to have another variable of which the units are the inverse of the first,
such that when I make an area between the two, well, this is the units of Q. This is units of inverse Q.
When I multiply with each other, now I have an invariant. And then invariant is the count of states.
Is that the volume in the phase space? And that's the volume in phase space. So you have
Q that defines the units. You have K that is the inverse units. And then you say, I want to measure
states with H bar. And so you just multiply K by H bar and you get P. Wait, why are we talking about
H bar when we're speaking about Hamiltonian mechanics or classical mechanics right now?
Because that's what we use for the unit that we use to count states is the units of actions. Is that
what we use? And the reason that we use that because in mechanics, the units turn out to be
position times kinetic momentum, m v squared, right? And that's then what we use to define units.
But you still need a unit to be able to measure these things. And when you calculate an entropy,
even in classical mechanics that you have a distribution on phase space, you're going to have
a logarithm of the distribution, but the distribution is going to be, you know, let's say probability over
volume. And if the volume is in unit of phase space, you are in a log, you have to take that out.
So you need some, you know, some constants so that you can define where your zero entropy is
and you get the correct. Right.
And so it turns out that these, you still need to fix some of these constants even in classical mechanics.
And again, it's one of those things that, uh, it's quite bizarre.
Right. But it's one of those things that, uh, if you just take all the units down and that's what
mathematicians do, you're not going to see. And unfortunately, this is what we do in theoretical
physics. So you, you, we have all the units, so we throw them out.
What do you mean we throw them out? Like set C equal to one? Is that what you're referring to?
Yeah, but it's not just setting it to one. It's setting it to one pure number.
Right. If you set it to one, but you're still have some units of space over some units of time,
then you're still preserving the physical content of what you're going to measure. Because when we
measure distances in space, we use different instruments than when we measure distances in
time. But that's what we do. We just set everything to one and we forget about the units. And then we
lose this structure because, uh, you, you, you don't see, you can't appreciate what is it that the
physics that the thing is described in. So what would be an example of something where they set C
equal to one or H bar equal to one or what have you, and it turns out it's incorrect under what
you've investigated? It's not incorrect. You see, this is, I'm assuming, if you do the calculation
correctly and do everything correctly, it's not the problem. You just lose the physical meaning. So for
example, do you know the Dirac equation? Yes. What does it tell you? What is it saying? So if you,
if you, instead of the gamma, right, the gamma is these matrices that sort of sum to one, put a C in
front. Now that C gamma is actually a velocity that comes from the boost of the spin part. So the gamma
is telling you what is velocity of the spin going. And then you have a partial derivative, you know,
put the H bar, that's momentum. So it's velocity contracted with the momentum of the particle
equal MC square. Right? So it's basically telling you all these things is telling you that the V times
P equal, it's going to give you MC square because you have the momentum, which is, uh, MV, and then you
have, uh, the velocity is MV, but you're contracting together those, uh, those vectors, the norm of the
square is going to be C. So you're just saying, uh, uh, you know, something that you already have in, uh,
in, uh, classical particle mechanics in, in a relativistic setting that the, uh, the inner product
between the momentum and velocity is equal to MC square. That's it. It's just that you're saying in
the context of field theory. So of course you're going to use a language of that. It's a lot more
complicated, but the physics that you're describing is what the equation is telling you is, is just
that there's nothing, there is nothing more. And so what I feel that we've done by essentially
stripping all these things away and just following blended mathematics and looking for mathematical
structure for new thing, we, we, I think we're just losing all the physics. They're still there.
And if we did, uh, it, uh, in the way that we used to do physics, right? Because, uh, you know,
these assumptions are just a new version, maybe like more, uh, rigorous version of, uh, uh, Newton's
laws, uh, and the laws of thermodynamics. Like we, we used to do physics like that. You start, you figure
out what are the, you boil the, the, the, the world into these assumptions that you're making or
these, uh, these, uh, starting points, uh, and then get everything from there. And, uh, you keep track
of what it is that you're doing. You, you check your, uh, you know, when you're doing, uh, uh, undergrad,
uh, problems, uh, in physics, you do the dimensional checking where, you know, to make sure that your
masses are masses and, uh, that suddenly didn't become velocity and so on. So why are we not doing it in,
uh, in the more complicated theories where we can even get, uh, you know, more confused because
it's all abstract math and so on. Well, I understand that you want to make sure at the
end that the units match up on both sides of the equation, but I don't see what would be an example
of something in mathematical physics, say the standard model, we set C equals to one and
H bar equal to one and so on. Yeah. And it's the most predictive of all the models that we have.
You're just choosing a specific type of units in which you're doing the calculation because they're
more convenient. So that's what you're doing. Okay. What I mean is, I don't know if you saw
the iceberg in string theory that I did. They understood the more about string theory
by looking at that than talking to actual string theorists. Okay.
Well, that's great. Can you give me an overview that it was better than what other people give?
So please go ahead. Thank you. Thank you. At any rate, at some point you get N equals four
is super Yang-Mills theory in four dimensions and so on. And there are different results. So what I'm saying is,
in those results, is there something that they're doing that is incorrect? Now, outside of the
complaint that there is no supersymmetry that we find, and this is assuming strings at a base,
even though what I just said was not assuming strings, the Yang-Mills case, but you get the idea.
So what's something that is quite advanced in mathematical sophistication that is incorrect?
I understand that for us to gain insight into what this is saying, what this means,
reintroducing units is useful, but is there something wrong at the mathematical level?
Like, is there something that we've gotten incorrect? I get you. So there becomes a little
tricky because that's not my job. So to be able to make the claim, I would have to know string theory
enough to be able to say that or any other physical theory. And I don't have the level of knowledge
that, you know, that I need that. But I can tell you this. Remember when I was talking about the real
numbers? The assumptions that we have to put there are very idealized, right? And there is no way that
those, all those assumptions are going to hold if we are looking at something at Planck scale.
And if you remember, before I said that the hard part was getting the ordering right,
was not getting the real numbers. It's getting the order. Right.
And so what needs to happen is that when you go at Planck scale, you are going to lose completely
the notion of ordering, which also means you're not going to be able to define real numbers for
things that you go and measure because you're not going to have ordered quantities. So I don't know
what structure we're going to have, because I don't have enough constraints to know what needs to
happen. I don't know what are the things that I can assume to be valid at the scale. But I know that
at that scale, the assumptions that you need for the real numbers are going to implode. And therefore,
if I have a theory that says, oh, yes, this is going to be going to work at Planck scales,
and I see that they're still using real numbers for quantities, they're using integration, right?
Because how can you have a differentiable structure if you don't have the structure of
the real numbers underneath, right? So all these pieces that assume underneath the real numbers,
and I'm pretty sure all those pieces are going to go. So if you have a theory, whatever it is,
that claims, oh, this is going to work at Planck scale, and it's still using differential geometry,
real numbers, and so on, from what I know, I would be extremely skeptical, right? But I can't tell you
any specific theory, because I would have to go and look at the difference. I can't.
And what about Dirac's equation? Does it not assume the real numbers? It's a differential equation.
Of course, yeah.
And that is also about the quantum. So how does that work?
If it's easier to go to Klein Gordon, feel free to go to Klein Gordon, any of them.
It doesn't matter. So the issue there is that you are doing, even in quantum mechanics,
you're still using real numbers, right? So you're still making this assumption that you have references,
and you can put them up, and you have a scale that it's perfect, and you know what number is greater
and below. And so, yes, these structures, I would think that they have to fail as well.
They fail at what point? Like, what does it mean that they have to fail experimentally?
That they do not... So here's how I think of physical theories, which is, at this point,
very different from what people think about the different... For me, it is. I have a system
in front of me, and I assume that some things are valid for this system. So, for example,
let's say in electromagnetism, we have the charge distribution, right? And you think that as a charge,
a field that is a charge density, okay? Well, that's not what we measure in practice, right?
What we measure is finite charge in the finite volume, and then we measure the size of the finite
volume, and then we can make the ratio of the charge within the size of the volume, and then we make
these things smaller and smaller and smaller, right? And on the assumption that both quantities are
additive, that is, if I take a volume, I divide it into two, right? Then the total charge is the charge
of this plus the charge of this, and the total volume is the size of this plus the size of this.
If I have that assumption and I make this limit, I can define a charge density, right?
But if I can't do that because I can't make this limit or the additivity does not hold,
I'm not going to be able to use this assumption. Therefore, I'm not going to be able to say,
oh yes, there is a charge density. Because you see, the charge density is not the thing that
physically exists. The thing that physically exists is the finite charge in finite volume.
And this is where we have all the math that we have for physics backwards as what it should be.
Because all the math that we do, our point set topology, our differential geometry, all that,
you start with points, and then you define infinitesimal things on points, and then you
integrate. But that's not what we do in a lab. In lab, we start with a finite thing. And then we say,
oh yeah, yeah, I'm going to make these things smaller and smaller. And then that's where you get the
points. And so on. But the points and all those things exist because you're assuming you can make
the limit. Yes.
So now, if you start with the math and you assume the points, you already assume that you can make
the limits. But if you can't make that limit because at some point you get to plant scale,
or because, for example, the mass is not really additive into volume because you have something that
goes on the surface between them. So it is not true that the sum or the total of the math is just
the sum of the mass in the volume. Same thing for entropy. Your entropy sums only if you're assuming that
things are independent. If they're not independent, that assumption, right? And so this is, again,
this is my game. I need to understand what are the things that I'm assuming at the top level,
such that I can make those limits and I can define the points and the mathematical objects, right?
And so what does it mean that a theory is applicable in a specific case? Oh, it's just
whether the system that I have in front of me happens to satisfy those assumptions that I'm making.
So do I have a classical system in front of me? Well, does it satisfy infinitesimal reducibility,
independence degree of freedom, deterministic reversibility and kinematic equivalence? Yes,
I can model it as a classical system. No, I cannot model it as a classical system. I have to use
something else. So the fact that you can infinitely divide a classical system doesn't imply points
still? In the theory, yes, but it doesn't mean that we have points in the reality. Uh-huh. So this would
be a great time to talk about what defines quantum mechanics. So go over the litany of what people
usually say separates a quantum system from a classical system and then show why that is false.
You have a set of videos, by the way, which I'll put on screen about this. Right, so I have never
seen, and this was my problem, that's why I started all these businesses, that I never
found somebody that told me, oh, for this system, you use classical mechanics, and for this system,
you use quantum mechanics. I mean, you have examples. Oh, you know, if you have a proton,
a double-slit experiment, then you have to use these things. But physics, at the end of the day,
if you think about it, it's not like mathematics, that you have, like, one overarching theory, and
you say, okay, these are things that are valid for everything, right? The set theory and logic,
or category theory, if you like category theory, because I don't say that to people from category
theory. And then you say, okay, these are the things that we always need to assume, and then you're
going to have topological spaces, and then we're going to have groups, and then you have things
that are both groups and topological spaces, and we call them topological groups. So you have a whole
hierarchy of sort of things that you assume in a sort of well-defined sort of uniform way of looking
at things. In physics, you have classical mechanics. And when do you use it? Oh, where I have bees on a
wire, where I have planets, and stuff like that. And then you have thermodynamics. Oh, I use that, you know,
when I have the volumes, and the gas, and the heat. And then I have relativistic mechanics. Oh, I guess
I use that when things are really fast. And then I have gravity. So it's basically, you learn, when
you do physics degree, you learn a bunch of problems, and you learn to recognize patterns. And then you
know, oh, I have a new problem, or this problem is closest to this one, and so I'm going to use those
things, right? And this is what I find completely unsatisfying. So when I was a summer student at
CERN in 1999, then I was sort of asking myself, that's also where I met my wife there. Well,
future wife. It wasn't my wife at the time. But the point was that, okay, I was studying engineering
at the time. I wasn't doing physics. And I just wanted to know, like, what are these things? I wasn't
really going to read, you know, to another thing. So I said, okay, I'm in a third, there's a big
library. And what I'm sure, I'm sure that what there is going to be a book, a textbook that in
the first chapter is going to tell me, oh, this is what quantum systems are. And this is why you
should use this thing. And of course, I went through 20, 30 books, and I found no such.
Why didn't you ask someone? I asked somebody, I got no answers.
Yeah, yeah, yeah. And you got no answers, or you got unsatisfactory answers?
I got the answers, well, I don't know, I can tell you, I just...
Okay, well, it obviously wasn't a great enough answer that it stuck with you.
Oh, there was no answer. Most professors that, all the professors that I talked to,
they admitted not having an answer. And they just point me to somewhere else. Oh,
Bell did some stuff. Go read that. I have no idea. And actually, the turning point for me was when
a PhD student at the time told me, look, you're never going to find these answers. The only thing
that we have is the math. I can teach you the math. And so he taught me the math. And I learned
the math badly, like all physicists. And it then stayed there for me. Okay, why do I have that math?
Right? And then, okay, that's reverse engineer the math. That's sort of how physical mathematics,
how reverse physics started. And then I realized, well, I need to actually understand the math a lot
better. And that's why... But anyway, we're talking about quantum mechanics. So let me tell you what I
think quantum mechanics is. And so the short story is this, is that classical mechanics assumes that you
can take something, divide it, divide it, divide it, divide it, and you can still talk about what
things are. And studying the part, all the parts is equivalent to studying the whole. So if you have a
ball, you can throw the ball, look how the ball evolves and describe the ball. Or you can take a red
marker and put a red dot on the ball and study the motion of the red dot on the ball. Right? And so
studying the motion of the whole ball is equivalent to studying all the possible red dot that you could
put on the ball. All possible finite sizes. Okay. Right? Because the infinitesimal is just the limit
of all the possible finite sizes. And so when you have all the possible finite sizes of all dimensions,
that's how you define it. Now, the reason I keep having this as a sticking point is because
infinitesimal doesn't mean point. It means it's as close as you get to a point without being a point.
Right. So this opens a whole, another word is how do we define calculus? Because I don't think,
when I'm doing physical mathematics, I will need to define calculus at some point. And I don't think
the starting points that we have for calculus can be physically motivated. I want to have a notion
infinitesimal. That it's similar to what, you know, we, Newton used to think.
And right now, if you look at the books of how differential geometry is defined, you really don't
have those things. You have completely different definition. That even when I talk to other
mathematicians that do topology, for example, like I was at a conference, a topology conference, talking to
one of the students and I asked, you know, why are you answering topology? And one of the reasons that
he said was because the definition of differential geometry were too abstract for him and made no sense.
To a mathematician, to somebody who has a PhD student. So if they're too abstract for him,
you can imagine for somebody, you know, that has a physics or engineering background. So I'm trying to
understand how, how we can, how we can actually define things in a way that are sort of, you know,
similar to this idea of, of pieces that become smaller, but they actually can, we can, we can do it
with modern math. So we, we, we would define it in a way that a modern mathematician would look and
say, okay, yeah, this is rigorous. This actually works, right? But this is a whole other problem. So
we're in physics right now. We don't care exactly what the infinitesimal means, but it's this
intuition that you had. It's something small, but, but it's not zero because if it's zero and then
we have all points that are zero dimension, how do we get the whole again? Okay. So getting to the
bowling ball and you can mark it with all these different points or mark it with a finite, finite,
but, but whatever size you want. So it's arbitrarily small as you can. And so at that point, it means
essentially describing all the points and so on. Okay. So this is classical mechanics and in one way or
another, in all that you do in classical mechanics, you are going to have this thing.
So, oh, just a moment. Is this classical mechanics in conjunction with thermodynamics yet? Or is this
just pure classical mechanics? It's pure classical mechanics.
Okay. So we need to distinguish those two. Is that, do you in your head call that pure classical
mechanics? Whereas the other one where there's the Heisenberg uncertainty analog is something more
CM plus T thermodynamics. Yeah. So the thermodynamics enters. So this is where
I cannot give you a straight answer because in my mind, the distinction is, is yet not clear because
you can understand, uh, one physical thing and one mathematical thing. Physically, you can understand
that if I say that I, what I'm really studying are objects and I'm looking at these parts and so on,
there is already a sense that, uh, well, I'm kind of doing some statistics there. So exactly what is
it that I'm doing? I don't know. Is it enough to get, I see. I don't know. Okay. And, but what I can
tell you is this, is that, uh, this is another thing that I think, uh, uh, you know, we, we look at
it backwards. We think as a statistical mechanics and thermodynamics as something that you add on top of
both classical mechanics and quantum mechanics, right? So there is mechanics, which is the real
thing. And then you use statistical mechanics, thermodynamics. It's all sort of derived, the
derivative thing. It's not really fundamental, but here's the thing. As I said, remember that
counter states that we need to define to, to have a classical mechanics, classical home internal
mechanics. Well, that's the geometrical structure of, of, of classical mechanics. It's the symplectic forms
that allows you essentially to count the configuration, to count the states. Okay. So that thing,
is what you use then to calculate, uh, thermodynamic entropy. So you use that structure to calculate
the entropy. Now, if I gave you all possible distributions, probability distribution in phase
space, and I told you what was the entropy of all those distributions, like the, the Shannon entropy,
Gibbs entropy, you would be able to recover the symplectic structure. So the symplectic structure
and the entropy are equivalent because either I give you one and you can calculate the other,
or I give you the other, you calculate the first one. Interesting. So the geometrical structure of
quantum, of classical mechanics is exactly the structure that you need to be able to do thermodynamics
and statistical mechanics. So how can you say that one is built on top of the other? They're really one
unit. The same applies for quantum mechanics. The geometrical part of quantum mechanics is given by the
born rule. The inner product tells you what is the probability from going from one state to another
state during measurement. Okay. You use the born rule to calculate the von Ohman entropy, the entropy of,
of distribution. Now, if you take all distribution, in fact, if you take in particular the, uh, uh, the
uniform distribution over two pure states, and you look at that entropy, from the entropy, you can recover
the probability of transition from one to the other. So again, I could give you the, uh, geometric inner
product structure of, of quantum mechanics, and you can recover the entropy, or I can give you the entropy,
and you can recover the, uh, the inner product. They are equivalent. So again, how can you tell me,
oh, quantum statistical mechanics is something that we sprinkle on top of, uh, of quantum mechanics? They're
really much more tied in. So that's why, uh, you know, I, I, I can't make these arguments fully because
again, this is where I said I need this theory of ensembles. I need something that is more foundational
to be able to say why I have these things, how exactly they are, they are related or not.
So what's interesting to me is classical mechanics seems more objective
than notions of entropy. Entropy is subjective to me because it depends on macro states.
So you can define macro states in, in any which way. You can say,
what are all the different arrangements of chairs in this room? But you could also say,
what are all the different arrangements of the lights or not even arrangements? You could have
something else. So there's something that seems quite subjective about entropy. It's never sat right
with me, but then there seems to be something ideal and objective about classical mechanics. Now I could
just be incorrect about entropy. Keep in mind that for me, statistical mechanics was an easier course
than thermodynamics. And I don't like this liquid notion of, of entropy and heat, the whole fluid
mechanics analogies. But when I got to statistical mechanics, it made much more sense to me.
So one of the important pieces that thermodynamics really pushes you in your face is that you need
to define the boundary of the system. So even if you have the same physical system, but you have a
different way that you interact with that physical system, you have a different physical system. So
entropy, like thermodynamic entropy, the one that is important for us physically, depends on the way
that you can interact with the system. Because if you think it like this, that the whole idea of
thermodynamics is figuring out how much work you can extract or put in the system, well, it will depend
by how you can interact with the system. So James is the one that really sort of made this clear.
James. James.
Uh-huh.
James. He had an example in one of these articles that basically says, you know, he was talking about
salt crystals. And you can say, I can have a salt crystal, and I would have a certain number of
thermodynamic variables. But I can put a polarization on the salt crystal. And now the states that I'm going
to have, the microstates that I'm going to have, will depend on the polarization. So before I had
unpolarized states, and I have polarized states, which are more because... And then you can say,
I can do the next, you know, instead of linear polarization, you can make, I don't remember,
the quadrupole. There you go. And now you have a different set of systems.
James. You have more.
James. Right. You have more systems. And the entropy associated with those states
is going to be different than the entropy that you have. So this, I think, where you have a feeling
that it's some sort of subjective.
James. Yeah. Because it depends on how you coarse-grained, no?
James. It's not coarse-graining. It's how you have defined the boundary of the system.
And once you define the boundary of the system, you say, I'm going to interact
with the system in this way, that's the definition of the system.
But this is true for all systems.
James. Okay.
So if I say I have a classical mechanics, I have a cannonball, and I studied the motion
of the cannonball, everything seems so objective.
James. Yes.
Right? But because we are on Earth, if I put the cannonball on the surface of the sun,
you're not going to be able to talk about the motion of the cannonball.
So even when you define the classical system, you have a notion, I have a boundary somewhere.
Wait, why wouldn't I be able to talk about the motion of the cannonball in the sun?
James. Because it would just vaporize and you have no cannonball.
James. Okay.
Okay.
James. Right? And so with just saying, I have a cannonball,
you're putting a constraint on the environment that you have.
You're going to have a certain temperature, pressure, you're going to have some sort of
equilibria with the environment that allows you to be able to talk about a cannonball.
Interesting.
Right? And this is true for classical mechanics and quantum mechanics as well.
If I say, oh, I have an electron and it's polarized spin-up,
well, it means that at some level, I'm going to have some magnetic trap where my electron is with
the external magnetic field oriented vertically so that my spin can be up.
Right? If I have it oriented in the other way, I wouldn't be able to…
So that's the idea. And I think that's what it's actually missing from the rest of physics.
You see, it's not that thermodynamic is weird because you have to talk about the boundaries.
No, it's on the other system, you're radiating some
outrageously simplifying assumptions and then you don't think about it.
I see.
And then you say, oh, thermodynamics is so weird.
No, it's like you've put yourself in the simplest case possible.
The case where isolated Hamiltonian mechanics, where you're completely isolated,
which means there is no interaction with the assignment.
Your system is completely closed. That's the harder assumption that you would have in practice
because nothing is really ever properly isolated. What happens on the surface of Jupiter will have
an influence on your system. But you're going to say, well, you know what?
It's small enough. I'm going to ignore it. But you are ignoring it. And the problem is that if you
don't take these assumptions out and you think about it, you don't even know what to ignore.
And then you're going to generalize both your mathematical structure, your physics and so on
to realm of applicabilities that don't work anymore because you don't know what your realm of
applicability was in the first place.
Okay. So we've gallivanted around the cannonball.
Yes.
Let's go back to what distinguishes quantum mechanics from classical mechanics.
Yes. Okay. So we said the classical mechanics is the thing that I can think of made of small pieces
and everything works. And I can study these pieces as small as I want. I have absolutely no problem.
And then you say, okay, but now I have an electron. I have an electron. I want to study the electron.
I can't take a red marker and say, oh, I'll put this dot on the electron, right? You can't say,
you know, how do we measure electrons? I don't know. You have electrons. You scatter some photons off of it.
These are the type of experiment that you do. You can't just say, oh, I'm going to scatter
the electron, but of only of this person, right? No. Either you interact with the whole of the
electron or none of the electron.
And is that actually what defines a particle?
I would think, yes. Yes. And again, it's, I can say, it depends on the circumstance. So if I'm
talking about a proton, right, at a certain skin, at a certain level of energy, the photon comes in,
interacts with the whole thing and is not going to tell me anything about the substructure. So in
those particular settings, I would say, aha, my proton is irreducible. Meaning not that there is no
substructure, is that I can't probe it. So anything that I can describe is only at the level of the whole
object. And there is no physical process that depends on the substructure. If I am in those
conditions, I can say my object is irreducible. But then I say, okay, now I take photons and I probe
the same object at higher energy. Now I can probe the substructure. And now the thing is not a single
particle. It's not a single quantum system because I can probe the inside. So I can't just use a single
wave function. So proton is not a single particle at that point, but the substructures, they are single
particles? Right now it's a mess. It's a little bit of a mess to tell you what the proton is. My wife
actually studies the structure of the proton, especially on the spin side. And there is a whole
problem of the spin crisis there. It's very complicated, but you can't describe the proton
as a single particle. And so now you have an electron, right? An electron, we haven't found any scale,
any energy level at which we can see an internal structure. So we can always assume, at least so far,
that the electron is a single irreducible thing, because there is nothing that we can set. But maybe
in a hundred years, somebody very clever will find a way... Strings underneath.
I... whatever. And then it's not going to be a single... No.
Now, in the example of strings, you don't say the electron is made of multiple strings.
You would say that one string in some vibrational mode is the electron.
Mm-hmm.
So would that be a substructure? Would that technically be a substructure? No. Well,
okay. Forget about strings. What I mean is, let's say there's something else that...
A mini electron inside the electron. In order for you to be reducible,
do you have to have more than one subpart? Or can you just have a smaller part?
Well, the whole needs to be the sum of the parts. So as long as you have one part,
you're going to have another part that you have to put together. But then you're also assuming that,
in classical mechanics, you're assuming that you can give a state to each part
independently from the other. Because you're saying the sum of the parts is... studying the parts
independently is the same as studying the whole thing. And this is not true in quantum mechanics.
Right? So if I have two particles that are entangled, that system is irreducible. Even if
there are two particles, that system is irreducible. I can't describe the system as,
oh, there are two parts and I can interact one part and study the motion of one part. No,
you can't do it. So quantum mechanics has a way to compose things and still be irreducible.
Right? And so if you have something inside, what's going to happen is that you're going to have
multiple parts and then you're going to have a quant. So here, the assumption, what I'm... I still
have to prove, again, as I said before, we get to quantum mechanics in sort of a physics-y,
hodgepodge way. I'd like to do it very precisely because I want to be assured that there is only one
way to create these quantized objects. And right now, I don't know that there is only one way.
And this is why you don't believe reductionism, even though it's associated with physics,
is ultimately... ultimately should be associated with physics. Maybe it shouldn't. Same with
mechanisms. No, it's fine to have reduction, but you have to assume that your physics description
at some point will stop. Because either we'll assume I have a fundamental structure or, in the
case of quantum mechanics, I can't observe below this threshold. This is the level at
which I can manipulate the system. Yeah. What I mean is, ultimately,
fundamental physics should be about what's at the fundament, so what is irreducible. And
if it's what's irreducible, then it can't be reduced and it can't be described with reductionism.
Right. Yes. Yeah. So the point is that either I have a system that is reducible, which I would
think it's just quantum mechanics, right? Or I do not. But then what you're doing is just
putting the level of the irreducible system below it. Right. Tell me about the early 2000s now. You
said in 1999, you started to think about these problems as to what classifies a quantum system
versus a classical or a thermodynamic system, et cetera. And now it's a couple of years later.
Take us through your academic journey and where you are in your mental framework.
Oh, so I got my degree in engineering. I was a software engineer just because I started doing
software when I was eight and nine. And when I was the choice to do physics engineering,
I said I'll do engineering first. I have much more of a stable job there. And then I had the intuition,
which turned out to be correct, that I will learn more things. I'm a generalist at heart. So in
engineering, I studied control theory, information theory, system theory, like a lot of different
things. And a lot of the idea that I got from there actually stuck. And I basically used every intuition
from every... I really like seeing the things from multiple angles. And that's why in the reverse
physics, I never liked to have just one condition. I like to have like... So for classical
amitone mechanics for one degree of freedom, I have 12 conditions that I can say, oh, this is equivalent
to this and this is equivalent to this. I really like from...
What are some of those 12?
Well, the four physical ones we already discussed, determines the irreversibility in terms of counting
states, conservation information entropy, conservation of thermodynamic entropy, which means
reversibility in thermodynamic level, and conservation of uncertainty for peak distribution. Those are the
physical ones. For the mathematical ones, there are the set of equations that you have. You have the fact
that the volumes are conserved, the fact that densities are conserved, the fact that the flow is
incompressible. If you look at phase space, how the flows goes around, you take an area, this flow is
incompressible. And then the symplectic structure is preserved, the Poisson brackets are preserved. And
then if you take the flow, rotate it 90 degrees in phase space, the curl of that flow is zero.
I think they should be all of them. But anyway, so that's what I like doing. Because
the more hats you have, the more intuition you get, and you can tie things a lot together. Because now I know
that, oh, the curl of the flow is somehow related to the conservation of information entropy, right?
Why is that? And then you look, oh, that's what's happening. And take us through some more of those
insights that you've had, where you've examined something, it could be physics related, but it
could also be math or computer science related, or even artists, even you're a musician as well,
even music related, where you thought you understood something, you realized you didn't, and then you
observed it from multiple angles and gained. Yeah, yeah, yeah. So the most beautiful thing,
it's where, it's when you don't even think that there is an explanation, and then you find it.
Because that's totally surprising. So when we do physics, we are taught that the math is the stuff
for mathematicians, right? And we, you know, discrete, continuous, whatever, it's a topology, what is
this? And again, because I wanted to really understand these things, I said, okay, I need
to understand what topology is. And what I found was that there is this link between, as I said,
verifiable statements to open sets in a topology. For somebody who knows, not know what a topology is,
a topology is essentially a collection of sets for which you can do a finite intersection and
an arbitrary union. So you have two sets, you can do the finite intersection, three sets, you can do
further, but you can't do it. Now, there is this translation between set theory and logic, where
an intersection becomes the end. And as we said before, if I have two verifiable statements, I can make
the finite conjunction, the finite end, which becomes the finite intersection in the topology.
Or if I have a verifiable statement, I can also test the or, because as long as I have an
statement, the one terminates successfully, I can say, oh, the disjunction is true.
And you can test an ultimate, an infinite amount of ors?
And that's the issue. How many ors can I test? Because the thing is that I need to find one
element of the or, and then I can drop out. So if I have countably many ors, I can go and find the
one that terminates and stop. But if I have more than countably many, I'm not going to be able to
do it. So the verifiable statements are closed under the countable or, right? And now that you see,
oh, there is a little bit of a difference between the topology, because the topology tells you
arbitrary or, right? Arbitrary union. But then you think, okay, but I want my theory
to be physically explorable with, with tests. Yes. And even if I give you an unlimited amount
of time, the most that you're going to be able to do is test countably many.
Now, if you truly wanted it to be physical, wouldn't you say that it has to, you put some
bound, like some Bekenstein bound or some informational bound, because we only have this universe.
And so there'll be the heat death at some point. And so you put Graham's number as the ultimate
large number. Yeah. But remember we're creating models. When we create physical theories,
we create models that are valid under certain assumptions, right? So why are you going to worry
about that when at the end of the day, I'm going to worry that I'm going to say that I have a system
that is isolated. So in other words, we currently think that the universe will end in a heat death.
We don't know because that's already assuming some physical model. So let's just say
finite and not think about all the interactions. And what I mean is that when people want to say
some large number, they'll usually say that's 10 to the 600. And that's larger than the amount
of atoms there are in the universe. They'll usually use the number of atoms or maybe it should be the
number of interactions between atoms or which is a much larger number, but it doesn't matter.
There exists some finite bound. I believe it could be, could be Graham's number. Yes.
You're saying even to calculate Graham's number as the largest finite bound, assume some other
physical theory, and we're trying to not assume that. So we're just going to say finite,
not a particular number that's finite. No, I'm saying that I'm perfectly fine to assume that
there are infinitely many things because it's in the model. And in the model, I can assume that there
are infinitely many things. Even it's like the thermodynamic limit. You make the thermodynamic limit.
You say you have infinitely many particles. What do you mean? I really mean a large amount of particles,
but still in the math, you're going to do the limit with infinity. What is the problem? You do it.
You know that you're making a model. So the model doesn't have to be factually correct. The model has
to be a good approximation of what you do. Then in science, you also have another problem is that
you assume reproducibility. If you assume reproducibility, you're already saying,
I can do it one more time. Yeah. And if you assume I can do it one more time,
you're already getting infinity. I see. Can we ever do something
one more time? Technically speaking? Technically speaking, I know, I'm going to die, so no.
But in the model, you assume that. You assume, well, okay, I'm not going to be able to do it
somebody else. Like really, we want to put the physical theory that the sun is going to expand
and destroy the... It's a model. So I don't see the problem of... The problem is that, again,
you need a justification to say that this model... Like you need to know when the model holds.
And so you're basically... Your model is, okay, I'm going to have an infinite amount of time. I will
have all these tests. It's not even infinite, you see. It's arbitrary or large, which is not infinite.
And if I have a procedure that has to cope for an arbitrary large amount of time, because I can
always do something one more time, you still need to give me an algorithm that have countably many
possible tests that it can run. Even if you're not going to run all of them, but the whole thing,
defined on arbitrary time, is defined on countably many.
So at this point in your journey, it's 2010 or...
Oh no, this I figured out in 2000... How was it? I don't know, 17...
Okay, so this is quite recent. Okay, that you were thinking about the...
So the whole thing worked like this. Up until 2012, which is when I moved to Michigan,
I was sort of fussing around by myself, reading book, auditing classes on quantum field theory,
reading book of quantum... I had absolutely no will interest to do any of this. I was happy to do
essentially engineering within a big computer. So I went at CERN, and then I remained in
sort of big particle accelerator, and I was doing databases, wide area network, data distribution,
security, cyber security. There's a lot of different things, control systems. I did a lot of these
things. In 2012... So it wasn't actually particle physics?
Well, I was in support of particle physics.
What I mean is, look, we can work on creating a TV show, or we could work on ensuring that the HDMI
cables are plugged into the right place. They're both working on the TV show, technically speaking.
I'm working within the experiment, working on the software infrastructure that they have.
Or I'm working at a facility that provides the acceleration, for example, in... I don't remember
when it was 2008, 2009, something like that. It was a Brookhaven National Lab. They were creating a new
light source. A light source is basically something where you accelerate a bunch of electrons, and then
you shake the electrons to generate photons. And then those are very high energy photons that then people
use to do crystallography, all sorts of things. So it's a facility that you go, you are a researcher
somewhere, you have your experiment, you book your beamline for two weeks, you come there,
your things, you attach it, you gather your data, and then you disappear. And I was there, sort of,
at the moment of construction, working on the control systems, working on the UI part of the control
system, working on the protocol of communication with... And you were studying physics in the...
On my spare time.
On your spare time.
Yes.
Okay.
Stealing books from all these other people and that's all. And also, I was auditing quantum
field theory at Stony Brook, which is the university closer to there. And so at some point, I started,
you know, attending classes to learn. Then I moved in... But again, it was just a hobby for me. I had no...
Yeah. I had no interest or inclination. I didn't think it was my job anyway. So I don't have the
background for doing these things and so on. Then what happened in 2012 when we moved to Michigan,
and that's where some of the things about the four different ways of thinking about Hamiltonian
mechanics clicked.
Okay. But you had to have been doing research in that. So you were doing research in your spare
time or you were paid to do this research?
No, in my spare time. I was just reading book and trying to figure things out. That's it. And
it's kind of my mind was doing that by itself. It's like having a background process. I kept going,
like I, you know, I would...
My mind would think about these things while dreaming. And then you wake up and say,
Oh, I figured out this stuff. It's all like this. Completely not driven by me. It was like the
curiosity of my brain. And okay, I'll give you some stuff. And yeah. And then fuzzing around completely.
Then in 2012, where it was where I sort of... Some things started to click on the classical mechanics
side. Before... I mean, before that, I was really more interested in quantum. And then at some point,
it dawned on me, right, that what I really wanted was essentially have this dictionary between the
math and the physics, right? What is the physics represent? And I realized that to really be sure
that the dictionary was working, I would have to go from the physics to the math. Because if I...
That's the only way that I know that the dictionary is complete. If from the physics,
I'm able to recover the math. Because if I'm not able to do that, or I don't know whether I can do
that, I don't know whether I figure out all the physical calls. And then at that point, it dawned on
me, I can't do this for classical mechanics either. So it's not that I don't understand quantum mechanics.
It's I don't understand classical mechanics. I don't understand thermodynamics. I don't understand
anything. And so that was the first aha moment that I paid more attention to classical mechanics.
In 2012 was where I started putting something together. Maybe even more. I don't know. I would
have to go and read them. But at some point, those things clicked on the classical mechanics side. And
at that moment, I was still on the idea, you know, this is not my job. This is not my field. I just
need to find somebody who understands this and they can write a paper and I don't care. And I couldn't
find anybody to be interested in lots of strange things. But anyway, I couldn't find anybody could
be bothered to understand or to care about the physical motivation of classical mechanics,
which is confirmed later by the difficulty of publishing this type of stuff. But that's another
story. So I did that. And then at some point, sort of the work that I was doing as a contractor on the
control system of the Brooker National Health fizzled. And that's the moment that basically said, okay,
you know, I have this thing. Clearly, you know, if I want to do something with it, I have to do it
myself. I'm never going to be able to find somebody who takes it and does something. And so I started
auditing classes and doing this more, but still in my spare time and in a more structured way.
And with my wife also, who is a professor in physics, so she is really more academic than me.
And the first thing that I did was a proof of concept. We got some seed money from the university.
And we also involved a person in the physics department, in the math department, and a person
in the physics department. And there for me was really, can we make like a proof of concept that
we can go from scratch and get to classical and particle mechanics?
A proof of concept of the Assumptions of Physics project?
Basically, yes.
Before it was even titled Assumptions of Physics?
Correct. And this is, again, my, I guess, my engineering thinking, you know, before doing
something, you do the...
Yes, an MVP.
Ah, yes.
Right. And so I did that. And that's where, you know, I drilled it through topology and so on.
And I said, okay, this starts making sense. I can actually, like, I know it can be done.
And then from there, I shifted and shifted more work towards this. And now I'm basically doing it full-time.
And the reason that I'm doing it full-time also today is because last summer, we got a grant from
the John Templeton Foundations that allowed me... It's actually the first grant that we were able
to do for this, because there is really no money for this type of thing. And they're funding a small
part into this whole enterprise.
It sounds like what you're doing is similar to foundations of quantum mechanics,
and there's money for that, not much. What would be the classification of what you do?
Foundations of physics?
It's really foundation of physics. And there are some tie-in with also foundations of math
and philosophy of science. It's really the thing that it's in the middle. Because the game is
figuring out when I have a problem. First, I need to understand if it's a philosophical problem,
mathematical problem, or physical problem. At the beginning, you said, oh, you don't just go and
look at the philosophy. That's because, first of all, I need to identify where the problem is. So,
for example, there is a lot of literature in philosophy that takes for face value what the
physicists say that Newtonian mechanics, Lagrangian mechanics, and Hamiltonian mechanics are equivalent.
Because, of course, you are a philosopher. You read this in almost every textbook. You're going to say,
okay, this is what the physicists conclude. I'll go and do my thing. But then I look at it and say,
okay, wait a minute. Wait a minute. Lagrangian and Hamiltonian mechanics are fully identified
by one function on the state. While Newtonian mechanics is identified by the forces, which is
one force for H degree of freedom. And I can't have a diffeomorphism. These things are not equivalent.
If I have n functions, I can't just go to one function in a continuous way and come back. So,
there's something fishy there. And again, that's the math that is telling me. And then the math is
informing me that. So you go on the physics and you figure out, oh, wait a second. When you go and
derive Lagrangian mechanics and Hamiltonian mechanics in the book, there is always an assumption of
conservative forces. Are we ever able to relax that condition? And of course not. And it turns out
that the assumption of conservative forces is so strong that you take essentially, let's say,
an n-dimensional problem into a one-dimensional problem. So you discarded a lot of stuff there,
right? And again, then you know what the physics is. And then you want to go back to the math and
say, can I get from these different physical assumptions, can I go and re-get the different
math? And then it turns out you can, right? And so if you're not well-informed on all three subjects,
I don't mean so well-informed. If you don't have a general sense, you can't put your head as a
mathematician and think like a mathematician, put yourself as a philosopher and think like a
philosopher, you're never going to be able to solve this because you don't know where the problem
is, right? It's like, I have a software problem and I try to fix it in the hardware. You're never going
to solve it because it's a software problem. So here is the same. If I have the math that is wrong,
you're not going to be able to fix the physics. Or if you have the philosophy that is wrong,
the math and the physics, you're interpreted incorrectly. They can do whatever they want,
but you're never going to get to the right answer.
Yeah. You and I both share this generalist mindset.
Yeah, exactly. Yeah.
So you mentioned you had difficulty publishing.
Yes.
Explain.
Because the stuff that I'm interested in is not what most people are interested in.
I'm interested in it.
I know. That's why I have the YouTube channel because I find that the YouTube channel is
actually what keeps me sane because I see that there are people that have exactly the same question as
me. And from this simple comment, I always suspected that these things were different. I can feel the
frustration of these people that went through classes like I did. The professor who is in a
hurry, who doesn't have the time to think about all these things deeply. And quite frankly, he has
his own research. He has to get the grant and so on. He's going to tell you some answer. And you kind of
feel that that answer doesn't satisfy you. There's something fishy, but you have to take your exam and
you have to move on and get a job. And you never have the time to sit there and think. And basically,
the idiot that stayed there on the time and sit there and think, right? And I know that there are
people that are interested in this thing, but it's not what you get grants for. And if you don't
get grants for it, then you don't have people that work in the field.
So it's not that people aren't interested in it or that researchers aren't interested in it,
because this podcast has a large platform of researchers who are interested in similar
subjects as you and myself. Hopefully. It's that the grant agencies aren't interested in it.
Yes. And it has been happening for so long that the people that were interested in these topics,
either they didn't get an academic job or they had to switch their topic.
You know, follow the money, right? So what can be done?
I find people that give me lots of money. No, seriously, I don't know. I really don't know.
Like what I'm trying to do is, again, through the channel, through the activity, I'm just trying to
find a community of people that sort of can help me push and work on the project. Because as I said,
like the ambition is, oh, we have to go from scratch. We derive all the math from scratch,
all the physics. It's an outrageously large amount of work. I can't do it all by myself.
Do you analogize what you're doing to what Bertrand Russell did with math,
trying to find the foundations, the axiomatic foundations?
Yeah, yeah, yeah. As I said, it has a similar feel to foundation of mathematics and foundation of
computer science. Like they both have a foundation where the foundation is not find the theorem of
everything or the algorithm of everything, but it's to find, okay, what is math? How do we do proofs?
Right.
And what can we do with the proof?
Right.
Or what is a computer? What is a complication device? What can we do with those things? What classes of
problems?
Okay, so it's a different sort of axiomatization than, say, axiomatic quantum field theory.
Correct.
Correct. Yes. Because I'm asking, okay, in the same way, what is a math proof? What is a computation?
What is a physical theory? What are the minimal requirements that a physical theory must have?
Therefore, what is the space of physical theory? And what physical theory can we possibly have and not?
And within this context, we put there all the theories that we have so that they are classified
and categorized and re-systematized in the same way that mathematics is systematized and computer
science is systematized. Yeah.
Now, suppose someone with funding was watching this and was saying, okay, is this more than just a
theoretical interest? Is there something that you see that is practical that can come from this,
such as, for instance, when people were funding research more fundamental than quantum mechanics,
to QFT, to whatever may come beyond? They're thinking in terms of an analogy to World War II,
where they invented the bomb because of investigations into physics. Okay, so they're thinking,
can some new technology emerge from understanding what general relativity would be like combined with
the standard model? Something like that.
I have no idea. That's the first honest answer.
What I know is that, first, it's going to make teaching physics a lot better because,
again, you're going to know what you're talking about. And usually, knowing what you're talking about
helps communicating more effectively. And the other thing, and this is my feeling, is that
that I can't see a way for us to go past the current theory and do the theories that people want to do,
that unify things and so on, without doing this work. And I'll tell you like this. So,
imagine that you are in the late 1800s, you studied classical mechanics, and therefore you, well,
I don't know if you knew manifold per se, because maybe the concept wasn't so crystal clear, but you
have, you know, that's how you thought about things with points and so on. Could you imagine,
knowing that, could you predict the Hilbert spaces of quantum mechanics, the projections, postulate,
and all this? No, because the mathematics is so different. The approach to the theory is so different.
Like, the jump from classical mechanics to quantum mechanics is too far for you to be able to say,
oh yeah, I want to quantize things. I'm going to need this thing. And there, at least, we had the
experiments that we could do, both in statistical mechanics and then, you know, that tells you,
okay, well, we need something different, and there are some hints and so on. And then it was, you know,
just cram some math together. Oh, it's kind of working, then it evolved. Now, let's say that,
okay, now we want to have a theory for Planck scale or whatever those other things. To me,
I expect the same jump that we had from classical mechanics to quantum mechanics. And so, I'm expecting
the math that we need to do be completely different. Lord knows what it is. As I said,
no differential geometry, topology, I don't know what time. We're going to have a topology,
because that's what we need to connect to experimental verification. And so, I can't
imagine that we just get to the math that we have right now, generalized by mathematicians to solve
their math problems, not for the physics problems. So, it's not generalized with an intent,
oh, we are relaxing some physical assumption, we're putting others, right? And I think it's going to
be very unlikely that we're just going to have this magnitude of experimental data that we had for
quantum mechanics. So, from my perspective, if we don't go back and we understand everything,
we understand exactly what's happening from classical to quantum, such that we can have an idea,
a principle idea of what needs to happen next, I don't see it happening. And again, it's not a direct
thing, because I can't work on that first. First, you want to build a building that is taller,
that allows you to see farther. That's what the ultimate theory, the theory of everything is not
the foundation, it's the top floor. You want the top floor, very high, so you can see everything and
do everything. Very good. You need the sturdier foundation on top to build higher. And this is the
work that I'm doing. I'm trying to re-understand. When you're doing the foundation, you're not going
to redo the foundation only for the top floor. You need to redo the foundation for all the floors in
between, so all the floors are more stable, so that you can build on top. So, that's what I'm
interested in, in reorganizing all of these things, get the math right, so that all the math that we have
is physical, and all the physics that we have is in the math. We understand, we can read all the
proofs, right, as a mathematical, as a physical argument, not just as a mathematical thing that
you're drawing. No, no. Every step, right, once you know, once you have a perfect dictionary,
you can re-read the proof and say, oh, this is what I'm doing physically. I'm making the limit by making
verifiable statements that are finer and finer and finer, and that's what I'm doing, that's what
a limit is, and therefore, I can do these things. What's the latest project that's in your mind that has
this unrelenting scintillating pull to you, much like when you were in 2012 thinking about classical
mechanics, and you couldn't stop, you would even dream about it?
So, once I've started doing this all my time, the mind hasn't been so pesky, but what I'm interested
right now, it's really this general theory of ensemble space, basically the idea of ensemble
spaces, yeah, and really figuring out the basic axioms, and again, right now, for me,
the interest is to be able to do the argument of classical mechanics and quantum mechanics
well. Basically, here is what I want to be able to prove, and let's do it like this. So,
we said before, right, that areas in volumes in phase space count the number of states, right?
And they have a measure, they don't count the points, right? If I have discrete elements,
you just count the points, then that's fine. But areas in phase space, right, when you are a
continue, you have infinitely many points. So you can't just say, oh, I have infinitely many states,
because then if you double the space, like if you double the volume, you would have the same number
of states, which makes no sense. So you put mathematically a measure, and the measure is
going to be additive. So if you take two volumes that are disjoint and, you know, you double it,
you're going to have double the size. Perfect. Now, imagine that you have this volume though,
and you divide them in half and half and half and half. At some point, your count of states
will become less than one. What does it mean to have a region with less than one state? It means
nothing. Not only, remember, if you have a uniform distribution on a certain amount of states,
so the entropy is the logarithm of that number, right? If I have less than one state, it would mean
I have a logarithm of a number less than one, which is negative number. What does it mean to have
negative entry? Nothing. So this is where, in another way to say, okay, classical mechanics does
not work because it tells me that there are regions with less than one state, for the thing.
Yeah.
Now, what happens is that if you do this analog, if you try to construct an analog of this, and I
can't understand why nobody has ever done it. I've never seen it in the literature. If you do the same
analog in quantum mechanics, you look at the entropy, how it goes. Well, the entropy of a pure state
is exactly zero, and the exponential of zero is one. So every pure state count as one. And you can't
have something smaller. But the state space of quantum mechanics is still a continuous. Like,
if you take the block ball, which is the two degrees, the surface is still continuous. So what happens
if you take the surface of the whole ball and you say, how many states there are there? There are two,
because the entropy is one, two to the one is two. And if you take smaller and smaller region,
you're going to have entropy that is less than two, sorry, entropy less than one, more than zero,
which means counts of states less than two and more than one. And you're going to go to one,
right? But that clearly cannot be additive, right? And there are basically these three conditions that
you want to be able to count things, right? You want to be able to count states. And there are three
things that you would imagine. One is that every state count as one. And if you have a finite region
of phase space, of your state space, that should have a finitely many states. And you want the measure
to be additive. Well, you can't have all three, because once you have infinitely many points and
you say everyone is one, well, the count of the region with additive is going to go to infinity.
And so you have to relax one of these. And what happens is that if you are in a classical discrete
space, you relax that the finite region are going to have a finite entropy, a finite count of states.
So everything is additive and every state is counted one. On a laid-back measure, what you do in phase
space, you say, well, points are zero, but then I still have finite volumes and I have additivity.
And in quantum mechanics, you say, well, I removed the additivity. And there are a lot of things that you
can see that the weirdness of quantum mechanics comes from that additivity. But then you see,
okay, why do I want to lose that additivity? Well, because I need to be able to count states.
Every state must be one. And a finite patch with infinitely many states on top of it,
if I make a mixture of that, I still need the finite ten to pre-finitely many states.
And so this is what I like to say, that there is only one way
to create ensembles that have an entropy and a count of states, such that I have
a measure defined on a continuum that counts state, but it has a lower limit. And so the quantization
in my mind is really putting this lower limit to the count of states. Classical mechanics does not
have, because you can make things smaller and smaller and smaller. So you take one state, chop it,
chop it, chop it, chop it, chop it. In quantum mechanics, the quantization is,
I can't have less than one state. And so when you go up, things are going to look additive,
things are going to look classical. But when you go small, I know that you have this lower bound.
And just to tell you, and so this is what I'd like to have in this ensemble of spaces,
I'd like to be able to run that argument. But I want to be able to create this structure in a way
that I'll be able to use for field theory as well. And that's a challenge because it's a whole
problem of infinity. And I want to try to see if I have a path for quantizing spacetime as well,
and leave it as a possibility. Because in spacetime, you're going to have the same problem. You say,
I have a field theory. Now, I count the number of states in each field, but then I have to count
the number of degrees of freedom. And in particle mechanics, it's finite, the content one, two,
three, right? But in a field theory, you have a field for each point of physical space.
And so now you have, you know, sort of continuously many degrees of freedom. Now,
you can't say that they're infinite. That wouldn't make sense. Because if you double the region of
space, now you would have the same number of degrees of freedom. No. So what's going to happen is that
you need to put a volume measure on space. And you say, if I double the volume, I have doubly many,
twice as many degrees of freedom, right?
Well, why don't you just use the, I've mentioned this before, the Bekenstein bound?
I need things to go smoothly to zero. I can't just say, at some point, things become discrete,
because that's not what's happening. What's happening is that I have something where I still
have, you know, all these dense states. Quite frankly, it doesn't even matter if it's real
or rational. The important thing is that you have a dense, you have dense sets, and you need to count
the elements in the dense set. And you can't just say that they're infinite.
All right, Gabriel. So we talked about philosophy, math, and physics. Let's talk about math and physics.
Where does that line lay?
Okay. Yeah. So the line between math and physics is something that I, you know, had to think a lot
about, because since I want to have this sort of rigorous axiomatization approach, I need to
understand how do they do in math and whether the way that they do in math is actually good for physics,
if it's enough. And one of the things that we have sort of a wrong impression in physics or in
engineering is that math, it seems also elegant or pristine and so precise. And it feels like everything
is there and we should imitate math in some way. But this is kind of never going to work because the
way that math is able to be rigorous, like the way that they did it, is essentially to remove all the parts
that are difficult or impossible to make precise and remain only with the formal structure, the
syntactic structure that you can actually be precise about. So there are sort of a lot of things like,
what are called semantic paradoxes, like something like...
There's the largest number that can't be described, or there's the smallest number that can't be
described in so-and-so amount of characters.
Exactly, right. So that's something that if you have meaning, right, meaning is attached,
meaning is always these very fuzzy things and it always allows you to create some things like that.
And so what I guess the formalists decided, Hilbert I think was the one that pushes for this,
is they say, okay, we'll forget what the meanings are, we just have some symbols, they have some rules,
and that's it. That's all that we're going to describe in mathematics. And a lot of mathematics is now
thought in that way, in one way or another. And in a sense, that's sort of where the power of math
comes from. Because if you talk about, I don't know, Boolean lattice, for example,
well, that same structure could be representing sets of statements, so a logical structure, or sets of
sets, or it could have, like, physically could even describe the systems and subsystem relationships. So
you can study the mathematical structure, you can study the equations, regardless of where they come
from, physics, biology, economics. So in the end of the day, to the mathematician, it has an advantage
to just drop the meaning, because then their tools are more powerful, because they cannot be applied
regardless of the meaning. And in physics, we can't do that, because we have that pesky connection with
experiments. And so we can't just manipulate the symbols in any way, whatever. We need to know that
that symbol corresponds to a specific system, prepared in a specific way with the things that
we measure a specific thing. So we always have an informal system in physics, you can't just get rid of
it. And so what the challenge is, is not saying we're going to put everything in the formal system,
because it's never going to happen, the experiments are not going to suddenly become symbols. You need
to define what is advantageous to put in the formal system and what is not. And that's the hard part.
So it's not a question of whether you can do it, but it becomes, you know, sort of a technical
problem, sort of an engineeristic problem in how can you do it efficiently. Essentially, the game is to
find, again, the minimal set of axioms that you want, that you need, actually, in the form that it's
as easily justifiable from the physics. Because that surface, right, that line in between when you take
physical informal things and you put them in the formal things, that's where the things can go wrong.
Once you are in the formal system, you have the math to help you. And so those parts, and that's the
part that I'm interested in physical mathematics, getting those definitions and justification right,
it's the part that is the most difficult. And it's most difficult because I have a feeling,
and I'd like to be able to have proof for this, but again, you can't because it ties in things in the
informal system. So it's difficult to create a proof for that. I'd like to have a tight argument that shows
that whenever you're taking something from the informal system to the formal system, that is my
feeling, you are always going to make some kind of simplification. And so even a simple concept
like, you know, whether something is an orange or not, right? You go to a supermarket, you can easily
identify what is an orange or not an orange. So it seems natural that, oh, that's a true false statement,
very easy. But if you think how an orange develops, it starts with a flower, gets pollinated,
and that, right? And there is no point that you can say, oh, this is the instant where it actually
became an orange, right? So all these concepts that we have are fuzzy, and you're going to have
to make a cut. And so if you're talking about objects in a supermarket, yeah, perfectly fine,
because we're not going to have these in between, and so it's going to be either true or false.
But if you're studying biology, that statement is going to be undefined. So even defining this
property, even defining the statements themselves, I don't think there is a way to define statements
that are universally applicable in all circumstances. It's always a matter of, I have a realm of
applicability, a domain, and in that domain, in that context, that statement makes sense.
Okay, you just mentioned the word cut, which makes me think of Heisenberg cut,
which makes me think of the measurement problem. So I'm curious what you think
of the measurement problem. What have you found out? What are your current thoughts?
I don't understand what the measurement problem is, because when I talk to a lot of people,
they seem to have a different interpretation. So how would you formulate the measurement problem?
What counts as a measurement?
Uh-huh. That I don't have an answer for. And it's, again, one of those things that, for me,
lives in the informal system. And so I don't even know if I can formulate something precise.
Right. So you see, this is exactly why I asked, because there is another part
that is, why do we have two different laws of evolution, one for measurement,
and one for processes, that I think can be understood.
Oh, okay.
Right. But what counts as a measurement, that...
What separates a measurer from a measured?
Well, yes. So what I wanted to say is that in this realm,
what counts as a measurement, what counts as a measurement, and all of these problems,
are connected to the problem that I was saying before of defining boundaries between system and
environment. Because when you're saying, I have a system and make a measurement, you're basically
saying, okay, there is a system, there is a boundary.
Well, let me predict a problem with this, is that if we're saying that, then there's
necessarily something subjective, because we're going to be the ones that are dictating the boundary.
There's then the meta measurement problem of who is defining the system.
Right. So defining the system is not subjective, it's objective, but it's contextual. Like you need,
it's again, in this context, these are the things that can happen. This is what happens at the boundary.
So it's not an arbitrary... When I say I have a system and I define a boundary, I'm also defining what
is happening at the boundary. Right. So it's not just saying, oh, I'm grouping these things together,
but I'm grouping this together. There is this interaction between the boundary and the system.
Like I need to give you the boundary conditions, not just to solve the, to define the problem of
the equation, but really to be able to define the system. Right. And so part of the problem of defining
what a measurement is and how it works and all of this is because you are trying to model something
that goes across the boundary, which is even just the information that passes from one thing to the
other. And then information has to be encoded in some physical system. So something needs to happen.
And then in quantum mechanics, there is a thing that actually happens during the measurement.
And this is how I think about it. So imagine that you have your block ball for the two-state system,
right? You pick an observable, right? Which means you're picking an axis in some direction. And the points
at the axis are going to be your eigenstates. And all the points in the middle are mixtures of those two
states, right? So now imagine that you start at any other points, right? And you want to say,
oh, I'm going to make a measurement, right? Like none of these, what you're going to be predicting
after the measurement is going to be that you're going to be either in this state or this state.
So you're going to be in this, after the measurement, what you predict is that you're going to be at a
point on the axis. So what the measurement process needs to do in one way or the another, whether it's
through whatever mechanism, it doesn't really matter. What needs to happen is that that point
that is here needs to be projected on that axis. That process is a process that increases entropy.
Right. And so that's something that needs to happen. And there are a lot of people that from
other places argue that measurement devices are things that increase entropy. You have a metastable
state that gets perturbed and then falls into two equilibri, right? There is this sense that you have
something and you fall into two equilibri. And there are some people that have argued that there is
literature that shows that. But I'm trying to argue it more from a sort of more conceptual, you know,
again, from what I need to have to be able to make this make sense. And there's something else that,
yes. So I understand that this measurement process is a process that actually increases entropy.
It has given me sort of a way to think about these changes of context along the lines of what happens
in thermodynamics. So since you studied statistical mechanics and you are happy with that, you know
that there are different types of ensembles. There is the grand canonical ensemble, there is canonical
ensemble and so on. And in each of those ensembles, some quantities are the ones used to actually define
the ensemble. So if I have a cup of water and it's just sitting there and I ask you how many molecules
are there in the cup of water. Well, it's a problem because molecules keep going out and coming in.
So the molecules are fluctuating, right? And this is the overall macrostate is not defined by the
number of molecules. It's a grand canonical ensemble. It's going to be defined by temperature, volume,
and chemical potential. But now you want to really see and say, I really want to know how many molecules
are there. And so you need a way first to stop these molecules from fluctuating because otherwise
you can't even know which one you can't resolve. So what you do, you close the glass. And when you
close the glass, you transition from a grand canonical ensemble to a canonical ensemble. And now the
canonical ensemble has a volume, temperature, and number of particles well defined. And the chemical
potential is no longer well defined. Now, of course, when you close that, you can't predict exactly
how many molecules are there because the molecules were fluctuating. So the final state is going to be
a probability distribution over all the possible canonical ensembles of all the different number
of molecules with the distribution exactly matching the fluctuation that you had before.
Wait, why can't you just say, if you have a cup, you say, how many molecules are in this cup
at 2 p.m., 2.01 p.m. on the dot? Exactly. You close it at that time. Yes. And now you go counting.
Yeah. Is that well defined, what I just said? Yeah. You're closing it.
Thank you. You're closing it at the time. Do we still need to do some averaging even for a question
like that, where we give a specific time? At specific time, you are going to have the problem
that, again, things are going to be fluctuating. How do you go and measure it at that time?
Can you not just close it at that exact instant? Exactly. So when you're closing it,
Yes. You went from a grand canonical ensemble to a canonical ensemble. I see.
Like you switch the thing, the number of molecules are no longer fluctuating.
In a way, you can think of measurements in quantum mechanics doing exactly that.
So you have your spin system, right? But wouldn't that have some hidden variable associated with it?
The hidden variables, you can only define them if you're able to prepare ensembles that are at a
final resolution of what you were able to do. Right? So you are able to talk about actual number of
particles and so on in those type of ensembles because you can isolate the molecule and talk about the parts.
But now when I have a single system, right, how can I talk about the fluctuations
of the spin in terms of hidden variables without at least being able to talk about
ensembles that are better specified than just a single spin state?
So to put it like this, so imagine that you have a probability distribution, right?
You could have that probability distribution because you have a single point that is jingling around
or because you have an actual statistical distribution, something that is actually smeared
and that thing is jiggling around, or I really have something smeared and I'm just taking a piece of it.
Right? The ability for you to distinguish between these three cases
means that you're able to resolve the system at a finer level.
But if you say, oh, my system is irreducible, I don't have a finer level,
you can't distinguish between these three things.
So whether there is really like a spin that is jiggling around or something that is more
complicated that is jingling around or some kind of uniform distribution that then collapses
into something like this. To be able to distinguish those cases, you would need to,
again, have a finer level description, which assuming irreducibility tells you that you can't have.
So there are a lot of things that once you assume irreducibility,
you can get at a conceptual level at quantum mechanics without...
So if you say, okay, my system is irreducible, right? It means I cannot have a perfect value for
position of momentum. I need to have this finite entropy that smears things out. Because if everything
was at a single point, I would be able to tell you what all the parts were doing. All the parts were
exactly there with the same exact fraction of momentum. So you can't say that. So you need some
kind of smearing. You need some uncertainty principle, which actually, in Italian and other
languages, is more an indetermination principle than uncertainty principle. And I think it captures
really more what's going on. So you need to have this system to be a little bit undetermined so that
you can say, I know everything of what's going on. But once you say that, I have a distribution in
space that I can't tell what the parts of the distribution are doing, well, that thing is non-local
by definition. Because I have something that is distributed in space, but I can't say, oh, I can
follow one part in space and what it's doing. And so you can only follow the whole thing. The object
is non-local because it's irreducible. But you're not going to be able to have communication from one
side to the other, like superluminar communication, all those things. Because if you were able to detect
it, you would be able to go at a resolution that is below this uncertainty and be able to make
correlation between parts. But you can't because the system is irreducible. So you see, a lot of
this weirdness, once you swallow the bullet, it's like in relativity. You say, okay, I will concede
that the speed of light is constant. And then you're, oh, energy is equal, mass is equal energy
and all these things, right? But it's all from here, from there, right? And so I think this is
sort of the same idea. The system is irreducible. You can't know what's going on inside. Okay,
then I'm going to have a certain principle. I'm going to have that the thing is, you know, non-local.
Does that mean that we could have some bizarre laws that are just inaccessible to us?
Yes. Including retrocausality or superluminal speeds?
If they're not accessible to us, you can't even say whether they are retrocausal or superluminal.
Interesting. You can only say that because you've set up an experiment
every time that you do this, you know, this happens before that or that.
So we've talked about what's directly next for you. You're hoping to solve this problem.
I'm working on this ensemble space and trying to get that math to work out.
What's something you hope to achieve in the next 10 years?
Oh, I hope to find other people to help me
clear up and fix both the mathematics and also the philosophy of this.
What I really love, because you see, I'm okay enough to scope some of these problems,
but I don't know that I will ever be able to achieve the technical competence in all the sub
fields that I need to be able to carry the project through. I mean, it's just a matter of time.
So the thing that I've been trained myself to do is to be a translator so that I can talk to the guy who
does philosophy of...
Yeah, that's something else that unites us is that I think of theories of everything as a Rosetta Stone,
or it's, I hope it to be a Rosetta Stone.
Because academia is designed to, instead of creating the silos, they don't really know how
to talk to each other. I really had, you know, some problems. And philosophy, I think in some
senses is a worse offender because they still have this idea in mind that the philosopher is the one
that thinks by himself in a room and then comes up with this great idea and then writes this single
author paper, which...
Right. That is true. So that for people who don't know, who are watching, who aren't researchers,
in physics, it's quite common and computer science and math to have multiple co-authors,
but in philosophy, it's quite rare.
Yeah.
And I have had this problem that I did find some
PhD students that were instruments working, and I wrote a paper with one. We have another one.
They're sort of PhD students in philosophy. And one of them clearly said, you know, I can't put
so much time in this because I need to have my single author literature. Otherwise, I'm not going
to get a position and all that. And to me, it's bizarre because
you start writing the single author paper, I guess, when you're 20-something. There is so much stuff that
I had to learn on both math and physics and everything before I had even something remotely
interesting to say. I said it before, I didn't start doing this when I was... I had no expectation that I
had anything so interesting to say to go and start a research. It was only after the fact when I had
the proof, oh, oh, I'm actually doing something, that I said, okay, it's worth to me doing this.
Otherwise, I'd probably go make a lot more money doing other things.
And so you're new. Yes. What are you going to be able to say?
The hard bit right now is putting all these pieces together because it's like we have most of the
pieces scrambled around in silos that don't know how to talk to each other. And nobody's ever even able
to see that they go together. And sometimes they're not designed to go together because
the math is designed by the mathematician who doesn't know the physics and the physicist is
thinking about their things without knowing that there is some other math over there.
And so what I'm trying to put is like a framework where I said, okay, the mathematician says that,
okay, that part has to be there, but the physicist says that, so that thing can't be said like that.
It needs to be... And then the philosopher says the other thing,
and I guess his perspective needs to fit... You need to put all these things in a way
that they all fit together. But the training that all they have is only from their viewpoint.
And so a mathematician might look at my thing and says, oh, but why did you find things like that
in mathematics? Yeah, I know that in mathematics you do that, but I need to justify the axioms from
the physical. And you're not interested in the fun and perfectly fine. I'm going to reach your
structures, but it can't be the foundation of physics, a mathematical structure that you put
there without knowing. So what I'd really like to have in 10 years is to find other people like me
that are interested in getting these things. And they can be specific technical on one thing without
having the general thing. That's not a problem. I can keep the general thing. I can keep all the
things together, right? But the other person needs to... Yeah, you're the manager hiring a front-end
developer and then a back-end developer. Exactly. They don't need to know... They don't need to know
the detail of all the... Yes, exactly. It's an engineering project. It's not a research... This
is the other problem. In academia, they always think that you need a grand new idea. And if you're an
engineer, you know that most of the time you want the simplest idea that works and that creates the
list. And these are the things that I like finding. It's not, oh, the new Grassmann compactification of
the... Whatever, whatever. Like... No, the simplest math that works. And we already have a lot of math
that works. And it must be a reason why it works. There must be a physical justification for where
it works. So we need to uncover and put it together. So if I had other people to help me do this,
maybe we can finish the project before I die. And that would make me happy.
There are some researchers who are watching right now who are probably interested. Where can they find out
more about you? How can they contact you? So I have a YouTube channel, but that's mainly for
popularizing the research. So my YouTube channel is called Gabriele Carcassi. Gabriele Carcassi,
it's my name and last name. There is another YouTube channel called Assumptions of Physics,
the Research. It's where I put... I try to put every month sort of me talking for an hour, an hour and a
half of open problems that I have. And even there, I did... This June, I had a sort of an online
summer school on the Assumptions of Physics, which again, it's something that we promoted through the
internet. And all of that is recorded. So you hear me rambling for, I don't know, nine hours in all
these things that saying, these are the pieces that we have. These are the pieces that we don't have.
These are the pieces and how... So there is a lot of content there. And then of course,
we have the website, assumptionsofphysics.org, that has all the research. We have an open access,
open source book, which is, to me, it's the thing that is the output of the research. So whenever pieces
are figured out, they become an extra chapter in the book. So there is a reverse physics part that has
all of the classical mechanics, all the details, all these conditions and how their equivalents are
or they're not. And then there is the physical mathematics, where we get topologies, we get
continuous functions, and we get the real numbers. All of that is there. So if somebody wants to look at
how actually things are done, are there. And that's the idea. I'd like to run this as an open source
project. Who knows whether we're going to be able to do it or not. But I'm trying to set up the structure
more and more and more like that. And I'll try to push some of my work more online. Because again,
since there might be other people, but I don't have salary to give them, but maybe they have
another position somewhere else, and then we can collaborate. Well, if you can structure it in
a manner similar to how open source projects are structured, people contribute little bits here and
there. That would be the idea. I don't know how to do it because I don't have a template for that,
but all the software development that I did within physics was all open source. So that's sort of my
nature. I think that may be more impactful than any given one of the outputs of this project is
the entire templating of an open source physics project. Because that can then be used.
It can be used. Yeah, I understand.
You can figure that out.
Well, I would be extremely interested because I want to know what are the limitations of academia?
So academia has pros and cons and what they're pro at, they're fantastic at. So don't touch that,
but what are the cons and how can they be filled, not to supplant academia, but to supplement?
We could have a whole other two-hour discussion just on that topic. And there is a lot of things
from my perspective that the type of things that I do, academia is ill-suited by design,
but I wouldn't even want to change academia because you don't change the structure of a whole field
for the project that it's like, it wouldn't even make sense. So yeah,
but the way that I'm trying to set up, it's this year, we are having the first PhD student
coming to work with us at the university and he learned about the project years ago through the
YouTube channel. Okay. The first PhD student for this project, not for your university.
No, no, no, no, no, no, no. Quite a new university. Yes.
But that's why I started becoming more active on YouTube because I've seen that I have much more impact
through popularizing the research that I do on YouTube than all the papers that I have published.
So Gabriel, it's been fantastic. Thank you for coming all the way down.
Thank you for having me.
Thank you for coming to my hometown.
Yeah, seriously, if you want to have another conversation on the other thing on academia, that's...
I would love that. Also, thank you to our partner, The Economist.
Firstly, thank you for watching. Thank you for listening. There's now a website,
curtjimungle.org, and that has a mailing list. The reason being that large platforms like YouTube,
like Patreon, they can disable you for whatever reason, whenever they like. That's just part of
the terms of service. Now, a direct mailing list ensures that I have an untrammeled communication
with you. Plus, soon I'll be releasing a one-page PDF of my top 10 toes. It's not as Quentin Tarantino as it
sounds like. Secondly, if you haven't subscribed or clicked that like button, now is the time to do
so. Why? Because each subscribe, each like helps YouTube push this content to more people like
yourself. Plus, it helps out Kurt directly, AKA me. I also found out last year that external links
count plenty toward the algorithm, which means that whenever you share on Twitter, say on Facebook,
or even on Reddit, et cetera, it shows YouTube, Hey, people are talking about this content outside
of YouTube, which in turn greatly aids the distribution on YouTube. Thirdly, there's a
remarkably active discord and subreddit for theories of everything where people explicate toes. They
disagree respectfully about theories and build as a community, our own toe links to both are in the
description. Fourthly, you should know this podcast is on iTunes. It's on Spotify. It's on all of the
audio platforms. All you have to do is type in theories of everything and you'll find it. Personally,
I gained from rewatching lectures and podcasts. I also read in the comments that, Hey, toe listeners
also gained from replaying. So how about instead you read, listen on those platforms like iTunes,
Spotify, Google podcasts, whichever podcast catcher you use. And finally, if you'd like to support more
conversations like this, more content like this, then do consider visiting patreon.com slash Kurt J.
Mungle and donating with whatever you like. There's also PayPal. There's also crypto. There's
also just joining on YouTube. Again, keep in mind, it's support from the sponsors and you that allow
me to work on toe full time. You also get early access to ad free episodes, whether it's audio or
video. It's audio in the case of Patreon video in the case of YouTube. For instance, this episode that
you're listening to right now was released a few days earlier. Every dollar helps far more than you
think. Either way, your viewership is generosity enough. Thank you so much.
