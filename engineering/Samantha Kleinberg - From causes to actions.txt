um so I'm a computer scientist I guess um but I mostly work on problems that look like this
um so this is an intensive period of patient in the neurological intensive care unit at Columbia
where my collaborator runs this tries to treat patients it has really complex uh life has all
these different sensors they're not talking to each other um my interest is trying to make sense
of this kind of data and see if we can find causal models that maybe help them better treat patients
um I have no ability to intervene we can't do randomized trials um I have no ability to
change what's measured about the patients so life is quite difficult um but on the other hand humans
are making these decisions every day and working in these environments and so the hope is to make
this a little bit easier uh with technology it's also been weird being computer scientists sort of
um working on causality for about 15 years um there's been ebbs and flows in people's interest
in this and lots of people say things along these lines that maybe for making predictions we don't
really care how things work we just need to know that they work um my favorite part about this quote
was it was written by a former Google employee after Google flu uh really failed spectacularly
um and was predicting cases of the flu really well and then all of a sudden failed and was predicting
twice as many cases as there were um so it seems like maybe there's something else we need other
than just prediction um and so the thing I think we need is causality um so I've devoted a lot of
time to trying to get causal relationships from this observational data we have no hope of experimenting
can't change anything about what's measured we have different things measured for different patients
different things measured over time uh there's huge amounts of confounding for some books about
that um and then over the last five years um I've come to believe that causality isn't enough we
have something more than that and I think the something more is where everyone here comes in
uh because it's an understanding of people and human behavior which we're really missing in our
computational causal models so I spent five years um trying to analyze this data that came from stroke
patients um the goal is to try to understand just what's happening during recovery um we had a lot
of problems with missing data that we work to solve after five years we came up with this
um so this is a causal model this is not a base net anything here that looks like a base net is not
a base net uh just so you know um so don't be alarmed when you see cycles and things there's also hidden
time I'm not showing you all these relationships they could be positive they could be negative
they have different intensity they have different time windows um not showing you any of that because
I don't know how to visualize it in a nice way uh if you have thoughts on that let me know
um and this is what we found so we're looking at two different periods right after stroke there's
the first 96 hours in the next period um where doctors thought there might be this transition
and these are just the variables related to the brain so this is not everything that is measured
um and what we're seeing here is in general one there's more causal relationships later on which
was interesting uh maybe things are reorganizing as the patients recover and also the causes of brain
swelling which none of these variables are things you're going to know that's fine uh tw percent
everything at the bottom relates to brain swelling uh the cause of that changed over time which is
interesting because the causes of the thing that doctors care about are changing maybe your
interventions also have to change over time um so that was really exciting to me but the whole
model looks like this um and after five years I was like you have a causal model I believe it this is
really cool and my very blood collaborator said this is an unholy mess um and he was not as excited as I
was um we spent about three hours going over the model uh I was answering his questions why is the
thing not there I'm like well it never changes and so without any variation I can't find any call
relationships um other things are only measured in people who are unconscious and so again lack of
variation some things are measured at the wrong time scale and so you're only seeing things
um at equilibrium another problem we had um and so we went through this process of like me trying
to explain to him why things he expected to see weren't there why other things were there eventually
he kind of bought into it um but it wasn't the reaction I was looking for I was expecting like I've
solved all your problems and you're going to use this to treat patients and like this amazing you
know we're we're done here we've solved this recovery um but I don't think it was unique to me
for this diagram um you see these kinds of things in a lot of places this is really well-known diagram
um created to model obesity um it was intended to help policymakers and since it was created this is
the force and obesity map um it's been mostly used to show wow obesity is really complicated and I don't
know what we can do about it right so if you imagine you're trying to figure out what's going to be the
effect of your policy right which of these things can you change and if you come up with a policy to
each one of them what are its effects going to be right it's almost impossible to look at that
and figure that out um and then once I started thinking about this these kinds of diagrams are
everywhere uh these things that we think are helpful are also just used to argue that some
things are hopeless uh this was diagram about the Afghanistan war the crystal said once we
understand the slide we'll be able to win the war it's also used uh with Obamacare and so this
was the Republicans said basically this is what's going to be between you and your doctor right
and so this is gonna be the result of Obamacare this is a terrible policy basically right because
there's gonna be this overwhelming complexity um I was hoping to find a diagram showing uh
Taylor Swift's effect on the local economy couldn't find that so homework for people um but there are
tons of these diagrams right because all these systems are really really complicated and if we
want to find these accurate models of what's happening they're going to be complicated I started to
agree that you know we haven't really tested is this helping people make decisions as a computer
scientist um our valuations look like this uh they all vary a little bit but that's pretty much
similar in flavor do we find more of the correct causal relationships and do we find fewer wrong ones
right and our value system is more is better right if we find more of the correct relationships
obviously we've done a better job our algorithm is better than the other algorithm um and if we find
fewer wrong things right well that's good we want to make fewer mistakes um but it encodes this idea
that one every causal relationship is equal we're just counting up the number that we find um and
that we want to find the maximum number sometimes we also look at how much data we need or runtime or
things like that uh but really our evaluation is based on do we find more none of that really has
to do with how well people can use causal models um so I thought well computer scientists we don't know a
lot about people clearly based on some of the things we've built uh but psychologists do right and you
all have a lot of very positive news right children are great finding causal models that was really
nice um a collaborator with an MD PhD who actually does brain surgery is not um so had some concerns
there um but overall this was uplifting right that people can find causal models and use them in a
variety of situations right quite reliably um but there's also a disconnect these are generally much
simpler than the kinds of models I give to my collaborator um and my collaborator already has a
lot of hypotheses about what's going to happen right he knows a lot about the brain he knows a lot
about physiology um in some cases might be hard to change his mind because he's had a lot of evidence
about some of these things um and so he's not coming in with blank slate right where he's just
trying to you know learn how this new room works he's coming in with these ideas and trying to put
them together with the cause and love about five years ago I started wondering can the kinds of
models that we find with machine learning and AI um help people make choices in familiar situations
so um not this you know blank slate robots and aliens but everyday choices like what should we
have for breakfast or things like that so I'll show you a series of experiments they're all large
online studies um one is mechanical Turk the rest are all prolific studies um and they look kind
like this and so this is you know a familiar situation you have a person here they have
some constraints they have a goal um and they have some options and the important thing is their
options aren't you know turn variable a on or off um it's an actual action you might take in the world
and so I might give you a diagram that tells you about you know carbohydrates and fat can work
together to slow the rise of blood sugar but you're at a break of the conference and have a few
options of food and have to decide which one to get right you're not intervening on you know grams of
carbohydrate fat you're deciding should I have that croissant or not uh should I have some coffee
what's going to be the effect of that right so there are all these very specific actions to take
at this point I was still sort of hopeful um and I thought this is kind of like taking an open
book exam uh we gave some people new diagram some people saw a causal model that looks like this
and some people saw the same information in text um so that might be a difference in how
information is presented um and that's the gap of disillusionment um we did this and after all
this time spending my life arguing we need causal models people did worse with causal models
and it was really fun giving a talk about this to my funding agencies we funded all this work
um we found the causal models the positive news is people are actually pretty good they know what
they should do uh with no information accuracy is 89 uh but it points with the causal models and it
didn't really matter if they were text or diagrams um causal information seemed to hurt so this was
quite distressing uh we looked at lots of different things you know are they spending time with it
the more information we show people the more time they spend on the problem they're not ignoring it
they're doing worse um we looked at how they felt about their decisions they're becoming less
confident so not only were they making worse choices they're less confident about them and the
people who were confident shouldn't have been um and something changed we started looking at domains
where some people had experience and others didn't and there we found a difference so people who had
some experience they were doing worse people had no experience started to do better um and all these
people also did control questions like with aliens robots and did just fine and so it seemed to be
something about having this prior knowledge however we know that a lot of what people know is wrong
um we all have lots of incorrect beliefs often about health um but we don't necessarily know
that right so we thought maybe if we help people realize there's a gap in their knowledge we can
come in with our causal models and we can fill that gap so that next study trying to change what
people think they know make them more receptive to the models see how that goes um we tried two
different things uh this is also work with Jessica Marsh she's in the back uh and maybe endorses
things I'm saying maybe doesn't um and we tried two different things one subjective so lose some
explanatory depth people rate how much they know about things like how type 2 diabetes develops
write out the whole causal story of how people develop diabetes we rate their knowledge we saw the
expected drop in knowledge and we also tried just giving them a quiz with and without feedback and so
there are quizzes about diabetes knowledge true false uh people actually realize when they're guessing and so
they don't actually need the feedback of this work which is interesting so we did these two different
things to see if we do this before we give you a diagram we made you realize you need the help
uh and use it a little bit better it was not the case um and so the best we had here was the
causal model the um the interventions to help you realize limited knowledge uh inoculated you against
the drop but didn't make a causal model better than nothing and so basically causal model no information
was same inaccuracy and without the intervention people had worse results and it didn't really
matter which intervention it was the results were the same um so for a long time that was the most
positive results I have is causal models are as good as nothing um which is really really depressing
uh again spending my whole life learning causal models and arguing why they're really important
um and so I realized my mental model of the causal model was like this that you have this
gap in your knowledge I'm coming in with my causal model I'm filling this gap perfectly and you should
be really grateful and excited um and it's actually more like this that I'm giving this causal model
you are in the situation where there are different gaps in your knowledge and you really don't know
necessarily how to fit this this causal model in with what else is happening and so trying desperately
to get some positive results um we thought well maybe what if we focus people's attention
right so we're giving you the causal model when you think about how we get health guidelines and
other guidelines they're often very generic and meant for multiple situations and so if you look
at American Heart Association or different health um organizations they give you guidance on blood
pressure weight management things like that and you have to pick out which parts of that are relevant
for you right they're not just telling you here's what you specifically should do you're getting a
number of different options and a number of different things and have to figure out from that what's
important um and the same thing in our causal models like the one I showed my collaborator these are
meant for multiple situations right there are things related to brain swelling brain temperature
blood pressure all of that and he has to figure out which parts are relevant in addition to figuring
out which interventions um can affect these things so we adopted that really complicated obesity
diagram that's been derided into something that's still overwhelmingly complicated but not quite as
possible um and then developed a set of questions where um there were different uh interventions
people could do related to diet and we showed people in the simple condition just the part of
the diagram that they need and so only the causal paths that were relevant for the choice and didn't
show them anything else um and compare that to this complicated condition questions were very similar
to the other ones again with a person they have some constraints they have some goals and they want
to make one specific lifestyle choice to manage their weight here so this guy can just give up say
weight's genetic can't do anything about it um fast forward through TV commercials get some takeout
add vegetables and so on so finally here we had some positive results uh simple diagrams helped
basically once we put blinders on people give them just developing information suddenly called the
models or helping people make better choices I felt better about my choice to study cause the models
um um and the node diagram a complex diagram were basically the same um so that was not so great
the other interesting thing was in the question I showed on the previous slide um we gave people a
causal chain and in that question we didn't give them just what was needed we gave them what was
needed plus one extra node to see how that would change their preferences and what was interesting was
simplicity can also push around people's preferences people like to intervene on root nodes this is well known
um and by making something seem more like a root that suddenly becomes a much more popular answer
uh which also suggests there's some downsides when you're simplifying your models because you might
make something seem more prominent and like a more likely intervention target if it seems like a
root in your simplified model so we were quite excited by this we again had positive results finally
after many years um expanded to a lot of different domains outside of health so we looked at lifestyle
choices uh you know picking college voting uh increasing voter turnout saving for retirement
health related things in all these domains applied the same uh thing found the same result so that was
really exciting this replicated across 16 different topics in four different domains um so the same
things seem to be happening we also tested what happens if we just highlight the relevant paths
so heads of an orange even though people see the whole model had the same effect so that was good
you don't have to just you know show people one part of the model you can show the whole model and
just focus people's attention question was why is this happening um is it just you know any extra
information is it about the amount of extra information um so we tried adding just a couple
extra nodes and edges um see what would happen how about simple plus and turns out uh basically any
amount of extra information is bad um and people in that condition had the same results as the
complex diagram and no information and so it was anything whatsoever that was extraneous and not
relevant for the decision led to worse choices um one question you might have after that is you might
think I'm a person who needs all the research or I like to really beat up on stuff before I make a
choice I see all these results and think well I would do better with complex information right um in all the
other experiments we randomize people to the conditions so here we tested what if we let
people choose um and they can make different choices for each of the 16 16 domains um and so
they would see at the beginning here's what it would look like if you choose most complicated
information simplest information different things for one question your next question is going to be
about increasing voter turnout how much information do you want and so people could could choose and
also they could see over time um how much information what it would look like um and change
their choices so in terms of what people pick the most popular answer is the simplest model which is
good because that turns out to be the best model um but people do still pick no information um or say
that they want you know a little bit extra information or the complex diagram and once again we find the
same thing as the other experiments the simplest diagram is the most helpful one um and so that's that's the
choice whereas for people who think that they need the most complex diagram uh turns out they're not
right um complex diagrams here and no information were basically tied for last uh so people who think
that they don't actually need any help and they know everything or that they really need all the
details um didn't have the ability to predict that uh the other sort of interesting thing we found was
this was a much larger experiment than the others we had 1200 participants and so we could look at
demographic differences um and we found significant differences in gender also education unfortunately
for graduate students uh high levels of education were not helpful for making good decisions uh people
with less less education made better choices and consistently with every information level women
made better choices um you can see there's also distinct differences in confidence levels across
these groups um unfortunately it didn't mediate the effect but we measured confidence at the end and
it's possible with a different measure of confidence that might explain things because these these are
both really strongly correlated okay so going back to lauren's talk this morning we think of what
computer scientists find and how we evaluate what we find all the causes are the same right we're not
thinking like is this a cause that's modifiable is it's a weaker cause a fast-acting cause a stronger
cause right we're just treating them all the same and assuming that more is better um but maybe some
of those would be better for being able to modify things right and thinking that we need to prioritize
what we show people we probably should be evaluating them differently and thinking about what kinds of
causes we're finding and then show people here's what you can actually modify or act on right so if we
develop type 2 diabetes uh genetics is a risk factor but you also can't change it right and so maybe
showing people things that are not modifiable given the effect of complexity is not super helpful
um but this is not currently how we evaluate machine learning in AI um so I'll just finish by
saying I now my current belief is we need causes for action um but definitely the most complete model
is not immediately useful right there's some extra step we need after we find the causal model to make
it valuable for a person to make decisions from um I need to think about new ways of evaluating AI
machine learning right just looking at precision recall is not enough there's something else to
figure out what makes the model useful and how we can present them in ways that are useful to
people so say thanks to all the collaborators and funding agencies okay so um what do you be curious
about so in all these vignettes these are like real-world situations where people presumably
have their own intuitive model so there's a thinking for there might be some for incongruency
between the model you're showing me well I think and what you see is the results when you're trying
to bring those together um so imagine like a new situation where there's a totally novel record
experience that has no real-world basis would you expect if you're you know providing more of
um yeah yeah so it's a great question absolutely um in most of these experiments we've done this uh
I didn't show the last one we had a controlled condition with like an alien dance-off um and
presumably you know people have no experience with alien dance-offs and they do fine and there's
one sort of different uh we've done other work trying to get people's mental models um and done a
lot of work trying to figure out how do we know if we're right and what does it mean to like get
the accurate mental model um which is a hard question by itself um we've also done think aloud
studies where people describe what they're doing when they answer the questions um so it's qualitative
data and there you see people are adding so much extra stuff in that's not in there and they're like
well if she does this you know then maybe she'll walk to work every day and then like she'll get
a dog and like all this other stuff is going to happen and so it's going to have this like snowball
effect and that'll be better but none of that's in the model right uh and that's part of I
think why it's so different when the other condition like you can't add in all this other
stuff about you know the flickets because it's it's not it's like rich environment that you can
sort of contribute to whereas this other stuff you can think oh it's hard for me to take medication or
I don't like medication people write a lot people are over medicated or it's hard to do two things you
should start small and do one thing even though it's not optimal and so they think about all this
extra stuff um it's really hard to change those models which is the other thing is we've had
people draw the models before and after um one hypothesis we had was maybe there were people
who were combining into one model and they did better than people who kind of maintained two
models but it turned out that basically everyone was trying to combine into one model um weren't
doing it well and so maybe that's a place to intervene is to help them build the model or
some feedback on the model I don't know so I'd like to go back to the question of complex
models and fiction so computer science especially there's a lot of talk about it um generalization
to domains and power of different context and um where the conference models seem to fail
most might be in uh generalization to other properties it's possible maybe there's a good
subset of the model that generalizes there's other parts of the model they're specific to
the major topic so you know you've shown that there are some of the call types of models and
stable models on the environmental sites the ladies and the first question and there's a
situation just to give my answer to this question so motivation I was like well people don't follow
guidelines right so maybe if I tell you the causal story like maybe you'll you know believe that take
it um the on my to-do list is comparing if we just give you you know a directive versus giving you
something causal um if there's a different but we don't it might be there that's a little bit
different like in a real world situation like with your doctor and there's no explanation at all for
how the medication works or what it's going to do versus like some explanation versus these are maybe
the more space um so I've done a lot of experiments that are not published here because we thought
that there'd be some effect of like the model sort of topology that like density might be an effect or
number of nodes and I just might have different effects it wasn't the case we were in so many
experiments and the only thing that mattered was the number of nodes um which was really disappointing
um because there was just no feature of like cycles or yeah I really thought it surprised me a lot
the density had no effect um no so they I mean they were small enough right that like the you
know you could pull it in your memory it was they were also sort of chosen in a way when possible that
they could rule out an answer so we maybe added one that said like alcohol is bad for sleep right
and then one of your options is like I've got some wine before bed and so it should kind of
help you rule out a second answer um I think it just gives you opportunity to overthink right
I see it like when I give students exams right that there's a question that I think is so easy
and I get so many questions during the exam about the question because they don't think it could
possibly be that easy yeah it's possible uh but it's also how people get guidance right they get
extra information and so they are invited to to research that yeah okay
do you think it's a problem that you touched that not about the one they could
people basically don't understand their lives as being possible and suppose you're actually setting
up so that you couldn't intervene on them on one of the positive and then you could actually
see the effect on the other part of that we're going to be able to do and I wonder if that would
change which now when could people really check them seriously I do think the results might be
different if people could interact with the causal models the problem is like then thinking about
giving health guidance nutrition guidance and some of the domains I work it's not feasible for people
to always interact with them all when you give them information at some point you have to be
to provide static information and so the hope is to figure out how we can do that but it's not
going to be hard to have um it's not going to be hard to have a screen and have some touch no but I
mean like in a reality like a doctor's office where they're giving you something it's like
coming track of my causal model and we can make some some predictions versus like here's some
information about how this medication might work or you know how this might change your your odds of
survival
