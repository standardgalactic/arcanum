This video is brought to you by 80,000 Hours.
Hi, welcome to another episode of ColdFusion.
Before I even utter a syllable, I think we should make something clear.
When we say AI, our minds go straight to the often trashy,
consumer-generative AI that's been all over the news.
But there's a distinction between that and regular neural networks that are quietly being
used in novel ways in the background. I've called artificial intelligence a dichotomy multiple
times for this reason. And just a last bit of housekeeping. We're not going to split hairs
on semantics here, because basically artificial intelligence in the modern zeitgeist is synonymous
with neural nets, so the terms will be used interchangeably just for simplicity.
Okay, so there's no question that AI certainly has split opinions among the public.
We can take America as an example to quantify this. A 2024 YouGov poll breaks it down.
The four most common emotions towards AI are caution, concern, scepticism, and curiosity.
Interestingly, 14% think it's already more intelligent than people.
And another note, the younger people are, the more positive they're likely to view AI.
This includes views on AI's effects on society, their own life, or the economy.
Whatever the figures are globally, one quick look online will show you a fact.
A lot of people love to hate AI. Online, all you hear about is scummy companies that lie,
that over-promise its capabilities, and under-deliver. And then, there's the other end.
You also hear about sneaky companies replacing workers with AI. For example, this unfortunate guy.
I just lost my job, and I lost it to AI. I've been a graphic designer for the past eight years of my life.
On Monday this week, I got told that I'm being made redundant.
It turns out, basically, all of the material that I've provided over the past six years
is now being fed to AI and templated. A design that would take me 30 minutes now takes AI 30 seconds.
In fact, a little while back, I made an episode looking at the corporate deception when it comes to AI.
But that's all the surface stuff that everyone keeps talking about. What about something new?
What if we dug deeper and took a comprehensive look at the flip side? That is, how can AI be used for good?
What I mean is this. Are there any world-benefiting, positive applications of AI that can't be achieved
with any other technology? So in this episode, we'll explore how AI can and is making a difference in
many fields like disability support, medicine, designing better chips, and other important
sectors. Keep in mind that some of these projects featured are still in their early stages, so a lot
could change in the future. But conceptually, I found these very interesting. We'll also feature a
special segment from Tasmania, Australia. I travelled there to see how AI is being used to help replenish a
species that has declined by 95%. So in this episode, let's dive into the real-world impacts of AI.
It's no secret by now that AI is predominantly powered by NVIDIA GPUs, especially in the training
process. So much so that it's seen NVIDIA's value as a company quite literally skyrocket along with
the AI hype. These GPUs rely on powerful silicon to deliver their capabilities. But there's a twist.
Now AI is improving the very same chips that they run on. It's an interesting closed-loop cycle.
Let's see how it works. In chip manufacturing, there's a key step known as lithography. This is
where detailed circuit designs are etched into semiconductor wafers. It's achieved with something
called a photo mask. NVIDIA designed a new GPU-based algorithm along with a new library,
which accelerates computational lithography by 40 times. Basically, they've developed an algorithm
which parallelizes the task among many GPUs. This reduces the amount of time needed for computing a
photo mask from several weeks to an overnight job. The main problem was that creating photo masks used to
be a slow, arduous task that could take weeks. But now, NVIDIA has a new platform that consists of
generative AI algorithms that can speed up the process. What used to take weeks is now 40 times
faster and can be done overnight. There are 89 reticles for the NVIDIA H100. Running on CPUs,
a single reticle currently takes two weeks to process. QLitho, running on GPUs, can process a reticle
in a single eight-hour shift. NVIDIA's new platform is called QLitho and it chews through nanoscale
computational lithography problems at incredible pace and at incredibly small scales. We're talking
two nanometers in size. That's like comparing the width of a human hair to the size of a football
field. This AI-driven approach isn't all just about speed. It's about making what seemed physically
impossible possible. TSMC, the world's largest independent semiconductor foundry, is already using
this accelerated process. Other big names in the industry like ASML have joined the effort. Together,
these companies are setting the foundation for the next generation of semiconductors, aiming for
two nanometer technology and beyond. So then, if NVIDIA has been using AI to create their own chips,
you'd expect to see a huge bump in performance, right? Well, where is it? We'll take a look at
this chart comparing NVIDIA's GPU performance to Moore's Law. It's hard to know exactly how much
their AI system is helping, but AI is making a difference here. So what's the takeaway? Well,
what's fast today is about to get a whole lot faster. AI could take the computing power of tomorrow
to levels we've only dreamed of. And as a side, I'm sure most of you know about DLSS. It's NVIDIA's
AI Upscaler that manages to provide higher quality visuals without demanding excessive computational
power. Better chip design is something that one might probably expect in terms of contributions of
AI. But using AI to help regenerate kelp plants in remote parts of Australia? Well, that's new, even for me.
I was invited to travel to Tasmania, Australia to check out how AI was being used to help restore
Australia's giant kelp population, thanks to a project by Google, the Commonwealth Scientific and
Industrial Research Organisation, or CSIRO, the Institute for Marine and Antarctic Studies, or IMAS,
the Nature Conservancy, or TNC, the Great Southern Reef Foundation, and the Kelp Alliance. That's a lot of
collaboration, so something must be going on here. And before we dive into it, we've got to understand
what's at stake here. So Australia has a massive kelp forest stretching from midway down the west coast
all the way to the island nation's east coast. In fact, 70% of Australians live within 50 kilometres
or 31 miles of a kelp forest. Due to rising water temperatures, a large population of kelp has died off
over time. In Tasmania, this number is at a staggering 95%. That's right, only 5% of the original population remains.
So who cares about some undersea plants? Well, kelp is actually important in sustaining
thousands of types of sea life. For example, some animals feed off kelp, others make kelp their homes,
and other animals feed off those animals, and so on. It's a massive community and ecosystem,
with thousands of types of sea life depending on kelp. It's not hard to imagine the runaway domino
effect if the kelp forest goes permanently extinct. To get started on fixing a disaster in the making,
mapping out the scale of the problem was essential. Now doing this by hand is virtually impossible.
So how does Google's AI help? Well Google is using their own engine from Google Earth and a cloud
platform called Vertex AI to accelerate the discovery of the remaining kelp forest at superhuman speeds.
Google is partnering with the NGIS to, quote, locate and analyse kelp forests in more than 7,000
square kilometres of satellite imagery for the first time. This helps researchers paint a more complete
picture of these ecosystems. We sat down in person with Leah Kaplan, sustainability business lead at
Google in Tasmania to share more. The giant kelp is interesting because the canopy floats on the
surface, which means that we can actually detect it with satellite imagery. The reason that is important
is because understanding the entire geographical span of the giant kelp in Australia actually hasn't been
done before. And so to generate a map of where the kelp is remaining so that we can understand how
restoration efforts are progressing, that's really, really important. And it's something we can do at
scale with satellite imagery, which is just way more affordable than the old way of doing it, which was
basically to fly a plane and take photographs. So satellite imagery can be automated, the processing
and the AI detection of kelp can be automated. And so we can actually have ongoing remnant maps.
Once the mapping is carried out, Google, the CSIRO and iMAS can use AI to do what it does best,
pattern recognition and prediction. Using the 5% kelp that has survived the higher temperature range,
AI analysis can uncover the genetic patterns that enable this kind of kelp
to survive. Once that's figured out, this special kind of kelp can be bred and then used to replenish
the dying population with a new breed of heat resistant kelp. We had a tour of the CSIRO and iMAS
labs to see parts of this in action. To get more insight into the genetic profiling, I had a chat to
Andrew Carroll, Product Manager at Google Research to give some further details. So one component of any sort
of study is to understand what amount of genetic diversity is present in the species, just to
understand where the starting point is. The second set is to understand what are the traits that give
resilience to various challenges. And the key challenge here is thermal tolerance, is the ability
for kelp to withstand an increase in ocean temperatures. This research project wouldn't just make a difference in
Australia, but could have a positive impact globally. Google states that they're making the geospatial map
accessible to all scientists and the AI tools used are open source. Perhaps one of the most incredible ways that AI
could make a difference is potentially giving mobility back to those who have lost it. Introducing AI powered prosthetics.
Yeah, so it's a full, it's a full robotic arm, like there's an AI chip in here and then this like
attaches to like the remainder of my arm. There's sensors and stuff in here that reads the signals
and nerves in my arm that the surgeons remap. So like me thinking about opening and closing,
like I'm using the same nerves and stuff. He evidently looks quite happy and you can feel his joy.
Let me tell you another story. This is Sarah de Lagarde. Two years ago she lost her arm in a subway accident.
At age 45, she's gotten a new AI assisted bionic arm. It trains itself and gets better the more she uses it.
But the thing is, it's heavy and has to be charged every day. But still, the important thing is that it's given
her the ability to do everyday tasks that were once impossible. Simple things like making a coffee,
straightening her hair and hugging her daughter. The New York Times did a piece on her earlier this year
and they put it all perfectly. Quote,
AI is seeping into further fields like healthcare. While many researchers have raised alarms about AI's
risks, other experts said that those concerns must be weighed against the technology's potential to
improve lives. End quote. And that is the central theme of this episode. AI can do good.
So we've all seen prosthetics before, but how do these AI powered ones work? Neural nets and machine
learning are used in these prosthetics to interpret electric nerve signals from the patient's muscles.
It allows for more precise and intuitive control. AI basically gives the prosthetic a brain. Imagine a
prosthetic leg that knows that you're climbing a stair or a hand that can grab a cup smoothly without
spilling. That's neural networks and action. It can use sensors within the limb to gather information
from the external environment. Sensors can read the muscle signals, then move the limb, and it can be
smart and adapt. Several companies are using AI to create smarter prosthetic limbs. Ottobock offers a
bionic hand which uses AI for improved functionality and control. Rewalk is known for their powered walking
assistance system. Last year, they revealed their plan to use AI for autonomous decision making in the new
exoskeleton prototype. How long had it been since you took a step? Almost 20 years. 20 years. When
you stand up and you hadn't stood up in years, that was something that, that was the best part of it. Other
examples include Osor, an Icelandic firm that makes bionic prosthetics for lower limb amputees. Actively
powered technology allows powering users to expand their activities, including those that are still
challenging for users of passive knees. And Atom Limbs, which combines advanced sensors and machine
learning for more accurate and realistic movement in prosthetic arms. We basically cover your stump in
electrodes and you train it up with your phantom limb that we can't see but you can flex your finger,
extend your finger, rotate your wrist, rotate it the other way. And our machine learning and AI system takes
a huge amount of training and spits out a result so that now you, whenever you think, can just move. So there's
nothing in your head, nothing on your head, nothing in your arm. It's all this surface electrode and AI
that basically powers it. According to an estimate, there's over 550 million amputees worldwide.
There's 2 million in the US alone and that number is expected to double by 2050. So just take a second
to think about how many people's lives could be changed by AI and advanced prosthetics. But there's a
catch. Even though there's huge potential, this technology is not quite ready for the prime time for
people who need it most. One big reason is, as you've probably already guessed, the cost. Building
a robotic system that can mimic all the movement is quite challenging. To add to this, recreating
sensation is probably still decades away at this point, if it's even possible at all. But even with
what's available right now, it's no doubt changing lives for those who have access to it. Over time,
as the technology improves and manufacturing becomes cheaper, access will increase. And that is a great
thing. Prosthetics are just the start. But in the field of healthcare, neural networks are showing
potential. It's augmenting the way we diagnose, treat and manage health on a global scale. This graph
extensively lists the areas in which healthcare is already having an impact. Sectors such as medical
equipment prep, medical assistants, and a variety of technicians are the ones being most affected.
The implications for healthcare are enormous. And most doctors right now are sleepwalking.
They do not understand how artificial intelligence is going to completely change the practice of
medicine. I'm a doctor myself. Once more, this is not an attack against any one doctor. But I believe the
medical profession has completely sold out. And they totally deserve what is about to come to them
over the next few years. And if any doctor out there thinks they can shield themselves from these
changes, well, good luck to you because you are absolutely not going to be able to do that.
Big change ahead. Better brace yourself for that. This next section is bypassing that tired
conversation of AI replacing doctors and other healthcare workers. That's not what I'm going to be
talking about. This is more about AI helping with the heavy lifting in many ways. Google's MedLM
aims to do just that. MedLM is a set of AI tools created to do things like quickly write up patient
notes and help find important markers and diseases. The idea is to make healthcare tasks easier and more
efficient. It's not just Google though. NVIDIA has rolled out some AI tools to make surgeries and
medical imaging smarter and faster. Titans like Johnson & Johnson and GE Healthcare are on board with
NVIDIA's AI tools. Looking to the field of medicines, Arda Ural from EY Americas has seen a
positive shift in the biopharma industry. They note that AI has gone from a meaningless buzzword to a
real game changer in just a year and a half. What do they mean by this? Typically, finding new drugs is
a lengthy journey filled with research, clinical trials and testing. This process can cost pharmaceutical
companies billions of dollars and all with a high risk of failure. Now with the help of AI, they can
cut down on time and cost and that's a big deal. We can point to a few biotech companies that are
already using AI and deep learning to boost their research. For example, Recursion Pharmaceuticals is
using NVIDIA's AI supercomputer BioHive 2 to find new medicines faster. Benevolent AI checks drugs that
are almost ready for testing. They want to treat diseases that don't have good treatments yet.
Atomwise, on the other hand, utilizes its AtomNet deep learning neural network for binding affinity
prediction. This is a crucial step in the drug discovery process. This helps them find effective
drugs quickly and more often. Neural networks are speeding things up and making the whole operation
more efficient and smarter. Mr armchair skeptic out there might shout, I call BS. But this is not just
theoretical. McKinsey published a research study where they found that AI does indeed positively
impact productivity and boost success rates in biopharma research. This is a hidden movement going
on under the noses and away from all the general AI hype. Already 270 AI driven drug discovery companies
have been founded. Combined with rapid advancements, if corporate greed stays out of it, we could see new
medicines with less side effects for a cheaper price. It's a tall ask, but a man can dream.
Others in the space, like Delphi Diagnostics, have developed a test that uses AI to identify
indicators of lung cancer. Similarly, researchers at the Children's National Hospital in Washington
have created an AI tool designed to diagnose rheumatic heart disease in children.
And in the past year, there's been plenty of these medical solutions coming online.
In a previous episode not long ago, we already saw how cancer detection is being made easier
through the use of AI. All you need is a simple sample of dried blood. Detection rates can reach
up to 85%. And best of all, it's quick and cheap. And it's not just one research paper or one hospital
that's used this solution. It's almost prolific. So in science, independent verification is always great.
So this is really exciting. In robotic surgery, AI is helping doctors and surgeons with precision.
We've covered the robot surgeon DaVinci all the way back in 2018. But now it can utilize machine
learning, image recognition and more for advanced image analysis, surgical planning and real-time
adjustments tailored to the patient's unique anatomy. So in all of this, it's important to note that the
training data is critical for healthcare related solutions. The effectiveness of the data can be cut
down due to variables like demographics, age, gender and environmental factors. So even though
I think these early signs are very promising, we have to be realistic. It will probably take some time
before we see a robust, meaningful impact for the average person. But this is still a great start.
What if artificial intelligence could help create better batteries? Lithium-iron types of batteries
are crucial for everything from mobile devices to electric vehicles. But lithium is very expensive
and wreaks havoc on its immediate environment. Replacing lithium is a major challenge that could
take years and it could involve testing millions of alternative materials. AI can be extremely useful
in this context and it's already being used to great effect. In a notable study, AI was instrumental in
sifting through millions of possibilities to pinpoint 23 materials that hold promise for next generation
batteries. This collaborative effort between Microsoft and the Pacific Northwest National Laboratory
has been documented in a recent publication. In related research in early 2024, Microsoft's Nathan
Baker and his colleagues used AI to sift through 23.6 million candidate materials. It tweaked existing
electrolyte designs by replacing some lithium atoms with other elements. The result was a battery that
required 70% less lithium than other current designs. The breakthrough material that the AI
found was named N2116. Experts from the Department of Energy later ensured the practical viability of
the material. N2116 is essentially a novel electrolyte where half of the lithium atoms were replaced with sodium.
This unconventional recipe opens up exciting possibilities for battery physics. Using this
material, they were able to whip up a rough, low-conducting prototype that could turn a light bulb on.
But the thing is, from the idea to a working prototype only took nine months. A massively accelerated timescale,
especially for a brand new chemical in battery research. But of course, there's some catches, so not so fast.
There are still some questions over the training data, as the available data in battery engineering is limited,
and there could be some unforeseen complications in bringing future AI designs to life in these batteries.
But this is no doubt some cool progress.
I think it's safe to say that by now, we've been inundated with consumer-facing AI applications,
with every single company adding AI as some, quote, novel perk. Honestly, it's been overdone,
and frankly, it's annoying at this point. But as a person who's been covering neural networks on this
channel since 2015, before all of this hype, it's good to get the full picture. The stories I just
covered are ones that I personally found fascinating. It helps to see where we stand in the grand scheme
of things, and not to get too tied up in the noise. Sure, I guess some people might find it interesting to
generate AI stickers in their messaging app for whatever reason. But to have AI potentially solve some of the
broader problems of humanity, and to ultimately help us dream of a better world, as cliched as it sounds.
That's what most of us have always imagined AI to be. And now that it's showing some promise in some
of these areas, it's good to see that there's some positive movement in that direction. And that's
despite the complete mess on the other side of the coin. So what do you guys think? Feel free to share
your thoughts in the comment section below. Today, we've seen AI helping humanity. But what if you
wanted a career to do the same? Actually, have you ever thought about how long a career is? On average,
it's about 80,000 hours of your life. So it's worth spending some time to plan it. And this is where the
nonprofit 80,000 hours can help. After 10 years of conducting research with academics at Oxford
University, they've come up with some of the most fulfilling career paths. Careers to help solve some of
the world's most pressing problems. 80,000 hours has a job board that's constantly updated with
hundreds of active job openings that they think might help you have a high impact. You can filter
the job by location, role type, job requirements, and what problem area they work on. I just want
to highlight that everything that they provide is free. They're a nonprofit. Their only aim is to help
you find a fulfilling, high impact career. For example, I think the career path of information security
in high impact areas is critically important, and there'll be more demand as time passes,
and they've got an entire career review on it. Go to 80,000 hours dot org slash cold fusion to be
sent a free copy of their in-depth career guide, which helps you learn about what makes for a high
impact career, get new ideas for impactful paths, and make a plan based on what you've learned and put
it into action. So that's 80,000 hours dot org slash cold fusion. So thanks for watching,
and I hope you learnt a thing or two. Hopefully, this has opened your eyes a little bit, just to see
that AI isn't all completely bad. Anyway, that's enough from me. My name is Dagogo, and you've been
watching ColdFusion, and I'll catch you again soon for the next episode. Cheers, guys. Have a good one.
time.
