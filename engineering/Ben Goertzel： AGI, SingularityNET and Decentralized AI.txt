that the book uh consciousness explosion in a way is a similar theme to my friend ray
kurzweil's book the singularity is near er right the sequel to his 2005 book singularity is near
and i guess at some point kurzweil or his mind upload will come out with the singularity is here
right and then and then then next will be like singularity passed by and here we are doing the
same old right but with better gadgets so what i'm talking about in the consciousness explosion
is basically the path to the singularity and beyond but i'm i'm trying to take a point of view
more focused on states of mind and experience than on the gadgets and and the underlying
algorithms and and technology we've spoken a number of times um and yeah i wanted to hear about the
book although i saw on amazon it's a hundred bucks so well this paperback is cheaper i think yeah the
the color version is more expensive but there's also there's a free pdf you can download from
the consciousness explosion.ai website so you can get the book for free and the kindle version is
10 bucks or something so there's a there's that information the information is made to be free but
if you if you want a big fat book with a lot of pretty color pictures it just uh still cost money for
ink that's all could you start by introducing yourself and give some of your background and
a list of the various projects sort of in the order of their importance yeah i'm uh ben gertzel i'm
originally a mathematician but i've been doing ai since the late late 1980s since long before
it became such a popular thing to do i i introduced the term and concept of agi in i guess 2005 in a
book titled artificial general intelligence and i've i've been working on both r d aimed at building
general intelligence and applications of ai in diverse vertical markets over many decades
uh among various other things i led the software team behind sophia who was the first robot citizen
you know robot made from uh henson robotics in hong kong where i was chief scientist for for
a number of years since 2017 i've been ceo of singularity net which is the the leading blockchain
based platform for decentralizing ai and we've recently done a tokenomic merger of singularity net
with two other blockchain ai projects fetch and ocean making me now the ceo of the asi alliance the
artificial super intelligence alliance so that's a sampling of sampling some of the things i'm i'm
engaged engaged with now i'm also dealing with a lot of application ai application projects we see uh
behind me on the wall the desdemona robot who uh is the lead lead singer of the desdemona's dream band
where i play the keyboards and we've got a lot of uh ai generated singing and uh music and so forth
going on so now yeah it's a incredible time to be in the ai field right both in terms of agi r d
and and in terms of just applying ai to all sorts of practical things yeah i i you know we have
spoken before i don't know if you remember but i'm i'm a bit of a skeptic on uh on sophia's
contributions to ai i think it's uh it creates more confusion than anything but we we talked about that
last time um on the i'm interested in the book because um i've i've been talking to people i had
stewart hammeroff you know who's working on uh microtubules uh with roger penrose or wrote a book
on it with roger yeah yeah i know i know i know stewart moderly well i've met roger a couple times and
also james tag and others from uh penrose institute and so i i'm fairly familiar yeah so thinking yeah
yeah i wanted to hear uh your thoughts on and and uh unfortunately i haven't read the book uh but i
wanted to hear your thoughts on well first of all the premise of the book if you can tell us the
premise of the book uh but then uh on on all of this talk about uh consciousness uh surrounding
uh artificial intelligence which has caused a lot of excitement and again a lot of confusion
yeah i mean the concept of consciousness has caused a lot of confusion even setting aside artificial
intelligence it's hardly surprising the intersection of consciousness with agi should confuse people
even even more i mean we don't have a solid understanding scientifically of what consciousness
is right so we i mean we don't we don't have a scientific refutation of solipsism of the idea
that only i am a conscious being and all the rest of you are just simulate or put here to uh
alternatingly amuse and annoy me right so i mean when we we don't have consciousness even nailed down
in the human or animal or plant realm right so i mean does it does a tree hurt when you chop it down
right does the fish hurt when you hook it the best definition and i can't remember who came up with
it but uh that it's consciousness is what it's like to be something like what is it like to be a bat i
think right right but then you had quite renowned people like daniel dennis saying well that's all a
bunch of rubbish and the whole concept should be should be thrown out right so i i i mean it's uh i'm just
saying it's a deep topic i have my own fairly strongly held views on it but it is it is an
unresolved topic from the standpoint of scientific consensus even outside of the ai domain so then
when you introduce ai i mean all the confusion about consciousness propagates over to the ai domain right
so i mean you you have people like dennett was who who are are like uh well the human brain is in
essence a biological automaton and it uses this language of consciousness to describe some things
that it's doing but this whole notion of qualia and experience is a bunch of blah blah blah pretty much
and then you have folks who are panpsychist which is more the direction i go in who think
everything in the universe as some right element of of consciousness which is just manifested differently
in different kinds kinds of of systems and then i mean then then you have folks like hammer off and
penrose yeah they think conscious experience is a real thing it inheres only in certain kinds of matter
and not others and then they have a particular rather out there theory of what kinds of matter can can
manifest consciousness like you need special quantum gravity dynamics to manifest itself in bio nanotech
yeah so the philosopher galen strawson who you're probably familiar with
he is he has a book called physicalism entails panpsychism where he's arguing if you believe the
world is physical and everything is physical then you should believe everything is conscious and he tries
to argue that any other position is logically untenable which on the one hand i like his argument on the
other hand i'm not that much a materialist i don't i don't believe everything is is is physical in like a
strong meta foundational sense anyway but all that confusion propagates into the ai world so then people
are like well no robots are just machines just like people are machines they have consciousness in
the exact same meaningless sense that that that people do right then then you have other people
saying well all particles are conscious so why aren't the particles inside machines just as conscious
as the particles inside humans then you have other people saying no only certain kinds of matter can
be conscious and it just happens that humans have that kind of matter and computers in their current
form don't but maybe a quantum computer or quantum gravity supercomputer will and all this
all this is interesting pretty much all that philosophizing goes on off to the side and meanwhile we're
building ai systems with greater and greater levels of of of capability but then even once you get
to an ai system which appears to have human or superhuman capability that won't necessarily resolve all
these questions either right but there are many views on it it's like what roger penrose believes
is that you will never get human level creativity and insight based on a digital computer penrose believes
that requires some as yet poorly specified quantum gravity voodoo manifesting itself in in in how the brain
works now many others believe you could get superhuman creativity in a digital computer but it would
still have no experience right and so these these are all points of view that are are out there and
i have my own positions or intuitions but we don't have scientific proof of any of it yeah and i'm more
confident i know i'm more confident i know how to build a thinking machine with superhuman capability yeah
than i am that i understand the nuances of how consciousness interacts with or manifests itself
from from matter like it seems like we're going to discover a lot about that in the next few decades
yeah well what what's the book about then the conscious explosion yeah well that's a different
topic yeah yeah yeah so that all this is mentioned in the book but it's not necessarily the theme of the
book so that the book uh consciousness explosion in a way is a similar theme to my friend ray
kerzwell's book the singularity is near er right the sequel to this 2005 book singularity is near and
i guess at some point kerzwell or his mind upload will come out with the singularity is here right and
then and then uh then next will be like uh singularity passed by and here we are doing the same old
shit right but with better gadgets so what what i'm talking about in the consciousness explosion is
basically the path to the singularity and beyond but i'm i'm trying to take a point of view more focused
on states of mind and experience than on the gadgets and and the underlying algorithms and and technology i
mean the underlying technology for building ai of course is what i spend most of my time on right i
mean it's important it's highly technical but it's it's it's it's key but i mean you could look at the
internet similarly in both ways like there's internet technology i mean that there's all the amazing
gadgetry inside this phone that lets it make a nice screen and lets it send information to them from
satellites there's satellite technology right there's protocols on the other hand there's the internet
as a social and psychological thing as an experience for people to interact with and and build
cultures in and that depends on the underlying tech but it's also in a way a different topic than
than the underlying tech right so what what i'm trying to look at in the consciousness explosion is
what kinds of mind systems are we building what kind of mind systems are they going to grow into
what kind of mind systems are we becoming how does our own state of mind individually and culturally
how does it influence the artificial minds that we're building and and and the path of the of of
the singularity as as it unfolds right and so this is this is really a perspective on a bunch of things
that i've talked about that that great length in in in media over the over the last few years including
agi versus narrow ai super intelligence and decentralized versus versus centralized ai and so
forth because if you if you look at current commercial ai systems being built by big tech companies
as mines it's pretty scary like we're building a bunch of proto agi autistic psychopaths pretty much
which are like they're concerned with only one thing maximize eyeballs maximize revenue maximize profit
they don't care about anything else besides that they interpret all data relative to their one
particular goal they're also built without much focus on modeling themselves and understanding who
they are or understanding who they're interacting with they're like building an i thou bond with who
they're interacting with right so we're building some very particular kinds of minds in big tech companies
now they're where they're autistic psychopaths focused on spying selling people stuff they don't need
killing people who happen to live in a different country plagiarizing stuff and helping wall street to
steal people's money right so i mean we're we're building digital autistic psychopaths focused on
a few particular ways of accumulating certain sorts of of of resources and we're doing this mediated by
corporations which are also probably autistic psychopaths if you if you have to psychoanalyze
the corporations but i mean most corporations are psychopaths by design right i mean they're only concerned
with maximizing shareholder value and and everything else you have the notion of a b corporation
in the us which is supposed to balance benefit with profit maximization and china is quite different
i mean big companies by design are supposed to benefit the common good as interpreted by the ccp as
well as making money for themselves so yeah plus is to that right but then you can look at what states of mind
what states of mind people are in when creating these sorts of ai systems and what sorts of mind
interacting with these ai systems put us in right like which is quite sort of resonant with the state
of mind in the ais themselves like if you look at ai for running social networks i mean they tend to
fractionate people they tend to focus you on buying stuff you don't need and on rallying up your righteous
indignation and like whatever emotion will keep you glued to that facebook page for for as for as long as
possible so that's that's psychology of the current ai industry and the people in involved in it so then
you can ask what sort of singularity will this lead to what other sort of ai could we be building
resonating with what other states of human consciousness and what other sorts of singularity
could be could be evolved yeah well i mean you're you're talking about building minds and that's
why i was i mean your book is about the conscious there's its title consciousness explosion that's why
i was asking about yeah consciousness i mean why are you using the word mind if you don't believe that
uh a a neural network no matter how big could become conscious i personally believe
that every elementary particle has its own spark of of consciousness so i i tend to be pretty strongly
panpsychist and i i i believe strawson and other philosophers that this is pretty much the only
consistent and coherent way to think about consciousness and of course it's a lot of thinking
with a long history you can look at say the buddhist logicians uh dignega and dharmakirti from the
middle ages laid out a whole theory of mind based on the rational panpsychist view a long a long time ago
so to me that's sort of the only coherent premise i know how to begin with but it doesn't solve everything
like it could still be that i mean okay if a coffee cup has its own species of consciousness
okay but it may be a very simplistic species of consciousness that's boring relative to a human
being right so that so then that still doesn't answer you in what sense does a coffee cup feel
pain when you cut it in half because you could have some forms of consciousness that don't feel pain like
a person with pain a symbolia right or a very muted sort of pain and it does that panpsychism in itself
doesn't tell you whether a digital computer that appears to be more aware and generally intelligent
than a person is having the same sort of experience that that a person is right so i mean that i i i do
think everything is conscious but i think that's only a starting point to to invest investigating
consciousness right it's not it's not in the finishing point but i also suspect that if you have a
digital system it has the same sort of emergent patterns in its structure and dynamics as a person
has i suspect it will have the same flavor of conscious experience that that that a person has i mean it
seems seems like by far the most straightforward hypothesis i i'm just saying that's an intuition
of mine i could i've written a bunch about it in this book and elsewhere i wouldn't say it's nailed
down scientifically in the way that we've nailed down that like okay the stars are probably not angels
flying around they're probably giant balls of fire right like we are plasma at least so i mean we we
haven't we haven't nailed down theories of consciousness to that to that level yet so i mean
there may be there may be some some big surprises right and it'll be interesting to explore them i
think we're going to do experiments with brain brain interfacing and brain computer interfacing which
should be quite informative like what happens if you literally wire your brain into the digital neural
network of an ai system versus wiring your brain into a neuroid grown in a vat right like what's the
different subjective sense that you get while carrying out these these brain machine interfacing
experiments i mean i think this this should be quite informative in a sort of mix of an intuitive and
and scientific way and we'll be able to do that during during the coming decades right so there's
going to be a lot of new input coming in to form our our particular theories of of consciousness and
that's well yeah yeah yeah go on well so of i mean the the the question of consciousness aside because
i have to say if you say uh a coffee cup has some form of consciousness i think pretty much drained the
word of any real meaning well why i mean a coffee cup is in everything around us is in space and time
space and time spatial and temporal properties are imminent in everything that doesn't mean space and
time have no meaning i look at consciousness just like spatiality and temporality these are aspects that
each thing in our universe has i mean they can have different something has different spatial
locations has different positions in time different things their consciousness can have different
aspects it doesn't mean it has no meaning i mean at least that's how i look at it yeah uh wait so on
your agi work um uh what what kind of uh paradigm are you pursuing i mean there's been right now it's
everything's being built off uh transformer algorithms and and neural nets and back propagation and and uh
and all of that is are you following that model or not at all no i mean we're i'm using those systems
but they're not central to my my agi architectures i i mean i think i i view current large language models
and other deep neural nets turned on huge bodies of data as extremely interesting and useful catalogs of
human knowledge and i mean the fact that you can synthesize stuff out of these knowledge catalogs is
is amazing right i mean i mean i mean i i i i love working with with these these systems on the other hand
i i think they're doing something very different than than a human mind is is doing when it's thinking or or
than a agi system really worthy of of the name we'll be we'll be doing when it's when it's thinking
so i mean i think on the other hand my intuition is you could automate 80 or 90 percent of the human
economy using using llms and cnn's and similar technology so i mean i think it's a there's a huge
economic revolution and humanitarian revolution that can happen from these systems i don't think these
systems can ever be creative or original in the way that people are that's just not not what they're
doing they're combining a whole bunch of knowledge on the surface level on the other hand most economic
activity does not involve a great amount of creativity or originality either right most economic
activity is wrote and is doing small variations of stuff that's been done before so then i mean you
can automate it with these technologies as hardware gets optimized and the software is optimized that'll
become cheaper than having humans do this so from from a business view i can totally see why businesses
want to focus on this technology because it's there it works you can scale it up you can bring the price
down you can improve reliability and then you can automate almost all of the world economy so then
in that sense why would you worry about doing r d aimed at automating the last 10 percent of the
world economy or or transforming humanity in some way right there's so much money to be made and so much
good to be done right i mean i i think you can automate so much medical research using using llms
and then i mean you can you can automate supply chains to deliver deliver food to the impoverished like
there's great stuff to do with them bottom line is though i mean they're so far they're not agents like
they don't try to understand who they are and who you are and what is their position in the world
and they don't abstract knowledge very well they abstract knowledge a little bit but they're mostly
just building surface level indexes of detailed knowledge and i think that making leaps of creative
generalization and imagination making leaps beyond your knowledge is done by having abstracted your your
knowledge and and and and these systems aren't doing that and agency and abstraction come together in
human minds right like we we form abstractions not arbitrarily but we form the abstractions of our
detailed knowledge that will help us achieve our goals as an agent in in the world and help us maintain
our boundaries and existence as an agent in the world help us grow and develop as an agent in the
world right the the need to grow develop survive achieve goals is what drives us to make mostly appropriate
abstractions we then use these abstractions to drive creative generalization right and all that stuff
is missing in current llms and you can't just wrap an llm in like an agent rapper people tried that with
baby agi and so forth right after gbg3 came out you can't just wrap an llm in an agent architecture and have
it be an actual agent in in the way in the way that that people are i mean you need a whole different
way to think about knowledge and the representation would be knowledge memory and and and learning and
so forth so yeah we're in the open cog hyperon project which is my main attempt to build agi
we are taking quite different approach i mean we start in a way from human cognitive science and the
different kinds of memory and reasoning that the human mind seems to have like episodic memory
declarative memory procedural memory working versus midterm versus long long-term memory and the
different sorts of goals and different time scales that we have but then we're not trying to emulate
precisely how the brain works instead we're taking the different key types of memory and learning and
reasoning and processing that seem to be done in the human mind and we're realizing these using a
diversity of mathematical and computer science algorithms so on the software level we have a
large distributed knowledge graph or knowledge metagraph more properly and we we represent both
perception action reasoning learning different types of memory as different sorts of organization
within this large distributed knowledge graph which can then rewrite and modify itself in the course of
its thinking and we then we then have a blockchain software layer that lets this whole knowledge graph
run on a decentralized network of machines without any central owner owner or or controller now you you
can have transformer type stuff in there as as part of that because these networks are very good at
recognizing patterns in in data right but but in our approach recognizing patterns in data
data is not the whole thing and you can if you look at something called the common model of cognition that
was put out by paul rosenbloom and john laird and others who have been sort of good old-fashioned ai
guys even longer than me they try to articulate what are the key aspects of human cognitive science
that we need to put into an ai if we want to be human-like and you can see that current deep neural net
systems being used in the commercial world i mean they cover only a quite small percentage of the
different kinds of things that seem to happen in in inside inside the human mind but we are so relative
to this deep neural net approach we're pretty far out there relative to penrose and hammer off i mean
we're we're building stuff in digital computers so and i mean in in that sense we're relatively close to the
mainstream we're acting under the premise that by putting stuff on a large distributed decentralized
network of digital computers we can create something that thinks better than people now
i mean i've done a bunch of work in quantum computing theory too so i think once we have
like qpus we have quantum processing units to plug in on our server farms i mean i think we can upgrade
many of these algorithms in in a very interesting way like it's not that i think that won't contribute
something but i i think it's probably not necessary to get superhuman general intelligence and probably
not necessary to get intensive subjective experience in in in the ai either although the latter part
again is is a bit less certain since we don't have a real theory of experience yeah so
uh the the the knowledge let's start with the knowledge graph how do you build this knowledge
graph your business is ready to launch but what's the most important thing to do before those doors
open getting more social media followers or actually legitimizing and protecting the business you've been
busy building make it official with legal zoom as a business owner traditional legal services come
with major sticker shock getting registered or talking to an attorney shouldn't have to cost you so
much well thankfully today's sponsor legal zoom created a better way to start and stay in business
from initial formation to one-to-one legal consultation i've used legal zoom for over 10 years
and it's kept me compliant they have everything you need to launch run and protect your business
all in one place setting up your business properly and remaining compliant are things you want to
get right from the get-go but you don't have to strain your brain or wallet legal zoom saves you from
wasting hours making sense of the legal stuff at legalzoom.com you can take care of business legal
needs in just a few clicks and if you need some hands-on help their network of experienced attorneys
from around the country has your back launch run and protect your business to make it official
today at legalzoom.com and use promo code smith10 to get 10 off any legal zoom business formation product
excluding subscriptions and renewals this offer expires at the end of the year
get everything you need from setup to success at legalzoom.com and use promo code smith10 that's s-m-i-t-h-1-0
legalzoom.com and use promo code smith10 s-m-i-t-h-1-0
for me i mean there are two ways or three i guess the number one way has to be from experience just
from perception of of the world i mean percepts come into the graph patterns are recognized in
those percepts and you have the formation of a hierarchy and heterarchy of patterns inside that
knowledge graph but you can also form a knowledge graph from reading text and we use llms for that
so we we uh we use prompting and fine-tuning of open source large language models to build knowledge
graphs from existing text and from existing structures data so we have a huge like bio
knowledge graph that we got from a bunch of biology data sets and bio ontologies and so forth and you
can you can cross link all these all these things together i mean you you could build a purely
experiential learning system that just builds its knowledge graph from low level perception and we
we're experimenting with that a bit actually but it seems like if you take the view that there's
an agi race going on and your competitors are trillion dollar companies you may be able to advance
faster by taking direct experience and combining it together with with knowledge graphs you can download
and sort of cross-linking it all in the distributed system yeah and and so how how are you on the on the
the direct experience uh accumulation uh you're talking about cameras yeah yeah yeah actually let me uh let me
let me briefly introduce you to one of one of my friends here here here here in the office so we've uh
we've got this little guy here for for for example so this is a this is a in progress version of one of
our one of our mind children robots that that that we're we're building here in our little office in
in the seattle area so i mean we i've been working with hanson robotics for uh for a long time as as you
know so we had the sophia robot desdemona and so forth and we we're we're still working with with
with the the larger humanoid robots from henson robotics which is great but i i wanted something
smaller and simpler that i could just have in my house or a classroom or and recharges itself when
it runs out of power like like a roomba and is a a little smaller and simpler to deal with than than
the hanson robot so yeah i i don't think you need a human-like robotic and environment embodiment
necessarily to get to human level agi i mean that robot i just showed you will have a human-like face
somewhat similar to a hanson robot when when it's when it's all put together but i don't think you
need that for you don't need that for human level agi on the other hand it's very convenient right
because we're trying to teach the robot ourselves as humans so to the extent that the robot is
embodied in the same world that that we're embodied in on the sort of pragmatic basis
the communication pipeline you know both content wise and emotionally and self and
other modeling wise again it's clear if the robot is right like right there in your house while you
play with your kids and and your your dog and right there right there in the classroom so i think
there's something to be gained from that we also have a virtual environment though called sophiaverse
and we're building a sort of agi preschool in there so some things you can get from robots
that are hard to get in the virtual world some things are easier to get in the virtual world because
virtual characters are more capable than than current robots and then there's there's a lot of
learning an ai system can do by proving math theorems or analyzing biology data sets and doing
doing other things that are not so so much similar to the way human interfaces with with the world
right but uh for the direct experience so you you have a robot has cameras for eyes
presumably it's got microphones for ears yep um some haptics we got some haptic yeah some skin too
that's right yeah uh for for touch and and as it uh manipulates objects or moves around within an
environment what's happening with that data stream that's coming in well what what we're doing right
now we're feeding that data stream into into deep neural networks and then those deep neural networks
are connected with the the open cog hyperon knowledge graph so we can and i mean it gets technical but
i mean we can we can represent parts of the torch compute graph for the neural net as nodes and symbolic
nodes and links in in inside the the open cog atom space knowledge graph and then patterns of activation
patterns of activity in the deep neural network are then represented as nodes and links in the symbolic
system so the the approach to perception is heavily neural symbolic and similarly on the action side
so to train a particular action like a hand picking up some object we're using deep reinforcement learning
to train train a neural network but then that that reinforcement learning network
is linked into the symbolic network which deals with higher level planning so like if if the
robot is planning to go into the other room get something and bring it back to you that planning
happens on the symbolic level but the specific movements in the arms of the head is is done by a
neural net trained by deep reinforcement learning and then we have some unique ways to connect what
happens inside these deep neural networks what happens inside the symbolic knowledge graph and which is
i think you can do the perception action purely symbolically also if if you wanted to i mean there's
no reason that the you know the luminosity and hue on a pixel can't be represented as a logical atom in a
logical knowledge graph it's just there's a certain degree of pragmatism here right like we we have nicely
working systems for arm movement and visual and auditory perception due to the amazing work of other
people these are deep neural networks right so so why not why not just link these into our symbolic
knowledge graph which can do things that deep neural nets are not now good at and using deep neural
nets for what they are good at and i mean this this comes is highlights the point that there's going to
be a lot of different ways to make agi systems right like while i'm not working on neural net centered
systems now i totally think you can make a human level agi putting together a bunch a bunch of
different formal neural networks i i mean that's what deep mind is trying to do i don't i don't see
why that wouldn't work it's not what interests me most for a couple reasons like i i think that you know
neurons and neural networks evolved to be very efficient on biological wetware and they're not
necessarily the cleverest way to leverage modern computing hardware which is quite different than
biological wetware i also think humans are not that good at reasoning in in the end we're not that good
at ethics either we're wildly inconsistent so so i mean i mean i mean i think it's interesting to make a
system that empathizes with humans and resonates emotionally with humans but can do science and math
at a much higher level than than human human beings can and this this this is a big disagreement with
me and penrose we mentioned earlier in the conversation like he thinks the quantum gravity voodoo in the
brain makes us better than any digital computer at doing mathematics and i i'm almost sure that's exactly
opposite from the truth like i think what's happening in the human brain is really cool but i mean i i think
that digital computers are going to be tremendously better than us at mathematics in the same way
they're now tremendously better than us at chess and and and and go right i mean math is also a formal
manipulation game albeit a much bigger and and more more flexible one so i i don't i mean emulating
exactly how a human brain works is really really interesting right it's a computational neuroscience
problem and i think we will be better off to have some advances in brain imaging before we fall on
attack that that that problem building a super agi doesn't necessarily require us to emulate exactly
what's happening in the human brain i mean any more than building a jet requires us to exactly emulate
what happens in in an eagle's wing which we still don't fully understand yeah uh so so you you've got this
this data flowing in and you're you're building this ever increasing knowledge graph uh of of
representations these are are vectors in effect that that that you're getting from the data stream
that are there calling them vectors is not is not quite right although you can you can embed them as
as as vectors but i mean it's it's weighted labeled nodes and links right and that they can be
there's links going between nodes you have links going between two three four five or a hundred
nodes you have links going to links or sub graphs you can have types on the links in the sense of
functional programming languages you could also have vectorial labels on links but it's it's not
primarily a vector based model though and then what happens so you're building you are building that
now that that graph yeah yeah and then do you have a a a model then that that queries that graph and and
and yeah relates answers out of it and what's that it's it there there are multiple but yeah i mean so we
we have uh we have our own ai programming language called meta with two t's m-e-t-t-a which is meta type
talk you know also means loving kindness and some species of buddhism so this programming language is
basically isomorphic to the knowledge metagraph itself right so and then so you can use that
as a query language like like uh neo4j's cipher graph query language or something but we have a
probabilistic logic engine called plm probabilistic logic networks and you can you can make queries of
the knowledge graph and it will do some probabilistic and fuzzy higher order logic reasoning to try to come
up with with that with answers to your queries now if if it can't find the answer though then you're
it sticks for creating new concepts say by blending together existing concepts or you can do evolutionary
learning like a sort of probabilistically enhanced genetic programming you can use evolutionary learning
to learn new patterns and and procedures the data that feeds the evolutionary learning is in the
knowledge graph that the programs and patterns learned by evolutionary are in the knowledge graph
the evolutionary algorithm itself it's just another chunk of knowledge graph also right so you can you
can do probabilistic fuzzy reasoning to answer questions then you can do various sorts of concept
creation and pattern recognition things to try to build new knowledge to to be accessed by the
probabilistic reasoning engine that tries to answer your questions and then there's there's an explicit
motivational system where there's a certain set of goals and the system is expanding a certain percent
of its resources trying to learn procedures that it probabilistically believes will help achieve its
goals in the current context and not all of the dynamics is goal-driven some of it some of
it's goal-driven some is just spontaneous node and link building and act activation spreading and so forth
so on that at that level we're roughly trying to emulate human and animal motivational systems but not
not in every precise detail because i think in some ways that will be undesirable i i don't want a super
ai that behaves that behaves exactly exactly exactly like a human right and then that yeah there's subtle
questions here like do you let the system replace its top level goals as it gets smarter or not right
i mean i mean the system certainly would allow that the top level goals are just cognitive content in
the knowledge graph along with everything else and what's the interface that you're using uh to to interact
with this system is it is it uh a web-based uh text box is it at the most fundamental level
level the interface is programmatic right i mean the interface is meta code is code in our own
language and then you have a you have a shell and you you can you can interface via that programming
shell much like in in in lisp or something on the other hand of course there's a variety of other
interfaces you can you can build i mean you can uh you can have a natural language interface
which is is basically chatting with an llm which is then connected to the knowledge graph on on on
on the back end right and so you can you can do that and or you can have a robot a robot interface
or or a virtual character virtual character interface or something so i mean again fundamentally
for a transformer neural net like chat gpt or llama or something the fundamental interface there
is you feed a sequence of tokens and then it outputs a probabilistically weighted set of next tokens right
and that's the core interface then on top of that they use instruction tuning to build this this this
dialogue system right so our our core interface is not next token prediction our our core interface is just
running scripts in the meta programming language which is isomorphic to to the graph but then you can
build a lot of different end user interfaces on top of that have you are there i mean is this something
that that uh that that people can can interact with that you have we've not rolled this out as a product
yet no that's it's alpha i mean as a product but as a is a you know there's a something that that
that people can see can see and and interact with uh just not yet i mean it's open source code
so for developers yeah developers could download it download and interact with the system but we
haven't made a public end user interface to the thing yet mostly for performance reasons so we have
the alpha version of this open cog hyperon system and we don't most of the work between alpha and beta
is massively speeding up and decreasing the resource utilization of the of the back end because right
now it just runs slowly and takes a huge amount of resources so if you open it up you would need to
dedicate a server a number of servers to each person who's interacting with it but we we're we're making
good progress i mean our current current uh new prototype version of the meta language interpreter is
like a million times faster than the than the public alpha version right so i mean i think we're
we should be by early next year we should have a vastly more performant version of all this
infrastructure which will then obviously like that's when that's when the research gets super super
interesting right because then because right now we can either have a large knowledge graph or we can
have fast interaction but we can't have both and i think we will have solved that by sometime around
the end the end of this year and then then we're sort of off off off to the races right and it's been
like two years of work just building this infrastructure for this new version of of open cog because
we had an ai project like we started open cog in 2008 based on code that was around since 2001 or
something we did a lot of interesting research about the back ends of some commercial systems including
parts of the back end of the henson robots and some stuff in biology and financial trading and blah blah blah
but you know we couldn't scale it up to the level that transformers are scaled up
yeah so we we like we've been spending two years working on building scalable infrastructure so we
can explore the hypothesis then when we take this open cog flavor of ai and run it at a gpt4 like scale
like then we can get amazing unprecedented things to happen because because that is one of the big
lessons from lms right like you take some old stuff tweak it a little bit run at massive scale and it does way
better things so if it's we have some reasons to believe that could work with our flavor of ai also
that when you just start running it on a massively bigger scale it will start to do a lot of more
interesting things also yeah and how are you uh financing all this i remember you guys did a a uh
uh token sales yeah yeah back in 2017 or something yeah we're financing all this work primarily via
tokenomics and and and the in the cryptocurrency world so yeah i mean we we still have the the liquid
token that was the agi token we did we did it ico for in 2017 we've now merged singularity net token with
the tokens of fetch dot ai and ocean protocol into the new asi token and then we have some ai services
running on singularity net platform that you pay to use them in you pay to use them in in in the asi
token and we we then have some spin-off projects using this decentralized ai platform for things in
decentralized finance and medicine and so forth we do also we have a traditional for-profit company
called true agi which has raised a bit of equity investment and is is aimed at wrapping up open god
hyperon for the for the enterprise so there's there's some of that like traditional venture investment
aimed at the sas products but the majority of the financing is from the cryptocurrency world and then
of course all this is open source and we have some element of just random agi and enthusiasts contributing
to the to the code base also but yeah we've we've managed to do this all open source and fully
decentralized by sort of bypassing the putting silicon valley vcs and and and such at at the center
of it which was was important to me like i'm an old school that open open source is that what yeah
and the how how big was that ico and then of course you know cryptos crashed shortly after that and i i've
never i remember thinking of you when when uh cryptocurrencies uh sort of deflated uh
well they've gone up and down many times since then it's a very volatile market yeah yeah i mean
i mean all all ai crypto tokens went up in price considerably when chat gpt came out actually so since
since that time has been a more favorable time for for ai oriented cryptocurrencies but i mean we've
we've basically kept our ai team fed and productively working through the ups and downs of the of the of the
crypto markets i mean that was that was a like 36 million dollar token sale in in 2017 i i guess but
i mean that that's that's ancient history we've had a whole lot of other other crypto token things both
good and bad happen happen since that point in time yeah but then do you uh do you when as you need
capital do you uh convert uh your your cryptocurrency to us dollars or whatever we can do that i mean
not that many us dollars involved because our team is mostly not in in us and many many developers are
happy to be paid in crypto tokens for the work they do so you know you don't always need to convert to
to to to fiat money either yeah that's fascinating so yeah i mean what do you what do you want uh
listeners to to take away there's one one other brief point i didn't get to make about consciousness
which i'll take 30 seconds or a minute to make so i outline what i see is the state of consciousness
of current corporate ai systems and and the human state of consciousness that they tend to lead to so
my perspective is if to the extent that humanity can shift to a more open peaceful and compassionate
state of consciousness which we humans manage to do sometimes right i mean you can you can meditate it
can help you get there but there's there's there's no magic bullet for it but of course humans at
our best we can be compassionate lovable open-minded non-attached wonderful creatures right and
the extent to which we can verge into these states of consciousness and
infuse this into the ai systems that we're building i think this will lead us toward a happy singularity
to a far more with a far higher probability like we we want to infuse the ais we're building
with our best selves with our best states of mind with the most wonderful joyous state of mind we
can get into when we gather together we don't want to infuse the agis we're building with the states of
mind that we get into when we're trying to defeat the defeat the other team and deprive them of all
their resources and manipulate them into doing stuff that's not for their own good right so we we need to
be guiding ourselves into our best states of mind individually and collectively and then interacting with
ais in in in this vibe as we improve the the ai technology and rolled out in different applications
and this is going to be very very important for making the first agis and super intelligences
warm compassionate beneficial open-minded creatures i mean very much like when you raise children and
i've got five children and one granddaughter like when you when you raise children what you tell them is
one thing but if you if you sort of emanate sort of an ambiance of kindness compassion and openness
when you're interacting with them when they watch you interacting with others when you're doing
things together with them this makes way more difference than any rules you lay down and way
more difference than what you're telling them to do right and that that's not what we're doing in
the ai industry right now it is very much what what we should be doing and uh i talk a lot more about
this in in the consciousness explosion like how do we guide the ais we're building into the most positive
sorts of state of consciousness that that we as as as the human species understand and that's the kind
of thing that's not being thought about enough really because the ai industry is is all about
how does one company make more money than than than another one right and and that's uh
something to think about and uh you go to the consciousness explosion.ai you can download the
book for free in pdf or find your way to the kindle hardcover or paperback versions also take a look at
my website gertzel.org or singularitynet.io superintelligence.io plenty of information
online to to follow up on all the themes we've been discussing today
