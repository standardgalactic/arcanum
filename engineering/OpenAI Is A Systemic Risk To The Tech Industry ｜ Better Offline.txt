Try spinning, that's a good trick.
I'm Ed Zitron, this is Better Offline, and this is the second episode of my two-part series
where I explain how OpenAI has become a systemic risk to the tech industry.
Even with its massive $40 billion funding round, a bird-brained benefactor in the form of SoftBank,
the world's foremost authority in losing money.
Now, before I continue, shameless request, Better Offline has been nominated for a Webby,
and I want to win this thing. I've linked to it in my Twitter and my Blue Sky,
and if you could vote for me, well, it'll be in the episode notes too.
Moving on, back at it.
Okay, alright, OpenAI now has $40 billion, somehow. Right? Great, right? Well, hold your horses.
As part of its deal with SoftBank, OpenAI must also convert its bizarre non-profit structure
into a for-profit entity by December 2025, or it'll lose $10 billion from that $40 billion
amount of funding. And just to be clear, by the way, they've only really got $10 billion of that
so far. The rest is at the end of the year. Furthermore, in the event that OpenAI fails
to convert into a for-profit company by October 2026, investors in its previous $6.6 billion funding
round can claw back their investment, with it converting into a loan with an attached interest rate.
Naturally, this represents a nightmare scenario for the company, as it'll increase both its costs
and its outgoings. This is a complex situation that almost warrants its own podcast, but the
long and short of it is that OpenAI would have to effectively dissolve itself, start in the process
of reforming an entirely new entity, and distribute its assets to other non-profits or sell or license
them to a for-profit company at fair market rates, which they would not set.
It would also require valuing OpenAI's assets, which in and of itself would be a difficult task,
as well as getting past the necessary state regulators, the IRS, state revenue agencies,
and the upcoming trial with Elon Musk. Well, that only adds further problems.
I've simplified things here, and that's because, as I've said, this stuff is a little complex and
pretty boring. Suffice to say, this isn't as simple as liquidating a company and starting afresh or
submitting a couple of legal filings. It's a long, fraught process and one that will be, as
has been, subject to legal challenges, both from OpenAI's business rivals, as well as from civil
society organizations in California. You may have heard the lost monologue. Based on discussions
with experts in the field of my own research, I simply do not know how OpenAI pulls off this by
October 2026, and honestly, I'm not sure how they do it by the end of this year. It's insane. It's a,
it's a really, I just, every time I read this stuff and I write, I'm like, how is nobody else
reading this and going, what the fuck is going on? You see, this is a big problem, this non-profit
thing, because OpenAI really has become a systemic risk to the tech industry, and anything that
increases that risk is bad news for everybody. OpenAI, they've become a kind of load-bearing
company for this industry, both as a narrative, as I've discussed multiple times, as ChatGPT is the
only large-language model company with any meaningful use base, and also as a financial
entity. Its ability to meet its obligations and its future expansion plans are critical to the
future health or, in some cases, survival of multiple large companies, and that's before the
after-effects that will affect its customers as a result of any kind of financial collapse.
The parallels to the 2007 and 2008 financial crisis are starting to become a little worrying.
Lehman Brothers wasn't the largest investment bank in the world, although it was pretty big.
Just like OpenAI isn't the largest tech company, though again, it's certainly large in terms of
alleged valuation and expenditures. Lehman Brothers' collapse sparked a contagion that would later
spread throughout the entire global financial services industry, and consequently the global
economy. Now, I can see OpenAI's failure not having as big an effect, but I can imagine a
systemic effect still. You have to realize that the whole AI trade, the narrative, the bubble,
it's holding up the economy. I think like 30-35% of the U.S. stock market is in the Magnificent
Seven, and all of their bullshit numbers right now are held up by this nonsense. And like the
financial crisis, the impact in this case won't be limited to just bankers and insurers. It will
bleed into everything else. This episode is going to be a bit grim. I'm not going to lie. I want to lay
out the direct result of any kind of financial crisis at OpenAI, because I don't think anybody is
taking this seriously. Let's start with Oracle, who will lose at least a billion dollars if OpenAI
doesn't fulfill its obligations. Per the information, Oracle, which has taken responsibility
for organizing the construction of the Stargate data centers with unproven data center builder
Crusoe, and I quote the information here, may need to raise more capital to fund its data center
ambitions. Oracle has signed a 15-year lease with Crusoe, and to quote the information, is on the hook
for $1 billion in payments to that firm. To further quote the information, while that's the standard
deal length, the unprecedented size of the facility Oracle is building for just one customer makes it
riskier than a standard cloud data center used by lots of interchangeable customers, with much more
predictable needs, according to half a dozen people familiar with these types of deals.
In simpler terms, Oracle is building a giant data center for one customer, OpenAI, and has taken
on the financial burden associated with it. If OpenAI fails to expand or lacks the capital to actually pay for
its share of the Stargate data center project, Oracle is on the hook for at least a billion dollars,
and based on the information it's reporting, it's also on the hook to buy the GPUs for the site.
This is me quoting them again.
Ahem. Even before the Stargate announcement, Oracle and OpenAI had agreed to expand their
Abilene deal from two to eight data center buildings, which can hold 400,000 NVIDIA Blackwell
GPUs, adding tens of billions of dollars to the cost of the facility.
In reality, this development will likely cost tens of billions of dollars,
$19 billion of which is due from OpenAI, which does not have the money until it receives its
second tranche of funding in December 2025 from SoftBank. And this is contingent partially on
their ability to convert into a for-profit entity, which, as mentioned, is extremely difficult and
extremely unlikely. It's unclear how many of the Blackwell GPUs that Oracle has had to purchase in
advance, but in the event of any kind of financial collapse at OpenAI, Oracle would likely have to
toss at least a billion dollars, if not several billion dollars. And then we get to CoreWeave,
a company whose expansion is likely driven entirely by OpenAI now and cannot survive without
OpenAI fulfilling its obligations, if it doesn't die anyway. Now, I've written and spoken a lot about
publicly traded AI compute firm CoreWeave, and it would give me the greatest pleasure in my life to
never think or talk about them ever again, nevertheless I have to. This is my curse.
This is my curse. CoreWeave has become my curse every time I think about this. Fuck.
Okay. The Financial Times revealed a few weeks ago that CoreWeave's debt payments could balloon to
over $2.4 billion a year by the end of 2025, far outstripping its cash reserves, and the information
reported that its cash burn would increase to $15 billion in 2025. As per its IPO, filing 62% of
CoreWeave's 2024 revenue, a little under $2 billion with losses amounting to $863 million, was Microsoft
compute. And based on the conversations I've had with sources, a good amount of this was Microsoft
running compute for OpenAI. Starting October 2025, OpenAI will start paying CoreWeave as part of its
five-year-long $12 billion contract, picking up the option that Microsoft declined. This is not great
timing, or maybe it's perfect timing, because this is also when CoreWeave will have to start making
payments on their massive, stupid, multi-billion-dollar DDTL 2.0 loan mentioned in previous
episodes, but really there's a newsletter. If you want to hear me go mad, you want to read me go mad, you
read my CoreWeave piece, because it really drove me insane. Nevertheless, these CoreWeave payments, the
ones from OpenAI to CoreWeave that October, they're pretty much critical to CoreWeave's future. This deal also
suggests that OpenAI will become CoreWeave's largest customer. Microsoft had previously committed to spending
$10 billion on CoreWeave services by the end of the decade, but CEO Satya Nadella added a few months later on a
podcast that its relationship with CoreWeave was a one-time thing. Man, man, I really like, really fucking around
there. Satya, Satya don't love CoreWeave. Assuming Microsoft keeps spending at its previous rate, so about 1.66% of
$2 billion, whatever that is, something that isn't guaranteed, by the way, it would still only be half of OpenAI's
potential revenue to CoreWeave. CoreWeave's expansion at this point is entirely driven by OpenAI.
77% of its 2024 revenue came from two customers, Microsoft being the largest, and yes, I just
fucked up a number, at 62%, and using CoreWeave as auxiliary compute for OpenAI. As a result, the
future expansion efforts, the theoretical 1.3 gigawatts of contracted, and by the way, that means it
doesn't exist, compute, at CoreWeave are largely, if not entirely, for the benefit of OpenAI. In the event
that OpenAI cannot fulfill its obligations, CoreWeave will collapse. It's that fucking simple.
And then the shockwaves will ripple further. NVIDIA relies on CoreWeave for more than 6% of its
revenue, and CoreWeave's future credit worthiness to continue receiving said revenue, well, much of
that is dependent on OpenAI continuing to buy services from CoreWeave. Now, I'm basing this on a
comment I received from the legendary Gil Luria, Managing Director and Head of Technology Research
analyst DA Davison and co. I quote him, Since CoreWeave bought 200,000 GPUs last year, and those
systems are around $40,000, we believe CoreWeave spent $8 billion on NVIDIA last year. That represents
more than 6% of NVIDIA's revenue in 2024. He said last year, but I just wanted to make it sound better.
CoreWeave receives preferential access to NVIDIA's GPUs, though NVIDIA kind of denies that, and makes up
billions of dollars of NVIDIA's revenue. CoreWeave then takes those GPUs, and then they raise debt
using the GPUs as collateral, as well as customer contracts. Then they use the money they've raised
to buy more GPUs from NVIDIA. You may think, that doesn't sound right. I am being complete, like,
this is factual information at this point. NVIDIA was the anchor for CoreWeave's IPO, and CEO Michael
Entraitor said that the IPO would not have closed without NVIDIA buying $250 million worth of their
shares. NVIDIA also invested $100 million in the early days of CoreWeave's, and for reasons I
cannot understand, also agreed to spend $1.3 billion over four years, too, when I quote the
information, rent its own chips from CoreWeave. Fun fact, I can't find a single fucking mention of
CoreWeave in any of NVIDIA's filings. Now, buried in CoreWeave's S1, the document every company publishes
before going public, was a warning about counterparty credit risk, which is when one party provides services
or goods to another with specific repayment terms, and the other party doesn't meet their side of the
deal. While this was written as a theoretical, as it could, theoretically speaking, come from any
company to which CoreWeave acts as a creditor, it only named one. OpenAI. Now, as discussed previously,
CoreWeave is saying that should a customer, any customer, but really they mean OpenAI, fail to pay its
bills for infrastructure built on their behalf or services rendered, it could have a material risk to the
company. Now, as an aside, the information reported that Google, and someone's going to email me this,
so I just want to get ahead of it, that CoreWeave is apparently in advanced talks with Google to rent
GPUs. It also added another thing in this story, just so I don't have to hear from any of you,
that Google's potential deal with CoreWeave is significantly smaller than their commitments
with Microsoft, according to one of the people briefed on it, but could potentially expand in future
years. Do not come to me and claim that Google is going to save CoreWeave, I'll be so mad.
Anyway, even with Google and OpenAI's money, CoreWeave's continued ability to do business
hinges heavily on its ability to raise further debt, which I have previously called into question
in a newsletter that gave me madness, and its ability to raise future debt is, to quote the
Financial Times, secured against its more than 250,000 NVIDIA GPUs and its contracts with customers
such as Microsoft. Now, any future debt that CoreWeave raises will be based off of its contract
with OpenAI, you know, the counterparty credit risk threat that represents a disproportionate
share of its revenue that I just mentioned, and also whatever GPUs they still have left
that they can get debt on. As a result, a chunk of NVIDIA's future revenue is dependent on
OpenAI's ability to fulfill its obligations to CoreWeave, both in its ability to pay them
and their timeliness in doing so. If OpenAI fails, then CoreWeave fails, then that hurts NVIDIA.
But Jensen's going to have to go, he's going to have to go to a cheaper leather jacketarium.
And it gets worse. OpenAI's expansion is dependent on two unproven startups, one of them I just
mentioned, who are also dependent on OpenAI to live. With Microsoft's data center pullback
and OpenAI's intent to become independent from Redmond, future data center expansion is
based on two partners, supporting CoreWeave, I know, we'll get there, and Oracle. Now, I'm
referring, of course, to CoreScientific, which is the data center developer for CoreWeave,
and, of course, Crusoe, who's the data center developer for Oracle. Now, if you were wondering,
I kind of hinted at about this earlier, how many data centers, how many AI data centers do you think
Crusoe's ever built? And the answer is none. And CoreScientific, how many do you think they've
built? And the answer is also none. These are the fucking companies underpending the AI boom.
I also really must explain how difficult it is to build a data center, and how
said difficulty increases when you're building an AI-focused one. For example,
NVIDIA had to delay the launch of its Blackwell GPUs because of how finicky the associated
infrastructure, so the servers and the cooling and such, is. For customers, this was for customers
that had already been using GPUs, and therefore likely knew how to manage the temperatures created
by them. Also, as another reminder, OpenAI is on the hook for $19 billion of funding behind
Stargate, and neither of them have that money. I just want to remind you of that because it costs so
much money to build a fucking data center. And imagine, if you didn't have any experience and
effectively had to learn from scratch, how do you think it would be building these data centers?
Let's find out. So let's start in Abilene, Texas, with Crusoe and the Stargate data center project.
Now, Crusoe is a former cryptocurrency mining company that has now raised hundreds of millions
of dollars to build data centers for AI companies, starting with a $3.4 billion data center financing deal
with asset manager Blue Owl Capital. This yet-to-be-completed data center has now been
leased by Oracle, which will allegedly fill it full of GPUs for OpenAI. Despite calling itself,
and I quote, the industry's first vertically integrated AI infrastructure provider,
with the company using flared gas as a waste byproduct of oil production to power IT infrastructure,
Crusoe does not appear to have built a single AI data center, and is now being tasked with building
1.2 gigawatts at a data center capacity for OpenAI. It's just so fucking...
Crusoe is the sole developer and operator of the Abilene site, meaning according to the information
that it is in charge of contracting with construction contractors and data center customers,
as well as running the data center after it is built. Oracle, it seems, will be responsible for
filling said data center with GPUs, as mentioned. Nevertheless, the project also appears to be
behind schedule. The information reported in October 2024 that Abilene was meant to have 50,000
of NVIDIA's Blackwell AI chips in the first quarter of 2025, and also suggested that the site was
projected to have a whopping 100,000 of them by the end of 2025. Now, you can join me back here in
reality, because a report from Bloomberg in March 2025 said that OpenAI and Oracle were expected to have
16,000 available by the summer of 2025 with, and I quote, OpenAI and Oracle expecting to deploy 64,000
in video GB200s at the Stargate data center by the end of 2026. That's very delayed. That's really
delayed. Again, how I run a PR firm in that I record a podcast. I write a newsletter. I have a book I'm
writing. I got all this shit on, and I'm the asshole who notices this. Anyway, as discussed previously,
OpenAI needs this capacity very badly. According to the information, OpenAI expects Stargate to
handle three quarters of its compute by 2030, and these delays call into question at the very least
whether this schedule is reasonable or logical or even possible. And I actually really question
whether Stargate itself is possible at this point. But it can get dumber, because we're about to talk
about Core Scientific, and they are CoreWeave's friends. They're the people building data centers
for CoreWeave in Denton, Texas.
Now, as you can probably tell, I've written a great deal about CoreWeave in the past. I've got a
monologue, I've got a newsletter, and I've got a therapy bill for it. And specifically, I've written
about their build-out partner, Core Scientific, a cryptocurrency mining company, yes, another
one, that has exactly one customer for its AI data centers, and you'll never guess who it is.
It's CoreWeave. Now, here's a few fun facts about Core Scientific. Core Scientific was bankrupt last
year. Core Scientific has never built an AI data center, and its cryptocurrency mining operations
were built around ASICs, specialist computers for mining Bitcoin, which led to an analyst to tell
CNBC that said data centers would, and I quote, need to be bulldozed and built from the ground up to
accommodate AI compute. That's the stuff. Core Scientific also does not appear to have any
meaningful AI compute of any kind. It's AI slash HPC, which is high-performance computing. Revenue
represents a teeny-tiny, teeny-little percentage of overall revenue, which mostly comes from mining
crypto, both for itself and other parties. Now, hearing all of this, would you give this company
your compute? Would you think, these are the people that I am going to call to build my data
centers? If you said no, you are smarter than CoreWeave, who has given their entire 1.3 gigawatt
build-out to Core Scientific. Core Scientific also, it seems, they seem to be taking on, like,
1.14 billion dollars of capital expenditures to build these data centers, which, by the way,
is not enough money. But nevertheless, CoreWeave has promised to reimburse them at 899.3 million of
these costs. This is all from public filings, by the way. It's also unclear how Core Scientific actually
intends to do any of this shit. While they've taken on a good amount of debt in the past,
550 million dollars in the convertible note towards the end of last year, this would be more debt than
they've ever taken on. It also, as with Crusoe, does not appear to have any experience building AI
data centers, a point I keep repeating because it's very important these are the companies behind the
growth for OpenAI, except unlike Crusoe, Core Scientific is a barely-functioning, recently-bankrupted
Bitcoin miner pretending to be a data center company. Crusoe, on the other hand, is possibly also doing the
same thing, but they're less egregious about it. Now, how important do you think CoreWeave is to
OpenAI, exactly? Well, that's our semaphore. CoreWeave has been one of our earliest and largest
compute partners, OpenAI chief Sam Altman said in CoreWeave's Roadshow video, adding that CoreWeave's
compute power led to the creation of some of the models that we're best known for. CoreWeave figured
out how to innovate on hardware, to innovate on data center construction, and to deliver results
very, very quickly. Did it? But even if it did, will it survive long term? Going back to the point
of the contagion, if OpenAI fails and CoreWeave fails, so too does Core Scientific, and I don't really
fancy Crusoe's chances either. But let's take a step back for a moment. We've been going so hard,
haven't we? I've got a genuine question, just for the fact-finders out there. Does Microsoft book
OpenAI's computers' revenue? Now, up until fairly recently, Microsoft has been the entire
infrastructure backing OpenAI, but recently, to free OpenAI up to work with Oracle and see other
people, released it from its exclusive cloud compute deal. Nevertheless, per the information,
OpenAI still intends to spend $13 billion on compute on Microsoft Azure this year.
What's confusing, however, is whether any of this is booked as revenue for Microsoft. Microsoft claimed
earlier in the year that it surpassed $13 billion in annual recurring revenue, by which it means
it's last month multiplied by 12, by the way, and they said it was from AI. OpenAI's compute costs
in 2024 were $5 billion, and that's at a discounted Azure rate, which on an annualized basis would be
about $416 million in revenue a month for Microsoft. It isn't, however, clear whether Microsoft counts
OpenAI's compute as money, which is really fucking weird. You'd think with all this money they're making
from this company, they'd be saying there was money coming in. It's peculiar. I've yet to find
a real answer. Now, Microsoft's earnings do not include an artificial intelligence section. No,
they're made up of three separate segments. Productivity and business processes, which
includes things like LinkedIn, Microsoft 365, and so on. More personal computing, which includes
Windows and gaming products. And then intelligent cloud, including server products and cloud services
like Azure, which is likely where OpenAI's compute is included and where Microsoft would book the
revenue from selling access to OpenAI's models, but not OpenAI's compute? Question mark?
As a result, it's hard to say specifically where OpenAI's revenue might sit, even guessing
intelligent cloud might not be right. But based on an analysis of Microsoft's intelligent cloud
segment from financial year 2023 Q1 through its most recent earnings, there was a spike in revenue
from 23 Q1 to 24 Q1. In financial year Q1, which ended on September 30th, 2022, a month before
ChatGPT's launch, the segment made $20.3 billion. The following year, in FY24 Q1, it made $24.3 billion,
a 19.7% year-over-year growth, or roughly $4 billion. This could represent the massive increase in
training and inference costs associated with hosting ChatGPT, and they peaked at $28.5 billion in
revenue in the financial year 24 Q4, before dropping dramatically to $24.1 billion in financial year
25 Q1 and raising a little to $25.5 billion in financial year 25 Q2. I'm so sorry, none of this
is easy to read. This is a plausible explanation. OpenAI spent 2023 training its GPT-40 model before
transitioning to its massive, expensive Orion model, which would eventually become GPT-4.5,
as well as its video-generating model Sora. According to the Wall Street Journal, training
GPT-4.5 involved at least one training run costing around half a billion dollars in compute costs
alone. These are huge sums, but it's worth noting a couple things. First, Microsoft licenses OpenAI's
models to third parties, so some of this revenue could be from other companies using GPT on Azure.
We've seen lots of companies launch AI products, and not all of them are based
on LLMs. Muddying things further, Microsoft provides OpenAI access to Azure cloud services
at a discounted rate, as I've mentioned in the past. And so there's a giant question mark
over OpenAI's actual contribution to the various spikes in revenue for Microsoft's intelligent
cloud segment, or whether other third parties played a significant role. Furthermore, Microsoft's
investment in OpenAI isn't entirely in cold, hard cash. Rather, it's provided the company
with credits to be redeemed on Azure services, kind of like Chuck E. Cheese tokens. I'm not entirely
sure how this would be represented in accounting terms, and if anyone can shed any light on this,
please get in touch. Would it be noted as revenue, or something else? OpenAI isn't paying Microsoft,
or are they? Are they doing the tech equivalent of redeeming air miles, or have they spent a gift
card of Azure? It really isn't obvious, and Microsoft is doing some accounting bullshit here.
I'm not suggesting impropriety, not suggesting anything illegal. I'm just saying it's insane that they
have this company spending billions of dollars, theoretically, on their services, and it's just
nowhere. Additionally, while equity is often treated as income for tax purposes, as is the case when an
employee receives RSUs as part of their compensation package, under the existing OpenAI structure,
Microsoft isn't actually a shareholder, but rather the owner of profit-sharing units. This is a
distinction worth noting. These profit-sharing units are treated as analogous to equity, or at least
in terms of OpenAI's ability to raise capital, but in practice they aren't the same thing. They don't
represent ownership in a company as directly as, for example, a normal share would. They lack the
liquidity of a share, and the upside they provide, namely dividends, is purely theoretical. Another key
difference. When a company goes bankrupt and enters liquidation, shareholders can potentially receive a
share of the proceeds after creditors, employees, and so on are paid. While that often doesn't happen,
as in the liabilities, generally, they can exceed the assets of the company in many cases,
it's at least theoretically possible. Given that profit-sharing units aren't actual salaries,
or shares, where does that leave Microsoft? This stuff is confusing, and I'm not ashamed to say
that I just fucked up a word, and that complicated accounting questions like these are far beyond my
understanding. If anyone can shed some light, drop me an email, buzz me on Twitter or Blue Sky,
hit me up on Plurk or Gorp, or post on the Better Offline subreddit. Someone might take your wallet,
though. Anyway, back on track. I think it's worth understanding the scale of the OpenAI vortex and
how it's distorting the tech investment market, and why, even without having failed, it represents a
systemic risk. Without OpenAI, American startup investment is flat, and even with it, less startups
are receiving investment. Crunchbase News reported in early April that North American startup investment
spiked in Q1 due to OpenAI, hitting $82 billion. Great, right? Sounds great? This statement, sadly,
has a darker undertone. American startup investment was actually like $42 billion in Q1 2025 when you
remove the deal, which is appropriate because none of the money is actually received by OpenAI yet,
and at best, only $10 billion of it will be received before December 2025. This quarter also included a
$3.5 billion investment in Worm Lake Competitor Anthropic run by Wario Amadei, making the appropriate
number of Paltry $39.5 billion. Now, this is still an improvement, though a marginal one. Over the
$37.5 billion raised in Q1 2024. Nevertheless, Crunchbase News also has a far, far darker story.
Deal volume in American startups has begun to collapse, trending downward almost every quarter.
While deal volume isn't a direct result of OpenAI's financial condition, the so-called revolution
created by OpenAI and other generative AI companies' technology appears to be petering out,
and the contagion is starting to impact the wider tech sector. It's important to understand how bleak
things are. The future of generative AI rests on OpenAI, and OpenAI's future rests on near-impossible
financial requirements. I've done my best to make this argument in as objective a tone as possible,
regardless of my feelings about the bubble and its associated boosters. OpenAI, as I've said before
and argued countless times in interviews and podcasts and newsletters, it's effectively the entire
generative AI industry, with its nearest competitor being less than 5% of its 500 million weekly active
users. Anthropic, Google, Microsoft, XAI, they're all rounding errors in the grand scheme of things.
But OpenAI's future is dependent, and this is not an opinion, this is an objective fact,
on effectively infinite resources in many forms. Let's start with the financial resources. If OpenAI
required $40 billion to continue operations this year, it's reasonable to believe it will need
at least another $40 billion next year, and based on its internal projections, will need at least
$40 billion every single year until 2030, when it claims somehow it will be profitable,
and I quote the information, with the completion of the Stargate Data Centre project.
You may be wondering, how's that possible, Ed? How? You think the information wrote that down?
Fuck no. Jessica Lesson's too busy humiliating people she let go, by name, on Twitter. Jessica Lesson,
I like the information. I think you're a fucking arsehole for how you treated your people. Say it
on my podcast, I say it on Twitter. Anyway, let's keep talking about some of these resources that
OpenAI is dealing with, specifically the compute resources and expansion. OpenAI requires more
compute resources than anyone has ever needed and will continue to do so in perpetuity. Building
these resources is now dependent on two partners, Core Scientific and Crusoe, though I've never built
a data centre, as Microsoft has materially pulled back on data centre development and has, as
aforementioned, pulled back on two gigawatts of data centres. Slowed or paused, of course,
some of its early stage data centre projects too, with TD Cohen's recent analysis report saying that
data centre pullbacks were, and I quote them, March 26th, 2025, data centre channel checks letter
because it's so good, driven by the decision to not support incremental OpenAI training workloads.
That's the stuff. In simpler terms, OpenAI needs more computer at a time when its lead backer,
which has the most GPUs in the world, has specifically walked away from building it.
Even in my most optimistic frame of mind, it isn't realistic to believe that Crusoe or Core
Scientific can build the data centres necessary for OpenAI's expansion. Even if SoftBank and OpenAI
had the money to invest in Stargate today, which they do not, dollars do not change the fabric of
reality. Data centres take time to build, requiring concrete, wood, steel and other materials to be
manufactured and placed, and that's after the permitting required to get these deals done.
Even if that succeeds, getting the power necessary is a challenge unto itself, to the point that even
Oracle, an established and storied cloud compute company run by a very evil man at one point,
to quote the information, has less experience than its larger arrivals in dealing with the utilities to
secure power and working with powerful and demanding cloud customers whose plans change frequently.
A partner like Crusoe or Core Scientific simply doesn't have the muscle memory or domain
expertise that Microsoft has when it comes to building and operating data centres.
As a result, it's hard to imagine even in the best case scenario, that they're able to match
the hunger for compute that OpenAI has. Now, I want to be clear, I believe OpenAI will still
continue to use Microsoft's compute, and even expand further into whatever remaining compute
Microsoft may have. However, there is now a hard limit on how much of that there's going to be,
both literally in what's physically available, and in what Microsoft itself will actually allow
open AI to use, especially given how unprofitable GPU compute seems to be, based on how every single
company that isn't NVIDIA loses money running them.
But really, and we're coming to the end of this, which leads to a question. How does all of this end?
Last week, a truly offensive piece of fanfiction, framed as a report, called AI 2027, went viral,
garnering press with the Dwarkesh podcast and gormless childlike wonder from dope New York Times
reporter Kevin Roos. And Reporter, I think, is a fucking stretch. Its predictions vaguely suggest
a theoretical company called OpenBrain will invent a self-teaching agent of some sort. It's total
bullshit, but it captured the hearts and minds of AI boosters and other people without object
permanence, because it vaguely suggests that somehow large language models and their associated
technology will become something entirely different. I don't like making predictions like
these, because the future, especially in our current political climate, is utter chaos. But I will say
that I do not see, and I say this with complete objectivity, how any of this bullshit continues.
I want to be extremely blunt with the following points, as I feel like both members of the media and
tech analysts have categorically failed to express how ridiculous things have become.
I will be repeating myself, but it's fucking necessary, as I need you to understand how
untenable things are. SoftBank is putting itself in dire straits simply to fund OpenAI once. This
deal threatens its credit rating, with SoftBank having to take on what will be multiple loans to
fund this $40 billion round, and OpenAI will need at least another $40 billion a year later.
This is before you consider the other $19 billion that SoftBank has agreed to contribute to the data
center project with Stargate, money it does not currently have available. Now, OpenAI has
promised $19 billion to the Stargate data center project too, and again, they do not have it, and
they need SoftBank to give it to them. And again, I've said it, and I'll say it again, neither of these
companies have the money. The money is not there, and OpenAI needs Stargate to get built to grow much
further. I see no way in which OpenAI can continue to raise money at this rate, even if OpenAI somehow
actually receives the $40 billion it's been promised, which will require it to become a
for-profit entity, which I don't think it can fucking do. While it could theoretically stretch
that $40 billion to last multiple years, projections say it will burn $320 billion in the next five years.
Or more likely, I can't see a realistic way in which OpenAI gets the resources it needs to survive.
It will need this insane streak of good fortune, the kind of which you only really hear about in
Greek epic poems or JoJo's Bizarre Adventure, you know, the more cultured choice. But let's go through
them. Somehow, SoftBank gets the resources and loses the constraints required to bankroll this
company forever. The world's wealthiest entities, those sovereign wealth funds mentioned in the last
episode, SOUDS and so on, they pick up the slack until OpenAI receive, they receive, they reach
profitability, which is a huge assumption. It's also assuming that OpenAI will have enough of these
mega-wealthy benefactors to provide it with the $320 billion they need to reach profitability,
which it won't. They'll also need Crusoe and Core Scientific to turn out to be really good at
building AI infrastructure, which they've never done before. Which is, that's very possible,
I'm sure. And then Microsoft will then walk back its walk back on building new AI infrastructure and
recommit to tens of billions of dollars of CapEx, specifically on AI data centers, and also will
give it to OpenAI. And then, of course, Stargate's construction happens faster than expected, and
there are no supply chain issues in terms of labor, building materials, GPUs, and so on. Now, I don't
know, I haven't checked the news in the last three weeks, but is there anything going on that might
increase the cost of materials? Probably not. Anyway, if those things happen, I'll eat crow. I'm not
particularly worried. In the present conditions, OpenAI is on course to run out of money, or run out
of compute capacity, and it's unclear which will happen first. But what is clear is it's time to
wake up. Even in a hysterical bubble where everybody is agreeing that this is the future, OpenAI is
currently requiring more money and more compute than is reasonable to acquire. Nobody, nowhere, ever,
anywhere has ever raised as much money as OpenAI needs to. And based on the sheer amount of
difficulty that SoftBank is having, raising the funds to meet the lower tranche, the $10 billion
one of its commitment, it may not actually be possible for this company to continue. Even with
the extremely preferential payment terms, months-long deferred payments, for example, that OpenAI
probably has, at some point someone will need a dollar. Look, I'll give Sam Altman some fucking
credit. He's found many partners to shoulder the burden of the rotten economics of OpenAI,
with Microsoft, Oracle, Crusoe, and Corweave handling the upfront costs of building the infrastructure,
and SoftBank finding the investors for its monstrous, stupid round, and the tech media mostly
handling marketing for him, which is really nice. Great job, everybody. He is, however, over-leveraged.
OpenAI has never been forced to stand on its own two feet or focus on efficiency. And I believe the
constant enabling of this ugly, nonsensical burn rate has doomed this company. OpenAI has acted like
it'll always have more money and compute. And that's kind of because everyone's acted as that would be
the case. No one's really called Sam Altman out on his bullshit. There are some people, but really no
one in the mainstream media is bothered. Really, Sam Altman has been enabled. OpenAI, by the way,
cannot just make things cheaper at this point, because the money has always been there to make
things more expensive, as has the compute to make larger and larger language models that burn
billions of dollars a year. This company is not built to reduce its footprint in any way,
nor is it built for a future in which it wouldn't have access to infinite resources.
Worse still, investors in the media have run cover for the fact that these models don't really do much
more than they did a year ago, and for the overall diminishing returns of large language models writ large.
Now, I've had many people attack my work about OpenAI, but none of them, not one of them,
nobody has provided me any real counterpoint to the underlying economic argument I've made since
July of last year, that OpenAI is unsustainable. Now, this is likely because there really isn't one,
other than OpenAI will continue to raise more money than anybody has ever raised in history in
perpetuity, and will somehow turn the least profitable company of all time into a profitable
company. This is not a rational argument, it's a religious one. It's a call for faith,
and it's disgusting to see well-paid reporters with, I don't know, 150,000 subscribers to their
newsletters and a really shitty podcast with a major news outlet constantly just ignore this shit.
And I see no greater pale horse of the apocalypse than Microsoft's material pullback on data centers.
While the argument might be that Microsoft wants OpenAI to have an independent future,
that's fucking laughable when you consider Microsoft's deeply monopolistic tendencies.
And for that matter, it owns a massive proportion of OpenAI's pseudo-equity. At one point,
Microsoft's portion was valued at 49%, and while additional fundraising has likely diluted
Microsoft's stake, it still owns a massive portion of what is, at the very least,
if you believe any of this nonsense, the most valuable private startup of all time.
And we're supposed to believe that Microsoft's pullback, which limits OpenAI's access to
infrastructure it needs to train and run its models, and thus, as mentioned, represents an
existential threat to the company, you're meant to believe that this is because of some sort of
paternal desire to see OpenAI leave childhood behind, to spread its wings and enter the real world.
Are you fucking stupid? Sorry, I shouldn't be calling people stupid. I shouldn't. I really shouldn't.
But I am. More likely, Microsoft got what it needed out of OpenAI, which has reached the limit of the
models it can develop, which Microsoft, by the way, already owns the IP of due to their 2019 funding
round. There's probably no reason for Microsoft to make any further significant investments other
than just kind of throwing a little cash in there, and then I imagine some sort of tax dodge. I'm just
guessing. It's also important to note that absolutely nobody other than NVIDIA is making any
money from generative AI. CoreWeave loses billions of dollars, OpenAI loses billions of dollars,
Anthropic loses billions of dollars, and I can't find a single fucking company providing generative
AI-powered software that's actually making a profit. The only companies even close to doing so
are consultancies providing services to train and create data for models like Turing and Scale AI,
and Scale isn't even fucking profitable. Now, the knock-on effects of OpenAI's collapse will be
wide-ranging. Neither CoreWeave nor Crusoe will have tenants for their massive unsustainable
operations, and Oracle will have nobody to sell compute to because they've leased that thing for
15 fucking years for one customer. Who else is going to take that? Anyway, CoreWeave will likely
collapse under the weight of its abominable debt anyway, which will lead to a 6-7% or more revenue
drop for NVIDIA at a time when revenue growth has already begun to slow. On a philosophical level
too, OpenAI's health is what keeps this industry alive. OpenAI has truly the only meaningful user
base in generative AI, and this entire hype cycle has been driven by its success, meaning any
deterioration or collapse of OpenAI will tell the market what I've been saying for over a year.
The generative AI is not the next type of growth market, and its underlying economics do not make
sense. But look, I'm not saying this to be a hater. I'm not saying this to be right. This stuff has
driven me insane, but I'm not doing it to be a pundit, to be a skeptic, to be a cynic, to be someone
that hates because I want to hate. And I hate them not because I think people like me because I hate
them. I hate them because I have brain worms. I have something wrong with me inside my brain that
tells me I have to be like this, and I have to look at these things, and I have to try and find what's
going on. Otherwise, I will be driven mad. Which is why I'll say if something changes, if I'm wrong
somehow, I promise you, I will tell you exactly how, exactly why, and what mistakes I made to come
to the conclusions I have in this episode, and the episodes before. But I don't believe that my peers
in the media will do the same when this collapses. But I promise you that they will be held accountable
because all of this abominable waste could have been avoided. Large language models are not on
their own the problem. They're tools, capable of some outcomes, doing some things, but the problem
ultimately are the extrapolations made about their abilities and the unnecessary drive to make them
larger, even if said largeness never really amounted to much. Everything that I'm describing is the result
of a tech industry, including media and analysts, that refuses to do business with reality, trafficking in
ideas and ideology, celebrating victories that have yet to take place, applauding those who have yet to
create the things that they're talking about, cheering on men lying about what's possible so that
they can continue to earn billions of dollars and increase their wealth and influence for barely any
fucking reason. I understand why others might not have said what I've said. What I am describing is a
systemic failure, one at a scale hereto unseen, one that has involved so many rich and powerful and
influential people agreeing to ignore reality, and that'll have crushing impacts for the wider tech
ecosystem when it happens. Don't say I didn't warn you.
Thank you for listening to Better Offline. The editor and composer of the Better Offline theme song is
Matt Ossowski. You can check out more of his music and audio projects at
matosowski.com. M-A-T-T-O-S-O-W-S-K-I.com. You can email me at ez at betteroffline.com or visit
betteroffline.com to find more podcast links and, of course, my newsletter. I also really recommend you go to
chat.wheresyoured.at to visit the discord and go to r slash betteroffline to check out our reddit.
Thank you so much for listening.
Better Offline is a production of Cool Zone Media.
For more from Cool Zone Media, visit our website, coolzonemedia.com,
or check us out on the iHeartRadio app, Apple Podcasts, or wherever you get your podcasts.
