I'm so humbled and thrilled to be here today with Matthew Siegel and Michael Levin, just
to give a brief introduction of each of them. Michael Levin is an American developmental
and synthetic biologist at Tufts University, where he is the Vannevar Bush Distinguished
Professor, Director of the Allen Discovery Center at Tufts and at the Tufts Center for
Regenerative and Developmental Biology. He's also co-director of the Institute for
Computationally Designed Organisms with Josh Bongard. Dr. Levin received dual bachelor's
degrees in computer science and biology from Tufts University and a PhD in genetics from
Harvard University. His group uses computational and experimental approaches, and this is very
important because that's basic for Dr. Levin is that things have an experimental approach,
to understanding diverse intelligence in a range of evolved, engineered, and hybrid living
systems. And they develop conceptual frameworks for understanding cognition in unconventional
embodiments, such as the collective intelligence of cells and use them to drive applications
in birth defects, regenerative medicine, cancer, and synthetic bioengineering. And Matthew David
Siegel is a transdisciplinary researcher, author, and teacher applying process philosophy across
the natural and social sciences, including the study of consciousness. He's associate professor
in the philosophy, cosmology, and consciousness program at California Institute of Integral Studies
in San Francisco, California. You can find out more about his research and writing at footnotestoplato.com.
That's a two. And also on Twitter, which where I have a lot of interesting conversations with
both of these gentlemen. So I'm really thrilled to have both of you here. Welcome to the Meaning
Code. Nice to be here. Thank you. Yeah, thanks, Karen. And I had asked each of you to talk about
what you might like to learn from each other. And now, where did I put it?
Oh, this is great. I had the questions right in front of me. But you probably remember what
your questions were. So maybe I'll just let you get started. I know that, Matt, you had a question
about Dr. Levin's basic viewpoint of... I can't believe I lost that thing.
It's a problem with paper. Yeah, that's the problem with paper. So I'm going to let you get
started in that. Why don't you ask your big question that you had? And then maybe by that
time, I'll be able to find number two. Sure. Yeah. So I think whenever philosophers and scientists
enter into dialogue, it's important to clarify the relationship between these disciplines,
right? And make sure that we're working from the same basic sense of how we can learn from each other.
And so, you know, from my point of view, as a philosopher seeking a metaphysical
scheme in terms of which we can interpret every aspect of our experience, including science,
I'm not here to try to sort of tell scientists what the proper concepts to use in approaching
and operationalizing, you know, certain knowledge sets.
I'm here to learn from science and to generalize from what the special sciences are telling us,
including biology and physics and the special sub-disciplines within biology and physics,
and to generalize from those findings so that we can learn what the implications are for the broader
questions of the nature of the universe. And I'm also interested in sort of looking at the
epistemological presuppositions of science, because I think historically, since the scientific
revolution in the 17th century, and the basically mechanistic and reductionistic approach that drove
science so successfully for a few centuries, there was a sense in which the kind of universe that
scientists were describing didn't really allow for human minds that were coming up with all this
knowledge, right? And so part of what I would want to do as a philosopher is understand nature,
drawing on science such that mind would be something likely to be possible in this universe,
right? Because obviously, if science is possible, there must be intelligent minds in the universe.
And so we don't really want, I think it's a problem if our science is describing the universe in a
way that makes minds highly, highly unlikely. And so that's why I'm so excited about your work,
because you're trying to generalize this notion of mind and agency and intelligence,
so that it in some ways goes all the way down. That there's a continuum and gradual development
through processes of evolutionary learning, so that the scientists can understand themselves as an
example of the very type of systems that they're studying, right? And so, you know, my, I think my first
question for you, Michael, would be, how do you, is this how you would understand the relationship
between philosophy and science, ideally? Or do you see it somewhat differently?
Yeah, no, I see, I see it quite similarly. And to me, the key fact that tells us how to,
how to think about these areas, you know, science and philosophy together, is basically the fact of
developmental biology. So if not for that, we could have two divergent sort of worlds, and many people
think we do have these two worlds, where we think about, you know, kind of classical philosophy of the
adult human, the, you know, sort of the moral agent, and, you know, things you know, and so on. And then
there's physics and chemistry and things like that. And the thing that ties these together, in a remarkable
way, is developmental biology, because each one of us has taken that journey from chemistry and physics
to being a complex metacognitive mind. And that happens slowly and gradually, and you can watch it
happen with your own eyes. In the case of a frog, you can watch the whole thing from beginning to end.
In the case of a human, it takes a little more instrumentation, but you can still watch it.
And so each of us was once a quiescent oocyte, a little blob of chemical, of chemistry. And now we
are whatever it is that we are, and that process happens slowly. So, so, so to me, these things are
fundamentally merged, because whatever, whatever it is, whatever philosophical approaches we have to
what, what we are, and how we should think about the outside world, and, and so on, we have to realize
that we are continuous with what we call chemistry and physics, and, and, and, you know, supposedly
mindless matter, which I'm not sure there is any such thing. But, right, and so, so that continuity,
I find, just binds the two fields in a way that cannot be, be untangled.
I like it. Yeah, definitely. Because developmental morphogenesis has been not totally left out of
our understanding of biology, but it's taken kind of a backseat in the 20th century with the focus
on genetics, right? And I, I think your work is blazing a trail in, in, in terms of bringing this,
these factors back into the picture, which I think really does change our understanding of evolution
more as a learning process, and not just a passive selection mechanism that neo-Darwinism would
suggest, right? And I think that's, it's so exciting to see that what you're, how you're moving the ball
forward on that. Yeah, I mean, another, you know, another thing, another area of interaction is that
I think a lot of, I mean, most of this was already available, you know, sort of conceptually,
but now practically, we can really show that a lot of categories that people who are having these
sort of philosophical and conceptual discussions, people throw around categories, a machine versus
a living organism, right? So people will say, well, machines can't this and that living organisms can
do this and that, and, and robots is something else and, and evolved versus engineered, completely
different, like the, to taking evolution seriously, taking developmental biology, bioengineering,
um, taking these things seriously, tells you immediately that those categories are no good,
right? These, these, these binary, um, crisp categories that people love to philosophize about,
I, I don't think there's any argument to be made anymore that they so-called carve nature at the
joints. They're just not, you know, we, we, we can, we can now do lots of experiments that tell you
immediately that if you're operating with those categories, you're tied up in knots, you, you've
got pseudo problems that you're never going to resolve with that frame of looking at things. And
so I, I also like that. I like the fact that, uh, these, the, these, these advances, so I kind of see
the, the philosophy and the, and the science as, as a, as a, um, a spiral because they help each other
out, right? And so, and so they, they, they sharpen and, and a lot of people don't see it that way. I've
had, I've had many people tell me, you know, they, I'll, you know, talk about some data, some,
some, something we've, we've discovered and people will say, that's pretty cool, but I wish you
wouldn't talk about all this philosophy stuff. Like, like that just like, don't do any of that.
Just give us the, you know, just give us the, the, the, the science and the, and the data. And it's,
it's kind of like the old joke of telling the publisher, you know, we'll just publish all the
bestsellers. Like, right after I, after we've done the thing, then you can say, well, I see how this
works. Well, then we don't need philosophy. No, but the, we only did that thing because of a
particular, you know, philosophical way of looking at things. And that's why I think it's
really critical. I think the philosophy is absolutely critical. And I think the, the,
the empirical work is critical and together they can, they can spiral up, I think.
Well, so Michael, one of the, one of the philosophical questions that you wanted to ask,
Matt, you said Plato's space of forms, which has become increasingly more relevant as we discover
ways to probe the latent space around biological objects and find forms and behaviors that cannot
be explained by evolutionary selection histories. And I just wanted to clarify the question a little
bit. When you talk about the latent space around biological objects, are you talking about the same
kind of thing where Anna Soto talks about the impact of the environment or the matrix in which
something develops or Darcy Thompson's work on attractor spaces, or do you mean something else
when you say latent space? Well, closer to what Darcy. So, so I think Thompson was onto this in an
important way, but, but I think it's not quite what Anna says. I'll, I'll give you, I'll give you an
example of, of what I'm talking about. People often ask me where do, so let's just talk about
anatomies, but it's also true for behavior and physiology and so on. Specific anatomical target
morphology, like a particular, let's say, let's say a salamander limb or an embryo that has a
particular shape. And if you deviate it from that shape, it will regenerate and try to get back to
that shape. And when it gets back to that shape, it stops. So these sorts of set points of, for these
kind of homeostatic capabilities, people often ask, where do those come from? So where does the shape
come from? And the typical answer is for most natural things. The answer is, well, evolution
selection. So the reason frogs look froggy is because for eons, they were selected for this
particular shape that fits a particular niche, solves a set of problems successfully and survives. And
that's where it comes from. It comes from that, that, that history. But now we know, and again,
really, we knew this before, but now we can really, it's right in our face now that we can make,
for example, xenobots, or which are, which have a wild type frog genome, and they have a novel
structure. They have novel behaviors like kinematic self-replication that nobody's seen before in the,
in the living world. We can make all kinds of unusual novel constructs. And the question is, where do
those forms come from? Because the answer, well, eons of selection is clearly wrong in this case. I mean,
the cells, of course, did evolve on earth, but they didn't evolve in the con, in the context of being
selected to be a good xenobot. There, there's never been any good xenobots. And so there's never
been selection to be a good xenobot. And so you have many examples where there are new, new ways
to solve problems, new forms, new behaviors, new physiological competencies that arise in, out of
some space of possibilities of which the standard example that we're looking at, let's say a particular
embryo is just one little tiny glimpse of that space. And of course, people have studied developmental
plasticity before, and here are four, you know, several different ways that this plant can come
out, depending on the dry, the water level of the environment and things like that. This is,
this is more than that. This isn't just developmental plasticity. This is, this is pushing, pushing cells
into coherent, large-scale behaviors in various spaces, including anatomical space, physiological space,
and so on, that have never existed before. And that are, that, that you can't predict from the
genome, and you can't predict from, from, I have many examples that I go through in my paper. So,
so when people ask, where do these things come from? It's kind of a subtle thing. And I always lean back
to, on, on this example, you know, this, the Galton board, right? So, so you take a board, and you bang
them with your nails into it, and you take a bucket of marbles, and you dump them in, and they go boom,
boom, boom, boom, boom, and then they land on the bottom. Well, they always land in this beautiful
bell curve, right? You always get the same shape. And so you could ask the same question, where does
that shape come from? And you could say, well, is it in a wood? Not really. Is it in the description
of the nails and the metal of the nails? No, not really. Like, to me, it sounds like, and, and Andreas
Wagner is another biologist who talks about this stuff. It comes from the same place where the truths
of mathematics come from. It comes from the same place that tells you what the distribution of crimes is,
and the, and the, you know, the truths of number theory, and all this stuff that isn't anywhere in
the physical world. In fact, all the facts of the physical world, I think, could be completely
different, and all those things would still be true. So, to me, it sounds like we're right back to,
and I think Thompson was onto this, in particular, the part of his book where he draws animals on these,
on these grids, and then he does this deformation of these, this mathematical deformation of these grids,
and you get, and, and what you get is, is other existing species. I mean, we've done things like
this, too. In the lab, we've actually done this, and this really does suggest that there's some kind
of a latent space, and now, actually, the computer, the machine learning folks are all over this stuff,
because you can, you can, for, just as a, as a, as a modern example, with one of these,
one of these programs that draws, it makes, makes pictures from words, right? And so, you can say,
I want this and that in the style of, I don't know, Salvador Dali, or Mark Chagall, or whatever,
and it'll give you something in that style. So, that's already cool that it can, you know,
go outside of the particular paintings that that person had done. But you can also make up a name,
and you can say, you know, I, I want, I want 10, 10 paintings in the style of, you know,
whatever, and they'll give you paintings that all look like they come from somebody with the
same style. Where is that? They're not copying that from some particular person that they've
seen before. They're exploring this latent space that they've constructed by looking at other
examples of art. So, this notion of having a space into which we can only see little tiny glimpses by
the few examples that we've seen, I think is really important, and I'd love to hear what, you know,
I certainly don't have a background in classical philosophy, so I'd love to hear, you know, what
did people say about this for mathematics, for, because I think, because in the end, I think that's,
it matters a lot. For example, is evolution really searching the very difficult space of
microstates for biological systems? I don't think so. What I think evolution is searching for is
a much nicer space of simple machines that pull down all kinds of free gifts from the laws of
physics, the laws of computation, the laws of geometry, and what evolution does is optimize the
hardware, but there's a ton of heavy lifting that is done elsewhere, so to speak. I lack the vocabulary
for it, really, but, you know, it's like a final example, and then I'll, you know, I'd love to hear
what Matthew thinks. Just as a dumb example, suppose you're revolving a triangle, a particular
kind of triangle, right? There's an environment, and only that kind of triangle is really fit,
and so you crank through a bunch of generations of the population, and you finally find that first
angle, and that works, and then you crank through some more, and you find the second angle,
you're done. You don't need to look for the third angle, because the three angles of a triangle
have to add up to 180, so it's not philosophy. It's very practical. Evolution just saved one-third
of its effort in finding that solution. You didn't need to look for it. Why didn't you need to? Where
did that come from? That amazing, and the same thing, you know, the same thing that we see in
Xenobots and these other creatures, where you make a very, you know, you make a very small change,
and you get a lot, quote-unquote, for free, with novelty, right? Things that it's very likely that
the evolutionary history had never seen before, so that aspect of it, that's what I'm really curious
about, is where does all this stuff come from? Can we use these synthetic biology and other AI for
sure, and then synthetic bioengineering as a kind of telescope to sort of peer around that space and
dig around and see what else is there? Can we map out the structure of that space the way that
mathematicians, I saw a map of mathematics ones, where they sort of have all the different fields
of math and how they relate to each other, so, you know, that's just one of the things that's up to.
There's probably all kinds of other things in that, in that latent space, so, anyway, that's, that,
that's, that's what I'm asking about. Yeah, so, Plato obviously had his theory of forms,
and as a high-level summary of what I think needs to happen here is we need to evolutionize
Plato, and so, the problem with, with Plato's view is it was this static realm of ideas,
and everything physical in our experience is a pale imitation or an attempt to mimic this perfect
realm of forms, and they're eternal, right? They, they never change, and the ancient Greeks had a very
static understanding of nature. There was no speciation, it was pretty much essentialist in
the, in the, in the sense that the organisms that exist now all have their proper place in this
teleological order. This would be to speak in more Aristotelian terms, but Aristotle is kind of like
the first Neoplatonist, and so, there's a lot of continuity here. There's this great chain of being
in Aristotle's view of the cosmos, right, from minerals to plants to animals to humans, and then
on up to this sort of super, um, lunary sphere of, um, of higher types of beings on up to, um, the,
the, the thought thinking itself, which would be like this divine mind, um, that everything else sort
of emanates from. Now, to evolutionize this platonic or Aristotelian view is kind of like
tipping it up, tipping it on its side, right, and horizontalizing what was conceived of in this
vertical way, and showing how these forms can emerge in the course of evolutionary history,
but there's a lot to work out, uh, in the details here about how this actually works, and I think
in the 20th century, the best figure I've been able to find who's addressing these issues is
Alfred North Whitehead, who, you know, Karen shared the name of my blog, Footnotes to Plato. He's the
one who famously says all of Western philosophy is a series of footnotes, or can be understood
as a series of footnotes to Plato, but Whitehead really wants to evolutionize Plato, and the way he
does this is by pointing out that mechanistic science, and we can talk about the mechanism-organism
thing, um, I'll just briefly say I think that organic thinkers, uh, don't dismiss mechanism.
They say it's a subset of this more general self-organizing dynamic. Um, obviously living
organisms need to make use of mechanisms to do what they do, um, it's, but when you flip it and talk
about what mechanistic thinkers tend to say, they don't think there's any such thing as organism,
it's all just purposeless, um, mechanisms that kind of fall together into place because of a series
of accidents that get preserved in the, in the biological world because they're, um, they're, you
know, selected, um, because of the enhanced, um, fitness that they provide. So from Whitehead's point
of view, mechanistic science that dismissed any, any, or didn't really take self-organization
seriously, and was more just, you know, the parts fall into place because of eternal laws. Um,
this mechanistic approach to science was based totally on what Aristotle called efficient causes,
sort of things banging into each other, and had no room for formal or final causation.
Um, and there was good reason for, uh, in the history of science and the emergence of science
for the first scientists to really want to distance themselves from this idea of purpose in nature and
teleology and whatnot, because the sort of scholastic way that those ideas were deployed was kind of
naive and inhibited our, um, understanding of, of the natural world around us. And so it turned out
when you bracket questions of purpose and final causality and stuff, and just study nature as if
it were determined by efficient causes. And you, you use mathematical modeling to do that. You can
make a lot of progress, especially in terms of instrumental knowledge, like you can develop
models that are highly predictive. And so we can get all sorts of technology out of this. And, and,
you know, that's been the story of science for the last few hundred years, but when you leave out
formal and final causes, then you end up in the problem I was describing when we first started, that
it's very difficult to understand, um, how science could be possible, how, how there could be minds like
ours capable of doing science if there's only efficient causation, um, operating in, in this universe.
And so how do you bring formal causality and final causality back into this naturalistic picture? I think
that's, that's, that's the challenge. And, you know, Whitehead does that by describing evolution,
not just as a, um, you know, I don't mean just biological evolution. I mean, a general picture
of evolution, cosmologically speaking, um, there's an accumulation of facts in the past that, um, just as
a mechanist would say, like Laplace or something, everything that's happened in the past has, has a,
uh, an impact on what's happening in the present, just causal chain of influence. And so evolution
is a process of the accumulation of all these facts of history, but there's also, um, there's
possible forms open in the future that are, that, that, that field of possible forms in the future is
constantly being adjusted as these facts of the past accumulate, but we can't understand the
relationship in the present between that past of facts and that future of forms purely in terms
of efficient causation, because what's missing in the mechanistic picture is, is the agency that's
operative in the present that can search this field of possibilities in the future. And so the
challenge is how to understand that agency in a naturalistic way that doesn't rely on, you know,
what Dan Dennett called skyhooks in Darwin's dangerous idea, right? Which would be a conception
of final causality that would imagine it as a kind of disembodied mind reaching in as if it can,
as if it's in the future already. And it's like a retro causality or something. And it's almost like
construing final causality in term, as though it were just another kind of efficient causality,
but working in reverse from the future. And I think we need a different way of imagining final causality
causality that doesn't just reduce it to what efficient causality is doing in reverse.
And so obviously, well, maybe it's not obvious, but in Whitehead's picture, at least the future is
open. He's not a deterministic thinker. There is real room for novelty here, despite the accumulation
of the facts of the past that influence what happens in the present. And despite the fact
that the present must conform to the past, there's room in the present for a kind of agency, which
operates differently at different scales, depending on the complexity of the system that's exhibiting
this agency. But what agency is, is, yes, it's inheriting and conforming to the past, which is
what constitutes memory, but it's also searching the future. And in the present, there's some kind
of confluence between future forms of possibility and past facts that are already actualized. And
Whitehead's whole philosophy is an attempt to what he it's an attempt to devise what he calls a cell
theory of actuality, such that agency is always understood to operate in a cellular way. And he's
using a biological metaphor here, but he ends up generalizing it beyond just biology to talk about
quantum events using the same set of categories that we would talk about cellular biology, but also the
same set of categories would also apply to our own conscious experience of being conscious decision
makers, that there's a single set of categories that applies across all of these scales. And it's about
a continuum of agency, inheriting the past, searching these this field of future possibilities. And so when we
think about biological development, and morphogenesis, this is obviously a collective form of intelligence, that has a
goal in mind, as a collective. And like, where is that goal that that form that finished form, like, as you're always
pointing out, Michael, the cells know when to stop growing when they've reached this, this form that they have in mind. And on some
level, that form is inherited by you could say the genome, but it's obviously not totally stored in the genome, because you can change the
genome, and the form would still be there, the cells will find it. You could say that it's stored in the whole environmental context, in
some ways. And I mean, and this, this is where I could pivot to your work with Chris fields and others on the free energy
principle and the agency of the environment. And all of this, you know, which I'd love to hear more from you about but but I'll pause there and see if these
thoughts are landing. No, no. So yeah, super interesting. Just just on the on the last bit. So the thing about the
environment, yes, but the environment is massively under determined, right? So, so xenobots live in basically the same empty water
dish as as frog embryos, you can't really pin the the shape of them on the environment per se. The thing is that now now now going back to, you
you know, where do these patterns store the funny thing is that we can now see them. So so we can actually see these so so just in the in the
case of the planarian, we can actually visualize the pattern memory that tells them how many heads to have, we have the technique
you can actually see it. And that's and the reason we know that's what it is, is that if you go ahead and rewrite that pattern,
they'll build something else, they'll build animals with two heads or no heads, or, you know, so we I mean, this is just scratching the
surface of what's possible, of course, but we're starting to unravel the actual like, like that, that idea that there's a
representation on it, you know, of course, molecular biologists don't like this at all, because they
like they like emergence and complexity. And that's it. They don't they don't want to have the system has
some kind of representation of a future state that it's working towards. But we can actually see those
in the same way that neuroscientists can read the electrical activity of the brain and see those in the
case of, you know, behaving creatures. So, so so the information structures are there and we can sort of start to
decode some of their physical correlates. But I wonder if so. So this is the thing I wanted to
kind of ask you about. I wonder if the whole the business with them, you know, the for the Aristotle
and the four types of causes and all that, could we is maybe this is crazy, but is it possible that what
what what if what if instead of having sharp categories, here are four different types of
causes instead of that, what if we draw, we put we put an agent in this like, and I like this
diagram, I use it for my cognitive light bone thing. It's almost a Minkowski diagram where you've
got the, you know, three dimensionals of space here, one dimension of time is here, right.
And so you put your thing on, and all you're going to do instead of having sharp categories, what you're going to do is have progressive
distance from the here and now of this agent. So we could say, you know, if you're a, if you're a, if you're a bowling ball, what I really need to know is the sum of the forces on you right now.
So, so basically I'm operating on the causes that are in a very tight, you know, cone around that system.
If you're a mouse in a field, it's not enough for me to know what your experience, what what's around you right now, because you may have memories and previous experiences and all kinds of other stuff that's going to determine what you're going to do and
right, and if and if you're a human, the answer, the best answer to why did you do what you did might be something like World War Two, that's why.
So right so so it might be this giant thing that's far away in space and time and or you know, and so if we, if we back off from if we back off from the idea that you always have to look at the lowest level right which is, you know that that's kind of how.
That's how Dan Dennett analyzes free will is he says look when you zoom in you only see two things you see either either hard determinism or randoms neither of those things is what we mean by free will so therefore.
Okay, that's I mean that works if if you're committed to the fact that everything has to be at the lowest level.
If you back off to some of the work, you know, for example, Eric hole and and Giulio Tononi and those kind of guys who are now like showing very rigorously that there are many systems in which the higher levels tell a more causally impotent story than the lowest levels.
Then, then it all becomes a matter of prediction and control from some kind of outside observer and that observer can draw not necessarily for specific.
You know bands around this thing, but just a smooth sort of so you can ask this question like in order to understand this particular system.
How far away are in space and time are the causes that I need to most efficiently relate to it, that would be that would be how I would phrase all this, I would say that it's not discrete it's continuous.
And as an engineer like that's my approach to all this is is as an engineer when you're telling me something about the cognitive makeup of a system, which are really are claims, you know yeah it's intelligent or yet has you know cognitive capacities, whatever.
What, what I am hearing are engineering protocols, you're telling me that I can rewire it or no you can do better than that you can read it, you can change the set points that things a thermostat cool or no you can do better than that you can give it rewards and punishments even better.
Now you can do better than that you could give it called cogent arguments and it'll go and you know, and so, so what I hear what I hear from these claims is.
How far away do I need to what do I need to know in this space time diagram to be able to optimally relate to that system.
So what do you think of that as a kind of you know as a way to like modernize these these these sharp categories, you know it always bothered me that they were supposed to be like, you know that they sound so discreet I just kind of see a distance.
I think this idea of a kind of cognitive light cone as you call it is is wonderful and it's very convergent with whiteheads understanding of you know what he calls actual occasions of experience and how they complexify over the course of of evolution because of the relationships that they enter into.
What she calls societies, you know, what she calls societies, you know, you call them collectives, cell collectives, or what have you.
And so I think that's that's right on and I mean the thing about.
Aristotle's for causes or reasons you could even translate the Greek term he's using there.
Is that these are when you ask questions about entities or processes in nature for Aristotle like these are the four basic ways that you can get at why something happens.
And it's not that there are some sorts of entities that are purposeful and other sorts of entities that are not.
So the continuum you're trying to describe, I think, is perfectly consistent.
Well, I shouldn't say perfectly consistent, but it's at least in in in fruitful conversation with the perspective like that Aristotle will talk about.
But yeah, at the end of the day, you know, he would differentiate between like, you know, a human being has like different levels of agency and sort of ontological layering within within them.
We have we have the mineral realm within us, which is our the matter we're made of.
And we also have the sort of plant like nature, this vegetative soul.
We have an animal like nature, the sentient soul, and then we also have this intellectual soul, which is where our reason comes from.
And, you know, yeah, it's kind of they seem like separate sorts of things when what we would want in an evolutionary context is more of a continuum here.
But I think to do that, to switch perspective successfully, we end up having to say that whatever we mean by reason or rationality, this capacity to be persuaded by arguments in human beings.
Obviously, that depends on language and stuff, but the the germ of whatever that capacity is must be rooted pretty far deep in our biology, if not even more deeply.
Right. And so you have to bite that bullet if you want continuity, I would say.
Otherwise, you end up in a situation where, again, the epistemological presuppositions of science start to become challenging because whatever mind is in human beings seems to be discontinuous with our biology and the nature of the physical world out of which that biology arises.
Right. Does that does that problem make sense? Yeah, yeah, yeah, yeah, it makes sense.
I mean, the discontinuity. Could I just jump in with two small things here to kind of help me clarify what's happening?
And also maybe to reduce some of these big ideas into something that's one one big idea that would be there's something that Jordan Peterson always says, which I think scales in every area of this.
And that is the ideal is the judge.
And it's really a very simple idea, and it doesn't have anything to do with doesn't have anything to do with metaphysics.
Actually, he's he's talking at the scale of psychology, the idea of whatever it is that you want to be or whatever it is that you look at that you admire is something that is constantly judging you because either you're not achieving it or if you're moving towards it.
How close have you gotten or if you've overshot it, how far did you overshoot it?
So you're always adjusting to this ideal, and I think that scales all the way down to particles.
It scales all the way down to cells your morphogenesis when the undifferentiated cells are given their subroutine and they go off to build an arm.
There's some sort of an ideal towards which they're working, and that ideal is constantly judging whether or not they're getting there.
And as a collective, they're working together towards that and and I think that this connects to this idea that you have of the distance.
Because with the bowling ball, the distance is very short.
The ideal distance is very short because those are physical laws that are absolutely determinative.
But by the time you get up to the human scale, we're affected not only by our own personal history, but by the history of the universe and everything that we think and do right.
So the distance of the ideal is much further from us, and that makes the path forward very much more complex.
And this made me think about your Xenobots.
What is it that causes that form for the Xenobots?
It's not the matrix that they're in because other things can arrive in that same matrix that they're floating around in.
But there's another idea that I learned from art that was very important to me, and that is constraint or limitation produces creativity.
And the way they used to say in the old days necessity is the mother of invention.
So the one thing that those Xenobots have absolutely is necessity.
They've been dumped in this medium, and if they're going to live, if they're going to continue living, they've got to get together and do something.
So this collective intelligence is being driven by necessity and necessity is producing the creativity that allows them to find that form where the form exists.
I don't know, but I think it's the necessity that's driving it.
So that's very interesting. I completely agree with the necessity bit, and I'll say something about it.
But, you know, just for the Xenobot example, just so we're clear on the biology, actually, the cells could have remained independent.
So when we when we dissociate all the skin cells, they could have sat there independently.
They could have done nothing. They could have crawled away from each other.
They could have formed a two-dimensional monolayer like in cell culture as many things they could have done.
So and they would have lived. They would have they would have continued to live.
They're not under under some kind of external survival pressure to join up together.
Okay, that's new information, but yeah, yeah, they could have.
They could have done other things, but but I love the constraint idea, and I like it for the following reason.
I mean, this this links up to something that Matthew said a minute ago, which is this.
When when you are a brand new living being starting off in this in this universe, one thing you don't have time or energy to do is to track microstates like some Laplacian demon.
You don't have the energy to do that. You don't you'll get eaten if you're sitting there trying to calculate all the microstates.
So what you have is tremendous pressure selection pressure for systems that coarse grain and be are able to see higher levels of what's going on around them.
So you need to organize your experience and into and chunk it up into macroscopic states that you are then going to track and decide what you're going to pay attention to and how you're going to prioritize it.
Because if you if you if you if you try to track the microstates, you'll be you'll be you'll be you'll be for for two reasons.
One one is if you know just limitations of time and energy, and then there's a more interesting reason, but but you'll you'll be dead very, very quickly.
So, so I think there is this this this this the pressure of necessity, I think drives the ability of life to see higher levels.
This is cool. I think that one of the reasons why chemists and physicists often don't see that agency and the things they they're looking at is because they're using low agency tools.
So, so there needs to be some resonance between the thing you're probing the world with and and what you're hoping to see.
So if you're using rulers and magnetometers and things like this, these are very low agency tools, all you can ever see is low agency chemistry and physics.
But life has agency detectors, we have to because otherwise you can't survive.
And so what we have are the ability to see these higher levels to do well or poor poorly but usually pretty well, they they living things have to be able to.
A coarse grain in the in the world, and then once you see these things and you start to make models of their behavior.
You know that's a cell and it does certain things and that's my neighbor cell and that's it does certain things or that's a cat that does certain things.
Then eventually you can sort of turn that around on you on yourself and say well i'm a thing and I do things I there's I have a model of myself as an agent.
This leads to a weird kind of thing I proposed, which is that any organism or being it might be completely engineer, you know, an engineer thing it doesn't have to be biological but anything that evolves under.
Resource constraint under necessity is going to fundamentally believe in free will not saying it has it i'm saying it believes in it because because fundamentally in order to survive you have to be able to.
You have to get good at telling stories about agents that do things you cannot survive with stories of.
All the particles to sort of move around on you know understood like that you you you will not live that way and so, and so anything that survives has to be good at telling these causal stories of agents with with agencies, you know.
And so, and so that's I think that's how we get to this to this place where where we are where where it's impossible for us to do things like you know you might say you don't believe in free will, for example, but if we go to a restaurant.
And you know the waitress comes along and she says, you know what what what what are you going to have.
We don't have the ability to sit back and see what the big bang ordained for us to eat today like you don't have that ability.
You will just you know we we we are fundamentally do doers because, and I think it's because of that I think it's be and and that's it.
The thing I realized just last week is that it's funny I I think I put all the emphasis in this kind of agency thing on the doing.
But actually most of the field, I think, has been mostly talking about the feeling aspect that not the output the input side because, for example, we have this idea of what's it like to be right that's a famous thing in philosophy of mind.
And and we haven't we somebody came up with a theory of epiphenomenalism this idea that we just feel stuff, but we don't actually ever do anything right that you know there is what's the opposite.
I'm not aware of that there's an opposite of this, you know, so people have realized, so people do have a theory of well, maybe you're just perceiving and you know you're really are, but the rest of it is fiction.
But nobody's that I know of has said it the other way around what but but I actually think the doing is the is is is, you know, the more I mean, of course, they all work together, but but but the doing is is also really critical.
And that's why so so coming back to this to to to something that Matthew was saying, I think one interesting thing if you if you do try just imagine for a second, a being that was a, you know, a being that is a Laplacian demon let's say it was possible.
I mean, for many reasons it's not but let's say it's possible.
One of the things that that that type of there are two interesting things I think that that type of being couldn't do.
And they're related what one one thing they couldn't do is, for example, they couldn't play a game of chess with you, because all of the micro states of what happens next are equivalent to them in terms of their value.
They there is they don't believe in chess pieces they don't believe in the chess board all they see is atoms.
And there's no such thing as the king or the position of, you know, dominating the center, all this other stuff.
And they don't believe in these in these higher level.
They don't track these these higher level things. So how do they choose their next move?
I think course grain all the molecular things that come that that are grouped into a move, a valid move, and in fact, the best next move.
You know, all the micro states are they it's very I don't see how they would have a preference over the micro states if they don't understand the groupings of the macro state.
And that leads that also leads me to to this.
If you if if if you're very good at following like a Laplacian demon, you're very good at following what happens next any given system that somebody prepares for you.
You can in a deterministic universe, you could say what will happen next.
You can do that. But what you can't do is prepare the interesting system in the first place.
You are you are a passive, you know, this prediction, but there's no pre invention.
And just as a kind of a dumb example of this, what I mean is, you know, there's this, you know, the cellular automaton, the game of life.
Right. So you got these very simple rules about whether whether the individual pixels are on or off.
And then if you follow these rules, our visual system starts to see interesting things like gliders, you know, these patterns that go up and what somebody.
And so and so what what somebody did was was create a configuration that results in the Turing machine that uses these gliders gliders as information signals.
I mean, it's this amazing giant thing. But so so if you were a determinist in that world, you could say there aren't any gliders.
All there is is individual pixels turning on and off, according to some rules.
And if you give me a prepared starting condition, I will tell you what all the what what it's going to do from here to eternity.
I can calculate on this is true. But what they're never going to do is is design the Turing machine because they don't believe in gliders.
Right. And so I think there is this this and it's, you know, it all stems from the same place, which is that if you're going to be active, surviving, interesting.
If you're if you're if you're going to persist in this world, you have to get good at core screening into mezzo scale.
You can't just stay at the lower levels because because of the because of the necessity that that that you were just talking about.
And you're never going to do anything.
You're always going to be reactive. You're never going to set up any anything interesting.
If you again, for the same reason that the Laplacian demons are not going to invent it, they can predict stuff you make, but they're never going to, you know, have enough preferences to make anything interesting of their own.
So that's, you know, that's that's that's what I've been thinking about this necessity, but I actually think it's really important.
Well, the other thing determinants don't take into account is anomaly.
I mean, that what you do when you when you create a designer tadpole and you screw up their eyes or something like that, you you've injected anomaly into the system.
But anomaly happens even without a scientist coming along and injecting anomaly into the system.
Anytime you trip over a rock or or anytime a wind comes along and pushes the bowling ball off the off the rack or something anomaly has come in and that has set up something that has disturbed things.
When you take a when you take a zygote and you scratch through it and then all of a sudden you have to maybe zygote is the wrong word, but anyway, you end up with with two organisms instead of one organism developing.
So those are the injection of anomaly into the system and the thing that has always fascinated me is way all these things scale all the way from social systems through humans down to particles.
And what got me onto that is my own study of creativity and the elements and principles of design seems to be a key that I can use to interpret Whitehead or Jordan Peterson or or you with with with with your work in developmental and regenerative medicine and so forth.
And Jordan Peterson's book maps of meaning is particularly interesting to me because I can read a paragraph from there and I can say, Oh, this is exactly what Michael Levin is talking about.
I just want to read you one sentence here.
The change that upsets and this would be an anomaly.
The change that upsets the presently predictable and orderly also means potential or advancement into a more promising future.
The unexpected is information itself information necessary for the constant expansion of adaptive competence.
So all all the adaptivity that you're talking about that seems to be built into organisms that allows them to face risk or anomaly or or danger or someone injecting change into the system.
That's actually advancing information.
It's creating more opportunity, even if it creates more risk down the road.
And I think determinists don't accept that.
Maybe they don't.
Maybe they think anomalies are also determined.
I mean, yeah, I think that's what they would say, right?
I think I think they would say that the wind that pushed the bowling ball could have been if you if you could just track those air molecules, you know, in and of course, you know, chaos.
The theory makes that very, very hard in practice.
But but I think I think they that's that's what they would say.
If you can you can look at a human situation.
If somebody sets off a bomb someplace and and that has ramifications in a thousand different directions for all the people and for the infrastructure and for the atmosphere and all of those things.
And was that also determined because that has injected anomaly into everything everywhere.
But I think, you know, just to sort of steel man a little bit, I think what they would say is that if you were tracking the molecules in that person's head, you would have been able to predict it.
That's what they would say that it's, you know, there's some neurotransmitters that zigged instead of zagged, and you should have been able to predict that this whole issue for me of determinism in the scientific picture of the universe is, I think, a side effect of this kind of deistic hangover.
All the first scientists were deists, right, and so God is this external engineer set the laws of physics, and then the the universe just rolls forward a bunch of atoms, you know, obeying these laws of physics and and for Newton or Descartes.
And God doesn't reach in and have to tinker with the machine because the machine was designed by this perfect being to just be able to do everything it does without any interference.
And this deistic picture of God, I think plays into the some of the epistemological presuppositions of this type of science that the observer is imagined to be outside the system reaching in tinkering and so on.
And 20th century science from physics on up has just demolished the idea that an observer can passively measure a system when we observe a system we're part of the very same system that we're trying to observe.
You can't even, you know, in quantum theory, this is it's on the one hand doesn't need to be a big mystery that you need to use photons to measure quantum system and that the photons going to interfere with the system you're trying to measure.
And so you end up with limitations on the amount of information you can get because you're changing what you want to measure by trying to measure it.
And it's it's like kind of obvious, but because there is this, again, a sort of deistic theology underlying science for a few hundred years, it's very easy to leave this idea out.
Or this is not even an idea as a fact that to measure something, you got to get in there and interfere with the system.
And so I like to say we need to reimagine science, like reimagine physics as endophysics, like we're within what we're trying to study biology, endobiology, we're within what we're trying to study and a lot that has a lot of implications.
But if I can go back to the comment from Jordan Peterson about the ideal, because I think I know he's read some Whitehead.
He references him once in a while.
It seems to me, though, I wouldn't say that the ideal is the judge, I would say that the agent is the judge and the ideal is the standard upon which that judgment is based.
And this gets back to Whitehead's view of what these platonic forms are.
Whitehead calls them eternal objects.
He says that they're deficient in actuality and he doesn't want to grant these forms any causal power.
All the causal power in Whitehead's universe comes from actual occasions, which are the agents.
And so that means we can't say that the ideal is the judge.
The ideal is a lure that the agencies are lured by.
And so decisions are made by agents.
Right. The ideal isn't where the judgment is coming from.
But when we when we start to really have this scale free conception of agency and of mind, you know, we begin to be able to look at physical processes like gravity or entropy and say, oh, OK, this is a very minimal form of of purpose.
And if you don't use purpose, it has direction and all you need is this little bit of directionality at that level.
And then you can begin to evolve higher forms of purpose, which have a larger cognitive light cone.
Right. But this is a very different picture.
Of of the universe from what science where science started, and I almost think science needed to bracket purpose and agency in mind from its picture of nature for a few hundred years to go as far as it could with that sort of a picture.
Yeah, but it's right. It ran up against walls in the early 20th century, and we're still trying to figure out how to revise and reimagine science.
I mean, scientists have gone about doing wonderful work even without it's really the metaphysics and the cosmology underlying science that needs to change.
Because mechanistic cosmology is is deism, basically, and we need a more, I would say, more organic cosmology to understand how mind has been part of this process from the get go.
And there's this kind of evolutionary continuum to human types of minds.
But one more thing I want to say to pick up on what you were saying, Michael, about epiphenomenalism and, you know, when it comes to consciousness studies and philosophy of mind and neuroscience and how we approach this challenge of the place of consciousness in nature.
Epiphenomenalism seems to me to be a nonstarter because if we do want an evolutionary explanation, we need to understand consciousness as something that has a causal role to play in the behavior of organisms.
Because if there is no behavioral implication of this thing called consciousness, then there's no way for it to be selected for, evolutionarily speaking, and we, we shouldn't be conscious, in other words, right, if it's just epiphenomenal, even if that is a total illusion, it only seems like we're conscious, and really, it's just the playing out of biochemical forces, as many philosophers have pointed out who are usually like panpsychists, the seeming is precisely what we mean by consciousness.
And so if you can't explain the seeming, then you're ignoring part of the evidence that's there to be explained.
And so most science has been, for good reason, the study of behavior, observable, measurable behaviors, kind of third person perspective on things as if we were outside the system.
When you start to study consciousness, you're putting yourself back inside the system, you have to take this first person point of view.
And from the inside out, thinking, feeling, willing, these sorts of concepts become really important.
That's the lingua franca of the interior domain, which is what we're pointing to with words like consciousness, as vague as they might seem initially.
And so what is the place of thinking and feeling and willing in nature?
We see behavior, some of this behavior has clear, can be understood as a goal seeking type of behavior.
And that has, that can be empirically demonstrated, like, you know, in the ways that you're doing it, Michael.
But this doesn't mean we can't also ask the question from the other point of view, the first person point of view about thinking, feeling and willing.
I think they always go together.
I don't mean to make sharp categories between distinctions between these things.
But when we talk about thinking, though, we're more than just, and this was an email exchange Karen and I had, we're more than just human beings, any, any, any organism, but especially human beings.
We're more than just perceiving beings, you know, and because there would be a kind of, in the philosophical sense, that this empiricist point of view that says that all of our concepts and our ideas and our thinking is really just faded sense impressions.
So we, all we really do is perceive the world and then we, we have these abstract ideas, which are just faded perceptions that we remember and that we generalize these perceptions so that they start to seem something like a concept.
But if that's the case, if, and this is what like David Hume would argue, right?
If that's the case, if we really only have that kind of access to the world around us, then our experience is very subjective.
And I start to wonder if natural science could be possible, if we can really take scientific law and scientific rationality seriously as anything more than just a nice story that we tell ourselves that sometimes has practical payoff.
And maybe you're happy, maybe some of us are happy with that as what science is.
But I would want there to be more theoretical heft to scientific explanation.
And I think to get there, you need to take thinking seriously that, in other words, we have concepts where not just perceiving beings, but conceiving beings.
And what a concept is or an idea is, is exactly the same thing that, that we mean when we talk about an ideal or about these forms that cellular communities are, are moving towards.
And when we think, when we think we're participating in this realm of forms, and these are universal, we all share the same set of forms, right?
And so what agency and experience would be then is this sort of confluence between what we perceive, which is always in terms of particular perceptions, the confluence of these particular perceptions with these universal concepts.
And they meet and synthesize in the context of our experience, but it's only if we have access to these types of universals that we can really do science, that we can talk about law, and then we can make explanations, which would not just be useful explanations.
That's important too, and it's a criterion for what successful science is, that this has instrumental operationalizable payoff, but that these are also true, right?
And so I resist the idea, like, you know, the kind of work that Donald Hoffman is doing is really interesting, and I think on some level, it's accurate, but I won't, I can't go all the way with them, because it, again, undermines the epistemological presuppositions of science itself, if we put ourselves in that kind of a simulation, right?
So, yeah, I wanted to touch on all those things and see what, see what lands.
Yeah, yeah, very, very interesting.
Well, a couple of, I want to say a couple of things.
One is that this distinction, you know, first person, third person, I also think that, and I haven't seen a lot on this, I don't know if somebody's already looked at this before, but I think, I think actually there should be a lot of emphasis on second person, which is that I think a lot of this is actually driven by
attempts to get some biology hacking each other, right?
So every cell is some other cells, external environment, every cell is trying to behavior, shape its neighbors, and, you know, trying to tell them, trying to get your neighbor, whether that be a commensal, a parasite, doing something to the host,
cells in a multicellular organism, creatures in a group, whatever, at every scale, there's a lot of stuff going on in second person, which means you're trying to get somebody to do something.
And then trying to get them to do something and trying to be efficient, so you don't spend all your energy and die, you need to have a decent model of what are they, what is the most complicated thing they're capable of doing with the least amount of prompting for me.
So it's very, in engineering, I see all of biology as fundamentally having a very engineering perspective.
So when I look at something, I ask, how much competency can I squeeze out of this thing so that it will do what I want it to do without me there to micromanage all of it?
Like, well, how far can I go, right?
And that then, once you're good at those kind of things, you can turn that back on yourself and you can tell a nice first person story.
Well, hey, I'm a complex, then I can do interesting things.
And, right, and so I think a lot of this stems from this kind of second person necessity of life.
And then we can go back and apply that same lens to, you know, what you were talking about from physics all the way up.
Like, you know, oftentimes people have asked me, you know, in my framework, is there a zero on the spectrum, right?
Like, is there any non-agential events in the universe?
And, you know, I think all the way back to, like, just action principle.
Yeah, yeah, yeah, yeah.
Right?
Like a dumb rock roll, you know, they always say, well, how about a rock rolling down the hill?
You know, you don't want to say that's, well, it's not much, but it isn't zero.
Because if I'm an engineer and I'm building a roller coaster, I have to work pretty hard to get the thing up to the top.
But what I don't have to spend any time worrying about is getting it to the bottom.
So I've just saved myself some effort as an engineer by having a frame where this thing has some competency.
Now, it isn't much.
It isn't, you know, the human level.
But, of course, it wouldn't be because we're looking for the minimum, right?
So with these least action kinds of things, even particles do this kind of stuff.
And then you might think that there's a non-zero minimum.
And then the things we call life are the things that are good at scaling that up, right?
So if you just put a pile of them into a rock, you haven't really scaled anything.
It's exactly the same as what you started with, just bigger.
But what life does is actually scale them up into this hierarchical architecture where they
can now do more in other problem spaces and whatnot.
And we call that when things are good at that, that's what we call living.
That's kind of my definition of life.
And so, yeah, you know, this kind of second-person attempt to control things and pass messages is
that engineering approach on all of this is, you know, is kind of what I see everywhere.
Yeah.
I think I heard Chris Fields in one of your recent conversations with him say something
like that physics is really, you can understand it in terms of a kind of communications theory.
Yeah.
Yeah.
Yeah.
Yeah, absolutely.
And so, I mean, he's the expert on this, certainly not me.
But I think that this is different from the typical.
I mean, the thing people typically don't like about panpsychist views is that they see it
as painting extra glow onto perfectly good physics, right?
So you've got a perfectly good physics that does everything you want it to do.
And then we say, oh, and by the way, also there's this other dongle that the guy hangs
on to that this is conscious thing.
So people don't like that.
But that's actually, you know, people like Chris and Carl Fristen and various others,
that isn't what they're doing.
They're trying to actually redefine physics in a more useful way where the primary thing
is the thing that we're talking about here, right?
The general stuff is.
And so that's a completely different thing.
And that's, and the judge there is going to be empirical utility.
It's not this kind of, you know, epiphenomenal glow that you paint onto stuff.
It actually has to work.
And I mean, I think it's done, you know, I think lots of interesting things have come
of it.
So I've asked Chris once, is it possible, could we design a universe that really had
a zero, you know, that had no least action and all that?
And he said, the only universe you can do that in is one where nothing ever happens.
So a completely static universe, then you could say it's zero.
But as soon as you have things interacting, at least in ways that we understand, you know,
and then that's it, you're not zero anymore.
And, you know, with respect to like the Hoffman stuff, I mean, I don't know.
I think that part of it is that, and people sometimes also ask, like, is it possible that
we're living in a simulation or something like, I'm like, I don't see any other alternative
because we are very limited, very specific types of cognitive systems.
We are good with, you know, medium-sized objects moving at medium speeds through three-dimensional
space.
We see a tiny slit of the electromagnetic spectrum, of the auditory, whatever.
We don't seem, you know, we don't feel other things at all.
So it's kind of inevitable that we're going to have some sort of perspective on these things
that to what extent, you know, I agree with you that I think it is picking out real things
in the world, but I think that almost by, you know, I don't see any way around this idea
that what we're picking out is the low-hanging fruit for the kind of cognitive system that
we have.
And then, you know, and then if there was another, you know, that comes up a lot in AI where people
say they want human understandable models.
They don't like AIs that make good predictions, but we can't figure out why it is.
And I mean, I get it.
It's nice to have human understandable models, but I don't see any reason to expect that the
vast bulk of the things that we want to understand are going to be human understandable, right?
I'm just not sure.
Like, just because we are a particular kind of, like, who said, you know, if somebody said,
here's a, you know, here's a planet of, you know, chimps and, you know, and you would
say, yeah, there's a whole bunch of stuff they're just not going to get.
I'm not sure that we're, you know, I'm not sure we're past some sort of critical mass
where, okay, now we can really just understand everything.
I think it's entirely possible that we have a particular lens and that lens is good enough,
as Don points out.
And then there are other kinds of cognitive systems out there.
Maybe, maybe AIs will do it.
Maybe there's some aliens out there or something, but, but, but other possible minds that are going
to do a very different job of carving up the world, you know?
If, again, if we were just perceptual beings, I think everything that Hoffman is saying would
be absolutely true.
And I'm not trying to create a dualism here, but it seems to me that our thinking activity,
when we're doing science, when we're reasoning about the world in any way, allows us to connect
up percepts in meaningful and, and intelligible ways.
So a concept is really a, it's a connection between percepts.
Um, once.
My robot vacuum just decided to turn on.
So I need to close the door.
Um, I'm trying to tell us something.
I know it's like, Hey, I'm an agent over here.
Um, lightning strikes, uh, a concept is a connection between percepts, right?
And so without this activity, that's able to, and it's because we're not just remembering
how percepts have related to each other in the past, because we're also capable of novelty.
We're capable of adapting to new situations.
And so there's some other pole here to the process of agency.
That's not just about perception.
And, but, but that perceptual pole is definitely highly contingent on the type of sensory organs
we have and on the type of, um, common sense way of amalgamating those different perceptual
streams into a picture of a three-dimensional world of, of moving bodies.
Um, and we get habituated to that, that world and that, that common sense way of perceiving
things.
But I, all I would say is that because we have this conceptual thinking capacity, um,
there's no, there's no limit sort of a priori limit to the knowledge that we can gain of the
world around us, right?
Um, we're, we're limited as a matter of fact, but in principle, we can always overcome
any limit, um, that seems to be in place, whether we can get to the final truth of the
nature of everything.
I don't know, but it seems to me that there's a pathway forward.
We have good reason to believe that by engaging in this process of thinking, we can discover
new things about the perceptual world that are not just there in the past as memory and
habit that we've accumulated.
And I don't want to get all spooky and mystical, but you, you know, Karen, you brought up Jordan
Peterson.
He will often reference the logos, the idea of this or this ordering principle in the
cosmos and whatever morpho spaces, I think it has something to do with this ordering principle
and many traditions have referred to it as the logos and our thinking activity, I think
is, is in some ways a participation in that ordering principle, um, finite participation
in an ordering principle that's far vaster and more, uh, magical and mysterious than, than
humans have yet even scratched the surface of.
But nonetheless, I think there is this deeper intelligibility in the nature of things, which
if it, if it weren't real, science would not be possible, right?
Well, the way to keep the, the ordering principle from being spooky is to just think about it
the way he thinks about it, which is at the, at the border between order and chaos is this
capacity to either move into chaos voluntarily or fall into chaos accidentally.
And in the chaos, there are all kinds of answers because all the answers lie in the unknown, all
the new information lies in the unknown.
And that that's the ordering principle gathering what's necessary from the unknown to bring it
back into the known so that the order becomes, um, new again and does not remain static, but
still has that dynamic quality that keeps it fresh.
That that's the ordering principle.
And I don't think that's spooky at all because that also scales all the way down when you can
see that, you can see that everywhere mm-hmm yeah, yeah.
And I think that the challenge here is to avoid falling prey to what Dan Dennett was so critical
of this idea of sky hooks.
And, you know, I think this is why we need to zero in on agency and recognize that, um, whatever
agency is it's operating at all scales.
It grows more capable as it evolves because it learns how to dip further into this space
of possibilities and it knows how to do.
So not just as a matter of, you know, ingressing novelty, but as a matter of ingressing relevant
novelty, like agents can, human beings can dip into this set of unrealized possibilities in
a way that is not just chaotic, but relevant to the past.
And the, the real evolutionary challenge challenge for agents is, is the ingression of relevant
novelty because there's infinite possibilities.
And we need to know as agents in any given moment of our experience, which of those possibilities
have relevance to our actual situation.
And that's a, uh, that's a problem that I think an evolutionary understanding and a, an
understanding of evolution as a pedagogical process, uh, of, of gradually learning about,
you know, like what John Ravicki would call relevance, realization and ratcheting up this
capacity.
Uh, and it's a collective effort.
And I, I like Michael, your emphasis on second person.
I think that's right.
Uh, I think that's where all the action is and we can talk about these two poles of the
first and the third person, but it's the, it's that relationship, the relationality, the
communication, um, where all the action is.
And so this is why agency is never just something that an, an individual does agency and intelligence
even are always collective efforts.
And I think for, but for cells to engage in this collective effort, there needs to be something
that they all share, right?
Some kind of ordering principle that they're all capable of participating in.
And that's the mystery.
I feel like that's what we're bumping up against here.
Um, and what we need new concepts to get a handle on and in a way that doesn't certainly
doesn't revert to the sort of, um, essentialist teleology that scholastics pre-evolutionary
thinkers were talking about, but we need to, we need to revisit some of those ideas of platonic
realism and again, you know, re-imagine it in an evolutionary context because we can't move
forward without some understanding of ideals, forms, right?
Yeah.
I'd like to ask Michael here, when you were using this, this term, um, ingression of relevant
novelty.
It made me think about something I heard Michael just say this morning.
Um, you were saying Michael, that this was in a video that you did with Carlos Farias.
I think you called it, uh, poly computing.
And you were saying that with the right prompting, meaning the right chemical signals from the
parasite, the Oak tree leaf will produce these beautiful galls.
So, but when I was thinking about that, I'm thinking, does that prompting presuppose that
the subroutine that creates that gall is already present in the leaf and it just needed to be
prompted by the chemical signal or what does that mean?
Right.
What does it mean?
I mean, that that's a, that's a, that's a tricky question is because, and I think, uh, you know,
I'm pretty sure the ancients were all over this in the sense that when you dump a bunch of marbles
onto this thing and you get this nice bell curve or you get a distribution of prime numbers, does that
mean that was already there and all you did is somehow pull it out by virtue of creating the right
machine or, or, or not.
Right.
I think it, I think it's exactly the same question.
Um, in the prompt is the physical machine, uh, that, that you're using to get this effect.
And the pattern is the thing that you're going to get.
I mean, I don't know, I don't know of, you know, people argue about whether mathematics is
discovered or invented and stuff like that.
But there are so many cases where, uh, there is this, uh, this, this, this deep, um, uh,
pattern that emerges and I, you know, I'm, I'm not sure it's, it's helpful to argue philosophically
about whether it was there or not, but I do think so.
So here, here's how I've taken this approach is, is I, you know, I, I don't really want
to argue whether this, this thing was there before or not, but as an engineer, what I'd
like is to have a frame that helps me engineer.
So a frame that helps me engineer.
If, if a frame like that is, well, you've got to track all the microstates of everything.
And, and, and the only things that are there are things that were, were selected for by
evolution, like those kinds of frames are, are, are provably deficient.
They, they do not do a great job.
And so, uh, that means we can have a different frame, which says, okay, there's
us, there's a space of possible outcomes.
The evolution produces machines for exploring that space.
And we can hijack some of that same machinery now faster and better with, with AI and with
other tools to, uh, pull out the contents of that space.
And in fact, to help me engineer, I'm even going to make a map of that space.
I don't want to have philosophical debates about whether that space is real.
All I know is if I had a map of that space and I knew which things were next to which other
things, and therefore, which of my prompts I could, I could leverage.
With the least amount of effort to pull out new things.
I would do better than somebody who doesn't believe in the space.
Who doesn't think it exists, you know, all of that, that kind of stuff.
So that, that's, you know, that's the approach I take on this, which maybe, you know, I've
had, I've had people call it, um, you know, philosophically unsophisticated and, and, and
fine, maybe it is, uh, but, but, but in the end, what I want is I want us to be able to
distinguish between competing worldviews.
And to me, the thing that produces more, more unified understanding, more compact descriptions
of, of reality that help us better relate to things around us, the various different
agency things in our environment, uh, better prediction and control, more invention, more
discovery, more new capabilities.
That that's the worldview I I'm looking for.
That's, that's the lens, whatever lens gets me to that.
And, and I think then this question of whether it was there before, I don't know, but I do
know that there's a whole, um, space of, of, of, of possibilities.
And I'd like a map of that space as an engineer, I want a map of that space.
Well, yeah, I mean, it's, it's like the possibility space, right?
I know, I know mathematicians who say that they can actually walk around in that possibility
space of mathematics.
They, they, they, they can visualize the entire thing inside their heads.
And, uh, that made me think about the salamander when it loses a limb, it can regrow a new limb.
Is that, is that some sort of memory capacity?
Well, well, we know, I mean, I, in planaria, uh, we, we know it's a memory capacity a, because,
uh, we can see it, we can see the memories and we can rewrite to these memories.
And also just for fun, and this is unpublished.
So take this with a grain of salt, but, uh, preliminary data say that when you put classic
memory blockers, you know, things that block learning and recall and rats and humans and
so on, uh, you can make planaria, forget how to be a planarian.
They literally go back and be a nice, I mean, again, I'm not peer reviewed, right?
Like early preliminary data, whatever, you know, take it, take it with a grain of salt.
But, but, but the, the fact is, aside from any of that, for all, all the work that we've done,
a lot of it is borrowing concepts from cognitive neuroscience and applying them fruitfully to
discover new things in areas where people normally don't think it belongs.
Right.
So we will take things, uh, um, uh, perceptual by stability.
And I mean, of course, active inference and, and memory and visual illusions and expectation.
I mean, there's a whole table in a couple of my papers.
I get this long table of, you take all these things and all of them are usable in developmental
biology and in other, other fields because the techniques can't tell the difference.
And therefore I, that's why, you know, we kind of started out this way talking about, um,
fields and silos come, come back to that.
Uh, I think they're artificial.
We, we make these differences and we make departments of this and departments of that.
And, and, and to the point where things I say in one department, everybody's like, yeah,
no kidding.
We, of course, that's obvious.
And then another department, they throw tomatoes because, because it sounds ridiculous.
Right.
And, and we have different journals and we have different funding bodies and whatever, but
the techniques can't tell the difference.
And so that tells me that this is artificial in a, in a, in a, in a large sense, um, there,
there needs to be.
Yeah.
And, and, and that also goes back to the strategy again, I don't, you know, philosophic, I don't
know if this is naive or not, but, uh, somebody said to me once, uh, you know, you, you get
into this, you get into so much trouble calling these things memory.
Why have all these arguments just call it about, come up with a different name, just come up
with a different name.
And then, and then people don't need to fight about it.
And all I could think of was, well, Newton could have said, well, let's see, there's gravity
for, for the moon and then there's shmavity for the, for the apple falling down to the
earth.
Good.
We, now we got two names.
We don't have to fight about it, but, but he would have missed out on like the core insight
that it's the same thing.
Right.
And so, so, so no, I don't want to come up with a new name because, because I think
the name of the game is unification.
I think as much as possible, we should be looking for symmetries for invariance and not
proliferating, uh, names for these things.
And yeah, um, this is exactly why Whitehead as a metaphysician, uh, wants to say that
energetic transmission is, uh, a kind of vector feeling.
And so that there are, he, I mean, his technical term is prehension that, that prehensive relationships,
which would be his way of talking about causal transmission, uh, has a, it's, it's the, it's
the transmission of feelings, right?
And so, uh, some people would hear that and think it's actually, it's absolutely kooky,
but on the other hand, it's a search for unification so that we don't have to say that the very complex,
intense, uh, forms of feeling that animals and, and human beings, uh, experience somehow
arises through some other mysterious process that, that seems very difficult to ever understand.
None of this was there from the beginning and we just need to, we're not adding something new to physics.
We're understanding what physics itself is already describing, um, as in some sense continuous with what
psychology would be describing.
Yeah.
Right.
So I think it was, I don't, I don't know if it was Chris Fields or who it was, but maybe it was Chris
who said, you know, the project is the sentience of physics and the physics of sentience.
Absolutely.
And that seems, that seems to get at all of it.
Mike, you, you made a comment in one of your other videos that for you, there's a very interesting
distinction between control and relationship.
Could you comment on that just briefly as it might connect with what he was just saying?
Yeah.
Um, you know, so, so figure one in my, uh, my first paper on tame this, uh, technological
approach to mind everywhere framework figure one is this thing that, uh, is kind of like
this, it's like, I call it the spectrum of persuadability.
So it's this idea that in order to put this, this all goes back to the, the, the, the whole,
um, light cognitive light cone thing came about in, uh, 2018 when I was at a Templeton conference
and Pranab Das asked us to come up with a framework in which diverse intelligences could all be
compared together, you know?
And so people were thinking, um, you know, primates and elephants and, and, and, you
know, uh, crows and maybe octopus and things like this.
And, you know, and so we were, we were thinking about this and I'm, I'm thinking, okay, let's,
what, what if we crank up the knobs to, to 11, you know, and all of this and say, it sells AI,
you know, software AI, aliens, synthetic beings, like all of it, what's the, and so, and so I started
thinking about what, what do all agents, regardless of their composition, regardless
of their provenance, how they gave, you know, designed, engineered, whatever, what do they
all have in common?
And so, so I came up with this, with this kind of focus, which again, not super new.
I mean, uh, we Wiener and Rosenbluth had it in 1943, this, this idea that, that everything's
about, um, levels of, uh, levels of controllability.
And so, and so I got this spectrum of persuadability, which is basically, uh, you know, you
got, and these are just some waypoints, right?
So you get your mechanical clock, which you're not going to convince of anything.
You're not going to reward and punish it.
You just have to physically rewire it and then you get your thermostat and that's better because
you have a set point and you don't have to even know how the rest of the thing works,
as long as you know how to, how to rewire the set point.
And then you've got some, some animals, which can, and, and some other agents, which can learn
from experience and there you really don't need to know much except the currency of behaviorist,
uh, and kinds of protocols, because they offer this amazing interface to you, this learning
interface where, you know, humans for thousands of years, train dogs and horses without knowing
any neuroscience at all.
Um, and then, and then you got humans and whatever else past that.
And so, and so one way to think about this as an engineer is control.
So what I want is I want to be at the right place on this, uh, diagram for any given system.
Somebody gives me something I don't want to undershoot with agency.
I don't want to be, um, you know, treating, uh, uh, the human brain as a, as a, as a paperweight
and, and kind of not understand what I've, what I've got.
And I don't want to overshoot.
I don't want to look at that.
I don't want to be yelling at this, um, uh, mechanical clock and trying to make it feel
guilty.
I want to be, I want to be at the, at the right level for whatever the system is.
Um, so, so an engineer sees that and he sees efficient prediction and control, but, but I see
this much more broadly, which is what you're really looking for is a relationship with the system.
And at lower ends, at the lower ends of that spectrum, it really does just kind of smoothly
blend into an engineering approach, but ultimately sort of at the, at the higher ends.
And so we're talking with other humans with, uh, possible, you know, cyborgs in the future,
maybe with AI's, maybe with aliens who don't look anything like us, what you're looking for
are ways to relate to that system, to ask how much agency is there that I can, um, relate
to.
And specifically I found, um, something, uh, and I apologize in about a minute, I'm gonna
have to run.
Um, somebody, I recently found something that, that they, they came out with, they came, they're
trying to come up with this thing to distinguish human products from, um, things that AI makes,
right.
Cause some people think that's a very profound difference.
And so they want to know, so they call it proof of humanity that, you know, you get,
you get these like, um, uh, uh, cryptographic certificates or something that says it's, you know, proof
of humanity and, and as I think about it, you know, if I want proof of humanity for whoever
I'm having a relationship with, what do I really, what am I really after?
Am I really after knowing what your DNA is?
Nah, I don't care about your DNA.
Am I really after knowing what your anatomy is?
And then I'm going to find out that, you know, 80% of you has been replaced by artificial
organs.
What, what, what do we care about when we're talking proof of humanity?
And I think what we care, what we're talking about is a, uh, is, is, is a level of, of
compassion, uh, uh, uh, uh, a minimally human standard human level of ability to care about
certain things and having similar existential, um, uh, you know, uh, struggles and, and, and
stuff like that.
So, so it's not just about the engineering and control like we have in regenerative medicine.
It, it, I think it shades into the kinds of things we do with other, with other
humans and societies and so on.
Yeah.
I love that.
We're ending here with ethics because there's so many ethical implications here, um, with
your research in this point of view, because if we're dealing with agencies all the way
down, obviously there's no way to never, um, um, inhibit or want to control the agency
of some beings.
Like we have to eat life is robbery as whitehead says, but he adds the, the robber needs justification.
And that's where ethics and morals come in.
And for whitehead, the whole process of evolution is this, this movement from force to persuasion
is the dominant mode of relationship.
And that's what human beings are struggling with right now.
Right.
So I know we both have to go, but I think that's a great place to, to end, um, so much more to
talk about, but this was so much fun.
Absolutely.
Yeah.
Thank you so much.
Yeah.
Great.
Great.
See you later.
All right.
Bye.
Thanks.
Alright.
Bye.
Bye.
Bye-bye.
Bye.
Bye.
Bye.
Bye.
Bye.
Bye.
Bye.
Bye.
Bye.
Bye.
Bye.
Bye.
Bye.
Bye.
Bye.
Bye.
Bye.
